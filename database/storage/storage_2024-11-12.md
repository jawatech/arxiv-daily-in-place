# arxiv-daily
 Automated deployment @ 2024-11-12 20:37:28 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-01**|**Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**|Mehdi Hosseini Chagahi et.al.|[2411.00916v2](http://arxiv.org/abs/2411.00916v2)|null|
|**2024-10-25**|**A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**|Muath Alsuhaibani et.al.|[2410.19898v1](http://arxiv.org/abs/2410.19898v1)|null|
|**2024-10-23**|**An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**|Shruthi Chari et.al.|[2410.17504v1](http://arxiv.org/abs/2410.17504v1)|[link](https://github.com/tetherless-world/metaexplainer)|
|**2024-10-22**|**Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**|Lukas Hughes-Noehrer et.al.|[2410.16879v1](http://arxiv.org/abs/2410.16879v1)|null|
|**2024-10-19**|**Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**|Gesa Mittmann et.al.|[2410.15012v1](http://arxiv.org/abs/2410.15012v1)|null|
|**2024-10-15**|**Explainable AI Methods for Multi-Omics Analysis: A Survey**|Ahmad Hussein et.al.|[2410.11910v1](http://arxiv.org/abs/2410.11910v1)|null|
|**2024-10-14**|**Study on the Helpfulness of Explainable Artificial Intelligence**|Tobias Labarta et.al.|[2410.11896v1](http://arxiv.org/abs/2410.11896v1)|[link](https://github.com/tlabarta/helpfulnessofxai)|
|**2024-10-12**|**Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**|Abdullah Mamun et.al.|[2410.09635v1](http://arxiv.org/abs/2410.09635v1)|[link](https://github.com/ab9mamun/aimen)|
|**2024-10-10**|**Artificial intelligence techniques in inherited retinal diseases: A review**|Han Trinh et.al.|[2410.09105v1](http://arxiv.org/abs/2410.09105v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|null|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v1](http://arxiv.org/abs/2410.01855v1)|null|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v3](http://arxiv.org/abs/2409.12087v3)|null|
|**2024-09-09**|**Explainable AI: Definition and attributes of a good explanation for health AI**|Evangelia Kyrimi et.al.|[2409.15338v1](http://arxiv.org/abs/2409.15338v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v2](http://arxiv.org/abs/2407.15851v2)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-17**|**Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**|Vincent Olesen et.al.|[2406.12142v2](http://arxiv.org/abs/2406.12142v2)|[link](https://github.com/volesen/slicing-through-bias)|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. ZajÄc et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel MirÃ³-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|SÃ©amus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Cause and Effect: Can Large Language Models Truly Understand Causality?**|Swagata Ashwani et.al.|[2402.18139v3](http://arxiv.org/abs/2402.18139v3)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|TimothÃ©e Schmude et.al.|[2401.13324v6](http://arxiv.org/abs/2401.13324v6)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-12-04**|**Class-Discriminative Attention Maps for Vision Transformers**|Lennart Brocki et.al.|[2312.02364v3](http://arxiv.org/abs/2312.02364v3)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v3](http://arxiv.org/abs/2311.12573v3)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|
|**2023-11-03**|**Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**|Emma A. M. Stanley et.al.|[2311.02115v2](http://arxiv.org/abs/2311.02115v2)|[link](https://github.com/estanley16/simba)|
|**2023-10-29**|**Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**|Adam White et.al.|[2310.19174v1](http://arxiv.org/abs/2310.19174v1)|null|
|**2023-10-03**|**Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**|Hossein Shreim et.al.|[2310.01828v2](http://arxiv.org/abs/2310.01828v2)|[link](https://github.com/geoaigroup/geoai-ecrs2023)|
|**2023-09-26**|**Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**|Muhammad Aurangzeb Ahmad et.al.|[2311.01463v1](http://arxiv.org/abs/2311.01463v1)|null|
|**2023-09-20**|**When to Trust AI: Advances and Challenges for Certification of Neural Networks**|Marta Kwiatkowska et.al.|[2309.11196v1](http://arxiv.org/abs/2309.11196v1)|null|

#### Abstracts
##### **Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**
2411.00916v2 by Mehdi Hosseini Chagahi, Saeed Mohammadi Dashtaki, Niloufar Delfan, Nadia Mohammadi, Alireza Samari, Behzad Moshiri, Md. Jalil Piran, Oliver Faust

Osteoporosis is a common condition that increases fracture risk, especially
in older adults. Early diagnosis is vital for preventing fractures, reducing
treatment costs, and preserving mobility. However, healthcare providers face
challenges like limited labeled data and difficulties in processing medical
images. This study presents a novel multi-modal learning framework that
integrates clinical and imaging data to improve diagnostic accuracy and model
interpretability. The model utilizes three pre-trained networks-VGG19,
InceptionV3, and ResNet50-to extract deep features from X-ray images. These
features are transformed using PCA to reduce dimensionality and focus on the
most relevant components. A clustering-based selection process identifies the
most representative components, which are then combined with preprocessed
clinical data and processed through a fully connected network (FCN) for final
classification. A feature importance plot highlights key variables, showing
that Medical History, BMI, and Height were the main contributors, emphasizing
the significance of patient-specific data. While imaging features were
valuable, they had lower importance, indicating that clinical data are crucial
for accurate predictions. This framework promotes precise and interpretable
predictions, enhancing transparency and building trust in AI-driven diagnoses
for clinical integration.

æè¦ï¼éª¨è³ªçé¬çæ¯ä¸ç¨®å¸¸è¦çç¾çï¼æå¢å éª¨æçé¢¨éªï¼ç¹å¥æ¯èå¹´äººãæ©æè¨ºæ·å°æ¼é é²éª¨æãéä½æ²»çææ¬åç¶­æè¡åè½åè³ééè¦ãç¶èï¼é«çä¿å¥æä¾èé¢è¨èæ¨è¨æ¸ææéåèçé«å­¸å½±åå°é£ç­ææ°ãæ¬ç ç©¶æåºäºä¸åæ°ç©çå¤æ¨¡å¼å­¸ç¿æ¡æ¶ï¼è©²æ¡æ¶æ´åäºè¨åºåå½±åæ¸æï¼ä»¥æé«è¨ºæ·æºç¢ºæ§åæ¨¡åå¯è§£éæ§ãè©²æ¨¡åå©ç¨ä¸åé è¨ç·´çç¶²è·¯ï¼VGG19ãInceptionV3 å ResNet50ï¼å¾ X å°ç·å½±åä¸­æåæ·±åº¦ç¹å¾µãéäºç¹å¾µä½¿ç¨ PCA è½æä»¥éä½ç¶­åº¦ä¸¦å°æ³¨æ¼æç¸éççµæé¨åãåºæ¼èé¡çé¸æéç¨è­å¥åºæå·ä»£è¡¨æ§ççµæé¨åï¼ç¶å¾å°éäºçµæé¨åèé èççè¨åºæ¸æçµåï¼ä¸¦ééå¨é£æ¥ç¶²è·¯ (FCN) é²è¡æçµåé¡ãç¹å¾µéè¦æ§åçªåºäºééµè®æ¸ï¼è¡¨æçå²ãBMI åèº«é«æ¯ä¸»è¦è²¢ç»å ç´ ï¼å¼·èª¿äºæ£èç¹å®æ¸æçéè¦æ§ãéç¶å½±åç¹å¾µå¾æå¹å¼ï¼ä½å®åçéè¦æ§è¼ä½ï¼éè¡¨æè¨åºæ¸æå°æ¼æºç¢ºé æ¸¬è³ééè¦ãæ­¤æ¡æ¶ä¿è¿äºæºç¢ºä¸å¯è§£éçé æ¸¬ï¼æé«äºéæåº¦ï¼ä¸¦å»ºç«äºå° AI é©åè¨ºæ·å¨è¨åºæ´åä¸­çä¿¡ä»»ã

##### **A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**
2410.19898v1 by Muath Alsuhaibani, Ali Pourramezan Fard, Jian Sun, Farida Far Poor, Peter S. Pressman, Mohammad H. Mahoor

This review paper explores recent advances in deep learning approaches for
non-invasive cognitive impairment detection. We examine various non-invasive
indicators of cognitive decline, including speech and language, facial, and
motoric mobility. The paper provides an overview of relevant datasets,
feature-extracting techniques, and deep-learning architectures applied to this
domain. We have analyzed the performance of different methods across modalities
and observed that speech and language-based methods generally achieved the
highest detection performance. Studies combining acoustic and linguistic
features tended to outperform those using a single modality. Facial analysis
methods showed promise for visual modalities but were less extensively studied.
Most papers focused on binary classification (impaired vs. non-impaired), with
fewer addressing multi-class or regression tasks. Transfer learning and
pre-trained language models emerged as popular and effective techniques,
especially for linguistic analysis. Despite significant progress, several
challenges remain, including data standardization and accessibility, model
explainability, longitudinal analysis limitations, and clinical adaptation.
Lastly, we propose future research directions, such as investigating
language-agnostic speech analysis methods, developing multi-modal diagnostic
systems, and addressing ethical considerations in AI-assisted healthcare. By
synthesizing current trends and identifying key obstacles, this review aims to
guide further development of deep learning-based cognitive impairment detection
systems to improve early diagnosis and ultimately patient outcomes.

æè¦ï¼æ¬ç¯è©è«æ¢è¨äºæ·±åº¦å­¸ç¿æ¹æ³å¨éä¾µå¥å¼èªç¥åè½éç¤æª¢æ¸¬ä¸çææ°é²å±ãæåæª¢è¦äºåç¨®éä¾µå¥å¼çèªç¥è¡°éææ¨ï¼åæ¬èªè¨åèªè¨ãé¢é¨åéåæ©è½ãæ¬ææ¦è¿°äºèæ­¤é åç¸éçè³æéãç¹å¾µæåæè¡åæ·±åº¦å­¸ç¿æ¶æ§ãæååæäºä¸åæ¹æ³å¨ä¸åæ¹å¼ä¸çè¡¨ç¾ï¼ä¸¦è§å¯å°åºæ¼èªè¨åèªè¨çæ¹æ³éå¸¸è½éå°æé«çæª¢æ¸¬è¡¨ç¾ãçµåè²å­¸åèªè¨ç¹å¾µçç ç©¶å¾å¾åªæ¼ä½¿ç¨å®ä¸æ¹å¼çç ç©¶ãé¢é¨åææ¹æ³é¡¯ç¤ºåºè¦è¦ºæ¹å¼çæ½åï¼ä½ç ç©¶è¼å°ãå¤§å¤æ¸è«æå°æ³¨æ¼äºååé¡ï¼åæèæªåæï¼ï¼è¼å°æ¢è¨å¤é¡æåæ­¸ä»»åãé·ç§»å­¸ç¿åé è¨ç·´èªè¨æ¨¡åå·²æçºæµè¡ä¸ææçæè¡ï¼ç¹å¥æ¯å°æ¼èªè¨åæãåç®¡åå¾äºéå¤§é²å±ï¼ä½ä»å­å¨ä¸äºææ°ï¼åæ¬è³ææ¨æºååå¯åæ§ãæ¨¡åå¯è§£éæ§ãç¸±ååæéå¶åè¨åºé©ææ§ãæå¾ï¼æåæåºäºæªä¾çç ç©¶æ¹åï¼ä¾å¦èª¿æ¥èèªè¨ç¡éçèªé³åææ¹æ³ãéç¼å¤æ¨¡å¼è¨ºæ·ç³»çµ±ï¼ä»¥åè§£æ±ºäººå·¥æºæ§è¼å©é«çä¿å¥ä¸­çå«çèéãééç¶åç®åçè¶¨å¢åæ¾åºééµéç¤ï¼æ¬ç¯è©è«æ¨å¨å¼å°æ·±åº¦å­¸ç¿çºåºç¤çèªç¥åè½éç¤æª¢æ¸¬ç³»çµ±çé²ä¸æ­¥ç¼å±ï¼ä»¥æ¹åæ©æè¨ºæ·ï¼ä¸¦æçµæ¹åæ£èçæ²»ççµæã

##### **An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**
2410.17504v1 by Shruthi Chari

Explainable Artificial Intelligence (AI) focuses on helping humans understand
the working of AI systems or their decisions and has been a cornerstone of AI
for decades. Recent research in explainability has focused on explaining the
workings of AI models or model explainability. There have also been several
position statements and review papers detailing the needs of end-users for
user-centered explainability but fewer implementations. Hence, this thesis
seeks to bridge some gaps between model and user-centered explainability. We
create an explanation ontology (EO) to represent literature-derived explanation
types via their supporting components. We implement a knowledge-augmented
question-answering (QA) pipeline to support contextual explanations in a
clinical setting. Finally, we are implementing a system to combine explanations
from different AI methods and data modalities. Within the EO, we can represent
fifteen different explanation types, and we have tested these representations
in six exemplar use cases. We find that knowledge augmentations improve the
performance of base large language models in the contextualized QA, and the
performance is variable across disease groups. In the same setting, clinicians
also indicated that they prefer to see actionability as one of the main foci in
explanations. In our explanations combination method, we plan to use similarity
metrics to determine the similarity of explanations in a chronic disease
detection setting. Overall, through this thesis, we design methods that can
support knowledge-enabled explanations across different use cases, accounting
for the methods in today's AI era that can generate the supporting components
of these explanations and domain knowledge sources that can enhance them.

æè¦ï¼å¯è§£éäººå·¥æºæ§ï¼AIï¼å°æ³¨æ¼åå©äººé¡äºè§£ AI ç³»çµ±éä½æå¶æ±ºç­ï¼æ¸åå¹´ä¾ä¸ç´æ¯ AI çåºç³ãæè¿çå¯è§£éæ§ç ç©¶å°æ³¨æ¼è§£é AI æ¨¡åææ¨¡åå¯è§£éæ§çéä½ãä¹æå¹¾ä»½ç«å ´è²æåè©è«è«æè©³ç´°èªªæäºæçµä½¿ç¨èå°ä»¥ä½¿ç¨èçºä¸­å¿çå¯è§£éæ§çéæ±ï¼ä½å¯¦ä½è¼å°ãå æ­¤ï¼æ¬è«ææ¨å¨å½è£æ¨¡ååä»¥ä½¿ç¨èçºä¸­å¿çå¯è§£éæ§ä¹éçä¸äºå·®è·ãæåå»ºç«ä¸åè§£éæ¬é«ï¼EOï¼ä»¥ééå¶æ¯æ´åä»¶ä¾è¡¨ç¤ºå¾æç»ä¸­è¡ççè§£éé¡åãæåå¯¦ä½ä¸åç¥è­å¢å¼·çåç­ï¼QAï¼ç®¡ç·ï¼ä»¥å¨è¨åºç°å¢ä¸­æ¯æ´æå¢è§£éãæå¾ï¼æåæ­£å¨å¯¦ä½ä¸åç³»çµ±ï¼ä»¥çµåä¾èªä¸å AI æ¹æ³åè³ææ¨¡å¼çè§£éãå¨ EO ä¸­ï¼æåå¯ä»¥è¡¨ç¤º 15 ç¨®ä¸åçè§£éé¡åï¼ä¸¦ä¸æåå·²å¨å­åç¯ä¾ä½¿ç¨æ¡ä¾ä¸­æ¸¬è©¦éäºè¡¨ç¤ºãæåç¼ç¾ï¼ç¥è­å¢å¼·æ¹åäºåºç¤å¤§åèªè¨æ¨¡åå¨æå¢å QA ä¸­çæè½ï¼ä¸¦ä¸æè½å ç¾çç¾¤çµèç°ãå¨ç¸åçç°å¢ä¸­ï¼è¨åºé«çä¹è¡¨ç¤ºä»åå¸æå°å¯æä½æ§è¦çºè§£éä¸­çä¸»è¦ç¦é»ä¹ä¸ãå¨æåçè§£éçµåæ¹æ³ä¸­ï¼æåè¨ç«ä½¿ç¨ç¸ä¼¼æ§ææ¨ä¾ç¢ºå®æ¢æ§çåµæ¸¬ç°å¢ä¸­è§£éçç¸ä¼¼æ§ãç¸½é«èè¨ï¼ééæ¬è«æï¼æåè¨­è¨äºå¯ä»¥å¨ä¸åä½¿ç¨æ¡ä¾ä¸­æ¯æ´ç¥è­åç¨è§£éçæ¹æ³ï¼èéå°ç¶ä» AI æä»£ä¸­å¯ä»¥ç¢çéäºè§£éçæ¯æ´åä»¶åå¯ä»¥å¢å¼·éäºè§£éçé åç¥è­ä¾æºçæ¹æ³ã

##### **Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**
2410.16879v1 by Lukas Hughes-Noehrer, Leda Channer, Gabriel Strain, Gregory Yates, Richard Body, Caroline Jay

Objectives: To investigate clinicians' attitudes towards current automated
interpretation of ECG and novel AI technologies and their perception of
computer-assisted interpretation. Materials and Methods: We conducted a series
of interviews with clinicians in the UK. Our study: (i) explores the potential
for AI, specifically future 'human-like' computing approaches, to facilitate
ECG interpretation and support clinical decision making, and (ii) elicits their
opinions about the importance of explainability and trustworthiness of AI
algorithms. Results: We performed inductive thematic analysis on interview
transcriptions from 23 clinicians and identified the following themes: (i) a
lack of trust in current systems, (ii) positive attitudes towards future AI
applications and requirements for these, (iii) the relationship between the
accuracy and explainability of algorithms, and (iv) opinions on education,
possible deskilling, and the impact of AI on clinical competencies. Discussion:
Clinicians do not trust current computerised methods, but welcome future 'AI'
technologies. Where clinicians trust future AI interpretation to be accurate,
they are less concerned that it is explainable. They also preferred ECG
interpretation that demonstrated the results of the algorithm visually. Whilst
clinicians do not fear job losses, they are concerned about deskilling and the
need to educate the workforce to use AI responsibly. Conclusion: Clinicians are
positive about the future application of AI in clinical decision-making.
Accuracy is a key factor of uptake and visualisations are preferred over
current computerised methods. This is viewed as a potential means of training
and upskilling, in contrast to the deskilling that automation might be
perceived to bring.

æè¦ï¼<paragraph>ç®çï¼èª¿æ¥è¨åºé«çå°ç®åèªååå¿é»åè§£è®åæ°çäººå·¥æºæ§æè¡çæåº¦ï¼ä»¥åä»åå°é»è¦è¼å©è§£è®ççæ³ãææåæ¹æ³ï¼æåå°è±åçè¨åºé«çé²è¡äºä¸ç³»åè¨ªè«ãæåçç ç©¶ï¼(i) æ¢è¨äººå·¥æºæ§çæ½åï¼ç¹å¥æ¯æªä¾çãé¡äººé¡ãéç®æ¹æ³ï¼ä»¥ä¿é²å¿é»åè§£è®ä¸¦æ¯æè¨åºæ±ºç­å¶å®ï¼ä»¥å (ii) å¾µæ±ä»åå°äººå·¥æºæ§æ¼ç®æ³çå¯è§£éæ§åå¯ä¿¡åº¦ççæ³ãçµæï¼æåå° 23 ä½è¨åºé«ççè¨ªè«è¨éé²è¡äºæ­¸ç´ä¸»é¡åæï¼ä¸¦æ¾åºä»¥ä¸ä¸»é¡ï¼(i) å°ç®åç³»çµ±ç¼ºä¹ä¿¡ä»»ï¼(ii) å°æªä¾äººå·¥æºæ§æç¨åå°éäºæç¨çè¦æ±ææ­£é¢æåº¦ï¼(iii) æ¼ç®æ³çæºç¢ºæ§åå¯è§£éæ§ä¹éçéä¿ï¼ä»¥å (iv) å°æè²ãå¯è½çæè½éåï¼ä»¥åäººå·¥æºæ§å°è¨åºè½åçå½±é¿ççæ³ãè¨è«ï¼è¨åºé«çä¸ä¿¡ä»»ç®åçé»è¦åæ¹æ³ï¼ä½æ­¡è¿æªä¾çãäººå·¥æºæ§ãæè¡ãå¨è¨åºé«çç¸ä¿¡æªä¾ç AI è§£è®æºç¢ºçææ³ä¸ï¼ä»åä¸å¤ªæå¿å®æ¯å¦å¯è§£éãä»åä¹æ¯è¼åæ­¡è½ä»¥è¦è¦ºæ¹å¼åç¾æ¼ç®æ³çµæçå¿é»åè§£è®ãéç¶è¨åºé«çä¸å®³æå¤±æ¥­ï¼ä½ä»åæå¿æè½éåï¼ä»¥åéè¦æè²å¡å·¥è² è²¬ä»»å°ä½¿ç¨äººå·¥æºæ§ãçµè«ï¼è¨åºé«çå°äººå·¥æºæ§å¨è¨åºæ±ºç­å¶å®ä¸­çæªä¾æç¨ææ­£é¢æåº¦ãæºç¢ºæ§æ¯æ¡ç¨äººå·¥æºæ§çä¸åééµå ç´ ï¼èè¦è¦ºåæ¯ç®åçé»è¦åæ¹æ³æ´åéçãéè¢«è¦çºä¸ç¨®æ½å¨çå¹è¨åæåæè½çæ¹æ³ï¼èèªååå¯è½å¸¶ä¾çæè½éåå½¢æå°æ¯ã</paragraph>

##### **Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**
2410.15012v1 by Gesa Mittmann, Sara Laiouar-Pedari, Hendrik A. Mehrtens, Sarah HaggenmÃ¼ller, Tabea-Clara Bucher, Tirtha Chanda, Nadine T. Gaisa, Mathias Wagner, Gilbert Georg Klamminger, Tilman T. Rau, Christina Neppl, Eva Maria CompÃ©rat, Andreas Gocht, Monika HÃ¤mmerle, Niels J. Rupp, Jula Westhoff, Irene KrÃ¼cken, Maximillian Seidl, Christian M. SchÃ¼rch, Marcus Bauer, Wiebke Solass, Yu Chun Tam, Florian Weber, Rainer Grobholz, Jaroslaw Augustyniak, Thomas Kalinski, Christian HÃ¶rner, Kirsten D. Mertz, Constanze DÃ¶ring, Andreas Erbersdobler, Gabriele Deubler, Felix Bremmer, Ulrich Sommer, Michael Brodhun, Jon Griffin, Maria Sarah L. Lenon, Kiril Trpkov, Liang Cheng, Fei Chen, Angelique Levi, Guoping Cai, Tri Q. Nguyen, Ali Amin, Alessia Cimadamore, Ahmed Shabaik, Varsha Manucha, Nazeel Ahmad, Nidia Messias, Francesca Sanguedolce, Diana Taheri, Ezra Baraban, Liwei Jia, Rajal B. Shah, Farshid Siadat, Nicole Swarbrick, Kyung Park, Oudai Hassan, Siamak Sakhaie, Michelle R. Downes, Hiroshi Miyamoto, Sean R. Williamson, Tim Holland-Letz, Carolin V. Schneider, Jakob Nikolas Kather, Yuri Tolkach, Titus J. Brinker

The aggressiveness of prostate cancer, the most common cancer in men
worldwide, is primarily assessed based on histopathological data using the
Gleason scoring system. While artificial intelligence (AI) has shown promise in
accurately predicting Gleason scores, these predictions often lack inherent
explainability, potentially leading to distrust in human-machine interactions.
To address this issue, we introduce a novel dataset of 1,015 tissue microarray
core images, annotated by an international group of 54 pathologists. The
annotations provide detailed localized pattern descriptions for Gleason grading
in line with international guidelines. Utilizing this dataset, we develop an
inherently explainable AI system based on a U-Net architecture that provides
predictions leveraging pathologists' terminology. This approach circumvents
post-hoc explainability methods while maintaining or exceeding the performance
of methods trained directly for Gleason pattern segmentation (Dice score: 0.713
$\pm$ 0.003 trained on explanations vs. 0.691 $\pm$ 0.010 trained on Gleason
patterns). By employing soft labels during training, we capture the intrinsic
uncertainty in the data, yielding strong results in Gleason pattern
segmentation even in the context of high interobserver variability. With the
release of this dataset, we aim to encourage further research into segmentation
in medical tasks with high levels of subjectivity and to advance the
understanding of pathologists' reasoning processes.

æè¦ï¼ååèºçæ¯å¨çç·æ§æå¸¸è¦çççï¼å¶æ¡æ§ç¨åº¦ä¸»è¦æ ¹æ Gleason è©åç³»çµ±ä½¿ç¨çµç¹ççå­¸æ¸æé²è¡è©ä¼°ãéç¶äººå·¥æºæ§ (AI) å¨æºç¢ºé æ¸¬ Gleason è©åæ¹é¢å·²å±ç¾æ½åï¼ä½éäºé æ¸¬éå¸¸ç¼ºä¹å§å¨çå¯è§£éæ§ï¼å¯è½æå°è´å°äººæ©äºåçä¸ä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æåå¼é²äºä¸åç± 54 ä½ççå­¸å®¶çµæçåéåéè¨»è§£ç 1,015 åçµç¹å¾®é£åæ ¸å¿å½±åçæ°ç©è³æéãéäºè¨»è§£æä¾äºè©³ç´°çå±é¨æ¨¡å¼æè¿°ï¼ç¨æ¼ç¬¦ååéæºåç Gleason åç´ãå©ç¨éåè³æéï¼æåéç¼äºä¸ååºæ¼ U-Net æ¶æ§çå§å¨å¯è§£é AI ç³»çµ±ï¼è©²ç³»çµ±æä¾äºå©ç¨ççå­¸å®¶è¡èªé²è¡é æ¸¬ãéç¨®æ¹æ³è¦é¿äºäºå¾å¯è§£éæ§æ¹æ³ï¼åæç¶­ææè¶è¶äºç´æ¥è¨ç·´ç¨æ¼ Gleason æ¨¡å¼åå²çæ¹æ³çæè½ï¼Dice åæ¸ï¼0.713 Â± 0.003ï¼è¨ç·´æ¼è§£éï¼ç¸å°æ¼ 0.691 Â± 0.010ï¼è¨ç·´æ¼ Gleason æ¨¡å¼ï¼ãééå¨è¨ç·´æéæ¡ç¨è»æ¨ç±¤ï¼æåææäºè³æä¸­çå§å¨ä¸ç¢ºå®æ§ï¼å³ä½¿å¨è§å¯èéè®ç°æ§é«çææ³ä¸ï¼ä¹è½å¨ Gleason æ¨¡å¼åå²ä¸­ç¢çå¼·å¤§ççµæãéééåºéåè³æéï¼æåæ¨å¨é¼åµé²ä¸æ­¥ç ç©¶ä¸»è§æ§é«çé«çä»»åä¸­çåå²ï¼ä¸¦å¢é²å°ççå­¸å®¶æ¨çéç¨ççè§£ã

##### **Explainable AI Methods for Multi-Omics Analysis: A Survey**
2410.11910v1 by Ahmad Hussein, Mukesh Prasad, Ali Braytee

Advancements in high-throughput technologies have led to a shift from
traditional hypothesis-driven methodologies to data-driven approaches.
Multi-omics refers to the integrative analysis of data derived from multiple
'omes', such as genomics, proteomics, transcriptomics, metabolomics, and
microbiomics. This approach enables a comprehensive understanding of biological
systems by capturing different layers of biological information. Deep learning
methods are increasingly utilized to integrate multi-omics data, offering
insights into molecular interactions and enhancing research into complex
diseases. However, these models, with their numerous interconnected layers and
nonlinear relationships, often function as black boxes, lacking transparency in
decision-making processes. To overcome this challenge, explainable artificial
intelligence (xAI) methods are crucial for creating transparent models that
allow clinicians to interpret and work with complex data more effectively. This
review explores how xAI can improve the interpretability of deep learning
models in multi-omics research, highlighting its potential to provide
clinicians with clear insights, thereby facilitating the effective application
of such models in clinical settings.

æè¦ï¼é«ééæè¡çé²æ­¥å°è´å¾å³çµ±çåè¨­é©åæ¹æ³è½è®çºè³æé©åçæ¹æ³ãå¤çµå­¸æ¯ææ´ååæä¾èªå¤åãçµå­¸ãçè³æï¼ä¾å¦åºå çµå­¸ãèç½è³ªçµå­¸ãè½éçµå­¸ãä»£è¬çµå­¸åå¾®çç©çµå­¸ãæ­¤æ¹æ³ééæ·åçç©è³è¨çä¸åå±¤é¢ï¼è½å¨é¢äºè§£çç©ç³»çµ±ãæ·±åº¦å­¸ç¿æ¹æ³æä¾æå¸¸è¢«ç¨æ¼æ´åå¤çµå­¸è³æï¼æä¾åå­äº¤äºä½ç¨çæ´å¯åï¼ä¸¦å å¼·å°è¤éç¾ççç ç©¶ãç¶èï¼éäºæ¨¡åå·æè¨±å¤ç¸äºé£æ¥çå±¤ç´åéç·æ§éä¿ï¼éå¸¸æåé»çå­ä¸æ¨£éä½ï¼ç¼ºä¹æ±ºç­éç¨çéæåº¦ãçºäºåææ­¤ææ°ï¼å¯è§£éäººå·¥æºæ§ (xAI) æ¹æ³å°æ¼å»ºç«éææ¨¡åè³ééè¦ï¼è®è¨åºé«çå¯ä»¥æ´ææå°è§£éåèçè¤éè³æãæ­¤è©è«æ¢è¨ xAI å¦ä½è½æ¹åå¤çµå­¸ç ç©¶ä¸­æ·±åº¦å­¸ç¿æ¨¡åçå¯è§£éæ§ï¼å¼·èª¿å¶æä¾è¨åºé«çæç¢ºè¦è§£çæ½åï¼é²èä¿é²æ­¤é¡æ¨¡åå¨è¨åºç°å¢ä¸­çæææç¨ã

##### **Study on the Helpfulness of Explainable Artificial Intelligence**
2410.11896v1 by Tobias Labarta, Elizaveta Kulicheva, Ronja Froelian, Christian GeiÃler, Xenia Melman, Julian von Klitzing

Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°æ¼å»ºæ§åé²çæ©å¨å­¸ç¿é©åæç¨ç¨å¼è³ééè¦ï¼ç¹å¥æ¯å¨é«çè¨ºæ·æèªåé§é§ç­ééµé åãæ³å¾ãåæ¥­åå«çè¦æ±ä¿ä½¿ä½¿ç¨ææç XAIï¼ä½æ¸éæ¥çå¢å çä¸åæ¹æ³ä½¿å¾æé¸æ­£ç¢ºçæ¹æ³å·æææ°æ§ãæ­¤å¤ï¼ç±æ¼è§£éé«åº¦ä¾è³´æ¼èæ¯ï¼å¨æ²æä½¿ç¨èçææ³ä¸è¡¡é XAI æ¹æ³çæææ§åªè½æ­ç¤ºæéçè³è¨ï¼æé¤äººé¡å ç´ ï¼ä¾å¦çè§£å®çè½åãæåå»ºè­°ééä½¿ç¨èæåå·è¡ä»£çä»»åçè½åä¾è©ä¼° XAI æ¹æ³ï¼è¨­è¨ä½¿å¾è¯å¥½çå·è¡è¡¨ç¾æ¯è§£éæä¾æç¨è³è¨çææ¨ãæå¥è©±èªªï¼æåæ¢è¨ XAI å°äººé¡æ±ºç­å¶å®çå¹«å©ãæ­¤å¤ï¼å°æåé²çæ¹æ³é²è¡ä½¿ç¨èç ç©¶ï¼é¡¯ç¤ºåºå®åå¨ç¢çä¿¡ä»»åæ·ççè½åä»¥åæ­£ç¢ºå¤æ· AI æ±ºç­æ¯å¦æ­£ç¢ºçè½åæ¹é¢å­å¨å·®ç°ãæ ¹æçµæï¼æåå¼·çå»ºè­°ä½¿ç¨åæ´åéç¨®æ¹æ³ï¼ä»¥é²è¡æ´å¤ä»¥ç®æ¨çºåºç¤çäººçºä¸­å¿ä½¿ç¨èç ç©¶ï¼ä»¥çµç«¯å°çµç«¯çæ¹å¼è¡¡é XAI æè½ã

##### **Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**
2410.09635v1 by Abdullah Mamun, Lawrence D. Devoe, Mark I. Evans, David W. Britt, Judith Klein-Seetharaman, Hassan Ghasemzadeh

Early detection of intrapartum risk enables interventions to potentially
prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently,
there is no accurate automated system to predict such events to assist with
clinical decision-making. To fill this gap, we propose "Artificial Intelligence
(AI) for Modeling and Explaining Neonatal Health" (AIMEN), a deep learning
framework that not only predicts adverse labor outcomes from maternal, fetal,
obstetrical, and intrapartum risk factors but also provides the model's
reasoning behind the predictions made. The latter can provide insights into
what modifications in the input variables of the model could have changed the
predicted outcome. We address the challenges of imbalance and small datasets by
synthesizing additional training data using Adaptive Synthetic Sampling
(ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN
uses an ensemble of fully-connected neural networks as the backbone for its
classification with the data augmentation supported by either ADASYN or CTGAN.
AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in
classification. AIMEN can predict a high risk for adverse labor outcomes with
an average F1 score of 0.784. It also provides counterfactual explanations that
can be achieved by changing 2 to 3 attributes on average. Resources available:
https://github.com/ab9mamun/AIMEN.

æè¦ï¼ç¢ç¨ä¸­é¢¨éªçæ©æåµæ¸¬æå©æ¼é²è¡å¹²é æªæ½ï¼ä»¥é é²ææ¸è¼ä¸å©ççç¢çµæï¼ä¾å¦è¦æ§éº»çºãç®åï¼æ²ææºç¢ºçèªååç³»çµ±å¯ä»¥é æ¸¬æ­¤é¡äºä»¶ï¼ä»¥åå©è¨åºæ±ºç­ãçºäºå¡«è£éä¸ç©ºç½ï¼æåæåºãç¨æ¼å»ºæ¨¡åè§£éæ°çåå¥åº·çäººå·¥æºæ§ã(AIMEN)ï¼éæ¯ä¸åæ·±åº¦å­¸ç¿æ¶æ§ï¼å®ä¸åå¯ä»¥æ ¹æå­ç¢å©¦ãèåãç¢ç§åç¢ç¨é¢¨éªå ç´ é æ¸¬ä¸å©ççç¢çµæï¼éè½æä¾æ¨¡åååºé æ¸¬èå¾çåå ãå¾èå¯ä»¥æä¾è¦è§£ï¼èªªææ¨¡åè¼¸å¥è®æ¸ä¸­çåªäºä¿®æ¹å¯è½ææ¹è®é æ¸¬çµæãæåééä½¿ç¨é©ææ§åææ½æ¨£ (ADASYN) åæ¢ä»¶è¡¨æ ¼çæå°æç¶²è·¯ (CTGAN) ä¾åæé¡å¤çè¨ç·´è³æï¼ä»¥è§£æ±ºä¸å¹³è¡¡åå°åè³æéçææ°ãAIMEN ä½¿ç¨å¨é£æ¥ç¥ç¶ç¶²è·¯çéåä½çºå¶åé¡çéª¨å¹¹ï¼ä¸¦éé ADASYN æ CTGAN æ¯æ´è³ææ´åãç± CTGAN æ¯æ´ç AIMEN å¨åé¡æ¹é¢åªæ¼ç± ADASYN æ¯æ´ç AIMENãAIMEN å¯ä»¥é æ¸¬ä¸å©ççç¢çµæçé«é¢¨éªï¼å¹³å F1 åæ¸çº 0.784ãå®éæä¾åäºå¯¦è§£éï¼å¯ééå¹³åè®æ´ 2 è³ 3 åå±¬æ§ä¾éæãå¯ç¨è³æºï¼https://github.com/ab9mamun/AIMENã

##### **Artificial intelligence techniques in inherited retinal diseases: A review**
2410.09105v1 by Han Trinh, Jordan Vice, Jason Charng, Zahra Tajbakhsh, Khyber Alam, Fred K. Chen, Ajmal Mian

Inherited retinal diseases (IRDs) are a diverse group of genetic disorders
that lead to progressive vision loss and are a major cause of blindness in
working-age adults. The complexity and heterogeneity of IRDs pose significant
challenges in diagnosis, prognosis, and management. Recent advancements in
artificial intelligence (AI) offer promising solutions to these challenges.
However, the rapid development of AI techniques and their varied applications
have led to fragmented knowledge in this field. This review consolidates
existing studies, identifies gaps, and provides an overview of AI's potential
in diagnosing and managing IRDs. It aims to structure pathways for advancing
clinical applications by exploring AI techniques like machine learning and deep
learning, particularly in disease detection, progression prediction, and
personalized treatment planning. Special focus is placed on the effectiveness
of convolutional neural networks in these areas. Additionally, the integration
of explainable AI is discussed, emphasizing its importance in clinical settings
to improve transparency and trust in AI-based systems. The review addresses the
need to bridge existing gaps in focused studies on AI's role in IRDs, offering
a structured analysis of current AI techniques and outlining future research
directions. It concludes with an overview of the challenges and opportunities
in deploying AI for IRDs, highlighting the need for interdisciplinary
collaboration and the continuous development of robust, interpretable AI models
to advance clinical applications.

æè¦ï¼éºå³æ§è¦ç¶²èç¾ç (IRD) æ¯ä¸çµå¤æ¨£åçéºå³ç¾çï¼
æå°è´è¦åéæ¼¸åªå¤±ï¼æ¯å·¥ä½å¹´é½¡æäººå¤±æçä¸»è¦åå ãIRD çè¤éæ§åç°è³ªæ§å°è¨ºæ·ãé å¾åç®¡çæåºäºéå¤§ææ°ãæè¿äººå·¥æºè½ (AI) çé²æ­¥çºéäºææ°æä¾äºæå¸æçè§£æ±ºæ¹æ¡ã
ç¶èï¼AI æè¡çå¿«éç¼å±åå¶å¤ç¨®æç¨å°è´äºè©²é åçç¥è­åæ£ãæ¬ç¶è¿°æ´åäºç¾æç ç©¶ï¼æ¾åºå·®è·ï¼ä¸¦æ¦è¿°äº AI å¨è¨ºæ·åç®¡ç IRD ä¸­çæ½åãå®æ¨å¨ééæ¢ç´¢æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿ç­ AI æè¡ï¼ç¹å¥æ¯å¨ç¾çæª¢æ¸¬ãé²ç¨é æ¸¬ååæ§åæ²»çè¨åä¸­ï¼çºæ¨é²è¨åºæç¨æ§å»ºéå¾ãç¹å¥éæ³¨éäºé åä¸­å·ç©ç¥ç¶ç¶²è·¯çæææ§ãæ­¤å¤ï¼è¨è«äºå¯è§£é AI çæ´åï¼å¼·èª¿äºå¶å¨è¨åºç°å¢ä¸­æé«éæåº¦åå°åºæ¼ AI çç³»çµ±çä¿¡ä»»çéè¦æ§ãè©²ç¶è¿°è§£æ±ºäºå½å AI å¨ IRD ä¸­ä½ç¨çéé»ç ç©¶ä¸­ç¾æå·®è·çå¿è¦æ§ï¼æä¾äºå°ç¶å AI æè¡ççµæ§ååæï¼ä¸¦æ¦è¿°äºæªä¾çç ç©¶æ¹åãæå¾æ¦è¿°äºå¨ IRD ä¸­é¨ç½² AI çææ°åæ©éï¼å¼·èª¿äºè·¨å­¸ç§åä½åæçºéç¼å¼·å¤§ãå¯è§£éç AI æ¨¡åä»¥æ¨é²è¨åºæç¨çå¿è¦æ§ã

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

æè¦ï¼è§£éäººå·¥æºæ§ (AI) çæ±ºç­æ¯ç¾å¨ AI çä¸é éå¤§ææ°ï¼ç¹å¥æ¯æç¨æ¼åé«å­¸åæ³å¾ç­æææå¢æãç¶èï¼è§£éæ±ºç­èå¾çç±çéæ±ä¹æ¯åºæ¼äººé¡çèéçä¸åä¸»è¦åé¡ï¼å çºæå¿è¦è­æçºä»éº¼ååºæåæ±ºç­ãä¾å¦ï¼ä½é¢é«å¸«ä¸åéè¦æä¾ï¼å¯è½æ¯æ­£ç¢ºçï¼è¨ºæ·ï¼ééè¦è§£éä»åå¦ä½éææåçµè«ãå æ­¤ï¼éç¼æ°çå·¥å·ä¾å¹«å©ä½é¢é«å¸«è¨ç·´ä»åçè§£éæå·§æ¯æè²ä¸­ AI çä¸é æ ¸å¿ç®æ¨ãå¨æ¬æä¸­ï¼æåéµå¾ªéåæ¹åï¼ä¸¦ä¸æ ¹ææåçäºè§£ï¼æåºç¬¬ä¸åå¤èªè¨é«å­¸åç­è³æéï¼å¶ä¸­è¨åºçä¾çæ­£ç¢ºåä¸æ­£ç¢ºè¨ºæ·é½éæç±é«çæ°å¯«çèªç¶èªè¨è§£éãéäºè§£éå·²ä½¿ç¨è«è­çµæï¼å³åæãä¸»å¼µï¼åè«è­éä¿ï¼å³æ»æãæ¯æï¼é²è¡æåè¨»è§£ï¼ç¢çå¤èªè¨ CasiMedicos-Arg è³æéï¼å¶ä¸­åå« 558 åå·æè§£éçåç¨®èªè¨ï¼è±èªãè¥¿ç­çèªãæ³èªãç¾©å¤§å©èªï¼çè¨åºçä¾ï¼æåè¨»è§£äº 5021 åä¸»å¼µã2313 ååæã2431 åæ¯æéä¿å 1106 åæ»æéä¿ãæåæå¾å±ç¤ºäºç«¶ç­åºæºå¦ä½éå°è«è­æ¢åä»»åå·è¡æ­¤å·ææ°æ§çè³æéã

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v1 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

æè¦ï¼è¨ºæ·é æ¸¬æ¯é«çä¿å¥ä¸­çä¸é ééµä»»åï¼åæä¸æºç¢ºå°è­å¥é«ççæ³æå°æ£èççµæç¢çéå¤§å½±é¿ãå³çµ±æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åå·²å¨æ­¤é ååå¾é¡¯èæåï¼ä½éå¸¸ç¼ºä¹å¯è§£éæ§ï¼éæ¯è¨åºç°å¢ä¸­çééµè¦æ±ãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨äºç¥ç¶ç¬¦èæ¹æ³ï¼ç¹å¥æ¯éè¼¯ç¥ç¶ç¶²è·¯ (LNN)ï¼ä»¥éç¼å¯è§£éçè¨ºæ·é æ¸¬æ¨¡åãåºæ¬ä¸ï¼æåè¨­è¨ä¸¦å¯¦ä½äºåºæ¼ LNN çæ¨¡åï¼è©²æ¨¡åéééè¼¯è¦ååå¯å­¸ç¿çé¾å¼æ´åé åç¹å®çç¥è­ãæåçæ¨¡åï¼ç¹å¥æ¯ $M_{\text{multi-pathway}}$ å $M_{\text{comprehensive}}$ï¼è¡¨ç¾åºåªæ¼å³çµ±æ¨¡åï¼å¦éè¼¯è¿´æ­¸ãSVM åé¨æ©æ£®æï¼çåè¶æè½ï¼å¨ç³å°¿çé æ¸¬çæ¡ä¾ç ç©¶ä¸­ï¼éå°äºæ´é«çæºç¢ºåº¦ï¼é«é 80.52%ï¼å AUROC åæ¸ï¼é«é 0.8457ï¼ãLNN æ¨¡åä¸­å­¸ç¿çæ¬éåé¾å¼æä¾äºå°ç¹å¾µè²¢ç»çç´æ¥è¦è§£ï¼å¢å¼·äºå¯è§£éæ§ï¼åæä¸æå®³é æ¸¬è½åãéäºç¼ç¾çªé¡¯äºç¥ç¶ç¬¦èæ¹æ³å¨å½åé«çä¿å¥ AI æç¨ä¸­æºç¢ºæ§åå¯è§£éæ§å·®è·æ¹é¢çæ½åãééæä¾éæä¸é©ææ§å¼·çè¨ºæ·æ¨¡åï¼æåçç ç©¶æå©æ¼ç²¾æºé«ççé²æ­¥ï¼ä¸¦æ¯æ´å¬å¹³é«çä¿å¥è§£æ±ºæ¹æ¡çéç¼ãæªä¾çç ç©¶å°å°æ³¨æ¼å°éäºæ¹æ³æ´å±å°æ´å¤§ä¸æ´å¤æ¨£åçè³æéï¼ä»¥é²ä¸æ­¥é©è­å¶å¨ä¸åé«ççæ³åäººç¾¤ä¸­çé©ç¨æ§ã

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éé²å±å¾¹åºæ¹è®äºæºæ§é«çä¿å¥ï¼æ¨åäºå¯ç©¿æ´æè¡ãæçºç£æ§è£ç½®åæºæ§è¨ºæ·ç³»çµ±çåµæ°ãç¶èï¼å®å¨æ§ãå¯è§£éæ§ãç©©å¥æ§åæè½æä½³åææ°ä»ç¶æ¯è¨åºç°å¢ä¸­å»£æ³æ¡ç¨çééµéç¤ãæ¬ç ç©¶æåºä¸ååµæ°çæ¼ç®æ³æ¹æ³ï¼ä½¿ç¨èªé©æç¹å¾µè©ä¼°å¨ (AFE) æ¼ç®æ³ä¾æ¹åé«çä¿å¥è³æéä¸­çç¹å¾µé¸åä¸¦åæåé¡ãAFE æ´åäºéºå³æ¼ç®æ³ (GA)ãå¯è§£éäººå·¥æºæ§ (XAI) åæåçµåæè¡ (PCT)ï¼è©²æ¼ç®æ³æä½³åäºè¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS)ï¼å¾èæé«äºé æ¸¬æºç¢ºæ§åå¯è§£éæ§ãææåºçæ¹æ³ä½¿ç¨å­ç¨®ä¸åçæ©å¨å­¸ç¿æ¼ç®æ³é©è­äºä¸åä¸åçé«çä¿å¥è³æéï¼è­æäºå¶ç©©å¥æ§ååªæ¼å³çµ±ç¹å¾µé¸åæè¡ãçµæå¼·èª¿äº AFE å¨æºæ§é«çä¿å¥ä¸­çè½è®æ½åï¼å¯¦ç¾äºåäººååéæçæ£èç§è­·ãå¼å¾æ³¨æçæ¯ï¼AFE æ¼ç®æ³èå¤å±¤æç¥å¨ (MLP) çµåä½¿ç¨æï¼æºç¢ºåº¦é«é 98.5%ï¼çªé¡¯äºå¶æ¹åå¯¦éé«çä¿å¥æç¨ä¸­è¨åºæ±ºç­å¶å®æµç¨çè½åã

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

æè¦ï¼äººå·¥æºæ§ (AI) ç³»çµ±å·²å¤§å¹æ¹åç®èç§é«å¸«å°é»è²ç´ ç¤çè¨ºæ·æºç¢ºåº¦ï¼èå¯è§£é AI (XAI) ç³»çµ±é²ä¸æ­¥æåè¨åºé«å¸«å° AI é©åæ±ºç­çä¿¡å¿èä¿¡è³´ãåç®¡æéäºé²å±ï¼å°æ¼ç®èç§é«å¸«å¦ä½ä½¿ç¨ AI å XAI å·¥å·ï¼ä»æå®¢è§è©ä¼°çè¿«åéæ±ãå¨éé ç ç©¶ä¸­ï¼76 ä½ç®èç§é«å¸«åèäºä¸é è®èç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±è¨ºæ· 16 å¼µé»è²ç´ ç¤åç£çç®èé¡å½±åï¼è©²ç³»çµ±æä¾è©³ç´°çé åç¹å®èªªæãæ¡ç¨ç¼çè¿½è¹¤æè¡ä¾è©ä¼°ä»åçäºåãå°è¨ºæ·è¡¨ç¾èç¼ºä¹èªªæåè½çæ¨æº AI ç³»çµ±é²è¡æ¯è¼ãæåçç ç©¶çµæé¡¯ç¤ºï¼XAI ç³»çµ±ç¸è¼æ¼æ¨æº AIï¼å°å¹³è¡¡è¨ºæ·æºç¢ºåº¦æåäº 2.8 åç¾åé»ãæ­¤å¤ï¼è AI/XAI ç³»çµ±çè¨ºæ·åæ­§åè¤éççç¶èèªç¥è² æåé«æéï¼éç±å¢å çç¼çæ³¨è¦æ¬¡æ¸æè­å¯¦ãéäºè¦è§£å°è¨åºå¯¦åãè¦è¦ºä»»å AI å·¥å·çè¨­è¨åé«å­¸è¨ºæ·ä¸­ XAI çå»£æ³ç¼å±å·æéå¤§æç¾©ã

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

æè¦ï¼èªéçè­ç³»éç¤ (ASD) çæ©æè¨ºæ·åä»å¥å·²è¢«è­å¯¦è½é¡¯èæ¹åèªéçæ£èççæ´»åè³ªãç¶èï¼ASD çè¨ºæ·æ¹æ³ä¾è³´æ¼åºæ¼è¨åºè¡¨ç¾çè©ä¼°ï¼å®¹æç¢çåè¦ï¼ä¸å¯è½é£ä»¥ååºæ©æè¨ºæ·ãæå¿è¦æ¾åº ASD çå®¢è§çç©æ¨è¨ï¼ä»¥å¹«å©æé«è¨ºæ·æºç¢ºæ§ãæ·±åº¦å­¸ç¿ (DL) å¨å¾é«å­¸å½±åè³æè¨ºæ·ç¾çåççæ¹é¢åå¾ååºçè¡¨ç¾ãå·²ç¶éå°å»ºç«ä½¿ç¨éæåè½æ§ç£æ¯é å½± (fMRI) è³æå° ASD é²è¡åé¡çæ¨¡åé²è¡å»£æ³çç ç©¶ãç¶èï¼ç¾æçæ¨¡åç¼ºä¹å¯è§£éæ§ãæ¬ç ç©¶æ¨å¨ééå»ºç«ä¸åä¸åè½æºç¢ºåé¡ ASDï¼éè½æä¾å¯è§£éè¦è§£èªªæå¶éä½åçç DL æ¨¡åï¼ä¾æ¹å ASD è¨ºæ·çæºç¢ºæ§åå¯è§£éæ§ãæä½¿ç¨çè³æéæ¯èªéçå¤§è¦å½±åè³æäº¤æ (ABIDE) çé èççæ¬ï¼åå« 884 åæ¨£æ¬ãæåçç ç©¶çµæé¡¯ç¤ºï¼è©²æ¨¡åè½æºç¢ºåé¡ ASDï¼ä¸¦å¼·èª¿ ASD èå¸åå°ç§çµä¹éå­å¨å·®ç°çééµè¦åï¼å°æ¼ ASD çæ©æè¨ºæ·åç¥ç¶åºç¤ççè§£å·ææ½å¨çæç¾©ãéäºç ç©¶çµæå·²ç±ä½¿ç¨ä¸åè³æéåæ¹å¼çæç»ç ç©¶é©è­ï¼è­å¯¦è©²æ¨¡åå¯¦éä¸å­¸ç¿äº ASD çç¹å¾µï¼èä¸ååæ¯è³æéãæ¬ç ç©¶ééæä¾ä¸åå¼·å¥ä¸å¯è§£éçæ¨¡åï¼æ¨åäºé«å­¸å½±åä¸­å¯è§£é AI çé åï¼å¾èçºæªä¾æä¾å®¢è§ä¸å¯é ç ASD è¨ºæ·ååºè²¢ç»ã

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, ClÃ©ment Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

æè¦ï¼å°¿è·¯é¡æª¢æ¥ä¸­èçµç³é¡åçé«å§è­å¥å°æ¯æ³å°¿ç§çä¸é éå¤§é²å±ï¼å çºå®å¯ä»¥æ¸å°ç¹ç£çèçµç³ååºéç¨çæéï¼åæéä½ææé¢¨éªãæ­¤å¤ï¼éç¨®èªååç¨åºå°ä½¿ç«å³éç«æå¾©ç¼æ²»çæçºå¯è½ãå¦ä»ï¼åªæå°æ¸ç¶é©è±å¯çæ³å°¿ç§é«çè½å¤ å¨å§è¦é¡æª¢æ¥æéå±å¹ä¸é¡¯ç¤ºçè¦é »ååä¸­è­å¥èçµç³é¡åãå æ­¤ï¼æè¿å·²æåºå¤ç¨®æ·±åº¦å­¸ç¿ (DL) æ¨¡åï¼ä»¥ä½¿ç¨è¼¸å°¿ç®¡é¡ååèªåè­å¥èçµç³é¡åãç¶èï¼éäº DL æ¨¡åæ¬è³ªä¸æ¯é»çå­ï¼ééå¶äºå®åå¨è¨åºç°å¢ä¸­çæç¨æ§ãæ¬ææåºäºä¸ååºæ¼æ¡ä¾æ¨çç DL æ¨¡åï¼å®ä½¿ç¨ååé¨å (PP) ä¸¦çæå±é¨åå¨å±æè¿°ç¬¦ãPP çºæ¯ç¨®é¡åï¼å³èçµç³é¡åï¼ç·¨ç¢¼è¦è¦ºç¹å¾µä¿¡æ¯ï¼è²èª¿ãé£½ååº¦ãå¼·åº¦åç´çï¼ï¼é¡ä¼¼æ¼çç©å­¸å®¶ä½¿ç¨çä¿¡æ¯ãç±æ¼å¨æ¨¡åè¨ç·´æéä½¿ç¨çæ°æå¤±å½æ¸ï¼PP å¾å°äºæä½³çæãæ­¤å¤ï¼PP çå±é¨åå¨å±æè¿°ç¬¦åè¨±ä»¥çç©å­¸å®¶åæ³å°¿ç§é«çå¯ä»¥çè§£çæ¹å¼è§£éæ±ºç­ï¼âä»éº¼âä¿¡æ¯ï¼âååä¸­çä»éº¼ä½ç½®âï¼ãææåºç DL æ¨¡åå·²å¨ä¸ååå«å­ç¨®æå»£æ³çèçµç³é¡åååçæ¸æåº«ä¸é²è¡äºæ¸¬è©¦ãç¸½é«å¹³ååé¡æºç¢ºççº 90.37ãå°æ­¤çµæèèçµç³æåé²çå«åå¶ä» DL æ¨¡åççµæé²è¡æ¯è¼æï¼å¯ä»¥çåºï¼å¯è§£éæ§çå¯¶è²´å¢çä¸¦æªä»¥æºç¢ºæ§çºä»£å¹ï¼çè³ç¥æå¢å èæç»ä¸­æå¥½çæ¹æ³ (88.2) ç¸æ¯ãéäºæå¸æä¸å¯è§£éççµæä¹é¼åµæ³å°¿ç§é«çç¸ä¿¡åºæ¼äººå·¥æºè½çè§£æ±ºæ¹æ¡ã

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v3 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

æè¦ï¼æ¬ç ç©¶æ¢è¨å©ç¨è¡æ¿ç³å ±è³æï¼çµååé²æ©å¨å­¸ç¿èæ·±åº¦å­¸ç¿æè¡ï¼é æ¸¬æ¢æ§èèç (CKD) é²å±è³æ«æèèç¾ç (ESRD) çå¯è½æ§ãæååæä¸å®¶å¤§åå¥åº·ä¿éªçµç¹æä¾ç 10 å¹´ç¶åè³æéï¼ä½¿ç¨å³çµ±æ©å¨å­¸ç¿æ¹æ³ï¼ä¾å¦é¨æ©æ£®æå XGBoostï¼ä»¥åæ·±åº¦å­¸ç¿æ¹æ³ï¼ä¾å¦é·æç­æè¨æ¶ (LSTM) ç¶²è·¯ï¼éç¼å¤åè§å¯è¦çªçé æ¸¬æ¨¡åãæåçç ç©¶çµæé¡¯ç¤ºï¼LSTM æ¨¡åï¼å°¤å¶æ¯ 24 åæè§å¯è¦çªï¼å¨é æ¸¬ ESRD é²å±æ¹é¢è¡¨ç¾åªç°ï¼åªæ¼æç»ä¸­çç¾ææ¨¡åãæåé²ä¸æ­¥æç¨ SHapley å¯å æ§è§£é (SHAP) åæä»¥å¢å¼·å¯è§£éæ§ï¼æ·±å¥äºè§£åå¥ç¹å¾µå°åå¥æ£èå±¤ç´é æ¸¬çå½±é¿ãæ¬ç ç©¶å¼·èª¿äºå©ç¨è¡æ¿ç³å ±è³æé²è¡ CKD ç®¡çåé æ¸¬ ESRD é²å±çå¹å¼ã

##### **Explainable AI: Definition and attributes of a good explanation for health AI**
2409.15338v1 by Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group

Proposals of artificial intelligence (AI) solutions based on increasingly
complex and accurate predictive models are becoming ubiquitous across many
disciplines. As the complexity of these models grows, transparency and users'
understanding often diminish. This suggests that accurate prediction alone is
insufficient for making an AI-based solution truly useful. In the development
of healthcare systems, this introduces new issues related to accountability and
safety. Understanding how and why an AI system makes a recommendation may
require complex explanations of its inner workings and reasoning processes.
Although research on explainable AI (XAI) has significantly increased in recent
years and there is high demand for XAI in medicine, defining what constitutes a
good explanation remains ad hoc, and providing adequate explanations continues
to be challenging. To fully realize the potential of AI, it is critical to
address two fundamental questions about explanations for safety-critical AI
applications, such as health-AI: (1) What is an explanation in health-AI? and
(2) What are the attributes of a good explanation in health-AI? In this study,
we examined published literature and gathered expert opinions through a
two-round Delphi study. The research outputs include (1) a definition of what
constitutes an explanation in health-AI and (2) a comprehensive list of
attributes that characterize a good explanation in health-AI.

æè¦ï¼é¨èè¶ä¾è¶è¤éä¸æºç¢ºçé æ¸¬æ¨¡åï¼åºæ¼äººå·¥æºæ§ (AI) è§£æ±ºæ¹æ¡çææ¡å¨è¨±å¤é åä¸­è®å¾ç¡èä¸å¨ãé¨èéäºæ¨¡åè¤éæ§çå¢å ï¼éæåº¦åä½¿ç¨èççè§£åå¾å¾æéä½ãéè¡¨ç¤ºåææºç¢ºçé æ¸¬ä¸¦ä¸è¶³ä»¥è® AI è§£æ±ºæ¹æ¡çæ­£æç¨ãå¨é«çä¿å¥ç³»çµ±çéç¼ä¸­ï¼éå¼å¥äºèåè²¬å¶åå®å¨æ§ç¸éçæ°åé¡ãç­è§£ AI ç³»çµ±å¦ä½ä»¥åçºä½æåºå»ºè­°å¯è½éè¦å°å¶å§é¨éä½åæ¨çéç¨é²è¡è¤éçèªªæãåç®¡è¿å¹´ä¾å°å¯è§£é AI (XAI) çç ç©¶å·²å¤§å¹å¢å ï¼ä¸é«å­¸é åå° XAI æå¾é«çéæ±ï¼ä½å®ç¾©ä»éº¼æ§æä¸åå¥½çè§£éä»æ¯è¨ææ§çï¼èæä¾é©ç¶çè§£éä»ç¶å·æææ°æ§ãçºäºååç¼æ® AI çæ½åï¼å°æ¼å®å¨ééµå AI æç¨ï¼ä¾å¦å¥åº· AIï¼çè§£éï¼æ¢è¨å©ååºæ¬åé¡è³ééè¦ï¼(1) ä»éº¼æ¯å¥åº· AI ä¸­çè§£éï¼ä»¥å (2) å¥åº· AI ä¸­ä¸åå¥½çè§£éæåªäºå±¬æ§ï¼å¨æ¬ç ç©¶ä¸­ï¼æåæª¢è¦äºå·²ç¼è¡¨çæç»ï¼ä¸¦ééå©è¼ªå¾·ç¾è²ç ç©¶æ¶éäºå°å®¶æè¦ãç ç©¶ææåæ¬ï¼(1) å¥åº· AI ä¸­ä»éº¼æ§æè§£éçå®ç¾©ï¼ä»¥å (2) å¥åº· AI ä¸­ä¸åå¥½è§£éçå±¬æ§æ¸å®ã

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼å·²ç¶å¼é²åç¨®æ¹æ³ä¾è§£éãé»ç®±ãAI æ¨¡åçè¼¸åºãç¶èï¼ç®åä¸¦ä¸æ¸æ¥ä½¿ç¨èæ¯å¦å¯¦éçè§£åä¿¡ä»»éäºè§£éãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼è©ä¼°ççé¢¨éªçåæ­¸å·¥å·çè§£éï¼ä¸¦æ¢è¨è§£éçå§å®¹åæ ¼å¼å°ä»¥ä½¿ç¨èçºä¸­å¿ççè§£åä¿¡ä»»ææ¨çå½±é¿ãéæ¼å§å®¹ï¼æåå¯¦é©äºå©ç¨®è§£éæ¹æ³ï¼æµè¡ç SHAPï¼åºæ¼åå¼è«æ¦å¿µï¼å æ­¤å°æ¼æ¥å¸¸ä½¿ç¨èä¾èªªå¯è½å¾è¤éï¼ä»¥ååºæ¼ç¹å¾µé®è½ç occlusion-1ï¼å¯è½æ´ææ¼çè§£ãéæ¼æ ¼å¼ï¼æåå° SHAP è§£éåç¾çºåè¡¨ (SC)ï¼éæ¯æ£ä¾ï¼èå° occlusion-1 è§£éåç¾çºåè¡¨ (OC) ä»¥åæå­ (OT)ï¼å¶è¼çºç°¡å®çæ§è³ªä¹é©ç¨æ¼æ­¤ãéäºå¯¦é©ç­åæ¼ä½¿ç¨èç ç©¶ï¼è©¢ååèèï¼å·æå©ç¨®ä¸åç¨åº¦çå°æ¥­ç¥è­ï¼ä¸è¬æ°ç¾åå·åä¸äºé«å­¸è¨ç·´çäººï¼ï¼ä»åå°åæ­¸å·¥å·è¼¸åºè§£éçä¸»è§åå®¢è§çè§£åä¿¡ä»»ãå¨å©é ç ç©¶ä¸­ï¼æåç¼ç¾ï¼å¨åºæ¼å§å®¹é²è¡æ¯è¼æï¼ä¸è¬ä¾èªªï¼occlusion-1 åªæ¼ SHAP è§£éï¼å¨ä¸»è§çè§£åä¿¡ä»»æ¹é¢ææé¡¯çåå¥½ãç¶èï¼å¨åæ§å¶æ ¼å¼çææ³ä¸ç´æ¥æ¯è¼è§£éï¼å¨å¤§å¤æ¸ææ³ä¸åªé¡¯ç¤º OT åªæ¼ SC è§£éçè­æï¼éè¡¨æ occlusion-1 åªæ¼ SHAP è§£éçä¸»å°å°ä½å¯è½æ¯ç±åå¥½æå­èéåè¡¨ä½çºè§£éæé©åçãæå¾ï¼æåæ²æç¼ç¾è§£éé¡åå¨å®¢è§çè§£æ¹é¢çå·®ç°è­æãå æ­¤ï¼ç¸½é«èè¨ï¼å°è§£éçå§å®¹åæ ¼å¼çé¸æéè¦ä»ç´°æ³¨æï¼å çºå¨æäºææ³ä¸ï¼æ ¼å¼èéå§å®¹ï¼å¯è½å¨æ¹åä½¿ç¨èé«é©æ¹é¢ç¼æ®ééµä½ç¨ã</paragraph>

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro LiÃ², Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°çªç ´æä¾äºåææªæçèªç¶èªè¨çè§£åçæè½åãç¶èï¼ç¾æéæ¼çç©é«å­¸ä¸­ LLM çèª¿æ¥éå¸¸å°æ³¨æ¼ç¹å®æç¨ææ¨¡åæ¶æ§ï¼ç¼ºä¹æ´ååç¨®çç©é«å­¸é åææ°é²å±çå¨é¢åæãæ¬ç¶è¿°åºæ¼å°ä¾èª PubMedãWeb of Science å arXiv ç­æ¸æåº«ç 484 ç¯åºçç©çåæï¼æ·±å¥æ¢è¨äºçç©é«å­¸ä¸­ LLM çç¶åç¾æ³ãæç¨ãææ°ååæ¯ï¼å¶ç¹é»æ¯éæ³¨éäºæ¨¡åå¨ç¾å¯¦ä¸ççç©é«å­¸èæ¯ä¸­çå¯¦éæç¨ãé¦åï¼æåæ¢è¨äº LLM å¨å»£æ³ççç©é«å­¸ä»»åä¸­çé¶æ¬¡å­¸ç¿è½åï¼åæ¬è¨ºæ·è¼å©ãè¥ç©ç¼ç¾ååæ§åé«çç­ï¼ä¸¦å¾ 137 é ééµç ç©¶ä¸­æ±²åè¦è§£ãç¶å¾ï¼æåè¨è«äº LLM çé©æç­ç¥ï¼åæ¬å®æ¨¡æåå¤æ¨¡æ LLM çå¾®èª¿æ¹æ³ï¼ä»¥å¢å¼·å®åå¨é¶æ¬¡å­¸ç¿ç¡æ³å¯¦ç¾çå°æ¥­çç©é«å­¸èæ¯ä¸­çæ§è½ï¼ä¾å¦é«çåé¡è§£ç­åçç©é«å­¸æç»çææèçãæå¾ï¼æåè¨è«äº LLM å¨çç©é«å­¸é åé¢è¨çææ°ï¼åæ¬æ¸æé±ç§åé¡ãæ¨¡åå¯è§£éæ§æéãæ¸æéè³ªéåé¡ä»¥åç±æ¼çç©é«å­¸æ¸æçæææ§ãå°é«åº¦å¯é æ¨¡åè¼¸åºçéæ±ä»¥åå¨é«çä¿å¥ä¸­é¨ç½² AI çå«çå½±é¿èç¢ççå«çåé¡ãçºäºæå°éäºææ°ï¼æåéç¢ºå®äºçç©é«å­¸ä¸­ LLM æªä¾çç ç©¶æ¹åï¼åæ¬ç¨æ¼ä¿è­·æ¸æé±ç§çè¯åå­¸ç¿æ¹æ³ä»¥åæ´åå¯è§£é AI æ¹æ³ä»¥å¢å¼· LLM çéæåº¦ã

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨é«çåä¿å¥æç¨ä¸­æå¥äºå¤§éçæè³åéç¼ï¼é²èå°è´é«çæè¡ä¸­çåé²æ§å¶ç³»çµ±ãç¶èï¼AI ç³»çµ±çä¸éææ§å¼ç¼äºå°æ­¤é¡æææç¨ä¸­æéåºæ¬ç¹æ§çææï¼ä¾å¦éæåº¦åå¯ä¿¡åº¦ãæåçç ç©¶ééèª¿æ¥ä¸åç¨åºä¾è§£æ±ºéäºåé¡ï¼ç¨æ¼é¸ææååçå¯è§£é AIï¼XAIï¼æ¹æ³ï¼ä»¥ç¬¦åæ­çæ³è¦å¨é«çå¨æçæºæ§åçç©é»å­å­¸ä¸­çèªªæè¦æ±ãæ¡ç¨çæ¹æ³å¾ééå¶æ§å¶æ©å¶ï¼éè¿´è·¯ãéè¿´è·¯ååéè¿´è·¯ç³»çµ±ï¼å°æºæ§åè£ç½®é²è¡åé¡ï¼ä¸¦æ·±å¥æ¢è¨å¶æè¡éå§ãç¶å¾ï¼æååæéäºæ³è¦ä»¥å®ç¾©å¶å°åç¨®è£ç½®åç¸éç®æ¨çå¯è§£éæ§è¦æ±ãåæï¼æåééå¶èªªæç®æ¨å° XAI æ¹æ³é²è¡åé¡ãéåè¨±å°æ³å¾å¯è§£éæ§è¦æ±è XAI èªªæç®æ¨ç¸å¹éï¼ä¸¦ç¢ºå®é©ç¶ç XAI æ¼ç®æ³ä¾éæå®åãæåçç ç©¶çµææä¾äºå°åªäº XAI æ¼ç®æ³æ´ç¬¦åæ­çæ³è¦ä»¥é©ç¨æ¼ä¸åé¡åçé«çå¨æçç´°ç·»çè§£ãæåééä¸åç¥ç¶æ¤å¥ç©çå¯¦éæ¡ä¾ç ç©¶ä¾è­æéä¸é»ï¼å¾æ¢æ§ç¾çç®¡çå°åé²çç¾©è¢ãéé ç ç©¶å¡«è£äºå°çç©é»å­å­¸ä¸­ç XAI æç¨èæ­çæ³è¦çå´æ ¼è¦å®ç¸ç¬¦çéè¦ç©ºç½ãå®çºéç¼äººå¡åç ç©¶äººå¡æä¾äºä¸åå¯¦ç¨çæ¶æ§ï¼ç¢ºä¿å¶ AI åµæ°è½ä¿é²é«çæè¡ä¸¦éµå®æ³å¾åéå¾·æ¨æºã

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

æè¦ï¼æåæ¢ç´¢æ·±åº¦çææ¨¡åï¼å¨é«çè¯é¦å­¸ç¿è¨­ç½®ä¸­çæåºæ¼æ¡ä¾çèªªæãééåºæ¼æ¡ä¾çå¯è§£éæ§ä¾è§£é AI æ¨¡åæ±ºç­ï¼å°æ¼å¢å ä¿¡ä»»ä¸¦åè¨± AI å¨è¨åºå¯¦åä¸­å»£æ³æ¡ç¨è³ééè¦ãç¶èï¼é«ç AI è¨ç·´ç¯ä¾æ­£è½åè¯é¦å­¸ç¿è¨­ç½®ï¼ä»¥ç¬¦åè³æä¿è­·æ³è¦ãå¨è¯é¦æå¢ä¸­ï¼éå»çè³æå°ç®åçä½¿ç¨èèè¨æ¯ç¡æ³åå¾çãå æ­¤ï¼æåä½¿ç¨æ·±åº¦çææ¨¡åä¾ç¢çä¿è­·é±ç§åè§£éæ±ºç­çåæç¯ä¾ãæåçæ¦å¿µé©è­èéæ¼è¸èç©æ¶²è¨ºæ·ï¼ä¸¦ä½¿ç¨å¬éå¯åå¾çè¸é¨ X åè³æã

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. GruÃ¼hagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

æè¦ï¼è»çµç¹åéª¨éª¼è«ç¤ï¼STBTï¼æ¯ç½è¦ãè¨ºæ·å·æææ°æ§ççç¶ï¼å¶è¨åºè¡çºåæ²»çæ¹æ³åä¸ç¸åãéç¯ç³»çµ±æ§åé¡§æä¾äºä½¿ç¨æ¾å°å½±åé²è¡è¨ºæ·åé å¾çäººå·¥æºæ§ (AI) æ¹æ³çæ¦è§ï¼éé»èªªæäºè¨åºè½è­¯çææ°ï¼ä¸¦è©ä¼°ç ç©¶èé«çå½±å AI æ ¸æ¥è¡¨ (CLAIM) å FUTURE-AI å¯ä¿¡è³´ä¸å¯é¨ç½² AI çåéå±è­æºåçä¸è´æ§ï¼ä»¥ä¿é² AI æ¹æ³çè¨åºè½è­¯ãéç¯åé¡§æ¶µèäºå¹¾åæ¸ç®è³æåº«ä¸­çæç»ï¼åæ¬å¨ 2024 å¹´ 7 æ 17 æ¥ä¹åç¼è¡¨çè«æãç´å¥äºä»¥æ¾å°çºåºç¤ç AI è¨ºæ·æé å¾åç¼æ§ STBT çåè¡è©å¯©æåä¸­çåå§ç ç©¶ãæé¤æ¨æºæ¯åç©ãå±é«æå¯¦é©å®¤ç ç©¶ï¼ä»¥åéè±æè«æãæè¦ç±ä¸ä½ç¨ç«å¯©æ¥å¡ä¸­çå©ä½ç¯©é¸è³æ ¼ãåæ ¼çè«æç±ä¸ä½ç¨ç«å¯©æ¥å¡ä¸­çä¸ä½æ ¹ææºåé²è¡è©ä¼°ãæç´¢è­å¥åº 15,015 ç¯æè¦ï¼å¶ä¸­ 325 ç¯æç« è¢«ç´å¥è©ä¼°ãå¤§å¤æ¸ç ç©¶å¨ CLAIM ä¸­è¡¨ç¾ä¸­ç­ï¼å¹³åå¾åçº 53 åä¸­ç 28.9Â±7.5 åï¼ä½å¨ FUTURE-AI ä¸­è¡¨ç¾ä¸ä½³ï¼å¹³åå¾åçº 30 åä¸­ç 5.1Â±2.1 åãSTBT çå½±å AI å·¥å·ä»èæ¼æ¦å¿µé©è­éæ®µï¼è¡¨ææé¡¯èçæ¹é²ç©ºéãAI éç¼äººå¡æªä¾çåªåæéä¸­å¨è¨­è¨ï¼ä¾å¦å®ç¾©æªæ»¿è¶³çè¨åºéæ±ãé æçè¨åºç°å¢ä»¥å AI å¦ä½æ´åå°è¨åºå·¥ä½æµç¨ä¸­ï¼ãéç¼ï¼ä¾å¦å»ºç«å¨ååçå·¥ä½ãå¯è§£éæ§ï¼ãè©ä¼°ï¼ä¾å¦è©ä¼°åè§£æ±ºåå·®ãè©ä¼° AI èæä½³å¯¦åï¼ãä»¥åæ¸æå¯è¤è£½æ§åå¯ç¨æ§ï¼å¬éæä¾æä»¶åçä»£ç¢¼åæ¸æï¼ãéµå¾ªéäºå»ºè­°å¯ä»¥æ¹å AI æ¹æ³çè¨åºè½è­¯ã

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga StrÃ¼mke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

æè¦ï¼è¦æ§éº»çº (CP) çæ©æåµæ¸¬å°æ¼ææçä»å¥åç£æ¸¬è³ééè¦ãæ¬ææ¸¬è©¦äºå¯è§£é AI (XAI) æ¹æ³çå¯é æ§åé©ç¨æ§ï¼ä½¿ç¨æ·±åº¦å­¸ç¿æ¹æ³ï¼ééåæå¾å¬°ååä½å½±çè¨éä¸­æåçéª¨éª¼è³æä¾é æ¸¬ CPãå·é«ä¾èªªï¼æåä½¿ç¨ XAI è©ä¼°ææ¨ï¼å³å¿ å¯¦åº¦åç©©å®æ§ï¼ä¾éåè©ä¼°é¡å¥æ¿æ´»æ å° (CAM) åæ¢¯åº¦å æ¬é¡å¥æ¿æ´»æ å° (Grad-CAM) å¨éåç¹å®é«çæç¨ä¸­çå¯é æ§ãæåå©ç¨ä¸åç¨ç¹çå¬°ååä½è³æéï¼ä¸¦æç¨éª¨éª¼è³ææ¾åï¼èä¸ææ­æ²å¬°ååä½çåå§ååãæåç CP é æ¸¬æ¨¡åå©ç¨æ´é«æ¹æ³ï¼å æ­¤æåè©ä¼°äºæ´é«æ´é«ååå¥æ¨¡åç XAI ææ¨è¡¨ç¾ãæåçç ç©¶çµæè¡¨æï¼å©ç¨® XAI æ¹æ³é½è½ææè­å¥å½±é¿ CP é æ¸¬çééµèº«é«é¨ä½ï¼ä¸¦ä¸éäºè§£éå°æ¼å¾®å°çè³ææ¾åå·æé­¯æ£æ§ãGrad-CAM å¨ RISv ææ¨ä¸­é¡¯èåªæ¼ CAMï¼è©²ææ¨è¡¡ééåº¦æ¹é¢çç©©å®æ§ãç¸æ¯ä¹ä¸ï¼CAM å¨ RISb ææ¨ä¸­è¡¨ç¾å¾æ´å¥½ï¼è©²ææ¨èéª¨éª¼ç©©å®æ§æéï¼è RRS ææ¨åè©ä¼°å§é¨è¡¨ç¤ºçé­¯æ£æ§ãæ´é«ä¸­çåå¥æ¨¡åé¡¯ç¤ºåºä¸åççµæï¼CAM å Grad-CAM é½ä¸ä¸è´å°åªæ¼å¦ä¸ç¨®ï¼æ´é«æ¹æ³æä¾äºå¶çµææ¨¡åçµæçè¡¨ç¤ºã

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

æè¦ï¼æè¿çå¨çä¼°è¨è¡¨æï¼å¤é 24.1 åäººæ
å¥åº·çæ³å¯å¾å¾©å¥æåä¸­åçãå±å®¶
ç©çæ²»ç (PT) å¨æä¾äºåå¼
åé¥åææç¾©çè§å¯æ¹é¢é¢è¨éå¤§ææ°ï¼ä¾æ²»çå¸«åæ£èä½¿ç¨ãçºäºå¡«è£é
åç¼ºå£ï¼æåæåº MicroXerciseï¼å®å°å¾®åä½åæè
å¯ç©¿æ´å¼ææ¸¬å¨æ´åå¨ä¸èµ·ï¼çºæ²»çå¸«åæ£èæä¾ä¸åå¨é¢ç
åé¥ä»é¢ï¼åæ¬å½±çãæå­ååæ¸ãè³ééè¦çæ¯ï¼å®æ¡ç¨
å¤ç¶­åææéè¦æ´ (DTW) ååºæ¼æ­¸å çå¯è§£é
æ¹æ³ä¾åæç£æ§éåä¸­ç¾æçæ·±åº¦å­¸ç¿ç¥ç¶ç¶²è·¯ï¼å°æ³¨æ¼éåçé«ç²åº¦ãéç¨®åå
æ¹æ³è³ééè¦ï¼æä¾èè¼¸å¥å¤§å°å¹éçè¼¸åºï¼ä»¥ç²¾ç¢ºå°
çªåº PT ä¸­ééµçç´°å¾®å·®å¥ååä½ï¼å¾èå°è¤éç AI
åæè½æçºæ¸æ°ãå¯æä½çåé¥ãééå¨ä¸åææ¨ä¸­çªé¡¯éäºå¾®åä½ï¼ä¾å¦ç©©å®æ§ååä½ç¯åï¼MicroXercise
é¡¯èæåæçµä½¿ç¨èå°åé¥ççè§£åç¸éæ§ãæ¯è¼æè½ææ¨å¼·èª¿å¶åªæ¼
å³çµ±æ¹æ³çæææ§ï¼ä¾å¦ç¹å¾µäºæ è³è¨ (FMI) åé£çºæ§åå¥æåäº 39% å 42%ãMicroXercise å¨å±å®¶
ç©çæ²»çæ¹é¢æ´é²ä¸æ­¥ï¼æä¾æè¡åé²ä¸ç´è¦ºæç¨ç
è§£æ±ºæ¹æ¡ï¼ä»¥æåæ£èç§è­·åçµæã

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah RÃ¶sman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

æè¦ï¼ç³»çµ±æ§æç»åé¡§æ¯ç ç©¶ä¸­è­æåè³ªæé«çãç¶èï¼åé¡§éç¨åå°é¡¯èè³æºåè³æéå¶çé»ç¤ãæç»åé¡§ç¶²è·¯ (LRN) æ¯ç¬¬ä¸åéµå¾ª PRISMA 2020 æ¨æºçå¯è§£é AI å¹³å°ï¼æ¨å¨èªååæ´åæç»åé¡§éç¨ãLRN å¨å¤ç§æå¥å¯¦åé åä¸­é²è¡è©ä¼°ï¼ä½¿ç¨å°å®¶éç¼ç 3 åæå°å­ä¸²ä¾æ¥è©¢ PubMedãéå°å®¶è¨ç·´ææ LRN æ¨¡åãæè½ä»¥å°å®¶æååé¡§ä½çºåºæºãå¯è§£éæ§åæè½ææ¨è©ä¼° LRN è¤è£½å°å®¶åé¡§çè½åãä¸è´æ§ä»¥ Jaccard ææ¸åæ··æ·ç©é£æ¸¬éãç ç©¶äººå¡å¨ç ç©¶å®æåå°å½¼æ­¤ççµæä¿å¯ãéççç ç©¶æ´åå° LRN çæçç³»çµ±æ§åé¡§ä¸­ãLRN æ¨¡åå¨æ²æå°å®¶è¨ç·´çææ³ä¸å±ç¾åºåªç°çåé¡æºç¢ºçï¼éå° 84.78% å 85.71% çæºç¢ºçãæè½æé«çæ¨¡åéå°äºé«è©åèéä¿¡è³´åº¦ (k = 0.4953) åå¯è§£éæ§ææ¨ï¼å°ãæ¸å°ãããæå¤ãåãé³å©ãèãééæ´æå¥ãé£çµå¨ä¸èµ·ãå¦ä¸å LRN æ¨¡åæ¶µèäº 91.51% çç¸éæç»ï¼åç®¡èéå°å®¶çå¤æ·ä¸å (k = 0.2174)ï¼ä½åå«äºãä¹³è ãããééãï¼æå¥ï¼åãé©æçãç­è©å½ãLRN åªæ¼æååé¡§ï¼11 åæè¶é 19,920 åéï¼ï¼å°æ´åéç¨ç¸®ç­çº 5 å¤©è¶é 288.6 åéãéé ç ç©¶é¡¯ç¤ºï¼å¯è§£éç AI ä¸éè¦å°å®¶è¨ç·´å³å¯æåé²è¡å°å®¶ç­ç´ç PRISMA ç¸å®¹ç³»çµ±æ§æç»åé¡§ãLRN ç¸½çµäºå¤ç§æå¥ç ç©¶ççµæï¼ä¸¦æ¾åºèè¨åºç ç©¶äººå¡ç¼ç¾å¹¾ä¹ç¸åçä¸»é¢ãå¯è§£éç AI å¯ä»¥æºç¢ºå°å å¿«æåå°è¨åºå¯¦åççè§£ï¼ææ½åé©æ°é«çä¿å¥ç ç©¶ã

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

æè¦ï¼æ¬ç ç©¶ä½¿ç¨çå­å­¸æ¡æ¶åææ··åäººå·¥æºæ§ç³»çµ±çè¨­è¨æ¨¡å¼åå¶å¨è¨åºæ±ºç­ä¸­çæææ§ãå®åé¡ä¸¦æ¯è¼çµåæ©å¨å­¸ç¿ååºæ¼è¦åçæ¨ççåç¨®æ¶æ§ï¼ä»¥æ·±å¥äºè§£å¶çµæ§åºç¤åé«çä¿å¥æç¨ãéå°å©åä¸»è¦åé¡ï¼å¦ä½æ ¹ææ¢å®çè¨­è¨æ¨¡å¼å°éäºç³»çµ±é²è¡åé¡ï¼ä»¥åå¦ä½ééæ¯è¼åææåè¦è§£ï¼æ¬ç ç©¶ä½¿ç¨è»é«å·¥ç¨ä¸­çè¨­è¨æ¨¡å¼ä¾äºè§£ååªåé«çä¿å¥äººå·¥æºæ§ç³»çµ±ãçå­å­¸æå©æ¼è­å¥å±æ§ä¸¦å»ºç«å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡ï¼å¾èå¢å¼·éäºç³»çµ±çå¯æ´åæ§ãå¯é æ§åæè½ãæª¢æ¥äºäºç¨®ä¸»è¦çæ¶æ§ï¼REMLãMLRBãRBMLãRMLT å PERMLãæ¯ç¨®æ¶æ§é½æç¨ç¹çåªç¼ºé»ï¼å¼·èª¿äºå¨è¨åºä»»åä¸­éè¦éèº«æé çæ¹æ³ãREML å¨è³ææéçè³æéä¸­è¡¨ç¾åºé«ç²¾åº¦çé æ¸¬ï¼MLRB å¨èçå¤§åè³æéåè¤éè³ææ´åæ¹é¢è¡¨ç¾åºè²ï¼RBML å¨å¯è§£éæ§åå¯ä¿¡åº¦æ¹é¢è¡¨ç¾åºè²ï¼RMLT å¨ç®¡çé«ç¶­è³ææ¹é¢è¡¨ç¾åºè²ï¼è PERML åç®¡å¨åææ¹é¢æéï¼ä½å¨ç·æ¥ç§è­·å ´æ¯ä¸­è¡¨ç¾åºæ½åãæ¬ç ç©¶å¼å¥äºåç¨®æ°æ¨¡å¼ï¼å»ºç«äºäºç¨®æ½è±¡åé¡æ¨¡å¼ï¼ä¸¦é²ä¸æ­¥å°éäºç¨®æ¨¡å¼ç´°åçºå·é«çç³»çµ±ãéäºè²¢ç»å¢å¼·äºçå­å­¸çåé¡çµç¹ï¼ä¸¦æä¾äºå°å°å®¶ç¥è­èæ©å¨å­¸ç¿æ´åçæ°æ¹æ³ãçå­å­¸ççµæ§åãæ¨¡çµåæ¹æ³å¨éç¼ååææ··åäººå·¥æºæ§ç³»çµ±ãæ­ç¤ºå±æ§ä»¥åæ¨å»£å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡æ¹é¢å·æé¡¯èåªå¢ãç¸½ä¹ï¼æ¬ç ç©¶å¼·èª¿äºæ··åäººå·¥æºæ§ç³»çµ±å¨æ¨é²é«çä¿å¥ä¸­çééµä½ç¨ï¼ä»¥åçå­å­¸å¨æ¨åäººå·¥æºæ§æ´åé²ä¸æ­¥åµæ°æ¹é¢çæ½åï¼æçµæ¹åè¨åºæ±ºç­æ¯æ´åæ£èçæ²»çææã

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

æè¦ï¼ç±æ¼å¶å¼·å¤§çé æ¸¬è½åï¼æ·±åº¦å­¸ç¿å·²æçºè¨±å¤ç¢æ¥­ä¸­ä¸å¯æç¼ºçå·¥å·ï¼åæ¬é«çä¿å¥ãç¶èï¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åéå¸¸ç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸å¿½ç¥äºå°é æ¸¬ä¸ç¢ºå®æ§ç´å¥èéï¼èéå©åå ç´ æ¯è¨åºæ±ºç­å¶å®çééµçµæé¨åãçºäºç¢çå¯è§£éä¸å·æä¸ç¢ºå®æ§æè­çé æ¸¬ï¼æ¬ç ç©¶æåºäºä¸ååçºè²æ°æ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯ (BKAN) çæ°æ¶æ§ï¼å®çµåäºæ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯çè¡¨éè½åèè²æ°æ¨è«ãæåå¨å©åé«å­¸è³æéä¸ä½¿ç¨ BKANï¼éäºè³æéæ¯è©ä¼°æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸è¨ºæ·ä¸­çå»£æ³ä½¿ç¨åºæºï¼ç®é¦¬å°ç¬¬å®äººç³å°¿çè³æéååéå¤«è­å¿èçè³æéãæåçæ¨¡åæä¾äºå°é æ¸¬ä¿¡å¿åæ±ºç­éççæçè¦è§£ï¼ä¸¦ä¸å¨é æ¸¬æºç¢ºåº¦æ¹é¢åªæ¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åãæ­¤å¤ï¼BKAN è¡¨ç¾é¨æ©åèªè­ä¸ç¢ºå®æ§çè½åï¼å¯ç¢ºä¿é«çç²å¾æ´å¯é ä¸å¼å¾ä¿¡è³´çæ±ºç­æ¯æ´ãæ ¹æå¯¦é©çµæï¼æåçè²æ°ç­ç¥æé«äºæ¨¡åçå¯è§£éæ§ï¼ä¸¦å¤§å¹æ¸å°äºéåº¦æ¬åï¼éå°æ¼å°åä¸ä¸å¹³è¡¡çé«å­¸è³æééå¸¸éè¦ãæåæåºäºå¯è½çæ´ååè½ï¼ä»¥é²ä¸æ­¥å° BKAN ç¨æ¼æ´è¤éçå¤æ¨¡å¼è³æéï¼ä¸¦æ¢è¨éäºç¼ç¾å°æ¼æªä¾å»ºç«å¯é çé«çä¿å¥ AI ç³»çµ±ç ç©¶çéè¦æ§ãéé å·¥ä½çºæ·±åº¦å­¸ç¿æ¨¡åé¨ç½²å¨éæåº¦åå¯é æ§è³ééè¦çéè¦é åä¸­éåäºä¸åæ°çå¸ç¯ã

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

æè¦ï¼å¨ç¾ä»£é«çä¿å¥ä¸­ï¼è§£æ±ºæºç¢ºç¾çé æ¸¬ååæ§åå»ºè­°çè¤éæ§æ¢è³ééè¦åå·æææ°æ§ãæ¬ç ç©¶å¼å¥äº MLtoGAIï¼å®å°èªç¾©ç¶²è·¯æè¡èæ©å¨å­¸ç¿ (ML) ç¸çµåï¼ä»¥å¢å¼·ç¾çé æ¸¬ä¸¦éé ChatGPT æä¾ä½¿ç¨èååçèªªæãè©²ç³»çµ±åå«ä¸åééµçµæé¨åï¼ä¸åå¯éè¤ä½¿ç¨çç¾çæ¬ä½ï¼å¶ä¸­åå«æéåç¨®ç¾ççè©³ç´°ç¥è­ï¼ä¸åè¨ºæ·åé¡æ¨¡åï¼å®ä½¿ç¨æ£èççä¾æºç¢ºæª¢æ¸¬ç¹å®ç¾çï¼ä»¥åèªç¾©ç¶²è·¯è¦åèªè¨ (SWRL) èæ¬ä½å ChatGPT çæ´åï¼ä»¥ç¢çæ¸æ°ãåæ§åçå¥åº·å»ºè­°ãéç¨®æ¹æ³é¡¯èæé«äºé æ¸¬æºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºææ¼çè§£ççµæï¼è§£æ±ºäºç¾çåä¸åçççè¤éæ§ãMLtoGAI ç³»çµ±å±ç¤ºäºæºç¢ºæ§åä½¿ç¨èæ»¿æåº¦çå¯¦è³ªæ§é²æ­¥ï¼æå©æ¼éç¼æ´æºæ§ä¸æ´ææ¼åå¾çé«çä¿å¥è§£æ±ºæ¹æ¡ãéç¨®åµæ°çæ¹æ³çµåäº ML æ¼ç®æ³çåªé»ï¼ä»¥åéé ChatGPT æä¾éæä¸äººé¡å¯ä»¥çè§£çèªªæçè½åï¼å¨é æ¸¬æºç¢ºæ§åä½¿ç¨èçè§£æ¹é¢åå¾äºé¡¯èçé²æ­¥ãééå©ç¨èªç¾©æè¡åå¯è§£éç AIï¼è©²ç³»çµ±æé«äºç¾çé æ¸¬çæºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºå»ºè­°èåå¥æ£èç¸éä¸ææ¼çè§£ãæåçç ç©¶å¼·èª¿äºæ´ååé²æè¡ä»¥åæé«çè¨ºæ·ä¸­ç¾æææ°çæ½åï¼çºæºæ§é«çä¿å¥ç³»çµ±çæªä¾ç¼å±éªè·¯ãæ­¤å¤ï¼è©²ç³»çµ±ä½¿ç¨ 200 ååææ£èè³æè¨éé²è¡é©è­ï¼ç¢ºä¿äºç©©å¥çæè½åå¯é æ§ã

##### **Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) æ¯å°äººå·¥æºæ§ (AI) åæ©å¨å­¸ç¿ (ML) æ¼ç®æ³æ´åå°è¨åºå¯¦åä¸­çè¾¯è«æ ¸å¿ãé«å·è¡æè½ç AI/ML æ¨¡åï¼ä¾å¦æ´é«å­¸ç¿å¨åæ·±åº¦ç¥ç¶ç¶²è·¯ï¼éå¸¸ç¼ºä¹å¯è§£éæ§ï¼é»ç¤è¨åºé«çå°å¶é æ¸¬çä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æ­£å¨éç¼ XAI æè¡ï¼ä»¥äººé¡å¯ä»¥çè§£çè¡èªæè¿° AI/ML é æ¸¬ãä¸åæå¸æçæ¹åæ¯æ¡ç¨ææåº¦åæ (SA) åå¨çææåº¦åæ (GSA)ï¼å®åæ¬è³ªä¸æä¾ææ¨¡åè¼¸å¥å°é æ¸¬çå½±é¿ä¾å°å¶é²è¡æåãå¨æ­¤ï¼æåä»ç´¹ä¸ç¨®æ°ç delta-XAI æ¹æ³ï¼ééæ´å GSA ææ¨ delta ææ¸ä¾æä¾ ML æ¨¡åé æ¸¬çå±é¨è§£éãdelta-XAI ææ¸è©ä¼°æ¯åç¹å¾µå¼å°åæ­¸ååé¡åé¡ä¸­åå¥ä¾é çé æ¸¬è¼¸åºä¹å½±é¿ãæåå° delta-XAI ææ¸å½¢å¼åï¼ä¸¦æä¾å¶å¯¦ä½çç¨å¼ç¢¼ãä½¿ç¨ç·æ§åæ­¸æ¨¡åå°æ¨¡æ¬æå¢è©ä¼° delta-XAI æ¹æ³ï¼ä¸¦ä»¥ Shapley å¼ä½çºåºæºãçµæé¡¯ç¤º delta-XAI ææ¸éå¸¸è Shapley å¼ä¸è´ï¼ä½å¨å·æé«åº¦å½±é¿åææ¥µç«¯ç¹å¾µå¼çæ¨¡åä¸­å­å¨é¡¯èå·®ç°ãdelta-XAI ææ¸å¨åµæ¸¬ä¸»è¦ç¹å¾µåèçæ¥µç«¯ç¹å¾µå¼æ¹é¢è¡¨ç¾åºæ´é«çææåº¦ãå®æ§å°ä¾èªªï¼delta-XAI ééå©ç¨æ©çå¯åº¦å½æ¸æä¾ç´è§çè§£éï¼ä½¿ç¹å¾µæåæ´æ¸æ°ä¸å°å¾æ¥­äººå¡ä¾èªªæ´å·å¯è§£éæ§ãç¸½é«èè¨ï¼delta-XAI æ¹æ³å°æ¼ç©©å¥å°åå¾ ML æ¨¡åé æ¸¬çå±é¨è§£éä¼¼ä¹å¾æå¸æãå°å¨çå¯¦ä¸ççè¨åºç°å¢ä¸­é²è¡é²ä¸æ­¥èª¿æ¥ï¼ä»¥è©ä¼°å¶å° AI è¼å©è¨åºå·¥ä½æµç¨çå½±é¿ã

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

æè¦ï¼å¤±æºçæ¯ä¸ç¨®å½±é¿å¨çæ¸ç¾è¬äººçè¡°å¼±æ§ç¥ç¶ç¾çï¼å¨è¨ºæ·ä¸å·æéå¤§ææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼ç¨æ¼å°å¤±æºåéå¤±æºèå¹´æ£èé²è¡åé¡ï¼ä½¿ç¨ 3D å¤§è¦ç£æ¯é å½± (MRI) ææãæåçåæ³æ¡ç¨äºä¸ç¨®ç¨ç¹æè¡ï¼ç¨æ¼é¸ææ§èç MRI åçï¼éé»éæ³¨æç¸éçå¤§è¦ååï¼ä¸¦æé¤ä¿¡æ¯éè¼å°çé¨åãéç¨®æ¹æ³ç±ä¸ååºæ¼ä¿¡å¿çåé¡å§å¡æè£åï¼è©²å§å¡æç±ä¸åèªå®ç¾©æ·±åº¦å­¸ç¿æ¨¡åçµæï¼Dem3D ResNetãDem3D CNN å Dem3D EfficientNetãéäºæ¨¡åååå·¥ä½ä»¥å¢å¼·æ±ºç­çæºç¢ºæ§ï¼å©ç¨å®åçéé«åªå¢ãå¨å½±åç ç©¶éæ¾å­åç³»å (OASIS) è³æéä¸é²è¡æ¸¬è©¦ï¼æåçæ¨¡åéå°äº 94.12% çé©äººæºç¢ºåº¦ï¼è¶éäºç¾ææ¹æ³ãæ­¤å¤ï¼å¨é¿è²æµ·é»çç¥ç¶å½±åå¡è­° (ADNI) è³æéä¸çé©è­è­å¯¦äºæåæ¹æ³çç©©å¥æ§åæ®éæ§ãå¯è§£é AI (XAI) æè¡åå¨é¢çæ¶èç ç©¶é²ä¸æ­¥è­å¯¦äºæåæè¡çæææ§ï¼æä¾äºå°æ±ºç­éç¨åæåæ¹æ³éè¦æ§çè¦è§£ãéé ç ç©¶çºå¤±æºçè¨ºæ·æä¾äºéå¤§é²å±ï¼çºè¨åºæç¨æä¾äºä¸åé«åº¦æºç¢ºä¸é«æçå·¥å·ã

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

æè¦ï¼èç±æºæ§ç°å¢ä¸­ä¸å¼äººæ³¨ç®çææ¸¬å¨è¾¨è­æ¥å¸¸æ´»åï¼è½åç¨åç¨®é«çä¿å¥æç¨ãç£æ§åè©¦èå¨å®¶ä¸­å¦ä½å·è¡æ´»åï¼ä»¥åå¶é¨èæéçè®åï¼å¯ä»¥æ­ç¤ºå¥åº·åé¡çæ©æççï¼ä¾å¦èªç¥è½åä¸éãæ­¤é åä¸­çå¤§å¤æ¸æ¹æ³é½ä½¿ç¨æ·±åº¦å­¸ç¿æ¨¡åï¼éäºæ¨¡åéå¸¸è¢«è¦çºå°ææ¸¬å¨è³æå°æè³æ´»åçé»çå­ãç¶èï¼éå°å®¶ä½¿ç¨èï¼ä¾å¦è¨åºé«å¸«ï¼éè¦ä¿¡ä»»ä¸¦äºè§£éäºæ¨¡åçè¼¸åºãå æ­¤ï¼äººé¡æ´»åè¾¨è­çå¯è§£é AI (XAI) æ¹æ³æéèçï¼ä»¥æä¾ä¾èªéäºæ¨¡åçç´è¦ºèªç¶èªè¨èªªæãä¸åç XAI æ¹æ³æç¢çä¸åçèªªæï¼èå¶æææ§éå¸¸ééä½¿ç¨èèª¿æ¥ä¾è©ä¼°ï¼éå¨ææ¬åå¬å¹³æ§æ¹é¢éå¸¸å·æææ°æ§ãæ¬ææåºä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) çèªåè©ä¼°æ¹æ³ï¼ä»¥å¨åé¸èä¸­æ¾åºæé©åéå°å®¶ä½¿ç¨èç XAI æ¹æ³ãæåçåæ­¥çµæè¡¨æï¼LLM è©ä¼°èä½¿ç¨èèª¿æ¥ä¸è´ã

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

æè¦ï¼å·¥æ¥­ 5.0 èéæ¼äººé¡èäººå·¥æºæ§ (AI) åä½å·è¡è£½é ä¸­çä¸åä»»åï¼æ¶åæ´å¤æ©å¨äººãç©è¯ç¶² (IoT) è£ç½®åäºé£ãæ´å¢/èæ¬å¯¦å¢ (AR) åå¶ä»æºæ§è£ç½®ãéäºè£ç½®åäºé£å¨ç¶æ¿ãé«çä¿å¥ãæè²ååé²ç³»çµ±ç­åç¨®ééµé åçå»£æ³åèï¼å¼ç¼äºå¤ç¨®é¡åçæ½å¨å®å¨æ¼æ´ãAI æ¬èº«å·²è¢«è­ææ¯ç¶²è·¯å®å¨ä¸åé åä¸­éå¸¸ææä¸å¼·å¤§çå·¥å·ï¼ä¾å¦å¥ä¾µåµæ¸¬ãæ¡æè»é«åµæ¸¬åç¶²è·¯é£é­åµæ¸¬ç­ãå°±åå¨è¨±å¤æç¨é åä¸æ¨£ï¼ç¶²è·¯å®å¨å°æ¥­äººå¡ä¸é¡ææ¥åé»ç ML è§£æ±ºæ¹æ¡ä¾æç¨æ¼ç¶²è·¯å®å¨ãéç¨®ä¸é¡æä¿ä½¿å¯è§£éäººå·¥æºæ§ (XAI) ä½çºä¸ç¨®å·¥å·è¢«æ¡ç¨ï¼æå©æ¼èªªæå¨åºæ¼ ML çç³»çµ±ä¸­å¦ä½ååºæ±ºç­ãå¨éé èª¿æ¥ä¸­ï¼æåå°å·¥æ¥­ 5.0 çä¸ååºæ¼ XAI çå¥ä¾µåµæ¸¬ç³»çµ±é²è¡äºå¨é¢çç ç©¶ï¼ä¸¦ä¸æåä¹ééå°æå¼ XIDS (Adv-XIDS) æ¹æ³çè§é»ä¾æ¢è¨å¯è§£éæ§åå¯è©®éæ§å°ç¶²è·¯å®å¨å¯¦åçå½±é¿ãæ­¤å¤ï¼æååæäºå·¥æ¥­ 5.0 ç XAI ç¶²è·¯å®å¨ç³»çµ±ä¸­å¯è½å­å¨çæ©æåææ°ï¼å¼ç¼äºæªä¾éå° XAI åºç¤è§£æ±ºæ¹æ¡çç ç©¶ï¼ä»¥ä¾é«é¢¨éªçå·¥æ¥­ 5.0 æç¨æ¡ç¨ãæåç¸ä¿¡éé å´è¬¹çåæå°çºæå®é åå§çå¾çºç ç©¶å·¥ä½å»ºç«åºç¤æ¶æ§ã

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

æè¦ï¼æ¬ç ç©¶æ¨å¨æ¢è¨å°èªç¶èªè¨èç (NLP) åæ©å¨å­¸ç¿ (ML) æè¡å¯¦ä½æ¼é«çä¿¡å½ç·¨ç¢¼èªååï¼ä¸¦å·åè¦è¦ºåèªªæè½ååè¼éåçæ¬å°é»è¦è¨­å®ãç®åå¨è¨åºç°å¢ä¸­ï¼ç·¨ç¢¼æ¯ä¸ç¨®æåæµç¨ï¼æ¶åçºçæ£æä»¶ä¸­çæ¯é ççãç¨åºåè¥ç©ææ´¾ä»£ç¢¼ (ä¾å¦ï¼ä½¿ç¨ SNOMED CT ä»£ç¢¼ 56265001 è¡¨ç¤ºå¿èç)ãæ­¤é åæä½¿ç¨ææ° ML æ¨¡åé²è¡èªåç·¨ç¢¼çåæ­¥ç ç©¶ï¼ç¶èï¼ç±æ¼æ¨¡åçè¤éæ§åå¤§å°ï¼ä¸¦æªå¯¦ç¾å¯¦éé¨ç½²ãçºäºé²ä¸æ­¥ä¿é²èªåç·¨ç¢¼å¯¦åçå¯è½æ§ï¼æåå¨æ¬å°é»è¦è¨­å®ä¸­æ¢è¨äºä¸äºè§£æ±ºæ¹æ¡ï¼æ­¤å¤ï¼æåæ¢è¨äºèªªæåè½å¨ AI æ¨¡åéæåº¦ä¸­çåè½ãæåä½¿ç¨å¬éç MIMIC-III è³æåº«å HAN/HLAN ç¶²è·¯æ¨¡åé²è¡ ICD ä»£ç¢¼é æ¸¬ãæåéè©¦é©äº ICD å SNOMED CT ç¥è­åº«ä¹éçå°æãå¨æåçå¯¦é©ä¸­ï¼éäºæ¨¡åæä¾äº 97.98% ä»£ç¢¼çæç¨è³è¨ãéé èª¿æ¥çµæå¯ä»¥çºå¯¦åä¸­çèªåè¨åºç·¨ç¢¼å¯¦ä½æä¾ä¸äºè¦è§£ï¼ä¾å¦å¨é«é¢ç°å¢ä¸­ï¼ç±è¨åºé«çä½¿ç¨çæ¬å°é»è¦ï¼å°æ¡é é¢ \url{https://github.com/Glenj01/Medical-Coding}ã

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

æè¦ï¼äººå·¥æºè½ (AI) æ¯æçæ±ºç­å¶å®æ¯æªä¾ 6G ç¶²è·¯ä¸­çééµåç´ ï¼å¶ä¸­å°å¼å¥åç AI çæ¦å¿µãæ­¤å¤ï¼AI å»£æ³ç¨æ¼ä¸åçééµæç¨ä¸­ï¼ä¾å¦èªåé§é§åé«çè¨ºæ·ãå¨éäºæç¨ä¸­ï¼ä½¿ç¨ AI ä½çºé»çæ¨¡åæ¯æé¢¨éªä¸å·æææ°æ§çãå æ­¤ï¼çè§£åä¿¡ä»»éäºæ¨¡åååºçæ±ºç­è³ééè¦ãè§£æ±ºæ­¤åé¡çæ¹æ³æ¯éç¼å¯è§£é AI (XAI) æ¶æ§ï¼æ¨å¨è§£éé»çæ¨¡åè¡çºèå¾çéè¼¯ï¼å¾èç¢ºä¿å¶ææä¸å®å¨çé¨ç½²ãæè¿ï¼æåæåºäºä¸åæ°çåºæ¼æ¾åç XAI-CHEST æ¡æ¶ï¼è©²æ¡æ¶é¢åç¡ç·éä¿¡ä¸­çä¿¡éä¼°è¨ãXAI-CHEST æ¡æ¶çæ ¸å¿ææ³æ¯ééå¨ç¡éè¼¸å¥ä¸å¼å¥é«åªè²ä¾è­å¥ç¸éæ¨¡åè¼¸å¥ãéä»½æç¨¿æä¾äº XAI-CHEST æ¡æ¶çè©³ç´°çè«åºç¤ãç¹å¥æ¯ï¼æåæ¨å°äº XAI-CHEST æå¤±å½æ¸ååªè²é¾å¼å¾®èª¿åªååé¡çè§£æè¡¨éå¼ãå æ­¤ï¼è¨­è¨ç XAI-CHEST æä¾äºä¸ç¨®æºè½è¼¸å¥ç¹å¾µé¸ææ¹æ³ï¼å¯ä»¥å¨åªåæç¨æ¨¡åçæ¶æ§çåæé²ä¸æ­¥æé«æ´é«æ§è½ãæ¨¡æ¬çµæè¡¨æï¼XAI-CHEST æ¡æ¶æä¾äºææçè§£éï¼å¨éä½æéçè¨ç®è¤éåº¦çåæï¼æä¾äºæ¹é²çæ¯ç¹é¯èª¤çæ§è½ï¼èéèåºæ¼å³çµ± DL çä¿¡éä¼°è¨ç¸æ¯ã

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

æè¦ï¼è¿ç¯è®ºææåºäºç¨äºä»è§ç½èç¼åºå¾åè¿è¡ç¾çåç±»çæ©å¼ æ®å·®ç½ç» (ResNet) æ¨¡åãæ©å¼ å·ç§¯æ»¤æ³¢å¨ç¨äºæ¿æ¢ ResNet æ¨¡åè¾é«å±ä¸­çæ­£å¸¸å·ç§¯æ»¤æ³¢å¨ï¼æ©å¼  ResNetï¼ï¼ä»¥æ¹åæç¥åºï¼ä»èéå¯¹ç¾çåç±»å¯¹æ­£å¸¸ ResNet æ¨¡åè¿è¡æ¹è¿ãæ¬ç ç©¶å¼å¥äºéç¨æ·±åº¦å­¦ä¹ çè®¡ç®æºè¾å©è¯æ­å·¥å·ï¼å¹¶éè¿å¯è§£éç AI ææ¯è¿è¡äºå¢å¼ºãè¿äºææ¯æ¨å¨ä½¿è¯¥å·¥å·çå³ç­è¿ç¨éæåï¼ä»èä½¿å»å­¦ä¸ä¸äººå£«è½å¤çè§£åä¿¡ä»» AI çè¯æ­å³ç­ãå®ä»¬ä¸å½ä»çå»çä¿å¥é¢åå°¤ä¸ºç¸å³ï¼å¨è¯¥é¢åï¼å¯¹ AI åºç¨çéæåº¦éæ±ä¸æ­å¢é¿ï¼ä»¥ç¡®ä¿å¶å¯é æ§ååä¹éå¾·çä½¿ç¨ãæ©å¼  ResNet ç¨ä½æ­£å¸¸ ResNet çæ¿ä»£åï¼ä»¥æé«è§ç½èç¼é¨ç¾ççåç±»åç¡®æ§å¹¶åå°æéçè®¡ç®æ¶é´ãæ¬å·¥ä½ä¸­ä½¿ç¨çæ°æ®éæ¯ç¼ç§ç¾çæºè½è¯å« (ODIR) æ°æ®éï¼è¿æ¯ä¸ä¸ªç»æåçç¼ç§æ°æ®åºï¼åå«å«ç±»æ¶µçå¤§å¤æ°å¸¸è§è§ç½èç¼é¨ç¾çãæ¬å·¥ä½ä¸­ä½¿ç¨çè¯ä¼°ææ åæ¬ç²¾ç¡®åº¦ãå¬åçãåç¡®åº¦å F1 å¾åãå¨è¿é¡¹å·¥ä½ä¸­ï¼å¯¹ ResNet-18ãResNet-34ãResNet-50ãResNet-101 å ResNet-152 äºä¸ªåä½çæ­£å¸¸ ResNet æ¨¡ååæ©å¼  ResNet æ¨¡åè¿è¡äºæ¯è¾ç ç©¶ãä¸æ­£å¸¸ ResNet ç¸æ¯ï¼æ©å¼  ResNet æ¨¡åæ¾ç¤ºåºæå¸æçç»æï¼å¨ ODIR å¤ç±»ç¾çåç±»ä¸­ï¼ä¸è¿°åä¸ªåä½çå¹³å F1 å¾åä¸º 0.71ã0.70ã0.69ã0.67 å 0.70ã

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v2 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
existing surveys on the trustworthiness of foundation models do not adequately
address their specific variations and applications within the medical imaging
domain. This survey aims to fill that gap by presenting a novel taxonomy of
foundation models used in medical imaging and analyzing the key motivations for
ensuring their trustworthiness. We review current research on foundation models
in major medical imaging applications, focusing on segmentation, medical report
generation, medical question and answering (Q\&A), and disease diagnosis. These
areas are highlighted because they have seen a relatively mature and
substantial number of foundation models compared to other applications. We
focus on literature that discusses trustworthiness in medical image analysis
manuscripts. We explore the complex challenges of building trustworthy
foundation models for each application, summarizing current concerns and
strategies for enhancing trustworthiness. Furthermore, we examine the potential
of these models to revolutionize patient care. Our analysis underscores the
imperative for advancing towards trustworthy AI in medical image analysis,
advocating for a balanced approach that fosters innovation while ensuring
ethical and equitable healthcare delivery.

æè¦ï¼åºç¤æ¨¡åå¨é«å­¸å½±åæ¹é¢çå¿«éé²å±ï¼ä»£è¡¨èå¨å å¼·è¨ºæ·æºç¢ºæ§ååäººåæ²»çæ¹é¢éåºä¸å¤§æ­¥ãç¶èï¼åºç¤æ¨¡åå¨é«çä¿å¥ä¸­çé¨ç½²éè¦å°å¶å¯ä¿¡åº¦é²è¡å´æ ¼çå¯©æ¥ï¼åæ¬é±ç§ãç©©å¥æ§ãå¯é æ§ãå¯è§£éæ§åå¬å¹³æ§ãç®åéæ¼é«å­¸å½±åä¸­åºç¤æ¨¡åçèª¿æ¥æç»ä¸­é¡¯ç¤ºåºç¸ç¶å¤§çå·®è·ï¼ç¹å¥æ¯å¨å¯ä¿¡åº¦æ¹é¢ãæ­¤å¤ï¼ç¾æéæ¼åºç¤æ¨¡åå¯ä¿¡åº¦çèª¿æ¥ä¸¦æªååè§£æ±ºå¶å¨é«å­¸å½±åé åä¸­çç¹å®è®ååæç¨ãæ¬èª¿æ¥æ¨å¨ééæåºé«å­¸å½±åä¸­ä½¿ç¨çåºç¤æ¨¡åçæ°åé¡æ³ä¸¦åæç¢ºä¿å¶å¯ä¿¡åº¦çééµåæ©ï¼ä¾å¡«è£éä¸ç©ºç½ãæååé¡§äºåºç¤æ¨¡åå¨ä¸»è¦é«å­¸å½±åæç¨ä¸­çç¶åç ç©¶ï¼éé»éæ³¨åå²ãé«çå ±åçæãé«çåé¡ååç­ (Q&A) ä»¥åç¾çè¨ºæ·ãéäºé åä¹æä»¥è¢«å¼·èª¿ï¼æ¯å çºèå¶ä»æç¨ç¸æ¯ï¼å®åå·²ç¶çå°ç¸å°æçä¸å¤§éçåºç¤æ¨¡åãæåå°æ³¨æ¼æ¢è¨é«å­¸å½±ååææç¨¿ä¸­å¯ä¿¡åº¦çæç»ãæåæ¢è¨äºçºæ¯åæç¨æ§å»ºå¯ä¿¡åºç¤æ¨¡åçè¤éææ°ï¼ç¸½çµäºç¶åéæ³¨é»åå¢å¼·å¯ä¿¡åº¦çç­ç¥ãæ­¤å¤ï¼æåæ¢è¨äºéäºæ¨¡åå¨é©æ°æ£èè­·çæ¹é¢çæ½åãæåçåæå¼·èª¿äºå¨é«å­¸å½±ååæä¸­æèå¯ä¿¡è³´çäººå·¥æºæ§éé²çå¿è¦æ§ï¼ä¸¦å¡å°ä¸ç¨®å¹³è¡¡çæ¹æ³ï¼æ¢è½ä¿é²åµæ°ï¼åè½ç¢ºä¿éå¾·åå¬å¹³çé«çä¿å¥æåã

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

æè¦ï¼åºéè¶é³æ³¢ (POCUS) æ¯è¨åºé«å¸«å¨æ£èåºéé²è¡åè§£è®è¶é³æ³¢ææçå¯¦åãç¶èï¼è§£è®éäºå½±åæéçå°æ¥­ç¥è­ç¸ç¶å¯è§ï¼èä¸å¨ç·æ¥ææ³ä¸å¯è½ä¸¦éé¨æå·åãéç¨®ç¾å¯¦ææ³ä½¿å¾æ©å¨å­¸ç¿åé¡å¨ç­æ¼ç®æ³å°æ¼å å¼·äººé¡æ±ºç­è®å¾æ¥µçºæå¹å¼ãPOCUS è£ç½®æ­£ä»¥åçææ¬æ¨åºï¼å°ºå¯¸çºææ©å¤§å°ãå° POCUS è£ç½®è½è®çºæçå·¥å·çææ°å¨æ¼ï¼è§£è®è¶é³æ³¢å½±åéè¦å°éè¨ç·´åç¶é©ãä¸å¹¸çæ¯ï¼åå¾æ­£åè¨ç·´å½±åçå°é£åº¦ä»£è¡¨èå»ºç½®ææçä¸æºç¢ºçåé¡å¨çä¸å¤§éç¤ãå æ­¤ï¼æååè©¦æ¢è¨çåé¡æ¯å¦ä½æ¢ç´¢ç­ç¥ï¼ä»¥æé«ä½¿ç¨ç¨çè³æè¨ç·´çåé¡å¨çæºç¢ºåº¦ãæååè¨­ä½¿ç¨å°æ¸è³æå¯¦ä¾é²è¡è¨ç·´å¯è½ä¸è¶³ä»¥è®åé¡å¨æ¦æ¬ï¼å°è´å®åéåº¦æ¬åãæåçåæ³ä½¿ç¨å¯è§£é AI å¢å¼·æ¹æ³ï¼ä»¥åå©æ¼ç®æ³å¾è¼å°çè³æä¸­å­¸ç¿æ´å¤ï¼ä¸¦æ½å¨åå©åé¡å¨æ´å¥½å°æ¦æ¬ã

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

æè¦ï¼è¿å¹´ä¾ï¼ç¾åè¦è­äºé»å­çæé»å­é¦è¸ä½¿ç¨çå¤§å¹æ¿å¢ï¼å°è´é»å­çåé»å­çä½¿ç¨ç¸éèºæå· (EVALI) çä¾é¡¯èå¢å ï¼å¨ 2019 å¹´ EVALI çç¼æéé æä½é¢åæ­»äº¡ï¼å¸é¡¯äºçè§£é»å­çè¡çºåå¶å®æææè¸ç­ç¥çè¿«åæ§ãç±æ¼ç¤¾ç¾¤åªé«å¹³å°çæ®åï¼å¨çè¶é 47 åä½¿ç¨èä½¿ç¨å®åé²è¡é£çµãæºéãæ°èåå¨æ¨ï¼å¶ä¸­å¾å¤§ä¸é¨åèå¥åº·ç¸éï¼å æ­¤å°ç¤¾ç¾¤åªé«è³æå»ºç«çºå¬å±è¡çç ç©¶ä¸­ç¡å¹çææ©è³æè³æºãå¨æ¬ç ç©¶ä¸­ï¼æåå¾ Reddit ä¸ä¸åé»å­çå­ç¤¾ç¾¤ä¸­æåä¸åç¯ä¾è³æéï¼ä»¥åæä½¿ç¨èçæé»å­çæåãå©ç¨ OpenAI ææ°çå¤§åèªè¨æ¨¡å GPT-4 é²è¡å¥å­å±¤ç´çæé»å­çæååµæ¸¬ï¼æ¬ç ç©¶æ¯è¼äºæ­¤æ¨¡åççµæèå¤è¡äººåè¨åºå°å®¶è¨»è§£ãä½¿ç¨ä¸åçæç¤ºç­ç¥ï¼ä¾å¦é¶æ¬¡å­¸ç¿ãä¸æ¬¡å­¸ç¿ãå°æ¬¡å­¸ç¿åæèéæç¤ºï¼æåéç¼äº 8 åæç¤ºï¼è©³ç´°ç¨åº¦ä¸åï¼å GPT-4 è§£éä»»åï¼ä¸¦è©ä¼°éäºç­ç¥å½¼æ­¤ä¹éçæè½ãéäºåæ­¥ç¼ç¾å¼·èª¿äº GPT-4 å¨ç¤¾ç¾¤åªé«è³æåæä¸­çæ½åï¼ç¹å¥æ¯å¨è­å¥äººé¡åµæ¸¬å¯è½ç¡æ³å¯è¦ºçä½¿ç¨èå¾®å¦æåæ¹é¢ã

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

æè¦ï¼<paragraph>äººå·¥æºæ§ï¼AIï¼ç®åå¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼ç¼ºä¹å¯è§£éæ§çé»çæ©å¨å­¸ç¿æ¨¡åãå¯è§£éæ§äººå·¥æºæ§ï¼XAIï¼é åè´åæ¼è§£æ±ºéåä¸»è¦åé¡ï¼éå¨éèãæ³å¾åå¥åº·ç­é«é¢¨éªé åè³ééè¦ã
æåæåºäºä¸ç¨®åºæ¼ç¯çè«å®ç¾© AI æ¨¡ååå¶å¯è§£éæ§çæ¹æ³ãçºæ­¤ï¼æåæ¡ç¨çµåæ¨¡åçæ¦å¿µï¼å®ä»¥å½¢å¼å¼¦åçå½¢å¼çå¾æ¨¡åï¼éäºå¼¦åæç²äºæ¨¡åçæ½è±¡çµæ§åå¶å·é«å¯¦ç¾ãéç¨®ç¶åè§é»åå«äºç¢ºå®æ§ãæ¦çæ§åéå­æ¨¡åãæåå°åç¨® AI æ¨¡åä½çºçµåæ¨¡åé²è¡æ¯è¼ï¼åæ¬ç·æ§ååºæ¼è¦åçæ¨¡åãï¼éè¿´ï¼ç¥ç¶ç¶²è·¯ãTransformerãVAEï¼ä»¥åå æå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåæ ¹ææ¨¡åççµåçµæ§çµ¦åºæ¨¡åè§£éçå®ç¾©ï¼å±ç¤ºå¦ä½åææ¨¡åçå¯è§£éæ§ï¼ä¸¦ä½¿ç¨å®ä¾æ¾æ¸ XAI ä¸­çå¸¸è¦ä¸»é¡ãæåç¼ç¾ï¼è®æ¨æºçãå§å¨å¯è§£éãæ¨¡åå¦æ­¤éæçåå å¨åè¡¨ä¸­è¡¨ç¾å¾æçºæ¸æ¥ãéå¼å°æåå¾åºæ´ä¸è¬ççµåå¯è§£éï¼CIï¼æ¨¡åæ¦å¿µï¼å®å¦å¤éåæ¬å æãæ¦å¿µç©ºéå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåå±ç¤ºäº CI æ¨¡åçå¯è§£éæ§åªå¢ãé¦åï¼å®åççµåçµæ§åè¨±è¨ç®å¶ä»æèè¶£çéï¼ä¸¦å¯è½ééå¹éæ¨¡åççµæ§ä¾ä¿é²å¾æ¨¡åå°è¢«å»ºæ¨¡ç¾è±¡çæ¨çãå¶æ¬¡ï¼å®ååè¨±å°å¶è¡çºé²è¡åè§£èªªæï¼éäºèªªæåºæ¼å½±é¿ç´æãåè§£æè¡åéå¯«èªªæãæå¾ï¼æåè¨è«äºéç¨®æ¹æ³çè¨±å¤æªä¾æ¹åï¼æåºäºå¦ä½å¨å¯¦è¸ä¸­å­¸ç¿éç¨®ææç¾©ççµæ§åæ¨¡åçåé¡ã</paragraph>

##### **Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**
2406.12142v2 by Vincent Olesen, Nina Weng, Aasa Feragen, Eike Petersen

Machine learning models have achieved high overall accuracy in medical image
analysis. However, performance disparities on specific patient groups pose
challenges to their clinical utility, safety, and fairness. This can affect
known patient groups - such as those based on sex, age, or disease subtype - as
well as previously unknown and unlabeled groups. Furthermore, the root cause of
such observed performance disparities is often challenging to uncover,
hindering mitigation efforts. In this paper, to address these issues, we
leverage Slice Discovery Methods (SDMs) to identify interpretable
underperforming subsets of data and formulate hypotheses regarding the cause of
observed performance disparities. We introduce a novel SDM and apply it in a
case study on the classification of pneumothorax and atelectasis from chest
x-rays. Our study demonstrates the effectiveness of SDMs in hypothesis
formulation and yields an explanation of previously observed but unexplained
performance disparities between male and female patients in widely used chest
X-ray datasets and models. Our findings indicate shortcut learning in both
classification tasks, through the presence of chest drains and ECG wires,
respectively. Sex-based differences in the prevalence of these shortcut
features appear to cause the observed classification performance gap,
representing a previously underappreciated interaction between shortcut
learning and model fairness analyses.

æè¦ï¼æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸å½±ååæä¸­å·²éå°æ´é«é«æºç¢ºåº¦ãç¶èï¼ç¹å®æ£èç¾¤é«çæè½å·®ç°å°å¶è¨åºæç¨ãå®å¨æ§èå¬å¹³æ§æ§æææ°ãéå¯è½æå½±é¿å·²ç¥çæ£èç¾¤é«ï¼ä¾å¦åºæ¼æ§å¥ãå¹´é½¡æç¾çäºåï¼ä»¥åååæªç¥ä¸æªæ¨ç±¤çç¾¤é«ãæ­¤å¤ï¼æ­¤é¡è§å¯å°çæè½å·®ç°çæ ¹æ¬åå éå¸¸é£ä»¥ç¼ç¾ï¼é»ç¤äºç·©è§£æªæ½ãå¨æ¬æä¸­ï¼çºäºè§£æ±ºéäºåé¡ï¼æåå©ç¨åçç¼ç¾æ¹æ³ (SDM) ä¾è­å¥å¯è§£éçè³ææè½ä¸ä½³å­éï¼ä¸¦éå°è§å¯å°çæè½å·®ç°åå å¶å®åè¨­ãæåå¼å¥ä¸ç¨®æ°ç SDMï¼ä¸¦å¨è¸é¨ X åçä¸­èºçåèºä¸å¼µåé¡çæ¡ä¾ç ç©¶ä¸­æç¨å®ãæåçç ç©¶è­æäº SDM å¨åè¨­å¶å®ä¸­çæææ§ï¼ä¸¦å°å»£æ³ä½¿ç¨çè¸é¨ X åçè³æéåæ¨¡åä¸­ååè§å¯å°ä½ç¡æ³è§£éçç·æ§åå¥³æ§æ£èä¹éçæè½å·®ç°æä¾äºè§£éãæåçç¼ç¾è¡¨æï¼å¨åé¡ä»»åä¸­ï¼ééè¸èå¼æµç®¡åå¿é»åå°ç·çå­å¨ï¼å­å¨æ·å¾å­¸ç¿ãéäºæ·å¾ç¹å¾µççè¡çå­å¨åºæ¼æ§å¥çå·®ç°ï¼ä¼¼ä¹æå°è´è§å¯å°çåé¡æè½å·®è·ï¼éä»£è¡¨æ·å¾å­¸ç¿åæ¨¡åå¬å¹³æ§åæä¹éååæªåå°éè¦çäº¤äºä½ç¨ã

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

æè¦ï¼åå®å®çæ¦å¿µå¨ååé åé½ååéæ³¨ï¼å¶éè¦æç¨ä¹ä¸ä¾¿æ¯é«çä¿å¥ãåå®å®æå·¨å¤§çæ½åééæ¹è®çæ£ç§è­·ãé«å­¸æè²ï¼ä»¥åæå­¸/å­¸ç¿åç ç©¶çæ¹å¼ä¾è½åé«çä¿å¥ãæ¬ç ç©¶çç®çæ¯æä¾åå®å®åºæ¬æ¦å¿µååºç¤æè¡çä»ç´¹ãæ¬ææ¢è¨äºåå®å®å¨é«çä¿å¥èæ¯ä¸çåªç¼ºé»ï¼ä¸¦å¾æè¡å AI çè§åº¦åæå¶æ½åãç¹å¥æ¯ï¼è¨è«äºæ©å¨å­¸ç¿æ¹æ³çè§è²ï¼æåå°èªªæå¦ä½å°æ©å¨å­¸ç¿æ¼ç®æ³æç¨æ¼åå®å®ç¢ççè³æï¼ä»¥ç²å¾é«çä¿å¥æç¨æ¹é¢çæ´ä½³è¦è§£ãæ­¤å¤ï¼æåééæ¢è¨åå¡éç­æ°èæè¡ï¼ä¸¦è§£æ±ºé±ç§åé¡ï¼ä¾æ¢è¨åå®å®å¨é«çä¿å¥æ¹é¢çæªä¾é¡æ¯ãæ¬ç ç©¶çç¼ç¾æå©æ¼æ´æ·±å¥å°äºè§£åå®å®å¨é«çä¿å¥ä¸­çæç¨ï¼ä»¥åå¶å¨é«çæåæä¾æ¹é¢ç¼æ®é©å½æ§è®é©çæ½åã

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

æè¦ï¼æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®å»£æ³çæ¢æ§ç¾çï¼æ²æå·²ç¥çæçµçæ³ä¸ç¼ççå¾é«ãç ç©¶è¡¨æï¼é²è¡æ§æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®ç°è³ªæ§ç¾çï¼æé¡¯èå½±é¿èèçµæ§ååè½ï¼æçµå°è´èè¡°ç«­ãé¨èæéçæ¨ç§»ï¼æ¢æ§èèçå·²å¾å½±é¿å°æ¸äººçè´å½ç¾çè½è®çºä¸ç¨®å´éç¨åº¦ä¸åçå¸¸è¦ç¾çãæ¬ç ç©¶çç®æ¨æ¯ä½¿ç¨éæå­¸ç¿åå¯è§£éç AI é²è¡æ©æé å¾å CKD æª¢æ¸¬ï¼ä¸¦è¦è¦ºåä¸»å°ç¹å¾µãç¹å¾µåæ¸åè¡¨ç¾åºçå¼ãçºæ­¤ï¼æåºäºä¸ç¨® AI é©åçé æ¸¬åææ¹æ³ï¼ä»¥å¹«å©è¨åºé«ççºåå¥æ£èéå·çæ´»æ¹å¼ä¿®æ¹å»ºè­°ï¼ä»¥éä½éç¨®ç¾ççé²å±éåº¦ãæåçæ¸æéæ¯å¾ CKD æ£èåå¥åº·åè©¦èçèº«é«çå½é«å¾µä¸­æ¶éçï¼ä»¥æºç¢ºéç¼æåæåºç AI é©åçè§£æ±ºæ¹æ¡ãå¨éæ¹é¢ï¼æä¾äºè¡æ¶²åå°¿æ¶²æª¢æ¸¬çµæï¼ä¸¦æç¨åºæ¼éææ¨¹çæ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬æªç¼ç¾ç CKD çä¾ãæåçç ç©¶çµæç¶éèèèç§é«ççé·æè«®è©¢å¾å¾å°é©è­ãæåçå¯¦é©åè§£éçµæèåç¨®é«çä¿å¥é åä¸­ç¾æçå¯è§£é AI æç¨é²è¡äºæ¯è¼ï¼åæ¬ CKDãæ¯è¼è¡¨æï¼æåéç¼ç AI æ¨¡åï¼ç¹å¥æ¯é¨æ©æ£®ææ¨¡åï¼å·²ç¶ç¢ºå®äºæ¯ XgBoost æ´å¤ä½çºéè¦è²¢ç»èçç¹å¾µãå¯è§£éæ§ (I) è¡¡ééè¦ç¹å¾µèæ©èç¹å¾µçæ¯çï¼è¡¨ææåç XgBoost æ¨¡åå¨éåææ¨ä¸­ç²å¾äºæ´é«çåæ¸ï¼ç¹å¥æ¯ 98% çä¿çåº¦ï¼ä¸¦ä¸å¨ FII ææ¸ä¸­èªç¶é«æ¼ç«¶ç­æ¨¡åã

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

æè¦ï¼å¿çå¥åº·æ§æäºä¸é è¤éä¸æ®éçå¨çææ°ï¼å½±é¿äºæ¸ç¾è¬äººççæ´»ï¼ä¸¦ç¶å¸¸å°è´å´éçå¾æãå¨æ¬æä¸­ï¼æåé²è¡äºä¸é å¾¹åºçèª¿æ¥ï¼ä»¥æ¢ç´¢æ¸æç§å­¸ãäººå·¥æºæ§åå¿çä¿å¥çäº¤éï¼éé»éæ³¨ééç·ä¸ç¤¾äº¤åªé« (OSM) é²è¡å¿çç¾çæª¢æ¸¬çææ°ç¼å±ãå¾å¤§ä¸é¨åäººå£ç©æ¥µåè OSM å¹³å°ï¼åµé äºä¸åé¾å¤§çäººå¡è³æåº«ï¼å°å¿çå¥åº·åæå·æå·¨å¤§çæ½åãæ¬ææ¢è¨äºå³çµ±çè¨ºæ·æ¹æ³ãæåé²çè³æå AI é©åçç ç©¶ï¼ä»¥åå¿çä¿å¥ä¸­å¯è§£é AI (XAI) æ¨¡åçåºç¾ãæååé¡§äºæåé²çæ©å¨å­¸ç¿æ¹æ³ï¼ç¹å¥æ¯é£äºåºæ¼ç¾ä»£æ·±åº¦å­¸ç¿çæ¹æ³ï¼åæå¼·èª¿äºé«çä¿å¥ AI æ¨¡åä¸­å¯è§£éæ§çå¿è¦æ§ãå¯¦é©è¨­è¨é¨åæä¾äºå°æ®éåæ³çè¦è§£ï¼åæ¬å¯ç¨çè³æéåè©ä¼°æ¹æ³ãæåéæ¾åºè©²é åçä¸»è¦åé¡åææ°ï¼ä¸¦æåºäºæå¸æçæªä¾ç ç©¶æ¹åãç±æ¼å¿çå¥åº·æ±ºç­éè¦éæåº¦ãå¯è§£éæ§åéå¾·èéï¼æ¬ææå©æ¼æ¨é²å¿çä¿å¥ä¸­ééç¤¾äº¤åªé«æ¨é² XAI çæçºè¨è«ãéè£¡æåºçå¨é¢æ¦è¿°æ¨å¨å¼å°ç ç©¶äººå¡ãå¾æ¥­äººå¡åæ¿ç­å¶å®èç¼å±å¿çç¾çæª¢æ¸¬é åã

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

æè¦ï¼<paragraph>é«çç§è­·ä¸­éè¦ AI è¼å©çè¨åºè¨ºæ·ãç¾æçæ·±åº¦å­¸ç¿æ¨¡åç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸ä¸»è¦å°æ³¨æ¼å½±ååæãæè¿éç¼çåæä¸ç¢ºå®å æéä¿å (DUCG) æ¹æ³æ¯å æé©åçãå¯è§£éçï¼ä¸¦ä¸å¨ä¸åçæç¨å ´æ¯ä¸­æ¯ä¸è®çï¼æ²æè³ææ¶éãæ¨è¨ãæ¬åãé±ç§ãåè¦ãæ¦åãé«ææ¬åé«è½èçåé¡ãééè¨åºå°å®¶å DUCG æè¡äººå¡ä¹éçå¯ååä½ï¼æ§å»ºäºæ¶µè 54 åä¸»è¨´ç 46 å DUCG æ¨¡åãå¯ä»¥å¨æ²æåæµçææ³ä¸è¨ºæ·åº 1,000 å¤ç¨®ç¾çãå¨æç¨æ¼å¯¦éä¸çä¹åï¼46 å DUCG æ¨¡åå·²ç±ç¬¬ä¸æ¹é«é¢åæº¯æ§é©è­ãé©è­çè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 95%ï¼å¶ä¸­åæ¬ç½è¦ç¾çå¨å§çæ¯ç¨®ç¾ççè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 80%ãé©è­å¾ï¼46 å DUCG æ¨¡åå·²å¨ä¸­åå¯¦éæç¨ãå·²ç¶å·è¡äºè¶éä¸ç¾è¬åçå¯¦è¨ºæ·æ¡ä¾ï¼åç¼ç¾ 17 åä¸æ­£ç¢ºçè¨ºæ·ãç±æ¼ DUCG çéææ§ï¼ç¼ç¾ä¸¦ç³¾æ­£äºå°è´ä¸æ­£ç¢ºè¨ºæ·çé¯èª¤ãé »ç¹æç¨ DUCG çè¨åºé«ççè¨ºæ·è½åå¾å°äºé¡¯èæé«ãå¨ä»ç´¹äºåé¢æåºç DUCG æ¹æ³è«ä¹å¾ï¼æåºäºæ½å¨å¥åº·æª¢æ¥çæ¨è¦æ¼ç®æ³ï¼ä¸¦æåäº DUCG çééµææ³ã</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

æè¦ï¼ç²¾ç¢ºä¸åæå°åµæ¸¬ä¹³çå°æ¼æ¹åæ£èé å¾è³ééè¦ãè¨ºæ·æ¹æ³å³çµ±ä¸ä¾è³´æ¼å®ä¸æ¨¡å¼æ¹æ³ï¼ç¶èï¼é«çè³æåææ­£å¨æ´åè¶è¶å³çµ±å½±åçåç¨®è³æä¾æºãä½¿ç¨æ´åå½±ååéå½±åè³æçå¤æ¨¡å¼æè¡ï¼æ¨èªèä¹³çè¨ºæ·çè®é©æ§é²å±ãæ¬ç¯ç¶è¿°çç®çæ¯æ¢è¨å¤æ¨¡å¼æè¡çæ°èé åï¼ç¹å¥æ¯å°çµç¹ççå­¸å½±åèéå½±åè³æèåãæ­¤å¤ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°ç¨æ¼é¡æè¤éæ¼ç®æ³çæ±ºç­éç¨ï¼å¼·èª¿è¨ºæ·éç¨ä¸­å¯è§£éæ§çå¿è¦æ§ãæ¬ç¶è¿°å©ç¨å¤æ¨¡å¼è³æä¸¦å¼·èª¿å¯è§£éæ§ï¼ä»¥æé«è¨ºæ·æºç¢ºæ§ãè¨åºé«å¸«çä¿¡å¿åæ£èåèåº¦ï¼æçµä¿é²ä¹³çæ´åäººåçæ²»çç­ç¥ï¼åæä¹æ¾åºå¤æ¨¡å¼åå¯è§£éæ§çç ç©¶å·®è·ï¼å¼å°æªä¾çç ç©¶ï¼ä¸¦çºè©²é åçç­ç¥æ¹åååºè²¢ç»ã

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

æè¦ï¼èªæ³¨æåæ©å¶å·²è¢«æ¡ç¨æ¼å¤åå»£æ³ä½¿ç¨çè¨æ¯å³éç¥ç¶ç¶²è·¯ (MPNN)ï¼ä¾å¦ GATï¼ï¼å®å¯ä»¥èªé©æå°æ§å¶æ²¿èåºå±¤åå½¢éç·£æµåçè³è¨éãéç¨®æ³¨æåçä½¿ç¨ä½¿å¾æ­¤é¡æ¨¡åæçºå¯è§£é AI (XAI) ç ç©¶çåºç·ï¼å çºééæ³¨æåçè©®éå·²å¨åç¨®é åï¼ä¾å¦èªç¶èªè¨èçåé»è¦è¦è¦ºï¼ä¸­æ®åãç¶èï¼ç¾æçç ç©¶éå¸¸ä½¿ç¨å¤©ççè¨ç®æ¹æ³å¾æ³¨æåä¸­æ¨å°åºæ­¸å åæ¸ï¼ä¸¦ä¸æ²æèæ®å°éç·£æ­¸å çç²¾ç¢ºä¸ä»ç´°çè¨ç®ãå¨æåçç ç©¶ä¸­ï¼æåæ¨å¨å¡«è£æ³¨æååç¨ MPNN çå»£æ³ä½¿ç¨èå®åå¨å¾å¤§ç¨åº¦ä¸æªè¢«ååæ¢ç´¢çå¯è§£éæ§ä¹éçå·®è·ï¼éåä¸»é¡å·²å¨å¶ä»é åç©æ¥µç ç©¶ãçºæ­¤ï¼ä½çºç¬¬ä¸æ¬¡åè©¦ï¼æåå° GNN ä¸­æ³¨æåæ¬éçéç·£æ­¸å åé¡å½¢å¼åãç¶å¾ï¼æåæåº GATTï¼ä¸ç¨®å»ºç«å¨è¨ç®æ¨¹ä¸çéç·£æ­¸å è¨ç®æ¹æ³ãééå¨é¢çå¯¦é©ï¼æåå±ç¤ºäºæåæåºçæ¹æ³å¨è©ä¼° GAT çæ­¸å ææå·æçææãç¸åå°ï¼æåæç¶é©é©è­äºåå°åæ³¨æåå±¤ä¸çæ³¨æåæ¬éåå¹³åå¼ä¸è¶³ä»¥è©®é GAT æ¨¡åçè¡çºãç¨å¼ç¢¼å·²å¬éæ¼ https://github.com/jordan7186/GAtt/tree/mainã

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

æè¦ï¼æ°çåææ¯å¤§è¦ç¼è²æèå¼±çææï¼å®¹æåºç¾ç²çç¼ä½ãå¤§è¦ç¼è²ä¸æçæåºç¾ç²çç¼ä½æé æä¸è¯å¾æï¼å æ­¤éè¦åæ©è¨ºæ·ãç®åæ°çåç²çç¼ä½çé»éæ¨æºä¾è³´æ¼é£çºçè¦è¨è¦é»å (EEG) ç£æ¸¬ï¼å¶ä¸­åæ¬å¨æ°çåå è­·çæ¿ (NICU) å§åæé²è¡å¤é »éè¦é»å (EEG) è¨éåå³æè¦è¨ç£æ§ãç¶èï¼è¦è¨è¦é»åç£æ§æè¡éè¦è¨åºå°æ¥­ç¥è­ï¼èä¸éå¸¸åéæ¼æè¡åé²ä¸è³æºè±å¯çç°å¢ãå·ææ¬æççæ°æè¡å¯ä»¥å¹«å©é«ççæºç¢ºè¨ºæ·ä¸¦ç«å³æå¡æ²»çãå¨éé å·¥ä½ä¸­ï¼æåºäºä¸åæ°ç©çå¯è§£éæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥èªååæ°çåç²çç¼ä½åµæ¸¬éç¨ï¼ä¸¦æ¡ç¨æ¸å°çè¦é»åè£ç½®ï¼å¶ä¸­æ¡ç¨äºå·ç©ç¥ç¶ç¶²è·¯ãåå½¢æ³¨æåå±¤åå¨é£æ¥å±¤ãé¤äºè½å¤ ä½¿ç¨æ¸å°çè£ç½®å³æåµæ¸¬ç²çç¼ä½å¤ï¼æ­¤æ¨¡åéæä¾äºå³æå¯è§£éæ§çç¨ç¹åªå¢ãééå¨ Zenodo è³æéä¸ä½¿ç¨ 10 åäº¤åé©è­è©ä¼°æè½ï¼ææåºçæ¨¡åå¨æ²ç·ä¸é¢ç© (AUC) åå¬åçæ¹é¢åå¥éå°äº 8.31% å 42.86% ççµå°æ¹åã

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

æè¦ï¼ä¹³ç (BC) æ¯å½±é¿å¨çå¥³æ§æå¸¸è¦çæ¡æ§è«ç¤ä¹ä¸ï¼å æ­¤éè¦é²æ­¥çè¨ºæ·æ¹æ³ï¼ä»¥æ¹åè¨åºçµæãæ¬æå¨é¢æ¢è¨äºå¯è§£éäººå·¥æºæ§ (XAI) æè¡å¨ä¹³çåµæ¸¬åè¨ºæ·ä¸­çæç¨ãé¨èäººå·¥æºæ§ (AI) æè¡æçºæ»²éé«çä¿å¥é åï¼ç¹å¥æ¯å¨è«ç¤å­¸ä¸­ï¼éæä¸å¯è§£éçæ¨¡åéæ±è®å¾å¢å¨å¿è¡ï¼ä»¥å¢å¼·è¨åºæ±ºç­å¶å®åæ£èç§è­·ãæ­¤ç¯è©è«æ¢è¨äºåç¨® XAI æ¹æ³çæ´åï¼ä¾å¦ SHAPãLIMEãGrad-CAM ç­ï¼ä»¥åç¨æ¼ä¹³çåµæ¸¬ååé¡çæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åãééæ¢è¨ä¹³çè³æéçæ¨¡å¼ï¼åæ¬ä¹³æ¿æå½±ãè¶é³æ³¢åå¶å¨ AI ä¸­çèçï¼æ¬æéé»èªªæ XAI å¦ä½è½å°è´æ´æºç¢ºçè¨ºæ·ååäººåæ²»çè¨ç«ãå®ä¹æ¢è¨äºå¯¦æ½éäºæè¡çææ°ï¼ä»¥åå¶å®æ¨æºåè©éææ¨ä»¥è©ä¼° XAI å¨è¨åºç°å¢ä¸­çæææ§çéè¦æ§ãééè©³ç´°çåæåè¨è«ï¼æ¬ææ¨å¨å¼·èª¿ XAI å¨ç¸®å°è¤é AI æ¨¡åèå¯¦åé«çä¿å¥æç¨ä¹éå·®è·çæ½åï¼é²èä¿é²é«çå°æ¥­äººå¡ä¹éçä¿¡ä»»èçè§£ï¼ä¸¦æ¹åæ£èççµæã

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

æè¦ï¼èªé³æç·è¾¨è­ (SER) ç±æ¼å¶å¨å¿çå¥åº·ãæè²åäººæ©äºåç­å¤åæç¨é åèååéæ³¨ãç¶èï¼SER ç³»çµ±çæºç¢ºæ§åå°é«ç¶­ç¹å¾µéçé»ç¤ï¼éäºç¹å¾µéå¯è½åå«ä¸ç¸éååé¤çè³è¨ãçºäºåæéåææ°ï¼æ¬ç ç©¶æåºäºä¸ç¨®ç¨æ¼ SER çè¿­ä»£ç¹å¾µæåæ¹æ³ï¼è©²æ¹æ³å¼·èª¿ç¹å¾µç¸éæ§åå¯è§£éæ§ï¼ä»¥å¢å¼·æ©å¨å­¸ç¿æ¨¡åçæè½ãæåçåæ³æ¶åä»ç´°çç¹å¾µé¸æååæï¼ä»¥å»ºç«é«æç SER ç³»çµ±ãçºäºééæ¨¡åå¯è§£éæ§è§£æ±ºæåçæ ¸å¿åé¡ï¼æåæ¡ç¨äºå·æ Shapley å¼çç¹å¾µè©ä¼°è¿´åï¼ä»¥åè¦æ¹åç¹å¾µéãéåéç¨å¨æ¨¡åæè½åéæåº¦ä¹éåå¾å¹³è¡¡ï¼éä½¿å¾æåè½å¤ å¨é¢äºè§£æ¨¡åçé æ¸¬ãææåºçæ¹æ³æä¾äºå¤é åªé»ï¼åæ¬è­å¥åç§»é¤ä¸ç¸éååé¤çç¹å¾µï¼å¾èå»ºç«æ´ææçæ¨¡åãæ­¤å¤ï¼å®ä¿é²äºå¯è§£éæ§ï¼æå©æ¼çè§£æ¨¡åçé æ¸¬ä»¥åè­å¥æç·æ±ºå®çééµç¹å¾µãææåºçæ¹æ³çæææ§å·²å¨å¤å«å¤æç·èªé³é (TESS)ãæææç·èªé³è³æåº« (EMO-DB)ãè³´ç¾æ£®é³è¨è¦è¦ºæç·èªé³åæ­æ²è³æåº« (RAVDESS) åè©éé³è¨è¦è¦ºè¡¨éæç· (SAVEE) è³æéç SER åºæºä¸å¾å°é©è­ï¼å¶æè½åªæ¼ç¾ææ¹æ³ãææåæç¥ï¼éæ¯ç¬¬ä¸åå°æ¨¡åå¯è§£éæ§ç´å¥ SER æ¶æ§çç ç©¶ãæ¬æçåå§ç¢¼å¯ééæ­¤é£çµå¬éåå¾ï¼https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognitionã

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, HÃ©loÃ¯se de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

æè¦ï¼å¯è§£éæ§éå¸¸å¯¹äºäººå·¥æºè½ (AI) çå¯æ¥åå®æ½è³å³éè¦ãå¨å»çä¿å¥é¢åï¼è¿ä¸ç¹å°¤ä¸ºéè¦ï¼å ä¸ºå³ç­ç´æ¥å½±åæ£èï¼å¹¶ä¸å¯¹ AI ç³»ç»çä¿¡ä»»è³å³éè¦ãè¿ç§ä¿¡ä»»éå¸¸å»ºç«å¨ AI æä¾çè§£éåè¯ éä¹ä¸ãå°½ç®¡ AI å¯è§£éæ§åå¾äºéå¤§è¿å±ï¼ä½ä»ç¶éè¦æç¡®çæå¯¼æ¹éï¼è¯´æå¨å»çç¯å¢ä¸­ä½æ¶ä»¥åå¨å¤å¤§ç¨åº¦ä¸éè¦è§£éãæä»¬æåºäºä¸ç§æ°é¢çåç±»ç³»ç»ï¼è¯¥ç³»ç»å·æåç§ä¸åçè§£éå¿è¦æ§ç±»å«ï¼æå¯¼æéçè§£éçº§å«ï¼æ£èææ ·æ¬ï¼å±é¨ï¼çº§å«ãéåææ°æ®éï¼å¨å±ï¼çº§å«ï¼æä¸¤ä¸ªçº§å«ãæä»¬å¼å¥äºä¸ä¸ªæ°å­¦å¬å¼ï¼è¯¥å¬å¼åºåäºè¿äºç±»å«ï¼å¹¶ä¸ºç ç©¶äººåæä¾äºä¸ä¸ªå®ç¨æ¡æ¶ï¼ä»¥ç¡®å®å»ç AI åºç¨ä¸­æéçè§£éçå¿è¦æ§åæ·±åº¦ãèèäºä¸ä¸ªå³é®å ç´ ï¼è¯ä¼°åè®®çç¨³å¥æ§ãä¸å®¶è§å¯çå¯åæ§ä»¥ååºç¨ç¨åºçè¡¨ç¤ºç»´æ°ãä»è¿ä¸ªè§åº¦æ¥çï¼æä»¬è§£å³äºè¿ä¸ªé®é¢ï¼AI å»çåºç¨ä½æ¶éè¦è§£éï¼ä»¥åéè¦è§£éå°ä½ç§ç¨åº¦ï¼

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

æè¦ï¼äººå·¥æºæ§ (AI) é åæ­£å¿«éå½±é¿èå¥åº·èé«çä¿å¥ï¼ä½å°æ¼é¢è¨å»£æ³çµæ§æ§å£è¿«çäººç¾¤ä¾èªªï¼åè¦åä¸è¯è¡¨ç¾ä¾ç¶å­å¨ãååçç ç©¶å·²æ¸æ¥èªªæï¼éè¦æ´å´æ ¼å°æ³¨æè³æä»£è¡¨æ§åæ¨¡åæè½ï¼ä»¥ä¿é²å¬å¹³æ§ä¸¦æ¸å°åè¦ãç¶èï¼æåææ©æéééç¨ç¤¾ææµè¡çå­¸åå¥åº·å¬å¹³çæä½³å¯¦åï¼ä¾æ¹å AI çå¯è§£éæ§ï¼ä»¥å¹«å©æåéå°ç¼ç¾çéè¯æ§ï¼ç¼å±åè¨­ãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼å¯è§£é AI (XAI)ï¼ä¸¦æè¿°ä¸åè·¨é åå°å®¶å°çµå¯©æ¥æ¶æ§ï¼ä»¥å¾å¤éè§é»è¨è«åæ¹å¤æ§è©ä¼° AI æ¨¡åçè§£éï¼ä¸¦æ¾åºåè¦é ååæªä¾ç ç©¶çæ¹åãæåå¼·èª¿è·¨é åå°å®¶å°çµå°æ¼ç¢çæ´æºç¢ºãå¬å¹³çè©®éè³ééè¦ï¼èéäºè©®éæ¯æ ¹ææ­·å²åèçµ¡èä¾çãè·¨é åå°çµè¨è«æå©æ¼æ¸å°åè¦ãæ¾åºæ½å¨çæ··æ·å ç´ ï¼ä¸¦å¨æç»ä¸­æç¼ºå£ææ¾åºé¡å¤ç ç©¶çæ©æãåéä¾ï¼éäºè¦è§£å¯ä»¥å»ºè­° AI æ¨¡åæ¹é²çæ©æã

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. ZajÄc, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨å¯¦é©å®¤å¯¦é©ä¸­ä¸æ·å°èæ¾å°ç§é«å¸«å¹æµæè¡¨ç¾å¾æ´åºè²ãç¶èï¼ç¼ç¾æ¾å°ç§ AI çºåºç¤ç³»çµ±çå¯¦éå·è¡å¹¾ä¹æ²ææä¾è¨åºå¹å¼ãæ¬ææ¢è¨å¦ä½çº AI è¨­è¨å¨ä¸åæå¢ä¸­è¨åºä¸çæç¨ãæåæ ¹æåè½æ§ AI çºåºç¤ååçä¸æ¬¡è¿­ä»£ï¼å¨ä¸¹éº¥åè¯äºç 7 åè¨åºå ´åè 13 ä½æ¾å°ç§é«å¸«é²è¡äº 19 æ¬¡è¨­è¨æè­°åè¨­è¨ä»å¥ãååç¤¾ææè¡ä¾è³´éä¿è¢«èªçºå°æ¼æ¾å°ç§ä¸­ AI çè¨­è¨è³ééè¦ãæåæ¦å¿µåäºååæè¡é¢åï¼å¿é æ ¹æé æçè¨åºä½¿ç¨æå¢é²è¡è¨­å®ï¼AI åè½ãAI é«çéé»ãAI æ±ºç­éæª»ï¼ä»¥å AI å¯è§£éæ§ãæåæåºåé è¨­è¨å»ºè­°ï¼èªªæå¦ä½èçèé«çç¥è­ãè¨ºæé¡åãä½¿ç¨èå°æ¥­ç¥è­ç­ç´ãæ£èæå¢ï¼ä»¥åå½±é¿éäºæè¡é¢åè¨­å®çä½¿ç¨èæå¢ç¸éçä¾è³´éä¿ã

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

æè¦ï¼é¨èåé²ç AI/MLï¼å°å¯è§£é AI (XAI) çç ç©¶ä¸æ·å¢å ï¼ä»¥åéæ¼äººé¡å¦ä½è AI å XAI äºåä»¥é²è¡ææçäººå·¥æºæ§åä½æ±ºç­å¶å®ãç¶èï¼æåä»ç¶ç¼ºä¹å° AI ç³»çµ±å XAI æå¦ä½é¦ååç¾çµ¦æ²ææè¡èæ¯çç¨æ¶çäºè§£ãå¨æ¬æä¸­ï¼æåå±ç¤ºäºèé«çå°æ¥­äººå¡ (n=12) åä¸»ä¿®é«å­¸åå¥åº·çå­¸ç (n=4) é²è¡åçµæ§åè¨ªè«ççµæï¼ä»¥ç ç©¶å¦ä½æ¹å AI å XAI çå¥éãå°æ¼è¨ªè«ï¼æåå»ºç«å¨äººæ©äºåæºåä¹ä¸ï¼çºä¸­é¢¨åº·å¾©è©ä¼°å AI è§£éç AI ç³»çµ±åµå»ºå¥éææï¼ä¸¦å°å®åä»ç´¹çµ¦åèèãæåçç ç©¶çµæè¡¨æï¼é¤äºåç¾å³çµ±ç AI æ§è½ææ¨å¤ï¼åèèéå¸æåºåä¿¡æ¯ãAI çå¯¦éå¥½èä»¥åäº¤äºè©¦é©ï¼ä»¥æ´å¥½å°å° AI æ§è½æå¢åï¼ä¸¦å®å AI çç®æ¨åæ§è½ãæ ¹æéäºç¼ç¾ï¼æåå¼·èª¿äºæ¹é² AI å XAI ä»¥åäººæ©åä½æ±ºç­å¶å®çå¥éæ¹åã

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

æè¦ï¼æ¬æä½¿ç¨æ©å¨å­¸ç¿ (ML) åå¯è§£éäººå·¥æºæ§ (XAI) æè¡ä¾æ¢è¨çé¤çæ³èé¿è²æµ·é»ç (AD) ç¸éçæ­»äº¡çä¹éçéä¿ãæ¡ç¨ç¬¬ä¸æ¬¡å¨åå¥åº·èçé¤æª¢æ¥èª¿æ¥ (NHANES III) è³æåº«é²è¡åæãé¸æé¨æ©æ£®ææ¨¡åä½çº XAI åæçåºç¤æ¨¡åï¼ä¸¦ä½¿ç¨ Shapley Additive Explanations (SHAP) æ¹æ³ä¾è©ä¼°ç¹å¾µéè¦æ§ãçµæçªé¡¯äºéè¦ççé¤å ç´ ï¼ä¾å¦è¡æ¸ç¶­çç´  B12 åç³åè¡ç´èç½ãè©²ç ç©¶è­æäºé¨æ©æ£®æå¨é æ¸¬ AD æ­»äº¡çæ¹é¢ç¸è¼æ¼å¶ä»ç¾ççæææ§ãæ¬ç ç©¶æä¾äºçé¤å° AD çå½±é¿çè¦è§£ï¼ä¸¦æå©æ¼æ´æ·±å¥å°äºè§£ç¾ççé²å±ã

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

æè¦ï¼<paragraph>åç´ä¿å¥æä¾èå°æ¼æåçåæµåè½è¨ºå°å°ç§ç§è­·è³ééè¦ãå¨éåç¼çææ³ä¸ï¼ç¡ççä¸å¿«éæ¡åå¯è½å°è´è¦ååªå¤±ï¼å æ­¤éè¦åæè½è¨ºçµ¦å°å®¶ãç¶èï¼åç´ç¼ç§ä¿å¥æä¾èå¯è½ç¡æ³è­å¥ç·æ¥ææ³ï¼å¯è½æå»¶èª¤ç§è­·ãæä¾è§£éçäººå·¥æºæ§ (AI) å¯ä»¥å å¼·ä»åçè½è¨ºæ±ºç­ãæåç ç©¶åç¨® AI è§£éå¦ä½å¹«å©æä¾èååéè¦ç«å³æéç·æ¥å°ç§è½è¨ºçæ£èãæåå»ºç«äºè§£éæ§ AI æ¼ç®æ³ï¼ä»¥å¾ä¾è¡ç¼ç§è­·çè³æé æ¸¬éåç¼æè¡éæ±ï¼ä½çºè­å¥é«é¢¨éªæ£èçä»£çãæåç´å¥äºå§å¨åäºå¾è§£éæ§ï¼ä¸¦èé©åå¸«é²è¡äºä¸é ç·ä¸ç ç©¶ï¼ä»¥è©ä¼°äººæ©åéçè¡¨ç¾ï¼è¡¡éè½è¨ºæºç¢ºåº¦ä¸¦åæè AI çäºåï¼åæ¬åæçãä»»åæéåä½¿ç¨èé«é©æç¥ãå¨ 87 ååèèä¸­ï¼AI æ¯æ´æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½¿ç¨ AI/æªä½¿ç¨çæ¯ä¾çº 59.9%/50.8%ï¼ï¼åç®¡äººæ©åéçè¡¨ç¾ä¸å¦å®ç¨ä½¿ç¨ AIãåèèèªçºä»åå¨ä½¿ç¨å§å¨æ¨¡åææ´å¤å°ç´å¥äº AI å»ºè­°ï¼ä¸¦èªçºå®æ´æç¨ä¸æ´æå¸æãæ²æè§£éï¼AI å»ºè­°çåå·®æå¢å ãAI æ¯æ´ä¸¦æªå¢å å·¥ä½éãä¿¡å¿åä¿¡ä»»ï¼ä½æ¸å°äºææ°ãå¨ä¸åå®ç¨çæ¸¬è©¦éä¸­ï¼æåçé»çå­åå§å¨æ¨¡åå¨é æ¸¬æè¡çµææ¹é¢åå¥éå°äº 77% å 71% çæºç¢ºåº¦ãæåæ¾åºå¨åç´ç¼ç§ä¿å¥ä¸­ï¼äººæ©åéåä½ç®¡çéåç¼çæ©æï¼ä¸¦æ³¨æå°éç¶ AI æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½å³ä½¿æè§£éï¼å®ä¹é¡¯ç¤ºåºèå®ç¨ä½¿ç¨ AI ç¸æ¯çæè½å·®è·ãäººé¡åèå¨é«çæ±ºç­ä¸­ä»ç¶è³ééè¦ï¼éå¼·èª¿äºæªä¾ç ç©¶åªååä½ãç¢ºä¿æ­£é¢ç¶é©åå®å¨ä½¿ç¨ AI çå¿è¦æ§ã</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

æè¦ï¼å¨é«å­¸å½±åä¸­ï¼ç¹å¥æ¯å¨æ©æç¾çæª¢æ¸¬åé å¾ä»»åä¸­ï¼è¾¨å¥ AI æ¨¡åé æ¸¬èå¾çåçå°æ¼è©ä¼°å¶æ±ºç­çå¯é æ§è³ééè¦ãå³çµ±çè§£éæ¹æ³å¨è­å¥é«å­¸å½±ååé¡ä¸­å¯è­å¥çæ±ºå®æ§ç¹å¾µæé¢è¨ææ°ï¼å¶ä¸­åå¥æ§ç¹å¾µå¾å¾®å¦æä¸¦ä¸æé¡¯ãçºäºå½åéä¸å·®è·ï¼æåæåºäºä¸åå¯è§£éçæ¨¡åï¼è©²æ¨¡åå·åæ±ºç­æ¨çåç¹å¾µè­å¥è½åãæåçåæ³ä¸åæª¢æ¸¬æå½±é¿åçå½±åæ¨¡å¼ï¼éæ­ç¤ºäºæ¨åæ¨¡åæçµé æ¸¬çæ±ºå®æ§ç¹å¾µãééå¯¦æ½æåçæ¨¡åï¼æåå¯ä»¥ææè­å¥åè¦è¦ºåç±æ¸æé©åæ¨¡åå©ç¨çé¡ç¹å®ç¹å¾µï¼å¾èæ·±å¥äºè§£æ·±åº¦å­¸ç¿æ¨¡åçæ±ºç­éç¨ãæåå¨è¦æ±å´æ ¼çé«å­¸é å¾ä»»åé åé©è­äºæåçæ¨¡åï¼å±ç¤ºäºå¶å¨æé« AI å¨é«çä¿å¥ä¸­çå¯é æ§åç¼ç¾é å¾çè§£åéç¾ççæ°ç¥è­æ¹é¢çåæåæ½åã

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

æè¦ï¼æ¬ç ç©¶æ¢è¨ç·ä¸å¥åº·ç¤¾ç¾¤ä¸­å°æ±è³è¨æ¯æçåé¡ãåæï¼ä»¥åæå¹«å©çè©åä¹éçéä¿ãæåå»ºç«äºä¸çµæ¨è¨çåç­éå°è³æéï¼ä¸¦éç¼äºå¤æ¨¡ææ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥å¯é å°é æ¸¬è³è¨æ¯æåé¡ååæãæåæ¡ç¨å¯è§£éç AI ä¾æ­ç¤ºè³è¨æ¯æäº¤æµä¸­èå«çæç·ï¼è­ææç·å¨æä¾è³è¨æ¯æä¸­çéè¦æ§ãéç¨®æç·æ¯æåè³è¨æ¯æä¹éçè¤éäº¤äºä½ç¨ä»¥åä¸¦æªè¢«ç ç©¶éãæ¬ç ç©¶æ¹é²äºç¤¾ææ¯æçè«ï¼ä¸¦çºä½¿ç¨èæ±ºç­è¼å©å·¥å·çéç¼å¥ å®äºåºç¤ãè¨è«äºé²ä¸æ­¥çå½±é¿ã

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

æè¦ï¼å¨ç§æé£éç¼å±çæä»£ï¼ä¸ä½æå¤çè¨ªå®¢å·²å¨å¨çæå®¤ä¸­ä½æä¸å¸­ä¹å°ï¼é£å°±æ¯äººå·¥æºæ§ãçæå¼ AIï¼ä¾å¦ ChatGPTï¼æ¿è«¾å¨æè²é åæèµ·ä¸å ´é©å½ï¼ä½å®å»æ¯ä¸æéé¢åãå®å¨åäººåå­¸ç¿æ¹é¢çæ½åï¼å»å ä½å¼ãä¸æºç¢ºä»¥åæè²å·¥ä½èé£ä»¥å°å¶ææèå¥æå­¸è¨­è¨ç­åé¡èæµé·ãæåæ­£ç«å¨éæè²åæ²¿çéç·£ï¼é¡¯ç¶æåéè¦éå¸¸å°å¿å°æ¢ç´¢éçé åãéæ¯ä¸åéå¤§çææ°ï¼å¯è½ææå®³æåæè²éç¨çå®æ´æ§åå¹å¼ãé£éº¼ï¼æåå¦ä½å°éäºææ°è½åçºæ©éï¼ç¶ä¸é©ç¶å°ä½¿ç¨æï¼AI å·¥å·å¯è½ææçºè¤è£½è²¼ä¸å¿æçå®ç¾å·¥å·ï¼ä¸¦è¿éèèæ¹å¤æ§æç¶­ãåµé ååæ·±å¥çè§£ï¼éäºé½æ¯æåå¿«éè®åçä¸çä¸­æéè¦çæè½ãæå¸«åè¦ºå¾ä»åæ²æè½åå©ç¨éé æè¡ï¼éæ´å¤§äºæè²å·¥ä½èåæ©æ§ä¹éçæ¸ä½é´»æºãè§£æ±ºéäºåé¡éè¦æ·±å¥çç ç©¶æ¹æ³ãæåå°æ¡ç¨å¯¦è­ç ç©¶ï¼åéæè¡æ¥åæ¨¡åï¼ä¾è©ä¼°æè²å·¥ä½èåå­¸çå°çæå¼ AI çæåº¦ãäºè§£ä»åççæ³ãä½¿ç¨æ¨¡å¼åéç¤æ¯åµé ææè§£æ±ºæ¹æ¡çç¬¬ä¸åééµæ­¥é©ãæ¬ç ç©¶å°ä½çºæªä¾ç ç©¶äººå¡æç¨çæµç¨æåï¼æ ¹ææ­¤èèªªæçæ­¥é©éè¡ä»åèªå·±çæ¸æ

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike GrÃ¼ne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, AndrÃ© Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

æè¦ï¼é¨èé«çä¿å¥ç³»çµ±çæ¸ä½åï¼äººå·¥æºæ§å¨é«å­¸é åä¸­è®å¾æ´å æ®åãç¹å¥æ¯æ©å¨å­¸ç¿å¨æéåºååé¡ç­è¤éä»»åä¸­å±ç¾åºæ¥µå¤§çæ½åï¼ä½éå¸¸æ¯ä»¥éæåº¦åå¯çè§£æ§çºä»£å¹ãéå°è´äººé¡ç¼ºä¹ä¿¡ä»»ï¼å¾èé»ç¤äºå¶ç©æ¥µä½¿ç¨ãå¯è§£éçäººå·¥æºæ§è©¦åééæä¾å°æ±ºç­éç¨çæ´å¯ä¾å½è£éä¸å·®è·ï¼ä½å¶ä¸åæ¹æ³çå¯¦éæç¨å°ä¸æ¸æ¥ãæ¬ææåºäºä¸ååºæ¼ä½¿ç¨èç ç©¶çè©ä¼°ï¼å¶ä¸­åå«äº Grad-CAM è§£éæ¹æ³ï¼ä¸¦å°å¶æç¨æ¼ç¥ç¶ç¶²è·¯ä»¥åé¡æéåºåæ°çåå¼å¸æ¸æä¸­çå¼å¸ãæåå±ç¤ºäºä¸åå©çç¸éèå°å¯è§£éæ§æ¹æ³çæç¥æç¨ï¼æ­ç¤ºäºå¯¦ç¾å¯¦ééæåº¦çé£åº¦ï¼ä»¥åè¨±å¤åèèå¸æç²å¾æ´æ·±å¥çè§£éã

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) èé«çè¨ºæ·æ´å
çºè¨åºæ±ºç­æä¾äºä¸åæåæ¯çéå¾ãæ¬ç ç©¶æ¦è¿°äºä¸ç¨®æ°ç©æ¹æ³çéç¼ï¼ç¨æ¼é¶æ¬¡å­¸ç¿/å°éå­¸ç¿æå¢å­¸ç¿ (ICL)ï¼æ¹æ³æ¯ä½¿ç¨å¤å±¤çµæ§åæç¤ºæ´åé«çé åç¥è­ãæåéæ¢è¨äºä½¿ç¨èè LLM ä¹éå©ç¨®æºéæ¹å¼çåæï¼æ¸å¼å°è©± (NC) æ¹å¼ï¼å®æéæ­¥èçè³æï¼ä»¥åèªç¶èªè¨å®åå (NL-ST) æ¹å¼ï¼å®æä½¿ç¨é·ç¯æäºæç¤ºã
æåçç ç©¶ç³»çµ±æ§å°è©ä¼°äºè¨ºæ·æºç¢ºæ§åé¢¨éªå å­ï¼åæ¬æ§å¥åè¦ååé°æ§çï¼ä½¿ç¨äºä¸ååå« 920 åæ£èè¨éçè³æéï¼æ¡ç¨åç¨®å°éå­¸ç¿æå¢ãçµæè¡¨æï¼å³çµ±çè¨åºæ©å¨å­¸ç¿ (ML) æ¨¡åéå¸¸å¨é¶æ¬¡å­¸ç¿åå°éå­¸ç¿è¨­å®ä¸­è¡¨ç¾åªæ¼ LLMãç¶èï¼ç¶ä½¿ç¨å°éå­¸ç¿ç¯ä¾ä»¥åææçå¯è§£é AI (XAI) æ¹æ³ä½çºé åç¥è­ä¾æºæï¼æè½å·®è·æé¡¯èç¸®å°ãæ­¤å¤ï¼é¨èæéåè¶³åç¯ä¾æ¸éå¢å ï¼å°è©±æ¹å¼ (NC) å¹¾ä¹å¯ä»¥åª²ç¾ ML æ¨¡åçæè½ãæå¼å¾æ³¨æçæ¯ï¼LLM ç¸å°æ¼ ML æ¨¡åå±ç¾åºç¸ç¶ææ´ä½³çææ¬æææºç¢ºåº¦ã
æ¬ç ç©¶è­å¯¦ï¼ééé©ç¶çé åç¥è­åéèº«æé çæºéç­ç¥ï¼LLM å¯ä»¥é¡¯èå¢å¼·è¨ºæ·ç¨åºãéäºç¼ç¾çªé¡¯äºæä½³åè¨ç·´ç¯ä¾æ¸éåæºéæ¹å¼çéè¦æ§ï¼ä»¥æé«æºç¢ºåº¦ä¸¦æ¸å° LLM æç¨ä¸­çåå·®ã

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel MirÃ³-Nicolau, Gabriel MoyÃ -Alcover, Antoni Jaume-i-CapÃ³, Manuel GonzÃ¡lez-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

æè¦ï¼é¨èå°æ·±åº¦å­¸ç¿æ¨¡åä¾è³´æ§çå¢å ï¼å ä¸å¶åºæçéæåº¦ä¸è¶³ï¼ä¿ä½¿ä¸åæ°çç ç©¶é åç¼å±ï¼ç¨±çºå¯è§£é AI (XAI) æ¹æ³ãéäºæ¹æ³æ¨å¨ééæ·±å¥äºè§£æ±ºç­èå¾çåçï¼ä¾æåæçµä½¿ç¨èå°èªååç³»çµ±çä¿¡è³´ãæ¬ææåºäºä¸ç¨®è¡¡éä½¿ç¨èå° XAI ç³»çµ±ä¿¡è³´åº¦çæ°ç©æ¹æ³ï¼åè¨±å°å¶é²è¡æ¹é²ãæåæåºçææ¨çµåäºå®¢è§è§é»ä¸çæè½ææ¨åä¿¡è³´ææ¨ãçºäºé©è­éåæ°ç©çæ¹æ³ï¼æåå¨ä¸åçå¯¦çé«çå ´æ¯ä¸­é²è¡äºä¸åæ¡ä¾ç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±å¾ X åå½±åä¸­åµæ¸¬èºçã

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

æè¦ï¼COVID-19 ç«æå°å¨çå¬å±è¡çé æå£åï¼å¿é é²è¡æºç¢ºçè¨ºæ·åå¹²é ï¼ä»¥æ§å¶ç¾çå³æ­ä¸¦éä½æ­»äº¡çãæ¬æä»ç´¹äºä¸åå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åï¼å°éè¨­è¨ç¨æ¼ééè¸é¨ X å (CXR) å½±åæ¹åå° COVID-19 é å¾ççè§£åä¿¡è³´ãééæ´åå¤§è¦æ¨¡é è¨ç·´å½±åç·¨ç¢¼å¨ãé¢¨éªç¹å® Grad-CAM åè§£ååååµæ¸¬æè¡ï¼æåçåæ³ç¢çååå¯è§£éççµæï¼ææææå¿è¦çç¾çç¹å¾µï¼åæå°æ³¨æ¼ç½è¦ä½ééµçç°å¸¸ååãæåçæ¨¡åé æ¸¬çµæééé¢¨éªååå®ä½æä¾å¢å¼·çæ¸æ°åº¦åéæåº¦ï¼è®è¨åºé«çè½å¤ å¨æ´äºè§£é å¾è¦è§£çææ³ä¸ï¼å°± COVID-19 è¨ºæ·ååºææºçæ±ºç­ãæåå¨å¤ä¸­å¿çå­è³æéä¸è©ä¼°ææåºçæ¹æ³ï¼ä¸¦éééååè³ªåè©ä¼°è­æå¶æææ§ï¼éå°åªç°ç C ææ¸ï¼0.764 å 0.727ï¼åæéç¸é AUCï¼0.799 å 0.691ï¼ãéäºçµæè¡¨æï¼æåå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åå¨é¢¨éªé æ¸¬æ¹é¢è¶è¶å³çµ±ççå­åææ¹æ³ï¼æåè¨åºæ±ºç­çè§£éæ§ï¼ä¸¦å¢å¼· AI ç³»çµ±çä¿¡è³´åº¦ã

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

æè¦ï¼<paragraph>å¨éå»å¹¾å¹´ï¼è¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS) ä¸­çäººå·¥æºæ§ (AI) å¨å©ç¨æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¶æ§æ¹é¢ç¼æ®äºééµä½ç¨ãåç®¡ AI æ¨¡åå·æä»¤äººæ»¿æçè½åï¼ä½ç¼ºä¹éæåº¦åå¯è§£éæ§ï¼ç¹å¥æ¯å¨å¯é æ§çºå¿è¦èéçé«çèæ¯ä¸ï¼éå¸¶ä¾äºéå¤§çææ°ãå¨ä¸å½±é¿é æ¸¬ç²¾æºåº¦çææ³ä¸å¯¦ç¾éæåº¦ä»ç¶æ¯ä¸é ééµææ°ãæ¬ææåºäºä¸ç¨®æ°æ¹æ³ï¼å³ Rad4XCNNï¼ä»¥å¢å¼· CNN è¡çç¹å¾µçé æ¸¬è½åï¼åæå·åæ¾å°ç¹å¾µåºæçå¯è§£éæ§ãRad4XCNN ä¸åæ¼åºæ¼é¡¯èæ§åçå³çµ±æ¹æ³ï¼å®ééæ¾å°çµå­¸å°å¯çè§£çå«ç¾©è CNN è¡çç¹å¾µéè¯èµ·ä¾ï¼çºè¶è¶è¦è¦ºååè¡¨çè§£éæ¹æ³æä¾äºæ°çè§é»ãæåä»¥ä¹³çåé¡ä»»åä½çºæ¡ä¾ç ç©¶ï¼å¨è¶é³æ³¢å½±åè³æéä¸è©ä¼° Rad4XCNNï¼åæ¬ä¸åç·ä¸è³æéåå©åç¨æ¼å§é¨åå¤é¨é©è­çå§é¨è³æéãä¸äºééµçµæå¦ä¸ï¼i) è ViT è¡çç¹å¾µåæ¾å°ç¹å¾µç¸æ¯ï¼CNN è¡çç¹å¾µä¿è­äºæ´ç©©å¥çæºç¢ºåº¦ï¼ii) å³çµ±çè¦è¦ºååè§£éæ¹æ³å­å¨ä¸äºç¼ºé·ï¼iii) Rad4XCNN æ²æç§ç²æ¨¡åæºç¢ºåº¦ä¾æåå¶å¯è§£éæ§ï¼iv) Rad4XCNN æä¾äºå¨å±è§£éè¦è§£ï¼ä½¿é«å¸«è½å¤ åææ¨¡åè¼¸åºåç¼ç¾ãæ­¤å¤ï¼æåå¼·èª¿å°å¯è§£éæ§æ´åå° AI æ¨¡åä¸­å°æ¼å¢å¼·è¨åºå¯¦åä¸­çä¿¡ä»»åæ¡ç¨è³ééè¦ï¼ä¸¦å¼·èª¿äºæåçæ¹æ³å¦ä½è½ç·©è§£èå¯è§£é AI æ¹æ³ç¸éçä¸äºçæ®ã</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) çæ®åæ´åï¼å¨æ¶å AI é©åç³»çµ±çäºæä¸­ï¼è²¬ä»»åç¾©åæ­¸å±¬ç¢çäºè¤éçææ°ãéäºç³»çµ±çäºé£æ§ãAI å¼ç¼äºæçå«çåé¡ï¼å ä¸ AI æè¡çä¸ç¢ºå®æ§åç¼ºä¹ç¸ææ³è¦ï¼ä½¿å¾å³çµ±è²¬ä»»æ­¸å±¬é¢è¨ææ°ãçºæ­¤ï¼æ¬ç ç©¶æåºäºä¸ç¨®è¨ç®åæåè¡¡ (CRE) æ¹æ³ï¼ä»¥å»ºç«ä¸åé£è²«ä¸å¨å«çä¸å¯æ¥åçè²¬ä»»æ­¸å±¬æ¶æ§ï¼é©ç¨æ¼ææå©å®³éä¿äººãè¨ç®æ¹æ³æä¾äºçµæ§åçåæï¼åæäºæ¦å¿µæ¹æ³å¨èçåæä¸å¤é¢åæå¢æçéå¶ï¼å±ç¤ºäºè©²æ¶æ§å¨è²¬ä»»æ­¸å±¬éç¨ä¸­å·åçå¯è§£éæ§ãé£è²«æ§åé©ææ§ãæåæ¢è¨äºèåè¡¡è¨ç®ä¸­ç´¢è³ ç¸éçåå§ååå±¤ç´çééµä½ç¨ãæåä»¥ AI è¼å©é«çæ±ºç­æ¯æ´ç³»çµ±çºæ¡ä¾ç ç©¶ï¼èªªæä¸åçåå§åå¦ä½å°è´ä¸åçè²¬ä»»åéãè©²æ¶æ§æä¾äºå° AI å¼ç¼äºæä¸­åè²¬å¶çå¯¶è²´è¦è§£ï¼ééæçºç£æ§ãä¿®è¨ååæï¼ä¿é²äºæ°¸çºä¸æéæ§çç³»çµ±ç¼å±ã

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

æè¦ï¼äººå·¥æºæ§ééé æ¸¬æ¨¡ååå©é«çå°æ¥­äººå¡ï¼å¤§å¹è½è®äºè¨åºæ±ºç­å¶å®ãæ¬ç ç©¶æ¢è¨äºå¨é«çä¿å¥ä¸­ä½¿ç¨äººå·¥æºæ§æç¨ç¨å¼æå¬å¹³æ§åå¯è§£éæ§çééµéæ±ï¼ä»¥ç¢ºä¿å¨ä¸åçæ£èäººå£çµ±è¨è³æä¸­ç²å¾å¬å¹³ççµæãééå°æ³¨æ¼æè¡çç¸éæ­»äº¡ççé æ¸¬æ¨¡åï¼æåæåºäºä¸ç¨®æ¹æ³ï¼è©²æ¹æ³æå­¸ç¿ä¸åæè½æä½³åçé æ¸¬æ¨¡åï¼ç¶å¾æ¡ç¨è½ç§»å­¸ç¿éç¨ä¾ç¢çä¸åå·ææ´å¥½å¬å¹³æ§çæ¨¡åãæåçæ¨¡åéå¼å¥äºä¸ç¨®æ°ç©çåºæ¼æåçç¹å¾µéè¦æ§æ¼ç®æ³ï¼æ¨å¨é¡ææ¯åç¹å¾µå¨å¢å¼·é æ¸¬å¬å¹³æ§æ¹é¢çè²¢ç»ãèç¾æçå¯è§£éæ§æ¹æ³å°æ³¨æ¼è§£éç¹å¾µå°é æ¸¬æè½çè²¢ç»ä¸åï¼æåæåºçæ¹æ³ç¨ç¹å°å½è£äºçè§£æ¯åç¹å¾µå¦ä½æå©æ¼å¬å¹³æ§çå·®è·ãéé é²å±è³ééè¦ï¼å çºæè¡ççæ­»äº¡çå¾é«ï¼ä¸å¨ä¸åä¹ä¸çé«é¢æ­»äº¡ä¸­æ®æ¼èè§è²ãæåçæ¨¡åä¸åæå©æ¼è­å¥åæ¸è¼é æ¸¬æ¨¡åä¸­çåå·®ï¼éè½ééæé«æ¨¡åé æ¸¬çéæåº¦åå¬å¹³æ§ä¾å¹é¤é«çä¿å¥å©çç¸éèä¹éçä¿¡ä»»ï¼é²èæå©æ¼æä¾æ´å¬å¹³ä¸å¼å¾ä¿¡è³´çé«çä¿å¥æåã

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

æè¦ï¼ç¾ä»ï¼æé¬±çæ¯ä¸åéè¦çè­°é¡ãæ ¹æä¸çè¡ççµç¹ (WHO) çè³æï¼å¨ 2023 å¹´ï¼è¶é 2.8 åäººæ­£å¨èæé¬±çæé¬¥ãéæ¯ä¸åé¾å¤§çæ¸å­ï¼å¦æä¸èªççå¾ï¼éäºæ¸å­å°æå¿«éå¢å ãå¤§ç´æ 48.9 åäººæ¯ç¤¾ç¾¤åªé«ä½¿ç¨èãäººåå¨ TwitterãFacebookãRedditãInstagram ç­å¹³å°ä¸è¡¨éèªå·±çæååæç·ãéäºå¹³å°åå«æå¹å¼çè³è¨ï¼å¯ç¨æ¼ç ç©¶ç®çãå·²ç¶å¨åç¨®ç¤¾ç¾¤åªé«å¹³å°ä¸é²è¡äºå¤§éçç ç©¶ãç¶èï¼éäºåªåä»å­å¨æäºéå¶ãç¹å¥æ¯ï¼ååçç ç©¶åå°æ³¨æ¼åµæ¸¬æ¨æä¸­çæé¬±çåæé¬±ççå¼·åº¦ãæ­¤å¤ï¼è³æéæ¨ç±¤ä¸­å­å¨ä¸æºç¢ºçææ³ãå¨éé ç ç©¶å·¥ä½ä¸­ï¼ä½¿ç¨åºæ¼è©å½æ¨ç±¤ç Twitter è³æåº«ä¸­çæ¨æé æ¸¬äºäºç¨®é¡åçæé¬±çï¼éæ¥µåãéåº¦ãç²¾ç¥çåãéå¸ååç¢å¾ï¼ãå¯è§£éç AI ç¨æ¼ééå¼·èª¿ä»£è¡¨æé¬±çé¡åçæ¨æé¨åä¾æä¾æ¨çãå¾ Transformersï¼BERTï¼ä¸­æåçéåç·¨ç¢¼å¨è¡¨ç¤ºç¨æ¼ç¹å¾µæååè¨ç·´ãæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¹æ³ç¨æ¼è¨ç·´æ¨¡åãBERT æ¨¡ååç¾åºææå¸æççµæï¼éå° 0.96 çæ´é«æºç¢ºåº¦ã

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

æè¦ï¼æ·±åº¦å­¦ä¹ æ­£å¤§å¹è½è®é«å­¸å½±ååæ¾å°ç·å­¸é åï¼è½è¾¨è­é«å­¸å½±åä¸­çççï¼åæ¬é»è¦æ·å±¤ææ (CT) å X åææãç¶èï¼æ·±åº¦å­¸ç¿æ¨¡åçæè½ï¼ç¹å¥æ¯å¨åå²ä»»åä¸­ï¼å¸¸å¸¸åå°å»£æ³è¨»è§£è³æééæ±çéå¶ãçºäºæå°æ­¤ææ°ï¼ééå¯è§£é AI ååäºå¯¦è§£éçç¢çï¼æ¢ç´¢å¼±ç£ç£èªæåå²çè½åãæ¬ç ç©¶çç¯åæ¯éç¼ä¸ç¨®æ°çåäºå¯¦å§ææ¹æ³ (COIN)ï¼è©²æ¹æ³ä½¿ç¨çææ¨¡åå°é æ¸¬çåé¡æ¨ç±¤å¾ç°å¸¸ç¿»è½çºæ­£å¸¸ãä¾å¦ï¼å¦æåé¡å¨å°è¼¸å¥çé«å­¸å½±å X è¦çºç°å¸¸ï¼è¡¨ç¤ºå­å¨ççï¼åçææ¨¡åæ¨å¨å§æç°å¸¸ååï¼å¾èéè½åé¡å¨çåå§é æ¸¬æ¨ç±¤ãæ­¤æ¹æ³ä½¿æåè½å¤ ç¢ççççç²¾ç¢ºåå²ï¼èç¡éä¾è³´æ¼é åå­å¨çåå²é®ç½©ãè³ééè¦çæ¯ï¼å©ç¨å½±åå±¤ç´æ¨ç±¤ï¼éæ¯å»ºç«è©³ç´°çåå²é®ç½©å®¹æåå¾ãè©²æ¹æ³çæææ§ééåå²åæç®æ¨åå¾ææ²å°¼äºå¡ç¾åå¤§å­¸é«é¢åå¾ç CT å½±åä¸­çå¯¦éèèè«ç¤ä¾è­æãç ç©¶çµæè¡¨æï¼COIN é é è¶éå·²å»ºç«çæ­¸å æ¹æ³ï¼ä¾å¦ RISEãScoreCAM å LayerCAMï¼ä»¥å Singla ç­äººæåºçå¦ä¸ç¨®åäºå¯¦è§£éæ¹æ³ãæ­¤è­æè¡¨æï¼COIN æ¯ä¸ç¨®å¾æåéç CT å½±åä¸­è«ç¤èªæåå²æ¹æ³ï¼ä¸¦å¨é«çä¿å¥ä¸­è®æ·±åº¦å­¸ç¿æç¨æ´ææ¼åå¾åæ´ææçéé²ä¸æ­¥ï¼å¶ä¸­è¨»è§£è³æå¾ç¨å°ã

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

æè¦ï¼å¨æ¬æä¸­ï¼æåæ¢è¨æ¸ä½äººæå­¸ç§ (DH) ä½çºä¸éå­¸ç§èæ··åæºè½ (HI) ä½çºä¸åç ç©¶å¸ç¯ä¹éçååä½ç¨ãå¨ DH ç ç©¶ä¸­ï¼æ¸ä½æ¹æ³çä½¿ç¨ï¼ç¹å¥æ¯äººå·¥æºæ§çä½¿ç¨ï¼åå°ä¸ç³»åè¦æ±åéå¶ãæåèªçºéäºè¦æ±åéå¶ç²å¾ HI çè½ååç®æ¨çååæ¯æãæåçè²¢ç»åæ¬æ¾åºäºåéæ¨£ç DH è¦æ±ï¼æåç AI ç³»çµ±éè¦è½å¤  1) èï¼äººé¡ï¼å­¸èåä½ï¼2) æ¯æ´è³ææ¹è©ï¼3) æ¯æ´å·¥å·æ¹è©ï¼4) å¯è¦ºä¸¦è¿ååç¨®è§é»ï¼5) æ¯æ´é è·åè¿è·é¢é±è®ãæåå°æ··åæºè½ç CARE ååï¼åä½ãé©æãè² è²¬åå¯è§£éï¼ä½çºçè«æ¶æ§ï¼ä¸¦å°éäºååå°æå° DH è¦æ±ãå¨æ­¤å°æä¸­ï¼æåç´å¥ç¯ä¾ç ç©¶å°æ¡ãæå¾ï¼æåæ¢è¨å¦ä½å° DH çè¦è§£æç¨æ¼ HIï¼ä¸¦è¨è«çµåéå©åå­¸ç§çéæ¾ææ°ã

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

æè¦ï¼åºç¤æ¨¡å (FM) å·æå¾¹åºæ¹è®é«å­¸å½±åçå·¨å¤§æ½åãç¶èï¼å®åå¨ç¾å¯¦ä¸çè¨åºç°å¢ä¸­çé¨ç½²éè¦å»£æ³çå«çèéãæ¬ææ¨å¨å¼·èª¿è FM ç¸éçå«çåé¡ï¼ä¸¦æåºä¸åæ¡æ¶ä¾æå°å®åå¨é«å­¸ä¸­çè² è²¬ä»»éç¼åå¯¦æ½ãæåä»ç´°å¯©æ¥äºå«çåé¡ï¼ä¾å¦æ£èæ¸æé±ç§ãåå·®ç·©è§£ãæ¼ç®æ³éæåº¦ãå¯è§£éæ§ååè²¬å¶ãææåºçæ¡æ¶æ¨å¨åªåèæ®æ£èç¦å©ãæ¸è¼æ½å¨é¢¨éªï¼ä¸¦å¹é¤å° AI è¼å©é«çä¿å¥çä¿¡ä»»ã

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

æè¦ï¼ç²çèºçæ¯ä¸ç¨®æ¥çå´éçå¨çå¥åº·åé¡ï¼éè¦åé²çè¨ºæ·æ¹æ³ãæ¬ç¯è©è«æ¢è¨äºäººå·¥æºè½èæ¾å°ç¹å¾µåæå¨ç²çèºçè¨ºæ·ä¸­çæç¨ãå¨ç¬¦å PRISMA æåçææ³ä¸ï¼å°å¤åè³æåº«é²è¡äºåé¡§ï¼ç´å° 2023 å¹´ 10 æãééçµåééµå­ï¼ç¼ç¾äºä¸ç¯éæ¼ç²çèºçåç¸éä¸»é¡çè±æå­¸è¡åºçç©ãå¨ç§»é¤ 109 ç¯éè¤æç»å¾ï¼åå§æå°å±åå³ 267 ç¯è«æãå¨æ ¹æé åç¢ºå®çæ¨æºï¼æ·æ±°äº 124 ç¯æç« çæè¦åæ¨é¡å¾ï¼é¸åºäºç¸éç ç©¶ãå¨é²è¡å¨é¢åæå¾ï¼é¡å¤æé¤äºå­é ç ç©¶ãå¨ç´å¥ç 28 é ç ç©¶ä¸­ï¼çµåè¶é³æ³¢ (US) å½±åçæ¾å°ç¹å¾µåæï¼è­æäºå¶å¨è¨ºæ·ç²çèºçæ¹é¢çæææ§ãç ç©¶çµæä¸ä¸ï¼æäºç ç©¶æåºäºåªæ¼ç¾ççæ°ç­ç¥ãæç»å¼·èª¿äºäººå·¥æºè½æ¨¡åé¢è¨çåç¨®ææ°ï¼åæ¬å¯è§£éæ§åé¡ãè³æééå¶åæä½å¡ä¾è³´æ§ã28 é ç´å¥ç ç©¶çç¶åç¼ç¾æå°ï¼éè¦æ¨æºåå·¥ä½ååç»æ§å¤ä¸­å¿ç ç©¶ä¾è§£æ±ºéäºåé¡ãæ­¤å¤ï¼éç¢ºå®äºåæéäºéç¤çæ¹æ³ï¼ä¾å¦å¯è§£éäººå·¥æºè½æè¡ååäººåé«çæè¡çé²æ­¥ãæ¬ç¯è©è«éé»æ¢è¨äºäººå·¥æºè½åæ¾å°ç¹å¾µåæå¦ä½è½è®ç²çèºççè¨ºæ·åæ²»çãåç®¡å­å¨ææ°ï¼ä½æªä¾å°å¤å­¸ç§åä½ãè¨åºé©ç¨æ§é©è­åæ¼ç®æ³æ¹é²çç ç©¶ï¼ä»ææ½åæ¹åç²çèºçæ²»çä¸­çæ£èé å¾åè¨ºæ·ç²¾æºåº¦ã

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼ä¹³çççè¡çè¿éå¢å ï¼ä½¿å¶æçºå¨çä¸»è¦çæ­»äº¡åå ä¹ä¸ãå¨ææççä¸­ï¼ä¹³çè¿ä»çºæ­¢æ¯æå¸¸è¦çãæåè¨ºæ·æ­¤ç¾çéè¦å¤§éçæéåå°æ¥­ç¥è­ãç±æ¼ä¹³ççæª¢æ¸¬éç¨èæï¼å æ­¤ééå»ºç«æ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬ï¼æå©æ¼é²æ­¢å¶é²ä¸æ­¥æ´æ£ãæ©å¨å­¸ç¿åå¯è§£é AI å¨åé¡ä¸­è³ééè¦ï¼å çºå®åä¸åå¯ä»¥æä¾æºç¢ºçé æ¸¬ï¼éå¯ä»¥æ·±å¥äºè§£æ¨¡åå¦ä½ååºæ±ºç­ï¼æå©æ¼çè§£åä¿¡è³´åé¡çµæãå¨æ­¤ç ç©¶ä¸­ï¼æåè©ä¼°ä¸¦æ¯è¼äºäºç¨®ä¸åçæ©å¨å­¸ç¿æ¹æ³çåé¡æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä½¿ç¨äºä¸åä¸»è¦çè³æéï¼éå¡é«å­¸é¢é«é¢ç 500 åæ£èï¼ãäºç¨®ä¸åçç£ç£å¼æ©å¨å­¸ç¿æè¡ï¼åæ¬æ±ºç­æ¨¹ãé¨æ©æ£®æãéè¼¯è¿´æ­¸ãæ´ç´ è²æ°å XGBoostï¼å·²ç¨æ¼å¨æåçè³æéä¸åå¾æä½³çµæãæ­¤å¤ï¼æ¬ç ç©¶å° SHAP åææç¨æ¼ XGBoost æ¨¡åï¼ä»¥è§£éæ¨¡åçé æ¸¬ä¸¦äºè§£æ¯åç¹å¾µå°æ¨¡åè¼¸åºçå½±é¿ãæåæ¯è¼äºå¹¾ç¨®æ¼ç®æ³å°è³æé²è¡åé¡çæºç¢ºåº¦ï¼ä¸¦èè©²é åçå¶ä»æç»é²è¡å°æ¯ãå¨æå¾è©ä¼°å¾ï¼æ¬ç ç©¶ç¼ç¾ XGBoost éå°äºæä½³çæ¨¡åæºç¢ºåº¦ï¼çº 97%ã</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

æè¦ï¼æ·±åº¦å­¸ç¿ (DL) ç¨æ¼å¾ä¹³æ¿æå½±è¡å½±åè¨ºæ·ä¹³ççæ¨¡åéå¸¸ä»¥ãé»çå­ãæ¹å¼éä½ï¼éä½¿å¾é«çä¿å¥å°æ¥­äººå¡é£ä»¥ä¿¡ä»»åçè§£å¶æ±ºç­éç¨ãæ¬ç ç©¶æåºä¸åæ´åæ¶æ§ï¼çµåå·ç©ç¥ç¶ç¶²è·¯ (CNN) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥ä½¿ç¨ CBIS-DDSM è³æéå¢å¼·ä¹³ççè¨ºæ·ãæ¹æ³åå«ä¸åç²¾ç´°çè³æåèçç®¡ç·åé²éè³ææ´åæè¡ï¼ä»¥å°æè³æééå¶ï¼ä¸¦æ¡ç¨é åè¨ç·´çç¶²è·¯ï¼ä¾å¦ VGG-16ãInception-V3 å ResNetï¼é²è¡é·ç§»å­¸ç¿ãæåç ç©¶çéé»æ¯è©ä¼° XAI å¨è§£éæ¨¡åé æ¸¬ä¸­çæææ§ï¼éé»å©ç¨è±ªæ¯å¤å¤«æ¸¬åº¦éåè©ä¼° AI çæçè§£éåå°å®¶è¨»è§£ä¹éçä¸è´æ§ãéç¨®æ¹æ³å°æ¼ XAI å¨ä¿é² AI è¼å©è¨ºæ·ä¸­çå¯ä¿¡åº¦åå«çå¬å¹³æ§è³ééè¦ãæåç ç©¶çç¼ç¾èªªæäº CNN å XAI å¨æ¨é²ä¹³çè¨ºæ·æ¹æ³ä¸­çææåä½ï¼å¾èä¿é²äºåé² AI æè¡å¨è¨åºç°å¢ä¸­çæ´é æ¢æ´åãééå¢å¼· AI é©åæ±ºç­çå¯è§£éæ§ï¼éé å·¥ä½çº AI ç³»çµ±åé«çå¾æ¥­äººå¡ä¹éçæ¹ååä½å¥ å®äºåºç¤ï¼æçµè±å¯äºæ£èç§è­·ãæ­¤å¤ï¼æåç ç©¶çå½±é¿é é è¶åºäºç®åçæè¡ãå®é¼åµé²ä¸æ­¥ç ç©¶å¦ä½çµåå¤æ¨¡å¼è³æä¸¦æ¹å AI è§£éï¼ä»¥æ»¿è¶³è¨åºå¯¦åçéæ±ã

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

æè¦ï¼æ¬ç ç©¶æåºäºä¸ç¨®åµæ°çå¤æ¨¡ææ¸æèåæ¹æ³ï¼ç¨æ¼ç¼çè¡çºè­å¥ï¼å°çµ±è¨ç¸éåæèä»¥äººçºä¸­å¿çè¦è§£ç¸çµåãæåçåæ³å¼å¥äºå©é ééµåµæ°ï¼1) å°æ¸æé©åççµ±è¨ç¸éæ¬éæ´åå°èåç­ç¥ä¸­ï¼ä»¥ææå©ç¨ä¾èªç°è³ªæ¨¡æçè£åä¿¡æ¯ï¼ä»¥å 2) å°ä»¥äººçºä¸­å¿çéåç¹å¾µç´å¥å¤æ¨¡æè¡¨ç¤ºå­¸ç¿ä¸­ï¼ä»¥è©³ç´°å»ºæ¨¡ç¼çè¡çºãæåçæ¨¡åå¨åç¨®æ·±åº¦å­¸ç¿æ¶æ§ä¸­å¾å°é©è­ï¼å±ç¤ºäºåè¶çæ§è½åå»£æ³çé©ç¨æ§ãæåæåºäºä¸åå¯èªå®ç¾©çæ¡æ¶ï¼æ ¹æçµ±è¨é¡¯èæ§å°æ¯åæ¨¡æèåé©çåé¡å¨å°é½ï¼æ¨é²åæ§ååææçå¤æ¨¡æèåãæ­¤å¤ï¼æåçæ¨¡åæä¾å°å¤æ¨¡ææ¸æçå¯è§£éåæï¼æå©æ¼é«çä¿å¥ä¸­çå¯è§£éåå¯è§£é AIãééå¼·èª¿æ¸æå¤æ¨£æ§åæ¨¡æç¹å®è¡¨ç¤ºçéè¦æ§ï¼æåå¢å¼·äºå³çµ±çèåæè¡ï¼ä¸¦çºè­å¥è¤éçç¼çè¡çºè¨­å®äºæ°çæ¨æºãæåçç¼ç¾å°ä¿é²ä»¥æ£èçºä¸­å¿çé«çä¿å¥å¹²é åæ¯æå¯è§£éçè¨åºæ±ºç­å¶å®å·æéè¦æç¾©ã

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

æè¦ï¼ä»¥äººä¸ºæ¬çå¯è§£é AI (HCXAI) å¡å¯¼å°ç¤¾ä¼å±é¢æ´åå° AI è§£éä¸­ãHCXAI è¯è¯­çæ ¸å¿æ¯ç¤¾ä¼éæåº¦ (ST) æ¡æ¶ï¼å¶ç®æ æ¯è®© AI ç³»ç»çç¤¾ä¼ç»ç»èæ¯å¯¹ç¨æ·æ¥è¯´æ¯å¯çè§£çãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å»ºè®®æ©å± ST æ¡æ¶ä»¥è§£å³å¤§åè¯­è¨æ¨¡å (LLM) ä¸­ç¤¾ä¼éè¯¯å½å çé£é©ï¼å°¤å¶æ¯å¨å¿çå¥åº·ç­ææé¢åãäºå®ä¸ï¼LLM è½å¤åºè²å°æ¨¡æè§è²åäººæ ¼ï¼è¿å¯è½å¯¼è´è®¾è®¡èçæå¾åç¨æ·å¯¹ç¤¾ä¼å±æ§çè®¤ç¥ä¹é´åºç°ééï¼ä»èæé£é©ä¿è¿æç»ªæçºµåå±é©è¡ä¸ºãè®¤ç¥ä¸å¬æ­£åä¸åççä¿¡ä»»ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬å»ºè®®ç¨ç¬¬äºä¸ªâW é®é¢âæ¥å¢å¼º ST æ¡æ¶ï¼ä»¥æç¡®è®¾è®¡èåç¨æ·èµäº LLM çå·ä½ç¤¾ä¼å±æ§ãæ­¤è¡¥åæ¨å¨å¼¥å LLM è½ååç¨æ·è®¤ç¥ä¹é´çå·®è·ï¼ä¿è¿åºäº LLM çææ¯å¨éå¾·ä¸è´è´£ä»»å°å¼ååä½¿ç¨ã

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

æè¦ï¼<paragraph>èæ¯ï¼æ°£è¸æ¯ä¸ç¨®å èºé¨èè¸å£ä¹éç°å¸¸éæ°£æå¼èµ·çæ¥æ§è¸èç¾çãçºäºè§£æ±ºæ·±åº¦å­¸ç¿ï¼DLï¼æ¨¡åç¶å¸¸ä¼´é¨çä¸éææ§ï¼å¯è§£éäººå·¥æºæ§ï¼XAIï¼æ¹æ³å·²è¢«å¼å¥ï¼ç¨æ¼æ¦è¿°è DL æ¨¡åååºçæ°£è¸è¨ºæ·ç¸éçååãç¶èï¼éäºè§£éæææèå¯¦éçç¶ååææåºå¥ï¼çªé¡¯åºé²ä¸æ­¥æ¹é²çå¿è¦æ§ãæ¹æ³ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼å°æ°£è¸çè¨åºç¥è­ç´å¥ XAI æ¹æ³ç¢ççæ¨¡åè§£éä¸­ï¼å¾èæåéäºè§£éçåè³ªãå©ç¨æ¾å°ç§é«å¸«å»ºç«ççç¶æç¹ªï¼æåçåæ³é¦åç¢çä¸åæ¨¡æ¿ï¼ç¨æ¼è¡¨ç¤ºæ°£è¸å¯è½ç¼ççååãç¶å¾å°æ­¤æ¨¡æ¿çå å¨æ¨¡åè§£éä¸ï¼ä»¥ç¯©é¸åºè¶åºæ¨¡æ¿éççç¡éè§£éãçºäºé©è­å¶æåï¼æåå°ä¸ç¨® XAI æ¹æ³é²è¡äºæ¯è¼åæï¼å¨å©åçå¯¦ä¸çè³æéä¸­è§£éå©å DL æ¨¡åæï¼åå¥æ¡ç¨åä¸æ¡ç¨æåçæ¨¡æ¿å¼å°ãçµæï¼ææåºçæ¹æ³å¨å»ºç«æ¼ä¸ç¨® XAI æ¹æ³ãå©å DL æ¨¡ååå©åè³æéçåäºç¨®åºæºæå¢ä¸­ï¼å§çµæ¹åäºåºæº XAI æ¹æ³ãå¨æ¯è¼æ¨¡åè§£éåçå¯¦çç¶ååæï¼ééåºæºæè½çæè½æ¹é²è¨ç®åºçå¹³åå¢éç¾åæ¯çºäº¤éæ¯ï¼IoUï¼ç 97.8% åéª°å­ç¸ä¼¼æ§ä¿æ¸ï¼DSCï¼ç 94.1%ãçµè«ï¼å¨æ°£è¸è¨ºæ·çèæ¯ä¸ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼ç¨æ¼æ¹å AI è§£éãæåé ææåçæ¨¡æ¿å¼å°å°ééæ´åè¨åºé åå°æ¥­ç¥è­ï¼çºé¡æ AI æ¨¡åå»ºç«ä¸ç¨®æ°æ¹æ³ã</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by SÃ©amus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

æè¦ï¼<paragraph>å¨ç¶åæ©å¨ç¿»è­¯ (MT) é åä¸­ï¼Transformer æ¶æ§è«ç©èåºï¼æçºé»éæ¨æºï¼ç¹å¥æ¯å°æ¼é«è³æºèªè¨å°ãæ¬ç ç©¶æ¢è¨å¶å°ä½è³æºèªè¨å°çæè½ï¼åæ¬è±èªâæç¾è­èªåè±èªâé¦¬æå°èªèªè¨å°ãå¼å¾æ³¨æçæ¯ï¼æ¬ç ç©¶è­å¥åºæä½³è¶åæ¸åå­è©æ¨¡åé¡åï¼ä»¥é¡¯èæé« Transformer æ¨¡åå°ä½è³æºèªè¨å°çç¿»è­¯åè³ªã
ä½è³æºèªè¨çå¹³è¡è³æéçç¨ç¼ºæé»ç¤ MT çç¼å±ãçºäºè§£æ±ºéååé¡ï¼éç¼äº gaHealthï¼éæ¯æç¾è­èªçç¬¬ä¸åéèªå¥åº·è³æèªæåº«ãå°æ³¨æ¼å¥åº·é åï¼ä½¿ç¨æ­¤åå§è³æééç¼çæ¨¡åå¨ BLEU å¾åæ¹é¢è¡¨ç¾åºéå¸¸é¡¯èçé²æ­¥ï¼è LoResMT2021 å±äº«ä»»åä¸­çæ¨¡åç¸æ¯ãé¨å¾ä½¿ç¨å¤ç¶­åè³ªææ¨é¯èª¤åé¡æ³é²è¡çäººå·¥è©ä¼°é¡¯ç¤ºï¼èåºæ¼ RNN çå°ææ¨¡åç¸æ¯ï¼Transformer ç³»çµ±å¨æ¸å°æºç¢ºæ§åæµæ¢æ§é¯èª¤æ¹é¢è¡¨ç¾åºåªç°çæ§è½ã
æ­¤å¤ï¼æ¬è«æä»ç´¹äº adaptNMT å adaptMLLMï¼éå©åéæºæç¨ç¨å¼ç°¡åäºç¥ç¶æ©å¨ç¿»è­¯æ¨¡åçéç¼ãå¾®èª¿åé¨ç½²ãéäºå·¥å·å¤§å¹ç°¡åäºè¨­å®åè©ä¼°æµç¨ï¼è® MT æ´å®¹æè®éç¼äººå¡åç¿»è­¯äººå¡ä½¿ç¨ãå¼å¾æ³¨æçæ¯ï¼adaptNMT ä»¥ OpenNMT çæç³»çµ±çºåºç¤ï¼ééå¼·èª¿æ¨¡åéç¼çç°å¢è¶³è·¡ä¾ä¿é²çæåå¥½çèªç¶èªè¨èçç ç©¶ãè LoResMT2021 å±äº«ä»»åä¸­çåºæºç¸æ¯ï¼adaptMLLM å° MLLM çå¾®èª¿è­æäºè±èªâæç¾è­èªåè±èªâé¦¬æå°èªéå©åä½è³æºèªè¨å°çç¿»è­¯æ§è½é²æ­¥ã</paragraph>

##### **Cause and Effect: Can Large Language Models Truly Understand Causality?**
2402.18139v3 by Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Mayank Jindal, Dushyant Singh Sengar, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, Aman Chadha

With the rise of Large Language Models(LLMs), it has become crucial to
understand their capabilities and limitations in deciphering and explaining the
complex web of causal relationships that language entails. Current methods use
either explicit or implicit causal reasoning, yet there is a strong need for a
unified approach combining both to tackle a wide array of causal relationships
more effectively. This research proposes a novel architecture called Context
Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to
enhance causal reasoning and explainability. The proposed framework
incorporates an explicit causal detection module with ConceptNet and
counterfactual statements, as well as implicit causal detection through LLMs.
Our framework goes one step further with a layer of counterfactual explanations
to accentuate LLMs understanding of causality. The knowledge from ConceptNet
enhances the performance of multiple causal reasoning tasks such as causal
discovery, causal identification and counterfactual reasoning. The
counterfactual sentences add explicit knowledge of the not caused by scenarios.
By combining these powerful modules, our model aims to provide a deeper
understanding of causal relationships, enabling enhanced interpretability.
Evaluation of benchmark datasets shows improved performance across all metrics,
such as accuracy, precision, recall, and F1 scores. We also introduce
CausalNet, a new dataset accompanied by our code, to facilitate further
research in this domain.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) çèèµ·ï¼äºè§£å®åå¨è§£ç¢¼åè§£éèªè¨æèå«çè¤éå æéä¿ç¶²è·¯ä¸­çè½ååéå¶è®å¾è³ééè¦ãç®åçæè¡ä½¿ç¨æç¢ºæé±å«çå ææ¨çï¼ä½å¼·çéè¦ä¸ç¨®çµ±ä¸çæ¹æ³ï¼çµåå©èä»¥æ´ææå°èçå»£æ³çå æéä¿ãæ¬ç ç©¶æåºäºä¸ç¨®ç¨±çºæå¢æç¥æ¨çå¢å¼·èåäºå¯¦åæ (CARE CA) æ¡æ¶çæ°æ¶æ§ï¼ä»¥å¢å¼·å ææ¨çåå¯è§£éæ§ãæåºçæ¡æ¶çµåäºä½¿ç¨ ConceptNet ååäºå¯¦é³è¿°çæç¢ºå ææª¢æ¸¬æ¨¡çµï¼ä»¥åéé LLM é²è¡çé±å«å ææª¢æ¸¬ãæåçæ¡æ¶æ´é²ä¸æ­¥ï¼å å¥ä¸å±¤åäºå¯¦è§£éï¼ä»¥å¼·èª¿ LLM å°å æéä¿ççè§£ãä¾èª ConceptNet çç¥è­å¢å¼·äºå¤é å ææ¨çä»»åçå·è¡ï¼ä¾å¦å æç¼ç¾ãå æè­å¥ååäºå¯¦æ¨çãåäºå¯¦å¥å å¥äºæªç±æå¢é æçæç¢ºç¥è­ãééçµåéäºå¼·å¤§çæ¨¡çµï¼æåçæ¨¡åæ¨å¨æä¾å°å æéä¿æ´æ·±å¥ççè§£ï¼å¯¦ç¾å¢å¼·çå¯è§£éæ§ãåºæºè³æéçè©ä¼°é¡¯ç¤ºå¨ææææ¨ï¼ä¾å¦æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä¸é½æææåãæåéå¼å¥äº CausalNetï¼ä¸åæ°çè³æéï¼ä¸¦éä¸äºæåçç¨å¼ç¢¼ï¼ä»¥ä¿é²å¨éåé åçé²ä¸æ­¥ç ç©¶ã

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

æè¦ï¼ç³å°¿çï¼DMï¼ä½¿æ£èå®¹æåºç¾è¡ç®¡ä½µç¼çã
è¦ç¶²èå½±ååè¡ç®¡åæ èº«é«çå¾®è¡ç®¡åå·¨è¡ç®¡å¥åº·çæ³ãå®åå¯ç¨æ¼è¨ºæ·ç³å°¿çä½µç¼çï¼åæ¬ç³å°¿çè¦ç¶²èçè®ï¼DRï¼ãç¥ç¶çè®ãèçååèç²¥æ¨£ç¡¬åæ§å¿è¡ç®¡ç¾çï¼ä»¥åé æ¸¬å¿è¡ç®¡äºä»¶çé¢¨éªãçºä½¿ç¨æ¸ä½åè¦ç¶²èå½±åé²è¡é«éé DR æª¢æ¸¬èéç¼çäººå·¥æºæ§ï¼AIï¼åç¨ç³»çµ±å·²å¨è¨åºæ¡ç¨ãé¤äº DR ç¯©æª¢å¤ï¼AI æ´åä¹å·æå·¨å¤§çæ½åä¾æå°èç³å°¿çæ£èæ´é«ç§è­·ç¸éçææ°ãå¨éé å·¥ä½ä¸­ï¼æåæ¨å¨å¨é¢åé¡§åºæ¼è¦ç¶²èå½±åç AI æç¨ç¸éç ç©¶çæç»ï¼éäºç ç©¶èç³å°¿ççè¨ºæ·ãé å¾åç®¡çæéãæåå°æè¿°æ´é« AI è¼å©ç³å°¿çç§è­·çç¼ç¾ï¼åæ¬ä½ä¸éæ¼ DR ç¯©æª¢ï¼ä¸¦è¨è«å¯¦æ½æ­¤é¡ç³»çµ±çéç¤ï¼åæ¬èå«çãè³æé±ç§ãå¬å¹³å­ååå¯è§£éæ§æéçåé¡ãééè©ä¼°æ£èçå¥åº·çæ³ï¼åæèéç³å°¿çä½µç¼çä»¥åæªä¾å¿è¡ç®¡ä½µç¼ççé¢¨éªé å¾ï¼AI è¼å©è¦ç¶²èå½±ååæææ½åæçºç³å°¿çæ£èç¾ä»£ååäººåé«ççä¸­å¿å·¥å·ã

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

æè¦ï¼éé ç ç©¶å¾å¤åå©å®³éä¿äººçè§åº¦æ¢è¨ä¸åçäººå·¥æºæ§ (AI) æç¨å¨æè²ä¸çå¯æ¥åæ§ï¼åæ¬å­¸çãèå¸«åå®¶é·ãæ¿èª AI å¨æè²ä¸çè½åæ½åï¼å®è§£æ±ºäºèè³æé±ç§ãAI ä»£çãéæåº¦ãå¯è§£éæ§å AI çéå¾·é¨ç½²ç¸éççæ®ãééå°ææ²æ¹æ³ï¼åèèè¢«åç¾äºåç¨®æå¢ï¼å¶ä¸­ AI çä»£çãéæåº¦ãå¯è§£éæ§åé±ç§åå°æç¸±ãå¨æ¯åæå¢å¾ï¼åèèå®æäºä¸é èª¿æ¥ï¼è©²èª¿æ¥ææäºä»åå° AI çæ´é«æç¨ãåäººæç¨ãæ­£ç¾©ãä¿¡å¿ãé¢¨éªåå¦æå¯ç¨ï¼ä½¿ç¨æ¯åæå¢ç AI çæåççæ³ãè³æèéåå«ä¾èªåä½æ©æ§åç¤¾ç¾¤åªé«æ´»åç 1198 ä½å¤å©å®³éä¿äººåèèçæçµæ¨£æ¬ï¼ä¸¦å°æ³¨æ¼å°åå AI ä½¿ç¨æ¡ä¾çåå¥åæãå°è³æçèª¿è§£åæè¡¨æï¼å° AI çæ¥ååº¦åä¿¡ä»»å¨å©å®³éä¿äººåé«ä¹éæé¡¯èå·®ç°ãæåç¼ç¾ï¼AI çä»£çãéæåº¦åå¯è§£éæ§é«ä½ç¨åº¦ä¹éçééµèª¿è§£èï¼ä»¥åä½¿ç¨ä¸åæè² AI çæåï¼åæ¬æç¥å°çæ´é«æç¨ãæ­£ç¾©åä¿¡å¿ãéé ç ç©¶å¼·èª¿ï¼æ¥å AI å¨æè²ä¸çæç¨æ¯ä¸åå¾®å¦ä¸å¤é¢åçåé¡ï¼é¤äºä¸åçå©å®³éä¿äººççæ³å¤ï¼ééè¦ä»ç´°èæ®å·é«ç AI æç¨åå¶ç¹å¾µã

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

æè¦ï¼<paragraph>åºæ¼å¯ç©¿æ´å¼å®å°ç¨å¿é»å (ECG) è£ç½®çé ç«¯çæ£ç£æ¸¬å¨æ©æåµæ¸¬å¿èç¾çæ¹é¢å·æé¡¯èçæ½åï¼ç¹å¥æ¯èç¨æ¼èªååå¿èç¾çåµæ¸¬çäººå·¥æºæ§ (AI) æ¹æ³çµåä½¿ç¨æãååå·²æç ç©¶æç¨åºæ¼æ·±åº¦å­¸ç¿ç AI æ¹æ³é²è¡å¿èç¾çåµæ¸¬ãç¶èï¼éäºæ¨¡åå°æªè¢«å»£æ³æ¥åçºè¨åºè¨ºæ·çå¯é è¼å©å·¥å·ï¼é¨ååå å¨æ¼åç¹è¨±å¤ AI æ¼ç®æ³çç¶åé»ç®±æç¥ãç¹å¥æ¯ï¼æå¿è¦æ¾åºæå©æ¼ååºæºç¢ºè¨ºæ·ç ECG è¨èééµç¹å¾µï¼å¾èå¢å¼·æ¨¡åçå¯è§£éæ§ãå¨æ¬ç ç©¶ä¸­ï¼æåéç¼äºä¸ç¨®è¦è¦ºè½æå¨æ¹æ³ï¼ä»¥æ ¹æå®å°ç¨ ECG è³ææ¾åºå¿æ¿é¡«åãæ®å·®ç¶²è·¯ (ResNet) æ¹æ³ä¹å·²éç¼åºä¾ï¼ä»¥ä¾¿èè¦è¦ºè½æå¨æ¹æ³é²è¡æ¯è¼ãéäºæ¨¡åæç¨æ¼ Chapman-Shaoxing è³æéï¼ä»¥åé¡å¿æ¿é¡«åï¼ä»¥åå¦ä¸ç¨®å¸¸è¦çå¿å¾ä¸æ´ï¼ç«æ§å¿åéç·©ï¼åæ­£å¸¸ç«æ§å¿å¾çå¿è·³ãéäºæ¨¡åè½å¤ æ¾åºæ±ºå®æçµåé¡çå¿è·³ééµååï¼ä¸¦å¼·èª¿ P æ³¢å T æ³¢ï¼ä»¥åå¿è·³æçºæéåè¨èæ¯å¹å¨ååæ­£å¸¸ç«æ§å¿å¾èå¿æ¿é¡«ååç«æ§å¿åéç·©æ¹é¢çéè¦æ§ã</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

æè¦ï¼æ¬æä»ç´¹äºä¸ç¨®ä½¿ç¨åé²å¤§åèªè¨æ¨¡å (LLM) é²è¡æé¬±çåµæ¸¬åæ²»ççæ°æ¨¡å¼ï¼çæå¼é è¨ç·´Transformer 4 (GPT-4)ãLlama 2 èå¤©æ©å¨äººå Geminiãéäº LLM ç¶éå¾®èª¿ï¼å·åå°æ¥­æç¤ºï¼å¯è¨ºæ·ãè§£éä¸¦å»ºè­°æé¬±ççæ²»çä»å¥æ¹æ³ãä¸ç¨®ç¨ç¹çå°æ¬¡æç¤ºæ¹æ³å¢å¼·äºæ¨¡åæ ¹æ DSM-5 æ¨æºåæåè§£éæé¬±çççè½åãå¨äºåéæ®µï¼éäºæ¨¡åæåèåçå¿å°è©±ç®¡çï¼å¾ PsychDB åèªç¥è¡çºçæ³ (CBT) æåç­è³æºä¸­æ±²åï¼ä¿é²èç¶æ­·éåº¦æé¬±ççäººåçæ¯ææ§äºåãæ­¤å¤ï¼éé ç ç©¶éä»ç´¹äº Illuminate è³æåº«ï¼å¶ä¸­åå«åç¨® CBT æ¨¡çµï¼æå©æ¼åæ§åæ²»çå»ºè­°ãéé ç ç©¶ä½¿ç¨ F1 åæ¸ãæºç¢ºçãå¬åçãé¤å¼¦ç¸ä¼¼åº¦åé¢åå¬åçç Gisting è©ä¼°æ¿èº« (ROUGE) ç­ææ¨ï¼å¨ä¸åçæ¸¬è©¦éä¸­è©ä¼° LLM çè¡¨ç¾ï¼è­æäºå®åçæææ§ãéç¨®ç¶åæ¹æ³çµåäºå°ç«¯ç AI èæ¢å®çå¿çæ¹æ³ï¼çºå¿çä¿å¥æä¾äºæ°çå¯è½æ§ï¼ä¸¦å±ç¤ºäº LLM å¨é©æ°æé¬±çè¨ºæ·åæ²»çç­ç¥æ¹é¢çæ½åã

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v6 by TimothÃ©e Schmude, Laura Koesten, Torsten MÃ¶ller, Sebastian Tschiatschek

Every AI system that makes decisions about people has a group of stakeholders
that are personally affected by these decisions. However, explanations of AI
systems rarely address the information needs of this stakeholder group, who
often are AI novices. This creates a gap between conveyed information and
information that matters to those who are impacted by the system's decisions,
such as domain experts and decision subjects. To address this, we present the
"XAI Novice Question Bank," an extension of the XAI Question Bank containing a
catalog of information needs from AI novices in two use cases: employment
prediction and health monitoring. The catalog covers the categories of data,
system context, system usage, and system specifications. We gathered
information needs through task-based interviews where participants asked
questions about two AI systems to decide on their adoption and received verbal
explanations in response. Our analysis showed that participants' confidence
increased after receiving explanations but that their understanding faced
challenges. These included difficulties in locating information and in
assessing their own understanding, as well as attempts to outsource
understanding. Additionally, participants' prior perceptions of the systems'
risks and benefits influenced their information needs. Participants who
perceived high risks sought explanations about the intentions behind a system's
deployment, while those who perceived low risks rather asked about the system's
operation. Our work aims to support the inclusion of AI novices in
explainability efforts by highlighting their information needs, aims, and
challenges. We summarize our findings as five key implications that can inform
the design of future explanations for lay stakeholder audiences.

æè¦ï¼<paragraph>æ¯åå°äººååºæ±ºå®ç AI ç³»çµ±é½æä¸ç¾¤å©å®³éä¿äºº
åå°éäºæ±ºå®çè¦ªèº«å½±é¿ãç¶èï¼AI
ç³»çµ±çè§£éå¾å°è½æ»¿è¶³éç¾¤å©å®³éä¿äººçè³è¨éæ±ï¼èä»å
éå¸¸é½æ¯ AI æ°æãéé æäºå³éè³è¨è
åå°ç³»çµ±æ±ºç­å½±é¿çäººå£«ï¼ä¾å¦é åå°å®¶åæ±ºç­ä¸»é«ï¼éè¦çè³è¨ä¹éçè½å·®ãçºäºè§£æ±ºéååé¡ï¼æåæåºäº
ãXAI æ°æåé¡åº«ãï¼å®æ¯ XAI åé¡åº«çå»¶ä¼¸ï¼åå«ä¾èª AI æ°æå¨å©åä½¿ç¨æ¡ä¾ä¸­çè³è¨éæ±ç®éï¼å°±æ¥­
é æ¸¬åå¥åº·ç£æ¸¬ãç®éæ¶µèäºè³æã
ç³»çµ±èæ¯ãç³»çµ±ä½¿ç¨åç³»çµ±è¦æ ¼ç­é¡å¥ãæåééä»»ååè¨ªè«æ¶éè³è¨éæ±ï¼åèèå¨è¨ªè«ä¸­è©¢åäºå©å AI ç³»çµ±çåé¡ï¼ä»¥æ±ºå®æ¯å¦æ¡ç¨å®åï¼ä¸¦æ¶å°å£é ­
è§£éä½çºåæãæåçåæé¡¯ç¤ºï¼åèèå¨æ¶å°è§£éå¾ä¿¡å¿æææåï¼ä½ä»åççè§£å»é¢è¨ææ°ãéäºææ°åæ¬é£ä»¥æ¾å°è³è¨åè©ä¼°èªå·±ççè§£ï¼ä»¥åè©¦åå¤å
çè§£ãæ­¤å¤ï¼åèèå°ç³»çµ±é¢¨éªåå¥½èçåååé¥å½±é¿äºä»åçè³è¨éæ±ãèªçºé¢¨éªé«çåèèå°æ±è§£éç³»çµ±é¨ç½²èå¾çæåï¼èèªçºé¢¨éªä½çäººåè©¢åç³»çµ±ç
æä½ãæåçç ç©¶æ¨å¨ééå¼·èª¿ AI æ°æçè³è¨éæ±ãç®æ¨å
ææ°ï¼ä¾æ¯æå° AI æ°æç´å¥å¯è§£éæ§å·¥ä½ä¸­ãæåå°æåçç ç©¶çµæç¸½çµçºäºåééµåç¤ºï¼éäºåç¤ºå¯ä»¥çºæªä¾éå°éå°æ¥­å©å®³éä¿äººåç¾çè§£éè¨­è¨æä¾åèã</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet GÃ¼rkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éæ¼é²ï¼å°¤å¶æ¯å¨å¤§åèªè¨æ¨¡å (LLM) åçæå¼ AI çé åï¼çºååé åçæç¨éåäºæ°éå¾ï¼ä½å¶å¨åæ¥­æè²ä¸­çè§è²ä»æªè¢«ååæ¢è¨ãæ¬ç ç©¶é¦æ¬¡å¼å¥äºåºæºï¼ç¨ä»¥è©ä¼°ä¸åä¸»è¦ LLM çæè½ï¼åæ¬ OpenAI çæ¨¡å (GPT-3.5 TurboãGPT-4 å GPT-4 Turbo)ãGoogle çæ¨¡å (PaLM 2ãGemini 1.0 Pro) å Anthropic çæ¨¡å (Claude 2 å Claude 2.1)ï¼éäºæ¨¡åå°ç¨æ¼ç ç©¶çåæ¥­èª²ç¨å¥å­¸ç¨åºä¸­çééµèè©¦ GMATãæåçåæé¡¯ç¤ºï¼å¤§å¤æ¸ LLM çè¡¨ç¾é½åªæ¼äººé¡èçï¼å¶ä¸­ GPT-4 Turbo ä¸ååªæ¼å¶ä»æ¨¡åï¼æ´è¶è¶äºé å°åå­¸é¢çç ç©¶çå¹³ååæ¸ãééæ¡ä¾ç ç©¶ï¼æ¬ç ç©¶æ¢è¨äº GPT-4 Turbo å¨è§£éç­æ¡ãè©ä¼°åæãè¾¨è­é¯èª¤ãèª¿æ´èªªæåç¢çæ¿ä»£æå¢æ¹é¢çè½åãèåä¸ä»£çæ¬ç¸æ¯ï¼ææ°ç LLM çæ¬ GPT-4 TurboãClaude 2.1 å Gemini 1.0 Pro å¨æ¨çä»»åæ¹é¢æé¡¯èçé²æ­¥ï¼å¸é¡¯äºå¶å¨è§£æ±ºè¤éåé¡æ¹é¢çæ½åãåç®¡ AI å¨æè²ãè©éåè¼å°æ¹é¢çæ¿è«¾å¾æç¢ºï¼ä½ä»æææ°å­å¨ãæåçç ç©¶ä¸åé¡æäº LLM çå­¸è¡æ½åï¼ä¹å¼·èª¿äºå¨æè²ä¸­å¯©æéç¼åæç¨ AI çå¿è¦æ§ãé¨è AI æè¡çé²æ­¥ï¼å»ºç« AI äºåçæ¶æ§ååå®ãé©è­ AI çæçå§å®¹çæºç¢ºæ§ãç¢ºä¿å¨çåå°å¤åå­¸ç¿èçå­åæ¬ï¼ä»¥ååµé ä¸å AI æ¯æäººé¡å°æ¥­ç¥è­çæè²ç°å¢è³ééè¦ãæ¬ç ç©¶çºé²ä¸æ­¥æ¢ç´¢è² è²¬ä»»å°ä½¿ç¨ AI ä¾è±å¯æè²é«é©ä¸¦æ¹åèè©¦æºååè©éæ¹æ³å¥ å®äºåºç¤ã

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

æè¦ï¼é æ¸¬å è­·çæ¿ (ICU) çæ£çé¢å§æ­»äº¡çæ¯æçµè¨åºçµæçééµãAI å·²å±ç¾åºåªç°çæºç¢ºåº¦ï¼ä½å»ç¼ºä¹å¯è§£éæ§ãçºäºè§£æ±ºéååé¡ï¼æ¬ææåºäºä¸åå¯è§£éçå¤æ¨¡å¼æ­»äº¡çé æ¸¬å¨ (X-MMP)ï¼æ¡ç¨ææä¸å¯è§£éç AI æ¹å¼ï¼èç±å¤æ¨¡å¼ ICU è³æä¾é æ¸¬é¢å§æ­»äº¡çãæåå¨æ¶æ§ä¸­æ¡ç¨å¤æ¨¡å¼å­¸ç¿ï¼å¯ä»¥æ¥æ¶ä¾èªè¨åºè³æçç°è³ªè¼¸å¥ä¸¦ååºæ±ºç­ãæ­¤å¤ï¼æåå¼å¥äºä¸åå¯è§£éçæ¹æ³ï¼ä¹å°±æ¯åå±¤å³æ­è³ Transformerï¼ä½çº LRP æ¹æ³é©ç¶å°å»¶ä¼¸è³ Transformerï¼å°å¤æ¨¡å¼è¼¸å¥ç¢çè§£éï¼ä¸¦æ­é²æ­¸å æ¼é æ¸¬çé¡¯èç¹å¾µãæ­¤å¤ï¼æ¯åæ¨¡å¼å°è¨åºçµæçè²¢ç»å¯ä»¥è¦è¦ºåï¼åå©è¨åºé«å¸«äºè§£æ±ºç­èå¾ççç±ãæåæ ¹æ MIMIC-III å MIMIC-III æ³¢å½¢è³æåº«æ¯å°å­éå»ºæ§äºä¸åå¤æ¨¡å¼è³æéãå¨åºæºè³æéä¸çå¨é¢å¯¦é©è­æï¼æåæåºçæ¶æ§å¯ä»¥éæåççè©®éï¼ä¸¦å·åç«¶ç­åçé æ¸¬æºç¢ºåº¦ãç¹å¥æ¯ï¼æåçæ¶æ§å¯ä»¥è¼é¬å°è½ç§»å°å¶ä»è¨åºä»»åï¼éæå©æ¼å¨é«çä¿å¥ç ç©¶ä¸­ç¼ç¾ééµå ç´ ã

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian GeiÃler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, BjÃ¶rn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias KÃ¼ster, AndrÃ© Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

æè¦ï¼å¨éå»çåå¹´ä¸­ï¼ççå­¸ä¸­çäººå·¥æºæ§ (AI) æ¹æ³å·²å¤§å¹é²æ­¥ãç¶èï¼ç±æ¼è¨±å¤ææ°ï¼åæ¬å°ç ç©¶çµæè½åçºè¨åºè¨ºæ·ç¢åå¨æè¡åæ³è¦æ¹é¢çéç¤ï¼ä»¥åç¼ºä¹æ¨æºåä»é¢ï¼å°è´æ´åå°å¸¸è¦è¨åºå¯¦åä¸­é²å±ç·©æ¢ãéæ¾ä¸èä¾æåç¡éç EMPAIA è¨ç«æå°äºéäºææ°ãå¨æ­¤ï¼æåæä¾ EMPAIA çæå°±åç¶é©æè¨çæ¦è¿°ãEMPAIA æ´åäºççå­¸ AI çæç³»çµ±çååå©å®³éä¿äººï¼å³ççå­¸å®¶ãé»è¦ç§å­¸å®¶åç¢æ¥­ãå¨å¯ååä½ä¸ï¼æåå¶å®äºæè¡äºéæ§æ¨æºãAI æ¸¬è©¦åç¢åéç¼å»ºè­°ï¼ä»¥åå¯è§£éæ§æ¹æ³ãæåå¯¦ä½äºæ¨¡çµåä¸éæ¾åå§ç¢¼ç EMPAIA å¹³èºï¼ä¸¦æåæ´åäºä¾èª 8 åä¸åä¾æåç 14 ååºæ¼ AI çå½±ååææç¨ç¨å¼ï¼å±ç¤ºäºä¸åçæç¨ç¨å¼å¦ä½ä½¿ç¨å®ä¸çæ¨æºåä»é¢ãæååªåèæ®éæ±ï¼ä¸¦è©ä¼°äº AI å¨æ­æ´²åäºæ´²ç 14 åä¸åççå¯¦é©å®¤ä¸­çå¯¦éè¨åºæç¨ãé¤äºæè¡éç¼å¤ï¼æåéçºææå©å®³éä¿äººå»ºç«äºä¸åè«å£ï¼ä»¥åäº«æ¸ä½ççå­¸å AI çè³è¨åç¶é©ãåæ¥­ãè¨åºåå­¸è¡å©å®³éä¿äººç¾å¨å¯ä»¥æ¡ç¨ EMPAIA çå¸¸è¦éæ¾åå§ç¢¼ä»é¢ï¼éçºå¤§è¦æ¨¡æ¨æºååç°¡åæµç¨æä¾äºç¨ç¹çæ©æãéè¦é²ä¸æ­¥çåªåæè½ææä¸å»£æ³å°å»ºç«ä¾è¡å¯¦é©å®¤ä½¿ç¨ä¸­ç AI è¼å©ãçºæ­¤ï¼å·²æç«éçå©åæ EMPAIA Internationalï¼ä»¥ä½çºæ°¸çºåºç¤æ¶æ§ï¼ç¹¼çºé²è¡æ¨æºåï¼ä¸¦æ¯æ´å»£æ³å¯¦ä½åå¡å° AI è¼å©æ¸ä½ççå­¸çæªä¾ã

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

æè¦ï¼åäºå¯¦è§£é (CE) æè¡å·²å¼èµ·éæ³¨ï¼ä½çºä¸ç¨®çºè AI ç³»çµ±äºåçä½¿ç¨èæä¾è¦è§£çæ¹æ³ãéç¶å¨é«å­¸å½±ååèªåé§é§æ±½è»ç­é åå»£æ³ç ç©¶ï¼åå½¢åäºå¯¦è§£é (GCE) æ¹æ³ç¸å°è¼å°è¢«æ¢ç´¢ãGCE æç¢çä¸åé¡ä¼¼æ¼åå§åå½¢çæ°åå½¢ï¼ä¸¦æ ¹æåºç¤é æ¸¬æ¨¡åç¢çä¸åççµæãå¨éäº GCE æè¡ä¸­ï¼åç®¡å¨å¶ä»é åï¼ä¾å¦èè¡é¢¨æ ¼åèªç¶èªè¨å»ºæ¨¡ï¼ä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çæå°±ï¼ä½æ¤åºæ¼çææ©å¶çæè¡ç²å¾çéæ³¨ç¸å°æéãå°çæå¼è§£éå¨çåå¥½æºæ¼å®åå¨æ¨çæéç¢çåäºå¯¦å¯¦ä¾çè½åï¼å©ç¨è¼¸å¥åå½¢çèªä¸»ç²åæ¾åãåºæ¼ä¸è¿°çç±ï¼æåçç ç©¶å¼å¥äº RSGG-CEï¼ä¸ç¨®ç¨æ¼åäºå¯¦è§£éçæ°åç©©å¥é¨æ©åå½¢çæå¨ï¼è½å¤ å¾å­¸ç¿å°çæ½å¨ç©ºéä¸­ç¢çåäºå¯¦ç¯ä¾ï¼èæ®é¨åæåºççæåºåãæ­¤å¤ï¼æåé²è¡å®éåå®æ§åæï¼ä»¥æ¯è¼ RSGG-CE çæè½è SoA çæå¼è§£éå¨ï¼å¼·èª¿å¶å¢å¼·äºç¢çåçè§£éåé¸çè½åã

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

æè¦ï¼å¯è§£é AI çåæ©ä¹ä¸æ¯è®äººåå¨ä½¿ç¨åé¨ç½² AI æ¨¡åæååºæ´å¥½ãæ´ææºçæ±ºç­ãä½éè¦ä»ç´°è©ä¼°ä»¥è©ä¼°æ¯å¦å·²éå°æ­¤é æãç®åçè©ä¼°ä¸»è¦éä¸­å¨è§£éçæ¼ç®æ³ç¹æ§ï¼èæ¶åäººé¡åè©¦èçè©ä¼°éå¸¸æ¡ç¨ä¸»è§åé¡ä¾æ¸¬è©¦äººé¡å°è§£éæç¨æ§ççæ³ï¼èæ²æåºæ¼å®¢è§ææ¨åæ¸¬éãå¨éé å·¥ä½ä¸­ï¼æåè©ä¼°è§£éæ¯å¦å¯ä»¥å¨æ©å¨å­¸ç¿æ¨¡åéç¼çå¯¦éå ´æ¯ä¸­æ¹åäººé¡æ±ºç­å¶å®ãæåé²è¡äºä¸é æ¶åå½±åè³æçæ··åæ¹æ³ä½¿ç¨èç ç©¶ï¼ä»¥è©ä¼° SmoothGradãGradCAM åé è¨è§£éå¨å©åä»»åä¸­ç¢ççé¡¯èæ§åï¼æ¨¡åé¸æååäºå¯¦æ¨¡æ¬ãä»¤äººé©è¨çæ¯ï¼æåæ²æç¼ç¾ä»»ä½é¡¯èæ§åï¼å³ä½¿æ¯è¨­è¨çºææ¼çè§£ä¸é«åº¦æç¤ºç­æ¡çåæé è¨è§£éï¼è½è®ä½¿ç¨èå¨éäºä»»åä¸é¡¯èæ¹åçè­æãåç®¡å¦æ­¤ï¼è§£éç¢ºå¯¦æå©æ¼ä½¿ç¨èæ´æºç¢ºå°æè¿°æ¨¡åãéäºç¼ç¾æç¤ºæåè¦å°åºæ¼é¡¯èæ§çè§£éä¸­å¯è½å­å¨èª¤è§£çæç¨æ§ä¿æè¬¹æã

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

æè¦ï¼å¯è§£éæ§åå®å¨æ§å»ºç«ä¿¡ä»»ãéäºéè¦ä¸åæ¨¡åä¾å±ç¤ºä¸è´æ§åå¯é æ§ãçºäºå¯¦ç¾éäºï¼æå¿è¦ä½¿ç¨ååææ¸æåç¥è­ï¼ä¸¦ä½¿ç¨è AI æç¨ç¸éççµ±è¨åç¬¦è AI æ¹æ³ - å®ç¨ä½¿ç¨ä»»ä½ä¸ç¨®æ¹æ³é½ä¸æå¥æãå æ­¤ï¼æåä¸»å¼µä¸¦è©¦åè­æ NeuroSymbolic AI æ¹æ³æ´é©åæ¼ä½¿ AI æçºåä¿¡ä»»ç AI ç³»çµ±ãæåæåºäº CREST æ¡æ¶ï¼å±ç¤ºäºä¸è´æ§ãå¯é æ§ãä½¿ç¨èå±¤ç´çå¯è§£éæ§åå®å¨æ§æ¯å¦ä½å»ºç«å¨ NeuroSymbolic æ¹æ³ä¸çï¼è©²æ¹æ³ä½¿ç¨æ¸æåç¥è­ä¾æ¯æééµæç¨ï¼ä¾å¦å¥åº·åç¦ç¥ï¼çè¦æ±ãæ¬æéé»éæ³¨å¤§åèªè¨æ¨¡å (LLM)ï¼å çºå®æ¯ CREST æ¡æ¶ä¸­é¸æç AI ç³»çµ±ãLLM å å¶å¨èçå»£æ³çèªç¶èªè¨èç (NLP) å ´æ¯æ¹é¢çå¤åè½æ§èååç ç©¶äººå¡çéæ³¨ãä¾å¦ï¼ChatGPT å Google ç MedPaLM å·²æçºæä¾ä¸è¬åå¥åº·ç¸éæ¥è©¢ä¿¡æ¯çæ¥µæå¸æçå¹³å°ãåç®¡å¦æ­¤ï¼éäºæ¨¡åä»ç¶æ¯é»çå­ï¼åç®¡ç´å¥äºäººé¡åé¥åæä»¤å¼å°çèª¿æ´ãä¾å¦ï¼åç®¡å¶å®äºå®å¨é²è­·æªæ½ï¼ChatGPT ä»å¯è½ç¢çä¸å®å¨çåæãCREST æåºäºä¸ç¨®åççæ¹æ³ï¼å¨ NeuroSymbolic æ¡æ¶ä¸­å©ç¨ç¨åºååºæ¼åè¡¨çç¥è­ï¼ä»¥é¡æè LLM ç¸éçææ°ã

##### **Class-Discriminative Attention Maps for Vision Transformers**
2312.02364v3 by Lennart Brocki, Jakub Binda, Neo Christopher Chung

Importance estimators are explainability methods that quantify feature
importance for deep neural networks (DNN). In vision transformers (ViT), the
self-attention mechanism naturally leads to attention maps, which are sometimes
interpreted as importance scores that indicate which input features ViT models
are focusing on. However, attention maps do not account for signals from
downstream tasks. To generate explanations that are sensitive to downstream
tasks, we have developed class-discriminative attention maps (CDAM), a
gradient-based extension that estimates feature importance with respect to a
known class or a latent concept. CDAM scales attention scores by how relevant
the corresponding tokens are for the predictions of a classifier head. In
addition to targeting the supervised classifier, CDAM can explain an arbitrary
concept shared by selected samples by measuring similarity in the latent space
of ViT. Additionally, we introduce Smooth CDAM and Integrated CDAM, which
average a series of CDAMs with slightly altered tokens. Our quantitative
benchmarks include correctness, compactness, and class sensitivity, in
comparison to 7 other importance estimators. Vanilla, Smooth, and Integrated
CDAM excel across all three benchmarks. In particular, our results suggest that
existing importance estimators may not provide sufficient class-sensitivity. We
demonstrate the utility of CDAM in medical images by training and explaining
malignancy and biomarker prediction models based on lung Computed Tomography
(CT) scans. Overall, CDAM is shown to be highly class-discriminative and
semantically relevant, while providing compact explanations.

æè¦ï¼<paragraph>éè¦æ§ä¼°è¨å¨æ¯ä¸ç¨®å¯è§£éæ§æ¹æ³ï¼ç¨æ¼éåæ·±åº¦ç¥ç¶ç¶²è·¯ (DNN) çç¹å¾µéè¦æ§ãå¨è¦è¦ºTransformer (ViT) ä¸­ï¼èªææ³¨ææ©å¶èªç¶æå°è´æ³¨æååï¼æææå°å¶è§£éçºéè¦æ§åæ¸ï¼è¡¨ç¤º ViT æ¨¡åéæ³¨åªäºè¼¸å¥ç¹å¾µãç¶èï¼æ³¨æååä¸¦æªèæ®ä¾èªä¸æ¸¸ä»»åçä¿¡èãçºäºç¢çå°ä¸æ¸¸ä»»åææçè§£éï¼æåéç¼äºé¡å¥ååæ³¨æåå (CDAM)ï¼éæ¯ä¸ç¨®åºæ¼æ¢¯åº¦çæ´åï¼ç¨æ¼ä¼°è¨ç¸å°æ¼å·²ç¥é¡å¥ææ½å¨æ¦å¿µçç¹å¾µéè¦æ§ãCDAM æ ¹æå°æçç¬¦èèåé¡å¨é ­çé æ¸¬ç¸éç¨åº¦ï¼èª¿æ´æ³¨æååæ¸ãé¤äºéå°ç£ç£åé¡å¨å¤ï¼CDAM éå¯ä»¥ééæ¸¬é ViT çæ½å¨ç©ºéä¸­çç¸ä¼¼æ§ä¾è§£éé¸å®æ¨£æ¬å±æçä»»ææ¦å¿µãæ­¤å¤ï¼æåå¼å¥äºå¹³æ» CDAM åç©å CDAMï¼å®åå°ä¸ç³»åå·æç¥å¾®æ¹è®çç¬¦èç CDAM é²è¡å¹³åãæåçéååºæºåæ¬æ­£ç¢ºæ§ãç·æ¹æ§åé¡å¥æææ§ï¼èå¶ä» 7 åéè¦æ§ä¼°è¨å¨ç¸æ¯ãé¦èãå¹³æ»åç©å CDAM å¨ææä¸ååºæºä¸­è¡¨ç¾åºè²ãç¹å¥æ¯ï¼æåççµæè¡¨æç¾æçéè¦æ§ä¼°è¨å¨å¯è½ç¡æ³æä¾è¶³å¤ çé¡å¥æææ§ãæåééåºæ¼èºé¨é»è¦æ·å±¤ææ (CT) ææè¨ç·´åè§£éæ¡æ§è«ç¤åçç©æ¨è¨é æ¸¬æ¨¡åï¼è­æäº CDAM å¨é«å­¸å½±åä¸­çæç¨ãç¸½çä¾èªªï¼CDAM è¢«è­æå·æé«åº¦é¡å¥ååæ§åèªç¾©ç¸éæ§ï¼åææä¾ç°¡æ½çè§£éã</paragraph>

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

æè¦ï¼æ¬ç ç©¶è°æ¥äºå¨ COVID-19 ç«ææé´åä»¥åé¢æµæ­»äº¡çæ¶ï¼å·²é¨ç½²äººå·¥æºè½ (AI) æ¨¡åçæ§è½ãå¯è§£éæ§åç¨³å¥æ§ãä½ä¸ºåç±»ç ç©¶ä¸­çé¦ä¾ï¼æä»¬åç°è´å¶æ¯ç¥ç»ç½ç» (BNN) åæºè½è®­ç»ææ¯è®©æä»¬çæ¨¡åå¨æ°æ®åçéå¤§ååæ¶ä»è½ä¿ææ§è½ãæä»¬çç»æå¼ºè°äºå¼åç¨³å¥ç AI æ¨¡åçéè¦æ§ï¼å³ä½¿å¨å·ææææ§çæ¡ä»¶ä¸ï¼è¿äºæ¨¡åä¹è½å¹éæè¶è¶ä¸´åºå»ççé¢æµãæä»¬å¯¹æ¨¡åå¯è§£éæ§çæ¢ç´¢è¡¨æï¼éæºæ¨¡åä¼äº§çæ´å¤æ ·åä¸ä¸ªæ§åçè§£éï¼ä»èçªåºäºå¨ç°å®ä¸ççä¸´åºç¯å¢ä¸­æä¾è¯¦ç»ä¸ä¸ªæ§åè§è§£ç AI æ¨¡åçå¿è¦æ§ãæ­¤å¤ï¼æä»¬å¼ºè°äºéå AI æ¨¡åä¸­ä¸ç¡®å®æ§çéè¦æ§ï¼è¿ä½¿ä¸´åºå»çè½å¤æ ¹æ®å¯é çé¢æµååºæ´ææºçå³ç­ãæä»¬çç ç©¶æå¡å¨å»çä¿å¥ç AI ç ç©¶ä¸­ä¼åèèå®æ½ç§å­¦ï¼å¹¶ç¡®ä¿ AI è§£å³æ¹æ¡å¨ç°å®ä¸ççä¸´åºç¯å¢ä¸­å®ç¨ãæçä¸å¯æç»­ãéè¿è§£å³å»çä¿å¥ç¯å¢ä¸­çç¬ç¹ææåå¤ææ§ï¼ç ç©¶äººåå¯ä»¥å¼ååºæææ¹åä¸´åºå®è·µåæ£èé¢åç AI æ¨¡åã

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

æè¦ï¼èºçå è±åççæ­»äº¡äººæ¸ç 21%ï¼äºå¹´å­æ´»çå¾å¤§ç¨åº¦åæ±ºæ¼ççè¢«ç¼ç¾çéæ®µãæè¿çç ç©¶å·²è­æäººå·¥æºè½æ¹æ³å·æå¾ä¾è¡ææä¸­æºç¢ºåæ©è¨ºæ·èºççè½åãç¶èï¼æ­¤è­æå°æªè½åçºè¨åºå¯¦åï¼å¶ä¸­ä¸åéç¤æ¯ç¼ºä¹å¯è§£éçæ¨¡åãæ¬ç ç©¶æ¢è¨äºæç¨è®åèªåç·¨ç¢¼å¨ (VAE)ï¼ä¸ç¨®çæå¼äººå·¥æºè½æ¨¡åï¼æ¼èºççç¶ãå°æåºçæ¨¡åè¨ç·´æ¼å¾ LIDC-IDRI å¬å±æ¸æéä¸­æåç 3D é»è¦æ·å±¤ææçç¶ãééèé¡æ¢ç´¢äº VAE çæç 2D åççæ½å¨åéè¡¨ç¤ºï¼ä»¥è­æå¶åè³ªï¼ä¸¦ç¨æ¼èºçè¨ºæ·ç MLP åé¡å¨æ¨¡åï¼æä½³æ¨¡åéå°äº AUC 0.98 å 93.1% æºç¢ºåº¦çæåé²ææ¨ãèé¡åæé¡¯ç¤ºï¼VAE æ½å¨ç©ºéæ ¹æææç¾©çç¹å¾µçµæï¼åæ¬è«ç¤å¤§å°ãå½¢çãæ£èåæ¡æ§é¡å¥ï¼å°æ¡æ§åè¯æ§çç¶çæ¸æéåéãæåéåæ¬æ¨æºé«æ¯ VAE (GVAE) åæ´æ°ççå©åé· VAE (DirVAE) çæ¯è¼åæï¼å¾èç¨çå©åé·åä½åä»£åé©ï¼ä»¥ä¿é²å·æè§£éç¹å¾µè¡¨ç¤ºçæ´å·å¯è§£éæ§çæ½å¨ç©ºéãæå¾ï¼æåå±ç¤ºäºèè¨åºææç¾©çç¹å¾µè®åç¸æçæ½å¨ç©ºéæ©«è¶çæ½åã

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

æè¦ï¼ç¾æçåååé¡å¨è¼¸åºè§£éå·¥å·å¯åçºä¾è³´æ¼æ¨¡åå§é¨å­åæ¬éçç½çï¼ä»¥åèæ¨¡åç¡éçé»çãé¨è AI å¨é«çé åçä½¿ç¨å¢å ï¼å¯è§£éæ§å·¥å·çä½¿ç¨ä¹é¨ä¹å¢å ãç¾æé«å­¸å½±åè§£éçå·¥ä½éé»å¨æ¼ç½çå·¥å·ï¼ä¾å¦ gradcamãç¶èï¼åæå°é»çå·¥å·ææé¡¯çåªé»ï¼åæ¬è½å¤ èä»»ä½åé¡å¨ä¸èµ·ä½¿ç¨ï¼ä»¥åå»£æ³çé»çå·¥å·å¯ä¾é¸æãå¨æ¨æºå½±åä¸ï¼é»çå·¥å·èç½çä¸æ¨£ç²¾ç¢ºãå¨æ¬æä¸­ï¼æåæ¯è¼äºå¤ç¨®é»çæ¹æ³å¨è¦ç MRI è³æéä¸è gradcam çæè½ãæåè­æå¤§å¤æ¸é»çå·¥å·ä¸é©åè§£éé«å­¸å½±ååé¡ï¼ä¸¦è©³ç´°åæå¶ç¼ºé»çåå ãæåéè¡¨æä¸ç¨®é»çå·¥å·ï¼åºæ¼å æå¯è§£éæ§ç rexï¼è¡¨ç¾è \gradcam ä¸æ¨£å¥½ã

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v3 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

æè¦ï¼AI éç¼ç¤¾ç¾¤æ¥çå©ç¨ Hugging Face ç­è¨ç®¡ä¸­ä»æ©æ§æä¾ç¨æ¶ä¸å³çæ¨¡ååè¨ç·´è³æçç°¡æå­åæ¬éãéäºæ¨¡åå¸ééä½äºæ¸åè¬åç¨æ¶çæè¡é¨ç½²éç¤ï¼ä½å¯è½æè¢«ç¨æ¼è¨±å¤æ½å¨æå®³åéæ³çæ¹å¼ãå¨æ¬æä¸­ï¼æåèªªæ AI ç³»çµ±æ¢å¯ä»¥ãåå«ãå§å®¹ï¼åå¯ä»¥ä½çºéæ¾å¼å·¥å·ï¼éæåºäºè¿ä»çºæ­¢ææ£æçå¹³å°æ²»çææ°ä¹ä¸ãæåæä¾ Hugging FaceãGitHub å Civitai ç­ä¸åèªªææ§å¹³å°ä¸æ¸èµ·äºä»¶çæ¡ä¾ç ç©¶ï¼ä»¥æª¢è¦æ¨¡åå¸éå¦ä½å¯©æ ¸æ¨¡åãæ ¹ææ­¤åæï¼æåæ¦è¿°ç¢æ¥­çºåæå¯©æ ¸éæ±èéç¼çéè¦ï¼ä½ä»æéï¼å¯¦åï¼ææ¬ãå­ååä½¿ç¨éå¶ãèªååå§å®¹å¯©æ ¸åéæ¾æ¿ç­å¶å®ãéç¶ç¶åæ¿ç­ææ°ç¸ç¶å¯è§ï¼æåæå¾æåºä¸äºæ§æ³ï¼èªªæå¹³å°å¦ä½è½æ´å¥½å°åå¡è³æºï¼ä½çºè¬¹æãå¬å¹³ä¸é©åº¦çæ³è¦å­åé»ã

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

æè¦ï¼<paragraph>èæ¯åç®æ¨ï¼ééæåéäºè³è¨ï¼æ©å¨ææ·±åº¦å­¸ç¿ (ML/DL) åºæ¼èªä¸»æ¸æåæå·¥å·å¯ä»¥åå©è¨åºé«çåççç ç©¶äººå¡å¾è¤éçæ¸æéä¸­ç¼ç¾æ¨¡å¼åéä¿ãæè¿å·²ç¼è¡¨è¨±å¤åºæ¼ DL çåµå·¢ç (OC) æ¸æåæãéäºåæå¨çççååæ¹é¢ï¼ä¾å¦ï¼å®åæ¶åçå­é ååççé¡åï¼åæ¸æåæåè½æ¹é¢é«åº¦å¤æ¨£åãç¶èï¼ç®åç¼ºä¹å°éäºåæå¨éäºç¹å¾µå AI ä¿è­ (AIA) æ¹é¢çå¨é¢çè§£ãéç¯ç³»çµ±æ§åé¡§æ¨å¨ééæª¢è¦ç¾ææç»ä¸¦æç¢ºéæ³¨ééµç¹å¾µå AI ä¿è­è§é»ï¼ä¾å¡«è£éåç©ºç½ãæ¹æ³ï¼ä½¿ç¨ PRISMA æ¶æ§å¨ä¸åæåè³æåº«ä¸­é²è¡å¨é¢æå°ãåæååæ¬ 2015 å¹´è³ 2023 å¹´éç¼è¡¨æ¼åè¡è©å¯©æåçç ç©¶ãçµæï¼å¨åé¡§ä¸­ï¼ç¸½å±æª¢è¦äº 96 é ç± DL é©åçåæãç ç©¶çµææ­ç¤ºäºå¹¾åéæ¼ç± DL é©åçåµå·¢çæ¸æåæçéè¦è¦è§£ï¼- å¤§å¤æ¸ç ç©¶ 71%ï¼96 é ä¸­æ 68 é ï¼å°æ³¨æ¼æª¢æ¸¬åè¨ºæ·ï¼èæ²æç ç©¶æ¢è¨ OC çé æ¸¬åé é²ã- éäºåæä¸»è¦åºæ¼ä¾èªéå¤åæç¾¤çæ¨£æ¬ï¼75%ï¼96 é ç ç©¶ä¸­ç 72 é ï¼ï¼ï¼åéæ¼æåå°çä½ç½®æåå®¶ã- åªæå°é¨åç ç©¶ï¼å 33%ï¼96 é ç ç©¶ä¸­ç 32 é ï¼å·è¡æ´ååæï¼å¶ä¸­å¤§å¤æ¸ä½¿ç¨åè³ªæ¸æï¼è¨åºæçµå­¸ï¼ã- å¼å¾æ³¨æçæ¯ï¼åªæ 8.3%ï¼96 é ç ç©¶ä¸­ç 8 é ï¼ä½¿ç¨å¤é¨åå¤åæ¸æéé©è­äºå¶æ¨¡åï¼å¼·èª¿äºå å¼·æ¨¡åé©è­çå¿è¦æ§ï¼ä»¥å- å° AIA ç´å¥ççæ¸æåæä»èæ¼éå¸¸æ©æçéæ®µï¼åªæ 2.1%ï¼96 é ç ç©¶ä¸­ç 2 é ï¼ééå¯è§£éæ§æç¢ºæ¢è¨äº AIAã</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

æè¦ï¼<paragraph>è§£éæ§æ¯æ·±åº¦å­¸ç¿ä¸­é·æçææ°ï¼ç¹å¥æ¯å¨é«çä¿å¥ç­é«é¢¨éªé åãå¸¸è¦çè§£éæ§æ¹æ³æå¼·èª¿é©å AI æ¨¡åæ±ºç­çå½±åååãç¶èï¼äººé¡å¾å¤§ç¨åº¦ä¾è³´èªè¨ä¾å³éä¸åæ¯ãå¨åªè£¡ãï¼éæãæ¯ä»éº¼ãçè§£éãæ­¤å¤ï¼å¤§å¤æ¸è§£éæ§æ¹æ³é½å°æ³¨æ¼è§£éåå¥ AI é æ¸¬ï¼èä¸æ¯æè¿° AI æ¨¡åä¸è¬ä½¿ç¨çç¹å¾µãå¾èå°æ¼æ¨¡ååè³æéç¨½æ ¸ç¹å¥æç¨ï¼çè³å¯è½å¨ AI æä¾æç¨æ¼æ°ç©ä»»åæç¢çç¥è­ãå¨æ­¤ï¼æåæåºä¸åä½¿ç¨è¦è¦ºèªè¨æ¨¡åä¾è¾¨è­è¦è¦ºåé¡ä»»åçèªè¨æè¿°ç¬¦çè§£éæ§ç­ç¥ãééå©ç¨å½±ååæå­ä¹éé åè¨ç·´çè¯ååµå¥ç©ºéï¼æåçåæ³å°æ°çåé¡ä»»åä¼°è¨çºä¸åç·æ§æå­çµåï¼å°è´æ¯åæå­é½ææ¬éï¼è¡¨ç¤ºå®èåºæ¼è¦è¦ºçåé¡å¨å°é½ãæåä½¿ç¨å©åé«å­¸å½±ååé¡ä»»åä¾è©ä¼°æåçåæ³ï¼æåç¼ç¾ç¢ççæè¿°ç¬¦å¨å¾å¤§ç¨åº¦ä¸èè¨åºç¥è­ä¸è´ï¼åç®¡ç¼ºä¹ç¹å®é åçèªè¨è¨ç·´ãç¶èï¼æåçåæ³ä¹ç¼ç¾äºæç¨å¬éè³æéä¸­çãæ·å¾é£ç·ãçå¯è½æ§ãçºäºéå°è§£éæ§çåè½æ§è¡¡éï¼æåé²è¡äºä¸é è©¦é©è®èç ç©¶ï¼ç¼ç¾ AI è­å¥çæå­è½è®éå°å®¶äººé¡å¨éå¹³å¡çå±¤ç´å·è¡å°æ¥­çé«çä»»åãç¸½ä¹ï¼æåççµæå¼·èª¿äºä½¿ç¨å¤æ¨¡å¼åºç¤æ¨¡åä¾æä¾ç´è§çãåºæ¼èªè¨çè¦è¦ºä»»åè§£éçæ½åã</paragraph>

##### **Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**
2311.02115v2 by Emma A. M. Stanley, Raissa Souza, Anthony Winder, Vedant Gulve, Kimberly Amador, Matthias Wilms, Nils D. Forkert

Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.

æè¦ï¼<paragraph>ä½¿ç¨é«çå½±åè¨ç·´çäººå·¥æºæ§ (AI) æ¨¡åï¼ç¨æ¼è¨åºä»»åæï¼å¸¸æå¨æè½ä¸å±ç¾åºæ¬¡ç¾¤é«ä¹éçå·®ç°ï¼å½¢æåè¦ãç±æ¼ä¸¦éææçå¯¦ä¸çé«çå½±åè³æä¸­çåè¦ä¾æºé½å®¹æè¾¨è­ï¼å æ­¤å¨é¢è©ä¼°éäºåè¦æ¯å¦ä½ç·¨ç¢¼å°æ¨¡åä¸­ï¼ä»¥ååè¦ç·©è§£æ¹æ³å¨æ¹åæè½å·®ç°æ¹é¢çè½åï¼æ¯ä¸é ææ°ãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸åæ°ç©çåææ¶æ§ï¼ç¨æ¼ç³»çµ±åä¸å®¢è§å°èª¿æ¥é«çå½±åä¸­çåè¦å° AI æ¨¡åçå½±é¿ãæåéç¼ä¸¦æ¸¬è©¦äºéåæ¶æ§ï¼ä»¥é²è¡åæ§çé»è¦æ¨¡æ¬è©¦é©ï¼ä½¿ç¨ä¸åå·¥å·ä¾è©ä¼°é«çå½±å AI ä¸­çåè¦ï¼è©²å·¥å·ç¨æ¼ç¢çå·æå·²ç¥ç¾çå½±é¿ååè¦ä¾æºçåæç£å±æ¯å½±åãå¯è¡æ§ééä½¿ç¨ä¸ååäºå¯¦åè¦æå¢ä¾è¡¡éæ¨¡æ¬åè¦ææå°å·ç©ç¥ç¶ç¶²è·¯ (CNN) åé¡å¨åä¸ååè¦ç·©è§£ç­ç¥çå½±é¿ï¼ä¸¦å±ç¤ºåºä¾ãåæé¡¯ç¤ºï¼ç¶ CNN å¨åæè³æéä¸åè¨æï¼æ¨¡æ¬åè¦æå°è´é æçæ¬¡ç¾¤é«æè½å·®ç°ãæ­¤å¤ï¼éæ°å æ¬è¢«èªçºæ¯æ­¤è¨­å®ä¸­ææåçåè¦ç·©è§£ç­ç¥ï¼æåå±ç¤ºäºè§£éæ§ AI æ¹æ³å¦ä½åå©ä½¿ç¨éåæ¶æ§èª¿æ¥æ¨¡åä¸­åè¦çè¡¨ç¾ãéç¼å¬å¹³ç AI æ¨¡åæ¯ä¸é éå¤§çææ°ï¼å çºé«çå½±åè³æéä¸­å¯è½å­å¨è¨±å¤ä¸ç¶å¸¸æªç¥çåè¦ä¾æºãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼ç¨æ¼å®¢è§å°ç ç©¶åè¦åç·©è§£ç­ç¥å°æ·±åº¦å­¸ç¿ç®¡ç·çå½±é¿ï¼éå¯ä»¥æ¯æ´å¥å¨ä¸è² è²¬ä»»çè¨åº AI çéç¼ã</paragraph>

##### **Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**
2310.19174v1 by Adam White, Margarita Saranti, Artur d'Avila Garcez, Thomas M. H. Hope, Cathy J. Price, Howard Bowman

Machine learning offers great potential for automated prediction of
post-stroke symptoms and their response to rehabilitation. Major challenges for
this endeavour include the very high dimensionality of neuroimaging data, the
relatively small size of the datasets available for learning, and how to
effectively combine neuroimaging and tabular data (e.g. demographic information
and clinical characteristics). This paper evaluates several solutions based on
two strategies. The first is to use 2D images that summarise MRI scans. The
second is to select key features that improve classification accuracy.
Additionally, we introduce the novel approach of training a convolutional
neural network (CNN) on images that combine regions-of-interest extracted from
MRIs, with symbolic representations of tabular data. We evaluate a series of
CNN architectures (both 2D and a 3D) that are trained on different
representations of MRI and tabular data, to predict whether a composite measure
of post-stroke spoken picture description ability is in the aphasic or
non-aphasic range. MRI and tabular data were acquired from 758 English speaking
stroke survivors who participated in the PLORAS study. The classification
accuracy for a baseline logistic regression was 0.678 for lesion size alone,
rising to 0.757 and 0.813 when initial symptom severity and recovery time were
successively added. The highest classification accuracy 0.854 was observed when
8 regions-of-interest was extracted from each MRI scan and combined with lesion
size, initial severity and recovery time in a 2D Residual Neural Network.Our
findings demonstrate how imaging and tabular data can be combined for high
post-stroke classification accuracy, even when the dataset is small in machine
learning terms. We conclude by proposing how the current models could be
improved to achieve even higher levels of accuracy using images from hospital
scanners.

æè¦ï¼æ©å¨å­¸ç¿çºèªåé æ¸¬ä¸­é¢¨å¾ççåå¶å°å¾©å¥çåææä¾äºæ¥µå¤§çæ½åãéé å·¥ä½çéå¤§ææ°åæ¬ç¥ç¶å½±åè³æçç¶­åº¦éå¸¸é«ãå¯ç¨æ¼å­¸ç¿çè³æéè¦æ¨¡ç¸å°è¼å°ï¼ä»¥åå¦ä½ææçµåç¥ç¶å½±ååè¡¨æ ¼è³æï¼ä¾å¦äººå£çµ±è¨è³è¨åè¨åºç¹å¾µï¼ãæ¬ææ ¹æå©ç¨®ç­ç¥è©ä¼°äºå¤ç¨®è§£æ±ºæ¹æ¡ãç¬¬ä¸ç¨®æ¯ä½¿ç¨ç¸½çµ MRI ææç 2D å½±åãç¬¬äºç¨®æ¯é¸ææå©æ¼æé«åé¡ç²¾ç¢ºåº¦çééµç¹å¾µãæ­¤å¤ï¼æåå¼å¥äºå¨çµåå¾ MRI ä¸­æåçæèè¶£ååèè¡¨æ ¼è³æçç¬¦èè¡¨ç¤ºçå½±åä¸è¨ç·´å·ç©ç¥ç¶ç¶²è·¯ (CNN) çæ°ç©æ¹æ³ãæåè©ä¼°äºä¸ç³»å CNN æ¶æ§ï¼2D å 3Dï¼ï¼éäºæ¶æ§å¨ MRI åè¡¨æ ¼è³æçä¸åè¡¨ç¤ºä¸é²è¡è¨ç·´ï¼ä»¥é æ¸¬ä¸­é¢¨å¾å£è¿°åçæè¿°è½åçç¶åæ¸¬éæ¯å¦å¨å¤±èªçæéå¤±èªçç¯åå§ãMRI åè¡¨æ ¼è³æä¾èª 758 ååè PLORAS ç ç©¶çè±èªä¸­é¢¨åå­èãåéå°çç¶å¤§å°çåºç·éè¼¯è¿´æ­¸åé¡æºç¢ºåº¦çº 0.678ï¼ç¶ä¾åºå å¥åå§ççå´éç¨åº¦åæ¢å¾©æéæï¼ä¸åè³ 0.757 å 0.813ãå¨å¾æ¯å MRI ææä¸­æå 8 åæèè¶£ååä¸¦å¨ 2D æ®å·®ç¥ç¶ç¶²è·¯ä¸­èçç¶å¤§å°ãåå§å´éç¨åº¦åæ¢å¾©æéçµåæï¼è§å¯å°æé«çåé¡æºç¢ºåº¦ 0.854ãæåçç ç©¶çµæå±ç¤ºäºå¦ä½å°å½±ååè¡¨æ ¼è³æçµåèµ·ä¾ä»¥ç²å¾é«æ¼ä¸­é¢¨å¾åé¡æºç¢ºåº¦ï¼å³ä½¿å¨æ©å¨å­¸ç¿è¡èªä¸­è³æéå¾å°çææ³ä¸ä¹æ¯å¦æ­¤ãæå¾ï¼æåæåºå¦ä½æ¹é²ç®åçæ¨¡åï¼ä»¥ä½¿ç¨ä¾èªé«é¢ææåçå½±åä¾å¯¦ç¾æ´é«çæºç¢ºåº¦ã

##### **Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**
2310.01828v2 by Hossein Shreim, Abdul Karim Gizzini, Ali J. Ghandour

eXplainable Artificial Intelligence (XAI) has emerged as an essential
requirement when dealing with mission-critical applications, ensuring
transparency and interpretability of the employed black box AI models. The
significance of XAI spans various domains, from healthcare to finance, where
understanding the decision-making process of deep learning algorithms is
essential. Most AI-based computer vision models are often black boxes; hence,
providing explainability of deep neural networks in image processing is crucial
for their wide adoption and deployment in medical image analysis, autonomous
driving, and remote sensing applications. Recently, several XAI methods for
image classification tasks have been introduced. On the contrary, image
segmentation has received comparatively less attention in the context of
explainability, although it is a fundamental task in computer vision
applications, especially in remote sensing. Only some research proposes
gradient-based XAI algorithms for image segmentation. This paper adapts the
recent gradient-free Sobol XAI method for semantic segmentation. To measure the
performance of the Sobol method for segmentation, we propose a quantitative XAI
evaluation method based on a learnable noise model. The main objective of this
model is to induce noise on the explanation maps, where higher induced noise
signifies low accuracy and vice versa. A benchmark analysis is conducted to
evaluate and compare performance of three XAI methods, including Seg-Grad-CAM,
Seg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation
technique. This constitutes the first attempt to run and evaluate XAI methods
using high-resolution satellite images.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) å·²æçºèçä»»åééµæç¨ç¨å¼æçä¸é åºæ¬éæ±ï¼ç¢ºä¿æ¡ç¨é»ç AI æ¨¡åçéæåº¦åå¯è§£éæ§ãXAI çéè¦æ§æ¶µèå¾é«çä¿å¥å°éèçåç¨®é åï¼å¨éäºé åä¸­ï¼äºè§£æ·±åº¦å­¸ç¿æ¼ç®æ³çæ±ºç­å¶å®éç¨è³ééè¦ãå¤§å¤æ¸åºæ¼ AI çé»è¦è¦è¦ºæ¨¡åéå¸¸æ¯é»çå­ï¼å æ­¤ï¼å¨å½±åèçä¸­æä¾æ·±åº¦ç¥ç¶ç¶²è·¯çå¯è§£éæ§å°æ¼å¶å¨é«å­¸å½±ååæãèªåé§é§åéæ¸¬æç¨ä¸­çå»£æ³æ¡ç¨åé¨ç½²è³ééè¦ãæè¿ï¼å·²éå°å½±ååé¡ä»»åå¼å¥äºå¤ç¨® XAI æ¹æ³ãç¸åå°ï¼å½±ååå²å¨å¯è§£éæ§çèæ¯ä¸åå°çéæ³¨ç¸å°è¼å°ï¼åç®¡å®æ¯é»è¦è¦è¦ºæç¨ä¸­çä¸é åºæ¬ä»»åï¼ç¹å¥æ¯å¨éæ¸¬ä¸­ãåªæé¨åç ç©¶æåºç¨æ¼å½±ååå²çåºæ¼æ¢¯åº¦ç XAI æ¼ç®æ³ãæ¬ææ¹ç·¨äºæè¿çç¡æ¢¯åº¦ Sobol XAI æ¹æ³ä»¥é²è¡èªæåå²ãçºäºè¡¡é Sobol æ¹æ³å¨åå²ä¸­çæè½ï¼æåæåºäºä¸ç¨®åºæ¼å¯å­¸ç¿éè¨æ¨¡åçå®é XAI è©ä¼°æ¹æ³ãæ­¤æ¨¡åçä¸»è¦ç®çæ¯å¨è§£éåä¸èªç¼éè¨ï¼å¶ä¸­è¼é«çèªç¼éè¨è¡¨ç¤ºè¼ä½çæºç¢ºåº¦ï¼åä¹äº¦ç¶ãé²è¡åºæºåæä»¥è©ä¼°åæ¯è¼ä¸ç¨® XAI æ¹æ³çæè½ï¼åæ¬ Seg-Grad-CAMãSeg-Grad-CAM++ å Seg-Sobolï¼ä¸¦ä½¿ç¨ææåºçåºæ¼éè¨çè©ä¼°æè¡ãéæ§æäºä½¿ç¨é«è§£æåº¦è¡æå½±åå·è¡åè©ä¼° XAI æ¹æ³çé¦æ¬¡åè©¦ã

##### **Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**
2311.01463v1 by Muhammad Aurangzeb Ahmad, Ilker Yaramis, Taposh Dutta Roy

Large language models have proliferated across multiple domains in as short
period of time. There is however hesitation in the medical and healthcare
domain towards their adoption because of issues like factuality, coherence, and
hallucinations. Give the high stakes nature of healthcare, many researchers
have even cautioned against its usage until these issues are resolved. The key
to the implementation and deployment of LLMs in healthcare is to make these
models trustworthy, transparent (as much possible) and explainable. In this
paper we describe the key elements in creating reliable, trustworthy, and
unbiased models as a necessary condition for their adoption in healthcare.
Specifically we focus on the quantification, validation, and mitigation of
hallucinations in the context in healthcare. Lastly, we discuss how the future
of LLMs in healthcare may look like.

æè¦ï¼å¤§åèªè¨æ¨¡åå¨ç­æéå§å·²å¨å¤åé åä¸­å¤§éæ¿å¢ãç¶èï¼ç±æ¼äºå¯¦æ§ãé£è²«æ§åå¹»è¦ºç­åé¡ï¼é«çåä¿å¥é åå°å¶æ¡ç¨ç¶è±«ä¸æ±ºãéæ¼é«çä¿å¥çé«é¢¨éªæ§è³ªï¼è¨±å¤ç ç©¶äººå¡çè³è­¦åä¸è¦ä½¿ç¨å®ï¼ç´å°éäºåé¡å¾å°è§£æ±ºãå¨é«çä¿å¥ä¸­å¯¦æ½åé¨ç½² LLM çééµæ¯ä½¿éäºæ¨¡åå¼å¾ä¿¡è³´ãéæï¼ç¡å¯è½å¤ï¼ä¸å¯è§£éãå¨æ¬æä¸­ï¼æåæè¿°äºå»ºç«å¯é ãå¼å¾ä¿¡è³´åç¡åè¦æ¨¡åçééµè¦ç´ ï¼ä½çºå®åå¨é«çä¿å¥ä¸­å¾å°æ¡ç¨çå¿è¦æ¢ä»¶ãå·é«ä¾èªªï¼æåå°æ³¨æ¼å¨é«çä¿å¥èæ¯ä¸å°å¹»è¦ºé²è¡éåãé©è­åç·©è§£ãæå¾ï¼æåè¨è«äº LLM å¨é«çä¿å¥ä¸­çæªä¾å¯è½æ¯ä»éº¼æ¨£å­ã

##### **When to Trust AI: Advances and Challenges for Certification of Neural Networks**
2309.11196v1 by Marta Kwiatkowska, Xiyue Zhang

Artificial intelligence (AI) has been advancing at a fast pace and it is now
poised for deployment in a wide range of applications, such as autonomous
systems, medical diagnosis and natural language processing. Early adoption of
AI technology for real-world applications has not been without problems,
particularly for neural networks, which may be unstable and susceptible to
adversarial examples. In the longer term, appropriate safety assurance
techniques need to be developed to reduce potential harm due to avoidable
system failures and ensure trustworthiness. Focusing on certification and
explainability, this paper provides an overview of techniques that have been
developed to ensure safety of AI decisions and discusses future challenges.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å·²å¿«éé²æ­¥ï¼ç¾å·²æºåé¨ç½²æ¼å»£æ³çæç¨ç¨å¼ä¸­ï¼ä¾å¦èªä¸»ç³»çµ±ãé«çè¨ºæ·åèªç¶èªè¨èçãåæ©æ¡ç¨ AI æè¡æ¼å¯¦éæç¨ç¨å¼ä¸¦éæ²æåé¡ï¼ç¹å¥æ¯å°æ¼ç¥ç¶ç¶²è·¯ï¼å®å¯è½ä¸ç©©å®ä¸å®¹æåå°å°ææ§ç¯ä¾çå½±é¿ãå¾é·é ä¾çï¼éè¦éç¼é©ç¶çå®å¨ä¿è­æè¡ï¼ä»¥æ¸å°å å¯é¿åçç³»çµ±æéèé æçæ½å¨å·å®³ï¼ä¸¦ç¢ºä¿å¯ä¿¡è³´æ§ãæ¬æèéæ¼èªè­åå¯è§£éæ§ï¼æ¦è¿°äºå·²éç¼ç¨æ¼ç¢ºä¿ AI æ±ºç­å®å¨çæè¡ï¼ä¸¦è¨è«æªä¾çææ°ã


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-11**|**Gradual Fine-Tuning with Graph Routing for Multi-Source Unsupervised Domain Adaptation**|Yao Ma et.al.|[2411.07185v1](http://arxiv.org/abs/2411.07185v1)|null|
|**2024-11-11**|**A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19**|Vedant Khandelwal et.al.|[2411.07163v1](http://arxiv.org/abs/2411.07163v1)|null|
|**2024-11-11**|**A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs**|Myeongsoo Kim et.al.|[2411.07098v1](http://arxiv.org/abs/2411.07098v1)|null|
|**2024-11-11**|**Bridge: A Unified Framework to Knowledge Graph Completion via Language Models and Knowledge Representation**|Qiao Qiao et.al.|[2411.06660v1](http://arxiv.org/abs/2411.06660v1)|null|
|**2024-11-10**|**CausalStock: Deep End-to-end Causal Discovery for News-driven Stock Movement Prediction**|Shuqi Li et.al.|[2411.06391v1](http://arxiv.org/abs/2411.06391v1)|null|
|**2024-11-09**|**Analyzing the Evolution of Graphs and Texts**|Xingzhi Guo et.al.|[2411.06295v1](http://arxiv.org/abs/2411.06295v1)|null|
|**2024-11-09**|**An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models**|Fatemeh Shiri et.al.|[2411.06048v1](http://arxiv.org/abs/2411.06048v1)|[link](https://github.com/fatemehshiri/spatial-mm)|
|**2024-11-08**|**Mitigating Hallucination with ZeroG: An Advanced Knowledge Management Engine**|Anantha Sharma et.al.|[2411.05936v1](http://arxiv.org/abs/2411.05936v1)|null|
|**2024-11-08**|**SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark**|Sithursan Sivasubramaniam et.al.|[2411.05521v1](http://arxiv.org/abs/2411.05521v1)|null|
|**2024-11-08**|**EUREKHA: Enhancing User Representation for Key Hackers Identification in Underground Forums**|Abdoul Nasser Hassane Amadou et.al.|[2411.05479v1](http://arxiv.org/abs/2411.05479v1)|[link](https://github.com/jumbo110/eurekha)|
|**2024-11-08**|**When are 1.58 bits enough? A Bottom-up Exploration of BitNet Quantization**|Jacob Nielsen et.al.|[2411.05882v1](http://arxiv.org/abs/2411.05882v1)|null|
|**2024-11-08**|**Exploring the Alignment Landscape: LLMs and Geometric Deep Models in Protein Representation**|Dong Shu et.al.|[2411.05316v1](http://arxiv.org/abs/2411.05316v1)|[link](https://github.com/tizzzzy/llm-gdm-alignment)|
|**2024-11-06**|**LEGO-GraphRAG: Modularizing Graph-based Retrieval-Augmented Generation for Design Space Exploration**|Yukun Cao et.al.|[2411.05844v1](http://arxiv.org/abs/2411.05844v1)|null|
|**2024-11-06**|**MEG: Medical Knowledge-Augmented Large Language Models for Question Answering**|Laura Cabello et.al.|[2411.03883v2](http://arxiv.org/abs/2411.03883v2)|[link](https://github.com/lautel/meg)|
|**2024-11-06**|**The American Sign Language Knowledge Graph: Infusing ASL Models with Linguistic Knowledge**|Lee Kezar et.al.|[2411.03568v1](http://arxiv.org/abs/2411.03568v1)|null|
|**2024-11-05**|**Graph-DPEP: Decomposed Plug and Ensemble Play for Few-Shot Document Relation Extraction with Graph-of-Thoughts Reasoning**|Tao Zhang et.al.|[2411.02864v1](http://arxiv.org/abs/2411.02864v1)|null|
|**2024-11-05**|**Multimodal Commonsense Knowledge Distillation for Visual Question Answering**|Shuo Yang et.al.|[2411.02722v1](http://arxiv.org/abs/2411.02722v1)|null|
|**2024-11-04**|**Geometry of orofacial neuromuscular signals: speech articulation decoding using surface electromyography**|Harshavardhana T. Gowda et.al.|[2411.02591v1](http://arxiv.org/abs/2411.02591v1)|[link](https://github.com/HarshavardhanaTG/geometryOfOrofacialNeuromuscularSystem)|
|**2024-11-04**|**GraphXAIN: Narratives to Explain Graph Neural Networks**|Mateusz Cedro et.al.|[2411.02540v2](http://arxiv.org/abs/2411.02540v2)|[link](https://github.com/ADMAntwerp/GraphXAIN)|
|**2024-11-04**|**Improving Scientific Hypothesis Generation with Knowledge Grounded Large Language Models**|Guangzhi Xiong et.al.|[2411.02382v1](http://arxiv.org/abs/2411.02382v1)|null|
|**2024-11-04**|**Can Language Models Enable In-Context Database?**|Yu Pan et.al.|[2411.01807v1](http://arxiv.org/abs/2411.01807v1)|null|
|**2024-11-03**|**Graph-based Confidence Calibration for Large Language Models**|Yukun Li et.al.|[2411.02454v1](http://arxiv.org/abs/2411.02454v1)|null|
|**2024-11-03**|**Ontology Population using LLMs**|Sanaz Saki Norouzi et.al.|[2411.01612v1](http://arxiv.org/abs/2411.01612v1)|null|
|**2024-11-03**|**Pre-trained Molecular Language Models with Random Functional Group Masking**|Tianhao Peng et.al.|[2411.01401v1](http://arxiv.org/abs/2411.01401v1)|null|
|**2024-11-01**|**Narrative Analysis of True Crime Podcasts With Knowledge Graph-Augmented Large Language Models**|Xinyi Leng et.al.|[2411.02435v1](http://arxiv.org/abs/2411.02435v1)|null|
|**2024-11-01**|**WLPlan: Relational Features for Symbolic Planning**|Dillon Z. Chen et.al.|[2411.00577v1](http://arxiv.org/abs/2411.00577v1)|null|
|**2024-11-01**|**GRS-QA -- Graph Reasoning-Structured Question Answering Dataset**|Anish Pahilajani et.al.|[2411.00369v3](http://arxiv.org/abs/2411.00369v3)|null|
|**2024-11-01**|**Evaluating the Impact of Lab Test Results on Large Language Models Generated Differential Diagnoses from Clinical Case Vignettes**|Balu Bhasuran et.al.|[2411.02523v1](http://arxiv.org/abs/2411.02523v1)|null|
|**2024-10-31**|**Compositional Automata Embeddings for Goal-Conditioned Reinforcement Learning**|Beyazit Yalcinkaya et.al.|[2411.00205v1](http://arxiv.org/abs/2411.00205v1)|null|
|**2024-10-31**|**Building Multi-Agent Copilot towards Autonomous Agricultural Data Management and Analysis**|Yu Pan et.al.|[2411.00188v1](http://arxiv.org/abs/2411.00188v1)|null|
|**2024-10-31**|**Exploring the Knowledge Mismatch Hypothesis: Hallucination Propensity in Small Models Fine-tuned on Data from Larger Models**|Phil Wee et.al.|[2411.00878v1](http://arxiv.org/abs/2411.00878v1)|null|
|**2024-10-31**|**Failure Modes of LLMs for Causal Reasoning on Narratives**|Khurram Yamin et.al.|[2410.23884v1](http://arxiv.org/abs/2410.23884v1)|[link](https://github.com/shantanu95/llm_causal_reasoning)|
|**2024-10-31**|**Plan-on-Graph: Self-Correcting Adaptive Planning of Large Language Model on Knowledge Graphs**|Liyi Chen et.al.|[2410.23875v1](http://arxiv.org/abs/2410.23875v1)|[link](https://github.com/liyichen-cly/pog)|
|**2024-10-31**|**LLaMo: Large Language Model-based Molecular Graph Assistant**|Jinyoung Park et.al.|[2411.00871v1](http://arxiv.org/abs/2411.00871v1)|[link](https://github.com/mlvlab/llamo)|
|**2024-10-31**|**End-to-End Ontology Learning with Large Language Models**|Andy Lo et.al.|[2410.23584v1](http://arxiv.org/abs/2410.23584v1)|[link](https://github.com/andylolu2/ollm)|
|**2024-10-30**|**Graph-Augmented Relation Extraction Model with LLMs-Generated Support Document**|Vicky Dong et.al.|[2410.23452v1](http://arxiv.org/abs/2410.23452v1)|null|
|**2024-10-30**|**FlowLLM: Flow Matching for Material Generation with Large Language Models as Base Distributions**|Anuroop Sriram et.al.|[2410.23405v1](http://arxiv.org/abs/2410.23405v1)|[link](https://github.com/facebookresearch/flowmm)|
|**2024-10-30**|**EMMA: End-to-End Multimodal Model for Autonomous Driving**|Jyh-Jing Hwang et.al.|[2410.23262v2](http://arxiv.org/abs/2410.23262v2)|null|
|**2024-10-30**|**ProTransformer: Robustify Transformers via Plug-and-Play Paradigm**|Zhichao Hou et.al.|[2410.23182v1](http://arxiv.org/abs/2410.23182v1)|null|
|**2024-10-30**|**Semantic Enrichment of the Quantum Cascade Laser Properties in Text- A Knowledge Graph Generation Approach**|Deperias Kerre et.al.|[2410.22996v1](http://arxiv.org/abs/2410.22996v1)|null|
|**2024-10-30**|**How Well Do Large Language Models Disambiguate Swedish Words?**|Richard Johansson et.al.|[2410.22827v1](http://arxiv.org/abs/2410.22827v1)|null|
|**2024-10-30**|**Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot**|Sejin Lee et.al.|[2410.22767v1](http://arxiv.org/abs/2410.22767v1)|[link](https://github.com/eastha0526/beyond-ontology-in-dst)|
|**2024-10-30**|**The Graph's Apprentice: Teaching an LLM Low Level Knowledge for Circuit Quality Estimation**|Reza Moravej et.al.|[2411.00843v1](http://arxiv.org/abs/2411.00843v1)|null|
|**2024-10-29**|**Are Large-Language Models Graph Algorithmic Reasoners?**|Alexander K Taylor et.al.|[2410.22597v1](http://arxiv.org/abs/2410.22597v1)|[link](https://github.com/ataylor24/magma)|
|**2024-10-29**|**Advancing Agentic Systems: Dynamic Task Decomposition, Tool Integration and Evaluation using Novel Metrics and Dataset**|Adrian Garret Gabriel et.al.|[2410.22457v1](http://arxiv.org/abs/2410.22457v1)|null|
|**2024-10-29**|**DynaMath: A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models**|Chengke Zou et.al.|[2411.00836v1](http://arxiv.org/abs/2411.00836v1)|null|
|**2024-10-29**|**ADAM: An Embodied Causal Agent in Open-World Environments**|Shu Yu et.al.|[2410.22194v1](http://arxiv.org/abs/2410.22194v1)|null|
|**2024-10-29**|**Synergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN**|Zhilun Zhou et.al.|[2411.00028v1](http://arxiv.org/abs/2411.00028v1)|null|
|**2024-10-29**|**A Hierarchical Language Model For Interpretable Graph Reasoning**|Sambhav Khurana et.al.|[2410.22372v1](http://arxiv.org/abs/2410.22372v1)|null|
|**2024-10-28**|**LLM-Forest for Health Tabular Data Imputation**|Xinrui He et.al.|[2410.21520v1](http://arxiv.org/abs/2410.21520v1)|null|
|**2024-10-28**|**Hierarchical Knowledge Graph Construction from Images for Scalable E-Commerce**|Zhantao Yang et.al.|[2410.21237v1](http://arxiv.org/abs/2410.21237v1)|null|
|**2024-10-28**|**CRAT: A Multi-Agent Framework for Causality-Enhanced Reflective and Retrieval-Augmented Translation with Large Language Models**|Meiqi Chen et.al.|[2410.21067v1](http://arxiv.org/abs/2410.21067v1)|null|
|**2024-10-28**|**CTINEXUS: Leveraging Optimized LLM In-Context Learning for Constructing Cybersecurity Knowledge Graphs Under Data Scarcity**|Yutong Cheng et.al.|[2410.21060v1](http://arxiv.org/abs/2410.21060v1)|null|
|**2024-10-28**|**Graph-based Uncertainty Metrics for Long-form Language Model Outputs**|Mingjian Jiang et.al.|[2410.20783v1](http://arxiv.org/abs/2410.20783v1)|[link](https://github.com/mingjianjiang-1/graph-based-uncertainty)|
|**2024-10-28**|**Plan$\times$RAG: Planning-guided Retrieval Augmented Generation**|Prakhar Verma et.al.|[2410.20753v1](http://arxiv.org/abs/2410.20753v1)|null|
|**2024-10-28**|**Simple is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation**|Mufei Li et.al.|[2410.20724v1](http://arxiv.org/abs/2410.20724v1)|null|
|**2024-10-27**|**Effective Instruction Parsing Plugin for Complex Logical Query Answering on Knowledge Graphs**|Xingrui Zhuo et.al.|[2410.20321v1](http://arxiv.org/abs/2410.20321v1)|null|
|**2024-10-26**|**Mathematical Derivation Graphs: A Task for Summarizing Equation Dependencies in STEM Manuscripts**|Vishesh Prasad et.al.|[2410.21324v1](http://arxiv.org/abs/2410.21324v1)|null|
|**2024-10-25**|**DualMAR: Medical-Augmented Representation from Dual-Expertise Perspectives**|Pengfei Hu et.al.|[2410.19955v1](http://arxiv.org/abs/2410.19955v1)|null|
|**2024-10-25**|**FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning**|Nicole Cho et.al.|[2410.19727v1](http://arxiv.org/abs/2410.19727v1)|null|
|**2024-10-25**|**Knowledge Graph Enhanced Language Agents for Recommendation**|Taicheng Guo et.al.|[2410.19627v1](http://arxiv.org/abs/2410.19627v1)|null|
|**2024-10-25**|**Graph Linearization Methods for Reasoning on Graphs with Large Language Models**|Christos Xypolopoulos et.al.|[2410.19494v1](http://arxiv.org/abs/2410.19494v1)|null|
|**2024-10-25**|**Hierarchical Mixture of Experts: Generalizable Learning for High-Level Synthesis**|Weikai Li et.al.|[2410.19225v1](http://arxiv.org/abs/2410.19225v1)|null|
|**2024-10-24**|**Enriching GNNs with Text Contextual Representations for Detecting Disinformation Campaigns on Social Media**|Bruno Croso Cunha da Silva et.al.|[2410.19193v1](http://arxiv.org/abs/2410.19193v1)|null|
|**2024-10-24**|**GCoder: Improving Large Language Model for Generalized Graph Problem Solving**|Qifan Zhang et.al.|[2410.19084v1](http://arxiv.org/abs/2410.19084v1)|[link](https://github.com/bklight999/www25-gcoder)|
|**2024-10-24**|**LLM-based Online Prediction of Time-varying Graph Signals**|Dayu Qin et.al.|[2410.18718v1](http://arxiv.org/abs/2410.18718v1)|null|
|**2024-10-24**|**Gene-Metabolite Association Prediction with Interactive Knowledge Transfer Enhanced Graph for Metabolite Production**|Kexuan Xin et.al.|[2410.18475v2](http://arxiv.org/abs/2410.18475v2)|null|
|**2024-10-24**|**ToolFlow: Boosting LLM Tool-Calling Through Natural and Coherent Dialogue Synthesis**|Zezhong Wang et.al.|[2410.18447v1](http://arxiv.org/abs/2410.18447v1)|null|
|**2024-10-24**|**Decoding on Graphs: Faithful and Sound Reasoning on Knowledge Graphs through Generation of Well-Formed Chains**|Kun Li et.al.|[2410.18415v1](http://arxiv.org/abs/2410.18415v1)|null|
|**2024-10-23**|**Explaining Bayesian Networks in Natural Language using Factor Arguments. Evaluation in the medical domain**|Jaime Sevilla et.al.|[2410.18060v1](http://arxiv.org/abs/2410.18060v1)|null|
|**2024-10-23**|**Graphusion: A RAG Framework for Knowledge Graph Construction with a Global Perspective**|Rui Yang et.al.|[2410.17600v1](http://arxiv.org/abs/2410.17600v1)|null|
|**2024-10-23**|**Navigate Complex Physical Worlds via Geometrically Constrained LLM**|Yongqiang Huang et.al.|[2410.17529v1](http://arxiv.org/abs/2410.17529v1)|null|
|**2024-10-22**|**Large Language Model-based Augmentation for Imbalanced Node Classification on Text-Attributed Graphs**|Leyao Wang et.al.|[2410.16882v1](http://arxiv.org/abs/2410.16882v1)|null|
|**2024-10-22**|**Context-aware Inductive Knowledge Graph Completion with Latent Type Constraints and Subgraph Reasoning**|Muzhi Li et.al.|[2410.16803v1](http://arxiv.org/abs/2410.16803v1)|null|
|**2024-10-22**|**The Scene Language: Representing Scenes with Programs, Words, and Embeddings**|Yunzhi Zhang et.al.|[2410.16770v1](http://arxiv.org/abs/2410.16770v1)|null|
|**2024-10-22**|**Atomic Fact Decomposition Helps Attributed Question Answering**|Zhichao Yan et.al.|[2410.16708v1](http://arxiv.org/abs/2410.16708v1)|null|
|**2024-10-22**|**PLDR-LLM: Large Language Model from Power Law Decoder Representations**|Burc Gokden et.al.|[2410.16703v1](http://arxiv.org/abs/2410.16703v1)|[link](https://github.com/burcgokden/llm-from-power-law-decoder-representations)|
|**2024-10-22**|**Distill-SynthKG: Distilling Knowledge Graph Synthesis Workflow for Improved Coverage and Efficiency**|Prafulla Kumar Choubey et.al.|[2410.16597v1](http://arxiv.org/abs/2410.16597v1)|null|
|**2024-10-21**|**Towards a Reliable Offline Personal AI Assistant for Long Duration Spaceflight**|Oliver Bensch et.al.|[2410.16397v1](http://arxiv.org/abs/2410.16397v1)|null|
|**2024-10-21**|**A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns**|Tianyi Men et.al.|[2410.16155v1](http://arxiv.org/abs/2410.16155v1)|null|
|**2024-10-21**|**CausalGraph2LLM: Evaluating LLMs for Causal Queries**|Ivaxi Sheth et.al.|[2410.15939v1](http://arxiv.org/abs/2410.15939v1)|[link](https://github.com/ivaxi0s/causalgraph2llm)|
|**2024-10-21**|**LLM4GRN: Discovering Causal Gene Regulatory Networks with LLMs -- Evaluation through Synthetic Data Generation**|Tejumade Afonja et.al.|[2410.15828v1](http://arxiv.org/abs/2410.15828v1)|null|
|**2024-10-21**|**NetSafe: Exploring the Topological Safety of Multi-agent Networks**|Miao Yu et.al.|[2410.15686v1](http://arxiv.org/abs/2410.15686v1)|null|
|**2024-10-20**|**TAGExplainer: Narrating Graph Explanations for Text-Attributed Graph Learning Models**|Bo Pan et.al.|[2410.15268v1](http://arxiv.org/abs/2410.15268v1)|null|
|**2024-10-19**|**Explaining Graph Neural Networks with Large Language Models: A Counterfactual Perspective for Molecular Property Prediction**|Yinhan He et.al.|[2410.15165v1](http://arxiv.org/abs/2410.15165v1)|null|
|**2024-10-19**|**MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science**|Junho Kim et.al.|[2410.15126v1](http://arxiv.org/abs/2410.15126v1)|null|
|**2024-10-19**|**Coarse-to-Fine Highlighting: Reducing Knowledge Hallucination in Large Language Models**|Qitan Lv et.al.|[2410.15116v1](http://arxiv.org/abs/2410.15116v1)|null|
|**2024-10-19**|**A Prompt Engineering Approach and a Knowledge Graph based Framework for Tackling Legal Implications of Large Language Model Answers**|George Hannah et.al.|[2410.15064v1](http://arxiv.org/abs/2410.15064v1)|null|
|**2024-10-19**|**LangGFM: A Large Language Model Alone Can be a Powerful Graph Foundation Model**|Tianqianjin Lin et.al.|[2410.14961v1](http://arxiv.org/abs/2410.14961v1)|null|
|**2024-10-18**|**TransBox: EL++-closed Ontology Embedding**|Hui Yang et.al.|[2410.14571v1](http://arxiv.org/abs/2410.14571v1)|null|
|**2024-10-18**|**Enabling Scalable Evaluation of Bias Patterns in Medical LLMs**|Hamed Fayyaz et.al.|[2410.14763v1](http://arxiv.org/abs/2410.14763v1)|[link](https://github.com/healthylaife/autofair)|
|**2024-10-18**|**Paths-over-Graph: Knowledge Graph Empowered Large Language Model Reasoning**|Xingyu Tan et.al.|[2410.14211v2](http://arxiv.org/abs/2410.14211v2)|null|
|**2024-10-18**|**UniMTS: Unified Pre-training for Motion Time Series**|Xiyuan Zhang et.al.|[2410.19818v1](http://arxiv.org/abs/2410.19818v1)|[link](https://github.com/xiyuanzh/unimts)|
|**2024-10-18**|**Supervised Chain of Thought**|Xiang Zhang et.al.|[2410.14198v1](http://arxiv.org/abs/2410.14198v1)|null|
|**2024-10-17**|**Towards Cross-Cultural Machine Translation with Retrieval-Augmented Generation from Multilingual Knowledge Graphs**|Simone Conia et.al.|[2410.14057v1](http://arxiv.org/abs/2410.14057v1)|null|
|**2024-10-17**|**RiTeK: A Dataset for Large Language Models Complex Reasoning over Textual Knowledge Graphs**|Jiatan Huang et.al.|[2410.13987v1](http://arxiv.org/abs/2410.13987v1)|null|
|**2024-10-17**|**The Mystery of the Pathological Path-star Task for Language Models**|Arvid Frydenlund et.al.|[2410.13779v1](http://arxiv.org/abs/2410.13779v1)|null|
|**2024-10-17**|**Knowledge-Aware Query Expansion with Large Language Models for Textual and Relational Retrieval**|Yu Xia et.al.|[2410.13765v1](http://arxiv.org/abs/2410.13765v1)|null|
|**2024-10-17**|**LLM-Rank: A Graph Theoretical Approach to Pruning Large Language Models**|David Hoffmann et.al.|[2410.13299v1](http://arxiv.org/abs/2410.13299v1)|null|
|**2024-10-17**|**Trust but Verify: Programmatic VLM Evaluation in the Wild**|Viraj Prabhu et.al.|[2410.13121v1](http://arxiv.org/abs/2410.13121v1)|null|

#### Abstracts
##### **Gradual Fine-Tuning with Graph Routing for Multi-Source Unsupervised Domain Adaptation**
2411.07185v1 by Yao Ma, Samuel Louvan, Zhunxuan Wang

Multi-source unsupervised domain adaptation aims to leverage labeled data
from multiple source domains for training a machine learning model to
generalize well on a target domain without labels. Source domain selection
plays a crucial role in determining the model's performance. It relies on the
similarities amongst source and target domains. Nonetheless, existing work for
source domain selection often involves heavyweight computational procedures,
especially when dealing with numerous source domains and the need to identify
the best ones from them. In this paper, we introduce a framework for gradual
fine tuning (GFT) of machine learning models on multiple source domains. We
represent multiple source domains as an undirected weighted graph. We then give
a new generalization error bound for GFT along any path within the graph, which
is used to determine the optimal path corresponding to the optimal training
order. With this formulation, we introduce three lightweight graph-routing
strategies which tend to minimize the error bound. Our best strategy improves
$2.3\%$ of accuracy over the state-of-the-art on Natural Language Inference
(NLI) task and achieves competitive performance on Sentiment Analysis (SA)
task, especially a $3.9\%$ improvement on a more diverse subset of data we use
for SA.

æè¦ï¼å¤æºæ çç£åèªéåºæ¨å¨å©ç¨æ¥èªå¤ä¸ªæºåçæ è®°æ°æ®ï¼è®­ç»æºå¨å­¦ä¹ æ¨¡åï¼ä»¥ä¾¿å¨æ²¡ææ ç­¾çç®æ åä¸å¾å¥½å°æ³åãæºåéæ©å¨ç¡®å®æ¨¡åæ§è½æ¹é¢èµ·çè³å³éè¦çä½ç¨ãå®ä¾èµäºæºååç®æ åä¹é´çç¸ä¼¼æ§ãå°½ç®¡å¦æ­¤ï¼ç°æçæºåéæ©å·¥ä½éå¸¸æ¶åééçº§è®¡ç®ç¨åºï¼å°¤å¶æ¯å¨å¤çä¼å¤æºåä»¥åéè¦ä»ä¸­è¯å«æä½³æºåæ¶ãå¨æ¬æä¸­ï¼æä»¬ä»ç»äºä¸ä¸ªå¨å¤ä¸ªæºåä¸å¯¹æºå¨å­¦ä¹ æ¨¡åè¿è¡éæ­¥å¾®è° (GFT) çæ¡æ¶ãæä»¬å°å¤ä¸ªæºåè¡¨ç¤ºä¸ºæ åå æå¾ãç¶åï¼æä»¬ä¸ºå¾ä¸­æ²¿ä»»ä½è·¯å¾ç GFT ç»åºäºä¸ä¸ªæ°çæ³åè¯¯å·®çï¼ç¨äºç¡®å®å¯¹åºäºæä½³è®­ç»é¡ºåºçæä½³è·¯å¾ãéè¿è¿ç§è¡¨è¿°ï¼æä»¬ä»ç»äºä¸ç§è½»éçº§çå¾è·¯ç±ç­ç¥ï¼è¿äºç­ç¥å¾åäºæå°åè¯¯å·®çãæä»¬æå¥½çç­ç¥å¨èªç¶è¯­è¨æ¨ç (NLI) ä»»å¡ä¸æ¯æåè¿çææ¯æé«äº 2.3% çåç¡®çï¼å¹¶å¨ææåæ (SA) ä»»å¡ä¸åå¾äºæç«äºåçæ§è½ï¼ç¹å«æ¯å¨æä»¬ç¨äº SA çæ´å¤æ ·åçæ°æ®å­éä¸æé«äº 3.9%ã

##### **A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19**
2411.07163v1 by Vedant Khandelwal, Manas Gaur, Ugur Kursuncu, Valerie Shalin, Amit Sheth

Monitoring public sentiment via social media is potentially helpful during
health crises such as the COVID-19 pandemic. However, traditional
frequency-based, data-driven neural network-based approaches can miss newly
relevant content due to the evolving nature of language in a dynamically
evolving environment. Human-curated symbolic knowledge sources, such as
lexicons for standard language and slang terms, can potentially elevate social
media signals in evolving language. We introduce a neurosymbolic method that
integrates neural networks with symbolic knowledge sources, enhancing the
detection and interpretation of mental health-related tweets relevant to
COVID-19. Our method was evaluated using a corpus of large datasets
(approximately 12 billion tweets, 2.5 million subreddit data, and 700k news
articles) and multiple knowledge graphs. This method dynamically adapts to
evolving language, outperforming purely data-driven models with an F1 score
exceeding 92\%. This approach also showed faster adaptation to new data and
lower computational demands than fine-tuning pre-trained large language models
(LLMs). This study demonstrates the benefit of neurosymbolic methods in
interpreting text in a dynamic environment for tasks such as health
surveillance.

æè¦ï¼ééç¤¾ç¾¤åªé«ç£æ§å¬ç¾æç·å¨ COVID-19 ç­å¥åº·å±æ©æéå¯è½å¾æå¹«å©ãç¶èï¼å³çµ±çåºæ¼é »çãè³æé©åçç¥ç¶ç¶²è·¯æ¹æ³å¯è½æé¯éæ°ç¸éçå§å®¹ï¼å çºèªè¨å¨åææ¼åçç°å¢ä¸­ææçºæ¼åãç±äººé¡ç­åçè±¡å¾µæ§ç¥è­ä¾æºï¼ä¾å¦æ¨æºèªè¨åä¿èªè¡èªçè©å½ï¼å¯è½ææåç¤¾ç¾¤åªé«å¨æ¼åèªè¨ä¸­çè¨èãæåå¼å¥ä¸ç¨®å°ç¥ç¶ç¶²è·¯èè±¡å¾µæ§ç¥è­ä¾æºæ´åçç¥ç¶ç¬¦èæ¹æ³ï¼å¢å¼·è COVID-19 ç¸éçå¿çå¥åº·ç¸éæ¨æçåµæ¸¬åè©®éãæåçåæ³ä½¿ç¨å¤§åè³æéèªæåº«ï¼ç´ 120 ååæ¨æã250 è¬å subreddit è³æå 70 è¬åæ°èæç« ï¼åå¤åç¥è­åè­é²è¡è©ä¼°ãéç¨®æ¹æ³åæé©ææ¼åçèªè¨ï¼åªæ¼ç´è³æé©åæ¨¡åï¼F1 åæ¸è¶é 92%ãéç¨®æ¹æ³ä¹é¡¯ç¤ºåºæ¯å¾®èª¿é è¨ç·´å¤§åèªè¨æ¨¡å (LLM) æ´å¿«é©ææ°è³æåæ´ä½çéç®éæ±ãæ¬ç ç©¶è­æäºç¥ç¶ç¬¦èæ¹æ³å¨åæç°å¢ä¸­è©®éæå­çåªé»ï¼é©ç¨æ¼å¥åº·ç£æ§ç­ä»»åã

##### **A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs**
2411.07098v1 by Myeongsoo Kim, Tyler Stennett, Saurabh Sinha, Alessandro Orso

As modern web services increasingly rely on REST APIs, their thorough testing
has become crucial. Furthermore, the advent of REST API specifications such as
the OpenAPI Specification has led to the emergence of many black-box REST API
testing tools. However, these tools often focus on individual test elements in
isolation (e.g., APIs, parameters, values), resulting in lower coverage and
less effectiveness in detecting faults (i.e., 500 response codes). To address
these limitations, we present AutoRestTest, the first black-box framework to
adopt a dependency-embedded multi-agent approach for REST API testing,
integrating Multi-Agent Reinforcement Learning (MARL) with a Semantic Property
Dependency Graph (SPDG) and Large Language Models (LLMs). Our approach treats
REST API testing as a separable problem, where four agents -- API, dependency,
parameter, and value -- collaborate to optimize API exploration. LLMs handle
domain-specific value restrictions, the SPDG model simplifies the search space
for dependencies using a similarity score between API operations, and MARL
dynamically optimizes the agents' behavior. Evaluated on 12 real-world REST
services, AutoRestTest outperforms the four leading black-box REST API testing
tools, including those assisted by RESTGPT (which augments realistic test
inputs using LLMs), in terms of code coverage, operation coverage, and fault
detection. Notably, AutoRestTest is the only tool able to identify an internal
server error in Spotify. Our ablation study underscores the significant
contributions of the agent learning, SPDG, and LLM components.

æè¦ï¼<paragraph>é¨èç¾ä»£ç¶²è·¯æåæ¥çä¾è³´ REST APIï¼å¶å¾¹åºçæ¸¬è©¦è®å¾è³ééè¦ãæ­¤å¤ï¼REST API è¦ç¯ï¼ä¾å¦ OpenAPI è¦ç¯ï¼çåºç¾ï¼å°è´è¨±å¤é»ç REST API æ¸¬è©¦å·¥å·çåºç¾ãç¶èï¼éäºå·¥å·éå¸¸å°æ³¨æ¼å®ç¨çæ¸¬è©¦åç´ ï¼ä¾å¦ APIãåæ¸ãå¼ï¼ï¼å°è´è¦èçè¼ä½ï¼ä¸å¨åµæ¸¬é¯èª¤ï¼å³ 500 åæç¢¼ï¼æ¹é¢æçè¼ä½ãçºäºè§£æ±ºéäºéå¶ï¼æåæåº AutoRestTestï¼éæ¯ç¬¬ä¸åæ¡ç¨ä¾è³´åµå¥å¼å¤ä»£çæ¹æ³é²è¡ REST API æ¸¬è©¦çé»çæ¡æ¶ï¼å°å¤ä»£çå¼·åå­¸ç¿ (MARL) èèªç¾©å±¬æ§ä¾è³´å (SPDG) åå¤§åèªè¨æ¨¡å (LLM) æ´åå¨ä¸èµ·ãæåçåæ³å° REST API æ¸¬è©¦è¦çºä¸åå¯åé¢çåé¡ï¼å¶ä¸­ååä»£çï¼APIãä¾è³´éä¿ãåæ¸åå¼ï¼åååä½ä»¥æä½³å API æ¢ç´¢ãLLM èçç¹å®é åçå¼éå¶ï¼SPDG æ¨¡åä½¿ç¨ API æä½ä¹éçç¸ä¼¼æ§åæ¸ç°¡åä¾è³´éä¿çæå°ç©ºéï¼è MARL ååææä½³åä»£ççè¡çºãå¨ 12 é çå¯¦ä¸çç REST æåä¸é²è¡è©ä¼°ï¼AutoRestTest å¨ç¨å¼ç¢¼è¦èçãæä½è¦èçåé¯èª¤åµæ¸¬æ¹é¢ï¼åªæ¼åç¨®é åçé»ç REST API æ¸¬è©¦å·¥å·ï¼åæ¬é£äºç± RESTGPTï¼ä½¿ç¨ LLM å¢å é¼ççæ¸¬è©¦è¼¸å¥ï¼è¼å©çå·¥å·ãå¼å¾æ³¨æçæ¯ï¼AutoRestTest æ¯å¯ä¸è½å¤ è­å¥ Spotify ä¸­å§é¨ä¼ºæå¨é¯èª¤çå·¥å·ãæåçæ¶èç ç©¶å¼·èª¿äºä»£çå­¸ç¿ãSPDG å LLM çµä»¶çéå¤§è²¢ç»ã</paragraph>

##### **Bridge: A Unified Framework to Knowledge Graph Completion via Language Models and Knowledge Representation**
2411.06660v1 by Qiao Qiao, Yuepei Li, Qing Wang, Kang Zhou, Qi Li

Knowledge graph completion (KGC) is a task of inferring missing triples based
on existing Knowledge Graphs (KGs). Both structural and semantic information
are vital for successful KGC. However, existing methods only use either the
structural knowledge from the KG embeddings or the semantic information from
pre-trained language models (PLMs), leading to suboptimal model performance.
Moreover, since PLMs are not trained on KGs, directly using PLMs to encode
triples may be inappropriate. To overcome these limitations, we propose a novel
framework called Bridge, which jointly encodes structural and semantic
information of KGs. Specifically, we strategically encode entities and
relations separately by PLMs to better utilize the semantic knowledge of PLMs
and enable structured representation learning via a structural learning
principle. Furthermore, to bridge the gap between KGs and PLMs, we employ a
self-supervised representation learning method called BYOL to fine-tune PLMs
with two different views of a triple. Unlike BYOL, which uses augmentation
methods to create two semantically similar views of the same image, potentially
altering the semantic information. We strategically separate the triple into
two parts to create different views, thus avoiding semantic alteration.
Experiments demonstrate that Bridge outperforms the SOTA models on three
benchmark datasets.

æè¦ï¼ç¥è­åè­è£å¨ (KGC) æ¯ä¸é æ ¹æç¾æç¥è­åè­ (KG) æ¨è«éºå¤±ä¸åçµçä»»åãçµæ§åèªç¾©è³è¨å°æ¼æåç KGC è³ééè¦ãç¶èï¼ç¾ææ¹æ³åä½¿ç¨ä¾èª KG åµå¥ççµæ§ç¥è­æä¾èªé è¨ç·´èªè¨æ¨¡å (PLM) çèªç¾©è³è¨ï¼å°è´æ¨¡åæè½ä¸ä½³ãæ­¤å¤ï¼ç±æ¼ PLM æ²æå¨ KG ä¸è¨ç·´ï¼å æ­¤ç´æ¥ä½¿ç¨ PLM ç·¨ç¢¼ä¸åçµå¯è½ä¸¦ä¸é©ç¶ãçºäºåæéäºéå¶ï¼æåæåºä¸ååçº Bridge çæ°æ¶æ§ï¼è©²æ¶æ§è¯åç·¨ç¢¼ KG ççµæ§åèªç¾©è³è¨ãå·é«ä¾èªªï¼æåéé PLM åå¥å°å¯¦é«åéä¿é²è¡ç­ç¥æ§ç·¨ç¢¼ï¼ä»¥æ´å¥½å°å©ç¨ PLM çèªç¾©ç¥è­ï¼ä¸¦ééçµæ§å­¸ç¿åååç¨çµæ§åè¡¨ç¤ºå­¸ç¿ãæ­¤å¤ï¼çºäºå½å KG å PLM ä¹éçå·®è·ï¼æåæ¡ç¨ä¸ç¨®ç¨±çº BYOL çèªç£ç£è¡¨ç¤ºå­¸ç¿æ¹æ³ï¼ä»¥ä¸åçµçå©åä¸åè¦åå¾®èª¿ PLMãè BYOL ä¸åï¼BYOL ä½¿ç¨æ´åæ¹æ³ä¾å»ºç«å©åèªç¾©ä¸ç¸ä¼¼çç¸åå½±åè¦åï¼å¯è½ææ¹è®èªç¾©è³è¨ãæåç­ç¥æ§å°å°ä¸åçµåçºå©é¨åä»¥å»ºç«ä¸åçè¦åï¼å¾èé¿åèªç¾©æ¹è®ãå¯¦é©è­æ Bridge å¨ä¸ååºæºè³æéä¸åªæ¼ SOTA æ¨¡åã

##### **CausalStock: Deep End-to-end Causal Discovery for News-driven Stock Movement Prediction**
2411.06391v1 by Shuqi Li, Yuebo Sun, Yuxin Lin, Xin Gao, Shuo Shang, Rui Yan

There are two issues in news-driven multi-stock movement prediction tasks
that are not well solved in the existing works. On the one hand, "relation
discovery" is a pivotal part when leveraging the price information of other
stocks to achieve accurate stock movement prediction. Given that stock
relations are often unidirectional, such as the "supplier-consumer"
relationship, causal relations are more appropriate to capture the impact
between stocks. On the other hand, there is substantial noise existing in the
news data leading to extracting effective information with difficulty. With
these two issues in mind, we propose a novel framework called CausalStock for
news-driven multi-stock movement prediction, which discovers the temporal
causal relations between stocks. We design a lag-dependent temporal causal
discovery mechanism to model the temporal causal graph distribution. Then a
Functional Causal Model is employed to encapsulate the discovered causal
relations and predict the stock movements. Additionally, we propose a Denoised
News Encoder by taking advantage of the excellent text evaluation ability of
large language models (LLMs) to extract useful information from massive news
data. The experiment results show that CausalStock outperforms the strong
baselines for both news-driven multi-stock movement prediction and multi-stock
movement prediction tasks on six real-world datasets collected from the US,
China, Japan, and UK markets. Moreover, getting benefit from the causal
relations, CausalStock could offer a clear prediction mechanism with good
explainability.

æè¦ï¼<paragraph>å¨æ°èé©åçå¤è¡ç¥¨ç§»åé æ¸¬ä»»åä¸­ï¼ç¾æç ç©¶å°æªå¦¥åè§£æ±ºå©ååé¡ãä¸æ¹é¢ï¼å¨å©ç¨å¶ä»è¡ç¥¨çå¹æ ¼è³è¨ä¾å¯¦ç¾æºç¢ºçè¡ç¥¨ç§»åé æ¸¬æï¼ãéä¿ç¼ç¾ãæ¯ä¸åééµé¨åãç±æ¼è¡ç¥¨éä¿éå¸¸æ¯å®åçï¼ä¾å¦ãä¾æå-æ¶è²»èãéä¿ï¼å æ­¤å æéä¿æ´é©åææè¡ç¥¨ä¹éçå½±é¿ãå¦ä¸æ¹é¢ï¼æ°èè³æä¸­å­å¨å¤§ééè¨ï¼å°è´é£ä»¥æåææè³è¨ãèæ®å°éå©ååé¡ï¼æåæåºäºä¸ååçº CausalStock çæ°æ¡æ¶ï¼ç¨æ¼æ°èé©åçå¤è¡ç¥¨ç§»åé æ¸¬ï¼è©²æ¡æ¶ç¼ç¾äºè¡ç¥¨ä¹éçæåºå æéä¿ãæåè¨­è¨äºä¸åå»¶é²ä¾è³´çæåºå æç¼ç¾æ©å¶ï¼ä»¥å»ºæ¨¡æåºå æååå¸ãç¶å¾æ¡ç¨åè½å ææ¨¡åä¾å°è£ç¼ç¾çå æéä¿ä¸¦é æ¸¬è¡ç¥¨èµ°å¢ãæ­¤å¤ï¼æåæåºäºä¸åå»åªæ°èç·¨ç¢¼å¨ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) åºè²çææ¬è©ä¼°è½åå¾å¤§éæ°èè³æä¸­æåæç¨è³è¨ãå¯¦é©çµæè¡¨æï¼CausalStock å¨å¾ç¾åãä¸­åãæ¥æ¬åè±åå¸å ´æ¶éçå­åçå¯¦ä¸çè³æéä¸ï¼å¨æ°èé©åçå¤è¡ç¥¨ç§»åé æ¸¬åå¤è¡ç¥¨ç§»åé æ¸¬ä»»åä¸­é½åªæ¼å¼·å¤§çåºç·ãæ­¤å¤ï¼CausalStock åçæ¼å æéä¿ï¼å¯ä»¥æä¾å·æè¯å¥½å¯è§£éæ§çæ¸æ°é æ¸¬æ©å¶ã</paragraph>

##### **Analyzing the Evolution of Graphs and Texts**
2411.06295v1 by Xingzhi Guo

With the recent advance of representation learning algorithms on graphs
(e.g., DeepWalk/GraphSage) and natural languages (e.g., Word2Vec/BERT) , the
state-of-the art models can even achieve human-level performance over many
downstream tasks, particularly for the task of node and sentence
classification. However, most algorithms focus on large-scale models for static
graphs and text corpus without considering the inherent dynamic characteristics
or discovering the reasons behind the changes. This dissertation aims to
efficiently model the dynamics in graphs (such as social networks and citation
graphs) and understand the changes in texts (specifically news titles and
personal biographies). To achieve this goal, we utilize the renowned
Personalized PageRank algorithm to create effective dynamic network embeddings
for evolving graphs. Our proposed approaches significantly improve the running
time and accuracy for both detecting network abnormal intruders and discovering
entity meaning shifts over large-scale dynamic graphs. For text changes, we
analyze the post-publication changes in news titles to understand the intents
behind the edits and discuss the potential impact of titles changes from
information integrity perspective. Moreover, we investigate self-presented
occupational identities in Twitter users' biographies over five years,
investigating job prestige and demographics effects in how people disclose
jobs, quantifying over-represented jobs and their transitions over time.

æè¦ï¼é¨èåå½¢è¡¨ç¤ºå­¸ç¿æ¼ç®æ³çææ°é²å±ï¼ä¾å¦ DeepWalk/GraphSageï¼åèªç¶èªè¨ï¼ä¾å¦ Word2Vec/BERTï¼ï¼æåé²çæ¨¡åçè³å¯ä»¥å¨è¨±å¤ä¸æ¸¸ä»»åä¸­éå°äººé¡ç­ç´çæè½ï¼ç¹å¥æ¯å°æ¼ç¯é»åå¥å­åé¡çä»»åãç¶èï¼å¤§å¤æ¸æ¼ç®æ³é½å°æ³¨æ¼éæåå½¢åå¤§è¦æ¨¡æå­èªæåº«çæ¨¡åï¼èæ²æèæ®åºæçåæç¹æ§ææ¾åºè®åçåå ãæ¬è«ææ¨å¨ææå°çºåå½¢ï¼ä¾å¦ç¤¾ç¾¤ç¶²è·¯åå¼æåå½¢ï¼å»ºæ¨¡åæï¼ä¸¦äºè§£æå­çè®åï¼ç¹å¥æ¯æ°èæ¨é¡ååäººå³è¨ï¼ãçºäºéæéåç®æ¨ï¼æåå©ç¨èåç Personalized PageRank æ¼ç®æ³çºä¸æ·è®åçåå½¢å»ºç«ææçåæç¶²è·¯åµå¥ãæåæåºçæ¹æ³é¡¯èæ¹åäºåµæ¸¬ç¶²è·¯ç°å¸¸å¥ä¾µèåæ¾åºå¤§è¦æ¨¡åæåå½¢ä¸­å¯¦é«å«ç¾©è½ç§»çå·è¡æéåæºç¢ºåº¦ãå°æ¼æå­è®åçé¨åï¼æååæäºæ°èæ¨é¡å¨åºçå¾çè®åï¼ä»¥äºè§£ç·¨è¼¯èå¾çæåï¼ä¸¦è¨è«æ¨é¡è®æ´å°è³è¨å®æ´æ§çæ½å¨å½±é¿ãæ­¤å¤ï¼æåèª¿æ¥äº Twitter ä½¿ç¨èå¨å³è¨ä¸­åç¾çè·æ¥­èº«åé·éäºå¹´ï¼æ¢è¨äºå·¥ä½è²æåäººå£çµ±è¨è³æå°äººåæ­é²å·¥ä½çå½±é¿ï¼ä¸¦éåäºéåº¦ä»£è¡¨çå·¥ä½åå¶é¨èæéæ¨ç§»çè½è®ã

##### **An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models**
2411.06048v1 by Fatemeh Shiri, Xiao-Yu Guo, Mona Golestan Far, Xin Yu, Gholamreza Haffari, Yuan-Fang Li

Large Multimodal Models (LMMs) have achieved strong performance across a
range of vision and language tasks. However, their spatial reasoning
capabilities are under-investigated. In this paper, we construct a novel VQA
dataset, Spatial-MM, to comprehensively study LMMs' spatial understanding and
reasoning capabilities. Our analyses on object-relationship and multi-hop
reasoning reveal several important findings. Firstly, bounding boxes and scene
graphs, even synthetic ones, can significantly enhance LMMs' spatial reasoning.
Secondly, LMMs struggle more with questions posed from the human perspective
than the camera perspective about the image. Thirdly, chain of thought (CoT)
prompting does not improve model performance on complex multi-hop questions
involving spatial relations. % Moreover, spatial reasoning steps are much less
accurate than non-spatial ones across MLLMs. Lastly, our perturbation analysis
on GQA-spatial reveals that LMMs are much stronger at basic object detection
than complex spatial reasoning. We believe our benchmark dataset and in-depth
analyses can spark further research on LMMs spatial reasoning. Spatial-MM
benchmark is available at: https://github.com/FatemehShiri/Spatial-MM

æè¦ï¼å¤§åå¤æ¨¡ææ¨¡å (LMM) å·²å¨åç¨®è¦è¦ºåèªè¨ä»»åä¸­åå¾å¼·åçè¡¨ç¾ãç¶èï¼å®åçç©ºéæ¨çè½åå°æªå¾å°ååç ç©¶ãå¨æ¬æä¸­ï¼æåæ§å»ºäºä¸åæ°ç©ç VQA è³æé Spatial-MMï¼ä»¥å¨é¢ç ç©¶ LMM çç©ºéçè§£åæ¨çè½åãæåå°ç©ä»¶éä¿åå¤è·³æ¨ççåææ­ç¤ºäºå¹¾åéè¦çç¼ç¾ãé¦åï¼éçæ¡åå ´æ¯åï¼å³ä½¿æ¯åæçï¼ä¹å¯ä»¥é¡¯èå¢å¼· LMM çç©ºéæ¨çè½åãå¶æ¬¡ï¼LMM å¨åç­å¾äººé¡è¦è§æåºçåé¡ææ¯å¾ç¸æ©è¦è§æåºçåé¡æéå°æ´å¤å°é£ãç¬¬ä¸ï¼æèé (CoT) æç¤ºä¸¦æªæ¹åæ¨¡åå¨æ¶åç©ºééä¿çè¤éå¤è·³åé¡ä¸çæè½ã% æ­¤å¤ï¼å¨ MLLM ä¸­ï¼ç©ºéæ¨çæ­¥é©çæºç¢ºåº¦é ä½æ¼éç©ºéæ­¥é©ãæå¾ï¼æåå° GQA-spatial çæ¾ååæè¡¨æï¼LMM å¨åºæ¬ç©ä»¶åµæ¸¬æ¹é¢çè½åé å¼·æ¼è¤éçç©ºéæ¨çãæåç¸ä¿¡æåçåºæºè³æéåæ·±å¥åæå¯ä»¥æ¿ç¼å° LMM ç©ºéæ¨ççé²ä¸æ­¥ç ç©¶ãSpatial-MM åºæºå¯å¨ä»¥ä¸ç¶²ååå¾ï¼https://github.com/FatemehShiri/Spatial-MM

##### **Mitigating Hallucination with ZeroG: An Advanced Knowledge Management Engine**
2411.05936v1 by Anantha Sharma, Sheeba Elizabeth John, Fatemeh Rezapoor Nikroo, Krupali Bhatt, Mrunal Zambre, Aditi Wikhe

The growth of digital documents presents significant challenges in efficient
management and knowledge extraction. Traditional methods often struggle with
complex documents, leading to issues such as hallucinations and high latency in
responses from Large Language Models (LLMs). ZeroG, an innovative approach,
significantly mitigates these challenges by leveraging knowledge distillation
and prompt tuning to enhance model performance.
  ZeroG utilizes a smaller model that replicates the behavior of a larger
teacher model, ensuring contextually relevant and grounded responses, by
employing a black-box distillation approach, it creates a distilled dataset
without relying on intermediate features, optimizing computational efficiency.
This method significantly enhances accuracy and reduces response times,
providing a balanced solution for modern document management.
  Incorporating advanced techniques for document ingestion and metadata
utilization, ZeroG improves the accuracy of question-and-answer systems. The
integration of graph databases and robust metadata management further
streamlines information retrieval, allowing for precise and context-aware
responses. By transforming how organizations interact with complex data, ZeroG
enhances productivity and user experience, offering a scalable solution for the
growing demands of digital document management.

æè¦ï¼æ¸ä½æä»¶æé·å¸¶ä¾é¡¯èçææ°ï¼åæ¬ææç®¡çåç¥è­èåãå³çµ±æ¹æ³ç¶å¸¸é£ä»¥èçè¤éæä»¶ï¼å°è´åé¡ï¼ä¾å¦ç¢çå¹»è¦ºåå¤§åèªè¨æ¨¡å (LLM) åæçé«å»¶é²ãZeroG æ¯ä¸ç¨®åµæ°çæ¹æ³ï¼ééå©ç¨ç¥è­è¸é¤¾åæç¤ºèª¿æ´ä¾å¢å¼·æ¨¡åæè½ï¼å¤§å¹æ¸è¼éäºææ°ã
ZeroG ä½¿ç¨è¼å°çæ¨¡åè¤è£½è¼å¤§çæå¸«æ¨¡åçè¡çºï¼ééæ¡ç¨é»çè¸é¤¾æ¹æ³ï¼ç¢ºä¿å¨èçµ¡ä¸ç¸éä¸ææ ¹æçåæï¼å®å»ºç«ä¸åè¸é¤¾çè³æéï¼èä¸éè¦ä¾è³´ä¸­éç¹å¾µï¼æä½³åéç®æçãéç¨®æ¹æ³å¤§å¹æåæºç¢ºåº¦ä¸¦æ¸å°åææéï¼æä¾ç¾ä»£æä»¶ç®¡ççå¹³è¡¡è§£æ±ºæ¹æ¡ã
ééæ´åé²éæè¡ä¾æ·åæä»¶åä½¿ç¨åè³æï¼ZeroG æ¹ååç­ç³»çµ±çæºç¢ºåº¦ãåå½¢è³æåº«åå¼·å¥çåè³æç®¡ççæ´åé²ä¸æ­¥ç°¡åè³è¨æ·åï¼åè¨±ç²¾ç¢ºä¸ç¬¦åèçµ¡çåæãééè½æçµç¹èè¤éè³æäºåçæ¹å¼ï¼ZeroG æåçç¢ååä½¿ç¨èé«é©ï¼æä¾å¯æ´åçè§£æ±ºæ¹æ¡ï¼ä»¥æ»¿è¶³æ¸ä½æä»¶ç®¡çæ¥çå¢é·çéæ±ã

##### **SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark**
2411.05521v1 by Sithursan Sivasubramaniam, Cedric Osei-Akoto, Yi Zhang, Kurt Stockinger, Jonathan Fuerst

Electronic health records (EHRs) are stored in various database systems with
different database models on heterogeneous storage architectures, such as
relational databases, document stores, or graph databases. These different
database models have a big impact on query complexity and performance. While
this has been a known fact in database research, its implications for the
growing number of Text-to-Query systems have surprisingly not been investigated
so far. In this paper, we present SM3-Text-to-Query, the first multi-model
medical Text-to-Query benchmark based on synthetic patient data from Synthea,
following the SNOMED-CT taxonomy -- a widely used knowledge graph ontology
covering medical terminology. SM3-Text-to-Query provides data representations
for relational databases (PostgreSQL), document stores (MongoDB), and graph
databases (Neo4j and GraphDB (RDF)), allowing the evaluation across four
popular query languages, namely SQL, MQL, Cypher, and SPARQL. We systematically
and manually develop 408 template questions, which we augment to construct a
benchmark of 10K diverse natural language question/query pairs for these four
query languages (40K pairs overall). On our dataset, we evaluate several common
in-context-learning (ICL) approaches for a set of representative closed and
open-source LLMs. Our evaluation sheds light on the trade-offs between database
models and query languages for different ICL strategies and LLMs. Last,
SM3-Text-to-Query is easily extendable to additional query languages or real,
standard-based patient databases.

æè¦ï¼é»å­å¥åº·ç´é (EHR) å²å­å¨åç¨®è³æåº«ç³»çµ±ä¸­ï¼éäºç³»çµ±å¨ç°è³ªå²å­æ¶æ§ä¸å·æä¸åçè³æåº«æ¨¡åï¼ä¾å¦éè¯å¼è³æåº«ãæä»¶å²å­æåå½¢è³æåº«ãéäºä¸åçè³æåº«æ¨¡åå°æ¥è©¢è¤éåº¦åæè½æå¾å¤§çå½±é¿ãéç¶éå¨è³æåº«ç ç©¶ä¸­å·²ç¶æ¯ç¾æå¨ç¥çäºå¯¦ï¼ä½ä»¤äººé©è¨çæ¯ï¼å®å°æ¥çå¢å çæå­è½æ¥è©¢ç³»çµ±çå½±é¿è¿ä»å°æªå¾å°èª¿æ¥ãå¨æ¬æä¸­ï¼æåæåº SM3-Text-to-Queryï¼éæ¯ç¬¬ä¸ååºæ¼ä¾èª Synthea çåææ£èè³æçå¤æ¨¡åé«çæå­è½æ¥è©¢åºæºï¼éµå¾ª SNOMED-CT åé¡æ³ââä¸ç¨®å»£æ³ä½¿ç¨çæ¶µèé«å­¸è¡èªçç¥è­åè­æ¬é«ãSM3-Text-to-Query æä¾äºéè¯å¼è³æåº« (PostgreSQL)ãæä»¶å²å­ (MongoDB) ååå½¢è³æåº« (Neo4j å GraphDB (RDF)) çè³æè¡¨ç¤ºï¼åè¨±è·¨åç¨®æµè¡æ¥è©¢èªè¨ï¼å³ SQLãMQLãCypher å SPARQLï¼é²è¡è©ä¼°ãæåç³»çµ±ä¸æåéç¼äº 408 åç¯æ¬åé¡ï¼æåæ´åéäºåé¡ä»¥æ§å»ºä¸ååºæºï¼å¶ä¸­åå« 10K åéå°éåç¨®æ¥è©¢èªè¨çå¤æ¨£åèªç¶èªè¨åé¡/æ¥è©¢å°ï¼ç¸½å± 40K å°ï¼ãå¨æåçè³æéä¸ï¼æåè©ä¼°äºå¹¾ç¨®å¸¸è¦çä»£è¡¨æ§éæºåéæº LLM çæå¢å­¸ç¿ (ICL) æ¹æ³ãæåçè©ä¼°æ­ç¤ºäºä¸å ICL ç­ç¥å LLM çè³æåº«æ¨¡ååæ¥è©¢èªè¨ä¹éçåæ¨ãæå¾ï¼SM3-Text-to-Query å¯ä»¥è¼é¬æ´å±å°å¶ä»æ¥è©¢èªè¨æçå¯¦çåºæ¼æ¨æºçæ£èè³æåº«ã

##### **EUREKHA: Enhancing User Representation for Key Hackers Identification in Underground Forums**
2411.05479v1 by Abdoul Nasser Hassane Amadou, Anas Motii, Saida Elouardi, EL Houcine Bergou

Underground forums serve as hubs for cybercriminal activities, offering a
space for anonymity and evasion of conventional online oversight. In these
hidden communities, malicious actors collaborate to exchange illicit knowledge,
tools, and tactics, driving a range of cyber threats from hacking techniques to
the sale of stolen data, malware, and zero-day exploits. Identifying the key
instigators (i.e., key hackers), behind these operations is essential but
remains a complex challenge. This paper presents a novel method called EUREKHA
(Enhancing User Representation for Key Hacker Identification in Underground
Forums), designed to identify these key hackers by modeling each user as a
textual sequence. This sequence is processed through a large language model
(LLM) for domain-specific adaptation, with LLMs acting as feature extractors.
These extracted features are then fed into a Graph Neural Network (GNN) to
model user structural relationships, significantly improving identification
accuracy. Furthermore, we employ BERTopic (Bidirectional Encoder
Representations from Transformers Topic Modeling) to extract personalized
topics from user-generated content, enabling multiple textual representations
per user and optimizing the selection of the most representative sequence. Our
study demonstrates that fine-tuned LLMs outperform state-of-the-art methods in
identifying key hackers. Additionally, when combined with GNNs, our model
achieves significant improvements, resulting in approximately 6% and 10%
increases in accuracy and F1-score, respectively, over existing methods.
EUREKHA was tested on the Hack-Forums dataset, and we provide open-source
access to our code.

æè¦ï¼<paragraph>å°ä¸è«å£æ¯ç¶²è·¯ç¯ç½ªæ´»åçæ¨ç´ï¼æä¾å¿ååè¦é¿å³çµ±ç¶²è·¯ç£ç£çç©ºéãå¨éäºé±èçç¤¾ç¾¤ä¸­ï¼æ¡æè¡çºèåä½äº¤æéæ³ç¥è­ãå·¥å·åç­ç¥ï¼æ¨åå¾é§­å®¢æè¡å°é·å®ç«åè³æãæ¡æè»é«åé¶æå·®æ¼æ´çåç¨®ç¶²è·¯å¨èãæ¾åºéäºè¡åèå¾çééµç½åèï¼å³ééµé§­å®¢ï¼è³ééè¦ï¼ä½ä»ç¶æ¯ä¸åè¤éçææ°ãæ¬ææåºäºä¸ç¨®ç¨±çº EUREKHAï¼å¢å¼·ä½¿ç¨èè¡¨å¾µä»¥è­å¥å°ä¸è«å£ä¸­çééµé§­å®¢ï¼çæ°æ¹æ³ï¼æ¨å¨ééå°æ¯åä½¿ç¨èå»ºæ¨¡çºæå­åºåä¾è­å¥éäºééµé§­å®¢ãæ­¤åºåééå¤§åèªè¨æ¨¡åï¼LLMï¼èçä»¥é²è¡ç¹å®é åçé©æï¼å¶ä¸­ LLM ä½çºç¹å¾µèåå¨ãç¶å¾å°éäºèåçç¹å¾µè¼¸å¥åç¥ç¶ç¶²è·¯ï¼GNNï¼ä»¥å»ºæ¨¡ä½¿ç¨èçµæ§éä¿ï¼å¤§å¹æåè­å¥æºç¢ºåº¦ãæ­¤å¤ï¼æåæ¡ç¨ BERTopicï¼ä¾èª Transformer ä¸»é¡å»ºæ¨¡çéåç·¨ç¢¼å¨è¡¨å¾µï¼å¾ä½¿ç¨èç¢ççå§å®¹ä¸­èååäººåä¸»é¡ï¼çºæ¯åä½¿ç¨èåç¨å¤åæå­è¡¨å¾µï¼ä¸¦æä½³åæå·ä»£è¡¨æ§åºåçé¸æãæåçç ç©¶è¡¨æï¼å¾®èª¿å¾ç LLM å¨è­å¥ééµé§­å®¢æ¹é¢åªæ¼æåé²çæ¹æ³ãæ­¤å¤ï¼ç¶è GNN çµåä½¿ç¨æï¼æåçæ¨¡åç²å¾é¡¯èçæåï¼èç¾ææ¹æ³ç¸æ¯ï¼æºç¢ºåº¦å F1 åæ¸åå¥æé«äºç´ 6% å 10%ãEUREKHA å·²å¨ Hack-Forums è³æéä¸é²è¡æ¸¬è©¦ï¼æåæä¾éæºæ¹å¼å­åæåçç¨å¼ç¢¼ã</paragraph>

##### **When are 1.58 bits enough? A Bottom-up Exploration of BitNet Quantization**
2411.05882v1 by Jacob Nielsen, Lukas Galke, Peter Schneider-Kamp

Contemporary machine learning models, such as language models, are powerful,
but come with immense resource requirements both at training and inference
time. It has been shown that decoder-only language models can be trained to a
competitive state with ternary weights (1.58 bits per weight), facilitating
efficient inference. Here, we start our exploration with non-transformer model
architectures, investigating 1.58-bit training for multi-layer perceptrons and
graph neural networks. Then, we explore 1.58-bit training in other
transformer-based language models, namely encoder-only and encoder-decoder
models. Our results show that in all of these settings, 1.58-bit training is on
par with or sometimes even better than the standard 32/16-bit models.

æè¦ï¼ç¶ä»£æ©å¨å­¸ç¿æ¨¡åï¼ä¾å¦èªè¨æ¨¡åï¼åè½å¼·å¤§ï¼
ä½å¨è¨ç·´åæ¨è«æéä¸é½éè¦å¤§éçè³æºãå·²ç¶è­æï¼åè§£ç¢¼å¨èªè¨æ¨¡åå¯ä»¥ç¨ä¸åæ¬éï¼æ¯åæ¬é 1.58 ä½åï¼è¨ç·´å°ç«¶ç­çæï¼ä¿é²ææççæ¨è«ãå¨æ­¤ï¼æåå¾éTransformeræ¨¡åæ¶æ§éå§æ¢è¨ï¼ç ç©¶å¤å±¤æç¥å¨ååç¥ç¶ç¶²è·¯ç 1.58 ä½åè¨ç·´ãæ¥èï¼æåæ¢è¨å¶ä»åºæ¼Transformerçèªè¨æ¨¡åï¼å³åç·¨ç¢¼å¨åç·¨ç¢¼å¨-è§£ç¢¼å¨æ¨¡åï¼ç 1.58 ä½åè¨ç·´ãæåççµæé¡¯ç¤ºï¼å¨ææéäºè¨­å®ä¸­ï¼1.58 ä½åè¨ç·´èæ¨æº 32/16 ä½åæ¨¡åç¸ç¶ï¼ææçè³æ´å¥½ã

##### **Exploring the Alignment Landscape: LLMs and Geometric Deep Models in Protein Representation**
2411.05316v1 by Dong Shu, Bingbing Duan, Kai Guo, Kaixiong Zhou, Jiliang Tang, Mengnan Du

Latent representation alignment has become a foundational technique for
constructing multimodal large language models (MLLM) by mapping embeddings from
different modalities into a shared space, often aligned with the embedding
space of large language models (LLMs) to enable effective cross-modal
understanding. While preliminary protein-focused MLLMs have emerged, they have
predominantly relied on heuristic approaches, lacking a fundamental
understanding of optimal alignment practices across representations. In this
study, we explore the alignment of multimodal representations between LLMs and
Geometric Deep Models (GDMs) in the protein domain. We comprehensively evaluate
three state-of-the-art LLMs (Gemma2-2B, LLaMa3.1-8B, and LLaMa3.1-70B) with
four protein-specialized GDMs (GearNet, GVP, ScanNet, GAT). Our work examines
alignment factors from both model and protein perspectives, identifying
challenges in current alignment methodologies and proposing strategies to
improve the alignment process. Our key findings reveal that GDMs incorporating
both graph and 3D structural information align better with LLMs, larger LLMs
demonstrate improved alignment capabilities, and protein rarity significantly
impacts alignment performance. We also find that increasing GDM embedding
dimensions, using two-layer projection heads, and fine-tuning LLMs on
protein-specific data substantially enhance alignment quality. These strategies
offer potential enhancements to the performance of protein-related multimodal
models. Our code and data are available at
https://github.com/Tizzzzy/LLM-GDM-alignment.

æè¦ï¼æ½å¨è¡¨å¾µå°é½å·²æçºå»ºæ§å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) çåºç¤æè¡ï¼æ¹æ³æ¯å°ä¸åæ¨¡æçåµå¥æ å°å°å±äº«ç©ºéä¸­ï¼éå¸¸èå¤§åèªè¨æ¨¡å (LLM) çåµå¥ç©ºéå°é½ï¼ä»¥å¯¦ç¾ææçè·¨æ¨¡æçè§£ãéç¶åæ­¥ä»¥èç½è³ªçºéé»ç MLLM å·²åºç¾ï¼ä½å®åä¸»è¦ä¾è³´åç¼å¼æ¹æ³ï¼ç¼ºä¹å°è·¨è¡¨å¾µæä½³å°é½å¯¦åçåºæ¬çè§£ãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨äºèç½è³ªé åä¸­ LLM èå¹¾ä½æ·±åº¦æ¨¡å (GDM) ä¹éçå¤æ¨¡æè¡¨å¾µå°é½ãæåå¨é¢è©ä¼°äºä¸åæåé²ç LLMï¼Gemma2-2BãLLaMa3.1-8B å LLaMa3.1-70Bï¼èååèç½è³ªå°ç¨ GDMï¼GearNetãGVPãScanNetãGATï¼ãæåçç ç©¶å¾æ¨¡ååèç½è³ªè§åº¦æª¢è¦å°é½å ç´ ï¼è­å¥ç¶åå°é½æ¹æ³çææ°ï¼ä¸¦æåºæ¹åå°é½ç¨åºçç­ç¥ãæåçééµç¼ç¾é¡¯ç¤ºï¼åæåå«åå½¢å 3D çµæ§è³è¨ç GDM è LLM çå°é½ææè¼ä½³ï¼è¼å¤§ç LLM å±ç¾åºæ´ä½³çå°é½è½åï¼èèç½è³ªçç¨ææ§é¡¯èå½±é¿å°é½æè½ãæåéç¼ç¾ï¼å¢å  GDM åµå¥ç¶­åº¦ãä½¿ç¨å©å±¤æå½±é ­ï¼ä»¥åéå°èç½è³ªç¹å®è³æå¾®èª¿ LLMï¼å¯ä»¥å¤§å¹æåå°é½åè³ªãéäºç­ç¥çºèç½è³ªç¸éå¤æ¨¡ææ¨¡åçæè½æä¾æ½å¨çå¼·åãæåçç¨å¼ç¢¼åè³æå¯å¨ https://github.com/Tizzzzy/LLM-GDM-alignment åå¾ã

##### **LEGO-GraphRAG: Modularizing Graph-based Retrieval-Augmented Generation for Design Space Exploration**
2411.05844v1 by Yukun Cao, Zengyi Gao, Zhiyang Li, Xike Xie, S Kevin Zhou

GraphRAG addresses significant challenges in Retrieval-Augmented Generation
(RAG) by leveraging graphs with embedded knowledge to enhance the reasoning
capabilities of Large Language Models (LLMs). Despite its promising potential,
the GraphRAG community currently lacks a unified framework for fine-grained
decomposition of the graph-based knowledge retrieval process. Furthermore,
there is no systematic categorization or evaluation of existing solutions
within the retrieval process. In this paper, we present LEGO-GraphRAG, a
modular framework that decomposes the retrieval process of GraphRAG into three
interconnected modules: subgraph-extraction, path-filtering, and
path-refinement. We systematically summarize and classify the algorithms and
neural network (NN) models relevant to each module, providing a clearer
understanding of the design space for GraphRAG instances. Additionally, we
identify key design factors, such as Graph Coupling and Computational Cost,
that influence the effectiveness of GraphRAG implementations. Through extensive
empirical studies, we construct high-quality GraphRAG instances using a
representative selection of solutions and analyze their impact on retrieval and
reasoning performance. Our findings offer critical insights into optimizing
GraphRAG instance design, ultimately contributing to the advancement of more
accurate and contextually relevant LLM applications.

æè¦ï¼GraphRAG ééå©ç¨å·åµå¥ç¥è­çåè¡¨ä¾å¢å¼·å¤§åèªè¨æ¨¡å (LLM) çæ¨çè½åï¼è§£æ±ºäºæª¢ç´¢å¢å¼·çæ (RAG) ä¸­çéå¤§ææ°ãåç®¡å·æä»¤äººæå¾çæ½åï¼ä½ GraphRAG ç¤¾ç¾¤ç®åç¼ºä¹ä¸åçµ±ä¸çæ¶æ§ï¼ç¨æ¼å°åºæ¼åè¡¨çç¥è­æª¢ç´¢éç¨é²è¡ç´°ç²åº¦çåè§£ãæ­¤å¤ï¼å¨æª¢ç´¢éç¨ä¸­ï¼ç¾æè§£æ±ºæ¹æ¡ä¸¦æªé²è¡ç³»çµ±æ§çåé¡æè©ä¼°ãå¨æ¬æä¸­ï¼æåæåºäº LEGO-GraphRAGï¼éæ¯ä¸åæ¨¡çµåæ¶æ§ï¼å° GraphRAG çæª¢ç´¢éç¨åè§£çºä¸åç¸äºé£æ¥çæ¨¡çµï¼å­åèåãè·¯å¾éæ¿¾åè·¯å¾ç²¾çãæåç³»çµ±æ§å°ç¸½çµååé¡èæ¯åæ¨¡çµç¸éçæ¼ç®æ³åç¥ç¶ç¶²è·¯ (NN) æ¨¡åï¼æä¾å° GraphRAG å¯¦ä¾è¨­è¨ç©ºéçæ´æ¸æ°çè§£ãæ­¤å¤ï¼æåæ¾åºå½±é¿ GraphRAG å¯¦ä½æææ§çééµè¨­è¨å ç´ ï¼ä¾å¦åè¡¨è¦ååéç®ææ¬ãééå»£æ³çç¶é©ç ç©¶ï¼æåä½¿ç¨å·ä»£è¡¨æ§çè§£æ±ºæ¹æ¡é¸æä¾å»ºæ§é«åè³ªç GraphRAG å¯¦ä¾ï¼ä¸¦åæå®åå°æª¢ç´¢åæ¨çæè½çå½±é¿ãæåçç ç©¶çµææä¾äºåªå GraphRAG å¯¦ä¾è¨­è¨çéè¦è¦è§£ï¼æçµæå©æ¼æ¨é²æ´æºç¢ºä¸èèçµ¡ç¸éç LLM æç¨ã

##### **MEG: Medical Knowledge-Augmented Large Language Models for Question Answering**
2411.03883v2 by Laura Cabello, Carmen Martin-Turrero, Uchenna Akujuobi, Anders SÃ¸gaard, Carlos Bobed

Question answering is a natural language understanding task that involves
reasoning over both explicit context and unstated, relevant domain knowledge.
Large language models (LLMs), which underpin most contemporary question
answering systems, struggle to induce how concepts relate in specialized
domains such as medicine. Existing medical LLMs are also costly to train. In
this work, we present MEG, a parameter-efficient approach for medical
knowledge-augmented LLMs. MEG uses a lightweight mapping network to integrate
graph embeddings into the LLM, enabling it to leverage external knowledge in a
cost-effective way. We evaluate our method on four popular medical
multiple-choice datasets and show that LLMs greatly benefit from the factual
grounding provided by knowledge graph embeddings. MEG attains an average of
+10.2% accuracy over the Mistral-Instruct baseline, and +6.7% over specialized
models like BioMistral. We also show results based on Llama-3. Finally, we show
that MEG's performance remains robust to the choice of graph encoder.

æè¦ï¼åç­æ¯èªç¶èªè¨çè§£ä»»åï¼æ¶åå°æç¢ºçä¸ä¸æåæªèªªæçç¸éé åç¥è­é²è¡æ¨çãæ¯æå¤§å¤æ¸ç¶ä»£åç­ç³»çµ±çå¤§åèªè¨æ¨¡å (LLM) é£ä»¥æ¨è«æ¦å¿µå¦ä½å¨é«å­¸ç­å°æ¥­é åä¸­éè¯ãç¾æçé«å­¸ LLM è¨ç·´ææ¬ä¹å¾é«ãå¨éé å·¥ä½ä¸­ï¼æåæåºäº MEGï¼éæ¯ä¸ç¨®ç¨æ¼é«å­¸ç¥è­å¢å¼· LLM çåæ¸æææ¹æ³ãMEG ä½¿ç¨è¼éç´æ å°ç¶²è·¯å°åè¡¨åµå¥æ´åå° LLM ä¸­ï¼ä½¿å¶è½å¤ ä»¥ç¶æ¿ææçæ¹å¼å©ç¨å¤é¨ç¥è­ãæåå¨ååæµè¡çé«å­¸å¤é¸é¡è³æéä¸è©ä¼°äºæåçæ¹æ³ï¼ä¸¦è¡¨æ LLM å¾ç¥è­åè¡¨åµå¥æä¾çå¯¦éä¾æä¸­åçåªæ·ºãMEG å¨ Mistral-Instruct åºæºä¸å¹³åæé«äº +10.2% çæºç¢ºåº¦ï¼å¨ BioMistral ç­å°éæ¨¡åä¸æé«äº +6.7%ãæåéå±ç¤ºäºåºæ¼ Llama-3 ççµæãæå¾ï¼æåè¡¨æ MEG çæ§è½å°åè¡¨ç·¨ç¢¼å¨çé¸æä¿æç©©å¥ã

##### **The American Sign Language Knowledge Graph: Infusing ASL Models with Linguistic Knowledge**
2411.03568v1 by Lee Kezar, Nidhi Munikote, Zian Zeng, Zed Sehyr, Naomi Caselli, Jesse Thomason

Language models for American Sign Language (ASL) could make language
technologies substantially more accessible to those who sign. To train models
on tasks such as isolated sign recognition (ISR) and ASL-to-English
translation, datasets provide annotated video examples of ASL signs. To
facilitate the generalizability and explainability of these models, we
introduce the American Sign Language Knowledge Graph (ASLKG), compiled from
twelve sources of expert linguistic knowledge. We use the ASLKG to train
neuro-symbolic models for 3 ASL understanding tasks, achieving accuracies of
91% on ISR, 14% for predicting the semantic features of unseen signs, and 36%
for classifying the topic of Youtube-ASL videos.

æè¦ï¼ç¾åæèª (ASL) çèªè¨æ¨¡åå¯ä»¥è®èªè¨æè¡å°æèªä½¿ç¨èæ´ææ¼ä½¿ç¨ãçºäºè¨ç·´æ¨¡åå·è¡æèªè¾¨è­ (ISR) å ASL è½ææè±æç­ä»»åï¼è³æéæä¾ ASL æå¢çè¨»è§£å½±çç¯ä¾ãçºäºä¿é²éäºæ¨¡åçæ¦æ¬æ§åå¯è§£éæ§ï¼æåå¼å¥äºç¾åæèªç¥è­åè­ (ASLKG)ï¼å®æ¯ç±åäºåå°å®¶èªè¨ç¥è­ä¾æºç·¨è­¯èæçãæåä½¿ç¨ ASLKG è¨ç·´ç¥ç¶ç¬¦èæ¨¡åä¾å·è¡ 3 é  ASL çè§£ä»»åï¼å¨ ISR ä¸éå° 91% çæºç¢ºåº¦ãå¨é æ¸¬æªè¦æå¢çèªç¾©ç¹å¾µä¸éå° 14%ï¼ä»¥åå¨åé¡ YouTube-ASL å½±çä¸»é¡ä¸éå° 36%ã

##### **Graph-DPEP: Decomposed Plug and Ensemble Play for Few-Shot Document Relation Extraction with Graph-of-Thoughts Reasoning**
2411.02864v1 by Tao Zhang, Ning Yan, Masood Mortazavi, Hoang H. Nguyen, Zhongfen Deng, Philip S. Yu

Large language models (LLMs) pre-trained on massive corpora have demonstrated
impressive few-shot learning capability on many NLP tasks. Recasting an NLP
task into a text-to-text generation task is a common practice so that
generative LLMs can be prompted to resolve it. However, performing
document-level relation extraction (DocRE) tasks with generative LLM models is
still challenging due to the structured output format of DocRE, which
complicates the conversion to plain text. Limited information available in
few-shot samples and prompt instructions induce further difficulties and
challenges in relation extraction for mentioned entities in a document. In this
paper, we represent the structured output as a graph-style triplet rather than
natural language expressions and leverage generative LLMs for the DocRE task.
Our approach, the Graph-DPEP framework is grounded in the reasoning behind
triplet explanation thoughts presented in natural language. In this framework,
we first introduce a ``decomposed-plug" method for performing the generation
from LLMs over prompts with type-space decomposition to alleviate the burden of
distinguishing all relation types. Second, we employ a verifier for calibrating
the generation and identifying overlooked query entity pairs. Third, we develop
"ensemble-play", reapplying generation on the entire type list by leveraging
the reasoning thoughts embedded in a sub-graph associated with the missing
query pair to address the missingness issue. Through extensive comparisons with
existing prompt techniques and alternative Language Models (LLMs), our
framework demonstrates superior performance on publicly available benchmarks in
experiments.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨æµ·éèªæåº«ä¸é åè¨ç·´ï¼å·²å¨è¨±å¤èªç¶èªè¨èçä»»åä¸å±ç¾åºä»¤äººå°è±¡æ·±å»çå°éæ¨£æ¬å­¸ç¿è½åãå°èªç¶èªè¨èçä»»åè½åçºæå­å°æå­ççæä»»åæ¯ä¸ç¨®å¸¸è¦åæ³ï¼éæ¨£çæå¼å¤§åèªè¨æ¨¡åå°±å¯ä»¥æç¤ºè§£æ±ºå®ãç¶èï¼ç±æ¼ DocRE ççµæ§åè¼¸åºæ ¼å¼ï¼ä½¿ç¨çæå¼å¤§åèªè¨æ¨¡åä¾å·è¡æä»¶ç´å¥éä¿èå (DocRE) ä»»åä»ç¶å·æææ°æ§ï¼éä½¿å¾è½æçºç´æå­è®å¾è¤éãå°éæ¨£æ¬åæç¤ºèªªæä¸­å¯ç¨çè³è¨æéï¼æå°è´å¨æä»¶ä¸­æå°å¯¦é«çéä¿èåä¸­ç¢çé²ä¸æ­¥çå°é£åææ°ãå¨æ¬æä¸­ï¼æåå°çµæ§åè¼¸åºè¡¨ç¤ºçºåå½¢æ¨£å¼çä¸åçµï¼èä¸æ¯èªç¶èªè¨è¡¨éï¼ä¸¦å©ç¨çæå¼å¤§åèªè¨æ¨¡åä¾å·è¡ DocRE ä»»åãæåçåæ³ï¼åå½¢ DPEP æ¡æ¶ï¼æ¯åºæ¼èªç¶èªè¨ä¸­åç¾çä¸åçµè§£éææ³èå¾çæ¨çãå¨éåæ¡æ¶ä¸­ï¼æåé¦åä»ç´¹ä¸ç¨®ãåè§£æå¥ãæ¹æ³ï¼ç¨æ¼å°å·æé¡åç©ºéåè§£çæç¤ºé²è¡å¤§åèªè¨æ¨¡åçæï¼ä»¥æ¸è¼ååææéä¿é¡åçè² æãå¶æ¬¡ï¼æåä½¿ç¨é©è­å¨ä¾æ ¡æºçæä¸¦è­å¥è¢«å¿½ç¥çæ¥è©¢å¯¦é«å°ãç¬¬ä¸ï¼æåéç¼ãæ´é«éæ²ãï¼ééå©ç¨èéºå¤±æ¥è©¢å°ç¸éçå­åä¸­åµå¥çæ¨çææ³ï¼å¨æ´åé¡ååè¡¨ä¸éæ°æç¨çæï¼ä»¥è§£æ±ºéºå¤±åé¡ãééèç¾ææç¤ºæè¡åæ¿ä»£èªè¨æ¨¡å (LLM) çå»£æ³æ¯è¼ï¼æåçæ¡æ¶å¨å¯¦é©ä¸­è­æäºå¨å¬éåºæºä¸çåªç°æ§è½ã

##### **Multimodal Commonsense Knowledge Distillation for Visual Question Answering**
2411.02722v1 by Shuo Yang, Siwen Luo, Soyeon Caren Han

Existing Multimodal Large Language Models (MLLMs) and Visual Language
Pretrained Models (VLPMs) have shown remarkable performances in the general
Visual Question Answering (VQA). However, these models struggle with VQA
questions that require external commonsense knowledge due to the challenges in
generating high-quality prompts and the high computational costs of
fine-tuning. In this work, we propose a novel graph-based multimodal
commonsense knowledge distillation framework that constructs a unified
relational graph over commonsense knowledge, visual objects and questions
through a Graph Convolutional Network (GCN) following a teacher-student
environment. This proposed framework is flexible with any type of teacher and
student models without further fine-tuning, and has achieved competitive
performances on the ScienceQA dataset.

æè¦ï¼ç¾æçå¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) åè¦è¦ºèªè¨é è¨ç·´æ¨¡å (VLPM) å¨ä¸è¬çè¦è¦ºåç­ (VQA) ä¸­å±ç¾äºåè¶çè¡¨ç¾ãç¶èï¼éäºæ¨¡åå¨éè¦å¤é¨å¸¸è­ç¥è­ç VQA åé¡ä¸æéå°å°é£ï¼åå å¨æ¼ç¢çé«åè³ªæç¤ºçææ°ä»¥åå¾®èª¿çé«éç®ææ¬ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸åæ°ç©çåºæ¼åå½¢çæ¨¡æå¸¸è­ç¥è­èåæ¶æ§ï¼ééåå½¢å·ç©ç¶²è·¯ (GCN) å¨å¸¸è­ç¥è­ãè¦è¦ºç©ä»¶ååé¡ä¸å»ºæ§ä¸åçµ±ä¸çéè¯åå½¢ï¼éµå¾ªå¸«çç°å¢ãéåæåºçæ¶æ§å°æ¼ä»»ä½é¡åçæå¸«åå­¸çæ¨¡åé½å·æå½æ§ï¼ç¡éé²ä¸æ­¥å¾®èª¿ï¼ä¸¦å¨ ScienceQA è³æéä¸åå¾äºæç«¶ç­åçè¡¨ç¾ã

##### **Geometry of orofacial neuromuscular signals: speech articulation decoding using surface electromyography**
2411.02591v1 by Harshavardhana T. Gowda, Zachary D. McNaughton, Lee M. Miller

Each year, millions of individuals lose the ability to speak intelligibly due
to causes such as neuromuscular disease, stroke, trauma, and head/neck cancer
surgery (e.g. laryngectomy) or treatment (e.g. radiotherapy toxicity to the
speech articulators). Effective communication is crucial for daily activities,
and losing the ability to speak leads to isolation, depression, anxiety, and a
host of detrimental sequelae. Noninvasive surface electromyography (sEMG) has
shown promise to restore speech output in these individuals. The goal is to
collect sEMG signals from multiple articulatory sites as people silently
produce speech and then decode the signals to enable fluent and natural
communication. Currently, many fundamental properties of orofacial
neuromuscular signals relating to speech articulation remain unanswered. They
include questions relating to 1) the data structure of the orofacial sEMG
signals, 2)the signal distribution shift of sEMG across individuals, 3) ability
of sEMG signals to span the entire English language phonetic space during
silent speech articulations, and 4) the generalization capability of
non-invasive sEMG based silent speech interfaces. We address these questions
through a series of experiments involving healthy human subjects. We show that
sEMG signals evince graph data structure and that the signal distribution shift
is given by a change of basis. Furthermore, we show that silently voiced
articulations spanning the entire English language phonetic space can be
decoded using small neural networks which can be trained with little data and
that such architectures work well across individuals. To ensure transparency
and reproducibility, we open-source all the data and codes used in this study.

æè¦ï¼æ¯å¹´ï¼æ¸ç¾è¬äººå çºç¥ç¶èèç¾çãä¸­é¢¨ãåµå·åé ­é ¸çæè¡ï¼ä¾å¦ååé¤è¡ï¼ææ²»çï¼ä¾å¦æ¾å°æ²»çå°è¨èªç¼é³å¨å®çæ¯æ§ï¼ç­åå èå¤±å»æ¸æ°èªªè©±çè½åãææçæºéå°æ¼æ¥å¸¸çæ´»è³ééè¦ï¼èå¤±å»èªªè©±è½åæå°è´å­¤ç«ãæ²®åªãç¦æ®åä¸ç³»åæå®³çå¾éºçãéä¾µå¥æ§è¡¨é¢èé»å (sEMG) å·²é¡¯ç¤ºåºæ¢å¾©éäºäººèªªè©±è¼¸åºçå¸æãç®æ¨æ¯å¾å¤åç¼é³é¨ä½æ¶é sEMG ä¿¡èï¼å çºäººåå¨ç¡è²å°ç¼åºè¨èªï¼ç¶å¾è§£ç¢¼ä¿¡èä»¥å¯¦ç¾æµå©åèªç¶çæºéãç®åï¼è¨±å¤èè¨èªç¼é³æéçé¡é¢ç¥ç¶èèä¿¡èçåºæ¬ç¹æ§ä»ç¶æ²æå¾å°è§£ç­ãå®ååæ¬è 1) é¡é¢ sEMG ä¿¡èçæ¸æçµæ§ã2) sEMG å¨åé«éçä¿¡èåä½è½ç§»ã3) sEMG ä¿¡èå¨ç¡è²è¨èªç¼é³éç¨ä¸­è·¨è¶æ´åè±èªèªè¨é³æ¨ç©ºéçè½åä»¥å 4) åºæ¼éä¾µå¥æ§ sEMG çç¡è²è¨èªä»é¢çæ¦æ¬è½åç¸éçåé¡ãæåééä¸ç³»åæ¶åå¥åº·äººé¡åè©¦èçå¯¦é©ä¾è§£æ±ºéäºåé¡ãæåè¡¨æ sEMG ä¿¡èè­æåæ¸æçµæ§ï¼ä¸¦ä¸ä¿¡èåä½è½ç§»æ¯ç±åºè®åççµ¦åºãæ­¤å¤ï¼æåè¡¨æä½¿ç¨å¯ä»¥ééå°éæ¸æè¨ç·´çå°ç¥ç¶ç¶²è·¯å¯ä»¥è§£ç¢¼è·¨è¶æ´åè±èªèªè¨é³æ¨ç©ºéçç¡è²ç¼é³ï¼ä¸¦ä¸æ­¤é¡æ¶æ§å¨ä¸ååé«ä¹ééè¡è¯å¥½ãçºäºç¢ºä¿éæåº¦åå¯éç¾æ§ï¼æåå¬éäºæ¬ç ç©¶ä¸­ä½¿ç¨çæææ¸æåä»£ç¢¼ã

##### **GraphXAIN: Narratives to Explain Graph Neural Networks**
2411.02540v2 by Mateusz Cedro, David Martens

Graph Neural Networks (GNNs) are a powerful technique for machine learning on
graph-structured data, yet they pose interpretability challenges, especially
for non-expert users. Existing GNN explanation methods often yield technical
outputs such as subgraphs and feature importance scores, which are not easily
understood. Building on recent insights from social science and other
Explainable AI (XAI) methods, we propose GraphXAIN, a natural language
narrative that explains individual predictions made by GNNs. We present a
model-agnostic and explainer-agnostic XAI approach that complements graph
explainers by generating GraphXAINs, using Large Language Models (LLMs) and
integrating graph data, individual predictions from GNNs, explanatory
subgraphs, and feature importances. We define XAI Narratives and XAI
Descriptions, highlighting their distinctions and emphasizing the importance of
narrative principles in effective explanations. By incorporating natural
language narratives, our approach supports graph practitioners and non-expert
users, aligning with social science research on explainability and enhancing
user understanding and trust in complex GNN models. We demonstrate GraphXAIN's
capabilities on a real-world graph dataset, illustrating how its generated
narratives can aid understanding compared to traditional graph explainer
outputs or other descriptive explanation methods.

æè¦ï¼åå½¢ç¥ç¶ç¶²è·¯ (GNN) æ¯ç¨æ¼åå½¢çµæ§è³æçæ©å¨å­¸ç¿å¼·å¤§æè¡ï¼ä½å®åæé æå¯è§£éæ§ææ°ï¼ç¹å¥æ¯å°æ¼éå°å®¶ä½¿ç¨èãç¾æç GNN è§£éæ¹æ³éå¸¸æç¢çæè¡è¼¸åºï¼ä¾å¦å­ååç¹å¾µéè¦æ§åæ¸ï¼éäºè¼¸åºä¸å®¹æçè§£ãå»ºæ§æ¼ç¤¾æç§å­¸åå¶ä»å¯è§£é AI (XAI) æ¹æ³çææ°è¦è§£ï¼æåæåº GraphXAINï¼éæ¯ä¸ç¨®èªç¶èªè¨æè¿°ï¼å¯ä»¥è§£é GNN ååºçåå¥é æ¸¬ãæåæåºä¸åèæ¨¡åç¡éä¸èè§£éå¨ç¡éç XAI æ¹æ³ï¼å®ééä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) åæ´ååå½¢è³æãGNN çåå¥é æ¸¬ãèªªææ§å­ååç¹å¾µéè¦æ§ä¾è£ååå½¢è§£éå¨ï¼é²èç¢ç GraphXAINãæåå®ç¾© XAI æè¿°å XAI æè¿°ï¼å¼·èª¿å®åçåå¥ï¼ä¸¦å¼·èª¿æè¿°ååå¨ææè§£éä¸­çéè¦æ§ãééçµåèªç¶èªè¨æè¿°ï¼æåçåæ³æ¯æ´åå½¢å¾æ¥­èåéå°å®¶ä½¿ç¨èï¼èå¯è§£éæ§çç¤¾æç§å­¸ç ç©¶ä¿æä¸è´ï¼ä¸¦å¢å¼·ä½¿ç¨èå°è¤é GNN æ¨¡åççè§£åä¿¡ä»»ãæåå¨çå¯¦ä¸çåå½¢è³æéä¸å±ç¤º GraphXAIN çåè½ï¼èªªæèå³çµ±åå½¢è§£éå¨è¼¸åºæå¶ä»æè¿°æ§è§£éæ¹æ³ç¸æ¯ï¼å¶ç¢ççæè¿°å¦ä½æå©æ¼çè§£ã

##### **Improving Scientific Hypothesis Generation with Knowledge Grounded Large Language Models**
2411.02382v1 by Guangzhi Xiong, Eric Xie, Amir Hassan Shariatmadari, Sikun Guo, Stefan Bekiranov, Aidong Zhang

Large language models (LLMs) have demonstrated remarkable capabilities in
various scientific domains, from natural language processing to complex
problem-solving tasks. Their ability to understand and generate human-like text
has opened up new possibilities for advancing scientific research, enabling
tasks such as data analysis, literature review, and even experimental design.
One of the most promising applications of LLMs in this context is hypothesis
generation, where they can identify novel research directions by analyzing
existing knowledge. However, despite their potential, LLMs are prone to
generating ``hallucinations'', outputs that are plausible-sounding but
factually incorrect. Such a problem presents significant challenges in
scientific fields that demand rigorous accuracy and verifiability, potentially
leading to erroneous or misleading conclusions. To overcome these challenges,
we propose KG-CoI (Knowledge Grounded Chain of Ideas), a novel system that
enhances LLM hypothesis generation by integrating external, structured
knowledge from knowledge graphs (KGs). KG-CoI guides LLMs through a structured
reasoning process, organizing their output as a chain of ideas (CoI), and
includes a KG-supported module for the detection of hallucinations. With
experiments on our newly constructed hypothesis generation dataset, we
demonstrate that KG-CoI not only improves the accuracy of LLM-generated
hypotheses but also reduces the hallucination in their reasoning chains,
highlighting its effectiveness in advancing real-world scientific research.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨®ç§å­¸é åå±ç¾åè¶çè½åï¼å¾èªç¶èªè¨èçå°è¤éçè§£æ±ºåé¡ä»»åãå®åçè§£åç¢çé¡ä¼¼äººé¡æå­çè½åçºæ¨é²ç§å­¸ç ç©¶éåäºæ°çå¯è½æ§ï¼è®è³æåæãæç»åé¡§ï¼çè³å¯¦é©è¨­è¨ç­ä»»åæçºå¯è½ãLLM å¨æ­¤èçµ¡ä¸­ææå¸æçæç¨ä¹ä¸æ¯åè¨­ç¢çï¼å®åè½ééåæç¾æç¥è­ä¾æ¾åºæ°çç ç©¶æ¹åãç¶èï¼åç®¡ LLM å·ææ½åï¼å®åå»å®¹æç¢çãå¹»è¦ºãï¼ä¹å°±æ¯è½èµ·ä¾åçä½äºå¯¦ä¸ä¸æ­£ç¢ºçè¼¸åºãæ­¤é¡åé¡å¨éè¦å´è¬¹æºç¢ºæ§åå¯é©è­æ§çç§å­¸é åä¸­æé æéå¤§ææ°ï¼æå¯è½å°è´é¯èª¤æèª¤å°æ§ççµè«ãçºäºåæéäºææ°ï¼æåæåº KG-CoIï¼ç¥è­åºç¤è§å¿µéï¼ï¼éæ¯ä¸ååµæ°çç³»çµ±ï¼å®ééæ´åç¥è­åè­ (KG) ä¸­çå¤é¨çµæ§åç¥è­ä¾å¢å¼· LLM åè¨­ç¢çãKG-CoI å¼å° LLM é²è¡çµæ§åæ¨çç¨åºï¼å°å¶è¼¸åºæ´çæè§å¿µé (CoI)ï¼ä¸¦åå«ä¸åç± KG æ¯æ´çæ¨¡çµä¾åµæ¸¬å¹»è¦ºãééæåæ°å»ºç«çåè¨­ç¢çè³æéé²è¡çå¯¦é©ï¼æåè­æ KG-CoI ä¸åæ¹åäº LLM ç¢ççåè¨­çæºç¢ºæ§ï¼ä¹æ¸å°äºå¶æ¨çéä¸­çå¹»è¦ºï¼çªé¡¯äºå¶å¨æ¨é²ç¾å¯¦ä¸çç§å­¸ç ç©¶ä¸­çæè½ã

##### **Can Language Models Enable In-Context Database?**
2411.01807v1 by Yu Pan, Hongfeng Yu, Tianjiao Zhao, Jianxin Sun

Large language models (LLMs) are emerging as few-shot learners capable of
handling a variety of tasks, including comprehension, planning, reasoning,
question answering, arithmetic calculations, and more. At the core of these
capabilities is LLMs' proficiency in representing and understanding structural
or semi-structural data, such as tables and graphs. Numerous studies have
demonstrated that reasoning on tabular data or graphs is not only feasible for
LLMs but also gives a promising research direction which treats these data as
in-context data. The lightweight and human readable characteristics of
in-context database can potentially make it an alternative for the traditional
database in typical RAG (Retrieval Augmented Generation) settings. However,
almost all current work focuses on static in-context data, which does not allow
dynamic update. In this paper, to enable dynamic database update, delta
encoding of database is proposed. We explore how data stored in traditional
RDBMS can be encoded as in-context text and evaluate LLMs' proficiency for CRUD
(Create, Read, Update and Delete) operations on in-context databases. A
benchmark named InConDB is presented and extensive experiments are conducted to
show the performance of different language models in enabling in-context
database by varying the database encoding method, prompting method, operation
type and input data distribution, revealing both the proficiency and
limitations.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) éæ¼¸æçºåéå°éç¯ä¾å°±è½èçåç¨®ä»»åçå­¸ç¿èï¼åæ¬çè§£ãè¦åãæ¨çãåç­ãç®è¡è¨ç®ç­ãéäºè½åçæ ¸å¿æ¯ LLM å¨è¡¨ç¤ºåçè§£çµæ§åæåçµæ§åè³æï¼ä¾å¦è¡¨æ ¼ååå½¢ï¼æ¹é¢çè½åãè¨±å¤ç ç©¶å·²è­æï¼LLM ä¸åå¯ä»¥æ¨è«è¡¨æ ¼è³ææåå½¢ï¼éæä¾äºä¸åæåæ¯çç ç©¶æ¹åï¼å°éäºè³æè¦çºèªå¢è³æãèªå¢è³æåº«çè¼éç´åäººé¡å¯è®åç¹æ§æå¯è½ä½¿å¶æçºå¸å RAGï¼æª¢ç´¢æ´åçæï¼è¨­å®ä¸­å³çµ±è³æåº«çæ¿ä»£æ¹æ¡ãç¶èï¼å¹¾ä¹ææç®åçå·¥ä½é½å°æ³¨æ¼éæèªå¢è³æï¼éä¸åè¨±åææ´æ°ãå¨æ¬æä¸­ï¼çºäºå¯¦ç¾åæè³æåº«æ´æ°ï¼æåºäºè³æåº«ç delta ç·¨ç¢¼ãæåæ¢è¨äºå¦ä½å°å²å­å¨å³çµ± RDBMS ä¸­çè³æç·¨ç¢¼çºèªå¢æå­ï¼ä¸¦è©ä¼° LLM å¨èªå¢è³æåº«ä¸é²è¡ CRUDï¼å»ºç«ãè®åãæ´æ°ååªé¤ï¼æä½çè½åãæåºäºåçº InConDB çåºæºï¼ä¸¦é²è¡äºå»£æ³çå¯¦é©ï¼ä»¥é¡¯ç¤ºä¸åèªè¨æ¨¡åå¨ééæ¹è®è³æåº«ç·¨ç¢¼æ¹æ³ãæç¤ºæ¹æ³ãæä½é¡ååè¼¸å¥è³æåä½ä¾åç¨èªå¢è³æåº«æ¹é¢çæè½ï¼æ­ç¤ºäºè½ååéå¶ã

##### **Graph-based Confidence Calibration for Large Language Models**
2411.02454v1 by Yukun Li, Sijia Wang, Lifu Huang, Li-Ping Liu

One important approach to improving the reliability of large language models
(LLMs) is to provide accurate confidence estimations regarding the correctness
of their answers. However, developing a well-calibrated confidence estimation
model is challenging, as mistakes made by LLMs can be difficult to detect. We
propose a novel method combining the LLM's self-consistency with labeled data
and training an auxiliary model to estimate the correctness of its responses to
questions. This auxiliary model predicts the correctness of responses based
solely on their consistent information. To set up the learning problem, we use
a weighted graph to represent the consistency among the LLM's multiple
responses to a question. Correctness labels are assigned to these responses
based on their similarity to the correct answer. We then train a graph neural
network to estimate the probability of correct responses. Experiments
demonstrate that the proposed approach substantially outperforms several of the
most recent methods in confidence calibration across multiple widely adopted
benchmark datasets. Furthermore, the proposed approach significantly improves
the generalization capability of confidence calibration on out-of-domain (OOD)
data.

æè¦ï¼ä¸ç¨®æ¹åå¤§åèªè¨æ¨¡å (LLM) å¯é æ§çéè¦æ¹æ³æ¯æä¾æéå¶ç­æ¡æ­£ç¢ºæ§çæºç¢ºä¿¡å¿ä¼°è¨ãç¶èï¼éç¼ä¸åæ ¡æºè¯å¥½çä¿¡å¿ä¼°è¨æ¨¡åå·æææ°æ§ï¼å çº LLM æç¯çé¯èª¤å¯è½é£ä»¥åµæ¸¬ãæåæåºä¸åæ°æ¹æ³ï¼çµå LLM çèªæä¸è´æ§èæ¨ç±¤è³æï¼ä¸¦è¨ç·´ä¸åè¼å©æ¨¡åä¾ä¼°è¨å¶å°åé¡çåææ­£ç¢ºæ§ãéåè¼å©æ¨¡ååæ ¹æå¶ä¸è´æ§è³è¨ä¾é æ¸¬åæçæ­£ç¢ºæ§ãçºäºè¨­å®å­¸ç¿åé¡ï¼æåä½¿ç¨ä¸åå æ¬åå½¢ä¾è¡¨ç¤º LLM å°ä¸ååé¡çå¤æ¬¡åæä¹éçä¸è´æ§ãæ­£ç¢ºæ§æ¨ç±¤ææ ¹æéäºåæèæ­£ç¢ºç­æ¡çç¸ä¼¼æ§åéçµ¦éäºåæãç¶å¾ï¼æåè¨ç·´ä¸ååå½¢ç¥ç¶ç¶²è·¯ä¾ä¼°è¨æ­£ç¢ºåæçæ©çãå¯¦é©è­æï¼ææåºçæ¹æ³å¨å¤åå»£æ³æ¡ç¨çåºæºè³æéä¸ï¼å¨ä¿¡å¿æ ¡æºæ¹é¢æé¡¯åªæ¼å¤ç¨®ææ°æ¹æ³ãæ­¤å¤ï¼ææåºçæ¹æ³é¡¯èæ¹åäºå¨é åå¤ (OOD) è³æä¸ä¿¡å¿æ ¡æºçæ³åè½åã

##### **Ontology Population using LLMs**
2411.01612v1 by Sanaz Saki Norouzi, Adrita Barua, Antrea Christou, Nikita Gautam, Andrew Eells, Pascal Hitzler, Cogan Shimizu

Knowledge graphs (KGs) are increasingly utilized for data integration,
representation, and visualization. While KG population is critical, it is often
costly, especially when data must be extracted from unstructured text in
natural language, which presents challenges, such as ambiguity and complex
interpretations. Large Language Models (LLMs) offer promising capabilities for
such tasks, excelling in natural language understanding and content generation.
However, their tendency to ``hallucinate'' can produce inaccurate outputs.
Despite these limitations, LLMs offer rapid and scalable processing of natural
language data, and with prompt engineering and fine-tuning, they can
approximate human-level performance in extracting and structuring data for KGs.
This study investigates LLM effectiveness for the KG population, focusing on
the Enslaved.org Hub Ontology. In this paper, we report that compared to the
ground truth, LLM's can extract ~90% of triples, when provided a modular
ontology as guidance in the prompts.

æè¦ï¼ç¥è­åè­ (KG) æä¾æå¤ç¨æ¼è³ææ´åãè¡¨ç¤ºåè¦è¦ºåãåç®¡ KG å¡«åè³ééè¦ï¼ä½å®éå¸¸å¾æè²´ï¼ç¹å¥æ¯å¨å¿é å¾èªç¶èªè¨ä¸­éçµæ§åæå­ä¸­æåè³ææï¼éæå¸¶ä¾ææ°ï¼ä¾å¦æ­§ç¾©åè¤éçè©®éãå¤§åèªè¨æ¨¡å (LLM) çºæ­¤é¡ä»»åæä¾äºæåæ¯çè½åï¼æé·èªç¶èªè¨çè§£åå§å®¹çæãç¶èï¼å®åãç¢çå¹»è¦ºãçå¾åå¯è½æç¢çä¸æºç¢ºçè¼¸åºãåç®¡æéäºéå¶ï¼LLM æä¾äºèªç¶èªè¨è³æçå¿«éä¸å¯æ´åèçï¼ä¸¦ä¸ééæç¤ºå·¥ç¨åå¾®èª¿ï¼å®åå¯ä»¥è¿ä¼¼äººé¡å±¤ç´çæè½ï¼ä»¥æååå»ºæ§ KG çè³æãæ¬ç ç©¶èª¿æ¥ LLM å° KG å¡«åçæææ§ï¼éé»éæ³¨ Enslaved.org Hub Ontologyãå¨æ¬æä¸­ï¼æåå ±åèçå¯¦ææ³ç¸æ¯ï¼ç¶å¨æç¤ºä¸­æä¾æ¨¡çµåæ¬ä½ä½çºæå°æï¼LLM å¯ä»¥æåç´ 90% çä¸åçµã

##### **Pre-trained Molecular Language Models with Random Functional Group Masking**
2411.01401v1 by Tianhao Peng, Yuchen Li, Xuhong Li, Jiang Bian, Zeke Xie, Ning Sui, Shahid Mumtaz, Yanwu Xu, Linghe Kong, Haoyi Xiong

Recent advancements in computational chemistry have leveraged the power of
trans-former-based language models, such as MoLFormer, pre-trained using a vast
amount of simplified molecular-input line-entry system (SMILES) sequences, to
understand and predict molecular properties and activities, a critical step in
fields like drug discovery and materials science. To further improve
performance, researchers have introduced graph neural networks with graph-based
molecular representations, such as GEM, incorporating the topology, geometry,
2D or even 3D structures of molecules into pre-training. While most of
molecular graphs in existing studies were automatically converted from SMILES
sequences, it is to assume that transformer-based language models might be able
to implicitly learn structure-aware representations from SMILES sequences. In
this paper, we propose \ours{} -- a SMILES-based \underline{\em M}olecular
\underline{\em L}anguage \underline{\em M}odel, which randomly masking SMILES
subsequences corresponding to specific molecular \underline{\em F}unctional
\underline{\em G}roups to incorporate structure information of atoms during the
pre-training phase. This technique aims to compel the model to better infer
molecular structures and properties, thus enhancing its predictive
capabilities. Extensive experimental evaluations across 11 benchmark
classification and regression tasks in the chemical domain demonstrate the
robustness and superiority of \ours{}. Our findings reveal that \ours{}
outperforms existing pre-training models, either based on SMILES or graphs, in
9 out of the 11 downstream tasks, ranking as a close second in the remaining
ones.

æè¦ï¼<paragraph>è¨ç®åå­¸çè¿æé²å±å·²å©ç¨è½æå¨èªè¨æ¨¡åçåéï¼ä¾å¦ MoLFormerï¼ä½¿ç¨å¤§éç°¡ååå­è¼¸å¥ç·æ¢è¼¸å¥ç³»çµ± (SMILES) åºåé²è¡é è¨ç·´ï¼ä»¥äºè§£åé æ¸¬åå­ç¹æ§åæ´»æ§ï¼éæ¯è¥ç©ç¼ç¾åææç§å­¸ç­é åçéè¦æ­¥é©ãçºäºé²ä¸æ­¥æåæè½ï¼ç ç©¶äººå¡å¼å¥äºå·æåå½¢çºåºç¤çåå­è¡¨ç¤ºçåå½¢ç¥ç¶ç¶²è·¯ï¼ä¾å¦ GEMï¼å°åå­çææ¨¸ãå¹¾ä½ã2D çè³ 3D çµæ§ç´å¥é è¨ç·´ä¸­ãéç¶ç¾æç ç©¶ä¸­çå¤§å¤æ¸åå­åå½¢é½æ¯å¾ SMILES åºåèªåè½æèä¾çï¼ä½å¯ä»¥åè¨­åºæ¼è½æå¨çèªè¨æ¨¡åå¯è½è½å¤ å¾ SMILES åºåä¸­é±å¼å­¸ç¿çµæ§æç¥è¡¨ç¤ºãå¨æ¬æä¸­ï¼æåæåº \ours{} -- ä¸ååºæ¼ SMILES ç\underline{\em M}olecular\underline{\em L}anguage \underline{\em M}odelï¼å®é¨æ©é®è½å°ææ¼ç¹å®åå­\underline{\em F}unctional\underline{\em G}roups ç SMILES å­åºåï¼ä»¥å¨é è¨ç·´éæ®µç´å¥åå­ççµæ§è³è¨ãæ­¤æè¡æ¨å¨å¼·å¶æ¨¡åæ´å¥½å°æ¨æ·åå­çµæ§åç¹æ§ï¼å¾èå¢å¼·å¶é æ¸¬è½åãå¨åå­¸é åç 11 ååºæºåé¡ååæ­¸ä»»åä¸­é²è¡çå»£æ³å¯¦é©è©ä¼°è­æäº \ours{} çç©©å¥æ§ååªè¶æ§ãæåçç ç©¶çµæé¡¯ç¤ºï¼\ours{} å¨ 11 åä¸æ¸¸ä»»åä¸­ç 9 åä»»åä¸­åªæ¼ç¾æçé è¨ç·´æ¨¡åï¼åºæ¼ SMILES æåå½¢ï¼ï¼å¨å©ä¸çä»»åä¸­æåç¬¬äºã</paragraph>

##### **Narrative Analysis of True Crime Podcasts With Knowledge Graph-Augmented Large Language Models**
2411.02435v1 by Xinyi Leng, Jason Liang, Jack Mauro, Xu Wang, Andrea L. Bertozzi, James Chapman, Junyuan Lin, Bohan Chen, Chenchen Ye, Temple Daniel, P. Jeffrey Brantingham

Narrative data spans all disciplines and provides a coherent model of the
world to the reader or viewer. Recent advancement in machine learning and Large
Language Models (LLMs) have enable great strides in analyzing natural language.
However, Large language models (LLMs) still struggle with complex narrative
arcs as well as narratives containing conflicting information. Recent work
indicates LLMs augmented with external knowledge bases can improve the accuracy
and interpretability of the resulting models. In this work, we analyze the
effectiveness of applying knowledge graphs (KGs) in understanding true-crime
podcast data from both classical Natural Language Processing (NLP) and LLM
approaches. We directly compare KG-augmented LLMs (KGLLMs) with classical
methods for KG construction, topic modeling, and sentiment analysis.
Additionally, the KGLLM allows us to query the knowledge base in natural
language and test its ability to factually answer questions. We examine the
robustness of the model to adversarial prompting in order to test the model's
ability to deal with conflicting information. Finally, we apply classical
methods to understand more subtle aspects of the text such as the use of
hearsay and sentiment in narrative construction and propose future directions.
Our results indicate that KGLLMs outperform LLMs on a variety of metrics, are
more robust to adversarial prompts, and are more capable of summarizing the
text into topics.

æè¦ï¼æäºè³ææ¶µèææå­¸ç§ï¼ä¸¦çºè®èæè§ç¾æä¾ä¸åé£è²«çä¸çæ¨¡åãæ©å¨å­¸ç¿åå¤§åèªè¨æ¨¡å (LLM) çææ°é²å±å¨åæèªç¶èªè¨æ¹é¢åå¾äºé·è¶³çé²æ­¥ãç¶èï¼å¤§åèªè¨æ¨¡å (LLM) ä»ç¶é£ä»¥æä»è¤éçæäºå¼§ç·ä»¥ååå«ç¸äºçç¾è³è¨çæäºãæè¿çç ç©¶è¡¨æï¼ä½¿ç¨å¤é¨ç¥è­åº«å¢å¼·ç LLM å¯ä»¥æé«æç¢çæ¨¡åçæºç¢ºæ§åå¯è§£éæ§ãå¨éé å·¥ä½ä¸­ï¼æååæäºå¨å¾å³çµ±èªç¶èªè¨èç (NLP) å LLM æ¹æ³ä¸­çè§£çå¯¦ç¯ç½ªæ­å®¢è³ææï¼æç¨ç¥è­åè­ (KG) çæææ§ãæåç´æ¥æ¯è¼äº KG å¢å¼·ç LLM (KGLLM) èç¨æ¼ KG å»ºæ§ãä¸»é¡å»ºæ¨¡åæç·åæçå³çµ±æ¹æ³ãæ­¤å¤ï¼KGLLM åè¨±æåä»¥èªç¶èªè¨æ¥è©¢ç¥è­åº«ï¼ä¸¦æ¸¬è©¦å¶äºå¯¦åç­åé¡çè½åãæåæª¢æ¥äºæ¨¡åå°å°ææ§æç¤ºçç©©å¥æ§ï¼ä»¥æ¸¬è©¦æ¨¡åèçç¸äºçç¾è³è¨çè½åãæå¾ï¼æåæç¨å³çµ±æ¹æ³ä¾çè§£ææ¬çæ´ç´°å¾®æ¹é¢ï¼ä¾å¦å¨æäºå»ºæ§ä¸­ä½¿ç¨éè½éèªªåæç·ï¼ä¸¦æåºæªä¾çæ¹åãæåççµæè¡¨æï¼KGLLM å¨åç¨®ææ¨ä¸åªæ¼ LLMï¼å°å°ææç¤ºæ´ç©©å¥ï¼ä¸¦ä¸æ´è½å¤ å°ææ¬ç¸½çµçºä¸»é¡ã

##### **WLPlan: Relational Features for Symbolic Planning**
2411.00577v1 by Dillon Z. Chen

Scalable learning for planning research generally involves juggling between
different programming languages for handling learning and planning modules
effectively. Interpreted languages such as Python are commonly used for
learning routines due to their ease of use and the abundance of highly
maintained learning libraries they exhibit, while compiled languages such as
C++ are used for planning routines due to their optimised resource usage.
Motivated by the need for tools for developing scalable learning planners, we
introduce WLPlan, a C++ package with Python bindings which implements recent
promising work for automatically generating relational features of planning
tasks. Such features can be used for any downstream routine, such as learning
domain control knowledge or probing and understanding planning tasks. More
specifically, WLPlan provides functionality for (1) transforming planning tasks
into graphs, and (2) embedding planning graphs into feature vectors via graph
kernels. The source code and instructions for the installation and usage of
WLPlan are available at tinyurl.com/42kymswc

æè¦ï¼å¯æ´åçå­¸ç¿è¦åç ç©¶éå¸¸éè¦å¨ä¸åçç¨å¼èªè¨ä¹éåæï¼æè½ææå°èçå­¸ç¿åè¦åæ¨¡çµãä¾å¦ Python ç­ç´è­¯èªè¨éå¸¸ç¨æ¼å­¸ç¿å¸¸å¼ï¼å çºå®åææ¼ä½¿ç¨ï¼ä¸æè¨±å¤ç¶­è­·å®åçå­¸ç¿å½å¼åº«ï¼èä¾å¦ C++ ç­ç·¨è­¯èªè¨åç¨æ¼è¦åå¸¸å¼ï¼å çºå®åè½æä½³åè³æºä½¿ç¨ãç±æ¼éè¦éç¼å¯æ´åå­¸ç¿è¦åå¨çå·¥å·ï¼æåå¼é²äº WLPlanï¼éæ¯ä¸åå·æ Python ç¹«çµç C++ å¥ä»¶ï¼å¯¦ä½äºè¿ææåéçèªåç¢çè¦åä»»åéä¿ç¹å¾µçå·¥ä½ãæ­¤é¡ç¹å¾µå¯ç¨æ¼ä»»ä½ä¸æ¸¸å¸¸å¼ï¼ä¾å¦å­¸ç¿é åæ§å¶ç¥è­ææ¢æ¸¬åçè§£è¦åä»»åãæ´å·é«å°èªªï¼WLPlan æä¾äºä»¥ä¸åè½ï¼(1) å°è¦åä»»åè½æçºåå½¢ï¼ä»¥å (2) ééåå½¢æ ¸å°è¦ååå½¢åµå¥ç¹å¾µåéãWLPlan çåå§ç¢¼åå®è£åä½¿ç¨èªªæå¯å¨ tinyurl.com/42kymswc åå¾

##### **GRS-QA -- Graph Reasoning-Structured Question Answering Dataset**
2411.00369v3 by Anish Pahilajani, Devasha Trivedi, Jincen Shuai, Khin S. Yone, Samyak Rajesh Jain, Namyong Park, Ryan A. Rossi, Nesreen K. Ahmed, Franck Dernoncourt, Yu Wang

Large Language Models (LLMs) have excelled in multi-hop question-answering
(M-QA) due to their advanced reasoning abilities. However, the impact of the
inherent reasoning structures on LLM M-QA performance remains unclear, largely
due to the absence of QA datasets that provide fine-grained reasoning
structures. To address this gap, we introduce the Graph Reasoning-Structured
Question Answering Dataset (GRS-QA), which includes both semantic contexts and
reasoning structures for QA pairs. Unlike existing M-QA datasets, where
different reasoning structures are entangled together, GRS-QA explicitly
captures intricate reasoning pathways by constructing reasoning graphs, where
nodes represent textual contexts and edges denote logical flows. These
reasoning graphs of different structures enable a fine-grained evaluation of
LLM reasoning capabilities across various reasoning structures. Our empirical
analysis reveals that LLMs perform differently when handling questions with
varying reasoning structures. This finding facilitates the exploration of
textual structures as compared with semantics.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ç±æ¼å¶åé²çæ¨çè½åï¼å¨å¤è·³åç­ (M-QA) ä¸­è¡¨ç¾åºè²ãç¶èï¼åºææ¨ççµæ§å° LLM M-QA æè½çå½±é¿ä»ä¸æ¸æ¥ï¼éä¸»è¦æ¯ç±æ¼ç¼ºä¹æä¾ç´°ç²åº¦æ¨ççµæ§ç QA è³æéãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äºåå½¢æ¨ççµæ§ååç­è³æé (GRS-QA)ï¼å¶ä¸­åå«èªç¾©èçµ¡å QA å°æçæ¨ççµæ§ãèç¾æç M-QA è³æéä¸åï¼å¶ä¸­ä¸åçæ¨ççµæ§ç³¾çºå¨ä¸èµ·ï¼GRS-QA ééå»ºæ§æ¨çåå½¢æç¢ºææè¤éçæ¨çè·¯å¾ï¼å¶ä¸­ç¯é»è¡¨ç¤ºæå­èçµ¡ï¼éç·£è¡¨ç¤ºéè¼¯æµç¨ãéäºä¸åçµæ§çæ¨çåå½¢è½å¤ ç´°ç·»å°è©ä¼° LLM å¨åç¨®æ¨ççµæ§ä¸­çæ¨çè½åãæåçå¯¦è­åæé¡¯ç¤ºï¼LLM å¨èçå·æä¸åæ¨ççµæ§çåé¡æè¡¨ç¾ä¸åãéåç¼ç¾ä¿é²äºå°æå­çµæ§èèªç¾©çæ¯è¼æ¢ç´¢ã

##### **Evaluating the Impact of Lab Test Results on Large Language Models Generated Differential Diagnoses from Clinical Case Vignettes**
2411.02523v1 by Balu Bhasuran, Qiao Jin, Yuzhang Xie, Carl Yang, Karim Hanna, Jennifer Costa, Cindy Shavor, Zhiyong Lu, Zhe He

Differential diagnosis is crucial for medicine as it helps healthcare
providers systematically distinguish between conditions that share similar
symptoms. This study assesses the impact of lab test results on differential
diagnoses (DDx) made by large language models (LLMs). Clinical vignettes from
50 case reports from PubMed Central were created incorporating patient
demographics, symptoms, and lab results. Five LLMs GPT-4, GPT-3.5, Llama-2-70b,
Claude-2, and Mixtral-8x7B were tested to generate Top 10, Top 5, and Top 1 DDx
with and without lab data. A comprehensive evaluation involving GPT-4, a
knowledge graph, and clinicians was conducted. GPT-4 performed best, achieving
55% accuracy for Top 1 diagnoses and 60% for Top 10 with lab data, with lenient
accuracy up to 80%. Lab results significantly improved accuracy, with GPT-4 and
Mixtral excelling, though exact match rates were low. Lab tests, including
liver function, metabolic/toxicology panels, and serology/immune tests, were
generally interpreted correctly by LLMs for differential diagnosis.

æè¦ï¼éå¥è¨ºæ·å°æ¼é«å­¸è³ééè¦ï¼å çºå®æå©æ¼é«çä¿å¥æä¾èç³»çµ±ååå·æç¸ä¼¼çççç¾çãéé ç ç©¶è©ä¼°äºå¯¦é©å®¤æª¢é©çµæå°å¤§åèªè¨æ¨¡å (LLM) ååºçéå¥è¨ºæ· (DDx) çå½±é¿ãå¾ PubMed Central ç 50 ä»½çä¾å ±åä¸­å»ºç«äºè¨åºç°¡å ±ï¼å¶ä¸­åå«æ£èäººå£çµ±è¨ãççåå¯¦é©å®¤çµæãæ¸¬è©¦äºäºå LLM GPT-4ãGPT-3.5ãLlama-2-70bãClaude-2 å Mixtral-8x7Bï¼ä»¥çæå¸¶åä¸å¸¶å¯¦é©å®¤æ¸æçå 10ãå 5 åå 1 DDxãé²è¡äºä¸é æ¶å GPT-4ãç¥è­åè­åè¨åºé«ççç¶åè©ä¼°ãGPT-4 è¡¨ç¾æä½³ï¼å¨æå¯¦é©å®¤æ¸æçææ³ä¸ï¼å 1 åè¨ºæ·çæºç¢ºçéå° 55%ï¼å 10 åçæºç¢ºçéå° 60%ï¼å¯¬é¬æºç¢ºçé«é 80%ãå¯¦é©å®¤çµæé¡¯èæé«äºæºç¢ºçï¼GPT-4 å Mixtral è¡¨ç¾åºè²ï¼åç®¡å®å¨å¹éçè¼ä½ãLLM éå¸¸å¯ä»¥æ­£ç¢ºè§£éåæ¬èåè½ãä»£è¬/æ¯çå­¸æª¢æ¥åè¡æ¸å­¸/åç«æ¸¬è©¦å¨å§çå¯¦é©å®¤æª¢é©ï¼ä»¥é²è¡éå¥è¨ºæ·ã

##### **Compositional Automata Embeddings for Goal-Conditioned Reinforcement Learning**
2411.00205v1 by Beyazit Yalcinkaya, Niklas Lauffer, Marcell Vazquez-Chanlatte, Sanjit A. Seshia

Goal-conditioned reinforcement learning is a powerful way to control an AI
agent's behavior at runtime. That said, popular goal representations, e.g.,
target states or natural language, are either limited to Markovian tasks or
rely on ambiguous task semantics. We propose representing temporal goals using
compositions of deterministic finite automata (cDFAs) and use cDFAs to guide RL
agents. cDFAs balance the need for formal temporal semantics with ease of
interpretation: if one can understand a flow chart, one can understand a cDFA.
On the other hand, cDFAs form a countably infinite concept class with Boolean
semantics, and subtle changes to the automaton can result in very different
tasks, making them difficult to condition agent behavior on. To address this,
we observe that all paths through a DFA correspond to a series of reach-avoid
tasks and propose pre-training graph neural network embeddings on "reach-avoid
derived" DFAs. Through empirical evaluation, we demonstrate that the proposed
pre-training method enables zero-shot generalization to various cDFA task
classes and accelerated policy specialization without the myopic suboptimality
of hierarchical methods.

æè¦ï¼ç®æ¨æ¢ä»¶å¼·åå­¸ç¿æ¯ä¸ç¨®å¨å·è¡éæ®µæ§å¶ AI ä»£çè¡çºçå¼·å¤§æ¹æ³ãè©±éå¦æ­¤ï¼ç±éçç®æ¨è¡¨ç¤ºï¼ä¾å¦ç®æ¨çææèªç¶èªè¨ï¼åéæ¼é¦¬å¯å¤«ä»»åæä¾è³´æ¼å«ç³ä¸æ¸çä»»åèªç¾©ãæåå»ºè­°ä½¿ç¨ç¢ºå®æ§æéçæèªåæ© (cDFA) ççµåä¾è¡¨ç¤ºæéç®æ¨ï¼ä¸¦ä½¿ç¨ cDFA ä¾æå° RL ä»£çãcDFA å¹³è¡¡äºå°å½¢å¼æéèªç¾©çéæ±èææ¼è§£éä¹éçéä¿ï¼å¦æä¸åäººè½çè§£æµç¨åï¼é£éº¼ä»å°±è½çè§£ cDFAãå¦ä¸æ¹é¢ï¼cDFA å½¢æäºä¸åå·æå¸æèªç¾©çå¯æ¸ç¡éæ¦å¿µé¡ï¼èå°èªåæ©çç´°å¾®æ´æ¹å¯è½æå°è´éå¸¸ä¸åçä»»åï¼éä½¿å¾å®åé£ä»¥å°ä»£çè¡çºé²è¡æ¢ä»¶åãçºäºè§£æ±ºéååé¡ï¼æåè§å¯å°éé DFA çææè·¯å¾é½å°ææ¼ä¸ç³»åå°éé¿åä»»åï¼ä¸¦æåºå°ãå°éé¿åè¡çãDFA é²è¡é è¨ç·´åç¥ç¶ç¶²è·¯åµå¥ãééç¶é©è©ä¼°ï¼æåè­æäºææåºçé è¨ç·´æ¹æ³è½å¤ å°åç¨® cDFA ä»»åé¡å¥é²è¡é¶æ¬¡å­¸ç¿æ³åï¼ä¸¦å éç­ç¥å°æ¥­åï¼èæ²æåå±¤æ¹æ³çè¿è¦æ¬¡åªæ§ã

##### **Building Multi-Agent Copilot towards Autonomous Agricultural Data Management and Analysis**
2411.00188v1 by Yu Pan, Jianxin Sun, Hongfeng Yu, Joe Luck, Geng Bai, Nipuna Chamara, Yufeng Ge, Tala Awada

Current agricultural data management and analysis paradigms are to large
extent traditional, in which data collecting, curating, integration, loading,
storing, sharing and analyzing still involve too much human effort and
know-how. The experts, researchers and the farm operators need to understand
the data and the whole process of data management pipeline to make fully use of
the data. The essential problem of the traditional paradigm is the lack of a
layer of orchestrational intelligence which can understand, organize and
coordinate the data processing utilities to maximize data management and
analysis outcome. The emerging reasoning and tool mastering abilities of large
language models (LLM) make it a potentially good fit to this position, which
helps a shift from the traditional user-driven paradigm to AI-driven paradigm.
In this paper, we propose and explore the idea of a LLM based copilot for
autonomous agricultural data management and analysis. Based on our previously
developed platform of Agricultural Data Management and Analytics (ADMA), we
build a proof-of-concept multi-agent system called ADMA Copilot, which can
understand user's intent, makes plans for data processing pipeline and
accomplishes tasks automatically, in which three agents: a LLM based
controller, an input formatter and an output formatter collaborate together.
Different from existing LLM based solutions, by defining a meta-program graph,
our work decouples control flow and data flow to enhance the predictability of
the behaviour of the agents. Experiments demonstrates the intelligence,
autonomy, efficacy, efficiency, extensibility, flexibility and privacy of our
system. Comparison is also made between ours and existing systems to show the
superiority and potential of our system.

æè¦ï¼<paragraph>ç®åçè¾²æ¥­è³æç®¡çèåææ¨¡å¼å¨å¾å¤§ç¨åº¦ä¸ä»æ¯å³çµ±çï¼å¶ä¸­è³ææ¶éãæ´çãæ´åãè¼å¥ãå²å­ãåäº«ååæä»ç¶éè¦å¤ªå¤çäººåèå°æ¥­ç¥è­ãå°å®¶ãç ç©¶äººå¡åè¾²å ´ç¶çèéè¦äºè§£è³æåæ´åè³æç®¡çæµç¨ï¼æè½ååå©ç¨è³æãå³çµ±æ¨¡å¼çåºæ¬åé¡æ¯ç¼ºä¹ä¸å±¤ç·¨ææºè½ï¼ç¡æ³çè§£ãçµç¹ååèª¿è³æèçå·¥å·ï¼ä»¥æå¤§åè³æç®¡çååæææãå¤§åèªè¨æ¨¡å (LLM) æ°èçæ¨çåå·¥å·ææ¡è½åä½¿å¶æ½å¨é©åéåè·ä½ï¼éæå©æ¼å¾å³çµ±çä½¿ç¨èé©åæ¨¡å¼è½è®çº AI é©åæ¨¡å¼ãå¨æ¬æä¸­ï¼æåæåºä¸¦æ¢è¨äºåºæ¼ LLM çå¯é§é§çæ³æ³ï¼ç¨æ¼èªååè¾²æ¥­è³æç®¡çååæãåºæ¼æåååéç¼çè¾²æ¥­è³æç®¡çååæ (ADMA) å¹³å°ï¼æåå»ºç«äºä¸ååçº ADMA Copilot çæ¦å¿µé©è­å¤ä»£çç³»çµ±ï¼å®å¯ä»¥çè§£ä½¿ç¨èçæåãè¦åè³æèçæµç¨ä¸¦èªåå®æä»»åï¼å¶ä¸­ä¸åä»£çï¼åºæ¼ LLM çæ§å¶å¨ãè¼¸å¥æ ¼å¼åç¨å¼åè¼¸åºæ ¼å¼åç¨å¼å±ååä½ãèç¾æçåºæ¼ LLM çè§£æ±ºæ¹æ¡ä¸åï¼ééå®ç¾©åç¨å¼åï¼æåçç ç©¶å°æ§å¶æµç¨åè³ææµç¨è§£è¦ï¼ä»¥å¢å¼·ä»£çè¡çºçå¯é æ¸¬æ§ãå¯¦é©è­æäºæåç³»çµ±çæºæ§ãèªä¸»æ§ãæè½ãæçãå¯æ´åæ§ãéæ´»æ§èé±ç§æ§ãæåä¹èç¾æç³»çµ±é²è¡æ¯è¼ï¼ä»¥é¡¯ç¤ºæåç³»çµ±çåªè¶æ§åæ½åã</paragraph>

##### **Exploring the Knowledge Mismatch Hypothesis: Hallucination Propensity in Small Models Fine-tuned on Data from Larger Models**
2411.00878v1 by Phil Wee, Riyadh Baghdadi

Recently, there has been an explosion of large language models created
through fine-tuning with data from larger models. These small models able to
produce outputs that appear qualitatively similar to significantly larger
models. However, one of the key limitations that have been observed with these
models is their propensity to hallucinate significantly more often than larger
models. In particular, they have been observed to generate coherent outputs
that involve factually incorrect information and spread misinformation,
toxicity, and stereotypes. There are many potential causes of hallucination, of
which, one hypothesis is that fine-tuning a model on data produced by a larger
model leads to a knowledge mismatch which contributes to hallucination. In
particular, it is hypothesized that there is a mismatch between the knowledge
that is fed to the model to fine-tune it and the knowledge that is already
present in the graph. Fine-tuning the model on data that has such mismatch
could contribute to an increased propensity to hallucinate. We show that on an
unseen test set, a smaller model fine-tuned on data generated from a larger
model produced more wrong answers when compared to models fine-tuned on data
created by the small model, which confirms the hypothesis.

æè¦ï¼æè¿ï¼éè¿ä½¿ç¨æ´å¤§æ¨¡åçæ°æ®è¿è¡å¾®è°ï¼åå»ºäºå¤§éè¯­è¨æ¨¡åçç¸ãè¿äºå°æ¨¡åè½å¤äº§çä¸ææ¾æ´å¤§çæ¨¡åå¨è´¨éä¸ç±»ä¼¼çè¾åºãç¶èï¼å¨è¿äºæ¨¡åä¸­è§å¯å°çä¸ä¸ªå³é®éå¶æ¯ï¼å®ä»¬æ¯æ´å¤§çæ¨¡åæ´å®¹æåºç°å¹»è§ãç¹å«æ¯ï¼å·²ç»è§å¯å°å®ä»¬ä¼çææ¶åäºå®ä¸æ­£ç¡®çä¿¡æ¯å¹¶ä¼ æ­éè¯¯ä¿¡æ¯ãæ¯æ§åå»æ¿å°è±¡çè¿è´¯è¾åºãå¹»è§æå¾å¤æ½å¨åå ï¼å¶ä¸­ä¸ä¸ªåè®¾æ¯ï¼å¨æ´å¤§æ¨¡åçæçæ°æ®ä¸å¾®è°æ¨¡åä¼å¯¼è´ç¥è¯ä¸å¹éï¼ä»èå¯¼è´å¹»è§ãç¹å«æ¯ï¼åè®¾æ¨¡åå¾®è°æé¦éçç¥è¯ä¸å¾ä¸­å·²æçç¥è¯ä¹é´å­å¨ä¸å¹éãå¨å·æè¿ç§ä¸å¹éçæ°æ®ä¸å¾®è°æ¨¡åå¯è½ä¼å¯¼è´å¹»è§å¾åå¢å ãæä»¬è¡¨æï¼å¨ä¸ä¸ªçä¸è§çæµè¯éä¸­ï¼ä¸ä¸ªå¨ä»ä¸ä¸ªæ´å¤§çæ¨¡åçæçæ°æ®ä¸å¾®è°çå°æ¨¡åï¼ä¸å¨å°æ¨¡ååå»ºçæ°æ®ä¸å¾®è°çæ¨¡åç¸æ¯ï¼äº§çäºæ´å¤éè¯¯çç­æ¡ï¼è¿è¯å®äºè¿ä¸åè®¾ã

##### **Failure Modes of LLMs for Causal Reasoning on Narratives**
2410.23884v1 by Khurram Yamin, Shantanu Gupta, Gaurav R. Ghosal, Zachary C. Lipton, Bryan Wilder

In this work, we investigate the causal reasoning abilities of large language
models (LLMs) through the representative problem of inferring causal
relationships from narratives. We find that even state-of-the-art language
models rely on unreliable shortcuts, both in terms of the narrative
presentation and their parametric knowledge. For example, LLMs tend to
determine causal relationships based on the topological ordering of events
(i.e., earlier events cause later ones), resulting in lower performance
whenever events are not narrated in their exact causal order. Similarly, we
demonstrate that LLMs struggle with long-term causal reasoning and often fail
when the narratives are long and contain many events. Additionally, we show
LLMs appear to rely heavily on their parametric knowledge at the expense of
reasoning over the provided narrative. This degrades their abilities whenever
the narrative opposes parametric knowledge. We extensively validate these
failure modes through carefully controlled synthetic experiments, as well as
evaluations on real-world narratives. Finally, we observe that explicitly
generating a causal graph generally improves performance while naive
chain-of-thought is ineffective. Collectively, our results distill precise
failure modes of current state-of-the-art models and can pave the way for
future techniques to enhance causal reasoning in LLMs.

æè¦ï¼å¨éé å·¥ä½ä¸­ï¼æåééæ¨è«æè¿°ä¸­çå æéä¿éåä»£è¡¨æ§åé¡ï¼ä¾æ¢è¨å¤§åèªè¨æ¨¡å (LLM) çå ææ¨çè½åãæåç¼ç¾ï¼å³ä½¿æ¯æåé²çèªè¨æ¨¡åï¼ä¹æä¾è³´æ¼ä¸å¯é çæ·å¾ï¼ç¡è«æ¯å¨æè¿°åç¾æå¶åæ¸ç¥è­æ¹é¢ãä¾å¦ï¼LLM å¾åæ¼æ ¹æäºä»¶çææ²é åºï¼å³ï¼è¼æ©çäºä»¶å°è´è¼æçäºä»¶ï¼ä¾ç¢ºå®å æéä¿ï¼ç¶äºä»¶æªæå¶ç¢ºåçå æé åºæè¿°æï¼å°±æå°è´è¼ä½çæè½ãåæ¨£å°ï¼æåè­æ LLM é£ä»¥é²è¡é·æå ææ¨çï¼ä¸¦ä¸ç¶æè¿°å¾é·ä¸åå«è¨±å¤äºä»¶æï¼å®åéå¸¸æå¤±æãæ­¤å¤ï¼æåè¡¨æ LLM ä¼¼ä¹éåº¦ä¾è³´å¶åæ¸ç¥è­ï¼èç§ç²äºå°ææä¾æè¿°çæ¨çãæ¯ç¶æè¿°èåæ¸ç¥è­ç¸è¡çªæï¼éå°±æéä½å®åçè½åãæåééä»ç´°æ§å¶çåæå¯¦é©ä»¥åå°çå¯¦ä¸çæè¿°çè©ä¼°ï¼å»£æ³é©è­äºéäºå¤±ææ¨¡å¼ãæå¾ï¼æåè§å¯å°ï¼æç¢ºç¢çå æåéå¸¸ææ¹åæè½ï¼èå¤©ççæèéåç¡æãç¸½çä¾èªªï¼æåççµæç²¾ç¢ºå°æçäºç¶åæåé²æ¨¡åçå¤±ææ¨¡å¼ï¼ä¸¦å¯ä»¥çºæªä¾å¢å¼· LLM ä¸­å ææ¨ççæè¡éªè·¯ã

##### **Plan-on-Graph: Self-Correcting Adaptive Planning of Large Language Model on Knowledge Graphs**
2410.23875v1 by Liyi Chen, Panrong Tong, Zhongming Jin, Ying Sun, Jieping Ye, Hui Xiong

Large Language Models (LLMs) have shown remarkable reasoning capabilities on
complex tasks, but they still suffer from out-of-date knowledge,
hallucinations, and opaque decision-making. In contrast, Knowledge Graphs (KGs)
can provide explicit and editable knowledge for LLMs to alleviate these issues.
Existing paradigm of KG-augmented LLM manually predefines the breadth of
exploration space and requires flawless navigation in KGs. However, this
paradigm cannot adaptively explore reasoning paths in KGs based on the question
semantics and self-correct erroneous reasoning paths, resulting in a bottleneck
in efficiency and effect. To address these limitations, we propose a novel
self-correcting adaptive planning paradigm for KG-augmented LLM named
Plan-on-Graph (PoG), which first decomposes the question into several
sub-objectives and then repeats the process of adaptively exploring reasoning
paths, updating memory, and reflecting on the need to self-correct erroneous
reasoning paths until arriving at the answer. Specifically, three important
mechanisms of Guidance, Memory, and Reflection are designed to work together,
to guarantee the adaptive breadth of self-correcting planning for graph
reasoning. Finally, extensive experiments on three real-world datasets
demonstrate the effectiveness and efficiency of PoG.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨è¤éä»»åä¸­å±ç¾åºéå¡çæ¨çè½åï¼ä½ä»å­å¨ç¥è­éæãå¹»è¦ºåæ±ºç­ä¸éæçåé¡ãç¸åå°ï¼ç¥è­åè­ (KG) å¯ä»¥æä¾æç¢ºä¸å¯ç·¨è¼¯çç¥è­ï¼ä¾ LLM ç·©è§£éäºåé¡ãç¾æç KG å¢å¼· LLM å¸ç¯æåé åå®ç¾©æ¢ç´¢ç©ºéçå»£åº¦ï¼ä¸¦éè¦å¨ KG ä¸­å®ç¾å°èªãç¶èï¼æ­¤å¸ç¯ç¡æ³æ ¹æåé¡èªæèªé©æå°æ¢ç´¢ KG ä¸­çæ¨çè·¯å¾ï¼ä¸¦èªè¡ç³¾æ­£é¯èª¤çæ¨çè·¯å¾ï¼å°è´æçåææçç¶é ¸ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäºä¸ååçºåå½¢è¨ç« (PoG) ç KG å¢å¼· LLM çæ°ç©èªä¿®æ­£èªé©æè¦åå¸ç¯ï¼å®é¦åå°åé¡åè§£æå¹¾åå­ç®æ¨ï¼ç¶å¾éè¤èªé©ææ¢ç´¢æ¨çè·¯å¾ãæ´æ°è¨æ¶é«ååæéè¦èªè¡ç³¾æ­£é¯èª¤æ¨çè·¯å¾çéç¨ï¼ç´å°å¾åºç­æ¡ãå·é«ä¾èªªï¼æå°ãè¨æ¶ååæéä¸åéè¦æ©å¶è¢«è¨­è¨çºååéä½ï¼ä»¥ä¿è­èªä¿®æ­£è¦åå¨åå½¢æ¨çä¸­çèªé©æå»£åº¦ãæå¾ï¼å¨ä¸åçå¯¦ä¸çè³æéä¸çå»£æ³å¯¦é©è­æäº PoG çæææ§åæçã

##### **LLaMo: Large Language Model-based Molecular Graph Assistant**
2411.00871v1 by Jinyoung Park, Minseong Bae, Dohwan Ko, Hyunwoo J. Kim

Large Language Models (LLMs) have demonstrated remarkable generalization and
instruction-following capabilities with instruction tuning. The advancements in
LLMs and instruction tuning have led to the development of Large
Vision-Language Models (LVLMs). However, the competency of the LLMs and
instruction tuning have been less explored in the molecular domain. Thus, we
propose LLaMo: Large Language Model-based Molecular graph assistant, which is
an end-to-end trained large molecular graph-language model. To bridge the
discrepancy between the language and graph modalities, we present the
multi-level graph projector that transforms graph representations into graph
tokens by abstracting the output representations of each GNN layer and motif
representations with the cross-attention mechanism. We also introduce
machine-generated molecular graph instruction data to instruction-tune the
large molecular graph-language model for general-purpose molecule and language
understanding. Our extensive experiments demonstrate that LLaMo shows the best
performance on diverse tasks, such as molecular description generation,
property prediction, and IUPAC name prediction. The code of LLaMo is available
at https://github.com/mlvlab/LLaMo.

æè¦ï¼å¤§åè¯­è¨æ¨¡å (LLM) å·²å±ç¤ºåºåè¶çæ¦æ¬åæä»¤éµå¾ªè½åï¼å¹¶è¿è¡æä»¤è°æ´ãLLM åæä»¤è°æ´çè¿æ­¥å¯¼è´äºå¤§åè§è§è¯­è¨æ¨¡å (LVLMs) çåå±ãç¶èï¼LLM åæä»¤è°æ´çè½åå¨åå­é¢åçç ç©¶è¾å°ãå æ­¤ï¼æä»¬æåºäº LLaMoï¼åºäºå¤§è¯­è¨æ¨¡åçåå­å¾å©æï¼è¿æ¯ä¸ä¸ªç«¯å°ç«¯è®­ç»çå¤§åå­å¾è¯­è¨æ¨¡åãä¸ºäºå¼¥åè¯­è¨åå¾æ¨¡å¼ä¹é´çå·®å¼ï¼æä»¬æåºäºå¤çº§å¾æå½±ä»ªï¼å®éè¿æ½è±¡æ¯ä¸ª GNN å±çè¾åºè¡¨ç¤ºååºåºè¡¨ç¤ºï¼ä½¿ç¨äº¤åæ³¨æåæºå¶ï¼å°å¾è¡¨ç¤ºè½¬æ¢ä¸ºå¾æ è®°ãæä»¬è¿å¼å¥äºæºå¨çæçåå­å¾æä»¤æ°æ®ï¼ä»¥å¯¹å¤§ååå­å¾è¯­è¨æ¨¡åè¿è¡æä»¤è°æ´ï¼ä»¥ç¨äºéç¨åå­åè¯­è¨çè§£ãæä»¬å¹¿æ³çå®éªè¡¨æï¼LLaMo å¨åå­æè¿°çæãå±æ§é¢æµå IUPAC åç§°é¢æµç­ä¸åä»»å¡ä¸è¡¨ç°åºæä½³æ§è½ãLLaMo çä»£ç å¯å¨ https://github.com/mlvlab/LLaMo è·å¾ã

##### **End-to-End Ontology Learning with Large Language Models**
2410.23584v1 by Andy Lo, Albert Q. Jiang, Wenda Li, Mateja Jamnik

Ontologies are useful for automatic machine processing of domain knowledge as
they represent it in a structured format. Yet, constructing ontologies requires
substantial manual effort. To automate part of this process, large language
models (LLMs) have been applied to solve various subtasks of ontology learning.
However, this partial ontology learning does not capture the interactions
between subtasks. We address this gap by introducing OLLM, a general and
scalable method for building the taxonomic backbone of an ontology from
scratch. Rather than focusing on subtasks, like individual relations between
entities, we model entire subcomponents of the target ontology by finetuning an
LLM with a custom regulariser that reduces overfitting on high-frequency
concepts. We introduce a novel suite of metrics for evaluating the quality of
the generated ontology by measuring its semantic and structural similarity to
the ground truth. In contrast to standard metrics, our metrics use deep
learning techniques to define more robust distance measures between graphs.
Both our quantitative and qualitative results on Wikipedia show that OLLM
outperforms subtask composition methods, producing more semantically accurate
ontologies while maintaining structural integrity. We further demonstrate that
our model can be effectively adapted to new domains, like arXiv, needing only a
small number of training examples. Our source code and datasets are available
at https://github.com/andylolu2/ollm.

æè¦ï¼æ¬ä½å¯¹äºé¢åç¥è¯çèªå¨æºå¨å¤çå¾æç¨ï¼å ä¸ºå®ä»¬ä»¥ç»æåæ ¼å¼è¡¨ç¤ºç¥è¯ãç¶èï¼æå»ºæ¬ä½éè¦å¤§éçæå¨å·¥ä½ãä¸ºäºèªå¨åè¿ä¸ªè¿ç¨çä¸é¨åï¼å¤§åè¯­è¨æ¨¡åï¼LLMï¼å·²è¢«åºç¨äºè§£å³æ¬ä½å­¦ä¹ çåç§å­ä»»å¡ãç¶èï¼è¿ç§é¨åæ¬ä½å­¦ä¹ å¹¶æ²¡æææå°å­ä»»å¡ä¹é´çäº¤äºãæä»¬éè¿å¼å¥ OLLM æ¥è§£å³è¿ä¸å·®è·ï¼è¿æ¯ä¸ç§ä»å¤´å¼å§æå»ºæ¬ä½åç±»éª¨æ¶çéç¨ä¸å¯æ©å±çæ¹æ³ãæä»¬æ²¡æä¸æ³¨äºå­ä»»å¡ï¼ä¾å¦å®ä½ä¹é´çä¸ªå«å³ç³»ï¼èæ¯éè¿ä½¿ç¨èªå®ä¹æ­£ååå¨å¾®è° LLM æ¥å¯¹ç®æ æ¬ä½çæ´ä¸ªå­ç»ä»¶è¿è¡å»ºæ¨¡ï¼è¯¥æ­£ååå¨åå°äºå¯¹é«é¢æ¦å¿µçè¿åº¦æåãæä»¬å¼å¥äºä¸å¥æ°çææ æ¥è¯ä¼°çææ¬ä½çè´¨éï¼æ¹æ³æ¯æµéå®ä¸å°é¢çå®å¼çè¯­ä¹åç»æç¸ä¼¼æ§ãä¸æ åææ ç¸åï¼æä»¬çææ ä½¿ç¨æ·±åº¦å­¦ä¹ ææ¯æ¥å®ä¹å¾ä¹é´çæ´ç¨³å¥çè·ç¦»åº¦éãæä»¬å¨ç»´åºç¾ç§ä¸çå®éåå®æ§ç»æè¡¨æï¼OLLM ä¼äºå­ä»»å¡ç»åæ¹æ³ï¼å¨ä¿æç»æå®æ´æ§çåæ¶çæè¯­ä¹ä¸æ´åç¡®çæ¬ä½ãæä»¬è¿ä¸æ­¥è¯æï¼æä»¬çæ¨¡åå¯ä»¥ææå°éåºæ°çé¢åï¼å¦ arXivï¼åªéè¦å°éçè®­ç»æ ·æ¬ãæä»¬çæºä»£ç åæ°æ®éå¯å¨ https://github.com/andylolu2/ollm è·å¾ã

##### **Graph-Augmented Relation Extraction Model with LLMs-Generated Support Document**
2410.23452v1 by Vicky Dong, Hao Yu, Yao Chen

This study introduces a novel approach to sentence-level relation extraction
(RE) that integrates Graph Neural Networks (GNNs) with Large Language Models
(LLMs) to generate contextually enriched support documents. By harnessing the
power of LLMs to generate auxiliary information, our approach crafts an
intricate graph representation of textual data. This graph is subsequently
processed through a Graph Neural Network (GNN) to refine and enrich the
embeddings associated with each entity ensuring a more nuanced and
interconnected understanding of the data. This methodology addresses the
limitations of traditional sentence-level RE models by incorporating broader
contexts and leveraging inter-entity interactions, thereby improving the
model's ability to capture complex relationships across sentences. Our
experiments, conducted on the CrossRE dataset, demonstrate the effectiveness of
our approach, with notable improvements in performance across various domains.
The results underscore the potential of combining GNNs with LLM-generated
context to advance the field of relation extraction.

æè¦ï¼æ¬ç ç©¶æåºäºä¸åå¥å­å±¤ç´éä¿èå (RE) çæ°æ¹æ³ï¼è©²æ¹æ³æ´åäºåå½¢ç¥ç¶ç¶²è·¯ (GNN) åå¤§åèªè¨æ¨¡å (LLM)ï¼ä»¥ç¢çèçµ¡è±å¯çæ¯æ´æä»¶ãééå©ç¨ LLM çåè½ä¾ç¢çè¼å©è³è¨ï¼æåçåæ³å»ºç«äºä¸åææ¬è³æçè¤éåå½¢è¡¨ç¤ºãæ­¤åå½¢é¨å¾ééåå½¢ç¥ç¶ç¶²è·¯ (GNN) é²è¡èçï¼ä»¥æ¹ååè±å¯èæ¯åå¯¦é«ç¸éçåµå¥ï¼ç¢ºä¿å°è³æææ´ç´°ç·»ä¸ç¸äºé£çµççè§£ãæ­¤æ¹æ³ééç´å¥æ´å»£æ³çèçµ¡ä¸¦å©ç¨å¯¦é«éäºåï¼ä¾è§£æ±ºå³çµ±å¥å­å±¤ç´ RE æ¨¡åçéå¶ï¼é²èæåæ¨¡åææè·¨å¥å­çè¤ééä¿çè½åãæåå¨ CrossRE è³æéä¸å·è¡çå¯¦é©è­æäºæåæ¹æ³çæææ§ï¼å¨åç¨®é åçæè½é½æé¡¯èçæåãéäºçµæå¼·èª¿äºå° GNN è LLM ç¢ççèçµ¡ç¸çµåï¼ä»¥æ¨é²éä¿èåé åçæ½åã

##### **FlowLLM: Flow Matching for Material Generation with Large Language Models as Base Distributions**
2410.23405v1 by Anuroop Sriram, Benjamin Kurt Miller, Ricky T. Q. Chen, Brandon M. Wood

Material discovery is a critical area of research with the potential to
revolutionize various fields, including carbon capture, renewable energy, and
electronics. However, the immense scale of the chemical space makes it
challenging to explore all possible materials experimentally. In this paper, we
introduce FlowLLM, a novel generative model that combines large language models
(LLMs) and Riemannian flow matching (RFM) to design novel crystalline
materials. FlowLLM first fine-tunes an LLM to learn an effective base
distribution of meta-stable crystals in a text representation. After converting
to a graph representation, the RFM model takes samples from the LLM and
iteratively refines the coordinates and lattice parameters. Our approach
significantly outperforms state-of-the-art methods, increasing the generation
rate of stable materials by over three times and increasing the rate for
stable, unique, and novel crystals by $\sim50\%$ - a huge improvement on a
difficult problem. Additionally, the crystals generated by FlowLLM are much
closer to their relaxed state when compared with another leading model,
significantly reducing post-hoc computational cost.

æè¦ï¼ææç¼ç¾æ¯ä¸åéè¦çç ç©¶é åï¼å·æé©æ°åç¨®é åçæ½åï¼åæ¬ç¢³æéãå¯åçè½æºåé»å­ç¢åãç¶èï¼åå­¸ç©ºéçå·¨å¤§è¦æ¨¡ä½¿å¾å¯¦é©æ¢ç´¢ææå¯è½çææå·æææ°æ§ãå¨æ¬æä¸­ï¼æåä»ç´¹äº FlowLLMï¼éæ¯ä¸ç¨®æ°ç©ççææ¨¡åï¼çµåäºå¤§åèªè¨æ¨¡å (LLM) åé»æ¼æµå¹é (RFM) ä¾è¨­è¨æ°åæ¶é«ææãFlowLLM é¦åå¾®èª¿ LLMï¼ä»¥å­¸ç¿ææ¬è¡¨ç¤ºä¸­äºç©©ææ¶é«çææåºç¤åä½ãå¨è½æçºåå½¢è¡¨ç¤ºå¾ï¼RFM æ¨¡åå¾ LLM ä¸­ç²åæ¨£æ¬ï¼ä¸¦åè¦ç²¾çåæ¨åæ¶æ ¼åæ¸ãæåçåæ³é¡¯èåªæ¼æåé²çæ¹æ³ï¼å°ç©©å®ææççæçæé«äºä¸åä»¥ä¸ï¼ä¸¦å°ç©©å®ãç¨ç¹åæ°ç©æ¶é«ççæçæé«äºç´ 50%ââéå¨ä¸åå°é£çåé¡ä¸æ¯ä¸åå·¨å¤§çæ¹é²ãæ­¤å¤ï¼èå¦ä¸ç¨®é åæ¨¡åç¸æ¯ï¼FlowLLM çæçæ¶é«æ´æ¥è¿å¶é¬å¼çæï¼é¡¯èéä½äºäºå¾è¨ç®ææ¬ã

##### **EMMA: End-to-End Multimodal Model for Autonomous Driving**
2410.23262v2 by Jyh-Jing Hwang, Runsheng Xu, Hubert Lin, Wei-Chih Hung, Jingwei Ji, Kristy Choi, Di Huang, Tong He, Paul Covington, Benjamin Sapp, Yin Zhou, James Guo, Dragomir Anguelov, Mingxing Tan

We introduce EMMA, an End-to-end Multimodal Model for Autonomous driving.
Built on a multi-modal large language model foundation, EMMA directly maps raw
camera sensor data into various driving-specific outputs, including planner
trajectories, perception objects, and road graph elements. EMMA maximizes the
utility of world knowledge from the pre-trained large language models, by
representing all non-sensor inputs (e.g. navigation instructions and ego
vehicle status) and outputs (e.g. trajectories and 3D locations) as natural
language text. This approach allows EMMA to jointly process various driving
tasks in a unified language space, and generate the outputs for each task using
task-specific prompts. Empirically, we demonstrate EMMA's effectiveness by
achieving state-of-the-art performance in motion planning on nuScenes as well
as competitive results on the Waymo Open Motion Dataset (WOMD). EMMA also
yields competitive results for camera-primary 3D object detection on the Waymo
Open Dataset (WOD). We show that co-training EMMA with planner trajectories,
object detection, and road graph tasks yields improvements across all three
domains, highlighting EMMA's potential as a generalist model for autonomous
driving applications. However, EMMA also exhibits certain limitations: it can
process only a small amount of image frames, does not incorporate accurate 3D
sensing modalities like LiDAR or radar and is computationally expensive. We
hope that our results will inspire further research to mitigate these issues
and to further evolve the state of the art in autonomous driving model
architectures.

æè¦ï¼<paragraph>æåä»ç´¹ EMMAï¼ä¸ç¨®ç¨æ¼èªåé§é§çç«¯å°ç«¯å¤æ¨¡ææ¨¡åã
å»ºç«å¨å¤æ¨¡æå¤§åèªè¨æ¨¡ååºç¤ä¸ï¼EMMA ç´æ¥å°åå§
ç¸æ©ææ¸¬å¨è³æå°æå°åç¨®ç¹å®æ¼é§é§çè¼¸åºï¼åæ¬è¦åå¨
è»è·¡ãæç¥ç©ä»¶åéè·¯åå½¢åç´ ãEMMA æå¤§åå©ç¨é è¨ç·´å¤§åèªè¨æ¨¡åä¸­çä¸çç¥è­ï¼æ¹æ³æ¯
å°ææéææ¸¬å¨è¼¸å¥ï¼ä¾å¦å°èªæç¤ºåèªæ
è»è¼çæï¼åè¼¸åºï¼ä¾å¦è»è·¡å 3D ä½ç½®ï¼è¡¨ç¤ºçºèªç¶
èªè¨æå­ãéç¨®æ¹æ³åè¨± EMMA å¨çµ±ä¸çèªè¨ç©ºéä¸­å±åèçåç¨®é§é§
ä»»åï¼ä¸¦ä½¿ç¨ç¹å®æ¼ä»»åçæç¤ºçºæ¯åä»»åç¢çè¼¸åºã
æ ¹æç¶é©ï¼æåè­æäº EMMA çæææ§ï¼å¨ nuScenes ä¸çéåè¦åä¸­éå°äºæåé²çæ§è½ï¼ä»¥å
å¨ Waymo éæ¾éåè³æé (WOMD) ä¸åå¾äºæç«¶ç­åççµæãEMMA ä¹
å¨ Waymo éæ¾è³æé (WOD) ä¸å°ç¸æ©åªåç 3D ç©ä»¶åµæ¸¬ç¢çäºæç«¶ç­åççµæãæåå±ç¤ºäºä½¿ç¨è¦åå¨è»è·¡ã
ç©ä»¶åµæ¸¬åéè·¯åå½¢ä»»åå±åè¨ç·´ EMMA æå¨ææä¸å
é åç¢çæ¹é²ï¼çªé¡¯äº EMMA ä½çºèªåé§é§æç¨ç¨å¼éç¨æ¨¡åçæ½åãç¶èï¼EMMA ä¹è¡¨ç¾åºæäºéå¶ï¼å®åªè½
èçå°éçå½±åå¹ï¼ä¸åå«å LiDAR æé·éç­æºç¢ºç 3D ææ¸¬æ¨¡å¼ï¼ä¸¦ä¸è¨ç®ææ¬æè²´ãæå
å¸ææåççµæè½æ¿åµé²ä¸æ­¥çç ç©¶ï¼ä»¥æ¸è¼éäºåé¡ä¸¦é²ä¸æ­¥ç¼å±èªåé§é§æ¨¡å
æ¶æ§çææ°æè¡ã</paragraph>

##### **ProTransformer: Robustify Transformers via Plug-and-Play Paradigm**
2410.23182v1 by Zhichao Hou, Weizhi Gao, Yuchen Shen, Feiyi Wang, Xiaorui Liu

Transformer-based architectures have dominated various areas of machine
learning in recent years. In this paper, we introduce a novel robust attention
mechanism designed to enhance the resilience of transformer-based
architectures. Crucially, this technique can be integrated into existing
transformers as a plug-and-play layer, improving their robustness without the
need for additional training or fine-tuning. Through comprehensive experiments
and ablation studies, we demonstrate that our ProTransformer significantly
enhances the robustness of transformer models across a variety of prediction
tasks, attack mechanisms, backbone architectures, and data domains. Notably,
without further fine-tuning, the ProTransformer consistently improves the
performance of vanilla transformers by 19.5%, 28.3%, 16.1%, and 11.4% for BERT,
ALBERT, DistilBERT, and RoBERTa, respectively, under the classical TextFooler
attack. Furthermore, ProTransformer shows promising resilience in large
language models (LLMs) against prompting-based attacks, improving the
performance of T5 and LLaMA by 24.8% and 17.8%, respectively, and enhancing
Vicuna by an average of 10.4% against the Jailbreaking attack. Beyond the
language domain, ProTransformer also demonstrates outstanding robustness in
both vision and graph domains.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼åºæ¼ Transformer çæ¶æ§ä¸»å°äºæ©å¨å­¸ç¿çååé åãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸ç¨®æ°ç©ä¸å¼·å¤§çæ³¨æåæ©å¶ï¼æ¨å¨å¢å¼·åºæ¼ Transformer çæ¶æ§çéæ§ãè³ééè¦çæ¯ï¼æ­¤æè¡å¯ä»¥ä½çºå³æå³ç¨çå±¤æ´åå°ç¾æç Transformer ä¸­ï¼å¨ç¡éé¡å¤è¨ç·´æå¾®èª¿çææ³ä¸æé«å¶ç©©å¥æ§ãééå¨é¢çå¯¦é©åæ¶èç ç©¶ï¼æåè­æäºæåç ProTransformer å¨åç¨®é æ¸¬ä»»åãæ»ææ©å¶ãä¸»å¹¹æ¶æ§åæ¸æé åä¸­é¡¯èå¢å¼·äº Transformer æ¨¡åçç©©å¥æ§ãå¼å¾æ³¨æçæ¯ï¼å¨ä¸é²ä¸æ­¥å¾®èª¿çææ³ä¸ï¼ProTransformer å¨ç¶å¸ç TextFooler æ»æä¸ï¼åå¥çº BERTãALBERTãDistilBERT å RoBERTa æåäº 19.5%ã28.3%ã16.1% å 11.4% çæ§è½ãæ­¤å¤ï¼ProTransformer å¨åºæ¼æç¤ºçæ»æä¸­å°å¤§åèªè¨æ¨¡å (LLM) é¡¯ç¤ºåºæå¸æçéæ§ï¼åå¥å° T5 å LLaMA çæ§è½æåäº 24.8% å 17.8%ï¼ä¸¦å¨è¶çæ»æä¸­å° Vicuna çæ§è½å¹³åæåäº 10.4%ãé¤äºèªè¨é åä¹å¤ï¼ProTransformer å¨è¦è¦ºååå½¢é åä¹è¡¨ç¾åºåºè²çç©©å¥æ§ã</paragraph>

##### **Semantic Enrichment of the Quantum Cascade Laser Properties in Text- A Knowledge Graph Generation Approach**
2410.22996v1 by Deperias Kerre, Anne Laurent, Kenneth Maussang, Dickson Owuor

A well structured collection of the various Quantum Cascade Laser (QCL)
design and working properties data provides a platform to analyze and
understand the relationships between these properties. By analyzing these
relationships, we can gain insights into how different design features impact
laser performance properties such as the working temperature. Most of these QCL
properties are captured in scientific text. There is therefore need for
efficient methodologies that can be utilized to extract QCL properties from
text and generate a semantically enriched and interlinked platform where the
properties can be analyzed to uncover hidden relations. There is also the need
to maintain provenance and reference information on which these properties are
based. Semantic Web technologies such as Ontologies and Knowledge Graphs have
proven capability in providing interlinked data platforms for knowledge
representation in various domains. In this paper, we propose an approach for
generating a QCL properties Knowledge Graph (KG) from text for semantic
enrichment of the properties. The approach is based on the QCL ontology and a
Retrieval Augmented Generation (RAG) enabled information extraction pipeline
based on GPT 4-Turbo language model. The properties of interest include:
working temperature, laser design type, lasing frequency, laser optical power
and the heterostructure. The experimental results demonstrate the feasibility
and effectiveness of this approach for efficiently extracting QCL properties
from unstructured text and generating a QCL properties Knowledge Graph, which
has potential applications in semantic enrichment and analysis of QCL data.

æè¦ï¼ä¸åçµæ§è¯å¥½çåç¨®éå­å±¤çé·å° (QCL) è¨­è¨åå·¥ä½ç¹æ§æ¸æéåï¼æä¾äºä¸åå¹³å°ä¾åæåçè§£éäºç¹æ§ä¹éçéä¿ãééåæéäºéä¿ï¼æåå¯ä»¥æ·±å¥äºè§£ä¸åçè¨­è¨ç¹å¾µå¦ä½å½±é¿é·å°æè½ç¹æ§ï¼ä¾å¦å·¥ä½æº«åº¦ãéäº QCL ç¹æ§å¤§å¤æ¸é½ææå¨ç§å­¸æå­ä¸­ãå æ­¤ï¼éè¦ææçæ¹æ³ï¼å¯ä»¥ç¨æ¼å¾æå­ä¸­èå QCL ç¹æ§ï¼ä¸¦ç¢çä¸åèªç¾©è±å¯ä¸ç¸äºé£çµçå¹³å°ï¼å¯ä»¥å¨å¶ä¸­åæéäºç¹æ§ä»¥ç¼ç¾é±èçéä¿ãééè¦ç¶­è­·éäºç¹æ§æä¾æçä¾æºååèè³è¨ãèªç¾©ç¶²è·¯æè¡ï¼ä¾å¦æ¬ä½åç¥è­åè­ï¼å·²è­æå®åå¨æä¾åç¨®é åä¸­ç¥è­è¡¨å¾µçç¸äºé£çµè³æå¹³å°æ¹é¢å·æè½åãå¨æ¬æä¸­ï¼æåæåºä¸åå¾æå­ä¸­ç¢ç QCL ç¹æ§ç¥è­åè­ (KG) çæ¹æ³ï¼ä»¥é²è¡ç¹æ§çèªç¾©è±å¯åãæ­¤æ¹æ³åºæ¼ QCL æ¬ä½ååºæ¼ GPT 4-Turbo èªè¨æ¨¡åçæª¢ç´¢æ´å¢çæ (RAG) åç¨è³è¨èåç®¡ç·ãæèè¶£çç¹æ§åæ¬ï¼å·¥ä½æº«åº¦ãé·å°è¨­è¨é¡åãé·å°é »çãé·å°ååçåç°è³ªçµæ§ãå¯¦é©çµæè­æäºæ­¤æ¹æ³å°æ¼å¾éçµæ§åæå­ä¸­ææèå QCL ç¹æ§åç¢ç QCL ç¹æ§ç¥è­åè­çå¯è¡æ§åæææ§ï¼éå¨ QCL æ¸æçèªç¾©è±å¯åååæä¸­å·ææ½å¨æç¨ã

##### **How Well Do Large Language Models Disambiguate Swedish Words?**
2410.22827v1 by Richard Johansson

We evaluate a battery of recent large language models on two benchmarks for
word sense disambiguation in Swedish. At present, all current models are less
accurate than the best supervised disambiguators in cases where a training set
is available, but most models outperform graph-based unsupervised systems.
Different prompting approaches are compared, with a focus on how to express the
set of possible senses in a given context. The best accuracies are achieved
when human-written definitions of the senses are included in the prompts.

æè¦ï¼æåéå°å©åçå¸èªè©å½æç¾©æ¶æ­§åºæºï¼è©ä¼°ä¸ç³»åè¿æçå¤§åèªè¨æ¨¡åãç®åï¼å¨æè¨ç·´éå¯ç¨çææ³ä¸ï¼ææç¾ææ¨¡åçæºç¢ºåº¦é½ä½æ¼æä½³ç£ç£å¼æ¶æ­§å¨ï¼ä½å¤§å¤æ¸æ¨¡åçè¡¨ç¾é½åªæ¼åºæ¼åå½¢çéç£ç£å¼ç³»çµ±ãæ¯è¼äºä¸åçæç¤ºæ¹æ³ï¼éé»å¨æ¼å¦ä½å¨ç¹å®èçµ¡ä¸­è¡¨éå¯è½çæç¾©éåãç¶æç¤ºä¸­åå«äººé¡æ°å¯«çæç¾©å®ç¾©æï¼å¯éå°æä½³æºç¢ºåº¦ã

##### **Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot**
2410.22767v1 by Sejin Lee, Dongha Kim, Min Song

Goal-oriented chatbots are essential for automating user tasks, such as
booking flights or making restaurant reservations. A key component of these
systems is Dialogue State Tracking (DST), which interprets user intent and
maintains the dialogue state. However, existing DST methods often rely on fixed
ontologies and manually compiled slot values, limiting their adaptability to
open-domain dialogues. We propose a novel approach that leverages instruction
tuning and advanced prompt strategies to enhance DST performance, without
relying on any predefined ontologies. Our method enables Large Language Model
(LLM) to infer dialogue states through carefully designed prompts and includes
an anti-hallucination mechanism to ensure accurate tracking in diverse
conversation contexts. Additionally, we employ a Variational Graph Auto-Encoder
(VGAE) to model and predict subsequent user intent. Our approach achieved
state-of-the-art with a JGA of 42.57% outperforming existing ontology-less DST
models, and performed well in open-domain real-world conversations. This work
presents a significant advancement in creating more adaptive and accurate
goal-oriented chatbots.

æè¦ï¼ä»¥ç®æ¨çºå°åçèå¤©æ©å¨äººå¨èªååä½¿ç¨èä»»åä¸­è³ééè¦ï¼ä¾å¦é è¨èªç­æé²è¡é¤å»³è¨ä½ãéäºç³»çµ±çä¸åééµçµæé¨åæ¯å°è©±çæè¿½è¹¤ (DST)ï¼å®æè§£è­¯ä½¿ç¨èçæåä¸¦ç¶­è­·å°è©±çæãç¶èï¼ç¾æç DST æ¹æ³éå¸¸ä¾è³´æ¼åºå®çæ¬ä½åæåç·¨è­¯çæ§½ä½å¼ï¼ééå¶äºå®åå°éæ¾é åå°è©±çé©ææ§ãæåæåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼å®å©ç¨æä»¤èª¿æ´ååé²çæç¤ºç­ç¥ä¾å¢å¼· DST æè½ï¼èç¡éä¾è³´ä»»ä½é å®ç¾©çæ¬ä½ãæåçæ¹æ³ä½¿å¤§åèªè¨æ¨¡å (LLM) è½å¤ ééç²¾å¿è¨­è¨çæç¤ºä¾æ¨è«å°è©±çæï¼ä¸¦åå«ä¸ååå¹»è¦ºæ©å¶ï¼ä»¥ç¢ºä¿å¨ä¸åçå°è©±æå¢ä¸­æºç¢ºè¿½è¹¤ãæ­¤å¤ï¼æåæ¡ç¨è®ååèªç·¨ç¢¼å¨ (VGAE) ä¾å»ºæ¨¡åé æ¸¬å¾çºä½¿ç¨èçæåãæåçåæ³ä»¥ 42.57% ç JGA éå°äºç¾ææè¡çé å³°ï¼åªæ¼ç¾æçç¡æ¬ä½ DST æ¨¡åï¼ä¸¦å¨éæ¾é åççå¯¦å°è©±ä¸­è¡¨ç¾è¯å¥½ãéé å·¥ä½å¨å»ºç«æ´å·é©ææ§åæºç¢ºæ§çä»¥ç®æ¨çºå°åçèå¤©æ©å¨äººæ¹é¢åå¾äºéå¤§é²å±ã

##### **The Graph's Apprentice: Teaching an LLM Low Level Knowledge for Circuit Quality Estimation**
2411.00843v1 by Reza Moravej, Saurabh Bodhe, Zhanguang Zhang, Didier Chetelat, Dimitrios Tsaras, Yingxue Zhang, Hui-Ling Zhen, Jianye Hao, Mingxuan Yuan

Logic synthesis is a crucial phase in the circuit design process, responsible
for transforming hardware description language (HDL) designs into optimized
netlists. However, traditional logic synthesis methods are computationally
intensive, restricting their iterative use in refining chip designs. Recent
advancements in large language models (LLMs), particularly those fine-tuned on
programming languages, present a promising alternative. In this paper, we
introduce VeriDistill, the first end-to-end machine learning model that
directly processes raw Verilog code to predict circuit quality-of-result
metrics. Our model employs a novel knowledge distillation method, transferring
low-level circuit insights via graphs into the predictor based on LLM.
Experiments show VeriDistill outperforms state-of-the-art baselines on
large-scale Verilog datasets and demonstrates robust performance when evaluated
on out-of-distribution datasets.

æè¦ï¼éè¼¯åææ¯é»è·¯è¨­è¨éç¨ä¸­è³ééè¦çä¸åéæ®µï¼è² è²¬å°ç¡¬é«æè¿°èªè¨ (HDL) è¨­è¨è½æçºæä½³åçç¶²è·¯è¡¨ãç¶èï¼å³çµ±çéè¼¯åææ¹æ³å¨éç®ä¸å¾å¯éï¼éå¶äºå®åå¨ç²¾çæ¶çè¨­è¨ä¸­çåè¦ä½¿ç¨ãæè¿å¤§åèªè¨æ¨¡å (LLM) çé²å±ï¼ç¹å¥æ¯é£äºç¶éç¨å¼èªè¨å¾®èª¿çï¼æä¾äºä¸åæå¸æçæ¿ä»£æ¹æ¡ãå¨æ¬æä¸­ï¼æåä»ç´¹äº VeriDistillï¼ç¬¬ä¸åç«¯å°ç«¯çæ©å¨å­¸ç¿æ¨¡åï¼å®ç´æ¥èçåå§ Verilog ç¨å¼ç¢¼ä»¥é æ¸¬é»è·¯åè³ªçµæææ¨ãæåçæ¨¡åæ¡ç¨äºä¸ç¨®æ°ç©çç¥è­æçæ¹æ³ï¼ééåè¡¨å°ä½éé»è·¯è¦è§£å³è¼¸å°åºæ¼ LLM çé æ¸¬å¨ä¸­ãå¯¦é©è¡¨æï¼VeriDistill å¨å¤§è¦æ¨¡ Verilog è³æéä¸åªæ¼æåé²çåºæºï¼ä¸¦ä¸å¨å¨åä½å¤è³æéä¸é²è¡è©ä¼°æè¡¨ç¾åºç©©å¥çæè½ã

##### **Are Large-Language Models Graph Algorithmic Reasoners?**
2410.22597v1 by Alexander K Taylor, Anthony Cuturrufo, Vishal Yathish, Mingyu Derek Ma, Wei Wang

We seek to address a core challenge facing current Large Language Models
(LLMs). LLMs have demonstrated superior performance in many tasks, yet continue
to struggle with reasoning problems on explicit graphs that require multiple
steps. To address this gap, we introduce a novel benchmark designed to evaluate
LLM performance on classical algorithmic reasoning tasks on explicit graphs.
Our benchmark encompasses five fundamental algorithms: Breadth-First Search
(BFS) and Depth-First Search (DFS) for connectivity, Dijkstra's algorithm and
Floyd-Warshall algorithm for all nodes shortest path, and Prim's Minimum
Spanning Tree (MST-Prim's) algorithm. Through extensive experimentation, we
assess the capabilities of state-of-the-art LLMs in executing these algorithms
step-by-step and systematically evaluate their performance at each stage. Our
findings highlight the persistent challenges LLMs face in this domain and
underscore the necessity for advanced prompting techniques and algorithmic
instruction to enhance their graph reasoning abilities. This work presents
MAGMA, the first comprehensive benchmark focused on LLMs completing classical
graph algorithms, and provides a critical step toward understanding and
improving their structured problem-solving skills.

æè¦ï¼æåè©¦åè§£æ±ºç¶åå¤§åèªè¨æ¨¡å (LLM) é¢è¨çæ ¸å¿ææ°ãLLM å¨è¨±å¤ä»»åä¸­è¡¨ç¾åºåªç°çæ§è½ï¼ä½ä»é£ä»¥æå°éè¦å¤åæ­¥é©çæç¢ºåè¡¨ä¸­çæ¨çåé¡ãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äºä¸åæ°çåºæºï¼ç¨æ¼è©ä¼° LLM å¨æç¢ºåè¡¨ä¸çç¶å¸æ¼ç®æ³æ¨çä»»åä¸çæ§è½ãæåçåºæºåå«äºååºæ¬æ¼ç®æ³ï¼å»£åº¦åªåæå° (BFS) åæ·±åº¦åªåæå° (DFS) ä»¥é²è¡é£éæ§ãDijkstra æ¼ç®æ³å Floyd-Warshall æ¼ç®æ³ä»¥æ¾åºææç¯é»çæç­è·¯å¾ï¼ä»¥å Prim æå°çææ¨¹ (MST-Prim) æ¼ç®æ³ãééå»£æ³çå¯¦é©ï¼æåè©ä¼°äºæåé²ç LLM å¨éæ­¥å·è¡éäºæ¼ç®æ³çè½åï¼ä¸¦ç³»çµ±æ§å°è©ä¼°å®åå¨æ¯åéæ®µçæ§è½ãæåçç ç©¶çµæçªåºäº LLM å¨éåé åé¢è¨çæçºææ°ï¼ä¸¦å¼·èª¿äºä½¿ç¨é²éæç¤ºæè¡åæ¼ç®æ³æä»¤ä¾å¢å¼·å¶åå½¢æ¨çè½åçå¿è¦æ§ãéé å·¥ä½æåºäº MAGMAï¼éæ¯ç¬¬ä¸åå°æ³¨æ¼ LLM å®æç¶å¸åå½¢æ¼ç®æ³çç¶ååºæºï¼ä¸¦çºäºè§£åæ¹é²å¶çµæ§ååé¡è§£æ±ºæè½æä¾äºééµçä¸æ­¥ã

##### **Advancing Agentic Systems: Dynamic Task Decomposition, Tool Integration and Evaluation using Novel Metrics and Dataset**
2410.22457v1 by Adrian Garret Gabriel, Alaa Alameer Ahmad, Shankar Kumar Jeyakumar

Advancements in Large Language Models (LLMs) are revolutionizing the
development of autonomous agentic systems by enabling dynamic, context-aware
task decomposition and automated tool selection. These sophisticated systems
possess significant automation potential across various industries, managing
complex tasks, interacting with external systems to enhance knowledge, and
executing actions independently. This paper presents three primary
contributions to advance this field:
  - Advanced Agentic Framework: A system that handles multi-hop queries,
generates and executes task graphs, selects appropriate tools, and adapts to
real-time changes.
  - Novel Evaluation Metrics: Introduction of Node F1 Score, Structural
Similarity Index (SSI), and Tool F1 Score to comprehensively assess agentic
systems.
  - Specialized Dataset: Development of an AsyncHow-based dataset for analyzing
agent behavior across different task complexities.
  Our findings reveal that asynchronous and dynamic task graph decomposition
significantly enhances system responsiveness and scalability, particularly for
complex, multi-step tasks. Detailed analysis shows that structural and
node-level metrics are crucial for sequential tasks, while tool-related metrics
are more important for parallel tasks. Specifically, the Structural Similarity
Index (SSI) is the most significant predictor of performance in sequential
tasks, and the Tool F1 Score is essential for parallel tasks. These insights
highlight the need for balanced evaluation methods that capture both structural
and operational dimensions of agentic systems. Additionally, our evaluation
framework, validated through empirical analysis and statistical testing,
provides valuable insights for improving the adaptability and reliability of
agentic systems in dynamic environments.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çé²å±æ­£ééåç¨åæãå·æå¢æç¥è½åçä»»ååè§£åèªååå·¥å·é¸æï¼é©æ°èªä¸»ä»£çç³»çµ±çéç¼ãéäºç²¾å¯çç³»çµ±å¨åç¢æ¥­ä¸­ææé¡¯èçèªååæ½åï¼ç®¡çè¤éçä»»åãèå¤é¨ç³»çµ±äºåä»¥å¢å¼·ç¥è­ï¼ä¸¦ç¨ç«å·è¡åä½ãæ¬ææåºäºä¸åä¸»è¦è²¢ç»ä»¥æ¨åéåé åçé²å±ï¼
  - é²éä»£çæ¶æ§ï¼ä¸ç¨®èçå¤éè·³èºæ¥è©¢ãç¢çä¸¦å·è¡ä»»ååè¡¨ãé¸æé©ç¶çå·¥å·ï¼ä¸¦é©æå³æè®åçç³»çµ±ã
  - æ°ç©çè©ä¼°ææ¨ï¼å°å¥ç¯é» F1 åæ¸ãçµæ§ç¸ä¼¼æ§ææ¨ (SSI) åå·¥å· F1 åæ¸ï¼ä»¥å¨é¢è©ä¼°ä»£çç³»çµ±ã
  - å°æ¥­è³æéï¼éç¼ä¸ååºæ¼ AsyncHow çè³æéï¼ç¨æ¼åæä»£çè¡çºå¨ä¸åä»»åè¤éåº¦ä¹éçå·®ç°ã
  æåçç ç©¶çµæé¡¯ç¤ºï¼éåæ­¥ååæä»»ååè¡¨åè§£è½é¡¯èå¢å¼·ç³»çµ±çåæè½ååå¯æ´åæ§ï¼ç¹å¥æ¯å°æ¼è¤éçå¤æ­¥é©ä»»åãè©³ç´°çåæé¡¯ç¤ºï¼çµæ§åç¯é»å±¤ç´çææ¨å°æ¼é åºä»»åè³ééè¦ï¼èèå·¥å·ç¸éçææ¨å°æ¼ä¸¦è¡ä»»åæ´çºéè¦ãå·é«ä¾èªªï¼çµæ§ç¸ä¼¼æ§ææ¨ (SSI) æ¯é åºä»»åä¸­æè½æé¡¯èçé æ¸¬ææ¨ï¼èå·¥å· F1 åæ¸å°æ¼ä¸¦è¡ä»»åè³ééè¦ãéäºè¦è§£çªé¡¯äºå¹³è¡¡è©ä¼°æ¹æ³çéæ±ï¼è©²æ¹æ³è½ææä»£çç³»çµ±ççµæ§åæä½é¢åãæ­¤å¤ï¼æåçè©ä¼°æ¶æ§ééå¯¦è­åæåçµ±è¨æª¢å®é©è­ï¼çºæ¹åä»£çç³»çµ±å¨åæç°å¢ä¸­çé©ææ§åå¯é æ§æä¾äºæå¹å¼çè¦è§£ã

##### **DynaMath: A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models**
2411.00836v1 by Chengke Zou, Xingang Guo, Rui Yang, Junyu Zhang, Bin Hu, Huan Zhang

The rapid advancements in Vision-Language Models (VLMs) have shown great
potential in tackling mathematical reasoning tasks that involve visual context.
Unlike humans who can reliably apply solution steps to similar problems with
minor modifications, we found that SOTA VLMs like GPT-4o can consistently fail
in these scenarios, revealing limitations in their mathematical reasoning
capabilities. In this paper, we investigate the mathematical reasoning
robustness in VLMs and evaluate how well these models perform under different
variants of the same question, such as changes in visual numerical values or
function graphs. While several vision-based math benchmarks have been developed
to assess VLMs' problem-solving capabilities, these benchmarks contain only
static sets of problems and cannot easily evaluate mathematical reasoning
robustness. To fill this gap, we introduce DynaMath, a dynamic visual math
benchmark designed for in-depth assessment of VLMs. DynaMath includes 501
high-quality, multi-topic seed questions, each represented as a Python program.
Those programs are carefully designed and annotated to enable the automatic
generation of a much larger set of concrete questions, including many different
types of visual and textual variations. DynaMath allows us to evaluate the
generalization ability of VLMs, by assessing their performance under varying
input conditions of a seed question. We evaluated 14 SOTA VLMs with 5,010
generated concrete questions. Our results show that the worst-case model
accuracy, defined as the percentage of correctly answered seed questions in all
10 variants, is significantly lower than the average-case accuracy. Our
analysis emphasizes the need to study the robustness of VLMs' reasoning
abilities, and DynaMath provides valuable insights to guide the development of
more reliable models for mathematical reasoning.

æè¦ï¼<paragraph>è¦è¦ºèªè¨æ¨¡å (VLM) çå¿«éé²æ­¥å¨è§£æ±ºæ¶åè¦è¦ºèæ¯çæ¸å­¸æ¨çä»»åæ¹é¢å±ç¾äºå·¨å¤§çæ½åãèäººé¡å¯ä»¥å°è§£æ±ºæ­¥é©å¯é å°æç¨æ¼é¡ä¼¼åé¡ï¼ä¸¦é²è¡å¾®å°çä¿®æ¹ï¼ä¸åï¼æåç¼ç¾å GPT-4o ç­ SOTA VLM å¨éäºå ´æ¯ä¸­å¯è½ææçºå¤±æï¼æ­é²äºå¶æ¸å­¸æ¨çè½åçéå¶ãå¨æ¬æä¸­ï¼æåç ç©¶äº VLM ä¸­çæ¸å­¸æ¨çç©©å¥æ§ï¼ä¸¦è©ä¼°äºéäºæ¨¡åå¨åä¸åé¡çä¸åè®é«ï¼ä¾å¦è¦è¦ºæ¸å¼æå½æ¸åå½¢çè®åï¼ä¸çè¡¨ç¾ãéç¶å·²ç¶éç¼äºå¤ååºæ¼è¦è¦ºçæ¸å­¸åºæºä¾è©ä¼° VLM çåé¡è§£æ±ºè½åï¼ä½éäºåºæºåªåå«éæåé¡éï¼ç¡æ³è¼é¬è©ä¼°æ¸å­¸æ¨çç©©å¥æ§ãçºäºå¡«è£éä¸ç©ºç½ï¼æåå¼å¥äº DynaMathï¼éæ¯ä¸ååæè¦è¦ºæ¸å­¸åºæºï¼å°éç¨æ¼æ·±å¥è©ä¼° VLMãDynaMath åå« 501 åé«åè³ªãå¤ä¸»é¡ç¨®å­åé¡ï¼æ¯ååé¡é½è¡¨ç¤ºçºä¸å Python ç¨å¼ãéäºç¨å¼ç¶éä»ç´°è¨­è¨åè¨»è§£ï¼ä»¥ä¾¿èªåç¢çä¸çµæ´å¤§çå·é«åé¡ï¼åæ¬è¨±å¤ä¸åé¡åçè¦è¦ºåæå­è®é«ãDynaMath åè¨±æåè©ä¼° VLM çæ³åè½åï¼æ¹æ³æ¯å¨ç¨®å­åé¡çä¸åè¼¸å¥æ¢ä»¶ä¸è©ä¼°å¶è¡¨ç¾ãæåä½¿ç¨ 5,010 åçæçå·é«åé¡è©ä¼°äº 14 å SOTA VLMãæåççµæé¡¯ç¤ºï¼æå·®ææ³çæ¨¡åæºç¢ºåº¦ï¼å®ç¾©çºå¨ææ 10 åè®é«ä¸­æ­£ç¢ºåç­çç¨®å­åé¡çç¾åæ¯ï¼é¡¯èä½æ¼å¹³åææ³æºç¢ºåº¦ãæåçåæå¼·èª¿äºç ç©¶ VLM æ¨çè½åç©©å¥æ§çå¿è¦æ§ï¼è DynaMath æä¾äºæå¹å¼çè¦è§£ï¼ä»¥æå°éç¼æ´å¯é çæ¸å­¸æ¨çæ¨¡åã</paragraph>

##### **ADAM: An Embodied Causal Agent in Open-World Environments**
2410.22194v1 by Shu Yu, Chaochao Lu

In open-world environments like Minecraft, existing agents face challenges in
continuously learning structured knowledge, particularly causality. These
challenges stem from the opacity inherent in black-box models and an excessive
reliance on prior knowledge during training, which impair their
interpretability and generalization capability. To this end, we introduce ADAM,
An emboDied causal Agent in Minecraft, that can autonomously navigate the open
world, perceive multimodal contexts, learn causal world knowledge, and tackle
complex tasks through lifelong learning. ADAM is empowered by four key
components: 1) an interaction module, enabling the agent to execute actions
while documenting the interaction processes; 2) a causal model module, tasked
with constructing an ever-growing causal graph from scratch, which enhances
interpretability and diminishes reliance on prior knowledge; 3) a controller
module, comprising a planner, an actor, and a memory pool, which uses the
learned causal graph to accomplish tasks; 4) a perception module, powered by
multimodal large language models, which enables ADAM to perceive like a human
player. Extensive experiments show that ADAM constructs an almost perfect
causal graph from scratch, enabling efficient task decomposition and execution
with strong interpretability. Notably, in our modified Minecraft games where no
prior knowledge is available, ADAM maintains its performance and shows
remarkable robustness and generalization capability. ADAM pioneers a novel
paradigm that integrates causal methods and embodied agents in a synergistic
manner. Our project page is at https://opencausalab.github.io/ADAM.

æè¦ï¼å¨å Minecraft éæ¨£çéæ¾ä¸çç°å¢ä¸­ï¼ç¾æçä»£çäººé¢è¨æçºå­¸ç¿çµæ§åç¥è­çææ°ï¼å°¤å¶æ¯å æéä¿ãéäºææ°æºæ¼é»çæ¨¡ååºæçä¸éææ§ï¼ä»¥åå¨è¨ç·´æééåº¦ä¾è³´åé©ç¥è­ï¼éææå®³å®åçå¯è§£éæ§åæ³åè½åãçºæ­¤ï¼æåå¼å¥äº ADAMï¼Minecraft ä¸­çä¸åå·èº«å æä»£çï¼å®å¯ä»¥èªä¸»å°èªéæ¾ä¸çï¼æç¥å¤æ¨¡å¼ä¸ä¸æï¼å­¸ç¿å æä¸çç¥è­ï¼ä¸¦ééçµèº«å­¸ç¿ä¾æå°è¤éä»»åãADAM ç±ååééµçµæé¨åè³¦è½ï¼1) ä¸åäº¤äºæ¨¡çµï¼ä½¿ä»£çè½å¤ å·è¡åä½ï¼åæè¨éäº¤äºéç¨ï¼2) ä¸åå ææ¨¡åæ¨¡çµï¼è² è²¬å¾é ­éå§æ§å»ºä¸åä¸æ·å¢é·çå æåï¼éå¢å¼·äºå¯è§£éæ§ä¸¦æ¸å°äºå°åé©ç¥è­çä¾è³´ï¼3) ä¸åæ§å¶å¨æ¨¡çµï¼åæ¬ä¸åè¦åå¨ãä¸åå·è¡å¨åä¸åè¨æ¶æ± ï¼å®ä½¿ç¨å­¸ç¿å°çå æåä¾å®æä»»åï¼4) ä¸åæç¥æ¨¡çµï¼ç±å¤æ¨¡å¼å¤§åèªè¨æ¨¡åæä¾æ¯æ´ï¼ä½¿ ADAM è½å¤ åäººé¡ç©å®¶ä¸æ¨£æç¥ãå¤§éçå¯¦é©è¡¨æï¼ADAM å¾é ­éå§æ§å»ºäºä¸åå¹¾ä¹å®ç¾çå æåï¼å¯¦ç¾äºé«æçä»»ååè§£åå·è¡ï¼ä¸¦å·æå¾å¼·çå¯è§£éæ§ãå¼å¾æ³¨æçæ¯ï¼å¨æåä¿®æ¹éç Minecraft éæ²ä¸­ï¼æ²æå¯ç¨çåé©ç¥è­ï¼ADAM ä¿æäºå¶æ§è½ï¼ä¸¦è¡¨ç¾åºé¡¯èçé­¯æ£æ§åæ³åè½åãADAM éåµäºä¸ç¨®æ°ç©çç¯ä¾ï¼ä»¥ååæ¹å¼æ´åå ææ¹æ³åå·èº«ä»£çãæåçå°æ¡é é¢ä½æ¼ https://opencausalab.github.io/ADAMã

##### **Synergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN**
2411.00028v1 by Zhilun Zhou, Jingyang Fan, Yu Liu, Fengli Xu, Depeng Jin, Yong Li

The fast development of location-based social networks (LBSNs) has led to
significant changes in society, resulting in popular studies of using LBSN data
for socioeconomic prediction, e.g., regional population and commercial activity
estimation. Existing studies design various graphs to model heterogeneous LBSN
data, and further apply graph representation learning methods for socioeconomic
prediction. However, these approaches heavily rely on heuristic ideas and
expertise to extract task-relevant knowledge from diverse data, which may not
be optimal for specific tasks. Additionally, they tend to overlook the inherent
relationships between different indicators, limiting the prediction accuracy.
Motivated by the remarkable abilities of large language models (LLMs) in
commonsense reasoning, embedding, and multi-agent collaboration, in this work,
we synergize LLM agents and knowledge graph for socioeconomic prediction. We
first construct a location-based knowledge graph (LBKG) to integrate
multi-sourced LBSN data. Then we leverage the reasoning power of LLM agent to
identify relevant meta-paths in the LBKG for each type of socioeconomic
prediction task, and design a semantic-guided attention module for knowledge
fusion with meta-paths. Moreover, we introduce a cross-task communication
mechanism to further enhance performance by enabling knowledge sharing across
tasks at both LLM agent and KG levels. On the one hand, the LLM agents for
different tasks collaborate to generate more diverse and comprehensive
meta-paths. On the other hand, the embeddings from different tasks are
adaptively merged for better socioeconomic prediction. Experiments on two
datasets demonstrate the effectiveness of the synergistic design between LLM
and KG, providing insights for information sharing across socioeconomic
prediction tasks.

æè¦ï¼åºæ¼ä½ç½®çç¤¾äº¤ç¶²è·¯ (LBSN) çå¿«éç¼å±å·²å°è´ç¤¾æç¼çéå¤§è®é©ï¼é²èä¿æä½¿ç¨ LBSN è³æé²è¡ç¤¾æç¶æ¿é æ¸¬çç±éç ç©¶ï¼ä¾å¦ååäººå£ååæ¥­æ´»åä¼°è¨ãç¾æç ç©¶è¨­è¨åç¨®åå½¢ä¾å»ºæ¨¡ç°è³ªç LBSN è³æï¼ä¸¦é²ä¸æ­¥æç¨åå½¢è¡¨ç¤ºå­¸ç¿æ¹æ³é²è¡ç¤¾æç¶æ¿é æ¸¬ãç¶èï¼éäºæ¹æ³æ¥µåº¦ä¾è³´åç¼å¼æ³æ³åå°æ¥­ç¥è­å¾ä¸åçè³æä¸­èåèä»»åç¸éçç¥è­ï¼éå°æ¼ç¹å®ä»»åèè¨å¯è½ä¸æ¯æä½³çãæ­¤å¤ï¼å®åå¾åæ¼å¿½ç¥ä¸åææ¨ä¹éçåºæéä¿ï¼é²èéå¶é æ¸¬æºç¢ºåº¦ãåæ æ¼å¤§åèªè¨æ¨¡å (LLM) å¨å¸¸è­æ¨çãåµå¥åå¤éä»£çåä½æ¹é¢çåè¶è½åï¼å¨éé å·¥ä½ä¸­ï¼æåå° LLM ä»£çåç¥è­åå½¢çµåèµ·ä¾é²è¡ç¤¾æç¶æ¿é æ¸¬ãæåé¦åå»ºæ§ä¸ååºæ¼ä½ç½®çç¥è­åå½¢ (LBKG) ä¾æ´åå¤ä¾æºç LBSN è³æãç¶å¾ï¼æåå©ç¨ LLM ä»£ççæ¨çè½åï¼éå°æ¯ç¨®é¡åçç¤¾æç¶æ¿é æ¸¬ä»»åè­å¥ LBKG ä¸­ç¸éç meta è·¯å¾ï¼ä¸¦è¨­è¨ä¸åèªç¾©å°åçæ³¨æåæ¨¡çµï¼ç¨æ¼è meta è·¯å¾çç¥è­èåãæ­¤å¤ï¼æåå¼å¥ä¸åè·¨ä»»åæºéæ©å¶ï¼ä»¥ééå¨ LLM ä»£çå KG å±¤ç´ä¸è·¨ä»»ååç¨ç¥è­å±äº«é²ä¸æ­¥æåæè½ãä¸æ¹é¢ï¼ä¸åä»»åç LLM ä»£çåä½ç¢çæ´å¤æ¨£åä¸å¨é¢ç meta è·¯å¾ãå¦ä¸æ¹é¢ï¼ä¾èªä¸åä»»åçåµå¥æèªé©æå°åä½µï¼ä»¥é²è¡æ´å¥½çç¤¾æç¶æ¿é æ¸¬ãå¨å©åè³æéä¸çå¯¦é©è­æäº LLM å KG ä¹éååè¨­è¨çæææ§ï¼ä¸¦æä¾è·¨ç¤¾æç¶æ¿é æ¸¬ä»»åé²è¡è³è¨å±äº«çè¦è§£ã

##### **A Hierarchical Language Model For Interpretable Graph Reasoning**
2410.22372v1 by Sambhav Khurana, Xiner Li, Shurui Gui, Shuiwang Ji

Large language models (LLMs) are being increasingly explored for graph tasks.
Despite their remarkable success in text-based tasks, LLMs' capabilities in
understanding explicit graph structures remain limited, particularly with large
graphs. In this work, we introduce Hierarchical Language Model for Graph
(HLM-G), which employs a two-block architecture to capture node-centric local
information and interaction-centric global structure, effectively enhancing
graph structure understanding abilities. The proposed scheme allows LLMs to
address various graph queries with high efficacy, efficiency, and robustness,
while reducing computational costs on large-scale graph tasks. Furthermore, we
demonstrate the interpretability of our model using intrinsic attention weights
and established explainers. Comprehensive evaluations across diverse graph
reasoning and real-world tasks of node, link, and graph-levels highlight the
superiority of our method, marking a significant advancement in the application
of LLMs to graph understanding.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æä¾æå¤ç¨æ¼åå½¢ä»»åã
åç®¡ LLM å¨åºæ¼æå­çä»»åä¸­åå¾é¡¯èçæåï¼ä½å¶å¨çè§£æç¢ºåå½¢çµæ§æ¹é¢çè½åä»ç¶æéï¼ç¹å¥æ¯å°æ¼å¤§ååå½¢ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºåå½¢éå±¤èªè¨æ¨¡å (HLM-G)ï¼å®æ¡ç¨éåå¡æ¶æ§ä¾æ·åä»¥ç¯é»çºä¸­å¿çå±é¨è³è¨åä»¥äºåçºä¸­å¿çæ´é«çµæ§ï¼ææå°å¢å¼·äºåå½¢çµæ§çè§£è½åãææåºçæ¶æ§åè¨± LLM ä»¥é«æçãé«æçåé«ç©©å¥æ§ä¾èçåç¨®åå½¢æ¥è©¢ï¼åæéä½å¤§ååå½¢ä»»åçéç®ææ¬ãæ­¤å¤ï¼æåä½¿ç¨å§å¨æ³¨æåæ¬éåå·²å»ºç«çè§£éå¨ä¾å±ç¤ºæåæ¨¡åçå¯è§£éæ§ãå¨ç¯é»ãé£çµååå½¢å±¤ç´çåç¨®åå½¢æ¨çåçå¯¦ä¸çä»»åä¸­é²è¡çå¨é¢è©ä¼°çªé¡¯äºæåæ¹æ³çåªè¶æ§ï¼æ¨èªè LLM å¨åå½¢çè§£æç¨æ¹é¢åå¾éå¤§é²å±ã

##### **LLM-Forest for Health Tabular Data Imputation**
2410.21520v1 by Xinrui He, Yikun Ban, Jiaru Zou, Tianxin Wei, Curtiss B. Cook, Jingrui He

Missing data imputation is a critical challenge in tabular datasets,
especially in healthcare, where data completeness is vital for accurate
analysis. Large language models (LLMs), trained on vast corpora, have shown
strong potential in data generation, making them a promising tool for tabular
data imputation. However, challenges persist in designing effective prompts for
a finetuning-free process and in mitigating the risk of LLM hallucinations. To
address these issues, we propose a novel framework, LLM-Forest, which
introduces a "forest" of few-shot learning LLM "trees" with confidence-based
weighted voting. This framework is established on a new concept of bipartite
information graphs to identify high-quality relevant neighboring entries with
both feature and value granularity. Extensive experiments on four real-world
healthcare datasets demonstrate the effectiveness and efficiency of LLM-Forest.

æè¦ï¼éºå¤±è³ææ¨ä¼°æ¯è¡¨æ ¼è³æéä¸­çéå¤§ææ°ï¼
ç¹å¥æ¯å¨é«çä¿å¥ä¸­ï¼è³æå®æ´æ§å°æ¼æºç¢ºåæè³ééè¦ã
å¤§åèªè¨æ¨¡å (LLM) å¨é¾å¤§çèªæåº«ä¸è¨ç·´ï¼å¨è³æç¢çæ¹é¢å±ç¾åºå¼·å¤§çæ½åï¼ä½¿å¶æçºè¡¨æ ¼è³ææ¨ä¼°çæåéå·¥å·ã
ç¶èï¼å¨è¨­è¨æææç¤ºä»¥é²è¡å¾®èª¿åè²»æµç¨åæ¸è¼ LLM å¹»è¦ºé¢¨éªæ¹é¢ä»å­å¨ææ°ã
çºäºè§£æ±ºéäºåé¡ï¼æåæåºä¸åæ°çæ¡æ¶ï¼LLM-Forestï¼å®å¼å¥äºä¸åãæ£®æãçå°éå­¸ç¿ LLMãæ¨¹ãï¼ä¸¦æ¡ç¨åºæ¼ä¿¡å¿çå æ¬æç¥¨ã
éåæ¡æ¶å»ºç«å¨éåè³è¨åçæ°æ¦å¿µä¸ï¼ä»¥è­å¥å·æç¹å¾µåå¼ç²åº¦çåªè³ªç¸éé°è¿é ç®ã
å¨ååçå¯¦ä¸ççé«çä¿å¥è³æéä¸é²è¡çå»£æ³å¯¦é©è­æäº LLM-Forest çæææ§åæçã

##### **Hierarchical Knowledge Graph Construction from Images for Scalable E-Commerce**
2410.21237v1 by Zhantao Yang, Han Zhang, Fangyi Chen, Anudeepsekhar Bolimera, Marios Savvides

Knowledge Graph (KG) is playing an increasingly important role in various AI
systems. For e-commerce, an efficient and low-cost automated knowledge graph
construction method is the foundation of enabling various successful downstream
applications. In this paper, we propose a novel method for constructing
structured product knowledge graphs from raw product images. The method
cooperatively leverages recent advances in the vision-language model (VLM) and
large language model (LLM), fully automating the process and allowing timely
graph updates. We also present a human-annotated e-commerce product dataset for
benchmarking product property extraction in knowledge graph construction. Our
method outperforms our baseline in all metrics and evaluated properties,
demonstrating its effectiveness and bright usage potential.

æè¦ï¼ç¥è­åè­ (KG) å¨åç¨® AI ç³»çµ±ä¸­æ®æ¼è¶ä¾è¶éè¦çè§è²ãå°æ¼é»å­ååä¾èªªï¼ä¸ç¨®ææä¸ä½ææ¬çèªååç¥è­åè­å»ºæ§æ¹æ³æ¯ä¿æåç¨®æåçä¸æ¸¸æç¨ç¨å¼çåºç¤ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®å¾åå§ç¢åå½±åå»ºæ§çµæ§åç¢åç¥è­åè­çæ°ç©æ¹æ³ãè©²æ¹æ³ååå©ç¨äºè¦è¦ºèªè¨æ¨¡å (VLM) åå¤§åèªè¨æ¨¡å (LLM) çææ°é²å±ï¼å®å¨èªååäºæµç¨ä¸¦åè¨±åææ´æ°åè­ãæåéæä¾äºä¸åç±äººå·¥æ¨è¨»çé»å­ååç¢åè³æéï¼ç¨æ¼è©éç¥è­åè­å»ºæ§ä¸­çç¢åå±¬æ§èåãæåçæ¨¡åå¨ææææ¨åè©ä¼°å±¬æ§ä¸é½åªæ¼æåçåºæºï¼è­æäºå¶æææ§åå»£éçä½¿ç¨æ½åã

##### **CRAT: A Multi-Agent Framework for Causality-Enhanced Reflective and Retrieval-Augmented Translation with Large Language Models**
2410.21067v1 by Meiqi Chen, Fandong Meng, Yingxue Zhang, Yan Zhang, Jie Zhou

Large language models (LLMs) have shown great promise in machine translation,
but they still struggle with contextually dependent terms, such as new or
domain-specific words. This leads to inconsistencies and errors that are
difficult to address. Existing solutions often depend on manual identification
of such terms, which is impractical given the complexity and evolving nature of
language. While Retrieval-Augmented Generation (RAG) could provide some
assistance, its application to translation is limited by issues such as
hallucinations from information overload. In this paper, we propose CRAT, a
novel multi-agent translation framework that leverages RAG and
causality-enhanced self-reflection to address these challenges. This framework
consists of several specialized agents: the Unknown Terms Identification agent
detects unknown terms within the context, the Knowledge Graph (KG) Constructor
agent extracts relevant internal knowledge about these terms and retrieves
bilingual information from external sources, the Causality-enhanced Judge agent
validates the accuracy of the information, and the Translator agent
incorporates the refined information into the final output. This automated
process allows for more precise and consistent handling of key terms during
translation. Our results show that CRAT significantly improves translation
accuracy, particularly in handling context-sensitive terms and emerging
vocabulary.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å¨æ©å¨ç¿»è­¯æ¹é¢å±ç¾åºæ¥µå¤§çåæ¯ï¼
ä½å®åä»ç¶é£ä»¥æå°ä¾è³´æ¼èªå¢çè©å½ï¼ä¾å¦æ°è©æç¹å®é åçè©å½ãéæå°è´ä¸ä¸è´åé¯èª¤ï¼èéäºé¯èª¤å¾é£è§£æ±ºãç¾æçè§£æ±ºæ¹æ¡éå¸¸ä¾è³´æ¼æåè­å¥æ­¤é¡è©å½ï¼ä½ç±æ¼èªè¨çè¤éæ§åä¸æ·æ¼è®çç¹æ§ï¼éä¸¦ä¸å¯è¡ãéç¶æª¢ç´¢å¢å¼·çæï¼RAGï¼å¯ä»¥æä¾ä¸äºåå©ï¼ä½å¶å¨ç¿»è­¯ä¸­çæç¨åå°è«¸å¦è³è¨è¶è¼ç¢ççå¹»è¦ºç­åé¡çéå¶ãå¨æ¬æä¸­ï¼æåæåº CRATï¼éæ¯ä¸åæ°ç©çå¤ä»£çç¿»è­¯æ¶æ§ï¼å®å©ç¨ RAG åå æå¢å¼·èªçä¾æå°éäºææ°ãæ­¤æ¶æ§åå«å¹¾åå°éçä»£çï¼æªç¥è©å½è­å¥ä»£çæåµæ¸¬èªå¢ä¸­çæªç¥è©å½ï¼ç¥è­åè­ï¼KGï¼å»ºæ§ä»£çææ·åéäºè©å½ç¸éçå§é¨ç¥è­ï¼ä¸¦å¾å¤é¨ä¾æºä¸­æª¢ç´¢éèªè³è¨ï¼å æå¢å¼·å¤æ·ä»£çæé©è­è³è¨çæºç¢ºæ§ï¼èç¿»è­¯ä»£çæå°ç²¾çéçè³è¨ç´å¥æçµè¼¸åºãéåèªååçæµç¨åè¨±å¨ç¿»è­¯éç¨ä¸­æ´ç²¾ç¢ºä¸ä¸è´å°èçééµè©å½ãæåççµæé¡¯ç¤ºï¼CRAT å¤§å¹æåäºç¿»è­¯æºç¢ºæ§ï¼ç¹å¥æ¯å¨èçå°èªå¢ææçè©å½åæ°èè©å½æ¹é¢ã

##### **CTINEXUS: Leveraging Optimized LLM In-Context Learning for Constructing Cybersecurity Knowledge Graphs Under Data Scarcity**
2410.21060v1 by Yutong Cheng, Osama Bajaber, Saimon Amanuel Tsegai, Dawn Song, Peng Gao

Textual descriptions in cyber threat intelligence (CTI) reports, such as
security articles and news, are rich sources of knowledge about cyber threats,
crucial for organizations to stay informed about the rapidly evolving threat
landscape. However, current CTI extraction methods lack flexibility and
generalizability, often resulting in inaccurate and incomplete knowledge
extraction. Syntax parsing relies on fixed rules and dictionaries, while model
fine-tuning requires large annotated datasets, making both paradigms
challenging to adapt to new threats and ontologies. To bridge the gap, we
propose CTINexus, a novel framework leveraging optimized in-context learning
(ICL) of large language models (LLMs) for data-efficient CTI knowledge
extraction and high-quality cybersecurity knowledge graph (CSKG) construction.
Unlike existing methods, CTINexus requires neither extensive data nor parameter
tuning and can adapt to various ontologies with minimal annotated examples.
This is achieved through (1) a carefully designed automatic prompt construction
strategy with optimal demonstration retrieval for extracting a wide range of
cybersecurity entities and relations; (2) a hierarchical entity alignment
technique that canonicalizes the extracted knowledge and removes redundancy;
(3) an ICL-enhanced long-distance relation prediction technique to further
complete the CKSG with missing links. Our extensive evaluations using 150
real-world CTI reports collected from 10 platforms demonstrate that CTINexus
significantly outperforms existing methods in constructing accurate and
complete CSKGs, highlighting its potential to transform CTI analysis with an
efficient and adaptable solution for the dynamic threat landscape.

æè¦ï¼ç¶²è·¯å¨èæå ± (CTI) å ±åä¸­çæå­æè¿°ï¼ä¾å¦å®å¨æç« åæ°èï¼æ¯ç¶²è·¯å¨èçè±å¯ç¥è­ä¾æºï¼å°æ¼çµç¹èè¨è³ééè¦ï¼å¯ä»¥é¨æäºè§£å¿«éæ¼è®çå¨èç°å¢ãç¶èï¼ç®åç CTI æåæ¹æ³ç¼ºä¹éæ´»æ§ä¸é£ä»¥æ¦æ¬ï¼éå¸¸æå°è´ç¥è­æåä¸æºç¢ºä¸ä¸å®æ´ãèªæ³è§£æä¾è³´æ¼åºå®è¦ååå­å¸ï¼èæ¨¡åå¾®èª¿éè¦å¤§éæ¨è¨»çè³æéï¼éä½¿å¾éå©ç¨®ç¯ä¾é½é£ä»¥é©ææ°çå¨èåæ¬ä½ãçºäºå½è£å·®è·ï¼æåæåºäº CTINexusï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) çæä½³åæå¢å­¸ç¿ (ICL) ä¾é²è¡è³æææçç CTI ç¥è­æååé«åè³ªçç¶²è·¯å®å¨ç¥è­å (CSKG) å»ºæ§ãèç¾ææ¹æ³ä¸åï¼CTINexus ä¸éè¦å»£æ³çè³ææåæ¸èª¿æ´ï¼ä¸¦ä¸å¯ä»¥ééæå°çæ¨è¨»ç¯ä¾é©æåç¨®æ¬ä½ãéæ¯éé (1) ç¶éç²¾å¿è¨­è¨çèªåæç¤ºå»ºæ§ç­ç¥ï¼ä¸¦ééæä½³ç¤ºç¯æª¢ç´¢ä¾æåå»£æ³çç¶²è·¯å®å¨å¯¦é«åéä¿ä¾å¯¦ç¾çï¼(2) ä¸ç¨®éå±¤å¼å¯¦é«æ¯å°æè¡ï¼å¯ä»¥å°æåçç¥è­æ¨æºåä¸¦æ¶é¤åé¤ï¼(3) ä¸ç¨® ICL å¢å¼·çé·è·é¢éä¿é æ¸¬æè¡ï¼å¯ä»¥é²ä¸æ­¥å®æå·æéºå¤±é£çµç CKSGãæåä½¿ç¨å¾ 10 åå¹³å°æ¶éç 150 ä»½çå¯¦ä¸ç CTI å ±åé²è¡å»£æ³è©ä¼°ï¼è­æ CTINexus å¨å»ºæ§æºç¢ºä¸å®æ´ç CSKG æ¹é¢æé¡¯åªæ¼ç¾ææ¹æ³ï¼çªé¡¯äºå¶ä»¥ææä¸é©ææ§å¼·çè§£æ±ºæ¹æ¡è½æ CTI åæçæ½åï¼ä»¥æå°åæçå¨èç°å¢ã

##### **Graph-based Uncertainty Metrics for Long-form Language Model Outputs**
2410.20783v1 by Mingjian Jiang, Yangjun Ruan, Prasanna Sattigeri, Salim Roukos, Tatsunori Hashimoto

Recent advancements in Large Language Models (LLMs) have significantly
improved text generation capabilities, but these systems are still known to
hallucinate, and granular uncertainty estimation for long-form LLM generations
remains challenging. In this work, we propose Graph Uncertainty -- which
represents the relationship between LLM generations and claims within them as a
bipartite graph and estimates the claim-level uncertainty with a family of
graph centrality metrics. Under this view, existing uncertainty estimation
methods based on the concept of self-consistency can be viewed as using degree
centrality as an uncertainty measure, and we show that more sophisticated
alternatives such as closeness centrality provide consistent gains at
claim-level uncertainty estimation. Moreover, we present uncertainty-aware
decoding techniques that leverage both the graph structure and uncertainty
estimates to improve the factuality of LLM generations by preserving only the
most reliable claims. Compared to existing methods, our graph-based uncertainty
metrics lead to an average of 6.8% relative gains on AUPRC across various
long-form generation settings, and our end-to-end system provides consistent
2-4% gains in factuality over existing decoding techniques while significantly
improving the informativeness of generated responses.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±é¡¯èæåäºæå­çæè½åï¼ä½éäºç³»çµ±ä»ä»¥ç¢çå¹»è¦ºèç¨±ï¼èéå°é·ç¯ LLM çæçç´°ç·»ä¸ç¢ºå®æ§ä¼°è¨ä»æ¯ä¸é ææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºåå½¢ä¸ç¢ºå®æ§ï¼å®å° LLM çæåå¶ä¸­çä¸»å¼µè¡¨ç¤ºçºäºé¨åï¼ä¸¦ä½¿ç¨ä¸ç³»ååå½¢ä¸­å¿æ§ææ¨ä¼°è¨ä¸»å¼µå±¤ç´çä¸ç¢ºå®æ§ãå¨æ­¤è§é»ä¸ï¼ç¾æçåºæ¼èªæ´½æ§æ¦å¿µçä¸ç¢ºå®æ§ä¼°è¨æ¹æ³å¯è¦çºä½¿ç¨åº¦éä¸­å¿æ§ä½çºä¸ç¢ºå®æ§ææ¨ï¼æåè­æäºæ´ç²¾å¯çæ¿ä»£æ¹æ¡ï¼ä¾å¦æ¥è¿ä¸­å¿æ§ï¼å¨ä¸»å¼µå±¤ç´ä¸ç¢ºå®æ§ä¼°è¨ä¸­æä¾äºç©©å®çå¢çãæ­¤å¤ï¼æåæåºäºä¸ç¢ºå®æ§æç¥è§£ç¢¼æè¡ï¼è©²æè¡å©ç¨åå½¢çµæ§åä¸ç¢ºå®æ§ä¼°è¨ä¾æå LLM çæççå¯¦æ§ï¼æ¹æ³æ¯åä¿çæå¯é çä¸»å¼µãèç¾ææ¹æ³ç¸æ¯ï¼æåçåºæ¼åå½¢çææ¨å¨åç¨®é·ç¯çæè¨­å®ä¸­å¹³åæåäº AUPRC ç 6.8%ï¼èæåçç«¯å°ç«¯ç³»çµ±å¨çå¯¦æ§æ¹é¢æä¾äº 2-4% çç©©å®å¢çï¼åæé¡¯èæåäºçæåæçè³è¨æ§ã

##### **Plan$\times$RAG: Planning-guided Retrieval Augmented Generation**
2410.20753v1 by Prakhar Verma, Sukruta Prakash Midigeshi, Gaurav Sinha, Arno Solin, Nagarajan Natarajan, Amit Sharma

We introduce Planning-guided Retrieval Augmented Generation
(Plan$\times$RAG), a novel framework that augments the
\emph{retrieve-then-reason} paradigm of existing RAG frameworks to
\emph{plan-then-retrieve}. Plan$\times$RAG formulates a reasoning plan as a
directed acyclic graph (DAG), decomposing queries into interrelated atomic
sub-queries. Answer generation follows the DAG structure, allowing significant
gains in efficiency through parallelized retrieval and generation. While
state-of-the-art RAG solutions require extensive data generation and
fine-tuning of language models (LMs), Plan$\times$RAG incorporates frozen LMs
as plug-and-play experts to generate high-quality answers. Compared to existing
RAG solutions, Plan$\times$RAG demonstrates significant improvements in
reducing hallucinations and bolstering attribution due to its structured
sub-query decomposition. Overall, Plan$\times$RAG offers a new perspective on
integrating external knowledge in LMs while ensuring attribution by design,
contributing towards more reliable LM-based systems.

æè¦ï¼<paragraph>æåå¼å¥äºè¦åå¼å°çæª¢ç´¢å¢å¼·çæ (Plan$\times$RAG)ï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼å®æ´åäºç¾æ RAG æ¡æ¶çãåæª¢ç´¢å¾æ¨çãç¯ä¾ï¼æ¹çºãåè¦åå¾æª¢ç´¢ããPlan$\times$RAG å°æ¨çè¨ç«å¶å®çºæåç¡ç°å (DAG)ï¼å°æ¥è©¢åè§£æç¸äºéè¯çåå­å­æ¥è©¢ãç­æ¡çæéµå¾ª DAG çµæ§ï¼ééä¸¦è¡æª¢ç´¢åçæï¼å¤§å¹æåæçãéç¶æåé²ç RAG è§£å³æ¹æ¡éè¦å¤§éè³æçæåèªè¨æ¨¡å (LM) çå¾®èª¿ï¼ä½ Plan$\times$RAG å°åçµç LM æ´åçºå³æå³ç¨çå°å®¶ï¼ä»¥çæé«åè³ªçç­æ¡ãèç¾æç RAG è§£å³æ¹æ¡ç¸æ¯ï¼Plan$\times$RAG å¨æ¸å°å¹»è¦ºåå å¼·æ­¸å æ¹é¢è¡¨ç¾åºé¡¯èçé²æ­¥ï¼éè¦æ­¸åæ¼å¶çµæ§åçå­æ¥è©¢åè§£ãç¸½é«èè¨ï¼Plan$\times$RAG æä¾äºä¸åæ°çè§é»ï¼ä»¥æ´å LM ä¸­çå¤é¨ç¥è­ï¼åæç¢ºä¿æ­¸å è¨­è¨ï¼æå©æ¼å»ºç«æ´å¯é çåºæ¼ LM çç³»çµ±ã</paragraph>

##### **Simple is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation**
2410.20724v1 by Mufei Li, Siqi Miao, Pan Li

Large Language Models (LLMs) demonstrate strong reasoning abilities but face
limitations such as hallucinations and outdated knowledge. Knowledge Graph
(KG)-based Retrieval-Augmented Generation (RAG) addresses these issues by
grounding LLM outputs in structured external knowledge from KGs. However,
current KG-based RAG frameworks still struggle to optimize the trade-off
between retrieval effectiveness and efficiency in identifying a suitable amount
of relevant graph information for the LLM to digest. We introduce SubgraphRAG,
extending the KG-based RAG framework that retrieves subgraphs and leverages
LLMs for reasoning and answer prediction. Our approach innovatively integrates
a lightweight multilayer perceptron with a parallel triple-scoring mechanism
for efficient and flexible subgraph retrieval while encoding directional
structural distances to enhance retrieval effectiveness. The size of retrieved
subgraphs can be flexibly adjusted to match the query's need and the downstream
LLM's capabilities. This design strikes a balance between model complexity and
reasoning power, enabling scalable and generalizable retrieval processes.
Notably, based on our retrieved subgraphs, smaller LLMs like
Llama3.1-8B-Instruct deliver competitive results with explainable reasoning,
while larger models like GPT-4o achieve state-of-the-art accuracy compared with
previous baselines -- all without fine-tuning. Extensive evaluations on the
WebQSP and CWQ benchmarks highlight SubgraphRAG's strengths in efficiency,
accuracy, and reliability by reducing hallucinations and improving response
grounding.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å±ç¤ºäºå¼·å¤§çæ¨çè½åï¼ä½é¢è¨å¹»è¦ºåéæç¥è­ç­éå¶ãåºæ¼ç¥è­åè­ (KG) çæª¢ç´¢å¢å¼·çæ (RAG) ééå° LLM è¼¸åºå»ºç«å¨ä¾èª KG ççµæ§åå¤é¨ç¥è­ä¸ï¼ä¾è§£æ±ºéäºåé¡ãç¶èï¼ç¶åçåºæ¼ KG ç RAG æ¶æ§ä»é£ä»¥åªåæª¢ç´¢ææèæçä¹éçæ¬è¡¡ï¼ä»¥è­å¥é©éçç¸éåå½¢è³è¨ä¾ LLM æ¶åãæåå¼å¥äº SubgraphRAGï¼æ´åäºåºæ¼ KG ç RAG æ¶æ§ï¼å®ææª¢ç´¢å­åä¸¦å©ç¨ LLM é²è¡æ¨çåç­æ¡é æ¸¬ãæåçåæ³åµæ°å°æ´åäºä¸åè¼éç´å¤å±¤æç¥å¨åä¸åä¸¦è¡çä¸åçµè©åæ©å¶ï¼ä»¥é²è¡ææä¸å½æ§çå­åæª¢ç´¢ï¼åæç·¨ç¢¼æ¹åçµæ§è·é¢ä»¥å¢å¼·æª¢ç´¢ææãæª¢ç´¢çå­åå¤§å°å¯ä»¥éæ´»èª¿æ´ï¼ä»¥ç¬¦åæ¥è©¢çéæ±åä¸æ¸¸ LLM çåè½ãæ­¤è¨­è¨å¨æ¨¡åè¤éåº¦åæ¨çè½åä¹éåå¾å¹³è¡¡ï¼å¯¦ç¾å¯æ´åä¸å¯æ¦åçæª¢ç´¢æµç¨ãå¼å¾æ³¨æçæ¯ï¼æ ¹ææåæª¢ç´¢çå­åï¼å Llama3.1-8B-Instruct ç­è¼å°ç LLM å¯ä»¥ééå¯è§£éçæ¨çæä¾å·æç«¶ç­åççµæï¼èå GPT-4o ç­è¼å¤§çæ¨¡ååå¯éå°èåååºæºç¸æ¯çææ°æºç¢ºåº¦ï¼èä¸ææéäºé½ä¸éè¦å¾®èª¿ãå¨ WebQSP å CWQ åºæºä¸çå»£æ³è©ä¼°çªåºäº SubgraphRAG å¨æçãæºç¢ºæ§åå¯é æ§æ¹é¢çåªå¢ï¼æ¹æ³æ¯æ¸å°å¹»è¦ºä¸¦æ¹ååæä¾æã

##### **Effective Instruction Parsing Plugin for Complex Logical Query Answering on Knowledge Graphs**
2410.20321v1 by Xingrui Zhuo, Jiapu Wang, Gongqing Wu, Shirui Pan, Xindong Wu

Knowledge Graph Query Embedding (KGQE) aims to embed First-Order Logic (FOL)
queries in a low-dimensional KG space for complex reasoning over incomplete
KGs. To enhance the generalization of KGQE models, recent studies integrate
various external information (such as entity types and relation context) to
better capture the logical semantics of FOL queries. The whole process is
commonly referred to as Query Pattern Learning (QPL). However, current QPL
methods typically suffer from the pattern-entity alignment bias problem,
leading to the learned defective query patterns limiting KGQE models'
performance. To address this problem, we propose an effective Query Instruction
Parsing Plugin (QIPP) that leverages the context awareness of Pre-trained
Language Models (PLMs) to capture latent query patterns from code-like query
instructions. Unlike the external information introduced by previous QPL
methods, we first propose code-like instructions to express FOL queries in an
alternative format. This format utilizes textual variables and nested tuples to
convey the logical semantics within FOL queries, serving as raw materials for a
PLM-based instruction encoder to obtain complete query patterns. Building on
this, we design a query-guided instruction decoder to adapt query patterns to
KGQE models. To further enhance QIPP's effectiveness across various KGQE
models, we propose a query pattern injection mechanism based on compressed
optimization boundaries and an adaptive normalization component, allowing KGQE
models to utilize query patterns more efficiently. Extensive experiments
demonstrate that our plug-and-play method improves the performance of eight
basic KGQE models and outperforms two state-of-the-art QPL methods.

æè¦ï¼ç¥è­åè­æ¥è©¢åµå¥ï¼KGQEï¼æ¨å¨å°ä¸ééè¼¯ï¼FOLï¼æ¥è©¢åµå¥å°ä½ç¶­ KG ç©ºéä¸­ï¼ä»¥ä¾¿å°ä¸å®æ´ç KG é²è¡è¤éæ¨çãçºäºå¢å¼· KGQE æ¨¡åçæ³åè½åï¼æè¿çç ç©¶æ´åäºåç¨®å¤é¨è³è¨ï¼ä¾å¦å¯¦é«é¡ååéä¿ä¸ä¸æï¼ï¼ä»¥æ´å¥½å°ææ FOL æ¥è©¢çéè¼¯èªç¾©ãæ´åéç¨éå¸¸ç¨±çºæ¥è©¢æ¨¡å¼å­¸ç¿ï¼QPLï¼ãç¶èï¼ç¶åç QPL æ¹æ³éå¸¸æåå°æ¨¡å¼å¯¦é«å°é½åå·®åé¡çå½±é¿ï¼å°è´å­¸ç¿å°çæç¼ºé·æ¥è©¢æ¨¡å¼éå¶äº KGQE æ¨¡åçæè½ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸åææçæ¥è©¢æä»¤è§£æå¤æç¨å¼ï¼QIPPï¼ï¼å®å©ç¨é è¨ç·´èªè¨æ¨¡åï¼PLMï¼çä¸ä¸ææç¥ä¾å¾é¡ä»£ç¢¼çæ¥è©¢æä»¤ä¸­æ·åæ½å¨æ¥è©¢æ¨¡å¼ãèåå QPL æ¹æ³å¼å¥çå¤é¨è³è¨ä¸åï¼æåé¦åæåºé¡ä»£ç¢¼çæä»¤ä»¥å¦é¡æ ¼å¼è¡¨é FOL æ¥è©¢ãæ­¤æ ¼å¼å©ç¨æå­è®æ¸åå·¢çåçµä¾å³é FOL æ¥è©¢ä¸­çéè¼¯èªç¾©ï¼ä½çºåºæ¼ PLM çæä»¤ç·¨ç¢¼å¨çåæï¼ä»¥åå¾å®æ´çæ¥è©¢æ¨¡å¼ãå¨æ­¤åºç¤ä¸ï¼æåè¨­è¨äºä¸åæ¥è©¢å¼å°çæä»¤è§£ç¢¼å¨ï¼ä»¥å°æ¥è©¢æ¨¡å¼èª¿æ´å° KGQE æ¨¡åãçºäºé²ä¸æ­¥å¢å¼· QIPP å¨åç¨® KGQE æ¨¡åä¸­çæææ§ï¼æåæåºäºä¸ååºæ¼å£ç¸®æä½³åéçåèªé©ææ­£è¦ååä»¶çæ¥è©¢æ¨¡å¼æ³¨å¥æ©å¶ï¼åè¨± KGQE æ¨¡åæ´ææå°å©ç¨æ¥è©¢æ¨¡å¼ãå»£æ³çå¯¦é©è¡¨æï¼æåçå³æå³ç¨æ¹æ³æ¹åäºå«ååºæ¬ KGQE æ¨¡åçæè½ï¼ä¸¦åªæ¼å©ç¨®æåé²ç QPL æ¹æ³ã

##### **Mathematical Derivation Graphs: A Task for Summarizing Equation Dependencies in STEM Manuscripts**
2410.21324v1 by Vishesh Prasad, Brian Kim, Nickvash Kani

Recent advances in natural language processing (NLP), particularly with the
emergence of large language models (LLMs), have significantly enhanced the
field of textual analysis. However, while these developments have yielded
substantial progress in analyzing textual data, applying analysis to
mathematical equations and their relationships within texts has produced mixed
results. In this paper, we take the initial steps toward understanding the
dependency relationships between mathematical expressions in STEM articles. Our
dataset, sourced from a random sampling of the arXiv corpus, contains an
analysis of 107 published STEM manuscripts whose inter-equation dependency
relationships have been hand-labeled, resulting in a new object we refer to as
a derivation graph that summarizes the mathematical content of the manuscript.
We exhaustively evaluate analytical and NLP-based models to assess their
capability to identify and extract the derivation relationships for each
article and compare the results with the ground truth. Our comprehensive
testing finds that both analytical and NLP models (including LLMs) achieve
$\sim$40-50% F1 scores for extracting derivation graphs from articles,
revealing that the recent advances in NLP have not made significant inroads in
comprehending mathematical texts compared to simpler analytic models. While
current approaches offer a solid foundation for extracting mathematical
information, further research is necessary to improve accuracy and depth in
this area.

æè¦ï¼èªç¶èªè¨èçï¼NLPï¼çææ°é²å±ï¼ç¹å¥æ¯å¤§èªè¨æ¨¡åï¼LLMï¼çåºç¾ï¼å·²é¡¯èå¢å¼·äºææ¬åæé åãç¶èï¼åç®¡éäºç¼å±å¨åæææ¬è³ææ¹é¢åå¾äºå¯¦è³ªæ§é²å±ï¼ä½å°åææç¨æ¼æ¸å­¸æ¹ç¨å¼åå¶å¨ææ¬ä¸­çéä¿å»ç¢çäºä¸åççµæãå¨æ¬æä¸­ï¼æåæ¡åäºåæ­¥æ­¥é©ä¾äºè§£ STEM æç« ä¸­æ¸å­¸è¡¨éå¼ä¹éçä¾è³´éä¿ãæåçè³æéåèª arXiv èªæåº«çé¨æ©æ½æ¨£ï¼å¶ä¸­åå«å° 107 ç¯å·²ç¼è¡¨ç STEM æç¨¿çåæï¼å¶æ¹ç¨å¼éçä¾è³´éä¿å·²é²è¡æåæ¨è¨ï¼ç¢çäºä¸åæåç¨±çºè¡çåçæ°ç©ä»¶ï¼è©²ç©ä»¶ç¸½çµäºæç¨¿çæ¸å­¸å§å®¹ãæåå¾¹åºè©ä¼°äºåæååºæ¼ NLP çæ¨¡åï¼ä»¥è©ä¼°å®åè­å¥åæåæ¯ç¯æç« çè¡çéä¿çè½åï¼ä¸¦å°çµæèçå¯¦ææ³é²è¡æ¯è¼ãæåçå¨é¢æ¸¬è©¦ç¼ç¾ï¼åæå NLP æ¨¡åï¼åæ¬ LLMï¼å¨å¾æç« ä¸­æåè¡çåæ¹é¢ç F1 åæ¸åéå° $\sim$40-50%ï¼éè¡¨æèæ´ç°¡å®çåææ¨¡åç¸æ¯ï¼NLP çææ°é²å±ä¸¦æ²æå¨çè§£æ¸å­¸ææ¬æ¹é¢åå¾éå¤§é²å±ãåç®¡ç®åçæ¹æ³çºæåæ¸å­¸è³è¨æä¾äºå å¯¦çåºç¤ï¼ä½ä»éè¦é²ä¸æ­¥çç ç©¶ä¾æé«æ­¤é åçæºç¢ºæ§åæ·±åº¦ã

##### **DualMAR: Medical-Augmented Representation from Dual-Expertise Perspectives**
2410.19955v1 by Pengfei Hu, Chang Lu, Fei Wang, Yue Ning

Electronic Health Records (EHR) has revolutionized healthcare data management
and prediction in the field of AI and machine learning. Accurate predictions of
diagnosis and medications significantly mitigate health risks and provide
guidance for preventive care. However, EHR driven models often have limited
scope on understanding medical-domain knowledge and mostly rely on
simple-and-sole ontologies. In addition, due to the missing features and
incomplete disease coverage of EHR, most studies only focus on basic analysis
on conditions and medication. We propose DualMAR, a framework that enhances EHR
prediction tasks through both individual observation data and public knowledge
bases. First, we construct a bi-hierarchical Diagnosis Knowledge Graph (KG)
using verified public clinical ontologies and augment this KG via Large
Language Models (LLMs); Second, we design a new proxy-task learning on lab
results in EHR for pretraining, which further enhance KG representation and
patient embeddings. By retrieving radial and angular coordinates upon polar
space, DualMAR enables accurate predictions based on rich hierarchical and
semantic embeddings from KG. Experiments also demonstrate that DualMAR
outperforms state-of-the-art models, validating its effectiveness in EHR
prediction and KG integration in medical domains.

æè¦ï¼é»å­å¥åº·ç´é (EHR) å·²å¾¹åºæ¹è®äºé«çä¿å¥è³æç®¡çï¼ä¸¦é æ¸¬äºäººå·¥æºæ§åæ©å¨å­¸ç¿é åãæºç¢ºé æ¸¬è¨ºæ·åè¥ç©å¯å¤§å¹æ¸è¼å¥åº·é¢¨éªï¼ä¸¦æä¾é é²æ§ç§è­·çæå°æ¹éãç¶èï¼EHR é©åçæ¨¡åå¨çè§£é«çé åç¥è­ä¸éå¸¸å·æå±éæ§ï¼èä¸å¤§å¤ä¾è³´æ¼ç°¡å®ä¸å®ä¸çæ¬ä½ãæ­¤å¤ï¼ç±æ¼ EHR éºæ¼äºåè½ä¸ç¾çæ¶µèä¸å®æ´ï¼å¤§å¤æ¸ç ç©¶åå°æ³¨æ¼ç¾çåè¥ç©çåºæ¬åæãæåæåº DualMARï¼ä¸åééåäººè§å¯è³æåå¬å±ç¥è­åº«å¢å¼· EHR é æ¸¬ä»»åçæ¶æ§ãé¦åï¼æåä½¿ç¨ç¶éé©è­çå¬å±è¨åºæ¬ä½æ§å»ºä¸åéå±¤ç´è¨ºæ·ç¥è­å (KG)ï¼ä¸¦ééå¤§åèªè¨æ¨¡å (LLM) æ´åéå KGï¼å¶æ¬¡ï¼æåè¨­è¨ä¸åæ°çä»£çä»»åå­¸ç¿ï¼éå° EHR ä¸­çå¯¦é©å®¤çµæé²è¡é è¨ç·´ï¼é²ä¸æ­¥å¢å¼· KG è¡¨ç¤ºåæ£èåµå¥ãééæ·åæ¥µåº§æ¨ç©ºéä¸çå¾ååè§ååæ¨ï¼DualMAR è½å¤ æ ¹æ KG ä¸­è±å¯çå±¤ç´åèªæåµå¥é²è¡æºç¢ºçé æ¸¬ãå¯¦é©ä¹è­æ DualMAR åªæ¼æåé²çæ¨¡åï¼é©è­äºå¶å¨ EHR é æ¸¬åé«çé åä¸­ KG æ´åçæææ§ã

##### **FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning**
2410.19727v1 by Nicole Cho, Nishan Srishankar, Lucas Cecchi, William Watson

Financial intelligence generation from vast data sources has typically relied
on traditional methods of knowledge-graph construction or database engineering.
Recently, fine-tuned financial domain-specific Large Language Models (LLMs),
have emerged. While these advancements are promising, limitations such as high
inference costs, hallucinations, and the complexity of concurrently analyzing
high-dimensional financial data, emerge. This motivates our invention FISHNET
(Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning,
Expert swarming, and Task planning), an agentic architecture that accomplishes
highly complex analytical tasks for more than 98,000 regulatory filings that
vary immensely in terms of semantics, data hierarchy, or format. FISHNET shows
remarkable performance for financial insight generation (61.8% success rate
over 5.0% Routing, 45.6% RAG R-Precision). We conduct rigorous ablations to
empirically prove the success of FISHNET, each agent's importance, and the
optimized performance of assembling all agents. Our modular architecture can be
leveraged for a myriad of use-cases, enabling scalability, flexibility, and
data integrity that are critical for financial tasks.

æè¦ï¼è²¡åæå ±çæéå¸¸ä¾è³´æ¼å³çµ±çç¥è­åè¡¨å»ºæ§æè³æåº«å·¥ç¨æ¹æ³ï¼éäºæ¹æ³ä¾èªæ¼é¾å¤§çè³æä¾æºãæè¿ï¼éå°è²¡åé åé²è¡å¾®èª¿çå¤§åèªè¨æ¨¡å (LLM) å·²æéèçãåç®¡éäºé²å±ä»¤äººæ¯å¥®ï¼ä½ä»å­å¨ä¸äºéå¶ï¼ä¾å¦é«æ¨çææ¬ãå¹»è¦ºï¼ä»¥ååæåæé«ç¶­åº¦è²¡åè³æçè¤éæ§ãéä¿ä½¿æåç¼æäº FISHNETï¼ä¾èªå­æ¥è©¢ãåèª¿ãç¥ç¶æ¢ä»¶åãå°å®¶ç¾¤éåä»»åè¦åçè²¡åæå ±ï¼ï¼éæ¯ä¸ç¨®ä»£çæ¶æ§ï¼å¯éå°è¶é 98,000 ä»½æ³è¦æä»¶å·è¡é«åº¦è¤éçåæä»»åï¼èéäºæä»¶å¨èªç¾©ãè³æéå±¤ææ ¼å¼æ¹é¢å·®ç°æ¥µå¤§ãFISHNET å¨ç¢çè²¡åè¦è§£æ¹é¢è¡¨ç¾åºè²ï¼æåççº 61.8%ï¼è·¯ç±ççº 5.0%ï¼RAG R-Precision çº 45.6%ï¼ãæåé²è¡äºå´æ ¼çæ¶èï¼ä»¥å¯¦è­è­æ FISHNET çæåãæ¯åä»£ççéè¦æ§ï¼ä»¥åçµè£ææä»£ççæä½³åæè½ãæåæ¨¡çµåçæ¶æ§å¯éç¨æ¼åç¨®ä½¿ç¨æ¡ä¾ï¼æä¾è²¡åä»»åè³ééè¦çå¯æ´åæ§ãå½æ§åè³æå®æ´æ§ã

##### **Knowledge Graph Enhanced Language Agents for Recommendation**
2410.19627v1 by Taicheng Guo, Chaochun Liu, Hai Wang, Varun Mannam, Fang Wang, Xin Chen, Xiangliang Zhang, Chandan K. Reddy

Language agents have recently been used to simulate human behavior and
user-item interactions for recommendation systems. However, current language
agent simulations do not understand the relationships between users and items,
leading to inaccurate user profiles and ineffective recommendations. In this
work, we explore the utility of Knowledge Graphs (KGs), which contain extensive
and reliable relationships between users and items, for recommendation. Our key
insight is that the paths in a KG can capture complex relationships between
users and items, eliciting the underlying reasons for user preferences and
enriching user profiles. Leveraging this insight, we propose Knowledge Graph
Enhanced Language Agents(KGLA), a framework that unifies language agents and KG
for recommendation systems. In the simulated recommendation scenario, we
position the user and item within the KG and integrate KG paths as natural
language descriptions into the simulation. This allows language agents to
interact with each other and discover sufficient rationale behind their
interactions, making the simulation more accurate and aligned with real-world
cases, thus improving recommendation performance. Our experimental results show
that KGLA significantly improves recommendation performance (with a 33%-95%
boost in NDCG@1 among three widely used benchmarks) compared to the previous
best baseline method.

æè¦ï¼èªè¨ä»£çæè¿å·²è¢«ç¨æ¼æ¨¡æ¬äººé¡è¡çºåæ¨è¦ç³»çµ±ä¸­çä½¿ç¨èé ç®äºåãç¶èï¼ç®åçèªè¨ä»£çæ¨¡æ¬ä¸¦æªäºè§£ä½¿ç¨èåé ç®ä¹éçéä¿ï¼å°è´ä½¿ç¨èè¼ªå»ä¸æºç¢ºåæ¨è¦ææä¸ä½³ãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äºç¥è­åè­ (KG) çæç¨ï¼å¶ä¸­åå«ä½¿ç¨èåé ç®ä¹éå»£æ³ä¸å¯é çéä¿ï¼ä»¥ä¾æ¨è¦ãæåçééµè¦è§£æ¯ï¼KG ä¸­çè·¯å¾å¯ä»¥ææä½¿ç¨èåé ç®ä¹éçè¤ééä¿ï¼å¼åºä½¿ç¨èåå¥½çæ ¹æ¬åå ä¸¦è±å¯ä½¿ç¨èè¼ªå»ãå©ç¨æ­¤è¦è§£ï¼æåæåºäºç¥è­åè­å¢å¼·èªè¨ä»£ç (KGLA)ï¼ä¸åçµ±ä¸èªè¨ä»£çå KG ä»¥ç¨æ¼æ¨è¦ç³»çµ±çæ¶æ§ãå¨æ¨¡æ¬æ¨è¦æå¢ä¸­ï¼æåå°ä½¿ç¨èåé ç®å®ä½å¨ KG ä¸­ï¼ä¸¦å° KG è·¯å¾æ´åçºèªç¶èªè¨æè¿°å°æ¨¡æ¬ä¸­ãéåè¨±èªè¨ä»£çå½¼æ­¤äºåä¸¦ç¼ç¾å¶äºåèå¾çååä¾æï¼ä½¿æ¨¡æ¬æ´æºç¢ºä¸èå¯¦éæ¡ä¾ç¸ç¬¦ï¼å¾èæ¹åæ¨è¦æè½ãæåçå¯¦é©çµæé¡¯ç¤ºï¼èååæä½³åºæºæ¹æ³ç¸æ¯ï¼KGLA å¤§å¹æ¹åäºæ¨è¦æè½ï¼å¨ä¸åå»£æ³ä½¿ç¨çåºæºä¸­ï¼NDCG@1 æåäº 33%-95%ï¼ã

##### **Graph Linearization Methods for Reasoning on Graphs with Large Language Models**
2410.19494v1 by Christos Xypolopoulos, Guokan Shang, Xiao Fei, Giannis Nikolentzos, Hadi Abdine, Iakovos Evdaimon, Michail Chatzianastasis, Giorgos Stamou, Michalis Vazirgiannis

Large language models have evolved to process multiple modalities beyond
text, such as images and audio, which motivates us to explore how to
effectively leverage them for graph machine learning tasks. The key question,
therefore, is how to transform graphs into linear sequences of tokens, a
process we term graph linearization, so that LLMs can handle graphs naturally.
We consider that graphs should be linearized meaningfully to reflect certain
properties of natural language text, such as local dependency and global
alignment, in order to ease contemporary LLMs, trained on trillions of textual
tokens, better understand graphs. To achieve this, we developed several graph
linearization methods based on graph centrality, degeneracy, and node
relabeling schemes. We then investigated their effect on LLM performance in
graph reasoning tasks. Experimental results on synthetic graphs demonstrate the
effectiveness of our methods compared to random linearization baselines. Our
work introduces novel graph representations suitable for LLMs, contributing to
the potential integration of graph machine learning with the trend of
multi-modal processing using a unified transformer model.

æè¦ï¼å¤§åèªè¨æ¨¡åå·²æ¼åçºèçæå­ä¹å¤çå¤ç¨®æ¨¡å¼ï¼ä¾å¦å½±ååé³è¨ï¼éä¿ä½¿æåæ¢ç´¢å¦ä½ææå°éç¨å®åæ¼åå½¢æ©å¨å­¸ç¿ä»»åãå æ­¤ï¼ééµåé¡å¨æ¼å¦ä½å°åå½¢è½æçºç·æ§åºåçä»£å¹£ï¼éæ¯ä¸åæåç¨±çºåå½¢ç·æ§åçéç¨ï¼è® LLM è½èªç¶å°èçåå½¢ãæåèªçºåå½¢æææç¾©å°é²è¡ç·æ§åï¼ä»¥åæ èªç¶èªè¨æå­çç¹å®å±¬æ§ï¼ä¾å¦å±é¨ä¾è³´æ§åå¨å±å°é½ï¼ä»¥ä¾¿è®å¨æ¸ååæå­ä»£å¹£ä¸è¨ç·´çç¶ä»£ LLM æ´è½çè§£åå½¢ãçºéææ­¤ç®çï¼æåéç¼äºå¹¾ç¨®åºæ¼åå½¢ä¸­å¿æ§ãç°¡ä½µæ§åç¯é»éæ°æ¨ç±¤æ¶æ§çåå½¢ç·æ§åæ¹æ³ãæ¥èï¼æåæ¢è¨å®åå° LLM å¨åå½¢æ¨çä»»åä¸­çæè½å½±é¿ãåæåå½¢ä¸çå¯¦é©çµæè­æäºæåçæ¹æ³æ¯é¨æ©ç·æ§ååºæºæ´ææãæåçç ç©¶å¼å¥äºé©å LLM çæ°ç©åå½¢è¡¨ç¤ºæ³ï¼æå©æ¼å°åå½¢æ©å¨å­¸ç¿èä½¿ç¨çµ±ä¸Transformeræ¨¡åçå¤æ¨¡å¼èçè¶¨å¢æ´åèµ·ä¾ã

##### **Hierarchical Mixture of Experts: Generalizable Learning for High-Level Synthesis**
2410.19225v1 by Weikai Li, Ding Wang, Zijian Ding, Atefeh Sohrabizadeh, Zongyue Qin, Jason Cong, Yizhou Sun

High-level synthesis (HLS) is a widely used tool in designing Field
Programmable Gate Array (FPGA). HLS enables FPGA design with software
programming languages by compiling the source code into an FPGA circuit. The
source code includes a program (called ``kernel'') and several pragmas that
instruct hardware synthesis, such as parallelization, pipeline, etc. While it
is relatively easy for software developers to design the program, it heavily
relies on hardware knowledge to design the pragmas, posing a big challenge for
software developers. Recently, different machine learning algorithms, such as
GNNs, have been proposed to automate the pragma design via performance
prediction. However, when applying the trained model on new kernels, the
significant domain shift often leads to unsatisfactory performance. We propose
a more domain-generalizable model structure: a two-level hierarchical Mixture
of Experts (MoE), that can be flexibly adapted to any GNN model. Different
expert networks can learn to deal with different regions in the representation
space, and they can utilize similar patterns between the old kernels and new
kernels. In the low-level MoE, we apply MoE on three natural granularities of a
program: node, basic block, and graph. The high-level MoE learns to aggregate
the three granularities for the final decision. To stably train the
hierarchical MoE, we further propose a two-stage training method. Extensive
experiments verify the effectiveness of the hierarchical MoE.

æè¦ï¼é«éç¶åï¼HLSï¼æ¯è¨­è¨ç¾å ´å¯ç·¨ç¨éé£åï¼FPGAï¼ä¸­å»£æ³ä½¿ç¨çå·¥å·ãHLS ééå°åå§ç¢¼ç·¨è­¯æ FPGA é»è·¯ï¼ä½¿ç¨è»é«ç¨å¼èªè¨é²è¡ FPGA è¨­è¨ãåå§ç¢¼åå«ä¸åç¨å¼ï¼ç¨±çºãæ ¸å¿ãï¼åå¤åæå°ç¡¬é«ç¶åçæç¤ºï¼ä¾å¦å¹³è¡åãç®¡ç·ç­ãéç¶è»é«éç¼äººå¡è¨­è¨ç¨å¼ç¸å°å®¹æï¼ä½å®æ¥µåº¦ä¾è³´ç¡¬é«ç¥è­ä¾è¨­è¨æç¤ºï¼éå°è»é«éç¼äººå¡ä¾èªªæ¯ä¸å¤§ææ°ãæè¿ï¼ä¸åçæ©å¨å­¸ç¿æ¼ç®æ³ï¼ä¾å¦ GNNï¼å·²è¢«æåºç¨æ¼ééæè½é æ¸¬èªåé²è¡æç¤ºè¨­è¨ãç¶èï¼å¨æ°çæ ¸å¿ä¸æç¨è¨ç·´å¥½çæ¨¡åæï¼é¡¯èçé åè½ç§»éå¸¸æå°è´æè½ä¸ä½³ãæåæåºä¸åæ´å·é åéç¨æ§çæ¨¡åçµæ§ï¼ä¸åäºéå±¤æ··åå°å®¶ï¼MoEï¼ï¼å®å¯ä»¥éæ´»å°é©æä»»ä½ GNN æ¨¡åãä¸åçå°å®¶ç¶²è·¯å¯ä»¥å­¸ç¿èçè¡¨ç¤ºç©ºéä¸­çä¸åååï¼ä¸¦ä¸å®åå¯ä»¥å©ç¨èæ ¸å¿åæ°æ ¸å¿ä¹éçç¸ä¼¼æ¨¡å¼ãå¨ä½é MoE ä¸­ï¼æåå°ç¨å¼çä¸åèªç¶ç²åº¦æç¨ MoEï¼ç¯é»ãåºæ¬åå¡ååãé«é MoE å­¸ç¿å½ç¸½éä¸åç²åº¦ä»¥ååºæçµæ±ºç­ãçºäºç©©å®è¨ç·´éå±¤å¼ MoEï¼æåé²ä¸æ­¥æåºä¸åäºéæ®µè¨ç·´æ¹æ³ãå»£æ³çå¯¦é©é©è­äºéå±¤å¼ MoE çæææ§ã

##### **Enriching GNNs with Text Contextual Representations for Detecting Disinformation Campaigns on Social Media**
2410.19193v1 by Bruno Croso Cunha da Silva, Thomas Palmeira Ferraz, Roseli De Deus Lopes

Disinformation on social media poses both societal and technical challenges.
While previous studies have integrated textual information into propagation
networks, they have yet to fully leverage the advancements in Transformer-based
language models for high-quality contextual text representations. This work
investigates the impact of incorporating textual features into Graph Neural
Networks (GNNs) for fake news detection. Our experiments demonstrate that
contextual representations improve performance by 9.3% in Macro F1 over static
ones and 33.8% over GNNs without textual features. However, noisy data
augmentation degrades performance and increases instability. We expect our
methodology to open avenues for further research, and all code is made publicly
available.

æè¦ï¼ç¤¾ç¾¤åªé«ä¸çé¯èª¤è¨æ¯é æç¤¾æåæè¡å±¤é¢çææ°ã
åç®¡éå¾çç ç©¶å·²å°æå­è³è¨æ´åå°å³æ­ç¶²è·¯ä¸­ï¼ä½å°æªååå©ç¨åºæ¼ Transformer çèªè¨æ¨¡åå¨é«åè³ªèçµ¡æå­è¡¨å¾µä¸çé²å±ãéé ç ç©¶æ¢è¨å°æå­ç¹å¾µç´å¥åå½¢ç¥ç¶ç¶²è·¯ (GNN) ä¸­å°æ¼åæ°èåµæ¸¬çå½±é¿ãæåçå¯¦é©çµæé¡¯ç¤ºï¼èçµ¡è¡¨å¾µå°å·¨è§ F1 çæè½æåäº 9.3%ï¼åªæ¼éæè¡¨å¾µï¼ä¸¦æ¯æ²ææå­ç¹å¾µç GNN æåäº 33.8%ãç¶èï¼æéè¨çè³ææ´åæéä½æè½ä¸¦å¢å ä¸ç©©å®æ§ãæåé ææåçç ç©¶æ¹æ³å°éåé²ä¸æ­¥ç ç©¶çéå¾ï¼ææç¨å¼ç¢¼çå¬éæä¾ã

##### **GCoder: Improving Large Language Model for Generalized Graph Problem Solving**
2410.19084v1 by Qifan Zhang, Xiaobin Hong, Jianheng Tang, Nuo Chen, Yuhan Li, Wenzhong Li, Jing Tang, Jia Li

Large Language Models (LLMs) have demonstrated strong reasoning abilities,
making them suitable for complex tasks such as graph computation. Traditional
reasoning steps paradigm for graph problems is hindered by unverifiable steps,
limited long-term reasoning, and poor generalization to graph variations. To
overcome these limitations, we introduce GCoder, a code-based LLM designed to
enhance problem-solving in generalized graph computation problems. Our method
involves constructing an extensive training dataset, GraphWild, featuring
diverse graph formats and algorithms. We employ a multi-stage training process,
including Supervised Fine-Tuning (SFT) and Reinforcement Learning from Compiler
Feedback (RLCF), to refine model capabilities. For unseen tasks, a hybrid
retrieval technique is used to augment performance. Experiments demonstrate
that GCoder outperforms GPT-4o, with an average accuracy improvement of 16.42%
across various graph computational problems. Furthermore, GCoder efficiently
manages large-scale graphs with millions of nodes and diverse input formats,
overcoming the limitations of previous models focused on the reasoning steps
paradigm. This advancement paves the way for more intuitive and effective graph
problem-solving using LLMs. Code and data are available at here:
https://github.com/Bklight999/WWW25-GCoder/tree/master.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾å¼·å¤§çæ¨çè½åï¼ä½¿å¶é©ç¨æ¼è¤éä»»åï¼ä¾å¦åå½¢éç®ãå³çµ±åå½¢åé¡çæ¨çæ­¥é©ç¯ä¾åå°ä¸å¯é©è­çæ­¥é©ãæéçé·ææ¨çåå°åå½¢è®åçæ¦æ¬æ§ä¸ä½³çé»ç¤ãçºäºåæéäºéå¶ï¼æåå¼å¥äº GCoderï¼ä¸ç¨®åºæ¼ä»£ç¢¼ç LLMï¼æ¨å¨å¢å¼·å»£ç¾©åå½¢éç®åé¡ä¸­çåé¡è§£æ±ºè½åãæåçæè¡æ¶åæ§å»ºä¸åå»£æ³çè¨ç·´è³æé GraphWildï¼å¶ä¸­åå«å¤æ¨£çåå½¢æ ¼å¼åæ¼ç®æ³ãæåæ¡ç¨å¤éæ®µè¨ç·´æµç¨ï¼åæ¬ç£ç£å¾®èª¿ (SFT) åç·¨è­¯å¨åé¥å¼·åå­¸ç¿ (RLCF)ï¼ä»¥æ¹åæ¨¡åè½åãå°æ¼æªç¥ä»»åï¼ä½¿ç¨æ··åæ·åæè¡ä¾å¢å¼·æè½ãå¯¦é©è­æï¼GCoder åªæ¼ GPT-4oï¼å¨åç¨®åå½¢éç®åé¡ä¸­å¹³åæºç¢ºåº¦æåäº 16.42%ãæ­¤å¤ï¼GCoder ææå°ç®¡çèæææ¸ç¾è¬åç¯é»åå¤æ¨£è¼¸å¥æ ¼å¼çå¤§è¦æ¨¡åå½¢ï¼åæäºååå°æ³¨æ¼æ¨çæ­¥é©ç¯ä¾çæ¨¡åçéå¶ãéé é²å±çºä½¿ç¨ LLM é²è¡æ´ç´è§ä¸ææçåå½¢åé¡è§£æ±ºéªå¹³äºéè·¯ãç¨å¼ç¢¼åè³æå¯æ¼æ­¤èåå¾ï¼https://github.com/Bklight999/WWW25-GCoder/tree/masterã

##### **LLM-based Online Prediction of Time-varying Graph Signals**
2410.18718v1 by Dayu Qin, Yi Yan, Ercan Engin Kuruoglu

In this paper, we propose a novel framework that leverages large language
models (LLMs) for predicting missing values in time-varying graph signals by
exploiting spatial and temporal smoothness. We leverage the power of LLM to
achieve a message-passing scheme. For each missing node, its neighbors and
previous estimates are fed into and processed by LLM to infer the missing
observations. Tested on the task of the online prediction of wind-speed graph
signals, our model outperforms online graph filtering algorithms in terms of
accuracy, demonstrating the potential of LLMs in effectively addressing
partially observed signals in graphs.

æè¦ï¼å¨æ¬æä¸­ï¼æåæåºäºä¸åæ°ç©çæ¡æ¶ï¼è©²æ¡æ¶å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾é æ¸¬æè®åå½¢ä¿¡èä¸­çç¼ºå¤±å¼ï¼æ¹æ³æ¯å©ç¨ç©ºéåæéå¹³æ»åº¦ãæåå©ç¨ LLM çè½åä¾å¯¦ç¾æ¶æ¯å³éæ¹æ¡ãå°æ¼æ¯åç¼ºå¤±ç¯é»ï¼å¶é°å±åååçä¼°è¨å¼æè¢«è¼¸å¥å° LLM ä¸­ä¸¦ç± LLM é²è¡èçï¼ä»¥æ¨æ·åºç¼ºå¤±çè§æ¸¬å¼ãå¨é¢¨éåå½¢ä¿¡èçç·ä¸é æ¸¬ä»»åä¸­é²è¡æ¸¬è©¦ï¼æåçæ¨¡åå¨æºç¢ºæ§æ¹é¢åªæ¼ç·ä¸åå½¢éæ¿¾æ¼ç®æ³ï¼éè­æäº LLM å¨ææèçåå½¢ä¸­é¨åè§æ¸¬å°çä¿¡èæ¹é¢çæ½åã

##### **Gene-Metabolite Association Prediction with Interactive Knowledge Transfer Enhanced Graph for Metabolite Production**
2410.18475v2 by Kexuan Xin, Qingyun Wang, Junyu Chen, Pengfei Yu, Huimin Zhao, Heng Ji

In the rapidly evolving field of metabolic engineering, the quest for
efficient and precise gene target identification for metabolite production
enhancement presents significant challenges. Traditional approaches, whether
knowledge-based or model-based, are notably time-consuming and labor-intensive,
due to the vast scale of research literature and the approximation nature of
genome-scale metabolic model (GEM) simulations. Therefore, we propose a new
task, Gene-Metabolite Association Prediction based on metabolic graphs, to
automate the process of candidate gene discovery for a given pair of metabolite
and candidate-associated genes, as well as presenting the first benchmark
containing 2474 metabolites and 1947 genes of two commonly used microorganisms
Saccharomyces cerevisiae (SC) and Issatchenkia orientalis (IO). This task is
challenging due to the incompleteness of the metabolic graphs and the
heterogeneity among distinct metabolisms. To overcome these limitations, we
propose an Interactive Knowledge Transfer mechanism based on Metabolism Graph
(IKT4Meta), which improves the association prediction accuracy by integrating
the knowledge from different metabolism graphs. First, to build a bridge
between two graphs for knowledge transfer, we utilize Pretrained Language
Models (PLMs) with external knowledge of genes and metabolites to help generate
inter-graph links, significantly alleviating the impact of heterogeneity.
Second, we propagate intra-graph links from different metabolic graphs using
inter-graph links as anchors. Finally, we conduct the gene-metabolite
association prediction based on the enriched metabolism graphs, which integrate
the knowledge from multiple microorganisms. Experiments on both types of
organisms demonstrate that our proposed methodology outperforms baselines by up
to 12.3% across various link prediction frameworks.

æè¦ï¼<paragraph>å¨å¿«éç¼å±çä»£è¬å·¥ç¨é åä¸­ï¼å°æ±ææä¸ç²¾ç¢ºçåºå ç®æ¨è­å¥ä»¥æåä»£è¬ç¢ç©ç¢éï¼æ¯ä¸é éå¤§çææ°ãå³çµ±æ¹æ³ï¼ç¡è«æ¯åºæ¼ç¥è­æåºæ¼æ¨¡åï¼é½ç¸ç¶èæä¸è²»åï¼éæ¯å çºç ç©¶æç»çè¦æ¨¡é¾å¤§ï¼ä¸åºå çµè¦æ¨¡ä»£è¬æ¨¡å (GEM) æ¨¡æ¬çè¿ä¼¼æ§è³ªãå æ­¤ï¼æåæåºäºä¸é æ°çä»»åï¼å³åºæ¼ä»£è¬åçåºå -ä»£è¬ç©éè¯é æ¸¬ï¼ä»¥èªåååé¸åºå ç¼ç¾çéç¨ï¼éå°çµ¦å®çä»£è¬ç©å°ååé¸ç¸éåºå ï¼ä¸¦åç¾ç¬¬ä¸ååºæºï¼å¶ä¸­åå« 2474 ç¨®ä»£è¬ç©å 1947 ååºå ï¼ä¾èªå©ç¨®å¸¸ç¨çå¾®çç©éééµæ¯ (SC) åæ±æ¹ä¼è©ç´ç§éµæ¯ (IO)ãç±æ¼ä»£è¬åçä¸å®æ´æ§åä¸åä»£è¬ç©ä¹éçç°è³ªæ§ï¼éé ä»»åå·æææ°æ§ãçºäºåæéäºéå¶ï¼æåæåºäºä¸ååºæ¼ä»£è¬åçäºåç¥è­å³è¼¸æ©å¶ (IKT4Meta)ï¼å®ééæ´åä¾èªä¸åä»£è¬åçç¥è­ä¾æé«éè¯é æ¸¬çæºç¢ºæ§ãé¦åï¼çºäºå¨å©ååä¹éå»ºç«ç¥è­å³è¼¸çæ©æ¨ï¼æåå©ç¨å·ååºå åä»£è¬ç©å¤é¨ç¥è­çé è¨ç·´èªè¨æ¨¡å (PLM) ä¾å¹«å©ç¢çåéé£çµï¼å¤§å¹æ¸è¼ç°è³ªæ§çå½±é¿ãå¶æ¬¡ï¼æåä½¿ç¨åéé£çµä½çºé¨é»ï¼å¾ä¸åçä»£è¬åå³æ­åå§é£çµãæå¾ï¼æåæ ¹ææ´åäºå¤ç¨®å¾®çç©ç¥è­çè±å¯ä»£è¬åï¼é²è¡åºå -ä»£è¬ç©éè¯é æ¸¬ãå©ç¨®çç©é«çå¯¦é©é½è­æï¼æåæåºçæ¹æ³å¨åç¨®é£çµé æ¸¬æ¶æ§ä¸­ï¼æ¯åºæºé«åº 12.3%ã</paragraph>

##### **ToolFlow: Boosting LLM Tool-Calling Through Natural and Coherent Dialogue Synthesis**
2410.18447v1 by Zezhong Wang, Xingshan Zeng, Weiwen Liu, Liangyou Li, Yasheng Wang, Lifeng Shang, Xin Jiang, Qun Liu, Kam-Fai Wong

Supervised fine-tuning (SFT) is a common method to enhance the tool calling
capabilities of Large Language Models (LLMs), with the training data often
being synthesized. The current data synthesis process generally involves
sampling a set of tools, formulating a requirement based on these tools, and
generating the call statements. However, tools sampled randomly lack relevance,
making them difficult to combine and thus reducing the diversity of the data.
Additionally, current work overlooks the coherence between turns of dialogues,
leading to a gap between the synthesized data and real-world scenarios. To
address these issues, we propose a Graph-based Sampling strategy to sample more
relevant tool combinations, and a Planned-generation strategy to create plans
that guide the synthesis of coherent dialogues. We integrate these two
strategies and enable multiple agents to synthesize the dialogue data
interactively, resulting in our tool-calling data synthesis pipeline ToolFlow.
Data quality assessments demonstrate improvements in the naturalness and
coherence of our synthesized dialogues. Finally, we apply SFT on LLaMA-3.1-8B
using 8,000 synthetic dialogues generated with ToolFlow. Results show that the
model achieves tool-calling performance comparable to or even surpassing GPT-4,
while maintaining strong general capabilities.

æè¦ï¼ç£ç£å¾®èª¿ (SFT) æ¯å¢å¼·å¤§åèªè¨æ¨¡å (LLM) å·¥å·å¼å«åè½çå¸¸è¦æ¹æ³ï¼è¨ç·´è³æéå¸¸æ¯åæè³æãç®åçè³æåææµç¨éå¸¸æ¶åæ½æ¨£ä¸çµå·¥å·ãæ ¹æéäºå·¥å·å¶å®éæ±ï¼ä¸¦ç¢çå¼å«é³è¿°ãç¶èï¼é¨æ©æ½æ¨£çå·¥å·ç¼ºä¹éè¯æ§ï¼ä½¿å¾å®åé£ä»¥çµåï¼å¾èéä½è³æçå¤æ¨£æ§ãæ­¤å¤ï¼ç®åçå·¥ä½å¿½ç¥äºå°è©±ååä¹éçé£è²«æ§ï¼å°è´åæè³æèç¾å¯¦ä¸çå ´æ¯ä¹éå­å¨å·®è·ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºä¸ååºæ¼åå½¢çæ½æ¨£ç­ç¥ä¾æ½åæ´å¤ç¸éçå·¥å·çµåï¼ä»¥åä¸åè¨ç«çæç­ç¥ä¾å»ºç«è¨ç«ï¼ä»¥å¼å°é£è²«å°è©±çåæãæåæ´åéå©ç¨®ç­ç¥ï¼ä¸¦ä½¿å¤åä»£çè½å¤ äºåå°åæå°è©±è³æï¼å¾èç¢çæåçå·¥å·å¼å«è³æåæç®¡ç· ToolFlowãè³æåè³ªè©ä¼°è­æäºæååæå°è©±çèªç¶æ§åé£è²«æ§æäºæ¹é²ãæå¾ï¼æåä½¿ç¨ ToolFlow çæç 8,000 ååæå°è©±å¨ LLaMA-3.1-8B ä¸æç¨ SFTãçµæè¡¨æï¼è©²æ¨¡åå¯¦ç¾äºè GPT-4 ç¸ç¶çè³è¶è¶ GPT-4 çå·¥å·å¼å«æè½ï¼åæä¿æå¼·å¤§çéç¨è½åã

##### **Decoding on Graphs: Faithful and Sound Reasoning on Knowledge Graphs through Generation of Well-Formed Chains**
2410.18415v1 by Kun Li, Tianhua Zhang, Xixin Wu, Hongyin Luo, James Glass, Helen Meng

Knowledge Graphs (KGs) can serve as reliable knowledge sources for question
answering (QA) due to their structured representation of knowledge. Existing
research on the utilization of KG for large language models (LLMs) prevalently
relies on subgraph retriever or iterative prompting, overlooking the potential
synergy of LLMs' step-wise reasoning capabilities and KGs' structural nature.
In this paper, we present DoG (Decoding on Graphs), a novel framework that
facilitates a deep synergy between LLMs and KGs. We first define a concept,
well-formed chain, which consists of a sequence of interrelated fact triplets
on the KGs, starting from question entities and leading to answers. We argue
that this concept can serve as a principle for making faithful and sound
reasoning for KGQA. To enable LLMs to generate well-formed chains, we propose
graph-aware constrained decoding, in which a constraint derived from the
topology of the KG regulates the decoding process of the LLMs. This constrained
decoding method ensures the generation of well-formed chains while making full
use of the step-wise reasoning capabilities of LLMs. Based on the above, DoG, a
training-free approach, is able to provide faithful and sound reasoning
trajectories grounded on the KGs. Experiments across various KGQA tasks with
different background KGs demonstrate that DoG achieves superior and robust
performance. DoG also shows general applicability with various open-source
LLMs.

æè¦ï¼ç¥è­åè­ (KG) ç±æ¼å¶çµæ§åçç¥è­è¡¨ç¤ºï¼å¯ç¨ä½åç­ (QA) çå¯é ç¥è­ä¾æºãç¾æéæ¼å©ç¨ KG çå¤§åèªè¨æ¨¡å (LLM) çç ç©¶æ®éä¾è³´æ¼å­åæª¢ç´¢å¨æåè¦æç¤ºï¼å¿½è¦äº LLM çéæ­¥æ¨çè½åå KG ççµæ§ç¹æ§çæ½å¨ååä½ç¨ãå¨æ¬æä¸­ï¼æåæåºäº DoGï¼åå½¢è§£ç¢¼ï¼ï¼ä¸åä¿é² LLM å KG ä¹éæ·±åº¦ååä½ç¨çæ°æ¡æ¶ãæåé¦åå®ç¾©äºä¸åæ¦å¿µï¼å³è¯å¥½å½¢æçéï¼å®ç± KG ä¸ä¸ç³»åç¸äºéè¯çäºå¯¦ä¸åçµçµæï¼å¾åé¡å¯¦é«éå§ä¸¦å°è´ç­æ¡ãæåèªçºéåæ¦å¿µå¯ä»¥ä½çºå° KGQA é²è¡å¿ å¯¦ååççæ¨ççååãçºäºä½¿ LLM è½å¤ çæè¯å¥½çéï¼æåæåºäºåæç¥ç´æè§£ç¢¼ï¼å¶ä¸­æºèª KG ææ²çç´æç´æäº LLM çè§£ç¢¼éç¨ãéç¨®åç´æçè§£ç¢¼æ¹æ³ç¢ºä¿äºè¯å¥½å½¢æçéççæï¼åæååå©ç¨äº LLM çéæ­¥æ¨çè½åãåºæ¼ä¸è¿°ï¼DoG æ¯ä¸ç¨®ç¡éè¨ç·´çæ¹æ³ï¼è½å¤ æä¾åºæ¼ KG çå¿ å¯¦ä¸åççæ¨çè»è·¡ãå¨å·æä¸åèæ¯ KG çåç¨® KGQA ä»»åä¸­çå¯¦é©è¡¨æï¼DoG éå°äºåè¶ä¸ç©©å¥çæ§è½ãDoG éé¡¯ç¤ºäºèåç¨®éæº LLM çéç¨é©ç¨æ§ã

##### **Explaining Bayesian Networks in Natural Language using Factor Arguments. Evaluation in the medical domain**
2410.18060v1 by Jaime Sevilla, Nikolay Babakov, Ehud Reiter, Alberto Bugarin

In this paper, we propose a model for building natural language explanations
for Bayesian Network Reasoning in terms of factor arguments, which are
argumentation graphs of flowing evidence, relating the observed evidence to a
target variable we want to learn about. We introduce the notion of factor
argument independence to address the outstanding question of defining when
arguments should be presented jointly or separately and present an algorithm
that, starting from the evidence nodes and a target node, produces a list of
all independent factor arguments ordered by their strength. Finally, we
implemented a scheme to build natural language explanations of Bayesian
Reasoning using this approach. Our proposal has been validated in the medical
domain through a human-driven evaluation study where we compare the Bayesian
Network Reasoning explanations obtained using factor arguments with an
alternative explanation method. Evaluation results indicate that our proposed
explanation approach is deemed by users as significantly more useful for
understanding Bayesian Network Reasoning than another existing explanation
method it is compared to.

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æåæåºäºä¸åæ¨¡åï¼ç¨æ¼å»ºæ§è²æ°ç¶²è·¯æ¨ççèªç¶èªè¨è§£éï¼ä»¥å å­è«è­çºåºç¤ï¼å®åæ¯æµåè­æçè«è­åï¼å°è§å¯å°çè­æèæåæ³è¦äºè§£çç®æ¨è®æ¸è¯ç¹«èµ·ä¾ãæåå¼å¥äºå å­è«è­ç¨ç«æ§çæ¦å¿µï¼ä»¥è§£æ±ºå®ç¾©ä½ææå°è«è­è¯åæå®ç¨åç¾çæªæ±ºåé¡ï¼ä¸¦æåºäºä¸ç¨®æ¼ç®æ³ï¼å¾è­æç¯é»åç®æ¨ç¯é»éå§ï¼ç¢çä¸åæå¼·åº¦æåºçææç¨ç«å å­è«è­æ¸å®ãæå¾ï¼æåå¯¦ä½äºä¸åæ¹æ¡ï¼ä½¿ç¨éç¨®æ¹æ³å»ºæ§è²æ°æ¨ççèªç¶èªè¨è§£éãæåçææ¡å·²å¨é«å­¸é åä¸­ééäººçºé©åçè©ä¼°ç ç©¶å¾å°é©è­ï¼å¨è©²ç ç©¶ä¸­ï¼æåå°ä½¿ç¨å å­è«è­ç²å¾çè²æ°ç¶²è·¯æ¨çè§£éèå¦ä¸ç¨®è§£éæ¹æ³é²è¡æ¯è¼ãè©ä¼°çµæè¡¨æï¼èå¦ä¸ç¨®ç¾æçè§£éæ¹æ³ç¸æ¯ï¼æåçæè­°è§£éæ¹æ³è¢«ä½¿ç¨èè¦çºé¡¯èæ´æå©æ¼çè§£è²æ°ç¶²è·¯æ¨çã</paragraph>

##### **Graphusion: A RAG Framework for Knowledge Graph Construction with a Global Perspective**
2410.17600v1 by Rui Yang, Boming Yang, Aosong Feng, Sixun Ouyang, Moritz Blum, Tianwei She, Yuang Jiang, Freddy Lecue, Jinghui Lu, Irene Li

Knowledge Graphs (KGs) are crucial in the field of artificial intelligence
and are widely used in downstream tasks, such as question-answering (QA). The
construction of KGs typically requires significant effort from domain experts.
Large Language Models (LLMs) have recently been used for Knowledge Graph
Construction (KGC). However, most existing approaches focus on a local
perspective, extracting knowledge triplets from individual sentences or
documents, missing a fusion process to combine the knowledge in a global KG.
This work introduces Graphusion, a zero-shot KGC framework from free text. It
contains three steps: in Step 1, we extract a list of seed entities using topic
modeling to guide the final KG includes the most relevant entities; in Step 2,
we conduct candidate triplet extraction using LLMs; in Step 3, we design the
novel fusion module that provides a global view of the extracted knowledge,
incorporating entity merging, conflict resolution, and novel triplet discovery.
Results show that Graphusion achieves scores of 2.92 and 2.37 out of 3 for
entity extraction and relation recognition, respectively. Moreover, we showcase
how Graphusion could be applied to the Natural Language Processing (NLP) domain
and validate it in an educational scenario. Specifically, we introduce TutorQA,
a new expert-verified benchmark for QA, comprising six tasks and a total of
1,200 QA pairs. Using the Graphusion-constructed KG, we achieve a significant
improvement on the benchmark, for example, a 9.2% accuracy improvement on
sub-graph completion.

æè¦ï¼<paragraph>ç¥è­åè­ (KG) å¨äººå·¥æºæ§é åè³ééè¦ï¼å»£æ³ç¨æ¼ä¸æ¸¸ä»»åï¼ä¾å¦åç­ (QA)ãKG çå»ºæ§éå¸¸éè¦é åå°å®¶ä»åºå¤§éå¿åãå¤§åèªè¨æ¨¡å (LLM) è¿ä¾å·²ç¨æ¼ç¥è­åè­å»ºæ§ (KGC)ãç¶èï¼ç¾ææ¹æ³å¤§å¤èéæ¼å±é¨è§é»ï¼å¾åå¥å¥å­ææä»¶æ·åç¥è­ä¸åçµï¼ç¼ºå°ä¸åèåç¨åºä¾å°ç¥è­çµåå¨ä¸åæ´é« KG ä¸­ãæ¬ç ç©¶å¼å¥äº Graphusionï¼ä¸åå¾èªç±æå­é²è¡é¶æ¬¡å­¸ç¿ç KGC æ¡æ¶ãå®åå«ä¸åæ­¥é©ï¼å¨æ­¥é© 1 ä¸­ï¼æåä½¿ç¨ä¸»é¡å»ºæ¨¡æ·åä¸çµç¨®å­å¯¦é«ï¼ä»¥å¼å°æçµç KG ç´å¥æç¸éçå¯¦é«ï¼å¨æ­¥é© 2 ä¸­ï¼æåä½¿ç¨ LLM é²è¡åé¸ä¸åçµæ·åï¼å¨æ­¥é© 3 ä¸­ï¼æåè¨­è¨äºæ°ç©çèåæ¨¡çµï¼æä¾æ·åç¥è­çæ´é«è§é»ï¼åå«å¯¦é«åä½µãè¡çªè§£æ±ºåæ°ä¸åçµç¼ç¾ãçµæé¡¯ç¤º Graphusion å¨å¯¦é«æ·ååéä¿è­å¥æ¹é¢åå¥ç²å¾ 3 åä¸­ç 2.92 åå 2.37 åãæ­¤å¤ï¼æåå±ç¤ºäº Graphusion å¦ä½æç¨æ¼èªç¶èªè¨èç (NLP) é åï¼ä¸¦å¨æè²æå¢ä¸­é©è­å®ãå·é«ä¾èªªï¼æåå¼å¥äº TutorQAï¼ä¸åç±å°å®¶é©è­çæ°å QA åºæºï¼åå«å­é ä»»ååç¸½è¨ 1,200 çµ QAãä½¿ç¨ Graphusion å»ºæ§ç KGï¼æåå¨åºæºä¸åå¾é¡¯èé²æ­¥ï¼ä¾å¦ï¼å¨å­åå®ææ¹é¢æåäº 9.2% çæºç¢ºåº¦ã</paragraph>

##### **Navigate Complex Physical Worlds via Geometrically Constrained LLM**
2410.17529v1 by Yongqiang Huang, Wentao Ye, Liyao Li, Junbo Zhao

This study investigates the potential of Large Language Models (LLMs) for
reconstructing and constructing the physical world solely based on textual
knowledge. It explores the impact of model performance on spatial understanding
abilities. To enhance the comprehension of geometric and spatial relationships
in the complex physical world, the study introduces a set of geometric
conventions and develops a workflow based on multi-layer graphs and multi-agent
system frameworks. It examines how LLMs achieve multi-step and multi-objective
geometric inference in a spatial environment using multi-layer graphs under
unified geometric conventions. Additionally, the study employs a genetic
algorithm, inspired by large-scale model knowledge, to solve geometric
constraint problems. In summary, this work innovatively explores the
feasibility of using text-based LLMs as physical world builders and designs a
workflow to enhance their capabilities.

æè¦ï¼æ¬ç ç©¶æ¢è¨å¤§åèªè¨æ¨¡å (LLM) ååºæ¼æå­ç¥è­éå»ºåå»ºæ§ç©çä¸ççæ½åãæ¢è¨æ¨¡åæè½å°ç©ºéçè§£è½åçå½±é¿ãçºäºå¢å¼·å°è¤éç©çä¸çä¸­å¹¾ä½åç©ºééä¿ççè§£ï¼æ¬ç ç©¶å¼å¥äºä¸çµå¹¾ä½æ£ä¾ï¼ä¸¦åºæ¼å¤å±¤åå½¢åå¤ä»£çç³»çµ±æ¶æ§éç¼äºä¸å¥å·¥ä½æµç¨ãç ç©¶æ¢è¨äº LLM å¦ä½å¨çµ±ä¸çå¹¾ä½æ£ä¾ä¸ï¼ä½¿ç¨å¤å±¤åå½¢å¨ç©ºéç°å¢ä¸­éæå¤æ­¥é©åå¤ç®æ¨çå¹¾ä½æ¨è«ãæ­¤å¤ï¼æ¬ç ç©¶æ¡ç¨åå¤§åæ¨¡åç¥è­åç¼çéºå³æ¼ç®æ³ä¾è§£æ±ºå¹¾ä½ç´æåé¡ãç¸½ä¹ï¼éé å·¥ä½åµæ°å°æ¢è¨äºä½¿ç¨åºæ¼æå­ç LLM ä½çºç©çä¸çå»ºæ§èçå¯è¡æ§ï¼ä¸¦è¨­è¨äºä¸å¥å·¥ä½æµç¨ä¾å¢å¼·å¶è½åã

##### **Large Language Model-based Augmentation for Imbalanced Node Classification on Text-Attributed Graphs**
2410.16882v1 by Leyao Wang, Yu Wang, Bo Ni, Yuying Zhao, Tyler Derr

Node classification on graphs frequently encounters the challenge of class
imbalance, leading to biased performance and posing significant risks in
real-world applications. Although several data-centric solutions have been
proposed, none of them focus on Text-Attributed Graphs (TAGs), and therefore
overlook the potential of leveraging the rich semantics encoded in textual
features for boosting the classification of minority nodes. Given this crucial
gap, we investigate the possibility of augmenting graph data in the text space,
leveraging the textual generation power of Large Language Models (LLMs) to
handle imbalanced node classification on TAGs. Specifically, we propose a novel
approach called LA-TAG (LLM-based Augmentation on Text-Attributed Graphs),
which prompts LLMs to generate synthetic texts based on existing node texts in
the graph. Furthermore, to integrate these synthetic text-attributed nodes into
the graph, we introduce a text-based link predictor to connect the synthesized
nodes with the existing nodes. Our experiments across multiple datasets and
evaluation metrics show that our framework significantly outperforms
traditional non-textual-based data augmentation strategies and specific node
imbalance solutions. This highlights the promise of using LLMs to resolve
imbalance issues on TAGs.

æè¦ï¼åå½¢ç¯é»åé¡ç¶å¸¸æéå°é¡å¥ä¸å¹³è¡¡çææ°ï¼å°è´æåå·®çæè½ï¼ä¸¦å¨å¯¦éæç¨ä¸­é æé¡¯èé¢¨éªãåç®¡å·²æåºå¤é ä»¥è³æçºä¸­å¿çè§£æ±ºæ¹æ¡ï¼ä½æ²æä¸é å°æ³¨æ¼æå­å±¬æ§åå½¢ (TAG)ï¼å æ­¤å¿½ç¥äºå©ç¨æå­ç¹å¾µä¸­ç·¨ç¢¼çè±å¯èªæä¾æåå°æ¸ç¯é»åé¡çå¯è½æ§ãéæ¼éåééµå·®è·ï¼æåæ¢è¨äºå¨æå­ç©ºéä¸­æ´ååå½¢è³æçå¯è½æ§ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) çæå­ç¢çè½åä¾èç TAG ä¸çä¸å¹³è¡¡ç¯é»åé¡ãå·é«ä¾èªªï¼æåæåºäºä¸ç¨®åçº LA-TAGï¼åºæ¼ LLM çæå­å±¬æ§åå½¢æ´åï¼çæ°æ¹æ³ï¼å®æç¤º LLM æ ¹æåå½¢ä¸­ç¾æçç¯é»æå­ç¢çåææå­ãæ­¤å¤ï¼çºäºå°éäºåææå­å±¬æ§ç¯é»æ´åå°åå½¢ä¸­ï¼æåå¼å¥äºä¸ååºæ¼æå­çé£çµé æ¸¬å¨ï¼ä»¥å°åæç¯é»èç¾æç¯é»é£æ¥èµ·ä¾ãæåå¨å¤åè³æéåè©ä¼°ææ¨ä¸çå¯¦é©è¡¨æï¼æåçæ¡æ¶æé¡¯åªæ¼å³çµ±çéæå­è³ææ´åç­ç¥åç¹å®çç¯é»ä¸å¹³è¡¡è§£æ±ºæ¹æ¡ãéçªé¡¯äºä½¿ç¨ LLM ä¾è§£æ±º TAG ä¸çä¸å¹³è¡¡åé¡çæ½åã

##### **Context-aware Inductive Knowledge Graph Completion with Latent Type Constraints and Subgraph Reasoning**
2410.16803v1 by Muzhi Li, Cehao Yang, Chengjin Xu, Zixing Song, Xuhui Jiang, Jian Guo, Ho-fung Leung, Irwin King

Inductive knowledge graph completion (KGC) aims to predict missing triples
with unseen entities. Recent works focus on modeling reasoning paths between
the head and tail entity as direct supporting evidence. However, these methods
depend heavily on the existence and quality of reasoning paths, which limits
their general applicability in different scenarios. In addition, we observe
that latent type constraints and neighboring facts inherent in KGs are also
vital in inferring missing triples. To effectively utilize all useful
information in KGs, we introduce CATS, a novel context-aware inductive KGC
solution. With sufficient guidance from proper prompts and supervised
fine-tuning, CATS activates the strong semantic understanding and reasoning
capabilities of large language models to assess the existence of query triples,
which consist of two modules. First, the type-aware reasoning module evaluates
whether the candidate entity matches the latent entity type as required by the
query relation. Then, the subgraph reasoning module selects relevant reasoning
paths and neighboring facts, and evaluates their correlation to the query
triple. Experiment results on three widely used datasets demonstrate that CATS
significantly outperforms state-of-the-art methods in 16 out of 18
transductive, inductive, and few-shot settings with an average absolute MRR
improvement of 7.2%.

æè¦ï¼æ­¸ç´ç¥è­åè­å®æ (KGC) æ¨å¨é æ¸¬å·ææªè¦å¯¦é«çç¼ºå¤±ä¸åçµãæè¿çå·¥ä½éé»å¨æ¼å»ºæ¨¡é ­å¯¦é«åå°¾å¯¦é«ä¹éçæ¨çè·¯å¾ä½çºç´æ¥æ¯æè­æãç¶èï¼éäºæ¹æ³é«åº¦ä¾è³´æ¨çè·¯å¾çå­å¨ååè³ªï¼ééå¶äºå®åå¨ä¸åå ´æ¯ä¸­çæ®éé©ç¨æ§ãæ­¤å¤ï¼æåè§å¯å°é±èé¡åç´æå KG ä¸­åºæçé°è¿äºå¯¦å°æ¼æ¨æ·ç¼ºå¤±ä¸åçµä¹è³ééè¦ãçºäºææå©ç¨ KG ä¸­æææç¨çè³è¨ï¼æåå¼å¥äº CATSï¼ä¸ç¨®æ°ç©çå·åæå¢æç¥è½åçæ­¸ç´å¼ KGC è§£å³æ¹æ¡ãå¨é©ç¶æç¤ºåç£ç£å¾®èª¿çååæå°ä¸ï¼CATS ååå¤§åèªè¨æ¨¡åå¼·å¤§çèªç¾©çè§£åæ¨çè½åï¼ä»¥è©ä¼°æ¥è©¢ä¸åçµçå­å¨ï¼å¶ä¸­åå«å©åæ¨¡çµãé¦åï¼é¡åæç¥æ¨çæ¨¡çµè©ä¼°åé¸å¯¦é«æ¯å¦èæ¥è©¢éä¿æéçé±èå¯¦é«é¡åç¸ç¬¦ãç¶å¾ï¼å­åæ¨çæ¨¡çµé¸æç¸éæ¨çè·¯å¾åé°è¿äºå¯¦ï¼ä¸¦è©ä¼°å®åèæ¥è©¢ä¸åçµçéè¯æ§ãå¨ä¸åå»£æ³ä½¿ç¨çè³æéä¸é²è¡çå¯¦é©çµæè¡¨æï¼å¨ 18 åè½å°ãæ­¸ç´åå°æ¬¡åè©¦è¨­å®ä¸­ï¼CATS å¨ 16 åè¨­å®ä¸­é¡¯èåªæ¼æåé²çæ¹æ³ï¼å¹³åçµå° MRR æåäº 7.2%ã

##### **The Scene Language: Representing Scenes with Programs, Words, and Embeddings**
2410.16770v1 by Yunzhi Zhang, Zizhang Li, Matt Zhou, Shangzhe Wu, Jiajun Wu

We introduce the Scene Language, a visual scene representation that concisely
and precisely describes the structure, semantics, and identity of visual
scenes. It represents a scene with three key components: a program that
specifies the hierarchical and relational structure of entities in the scene,
words in natural language that summarize the semantic class of each entity, and
embeddings that capture the visual identity of each entity. This representation
can be inferred from pre-trained language models via a training-free inference
technique, given text or image inputs. The resulting scene can be rendered into
images using traditional, neural, or hybrid graphics renderers. Together, this
forms a robust, automated system for high-quality 3D and 4D scene generation.
Compared with existing representations like scene graphs, our proposed Scene
Language generates complex scenes with higher fidelity, while explicitly
modeling the scene structures to enable precise control and editing.

æè¦ï¼æåå¼å¥äºå ´æ¯èªè¨ï¼éæ¯ä¸ç¨®è¦è¦ºå ´æ¯è¡¨ç¤ºæ³ï¼ç°¡æ½ä¸ç²¾ç¢ºå°æè¿°äºè¦è¦ºå ´æ¯ççµæ§ãèªæåèº«åãå®ä½¿ç¨ä¸åééµçµæé¨åä¾è¡¨ç¤ºå ´æ¯ï¼ä¸åç¨å¼ï¼ç¨æ¼æå®å ´æ¯ä¸­å¯¦é«çéå±¤åéä¿çµæ§ï¼ä»¥èªç¶èªè¨è¡¨ç¤ºçè©å½ï¼ç¨æ¼ç¸½çµæ¯åå¯¦é«çèªæé¡å¥ï¼ä»¥åç¨æ¼æ·åæ¯åå¯¦é«çè¦è¦ºèº«åçåµå¥ãéåè¡¨ç¤ºæ³å¯ä»¥ééç¡è¨ç·´æ¨è«æè¡å¾é åè¨ç·´çèªè¨æ¨¡åæ¨è«åºä¾ï¼çµ¦å®æå­æå½±åè¼¸å¥ãç¢ççå ´æ¯å¯ä»¥ä½¿ç¨å³çµ±ãç¥ç¶ææ··ååå½¢æ¸²æå¨æ¸²ææå½±åãç¸½èè¨ä¹ï¼éå½¢æäºä¸åå¼·å¥çèªååç³»çµ±ï¼ç¨æ¼é«åè³ª 3D å 4D å ´æ¯çæãèç¾æçè¡¨ç¤ºæ³ï¼ä¾å¦å ´æ¯åï¼ç¸æ¯ï¼æåæåºçå ´æ¯èªè¨å¯ä»¥çæå·ææ´é«ä¿çåº¦çè¤éå ´æ¯ï¼åææç¢ºå°å»ºæ¨¡å ´æ¯çµæ§ä»¥å¯¦ç¾ç²¾ç¢ºæ§å¶åç·¨è¼¯ã

##### **Atomic Fact Decomposition Helps Attributed Question Answering**
2410.16708v1 by Zhichao Yan, Jiapu Wang, Jiaoyan Chen, Xiaoli Li, Ru Li, Jeff Z. Pan

Attributed Question Answering (AQA) aims to provide both a trustworthy answer
and a reliable attribution report for a given question. Retrieval is a widely
adopted approach, including two general paradigms: Retrieval-Then-Read (RTR)
and post-hoc retrieval. Recently, Large Language Models (LLMs) have shown
remarkable proficiency, prompting growing interest in AQA among researchers.
However, RTR-based AQA often suffers from irrelevant knowledge and rapidly
changing information, even when LLMs are adopted, while post-hoc
retrieval-based AQA struggles with comprehending long-form answers with complex
logic, and precisely identifying the content needing revision and preserving
the original intent. To tackle these problems, this paper proposes an Atomic
fact decomposition-based Retrieval and Editing (ARE) framework, which
decomposes the generated long-form answers into molecular clauses and atomic
facts by the instruction-tuned LLMs. Notably, the instruction-tuned LLMs are
fine-tuned using a well-constructed dataset, generated from large scale
Knowledge Graphs (KGs). This process involves extracting one-hop neighbors from
a given set of entities and transforming the result into coherent long-form
text. Subsequently, ARE leverages a search engine to retrieve evidences related
to atomic facts, inputting these evidences into an LLM-based verifier to
determine whether the facts require expansion for re-retrieval or editing.
Furthermore, the edited facts are backtracked into the original answer, with
evidence aggregated based on the relationship between molecular clauses and
atomic facts. Extensive evaluations demonstrate the superior performance of our
proposed method over the state-of-the-arts on several datasets, with an
additionally proposed new metric $Attr_{p}$ for evaluating the precision of
evidence attribution.

æè¦ï¼<paragraph>æ­¸å å¼åç­ (AQA) çç®æ¨æ¯éå°ç¹å®åé¡æä¾å¯ä¿¡çç­æ¡åå¯é çæ­¸å å ±åãæ·åæ¯ä¸ç¨®å»£æ³æ¡ç¨çæ¹æ³ï¼åæ¬å©ç¨®ä¸è¬ç¯ä¾ï¼æ·ååé±è® (RTR) åäºå¾æ·åãæè¿ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºåè¶ççç·´åº¦ï¼ä¿ä½¿ç ç©¶äººå¡å° AQA ç¢çè¶ä¾è¶æ¿åçèè¶£ãç¶èï¼å³ä½¿æ¡ç¨ LLMï¼åºæ¼ RTR ç AQA ä»å¸¸å¸¸æåå°ä¸ç¸éç¥è­åå¿«éè®åçè³è¨å½±é¿ï¼èåºæ¼äºå¾æ·åç AQA åé£ä»¥çè§£å·æè¤ééè¼¯çé·ç¯ç­æ¡ï¼ä¸¦ç²¾ç¢ºæ¾åºéè¦ä¿®æ¹çå§å®¹ï¼åæä¿çåå§æåãçºäºè§£æ±ºéäºåé¡ï¼æ¬ææåºäºä¸ååºæ¼åå­äºå¯¦åè§£çæ·ååç·¨è¼¯ (ARE) æ¶æ§ï¼å®ééæä»¤èª¿æ´ç LLM å°ç¢ççé·ç¯ç­æ¡åè§£çºåå­å­å¥ååå­äºå¯¦ãå¼å¾æ³¨æçæ¯ï¼æä»¤èª¿æ´ç LLM æä½¿ç¨å¾å¤§è¦æ¨¡ç¥è­åè­ (KG) ä¸­ç¢çççµæ§è¯å¥½è³æéé²è¡å¾®èª¿ãæ­¤ç¨åºåå«å¾ç¹å®å¯¦é«éåä¸­æ·åä¸è·³é°å±ï¼ä¸¦å°çµæè½æçºé£è²«çé·ç¯æå­ãé¨å¾ï¼ARE æå©ç¨æå°å¼ææ·åèåå­äºå¯¦ç¸éçè­æï¼å°éäºè­æè¼¸å¥å°åºæ¼ LLM çé©è­å¨ä¸­ï¼ä»¥ç¢ºå®äºå¯¦æ¯å¦éè¦æ´åä»¥ä¾éæ°æ·åæç·¨è¼¯ãæ­¤å¤ï¼ç·¨è¼¯å¾ççµææåæº¯å°åå§ç­æ¡ï¼ä¸¦æ ¹æåå­å­å¥ååå­äºå¯¦ä¹éçéä¿å½æ´è­æãå»£æ³çè©ä¼°é¡¯ç¤ºï¼æåæåºçæ¹æ³å¨å¤åè³æéä¸åªæ¼ç¾ææè¡ï¼ä¸¦é¡å¤æåºäºä¸åæ°çææ¨ $Attr_{p}$ï¼ç¨æ¼è©ä¼°è­ææ­¸å çç²¾æºåº¦ã</paragraph>

##### **PLDR-LLM: Large Language Model from Power Law Decoder Representations**
2410.16703v1 by Burc Gokden

We present the Large Language Model from Power Law Decoder Representations
(PLDR-LLM), a language model that leverages non-linear and linear
transformations through Power Law Graph Attention mechanism to generate
well-defined deductive and inductive outputs. We pretrain the PLDR-LLMs of
varying layer sizes with a small batch size of 32 and $\sim$8B tokens from the
RefinedWeb dataset, and show that they achieve competitive performance in
zero-shot and few-shot settings compared to scaled dot-product LLMs of similar
model size reported in the literature. We show that deductive outputs of
PLDR-LLMs can be used to compare model characteristics or improve the
performance by introducing the Directed Acyclic Graph (DAG) loss as a metric
and regularizer. Our results indicate that the initial maximum learning rate
and warm-up steps have a lasting impact on deductive outputs throughout the
pretraining. We provide a detailed description of PLDR-LLM architecture, its
implementation and the pretraining procedure.

æè¦ï¼æåæåºä½¿ç¨åªå¾è§£ç¢¼å¨è¡¨ç¤ºæ³çå¤§èªè¨æ¨¡å (PLDR-LLM)ï¼éæ¯ä¸åèªè¨æ¨¡åï¼å®ééåªå¾åæ³¨æåæ©å¶ï¼å©ç¨éç·æ§åç·æ§è½æä¾ç¢çå®ç¾©è¯å¥½çæ¼ç¹¹åæ­¸ç´è¼¸åºãæåä½¿ç¨ 32 çå°æ¹æ¬¡å¤§å°å RefinedWeb è³æéä¸­ç $\sim$8B ä»¤çï¼é è¨ç·´ä¸åå±¤å¤§å°ç PLDR-LLMï¼ä¸¦å±ç¤ºåºå®åå¨é¶æ¬¡åå°æ¬¡è¨­å®ä¸­ï¼èæç»ä¸­å ±å°çé¡ä¼¼æ¨¡åå¤§å°çç¸®æ¾é»ç© LLM ç¸æ¯ï¼å®åéå°äºç«¶ç­åè¡¨ç¾ãæåå±ç¤ºäº PLDR-LLM çæ¼ç¹¹è¼¸åºå¯ç¨æ¼æ¯è¼æ¨¡åç¹å¾µæééå¼å¥æåç¡ç°å (DAG) æå¤±ä½çºææ¨åæ­£ååå¨ä¾æ¹åæè½ãæåççµæè¡¨æï¼åå§æå¤§å­¸ç¿çåç±èº«æ­¥é©å°æ´åé è¨ç·´éç¨ä¸­çæ¼ç¹¹è¼¸åºææä¹çå½±é¿ãæåæä¾äº PLDR-LLM æ¶æ§ãå¶å¯¦ç¾åé è¨ç·´ç¨åºçè©³ç´°èªªæã

##### **Distill-SynthKG: Distilling Knowledge Graph Synthesis Workflow for Improved Coverage and Efficiency**
2410.16597v1 by Prafulla Kumar Choubey, Xin Su, Man Luo, Xiangyu Peng, Caiming Xiong, Tiep Le, Shachar Rosenman, Vasudev Lal, Phil Mui, Ricky Ho, Phillip Howard, Chien-Sheng Wu

Knowledge graphs (KGs) generated by large language models (LLMs) are becoming
increasingly valuable for Retrieval-Augmented Generation (RAG) applications
that require knowledge-intensive reasoning. However, existing KG extraction
methods predominantly rely on prompt-based approaches, which are inefficient
for processing large-scale corpora. These approaches often suffer from
information loss, particularly with long documents, due to the lack of
specialized design for KG construction. Additionally, there is a gap in
evaluation datasets and methodologies for ontology-free KG construction. To
overcome these limitations, we propose SynthKG, a multi-step, document-level
ontology-free KG synthesis workflow based on LLMs. By fine-tuning a smaller LLM
on the synthesized document-KG pairs, we streamline the multi-step process into
a single-step KG generation approach called Distill-SynthKG, substantially
reducing the number of LLM inference calls. Furthermore, we re-purpose existing
question-answering datasets to establish KG evaluation datasets and introduce
new evaluation metrics. Using KGs produced by Distill-SynthKG, we also design a
novel graph-based retrieval framework for RAG. Experimental results demonstrate
that Distill-SynthKG not only surpasses all baseline models in KG quality --
including models up to eight times larger -- but also consistently excels in
retrieval and question-answering tasks. Our proposed graph retrieval framework
also outperforms all KG-retrieval methods across multiple benchmark datasets.
We release the SynthKG dataset and Distill-SynthKG model publicly to support
further research and development.

æè¦ï¼ç±å¤§åèªè¨æ¨¡å (LLM) çæçç¥è­åè­ (KG) å°æ¼éè¦ç¥è­å¯éåæ¨ççæª¢ç´¢å¢å¼·çæ (RAG) æç¨ç¨å¼è®å¾è¶ä¾è¶æå¹å¼ãç¶èï¼ç¾æç KG èåæ¹æ³ä¸»è¦ä¾è³´æ¼æç¤ºå¼æ¹æ³ï¼éç¨®æ¹æ³å°æ¼èçå¤§è¦æ¨¡èªæåº«èè¨æçä½ä¸ãç±æ¼ç¼ºä¹éå° KG å»ºæ§çå°éè¨­è¨ï¼éäºæ¹æ³éå¸¸æé­åè³è¨éºå¤±ï¼ç¹å¥æ¯å¨é·ç¯æä»¶çææ³ä¸ãæ­¤å¤ï¼å¨ç¨æ¼å»ºæ§ç¡æ¬ä½ KG çè©ä¼°è³æéåæ¹æ³è«æ¹é¢å­å¨å·®è·ãçºäºåæéäºéå¶ï¼æåæåºäº SynthKGï¼éæ¯ä¸ååºæ¼ LLM çå¤æ­¥é©æä»¶ç´å¥ç¡æ¬ä½ KG åæå·¥ä½æµç¨ãééå¾®èª¿è¼å°ç LLM å¨åæçæä»¶-KG å°ä¸ï¼æåå°å¤æ­¥é©æµç¨ç°¡åçºç¨±çº Distill-SynthKG çå®æ­¥é© KG çææ¹æ³ï¼å¤§å¹æ¸å°äº LLM æ¨è«å¼å«çæ¸éãæ­¤å¤ï¼æåéæ°å©ç¨ç¾æçåç­è³æéä¾å»ºç« KG è©ä¼°è³æéï¼ä¸¦å¼å¥æ°çè©ä¼°ææ¨ãä½¿ç¨ Distill-SynthKG çæç KGï¼æåéçº RAG è¨­è¨äºä¸åæ°ç©çåºæ¼åå½¢çæª¢ç´¢æ¶æ§ãå¯¦é©çµæè¡¨æï¼Distill-SynthKG ä¸åå¨ KG åè³ªæ¹é¢è¶è¶äºææåºæºæ¨¡åï¼åæ¬å¤§å«åçæ¨¡åï¼ï¼èä¸å¨æª¢ç´¢ååç­ä»»åä¸­ä¹å§çµè¡¨ç¾åºè²ãæåæåºçåå½¢æª¢ç´¢æ¶æ§å¨å¤ååºæºè³æéä¸ä¹åªæ¼ææ KG æª¢ç´¢æ¹æ³ãæåå¬ééåº SynthKG è³æéå Distill-SynthKG æ¨¡åï¼ä»¥æ¯æé²ä¸æ­¥çç ç©¶åéç¼ã

##### **Towards a Reliable Offline Personal AI Assistant for Long Duration Spaceflight**
2410.16397v1 by Oliver Bensch, Leonie Bensch, Tommy Nilsson, Florian Saling, Wafa M. Sadri, Carsten Hartmann, Tobias Hecking, J. Nathan Kutz

As humanity prepares for new missions to the Moon and Mars, astronauts will
need to operate with greater autonomy, given the communication delays that make
real-time support from Earth difficult. For instance, messages between Mars and
Earth can take up to 24 minutes, making quick responses impossible. This
limitation poses a challenge for astronauts who must rely on in-situ tools to
access the large volume of data from spacecraft sensors, rovers, and
satellites, data that is often fragmented and difficult to use. To bridge this
gap, systems like the Mars Exploration Telemetry-Driven Information System
(METIS) are being developed. METIS is an AI assistant designed to handle
routine tasks, monitor spacecraft systems, and detect anomalies, all while
reducing the reliance on mission control. Current Generative Pretrained
Transformer (GPT) Models, while powerful, struggle in safety-critical
environments. They can generate plausible but incorrect responses, a phenomenon
known as "hallucination," which could endanger astronauts. To overcome these
limitations, this paper proposes enhancing systems like METIS by integrating
GPTs, Retrieval-Augmented Generation (RAG), Knowledge Graphs (KGs), and
Augmented Reality (AR). The idea is to allow astronauts to interact with their
data more intuitively, using natural language queries and visualizing real-time
information through AR. KGs will be used to easily access live telemetry and
multimodal data, ensuring that astronauts have the right information at the
right time. By combining AI, KGs, and AR, this new system will empower
astronauts to work more autonomously, safely, and efficiently during future
space missions.

æè¦ï¼é¨èäººé¡æºååå¾æçåç«æå·è¡æ°ä»»åï¼èéå°éè¨å»¶é²è®ä¾èªå°ççå³ææ¯æ´è®å¾å°é£ï¼å¤ªç©ºäººå°éè¦ä»¥æ´é«çèªä¸»æ§å·è¡ä»»åãä¾å¦ï¼ç«æåå°çä¹éçè¨æ¯å³éå¯è½éè¦é·é 24 åéï¼éä½¿å¾å¿«éåæè®å¾ä¸å¯è½ãéåéå¶å°å¿é ä»°è³´ç¾å ´å·¥å·æè½å­åä¾èªå¤ªç©ºè¹ææ¸¬å¨ãæ¢æ¸¬è»åè¡æçå¤§éè³æçå¤ªç©ºäººä¾èªªæ¯ä¸é ææ°ï¼èéäºè³æéå¸¸æ¯çæ®µä¸é£ä»¥ä½¿ç¨çãçºäºå½åéåå·®è·ï¼åç«ææ¢æ¸¬éæ¸¬é©åè³è¨ç³»çµ± (METIS) ä¹é¡çç³»çµ±æ­£å¨éç¼ä¸­ãMETIS æ¯ä¸å AI å©çï¼æ¨å¨èçä¾è¡å·¥ä½ãç£æ§å¤ªç©ºè¹ç³»çµ±ååµæ¸¬ç°å¸¸ï¼åææ¸å°å°ä»»åæ§å¶çä¾è³´ãç¾æççæå¼é è¨ç·´Transformer (GPT) æ¨¡åéç¶å¼·å¤§ï¼ä½å¨å®å¨ééµç°å¢ä¸­å»é£ä»¥ç¼æ®ä½ç¨ãå®åå¯è½æç¢ççä¼¼åçä½é¯èª¤çåæï¼éç¨®ç¾è±¡ç¨±çºãå¹»è¦ºãï¼å¯è½æä½¿å¤ªç©ºäººé·å¥å±éªãçºäºåæéäºéå¶ï¼æ¬ææåºééæ´å GPTãæª¢ç´¢å¢å¼·çæ (RAG)ãç¥è­åè­ (KG) åæ´å¢å¯¦å¢ (AR) ä¾å¢å¼·å METIS ä¹é¡çç³»çµ±ãéåæ³æ³æ¯è®å¤ªç©ºäººè½å¤ æ´ç´è¦ºå°èä»åçè³æäºåï¼ä½¿ç¨èªç¶èªè¨æ¥è©¢ä¸¦éé AR è¦è¦ºåå³æè³è¨ãKG å°ç¨æ¼è¼é¬å­åå³æéæ¸¬åå¤æ¨¡å¼è³æï¼ç¢ºä¿å¤ªç©ºäººå¨é©ç¶çæéåå¾é©ç¶çè³è¨ãééçµå AIãKG å ARï¼éåæ°ç³»çµ±å°è³¦è½å¤ªç©ºäººå¨æªä¾çå¤ªç©ºä»»åä¸­æ´èªä¸»ãå®å¨ä¸ææçå°å·¥ä½ã

##### **A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns**
2410.16155v1 by Tianyi Men, Pengfei Cao, Zhuoran Jin, Yubo Chen, Kang Liu, Jun Zhao

With the development of large language models, they are widely used as agents
in various fields. A key component of agents is memory, which stores vital
information but is susceptible to jailbreak attacks. Existing research mainly
focuses on single-agent attacks and shared memory attacks. However, real-world
scenarios often involve independent memory. In this paper, we propose the
Troublemaker Makes Chaos in Honest Town (TMCHT) task, a large-scale,
multi-agent, multi-topology text-based attack evaluation framework. TMCHT
involves one attacker agent attempting to mislead an entire society of agents.
We identify two major challenges in multi-agent attacks: (1) Non-complete graph
structure, (2) Large-scale systems. We attribute these challenges to a
phenomenon we term toxicity disappearing. To address these issues, we propose
an Adversarial Replication Contagious Jailbreak (ARCJ) method, which optimizes
the retrieval suffix to make poisoned samples more easily retrieved and
optimizes the replication suffix to make poisoned samples have contagious
ability. We demonstrate the superiority of our approach in TMCHT, with 23.51%,
18.95%, and 52.93% improvements in line topology, star topology, and 100-agent
settings. Encourage community attention to the security of multi-agent systems.

æè¦ï¼éçå¤§åè¯­è¨æ¨¡åçåå±ï¼å®ä»¬è¢«å¹¿æ³ç¨ä½åä¸ªé¢åçä»£çãä»£ççå³é®ç»æé¨åæ¯è®°å¿ï¼å®å­å¨éè¦ä¿¡æ¯ï¼ä½å®¹æåå°è¶ç±æ»å»ãç°æç ç©¶ä¸»è¦éä¸­å¨åä¸ä»£çæ»å»åå±äº«åå­æ»å»ä¸ãç¶èï¼ç°å®ä¸çä¸­çåºæ¯éå¸¸æ¶åç¬ç«çåå­ãå¨æ¬æä¸­ï¼æä»¬æåºäº Troublemaker Makes Chaos in Honest Town (TMCHT) ä»»å¡ï¼è¿æ¯ä¸ä¸ªå¤§è§æ¨¡ãå¤ä»£çãå¤ææåºäºææ¬çæ»å»è¯ä¼°æ¡æ¶ãTMCHT æ¶åä¸ä¸ªæ»å»èä»£çè¯å¾è¯¯å¯¼æ´ä¸ªä»£çç¤¾ä¼ãæä»¬ç¡®å®äºå¤ä»£çæ»å»ä¸­çä¸¤ä¸ªä¸»è¦ææï¼(1) éå®æ´å¾ç»æï¼(2) å¤§è§æ¨¡ç³»ç»ãæä»¬å°è¿äºææå½å äºæä»¬ç§°ä¹ä¸ºæ¯æ§æ¶å¤±çç°è±¡ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬æåºäºä¸ç§å¯¹ææ§å¤å¶ä¼ ææ§è¶ç± (ARCJ) æ¹æ³ï¼è¯¥æ¹æ³ä¼åäºæ£ç´¢åç¼ä»¥ä½¿ä¸­æ¯æ ·æ¬æ´å®¹æè¢«æ£ç´¢ï¼å¹¶ä¼åäºå¤å¶åç¼ä»¥ä½¿ä¸­æ¯æ ·æ¬å·æä¼ ææ§ãæä»¬å¨ TMCHT ä¸­å±ç¤ºäºæä»¬æ¹æ³çä¼è¶æ§ï¼å¨ç´çº¿ææãæå½¢ææå 100 ä»£çè®¾ç½®ä¸­åå«æé«äº 23.51%ã18.95% å 52.93%ãé¼å±ç¤¾åºå³æ³¨å¤ä»£çç³»ç»çå®å¨æ§ã

##### **CausalGraph2LLM: Evaluating LLMs for Causal Queries**
2410.15939v1 by Ivaxi Sheth, Bahare Fatemi, Mario Fritz

Causality is essential in scientific research, enabling researchers to
interpret true relationships between variables. These causal relationships are
often represented by causal graphs, which are directed acyclic graphs. With the
recent advancements in Large Language Models (LLMs), there is an increasing
interest in exploring their capabilities in causal reasoning and their
potential use to hypothesize causal graphs. These tasks necessitate the LLMs to
encode the causal graph effectively for subsequent downstream tasks. In this
paper, we propose a comprehensive benchmark, \emph{CausalGraph2LLM},
encompassing a variety of causal graph settings to assess the causal graph
understanding capability of LLMs. We categorize the causal queries into two
types: graph-level and node-level queries. We benchmark both open-sourced and
closed models for our study. Our findings reveal that while LLMs show promise
in this domain, they are highly sensitive to the encoding used. Even capable
models like GPT-4 and Gemini-1.5 exhibit sensitivity to encoding, with
deviations of about $60\%$. We further demonstrate this sensitivity for
downstream causal intervention tasks. Moreover, we observe that LLMs can often
display biases when presented with contextual information about a causal graph,
potentially stemming from their parametric memory.

æè¦ï¼å æå³ç³»å¨ç§å­¦ç ç©¶ä¸­è³å³éè¦ï¼å®ä½¿ç ç©¶äººåè½å¤è§£éåéä¹é´ççå®å³ç³»ãè¿äºå æå³ç³»éå¸¸ç¨å æå¾è¡¨ç¤ºï¼å æå¾æ¯æåæ ç¯å¾ãéçå¤§è¯­è¨æ¨¡å (LLM) çææ°è¿å±ï¼äººä»¬è¶æ¥è¶æå´è¶£æ¢ç´¢å®ä»¬å¨å ææ¨çä¸­çè½åä»¥åå®ä»¬å¨åè®¾å æå¾ä¸­çæ½å¨ç¨éãè¿äºä»»å¡éè¦ LLM ææå°å¯¹å æå¾è¿è¡ç¼ç ï¼ä»¥ä¾¿åç»­çä¸æ¸¸ä»»å¡ãå¨æ¬æä¸­ï¼æä»¬æåºäºä¸ä¸ªç»¼ååºåï¼\emph{CausalGraph2LLM}ï¼å®åå«äºåç§å æå¾è®¾ç½®ï¼ä»¥è¯ä¼° LLM çå æå¾çè§£è½åãæä»¬å°å ææ¥è¯¢åä¸ºä¸¤ç±»ï¼å¾çº§æ¥è¯¢åèç¹çº§æ¥è¯¢ãæä»¬å¯¹å¼æºæ¨¡ååå°é­æ¨¡åè¿è¡äºåºåæµè¯ãæä»¬çç ç©¶ç»æè¡¨æï¼è½ç¶ LLM å¨è¯¥é¢åæ¾ç¤ºåºåæ¯ï¼ä½å®ä»¬å¯¹æä½¿ç¨çç¼ç éå¸¸ææãå³ä½¿å GPT-4 å Gemini-1.5 è¿æ ·çå¼ºå¤§æ¨¡åä¹å¯¹ç¼ç è¡¨ç°åºæææ§ï¼åå·®çº¦ä¸º 60%ãæä»¬è¿ä¸æ­¥è¯æäºè¿ç§å¯¹ä¸æ¸¸å æå¹²é¢ä»»å¡çæææ§ãæ­¤å¤ï¼æä»¬è§å¯å°ï¼å½ LLM è·å¾æå³å æå¾çä¸ä¸æä¿¡æ¯æ¶ï¼å®ä»¬éå¸¸ä¼è¡¨ç°åºåè§ï¼è¿å¯è½æºäºå®ä»¬çåæ°è®°å¿ã

##### **LLM4GRN: Discovering Causal Gene Regulatory Networks with LLMs -- Evaluation through Synthetic Data Generation**
2410.15828v1 by Tejumade Afonja, Ivaxi Sheth, Ruta Binkyte, Waqar Hanif, Thomas Ulas, Matthias Becker, Mario Fritz

Gene regulatory networks (GRNs) represent the causal relationships between
transcription factors (TFs) and target genes in single-cell RNA sequencing
(scRNA-seq) data. Understanding these networks is crucial for uncovering
disease mechanisms and identifying therapeutic targets. In this work, we
investigate the potential of large language models (LLMs) for GRN discovery,
leveraging their learned biological knowledge alone or in combination with
traditional statistical methods. We develop a task-based evaluation strategy to
address the challenge of unavailable ground truth causal graphs. Specifically,
we use the GRNs suggested by LLMs to guide causal synthetic data generation and
compare the resulting data against the original dataset. Our statistical and
biological assessments show that LLMs can support statistical modeling and data
synthesis for biological research.

æè¦ï¼åºå èª¿æ§ç¶²è·¯ (GRN) ä»£è¡¨å®ç´°è RNA å®åº (scRNA-seq) è³æä¸­è½éå å­ (TF) èç®æ¨åºå ä¹éçå æéä¿ãäºè§£éäºç¶²è·¯å°æ¼æ­é²ç¾çæ©å¶åæ¾åºæ²»çç®æ¨è³ééè¦ãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨å¤§åèªè¨æ¨¡å (LLM) å¨ GRN æ¢ç´¢ä¸­çæ½åï¼å©ç¨å®åå­¸ç¿å°ççç©ç¥è­ï¼å®ç¨æèå³çµ±çµ±è¨æ¹æ³çµåä½¿ç¨ãæåå¶å®äºä¸é åºæ¼ä»»åçè©ä¼°ç­ç¥ï¼ä»¥è§£æ±ºç¡æ³åå¾å°é¢çç¸å æåè¡¨çææ°ãå·é«ä¾èªªï¼æåä½¿ç¨ LLM å»ºè­°ç GRN ä¾å¼å°å æåæè³æç¢çï¼ä¸¦å°ç¢ççè³æèåå§è³æéé²è¡æ¯è¼ãæåççµ±è¨åçç©è©ä¼°é¡¯ç¤ºï¼LLM å¯ä»¥æ¯æ´çç©ç ç©¶ççµ±è¨å»ºæ¨¡åè³æåæã

##### **NetSafe: Exploring the Topological Safety of Multi-agent Networks**
2410.15686v1 by Miao Yu, Shilong Wang, Guibin Zhang, Junyuan Mao, Chenlong Yin, Qijiong Liu, Qingsong Wen, Kun Wang, Yang Wang

Large language models (LLMs) have empowered nodes within multi-agent networks
with intelligence, showing growing applications in both academia and industry.
However, how to prevent these networks from generating malicious information
remains unexplored with previous research on single LLM's safety be challenging
to transfer. In this paper, we focus on the safety of multi-agent networks from
a topological perspective, investigating which topological properties
contribute to safer networks. To this end, we propose a general framework,
NetSafe along with an iterative RelCom interaction to unify existing diverse
LLM-based agent frameworks, laying the foundation for generalized topological
safety research. We identify several critical phenomena when multi-agent
networks are exposed to attacks involving misinformation, bias, and harmful
information, termed as Agent Hallucination and Aggregation Safety. Furthermore,
we find that highly connected networks are more susceptible to the spread of
adversarial attacks, with task performance in a Star Graph Topology decreasing
by 29.7%. Besides, our proposed static metrics aligned more closely with
real-world dynamic evaluations than traditional graph-theoretic metrics,
indicating that networks with greater average distances from attackers exhibit
enhanced safety. In conclusion, our work introduces a new topological
perspective on the safety of LLM-based multi-agent networks and discovers
several unreported phenomena, paving the way for future research to explore the
safety of such networks.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è³¦äºäºå¤ä¸»é«ç¶²è·¯ä¸­çç¯é»æºæ§ï¼å¨å­¸è¡çåç¢æ¥­ä¸­å±ç¾åºè¶ä¾è¶å¤çæç¨ãç¶èï¼å¦ä½é²æ­¢éäºç¶²è·¯ç¢çæ¡æè³è¨ä»ç¶æ¯æªç¶æ¢ç´¢çé åï¼ååéå°å®ä¸ LLM å®å¨æ§çç ç©¶é£ä»¥è½ç§»ãå¨æ¬æä¸­ï¼æåå¾ææ²å­¸çè§åº¦æ¢è¨å¤ä¸»é«ç¶²è·¯çå®å¨æ§ï¼ç ç©¶åªäºææ²å±¬æ§æå©æ¼ç¶²è·¯æ´å®å¨ãçºæ­¤ï¼æåæåºäºä¸åéç¨æ¡æ¶ NetSafeï¼ä»¥åä¸ååè¦ç RelCom äºåï¼ä»¥çµ±ä¸ç¾æçåç¨®åºæ¼ LLM çä¸»é«æ¡æ¶ï¼çºå»£ç¾©çææ²å®å¨æ§ç ç©¶å¥ å®åºç¤ãæåå¨å¤ä¸»é«ç¶²è·¯é­åæ¶åé¯èª¤è³è¨ãåè¦åæå®³è³è¨çæ»ææï¼æ¾åºå¹¾åééµç¾è±¡ï¼ç¨±çºä¸»é«å¹»è¦ºåèåå®å¨æ§ãæ­¤å¤ï¼æåç¼ç¾é«åº¦é£æ¥çç¶²è·¯æ´å®¹æåå°å°ææ§æ»æçå½±é¿ï¼æå½¢åå½¢ææ²ä¸­çä»»åæè½ä¸éäº 29.7%ãæ­¤å¤ï¼æåæåºçéæææ¨æ¯å³çµ±çåè«ææ¨æ´è²¼è¿çå¯¦ä¸ççåæè©ä¼°ï¼éè¡¨ç¤ºèæ»æèå¹³åè·é¢è¼å¤§çç¶²è·¯å·ææ´é«çå®å¨æ§ãç¸½ä¹ï¼æåçç ç©¶å¼å¥äºåºæ¼ LLM çå¤ä¸»é«ç¶²è·¯å®å¨æ§çæ°ææ²è§é»ï¼ä¸¦ç¼ç¾äºå¹¾åæªæ¾å ±å°çç¾è±¡ï¼çºæªä¾æ¢ç´¢æ­¤é¡ç¶²è·¯å®å¨æ§çç ç©¶éªè·¯ã

##### **TAGExplainer: Narrating Graph Explanations for Text-Attributed Graph Learning Models**
2410.15268v1 by Bo Pan, Zhen Xiong, Guanchen Wu, Zheng Zhang, Yifei Zhang, Liang Zhao

Representation learning of Text-Attributed Graphs (TAGs) has garnered
significant attention due to its applications in various domains, including
recommendation systems and social networks. Despite advancements in TAG
learning methodologies, challenges remain in explainability due to the
black-box nature of existing TAG representation learning models. This paper
presents TAGExplainer, the first method designed to generate natural language
explanations for TAG learning. TAGExplainer employs a generative language model
that maps input-output pairs to explanations reflecting the model's
decision-making process. To address the lack of annotated ground truth
explanations in real-world scenarios, we propose first generating pseudo-labels
that capture the model's decisions from saliency-based explanations, then the
pseudo-label generator is iteratively trained based on three training
objectives focusing on faithfulness and brevity via Expert Iteration, to
improve the quality of generated pseudo-labels. The high-quality pseudo-labels
are finally utilized to train an end-to-end explanation generator model.
Extensive experiments are conducted to demonstrate the effectiveness of
TAGExplainer in producing faithful and concise natural language explanations.

æè¦ï¼ææ¬æ­¸å å (TAG) çè¡¨ç¤ºå­¸ç¿å å¶å¨åç¨®é åï¼åæ¬æ¨è¦ç³»çµ±åç¤¾äº¤ç¶²çµ¡ï¼ä¸­çæç¨èååéæ³¨ãåç®¡ TAG å­¸ç¿æ¹æ³åå¾äºé²å±ï¼ä½ç±æ¼ç¾æ TAG è¡¨ç¤ºå­¸ç¿æ¨¡åçé»ç®±æ§è³ªï¼å¯è§£éæ§ä»ç¶é¢è¨ææ°ãæ¬ææåºäº TAGExplainerï¼éæ¯ä¸ç¨®æ¨å¨çº TAG å­¸ç¿çæèªç¶èªè¨è§£éçç¬¬ä¸ç¨®æ¹æ³ãTAGExplainer æ¡ç¨çæèªè¨æ¨¡åï¼å°è¼¸å¥è¼¸åºå°æå°åæ æ¨¡åæ±ºç­éç¨çè§£éãçºäºè§£æ±ºç¾å¯¦å ´æ¯ä¸­ç¼ºä¹è¨»è§£å°é¢çå¯¦è§£éçåé¡ï¼æåå»ºè­°é¦åå¾åºæ¼é¡¯èæ§çè§£éä¸­çæå½æ¨ç±¤ä¾æææ¨¡åçæ±ºç­ï¼ç¶å¾ééå°å®¶è¿­ä»£åºæ¼ä¸åè¨ç·´ç®æ¨ï¼å´éæ¼å¿ å¯¦åº¦åç°¡æ½æ§ï¼åè¦è¨ç·´å½æ¨ç±¤çæå¨ï¼ä»¥æé«çæå½æ¨ç±¤çåè³ªãæå¾å°é«åè³ªçå½æ¨ç±¤ç¨æ¼è¨ç·´ç«¯å°ç«¯è§£éçæå¨æ¨¡åãé²è¡äºå»£æ³çå¯¦é©ï¼ä»¥è­æ TAGExplainer å¨çæå¿ å¯¦ä¸ç°¡æ½çèªç¶èªè¨è§£éæ¹é¢çæææ§ã

##### **Explaining Graph Neural Networks with Large Language Models: A Counterfactual Perspective for Molecular Property Prediction**
2410.15165v1 by Yinhan He, Zaiyi Zheng, Patrick Soga, Yaozhen Zhu, yushun Dong, Jundong Li

In recent years, Graph Neural Networks (GNNs) have become successful in
molecular property prediction tasks such as toxicity analysis. However, due to
the black-box nature of GNNs, their outputs can be concerning in high-stakes
decision-making scenarios, e.g., drug discovery. Facing such an issue, Graph
Counterfactual Explanation (GCE) has emerged as a promising approach to improve
GNN transparency. However, current GCE methods usually fail to take
domain-specific knowledge into consideration, which can result in outputs that
are not easily comprehensible by humans. To address this challenge, we propose
a novel GCE method, LLM-GCE, to unleash the power of large language models
(LLMs) in explaining GNNs for molecular property prediction. Specifically, we
utilize an autoencoder to generate the counterfactual graph topology from a set
of counterfactual text pairs (CTPs) based on an input graph. Meanwhile, we also
incorporate a CTP dynamic feedback module to mitigate LLM hallucination, which
provides intermediate feedback derived from the generated counterfactuals as an
attempt to give more faithful guidance. Extensive experiments demonstrate the
superior performance of LLM-GCE. Our code is released on
https://github.com/YinhanHe123/new\_LLM4GNNExplanation.

æè¦ï¼è¿å¹´æ¥ï¼å¾ç¥ç»ç½ç» (GNN) å·²æååºç¨äºåå­æ§è´¨é¢æµä»»å¡ï¼ä¾å¦æ¯æ§åæãç¶èï¼ç±äº GNN çé»çæ§è´¨ï¼å¶è¾åºå¨é«é£é©å³ç­åºæ¯ä¸­å¯è½ä¼ä»¤äººæå¿§ï¼ä¾å¦è¯ç©åç°ãéå¯¹è¿ä¸é®é¢ï¼å¾åäºå®è§£é (GCE) å·²æä¸ºæé« GNN éæåº¦çä¸ç§å¾æåæ¯çæ¹æ³ãç¶èï¼å½åç GCE æ¹æ³éå¸¸æ æ³èèç¹å®é¢åçç¥è¯ï¼è¿å¯è½å¯¼è´äººç±»é¾ä»¥çè§£è¾åºãä¸ºäºåºå¯¹è¿ä¸ææï¼æä»¬æåºäºä¸ç§æ°é¢ç GCE æ¹æ³ï¼LLM-GCEï¼ä»¥éæ¾å¤§åè¯­è¨æ¨¡å (LLM) å¨è§£é GNN ç¨äºåå­æ§è´¨é¢æµæ¹é¢çè½åãå·ä½æ¥è¯´ï¼æä»¬å©ç¨èªå¨ç¼ç å¨ä»ä¸ç»åºäºè¾å¥å¾çåäºå®ææ¬å¯¹ (CTP) çæåäºå®å¾ææãåæ¶ï¼æä»¬è¿å å¥äºä¸ä¸ª CTP å¨æåé¦æ¨¡åæ¥åè½» LLM å¹»è§ï¼è¯¥æ¨¡åæä¾ä»çæçåäºå®ä¸­æ´¾ççä¸­é´åé¦ï¼ä»¥å°è¯æä¾æ´çå®çæå¯¼ãå¤§éçå®éªè¡¨æäº LLM-GCE çåè¶æ§è½ãæä»¬çä»£ç å·²åå¸å¨ https://github.com/YinhanHe123/new\_LLM4GNNExplanationã

##### **MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science**
2410.15126v1 by Junho Kim, Yeachan Kim, Jun-Hyung Park, Yerim Oh, Suho Kim, SangKeun Lee

We introduce a novel continued pre-training method, MELT (MatEriaLs-aware
continued pre-Training), specifically designed to efficiently adapt the
pre-trained language models (PLMs) for materials science. Unlike previous
adaptation strategies that solely focus on constructing domain-specific corpus,
MELT comprehensively considers both the corpus and the training strategy, given
that materials science corpus has distinct characteristics from other domains.
To this end, we first construct a comprehensive materials knowledge base from
the scientific corpus by building semantic graphs. Leveraging this extracted
knowledge, we integrate a curriculum into the adaptation process that begins
with familiar and generalized concepts and progressively moves toward more
specialized terms. We conduct extensive experiments across diverse benchmarks
to verify the effectiveness and generality of MELT. A comprehensive evaluation
convincingly supports the strength of MELT, demonstrating superior performance
compared to existing continued pre-training methods. The in-depth analysis also
shows that MELT enables PLMs to effectively represent materials entities
compared to the existing adaptation methods, thereby highlighting its broad
applicability across a wide spectrum of materials science.

æè¦ï¼æåä»ç´¹äºä¸ç¨®æ°ç©çæçºé è¨ç·´æ¹æ³ï¼MELTï¼MatEriaLs-awareæçºé è¨ç·´ï¼ï¼å°éè¨­è¨ç¨æ¼ææå°èª¿æ´ææç§å­¸çé è¨ç·´èªè¨æ¨¡å (PLM)ãèåååå°æ³¨æ¼å»ºæ§ç¹å®é åèªæåº«çèª¿æ´ç­ç¥ä¸åï¼MELT å¨é¢èæ®èªæåº«åè¨ç·´ç­ç¥ï¼å çºææç§å­¸èªæåº«å·æä¸åæ¼å¶ä»é åçç¹å¾µãçºæ­¤ï¼æåé¦åééå»ºç«èªç¾©åå¾ç§å­¸èªæåº«æ§å»ºä¸åå¨é¢çææç¥è­åº«ãå©ç¨æåçç¥è­ï¼æåå°èª²ç¨æ´åå°èª¿æ´éç¨ä¸­ï¼å¾çæä¸éç¨çæ¦å¿µéå§ï¼éæ¼¸è½åæ´å°æ¥­çè¡èªãæåå¨ä¸åçåºæºä¸é²è¡äºå»£æ³çå¯¦é©ï¼ä»¥é©è­ MELT çæææ§åæ®éæ§ãå¨é¢çè©ä¼°ä»¤äººä¿¡æå°æ¯æäº MELT çåªé»ï¼èç¾æçæçºé è¨ç·´æ¹æ³ç¸æ¯ï¼è¡¨ç¾åºåªç°çæ§è½ãæ·±å¥åæéè¡¨æï¼èç¾æçèª¿æ´æ¹æ³ç¸æ¯ï¼MELT è½è® PLM ææå°è¡¨ç¤ºææå¯¦é«ï¼å¾èçªé¡¯å¶å¨å»£æ³çææç§å­¸é åä¸­çå»£æ³é©ç¨æ§ã

##### **Coarse-to-Fine Highlighting: Reducing Knowledge Hallucination in Large Language Models**
2410.15116v1 by Qitan Lv, Jie Wang, Hanzhu Chen, Bin Li, Yongdong Zhang, Feng Wu

Generation of plausible but incorrect factual information, often termed
hallucination, has attracted significant research interest. Retrieval-augmented
language model (RALM) -- which enhances models with up-to-date knowledge --
emerges as a promising method to reduce hallucination. However, existing RALMs
may instead exacerbate hallucination when retrieving lengthy contexts. To
address this challenge, we propose COFT, a novel
\textbf{CO}arse-to-\textbf{F}ine highligh\textbf{T}ing method to focus on
different granularity-level key texts, thereby avoiding getting lost in lengthy
contexts. Specifically, COFT consists of three components: \textit{recaller},
\textit{scorer}, and \textit{selector}. First, \textit{recaller} applies a
knowledge graph to extract potential key entities in a given context. Second,
\textit{scorer} measures the importance of each entity by calculating its
contextual weight. Finally, \textit{selector} selects high contextual weight
entities with a dynamic threshold algorithm and highlights the corresponding
paragraphs, sentences, or words in a coarse-to-fine manner. Extensive
experiments on the knowledge hallucination benchmark demonstrate the
effectiveness of COFT, leading to a superior performance over $30\%$ in the F1
score metric. Moreover, COFT also exhibits remarkable versatility across
various long-form tasks, such as reading comprehension and question answering.

æè¦ï¼çæçä¼¼åçä½å®éä¸ä¸æ­£ç¡®çå®éä¿¡æ¯ï¼éå¸¸ç§°ä¸ºå¹»è§ï¼å¼èµ·äºéè¦çç ç©¶å´è¶£ãæ£ç´¢å¢å¼ºè¯­è¨æ¨¡å (RALM) éè¿ä¸ºæ¨¡åæä¾ææ°çç¥è¯æ¥å¢å¼ºæ¨¡åï¼è¿æ¯ä¸ç§æåéçæ¹æ³ï¼å¯ä»¥åå°å¹»è§ãç¶èï¼ç°æç RALM å¨æ£ç´¢åé¿çä¸ä¸ææ¶å¯è½ä¼å å§å¹»è§ãä¸ºäºåºå¯¹è¿ä¸ææï¼æä»¬æåºäº COFTï¼ä¸ç§æ°é¢ç\textbf{ç²}å°\textbf{ç»}é«äº®\textbf{T}ing æ¹æ³ï¼ä¸æ³¨äºä¸åç²åº¦çº§å«çå³é®ææ¬ï¼ä»èé¿åå¨åé¿çä¸ä¸æä¸­è¿·å¤±ãå·ä½æ¥è¯´ï¼COFT ç±ä¸ä¸ªç»ä»¶ç»æï¼\textit{recaller}ã\textit{scorer} å \textit{selector}ãé¦åï¼\textit{recaller} åºç¨ç¥è¯å¾è°±æ¥æåç»å®ä¸ä¸æä¸­æ½å¨çå³é®å®ä½ãå¶æ¬¡ï¼\textit{scorer} éè¿è®¡ç®æ¯ä¸ªå®ä½çä¸ä¸ææéæ¥è¡¡éå¶éè¦æ§ãæåï¼\textit{selector} ä½¿ç¨å¨æéå¼ç®æ³éæ©å·æé«ä¸ä¸ææéçå®ä½ï¼å¹¶ä»¥ç²å°ç»çæ¹å¼çªåºæ¾ç¤ºç¸åºçæ®µè½ãå¥å­æåè¯ãå¨ç¥è¯å¹»è§åºåä¸çå¹¿æ³å®éªè¯æäº COFT çæææ§ï¼å¨ F1 åæ°ææ ä¸åå¾äºè¶è¿ 30% çåè¶æ§è½ãæ­¤å¤ï¼COFT å¨åç§é¿ç¯ä»»å¡ä¸­ä¹è¡¨ç°åºåè¶çå¤åè½æ§ï¼ä¾å¦éè¯»çè§£åé®é¢è§£ç­ã

##### **A Prompt Engineering Approach and a Knowledge Graph based Framework for Tackling Legal Implications of Large Language Model Answers**
2410.15064v1 by George Hannah, Rita T. Sousa, Ioannis Dasoulas, Claudia d'Amato

With the recent surge in popularity of Large Language Models (LLMs), there is
the rising risk of users blindly trusting the information in the response, even
in cases where the LLM recommends actions that have potential legal
implications and this may put the user in danger. We provide an empirical
analysis on multiple existing LLMs showing the urgency of the problem. Hence,
we propose a short-term solution consisting in an approach for isolating these
legal issues through prompt re-engineering. We further analyse the outcomes but
also the limitations of the prompt engineering based approach and we highlight
the need of additional resources for fully solving the problem We also propose
a framework powered by a legal knowledge graph (KG) to generate legal citations
for these legal issues, enriching the response of the LLM.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡åï¼LLMï¼è¿ææµè¡æ¿å¢ï¼ä½¿ç¨èç²ç®ç¸ä¿¡åæä¸­è³è¨çé¢¨éªä¹é¨ä¹åé«ï¼å³ä½¿å¨ LLM å»ºè­°æ¡åå¯è½ç¢çæ³å¾å½±é¿çè¡åæäº¦ç¶ï¼éå¯è½æä½¿ä½¿ç¨èé·å¥å±éªä¹ä¸­ãæåéå°å¤åç¾æ LLM æä¾å¯¦è­åæï¼é¡¯ç¤ºæ­¤åé¡çæ¥è¿«æ§ãå æ­¤ï¼æåæåºä¸åç­æè§£æ±ºæ¹æ¡ï¼åæ¬ééæç¤ºéæ°è¨­è¨ä¾å­¤ç«éäºæ³å¾åé¡çæ¹æ³ãæåé²ä¸æ­¥åææç¤ºå·¥ç¨æ¹æ³çææï¼ä½ä¹åæå¶éå¶ï¼ä¸¦å¼·èª¿å®å¨è§£æ±ºåé¡éè¦é¡å¤è³æºãæåéæåºä¸åç±æ³å¾ç¥è­åè­ï¼KGï¼é©åçæ¶æ§ï¼çºéäºæ³å¾åé¡ç¢çæ³å¾å¼æï¼è±å¯ LLM çåæã

##### **LangGFM: A Large Language Model Alone Can be a Powerful Graph Foundation Model**
2410.14961v1 by Tianqianjin Lin, Pengwei Yan, Kaisong Song, Zhuoren Jiang, Yangyang Kang, Jun Lin, Weikang Yuan, Junjie Cao, Changlong Sun, Xiaozhong Liu

Graph foundation models (GFMs) have recently gained significant attention.
However, the unique data processing and evaluation setups employed by different
studies hinder a deeper understanding of their progress. Additionally, current
research tends to focus on specific subsets of graph learning tasks, such as
structural tasks, node-level tasks, or classification tasks. As a result, they
often incorporate specialized modules tailored to particular task types, losing
their applicability to other graph learning tasks and contradicting the
original intent of foundation models to be universal. Therefore, to enhance
consistency, coverage, and diversity across domains, tasks, and research
interests within the graph learning community in the evaluation of GFMs, we
propose GFMBench-a systematic and comprehensive benchmark comprising 26
datasets. Moreover, we introduce LangGFM, a novel GFM that relies entirely on
large language models. By revisiting and exploring the effective graph
textualization principles, as well as repurposing successful techniques from
graph augmentation and graph self-supervised learning within the language
space, LangGFM achieves performance on par with or exceeding the state of the
art across GFMBench, which can offer us new perspectives, experiences, and
baselines to drive forward the evolution of GFMs.

æè¦ï¼åå½¢åºç¤æ¨¡å (GFM) è¿æç²å¾é¡¯èçéæ³¨ã
ç¶èï¼ä¸åç ç©¶æ¡ç¨ç¨ç¹è³æèçåè©ä¼°è¨­å®ï¼é»ç¤äºå°å¶é²å±çæ·±å¥çè§£ãæ­¤å¤ï¼ç®åçç ç©¶å¾åæ¼å°æ³¨æ¼åå½¢å­¸ç¿ä»»åçç¹å®å­éï¼ä¾å¦çµæ§ä»»åãç¯é»å±¤ç´ä»»åæåé¡ä»»åãå æ­¤ï¼å®åç¶å¸¸æ´åå°ééå°ç¹å®ä»»åé¡åéèº«æé çæ¨¡çµï¼å¤±å»å¶å°å¶ä»åå½¢å­¸ç¿ä»»åçé©ç¨æ§ï¼ä¸¦èåºç¤æ¨¡åæçºéç¨çåå§æåç¸çç¾ãå æ­¤ï¼çºäºå¢å¼·åå½¢å­¸ç¿ç¤¾ç¾¤å¨è©ä¼° GFM æè·¨é åãä»»ååç ç©¶èè¶£çä¸è´æ§ãæ¶µèç¯ååå¤æ¨£æ§ï¼æåæåº GFMBenchï¼éæ¯ä¸ååå« 26 åè³æéçç³»çµ±åä¸å¨é¢çåºæºãæ­¤å¤ï¼æåä»ç´¹ LangGFMï¼éæ¯ä¸ç¨®å®å¨ä¾è³´å¤§åèªè¨æ¨¡åçæ°ç© GFMãéééæ°æª¢è¦åæ¢ç´¢ææçåå½¢æå­åååï¼ä»¥åå¨èªè¨ç©ºéä¸­éæ°å©ç¨åå½¢æ´åååå½¢èªç£ç£å­¸ç¿çæåæè¡ï¼LangGFM å¨ GFMBench ä¸å¯¦ç¾èç¾ææè¡åç­æè¶è¶ç¾ææè¡çæè½ï¼éå¯ä»¥çºæåæä¾æ°çè§é»ãç¶é©ååºæºï¼ä»¥æ¨å GFM çæ¼é²ã

##### **TransBox: EL++-closed Ontology Embedding**
2410.14571v1 by Hui Yang, Jiaoyan Chen, Uli Sattler

OWL (Web Ontology Language) ontologies, which are able to represent both
relational and type facts as standard knowledge graphs and complex domain
knowledge in Description Logic (DL) axioms, are widely adopted in domains such
as healthcare and bioinformatics. Inspired by the success of knowledge graph
embeddings, embedding OWL ontologies has gained significant attention in recent
years. Current methods primarily focus on learning embeddings for atomic
concepts and roles, enabling the evaluation based on normalized axioms through
specially designed score functions. However, they often neglect the embedding
of complex concepts, making it difficult to infer with more intricate axioms.
This limitation reduces their effectiveness in advanced reasoning tasks, such
as Ontology Learning and ontology-mediated Query Answering. In this paper, we
propose EL++-closed ontology embeddings which are able to represent any logical
expressions in DL via composition. Furthermore, we develop TransBox, an
effective EL++-closed ontology embedding method that can handle many-to-one,
one-to-many and many-to-many relations. Our extensive experiments demonstrate
that TransBox often achieves state-of-the-art performance across various
real-world datasets for predicting complex axioms.

æè¦ï¼OWLï¼Web Ontology Languageï¼æ¬ä½ï¼è½å¤å°å³ç³»åç±»åäºå®è¡¨ç¤ºä¸ºæ åç¥è¯å¾åæè¿°é»è¾ (DL) å¬çä¸­çå¤æé¢åç¥è¯ï¼å¨å»çä¿å¥åçç©ä¿¡æ¯å­¦ç­é¢åå¾å°å¹¿æ³éç¨ãåç¥è¯å¾åµå¥çæåå¯åï¼åµå¥ OWL æ¬ä½è¿å¹´æ¥å¤åå³æ³¨ãå½åæ¹æ³ä¸»è¦éä¸­å¨å­¦ä¹ åå­æ¦å¿µåè§è²çåµå¥ï¼éè¿ä¸é¨è®¾è®¡çè¯åå½æ°ï¼æ¯æåºäºå½ä¸åå¬ççè¯ä¼°ãç¶èï¼å®ä»¬ç»å¸¸å¿½ç¥å¤ææ¦å¿µçåµå¥ï¼è¿ä½¿å¾é¾ä»¥æ¨æ­åºæ´å¤æçå¬çãè¿ç§éå¶éä½äºå®ä»¬å¨é«çº§æ¨çä»»å¡ï¼ä¾å¦æ¬ä½å­¦ä¹ åæ¬ä½ä»å¯¼æ¥è¯¢åºç­ï¼ä¸­çæææ§ãå¨æ¬æä¸­ï¼æä»¬æåºäº EL++ å°é­æ¬ä½åµå¥ï¼å®è½å¤éè¿ç»åæ¥è¡¨ç¤º DL ä¸­çä»»ä½é»è¾è¡¨è¾¾å¼ãæ­¤å¤ï¼æä»¬å¼åäº TransBoxï¼ä¸ç§ææç EL++ å°é­æ¬ä½åµå¥æ¹æ³ï¼å¯ä»¥å¤çå¤å¯¹ä¸ãä¸å¯¹å¤åå¤å¯¹å¤å³ç³»ãæä»¬å¹¿æ³çå®éªè¡¨æï¼TransBox å¨é¢æµå¤æå¬ççåç§çå®ä¸çæ°æ®éä¸éå¸¸é½è½è¾¾å°æåè¿çæ§è½ã

##### **Enabling Scalable Evaluation of Bias Patterns in Medical LLMs**
2410.14763v1 by Hamed Fayyaz, Raphael Poulain, Rahmatollah Beheshti

Large language models (LLMs) have shown impressive potential in helping with
numerous medical challenges. Deploying LLMs in high-stakes applications such as
medicine, however, brings in many concerns. One major area of concern relates
to biased behaviors of LLMs in medical applications, leading to unfair
treatment of individuals. To pave the way for the responsible and impactful
deployment of Med LLMs, rigorous evaluation is a key prerequisite. Due to the
huge complexity and variability of different medical scenarios, existing work
in this domain has primarily relied on using manually crafted datasets for bias
evaluation. In this study, we present a new method to scale up such bias
evaluations by automatically generating test cases based on rigorous medical
evidence. We specifically target the challenges of a) domain-specificity of
bias characterization, b) hallucinating while generating the test cases, and c)
various dependencies between the health outcomes and sensitive attributes. To
that end, we offer new methods to address these challenges integrated with our
generative pipeline, using medical knowledge graphs, medical ontologies, and
customized general LLM evaluation frameworks in our method. Through a series of
extensive experiments, we show that the test cases generated by our proposed
method can effectively reveal bias patterns in Med LLMs at larger and more
flexible scales than human-crafted datasets. We publish a large bias evaluation
dataset using our pipeline, which is dedicated to a few medical case studies. A
live demo of our application for vignette generation is available at
https://vignette.streamlit.app. Our code is also available at
https://github.com/healthylaife/autofair.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºå¨åå©è§£æ±º
è¨±å¤é«çææ°æ¹é¢çé©äººæ½åãç¶èï¼å¨é«é¢¨éªæç¨ç¨å¼ï¼ä¾å¦
é«çï¼ä¸­é¨ç½² LLM æå¸¶ä¾è¨±å¤çæ®ãä¸åä¸»è¦ççæ®é åè
é«çæç¨ç¨å¼ä¸­ LLM çåè¦è¡çºæéï¼å°è´å°åäººä¸å¬å¹³ç
å¾éãçºäºçºè² è²¬ä»»ä¸æå½±é¿åç Med LLM é¨ç½²éªè·¯ï¼å´è¬¹ç
è©ä¼°æ¯ä¸é ééµåæãç±æ¼ä¸åé«çå ´æ¯çè¤éæ§åè®ç°æ§æ¥µå¤§ï¼
æ­¤é åç¾æçå·¥ä½ä¸»è¦ä¾è³´ä½¿ç¨äººå·¥è£½ä½çè³æéé²è¡åè¦
è©ä¼°ãå¨æ¬ç ç©¶ä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼å¯ä»¥æ ¹æå´è¬¹çé«ç
è­æèªåç¢çæ¸¬è©¦æ¡ä¾ï¼ä»¥æ´å¤§æ­¤é¡åè¦è©ä¼°ãæåç¹å¥éå°
a) åè¦ç¹å¾µçé åå°å±¬æ§ãb) å¨ç¢çæ¸¬è©¦æ¡ä¾æåºç¾å¹»è¦ºï¼ä»¥å c)
å¥åº·çµæåææå±¬æ§ä¹éçåç¨®ä¾è³´æ§ç­ææ°ãçºæ­¤ï¼æåæä¾
æ°çæ¹æ³ä¾è§£æ±ºéäºææ°ï¼ä¸¦å°å¶èæåççæç®¡éæ´åï¼å¨æåç
æ¹æ³ä¸­ä½¿ç¨é«çç¥è­åãé«çæ¬ä½åèªè¨çéç¨ LLM è©ä¼°æ¶æ§ãéé
ä¸ç³»åå»£æ³çå¯¦é©ï¼æåè¡¨ææåæåºçæ¹æ³ç¢ççæ¸¬è©¦æ¡ä¾å¯ä»¥ææ
æ­ç¤º Med LLM ä¸­çåè¦æ¨¡å¼ï¼å¶è¦æ¨¡æ¯äººå·¥è£½ä½çè³æéæ´å¤§ä¸æ´å·
å½æ§ãæåä½¿ç¨æåçç®¡éç¼å¸äºä¸åå¤§ååè¦è©ä¼°è³æéï¼è©²è³æé
å°ééå°ä¸äºé«çæ¡ä¾ç ç©¶ãæåçå°æåçææç¨ç¨å¼çç¾å ´ç¤ºç¯
å¯å¨ https://vignette.streamlit.app åå¾ãæåçç¨å¼ç¢¼ä¹å¯å¨
https://github.com/healthylaife/autofair åå¾ã

##### **Paths-over-Graph: Knowledge Graph Empowered Large Language Model Reasoning**
2410.14211v2 by Xingyu Tan, Xiaoyang Wang, Qing Liu, Xiwei Xu, Xin Yuan, Wenjie Zhang

Large Language Models (LLMs) have achieved impressive results in various
tasks but struggle with hallucination problems and lack of relevant knowledge,
especially in deep complex reasoning and knowledge-intensive tasks. Knowledge
Graphs (KGs), which capture vast amounts of facts in a structured format, offer
a reliable source of knowledge for reasoning. However, existing KG-based LLM
reasoning methods face challenges like handling multi-hop reasoning,
multi-entity questions, and effectively utilizing graph structures. To address
these issues, we propose Paths-over-Graph (PoG), a novel method that enhances
LLM reasoning by integrating knowledge reasoning paths from KGs, improving the
interpretability and faithfulness of LLM outputs. PoG tackles multi-hop and
multi-entity questions through a three-phase dynamic multi-hop path
exploration, which combines the inherent knowledge of LLMs with factual
knowledge from KGs. In order to improve the efficiency, PoG prunes irrelevant
information from the graph exploration first and introduces efficient
three-step pruning techniques that incorporate graph structures, LLM prompting,
and a pre-trained language model (e.g., SBERT) to effectively narrow down the
explored candidate paths. This ensures all reasoning paths contain highly
relevant information captured from KGs, making the reasoning faithful and
interpretable in problem-solving. PoG innovatively utilizes graph structure to
prune the irrelevant noise and represents the first method to implement
multi-entity deep path detection on KGs for LLM reasoning tasks. Comprehensive
experiments on five benchmark KGQA datasets demonstrate PoG outperforms the
state-of-the-art method ToG across GPT-3.5-Turbo and GPT-4, achieving an
average accuracy improvement of 18.9%. Notably, PoG with GPT-3.5-Turbo
surpasses ToG with GPT-4 by up to 23.9%.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®ä»»åä¸­åå¾ä»¤äººå°è±¡æ·±å»çææï¼ä½ä»å­å¨å¹»è¦ºåé¡åç¼ºä¹ç¸éç¥è­ï¼å°¤å¶æ¯å¨æ·±åº¦è¤éæ¨çåç¥è­å¯éåä»»åä¸­ãç¥è­åè­ (KG) ä»¥çµæ§åæ ¼å¼æ·åå¤§éäºå¯¦ï¼çºæ¨çæä¾äºå¯é çç¥è­ä¾æºãç¶èï¼ç¾æçåºæ¼ KG ç LLM æ¨çæ¹æ³é¢è¨èçå¤è·³æ¨çãå¤å¯¦é«åé¡åææå©ç¨åçµæ§ç­ææ°ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºåä¸è·¯å¾ (PoG)ï¼éæ¯ä¸ç¨®åµæ°çæ¹æ³ï¼ééæ´åä¾èª KG çç¥è­æ¨çè·¯å¾ä¾å¢å¼· LLM æ¨çï¼æé« LLM è¼¸åºçå¯è§£éæ§åä¿çæ§ãPoG ééä¸éæ®µåæå¤è·³è·¯å¾æ¢ç´¢ä¾è§£æ±ºå¤è·³åå¤å¯¦é«åé¡ï¼å° LLM çåºæç¥è­èä¾èª KG çäºå¯¦ç¥è­ç¸çµåãçºäºæé«æçï¼PoG é¦åå¾åæ¢ç´¢ä¸­åªé¤ç¡éä¿¡æ¯ï¼ä¸¦å¼å¥äºä¸æ­¥åªææè¡ï¼éäºæè¡çµåäºåçµæ§ãLLM æç¤ºåé è¨ç·´èªè¨æ¨¡åï¼ä¾å¦ï¼SBERTï¼ä¾ææç¸®å°æ¢ç´¢çåé¸è·¯å¾ãéç¢ºä¿äºæææ¨çè·¯å¾é½åå«å¾ KG æ·åçé«åº¦ç¸éä¿¡æ¯ï¼å¾èä½¿æ¨çå¨åé¡è§£æ±ºä¸­å·æä¿çæ§åå¯è§£éæ§ãPoG åµæ°å°å©ç¨åçµæ§ä¾åªé¤ç¡éåªè²ï¼ä¸¦ä»£è¡¨äºå¨ KG ä¸å¯¦ç¾ LLM æ¨çä»»åçå¤å¯¦é«æ·±åº¦è·¯å¾æª¢æ¸¬çç¬¬ä¸ç¨®æ¹æ³ãå¨äºååºæº KGQA æ¸æéä¸çç¶åå¯¦é©è¡¨æï¼PoG å¨ GPT-3.5-Turbo å GPT-4 ä¸çè¡¨ç¾åªæ¼æåé²çæ¹æ³ ToGï¼å¹³åæºç¢ºçæé«äº 18.9%ãå¼å¾æ³¨æçæ¯ï¼ä½¿ç¨ GPT-3.5-Turbo ç PoG æ¯ä½¿ç¨ GPT-4 ç ToG é«åº 23.9%ã

##### **UniMTS: Unified Pre-training for Motion Time Series**
2410.19818v1 by Xiyuan Zhang, Diyan Teng, Ranak Roy Chowdhury, Shuheng Li, Dezhi Hong, Rajesh K. Gupta, Jingbo Shang

Motion time series collected from mobile and wearable devices such as
smartphones and smartwatches offer significant insights into human behavioral
patterns, with wide applications in healthcare, automation, IoT, and AR/XR due
to their low-power, always-on nature. However, given security and privacy
concerns, building large-scale motion time series datasets remains difficult,
preventing the development of pre-trained models for human activity analysis.
Typically, existing models are trained and tested on the same dataset, leading
to poor generalizability across variations in device location, device mounting
orientation and human activity type. In this paper, we introduce UniMTS, the
first unified pre-training procedure for motion time series that generalizes
across diverse device latent factors and activities. Specifically, we employ a
contrastive learning framework that aligns motion time series with text
descriptions enriched by large language models. This helps the model learn the
semantics of time series to generalize across activities. Given the absence of
large-scale motion time series data, we derive and synthesize time series from
existing motion skeleton data with all-joint coverage. Spatio-temporal graph
networks are utilized to capture the relationships across joints for
generalization across different device locations. We further design
rotation-invariant augmentation to make the model agnostic to changes in device
mounting orientations. Our model shows exceptional generalizability across 18
motion time series classification benchmark datasets, outperforming the best
baselines by 340% in the zero-shot setting, 16.3% in the few-shot setting, and
9.2% in the full-shot setting.

æè¦ï¼å¾æºæ§åææ©èæºæ§åæé¶ç­è¡åè£ç½®åç©¿æ´å¼è£ç½®æ¶éçåä½æéåºåï¼ç±æ¼å¶ä½èé»ãæçºéä½çç¹æ§ï¼å¯æä¾äººé¡è¡çºæ¨¡å¼çéè¦è¦è§£ï¼å¨é«çä¿å¥ãèªååãç©è¯ç¶²å AR/XR ä¸­æå»£æ³çæç¨ãç¶èï¼èéå°å®å¨æ§åé±ç§åé¡ï¼å»ºæ§å¤§è¦æ¨¡çåä½æéåºåè³æéä»ç¶å°é£ï¼é»ç¤äºäººé¡æ´»ååæé åè¨ç·´æ¨¡åçç¼å±ãä¸è¬ä¾èªªï¼ç¾æçæ¨¡åæå¨åä¸åè³æéä¸è¨ç·´åæ¸¬è©¦ï¼å°è´ç¡æ³å°è£ç½®ä½ç½®ãè£ç½®å®è£æ¹ååäººé¡æ´»åé¡åçè®åé²è¡è¯å¥½çæ¦åãå¨æ¬æä¸­ï¼æåä»ç´¹ UniMTSï¼éæ¯ç¬¬ä¸åçµ±ä¸çåä½æéåºåé è¨ç·´ç¨åºï¼å¯æ¦åå°ä¸åçè£ç½®æ½å¨å å­åæ´»åãå·é«ä¾èªªï¼æåæ¡ç¨å°æ¯å­¸ç¿æ¶æ§ï¼å°åä½æéåºåèå¤§åèªè¨æ¨¡åè±å¯çæå­æè¿°å°é½ãéæå©æ¼æ¨¡åå­¸ç¿æéåºåçèªç¾©ï¼ä»¥æ¦åå°åç¨®æ´»åãç±æ¼ç¼ºä¹å¤§è¦æ¨¡çåä½æéåºåè³æï¼æåå¾ç¾æçåä½éª¨æ¶è³æä¸­è¡çååææéåºåï¼ä¸¦æ¶µèææéç¯ãæç©ºåå½¢ç¶²è·¯ç¨æ¼æ·åéç¯ä¹éçéä¿ï¼ä»¥æ¦åå°ä¸åçè£ç½®ä½ç½®ãæåé²ä¸æ­¥è¨­è¨äºæè½ä¸è®å¢å¼·ï¼è®æ¨¡åä¸æåè£ç½®å®è£æ¹åè®åçå½±é¿ãæåçæ¨¡åå¨ 18 ååä½æéåºååé¡åºæºè³æéä¸å±ç¾åºåè¶çæ¦åè½åï¼å¨é¶æ¬¡å­¸ç¿è¨­å®ä¸­åªæ¼æä½³åºæº 340%ï¼å¨å°æ¬¡å­¸ç¿è¨­å®ä¸­åªæ¼æä½³åºæº 16.3%ï¼å¨å¨æ¬¡å­¸ç¿è¨­å®ä¸­åªæ¼æä½³åºæº 9.2%ã

##### **Supervised Chain of Thought**
2410.14198v1 by Xiang Zhang, Dujian Ding

Large Language Models (LLMs) have revolutionized natural language processing
and hold immense potential for advancing Artificial Intelligence. However, the
core architecture of most mainstream LLMs -- the Transformer -- has inherent
limitations in computational depth, rendering them theoretically incapable of
solving many reasoning tasks that demand increasingly deep computations. Chain
of Thought (CoT) prompting has emerged as a technique to address these
architectural limitations, as evidenced by several theoretical studies. It
offers a promising approach to solving complex reasoning tasks that were
previously beyond the capabilities of these models. Despite its successes, CoT
and its variants (such as Tree of Thought, Graph of Thought, etc.) rely on a
"one-prompt-for-all" approach, using a single prompt structure (e.g., "think
step by step") for a wide range of tasks -- from counting and sorting to
solving mathematical and algorithmic problems. This approach poses significant
challenges for models to generate the correct reasoning steps, as the model
must navigate through a vast prompt template space to find the appropriate
template for each task. In this work, we build upon previous theoretical
analyses of CoT to demonstrate how the one-prompt-for-all approach can
negatively affect the computability of LLMs. We partition the solution search
space into two: the prompt space and the answer space. Our findings show that
task-specific supervision is essential for navigating the prompt space
accurately and achieving optimal performance. Through experiments with
state-of-the-art LLMs, we reveal a gap in reasoning performance when
supervision is applied versus when it is not.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¾¹åºæ¹è®äºèªç¶èªè¨èçï¼ä¸¦å·åä¿é²äººå·¥æºæ§ç¼å±çå·¨å¤§æ½åãç¶èï¼å¤§å¤æ¸ä¸»æµ LLM çæ ¸å¿æ¶æ§ï¼Transformerï¼å¨è¨ç®æ·±åº¦æ¹é¢æå¶å§å¨éå¶ï¼çè«ä¸ç¡æ³è§£æ±ºè¨±å¤éè¦è¶ä¾è¶æ·±å¥è¨ç®çæ¨çä»»åãæç¶­é (CoT) æç¤ºå·²æçºè§£æ±ºéäºæ¶æ§éå¶çä¸ç¨®æè¡ï¼éå·²ç±å¹¾é çè«ç ç©¶è­å¯¦ãå®æä¾äºä¸åæåéçæ¹æ³ä¾è§£æ±ºè¤éçæ¨çä»»åï¼éäºä»»åä»¥åè¶åºäºéäºæ¨¡åçè½åãåç®¡åå¾äºæåï¼CoT åå¶è®é«ï¼ä¾å¦æç¶­æ¨¹ãæç¶­åç­ï¼ä¾è³´æ¼ãä¸æç¤ºé©ç¨ææãçæ¹æ³ï¼å°åç¨®ä»»åï¼å¾è¨æ¸åæåºå°è§£æ±ºæ¸å­¸åæ¼ç®æ³åé¡ï¼ä½¿ç¨å®ä¸çæç¤ºçµæ§ï¼ä¾å¦ï¼ãéæ­¥æèãï¼ãéç¨®æ¹æ³å°æ¨¡åç¢çæ­£ç¢ºçæ¨çæ­¥é©æ§æäºéå¤§ææ°ï¼å çºæ¨¡åå¿é å¨å»£æ³çæç¤ºç¯æ¬ç©ºéä¸­å°èªï¼æè½çºæ¯åä»»åæ¾å°é©ç¶çç¯æ¬ãå¨éé å·¥ä½ä¸­ï¼æåå»ºç«å¨ CoT ååççè«åæä¹ä¸ï¼èªªæãä¸æç¤ºé©ç¨ææãçæ¹æ³å¦ä½å° LLM çå¯è¨ç®æ§ç¢çè² é¢å½±é¿ãæåå°è§£çæå°ç©ºéåçºå©é¨åï¼æç¤ºç©ºéåç­æ¡ç©ºéãæåçç ç©¶çµæè¡¨æï¼ç¹å®æ¼ä»»åçç£ç£å°æ¼æºç¢ºå°èªæç¤ºç©ºéä¸¦å¯¦ç¾æä½³æè½è³ééè¦ãééä½¿ç¨æåé²ç LLM é²è¡å¯¦é©ï¼æåæ­ç¤ºäºå¨æç¨ç£ç£èæªæç¨ç£ç£ææ¨çæè½çå·®è·ã

##### **Towards Cross-Cultural Machine Translation with Retrieval-Augmented Generation from Multilingual Knowledge Graphs**
2410.14057v1 by Simone Conia, Daniel Lee, Min Li, Umar Farooq Minhas, Saloni Potdar, Yunyao Li

Translating text that contains entity names is a challenging task, as
cultural-related references can vary significantly across languages. These
variations may also be caused by transcreation, an adaptation process that
entails more than transliteration and word-for-word translation. In this paper,
we address the problem of cross-cultural translation on two fronts: (i) we
introduce XC-Translate, the first large-scale, manually-created benchmark for
machine translation that focuses on text that contains potentially
culturally-nuanced entity names, and (ii) we propose KG-MT, a novel end-to-end
method to integrate information from a multilingual knowledge graph into a
neural machine translation model by leveraging a dense retrieval mechanism. Our
experiments and analyses show that current machine translation systems and
large language models still struggle to translate texts containing entity
names, whereas KG-MT outperforms state-of-the-art approaches by a large margin,
obtaining a 129% and 62% relative improvement compared to NLLB-200 and GPT-4,
respectively.

æè¦ï¼ç¿»è­¯åå«å¯¦é«åç¨±çæå­æ¯ä¸é å·æææ°æ§çä»»åï¼å çºèæåç¸éçåèå¨ä¸åèªè¨ä¸­å¯è½ææå¾å¤§å·®ç°ãéäºå·®ç°ä¹å¯è½æ¯ç±è½è­¯é æçï¼è½è­¯æ¯ä¸ç¨®æ¹ç·¨éç¨ï¼ä¸åæ¶åé³è­¯åéå­ç¿»è­¯ãå¨æ¬æä¸­ï¼æåå¾å©åæ¹é¢è§£æ±ºè·¨æåç¿»è­¯çåé¡ï¼(i) æåä»ç´¹ XC-Translateï¼éæ¯ç¬¬ä¸åéå°åå«æ½å¨æåç´°å¾®å·®å¥å¯¦é«åç¨±çæå­çå¤§è¦æ¨¡ãäººå·¥å»ºç«çæ©å¨ç¿»è­¯åºæºæ¸¬è©¦ï¼ä»¥å (ii) æåæåº KG-MTï¼éæ¯ä¸ç¨®æ°çç«¯å°ç«¯æ¹æ³ï¼ééå©ç¨å¯éæª¢ç´¢æ©å¶å°ä¾èªå¤èªè¨ç¥è­åè­çè³è¨æ´åå°ç¥ç¶æ©å¨ç¿»è­¯æ¨¡åä¸­ãæåçå¯¦é©ååæè¡¨æï¼ç®åçæ©å¨ç¿»è­¯ç³»çµ±åå¤§åèªè¨æ¨¡åå¨ç¿»è­¯åå«å¯¦é«åç¨±çæå­æä»å­å¨å°é£ï¼è KG-MT åä»¥å¤§å¹åªæ¼æåé²æ¹æ³çåªå¢ååºï¼è NLLB-200 å GPT-4 ç¸æ¯ï¼åå¥ç²å¾äº 129% å 62% çç¸å°æ¹é²ã

##### **RiTeK: A Dataset for Large Language Models Complex Reasoning over Textual Knowledge Graphs**
2410.13987v1 by Jiatan Huang, Mingchen Li, Zonghai Yao, Zhichao Yang, Yongkang Xiao, Feiyun Ouyang, Xiaohan Li, Shuo Han, Hong Yu

Answering complex real-world questions often requires accurate retrieval from
textual knowledge graphs (TKGs). The scarcity of annotated data, along with
intricate topological structures, makes this task particularly challenging. As
the nature of relational path information could enhance the inference ability
of Large Language Models (LLMs), efficiently retrieving more complex relational
path information from TKGs presents another key challenge. To tackle these
challenges, we first develop a Dataset for LLMs Complex Reasoning over Textual
Knowledge Graphs (RiTeK) with a broad topological structure coverage.We
synthesize realistic user queries that integrate diverse topological
structures, relational information, and complex textual descriptions. We
conduct rigorous expert evaluation to validate the quality of our synthesized
queries. And then, we introduce an enhanced Monte Carlo Tree Search (MCTS)
method, Relational MCTS, to automatically extract relational path information
from textual graphs for specific queries. Our dataset mainly covers the medical
domain as the relation types and entity are complex and publicly available.
Experimental results indicate that RiTeK poses significant challenges for
current retrieval and LLM systems, while the proposed Relational MCTS method
enhances LLM inference ability and achieves state-of-the-art performance on
RiTeK.

æè¦ï¼åç­è¤éçç¾å¯¦ä¸çåé¡éå¸¸éè¦å¾ææ¬ç¥è­å (TKG) ä¸­æºç¢ºæ·åãæ¨è¨»è³æçç¨å°ï¼å ä¸è¤éçææ²çµæ§ï¼ä½¿å¾éé ä»»åç¹å¥å·æææ°æ§ãç±æ¼éä¿è·¯å¾è³è¨çæ§è³ªå¯ä»¥å¢å¼·å¤§åèªè¨æ¨¡å (LLM) çæ¨è«è½åï¼å¾ TKG ææå°æ·åæ´è¤éçéä¿è·¯å¾è³è¨æåºäºå¦ä¸åééµææ°ãçºäºæå°éäºææ°ï¼æåé¦åéç¼äºä¸åå·æå»£æ³ææ²çµæ§æ¶µèç¯åçææ¬ç¥è­å (RiTeK) ä¸ç LLM è¤éæ¨çè³æéãæåç¶åäºæ´åäºå¤æ¨£åææ²çµæ§ãéä¿è³è¨åè¤éææ¬æè¿°çç¾å¯¦ä½¿ç¨èæ¥è©¢ãæåé²è¡å´æ ¼çå°å®¶è©ä¼°ï¼ä»¥é©è­æåç¶åæ¥è©¢çåè³ªãç¶å¾ï¼æåå¼å¥ä¸ç¨®å¢å¼·çèå°å¡ç¾æ¨¹æå° (MCTS) æ¹æ³ï¼å³éä¿ MCTSï¼ä»¥èªåå¾ææ¬åä¸­æ·åç¹å®æ¥è©¢çéä¿è·¯å¾è³è¨ãæåçè³æéä¸»è¦æ¶µèé«çé åï¼å çºéä¿é¡ååå¯¦é«å¾è¤éä¸å¬éå¯ç¨ãå¯¦é©çµæè¡¨æï¼RiTeK å°ç®åçæ·åå LLM ç³»çµ±æåºäºéå¤§ææ°ï¼èææåºçéä¿ MCTS æ¹æ³å¢å¼·äº LLM æ¨è«è½åï¼ä¸¦å¨ RiTeK ä¸éå°äºæåé²çæè½ã

##### **The Mystery of the Pathological Path-star Task for Language Models**
2410.13779v1 by Arvid Frydenlund

The recently introduced path-star task is a minimal task designed to
exemplify limitations to the abilities of language models (Bachmann and
Nagarajan, 2024). It involves a path-star graph where multiple arms radiate
from a single starting node and each node is unique. Given the start node and a
specified target node that ends an arm, the task is to generate the arm
containing that target node. This is straightforward for a human but
surprisingly difficult for language models, which did not outperform the random
baseline. The authors hypothesized this is due to a deficiency in
teacher-forcing and the next-token prediction paradigm.
  We demonstrate the task is learnable using teacher-forcing in alternative
settings and that the issue is partially due to representation. We introduce a
regularization method using structured samples of the same graph but with
differing target nodes, improving results across a variety of model types. We
provide RASP proofs showing the task is theoretically solvable. Finally, we
find settings where an encoder-only model can consistently solve the task.

æè¦ï¼æè¿æ¨åºçè·¯å¾æå½¢ä»»åæ¯ä¸åæ¥µç°¡ä»»åï¼æ¨å¨èªªæèªè¨æ¨¡åè½åçéå¶ï¼Bachmann å Nagarajanï¼2024 å¹´ï¼ãå®æ¶åä¸åè·¯å¾æå½¢åï¼å¶ä¸­å¤ååæ¯å¾ä¸åèµ·å§ç¯é»è¼»å°åºå»ï¼æ¯åç¯é»é½æ¯å¯ä¸çãçµ¦å®èµ·å§ç¯é»åçµæä¸ååæ¯çæå®ç®æ¨ç¯é»ï¼ä»»åæ¯çæåå«è©²ç®æ¨ç¯é»çåæ¯ãéå°äººé¡ä¾èªªå¾ç°¡å®ï¼ä½å°èªè¨æ¨¡åä¾èªªå»ç°ä¹å°å¸¸å°å°é£ï¼å çºèªè¨æ¨¡åä¸¦æªåªæ¼é¨æ©åºæºç·ãä½èåè¨­éæ¯ç±æ¼æå¸«å¼·å¶åä¸ä¸åç¬¦èé æ¸¬ç¯ä¾çä¸è¶³ã
æåå±ç¤ºäºè©²ä»»åå¯ä»¥ä½¿ç¨æ¿ä»£è¨­ç½®ä¸­çæå¸«å¼·å¶ä¾å­¸ç¿ï¼ä¸¦ä¸åé¡é¨åæ¯ç±æ¼è¡¨ç¤ºãæåå¼å¥äºä¸ç¨®æ­£ååæ¹æ³ï¼ä½¿ç¨åä¸åå½¢ççµæ§åæ¨£æ¬ï¼ä½ç®æ¨ç¯é»ä¸åï¼å¾èæ¹é²äºåç¨®æ¨¡åé¡åççµæãæåæä¾äº RASP è­æï¼è¡¨æè©²ä»»åå¨çè«ä¸æ¯å¯ä»¥è§£æ±ºçãæå¾ï¼æåæ¾å°äºåç·¨ç¢¼å¨æ¨¡åå¯ä»¥æçºè§£æ±ºä»»åçè¨­ç½®ã

##### **Knowledge-Aware Query Expansion with Large Language Models for Textual and Relational Retrieval**
2410.13765v1 by Yu Xia, Junda Wu, Sungchul Kim, Tong Yu, Ryan A. Rossi, Haoliang Wang, Julian McAuley

Large language models (LLMs) have been used to generate query expansions
augmenting original queries for improving information search. Recent studies
also explore providing LLMs with initial retrieval results to generate query
expansions more grounded to document corpus. However, these methods mostly
focus on enhancing textual similarities between search queries and target
documents, overlooking document relations. For queries like "Find me a highly
rated camera for wildlife photography compatible with my Nikon F-Mount lenses",
existing methods may generate expansions that are semantically similar but
structurally unrelated to user intents. To handle such semi-structured queries
with both textual and relational requirements, in this paper we propose a
knowledge-aware query expansion framework, augmenting LLMs with structured
document relations from knowledge graph (KG). To further address the limitation
of entity-based scoring in existing KG-based methods, we leverage document
texts as rich KG node representations and use document-based relation filtering
for our Knowledge-Aware Retrieval (KAR). Extensive experiments on three
datasets of diverse domains show the advantages of our method compared against
state-of-the-art baselines on textual and relational semi-structured retrieval.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²ç¨æ¼ç¢çæ¥è©¢æ´åï¼èä»¥æ´ååå§æ¥è©¢ï¼ä»¥æ¹åè³è¨æå°ãæè¿çç ç©¶ä¹æ¢è¨æä¾ LLM åå§æª¢ç´¢çµæï¼ä»¥ç¢çæ´è²¼è¿æä»¶èªæåº«çæ¥è©¢æ´åãç¶èï¼éäºæ¹æ³å¤§å¤èéæ¼å å¼·æå°æ¥è©¢èç®æ¨æä»¶ä¹éçæå­ç¸ä¼¼æ§ï¼èå¿½ç¥äºæä»¶éä¿ãå°æ¼ãå¹«ææ¾ä¸å°èæç Nikon F-Mount é¡é ­ç¸å®¹ãè©å¹å¾é«çéçåç©æå½±ç¸æ©ãç­æ¥è©¢ï¼ç¾ææ¹æ³å¯è½æç¢çèªç¾©ä¸ç¸ä¼¼ä½çµæ§ä¸èä½¿ç¨èæåç¡éçæ´åãçºäºèçå·ææå­åéä¿éæ±çæ­¤é¡åçµæ§åæ¥è©¢ï¼æåå¨æ¬æä¸­æåºä¸åç¥è­æç¥æ¥è©¢æ´åæ¶æ§ï¼å©ç¨ç¥è­åè­ (KG) ä¸­ççµæ§åæä»¶éä¿æ´å LLMãçºäºé²ä¸æ­¥è§£æ±ºç¾æåºæ¼ KG çæ¹æ³ä¸­åºæ¼å¯¦é«çè©åéå¶ï¼æåå©ç¨æä»¶æå­ä½çºè±å¯ç KG ç¯é»è¡¨å¾µï¼ä¸¦ä½¿ç¨åºæ¼æä»¶çéä¿ç¯©é¸ï¼é²è¡æåçç¥è­æç¥æª¢ç´¢ (KAR)ãéå°ä¸åä¸åé åè³æéé²è¡çå»£æ³å¯¦é©é¡¯ç¤ºï¼æåçæ¨¡åèæå­åéä¿åçµæ§åæª¢ç´¢çææ°åºæºç¸æ¯ï¼å·æåªå¢ã

##### **LLM-Rank: A Graph Theoretical Approach to Pruning Large Language Models**
2410.13299v1 by David Hoffmann, Kailash Budhathoki, Matthaeus Kleindessner

The evolving capabilities of large language models are accompanied by growing
sizes and deployment costs, necessitating effective inference optimisation
techniques. We propose a novel pruning method utilising centrality measures
from graph theory, reducing both the computational requirements and the memory
footprint of these models. Specifically, we devise a method for creating a
weighted directed acyclical graph representation of multilayer perceptrons to
which we apply a modified version of the weighted PageRank centrality measure
to compute node importance scores. In combination with uniform pruning this
leads to structured sparsity. We call this pruning method MLPRank. Furthermore
we introduce an extension to decoder-only transformer models and call it
LLMRank. For both variants we demonstrate a strong performance. With MLPRank on
average leading to 6.09 % higher accuracy retention than three popular
baselines and 13.42 % with LLMRank compared to two popular baselines.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡ååè½çæ¼é²ï¼æ¨¡åè¦æ¨¡èé¨ç½²ææ¬ä¹é¨ä¹å¢å ï¼å æ­¤éè¦ææçæ¨è«æä½³åæè¡ãæåæåºä¸ååµæ°çä¿®åªæ¹æ³ï¼å©ç¨åè«ä¸­çä¸­å¿æ§æ¸¬éï¼åææ¸å°éäºæ¨¡åçéç®éæ±åè¨æ¶é«ä½¿ç¨éãå·é«ä¾èªªï¼æåè¨­è¨äºä¸ç¨®æ¹æ³ï¼ç¨æ¼å»ºç«å¤å±¤æç¥å¨çå æ¬æåç¡ç°åè¡¨ç¤ºï¼ä¸¦å°å¶å¥ç¨å æ¬ PageRank ä¸­å¿æ§æ¸¬éçä¿®æ¹çæ¬ï¼ä»¥è¨ç®ç¯é»éè¦æ§åæ¸ãçµååå»ä¿®åªï¼éå°å°è´çµæ§åç¨çæ§ãæåç¨±éç¨®ä¿®åªæ¹æ³çº MLPRankãæ­¤å¤ï¼æåéå¼å¥äºåè§£ç¢¼å¨Transformeræ¨¡åçå»¶ä¼¸ï¼ä¸¦ç¨±ä¹çº LLMRankãå°æ¼éå©ç¨®è®é«ï¼æåé½å±ç¤ºäºå¼·å¤§çæè½ãMLPRank å¹³åæ¯ä¸ç¨®æµè¡åºæºé«åº 6.09% çæºç¢ºæ§ä¿ççï¼è LLMRank åæ¯å©ç¨®æµè¡åºæºé«åº 13.42%ã

##### **Trust but Verify: Programmatic VLM Evaluation in the Wild**
2410.13121v1 by Viraj Prabhu, Senthil Purushwalkam, An Yan, Caiming Xiong, Ran Xu

Vision-Language Models (VLMs) often generate plausible but incorrect
responses to visual queries. However, reliably quantifying the effect of such
hallucinations in free-form responses to open-ended queries is challenging as
it requires visually verifying each claim within the response. We propose
Programmatic VLM Evaluation (PROVE), a new benchmarking paradigm for evaluating
VLM responses to open-ended queries. To construct PROVE, we provide a large
language model (LLM) with a high-fidelity scene-graph representation
constructed from a hyper-detailed image caption, and prompt it to generate
diverse question-answer (QA) pairs, as well as programs that can be executed
over the scene graph object to verify each QA pair. We thus construct a
benchmark of 10.5k challenging but visually grounded QA pairs. Next, to
evaluate free-form model responses to queries in PROVE, we propose a
programmatic evaluation strategy that measures both the helpfulness and
truthfulness of a response within a unified scene graph-based framework. We
benchmark the helpfulness-truthfulness trade-offs of a range of VLMs on PROVE,
finding that very few are in-fact able to achieve a good balance between the
two. Project page: \url{https://prove-explorer.netlify.app/}.

æè¦ï¼è¦è¦ºèªè¨æ¨¡å (VLM) ç¶å¸¸å°è¦è¦ºæ¥è©¢ç¢ççä¼¼åçä½é¯èª¤çåæãç¶èï¼å¯é å°éåæ­¤é¡å¹»è¦ºå¨éæ¾å¼æ¥è©¢çèªç±å½¢å¼åæä¸­çå½±é¿å·æææ°æ§ï¼å çºééè¦è¦è¦ºé©è­åæä¸­çæ¯åèªªæ³ãæåæåºç¨å¼å VLM è©ä¼° (PROVE)ï¼ä¸ç¨®ç¨æ¼è©ä¼° VLM å°éæ¾å¼æ¥è©¢çåæçæ°åºæºç¯ä¾ãçºäºå»ºæ§ PROVEï¼æåæä¾ä¸åå¤§åèªè¨æ¨¡å (LLM) ä¸åç±è¶è©³ç´°å½±åæ¨é¡å»ºæ§çé«ä¿çå ´æ¯åè¡¨ç¤ºï¼ä¸¦æç¤ºå®ç¢çå¤æ¨£åçåç­ (QA) éå°ï¼ä»¥åå¯ä»¥å¨å ´æ¯åç©ä»¶ä¸å·è¡çç¨å¼ï¼ä»¥é©è­æ¯å QA éå°ãå æ­¤ï¼æåå»ºæ§äºä¸åç± 10.5k åå·æææ°æ§ä½è¦è¦ºä¸åçç QA éå°çµæçåºæºãæ¥ä¸ä¾ï¼çºäºè©ä¼° PROVE ä¸­çæ¥è©¢çèªç±å½¢å¼æ¨¡ååæï¼æåæåºäºä¸åç¨å¼åè©ä¼°ç­ç¥ï¼è©²ç­ç¥å¨ä¸åçµ±ä¸çåºæ¼å ´æ¯åçæ¡æ¶ä¸­è¡¡éåæçæç¨æ§åçå¯¦æ§ãæåå¨ PROVE ä¸å°ä¸ç³»å VLM çæç¨æ§-çå¯¦æ§æ¬è¡¡é²è¡åºæºæ¸¬è©¦ï¼ç¼ç¾äºå¯¦ä¸å¾å°æ VLM è½å¨å©èä¹éåå¾è¯å¥½çå¹³è¡¡ãå°æ¡é é¢ï¼\url{https://prove-explorer.netlify.app/}ã


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-11**|**A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19**|Vedant Khandelwal et.al.|[2411.07163v1](http://arxiv.org/abs/2411.07163v1)|null|
|**2024-11-11**|**Ambient AI Scribing Support: Comparing the Performance of Specialized AI Agentic Architecture to Leading Foundational Models**|Chanseo Lee et.al.|[2411.06713v1](http://arxiv.org/abs/2411.06713v1)|null|
|**2024-11-10**|**In-Context Learning for Preserving Patient Privacy: A Framework for Synthesizing Realistic Patient Portal Messages**|Joseph Gatto et.al.|[2411.06549v1](http://arxiv.org/abs/2411.06549v1)|[link](https://github.com/persist-lab/syntheticportalgen)|
|**2024-11-09**|**NeuReg: Domain-invariant 3D Image Registration on Human and Mouse Brains**|Taha Razzaq et.al.|[2411.06315v1](http://arxiv.org/abs/2411.06315v1)|null|
|**2024-11-09**|**GuidelineGuard: An Agentic Framework for Medical Note Evaluation with Guideline Adherence**|MD Ragib Shahriyear et.al.|[2411.06264v1](http://arxiv.org/abs/2411.06264v1)|null|
|**2024-11-09**|**Deep Reinforcement Learning for Digital Twin-Oriented Complex Networked Systems**|Jiaqi Wen et.al.|[2411.06148v1](http://arxiv.org/abs/2411.06148v1)|null|
|**2024-11-09**|**Evaluating the Propensity of Generative AI for Producing Disinformation During an Election Cycle**|Erik J Schlicht et.al.|[2411.06120v1](http://arxiv.org/abs/2411.06120v1)|null|
|**2024-11-09**|**Personalize to generalize: Towards a universal medical multi-modality generalization through personalization**|Zhaorui Tan et.al.|[2411.06106v1](http://arxiv.org/abs/2411.06106v1)|null|
|**2024-11-08**|**Assessing Foundational Medical 'Segment Anything' (Med-SAM1, Med-SAM2) Deep Learning Models for Left Atrial Segmentation in 3D LGE MRI**|Mehri Mehrnia et.al.|[2411.05963v1](http://arxiv.org/abs/2411.05963v1)|null|
|**2024-11-08**|**GazeSearch: Radiology Findings Search Benchmark**|Trong Thang Pham et.al.|[2411.05780v1](http://arxiv.org/abs/2411.05780v1)|null|
|**2024-11-08**|**Humans Continue to Outperform Large Language Models in Complex Clinical Decision-Making: A Study with Medical Calculators**|Nicholas Wan et.al.|[2411.05897v1](http://arxiv.org/abs/2411.05897v1)|null|
|**2024-11-08**|**Identifying and Decomposing Compound Ingredients in Meal Plans Using Large Language Models**|Leon Kopitar et.al.|[2411.05892v1](http://arxiv.org/abs/2411.05892v1)|null|
|**2024-11-08**|**SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark**|Sithursan Sivasubramaniam et.al.|[2411.05521v1](http://arxiv.org/abs/2411.05521v1)|null|
|**2024-11-08**|**Towards Scalable Foundation Models for Digital Dermatology**|Fabian GrÃ¶ger et.al.|[2411.05514v1](http://arxiv.org/abs/2411.05514v1)|null|
|**2024-11-08**|**Towards Equitable ASD Diagnostics: A Comparative Study of Machine and Deep Learning Models Using Behavioral and Facial Data**|Mohammed Aledhari et.al.|[2411.05880v1](http://arxiv.org/abs/2411.05880v1)|null|
|**2024-11-07**|**Interactive Dialogue Agents via Reinforcement Learning on Hindsight Regenerations**|Joey Hong et.al.|[2411.05194v1](http://arxiv.org/abs/2411.05194v1)|null|
|**2024-11-07**|**Inverse Transition Learning: Learning Dynamics from Demonstrations**|Leo Benac et.al.|[2411.05174v1](http://arxiv.org/abs/2411.05174v1)|null|
|**2024-11-07**|**PadChest-GR: A Bilingual Chest X-ray Dataset for Grounded Radiology Report Generation**|Daniel C. Castro et.al.|[2411.05085v1](http://arxiv.org/abs/2411.05085v1)|null|
|**2024-11-07**|**Position Paper On Diagnostic Uncertainty Estimation from Large Language Models: Next-Word Probability Is Not Pre-test Probability**|Yanjun Gao et.al.|[2411.04962v1](http://arxiv.org/abs/2411.04962v1)|null|
|**2024-11-07**|**FineTuneBench: How well do commercial fine-tuning APIs infuse knowledge into LLMs?**|Eric Wu et.al.|[2411.05059v1](http://arxiv.org/abs/2411.05059v1)|null|
|**2024-11-07**|**Integrating Large Language Models for Genetic Variant Classification**|Youssef Boulaimen et.al.|[2411.05055v1](http://arxiv.org/abs/2411.05055v1)|null|
|**2024-11-07**|**AWARE Narrator and the Utilization of Large Language Models to Extract Behavioral Insights from Smartphone Sensing Data**|Tianyi Zhang et.al.|[2411.04691v1](http://arxiv.org/abs/2411.04691v1)|null|
|**2024-11-07**|**FedDP: Privacy-preserving method based on federated learning for histopathology image segmentation**|Liangrui Pan et.al.|[2411.04509v1](http://arxiv.org/abs/2411.04509v1)|null|
|**2024-11-07**|**Conditional Diffusion Model for Longitudinal Medical Image Generation**|Duy-Phuong Dao et.al.|[2411.05860v1](http://arxiv.org/abs/2411.05860v1)|null|
|**2024-11-07**|**Evaluating the Economic Implications of Using Machine Learning in Clinical Psychiatry**|Soaad Hossain et.al.|[2411.05856v1](http://arxiv.org/abs/2411.05856v1)|null|
|**2024-11-06**|**Robust Real-Time Mortality Prediction in the Intensive Care Unit using Temporal Difference Learning**|Thomas Frost et.al.|[2411.04285v1](http://arxiv.org/abs/2411.04285v1)|[link](https://github.com/tdgfrost/td-icu-mortality)|
|**2024-11-06**|**Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?**|Daniel P. Jeong et.al.|[2411.04118v1](http://arxiv.org/abs/2411.04118v1)|null|
|**2024-11-06**|**RaVL: Discovering and Mitigating Spurious Correlations in Fine-Tuned Vision-Language Models**|Maya Varma et.al.|[2411.04097v1](http://arxiv.org/abs/2411.04097v1)|[link](https://github.com/stanford-aimi/ravl)|
|**2024-11-06**|**Aligning Characteristic Descriptors with Images for Human-Expert-like Explainability**|Bharat Chandra Yalavarthi et.al.|[2411.04008v1](http://arxiv.org/abs/2411.04008v1)|null|
|**2024-11-06**|**Fine-tuning -- a Transfer Learning approach**|Joseph Arul Raj et.al.|[2411.03941v1](http://arxiv.org/abs/2411.03941v1)|null|
|**2024-11-06**|**MEG: Medical Knowledge-Augmented Large Language Models for Question Answering**|Laura Cabello et.al.|[2411.03883v2](http://arxiv.org/abs/2411.03883v2)|[link](https://github.com/lautel/meg)|
|**2024-11-06**|**Navigating the landscape of multimodal AI in medicine: a scoping review on technical challenges and clinical applications**|Daan Schouten et.al.|[2411.03782v1](http://arxiv.org/abs/2411.03782v1)|null|
|**2024-11-06**|**Sub-DM:Subspace Diffusion Model with Orthogonal Decomposition for MRI Reconstruction**|Yu Guan et.al.|[2411.03758v1](http://arxiv.org/abs/2411.03758v1)|null|
|**2024-11-06**|**Ultrasound-Based AI for COVID-19 Detection: A Comprehensive Review of Public and Private Lung Ultrasound Datasets and Studies**|Abrar Morshed et.al.|[2411.05029v1](http://arxiv.org/abs/2411.05029v1)|null|
|**2024-11-06**|**Touchstone Benchmark: Are We on the Right Way for Evaluating AI Algorithms for Medical Segmentation?**|Pedro R. A. S. Bassi et.al.|[2411.03670v1](http://arxiv.org/abs/2411.03670v1)|[link](https://github.com/mrgiovanni/touchstone)|
|**2024-11-06**|**Requirements Engineering for Older Adult Digital Health Software: A Systematic Literature Review**|Yuqing Xiao et.al.|[2411.03656v1](http://arxiv.org/abs/2411.03656v1)|null|
|**2024-11-06**|**Cross Feature Fusion of Fundus Image and Generated Lesion Map for Referable Diabetic Retinopathy Classification**|Dahyun Mok et.al.|[2411.03618v1](http://arxiv.org/abs/2411.03618v1)|null|
|**2024-11-05**|**The Future of Intelligent Healthcare: A Systematic Analysis and Discussion on the Integration and Impact of Robots Using Large Language Models for Healthcare**|Souren Pashangpour et.al.|[2411.03287v1](http://arxiv.org/abs/2411.03287v1)|null|
|**2024-11-05**|**Discovering Data Structures: Nearest Neighbor Search and Beyond**|Omar Salemohamed et.al.|[2411.03253v1](http://arxiv.org/abs/2411.03253v1)|null|
|**2024-11-05**|**Evaluating Machine Learning Models against Clinical Protocols for Enhanced Interpretability and Continuity of Care**|Christel Sirocchi et.al.|[2411.03105v1](http://arxiv.org/abs/2411.03105v1)|[link](https://github.com/ChristelSirocchi/XAI-similarity)|
|**2024-11-05**|**Local Lesion Generation is Effective for Capsule Endoscopy Image Data Augmentation in a Limited Data Setting**|Adrian B. ChÅopowiec et.al.|[2411.03098v1](http://arxiv.org/abs/2411.03098v1)|null|
|**2024-11-05**|**Controlling for Unobserved Confounding with Large Language Model Classification of Patient Smoking Status**|Samuel Lee et.al.|[2411.03004v1](http://arxiv.org/abs/2411.03004v1)|null|
|**2024-11-05**|**Region-Guided Attack on the Segment Anything Model (SAM)**|Xiaoliang Liu et.al.|[2411.02974v2](http://arxiv.org/abs/2411.02974v2)|null|
|**2024-11-05**|**[Vision Paper] PRObot: Enhancing Patient-Reported Outcome Measures for Diabetic Retinopathy using Chatbots and Generative AI**|Maren Pielka et.al.|[2411.02973v1](http://arxiv.org/abs/2411.02973v1)|null|
|**2024-11-05**|**Leveraging Transfer Learning and Multiple Instance Learning for HER2 Automatic Scoring of H\&E Whole Slide Images**|Rawan S. Abdulsadig et.al.|[2411.05028v1](http://arxiv.org/abs/2411.05028v1)|null|
|**2024-11-05**|**Membership Inference Attacks against Large Vision-Language Models**|Zhan Li et.al.|[2411.02902v1](http://arxiv.org/abs/2411.02902v1)|[link](https://github.com/lions-epfl/vl-mia)|
|**2024-11-04**|**Advanced XR-Based 6-DOF Catheter Tracking System for Immersive Cardiac Intervention Training**|Mohsen Annabestani et.al.|[2411.02611v1](http://arxiv.org/abs/2411.02611v1)|null|
|**2024-11-04**|**"It's a conversation, not a quiz": A Risk Taxonomy and Reflection Tool for LLM Adoption in Public Health**|Jiawei Zhou et.al.|[2411.02594v1](http://arxiv.org/abs/2411.02594v1)|null|
|**2024-11-04**|**Digitizing Touch with an Artificial Multimodal Fingertip**|Mike Lambeta et.al.|[2411.02479v1](http://arxiv.org/abs/2411.02479v1)|[link](https://github.com/facebookresearch/digit360)|
|**2024-11-04**|**Simulation of Nanorobots with Artificial Intelligence and Reinforcement Learning for Advanced Cancer Cell Detection and Tracking**|Shahab Kavousinejad et.al.|[2411.02345v1](http://arxiv.org/abs/2411.02345v1)|[link](https://github.com/shahab-k93/cancer-and-smart-nanorobot)|
|**2024-11-04**|**Taking AI Welfare Seriously**|Robert Long et.al.|[2411.00986v1](http://arxiv.org/abs/2411.00986v1)|null|
|**2024-11-04**|**Federated GNNs for EEG-Based Stroke Assessment**|Andrea Protani et.al.|[2411.02286v1](http://arxiv.org/abs/2411.02286v1)|null|
|**2024-11-04**|**Weakly supervised deep learning model with size constraint for prostate cancer detection in multiparametric MRI and generalization to unseen domains**|Robin Trombetta et.al.|[2411.02466v1](http://arxiv.org/abs/2411.02466v1)|null|
|**2024-11-04**|**Evaluating the quality of published medical research with ChatGPT**|Mike Thelwall et.al.|[2411.01952v1](http://arxiv.org/abs/2411.01952v1)|null|
|**2024-11-04**|**You are out of context!**|Giancarlo Cobino et.al.|[2411.02464v1](http://arxiv.org/abs/2411.02464v1)|null|
|**2024-11-03**|**Diagnosing Medical Datasets with Training Dynamics**|Laura Wenderoth et.al.|[2411.01653v1](http://arxiv.org/abs/2411.01653v1)|[link](https://github.com/laurawenderoth/training-dynamics)|
|**2024-11-03**|**Optical Flow Representation Alignment Mamba Diffusion Model for Medical Video Generation**|Zhenbin Wang et.al.|[2411.01647v1](http://arxiv.org/abs/2411.01647v1)|null|
|**2024-11-03**|**Customized Subgraph Selection and Encoding for Drug-drug Interaction Prediction**|Haotong Du et.al.|[2411.01535v1](http://arxiv.org/abs/2411.01535v1)|null|
|**2024-11-03**|**Conditional Latent Space Molecular Scaffold Optimization for Accelerated Molecular Design**|Onur Boyar et.al.|[2411.01423v1](http://arxiv.org/abs/2411.01423v1)|null|
|**2024-11-02**|**Medical X-Ray Image Enhancement Using Global Contrast-Limited Adaptive Histogram Equalization**|Sohrab Namazi Nia et.al.|[2411.01373v1](http://arxiv.org/abs/2411.01373v1)|null|
|**2024-11-02**|**Guided Synthesis of Labeled Brain MRI Data Using Latent Diffusion Models for Segmentation of Enlarged Ventricles**|Tim Ruschke et.al.|[2411.01351v1](http://arxiv.org/abs/2411.01351v1)|null|
|**2024-11-02**|**Causal reasoning in difference graphs**|Charles K. Assaad et.al.|[2411.01292v1](http://arxiv.org/abs/2411.01292v1)|null|
|**2024-11-02**|**Designing a Robust Radiology Report Generation System**|Sonit Singh et.al.|[2411.01153v1](http://arxiv.org/abs/2411.01153v1)|null|
|**2024-11-02**|**LEARNER: Learning Granular Labels from Coarse Labels using Contrastive Learning**|Gautam Gare et.al.|[2411.01144v1](http://arxiv.org/abs/2411.01144v1)|null|
|**2024-11-02**|**Artificial Intelligence for Microbiology and Microbiome Research**|Xu-Wen Wang et.al.|[2411.01098v1](http://arxiv.org/abs/2411.01098v1)|null|
|**2024-11-01**|**Contrasting with Symile: Simple Model-Agnostic Representation Learning for Unlimited Modalities**|Adriel Saporta et.al.|[2411.01053v1](http://arxiv.org/abs/2411.01053v1)|[link](https://github.com/rajesh-lab/symile)|
|**2024-11-01**|**Cross-Fundus Transformer for Multi-modal Diabetic Retinopathy Grading with Cataract**|Fan Xiao et.al.|[2411.00726v1](http://arxiv.org/abs/2411.00726v1)|null|
|**2024-11-01**|**CTPD: Cross-Modal Temporal Pattern Discovery for Enhanced Multimodal Electronic Health Records Analysis**|Fuying Wang et.al.|[2411.00696v1](http://arxiv.org/abs/2411.00696v1)|null|
|**2024-11-01**|**Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**|Mehdi Hosseini Chagahi et.al.|[2411.00916v2](http://arxiv.org/abs/2411.00916v2)|null|
|**2024-11-01**|**Deep learning-based auto-contouring of organs/structures-at-risk for pediatric upper abdominal radiotherapy**|Mianyong Ding et.al.|[2411.00594v1](http://arxiv.org/abs/2411.00594v1)|[link](https://github.com/MMianyong/-PedAbdSeg-)|
|**2024-11-01**|**Enhancing the Traditional Chinese Medicine Capabilities of Large Language Model through Reinforcement Learning from AI Feedback**|Song Yu et.al.|[2411.00897v1](http://arxiv.org/abs/2411.00897v1)|null|
|**2024-11-01**|**StepCountJITAI: simulation environment for RL with application to physical activity adaptive intervention**|Karine Karine et.al.|[2411.00336v1](http://arxiv.org/abs/2411.00336v1)|null|
|**2024-11-01**|**Strongly Topology-preserving GNNs for Brain Graph Super-resolution**|Pragya Singh et.al.|[2411.02525v1](http://arxiv.org/abs/2411.02525v1)|null|
|**2024-11-01**|**Evaluating the Impact of Lab Test Results on Large Language Models Generated Differential Diagnoses from Clinical Case Vignettes**|Balu Bhasuran et.al.|[2411.02523v1](http://arxiv.org/abs/2411.02523v1)|null|
|**2024-10-31**|**Deep Learning Predicts Mammographic Breast Density in Clinical Breast Ultrasound Images**|Arianna Bunnell et.al.|[2411.00891v2](http://arxiv.org/abs/2411.00891v2)|[link](https://github.com/hawaii-ai/bus-density)|
|**2024-10-31**|**Monitoring fairness in machine learning models that predict patient mortality in the ICU**|Tempest A. van Schaik et.al.|[2411.00190v2](http://arxiv.org/abs/2411.00190v2)|null|
|**2024-10-31**|**Clinical Evaluation of Medical Image Synthesis: A Case Study in Wireless Capsule Endoscopy**|Panagiota Gatoula et.al.|[2411.00178v1](http://arxiv.org/abs/2411.00178v1)|null|
|**2024-10-31**|**Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning**|John Wu et.al.|[2411.00173v1](http://arxiv.org/abs/2411.00173v1)|null|
|**2024-10-31**|**Navigating the Unknown: A Chat-Based Collaborative Interface for Personalized Exploratory Tasks**|Yingzhe Peng et.al.|[2410.24032v1](http://arxiv.org/abs/2410.24032v1)|null|
|**2024-10-31**|**Neural Network Verification with PyRAT**|Augustin Lemesle et.al.|[2410.23903v1](http://arxiv.org/abs/2410.23903v1)|null|
|**2024-10-31**|**Counterfactual MRI Data Augmentation using Conditional Denoising Diffusion Generative Models**|Pedro MorÃ£o et.al.|[2410.23835v1](http://arxiv.org/abs/2410.23835v1)|[link](https://github.com/pedromorao/counterfactual-mri-data-augmentation)|
|**2024-10-31**|**Parameter-Efficient Fine-Tuning Medical Multimodal Large Language Models for Medical Visual Grounding**|Jinlong He et.al.|[2410.23822v1](http://arxiv.org/abs/2410.23822v1)|null|
|**2024-10-31**|**Improving snore detection under limited dataset through harmonic/percussive source separation and convolutional neural networks**|F. D. Gonzalez-Martinez et.al.|[2410.23796v1](http://arxiv.org/abs/2410.23796v1)|null|
|**2024-10-31**|**The Potential of LLMs in Medical Education: Generating Questions and Answers for Qualification Exams**|Yunqi Zhu et.al.|[2410.23769v1](http://arxiv.org/abs/2410.23769v1)|null|
|**2024-10-31**|**Artificial intelligence to improve clinical coding practice in Scandinavia: a crossover randomized controlled trial**|Taridzo Chomutare et.al.|[2410.23725v1](http://arxiv.org/abs/2410.23725v1)|null|
|**2024-10-31**|**Enhancing Brain Tumor Classification Using TrAdaBoost and Multi-Classifier Deep Learning Approaches**|Mahin Mohammadi et.al.|[2411.00875v1](http://arxiv.org/abs/2411.00875v1)|null|
|**2024-10-31**|**Deep Convolutional Neural Networks on Multiclass Classification of Three-Dimensional Brain Images for Parkinson's Disease Stage Prediction**|Guan-Hua Huang et.al.|[2410.23649v1](http://arxiv.org/abs/2410.23649v1)|null|
|**2024-10-31**|**MS-Glance: Non-semantic context vectors and the applications in supervising image reconstruction**|Ziqi Gao et.al.|[2410.23577v1](http://arxiv.org/abs/2410.23577v1)|[link](https://github.com/z7gao/msglance)|
|**2024-10-31**|**LEAF: Learning and Evaluation Augmented by Fact-Checking to Improve Factualness in Large Language Models**|Hieu Tran et.al.|[2410.23526v1](http://arxiv.org/abs/2410.23526v1)|null|
|**2024-10-30**|**Emory Knee Radiograph (MRKR) Dataset**|Brandon Price et.al.|[2411.00866v1](http://arxiv.org/abs/2411.00866v1)|null|
|**2024-10-30**|**STIED: A deep learning model for the SpatioTemporal detection of focal Interictal Epileptiform Discharges with MEG**|Raquel FernÃ¡ndez-MartÃ­n et.al.|[2410.23386v1](http://arxiv.org/abs/2410.23386v1)|null|
|**2024-10-30**|**Larger models yield better results? Streamlined severity classification of ADHD-related concerns using BERT-based knowledge distillation**|Ahmed Akib Jawad Karim et.al.|[2411.00052v1](http://arxiv.org/abs/2411.00052v1)|null|
|**2024-10-30**|**DiaMond: Dementia Diagnosis with Multi-Modal Vision Transformers Using MRI and PET**|Yitong Li et.al.|[2410.23219v1](http://arxiv.org/abs/2410.23219v1)|[link](https://github.com/ai-med/diamond)|
|**2024-10-30**|**Variable Resolution Sampling and Deep Learning Image Recovery for Accelerated Multi-Spectral MRI Near Metal Implants**|Azadeh Sharafi et.al.|[2410.23329v1](http://arxiv.org/abs/2410.23329v1)|null|
|**2024-10-30**|**DiabML: AI-assisted diabetes diagnosis method with meta-heuristic-based feature selection**|Vahideh Hayyolalam et.al.|[2411.00858v1](http://arxiv.org/abs/2411.00858v1)|null|
|**2024-10-30**|**Revisiting MAE pre-training for 3D medical image segmentation**|Tassilo Wald et.al.|[2410.23132v1](http://arxiv.org/abs/2410.23132v1)|null|
|**2024-10-30**|**SpiroActive: Active Learning for Efficient Data Acquisition for Spirometry**|Ankita Kumari Jain et.al.|[2410.22950v1](http://arxiv.org/abs/2410.22950v1)|null|
|**2024-10-30**|**Efficient Feature Extraction and Classification Architecture for MRI-Based Brain Tumor Detection**|Plabon Paul et.al.|[2410.22619v1](http://arxiv.org/abs/2410.22619v1)|null|
|**2024-10-29**|**Do Large Language Models Align with Core Mental Health Counseling Competencies?**|Viet Cuong Nguyen et.al.|[2410.22446v1](http://arxiv.org/abs/2410.22446v1)|null|
|**2024-10-29**|**MAPUNetR: A Hybrid Vision Transformer and U-Net Architecture for Efficient and Interpretable Medical Image Segmentation**|Ovais Iqbal Shah et.al.|[2410.22223v1](http://arxiv.org/abs/2410.22223v1)|null|

#### Abstracts
##### **A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19**
2411.07163v1 by Vedant Khandelwal, Manas Gaur, Ugur Kursuncu, Valerie Shalin, Amit Sheth

Monitoring public sentiment via social media is potentially helpful during
health crises such as the COVID-19 pandemic. However, traditional
frequency-based, data-driven neural network-based approaches can miss newly
relevant content due to the evolving nature of language in a dynamically
evolving environment. Human-curated symbolic knowledge sources, such as
lexicons for standard language and slang terms, can potentially elevate social
media signals in evolving language. We introduce a neurosymbolic method that
integrates neural networks with symbolic knowledge sources, enhancing the
detection and interpretation of mental health-related tweets relevant to
COVID-19. Our method was evaluated using a corpus of large datasets
(approximately 12 billion tweets, 2.5 million subreddit data, and 700k news
articles) and multiple knowledge graphs. This method dynamically adapts to
evolving language, outperforming purely data-driven models with an F1 score
exceeding 92\%. This approach also showed faster adaptation to new data and
lower computational demands than fine-tuning pre-trained large language models
(LLMs). This study demonstrates the benefit of neurosymbolic methods in
interpreting text in a dynamic environment for tasks such as health
surveillance.

æè¦ï¼ééç¤¾ç¾¤åªé«ç£æ§å¬ç¾æç·å¨ COVID-19 ç­å¥åº·å±æ©æéå¯è½å¾æå¹«å©ãç¶èï¼å³çµ±çåºæ¼é »çãè³æé©åçç¥ç¶ç¶²è·¯æ¹æ³å¯è½æé¯éæ°ç¸éçå§å®¹ï¼å çºèªè¨å¨åææ¼åçç°å¢ä¸­ææçºæ¼åãç±äººé¡ç­åçè±¡å¾µæ§ç¥è­ä¾æºï¼ä¾å¦æ¨æºèªè¨åä¿èªè¡èªçè©å½ï¼å¯è½ææåç¤¾ç¾¤åªé«å¨æ¼åèªè¨ä¸­çè¨èãæåå¼å¥ä¸ç¨®å°ç¥ç¶ç¶²è·¯èè±¡å¾µæ§ç¥è­ä¾æºæ´åçç¥ç¶ç¬¦èæ¹æ³ï¼å¢å¼·è COVID-19 ç¸éçå¿çå¥åº·ç¸éæ¨æçåµæ¸¬åè©®éãæåçåæ³ä½¿ç¨å¤§åè³æéèªæåº«ï¼ç´ 120 ååæ¨æã250 è¬å subreddit è³æå 70 è¬åæ°èæç« ï¼åå¤åç¥è­åè­é²è¡è©ä¼°ãéç¨®æ¹æ³åæé©ææ¼åçèªè¨ï¼åªæ¼ç´è³æé©åæ¨¡åï¼F1 åæ¸è¶é 92%ãéç¨®æ¹æ³ä¹é¡¯ç¤ºåºæ¯å¾®èª¿é è¨ç·´å¤§åèªè¨æ¨¡å (LLM) æ´å¿«é©ææ°è³æåæ´ä½çéç®éæ±ãæ¬ç ç©¶è­æäºç¥ç¶ç¬¦èæ¹æ³å¨åæç°å¢ä¸­è©®éæå­çåªé»ï¼é©ç¨æ¼å¥åº·ç£æ§ç­ä»»åã

##### **Ambient AI Scribing Support: Comparing the Performance of Specialized AI Agentic Architecture to Leading Foundational Models**
2411.06713v1 by Chanseo Lee, Sonu Kumar, Kimon A. Vogt, Sam Meraj

This study compares Sporo Health's AI Scribe, a proprietary model fine-tuned
for medical scribing, with various LLMs (GPT-4o, GPT-3.5, Gemma-9B, and
Llama-3.2-3B) in clinical documentation. We analyzed de-identified patient
transcripts from partner clinics, using clinician-provided SOAP notes as the
ground truth. Each model generated SOAP summaries using zero-shot prompting,
with performance assessed via recall, precision, and F1 scores. Sporo
outperformed all models, achieving the highest recall (73.3%), precision
(78.6%), and F1 score (75.3%) with the lowest performance variance.
Statistically significant differences (p < 0.05) were found between Sporo and
the other models, with post-hoc tests showing significant improvements over
GPT-3.5, Gemma-9B, and Llama 3.2-3B. While Sporo outperformed GPT-4o by up to
10%, the difference was not statistically significant (p = 0.25). Clinical user
satisfaction, measured with a modified PDQI-9 inventory, favored Sporo.
Evaluations indicated Sporo's outputs were more accurate and relevant. This
highlights the potential of Sporo's multi-agentic architecture to improve
clinical workflows.

æè¦ï¼æ¬ç ç©¶æ¯è¾äº Sporo Health ç AI Scribeï¼ä¸ç§éå¯¹å»çè®°å½ä¸é¨å¾®è°çä¸ææ¨¡åï¼ä¸ä¸´åºè®°å½ä¸­çåç§ LLMï¼GPT-4oãGPT-3.5ãGemma-9B å Llama-3.2-3Bï¼ãæä»¬åæäºæ¥èªåä½è¯æçå»æ è¯æ£èè®°å½ï¼ä½¿ç¨ä¸´åºå»çæä¾ç SOAP è®°å½ä½ä¸ºåºæ¬äºå®ãæ¯ä¸ªæ¨¡åä½¿ç¨é¶æ¬¡æç¤ºçæäº SOAP æè¦ï¼éè¿å¬åçãç²¾ç¡®çå F1 åæ°è¯ä¼°æ§è½ãSporo ä¼äºæææ¨¡åï¼ä»¥æä½çæ§è½å·®å¼å®ç°äºæé«çå¬åç (73.3%)ãç²¾ç¡®ç (78.6%) å F1 åæ° (75.3%)ãå¨ Sporo åå¶ä»æ¨¡åä¹é´åç°äºç»è®¡å­¦ä¸çæ¾çå·®å¼ (p < 0.05)ï¼äºåæ£éªæ¾ç¤ºä¸ GPT-3.5ãGemma-9B å Llama 3.2-3B ç¸æ¯ææ¾çæ¹åãè½ç¶ Sporo çè¡¨ç°ä¼äº GPT-4o è¾¾ 10%ï¼ä½å·®å¼å¨ç»è®¡å­¦ä¸å¹¶ä¸æ¾ç (p = 0.25)ãä½¿ç¨ä¿®æ¹åç PDQI-9 æ¸åè¡¡éçä¸´åºç¨æ·æ»¡æåº¦åå¥½ Sporoãè¯ä¼°è¡¨æ Sporo çè¾åºæ´åç¡®ãæ´ç¸å³ãè¿çªåºäº Sporo çå¤ä»£çæ¶æå¨æ¹è¿ä¸´åºå·¥ä½æµç¨æ¹é¢çæ½åã

##### **In-Context Learning for Preserving Patient Privacy: A Framework for Synthesizing Realistic Patient Portal Messages**
2411.06549v1 by Joseph Gatto, Parker Seegmiller, Timothy E. Burdick, Sarah Masud Preum

Since the COVID-19 pandemic, clinicians have seen a large and sustained
influx in patient portal messages, significantly contributing to clinician
burnout. To the best of our knowledge, there are no large-scale public patient
portal messages corpora researchers can use to build tools to optimize
clinician portal workflows. Informed by our ongoing work with a regional
hospital, this study introduces an LLM-powered framework for configurable and
realistic patient portal message generation. Our approach leverages few-shot
grounded text generation, requiring only a small number of de-identified
patient portal messages to help LLMs better match the true style and tone of
real data. Clinical experts in our team deem this framework as HIPAA-friendly,
unlike existing privacy-preserving approaches to synthetic text generation
which cannot guarantee all sensitive attributes will be protected. Through
extensive quantitative and human evaluation, we show that our framework
produces data of higher quality than comparable generation methods as well as
all related datasets. We believe this work provides a path forward for (i) the
release of large-scale synthetic patient message datasets that are
stylistically similar to ground-truth samples and (ii) HIPAA-friendly data
generation which requires minimal human de-identification efforts.

æè¦ï¼èª COVID-19 å¤§æµè¡ä»¥ä¾ï¼è¨åºé«çæ¶å°äºå¤§éçæçºæ§æ£èå¥å£è¨æ¯ï¼éé¡¯èå åäºè¨åºé«ççå¦æ æãææåæç¥ï¼æ²æå¤§åå¬å±æ£èå¥å£è¨æ¯èªæåº«å¯ä¾ç ç©¶äººå¡ç¨æ¼å»ºæ§å·¥å·ä¾æä½³åè¨åºé«çå¥å£å·¥ä½æµç¨ãæ¬ç ç©¶åéäºæåèååé«é¢æ­£å¨é²è¡çå·¥ä½ï¼ä»ç´¹äºä¸åç± LLM é©åçæ¡æ¶ï¼ç¨æ¼å¯éç½®ä¸é¼ççæ£èå¥å£è¨æ¯ç¢çãæåçåæ³å©ç¨äºå°æ¨£æ¬æ¥å°ææ¬ç¢çï¼åªéå°æ¸å»è­å¥åçæ£èå¥å£è¨æ¯ï¼å°±è½å¹«å© LLM æ´ä½³å¹éçå¯¦è³æççå¯¦é¢¨æ ¼åèªæ°£ãæååéä¸­çè¨åºå°å®¶èªçºéåæ¡æ¶ç¬¦å HIPAAï¼éèç¾æçåæææ¬ç¢çé±ç§ä¿è­·æ¹æ³ä¸åï¼å¾èç¡æ³ä¿è­ææææå±¬æ§é½åå°ä¿è­·ãééå»£æ³çéååäººå·¥è©ä¼°ï¼æåè­æäºæåçæ¡æ¶ç¢ççè³æåè³ªé«æ¼å¯æ¯è¼çç¢çæ¹æ³ä»¥åææç¸éçè³æéãæåç¸ä¿¡éé å·¥ä½çºä»¥ä¸äºé æä¾äºåé²çéè·¯ï¼(i) ç¼å¸èçå¯¦æ¨£æ¬å¨é¢¨æ ¼ä¸ç¸ä¼¼çãå¤§è¦æ¨¡çåææ£èè¨æ¯è³æéï¼ä»¥å (ii) ç¬¦å HIPAA çè³æç¢çï¼èééè¦æå°çäººå·¥å»è­å¥åå·¥ä½ã

##### **NeuReg: Domain-invariant 3D Image Registration on Human and Mouse Brains**
2411.06315v1 by Taha Razzaq, Asim Iqbal

Medical brain imaging relies heavily on image registration to accurately
curate structural boundaries of brain features for various healthcare
applications. Deep learning models have shown remarkable performance in image
registration in recent years. Still, they often struggle to handle the
diversity of 3D brain volumes, challenged by their structural and contrastive
variations and their imaging domains. In this work, we present NeuReg, a
Neuro-inspired 3D image registration architecture with the feature of domain
invariance. NeuReg generates domain-agnostic representations of imaging
features and incorporates a shifting window-based Swin Transformer block as the
encoder. This enables our model to capture the variations across brain imaging
modalities and species. We demonstrate a new benchmark in multi-domain publicly
available datasets comprising human and mouse 3D brain volumes. Extensive
experiments reveal that our model (NeuReg) outperforms the existing baseline
deep learning-based image registration models and provides a high-performance
boost on cross-domain datasets, where models are trained on 'source-only'
domain and tested on completely 'unseen' target domains. Our work establishes a
new state-of-the-art for domain-agnostic 3D brain image registration,
underpinned by Neuro-inspired Transformer-based architecture.

æè¦ï¼é«å­¸è¦é¨å½±åé«åº¦ä¾è³´å½±åéæºï¼ä»¥æºç¢ºç­ç«å¤§è¦ç¹å¾µççµæ§æ§éçï¼ç¨æ¼åç¨®é«çä¿å¥æç¨ãæ·±åº¦å­¸ç¿æ¨¡åè¿å¹´ä¾å¨å½±åéæºä¸­å±ç¾åºåè¶çæè½ãåç®¡å¦æ­¤ï¼éäºæ¨¡åå¨èçå¤åç 3D å¤§è¦é«ç©æå¸¸å¸¸æéå°å°é£ï¼åå°å¶çµæ§åå°æ¯è®åä»¥åå½±åé åçææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåº NeuRegï¼ä¸ç¨®å·åé åä¸è®æ§ç¹å¾µçç¥ç¶åç¼å¼ 3D å½±åéæºæ¶æ§ãNeuReg ç¢çå½±åç¹å¾µçé åä¸å¯ç¥è¡¨ç¤ºï¼ä¸¦å°åºæ¼æ»åè¦çªç Swin Transformer åå¡ä½çºç·¨ç¢¼å¨ãéä½¿æåçæ¨¡åè½å¤ æ·åè·¨å¤§è¦å½±åæ¨¡å¼åç©ç¨®çè®åãæåå±ç¤ºäºä¸åæ°çåºæºï¼åå«äººé¡åèé¼  3D å¤§è¦é«ç©çå¤é åå¬éå¯ç¨è³æéãå»£æ³çå¯¦é©é¡¯ç¤ºï¼æåçæ¨¡å (NeuReg) åªæ¼ç¾æçåºæºæ·±åº¦å­¸ç¿å½±åéæºæ¨¡åï¼ä¸¦å¨è·¨é åè³æéä¸æä¾é«æ§è½æåï¼å¶ä¸­æ¨¡åå¨ãåä¾æºãé åä¸è¨ç·´ï¼ä¸¦å¨å®å¨ãæªè¦ãçç®æ¨é åä¸é²è¡æ¸¬è©¦ãæåçç ç©¶å»ºç«äºé åä¸å¯ç¥ 3D å¤§è¦å½±åéæºçæ°æè¡ï¼ç±ç¥ç¶åç¼å¼ Transformer çºåºç¤çæ¶æ§ææ¯æã

##### **GuidelineGuard: An Agentic Framework for Medical Note Evaluation with Guideline Adherence**
2411.06264v1 by MD Ragib Shahriyear

Although rapid advancements in Large Language Models (LLMs) are facilitating
the integration of artificial intelligence-based applications and services in
healthcare, limited research has focused on the systematic evaluation of
medical notes for guideline adherence. This paper introduces GuidelineGuard, an
agentic framework powered by LLMs that autonomously analyzes medical notes,
such as hospital discharge and office visit notes, to ensure compliance with
established healthcare guidelines. By identifying deviations from recommended
practices and providing evidence-based suggestions, GuidelineGuard helps
clinicians adhere to the latest standards from organizations like the WHO and
CDC. This framework offers a novel approach to improving documentation quality
and reducing clinical errors.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) çå¿«éé²å±ä¿é²äºäººå·¥æºæ§æç¨ç¨å¼åæåå¨é«çä¿å¥ä¸­çæ´åï¼ä½æéçç ç©¶å°æ³¨æ¼å°é«çè¨éé²è¡ç³»çµ±è©ä¼°ä»¥ç¬¦åæºåãæ¬æä»ç´¹äº GuidelineGuardï¼ä¸åç± LLM æä¾ååçä»£çæ¶æ§ï¼å®æèªååæé«çè¨éï¼ä¾å¦é«é¢åºé¢åéè¨ºè¨éï¼ä»¥ç¢ºä¿ç¬¦åæ¢å®çé«çä¿å¥æºåãééæ¾åºèå»ºè­°åæ³çåå·®ä¸¦æä¾åºæ¼è­æçå»ºè­°ï¼GuidelineGuard å¯åå©è¨åºé«çéµå®ä¸çè¡ççµç¹ (WHO) åç¾çç®¡å¶ä¸­å¿ (CDC) ç­çµç¹çææ°æ¨æºãæ­¤æ¶æ§æä¾äºä¸ç¨®æ¹åæä»¶åè³ªåæ¸å°è¨åºé¯èª¤çæ°æ¹æ³ã

##### **Deep Reinforcement Learning for Digital Twin-Oriented Complex Networked Systems**
2411.06148v1 by Jiaqi Wen, Bogdan Gabrys, Katarzyna Musial

The Digital Twin Oriented Complex Networked System (DT-CNS) aims to build and
extend a Complex Networked System (CNS) model with progressively increasing
dynamics complexity towards an accurate reflection of reality -- a Digital Twin
of reality. Our previous work proposed evolutionary DT-CNSs to model the
long-term adaptive network changes in an epidemic outbreak. This study extends
this framework by proposeing the temporal DT-CNS model, where reinforcement
learning-driven nodes make decisions on temporal directed interactions in an
epidemic outbreak. We consider cooperative nodes, as well as egocentric and
ignorant "free-riders" in the cooperation. We describe this epidemic spreading
process with the Susceptible-Infected-Recovered ($SIR$) model and investigate
the impact of epidemic severity on the epidemic resilience for different types
of nodes. Our experimental results show that (i) the full cooperation leads to
a higher reward and lower infection number than a cooperation with egocentric
or ignorant "free-riders"; (ii) an increasing number of "free-riders" in a
cooperation leads to a smaller reward, while an increasing number of egocentric
"free-riders" further escalate the infection numbers and (iii) higher infection
rates and a slower recovery weakens networks' resilience to severe epidemic
outbreaks. These findings also indicate that promoting cooperation and reducing
"free-riders" can improve public health during epidemics.

æè¦ï¼æ¸ä½å­¿çå°åè¤éç¶²è·¯ç³»çµ±ï¼DT-CNSï¼æ¨å¨å»ºç«åæ´å±è¤éç¶²è·¯ç³»çµ±ï¼CNSï¼æ¨¡åï¼ä¸¦éæ­¥å¢å åæè¤éæ§ä»¥æºç¢ºåæ ç¾å¯¦ââç¾å¯¦çæ¸ä½å­¿çãæåååçå·¥ä½æåºæ¼åç DT-CNS ä¾å»ºæ¨¡æµè¡ççç¼ä¸­çé·æé©ææ§ç¶²è·¯è®åãæ¬ç ç©¶ééæåºæé DT-CNS æ¨¡åä¾å»¶ä¼¸éåæ¶æ§ï¼å¶ä¸­å¼·åå­¸ç¿é©åçç¯é»å¨æµè¡ççç¼ä¸­å°æéå°åäºåååºæ±ºç­ãæåèæ®åä½ç¯é»ï¼ä»¥ååä½ä¸­çèªæä¸­å¿åç¡ç¥çãæ­ä¾¿è»èããæåä½¿ç¨ææè-åææè-åº·å¾©èï¼$SIR$ï¼æ¨¡åæè¿°éåæµè¡çæ´æ£éç¨ï¼ä¸¦èª¿æ¥æµè¡çå´éæ§å°ä¸åé¡åç¯é»çæµè¡çå¾©ååçå½±é¿ãæåçå¯¦é©çµæé¡¯ç¤º (i) å¨é¢åä½æå°è´æ¯èèªæä¸­å¿æç¡ç¥çãæ­ä¾¿è»èãåä½æ´é«çåå ±åæ´ä½çæææ¸ï¼(ii) åä½ä¸­çãæ­ä¾¿è»èãæ¸éå¢å æå°è´è¼å°çåå ±ï¼èèªæä¸­å¿çãæ­ä¾¿è»èãæ¸éå¢å æé²ä¸æ­¥æåæææ¸ï¼(iii) è¼é«çææçåè¼æ¢çå¾©åæåå¼±ç¶²è·¯å°å´éæµè¡ççç¼çå¾©ååãéäºç¼ç¾ä¹è¡¨ç¤ºï¼å¨æµè¡çæéä¿é²åä½åæ¸å°ãæ­ä¾¿è»èãå¯ä»¥æ¹åå¬å±è¡çã

##### **Evaluating the Propensity of Generative AI for Producing Disinformation During an Election Cycle**
2411.06120v1 by Erik J Schlicht

Generative Artificial Intelligence offers a powerful tool for adversaries who
wish to engage in influence operations, such as the Chinese Spamouflage
operation and the Russian Internet Research Agency effort that both sought to
interfere with recent US election cycles. Therefore, this study seeks to
investigate the propensity of current Generative AI models for producing
harmful disinformation during an election cycle. The probability that different
Generative AI models produced disinformation when given adversarial prompts was
evaluated, in addition the associated harm. This allows for the expected harm
for each model to be computed and it was discovered that Copilot and Gemini
tied for the overall safest performance by realizing the lowest expected harm,
while GPT-4o produced the greatest rates of harmful disinformation, resulting
in much higher expected harm scores. The impact of disinformation category was
also investigated and Gemini was safest within the political category of
disinformation, while Copilot was safest for topics related to health.
Moreover, characteristics of adversarial roles were discovered that led to
greater expected harm across all models. Finally, classification models were
developed that predicted disinformation production based on the conditions
considered in this study, which offers insight into factors important for
predicting disinformation production. Based on all of these insights,
recommendations are provided that seek to mitigate factors that lead to harmful
disinformation being produced by Generative AI models. It is hoped that
developers will use these insights to improve future models.

æè¦ï¼çæå¼äººå·¥æºæ§çºææå¾äºå½±é¿åæä½çæµå°èæä¾å¼·å¤§çå·¥å·ï¼ä¾å¦ä¸­åçåå¾éµä»¶å½è£è¡ååä¿ç¾æ¯çç¶²è·¯ç ç©¶æ©æ§åªåï¼éå©èé½è©¦åå¹²é æè¿çç¾åé¸èé±æãå æ­¤ï¼æ¬ç ç©¶æ¨å¨èª¿æ¥ç¶åçæå¼ AI æ¨¡åå¨é¸èé±æä¸­ç¢çæå®³é¯èª¤è¨æ¯çå¾åãé¤äºç¸éå±å®³ä¹å¤ï¼éè©ä¼°äºå¨çµ¦å®å°ææç¤ºæä¸åçæå¼ AI æ¨¡åç¢çé¯èª¤è¨æ¯çå¯è½æ§ãéåè¨±è¨ç®æ¯åæ¨¡åçé æå±å®³ï¼ä¸¦ä¸ç¼ç¾ Copilot å Gemini å¨å¯¦ç¾æä½é æå±å®³æ¹é¢ä¸¦åçºæå®å¨çæ´é«æè½ï¼è GPT-4o ç¢çäºæé«æ¯ççæå®³é¯èª¤è¨æ¯ï¼å°è´é æå±å®³åæ¸é«å¾å¤ãéèª¿æ¥äºé¯èª¤è¨æ¯é¡å¥çå½±é¿ï¼ä¸¦ä¸ Gemini å¨æ¿æ²»é¡å¥çé¯èª¤è¨æ¯ä¸­æ¯æå®å¨çï¼è Copilot å¨èå¥åº·ç¸éçä¸»é¡ä¸­æå®å¨ãæ­¤å¤ï¼ç¼ç¾äºå°æè§è²çç¹æ§ï¼å°è´æææ¨¡åçé æå±å®³æ´å¤§ãæå¾ï¼éç¼äºåé¡æ¨¡åï¼æ ¹ææ¬ç ç©¶ä¸­èæ®çæ¢ä»¶é æ¸¬é¯èª¤è¨æ¯ç¢çï¼éæä¾äºå°é æ¸¬é¯èª¤è¨æ¯ç¢çå¾éè¦çå ç´ çè¦è§£ãæ ¹æææéäºè¦è§£ï¼æä¾äºå»ºè­°ï¼æ¨å¨æ¸è¼å°è´çæå¼ AI æ¨¡åç¢çæå®³é¯èª¤è¨æ¯çå ç´ ãå¸æéç¼äººå¡å°ä½¿ç¨éäºè¦è§£ä¾æ¹é²æªä¾çæ¨¡åã

##### **Personalize to generalize: Towards a universal medical multi-modality generalization through personalization**
2411.06106v1 by Zhaorui Tan, Xi Yang, Tan Pan, Tianyi Liu, Chen Jiang, Xin Guo, Qiufeng Wang, Anh Nguyen, Yuan Qi, Kaizhu Huang, Yuan Cheng

Personalized medicine is a groundbreaking healthcare framework for the
$21^{st}$ century, tailoring medical treatments to individuals based on unique
clinical characteristics, including diverse medical imaging modalities. Given
the significant differences among these modalities due to distinct underlying
imaging principles, generalization in multi-modal medical image tasks becomes
substantially challenging. Previous methods addressing multi-modal
generalization rarely consider personalization, primarily focusing on common
anatomical information. This paper aims to bridge multi-modal generalization
with the concept of personalized medicine. Specifically, we propose a novel
approach to derive a tractable form of the underlying personalized invariant
representation $\mathbb{X}_h$ by leveraging individual-level constraints and a
learnable biological prior. We demonstrate the feasibility and benefits of
learning a personalized $\mathbb{X}_h$, showing that this representation is
highly generalizable and transferable across various multi-modal medical tasks.
Our method is rigorously validated on medical imaging modalities emphasizing
both physical structure and functional information, encompassing a range of
tasks that require generalization. Extensive experimental results consistently
show that our approach significantly improves performance across diverse
scenarios, confirming its effectiveness.

æè¦ï¼åäººåé«çæ¯ 21 ä¸ç´çåµæ°é«çä¿å¥æ¶æ§ï¼æ ¹æç¨ç¹çè¨åºç¹å¾µï¼åæ¬å¤ç¨®é«å­¸å½±åæ¹å¼ï¼çºåäººéèº«æé é«çæ²»çãç±æ¼éäºæ¹å¼åºæ¼ä¸åçå½±ååçï¼å æ­¤å­å¨é¡¯èå·®ç°ï¼å¤æ¨¡å¼é«å­¸å½±åä»»åä¸­çæ¦æ¬è®å¾æ¥µå·ææ°æ§ãååèçå¤æ¨¡å¼æ¦æ¬çæ¹æ³å¾å°èæ®åäººåï¼ä¸»è¦éæ³¨æ¼å±åçè§£åè³è¨ãæ¬ææ¨å¨å°å¤æ¨¡å¼æ¦æ¬èåäººåé«ççæ¦å¿µè¯ç¹«èµ·ä¾ãå·é«ä¾èªªï¼æåæåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼ééå©ç¨åäººå±¤ç´ç´æåå¯å­¸ç¿ççç©åé©ï¼è¡çåºåºç¤åäººåä¸è®è¡¨ç¤º $\mathbb{X}_h$ çææ¼èçå½¢å¼ãæåå±ç¤ºäºå­¸ç¿åäººå $\mathbb{X}_h$ çå¯è¡æ§åå¥½èï¼è¡¨ææ­¤è¡¨ç¤ºå·æé«åº¦å¯æ¦æ¬æ§ï¼ä¸¦ä¸å¯ä»¥å¨åç¨®å¤æ¨¡å¼é«çä»»åä¸­è½ç§»ãæåçæè¡å¨å¼·èª¿ç©ççµæ§ååè½è³è¨çé«å­¸å½±åæ¹å¼ä¸å¾å°å´æ ¼é©è­ï¼æ¶µèäºéè¦æ¦æ¬çä¸ç³»åä»»åãå»£æ³çå¯¦é©çµæä¸è´è¡¨æï¼æåçæè¡é¡¯èæ¹åäºåç¨®æå¢ä¸çæè½ï¼è­å¯¦äºå¶æææ§ã

##### **Assessing Foundational Medical 'Segment Anything' (Med-SAM1, Med-SAM2) Deep Learning Models for Left Atrial Segmentation in 3D LGE MRI**
2411.05963v1 by Mehri Mehrnia, Mohamed Elbayumi, Mohammed S. M. Elbaz

Atrial fibrillation (AF), the most common cardiac arrhythmia, is associated
with heart failure and stroke. Accurate segmentation of the left atrium (LA) in
3D late gadolinium-enhanced (LGE) MRI is helpful for evaluating AF, as fibrotic
remodeling in the LA myocardium contributes to arrhythmia and serves as a key
determinant of therapeutic strategies. However, manual LA segmentation is
labor-intensive and challenging. Recent foundational deep learning models, such
as the Segment Anything Model (SAM), pre-trained on diverse datasets, have
demonstrated promise in generic segmentation tasks. MedSAM, a fine-tuned
version of SAM for medical applications, enables efficient, zero-shot
segmentation without domain-specific training. Despite the potential of MedSAM
model, it has not yet been evaluated for the complex task of LA segmentation in
3D LGE-MRI. This study aims to (1) evaluate the performance of MedSAM in
automating LA segmentation, (2) compare the performance of the MedSAM2 model,
which uses a single prompt with automated tracking, with the MedSAM1 model,
which requires separate prompt for each slice, and (3) analyze the performance
of MedSAM1 in terms of Dice score(i.e., segmentation accuracy) by varying the
size and location of the box prompt.

æè¦ï¼å¿æ¿é¡«å (AF) æ¯æå¸¸è¦çå¿å¾ä¸æ´ï¼èå¿èè¡°ç«­åä¸­é¢¨æéã3D ææéå¢å¼· (LGE) MRI ä¸­å·¦å¿æ¿ (LA) çç²¾ç¢ºåå²æå©æ¼è©ä¼° AFï¼å çº LA å¿èä¸­ççºç¶­åéå¡æå°è´å¿å¾ä¸æ´ï¼ä¸¦ä½çºæ²»çç­ç¥çééµæ±ºå®å ç´ ãç¶èï¼æå LA åå²æ¢è²»ååå·æææ°æ§ãæè¿åºç¤æ·±åº¦å­¸ç¿æ¨¡åï¼ä¾å¦å¨ä¸åè³æéä¸é åè¨ç·´ç Segment Anything Model (SAM)ï¼å·²å¨éç¨åå²ä»»åä¸­å±ç¾åºåæ¯ãMedSAM æ¯ SAM çå¾®èª¿çæ¬ï¼é©ç¨æ¼é«çæç¨ï¼å®è½é²è¡ææãé¶æ¬¡å­¸ç¿çåå²ï¼èç¡éç¹å®é åçè¨ç·´ãåç®¡ MedSAM æ¨¡åå·ææ½åï¼ä½å°æªè©ä¼°å¶å¨ 3D LGE-MRI ä¸­ LA åå²çè¤éä»»åãæ¬ç ç©¶æ¨å¨ (1) è©ä¼° MedSAM å¨èªåå LA åå²ä¸­çæè½ï¼(2) æ¯è¼ä½¿ç¨å®ä¸æç¤ºåèªåè¿½è¹¤ç MedSAM2 æ¨¡åèéè¦çºæ¯ååçæä¾å®ç¨æç¤ºç MedSAM1 æ¨¡åçæè½ï¼ä»¥å (3) åæ MedSAM1 å¨éª°å­åæ¸ï¼å³åå²æºç¢ºåº¦ï¼æ¹é¢çæè½ï¼æ¹æ³æ¯æ¹è®æ¹æ¡æç¤ºçå¤§å°åä½ç½®ã

##### **GazeSearch: Radiology Findings Search Benchmark**
2411.05780v1 by Trong Thang Pham, Tien-Phat Nguyen, Yuki Ikebe, Akash Awasthi, Zhigang Deng, Carol C. Wu, Hien Nguyen, Ngan Le

Medical eye-tracking data is an important information source for
understanding how radiologists visually interpret medical images. This
information not only improves the accuracy of deep learning models for X-ray
analysis but also their interpretability, enhancing transparency in
decision-making. However, the current eye-tracking data is dispersed,
unprocessed, and ambiguous, making it difficult to derive meaningful insights.
Therefore, there is a need to create a new dataset with more focus and
purposeful eyetracking data, improving its utility for diagnostic applications.
In this work, we propose a refinement method inspired by the target-present
visual search challenge: there is a specific finding and fixations are guided
to locate it. After refining the existing eye-tracking datasets, we transform
them into a curated visual search dataset, called GazeSearch, specifically for
radiology findings, where each fixation sequence is purposefully aligned to the
task of locating a particular finding. Subsequently, we introduce a scan path
prediction baseline, called ChestSearch, specifically tailored to GazeSearch.
Finally, we employ the newly introduced GazeSearch as a benchmark to evaluate
the performance of current state-of-the-art methods, offering a comprehensive
assessment for visual search in the medical imaging domain.

æè¦ï¼é«çç¼åè¿½è¹¤è³ææ¯äºè§£æ¾å°ç§é«å¸«å¦ä½è¦è¦ºåè©®éé«çå½±åçéè¦è³è¨ä¾æºãéäºè³è¨ä¸åæåäºæ·±åº¦å­¸ç¿æ¨¡åå¨ X ååæä¸­çæºç¢ºåº¦ï¼ä¹æåäºå¶å¯è§£éæ§ï¼å¢é²æ±ºç­å¶å®ä¸­çéæåº¦ãç¶èï¼ç®åçé«çç¼åè¿½è¹¤è³æåæ£ãæªç¶èçä¸ä¸æç¢ºï¼éä½¿å¾é£ä»¥æ¨å°åºææç¾©çè¦è§£ãå æ­¤ï¼æå¿è¦å»ºç«ä¸åæ°çè³æéï¼å¶ä¸­åå«æ´å¤ç¦é»åæç®ççç¼åè¿½è¹¤è³æï¼ä»¥æåå¶å¨è¨ºæ·æç¨ä¸­çæç¨ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ¹è¯æ¹æ³ï¼å¶éæä¾èªç®æ¨åç¾è¦è¦ºæå°ææ°ï¼æä¸åç¹å®çç¼ç¾ï¼èåºå®åç¨æ¼å®ä½å®ãå¨æ¹è¯ç¾æçç¼åè¿½è¹¤è³æéå¾ï¼æåå°å¶è½æçºä¸ååçº GazeSearch çç²¾é¸è¦è¦ºæå°è³æéï¼å°éç¨æ¼æ¾å°ç§ç¼ç¾ï¼å¶ä¸­æ¯ååºå®åºåé½å»æèå®ä½ç¹å®ç¼ç¾çä»»åå°é½ãé¨å¾ï¼æåä»ç´¹äºä¸åææè·¯å¾é æ¸¬åºæºï¼ç¨±çº ChestSearchï¼å°ééå° GazeSearch éèº«æé ãæå¾ï¼æåæ¡ç¨æ°æ¨åºç GazeSearch ä½çºåºæºï¼è©ä¼°ç®åæåé²æ¹æ³çæè½ï¼æä¾é«çå½±åé åä¸­è¦è¦ºæå°çå¨é¢è©ä¼°ã

##### **Humans Continue to Outperform Large Language Models in Complex Clinical Decision-Making: A Study with Medical Calculators**
2411.05897v1 by Nicholas Wan, Qiao Jin, Joey Chan, Guangzhi Xiong, Serina Applebaum, Aidan Gilson, Reid McMurry, R. Andrew Taylor, Aidong Zhang, Qingyu Chen, Zhiyong Lu

Although large language models (LLMs) have been assessed for general medical
knowledge using medical licensing exams, their ability to effectively support
clinical decision-making tasks, such as selecting and using medical
calculators, remains uncertain. Here, we evaluate the capability of both
medical trainees and LLMs to recommend medical calculators in response to
various multiple-choice clinical scenarios such as risk stratification,
prognosis, and disease diagnosis. We assessed eight LLMs, including
open-source, proprietary, and domain-specific models, with 1,009
question-answer pairs across 35 clinical calculators and measured human
performance on a subset of 100 questions. While the highest-performing LLM,
GPT-4o, provided an answer accuracy of 74.3% (CI: 71.5-76.9%), human
annotators, on average, outperformed LLMs with an accuracy of 79.5% (CI:
73.5-85.0%). With error analysis showing that the highest-performing LLMs
continue to make mistakes in comprehension (56.6%) and calculator knowledge
(8.1%), our findings emphasize that humans continue to surpass LLMs on complex
clinical tasks such as calculator recommendation.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) å·²ä½¿ç¨é«å­¸å·ç§èè©¦è©ä¼°å¶ä¸è¬é«å­¸ç¥è­ï¼ä½å®åæææ¯æ´è¨åºæ±ºç­ä»»åï¼ä¾å¦é¸æåä½¿ç¨é«å­¸è¨ç®å¨ï¼çè½åä»ä¸ç¢ºå®ãå¨æ­¤ï¼æåè©ä¼°é«å­¸åè¨èå LLM æ¨è¦é«å­¸è¨ç®å¨çè½åï¼ä»¥åæåç¨®å¤é¸é¡è¨åºæå¢ï¼ä¾å¦é¢¨éªåå±¤ãé å¾åç¾çè¨ºæ·ãæåè©ä¼°äºå«å LLMï¼åæ¬éæºãå°æåç¹å®é åçæ¨¡åï¼å¶ä¸­åå« 35 åè¨åºè¨ç®å¨ç 1,009 ååç­å°ï¼ä¸¦æ¸¬éäºäººé¡å¨ 100 ååé¡å­éä¸çè¡¨ç¾ãè¡¨ç¾æä½³ç LLM GPT-4o æä¾äº 74.3% çåç­æºç¢ºåº¦ (CIï¼71.5-76.9%)ï¼èäººé¡è¨»è§£èå¹³åè¡¨ç¾åªæ¼ LLMï¼æºç¢ºåº¦çº 79.5% (CIï¼73.5-85.0%)ãé¯èª¤åæé¡¯ç¤ºï¼è¡¨ç¾æä½³ç LLM å¨çè§£ (56.6%) åè¨ç®å¨ç¥è­ (8.1%) æ¹é¢ä»æç¯é¯ï¼æåçç ç©¶çµæå¼·èª¿ï¼äººé¡å¨è¨ç®å¨æ¨è¦ç­è¤éè¨åºä»»åä¸ä»ç¶åªæ¼ LLMã

##### **Identifying and Decomposing Compound Ingredients in Meal Plans Using Large Language Models**
2411.05892v1 by Leon Kopitar, Leon Bedrac, Larissa J Strath, Jiang Bian, Gregor Stiglic

This study explores the effectiveness of Large Language Models in meal
planning, focusing on their ability to identify and decompose compound
ingredients. We evaluated three models-GPT-4o, Llama-3 (70b), and Mixtral
(8x7b)-to assess their proficiency in recognizing and breaking down complex
ingredient combinations. Preliminary results indicate that while Llama-3 (70b)
and GPT-4o excels in accurate decomposition, all models encounter difficulties
with identifying essential elements like seasonings and oils. Despite strong
overall performance, variations in accuracy and completeness were observed
across models. These findings underscore LLMs' potential to enhance
personalized nutrition but highlight the need for further refinement in
ingredient decomposition. Future research should address these limitations to
improve nutritional recommendations and health outcomes.

æè¦ï¼éé ç ç©¶æ¢è¨å¤§åèªè¨æ¨¡åå¨é¤é»è¦åä¸­çæè½ï¼èéæ¼å¶è¾¨è­ä¸¦åè§£è¤åé£æçè½åãæåè©ä¼°äºä¸åæ¨¡åï¼GPT-4oãLlama-3 (70b) å Mixtral (8x7b)ï¼ä»¥è©éå¶è¾¨è­ä¸¦åè§£è¤éé£æçµåçè½åãåæ­¥çµæé¡¯ç¤ºï¼éç¶ Llama-3 (70b) å GPT-4o å¨æºç¢ºåè§£æ¹é¢è¡¨ç¾åºè²ï¼ä½æææ¨¡åå¨è¾¨è­èª¿å³æåæ²¹èç­å¿è¦åç´ æé½éå°å°é£ãåç®¡æ´é«è¡¨ç¾å¼·åï¼ä½ååæ¨¡åå¨æºç¢ºæ§åå®æ´æ§æ¹é¢ä»æå·®ç°ãéäºç¼ç¾å¼·èª¿äº LLM å¢å¼·åäººåçé¤çæ½åï¼ä½åæä¹çªé¡¯äºé²ä¸æ­¥åªåé£æåè§£æè¡çå¿è¦æ§ãæªä¾çç ç©¶æéå°éäºéå¶é²è¡æ¢è¨ï¼ä»¥æ¹åçé¤å»ºè­°åå¥åº·ææã

##### **SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark**
2411.05521v1 by Sithursan Sivasubramaniam, Cedric Osei-Akoto, Yi Zhang, Kurt Stockinger, Jonathan Fuerst

Electronic health records (EHRs) are stored in various database systems with
different database models on heterogeneous storage architectures, such as
relational databases, document stores, or graph databases. These different
database models have a big impact on query complexity and performance. While
this has been a known fact in database research, its implications for the
growing number of Text-to-Query systems have surprisingly not been investigated
so far. In this paper, we present SM3-Text-to-Query, the first multi-model
medical Text-to-Query benchmark based on synthetic patient data from Synthea,
following the SNOMED-CT taxonomy -- a widely used knowledge graph ontology
covering medical terminology. SM3-Text-to-Query provides data representations
for relational databases (PostgreSQL), document stores (MongoDB), and graph
databases (Neo4j and GraphDB (RDF)), allowing the evaluation across four
popular query languages, namely SQL, MQL, Cypher, and SPARQL. We systematically
and manually develop 408 template questions, which we augment to construct a
benchmark of 10K diverse natural language question/query pairs for these four
query languages (40K pairs overall). On our dataset, we evaluate several common
in-context-learning (ICL) approaches for a set of representative closed and
open-source LLMs. Our evaluation sheds light on the trade-offs between database
models and query languages for different ICL strategies and LLMs. Last,
SM3-Text-to-Query is easily extendable to additional query languages or real,
standard-based patient databases.

æè¦ï¼é»å­å¥åº·ç´é (EHR) å²å­å¨åç¨®è³æåº«ç³»çµ±ä¸­ï¼éäºç³»çµ±å¨ç°è³ªå²å­æ¶æ§ä¸å·æä¸åçè³æåº«æ¨¡åï¼ä¾å¦éè¯å¼è³æåº«ãæä»¶å²å­æåå½¢è³æåº«ãéäºä¸åçè³æåº«æ¨¡åå°æ¥è©¢è¤éåº¦åæè½æå¾å¤§çå½±é¿ãéç¶éå¨è³æåº«ç ç©¶ä¸­å·²ç¶æ¯ç¾æå¨ç¥çäºå¯¦ï¼ä½ä»¤äººé©è¨çæ¯ï¼å®å°æ¥çå¢å çæå­è½æ¥è©¢ç³»çµ±çå½±é¿è¿ä»å°æªå¾å°èª¿æ¥ãå¨æ¬æä¸­ï¼æåæåº SM3-Text-to-Queryï¼éæ¯ç¬¬ä¸ååºæ¼ä¾èª Synthea çåææ£èè³æçå¤æ¨¡åé«çæå­è½æ¥è©¢åºæºï¼éµå¾ª SNOMED-CT åé¡æ³ââä¸ç¨®å»£æ³ä½¿ç¨çæ¶µèé«å­¸è¡èªçç¥è­åè­æ¬é«ãSM3-Text-to-Query æä¾äºéè¯å¼è³æåº« (PostgreSQL)ãæä»¶å²å­ (MongoDB) ååå½¢è³æåº« (Neo4j å GraphDB (RDF)) çè³æè¡¨ç¤ºï¼åè¨±è·¨åç¨®æµè¡æ¥è©¢èªè¨ï¼å³ SQLãMQLãCypher å SPARQLï¼é²è¡è©ä¼°ãæåç³»çµ±ä¸æåéç¼äº 408 åç¯æ¬åé¡ï¼æåæ´åéäºåé¡ä»¥æ§å»ºä¸ååºæºï¼å¶ä¸­åå« 10K åéå°éåç¨®æ¥è©¢èªè¨çå¤æ¨£åèªç¶èªè¨åé¡/æ¥è©¢å°ï¼ç¸½å± 40K å°ï¼ãå¨æåçè³æéä¸ï¼æåè©ä¼°äºå¹¾ç¨®å¸¸è¦çä»£è¡¨æ§éæºåéæº LLM çæå¢å­¸ç¿ (ICL) æ¹æ³ãæåçè©ä¼°æ­ç¤ºäºä¸å ICL ç­ç¥å LLM çè³æåº«æ¨¡ååæ¥è©¢èªè¨ä¹éçåæ¨ãæå¾ï¼SM3-Text-to-Query å¯ä»¥è¼é¬æ´å±å°å¶ä»æ¥è©¢èªè¨æçå¯¦çåºæ¼æ¨æºçæ£èè³æåº«ã

##### **Towards Scalable Foundation Models for Digital Dermatology**
2411.05514v1 by Fabian GrÃ¶ger, Philippe Gottfrois, Ludovic Amruthalingam, Alvaro Gonzalez-Jimenez, Simone Lionetti, Luis R. Soenksen-Martinez, Alexander A. Navarini, Marc Pouly

The growing demand for accurate and equitable AI models in digital
dermatology faces a significant challenge: the lack of diverse, high-quality
labeled data. In this work, we investigate the potential of domain-specific
foundation models for dermatology in addressing this challenge. We utilize
self-supervised learning (SSL) techniques to pre-train models on a dataset of
over 240,000 dermatological images from public and private collections. Our
study considers several SSL methods and compares the resulting foundation
models against domain-agnostic models like those pre-trained on ImageNet and
state-of-the-art models such as MONET across 12 downstream tasks. Unlike
previous research, we emphasize the development of smaller models that are more
suitable for resource-limited clinical settings, facilitating easier adaptation
to a broad range of use cases. Results show that models pre-trained in this
work not only outperform general-purpose models but also approach the
performance of models 50 times larger on clinically relevant diagnostic tasks.
To promote further research in this direction, we publicly release both the
training code and the foundation models, which can benefit clinicians in
dermatological applications.

æè¦ï¼æ¸ä½ç®èç§å°ç²¾æºä¸å¬å¹³ç AI æ¨¡åéæ±æ¥çå¢å ï¼ä½é¢è¨ä¸é éå¤§ææ°ï¼ç¼ºä¹å¤åä¸é«åè³ªçæ¨è¨è³æãå¨éé ç ç©¶ä¸­ï¼æåæ¢è¨ç¹å®é åçåºç¤æ¨¡åå¨ç®èç§ä¸­è§£æ±ºæ­¤ææ°çå¯è½æ§ãæåå©ç¨èªç£ç£å­¸ç¿ (SSL) æè¡å¨åå«è¶é 24 è¬å¼µä¾èªå¬æåç§æè³æåº«çç®èç§å½±åçè³æéä¸é åè¨ç·´æ¨¡åãæåçç ç©¶èéäºå¤ç¨® SSL æ¹æ³ï¼ä¸¦å°ç¢ççåºç¤æ¨¡åèä¸åé åéå¶çæ¨¡åï¼ä¾å¦å¨ ImageNet ä¸é åè¨ç·´çæ¨¡åï¼ä»¥åæåé²çæ¨¡åï¼ä¾å¦ MONETï¼å¨ 12 åä¸æ¸¸ä»»åä¸­é²è¡æ¯è¼ãèååçç ç©¶ä¸åï¼æåå¼·èª¿éç¼æ´é©åè³æºæéçè¨åºç°å¢çå°åæ¨¡åï¼ä»¥å©æ¼æ´è¼é¬å°é©æå»£æ³çç¨ä¾ãçµæé¡¯ç¤ºï¼å¨éé ç ç©¶ä¸­é åè¨ç·´çæ¨¡åä¸ååªæ¼éç¨æ¨¡åï¼èä¸å¨è¨åºä¸ç¸éçè¨ºæ·ä»»åä¸­ï¼å¶æè½ä¹æ¥è¿å¤§ 50 åçæ¨¡åãçºäºä¿é²æ­¤æ¹åçé²ä¸æ­¥ç ç©¶ï¼æåå¬éç¼å¸è¨ç·´ç¨å¼ç¢¼ååºç¤æ¨¡åï¼éäºæ¨¡åå¯è®ç®èç§æç¨ä¸­çè¨åºé«çåçã

##### **Towards Equitable ASD Diagnostics: A Comparative Study of Machine and Deep Learning Models Using Behavioral and Facial Data**
2411.05880v1 by Mohammed Aledhari, Mohamed Rahouti, Ali Alfatemi

Autism Spectrum Disorder (ASD) is often underdiagnosed in females due to
gender-specific symptom differences overlooked by conventional diagnostics.
This study evaluates machine learning models, particularly Random Forest and
convolutional neural networks, for enhancing ASD diagnosis through structured
data and facial image analysis. Random Forest achieved 100% validation accuracy
across datasets, highlighting its ability to manage complex relationships and
reduce false negatives, which is crucial for early intervention and addressing
gender biases. In image-based analysis, MobileNet outperformed the baseline
CNN, achieving 87% accuracy, though a 30% validation loss suggests possible
overfitting, requiring further optimization for robustness in clinical
settings. Future work will emphasize hyperparameter tuning, regularization, and
transfer learning. Integrating behavioral data with facial analysis could
improve diagnosis for underdiagnosed groups. These findings suggest Random
Forest's high accuracy and balanced precision-recall metrics could enhance
clinical workflows. MobileNet's lightweight structure also shows promise for
resource-limited environments, enabling accessible ASD screening. Addressing
model explainability and clinician trust will be vital.

æè¦ï¼èªéçè­ç³»éç¤ (ASD) ç±æ¼æ§å¥ç¹ç°çççå·®ç°ï¼å¸¸è¢«å¿½ç¥èæ¼è¨ºãæ¬ç ç©¶è©ä¼°æ©å¨å­¸ç¿æ¨¡åï¼ç¹å¥æ¯é¨æ©æ£®æåå·ç©ç¥ç¶ç¶²è·¯ï¼ä»¥ééçµæ§åè³æåèé¨å½±ååæä¾å¼·å ASD è¨ºæ·ãé¨æ©æ£®æå¨ææè³æéä¸­çé©è­æºç¢ºåº¦éå° 100%ï¼çªé¡¯å¶èçè¤ééä¿åæ¸å°åé°æ§çè½åï¼éå°æ¼æ©æä»å¥åè§£æ±ºæ§å¥åè¦è³ééè¦ãå¨åºæ¼å½±åçåæä¸­ï¼MobileNet åªæ¼åºæº CNNï¼æºç¢ºåº¦éå° 87%ï¼åç®¡ 30% çé©è­æå¤±è¡¨æå¯è½éåº¦æ¬åï¼éè¦é²ä¸æ­¥æä½³åä»¥æé«è¨åºç°å¢ä¸­çç©©å¥æ§ãæªä¾çç ç©¶å°å¼·èª¿è¶åæ¸èª¿æ´ãæ­£åååé·ç§»å­¸ç¿ãå°è¡çºè³æèèé¨åææ´åï¼å¯ä»¥æ¹åæ¼è¨ºç¾¤é«çè¨ºæ·ãéäºç¼ç¾è¡¨æé¨æ©æ£®æçé«æºç¢ºåº¦åå¹³è¡¡çç²¾ç¢ºåº¦å¬åææ¨å¯ä»¥å¢å¼·è¨åºå·¥ä½æµç¨ãMobileNet çè¼éç´çµæ§ä¹é¡¯ç¤ºåºå¨è³æºåéçç°å¢ä¸­å¾æåæ¯ï¼å¯ä»¥é²è¡ç¡éç¤ç ASD ç¯©æª¢ãè§£æ±ºæ¨¡åå¯è§£éæ§åè¨åºé«å¸«çä¿¡ä»»è³ééè¦ã

##### **Interactive Dialogue Agents via Reinforcement Learning on Hindsight Regenerations**
2411.05194v1 by Joey Hong, Jessica Lin, Anca Dragan, Sergey Levine

Recent progress on large language models (LLMs) has enabled dialogue agents
to generate highly naturalistic and plausible text. However, current LLM
language generation focuses on responding accurately to questions and requests
with a single effective response. In reality, many real dialogues are
interactive, meaning an agent's utterances will influence their conversational
partner, elicit information, or change their opinion. Accounting for how an
agent can effectively steer a conversation is a crucial ability in many
dialogue tasks, from healthcare to preference elicitation. Existing methods for
fine-tuning dialogue agents to accomplish such tasks would rely on curating
some amount of expert data. However, doing so often requires understanding the
underlying cognitive processes of the conversational partner, which is a skill
neither humans nor LLMs trained on human data can reliably do. Our key insight
is that while LLMs may not be adept at identifying effective strategies for
steering conversations a priori, or in the middle of an ongoing conversation,
they can do so post-hoc, or in hindsight, after seeing how their conversational
partner responds. We use this fact to rewrite and augment existing suboptimal
data, and train via offline reinforcement learning (RL) an agent that
outperforms both prompting and learning from unaltered human demonstrations. We
apply our approach to two domains that require understanding human mental
state, intelligent interaction, and persuasion: mental health support, and
soliciting charitable donations. Our results in a user study with real humans
show that our approach greatly outperforms existing state-of-the-art dialogue
agents.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±ä½¿å°è©±ä»£çè½å¤ çæé«åº¦èªç¶ä¸åççæå­ãç¶èï¼ç®åç LLM èªè¨çæèéæ¼ä»¥å®ä¸ææçåææºç¢ºåæåé¡åè¦æ±ãå¨ç¾å¯¦ä¸­ï¼è¨±å¤çå¯¦å°è©±é½æ¯äºåçï¼éè¡¨ç¤ºä»£çäººçç¼è¨æå½±é¿ä»åçå°è©±å¤¥ä¼´ãå¼åºè³è¨ææ¹è®ä»åçæè¦ãèéä»£çäººå¦ä½ææå¼å°å°è©±çè½åå¨è¨±å¤å°è©±ä»»åä¸­è³ééè¦ï¼å¾é«çä¿å¥å°åå¥½å¼å°çæ¯å¦æ­¤ãç¾æçå¾®èª¿å°è©±ä»£çæ¹æ³ä»¥å®ææ­¤é¡ä»»åæä¾è³´æ¼ç­åä¸å®éçå°å®¶è³æãç¶èï¼ééº¼åéå¸¸éè¦äºè§£å°è©±å¤¥ä¼´çåºç¤èªç¥æ­·ç¨ï¼èéé æè½æ¢ä¸æ¯äººé¡ä¹ä¸æ¯è¨ç·´éäººé¡è³æç LLM å¯é å·åçãæåçééµè¦è§£å¨æ¼ï¼åç®¡ LLM å¯è½ä¸æé·æ¼äºåæå¨å°è©±é²è¡ä¸­è­å¥åºå¼å°å°è©±çææç­ç¥ï¼ä½ä»åå¯ä»¥å¨äºå¾æåé¡§æï¼å¨çå°ä»åçå°è©±å¤¥ä¼´å¦ä½åæå¾ééº¼åãæåå©ç¨éåäºå¯¦ä¾æ¹å¯«ä¸¦æ´åç¾æçæ¬¡ä½³è³æï¼ä¸¦ééé¢ç·å¼·åå­¸ç¿ (RL) è¨ç·´ä¸åä»£çäººï¼å¶è¡¨ç¾åªæ¼æç¤ºåå¾æªç¶ä¿®æ¹çäººé¡ç¤ºç¯ä¸­å­¸ç¿ãæåå°æåçåæ³æç¨æ¼éè¦äºè§£äººé¡å¿ççæãæºæ§äºååèªªæçå©åé åï¼å¿çå¥åº·æ¯æååéæåææ¬¾ãæåå¨èçå¯¦äººé¡é²è¡çä½¿ç¨èç ç©¶ä¸­ççµæé¡¯ç¤ºï¼æåçåæ³å¤§å¹åªæ¼ç¾æçæåé²å°è©±ä»£çã

##### **Inverse Transition Learning: Learning Dynamics from Demonstrations**
2411.05174v1 by Leo Benac, Abhishek Sharma, Sonali Parbhoo, Finale Doshi-Velez

We consider the problem of estimating the transition dynamics $T^*$ from
near-optimal expert trajectories in the context of offline model-based
reinforcement learning. We develop a novel constraint-based method, Inverse
Transition Learning, that treats the limited coverage of the expert
trajectories as a \emph{feature}: we use the fact that the expert is
near-optimal to inform our estimate of $T^*$. We integrate our constraints into
a Bayesian approach. Across both synthetic environments and real healthcare
scenarios like Intensive Care Unit (ICU) patient management in hypotension, we
demonstrate not only significant improvements in decision-making, but that our
posterior can inform when transfer will be successful.

æè¦ï¼æåèæ®å¨é¢ç·æ¨¡ååºç¤å¼·åå­¸ç¿çèçµ¡ä¸­ï¼å¾æ¥è¿æä½³çå°å®¶è»è·¡ä¼°è¨è½æåæ $T^*$ çåé¡ãæåéç¼ä¸ç¨®æ°çåºæ¼ç´æçæ¹æ³ï¼éè½æå­¸ç¿ï¼å®å°å°å®¶è»è·¡çæéè¦èç¯åè¦çºä¸ç¨®ãç¹å¾µãï¼æåå©ç¨å°å®¶æ¥è¿æä½³çäºå¯¦ä¾åç¥æåå° $T^*$ çä¼°è¨ãæåå°æåçç´ææ´åå°è²æ°æ¹æ³ä¸­ãå¨ç¶åç°å¢åå¯¦éé«çä¿å¥å ´æ¯ï¼ä¾å¦ä½è¡å£éçç£è­·çæ¿ (ICU) çæ£ç®¡çï¼ä¸­ï¼æåä¸åå±ç¤ºäºæ±ºç­å¶å®æ¹é¢çé¡¯èé²æ­¥ï¼èä¸æåçå¾é©å¯ä»¥åç¥è½ç§»ä½æææåã

##### **PadChest-GR: A Bilingual Chest X-ray Dataset for Grounded Radiology Report Generation**
2411.05085v1 by Daniel C. Castro, Aurelia Bustos, Shruthi Bannur, Stephanie L. Hyland, Kenza Bouzid, Maria Teodora Wetscherek, Maria Dolores SÃ¡nchez-Valverde, Lara Jaques-PÃ©rez, Lourdes PÃ©rez-RodrÃ­guez, Kenji Takeda, JosÃ© MarÃ­a Salinas, Javier Alvarez-Valle, JoaquÃ­n Galant Herrero, Antonio Pertusa

Radiology report generation (RRG) aims to create free-text radiology reports
from clinical imaging. Grounded radiology report generation (GRRG) extends RRG
by including the localisation of individual findings on the image. Currently,
there are no manually annotated chest X-ray (CXR) datasets to train GRRG
models. In this work, we present a dataset called PadChest-GR
(Grounded-Reporting) derived from PadChest aimed at training GRRG models for
CXR images. We curate a public bi-lingual dataset of 4,555 CXR studies with
grounded reports (3,099 abnormal and 1,456 normal), each containing complete
lists of sentences describing individual present (positive) and absent
(negative) findings in English and Spanish. In total, PadChest-GR contains
7,037 positive and 3,422 negative finding sentences. Every positive finding
sentence is associated with up to two independent sets of bounding boxes
labelled by different readers and has categorical labels for finding type,
locations, and progression. To the best of our knowledge, PadChest-GR is the
first manually curated dataset designed to train GRRG models for understanding
and interpreting radiological images and generated text. By including detailed
localization and comprehensive annotations of all clinically relevant findings,
it provides a valuable resource for developing and evaluating GRRG models from
CXR images. PadChest-GR can be downloaded under request from
https://bimcv.cipf.es/bimcv-projects/padchest-gr/

æè¦ï¼<paragraph>æ¾å°å­¸å ±åçæ (RRG) æ¨å¨å¾è¨åºå½±åå»ºç«èªç±æå­çæ¾å°å­¸å ±åãåºç¤æ¾å°å­¸å ±åçæ (GRRG) ééç´å¥å½±åä¸åå¥ç¼ç¾çå®ä½ï¼ä¾å»¶ä¼¸ RRGãç®åï¼æ²ææåæ¨è¨çè¸é¨ X å (CXR) è³æéï¼å¯ä¾è¨ç·´ GRRG æ¨¡åãå¨æ­¤ç ç©¶ä¸­ï¼æåæåºä¸ååçº PadChest-GRï¼åºç¤å ±åï¼çè³æéï¼å¶æºèª PadChestï¼æ¨å¨è¨ç·´ CXR å½±åç GRRG æ¨¡åãæåç­åäºä¸åå¬éçéèªè³æéï¼å¶ä¸­åå« 4,555 ä»½ CXR ç ç©¶ï¼éæåºç¤å ±åï¼3,099 ä»½ç°å¸¸å ±åå 1,456 ä»½æ­£å¸¸å ±åï¼ï¼æ¯åå ±åé½åå«å®æ´çå¥å­æ¸å®ï¼ç¨è±æåè¥¿ç­çææè¿°åå¥å­å¨çï¼é½æ§ï¼åä¸å­å¨çï¼é°æ§ï¼ç¼ç¾ãç¸½è¨ï¼PadChest-GR åå« 7,037 åé½æ§ç¼ç¾å¥å­å 3,422 åé°æ§ç¼ç¾å¥å­ãæ¯åé½æ§ç¼ç¾å¥å­æå¤èå©çµç¨ç«çéçæ¡ç¸éè¯ï¼ç±ä¸åçè®èæ¨è¨ï¼ä¸¦å·æç¼ç¾é¡åãä½ç½®åé²å±çåé¡æ¨ç±¤ãææåæç¥ï¼PadChest-GR æ¯ç¬¬ä¸åæåç­åçè³æéï¼æ¨å¨è¨ç·´ GRRG æ¨¡åï¼ä»¥çè§£åè©®éæ¾å°å­¸å½±ååç¢ççæå­ãééç´å¥ææè¨åºç¸éç¼ç¾çè©³ç´°å®ä½åç¶åè¨»è§£ï¼å®çºå¾ CXR å½±åéç¼åè©ä¼° GRRG æ¨¡åæä¾äºå¯¶è²´çè³æºãPadChest-GR å¯æè¦æ±å¾ https://bimcv.cipf.es/bimcv-projects/padchest-gr/ ä¸è¼</paragraph>

##### **Position Paper On Diagnostic Uncertainty Estimation from Large Language Models: Next-Word Probability Is Not Pre-test Probability**
2411.04962v1 by Yanjun Gao, Skatje Myers, Shan Chen, Dmitriy Dligach, Timothy A Miller, Danielle Bitterman, Guanhua Chen, Anoop Mayampurath, Matthew Churpek, Majid Afshar

Large language models (LLMs) are being explored for diagnostic decision
support, yet their ability to estimate pre-test probabilities, vital for
clinical decision-making, remains limited. This study evaluates two LLMs,
Mistral-7B and Llama3-70B, using structured electronic health record data on
three diagnosis tasks. We examined three current methods of extracting LLM
probability estimations and revealed their limitations. We aim to highlight the
need for improved techniques in LLM confidence estimation.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æ­£å¨è¢«æ¢ç´¢ç¨æ¼è¨ºæ·æ±ºç­æ¯æï¼ä½å®åä¼°è¨è¨åºæ±ºç­å¶å®ä¸­è³ééè¦çé æ¸¬è©¦æ¦ççè½åä»ç¶æéãæ¬ç ç©¶ä½¿ç¨ä¸åè¨ºæ·ä»»åççµæ§åé»å­å¥åº·è¨éæ¸æè©ä¼°äºå©å LLMï¼Mistral-7B å Llama3-70Bãæåæª¢æ¥äºæå LLM æ¦çä¼°è¨çä¸ç¨®ç¶åæ¹æ³ä¸¦æ­ç¤ºäºå®åçå±éæ§ãæåçç®æ¨æ¯å¼·èª¿æ¹é² LLM ç½®ä¿¡åº¦ä¼°è¨æè¡çå¿è¦æ§ã

##### **FineTuneBench: How well do commercial fine-tuning APIs infuse knowledge into LLMs?**
2411.05059v1 by Eric Wu, Kevin Wu, James Zou

There is great interest in fine-tuning frontier large language models (LLMs)
to inject new information and update existing knowledge. While commercial LLM
fine-tuning APIs from providers such as OpenAI and Google promise flexible
adaptation for various applications, the efficacy of fine-tuning remains
unclear. In this study, we introduce FineTuneBench, an evaluation framework and
dataset for understanding how well commercial fine-tuning APIs can successfully
learn new and updated knowledge. We analyze five frontier LLMs with
commercially available fine-tuning APIs, including GPT-4o and Gemini 1.5 Pro,
on their effectiveness in two settings: (1) ingesting novel information, such
as recent news events and new people profiles, and (2) updating existing
knowledge, such as updated medical guidelines and code frameworks. Our results
reveal substantial shortcomings in all the models' abilities to effectively
learn new information through fine-tuning, with an average generalization
accuracy of 37% across all models. When updating existing knowledge, such as
incorporating medical guideline updates, commercial fine-tuning APIs show even
more limited capability (average generalization accuracy of 19%). Overall,
fine-tuning GPT-4o mini is the most effective for infusing new knowledge and
updating knowledge, followed by GPT-3.5 Turbo and GPT-4o. The fine-tuning APIs
for Gemini 1.5 Flesh and Gemini 1.5 Pro are unable to learn new knowledge or
update existing knowledge. These findings underscore a major shortcoming in
using current commercial fine-tuning services to achieve reliable knowledge
infusion in common scenarios. We open source the FineTuneBench dataset at
https://github.com/kevinwu23/StanfordFineTuneBench.

æè¦ï¼<paragraph>å°æ¼å¾®èª¿åæ²¿å¤§åèªè¨æ¨¡å (LLM) ä»¥æ³¨å¥æ°è³è¨åæ´æ°ç¾æç¥è­ï¼å­å¨æ¥µå¤§çèè¶£ãéç¶ä¾èª OpenAI å Google ç­ä¾æåçåç¨ LLM å¾®èª¿ API æ¿è«¾éæ´»é©æåç¨®æç¨ï¼ä½å¾®èª¿çæè½ä»ä¸æç¢ºãå¨éé ç ç©¶ä¸­ï¼æåå¼å¥äº FineTuneBenchï¼éæ¯ä¸åè©ä¼°æ¶æ§åè³æéï¼ç¨æ¼äºè§£åç¨å¾®èª¿ API å¦ä½æåå­¸ç¿æ°çåæ´æ°çç¥è­ãæååæäºäºåå·æåç¨å¾®èª¿ API çåæ²¿ LLMï¼åæ¬ GPT-4o å Gemini 1.5 Proï¼å¨å©ç¨®è¨­å®ä¸­çæè½ï¼(1) å¸æ¶æ°è³è¨ï¼ä¾å¦æè¿çæ°èäºä»¶åæ°äººç©ç°¡ä»ï¼ä»¥å (2) æ´æ°ç¾æç¥è­ï¼ä¾å¦æ´æ°çé«çæååç¨å¼ç¢¼æ¶æ§ãæåççµææ­ç¤ºäºæææ¨¡åå¨ééå¾®èª¿ææå­¸ç¿æ°è³è¨çè½åæ¹é¢å­å¨éå¤§ç¼ºé·ï¼æææ¨¡åçå¹³åæ¦åæºç¢ºåº¦çº 37%ãå¨æ´æ°ç¾æç¥è­ï¼ä¾å¦ç´å¥é«çæåæ´æ°ï¼æï¼åç¨å¾®èª¿ API é¡¯ç¤ºåºæ´æéçè½åï¼å¹³åæ¦åæºç¢ºåº¦çº 19%ï¼ãç¸½é«èè¨ï¼å¾®èª¿ GPT-4o mini å¨çè¼¸æ°ç¥è­åæ´æ°ç¥è­æ¹é¢æææï¼å¶æ¬¡æ¯ GPT-3.5 Turbo å GPT-4oãGemini 1.5 Flesh å Gemini 1.5 Pro çå¾®èª¿ API ç¡æ³å­¸ç¿æ°ç¥è­ææ´æ°ç¾æç¥è­ãéäºç¼ç¾å¼·èª¿äºå¨å¸¸è¦å ´æ¯ä¸­ä½¿ç¨ç®åçåç¨å¾®èª¿æåä¾å¯¦ç¾å¯é ç¥è­çè¼¸çä¸»è¦ç¼ºé»ãæåå¨ https://github.com/kevinwu23/StanfordFineTuneBench éæºäº FineTuneBench è³æéã</paragraph>

##### **Integrating Large Language Models for Genetic Variant Classification**
2411.05055v1 by Youssef Boulaimen, Gabriele Fossi, Leila Outemzabet, Nathalie Jeanray, Oleksandr Levenets, Stephane Gerart, Sebastien Vachenc, Salvatore Raieli, Joanna Giemza

The classification of genetic variants, particularly Variants of Uncertain
Significance (VUS), poses a significant challenge in clinical genetics and
precision medicine. Large Language Models (LLMs) have emerged as transformative
tools in this realm. These models can uncover intricate patterns and predictive
insights that traditional methods might miss, thus enhancing the predictive
accuracy of genetic variant pathogenicity.
  This study investigates the integration of state-of-the-art LLMs, including
GPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data
alongside structural insights to form a comprehensive analytical framework for
variant classification. Our approach evaluates these integrated models using
the well-annotated ProteinGym and ClinVar datasets, setting new benchmarks in
classification performance. The models were rigorously tested on a set of
challenging variants, demonstrating substantial improvements over existing
state-of-the-art tools, especially in handling ambiguous and clinically
uncertain variants.
  The results of this research underline the efficacy of combining multiple
modeling approaches to significantly refine the accuracy and reliability of
genetic variant classification systems. These findings support the deployment
of these advanced computational models in clinical environments, where they can
significantly enhance the diagnostic processes for genetic disorders,
ultimately pushing the boundaries of personalized medicine by offering more
detailed and actionable genetic insights.

æè¦ï¼éºå³è®ç°çåé¡ï¼ç¹å¥æ¯ä¸ç¢ºå®æç¾©è®ç°ï¼VUSï¼ï¼å°è¨åºéºå³å­¸åç²¾æºé«çæåºäºéå¤§ææ°ãå¤§åèªè¨æ¨¡åï¼LLMï¼å·²æçºéåé åçè®é©æ§å·¥å·ãéäºæ¨¡åå¯ä»¥æ­ç¤ºå³çµ±æ¹æ³å¯è½éºæ¼çè¤éæ¨¡å¼åé æ¸¬è¦è§£ï¼å¾èæé«éºå³è®ç°è´çæ§çé æ¸¬æºç¢ºåº¦ã
æ¬ç ç©¶èª¿æ¥äºæåé² LLM çæ´åï¼åæ¬ GPN-MSAãESM1b å AlphaMissenseï¼éäº LLM å©ç¨ DNA åèç½è³ªåºåæ¸æä»¥åçµæ§è¦è§£ï¼å½¢æäºä¸åå¨é¢çè®ç°åé¡åææ¡æ¶ãæåçåæ³ä½¿ç¨æ¨è¨»å®åç ProteinGym å ClinVar æ¸æéä¾è©ä¼°éäºæ´åæ¨¡åï¼å¨åé¡æè½ä¸è¨­å®äºæ°çåºæºãéäºæ¨¡åç¶éå´æ ¼æ¸¬è©¦ï¼ä½¿ç¨ä¸çµå·æææ°æ§çè®ç°ï¼è­æäºå°ç¾ææåé²å·¥å·çå¯¦è³ªæ§æ¹é²ï¼ç¹å¥æ¯å¨èçæ¨¡ç¨å©å¯åè¨åºä¸ä¸ç¢ºå®çè®ç°æ¹é¢ã
éé ç ç©¶ççµæå¼·èª¿äºçµåå¤ç¨®å»ºæ¨¡æ¹æ³ä»¥é¡¯èæé«éºå³è®ç°åé¡ç³»çµ±çæºç¢ºåº¦åå¯é æ§çæææ§ãéäºç¼ç¾æ¯æå¨è¨åºç°å¢ä¸­é¨ç½²éäºåé²çè¨ç®æ¨¡åï¼å®åå¯ä»¥å¨é£è£¡é¡¯èå¢å¼·éºå³ç¾ççè¨ºæ·ç¨åºï¼æçµééæä¾æ´è©³ç´°ä¸å¯æä½çéºå³è¦è§£ä¾çªç ´åäººåé«çççéã

##### **AWARE Narrator and the Utilization of Large Language Models to Extract Behavioral Insights from Smartphone Sensing Data**
2411.04691v1 by Tianyi Zhang, Miu Kojima, Simon D'Alfonso

Smartphones, equipped with an array of sensors, have become valuable tools
for personal sensing. Particularly in digital health, smartphones facilitate
the tracking of health-related behaviors and contexts, contributing
significantly to digital phenotyping, a process where data from digital
interactions is analyzed to infer behaviors and assess mental health.
Traditional methods process raw sensor data into information features for
statistical and machine learning analyses. In this paper, we introduce a novel
approach that systematically converts smartphone-collected data into
structured, chronological narratives. The AWARE Narrator translates
quantitative smartphone sensing data into English language descriptions,
forming comprehensive narratives of an individual's activities. We apply the
framework to the data collected from university students over a week,
demonstrating the potential of utilizing the narratives to summarize individual
behavior, and analyzing psychological states by leveraging large language
models.

æè¦ï¼æºæ§åææ©éåäºåå¼ææ¸¬å¨ï¼å·²æçºåäººææ¸¬çå¯¶è²´å·¥å·ãç¹å¥æ¯å¨æ¸ä½å¥åº·é åï¼æºæ§åææ©ä¿é²äºå¥åº·ç¸éè¡çºåæå¢çè¿½è¹¤ï¼å°æ¸ä½è¡¨ååæååºäºéå¤§è²¢ç»ï¼æ¸ä½è¡¨ååææ¯ä¸ç¨®å¾æ¸ä½äºåä¸­åæè³æä»¥æ¨è«è¡çºåè©ä¼°å¿çå¥åº·çç¨åºãå³çµ±æ¹æ³å°åå§ææ¸¬å¨è³æèçæè³è¨ç¹å¾µï¼ä»¥é²è¡çµ±è¨åæ©å¨å­¸ç¿åæãå¨æ¬æä¸­ï¼æåä»ç´¹ä¸ç¨®æ°ç©çæ¹æ³ï¼è©²æ¹æ³ç³»çµ±æ§å°å°æºæ§åææ©æ¶éçè³æè½ææçµæ§åçæéé åºæäºãAWARE Narrator å°å®éçæºæ§åææ©ææ¸¬è³æè½ææè±æèªè¨æè¿°ï¼å½¢æåäººæ´»åçç¶åæäºãæåå°æ­¤æ¶æ§å¥ç¨å¨å¤§å­¸çä¸é±å§æ¶éçè³æä¸ï¼è­æäºå©ç¨æäºç¸½çµåäººè¡çºçæ½åï¼ä¸¦éééç¨å¤§åèªè¨æ¨¡åä¾åæå¿ççæã

##### **FedDP: Privacy-preserving method based on federated learning for histopathology image segmentation**
2411.04509v1 by Liangrui Pan, Mao Huang, Lian Wang, Pinle Qin, Shaoliang Peng

Hematoxylin and Eosin (H&E) staining of whole slide images (WSIs) is
considered the gold standard for pathologists and medical practitioners for
tumor diagnosis, surgical planning, and post-operative assessment. With the
rapid advancement of deep learning technologies, the development of numerous
models based on convolutional neural networks and transformer-based models has
been applied to the precise segmentation of WSIs. However, due to privacy
regulations and the need to protect patient confidentiality, centralized
storage and processing of image data are impractical. Training a centralized
model directly is challenging to implement in medical settings due to these
privacy concerns.This paper addresses the dispersed nature and privacy
sensitivity of medical image data by employing a federated learning framework,
allowing medical institutions to collaboratively learn while protecting patient
privacy. Additionally, to address the issue of original data reconstruction
through gradient inversion during the federated learning training process,
differential privacy introduces noise into the model updates, preventing
attackers from inferring the contributions of individual samples, thereby
protecting the privacy of the training data.Experimental results show that the
proposed method, FedDP, minimally impacts model accuracy while effectively
safeguarding the privacy of cancer pathology image data, with only a slight
decrease in Dice, Jaccard, and Acc indices by 0.55%, 0.63%, and 0.42%,
respectively. This approach facilitates cross-institutional collaboration and
knowledge sharing while protecting sensitive data privacy, providing a viable
solution for further research and application in the medical field.

æè¦ï¼èæ¨ç²¾åä¼ç´ï¼H&Eï¼æè²å¨åçååï¼WSIï¼è¢«èªçºæ¯ççå­¸å®¶åé«çå¾æ¥­äººå¡ç¨æ¼è«ç¤è¨ºæ·ãæè¡è¦ååè¡å¾è©ä¼°çé»éæ¨æºãé¨èæ·±åº¦å­¸ç¿æè¡çå¿«éé²å±ï¼åºæ¼å·ç©ç¥ç¶ç¶²è·¯ååºæ¼Transformerçæ¨¡åçç¾å¤æ¨¡åå·²è¢«æç¨æ¼ WSI çç²¾ç¢ºåå²ãç¶èï¼ç±æ¼é±ç§æ³è¦åä¿è­·æ£èæ©å¯æ§çéè¦ï¼éä¸­å¼å²å­åèçå½±åè³ææ¯ä¸åå¯¦éçãç±æ¼éäºé±ç§åé¡ï¼å¨é«çç°å¢ä¸­ç´æ¥è¨ç·´éä¸­å¼æ¨¡åé£ä»¥å¯¦æ½ãæ¬æééæ¡ç¨è¯åå­¸ç¿æ¡æ¶ä¾è§£æ±ºé«çå½±åè³æçåæ£æ§è³ªåé±ç§æææ§ï¼åè¨±é«çæ©æ§å¨ä¿è­·æ£èé±ç§çåæé²è¡åä½å­¸ç¿ãæ­¤å¤ï¼çºäºè§£æ±ºè¯åå­¸ç¿è¨ç·´éç¨ä¸­ééæ¢¯åº¦åè½é²è¡åå§è³æéå»ºçåé¡ï¼å·®åé±ç§æå¨æ¨¡åæ´æ°ä¸­å¼å¥éè¨ï¼é²æ­¢æ»æèæ¨æ·åå¥æ¨£æ¬çè²¢ç»ï¼å¾èä¿è­·è¨ç·´è³æçé±ç§ãå¯¦é©çµæè¡¨æï¼ææåºçæ¹æ³ FedDP å°æ¨¡åæºç¢ºåº¦çå½±é¿æå°ï¼åæææä¿è­·äºççççå½±åè³æçé±ç§ï¼DiceãJaccard å Acc ææ¸åå¥åç¥å¾®ä¸éäº 0.55%ã0.63% å 0.42%ãéç¨®æ¹æ³ä¿é²äºæ©æ§éçåä½åç¥è­å±äº«ï¼åæä¿è­·äºææè³æçé±ç§ï¼çºé«çé åçé²ä¸æ­¥ç ç©¶åæç¨æä¾äºå¯è¡çè§£æ±ºæ¹æ¡ã

##### **Conditional Diffusion Model for Longitudinal Medical Image Generation**
2411.05860v1 by Duy-Phuong Dao, Hyung-Jeong Yang, Jahae Kim

Alzheimers disease progresses slowly and involves complex interaction between
various biological factors. Longitudinal medical imaging data can capture this
progression over time. However, longitudinal data frequently encounter issues
such as missing data due to patient dropouts, irregular follow-up intervals,
and varying lengths of observation periods. To address these issues, we
designed a diffusion-based model for 3D longitudinal medical imaging generation
using single magnetic resonance imaging (MRI). This involves the injection of a
conditioning MRI and time-visit encoding to the model, enabling control in
change between source and target images. The experimental results indicate that
the proposed method generates higher-quality images compared to other competing
methods.

æè¦ï¼é¿è²æµ·é»ççé²ç¨ç·©æ¢ï¼æ¶ååç¨®çç©å å­ä¹éçè¤éäºåãç¸±åé«å­¸å½±åè³æå¯ä»¥é¨èæéæ¨ç§»ææéç¨®é²ç¨ãç¶èï¼ç¸±åè³æç¶å¸¸æéå°åé¡ï¼ä¾å¦ç±æ¼æ£èéåºãä¸è¦åçè¿½è¹¤ééåè§å¯æé·åº¦ä¸åèå°è´è³æéºå¤±ãçºäºè§£æ±ºéäºåé¡ï¼æåè¨­è¨äºä¸ååºæ¼æ´æ£çæ¨¡åï¼ç¨æ¼ä½¿ç¨å®ä¸ç£å±æ¯æå (MRI) é²è¡ 3D ç¸±åé«å­¸å½±åçæãéæ¶åå°æ¢ä»¶ MRI åæéè¨ªåç·¨ç¢¼æ³¨å¥æ¨¡åï¼å¾èè½å¤ æ§å¶æºå½±ååç®æ¨å½±åä¹éçè½æãå¯¦é©çµæè¡¨æï¼èå¶ä»ç«¶ç­æ¹æ³ç¸æ¯ï¼ææåºçæ¹æ³çæçå½±ååè³ªè¼é«ã

##### **Evaluating the Economic Implications of Using Machine Learning in Clinical Psychiatry**
2411.05856v1 by Soaad Hossain, James Rasalingam, Arhum Waheed, Fatah Awil, Rachel Kandiah, Syed Ishtiaque Ahmed

With the growing interest in using AI and machine learning (ML) in medicine,
there is an increasing number of literature covering the application and ethics
of using AI and ML in areas of medicine such as clinical psychiatry. The
problem is that there is little literature covering the economic aspects
associated with using ML in clinical psychiatry. This study addresses this gap
by specifically studying the economic implications of using ML in clinical
psychiatry. In this paper, we evaluate the economic implications of using ML in
clinical psychiatry through using three problem-oriented case studies,
literature on economics, socioeconomic and medical AI, and two types of health
economic evaluations. In addition, we provide details on fairness, legal,
ethics and other considerations for ML in clinical psychiatry.

æè¦ï¼é¨è AI åæ©å¨å­¸ç¿ (ML) å¨é«å­¸ä¸­æç¨æ¥çåå°éè¦ï¼
æ¢è¨ AI å ML å¨é«å­¸é åï¼ä¾å¦è¨åºç²¾ç¥çå­¸ï¼ä¸­æç¨åå«ççæç»è¶ä¾è¶å¤ãåé¡å¨æ¼ï¼æ¢è¨è ML å¨è¨åºç²¾ç¥çå­¸ä¸­æç¨ç¸éçç¶æ¿æ¹é¢çæç»å¾å°ãæ¬ç ç©¶ééç¹å¥æ¢è¨ ML å¨è¨åºç²¾ç¥çå­¸ä¸­æç¨çç¶æ¿å½±é¿ï¼ä¾è§£æ±ºéååé¡ãå¨æ¬æä¸­ï¼æåééä½¿ç¨ä¸åä»¥åé¡çºå°åçæ¡ä¾ç ç©¶ãç¶æ¿å­¸ãç¤¾æç¶æ¿åé«ç AI çæç»ï¼ä»¥åå©ç¨®é¡åçå¥åº·ç¶æ¿è©ä¼°ï¼è©ä¼° ML å¨è¨åºç²¾ç¥çå­¸ä¸­æç¨çç¶æ¿å½±é¿ãæ­¤å¤ï¼æåæä¾æé ML å¨è¨åºç²¾ç¥çå­¸ä¸­çå¬å¹³æ§ãæ³å¾ãå«çåå¶ä»èéçè©³ç´°è³è¨ã

##### **Robust Real-Time Mortality Prediction in the Intensive Care Unit using Temporal Difference Learning**
2411.04285v1 by Thomas Frost, Kezhi Li, Steve Harris

The task of predicting long-term patient outcomes using supervised machine
learning is a challenging one, in part because of the high variance of each
patient's trajectory, which can result in the model over-fitting to the
training data. Temporal difference (TD) learning, a common reinforcement
learning technique, may reduce variance by generalising learning to the pattern
of state transitions rather than terminal outcomes. However, in healthcare this
method requires several strong assumptions about patient states, and there
appears to be limited literature evaluating the performance of TD learning
against traditional supervised learning methods for long-term health outcome
prediction tasks. In this study, we define a framework for applying TD learning
to real-time irregularly sampled time series data using a Semi-Markov Reward
Process. We evaluate the model framework in predicting intensive care mortality
and show that TD learning under this framework can result in improved model
robustness compared to standard supervised learning methods. and that this
robustness is maintained even when validated on external datasets. This
approach may offer a more reliable method when learning to predict patient
outcomes using high-variance irregular time series data.

æè¦ï¼é æ¸¬é·ææ£èçµæçä»»åä½¿ç¨ç£ç£å¼æ©å¨å­¸ç¿ï¼éæ¯ä¸åå·æææ°æ§çä»»åï¼é¨ååå æ¯æ¯åæ£èçè»è·¡çè®ç°æ§å¾é«ï¼éå¯è½å°è´æ¨¡åéåº¦æ¬åå°è¨ç·´æ¸æãæéå·®å (TD) å­¸ç¿ï¼ä¸ç¨®å¸¸è¦çå¼·åå­¸ç¿æè¡ï¼å¯ä»¥ééå°å­¸ç¿æ¦æ¬çºçæè½ææ¨¡å¼èä¸æ¯çµç«¯çµæä¾æ¸å°è®ç°ãç¶èï¼å¨é«çä¿å¥ä¸­ï¼éç¨®æ¹æ³éè¦å°æ£èçæååºå¹¾åå¼·æåçåè¨­ï¼èä¸ä¼¼ä¹æéçæç»è©ä¼°äº TD å­¸ç¿ç¸å°æ¼å³çµ±ç£ç£å¼å­¸ç¿æ¹æ³å¨é·æå¥åº·çµæé æ¸¬ä»»åä¸­çæ§è½ãå¨éé ç ç©¶ä¸­ï¼æåå®ç¾©äºä¸åæ¡æ¶ï¼ç¨æ¼å° TD å­¸ç¿æç¨æ¼ä½¿ç¨åé¦¬ç¾å¯å¤«çåµéç¨çå¯¦æä¸è¦åæ¡æ¨£æéåºåæ¸æãæåè©ä¼°äºæ¨¡åæ¡æ¶å¨é æ¸¬éçç£è­·æ­»äº¡çä¸­çè¡¨ç¾ï¼ä¸¦è¡¨æå¨éåæ¡æ¶ä¸ç TD å­¸ç¿å¯ä»¥å°è´èæ¨æºç£ç£å¼å­¸ç¿æ¹æ³ç¸æ¯æ¨¡åé­¯æ£æ§å¾å°æ¹åãèä¸éç¨®é­¯æ£æ§å³ä½¿å¨å¤é¨æ¸æéä¸é©è­ä¹è½ä¿æãå¨ä½¿ç¨é«è®ç°ä¸è¦åæéåºåæ¸æå­¸ç¿é æ¸¬æ£èçµææï¼éç¨®æ¹æ³å¯è½ææä¾ä¸ç¨®æ´å¯é çæ¹æ³ã

##### **Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?**
2411.04118v1 by Daniel P. Jeong, Saurabh Garg, Zachary C. Lipton, Michael Oberst

Several recent works seek to develop foundation models specifically for
medical applications, adapting general-purpose large language models (LLMs) and
vision-language models (VLMs) via continued pretraining on publicly available
biomedical corpora. These works typically claim that such domain-adaptive
pretraining (DAPT) improves performance on downstream medical tasks, such as
answering medical licensing exam questions. In this paper, we compare seven
public "medical" LLMs and two VLMs against their corresponding base models,
arriving at a different conclusion: all medical VLMs and nearly all medical
LLMs fail to consistently improve over their base models in the zero-/few-shot
prompting regime for medical question-answering (QA) tasks. For instance,
across the tasks and model pairs we consider in the 3-shot setting, medical
LLMs only outperform their base models in 12.1% of cases, reach a (statistical)
tie in 49.8% of cases, and are significantly worse than their base models in
the remaining 38.2% of cases. Our conclusions are based on (i) comparing each
medical model head-to-head, directly against the corresponding base model; (ii)
optimizing the prompts for each model separately; and (iii) accounting for
statistical uncertainty in comparisons. While these basic practices are not
consistently adopted in the literature, our ablations show that they
substantially impact conclusions. Our findings suggest that state-of-the-art
general-domain models may already exhibit strong medical knowledge and
reasoning capabilities, and offer recommendations to strengthen the conclusions
of future studies.

æè¦ï¼<paragraph>è¿æçå¹¾é ç ç©¶è´åæ¼å°ééå°é«çæç¨éç¼åºç¤æ¨¡åï¼ééå¨å¬éççç©é«å­¸èªæåº«ä¸æçºé è¨ç·´ï¼èª¿æ´éç¨çå¤§åèªè¨æ¨¡å (LLM) åè¦è¦ºèªè¨æ¨¡å (VLM)ãéäºç ç©¶éå¸¸è²ç¨±ï¼éç¨®é åé©ææ§é è¨ç·´ (DAPT) è½æ¹åä¸æ¸¸é«çä»»åçæè½ï¼ä¾å¦åç­é«çå·ç§èè©¦é¡ç®ãå¨æ¬æä¸­ï¼æåæ¯è¼äºä¸åå¬éçãé«çãLLM åå©å VLM èå®åå°æçåºæ¬æ¨¡åï¼ä¸¦å¾åºä¸åççµè«ï¼å¨é«çåé¡åç­ (QA) ä»»åçé¶æ¬¡ï¼å°æ¨£æ¬æç¤ºæ©å¶ä¸­ï¼ææé«ç VLM åå¹¾ä¹ææé«ç LLM é½ç¡æ³æçºåªæ¼å®åçåºæ¬æ¨¡åãä¾å¦ï¼å¨æåå¨ 3 æ¬¡æç¤ºè¨­å®ä¸­èæ®çä»»ååæ¨¡åéå°ä¸­ï¼é«ç LLM åå¨ 12.1% çææ³ä¸åªæ¼å®åçåºæ¬æ¨¡åï¼å¨ 49.8% çææ³ä¸éå°ï¼çµ±è¨ï¼å¹³æï¼èå¨å¶é¤ 38.2% çææ³ä¸é¡¯èä½æ¼å®åçåºæ¬æ¨¡åãæåççµè«åºæ¼ (i) ç´æ¥éå°å°æçåºæ¬æ¨¡åï¼éä¸æ¯è¼æ¯åé«çæ¨¡åï¼(ii) åå¥éå°æ¯åæ¨¡åæä½³åæç¤ºï¼ä»¥å (iii) èæ®æ¯è¼ä¸­ççµ±è¨ä¸ç¢ºå®æ§ãéç¶éäºåºæ¬åæ³ä¸¦æªæçºæ¡ç¨å¨æç»ä¸­ï¼ä½æåçæ¶èç ç©¶è¡¨æï¼å®åæå¤§å¹å½±é¿çµè«ãæåçç ç©¶çµæè¡¨æï¼æåé²çéç¨é åæ¨¡åå¯è½å·²ç¶å±ç¾åºå¼·å¤§çé«çç¥è­åæ¨çè½åï¼ä¸¦æåºå»ºè­°ä»¥å¼·åæªä¾ç ç©¶ççµè«ã</paragraph>

##### **RaVL: Discovering and Mitigating Spurious Correlations in Fine-Tuned Vision-Language Models**
2411.04097v1 by Maya Varma, Jean-Benoit Delbrouck, Zhihong Chen, Akshay Chaudhari, Curtis Langlotz

Fine-tuned vision-language models (VLMs) often capture spurious correlations
between image features and textual attributes, resulting in degraded zero-shot
performance at test time. Existing approaches for addressing spurious
correlations (i) primarily operate at the global image-level rather than
intervening directly on fine-grained image features and (ii) are predominantly
designed for unimodal settings. In this work, we present RaVL, which takes a
fine-grained perspective on VLM robustness by discovering and mitigating
spurious correlations using local image features rather than operating at the
global image level. Given a fine-tuned VLM, RaVL first discovers spurious
correlations by leveraging a region-level clustering approach to identify
precise image features contributing to zero-shot classification errors. Then,
RaVL mitigates the identified spurious correlation with a novel region-aware
loss function that enables the VLM to focus on relevant regions and ignore
spurious relationships during fine-tuning. We evaluate RaVL on 654 VLMs with
various model architectures, data domains, and learned spurious correlations.
Our results show that RaVL accurately discovers (191% improvement over the
closest baseline) and mitigates (8.2% improvement on worst-group image
classification accuracy) spurious correlations. Qualitative evaluations on
general-domain and medical-domain VLMs confirm our findings.

æè¦ï¼å¾®è°çè§è§è¯­è¨æ¨¡åï¼VLMï¼éå¸¸ä¼ææå¾åç¹å¾åææ¬å±æ§ä¹é´çèåç¸å³æ§ï¼å¯¼è´å¨æµè¯æ¶é¶æ ·æ¬æ§è½ä¸éãç°æçè§£å³èåç¸å³æ§çæ¹æ³ï¼iï¼ä¸»è¦å¨å¨å±å¾åçº§å«æä½ï¼èä¸æ¯ç´æ¥å¹²é¢ç»ç²åº¦çå¾åç¹å¾ï¼å¹¶ä¸ï¼iiï¼ä¸»è¦è®¾è®¡ç¨äºåæ¨¡æè®¾ç½®ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬æåºäº RaVLï¼å®éè¿ä½¿ç¨å±é¨å¾åç¹å¾èä¸æ¯å¨å¨å±å¾åçº§å«æä½æ¥åç°ååè½»èåç¸å³æ§ï¼ä»èå¯¹ VLM é²æ£æ§éåäºç»ç²åº¦çè§è§ãç»å®ä¸ä¸ªå¾®è°ç VLMï¼RaVL é¦åéè¿å©ç¨åºåçº§èç±»æ¹æ³åç°èåç¸å³æ§ï¼ä»¥è¯å«å¯¼è´é¶æ ·æ¬åç±»éè¯¯çç²¾ç¡®å¾åç¹å¾ãç¶åï¼RaVL ä½¿ç¨ä¸ç§æ°é¢çåºåæç¥æå¤±å½æ°æ¥åè½»å·²è¯å«çèåç¸å³æ§ï¼è¯¥æå¤±å½æ°ä½¿ VLM è½å¤å¨å¾®è°æé´å³æ³¨ç¸å³åºåå¹¶å¿½ç¥èåå³ç³»ãæä»¬ä½¿ç¨ 654 ä¸ª VLM å¯¹ RaVL è¿è¡äºè¯ä¼°ï¼è¿äº VLM å·æåç§æ¨¡åæ¶æãæ°æ®ååå­¦ä¹ å°çèåç¸å³æ§ãæä»¬çç»æè¡¨æï¼RaVL åç¡®å°åç°äºï¼æ¯ææ¥è¿çåºçº¿æé«äº 191%ï¼ååè½»äºï¼å¨æå·®ç»å¾ååç±»åç¡®æ§ä¸æé«äº 8.2%ï¼èåç¸å³æ§ãå¯¹éç¨ååå»å­¦å VLM çå®æ§è¯ä¼°è¯å®äºæä»¬çåç°ã

##### **Aligning Characteristic Descriptors with Images for Human-Expert-like Explainability**
2411.04008v1 by Bharat Chandra Yalavarthi, Nalini Ratha

In mission-critical domains such as law enforcement and medical diagnosis,
the ability to explain and interpret the outputs of deep learning models is
crucial for ensuring user trust and supporting informed decision-making.
Despite advancements in explainability, existing methods often fall short in
providing explanations that mirror the depth and clarity of those given by
human experts. Such expert-level explanations are essential for the dependable
application of deep learning models in law enforcement and medical contexts.
Additionally, we recognize that most explanations in real-world scenarios are
communicated primarily through natural language. Addressing these needs, we
propose a novel approach that utilizes characteristic descriptors to explain
model decisions by identifying their presence in images, thereby generating
expert-like explanations. Our method incorporates a concept bottleneck layer
within the model architecture, which calculates the similarity between image
and descriptor encodings to deliver inherent and faithful explanations. Through
experiments in face recognition and chest X-ray diagnosis, we demonstrate that
our approach offers a significant contrast over existing techniques, which are
often limited to the use of saliency maps. We believe our approach represents a
significant step toward making deep learning systems more accountable,
transparent, and trustworthy in the critical domains of face recognition and
medical diagnosis.

æè¦ï¼å¨æ§æ³åå»çè¯æ­ç­ä»»å¡å³é®åé¢åï¼
è§£éåè¯ éæ·±åº¦å­¦ä¹ æ¨¡åçè¾åºå¯¹äºç¡®ä¿ç¨æ·ä¿¡ä»»åæ¯æç¥æå³ç­è³å³éè¦ã
å°½ç®¡å¯è§£éæ§æ¹é¢åå¾äºè¿æ­¥ï¼ä½ç°ææ¹æ³å¨æä¾è§£éæ¶å¾å¾è¾¾ä¸å°äººç±»ä¸å®¶ç»åºçæ·±åº¦åæ¸æ°åº¦ãè¿ç§ä¸å®¶çº§å«çè§£éå¯¹äºå¨æ§æ³åå»çç¯å¢ä¸­å¯é å°åºç¨æ·±åº¦å­¦ä¹ æ¨¡åè³å³éè¦ã
æ­¤å¤ï¼æä»¬è®¤è¯å°ï¼å¨ç°å®ä¸çåºæ¯ä¸­ï¼å¤§å¤æ°è§£éä¸»è¦æ¯éè¿èªç¶è¯­è¨è¿è¡äº¤æµçãä¸ºäºæ»¡è¶³è¿äºéæ±ï¼æä»¬æåºäºä¸ç§æ°é¢çæ¹æ³ï¼è¯¥æ¹æ³å©ç¨ç¹å¾æè¿°ç¬¦éè¿è¯å«å¾åä¸­çç¹å¾æè¿°ç¬¦çå­å¨æ¥è§£éæ¨¡åå³ç­ï¼ä»èçæç±»ä¼¼ä¸å®¶çè§£éãæä»¬çæ¹æ³å¨æ¨¡åæ¶æä¸­å å¥äºä¸ä¸ªæ¦å¿µç¶é¢å±ï¼è¯¥å±è®¡ç®å¾ååæè¿°ç¬¦ç¼ç ä¹é´çç¸ä¼¼æ§ï¼ä»¥æä¾åå¨ä¸å¯é çè§£éãéè¿é¢é¨è¯å«åè¸é¨ X å°çº¿è¯æ­çå®éªï¼æä»¬è¯æäºæä»¬çæ¹æ³ä¸ç°æææ¯ç¸æ¯å·ææ¾çä¼å¿ï¼èç°æææ¯éå¸¸ä»éäºä½¿ç¨æ¾çæ§å¾ãæä»¬ç¸ä¿¡ï¼æä»¬çæ¹æ³ä»£è¡¨äºæçä½¿æ·±åº¦å­¦ä¹ ç³»ç»å¨é¢é¨è¯å«åå»çè¯æ­çå³é®é¢åæ´å è´è´£ãéæåå¼å¾ä¿¡èµè¿åºçéè¦ä¸æ­¥ã

##### **Fine-tuning -- a Transfer Learning approach**
2411.03941v1 by Joseph Arul Raj, Linglong Qian, Zina Ibrahim

Secondary research use of Electronic Health Records (EHRs) is often hampered
by the abundance of missing data in this valuable resource. Missingness in EHRs
occurs naturally as a result of the data recording practices during routine
clinical care, but handling it is crucial to the precision of medical analysis
and the decision-making that follows. The literature contains a variety of
imputation methodologies based on deep neural networks. Those aim to overcome
the dynamic, heterogeneous and multivariate missingness patterns of EHRs, which
cannot be handled by classical and statistical imputation methods. However, all
existing deep imputation methods rely on end-to-end pipelines that incorporate
both imputation and downstream analyses, e.g. classification. This coupling
makes it difficult to assess the quality of imputation and takes away the
flexibility of re-using the imputer for a different task. Furthermore, most
end-to-end deep architectures tend to use complex networks to perform the
downstream task, in addition to the already sophisticated deep imputation
network. We, therefore ask if the high performance reported in the literature
is due to the imputer or the classifier and further ask if an optimised
state-of-the-art imputer is used, a simpler classifier can achieve comparable
performance. This paper explores the development of a modular, deep
learning-based imputation and classification pipeline, specifically built to
leverage the capabilities of state-of-the-art imputation models for downstream
classification tasks. Such a modular approach enables a) objective assessment
of the quality of the imputer and classifier independently, and b) enables the
exploration of the performance of simpler classification architectures using an
optimised imputer.

æè¦ï¼é»å­å¥åº·ç´é (EHR) çäºæ¬¡ç ç©¶ç¨éç¶å¸¸åå°æ­¤å¯¶è²´è³æºä¸­å¤§ééºå¤±è³æçé»ç¤ãEHR ä¸­çéºå¤±è³ææå¨ä¾è¡è¨åºç§è­·æéçè³æè¨éå¯¦åä¸­èªç¶ç¼çï¼ä½èçéºå¤±è³æå°æ¼é«çåæçç²¾ç¢ºåº¦åå¾çºæ±ºç­è³ééè¦ãæç»ä¸­åå«åç¨®åºæ¼æ·±åº¦ç¥ç¶ç¶²è·¯çå§ææ¹æ³ãéäºæ¹æ³æ¨å¨åæ EHR ä¸­åæãç°è³ªä¸å¤è®éçéºå¤±è³ææ¨¡å¼ï¼èéç¡æ³ééå³çµ±åçµ±è¨å§ææ¹æ³ä¾èçãç¶èï¼ææç¾æçæ·±åº¦å§ææ¹æ³é½ä¾è³´æ¼å°å§æåä¸æ¸¸åæï¼ä¾å¦åé¡ï¼çµåå¨ä¸èµ·çç«¯å°ç«¯ç®¡éãéç¨®çµåä½¿å¾é£ä»¥è©ä¼°å§æçåè³ªï¼ä¸¦æ¶é¤äºéæ°ä½¿ç¨å§æå¨é²è¡ä¸åä»»åçéæ´»æ§ãæ­¤å¤ï¼å¤§å¤æ¸ç«¯å°ç«¯æ·±åº¦æ¶æ§å¾åæ¼ä½¿ç¨è¤éçç¶²è·¯ä¾å·è¡ä¸æ¸¸ä»»åï¼é¤äºå·²ç¶å¾è¤éçæ·±åº¦å§æç¶²è·¯ä¹å¤ãå æ­¤ï¼æåè©¢åæç»ä¸­å ±å°çé«æè½æ¯ç±æ¼å§æå¨éæ¯åé¡å¨ï¼ä¸¦é²ä¸æ­¥è©¢åæ¯å¦ä½¿ç¨äºæä½³åçææ°å§æå¨ï¼è¼ç°¡å®çåé¡å¨æ¯å¦å¯ä»¥éå°ç¸è¿çæè½ãæ¬ææ¢è¨æ¨¡çµåãåºæ¼æ·±åº¦å­¸ç¿çå§æååé¡ç®¡éçéç¼ï¼ç¹å¥æ¯å»ºæ§ä¾å©ç¨ææ°å§ææ¨¡åçè½åï¼ä»¥é²è¡ä¸æ¸¸åé¡ä»»åãéç¨®æ¨¡çµåæ¹æ³è½ a) å®¢è§è©ä¼°å§æå¨ååé¡å¨çåè³ªï¼ä»¥å b) è½å¤ ä½¿ç¨æä½³åçå§æå¨ä¾æ¢è¨è¼ç°¡å®åé¡æ¶æ§çæè½ã

##### **MEG: Medical Knowledge-Augmented Large Language Models for Question Answering**
2411.03883v2 by Laura Cabello, Carmen Martin-Turrero, Uchenna Akujuobi, Anders SÃ¸gaard, Carlos Bobed

Question answering is a natural language understanding task that involves
reasoning over both explicit context and unstated, relevant domain knowledge.
Large language models (LLMs), which underpin most contemporary question
answering systems, struggle to induce how concepts relate in specialized
domains such as medicine. Existing medical LLMs are also costly to train. In
this work, we present MEG, a parameter-efficient approach for medical
knowledge-augmented LLMs. MEG uses a lightweight mapping network to integrate
graph embeddings into the LLM, enabling it to leverage external knowledge in a
cost-effective way. We evaluate our method on four popular medical
multiple-choice datasets and show that LLMs greatly benefit from the factual
grounding provided by knowledge graph embeddings. MEG attains an average of
+10.2% accuracy over the Mistral-Instruct baseline, and +6.7% over specialized
models like BioMistral. We also show results based on Llama-3. Finally, we show
that MEG's performance remains robust to the choice of graph encoder.

æè¦ï¼åç­æ¯èªç¶èªè¨çè§£ä»»åï¼æ¶åå°æç¢ºçä¸ä¸æåæªèªªæçç¸éé åç¥è­é²è¡æ¨çãæ¯æå¤§å¤æ¸ç¶ä»£åç­ç³»çµ±çå¤§åèªè¨æ¨¡å (LLM) é£ä»¥æ¨è«æ¦å¿µå¦ä½å¨é«å­¸ç­å°æ¥­é åä¸­éè¯ãç¾æçé«å­¸ LLM è¨ç·´ææ¬ä¹å¾é«ãå¨éé å·¥ä½ä¸­ï¼æåæåºäº MEGï¼éæ¯ä¸ç¨®ç¨æ¼é«å­¸ç¥è­å¢å¼· LLM çåæ¸æææ¹æ³ãMEG ä½¿ç¨è¼éç´æ å°ç¶²è·¯å°åè¡¨åµå¥æ´åå° LLM ä¸­ï¼ä½¿å¶è½å¤ ä»¥ç¶æ¿ææçæ¹å¼å©ç¨å¤é¨ç¥è­ãæåå¨ååæµè¡çé«å­¸å¤é¸é¡è³æéä¸è©ä¼°äºæåçæ¹æ³ï¼ä¸¦è¡¨æ LLM å¾ç¥è­åè¡¨åµå¥æä¾çå¯¦éä¾æä¸­åçåªæ·ºãMEG å¨ Mistral-Instruct åºæºä¸å¹³åæé«äº +10.2% çæºç¢ºåº¦ï¼å¨ BioMistral ç­å°éæ¨¡åä¸æé«äº +6.7%ãæåéå±ç¤ºäºåºæ¼ Llama-3 ççµæãæå¾ï¼æåè¡¨æ MEG çæ§è½å°åè¡¨ç·¨ç¢¼å¨çé¸æä¿æç©©å¥ã

##### **Navigating the landscape of multimodal AI in medicine: a scoping review on technical challenges and clinical applications**
2411.03782v1 by Daan Schouten, Giulia Nicoletti, Bas Dille, Catherine Chia, Pierpaolo Vendittelli, Megan Schuurmans, Geert Litjens, Nadieh Khalili

Recent technological advances in healthcare have led to unprecedented growth
in patient data quantity and diversity. While artificial intelligence (AI)
models have shown promising results in analyzing individual data modalities,
there is increasing recognition that models integrating multiple complementary
data sources, so-called multimodal AI, could enhance clinical decision-making.
This scoping review examines the landscape of deep learning-based multimodal AI
applications across the medical domain, analyzing 432 papers published between
2018 and 2024. We provide an extensive overview of multimodal AI development
across different medical disciplines, examining various architectural
approaches, fusion strategies, and common application areas. Our analysis
reveals that multimodal AI models consistently outperform their unimodal
counterparts, with an average improvement of 6.2 percentage points in AUC.
However, several challenges persist, including cross-departmental coordination,
heterogeneous data characteristics, and incomplete datasets. We critically
assess the technical and practical challenges in developing multimodal AI
systems and discuss potential strategies for their clinical implementation,
including a brief overview of commercially available multimodal AI models for
clinical decision-making. Additionally, we identify key factors driving
multimodal AI development and propose recommendations to accelerate the field's
maturation. This review provides researchers and clinicians with a thorough
understanding of the current state, challenges, and future directions of
multimodal AI in medicine.

æè¦ï¼é«çä¿å¥é åçè¿æç§æé²å±å°è´çæ£è³ææ¸éåå¤æ¨£æ§åææªæçæé·ãåç®¡äººå·¥æºæ§ (AI) æ¨¡åå¨åæåå¥è³ææ¨¡å¼ä¸­å±ç¾åºæåéçææï¼ä½æ´åå¤åäºè£è³æä¾æºçæ¨¡åï¼å³æè¬çå¤æ¨¡å¼ AIï¼å¯ä»¥æåè¨åºæ±ºç­å¶å®ï¼éé èªç¥æ­£èæ¥ä¿±å¢ãéç¯ç¯åæ¢è¨åé¡§ç ç©¶æ¢è¨äºæ¶µèé«çé åçæ·±åº¦å­¸ç¿åºç¤å¤æ¨¡å¼ AI æç¨ç¾æ³ï¼åæ 2018 å¹´è³ 2024 å¹´éç¼è¡¨ç 432 ç¯è«æãæåæä¾äºå¤æ¨¡å¼ AI ç¼å±çå»£æ³æ¦è§ï¼æ¶µèä¸åçé«çé åï¼æ¢è¨åç¨®æ¶æ§æ¹æ³ãèåç­ç¥åå¸¸è¦æç¨é åãæåçåæé¡¯ç¤ºï¼å¤æ¨¡å¼ AI æ¨¡åå§çµåªæ¼å¶å®ä¸æ¨¡å¼çå°ææ¨¡åï¼AUC å¹³åæ¹å 6.2 åç¾åé»ãç¶èï¼ä»æè¨±å¤ææ°æçºå­å¨ï¼åæ¬è·¨é¨éåèª¿ãç°è³ªè³æç¹æ§åä¸å®æ´è³æéãæåæ¹å¤æ§å°è©ä¼°éç¼å¤æ¨¡å¼ AI ç³»çµ±å¨æè¡åå¯¦åä¸çææ°ï¼ä¸¦è¨è«å¶è¨åºå¯¦ä½çæ½å¨ç­ç¥ï¼åæ¬å°å¸å®å¤æ¨¡å¼ AI æ¨¡åçç°¡è¦æ¦è¿°ï¼ç¨æ¼è¨åºæ±ºç­å¶å®ãæ­¤å¤ï¼æåæ¾åºæ¨åå¤æ¨¡å¼ AI ç¼å±çä¸»è¦å ç´ ï¼ä¸¦æåºå»ºè­°ä»¥å éè©²é åçæçãæ¬åé¡§ç ç©¶è®ç ç©¶äººå¡åè¨åºé«å¸«æ·±å¥äºè§£å¤æ¨¡å¼ AI å¨é«å­¸é åçç¾æ³ãææ°åæªä¾æ¹åã

##### **Sub-DM:Subspace Diffusion Model with Orthogonal Decomposition for MRI Reconstruction**
2411.03758v1 by Yu Guan, Qinrong Cai, Wei Li, Qiuyun Fan, Dong Liang, Qiegen Liu

Diffusion model-based approaches recently achieved re-markable success in MRI
reconstruction, but integration into clinical routine remains challenging due
to its time-consuming convergence. This phenomenon is partic-ularly notable
when directly apply conventional diffusion process to k-space data without
considering the inherent properties of k-space sampling, limiting k-space
learning efficiency and image reconstruction quality. To tackle these
challenges, we introduce subspace diffusion model with orthogonal
decomposition, a method (referred to as Sub-DM) that restrict the diffusion
process via projections onto subspace as the k-space data distribution evolves
toward noise. Particularly, the subspace diffusion model circumvents the
inference challenges posed by the com-plex and high-dimensional characteristics
of k-space data, so the highly compact subspace ensures that diffusion process
requires only a few simple iterations to produce accurate prior information.
Furthermore, the orthogonal decomposition strategy based on wavelet transform
hin-ders the information loss during the migration of the vanilla diffusion
process to the subspace. Considering the strate-gy is approximately reversible,
such that the entire pro-cess can be reversed. As a result, it allows the
diffusion processes in different spaces to refine models through a mutual
feedback mechanism, enabling the learning of ac-curate prior even when dealing
with complex k-space data. Comprehensive experiments on different datasets
clearly demonstrate that the superiority of Sub-DM against state of-the-art
methods in terms of reconstruction speed and quality.

æè¦ï¼åºæ¼æ´æ£æ¨¡åçæ¹æ³æè¿å¨ MRI éå»ºä¸­åå¾äºé¡¯èçæåï¼ä½ç±æ¼å¶èæçæ¶ææ§ï¼æ´åå°è¨åºå¸¸è¦ä¸­ä»ç¶å·æææ°æ§ãç¶ç´æ¥å°å³çµ±æ´æ£éç¨æç¨å° k-space è³æï¼èæ²æèæ® k-space åæ¨£çåºæç¹æ§æï¼éç¨®ç¾è±¡å°¤å¶æé¡¯ï¼éå¶äº k-space å­¸ç¿æçåå½±åéå»ºåè³ªãçºäºæå°éäºææ°ï¼æåå¼å¥äºå·ææ­£äº¤åè§£çå­ç©ºéæ´æ£æ¨¡åï¼ä¸ç¨®æ¹æ³ï¼ç¨±çº Sub-DMï¼ï¼å®ééæå½±å°å­ç©ºéä¾éå¶æ´æ£éç¨ï¼å çº k-space è³æåä½ææ¼è®æéè¨ãç¹å¥æ¯ï¼å­ç©ºéæ´æ£æ¨¡åè¿´é¿äº k-space è³æçè¤éåé«ç¶­ç¹å¾µæå¸¶ä¾çæ¨è«ææ°ï¼å æ­¤é«åº¦ç·æ¹çå­ç©ºéç¢ºä¿æ´æ£éç¨åªéè¦å¹¾åç°¡å®çè¿­ä»£å³å¯ç¢çæºç¢ºçåé©è³è¨ãæ­¤å¤ï¼åºæ¼å°æ³¢è½æçæ­£äº¤åè§£ç­ç¥é»ç¤äºé¦èæ´æ£éç¨é·ç§»å°å­ç©ºéæéçè³è¨éºå¤±ãèæ®å°è©²ç­ç¥è¿ä¼¼å¯éï¼å æ­¤æ´åéç¨å¯ä»¥éè½ãå æ­¤ï¼å®åè¨±ä¸åç©ºéä¸­çæ´æ£éç¨ééç¸äºåé¥æ©å¶ä¾åªåæ¨¡åï¼å³ä½¿å¨èçè¤éç k-space è³ææä¹è½å­¸ç¿æºç¢ºçåé©ãå¨ä¸åè³æéä¸çå¨é¢å¯¦é©æ¸æ¥å°è­æäº Sub-DM å¨éå»ºéåº¦ååè³ªæ¹é¢åªæ¼æåé²çæ¹æ³ã

##### **Ultrasound-Based AI for COVID-19 Detection: A Comprehensive Review of Public and Private Lung Ultrasound Datasets and Studies**
2411.05029v1 by Abrar Morshed, Abdulla Al Shihab, Md Abrar Jahin, Md Jaber Al Nahian, Md Murad Hossain Sarker, Md Sharjis Ibne Wadud, Mohammad Istiaq Uddin, Muntequa Imtiaz Siraji, Nafisa Anjum, Sumiya Rajjab Shristy, Tanvin Rahman, Mahmuda Khatun, Md Rubel Dewan, Mosaddeq Hossain, Razia Sultana, Ripel Chakma, Sonet Barua Emon, Towhidul Islam, Mohammad Arafat Hussain

The COVID-19 pandemic has affected millions of people globally, with
respiratory organs being strongly affected in individuals with comorbidities.
Medical imaging-based diagnosis and prognosis have become increasingly popular
in clinical settings for detecting COVID-19 lung infections. Among various
medical imaging modalities, ultrasound stands out as a low-cost, mobile, and
radiation-safe imaging technology. In this comprehensive review, we focus on
AI-driven studies utilizing lung ultrasound (LUS) for COVID-19 detection and
analysis. We provide a detailed overview of both publicly available and private
LUS datasets and categorize the AI studies according to the dataset they used.
Additionally, we systematically analyzed and tabulated the studies across
various dimensions, including data preprocessing methods, AI models,
cross-validation techniques, and evaluation metrics. In total, we reviewed 60
articles, 41 of which utilized public datasets, while the remaining employed
private data. Our findings suggest that ultrasound-based AI studies for
COVID-19 detection have great potential for clinical use, especially for
children and pregnant women. Our review also provides a useful summary for
future researchers and clinicians who may be interested in the field.

æè¦ï¼COVID-19 ç«æå½±é¿å¨çæ¸ç¾è¬äººï¼å¶ä¸­åä½µçæ£èçå¼å¸å¨å®åå°å´éå½±é¿ãåºæ¼é«å­¸å½±åçè¨ºæ·åé å¾å¨è¨åºç°å¢ä¸­å·²æ¥çæ®åï¼ç¨æ¼åµæ¸¬ COVID-19 èºé¨ææãå¨åç¨®é«å­¸å½±åæ¨¡å¼ä¸­ï¼è¶é³æ³¢å å¶ä½ææ¬ãå¯æå¼ä¸ç¡è¼»å°çå½±åæè¡èè«ç©èåºãå¨éç¯å¨é¢çè©è«ä¸­ï¼æåå°æ³¨æ¼å©ç¨èºé¨è¶é³æ³¢ (LUS) é²è¡ COVID-19 åµæ¸¬ååæçäººå·¥æºæ§é©åç ç©¶ãæåæä¾å¬éåç§äºº LUS è³æéçè©³ç´°æ¦è§ï¼ä¸¦æ ¹ææä½¿ç¨çè³æéå°äººå·¥æºæ§ç ç©¶é²è¡åé¡ãæ­¤å¤ï¼æåç³»çµ±å°åæä¸¦æ´çäºåç¨®é¢åçç ç©¶ï¼åæ¬è³æåèçæ¹æ³ãäººå·¥æºæ§æ¨¡åãäº¤åé©è­æè¡åè©ä¼°ææ¨ãç¸½è¨ï¼æåæª¢é±äº 60 ç¯æç« ï¼å¶ä¸­ 41 ç¯ä½¿ç¨å¬éè³æéï¼èå¶é¤åä½¿ç¨ç§äººè³æãæåçç ç©¶çµæè¡¨æï¼åºæ¼è¶é³æ³¢çäººå·¥æºæ§ç ç©¶å°æ¼ COVID-19 åµæ¸¬å·ææ¥µå¤§çè¨åºæç¨æ½åï¼ç¹å¥æ¯å°æ¼åç«¥åå­å©¦ãæåçè©è«ä¹çºå¯è½å°æ­¤é åæèè¶£çæªä¾ç ç©¶äººå¡åè¨åºé«çæä¾äºæç¨çæè¦ã

##### **Touchstone Benchmark: Are We on the Right Way for Evaluating AI Algorithms for Medical Segmentation?**
2411.03670v1 by Pedro R. A. S. Bassi, Wenxuan Li, Yucheng Tang, Fabian Isensee, Zifu Wang, Jieneng Chen, Yu-Cheng Chou, Yannick Kirchhoff, Maximilian Rokuss, Ziyan Huang, Jin Ye, Junjun He, Tassilo Wald, Constantin Ulrich, Michael Baumgartner, Saikat Roy, Klaus H. Maier-Hein, Paul Jaeger, Yiwen Ye, Yutong Xie, Jianpeng Zhang, Ziyang Chen, Yong Xia, Zhaohu Xing, Lei Zhu, Yousef Sadegheih, Afshin Bozorgpour, Pratibha Kumari, Reza Azad, Dorit Merhof, Pengcheng Shi, Ting Ma, Yuxin Du, Fan Bai, Tiejun Huang, Bo Zhao, Haonan Wang, Xiaomeng Li, Hanxue Gu, Haoyu Dong, Jichen Yang, Maciej A. Mazurowski, Saumya Gupta, Linshan Wu, Jiaxin Zhuang, Hao Chen, Holger Roth, Daguang Xu, Matthew B. Blaschko, Sergio Decherchi, Andrea Cavalli, Alan L. Yuille, Zongwei Zhou

How can we test AI performance? This question seems trivial, but it isn't.
Standard benchmarks often have problems such as in-distribution and small-size
test sets, oversimplified metrics, unfair comparisons, and short-term outcome
pressure. As a consequence, good performance on standard benchmarks does not
guarantee success in real-world scenarios. To address these problems, we
present Touchstone, a large-scale collaborative segmentation benchmark of 9
types of abdominal organs. This benchmark is based on 5,195 training CT scans
from 76 hospitals around the world and 5,903 testing CT scans from 11
additional hospitals. This diverse test set enhances the statistical
significance of benchmark results and rigorously evaluates AI algorithms across
various out-of-distribution scenarios. We invited 14 inventors of 19 AI
algorithms to train their algorithms, while our team, as a third party,
independently evaluated these algorithms on three test sets. In addition, we
also evaluated pre-existing AI frameworks--which, differing from algorithms,
are more flexible and can support different algorithms--including MONAI from
NVIDIA, nnU-Net from DKFZ, and numerous other open-source frameworks. We are
committed to expanding this benchmark to encourage more innovation of AI
algorithms for the medical domain.

æè¦ï¼å¦ä½æ¸¬è©¦ AI æè½ï¼éååé¡çä¼¼ç°¡å®ï¼ä½ä¸¦éå¦æ­¤ã
æ¨æºåºæºç¶å¸¸æè«¸å¦åä½å§åå°åæ¸¬è©¦éãéæ¼ç°¡åçææ¨ãä¸å¬å¹³çæ¯è¼åç­æçµæå£åç­åé¡ãå æ­¤ï¼å¨æ¨æºåºæºä¸çè¯å¥½æè½ç¡æ³ä¿è­å¨å¯¦éææ³ä¸­ä¹è½æåãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäº Touchstoneï¼ä¸ç¨®å¤§ååä½åå²åºæºï¼åå« 9 ç¨®é¡åçè¹é¨å¨å®ãæ­¤åºæºåºæ¼ä¾èªå¨ç 76 å®¶é«é¢ç 5,195 åè¨ç·´ CT ææåä¾èª 11 å®¶å¶ä»é«é¢ç 5,903 åæ¸¬è©¦ CT ææãéåå¤æ¨£åçæ¸¬è©¦éå¢å¼·äºåºæºçµæççµ±è¨é¡¯èæ§ï¼ä¸¦å´æ ¼è©ä¼°äºåç¨®åä½å¤ææ³ä¸ç AI æ¼ç®æ³ãæåéè«äº 19 ç¨® AI æ¼ç®æ³ç 14 ä½ç¼æèè¨ç·´ä»åçæ¼ç®æ³ï¼èæåçåéä½çºç¬¬ä¸æ¹ï¼ç¨ç«è©ä¼°äºéäºæ¼ç®æ³å¨ä¸åæ¸¬è©¦éä¸çè¡¨ç¾ãæ­¤å¤ï¼æåéè©ä¼°äºç¾æç AI æ¡æ¶ï¼éäºæ¡æ¶èæ¼ç®æ³ä¸åï¼æ´å·å½æ§ï¼ä¸å¯ä»¥æ¯æ´ä¸åçæ¼ç®æ³ï¼åæ¬ NVIDIA ç MONAIãDKFZ ç nnU-Net åè¨±å¤å¶ä»éæºæ¡æ¶ãæåè´åæ¼æ´å±æ­¤åºæºï¼ä»¥é¼åµæ´å¤ AI æ¼ç®æ³å¨é«çé åçåµæ°ã

##### **Requirements Engineering for Older Adult Digital Health Software: A Systematic Literature Review**
2411.03656v1 by Yuqing Xiao, John Grundy, Anuradha Madugalla

Growth of the older adult population has led to an increasing interest in
technology-supported aged care. However, the area has some challenges such as a
lack of caregivers and limitations in understanding the emotional, social,
physical, and mental well-being needs of seniors. Furthermore, there is a gap
in the understanding between developers and ageing people of their
requirements. Digital health can be important in supporting older adults
wellbeing, emotional requirements, and social needs. Requirements Engineering
(RE) is a major software engineering field, which can help to identify, elicit
and prioritize the requirements of stakeholders and ensure that the systems
meet standards for performance, reliability, and usability. We carried out a
systematic review of the literature on RE for older adult digital health
software. This was necessary to show the representatives of the current stage
of understanding the needs of older adults in aged care digital health. Using
established guidelines outlined by the Kitchenham method, the PRISMA and the
PICO guideline, we developed a protocol, followed by the systematic exploration
of eight databases. This resulted in 69 primary studies of high relevance,
which were subsequently subjected to data extraction, synthesis, and reporting.
We highlight key RE processes in digital health software for ageing people. It
explored the utilization of technology for older user well-being and care, and
the evaluations of such solutions. The review also identified key limitations
found in existing primary studies that inspire future research opportunities.
The results indicate that requirement gathering and understanding have a
significant variation between different studies. The differences are in the
quality, depth, and techniques adopted for requirement gathering and these
differences are largely due to uneven adoption of RE methods.

æè¦ï¼é«é½¡äººå£çå¢é·ï¼å°è´å°ç§æè¼å©é·ç§æåçéæ±èæ¥ä¿±å¢ãç¶èï¼è©²é åä¹é¢è¨ä¸äºææ°ï¼ä¾å¦ç§è­·äººå¡çç­ç¼ºï¼ä»¥åå¨çè§£é·èå¨æç·ãç¤¾äº¤ãççåå¿çæ¹é¢çç¦ç¥éæ±ææå­å¨çéå¶ãæ­¤å¤ï¼éç¼äººå¡åé·èå¨éæ±çè§£ä¸ä¹å­å¨å·®è·ãæ¸ä½å¥åº·å¨æ¯æé·èçç¦ç¥ãæç·éæ±åç¤¾æéæ±æ¹é¢æ®æ¼èéè¦çè§è²ãéæ±å·¥ç¨ï¼REï¼æ¯è»é«å·¥ç¨é åçä¸å¤§é åï¼æå©æ¼è­å¥ãå¼å°ååªåèçå©å®³éä¿äººçéæ±ï¼ä¸¦ç¢ºä¿ç³»çµ±ç¬¦åæè½ãå¯é æ§åå¯ç¨æ§çæ¨æºãæåå°é·èæ¸ä½å¥åº·è»é«çREæç»é²è¡äºç³»çµ±æ§çåé¡§ãéå°æ¼å±ç¾ç®åå¨é·ç§æ¸ä½å¥åº·é åä¸­çè§£é·èéæ±çéæ®µä»£è¡¨æ§æ¯å¿è¦çãæåæ ¹æKitchenhamæ¹æ³ãPRISMAåPICOæåæååºçæ¢å®æºåï¼å¶å®äºä¸å¥åå®ï¼æ¥èç³»çµ±æ§å°æ¢è¨äºå«åè³æåº«ãéç¢çäº69é é«åº¦ç¸éçä¸»è¦ç ç©¶ï¼å¶å¾é²è¡äºè³æèåãç¶åååå ±ãæåéé»ä»ç´¹äºé·èæ¸ä½å¥åº·è»é«ä¸­çééµREæµç¨ãå®æ¢è¨äºç§æå¨é·èä½¿ç¨èç¦ç¥åç§è­·ä¸­çæç¨ï¼ä»¥åéäºè§£æ±ºæ¹æ¡çè©ä¼°ãéä»½åé¡§ä¹æ¾åºäºç¾æä¸»è¦ç ç©¶ä¸­ç¼ç¾çä¸»è¦éå¶ï¼æ¿åµäºæªä¾çç ç©¶æ©æãçµæé¡¯ç¤ºï¼ä¸åç ç©¶ä¹éå¨éæ±æ¶éåçè§£æ¹é¢æé¡¯èçå·®ç°ãå·®ç°å¨æ¼éæ±æ¶éææ¡ç¨çåè³ªãæ·±åº¦åæè¡ï¼èéäºå·®ç°å¨å¾å¤§ç¨åº¦ä¸æ¯ç±æ¼REæ¹æ³æ¡ç¨ä¸åæè´ã

##### **Cross Feature Fusion of Fundus Image and Generated Lesion Map for Referable Diabetic Retinopathy Classification**
2411.03618v1 by Dahyun Mok, Junghyun Bum, Le Duc Tai, Hyunseung Choo

Diabetic Retinopathy (DR) is a primary cause of blindness, necessitating
early detection and diagnosis. This paper focuses on referable DR
classification to enhance the applicability of the proposed method in clinical
practice. We develop an advanced cross-learning DR classification method
leveraging transfer learning and cross-attention mechanisms. The proposed
method employs the Swin U-Net architecture to segment lesion maps from DR
fundus images. The Swin U-Net segmentation model, enriched with DR lesion
insights, is transferred to generate a lesion map. Both the fundus image and
its segmented lesion map are used as complementary inputs for the
classification model. A cross-attention mechanism is deployed to improve the
model's ability to capture fine-grained details from the input pairs. Our
experiments, utilizing two public datasets, FGADR and EyePACS, demonstrate a
superior accuracy of 94.6%, surpassing current state-of-the-art methods by
4.4%. To this end, we aim for the proposed method to be seamlessly integrated
into clinical workflows, enhancing accuracy and efficiency in identifying
referable DR.

æè¦ï¼ç³å°¿çè¦ç¶²èçè® (DR) æ¯å¤±æçé¦è¦åå ï¼éè¦æ©ææª¢æ¸¬åè¨ºæ·ãæ¬æéé»éæ³¨å¯è½è¨ºç DR åé¡ï¼ä»¥å¢å¼·ææåºæ¹æ³å¨è¨åºå¯¦åä¸­çé©ç¨æ§ãæåéç¼äºä¸ç¨®åé²çäº¤åå­¸ç¿ DR åé¡æ¹æ³ï¼å©ç¨é·ç§»å­¸ç¿åäº¤åæ³¨ææ©å¶ãææåºçæ¹æ³æ¡ç¨ Swin U-Net æ¶æ§ï¼å¾ DR ç¼åºååä¸­åå²çç¶åãè±å¯äº DR çç¶è¦è§£ç Swin U-Net åå²æ¨¡åè¢«è½ç§»ä»¥çæçç¶åãç¼åºåååå¶åå²ççç¶åé½è¢«ç¨ä½åé¡æ¨¡åçè£åè¼¸å¥ãé¨ç½²äº¤åæ³¨ææ©å¶ä»¥æé«æ¨¡åå¾è¼¸å¥å°ä¸­æ·åç´°ç²åº¦ç´°ç¯çè½åãæåçå¯¦é©å©ç¨äºå©åå¬éæ¸æéï¼FGADR å EyePACSï¼å±ç¤ºäº 94.6% çåªç°æºç¢ºçï¼æ¯ç¶åæåé²çæ¹æ³é«åº 4.4%ãçºæ­¤ï¼æåå¸æææåºçæ¹æ³è½ç¡ç¸«æ´åå°è¨åºå·¥ä½æµç¨ä¸­ï¼æé«æºç¢ºåº¦åæçï¼ä»¥è­å¥å¯è½è¨ºç DRã

##### **The Future of Intelligent Healthcare: A Systematic Analysis and Discussion on the Integration and Impact of Robots Using Large Language Models for Healthcare**
2411.03287v1 by Souren Pashangpour, Goldie Nejat

The potential use of large language models (LLMs) in healthcare robotics can
help address the significant demand put on healthcare systems around the world
with respect to an aging demographic and a shortage of healthcare
professionals. Even though LLMs have already been integrated into medicine to
assist both clinicians and patients, the integration of LLMs within healthcare
robots has not yet been explored for clinical settings. In this perspective
paper, we investigate the groundbreaking developments in robotics and LLMs to
uniquely identify the needed system requirements for designing health specific
LLM based robots in terms of multi modal communication through human robot
interactions (HRIs), semantic reasoning, and task planning. Furthermore, we
discuss the ethical issues, open challenges, and potential future research
directions for this emerging innovative field.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨é«çä¿å¥æ©å¨äººä¸­æ½å¨çæç¨ï¼æå©æ¼æ»¿è¶³å¨çé«çä¿å¥ç³»çµ±å°æèé½¡åäººå£åé«çä¿å¥å°æ¥­äººå¡ç­ç¼ºåé¡çéå¤§éæ±ãåç®¡ LLM å·²æ´åå°é«çé åä¸­ï¼ä»¥åå©è¨åºé«çåæ£èï¼ä½ LLM å¨é«çä¿å¥æ©å¨äººä¸­çæ´åå°æªéå°è¨åºç°å¢é²è¡æ¢è¨ãå¨æ­¤è§é»è«æä¸­ï¼æåæ¢è¨æ©å¨äººå LLM çåµæ°ç¼å±ï¼ä»¥ç¨ç¹å°æ¾åºè¨­è¨ç¹å®æ¼å¥åº·ç LLM æ©å¨äººçç³»çµ±éæ±ï¼åæ¬ééäººæ©äºå (HRI)ãèªç¾©æ¨çåä»»åè¦åçå¤æ¨¡å¼æºéãæ­¤å¤ï¼æåè¨è«äºéåæ°èåµæ°é åçå«çè­°é¡ãéæ¾æ§ææ°åæ½å¨çæªä¾ç ç©¶æ¹åã

##### **Discovering Data Structures: Nearest Neighbor Search and Beyond**
2411.03253v1 by Omar Salemohamed, Laurent Charlin, Shivam Garg, Vatsal Sharan, Gregory Valiant

We propose a general framework for end-to-end learning of data structures.
Our framework adapts to the underlying data distribution and provides
fine-grained control over query and space complexity. Crucially, the data
structure is learned from scratch, and does not require careful initialization
or seeding with candidate data structures/algorithms. We first apply this
framework to the problem of nearest neighbor search. In several settings, we
are able to reverse-engineer the learned data structures and query algorithms.
For 1D nearest neighbor search, the model discovers optimal distribution
(in)dependent algorithms such as binary search and variants of interpolation
search. In higher dimensions, the model learns solutions that resemble k-d
trees in some regimes, while in others, they have elements of
locality-sensitive hashing. The model can also learn useful representations of
high-dimensional data and exploit them to design effective data structures. We
also adapt our framework to the problem of estimating frequencies over a data
stream, and believe it could also be a powerful discovery tool for new
problems.

æè¦ï¼æåæåºä¸åéç¨çæ¶æ§ï¼ç¨æ¼è³æçµæ§çç«¯å°ç«¯å­¸ç¿ã
æåçæ¶æ§æé©æåºç¤è³æåä½ï¼ä¸¦æä¾å°æ¥è©¢åç©ºéè¤éåº¦çç´°ç·»æ§å¶ãè³ééè¦çæ¯ï¼è³æçµæ§æ¯å¾é ­éå§å­¸ç¿ï¼ä¸éè¦ä»ç´°åå§åæä½¿ç¨åé¸è³æçµæ§/æ¼ç®æ³é²è¡è¨­å®ãæåé¦åå°éåæ¶æ§æç¨å°æè¿é°æå°çåé¡ãå¨å¤ç¨®è¨­å®ä¸­ï¼æåè½å¤ éåå·¥ç¨å·²å­¸ç¿çè³æçµæ§åæ¥è©¢æ¼ç®æ³ãå°æ¼ 1D æè¿é°æå°ï¼æ¨¡åæç¼ç¾æä½³åä½ï¼å§é¨ï¼ç¨ç«æ¼ç®æ³ï¼ä¾å¦äºåæå°åå§ææå°è®é«ãå¨æ´é«ç¶­åº¦ä¸­ï¼æ¨¡åå­¸ç¿å°çè§£æå¨æäºæ¨¡å¼ä¸é¡ä¼¼æ¼ k-d æ¨¹ï¼èå¨å¶ä»æ¨¡å¼ä¸ï¼å®åæåå«å±é¨ææéæ¹çåç´ ãè©²æ¨¡åéå¯ä»¥å­¸ç¿é«ç¶­è³æçæç¨è¡¨ç¤ºï¼ä¸¦å©ç¨å®åä¾è¨­è¨ææçè³æçµæ§ãæåä¹å°æåçæ¶æ§èª¿æ´å°è³æä¸²æµä¸é »çä¼°è¨çåé¡ï¼ä¸¦ç¸ä¿¡å®å°æ¼æ°åé¡ä¾èªªä¹å¯è½æ¯ä¸åå¼·å¤§çç¼ç¾å·¥å·ã

##### **Evaluating Machine Learning Models against Clinical Protocols for Enhanced Interpretability and Continuity of Care**
2411.03105v1 by Christel Sirocchi, Muhammad Suffian, Federico Sabbatini, Alessandro Bogliolo, Sara Montagna

In clinical practice, decision-making relies heavily on established
protocols, often formalised as rules. Concurrently, Machine Learning (ML)
models, trained on clinical data, aspire to integrate into medical
decision-making processes. However, despite the growing number of ML
applications, their adoption into clinical practice remains limited. Two
critical concerns arise, relevant to the notions of consistency and continuity
of care: (a) accuracy - the ML model, albeit more accurate, might introduce
errors that would not have occurred by applying the protocol; (b)
interpretability - ML models operating as black boxes might make predictions
based on relationships that contradict established clinical knowledge. In this
context, the literature suggests using ML models integrating domain knowledge
for improved accuracy and interpretability. However, there is a lack of
appropriate metrics for comparing ML models with clinical rules in addressing
these challenges. Accordingly, in this article, we first propose metrics to
assess the accuracy of ML models with respect to the established protocol.
Secondly, we propose an approach to measure the distance of explanations
provided by two rule sets, with the goal of comparing the explanation
similarity between clinical rule-based systems and rules extracted from ML
models. The approach is validated on the Pima Indians Diabetes dataset by
training two neural networks - one exclusively on data, and the other
integrating a clinical protocol. Our findings demonstrate that the integrated
ML model achieves comparable performance to that of a fully data-driven model
while exhibiting superior accuracy relative to the clinical protocol, ensuring
enhanced continuity of care. Furthermore, we show that our integrated model
provides explanations for predictions that align more closely with the clinical
protocol compared to the data-driven model.

æè¦ï¼<paragraph>å¨è¨åºå¯¦åä¸­ï¼æ±ºç­ä»°è³´æ¢å®çåå®ï¼éå¸¸ä»¥è¦åå½¢å¼åãåæï¼ä»¥è¨åºè³æè¨ç·´çæ©å¨å­¸ç¿ (ML) æ¨¡åï¼æ¸´ææ´åå°é«çæ±ºç­æµç¨ä¸­ãç¶èï¼åç®¡ ML æç¨æ¸éæ¥å¢ï¼å®åå¨è¨åºå¯¦åä¸­çæ¡ç¨ä»åéãå©åééµçæ®æµ®ç¾ï¼èç§è­·çä¸è´æ§åé£çºæ§æ¦å¿µç¸éï¼(a) æºç¢ºæ§ - ML æ¨¡åéç¶æ´æºç¢ºï¼ä½å¯è½æå¼å¥å¥ç¨åå®æä¸æç¼ççé¯èª¤ï¼(b) å¯è§£éæ§ - ä½çºé»çéä½ç ML æ¨¡åå¯è½ææ ¹æèæ¢å®è¨åºç¥è­ç¸çç¾çéä¿é²è¡é æ¸¬ãå¨æ­¤èçµ¡ä¸­ï¼æç»å»ºè­°ä½¿ç¨æ´åé åç¥è­ç ML æ¨¡åä»¥æåæºç¢ºæ§åå¯è§£éæ§ãç¶èï¼ç¼ºä¹é©ç¶çææ¨ä¾æ¯è¼ ML æ¨¡åèè¨åºè¦åï¼ä»¥æå°éäºææ°ãå æ­¤ï¼å¨æ¬æä¸­ï¼æåé¦åæåºææ¨ä¾è©ä¼° ML æ¨¡åç¸å°æ¼æ¢å®åå®çæºç¢ºæ§ãå¶æ¬¡ï¼æåæåºä¸åæ¹æ³ä¾è¡¡éå©çµè¦åææä¾çè§£éçè·é¢ï¼ç®æ¨æ¯æ¯è¼åºæ¼è¨åºè¦åçç³»çµ±èå¾ ML æ¨¡åä¸­æåçè¦åä¹éçè§£éç¸ä¼¼æ§ãæ­¤æ¹æ³å¨ Pima å°å°å®äººç³å°¿çè³æéä¸é©è­ï¼æ¹æ³æ¯è¨ç·´å©åç¥ç¶ç¶²è·¯ - ä¸ååéå°è³æï¼å¦ä¸åæ´åè¨åºåå®ãæåçç ç©¶çµæè­æï¼æ´åå¼ ML æ¨¡åéå°äºèå®å¨è³æé©åæ¨¡åç¸ç¶çæè½ï¼åæå±ç¾åºç¸å°æ¼è¨åºåå®çåªç°æºç¢ºæ§ï¼ç¢ºä¿å¢å¼·çç§è­·é£çºæ§ãæ­¤å¤ï¼æåè­ææåçæ´åæ¨¡åæä¾çé æ¸¬è§£éèè¨åºåå®ç¸æ¯ï¼æ´çºç·å¯å°çµåã</paragraph>

##### **Local Lesion Generation is Effective for Capsule Endoscopy Image Data Augmentation in a Limited Data Setting**
2411.03098v1 by Adrian B. ChÅopowiec, Adam R. ChÅopowiec, Krzysztof Galus, Wojciech Cebula, Martin Tabakov

Limited medical imaging datasets challenge deep learning models by increasing
risks of overfitting and reduced generalization, particularly in Generative
Adversarial Networks (GANs), where discriminators may overfit, leading to
training divergence. This constraint also impairs classification models trained
on small datasets. Generative Data Augmentation (GDA) addresses this by
expanding training datasets with synthetic data, although it requires training
a generative model. We propose and evaluate two local lesion generation
approaches to address the challenge of augmenting small medical image datasets.
The first approach employs the Poisson Image Editing algorithm, a classical
image processing technique, to create realistic image composites that
outperform current state-of-the-art methods. The second approach introduces a
novel generative method, leveraging a fine-tuned Image Inpainting GAN to
synthesize realistic lesions within specified regions of real training images.
A comprehensive comparison of the two proposed methods demonstrates that
effective local lesion generation in a data-constrained setting allows for
reaching new state-of-the-art results in capsule endoscopy lesion
classification. Combination of our techniques achieves a macro F1-score of
33.07%, surpassing the previous best result by 7.84 percentage points (p.p.) on
the highly imbalanced Kvasir Capsule Dataset, a benchmark for capsule
endoscopy. To the best of our knowledge, this work is the first to apply a
fine-tuned Image Inpainting GAN for GDA in medical imaging, demonstrating that
an image-conditional GAN can be adapted effectively to limited datasets to
generate high-quality examples, facilitating effective data augmentation.
Additionally, we show that combining this GAN-based approach with classical
image processing techniques further enhances the results.

æè¦ï¼<paragraph>åéçé«å­¸å½±åè³æéæééå¢å éåº¦æ¬åçé¢¨éªåéä½æ¦åè½åï¼ç¹å¥æ¯å¨çæå°æç¶²è·¯ (GAN) ä¸­ï¼å¶ä¸­å¤å¥å¨å¯è½æéåº¦æ¬åï¼å°è´è¨ç·´åæ­§ï¼å°æ·±åº¦å­¸ç¿æ¨¡åæ§æææ°ãéç¨®éå¶ä¹æå®³äºå¨å°åè³æéä¸è¨ç·´çåé¡æ¨¡åãçæè³ææ´å (GDA) ééä½¿ç¨åæè³ææ´åè¨ç·´è³æéä¾è§£æ±ºæ­¤åé¡ï¼åç®¡å®éè¦è¨ç·´çææ¨¡åãæåæåºä¸¦è©ä¼°å©ç¨®å±é¨çç¶çææ¹æ³ï¼ä»¥è§£æ±ºæ´åå°åé«å­¸å½±åè³æéçææ°ãç¬¬ä¸ç¨®æ¹æ³æ¡ç¨æ³æ¾å½±åç·¨è¼¯æ¼ç®æ³ï¼ä¸ç¨®ç¶å¸å½±åèçæè¡ï¼ä¾å»ºç«é¼ççå½±ååæï¼å¶åªæ¼ç®åæåé²çæ¹æ³ãç¬¬äºç¨®æ¹æ³å¼é²ä¸ç¨®æ°ç©ççææ¹æ³ï¼å©ç¨å¾®èª¿çå½±åä¿®å¾© GANï¼å¨çå¯¦è¨ç·´å½±åçç¹å®ååå§åæé¼çççç¶ãå°éå©ç¨®æè­°æ¹æ³çå¨é¢æ¯è¼è­æï¼å¨è³æåéçè¨­å®ä¸­ï¼ææçå±é¨çç¶çæåè¨±å¨è åå§è¦é¡çç¶åé¡ä¸­éå°æ°çæåé²çµæãæåçæè¡çµåå¨é«åº¦ä¸å¹³è¡¡ç Kvasir Capsule è³æéï¼è åå§è¦é¡çåºæºï¼ä¸ï¼éå°äº 33.07% çå·¨è§ F1 åæ¸ï¼æ¯ååçæä½³çµæé«åº 7.84 åç¾åé» (p.p.)ãææåæç¥ï¼éé å·¥ä½æ¯ç¬¬ä¸åå°å¾®èª¿çå½±åä¿®å¾© GAN æç¨æ¼é«å­¸å½±åä¸­ç GDAï¼è­æäºå½±åæ¢ä»¶ GAN å¯ä»¥ææå°é©æåéçè³æéï¼ä»¥ç¢çé«åè³ªçç¯ä¾ï¼ä¿é²ææçè³ææ´åãæ­¤å¤ï¼æåè¡¨æå°éç¨®åºæ¼ GAN çæ¹æ³èç¶å¸å½±åèçæè¡ç¸çµåï¼é²ä¸æ­¥å¢å¼·äºçµæã</paragraph>

##### **Controlling for Unobserved Confounding with Large Language Model Classification of Patient Smoking Status**
2411.03004v1 by Samuel Lee, Zach Wood-Doughty

Causal understanding is a fundamental goal of evidence-based medicine. When
randomization is impossible, causal inference methods allow the estimation of
treatment effects from retrospective analysis of observational data. However,
such analyses rely on a number of assumptions, often including that of no
unobserved confounding. In many practical settings, this assumption is violated
when important variables are not explicitly measured in the clinical record.
Prior work has proposed to address unobserved confounding with machine learning
by imputing unobserved variables and then correcting for the classifier's
mismeasurement. When such a classifier can be trained and the necessary
assumptions are met, this method can recover an unbiased estimate of a causal
effect. However, such work has been limited to synthetic data, simple
classifiers, and binary variables. This paper extends this methodology by using
a large language model trained on clinical notes to predict patients' smoking
status, which would otherwise be an unobserved confounder. We then apply a
measurement error correction on the categorical predicted smoking status to
estimate the causal effect of transthoracic echocardiography on mortality in
the MIMIC dataset.

æè¦ï¼å æçè§£æ¯å¾ªè¯å»å­¦çåºæ¬ç®æ ãå½éæºåä¸å¯è¡æ¶ï¼å ææ¨è®ºæ¹æ³åè®¸ä»è§å¯æ§æ°æ®çåé¡¾æ§åæä¸­ä¼°è®¡æ²»çææãç¶èï¼æ­¤ç±»åæä¾èµäºè®¸å¤åè®¾ï¼éå¸¸åæ¬æ²¡ææªè§å¯å°çæ··æå ç´ ãå¨è®¸å¤å®éæåµä¸ï¼å½éè¦çåéå¨ä¸´åºè®°å½ä¸­æ²¡ææç¡®æµéæ¶ï¼è¿ä¸åè®¾å°±ä¼è¢«è¿åãååçå·¥ä½æåºç¨æºå¨å­¦ä¹ æ¥è§£å³æªè§å¯å°çæ··æé®é¢ï¼æ¹æ³æ¯æ¨ç®æªè§å¯å°çåéï¼ç¶åæ ¡æ­£åç±»å¨çæµéè¯¯å·®ãå½å¯ä»¥è®­ç»è¿æ ·çåç±»å¨å¹¶ä¸æ»¡è¶³å¿è¦çåè®¾æ¶ï¼è¿ç§æ¹æ³å¯ä»¥æ¢å¤å ææåºçæ åä¼°è®¡ãç¶èï¼æ­¤ç±»å·¥ä½ä»éäºåææ°æ®ãç®åçåç±»å¨åäºååéãæ¬æéè¿ä½¿ç¨å¨ä¸´åºè®°å½ä¸è®­ç»çå¤§è¯­è¨æ¨¡åæ¥é¢æµæ£èçå¸çç¶åµæ¥æ©å±è¿ç§æ¹æ³ï¼å¦åè¿å°æ¯ä¸ä¸ªæªè§å¯å°çæ··æå ç´ ãç¶åï¼æä»¬å¯¹åç±»é¢æµçå¸çç¶æåºç¨æµéè¯¯å·®æ ¡æ­£ï¼ä»¥ä¼°è®¡ç»è¸è¶å£°å¿å¨å¾å¯¹ MIMIC æ°æ®éä¸­æ­»äº¡ççå ææåºã

##### **Region-Guided Attack on the Segment Anything Model (SAM)**
2411.02974v2 by Xiaoliang Liu, Furao Shen, Jian Zhao

The Segment Anything Model (SAM) is a cornerstone of image segmentation,
demonstrating exceptional performance across various applications, particularly
in autonomous driving and medical imaging, where precise segmentation is
crucial. However, SAM is vulnerable to adversarial attacks that can
significantly impair its functionality through minor input perturbations.
Traditional techniques, such as FGSM and PGD, are often ineffective in
segmentation tasks due to their reliance on global perturbations that overlook
spatial nuances. Recent methods like Attack-SAM-K and UAD have begun to address
these challenges, but they frequently depend on external cues and do not fully
leverage the structural interdependencies within segmentation processes. This
limitation underscores the need for a novel adversarial strategy that exploits
the unique characteristics of segmentation tasks. In response, we introduce the
Region-Guided Attack (RGA), designed specifically for SAM. RGA utilizes a
Region-Guided Map (RGM) to manipulate segmented regions, enabling targeted
perturbations that fragment large segments and expand smaller ones, resulting
in erroneous outputs from SAM. Our experiments demonstrate that RGA achieves
high success rates in both white-box and black-box scenarios, emphasizing the
need for robust defenses against such sophisticated attacks. RGA not only
reveals SAM's vulnerabilities but also lays the groundwork for developing more
resilient defenses against adversarial threats in image segmentation.

æè¦ï¼å½±ååå²çåºç³çºåæ®µä»»ä½æ¨¡å (SAM)ï¼å¨åç¨®æç¨ä¸­å±ç¾åºè²çæè½ï¼ç¹å¥æ¯å¨èªåé§é§åé«çå½±åä¸­ï¼ç²¾æºçåå²è³ééè¦ãç¶èï¼SAM å®¹æåå°å°ææ»æï¼èå°ææ»æå¯è½ééè¼å¾®çè¼¸å¥æ¾åå¤§å¹æå®³å¶åè½æ§ãå³çµ±æè¡ï¼ä¾å¦ FGSM å PGDï¼éå¸¸å¨åå²ä»»åä¸­ç¡æï¼å çºå®åä¾è³´æ¼å¿½ç¥ç©ºéç´°å¾®å·®çå¨å±æ¾åãæè¿çæ¹æ³ï¼ä¾å¦ Attack-SAM-K å UADï¼å·²éå§è§£æ±ºéäºææ°ï¼ä½å®åç¶å¸¸ä¾è³´æ¼å¤é¨æç¤ºï¼ä¸ä¸¦æªååå©ç¨åå²éç¨ä¸­çµæ§æ§çç¸äºä¾è³´æ§ãæ­¤éå¶å¼·èª¿éè¦ä¸ç¨®æ°çå°æç­ç¥ï¼ä»¥å©ç¨åå²ä»»åçç¨ç¹ç¹æ§ãçºäºè§£æ±ºéååé¡ï¼æåå¼é²å°éçº SAM è¨­è¨çååå¼å°æ»æ (RGA)ãRGA å©ç¨ååå¼å°å°å (RGM) ææ§åå²ååï¼é²èéå°æ¾åé²è¡æ¨å®ï¼å°å¤§ååæ®µåå²ä¸¦æ´å±è¼å°çåæ®µï¼å°è´ SAM ç¢çé¯èª¤è¼¸åºãæåçå¯¦é©è­æï¼RGA å¨ç½çåé»çå ´æ¯ä¸­é½åå¾é«æåçï¼å¼·èª¿éè¦éå°æ­¤é¡ç²¾å¯æ»æå»ºç«å¼·åºçé²ç¦¦æ©å¶ãRGA ä¸åæ­é² SAM çæ¼æ´ï¼ä¹çºå¨å½±ååå²ä¸­éå°å°æå¨èç¼å±æ´å·å¾©ååçé²ç¦¦æªæ½å¥ å®åºç¤ã

##### **[Vision Paper] PRObot: Enhancing Patient-Reported Outcome Measures for Diabetic Retinopathy using Chatbots and Generative AI**
2411.02973v1 by Maren Pielka, Tobias Schneider, Jan Terheyden, Rafet Sifa

We present an outline of the first large language model (LLM) based chatbot
application in the context of patient-reported outcome measures (PROMs) for
diabetic retinopathy. By utilizing the capabilities of current LLMs, we enable
patients to provide feedback about their quality of life and treatment progress
via an interactive application. The proposed framework offers significant
advantages over the current approach, which encompasses only qualitative
collection of survey data or a static survey with limited answer options. Using
the PROBot LLM-PROM application, patients will be asked tailored questions
about their individual challenges, and can give more detailed feedback on the
progress of their treatment. Based on this input, we will use machine learning
to infer conventional PROM scores, which can be used by clinicians to evaluate
the treatment status. The goal of the application is to improve adherence to
the healthcare system and treatments, and thus ultimately reduce cases of
subsequent vision impairment. The approach needs to be further validated using
a survey and a clinical study.

æè¦ï¼æåæåºä¸ååºæ¼ç¬¬ä¸åå¤§åèªè¨æ¨¡å (LLM) çèå¤©æ©å¨äººæç¨ç¨å¼ï¼ç¨æ¼ç³å°¿çè¦ç¶²èçè®ççäººåå ±çµææ¸¬é (PROM)ãééå©ç¨ç¶å LLM çåè½ï¼æåè®çäººè½å¤ ééäºåå¼æç¨ç¨å¼æä¾æéå¶çæ´»åè³ªåæ²»çé²åº¦çåé¥ãææåºçæ¶æ§æä¾é¡¯èåªæ¼ç®åæ¹æ³çåªé»ï¼ç®åæ¹æ³ååå«èª¿æ¥è³æçè³ªæ§æ¶éæå·ææéç­æ¡é¸é çéæèª¿æ¥ãä½¿ç¨ PROBot LLM-PROM æç¨ç¨å¼ï¼çäººå°æè¢«è©¢åæéå¶åäººææ°çå®¢è£½ååé¡ï¼ä¸¦è½æä¾æ´è©³ç´°çåé¥ï¼èªªæå¶æ²»çé²åº¦ãæ ¹ææ­¤è¼¸å¥ï¼æåå°ä½¿ç¨æ©å¨å­¸ç¿æ¨è«å³çµ± PROM åæ¸ï¼è¨åºé«çå¯ä»¥ä½¿ç¨éäºåæ¸ä¾è©ä¼°æ²»ççæãæ­¤æç¨ç¨å¼çç®æ¨æ¯æ¹åå°é«çä¿å¥ç³»çµ±åæ²»ççä¾å¾æ§ï¼ä¸¦å æ­¤æçµæ¸å°å¾çºè¦åæå®³ççä¾ãéè¦ä½¿ç¨èª¿æ¥åè¨åºç ç©¶é²ä¸æ­¥é©è­æ­¤æ¹æ³ã

##### **Leveraging Transfer Learning and Multiple Instance Learning for HER2 Automatic Scoring of H\&E Whole Slide Images**
2411.05028v1 by Rawan S. Abdulsadig, Bryan M. Williams, Nikolay Burlutskiy

Expression of human epidermal growth factor receptor 2 (HER2) is an important
biomarker in breast cancer patients who can benefit from cost-effective
automatic Hematoxylin and Eosin (H\&E) HER2 scoring. However, developing such
scoring models requires large pixel-level annotated datasets. Transfer learning
allows prior knowledge from different datasets to be reused while
multiple-instance learning (MIL) allows the lack of detailed annotations to be
mitigated. The aim of this work is to examine the potential of transfer
learning on the performance of deep learning models pre-trained on (i)
Immunohistochemistry (IHC) images, (ii) H\&E images and (iii) non-medical
images. A MIL framework with an attention mechanism is developed using
pre-trained models as patch-embedding models. It was found that embedding
models pre-trained on H\&E images consistently outperformed the others,
resulting in an average AUC-ROC value of $0.622$ across the 4 HER2 scores
($0.59-0.80$ per HER2 score). Furthermore, it was found that using
multiple-instance learning with an attention layer not only allows for good
classification results to be achieved, but it can also help with producing
visual indication of HER2-positive areas in the H\&E slide image by utilising
the patch-wise attention weights.

æè¦ï¼äººé¡è¡¨ç®çé·å å­åé« 2 (HER2) çè¡¨ç¾æ¯ä¹³çæ£èä¸­çä¸é éè¦çç©æ¨è¨ï¼éäºæ£èå¯ä»¥åçæ¼å·æææ¬æççèªåèæ¨ç²¾åä¼ç´ (H&E) HER2 è©åãç¶èï¼éç¼æ­¤é¡è©åæ¨¡åéè¦å¤§éçåç´ ç´è¨»è§£è³æéãé·ç§»å­¸ç¿åè¨±éè¤ä½¿ç¨ä¾èªä¸åè³æéçåé©ç¥è­ï¼èå¤å¯¦ä¾å­¸ç¿ (MIL) åè¨±æ¸è¼è©³ç´°è¨»è§£çç¼ºä¹ãéé å·¥ä½çç®çæ¯æª¢æ¥é·ç§»å­¸ç¿å¨é åè¨ç·´æ¼ (i) åç«çµç¹åå­¸ (IHC) å½±åã(ii) H&E å½±åå (iii) éé«å­¸å½±åä¸çæ·±åº¦å­¸ç¿æ¨¡åçæè½ä¸çæ½åãä½¿ç¨é åè¨ç·´çæ¨¡åä½çºåå¡åµå¥æ¨¡åï¼éç¼äºä¸åå·ææ³¨æåæ©å¶ç MIL æ¡æ¶ãç ç©¶ç¼ç¾ï¼é åè¨ç·´æ¼ H&E å½±åä¸çåµå¥æ¨¡åå§çµåªæ¼å¶ä»æ¨¡åï¼å¨ 4 å HER2 åæ¸ä¸­ç¢çå¹³å AUC-ROC å¼çº $0.622$ï¼æ¯å HER2 åæ¸çº $0.59-0.80$ï¼ãæ­¤å¤ï¼ç ç©¶ç¼ç¾ï¼ä½¿ç¨å·ææ³¨æåå±¤çå¤å¯¦ä¾å­¸ç¿ä¸åå¯ä»¥ç²å¾è¯å¥½çåé¡çµæï¼éå¯ä»¥å¹«å©ééå©ç¨åå¡æ³¨æåæ¬éç¢ç H&E ç»çå½±åä¸­ HER2 é½æ§ååçå¯è¦åæç¤ºã

##### **Membership Inference Attacks against Large Vision-Language Models**
2411.02902v1 by Zhan Li, Yongtao Wu, Yihang Chen, Francesco Tonin, Elias Abad Rocamora, Volkan Cevher

Large vision-language models (VLLMs) exhibit promising capabilities for
processing multi-modal tasks across various application scenarios. However,
their emergence also raises significant data security concerns, given the
potential inclusion of sensitive information, such as private photos and
medical records, in their training datasets. Detecting inappropriately used
data in VLLMs remains a critical and unresolved issue, mainly due to the lack
of standardized datasets and suitable methodologies. In this study, we
introduce the first membership inference attack (MIA) benchmark tailored for
various VLLMs to facilitate training data detection. Then, we propose a novel
MIA pipeline specifically designed for token-level image detection. Lastly, we
present a new metric called MaxR\'enyi-K%, which is based on the confidence of
the model output and applies to both text and image data. We believe that our
work can deepen the understanding and methodology of MIAs in the context of
VLLMs. Our code and datasets are available at
https://github.com/LIONS-EPFL/VL-MIA.

æè¦ï¼å¤§åè¦è¦ºèªè¨æ¨¡å (VLLM) å¨èçåç¨®æç¨å ´æ¯çå¤æ¨¡æä»»åæ¹é¢è¡¨ç¾åºæåæ¯çè½åãç¶èï¼å®åçåºç¾ä¹å¼ç¼äºéå¤§çè³æå®å¨åé¡ï¼å çºå®åçè¨ç·´è³æéä¸­å¯è½æåå«ææè³è¨ï¼ä¾å¦ç§äººç§çåé«çè¨éãåµæ¸¬ VLLM ä¸­ä¸ç¶ä½¿ç¨çè³æä»ç¶æ¯ä¸åééµä¸å°æªè§£æ±ºçåé¡ï¼ä¸»è¦æ¯ç±æ¼ç¼ºä¹æ¨æºåçè³æéåé©ç¶çæ¹æ³ãå¨æ¬ç ç©¶ä¸­ï¼æåå¼å¥äºç¬¬ä¸åéå°åç¨® VLLM éèº«æé çæå¡æ¨è«æ»æ (MIA) åºæºï¼ä»¥å©æ¼è¨ç·´è³æåµæ¸¬ãç¶å¾ï¼æåæåºäºä¸åå°éè¨­è¨ç¨æ¼ä»¤çç´å¥å½±ååµæ¸¬çå¨æ° MIA ç®¡ç·ãæå¾ï¼æåæåºä¸ååçº MaxR\'enyi-K% çæ°ææ¨ï¼å®åºæ¼æ¨¡åè¼¸åºçä¿¡å¿ï¼ä¸¦é©ç¨æ¼æå­åå½±åè³æãæåç¸ä¿¡ï¼æåçç ç©¶å¯ä»¥å æ·±å° VLLM èæ¯ä¸ MIA ççè§£åæ¹æ³ãæåçç¨å¼ç¢¼åè³æéå¯å¨ https://github.com/LIONS-EPFL/VL-MIA åå¾ã

##### **Advanced XR-Based 6-DOF Catheter Tracking System for Immersive Cardiac Intervention Training**
2411.02611v1 by Mohsen Annabestani, Sandhya Sriram, S. Chiu Wong, Alexandros Sigaras, Bobak Mosadegh

Extended Reality (XR) technologies are gaining traction as effective tools
for medical training and procedural guidance, particularly in complex cardiac
interventions. This paper presents a novel system for real-time 3D tracking and
visualization of intracardiac echocardiography (ICE) catheters, with precise
measurement of the roll angle. A custom 3D-printed setup, featuring orthogonal
cameras, captures biplane video of the catheter, while a specialized computer
vision algorithm reconstructs its 3D trajectory, localizing the tip with
sub-millimeter accuracy and tracking the roll angle in real-time. The system's
data is integrated into an interactive Unity-based environment, rendered
through the Meta Quest 3 XR headset, combining a dynamically tracked catheter
with a patient-specific 3D heart model. This immersive environment allows the
testing of the importance of 3D depth perception, in comparison to 2D
projections, as a form of visualization in XR. Our experimental study,
conducted using the ICE catheter with six participants, suggests that 3D
visualization is not necessarily beneficial over 2D views offered by the XR
system; although all cardiologists saw its utility for pre-operative training,
planning, and intra-operative guidance. The proposed system qualitatively shows
great promise in transforming catheter-based interventions, particularly ICE
procedures, by improving visualization, interactivity, and skill development.

æè¦ï¼æ´å¢å¯¦å¢ (XR) æè¡æ­£ä½çºé«çè¨ç·´åç¨åºæå°çææå·¥å·èç²å¾éè¦ï¼ç¹å¥æ¯å¨è¤éçå¿èä»å¥æ²»çä¸­ãæ¬ææåºäºä¸åæ°çç³»çµ±ï¼ç¨æ¼å¯¦æ 3D è¿½è¹¤åå¯è¦åå¿å§è¶è²å¿åå (ICE) å°ç®¡ï¼ä¸¦ç²¾ç¢ºæ¸¬éæ»¾åè§åº¦ãä¸åå®¢è£½åç 3D åå°è¨­å®ï¼éåæ­£äº¤ç¸æ©ï¼ææå°ç®¡çéå¹³é¢å½±çï¼èä¸åå°éçé»è¦è¦è¦ºæ¼ç®æ³éå»ºå¶ 3D è»è·¡ï¼ä»¥å°æ¼æ¯«ç±³çç²¾ç¢ºåº¦å®ä½å°ç«¯ä¸¦å³æè¿½è¹¤æ»¾åè§åº¦ãç³»çµ±çè³ææ´åå°ä¸åäºåå¼ç Unity çºåºç¤çç°å¢ä¸­ï¼éé Meta Quest 3 XR é ­æ´å¼è£ç½®åç¾ï¼çµååæè¿½è¹¤çå°ç®¡åç¹å®çæ£ç 3D å¿èæ¨¡åãéåæ²æµ¸å¼çç°å¢åè¨±æ¸¬è©¦ 3D æ·±åº¦æç¥çéè¦æ§ï¼è 2D æå½±ç¸æ¯ï¼ä½çº XR ä¸­çä¸ç¨®è¦è¦ºåå½¢å¼ãæåçå¯¦é©ç ç©¶ï¼ä½¿ç¨ ICE å°ç®¡é²è¡ï¼æå­ä½åèèï¼é¡¯ç¤º 3D è¦è¦ºåä¸ä¸å®æ¯ XR ç³»çµ±æä¾ç 2D è¦åæçï¼åç®¡ææå¿èç§é«å¸«é½çå°å®å¨è¡åè¨ç·´ãè¦ååè¡ä¸­æå°ä¸­çç¨éãææåºçç³»çµ±å¨è³ªåä¸é¡¯ç¤ºåºå¨è½æå°ç®¡ä»å¥æ²»çï¼ç¹å¥æ¯ ICE ç¨åºæ¹é¢ï¼ééæ¹åè¦è¦ºåãäºåæ§åæè½ç¼å±ï¼å·æå¾å¤§çåæ¯ã

##### **"It's a conversation, not a quiz": A Risk Taxonomy and Reflection Tool for LLM Adoption in Public Health**
2411.02594v1 by Jiawei Zhou, Amy Z. Chen, Darshi Shah, Laura Schwab Reese, Munmun De Choudhury

Recent breakthroughs in large language models (LLMs) have generated both
interest and concern about their potential adoption as accessible information
sources or communication tools across different domains. In public health --
where stakes are high and impacts extend across populations -- adopting LLMs
poses unique challenges that require thorough evaluation. However, structured
approaches for assessing potential risks in public health remain
under-explored. To address this gap, we conducted focus groups with health
professionals and health issue experiencers to unpack their concerns, situated
across three distinct and critical public health issues that demand
high-quality information: vaccines, opioid use disorder, and intimate partner
violence. We synthesize participants' perspectives into a risk taxonomy,
distinguishing and contextualizing the potential harms LLMs may introduce when
positioned alongside traditional health communication. This taxonomy highlights
four dimensions of risk in individual behaviors, human-centered care,
information ecosystem, and technology accountability. For each dimension, we
discuss specific risks and example reflection questions to help practitioners
adopt a risk-reflexive approach. This work offers a shared vocabulary and
reflection tool for experts in both computing and public health to
collaboratively anticipate, evaluate, and mitigate risks in deciding when to
employ LLM capabilities (or not) and how to mitigate harm when they are used.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°çªç ´å¼èµ·äºäººåçèè¶£ï¼ä¹å¼èµ·äºäººåå°å¶ä½çºä¸åé åçç¡éç¤ä¿¡æ¯ä¾æºæéä¿¡å·¥å·çæ½å¨æ¡ç¨æç¢ççææãå¨å¬å±è¡çé åââå©å®³éä¿å¾é«ä¸å½±é¿éåäººç¾¤ââæ¡ç¨ LLM æ§æäºç¨ç¹çææ°ï¼éè¦å¾¹åºè©ä¼°ãç¶èï¼è©ä¼°å¬å±è¡çä¸­æ½å¨é¢¨éªççµæ§åæ¹æ³ä»æªå¾å°ååæ¢ç´¢ãçºäºè§£æ±ºéä¸å·®è·ï¼æåèé«çå°æ¥­äººå¡åå¥åº·åé¡é«é©èé²è¡äºç¦é»å°çµï¼ä»¥è§£éä»åççæ®ï¼éäºçæ®æ¶åä¸åä¸åçééµå¬å±è¡çåé¡ï¼éäºåé¡éè¦é«è³ªéçè³è¨ï¼ç«èãé¿çé¡è¥ç©ä½¿ç¨éç¤åè¦ªå¯ä¼´ä¾¶æ´åãæåå°åèèçè§é»ç¶åå°é¢¨éªåé¡æ³ä¸­ï¼åååæå¢å LLM å¨èå³çµ±å¥åº·å³æ­ä¸¦åæå¯è½é æçæ½å¨å±å®³ãéç¨®åé¡æ³çªåºäºåäººè¡çºãä»¥äººçºä¸­å¿çè­·çãè³è¨çæç³»çµ±åæè¡åè²¬å¶éååç¶­åº¦çé¢¨éªãå°æ¼æ¯åç¶­åº¦ï¼æåè¨è«å·é«çé¢¨éªåç¯ä¾åæåé¡ï¼ä»¥å¹«å©å¾æ¥­èæ¡ç¨é¢¨éªåææ¹æ³ãéé å·¥ä½çºè¨ç®åå¬å±è¡çé åçå°å®¶æä¾äºä¸åå±åçè©å½ååæå·¥å·ï¼ä»¥ä¾¿å¨æ±ºå®ä½ææ¡ç¨ LLM åè½ï¼æä¸æ¡ç¨ï¼ä»¥åå¨ä½¿ç¨ LLM åè½æå¦ä½æ¸è¼å±å®³æï¼å±åé æ¸¬ãè©ä¼°åæ¸è¼é¢¨éªã

##### **Digitizing Touch with an Artificial Multimodal Fingertip**
2411.02479v1 by Mike Lambeta, Tingfan Wu, Ali Sengul, Victoria Rose Most, Nolan Black, Kevin Sawyer, Romeo Mercado, Haozhi Qi, Alexander Sohn, Byron Taylor, Norb Tydingco, Gregg Kammerer, Dave Stroud, Jake Khatha, Kurt Jenkins, Kyle Most, Neal Stein, Ricardo Chavira, Thomas Craven-Bartle, Eric Sanchez, Yitian Ding, Jitendra Malik, Roberto Calandra

Touch is a crucial sensing modality that provides rich information about
object properties and interactions with the physical environment. Humans and
robots both benefit from using touch to perceive and interact with the
surrounding environment (Johansson and Flanagan, 2009; Li et al., 2020;
Calandra et al., 2017). However, no existing systems provide rich, multi-modal
digital touch-sensing capabilities through a hemispherical compliant
embodiment. Here, we describe several conceptual and technological innovations
to improve the digitization of touch. These advances are embodied in an
artificial finger-shaped sensor with advanced sensing capabilities.
Significantly, this fingertip contains high-resolution sensors (~8.3 million
taxels) that respond to omnidirectional touch, capture multi-modal signals, and
use on-device artificial intelligence to process the data in real time.
Evaluations show that the artificial fingertip can resolve spatial features as
small as 7 um, sense normal and shear forces with a resolution of 1.01 mN and
1.27 mN, respectively, perceive vibrations up to 10 kHz, sense heat, and even
sense odor. Furthermore, it embeds an on-device AI neural network accelerator
that acts as a peripheral nervous system on a robot and mimics the reflex arc
found in humans. These results demonstrate the possibility of digitizing touch
with superhuman performance. The implications are profound, and we anticipate
potential applications in robotics (industrial, medical, agricultural, and
consumer-level), virtual reality and telepresence, prosthetics, and e-commerce.
Toward digitizing touch at scale, we open-source a modular platform to
facilitate future research on the nature of touch.

æè¦ï¼è§¸è¦ºæ¯ä¸ç¨®è³ééè¦çææ¸¬æ¹å¼ï¼å¯æä¾éæ¼ç©é«å±¬æ§åèç©çç°å¢äº¤äºä½ç¨çè±å¯è³è¨ãäººé¡åæ©å¨äººé½åçæ¼ä½¿ç¨è§¸è¦ºä¾æç¥åèå¨åç°å¢äºåï¼Johansson and Flanagan, 2009; Li et al., 2020; Calandra et al., 2017ï¼ãç¶èï¼æ²æç¾æç³»çµ±ééåçå½¢é ææ§å·èº«åæä¾è±å¯çå¤æ¨¡å¼æ¸ä½è§¸è¦ºææ¸¬åè½ãå¨æ­¤ï¼æåæè¿°äºå¹¾åæ¦å¿µåæè¡åµæ°ï¼ä»¥æ¹åè§¸è¦ºçæ¸ä½åãéäºé²å±é«ç¾å¨å·ååé²ææ¸¬åè½çäººå·¥ææå½¢ææ¸¬å¨ä¸­ãéè¦çæ¯ï¼éåæå°åå«é«è§£æåº¦ææ¸¬å¨ï¼ç´ 830 è¬åè§¸è¦ºé»ï¼ï¼å¯å°å¨æ¹ä½è§¸è¦ºååºåæãæ·åå¤æ¨¡å¼è¨èï¼ä¸¦ä½¿ç¨è£ç½®ä¸çäººå·¥æºæ§å³æèçè³æãè©ä¼°é¡¯ç¤ºï¼äººå·¥æå°å¯ä»¥è§£æå°è³ 7 å¾®ç±³çç©ºéç¹å¾µï¼ä»¥ 1.01 æ¯«çé å 1.27 æ¯«çé çè§£æåº¦ææ¸¬æ³ååååªååï¼æç¥é«é 10 åèµ«çæ¯åãææ¸¬ç±ï¼çè³ææ¸¬æ°£å³ãæ­¤å¤ï¼å®å§åµäºä¸åè£ç½®ä¸ç AI ç¥ç¶ç¶²è·¯å éå¨ï¼ä½çºæ©å¨äººçå¨éç¥ç¶ç³»çµ±ï¼ä¸¦æ¨¡ä»¿äººé¡çåå°å¼§ãéäºçµæè­æäºä»¥è¶äººé¡æè½æ¸ä½åè§¸è¦ºçå¯è½æ§ãå¶å½±é¿æ·±é ï¼æåé æå¨æ©å¨äººæè¡ï¼å·¥æ¥­ãé«çãè¾²æ¥­åæ¶è²»èå±¤ç´ï¼ãèæ¬å¯¦å¢åé è·è¨å ´ãåè¢åé»å­ååä¸­æ½å¨çæç¨ãçºäºå¤§è¦æ¨¡æ¸ä½åè§¸è¦ºï¼æåéæ¾åå§ç¢¼ä¸åæ¨¡çµåå¹³å°ï¼ä»¥ä¿é²æªä¾å°è§¸è¦ºæ¬è³ªçç ç©¶ã

##### **Simulation of Nanorobots with Artificial Intelligence and Reinforcement Learning for Advanced Cancer Cell Detection and Tracking**
2411.02345v1 by Shahab Kavousinejad

Nanorobots are a promising development in targeted drug delivery and the
treatment of neurological disorders, with potential for crossing the
blood-brain barrier (BBB). These small devices leverage advancements in
nanotechnology and bioengineering for precise navigation and targeted payload
delivery, particularly for conditions like brain tumors, Alzheimer's disease,
and Parkinson's disease. Recent progress in artificial intelligence (AI) and
machine learning (ML) has improved the navigation and effectiveness of
nanorobots, allowing them to detect and interact with cancer cells through
biomarker analysis. This study presents a new reinforcement learning (RL)
framework for optimizing nanorobot navigation in complex biological
environments, focusing on cancer cell detection by analyzing the concentration
gradients of surrounding biomarkers. We utilize a computer simulation model to
explore the behavior of nanorobots in a three-dimensional space with cancer
cells and biological barriers. The proposed method uses Q-learning to refine
movement strategies based on real-time biomarker concentration data, enabling
nanorobots to autonomously navigate to cancerous tissues for targeted drug
delivery. This research lays the groundwork for future laboratory experiments
and clinical applications, with implications for personalized medicine and less
invasive cancer treatments. The integration of intelligent nanorobots could
revolutionize therapeutic strategies, reducing side effects and enhancing
treatment effectiveness for cancer patients. Further research will investigate
the practical deployment of these technologies in medical settings, aiming to
unlock the full potential of nanorobotics in healthcare.

æè¦ï¼å¥ç±³æ©å¨äººå¨æ¨é¶è¥ç©å³è¼¸åç¥ç¶ç¾çæ²»çä¸­æ¯ä¸é æåæ¯çç¼å±ï¼ä¸¦å·æç©¿è¶è¡è¦å±é (BBB) çæ½åãéäºå°åè£ç½®å©ç¨å¥ç±³æè¡åçç©å·¥ç¨çé²å±ï¼é²è¡ç²¾ç¢ºå°èªåæ¨é¶ææè¼è·å³è¼¸ï¼ç¹å¥æ¯éå°è¦ç¤ãé¿è²æµ·é»çåå¸éæ£®æ°çç­ç¾çãäººå·¥æºæ§ (AI) åæ©å¨å­¸ç¿ (ML) çææ°é²å±æ¹åäºå¥ç±³æ©å¨äººçå°èªåæè½ï¼è®å®åè½ééçç©æ¨è¨åæä¾åµæ¸¬åèçç´°èäºåãæ¬ç ç©¶æåºäºä¸åæ°çå¼·åå­¸ç¿ (RL) æ¶æ§ï¼ç¨æ¼æä½³åå¥ç±³æ©å¨äººå¨è¤éçç©ç°å¢ä¸­çå°èªï¼éé»å¨æ¼ééåæå¨åçç©æ¨è¨çæ¿åº¦æ¢¯åº¦ä¾åµæ¸¬çç´°èãæåå©ç¨é»è¦æ¨¡æ¬æ¨¡åä¾æ¢ç´¢å¥ç±³æ©å¨äººå¨ä¸ç¶­ç©ºéä¸­èçç´°èåçç©éç¤ç©ä¹éçè¡çºãææåºçæ¹æ³ä½¿ç¨ Q å­¸ç¿ä¾æ ¹æå³æçç©æ¨è¨æ¿åº¦è³æèª¿æ´ç§»åç­ç¥ï¼è®å¥ç±³æ©å¨äººè½èªä¸»å°èªè³ççµç¹é²è¡æ¨é¶è¥ç©å³è¼¸ãéé ç ç©¶çºæªä¾çå¯¦é©å®¤å¯¦é©åè¨åºæç¨å¥ å®äºåºç¤ï¼ä¸¦å°åäººåé«çåä¾µå¥æ§è¼å°çççæ²»çç¢çå½±é¿ãæ´åæºæ§å¥ç±³æ©å¨äººå¯ä»¥é©æ°æ²»çç­ç¥ï¼æ¸å°å¯ä½ç¨ä¸¦æé«ççæ£èçæ²»çææãé²ä¸æ­¥çç ç©¶å°æ¢è¨éäºæè¡å¨é«çç°å¢ä¸­çå¯¦éé¨ç½²ï¼ç®æ¨æ¯ç¼æ®å¥ç±³æ©å¨äººå¨é«çä¿å¥ä¸­çå¨é¨æ½åã

##### **Taking AI Welfare Seriously**
2411.00986v1 by Robert Long, Jeff Sebo, Patrick Butlin, Kathleen Finlinson, Kyle Fish, Jacqueline Harding, Jacob Pfau, Toni Sims, Jonathan Birch, David Chalmers

In this report, we argue that there is a realistic possibility that some AI
systems will be conscious and/or robustly agentic in the near future. That
means that the prospect of AI welfare and moral patienthood, i.e. of AI systems
with their own interests and moral significance, is no longer an issue only for
sci-fi or the distant future. It is an issue for the near future, and AI
companies and other actors have a responsibility to start taking it seriously.
We also recommend three early steps that AI companies and other actors can
take: They can (1) acknowledge that AI welfare is an important and difficult
issue (and ensure that language model outputs do the same), (2) start assessing
AI systems for evidence of consciousness and robust agency, and (3) prepare
policies and procedures for treating AI systems with an appropriate level of
moral concern. To be clear, our argument in this report is not that AI systems
definitely are, or will be, conscious, robustly agentic, or otherwise morally
significant. Instead, our argument is that there is substantial uncertainty
about these possibilities, and so we need to improve our understanding of AI
welfare and our ability to make wise decisions about this issue. Otherwise
there is a significant risk that we will mishandle decisions about AI welfare,
mistakenly harming AI systems that matter morally and/or mistakenly caring for
AI systems that do not.

æè¦ï¼å¨éä»½å ±åä¸­ï¼æåèªçºæäº AI ç³»çµ±å¨ä¸ä¹çå°ä¾æç¾å¯¦çå¯è½æ§æå·ææè­å/æå¼·å¤§çè½åæ§ãéè¡¨ç¤º AI ç¦å©åéå¾·ä¸ççäººå°ä½çåæ¯ï¼äº¦å³å·æèªèº«å©çåéå¾·æç¾©ç AI ç³»çµ±ï¼ä¸ååªæ¯ç§å¹»å°èªªæéé æªä¾çè­°é¡ãéæ¯è¿æªä¾çè­°é¡ï¼è AI å¬å¸åå¶ä»è¡çºèæè²¬ä»»éå§èªççå¾å®ãæåä¹å»ºè­° AI å¬å¸åå¶ä»è¡çºèå¯ä»¥æ¡åä¸åæ©æçæ­¥é©ï¼ä»åå¯ä»¥ (1) æ¿èª AI ç¦å©æ¯ä¸åéè¦ä¸å°é£çè­°é¡ï¼ä¸¦ç¢ºä¿èªè¨æ¨¡åçè¼¸åºä¹ééº¼åï¼ï¼(2) éå§è©ä¼° AI ç³»çµ±æ¯å¦ææè­åå¼·å¤§è½åæ§çè­æï¼ä»¥å (3) æºåæ¿ç­åç¨åºï¼ä»¥é©ç¶çéå¾·éæ³¨å±¤ç´ä¾å°å¾ AI ç³»çµ±ãæç¢ºä¾èªªï¼æåå¨éä»½å ±åä¸­çè«é»ä¸¦é AI ç³»çµ±çµå°æ¯æå°æå·ææè­ãå¼·å¤§çè½åæ§æå¶ä»éå¾·æç¾©ãç¸åå°ï¼æåçè«é»æ¯éæ¼éäºå¯è½æ§å­å¨èå¯¦è³ªçä¸ç¢ºå®æ§ï¼å æ­¤æåéè¦å¢é²æåå° AI ç¦å©çäºè§£ï¼ä»¥åæåååºéæ¼æ­¤è­°é¡çææºæ±ºå®çè½åãå¦åï¼æåå°é¢è¨éå¤§é¢¨éªï¼é¯èª¤å°èçéæ¼ AI ç¦å©çæ±ºç­ï¼é¯èª¤å°å·å®³å°å¨éå¾·ä¸éè¦ç AI ç³»çµ±ï¼å/æé¯èª¤å°ç§é¡§å°å¨éå¾·ä¸ä¸éè¦ç AI ç³»çµ±ã

##### **Federated GNNs for EEG-Based Stroke Assessment**
2411.02286v1 by Andrea Protani, Lorenzo Giusti, Albert Sund Aillet, Simona Sacco, Paolo Manganotti, Lucio Marinelli, Diogo Reis Santos, Pierpaolo Brutti, Pietro Caliandro, Luigi Serio

Machine learning (ML) has the potential to become an essential tool in
supporting clinical decision-making processes, offering enhanced diagnostic
capabilities and personalized treatment plans. However, outsourcing medical
records to train ML models using patient data raises legal, privacy, and
security concerns. Federated learning has emerged as a promising paradigm for
collaborative ML, meeting healthcare institutions' requirements for robust
models without sharing sensitive data and compromising patient privacy. This
study proposes a novel method that combines federated learning (FL) and Graph
Neural Networks (GNNs) to predict stroke severity using electroencephalography
(EEG) signals across multiple medical institutions. Our approach enables
multiple hospitals to jointly train a shared GNN model on their local EEG data
without exchanging patient information. Specifically, we address a regression
problem by predicting the National Institutes of Health Stroke Scale (NIHSS), a
key indicator of stroke severity. The proposed model leverages a masked
self-attention mechanism to capture salient brain connectivity patterns and
employs EdgeSHAP to provide post-hoc explanations of the neurological states
after a stroke. We evaluated our method on EEG recordings from four
institutions, achieving a mean absolute error (MAE) of 3.23 in predicting
NIHSS, close to the average error made by human experts (MAE $\approx$ 3.0).
This demonstrates the method's effectiveness in providing accurate and
explainable predictions while maintaining data privacy.

æè¦ï¼æ©å¨å­¸ç¿ (ML) ææ½åæçºæ¯æ´è¨åºæ±ºç­å¶å®æµç¨çå¿è¦å·¥å·ï¼æä¾å¢å¼·çè¨ºæ·è½åååäººåæ²»çè¨ç«ãç¶èï¼ä½¿ç¨çæ£è³æè¨ç·´æ©å¨å­¸ç¿æ¨¡åçå¤åé«çç´éå¼ç¼äºæ³å¾ãé±ç§åå®å¨æ¹é¢ççæ®ãè¯åå­¸ç¿å·²æçºåä½æ©å¨å­¸ç¿çä¸ç¨®æåæ¯çå¸ç¯ï¼å®ç¬¦åé«çä¿å¥æ©æ§å°ç©©å¥æ¨¡åçè¦æ±ï¼åæä¸æåäº«ææè³æåå±å®³çæ£é±ç§ãæ¬ç ç©¶æåºäºä¸ç¨®æ°çæ¹æ³ï¼çµåè¯åå­¸ç¿ (FL) ååå½¢ç¥ç¶ç¶²è·¯ (GNN) ä¾ä½¿ç¨è¦é»å (EEG) è¨èé æ¸¬å¤åé«çæ©æ§çè¦ä¸­é¢¨å´éç¨åº¦ãæåçåæ³è®å¤å®¶é«é¢è½å¤ å±åå¨ä»åçæ¬å° EEG è³æä¸è¨ç·´ä¸åå±äº«ç GNN æ¨¡åï¼èç¡éäº¤æçæ£è³è¨ãå·é«ä¾èªªï¼æåééé æ¸¬ç¾ååå®¶è¡çç ç©¶é¢è¦ä¸­é¢¨éè¡¨ (NIHSS) ä¾è§£æ±ºåæ­¸åé¡ï¼NIHSS æ¯è¦ä¸­é¢¨å´éç¨åº¦çä¸åééµææ¨ãææåºçæ¨¡åå©ç¨é®ç½©èªææ³¨ææ©å¶ä¾æ·åé¡¯èçè¦é¨é£çµæ¨¡å¼ï¼ä¸¦æ¡ç¨ EdgeSHAP å¨ä¸­é¢¨å¾æä¾ç¥ç¶çæçäºå¾è§£éãæåå¨ä¾èªåå®¶æ©æ§ç EEG è¨éä¸è©ä¼°äºæåçæ¨¡åï¼å¨é æ¸¬ NIHSS æéå°äº 3.23 çå¹³åçµå°èª¤å·® (MAE)ï¼æ¥è¿äººé¡å°å®¶æç¯çå¹³åèª¤å·® (MAE â 3.0)ãéè­æäºè©²æ¹æ³å¨ç¶­æè³æé±ç§çåæï¼è½æä¾æºç¢ºä¸å¯è§£éçé æ¸¬ï¼é²èå±ç¾å¶æè½ã

##### **Weakly supervised deep learning model with size constraint for prostate cancer detection in multiparametric MRI and generalization to unseen domains**
2411.02466v1 by Robin Trombetta, Olivier RouviÃ¨re, Carole Lartizien

Fully supervised deep models have shown promising performance for many
medical segmentation tasks. Still, the deployment of these tools in clinics is
limited by the very timeconsuming collection of manually expert-annotated data.
Moreover, most of the state-ofthe-art models have been trained and validated on
moderately homogeneous datasets. It is known that deep learning methods are
often greatly degraded by domain or label shifts and are yet to be built in
such a way as to be robust to unseen data or label distributions. In the
clinical setting, this problematic is particularly relevant as the deployment
institutions may have different scanners or acquisition protocols than those
from which the data has been collected to train the model. In this work, we
propose to address these two challenges on the detection of clinically
significant prostate cancer (csPCa) from bi-parametric MRI. We evaluate the
method proposed by (Kervadec et al., 2018), which introduces a size constaint
loss to produce fine semantic cancer lesions segmentations from weak circle
scribbles annotations. Performance of the model is based on two public (PI-CAI
and Prostate158) and one private databases. First, we show that the model
achieves on-par performance with strong fully supervised baseline models, both
on in-distribution validation data and unseen test images. Second, we observe a
performance decrease for both fully supervised and weakly supervised models
when tested on unseen data domains. This confirms the crucial need for
efficient domain adaptation methods if deep learning models are aimed to be
deployed in a clinical environment. Finally, we show that ensemble predictions
from multiple trainings increase generalization performance.

æè¦ï¼<paragraph>å®å¨ç£ç£çæ·±åº¦æ¨¡åå¨è¨±å¤é«çå½±ååå²ä»»åä¸­å±ç¾åºè¯å¥½çæè½ãç¶èï¼éäºå·¥å·å¨è¨åºä¸çé¨ç½²åå°èæçäººå·¥æ¨è¨è³æèééå¶ãæ­¤å¤ï¼å¤§å¤æ¸æåé²çæ¨¡åé½å¨ä¸­ç­åè³ªçè³æéä¸è¨ç·´åé©è­ãç¾æå¨ç¥ï¼æ·±åº¦å­¸ç¿æ¹æ³ç¶å¸¸æå é åææ¨ç±¤è½ç§»èå¤§å¹éä½ï¼èä¸å°æªå»ºæ§åºå°æªè¦è³æææ¨ç±¤åä½å·æç©©å¥æ§çæ¹æ³ãå¨è¨åºç°å¢ä¸­ï¼éååé¡ç¹å¥ç¸éï¼å çºé¨ç½²æ©æ§å¯è½ææèç¨æ¼è¨ç·´æ¨¡åçè³æä¸åçææå¨ææ·ååå®ãå¨éé å·¥ä½ä¸­ï¼æåæè­°éå°å¾éåæ¸ MRI ä¸­åµæ¸¬è¨åºé¡¯èçååèºç (csPCa) ä¾è§£æ±ºéå©åææ°ãæåè©ä¼°ç± (Kervadec ç­äººï¼2018 å¹´) æåºï¼ä¸¦å¼å¥å¤§å°ç´ææå¤±çæ¹æ³ï¼ä»¥å¾å¼±åå½¢å¡é´æ¨è¨»ä¸­ç¢çç²¾ç´°çèªç¾©çççç¶åå²ãæ¨¡åçæè½åºæ¼å©åå¬éè³æåº« (PI-CAI å Prostate158) åä¸åç§äººè³æåº«ãé¦åï¼æåå±ç¤ºè©²æ¨¡åå¨åä½å§é©è­è³æåæªè¦æ¸¬è©¦å½±åä¸é½éå°èå¼·å¤§çå®å¨ç£ç£åºç·æ¨¡ååç­çæè½ãå¶æ¬¡ï¼æåè§å¯å°å¨æªè¦è³æé åä¸æ¸¬è©¦æï¼å®å¨ç£ç£åå¼±ç£ç£æ¨¡åçæè½é½æä¸éãéè­å¯¦äºå°ææé åé©ææ¹æ³çè¿«åéæ±ï¼å¦ææ·±åº¦å­¸ç¿æ¨¡åæ¨å¨é¨ç½²å¨è¨åºç°å¢ä¸­ãæå¾ï¼æåå±ç¤ºä¾èªå¤éè¨ç·´çæ´é«é æ¸¬ææåæ¦åæè½ã</paragraph>

##### **Evaluating the quality of published medical research with ChatGPT**
2411.01952v1 by Mike Thelwall, Xiaorui Jiang, Peter A. Bath

Evaluating the quality of published research is time-consuming but important
for departmental evaluations, appointments, and promotions. Previous research
has shown that ChatGPT can score articles for research quality, with the
results correlating positively with an indicator of quality in all fields
except Clinical Medicine. This article investigates this anomaly with the
largest dataset yet and a more detailed analysis. The results showed that
ChatGPT 4o-mini scores for articles submitted to the UK's Research Excellence
Framework (REF) 2021 Unit of Assessment (UoA) 1 Clinical Medicine correlated
positively (r=0.134, n=9872) with departmental mean REF scores, against a
theoretical maximum correlation of r=0.226 (due to the departmental averaging
involved). At the departmental level, mean ChatGPT scores correlated more
strongly with departmental mean REF scores (r=0.395, n=31). For the 100
journals with the most articles in UoA 1, their mean ChatGPT score correlated
strongly with their REF score (r=0.495) but negatively with their citation rate
(r=-0.148). Journal and departmental anomalies in these results point to
ChatGPT being ineffective at assessing the quality of research in prestigious
medical journals or research directly affecting human health, or both.
Nevertheless, the results give evidence of ChatGPT's ability to assess research
quality overall for Clinical Medicine, so now there is evidence of its ability
in all academic fields.

æè¦ï¼<paragraph>è©ä¼°å·²ç¼è¡¨çåè³ªç ç©¶å¾èæï¼ä½å°æ¼é¨éè©éãä»»å½åæåä¾èªªå¾éè¦ãååçç ç©¶é¡¯ç¤ºï¼ChatGPT å¯ä»¥çºç ç©¶åè³ªè©åï¼å¶çµæèææé åï¼è¨åºé«å­¸é¤å¤ï¼çåè³ªææ¨åæ­£ç¸éãæ¬æä½¿ç¨è¿ä»çºæ­¢æå¤§çè³æéåæ´è©³ç´°çåæä¾æ¢è¨éç¨®ç°å¸¸ç¾è±¡ãçµæé¡¯ç¤ºï¼æäº¤çµ¦è±åç ç©¶åè¶æ¶æ§ (REF) 2021 è©ä¼°å®ä½ (UoA) 1 è¨åºé«å­¸ç ChatGPT 4o-mini åæ¸èé¨éå¹³å REF åæ¸åæ­£ç¸éï¼r=0.134ï¼n=9872ï¼ï¼èçè«æå¤§ç¸éä¿æ¸çº r=0.226ï¼ç±æ¼æ¶åé¨éå¹³åï¼ãå¨é¨éå±¤ç´ï¼å¹³å ChatGPT åæ¸èé¨éå¹³å REF åæ¸ç¸éæ§æ´å¼·ï¼r=0.395ï¼n=31ï¼ãå°æ¼ UoA 1 ä¸­æç« æå¤ç 100 æ¬æåï¼å¶å¹³å ChatGPT åæ¸èå¶ REF åæ¸åå¼·æ­£ç¸éï¼r=0.495ï¼ï¼ä½èå¶å¼ç¨çåè² ç¸éï¼r=-0.148ï¼ãéäºçµæä¸­çæååé¨éç°å¸¸ç¾è±¡è¡¨æï¼ChatGPT ç¡æ³è©ä¼°è²æåèçé«å­¸æåæç´æ¥å½±é¿äººé¡å¥åº·çç ç©¶ï¼æå©èï¼çåè³ªãåç®¡å¦æ­¤ï¼çµæè­æäº ChatGPT æ´é«è©ä¼°è¨åºé«å­¸ç ç©¶åè³ªçè½åï¼å æ­¤ç¾å¨æè­æè­æå¶å¨ææå­¸è¡é åçè½åã</paragraph>

##### **You are out of context!**
2411.02464v1 by Giancarlo Cobino, Simone Farci

This research proposes a novel drift detection methodology for machine
learning (ML) models based on the concept of ''deformation'' in the vector
space representation of data. Recognizing that new data can act as forces
stretching, compressing, or twisting the geometric relationships learned by a
model, we explore various mathematical frameworks to quantify this deformation.
We investigate measures such as eigenvalue analysis of covariance matrices to
capture global shape changes, local density estimation using kernel density
estimation (KDE), and Kullback-Leibler divergence to identify subtle shifts in
data concentration. Additionally, we draw inspiration from continuum mechanics
by proposing a ''strain tensor'' analogy to capture multi-faceted deformations
across different data types. This requires careful estimation of the
displacement field, and we delve into strategies ranging from density-based
approaches to manifold learning and neural network methods. By continuously
monitoring these deformation metrics and correlating them with model
performance, we aim to provide a sensitive, interpretable, and adaptable drift
detection system capable of distinguishing benign data evolution from true
drift, enabling timely interventions and ensuring the reliability of machine
learning systems in dynamic environments. Addressing the computational
challenges of this methodology, we discuss mitigation strategies like
dimensionality reduction, approximate algorithms, and parallelization for
real-time and large-scale applications. The method's effectiveness is
demonstrated through experiments on real-world text data, focusing on detecting
context shifts in Generative AI. Our results, supported by publicly available
code, highlight the benefits of this deformation-based approach in capturing
subtle drifts that traditional statistical methods often miss. Furthermore, we
present a detailed application example within the healthcare domain, showcasing
the methodology's potential in diverse fields. Future work will focus on
further improving computational efficiency and exploring additional
applications across different ML domains.

æè¦ï¼æ¬ç ç©¶æåºä¸åæ°ç©çæ¼ç§»åµæ¸¬æ¹æ³ï¼è©²æ¹æ³éå°æ©å¨å­¸ç¿ (ML) æ¨¡åï¼ä¸¦åºæ¼è³æåéç©ºéè¡¨ç¤ºä¸­çãè®å½¢ãæ¦å¿µãæåäºè§£å°æ°è³æå¯ä»¥ä½çºåéï¼å»¶ä¼¸ãå£ç¸®ææ­æ²æ¨¡åå­¸ç¿å°çå¹¾ä½éä¿ï¼æåæ¢ç´¢åç¨®æ¸å­¸æ¶æ§ä¾éåéç¨®è®å½¢ãæåç ç©¶äºè«¸å¦åæ¹å·®ç©é£çç¹å¾µå¼åæä¾æ·åæ´é«å½¢çè®åãä½¿ç¨æ ¸å¯åº¦ä¼°è¨ (KDE) çå±é¨å¯åº¦ä¼°è¨ï¼ä»¥å Kullback-Leibler è·é¢ä¾è­å¥è³æéä¸­å¾®å¦çåç§»ãæ­¤å¤ï¼æåå¾é£çºåå­¸ä¸­æ±²åéæï¼æåºä¸åãæè®å¼µéãé¡æ¯ä¾æ·åä¸åè³æé¡åä¸­çå¤é¢åè®å½¢ãééè¦ä»ç´°ä¼°è¨ä½ç§»å ´ï¼æåæ·±å¥æ¢è¨å¾åºæ¼å¯åº¦çéå¾å°æµå½¢å­¸ç¿åç¥ç¶ç¶²è·¯æ¹æ³çç­ç¥ãééæçºç£æ§éäºè®å½¢éåº¦ä¸¦å°å®åèæ¨¡åæè½ç¸éè¯ï¼æåæ¨å¨æä¾ä¸åéæãå¯è§£éä¸é©ææ§å¼·çæ¼ç§»åµæ¸¬ç³»çµ±ï¼è½å¤ ååè¯æ§çè³ææ¼ååçæ­£çæ¼ç§»ï¼å¾èå¯¦ç¾åæçå¹²é ä¸¦ç¢ºä¿æ©å¨å­¸ç¿ç³»çµ±å¨åæç°å¢ä¸­çå¯é æ§ãçºäºæå°éç¨®æ¹æ³çè¨ç®ææ°ï¼æåè¨è«äºéç¶­ãè¿ä¼¼æ¼ç®æ³åä¸¦è¡åç­ç·©è§£ç­ç¥ï¼ä»¥ç¨æ¼å³æåå¤§è¦æ¨¡æç¨ãééå¨çå¯¦ä¸çæå­è³æä¸é²è¡å¯¦é©ï¼è­æäºè©²æ¹æ³çæææ§ï¼éé»å¨æ¼åµæ¸¬çæå¼ AI ä¸­çèçµ¡è½ç§»ãæåççµæç±å¬éå¯ç¨çç¨å¼ç¢¼æ¯æ´ï¼çªé¡¯äºéç¨®åºæ¼è®å½¢çéå¾å¨æ·åå³çµ±çµ±è¨æ¹æ³ç¶å¸¸éºæ¼çå¾®å¦æ¼ç§»æ¹é¢çåªé»ãæ­¤å¤ï¼æåå¨é«çä¿å¥é åä¸­å±ç¤ºäºä¸åè©³ç´°çæç¨ç¯ä¾ï¼å±ç¤ºäºè©²æ¹æ³å¨ä¸åé åçæ½åãæªä¾çç ç©¶å°éä¸­å¨é²ä¸æ­¥æé«è¨ç®æçï¼ä¸¦æ¢ç´¢ä¸å ML é åä¸­çå¶ä»æç¨ã

##### **Diagnosing Medical Datasets with Training Dynamics**
2411.01653v1 by Laura Wenderoth

This study explores the potential of using training dynamics as an automated
alternative to human annotation for evaluating the quality of training data.
The framework used is Data Maps, which classifies data points into categories
such as easy-to-learn, hard-to-learn, and ambiguous (Swayamdipta et al., 2020).
Swayamdipta et al. (2020) highlight that difficult-to-learn examples often
contain errors, and ambiguous cases significantly impact model training. To
confirm the reliability of these findings, we replicated the experiments using
a challenging dataset, with a focus on medical question answering. In addition
to text comprehension, this field requires the acquisition of detailed medical
knowledge, which further complicates the task. A comprehensive evaluation was
conducted to assess the feasibility and transferability of the Data Maps
framework to the medical domain. The evaluation indicates that the framework is
unsuitable for addressing datasets' unique challenges in answering medical
questions.

æè¦ï¼æ¬ç ç©¶æ¢è¨ä½¿ç¨è¨ç·´åæä½çºèªååæ¿ä»£æ¹æ¡ï¼ä»¥è©ä¼°è¨ç·´è³æåè³ªï¼ä»¥åä»£äººå·¥æ¨è¨»ãæä½¿ç¨çæ¶æ§çºè³æå°åï¼å¶å°è³æé»åé¡çºææ¼å­¸ç¿ãé£ä»¥å­¸ç¿åæ¨¡ç¨å©å¯ç­é¡å¥ï¼Swayamdipta ç­äººï¼2020 å¹´ï¼ãSwayamdipta ç­äººï¼2020 å¹´ï¼å¼·èª¿ï¼é£ä»¥å­¸ç¿çç¯ä¾éå¸¸åå«é¯èª¤ï¼èæ¨¡ç¨å©å¯çææ³æå°æ¨¡åè¨ç·´ç¢çéå¤§å½±é¿ãçºäºç¢ºèªéäºç¼ç¾çå¯é æ§ï¼æåä½¿ç¨å·æææ°æ§çè³æéè¤è£½äºå¯¦é©ï¼éé»æ¾å¨é«å­¸åé¡è§£ç­ä¸ãé¤äºæå­çè§£ä¹å¤ï¼éåé åééè¦ç²åè©³ç´°çé«å­¸ç¥è­ï¼éé²ä¸æ­¥ä½¿ä»»åè¤éåãæåé²è¡äºå¨é¢çè©ä¼°ï¼ä»¥è©ä¼°è³æå°åæ¶æ§å¨é«å­¸é åçå¯è¡æ§åå¯è½ç§»æ§ãè©ä¼°çµæè¡¨æï¼è©²æ¶æ§ä¸é©åè§£æ±ºè³æéå¨åç­é«å­¸åé¡æé¢è¨çç¨ç¹ææ°ã

##### **Optical Flow Representation Alignment Mamba Diffusion Model for Medical Video Generation**
2411.01647v1 by Zhenbin Wang, Lei Zhang, Lituan Wang, Minjuan Zhu, Zhenwei Zhang

Medical video generation models are expected to have a profound impact on the
healthcare industry, including but not limited to medical education and
training, surgical planning, and simulation. Current video diffusion models
typically build on image diffusion architecture by incorporating temporal
operations (such as 3D convolution and temporal attention). Although this
approach is effective, its oversimplification limits spatio-temporal
performance and consumes substantial computational resources. To counter this,
we propose Medical Simulation Video Generator (MedSora), which incorporates
three key elements: i) a video diffusion framework integrates the advantages of
attention and Mamba, balancing low computational load with high-quality video
generation, ii) an optical flow representation alignment method that implicitly
enhances attention to inter-frame pixels, and iii) a video variational
autoencoder (VAE) with frequency compensation addresses the information loss of
medical features that occurs when transforming pixel space into latent features
and then back to pixel frames. Extensive experiments and applications
demonstrate that MedSora exhibits superior visual quality in generating medical
videos, outperforming the most advanced baseline methods. Further results and
code are available at https://wongzbb.github.io/MedSora

æè¦ï¼é«çå½±ççææ¨¡åé è¨å°å°é«çä¿å¥ç¢æ¥­ç¢çæ·±é çå½±é¿ï¼åæ¬ä½ä¸éæ¼é«å­¸æè²åè¨ç·´ãæè¡è¦ååæ¨¡æ¬ãç®åçå½±çæ´æ£æ¨¡åéå¸¸å»ºç«å¨å½±åæ´æ£æ¶æ§ä¸ï¼ä¸¦çµåæééç®ï¼ä¾å¦ 3D æºç©åæéæ³¨æåï¼ãåç®¡æ­¤æ¹æ³ææï¼ä½å¶éæ¼ç°¡åéå¶äºæç©ºæè½ï¼ä¸¦æ¶èå¤§éçéç®è³æºãçºäºè§£æ±ºéååé¡ï¼æåæåºé«å­¸æ¨¡æ¬å½±ççæå¨ (MedSora)ï¼å®çµåäºä¸åééµè¦ç´ ï¼i) ä¸åå½±çæ´æ£æ¶æ§æ´åäºæ³¨æåå Mamba çåªé»ï¼å¨ä½éç®è² è¼åé«åè³ªå½±ççæä¹éåå¾å¹³è¡¡ï¼ii) ä¸ååæµè¡¨ç¤ºå°é½æ¹æ³ï¼å¯ä»¥é±å«å°å¢å¼·å°å½±æ ¼éåç´ çæ³¨æåï¼ä»¥å iii) ä¸åå·æé »çè£åçå½±çè®ç°èªåç·¨ç¢¼å¨ (VAE)ï¼ç¨æ¼è§£æ±ºå¨å°åç´ ç©ºéè½æçºæ½å¨ç¹å¾µï¼ç¶å¾åè½ååç´ å½±æ ¼æç¼ççé«çç¹å¾µè³è¨éºå¤±åé¡ãå»£æ³çå¯¦é©åæç¨è­æï¼MedSora å¨çæé«çå½±çæ¹é¢å±ç¾åºåªç°çè¦è¦ºåè³ªï¼åªæ¼æåé²çåºæºæ¹æ³ãé²ä¸æ­¥ççµæåç¨å¼ç¢¼å¯ä»¥å¨ https://wongzbb.github.io/MedSora åå¾

##### **Customized Subgraph Selection and Encoding for Drug-drug Interaction Prediction**
2411.01535v1 by Haotong Du, Quanming Yao, Juzheng Zhang, Yang Liu, Zhen Wang

Subgraph-based methods have proven to be effective and interpretable in
predicting drug-drug interactions (DDIs), which are essential for medical
practice and drug development. Subgraph selection and encoding are critical
stages in these methods, yet customizing these components remains underexplored
due to the high cost of manual adjustments. In this study, inspired by the
success of neural architecture search (NAS), we propose a method to search for
data-specific components within subgraph-based frameworks. Specifically, we
introduce extensive subgraph selection and encoding spaces that account for the
diverse contexts of drug interactions in DDI prediction. To address the
challenge of large search spaces and high sampling costs, we design a
relaxation mechanism that uses an approximation strategy to efficiently explore
optimal subgraph configurations. This approach allows for robust exploration of
the search space. Extensive experiments demonstrate the effectiveness and
superiority of the proposed method, with the discovered subgraphs and encoding
functions highlighting the model's adaptability.

æè¦ï¼åºæ¼å­åçæ¹æ³å·²è¢«è­æå¨é æ¸¬è¥ç©-è¥ç©äº¤äºä½ç¨ (DDI) ä¸­ææä¸ææ¼è§£éï¼éå°æ¼é«çå¯¦ååè¥ç©éç¼è³ééè¦ãå­åé¸æåç·¨ç¢¼æ¯éäºæ¹æ³ä¸­çééµéæ®µï¼ç¶èï¼ç±æ¼æåèª¿æ´çææ¬é«æï¼å®¢è£½åéäºåä»¶ä»æªè¢«ååæ¢è¨ãå¨æ¬ç ç©¶ä¸­ï¼åå°ç¥ç¶æ¶æ§æå° (NAS) æååç¼ï¼æåæåºä¸åæ¹æ³ä¾æå°å­åæ¶æ§ä¸­çè³æç¹å®åä»¶ãå·é«ä¾èªªï¼æåå¼å¥äºå»£æ³çå­åé¸æåç·¨ç¢¼ç©ºéï¼ä»¥èªªæ DDI é æ¸¬ä¸­è¥ç©äº¤äºä½ç¨çä¸åèæ¯ãçºäºæå°å¤§åæå°ç©ºéåé«åæ¨£ææ¬çææ°ï¼æåè¨­è¨äºä¸åæ¾é¬æ©å¶ï¼ä½¿ç¨è¿ä¼¼ç­ç¥ä¾æææ¢ç´¢æä½³å­åéç½®ãéç¨®æ¹æ³åè¨±å°æå°ç©ºéé²è¡ç©©å¥çæ¢ç´¢ãå»£æ³çå¯¦é©è­æäºææåºæ¹æ³çæææ§ååªè¶æ§ï¼ç¼ç¾çå­ååç·¨ç¢¼å½æ¸çªé¡¯äºæ¨¡åçé©ææ§ã

##### **Conditional Latent Space Molecular Scaffold Optimization for Accelerated Molecular Design**
2411.01423v1 by Onur Boyar, Hiroyuki Hanada, Ichiro Takeuchi

The rapid discovery of new chemical compounds is essential for advancing
global health and developing treatments. While generative models show promise
in creating novel molecules, challenges remain in ensuring the real-world
applicability of these molecules and finding such molecules efficiently. To
address this, we introduce Conditional Latent Space Molecular Scaffold
Optimization (CLaSMO), which combines a Conditional Variational Autoencoder
(CVAE) with Latent Space Bayesian Optimization (LSBO) to modify molecules
strategically while maintaining similarity to the original input. Our LSBO
setting improves the sample-efficiency of our optimization, and our
modification approach helps us to obtain molecules with higher chances of
real-world applicability. CLaSMO explores substructures of molecules in a
sample-efficient manner by performing BO in the latent space of a CVAE
conditioned on the atomic environment of the molecule to be optimized. Our
experiments demonstrate that CLaSMO efficiently enhances target properties with
minimal substructure modifications, achieving state-of-the-art results with a
smaller model and dataset compared to existing methods. We also provide an
open-source web application that enables chemical experts to apply CLaSMO in a
Human-in-the-Loop setting.

æè¦ï¼æ°åå­¸ååç©çå¿«éç¼ç¾å°æ¼ä¿é²å¨çå¥åº·åéç¼æ²»çæ¹æ³è³ééè¦ãåç®¡çææ¨¡åå¨åµé æ°åå­æ¹é¢é¡¯ç¤ºåºåæ¯ï¼ä½ä»ç¶å­å¨ææ°ï¼ä»¥ç¢ºä¿éäºåå­çå¯¦éé©ç¨æ§ä¸¦ææå°æ¾å°éäºåå­ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äºæ¢ä»¶æ½å¨ç©ºéåå­æ¯æ¶æä½³å (CLaSMO)ï¼å®çµåäºæ¢ä»¶è®ç°èªåç·¨ç¢¼å¨ (CVAE) èæ½å¨ç©ºéè²æ°æä½³å (LSBO)ï¼ä»¥ç­ç¥æ§å°ä¿®æ¹åå­ï¼åæä¿æèåå§è¼¸å¥çç¸ä¼¼æ§ãæåç LSBO è¨­å®æ¹åäºæåæä½³åçæ¨£æ¬æçï¼æåçä¿®æ¹æ¹æ³å¹«å©æåç²å¾å·ææ´é«å¯¦éé©ç¨æ©æçåå­ãCLaSMO ä»¥æ¨£æ¬ææçæ¹å¼æ¢ç´¢åå­çå­çµæ§ï¼æ¹æ³æ¯å¨ CVAE çæ½å¨ç©ºéä¸­å·è¡ BOï¼è©²ç©ºéä»¥è¦æä½³åçåå­çåå­ç°å¢çºæ¢ä»¶ãæåçå¯¦é©è¡¨æï¼CLaSMO ä»¥æå°çå­çµæ§ä¿®æ¹ææå°å¢å¼·äºç®æ¨å±¬æ§ï¼èç¾ææ¹æ³ç¸æ¯ï¼ä½¿ç¨è¼å°çæ¨¡ååæ¸æéå¯¦ç¾äºæåé²ççµæãæåéæä¾äºä¸åéæºç¶²è·¯æç¨ç¨å¼ï¼è®åå­¸å°å®¶è½å¤ å¨äººæ©è¿´åè¨­å®ä¸­æç¨ CLaSMOã

##### **Medical X-Ray Image Enhancement Using Global Contrast-Limited Adaptive Histogram Equalization**
2411.01373v1 by Sohrab Namazi Nia, Frank Y. Shih

In medical imaging, accurate diagnosis heavily relies on effective image
enhancement techniques, particularly for X-ray images. Existing methods often
suffer from various challenges such as sacrificing global image characteristics
over local image characteristics or vice versa. In this paper, we present a
novel approach, called G-CLAHE (Global-Contrast Limited Adaptive Histogram
Equalization), which perfectly suits medical imaging with a focus on X-rays.
This method adapts from Global Histogram Equalization (GHE) and Contrast
Limited Adaptive Histogram Equalization (CLAHE) to take both advantages and
avoid weakness to preserve local and global characteristics. Experimental
results show that it can significantly improve current state-of-the-art
algorithms to effectively address their limitations and enhance the contrast
and quality of X-ray images for diagnostic accuracy.

æè¦ï¼å¨é«å­¸å½±åä¸­ï¼æºç¢ºçè¨ºæ·é«åº¦ä¾è³´æ¼ææçå½±åå¢å¼·æè¡ï¼ç¹å¥æ¯ X åå½±åãç¾æçæ¹æ³éå¸¸æéå°åç¨®ææ°ï¼ä¾å¦ç§ç²æ´é«å½±åç¹æ§ä»¥æåå±é¨å½±åç¹æ§ï¼åä¹äº¦ç¶ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼ç¨±çº G-CLAHEï¼å¨å±å°æ¯åº¦éå¶èªé©æç´æ¹ååè¡¡åï¼ï¼å®éå¸¸é©åæ¼ä»¥ X åçºéé»çé«å­¸å½±åãæ­¤æ¹æ³æ¹ç·¨èªå¨å±ç´æ¹ååè¡¡å (GHE) åå°æ¯åº¦éå¶èªé©æç´æ¹ååè¡¡å (CLAHE)ï¼ä»¥åå¾å©èçåªé»ï¼ä¸¦é¿åå¼±é»ï¼ä»¥ä¿çå±é¨åå¨å±ç¹æ§ãå¯¦é©çµæè¡¨æï¼å®å¯ä»¥é¡¯èæ¹åç¶åæåé²çæ¼ç®æ³ï¼ä»¥ææè§£æ±ºå¶éå¶ï¼ä¸¦å¢å¼· X åå½±åçå°æ¯åº¦ååè³ªï¼ä»¥å©æ¼è¨ºæ·æºç¢ºæ§ã

##### **Guided Synthesis of Labeled Brain MRI Data Using Latent Diffusion Models for Segmentation of Enlarged Ventricles**
2411.01351v1 by Tim Ruschke, Jonathan Frederik Carlsen, Adam Espe Hansen, Ulrich Lindberg, Amalie Monberg Hindsholm, Martin Norgaard, Claes NÃ¸hr Ladefoged

Deep learning models in medical contexts face challenges like data scarcity,
inhomogeneity, and privacy concerns. This study focuses on improving
ventricular segmentation in brain MRI images using synthetic data. We employed
two latent diffusion models (LDMs): a mask generator trained using 10,000
masks, and a corresponding SPADE image generator optimized using 6,881 scans to
create an MRI conditioned on a 3D brain mask. Conditioning the mask generator
on ventricular volume in combination with classifier-free guidance enabled the
control of the ventricular volume distribution of the generated synthetic
images. Next, the performance of the synthetic data was tested using three
nnU-Net segmentation models trained on a real, augmented and entirely synthetic
data, respectively. The resulting models were tested on a completely
independent hold-out dataset of patients with enlarged ventricles, with manual
delineation of the ventricles used as ground truth. The model trained on real
data showed a mean absolute error (MAE) of 9.09 \pm 12.18 mL in predicted
ventricular volume, while the models trained on synthetic and augmented data
showed MAEs of 7.52 \pm 4.81 mL and 6.23 \pm 4.33 mL, respectively. Both the
synthetic and augmented model also outperformed the state-of-the-art model
SynthSeg, which due to limited performance in cases of large ventricular
volumes, showed an MAE of 7.73 \pm 12.12 mL with a factor of 3 higher standard
deviation. The model trained on augmented data showed the highest Dice score of
0.892 \pm 0.05, slightly outperforming SynthSeg and on par with the model
trained on real data. The synthetic model performed similar to SynthSeg. In
summary, we provide evidence that guided synthesis of labeled brain MRI data
using LDMs improves the segmentation of enlarged ventricles and outperforms
existing state-of-the-art segmentation models.

æè¦ï¼<paragraph>å¨å»å­¦èæ¯ä¸­ï¼æ·±åº¦å­¦ä¹ æ¨¡åé¢ä¸´çæ°æ®ç¨ç¼ºæ§ãä¸ååæ§åéç§é®é¢ç­ææãæ¬ç ç©¶ä¸æ³¨äºä½¿ç¨åææ°æ®æ¹è¿èé¨ MRI å¾åä¸­çå¿å®¤åå²ãæä»¬éç¨äºä¸¤ä¸ªæ½å¨æ©æ£æ¨¡å (LDM)ï¼ä¸ä¸ªä½¿ç¨ 10,000 ä¸ªèçè®­ç»çèççæå¨ï¼ä»¥åä¸ä¸ªä½¿ç¨ 6,881 æ¬¡æ«æè¿è¡ä¼åçç¸åº SPADE å¾åçæå¨ï¼ä»¥åå»ºåºäº 3D èé¨èçç MRIãå¯¹èççæå¨è¿è¡å¿å®¤ä½ç§¯è°èï¼å¹¶ç»åæ åç±»å¨æå¯¼ï¼è½å¤æ§å¶çæåæå¾åçå¿å®¤ä½ç§¯åå¸ãæ¥ä¸æ¥ï¼ä½¿ç¨åå«è®­ç»äºçå®ãå¢å¼ºåå®å¨åææ°æ®ä¸çä¸ä¸ª nnU-Net åå²æ¨¡åæµè¯äºåææ°æ®çæ§è½ãå°è®­ç»æå¾çæ¨¡åå¨å®å¨ç¬ç«çãå·ææ©å¤§å¿å®¤çæ£èçä¿çæ°æ®éä¸è¿è¡æµè¯ï¼å¹¶ä½¿ç¨å¿å®¤çæå¨æç»ä½ä¸ºçå®æåµãå¨çå®æ°æ®ä¸è®­ç»çæ¨¡åå¨é¢æµçå¿å®¤ä½ç§¯ä¸­æ¾ç¤ºåº 9.09 Â± 12.18 mL çå¹³åç»å¯¹è¯¯å·® (MAE)ï¼èå¨åæåå¢å¼ºæ°æ®ä¸è®­ç»çæ¨¡åæ¾ç¤ºåº 7.52 Â± 4.81 mL å 6.23 Â± 4.33 mL ç MAEãåææ¨¡ååå¢å¼ºæ¨¡åçæ§è½åä¼äºæåè¿çæ¨¡å SynthSegï¼åèç±äºå¨å¤§å¿å®¤ä½ç§¯çæåµä¸æ§è½æéï¼æ¾ç¤ºåº 7.73 Â± 12.12 mL ç MAEï¼æ åå·®é«åº 3 åãå¨å¢å¼ºæ°æ®ä¸è®­ç»çæ¨¡åæ¾ç¤ºåºæé«ç Dice å¾å 0.892 Â± 0.05ï¼ç¥ä¼äº SynthSegï¼å¹¶ä¸ä¸å¨çå®æ°æ®ä¸è®­ç»çæ¨¡åç¸å½ãåææ¨¡åçæ§è½ä¸ SynthSeg ç±»ä¼¼ãæ»ä¹ï¼æä»¬æä¾äºè¯æ®è¡¨æï¼ä½¿ç¨ LDM å¯¹æ è®°çèé¨ MRI æ°æ®è¿è¡å¼å¯¼åæå¯ä»¥æ¹åæ©å¤§å¿å®¤çåå²ï¼å¹¶ä¸ä¼äºç°æçæåè¿çåå²æ¨¡åã</paragraph>

##### **Causal reasoning in difference graphs**
2411.01292v1 by Charles K. Assaad

In epidemiology, understanding causal mechanisms across different populations
is essential for designing effective public health interventions. Recently,
difference graphs have been introduced as a tool to visually represent causal
variations between two distinct populations. While there has been progress in
inferring these graphs from data through causal discovery methods, there
remains a gap in systematically leveraging their potential to enhance causal
reasoning. This paper addresses that gap by establishing conditions for
identifying causal changes and effects using difference graphs and
observational data. It specifically focuses on identifying total causal changes
and total effects in a nonparametric framework, as well as direct causal
changes and direct effects in a linear context. In doing so, it provides a
novel approach to causal reasoning that holds potential for various public
health applications.

æè¦ï¼å¨æµè¡çå­¸ä¸­ï¼äºè§£ä¸åäººç¾¤ä¹éçå ææ©å¶å°æ¼è¨­è¨ææçå¬å±è¡çå¹²é æªæ½è³ééè¦ãæè¿ï¼å·®ç°åè¡¨å·²è¢«å¼å¥ä½çºä¸ç¨®å·¥å·ï¼ç¨æ¼ç´è§å°è¡¨ç¤ºå©åä¸åäººç¾¤ä¹éçå æè®åãåç®¡ééå æç¼ç¾æ¹æ³å¾æ¸æä¸­æ¨æ·éäºåè¡¨æ¹é¢åå¾äºé²å±ï¼ä½å¨ç³»çµ±æ§å°å©ç¨å¶å¢å¼·å ææ¨ççæ½åæ¹é¢ä»ç¶å­å¨å·®è·ãæ¬æééå»ºç«ä½¿ç¨å·®ç°åè¡¨åè§å¯æ¸æè­å¥å æè®ååå æææçæ¢ä»¶ä¾è§£æ±ºéä¸å·®è·ãå®ç¹å¥å´éæ¼å¨éåæ¸æ¡æ¶ä¸­è­å¥ç¸½å æè®ååç¸½ææï¼ä»¥åå¨ç·æ§èæ¯ä¸­è­å¥ç´æ¥å æè®ååç´æ¥ææãéæ¨£ä¸ä¾ï¼å®æä¾äºä¸ç¨®å ææ¨ççæ°æ¹æ³ï¼å°åç¨®å¬å±è¡çæç¨å·ææ½åã

##### **Designing a Robust Radiology Report Generation System**
2411.01153v1 by Sonit Singh

Recent advances in deep learning have enabled researchers to explore tasks at
the intersection of computer vision and natural language processing, such as
image captioning, visual question answering, visual dialogue, and visual
language navigation. Taking inspiration from image captioning, the task of
radiology report generation aims at automatically generating radiology reports
by having a comprehensive understanding of medical images. However,
automatically generating radiology reports from medical images is a challenging
task due to the complexity, diversity, and nature of medical images. In this
paper, we outline the design of a robust radiology report generation system by
integrating different modules and highlighting best practices drawing upon
lessons from our past work and also from relevant studies in the literature. We
also discuss the impact of integrating different components to form a single
integrated system. We believe that these best practices, when implemented,
could improve automatic radiology report generation, augment radiologists in
decision making, and expedite diagnostic workflow, in turn improve healthcare
and save human lives.

æè¦ï¼æè¿æ·±åº¦å­¸ç¿çé²å±ä½¿ç ç©¶äººå¡è½å¤ æ¢ç´¢é»è¦è¦è¦ºåèªç¶èªè¨èçäº¤éä¸­çä»»åï¼ä¾å¦å½±åæ¨é¡ãè¦è¦ºåç­ãè¦è¦ºå°è©±åè¦è¦ºèªè¨å°èªãåå½±åæ¨é¡çåç¼ï¼æ¾å°ç§å ±åçæçä»»åæ¨å¨ééå¨é¢äºè§£é«å­¸å½±åèªåçææ¾å°ç§å ±åãç¶èï¼ç±æ¼é«å­¸å½±åçè¤éæ§ãå¤æ¨£æ§åæ§è³ªï¼èªåå¾é«å­¸å½±åçææ¾å°ç§å ±åæ¯ä¸é å·æææ°æ§çä»»åãå¨æ¬æä¸­ï¼æåééæ´åä¸åçæ¨¡çµä¸¦å¼·èª¿æä½³å¯¦åï¼æ¦è¿°äºå¥å¨çæ¾å°ç§å ±åçæç³»çµ±çè¨­è¨ï¼éäºå¯¦åæ±²åèªæåéå»çå·¥ä½ä»¥åæç»ä¸­çç¸éç ç©¶ãæåä¹è¨è«äºæ´åä¸åçµä»¶ä»¥å½¢æå®ä¸æ´åç³»çµ±çå½±é¿ãæåç¸ä¿¡ï¼éäºæä½³å¯¦åå¨å¯¦æ½å¾ï¼å¯ä»¥æ¹åèªåæ¾å°ç§å ±åçæï¼å¢å¼·æ¾å°ç§é«å¸«å¨æ±ºç­å¶å®ä¸­çè½åï¼ä¸¦å å¿«è¨ºæ·å·¥ä½æµç¨ï¼é²èæ¹åé«çä¿å¥ä¸¦æ¯æäººå½ã

##### **LEARNER: Learning Granular Labels from Coarse Labels using Contrastive Learning**
2411.01144v1 by Gautam Gare, Jana Armouti, Nikhil Madaan, Rohan Panda, Tom Fox, Laura Hutchins, Amita Krishnan, Ricardo Rodriguez, Bennett DeBoisblanc, Deva Ramanan, John Galeotti

A crucial question in active patient care is determining if a treatment is
having the desired effect, especially when changes are subtle over short
periods. We propose using inter-patient data to train models that can learn to
detect these fine-grained changes within a single patient. Specifically, can a
model trained on multi-patient scans predict subtle changes in an individual
patient's scans? Recent years have seen increasing use of deep learning (DL) in
predicting diseases using biomedical imaging, such as predicting COVID-19
severity using lung ultrasound (LUS) data. While extensive literature exists on
successful applications of DL systems when well-annotated large-scale datasets
are available, it is quite difficult to collect a large corpus of personalized
datasets for an individual. In this work, we investigate the ability of recent
computer vision models to learn fine-grained differences while being trained on
data showing larger differences. We evaluate on an in-house LUS dataset and a
public ADNI brain MRI dataset. We find that models pre-trained on clips from
multiple patients can better predict fine-grained differences in scans from a
single patient by employing contrastive learning.

æè¦ï¼å¨ä¸»åæ£èç§è­·ä¸­ï¼ä¸åééµåé¡æ¯ç¢ºå®æ²»çæ¯å¦ç¢çé æçææï¼ç¹å¥æ¯å¨ç­æéå§è®åç´°å¾®çææ³ä¸ãæåæè­°ä½¿ç¨æ£èéæ¸æä¾è¨ç·´æ¨¡åï¼ä»¥ä¾¿å­¸ç¿åµæ¸¬å®ä¸æ£èå§éäºç´°å¾®çè®åãå·é«ä¾èªªï¼å¨å¤ä½æ£èææä¸­è¨ç·´çæ¨¡åæ¯å¦å¯ä»¥é æ¸¬åå¥æ£èææä¸­çç´°å¾®è®åï¼è¿å¹´ä¾ï¼æ·±åº¦å­¸ç¿ (DL) å¨ä½¿ç¨çç©é«å­¸å½±åé æ¸¬ç¾çæ¹é¢æç¨æ¥çå»£æ³ï¼ä¾å¦ä½¿ç¨èºé¨è¶é³æ³¢ (LUS) æ¸æé æ¸¬ COVID-19 çå´éç¨åº¦ãåç®¡æå¤§éæç»è¨è¼äºå¨ææ¨è¨»çå¤§è¦æ¨¡æ¸æéå¯ç¨æ DL ç³»çµ±çæåæç¨ï¼ä½è¦çºåäººæ¶éå¤§éåäººåæ¸æéç¸ç¶å°é£ãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äºè¿æé»è¦è¦è¦ºæ¨¡åå¨éå°é¡¯ç¤ºè¼å¤§å·®ç°çæ¸æé²è¡è¨ç·´æï¼å­¸ç¿ç´°å¾®å·®ç°çè½åãæåå¨å§é¨ LUS æ¸æéåå¬éç ADNI å¤§è¦ MRI æ¸æéä¸é²è¡è©ä¼°ãæåç¼ç¾ï¼ééä½¿ç¨å°æ¯å­¸ç¿ï¼å¨å¤ä½æ£èççæ®µä¸é åè¨ç·´çæ¨¡åå¯ä»¥æ´å¥½å°é æ¸¬å®ä¸æ£èææä¸­çç´°å¾®å·®ç°ã

##### **Artificial Intelligence for Microbiology and Microbiome Research**
2411.01098v1 by Xu-Wen Wang, Tong Wang, Yang-Yu Liu

Advancements in artificial intelligence (AI) have transformed many scientific
fields, with microbiology and microbiome research now experiencing significant
breakthroughs through machine learning and deep learning applications. This
review provides a comprehensive overview of AI-driven approaches tailored for
microbiology and microbiome studies, emphasizing both technical advancements
and biological insights. We begin with an introduction to foundational AI
techniques, including primary machine learning paradigms and various deep
learning architectures, and offer guidance on choosing between machine learning
and deep learning methods based on specific research goals. The primary section
on application scenarios spans diverse research areas, from taxonomic
profiling, functional annotation & prediction, microbe-X interactions,
microbial ecology, metabolic modeling, precision nutrition, clinical
microbiology, to prevention & therapeutics. Finally, we discuss challenges
unique to this field, including the balance between interpretability and
complexity, the "small n, large p" problem, and the critical need for
standardized benchmarking datasets to validate and compare models. Together,
this review underscores AI's transformative role in microbiology and microbiome
research, paving the way for innovative methodologies and applications that
enhance our understanding of microbial life and its impact on our planet and
our health.

æè¦ï¼äººå·¥æºæ§ (AI) çé²æ­¥å·²è½è®è¨±å¤ç§å­¸é åï¼èå¾®çç©å­¸åå¾®çç©çµç ç©¶ç¾å¨æ­£ééæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æç¨é«é©å°é¡¯èççªç ´ãæ¬ç¯è©è«æä¾ AI é©åæ¹æ³çå¨é¢æ¦è¿°ï¼éäºæ¹æ³å°çºå¾®çç©å­¸åå¾®çç©çµç ç©¶éèº«æé ï¼å¼·èª¿æè¡é²æ­¥åçç©è¦è§£ãæåå¾åºç¤ AI æè¡çä»ç´¹éå§ï¼åæ¬ä¸»è¦çæ©å¨å­¸ç¿ç¯ä¾ååç¨®æ·±åº¦å­¸ç¿æ¶æ§ï¼ä¸¦æä¾æ ¹æå·é«ç ç©¶ç®æ¨å¨æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¹æ³ä¹éé²è¡é¸æçæå°ãæç¨å ´æ¯çä¸»è¦é¨åæ¶µèäºå¾åé¡åæãåè½è¨»è§£åé æ¸¬ãå¾®çç© X ç¸äºä½ç¨ãå¾®çç©çæãä»£è¬å»ºæ¨¡ãç²¾æºçé¤ãè¨åºå¾®çç©å­¸å°é é²åæ²»çç­å¤åç ç©¶é åãæå¾ï¼æåè¨è«äºè©²é åç¨æçææ°ï¼åæ¬å¯è§£éæ§åè¤éæ§ä¹éçå¹³è¡¡ããå° nï¼å¤§ pãåé¡ï¼ä»¥åé©è­åæ¯è¼æ¨¡åçæ¨æºååºæºæ¸æéçééµéæ±ãæ¬ç¯è©è«å±åå¼·èª¿äº AI å¨å¾®çç©å­¸åå¾®çç©çµç ç©¶ä¸­çè½åä½ç¨ï¼çºåµæ°æ¹æ³åæç¨éªå¹³éè·¯ï¼éäºæ¹æ³åæç¨å¢å¼·äºæåå°å¾®çç©çå½åå¶å°æåæçåæåå¥åº·çå½±é¿ççè§£ã

##### **Contrasting with Symile: Simple Model-Agnostic Representation Learning for Unlimited Modalities**
2411.01053v1 by Adriel Saporta, Aahlad Puli, Mark Goldstein, Rajesh Ranganath

Contrastive learning methods, such as CLIP, leverage naturally paired
data-for example, images and their corresponding text captions-to learn general
representations that transfer efficiently to downstream tasks. While such
approaches are generally applied to two modalities, domains such as robotics,
healthcare, and video need to support many types of data at once. We show that
the pairwise application of CLIP fails to capture joint information between
modalities, thereby limiting the quality of the learned representations. To
address this issue, we present Symile, a simple contrastive learning approach
that captures higher-order information between any number of modalities. Symile
provides a flexible, architecture-agnostic objective for learning
modality-specific representations. To develop Symile's objective, we derive a
lower bound on total correlation, and show that Symile representations for any
set of modalities form a sufficient statistic for predicting the remaining
modalities. Symile outperforms pairwise CLIP, even with modalities missing in
the data, on cross-modal classification and retrieval across several
experiments including on an original multilingual dataset of 33M image, text
and audio samples and a clinical dataset of chest X-rays, electrocardiograms,
and laboratory measurements. All datasets and code used in this work are
publicly available at https://github.com/rajesh-lab/symile.

æè¦ï¼å°æ¯å­¸ç¿æ¹æ³ï¼ä¾å¦ CLIPï¼å©ç¨èªç¶éå°çè³æï¼ä¾å¦å½±ååå¶å°æçæå­æ¨é¡ï¼ä¾å­¸ç¿ä¸è¬åè¡¨å¾µï¼ä¸¦ææçå°è½ç§»å°ä¸æ¸¸ä»»åãéç¶æ­¤é¡æ¹æ³éå¸¸æç¨æ¼å©ç¨®å½¢å¼ï¼ä½æ©å¨äººæè¡ãé«çä¿å¥åè¦è¨ç­é åéè¦ä¸æ¬¡æ¯æ´å¤ç¨®é¡åçè³æãæåé¡¯ç¤ºï¼CLIP çæå°æç¨ç¡æ³æ·åå½¢å¼éçè¯åè³è¨ï¼å æ­¤éå¶äºå­¸ç¿è¡¨å¾µçåè³ªãçºäºè§£æ±ºæ­¤åé¡ï¼æåæåº Symileï¼éæ¯ä¸ç¨®ç°¡å®çå°æ¯å­¸ç¿æ¹æ³ï¼å¯ä»¥æ·åä»»ææ¸éçå½¢å¼ä¹éçé«éè³è¨ãSymile æä¾äºä¸åéæ´»ä¸èæ¶æ§ç¡éçç®æ¨ï¼ç¨æ¼å­¸ç¿ç¹å®æ¼å½¢å¼çè¡¨å¾µãçºéç¼ Symile çç®æ¨ï¼æåæ¨å°åºç¸½ç¸éæ§çä¸çï¼ä¸¦é¡¯ç¤ºä»»ä½å½¢å¼éåç Symile è¡¨å¾µå½¢æä¸åååççµ±è¨éï¼ç¨æ¼é æ¸¬å¶é¤å½¢å¼ãSymile åªæ¼æå° CLIPï¼å³ä½¿è³æä¸­ç¼ºå°å½¢å¼ï¼ä¹è½å¨è·¨å½¢å¼åé¡åæª¢ç´¢ä¸­è¡¨ç¾åºè²ï¼åæ¬å¨ä¸ååå« 3300 è¬å¼µå½±åãæå­åé³è¨æ¨£æ¬çåå§å¤èªè¨è³æéåä¸ååå«è¸é¨ X åãå¿é»ååå¯¦é©å®¤æ¸¬éçè¨åºè³æéä¸é²è¡çå¤æ¬¡å¯¦é©ãæ¬ç ç©¶ä¸­ä½¿ç¨ææè³æéåç¨å¼ç¢¼çå¬éæ¼ https://github.com/rajesh-lab/symileã

##### **Cross-Fundus Transformer for Multi-modal Diabetic Retinopathy Grading with Cataract**
2411.00726v1 by Fan Xiao, Junlin Hou, Ruiwei Zhao, Rui Feng, Haidong Zou, Lina Lu, Yi Xu, Juzhao Zhang

Diabetic retinopathy (DR) is a leading cause of blindness worldwide and a
common complication of diabetes. As two different imaging tools for DR grading,
color fundus photography (CFP) and infrared fundus photography (IFP) are
highly-correlated and complementary in clinical applications. To the best of
our knowledge, this is the first study that explores a novel multi-modal deep
learning framework to fuse the information from CFP and IFP towards more
accurate DR grading. Specifically, we construct a dual-stream architecture
Cross-Fundus Transformer (CFT) to fuse the ViT-based features of two fundus
image modalities. In particular, a meticulously engineered Cross-Fundus
Attention (CFA) module is introduced to capture the correspondence between CFP
and IFP images. Moreover, we adopt both the single-modality and multi-modality
supervisions to maximize the overall performance for DR grading. Extensive
experiments on a clinical dataset consisting of 1,713 pairs of multi-modal
fundus images demonstrate the superiority of our proposed method. Our code will
be released for public access.

æè¦ï¼ç³å°¿çè¦ç¶²èçè® (DR) æ¯å¨çå¤±æçä¸»è¦åå ï¼ä¹æ¯ç³å°¿ççå¸¸è¦ä½µç¼çãä½çº DR åç´çå©ç¨®ä¸åçå½±åå·¥å·ï¼å½©è²ç¼åºæå½± (CFP) åç´å¤ç·ç¼åºæå½± (IFP) å¨è¨åºæç¨ä¸­é«åº¦ç¸éä¸äºè£ãææåæç¥ï¼éæ¯ç¬¬ä¸åæ¢è¨åµæ°çå¤æ¨¡å¼æ·±åº¦å­¸ç¿æ¡æ¶ï¼ä»¥èå CFP å IFP çè³è¨ï¼ä»¥é²è¡æ´æºç¢ºç DR åç´ãå·é«ä¾èªªï¼æåæ§å»ºäºä¸åéæµæ¶æ§ Cross-Fundus Transformer (CFT)ï¼ä»¥èåå©ç¨®ç¼åºå½±åæ¨¡å¼çåºæ¼ ViT çç¹å¾µãç¹å¥æ¯ï¼å¼å¥äºç²¾å¿è¨­è¨ç Cross-Fundus Attention (CFA) æ¨¡çµï¼ä»¥ææ CFP å IFP å½±åä¹éçå°æéä¿ãæ­¤å¤ï¼æåæ¡ç¨å®ä¸æ¨¡å¼åå¤æ¨¡å¼ç£ç£ï¼ä»¥æå¤§å DR åç´çæ´é«æè½ãå¨ç± 1,713 å°å¤æ¨¡å¼ç¼åºå½±åçµæçè¨åºè³æéä¸é²è¡çå»£æ³å¯¦é©è­æäºæåæåºçæ¹æ³çåªè¶æ§ãæåçç¨å¼ç¢¼å°æå¬éç¼å¸ã

##### **CTPD: Cross-Modal Temporal Pattern Discovery for Enhanced Multimodal Electronic Health Records Analysis**
2411.00696v1 by Fuying Wang, Feng Wu, Yihan Tang, Lequan Yu

Integrating multimodal Electronic Health Records (EHR) data, such as
numerical time series and free-text clinical reports, has great potential in
predicting clinical outcomes. However, prior work has primarily focused on
capturing temporal interactions within individual samples and fusing multimodal
information, overlooking critical temporal patterns across patients. These
patterns, such as trends in vital signs like abnormal heart rate or blood
pressure, can indicate deteriorating health or an impending critical event.
Similarly, clinical notes often contain textual descriptions that reflect these
patterns. Identifying corresponding temporal patterns across different
modalities is crucial for improving the accuracy of clinical outcome
predictions, yet it remains a challenging task. To address this gap, we
introduce a Cross-Modal Temporal Pattern Discovery (CTPD) framework, designed
to efficiently extract meaningful cross-modal temporal patterns from multimodal
EHR data. Our approach introduces shared initial temporal pattern
representations which are refined using slot attention to generate temporal
semantic embeddings. To ensure rich cross-modal temporal semantics in the
learned patterns, we introduce a contrastive-based TPNCE loss for cross-modal
alignment, along with two reconstruction losses to retain core information of
each modality. Evaluations on two clinically critical tasks, 48-hour
in-hospital mortality and 24-hour phenotype classification, using the MIMIC-III
database demonstrate the superiority of our method over existing approaches.

æè¦ï¼æ´åå¤æ¨¡æçµå­å¥åº·è®°å½ (EHR) æ°æ®ï¼ä¾å¦æ°å¼æ¶é´åºååèªç±ææ¬ä¸´åºæ¥åï¼å¨é¢æµä¸´åºç»ææ¹é¢å·æå·¨å¤§æ½åãç¶èï¼ä»¥åçå·¥ä½ä¸»è¦éä¸­å¨ææåä¸ªæ ·æ¬ä¸­çæ¶é´äº¤äºå¹¶èåå¤æ¨¡æä¿¡æ¯ï¼èå¿½ç¥äºæ£èä¹é´çå³é®æ¶é´æ¨¡å¼ãè¿äºæ¨¡å¼ï¼ä¾å¦çå½ä½å¾è¶å¿ï¼å¦å¼å¸¸å¿çæè¡åï¼å¯è½è¡¨æå¥åº·ç¶åµæ¶åæå³å°åççå±éäºä»¶ãç±»ä¼¼å°ï¼ä¸´åºç¬è®°éå¸¸åå«åæ è¿äºæ¨¡å¼çææ¬æè¿°ãè¯å«ä¸åæ¨¡æä¹é´ç¸åºçæ¶é´æ¨¡å¼å¯¹äºæé«ä¸´åºç»æé¢æµçåç¡®æ§è³å³éè¦ï¼ä½å®ä»ç¶æ¯ä¸é¡¹å·ææææ§çä»»å¡ãä¸ºäºè§£å³è¿ä¸å·®è·ï¼æä»¬å¼å¥äºä¸ä¸ªè·¨æ¨¡ææ¶é´æ¨¡å¼åç° (CTPD) æ¡æ¶ï¼æ¨å¨ä»å¤æ¨¡æ EHR æ°æ®ä¸­æææåææä¹çè·¨æ¨¡ææ¶é´æ¨¡å¼ãæä»¬çæ¹æ³å¼å¥äºå±äº«çåå§æ¶é´æ¨¡å¼è¡¨ç¤ºï¼è¿äºè¡¨ç¤ºä½¿ç¨ææ§½æ³¨æåè¿è¡ä¼åä»¥çææ¶é´è¯­ä¹åµå¥ãä¸ºäºç¡®ä¿å­¦ä¹ æ¨¡å¼ä¸­ä¸°å¯çè·¨æ¨¡ææ¶é´è¯­ä¹ï¼æä»¬å¼å¥äºåºäºå¯¹æ¯ç TPNCE æå¤±ç¨äºè·¨æ¨¡æå¯¹é½ï¼ä»¥åä¸¤ä¸ªéå»ºæå¤±ä»¥ä¿çæ¯ä¸ªæ¨¡æçæ ¸å¿ä¿¡æ¯ãå¨ä¸¤ä¸ªä¸´åºå³é®ä»»å¡ï¼48 å°æ¶é¢åæ­»äº¡çå 24 å°æ¶è¡¨ååç±»ï¼ä¸çè¯ä¼°ï¼ä½¿ç¨ MIMIC-III æ°æ®åºè¯æäºæä»¬æ¹æ³ä¼äºç°ææ¹æ³ã

##### **Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**
2411.00916v2 by Mehdi Hosseini Chagahi, Saeed Mohammadi Dashtaki, Niloufar Delfan, Nadia Mohammadi, Alireza Samari, Behzad Moshiri, Md. Jalil Piran, Oliver Faust

Osteoporosis is a common condition that increases fracture risk, especially
in older adults. Early diagnosis is vital for preventing fractures, reducing
treatment costs, and preserving mobility. However, healthcare providers face
challenges like limited labeled data and difficulties in processing medical
images. This study presents a novel multi-modal learning framework that
integrates clinical and imaging data to improve diagnostic accuracy and model
interpretability. The model utilizes three pre-trained networks-VGG19,
InceptionV3, and ResNet50-to extract deep features from X-ray images. These
features are transformed using PCA to reduce dimensionality and focus on the
most relevant components. A clustering-based selection process identifies the
most representative components, which are then combined with preprocessed
clinical data and processed through a fully connected network (FCN) for final
classification. A feature importance plot highlights key variables, showing
that Medical History, BMI, and Height were the main contributors, emphasizing
the significance of patient-specific data. While imaging features were
valuable, they had lower importance, indicating that clinical data are crucial
for accurate predictions. This framework promotes precise and interpretable
predictions, enhancing transparency and building trust in AI-driven diagnoses
for clinical integration.

æè¦ï¼éª¨è³ªçé¬çæ¯ä¸ç¨®å¸¸è¦çç¾çï¼æå¢å éª¨æçé¢¨éªï¼ç¹å¥æ¯èå¹´äººãæ©æè¨ºæ·å°æ¼é é²éª¨æãéä½æ²»çææ¬åç¶­æè¡åè½åè³ééè¦ãç¶èï¼é«çä¿å¥æä¾èé¢è¨èæ¨è¨æ¸ææéåèçé«å­¸å½±åå°é£ç­ææ°ãæ¬ç ç©¶æåºäºä¸åæ°ç©çå¤æ¨¡å¼å­¸ç¿æ¡æ¶ï¼è©²æ¡æ¶æ´åäºè¨åºåå½±åæ¸æï¼ä»¥æé«è¨ºæ·æºç¢ºæ§åæ¨¡åå¯è§£éæ§ãè©²æ¨¡åå©ç¨ä¸åé è¨ç·´çç¶²è·¯ï¼VGG19ãInceptionV3 å ResNet50ï¼å¾ X å°ç·å½±åä¸­æåæ·±åº¦ç¹å¾µãéäºç¹å¾µä½¿ç¨ PCA è½æä»¥éä½ç¶­åº¦ä¸¦å°æ³¨æ¼æç¸éççµæé¨åãåºæ¼èé¡çé¸æéç¨è­å¥åºæå·ä»£è¡¨æ§ççµæé¨åï¼ç¶å¾å°éäºçµæé¨åèé èççè¨åºæ¸æçµåï¼ä¸¦ééå¨é£æ¥ç¶²è·¯ (FCN) é²è¡æçµåé¡ãç¹å¾µéè¦æ§åçªåºäºééµè®æ¸ï¼è¡¨æçå²ãBMI åèº«é«æ¯ä¸»è¦è²¢ç»å ç´ ï¼å¼·èª¿äºæ£èç¹å®æ¸æçéè¦æ§ãéç¶å½±åç¹å¾µå¾æå¹å¼ï¼ä½å®åçéè¦æ§è¼ä½ï¼éè¡¨æè¨åºæ¸æå°æ¼æºç¢ºé æ¸¬è³ééè¦ãæ­¤æ¡æ¶ä¿è¿äºæºç¢ºä¸å¯è§£éçé æ¸¬ï¼æé«äºéæåº¦ï¼ä¸¦å»ºç«äºå° AI é©åè¨ºæ·å¨è¨åºæ´åä¸­çä¿¡ä»»ã

##### **Deep learning-based auto-contouring of organs/structures-at-risk for pediatric upper abdominal radiotherapy**
2411.00594v1 by Mianyong Ding, Matteo Maspero, Annemieke S Littooij, Martine van Grotel, Raquel Davila Fajardo, Max M van Noesel, Marry M van den Heuvel-Eibrink, Geert O Janssens

Purposes: This study aimed to develop a computed tomography (CT)-based
multi-organ segmentation model for delineating organs-at-risk (OARs) in
pediatric upper abdominal tumors and evaluate its robustness across multiple
datasets. Materials and methods: In-house postoperative CTs from pediatric
patients with renal tumors and neuroblastoma (n=189) and a public dataset
(n=189) with CTs covering thoracoabdominal regions were used. Seventeen OARs
were delineated: nine by clinicians (Type 1) and eight using TotalSegmentator
(Type 2). Auto-segmentation models were trained using in-house (ModelPMC-UMCU)
and a combined dataset of public data (Model-Combined). Performance was
assessed with Dice Similarity Coefficient (DSC), 95% Hausdorff Distance (HD95),
and mean surface distance (MSD). Two clinicians rated clinical acceptability on
a 5-point Likert scale across 15 patient contours. Model robustness was
evaluated against sex, age, intravenous contrast, and tumor type. Results:
Model-PMC-UMCU achieved mean DSC values above 0.95 for five of nine OARs, while
spleen and heart ranged between 0.90 and 0.95. The stomach-bowel and pancreas
exhibited DSC values below 0.90. Model-Combined demonstrated improved
robustness across both datasets. Clinical evaluation revealed good usability,
with both clinicians rating six of nine Type 1 OARs above four and six of eight
Type 2 OARs above three. Significant performance 2 differences were only found
across age groups in both datasets, specifically in the left lung and pancreas.
The 0-2 age group showed the lowest performance. Conclusion: A multi-organ
segmentation model was developed, showcasing enhanced robustness when trained
on combined datasets. This model is suitable for various OARs and can be
applied to multiple datasets in clinical settings.

æè¦ï¼<paragraph>ç®çï¼æ¬ç ç©¶æ¨å¨å¼åä¸ä¸ªåºäºè®¡ç®æºæ­å±æ«æ (CT) çå¤å¨å®åå²æ¨¡åï¼ç¨äºæç»å°å¿ä¸è¹é¨è¿ç¤ä¸­çå±é©å¨å® (OAR)ï¼å¹¶è¯ä¼°å¶å¨å¤ä¸ªæ°æ®éä¸­çç¨³å¥æ§ãææåæ¹æ³ï¼ä½¿ç¨å°å¿è¾è¿ç¤åç¥ç»æ¯ç»èç¤æ£è (n=189) çé¢åæ¯å CT ä»¥ååå«è¸è¹åºå CT çå¬å±æ°æ®é (n=189)ãæç»äº 17 ä¸ª OARï¼9 ä¸ªç±ä¸´åºå»çæç» (ç±»å 1)ï¼8 ä¸ªä½¿ç¨ TotalSegmentator æç» (ç±»å 2)ãä½¿ç¨é¢å (ModelPMC-UMCU) åå¬å±æ°æ®ç»åæ°æ®é (Model-Combined) è®­ç»èªå¨åå²æ¨¡åãä½¿ç¨éª°å­ç¸ä¼¼æ§ç³»æ° (DSC)ã95% éæ¯å¤å¤«è·ç¦» (HD95) åå¹³åè¡¨é¢è·ç¦» (MSD) è¯ä¼°æ§è½ãä¸¤ä½ä¸´åºå»çä½¿ç¨ 5 ç¹æåç¹éè¡¨å¯¹ 15 ä¸ªæ£èè½®å»çä¸´åºå¯æ¥åæ§è¿è¡è¯çº§ãéå¯¹æ§å«ãå¹´é¾ãéèå¯¹æ¯åè¿ç¤ç±»åè¯ä¼°æ¨¡åçç¨³å¥æ§ãç»æï¼Model-PMC-UMCU å¯¹ä¹ä¸ª OAR ä¸­çäºä¸ª OAR çå¹³å DSC å¼è¾¾å° 0.95 ä»¥ä¸ï¼èè¾èåå¿èå¨ 0.90 å° 0.95 ä¹é´ãèè åè°èºç DSC å¼ä½äº 0.90ãModel-Combined å¨ä¸¤ä¸ªæ°æ®éä¸é½è¡¨ç°åºæ¹è¿çç¨³å¥æ§ãä¸´åºè¯ä¼°æ¾ç¤ºåºè¯å¥½çå¯ç¨æ§ï¼ä¸¤ä½ä¸´åºå»çå¯¹å­ä¸ªä¹ä¸ªç±»å 1 OAR çè¯ååé«äºååï¼å¯¹å«ä¸ªç±»å 2 OAR ä¸­çå­ä¸ªè¯ååé«äºä¸åãä»å¨ä¸¤ä¸ªæ°æ®éçå¹´é¾ç»ä¸­åç°äºæ¾ççæ§è½ 2 å·®å¼ï¼ç¹å«æ¯å¨å·¦èºåè°èºä¸­ã0-2 å²å¹´é¾ç»è¡¨ç°æå·®ãç»è®ºï¼å¼åäºä¸ä¸ªå¤å¨å®åå²æ¨¡åï¼å¨åå¹¶æ°æ®éä¸è®­ç»æ¶æ¾ç¤ºåºå¢å¼ºçç¨³å¥æ§ãè¯¥æ¨¡åéç¨äºåç§ OARï¼å¹¶ä¸å¯ä»¥å¨ä¸´åºç¯å¢ä¸­åºç¨äºå¤ä¸ªæ°æ®éã</paragraph>

##### **Enhancing the Traditional Chinese Medicine Capabilities of Large Language Model through Reinforcement Learning from AI Feedback**
2411.00897v1 by Song Yu, Xiaofei Xu, Fangfei Xu, Li Li

Although large language models perform well in understanding and responding
to user intent, their performance in specialized domains such as Traditional
Chinese Medicine (TCM) remains limited due to lack of expertise. In addition,
high-quality data related to TCM is scarce and difficult to obtain, making
large language models ineffective in handling TCM tasks. In this work, we
propose a framework to improve the performance of large language models for TCM
tasks using only a small amount of data. First, we use medical case data for
supervised fine-tuning of the large model, making it initially capable of
performing TCM tasks. Subsequently, we further optimize the model's performance
using reinforcement learning from AI feedback (RLAIF) to align it with the
preference data. The ablation study also demonstrated the performance gain is
attributed to both supervised fine-tuning and the direct policy optimization.
The experimental results show that the model trained with a small amount of
data achieves a significant performance improvement on a representative TCM
task.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡åå¨çè§£ååæä½¿ç¨èæåæ¹é¢è¡¨ç¾è¯å¥½ï¼ä½ç±æ¼ç¼ºä¹å°æ¥­ç¥è­ï¼å®åå¨å³çµ±ä¸­é« (TCM) ç­å°æ¥­é åçè¡¨ç¾ä»ç¶æéãæ­¤å¤ï¼èä¸­é«ç¸éçé«åè³ªè³æç¨å°ä¸é£ä»¥åå¾ï¼éä½¿å¾å¤§åèªè¨æ¨¡åå¨èçä¸­é«ä»»åæææä¸å½°ãå¨éé å·¥ä½ä¸­ï¼æåæåºä¸åæ¶æ§ï¼ä½¿ç¨å°éè³æä¾æ¹åå¤§åèªè¨æ¨¡åå¨ä¸­é«ä»»åä¸­çè¡¨ç¾ãé¦åï¼æåä½¿ç¨é«çæ¡ä¾è³æå°å¤§åæ¨¡åé²è¡ç£ç£å¾®èª¿ï¼ä½¿å¶æåå·åå·è¡ä¸­é«ä»»åçè½åãé¨å¾ï¼æåé²ä¸æ­¥ä½¿ç¨äººå·¥æºæ§åé¥çå¼·åå­¸ç¿ (RLAIF) ä¾æä½³åæ¨¡åçè¡¨ç¾ï¼ä½¿å¶èåå¥½è³æä¿æä¸è´ãæ¶èç ç©¶ä¹è­æï¼è¡¨ç¾æåæ­¸åæ¼ç£ç£å¾®èª¿åç´æ¥ç­ç¥æä½³åãå¯¦é©çµæé¡¯ç¤ºï¼ä½¿ç¨å°éè³æè¨ç·´çæ¨¡åå¨ä»£è¡¨æ§çä¸­é«ä»»åä¸åå¾é¡¯èçè¡¨ç¾æåã

##### **StepCountJITAI: simulation environment for RL with application to physical activity adaptive intervention**
2411.00336v1 by Karine Karine, Benjamin M. Marlin

The use of reinforcement learning (RL) to learn policies for just-in-time
adaptive interventions (JITAIs) is of significant interest in many behavioral
intervention domains including improving levels of physical activity. In a
messaging-based physical activity JITAI, a mobile health app is typically used
to send messages to a participant to encourage engagement in physical activity.
In this setting, RL methods can be used to learn what intervention options to
provide to a participant in different contexts. However, deploying RL methods
in real physical activity adaptive interventions comes with challenges: the
cost and time constraints of real intervention studies result in limited data
to learn adaptive intervention policies. Further, commonly used RL simulation
environments have dynamics that are of limited relevance to physical activity
adaptive interventions and thus shed little light on what RL methods may be
optimal for this challenging application domain. In this paper, we introduce
StepCountJITAI, an RL environment designed to foster research on RL methods
that address the significant challenges of policy learning for adaptive
behavioral interventions.

æè¦ï¼å©ç¨å¼·åå­¸ç¿ (RL) ä¾å­¸ç¿å³æé©ææ§ä»å¥ (JITAI) çç­ç¥ï¼å¨è¨±å¤è¡çºä»å¥é åä¸­ååéæ³¨ï¼åæ¬æåé«è½æ´»åçå±¤ç´ãå¨åºæ¼è¨æ¯çé«è½æ´»å JITAI ä¸­ï¼è¡åå¥åº·æç¨ç¨å¼éå¸¸ç¨æ¼ååèèå³éè¨æ¯ï¼ä»¥é¼åµåèé«è½æ´»åãå¨æ­¤è¨­å®ä¸­ï¼RL æ¹æ³å¯è¢«ç¨æ¼å­¸ç¿å¨ä¸åæå¢ä¸æä¾çµ¦åèèçä»å¥é¸é ãç¶èï¼å¨å¯¦éé«è½æ´»åé©ææ§ä»å¥ä¸­é¨ç½² RL æ¹æ³æéå°ææ°ï¼å¯¦éä»å¥ç ç©¶çææ¬åæééå¶ï¼å°è´å¯ä¾å­¸ç¿é©ææ§ä»å¥ç­ç¥çè³ææéãæ­¤å¤ï¼å¸¸ç¨ç RL æ¨¡æ¬ç°å¢å·æèé«è½æ´»åé©ææ§ä»å¥ç¸éæ§æéçåæï¼å æ­¤é£ä»¥äºè§£åªäº RL æ¹æ³å¯è½æé©åéåå·ææ°æ§çæç¨é åãå¨æ¬æä¸­ï¼æåä»ç´¹ StepCountJITAIï¼éæ¯ä¸å RL ç°å¢ï¼æ¨å¨ä¿é²å° RL æ¹æ³çç ç©¶ï¼ä»¥æå°é©ææ§è¡çºä»å¥ç­ç¥å­¸ç¿çéå¤§ææ°ã

##### **Strongly Topology-preserving GNNs for Brain Graph Super-resolution**
2411.02525v1 by Pragya Singh, Islem Rekik

Brain graph super-resolution (SR) is an under-explored yet highly relevant
task in network neuroscience. It circumvents the need for costly and
time-consuming medical imaging data collection, preparation, and processing.
Current SR methods leverage graph neural networks (GNNs) thanks to their
ability to natively handle graph-structured datasets. However, most GNNs
perform node feature learning, which presents two significant limitations: (1)
they require computationally expensive methods to learn complex node features
capable of inferring connectivity strength or edge features, which do not scale
to larger graphs; and (2) computations in the node space fail to adequately
capture higher-order brain topologies such as cliques and hubs. However,
numerous studies have shown that brain graph topology is crucial in identifying
the onset and presence of various neurodegenerative disorders like Alzheimer
and Parkinson. Motivated by these challenges and applications, we propose our
STP-GSR framework. It is the first graph SR architecture to perform
representation learning in higher-order topological space. Specifically, using
the primal-dual graph formulation from graph theory, we develop an efficient
mapping from the edge space of our low-resolution (LR) brain graphs to the node
space of a high-resolution (HR) dual graph. This approach ensures that
node-level computations on this dual graph correspond naturally to edge-level
learning on our HR brain graphs, thereby enforcing strong topological
consistency within our framework. Additionally, our framework is GNN layer
agnostic and can easily learn from smaller, scalable GNNs, reducing
computational requirements. We comprehensively benchmark our framework across
seven key topological measures and observe that it significantly outperforms
the previous state-of-the-art methods and baselines.

æè¦ï¼è¦ååè¶è§£æåº¦ (SR) æ¯ç¶²è·¯ç¥ç¶ç§å­¸ä¸­ä¸åå°æªååæ¢ç´¢ä½é«åº¦ç¸éçä»»åãå®é¿éäºä»£å¹é«æä¸èæçé«å­¸å½±åè³ææ¶éãæºååèççéè¦ãç®åç SR æ¹æ³å©ç¨åç¥ç¶ç¶²è·¯ (GNN)ï¼å çºå®åè½å¤ åçèçåå½¢çµæ§çè³æéãç¶èï¼å¤§å¤æ¸ GNN é½å·è¡ç¯é»ç¹å¾µå­¸ç¿ï¼éæåºäºå©åéå¤§çéå¶ï¼(1) å®åéè¦ä»¥è¨ç®ææ¬é«çæ¹å¼ä¾å­¸ç¿è¤éçç¯é»ç¹å¾µï¼éäºç¹å¾µè½å¤ æ¨è«é£æ¥å¼·åº¦æéç·£ç¹å¾µï¼éç¡æ³æ´å±å°æ´å¤§çåå½¢ï¼(2) ç¯é»ç©ºéä¸­çè¨ç®ç¡æ³ååæ·åé«éè¦é¨ææ²ï¼ä¾å¦æ´¾ç³»åæ¨ç´ãç¶èï¼è¨±å¤ç ç©¶è¡¨æï¼è¦åå½¢ææ²å°æ¼è­å¥åç¨®ç¥ç¶éåæ§ç¾çï¼å¦é¿è²æµ·é»çåå¸éæ£®æ°çï¼çç¼çåå­å¨è³ééè¦ãåå°éäºææ°åæç¨æ¿åµï¼æåæåºäºæåç STP-GSR æ¶æ§ãå®æ¯ç¬¬ä¸åå¨é«éææ²ç©ºéä¸­å·è¡è¡¨ç¤ºå­¸ç¿çåå½¢ SR æ¶æ§ãå·é«ä¾èªªï¼æåä½¿ç¨åè«ä¸­çåå§å°å¶åå½¢å¬å¼ï¼å¾æåä½è§£æåº¦ (LR) è¦åå½¢çéç·£ç©ºééç¼äºä¸åé«æçå°æ ï¼å°æ å°é«è§£æåº¦ (HR) å°å¶åå½¢ç¯é»ç©ºéãéç¨®æ¹æ³ç¢ºä¿äºå¨éåå°å¶åå½¢ä¸çç¯é»å±¤ç´è¨ç®èªç¶å°å°ææ¼æå HR è¦åå½¢ä¸çéç·£å±¤ç´å­¸ç¿ï¼å¾èå¼·å¶å·è¡æåæ¡æ¶å§å¼·å¤§çææ²ä¸è´æ§ãæ­¤å¤ï¼æåçæ¡æ¶è GNN å±¤ç¡éï¼ä¸¦ä¸å¯ä»¥è¼é¬å°å¾æ´å°ãå¯æ´å±ç GNN ä¸­å­¸ç¿ï¼å¾èæ¸å°è¨ç®éæ±ãæåå¨ä¸é ééµææ²æ¸¬éä¸­å¨é¢è©å®äºæåçæ¡æ¶ï¼ä¸¦è§å¯å°å®é¡¯èåªæ¼ä»¥å¾çåé²æ¹æ³ååºç·ã

##### **Evaluating the Impact of Lab Test Results on Large Language Models Generated Differential Diagnoses from Clinical Case Vignettes**
2411.02523v1 by Balu Bhasuran, Qiao Jin, Yuzhang Xie, Carl Yang, Karim Hanna, Jennifer Costa, Cindy Shavor, Zhiyong Lu, Zhe He

Differential diagnosis is crucial for medicine as it helps healthcare
providers systematically distinguish between conditions that share similar
symptoms. This study assesses the impact of lab test results on differential
diagnoses (DDx) made by large language models (LLMs). Clinical vignettes from
50 case reports from PubMed Central were created incorporating patient
demographics, symptoms, and lab results. Five LLMs GPT-4, GPT-3.5, Llama-2-70b,
Claude-2, and Mixtral-8x7B were tested to generate Top 10, Top 5, and Top 1 DDx
with and without lab data. A comprehensive evaluation involving GPT-4, a
knowledge graph, and clinicians was conducted. GPT-4 performed best, achieving
55% accuracy for Top 1 diagnoses and 60% for Top 10 with lab data, with lenient
accuracy up to 80%. Lab results significantly improved accuracy, with GPT-4 and
Mixtral excelling, though exact match rates were low. Lab tests, including
liver function, metabolic/toxicology panels, and serology/immune tests, were
generally interpreted correctly by LLMs for differential diagnosis.

æè¦ï¼éå¥è¨ºæ·å°æ¼é«å­¸è³ééè¦ï¼å çºå®æå©æ¼é«çä¿å¥æä¾èç³»çµ±ååå·æç¸ä¼¼çççç¾çãéé ç ç©¶è©ä¼°äºå¯¦é©å®¤æª¢é©çµæå°å¤§åèªè¨æ¨¡å (LLM) ååºçéå¥è¨ºæ· (DDx) çå½±é¿ãå¾ PubMed Central ç 50 ä»½çä¾å ±åä¸­å»ºç«äºè¨åºç°¡å ±ï¼å¶ä¸­åå«æ£èäººå£çµ±è¨ãççåå¯¦é©å®¤çµæãæ¸¬è©¦äºäºå LLM GPT-4ãGPT-3.5ãLlama-2-70bãClaude-2 å Mixtral-8x7Bï¼ä»¥çæå¸¶åä¸å¸¶å¯¦é©å®¤æ¸æçå 10ãå 5 åå 1 DDxãé²è¡äºä¸é æ¶å GPT-4ãç¥è­åè­åè¨åºé«ççç¶åè©ä¼°ãGPT-4 è¡¨ç¾æä½³ï¼å¨æå¯¦é©å®¤æ¸æçææ³ä¸ï¼å 1 åè¨ºæ·çæºç¢ºçéå° 55%ï¼å 10 åçæºç¢ºçéå° 60%ï¼å¯¬é¬æºç¢ºçé«é 80%ãå¯¦é©å®¤çµæé¡¯èæé«äºæºç¢ºçï¼GPT-4 å Mixtral è¡¨ç¾åºè²ï¼åç®¡å®å¨å¹éçè¼ä½ãLLM éå¸¸å¯ä»¥æ­£ç¢ºè§£éåæ¬èåè½ãä»£è¬/æ¯çå­¸æª¢æ¥åè¡æ¸å­¸/åç«æ¸¬è©¦å¨å§çå¯¦é©å®¤æª¢é©ï¼ä»¥é²è¡éå¥è¨ºæ·ã

##### **Deep Learning Predicts Mammographic Breast Density in Clinical Breast Ultrasound Images**
2411.00891v2 by Arianna Bunnell, Dustin Valdez, Thomas K. Wolfgruber, Brandon Quon, Kailee Hung, Brenda Y. Hernandez, Todd B. Seto, Jeffrey Killeen, Marshall Miyoshi, Peter Sadowski, John A. Shepherd

Background: Breast density, as derived from mammographic images and defined
by the American College of Radiology's Breast Imaging Reporting and Data System
(BI-RADS), is one of the strongest risk factors for breast cancer. Breast
ultrasound (BUS) is an alternative breast cancer screening modality,
particularly useful for early detection in low-resource, rural contexts. The
purpose of this study was to explore an artificial intelligence (AI) model to
predict BI-RADS mammographic breast density category from clinical, handheld
BUS imaging. Methods: All data are sourced from the Hawaii and Pacific Islands
Mammography Registry. We compared deep learning methods from BUS imaging, as
well as machine learning models from image statistics alone. The use of
AI-derived BUS density as a risk factor for breast cancer was then compared to
clinical BI-RADS breast density while adjusting for age. The BUS data were
split by individual into 70/20/10% groups for training, validation, and
testing. Results: 405,120 clinical BUS images from 14.066 women were selected
for inclusion in this study, resulting in 9.846 women for training (302,574
images), 2,813 for validation (11,223 images), and 1,406 for testing (4,042
images). On the held-out testing set, the strongest AI model achieves AUROC
0.854 predicting BI-RADS mammographic breast density from BUS imaging and
outperforms all shallow machine learning methods based on image statistics. In
cancer risk prediction, age-adjusted AI BUS breast density predicted 5-year
breast cancer risk with 0.633 AUROC, as compared to 0.637 AUROC from
age-adjusted clinical breast density. Conclusions: BI-RADS mammographic breast
density can be estimated from BUS imaging with high accuracy using a deep
learning model. Furthermore, we demonstrate that AI-derived BUS breast density
is predictive of 5-year breast cancer risk in our population.

æè¦ï¼èæ¯ï¼ä¹³æ¿å¯åº¦æ¯æ ¹æ®ä¹³æ¿ X åå¾åè¡çèæ¥ï¼å¹¶ç±ç¾å½æ¾å°å­¦é¢çä¹³æ¿å½±åæ¥ååæ°æ®ç³»ç» (BI-RADS) å®ä¹ï¼æ¯ä¹³èºçæå¼ºçé£é©å ç´ ä¹ä¸ãä¹³æ¿è¶é³æ³¢ (BUS) æ¯ä¸ç§æ¿ä»£çä¹³èºçç­æ£æ¹å¼ï¼ç¹å«éç¨äºèµæºå®ä¹çåæç¯å¢ä¸­çæ©æä¾¦æµãæ¬ç ç©¶çç®çæ¯æ¢ç´¢ä¸ç§äººå·¥æºè½ (AI) æ¨¡åï¼ä»¥æ ¹æ®ä¸´åºææå¼ BUS å½±åé¢æµ BI-RADS ä¹³æ¿ X åæå½±ä¹³æ¿å¯åº¦ç±»å«ãæ¹æ³ï¼æææ°æ®åæ¥èªå¤å¨å¤·åå¤ªå¹³æ´å²å±¿ä¹³æ¿æå½±æ³¨åä¸­å¿ãæä»¬æ¯è¾äºæ¥èª BUS å½±åçæ·±åº¦å­¦ä¹ æ¹æ³ï¼ä»¥åä»æ¥èªå¾åç»è®¡æ°æ®çæºå¨å­¦ä¹ æ¨¡åãç¶åå° AI è¡çç BUS å¯åº¦ç¨ä½ä¹³èºççé£é©å å­ï¼ä¸ä¸´åº BI-RADS ä¹³æ¿å¯åº¦è¿è¡æ¯è¾ï¼åæ¶è°æ´å¹´é¾ãBUS æ°æ®æä¸ªäººåä¸º 70/20/10% çç»å«ï¼ç¨äºè®­ç»ãéªè¯åæµè¯ãç»æï¼æ¬ç ç©¶éåäºæ¥èª 14.066 åå¥³æ§ç 405,120 å¼ ä¸´åº BUS å½±åï¼äº§çäº 9.846 åå¥³æ§ç¨äºè®­ç»ï¼302,574 å¼ å½±åï¼ã2,813 åç¨äºéªè¯ï¼11,223 å¼ å½±åï¼å 1,406 åç¨äºæµè¯ï¼4,042 å¼ å½±åï¼ãå¨çåºçæµè¯éä¸­ï¼æå¼ºç AI æ¨¡åå®ç°äº 0.854 ç AUROCï¼æ ¹æ® BUS å½±åé¢æµ BI-RADS ä¹³æ¿ X åæå½±ä¹³æ¿å¯åº¦ï¼å¹¶ä¸ä¼äºææåºäºå¾åç»è®¡çæµå±æºå¨å­¦ä¹ æ¹æ³ãå¨ççé£é©é¢æµä¸­ï¼ç»å¹´é¾è°æ´ç AI BUS ä¹³æ¿å¯åº¦é¢æµ 5 å¹´ä¹³èºçé£é©ç AUROC ä¸º 0.633ï¼èç»å¹´é¾è°æ´çä¸´åºä¹³æ¿å¯åº¦é¢æµç AUROC ä¸º 0.637ãç»è®ºï¼ä½¿ç¨æ·±åº¦å­¦ä¹ æ¨¡åï¼å¯ä»¥ä» BUS å½±åä¸­ä»¥é«ç²¾åº¦ä¼°è®¡ BI-RADS ä¹³æ¿ X åæå½±ä¹³æ¿å¯åº¦ãæ­¤å¤ï¼æä»¬è¯æäº AI è¡çç BUS ä¹³æ¿å¯åº¦å¯ä»¥é¢æµæä»¬äººç¾¤ä¸­ 5 å¹´çä¹³èºçé£é©ã

##### **Monitoring fairness in machine learning models that predict patient mortality in the ICU**
2411.00190v2 by Tempest A. van Schaik, Xinggang Liu, Louis Atallah, Omar Badawi

This work proposes a fairness monitoring approach for machine learning models
that predict patient mortality in the ICU. We investigate how well models
perform for patient groups with different race, sex and medical diagnoses. We
investigate Documentation bias in clinical measurement, showing how fairness
analysis provides a more detailed and insightful comparison of model
performance than traditional accuracy metrics alone.

æè¦ï¼éé ç ç©¶æåºä¸åå¬å¹³æ§ç£æ§æ¹æ³ï¼ç¨æ¼é æ¸¬å è­·çæ¿ä¸­çæ£æ­»äº¡ççæ©å¨å­¸ç¿æ¨¡åãæåæ¢è¨æ¨¡åå¨ä¸åç¨®æãæ§å¥åé«çè¨ºæ·ççæ£ç¾¤é«ä¸­è¡¨ç¾å¦ä½ãæåæ¢è¨è¨åºæ¸¬éä¸­çæä»¶åå·®ï¼èªªæå¬å¹³æ§åæå¦ä½æä¾æ¯å³çµ±æºç¢ºæ§ææ¨æ´è©³ç´°ä¸æè¦å°çæ¨¡åæè½æ¯è¼ã

##### **Clinical Evaluation of Medical Image Synthesis: A Case Study in Wireless Capsule Endoscopy**
2411.00178v1 by Panagiota Gatoula, Dimitrios E. Diamantis, Anastasios Koulaouzidis, Cristina Carretero, Stefania Chetcuti-Zammit, Pablo Cortegoso Valdivia, BegoÃ±a GonzÃ¡lez-SuÃ¡rez, Alessandro Mussetto, John Plevris, Alexander Robertson, Bruno Rosa, Ervin Toth, Dimitris K. Iakovidis

Sharing retrospectively acquired data is essential for both clinical research
and training. Synthetic Data Generation (SDG), using Artificial Intelligence
(AI) models, can overcome privacy barriers in sharing clinical data, enabling
advancements in medical diagnostics. This study focuses on the clinical
evaluation of medical SDG, with a proof-of-concept investigation on diagnosing
Inflammatory Bowel Disease (IBD) using Wireless Capsule Endoscopy (WCE) images.
The paper contributes by a) presenting a protocol for the systematic evaluation
of synthetic images by medical experts and b) applying it to assess TIDE-II, a
novel variational autoencoder-based model for high-resolution WCE image
synthesis, with a comprehensive qualitative evaluation conducted by 10
international WCE specialists, focusing on image quality, diversity, realism,
and clinical decision-making. The results show that TIDE-II generates
clinically relevant WCE images, helping to address data scarcity and enhance
diagnostic tools. The proposed protocol serves as a reference for future
research on medical image-generation techniques.

æè¦ï¼åé¡§æ§ç²åçè³æåäº«å°æ¼è¨åºç ç©¶åè¨ç·´è³ééè¦ãä½¿ç¨äººå·¥æºæ§ (AI) æ¨¡åçåæè³æç¢ç (SDG) è½å¤ åæè¨åºè³æå±äº«ä¸­çé±ç§éç¤ï¼ä¿é²é«çè¨ºæ·çé²å±ãæ¬ç ç©¶å°æ³¨æ¼è¨åºè©ä¼°é«å­¸ SDGï¼ä¸¦ééç¡ç·è åå§è¦é¡ (WCE) å½±åè¨ºæ·ç¼çæ§è¸éç¾ç (IBD) çæ¦å¿µé©è­èª¿æ¥ãæ¬æçè²¢ç»åæ¬ï¼a) æåºç±é«å­¸å°å®¶ç³»çµ±æ§è©ä¼°åæå½±åçåå®ï¼ä»¥å b) å°å¶æç¨æ¼è©ä¼° TIDE-IIï¼éæ¯ä¸åç¨æ¼é«è§£æåº¦ WCE å½±ååæçè®ç°èªåç·¨ç¢¼å¨æ¨¡åï¼ä¸¦ç± 10 ä½åé WCE å°å®¶é²è¡å¨é¢çåè³ªè©ä¼°ï¼éé»å¨æ¼å½±ååè³ªãå¤æ¨£æ§ãçå¯¦æ§ï¼ä»¥åè¨åºæ±ºç­å¶å®ãçµæé¡¯ç¤º TIDE-II ç¢çäºè¨åºç¸éç WCE å½±åï¼æå©æ¼è§£æ±ºè³æç¨å°çåé¡ï¼ä¸¦å¢å¼·è¨ºæ·å·¥å·ãææåºçåå®å¯ä½çºæªä¾é«å­¸å½±åç¢çæè¡ç ç©¶çåèã

##### **Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning**
2411.00173v1 by John Wu, David Wu, Jimeng Sun

Medical coding, the translation of unstructured clinical text into
standardized medical codes, is a crucial but time-consuming healthcare
practice. Though large language models (LLM) could automate the coding process
and improve the efficiency of such tasks, interpretability remains paramount
for maintaining patient trust. Current efforts in interpretability of medical
coding applications rely heavily on label attention mechanisms, which often
leads to the highlighting of extraneous tokens irrelevant to the ICD code. To
facilitate accurate interpretability in medical language models, this paper
leverages dictionary learning that can efficiently extract sparsely activated
representations from dense language model embeddings in superposition. Compared
with common label attention mechanisms, our model goes beyond token-level
representations by building an interpretable dictionary which enhances the
mechanistic-based explanations for each ICD code prediction, even when the
highlighted tokens are medically irrelevant. We show that dictionary features
can steer model behavior, elucidate the hidden meanings of upwards of 90% of
medically irrelevant tokens, and are human interpretable.

æè¦ï¼é«çç·¨ç¢¼æ¯å°éçµæ§åçè¨åºææ¬è½æçºæ¨æºåé«çä»£ç¢¼çéç¨ï¼æ¯ä¸é è³ééè¦çé«çä¿å¥å¯¦åï¼ä½èæè²»åãåç®¡å¤§åèªè¨æ¨¡å (LLM) å¯ä»¥èªååç·¨ç¢¼æµç¨ä¸¦æåæ­¤é¡ä»»åçæçï¼ä½å¯è§£éæ§å°æ¼ç¶­è­·æ£èä¿¡ä»»ä»ç¶è³ééè¦ãç®åå¨é«çç·¨ç¢¼æç¨ç¨å¼çå¯è§£éæ§æ¹é¢æåçåªåï¼æ¥µåº¦ä¾è³´æ¨ç±¤æ³¨ææ©å¶ï¼ééå¸¸æå°è´å¼·èª¿è ICD ä»£ç¢¼ç¡éçç¡éç¬¦èãçºäºä¿é²é«çèªè¨æ¨¡åçæºç¢ºå¯è§£éæ§ï¼æ¬æå©ç¨å­å¸å­¸ç¿ï¼å¯ä»¥ææå°å¾çå çç¨ å¯èªè¨æ¨¡ååµå¥ä¸­æåç¨çæ¿æ´»çè¡¨ç¤ºãèå¸¸è¦çæ¨ç±¤æ³¨ææ©å¶ç¸æ¯ï¼æåçæ¨¡åè¶è¶äºç¬¦èå±¤ç´çè¡¨ç¤ºï¼å»ºç«äºä¸åå¯è§£éçå­å¸ï¼å¢å¼·äºå°æ¯å ICD ä»£ç¢¼é æ¸¬çåºæ¼æ©å¶çè§£éï¼å³ä½¿å¼·èª¿çç¬¦èå¨é«å­¸ä¸ç¡éç·è¦ãæåè­æå­å¸ç¹å¾µå¯ä»¥å¼å°æ¨¡åè¡çºï¼é¡æ 90% ä»¥ä¸å¨é«å­¸ä¸ç¡éçç¬¦èçé±èæç¾©ï¼ä¸¦ä¸äººé¡å¯ä»¥è§£éã

##### **Navigating the Unknown: A Chat-Based Collaborative Interface for Personalized Exploratory Tasks**
2410.24032v1 by Yingzhe Peng, Xiaoting Qin, Zhiyang Zhang, Jue Zhang, Qingwei Lin, Xu Yang, Dongmei Zhang, Saravan Rajmohan, Qi Zhang

The rise of large language models (LLMs) has revolutionized user interactions
with knowledge-based systems, enabling chatbots to synthesize vast amounts of
information and assist with complex, exploratory tasks. However, LLM-based
chatbots often struggle to provide personalized support, particularly when
users start with vague queries or lack sufficient contextual information. This
paper introduces the Collaborative Assistant for Personalized Exploration
(CARE), a system designed to enhance personalization in exploratory tasks by
combining a multi-agent LLM framework with a structured user interface. CARE's
interface consists of a Chat Panel, Solution Panel, and Needs Panel, enabling
iterative query refinement and dynamic solution generation. The multi-agent
framework collaborates to identify both explicit and implicit user needs,
delivering tailored, actionable solutions. In a within-subject user study with
22 participants, CARE was consistently preferred over a baseline LLM chatbot,
with users praising its ability to reduce cognitive load, inspire creativity,
and provide more tailored solutions. Our findings highlight CARE's potential to
transform LLM-based systems from passive information retrievers to proactive
partners in personalized problem-solving and exploration.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çèèµ·å¾¹åºæ¹è®äºä½¿ç¨èèåºæ¼ç¥è­çç³»çµ±äºåçæ¹å¼ï¼è®èå¤©æ©å¨äººè½å¤ ç¶åå¤§éçè³è¨ï¼ä¸¦åå©é²è¡è¤éçæ¢ç´¢æ§ä»»åãç¶èï¼åºæ¼ LLM çèå¤©æ©å¨äººéå¸¸é£ä»¥æä¾åäººåçæ¯æ´ï¼ç¹å¥æ¯å¨ä½¿ç¨èä¸éå§æåºçæ¥è©¢å¾æ¨¡ç³ï¼æç¼ºä¹è¶³å¤ çèçµ¡è³è¨æãæ¬æä»ç´¹äºåäººåæ¢ç´¢çåä½å©ç (CARE)ï¼ä¸åæ¨å¨ééçµåå¤éä»£ç LLM æ¶æ§èçµæ§åçä½¿ç¨èä»é¢ä¾å¢å¼·æ¢ç´¢æ§ä»»åä¸­åäººåçç³»çµ±ãCARE çä»é¢åå«èå¤©é¢æ¿ãè§£æ±ºæ¹æ¡é¢æ¿åéæ±é¢æ¿ï¼å¯é²è¡åè¦çæ¥è©¢ç²¾çååæçè§£æ±ºæ¹æ¡ç¢çãå¤éä»£çæ¶æ§åä½è­å¥æç¢ºåé±å«çä½¿ç¨èéæ±ï¼æä¾å®¢è£½åä¸å¯è¡çè§£æ±ºæ¹æ¡ãå¨ä¸åæ 22 ä½åèèçåè©¦èå§ç ç©¶ä¸­ï¼CARE æçºç²å¾æ¯åºæº LLM èå¤©æ©å¨äººæ´å¥½çè©å¹ï¼ä½¿ç¨èè®è³å¶æ¸è¼èªç¥è² æãæ¿ç¼åµé åï¼ä»¥åæä¾æ´å®¢è£½åè§£æ±ºæ¹æ¡çè½åãæåçç¼ç¾çªé¡¯äº CARE å°åºæ¼ LLM çç³»çµ±å¾è¢«åçè³è¨æª¢ç´¢èè½è®çºåäººååé¡è§£æ±ºåæ¢ç´¢ä¸­çä¸»åå¤¥ä¼´çæ½åã

##### **Neural Network Verification with PyRAT**
2410.23903v1 by Augustin Lemesle, Julien Lehmann, Tristan Le Gall

As AI systems are becoming more and more popular and used in various critical
domains (health, transport, energy, ...), the need to provide guarantees and
trust of their safety is undeniable. To this end, we present PyRAT, a tool
based on abstract interpretation to verify the safety and the robustness of
neural networks. In this paper, we describe the different abstractions used by
PyRAT to find the reachable states of a neural network starting from its input
as well as the main features of the tool to provide fast and accurate analysis
of neural networks. PyRAT has already been used in several collaborations to
ensure safety guarantees, with its second place at the VNN-Comp 2024 showcasing
its performance.

æè¦ï¼é¨è AI ç³»çµ±è¶ä¾è¶æ®åï¼ä¸¦ç¨æ¼åç¨®ééµé åï¼å¥åº·ãéè¼¸ãè½æºï¼...ï¼ï¼æä¾å¶å®å¨ä¿è­åä¿¡ä»»çéæ±æ¯ä¸å®¹å¦èªçãçºæ­¤ï¼æåæåºäº PyRATï¼ä¸ååºæ¼æ½è±¡è©®éçå·¥å·ï¼ç¨æ¼é©è­ç¥ç¶ç¶²è·¯çå®å¨æ§åç©©å¥æ§ãå¨æ¬æä¸­ï¼æåæè¿°äº PyRAT ç¨æ¼å¾ç¥ç¶ç¶²è·¯è¼¸å¥ä¸­æ¾åºå¯éçæçä¸åæ½è±¡ï¼ä»¥åè©²å·¥å·çä¸»è¦åè½ï¼ä»¥æä¾å¿«éä¸æºç¢ºçç¥ç¶ç¶²è·¯åæãPyRAT å·²å¨å¤é åä½ä¸­ç¨æ¼ç¢ºä¿å®å¨ä¿è­ï¼å¶å¨ VNN-Comp 2024 ä¸­ç²å¾ç¬¬äºåï¼å±ç¤ºäºå¶æè½ã

##### **Counterfactual MRI Data Augmentation using Conditional Denoising Diffusion Generative Models**
2410.23835v1 by Pedro MorÃ£o, Joao Santinha, Yasna Forghani, Nuno LouÃ§Ã£o, Pedro Gouveia, Mario A. T. Figueiredo

Deep learning (DL) models in medical imaging face challenges in
generalizability and robustness due to variations in image acquisition
parameters (IAP). In this work, we introduce a novel method using conditional
denoising diffusion generative models (cDDGMs) to generate counterfactual
magnetic resonance (MR) images that simulate different IAP without altering
patient anatomy. We demonstrate that using these counterfactual images for data
augmentation can improve segmentation accuracy, particularly in
out-of-distribution settings, enhancing the overall generalizability and
robustness of DL models across diverse imaging conditions. Our approach shows
promise in addressing domain and covariate shifts in medical imaging. The code
is publicly available at https:
//github.com/pedromorao/Counterfactual-MRI-Data-Augmentation

æè¦ï¼æ·±åº¦å­¸ç¿ (DL) æ¨¡åå¨é«å­¸å½±åä¸­æå å½±åæ·ååæ¸ (IAP) çè®åèé¢è¨å¯æ¦æ¬æ§åç©©å¥æ§çææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®ä½¿ç¨æ¢ä»¶å¼å»åªæ´æ£çææ¨¡å (cDDGMs) çæ°æ¹æ³ï¼ä»¥ç¢çåäºå¯¦ç£å±æ¯ (MR) å½±åï¼æ¨¡æ¬ä¸åç IAPï¼èä¸ææ¹è®æ£èçè§£åçµæ§ãæåè­æä½¿ç¨éäºåäºå¯¦å½±åé²è¡è³ææ´åå¯ä»¥æé«åå²æºç¢ºåº¦ï¼ç¹å¥æ¯å¨åä½å¤è¨­å®ä¸­ï¼å¢å¼· DL æ¨¡åå¨ä¸åå½±åæ¢ä»¶ä¸çæ´é«å¯æ¦æ¬æ§åç©©å¥æ§ãæåçåæ³é¡¯ç¤ºäºè§£æ±ºé«å­¸å½±åä¸­çé åååè®æ¸è½ç§»çåæ¯ãç¨å¼ç¢¼å·²å¬éæ¼ https:
//github.com/pedromorao/Counterfactual-MRI-Data-Augmentation

##### **Parameter-Efficient Fine-Tuning Medical Multimodal Large Language Models for Medical Visual Grounding**
2410.23822v1 by Jinlong He, Pengfei Li, Gang Liu, Shenjun Zhong

Multimodal Large Language Models (MLLMs) inherit the superior text
understanding capabilities of LLMs and extend these capabilities to multimodal
scenarios. These models achieve excellent results in the general domain of
multimodal tasks. However, in the medical domain, the substantial training
costs and the requirement for extensive medical data pose challenges to the
development of medical MLLMs. Furthermore, due to the free-text form of
answers, tasks such as visual grounding that need to produce output in a
prescribed form become difficult for MLLMs. So far, there have been no medical
MLLMs works in medical visual grounding area. For the medical vision grounding
task, which involves identifying locations in medical images based on short
text descriptions, we propose Parameter-efficient Fine-tuning medical
multimodal large language models for Medcial Visual Grounding (PFMVG). To
validate the performance of the model, we evaluate it on a public benchmark
dataset for medical visual grounding, where it achieves competitive results,
and significantly outperforming GPT-4v. Our code will be open sourced after
peer review.

æè¦ï¼å¤æ¨¡æå¤§åè¯­è¨æ¨¡å (MLLM) ç»§æ¿äº LLM ä¼è¶çææ¬çè§£è½åï¼å¹¶å°è¿äºè½åæ©å±å°å¤æ¨¡æåºæ¯ãè¿äºæ¨¡åå¨å¤æ¨¡æä»»å¡çéç¨é¢åä¸­åå¾äºåºè²çææãç¶èï¼å¨å»å­¦é¢åï¼å¤§éçè®­ç»ææ¬åå¯¹å¹¿æ³å»å­¦æ°æ®çéæ±å¯¹å»å­¦ MLLM çåå±ææäºææãæ­¤å¤ï¼ç±äºç­æ¡çèªç±ææ¬å½¢å¼ï¼éè¦ä»¥è§å®å½¢å¼çæè¾åºçä»»å¡ï¼ä¾å¦è§è§åºç¡ï¼å¯¹äº MLLM æ¥è¯´åå¾å°é¾ãå°ç®åä¸ºæ­¢ï¼è¿æ²¡æå»å­¦ MLLM å¨å»å­¦è§è§åºç¡é¢åå·¥ä½ãå¯¹äºå»å­¦è§è§åºç¡ä»»å¡ï¼å®æ¶åæ ¹æ®ç®ç­çææ¬æè¿°è¯å«å»å­¦å¾åä¸­çä½ç½®ï¼æä»¬æåºäºç¨äºå»å­¦è§è§åºç¡çåæ°é«æå¾®è°å»å­¦å¤æ¨¡æå¤§åè¯­è¨æ¨¡å (PFMVG)ãä¸ºäºéªè¯æ¨¡åçæ§è½ï¼æä»¬å¨å»å­¦è§è§åºç¡çå¬å±åºåæ°æ®éä¸å¯¹å¶è¿è¡äºè¯ä¼°ï¼å®åå¾äºæç«äºåçç»æï¼å¹¶ä¸ææ¾ä¼äº GPT-4vãæä»¬çä»£ç å°å¨åè¡è¯å®¡åå¼æºã

##### **Improving snore detection under limited dataset through harmonic/percussive source separation and convolutional neural networks**
2410.23796v1 by F. D. Gonzalez-Martinez, J. J. Carabias-Orti, F. J. Canadas-Quesada, N. Ruiz-Reyes, D. Martinez-Munoz, S. Garcia-Galan

Snoring, an acoustic biomarker commonly observed in individuals with
Obstructive Sleep Apnoea Syndrome (OSAS), holds significant potential for
diagnosing and monitoring this recognized clinical disorder. Irrespective of
snoring types, most snoring instances exhibit identifiable harmonic patterns
manifested through distinctive energy distributions over time. In this work, we
propose a novel method to differentiate monaural snoring from non-snoring
sounds by analyzing the harmonic content of the input sound using
harmonic/percussive sound source separation (HPSS). The resulting feature,
based on the harmonic spectrogram from HPSS, is employed as input data for
conventional neural network architectures, aiming to enhance snoring detection
performance even under a limited data learning framework. To evaluate the
performance of our proposal, we studied two different scenarios: 1) using a
large dataset of snoring and interfering sounds, and 2) using a reduced
training set composed of around 1% of the data material. In the former
scenario, the proposed HPSS-based feature provides competitive results compared
to other input features from the literature. However, the key advantage of the
proposed method lies in the superior performance of the harmonic spectrogram
derived from HPSS in a limited data learning context. In this particular
scenario, using the proposed harmonic feature significantly enhances the
performance of all the studied architectures in comparison to the classical
input features documented in the existing literature. This finding clearly
demonstrates that incorporating harmonic content enables more reliable learning
of the essential time-frequency characteristics that are prevalent in most
snoring sounds, even in scenarios where the amount of training data is limited.

æè¦ï¼é¼¾è²æ¯ä¸ç¨®å¨é»å¡æ§ç¡ç å¼å¸ä¸­æ­¢çåç¾¤ (OSAS) æ£èä¸­å¸¸è¦çè²å­¸çç©æ¨è¨ï¼å°æ¼è¨ºæ·åç£æ§æ­¤å¬èªçè¨åºç¾çå·æé¡¯èæ½åãç¡è«é¼¾è²é¡åå¦ä½ï¼å¤§å¤æ¸é¼¾è²é½è¡¨ç¾åºå¯è­å¥çè«§æ³¢æ¨¡å¼ï¼ä¸¦é¨èæéæ¨ç§»è¡¨ç¾åºç¨ç¹çè½éåä½ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°æ¹æ³ï¼ééä½¿ç¨è«§æ³¢/ææè²æºåé¢ (HPSS) åæè¼¸å¥è²é³çè«§æ³¢å§å®¹ï¼å°å®è²éé¼¾è²èéé¼¾è²ååéä¾ãåºæ¼ HPSS çè«§æ³¢é »è­åæç¢ççç¹å¾µï¼è¢«ç¨ä½å³çµ±ç¥ç¶ç¶²è·¯æ¶æ§çè¼¸å¥è³æï¼æ¨å¨å³ä½¿å¨æéè³æå­¸ç¿æ¶æ§ä¸ä¹è½å¢å¼·é¼¾è²åµæ¸¬æè½ãçºäºè©ä¼°æåææ¡çæè½ï¼æåç ç©¶äºå©ç¨®ä¸åçæå¢ï¼1) ä½¿ç¨å¤§éçé¼¾è²åå¹²æ¾è²è³æéï¼ä»¥å 2) ä½¿ç¨ç±ç´ 1% è³æç´ æçµæçç¸®æ¸è¨ç·´éãå¨åä¸ç¨®æå¢ä¸­ï¼èæç»ä¸­çå¶ä»è¼¸å¥ç¹å¾µç¸æ¯ï¼ææåºçåºæ¼ HPSS çç¹å¾µæä¾äºå·æç«¶ç­åççµæãç¶èï¼ææåºæ¹æ³çä¸»è¦åªé»å¨æ¼ï¼å¨æéè³æå­¸ç¿æå¢ä¸­ï¼æºèª HPSS çè«§æ³¢é »è­åå·æåªç°çæè½ãå¨éåç¹å®æå¢ä¸­ï¼èç¾ææç»ä¸­è¨è¼çå³çµ±è¼¸å¥ç¹å¾µç¸æ¯ï¼ä½¿ç¨ææåºçè«§æ³¢ç¹å¾µé¡¯èå¢å¼·äºææç ç©¶æ¶æ§çæè½ãéä¸ç¼ç¾æ¸æ¥å°è¡¨æï¼å³ä½¿å¨è¨ç·´è³æéæéçæå¢ä¸­ï¼ç´å¥è«§æ³¢å§å®¹ä¹è½å¤ æ´å¯é å°å­¸ç¿å¤§å¤æ¸é¼¾è²ä¸­æ®éå­å¨çå¿è¦æé »ç¹å¾µã

##### **The Potential of LLMs in Medical Education: Generating Questions and Answers for Qualification Exams**
2410.23769v1 by Yunqi Zhu, Wen Tang, Ying Sun, Xuebing Yang

Recent research on large language models (LLMs) has primarily focused on
their adaptation and application in specialized domains. The application of
LLMs in the medical field is mainly concentrated on tasks such as the
automation of medical report generation, summarization, diagnostic reasoning,
and question-and-answer interactions between doctors and patients. The
challenge of becoming a good teacher is more formidable than that of becoming a
good student, and this study pioneers the application of LLMs in the field of
medical education. In this work, we investigate the extent to which LLMs can
generate medical qualification exam questions and corresponding answers based
on few-shot prompts. Utilizing a real-world Chinese dataset of elderly chronic
diseases, we tasked the LLMs with generating open-ended questions and answers
based on a subset of sampled admission reports across eight widely used LLMs,
including ERNIE 4, ChatGLM 4, Doubao, Hunyuan, Spark 4, Qwen, Llama 3, and
Mistral. Furthermore, we engaged medical experts to manually evaluate these
open-ended questions and answers across multiple dimensions. The study found
that LLMs, after using few-shot prompts, can effectively mimic real-world
medical qualification exam questions, whereas there is room for improvement in
the correctness, evidence-based statements, and professionalism of the
generated answers. Moreover, LLMs also demonstrate a decent level of ability to
correct and rectify reference answers. Given the immense potential of
artificial intelligence in the medical field, the task of generating questions
and answers for medical qualification exams aimed at medical students, interns
and residents can be a significant focus of future research.

æè¦ï¼<paragraph>éå°å¤§åèªè¨æ¨¡å (LLM) çè¿æç ç©¶ä¸»è¦éä¸­å¨å®åå¨ç¹å®é åçé©æåæç¨ãLLM å¨é«å­¸é åçæç¨ä¸»è¦éä¸­å¨èªååçæ­·ç¢çãæè¦ãè¨ºæ·æ¨çä»¥åé«çèçäººä¹éåç­äºåç­ä»»åãæçºä¸åå¥½èå¸«çææ°æ¯æçºä¸åå¥½å­¸çæ´è±éï¼èæ¬ç ç©¶éåµäº LLM å¨é«å­¸æè²é åçæç¨ãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äº LLM å¨å°æ¸æç¤ºä¸ç¢çé«å­¸è³æ ¼èè©¦é¡ç®åå°æç­æ¡çç¨åº¦ãå©ç¨ä¸åçå¯¦ä¸ççèå¹´æ¢æ§ç¾çä¸­ææ¸æéï¼æåè® LLM æ ¹æå«åå»£æ³ä½¿ç¨ç LLMï¼åæ¬ ERNIE 4ãChatGLM 4ãè±åãæ··åãSpark 4ãQwenãLlama 3 å Mistralï¼æ½åçå¥é¢å ±åå­éç¢çéæ¾å¼åé¡åç­æ¡ãæ­¤å¤ï¼æåèè«é«å­¸å°å®¶æåè©ä¼°éäºéæ¾å¼åé¡åç­æ¡çå¤åé¢åãç ç©¶ç¼ç¾ï¼LLM å¨ä½¿ç¨å°æ¸æç¤ºå¾ï¼å¯ä»¥æææ¨¡æ¬çå¯¦ä¸ççé«å­¸è³æ ¼èè©¦é¡ç®ï¼èç¢ççç­æ¡å¨æ­£ç¢ºæ§ãå¾ªè­é³è¿°åå°æ¥­æ§æ¹é¢ä»ææ¹é²ç©ºéãæ­¤å¤ï¼LLM ä¹å±ç¾åºç¸ç¶ç¨åº¦æ´æ­£åä¿®æ­£åèç­æ¡çè½åãéæ¼äººå·¥æºè½å¨é«å­¸é åçå·¨å¤§æ½åï¼ç¢çéå°é«å­¸çãå¯¦ç¿é«çåä½é¢é«ççé«å­¸è³æ ¼èè©¦é¡ç®åç­æ¡çä»»åï¼å¯ä»¥æçºæªä¾ç ç©¶çéè¦éé»ã</paragraph>

##### **Artificial intelligence to improve clinical coding practice in Scandinavia: a crossover randomized controlled trial**
2410.23725v1 by Taridzo Chomutare, Therese Olsen Svenning, Miguel Ãngel Tejedor HernÃ¡ndez, Phuong Dinh Ngo, Andrius Budrionis, Kaisa Markljung, Lill Irene Hind, TorbjÃ¸rn Torsvik, Karl Ãyvind Mikalsen, Aleksandar Babic, Hercules Dalianis

\textbf{Trial design} Crossover randomized controlled trial. \textbf{Methods}
An AI tool, Easy-ICD, was developed to assist clinical coders and was tested
for improving both accuracy and time in a user study in Norway and Sweden.
Participants were randomly assigned to two groups, and crossed over between
coding complex (longer) texts versus simple (shorter) texts, while using our
tool versus not using our tool. \textbf{Results} Based on Mann-Whitney U test,
the median coding time difference for complex clinical text sequences was 123
seconds (\emph{P}\textless.001, 95\% CI: 81 to 164), representing a 46\%
reduction in median coding time when our tool is used. There was no significant
time difference for simpler text sequences. For coding accuracy, the
improvement we noted for both complex and simple texts was not significant.
\textbf{Conclusions} This study demonstrates the potential of AI to transform
common tasks in clinical workflows, with ostensible positive impacts on work
efficiencies for complex clinical coding tasks. Further studies within hospital
workflows are required before these presumed impacts can be more clearly
understood.

æè¦ï¼**è©¦é©è¨­è¨** äº¤åé¨æ©å°ç§è©¦é©ã**æ¹æ³**éç¼äºä¸ç¨® AI å·¥å· Easy-ICDï¼ä»¥åå©è¨åºç·¨ç¢¼å¡ï¼ä¸¦å¨æªå¨åçå¸é²è¡çä¸é ä½¿ç¨èç ç©¶ä¸­æ¸¬è©¦å¶å¨æºç¢ºæ§åæéä¸çæ¹é²ãåèèè¢«é¨æ©åçºå©çµï¼ä¸¦å¨ä½¿ç¨æåçå·¥å·èä¸ä½¿ç¨æåçå·¥å·çææ³ä¸ï¼å°è¤éï¼è¼é·ï¼ææ¬èç°¡å®ï¼è¼ç­ï¼ææ¬é²è¡ç·¨ç¢¼äº¤åã**çµæ**æ ¹æ Mann-Whitney U æª¢å®ï¼è¤éè¨åºææ¬åºåçä¸­ä½æ¸ç·¨ç¢¼æéå·®çº 123 ç§ï¼\emph{P}\textless.001ï¼95% CIï¼81 è³ 164ï¼ï¼è¡¨ç¤ºä½¿ç¨æåçå·¥å·æä¸­ä½æ¸ç·¨ç¢¼æéæ¸å°äº 46%ãå°æ¼è¼ç°¡å®çææ¬åºåï¼æ²æé¡¯èçæéå·®ç°ãå°æ¼ç·¨ç¢¼æºç¢ºæ§ï¼æåå°è¤éææ¬åç°¡å®ææ¬æè§å¯å°çæ¹é²ä¸¦ä¸é¡¯èã**çµè«**éé ç ç©¶å±ç¤ºäº AI å¨è½æè¨åºå·¥ä½æµç¨ä¸­å¸¸è¦ä»»åçæ½åï¼å°è¤éè¨åºç·¨ç¢¼ä»»åçå·¥ä½æçææé¡¯çæ­£é¢å½±é¿ãå¨éäºåè¨­å½±é¿è½æ´æ¸æ¥å°è¢«çè§£ä¹åï¼éè¦å¨é«é¢å·¥ä½æµç¨ä¸­é²è¡é²ä¸æ­¥çç ç©¶ã

##### **Enhancing Brain Tumor Classification Using TrAdaBoost and Multi-Classifier Deep Learning Approaches**
2411.00875v1 by Mahin Mohammadi, Saman Jamshidi

Brain tumors pose a serious health threat due to their rapid growth and
potential for metastasis. While medical imaging has advanced significantly,
accurately identifying and characterizing these tumors remains a challenge.
This study addresses this challenge by leveraging the innovative TrAdaBoost
methodology to enhance the Brain Tumor Segmentation (BraTS2020) dataset, aiming
to improve the efficiency and accuracy of brain tumor classification. Our
approach combines state-of-the-art deep learning algorithms, including the
Vision Transformer (ViT), Capsule Neural Network (CapsNet), and convolutional
neural networks (CNNs) such as ResNet-152 and VGG16. By integrating these
models within a multi-classifier framework, we harness the strengths of each
approach to achieve more robust and reliable tumor classification. A novel
decision template is employed to synergistically combine outputs from different
algorithms, further enhancing classification accuracy. To augment the training
process, we incorporate a secondary dataset, "Brain Tumor MRI Dataset," as a
source domain, providing additional data for model training and improving
generalization capabilities. Our findings demonstrate a high accuracy rate in
classifying tumor versus non-tumor images, signifying the effectiveness of our
approach in the medical imaging domain. This study highlights the potential of
advanced machine learning techniques to contribute significantly to the early
and accurate diagnosis of brain tumors, ultimately improving patient outcomes.

æè¦ï¼è¦ç¤ç±æ¼çé·å¿«éä¸æè½ç§»çå¯è½æ§ï¼å°å¥åº·æ§æå´éå¨èãéç¶é«å­¸å½±åæè¡å·²å¤§å¹é²æ­¥ï¼ä½ç²¾æºè¾¨è­åæè¿°éäºè«ç¤ä»ç¶æ¯ä¸å¤§ææ°ãæ¬ç ç©¶éééç¨åµæ°ç TrAdaBoost æ¹æ³æåè¦ç¤åå² (BraTS2020) è³æéä¾è§£æ±ºéåææ°ï¼ç®æ¨æ¯æåè¦ç¤åé¡çæçåæºç¢ºåº¦ãæåçåæ³çµåäºæåé²çæ·±åº¦å­¸ç¿æ¼ç®æ³ï¼åæ¬è¦è¦ºè½æå¨ (ViT)ãè åç¥ç¶ç¶²è·¯ (CapsNet) åå·ç©ç¥ç¶ç¶²è·¯ (CNN)ï¼ä¾å¦ ResNet-152 å VGG16ãééå¨å¤åé¡å¨æ¶æ§ä¸­æ´åéäºæ¨¡åï¼æåå©ç¨æ¯ç¨®æ¹æ³çåªé»ä¾éææ´å¼·å¥ä¸å¯é çè«ç¤åé¡ãæ¡ç¨æ°ç©çæ±ºç­ç¯æ¬ï¼ä»¥ç¶æçµåä¸åæ¼ç®æ³çè¼¸åºï¼é²ä¸æ­¥æååé¡æºç¢ºåº¦ãçºäºæ´åè¨ç·´æµç¨ï¼æåç´å¥æ¬¡è¦è³æéãè¦ç¤ MRI è³æéãä½çºä¾æºç¶²åï¼æä¾é¡å¤çè³æç¨æ¼æ¨¡åè¨ç·´ï¼ä¸¦æåæ¦åè½åãæåçç ç©¶çµæé¡¯ç¤ºï¼å¨åé¡è«ç¤èéè«ç¤å½±åæï¼æºç¢ºçå¾é«ï¼è¡¨ç¤ºæåçæ¹æ³å¨é«å­¸å½±åé åä¸­å¾ææãæ¬ç ç©¶å¼·èª¿é²éæ©å¨å­¸ç¿æè¡çæ½åï¼å°è¦ç¤çæ©æä¸ç²¾æºè¨ºæ·æé¡¯èè²¢ç»ï¼é²èæ¹åçæ£çæ²»ççµæã

##### **Deep Convolutional Neural Networks on Multiclass Classification of Three-Dimensional Brain Images for Parkinson's Disease Stage Prediction**
2410.23649v1 by Guan-Hua Huang, Wan-Chen Lai, Tai-Been Chen, Chien-Chin Hsu, Huei-Yung Chen, Yi-Chen Wu, Li-Ren Yeh

Parkinson's disease (PD), a degenerative disorder of the central nervous
system, is commonly diagnosed using functional medical imaging techniques such
as single-photon emission computed tomography (SPECT). In this study, we
utilized two SPECT data sets (n = 634 and n = 202) from different hospitals to
develop a model capable of accurately predicting PD stages, a multiclass
classification task. We used the entire three-dimensional (3D) brain images as
input and experimented with various model architectures. Initially, we treated
the 3D images as sequences of two-dimensional (2D) slices and fed them
sequentially into 2D convolutional neural network (CNN) models pretrained on
ImageNet, averaging the outputs to obtain the final predicted stage. We also
applied 3D CNN models pretrained on Kinetics-400. Additionally, we incorporated
an attention mechanism to account for the varying importance of different
slices in the prediction process. To further enhance model efficacy and
robustness, we simultaneously trained the two data sets using weight sharing, a
technique known as cotraining. Our results demonstrated that 2D models
pretrained on ImageNet outperformed 3D models pretrained on Kinetics-400, and
models utilizing the attention mechanism outperformed both 2D and 3D models.
The cotraining technique proved effective in improving model performance when
the cotraining data sets were sufficiently large.

æè¦ï¼å¸éæ£®æ°ç (PD) æ¯ä¸ç¨®ä¸­æ¨ç¥ç¶ç³»çµ±éåæ§ç¾çï¼éå¸¸ä½¿ç¨åè½æ§é«å­¸å½±åæè¡ï¼ä¾å¦å®åå­ç¼å°æ·å±¤ææ (SPECT) ä¾è¨ºæ·ãå¨éé ç ç©¶ä¸­ï¼æåå©ç¨ä¾èªä¸åé«é¢çå©å SPECT è³æé (n = 634 å n = 202) ä¾éç¼ä¸åæ¨¡åï¼è½å¤ æºç¢ºé æ¸¬ PD åæï¼éæ¯ä¸åå¤é¡å¥åé¡ä»»åãæåä½¿ç¨æ´åä¸ç¶­ (3D) å¤§è¦å½±åä½çºè¼¸å¥ï¼ä¸¦åè©¦ä½¿ç¨åç¨®æ¨¡åæ¶æ§ãæåï¼æåå° 3D å½±åè¦çºäºç¶­ (2D) åççåºåï¼ä¸¦å°å®åä¾åºè¼¸å¥å°é åå¨ ImageNet ä¸è¨ç·´éç 2D å·ç©ç¥ç¶ç¶²è·¯ (CNN) æ¨¡åä¸­ï¼åå¹³åè¼¸åºå¼ä¾åå¾æçµé æ¸¬çæå¥ãæåä¹æç¨é åå¨ Kinetics-400 ä¸è¨ç·´éç 3D CNN æ¨¡åãæ­¤å¤ï¼æåç´å¥ä¸åæ³¨æåæ©å¶ï¼ä»¥èéä¸ååçå¨é æ¸¬éç¨ä¸­çéè¦æ§å·®ç°ãçºäºé²ä¸æ­¥å¢å¼·æ¨¡åçæè½åç©©å¥æ§ï¼æåä½¿ç¨æ¬éå±äº«åæè¨ç·´å©åè³æéï¼éæ¯ä¸ç¨®ç¨±çºå±åè¨ç·´çæè¡ãæåççµæé¡¯ç¤ºï¼é åå¨ ImageNet ä¸è¨ç·´éç 2D æ¨¡ååªæ¼é åå¨ Kinetics-400 ä¸è¨ç·´éç 3D æ¨¡åï¼èä½¿ç¨æ³¨æåæ©å¶çæ¨¡åååªæ¼ 2D å 3D æ¨¡åãç¶å±åè¨ç·´çè³æéå¤ å¤§çæåï¼å±åè¨ç·´æè¡å·²è¢«è­æè½æææ¹åæ¨¡åæè½ã

##### **MS-Glance: Non-semantic context vectors and the applications in supervising image reconstruction**
2410.23577v1 by Ziqi Gao, Wendi Yang, Yujia Li, Lei Xing, S. Kevin Zhou

Non-semantic context information is crucial for visual recognition, as the
human visual perception system first uses global statistics to process scenes
rapidly before identifying specific objects. However, while semantic
information is increasingly incorporated into computer vision tasks such as
image reconstruction, non-semantic information, such as global spatial
structures, is often overlooked. To bridge the gap, we propose a biologically
informed non-semantic context descriptor, \textbf{MS-Glance}, along with the
Glance Index Measure for comparing two images. A Global Glance vector is
formulated by randomly retrieving pixels based on a perception-driven rule from
an image to form a vector representing non-semantic global context, while a
local Glance vector is a flattened local image window, mimicking a zoom-in
observation. The Glance Index is defined as the inner product of two
standardized sets of Glance vectors. We evaluate the effectiveness of
incorporating Glance supervision in two reconstruction tasks: image fitting
with implicit neural representation (INR) and undersampled MRI reconstruction.
Extensive experimental results show that MS-Glance outperforms existing image
restoration losses across both natural and medical images. The code is
available at \url{https://github.com/Z7Gao/MSGlance}.

æè¦ï¼éè¯­ä¹ä¸ä¸æä¿¡æ¯å¯¹äºè§è§è¯å«è³å³éè¦ï¼å ä¸ºäººç±»è§è§æç¥ç³»ç»é¦åä½¿ç¨å¨å±ç»è®¡æ°æ®æ¥å¿«éå¤çåºæ¯ï¼ç¶ååè¯å«ç¹å®å¯¹è±¡ãç¶èï¼è½ç¶è¯­ä¹ä¿¡æ¯æ­£è¶æ¥è¶å¤å°èå¥å°å¾åéå»ºç­è®¡ç®æºè§è§ä»»å¡ä¸­ï¼ä½éè¯­ä¹ä¿¡æ¯ï¼å¦å¨å±ç©ºé´ç»æï¼å´å¸¸å¸¸è¢«å¿½è§ãä¸ºäºå¼¥åè¿ä¸å·®è·ï¼æä»¬æåºäºä¸ä¸ªçç©ä¿¡æ¯å¯åçéè¯­ä¹ä¸ä¸ææè¿°ç¬¦ï¼å³ \textbf{MS-Glance}ï¼ä»¥åç¨äºæ¯è¾ä¸¤å¹å¾åç Glance ææ°åº¦éãéè¿æ ¹æ®æç¥é©±å¨çè§åä»å¾åä¸­éæºæ£ç´¢åç´ æ¥æå»ºä¸ä¸ªå¨å± Glance åéï¼ä»¥å½¢æä¸ä¸ªè¡¨ç¤ºéè¯­ä¹å¨å±ä¸ä¸æçåéï¼èå±é¨ Glance åéæ¯ä¸ä¸ªæå¹³çå±é¨å¾åçªå£ï¼æ¨¡ä»¿äºæ¾å¤§è§å¯ãGlance ææ°è¢«å®ä¹ä¸ºä¸¤ç»æ ååç Glance åéçåç§¯ãæä»¬è¯ä¼°äºå¨ä¸¤ä¸ªéå»ºä»»å¡ä¸­çº³å¥ Glance çç£çæææ§ï¼å·æéå¼ç¥ç»è¡¨å¾ (INR) çå¾åæååæ¬ éæ · MRI éå»ºãå¤§éçå®éªç»æè¡¨æï¼MS-Glance å¨èªç¶å¾ååå»å­¦å¾åä¸­é½ä¼äºç°æçå¾åæ¢å¤æå¤±ãä»£ç å¯å¨ \url{https://github.com/Z7Gao/MSGlance} è·å¾ã

##### **LEAF: Learning and Evaluation Augmented by Fact-Checking to Improve Factualness in Large Language Models**
2410.23526v1 by Hieu Tran, Junda Wang, Yujan Ting, Weijing Huang, Terrence Chen

Large language models (LLMs) have shown remarkable capabilities in various
natural language processing tasks, yet they often struggle with maintaining
factual accuracy, particularly in knowledge-intensive domains like healthcare.
This study introduces LEAF: Learning and Evaluation Augmented by Fact-Checking,
a novel approach designed to enhance the factual reliability of LLMs, with a
focus on medical question answering (QA). LEAF utilizes a dual strategy to
enhance the factual accuracy of responses from models such as Llama 3 70B
Instruct and Llama 3 8B Instruct. The first strategy, Fact-Check-Then-RAG,
improves Retrieval-Augmented Generation (RAG) by incorporating fact-checking
results to guide the retrieval process without updating model parameters. The
second strategy, Learning from Fact-Checks via Self-Training, involves
supervised fine-tuning (SFT) on fact-checked responses or applying Simple
Preference Optimization (SimPO) with fact-checking as a ranking mechanism, both
updating LLM parameters from supervision. These findings suggest that
integrating fact-checked responses whether through RAG enhancement or
self-training enhances the reliability and factual correctness of LLM outputs,
offering a promising solution for applications where information accuracy is
crucial.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®èªç¶èªè¨èçä»»åä¸­å±ç¾åºåè¶çè½åï¼ç¶èå®åå¨ç¶­æäºå¯¦æºç¢ºæ§æ¹é¢å¸¸å¸¸é¢è¨å°é£ï¼ç¹å¥æ¯å¨åé«çä¿å¥éæ¨£çç¥è­å¯éé åãæ¬ç ç©¶å¼å¥äº LEAFï¼ééäºå¯¦æ¥æ ¸å¢å¼·çå­¸ç¿èè©ä¼°ï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼æ¨å¨æå LLM çäºå¯¦å¯é æ§ï¼ä¸¦å°æ³¨æ¼é«çåé¡è§£ç­ (QA)ãLEAF å©ç¨ééç­ç¥ä¾æå LLM åæçäºå¯¦æºç¢ºæ§ï¼ä¾å¦ Llama 3 70B Instruct å Llama 3 8B Instructãç¬¬ä¸ç¨®ç­ç¥ Fact-Check-Then-RAGï¼ééæ´åäºå¯¦æ¥æ ¸çµæä¾æ¹é²æª¢ç´¢å¢å¼·çæ (RAG)ï¼ä»¥å¼å°æª¢ç´¢ç¨åºï¼èä¸ææ´æ°æ¨¡ååæ¸ãç¬¬äºç¨®ç­ç¥ééèªæè¨ç·´å­¸ç¿äºå¯¦æ¥æ ¸ï¼æ¶åéå°ç¶éäºå¯¦æ¥æ ¸çåæé²è¡ç£ç£å¾®èª¿ (SFT)ï¼æå°ç°¡å®åå¥½æä½³å (SimPO) æç¨æ¼äºå¯¦æ¥æ ¸ä½çºæåæ©å¶ï¼éå©ç¨®æ¹æ³é½æå¾ç£ç£ä¸­æ´æ° LLM åæ¸ãéäºç¼ç¾è¡¨æï¼ç¡è«æ¯éé RAG å¢å¼·æèªæè¨ç·´ï¼æ´åç¶éäºå¯¦æ¥æ ¸çåæï¼é½è½æå LLM è¼¸åºçå¯é æ§åäºå¯¦æ­£ç¢ºæ§ï¼çºè³è¨æºç¢ºæ§è³ééè¦çæç¨ç¨å¼æä¾äºä¸åæåæ¯çè§£æ±ºæ¹æ¡ã

##### **Emory Knee Radiograph (MRKR) Dataset**
2411.00866v1 by Brandon Price, Jason Adleberg, Kaesha Thomas, Zach Zaiman, Aawez Mansuri, Beatrice Brown-Mulry, Chima Okecheukwu, Judy Gichoya, Hari Trivedi

The Emory Knee Radiograph (MRKR) dataset is a large, demographically diverse
collection of 503,261 knee radiographs from 83,011 patients, 40% of which are
African American. This dataset provides imaging data in DICOM format along with
detailed clinical information, including patient-reported pain scores,
diagnostic codes, and procedural codes, which are not commonly available in
similar datasets. The MRKR dataset also features imaging metadata such as image
laterality, view type, and presence of hardware, enhancing its value for
research and model development. MRKR addresses significant gaps in existing
datasets by offering a more representative sample for studying osteoarthritis
and related outcomes, particularly among minority populations, thereby
providing a valuable resource for clinicians and researchers.

æè¦ï¼åé»éèé¨ X åç (MRKR) è³æéæ¯ä¸åé¾å¤§ãäººå£çµ±è¨è³æå¤åçè³æéï¼åå«ä¾èª 83,011 åæ£èç 503,261 å¼µèé¨ X åçï¼å¶ä¸­ 40% çºéè£ç¾åäººãæ­¤è³æéæä¾ DICOM æ ¼å¼çå½±åè³æï¼ä»¥åè©³ç´°çè¨åºè³è¨ï¼åæ¬æ£èåå ±çç¼çè©åãè¨ºæ·ç¢¼åç¨åºç¢¼ï¼éäºè³æå¨é¡ä¼¼çè³æéä¸­ä¸¦ä¸å¸¸è¦ãMRKR è³æéä¹åå«å½±åçå¾è¨­è³æï¼ä¾å¦å½±åçå·¦å³å´ãæª¢è¦é¡ååç¡¬é«çå­å¨ï¼æåå¶å¨ç ç©¶åæ¨¡åéç¼æ¹é¢çå¹å¼ãMRKR ééæä¾æ´å·ä»£è¡¨æ§çæ¨£æ¬ï¼ä¾æ¢è¨éª¨éç¯çåç¸éçµæï¼ç¹å¥æ¯å¨å°æ¸æç¾¤ä¸­ï¼å¾èå¡«è£ç¾æè³æéä¸­é¡¯èçç¼ºå£ï¼çºè¨åºé«çåç ç©¶äººå¡æä¾æå¹å¼çè³æºã

##### **STIED: A deep learning model for the SpatioTemporal detection of focal Interictal Epileptiform Discharges with MEG**
2410.23386v1 by Raquel FernÃ¡ndez-MartÃ­n, Alfonso GijÃ³n, Odile Feys, Elodie JuvenÃ©, Alec Aeby, Charline Urbain, Xavier De TiÃ¨ge, Vincent Wens

Magnetoencephalography (MEG) allows the non-invasive detection of interictal
epileptiform discharges (IEDs). Clinical MEG analysis in epileptic patients
traditionally relies on the visual identification of IEDs, which is time
consuming and partially subjective. Automatic, data-driven detection methods
exist but show limited performance. Still, the rise of deep learning (DL)-with
its ability to reproduce human-like abilities-could revolutionize clinical MEG
practice. Here, we developed and validated STIED, a simple yet powerful
supervised DL algorithm combining two convolutional neural networks with
temporal (1D time-course) and spatial (2D topography) features of MEG signals
inspired from current clinical guidelines. Our DL model enabled both temporal
and spatial localization of IEDs in patients suffering from focal epilepsy with
frequent and high amplitude spikes (FE group), with high-performance
metrics-accuracy, specificity, and sensitivity all exceeding 85%-when learning
from spatiotemporal features of IEDs. This performance can be attributed to our
handling of input data, which mimics established clinical MEG practice. Reverse
engineering further revealed that STIED encodes fine spatiotemporal features of
IEDs rather than their mere amplitude. The model trained on the FE group also
showed promising results when applied to a separate group of presurgical
patients with different types of refractory focal epilepsy, though further work
is needed to distinguish IEDs from physiological transients. This study paves
the way of incorporating STIED and DL algorithms into the routine clinical MEG
evaluation of epilepsy.

æè¦ï¼è¦ç£åï¼MEGï¼åè¨±å°ç¼ä½éæç²çæ¨£æ¾é»ï¼IEDï¼é²è¡éä¾µå¥æ§æª¢æ¸¬ãç²çæ£èçè¨åº MEG åæå³çµ±ä¸ä¾è³´æ¼ IED çè¦è¦ºè­å¥ï¼éæ¢èæåé¨åä¸»è§ãèªååãæ¸æé©åçæª¢æ¸¬æ¹æ³å­å¨ï¼ä½é¡¯ç¤ºæ§è½æéãåç®¡å¦æ­¤ï¼æ·±åº¦å­¸ç¿ (DL) çèèµ·ââå®å·æè¤è£½é¡äººè½åçè½åââå¯ä»¥å¾¹åºæ¹è®è¨åº MEG å¯¦è¸ãå¨éè£¡ï¼æåéç¼ä¸¦é©è­äº STIEDï¼éæ¯ä¸ç¨®ç°¡å®ä½å¼·å¤§çç£ç£å¼ DL æ¼ç®æ³ï¼å®çµåäºå©åå·ç©ç¥ç¶ç¶²è·¯ï¼å·æ MEG è¨èçæéï¼1D æééç¨ï¼åç©ºéï¼2D å°å½¢ï¼ç¹å¾µï¼éæä¾èªç¶åçè¨åºæåãæåç DL æ¨¡åè½å¤ å°æ£æå±ç¶æ§ç²çä¸å°å³°é »ç¹ä¸æ¯å¹é«çæ£èï¼FE çµï¼ä¸­ç IED é²è¡æéåç©ºéå®ä½ï¼ä¸¦å·æé«æ§è½ææ¨ââæºç¢ºåº¦ãç¹ç°æ§åæææ§åè¶é 85%ââå¾ IED çæç©ºç¹å¾µä¸­å­¸ç¿ãéç¨®æ§è½å¯ä»¥æ­¸å æ¼æåå°è¼¸å¥è³æçèçï¼å®æ¨¡æ¬äºæ¢å®çè¨åº MEG å¯¦åãéåå·¥ç¨é²ä¸æ­¥æ­ç¤º STIED ç·¨ç¢¼äº IED çç²¾ç´°æç©ºç¹å¾µï¼èä¸æ¯å®åçå®ç´æ¯å¹ãå¨ FE çµä¸è¨ç·´çæ¨¡åå¨æç¨æ¼å¦ä¸çµæ£æä¸åé¡åé£æ²»æ§å±ç¶æ§ç²ççè¡åæ£èæä¹é¡¯ç¤ºåºæå¸æççµæï¼åç®¡éè¦é²ä¸æ­¥çå·¥ä½ä¾åå IED åççæ§æ«æãéé ç ç©¶çºå° STIED å DL æ¼ç®æ³ç´å¥ç²ççå¸¸è¦è¨åº MEG è©ä¼°éªå¹³äºéè·¯ã

##### **Larger models yield better results? Streamlined severity classification of ADHD-related concerns using BERT-based knowledge distillation**
2411.00052v1 by Ahmed Akib Jawad Karim, Kazi Hafiz Md. Asad, Md. Golam Rabiul Alam

This work focuses on the efficiency of the knowledge distillation approach in
generating a lightweight yet powerful BERT based model for natural language
processing applications. After the model creation, we applied the resulting
model, LastBERT, to a real-world task classifying severity levels of Attention
Deficit Hyperactivity Disorder (ADHD)-related concerns from social media text
data. Referring to LastBERT, a customized student BERT model, we significantly
lowered model parameters from 110 million BERT base to 29 million, resulting in
a model approximately 73.64% smaller. On the GLUE benchmark, comprising
paraphrase identification, sentiment analysis, and text classification, the
student model maintained strong performance across many tasks despite this
reduction. The model was also used on a real-world ADHD dataset with an
accuracy and F1 score of 85%. When compared to DistilBERT (66M) and
ClinicalBERT (110M), LastBERT demonstrated comparable performance, with
DistilBERT slightly outperforming it at 87%, and ClinicalBERT achieving 86%
across the same metrics. These findings highlight the LastBERT model's capacity
to classify degrees of ADHD severity properly, so it offers a useful tool for
mental health professionals to assess and comprehend material produced by users
on social networking platforms. The study emphasizes the possibilities of
knowledge distillation to produce effective models fit for use in
resource-limited conditions, hence advancing NLP and mental health diagnosis.
Furthermore underlined by the considerable decrease in model size without
appreciable performance loss is the lower computational resources needed for
training and deployment, hence facilitating greater applicability. Especially
using readily available computational tools like Google Colab. This study shows
the accessibility and usefulness of advanced NLP methods in pragmatic world
applications.

æè¦ï¼<paragraph>æ¬ç ç©¶éé»å¨æ¼ç¥è­èåæ¹æ³å¨ç¢çè¼éç´ä¸å¼·å¤§çåºæ¼ BERT çæ¨¡åä»¥ç¨æ¼èªç¶èªè¨èçæç¨æ¹é¢çæçãå¨æ¨¡åå»ºç«å¾ï¼æåå°ç¢ççæ¨¡å LastBERT æç¨æ¼ä¸åçå¯¦ä¸ççä»»åï¼å³å¾ç¤¾ç¾¤åªé«æå­è³æä¸­åé¡æ³¨æåä¸è¶³éåç (ADHD) ç¸éåé¡çå´éç¨åº¦å±¤ç´ãæå° LastBERTï¼ä¸åå®¢è£½åçå­¸ç BERT æ¨¡åï¼æåå¤§å¹éä½äºæ¨¡ååæ¸ï¼å¾ 1.1 åå BERT åºåºæ¸å°è³ 2900 è¬åï¼å°è´æ¨¡åç¸®å°äºå¤§ç´ 73.64%ãå¨ GLUE åºæºï¼åæ¬åç¾©å¥è¾¨è­ãæç·åæåæå­åé¡ï¼åç®¡ææ­¤ç¸®æ¸ï¼å­¸çæ¨¡åå¨è¨±å¤ä»»åä¸­ä»ç¶­æå¼·åçè¡¨ç¾ãæ­¤æ¨¡åä¹ç¨æ¼ä¸åçå¯¦ä¸çç ADHD è³æéï¼å¶æºç¢ºåº¦å F1 åæ¸çº 85%ãè DistilBERT (66M) å ClinicalBERT (110M) ç¸è¼ï¼LastBERT è¡¨ç¾åºå¯æ¯è¼çè¡¨ç¾ï¼DistilBERT ä»¥ 87% çè¡¨ç¾ç¥åä¸ç±ï¼è ClinicalBERT å¨ç¸åçææ¨ä¸­éå° 86%ãéäºç¼ç¾çªé¡¯äº LastBERT æ¨¡åé©ç¶å°åé¡ ADHD å´éç¨åº¦çè½åï¼å æ­¤å®çºå¿çå¥åº·å°æ¥­äººå¡æä¾äºä¸åæç¨çå·¥å·ï¼ç¨æ¼è©ä¼°åçè§£ç¤¾ç¾¤ç¶²è·¯å¹³å°ä¸ä½¿ç¨èç¢åºçè³æãæ¬ç ç©¶å¼·èª¿äºç¥è­èåå¨ç¢çé©ç¨æ¼è³æºæéæ¢ä»¶çæææ¨¡åæ¹é¢çå¯è½æ§ï¼å æ­¤ä¿é²äº NLP åå¿çå¥åº·è¨ºæ·ãæ­¤å¤ï¼å¨æ²æé¡¯èæè½æå¤±çææ³ä¸å¤§å¹ç¸®å°æ¨¡åå¤§å°ï¼ä¹çªé¡¯äºè¨ç·´åé¨ç½²æéçè¼ä½éç®è³æºï¼å æ­¤ä¿é²äºæ´å»£æ³çæç¨æ§ãç¹å¥æ¯ä½¿ç¨ç¾æçéç®å·¥å·ï¼ä¾å¦ Google Colabãæ¬ç ç©¶é¡¯ç¤ºäºåé² NLP æ¹æ³å¨åå¯¦ä¸çæç¨ä¸­çå¯åæ§åå¯¦ç¨æ§ã</paragraph>

##### **DiaMond: Dementia Diagnosis with Multi-Modal Vision Transformers Using MRI and PET**
2410.23219v1 by Yitong Li, Morteza Ghahremani, Youssef Wally, Christian Wachinger

Diagnosing dementia, particularly for Alzheimer's Disease (AD) and
frontotemporal dementia (FTD), is complex due to overlapping symptoms. While
magnetic resonance imaging (MRI) and positron emission tomography (PET) data
are critical for the diagnosis, integrating these modalities in deep learning
faces challenges, often resulting in suboptimal performance compared to using
single modalities. Moreover, the potential of multi-modal approaches in
differential diagnosis, which holds significant clinical importance, remains
largely unexplored. We propose a novel framework, DiaMond, to address these
issues with vision Transformers to effectively integrate MRI and PET. DiaMond
is equipped with self-attention and a novel bi-attention mechanism that
synergistically combine MRI and PET, alongside a multi-modal normalization to
reduce redundant dependency, thereby boosting the performance. DiaMond
significantly outperforms existing multi-modal methods across various datasets,
achieving a balanced accuracy of 92.4% in AD diagnosis, 65.2% for AD-MCI-CN
classification, and 76.5% in differential diagnosis of AD and FTD. We also
validated the robustness of DiaMond in a comprehensive ablation study. The code
is available at https://github.com/ai-med/DiaMond.

æè¦ï¼è¨ºæ·å¤±æºçï¼å°¤å¶æ¯é¿è²æµ·é»ç (AD) åé¡é¡³èåå¤±æºç (FTD)ï¼ç±æ¼ççéçï¼å æ­¤å¾è¤éãéç¶ç£å±æ¯é å½± (MRI) åæ­£å­æ·å±¤ææ (PET) æ¸æå°æ¼è¨ºæ·è³ééè¦ï¼ä½å°éäºæ¹å¼æ´åå°æ·±åº¦å­¸ç¿ä¸­æé¢è¨ææ°ï¼éå¸¸æå°è´èä½¿ç¨å®ä¸æ¹å¼ç¸æ¯æ§è½ä¸ä½³ãæ­¤å¤ï¼å¤æ¨¡å¼æ¹æ³å¨éå¥è¨ºæ·ä¸­çæ½åå·æéè¦çè¨åºæç¾©ï¼ä½ä»æªå¾å°ååæ¢ç´¢ãæåæåºä¸åæ°çæ¡æ¶ DiaMondï¼ä»¥è§£æ±ºéäºåé¡ï¼ä½¿ç¨è¦è¦ºè½æå¨æææ´å MRI å PETãDiaMond å·åèªæ³¨æååæ°ç©çéæ³¨æåæ©å¶ï¼å¯ä»¥ååçµå MRI å PETï¼ä¸¦æ¡ç¨å¤æ¨¡å¼æ­£è¦åä¾æ¸å°åé¤ä¾è³´ï¼å¾èæåæ§è½ãDiaMond å¨åç¨®æ¸æéä¸­çè¡¨ç¾æé¡¯åªæ¼ç¾æçå¤æ¨¡å¼æ¹æ³ï¼å¨ AD è¨ºæ·ä¸­éå° 92.4% çå¹³è¡¡æºç¢ºåº¦ï¼å¨ AD-MCI-CN åé¡ä¸­éå° 65.2%ï¼å¨ AD å FTD çéå¥è¨ºæ·ä¸­éå° 76.5%ãæåéå¨å¨é¢çæ¶èç ç©¶ä¸­é©è­äº DiaMond çç©©å¥æ§ãç¨å¼ç¢¼å¯å¨ https://github.com/ai-med/DiaMond åå¾ã

##### **Variable Resolution Sampling and Deep Learning Image Recovery for Accelerated Multi-Spectral MRI Near Metal Implants**
2410.23329v1 by Azadeh Sharafi, Nikolai J. Mickevicius, Mehran Baboli, Andrew S. Nencka, Kevin M. Koch

Purpose: This study presents a variable resolution (VR) sampling and deep
learning reconstruction approach for multi-spectral MRI near metal implants,
aiming to reduce scan times while maintaining image quality. Background: The
rising use of metal implants has increased MRI scans affected by metal
artifacts. Multi-spectral imaging (MSI) reduces these artifacts but sacrifices
acquisition efficiency. Methods: This retrospective study on 1.5T MSI knee and
hip data from patients with metal hardware used a novel spectral undersampling
scheme to improve acquisition efficiency by ~40%. U-Net-based deep learning
models were trained for reconstruction. Image quality was evaluated using SSIM,
PSNR, and RESI metrics. Results: Deep learning reconstructions of undersampled
VR data (DL-VR) showed significantly higher SSIM and PSNR values (p<0.001)
compared to conventional reconstruction (CR-VR), with improved edge sharpness.
Edge sharpness in DL-reconstructed images matched fully sampled references
(p=0.5). Conclusion: This approach can potentially enhance MRI examinations
near metal implants by reducing scan times or enabling higher resolution.
Further prospective studies are needed to assess clinical value.

æè¦ï¼ç®çï¼æ¬ç ç©¶æåºä¸ç§å¯ååè¾¨ç (VR) éæ ·åæ·±åº¦å­¦ä¹ éå»ºæ¹æ³ï¼ç¨äºéå±æ¤å¥ç©éè¿çå¤åå MRIï¼æ¨å¨å¨ä¿æå¾åè´¨éçåæ¶åå°æ«ææ¶é´ãèæ¯ï¼éå±æ¤å¥ç©çä½¿ç¨å¢å ï¼å¯¼è´åéå±ä¼ªå½±å½±åç MRI æ«æå¢å ãå¤ååæå (MSI) åå°äºè¿äºä¼ªå½±ï¼ä½çºç²äºééæçãæ¹æ³ï¼è¿é¡¹éå¯¹ 1.5T MSI èçåé«é¨æ°æ®çåé¡¾æ§ç ç©¶ï¼æ¥èªè£æéå±ç¡¬ä»¶çæ£èï¼ä½¿ç¨äºä¸ç§æ°é¢çåè°±æ¬ éæ ·æ¹æ¡ï¼å°ééæçæé«äºçº¦ 40%ãåºäº U-Net çæ·±åº¦å­¦ä¹ æ¨¡åç»è¿è®­ç»ç¨äºéå»ºãä½¿ç¨ SSIMãPSNR å RESI ææ è¯ä¼°å¾åè´¨éãç»æï¼æ¬ éæ · VR æ°æ®çæ·±åº¦å­¦ä¹ éå»º (DL-VR) ä¸ä¼ ç»éå»º (CR-VR) ç¸æ¯ï¼æ¾ç¤ºåºææ¾æ´é«ç SSIM å PSNR å¼ï¼p<0.001ï¼ï¼å¹¶æé«äºè¾¹ç¼æ¸æ°åº¦ãDL éå»ºå¾åä¸­çè¾¹ç¼æ¸æ°åº¦ä¸å®å¨éæ ·çåèå¼ç¸å¹éï¼p=0.5ï¼ãç»è®ºï¼è¿ç§æ¹æ³å¯ä»¥éè¿åå°æ«ææ¶é´æå¯ç¨æ´é«åè¾¨çæ¥å¢å¼ºéå±æ¤å¥ç©éè¿ç MRI æ£æ¥ãéè¦è¿ä¸æ­¥çåç»æ§ç ç©¶æ¥è¯ä¼°ä¸´åºä»·å¼ã

##### **DiabML: AI-assisted diabetes diagnosis method with meta-heuristic-based feature selection**
2411.00858v1 by Vahideh Hayyolalam, Ãznur Ãzkasap

Diabetes is a chronic disorder identified by the high sugar level in the
blood that can cause various different disorders such as kidney failure, heart
attack, sightlessness, and stroke. Developments in the healthcare domain by
facilitating the early detection of diabetes risk can help not only caregivers
but also patients. AIoMT is a recent technology that integrates IoT and machine
learning methods to give services for medical purposes, which is a powerful
technology for the early detection of diabetes. In this paper, we take
advantage of AIoMT and propose a hybrid diabetes risk detection method, DiabML,
which uses the BWO algorithm and ML methods. BWO is utilized for feature
selection and SMOTE for imbalance handling in the pre-processing procedure. The
simulation results prove the superiority of the proposed DiabML method compared
to the existing works. DiabML achieves 86.1\% classification accuracy by
AdaBoost classifier outperforms the relevant existing methods.

æè¦ï¼ç³å°¿çæ¯ä¸ç¨®æ¢æ§ç¾çï¼ç¹å¾µæ¯è¡æ¶²ä¸­çé«ç³åï¼å¯è½å°è´åç¨®ä¸åçç¾çï¼ä¾å¦èè¡°ç«­ãå¿èçç¼ä½ãå¤±æåä¸­é¢¨ãé«çä¿å¥é åçç¼å±ééä¿é²æ©æç¼ç¾ç³å°¿çé¢¨éªï¼ä¸åå¯ä»¥å¹«å©ç§è­·èï¼éå¯ä»¥å¹«å©æ£èãAIoMT æ¯ä¸ç¨®å°ç©è¯ç¶²åæ©å¨å­¸ç¿æ¹æ³æ´åå¨ä¸èµ·çæ°æè¡ï¼ç¨æ¼æä¾é«çç®ççæåï¼éæ¯ä¸ç¨®ç¨æ¼æ©æç¼ç¾ç³å°¿ççå¼·å¤§æè¡ãå¨æ¬æä¸­ï¼æåå©ç¨ AIoMT ä¸¦æåºäºä¸ç¨®æ··åç³å°¿çé¢¨éªæª¢æ¸¬æ¹æ³ DiabMLï¼å®ä½¿ç¨ BWO æ¼ç®æ³å ML æ¹æ³ãBWO ç¨æ¼é èçç¨åºä¸­çç¹å¾µé¸æï¼è SMOTE ç¨æ¼èçä¸å¹³è¡¡ãæ¨¡æ¬çµæè­æäºææåºç DiabML æ¹æ³åªæ¼ç¾ææ¹æ³ãDiabML éé AdaBoost åé¡å¨å¯¦ç¾äº 86.1% çåé¡æºç¢ºåº¦ï¼åªæ¼ç¸éçç¾ææ¹æ³ã

##### **Revisiting MAE pre-training for 3D medical image segmentation**
2410.23132v1 by Tassilo Wald, Constantin Ulrich, Stanislav Lukyanenko, Andrei Goncharov, Alberto Paderno, Leander Maerkisch, Paul F. JÃ¤ger, Klaus Maier-Hein

Self-Supervised Learning (SSL) presents an exciting opportunity to unlock the
potential of vast, untapped clinical datasets, for various downstream
applications that suffer from the scarcity of labeled data. While SSL has
revolutionized fields like natural language processing and computer vision,
their adoption in 3D medical image computing has been limited by three key
pitfalls: Small pre-training dataset sizes, architectures inadequate for 3D
medical image analysis, and insufficient evaluation practices. We address these
issues by i) leveraging a large-scale dataset of 44k 3D brain MRI volumes and
ii) using a Residual Encoder U-Net architecture within the state-of-the-art
nnU-Net framework. iii) A robust development framework, incorporating 5
development and 8 testing brain MRI segmentation datasets, allowed
performance-driven design decisions to optimize the simple concept of Masked
Auto Encoders (MAEs) for 3D CNNs. The resulting model not only surpasses
previous SSL methods but also outperforms the strong nnU-Net baseline by an
average of approximately 3 Dice points. Furthermore, our model demonstrates
exceptional stability, achieving the highest average rank of 2 out of 7
methods, compared to the second-best method's mean rank of 3.

æè¦ï¼èªçç£å­¦ä¹  (SSL) ä¸ºè§£éå¤§éæªå¼åä¸´åºæ°æ®éçæ½åæä¾äºä¸ä¸ªæ¿å¨äººå¿çæºä¼ï¼ç¨äºåç§ä¸æ¸¸åºç¨ç¨åºï¼è¿äºåºç¨ç¨åºå æ è®°æ°æ®ç¨ç¼ºèåå°å½±åãè½ç¶ SSL å·²å½»åºæ¹åäºèªç¶è¯­è¨å¤çåè®¡ç®æºè§è§ç­é¢åï¼ä½å¶å¨ 3D å»å­¦å¾åè®¡ç®ä¸­çéç¨åå°ä¸ä¸ªä¸»è¦ç¼ºé·çéå¶ï¼å°åé¢è®­ç»æ°æ®éå¤§å°ãä¸éç¨äº 3D å»å­¦å¾ååæçæ¶æä»¥åè¯ä¼°å®è·µä¸è¶³ãæä»¬éè¿ä»¥ä¸æ¹å¼è§£å³è¿äºé®é¢ï¼i) å©ç¨ 44k 3D å¤§è MRI ä½ç§¯çå¤§è§æ¨¡æ°æ®éï¼ä»¥å ii) å¨æåè¿ç nnU-Net æ¡æ¶åä½¿ç¨æ®å·®ç¼ç å¨ U-Net æ¶æãiii) ä¸ä¸ªç¨³å¥çå¼åæ¡æ¶ï¼åå« 5 ä¸ªå¼åå 8 ä¸ªæµè¯å¤§è MRI åå²æ°æ®éï¼åè®¸åºäºæ§è½çè®¾è®¡å³ç­æ¥ä¼å 3D CNN çæ©è½èªå¨ç¼ç å¨ (MAE) çç®åæ¦å¿µãç±æ­¤äº§ççæ¨¡åä¸ä»è¶è¶äºä¹åç SSL æ¹æ³ï¼èä¸æ¯å¼ºå¤§ç nnU-Net åºçº¿å¹³åé«åºå¤§çº¦ 3 ä¸ªéª°å­ç¹ãæ­¤å¤ï¼æä»¬çæ¨¡åè¡¨ç°åºéå¡çç¨³å®æ§ï¼å¨ 7 ç§æ¹æ³ä¸­è¾¾å° 2 çæé«å¹³åæåï¼èç¬¬äºå¥½çæ¹æ³çå¹³åæåä¸º 3ã

##### **SpiroActive: Active Learning for Efficient Data Acquisition for Spirometry**
2410.22950v1 by Ankita Kumari Jain, Nitish Sharma, Madhav Kanda, Nipun Batra

Respiratory illnesses are a significant global health burden. Respiratory
illnesses, primarily Chronic obstructive pulmonary disease (COPD), is the
seventh leading cause of poor health worldwide and the third leading cause of
death worldwide, causing 3.23 million deaths in 2019, necessitating early
identification and diagnosis for effective mitigation. Among the diagnostic
tools employed, spirometry plays a crucial role in detecting respiratory
abnormalities. However, conventional clinical spirometry methods often entail
considerable costs and practical limitations like the need for specialized
equipment, trained personnel, and a dedicated clinical setting, making them
less accessible. To address these challenges, wearable spirometry technologies
have emerged as promising alternatives, offering accurate, cost-effective, and
convenient solutions. The development of machine learning models for wearable
spirometry heavily relies on the availability of high-quality ground truth
spirometry data, which is a laborious and expensive endeavor. In this research,
we propose using active learning, a sub-field of machine learning, to mitigate
the challenges associated with data collection and labeling. By strategically
selecting samples from the ground truth spirometer, we can mitigate the need
for resource-intensive data collection. We present evidence that models trained
on small subsets obtained through active learning achieve comparable/better
results than models trained on the complete dataset.

æè¦ï¼å¼å¸éç¾çæ¯å¨çéå¤§çå¥åº·è² æãå¼å¸éç¾çï¼ä¸»è¦æ¯æ¢æ§é»å¡æ§èºç (COPD)ï¼æ¯å¨çç¬¬ä¸å¤§ä¸è¯å¥åº·åå ï¼ä¹æ¯å¨çç¬¬ä¸å¤§æ­»äº¡åå ï¼2019 å¹´é æ 323 è¬äººæ­»äº¡ï¼éè¦åæ©è­å¥åè¨ºæ·ä»¥æææ¸è¼ççãå¨ææ¡ç¨çè¨ºæ·å·¥å·ä¸­ï¼èºæ´»éæ¸¬éå¨æª¢æ¸¬å¼å¸éç°å¸¸æ¹é¢ç¼æ®èè³ééè¦çä½ç¨ãç¶èï¼å³çµ±çè¨åºèºæ´»éæ¸¬éæ¹æ³éå¸¸éè¦å¤§éçææ¬åå¯¦ééå¶ï¼ä¾å¦éè¦å°æ¥­è¨­åãè¨ç·´æç´ çäººå¡åå°éçè¨åºç°å¢ï¼éä½¿å¾å®åçå¯åæ§è¼ä½ãçºäºæå°éäºææ°ï¼å¯ç©¿æ´å¼èºæ´»éæ¸¬éæè¡å·²æçºæå¸æçæ¿ä»£æ¹æ¡ï¼æä¾æºç¢ºãç¶æ¿é«æä¸ä¾¿å©çè§£æ±ºæ¹æ¡ãå¯ç©¿æ´å¼èºæ´»éæ¸¬éæ©å¨å­¸ç¿æ¨¡åçéç¼å¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼é«åè³ªçåºæºèºæ´»éæ¸¬éæ¸æï¼éæ¯ä¸é è²»æä¸æè²´çå·¥ä½ãå¨éé ç ç©¶ä¸­ï¼æåå»ºè­°ä½¿ç¨ä¸»åå­¸ç¿ï¼æ©å¨å­¸ç¿çä¸åå­é åï¼ä¾æ¸è¼èæ¸ææ¶éåæ¨è¨ç¸éçææ°ãééå¾åºæºèºæ´»éè¨ä¸­ç­ç¥æ§å°é¸ææ¨£æ¬ï¼æåå¯ä»¥æ¸å°å°è³æºå¯éåæ¸ææ¶éçéæ±ãæåæä¾çè­æè¡¨æï¼å¨ééä¸»åå­¸ç¿ç²å¾çå°å­éä¸­è¨ç·´çæ¨¡åï¼ç²å¾ççµæèå¨å®æ´æ¸æéä¸è¨ç·´çæ¨¡åç¸ç¶/æ´å¥½ã

##### **Efficient Feature Extraction and Classification Architecture for MRI-Based Brain Tumor Detection**
2410.22619v1 by Plabon Paul, Md. Nazmul Islam, Fazle Rafsani, Pegah Khorasani, Shovito Barua Soumma

Uncontrolled cell division in the brain is what gives rise to brain tumors.
If the tumor size increases by more than half, there is little hope for the
patient's recovery. This emphasizes the need of rapid and precise brain tumor
diagnosis. When it comes to analyzing, diagnosing, and planning therapy for
brain tumors, MRI imaging plays a crucial role. A brain tumor's development
history is crucial information for doctors to have. When it comes to
distinguishing between human soft tissues, MRI scans are superior. In order to
get reliable classification results from MRI scans quickly, deep learning is
one of the most practical methods. Early human illness diagnosis has been
demonstrated to be more accurate when deep learning methods are used. In the
case of diagnosing a brain tumor, when even a little misdiagnosis might have
serious consequences, accuracy is especially important. Disclosure of brain
tumors in medical images is still a difficult task. Brain MRIs are notoriously
imprecise in revealing the presence or absence of tumors. Using MRI scans of
the brain, a Convolutional Neural Network (CNN) was trained to identify the
presence of a tumor in this research. Results from the CNN model showed an
accuracy of 99.17%. The CNN model's characteristics were also retrieved. In
order to evaluate the CNN model's capability for processing images, we applied
the features via the following machine learning models: KNN, Logistic
regression, SVM, Random Forest, Naive Bayes, and Perception. CNN and machine
learning models were also evaluated using the standard metrics of Precision,
Recall, Specificity, and F1 score. The significance of the doctor's diagnosis
enhanced the accuracy of the CNN model's assistance in identifying the
existence of tumor and treating the patient.

æè¦ï¼è¦é¨ç´°èåè£å¤±æ§ï¼å°±æç¢çè¦ç¤ã
å¦æè«ç¤å¤§å°å¢å è¶éä¸åï¼çæ£åº·å¾©çå¸æå¾æ¸ºè«ãéå¼·èª¿äºå¿«éä¸ç²¾æºè¨ºæ·è¦ç¤çå¿è¦æ§ã
å¨åæãè¨ºæ·åè¦åè¦ç¤æ²»çæï¼æ ¸ç£å±æ¯é å½±æ®æ¼äºè³ééè¦çè§è²ãè¦ç¤çç¼å±å²æ¯é«çå¿åçéè¦è³è¨ã
å¨ååäººé«è»çµç¹æï¼æ ¸ç£å±æ¯ææçè¡¨ç¾åªç°ãçºäºå¾æ ¸ç£å±æ¯ææä¸­å¿«éåå¾å¯é çåé¡çµæï¼æ·±åº¦å­¸ç¿æ¯æå¯¦ç¨çæ¹æ³ä¹ä¸ã
ç ç©¶é¡¯ç¤ºï¼ä½¿ç¨æ·±åº¦å­¸ç¿æ¹æ³å¯ä»¥æ´æºç¢ºå°è¨ºæ·äººé¡æ©æç¾çãå¨è¨ºæ·è¦ç¤æï¼å³ä½¿æ¯è¼å¾®çèª¤è¨ºé½å¯è½é æå´éå¾æï¼å æ­¤æºç¢ºæ§ç¹å¥éè¦ã
å¨é«å­¸å½±åä¸­æ­é²è¦ç¤ä»ç¶æ¯ä¸é è±é£çä»»åãè¦é¨æ ¸ç£å±æ¯é å½±å¨æ­é²è«ç¤çå­å¨èå¦æ¹é¢åºäºåçä¸ç²¾ç¢ºã
æ¬ç ç©¶è¨ç·´äºä¸åå·ç©ç¥ç¶ç¶²è·¯ (CNN)ï¼ä½¿ç¨è¦é¨æ ¸ç£å±æ¯ææä¾è¾¨è­è«ç¤çå­å¨ãCNN æ¨¡åççµæé¡¯ç¤ºæºç¢ºåº¦çº 99.17%ãCNN æ¨¡åçç¹å¾µä¹å·²æ·åã
çºäºè©ä¼° CNN æ¨¡åèçå½±åçè½åï¼æåééä»¥ä¸æ©å¨å­¸ç¿æ¨¡åå¥ç¨éäºç¹å¾µï¼KNNãéè¼¯è¿´æ­¸ãSVMãé¨æ©æ£®æãæ¨¸ç´ è²æ°åæç¥å¨ãCNN åæ©å¨å­¸ç¿æ¨¡åä¹ä½¿ç¨ç²¾æºåº¦ãå¬åçãç¹ç°æ§å F1 åæ¸ç­æ¨æºææ¨é²è¡è©ä¼°ã
é«ççè¨ºæ·æç¾©æåäº CNN æ¨¡åå¨åå©è¾¨è­è«ç¤å­å¨åæ²»ççæ£æ¹é¢çæºç¢ºæ§ã

##### **Do Large Language Models Align with Core Mental Health Counseling Competencies?**
2410.22446v1 by Viet Cuong Nguyen, Mohammad Taher, Dongwan Hong, Vinicius Konkolics Possobom, Vibha Thirunellayi Gopalakrishnan, Ekta Raj, Zihang Li, Heather J. Soled, Michael L. Birnbaum, Srijan Kumar, Munmun De Choudhury

The rapid evolution of Large Language Models (LLMs) offers promising
potential to alleviate the global scarcity of mental health professionals.
However, LLMs' alignment with essential mental health counseling competencies
remains understudied. We introduce CounselingBench, a novel NCMHCE-based
benchmark evaluating LLMs across five key mental health counseling
competencies. Testing 22 general-purpose and medical-finetuned LLMs, we find
frontier models exceed minimum thresholds but fall short of expert-level
performance, with significant variations: they excel in Intake, Assessment &
Diagnosis yet struggle with Core Counseling Attributes and Professional
Practice & Ethics. Medical LLMs surprisingly underperform generalist models
accuracy-wise, while at the same time producing slightly higher-quality
justifications but making more context-related errors. Our findings highlight
the complexities of developing AI systems for mental health counseling,
particularly for competencies requiring empathy and contextual understanding.
We found that frontier LLMs perform at a level exceeding the minimal required
level of aptitude for all key mental health counseling competencies, but fall
short of expert-level performance, and that current medical LLMs do not
significantly improve upon generalist models in mental health counseling
competencies. This underscores the critical need for specialized, mental health
counseling-specific fine-tuned LLMs that rigorously aligns with core
competencies combined with appropriate human supervision before any responsible
real-world deployment can be considered.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çå¿«éç¼å±ï¼æä¾äºç·©è§£å¨çå¿çå¥åº·å°æ¥­äººå¡ç­ç¼ºçæ½å¨å¸æã
ç¶èï¼LLM èåºæ¬å¿çå¥åº·è«®åè½åçå°é½ç¨åº¦ï¼ä»æªç²å¾ååç ç©¶ãæåå¼å¥äº CounselingBenchï¼ä¸ååºæ¼ NCMHCE çæ°åºæºï¼ç¨æ¼è©ä¼° LLM å¨äºé ééµå¿çå¥åº·è«®åè½åä¸çè¡¨ç¾ãæåæ¸¬è©¦äº 22 åéç¨åé«å­¸å¾®èª¿ç LLMï¼ç¼ç¾åæ²¿æ¨¡åè¶éäºæä½éæª»ï¼ä½æªéå°å°å®¶ç´å¥çè¡¨ç¾ï¼ä¸å·®ç°é¡¯èï¼å®åå¨ãæåãè©ä¼°åè¨ºæ·ãæ¹é¢è¡¨ç¾åºè²ï¼ä½å¨ãæ ¸å¿è«®åå±¬æ§ãåãå°æ¥­å¯¦ååå«çãæ¹é¢å»æå°é£ãä»¤äººé©è¨çæ¯ï¼é«ç LLM å¨æºç¢ºæ§æ¹é¢è¡¨ç¾ä¸å¦éç¨æ¨¡åï¼ä½åæç¢çççç±åè³ªç¥é«ï¼ä½ç¢çæ´å¤èèçµ¡ç¸éçé¯èª¤ãæåçç ç©¶çµæçªåºäºçºå¿çå¥åº·è«®åéç¼ AI ç³»çµ±çè¤éæ§ï¼ç¹å¥æ¯å°æ¼éè¦åçå¿åèçµ¡çè§£çè½åãæåç¼ç¾ï¼åæ²¿ LLM çè¡¨ç¾æ°´å¹³è¶éäºææééµå¿çå¥åº·è«®åè½åæéçæä½è½åæ°´æºï¼ä½æªéå°å°å®¶ç´å¥çè¡¨ç¾ï¼èä¸ç®åçé«ç LLM ä¸¦æªé¡¯èæ¹åéç¨æ¨¡åå¨å¿çå¥åº·è«®åè½åä¸çè¡¨ç¾ãéå¼·èª¿äºå°å°éçãéå°å¿çå¥åº·è«®è©¢çå¾®èª¿ LLM çè¿«åéæ±ï¼éäº LLM å¿é å´æ ¼ç¬¦åæ ¸å¿è½åï¼ä¸¦çµåé©ç¶çäººé¡ç£ç£ï¼æè½èæ®ä»»ä½è² è²¬ä»»çå¯¦éé¨ç½²ã

##### **MAPUNetR: A Hybrid Vision Transformer and U-Net Architecture for Efficient and Interpretable Medical Image Segmentation**
2410.22223v1 by Ovais Iqbal Shah, Danish Raza Rizvi, Aqib Nazir Mir

Medical image segmentation is pivotal in healthcare, enhancing diagnostic
accuracy, informing treatment strategies, and tracking disease progression.
This process allows clinicians to extract critical information from visual
data, enabling personalized patient care. However, developing neural networks
for segmentation remains challenging, especially when preserving image
resolution, which is essential in detecting subtle details that influence
diagnoses. Moreover, the lack of transparency in these deep learning models has
slowed their adoption in clinical practice. Efforts in model interpretability
are increasingly focused on making these models' decision-making processes more
transparent. In this paper, we introduce MAPUNetR, a novel architecture that
synergizes the strengths of transformer models with the proven U-Net framework
for medical image segmentation. Our model addresses the resolution preservation
challenge and incorporates attention maps highlighting segmented regions,
increasing accuracy and interpretability. Evaluated on the BraTS 2020 dataset,
MAPUNetR achieved a dice score of 0.88 and a dice coefficient of 0.92 on the
ISIC 2018 dataset. Our experiments show that the model maintains stable
performance and potential as a powerful tool for medical image segmentation in
clinical practice.

æè¦ï¼é«å­¸å½±ååå²å¨é«çä¿å¥ä¸­è³ééè¦ï¼è½æåè¨ºæ·æºç¢ºåº¦ãæä¾æ²»çç­ç¥è³è¨ï¼ä¸¦è¿½è¹¤ç¾çé²ç¨ãæ­¤ç¨åºè®è¨åºé«çè½å¾è¦è¦ºè³æä¸­èåééµè³è¨ï¼é²èæä¾åäººåçæ£èç§è­·ãç¶èï¼éç¼ç¨æ¼åå²çç¥ç¶ç¶²è·¯ä»å·ææ°æ§ï¼ç¹å¥æ¯å¨ä¿çå½±åè§£æåº¦æï¼éå°æ¼åµæ¸¬å½±é¿è¨ºæ·çç´°å¾®ç´°ç¯è³ééè¦ãæ­¤å¤ï¼éäºæ·±åº¦å­¸ç¿æ¨¡åç¼ºä¹éæåº¦ï¼å°è´å¶å¨è¨åºå¯¦åä¸­çæ¡ç¨éåº¦è®æ¢ãæ¨¡åå¯è§£éæ§çåªåè¶ä¾è¶å°æ³¨æ¼è®éäºæ¨¡åçæ±ºç­éç¨æ´éæãå¨æ¬æä¸­ï¼æåä»ç´¹äº MAPUNetRï¼éæ¯ä¸ç¨®æ°ç©çæ¶æ§ï¼çµåäºTransformeræ¨¡åçåªé»åå·²è­å¯¦ç U-Net æ¡æ¶ï¼ç¨æ¼é«å­¸å½±ååå²ãæåçæ¨¡åè§£æ±ºäºè§£æåº¦ä¿ççææ°ï¼ä¸¦çµåäºçªé¡¯åå²ååçæ³¨æååï¼æé«äºæºç¢ºåº¦åå¯è§£éæ§ãå¨ BraTS 2020 è³æéä¸é²è¡è©ä¼°ï¼MAPUNetR å¨ ISIC 2018 è³æéä¸éå°äº 0.88 çéª°å­ä¿æ¸å 0.92 çéª°å­ç³»æ¸ãæåçå¯¦é©è¡¨æï¼è©²æ¨¡åå¨è¨åºå¯¦åä¸­ä½çºé«å­¸å½±ååå²çå¼·å¤§å·¥å·ï¼å·æç©©å®çæè½åæ½åã


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-11**|**UTMath: Math Evaluation with Unit Test via Reasoning-to-Coding Thoughts**|Bo Yang et.al.|[2411.07240v1](http://arxiv.org/abs/2411.07240v1)|null|
|**2024-11-11**|**OpenThaiGPT 1.5: A Thai-Centric Open Source Large Language Model**|Sumeth Yuenyong et.al.|[2411.07238v1](http://arxiv.org/abs/2411.07238v1)|null|
|**2024-11-11**|**Contextualized Evaluations: Taking the Guesswork Out of Language Model Evaluations**|Chaitanya Malaviya et.al.|[2411.07237v1](http://arxiv.org/abs/2411.07237v1)|null|
|**2024-11-11**|**Add-it: Training-Free Object Insertion in Images With Pretrained Diffusion Models**|Yoad Tewel et.al.|[2411.07232v1](http://arxiv.org/abs/2411.07232v1)|null|
|**2024-11-11**|**Tooling or Not Tooling? The Impact of Tools on Language Agents for Chemistry Problem Solving**|Botao Yu et.al.|[2411.07228v1](http://arxiv.org/abs/2411.07228v1)|null|
|**2024-11-11**|**TempCharBERT: Keystroke Dynamics for Continuous Access Control Based on Pre-trained Language Models**|Matheus SimÃ£o et.al.|[2411.07224v1](http://arxiv.org/abs/2411.07224v1)|null|
|**2024-11-11**|**Grounding Video Models to Actions through Goal Conditioned Exploration**|Yunhao Luo et.al.|[2411.07223v1](http://arxiv.org/abs/2411.07223v1)|null|
|**2024-11-11**|**TreeCoders: Trees of Transformers**|Pierre Colonna D'Istria et.al.|[2411.07218v1](http://arxiv.org/abs/2411.07218v1)|null|
|**2024-11-11**|**OmniEdit: Building Image Editing Generalist Models Through Specialist Supervision**|Cong Wei et.al.|[2411.07199v1](http://arxiv.org/abs/2411.07199v1)|null|
|**2024-11-11**|**The Super Weight in Large Language Models**|Mengxia Yu et.al.|[2411.07191v1](http://arxiv.org/abs/2411.07191v1)|[link](https://github.com/mengxiayu/llmsuperweight)|
|**2024-11-11**|**NatureLM-audio: an Audio-Language Foundation Model for Bioacoustics**|David Robinson et.al.|[2411.07186v1](http://arxiv.org/abs/2411.07186v1)|null|
|**2024-11-11**|**Gradual Fine-Tuning with Graph Routing for Multi-Source Unsupervised Domain Adaptation**|Yao Ma et.al.|[2411.07185v1](http://arxiv.org/abs/2411.07185v1)|null|
|**2024-11-11**|**Counterfactual Generation from Language Models**|Shauli Ravfogel et.al.|[2411.07180v1](http://arxiv.org/abs/2411.07180v1)|[link](https://github.com/shauli-ravfogel/lm-counterfactuals)|
|**2024-11-11**|**More Expressive Attention with Negative Weights**|Ang Lv et.al.|[2411.07176v1](http://arxiv.org/abs/2411.07176v1)|[link](https://github.com/trestad/cogattn)|
|**2024-11-11**|**Continual Memorization of Factoids in Large Language Models**|Howard Chen et.al.|[2411.07175v1](http://arxiv.org/abs/2411.07175v1)|null|
|**2024-11-11**|**A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19**|Vedant Khandelwal et.al.|[2411.07163v1](http://arxiv.org/abs/2411.07163v1)|null|
|**2024-11-11**|**A Primer on Word Embeddings: AI Techniques for Text Analysis in Social Work**|Brian E. Perron et.al.|[2411.07156v1](http://arxiv.org/abs/2411.07156v1)|null|
|**2024-11-11**|**HierTOD: A Task-Oriented Dialogue System Driven by Hierarchical Goals**|Lingbo Mo et.al.|[2411.07152v1](http://arxiv.org/abs/2411.07152v1)|null|
|**2024-11-11**|**Chinese SimpleQA: A Chinese Factuality Evaluation for Large Language Models**|Yancheng He et.al.|[2411.07140v1](http://arxiv.org/abs/2411.07140v1)|null|
|**2024-11-11**|**Edify 3D: Scalable High-Quality 3D Asset Generation**|NVIDIA et.al.|[2411.07135v1](http://arxiv.org/abs/2411.07135v1)|null|
|**2024-11-11**|**Stronger Models are NOT Stronger Teachers for Instruction Tuning**|Zhangchen Xu et.al.|[2411.07133v1](http://arxiv.org/abs/2411.07133v1)|null|
|**2024-11-11**|**Token Merging for Training-Free Semantic Binding in Text-to-Image Synthesis**|Taihang Hu et.al.|[2411.07132v1](http://arxiv.org/abs/2411.07132v1)|[link](https://github.com/hutaihang/tome)|
|**2024-11-11**|**Retrieval or Global Context Understanding? On Many-Shot In-Context Learning for Long-Context Evaluation**|Kaijian Zou et.al.|[2411.07130v1](http://arxiv.org/abs/2411.07130v1)|null|
|**2024-11-11**|**Benchmarking LLMs' Judgments with No Gold Standard**|Shengwei Xu et.al.|[2411.07127v1](http://arxiv.org/abs/2411.07127v1)|[link](https://github.com/yx-lu/benchmarking-llms--judgments-with-no-gold-standard)|
|**2024-11-11**|**Fast and Robust Contextual Node Representation Learning over Dynamic Graphs**|Xingzhi Guo et.al.|[2411.07123v1](http://arxiv.org/abs/2411.07123v1)|null|
|**2024-11-11**|**SCAR: Sparse Conditioned Autoencoders for Concept Detection and Steering in LLMs**|Ruben HÃ¤rle et.al.|[2411.07122v1](http://arxiv.org/abs/2411.07122v1)|null|
|**2024-11-11**|**Building a Taiwanese Mandarin Spoken Language Model: A First Attempt**|Chih-Kai Yang et.al.|[2411.07111v1](http://arxiv.org/abs/2411.07111v1)|null|
|**2024-11-11**|**Training Neural Networks as Recognizers of Formal Languages**|Alexandra Butoi et.al.|[2411.07107v1](http://arxiv.org/abs/2411.07107v1)|[link](https://github.com/rycolab/neural-network-recognizers)|
|**2024-11-11**|**Bounded Rationality Equilibrium Learning in Mean Field Games**|Yannick Eich et.al.|[2411.07099v1](http://arxiv.org/abs/2411.07099v1)|null|
|**2024-11-11**|**A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs**|Myeongsoo Kim et.al.|[2411.07098v1](http://arxiv.org/abs/2411.07098v1)|null|
|**2024-11-11**|**Towards Characterizing Cyber Networks with Large Language Models**|Alaric Hartsock et.al.|[2411.07089v1](http://arxiv.org/abs/2411.07089v1)|null|
|**2024-11-11**|**OCMDP: Observation-Constrained Markov Decision Process**|Taiyi Wang et.al.|[2411.07087v1](http://arxiv.org/abs/2411.07087v1)|null|
|**2024-11-11**|**StoryTeller: Improving Long Video Description through Global Audio-Visual Character Identification**|Yichen He et.al.|[2411.07076v1](http://arxiv.org/abs/2411.07076v1)|[link](https://github.com/hyc2026/StoryTeller)|
|**2024-11-11**|**Transformer verbatim in-context retrieval across time and scale**|Kristijan Armeni et.al.|[2411.07075v1](http://arxiv.org/abs/2411.07075v1)|null|
|**2024-11-11**|**Universal Response and Emergence of Induction in LLMs**|Niclas Luick et.al.|[2411.07071v1](http://arxiv.org/abs/2411.07071v1)|null|
|**2024-11-11**|**On Active Privacy Auditing in Supervised Fine-tuning for White-Box Language Models**|Qian Sun et.al.|[2411.07070v1](http://arxiv.org/abs/2411.07070v1)|null|
|**2024-11-11**|**Zeroth-Order Adaptive Neuron Alignment Based Pruning without Re-Training**|Elia Cunegatti et.al.|[2411.07066v1](http://arxiv.org/abs/2411.07066v1)|[link](https://github.com/eliacunegatti/neuroal)|
|**2024-11-11**|**Minion: A Technology Probe for Resolving Value Conflicts through Expert-Driven and User-Driven Strategies in AI Companion Applications**|Xianzhe Fan et.al.|[2411.07042v1](http://arxiv.org/abs/2411.07042v1)|null|
|**2024-11-11**|**Designing Reliable Experiments with Generative Agent-Based Modeling: A Comprehensive Guide Using Concordia by Google DeepMind**|Alejandro Leonardo GarcÃ­a Navarro et.al.|[2411.07038v1](http://arxiv.org/abs/2411.07038v1)|null|
|**2024-11-11**|**LIFBench: Evaluating the Instruction Following Performance and Stability of Large Language Models in Long-Context Scenarios**|Xiaodong Wu et.al.|[2411.07037v1](http://arxiv.org/abs/2411.07037v1)|null|
|**2024-11-11**|**UniHR: Hierarchical Representation Learning for Unified Knowledge Graph Link Prediction**|Zhiqiang Liu et.al.|[2411.07019v1](http://arxiv.org/abs/2411.07019v1)|[link](https://github.com/lza12a/unihr)|
|**2024-11-11**|**Leveraging LSTM for Predictive Modeling of Satellite Clock Bias**|Ahan Bhatt et.al.|[2411.07015v1](http://arxiv.org/abs/2411.07015v1)|null|
|**2024-11-11**|**A neural-network based anomaly detection system and a safety protocol to protect vehicular network**|Marco Franceschini et.al.|[2411.07013v1](http://arxiv.org/abs/2411.07013v1)|null|
|**2024-11-11**|**Non-Adversarial Inverse Reinforcement Learning via Successor Feature Matching**|Arnav Kumar Jain et.al.|[2411.07007v1](http://arxiv.org/abs/2411.07007v1)|[link](https://github.com/arnavkj1995/sfm)|
|**2024-11-11**|**Estimating Causal Effects in Partially Directed Parametric Causal Factor Graphs**|Malte Luttermann et.al.|[2411.07006v1](http://arxiv.org/abs/2411.07006v1)|null|
|**2024-11-11**|**Token2Wave**|Xin Zhang et.al.|[2411.06989v1](http://arxiv.org/abs/2411.06989v1)|null|
|**2024-11-11**|**ENAT: Rethinking Spatial-temporal Interactions in Token-based Image Synthesis**|Zanlin Ni et.al.|[2411.06959v1](http://arxiv.org/abs/2411.06959v1)|[link](https://github.com/leaplabthu/enat)|
|**2024-11-11**|**Sniff AI: Is My 'Spicy' Your 'Spicy'? Exploring LLM's Perceptual Alignment with Human Smell Experiences**|Shu Zhong et.al.|[2411.06950v1](http://arxiv.org/abs/2411.06950v1)|null|
|**2024-11-11**|**Cancer-Answer: Empowering Cancer Care with Advanced Large Language Models**|Aniket Deroy et.al.|[2411.06946v1](http://arxiv.org/abs/2411.06946v1)|null|
|**2024-11-11**|**Electroencephalogram-based Multi-class Decoding of Attended Speakers' Direction with Audio Spatial Spectrum**|Yuanming Zhang et.al.|[2411.06928v1](http://arxiv.org/abs/2411.06928v1)|null|
|**2024-11-11**|**Slowing Down Forgetting in Continual Learning**|Pascal Janetzky et.al.|[2411.06916v1](http://arxiv.org/abs/2411.06916v1)|null|
|**2024-11-11**|**Gaussian Process Emulators for Few-Shot Segmentation in Cardiac MRI**|Bruno Viti et.al.|[2411.06911v1](http://arxiv.org/abs/2411.06911v1)|[link](https://gitlab.com/bruno_viti/gpe_4_cardiac_fss)|
|**2024-11-11**|**EVQAScore: Efficient Video Question Answering Data Evaluation**|Hao Liang et.al.|[2411.06908v1](http://arxiv.org/abs/2411.06908v1)|null|
|**2024-11-11**|**LongSafetyBench: Long-Context LLMs Struggle with Safety Issues**|Mianqiu Huang et.al.|[2411.06899v1](http://arxiv.org/abs/2411.06899v1)|null|
|**2024-11-11**|**GraphRPM: Risk Pattern Mining on Industrial Large Attributed Graphs**|Sheng Tian et.al.|[2411.06878v1](http://arxiv.org/abs/2411.06878v1)|null|
|**2024-11-11**|**Multi-Modal interpretable automatic video captioning**|Antoine Hanna-Asaad et.al.|[2411.06872v1](http://arxiv.org/abs/2411.06872v1)|null|
|**2024-11-11**|**Subgraph Retrieval Enhanced by Graph-Text Alignment for Commonsense Question Answering**|Boci Peng et.al.|[2411.06866v1](http://arxiv.org/abs/2411.06866v1)|null|
|**2024-11-11**|**Computable Model-Independent Bounds for Adversarial Quantum Machine Learning**|Bacui Li et.al.|[2411.06863v1](http://arxiv.org/abs/2411.06863v1)|null|
|**2024-11-11**|**Enhancing Phishing Detection through Feature Importance Analysis and Explainable AI: A Comparative Study of CatBoost, XGBoost, and EBM Models**|Abdullah Fajar et.al.|[2411.06860v1](http://arxiv.org/abs/2411.06860v1)|null|
|**2024-11-11**|**Scientific machine learning in ecological systems: A study on the predator-prey dynamics**|Ranabir Devgupta et.al.|[2411.06858v1](http://arxiv.org/abs/2411.06858v1)|null|
|**2024-11-11**|**A Unified Multi-Task Learning Architecture for Hate Detection Leveraging User-Based Information**|Prashant Kapil et.al.|[2411.06855v1](http://arxiv.org/abs/2411.06855v1)|null|
|**2024-11-11**|**Evaluating Large Language Models on Financial Report Summarization: An Empirical Study**|Xinqi Yang et.al.|[2411.06852v1](http://arxiv.org/abs/2411.06852v1)|null|
|**2024-11-11**|**1-800-SHARED-TASKS @ NLU of Devanagari Script Languages: Detection of Language, Hate Speech, and Targets using LLMs**|Jebish Purbey et.al.|[2411.06850v1](http://arxiv.org/abs/2411.06850v1)|null|
|**2024-11-11**|**LLM-Neo: Parameter Efficient Knowledge Distillation for Large Language Models**|Runming Yang et.al.|[2411.06839v1](http://arxiv.org/abs/2411.06839v1)|null|
|**2024-11-11**|**Persuasion with Large Language Models: a Survey**|Alexander Rogiers et.al.|[2411.06837v1](http://arxiv.org/abs/2411.06837v1)|null|
|**2024-11-11**|**HarmLevelBench: Evaluating Harm-Level Compliance and the Impact of Quantization on Model Alignment**|Yannis Belkhiter et.al.|[2411.06835v1](http://arxiv.org/abs/2411.06835v1)|null|
|**2024-11-11**|**Combining Domain and Alignment Vectors to Achieve Better Knowledge-Safety Trade-offs in LLMs**|Megh Thakkar et.al.|[2411.06824v1](http://arxiv.org/abs/2411.06824v1)|null|
|**2024-11-11**|**Generative midtended cognition and Artificial Intelligence. Thinging with thinging things**|Xabier E. Barandiaran et.al.|[2411.06812v1](http://arxiv.org/abs/2411.06812v1)|null|
|**2024-11-11**|**JPEG AI Image Compression Visual Artifacts: Detection Methods and Dataset**|Daria Tsereh et.al.|[2411.06810v1](http://arxiv.org/abs/2411.06810v1)|null|
|**2024-11-11**|**AssistRAG: Boosting the Potential of Large Language Models with an Intelligent Information Assistant**|Yujia Zhou et.al.|[2411.06805v1](http://arxiv.org/abs/2411.06805v1)|[link](https://github.com/smallporridge/assistrag)|
|**2024-11-11**|**LA4SR: illuminating the dark proteome with generative AI**|David R. Nelson et.al.|[2411.06798v1](http://arxiv.org/abs/2411.06798v1)|null|
|**2024-11-11**|**Evolving Efficient Genetic Encoding for Deep Spiking Neural Networks**|Wenxuan Pan et.al.|[2411.06792v1](http://arxiv.org/abs/2411.06792v1)|null|
|**2024-11-11**|**Large-scale moral machine experiment on large language models**|Muhammad Shahrul Zaim bin Ahmad et.al.|[2411.06790v1](http://arxiv.org/abs/2411.06790v1)|[link](https://github.com/kztakemoto/mmllm)|
|**2024-11-11**|**ScaleKD: Strong Vision Transformers Could Be Excellent Teachers**|Jiawei Fan et.al.|[2411.06786v1](http://arxiv.org/abs/2411.06786v1)|[link](https://github.com/deep-optimization/scalekd)|
|**2024-11-11**|**MP-PINN: A Multi-Phase Physics-Informed Neural Network for Epidemic Forecasting**|Thang Nguyen et.al.|[2411.06781v1](http://arxiv.org/abs/2411.06781v1)|null|
|**2024-11-11**|**A Text Classification Model Combining Adversarial Training with Pre-trained Language Model and neural networks: A Case Study on Telecom Fraud Incident Texts**|Liu Zhuoxian et.al.|[2411.06772v1](http://arxiv.org/abs/2411.06772v1)|null|
|**2024-11-11**|**PDC & DM-SFT: A Road for LLM SQL Bug-Fix Enhancing**|Yiwen Duan et.al.|[2411.06767v1](http://arxiv.org/abs/2411.06767v1)|null|
|**2024-11-11**|**KLCBL: An Improved Police Incident Classification Model**|Liu Zhuoxian et.al.|[2411.06749v1](http://arxiv.org/abs/2411.06749v1)|null|
|**2024-11-11**|**Dockformer: A transformer-based molecular docking paradigm for large-scale virtual screening**|Zhangfan Yang et.al.|[2411.06740v1](http://arxiv.org/abs/2411.06740v1)|null|
|**2024-11-11**|**Multi-Modal Forecaster: Jointly Predicting Time Series and Textual Data**|Kai Kim et.al.|[2411.06735v1](http://arxiv.org/abs/2411.06735v1)|null|
|**2024-11-11**|**Reverse Prompt Engineering**|Hanqing Li et.al.|[2411.06729v1](http://arxiv.org/abs/2411.06729v1)|null|
|**2024-11-11**|**Script-Strategy Aligned Generation: Aligning LLMs with Expert-Crafted Dialogue Scripts and Therapeutic Strategies for Psychotherapy**|Xin Sun et.al.|[2411.06723v1](http://arxiv.org/abs/2411.06723v1)|null|
|**2024-11-11**|**Synthesize, Partition, then Adapt: Eliciting Diverse Samples from Foundation Models**|Yeming Wen et.al.|[2411.06722v1](http://arxiv.org/abs/2411.06722v1)|null|
|**2024-11-11**|**DiffSR: Learning Radar Reflectivity Synthesis via Diffusion Model from Satellite Observations**|Xuming He et.al.|[2411.06714v1](http://arxiv.org/abs/2411.06714v1)|null|
|**2024-11-11**|**Ambient AI Scribing Support: Comparing the Performance of Specialized AI Agentic Architecture to Leading Foundational Models**|Chanseo Lee et.al.|[2411.06713v1](http://arxiv.org/abs/2411.06713v1)|null|
|**2024-11-11**|**Model Fusion through Bayesian Optimization in Language Model Fine-Tuning**|Chaeyun Jang et.al.|[2411.06710v1](http://arxiv.org/abs/2411.06710v1)|[link](https://github.com/chaeyoon-jang/bomf)|
|**2024-11-11**|**Autonomous Droplet Microfluidic Design Framework with Large Language Models**|Dinh-Nguyen Nguyen et.al.|[2411.06691v1](http://arxiv.org/abs/2411.06691v1)|null|
|**2024-11-11**|**WDMoE: Wireless Distributed Mixture of Experts for Large Language Models**|Nan Xue et.al.|[2411.06681v1](http://arxiv.org/abs/2411.06681v1)|null|
|**2024-11-11**|**What Should Baby Models Read? Exploring Sample-Efficient Data Composition on Model Performance**|Hong Meng Yam et.al.|[2411.06672v1](http://arxiv.org/abs/2411.06672v1)|null|
|**2024-11-11**|**Adversarial Detection with a Dynamically Stable System**|Xiaowei Long et.al.|[2411.06666v1](http://arxiv.org/abs/2411.06666v1)|null|
|**2024-11-11**|**Bridge: A Unified Framework to Knowledge Graph Completion via Language Models and Knowledge Representation**|Qiao Qiao et.al.|[2411.06660v1](http://arxiv.org/abs/2411.06660v1)|null|
|**2024-11-11**|**An Efficient Memory Module for Graph Few-Shot Class-Incremental Learning**|Dong Li et.al.|[2411.06659v1](http://arxiv.org/abs/2411.06659v1)|[link](https://github.com/arvin0313/mecoin-gfscil)|
|**2024-11-11**|**Renaissance: Investigating the Pretraining of Vision-Language Encoders**|Clayton Fields et.al.|[2411.06657v1](http://arxiv.org/abs/2411.06657v1)|[link](https://github.com/bsu-slim/renaissance)|
|**2024-11-11**|**Explore the Reasoning Capability of LLMs in the Chess Testbed**|Shu Wang et.al.|[2411.06655v1](http://arxiv.org/abs/2411.06655v1)|null|
|**2024-11-11**|**Understanding Scaling Laws with Statistical and Approximation Theory for Transformer Neural Networks on Intrinsically Low-dimensional Data**|Alex Havrilla et.al.|[2411.06646v1](http://arxiv.org/abs/2411.06646v1)|[link](https://github.com/dahoas/transformer_manifolds_learning)|
|**2024-11-11**|**Predicting Country Instability Using Bayesian Deep Learning and Random Forest**|Adam Zebrowski et.al.|[2411.06639v1](http://arxiv.org/abs/2411.06639v1)|null|
|**2024-11-11**|**Model Editing for LLMs4Code: How Far are We?**|Xiaopeng Li et.al.|[2411.06638v1](http://arxiv.org/abs/2411.06638v1)|[link](https://github.com/xpq-tech/code-llmedit)|
|**2024-11-10**|**A Review of Fairness and A Practical Guide to Selecting Context-Appropriate Fairness Metrics in Machine Learning**|Caleb J. S. Barr et.al.|[2411.06624v1](http://arxiv.org/abs/2411.06624v1)|null|
|**2024-11-10**|**MEANT: Multimodal Encoder for Antecedent Information**|Benjamin Iyoya Irving et.al.|[2411.06616v1](http://arxiv.org/abs/2411.06616v1)|null|
|**2024-11-10**|**vTune: Verifiable Fine-Tuning for LLMs Through Backdooring**|Eva Zhang et.al.|[2411.06611v1](http://arxiv.org/abs/2411.06611v1)|null|

#### Abstracts
##### **UTMath: Math Evaluation with Unit Test via Reasoning-to-Coding Thoughts**
2411.07240v1 by Bo Yang, Qingping Yang, Runtao Liu

The evaluation of mathematical reasoning capabilities is essential for
advancing Artificial General Intelligence (AGI). While Large Language Models
(LLMs) have shown impressive performance in solving mathematical problems,
existing benchmarks such as GSM8K and MATH present limitations, including
narrow problem definitions with specific numbers and reliance on predetermined
rules that hinder accurate assessments of reasoning and adaptability. This
paper introduces the UTMath Benchmark, which robustly evaluates the models
through extensive unit tests. It consists of 1,053 problems across 9
mathematical domains, with over 68 test cases per problem.We propose an
innovative evaluation framework inspired by unit testing in software
development, focusing on both accuracy and reliability of results. Furthermore,
we introduce the Reasoning-to-Coding of Thoughts (RCoT) approach, which
encourages LLMs to perform explicit reasoning before generating code, leading
to generating more advanced solution and improved performance. Furthermore, we
are releasing not only the UTMath benchmark but also the UTMath-Train training
dataset (more than 70k samples), to support the community in further exploring
mathematical reasoning.

æè¦ï¼è©ä¼°æ¸å­¸æ¨çè½åå°æ¼æ¨é²äººå·¥éç¨æºæ§ (AGI) è³ééè¦ãåç®¡å¤§åèªè¨æ¨¡å (LLM) å¨è§£æ±ºæ¸å­¸åé¡æ¹é¢è¡¨ç¾åºè²ï¼ä½ç¾æçåºæºå¦ GSM8K å MATH å­å¨å±éæ§ï¼åæ¬åé¡å®ç¾©ç¹éï¼ä½¿ç¨ç¹å®æ¸å­ï¼ä»¥åä¾è³´æ¼é åç¢ºå®çè¦åï¼éäºè¦åé»ç¤äºå°æ¨çåé©ææ§çæºç¢ºè©ä¼°ãæ¬æä»ç´¹äº UTMath åºæºï¼å®ééå»£æ³çå®åæ¸¬è©¦å°æ¨¡åé²è¡äºç©©å¥çè©ä¼°ãå®åå« 9 åæ¸å­¸é åç 1,053 ååé¡ï¼æ¯ååé¡æè¶é 68 åæ¸¬è©¦ç¨ä¾ãæåæåºäºä¸ååµæ°çè©ä¼°æ¡æ¶ï¼éæä¾èªè»é«éç¼ä¸­çå®åæ¸¬è©¦ï¼éé»éæ³¨çµæçæºç¢ºæ§åå¯é æ§ãæ­¤å¤ï¼æåå¼å¥äºææ³æ¨çå°ç·¨ç¢¼ (RCoT) æ¹æ³ï¼å®é¼åµ LLM å¨çæä»£ç¢¼ä¹åå·è¡æç¢ºæ¨çï¼å¾èçææ´é«ç´çè§£æ±ºæ¹æ¡åæ¹é²æ§è½ãæ­¤å¤ï¼æåä¸åç¼å¸äº UTMath åºæºï¼éç¼å¸äº UTMath-Train è¨ç·´æ¸æéï¼è¶é 70k åæ¨£æ¬ï¼ï¼ä»¥æ¯æç¤¾ç¾¤é²ä¸æ­¥æ¢ç´¢æ¸å­¸æ¨çã

##### **OpenThaiGPT 1.5: A Thai-Centric Open Source Large Language Model**
2411.07238v1 by Sumeth Yuenyong, Kobkrit Viriyayudhakorn, Apivadee Piyatumrong, Jillaphat Jaroenkantasima

OpenThaiGPT 1.5 is an advanced Thai language chat model based on Qwen v2.5,
finetuned on over 2,000,000 Thai instruction pairs. This report provides an
engineering perspective on the model's development, capabilities, and
performance. We discuss the model's architecture, training process, and key
features, including multi-turn conversation support, Retrieval Augmented
Generation (RAG) compatibility, and tool-calling functionality. Benchmark
results demonstrate OpenThaiGPT 1.5's state-of-the-art performance on various
Thai language tasks, outperforming other open-source Thai language models. We
also address practical considerations such as GPU memory requirements and
deployment strategies.

æè¦ï¼OpenThaiGPT 1.5 æ¯ä¸æ¬¾é²éçæ³°èªèå¤©æ¨¡åï¼åºæ¼ Qwen v2.5ï¼ç¶éå¾®èª¿ï¼è¶é 2,000,000 çµæ³°èªæä»¤ãæ¬å ±åæä¾äºæ¨¡åéç¼ãåè½åæè½çå·¥ç¨è§é»ãæåè¨è«äºæ¨¡åçæ¶æ§ãè¨ç·´æµç¨åä¸»è¦åè½ï¼åæ¬å¤ååå°è©±æ¯æ´ãæª¢ç´¢æ´å¢çæ (RAG) ç¸å®¹æ§ï¼ä»¥åå·¥å·å¼å«åè½ãåºæºæ¸¬è©¦çµæè­æ OpenThaiGPT 1.5 å¨åç¨®æ³°èªä»»åä¸è¡¨ç¾åºæåé²çæè½ï¼åªæ¼å¶ä»éæºæ³°èªæ¨¡åãæåä¹è§£æ±ºäºå¯¦éèéï¼ä¾å¦ GPU è¨æ¶é«éæ±åé¨ç½²ç­ç¥ã

##### **Contextualized Evaluations: Taking the Guesswork Out of Language Model Evaluations**
2411.07237v1 by Chaitanya Malaviya, Joseph Chee Chang, Dan Roth, Mohit Iyyer, Mark Yatskar, Kyle Lo

Language model users often issue queries that lack specification, where the
context under which a query was issued -- such as the user's identity, the
query's intent, and the criteria for a response to be useful -- is not
explicit. For instance, a good response to a subjective query like "What book
should I read next?" would depend on the user's preferences, and a good
response to an open-ended query like "How do antibiotics work against
bacteria?" would depend on the user's expertise. This makes evaluation of
responses to such queries an ill-posed task, as evaluators may make arbitrary
judgments about the response quality. To remedy this, we present contextualized
evaluations, a protocol that synthetically constructs context surrounding an
underspecified query and provides it during evaluation. We find that the
presence of context can 1) alter conclusions drawn from evaluation, even
flipping win rates between model pairs, 2) nudge evaluators to make fewer
judgments based on surface-level criteria, like style, and 3) provide new
insights about model behavior across diverse contexts. Specifically, our
procedure uncovers an implicit bias towards WEIRD contexts in models' "default"
responses and we find that models are not equally sensitive to following
different contexts, even when they are provided in prompts.

æè¦ï¼èªè¨æ¨¡åä½¿ç¨èç¶å¸¸ç¼åºç¼ºä¹è¦ç¯çæ¥è©¢ï¼å¶ä¸­ç¼åºæ¥è©¢çèæ¯ï¼ä¾å¦ä½¿ç¨èçèº«åãæ¥è©¢çæåä»¥ååææç¨çæ¨æºï¼æªæç¢ºèªªæãä¾å¦ï¼å°æ¼ãæä¸ä¸æ­¥è©²è®ä»éº¼æ¸ï¼ãéé¡ä¸»è§æ¥è©¢çè¯å¥½åææåæ±ºæ¼ä½¿ç¨èçåå¥½ï¼èå°æ¼ãæçç´ å¦ä½å°æç´°èï¼ãéé¡éæ¾å¼æ¥è©¢çè¯å¥½åææåæ±ºæ¼ä½¿ç¨èçå°æ¥­ç¥è­ãéä½¿å¾è©ä¼°æ­¤é¡æ¥è©¢çåææçºä¸é é£ä»¥è§£æ±ºçä»»åï¼å çºè©ä¼°èå¯è½æå°åæåè³ªååºæ­¦æ·çå¤æ·ãçºäºè£æéä¸é»ï¼æåæåºäºæå¢åè©ä¼°ï¼éæ¯ä¸ç¨®åå®ï¼å¯ä»¥åææ§é åºæªæç¢ºæå®æ¥è©¢å¨åçèæ¯ï¼ä¸¦å¨è©ä¼°æéæä¾èæ¯ãæåç¼ç¾èæ¯çå­å¨å¯ä»¥ 1) æ¹è®å¾è©ä¼°ä¸­å¾åºççµè«ï¼çè³æé¡åæ¨¡åéå°ä¹éçç²åçï¼2) ä¿ä½¿è©ä¼°èæ ¹æè¡¨é¢å±¤æ¨æºï¼ä¾å¦é¢¨æ ¼ï¼ååºè¼å°çå¤æ·ï¼ä»¥å 3) æä¾éæ¼æ¨¡åå¨ä¸åèæ¯ä¸çè¡çºçæ°è¦è§£ãå·é«ä¾èªªï¼æåçç¨åºæ­ç¤ºäºæ¨¡åãé è¨­ãåæä¸­å° WEIRD èæ¯çé±å«åè¦ï¼æåç¼ç¾æ¨¡åå°æ¼éµå¾ªä¸åçèæ¯ä¸¦éåæ¨£ææï¼å³ä½¿éäºèæ¯æ¯å¨æç¤ºä¸­æä¾çã

##### **Add-it: Training-Free Object Insertion in Images With Pretrained Diffusion Models**
2411.07232v1 by Yoad Tewel, Rinon Gal, Dvir Samuel Yuval Atzmon, Lior Wolf, Gal Chechik

Adding Object into images based on text instructions is a challenging task in
semantic image editing, requiring a balance between preserving the original
scene and seamlessly integrating the new object in a fitting location. Despite
extensive efforts, existing models often struggle with this balance,
particularly with finding a natural location for adding an object in complex
scenes. We introduce Add-it, a training-free approach that extends diffusion
models' attention mechanisms to incorporate information from three key sources:
the scene image, the text prompt, and the generated image itself. Our weighted
extended-attention mechanism maintains structural consistency and fine details
while ensuring natural object placement. Without task-specific fine-tuning,
Add-it achieves state-of-the-art results on both real and generated image
insertion benchmarks, including our newly constructed "Additing Affordance
Benchmark" for evaluating object placement plausibility, outperforming
supervised methods. Human evaluations show that Add-it is preferred in over 80%
of cases, and it also demonstrates improvements in various automated metrics.

æè¦ï¼å¨è¯­ä¹å¾åç¼è¾ä¸­ï¼æ ¹æ®ææ¬æä»¤å°å¯¹è±¡æ·»å å°å¾åæ¯ä¸é¡¹å·ææææ§çä»»å¡ï¼éè¦å¨ä¿çåå§åºæ¯åå°æ°å¯¹è±¡æ ç¼éæå°åéä½ç½®ä¹é´åå¾å¹³è¡¡ãå°½ç®¡ä»åºäºå·¨å¤§çåªåï¼ä½ç°ææ¨¡åéå¸¸é¾ä»¥è¾¾å°è¿ç§å¹³è¡¡ï¼å°¤å¶æ¯å¨å¤æåºæ¯ä¸­ä¸ºæ·»å å¯¹è±¡æ¾å°èªç¶ä½ç½®æ¶ãæä»¬å¼å¥äº Add-itï¼è¿æ¯ä¸ç§æ è®­ç»æ¹æ³ï¼å®æ©å±äºæ©æ£æ¨¡åçæ³¨ææºå¶ï¼ä»¥çº³å¥æ¥èªä¸ä¸ªå³é®æ¥æºçä¿¡æ¯ï¼åºæ¯å¾åãææ¬æç¤ºåçæå¾åæ¬èº«ãæä»¬å æçæ©å±æ³¨ææºå¶ä¿æäºç»æä¸è´æ§åç²¾ç»ç»èï¼åæ¶ç¡®ä¿äºèªç¶çç©ä½æ¾ç½®ãå¨æ²¡æéå¯¹ç¹å®ä»»å¡è¿è¡å¾®è°çæåµä¸ï¼Add-it å¨çå®åçæå¾åæå¥åºåä¸é½åå¾äºæåè¿çç»æï¼åæ¬æä»¬æ°æå»ºçâæ·»å è½ååºåâï¼ç¨äºè¯ä¼°å¯¹è±¡æ¾ç½®çåçæ§ï¼ä¼äºçç£æ¹æ³ãäººç±»è¯ä¼°è¡¨æï¼å¨ 80% ä»¥ä¸çæåµä¸æ´åæ¬¢ Add-itï¼å¹¶ä¸å®è¿å±ç¤ºäºåç§èªå¨åææ çæ¹è¿ã

##### **Tooling or Not Tooling? The Impact of Tools on Language Agents for Chemistry Problem Solving**
2411.07228v1 by Botao Yu, Frazier N. Baker, Ziru Chen, Garrett Herb, Boyu Gou, Daniel Adu-Ampratwum, Xia Ning, Huan Sun

To enhance large language models (LLMs) for chemistry problem solving,
several LLM-based agents augmented with tools have been proposed, such as
ChemCrow and Coscientist. However, their evaluations are narrow in scope,
leaving a large gap in understanding the benefits of tools across diverse
chemistry tasks. To bridge this gap, we develop ChemAgent, an enhanced
chemistry agent over ChemCrow, and conduct a comprehensive evaluation of its
performance on both specialized chemistry tasks and general chemistry
questions. Surprisingly, ChemAgent does not consistently outperform its base
LLMs without tools. Our error analysis with a chemistry expert suggests that:
For specialized chemistry tasks, such as synthesis prediction, we should
augment agents with specialized tools; however, for general chemistry questions
like those in exams, agents' ability to reason correctly with chemistry
knowledge matters more, and tool augmentation does not always help.

æè¦ï¼çºäºå¢å¼·å¤§åèªè¨æ¨¡åï¼LLMï¼å¨åå­¸åé¡æ±è§£æ¹é¢çè½åï¼å·²ç¶æåºäºå¤ç¨®å·åå·¥å·å¢å¼·åè½ç LLM åºç¤ä»£çï¼ä¾å¦ ChemCrow å Coscientistãç¶èï¼å®åçè©ä¼°ç¯åç¹çªï¼å¨äºè§£å·¥å·å¨åç¨®åå­¸ä»»åä¸­çå¥½èæ¹é¢çä¸äºå¾å¤§çç©ºç½ãçºäºå½è£éåå·®è·ï¼æåéç¼äº ChemAgentï¼éæ¯ä¸åæ¯ ChemCrow æ´å¼·å¤§çåå­¸ä»£çï¼ä¸¦å°å¶å¨å°æ¥­åå­¸ä»»ååä¸è¬åå­¸åé¡ä¸çæ§è½é²è¡äºå¨é¢è©ä¼°ãä»¤äººé©è¨çæ¯ï¼ChemAgent ä¸¦æ²æå§çµåªæ¼æ²æå·¥å·çåºç¤ LLMãæåèåå­¸å°å®¶çé¯èª¤åæè¡¨æï¼å°æ¼åæé æ¸¬ç­å°æ¥­åå­¸ä»»åï¼æåæè©²ç¨å°æ¥­å·¥å·ä¾å¢å¼·ä»£çï¼ç¶èï¼å°æ¼èè©¦ä¸­åºç¾çé¡ä¼¼ä¸è¬åå­¸åé¡ï¼ä»£çæ­£ç¢ºæ¨çåå­¸ç¥è­çè½åæ´éè¦ï¼èå·¥å·å¢å¼·ä¸¦ä¸ç¸½æ¯è½æä¾å¹«å©ã

##### **TempCharBERT: Keystroke Dynamics for Continuous Access Control Based on Pre-trained Language Models**
2411.07224v1 by Matheus SimÃ£o, Fabiano Prado, Omar Abdul Wahab, Anderson Avila

With the widespread of digital environments, reliable authentication and
continuous access control has become crucial. It can minimize cyber attacks and
prevent frauds, specially those associated with identity theft. A particular
interest lies on keystroke dynamics (KD), which refers to the task of
recognizing individuals' identity based on their unique typing style. In this
work, we propose the use of pre-trained language models (PLMs) to recognize
such patterns. Although PLMs have shown high performance on multiple NLP
benchmarks, the use of these models on specific tasks requires customization.
BERT and RoBERTa, for instance, rely on subword tokenization, and they cannot
be directly applied to KD, which requires temporal-character information to
recognize users. Recent character-aware PLMs are able to process both subwords
and character-level information and can be an alternative solution.
Notwithstanding, they are still not suitable to be directly fine-tuned for KD
as they are not optimized to account for user's temporal typing information
(e.g., hold time and flight time). To overcome this limitation, we propose
TempCharBERT, an architecture that incorporates temporal-character information
in the embedding layer of CharBERT. This allows modeling keystroke dynamics for
the purpose of user identification and authentication. Our results show a
significant improvement with this customization. We also showed the feasibility
of training TempCharBERT on a federated learning settings in order to foster
data privacy.

æè¦ï¼é¨èæ¸ä½ç°å¢çæ®åï¼å¯é çèº«åé©è­åæçºçå­åæ§å¶å·²è®å¾è³ééè¦ãéå¯ä»¥å°ç¶²è·¯æ»æéè³æä½ï¼ä¸¦é²æ­¢è©é¨ï¼ç¹å¥æ¯èèº«åç«åç¸éçè©é¨ãä¸åç¹å¥çèè¶£å¨æ¼éµç¤åæ (KD)ï¼éæ¯ææ ¹æåäººç¨ç¹çè¼¸å¥é¢¨æ ¼ä¾è­å¥åäººèº«åçä»»åãå¨éé å·¥ä½ä¸­ï¼æåæåºä½¿ç¨é åè¨ç·´å¥½çèªè¨æ¨¡å (PLM) ä¾è­å¥éç¨®æ¨¡å¼ãåç®¡ PLM å¨å¤å NLP åºæºæ¸¬è©¦ä¸­è¡¨ç¾åºé«æ§è½ï¼ä½å°éäºæ¨¡åç¨æ¼ç¹å®ä»»åéè¦èªè¨ãä¾å¦ï¼BERT å RoBERTa ä¾è³´æ¼å­å­è©åï¼å®åç¡æ³ç´æ¥æç¨æ¼ KDï¼è KD éè¦æéå­åè³è¨ä¾è­å¥ä½¿ç¨èãæè¿çå­åæç¥ PLM è½å¤ èçå­å­è©åå­åå±¤ç´çè³è¨ï¼ä¸¦ä¸å¯ä»¥ä½çºæ¿ä»£æ¹æ¡ãåç®¡å¦æ­¤ï¼å®åä»ç¶ä¸é©åç´æ¥å¾®èª¿ KDï¼å çºå®åä¸¦æªéå°ä½¿ç¨èçæéè¼¸å¥è³è¨ï¼ä¾å¦ï¼æä½æéåé£è¡æéï¼é²è¡æä½³åãçºäºåæéåéå¶ï¼æåæåºäº TempCharBERTï¼éæ¯ä¸ç¨®å°æéå­åè³è¨ç´å¥ CharBERT åµå¥å±¤çæ¶æ§ãéåè¨±çºä½¿ç¨èè­å¥åé©è­çç®çå»ºæ¨¡éµç¤åæãæåççµæé¡¯ç¤ºï¼éééåèªè¨æé¡¯èçæ¹åãæåä¹å±ç¤ºäºå¨è¯åå­¸ç¿è¨­å®ä¸­è¨ç·´ TempCharBERT çå¯è¡æ§ï¼ä»¥ä¿é²è³æé±ç§ã

##### **Grounding Video Models to Actions through Goal Conditioned Exploration**
2411.07223v1 by Yunhao Luo, Yilun Du

Large video models, pretrained on massive amounts of Internet video, provide
a rich source of physical knowledge about the dynamics and motions of objects
and tasks. However, video models are not grounded in the embodiment of an
agent, and do not describe how to actuate the world to reach the visual states
depicted in a video. To tackle this problem, current methods use a separate
vision-based inverse dynamic model trained on embodiment-specific data to map
image states to actions. Gathering data to train such a model is often
expensive and challenging, and this model is limited to visual settings similar
to the ones in which data are available. In this paper, we investigate how to
directly ground video models to continuous actions through self-exploration in
the embodied environment -- using generated video states as visual goals for
exploration. We propose a framework that uses trajectory level action
generation in combination with video guidance to enable an agent to solve
complex tasks without any external supervision, e.g., rewards, action labels,
or segmentation masks. We validate the proposed approach on 8 tasks in Libero,
6 tasks in MetaWorld, 4 tasks in Calvin, and 12 tasks in iThor Visual
Navigation. We show how our approach is on par with or even surpasses multiple
behavior cloning baselines trained on expert demonstrations while without
requiring any action annotations.

æè¦ï¼å¤§åè§é¢æ¨¡åç»è¿å¤§éäºèç½è§é¢é¢è®­ç»ï¼æä¾äºå³äºç©ä½åä»»å¡çå¨æåè¿å¨çä¸°å¯ç©çç¥è¯ãç¶èï¼è§é¢æ¨¡åå¹¶æ²¡æå»ºç«å¨ä»£ççä½ç°ä¸­ï¼ä¹æ²¡ææè¿°å¦ä½å¯å¨ä¸çä»¥è¾¾å°è§é¢ä¸­æç»çè§è§ç¶æãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼å½åçæ¹æ³ä½¿ç¨ä¸ä¸ªåç¬çåºäºè§è§çååå¨ææ¨¡åï¼è¯¥æ¨¡åå¨ç¹å®äºä½ç°çæ°æ®ä¸è¿è¡è®­ç»ï¼ä»¥å°å¾åç¶ææ å°å°å¨ä½ãæ¶éæ°æ®æ¥è®­ç»è¿æ ·ä¸ä¸ªæ¨¡åéå¸¸æ¢æè´µåå·ææææ§ï¼å¹¶ä¸è¯¥æ¨¡åä»éäºä¸æ°æ®å¯ç¨çæ¨¡åç±»ä¼¼çè§è§è®¾ç½®ãå¨æ¬æä¸­ï¼æä»¬ç ç©¶å¦ä½éè¿å¨å·èº«ç¯å¢ä¸­è¿è¡èªææ¢ç´¢ï¼å°è§é¢æ¨¡åç´æ¥å½ç»ä¸ºè¿ç»­å¨ä½ââä½¿ç¨çæçè§é¢ç¶æä½ä¸ºæ¢ç´¢çè§è§ç®æ ãæä»¬æåºä¸ä¸ªæ¡æ¶ï¼è¯¥æ¡æ¶ç»åä½¿ç¨è½¨è¿¹çº§å«å¨ä½çæåè§é¢æå¯¼ï¼ä½¿ä»£çè½å¤å¨æ²¡æä»»ä½å¤é¨çç£ï¼ä¾å¦å¥å±ãå¨ä½æ ç­¾æåå²æ©ç ï¼çæåµä¸è§£å³å¤æçä»»å¡ãæä»¬å¨ Libero ä¸­ç 8 ä¸ªä»»å¡ãMetaWorld ä¸­ç 6 ä¸ªä»»å¡ãCalvin ä¸­ç 4 ä¸ªä»»å¡å iThor Visual Navigation ä¸­ç 12 ä¸ªä»»å¡ä¸éªè¯äºææåºçæ¹æ³ãæä»¬å±ç¤ºäºæä»¬çæ¹æ³å¦ä½ä¸å¨ä¸å®¶æ¼ç¤ºä¸­è®­ç»çå¤ä¸ªè¡ä¸ºåéåºçº¿ç¸å½çè³è¶è¿å®ä»¬ï¼èä¸éè¦ä»»ä½å¨ä½æ³¨éã

##### **TreeCoders: Trees of Transformers**
2411.07218v1 by Pierre Colonna D'Istria, Abdulrahman Altahhan

In this paper, we introduce TreeCoders, a novel family of transformer trees.
We moved away from traditional linear transformers to complete k-ary trees.
Transformer blocks serve as nodes, and generic classifiers learn to select the
best child and route the sequence of tokens to a specific leaf. The selectors,
moved outside the transformer blocks, allow for the use of a variety of
architecture without further modifications. Furthermore, our proposed
architecture supports sparse node activation due to the logarithmic complexity
of a tree search. We validate our idea by testing a series of decoder-only tree
transformers, achieving competitive results across a diverse range of language
datasets. Our study demonstrates that the proposed tree transformer model
outperforms a size-equivalent linear transformer model 76\% of the time over a
wide range of tree architectures. Furthermore, our proposed model naturally
lends itself to distributed implementation.

æè¦ï¼å¨æ¬æä¸­ï¼æåä»ç´¹äº TreeCodersï¼ä¸ç¨®æ°ç©çTransformeræ¨¹ç³»åã
æåå¾å³çµ±ç·æ§Transformerè½ç§»å°å®æ k åæ¨¹ã
Transformeråå¡ä½çºç¯é»ï¼éç¨åé¡å¨å­¸ç¿é¸æ
æä½³å­ç¯é»ä¸¦å°åºåæ¨è¨è·¯ç±å°ç¹å®èç¯é»ãé¸æå¨ï¼
ç§»å°Transformeråå¡å¤é¨ï¼åè¨±ä½¿ç¨åç¨®
æ¶æ§èç¡éé²ä¸æ­¥ä¿®æ¹ãæ­¤å¤ï¼æåæåºç
æ¶æ§æ¯æ´ç¨çç¯é»åç¨ï¼å çºæ¨¹æå°å°æ¸è¤éåº¦ãæåé©è­æåçæ³æ³ï¼æ¹æ³æ¯æ¸¬è©¦ä¸ç³»ååè§£ç¢¼å¨æ¨¹
Transformerï¼å¨åç¨®èªè¨ä¸­å¯¦ç¾ç«¶ç­çµæ
è³æéãæåçç ç©¶è¡¨æï¼ææåºçæ¨¹Transformeræ¨¡å
å¨å»£æ³çæ¨¹æ¶æ§ä¸­ï¼76% çæéåªæ¼å¤§å°ç¸ç¶çç·æ§Transformeræ¨¡åãæ­¤å¤ï¼æåæåºçæ¨¡åèªç¶
é©ç¨æ¼åæ£å¼å¯¦ä½ã

##### **OmniEdit: Building Image Editing Generalist Models Through Specialist Supervision**
2411.07199v1 by Cong Wei, Zheyang Xiong, Weiming Ren, Xinrun Du, Ge Zhang, Wenhu Chen

Instruction-guided image editing methods have demonstrated significant
potential by training diffusion models on automatically synthesized or manually
annotated image editing pairs. However, these methods remain far from
practical, real-life applications. We identify three primary challenges
contributing to this gap. Firstly, existing models have limited editing skills
due to the biased synthesis process. Secondly, these methods are trained with
datasets with a high volume of noise and artifacts. This is due to the
application of simple filtering methods like CLIP-score. Thirdly, all these
datasets are restricted to a single low resolution and fixed aspect ratio,
limiting the versatility to handle real-world use cases. In this paper, we
present \omniedit, which is an omnipotent editor to handle seven different
image editing tasks with any aspect ratio seamlessly. Our contribution is in
four folds: (1) \omniedit is trained by utilizing the supervision from seven
different specialist models to ensure task coverage. (2) we utilize importance
sampling based on the scores provided by large multimodal models (like GPT-4o)
instead of CLIP-score to improve the data quality. (3) we propose a new editing
architecture called EditNet to greatly boost the editing success rate, (4) we
provide images with different aspect ratios to ensure that our model can handle
any image in the wild. We have curated a test set containing images of
different aspect ratios, accompanied by diverse instructions to cover different
tasks. Both automatic evaluation and human evaluations demonstrate that
\omniedit can significantly outperform all the existing models. Our code,
dataset and model will be available at
\url{https://tiger-ai-lab.github.io/OmniEdit/}

æè¦ï¼<paragraph>ä»¥æä»¤çºå°åçå½±åç·¨è¼¯æ¹æ³å·²å±ç¾åºé¡¯èçæ½åï¼æ¹æ³æ¯è¨ç·´æ´æ£æ¨¡åæ¼èªååæææåæ¨è¨»çå½±åç·¨è¼¯éå°ä¸ãç¶èï¼éäºæ¹æ³ä»é é¢å¯¦åä¸çå¯¦éæç¨ãæåæ¾åºå°è´æ­¤å·®è·çä¸åä¸»è¦ææ°ãé¦åï¼ç¾æçæ¨¡åç±æ¼æåå·®çåæç¨åºï¼å°è´ç·¨è¼¯æè½åéãå¶æ¬¡ï¼éäºæ¹æ³ä½¿ç¨åå«å¤§ééè¨åäººå·¥è£½åçè³æéé²è¡è¨ç·´ãéæ¯ç±æ¼æç¨å CLIP åæ¸ä¹é¡çç°¡å®éæ¿¾æ¹æ³æè´ãç¬¬ä¸ï¼ææéäºè³æéé½éå¶æ¼å®ä¸ä½è§£æåº¦ååºå®é·å¯¬æ¯ï¼éå¶äºèçå¯¦éç¨ä¾çå¤åè½æ§ãå¨æ¬æä¸­ï¼æåæåº \omnieditï¼éæ¯ä¸åè¬è½ç·¨è¼¯å¨ï¼å¯ç¡ç¸«èçä¸ç¨®ä¸åçå½±åç·¨è¼¯ä»»åï¼ä¸ä¸éé·å¯¬æ¯ãæåçè²¢ç»æååé¢åï¼(1) \omniedit ééå©ç¨ä¾èªä¸ç¨®ä¸åå°å®¶æ¨¡åçç£ç£é²è¡è¨ç·´ï¼ä»¥ç¢ºä¿ä»»åæ¶µèç¯åã(2) æåå©ç¨å¤§åå¤æ¨¡ææ¨¡å (ä¾å¦ GPT-4o) ææä¾çåæ¸ï¼èä¸æ¯ CLIP åæ¸ï¼ä¾é²è¡éè¦æ§æ½æ¨£ï¼ä»¥æåè³æåè³ªã(3) æåæåºä¸ååçº EditNet çæ°ç·¨è¼¯æ¶æ§ï¼ä»¥å¤§å¹æåç·¨è¼¯æåçï¼(4) æåæä¾å·æä¸åé·å¯¬æ¯çå½±åï¼ä»¥ç¢ºä¿æåçæ¨¡åè½å¤ èçä»»ä½éå¤å½±åãæåç­åäºä¸ååå«ä¸åé·å¯¬æ¯å½±åçæ¸¬è©¦éï¼ä¸¦éæä¸åçæä»¤ä¾æ¶µèä¸åçä»»åãèªåè©ä¼°åäººå·¥è©ä¼°åé¡¯ç¤ºï¼\omniedit è½é¡¯èåªæ¼ææç¾ææ¨¡åãæåçç¨å¼ç¢¼ãè³æéåæ¨¡åå°æå¨ \url{https://tiger-ai-lab.github.io/OmniEdit/} æä¾ã</paragraph>

##### **The Super Weight in Large Language Models**
2411.07191v1 by Mengxia Yu, De Wang, Qi Shan, Colorado Reed, Alvin Wan

Recent works have shown a surprising result: a small fraction of Large
Language Model (LLM) parameter outliers are disproportionately important to the
quality of the model. LLMs contain billions of parameters, so these small
fractions, such as 0.01%, translate to hundreds of thousands of parameters. In
this work, we present an even more surprising finding: Pruning as few as a
single parameter can destroy an LLM's ability to generate text -- increasing
perplexity by 3 orders of magnitude and reducing zero-shot accuracy to
guessing. We propose a data-free method for identifying such parameters, termed
super weights, using a single forward pass through the model. We additionally
find that these super weights induce correspondingly rare and large activation
outliers, termed super activations. When preserved with high precision, super
activations can improve simple round-to-nearest quantization to become
competitive with state-of-the-art methods. For weight quantization, we
similarly find that by preserving the super weight and clipping other weight
outliers, round-to-nearest quantization can scale to much larger block sizes
than previously considered. To facilitate further research into super weights,
we provide an index of super weight coordinates for common, openly available
LLMs.

æè¦ï¼<paragraph>æè¿çç ç©¶æ¾ç¤ºäºä¸ä¸ªä»¤äººæè®¶çç»æï¼å¤§åè¯­è¨æ¨¡å (LLM) åæ°å¼å¸¸å¼çä¸å°é¨åå¯¹äºæ¨¡åçè´¨éè³å³éè¦ãLLM åå«æ°åäº¿ä¸ªåæ°ï¼å æ­¤è¿äºå°é¨åï¼ä¾å¦ 0.01%ï¼è½¬æ¢ä¸ºæ°åä¸ä¸ªåæ°ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬æåºäºä¸ä¸ªæ´ä»¤äººæè®¶çåç°ï¼ä¿®åªä¸ä¸ªåæ°å°±å¯ä»¥ç ´å LLM çæææ¬çè½åââå°æåº¦å¢å äº 3 ä¸ªæ°éçº§ï¼å¹¶å°é¶æ¬¡ç²¾åº¦éä½å°çæµãæä»¬æåºäºä¸ç§æ æ°æ®çæ¹æ³æ¥è¯å«è¿äºåæ°ï¼ç§°ä¸ºè¶çº§æéï¼ä½¿ç¨åä¸ªååä¼ ééè¿æ¨¡åãæä»¬è¿åç°ï¼è¿äºè¶çº§æéè¯±å¯¼äºç¸åºç½è§ä¸å¤§çæ¿æ´»å¼å¸¸å¼ï¼ç§°ä¸ºè¶çº§æ¿æ´»ãå½ä»¥é«ç²¾åº¦ä¿çæ¶ï¼è¶çº§æ¿æ´»å¯ä»¥æ¹åç®åçåèäºå¥éåï¼ä»¥ä¸æåè¿çæ¹æ³ç«äºãå¯¹äºæééåï¼æä»¬åæ ·åç°ï¼éè¿ä¿çè¶çº§æéå¹¶è£åªå¶ä»æéå¼å¸¸å¼ï¼åèäºå¥éåå¯ä»¥æ©å±å°æ¯ä»¥åèèçæ´å¤§çåå¤§å°ãä¸ºäºä¿è¿å¯¹è¶çº§æéçè¿ä¸æ­¥ç ç©¶ï¼æä»¬æä¾äºä¸ä¸ªè¶çº§æéåæ ç´¢å¼ï¼ç¨äºå¸¸è§ä¸å¬å¼å¯ç¨ç LLMã</paragraph>

##### **NatureLM-audio: an Audio-Language Foundation Model for Bioacoustics**
2411.07186v1 by David Robinson, Marius Miron, Masato Hagiwara, Olivier Pietquin

Large language models (LLMs) prompted with text and audio represent the state
of the art in various auditory tasks, including speech, music, and general
audio, showing emergent abilities on unseen tasks. However, these capabilities
have yet to be fully demonstrated in bioacoustics tasks, such as detecting
animal vocalizations in large recordings, classifying rare and endangered
species, and labeling context and behavior - tasks that are crucial for
conservation, biodiversity monitoring, and the study of animal behavior. In
this work, we present NatureLM-audio, the first audio-language foundation model
specifically designed for bioacoustics. Our carefully curated training dataset
comprises text-audio pairs spanning a diverse range of bioacoustics, speech,
and music data, designed to address the challenges posed by limited annotated
datasets in the field. We demonstrate successful transfer of learned
representations from music and speech to bioacoustics, and our model shows
promising generalization to unseen taxa and tasks. Importantly, we test
NatureLM-audio on a novel benchmark (BEANS-Zero) and it sets the new state of
the art (SotA) on several bioacoustics tasks, including zero-shot
classification of unseen species. To advance bioacoustics research, we also
open-source the code for generating training and benchmark data, as well as for
training the model.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ä»¥æå­åé³è¨çºæç¤ºï¼ä»£è¡¨åç¨®è½è¦ºä»»åçææ°æè¡ï¼åæ¬èªé³ãé³æ¨åä¸è¬é³è¨ï¼å¨æªè¦ä»»åä¸­å±ç¾åºæ°èçè½åãç¶èï¼éäºåè½å°æªå¨çç©é³é¿ä»»åä¸­å¾å°ååå±ç¤ºï¼ä¾å¦å¨å¤§åéé³ä¸­åµæ¸¬åç©ç¼è²ãåé¡ç¨æåçè¨çµç¨®çç©ç¨®ï¼ä»¥åæ¨è¨èæ¯åè¡çºï¼éäºä»»åå°æ¼ä¿è²ãçç©å¤æ¨£æ§ç£æ¸¬ååç©è¡çºç ç©¶è³ééè¦ãå¨éé å·¥ä½ä¸­ï¼æåæåº NatureLM-audioï¼éæ¯ç¬¬ä¸åå°éçºçç©é³é¿è¨­è¨çé³è¨èªè¨åºç¤æ¨¡åãæåç²¾å¿ç­åçè¨ç·´è³æéåå«è·¨è¶åç¨®çç©é³é¿ãèªé³åé³æ¨è³æçæå­é³è¨éå°ï¼æ¨å¨è§£æ±ºè©²é åä¸­æ¨è¨»è³æéæéæå¸¶ä¾çææ°ãæåå±ç¤ºäºå¾é³æ¨åèªé³å°çç©é³é¿çå­¸ç¿è¡¨å¾µçæåè½ç§»ï¼èæåçæ¨¡åé¡¯ç¤ºåºå°æªè¦åé¡å®ååä»»åçæåæ¯çæ¦åãéè¦çæ¯ï¼æåå¨ä¸åæ°åºæº (BEANS-Zero) ä¸æ¸¬è©¦ NatureLM-audioï¼å®å¨å¹¾åçç©é³é¿ä»»åä¸è¨­å®äºæ°çæè¡æ°´æº (SotA)ï¼åæ¬æªè¦ç©ç¨®çé¶æ¬¡å­¸ç¿åé¡ãçºäºæ¨é²çç©é³é¿ç ç©¶ï¼æåä¹éæ¾åå§ç¢¼ä¾ç¢çè¨ç·´ååºæºè³æï¼ä»¥åè¨ç·´æ¨¡åã

##### **Gradual Fine-Tuning with Graph Routing for Multi-Source Unsupervised Domain Adaptation**
2411.07185v1 by Yao Ma, Samuel Louvan, Zhunxuan Wang

Multi-source unsupervised domain adaptation aims to leverage labeled data
from multiple source domains for training a machine learning model to
generalize well on a target domain without labels. Source domain selection
plays a crucial role in determining the model's performance. It relies on the
similarities amongst source and target domains. Nonetheless, existing work for
source domain selection often involves heavyweight computational procedures,
especially when dealing with numerous source domains and the need to identify
the best ones from them. In this paper, we introduce a framework for gradual
fine tuning (GFT) of machine learning models on multiple source domains. We
represent multiple source domains as an undirected weighted graph. We then give
a new generalization error bound for GFT along any path within the graph, which
is used to determine the optimal path corresponding to the optimal training
order. With this formulation, we introduce three lightweight graph-routing
strategies which tend to minimize the error bound. Our best strategy improves
$2.3\%$ of accuracy over the state-of-the-art on Natural Language Inference
(NLI) task and achieves competitive performance on Sentiment Analysis (SA)
task, especially a $3.9\%$ improvement on a more diverse subset of data we use
for SA.

æè¦ï¼å¤æºæ çç£åèªéåºæ¨å¨å©ç¨æ¥èªå¤ä¸ªæºåçæ è®°æ°æ®ï¼è®­ç»æºå¨å­¦ä¹ æ¨¡åï¼ä»¥ä¾¿å¨æ²¡ææ ç­¾çç®æ åä¸å¾å¥½å°æ³åãæºåéæ©å¨ç¡®å®æ¨¡åæ§è½æ¹é¢èµ·çè³å³éè¦çä½ç¨ãå®ä¾èµäºæºååç®æ åä¹é´çç¸ä¼¼æ§ãå°½ç®¡å¦æ­¤ï¼ç°æçæºåéæ©å·¥ä½éå¸¸æ¶åééçº§è®¡ç®ç¨åºï¼å°¤å¶æ¯å¨å¤çä¼å¤æºåä»¥åéè¦ä»ä¸­è¯å«æä½³æºåæ¶ãå¨æ¬æä¸­ï¼æä»¬ä»ç»äºä¸ä¸ªå¨å¤ä¸ªæºåä¸å¯¹æºå¨å­¦ä¹ æ¨¡åè¿è¡éæ­¥å¾®è° (GFT) çæ¡æ¶ãæä»¬å°å¤ä¸ªæºåè¡¨ç¤ºä¸ºæ åå æå¾ãç¶åï¼æä»¬ä¸ºå¾ä¸­æ²¿ä»»ä½è·¯å¾ç GFT ç»åºäºä¸ä¸ªæ°çæ³åè¯¯å·®çï¼ç¨äºç¡®å®å¯¹åºäºæä½³è®­ç»é¡ºåºçæä½³è·¯å¾ãéè¿è¿ç§è¡¨è¿°ï¼æä»¬ä»ç»äºä¸ç§è½»éçº§çå¾è·¯ç±ç­ç¥ï¼è¿äºç­ç¥å¾åäºæå°åè¯¯å·®çãæä»¬æå¥½çç­ç¥å¨èªç¶è¯­è¨æ¨ç (NLI) ä»»å¡ä¸æ¯æåè¿çææ¯æé«äº 2.3% çåç¡®çï¼å¹¶å¨ææåæ (SA) ä»»å¡ä¸åå¾äºæç«äºåçæ§è½ï¼ç¹å«æ¯å¨æä»¬ç¨äº SA çæ´å¤æ ·åçæ°æ®å­éä¸æé«äº 3.9%ã

##### **Counterfactual Generation from Language Models**
2411.07180v1 by Shauli Ravfogel, Anej Svete, VÃ©steinn SnÃ¦bjarnarson, Ryan Cotterell

Understanding and manipulating the causal generation mechanisms in language
models is essential for controlling their behavior. Previous work has primarily
relied on techniques such as representation surgery -- e.g., model ablations or
manipulation of linear subspaces tied to specific concepts -- to intervene on
these models. To understand the impact of interventions precisely, it is useful
to examine counterfactuals -- e.g., how a given sentence would have appeared
had it been generated by the model following a specific intervention. We
highlight that counterfactual reasoning is conceptually distinct from
interventions, as articulated in Pearl's causal hierarchy. Based on this
observation, we propose a framework for generating true string counterfactuals
by reformulating language models as Generalized Structural-equation. Models
using the Gumbel-max trick. This allows us to model the joint distribution over
original strings and their counterfactuals resulting from the same
instantiation of the sampling noise. We develop an algorithm based on hindsight
Gumbel sampling that allows us to infer the latent noise variables and generate
counterfactuals of observed strings. Our experiments demonstrate that the
approach produces meaningful counterfactuals while at the same time showing
that commonly used intervention techniques have considerable undesired side
effects.

æè¦ï¼çè§£ä¸¦ææ§èªè¨æ¨¡åä¸­çå æçææ©å¶ï¼å°æ¼æ§å¶å¶è¡çºè³ééè¦ãä»¥å¾çç ç©¶ä¸»è¦ä¾è³´æ¼è¡¨å¾µæè¡ç­æè¡ââä¾å¦ï¼æ¨¡åæ¶èæèç¹å®æ¦å¿µç¸éçç·æ§å­ç©ºéçææ§ââä¾å¹²é éäºæ¨¡åãçºäºç²¾ç¢ºçè§£å¹²é çå½±é¿ï¼å¯©æ¥åäºå¯¦ââä¾å¦ï¼å¦ææ¨¡åå¨ç¹å®å¹²é å¾çæçµ¦å®çå¥å­ï¼å¥å­å°å¦ä½åç¾ââæ¯æç¨çãæåå¼·èª¿ï¼åäºå¯¦æ¨çå¨æ¦å¿µä¸ä¸åæ¼å¹²é ï¼æ­£å¦ Pearl çå æå±¤ç´æé¡è¿°çé£æ¨£ãåºæ¼æ­¤è§å¯ï¼æåæåºäºä¸åçæçæ­£å­ä¸²åäºå¯¦çæ¡æ¶ï¼æ¹æ³æ¯å°èªè¨æ¨¡åéæ°è¡¨è¿°çºå»£ç¾©çµæ§æ¹ç¨æ¨¡åï¼ä½¿ç¨ Gumbel-max æå·§ãéä½¿æåè½å¤ å°åå§å­ä¸²åå¶åäºå¯¦çè¯ååä½å»ºæ¨¡ï¼éäºåäºå¯¦ä¾èªæ¡æ¨£éè¨çç¸åä¾ç¤ºãæåæ ¹æå¾è¦ä¹æ Gumbel æ¡æ¨£éç¼äºä¸ç¨®æ¼ç®æ³ï¼ä½¿æåè½å¤ æ¨æ·æ½å¨éè¨è®æ¸ä¸¦çæå·²è§å¯å­ä¸²çåäºå¯¦ãæåçå¯¦é©è­æï¼è©²æ¹æ³ç¢çææç¾©çåäºå¯¦ï¼åæè¡¨æå¸¸ç¨çå¹²é æè¡å·æç¸ç¶å¤§çä¸è¯å¯ä½ç¨ã

##### **More Expressive Attention with Negative Weights**
2411.07176v1 by Ang Lv, Ruobing Xie, Shuaipeng Li, Jiayi Liao, Xingwu Sun, Zhanhui Kang, Rui Yan

We propose a novel attention mechanism, named Cog Attention, that enables
attention weights to be negative for enhanced expressiveness, which stems from
two key factors: (1) Cog Attention can shift the token deletion and copying
function from a static OV matrix to dynamic QK inner products, with the OV
matrix now focusing more on refinement or modification. The attention head can
simultaneously delete, copy, or retain tokens by assigning them negative,
positive, or minimal attention weights, respectively. As a result, a single
attention head becomes more flexible and expressive. (2) Cog Attention improves
the model's robustness against representational collapse, which can occur when
earlier tokens are over-squashed into later positions, leading to homogeneous
representations. Negative weights reduce effective information paths from
earlier to later tokens, helping to mitigate this issue. We develop
Transformer-like models which use Cog Attention as attention modules, including
decoder-only models for language modeling and U-ViT diffusion models for image
generation. Experiments show that models using Cog Attention exhibit superior
performance compared to those employing traditional softmax attention modules.
Our approach suggests a promising research direction for rethinking and
breaking the entrenched constraints of traditional softmax attention, such as
the requirement for non-negative weights.

æè¦ï¼æåæåºäºä¸ç¨®åçº Cog Attention çæ°æ³¨æåæ©å¶ï¼å®è½è®æ³¨æåæ¬éçºè² æ¸ä»¥å¢å¼·è¡¨éåï¼éæºæ¼å©åééµå ç´ ï¼(1) Cog Attention å¯ä»¥å°ç¬¦èåªé¤åè¤è£½åè½å¾éæ OV ç©é£è½ç§»å°åæ QK å§ç©ï¼è OV ç©é£ç¾å¨æ´å°æ³¨æ¼ç²¾çæä¿®æ¹ãæ³¨æåé ­é¨å¯ä»¥åæåªé¤ãè¤è£½æä¿çç¬¦èï¼åå¥çµ¦å®ååéè² ãæ­£ææå°çæ³¨æåæ¬éãå æ­¤ï¼å®ä¸æ³¨æåé ­é¨è®å¾æ´éæ´»åå¯æè¡¨ç¾åã(2) Cog Attention æé«äºæ¨¡åå°è¡¨å¾µå´©æ½°çç©©å¥æ§ï¼éç¨®ææ³å¯è½ç¼çå¨è¼æ©çç¬¦èéåº¦å£ç¸®å°å¾é¢çä½ç½®æï¼å°è´åè³ªè¡¨å¾µãè² æ¬éæ¸å°äºå¾è¼æ©ç¬¦èå°è¼å¾ç¬¦èçææè³è¨è·¯å¾ï¼æå©æ¼ç·©è§£éååé¡ãæåéç¼äºä½¿ç¨ Cog Attention ä½çºæ³¨æåæ¨¡çµçé¡ Transformer æ¨¡åï¼åæ¬ç¨æ¼èªè¨å»ºæ¨¡çåè§£ç¢¼å¨æ¨¡ååç¨æ¼å½±åçæç U-ViT æ´æ£æ¨¡åãå¯¦é©è¡¨æï¼ä½¿ç¨ Cog Attention çæ¨¡åè¡¨ç¾åºåªæ¼æ¡ç¨å³çµ± softmax æ³¨æåæ¨¡çµçæ¨¡åãæåçåæ³çºéæ°æèåæç ´å³çµ± softmax æ³¨æåçæ ¹æ·±èåºç´æï¼ä¾å¦éè² æ¬éçè¦æ±ï¼æåºäºæå¸æçç ç©¶æ¹åã

##### **Continual Memorization of Factoids in Large Language Models**
2411.07175v1 by Howard Chen, Jiayi Geng, Adithya Bhaskar, Dan Friedman, Danqi Chen

Large language models can absorb a massive amount of knowledge through
pretraining, but pretraining is inefficient for acquiring long-tailed or
specialized facts. Therefore, fine-tuning on specialized or new knowledge that
reflects changes in the world has become popular, though it risks disrupting
the model's original capabilities. We study this fragility in the context of
continual memorization, where the model is trained on a small set of long-tail
factoids (factual associations) and must retain these factoids after multiple
stages of subsequent training on other datasets. Through extensive experiments,
we show that LLMs suffer from forgetting across a wide range of subsequent
tasks, and simple replay techniques do not fully prevent forgetting, especially
when the factoid datasets are trained in the later stages. We posit that there
are two ways to alleviate forgetting: 1) protect the memorization process as
the model learns the factoids, or 2) reduce interference from training in later
stages. With this insight, we develop an effective mitigation strategy: REMIX
(Random and Generic Data Mixing). REMIX prevents forgetting by mixing generic
data sampled from pretraining corpora or even randomly generated word sequences
during each stage, despite being unrelated to the memorized factoids in the
first stage. REMIX can recover performance from severe forgetting, often
outperforming replay-based methods that have access to the factoids from the
first stage. We then analyze how REMIX alters the learning process and find
that successful forgetting prevention is associated with a pattern: the model
stores factoids in earlier layers than usual and diversifies the set of layers
that store these factoids. The efficacy of REMIX invites further investigation
into the underlying dynamics of memorization and forgetting, opening exciting
possibilities for future research.

æè¦ï¼å¤§åèªè¨æ¨¡åå¯ééé è¨ç·´å¸æ¶å¤§éç¥è­ï¼ä½é è¨ç·´å°æ¼ç²åé·å°¾æå°æ¥­ç¥è­èè¨æçä½ä¸ãå æ­¤ï¼éå°åæ ä¸çè®åçå°æ¥­ææ°ç¥è­é²è¡å¾®èª¿å·²è®å¾æ®éï¼åç®¡éæç ´å£æ¨¡ååå§åè½çé¢¨éªãæåå¨æçºè¨æ¶çèæ¯ä¸ç ç©¶éç¨®èå¼±æ§ï¼å¶ä¸­æ¨¡åå¨å°éé·å°¾äºå¯¦ï¼äºå¯¦éè¯ï¼ä¸é²è¡è¨ç·´ï¼ä¸¦ä¸å¿é å¨å¾çºå¨å¶ä»è³æéä¸é²è¡å¤åéæ®µè¨ç·´å¾ä¿çéäºäºå¯¦ãééå»£æ³çå¯¦é©ï¼æåè¡¨æ LLM å¨åç¨®å¾çºä»»åä¸­æç¼çéºå¿ï¼èä¸ç°¡å®çéæ­æè¡ä¸¦ä¸è½å®å¨é²æ­¢éºå¿ï¼ç¹å¥æ¯å¨å¾çºéæ®µè¨ç·´äºå¯¦è³æéæãæååè¨­æå©ç¨®æ¹æ³å¯ä»¥æ¸è¼éºå¿ï¼1) å¨æ¨¡åå­¸ç¿äºå¯¦æä¿è­·è¨æ¶éç¨ï¼æ 2) æ¸å°å¾çºéæ®µè¨ç·´çå¹²æ¾ãæäºéåè¦è§£ï¼æåå¶å®äºä¸åææçç·©è§£ç­ç¥ï¼REMIXï¼é¨æ©åéç¨è³ææ··åï¼ãREMIX ééå¨æ¯åéæ®µæ··åå¾é è¨ç·´èªæåº«ä¸­åæ¨£çéç¨è³æï¼çè³é¨æ©ç¢ççå­è©åºåä¾é²æ­¢éºå¿ï¼åç®¡èç¬¬ä¸éæ®µä¸­è¨æ¶çäºå¯¦ç¡éãREMIX å¯ä»¥å¾å´éçéºå¿ä¸­æ¢å¾©æè½ï¼éå¸¸åªæ¼å¯ä»¥å­åç¬¬ä¸éæ®µäºå¯¦çåºæ¼éæ­çæ¹æ³ãç¶å¾æååæ REMIX å¦ä½æ¹è®å­¸ç¿éç¨ï¼ä¸¦ç¼ç¾æåçéºå¿é é²èä¸åæ¨¡å¼ç¸éï¼æ¨¡åæ¯å¹³å¸¸æ´æ©å°äºå¯¦å²å­å¨è¼æ©çå±¤ä¸­ï¼ä¸¦å°å²å­éäºäºå¯¦çå±¤çµå¤æ¨£åãREMIX çåæä¿ä½¿é²ä¸æ­¥ç ç©¶è¨æ¶åéºå¿çåºç¤åæï¼çºæªä¾çç ç©¶éåä»¤äººèå¥®çå¯è½æ§ã

##### **A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19**
2411.07163v1 by Vedant Khandelwal, Manas Gaur, Ugur Kursuncu, Valerie Shalin, Amit Sheth

Monitoring public sentiment via social media is potentially helpful during
health crises such as the COVID-19 pandemic. However, traditional
frequency-based, data-driven neural network-based approaches can miss newly
relevant content due to the evolving nature of language in a dynamically
evolving environment. Human-curated symbolic knowledge sources, such as
lexicons for standard language and slang terms, can potentially elevate social
media signals in evolving language. We introduce a neurosymbolic method that
integrates neural networks with symbolic knowledge sources, enhancing the
detection and interpretation of mental health-related tweets relevant to
COVID-19. Our method was evaluated using a corpus of large datasets
(approximately 12 billion tweets, 2.5 million subreddit data, and 700k news
articles) and multiple knowledge graphs. This method dynamically adapts to
evolving language, outperforming purely data-driven models with an F1 score
exceeding 92\%. This approach also showed faster adaptation to new data and
lower computational demands than fine-tuning pre-trained large language models
(LLMs). This study demonstrates the benefit of neurosymbolic methods in
interpreting text in a dynamic environment for tasks such as health
surveillance.

æè¦ï¼ééç¤¾ç¾¤åªé«ç£æ§å¬ç¾æç·å¨ COVID-19 ç­å¥åº·å±æ©æéå¯è½å¾æå¹«å©ãç¶èï¼å³çµ±çåºæ¼é »çãè³æé©åçç¥ç¶ç¶²è·¯æ¹æ³å¯è½æé¯éæ°ç¸éçå§å®¹ï¼å çºèªè¨å¨åææ¼åçç°å¢ä¸­ææçºæ¼åãç±äººé¡ç­åçè±¡å¾µæ§ç¥è­ä¾æºï¼ä¾å¦æ¨æºèªè¨åä¿èªè¡èªçè©å½ï¼å¯è½ææåç¤¾ç¾¤åªé«å¨æ¼åèªè¨ä¸­çè¨èãæåå¼å¥ä¸ç¨®å°ç¥ç¶ç¶²è·¯èè±¡å¾µæ§ç¥è­ä¾æºæ´åçç¥ç¶ç¬¦èæ¹æ³ï¼å¢å¼·è COVID-19 ç¸éçå¿çå¥åº·ç¸éæ¨æçåµæ¸¬åè©®éãæåçåæ³ä½¿ç¨å¤§åè³æéèªæåº«ï¼ç´ 120 ååæ¨æã250 è¬å subreddit è³æå 70 è¬åæ°èæç« ï¼åå¤åç¥è­åè­é²è¡è©ä¼°ãéç¨®æ¹æ³åæé©ææ¼åçèªè¨ï¼åªæ¼ç´è³æé©åæ¨¡åï¼F1 åæ¸è¶é 92%ãéç¨®æ¹æ³ä¹é¡¯ç¤ºåºæ¯å¾®èª¿é è¨ç·´å¤§åèªè¨æ¨¡å (LLM) æ´å¿«é©ææ°è³æåæ´ä½çéç®éæ±ãæ¬ç ç©¶è­æäºç¥ç¶ç¬¦èæ¹æ³å¨åæç°å¢ä¸­è©®éæå­çåªé»ï¼é©ç¨æ¼å¥åº·ç£æ§ç­ä»»åã

##### **A Primer on Word Embeddings: AI Techniques for Text Analysis in Social Work**
2411.07156v1 by Brian E. Perron, Kelley A. Rivenburgh, Bryan G. Victor, Zia Qi, Hui Luan

Word embeddings represent a transformative technology for analyzing text data
in social work research, offering sophisticated tools for understanding case
notes, policy documents, research literature, and other text-based materials.
This methodological paper introduces word embeddings to social work
researchers, explaining how these mathematical representations capture meaning
and relationships in text data more effectively than traditional keyword-based
approaches. We discuss fundamental concepts, technical foundations, and
practical applications, including semantic search, clustering, and retrieval
augmented generation. The paper demonstrates how embeddings can enhance
research workflows through concrete examples from social work practice, such as
analyzing case notes for housing instability patterns and comparing social work
licensing examinations across languages. While highlighting the potential of
embeddings for advancing social work research, we acknowledge limitations
including information loss, training data constraints, and potential biases. We
conclude that successfully implementing embedding technologies in social work
requires developing domain-specific models, creating accessible tools, and
establishing best practices aligned with social work's ethical principles. This
integration can enhance our ability to analyze complex patterns in text data
while supporting more effective services and interventions.

æè¦ï¼è©å½åµå¥ä»£è¡¨äºä¸ç¨®è®é©æ§çæè¡ï¼å¯ç¨æ¼åæç¤¾å·¥ç ç©¶ä¸­çæå­è³æï¼ä¸¦æä¾ç²¾å¯çå·¥å·ä¾çè§£åæ¡ç­è¨ãæ¿ç­æä»¶ãç ç©¶æç»åå¶ä»åºæ¼æå­çææãéç¯æ¹æ³è«è«æå°è©å½åµå¥ä»ç´¹çµ¦ç¤¾å·¥ç ç©¶äººå¡ï¼èªªæéäºæ¸å­¸è¡¨å¾µå¦ä½æ¯å³çµ±çåºæ¼ééµå­çæ¹æ³æ´ææå°æ·åæå­è³æä¸­çæç¾©åéä¿ãæåæè¨è«åºæ¬æ¦å¿µãæè¡åºç¤åå¯¦åæç¨ï¼åæ¬èªææå°ãåç¾¤åæª¢ç´¢å¢å¼·ç¢çãæ¬æééç¤¾å·¥å¯¦åä¸­çå·é«ç¯ä¾èªªæåµå¥å¦ä½å¢å¼·ç ç©¶å·¥ä½æµç¨ï¼ä¾å¦åæåæ¡ç­è¨ä»¥æ¾åºä½æ¿ä¸ç©©å®çæ¨¡å¼ï¼ä»¥åæ¯è¼ä¸åèªè¨çç¤¾å·¥å·ç§èè©¦ãæåå¨å¼·èª¿åµå¥å°ä¿é²ç¤¾å·¥ç ç©¶çæ½åçåæï¼ä¹æ¿èªå¶éå¶ï¼åæ¬è³è¨éºå¤±ãè¨ç·´è³æéå¶åæ½å¨åè¦ãæåå¾åºççµè«æ¯ï¼å¨ç¤¾å·¥ä¸­æåå¯¦æ½åµå¥æè¡éè¦éç¼ç¹å®é åçæ¨¡åãå»ºç«å¯å­åçå·¥å·ï¼ä»¥åå»ºç«èç¤¾å·¥å«çååä¸è´çæä½³å¯¦åãéç¨®æ´åå¯ä»¥å¢å¼·æååææå­è³æä¸­è¤éæ¨¡å¼çè½åï¼åææ¯æ´æ´ææçæååä»å¥æªæ½ã

##### **HierTOD: A Task-Oriented Dialogue System Driven by Hierarchical Goals**
2411.07152v1 by Lingbo Mo, Shun Jiang, Akash Maharaj, Bernard Hishamunda, Yunyao Li

Task-Oriented Dialogue (TOD) systems assist users in completing tasks through
natural language interactions, often relying on a single-layered workflow
structure for slot-filling in public tasks, such as hotel bookings. However, in
enterprise environments, which involve rich domain-specific knowledge, TOD
systems face challenges due to task complexity and the lack of standardized
documentation. In this work, we introduce HierTOD, an enterprise TOD system
driven by hierarchical goals and can support composite workflows. By focusing
on goal-driven interactions, our system serves a more proactive role,
facilitating mixed-initiative dialogue and improving task completion. Equipped
with components for natural language understanding, composite goal retriever,
dialogue management, and response generation, backed by a well-organized data
service with domain knowledge base and retrieval engine, HierTOD delivers
efficient task assistance. Furthermore, our system implementation unifies two
TOD paradigms: slot-filling for information collection and step-by-step
guidance for task execution. Our human study demonstrates the effectiveness and
helpfulness of HierTOD in performing both paradigms.

æè¦ï¼ä»»åå°åå°è©± (TOD) ç³»çµ±åå©ä½¿ç¨èééèªç¶èªè¨äºåå®æä»»åï¼éå¸¸ä¾è³´å®å±¤å·¥ä½æµç¨çµæ§ï¼ä»¥å¡«è£å¬å±ä»»åä¸­çæ§½ä½ï¼ä¾å¦é£¯åºé è¨ãç¶èï¼å¨æ¶åè±å¯ç¹å®é åç¥è­çä¼æ¥­ç°å¢ä¸­ï¼TOD ç³»çµ±æå çºä»»åè¤éæ§åç¼ºä¹æ¨æºåæä»¶èé¢è¨ææ°ãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹ HierTODï¼ä¸ç¨®ç±éå±¤ç®æ¨é©åä¸æ¯æ´è¤åå·¥ä½æµç¨çä¼æ¥­ TOD ç³»çµ±ãééå°æ³¨æ¼ç®æ¨å°åäºåï¼æåçç³»çµ±æ®æ¼æ´ç©æ¥µçè§è²ï¼ä¿é²æ··åä¸»åå°è©±ä¸¦æ¹åä»»åå®æãéåèªç¶èªè¨çè§£ãè¤åç®æ¨æ·åå¨ãå°è©±ç®¡çååæç¢çç­åä»¶ï¼ä¸¦ç±å·åé åç¥è­åº«åæ·åå¼æçäºç¶æåºè³ææåæä¾æ¯æ´ï¼HierTOD æä¾ææçä»»ååå©ãæ­¤å¤ï¼æåçç³»çµ±å¯¦ä½çµ±ä¸äºå©ç¨® TOD å¸ç¯ï¼ç¨æ¼è³è¨æ¶éçæ§½ä½å¡«è£åç¨æ¼ä»»åå·è¡çéæ­¥æåãæåçäººé¡ç ç©¶è­æäº HierTOD å¨å·è¡éå©ç¨®å¸ç¯æ¹é¢çæææ§åå©çã

##### **Chinese SimpleQA: A Chinese Factuality Evaluation for Large Language Models**
2411.07140v1 by Yancheng He, Shilong Li, Jiaheng Liu, Yingshui Tan, Hui Huang, Weixun Wang, Xingyuan Bu, Hangyu Guo, Chengwei Hu, Boren Zheng, Xuepeng Liu, Dekai Sun, Wenbo Su, Bo Zheng

New LLM evaluation benchmarks are important to align with the rapid
development of Large Language Models (LLMs). In this work, we present Chinese
SimpleQA, the first comprehensive Chinese benchmark to evaluate the factuality
ability of language models to answer short questions, and Chinese SimpleQA
mainly has five properties (i.e., Chinese, Diverse, High-quality, Static,
Easy-to-evaluate). Specifically, first, we focus on the Chinese language over 6
major topics with 99 diverse subtopics. Second, we conduct a comprehensive
quality control process to achieve high-quality questions and answers, where
the reference answers are static and cannot be changed over time. Third,
following SimpleQA, the questions and answers are very short, and the grading
process is easy-to-evaluate based on OpenAI API. Based on Chinese SimpleQA, we
perform a comprehensive evaluation on the factuality abilities of existing
LLMs. Finally, we hope that Chinese SimpleQA could guide the developers to
better understand the Chinese factuality abilities of their models and
facilitate the growth of foundation models.

æè¦ï¼æ°ç LLM è©ä¼°åºæºå°æ¼èå¤§åèªè¨æ¨¡å (LLM) çå¿«éç¼å±ä¿æä¸è´éå¸¸éè¦ãå¨éé å·¥ä½ä¸­ï¼æåæåºä¸­æ SimpleQAï¼éæ¯ç¬¬ä¸åå¨é¢çä¸­æåºæºï¼ç¨æ¼è©ä¼°èªè¨æ¨¡ååç­ç°¡ç­åé¡çäºå¯¦è½åï¼èä¸­æ SimpleQA ä¸»è¦æäºåç¹æ§ï¼å³ä¸­æãå¤ååãé«åè³ªãéæãææ¼è©ä¼°ï¼ãå·é«ä¾èªªï¼é¦åï¼æåå°æ³¨æ¼ 6 åä¸»è¦ä¸»é¡çä¸­æï¼ä»¥å 99 åä¸åçå­ä¸»é¡ãå¶æ¬¡ï¼æåé²è¡å¨é¢çåè³ªæ§ç®¡æµç¨ï¼ä»¥ç²å¾é«åè³ªçåé¡åç­æ¡ï¼å¶ä¸­åèç­æ¡æ¯éæçï¼ä¸¦ä¸ä¸æé¨èæéèæ¹è®ãç¬¬ä¸ï¼éµå¾ª SimpleQAï¼åé¡åç­æ¡éå¸¸ç°¡ç­ï¼è©åéç¨åºæ¼ OpenAI APIï¼ææ¼è©ä¼°ãæ ¹æä¸­æ SimpleQAï¼æåå°ç¾æ LLM çäºå¯¦è½åé²è¡å¨é¢è©ä¼°ãæå¾ï¼æåå¸æä¸­æ SimpleQA å¯ä»¥å¼å°éç¼äººå¡æ´å¥½å°äºè§£å¶æ¨¡åçä¸­æäºå¯¦è½åï¼ä¸¦ä¿é²åºç¤æ¨¡åçç¼å±ã

##### **Edify 3D: Scalable High-Quality 3D Asset Generation**
2411.07135v1 by NVIDIA, :, Maciej Bala, Yin Cui, Yifan Ding, Yunhao Ge, Zekun Hao, Jon Hasselgren, Jacob Huffman, Jingyi Jin, J. P. Lewis, Zhaoshuo Li, Chen-Hsuan Lin, Yen-Chen Lin, Tsung-Yi Lin, Ming-Yu Liu, Alice Luo, Qianli Ma, Jacob Munkberg, Stella Shi, Fangyin Wei, Donglai Xiang, Jiashu Xu, Xiaohui Zeng, Qinsheng Zhang

We introduce Edify 3D, an advanced solution designed for high-quality 3D
asset generation. Our method first synthesizes RGB and surface normal images of
the described object at multiple viewpoints using a diffusion model. The
multi-view observations are then used to reconstruct the shape, texture, and
PBR materials of the object. Our method can generate high-quality 3D assets
with detailed geometry, clean shape topologies, high-resolution textures, and
materials within 2 minutes of runtime.

æè¦ï¼æåæ¨åº Edify 3Dï¼éæ¯ä¸ç¨®åé²çè§£æ±ºæ¹æ¡ï¼å°çºé«åè³ª 3D è³ç¢çæèè¨­è¨ãæåçæè¡é¦åä½¿ç¨æ´æ£æ¨¡åï¼å¨å¤åè¦é»åææè¿°ç©ä»¶ç RGB åæ²é¢æ³ç·å½±åãæ¥èä½¿ç¨å¤è¦åè§å¯ï¼éå»ºç©ä»¶çå½¢çãç´çå PBR æè³ªãæåçæè¡å¯ä»¥å¨ 2 åéçå·è¡æéå§ï¼ç¢çå·æè©³ç´°å¹¾ä½å½¢çãä¹¾æ·¨å½¢çææ²ãé«è§£æåº¦ç´çåæè³ªçé«åè³ª 3D è³ç¢ã

##### **Stronger Models are NOT Stronger Teachers for Instruction Tuning**
2411.07133v1 by Zhangchen Xu, Fengqing Jiang, Luyao Niu, Bill Yuchen Lin, Radha Poovendran

Instruction tuning has been widely adopted to ensure large language models
(LLMs) follow user instructions effectively. The resulting
instruction-following capabilities of LLMs heavily rely on the instruction
datasets used for tuning. Recently, synthetic instruction datasets have emerged
as an economically viable solution to provide LLMs diverse and high-quality
instructions. However, existing approaches typically assume that larger or
stronger models are stronger teachers for instruction tuning, and hence simply
adopt these models as response generators to the synthetic instructions. In
this paper, we challenge this commonly-adopted assumption. Our extensive
experiments across five base models and twenty response generators reveal that
larger and stronger models are not necessarily stronger teachers of smaller
models. We refer to this phenomenon as the Larger Models' Paradox. We observe
that existing metrics cannot precisely predict the effectiveness of response
generators since they ignore the compatibility between teachers and base models
being fine-tuned. We thus develop a novel metric, named as
Compatibility-Adjusted Reward (CAR) to measure the effectiveness of response
generators. Our experiments across five base models demonstrate that CAR
outperforms almost all baselines.

æè¦ï¼æä»¤å¾®è°å·²è¢«å¹¿æ³éç¨ï¼ä»¥ç¡®ä¿å¤§åè¯­è¨æ¨¡å (LLM) ææéµå¾ªç¨æ·æä»¤ãLLM çæä»¤éµå¾ªè½åå¾å¤§ç¨åº¦ä¸ä¾èµäºç¨äºå¾®è°çæä»¤æ°æ®éãæè¿ï¼åææä»¤æ°æ®éå·²æä¸ºä¸º LLM æä¾å¤æ ·åä¸é«è´¨éæä»¤çä¸ç§ç»æµå¯è¡çè§£å³æ¹æ¡ãç¶èï¼ç°ææ¹æ³éå¸¸åè®¾æ´å¤§ææ´å¼ºçæ¨¡åæ¯æä»¤å¾®è°çæ´å¼ºæå¸ï¼å æ­¤åªæ¯éç¨è¿äºæ¨¡åä½ä¸ºåææä»¤çååºçæå¨ãå¨æ¬æä¸­ï¼æä»¬å¯¹è¿ä¸æ®ééç¨çåè®¾æåºè´¨çãæä»¬å¯¹äºä¸ªåºç¡æ¨¡åå 20 ä¸ªååºçæå¨è¿è¡çå¹¿æ³å®éªè¡¨æï¼æ´å¤§ãæ´å¼ºçæ¨¡åä¸ä¸å®æ¯å¯¹è¾å°æ¨¡åçæ´å¼ºèå¸ãæä»¬å°è¿ç§ç°è±¡ç§°ä¸ºå¤§æ¨¡åæè®ºãæä»¬è§å¯å°ï¼ç°æçææ æ æ³åç¡®é¢æµååºçæå¨çæææ§ï¼å ä¸ºå®ä»¬å¿½ç¥äºæ­£å¨å¾®è°çæå¸ååºç¡æ¨¡åä¹é´çå¼å®¹æ§ãå æ­¤ï¼æä»¬å¼åäºä¸ç§åä¸ºå¼å®¹æ§è°æ´å¥å± (CAR) çæ°ææ æ¥è¡¡éååºçæå¨çæææ§ãæä»¬å¯¹äºä¸ªåºç¡æ¨¡åçå®éªè¡¨æï¼CAR ä¼äºå ä¹ææåºçº¿ã

##### **Token Merging for Training-Free Semantic Binding in Text-to-Image Synthesis**
2411.07132v1 by Taihang Hu, Linxuan Li, Joost van de Weijer, Hongcheng Gao, Fahad Shahbaz Khan, Jian Yang, Ming-Ming Cheng, Kai Wang, Yaxing Wang

Although text-to-image (T2I) models exhibit remarkable generation
capabilities, they frequently fail to accurately bind semantically related
objects or attributes in the input prompts; a challenge termed semantic
binding. Previous approaches either involve intensive fine-tuning of the entire
T2I model or require users or large language models to specify generation
layouts, adding complexity. In this paper, we define semantic binding as the
task of associating a given object with its attribute, termed attribute
binding, or linking it to other related sub-objects, referred to as object
binding. We introduce a novel method called Token Merging (ToMe), which
enhances semantic binding by aggregating relevant tokens into a single
composite token. This ensures that the object, its attributes and sub-objects
all share the same cross-attention map. Additionally, to address potential
confusion among main objects with complex textual prompts, we propose end token
substitution as a complementary strategy. To further refine our approach in the
initial stages of T2I generation, where layouts are determined, we incorporate
two auxiliary losses, an entropy loss and a semantic binding loss, to
iteratively update the composite token to improve the generation integrity. We
conducted extensive experiments to validate the effectiveness of ToMe,
comparing it against various existing methods on the T2I-CompBench and our
proposed GPT-4o object binding benchmark. Our method is particularly effective
in complex scenarios that involve multiple objects and attributes, which
previous methods often fail to address. The code will be publicly available at
\url{https://github.com/hutaihang/ToMe}.

æè¦ï¼åç®¡æå­è½åå (T2I) æ¨¡åå±ç¾åºåè¶ççæè½åï¼ä½å®åç¶å¸¸ç¡æ³æºç¢ºå°çµåè¼¸å¥æç¤ºä¸­çèªç¾©ç¸éç©ä»¶æå±¬æ§ï¼éé ææ°ç¨±çºèªç¾©çµåãååçåæ³åæ¬å°æ´å T2I æ¨¡åé²è¡å¯éå¾®èª¿ï¼æè¦æ±ä½¿ç¨èæå¤§åèªè¨æ¨¡åæå®çæä½å±ï¼éå¢å äºè¤éæ§ãå¨æ¬æä¸­ï¼æåå°èªç¾©çµåå®ç¾©çºå°çµ¦å®ç©ä»¶èå¶å±¬æ§ï¼ç¨±çºå±¬æ§çµåï¼éè¯ï¼æå°å¶é£çµå°å¶ä»ç¸éå­ç©ä»¶ï¼ç¨±çºç©ä»¶çµåï¼çä»»åãæåå¼å¥ä¸ç¨®åçº Token Merging (ToMe) çæ°æ¹æ³ï¼ééå°ç¸éç token èåå°å®ä¸è¤å token ä¸­ä¾å¢å¼·èªç¾©çµåãéå¯ç¢ºä¿ç©ä»¶ãå¶å±¬æ§åå­ç©ä»¶é½å±ç¨ç¸åçäº¤åæ³¨æååãæ­¤å¤ï¼çºäºè§£æ±ºå¨è¤éæå­æç¤ºä¸­ä¸»ç©ä»¶ä¹éæ½å¨çæ··æ·ï¼æåæåºçµç«¯ token æ¿æä½çºä¸ç¨®è£åç­ç¥ãçºäºé²ä¸æ­¥æ¹åæåå¨ T2I çæåå§éæ®µï¼å¶ä¸­ææ±ºå®ä½å±ï¼ä¸­çæ¹æ³ï¼æåç´å¥å©åè¼å©æå¤±ï¼ä¸åæ¯çµæå¤±ï¼å¦ä¸åæ¯èªç¾©çµåæå¤±ï¼ä»¥åè¦æ´æ°è¤å token ä¾æ¹åçæå®æ´æ§ãæåé²è¡äºå»£æ³çå¯¦é©ä¾é©è­ ToMe çæææ§ï¼ä¸¦å¨ T2I-CompBench åæåæåºç GPT-4o ç©ä»¶çµååºæºä¸å°å¶èåç¨®ç¾ææ¹æ³é²è¡æ¯è¼ãæåçéé æ¹æ³å¨æ¶åå¤åç©ä»¶åå±¬æ§çè¤éå ´æ¯ä¸­ç¹å¥ææï¼èååçè¨±å¤æ¹æ³é½ç¡æ³èçéé¡å ´æ¯ãç¨å¼ç¢¼å°å¬éæ¼ \url{https://github.com/hutaihang/ToMe}ã

##### **Retrieval or Global Context Understanding? On Many-Shot In-Context Learning for Long-Context Evaluation**
2411.07130v1 by Kaijian Zou, Muhammad Khalifa, Lu Wang

Language models (LMs) have demonstrated an improved capacity to handle
long-context information, yet existing long-context benchmarks primarily
measure LMs' retrieval abilities with extended inputs, e.g., pinpointing a
short phrase from long-form text. Therefore, they may fall short when
evaluating models' global context understanding capacity, such as synthesizing
and reasoning over content across input to generate the response. In this
paper, we study long-context language model (LCLM) evaluation through many-shot
in-context learning (ICL). Concretely, we identify the skills each ICL task
requires, and examine models' long-context capabilities on them. We first ask:
What types of ICL tasks benefit from additional demonstrations, and are these
tasks effective at evaluating LCLMs? We find that classification and
summarization tasks show notable performance improvements with additional
demonstrations, while translation and reasoning tasks do not exhibit clear
trends. This suggests the classification tasks predominantly test models'
retrieval skills. Next, we ask: To what extent does each task require retrieval
skills versus global context understanding from LCLMs? We develop metrics to
categorize ICL tasks into two groups: (i) retrieval tasks that require strong
retrieval ability to pinpoint relevant examples, and (ii) global context
understanding tasks that necessitate a deeper comprehension of the full input.
We find that not all datasets can effectively evaluate these long-context
capabilities. To address this gap, we introduce a new many-shot ICL benchmark,
MANYICLBENCH, designed to characterize LCLMs' retrieval and global context
understanding capabilities separately. Benchmarking 11 open-weight LCLMs with
MANYICLBENCH, we find that while state-of-the-art models perform well in
retrieval tasks up to 64k tokens, many show significant drops in global context
tasks at just 16k tokens.

æè¦ï¼<paragraph>èªè¨æ¨¡å (LM) å·²å±ç¾åºèçé·èªå¢è³è¨çé²æ­¥è½åï¼ä½ç¾æçé·èªå¢åºæºä¸»è¦æ¸¬é LM çæ·åè½åï¼è¼¸å¥å§å®¹è¼é·ï¼ä¾å¦å¾é·ç¯æå­ä¸­ç²¾ç¢ºæ¾åºç­èªãå æ­¤ï¼å¨è©ä¼°æ¨¡åçæ´é«èªå¢çè§£è½åæï¼ä¾å¦ç¶ååæ¨çè¼¸å¥ä¸­çå§å®¹ä»¥ç¢çåæï¼éäºåºæºå¯è½æä¸è¶³ãå¨æ¬æä¸­ï¼æåééå¤è¼ªæ¬¡èªå¢ä¸­å­¸ç¿ (ICL) ç ç©¶é·èªå¢èªè¨æ¨¡å (LCLM) è©ä¼°ãå·é«ä¾èªªï¼æåæ¾åºæ¯å ICL ä»»åæéçæè½ï¼ä¸¦æª¢è¦æ¨¡åå¨éäºæè½ä¸çé·èªå¢è½åãæåé¦åè©¢åï¼åªäºé¡åç ICL ä»»åå¯ä»¥å¾é¡å¤çç¤ºç¯ä¸­åçï¼éäºä»»åå¨è©ä¼° LCLM ææ¯å¦ææï¼æåç¼ç¾åé¡åæè¦ä»»åå¨é¡å¤çç¤ºç¯ä¸­è¡¨ç¾åºé¡¯èçé²æ­¥ï¼èç¿»è­¯åæ¨çä»»åä¸¦æªå±ç¾åºæç¢ºçè¶¨å¢ãéè¡¨ç¤ºåé¡ä»»åä¸»è¦æ¸¬è©¦æ¨¡åçæ·åæè½ãæ¥ä¸ä¾ï¼æåè©¢åï¼æ¯åä»»åå¨å¤å¤§ç¨åº¦ä¸éè¦ LCLM çæ·åæè½åæ´é«èªå¢çè§£ï¼æåéç¼ææ¨å° ICL ä»»ååé¡çºå©çµï¼(i) éè¦å¼·å¤§æ·åè½åä¾ç²¾ç¢ºæ¾åºç¸éç¯ä¾çæ·åä»»åï¼ä»¥å (ii) éè¦æ´æ·±å¥çè§£å®æ´è¼¸å¥çæ´é«èªå¢çè§£ä»»åãæåç¼ç¾ä¸¦éææè³æéé½è½ææè©ä¼°éäºé·èªå¢è½åãçºäºè§£æ±ºéåå·®è·ï¼æåå¼é²ä¸åæ°çå¤è¼ªæ¬¡ ICL åºæºï¼MANYICLBENCHï¼æ¨å¨åå¥æè¿° LCLM çæ·ååæ´é«èªå¢çè§£è½åãä½¿ç¨ MANYICLBENCH å° 11 åéæ¾æ¬éç LCLM é²è¡åºæºæ¸¬è©¦ï¼æåç¼ç¾éç¶æåé²çæ¨¡åå¨é·é 64k åè©å½çæ·åä»»åä¸­è¡¨ç¾è¯å¥½ï¼ä½è¨±å¤æ¨¡åå¨å 16k åè©å½çæ´é«èªå¢ä»»åä¸­é¡¯èä¸éã</paragraph>

##### **Benchmarking LLMs' Judgments with No Gold Standard**
2411.07127v1 by Shengwei Xu, Yuxuan Lu, Grant Schoenebeck, Yuqing Kong

We introduce the GEM (Generative Estimator for Mutual Information), an
evaluation metric for assessing language generation by Large Language Models
(LLMs), particularly in generating informative judgments, without the need for
a gold standard reference. GEM broadens the scenarios where we can benchmark
LLM generation performance-from traditional ones, like machine translation and
summarization, where gold standard references are readily available, to
subjective tasks without clear gold standards, such as academic peer review.
  GEM uses a generative model to estimate mutual information between candidate
and reference responses, without requiring the reference to be a gold standard.
In experiments on a human-annotated dataset, GEM demonstrates competitive
correlations with human scores compared to the state-of-the-art GPT-4o
Examiner, and outperforms all other baselines. Additionally, GEM is more robust
against strategic manipulations, such as rephrasing or elongation, which can
artificially inflate scores under a GPT-4o Examiner.
  We also present GRE-bench (Generating Review Evaluation Benchmark) which
evaluates LLMs based on how well they can generate high-quality peer reviews
for academic research papers. Because GRE-bench is based upon GEM, it inherits
its robustness properties. Additionally, GRE-bench circumvents data
contamination problems (or data leakage) by using the continuous influx of new
open-access research papers and peer reviews each year. We show GRE-bench
results of various popular LLMs on their peer review capabilities using the
ICLR2023 dataset.

æè¦ï¼<paragraph>æåä»ç´¹ GEMï¼äºä¿¡æ¯çæä¼°è¨å¨ï¼ï¼ä¸ç¨®ç¨æ¼è©ä¼°å¤§åèªè¨æ¨¡åï¼LLMï¼èªè¨çæè½åçè©ä¼°ææ¨ï¼ç¹å¥æ¯å¨çæè³è¨æ§å¤æ·æï¼ç¡éé»éæ¨æºåèãGEM æ´å±äºæåå¯ä»¥å° LLM çææè½é²è¡åºæºæ¸¬è©¦çå ´æ¯ï¼å¾å³çµ±å ´æ¯ï¼ä¾å¦æ©å¨ç¿»è­¯åæè¦ï¼å¶ä¸­é»éæ¨æºåèå¾å®¹æåå¾ï¼å°æ²ææç¢ºé»éæ¨æºçä¸»è§ä»»åï¼ä¾å¦å­¸è¡åè¡è©å¯©ï¼ã
  GEM ä½¿ç¨çææ¨¡åä¾ä¼°è¨åé¸åæååèåæä¹éçäºä¿¡æ¯ï¼èä¸è¦æ±åèæ¯é»éæ¨æºãå¨äººé¡æ¨è¨»è³æéä¸çå¯¦é©ä¸­ï¼èæåé²ç GPT-4o Examiner ç¸æ¯ï¼GEM å±ç¤ºåºèäººé¡è©åå·æç«¶ç­åçéè¯æ§ï¼ä¸¦ä¸åªæ¼ææå¶ä»åºç·ãæ­¤å¤ï¼GEM å°ç­ç¥æ§æä½ï¼ä¾å¦æ¹å¯«æå»¶ä¼¸ï¼å·ææ´å¼·å¤§çç©©å¥æ§ï¼éäºæä½æå¨ GPT-4o Examiner ä¸äººçºå°æé«åæ¸ã
  æåéæåºäº GRE-benchï¼çæè©è«è©ä¼°åºæºï¼ï¼å®æ ¹æ LLM çæé«åè³ªå­¸è¡ç ç©¶è«æåè¡è©å¯©çè½åä¾è©ä¼° LLMãç±æ¼ GRE-bench åºæ¼ GEMï¼å æ­¤å®ç¹¼æ¿äºå¶ç©©å¥æ§ãæ­¤å¤ï¼GRE-bench ééæ¯å¹´ä½¿ç¨å¤§éæ°éæ¾å­åç ç©¶è«æååè¡è©å¯©ä¾è¦é¿è³ææ±¡æåé¡ï¼æè³æå¤æ´©ï¼ãæåå±ç¤ºäº GRE-bench å¨ ICLR2023 è³æéä¸ä½¿ç¨åç¨®æµè¡ LLM çåè¡è©å¯©è½åççµæã</paragraph>

##### **Fast and Robust Contextual Node Representation Learning over Dynamic Graphs**
2411.07123v1 by Xingzhi Guo, Silong Wang, Baojian Zhou, Yanghua Xiao, Steven Skiena

Real-world graphs grow rapidly with edge and vertex insertions over time,
motivating the problem of efficiently maintaining robust node representation
over evolving graphs. Recent efficient GNNs are designed to decouple recursive
message passing from the learning process, and favor Personalized PageRank
(PPR) as the underlying feature propagation mechanism. However, most PPR-based
GNNs are designed for static graphs, and efficient PPR maintenance remains as
an open problem. Further, there is surprisingly little theoretical
justification for the choice of PPR, despite its impressive empirical
performance.
  In this paper, we are inspired by the recent PPR formulation as an explicit
$\ell_1$-regularized optimization problem and propose a unified dynamic graph
learning framework based on sparse node-wise attention. We also present a set
of desired properties to justify the choice of PPR in STOA GNNs, and serves as
the guideline for future node attention designs. Meanwhile, we take advantage
of the PPR-equivalent optimization formulation and employ the proximal gradient
method (ISTA) to improve the efficiency of PPR-based GNNs upto 6 times.
Finally, we instantiate a simple-yet-effective model (\textsc{GoPPE}) with
robust positional encodings by maximizing PPR previously used as attention. The
model performs comparably to or better than the STOA baselines and greatly
outperforms when the initial node attributes are noisy during graph evolution,
demonstrating the effectiveness and robustness of \textsc{GoPPE}.

æè¦ï¼<paragraph>é¨èæéæ¨ç§»ï¼çå¯¦ä¸ççåè¡¨æé¨èéç·£åé é»çæå¥èå¿«éå¢é·ï¼ä¿ä½¿é«æç¶­è­·ä¸æ·æ¼åçåè¡¨ä¸­çç©©å¥ç¯é»è¡¨ç¤ºçåé¡ãæè¿çé«æ GNN è¢«è¨­è¨çºå°éè¿´è¨æ¯å³éèå­¸ç¿éç¨è§£è¦ï¼ä¸¦å°åæ§å PageRank (PPR) ä½çºåºç¤ç¹å¾µå³æ­æ©å¶ãç¶èï¼å¤§å¤æ¸åºæ¼ PPR ç GNN æ¯çºéæåè¡¨è¨­è¨çï¼èé«æç PPR ç¶­è­·ä»ç¶æ¯ä¸åæªè§£æ±ºçåé¡ãæ­¤å¤ï¼åç®¡ PPR å·æä»¤äººå°è±¡æ·±å»çç¶é©æè½ï¼ä½ä»¤äººé©è¨çæ¯ï¼å°æ¼é¸æ PPR å¹¾ä¹æ²æçè«ä¾æã
å¨æ¬æä¸­ï¼æååå°æè¿å° PPR è¡¨è¿°çºä¸åæç¢ºç $\ell_1$ æ­£ååæä½³ååé¡çåç¼ï¼ä¸¦æåºäºä¸ååºæ¼ç¨çç¯é»æ³¨æåççµ±ä¸åæåè¡¨å­¸ç¿æ¡æ¶ãæåéæåºäºä¸çµæéçå±¬æ§ä¾è­æ STOA GNN ä¸­é¸æ PPR çåçæ§ï¼ä¸¦ä½çºæªä¾ç¯é»æ³¨æåè¨­è¨çæå°æ¹éãåæï¼æåå©ç¨ PPR ç­æçæä½³åå¬å¼ï¼ä¸¦æ¡ç¨è¿ç«¯æ¢¯åº¦æ¹æ³ (ISTA) å°åºæ¼ PPR ç GNN çæçæé«äº 6 åã
æå¾ï¼æåééæå¤§åååç¨ä½æ³¨æåç PPR ä¾å¯¦ä¾åä¸åç°¡å®èææçæ¨¡å (\textsc{GoPPE})ï¼å¶ä¸­åå«ç©©å¥çä½ç½®ç·¨ç¢¼ãè©²æ¨¡åçæè½è STOA åºæºç¸ç¶ææ´å¥½ï¼ä¸¦ä¸å¨åè¡¨æ¼åéç¨ä¸­åå§ç¯é»å±¬æ§æéè¨æè¡¨ç¾å¾éå¸¸å¥½ï¼è­æäº \textsc{GoPPE} çæææ§åç©©å¥æ§ã</paragraph>

##### **SCAR: Sparse Conditioned Autoencoders for Concept Detection and Steering in LLMs**
2411.07122v1 by Ruben HÃ¤rle, Felix Friedrich, Manuel Brack, BjÃ¶rn Deiseroth, Patrick Schramowski, Kristian Kersting

Large Language Models (LLMs) have demonstrated remarkable capabilities in
generating human-like text, but their output may not be aligned with the user
or even produce harmful content. This paper presents a novel approach to detect
and steer concepts such as toxicity before generation. We introduce the Sparse
Conditioned Autoencoder (SCAR), a single trained module that extends the
otherwise untouched LLM. SCAR ensures full steerability, towards and away from
concepts (e.g., toxic content), without compromising the quality of the model's
text generation on standard evaluation benchmarks. We demonstrate the effective
application of our approach through a variety of concepts, including toxicity,
safety, and writing style alignment. As such, this work establishes a robust
framework for controlling LLM generations, ensuring their ethical and safe
deployment in real-world applications.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨çæé¡ä¼¼äººé¡çæå­æ¹é¢å±ç¾äºéå¡çè½åï¼ä½å¶è¼¸åºå¯è½èä½¿ç¨èä¸ä¸è´ï¼çè³ç¢çæå®³çå§å®¹ãæ¬ææåºäºä¸ç¨®æ°ç©çæ¹æ³ä¾åµæ¸¬åå¼å°æ¯æ§ç­æ¦å¿µï¼å¨çæä¹åãæåå¼å¥äºç¨çæ¢ä»¶èªåç·¨ç¢¼å¨ (SCAR)ï¼éæ¯ä¸åå®ä¸çè¨ç·´æ¨¡çµï¼å¯æ´ååæ¬æªè§¸åç LLMãSCAR ç¢ºä¿äºå®å¨çå¯å¼å°æ§ï¼æååé é¢æ¦å¿µï¼ä¾å¦ï¼ææ¯å§å®¹ï¼ï¼èä¸ææå®³æ¨¡åå¨æ¨æºè©ä¼°åºæºä¸çæå­çæåè³ªãæåééåç¨®æ¦å¿µï¼åæ¬æ¯æ§ãå®å¨æ§ä»¥åå¯«ä½é¢¨æ ¼å°é½ï¼å±ç¤ºäºæåæ¹æ³çæææç¨ãå æ­¤ï¼éé å·¥ä½å»ºç«äºä¸åç©©å¥çæ¡æ¶ä¾æ§å¶ LLM çæï¼ç¢ºä¿å®åå¨å¯¦éæç¨ä¸­ç¬¦åéå¾·ä¸å®å¨å°é¨ç½²ã

##### **Building a Taiwanese Mandarin Spoken Language Model: A First Attempt**
2411.07111v1 by Chih-Kai Yang, Yu-Kuan Fu, Chen-An Li, Yi-Cheng Lin, Yu-Xiang Lin, Wei-Chih Chen, Ho Lam Chung, Chun-Yi Kuan, Wei-Ping Huang, Ke-Han Lu, Tzu-Quan Lin, Hsiu-Hsuan Wang, En-Pei Hu, Chan-Jan Hsu, Liang-Hsuan Tseng, I-Hsiang Chiu, Ulin Sanga, Xuanjun Chen, Po-chun Hsu, Shu-wen Yang, Hung-yi Lee

This technical report presents our initial attempt to build a spoken large
language model (LLM) for Taiwanese Mandarin, specifically tailored to enable
real-time, speech-to-speech interaction in multi-turn conversations. Our
end-to-end model incorporates a decoder-only transformer architecture and aims
to achieve seamless interaction while preserving the conversational flow,
including full-duplex capabilities allowing simultaneous speaking and
listening. The paper also details the training process, including data
preparation with synthesized dialogues and adjustments for real-time
interaction. We also developed a platform to evaluate conversational fluency
and response coherence in multi-turn dialogues. We hope the release of the
report can contribute to the future development of spoken LLMs in Taiwanese
Mandarin.

æè¦ï¼éä»½æè¡å ±ååç¾æåæååè©¦å»ºæ§ä¸åå°ç£åèªçå¤§åå£èªèªè¨æ¨¡å (LLM)ï¼ç¹å¥éèº«æé ä»¥å¨å¤ååå°è©±ä¸­å¯¦ç¾å³æçèªé³è½èªé³äºåãæåçç«¯å°ç«¯æ¨¡åçµåäºåè§£ç¢¼å¨Transformeræ¶æ§ï¼ä¸¦æ¨å¨å¨ä¿çå°è©±æµæ¢åº¦çåæå¯¦ç¾ç¡ç¸«äºåï¼åæ¬åè¨±åæèªªè©±åèè½çå¨éå·¥åè½ãæ¬æä¹è©³ç´°èªªæè¨ç·´æµç¨ï¼åæ¬ä½¿ç¨åæå°è©±çè³ææºåä»¥åéå°å³æäºåçèª¿æ´ãæåä¹éç¼äºä¸åå¹³å°ä¾è©ä¼°å¤ååå°è©±ä¸­çå°è©±æµæ¢åº¦ååæä¸è´æ§ãæåå¸æéä»½å ±åçç¼å¸æå©æ¼å°ç£åèªå£èª LLM æªä¾çç¼å±ã

##### **Training Neural Networks as Recognizers of Formal Languages**
2411.07107v1 by Alexandra Butoi, Ghazal Khalighinejad, Anej Svete, Josef Valvoda, Ryan Cotterell, Brian DuSell

Characterizing the computational power of neural network architectures in
terms of formal language theory remains a crucial line of research, as it
describes lower and upper bounds on the reasoning capabilities of modern AI.
However, when empirically testing these bounds, existing work often leaves a
discrepancy between experiments and the formal claims they are meant to
support. The problem is that formal language theory pertains specifically to
recognizers: machines that receive a string as input and classify whether it
belongs to a language. On the other hand, it is common to instead use proxy
tasks that are similar in only an informal sense, such as language modeling or
sequence-to-sequence transduction. We correct this mismatch by training and
evaluating neural networks directly as binary classifiers of strings, using a
general method that can be applied to a wide variety of languages. As part of
this, we extend an algorithm recently proposed by Sn{\ae}bjarnarson et al.
(2024) to do length-controlled sampling of strings from regular languages, with
much better asymptotic time complexity than previous methods. We provide
results on a variety of languages across the Chomsky hierarchy for three neural
architectures: a simple RNN, an LSTM, and a causally-masked transformer. We
find that the RNN and LSTM often outperform the transformer, and that auxiliary
training objectives such as language modeling can help, although no single
objective uniformly improves performance across languages and architectures.
Our contributions will facilitate theoretically sound empirical testing of
language recognition claims in future work. We have released our datasets as a
benchmark called FLaRe (Formal Language Recognition), along with our code.

æè¦ï¼<paragraph>ä»¥å½¢å¼èªè¨çè«ä¾æè¿°ç¥ç¶ç¶²è·¯æ¶æ§çéç®è½åï¼ä»ç¶æ¯ç ç©¶çä¸æ¢ééµè·¯ç·ï¼å çºå®æè¿°äºç¾ä»£äººå·¥æºæ§çæ¨çè½åçä¸éåä¸éãç¶èï¼å¨å¯¦è­æª¢é©éäºçéæï¼ç¾æç ç©¶éå¸¸æå¨å¯¦é©åå®åæåæ¯æçå½¢å¼åä¸»å¼µä¹éçä¸åºå¥ãåé¡å¨æ¼å½¢å¼èªè¨çè«ç¹å¥é©ç¨æ¼è¾¨è­å¨ï¼æ¥æ¶å­ä¸²ä½çºè¼¸å¥ä¸¦åé¡å®æ¯å¦å±¬æ¼æç¨®èªè¨çæ©å¨ãå¦ä¸æ¹é¢ï¼éå¸¸æä½¿ç¨åå¨éæ­£å¼æç¾©ä¸ç¸ä¼¼çä»£çä»»åï¼ä¾å¦èªè¨æ¨¡åæåºåå°åºåçè½æãæåééä½¿ç¨ä¸ç¨®å¯æç¨æ¼åç¨®èªè¨çä¸è¬æ¹æ³ï¼ç´æ¥è¨ç·´åè©ä¼°ç¥ç¶ç¶²è·¯ä½çºå­ä¸²çäºååé¡å¨ï¼ä¾ä¿®æ­£éç¨®ä¸å¹éãä½çºå¶ä¸­çä¸é¨åï¼æåæ´å±äº Sn{\ae}bjarnarson ç­äººæè¿æåºçæ¼ç®æ³ï¼2024 å¹´ï¼ï¼ä»¥å°æ­£åèªè¨ä¸­çå­ä¸²é²è¡é·åº¦æ§å¶çæ½æ¨£ï¼å¶æ¼¸è¿æéè¤éåº¦é åªæ¼ååçæ¼ç®æ³ãæåéå°ä¸åç¥ç¶æ¶æ§æä¾åç¨®å¬å§æ¯åºéå±¤èªè¨ççµæï¼ä¸åç°¡å®çéè¿´ç¥ç¶ç¶²è·¯ãä¸åé·ç­æè¨æ¶ç¶²è·¯åä¸åå æé®ç½©Transformerãæåç¼ç¾éè¿´ç¥ç¶ç¶²è·¯åé·ç­æè¨æ¶ç¶²è·¯éå¸¸åªæ¼Transformerï¼ä¸¦ä¸èªè¨æ¨¡åç­è¼å©è¨ç·´ç®æ¨å¯è½æå¹«å©ï¼åç®¡æ²æå®ä¸çç®æ¨è½æ®éæååç¨®èªè¨åæ¶æ§çæè½ãæåçè²¢ç»å°æå©æ¼å¨æªä¾çç ç©¶ä¸­å°èªè¨è¾¨è­ä¸»å¼µé²è¡çè«ä¸åççå¯¦è­æª¢é©ãæåå·²å°æåçè³æéä½çºä¸ååçº FLaReï¼å½¢å¼èªè¨è¾¨è­ï¼çåºæºç¼å¸ï¼ä¸¦éä¸æåçç¨å¼ç¢¼ã</paragraph>

##### **Bounded Rationality Equilibrium Learning in Mean Field Games**
2411.07099v1 by Yannick Eich, Christian Fabian, Kai Cui, Heinz Koeppl

Mean field games (MFGs) tractably model behavior in large agent populations.
The literature on learning MFG equilibria typically focuses on finding Nash
equilibria (NE), which assume perfectly rational agents and are hence
implausible in many realistic situations. To overcome these limitations, we
incorporate bounded rationality into MFGs by leveraging the well-known concept
of quantal response equilibria (QRE). Two novel types of MFG QRE enable the
modeling of large agent populations where individuals only noisily estimate the
true objective. We also introduce a second source of bounded rationality to
MFGs by restricting agents' planning horizon. The resulting novel receding
horizon (RH) MFGs are combined with QRE and existing approaches to model
different aspects of bounded rationality in MFGs. We formally define MFG QRE
and RH MFGs and compare them to existing equilibrium concepts such as
entropy-regularized NE. Subsequently, we design generalized fixed point
iteration and fictitious play algorithms to learn QRE and RH equilibria. After
a theoretical analysis, we give different examples to evaluate the capabilities
of our learning algorithms and outline practical differences between the
equilibrium concepts.

æè¦ï¼å¹³åå ´åå¼ï¼MFGï¼å¯ä»¥è¿½è¹¤å¤§éä»£çäººå£çè¡çºã
å­¸ç¿ MFG åè¡¡çæç»éå¸¸èéæ¼å°æ¾ç´è¨±åè¡¡ï¼NEï¼ï¼å®åè¨­ä»£çäººå®å¨çæ§ï¼å æ­¤å¨è¨±å¤ç¾å¯¦ææ³ä¸æ¯ä¸åççãçºäºåæéäºéå¶ï¼æåééå©ç¨èåçåä½æ¸åæåè¡¡ï¼QREï¼æ¦å¿µï¼å°åéçæ§ç´å¥ MFG ä¸­ãå©ç¨®æ°ç©ç MFG QRE é¡åå¯ä»¥å°å¤§åä»£çäººå£é²è¡å»ºæ¨¡ï¼å¶ä¸­åé«åå°çå¯¦ç®æ¨é²è¡éè¨ä¼°è¨ãæåééééå¶ä»£çäººçè¦åæåï¼å¨ MFG ä¸­å¼å¥ç¬¬äºååéçæ§ä¾æºãç±æ­¤ç¢ççæ°ç©å¾éæåï¼RHï¼MFG è QRE åç¾ææ¹æ³ç¸çµåï¼ä»¥å° MFG ä¸­åéçæ§çä¸åé¢åé²è¡å»ºæ¨¡ãæåæ­£å¼å®ç¾© MFG QRE å RH MFGï¼ä¸¦å°å®åèç¾æçåè¡¡æ¦å¿µï¼ä¾å¦çµæ­£åå NEï¼é²è¡æ¯è¼ãé¨å¾ï¼æåè¨­è¨äºå»£ç¾©ä¸åé»è¿­ä»£åèæ§åå¼æ¼ç®æ³ä¾å­¸ç¿ QRE å RH åè¡¡ãå¨é²è¡çè«åæå¾ï¼æåèåºä¸åçç¯ä¾ä¾è©ä¼°æåå­¸ç¿æ¼ç®æ³çè½åï¼ä¸¦æ¦è¿°åè¡¡æ¦å¿µä¹éçå¯¦éå·®ç°ã

##### **A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs**
2411.07098v1 by Myeongsoo Kim, Tyler Stennett, Saurabh Sinha, Alessandro Orso

As modern web services increasingly rely on REST APIs, their thorough testing
has become crucial. Furthermore, the advent of REST API specifications such as
the OpenAPI Specification has led to the emergence of many black-box REST API
testing tools. However, these tools often focus on individual test elements in
isolation (e.g., APIs, parameters, values), resulting in lower coverage and
less effectiveness in detecting faults (i.e., 500 response codes). To address
these limitations, we present AutoRestTest, the first black-box framework to
adopt a dependency-embedded multi-agent approach for REST API testing,
integrating Multi-Agent Reinforcement Learning (MARL) with a Semantic Property
Dependency Graph (SPDG) and Large Language Models (LLMs). Our approach treats
REST API testing as a separable problem, where four agents -- API, dependency,
parameter, and value -- collaborate to optimize API exploration. LLMs handle
domain-specific value restrictions, the SPDG model simplifies the search space
for dependencies using a similarity score between API operations, and MARL
dynamically optimizes the agents' behavior. Evaluated on 12 real-world REST
services, AutoRestTest outperforms the four leading black-box REST API testing
tools, including those assisted by RESTGPT (which augments realistic test
inputs using LLMs), in terms of code coverage, operation coverage, and fault
detection. Notably, AutoRestTest is the only tool able to identify an internal
server error in Spotify. Our ablation study underscores the significant
contributions of the agent learning, SPDG, and LLM components.

æè¦ï¼<paragraph>é¨èç¾ä»£ç¶²è·¯æåæ¥çä¾è³´ REST APIï¼å¶å¾¹åºçæ¸¬è©¦è®å¾è³ééè¦ãæ­¤å¤ï¼REST API è¦ç¯ï¼ä¾å¦ OpenAPI è¦ç¯ï¼çåºç¾ï¼å°è´è¨±å¤é»ç REST API æ¸¬è©¦å·¥å·çåºç¾ãç¶èï¼éäºå·¥å·éå¸¸å°æ³¨æ¼å®ç¨çæ¸¬è©¦åç´ ï¼ä¾å¦ APIãåæ¸ãå¼ï¼ï¼å°è´è¦èçè¼ä½ï¼ä¸å¨åµæ¸¬é¯èª¤ï¼å³ 500 åæç¢¼ï¼æ¹é¢æçè¼ä½ãçºäºè§£æ±ºéäºéå¶ï¼æåæåº AutoRestTestï¼éæ¯ç¬¬ä¸åæ¡ç¨ä¾è³´åµå¥å¼å¤ä»£çæ¹æ³é²è¡ REST API æ¸¬è©¦çé»çæ¡æ¶ï¼å°å¤ä»£çå¼·åå­¸ç¿ (MARL) èèªç¾©å±¬æ§ä¾è³´å (SPDG) åå¤§åèªè¨æ¨¡å (LLM) æ´åå¨ä¸èµ·ãæåçåæ³å° REST API æ¸¬è©¦è¦çºä¸åå¯åé¢çåé¡ï¼å¶ä¸­ååä»£çï¼APIãä¾è³´éä¿ãåæ¸åå¼ï¼åååä½ä»¥æä½³å API æ¢ç´¢ãLLM èçç¹å®é åçå¼éå¶ï¼SPDG æ¨¡åä½¿ç¨ API æä½ä¹éçç¸ä¼¼æ§åæ¸ç°¡åä¾è³´éä¿çæå°ç©ºéï¼è MARL ååææä½³åä»£ççè¡çºãå¨ 12 é çå¯¦ä¸çç REST æåä¸é²è¡è©ä¼°ï¼AutoRestTest å¨ç¨å¼ç¢¼è¦èçãæä½è¦èçåé¯èª¤åµæ¸¬æ¹é¢ï¼åªæ¼åç¨®é åçé»ç REST API æ¸¬è©¦å·¥å·ï¼åæ¬é£äºç± RESTGPTï¼ä½¿ç¨ LLM å¢å é¼ççæ¸¬è©¦è¼¸å¥ï¼è¼å©çå·¥å·ãå¼å¾æ³¨æçæ¯ï¼AutoRestTest æ¯å¯ä¸è½å¤ è­å¥ Spotify ä¸­å§é¨ä¼ºæå¨é¯èª¤çå·¥å·ãæåçæ¶èç ç©¶å¼·èª¿äºä»£çå­¸ç¿ãSPDG å LLM çµä»¶çéå¤§è²¢ç»ã</paragraph>

##### **Towards Characterizing Cyber Networks with Large Language Models**
2411.07089v1 by Alaric Hartsock, Luiz Manella Pereira, Glenn Fink

Threat hunting analyzes large, noisy, high-dimensional data to find sparse
adversarial behavior. We believe adversarial activities, however they are
disguised, are extremely difficult to completely obscure in high dimensional
space. In this paper, we employ these latent features of cyber data to find
anomalies via a prototype tool called Cyber Log Embeddings Model (CLEM). CLEM
was trained on Zeek network traffic logs from both a real-world production
network and an from Internet of Things (IoT) cybersecurity testbed. The model
is deliberately overtrained on a sliding window of data to characterize each
window closely. We use the Adjusted Rand Index (ARI) to comparing the k-means
clustering of CLEM output to expert labeling of the embeddings. Our approach
demonstrates that there is promise in using natural language modeling to
understand cyber data.

æè¦ï¼å¨èè¿½è¹¤åæå¤§éãéè¨ãé«ç¶­åº¦è³æï¼ä»¥æ¾åºç¨ççå°æè¡çºãæåç¸ä¿¡å°ææ´»åï¼ç¡è«å¶å¦ä½å½è£ï¼å¨é«ç¶­åº¦ç©ºéä¸­é½æ¥µé£å®å¨é±èãå¨æ¬æä¸­ï¼æåä½¿ç¨ç¶²è·¯è³æçéäºæ½å¨ç¹å¾µï¼ééä¸ååçºç¶²è·¯æ¥èªåµå¥æ¨¡å (CLEM) çååå·¥å·ä¾æ¾åºç°å¸¸å¼ãCLEM æ ¹æä¾èªçå¯¦ä¸ççç¢ç¶²è·¯åç©è¯ç¶² (IoT) ç¶²è·¯å®å¨æ¸¬è©¦å¹³å°ç Zeek ç¶²è·¯æµéæ¥èªé²è¡è¨ç·´ãè©²æ¨¡åææå¨è³æçæ»åè¦çªä¸é²è¡éåº¦è¨ç·´ï¼ä»¥ç²¾ç¢ºæè¿°æ¯åè¦çªãæåä½¿ç¨èª¿æ´è­å¾·ææ¸ (ARI) å° CLEM è¼¸åºç k å¹³åç¾¤éèåµå¥çå°å®¶æ¨ç±¤é²è¡æ¯è¼ãæåçåæ³è­æï¼ä½¿ç¨èªç¶èªè¨å»ºæ¨¡ä¾çè§£ç¶²è·¯è³ææ¯æå¸æçã

##### **OCMDP: Observation-Constrained Markov Decision Process**
2411.07087v1 by Taiyi Wang, Jianheng Liu, Jiaye Li, Zhihao Wu, Yu Wu

In many practical applications, decision-making processes must balance the
costs of acquiring information with the benefits it provides. Traditional
control systems often assume full observability, an unrealistic assumption when
observations are expensive. We tackle the challenge of simultaneously learning
observation and control strategies in such cost-sensitive environments by
introducing the Observation-Constrained Markov Decision Process (OCMDP), where
the policy influences the observability of the true state. To manage the
complexity arising from the combined observation and control actions, we
develop an iterative, model-free deep reinforcement learning algorithm that
separates the sensing and control components of the policy. This decomposition
enables efficient learning in the expanded action space by focusing on when and
what to observe, as well as determining optimal control actions, without
requiring knowledge of the environment's dynamics. We validate our approach on
a simulated diagnostic task and a realistic healthcare environment using
HeartPole. Given both scenarios, the experimental results demonstrate that our
model achieves a substantial reduction in observation costs on average,
significantly outperforming baseline methods by a notable margin in efficiency.

æè¦ï¼å¨è¨±å¤å¯¦éæç¨ä¸­ï¼æ±ºç­å¶å®æµç¨å¿é å¹³è¡¡åå¾è³è¨çææ¬èå¶æä¾çæçãå³çµ±æ§å¶ç³»çµ±éå¸¸åè¨­å®å¨å¯è§å¯æ§ï¼éå¨è§å¯ææ¬é«æææ¯ä¸åå¯¦éçåè¨­ãæåééå°å¥è§å¯åéé¦¬å¯å¤«æ±ºç­éç¨ (OCMDP) ä¾æå°å¨éç¨®ææ¬ææç°å¢ä¸­åæå­¸ç¿è§å¯åæ§å¶ç­ç¥çææ°ï¼å¶ä¸­æ¿ç­æå½±é¿çå¯¦çæçå¯è§å¯æ§ãçºäºç®¡çä¾èªçµåè§å¯åæ§å¶åä½çè¤éæ§ï¼æåéç¼äºä¸ç¨®åè¦ãç¡æ¨¡åçæ·±åº¦å¼·åå­¸ç¿æ¼ç®æ³ï¼å®å°ç­ç¥çææ¸¬åæ§å¶åä»¶åéãéç¨®åè§£ééå°æ³¨æ¼ä½æä»¥åè§å¯ä»éº¼ï¼ä»¥åç¢ºå®æä½³æ§å¶åä½ï¼å¨æ´å±çåä½ç©ºéä¸­å¯¦ç¾ææå­¸ç¿ï¼èç¡éäºè§£ç°å¢çåæãæåå¨æ¨¡æ¬è¨ºæ·ä»»ååä½¿ç¨ HeartPole çå¯¦éé«çä¿å¥ç°å¢ä¸­é©è­æåçåæ³ãå¨å©ç¨®ææ³ä¸ï¼å¯¦é©çµæè­ææåçæ¨¡åå¹³åå¯å¤§å¹éä½è§å¯ææ¬ï¼å¨æçæ¹é¢é¡¯èåªæ¼åºæºæ¹æ³ã

##### **StoryTeller: Improving Long Video Description through Global Audio-Visual Character Identification**
2411.07076v1 by Yichen He, Yuan Lin, Jianchao Wu, Hanchong Zhang, Yuchen Zhang, Ruicheng Le

Existing large vision-language models (LVLMs) are largely limited to
processing short, seconds-long videos and struggle with generating coherent
descriptions for extended video spanning minutes or more. Long video
description introduces new challenges, such as plot-level consistency across
descriptions. To address these, we figure out audio-visual character
identification, matching character names to each dialogue, as a key factor. We
propose StoryTeller, a system for generating dense descriptions of long videos,
incorporating both low-level visual concepts and high-level plot information.
StoryTeller uses a multimodal large language model that integrates visual,
audio, and text modalities to perform audio-visual character identification on
minute-long video clips. The results are then fed into a LVLM to enhance
consistency of video description. We validate our approach on movie description
tasks and introduce MovieStory101, a dataset with dense descriptions for
three-minute movie clips. To evaluate long video descriptions, we create
MovieQA, a large set of multiple-choice questions for the MovieStory101 test
set. We assess descriptions by inputting them into GPT-4 to answer these
questions, using accuracy as an automatic evaluation metric. Experiments show
that StoryTeller outperforms all open and closed-source baselines on MovieQA,
achieving 9.5% higher accuracy than the strongest baseline, Gemini-1.5-pro, and
demonstrating a +15.56% advantage in human side-by-side evaluations.
Additionally, incorporating audio-visual character identification from
StoryTeller improves the performance of all video description models, with
Gemini-1.5-pro and GPT-4o showing relative improvement of 5.5% and 13.0%,
respectively, in accuracy on MovieQA.

æè¦ï¼ç¾æçå¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) ä¸»è¦åéæ¼èçæ¸ç§é·çç­å½±çï¼ä¸¦é£ä»¥ç¢çé·éæ¸åéææ´é·æéçé£è²«å½±çèªªæãé·å½±çèªªæå¼å¥äºæ°çææ°ï¼ä¾å¦èªªæä¸­æç¯å±¤ç´çä¸è´æ§ãçºäºè§£æ±ºéäºåé¡ï¼æåæ¾åºè¦è¦ºè½è¦ºè§è²è­å¥ï¼å°è§è²åç¨±èæ¯åå°è©±éå°ï¼ä½çºä¸åééµå ç´ ãæåæåº StoryTellerï¼ä¸åç¨æ¼ç¢çé·å½±ççå¯éèªªæçç³»çµ±ï¼çµåäºä½éè¦è¦ºæ¦å¿µåé«éæç¯è³è¨ãStoryTeller ä½¿ç¨ä¸åæ´åè¦è¦ºãè½è¦ºåæå­æ¨¡å¼çå¤æ¨¡æå¤§åèªè¨æ¨¡åï¼å°é·éä¸åéçå½±çåªè¼¯å·è¡è¦è¦ºè½è¦ºè§è²è­å¥ãç¶å¾å°çµæè¼¸å¥ LVLM ä»¥å¢å¼·å½±çèªªæçä¸è´æ§ãæåå¨é»å½±èªªæä»»åä¸é©è­äºæåçåæ³ï¼ä¸¦å¼å¥äº MovieStory101ï¼ä¸ååå«ä¸åéé»å½±åªè¼¯çå¯éèªªæçè³æéãçºäºè©ä¼°é·å½±çèªªæï¼æåå»ºç«äº MovieQAï¼ä¸åéå° MovieStory101 æ¸¬è©¦éçå¤§åå¤éé¸æé¡çµãæåééå°èªªæè¼¸å¥ GPT-4 ä¾åç­éäºåé¡ä¾è©ä¼°èªªæï¼ä½¿ç¨æºç¢ºåº¦ä½çºèªåè©ä¼°ææ¨ãå¯¦é©é¡¯ç¤ºï¼StoryTeller å¨ MovieQA ä¸åªæ¼ææéæ¾åå°éåå§ç¢¼åºæºï¼æ¯æå¼·åºæº Gemini-1.5-pro é«åº 9.5% çæºç¢ºåº¦ï¼ä¸¦å¨äººé¡ä¸¦æè©ä¼°ä¸­å±ç¾åº +15.56% çåªå¢ãæ­¤å¤ï¼çµå StoryTeller çè¦è¦ºè½è¦ºè§è²è­å¥å¯ä»¥æåææå½±çèªªææ¨¡åçæè½ï¼å¶ä¸­ Gemini-1.5-pro å GPT-4o å¨ MovieQA ä¸çæºç¢ºåº¦åå¥é¡¯ç¤ºåº 5.5% å 13.0% çç¸å°æåã

##### **Transformer verbatim in-context retrieval across time and scale**
2411.07075v1 by Kristijan Armeni, Marko PranjiÄ, Senja Pollak

To predict upcoming text, language models must in some cases retrieve
in-context information verbatim. In this report, we investigated how the
ability of language models to retrieve arbitrary in-context nouns developed
during training (across time) and as language models trained on the same
dataset increase in size (across scale). We then asked whether learning of
in-context retrieval correlates with learning of more challenging zero-shot
benchmarks. Furthermore, inspired by semantic effects in human short-term
memory, we evaluated the retrieval with respect to a major semantic component
of target nouns, namely whether they denote a concrete or abstract entity, as
rated by humans. We show that verbatim in-context retrieval developed in a
sudden transition early in the training process, after about 1% of the training
tokens. This was observed across model sizes (from 14M and up to 12B
parameters), and the transition occurred slightly later for the two smallest
models. We further found that the development of verbatim in-context retrieval
is positively correlated with the learning of zero-shot benchmarks. Around the
transition point, all models showed the advantage of retrieving concrete nouns
as opposed to abstract nouns. In all but two smallest models, the advantage
dissipated away toward the end of training.

æè¦ï¼èªè¨æ¨¡åè¥è¦é æ¸¬å¾çºæå­ï¼ææå¿é éå­æ·åèçµ¡ä¸­çè³è¨ãå¨æ­¤å ±åä¸­ï¼æåæ¢è¨èªè¨æ¨¡åæ·åä»»æèçµ¡ä¸­åè©çè½åå¨è¨ç·´éç¨ä¸­ï¼é¨èæéæ¨ç§»ï¼åå¨éå°ç¸åè³æéè¨ç·´çèªè¨æ¨¡åå¤§å°å¢å ï¼é¨èè¦æ¨¡æ´å¤§ï¼çæ¼è®ãæ¥èæåæ¢è¨èçµ¡ä¸­æ·åçå­¸ç¿æ¯å¦èå­¸ç¿æ´å·ææ°æ§çé¶æ¬¡å­¸ç¿åºæºç¸éãæ­¤å¤ï¼åäººé¡ç­æè¨æ¶ä¸­èªç¾©ææçåç¼ï¼æåéå°ç®æ¨åè©çä¸»è¦èªç¾©æåè©ä¼°æ·åï¼ä¹å°±æ¯ç±äººé¡è©åçåè©æ¯å¦è¡¨ç¤ºå·é«ææ½è±¡å¯¦é«ãæåé¡¯ç¤ºéå­èçµ¡ä¸­æ·åå¨è¨ç·´éç¨çæ©æçªç¶è½è®ä¸­ç¼å±ï¼å¤§ç´å¨è¨ç·´ç¬¦èç 1% ä¹å¾ãéå¨åç¨®æ¨¡åå¤§å°ï¼å¾ 14M å° 12B åæ¸ï¼ä¸­è§å¯å°ï¼èä¸è½è®ç¼çå¨å©åæå°æ¨¡åçç¨å¾æéãæåé²ä¸æ­¥ç¼ç¾ï¼éå­èçµ¡ä¸­æ·åçç¼å±èé¶æ¬¡å­¸ç¿åºæºçå­¸ç¿åæ­£ç¸éãå¨è½è®é»éè¿ï¼æææ¨¡åé½é¡¯ç¤ºåºæ·åå·é«åè©èéæ½è±¡åè©çåªå¢ãå¨æææ¨¡åä¸­ï¼é¤äºå©åæå°æ¨¡åï¼åªå¢å¨è¨ç·´çµææéæ¼¸æ¶å¤±ã

##### **Universal Response and Emergence of Induction in LLMs**
2411.07071v1 by Niclas Luick

While induction is considered a key mechanism for in-context learning in
LLMs, understanding its precise circuit decomposition beyond toy models remains
elusive. Here, we study the emergence of induction behavior within LLMs by
probing their response to weak single-token perturbations of the residual
stream. We find that LLMs exhibit a robust, universal regime in which their
response remains scale-invariant under changes in perturbation strength,
thereby allowing us to quantify the build-up of token correlations throughout
the model. By applying our method, we observe signatures of induction behavior
within the residual stream of Gemma-2-2B, Llama-3.2-3B, and GPT-2-XL. Across
all models, we find that these induction signatures gradually emerge within
intermediate layers and identify the relevant model sections composing this
behavior. Our results provide insights into the collective interplay of
components within LLMs and serve as a benchmark for large-scale circuit
analysis.

æè¦ï¼éç¶æ­¸ç´è¢«èªçºæ¯ LLM ä¸­æå¢å­¸ç¿çééµæ©å¶ï¼ä½è¦çè§£å¶è¶è¶ç©å·æ¨¡åçç²¾ç¢ºé»è·¯åè§£ä»ç¶é£ä»¥ææ¸ãå¨æ­¤ï¼æåééæ¢æ¸¬ LLM å°æ®å·®æµçå¾®å¼±å®ä¸ç¬¦èæ¾åçåæï¼ç ç©¶äºæ­¸ç´è¡çºå¨ LLM ä¸­çåºç¾ãæåç¼ç¾ï¼LLM è¡¨ç¾åºä¸åç©©å¥ãéç¨çæ©å¶ï¼å¶ä¸­å®åçåæå¨æ¾åå¼·åº¦è®åä¸ä¿æå°ºåº¦ä¸è®ï¼å¾èä½¿æåè½å¤ éåæ´åæ¨¡åä¸­ç¬¦èç¸éæ§çç´¯ç©ãééæç¨æåçæ¨¡åï¼æåè§å¯å° Gemma-2-2BãLlama-3.2-3B å GPT-2-XL çæ®å·®æµä¸­çæ­¸ç´è¡çºç¹å¾µãå¨æææ¨¡åä¸­ï¼æåç¼ç¾éäºæ­¸ç´ç¹å¾µéæ¼¸åºç¾å¨ä¸­éå±¤ï¼ä¸¦è­å¥åºæ§æéç¨®è¡çºçç¸éæ¨¡åé¨åãæåççµææä¾äºå° LLM å§é¨çµæé¨åçéé«äº¤äºä½ç¨çè¦è§£ï¼ä¸¦ä½çºå¤§è¦æ¨¡é»è·¯åæçåºæºã

##### **On Active Privacy Auditing in Supervised Fine-tuning for White-Box Language Models**
2411.07070v1 by Qian Sun, Hanpeng Wu, Xi Sheryl Zhang

The pretraining and fine-tuning approach has become the leading technique for
various NLP applications. However, recent studies reveal that fine-tuning data,
due to their sensitive nature, domain-specific characteristics, and
identifiability, pose significant privacy concerns. To help develop more
privacy-resilient fine-tuning models, we introduce a novel active privacy
auditing framework, dubbed Parsing, designed to identify and quantify privacy
leakage risks during the supervised fine-tuning (SFT) of language models (LMs).
The framework leverages improved white-box membership inference attacks (MIAs)
as the core technology, utilizing novel learning objectives and a two-stage
pipeline to monitor the privacy of the LMs' fine-tuning process, maximizing the
exposure of privacy risks. Additionally, we have improved the effectiveness of
MIAs on large LMs including GPT-2, Llama2, and certain variants of them. Our
research aims to provide the SFT community of LMs with a reliable, ready-to-use
privacy auditing tool, and to offer valuable insights into safeguarding privacy
during the fine-tuning process. Experimental results confirm the framework's
efficiency across various models and tasks, emphasizing notable privacy
concerns in the fine-tuning process. Project code available for
https://github.com/mapleleavesss/PARSING.

æè¦ï¼é è¨ç·´åå¾®èª¿æ¹æ³å·²æçºåç¨® NLP æç¨ç¨å¼çä¸»æµæè¡ãç¶èï¼æè¿çç ç©¶é¡¯ç¤ºï¼å¾®èª¿è³æç±æ¼å¶ææçæ¬è³ªãç¹å®é åçç¹å¾µåå¯è­å¥æ§ï¼æé æéå¤§çé±ç§åé¡ãçºäºåå©éç¼æ´å·é±ç§å½æ§çå¾®èª¿æ¨¡åï¼æåå¼é²ä¸ååµæ°çä¸»åå¼é±ç§ç¨½æ ¸æ¶æ§ï¼ç¨±çº Parsingï¼å¶è¨­è¨ç®çæ¯å¨èªè¨æ¨¡å (LM) çç£ç£å¼å¾®èª¿ (SFT) éç¨ä¸­è­å¥åéåé±ç§å¤æ´©é¢¨éªãæ­¤æ¶æ§å©ç¨æ¹è¯çç½çæå¡èº«åæ¨è«æ»æ (MIA) ä½çºæ ¸å¿æè¡ï¼æ¡ç¨æ°ç©çå­¸ç¿ç®æ¨åå©éæ®µç®¡ç·ä¾ç£æ§ LM å¾®èª¿ç¨åºçé±ç§ï¼æå¤§åé±ç§é¢¨éªçæ´é²ãæ­¤å¤ï¼æåå·²ç¶æ¹åäº MIA å¨å¤§å LMï¼åæ¬ GPT-2ãLlama2 åæäºè®é«ï¼ä¸çæè½ãæåçç ç©¶æ¨å¨çº LM ç SFT ç¤¾ç¾¤æä¾ä¸åå¯é ãå¯ç«å³ä½¿ç¨çé±ç§ç¨½æ ¸å·¥å·ï¼ä¸¦æä¾æå¹å¼çè¦è§£ï¼ä»¥å¨å¾®èª¿éç¨ä¸­ä¿è­·é±ç§ãå¯¦é©çµæè­å¯¦äºæ­¤æ¶æ§å¨åç¨®æ¨¡ååä»»åä¸­çæçï¼å¼·èª¿äºå¾®èª¿éç¨ä¸­é¡¯èçé±ç§åé¡ãå°æ¡ç¨å¼ç¢¼å¯æ¼ https://github.com/mapleleavesss/PARSING åå¾ã

##### **Zeroth-Order Adaptive Neuron Alignment Based Pruning without Re-Training**
2411.07066v1 by Elia Cunegatti, Leonardo Lucio Custode, Giovanni Iacca

Network pruning is a set of computational techniques that aim to reduce a
given model's computational cost by removing a subset of its parameters while
having minimal impact on performance. Throughout the last decade, the most
widely used pruning paradigm has focused on pruning and re-training, which
nowadays is inconvenient due to the vast amount of pre-trained models, which
are in any case too expensive to re-train. In this paper, we exploit functional
information from dense pre-trained models, i.e., their activations, to obtain
sparse models that maximize the activations' alignment w.r.t. their
corresponding dense models. Hence, we propose \textsc{NeuroAl}, a \emph{top-up}
algorithm that can be used on top of any given pruning algorithm for LLMs, that
modifies the block-wise and row-wise sparsity ratios to maximize the
\emph{neuron alignment} among activations. Moreover, differently from existing
methods, our approach adaptively selects the best parameters for the block-wise
and row-wise sparsity ratios w.r.t. to the model and the desired sparsity
(given as input), and requires \emph{no re-training}. We test our method on 4
different LLM families and 3 different sparsity ratios, showing how it
consistently outperforms the latest state-of-the-art techniques. The code is
available at https://github.com/eliacunegatti/NeuroAL.

æè¦ï¼ç¶²è·¯åªææ¯ä¸çµè¨ç®æè¡ï¼æ¨å¨ééç§»é¤æ¨¡ååæ¸å­éä¾éä½çµ¦å®æ¨¡åçè¨ç®ææ¬ï¼åæå°æè½çå½±é¿éå°æä½ãå¨éå»åå¹´ä¸­ï¼ä½¿ç¨æå»£æ³çåªæç¯ä¾èéæ¼åªæåéæ°è¨ç·´ï¼éå¨ç¾ä»ç±æ¼å¤§éçé è¨ç·´æ¨¡åèè®å¾ä¸æ¹ä¾¿ï¼èéäºæ¨¡åå¨ä»»ä½ææ³ä¸é½å¤ªæè²´èç¡æ³éæ°è¨ç·´ãå¨æ¬æä¸­ï¼æåå©ç¨ç¨ å¯é è¨ç·´æ¨¡åä¸­çåè½è³è¨ï¼å³å®åçæ´»åï¼ä»¥åå¾ç¨çæ¨¡åï¼æå¤§åæ´»åèå¶å°æç¨ å¯æ¨¡åçå°é½ãå æ­¤ï¼æåæåº \textsc{NeuroAl}ï¼ä¸ç¨®å¯ä»¥éå°ä»»ä½çµ¦å®ç LLM åªææ¼ç®æ³ä½¿ç¨ç \emph{è£å} æ¼ç®æ³ï¼å®ä¿®æ¹åå¡ååçç¨ççä»¥æå¤§åæ´»åä¹éç \emph{ç¥ç¶åå°é½}ãæ­¤å¤ï¼èç¾ææ¹æ³ä¸åï¼æåçåæ³èªé©æå°éå°åå¡ååçç¨ççé¸ææä½³åæ¸ï¼ä¸èæ¨¡ååæéçç¨ççï¼ä½çºè¼¸å¥æä¾ï¼æéï¼ä¸¦ä¸éè¦ \emph{ç¡éæ°è¨ç·´}ãæåå¨ 4 åä¸åç LLM ç³»åå 3 åä¸åçç¨ççä¸æ¸¬è©¦æåçåæ³ï¼é¡¯ç¤ºå®å¦ä½æçºåªæ¼ææ°çæåé²æè¡ãç¨å¼ç¢¼å¯å¨ https://github.com/eliacunegatti/NeuroAL åå¾ã

##### **Minion: A Technology Probe for Resolving Value Conflicts through Expert-Driven and User-Driven Strategies in AI Companion Applications**
2411.07042v1 by Xianzhe Fan, Qing Xiao, Xuhui Zhou, Yuran Su, Zhicong Lu, Maarten Sap, Hong Shen

AI companions based on large language models can role-play and converse very
naturally. When value conflicts arise between the AI companion and the user, it
may offend or upset the user. Yet, little research has examined such conflicts.
We first conducted a formative study that analyzed 151 user complaints about
conflicts with AI companions, providing design implications for our study.
Based on these, we created Minion, a technology probe to help users resolve
human-AI value conflicts. Minion applies a user-empowerment intervention method
that provides suggestions by combining expert-driven and user-driven conflict
resolution strategies. We conducted a technology probe study, creating 40 value
conflict scenarios on Character.AI and Talkie. 22 participants completed 274
tasks and successfully resolved conflicts 94.16% of the time. We summarize user
responses, preferences, and needs in resolving value conflicts, and propose
design implications to reduce conflicts and empower users to resolve them more
effectively.

æè¦ï¼åºæ¼å¤§åèªè¨æ¨¡åçäººå·¥æºæ§ä¼´ä¾¶å¯ä»¥æ®æ¼è§è²ä¸¦éå¸¸èªç¶å°äº¤è«ãç¶äººå·¥æºæ§ä¼´ä¾¶èä½¿ç¨èä¹éåºç¾å¹å¼è§è¡çªæï¼å¯è½æåç¯ææ¿æä½¿ç¨èãç¶èï¼å¾å°æç ç©¶æ¢è¨æ­¤é¡è¡çªãæåé¦åé²è¡äºä¸é å½¢ææ§ç ç©¶ï¼åæäº 151 èµ·éæ¼èäººå·¥æºæ§ä¼´ä¾¶ç¼çè¡çªçä½¿ç¨èæ±æ¨ï¼ä¸¦çºæåçç ç©¶æä¾äºè¨­è¨åç¤ºãåºæ¼éäºï¼æååµé äº Minionï¼éæ¯ä¸ç¨®æè¡æ¢æ¸¬ï¼å¯å¹«å©ä½¿ç¨èè§£æ±ºäººèäººå·¥æºæ§çå¹å¼è§è¡çªãMinion æ¡ç¨ä½¿ç¨èææ¬ä»å¥æ¹æ³ï¼çµåå°å®¶é©ååä½¿ç¨èé©åçè¡çªè§£æ±ºç­ç¥ä¾æä¾å»ºè­°ãæåé²è¡äºä¸é æè¡æ¢æ¸¬ç ç©¶ï¼å¨ Character.AI å Talkie ä¸åµé äº 40 åå¹å¼è§è¡çªæå¢ã22 ä½åèèå®æäº 274 é ä»»åï¼ä¸¦å¨ 94.16% çæéå§æåè§£æ±ºè¡çªãæåç¸½çµäºä½¿ç¨èå¨è§£æ±ºå¹å¼è§è¡çªæçåæãåå¥½åéæ±ï¼ä¸¦æåºè¨­è¨åç¤ºï¼ä»¥æ¸å°è¡çªä¸¦è³¦äºä½¿ç¨èæ´ææå°è§£æ±ºè¡çªçè½åã

##### **Designing Reliable Experiments with Generative Agent-Based Modeling: A Comprehensive Guide Using Concordia by Google DeepMind**
2411.07038v1 by Alejandro Leonardo GarcÃ­a Navarro, Nataliia Koneva, Alfonso SÃ¡nchez-MaciÃ¡n, JosÃ© Alberto HernÃ¡ndez, Manuel Goyanes

In social sciences, researchers often face challenges when conducting
large-scale experiments, particularly due to the simulations' complexity and
the lack of technical expertise required to develop such frameworks.
Agent-Based Modeling (ABM) is a computational approach that simulates agents'
actions and interactions to evaluate how their behaviors influence the
outcomes. However, the traditional implementation of ABM can be demanding and
complex. Generative Agent-Based Modeling (GABM) offers a solution by enabling
scholars to create simulations where AI-driven agents can generate complex
behaviors based on underlying rules and interactions. This paper introduces a
framework for designing reliable experiments using GABM, making sophisticated
simulation techniques more accessible to researchers across various fields. We
provide a step-by-step guide for selecting appropriate tools, designing the
model, establishing experimentation protocols, and validating results.

æè¦ï¼<paragraph>å¨ç¤¾æç§å­¸ä¸­ï¼ç ç©¶äººå¡å¨é²è¡
å¤§è¦æ¨¡å¯¦é©æå¸¸å¸¸æé¢è¨ææ°ï¼ç¹å¥æ¯æ¨¡æ¬çè¤éæ§ä»¥åéç¼æ­¤é¡æ¡æ¶æéæè¡å°æ¥­ç¥è­çç¼ºä¹ã
åºæ¼ä»£ççå»ºæ¨¡ (ABM) æ¯ä¸ç¨®è¨ç®æ¹æ³ï¼ç¨æ¼æ¨¡æ¬ä»£çç
åä½åäºåï¼ä»¥è©ä¼°ä»åçè¡çºå¦ä½å½±é¿
çµæãç¶èï¼ABM çå³çµ±å¯¦æ½å¯è½æ¯è¦æ±å´æ ¼ä¸
è¤éçãçæå¼åºæ¼ä»£ççå»ºæ¨¡ (GABM) æä¾äºè§£æ±ºæ¹æ¡ï¼æ¹æ³æ¯è®
å­¸èè½å¤ å»ºç«æ¨¡æ¬ï¼å¶ä¸­ç± AI é©åçä»£çå¯ä»¥æ ¹æ
åºå±¤è¦ååäºåç¢çè¤éçè¡çºãæ¬æä»ç´¹äºä¸å
ä½¿ç¨ GABM è¨­è¨å¯é å¯¦é©çæ¡æ¶ï¼è®ååé åçç ç©¶äººå¡æ´è½ä½¿ç¨è¤é
çæ¨¡æ¬æè¡ãæåæä¾äºä¸åéæ­¥æåï¼ç¨æ¼é¸æé©ç¶çå·¥å·ãè¨­è¨
æ¨¡åãå»ºç«å¯¦é©è¦ç¨åé©è­çµæã</paragraph>

##### **LIFBench: Evaluating the Instruction Following Performance and Stability of Large Language Models in Long-Context Scenarios**
2411.07037v1 by Xiaodong Wu, Minhao Wang, Yichen Liu, Xiaoming Shi, He Yan, Xiangju Lu, Junmin Zhu, Wei Zhang

As Large Language Models (LLMs) continue to advance in natural language
processing (NLP), their ability to stably follow instructions in long-context
inputs has become crucial for real-world applications. While existing
benchmarks assess various LLM capabilities, they rarely focus on
instruction-following in long-context scenarios or stability on different
inputs. In response, we introduce the Long-context Instruction-Following
Benchmark (LIFBench), a scalable dataset designed to evaluate LLMs'
instruction-following capabilities and stability across long contexts. LIFBench
comprises three long-context scenarios and eleven diverse tasks, supported by
2,766 instructions generated through an automated expansion method across three
dimensions: length, expression, and variables. For evaluation, we propose
LIFEval, a rubric-based assessment framework that provides precise, automated
scoring of complex LLM responses without relying on LLM-assisted evaluations or
human judgments. This approach facilitates a comprehensive analysis of model
performance and stability across various perspectives. We conduct extensive
experiments on 20 notable LLMs across six length intervals, analyzing their
instruction-following capabilities and stability. Our work contributes LIFBench
and LIFEval as robust tools for assessing LLM performance in complex,
long-context settings, providing insights that can inform future LLM
development.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) å¨èªç¶èªè¨èç (NLP) ä¸­æçºé²æ­¥ï¼å®åå¨é·èªå¢è¼¸å¥ä¸­ç©©å®éµå¾ªæä»¤çè½åå°æ¼å¯¦éæç¨å·²è®å¾è³ééè¦ãç¾æçåºæºè©ä¼°åç¨® LLM è½åï¼ä½å®åå¾å°éæ³¨é·èªå¢å ´æ¯ä¸­çæä»¤éµå¾ªæä¸åè¼¸å¥çç©©å®æ§ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äºé·èªå¢æä»¤éµå¾ªåºæº (LIFBench)ï¼éæ¯ä¸åå¯æ´åçè³æéï¼æ¨å¨è©ä¼° LLM å¨é·èªå¢ä¸­çæä»¤éµå¾ªè½ååç©©å®æ§ãLIFBench åå«ä¸ç¨®é·èªå¢å ´æ¯ååä¸é ä¸åçä»»åï¼ä¸¦ééèªåæ´åæ¹æ³å¨ä¸åç¶­åº¦ï¼é·åº¦ãè¡¨éå¼åè®æ¸ï¼ä¸­ç¢ç 2,766 æ¢æä»¤ãçºäºè©ä¼°ï¼æåæåºäº LIFEvalï¼éæ¯ä¸ååºæ¼è¦åçè©éæ¶æ§ï¼å¯ä»¥å¨ä¸ä¾è³´ LLM è¼å©è©ä¼°æäººé¡å¤æ·çææ³ä¸ï¼å°è¤éç LLM åæé²è¡ç²¾ç¢ºçèªåè©åãéç¨®æ¹æ³æå©æ¼å¨é¢åææ¨¡åå¨åç¨®è§é»ä¸çæè½åç©©å®æ§ãæåå°å­åé·åº¦åéä¸­ç 20 åèåç LLM é²è¡äºå»£æ³çå¯¦é©ï¼åæäºå®åçæä»¤éµå¾ªè½ååç©©å®æ§ãæåçç ç©¶è²¢ç»äº LIFBench å LIFEvalï¼ä½çºè©ä¼° LLM å¨è¤éãé·èªå¢è¨­å®ä¸­æè½çå¼·å¤§å·¥å·ï¼ä¸¦æä¾äºå¯ä»¥çºæªä¾ç LLM éç¼æä¾åèçè¦è§£ã

##### **UniHR: Hierarchical Representation Learning for Unified Knowledge Graph Link Prediction**
2411.07019v1 by Zhiqiang Liu, Mingyang Chen, Yin Hua, Zhuo Chen, Ziqi Liu, Lei Liang, Huajun Chen, Wen Zhang

Beyond-triple fact representations including hyper-relational facts with
auxiliary key-value pairs, temporal facts with additional timestamps, and
nested facts implying relationships between facts, are gaining significant
attention. However, existing link prediction models are usually designed for
one specific type of facts, making it difficult to generalize to other fact
representations. To overcome this limitation, we propose a Unified Hierarchical
Representation learning framework (UniHR) for unified knowledge graph link
prediction. It consists of a unified Hierarchical Data Representation (HiDR)
module and a unified Hierarchical Structure Learning (HiSL) module as graph
encoder. The HiDR module unifies hyper-relational KGs, temporal KGs, and nested
factual KGs into triple-based representations. Then HiSL incorporates
intra-fact and inter-fact message passing, focusing on enhancing the semantic
information within individual facts and enriching the structural information
between facts. Experimental results across 7 datasets from 3 types of KGs
demonstrate that our UniHR outperforms baselines designed for one specific kind
of KG, indicating strong generalization capability of HiDR form and the
effectiveness of HiSL module. Code and data are available at
https://github.com/Lza12a/UniHR.

æè¦ï¼è¶è¶ä¸åçµäºå¯¦è¡¨ç¤ºï¼åæ¬å·æè¼å©éµå¼å°çè¶éä¿äºå¯¦ãå·æéå æéæ³çæéäºå¯¦ï¼ä»¥åæç¤ºäºå¯¦ä¹ééä¿çåµå¥äºå¯¦ï¼æ­£åå°æ¥µå¤§çéæ³¨ãç¶èï¼ç¾æçé£çµé æ¸¬æ¨¡åéå¸¸æ¯çºç¹å®é¡åçäºå¯¦èè¨­è¨çï¼éä½¿å¾æ¦æ¬å°å¶ä»äºå¯¦è¡¨ç¤ºè®å¾å°é£ãçºäºåæéåéå¶ï¼æåæåºäºä¸åçµ±ä¸çåå±¤è¡¨ç¤ºå­¸ç¿æ¡æ¶ (UniHR)ï¼ç¨æ¼çµ±ä¸çç¥è­åè­é£çµé æ¸¬ãå®åå«ä¸åçµ±ä¸çåå±¤æ¸æè¡¨ç¤º (HiDR) æ¨¡çµåä¸åçµ±ä¸çåå±¤çµæ§å­¸ç¿ (HiSL) æ¨¡çµä½çºåå½¢ç·¨ç¢¼å¨ãHiDR æ¨¡çµå°è¶éä¿ KGãæé KG ååµå¥äºå¯¦ KG çµ±ä¸å°åºæ¼ä¸åçµçè¡¨ç¤ºä¸­ãç¶å¾ï¼HiSL çµåäºäºå¯¦å§åäºå¯¦éçè¨æ¯å³éï¼éé»å å¼·åå¥äºå¯¦ä¸­çèªç¾©è³è¨ä¸¦è±å¯äºå¯¦ä¹éççµæ§è³è¨ãä¾èª 3 ç¨®é¡å KG ç 7 åè³æéçå¯¦é©çµæè­æï¼æåç UniHR åªæ¼çºç¹å®é¡å KG è¨­è¨çåºæºï¼è¡¨æ HiDR å½¢å¼çå¼·æ³åè½åå HiSL æ¨¡çµçæææ§ãç¨å¼ç¢¼åè³æå¯å¨ https://github.com/Lza12a/UniHR åå¾ã

##### **Leveraging LSTM for Predictive Modeling of Satellite Clock Bias**
2411.07015v1 by Ahan Bhatt, Ishaan Mehta, Pravin Patidar

Satellite clock bias prediction plays a crucial role in enhancing the
accuracy of satellite navigation systems. In this paper, we propose an approach
utilizing Long Short-Term Memory (LSTM) networks to predict satellite clock
bias. We gather data from the PRN 8 satellite of the Galileo and preprocess it
to obtain a single difference sequence, crucial for normalizing the data.
Normalization allows resampling of the data, ensuring that the predictions are
equidistant and complete. Our methodology involves training the LSTM model on
varying lengths of datasets, ranging from 7 days to 31 days. We employ a
training set consisting of two days' worth of data in each case. Our LSTM model
exhibits exceptional accuracy, with a Root Mean Square Error (RMSE) of 2.11
$\times$ 10$^{-11}$. Notably, our approach outperforms traditional methods used
for similar time-series forecasting projects, being 170 times more accurate
than RNN, 2.3 $\times$ 10$^7$ times more accurate than MLP, and 1.9 $\times$
10$^4$ times more accurate than ARIMA. This study holds significant potential
in enhancing the accuracy and efficiency of low-power receivers used in various
devices, particularly those requiring power conservation. By providing more
accurate predictions of satellite clock bias, the findings of this research can
be integrated into the algorithms of such devices, enabling them to function
with heightened precision while conserving power. Improved accuracy in clock
bias predictions ensures that low-power receivers can maintain optimal
performance levels, thereby enhancing the overall reliability and effectiveness
of satellite navigation systems. Consequently, this advancement holds promise
for a wide range of applications, including remote areas, IoT devices, wearable
technology, and other devices where power efficiency and navigation accuracy
are paramount.

æè¦ï¼<paragraph>è¡ææéåå·®é æ¸¬å¨æåè¡æå°èªç³»çµ±æºç¢ºåº¦æ¹é¢æ®æ¼èééµè§è²ãå¨æ¬æä¸­ï¼æåæåºä¸åå©ç¨é·ç­æè¨æ¶ç¶²è·¯ (LSTM) ä¾é æ¸¬è¡ææéåå·®çæ¹æ³ãæåå¾ä¼½å©ç¥ç PRN 8 è¡ææ¶éè³æï¼ä¸¦å°å¶é²è¡é èçä»¥åå¾å®ä¸å·®ååºåï¼éå°æ¼æ¨æºåè³æè³ééè¦ãæ¨æºååè¨±å°è³æé²è¡éæ°åæ¨£ï¼ç¢ºä¿é æ¸¬æ¯ç­è·ä¸å®æ´çãæåçæè¡åæ¬å¨ä¸åé·åº¦çè³æéä¸è¨ç·´ LSTM æ¨¡åï¼ç¯åå¾ 7 å¤©å° 31 å¤©ãæåå¨æ¯ç¨®ææ³ä¸é½ä½¿ç¨åå«å©å¤©è³æçè¨ç·´çµãæåç LSTM æ¨¡åå±ç¾åºæ¥µä½³çæºç¢ºåº¦ï¼åæ¹æ ¹èª¤å·® (RMSE) çº 2.11 $\times$ 10$^{-11}$ãå¼å¾æ³¨æçæ¯ï¼æåçåæ³åªæ¼ç¨æ¼é¡ä¼¼æéåºåé æ¸¬å°æ¡çå³çµ±æ¹æ³ï¼æ¯ RNN æºç¢º 170 åï¼æ¯ MLP æºç¢º 2.3 $\times$ 10$^7$ åï¼æ¯ ARIMA æºç¢º 1.9 $\times$ 10$^4$ åãéé ç ç©¶å¨æååç¨®è£ç½®ä¸­ä½¿ç¨çä½åçæ¥æ¶å¨çæºç¢ºåº¦åæçæ¹é¢å·æé¡¯èçæ½åï¼ç¹å¥æ¯é£äºéè¦ç¯è½çè£ç½®ãééæä¾æ´æºç¢ºçè¡ææéåå·®é æ¸¬ï¼éé ç ç©¶çç¼ç¾å¯ä»¥æ´åå°éäºè£ç½®çæ¼ç®æ³ä¸­ï¼è®å®åå¨ç¯è½çåæéè½ä»¥æ´é«çç²¾æºåº¦éä½ãæéåå·®é æ¸¬æºç¢ºåº¦çæåç¢ºä¿ä½åçæ¥æ¶å¨è½ç¶­ææä½³æè½ï¼é²èæåè¡æå°èªç³»çµ±çæ´é«å¯é åº¦åæè½ãå æ­¤ï¼éé é²å±ææå¨å»£æ³çæç¨ä¸­ç¼æ®ä½ç¨ï¼åæ¬åé å°åãIoT è£ç½®ãç©¿æ´å¼æè¡ä»¥åå¶ä»ä»¥é»åæçåå°èªæºç¢ºåº¦çºé¦è¦èéçè£ç½®ã</paragraph>

##### **A neural-network based anomaly detection system and a safety protocol to protect vehicular network**
2411.07013v1 by Marco Franceschini

This thesis addresses the use of Cooperative Intelligent Transport Systems
(CITS) to improve road safety and efficiency by enabling vehicle-to-vehicle
communication, highlighting the importance of secure and accurate data
exchange. To ensure safety, the thesis proposes a Machine Learning-based
Misbehavior Detection System (MDS) using Long Short-Term Memory (LSTM) networks
to detect and mitigate incorrect or misleading messages within vehicular
networks. Trained offline on the VeReMi dataset, the detection model is tested
in real-time within a platooning scenario, demonstrating that it can prevent
nearly all accidents caused by misbehavior by triggering a defense protocol
that dissolves the platoon if anomalies are detected. The results show that
while the system can accurately detect general misbehavior, it struggles to
label specific types due to varying traffic conditions, implying the difficulty
of creating a universally adaptive protocol. However, the thesis suggests that
with more data and further refinement, this MDS could be implemented in
real-world CITS, enhancing driving safety by mitigating risks from misbehavior
in cooperative driving networks.

æè¦ï¼æ¬è«ææ¢è¨ä½¿ç¨ååæºæ§éè¼¸ç³»çµ± (CITS) ä¾æ¹åéè·¯å®å¨åæçï¼æ¹æ³æ¯åç¨è»å°è»éè¨ï¼ä¸¦å¼·èª¿å®å¨ä¸æºç¢ºçè³æäº¤æçéè¦æ§ãçºäºç¢ºä¿å®å¨ï¼æ¬è«ææåºä¸ååºæ¼æ©å¨å­¸ç¿çä¸ç¶è¡çºåµæ¸¬ç³»çµ± (MDS)ï¼ä½¿ç¨é·ç­æè¨æ¶ (LSTM) ç¶²è·¯ä¾åµæ¸¬åæ¸è¼è»è¼ç¶²è·¯ä¸­çä¸æ­£ç¢ºæèª¤å°è¨æ¯ãåµæ¸¬æ¨¡åå¨ VeReMi è³æéä¸é¢ç·è¨ç·´ï¼ä¸¦å¨æéå ´æ¯ä¸­é²è¡å³ææ¸¬è©¦ï¼è­æå®å¯ä»¥ééè§¸ç¼é²ç¦¦åå®ä¾é²æ­¢å¹¾ä¹ææç±ä¸ç¶è¡çºé æçæå¤ï¼èç¶åµæ¸¬å°ç°å¸¸æï¼æè§£æ£æéãçµæé¡¯ç¤ºï¼éç¶ç³»çµ±å¯ä»¥æºç¢ºåµæ¸¬ä¸è¬çä¸ç¶è¡çºï¼ä½ç±æ¼äº¤éçæ³ä¸åï¼ç³»çµ±é£ä»¥æ¨è¨ç¹å®é¡åçä¸ç¶è¡çºï¼éè¡¨ç¤ºå»ºç«ä¸åæ®éé©æçåå®æå¶é£åº¦ãç¶èï¼æ¬è«æå»ºè­°ï¼ééæ´å¤è³æåé²ä¸æ­¥çä¿®æ­£ï¼éå MDS å¯ä»¥å¯¦ä½å¨çå¯¦ä¸çç CITS ä¸­ï¼ééæ¸è¼ååé§é§ç¶²è·¯ä¸­ä¸ç¶è¡çºçé¢¨éªä¾æåè¡è»å®å¨ã

##### **Non-Adversarial Inverse Reinforcement Learning via Successor Feature Matching**
2411.07007v1 by Arnav Kumar Jain, Harley Wiltzer, Jesse Farebrother, Irina Rish, Glen Berseth, Sanjiban Choudhury

In inverse reinforcement learning (IRL), an agent seeks to replicate expert
demonstrations through interactions with the environment. Traditionally, IRL is
treated as an adversarial game, where an adversary searches over reward models,
and a learner optimizes the reward through repeated RL procedures. This
game-solving approach is both computationally expensive and difficult to
stabilize. In this work, we propose a novel approach to IRL by direct policy
optimization: exploiting a linear factorization of the return as the inner
product of successor features and a reward vector, we design an IRL algorithm
by policy gradient descent on the gap between the learner and expert features.
Our non-adversarial method does not require learning a reward function and can
be solved seamlessly with existing actor-critic RL algorithms. Remarkably, our
approach works in state-only settings without expert action labels, a setting
which behavior cloning (BC) cannot solve. Empirical results demonstrate that
our method learns from as few as a single expert demonstration and achieves
improved performance on various control tasks.

æè¦ï¼å¨éåå¼·åå­¸ç¿ (IRL) ä¸­ï¼ä»£çæééèç°å¢äºåä¾è¤è£½å°å®¶ç¤ºç¯ãå³çµ±ä¸ï¼IRL è¢«è¦çºå°ææ§éæ²ï¼å°æææå°çåµæ¨¡åï¼èå­¸ç¿èæéééè¤ç RL ç¨åºæä½³åçåµãéç¨®éæ²è§£æ³æ¢èè²»éç®è³æºï¼åé£ä»¥ç©©å®ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®ééç´æ¥æ¿ç­æä½³åä¾é²è¡ IRL çæ°æ¹æ³ï¼å©ç¨åå ±çç·æ§åè§£ä½çºå¾ç¹¼ç¹å¾µåçåµåéçå§ç©ï¼æåééå­¸ç¿èåå°å®¶ç¹å¾µä¹éçå·®è·ä¾è¨­è¨ä¸ç¨® IRL æ¼ç®æ³ï¼ä¸¦ééç­ç¥æ¢¯åº¦ä¸éæ³é²è¡ãæåçéå°ææ¹æ³ä¸éè¦å­¸ç¿çåµå½æ¸ï¼ä¸¦ä¸å¯ä»¥èç¾æçåä½-è©è« RL æ¼ç®æ³ç¡ç¸«è§£æ±ºãå¼å¾æ³¨æçæ¯ï¼æåçåæ³å¯ä»¥å¨æ²æå°å®¶åä½æ¨ç±¤çåçæè¨­å®ä¸­éä½ï¼éæ¯è¡çºè¤è£½ (BC) ç¡æ³è§£æ±ºçè¨­å®ãå¯¦è­çµæé¡¯ç¤ºï¼æåçåæ³å¯ä»¥å¾å°è³ä¸åå°å®¶ç¤ºç¯ä¸­å­¸ç¿ï¼ä¸¦å¨åç¨®æ§å¶ä»»åä¸­ç²å¾æ´å¥½çæè½ã

##### **Estimating Causal Effects in Partially Directed Parametric Causal Factor Graphs**
2411.07006v1 by Malte Luttermann, Tanya Braun, Ralf MÃ¶ller, Marcel Gehrke

Lifting uses a representative of indistinguishable individuals to exploit
symmetries in probabilistic relational models, denoted as parametric factor
graphs, to speed up inference while maintaining exact answers. In this paper,
we show how lifting can be applied to causal inference in partially directed
graphs, i.e., graphs that contain both directed and undirected edges to
represent causal relationships between random variables. We present partially
directed parametric causal factor graphs (PPCFGs) as a generalisation of
previously introduced parametric causal factor graphs, which require a fully
directed graph. We further show how causal inference can be performed on a
lifted level in PPCFGs, thereby extending the applicability of lifted causal
inference to a broader range of models requiring less prior knowledge about
causal relationships.

æè¦ï¼æåä½¿ç¨ä¸å¯åååé«çä»£è¡¨ä¾å©ç¨æ©çéä¿æ¨¡åä¸­çå°ç¨±æ§ï¼è¡¨ç¤ºçºåæ¸å å­åï¼ä»¥å¨ç¶­æç²¾ç¢ºç­æ¡çåæå éæ¨è«ãå¨æ¬æä¸­ï¼æåå±ç¤ºå¦ä½å°æåæç¨æ¼é¨åæååä¸­çå ææ¨è«ï¼äº¦å³åå«æååç¡åéç·£ä¾è¡¨ç¤ºé¨æ©è®æ¸ä¹éå æéä¿çåå½¢ãæåæåºé¨åæååæ¸å æå å­å (PPCFG) ä½çºååå¼å¥çåæ¸å æå å­åçæ¦æ¬ï¼ééè¦ä¸åå®å¨æååãæåé²ä¸æ­¥å±ç¤ºå¦ä½å¨ PPCFG ä¸­å·è¡æåå±¤ç´çå ææ¨è«ï¼å¾èå°æåå ææ¨è«çé©ç¨æ§æ´å±å°æ´å»£æ³çæ¨¡åï¼èéäºæ¨¡åéè¦è¼å°çéæ¼å æéä¿çåé©ç¥è­ã

##### **Token2Wave**
2411.06989v1 by Xin Zhang, Victor S. Sheng

This paper provides an in-depth analysis of Token2Wave, a novel token
representation method derived from the Wave Network, designed to capture both
global and local semantics of input text through wave-inspired complex vectors.
In Token2Wave, each token is represented with a magnitude component, capturing
the global semantics of the entire input text, and a phase component, encoding
the relationships between individual tokens and the global semantics. Building
on prior research that demonstrated the effectiveness of wave-like operations,
such as interference and modulation, during forward propagation, this study
investigates the convergence behavior, backpropagation characteristics, and
embedding independence within the Token2Wave framework. A detailed
computational complexity analysis shows that Token2Wave can significantly
reduce video memory usage and training time compared to BERT. Gradient
comparisons for the [CLS] token, total input text, and classifier parameters
further highlight Token2Wave's unique characteristics. This research offers new
insights into wave-based token representations, demonstrating their potential
to enable efficient and computationally friendly language model architectures.

æè¦ï¼æ¬ææ·±å¥åæ Token2Waveï¼éæ¯ä¸ç¨®æºèª Wave Network çåµæ°å Token è¡¨ç¤ºæ¹æ³ï¼æ¨å¨ééåæ³¢æ¿åµçè¤éåéææè¼¸å¥ææ¬çå¨å±èªç¾©åå±é¨èªç¾©ãå¨ Token2Wave ä¸­ï¼æ¯å Token é½ç¨ä¸åå¹åº¦åéè¡¨ç¤ºï¼ç¨æ¼æææ´åè¼¸å¥ææ¬çå¨å±èªç¾©ï¼ä»¥åä¸åç¸ä½åéï¼ç¨æ¼ç·¨ç¢¼åå¥ Token èå¨å±èªç¾©ä¹éçéä¿ãå¨ååç ç©¶çåºç¤ä¸ï¼è©²ç ç©¶è­æäºæ³¢çéç®ï¼ä¾å¦å¹²æ¶åèª¿è£½ï¼å¨æ­£åå³æ­æéçæææ§ï¼æ¢è¨äº Token2Wave æ¡æ¶å§çæ¶æè¡çºãååå³æ­ç¹æ§ååµå¥ç¨ç«æ§ãè©³ç´°çè¨ç®è¤éåº¦åæè¡¨æï¼è BERT ç¸æ¯ï¼Token2Wave å¯ä»¥é¡¯èæ¸å°è¦é »å§å­ä½¿ç¨éåè¨ç·´æéã[CLS] Tokenãç¸½è¼¸å¥ææ¬ååé¡å¨åæ¸çæ¢¯åº¦æ¯è¼é²ä¸æ­¥çªåºäº Token2Wave çç¨ç¹ç¹å¾µãæ¬ç ç©¶æä¾äºå°åºæ¼æ³¢ç Token è¡¨ç¤ºçæ°è¦è§£ï¼è­æäºå®åå¨å¯¦ç¾é«æä¸è¨ç®åå¥½çèªè¨æ¨¡åæ¶æ§æ¹é¢çæ½åã

##### **ENAT: Rethinking Spatial-temporal Interactions in Token-based Image Synthesis**
2411.06959v1 by Zanlin Ni, Yulin Wang, Renping Zhou, Yizeng Han, Jiayi Guo, Zhiyuan Liu, Yuan Yao, Gao Huang

Recently, token-based generation have demonstrated their effectiveness in
image synthesis. As a representative example, non-autoregressive Transformers
(NATs) can generate decent-quality images in a few steps. NATs perform
generation in a progressive manner, where the latent tokens of a resulting
image are incrementally revealed. At each step, the unrevealed image regions
are padded with mask tokens and inferred by NAT. In this paper, we delve into
the mechanisms behind the effectiveness of NATs and uncover two important
patterns that naturally emerge from NATs: Spatially (within a step), although
mask and visible tokens are processed uniformly by NATs, the interactions
between them are highly asymmetric. In specific, mask tokens mainly gather
information for decoding, while visible tokens tend to primarily provide
information, and their deep representations can be built only upon themselves.
Temporally (across steps), the interactions between adjacent generation steps
mostly concentrate on updating the representations of a few critical tokens,
while the computation for the majority of tokens is generally repetitive.
Driven by these findings, we propose EfficientNAT (ENAT), a NAT model that
explicitly encourages these critical interactions inherent in NATs. At the
spatial level, we disentangle the computations of visible and mask tokens by
encoding visible tokens independently, while decoding mask tokens conditioned
on the fully encoded visible tokens. At the temporal level, we prioritize the
computation of the critical tokens at each step, while maximally reusing
previously computed token representations to supplement necessary information.
ENAT improves the performance of NATs notably with significantly reduced
computational cost. Experiments on ImageNet-256, ImageNet-512 and MS-COCO
validate the effectiveness of ENAT. Code is available at
https://github.com/LeapLabTHU/ENAT.

æè¦ï¼<paragraph>æè¿ï¼åºäºæ è®°ççæå·²è¯æå¶å¨å¾ååæä¸­çæææ§ãä½ä¸ºä»£è¡¨æ§ç¤ºä¾ï¼éèªåå½å¼ Transformerï¼NATï¼å¯ä»¥å¨å ä¸ªæ­¥éª¤ä¸­çæè´¨éä¸éçå¾åãNAT ä»¥æ¸è¿çæ¹å¼æ§è¡çæï¼å¶ä¸­ç»æå¾åçæ½å¨æ è®°éæ¸è¢«æ­ç¤ºãå¨æ¯ä¸æ­¥ä¸­ï¼æªæ­ç¤ºçå¾ååºåé½ç¨æ©ç æ è®°å¡«åå¹¶ç± NAT æ¨æ­ãå¨æ¬æä¸­ï¼æä»¬æ·±å¥ç ç©¶äº NAT æææ§èåçæºå¶ï¼å¹¶æ­ç¤ºäº NAT èªç¶åºç°çä¸¤ä¸ªéè¦æ¨¡å¼ï¼ç©ºé´ä¸ï¼å¨æ­¥éª¤åï¼ï¼å°½ç®¡ NAT å¯¹æ©ç åå¯è§æ è®°è¿è¡ç»ä¸å¤çï¼ä½å®ä»¬ä¹é´çäº¤äºé«åº¦ä¸å¯¹ç§°ãå·ä½æ¥è¯´ï¼æ©ç æ è®°ä¸»è¦æ¶éç¨äºè§£ç çä¿¡æ¯ï¼èå¯è§æ è®°å¾åäºä¸»è¦æä¾ä¿¡æ¯ï¼å¹¶ä¸å®ä»¬çæ·±åº¦è¡¨ç¤ºåªè½å»ºç«å¨å®ä»¬èªå·±ä¹ä¸ãæ¶é´ä¸ï¼è·¨æ­¥éª¤ï¼ï¼ç¸é»çææ­¥éª¤ä¹é´çäº¤äºä¸»è¦éä¸­å¨æ´æ°å ä¸ªå³é®æ è®°çè¡¨ç¤ºä¸ï¼èå¤§å¤æ°æ è®°çè®¡ç®éå¸¸æ¯éå¤çãåè¿äºåç°çå¯åï¼æä»¬æåºäº EfficientNATï¼ENATï¼ï¼è¿æ¯ä¸ä¸ª NAT æ¨¡åï¼å®æç¡®å°é¼å±äº NAT ä¸­åºæçè¿äºå³é®äº¤äºãå¨ç©ºé´å±é¢ä¸ï¼æä»¬éè¿ç¬ç«ç¼ç å¯è§æ è®°æ¥è§£å¼å¯è§æ è®°åæ©ç æ è®°çè®¡ç®ï¼åæ¶å¯¹å®å¨ç¼ç çå¯è§æ è®°è¿è¡æ¡ä»¶è§£ç æ©ç æ è®°ãå¨æ¶é´å±é¢ä¸ï¼æä»¬ä¼åèèå¨æ¯ä¸æ­¥è®¡ç®å³é®æ è®°ï¼åæ¶æå¤§ç¨åº¦å°éç¨ååè®¡ç®çæ è®°è¡¨ç¤ºä»¥è¡¥åå¿è¦ä¿¡æ¯ãENAT æ¾çæé«äº NAT çæ§è½ï¼åæ¶æ¾çéä½äºè®¡ç®ææ¬ãå¨ ImageNet-256ãImageNet-512 å MS-COCO ä¸çå®éªéªè¯äº ENAT çæææ§ãä»£ç å¯å¨ https://github.com/LeapLabTHU/ENAT è·å¾ã</paragraph>

##### **Sniff AI: Is My 'Spicy' Your 'Spicy'? Exploring LLM's Perceptual Alignment with Human Smell Experiences**
2411.06950v1 by Shu Zhong, Zetao Zhou, Christopher Dawes, Giada Brianz, Marianna Obrist

Aligning AI with human intent is important, yet perceptual alignment-how AI
interprets what we see, hear, or smell-remains underexplored. This work focuses
on olfaction, human smell experiences. We conducted a user study with 40
participants to investigate how well AI can interpret human descriptions of
scents. Participants performed "sniff and describe" interactive tasks, with our
designed AI system attempting to guess what scent the participants were
experiencing based on their descriptions. These tasks evaluated the Large
Language Model's (LLMs) contextual understanding and representation of scent
relationships within its internal states - high-dimensional embedding space.
Both quantitative and qualitative methods were used to evaluate the AI system's
performance. Results indicated limited perceptual alignment, with biases
towards certain scents, like lemon and peppermint, and continued failing to
identify others, like rosemary. We discuss these findings in light of human-AI
alignment advancements, highlighting the limitations and opportunities for
enhancing HCI systems with multisensory experience integration.

æè¦ï¼å°é½ AI èäººé¡æåå¾éè¦ï¼ä½æç¥å°é½ââAI å¦ä½è©®éæåæè¦ãæè½ææèââä»æªå¾å°ååæ¢è¨ãéé å·¥ä½èéæ¼åè¦ºï¼ä¹å°±æ¯äººé¡çåè¦ºé«é©ãæåéå° 40 ä½åèèé²è¡ä½¿ç¨èç ç©¶ï¼ä»¥æ¢è¨ AI è½å¤å¥½å°è©®éäººé¡å°æ°£å³çæè¿°ãåèèå·è¡äºãèé¦ä¸¦æè¿°ãäºåä»»åï¼æåç AI ç³»çµ±è¨­è¨åè©¦æ ¹æåèèçæè¿°çæ¸¬ä»åèå°ä»éº¼æ°£å³ãéäºä»»åè©ä¼°äºå¤§åèªè¨æ¨¡å (LLM) å¨å¶å§é¨çæââé«ç¶­åµå¥ç©ºéââä¸­å°æ°£å³éä¿çèçµ¡çè§£åè¡¨ç¤ºãä½¿ç¨éååè³ªåæ¹æ³ä¾è©ä¼° AI ç³»çµ±çæè½ãçµæé¡¯ç¤ºæç¥å°é½æéï¼å°æäºæ°£å³ï¼ä¾å¦æª¸æª¬åèè·ï¼æåè¦ï¼ä¸¦ä¸æçºç¡æ³è¾¨è­å¶ä»æ°£å³ï¼ä¾å¦è¿·è¿­é¦ï¼ãæåæ ¹æäººé¡è AI å°é½çé²å±è¨è«éäºç¼ç¾ï¼å¼·èª¿äºééå¤æå®é«é©æ´åä¾æå HCI ç³»çµ±çéå¶åæ©æã

##### **Cancer-Answer: Empowering Cancer Care with Advanced Large Language Models**
2411.06946v1 by Aniket Deroy, Subhankar Maity

Gastrointestinal (GI) tract cancers account for a substantial portion of the
global cancer burden, where early diagnosis is critical for improved management
and patient outcomes. The complex aetiologies and overlapping symptoms across
GI cancers often delay diagnosis, leading to suboptimal treatment strategies.
Cancer-related queries are crucial for timely diagnosis, treatment, and patient
education, as access to accurate, comprehensive information can significantly
influence outcomes. However, the complexity of cancer as a disease, combined
with the vast amount of available data, makes it difficult for clinicians and
patients to quickly find precise answers. To address these challenges, we
leverage large language models (LLMs) such as GPT-3.5 Turbo to generate
accurate, contextually relevant responses to cancer-related queries.
Pre-trained with medical data, these models provide timely, actionable insights
that support informed decision-making in cancer diagnosis and care, ultimately
improving patient outcomes. We calculate two metrics: A1 (which represents the
fraction of entities present in the model-generated answer compared to the gold
standard) and A2 (which represents the linguistic correctness and
meaningfulness of the model-generated answer with respect to the gold
standard), achieving maximum values of 0.546 and 0.881, respectively.

æè¦ï¼èè¸é (GI) ççä½å¨çççè² æçå¾å¤§ä¸é¨åï¼æ©æè¨ºæ·å°æ¼æ¹åç®¡çåæ£èé å¾è³ééè¦ãèè¸éçççè¤éçå åéçççç¶å¸¸æå»¶èª¤è¨ºæ·ï¼å°è´æ¬¡åªçæ²»çç­ç¥ãèççç¸éçæ¥è©¢å°æ¼åæè¨ºæ·ãæ²»çåæ£èæè²è³ééè¦ï¼å çºç²åæºç¢ºãå¨é¢çä¿¡æ¯å¯ä»¥é¡¯èå½±é¿çµæãç¶èï¼ççä½çºä¸ç¨®ç¾ççè¤éæ§ï¼å ä¸å¤§éå¯ç¨æ¸æï¼ä½¿å¾è¨åºé«çåæ£èé£ä»¥å¿«éæ¾å°æºç¢ºçç­æ¡ãçºäºæå°éäºææ°ï¼æåå©ç¨å¤§åèªè¨æ¨¡å (LLM)ï¼ä¾å¦ GPT-3.5 Turboï¼ä¾çæèççç¸éæ¥è©¢çæºç¢ºãä¸ä¸æç¸éçåæãéäºæ¨¡åç¶éé«å­¸æ¸æé è¨ç·´ï¼å¯æä¾åæãå¯æä½çè¦è§£ï¼æ¯æççè¨ºæ·åè­·çä¸­çææºæ±ºç­å¶å®ï¼æçµæ¹åæ£èé å¾ãæåè¨ç®äºå©åææ¨ï¼A1ï¼è¡¨ç¤ºæ¨¡åçæçç­æ¡ä¸­å­å¨çå¯¦é«é¨åï¼èé»éæ¨æºç¸æ¯ï¼å A2ï¼è¡¨ç¤ºæ¨¡åçæçç­æ¡çèªè¨æ­£ç¢ºæ§åæç¾©ï¼ç¸å°æ¼é»éæ¨æºï¼ï¼åå¥éå°æå¤§å¼ 0.546 å 0.881ã

##### **Electroencephalogram-based Multi-class Decoding of Attended Speakers' Direction with Audio Spatial Spectrum**
2411.06928v1 by Yuanming Zhang, Jing Lu, Zhibin Lin, Fei Chen, Haoliang Du, Xia Gao

Decoding the directional focus of an attended speaker from listeners'
electroencephalogram (EEG) signals is essential for developing brain-computer
interfaces to improve the quality of life for individuals with hearing
impairment. Previous works have concentrated on binary directional focus
decoding, i.e., determining whether the attended speaker is on the left or
right side of the listener. However, a more precise decoding of the exact
direction of the attended speaker is necessary for effective speech processing.
Additionally, audio spatial information has not been effectively leveraged,
resulting in suboptimal decoding results. In this paper, we observe that, on
our recently presented dataset with 15-class directional focus, models relying
exclusively on EEG inputs exhibits significantly lower accuracy when decoding
the directional focus in both leave-one-subject-out and leave-one-trial-out
scenarios. By integrating audio spatial spectra with EEG features, the decoding
accuracy can be effectively improved. We employ the CNN, LSM-CNN, and
EEG-Deformer models to decode the directional focus from listeners' EEG signals
with the auxiliary audio spatial spectra. The proposed Sp-Aux-Deformer model
achieves notable 15-class decoding accuracies of 57.48% and 61.83% in
leave-one-subject-out and leave-one-trial-out scenarios, respectively.

æè¦ï¼è§£ç¢¼è½ç¾è¦é»å (EEG) è¨èä¸­åéæ³¨èªªè©±èçæ¹åç¦é»å°æ¼éç¼è¦é»è¦ä»é¢è³ééè¦ï¼ä»¥æé«è½ååæèççæ´»åè³ªãååçç ç©¶éä¸­æ¼äºé²ä½æ¹åç¦é»è§£ç¢¼ï¼å³å¤æ·åéæ³¨çèªªè©±èå¨è½ç¾çå·¦å´éæ¯å³å´ãç¶èï¼ç²¾ç¢ºè§£ç¢¼åéæ³¨èªªè©±èçç¢ºåæ¹åå°æ¼ææçèªé³èçæ¯å¿è¦çãæ­¤å¤ï¼é³è¨ç©ºéè³è¨å°æªè¢«ææå©ç¨ï¼å°è´æ¬¡ä½³è§£ç¢¼çµæãå¨æ¬æä¸­ï¼æåè§å¯å°ï¼å¨æåæè¿æåºç 15 é¡æ¹åç¦é»è³æéä¸­ï¼åä¾è³´ EEG è¼¸å¥çæ¨¡åå¨é¢éä¸ååè©¦èåé¢éä¸åè©¦é©çå ´æ¯ä¸­è§£ç¢¼æ¹åç¦é»æï¼æºç¢ºåº¦é¡¯èéä½ãééå°é³è¨ç©ºéé »è­è EEG ç¹å¾µæ´åï¼å¯ä»¥æææé«è§£ç¢¼æºç¢ºåº¦ãæåæ¡ç¨ CNNãLSM-CNN å EEG-Deformer æ¨¡åå¾è½ç¾ç EEG è¨èä¸­è§£ç¢¼æ¹åç¦é»ï¼ä¸¦è¼ä»¥é³è¨ç©ºéé »è­ãæåºç Sp-Aux-Deformer æ¨¡ååå¥å¨é¢éä¸ååè©¦èåé¢éä¸åè©¦é©çå ´æ¯ä¸­éå°é¡¯èç 15 é¡è§£ç¢¼æºç¢ºåº¦ 57.48% å 61.83%ã

##### **Slowing Down Forgetting in Continual Learning**
2411.06916v1 by Pascal Janetzky, Tobias Schlagenhauf, Stefan Feuerriegel

A common challenge in continual learning (CL) is catastrophic forgetting,
where the performance on old tasks drops after new, additional tasks are
learned. In this paper, we propose a novel framework called ReCL to slow down
forgetting in CL. Our framework exploits an implicit bias of gradient-based
neural networks due to which these converge to margin maximization points. Such
convergence points allow us to reconstruct old data from previous tasks, which
we then combine with the current training data. Our framework is flexible and
can be applied on top of existing, state-of-the-art CL methods to slow down
forgetting. We further demonstrate the performance gain from our framework
across a large series of experiments, including different CL scenarios (class
incremental, domain incremental, task incremental learning) different datasets
(MNIST, CIFAR10), and different network architectures. Across all experiments,
we find large performance gains through ReCL. To the best of our knowledge, our
framework is the first to address catastrophic forgetting by leveraging models
in CL as their own memory buffers.

æè¦ï¼æçºå­¸ç¿ (CL) ä¸­å¸¸è¦çææ°æ¯ç½é£æ§éºå¿ï¼ä¹å°±æ¯å¨å­¸ç¿æ°çé¡å¤ä»»åå¾ï¼èä»»åçè¡¨ç¾ä¸éãå¨æ¬æä¸­ï¼æåæåºäºä¸ååçº ReCL çæ°æ¡æ¶ï¼ç¨ä¾æ¸ç·© CL ä¸­çéºå¿ãæåçæ¡æ¶å©ç¨äºåºæ¼æ¢¯åº¦çé¡ç¥ç¶ç¶²è·¯çå§é±åå·®ï¼å çºéäºç¶²è·¯ææ¶æå°éçæå¤§åé»ãéæ¨£çæ¶æé»è®æåå¯ä»¥å¾ååçä»»åä¸­éå»ºèè³æï¼ç¶å¾æåå°å¶èç®åçè¨ç·´è³æçµåãæåçæ¡æ¶å¾éæ´»ï¼å¯ä»¥æç¨æ¼ç¾æçãæåé²ç CL æ¹æ³ä¹ä¸ï¼ä»¥æ¸ç·©éºå¿ãæåé²ä¸æ­¥å±ç¤ºäºæåçæ¡æ¶å¨å¤§éå¯¦é©ä¸­ç²å¾çæè½æåï¼åæ¬ä¸åç CL å ´æ¯ï¼é¡å¥å¢éãé åå¢éãä»»åå¢éå­¸ç¿ï¼ä¸åçè³æéï¼MNISTãCIFAR10ï¼åä¸åçç¶²è·¯æ¶æ§ãå¨ææå¯¦é©ä¸­ï¼æåé½ç¼ç¾ ReCL å¸¶ä¾äºé¡¯èçæè½æåãææåæç¥ï¼æåçæ¡æ¶æ¯ç¬¬ä¸åééå©ç¨ CL ä¸­çæ¨¡åä½çºå¶èªå·±çè¨æ¶é«ç·©è¡åä¾è§£æ±ºç½é£æ§éºå¿çæ¡æ¶ã

##### **Gaussian Process Emulators for Few-Shot Segmentation in Cardiac MRI**
2411.06911v1 by Bruno Viti, Franz Thaler, Kathrin Lisa Kapper, Martin Urschler, Martin Holler, Elias Karabelas

Segmentation of cardiac magnetic resonance images (MRI) is crucial for the
analysis and assessment of cardiac function, helping to diagnose and treat
various cardiovascular diseases. Most recent techniques rely on deep learning
and usually require an extensive amount of labeled data. To overcome this
problem, few-shot learning has the capability of reducing data dependency on
labeled data. In this work, we introduce a new method that merges few-shot
learning with a U-Net architecture and Gaussian Process Emulators (GPEs),
enhancing data integration from a support set for improved performance. GPEs
are trained to learn the relation between the support images and the
corresponding masks in latent space, facilitating the segmentation of unseen
query images given only a small labeled support set at inference. We test our
model with the M&Ms-2 public dataset to assess its ability to segment the heart
in cardiac magnetic resonance imaging from different orientations, and compare
it with state-of-the-art unsupervised and few-shot methods. Our architecture
shows higher DICE coefficients compared to these methods, especially in the
more challenging setups where the size of the support set is considerably
small.

æè¦ï¼å¿èç£æ¯é å½± (MRI) å½±åçåå²å°æ¼å¿èåè½çåæåè©ä¼°è³ééè¦ï¼æå©æ¼è¨ºæ·åæ²»çåç¨®å¿è¡ç®¡ç¾çãææ°æè¡å¤§å¤ä¾è³´æ·±åº¦å­¸ç¿ï¼ä¸éå¸¸éè¦å¤§éçæ¨ç±¤è³æãçºäºåæéååé¡ï¼å°æ¨£æ¬å­¸ç¿æè½åéä½å°æ¨ç±¤è³æçè³æä¾è³´æ§ãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹ä¸ç¨®æ°çæ¹æ³ï¼å°å°æ¨£æ¬å­¸ç¿è U-Net æ¶æ§åé«æ¯éç¨æ¨¡æ¬å¨ (GPE) çµåï¼å¢å¼·äºä¾èªæ¯æ´éçè³ææ´åï¼ä»¥æåæè½ãGPE ç¶éè¨ç·´ï¼å¯ä»¥å­¸ç¿æ¯æ´å½±åèæ½å¨ç©ºéä¸­å°æé®ç½©ä¹éçéä¿ï¼å¨æ¨è«æåçµ¦äºä¸åæ¨ç±¤è¼å°çæ¯æ´éï¼ä¹è½ä¿é²æªè¦éæ¥è©¢å½±åçåå²ãæåä½¿ç¨ M&Ms-2 å¬éè³æéä¾æ¸¬è©¦æåçæ¨¡åï¼ä»¥è©ä¼°å¶å¾ä¸åæ¹åçå¿èç£æ¯é å½±ä¸­åå²å¿èçè½åï¼ä¸¦å°å¶èæåé²çç¡ç£ç£åå°æ¨£æ¬æ¹æ³é²è¡æ¯è¼ãæåçæ¶æ§èéäºæ¹æ³ç¸æ¯ï¼é¡¯ç¤ºåºæ´é«ç DICE ä¿æ¸ï¼ç¹å¥æ¯å¨æ¯æ´éå¤§å°ç¸ç¶å°çæ´å·ææ°æ§çè¨­å®ä¸­ã

##### **EVQAScore: Efficient Video Question Answering Data Evaluation**
2411.06908v1 by Hao Liang, Zirong Chen, Wentao Zhang

Video question-answering (QA) is a core task in video understanding.
Evaluating the quality of video QA and video caption data quality for training
video large language models (VideoLLMs) is an essential challenge. Although
various methods have been proposed for assessing video caption quality, there
remains a lack of dedicated evaluation methods for Video QA. To address this
gap, we introduce EVQAScore, a reference-free method that leverages keyword
extraction to assess both video caption and video QA data quality.
Additionally, we incorporate frame sampling and rescaling techniques to enhance
the efficiency and robustness of our evaluation, this enables our score to
evaluate the quality of extremely long videos. Our approach achieves
state-of-the-art (SOTA) performance (32.8 for Kendall correlation and 42.3 for
Spearman correlation, 4.7 and 5.9 higher than the previous method PAC-S++) on
the VATEX-EVAL benchmark for video caption evaluation. Furthermore, by using
EVQAScore for data selection, we achieved SOTA results with only 12.5\% of the
original data volume, outperforming the previous SOTA method PAC-S and 100\% of
data.

æè¦ï¼å½±çåç­ (QA) æ¯å½±ççè§£ä¸­çä¸é æ ¸å¿ä»»åã
è©ä¼°å½±ç QA åå½±çæ¨é¡è³æåè³ªä»¥è¨ç·´å½±çå¤§åèªè¨æ¨¡å (VideoLLM) æ¯é éè¦çææ°ãåç®¡
å·²ç¶æåºåç¨®æ¹æ³ä¾è©ä¼°å½±çæ¨é¡åè³ªï¼ä½ä»ç¶ç¼ºä¹éå°å½±ç QA çå°ç¨è©ä¼°æ¹æ³ãçºäºè§£æ±ºéå
åé¡ï¼æåå¼å¥äº EVQAScoreï¼ä¸ç¨®ç¡åèæ¹æ³ï¼å®å©ç¨ééµå­èåä¾è©ä¼°å½±çæ¨é¡åå½±ç QA è³æåè³ªã
æ­¤å¤ï¼æåçµåäºå½±æ ¼åæ¨£åç¸®æ¾æè¡ä¾æåæåè©ä¼°çæçåç©©å¥æ§ï¼éä½¿å¾æåçè©åè½å¤ 
è©ä¼°æ¥µé·å½±ççåè³ªãæåçåæ³å¨å½±çæ¨é¡è©ä¼°ç VATEX-EVAL åºæºä¸éå°äºæåé² (SOTA) çæè½ï¼Kendall ç¸éæ§çº 32.8ï¼Spearman ç¸éæ§çº 42.3ï¼æ¯åä¸åæ¹æ³ PAC-S++ é«åº 4.7 å 5.9ï¼ãæ­¤å¤ï¼ééä½¿ç¨ EVQAScore é²è¡è³æé¸åï¼æååä½¿ç¨åè³æé 12.5% å°±éå°äº SOTA çµæï¼åªæ¼åä¸å SOTA æ¹æ³ PAC-S å 100% çè³æã

##### **LongSafetyBench: Long-Context LLMs Struggle with Safety Issues**
2411.06899v1 by Mianqiu Huang, Xiaoran Liu, Shaojun Zhou, Mozhi Zhang, Chenkun Tan, Pengyu Wang, Qipeng Guo, Zhe Xu, Linyang Li, Zhikai Lei, Linlin Li, Qun Liu, Yaqian Zhou, Xipeng Qiu, Xuanjing Huang

With the development of large language models (LLMs), the sequence length of
these models continues to increase, drawing significant attention to
long-context language models. However, the evaluation of these models has been
primarily limited to their capabilities, with a lack of research focusing on
their safety. Existing work, such as ManyShotJailbreak, has to some extent
demonstrated that long-context language models can exhibit safety concerns.
However, the methods used are limited and lack comprehensiveness. In response,
we introduce \textbf{LongSafetyBench}, the first benchmark designed to
objectively and comprehensively evaluate the safety of long-context models.
LongSafetyBench consists of 10 task categories, with an average length of
41,889 words. After testing eight long-context language models on
LongSafetyBench, we found that existing models generally exhibit insufficient
safety capabilities. The proportion of safe responses from most mainstream
long-context LLMs is below 50\%. Moreover, models' safety performance in
long-context scenarios does not always align with that in short-context
scenarios. Further investigation revealed that long-context models tend to
overlook harmful content within lengthy texts. We also proposed a simple yet
effective solution, allowing open-source models to achieve performance
comparable to that of top-tier closed-source models. We believe that
LongSafetyBench can serve as a valuable benchmark for evaluating the safety
capabilities of long-context language models. We hope that our work will
encourage the broader community to pay attention to the safety of long-context
models and contribute to the development of solutions to improve the safety of
long-context LLMs.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡åï¼LLMï¼çç¼å±ï¼éäºæ¨¡åçåºåé·åº¦æçºå¢å ï¼å¸å¼äºäººåå°é·èªå¢èªè¨æ¨¡åçæ¥µå¤§éæ³¨ãç¶èï¼å°éäºæ¨¡åçè©ä¼°ä¸»è¦ä¾·éæ¼å®åçè½åï¼èç¼ºä¹éå°å¶å®å¨æ§é²è¡çç ç©¶ãç¾æçç ç©¶ï¼ä¾å¦ ManyShotJailbreakï¼å¨æç¨®ç¨åº¦ä¸è­æäºé·èªå¢èªè¨æ¨¡åå¯è½æåºç¾å®å¨åé¡ãç¶èï¼æä½¿ç¨çæ¹æ³æéä¸ç¼ºä¹å¨é¢æ§ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº \textbf{LongSafetyBench}ï¼éæ¯ç¬¬ä¸åæ¨å¨å®¢è§ä¸å¨é¢è©ä¼°é·èªå¢æ¨¡åå®å¨æ§çåºæºãLongSafetyBench åå« 10 åä»»åé¡å¥ï¼å¹³åé·åº¦çº 41,889 åå­è©ãå¨ LongSafetyBench ä¸æ¸¬è©¦äºå«åé·èªå¢èªè¨æ¨¡åå¾ï¼æåç¼ç¾ç¾ææ¨¡åæ®éè¡¨ç¾åºå®å¨æ§ä¸è¶³ãå¤§å¤æ¸ä¸»æµé·èªå¢ LLM çå®å¨åææ¯ä¾ä½æ¼ 50%ãæ­¤å¤ï¼æ¨¡åå¨é·èªå¢å ´æ¯ä¸­çå®å¨æ§è¡¨ç¾ä¸¦ä¸ç¸½æ¯èå¨ç­èªå¢å ´æ¯ä¸­çè¡¨ç¾ä¸è´ãé²ä¸æ­¥çèª¿æ¥é¡¯ç¤ºï¼é·èªå¢æ¨¡åå¾åæ¼å¿½ç¥é·ç¯æå­ä¸­çæå®³å§å®¹ãæåéæåºäºä¸åç°¡å®ä½ææçæ¹æ³ï¼è®éæºæ¨¡åè½å¤ å¯¦ç¾èé ç´éæºæ¨¡åç¸ç¶çè¡¨ç¾ãæåç¸ä¿¡ LongSafetyBench å¯ä»¥ä½çºè©ä¼°é·èªå¢èªè¨æ¨¡åå®å¨æ§è½åçå¯¶è²´åºæºãæåå¸ææåçç ç©¶è½é¼åµæ´å»£æ³çç¤¾ç¾¤éæ³¨é·èªå¢æ¨¡åçå®å¨æ§ï¼ä¸¦çºéç¼è§£æ±ºæ¹æ¡ä»¥æ¹åé·èªå¢ LLM çå®å¨æ§ååºè²¢ç»ã

##### **GraphRPM: Risk Pattern Mining on Industrial Large Attributed Graphs**
2411.06878v1 by Sheng Tian, Xintan Zeng, Yifei Hu, Baokun Wang, Yongchao Liu, Yue Jin, Changhua Meng, Chuntao Hong, Tianyi Zhang, Weiqiang Wang

Graph-based patterns are extensively employed and favored by practitioners
within industrial companies due to their capacity to represent the behavioral
attributes and topological relationships among users, thereby offering enhanced
interpretability in comparison to black-box models commonly utilized for
classification and recognition tasks. For instance, within the scenario of
transaction risk management, a graph pattern that is characteristic of a
particular risk category can be readily employed to discern transactions
fraught with risk, delineate networks of criminal activity, or investigate the
methodologies employed by fraudsters. Nonetheless, graph data in industrial
settings is often characterized by its massive scale, encompassing data sets
with millions or even billions of nodes, making the manual extraction of graph
patterns not only labor-intensive but also necessitating specialized knowledge
in particular domains of risk. Moreover, existing methodologies for mining
graph patterns encounter significant obstacles when tasked with analyzing
large-scale attributed graphs. In this work, we introduce GraphRPM, an
industry-purpose parallel and distributed risk pattern mining framework on
large attributed graphs. The framework incorporates a novel edge-involved graph
isomorphism network alongside optimized operations for parallel graph
computation, which collectively contribute to a considerable reduction in
computational complexity and resource expenditure. Moreover, the intelligent
filtration of efficacious risky graph patterns is facilitated by the proposed
evaluation metrics. Comprehensive experimental evaluations conducted on
real-world datasets of varying sizes substantiate the capability of GraphRPM to
adeptly address the challenges inherent in mining patterns from large-scale
industrial attributed graphs, thereby underscoring its substantial value for
industrial deployment.

æè¦ï¼<paragraph>åå½¢åæ¨¡å¼å è½è¡¨ç¤ºä½¿ç¨èè¡çºå±¬æ§åææ²éä¿ï¼å¨ç¢æ¥­å¬å¸ä¸­è¢«å»£æ³æ¡ç¨ä¸åéçï¼å æ­¤èå¸¸ä½¿ç¨æ¼åé¡åè¾¨è­ä»»åçé»ç®±æ¨¡åç¸æ¯ï¼å·åå¢å¼·çå¯è§£éæ§ãä¾å¦ï¼å¨äº¤æé¢¨éªç®¡ççæå¢ä¸­ï¼å·æç¹å®é¢¨éªé¡å¥ç¹å¾µçåå½¢æ¨¡å¼å¯è¼æç¨æ¼è¾¨è­é¢¨éªäº¤æãæç¹ªç¯ç½ªæ´»åç¶²è·¯ï¼æèª¿æ¥è©é¨èææ¡ç¨çæ¹æ³ãç¶èï¼ç¢æ¥­ç°å¢ä¸­çåå½¢è³æéå¸¸ä»¥å¶é¾å¤§è¦æ¨¡çºç¹å¾µï¼åå«æ¸ç¾è¬çè³æ¸åååç¯é»çè³æéï¼éä½¿å¾åå½¢æ¨¡å¼çæåèåä¸åèè²»å¤§éäººåï¼ééè¦ç¹å®é¢¨éªé åçå°æ¥­ç¥è­ãæ­¤å¤ï¼ç¾æçåå½¢æ¨¡å¼æææ¹æ³å¨åæå¤§åå±¬æ§åå½¢ææé­ééå¤§éç¤ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äº GraphRPMï¼ä¸åéå°å¤§åå±¬æ§åå½¢é²è¡ç¢æ¥­ç¨éå¹³è¡ä¸åæ£çé¢¨éªæ¨¡å¼æææ¶æ§ãæ­¤æ¶æ§çµåäºæ°ç©çéç·£åèåå½¢åæ§ç¶²è·¯ä»¥åå¹³è¡åå½¢éç®çæä½³åéç®ï¼å±åå¤§å¹éä½äºéç®è¤éåº¦åè³æºæ¯åºãæ­¤å¤ï¼ææåºçè©ä¼°ææ¨æå©æ¼ææé¢¨éªåå½¢æ¨¡å¼çæºæ§åéæ¿¾ãå¨åç¨®è¦æ¨¡ççå¯¦ä¸çè³æéä¸é²è¡çå¨é¢å¯¦é©è©ä¼°è­å¯¦äº GraphRPM è½å¤ é©ç¶å°è§£æ±ºå¾å¤§åç¢æ¥­å±¬æ§åå½¢ä¸­æææ¨¡å¼æåºæçææ°ï¼å æ­¤å¼·èª¿äºå¶å¨ç¢æ¥­é¨ç½²ä¸­çéè¦å¹å¼ã</paragraph>

##### **Multi-Modal interpretable automatic video captioning**
2411.06872v1 by Antoine Hanna-Asaad, Decky Aspandi, Titus Zaharia

Video captioning aims to describe video contents using natural language
format that involves understanding and interpreting scenes, actions and events
that occurs simultaneously on the view. Current approaches have mainly
concentrated on visual cues, often neglecting the rich information available
from other important modality of audio information, including their
inter-dependencies. In this work, we introduce a novel video captioning method
trained with multi-modal contrastive loss that emphasizes both multi-modal
integration and interpretability. Our approach is designed to capture the
dependency between these modalities, resulting in more accurate, thus pertinent
captions. Furthermore, we highlight the importance of interpretability,
employing multiple attention mechanisms that provide explanation into the
model's decision-making process. Our experimental results demonstrate that our
proposed method performs favorably against the state-of the-art models on
commonly used benchmark datasets of MSR-VTT and VATEX.

æè¦ï¼å½±çå­å¹æ¨å¨ä½¿ç¨èªç¶èªè¨æ ¼å¼æè¿°å½±çå§å®¹ï¼å¶ä¸­åæ¬çè§£åè©®éåæå¨è¦åä¸ç¼ççå ´æ¯ãåä½åäºä»¶ãç®åçåæ³ä¸»è¦éä¸­å¨è¦è¦ºç·ç´¢ä¸ï¼å¸¸å¸¸å¿½ç¥å¾å¶ä»éè¦çé³è¨è³è¨æ¨¡å¼ä¸­ç²å¾çè±å¯è³è¨ï¼åæ¬å®åçç¸äºä¾è³´æ§ãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹äºä¸ç¨®æ°ç©çå½±çå­å¹æ¹æ³ï¼ä½¿ç¨å¤æ¨¡å¼å°æ¯æå¤±é²è¡è¨ç·´ï¼å¼·èª¿å¤æ¨¡å¼æ´ååå¯è§£éæ§ãæåçåæ³æ¨å¨ææéäºæ¨¡å¼ä¹éçä¾è³´æ§ï¼å¾èç¢çæ´æºç¢ºãå æ­¤æ´ç¸éçå­å¹ãæ­¤å¤ï¼æåå¼·èª¿å¯è§£éæ§çéè¦æ§ï¼æ¡ç¨å¤ç¨®æ³¨æåæ©å¶ï¼å°æ¨¡åçæ±ºç­éç¨æä¾èªªæãæåçå¯¦é©çµæè­æï¼æåæåºçæ¹æ³å¨ MSR-VTT å VATEX å¸¸ç¨çåºæºè³æéä¸ï¼è¡¨ç¾åªæ¼ç¾ææåé²çæ¨¡åã

##### **Subgraph Retrieval Enhanced by Graph-Text Alignment for Commonsense Question Answering**
2411.06866v1 by Boci Peng, Yongchao Liu, Xiaohe Bo, Sheng Tian, Baokun Wang, Chuntao Hong, Yan Zhang

Commonsense question answering is a crucial task that requires machines to
employ reasoning according to commonsense. Previous studies predominantly
employ an extracting-and-modeling paradigm to harness the information in KG,
which first extracts relevant subgraphs based on pre-defined rules and then
proceeds to design various strategies aiming to improve the representations and
fusion of the extracted structural knowledge. Despite their effectiveness,
there are still two challenges. On one hand, subgraphs extracted by rule-based
methods may have the potential to overlook critical nodes and result in
uncontrollable subgraph size. On the other hand, the misalignment between graph
and text modalities undermines the effectiveness of knowledge fusion,
ultimately impacting the task performance. To deal with the problems above, we
propose a novel framework: \textbf{S}ubgraph R\textbf{E}trieval Enhanced by
Gra\textbf{P}h-\textbf{T}ext \textbf{A}lignment, named \textbf{SEPTA}. Firstly,
we transform the knowledge graph into a database of subgraph vectors and
propose a BFS-style subgraph sampling strategy to avoid information loss,
leveraging the analogy between BFS and the message-passing mechanism. In
addition, we propose a bidirectional contrastive learning approach for
graph-text alignment, which effectively enhances both subgraph retrieval and
knowledge fusion. Finally, all the retrieved information is combined for
reasoning in the prediction module. Extensive experiments on five datasets
demonstrate the effectiveness and robustness of our framework.

æè¦ï¼å¸¸è­åç­æ¯ä¸é è³ééè¦çä»»åï¼è¦æ±æ©å¨æ ¹æå¸¸è­é²è¡æ¨çãååçç ç©¶ä¸»è¦æ¡ç¨æååå»ºæ¨¡ç¯ä¾ä¾å©ç¨ç¥è­åè­ä¸­çè³è¨ï¼è©²ç¯ä¾é¦åæ ¹æé å®ç¾©è¦åæåç¸éå­åï¼ç¶å¾ç¹¼çºè¨­è¨åç¨®ç­ç¥ï¼æ¨å¨æ¹åæåççµæ§ç¥è­çè¡¨ç¤ºåèåãåç®¡å®åå¾ææï¼ä½ä»å­å¨å©åææ°ãä¸æ¹é¢ï¼åºæ¼è¦åçæ¹æ³æåçå­åå¯è½æå¿½ç¥ééµç¯é»ä¸¦å°è´ç¡æ³æ§å¶çå­åå¤§å°ãå¦ä¸æ¹é¢ï¼åå½¢åææ¬æ¨¡å¼ä¹éçé¯ä½ææå®³ç¥è­èåçæææ§ï¼æçµå½±é¿ä»»åç¸¾æãçºäºæå°ä¸è¿°åé¡ï¼æåæåºäºä¸åæ°çæ¡æ¶ï¼ç±åå½¢-ææ¬å°é½å¢å¼·çå­åæª¢ç´¢ï¼ç¨±çº SEPTAãé¦åï¼æåå°ç¥è­åå½¢è½æçºå­ååéçè³æåº«ï¼ä¸¦æåº BFS é¢¨æ ¼çå­åæ¡æ¨£ç­ç¥ä»¥é¿åè³è¨éºå¤±ï¼å©ç¨ BFS åè¨æ¯å³éæ©å¶ä¹éçé¡æ¯ãæ­¤å¤ï¼æåæåºäºä¸åéåå°æ¯å­¸ç¿æ¹æ³ï¼ç¨æ¼åå½¢-ææ¬å°é½ï¼éææå°å¢å¼·äºå­åæª¢ç´¢åç¥è­èåãæå¾ï¼æææª¢ç´¢å°çè³è¨é½çµåèµ·ä¾ï¼å¨é æ¸¬æ¨¡çµä¸­é²è¡æ¨çãå¨äºåè³æéä¸çå¤§éå¯¦é©è­æäºæåæ¡æ¶çæææ§åç©©å¥æ§ã

##### **Computable Model-Independent Bounds for Adversarial Quantum Machine Learning**
2411.06863v1 by Bacui Li, Tansu Alpcan, Chandra Thapa, Udaya Parampalli

By leveraging the principles of quantum mechanics, QML opens doors to novel
approaches in machine learning and offers potential speedup. However, machine
learning models are well-documented to be vulnerable to malicious
manipulations, and this susceptibility extends to the models of QML. This
situation necessitates a thorough understanding of QML's resilience against
adversarial attacks, particularly in an era where quantum computing
capabilities are expanding. In this regard, this paper examines
model-independent bounds on adversarial performance for QML. To the best of our
knowledge, we introduce the first computation of an approximate lower bound for
adversarial error when evaluating model resilience against sophisticated
quantum-based adversarial attacks. Experimental results are compared to the
computed bound, demonstrating the potential of QML models to achieve high
robustness. In the best case, the experimental error is only 10% above the
estimated bound, offering evidence of the inherent robustness of quantum
models. This work not only advances our theoretical understanding of quantum
model resilience but also provides a precise reference bound for the future
development of robust QML algorithms.

æè¦ï¼<paragraph>éééç¨éå­åå­¸åçï¼QML éåäºæ©å¨å­¸ç¿çæ°æ¹æ³ï¼ä¸¦æä¾æ½å¨çå éãç¶èï¼æ©å¨å­¸ç¿æ¨¡åå·²è¢«ååè­æå®¹æåå°æ¡æçæç¸±ï¼èéç¨®æåæ§ä¹å»¶ä¼¸å° QML çæ¨¡åãéç¨®ææ³éè¦å¾¹åºäºè§£ QML å°ææ»æçéæ§ï¼ç¹å¥æ¯å¨éå­éç®è½åæ´å±çæä»£ãå¨éæ¹é¢ï¼æ¬ææ¢è¨äº QML å°ææè½çæ¨¡åç¡ééçãææåæç¥ï¼æåå¼å¥äºéå°å°æé¯èª¤çè¿ä¼¼ä¸éçé¦æ¬¡è¨ç®ï¼ä»¥è©ä¼°æ¨¡åå°æè¤éçåºæ¼éå­çå°ææ»æçéæ§ãå¯¦é©çµæèè¨ç®åºçéçé²è¡æ¯è¼ï¼è­æäº QML æ¨¡åå¯¦ç¾é«åº¦ç©©å¥æ§çæ½åãå¨æä½³ææ³ä¸ï¼å¯¦é©èª¤å·®åæ¯ä¼°è¨éçé«åº 10%ï¼æä¾äºéå­æ¨¡åå§å¨ç©©å¥æ§çè­æãéé å·¥ä½ä¸åæåäºæåå°éå­æ¨¡åéæ§ççè«çè§£ï¼éçºæªä¾ç¼å±ç©©å¥ç QML æ¼ç®æ³æä¾äºç²¾ç¢ºçåèéçã</paragraph>

##### **Enhancing Phishing Detection through Feature Importance Analysis and Explainable AI: A Comparative Study of CatBoost, XGBoost, and EBM Models**
2411.06860v1 by Abdullah Fajar, Setiadi Yazid, Indra Budi

Phishing attacks remain a persistent threat to online security, demanding
robust detection methods. This study investigates the use of machine learning
to identify phishing URLs, emphasizing the crucial role of feature selection
and model interpretability for improved performance. Employing Recursive
Feature Elimination, the research pinpointed key features like "length_url,"
"time_domain_activation" and "Page_rank" as strong indicators of phishing
attempts. The study evaluated various algorithms, including CatBoost, XGBoost,
and Explainable Boosting Machine, assessing their robustness and scalability.
XGBoost emerged as highly efficient in terms of runtime, making it well-suited
for large datasets. CatBoost, on the other hand, demonstrated resilience by
maintaining high accuracy even with reduced features. To enhance transparency
and trustworthiness, Explainable AI techniques, such as SHAP, were employed to
provide insights into feature importance. The study's findings highlight that
effective feature selection and model interpretability can significantly
bolster phishing detection systems, paving the way for more efficient and
adaptable defenses against evolving cyber threats

æè¦ï¼ç¶²è·¯é£é­æ»ææçºå°ç·ä¸å®å¨æ§æå¨èï¼å æ­¤éè¦å¼·å¤§çåµæ¸¬æ¹æ³ãæ¬ç ç©¶æ¢è¨ä½¿ç¨æ©å¨å­¸ç¿ä¾è­å¥ç¶²è·¯é£é­ç¶²åï¼ä¸¦å¼·èª¿ç¹å¾µé¸æåæ¨¡åå¯è§£éæ§å°æ¼æåæè½è³ééè¦çè§è²ãç ç©¶æ¡ç¨éè¿´ç¹å¾µæ¶é¤æ³ï¼æ¾åºãç¶²åé·åº¦ãããæåååãåãç¶²é æåãç­ééµç¹å¾µï¼ä½çºç¶²è·¯é£é­æ»æçå¼·åææ¨ãæ¬ç ç©¶è©ä¼°äºåç¨®æ¼ç®æ³ï¼åæ¬ CatBoostãXGBoost åå¯è§£éæåæ©ï¼è©ä¼°å¶ç©©å¥æ§åå¯æ´åæ§ãXGBoost å¨å·è¡æéæ¹é¢è¡¨ç¾åºæ¥µé«çæçï¼ä½¿å¶éå¸¸é©åå¤§åè³æéãå¦ä¸æ¹é¢ï¼CatBoost å³ä½¿å¨ç¹å¾µæ¸å°çææ³ä¸ï¼ä»è½ç¶­æé«æºç¢ºåº¦ï¼å±ç¾åºéæ§ãçºäºæé«éæåº¦åå¯ä¿¡åº¦ï¼æ¬ç ç©¶æ¡ç¨å¯è§£é AI æè¡ï¼ä¾å¦ SHAPï¼ï¼ä»¥æä¾ç¹å¾µéè¦æ§çè¦è§£ãæ¬ç ç©¶çç¼ç¾å¼·èª¿ï¼ææçç¹å¾µé¸æåæ¨¡åå¯è§£éæ§å¯ä»¥é¡¯èå°å¼·åç¶²è·¯é£é­åµæ¸¬ç³»çµ±ï¼çºå°æä¸æ·æ¼è®çç¶²è·¯å¨èå¥ å®æ´ææçä¸é©ææ§æ´å¼·çé²ç¦¦åºç¤ã

##### **Scientific machine learning in ecological systems: A study on the predator-prey dynamics**
2411.06858v1 by Ranabir Devgupta, Raj Abhijit Dandekar, Rajat Dandekar, Sreedath Panat

In this study, we apply two pillars of Scientific Machine Learning: Neural
Ordinary Differential Equations (Neural ODEs) and Universal Differential
Equations (UDEs) to the Lotka Volterra Predator Prey Model, a fundamental
ecological model describing the dynamic interactions between predator and prey
populations. The Lotka-Volterra model is critical for understanding ecological
dynamics, population control, and species interactions, as it is represented by
a system of differential equations. In this work, we aim to uncover the
underlying differential equations without prior knowledge of the system,
relying solely on training data and neural networks. Using robust modeling in
the Julia programming language, we demonstrate that both Neural ODEs and UDEs
can be effectively utilized for prediction and forecasting of the
Lotka-Volterra system. More importantly, we introduce the forecasting breakdown
point: the time at which forecasting fails for both Neural ODEs and UDEs. We
observe how UDEs outperform Neural ODEs by effectively recovering the
underlying dynamics and achieving accurate forecasting with significantly less
training data. Additionally, we introduce Gaussian noise of varying magnitudes
(from mild to high) to simulate real-world data perturbations and show that
UDEs exhibit superior robustness, effectively recovering the underlying
dynamics even in the presence of noisy data, while Neural ODEs struggle with
high levels of noise. Through extensive hyperparameter optimization, we offer
insights into neural network architectures, activation functions, and
optimizers that yield the best results. This study opens the door to applying
Scientific Machine Learning frameworks for forecasting tasks across a wide
range of ecological and scientific domains.

æè¦ï¼<paragraph>å¨éé ç ç©¶ä¸­ï¼æåéç¨ç§å­¸æ©å¨å­¸ç¿çå©å¤§æ¯æ±ï¼ç¥ç¶å¸¸å¾®åæ¹ç¨å¼ (Neural ODE) åéç¨å¾®åæ¹ç¨å¼ (UDE) å° Lotka Volterra æ é£èçµç©æ¨¡åï¼éæ¯ä¸åæè¿°æ é£èåçµç©æç¾¤ä¹éåæäº¤äºä½ç¨çåºæ¬çææ¨¡åãLotka-Volterra æ¨¡åå°æ¼äºè§£çæååå­¸ãæç¾¤æ§å¶åç©ç¨®äº¤äºè³ééè¦ï¼å çºå®æ¯ç±å¾®åæ¹ç¨å¼ç³»çµ±è¡¨ç¤ºãå¨éé å·¥ä½ä¸­ï¼æåæ¨å¨æ­ç¤ºå¨æ²æç³»çµ±ååç¥è­çææ³ä¸ï¼åä¾è³´è¨ç·´è³æåç¥ç¶ç¶²è·¯çåºç¤å¾®åæ¹ç¨å¼ãä½¿ç¨ Julia ç¨å¼èªè¨ä¸­çå¼·å¥å»ºæ¨¡ï¼æåè­æäºç¥ç¶ ODE å UDE é½å¯ä»¥ææå°ç¨æ¼ Lotka-Volterra ç³»çµ±çé æ¸¬åé å ±ãæ´éè¦çæ¯ï¼æåå¼å¥äºé æ¸¬å´©æ½°é»ï¼ç¥ç¶ ODE å UDE é æ¸¬å¤±æçæéãæåè§å¯å° UDE å¦ä½ééææå°æ¢å¾©åºç¤åæä¸¦å¨è¨ç·´è³æé¡¯èæ¸å°çææ³ä¸å¯¦ç¾æºç¢ºé æ¸¬ï¼å¾èåªæ¼ç¥ç¶ ODEãæ­¤å¤ï¼æåå¼å¥äºä¸åå¤§å°ç Gaussian éè¨ï¼å¾è¼å¾®å°é«ï¼ä¾æ¨¡æ¬çå¯¦ä¸ççè³ææ¾åï¼ä¸¦è¡¨æ UDE è¡¨ç¾åºåªç°çç©©å¥æ§ï¼å³ä½¿å¨æéè¨è³æçææ³ä¸ä¹è½æææ¢å¾©åºç¤åæï¼èç¥ç¶ ODE åé£ä»¥æä»é«æ°´æºçéè¨ãééå»£æ³çè¶åæ¸æä½³åï¼æåæ·±å¥äºè§£äºç¥ç¶ç¶²è·¯æ¶æ§ãååå½æ¸åæä½³åå¨ï¼éäºæ¶æ§ãå½æ¸åæä½³åå¨å¯ç¢çæä½³çµæãéé ç ç©¶éåäºæç¨ç§å­¸æ©å¨å­¸ç¿æ¶æ§é²è¡é æ¸¬ä»»åçå¤§éï¼æ¶µèå»£æ³ççæåç§å­¸é åã</paragraph>

##### **A Unified Multi-Task Learning Architecture for Hate Detection Leveraging User-Based Information**
2411.06855v1 by Prashant Kapil, Asif Ekbal

Hate speech, offensive language, aggression, racism, sexism, and other
abusive language are common phenomena in social media. There is a need for
Artificial Intelligence(AI)based intervention which can filter hate content at
scale. Most existing hate speech detection solutions have utilized the features
by treating each post as an isolated input instance for the classification.
This paper addresses this issue by introducing a unique model that improves
hate speech identification for the English language by utilising intra-user and
inter-user-based information. The experiment is conducted over single-task
learning (STL) and multi-task learning (MTL) paradigms that use deep neural
networks, such as convolutional neural networks (CNN), gated recurrent unit
(GRU), bidirectional encoder representations from the transformer (BERT), and A
Lite BERT (ALBERT). We use three benchmark datasets and conclude that combining
certain user features with textual features gives significant improvements in
macro-F1 and weighted-F1.

æè¦ï¼ä»æ¨è¨è«ãæ»ææ§èªè¨ãä¾µç¥ãç¨®æä¸»ç¾©ãæ§å¥æ­§è¦åå¶ä»
è¾±ç½µæ§èªè¨æ¯ç¤¾ç¾¤åªé«ä¸­çå¸¸è¦ç¾è±¡ãæå¿è¦é²è¡
åºæ¼äººå·¥æºæ§ (AI) çå¹²é ï¼å®å¯ä»¥å¤§è¦æ¨¡éæ¿¾ä»æ¨å§å®¹ãå¤§å¤æ¸ç¾æçä»æ¨è¨è«åµæ¸¬è§£æ±ºæ¹æ¡é½å©ç¨äºéäºåè½
å°æ¯åè²¼æè¦çºåé¡çå­¤ç«è¼¸å¥å¯¦é«ã
æ¬æééå¼å¥ä¸åç¨ç¹æ¨¡åä¾è§£æ±ºéååé¡ï¼è©²æ¨¡åééå©ç¨ä½¿ç¨èå§é¨å
åºæ¼ä½¿ç¨èä¹éçè³è¨ä¾æ¹åè±æä»æ¨è¨è«çè­å¥ãå¯¦é©æ¯å¨å®ä¸ä»»å
å­¸ç¿ (STL) åå¤ä»»åå­¸ç¿ (MTL) å¸ç¯ä¸é²è¡ï¼éäºå¸ç¯ä½¿ç¨æ·±åº¦ç¥ç¶
ç¶²è·¯ï¼ä¾å¦å·ç©ç¥ç¶ç¶²è·¯ (CNN)ãéæ§éè¿´å®å
(GRU)ãä¾èª Transformer çéåç·¨ç¢¼å¨è¡¨ç¤º (BERT) å A
Lite BERT (ALBERT)ãæåä½¿ç¨ä¸ååºæºè³æéï¼ä¸¦å¾åºçµè«ï¼å°
æäºä½¿ç¨èåè½èæå­åè½ç¸çµåï¼å¯ä»¥å¨å·¨é F1 åå æ¬ F1 ä¸­ç²å¾é¡¯èçæ¹åã

##### **Evaluating Large Language Models on Financial Report Summarization: An Empirical Study**
2411.06852v1 by Xinqi Yang, Scott Zang, Yong Ren, Dingjie Peng, Zheng Wen

In recent years, Large Language Models (LLMs) have demonstrated remarkable
versatility across various applications, including natural language
understanding, domain-specific knowledge tasks, etc. However, applying LLMs to
complex, high-stakes domains like finance requires rigorous evaluation to
ensure reliability, accuracy, and compliance with industry standards. To
address this need, we conduct a comprehensive and comparative study on three
state-of-the-art LLMs, GLM-4, Mistral-NeMo, and LLaMA3.1, focusing on their
effectiveness in generating automated financial reports. Our primary motivation
is to explore how these models can be harnessed within finance, a field
demanding precision, contextual relevance, and robustness against erroneous or
misleading information. By examining each model's capabilities, we aim to
provide an insightful assessment of their strengths and limitations. Our paper
offers benchmarks for financial report analysis, encompassing proposed metrics
such as ROUGE-1, BERT Score, and LLM Score. We introduce an innovative
evaluation framework that integrates both quantitative metrics (e.g.,
precision, recall) and qualitative analyses (e.g., contextual fit, consistency)
to provide a holistic view of each model's output quality. Additionally, we
make our financial dataset publicly available, inviting researchers and
practitioners to leverage, scrutinize, and enhance our findings through broader
community engagement and collaborative improvement. Our dataset is available on
huggingface.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®æç¨ä¸­å±ç¾äºéå¡çå¤æ¨£æ§ï¼åæ¬èªç¶èªè¨çè§£ãç¹å®é åçç¥è­ä»»åç­ãç¶èï¼å° LLM æç¨æ¼éèç­è¤éä¸é«é¢¨éªçé åéè¦å´æ ¼çè©ä¼°ï¼ä»¥ç¢ºä¿å¯é æ§ãæºç¢ºæ§åç¬¦åç¢æ¥­æ¨æºãçºäºæ»¿è¶³éåéæ±ï¼æåå°ä¸ç¨®æåé²ç LLM é²è¡äºå¨é¢ä¸æ¯è¼æ§çç ç©¶ï¼åæ¬ GLM-4ãMistral-NeMo å LLaMA3.1ï¼éé»å¨æ¼å®åçæèªååè²¡åå ±è¡¨çæè½ãæåçé¦è¦åæ©æ¯æ¢ç´¢å¦ä½å°éäºæ¨¡åæç¨æ¼éèé åï¼éæ¯ä¸åéè¦ç²¾æºæ§ãèçµ¡ç¸éæ§åå°é¯èª¤æèª¤å°è³è¨å·æç©©å¥æ§çé åãééæª¢è¦æ¯åæ¨¡åçè½åï¼æåæ¨å¨å°å®åçåªç¼ºé»æä¾æ·±å¥çè©ä¼°ãæåçè«ææä¾äºè²¡åå ±è¡¨åæçåºæºï¼åå«æè­°çææ¨ï¼ä¾å¦ ROUGE-1ãBERT åæ¸å LLM åæ¸ãæåå¼å¥äºä¸ååµæ°çè©ä¼°æ¶æ§ï¼å®æ´åäºéåææ¨ï¼ä¾å¦ï¼ç²¾æºåº¦ãå¬åçï¼åå®æ§åæï¼ä¾å¦ï¼èçµ¡è²¼ååº¦ãä¸è´æ§ï¼ï¼ä»¥æä¾æ¯åæ¨¡åè¼¸åºåè³ªçå¨è²ãæ­¤å¤ï¼æåå¬éäºæåçè²¡åè³æéï¼éè«ç ç©¶äººå¡åå¯¦åå·¥ä½èééæ´å»£æ³çç¤¾ç¾¤åèååä½æ¹é²ï¼ä¾å©ç¨ãå¯©æ¥åå¢å¼·æåçç¼ç¾ãæåçè³æéå¯å¨ huggingface ä¸åå¾ã</paragraph>

##### **1-800-SHARED-TASKS @ NLU of Devanagari Script Languages: Detection of Language, Hate Speech, and Targets using LLMs**
2411.06850v1 by Jebish Purbey, Siddartha Pullakhandam, Kanwal Mehreen, Muhammad Arham, Drishti Sharma, Ashay Srivastava, Ram Mohan Rao Kadiyala

This paper presents a detailed system description of our entry for the
CHiPSAL 2025 shared task, focusing on language detection, hate speech
identification, and target detection in Devanagari script languages. We
experimented with a combination of large language models and their ensembles,
including MuRIL, IndicBERT, and Gemma-2, and leveraged unique techniques like
focal loss to address challenges in the natural understanding of Devanagari
languages, such as multilingual processing and class imbalance. Our approach
achieved competitive results across all tasks: F1 of 0.9980, 0.7652, and 0.6804
for Sub-tasks A, B, and C respectively. This work provides insights into the
effectiveness of transformer models in tasks with domain-specific and
linguistic challenges, as well as areas for potential improvement in future
iterations.

æè¦ï¼éç¯è«æè©³ç´°èªªæäºæåå¨ CHiPSAL 2025 å±äº«ä»»åä¸­çåè³½ç³»çµ±ï¼éé»å¨æ¼å¤©åæèªè¨ä¸­çèªè¨åµæ¸¬ãä»æ¨è¨è«è¾¨è­åç®æ¨åµæ¸¬ãæåå¯¦é©äºå¤§åèªè¨æ¨¡ååå¶éåççµåï¼åæ¬ MuRILãIndicBERT å Gemma-2ï¼ä¸¦å©ç¨ç¦é»æå¤±ç­ç¨ç¹æè¡ä¾è§£æ±ºå¤©åæèªè¨èªç¶çè§£ä¸­çææ°ï¼ä¾å¦å¤èªè¨èçåé¡å¥ä¸å¹³è¡¡ãæåçåæ³å¨ææä»»åä¸­é½åå¾äºæç«¶ç­åççµæï¼å­ä»»å AãB å C ç F1 åå¥çº 0.9980ã0.7652 å 0.6804ãéé å·¥ä½æä¾äºå°Transformeræ¨¡åå¨å·æç¹å®é ååèªè¨ææ°çä»»åä¸­çæææ§çè¦è§£ï¼ä»¥åæªä¾è¿­ä»£ä¸­æ½å¨æ¹é²çé åã

##### **LLM-Neo: Parameter Efficient Knowledge Distillation for Large Language Models**
2411.06839v1 by Runming Yang, Taiqiang Wu, Jiahao Wang, Pengfei Hu, Ngai Wong, Yujiu Yang

In this paper, we propose a novel LLM-Neo framework that efficiently
transfers knowledge from a large language model (LLM) teacher to a compact
student. Initially, we revisit the knowledge distillation (KD) and low-rank
adaption (LoRA), and argue that they share the same paradigm. Inspired by this
observation, we explore the strategy that combines LoRA and KD to enhance the
efficiency of knowledge transfer. We first summarize some guidelines for this
design and further develop the LLM-Neo. Experimental results on compressing
Llama 2 and Llama 3 show that LLM-Neo outperforms various baselines. Further
analysis demonstrates the robustness of the proposed LLM-Neo on variants of
LoRA. The trained models have been available at
\href{https://huggingface.co/collections/yang31210999/llm-neo-66e3c882f5579b829ff57eba}{this
repository}.

æè¦ï¼å¨æ¬æä¸­ï¼æåæåºä¸åæ°ç©ç LLM-Neo æ¡æ¶ï¼å¯ææå°å°ç¥è­å¾å¤§åèªè¨æ¨¡å (LLM) æå¸«å³è¼¸å°ä¸åç²¾ç°¡çå­¸çãæåï¼æåéæ°æ¢è¨ç¥è­è¸é¤¾ (KD) åä½ç§©é©æ (LoRA)ï¼ä¸¦è«è­å®åå±äº«ç¸åçç¯ä¾ãåæ­¤è§å¯åç¼ï¼æåæ¢è¨äºçµå LoRA å KD ä»¥å¢å¼·ç¥è­å³è¼¸æççç­ç¥ãæåé¦åç¸½çµäºä¸äºéæ¼æ­¤è¨­è¨çæå°æ¹éï¼ä¸¦é²ä¸æ­¥éç¼ LLM-Neoãå° Llama 2 å Llama 3 é²è¡å£ç¸®çå¯¦é©çµæè¡¨æï¼LLM-Neo åªæ¼åç¨®åºç·ãé²ä¸æ­¥çåæè­æäºææåºç LLM-Neo å¨ LoRA è®é«ä¸çç©©å¥æ§ãè¨ç·´éçæ¨¡åå·²å¨
\href{https://huggingface.co/collections/yang31210999/llm-neo-66e3c882f5579b829ff57eba}{æ­¤å²å­åº«}ä¸­æä¾ã

##### **Persuasion with Large Language Models: a Survey**
2411.06837v1 by Alexander Rogiers, Sander Noels, Maarten Buyl, Tijl De Bie

The rapid rise of Large Language Models (LLMs) has created new disruptive
possibilities for persuasive communication, by enabling fully-automated
personalized and interactive content generation at an unprecedented scale. In
this paper, we survey the research field of LLM-based persuasion that has
emerged as a result. We begin by exploring the different modes in which LLM
Systems are used to influence human attitudes and behaviors. In areas such as
politics, marketing, public health, e-commerce, and charitable giving, such LLM
Systems have already achieved human-level or even super-human persuasiveness.
We identify key factors influencing their effectiveness, such as the manner of
personalization and whether the content is labelled as AI-generated. We also
summarize the experimental designs that have been used to evaluate progress.
Our survey suggests that the current and future potential of LLM-based
persuasion poses profound ethical and societal risks, including the spread of
misinformation, the magnification of biases, and the invasion of privacy. These
risks underscore the urgent need for ethical guidelines and updated regulatory
frameworks to avoid the widespread deployment of irresponsible and harmful LLM
Systems.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çå¿«éå´èµ·çºå·æèªªæåçæºéåµé äºæ°çç ´å£æ§å¯è½æ§ï¼å®è½ä»¥åææªæçè¦æ¨¡å¯¦ç¾å¨èªååãåæ§ååäºåå¼å§å®¹çæãå¨æ¬æä¸­ï¼æåèª¿æ¥äºç±æ­¤ç¢ççåºæ¼ LLM çèªªæç ç©¶é åãæåé¦åæ¢è¨äº LLM ç³»çµ±ç¨æ¼å½±é¿äººé¡æåº¦åè¡çºçä¸åæ¨¡å¼ãå¨æ¿æ²»ãè¡é·ãå¬å±è¡çãé»å­åååæåæè´ç­é åï¼æ­¤é¡ LLM ç³»çµ±å·²ç¶éå°äººé¡æ°´å¹³çè³è¶äººé¡çèªªæåãæåæ¾åºå½±é¿å¶æææ§çééµå ç´ ï¼ä¾å¦åæ§åçæ¹å¼ä»¥åå§å®¹æ¯å¦æ¨ç¤ºçº AI çæçãæåä¹ç¸½çµäºç¨æ¼è©ä¼°é²åº¦çå¯¦é©è¨­è¨ãæåçèª¿æ¥è¡¨æï¼åºæ¼ LLM çèªªæçç¶ååæªä¾æ½åå¸¶ä¾äºæ·±é çå«çåç¤¾æé¢¨éªï¼åæ¬é¯èª¤è¨æ¯çå³æ­ãåè¦çæ¾å¤§åé±ç§çä¾µç¯ãéäºé¢¨éªå¼·èª¿äºå¶å®éå¾·æºååæ´æ°æ³è¦æ¡æ¶çè¿«åéè¦ï¼ä»¥é¿åä¸è² è²¬ä»»åæå®³ç LLM ç³»çµ±çå»£æ³é¨ç½²ã

##### **HarmLevelBench: Evaluating Harm-Level Compliance and the Impact of Quantization on Model Alignment**
2411.06835v1 by Yannis Belkhiter, Giulio Zizzo, Sergio Maffeis

With the introduction of the transformers architecture, LLMs have
revolutionized the NLP field with ever more powerful models. Nevertheless,
their development came up with several challenges. The exponential growth in
computational power and reasoning capabilities of language models has
heightened concerns about their security. As models become more powerful,
ensuring their safety has become a crucial focus in research. This paper aims
to address gaps in the current literature on jailbreaking techniques and the
evaluation of LLM vulnerabilities. Our contributions include the creation of a
novel dataset designed to assess the harmfulness of model outputs across
multiple harm levels, as well as a focus on fine-grained harm-level analysis.
Using this framework, we provide a comprehensive benchmark of state-of-the-art
jailbreaking attacks, specifically targeting the Vicuna 13B v1.5 model.
Additionally, we examine how quantization techniques, such as AWQ and GPTQ,
influence the alignment and robustness of models, revealing trade-offs between
enhanced robustness with regards to transfer attacks and potential increases in
vulnerability on direct ones. This study aims to demonstrate the influence of
harmful input queries on the complexity of jailbreaking techniques, as well as
to deepen our understanding of LLM vulnerabilities and improve methods for
assessing model robustness when confronted with harmful content, particularly
in the context of compression strategies.

æè¦ï¼é¨èTransformeræ¶æ§çå¼å¥ï¼LLM å·²ééæ´å¼·å¤§çæ¨¡åå¾¹åºæ¹è® NLP é åãåç®¡å¦æ­¤ï¼å®åçéç¼ä»é¢è¨è¨±å¤ææ°ãèªè¨æ¨¡åå¨è¨ç®è½ååæ¨çè½åä¸çææ¸æé·ï¼å·²å åäººåå°å¶å®å¨æ§ççæ®ãé¨èæ¨¡åè®å¾æ´å¼·å¤§ï¼ç¢ºä¿å¶å®å¨æ§å·²æçºç ç©¶ä¸­çééµç¦é»ãæ¬ææ¨å¨è§£æ±ºç¶åæéè¶çæè¡å LLM æ¼æ´è©ä¼°æç»ä¸­çå·®è·ãæåçè²¢ç»åæ¬å»ºç«ä¸åæ°ç©çè³æéï¼æ¨å¨è©ä¼°æ¨¡åè¼¸åºå¨å¤åå±å®³å±¤ç´ä¸­çå±å®³æ§ï¼ä»¥åå°æ³¨æ¼ç´°å¾®çå±å®³å±¤ç´åæãä½¿ç¨æ­¤æ¶æ§ï¼æåæä¾äºæåé²è¶çæ»æçå¨é¢åºæºï¼ç¹å¥éå° Vicuna 13B v1.5 æ¨¡åãæ­¤å¤ï¼æåæ¢è¨éåæè¡ï¼ä¾å¦ AWQ å GPTQï¼å¦ä½å½±é¿æ¨¡åçå°é½åç©©å¥æ§ï¼æ­ç¤ºäºå¨éå°è½ç§»æ»æçå¢å¼·ç©©å¥æ§èç´æ¥æ»æçæ½å¨æ¼æ´å¢å ä¹éçæ¬è¡¡ãæ¬ç ç©¶æ¨å¨è­ææå®³è¼¸å¥æ¥è©¢å°è¶çæè¡è¤éæ§çå½±é¿ï¼ä»¥åå æ·±æåå° LLM æ¼æ´ççè§£ï¼ä¸¦æ¹åå¨é¢å°æå®³å§å®¹æè©ä¼°æ¨¡åç©©å¥æ§çæ¹æ³ï¼ç¹å¥æ¯å¨å£ç¸®ç­ç¥çèæ¯ä¸ã

##### **Combining Domain and Alignment Vectors to Achieve Better Knowledge-Safety Trade-offs in LLMs**
2411.06824v1 by Megh Thakkar, Yash More, Quentin Fournier, Matthew Riemer, Pin-Yu Chen, Amal Zouaq, Payel Das, Sarath Chandar

There is a growing interest in training domain-expert LLMs that excel in
specific technical fields compared to their general-purpose instruction-tuned
counterparts. However, these expert models often experience a loss in their
safety abilities in the process, making them capable of generating harmful
content. As a solution, we introduce an efficient and effective merging-based
alignment method called \textsc{MergeAlign} that interpolates the domain and
alignment vectors, creating safer domain-specific models while preserving their
utility. We apply \textsc{MergeAlign} on Llama3 variants that are experts in
medicine and finance, obtaining substantial alignment improvements with minimal
to no degradation on domain-specific benchmarks. We study the impact of model
merging through model similarity metrics and contributions of individual models
being merged. We hope our findings open new research avenues and inspire more
efficient development of safe expert LLMs.

æè¦ï¼ç¸è¼æ¼ç¶ééç¨æç¤ºå¾®èª¿çæ¨¡åï¼è¨ç·´å¨ç¹å®æè¡é åä¸­è¡¨ç¾åºè²çé åå°å®¶ LLM çèè¶£æ­£èæ¥ä¿±å¢ãç¶èï¼éäºå°å®¶æ¨¡åå¨éç¨ä¸­éå¸¸æåªå¤±å¶å®å¨æ§ï¼ä½¿å¶è½å¤ ç¢çæå®³å§å®¹ãä½çºè§£æ±ºæ¹æ¡ï¼æåå¼å¥ä¸ç¨®ç¨±çº \textsc{MergeAlign} çé«æä¸ææçåºæ¼åä½µçå°é½æ¹æ³ï¼è©²æ¹æ³æå§æé ååå°é½åéï¼å¨ä¿çå¶æç¨çåæå»ºç«æ´å®å¨çé åç¹å®æ¨¡åãæåå¨é«å­¸åéèé åå°å®¶ç Llama3 è®é«ä¸å¥ç¨ \textsc{MergeAlign}ï¼å¨é åç¹å®åºæºä¸ç²å¾é¡¯èçå°é½æ¹åï¼ä¸å¹¾ä¹æ²æææ²æä»»ä½éä½ãæåééæ¨¡åç¸ä¼¼æ§ææ¨ååå¥æ¨¡ååä½µçè²¢ç»ä¾ç ç©¶æ¨¡ååä½µçå½±é¿ãæåå¸ææåçç¼ç¾è½éåæ°çç ç©¶éå¾ï¼ä¸¦æ¿åµæ´ææå°éç¼å®å¨çå°å®¶ LLMã

##### **Generative midtended cognition and Artificial Intelligence. Thinging with thinging things**
2411.06812v1 by Xabier E. Barandiaran, Marta PÃ©rez-Verdugo

This paper introduces the concept of ``generative midtended cognition'',
exploring the integration of generative AI with human cognition. The term
"generative" reflects AI's ability to iteratively produce structured outputs,
while "midtended" captures the potential hybrid (human-AI) nature of the
process. It stands between traditional conceptions of intended creation,
understood directed from within, and extended processes that bring
exo-biological processes into the creative process. We examine current
generative technologies (based on multimodal transformer architectures typical
of large language models like ChatGPT), to explain how they can transform human
cognitive agency beyond what standard theories of extended cognition can
capture. We suggest that the type of cognitive activity typical of the coupling
between a human and generative technologies is closer (but not equivalent) to
social cognition than to classical extended cognitive paradigms. Yet, it
deserves a specific treatment. We provide an explicit definition of generative
midtended cognition in which we treat interventions by AI systems as
constitutive of the agent's intentional creative processes. Furthermore, we
distinguish two dimensions of generative hybrid creativity: 1. Width: captures
the sensitivity of the context of the generative process (from the single
letter to the whole historical and surrounding data), 2. Depth: captures the
granularity of iteration loops involved in the process. Generative midtended
cognition stands in the middle depth between conversational forms of cognition
in which complete utterances or creative units are exchanged, and
micro-cognitive (e.g. neural) subpersonal processes. Finally, the paper
discusses the potential risks and benefits of widespread generative AI
adoption, including the challenges of authenticity, generative power asymmetry,
and creative boost or atrophy.

æè¦ï¼<paragraph>æ¬æä»ç»äº``çæå¼ä¸­é´è®¤ç¥''çæ¦å¿µï¼æ¢è®¨äºçæå¼äººå·¥æºè½ä¸äººç±»è®¤ç¥çæ´åãæ¯è¯­âçæå¼âåæ äºäººå·¥æºè½è¿­ä»£çæç»æåè¾åºçè½åï¼èâä¸­é´âåææå°äºè¯¥è¿ç¨æ½å¨çæ··åï¼äººæºï¼æ§è´¨ãå®ä»äºä¼ ç»çææåé æ¦å¿µï¼çè§£ä¸ºä»åé¨æå¯¼ï¼åå°å¤çç©è¿ç¨å¸¦å¥åé è¿ç¨çæ©å±è¿ç¨ä¹é´ãæä»¬ç ç©¶äºå½åççæå¼ææ¯ï¼åºäºå¤§åè¯­è¨æ¨¡åï¼å¦ ChatGPTï¼ä¸­å¸åçå¤æ¨¡æè½¬æ¢å¨æ¶æï¼ï¼ä»¥è§£éå®ä»¬å¦ä½è½¬åäººç±»è®¤ç¥è½å¨æ§ï¼è¶åºæ©å±è®¤ç¥çæ åçè®ºæè½ææå°çèå´ãæä»¬è®¤ä¸ºï¼äººä¸çæå¼ææ¯ä¹é´è¦åæç¹æçè®¤ç¥æ´»å¨ç±»åæ´æ¥è¿ï¼ä½ä¸ç­åäºï¼ç¤¾ä¼è®¤ç¥ï¼èä¸æ¯ç»å¸çæ©å±è®¤ç¥èä¾ãç¶èï¼å®å¼å¾è¿è¡ä¸é¨å¤çãæä»¬å¯¹çæå¼ä¸­é´è®¤ç¥æä¾äºä¸ä¸ªæç¡®çå®ä¹ï¼å¶ä¸­æä»¬å°äººå·¥æºè½ç³»ç»çå¹²é¢è§ä¸ºä»£çäººçææåé è¿ç¨çç»æé¨åãæ­¤å¤ï¼æä»¬åºåäºçæå¼æ··ååé åçä¸¤ä¸ªç»´åº¦ï¼1. å®½åº¦ï¼ææçæè¿ç¨ä¸ä¸æçæææ§ï¼ä»åä¸ªå­æ¯å°æ´ä¸ªåå²åå¨å´æ°æ®ï¼ï¼2. æ·±åº¦ï¼ææè¿ç¨ä¸­æ¶åçè¿­ä»£å¾ªç¯çç²åº¦ãçæå¼ä¸­é´è®¤ç¥å¤äºè®¤ç¥çå¯¹è¯å½¢å¼ï¼å¶ä¸­äº¤æ¢å®æ´çéè¿°æåé æ§åä½ï¼åå¾®è®¤ç¥ï¼ä¾å¦ç¥ç»ï¼äºä¸ªäººè¿ç¨ä¹é´çä¸­é´æ·±åº¦ãæåï¼æ¬æè®¨è®ºäºå¹¿æ³éç¨çæå¼äººå·¥æºè½çæ½å¨é£é©åå¥½å¤ï¼åæ¬çå®æ§ãçæè½åä¸å¯¹ç§°ä»¥ååé åçæåæèç¼©ç­ææã</paragraph>

##### **JPEG AI Image Compression Visual Artifacts: Detection Methods and Dataset**
2411.06810v1 by Daria Tsereh, Mark Mirgaleev, Ivan Molodetskikh, Roman Kazantsev, Dmitriy Vatolin

Learning-based image compression methods have improved in recent years and
started to outperform traditional codecs. However, neural-network approaches
can unexpectedly introduce visual artifacts in some images. We therefore
propose methods to separately detect three types of artifacts (texture and
boundary degradation, color change, and text corruption), to localize the
affected regions, and to quantify the artifact strength. We consider only those
regions that exhibit distortion due solely to the neural compression but that a
traditional codec recovers successfully at a comparable bitrate. We employed
our methods to collect artifacts for the JPEG AI verification model with
respect to HM-18.0, the H.265 reference software. We processed about 350,000
unique images from the Open Images dataset using different compression-quality
parameters; the result is a dataset of 46,440 artifacts validated through
crowd-sourced subjective assessment. Our proposed dataset and methods are
valuable for testing neural-network-based image codecs, identifying bugs in
these codecs, and enhancing their performance. We make source code of the
methods and the dataset publicly available.

æè¦ï¼è¿å¹´ä¾ï¼åºæ¼å­¸ç¿çå½±åå£ç¸®æ¹æ³å·²æé²æ­¥ï¼ä¸
éå§åªæ¼å³çµ±çç·¨è§£ç¢¼å¨ãç¶èï¼ç¥ç¶ç¶²è·¯æ¹æ³
å¯è½ææå¤å°å¨æäºå½±åä¸­å¼å¥è¦è¦ºççµãå æ­¤
æåæåºæ¹æ³ä¾åå¥åµæ¸¬ä¸ç¨®é¡åçççµï¼ç´çå
éçå£åãè²å½©è®ç°åæå­ææ¯ï¼ï¼ä»¥æ¾åºåå½±é¿ååï¼ä¸¦
éåççµå¼·åº¦ãæååèæ®é£äºåå ç¥ç¶å£ç¸®èç¢çå¤±ççååï¼ä½
å³çµ±ç·¨è§£ç¢¼å¨å¨å¯æ¯è¼çä½åçä¸å¯ä»¥æåå¾©åçååãæåæ¡ç¨
æåçéäºæ¹æ³ä¾æ¶é JPEG AI é©è­æ¨¡åç¸å°æ¼ HM-18.0ãH.265
åèè»é«çççµãæåä½¿ç¨ä¸åçå£ç¸®åè³ª
åæ¸èçäº Open Images è³æéä¸­çç´ 350,000 å¼µç¨ç¹å½±åï¼çµææ¯
ä¸ååå« 46,440 åççµçè³æéï¼ä¸¦ç¶éç¾¤ç¾å¤åç
ä¸»è§è©ä¼°é©è­ãæåæåºçè³æéåæ¹æ³å°æ¼æ¸¬è©¦
åºæ¼ç¥ç¶ç¶²è·¯çå½±åç·¨è§£ç¢¼å¨ãæ¾åºéäºç·¨è§£ç¢¼å¨ä¸­çé¯èª¤ï¼ä»¥å
æåå¶æè½å¾æå¹å¼ãæåå¬éåå§ç¢¼
æ¹æ³åè³æéã

##### **AssistRAG: Boosting the Potential of Large Language Models with an Intelligent Information Assistant**
2411.06805v1 by Yujia Zhou, Zheng Liu, Zhicheng Dou

The emergence of Large Language Models (LLMs) has significantly advanced
natural language processing, but these models often generate factually
incorrect information, known as "hallucination". Initial retrieval-augmented
generation (RAG) methods like the "Retrieve-Read" framework was inadequate for
complex reasoning tasks. Subsequent prompt-based RAG strategies and Supervised
Fine-Tuning (SFT) methods improved performance but required frequent retraining
and risked altering foundational LLM capabilities. To cope with these
challenges, we propose Assistant-based Retrieval-Augmented Generation
(AssistRAG), integrating an intelligent information assistant within LLMs. This
assistant manages memory and knowledge through tool usage, action execution,
memory building, and plan specification. Using a two-phase training approach,
Curriculum Assistant Learning and Reinforced Preference Optimization. AssistRAG
enhances information retrieval and decision-making. Experiments show AssistRAG
significantly outperforms benchmarks, especially benefiting less advanced LLMs,
by providing superior reasoning capabilities and accurate responses.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çåºç¾å¤§å¹æåäºèªç¶èªè¨èçï¼ä½éäºæ¨¡åéå¸¸æç¢çäºå¯¦ä¸æ­£ç¢ºçè³è¨ï¼ç¨±çºãå¹»è¦ºããæåçæª¢ç´¢å¢å¼·ç¢ç (RAG) æ¹æ³ï¼ä¾å¦ãæª¢ç´¢-é±è®ãæ¶æ§ï¼ä¸è¶³ä»¥æä»è¤éçæ¨çä»»åãå¾çºåºæ¼æç¤ºç RAG ç­ç¥åç£ç£å¾®èª¿ (SFT) æ¹æ³æ¹åäºæè½ï¼ä½éè¦é »ç¹éæ°è¨ç·´ï¼ä¸¦ä¸æé¢¨éªææ¹è® LLM çåºæ¬è½åãçºäºæå°éäºææ°ï¼æåæåºåºæ¼å©ççæª¢ç´¢å¢å¼·ç¢ç (AssistRAG)ï¼å¨ LLM ä¸­æ´åä¸åæºæ§åè³è¨å©çãéåå©çééå·¥å·ä½¿ç¨ãåä½å·è¡ãè¨æ¶é«å»ºæ§åè¨ç«è¦ç¯ä¾ç®¡çè¨æ¶é«åç¥è­ãä½¿ç¨å©éæ®µè¨ç·´æ¹æ³ï¼èª²ç¨å©çå­¸ç¿åå¼·ååå¥½æä½³åãAssistRAG å¢å¼·äºè³è¨æª¢ç´¢åæ±ºç­å¶å®ãå¯¦é©é¡¯ç¤ºï¼AssistRAG æé¡¯åªæ¼åºæºï¼ç¹å¥æ¯æçæ¼è¼ä¸åé²ç LLMï¼å çºå®æä¾äºåªç°çæ¨çè½ååæºç¢ºçåæã

##### **LA4SR: illuminating the dark proteome with generative AI**
2411.06798v1 by David R. Nelson, Ashish Kumar Jaiswal, Noha Ismail, Alexandra Mystikou, Kourosh Salehi-Ashtiani

AI language models (LMs) show promise for biological sequence analysis. We
re-engineered open-source LMs (GPT-2, BLOOM, DistilRoBERTa, ELECTRA, and Mamba,
ranging from 70M to 12B parameters) for microbial sequence classification. The
models achieved F1 scores up to 95 and operated 16,580x faster and at 2.9x the
recall of BLASTP. They effectively classified the algal dark proteome -
uncharacterized proteins comprising about 65% of total proteins - validated on
new data including a new, complete Hi-C/Pacbio Chlamydomonas genome. Larger
(>1B) LA4SR models reached high accuracy (F1 > 86) when trained on less than 2%
of available data, rapidly achieving strong generalization capacity. High
accuracy was achieved when training data had intact or scrambled terminal
information, demonstrating robust generalization to incomplete sequences.
Finally, we provide custom AI explainability software tools for attributing
amino acid patterns to AI generative processes and interpret their outputs in
evolutionary and biophysical contexts.

æè¦ï¼äººå·¥æºæ§èªè¨æ¨¡åï¼LMï¼å¨çç©åºååæä¸­å±ç¾åºæ½åãæåéæ°è¨­è¨äºéæ¾åå§ç¢¼ç LMï¼GPT-2ãBLOOMãDistilRoBERTaãELECTRA å Mambaï¼ç¯åå¾ 70M å° 12B ååæ¸ï¼ï¼ç¨æ¼å¾®çç©åºååé¡ãéäºæ¨¡åéå°äºé«é 95 ç F1 åæ¸ï¼éä½éåº¦æ¯ BLASTP å¿«äº 16,580 åï¼å¬åççºå¶ 2.9 åãå®åææå°å°è»é¡æèç½çµé²è¡äºåé¡ï¼éäºèç½è³ªæªç¶è¡¨å¾µï¼ç´ä½ç¸½èç½è³ªç 65%ï¼ä¸¦å¨æ°çè³æä¸é²è¡äºé©è­ï¼åæ¬ä¸åæ°çãå®æ´ç Hi-C/Pacbio è¡£è»åºå çµãç¶ä½¿ç¨ä¸å° 2% çå¯ç¨è³æé²è¡è¨ç·´æï¼è¼å¤§ç (>1B) LA4SR æ¨¡åéå°äºé«æºç¢ºåº¦ï¼F1 > 86ï¼ï¼è¿ééå°äºå¼·å¤§çæ³åè½åãç¶è¨ç·´è³æå·æå®æ´çææäºççµç«¯è³è¨æï¼éå°äºé«æºç¢ºåº¦ï¼è­æäºå°ä¸å®æ´åºåçå¼·å¤§æ³åè½åãæå¾ï¼æåæä¾å®¢è£½åç AI å¯è§£éæ§è»é«å·¥å·ï¼ç¨æ¼å°èºåºé¸æ¨¡å¼æ­¸å æ¼ AI çæéç¨ï¼ä¸¦å¨æ¼ååçç©ç©çèæ¯ä¸è§£éå¶è¼¸åºã

##### **Evolving Efficient Genetic Encoding for Deep Spiking Neural Networks**
2411.06792v1 by Wenxuan Pan, Feifei Zhao, Bing Han, Haibo Tong, Yi Zeng

By exploiting discrete signal processing and simulating brain neuron
communication, Spiking Neural Networks (SNNs) offer a low-energy alternative to
Artificial Neural Networks (ANNs). However, existing SNN models, still face
high computational costs due to the numerous time steps as well as network
depth and scale. The tens of billions of neurons and trillions of synapses in
the human brain are developed from only 20,000 genes, which inspires us to
design an efficient genetic encoding strategy that dynamic evolves to regulate
large-scale deep SNNs at low cost. Therefore, we first propose a genetically
scaled SNN encoding scheme that incorporates globally shared genetic
interactions to indirectly optimize neuronal encoding instead of weight, which
obviously brings about reductions in parameters and energy consumption. Then, a
spatio-temporal evolutionary framework is designed to optimize the inherently
initial wiring rules. Two dynamic regularization operators in the fitness
function evolve the neuronal encoding to a suitable distribution and enhance
information quality of the genetic interaction respectively, substantially
accelerating evolutionary speed and improving efficiency. Experiments show that
our approach compresses parameters by approximately 50\% to 80\%, while
outperforming models on the same architectures by 0.21\% to 4.38\% on CIFAR-10,
CIFAR-100 and ImageNet. In summary, the consistent trends of the proposed
genetically encoded spatio-temporal evolution across different datasets and
architectures highlight its significant enhancements in terms of efficiency,
broad scalability and robustness, demonstrating the advantages of the
brain-inspired evolutionary genetic coding for SNN optimization.

æè¦ï¼<paragraph>ééå©ç¨é¢æ£è¨èèçåæ¨¡æ¬å¤§è¦ç¥ç¶åéè¨ï¼èè¡ç¥ç¶ç¶²è·¯ (SNN) æä¾äºäººå·¥ç¥ç¶ç¶²è·¯ (ANN) çä½è½èæ¿ä»£æ¹æ¡ãç¶èï¼ç¾æç SNN æ¨¡åç±æ¼å¤§éçæéæ­¥é©ä»¥åç¶²è·¯æ·±åº¦åè¦æ¨¡ï¼ä»ç¶é¢è¨é«éç®ææ¬ãäººé¡å¤§è¦ä¸­çæ¸åååç¥ç¶ååæ¸åçªè§¸åç± 20,000 ååºå çµæï¼éåç¼æåè¨­è¨ä¸ç¨®ææççéºå³ç·¨ç¢¼ç­ç¥ï¼ä»¥åææ¼åä¾ä½ææ¬å°èª¿ç¯å¤§è¦æ¨¡æ·±åº¦ SNNãå æ­¤ï¼æåé¦åæåºä¸åéºå³æ¯ä¾ç SNN ç·¨ç¢¼æ¹æ¡ï¼å®çµåäºå¨çå±äº«çéºå³äº¤äºä½ç¨ï¼ä»¥éæ¥åªåç¥ç¶åç·¨ç¢¼ï¼èä¸æ¯æ¬éï¼éé¡¯ç¶ææ¸å°åæ¸åè½èãç¶å¾ï¼è¨­è¨äºä¸åæç©ºæ¼åæ¡æ¶ä¾åªååºæçåå§æ¥ç·è¦åãé©è½å½æ¸ä¸­çå©ååææ­£ååéç®å­å°ç¥ç¶åç·¨ç¢¼æ¼åå°ä¸ååé©çåå¸ï¼ä¸¦åå¥å¢å¼·éºå³äº¤äºä½ç¨çè³è¨åè³ªï¼å¤§å¹å éæ¼åéåº¦ä¸¦æé«æçãå¯¦é©è¡¨æï¼æåçåæ³å°åæ¸å£ç¸®äºå¤§ç´ 50% å° 80%ï¼åæå¨ CIFAR-10ãCIFAR-100 å ImageNet ä¸ä»¥ 0.21% å° 4.38% çå¹åº¦åªæ¼ç¸åæ¶æ§ä¸çæ¨¡åãç¸½ä¹ï¼ææåºçéºå³ç·¨ç¢¼æç©ºæ¼åå¨ä¸åè³æéåæ¶æ§ä¸­çä¸è´è¶¨å¢çªé¡¯äºå®å¨æçãå»£æ³å¯æ´åæ§åç©©å¥æ§æ¹é¢çé¡¯èå¢å¼·ï¼è­æäºå¤§è¦åç¼çæ¼åéºå³ç·¨ç¢¼å¨ SNN æä½³åæ¹é¢çåªå¢ã</paragraph>

##### **Large-scale moral machine experiment on large language models**
2411.06790v1 by Muhammad Shahrul Zaim bin Ahmad, Kazuhiro Takemoto

The rapid advancement of Large Language Models (LLMs) and their potential
integration into autonomous driving systems necessitates understanding their
moral decision-making capabilities. While our previous study examined four
prominent LLMs using the Moral Machine experimental framework, the dynamic
landscape of LLM development demands a more comprehensive analysis. Here, we
evaluate moral judgments across 51 different LLMs, including multiple versions
of proprietary models (GPT, Claude, Gemini) and open-source alternatives
(Llama, Gemma), to assess their alignment with human moral preferences in
autonomous driving scenarios. Using a conjoint analysis framework, we evaluated
how closely LLM responses aligned with human preferences in ethical dilemmas
and examined the effects of model size, updates, and architecture. Results
showed that proprietary models and open-source models exceeding 10 billion
parameters demonstrated relatively close alignment with human judgments, with a
significant negative correlation between model size and distance from human
judgments in open-source models. However, model updates did not consistently
improve alignment with human preferences, and many LLMs showed excessive
emphasis on specific ethical principles. These findings suggest that while
increasing model size may naturally lead to more human-like moral judgments,
practical implementation in autonomous driving systems requires careful
consideration of the trade-off between judgment quality and computational
efficiency. Our comprehensive analysis provides crucial insights for the
ethical design of autonomous systems and highlights the importance of
considering cultural contexts in AI moral decision-making.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼çå¿«éé²å±åå¶æ´åå°èªåé§é§ç³»çµ±ä¸­çæ½åï¼ä½¿å¾äºè§£å¶éå¾·æ±ºç­è½åè®å¾å¿è¦ãéç¶æåååçç ç©¶ä½¿ç¨éå¾·æ©å¨å¯¦é©æ¡æ¶æª¢é©äºååçªåºç LLMï¼ä½ LLM éç¼çåæç°å¢éè¦æ´å¨é¢çåæãå¨æ­¤ï¼æåè©ä¼°äº 51 åä¸åç LLM çéå¾·å¤æ·ï¼åæ¬å¤åçæ¬çå°ææ¨¡åï¼GPTãClaudeãGeminiï¼åéæºæ¿ä»£æ¹æ¡ï¼LlamaãGemmaï¼ï¼ä»¥è©ä¼°å®åå¨èªåé§é§å ´æ¯ä¸­èäººé¡éå¾·åå¥½çå°é½ç¨åº¦ãä½¿ç¨è¯ååææ¡æ¶ï¼æåè©ä¼°äº LLM åæå¨éå¾·å°å¢ä¸­èäººé¡åå¥½çæ¥è¿ç¨åº¦ï¼ä¸¦æª¢é©äºæ¨¡åå¤§å°ãæ´æ°åæ¶æ§çå½±é¿ãçµæè¡¨æï¼è¶é 100 åååæ¸çå°ææ¨¡ååéæºæ¨¡åé¡¯ç¤ºåºèäººé¡å¤æ·ç¸å°æ¥è¿çå°é½ï¼å¨éæºæ¨¡åä¸­ï¼æ¨¡åå¤§å°èèäººé¡å¤æ·çè·é¢ä¹éå­å¨é¡¯èçè² ç¸éãç¶èï¼æ¨¡åæ´æ°ä¸¦æªæçºæ¹åèäººé¡åå¥½çå°é½ï¼ä¸¦ä¸è¨±å¤ LLM å°ç¹å®çéå¾·ååè¡¨ç¾åºéåº¦çå¼·èª¿ãéäºç¼ç¾è¡¨æï¼éç¶å¢å æ¨¡åå¤§å°å¯è½æèªç¶å°å°è´æ´é¡ä¼¼äººé¡çéå¾·å¤æ·ï¼ä½å¨èªåé§é§ç³»çµ±ä¸­çå¯¦éå¯¦æ½éè¦ä»ç´°èæ®å¤æ·åè³ªåè¨ç®æçä¹éçæ¬è¡¡ãæåå¨é¢çåæçºèªä¸»ç³»çµ±çéå¾·è¨­è¨æä¾äºéè¦çè¦è§£ï¼ä¸¦å¼·èª¿äºå¨äººå·¥æºè½éå¾·æ±ºç­ä¸­èæ®æåèæ¯çéè¦æ§ã

##### **ScaleKD: Strong Vision Transformers Could Be Excellent Teachers**
2411.06786v1 by Jiawei Fan, Chao Li, Xiaolong Liu, Anbang Yao

In this paper, we question if well pre-trained vision transformer (ViT)
models could be used as teachers that exhibit scalable properties to advance
cross architecture knowledge distillation (KD) research, in the context of
using large-scale datasets for evaluation. To make this possible, our analysis
underlines the importance of seeking effective strategies to align (1) feature
computing paradigm differences, (2) model scale differences, and (3) knowledge
density differences. By combining three coupled components namely cross
attention projector, dual-view feature mimicking and teacher parameter
perception tailored to address the above problems, we present a simple and
effective KD method, called ScaleKD. Our method can train student backbones
that span across a variety of convolutional neural network (CNN), multi-layer
perceptron (MLP), and ViT architectures on image classification datasets,
achieving state-of-the-art distillation performance. For instance, taking a
well pre-trained Swin-L as the teacher model, our method gets
75.15%|82.03%|84.16%|78.63%|81.96%|83.93%|83.80%|85.53% top-1 accuracies for
MobileNet-V1|ResNet-50|ConvNeXt-T|Mixer-S/16|Mixer-B/16|ViT-S/16|Swin-T|ViT-B/16
models trained on ImageNet-1K dataset from scratch, showing
3.05%|3.39%|2.02%|4.61%|5.52%|4.03%|2.62%|3.73% absolute gains to the
individually trained counterparts. Intriguingly, when scaling up the size of
teacher models or their pre-training datasets, our method showcases the desired
scalable properties, bringing increasingly larger gains to student models. The
student backbones trained by our method transfer well on downstream MS-COCO and
ADE20K datasets. More importantly, our method could be used as a more efficient
alternative to the time-intensive pre-training paradigm for any target student
model if a strong pre-trained ViT is available, reducing the amount of viewed
training samples up to 195x.

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æä»¬è´¨çç»è¿è¯å¥½é¢è®­ç»çè§è§è½¬æ¢å¨ (ViT) æ¨¡åæ¯å¦å¯ç¨ä½æå¸ï¼å¨è¯ä¼°ä¸­ä½¿ç¨å¤§è§æ¨¡æ°æ®éæ¶ï¼å±ç¤ºå¯æ©å±å±æ§ä»¥æ¨è¿è·¨æ¶æç¥è¯è¸é¦ (KD) ç ç©¶ãä¸ºäºå®ç°è¿ä¸ç®æ ï¼æä»¬çåæå¼ºè°äºå¯»æ±ææç­ç¥ä»¥å¯¹é½ (1) ç¹å¾è®¡ç®èä¾å·®å¼ã(2) æ¨¡åè§æ¨¡å·®å¼å (3) ç¥è¯å¯åº¦å·®å¼çéè¦æ§ãéè¿ç»åä¸ä¸ªè¦åç»ä»¶ï¼å³è·¨æ³¨æåæå½±ä»ªãåè§å¾ç¹å¾æ¨¡æåéå¯¹ä¸è¿°é®é¢éèº«å®å¶çæå¸åæ°æç¥ï¼æä»¬æåºäºä¸ç§ç®åææç KD æ¹æ³ï¼ç§°ä¸º ScaleKDãæä»¬çæ¹æ³å¯ä»¥è®­ç»è·¨è¶åç§å·ç§¯ç¥ç»ç½ç» (CNN)ãå¤å±æç¥å¨ (MLP) å ViT æ¶æçå­¦çä¸»å¹²å¨å¾ååç±»æ°æ®éä¸ï¼å®ç°æåè¿çè¸é¦æ§è½ãä¾å¦ï¼ä»¥ç»è¿è¯å¥½é¢è®­ç»ç Swin-L ä½ä¸ºæå¸æ¨¡åï¼æä»¬çæ¹æ³è·å¾äº 75.15%|82.03%|84.16%|78.63%|81.96%|83.93%|83.80%|85.53% ç top-1 åç¡®çï¼ç¨äºå¨ ImageNet-1K æ°æ®éä¸ä»å¤´å¼å§è®­ç»ç MobileNet-V1|ResNet-50|ConvNeXt-T|Mixer-S/16|Mixer-B/16|ViT-S/16|Swin-T|ViT-B/16 æ¨¡åï¼æ¾ç¤ºåº 3.05%|3.39%|2.02%|4.61%|5.52%|4.03%|2.62%|3.73% çç»å¯¹å¢çï¼é«äºåç¬è®­ç»çå¯¹åºæ¨¡åãæè¶£çæ¯ï¼å½æ©å¤§æå¸æ¨¡åæå¶é¢è®­ç»æ°æ®éçè§æ¨¡æ¶ï¼æä»¬çæ¹æ³å±ç¤ºäºæéçå¯æ©å±å±æ§ï¼ä¸ºå­¦çæ¨¡åå¸¦æ¥äºè¶æ¥è¶å¤§çæ¶çãç±æä»¬çæ¹æ³è®­ç»çå­¦çä¸»å¹²å¾å¥½å°è½¬ç§»å°ä¸æ¸¸ MS-COCO å ADE20K æ°æ®éä¸ãæ´éè¦çæ¯ï¼å¦æå¯ä»¥ä½¿ç¨ç»è¿è¯å¥½é¢è®­ç»ç ViTï¼æä»¬çæ¹æ³å¯ä»¥ç¨ä½ä»»ä½ç®æ å­¦çæ¨¡åçæ¶é´å¯éåé¢è®­ç»èä¾çæ´æææ¿ä»£æ¹æ¡ï¼ä»èå°æ¥ççè®­ç»æ ·æ¬æ°éåå°å¤è¾¾ 195 åã</paragraph>

##### **MP-PINN: A Multi-Phase Physics-Informed Neural Network for Epidemic Forecasting**
2411.06781v1 by Thang Nguyen, Dung Nguyen, Kha Pham, Truyen Tran

Forecasting temporal processes such as virus spreading in epidemics often
requires more than just observed time-series data, especially at the beginning
of a wave when data is limited. Traditional methods employ mechanistic models
like the SIR family, which make strong assumptions about the underlying
spreading process, often represented as a small set of compact differential
equations. Data-driven methods such as deep neural networks make no such
assumptions and can capture the generative process in more detail, but fail in
long-term forecasting due to data limitations. We propose a new hybrid method
called MP-PINN (Multi-Phase Physics-Informed Neural Network) to overcome the
limitations of these two major approaches. MP-PINN instils the spreading
mechanism into a neural network, enabling the mechanism to update in phases
over time, reflecting the dynamics of the epidemics due to policy
interventions. Experiments on COVID-19 waves demonstrate that MP-PINN achieves
superior performance over pure data-driven or model-driven approaches for both
short-term and long-term forecasting.

æè¦ï¼é æ¸¬æééç¨ï¼ä¾å¦æµè¡çä¸­ççæ¯å³æ­ï¼éå¸¸éè¦çä¸ååæ¯è§å¯å°çæéåºåè³æï¼å°¤å¶æ¯å¨è³ææéçæ³¢æµªéå§æãå³çµ±æ¹æ³æ¡ç¨æ©æ¢°æ¨¡åï¼ä¾å¦ SIR å®¶æï¼å°åºç¤å³æ­éç¨ååºå¼·æåçåè¨­ï¼éå¸¸è¡¨ç¤ºçºä¸çµç·æ¹çå¾®åæ¹ç¨å¼ãè³æé©åçæ¹æ³ï¼ä¾å¦æ·±åº¦ç¥ç¶ç¶²è·¯ï¼æ²æéæ¨£çåè¨­ï¼ä¸¦ä¸å¯ä»¥æ´è©³ç´°å°ææçæéç¨ï¼ä½ç±æ¼è³æéå¶ï¼é·æé æ¸¬æå¤±æãæåæåºäºä¸ç¨®æ°çæ··åæ¹æ³ï¼ç¨±çº MP-PINNï¼å¤éæ®µç©çè³è¨ç¥ç¶ç¶²è·¯ï¼ï¼ä»¥åæéå©ç¨®ä¸»è¦æ¹æ³çéå¶ãMP-PINN å°å³æ­æ©å¶çè¼¸å°ç¥ç¶ç¶²è·¯ä¸­ï¼ä½¿æ©å¶è½å¤ é¨èæéæ¨ç§»èåéæ®µæ´æ°ï¼åæ ç±æ¼æ¿ç­å¹²é èç¢ççæµè¡çåæãå° COVID-19 æ³¢æµªçå¯¦é©è¡¨æï¼MP-PINN å¨ç­æåé·æé æ¸¬æ¹é¢é½åªæ¼ç´è³æé©åææ¨¡åé©åçæ¹æ³ã

##### **A Text Classification Model Combining Adversarial Training with Pre-trained Language Model and neural networks: A Case Study on Telecom Fraud Incident Texts**
2411.06772v1 by Liu Zhuoxian, Shi Tuo, Hu Xiaofeng

Front-line police officers often categorize all police call reported cases of
Telecom Fraud into 14 subcategories to facilitate targeted prevention measures,
such as precise public education. However, the associated data is characterized
by its large volume, diverse information content, and variations in expression.
Currently, there is a lack of efficient and accurate intelligent models to
replace manual classification, which, while precise, is relatively inefficient.
To address these challenges, this paper proposes a text classification model
that combines adversarial training with Pre-trained Language Model and neural
networks. The Linguistically-motivated Pre-trained Language Model model
extracts three types of language features and then utilizes the Fast Gradient
Method algorithm to perturb the generated embedding layer. Subsequently, the
Bi-directional Long Short-Term Memory and Convolutional Neural Networks
networks extract contextual syntactic information and local semantic
information, respectively. The model achieved an 83.9% classification accuracy
when trained on a portion of telecom fraud case data provided by the
operational department. The model established in this paper has been deployed
in the operational department, freeing up a significant amount of manpower and
improving the department's efficiency in combating Telecom Fraud crimes.
Furthermore, considering the universality of the model established in this
paper, other application scenarios await further exploration.

æè¦ï¼ç¬¬ä¸ç·çè­¦å¯äººå¡éå¸¸æå°ææè­¦æ¹éå ±çé»ä¿¡è©é¨æ¡ä»¶åé¡æ 14 åå­é¡å¥ï¼ä»¥å©å¾çºæ¡åæéå°æ§çé é²æªæ½ï¼ä¾å¦ç²¾æºçå®£å°æè²ãç¶èï¼ç¸éè³æçç¹é»æ¯è³æéé¾å¤§ãè³è¨å§å®¹å¤åãè¡¨éæ¹å¼è®åå¤ç«¯ãç®åï¼ç¼ºä¹ææä¸æºç¢ºçæºæ§åæ¨¡åå¯ä»¥åä»£äººå·¥åé¡ï¼éç¶äººå·¥åé¡æºç¢ºï¼ä½ç¸å°æ²ææçãçºäºæå°éäºææ°ï¼æ¬ç¯è«ææåºä¸åæå­åé¡æ¨¡åï¼å°å°æè¨ç·´èé è¨ç·´èªè¨æ¨¡åèç¥ç¶ç¶²è·¯çµåãä»¥èªè¨å­¸çºåºç¤çé è¨ç·´èªè¨æ¨¡åæèååºä¸ç¨®é¡åçèªè¨ç¹å¾µï¼ç¶å¾å©ç¨å¿«éæ¢¯åº¦æ³æ¼ç®æ³æ¾åç¢ççåµå¥å±¤ãæ¥èï¼éåé·ç­æè¨æ¶èå·ç©ç¥ç¶ç¶²è·¯åå¥èååºèçµ¡èªæ³è³è¨èå±é¨èªæè³è¨ãæ­¤æ¨¡åå¨çéé¨éæä¾çé»ä¿¡è©é¨æ¡ä»¶è³æé¨åè¨ç·´è³æä¸ï¼åé¡æºç¢ºçéå° 83.9%ãæ¬ç¯è«æå»ºç«çæ¨¡åå·²é¨ç½²å¨çéé¨éï¼å¤§å¹ç¯çäººåï¼æåè©²é¨éææé»ä¿¡è©é¨ç¯ç½ªçæçãæ­¤å¤ï¼èéæ¬ç¯è«æå»ºç«çæ¨¡åå·ææ®éæ§ï¼å°å¾é²ä¸æ­¥æ¢ç´¢å¶ä»æç¨æå¢ã

##### **PDC & DM-SFT: A Road for LLM SQL Bug-Fix Enhancing**
2411.06767v1 by Yiwen Duan, Yonghong Yu, Xiaoming Zhao, Yichang Wu, Wenbo Liu

Code Large Language Models (Code LLMs), such as Code llama and
DeepSeek-Coder, have demonstrated exceptional performance in the code
generation tasks. However, most existing models focus on the abilities of
generating correct code, but often struggle with bug repair. We introduce a
suit of methods to enhance LLM's SQL bug-fixing abilities. The methods are
mainly consisted of two parts: A Progressive Dataset Construction (PDC) from
scratch and Dynamic Mask Supervised Fine-tuning (DM-SFT). PDC proposes two data
expansion methods from the perspectives of breadth first and depth first
respectively. DM-SFT introduces an efficient bug-fixing supervised learning
approach, which effectively reduce the total training steps and mitigate the
"disorientation" in SQL code bug-fixing training. In our evaluation, the code
LLM models trained with two methods have exceeds all current best performing
model which size is much larger.

æè¦ï¼å¤§åèªè¨æ¨¡å (Code LLM)ï¼ä¾å¦ Code llama å DeepSeek-Coderï¼å·²å¨ç¨å¼ç¢¼çæä»»åä¸­å±ç¾åºéå¡çæè½ãç¶èï¼ç¾æçå¤§å¤æ¸æ¨¡åé½èéæ¼ç¢çæ­£ç¢ºç¨å¼ç¢¼çè½åï¼ä½ç¶å¸¸é£ä»¥ä¿®å¾©é¯èª¤ãæåæåºäºä¸å¥æ¹æ³ä¾å¢å¼· LLM ç SQL é¯èª¤ä¿®å¾©è½åãéäºæ¹æ³ä¸»è¦åå«å©åé¨åï¼å¾é ­éå§çæ¼¸é²å¼è³æéå»ºæ§ (PDC) ååæé®ç½©ç£ç£å¾®èª¿ (DM-SFT)ãPDC æåºäºå©ç¨®è³ææ´åæ¹æ³ï¼åå¥å¾å»£åº¦åªååæ·±åº¦åªåçè§åº¦åºç¼ãDM-SFT ä»ç´¹äºä¸ç¨®é«æçé¯èª¤ä¿®å¾©ç£ç£å­¸ç¿æ¹æ³ï¼å¯æææ¸å°ç¸½è¨ç·´æ­¥é©ä¸¦æ¸è¼ SQL ç¨å¼ç¢¼é¯èª¤ä¿®å¾©è¨ç·´ä¸­çãè¿·å¤±æ¹åãåé¡ãå¨æåçè©ä¼°ä¸­ï¼ä½¿ç¨éå©ç¨®æ¹æ³è¨ç·´çç¨å¼ç¢¼ LLM æ¨¡åè¶è¶äºææç¾ææä½³æè½æ¨¡åï¼èéäºæ¨¡åçè¦æ¨¡é½å¤§å¾å¤ã

##### **KLCBL: An Improved Police Incident Classification Model**
2411.06749v1 by Liu Zhuoxian, Shi Tuo, Hu Xiaofeng

Police incident data is crucial for public security intelligence, yet
grassroots agencies struggle with efficient classification due to manual
inefficiency and automated system limitations, especially in telecom and online
fraud cases. This research proposes a multichannel neural network model, KLCBL,
integrating Kolmogorov-Arnold Networks (KAN), a linguistically enhanced text
preprocessing approach (LERT), Convolutional Neural Network (CNN), and
Bidirectional Long Short-Term Memory (BiLSTM) for police incident
classification. Evaluated with real data, KLCBL achieved 91.9% accuracy,
outperforming baseline models. The model addresses classification challenges,
enhances police informatization, improves resource allocation, and offers broad
applicability to other classification tasks.

æè¦ï¼è­¦åäºä»¶è³æå°æ¼å¬å±å®å¨æå ±è³ééè¦ï¼ä½åºå±¤å®ä½å»å äººå·¥èçæçä½è½åèªååç³»çµ±éå¶èé£ä»¥ææåé¡ï¼ç¹å¥æ¯å¨é»ä¿¡åç¶²è·¯è©é¨æ¡ä»¶ä¸­ãæ¬ç ç©¶æåºä¸åå¤ééç¥ç¶ç¶²è·¯æ¨¡å KLCBLï¼æ´å Kolmogorov-Arnold ç¶²è·¯ (KAN)ãèªè¨å¢å¼·æå­åèçæ¹æ³ (LERT)ãå·ç©ç¥ç¶ç¶²è·¯ (CNN) åéåé·ç­æè¨æ¶ (BiLSTM) é²è¡è­¦åäºä»¶åé¡ãç¶ç±å¯¦éè³æè©ä¼°ï¼KLCBL éå° 91.9% çæºç¢ºåº¦ï¼åªæ¼åºæºæ¨¡åãè©²æ¨¡åè§£æ±ºäºåé¡ææ°ï¼å¢å¼·è­¦åè³è¨åï¼æ¹åè³æºéç½®ï¼ä¸¦å¯å»£æ³æç¨æ¼å¶ä»åé¡ä»»åã

##### **Dockformer: A transformer-based molecular docking paradigm for large-scale virtual screening**
2411.06740v1 by Zhangfan Yang, Junkai Ji, Shan He, Jianqiang Li, Ruibin Bai, Zexuan Zhu, Yew Soon Ong

Molecular docking enables virtual screening of compound libraries to identify
potential ligands that target proteins of interest, a crucial step in drug
development; however, as the size of the compound library increases, the
computational complexity of traditional docking models increases. Deep learning
algorithms can provide data-driven research and development models to increase
the speed of the docking process. Unfortunately, few models can achieve
superior screening performance compared to that of traditional models.
Therefore, a novel deep learning-based docking approach named Dockformer is
introduced in this study. Dockformer leverages multimodal information to
capture the geometric topology and structural knowledge of molecules and can
directly generate binding conformations with the corresponding confidence
measures in an end-to-end manner. The experimental results show that Dockformer
achieves success rates of 90.53\% and 82.71\% on the PDBbind core set and
PoseBusters benchmarks, respectively, and more than a 100-fold increase in the
inference process speed, outperforming almost all state-of-the-art docking
methods. In addition, the ability of Dockformer to identify the main protease
inhibitors of coronaviruses is demonstrated in a real-world virtual screening
scenario. Considering its high docking accuracy and screening efficiency,
Dockformer can be regarded as a powerful and robust tool in the field of drug
design.

æè¦ï¼åå­å°æ¥å¯å°ååç©åº«é²è¡èæ¬ç¯©é¸ï¼ä»¥è­å¥ç®æ¨èç½è³ªçæ½å¨éé«ï¼éæ¯è¥ç©éç¼ä¸­è³ééè¦çä¸æ­¥ï¼ç¶èï¼é¨èååç©åº«è¦æ¨¡çå¢å ï¼å³çµ±å°æ¥æ¨¡åçè¨ç®è¤éåº¦ä¹é¨ä¹å¢å ãæ·±åº¦å­¸ç¿æ¼ç®æ³å¯ä»¥æä¾è³æé©åçç ç©¶åéç¼æ¨¡åï¼ä»¥æé«å°æ¥éç¨çéåº¦ãéºæ¾çæ¯ï¼å¾å°ææ¨¡åè½éå°åªæ¼å³çµ±æ¨¡åçç¯©é¸æè½ãå æ­¤ï¼æ¬ç ç©¶ä¸­å¼å¥äºåçº Dockformer çæ°ååºæ¼æ·±åº¦å­¸ç¿çå°æ¥æ¹æ³ãDockformer æ¡ç¨å¤æ¨¡æè³è¨ä¾æ·ååå­çå¹¾ä½ææ²åçµæ§ç¥è­ï¼ä¸¦è½ä»¥ç«¯å°ç«¯çæ¹å¼ç´æ¥ç¢çå·æç¸æç½®ä¿¡åº¦æ¸¬éççµåæ§è±¡ãå¯¦é©çµæè¡¨æï¼Dockformer å¨ PDBbind core set å PoseBusters åºæºæ¸¬è©¦ä¸­åå¥éå°äº 90.53% å 82.71% çæåçï¼ä¸¦ä¸æ¨çéç¨éåº¦æåäº 100 åä»¥ä¸ï¼åªæ¼å¹¾ä¹æææåé²çå°æ¥æ¹æ³ãæ­¤å¤ï¼å¨ç¾å¯¦ä¸ççèæ¬ç¯©é¸å ´æ¯ä¸­ï¼è­æäº Dockformer è­å¥å ççæ¯ä¸»è¦èç½é¶æå¶åçè½åãèæ®å°å¶å°æ¥ç²¾æºåº¦åç¯©é¸æçï¼Dockformer å¯è¢«è¦çºè¥ç©è¨­è¨é åä¸­ä¸ç¨®å¼·å¤§ä¸ç©©å¥çå·¥å·ã

##### **Multi-Modal Forecaster: Jointly Predicting Time Series and Textual Data**
2411.06735v1 by Kai Kim, Howard Tsai, Rajat Sen, Abhimanyu Das, Zihao Zhou, Abhishek Tanpure, Mathew Luo, Rose Yu

Current forecasting approaches are largely unimodal and ignore the rich
textual data that often accompany the time series due to lack of well-curated
multimodal benchmark dataset. In this work, we develop TimeText Corpus (TTC), a
carefully curated, time-aligned text and time dataset for multimodal
forecasting. Our dataset is composed of sequences of numbers and text aligned
to timestamps, and includes data from two different domains: climate science
and healthcare. Our data is a significant contribution to the rare selection of
available multimodal datasets. We also propose the Hybrid Multi-Modal
Forecaster (Hybrid-MMF), a multimodal LLM that jointly forecasts both text and
time series data using shared embeddings. However, contrary to our
expectations, our Hybrid-MMF model does not outperform existing baselines in
our experiments. This negative result highlights the challenges inherent in
multimodal forecasting. Our code and data are available at
https://github.com/Rose-STL-Lab/Multimodal_ Forecasting.

æè¦ï¼ç®åï¼é æ¸¬æ¹æ³å¤§å¤æ¯å®æ¨¡æçï¼ä¸ç±æ¼ç¼ºä¹ç¶éç²¾å¿ç­åçå¤æ¨¡æåºæºè³æéï¼å æ­¤æå¿½ç¥ç¶å¸¸ä¼´é¨æéåºåçè±å¯æå­è³æãå¨éé å·¥ä½ä¸­ï¼æåéç¼äº TimeText Corpus (TTC)ï¼ä¸åç¶éç²¾å¿ç­åãæéå°é½çæå­åæéè³æéï¼ç¨æ¼å¤æ¨¡æé æ¸¬ãæåçè³æéç±èæéæ³å°é½çæ¸å­åæå­åºåçµæï¼ä¸¦åå«ä¾èªå©åä¸åé åçè³æï¼æ°£åç§å­¸åé«çä¿å¥ãæåçè³æå°å¯ç¨çå¤æ¨¡æè³æéçç¨æé¸æååºäºéå¤§è²¢ç»ãæåéæåºäºæ··åå¤æ¨¡æé æ¸¬å¨ (Hybrid-MMF)ï¼éæ¯ä¸åå¤æ¨¡æ LLMï¼ä½¿ç¨å±äº«åµå¥åæé æ¸¬æå­åæéåºåè³æãç¶èï¼èæåçé æç¸åï¼æåç Hybrid-MMF æ¨¡åå¨æåçå¯¦é©ä¸­ä¸¦æ²æåªæ¼ç¾æçåºç·ãéåè² é¢çµæçªé¡¯äºå¤æ¨¡æé æ¸¬ä¸­åºæçææ°ãæåçç¨å¼ç¢¼åè³æå¯å¨ https://github.com/Rose-STL-Lab/Multimodal_ Forecasting ä¸­åå¾ã

##### **Reverse Prompt Engineering**
2411.06729v1 by Hanqing Li, Diego Klabjan

This paper explores a new black-box, zero-shot language model inversion
problem and proposes an innovative framework for prompt reconstruction using
only text outputs from a language model. Leveraging a large language model
alongside an optimization algorithm, the proposed method effectively recovers
prompts with minimal resources. Experimental results on several datasets
derived from public sources indicate that the proposed approach achieves
high-quality prompt recovery and generates prompts more similar to the
originals than current state-of-the-art methods. Additionally, the use-case
study demonstrates the method's strong potential for generating high-quality
text data.

æè¦ï¼æ¬ææ¢è¨äºä¸åæ°çé»çãé¶æ¬¡å­¸ç¿èªè¨æ¨¡ååè½åé¡ï¼ä¸¦æåºäºä¸ååµæ°çæ¡æ¶ï¼ä½¿ç¨èªè¨æ¨¡åçæå­è¼¸åºéå»ºæç¤ºãææåºçæ¹æ³å©ç¨å¤§åèªè¨æ¨¡ååæä½³åæ¼ç®æ³ï¼ææå°ä»¥æå°è³æºå¾©åæç¤ºãå¾å¬éä¾æºè¡ççå¹¾åè³æéä¸çå¯¦é©çµæè¡¨æï¼ææåºçæ¹æ³å¯éæé«åè³ªçæç¤ºå¾©åï¼ä¸¦ç¢çæ¯ç®åæåé²çæ¹æ³æ´é¡ä¼¼åå§æç¤ºçæç¤ºãæ­¤å¤ï¼ä½¿ç¨æ¡ä¾ç ç©¶è­æäºè©²æ¹æ³å¨ç¢çé«åè³ªæå­è³ææ¹é¢çå¼·å¤§æ½åã

##### **Script-Strategy Aligned Generation: Aligning LLMs with Expert-Crafted Dialogue Scripts and Therapeutic Strategies for Psychotherapy**
2411.06723v1 by Xin Sun, Jan de Wit, Zhuying Li, Jiahuan Pei, Abdallah El Ali, Jos A. Bosch

Chatbots or conversational agents (CAs) are increasingly used to improve
access to digital psychotherapy. Many current systems rely on rigid, rule-based
designs, heavily dependent on expert-crafted dialogue scripts for guiding
therapeutic conversations. Although recent advances in large language models
(LLMs) offer the potential for more flexible interactions, their lack of
controllability and transparency poses significant challenges in sensitive
areas like psychotherapy. In this work, we explored how aligning LLMs with
expert-crafted scripts can enhance psychotherapeutic chatbot performance. Our
comparative study showed that LLMs aligned with expert-crafted scripts through
prompting and fine-tuning significantly outperformed both pure LLMs and
rule-based chatbots, achieving a more effective balance between dialogue
flexibility and adherence to therapeutic principles. Building on findings, we
proposed ``Script-Strategy Aligned Generation (SSAG)'', a flexible alignment
approach that reduces reliance on fully scripted content while enhancing LLMs'
therapeutic adherence and controllability. In a 10-day field study, SSAG
demonstrated performance comparable to full script alignment and outperformed
rule-based chatbots, empirically supporting SSAG as an efficient approach for
aligning LLMs with domain expertise. Our work advances LLM applications in
psychotherapy by providing a controllable, adaptable, and scalable solution for
digital interventions, reducing reliance on expert effort. It also provides a
collaborative framework for domain experts and developers to efficiently build
expertise-aligned chatbots, broadening access to psychotherapy and behavioral
interventions.

æè¦ï¼èå¤©æ©å¨äººæå°è©±ä»£çï¼CAï¼æ­£æ¥çè¢«ç¨æ¼æ¹åå°æ¸ä½å¿çæ²»ççå­åãè¨±å¤ç¾æç³»çµ±ä¾è³´æ¼åµç¡¬ä¸åºæ¼è¦åçè¨­è¨ï¼å´éä¾è³´å°å®¶ç²¾å¿è£½ä½çå°è©±è³æ¬ä»¥å¼å°æ²»çå°è©±ãåç®¡å¤§åèªè¨æ¨¡åï¼LLMï¼çææ°é²å±æä¾äºæ´éæ´»äºåçå¯è½æ§ï¼ä½å®åç¼ºä¹å¯æ§æ§åéæåº¦ï¼å¨å¿çæ²»çç­ææé åæ§æäºéå¤§ææ°ãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äºå¦ä½å° LLM èå°å®¶ç²¾å¿è£½ä½çè³æ¬ç¸çµåï¼ä»¥å¢å¼·å¿çæ²»çèå¤©æ©å¨äººçæè½ãæåçæ¯è¼ç ç©¶è¡¨æï¼ééæç¤ºåå¾®èª¿èå°å®¶ç²¾å¿è£½ä½çè³æ¬ç¸çµåç LLMï¼æé¡¯åªæ¼ç´ LLM ååºæ¼è¦åçèå¤©æ©å¨äººï¼å¨å°è©±éæ´»æ§èå°æ²»çååçéµå®ä¹éåå¾æ´ææçå¹³è¡¡ãæ ¹æç ç©¶çµæï¼æåæåºäºãè³æ¬ç­ç¥å°é½çæï¼SSAGï¼ãââä¸ç¨®éæ´»çå°é½æ¹æ³ï¼å®æ¸å°å°å®å¨è³æ¬åå§å®¹çä¾è³´ï¼åæå¢å¼· LLM çæ²»çä¾å¾æ§åå¯æ§æ§ãå¨çºæ 10 å¤©çå¯¦å°ç ç©¶ä¸­ï¼SSAG è¡¨ç¾åºèå®å¨è³æ¬å°é½ç¸ç¶çæè½ï¼ä¸¦ä¸åªæ¼åºæ¼è¦åçèå¤©æ©å¨äººï¼å¯¦è­å°æ¯æ SSAG ä½çºä¸ç¨®å° LLM èé åå°æ¥­ç¥è­å°é½çæææ¹æ³ãæåçç ç©¶ééæä¾ä¸ç¨®å¯æ§ãå¯é©æä¸å¯æ´åçæ¸ä½ä»å¥è§£æ±ºæ¹æ¡ï¼æ¨åäº LLM å¨å¿çæ²»çä¸­çæç¨ï¼æ¸å°å°å°å®¶å·¥ä½çä¾è³´ãå®éçºé åå°å®¶åéç¼äººå¡æä¾äºä¸ååä½æ¡æ¶ï¼ä»¥ä¾¿ææå°å»ºæ§èå°æ¥­ç¥è­ç¸ç¬¦çèå¤©æ©å¨äººï¼æ´å¤§å°å¿çæ²»çåè¡çºä»å¥çå­åã

##### **Synthesize, Partition, then Adapt: Eliciting Diverse Samples from Foundation Models**
2411.06722v1 by Yeming Wen, Swarat Chaudhuri

Presenting users with diverse responses from foundation models is crucial for
enhancing user experience and accommodating varying preferences. However,
generating multiple high-quality and diverse responses without sacrificing
accuracy remains a challenge, especially when using greedy sampling. In this
work, we propose a novel framework, Synthesize-Partition-Adapt (SPA), that
leverages the abundant synthetic data available in many domains to elicit
diverse responses from foundation models. By leveraging signal provided by data
attribution methods such as influence functions, SPA partitions data into
subsets, each targeting unique aspects of the data, and trains multiple model
adaptations optimized for these subsets. Experimental results demonstrate the
effectiveness of our approach in diversifying foundation model responses while
maintaining high quality, showcased through the HumanEval and MBPP tasks in the
code generation domain and several tasks in the natural language understanding
domain, highlighting its potential to enrich user experience across various
applications.

æè¦ï¼çºä½¿ç¨èæä¾åºç¤æ¨¡åçå¤ååæï¼å°æ¼æåä½¿ç¨èé«é©åé©æä¸åçåå¥½è³ééè¦ãç¶èï¼å¨ä¸ç§ç²æºç¢ºæ§çææ³ä¸ç¢çå¤åé«åè³ªä¸å¤åçåæä»ç¶æ¯ä¸é ææ°ï¼ç¹å¥æ¯å¨ä½¿ç¨è²ªå©ªæ¡æ¨£æãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸åæ°çæ¡æ¶ï¼ç¨±çºåæ-åå²-é©æ (SPA)ï¼å®å©ç¨è¨±å¤é åä¸­è±å¯çåæè³æï¼å¾åºç¤æ¨¡åä¸­å¼åºå¤æ¨£åçåæãééå©ç¨è³ææ­¸å æ¹æ³ï¼ä¾å¦å½±é¿å½æ¸ï¼æä¾çè¨èï¼SPA å°è³æåå²çºå­éï¼æ¯åå­ééå°è³æçä¸åé¢åï¼ä¸¦è¨ç·´å¤åéå°éäºå­éæä½³åçæ¨¡åé©æãå¯¦é©çµæè­æäºæåçæ¹æ³å¨ä½¿åºç¤æ¨¡ååæå¤æ¨£åæ¹é¢çæææ§ï¼åæä¿æé«åè³ªï¼éééç¨å¼ç¢¼çæé åä¸­çäººé¡è©ä¼°å MBPP ä»»åä»¥åèªç¶èªè¨çè§£é åä¸­çå¹¾åä»»åå±ç¤ºåºä¾ï¼çªé¡¯äºå®å¨åç¨®æç¨ä¸­è±å¯ä½¿ç¨èé«é©çæ½åã

##### **DiffSR: Learning Radar Reflectivity Synthesis via Diffusion Model from Satellite Observations**
2411.06714v1 by Xuming He, Zhiwang Zhou, Wenlong Zhang, Xiangyu Zhao, Hao Chen, Shiqi Chen, Lei Bai

Weather radar data synthesis can fill in data for areas where ground
observations are missing. Existing methods often employ reconstruction-based
approaches with MSE loss to reconstruct radar data from satellite observation.
However, such methods lead to over-smoothing, which hinders the generation of
high-frequency details or high-value observation areas associated with
convective weather. To address this issue, we propose a two-stage
diffusion-based method called DiffSR. We first pre-train a reconstruction model
on global-scale data to obtain radar estimation and then synthesize radar
reflectivity by combining radar estimation results with satellite data as
conditions for the diffusion model. Extensive experiments show that our method
achieves state-of-the-art (SOTA) results, demonstrating the ability to generate
high-frequency details and high-value areas.

æè¦ï¼å©ç¨å¤©æ°£é·éè³æåæå¯ä»¥å¡«è£å°é¢è§æ¸¬è³æç¼ºå¤±ååçè³æãç¾æçæ¹æ³éå¸¸ä½¿ç¨åºæ¼éå»ºç MSE æå¤±æ¹æ³ï¼å¾è¡æè§æ¸¬è³æéå»ºé·éè³æãç¶èï¼éç¨®æ¹æ³æå°è´éåº¦å¹³æ»ï¼é»ç¤çæå°æµå¤©æ°£ç¸éçé«é »ç´°ç¯æé«å¼è§æ¸¬ååãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ç¨®ç¨±çº DiffSR çå©éæ®µåºæ¼æ´æ£çæ¹æ³ãæåé¦åå¨å¨çå°ºåº¦çè³æä¸é è¨ç·´ä¸åéå»ºæ¨¡åï¼ä»¥ç²å¾é·éä¼°è¨ï¼ç¶å¾ééå°é·éä¼°è¨çµæèè¡æè³æçµåä½çºæ´æ£æ¨¡åçæ¢ä»¶ï¼ä¾åæé·éåå°çãå¤§éçå¯¦é©è¡¨æï¼æåçæ¨¡åéå°äºæåé² (SOTA) ççµæï¼è­æäºçæé«é »ç´°ç¯åé«å¼ååçè½åã

##### **Ambient AI Scribing Support: Comparing the Performance of Specialized AI Agentic Architecture to Leading Foundational Models**
2411.06713v1 by Chanseo Lee, Sonu Kumar, Kimon A. Vogt, Sam Meraj

This study compares Sporo Health's AI Scribe, a proprietary model fine-tuned
for medical scribing, with various LLMs (GPT-4o, GPT-3.5, Gemma-9B, and
Llama-3.2-3B) in clinical documentation. We analyzed de-identified patient
transcripts from partner clinics, using clinician-provided SOAP notes as the
ground truth. Each model generated SOAP summaries using zero-shot prompting,
with performance assessed via recall, precision, and F1 scores. Sporo
outperformed all models, achieving the highest recall (73.3%), precision
(78.6%), and F1 score (75.3%) with the lowest performance variance.
Statistically significant differences (p < 0.05) were found between Sporo and
the other models, with post-hoc tests showing significant improvements over
GPT-3.5, Gemma-9B, and Llama 3.2-3B. While Sporo outperformed GPT-4o by up to
10%, the difference was not statistically significant (p = 0.25). Clinical user
satisfaction, measured with a modified PDQI-9 inventory, favored Sporo.
Evaluations indicated Sporo's outputs were more accurate and relevant. This
highlights the potential of Sporo's multi-agentic architecture to improve
clinical workflows.

æè¦ï¼æ¬ç ç©¶æ¯è¾äº Sporo Health ç AI Scribeï¼ä¸ç§éå¯¹å»çè®°å½ä¸é¨å¾®è°çä¸ææ¨¡åï¼ä¸ä¸´åºè®°å½ä¸­çåç§ LLMï¼GPT-4oãGPT-3.5ãGemma-9B å Llama-3.2-3Bï¼ãæä»¬åæäºæ¥èªåä½è¯æçå»æ è¯æ£èè®°å½ï¼ä½¿ç¨ä¸´åºå»çæä¾ç SOAP è®°å½ä½ä¸ºåºæ¬äºå®ãæ¯ä¸ªæ¨¡åä½¿ç¨é¶æ¬¡æç¤ºçæäº SOAP æè¦ï¼éè¿å¬åçãç²¾ç¡®çå F1 åæ°è¯ä¼°æ§è½ãSporo ä¼äºæææ¨¡åï¼ä»¥æä½çæ§è½å·®å¼å®ç°äºæé«çå¬åç (73.3%)ãç²¾ç¡®ç (78.6%) å F1 åæ° (75.3%)ãå¨ Sporo åå¶ä»æ¨¡åä¹é´åç°äºç»è®¡å­¦ä¸çæ¾çå·®å¼ (p < 0.05)ï¼äºåæ£éªæ¾ç¤ºä¸ GPT-3.5ãGemma-9B å Llama 3.2-3B ç¸æ¯ææ¾çæ¹åãè½ç¶ Sporo çè¡¨ç°ä¼äº GPT-4o è¾¾ 10%ï¼ä½å·®å¼å¨ç»è®¡å­¦ä¸å¹¶ä¸æ¾ç (p = 0.25)ãä½¿ç¨ä¿®æ¹åç PDQI-9 æ¸åè¡¡éçä¸´åºç¨æ·æ»¡æåº¦åå¥½ Sporoãè¯ä¼°è¡¨æ Sporo çè¾åºæ´åç¡®ãæ´ç¸å³ãè¿çªåºäº Sporo çå¤ä»£çæ¶æå¨æ¹è¿ä¸´åºå·¥ä½æµç¨æ¹é¢çæ½åã

##### **Model Fusion through Bayesian Optimization in Language Model Fine-Tuning**
2411.06710v1 by Chaeyun Jang, Hyungi Lee, Jungtaek Kim, Juho Lee

Fine-tuning pre-trained models for downstream tasks is a widely adopted
technique known for its adaptability and reliability across various domains.
Despite its conceptual simplicity, fine-tuning entails several troublesome
engineering choices, such as selecting hyperparameters and determining
checkpoints from an optimization trajectory. To tackle the difficulty of
choosing the best model, one effective solution is model fusion, which combines
multiple models in a parameter space. However, we observe a large discrepancy
between loss and metric landscapes during the fine-tuning of pre-trained
language models. Building on this observation, we introduce a novel model
fusion technique that optimizes both the desired metric and loss through
multi-objective Bayesian optimization. In addition, to effectively select
hyperparameters, we establish a two-stage procedure by integrating Bayesian
optimization processes into our framework. Experiments across various
downstream tasks show considerable performance improvements using our Bayesian
optimization-guided method.

æè¦ï¼å¾®èª¿é è¨ç·´æ¨¡åä»¥é²è¡ä¸æ¸¸ä»»åæ¯ä¸ç¨®å»£æ³æ¡ç¨çæè¡ï¼ä»¥å¶å¨åç¨®é åçé©ææ§åå¯é æ§èèåãåç®¡å¶æ¦å¿µç°¡å®ï¼ä½å¾®èª¿éè¦é²è¡å¤é ç¹ç£çå·¥ç¨é¸æï¼ä¾å¦é¸æè¶åæ¸åç¢ºå®åªåè»è·¡ä¸­çæª¢æ¥é»ãçºäºè§£æ±ºé¸ææä½³æ¨¡åçé£é¡ï¼ä¸ç¨®ææçè§£æ±ºæ¹æ¡æ¯æ¨¡åèåï¼å®å¨åæ¸ç©ºéä¸­çµåäºå¤åæ¨¡åãç¶èï¼æåå¨é è¨ç·´èªè¨æ¨¡åçå¾®èª¿éç¨ä¸­è§å¯å°æå¤±åææ¨æ¯è§ä¹éå­å¨å¾å¤§å·®ç°ãåºæ¼éä¸è§å¯ï¼æåå¼å¥äºä¸ç¨®æ°ç©çæ¨¡åèåæè¡ï¼ééå¤ç®æ¨è²èæ¯åªåä¾åªåæéçææ¨åæå¤±ãæ­¤å¤ï¼çºäºææå°é¸æè¶åæ¸ï¼æåééå°è²èæ¯åªåæµç¨æ´åå°æåçæ¡æ¶ä¸­ä¾å»ºç«ä¸åå©éæ®µç¨åºãå¨åç¨®ä¸æ¸¸ä»»åä¸­çå¯¦é©è¡¨æï¼ä½¿ç¨æåçè²èæ¯åªåæå°æ¹æ³é¡¯èæé«äºæ§è½ã

##### **Autonomous Droplet Microfluidic Design Framework with Large Language Models**
2411.06691v1 by Dinh-Nguyen Nguyen, Raymond Kai-Yu Tong, Ngoc-Duy Dinh

Droplet-based microfluidic devices have substantial promise as cost-effective
alternatives to current assessment tools in biological research. Moreover,
machine learning models that leverage tabular data, including input design
parameters and their corresponding efficiency outputs, are increasingly
utilised to automate the design process of these devices and to predict their
performance. However, these models fail to fully leverage the data presented in
the tables, neglecting crucial contextual information, including column
headings and their associated descriptions. This study presents
MicroFluidic-LLMs, a framework designed for processing and feature extraction,
which effectively captures contextual information from tabular data formats.
MicroFluidic-LLMs overcomes processing challenges by transforming the content
into a linguistic format and leveraging pre-trained large language models
(LLMs) for analysis. We evaluate our MicroFluidic-LLMs framework on 11
prediction tasks, covering aspects such as geometry, flow conditions, regimes,
and performance, utilising a publicly available dataset on flow-focusing
droplet microfluidics. We demonstrate that our MicroFluidic-LLMs framework can
empower deep neural network models to be highly effective and straightforward
while minimising the need for extensive data preprocessing. Moreover, the
exceptional performance of deep neural network models, particularly when
combined with advanced natural language processing models such as DistilBERT
and GPT-2, reduces the mean absolute error in the droplet diameter and
generation rate by nearly 5- and 7-fold, respectively, and enhances the regime
classification accuracy by over 4%, compared with the performance reported in a
previous study. This study lays the foundation for the huge potential
applications of LLMs and machine learning in a wider spectrum of microfluidic
applications.

æè¦ï¼<paragraph>åºæ¼æ¶²æ»´çå¾®æµé«è£ç½®æææçºçç©ç ç©¶ä¸­ç¶æ¿ææçæ¿ä»£æ¹æ¡ï¼å¯åä»£ç¾æçè©ä¼°å·¥å·ãæ­¤å¤ï¼å©ç¨è¡¨æ ¼æ¸æï¼åæ¬è¼¸å¥è¨­è¨åæ¸åå¶å°æçæçè¼¸åºï¼çæ©å¨å­¸ç¿æ¨¡åæ­£æ¥çç¨æ¼èªååéäºè£ç½®çè¨­è¨æµç¨ï¼ä¸¦é æ¸¬å¶æ§è½ãç¶èï¼éäºæ¨¡åæªè½ååå©ç¨è¡¨æ ¼ä¸­åç¾çæ¸æï¼å¿½è¦äºééµçä¸ä¸æä¿¡æ¯ï¼åæ¬æ¬ä½æ¨é¡åå¶ç¸éæè¿°ãæ¬ç ç©¶æåºäº MicroFluidic-LLMsï¼éæ¯ä¸åå°éç¨æ¼èçåç¹å¾µæåçæ¡æ¶ï¼å¯æææ·åè¡¨æ ¼æ¸ææ ¼å¼ä¸­çä¸ä¸æä¿¡æ¯ãMicroFluidic-LLMs ééå°å§å®¹è½æçºèªè¨æ ¼å¼ï¼ä¸¦å©ç¨é åè¨ç·´çå¤§èªè¨æ¨¡å (LLM) é²è¡åæï¼åæäºèçææ°ãæåå¨ 11 é é æ¸¬ä»»åä¸è©ä¼°äºæåç MicroFluidic-LLMs æ¡æ¶ï¼æ¶µèå¹¾ä½å½¢çãæµåæ¢ä»¶ãæ©å¶åæ§è½ç­æ¹é¢ï¼ä¸¦å©ç¨äºå¬éçæµåèç¦æ¶²æ»´å¾®æµé«æ¸æéãæåè­æäºæåç MicroFluidic-LLMs æ¡æ¶å¯ä»¥è®æ·±åº¦ç¥ç¶ç¶²è·¯æ¨¡åé«æä¸ç´æ¥ï¼åææå¤§éåº¦å°æ¸å°å°å¤§éæ¸æé èççéæ±ãæ­¤å¤ï¼æ·±åº¦ç¥ç¶ç¶²è·¯æ¨¡åçåºè²æ§è½ï¼ç¹å¥æ¯è DistilBERT å GPT-2 ç­åé²çèªç¶èªè¨èçæ¨¡åçµåä½¿ç¨æï¼å°æ¶²æ»´ç´å¾åçæççå¹³åçµå°èª¤å·®åå¥éä½äºè¿ 5 åå 7 åï¼ä¸¦å°æ©å¶åé¡æºç¢ºåº¦æé«äº 4% ä»¥ä¸ï¼èååç ç©¶å ±åçæ§è½ç¸æ¯ãæ¬ç ç©¶çº LLM åæ©å¨å­¸ç¿å¨æ´å»£æ³çå¾®æµé«æç¨ä¸­çå·¨å¤§æ½å¨æç¨å¥ å®äºåºç¤ã</paragraph>

##### **WDMoE: Wireless Distributed Mixture of Experts for Large Language Models**
2411.06681v1 by Nan Xue, Yaping Sun, Zhiyong Chen, Meixia Tao, Xiaodong Xu, Liang Qian, Shuguang Cui, Wenjun Zhang, Ping Zhang

Large Language Models (LLMs) have achieved significant success in various
natural language processing tasks, but the role of wireless networks in
supporting LLMs has not been thoroughly explored. In this paper, we propose a
wireless distributed Mixture of Experts (WDMoE) architecture to enable
collaborative deployment of LLMs across edge servers at the base station (BS)
and mobile devices in wireless networks. Specifically, we decompose the MoE
layer in LLMs by placing the gating network and the preceding neural network
layer at BS, while distributing the expert networks among the devices. This
deployment leverages the parallel inference capabilities of expert networks on
mobile devices, effectively utilizing the limited computing and caching
resources of these devices. Accordingly, we develop a performance metric for
WDMoE-based LLMs, which accounts for both model capability and latency. To
minimize the latency while maintaining accuracy, we jointly optimize expert
selection and bandwidth allocation based on the performance metric. Moreover,
we build a hardware testbed using NVIDIA Jetson kits to validate the
effectiveness of WDMoE. Both theoretical simulations and practical hardware
experiments demonstrate that the proposed method can significantly reduce the
latency without compromising LLM performance.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨®èªç¶èªè¨èçä»»åä¸­åå¾é¡¯èæåï¼ä½ç¡ç·ç¶²è·¯å¨æ¯æ´ LLM ä¸­çè§è²å°æªè¢«å¾¹åºæ¢è¨ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®ç¡ç·åæ£å¼å°å®¶æ··å (WDMoE) æ¶æ§ï¼ä»¥å¨åºå°å° (BS) çéç·£ä¼ºæå¨åç¡ç·ç¶²è·¯ä¸­çè¡åè£ç½®ä¸å¯¦ç¾ LLM çåä½é¨ç½²ãå·é«ä¾èªªï¼æåééå°éæ§ç¶²è·¯ååç½®ç¥ç¶ç¶²è·¯å±¤ç½®æ¼ BSï¼åæå°å°å®¶ç¶²è·¯åä½å¨è£ç½®ä¸­ï¼ä¾åè§£ LLM ä¸­ç MoE å±¤ãæ­¤é¨ç½²å©ç¨äºè¡åè£ç½®ä¸å°å®¶ç¶²è·¯çä¸¦è¡æ¨è«è½åï¼ææå°å©ç¨äºéäºè£ç½®æéçéç®åå¿«åè³æºãå æ­¤ï¼æåéç¼äºä¸ååºæ¼ WDMoE ç LLM æè½ææ¨ï¼å®åæèéäºæ¨¡åè½ååå»¶é²ãçºäºå¨ç¶­æç²¾æºåº¦çåæå°å»¶é²éè³æä½ï¼æåæ ¹ææè½ææ¨å±åæä½³åå°å®¶é¸æåé »å¯¬éç½®ãæ­¤å¤ï¼æåä½¿ç¨ NVIDIA Jetson å¥ä»¶å»ºæ§ç¡¬é«æ¸¬è©¦å¹³å°ï¼ä»¥é©è­ WDMoE çæè½ãçè«æ¨¡æ¬åå¯¦éç¡¬é«å¯¦é©é½è­æï¼ææåºçæ¹æ³å¯ä»¥å¨ä¸å½±é¿ LLM æè½çææ³ä¸ï¼é¡¯èéä½å»¶é²ã

##### **What Should Baby Models Read? Exploring Sample-Efficient Data Composition on Model Performance**
2411.06672v1 by Hong Meng Yam, Nathan J Paek

We explore the impact of pre-training data composition on the performance of
small language models in a sample-efficient setting. Using datasets limited to
10 million words, we evaluate several dataset sources, including child-directed
speech (CHILDES), classic books (Gutenberg), synthetic data (TinyStories), and
a mix of these (Mix) across different model sizes ranging from 18 million to
705 million parameters. Our experiments show that smaller models (e.g.,
GPT2-97M, GPT2-705M, Llama-360M) perform better when trained on more complex
and rich datasets like Gutenberg. Models trained on the CHILDES and TinyStories
datasets underperformed across all model sizes. These findings suggest that the
optimal dataset for sample efficient training depends on the model size, and
that neither child-directed speech nor simplified stories are optimal for
language models of all sizes. We highlight the importance of considering both
dataset composition and model capacity for effective sample efficient language
model training.

æè¦ï¼æåæ¢è¨é è¨ç·´è³æçµæå°å°åèªè¨æ¨¡åå¨æ¨£æ¬æçè¨­å®ä¸çæè½å½±é¿ãä½¿ç¨éå¶å¨ 1 åè¬åå®å­çè³æéï¼æåè©ä¼°äºå¹¾åè³æéä¾æºï¼åæ¬åç«¥å°åèªè¨ (CHILDES)ãç¶å¸æ¸ç± (Gutenberg)ãåæè³æ (TinyStories) ä»¥åéäºè³æçæ··å (Mix)ï¼æ¶µèå¾ 1800 è¬å° 7.05 åååæ¸çä¸åæ¨¡åå¤§å°ãæåçå¯¦é©é¡¯ç¤ºï¼è¼å°çæ¨¡å (ä¾å¦ GPT2-97MãGPT2-705MãLlama-360M) å¨éå°æ´è¤éä¸è±å¯çè³æéï¼ä¾å¦ Gutenbergï¼é²è¡è¨ç·´æè¡¨ç¾è¼ä½³ãå¨ CHILDES å TinyStories è³æéä¸è¨ç·´çæ¨¡åå¨æææ¨¡åå¤§å°ä¸­è¡¨ç¾ä¸ä½³ãéäºç¼ç¾è¡¨æï¼æ¨£æ¬æçè¨ç·´çæä½³è³æéåæ±ºæ¼æ¨¡åå¤§å°ï¼ä¸¦ä¸åç«¥å°åèªè¨æç°¡åæäºé½ä¸æ¯ææå¤§å°èªè¨æ¨¡åçæä½³é¸æãæåå¼·èª¿èæ®è³æéçµæåæ¨¡åå®¹éå°æ¼ææçæ¨£æ¬æçèªè¨æ¨¡åè¨ç·´çéè¦æ§ã

##### **Adversarial Detection with a Dynamically Stable System**
2411.06666v1 by Xiaowei Long, Jie Lin, Xiangyuan Yang

Adversarial detection is designed to identify and reject maliciously crafted
adversarial examples(AEs) which are generated to disrupt the classification of
target models.
  Presently, various input transformation-based methods have been developed on
adversarial example detection, which typically rely on empirical experience and
lead to unreliability against new attacks.
  To address this issue, we propose and conduct a Dynamically Stable System
(DSS), which can effectively detect the adversarial examples from normal
examples according to the stability of input examples.
  Particularly, in our paper, the generation of adversarial examples is
considered as the perturbation process of a Lyapunov dynamic system, and we
propose an example stability mechanism, in which a novel control term is added
in adversarial example generation to ensure that the normal examples can
achieve dynamic stability while the adversarial examples cannot achieve the
stability.
  Then, based on the proposed example stability mechanism, a Dynamically Stable
System (DSS) is proposed, which can utilize the disruption and restoration
actions to determine the stability of input examples and detect the adversarial
examples through changes in the stability of the input examples.
  In comparison with existing methods in three benchmark datasets(MNIST,
CIFAR10, and CIFAR100), our evaluation results show that our proposed DSS can
achieve ROC-AUC values of 99.83%, 97.81% and 94.47%, surpassing the
state-of-the-art(SOTA) values of 97.35%, 91.10% and 93.49% in the other 7
methods.

æè¦ï¼å°ææ§åµæ¸¬æ¨å¨è­å¥åæçµæ¡æè£½ä½çå°ææ§ç¯ä¾ (AE)ï¼éäºç¯ä¾æç¢çä»¥æ¾äºç®æ¨æ¨¡ååé¡ã
ç®åï¼å·²éå°å°ææ§ç¯ä¾åµæ¸¬éç¼äºåç¨®åºæ¼è¼¸å¥è½æçæ¹æ³ï¼éäºæ¹æ³éå¸¸ä¾è³´æ¼ç¶é©ç¶é©ï¼ä¸ç¡æ³å°ææ°çæ»æã
çºäºè§£æ±ºæ­¤åé¡ï¼æåæåºä¸¦é²è¡åæç©©å®ç³»çµ± (DSS)ï¼å¯æ ¹æè¼¸å¥ç¯ä¾çç©©å®æ§ææåµæ¸¬åºæ­£å¸¸ç¯ä¾ä¸­çå°ææ§ç¯ä¾ã
ç¹å¥æ¯å¨æåçè«æä¸­ï¼å°ææ§ç¯ä¾çç¢çè¢«è¦çºæäºæ®è«¾å¤«åæç³»çµ±çæ¾åéç¨ï¼æåæåºäºä¸åç¯ä¾ç©©å®æ©å¶ï¼å¨å¶ä¸­æ¼å°ææ§ç¯ä¾ç¢çä¸­å å¥ä¸åæ°ç©çæ§å¶é ï¼ä»¥ç¢ºä¿æ­£å¸¸ç¯ä¾å¯ä»¥éå°åæç©©å®ï¼èå°ææ§ç¯ä¾åç¡æ³éå°ç©©å®ã
ç¶å¾ï¼æ ¹æææåºçç¯ä¾ç©©å®æ©å¶ï¼æåºäºä¸ååæç©©å®ç³»çµ± (DSS)ï¼å®å¯ä»¥å©ç¨æ¾ååå¾©ååä½ä¾ç¢ºå®è¼¸å¥ç¯ä¾çç©©å®æ§ï¼ä¸¦ééè¼¸å¥ç¯ä¾ç©©å®æ§çè®åä¾åµæ¸¬å°ææ§ç¯ä¾ã
èä¸ååºæºè³æé (MNISTãCIFAR10 å CIFAR100) ä¸­ç¾ææ¹æ³ç¸æ¯ï¼æåçè©ä¼°çµæé¡¯ç¤ºï¼æåæåºç DSS å¯ä»¥éå° 99.83%ã97.81% å 94.47% ç ROC-AUC å¼ï¼è¶è¶å¶ä» 7 ç¨®æ¹æ³ç 97.35%ã91.10% å 93.49% çæåé² (SOTA) å¼ã

##### **Bridge: A Unified Framework to Knowledge Graph Completion via Language Models and Knowledge Representation**
2411.06660v1 by Qiao Qiao, Yuepei Li, Qing Wang, Kang Zhou, Qi Li

Knowledge graph completion (KGC) is a task of inferring missing triples based
on existing Knowledge Graphs (KGs). Both structural and semantic information
are vital for successful KGC. However, existing methods only use either the
structural knowledge from the KG embeddings or the semantic information from
pre-trained language models (PLMs), leading to suboptimal model performance.
Moreover, since PLMs are not trained on KGs, directly using PLMs to encode
triples may be inappropriate. To overcome these limitations, we propose a novel
framework called Bridge, which jointly encodes structural and semantic
information of KGs. Specifically, we strategically encode entities and
relations separately by PLMs to better utilize the semantic knowledge of PLMs
and enable structured representation learning via a structural learning
principle. Furthermore, to bridge the gap between KGs and PLMs, we employ a
self-supervised representation learning method called BYOL to fine-tune PLMs
with two different views of a triple. Unlike BYOL, which uses augmentation
methods to create two semantically similar views of the same image, potentially
altering the semantic information. We strategically separate the triple into
two parts to create different views, thus avoiding semantic alteration.
Experiments demonstrate that Bridge outperforms the SOTA models on three
benchmark datasets.

æè¦ï¼ç¥è­åè­è£å¨ (KGC) æ¯ä¸é æ ¹æç¾æç¥è­åè­ (KG) æ¨è«éºå¤±ä¸åçµçä»»åãçµæ§åèªç¾©è³è¨å°æ¼æåç KGC è³ééè¦ãç¶èï¼ç¾ææ¹æ³åä½¿ç¨ä¾èª KG åµå¥ççµæ§ç¥è­æä¾èªé è¨ç·´èªè¨æ¨¡å (PLM) çèªç¾©è³è¨ï¼å°è´æ¨¡åæè½ä¸ä½³ãæ­¤å¤ï¼ç±æ¼ PLM æ²æå¨ KG ä¸è¨ç·´ï¼å æ­¤ç´æ¥ä½¿ç¨ PLM ç·¨ç¢¼ä¸åçµå¯è½ä¸¦ä¸é©ç¶ãçºäºåæéäºéå¶ï¼æåæåºä¸ååçº Bridge çæ°æ¶æ§ï¼è©²æ¶æ§è¯åç·¨ç¢¼ KG ççµæ§åèªç¾©è³è¨ãå·é«ä¾èªªï¼æåéé PLM åå¥å°å¯¦é«åéä¿é²è¡ç­ç¥æ§ç·¨ç¢¼ï¼ä»¥æ´å¥½å°å©ç¨ PLM çèªç¾©ç¥è­ï¼ä¸¦ééçµæ§å­¸ç¿åååç¨çµæ§åè¡¨ç¤ºå­¸ç¿ãæ­¤å¤ï¼çºäºå½å KG å PLM ä¹éçå·®è·ï¼æåæ¡ç¨ä¸ç¨®ç¨±çº BYOL çèªç£ç£è¡¨ç¤ºå­¸ç¿æ¹æ³ï¼ä»¥ä¸åçµçå©åä¸åè¦åå¾®èª¿ PLMãè BYOL ä¸åï¼BYOL ä½¿ç¨æ´åæ¹æ³ä¾å»ºç«å©åèªç¾©ä¸ç¸ä¼¼çç¸åå½±åè¦åï¼å¯è½ææ¹è®èªç¾©è³è¨ãæåç­ç¥æ§å°å°ä¸åçµåçºå©é¨åä»¥å»ºç«ä¸åçè¦åï¼å¾èé¿åèªç¾©æ¹è®ãå¯¦é©è­æ Bridge å¨ä¸ååºæºè³æéä¸åªæ¼ SOTA æ¨¡åã

##### **An Efficient Memory Module for Graph Few-Shot Class-Incremental Learning**
2411.06659v1 by Dong Li, Aijia Zhang, Junqi Gao, Biqing Qi

Incremental graph learning has gained significant attention for its ability
to address the catastrophic forgetting problem in graph representation
learning. However, traditional methods often rely on a large number of labels
for node classification, which is impractical in real-world applications. This
makes few-shot incremental learning on graphs a pressing need. Current methods
typically require extensive training samples from meta-learning to build memory
and perform intensive fine-tuning of GNN parameters, leading to high memory
consumption and potential loss of previously learned knowledge. To tackle these
challenges, we introduce Mecoin, an efficient method for building and
maintaining memory. Mecoin employs Structured Memory Units to cache prototypes
of learned categories, as well as Memory Construction Modules to update these
prototypes for new categories through interactions between the nodes and the
cached prototypes. Additionally, we have designed a Memory Representation
Adaptation Module to store probabilities associated with each class prototype,
reducing the need for parameter fine-tuning and lowering the forgetting rate.
When a sample matches its corresponding class prototype, the relevant
probabilities are retrieved from the MRaM. Knowledge is then distilled back
into the GNN through a Graph Knowledge Distillation Module, preserving the
model's memory. We analyze the effectiveness of Mecoin in terms of
generalization error and explore the impact of different distillation
strategies on model performance through experiments and VC-dimension analysis.
Compared to other related works, Mecoin shows superior performance in accuracy
and forgetting rate. Our code is publicly available on the
https://github.com/Arvin0313/Mecoin-GFSCIL.git .

æè¦ï¼å¢éåå½¢å­¸ç¿å å¶è§£æ±ºåå½¢è¡¨å¾µå­¸ç¿ä¸­ç½é£æ§éºå¿åé¡çè½åèååéæ³¨ãç¶èï¼å³çµ±æ¹æ³éå¸¸ä¾è³´å¤§éæ¨ç±¤é²è¡ç¯é»åé¡ï¼éå¨å¯¦éæç¨ä¸­æ¯ä¸åå¯¦éçãéä½¿å¾åå½¢ä¸çå°æ¨£æ¬å¢éå­¸ç¿æçºè¿«åéæ±ãç®åçæè¡éå¸¸éè¦ä¾èªåå­¸ç¿çå¤§éè¨ç·´æ¨£æ¬ä¾å»ºç«è¨æ¶ä¸¦å° GNN åæ¸é²è¡å¯éçå¾®èª¿ï¼å¾èå°è´é«è¨æ¶é«æ¶èåååå­¸ç¿ç¥è­çæ½å¨æå¤±ãçºäºæå°éäºææ°ï¼æåå¼å¥äº Mecoinï¼ä¸ç¨®ç¨æ¼æ§å»ºåç¶­è­·è¨æ¶çæææ¹æ³ãMecoin ä½¿ç¨çµæ§åè¨æ¶å®åç·©å­å­¸ç¿é¡å¥çååï¼ä»¥åè¨æ¶é«å»ºæ§æ¨¡çµééç¯é»åç·©å­ååä¹éçäºåä¾æ´æ°éäºæ°é¡å¥çååãæ­¤å¤ï¼æåè¨­è¨äºä¸åè¨æ¶é«è¡¨å¾µé©ææ¨¡çµä¾å²å­èæ¯åé¡å¥ååç¸éçæ©çï¼æ¸å°äºå°åæ¸å¾®èª¿çéæ±ä¸¦éä½äºéºå¿çãç¶æ¨£æ¬èå¶å°æçé¡å¥ååå¹éæï¼ç¸éæ©çæå¾ MRaM ä¸­æ·åãç¶å¾ééåå½¢ç¥è­è¸é¤¾æ¨¡çµå°ç¥è­è¸é¤¾å GNNï¼ä¿çæ¨¡åçè¨æ¶é«ãæååæäº Mecoin å¨æ³åèª¤å·®æ¹é¢çæææ§ï¼ä¸¦ééå¯¦é©å VC ç¶­åº¦åææ¢è¨äºä¸åè¸é¤¾ç­ç¥å°æ¨¡åæè½çå½±é¿ãèå¶ä»ç¸éå·¥ä½ç¸æ¯ï¼Mecoin å¨æºç¢ºåº¦åéºå¿çæ¹é¢è¡¨ç¾åºåªç°çæè½ãæåçç¨å¼ç¢¼å¯ä»¥å¨ https://github.com/Arvin0313/Mecoin-GFSCIL.git å¬éåå¾ã

##### **Renaissance: Investigating the Pretraining of Vision-Language Encoders**
2411.06657v1 by Clayton Fields, Casey Kennington

In the past several years there has been an explosion of available models for
vision-language tasks. Unfortunately, the literature still leaves open a number
of questions related to best practices in designing and training such models.
In this paper we seek to answer several questions related to the pretraining of
vision-language encoders through meta-analysis. In our first set of
experiments, we show that we can save significant compute at no cost to
downstream performance, by freezing large parts of vision-language models
during pretraining. In our second set of experiments we examine the effect of
basing a VL transformer on a vision model versus a text model. Additionally, we
introduce a VL modeling platform called Renaissance that we use to conduct all
of the experiments. This program offers a great deal of flexibility in
creating, training and evaluating transformer encoders for VL modeling. The
source code for Renaissance can be found at
https://github.com/bsu-slim/renaissance.

æè¦ï¼éå»å¹¾å¹´ä¾ï¼å¯ç¨æ¼è¦è¦ºèªè¨ä»»åçæ¨¡ååºç¾äºçç¸æ§çå¢é·ãä¸å¹¸çæ¯ï¼æç»ä¸­ä»æè¨±å¤èè¨­è¨åè¨ç·´æ­¤é¡æ¨¡åçæä½³å¯¦åç¸éçåé¡å°æªè§£æ±ºãå¨æ¬æä¸­ï¼æåå°æ±ééååæä¾åç­èè¦è¦ºèªè¨ç·¨ç¢¼å¨çé è¨ç·´ç¸éçå¹¾ååé¡ãå¨æåçé¦çµå¯¦é©ä¸­ï¼æåè¡¨æï¼ééå¨é è¨ç·´æéåçµè¦è¦ºèªè¨æ¨¡åçå¤§é¨åï¼æåå¯ä»¥å¨ä¸æå®³ä¸æ¸¸æè½çææ³ä¸ï¼ç¯çå¤§éçéç®ãå¨æåçç¬¬äºçµå¯¦é©ä¸­ï¼æåæª¢é©äºå° VL è½æå¨å»ºç«å¨è¦è¦ºæ¨¡åèæå­æ¨¡åä¸çææãæ­¤å¤ï¼æåå¼å¥äºç¨±çº Renaissance ç VL å»ºæ¨¡å¹³å°ï¼æåä½¿ç¨è©²å¹³å°ä¾é²è¡ææå¯¦é©ãæ­¤ç¨å¼å¨å»ºç«ãè¨ç·´åè©ä¼°ç¨æ¼ VL å»ºæ¨¡çè½æå¨ç·¨ç¢¼å¨æ¹é¢æä¾äºæ¥µå¤§çéæ´»æ§ãRenaissance çåå§ç¨å¼ç¢¼å¯ä»¥å¨ https://github.com/bsu-slim/renaissance æ¾å°ã

##### **Explore the Reasoning Capability of LLMs in the Chess Testbed**
2411.06655v1 by Shu Wang, Lei Ji, Renxi Wang, Wenxiao Zhao, Haokun Liu, Yifan Hou, Ying Nian Wu

Reasoning is a central capability of human intelligence. In recent years,
with the advent of large-scale datasets, pretrained large language models have
emerged with new capabilities, including reasoning. However, these models still
struggle with long-term, complex reasoning tasks, such as playing chess. Based
on the observation that expert chess players employ a dual approach combining
long-term strategic play with short-term tactical play along with language
explanation, we propose improving the reasoning capability of large language
models in chess by integrating annotated strategy and tactic. Specifically, we
collect a dataset named MATE, which consists of 1 million chess positions with
candidate moves annotated by chess experts for strategy and tactics. We
finetune the LLaMA-3-8B model and compare it against state-of-the-art
commercial language models in the task of selecting better chess moves. Our
experiments show that our models perform better than GPT, Claude, and Gemini
models. We find that language explanations can enhance the reasoning capability
of large language models.

æè¦ï¼æ¨çæ¯äººé¡æºè½çæ ¸å¿è½åãè¿å¹´ä¾ï¼é¨èå¤§è¦æ¨¡æ¸æéçåºç¾ï¼é è¨ç·´çå¤§èªè¨æ¨¡åå·²ç¶åºç¾äºæ°çè½åï¼åæ¬æ¨çãç¶èï¼éäºæ¨¡åä»ç¶é£ä»¥æä»é·æãè¤éçæ¨çä»»åï¼ä¾å¦ä¸æ£ãåºæ¼å°å®¶æ£ææ¡ç¨ééæ¹æ³çè§å¯ï¼å°é·ææ°ç¥åå¼èç­ææ°è¡åå¼çµåèªè¨èªªæï¼æåæåºééæ´åè¨»è§£ç­ç¥åæ°è¡ä¾æé«å¤§èªè¨æ¨¡åå¨åéè±¡æ£ä¸­çæ¨çè½åãå·é«ä¾èªªï¼æåæ¶éäºä¸ååçº MATE çæ¸æéï¼å¶ä¸­åå« 100 è¬ååéè±¡æ£ä½ç½®ï¼å¶ä¸­åé¸ç§»åç±åéè±¡æ£å°å®¶å°ç­ç¥åæ°è¡é²è¡äºè¨»éãæåå° LLaMA-3-8B æ¨¡åé²è¡äºå¾®èª¿ï¼ä¸¦å¨é¸ææ´å¥½çåéè±¡æ£èµ°æ³ä»»åä¸­å°å¶èæåé²çåæ¥­èªè¨æ¨¡åé²è¡äºæ¯è¼ãæåçå¯¦é©è¡¨æï¼æåçæ¨¡åæ¯ GPTãClaude å Gemini æ¨¡åè¡¨ç¾å¾æ´å¥½ãæåç¼ç¾èªè¨è§£éå¯ä»¥å¢å¼·å¤§èªè¨æ¨¡åçæ¨çè½åã

##### **Understanding Scaling Laws with Statistical and Approximation Theory for Transformer Neural Networks on Intrinsically Low-dimensional Data**
2411.06646v1 by Alex Havrilla, Wenjing Liao

When training deep neural networks, a model's generalization error is often
observed to follow a power scaling law dependent both on the model size and the
data size. Perhaps the best known example of such scaling laws are for
transformer-based large language models, where networks with billions of
parameters are trained on trillions of tokens of text. Yet, despite sustained
widespread interest, a rigorous understanding of why transformer scaling laws
exist is still missing. To answer this question, we establish novel statistical
estimation and mathematical approximation theories for transformers when the
input data are concentrated on a low-dimensional manifold. Our theory predicts
a power law between the generalization error and both the training data size
and the network size for transformers, where the power depends on the intrinsic
dimension $d$ of the training data. Notably, the constructed model architecture
is shallow, requiring only logarithmic depth in $d$. By leveraging
low-dimensional data structures under a manifold hypothesis, we are able to
explain transformer scaling laws in a way which respects the data geometry.
Moreover, we test our theory with empirical observation by training LLMs on
natural language datasets. We find the observed empirical data scaling laws
closely agree with our theoretical predictions. Taken together, these results
rigorously show the intrinsic dimension of data to be a crucial quantity
affecting transformer scaling laws in both theory and practice.

æè¦ï¼å¨è®­ç»æ·±åº¦ç¥ç»ç½ç»æ¶ï¼éå¸¸ä¼è§å¯å°æ¨¡åçæ³åè¯¯å·®éµå¾ªä¸ç§å¹æ¬¡ç¼©æ¾å®å¾ï¼è¯¥å®å¾åæ¶åå³äºæ¨¡åå¤§å°åæ°æ®å¤§å°ãè¿ç§ç¼©æ¾å®å¾æèåçä¾å­å¯è½æ¯åºäº Transformer çå¤§åè¯­è¨æ¨¡åï¼å¶ä¸­æ°åäº¿ä¸ªåæ°çç½ç»å¨æ°ä¸äº¿ä¸ªææ¬æ è®°ä¸è¿è¡è®­ç»ãç¶èï¼å°½ç®¡æç»­çå¹¿æ³å³æ³¨ï¼ä½å¯¹äº Transformer ç¼©æ¾å®å¾ä¸ºä½å­å¨ï¼ä»ç¶ç¼ºä¹ä¸¥æ ¼ççè§£ãä¸ºäºåç­è¿ä¸ªé®é¢ï¼æä»¬å¨è¾å¥æ°æ®éä¸­äºä½ç»´æµå½¢æ¶ï¼ä¸º Transformer å»ºç«äºæ°é¢çç»è®¡ä¼°è®¡åæ°å­¦é¼è¿çè®ºãæä»¬ççè®ºé¢æµäºæ³åè¯¯å·®ä¸è®­ç»æ°æ®å¤§å°å Transformer çç½ç»å¤§å°ä¹é´çå¹å¾ï¼å¶ä¸­å¹åå³äºè®­ç»æ°æ®çåå¨ç»´æ° $d$ãå¼å¾æ³¨æçæ¯ï¼æå»ºçæ¨¡åæ¶ææ¯æµå±çï¼åªéè¦ $d$ ä¸­çå¯¹æ°æ·±åº¦ãéè¿å©ç¨æµå½¢åè®¾ä¸çä½ç»´æ°æ®ç»æï¼æä»¬è½å¤ä»¥å°éæ°æ®å ä½çæ¹å¼æ¥è§£é Transformer ç¼©æ¾å®å¾ãæ­¤å¤ï¼æä»¬éè¿å¨èªç¶è¯­è¨æ°æ®éä¸è®­ç» LLM æ¥ç¨ç»éªè§å¯æ£éªæä»¬ççè®ºãæä»¬åç°è§å¯å°çç»éªæ°æ®ç¼©æ¾å®å¾ä¸æä»¬ççè®ºé¢æµéå¸¸å»åãç»¼ä¸æè¿°ï¼è¿äºç»æä¸¥æ ¼å°è¡¨æï¼æ°æ®çåå¨ç»´æ°æ¯å½±åçè®ºåå®è·µä¸­ Transformer ç¼©æ¾å®å¾çå³é®éã

##### **Predicting Country Instability Using Bayesian Deep Learning and Random Forest**
2411.06639v1 by Adam Zebrowski, Haithem Afli

Country instability is a global issue, with unpredictably high levels of
instability thwarting socio-economic growth and possibly causing a slew of
negative consequences. As a result, uncertainty prediction models for a country
are becoming increasingly important in the real world, and they are expanding
to provide more input from 'big data' collections, as well as the
interconnectedness of global economies and social networks. This has culminated
in massive volumes of qualitative data from outlets like television, print,
digital, and social media, necessitating the use of artificial intelligence
(AI) tools like machine learning to make sense of it all and promote predictive
precision [1]. The Global Database of Activities, Voice, and Tone (GDELT
Project) records broadcast, print, and web news in over 100 languages every
second of every day, identifying the people, locations, organisations, counts,
themes, outlets, and events that propel our global community and offering a
free open platform for computation on the entire world. The main goal of our
research is to investigate how, when our data grows more voluminous and
fine-grained, we can conduct a more complex methodological analysis of
political conflict. The GDELT dataset, which was released in 2012, is the first
and potentially the most technologically sophisticated publicly accessible
dataset on political conflict.

æè¦ï¼åå®¶ä¸ç©©å®æ¯ä¸åå¨çæ§çåé¡ï¼ä¸å¯é æ¸¬çé«ä¸ç©©å®æ§æ°´å¹³é»ç¤äºç¤¾æç¶æ¿çç¼å±ï¼ä¸¦å¯è½å°è´ä¸ç³»åçè² é¢å¾æãå æ­¤ï¼å°ä¸ååå®¶çä¸ç¢ºå®æ§é æ¸¬æ¨¡åå¨ç¾å¯¦ä¸çä¸­è®å¾è¶ä¾è¶éè¦ï¼ä¸¦ä¸å®åæ­£å¨æ´å±ä»¥æä¾ä¾èªãå¤§æ¸æãæ¶éçæ´å¤è¼¸å¥ï¼ä»¥åå¨çç¶æ¿åç¤¾äº¤ç¶²çµ¡çç¸äºè¯ç¹«ãéå¨é»è¦ãå°å·åãæ¸ä½åç¤¾äº¤åªé«ç­åªé«ä¸ç¢çäºå¤§éçå®æ§æ¸æï¼å æ­¤éè¦ä½¿ç¨äººå·¥æºæ§ (AI) å·¥å·ï¼ä¾å¦æ©å¨å­¸ç¿ï¼ä¾çè§£ææéäºæ¸æä¸¦ä¿é²é æ¸¬ç²¾æºåº¦ [1]ãå¨çæ´»åãèªé³åèªèª¿è³æåº« (GDELT è¨ç«) æ¯ç§è¨éè¶é 100 ç¨®èªè¨çå»£æ­ãå°å·åç¶²è·¯æ°èï¼è­å¥æ¨åæåå¨çç¤¾ç¾¤çäººå¡ãå°é»ãçµç¹ãè¨æ¸ãä¸»é¡ãåªé«åäºä»¶ï¼ä¸¦æä¾ä¸ååè²»éæ¾çå¹³å°ï¼ç¨æ¼è¨ç®æ´åä¸çãæåç ç©¶çä¸»è¦ç®æ¨æ¯èª¿æ¥ç¶æåçæ¸æè®å¾æ´é¾å¤§ä¸æ´ç²¾ç´°æï¼æåå¦ä½å°æ¿æ²»è¡çªé²è¡æ´è¤éçæ¹æ³è«åæãæ¼ 2012 å¹´ç¼å¸ç GDELT è³æéæ¯ç¬¬ä¸åï¼ä¹æ¯æ½å¨æè¡æåé²çéæ¼æ¿æ²»è¡çªçå¬éå­åè³æéã

##### **Model Editing for LLMs4Code: How Far are We?**
2411.06638v1 by Xiaopeng Li, Shangwen Wang, Shasha Li, Jun Ma, Jie Yu, Xiaodong Liu, Jing Wang, Bin Ji, Weimin Zhang

Large Language Models for Code (LLMs4Code) have been found to exhibit
outstanding performance in the software engineering domain, especially the
remarkable performance in coding tasks. However, even the most advanced
LLMs4Code can inevitably contain incorrect or outdated code knowledge. Due to
the high cost of training LLMs4Code, it is impractical to re-train the models
for fixing these problematic code knowledge. Model editing is a new technical
field for effectively and efficiently correcting erroneous knowledge in LLMs,
where various model editing techniques and benchmarks have been proposed
recently. Despite that, a comprehensive study that thoroughly compares and
analyzes the performance of the state-of-the-art model editing techniques for
adapting the knowledge within LLMs4Code across various code-related tasks is
notably absent. To bridge this gap, we perform the first systematic study on
applying state-of-the-art model editing approaches to repair the inaccuracy of
LLMs4Code. To that end, we introduce a benchmark named CLMEEval, which consists
of two datasets, i.e., CoNaLa-Edit (CNLE) with 21K+ code generation samples and
CodeSearchNet-Edit (CSNE) with 16K+ code summarization samples. With the help
of CLMEEval, we evaluate six advanced model editing techniques on three
LLMs4Code: CodeLlama (7B), CodeQwen1.5 (7B), and Stable-Code (3B). Our findings
include that the external memorization-based GRACE approach achieves the best
knowledge editing effectiveness and specificity (the editing does not influence
untargeted knowledge), while generalization (whether the editing can generalize
to other semantically-identical inputs) is a universal challenge for existing
techniques. Furthermore, building on in-depth case analysis, we introduce an
enhanced version of GRACE called A-GRACE, which incorporates contrastive
learning to better capture the semantics of the inputs.

æè¦ï¼<paragraph>å¤§åèªè¨æ¨¡åä»£ç¢¼ (LLMs4Code) å·²è¢«ç¼ç¾å¯å¨è»é«å·¥ç¨é åå±ç¾ååºçæè½ï¼ç¹å¥æ¯å¨ç·¨ç¢¼ä»»åä¸­è¡¨ç¾åºè²ãç¶èï¼å³ä½¿æ¯æåé²ç LLMs4Code ä¹é£ååå«ä¸æ­£ç¢ºæéæçç¨å¼ç¢¼ç¥è­ãç±æ¼è¨ç·´ LLMs4Code çææ¬å¾é«ï¼å æ­¤ä¸åå¯¦éå°éæ°è¨ç·´æ¨¡åä¾ä¿®æ­£éäºæåé¡çç¨å¼ç¢¼ç¥è­ãæ¨¡åç·¨è¼¯æ¯ä¸åæ°çæè¡é åï¼ç¨æ¼ææä¸é«æå°ä¿®æ­£å¤§åèªè¨æ¨¡åä¸­çé¯èª¤ç¥è­ï¼æè¿å·²æåºåç¨®æ¨¡åç·¨è¼¯æè¡ååºæºãåç®¡å¦æ­¤ï¼ä¸åå¨é¢ç ç©¶ï¼å¾¹åºæ¯è¼ååææåé²çæ¨¡åç·¨è¼¯æè¡å¨åç¨®èç¨å¼ç¢¼ç¸éä»»åä¸­èª¿æ´ LLMs4Code å§é¨ç¥è­çæè½ï¼é¡¯èå°ä¸å­å¨ãçºäºå½åéåå·®è·ï¼æåå°æç¨æåé²çæ¨¡åç·¨è¼¯æ¹æ³ä¾ä¿®å¾© LLMs4Code çä¸æºç¢ºæ§é²è¡äºç¬¬ä¸åç³»çµ±æ§ç ç©¶ãçºæ­¤ï¼æåå¼å¥äºä¸ååçº CLMEEval çåºæºï¼å®åå«å©åè³æéï¼å³åå« 21K+ ç¨å¼ç¢¼çæç¯ä¾ç CoNaLa-Edit (CNLE) ååå« 16K+ ç¨å¼ç¢¼æè¦ç¯ä¾ç CodeSearchNet-Edit (CSNE)ãå¨ CLMEEval çå¹«å©ä¸ï¼æåè©ä¼°äºå­ç¨®åé²çæ¨¡åç·¨è¼¯æè¡å¨ä¸å LLMs4Code ä¸çè¡¨ç¾ï¼CodeLlama (7B)ãCodeQwen1.5 (7B) å Stable-Code (3B)ãæåçç¼ç¾åæ¬åºæ¼å¤é¨è¨æ¶ç GRACE æ¹æ³å¯¦ç¾äºæä½³çç¥è­ç·¨è¼¯æè½åç¹ç°æ§ï¼ç·¨è¼¯ä¸æå½±é¿æªéå®çç¥è­ï¼ï¼èæ³åï¼ç·¨è¼¯æ¯å¦å¯ä»¥æ³åå°å¶ä»èªç¾©ç¸åçè¼¸å¥ï¼æ¯ç¾ææè¡çæ®éææ°ãæ­¤å¤ï¼å¨æ·±å¥æ¡ä¾åæçåºç¤ä¸ï¼æåå¼å¥äº GRACE çå¢å¼·çæ¬ï¼ç¨±çº A-GRACEï¼å®çµåäºå°æ¯å­¸ç¿ä»¥æ´å¥½å°ææè¼¸å¥çèªç¾©ã</paragraph>

##### **A Review of Fairness and A Practical Guide to Selecting Context-Appropriate Fairness Metrics in Machine Learning**
2411.06624v1 by Caleb J. S. Barr, Olivia Erdelyi, Paul D. Docherty, Randolph C. Grace

Recent regulatory proposals for artificial intelligence emphasize fairness
requirements for machine learning models. However, precisely defining the
appropriate measure of fairness is challenging due to philosophical, cultural
and political contexts. Biases can infiltrate machine learning models in
complex ways depending on the model's context, rendering a single common metric
of fairness insufficient. This ambiguity highlights the need for criteria to
guide the selection of context-aware measures, an issue of increasing
importance given the proliferation of ever tighter regulatory requirements. To
address this, we developed a flowchart to guide the selection of contextually
appropriate fairness measures. Twelve criteria were used to formulate the
flowchart. This included consideration of model assessment criteria, model
selection criteria, and data bias. We also review fairness literature in the
context of machine learning and link it to core regulatory instruments to
assist policymakers, AI developers, researchers, and other stakeholders in
appropriately addressing fairness concerns and complying with relevant
regulatory requirements.

æè¦ï¼è¿æéå°äººå·¥æºæ§çç£ç®¡ææ¡å¼·èª¿æ©å¨å­¸ç¿æ¨¡åçå¬å¹³æ§è¦æ±ãç¶èï¼ç±æ¼å²å­¸ãæååæ¿æ²»èçµ¡ï¼ç²¾ç¢ºå®ç¾©å¬å¹³æ§çé©ç¶è¡¡éæ¨æºæ¯ä¸é ææ°ãåè¦æä»¥è¤éçæ¹å¼æ»²éå°æ©å¨å­¸ç¿æ¨¡åä¸­ï¼å·é«åæ±ºæ¼æ¨¡åçèçµ¡ï¼å°è´å®ä¸çå¬å¹³æ§éç¨ææ¨ä¸è¶³ãéç¨®æ¨¡ç¨å©å¯çªé¡¯äºéè¦æºåä¾å¼å°æå¢æç¥ææ¨çé¸æï¼éæ¯ä¸åè¶ä¾è¶éè¦çåé¡ï¼å çºç£ç®¡è¦æ±è¶ä¾è¶å´æ ¼ãçºäºè§£æ±ºéååé¡ï¼æåéç¼äºä¸åæµç¨åä¾æå°æå¢é©ç¶çå¬å¹³æ§ææ¨çé¸æãåäºåæºåç¨æ¼å¶å®æµç¨åãéåæ¬èéæ¨¡åè©ä¼°æºåãæ¨¡åé¸ææºååè³æåèª¤ãæåéåé¡§äºæ©å¨å­¸ç¿ä¸­çå¬å¹³æ§æç»ï¼ä¸¦å°å¶é£çµå°æ ¸å¿ç£ç®¡å·¥å·ï¼ä»¥åå©æ¿ç­å¶å®èãäººå·¥æºæ§éç¼äººå¡ãç ç©¶äººå¡åå¶ä»å©å®³éä¿äººé©ç¶å°è§£æ±ºå¬å¹³æ§åé¡ä¸¦éµå®ç¸éç£ç®¡è¦æ±ã

##### **MEANT: Multimodal Encoder for Antecedent Information**
2411.06616v1 by Benjamin Iyoya Irving, Annika Marie Schoene

The stock market provides a rich well of information that can be split across
modalities, making it an ideal candidate for multimodal evaluation. Multimodal
data plays an increasingly important role in the development of machine
learning and has shown to positively impact performance. But information can do
more than exist across modes -- it can exist across time. How should we attend
to temporal data that consists of multiple information types? This work
introduces (i) the MEANT model, a Multimodal Encoder for Antecedent information
and (ii) a new dataset called TempStock, which consists of price, Tweets, and
graphical data with over a million Tweets from all of the companies in the S&P
500 Index. We find that MEANT improves performance on existing baselines by
over 15%, and that the textual information affects performance far more than
the visual information on our time-dependent task from our ablation study.

æè¦ï¼è¡ç¥¨å¸å ´æä¾äºè±å¯çä¿¡æ¯ä¾æºï¼å¯ä»¥è·¨æ¨¡æåå²ï¼ä½¿å¶æçºå¤æ¨¡æè©ä¼°ççæ³åé¸èãå¤æ¨¡ææ¸æå¨æ©å¨å­¸ç¿çç¼å±ä¸­æ®æ¼èè¶ä¾è¶éè¦çè§è²ï¼ä¸¦å·²é¡¯ç¤ºåºå°æ§è½çæ­£é¢å½±é¿ãä½ä¿¡æ¯ä¸åå¯ä»¥è·¨æ¨¡å¼å­å¨ï¼å®ä¹å¯ä»¥è·¨æéå­å¨ãæåæè©²å¦ä½éæ³¨åå«å¤ç¨®ä¿¡æ¯é¡åçæéæ¸æï¼éé å·¥ä½å¼å¥äº (i) MEANT æ¨¡åï¼ä¸ç¨®ç¨æ¼åè¡ä¿¡æ¯çå¤æ¨¡æç·¨ç¢¼å¨ï¼ä»¥å (ii) ä¸ååçº TempStock çæ°æ¸æéï¼å¶ä¸­åå«ä¾èªæ¨æºæ®ç¾ 500 ææ¸ä¸­ææå¬å¸çå¹æ ¼ãæ¨æååå½¢æ¸æï¼æ¨ææ¸éè¶éä¸ç¾è¬æ¢ãæåç¼ç¾ MEANT å°ç¾æåºæºçæ§è½æé«äº 15% ä»¥ä¸ï¼ä¸¦ä¸å¨æåçæ¶èç ç©¶ä¸­ï¼ææ¬ä¿¡æ¯å°æåä¾æéèå®çä»»åçå½±é¿é å¤§æ¼è¦è¦ºä¿¡æ¯ã

##### **vTune: Verifiable Fine-Tuning for LLMs Through Backdooring**
2411.06611v1 by Eva Zhang, Arka Pal, Akilesh Potti, Micah Goldblum

As fine-tuning large language models (LLMs) becomes increasingly prevalent,
users often rely on third-party services with limited visibility into their
fine-tuning processes. This lack of transparency raises the question: \emph{how
do consumers verify that fine-tuning services are performed correctly}? For
instance, a service provider could claim to fine-tune a model for each user,
yet simply send all users back the same base model. To address this issue, we
propose vTune, a simple method that uses a small number of \textit{backdoor}
data points added to the training data to provide a statistical test for
verifying that a provider fine-tuned a custom model on a particular user's
dataset. Unlike existing works, vTune is able to scale to verification of
fine-tuning on state-of-the-art LLMs, and can be used both with open-source and
closed-source models. We test our approach across several model families and
sizes as well as across multiple instruction-tuning datasets, and find that the
statistical test is satisfied with p-values on the order of $\sim 10^{-40}$,
with no negative impact on downstream task performance. Further, we explore
several attacks that attempt to subvert vTune and demonstrate the method's
robustness to these attacks.

æè¦ï¼éçå¯¹å¤§åè¯­è¨æ¨¡å (LLM) çå¾®è°åå¾è¶æ¥è¶æ®éï¼
ç¨æ·éå¸¸ä¾èµäºç¬¬ä¸æ¹æå¡ï¼èè¿äºæå¡å¯¹å¶å¾®è°è¿ç¨çå¯è§æ§æéãè¿ç§ç¼ºä¹éæåº¦å¼åäºä¸ä¸ªé®é¢ï¼\emph{æ¶è´¹èå¦ä½éªè¯å¾®è°æå¡æ¯å¦æ­£ç¡®æ§è¡}ï¼ä¾å¦ï¼æå¡æä¾åå¯ä»¥å£°ç§°éå¯¹æ¯ä¸ªç¨æ·å¾®è°æ¨¡åï¼ä½å®éä¸åªæ¯åææç¨æ·åéåç¸åçåºå±æ¨¡åãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬æåºäº vTuneï¼è¿æ¯ä¸ç§ç®åçæ¹æ³ï¼å®ä½¿ç¨æ·»å å°è®­ç»æ°æ®ä¸­çå°é\textit{åé¨}æ°æ®ç¹ï¼ä»¥æä¾ä¸ä¸ªç»è®¡æµè¯ï¼ç¨äºéªè¯æä¾åæ¯å¦éå¯¹ç¹å®ç¨æ·çè®­ç»æ°æ®éå¾®è°äºèªå®ä¹æ¨¡åãä¸ç°æå·¥ä½ä¸åï¼vTune è½å¤æ©å±å°å¯¹æåè¿ç LLM è¿è¡å¾®è°éªè¯ï¼å¹¶ä¸å¯ä»¥ä¸å¼æºåé­æºæ¨¡åä¸èµ·ä½¿ç¨ãæä»¬å¨å¤ä¸ªæ¨¡åç³»ååè§æ¨¡ä»¥åå¤ä¸ªæä»¤å¾®è°æ°æ®éä¸æµè¯äºæä»¬çæ¹æ³ï¼åç°ç»è®¡æµè¯æ»¡è¶³ p å¼çº¦ä¸º $\sim 10^{-40}$ï¼å¯¹ä¸æ¸¸ä»»å¡æ§è½æ²¡æè´é¢å½±åãæ­¤å¤ï¼æä»¬æ¢ç´¢äºå ç§è¯å¾ç ´å vTune çæ»å»ï¼å¹¶è¯æäºè¯¥æ¹æ³å¯¹è¿äºæ»å»çé²æ£æ§ã

