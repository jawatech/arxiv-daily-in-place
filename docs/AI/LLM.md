
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-05-21**|**Reducing Transformer Key-Value Cache Size with Cross-Layer Attention**|William Brandon et.al.|[2405.12981v1](http://arxiv.org/abs/2405.12981v1)|null|
|**2024-05-21**|**Energy Rank Alignment: Using Preference Optimization to Search Chemical Space at Scale**|Shriram Chennakesavalu et.al.|[2405.12961v1](http://arxiv.org/abs/2405.12961v1)|null|
|**2024-05-21**|**Strategic Deployment of Honeypots in Blockchain-based IoT Systems**|Daniel Commey et.al.|[2405.12951v1](http://arxiv.org/abs/2405.12951v1)|null|
|**2024-05-21**|**Aggregation of Reasoning: A Hierarchical Framework for Enhancing Answer Selection in Large Language Models**|Zhangyue Yin et.al.|[2405.12939v1](http://arxiv.org/abs/2405.12939v1)|null|
|**2024-05-21**|**Skin-in-the-Game: Decision Making via Multi-Stakeholder Alignment in LLMs**|Bilgehan Sel et.al.|[2405.12933v1](http://arxiv.org/abs/2405.12933v1)|null|
|**2024-05-21**|**Code-mixed Sentiment and Hate-speech Prediction**|Anjali Yadav et.al.|[2405.12929v1](http://arxiv.org/abs/2405.12929v1)|null|
|**2024-05-21**|**Panmodal Information Interaction**|Chirag Shah et.al.|[2405.12923v1](http://arxiv.org/abs/2405.12923v1)|null|
|**2024-05-21**|**G-DIG: Towards Gradient-based DIverse and hiGh-quality Instruction Data Selection for Machine Translation**|Xingyuan Pan et.al.|[2405.12915v1](http://arxiv.org/abs/2405.12915v1)|null|
|**2024-05-21**|**Topic Modelling Case Law Using a Large Language Model and a New Taxonomy for UK Law: AI Insights into Summary Judgment**|Holli Sargeant et.al.|[2405.12910v1](http://arxiv.org/abs/2405.12910v1)|null|
|**2024-05-21**|**Adversarial DPO: Harnessing Harmful Data for Reducing Toxicity with Minimal Impact on Coherence and Evasiveness in Dialogue Agents**|San Kim et.al.|[2405.12900v1](http://arxiv.org/abs/2405.12900v1)|null|
|**2024-05-21**|**Investigating Persuasion Techniques in Arabic: An Empirical Study Leveraging Large Language Models**|Abdurahmman Alzahrani et.al.|[2405.12884v1](http://arxiv.org/abs/2405.12884v1)|null|
|**2024-05-21**|**Diffusion-RSCC: Diffusion Probabilistic Model for Change Captioning in Remote Sensing Images**|Xiaofei Yu et.al.|[2405.12875v1](http://arxiv.org/abs/2405.12875v1)|[link](https://github.com/fay-y/diffusion-rscc)|
|**2024-05-21**|**Equivariant Spatio-Temporal Attentive Graph Networks to Simulate Physical Dynamics**|Liming Wu et.al.|[2405.12868v1](http://arxiv.org/abs/2405.12868v1)|null|
|**2024-05-21**|**LLM Processes: Numerical Predictive Distributions Conditioned on Natural Language**|James Requeima et.al.|[2405.12856v1](http://arxiv.org/abs/2405.12856v1)|null|
|**2024-05-21**|**Training and inference in the ReckON RSNN architecture implemented on a MPSoC**|Alejandro Linares-Barranco et.al.|[2405.12849v1](http://arxiv.org/abs/2405.12849v1)|null|
|**2024-05-21**|**Large Language Models Meet NLP: A Survey**|Libo Qin et.al.|[2405.12819v1](http://arxiv.org/abs/2405.12819v1)|null|
|**2024-05-21**|**FAdam: Adam is a natural gradient optimizer using diagonal empirical Fisher information**|Dongseong Hwang et.al.|[2405.12807v1](http://arxiv.org/abs/2405.12807v1)|null|
|**2024-05-21**|**What Have We Achieved on Non-autoregressive Translation?**|Yafu Li et.al.|[2405.12788v1](http://arxiv.org/abs/2405.12788v1)|null|
|**2024-05-21**|**Transformer in Touch: A Survey**|Jing Gao et.al.|[2405.12779v1](http://arxiv.org/abs/2405.12779v1)|null|
|**2024-05-21**|**Unsupervised Multimodal Clustering for Semantics Discovery in Multimodal Utterances**|Hanlei Zhang et.al.|[2405.12775v1](http://arxiv.org/abs/2405.12775v1)|null|
|**2024-05-21**|**Progress Measures for Grokking on Real-world Datasets**|Satvik Golechha et.al.|[2405.12755v1](http://arxiv.org/abs/2405.12755v1)|null|
|**2024-05-21**|**Neural Operator for Accelerating Coronal Magnetic Field Model**|Yutao Du et.al.|[2405.12754v1](http://arxiv.org/abs/2405.12754v1)|null|
|**2024-05-21**|**Generative AI and Large Language Models for Cyber Security: All Insights You Need**|Mohamed Amine Ferrag et.al.|[2405.12750v1](http://arxiv.org/abs/2405.12750v1)|null|
|**2024-05-21**|**The Echoes of Multilinguality: Tracing Cultural Value Shifts during LM Fine-tuning**|Rochelle Choenni et.al.|[2405.12744v1](http://arxiv.org/abs/2405.12744v1)|null|
|**2024-05-21**|**RecGPT: Generative Pre-training for Text-based Recommendation**|Hoang Ngo et.al.|[2405.12715v1](http://arxiv.org/abs/2405.12715v1)|null|
|**2024-05-21**|**From Human-to-Human to Human-to-Bot Conversations in Software Engineering**|Ranim Khojah et.al.|[2405.12712v1](http://arxiv.org/abs/2405.12712v1)|null|
|**2024-05-21**|**A Masked Semi-Supervised Learning Approach for Otago Micro Labels Recognition**|Meng Shang et.al.|[2405.12711v1](http://arxiv.org/abs/2405.12711v1)|null|
|**2024-05-21**|**Multimodal Adaptive Inference for Document Image Classification with Anytime Early Exiting**|Omar Hamed et.al.|[2405.12705v1](http://arxiv.org/abs/2405.12705v1)|null|
|**2024-05-21**|**OLAPH: Improving Factuality in Biomedical Long-form Question Answering**|Minbyul Jeong et.al.|[2405.12701v1](http://arxiv.org/abs/2405.12701v1)|[link](https://github.com/dmis-lab/olaph)|
|**2024-05-21**|**Spotting AI's Touch: Identifying LLM-Paraphrased Spans in Text**|Yafu Li et.al.|[2405.12689v1](http://arxiv.org/abs/2405.12689v1)|null|
|**2024-05-21**|**A Survey on Multi-modal Machine Translation: Tasks, Methods and Challenges**|Huangjun Shen et.al.|[2405.12669v1](http://arxiv.org/abs/2405.12669v1)|null|
|**2024-05-21**|**Mitigating Overconfidence in Out-of-Distribution Detection by Capturing Extreme Activations**|Mohammad Azizmalayeri et.al.|[2405.12658v1](http://arxiv.org/abs/2405.12658v1)|null|
|**2024-05-21**|**Retrieval-Augmented Language Model for Extreme Multi-Label Knowledge Graph Link Prediction**|Yu-Hsiang Lin et.al.|[2405.12656v1](http://arxiv.org/abs/2405.12656v1)|[link](https://github.com/exiled1143/retrieval-augmented-language-model-for-multi-label-knowledge-graph-link-prediction)|
|**2024-05-21**|**Scene Graph Generation Strategy with Co-occurrence Knowledge and Learnable Term Frequency**|Hyeongjin Kim et.al.|[2405.12648v1](http://arxiv.org/abs/2405.12648v1)|null|
|**2024-05-21**|**Exploration of Masked and Causal Language Modelling for Text Generation**|Nicolo Micheletti et.al.|[2405.12630v1](http://arxiv.org/abs/2405.12630v1)|null|
|**2024-05-21**|**Limits of Theory of Mind Modelling in Dialogue-Based Collaborative Plan Acquisition**|Matteo Bortoletto et.al.|[2405.12621v1](http://arxiv.org/abs/2405.12621v1)|null|
|**2024-05-21**|**Quantifying Emergence in Large Language Models**|Hang Chen et.al.|[2405.12617v1](http://arxiv.org/abs/2405.12617v1)|[link](https://github.com/zodiark-ch/emergence-of-llms)|
|**2024-05-21**|**Tagengo: A Multilingual Chat Dataset**|Peter Devine et.al.|[2405.12612v1](http://arxiv.org/abs/2405.12612v1)|null|
|**2024-05-21**|**Tiny Refinements Elicit Resilience: Toward Efficient Prefix-Model Against LLM Red-Teaming**|Jiaxu Liu et.al.|[2405.12604v1](http://arxiv.org/abs/2405.12604v1)|null|
|**2024-05-21**|**Unlocking Data-free Low-bit Quantization with Matrix Decomposition for KV Cache Compression**|Peiyu Liu et.al.|[2405.12591v1](http://arxiv.org/abs/2405.12591v1)|null|
|**2024-05-21**|**Mining the Explainability and Generalization: Fact Verification Based on Self-Instruction**|Guangyao Lu et.al.|[2405.12579v1](http://arxiv.org/abs/2405.12579v1)|null|
|**2024-05-21**|**ProtT3: Protein-to-Text Generation for Text-based Protein Understanding**|Zhiyuan Liu et.al.|[2405.12564v1](http://arxiv.org/abs/2405.12564v1)|[link](https://github.com/acharkq/prott3)|
|**2024-05-21**|**DrHouse: An LLM-empowered Diagnostic Reasoning System through Harnessing Outcomes from Sensor Data and Expert Knowledge**|Bufang Yang et.al.|[2405.12541v1](http://arxiv.org/abs/2405.12541v1)|null|
|**2024-05-21**|**PyramidInfer: Pyramid KV Cache Compression for High-throughput LLM Inference**|Dongjie Yang et.al.|[2405.12532v1](http://arxiv.org/abs/2405.12532v1)|null|
|**2024-05-21**|**SirLLM: Streaming Infinite Retentive LLM**|Yao Yao et.al.|[2405.12528v1](http://arxiv.org/abs/2405.12528v1)|[link](https://github.com/zoeyyao27/sirllm)|
|**2024-05-21**|**Single Image Unlearning: Efficient Machine Unlearning in Multimodal Large Language Models**|Jiaqi Li et.al.|[2405.12523v1](http://arxiv.org/abs/2405.12523v1)|null|
|**2024-05-21**|**Sparse Autoencoders Enable Scalable and Reliable Circuit Identification in Language Models**|Charles O'Neill et.al.|[2405.12522v1](http://arxiv.org/abs/2405.12522v1)|null|
|**2024-05-21**|**MAGE: Model-Level Graph Neural Networks Explanations via Motif-based Graph Generation**|Zhaoning Yu et.al.|[2405.12519v1](http://arxiv.org/abs/2405.12519v1)|null|
|**2024-05-21**|**EntropyStop: Unsupervised Deep Outlier Detection with Loss Entropy**|Yihong Huang et.al.|[2405.12502v1](http://arxiv.org/abs/2405.12502v1)|null|
|**2024-05-21**|**Exploring and Exploiting the Asymmetric Valley of Deep Neural Networks**|Xin-Chun Li et.al.|[2405.12489v1](http://arxiv.org/abs/2405.12489v1)|null|
|**2024-05-21**|**Time Matters: Enhancing Pre-trained News Recommendation Models with Robust User Dwell Time Injection**|Hao Jiang et.al.|[2405.12486v1](http://arxiv.org/abs/2405.12486v1)|null|
|**2024-05-21**|**GASE: Graph Attention Sampling with Edges Fusion for Solving Vehicle Routing Problems**|Zhenwei Wang et.al.|[2405.12475v1](http://arxiv.org/abs/2405.12475v1)|null|
|**2024-05-21**|**Learning Partially Aligned Item Representation for Cross-Domain Sequential Recommendation**|Mingjia Yin et.al.|[2405.12473v1](http://arxiv.org/abs/2405.12473v1)|null|
|**2024-05-21**|**Leveraging Diverse Data Generation for Adaptable Zero-Shot Dialogue State Tracking**|James D. Finch et.al.|[2405.12468v1](http://arxiv.org/abs/2405.12468v1)|null|
|**2024-05-21**|**Stochastic Learning of Computational Resource Usage as Graph Structured Multimarginal Schrödinger Bridge**|Georgiy A. Bondar et.al.|[2405.12463v1](http://arxiv.org/abs/2405.12463v1)|null|
|**2024-05-21**|**Boosting X-formers with Structured Matrix for Long Sequence Time Series Forecasting**|Zhicheng Zhang et.al.|[2405.12462v1](http://arxiv.org/abs/2405.12462v1)|null|
|**2024-05-21**|**WorldAfford: Affordance Grounding based on Natural Language Instructions**|Changmao Chen et.al.|[2405.12461v1](http://arxiv.org/abs/2405.12461v1)|null|
|**2024-05-21**|**PathOCL: Path-Based Prompt Augmentation for OCL Generation with GPT-4**|Seif Abukhalaf et.al.|[2405.12450v1](http://arxiv.org/abs/2405.12450v1)|null|
|**2024-05-21**|**Learning Structure and Knowledge Aware Representation with Large Language Models for Concept Recommendation**|Qingyao Li et.al.|[2405.12442v1](http://arxiv.org/abs/2405.12442v1)|null|
|**2024-05-21**|**CoCo Matrix: Taxonomy of Cognitive Contributions in Co-writing with Intelligent Agents**|Ruyuan Wan et.al.|[2405.12438v1](http://arxiv.org/abs/2405.12438v1)|null|
|**2024-05-21**|**Resolving Word Vagueness with Scenario-guided Adapter for Natural Language Inference**|Yonghao Liu et.al.|[2405.12434v1](http://arxiv.org/abs/2405.12434v1)|null|
|**2024-05-21**|**LLM+Reasoning+Planning for supporting incomplete user queries in presence of APIs**|Sudhir Agarwal et.al.|[2405.12433v1](http://arxiv.org/abs/2405.12433v1)|null|
|**2024-05-20**|**A Unified Linear Programming Framework for Offline Reward Learning from Human Demonstrations and Feedback**|Kihyun Kim et.al.|[2405.12421v1](http://arxiv.org/abs/2405.12421v1)|null|
|**2024-05-20**|**Targeted Multilingual Adaptation for Low-resource Language Families**|C. M. Downey et.al.|[2405.12413v1](http://arxiv.org/abs/2405.12413v1)|null|
|**2024-05-20**|**Diffusion for World Modeling: Visual Details Matter in Atari**|Eloi Alonso et.al.|[2405.12399v1](http://arxiv.org/abs/2405.12399v1)|[link](https://github.com/eloialonso/diamond)|
|**2024-05-20**|**Layout Agnostic Human Activity Recognition in Smart Homes through Textual Descriptions Of Sensor Triggers (TDOST)**|Megha Thukral et.al.|[2405.12368v1](http://arxiv.org/abs/2405.12368v1)|null|
|**2024-05-20**|**Question-Based Retrieval using Atomic Units for Enterprise RAG**|Vatsal Raina et.al.|[2405.12363v1](http://arxiv.org/abs/2405.12363v1)|null|
|**2024-05-20**|**Perturbing the Gradient for Alleviating Meta Overfitting**|Manas Gogoi et.al.|[2405.12299v1](http://arxiv.org/abs/2405.12299v1)|null|
|**2024-05-20**|**Adapting Large Multimodal Models to Distribution Shifts: The Role of In-Context Learning**|Guanglin Zhou et.al.|[2405.12217v1](http://arxiv.org/abs/2405.12217v1)|[link](https://github.com/jameszhou-gl/icl-distribution-shift)|
|**2024-05-20**|**MathBench: Evaluating the Theory and Application Proficiency of LLMs with a Hierarchical Mathematics Benchmark**|Hongwei Liu et.al.|[2405.12209v1](http://arxiv.org/abs/2405.12209v1)|[link](https://github.com/open-compass/mathbench)|
|**2024-05-20**|**Modeling citation worthiness by using attention-based bidirectional long short-term memory networks and interpretable models**|Tong Zeng et.al.|[2405.12206v1](http://arxiv.org/abs/2405.12206v1)|[link](https://github.com/sciosci/cite-worthiness)|
|**2024-05-20**|**Metacognitive Capabilities of LLMs: An Exploration in Mathematical Problem Solving**|Aniket Didolkar et.al.|[2405.12205v1](http://arxiv.org/abs/2405.12205v1)|null|
|**2024-05-20**|**Hierarchical Neural Operator Transformer with Learnable Frequency-aware Loss Prior for Arbitrary-scale Super-resolution**|Xihaier Luo et.al.|[2405.12202v1](http://arxiv.org/abs/2405.12202v1)|null|
|**2024-05-20**|**Multi-order Graph Clustering with Adaptive Node-level Weight Learning**|Ye Liu et.al.|[2405.12183v1](http://arxiv.org/abs/2405.12183v1)|[link](https://github.com/scutft-ml/mogc)|
|**2024-05-20**|**Building Temporal Kernels with Orthogonal Polynomials**|Yan Ru Pei et.al.|[2405.12179v1](http://arxiv.org/abs/2405.12179v1)|[link](https://github.com/peabrane/pleiades)|
|**2024-05-20**|**CT-Eval: Benchmarking Chinese Text-to-Table Performance in Large Language Models**|Haoxiang Shi et.al.|[2405.12174v1](http://arxiv.org/abs/2405.12174v1)|null|
|**2024-05-20**|**Fennec: Fine-grained Language Model Evaluation and Correction Extended through Branching and Bridging**|Xiaobo Liang et.al.|[2405.12163v1](http://arxiv.org/abs/2405.12163v1)|[link](https://github.com/dropreg/fennec)|
|**2024-05-20**|**Bangladeshi Native Vehicle Detection in Wild**|Bipin Saha et.al.|[2405.12150v1](http://arxiv.org/abs/2405.12150v1)|[link](https://github.com/bipin-saha/bnvd)|
|**2024-05-20**|**Eliciting Problem Specifications via Large Language Models**|Robert E. Wray et.al.|[2405.12147v1](http://arxiv.org/abs/2405.12147v1)|null|
|**2024-05-20**|**MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning**|Ting Jiang et.al.|[2405.12130v1](http://arxiv.org/abs/2405.12130v1)|[link](https://github.com/kongds/mora)|
|**2024-05-20**|**Prompt Learning for Generalized Vehicle Routing**|Fei Liu et.al.|[2405.12262v1](http://arxiv.org/abs/2405.12262v1)|null|
|**2024-05-20**|**Reindex-Then-Adapt: Improving Large Language Models for Conversational Recommendation**|Zhankui He et.al.|[2405.12119v1](http://arxiv.org/abs/2405.12119v1)|null|
|**2024-05-20**|**Linguistic Structure from a Bottleneck on Sequential Information Processing**|Richard Futrell et.al.|[2405.12109v1](http://arxiv.org/abs/2405.12109v1)|null|
|**2024-05-20**|**Imp: Highly Capable Large Multimodal Models for Mobile Devices**|Zhenwei Shao et.al.|[2405.12107v1](http://arxiv.org/abs/2405.12107v1)|[link](https://github.com/milvlg/imp)|
|**2024-05-20**|**DOP: Diagnostic-Oriented Prompting for Large Language Models in Mathematical Correction**|Hao Chen et.al.|[2405.12100v1](http://arxiv.org/abs/2405.12100v1)|null|
|**2024-05-20**|**Distributional Semantics, Holism, and the Instability of Meaning**|Jumbly Grindrod et.al.|[2405.12084v1](http://arxiv.org/abs/2405.12084v1)|null|
|**2024-05-20**|**Selective Annotation via Data Allocation: These Data Should Be Triaged to Experts for Annotation Rather Than the Model**|Chen Huang et.al.|[2405.12081v1](http://arxiv.org/abs/2405.12081v1)|null|
|**2024-05-20**|**AutoSoccerPose: Automated 3D posture Analysis of Soccer Shot Movements**|Calvin Yeung et.al.|[2405.12070v1](http://arxiv.org/abs/2405.12070v1)|[link](https://github.com/calvinyeungck/3d-shot-posture-dataset)|
|**2024-05-20**|**CLAMBER: A Benchmark of Identifying and Clarifying Ambiguous Information Needs in Large Language Models**|Tong Zhang et.al.|[2405.12063v1](http://arxiv.org/abs/2405.12063v1)|[link](https://github.com/zt991211/clamber)|
|**2024-05-20**|**STYLE: Improving Domain Transferability of Asking Clarification Questions in Large Language Model Powered Conversational Agents**|Yue Chen et.al.|[2405.12059v1](http://arxiv.org/abs/2405.12059v1)|null|
|**2024-05-20**|**Unveiling factors influencing judgment variation in Sentiment Analysis with Natural Language Processing and Statistics**|Olga Kellert et.al.|[2405.12055v1](http://arxiv.org/abs/2405.12055v1)|null|
|**2024-05-20**|**EXACT: Towards a platform for empirically benchmarking Machine Learning model explanation methods**|Benedict Clark et.al.|[2405.12261v1](http://arxiv.org/abs/2405.12261v1)|null|
|**2024-05-20**|**KG-RAG: Bridging the Gap Between Knowledge and Creativity**|Diego Sanmartin et.al.|[2405.12035v1](http://arxiv.org/abs/2405.12035v1)|null|
|**2024-05-20**|**Can AI Relate: Testing Large Language Model Response for Mental Health Support**|Saadia Gabriel et.al.|[2405.12021v1](http://arxiv.org/abs/2405.12021v1)|null|
|**2024-05-20**|**Scrutinize What We Ignore: Reining Task Representation Shift In Context-Based Offline Meta Reinforcement Learning**|Hai Zhang et.al.|[2405.12001v1](http://arxiv.org/abs/2405.12001v1)|null|
|**2024-05-20**|**A review on the use of large language models as virtual tutors**|Silvia García-Méndez et.al.|[2405.11983v1](http://arxiv.org/abs/2405.11983v1)|null|
|**2024-05-20**|**Robust Deep Reinforcement Learning with Adaptive Adversarial Perturbations in Action Space**|Qianmei Liu et.al.|[2405.11982v1](http://arxiv.org/abs/2405.11982v1)|null|
|**2024-05-20**|**SM-DTW: Stability Modulated Dynamic Time Warping for signature verification**|Antonio Parziale et.al.|[2405.11978v1](http://arxiv.org/abs/2405.11978v1)|null|
|**2024-05-20**|**Conditional Shift-Robust Conformal Prediction for Graph Neural Network**|S. Akansha et.al.|[2405.11968v1](http://arxiv.org/abs/2405.11968v1)|null|
|**2024-05-20**|**Recommender Algorithm for Supporting Self-Management of CVD Risk Factors in an Adult Population at Home**|Tatiana V. Afanasieva et.al.|[2405.11967v1](http://arxiv.org/abs/2405.11967v1)|null|

#### Abstracts
##### **Reducing Transformer Key-Value Cache Size with Cross-Layer Attention**
2405.12981v1 by William Brandon, Mayank Mishra, Aniruddha Nrusimha, Rameswar Panda, Jonathan Ragan Kelly

Key-value (KV) caching plays an essential role in accelerating decoding for
transformer-based autoregressive large language models (LLMs). However, the
amount of memory required to store the KV cache can become prohibitive at long
sequence lengths and large batch sizes. Since the invention of the transformer,
two of the most effective interventions discovered for reducing the size of the
KV cache have been Multi-Query Attention (MQA) and its generalization,
Grouped-Query Attention (GQA). MQA and GQA both modify the design of the
attention block so that multiple query heads can share a single key/value head,
reducing the number of distinct key/value heads by a large factor while only
minimally degrading accuracy. In this paper, we show that it is possible to
take Multi-Query Attention a step further by also sharing key and value heads
between adjacent layers, yielding a new attention design we call Cross-Layer
Attention (CLA). With CLA, we find that it is possible to reduce the size of
the KV cache by another 2x while maintaining nearly the same accuracy as
unmodified MQA. In experiments training 1B- and 3B-parameter models from
scratch, we demonstrate that CLA provides a Pareto improvement over the
memory/accuracy tradeoffs which are possible with traditional MQA, enabling
inference with longer sequence lengths and larger batch sizes than would
otherwise be possible

摘要：關鍵值 (KV) 快取在加速轉換器式自迴歸大型語言模型 (LLM) 的解碼過程中扮演著不可或缺的角色。然而，在序列長度和批次大小較大的情況下，儲存 KV 快取所需的記憶體量可能過於龐大。自轉換器發明以來，已發現用於縮減 KV 快取大小最有效的兩個介入措施分別為多重查詢注意力 (MQA) 及其廣義化版本群組查詢注意力 (GQA)。MQA 和 GQA 都修改了注意力區塊的設計，讓多個查詢頭部可以共用一個金鑰/值頭部，大幅減少相異金鑰/值頭部的數量，同時僅造成極小的準確度降低。在本文中，我們展示了進一步共用相鄰層之間的金鑰和值頭部，讓多重查詢注意力更上一層樓，並產生一種我們稱之為跨層注意力 (CLA) 的新注意力設計。透過 CLA，我們發現可以再將 KV 快取的尺寸縮小 2 倍，同時維持與未修改 MQA 近乎相同的準確度。在從頭訓練 1B 和 3B 參數模型的實驗中，我們證明了 CLA 在記憶體/準確度權衡方面提供了帕累托改善，超越了傳統 MQA 的可能性，讓推論得以使用更長的序列長度和更大的批次大小，而這在其他情況下是無法實現的

##### **Energy Rank Alignment: Using Preference Optimization to Search Chemical Space at Scale**
2405.12961v1 by Shriram Chennakesavalu, Frank Hu, Sebastian Ibarraran, Grant M. Rotskoff

Searching through chemical space is an exceptionally challenging problem
because the number of possible molecules grows combinatorially with the number
of atoms. Large, autoregressive models trained on databases of chemical
compounds have yielded powerful generators, but we still lack robust strategies
for generating molecules with desired properties. This molecular search problem
closely resembles the "alignment" problem for large language models, though for
many chemical tasks we have a specific and easily evaluable reward function.
Here, we introduce an algorithm called energy rank alignment (ERA) that
leverages an explicit reward function to produce a gradient-based objective
that we use to optimize autoregressive policies. We show theoretically that
this algorithm is closely related to proximal policy optimization (PPO) and
direct preference optimization (DPO), but has a minimizer that converges to an
ideal Gibbs-Boltzmann distribution with the reward playing the role of an
energy function. Furthermore, this algorithm is highly scalable, does not
require reinforcement learning, and performs well relative to DPO when the
number of preference observations per pairing is small. We deploy this approach
to align molecular transformers to generate molecules with externally specified
properties and find that it does so robustly, searching through diverse parts
of chemical space. While our focus here is on chemical search, we also obtain
excellent results on an AI supervised task for LLM alignment, showing that the
method is scalable and general.

摘要：<paragraph>在化學空間中進行搜尋是一個極具挑戰性的問題，因為可能的分子數量會隨著原子數量的增加而組合式增長。在化學化合物資料庫上訓練的大型自迴歸模型已經產生了強大的生成器，但我們仍然缺乏用於生成具有所需屬性的分子的穩健策略。這個分子搜尋問題與大型語言模型的「比對」問題非常相似，儘管對於許多化學任務，我們有一個具體且易於評估的回饋函數。在此，我們引入一種稱為能量等級比對 (ERA) 的演算法，它利用明確的回饋函數來產生基於梯度的目標，我們使用該目標來最佳化自迴歸策略。我們在理論上證明了這個演算法與近端策略最佳化 (PPO) 和直接偏好最佳化 (DPO) 密切相關，但具有收斂到理想 Gibbs-Boltzmann 分布的最小化器，其中回饋扮演能量函數的角色。此外，這個演算法具有高度的可擴充性，不需要強化學習，並且在每次配對的偏好觀察數量較少時，相對於 DPO 的表現良好。我們採用這種方法來比對分子轉換器，以生成具有外部指定屬性的分子，並發現它能穩健地進行搜尋，在化學空間的不同部分中進行搜尋。雖然我們這裡的重點是化學搜尋，但我們也在 LLM 比對的人工智慧監督任務中獲得了極佳的結果，這表明這個方法具有可擴充性和通用性。</paragraph>

##### **Strategic Deployment of Honeypots in Blockchain-based IoT Systems**
2405.12951v1 by Daniel Commey, Sena Hounsinou, Garth V. Crosby

This paper addresses the challenge of enhancing cybersecurity in
Blockchain-based Internet of Things (BIoTs) systems, which are increasingly
vulnerable to sophisticated cyberattacks. It introduces an AI-powered system
model for the dynamic deployment of honeypots, utilizing an Intrusion Detection
System (IDS) integrated with smart contract functionalities on IoT nodes. This
model enables the transformation of regular nodes into decoys in response to
suspicious activities, thereby strengthening the security of BIoT networks. The
paper analyses strategic interactions between potential attackers and the
AI-enhanced IDS through a game-theoretic model, specifically Bayesian games.
The model focuses on understanding and predicting sophisticated attacks that
may initially appear normal, emphasizing strategic decision-making, optimized
honeypot deployment, and adaptive strategies in response to evolving attack
patterns.

摘要：本文探討了提升區塊鏈物聯網 (BIoTs) 系統中網路安全性的挑戰，這些系統越來越容易受到複雜的網路攻擊。它提出了一個由 AI 驅動的系統模型，用於動態部署誘捕器，利用與物聯網節點上的智慧合約功能整合的入侵偵測系統 (IDS)。此模型能將一般節點轉換為誘餌，以回應可疑活動，進而強化 BIoT 網路的安全性。本文透過博弈論模型，特別是貝氏遊戲，分析潛在攻擊者與 AI 增強的 IDS 之間的策略互動。此模型專注於了解和預測一開始看起來正常的複雜攻擊，強調策略決策、最佳化誘捕器部署，以及根據不斷變化的攻擊模式採取適應策略。

##### **Aggregation of Reasoning: A Hierarchical Framework for Enhancing Answer Selection in Large Language Models**
2405.12939v1 by Zhangyue Yin, Qiushi Sun, Qipeng Guo, Zhiyuan Zeng, Xiaonan Li, Tianxiang Sun, Cheng Chang, Qinyuan Cheng, Ding Wang, Xiaofeng Mou, Xipeng Qiu, XuanJing Huang

Recent advancements in Chain-of-Thought prompting have facilitated
significant breakthroughs for Large Language Models (LLMs) in complex reasoning
tasks. Current research enhances the reasoning performance of LLMs by sampling
multiple reasoning chains and ensembling based on the answer frequency.
However, this approach fails in scenarios where the correct answers are in the
minority. We identify this as a primary factor constraining the reasoning
capabilities of LLMs, a limitation that cannot be resolved solely based on the
predicted answers. To address this shortcoming, we introduce a hierarchical
reasoning aggregation framework AoR (Aggregation of Reasoning), which selects
answers based on the evaluation of reasoning chains. Additionally, AoR
incorporates dynamic sampling, adjusting the number of reasoning chains in
accordance with the complexity of the task. Experimental results on a series of
complex reasoning tasks show that AoR outperforms prominent ensemble methods.
Further analysis reveals that AoR not only adapts various LLMs but also
achieves a superior performance ceiling when compared to current methods.

摘要：最近在思考链提示方面的进步促进了大型语言模型（LLM）在复杂推理任务中的重大突破。目前的研究通过对多个推理链进行采样并根据答案频率进行集成，增强了 LLM 的推理性能。然而，这种方法在正确答案属于少数派的情况下会失败。我们将其确定为制约 LLM 推理能力的主要因素，这种限制不能仅基于预测答案来解决。为了解决这一缺点，我们引入了一个分层推理聚合框架 AoR（推理聚合），它根据推理链的评估来选择答案。此外，AoR 结合了动态采样，根据任务的复杂性调整推理链的数量。在一系列复杂推理任务上的实验结果表明，AoR 优于突出的集成方法。进一步的分析表明，AoR 不仅适应各种 LLM，而且与当前方法相比，还实现了更高的性能上限。

##### **Skin-in-the-Game: Decision Making via Multi-Stakeholder Alignment in LLMs**
2405.12933v1 by Bilgehan Sel, Priya Shanmugasundaram, Mohammad Kachuee, Kun Zhou, Ruoxi Jia, Ming Jin

Large Language Models (LLMs) have shown remarkable capabilities in tasks such
as summarization, arithmetic reasoning, and question answering. However, they
encounter significant challenges in the domain of moral reasoning and ethical
decision-making, especially in complex scenarios with multiple stakeholders.
This paper introduces the Skin-in-the-Game (SKIG) framework, aimed at enhancing
moral reasoning in LLMs by exploring decisions' consequences from multiple
stakeholder perspectives. Central to SKIG's mechanism is simulating
accountability for actions, which, alongside empathy exercises and risk
assessment, is pivotal to its effectiveness. We validate SKIG's performance
across various moral reasoning benchmarks with proprietary and opensource LLMs,
and investigate its crucial components through extensive ablation analyses.

摘要：大型語言模型 (LLM) 在摘要、算術推理和問題解答等任務中展現出非凡的能力。然而，它們在道德推理和道德決策領域中遇到重大挑戰，特別是在涉及多個利害關係人的複雜場景中。本文介紹了 Skin-in-the-Game (SKIG) 框架，旨在通過從多個利害關係人的角度探討決策的後果來增強 LLM 的道德推理。SKIG 機制的核心是模擬對行動的負責，這與同理心練習和風險評估一起，對其有效性至關重要。我們使用專有和開源 LLM 在各種道德推理基準上驗證了 SKIG 的性能，並通過廣泛的消融分析研究了其關鍵組成部分。

##### **Code-mixed Sentiment and Hate-speech Prediction**
2405.12929v1 by Anjali Yadav, Tanya Garg, Matej Klemen, Matej Ulcar, Basant Agarwal, Marko Robnik Sikonja

Code-mixed discourse combines multiple languages in a single text. It is
commonly used in informal discourse in countries with several official
languages, but also in many other countries in combination with English or
neighboring languages. As recently large language models have dominated most
natural language processing tasks, we investigated their performance in
code-mixed settings for relevant tasks. We first created four new bilingual
pre-trained masked language models for English-Hindi and English-Slovene
languages, specifically aimed to support informal language. Then we performed
an evaluation of monolingual, bilingual, few-lingual, and massively
multilingual models on several languages, using two tasks that frequently
contain code-mixed text, in particular, sentiment analysis and offensive
language detection in social media texts. The results show that the most
successful classifiers are fine-tuned bilingual models and multilingual models,
specialized for social media texts, followed by non-specialized massively
multilingual and monolingual models, while huge generative models are not
competitive. For our affective problems, the models mostly perform slightly
better on code-mixed data compared to non-code-mixed data.

摘要：<paragraph>代碼混合語篇在單一文本中結合多種語言。在擁有數種官方語言的國家，它通常用於非正式語篇，但它也用於許多其他國家，與英語或鄰近語言結合使用。由於最近大型語言模型主導了大多數自然語言處理任務，我們調查了它們在代碼混合設定中執行相關任務的效能。我們首先為英語-印地語和英語-斯洛維尼亞語建立了四個新的雙語預訓練遮罩語言模型，特別用於支援非正式語言。然後，我們對單語、雙語、少語和大量多語模型進行了評估，使用兩種經常包含代碼混合文本的任務，特別是在社交媒體文本中的情緒分析和攻擊性語言偵測。結果顯示，最成功的分類器是針對社交媒體文本進行微調的雙語模型和多語模型，其次是非專業的大量多語模型和單語模型，而巨大的生成模型則沒有競爭力。對於我們的感情問題，這些模型在代碼混合資料上的執行表現大多略優於非代碼混合資料。</paragraph>

##### **Panmodal Information Interaction**
2405.12923v1 by Chirag Shah, Ryen W. White

The emergence of generative artificial intelligence (GenAI) is transforming
information interaction. For decades, search engines such as Google and Bing
have been the primary means of locating relevant information for the general
population. They have provided search results in the same standard format (the
so-called "10 blue links"). The recent ability to chat via natural language
with AI-based agents and have GenAI automatically synthesize answers in
real-time (grounded in top-ranked results) is changing how people interact with
and consume information at massive scale. These two information interaction
modalities (traditional search and AI-powered chat) coexist in current search
engines, either loosely coupled (e.g., as separate options/tabs) or tightly
coupled (e.g., integrated as a chat answer embedded directly within a
traditional search result page). We believe that the existence of these two
different modalities, and potentially many others, is creating an opportunity
to re-imagine the search experience, capitalize on the strengths of many
modalities, and develop systems and strategies to support seamless flow between
them. We refer to these as panmodal experiences. Unlike monomodal experiences,
where only one modality is available and/or used for the task at hand, panmodal
experiences make multiple modalities available to users (multimodal), directly
support transitions between modalities (crossmodal), and seamlessly combine
modalities to tailor task assistance (transmodal). While our focus is search
and chat, with learnings from insights from a survey of over 100 individuals
who have recently performed common tasks on these two modalities, we also
present a more general vision for the future of information interaction using
multiple modalities and the emergent capabilities of GenAI.

摘要：生成式人工智能 (GenAI) 的出現正在轉變資訊互動。數十年來，Google 和 Bing 等搜尋引擎一直是普羅大眾尋找相關資訊的主要管道。他們以相同的標準格式（所謂的「10 個藍色連結」）提供搜尋結果。近來，透過自然語言與 AI 代理聊天，並讓 GenAI 自動綜合答案（建立於排名最高的結果）的能力，正在改變人們互動和大量消費資訊的方式。這兩種資訊互動模式（傳統搜尋和 AI 驅動的聊天）在目前的搜尋引擎中並存，它們可能是鬆散結合（例如，作為獨立選項/分頁），或緊密結合（例如，整合為直接嵌入傳統搜尋結果頁面中的聊天答案）。我們相信，這兩種不同模式的存在，以及潛在的許多其他模式，正在創造一個機會，可以重新構想搜尋體驗，利用許多模式的優勢，並開發系統和策略來支援它們之間的無縫流動。我們將這些稱為泛模態體驗。與單模態體驗不同，單模態體驗僅提供一種模式，或僅使用一種模式來執行手邊的任務，泛模態體驗讓使用者可以使用多種模式（多模式），直接支援在模式之間的轉換（跨模式），並無縫地結合模式以客製化任務協助（跨模式）。雖然我們的重點是搜尋和聊天，並從最近在兩種模式上執行常見任務的 100 多位個人的見解中學習，但我們也提出了一個更通用的願景，用於透過多種模式和 GenAI 的新興能力進行未來資訊互動。

##### **G-DIG: Towards Gradient-based DIverse and hiGh-quality Instruction Data Selection for Machine Translation**
2405.12915v1 by Xingyuan Pan, Luyang Huang, Liyan Kang, Zhicheng Liu, Yu Lu, Shanbo Cheng

Large Language Models (LLMs) have demonstrated remarkable abilities in
general scenarios. Instruction finetuning empowers them to align with humans in
various tasks. Nevertheless, the Diversity and Quality of the instruction data
remain two main challenges for instruction finetuning. With regard to this, in
this paper, we propose a novel gradient-based method to automatically select
high-quality and diverse instruction finetuning data for machine translation.
Our key innovation centers around analyzing how individual training examples
influence the model during training. Specifically, we select training examples
that exert beneficial influences on the model as high-quality ones by means of
Influence Function plus a small high-quality seed dataset. Moreover, to enhance
the diversity of the training data we maximize the variety of influences they
have on the model by clustering on their gradients and resampling. Extensive
experiments on WMT22 and FLORES translation tasks demonstrate the superiority
of our methods, and in-depth analysis further validates their effectiveness and
generalization.

摘要：大型語言模型 (LLM) 已在一般場景中展現出非凡的能力。指示微調使它們能夠在各種任務中與人類保持一致。儘管如此，指示數據的多樣性和品質仍然是指示微調的兩項主要挑戰。有鑑於此，我們在本文中提出了一種新穎的基於梯度的自動選擇機器翻譯的高品質且多樣化的指示微調數據的方法。我們的關鍵創新圍繞分析個別訓練範例在訓練期間如何影響模型。具體來說，我們選擇對模型產生有益影響的訓練範例，並透過影響函數加上少量高品質種子資料集來作為高品質的訓練範例。此外，為了增強訓練數據的多樣性，我們透過對它們的梯度進行分群和重新取樣，將它們對模型的影響最大化。在 WMT22 和 FLORES 翻譯任務上的廣泛實驗證明了我們方法的優越性，深入分析進一步驗證了它們的有效性和概括性。

##### **Topic Modelling Case Law Using a Large Language Model and a New Taxonomy for UK Law: AI Insights into Summary Judgment**
2405.12910v1 by Holli Sargeant, Ahmed Izzidien, Felix Steffek

This paper addresses a critical gap in legal analytics by developing and
applying a novel taxonomy for topic modelling summary judgment cases in the
United Kingdom. Using a curated dataset of summary judgment cases, we use the
Large Language Model Claude 3 Opus to explore functional topics and trends. We
find that Claude 3 Opus correctly classified the topic with an accuracy of
87.10%. The analysis reveals distinct patterns in the application of summary
judgments across various legal domains. As case law in the United Kingdom is
not originally labelled with keywords or a topic filtering option, the findings
not only refine our understanding of the thematic underpinnings of summary
judgments but also illustrate the potential of combining traditional and
AI-driven approaches in legal classification. Therefore, this paper provides a
new and general taxonomy for UK law. The implications of this work serve as a
foundation for further research and policy discussions in the field of judicial
administration and computational legal research methodologies.

摘要：本論文透過開發並應用一種新的分類法，針對主題建模摘要判決案件，來探討法律分析中的一個關鍵缺口，並將其應用於英國。我們使用策展的摘要判決案件資料集，使用大型語言模型 Claude 3 Opus 來探討功能性主題和趨勢。我們發現 Claude 3 Opus 正確分類主題的準確率為 87.10%。分析揭示了在各種法律領域中應用摘要判決的不同模式。由於英國的判例法最初並未標記關鍵字或主題過濾選項，因此這些發現不僅能改善我們對摘要判決主題基礎的理解，還能說明傳統方法和 AI 驅動方法在法律分類中結合的潛力。因此，本文提供了英國法律的一個新的通用分類法。這項工作的意義為司法行政和計算法律研究方法領域的進一步研究和政策討論奠定了基礎。

##### **Adversarial DPO: Harnessing Harmful Data for Reducing Toxicity with Minimal Impact on Coherence and Evasiveness in Dialogue Agents**
2405.12900v1 by San Kim, Gary Geunbae Lee

Recent advancements in open-domain dialogue systems have been propelled by
the emergence of high-quality large language models (LLMs) and various
effective training methodologies. Nevertheless, the presence of toxicity within
these models presents a significant challenge that can potentially diminish the
user experience. In this study, we introduce an innovative training algorithm,
an improvement upon direct preference optimization (DPO), called adversarial
DPO (ADPO). The ADPO algorithm is designed to train models to assign higher
probability distributions to preferred responses and lower distributions to
unsafe responses, which are self-generated using the toxic control token. We
demonstrate that ADPO enhances the model's resilience against harmful
conversations while minimizing performance degradation. Furthermore, we
illustrate that ADPO offers a more stable training procedure compared to the
traditional DPO. To the best of our knowledge, this is the first adaptation of
the DPO algorithm that directly incorporates harmful data into the generative
model, thereby reducing the need to artificially create safe dialogue data.

摘要：開放領域對話系統的最新進展是由高品質大型語言模型 (LLM) 和各種有效訓練方法的出現所推動。然而，這些模型中存在的毒性是一個重大挑戰，可能會降低使用者體驗。在本研究中，我們介紹了一種創新的訓練演算法，一種直接偏好最佳化的改進，稱為對抗性 DPO (ADPO)。ADPO 演算法旨在訓練模型將較高的機率分佈分配給偏好的回應，並將較低的機率分佈分配給不安全的回應，這些回應是使用有毒控制代碼自生。我們證明 ADPO 提升了模型對有害對話的復原力，同時將效能下降降到最低。此外，我們說明 ADPO 與傳統 DPO 相比提供了更穩定的訓練程序。據我們所知，這是 DPO 演算法首次將有害資料直接納入生成模型，從而減少了人工建立安全對話資料的需求。

##### **Investigating Persuasion Techniques in Arabic: An Empirical Study Leveraging Large Language Models**
2405.12884v1 by Abdurahmman Alzahrani, Eyad Babkier, Faisal Yanbaawi, Firas Yanbaawi, Hassan Alhuzali

In the current era of digital communication and widespread use of social
media, it is crucial to develop an understanding of persuasive techniques
employed in written text. This knowledge is essential for effectively
discerning accurate information and making informed decisions. To address this
need, this paper presents a comprehensive empirical study focused on
identifying persuasive techniques in Arabic social media content. To achieve
this objective, we utilize Pre-trained Language Models (PLMs) and leverage the
ArAlEval dataset, which encompasses two tasks: binary classification to
determine the presence or absence of persuasion techniques, and multi-label
classification to identify the specific types of techniques employed in the
text. Our study explores three different learning approaches by harnessing the
power of PLMs: feature extraction, fine-tuning, and prompt engineering
techniques. Through extensive experimentation, we find that the fine-tuning
approach yields the highest results on the aforementioned dataset, achieving an
f1-micro score of 0.865 and an f1-weighted score of 0.861. Furthermore, our
analysis sheds light on an interesting finding. While the performance of the
GPT model is relatively lower compared to the other approaches, we have
observed that by employing few-shot learning techniques, we can enhance its
results by up to 20\%. This offers promising directions for future research and
exploration in this topic\footnote{Upon Acceptance, the source code will be
released on GitHub.}.

摘要：<paragraph>在數位通訊和社群媒體廣泛使用的當今時代，培養對於書面文字中所使用說服技巧的理解至關重要。這項知識對於有效辨別準確資訊和做出明智決策至關重要。為了滿足這項需求，本文提出了一項全面的實證研究，重點在於辨識阿拉伯社群媒體內容中的說服技巧。為達成此目標，我們利用預先訓練的語言模型 (PLM)，並運用 ArAlEval 資料集，其中包含兩項任務：二元分類以判斷說服技巧的存在與否，以及多標籤分類以辨識文字中所使用的特定技巧類型。我們的研究透過運用 PLM 的力量，探討了三種不同的學習方法：特徵提取、微調和提示工程技術。透過廣泛的實驗，我們發現微調方法在上述資料集上產生了最高的結果，達到了 f1-micro 分數 0.865 和 f1-weighted 分數 0.861。此外，我們的分析揭露了一個有趣的發現。雖然 GPT 模型的效能與其他方法相比相對較低，但我們觀察到透過採用少次學習技術，我們可以將其結果提升多達 20%。這為此主題未來的研究和探索提供了有希望的方向\footnote{在接受後，原始碼將在 GitHub 上釋出。}。</paragraph>

##### **Diffusion-RSCC: Diffusion Probabilistic Model for Change Captioning in Remote Sensing Images**
2405.12875v1 by Xiaofei Yu, Yitong Li, Jie Ma

Remote sensing image change captioning (RSICC) aims at generating human-like
language to describe the semantic changes between bi-temporal remote sensing
image pairs. It provides valuable insights into environmental dynamics and land
management. Unlike conventional change captioning task, RSICC involves not only
retrieving relevant information across different modalities and generating
fluent captions, but also mitigating the impact of pixel-level differences on
terrain change localization. The pixel problem due to long time span decreases
the accuracy of generated caption. Inspired by the remarkable generative power
of diffusion model, we propose a probabilistic diffusion model for RSICC to
solve the aforementioned problems. In training process, we construct a noise
predictor conditioned on cross modal features to learn the distribution from
the real caption distribution to the standard Gaussian distribution under the
Markov chain. Meanwhile, a cross-mode fusion and a stacking self-attention
module are designed for noise predictor in the reverse process. In testing
phase, the well-trained noise predictor helps to estimate the mean value of the
distribution and generate change captions step by step. Extensive experiments
on the LEVIR-CC dataset demonstrate the effectiveness of our Diffusion-RSCC and
its individual components. The quantitative results showcase superior
performance over existing methods across both traditional and newly augmented
metrics. The code and materials will be available online at
https://github.com/Fay-Y/Diffusion-RSCC.

摘要：遙感影像變化標題 (RSICC) 的目標是產生類似人類的語言來描述雙時相遙感影像對之間的語義變化。它提供了對環境動態和土地管理的寶貴見解。與傳統的變化標題任務不同，RSICC 不僅涉及跨不同模態擷取相關資訊和產生流利的標題，還減輕了像素級差異對地形變化定位的影響。由於時間跨度長而產生的像素問題降低了生成標題的準確度。受到擴散模型卓越的生成能力的啟發，我們提出了 RSICC 的機率擴散模型來解決上述問題。在訓練過程中，我們建構一個以跨模態特徵為條件的雜訊預測器，以學習從真實標題分佈到馬可夫鏈下的標準高斯分佈的分佈。同時，在反向過程中，為雜訊預測器設計了跨模式融合和堆疊自注意力模組。在測試階段，訓練良好的雜訊預測器有助於估計分佈的平均值並逐步產生變化標題。在 LEVIR-CC 資料集上進行的廣泛實驗證明了我們的 Diffusion-RSCC 及其個別元件的有效性。定量結果展示了在傳統和新擴充的指標上優於現有方法的出色效能。程式碼和材料將在 https://github.com/Fay-Y/Diffusion-RSCC 上線上提供。

##### **Equivariant Spatio-Temporal Attentive Graph Networks to Simulate Physical Dynamics**
2405.12868v1 by Liming Wu, Zhichao Hou, Jirui Yuan, Yu Rong, Wenbing Huang

Learning to represent and simulate the dynamics of physical systems is a
crucial yet challenging task. Existing equivariant Graph Neural Network (GNN)
based methods have encapsulated the symmetry of physics, \emph{e.g.},
translations, rotations, etc, leading to better generalization ability.
Nevertheless, their frame-to-frame formulation of the task overlooks the
non-Markov property mainly incurred by unobserved dynamics in the environment.
In this paper, we reformulate dynamics simulation as a spatio-temporal
prediction task, by employing the trajectory in the past period to recover the
Non-Markovian interactions. We propose Equivariant Spatio-Temporal Attentive
Graph Networks (ESTAG), an equivariant version of spatio-temporal GNNs, to
fulfill our purpose. At its core, we design a novel Equivariant Discrete
Fourier Transform (EDFT) to extract periodic patterns from the history frames,
and then construct an Equivariant Spatial Module (ESM) to accomplish spatial
message passing, and an Equivariant Temporal Module (ETM) with the forward
attention and equivariant pooling mechanisms to aggregate temporal message. We
evaluate our model on three real datasets corresponding to the molecular-,
protein- and macro-level. Experimental results verify the effectiveness of
ESTAG compared to typical spatio-temporal GNNs and equivariant GNNs.

摘要：學習表示和模擬物理系統的動態是一個至關重要且具有挑戰性的任務。現有的等變圖神經網路 (GNN) 基於封裝物理對稱性的方法，例如平移、旋轉等，從而提高了泛化能力。儘管如此，它們逐幀制定任務的方式忽視了主要由環境中未觀察到的動態導致的非馬可夫性質。在本文中，我們將動態模擬重新表述為時空預測任務，通過採用過去一段時間的軌跡來恢復非馬可夫交互作用。我們提出了等變時空注意力圖神經網路 (ESTAG)，這是時空 GNN 的等變版本，以實現我們的目的。在它的核心，我們設計了一種新穎的等變離散傅立葉變換 (EDFT) 來從歷史幀中提取週期性模式，然後構造一個等變空間模組 (ESM) 來完成空間訊息傳遞，以及一個具有前饋注意力和等變池化機制的等變時間模組 (ETM) 來匯總時間訊息。我們在對應於分子、蛋白質和巨觀層級的三個真實資料集上評估我們的模型。實驗結果驗證了 ESTAG 與典型的時空 GNN 和等變 GNN 相比的有效性。

##### **LLM Processes: Numerical Predictive Distributions Conditioned on Natural Language**
2405.12856v1 by James Requeima, John Bronskill, Dami Choi, Richard E. Turner, David Duvenaud

Machine learning practitioners often face significant challenges in formally
integrating their prior knowledge and beliefs into predictive models, limiting
the potential for nuanced and context-aware analyses. Moreover, the expertise
needed to integrate this prior knowledge into probabilistic modeling typically
limits the application of these models to specialists. Our goal is to build a
regression model that can process numerical data and make probabilistic
predictions at arbitrary locations, guided by natural language text which
describes a user's prior knowledge. Large Language Models (LLMs) provide a
useful starting point for designing such a tool since they 1) provide an
interface where users can incorporate expert insights in natural language and
2) provide an opportunity for leveraging latent problem-relevant knowledge
encoded in LLMs that users may not have themselves. We start by exploring
strategies for eliciting explicit, coherent numerical predictive distributions
from LLMs. We examine these joint predictive distributions, which we call LLM
Processes, over arbitrarily-many quantities in settings such as forecasting,
multi-dimensional regression, black-box optimization, and image modeling. We
investigate the practical details of prompting to elicit coherent predictive
distributions, and demonstrate their effectiveness at regression. Finally, we
demonstrate the ability to usefully incorporate text into numerical
predictions, improving predictive performance and giving quantitative structure
that reflects qualitative descriptions. This lets us begin to explore the rich,
grounded hypothesis space that LLMs implicitly encode.

摘要：機器學習從業人員在正式將先驗知識和信念整合到預測模型中時，經常會遇到重大的挑戰，這會限制細緻入微且具備情境感知的分析潛力。此外，將此先驗知識整合到機率模型中所需的專業知識通常會將這些模型的應用限制在專家身上。我們的目標是建立一個回歸模型，該模型可以處理數值資料並在任意位置進行機率預測，並由描述使用者先驗知識的自然語言文字加以引導。大型語言模型 (LLM) 為設計此類工具提供了有用的起點，因為它們 1) 提供了一個介面，使用者可以在其中以自然語言納入專家見解，以及 2) 提供了一個機會，可以利用編碼在 LLM 中的潛在問題相關知識，而使用者可能自己沒有這些知識。我們首先探索從 LLM 引出明確、連貫的數值預測分佈的策略。我們檢驗這些聯合預測分佈，我們稱之為 LLM 程序，它們在預測、多維回歸、黑盒最佳化和影像建模等設定中涵蓋任意大量的數量。我們調查引發連貫預測分佈的實際提示細節，並展示它們在回歸中的有效性。最後，我們展示了將文字有效納入數值預測的能力，改善預測效能並提供反映定性描述的量化結構。這讓我們開始探索 LLM 隱含編碼的豐富、紮實的假設空間。

##### **Training and inference in the ReckON RSNN architecture implemented on a MPSoC**
2405.12849v1 by Alejandro Linares-Barranco, Luciano Prono, Robert Lengenstein, Giacomo Indiveri, Charlotte Frenkel

With the rise of artificial intelligence, biological neuron models are being
used to implement neural networks that can learn certain tasks after a training
phase. One type of such networks are spiking neural networks (SNNs) that rely
on a simplified model for biological neurons, the Integrate and Fire neuron.
Several accelerators have emerged to implement SNNs with this kind of neuron.
The ReckON system is one of these that allows both the training and execution
of a recurrent SNN. The ReckON architecture, implemented on a custom ASIC, can
be fully described using a hardware description language. In this work, we
adapt the Verilog description to implement it on a Xilinx Multiprocessor System
on Chip system (MPSoC). We present the circuits required for the efficient
operation of the system, and a Python framework to use it on the Pynq ZU
platform. We validate the architecture and implementation in two different
scenarios, and show how the simulated accuracy is preserved with a peak
performance of 3.8M events processed per second.

摘要：隨著人工智慧的崛起，生物神經元模型被用於實現神經網路，讓其在訓練階段後能夠學習特定任務。其中一種此類網路是尖峰神經網路 (SNN)，它依賴於生物神經元的簡化模型，即積分與發射神經元。已經出現了多種加速器，用於使用這種神經元來實現 SNN。ReckON 系統就是其中之一，它允許訓練和執行遞迴 SNN。ReckON 架構實作於客製化 ASIC 上，可以使用硬體描述語言完整描述。在這項工作中，我們調整了 Verilog 描述，以便在 Xilinx 多處理器系統單晶片系統 (MPSoC) 上實現它。我們展示了系統有效運作所需的電路，以及一個 Python 框架，以便在 Pynq ZU 平台上使用它。我們在兩種不同的情境中驗證了架構和實作，並展示了模擬準確度如何以每秒處理 380 萬個事件的峰值效能保留下來。

##### **Large Language Models Meet NLP: A Survey**
2405.12819v1 by Libo Qin, Qiguang Chen, Xiachong Feng, Yang Wu, Yongheng Zhang, Yinghui Li, Min Li, Wanxiang Che, Philip S. Yu

While large language models (LLMs) like ChatGPT have shown impressive
capabilities in Natural Language Processing (NLP) tasks, a systematic
investigation of their potential in this field remains largely unexplored. This
study aims to address this gap by exploring the following questions: (1) How
are LLMs currently applied to NLP tasks in the literature? (2) Have traditional
NLP tasks already been solved with LLMs? (3) What is the future of the LLMs for
NLP? To answer these questions, we take the first step to provide a
comprehensive overview of LLMs in NLP. Specifically, we first introduce a
unified taxonomy including (1) parameter-frozen application and (2)
parameter-tuning application to offer a unified perspective for understanding
the current progress of LLMs in NLP. Furthermore, we summarize the new
frontiers and the associated challenges, aiming to inspire further
groundbreaking advancements. We hope this work offers valuable insights into
the {potential and limitations} of LLMs in NLP, while also serving as a
practical guide for building effective LLMs in NLP.

摘要：儘管大型語言模型 (LLM) 如 ChatGPT 已在自然語言處理 (NLP) 任務中展現出令人印象深刻的能力，但對其在該領域的潛力進行系統性調查仍未廣泛探討。本研究旨在透過探討以下問題來解決此一差距：(1) LLM 目前如何在文獻中應用於 NLP 任務？(2) 傳統的 NLP 任務是否已透過 LLM 解決？(3) LLM 的 NLP 未來是什麼？為了回答這些問題，我們採取第一步，提供 LLM 在 NLP 中的全面概述。具體來說，我們首先介紹一個統一的分類法，包括 (1) 參數凍結應用和 (2) 參數調整應用，以提供一個統一的觀點來了解 LLM 在 NLP 中的當前進度。此外，我們總結了新的領域和相關挑戰，旨在激勵進一步的突破性進展。我們希望這項工作能提供有價值的見解，了解 LLM 在 NLP 中的{潛力與限制}，同時也作為在 NLP 中建構有效 LLM 的實用指南。

##### **FAdam: Adam is a natural gradient optimizer using diagonal empirical Fisher information**
2405.12807v1 by Dongseong Hwang

This paper establishes a mathematical foundation for the Adam optimizer,
elucidating its connection to natural gradient descent through Riemannian and
information geometry. We rigorously analyze the diagonal empirical Fisher
information matrix (FIM) in Adam, clarifying all detailed approximations and
advocating for the use of log probability functions as loss, which should be
based on discrete distributions, due to the limitations of empirical FIM. Our
analysis uncovers flaws in the original Adam algorithm, leading to proposed
corrections such as enhanced momentum calculations, adjusted bias corrections,
and gradient clipping. We refine the weight decay term based on our theoretical
framework. Our modified algorithm, Fisher Adam (FAdam), demonstrates superior
performance across diverse domains including LLM, ASR, and VQ-VAE, achieving
state-of-the-art results in ASR.

摘要：這篇論文為 Adam 最佳化器建立了一個數學基礎，
闡明了它與透過黎曼和資訊幾何的自然梯度下降的關聯。我們嚴謹地分析了 Adam 中的對角經驗 Fisher 資訊矩陣 (FIM)，釐清所有詳細的近似，並提倡使用對數機率函數作為損失，這應基於離散分佈，因為經驗 FIM 有其限制。我們的分析揭露了原始 Adam 演算法的缺陷，導致建議進行修正，例如增強動量計算、調整偏差修正和梯度裁剪。我們根據我們的理論架構改善了權重衰減項。我們改良的演算法 Fisher Adam (FAdam) 在 LLM、ASR 和 VQ-VAE 等不同領域展示了卓越的效能，在 ASR 中取得了最先進的結果。

##### **What Have We Achieved on Non-autoregressive Translation?**
2405.12788v1 by Yafu Li, Huajian Zhang, Jianhao Yan, Yongjing Yin, Yue Zhang

Recent advances have made non-autoregressive (NAT) translation comparable to
autoregressive methods (AT). However, their evaluation using BLEU has been
shown to weakly correlate with human annotations. Limited research compares
non-autoregressive translation and autoregressive translation comprehensively,
leaving uncertainty about the true proximity of NAT to AT. To address this gap,
we systematically evaluate four representative NAT methods across various
dimensions, including human evaluation. Our empirical results demonstrate that
despite narrowing the performance gap, state-of-the-art NAT still underperforms
AT under more reliable evaluation metrics. Furthermore, we discover that
explicitly modeling dependencies is crucial for generating natural language and
generalizing to out-of-distribution sequences.

摘要：最近的進展使非自迴歸 (NAT) 翻譯與自迴歸方法 (AT) 相媲美。然而，使用 BLEU 評估它們已被證明與人類註釋相關性較弱。有限的研究全面比較了非自迴歸翻譯和自迴歸翻譯，對 NAT 與 AT 的真實接近程度留下不確定性。為了解決這個差距，我們系統性地評估了四種具有代表性的 NAT 方法，包括人類評估在內的各種面向。我們的實證結果表明，儘管縮小了效能差距，但最先進的 NAT 在更可靠的評估指標下仍然表現不如 AT。此外，我們發現明確建模依賴性對於生成自然語言和概括到分布外序列至關重要。

##### **Transformer in Touch: A Survey**
2405.12779v1 by Jing Gao, Ning Cheng, Bin Fang, Wenjuan Han

The Transformer model, initially achieving significant success in the field
of natural language processing, has recently shown great potential in the
application of tactile perception. This review aims to comprehensively outline
the application and development of Transformers in tactile technology. We first
introduce the two fundamental concepts behind the success of the Transformer:
the self-attention mechanism and large-scale pre-training. Then, we delve into
the application of Transformers in various tactile tasks, including but not
limited to object recognition, cross-modal generation, and object manipulation,
offering a concise summary of the core methodologies, performance benchmarks,
and design highlights. Finally, we suggest potential areas for further research
and future work, aiming to generate more interest within the community, tackle
existing challenges, and encourage the use of Transformer models in the tactile
field.

摘要：Transformer 模型最初在自然語言處理領域取得了顯著的成功，最近在觸覺感知的應用中也展現了巨大的潛力。本綜述旨在全面概述 Transformer 在觸覺技術中的應用和發展。我們首先介紹 Transformer 成功背後的兩個基本概念：自注意力機制和大規模預訓練。然後，我們深入探討 Transformer 在各種觸覺任務中的應用，包括但不限於物體識別、跨模態生成和物體操作，簡要總結了核心方法、性能基準和設計亮點。最後，我們提出了進一步研究和未來工作的潛在領域，旨在激發社區內部更多的興趣，應對現有挑戰，並鼓勵在觸覺領域使用 Transformer 模型。

##### **Unsupervised Multimodal Clustering for Semantics Discovery in Multimodal Utterances**
2405.12775v1 by Hanlei Zhang, Hua Xu, Fei Long, Xin Wang, Kai Gao

Discovering the semantics of multimodal utterances is essential for
understanding human language and enhancing human-machine interactions. Existing
methods manifest limitations in leveraging nonverbal information for discerning
complex semantics in unsupervised scenarios. This paper introduces a novel
unsupervised multimodal clustering method (UMC), making a pioneering
contribution to this field. UMC introduces a unique approach to constructing
augmentation views for multimodal data, which are then used to perform
pre-training to establish well-initialized representations for subsequent
clustering. An innovative strategy is proposed to dynamically select
high-quality samples as guidance for representation learning, gauged by the
density of each sample's nearest neighbors. Besides, it is equipped to
automatically determine the optimal value for the top-$K$ parameter in each
cluster to refine sample selection. Finally, both high- and low-quality samples
are used to learn representations conducive to effective clustering. We build
baselines on benchmark multimodal intent and dialogue act datasets. UMC shows
remarkable improvements of 2-6\% scores in clustering metrics over
state-of-the-art methods, marking the first successful endeavor in this domain.
The complete code and data are available at https://github.com/thuiar/UMC.

摘要：發現多模態語句的語義對於理解人類語言和增強人機互動至關重要。現有方法在利用非語言資訊來辨別無監督場景中的複雜語義時，表現出其限制。本文介紹了一種新穎的無監督多模態聚類方法 (UMC)，為此領域做出了開創性的貢獻。UMC 介紹了一種構建多模態資料擴充檢視的獨特方法，然後用於執行預訓練，以建立後續聚類的良好初始化表示。提出了一種創新的策略，根據每個樣本最近鄰居的密度，動態選擇高品質樣本作為表示學習的指導。此外，它具備自動確定每個群集中頂部-$K$ 參數的最佳值的裝備，以優化樣本選擇。最後，高品質和低品質樣本都用於學習有助於有效聚類的表示。我們在基準多模態意圖和對話行為資料集上建立基準。UMC 在聚類指標上顯示出比最先進的方法高出 2-6% 的顯著改進，標誌著在這個領域的首次成功嘗試。完整的程式碼和資料可在 https://github.com/thuiar/UMC 取得。

##### **Progress Measures for Grokking on Real-world Datasets**
2405.12755v1 by Satvik Golechha

Grokking, a phenomenon where machine learning models generalize long after
overfitting, has been primarily observed and studied in algorithmic tasks. This
paper explores grokking in real-world datasets using deep neural networks for
classification under the cross-entropy loss. We challenge the prevalent
hypothesis that the $L_2$ norm of weights is the primary cause of grokking by
demonstrating that grokking can occur outside the expected range of weight
norms. To better understand grokking, we introduce three new progress measures:
activation sparsity, absolute weight entropy, and approximate local circuit
complexity. These measures are conceptually related to generalization and
demonstrate a stronger correlation with grokking in real-world datasets
compared to weight norms. Our findings suggest that while weight norms might
usually correlate with grokking and our progress measures, they are not
causative, and our proposed measures provide a better understanding of the
dynamics of grokking.

摘要：格羅金現象，一種機器學習模型在過度擬合後仍能泛化的現象，主要在演算法任務中觀察和研究。本文使用深度神經網路在交叉熵損失下進行分類，探討格羅金在真實世界資料集中的表現。我們挑戰了流行的假設，即權重的 $L_2$ 範數是格羅金的主要原因，證明了格羅金可以在預期的權重範數範圍之外發生。為了更好地理解格羅金，我們引入了三項新的進度衡量標準：激活稀疏性、絕對權重熵和近似局部電路複雜度。這些衡量標準在概念上與泛化相關，並證明與真實世界資料集中的格羅金相比，與權重範數有更強的相關性。我們的研究結果表明，雖然權重範數通常可能與格羅金和我們的進度衡量標準相關，但它們並非因果關係，而我們提出的衡量標準可以更好地理解格羅金的動態。

##### **Neural Operator for Accelerating Coronal Magnetic Field Model**
2405.12754v1 by Yutao Du, Qin Li, Raghav Gnanasambandam, Mengnan Du, Haimin Wang, Bo Shen

Studying the sun's outer atmosphere is challenging due to its complex
magnetic fields impacting solar activities. Magnetohydrodynamics (MHD)
simulations help model these interactions but are extremely time-consuming
(usually on a scale of days). Our research applies the Fourier Neural Operator
(FNO) to accelerate the coronal magnetic field modeling, specifically, the
Bifrost MHD model. We apply Tensorized FNO (TFNO) to generate solutions from
partial differential equations (PDEs) over a 3D domain efficiently. TFNO's
performance is compared with other deep learning methods, highlighting its
accuracy and scalability. Physics analysis confirms that TFNO is reliable and
capable of accelerating MHD simulations with high precision. This advancement
improves efficiency in data handling, enhances predictive capabilities, and
provides a better understanding of magnetic topologies.

摘要：由於太陽外大氣層複雜的磁場會影響太陽活動，因此研究太陽外大氣層是一項挑戰。磁流體動力學 (MHD) 模擬有助於建立這些交互作用的模型，但極為耗時（通常以天為單位）。我們的研究將傅立葉神經算子 (FNO) 應用於加速日冕磁場建模，特別是 Bifrost MHD 模型。我們應用張量化 FNO (TFNO) 來有效地根據 3D 域上的偏微分方程式 (PDE) 生成解。TFNO 的效能與其他深度學習方法進行比較，突出了它的準確性和可擴充性。物理分析證實 TFNO 是可靠的，並且能夠以高精度加速 MHD 模擬。此進展提升了資料處理的效率，增強了預測能力，並且提供了對磁場拓撲結構的更深入了解。

##### **Generative AI and Large Language Models for Cyber Security: All Insights You Need**
2405.12750v1 by Mohamed Amine Ferrag, Fatima Alwahedi, Ammar Battah, Bilel Cherif, Abdechakour Mechri, Norbert Tihanyi

This paper provides a comprehensive review of the future of cybersecurity
through Generative AI and Large Language Models (LLMs). We explore LLM
applications across various domains, including hardware design security,
intrusion detection, software engineering, design verification, cyber threat
intelligence, malware detection, and phishing detection. We present an overview
of LLM evolution and its current state, focusing on advancements in models such
as GPT-4, GPT-3.5, Mixtral-8x7B, BERT, Falcon2, and LLaMA. Our analysis extends
to LLM vulnerabilities, such as prompt injection, insecure output handling,
data poisoning, DDoS attacks, and adversarial instructions. We delve into
mitigation strategies to protect these models, providing a comprehensive look
at potential attack scenarios and prevention techniques. Furthermore, we
evaluate the performance of 42 LLM models in cybersecurity knowledge and
hardware security, highlighting their strengths and weaknesses. We thoroughly
evaluate cybersecurity datasets for LLM training and testing, covering the
lifecycle from data creation to usage and identifying gaps for future research.
In addition, we review new strategies for leveraging LLMs, including techniques
like Half-Quadratic Quantization (HQQ), Reinforcement Learning with Human
Feedback (RLHF), Direct Preference Optimization (DPO), Quantized Low-Rank
Adapters (QLoRA), and Retrieval-Augmented Generation (RAG). These insights aim
to enhance real-time cybersecurity defenses and improve the sophistication of
LLM applications in threat detection and response. Our paper provides a
foundational understanding and strategic direction for integrating LLMs into
future cybersecurity frameworks, emphasizing innovation and robust model
deployment to safeguard against evolving cyber threats.

摘要：本文全面探討了透過生成式 AI 和大型語言模型 (LLM) 來保障網路安全的未來。我們探討了 LLM 在各個領域的應用，包括硬體設計安全性、入侵偵測、軟體工程、設計驗證、網路威脅情報、惡意軟體偵測和網路釣魚偵測。我們概述了 LLM 的演進及其現況，重點關注 GPT-4、GPT-3.5、Mixtral-8x7B、BERT、Falcon2 和 LLaMA 等模型的進展。我們的分析延伸到 LLM 的漏洞，例如提示注入、不安全的輸出處理、資料中毒、DDoS 攻擊和對抗性指令。我們深入探討了保護這些模型的緩解策略，全面了解潛在的攻擊情境和預防技術。此外，我們評估了 42 個 LLM 模型在網路安全知識和硬體安全性方面的效能，重點說明它們的優點和缺點。我們徹底評估了 LLM 訓練和測試的網路安全資料集，涵蓋從資料建立到使用的生命週期，並找出未來研究的差距。此外，我們回顧了利用 LLM 的新策略，包括半二次量化 (HQQ)、具有人類回饋的強化學習 (RLHF)、直接偏好最佳化 (DPO)、量化低秩適配器 (QLoRA) 和檢索增強生成 (RAG) 等技術。這些見解旨在增強即時網路安全防禦，並提升 LLM 應用在威脅偵測和回應方面的複雜性。我們的論文提供了基礎理解和策略方向，用於將 LLM 整合到未來的網路安全架構中，強調創新和穩健的模型部署，以防範不斷演變的網路威脅。

##### **The Echoes of Multilinguality: Tracing Cultural Value Shifts during LM Fine-tuning**
2405.12744v1 by Rochelle Choenni, Anne Lauscher, Ekaterina Shutova

Texts written in different languages reflect different culturally-dependent
beliefs of their writers. Thus, we expect multilingual LMs (MLMs), that are
jointly trained on a concatenation of text in multiple languages, to encode
different cultural values for each language. Yet, as the 'multilinguality' of
these LMs is driven by cross-lingual sharing, we also have reason to belief
that cultural values bleed over from one language into another. This limits the
use of MLMs in practice, as apart from being proficient in generating text in
multiple languages, creating language technology that can serve a community
also requires the output of LMs to be sensitive to their biases (Naous et al.,
2023). Yet, little is known about how cultural values emerge and evolve in MLMs
(Hershcovich et al., 2022a). We are the first to study how languages can exert
influence on the cultural values encoded for different test languages, by
studying how such values are revised during fine-tuning. Focusing on the
fine-tuning stage allows us to study the interplay between value shifts when
exposed to new linguistic experience from different data sources and languages.
Lastly, we use a training data attribution method to find patterns in the
fine-tuning examples, and the languages that they come from, that tend to
instigate value shifts.

摘要：以不同語言寫成的文本反映了作者不同的文化依賴性信念。因此，我們預期在多種語言文本串接上進行聯合訓練的多語言 LM（MLM），會針對每種語言編碼不同的文化價值。然而，由於這些 LM 的「多語言性」是由跨語言共享驅動的，我們也有理由相信文化價值會從一種語言滲透到另一種語言。這限制了 MLM 在實務上的使用，因為除了能熟練生成多種語言的文本之外，創造能服務社群的語言技術也要求 LM 的輸出對其偏見敏感（Naous et al., 2023）。然而，我們對文化價值如何在 MLM 中出現和演化知之甚少（Hershcovich et al., 2022a）。我們率先研究語言如何對針對不同測試語言編碼的文化價值施加影響，方法是研究這些價值在微調過程中如何被修正。專注於微調階段讓我們得以研究當接觸到來自不同資料來源和語言的新語言經驗時，價值轉變之間的交互作用。最後，我們使用訓練資料歸因方法來找出微調範例中的模式，以及它們來自的語言，這些模式往往會引發價值轉變。

##### **RecGPT: Generative Pre-training for Text-based Recommendation**
2405.12715v1 by Hoang Ngo, Dat Quoc Nguyen

We present the first domain-adapted and fully-trained large language model,
RecGPT-7B, and its instruction-following variant, RecGPT-7B-Instruct, for
text-based recommendation. Experimental results on rating prediction and
sequential recommendation tasks show that our model, RecGPT-7B-Instruct,
outperforms previous strong baselines. We are releasing our RecGPT models as
well as their pre-training and fine-tuning datasets to facilitate future
research and downstream applications in text-based recommendation. Public
"huggingface" links to our RecGPT models and datasets are available at:
https://github.com/VinAIResearch/RecGPT

摘要：我們展示第一個領域適應且完全訓練好的大型語言模型 RecGPT-7B，以及其遵循指令的變體 RecGPT-7B-Instruct，用於基於文字的推薦。評分預測和順序推薦任務的實驗結果表明，我們的模型 RecGPT-7B-Instruct 優於先前的強大基準。我們正在發布我們的 RecGPT 模型以及它們的預訓練和微調數據集，以促進未來基於文字的推薦的研究和下游應用。可在以下網址取得我們 RecGPT 模型和數據集的公開「huggingface」連結：https://github.com/VinAIResearch/RecGPT

##### **From Human-to-Human to Human-to-Bot Conversations in Software Engineering**
2405.12712v1 by Ranim Khojah, Francisco Gomes de Oliveira Neto, Philipp Leitner

Software developers use natural language to interact not only with other
humans, but increasingly also with chatbots. These interactions have different
properties and flow differently based on what goal the developer wants to
achieve and who they interact with. In this paper, we aim to understand the
dynamics of conversations that occur during modern software development after
the integration of AI and chatbots, enabling a deeper recognition of the
advantages and disadvantages of including chatbot interactions in addition to
human conversations in collaborative work. We compile existing conversation
attributes with humans and NLU-based chatbots and adapt them to the context of
software development. Then, we extend the comparison to include LLM-powered
chatbots based on an observational study. We present similarities and
differences between human-to-human and human-to-bot conversations, also
distinguishing between NLU- and LLM-based chatbots. Furthermore, we discuss how
understanding the differences among the conversation styles guides the
developer on how to shape their expectations from a conversation and
consequently support the communication within a software team. We conclude that
the recent conversation styles that we observe with LLM-chatbots can not
replace conversations with humans due to certain attributes regarding social
aspects despite their ability to support productivity and decrease the
developers' mental load.

摘要：軟體開發人員不僅使用自然語言與其他人互動，也越來越常與聊天機器人互動。這些互動具有不同的屬性，並且根據開發人員想要達成的目標和他們互動的對象，而有不同的流程。在本文中，我們旨在了解在整合 AI 和聊天機器人後，現代軟體開發中發生的對話動態，進一步了解在協作工作中加入聊天機器人互動的優缺點。我們編譯了與人類和基於 NLU 的聊天機器人的現有對話屬性，並將它們調整到軟體開發的脈絡中。然後，我們根據觀察研究，將比較擴展到包括由 LLM 驅動的聊天機器人。我們呈現人對人與人對機器人對話之間的相似性和差異，也區分基於 NLU 和 LLM 的聊天機器人。此外，我們討論如何了解對話風格之間的差異，引導開發人員如何塑造他們對對話的期望，並因此支援軟體團隊內的溝通。我們得出結論，我們在 LLM 聊天機器人中觀察到的最新對話風格，儘管它們有支援生產力和降低開發人員心理負擔的能力，但由於某些關於社交方面的屬性，無法取代與人類的對話。

##### **A Masked Semi-Supervised Learning Approach for Otago Micro Labels Recognition**
2405.12711v1 by Meng Shang, Lenore Dedeyne, Jolan Dupont, Laura Vercauteren, Nadjia Amini, Laurence Lapauw, Evelien Gielen, Sabine Verschueren, Carolina Varon, Walter De Raedt, Bart Vanrumste

The Otago Exercise Program (OEP) serves as a vital rehabilitation initiative
for older adults, aiming to enhance their strength and balance, and
consequently prevent falls. While Human Activity Recognition (HAR) systems have
been widely employed in recognizing the activities of individuals, existing
systems focus on the duration of macro activities (i.e. a sequence of
repetitions of the same exercise), neglecting the ability to discern micro
activities (i.e. the individual repetitions of the exercises), in the case of
OEP. This study presents a novel semi-supervised machine learning approach
aimed at bridging this gap in recognizing the micro activities of OEP. To
manage the limited dataset size, our model utilizes a Transformer encoder for
feature extraction, subsequently classified by a Temporal Convolutional Network
(TCN). Simultaneously, the Transformer encoder is employed for masked
unsupervised learning to reconstruct input signals. Results indicate that the
masked unsupervised learning task enhances the performance of the supervised
learning (classification task), as evidenced by f1-scores surpassing the
clinically applicable threshold of 0.8. From the micro activities, two
clinically relevant outcomes emerge: counting the number of repetitions of each
exercise and calculating the velocity during chair rising. These outcomes
enable the automatic monitoring of exercise intensity and difficulty in the
daily lives of older adults.

摘要：奧塔哥運動計畫 (OEP) 是一項重要的復健計畫，
旨在增強老年人的肌力和平衡，
進而預防跌倒。儘管人類活動辨識 (HAR) 系統
已被廣泛用於辨識個人的活動，現有的
系統著重於巨觀活動的持續時間（即
重複相同運動的順序），忽略了辨別微觀
活動（即運動的個別重複）的能力，就
OEP 而言。本研究提出了一種新穎的半監督機器學習方法，
旨在彌合辨識 OEP 微觀活動的差距。為了
管理有限的資料集大小，我們的模型利用 Transformer 編碼器進行
特徵萃取，隨後由時序卷積網路 (TCN) 分類。同時，Transformer 編碼器被用於遮蔽無監督學習以重建輸入訊號。結果表明，遮蔽無監督學習任務增強了監督式學習（分類任務）的效能，這由 f1 分數超過 0.8 的臨床適用閾值所證實。從微觀活動中，出現了兩個臨床上相關的結果：計算每個運動的重複次數和計算椅子上升時的速率。這些結果能自動監控老年人日常生活中的運動強度和難度。

##### **Multimodal Adaptive Inference for Document Image Classification with Anytime Early Exiting**
2405.12705v1 by Omar Hamed, Souhail Bakkali, Marie-Francine Moens, Matthew Blaschko, Jordy Van Landeghem

This work addresses the need for a balanced approach between performance and
efficiency in scalable production environments for visually-rich document
understanding (VDU) tasks. Currently, there is a reliance on large document
foundation models that offer advanced capabilities but come with a heavy
computational burden. In this paper, we propose a multimodal early exit (EE)
model design that incorporates various training strategies, exit layer types
and placements. Our goal is to achieve a Pareto-optimal balance between
predictive performance and efficiency for multimodal document image
classification. Through a comprehensive set of experiments, we compare our
approach with traditional exit policies and showcase an improved
performance-efficiency trade-off. Our multimodal EE design preserves the
model's predictive capabilities, enhancing both speed and latency. This is
achieved through a reduction of over 20% in latency, while fully retaining the
baseline accuracy. This research represents the first exploration of multimodal
EE design within the VDU community, highlighting as well the effectiveness of
calibration in improving confidence scores for exiting at different layers.
Overall, our findings contribute to practical VDU applications by enhancing
both performance and efficiency.

摘要：這項工作探討了在視覺豐富文件理解 (VDU) 任務的可擴充生產環境中，在效能和效率之間取得平衡方法的必要性。目前，我們依賴於大型文件基礎模型，這些模型提供進階功能，但伴隨著繁重的運算負擔。在本文中，我們提出多模態早期退出 (EE) 模型設計，它結合了各種訓練策略、退出層類型和配置。我們的目標是針對多模態文件影像分類，在預測效能和效率之間取得帕雷托最優平衡。透過一組全面的實驗，我們將我們的方法與傳統退出政策進行比較，並展示出改良的效能效率權衡。我們的多模態 EE 設計保留了模型的預測能力，同時提升了速度和延遲。這是透過減少超過 20% 的延遲來實現的，同時完全保留基準準確度。這項研究代表了 VDU 社群中首次探討多模態 EE 設計，同時強調了校正對於改進在不同層退出時的信心分數的有效性。總體而言，我們的發現透過提升效能和效率，為實際的 VDU 應用做出了貢獻。

##### **OLAPH: Improving Factuality in Biomedical Long-form Question Answering**
2405.12701v1 by Minbyul Jeong, Hyeon Hwang, Chanwoong Yoon, Taewhoo Lee, Jaewoo Kang

In the medical domain, numerous scenarios necessitate the long-form
generation ability of large language models (LLMs). Specifically, when
addressing patients' questions, it is essential that the model's response
conveys factual claims, highlighting the need for an automated method to
evaluate those claims. Thus, we introduce MedLFQA, a benchmark dataset
reconstructed using long-form question-answering datasets related to the
biomedical domain. We use MedLFQA to facilitate the automatic evaluations of
factuality. We also propose OLAPH, a simple and novel framework that enables
the improvement of factuality through automatic evaluations. The OLAPH
framework iteratively trains LLMs to mitigate hallucinations using sampling
predictions and preference optimization. In other words, we iteratively set the
highest-scoring response as a preferred response derived from sampling
predictions and train LLMs to align with the preferred response that improves
factuality. We highlight that, even on evaluation metrics not used during
training, LLMs trained with our OLAPH framework demonstrate significant
performance improvement in factuality. Our findings reveal that a 7B LLM
trained with our OLAPH framework can provide long answers comparable to the
medical experts' answers in terms of factuality. We believe that our work could
shed light on gauging the long-text generation ability of LLMs in the medical
domain. Our code and datasets are available at
https://github.com/dmis-lab/OLAPH}{https://github.com/dmis-lab/OLAPH.

摘要：<paragraph>在醫療領域，許多情境都需要大型語言模型 (LLM) 產生長篇文字的能力。具體來說，在回答患者問題時，模型的回應傳達事實聲明至關重要，這突顯了自動化方法來評估這些聲明的必要性。因此，我們引入了 MedLFQA，這是一個使用與生物醫學領域相關的長篇問答資料集重建的基準資料集。我們使用 MedLFQA 來促進事實性的自動評估。我們還提出了一個簡單且新穎的框架 OLAPH，它能夠透過自動評估來改善事實性。OLAPH 框架反覆訓練 LLM，以使用抽樣預測和偏好最佳化來減輕幻覺。換句話說，我們反覆將最高分回應設定為從抽樣預測中得出的首選回應，並訓練 LLM 與改善事實性的首選回應保持一致。我們強調，即使在訓練期間未使用評估指標，使用我們的 OLAPH 框架訓練的 LLM 也在事實性方面表現出顯著的進步。我們的研究結果表明，使用我們的 OLAPH 框架訓練的 7B LLM 在事實性方面可以提供與醫療專家答案相當的長篇回答。我們相信，我們的研究可以幫助評估 LLM 在醫療領域的長篇文字產生能力。我們的程式碼和資料集可在 https://github.com/dmis-lab/OLAPH 獲得。</paragraph>

##### **Spotting AI's Touch: Identifying LLM-Paraphrased Spans in Text**
2405.12689v1 by Yafu Li, Zhilin Wang, Leyang Cui, Wei Bi, Shuming Shi, Yue Zhang

AI-generated text detection has attracted increasing attention as powerful
language models approach human-level generation. Limited work is devoted to
detecting (partially) AI-paraphrased texts. However, AI paraphrasing is
commonly employed in various application scenarios for text refinement and
diversity. To this end, we propose a novel detection framework, paraphrased
text span detection (PTD), aiming to identify paraphrased text spans within a
text. Different from text-level detection, PTD takes in the full text and
assigns each of the sentences with a score indicating the paraphrasing degree.
We construct a dedicated dataset, PASTED, for paraphrased text span detection.
Both in-distribution and out-of-distribution results demonstrate the
effectiveness of PTD models in identifying AI-paraphrased text spans.
Statistical and model analysis explains the crucial role of the surrounding
context of the paraphrased text spans. Extensive experiments show that PTD
models can generalize to versatile paraphrasing prompts and multiple
paraphrased text spans. We release our resources at
https://github.com/Linzwcs/PASTED.

摘要：AI 生成的文字偵測已吸引越來越多的關注，因為強大的語言模型接近人類層級的生成。有限的工作致力於偵測（部分）AI 改寫的文字。然而，AI 改寫通常用於各種應用場景中，以進行文字精煉和多元化。為此，我們提出一個新穎的偵測架構，改寫文字跨距偵測 (PTD)，旨在識別文字中的改寫文字跨距。不同於文字層級偵測，PTD 會輸入完整文字，並為每個句子指定一個分數，表示改寫程度。我們建構了一個專門的資料集 PASTED，用於改寫文字跨距偵測。分佈內和分佈外結果都證明了 PTD 模型在識別 AI 改寫文字跨距方面的有效性。統計和模型分析說明了改寫文字跨距周圍環境的重要角色。廣泛的實驗表明，PTD 模型可以概括為多功能改寫提示和多個改寫文字跨距。我們在 https://github.com/Linzwcs/PASTED 上發布我們的資源。

##### **A Survey on Multi-modal Machine Translation: Tasks, Methods and Challenges**
2405.12669v1 by Huangjun Shen, Liangying Shao, Wenbo Li, Zhibin Lan, Zhanyu Liu, Jinsong Su

In recent years, multi-modal machine translation has attracted significant
interest in both academia and industry due to its superior performance. It
takes both textual and visual modalities as inputs, leveraging visual context
to tackle the ambiguities in source texts. In this paper, we begin by offering
an exhaustive overview of 99 prior works, comprehensively summarizing
representative studies from the perspectives of dominant models, datasets, and
evaluation metrics. Afterwards, we analyze the impact of various factors on
model performance and finally discuss the possible research directions for this
task in the future. Over time, multi-modal machine translation has developed
more types to meet diverse needs. Unlike previous surveys confined to the early
stage of multi-modal machine translation, our survey thoroughly concludes these
emerging types from different aspects, so as to provide researchers with a
better understanding of its current state.

摘要：近年來，多模態機器翻譯由於其卓越的性能，在學術界和產業界都引起了極大的興趣。它將文本和視覺模式作為輸入，利用視覺語境來解決源文本中的歧義。在本文中，我們首先提供 99 項先前工作的詳盡概述，全面總結了從主要模型、資料集和評估指標角度的代表性研究。之後，我們分析了各種因素對模型效能的影響，最後討論了未來此任務可能的研究方向。隨著時間推移，多模態機器翻譯已發展出更多類型，以滿足不同的需求。與先前僅限於多模態機器翻譯早期階段的調查不同，我們的調查從不同面向徹底總結了這些新興類型，以便讓研究人員更了解其現狀。

##### **Mitigating Overconfidence in Out-of-Distribution Detection by Capturing Extreme Activations**
2405.12658v1 by Mohammad Azizmalayeri, Ameen Abu-Hanna, Giovanni Cinà

Detecting out-of-distribution (OOD) instances is crucial for the reliable
deployment of machine learning models in real-world scenarios. OOD inputs are
commonly expected to cause a more uncertain prediction in the primary task;
however, there are OOD cases for which the model returns a highly confident
prediction. This phenomenon, denoted as "overconfidence", presents a challenge
to OOD detection. Specifically, theoretical evidence indicates that
overconfidence is an intrinsic property of certain neural network
architectures, leading to poor OOD detection. In this work, we address this
issue by measuring extreme activation values in the penultimate layer of neural
networks and then leverage this proxy of overconfidence to improve on several
OOD detection baselines. We test our method on a wide array of experiments
spanning synthetic data and real-world data, tabular and image datasets,
multiple architectures such as ResNet and Transformer, different training loss
functions, and include the scenarios examined in previous theoretical work.
Compared to the baselines, our method often grants substantial improvements,
with double-digit increases in OOD detection AUC, and it does not damage
performance in any scenario.

摘要：偵測出分布 (OOD) 範例對於機器學習模型在真實世界場景中可靠地部署至關重要。OOD 輸入通常預期會在主要任務中造成更不確定的預測；然而，有些 OOD 案例會讓模型回傳高度自信的預測。這個現象稱為「過度自信」，對 OOD 偵測構成挑戰。具體來說，理論證據指出，過度自信是特定神經網路架構的內在屬性，導致 OOD 偵測不佳。在這項工作中，我們透過測量神經網路倒數第二層中的極端啟用值來解決這個問題，然後利用這個過度自信的代理來改善幾個 OOD 偵測基準。我們在涵蓋合成資料和真實世界資料、表格和影像資料集、多種架構（例如 ResNet 和 Transformer）、不同訓練損失函數的各種實驗中測試方法，並納入先前理論工作中檢驗的場景。與基準相比，我們的模型通常能大幅改善，OOD 偵測 AUC 增加兩位數，且不會損害任何場景的效能。

##### **Retrieval-Augmented Language Model for Extreme Multi-Label Knowledge Graph Link Prediction**
2405.12656v1 by Yu-Hsiang Lin, Huang-Ting Shieh, Chih-Yu Liu, Kuang-Ting Lee, Hsiao-Cheng Chang, Jing-Lun Yang, Yu-Sheng Lin

Extrapolation in Large language models (LLMs) for open-ended inquiry
encounters two pivotal issues: (1) hallucination and (2) expensive training
costs. These issues present challenges for LLMs in specialized domains and
personalized data, requiring truthful responses and low fine-tuning costs.
Existing works attempt to tackle the problem by augmenting the input of a
smaller language model with information from a knowledge graph (KG). However,
they have two limitations: (1) failing to extract relevant information from a
large one-hop neighborhood in KG and (2) applying the same augmentation
strategy for KGs with different characteristics that may result in low
performance. Moreover, open-ended inquiry typically yields multiple responses,
further complicating extrapolation. We propose a new task, the extreme
multi-label KG link prediction task, to enable a model to perform extrapolation
with multiple responses using structured real-world knowledge. Our retriever
identifies relevant one-hop neighbors by considering entity, relation, and
textual data together. Our experiments demonstrate that (1) KGs with different
characteristics require different augmenting strategies, and (2) augmenting the
language model's input with textual data improves task performance
significantly. By incorporating the retrieval-augmented framework with KG, our
framework, with a small parameter size, is able to extrapolate based on a given
KG. The code can be obtained on GitHub:
https://github.com/exiled1143/Retrieval-Augmented-Language-Model-for-Multi-Label-Knowledge-Graph-Link-Prediction.git

摘要：<paragraph>大型語言模型 (LLM) 中用於開放式探究的推斷會遭遇兩個關鍵問題：(1) 幻覺和 (2) 昂貴的訓練成本。這些問題為專門領域和個人化數據中的 LLM 帶來挑戰，需要真實的回應和低微調成本。現有作品嘗試通過使用來自知識圖 (KG) 的資訊擴充較小型語言模型的輸入來解決問題。然而，它們有兩個限制：(1) 無法從 KG 中的廣大一跳鄰域中提取相關資訊，以及 (2) 對具有不同特徵的 KG 應用相同的擴充策略，這可能會導致低效能。此外，開放式探究通常會產生多重回應，進一步複雜化推斷。我們提出一個新任務，即極端多標籤 KG 連結預測任務，以使模型能夠使用結構化的真實世界知識執行具有多重回應的推斷。我們的檢索器通過同時考慮實體、關係和文字資料來識別相關的一跳鄰居。我們的實驗證明：(1) 具有不同特徵的 KG 需要不同的擴充策略，以及 (2) 使用文字資料擴充語言模型的輸入會顯著改善任務效能。透過將檢索擴充框架與 KG 整合，我們的框架在參數規模較小的情況下，能夠根據給定的 KG 進行推斷。代碼可以在 GitHub 上取得：
https://github.com/exiled1143/Retrieval-Augmented-Language-Model-for-Multi-Label-Knowledge-Graph-Link-Prediction.git</paragraph>

##### **Scene Graph Generation Strategy with Co-occurrence Knowledge and Learnable Term Frequency**
2405.12648v1 by Hyeongjin Kim, Sangwon Kim, Dasom Ahn, Jong Taek Lee, Byoung Chul Ko

Scene graph generation (SGG) is an important task in image understanding
because it represents the relationships between objects in an image as a graph
structure, making it possible to understand the semantic relationships between
objects intuitively. Previous SGG studies used a message-passing neural
networks (MPNN) to update features, which can effectively reflect information
about surrounding objects. However, these studies have failed to reflect the
co-occurrence of objects during SGG generation. In addition, they only
addressed the long-tail problem of the training dataset from the perspectives
of sampling and learning methods. To address these two problems, we propose
CooK, which reflects the Co-occurrence Knowledge between objects, and the
learnable term frequency-inverse document frequency (TF-l-IDF) to solve the
long-tail problem. We applied the proposed model to the SGG benchmark dataset,
and the results showed a performance improvement of up to 3.8% compared with
existing state-of-the-art models in SGGen subtask. The proposed method exhibits
generalization ability from the results obtained, showing uniform performance
improvement for all MPNN models.

摘要：場景圖生成（SGG）是影像理解中的一項重要任務，因為它將影像中物體之間的關係表示為圖形結構，讓直觀地理解物體之間的語義關係成為可能。先前的 SGG 研究使用訊息傳遞神經網路（MPNN）來更新特徵，可以有效反映周圍物體的資訊。然而，這些研究未能反映物體在 SGG 生成期間的共現性。此外，它們僅從取樣和學習方法的角度來解決訓練資料集的長尾問題。為了解決這兩個問題，我們提出了 CooK，它反映了物體之間的共現知識，以及可學習的詞頻-逆文件頻率（TF-l-IDF）來解決長尾問題。我們將所提出的模型應用於 SGG 基準資料集，結果顯示與 SGGen 子任務中現有的最先進模型相比，效能提升了 3.8%。所提出的方法從獲得的結果中展現出概化能力，顯示所有 MPNN 模型的效能都有均勻的提升。

##### **Exploration of Masked and Causal Language Modelling for Text Generation**
2405.12630v1 by Nicolo Micheletti, Samuel Belkadi, Lifeng Han, Goran Nenadic

Large Language Models (LLMs) have revolutionised the field of Natural
Language Processing (NLP) and have achieved state-of-the-art performance in
practically every task in this field. However, the prevalent approach used in
text generation, Causal Language Modelling (CLM), which generates text
sequentially from left to right, inherently limits the freedom of the model,
which does not decide when and where each token is generated. In contrast,
Masked Language Modelling (MLM), primarily used for language understanding
tasks, can generate tokens anywhere in the text and any order. This paper
conducts an extensive comparison of MLM and CLM approaches for text generation
tasks. To do so, we pre-train several language models of comparable sizes on
three different datasets, namely 1) medical discharge summaries, 2) movie plot
synopses, and 3) authorship verification datasets. To assess the quality of the
generations, we first employ quantitative metrics and then perform a
qualitative human evaluation to analyse coherence and grammatical correctness.
In addition, we evaluate the usefulness of the generated texts by using them in
three different downstream tasks: 1) Entity Recognition, 2) Text
Classification, and 3) Authorship Verification. The results show that MLM
consistently outperforms CLM in text generation across all datasets, with
higher quantitative scores and better coherence in the generated text. The
study also finds \textit{no strong correlation} between the quality of the
generated text and the performance of the models in the downstream tasks. With
this study, we show that MLM for text generation has great potential for future
research and provides direction for future studies in this area.

摘要：<paragraph>大型語言模型 (LLM) 徹底改變了自然語言處理 (NLP) 領域，並在該領域的幾乎每一項任務中都達到了最先進的性能。然而，文本生成中使用的流行方法因果語言建模 (CLM)，它從左到右按順序生成文本，從本質上限制了模型的自由度，它不會決定何時何地生成每個符號。相比之下，主要用於語言理解任務的遮罩語言建模 (MLM) 可以按任何順序在文本中的任何位置生成符號。本文對 MLM 和 CLM 方法在文本生成任務中的進行了廣泛比較。為此，我們在三個不同的數據集上預訓練了幾個大小相當的語言模型，即 1) 醫療出院摘要、2) 電影情節簡介和 3) 作者驗證數據集。為了評估生成的質量，我們首先採用定量指標，然後進行定性的人工評估，以分析連貫性和語法正確性。此外，我們通過在三個不同的下游任務中使用生成的文本來評估其有用性：1) 實體識別、2) 文本分類和 3) 作者驗證。結果表明，MLM 在所有數據集上的文本生成中始終優於 CLM，生成的文本具有更高的定量分數和更好的連貫性。該研究還發現生成的文本質量與模型在下游任務中的性能之間\textit{沒有強相關性}。通過這項研究，我們表明文本生成的 MLM 對於未來的研究具有巨大潛力，並為該領域的未來研究提供了方向。</paragraph>

##### **Limits of Theory of Mind Modelling in Dialogue-Based Collaborative Plan Acquisition**
2405.12621v1 by Matteo Bortoletto, Constantin Ruhdorfer, Adnen Abdessaied, Lei Shi, Andreas Bulling

Recent work on dialogue-based collaborative plan acquisition (CPA) has
suggested that Theory of Mind (ToM) modelling can improve missing knowledge
prediction in settings with asymmetric skill-sets and knowledge. Although ToM
was claimed to be important for effective collaboration, its real impact on
this novel task remains under-explored. By representing plans as graphs and by
exploiting task-specific constraints we show that, as performance on CPA nearly
doubles when predicting one's own missing knowledge, the improvements due to
ToM modelling diminish. This phenomenon persists even when evaluating existing
baseline methods. To better understand the relevance of ToM for CPA, we report
a principled performance comparison of models with and without ToM features.
Results across different models and ablations consistently suggest that learned
ToM features are indeed more likely to reflect latent patterns in the data with
no perceivable link to ToM. This finding calls for a deeper understanding of
the role of ToM in CPA and beyond, as well as new methods for modelling and
evaluating mental states in computational collaborative agents.

摘要：<paragraph>最近关于基于对话的协作计划获取 (CPA) 的研究表明，心智理论 (ToM) 建模可以改善在技能和知识不对称的情况下缺失知识的预测。虽然 ToM 被认为对有效的协作很重要，但它对这项新任务的实际影响仍未得到充分探索。通过将计划表示为图表并利用特定于任务的约束，我们表明，当预测自己缺失的知识时，CPA 的性能几乎翻倍，由于 ToM 建模而产生的改进会减少。即使在评估现有的基线方法时，这种现象仍然存在。为了更好地理解 ToM 对 CPA 的相关性，我们报告了有和没有 ToM 特征的模型的原则性性能比较。不同模型和消融的结果一致表明，学习的 ToM 特征实际上更有可能反映数据中的潜在模式，而与 ToM 没有明显联系。这一发现要求我们更深入地了解 ToM 在 CPA 及其之外的作用，以及对计算协作代理中的心理状态进行建模和评估的新方法。</paragraph>

##### **Quantifying Emergence in Large Language Models**
2405.12617v1 by Hang Chen, Xinyu Yang, Jiaying Zhu, Wenya Wang

Emergence, broadly conceptualized as the ``intelligent'' behaviors of LLMs,
has recently been studied and proved challenging to quantify due to the lack of
a measurable definition. Most commonly, it has been estimated statistically
through model performances across extensive datasets and tasks, which consumes
significant resources. In addition, such estimation is difficult to interpret
and may not accurately reflect the models' intrinsic emergence. In this work,
we propose a quantifiable solution for estimating emergence. Inspired by
emergentism in dynamics, we quantify the strength of emergence by comparing the
entropy reduction of the macroscopic (semantic) level with that of the
microscopic (token) level, both of which are derived from the representations
within the transformer block. Using a low-cost estimator, our quantification
method demonstrates consistent behaviors across a suite of LMs (GPT-2, GEMMA,
etc.) under both in-context learning (ICL) and natural sentences. Empirical
results show that (1) our method gives consistent measurements which align with
existing observations based on performance metrics, validating the
effectiveness of our emergence quantification; (2) our proposed metric uncovers
novel emergence patterns such as the correlations between the variance of our
metric and the number of ``shots'' in ICL, which further suggests a new way of
interpreting hallucinations in LLMs; (3) we offer a potential solution towards
estimating the emergence of larger and closed-resource LMs via smaller LMs like
GPT-2. Our codes are available at:
https://github.com/Zodiark-ch/Emergence-of-LLMs/.

摘要：<paragraph>出現，廣泛概念化為 LLM 的「智慧」行為，
最近已被研究並證實難以量化，因為缺乏可衡量的定義。最常見的是，它已透過模型在廣泛的資料集和任務中的表現統計估計，這消耗了大量的資源。此外，這種估計難以解釋，可能無法準確反映模型的內在出現。在這項工作中，我們提出了估計出現的可量化解決方案。受到動力學出現主義的啟發，我們透過比較巨觀（語義）層級和微觀（符號）層級的熵減少來量化出現的強度，兩者都來自於Transformer區塊中的表示。使用低成本估計器，我們的量化方法展示了在情境學習 (ICL) 和自然句子的情況下，在 LMs（GPT-2、GEMMA 等）中的一致行為。實證結果顯示，（1）我們的量化方法與基於效能指標的現有觀察結果一致，驗證了我們出現量化的有效性；（2）我們提出的指標揭示了新的出現模式，例如我們的指標的變異數與 ICL 中「次數」之間的相關性，進一步提出了解釋 LLM 中幻覺的新方法；（3）我們提供了一個潛在的解決方案，透過較小的 LLM（例如 GPT-2）來估計較大且封閉資源的 LLM 的出現。我們的程式碼可在以下位置取得：
https://github.com/Zodiark-ch/Emergence-of-LLMs/.</paragraph>

##### **Tagengo: A Multilingual Chat Dataset**
2405.12612v1 by Peter Devine

Open source large language models (LLMs) have shown great improvements in
recent times. However, many of these models are focused solely on popular
spoken languages. We present a high quality dataset of more than 70k
prompt-response pairs in 74 languages which consist of human generated prompts
and synthetic responses. We use this dataset to train a state-of-the-art open
source English LLM to chat multilingually. We evaluate our model on MT-Bench
chat benchmarks in 6 languages, finding that our multilingual model outperforms
previous state-of-the-art open source LLMs across each language. We further
find that training on more multilingual data is beneficial to the performance
in a chosen target language (Japanese) compared to simply training on only data
in that language. These results indicate the necessity of training on large
amounts of high quality multilingual data to make a more accessible LLM.

摘要：開放原始碼大型語言模型 (LLM) 近期展現出顯著的進步。然而，許多此類模型僅專注於熱門的口語語言。我們提出一個高品質的資料集，其中包含 74 種語言中超過 70k 個提示回應配對，這些配對由人類產生的提示和合成回應組成。我們使用此資料集訓練一個最先進的開放原始碼英文 LLM，以進行多語言聊天。我們在 6 種語言的 MT-Bench 聊天基準上評估我們的模型，發現我們的多語言模型在每種語言中都優於先前的最先進開放原始碼 LLM。我們進一步發現，與僅訓練該語言中的資料相比，訓練更多多語言資料有助於在所選目標語言（日語）中的表現。這些結果表明，需要訓練大量高品質的多語言資料，才能製作出更易於使用的 LLM。

##### **Tiny Refinements Elicit Resilience: Toward Efficient Prefix-Model Against LLM Red-Teaming**
2405.12604v1 by Jiaxu Liu, Xiangyu Yin, Sihao Wu, Jianhong Wang, Meng Fang, Xinping Yi, Xiaowei Huang

With the proliferation of red-teaming strategies for Large Language Models
(LLMs), the deficiency in the literature about improving the safety and
robustness of LLM defense strategies is becoming increasingly pronounced. This
paper introduces the LLM-based \textbf{sentinel} model as a plug-and-play
prefix module designed to reconstruct the input prompt with just a few ($<30$)
additional tokens, effectively reducing toxicity in responses from target LLMs.
The sentinel model naturally overcomes the \textit{parameter inefficiency} and
\textit{limited model accessibility} for fine-tuning large target models. We
employ an interleaved training regimen using Proximal Policy Optimization (PPO)
to optimize both red team and sentinel models dynamically, incorporating a
value head-sharing mechanism inspired by the multi-agent centralized critic to
manage the complex interplay between agents. Our extensive experiments across
text-to-text and text-to-image demonstrate the effectiveness of our approach in
mitigating toxic outputs, even when dealing with larger models like
\texttt{Llama-2}, \texttt{GPT-3.5} and \texttt{Stable-Diffusion}, highlighting
the potential of our framework in enhancing safety and robustness in various
applications.

摘要：隨著大型語言模型（LLM）的紅隊策略擴散，關於改善 LLM 防禦策略安全性與穩健性的文獻不足之處日益明顯。本文介紹基於 LLM 的**哨兵**模型，作為一個即插即用的前綴模組，旨在僅使用少數（$<30$）額外代幣重建輸入提示，有效降低目標 LLM 回應中的毒性。哨兵模型自然克服了微調大型目標模型的**參數效率低下**和**模型可存取性有限**。我們採用穿插訓練方式，使用近端策略最佳化（PPO）動態最佳化紅隊和哨兵模型，並結合受多重代理集中式批評者啟發的價值頭部共享機制，來管理代理之間的複雜交互。我們在文字轉文字和文字轉影像的廣泛實驗中，展示了我們的方法在減輕有毒輸出方面的有效性，即使在處理像 \texttt{Llama-2}、\texttt{GPT-3.5} 和 \texttt{Stable-Diffusion} 等較大型模型時也是如此，突顯了我們的架構在增強各種應用中安全性與穩健性的潛力。

##### **Unlocking Data-free Low-bit Quantization with Matrix Decomposition for KV Cache Compression**
2405.12591v1 by Peiyu Liu, Ze-Feng Gao, Wayne Xin Zhao, Yipeng Ma, Tao Wang, Ji-Rong Wen

Key-value~(KV) caching is an important technique to accelerate the inference
of large language models~(LLMs), but incurs significant memory overhead. To
compress the size of KV cache, existing methods often compromise precision or
require extra data for calibration, limiting their practicality in LLM
deployment. In this paper, we introduce \textbf{DecoQuant}, a novel data-free
low-bit quantization technique based on tensor decomposition methods, to
effectively compress KV cache. Our core idea is to adjust the outlier
distribution of the original matrix by performing tensor decomposition, so that
the quantization difficulties are migrated from the matrix to decomposed local
tensors. Specially, we find that outliers mainly concentrate on small local
tensors, while large tensors tend to have a narrower value range. Based on this
finding, we propose to apply low-bit quantization to the large tensor, while
maintaining high-precision representation for the small tensor. Furthermore, we
utilize the proposed quantization method to compress the KV cache of LLMs to
accelerate the inference and develop an efficient dequantization kernel
tailored specifically for DecoQuant. Through extensive experiments, DecoQuant
demonstrates remarkable efficiency gains, showcasing up to a $\sim$75\%
reduction in memory footprint while maintaining comparable generation quality.

摘要：關鍵值~(KV) 快取是一種加速大型語言模型~(LLM) 推論的重要技術，但會造成顯著的記憶體開銷。為了壓縮 KV 快取的大小，現有方法通常會折衷精度或需要額外的校正資料，這會限制它們在 LLM 部署中的實用性。在本文中，我們介紹了 \textbf{DecoQuant}，這是一種基於張量分解方法的新型無資料低位元量化技術，可有效壓縮 KV 快取。我們的核心概念是透過執行張量分解來調整原始矩陣的異常值分佈，以便將量化難度從矩陣轉移到分解的局部張量。特別是，我們發現異常值主要集中在小型局部張量上，而大型張量往往具有較窄的值域。根據這個發現，我們建議將低位元量化應用於大型張量，同時維持小型張量的精確度表示。此外，我們利用所提出的量化方法來壓縮 LLM 的 KV 快取，以加速推論，並開發了一個專門針對 DecoQuant 的高效去量化核心。透過廣泛的實驗，DecoQuant 展示了顯著的效率提升，展示出記憶體使用量減少了約 $\sim$75%，同時維持了可比較的產生品質。

##### **Mining the Explainability and Generalization: Fact Verification Based on Self-Instruction**
2405.12579v1 by Guangyao Lu, Yulin Liu

Fact-checking based on commercial LLMs has become mainstream. Although these
methods offer high explainability, it falls short in accuracy compared to
traditional fine-tuning approaches, and data security is also a significant
concern. In this paper, we propose a self-instruction based fine-tuning
approach for fact-checking that balances accuracy and explainability. Our
method consists of Data Augmentation and Improved DPO fine-tuning. The former
starts by instructing the model to generate both positive and negative
explanations based on claim-evidence pairs and labels, then sampling the
dataset according to our customized difficulty standards. The latter employs
our proposed improved DPO to fine-tune the model using the generated samples.
We fine-tune the smallest-scale LLaMA-7B model and evaluate it on the
challenging fact-checking datasets FEVEROUS and HOVER, utilizing four
fine-tuning methods and three few-shot learning methods for comparison. The
experiments demonstrate that our approach not only retains accuracy comparable
to, or even surpassing, traditional fine-tuning methods, but also generates
fluent explanation text. Moreover, it also exhibit high generalization
performance. Our method is the first to leverage self-supervised learning for
fact-checking and innovatively combines contrastive learning and improved DPO
in fine-tuning LLMs, as shown in the experiments.

摘要：基於商業 LLM 的事實查核已成為主流。儘管這些方法提供了高度的可解釋性，但與傳統的微調方法相比，其準確性較差，而且資料安全性也是一個重大的問題。在本文中，我們提出了一種基於自教學的微調方法，用於在準確性和可解釋性之間取得平衡。我們的做法包括資料擴充和改進的 DPO 微調。前者首先指導模型根據聲明-證據對和標籤生成正面和負面的解釋，然後根據我們自訂的難度標準對資料集進行抽樣。後者採用我們提出的改進 DPO 來使用生成的樣本微調模型。我們微調了最小規模的 LLaMA-7B 模型，並在具有挑戰性的事實查核資料集 FEVEROUS 和 HOVER 上對其進行評估，利用四種微調方法和三種少樣本學習方法進行比較。實驗表明，我們的做法不僅保持了與傳統微調方法相當甚至更高的準確性，而且還生成了流暢的解釋文字。此外，它還表現出很高的泛化效能。我們的做法是第一個利用自我監督學習進行事實查核，並在微調 LLM 中創新地結合了對比學習和改進的 DPO，如實驗所示。

##### **ProtT3: Protein-to-Text Generation for Text-based Protein Understanding**
2405.12564v1 by Zhiyuan Liu, An Zhang, Hao Fei, Enzhi Zhang, Xiang Wang, Kenji Kawaguchi, Tat-Seng Chua

Language Models (LMs) excel in understanding textual descriptions of
proteins, as evident in biomedical question-answering tasks. However, their
capability falters with raw protein data, such as amino acid sequences, due to
a deficit in pretraining on such data. Conversely, Protein Language Models
(PLMs) can understand and convert protein data into high-quality
representations, but struggle to process texts. To address their limitations,
we introduce ProtT3, a framework for Protein-to-Text Generation for Text-based
Protein Understanding. ProtT3 empowers an LM to understand protein sequences of
amino acids by incorporating a PLM as its protein understanding module,
enabling effective protein-to-text generation. This collaboration between PLM
and LM is facilitated by a cross-modal projector (i.e., Q-Former) that bridges
the modality gap between the PLM's representation space and the LM's input
space. Unlike previous studies focusing on protein property prediction and
protein-text retrieval, we delve into the largely unexplored field of
protein-to-text generation. To facilitate comprehensive benchmarks and promote
future research, we establish quantitative evaluations for protein-text
modeling tasks, including protein captioning, protein question-answering, and
protein-text retrieval. Our experiments show that ProtT3 substantially
surpasses current baselines, with ablation studies further highlighting the
efficacy of its core components. Our code is available at
https://github.com/acharkq/ProtT3.

摘要：語言模型 (LM) 擅長理解蛋白質的文字描述，這在生物醫學問題解答任務中很明顯。然而，由於缺乏此類數據的預訓練，它們在處理原始蛋白質數據（例如胺基酸序列）時會出現能力不足的情況。相反地，蛋白質語言模型 (PLM) 可以理解並將蛋白質數據轉換為高品質的表示，但難以處理文本。為了解決它們的限制，我們引入了 ProtT3，一個蛋白質到文本生成框架，用於基於文本的蛋白質理解。ProtT3 透過將 PLM 納入其蛋白質理解模組，賦予 LM 理解胺基酸蛋白質序列的能力，進而能有效地進行蛋白質到文本的生成。PLM 和 LM 之間的這種協作是由跨模態投影器（即 Q-Former）促成的，它彌合了 PLM 的表示空間和 LM 的輸入空間之間的模態差距。與先前專注於蛋白質屬性預測和蛋白質到文本檢索的研究不同，我們深入探討了蛋白質到文本生成的廣闊未探索領域。為了促進全面的基準測試和未來的研究，我們為蛋白質到文本建模任務（包括蛋白質標註、蛋白質問題解答和蛋白質到文本檢索）建立了定量評估。我們的實驗表明，ProtT3 明顯優於目前的基準，消融研究進一步突出了其核心組件的功效。我們的程式碼可在 https://github.com/acharkq/ProtT3 取得。

##### **DrHouse: An LLM-empowered Diagnostic Reasoning System through Harnessing Outcomes from Sensor Data and Expert Knowledge**
2405.12541v1 by Bufang Yang, Siyang Jiang, Lilin Xu, Kaiwei Liu, Hai Li, Guoliang Xing, Hongkai Chen, Xiaofan Jiang, Zhenyu Yan

Large language models (LLMs) have the potential to transform digital
healthcare, as evidenced by recent advances in LLM-based virtual doctors.
However, current approaches rely on patient's subjective descriptions of
symptoms, causing increased misdiagnosis. Recognizing the value of daily data
from smart devices, we introduce a novel LLM-based multi-turn consultation
virtual doctor system, DrHouse, which incorporates three significant
contributions: 1) It utilizes sensor data from smart devices in the diagnosis
process, enhancing accuracy and reliability. 2) DrHouse leverages continuously
updating medical databases such as Up-to-Date and PubMed to ensure our model
remains at diagnostic standard's forefront. 3) DrHouse introduces a novel
diagnostic algorithm that concurrently evaluates potential diseases and their
likelihood, facilitating more nuanced and informed medical assessments. Through
multi-turn interactions, DrHouse determines the next steps, such as accessing
daily data from smart devices or requesting in-lab tests, and progressively
refines its diagnoses. Evaluations on three public datasets and our
self-collected datasets show that DrHouse can achieve up to an 18.8% increase
in diagnosis accuracy over the state-of-the-art baselines. The results of a
32-participant user study show that 75% medical experts and 91.7% patients are
willing to use DrHouse.

摘要：大型語言模型 (LLM) 有潛力轉變數位醫療保健，這點從 LLM 為基礎的虛擬醫師最近的進展中就能看出。然而，目前的做法依賴於患者主觀的症狀描述，導致誤診增加。我們認識到來自智慧裝置的每日資料價值，因此我們引進一個新穎的 LLM 為基礎的多輪諮詢虛擬醫師系統 DrHouse，它包含三個重要的貢獻：1) 它在診斷過程中利用來自智慧裝置的感測器資料，提升準確度和可靠度。2) DrHouse 充分利用持續更新的醫療資料庫，例如 Up-to-Date 和 PubMed，以確保我們的模型維持在診斷標準的最前線。3) DrHouse 引進一種新穎的診斷演算法，它同時評估潛在疾病及其可能性，促進更細緻且明智的醫療評估。透過多輪互動，DrHouse 決定下一步，例如取得來自智慧裝置的每日資料或要求實驗室檢驗，並逐步改善其診斷。針對三個公開資料集和我們自行收集的資料集進行評估顯示，DrHouse 在診斷準確度方面可以比現有最先進的基準線提高 18.8%。一個有 32 位參與者的使用者研究結果顯示，75% 的醫療專家和 91.7% 的患者願意使用 DrHouse。

##### **PyramidInfer: Pyramid KV Cache Compression for High-throughput LLM Inference**
2405.12532v1 by Dongjie Yang, XiaoDong Han, Yan Gao, Yao Hu, Shilin Zhang, Hai Zhao

Large Language Models (LLMs) have shown remarkable comprehension abilities
but face challenges in GPU memory usage during inference, hindering their
scalability for real-time applications like chatbots. To accelerate inference,
we store computed keys and values (KV cache) in the GPU memory. Existing
methods study the KV cache compression to reduce memory by pruning the
pre-computed KV cache. However, they neglect the inter-layer dependency between
layers and huge memory consumption in pre-computation. To explore these
deficiencies, we find that the number of crucial keys and values that influence
future generations decreases layer by layer and we can extract them by the
consistency in attention weights. Based on the findings, we propose
PyramidInfer, a method that compresses the KV cache by layer-wise retaining
crucial context. PyramidInfer saves significant memory by computing fewer keys
and values without sacrificing performance. Experimental results show
PyramidInfer improves 2.2x throughput compared to Accelerate with over 54% GPU
memory reduction in KV cache.

摘要：大型語言模型 (LLM) 已展現出卓越的理解能力，但在推論過程中面臨 GPU 記憶體使用率的挑戰，阻礙了它們在聊天機器人等即時應用程式中的可擴充性。為了加速推論，我們將計算出的金鑰和值 (KV 快取) 儲存在 GPU 記憶體中。現有方法研究 KV 快取壓縮，透過修剪預先計算的 KV 快取來減少記憶體。然而，它們忽略了層與層之間的層間相依性，以及預先計算中的龐大記憶體消耗。為了探討這些不足之處，我們發現影響後代的金鑰和值數量會逐層遞減，而且我們可以透過注意力權重的相容性來萃取它們。根據這些發現，我們提出 PyramidInfer，這是一種透過逐層保留關鍵內容來壓縮 KV 快取的方法。PyramidInfer 透過計算較少的金鑰和值來節省大量記憶體，同時不犧牲效能。實驗結果顯示，與 Accelerate 相比，PyramidInfer 將 KV 快取的 GPU 記憶體減少了 54% 以上，同時將處理量提升了 2.2 倍。

##### **SirLLM: Streaming Infinite Retentive LLM**
2405.12528v1 by Yao Yao, Zuchao Li, Hai Zhao

As Large Language Models (LLMs) become increasingly prevalent in various
domains, their ability to process inputs of any length and maintain a degree of
memory becomes essential. However, the one-off input of overly long texts is
limited, as studies have shown that when input lengths exceed the LLMs'
pre-trained text length, there is a dramatic decline in text generation
capabilities. Moreover, simply extending the length of pre-training texts is
impractical due to the difficulty in obtaining long text data and the
substantial memory consumption costs this would entail for LLMs. Recent efforts
have employed streaming inputs to alleviate the pressure of excessively long
text inputs, but this approach can significantly impair the model's long-term
memory capabilities.
  Motivated by this challenge, we introduce Streaming Infinite Retentive LLM
(SirLLM), which allows LLMs to maintain longer memory during infinite-length
dialogues without the need for fine-tuning. SirLLM utilizes the Token Entropy
metric and a memory decay mechanism to filter key phrases, endowing LLMs with
both long-lasting and flexible memory. We designed three distinct tasks and
constructed three datasets to measure the effectiveness of SirLLM from various
angles: (1) DailyDialog; (2) Grocery Shopping; (3) Rock-Paper-Scissors. Our
experimental results robustly demonstrate that SirLLM can achieve stable and
significant improvements across different LLMs and tasks, compellingly proving
its effectiveness. When having a coversation, "A sir could forget himself," but
SirLLM never does! Our code is publicly available at
https://github.com/Zoeyyao27/SirLLM

摘要：<paragraph>隨著大型語言模型 (LLM) 在各種領域中日益普及，它們處理任何長度的輸入並保持一定程度記憶的能力變得至關重要。然而，過度冗長的文本的一次性輸入是有限的，因為研究表明，當輸入長度超過 LLM 的預訓練文本長度時，文本生成能力會急劇下降。此外，僅僅延長預訓練文本的長度是不切實際的，因為難以獲取長文本數據，並且這將給 LLM 帶來巨大的內存消耗成本。最近的努力採用串流輸入來緩解過長文本輸入的壓力，但這種方法會顯著損害模型的長期記憶能力。
受此挑戰的激勵，我們引入了串流無限保留 LLM (SirLLM)，它允許 LLM 在無限長的對話中保持更長的記憶，而無需進行微調。SirLLM 利用 Token Entropy 度量和記憶衰減機制來過濾關鍵短語，賦予 LLM 持久且靈活的記憶。我們設計了三個不同的任務，並構建了三個數據集，從不同的角度衡量 SirLLM 的有效性：(1) DailyDialog；(2) Grocery Shopping；(3) Rock-Paper-Scissors。我們的實驗結果有力地證明，SirLLM 可以跨不同的 LLM 和任務實現穩定且顯著的改進，有力地證明了它的有效性。在進行對話時，“一位先生可能會忘記自己”，但 SirLLM 永遠不會！我們的代碼可在 https://github.com/Zoeyyao27/SirLLM 公開獲得</paragraph>

##### **Single Image Unlearning: Efficient Machine Unlearning in Multimodal Large Language Models**
2405.12523v1 by Jiaqi Li, Qianshan Wei, Chuanyi Zhang, Guilin Qi, Miaozeng Du, Yongrui Chen, Sheng Bi

Machine unlearning empowers individuals with the `right to be forgotten' by
removing their private or sensitive information encoded in machine learning
models. However, it remains uncertain whether MU can be effectively applied to
Multimodal Large Language Models (MLLMs), particularly in scenarios of
forgetting the leaked visual data of concepts. To overcome the challenge, we
propose an efficient method, Single Image Unlearning (SIU), to unlearn the
visual recognition of a concept by fine-tuning a single associated image for
few steps. SIU consists of two key aspects: (i) Constructing Multifaceted
fine-tuning data. We introduce four targets, based on which we construct
fine-tuning data for the concepts to be forgotten; (ii) Jointly training loss.
To synchronously forget the visual recognition of concepts and preserve the
utility of MLLMs, we fine-tune MLLMs through a novel Dual Masked KL-divergence
Loss combined with Cross Entropy loss. Alongside our method, we establish
MMUBench, a new benchmark for MU in MLLMs and introduce a collection of metrics
for its evaluation. Experimental results on MMUBench show that SIU completely
surpasses the performance of existing methods. Furthermore, we surprisingly
find that SIU can avoid invasive membership inference attacks and jailbreak
attacks. To the best of our knowledge, we are the first to explore MU in MLLMs.
We will release the code and benchmark in the near future.

摘要：機器去學習賦予個人「被遺忘的權利」，方法是移除編碼在機器學習模型中的私人或敏感資訊。然而，目前仍不確定 MU 是否能有效套用在多模態大型語言模型 (MLLM)，特別是在遺忘概念外洩視覺資料的場景中。為了克服此挑戰，我們提出一個有效率的方法，單一影像去學習 (SIU)，透過微調單一關聯影像幾個步驟，來去學習概念的視覺辨識。SIU 包含兩個關鍵面向：(i) 建構多面向微調資料。我們引入四個目標，根據這些目標建構要遺忘概念的微調資料；(ii) 聯合訓練損失。為了同步遺忘概念的視覺辨識，並保留 MLLM 的效用，我們透過一個新穎的雙遮罩 KL-散度損失，結合交叉熵損失，來微調 MLLM。除了我們的方法之外，我們還建立了 MMUBench，一個 MLLM 中 MU 的新基準，並引入一組用於評估的指標。MMUBench 上的實驗結果顯示，SIU 完全超越現有方法的效能。此外，我們驚訝地發現，SIU 可以避免侵入性的成員推論攻擊和越獄攻擊。據我們所知，我們是第一個探索 MLLM 中 MU 的人。我們將在不久的將來釋出程式碼和基準。

##### **Sparse Autoencoders Enable Scalable and Reliable Circuit Identification in Language Models**
2405.12522v1 by Charles O'Neill, Thang Bui

This paper introduces an efficient and robust method for discovering
interpretable circuits in large language models using discrete sparse
autoencoders. Our approach addresses key limitations of existing techniques,
namely computational complexity and sensitivity to hyperparameters. We propose
training sparse autoencoders on carefully designed positive and negative
examples, where the model can only correctly predict the next token for the
positive examples. We hypothesise that learned representations of attention
head outputs will signal when a head is engaged in specific computations. By
discretising the learned representations into integer codes and measuring the
overlap between codes unique to positive examples for each head, we enable
direct identification of attention heads involved in circuits without the need
for expensive ablations or architectural modifications. On three well-studied
tasks - indirect object identification, greater-than comparisons, and docstring
completion - the proposed method achieves higher precision and recall in
recovering ground-truth circuits compared to state-of-the-art baselines, while
reducing runtime from hours to seconds. Notably, we require only 5-10 text
examples for each task to learn robust representations. Our findings highlight
the promise of discrete sparse autoencoders for scalable and efficient
mechanistic interpretability, offering a new direction for analysing the inner
workings of large language models.

摘要：本文介紹了一種使用離散稀疏自動編碼器在大型語言模型中發現可解釋電路的有效且穩健的方法。我們的做法解決了現有技術的主要限制，即計算複雜度和對超參數的敏感性。我們建議在精心設計的正負範例上訓練稀疏自動編碼器，其中模型只能正確預測正範例的下一代幣。我們假設注意頭輸出學習到的表示會在頭部參與特定計算時發出信號。通過將學習到的表示離散化為整數代碼並測量每個頭部的正範例唯一代碼之間的重疊，我們可以在無需昂貴的消融或架構修改的情況下直接識別參與電路的注意頭部。在三項研究良好的任務（間接對象識別、大於比較和文件字串完成）中，所提出的方法在恢復真實電路方面實現了比最先進的基準更高的精確度和召回率，同時將運行時間從數小時縮短到數秒。值得注意的是，我們每個任務只需要 5-10 個文本範例來學習穩健的表示。我們的發現突出了離散稀疏自動編碼器在可擴充且有效機制可解釋性方面的潛力，為分析大型語言模型的內部運作提供了新的方向。

##### **MAGE: Model-Level Graph Neural Networks Explanations via Motif-based Graph Generation**
2405.12519v1 by Zhaoning Yu, Hongyang Gao

Graph Neural Networks (GNNs) have shown remarkable success in molecular
tasks, yet their interpretability remains challenging. Traditional model-level
explanation methods like XGNN and GNNInterpreter often fail to identify valid
substructures like rings, leading to questionable interpretability. This
limitation stems from XGNN's atom-by-atom approach and GNNInterpreter's
reliance on average graph embeddings, which overlook the essential structural
elements crucial for molecules. To address these gaps, we introduce an
innovative \textbf{M}otif-b\textbf{A}sed \textbf{G}NN \textbf{E}xplainer (MAGE)
that uses motifs as fundamental units for generating explanations. Our approach
begins with extracting potential motifs through a motif decomposition
technique. Then, we utilize an attention-based learning method to identify
class-specific motifs. Finally, we employ a motif-based graph generator for
each class to create molecular graph explanations based on these class-specific
motifs. This novel method not only incorporates critical substructures into the
explanations but also guarantees their validity, yielding results that are
human-understandable. Our proposed method's effectiveness is demonstrated
through quantitative and qualitative assessments conducted on six real-world
molecular datasets.

摘要：圖形神經網路 (GNN) 在分子任務中展現出顯著的成功，但其可解釋性仍具挑戰性。傳統的模型層級解釋方法，如 XGNN 和 GNNInterpreter，通常無法識別有效的子結構（例如環），導致可解釋性有疑慮。此限制源自於 XGNN 的逐原子方法，以及 GNNInterpreter 依賴於平均圖形嵌入，這忽略了對分子至關重要的基本結構元素。為了解決這些差距，我們引進了一個創新的基於基序的 GNN 解釋器 (MAGE)，它使用基序作為產生解釋的基本單位。我們的做法從透過基序分解技術提取潛在基序開始。接著，我們利用基於注意力的學習方法來識別特定類別的基序。最後，我們為每個類別採用基於基序的圖形產生器，以根據這些特定類別的基序建立分子圖形解釋。這種新穎的方法不僅將關鍵的子結構納入解釋中，還保證了它們的有效性，產生人類可以理解的結果。我們提出的方法的有效性已透過對六個真實世界的分子資料集進行的量化和質化評估得到證明。

##### **EntropyStop: Unsupervised Deep Outlier Detection with Loss Entropy**
2405.12502v1 by Yihong Huang, Yuang Zhang, Liping Wang, Fan Zhang, Xuemin Lin

Unsupervised Outlier Detection (UOD) is an important data mining task. With
the advance of deep learning, deep Outlier Detection (OD) has received broad
interest. Most deep UOD models are trained exclusively on clean datasets to
learn the distribution of the normal data, which requires huge manual efforts
to clean the real-world data if possible. Instead of relying on clean datasets,
some approaches directly train and detect on unlabeled contaminated datasets,
leading to the need for methods that are robust to such conditions. Ensemble
methods emerged as a superior solution to enhance model robustness against
contaminated training sets. However, the training time is greatly increased by
the ensemble.
  In this study, we investigate the impact of outliers on the training phase,
aiming to halt training on unlabeled contaminated datasets before performance
degradation. Initially, we noted that blending normal and anomalous data causes
AUC fluctuations, a label-dependent measure of detection accuracy. To
circumvent the need for labels, we propose a zero-label entropy metric named
Loss Entropy for loss distribution, enabling us to infer optimal stopping
points for training without labels. Meanwhile, we theoretically demonstrate
negative correlation between entropy metric and the label-based AUC. Based on
this, we develop an automated early-stopping algorithm, EntropyStop, which
halts training when loss entropy suggests the maximum model detection
capability. We conduct extensive experiments on ADBench (including 47 real
datasets), and the overall results indicate that AutoEncoder (AE) enhanced by
our approach not only achieves better performance than ensemble AEs but also
requires under 1\% of training time. Lastly, our proposed metric and
early-stopping approach are evaluated on other deep OD models, exhibiting their
broad potential applicability.

摘要：無監督異常值偵測 (UOD) 是一項重要的資料探勘任務。隨著深度學習的進展，深度異常值偵測 (OD) 已廣受關注。大多數深度 UOD 模型僅在乾淨的資料集上訓練，以了解正常資料的分布，如果可能的話，這需要大量手動工作來清理真實世界的資料。有些方法並非依賴乾淨的資料集，而是直接在未標籤的受污染資料集上進行訓練和偵測，導致需要對此類狀況具有穩健性的方法。整體方法已成為增強模型對受污染訓練集穩健性的優異解決方案。然而，整體會大幅增加訓練時間。
在本研究中，我們探討異常值對訓練階段的影響，旨在暫停在未標籤的受污染資料集上進行訓練，以避免效能下降。最初，我們注意到混合正常和異常資料會導致 AUC 波動，這是一種與標籤相關的偵測準確度測量。為了避免需要標籤，我們提出一個名為損失熵的零標籤熵指標，用於損失分佈，使我們能夠推論出沒有標籤的最佳訓練停止點。同時，我們在理論上證明了熵指標和基於標籤的 AUC 之間存在負相關性。基於此，我們開發了一種自動早期停止演算法 EntropyStop，當損失熵建議最大模型偵測能力時，便會停止訓練。我們在 ADBench（包括 47 個真實資料集）上進行廣泛的實驗，整體結果表明，由我們的方法增強的自動編碼器 (AE) 不僅比整體 AE 達到更好的效能，而且訓練時間不到 1%。最後，我們提出的指標和早期停止方法在其他深度 OD 模型上進行評估，展示了它們廣泛的潛在應用性。

##### **Exploring and Exploiting the Asymmetric Valley of Deep Neural Networks**
2405.12489v1 by Xin-Chun Li, Jin-Lin Tang, Bo Zhang, Lan Li, De-Chuan Zhan

Exploring the loss landscape offers insights into the inherent principles of
deep neural networks (DNNs). Recent work suggests an additional asymmetry of
the valley beyond the flat and sharp ones, yet without thoroughly examining its
causes or implications. Our study methodically explores the factors affecting
the symmetry of DNN valleys, encompassing (1) the dataset, network
architecture, initialization, and hyperparameters that influence the
convergence point; and (2) the magnitude and direction of the noise for 1D
visualization. Our major observation shows that the {\it degree of sign
consistency} between the noise and the convergence point is a critical
indicator of valley symmetry. Theoretical insights from the aspects of ReLU
activation and softmax function could explain the interesting phenomenon. Our
discovery propels novel understanding and applications in the scenario of Model
Fusion: (1) the efficacy of interpolating separate models significantly
correlates with their sign consistency ratio, and (2) imposing sign alignment
during federated learning emerges as an innovative approach for model parameter
alignment.

摘要：探索損失景觀有助於深入了解深度神經網路 (DNN) 的內在原理。最近的研究表明，除了平坦和陡峭的谷底之外，山谷還存在額外的不對稱性，但尚未徹底檢視其成因或影響。我們的研究方法性地探討影響 DNN 山谷對稱性的因素，包括 (1) 資料集、網路架構、初始化和影響收斂點的超參數；以及 (2) 1D 可視化的雜訊大小和方向。我們的重大觀察結果顯示，雜訊與收斂點之間的「符號一致性程度」是山谷對稱性的關鍵指標。ReLU 激活和 softmax 函數方面的理論見解可以解釋這個有趣的現象。我們的發現推動了模型融合場景中新的理解和應用：(1) 插值單獨模型的功效與其符號一致性比率顯著相關，以及 (2) 在聯合學習期間強加符號對齊成為模型參數對齊的一種創新方法。

##### **Time Matters: Enhancing Pre-trained News Recommendation Models with Robust User Dwell Time Injection**
2405.12486v1 by Hao Jiang, Chuanzhen Li, Mingxiao An

Large Language Models (LLMs) have revolutionized text comprehension, leading
to State-of-the-Art (SOTA) news recommendation models that utilize LLMs for
in-depth news understanding. Despite this, accurately modeling user preferences
remains challenging due to the inherent uncertainty of click behaviors.
Techniques like multi-head attention in Transformers seek to alleviate this by
capturing interactions among clicks, yet they fall short in integrating
explicit feedback signals. User Dwell Time emerges as a powerful indicator,
offering the potential to enhance the weak signals emanating from clicks.
Nonetheless, its real-world applicability is questionable, especially when
dwell time data collection is subject to delays. To bridge this gap, this paper
proposes two novel and robust dwell time injection strategies, namely Dwell
time Weight (DweW) and Dwell time Aware (DweA). Dwe} concentrates on refining
Effective User Clicks through detailed analysis of dwell time, integrating with
initial behavioral inputs to construct a more robust user preference. DweA
empowers the model with awareness of dwell time information, thereby
facilitating autonomous adjustment of attention values in user modeling. This
enhancement sharpens the model's ability to accurately identify user
preferences. In our experiment using the real-world news dataset from MSN
website, we validated that our two strategies significantly improve
recommendation performance, favoring high-quality news. Crucially, our
approaches exhibit robustness to user dwell time information, maintaining their
ability to recommend high-quality content even in extreme cases where dwell
time data is entirely missing.

摘要：大型語言模型 (LLM) 已徹底改變文字理解，進而產生利用 LLM 深入理解新聞的最新推薦模型。儘管如此，由於點擊行為的內在不確定性，精確建模使用者偏好仍然具有挑戰性。Transformer中的多頭注意力等技術試圖透過捕捉點擊之間的互動來減輕這種情況，但它們在整合明確的回饋訊號方面仍有不足。使用者停留時間成為一個強有力的指標，提供增強來自點擊的弱訊號的潛力。儘管如此，它的實際應用性仍有疑問，特別是在停留時間資料收集會延遲時。為了彌補這個差距，本文提出了兩種新穎且強大的停留時間注入策略，即停留時間加權 (DweW) 和停留時間感知 (DweA)。Dwe} 專注於透過詳細分析停留時間來精煉有效的使用者點擊，並與初始行為輸入整合，以建構更強大的使用者偏好。DweA 讓模型具備停留時間資訊的感知，從而促進使用者建模中注意力值的自主調整。這種增強使模型更精準地識別使用者偏好的能力更為敏銳。在我們使用來自 MSN 網站的真實世界新聞資料集進行的實驗中，我們驗證了我們的兩種策略顯著改善了推薦效能，偏好高品質的新聞。至關重要的是，我們的做法展現出對使用者停留時間資訊的穩健性，即使在停留時間資料完全遺失的極端情況下，它們仍能推薦高品質的內容。

##### **GASE: Graph Attention Sampling with Edges Fusion for Solving Vehicle Routing Problems**
2405.12475v1 by Zhenwei Wang, Ruibin Bai, Fazlullah Khan, Ender Ozcan, Tiehua Zhang

Learning-based methods have become increasingly popular for solving vehicle
routing problems due to their near-optimal performance and fast inference
speed. Among them, the combination of deep reinforcement learning and graph
representation allows for the abstraction of node topology structures and
features in an encoder-decoder style. Such an approach makes it possible to
solve routing problems end-to-end without needing complicated heuristic
operators designed by domain experts. Existing research studies have been
focusing on novel encoding and decoding structures via various neural network
models to enhance the node embedding representation. Despite the sophisticated
approaches applied, there is a noticeable lack of consideration for the
graph-theoretic properties inherent to routing problems. Moreover, the
potential ramifications of inter-nodal interactions on the decision-making
efficacy of the models have not been adequately explored. To bridge this gap,
we propose an adaptive Graph Attention Sampling with the Edges Fusion framework
(GASE),where nodes' embedding is determined through attention calculation from
certain highly correlated neighbourhoods and edges, utilizing a filtered
adjacency matrix. In detail, the selections of particular neighbours and
adjacency edges are led by a multi-head attention mechanism, contributing
directly to the message passing and node embedding in graph attention sampling
networks. Furthermore, we incorporate an adaptive actor-critic algorithm with
policy improvements to expedite the training convergence. We then conduct
comprehensive experiments against baseline methods on learning-based VRP tasks
from different perspectives. Our proposed model outperforms the existing
methods by 2.08\%-6.23\% and shows stronger generalization ability, achieving
state-of-the-art performance on randomly generated instances and real-world
datasets.

摘要：<paragraph>基於學習的方法由於其近乎最佳的效能和快速的推論速度，已在解決車輛路線問題上變得越來越普遍。其中，深度強化學習和圖形表示的結合允許在編碼器-解碼器樣式中抽象節點拓撲結構和特徵。這種方法使得在不需要由領域專家設計的複雜啟發式運算子情況下，就能解決端到端的路線問題。現有的研究一直專注於通過各種神經網路模型對新的編碼和解碼結構進行研究，以增強節點嵌入式表示。儘管運用了複雜的方法，但對於路線問題固有的圖論特性卻明顯缺乏考量。此外，節點間互動對模型決策效能的潛在影響尚未得到充分探討。為了彌合理論與實務的差距，我們提出了一種自適應圖注意力抽樣和邊緣融合框架 (GASE)，其中節點的嵌入是通過從某些高度相關的鄰域和邊緣進行注意力計算，利用過濾的鄰接矩陣來確定的。詳細來說，特定鄰域和鄰接邊緣的選擇是由多頭注意力機制引導的，直接有助於訊息傳遞和圖注意力抽樣網路中的節點嵌入。此外，我們結合了一個自適應的動作-評論演算法和策略改進，以加速訓練收斂。然後，我們針對基於學習的 VRP 任務，從不同的角度對基準方法進行了全面的實驗。我們提出的模型比現有方法的效能高出 2.08%-6.23%，並且顯示出更強的泛化能力，在隨機生成的實例和真實世界資料集上達到了最先進的效能。</paragraph>

##### **Learning Partially Aligned Item Representation for Cross-Domain Sequential Recommendation**
2405.12473v1 by Mingjia Yin, Hao Wang, Wei Guo, Yong Liu, Zhi Li, Sirui Zhao, Defu Lian, Enhong Chen

Cross-domain sequential recommendation (CDSR) aims to uncover and transfer
users' sequential preferences across multiple recommendation domains. While
significant endeavors have been made, they primarily concentrated on developing
advanced transfer modules and aligning user representations using
self-supervised learning techniques. However, the problem of aligning item
representations has received limited attention, and misaligned item
representations can potentially lead to sub-optimal sequential modeling and
user representation alignment. To this end, we propose a model-agnostic
framework called \textbf{C}ross-domain item representation \textbf{A}lignment
for \textbf{C}ross-\textbf{D}omain \textbf{S}equential \textbf{R}ecommendation
(\textbf{CA-CDSR}), which achieves sequence-aware generation and adaptively
partial alignment for item representations. Specifically, we first develop a
sequence-aware feature augmentation strategy, which captures both collaborative
and sequential item correlations, thus facilitating holistic item
representation generation. Next, we conduct an empirical study to investigate
the partial representation alignment problem from a spectrum perspective. It
motivates us to devise an adaptive spectrum filter, achieving partial alignment
adaptively. Furthermore, the aligned item representations can be fed into
different sequential encoders to obtain user representations. The entire
framework is optimized in a multi-task learning paradigm with an annealing
strategy. Extensive experiments have demonstrated that CA-CDSR can surpass
state-of-the-art baselines by a significant margin and can effectively align
items in representation spaces to enhance performance.

摘要：跨網域序列推薦（CDSR）旨在揭示和傳遞使用者在多個推薦網域中的序列偏好。儘管已做出重大努力，但主要集中在開發先進的傳輸模組和使用自我監督學習技術對齊使用者表徵。然而，對齊項目表徵的問題受到的關注有限，而未對齊的項目表徵可能會導致次佳序列建模和使用者表徵對齊。為此，我們提出了一個與模型無關的框架，稱為跨網域項目表徵對齊，用於跨網域序列推薦（CA-CDSR），它實現了序列感知生成和項目表徵的自適應部分對齊。具體來說，我們首先開發了一個序列感知特徵擴充策略，它捕獲協作和序列項目關聯，從而促進整體項目表徵生成。接下來，我們進行了一項實證研究，從頻譜角度探討部分表徵對齊問題。它激勵我們設計一個自適應頻譜濾波器，自適應地實現部分對齊。此外，對齊的項目表徵可以輸入不同的序列編碼器以獲取使用者表徵。整個框架在具有退火策略的多任務學習範例中進行最佳化。廣泛的實驗表明，CA-CDSR 可以顯著超越最先進的基準，並可以有效地對齊表徵空間中的項目以增強效能。

##### **Leveraging Diverse Data Generation for Adaptable Zero-Shot Dialogue State Tracking**
2405.12468v1 by James D. Finch, Boxin Zhao, Jinho D. Choi

This work demonstrates that substantial gains in zero-shot dialogue state
tracking (DST) accuracy can be achieved by increasing the diversity of training
data using synthetic data generation techniques. Current DST training resources
are severely limited in the number of application domains and slot types they
cover due to the high costs of data collection, resulting in limited
adaptability to new domains. The presented work overcomes this challenge using
a novel, fully automatic data generation approach to create synthetic zero-shot
DST training resources. Unlike previous approaches for generating DST data, the
presented approach generates entirely new application domains to generate
dialogues, complete with silver dialogue state annotations and slot
descriptions. This approach is used to create the D0T dataset for training
zero-shot DST models, which covers an unprecedented 1,000+ domains. Experiments
performed on the MultiWOZ benchmark indicate that training models on diverse
synthetic data yields a performance improvement of +6.7% Joint Goal Accuracy,
achieving results competitive with much larger models.

摘要：这项研究表明，通过使用合成数据生成技术来增加训练数据的多样性，可以大幅提升零次学习对话状态追踪 (DST) 的准确性。由于数据收集成本高昂，当前的 DST 训练资源在应用领域和槽位类型数量上受到严重限制，导致适应新领域的灵活性有限。这项研究通过使用一种新颖的全自动数据生成方法来克服这一挑战，从而创建合成零次学习 DST 训练资源。与之前生成 DST 数据的方法不同，这种方法生成了全新的应用领域来生成对话，并附有银质对话状态注释和槽位描述。此方法用于创建 D0T 数据集，用于训练零次学习 DST 模型，该数据集涵盖了前所未有的 1,000 多个领域。在 MultiWOZ 基准上进行的实验表明，在多样化的合成数据上训练模型可将联合目标准确度提高 +6.7%，取得了与更大模型相当的结果。

##### **Stochastic Learning of Computational Resource Usage as Graph Structured Multimarginal Schrödinger Bridge**
2405.12463v1 by Georgiy A. Bondar, Robert Gifford, Linh Thi Xuan Phan, Abhishek Halder

We propose to learn the time-varying stochastic computational resource usage
of software as a graph structured Schr\"odinger bridge problem. In general,
learning the computational resource usage from data is challenging because
resources such as the number of CPU instructions and the number of last level
cache requests are both time-varying and statistically correlated. Our proposed
method enables learning the joint time-varying stochasticity in computational
resource usage from the measured profile snapshots in a nonparametric manner.
The method can be used to predict the most-likely time-varying distribution of
computational resource availability at a desired time. We provide detailed
algorithms for stochastic learning in both single and multi-core cases, discuss
the convergence guarantees, computational complexities, and demonstrate their
practical use in two case studies: a single-core nonlinear model predictive
controller, and a synthetic multi-core software.

摘要：我們提出學習時間變動隨機計算資源使用率的軟體，作為圖形結構薛丁格橋樑問題。一般來說，從資料中學習計算資源使用率具有挑戰性，因為資源（例如 CPU 指令數和最後層級快取要求數）同時具有時間變異性和統計相關性。我們提出的方法能夠以非參數方式從測量輪廓快照中學習計算資源使用率中的聯合時間變異隨機性。此方法可用於預測在所需時間內最有可能的時間變異計算資源可用性分佈。我們提供單核和多核情況下隨機學習的詳細演算法，討論收斂保證、計算複雜度，並展示它們在兩個案例研究中的實際用途：單核非線性模型預測控制器和合成多核軟體。

##### **Boosting X-formers with Structured Matrix for Long Sequence Time Series Forecasting**
2405.12462v1 by Zhicheng Zhang, Yong Wang, Shaoqi Tan, Bowei Xia, Yujie Luo

Transformer-based models for long sequence time series forecasting (LSTF)
problems have gained significant attention due to their exceptional forecasting
precision. As the cornerstone of these models, the self-attention mechanism
poses a challenge to efficient training and inference due to its quadratic time
complexity. In this article, we propose a novel architectural design for
Transformer-based models in LSTF, leveraging a substitution framework that
incorporates Surrogate Attention Blocks and Surrogate FFN Blocks. The framework
aims to boost any well-designed model's efficiency without sacrificing its
accuracy. We further establish the equivalence of the Surrogate Attention Block
to the self-attention mechanism in terms of both expressiveness and
trainability. Through extensive experiments encompassing nine Transformer-based
models across five time series tasks, we observe an average performance
improvement of 9.45% while achieving a significant reduction in model size by
46%

摘要：基於 Transformer 的長序列時間序列預測 (LSTF) 問題模型由於其出色的預測精度而備受關注。作為這些模型的基石，自我注意機制由於其二次時間複雜度對高效訓練和推理提出了挑戰。在本文中，我們提出了一個基於 Transformer 的 LSTF 模型的新架構設計，利用了一個包含代理注意區塊和代理 FFN 區塊的替換框架。該框架旨在提高任何設計良好的模型的效率，而不會犧牲其準確性。我們進一步建立了代理注意區塊與自我注意機制在表達能力和可訓練性方面的等價性。通過涵蓋五個時間序列任務的九個基於 Transformer 的模型的廣泛實驗，我們觀察到平均性能提高了 9.45%，同時模型大小顯著減少了 46%

##### **WorldAfford: Affordance Grounding based on Natural Language Instructions**
2405.12461v1 by Changmao Chen, Yuren Cong, Zhen Kan

Affordance grounding aims to localize the interaction regions for the
manipulated objects in the scene image according to given instructions. A
critical challenge in affordance grounding is that the embodied agent should
understand human instructions and analyze which tools in the environment can be
used, as well as how to use these tools to accomplish the instructions. Most
recent works primarily supports simple action labels as input instructions for
localizing affordance regions, failing to capture complex human objectives.
Moreover, these approaches typically identify affordance regions of only a
single object in object-centric images, ignoring the object context and
struggling to localize affordance regions of multiple objects in complex scenes
for practical applications. To address this concern, for the first time, we
introduce a new task of affordance grounding based on natural language
instructions, extending it from previously using simple labels for complex
human instructions. For this new task, we propose a new framework, WorldAfford.
We design a novel Affordance Reasoning Chain-of-Thought Prompting to reason
about affordance knowledge from LLMs more precisely and logically.
Subsequently, we use SAM and CLIP to localize the objects related to the
affordance knowledge in the image. We identify the affordance regions of the
objects through an affordance region localization module. To benchmark this new
task and validate our framework, an affordance grounding dataset, LLMaFF, is
constructed. We conduct extensive experiments to verify that WorldAfford
performs state-of-the-art on both the previous AGD20K and the new LLMaFF
dataset. In particular, WorldAfford can localize the affordance regions of
multiple objects and provide an alternative when objects in the environment
cannot fully match the given instruction.

摘要：affordance grounding 旨在根据给定的指令对场景图像中受操纵对象的交互区域进行定位。affordance grounding 中的一个关键挑战在于，具身代理应该理解人类指令并分析环境中哪些工具可以使用，以及如何使用这些工具来完成指令。最近的大多数工作主要支持简单的动作标签作为定位 affordance 区域的输入指令，未能捕捉复杂的人类目标。此外，这些方法通常只识别以对象为中心的图像中单个对象的 affordance 区域，忽略了对象上下文，并且难以在复杂场景中定位多个对象的 affordance 区域以用于实际应用。为了解决这一问题，我们首次引入了一种基于自然语言指令的 affordance grounding 新任务，将其从以前使用简单标签扩展到复杂的人类指令。对于这个新任务，我们提出了一个新框架 WorldAfford。我们设计了一个新颖的 Affordance 推理思维链提示，以更精确和合乎逻辑地推理来自 LLM 的 affordance 知识。随后，我们使用 SAM 和 CLIP 来定位图像中与 affordance 知识相关的对象。我们通过 affordance 区域定位模块识别对象的 affordance 区域。为了对这个新任务进行基准测试并验证我们的框架，构建了一个 affordance grounding 数据集 LLMaFF。我们进行了广泛的实验来验证 WorldAfford 在之前的 AGD20K 和新的 LLMaFF 数据集上都表现出最先进的水平。特别是，WorldAfford 可以定位多个对象的 affordance 区域，并在环境中的对象无法完全匹配给定指令时提供替代方案。

##### **PathOCL: Path-Based Prompt Augmentation for OCL Generation with GPT-4**
2405.12450v1 by Seif Abukhalaf, Mohammad Hamdaqa, Foutse Khomh

The rapid progress of AI-powered programming assistants, such as GitHub
Copilot, has facilitated the development of software applications. These
assistants rely on large language models (LLMs), which are foundation models
(FMs) that support a wide range of tasks related to understanding and
generating language. LLMs have demonstrated their ability to express UML model
specifications using formal languages like the Object Constraint Language
(OCL). However, the context size of the prompt is limited by the number of
tokens an LLM can process. This limitation becomes significant as the size of
UML class models increases. In this study, we introduce PathOCL, a novel
path-based prompt augmentation technique designed to facilitate OCL generation.
PathOCL addresses the limitations of LLMs, specifically their token processing
limit and the challenges posed by large UML class models. PathOCL is based on
the concept of chunking, which selectively augments the prompts with a subset
of UML classes relevant to the English specification. Our findings demonstrate
that PathOCL, compared to augmenting the complete UML class model
(UML-Augmentation), generates a higher number of valid and correct OCL
constraints using the GPT-4 model. Moreover, the average prompt size crafted
using PathOCL significantly decreases when scaling the size of the UML class
models.

摘要：AI 驅動程式設計助理的快速進展，例如 GitHub Copilot，促進了軟體應用的開發。這些助理依賴於大型語言模型 (LLM)，它們是支援與理解和產生語言相關的廣泛任務的基礎模型 (FM)。LLM 已展示它們使用正式語言（例如物件約束語言 (OCL)）表達 UML 模型規範的能力。然而，提示的上下文大小受到 LLM 可以處理的記號數量限制。隨著 UML 類別模型的規模增加，這個限制變得顯著。在這項研究中，我們介紹了 PathOCL，這是一種新穎的基於路徑的提示擴充技術，旨在促進 OCL 產生。PathOCL 解決了 LLM 的限制，特別是它們的記號處理限制和大型 UML 類別模型帶來的挑戰。PathOCL 基於分塊的概念，它有選擇地使用與英文規範相關的 UML 類別子集來擴充提示。我們的發現表明，與擴充完整的 UML 類別模型 (UML-Augmentation) 相比，PathOCL 使用 GPT-4 模型產生了更多有效且正確的 OCL 約束。此外，使用 PathOCL 製作的平均提示大小在擴充 UML 類別模型的規模時顯著減少。

##### **Learning Structure and Knowledge Aware Representation with Large Language Models for Concept Recommendation**
2405.12442v1 by Qingyao Li, Wei Xia, Kounianhua Du, Qiji Zhang, Weinan Zhang, Ruiming Tang, Yong Yu

Concept recommendation aims to suggest the next concept for learners to study
based on their knowledge states and the human knowledge system. While knowledge
states can be predicted using knowledge tracing models, previous approaches
have not effectively integrated the human knowledge system into the process of
designing these educational models. In the era of rapidly evolving Large
Language Models (LLMs), many fields have begun using LLMs to generate and
encode text, introducing external knowledge. However, integrating LLMs into
concept recommendation presents two urgent challenges: 1) How to construct text
for concepts that effectively incorporate the human knowledge system? 2) How to
adapt non-smooth, anisotropic text encodings effectively for concept
recommendation? In this paper, we propose a novel Structure and Knowledge Aware
Representation learning framework for concept Recommendation (SKarREC). We
leverage factual knowledge from LLMs as well as the precedence and succession
relationships between concepts obtained from the knowledge graph to construct
textual representations of concepts. Furthermore, we propose a graph-based
adapter to adapt anisotropic text embeddings to the concept recommendation
task. This adapter is pre-trained through contrastive learning on the knowledge
graph to get a smooth and structure-aware concept representation. Then, it's
fine-tuned through the recommendation task, forming a
text-to-knowledge-to-recommendation adaptation pipeline, which effectively
constructs a structure and knowledge-aware concept representation. Our method
does a better job than previous adapters in transforming text encodings for
application in concept recommendation. Extensive experiments on real-world
datasets demonstrate the effectiveness of the proposed approach.

摘要：概念推薦旨在根據學習者的知識狀態和人類知識系統，建議學習者學習的下一個概念。雖然知識狀態可以使用知識追蹤模型來預測，但先前的做法並未有效地將人類知識系統整合到設計這些教育模型的過程中。在快速發展的大型語言模型 (LLM) 時代，許多領域已開始使用 LLM 來產生和編碼文字，引入外部知識。然而，將 LLM 整合到概念推薦中會出現兩個迫切的挑戰：1) 如何建構有效地整合人類知識系統的概念文字？2) 如何有效地調整非平滑、各向異性的文字編碼以進行概念推薦？在本文中，我們提出了一個新的結構和知識感知表示學習架構，用於概念推薦 (SKarREC)。我們利用 LLM 的事實知識以及從知識圖譜中獲得的概念之間的先後關係來建構概念的文字表示。此外，我們提出了一個基於圖表的適配器，以將各向異性的文字嵌入調整到概念推薦任務。這個適配器透過對比學習在知識圖譜上進行預訓練，以獲得平滑且具有結構感知的概念表示。然後，透過推薦任務進行微調，形成從文字到知識再到推薦的適配管道，有效地建構一個結構和知識感知的概念表示。我們的方法在轉換文字編碼以應用於概念推薦方面，比先前的適配器做得更好。在真實世界資料集上的廣泛實驗證明了所提出方法的有效性。

##### **CoCo Matrix: Taxonomy of Cognitive Contributions in Co-writing with Intelligent Agents**
2405.12438v1 by Ruyuan Wan, Simret Gebreegziabhe, Toby Jia-Jun Li, Karla Badillo-Urquiola

In recent years, there has been a growing interest in employing intelligent
agents in writing. Previous work emphasizes the evaluation of the quality of
end product-whether it was coherent and polished, overlooking the journey that
led to the product, which is an invaluable dimension of the creative process.
To understand how to recognize human efforts in co-writing with intelligent
writing systems, we adapt Flower and Hayes' cognitive process theory of writing
and propose CoCo Matrix, a two-dimensional taxonomy of entropy and information
gain, to depict the new human-agent co-writing model. We define four quadrants
and situate thirty-four published systems within the taxonomy. Our research
found that low entropy and high information gain systems are under-explored,
yet offer promising future directions in writing tasks that benefit from the
agent's divergent planning and the human's focused translation. CoCo Matrix,
not only categorizes different writing systems but also deepens our
understanding of the cognitive processes in human-agent co-writing. By
analyzing minimal changes in the writing process, CoCo Matrix serves as a proxy
for the writer's mental model, allowing writers to reflect on their
contributions. This reflection is facilitated through the measured metrics of
information gain and entropy, which provide insights irrespective of the
writing system used.

摘要：近年来，人们对在写作中使用智能代理越来越感兴趣。以往的研究重点在于评估最终产品的质量——它是否连贯且完善，而忽略了导致该产品诞生的过程，而这正是创作过程中一个宝贵的维度。为了理解如何在与智能写作系统合作写作中识别人的努力，我们采用了 Flower 和 Hayes 的写作认知过程理论，并提出了 CoCo Matrix，这是一个关于熵和信息增益的二维分类法，以描述新的、人与代理合作写作的模型。我们定义了四个象限，并在分类法中定位了 34 个已发布系统。我们的研究发现，低熵和高信息增益系统尚未得到充分探索，但在受益于代理的发散规划和人的专注翻译的写作任务中提供了有希望的未来方向。CoCo Matrix 不仅对不同的写作系统进行了分类，还加深了我们对人与代理合作写作中的认知过程的理解。通过分析写作过程中的最小变化，CoCo Matrix 可以作为作家心智模型的代理，让作家能够反思自己的贡献。这种反思是通过信息增益和熵的测量指标实现的，这些指标提供了与所使用的写作系统无关的见解。

##### **Resolving Word Vagueness with Scenario-guided Adapter for Natural Language Inference**
2405.12434v1 by Yonghao Liu, Mengyu Li, Di Liang, Ximing Li, Fausto Giunchiglia, Lan Huang, Xiaoyue Feng, Renchu Guan

Natural Language Inference (NLI) is a crucial task in natural language
processing that involves determining the relationship between two sentences,
typically referred to as the premise and the hypothesis. However, traditional
NLI models solely rely on the semantic information inherent in independent
sentences and lack relevant situational visual information, which can hinder a
complete understanding of the intended meaning of the sentences due to the
ambiguity and vagueness of language. To address this challenge, we propose an
innovative ScenaFuse adapter that simultaneously integrates large-scale
pre-trained linguistic knowledge and relevant visual information for NLI tasks.
Specifically, we first design an image-sentence interaction module to
incorporate visuals into the attention mechanism of the pre-trained model,
allowing the two modalities to interact comprehensively. Furthermore, we
introduce an image-sentence fusion module that can adaptively integrate visual
information from images and semantic information from sentences. By
incorporating relevant visual information and leveraging linguistic knowledge,
our approach bridges the gap between language and vision, leading to improved
understanding and inference capabilities in NLI tasks. Extensive benchmark
experiments demonstrate that our proposed ScenaFuse, a scenario-guided
approach, consistently boosts NLI performance.

摘要：自然語言推理 (NLI) 是自然語言處理中的一項關鍵任務，涉及確定兩個句子之間的關係，通常稱為前提和假設。然而，傳統的 NLI 模型僅依賴於獨立句子中固有的語義資訊，並且缺乏相關的情境視覺資訊，這可能會阻礙對句子的預期含義的完整理解，因為語言的模糊性和含糊性。為了應對這一挑戰，我們提出了一個創新的 ScenaFuse 適配器，它同時整合了大規模預訓練的語言知識和相關視覺資訊，用於 NLI 任務。具體來說，我們首先設計了一個影像句子互動模組，將視覺效果納入預訓練模型的注意機制，讓這兩種模式全面互動。此外，我們還引入了影像句子融合模組，它可以適應性地整合來自影像的視覺資訊和來自句子的語義資訊。透過整合相關視覺資訊並利用語言知識，我們的做法縮小了語言和視覺之間的差距，進而提升 NLI 任務中的理解和推理能力。廣泛的基準實驗證明，我們提出的 ScenaFuse 是一種情境引導式方法，可持續提升 NLI 的效能。

##### **LLM+Reasoning+Planning for supporting incomplete user queries in presence of APIs**
2405.12433v1 by Sudhir Agarwal, Anu Sreepathy, David H. Alonso, Prarit Lamba

Recent availability of Large Language Models (LLMs) has led to the
development of numerous LLM-based approaches aimed at providing natural
language interfaces for various end-user tasks. These end-user tasks in turn
can typically be accomplished by orchestrating a given set of APIs. In
practice, natural language task requests (user queries) are often incomplete,
i.e., they may not contain all the information required by the APIs. While LLMs
excel at natural language processing (NLP) tasks, they frequently hallucinate
on missing information or struggle with orchestrating the APIs. The key idea
behind our proposed approach is to leverage logical reasoning and classical AI
planning along with an LLM for accurately answering user queries including
identification and gathering of any missing information in these queries. Our
approach uses an LLM and ASP (Answer Set Programming) solver to translate a
user query to a representation in Planning Domain Definition Language (PDDL)
via an intermediate representation in ASP. We introduce a special API
"get_info_api" for gathering missing information. We model all the APIs as PDDL
actions in a way that supports dataflow between the APIs. Our approach then
uses a classical AI planner to generate an orchestration of API calls
(including calls to get_info_api) to answer the user query. Our evaluation
results show that our approach significantly outperforms a pure LLM based
approach by achieving over 95\% success rate in most cases on a dataset
containing complete and incomplete single goal and multi-goal queries where the
multi-goal queries may or may not require dataflow among the APIs.

摘要：<paragraph>最近大型语言模型 (LLM) 的可用性促成了许多基于 LLM 的方法的发展，这些方法旨在为各种最终用户任务提供自然语言界面。这些最终用户任务反过来通常可以通过编排给定的 API 集来完成。在实践中，自然语言任务请求（用户查询）通常是不完整的，即它们可能不包含 API 所需的所有信息。虽然 LLM 在自然语言处理 (NLP) 任务中表现出色，但它们经常对缺失的信息产生幻觉或难以编排 API。我们提出的方法背后的关键思想是利用逻辑推理和经典 AI 规划以及 LLM 来准确回答用户查询，包括识别和收集这些查询中任何缺失的信息。我们的方法使用 LLM 和 ASP（Answer Set Programming）求解器，通过 ASP 中的中间表示将用户查询转换为规划域定义语言 (PDDL) 中的表示。我们引入了一个特殊 API “get_info_api” 来收集缺失的信息。我们将所有 API 建模为 PDDL 动作，以支持 API 之间的数据流。然后，我们的方法使用经典 AI 规划器生成 API 调用编排（包括对 get_info_api 的调用）来回答用户查询。我们的评估结果表明，我们的方法明显优于基于纯 LLM 的方法，在包含完整和不完整单目标和多目标查询的数据集上，在大多数情况下实现了超过 95% 的成功率，其中多目标查询可能需要也可能不需要 API 之间的数据流。</paragraph>

##### **A Unified Linear Programming Framework for Offline Reward Learning from Human Demonstrations and Feedback**
2405.12421v1 by Kihyun Kim, Jiawei Zhang, Pablo A. Parrilo, Asuman Ozdaglar

Inverse Reinforcement Learning (IRL) and Reinforcement Learning from Human
Feedback (RLHF) are pivotal methodologies in reward learning, which involve
inferring and shaping the underlying reward function of sequential
decision-making problems based on observed human demonstrations and feedback.
Most prior work in reward learning has relied on prior knowledge or assumptions
about decision or preference models, potentially leading to robustness issues.
In response, this paper introduces a novel linear programming (LP) framework
tailored for offline reward learning. Utilizing pre-collected trajectories
without online exploration, this framework estimates a feasible reward set from
the primal-dual optimality conditions of a suitably designed LP, and offers an
optimality guarantee with provable sample efficiency. Our LP framework also
enables aligning the reward functions with human feedback, such as pairwise
trajectory comparison data, while maintaining computational tractability and
sample efficiency. We demonstrate that our framework potentially achieves
better performance compared to the conventional maximum likelihood estimation
(MLE) approach through analytical examples and numerical experiments.

摘要：逆向強化學習 (IRL) 與人類回饋強化學習 (RLHF) 是獎勵學習中的關鍵方法，涉及根據觀察到的人類示範和回饋推論和塑造序貫決策問題的基礎獎勵函數。大多數先前的獎勵學習工作依賴於決策或偏好模型的先驗知識或假設，這可能會導致穩健性問題。為了解決這個問題，本文介紹了一個針對離線獎勵學習量身定制的新型線性規劃 (LP) 框架。利用預先收集的軌跡而無需在線探索，此框架從適當設計的 LP 的原始對偶最優條件估計一個可行的獎勵集，並提供具有可證明樣本效率的最優保證。我們的 LP 框架還能夠將獎勵函數與人類回饋對齊，例如成對軌跡比較數據，同時保持計算可處理性和樣本效率。我們證明，與傳統的最大似然估計 (MLE) 方法相比，我們的框架有可能通過分析範例和數值實驗實現更好的性能。

##### **Targeted Multilingual Adaptation for Low-resource Language Families**
2405.12413v1 by C. M. Downey, Terra Blevins, Dhwani Serai, Dwija Parikh, Shane Steinert-Threlkeld

The "massively-multilingual" training of multilingual models is known to
limit their utility in any one language, and they perform particularly poorly
on low-resource languages. However, there is evidence that low-resource
languages can benefit from targeted multilinguality, where the model is trained
on closely related languages. To test this approach more rigorously, we
systematically study best practices for adapting a pre-trained model to a
language family. Focusing on the Uralic family as a test case, we adapt XLM-R
under various configurations to model 15 languages; we then evaluate the
performance of each experimental setting on two downstream tasks and 11
evaluation languages. Our adapted models significantly outperform mono- and
multilingual baselines. Furthermore, a regression analysis of hyperparameter
effects reveals that adapted vocabulary size is relatively unimportant for
low-resource languages, and that low-resource languages can be aggressively
up-sampled during training at little detriment to performance in high-resource
languages. These results introduce new best practices for performing language
adaptation in a targeted setting.

摘要：已知多语言模型的「大规模多语言」训练会限制其在任何一种语言中的实用性，而且在低资源语言中表现特别差。然而，有证据表明低资源语言可以受益于有针对性的多语言性，其中模型是在密切相关的语言上进行训练的。为了更严格地测试这种方法，我们系统地研究了将预训练模型适应到语言家族的最佳实践。以乌拉尔语系为测试案例，我们根据各种配置调整了 XLM-R 以对 15 种语言进行建模；然后，我们在两个下游任务和 11 种评估语言上评估了每个实验设置的性能。我们调整后的模型明显优于单语言和多语言基线。此外，对超参数效应的回归分析表明，对于低资源语言来说，调整后的词汇量大小相对不重要，并且在训练期间可以积极地对低资源语言进行上采样，而对高资源语言的性能几乎没有损害。这些结果为在有针对性的设置中执行语言适应引入了新的最佳实践。

##### **Diffusion for World Modeling: Visual Details Matter in Atari**
2405.12399v1 by Eloi Alonso, Adam Jelley, Vincent Micheli, Anssi Kanervisto, Amos Storkey, Tim Pearce, François Fleuret

World models constitute a promising approach for training reinforcement
learning agents in a safe and sample-efficient manner. Recent world models
predominantly operate on sequences of discrete latent variables to model
environment dynamics. However, this compression into a compact discrete
representation may ignore visual details that are important for reinforcement
learning. Concurrently, diffusion models have become a dominant approach for
image generation, challenging well-established methods modeling discrete
latents. Motivated by this paradigm shift, we introduce DIAMOND (DIffusion As a
Model Of eNvironment Dreams), a reinforcement learning agent trained in a
diffusion world model. We analyze the key design choices that are required to
make diffusion suitable for world modeling, and demonstrate how improved visual
details can lead to improved agent performance. DIAMOND achieves a mean human
normalized score of 1.46 on the competitive Atari 100k benchmark; a new best
for agents trained entirely within a world model. To foster future research on
diffusion for world modeling, we release our code, agents and playable world
models at https://github.com/eloialonso/diamond.

摘要：世界模型構成了一種有前途的方法，可以用於以安全且樣本有效的方式訓練強化學習代理。最近的世界模型主要在離散潛在變數序列上運作，以模擬環境動態。然而，這種壓縮成一個緊湊的離散表示可能會忽略對強化學習很重要的視覺細節。同時，擴散模型已成為圖像生成的顯著方法，挑戰了對離散潛在變數進行建模的既定方法。受這種範式轉變的激勵，我們引入了 DIAMOND（DIffusion As a Model Of eNvironment Dreams），這是一種在擴散世界模型中訓練的強化學習代理。我們分析了使擴散適合世界建模所需的關鍵設計選擇，並展示了改進的視覺細節如何能提升代理效能。DIAMOND 在競爭激烈的 Atari 100k 基準測試中獲得了 1.46 的平均人類標準化分數；這是完全在世界模型內訓練的代理的新最佳分數。為了促進未來對世界建模擴散的研究，我們在 https://github.com/eloialonso/diamond 上發布了我們的程式碼、代理和可玩世界模型。

##### **Layout Agnostic Human Activity Recognition in Smart Homes through Textual Descriptions Of Sensor Triggers (TDOST)**
2405.12368v1 by Megha Thukral, Sourish Gunesh Dhekane, Shruthi K. Hiremath, Harish Haresamudram, Thomas Ploetz

Human activity recognition (HAR) using ambient sensors in smart homes has
numerous applications for human healthcare and wellness. However, building
general-purpose HAR models that can be deployed to new smart home environments
requires a significant amount of annotated sensor data and training overhead.
Most smart homes vary significantly in their layouts, i.e., floor plans and the
specifics of sensors embedded, resulting in low generalizability of HAR models
trained for specific homes. We address this limitation by introducing a novel,
layout-agnostic modeling approach for HAR systems in smart homes that utilizes
the transferrable representational capacity of natural language descriptions of
raw sensor data. To this end, we generate Textual Descriptions Of Sensor
Triggers (TDOST) that encapsulate the surrounding trigger conditions and
provide cues for underlying activities to the activity recognition models.
Leveraging textual embeddings, rather than raw sensor data, we create activity
recognition systems that predict standard activities across homes without
either (re-)training or adaptation on target homes. Through an extensive
evaluation, we demonstrate the effectiveness of TDOST-based models in unseen
smart homes through experiments on benchmarked CASAS datasets. Furthermore, we
conduct a detailed analysis of how the individual components of our approach
affect downstream activity recognition performance.

摘要：利用智慧家庭中環境感測器進行人類活動辨識 (HAR) 在人類醫療保健和健康方面有許多應用。然而，建立可部署到新智慧家庭環境的通用 HAR 模型需要大量的註解感測器資料和訓練開銷。大多數智慧家庭的配置差異很大，例如樓層平面圖和嵌入式感測器的規格，導致為特定家庭訓練的 HAR 模型的概括性很低。我們透過引入一種創新的、與配置無關的智慧家庭 HAR 系統建模方法來解決這個限制，該方法利用自然語言描述原始感測器資料的可轉移表示能力。為此，我們產生感測器觸發文字描述 (TDOST)，它包含周圍的觸發條件，並為活動辨識模型提供底層活動的線索。我們利用文字嵌入，而非原始感測器資料，建立活動辨識系統，可在家庭中預測標準活動，而無需在目標家庭中進行（重新）訓練或調整。透過廣泛的評估，我們在基準 CASAS 資料集上的實驗中證明了 TDOST 模型在未見過的智慧家庭中的有效性。此外，我們對我們方法的各個組成部分如何影響下游活動辨識效能進行了詳細的分析。

##### **Question-Based Retrieval using Atomic Units for Enterprise RAG**
2405.12363v1 by Vatsal Raina, Mark Gales

Enterprise retrieval augmented generation (RAG) offers a highly flexible
framework for combining powerful large language models (LLMs) with internal,
possibly temporally changing, documents. In RAG, documents are first chunked.
Relevant chunks are then retrieved for a specific user query, which are passed
as context to a synthesizer LLM to generate the query response. However, the
retrieval step can limit performance, as incorrect chunks can lead the
synthesizer LLM to generate a false response. This work proposes a zero-shot
adaptation of standard dense retrieval steps for more accurate chunk recall.
Specifically, a chunk is first decomposed into atomic statements. A set of
synthetic questions are then generated on these atoms (with the chunk as the
context). Dense retrieval involves finding the closest set of synthetic
questions, and associated chunks, to the user query. It is found that retrieval
with the atoms leads to higher recall than retrieval with chunks. Further
performance gain is observed with retrieval using the synthetic questions
generated over the atoms. Higher recall at the retrieval step enables higher
performance of the enterprise LLM using the RAG pipeline.

摘要：企業檢索增強生成 (RAG) 提供了一個高度彈性的框架，用於將強大的大型語言模型 (LLM) 與內部（可能在時間上會變動的）文件結合起來。在 RAG 中，文件會先進行分塊。接著針對特定使用者查詢檢索相關的區塊，並將這些區塊作為背景傳遞給合成器 LLM，以產生查詢回應。然而，檢索步驟可能會限制效能，因為不正確的區塊可能會導致合成器 LLM 產生錯誤的回應。這項工作提出了一個標準密集檢索步驟的零次學習適應，以提高區塊召回的準確性。具體來說，會先將區塊分解成原子陳述。接著在這些原子（以區塊作為背景）上產生一組合成式問題。密集檢索涉及尋找與使用者查詢最接近的一組合成式問題和關聯區塊。發現使用原子進行檢索會比使用區塊進行檢索產生更高的召回率。使用在原子上產生的合成式問題進行檢索時，還觀察到效能進一步提升。檢索步驟的召回率越高，使用 RAG 管線的企業 LLM 效能就越高。

##### **Perturbing the Gradient for Alleviating Meta Overfitting**
2405.12299v1 by Manas Gogoi, Sambhavi Tiwari, Shekhar Verma

The reason for Meta Overfitting can be attributed to two factors: Mutual
Non-exclusivity and the Lack of diversity, consequent to which a single global
function can fit the support set data of all the meta-training tasks and fail
to generalize to new unseen tasks. This issue is evidenced by low error rates
on the meta-training tasks, but high error rates on new tasks. However, there
can be a number of novel solutions to this problem keeping in mind any of the
two objectives to be attained, i.e. to increase diversity in the tasks and to
reduce the confidence of the model for some of the tasks. In light of the
above, this paper proposes a number of solutions to tackle meta-overfitting on
few-shot learning settings, such as few-shot sinusoid regression and few shot
classification. Our proposed approaches demonstrate improved generalization
performance compared to state-of-the-art baselines for learning in a
non-mutually exclusive task setting. Overall, this paper aims to provide
insights into tackling overfitting in meta-learning and to advance the field
towards more robust and generalizable models.

摘要：Meta 過擬合的原因可歸因於兩個因素：相互非獨佔性和缺乏多樣性，因此單一全域函數可以擬合所有元訓練任務的支援集資料，但無法概化到新的未見任務。此問題的證據是元訓練任務的錯誤率低，但新任務的錯誤率高。然而，可以針對這個問題提出許多新穎的解決方案，同時考慮要達成的兩個目標，即增加任務的多樣性並降低模型對某些任務的信心。有鑑於此，本文提出了一些解決方案來解決少次學習設定中的元過擬合，例如少次正弦迴歸和少次分類。與學習中非相互排他任務設定的最新基準線相比，我們提出的方法展示了改進的概化效能。總而言之，本文旨在提供見解來解決元學習中的過擬合，並推動該領域朝向更穩健且可概化的模型。

##### **Adapting Large Multimodal Models to Distribution Shifts: The Role of In-Context Learning**
2405.12217v1 by Guanglin Zhou, Zhongyi Han, Shiming Chen, Biwei Huang, Liming Zhu, Salman Khan, Xin Gao, Lina Yao

Recent studies indicate that large multimodal models (LMMs) are highly robust
against natural distribution shifts, often surpassing previous baselines.
Despite this, domain-specific adaptation is still necessary, particularly in
specialized areas like healthcare. Due to the impracticality of fine-tuning
LMMs given their vast parameter space, this work investigates in-context
learning (ICL) as an effective alternative for enhancing LMMs' adaptability. We
find that the success of ICL heavily relies on the choice of demonstration,
mirroring challenges seen in large language models but introducing unique
complexities for LMMs facing distribution shifts. Our study addresses this by
evaluating an unsupervised ICL method, TopKNearestPR, which selects in-context
examples through a nearest example search based on feature similarity. We
uncover that its effectiveness is limited by the deficiencies of pre-trained
vision encoders under distribution shift scenarios. To address these
challenges, we propose InvariantSelectPR, a novel method leveraging
Class-conditioned Contrastive Invariance (CCI) for more robust demonstration
selection. Specifically, CCI enhances pre-trained vision encoders by improving
their discriminative capabilities across different classes and ensuring
invariance to domain-specific variations. This enhancement allows the encoders
to effectively identify and retrieve the most informative examples, which are
then used to guide LMMs in adapting to new query samples under varying
distributions. Our experiments show that InvariantSelectPR substantially
improves the adaptability of LMMs, achieving significant performance gains on
benchmark datasets, with a 34.2%$\uparrow$ accuracy increase in 7-shot on
Camelyon17 and 16.9%$\uparrow$ increase in 7-shot on HAM10000 compared to the
baseline zero-shot performance.

摘要：<paragraph>最近的研究表明，大型多模态模型 (LMM) 对于自然分布位移具有高度鲁棒性，通常超越之前的基准。
尽管如此，领域特定适应仍然是必要的，尤其是在医疗保健等专业领域。由于 LMM 参数空间巨大，微调不切实际，因此这项工作研究了语境学习 (ICL) 作为增强 LMM 适应性的有效替代方案。我们
发现 ICL 的成功在很大程度上取决于演示的选择，这反映了在大语言模型中看到的挑战，但为面临分布位移的 LMM 引入了独特的复杂性。我们的研究通过评估无监督 ICL 方法 TopKNearestPR 来解决这个问题，该方法通过基于特征相似性的最近示例搜索来选择语境示例。我们
发现其有效性受到预训练视觉编码器在分布位移场景下的缺陷的限制。为了解决这些
挑战，我们提出了 InvariantSelectPR，这是一种利用类条件对比不变性 (CCI) 进行更稳健的演示选择的新方法。具体来说，CCI 通过提高预训练视觉编码器在不同类别的判别能力并确保
对特定领域的变化保持不变性来增强它们。这种增强使编码器能够有效识别和检索信息最丰富的示例，然后用于指导 LMM 在不同分布下适应新的查询样本。我们的实验表明，InvariantSelectPR 大大提高了 LMM 的适应性，在基准数据集上实现了显著的性能提升，在 Camelyon17 上的 7 次拍摄准确率提高了 34.2%，在 HAM10000 上的 7 次拍摄准确率提高了 16.9%，与
基线零次拍摄性能相比。</paragraph>

##### **MathBench: Evaluating the Theory and Application Proficiency of LLMs with a Hierarchical Mathematics Benchmark**
2405.12209v1 by Hongwei Liu, Zilong Zheng, Yuxuan Qiao, Haodong Duan, Zhiwei Fei, Fengzhe Zhou, Wenwei Zhang, Songyang Zhang, Dahua Lin, Kai Chen

Recent advancements in large language models (LLMs) have showcased
significant improvements in mathematics. However, traditional math benchmarks
like GSM8k offer a unidimensional perspective, falling short in providing a
holistic assessment of the LLMs' math capabilities. To address this gap, we
introduce MathBench, a new benchmark that rigorously assesses the mathematical
capabilities of large language models. MathBench spans a wide range of
mathematical disciplines, offering a detailed evaluation of both theoretical
understanding and practical problem-solving skills. The benchmark progresses
through five distinct stages, from basic arithmetic to college mathematics, and
is structured to evaluate models at various depths of knowledge. Each stage
includes theoretical questions and application problems, allowing us to measure
a model's mathematical proficiency and its ability to apply concepts in
practical scenarios. MathBench aims to enhance the evaluation of LLMs'
mathematical abilities, providing a nuanced view of their knowledge
understanding levels and problem solving skills in a bilingual context. The
project is released at https://github.com/open-compass/MathBench .

摘要：大型語言模型 (LLM) 近期進展已展示出數學方面的重大改進。然而，傳統數學基準（例如 GSM8k）提供了一種單向度觀點，無法全面評估 LLM 的數學能力。為了解決這個差距，我們引入了 MathBench，這是一個新的基準，可以嚴格評估大型語言模型的數學能力。MathBench 涵蓋了廣泛的數學學科，對理論理解和實際問題解決技能進行了詳細評估。基準分為五個不同的階段，從基礎算術到大學數學，並旨在評估模型在不同知識深度下的表現。每個階段都包含理論問題和應用問題，讓我們可以衡量模型的數學能力及其在實際場景中應用概念的能力。MathBench 旨在加強對 LLM 數學能力的評估，在雙語環境中提供其知識理解層次和問題解決技能的細緻觀點。該專案已在 https://github.com/open-compass/MathBench 發布。

##### **Modeling citation worthiness by using attention-based bidirectional long short-term memory networks and interpretable models**
2405.12206v1 by Tong Zeng, Daniel E. Acuna

Scientist learn early on how to cite scientific sources to support their
claims. Sometimes, however, scientists have challenges determining where a
citation should be situated -- or, even worse, fail to cite a source
altogether. Automatically detecting sentences that need a citation (i.e.,
citation worthiness) could solve both of these issues, leading to more robust
and well-constructed scientific arguments. Previous researchers have applied
machine learning to this task but have used small datasets and models that do
not take advantage of recent algorithmic developments such as attention
mechanisms in deep learning. We hypothesize that we can develop significantly
accurate deep learning architectures that learn from large supervised datasets
constructed from open access publications. In this work, we propose a
Bidirectional Long Short-Term Memory (BiLSTM) network with attention mechanism
and contextual information to detect sentences that need citations. We also
produce a new, large dataset (PMOA-CITE) based on PubMed Open Access Subset,
which is orders of magnitude larger than previous datasets. Our experiments
show that our architecture achieves state of the art performance on the
standard ACL-ARC dataset ($F_{1}=0.507$) and exhibits high performance
($F_{1}=0.856$) on the new PMOA-CITE. Moreover, we show that it can transfer
learning across these datasets. We further use interpretable models to
illuminate how specific language is used to promote and inhibit citations. We
discover that sections and surrounding sentences are crucial for our improved
predictions. We further examined purported mispredictions of the model, and
uncovered systematic human mistakes in citation behavior and source data. This
opens the door for our model to check documents during pre-submission and
pre-archival procedures. We make this new dataset, the code, and a web-based
tool available to the community.

摘要：<paragraph>科學家很早就學會如何引用科學文獻來支持他們的說法。然而，有時候，科學家在決定引文應置於何處時會遇到挑戰，或者更糟的是，根本沒有引用來源。自動偵測需要引用的句子（即引用的價值）可以解決這兩個問題，從而產生更強大且結構良好的科學論證。先前的研究人員已將機器學習應用於此任務，但使用了小型資料集和模型，這些模型並未利用深度學習中的最新演算法發展，例如注意力機制。我們假設我們可以開發出從由開放獲取出版物建構的大型監督式資料集中學習的顯著準確深度學習架構。在這項工作中，我們提出了一個具有注意力機制和上下文資訊的雙向長短期記憶 (BiLSTM) 網路，以偵測需要引用的句子。我們還根據 PubMed 開放獲取子集製作了一個新的大型資料集 (PMOA-CITE)，其數量級大於先前的資料集。我們的實驗表明，我們的架構在標準 ACL-ARC 資料集 ($F_{1}=0.507$) 上達到了最先進的效能，並在新的 PMOA-CITE 上表現出高效能 ($F_{1}=0.856$)。此外，我們展示了它可以在這些資料集之間轉移學習。我們進一步使用可解釋模型來說明如何使用特定語言來促進和抑制引用。我們發現章節和周圍的句子對於我們改進的預測至關重要。我們進一步檢查了模型的假定錯誤預測，並發現了引用行為和來源資料中的人為系統性錯誤。這為我們的模型在提交前和歸檔前程序中檢查文件開啟了大門。我們將這個新資料集、程式碼和一個基於網路的工具提供給社群使用。</paragraph>

##### **Metacognitive Capabilities of LLMs: An Exploration in Mathematical Problem Solving**
2405.12205v1 by Aniket Didolkar, Anirudh Goyal, Nan Rosemary Ke, Siyuan Guo, Michal Valko, Timothy Lillicrap, Danilo Rezende, Yoshua Bengio, Michael Mozer, Sanjeev Arora

Metacognitive knowledge refers to humans' intuitive knowledge of their own
thinking and reasoning processes. Today's best LLMs clearly possess some
reasoning processes. The paper gives evidence that they also have metacognitive
knowledge, including ability to name skills and procedures to apply given a
task. We explore this primarily in context of math reasoning, developing a
prompt-guided interaction procedure to get a powerful LLM to assign sensible
skill labels to math questions, followed by having it perform semantic
clustering to obtain coarser families of skill labels. These coarse skill
labels look interpretable to humans.
  To validate that these skill labels are meaningful and relevant to the LLM's
reasoning processes we perform the following experiments. (a) We ask GPT-4 to
assign skill labels to training questions in math datasets GSM8K and MATH. (b)
When using an LLM to solve the test questions, we present it with the full list
of skill labels and ask it to identify the skill needed. Then it is presented
with randomly selected exemplar solved questions associated with that skill
label. This improves accuracy on GSM8k and MATH for several strong LLMs,
including code-assisted models. The methodology presented is domain-agnostic,
even though this article applies it to math problems.

摘要：元认知知识是指人类对自身思考和推理过程的直觉知识。当今最好的 LLM 显然拥有一些推理过程。本文提供了证据表明它们也具有元认知知识，包括根据给定的任务来命名技能和应用程序的能力。我们主要在数学推理的背景下探索这一点，开发了一个提示引导的交互程序，让一个强大的 LLM 为数学问题分配明智的技能标签，然后对其执行语义聚类以获得更粗略的技能标签族。这些粗略的技能标签看起来对人类来说是可解释的。
为了验证这些技能标签对 LLM 的推理过程有意义且相关，我们进行了以下实验。(a) 我们要求 GPT-4 为数学数据集 GSM8K 和 MATH 中的训练问题分配技能标签。(b) 当使用 LLM 来解决测试问题时，我们向其提供完整的技能标签列表，并要求其识别所需的技能。然后向其展示与该技能标签相关联的随机选择的示例求解问题。这提高了 GSM8k 和 MATH 对几个强大的 LLM 的准确性，包括代码辅助模型。所提出的方法论与领域无关，尽管本文将其应用于数学问题。

##### **Hierarchical Neural Operator Transformer with Learnable Frequency-aware Loss Prior for Arbitrary-scale Super-resolution**
2405.12202v1 by Xihaier Luo, Xiaoning Qian, Byung-Jun Yoon

In this work, we present an arbitrary-scale super-resolution (SR) method to
enhance the resolution of scientific data, which often involves complex
challenges such as continuity, multi-scale physics, and the intricacies of
high-frequency signals. Grounded in operator learning, the proposed method is
resolution-invariant. The core of our model is a hierarchical neural operator
that leverages a Galerkin-type self-attention mechanism, enabling efficient
learning of mappings between function spaces. Sinc filters are used to
facilitate the information transfer across different levels in the hierarchy,
thereby ensuring representation equivalence in the proposed neural operator.
Additionally, we introduce a learnable prior structure that is derived from the
spectral resizing of the input data. This loss prior is model-agnostic and is
designed to dynamically adjust the weighting of pixel contributions, thereby
balancing gradients effectively across the model. We conduct extensive
experiments on diverse datasets from different domains and demonstrate
consistent improvements compared to strong baselines, which consist of various
state-of-the-art SR methods.

摘要：在這項工作中，我們提出了一種任意尺度的超解析度 (SR) 方法，以增強科學數據的分辨率，這通常涉及連續性、多尺度物理以及高頻率訊號的複雜性等挑戰。該方法以算子學習為基礎，具有解析度不變性。我們模型的核心是一個分層神經算子，它利用了伽遼金類型自注意力機制，實現了函數空間之間對應關係的有效學習。Sinc 濾波器用於促進層次結構中不同層級之間的資訊傳遞，從而確保了所提出的神經算子中的表示等價性。此外，我們還引入了一個可學習的先驗結構，它來自輸入數據的頻譜調整。此損失先驗與模型無關，旨在動態調整像素貢獻的權重，從而有效地平衡整個模型中的梯度。我們對來自不同領域的不同數據集進行了廣泛的實驗，並展示了與強基線相比的一致改進，這些基線包括各種最先進的 SR 方法。

##### **Multi-order Graph Clustering with Adaptive Node-level Weight Learning**
2405.12183v1 by Ye Liu, Xuelei Lin, Yejia Chen, Reynold Cheng

Current graph clustering methods emphasize individual node and edge con
nections, while ignoring higher-order organization at the level of motif. Re
cently, higher-order graph clustering approaches have been designed by motif
based hypergraphs. However, these approaches often suffer from hypergraph
fragmentation issue seriously, which degrades the clustering performance
greatly. Moreover, real-world graphs usually contain diverse motifs, with nodes
participating in multiple motifs. A key challenge is how to achieve precise
clustering results by integrating information from multiple motifs at the node
level. In this paper, we propose a multi-order graph clustering model (MOGC) to
integrate multiple higher-order structures and edge connections at node level.
MOGC employs an adaptive weight learning mechanism to au tomatically adjust the
contributions of different motifs for each node. This not only tackles
hypergraph fragmentation issue but enhances clustering accuracy. MOGC is
efficiently solved by an alternating minimization algo rithm. Experiments on
seven real-world datasets illustrate the effectiveness of MOGC.

摘要：目前圖形聚類方法強調個別節點和邊緣連接，而忽略了母題層級的高階組織。最近，高階圖形聚類方法已由基於母題的超圖設計。然而，這些方法通常會遭受超圖碎片化問題的嚴重影響，這會大幅降低聚類效能。此外，真實世界的圖形通常包含多種母題，且節點參與多個母題。一項關鍵挑戰是如何透過整合節點層級來自多個母題的資訊，來達成精確的聚類結果。在本文中，我們提出一個多階圖形聚類模型 (MOGC)，以整合節點層級的多個高階結構和邊緣連接。MOGC 採用自適應權重學習機制，自動調整每個節點不同母題的貢獻。這不僅解決了超圖碎片化問題，也增強了聚類準確度。MOGC 可透過交替最小化演算法有效率地解決。在七個真實世界資料集上的實驗說明了 MOGC 的有效性。

##### **Building Temporal Kernels with Orthogonal Polynomials**
2405.12179v1 by Yan Ru Pei, Olivier Coenen

We introduce a class of models named PLEIADES (PoLynomial Expansion In
Adaptive Distributed Event-based Systems), which contains temporal convolution
kernels generated from orthogonal polynomial basis functions. We focus on
interfacing these networks with event-based data to perform online
spatiotemporal classification and detection with low latency. By virtue of
using structured temporal kernels and event-based data, we have the freedom to
vary the sample rate of the data along with the discretization step-size of the
network without additional finetuning. We experimented with three event-based
benchmarks and obtained state-of-the-art results on all three by large margins
with significantly smaller memory and compute costs. We achieved: 1) 99.59%
accuracy with 192K parameters on the DVS128 hand gesture recognition dataset
and 100% with a small additional output filter; 2) 99.58% test accuracy with
277K parameters on the AIS 2024 eye tracking challenge; and 3) 0.556 mAP with
576k parameters on the PROPHESEE 1 Megapixel Automotive Detection Dataset.

摘要：<paragraph>我们引入了一类名为 PLEIADES（自适应分布式事件驱动系统中的多项式扩展）的模型，其中包含由正交多项式基函数生成的时序卷积核。我们专注于将这些网络与基于事件的数据进行接口，以执行具有低延迟的在线时空分类和检测。由于使用了结构化的时序核和基于事件的数据，我们可以在不进行额外微调的情况下自由改变数据的采样率以及网络的离散化步长。我们对三个基于事件的基准进行了实验，在所有三个基准上都获得了最先进的结果，并且显著降低了内存和计算成本。我们实现了：1）在 DVS128 手势识别数据集上，使用 192K 参数实现了 99.59% 的准确度，使用一个小的附加输出滤波器实现了 100% 的准确度；2）在 AIS 2024 眼动追踪挑战中，使用 277K 参数实现了 99.58% 的测试准确度；3）在 PROPHESEE 1 百万像素汽车检测数据集中，使用 576k 参数实现了 0.556 mAP。</paragraph>

##### **CT-Eval: Benchmarking Chinese Text-to-Table Performance in Large Language Models**
2405.12174v1 by Haoxiang Shi, Jiaan Wang, Jiarong Xu, Cen Wang, Tetsuya Sakai

Text-to-Table aims to generate structured tables to convey the key
information from unstructured documents. Existing text-to-table datasets are
typically oriented English, limiting the research in non-English languages.
Meanwhile, the emergence of large language models (LLMs) has shown great
success as general task solvers in multi-lingual settings (e.g., ChatGPT),
theoretically enabling text-to-table in other languages. In this paper, we
propose a Chinese text-to-table dataset, CT-Eval, to benchmark LLMs on this
task. Our preliminary analysis of English text-to-table datasets highlights two
key factors for dataset construction: data diversity and data hallucination.
Inspired by this, the CT-Eval dataset selects a popular Chinese
multidisciplinary online encyclopedia as the source and covers 28 domains to
ensure data diversity. To minimize data hallucination, we first train an LLM to
judge and filter out the task samples with hallucination, then employ human
annotators to clean the hallucinations in the validation and testing sets.
After this process, CT-Eval contains 88.6K task samples. Using CT-Eval, we
evaluate the performance of open-source and closed-source LLMs. Our results
reveal that zero-shot LLMs (including GPT-4) still have a significant
performance gap compared with human judgment. Furthermore, after fine-tuning,
open-source LLMs can significantly improve their text-to-table ability,
outperforming GPT-4 by a large margin. In short, CT-Eval not only helps
researchers evaluate and quickly understand the Chinese text-to-table ability
of existing LLMs but also serves as a valuable resource to significantly
improve the text-to-table performance of LLMs.

摘要：文本到表格旨在生成结构化表格来传达非结构化文档中的关键信息。现有的文本到表格数据集通常面向英语，限制了非英语语言的研究。与此同时，大型语言模型（LLM）的出现已显示出作为多语言环境中的通用任务解决者的巨大成功（例如 ChatGPT），理论上可以在其他语言中实现文本到表格。在本文中，我们提出了一个中文文本到表格数据集 CT-Eval，以对 LLM 在此任务上进行基准测试。我们对英语文本到表格数据集的初步分析突出了数据集构建的两个关键因素：数据多样性和数据幻觉。受此启发，CT-Eval 数据集选择了一个流行的中文多学科在线百科全书作为来源，并涵盖 28 个领域以确保数据多样性。为了最大程度地减少数据幻觉，我们首先训练一个 LLM 来判断并过滤掉带有幻觉的任务样本，然后雇用人工注释员来清理验证和测试集中的幻觉。经过这个过程，CT-Eval 包含 88.6K 个任务样本。使用 CT-Eval，我们评估了开源和闭源 LLM 的性能。我们的结果表明，零样本 LLM（包括 GPT-4）与人类判断相比仍然存在显着的性能差距。此外，在微调之后，开源 LLM 可以显着提高其文本到表格的能力，大幅优于 GPT-4。简而言之，CT-Eval 不仅帮助研究人员评估和快速了解现有 LLM 的中文文本到表格能力，而且还作为一种宝贵的资源来显着提高 LLM 的文本到表格性能。

##### **Fennec: Fine-grained Language Model Evaluation and Correction Extended through Branching and Bridging**
2405.12163v1 by Xiaobo Liang, Haoke Zhang, Helan hu, Juntao Li, Jun Xu, Min Zhang

The rapid advancement of large language models has given rise to a plethora
of applications across a myriad of real-world tasks, mainly centered on
aligning with human intent. However, the complexities inherent in human intent
necessitate a dependence on labor-intensive and time-consuming human
evaluation. To alleviate this constraint, we delve into the paradigm of
employing open-source large language models as evaluators, aligning with the
prevailing trend of utilizing GPT-4. Particularly, we present a step-by-step
evaluation framework: \textbf{Fennec}, capable of \textbf{F}ine-grained
\textbf{E}valuatio\textbf{N} and correctio\textbf{N} \textbf{E}xtended through
bran\textbf{C}hing and bridging. Specifically, the branching operation dissects
the evaluation task into various dimensions and granularities, thereby
alleviating the challenges associated with evaluation. Concurrently, the
bridging operation amalgamates diverse training datasets, augmenting the
variety of evaluation tasks. In experimental trials, our 7B model consistently
outperforms open-source larger-scale evaluation models across various widely
adopted benchmarks in terms of both \textit{Agreement} and
\textit{Consistency}, closely approaching the capabilities of GPT-4. We employ
the fine-grained correction capabilities induced by the evaluation model to
refine multiple model responses, and the results show that the refinement
elevates the quality of responses, leading to an improvement of 1-2 points on
the MT-Bench. Our code is available at
Github\footnote{\url{https://github.com/dropreg/Fennec}}.

摘要：<paragraph>大型語言模型的快速進展已產生大量應用，橫跨無數真實世界的任務，主要集中在與人類意圖保持一致。然而，人類意圖中固有的複雜性需要依賴於勞動密集且耗時的評估。為了緩解這種限制，我們深入探討採用開放原始碼大型語言模型作為評估者的範例，與利用 GPT-4 的盛行趨勢保持一致。特別是，我們提出了一個逐步評估框架：**Fennec**，能夠進行**F**ine-grained**E**valuatio**N** and correctio**N** **E**xtended through bran**C**hing and bridging。具體來說，分支操作將評估任務剖析成各種維度和粒度，從而緩解與評估相關的挑戰。同時，橋接操作合併了不同的訓練資料集，增加了評估任務的多樣性。在實驗試驗中，我們的 7B 模型在各種廣泛採用的基準測試中，無論在**一致性**和**一致性**方面，都持續優於開放原始碼的大規模評估模型，接近 GPT-4 的能力。我們採用評估模型誘導的細粒度校正能力來改善多個模型回應，結果表明，這種改善提升了回應的品質，導致 MT-Bench 上提高了 1-2 分。我們的程式碼可以在 Github\footnote{\url{https://github.com/dropreg/Fennec}} 中取得。</paragraph>

##### **Bangladeshi Native Vehicle Detection in Wild**
2405.12150v1 by Bipin Saha, Md. Johirul Islam, Shaikh Khaled Mostaque, Aditya Bhowmik, Tapodhir Karmakar Taton, Md. Nakib Hayat Chowdhury, Mamun Bin Ibne Reaz

The success of autonomous navigation relies on robust and precise vehicle
recognition, hindered by the scarcity of region-specific vehicle detection
datasets, impeding the development of context-aware systems. To advance
terrestrial object detection research, this paper proposes a native vehicle
detection dataset for the most commonly appeared vehicle classes in Bangladesh.
17 distinct vehicle classes have been taken into account, with fully annotated
81542 instances of 17326 images. Each image width is set to at least 1280px.
The dataset's average vehicle bounding box-to-image ratio is 4.7036. This
Bangladesh Native Vehicle Dataset (BNVD) has accounted for several
geographical, illumination, variety of vehicle sizes, and orientations to be
more robust on surprised scenarios. In the context of examining the BNVD
dataset, this work provides a thorough assessment with four successive You Only
Look Once (YOLO) models, namely YOLO v5, v6, v7, and v8. These dataset's
effectiveness is methodically evaluated and contrasted with other vehicle
datasets already in use. The BNVD dataset exhibits mean average precision(mAP)
at 50% intersection over union (IoU) is 0.848 corresponding precision and
recall values of 0.841 and 0.774. The research findings indicate a mAP of 0.643
at an IoU range of 0.5 to 0.95. The experiments show that the BNVD dataset
serves as a reliable representation of vehicle distribution and presents
considerable complexities.

摘要：<paragraph>自主導航的成功有賴於強健且精確的車輛辨識，而這卻受到特定區域車輛偵測資料集的匱乏所阻礙，進而妨礙了情境感知系統的發展。為了推動地面物體偵測的研究，本篇論文提出了一個針對孟加拉國最常見車輛類別的原生車輛偵測資料集。我們考慮了 17 個不同的車輛類別，並針對 17326 張影像進行了完整的標註，共標註了 81542 個實例。每張影像的寬度都設定為至少 1280 像素。該資料集的平均車輛邊界框與影像比例為 4.7036。這個孟加拉國原生車輛資料集 (BNVD) 考慮了多種地理、光照、車輛大小和方向，以便在意外的情況下更為強健。在檢查 BNVD 資料集的脈絡下，本研究提供了對四個連續的 You Only Look Once (YOLO) 模型的徹底評估，分別是 YOLO v5、v6、v7 和 v8。我們有系統地評估了這些資料集的有效性，並與其他現有車輛資料集進行對比。BNVD 資料集在 50% 交集並集 (IoU) 上展現出 0.848 的平均準確度 (mAP)，對應的準確率和召回率分別為 0.841 和 0.774。研究結果顯示，在 0.5 到 0.95 的 IoU 範圍內，mAP 為 0.643。實驗顯示，BNVD 資料集可作為車輛分佈的可靠表示，並呈現出相當的複雜性。</paragraph>

##### **Eliciting Problem Specifications via Large Language Models**
2405.12147v1 by Robert E. Wray, James R. Kirk, John E. Laird

Cognitive systems generally require a human to translate a problem definition
into some specification that the cognitive system can use to attempt to solve
the problem or perform the task. In this paper, we illustrate that large
language models (LLMs) can be utilized to map a problem class, defined in
natural language, into a semi-formal specification that can then be utilized by
an existing reasoning and learning system to solve instances from the problem
class. We present the design of LLM-enabled cognitive task analyst agent(s).
Implemented with LLM agents, this system produces a definition of problem
spaces for tasks specified in natural language. LLM prompts are derived from
the definition of problem spaces in the AI literature and general
problem-solving strategies (Polya's How to Solve It). A cognitive system can
then use the problem-space specification, applying domain-general problem
solving strategies ("weak methods" such as search), to solve multiple instances
of problems from the problem class. This result, while preliminary, suggests
the potential for speeding cognitive systems research via disintermediation of
problem formulation while also retaining core capabilities of cognitive
systems, such as robust inference and online learning.

摘要：認知系統通常需要人類將問題定義轉換為認知系統可利用來嘗試解決問題或執行任務的某些規格。在本文中，我們說明大型語言模型 (LLM) 可用於將以自然語言定義的問題類別對應到半正式規格，然後現有的推理和學習系統可利用該規格來解決問題類別中的實例。我們提出 LLM 啟用的認知任務分析代理的設計。此系統利用 LLM 代理實作，可產生以自然語言指定的任務問題空間定義。LLM 提示來自 AI 文獻中問題空間的定義和一般問題解決策略（波利亞的如何解題）。認知系統接著可以使用問題空間規格，套用領域通用的問題解決策略（「弱方法」，例如搜尋），來解決問題類別中多個問題實例。此結果雖然初步，但顯示出透過問題表述的去中介化來加速認知系統研究的潛力，同時也保留認知系統的核心功能，例如強健的推論和線上學習。

##### **MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning**
2405.12130v1 by Ting Jiang, Shaohan Huang, Shengyue Luo, Zihan Zhang, Haizhen Huang, Furu Wei, Weiwei Deng, Feng Sun, Qi Zhang, Deqing Wang, Fuzhen Zhuang

Low-rank adaptation is a popular parameter-efficient fine-tuning method for
large language models. In this paper, we analyze the impact of low-rank
updating, as implemented in LoRA. Our findings suggest that the low-rank
updating mechanism may limit the ability of LLMs to effectively learn and
memorize new knowledge. Inspired by this observation, we propose a new method
called MoRA, which employs a square matrix to achieve high-rank updating while
maintaining the same number of trainable parameters. To achieve it, we
introduce the corresponding non-parameter operators to reduce the input
dimension and increase the output dimension for the square matrix. Furthermore,
these operators ensure that the weight can be merged back into LLMs, which
makes our method can be deployed like LoRA. We perform a comprehensive
evaluation of our method across five tasks: instruction tuning, mathematical
reasoning, continual pretraining, memory and pretraining. Our method
outperforms LoRA on memory-intensive tasks and achieves comparable performance
on other tasks.

摘要：低秩適應是一種廣受歡迎且參數效率高的微調方法，適用於大型語言模型。在本文中，我們分析了低秩更新的影響，就像在 LoRA 中實作的那樣。我們的研究結果表明，低秩更新機制可能會限制大型語言模型有效學習和記憶新知識的能力。受到這一觀察結果的啟發，我們提出了一種名為 MoRA 的新方法，它採用一個方陣來實現高秩更新，同時保持相同數量的可訓練參數。為此，我們引入了相應的非參數運算子，以降低輸入維度並增加方陣的輸出維度。此外，這些運算子確保權重可以合併回大型語言模型，這使得我們的模型可以像 LoRA 一樣部署。我們對我們的模型進行了全面的評估，涵蓋了五項任務：指令微調、數學推理、持續預訓練、記憶和預訓練。我們的模型在記憶密集型任務上優於 LoRA，並在其他任務上實現了可比的效能。

##### **Prompt Learning for Generalized Vehicle Routing**
2405.12262v1 by Fei Liu, Xi Lin, Weiduo Liao, Zhenkun Wang, Qingfu Zhang, Xialiang Tong, Mingxuan Yuan

Neural combinatorial optimization (NCO) is a promising learning-based
approach to solving various vehicle routing problems without much manual
algorithm design. However, the current NCO methods mainly focus on the
in-distribution performance, while the real-world problem instances usually
come from different distributions. A costly fine-tuning approach or generalized
model retraining from scratch could be needed to tackle the out-of-distribution
instances. Unlike the existing methods, this work investigates an efficient
prompt learning approach in NCO for cross-distribution adaptation. To be
concrete, we propose a novel prompt learning method to facilitate fast
zero-shot adaptation of a pre-trained model to solve routing problem instances
from different distributions. The proposed model learns a set of prompts among
various distributions and then selects the best-matched one to prompt a
pre-trained attention model for each problem instance. Extensive experiments
show that the proposed prompt learning approach facilitates the fast adaptation
of pre-trained routing models. It also outperforms existing generalized models
on both in-distribution prediction and zero-shot generalization to a diverse
set of new tasks. Our code implementation is available online
https://github.com/FeiLiu36/PromptVRP.

摘要：神經組合最佳化 (NCO) 是一種有前途的基於學習的方法，用於解決各種車輛路線問題，而無需太多手動演算法設計。然而，目前的 NCO 方法主要關注於分配內效能，而真實世界的問題實例通常來自不同的分配。可能需要昂貴的微調方法或從頭開始進行廣義模型再訓練，才能處理分配外實例。與現有方法不同，這項工作研究了 NCO 中一種有效的提示學習方法，用於跨分配適應。具體來說，我們提出了一種新穎的提示學習方法，以促進預訓練模型快速零次適應，以解決來自不同分配的路由問題實例。所提出的模型學習了各種分配之間的一組提示，然後選擇最佳匹配的一個來提示每個問題實例的預訓練注意力模型。廣泛的實驗表明，所提出的提示學習方法促进了預訓練路由模型的快速適應。它在分配內預測和零次泛化到各種新任務上也優於現有的廣義模型。我們的程式碼實作可以在線上取得 https://github.com/FeiLiu36/PromptVRP。

##### **Reindex-Then-Adapt: Improving Large Language Models for Conversational Recommendation**
2405.12119v1 by Zhankui He, Zhouhang Xie, Harald Steck, Dawen Liang, Rahul Jha, Nathan Kallus, Julian McAuley

Large language models (LLMs) are revolutionizing conversational recommender
systems by adeptly indexing item content, understanding complex conversational
contexts, and generating relevant item titles. However, controlling the
distribution of recommended items remains a challenge. This leads to suboptimal
performance due to the failure to capture rapidly changing data distributions,
such as item popularity, on targeted conversational recommendation platforms.
In conversational recommendation, LLMs recommend items by generating the titles
(as multiple tokens) autoregressively, making it difficult to obtain and
control the recommendations over all items. Thus, we propose a
Reindex-Then-Adapt (RTA) framework, which converts multi-token item titles into
single tokens within LLMs, and then adjusts the probability distributions over
these single-token item titles accordingly. The RTA framework marries the
benefits of both LLMs and traditional recommender systems (RecSys):
understanding complex queries as LLMs do; while efficiently controlling the
recommended item distributions in conversational recommendations as traditional
RecSys do. Our framework demonstrates improved accuracy metrics across three
different conversational recommendation datasets and two adaptation settings

摘要：大型語言模型 (LLM) 透過靈活地索引項目內容、理解複雜的對話脈絡，以及產生相關的項目標題，徹底革新對話推薦系統。然而，控制推薦項目的分佈仍然是一項挑戰。這會導致次佳效能，因為無法擷取快速變化的資料分佈，例如目標對話推薦平台上的項目熱門程度。在對話推薦中，LLM 透過自迴歸產生標題（作為多個符號），這使得難以取得和控制所有項目的推薦。因此，我們提出一個重新索引再調整 (RTA) 架構，將多符號項目標題轉換為 LLM 中的單一符號，然後相應地調整這些單一符號項目標題的機率分佈。RTA 架構結合了 LLM 和傳統推薦系統 (RecSys) 的優點：像 LLM 一樣理解複雜的查詢；同時像傳統 RecSys 一樣有效控制對話推薦中的推薦項目分佈。我們的架構在三個不同的對話推薦資料集和兩個調整設定中展示了改善的準確度指標

##### **Linguistic Structure from a Bottleneck on Sequential Information Processing**
2405.12109v1 by Richard Futrell, Michael Hahn

Human language is a unique form of communication in the natural world,
distinguished by its structured nature. Most fundamentally, it is systematic,
meaning that signals can be broken down into component parts that are
individually meaningful -- roughly, words -- which are combined in a regular
way to form sentences. Furthermore, the way in which these parts are combined
maintains a kind of locality: words are usually concatenated together, and they
form contiguous phrases, keeping related parts of sentences close to each
other. We address the challenge of understanding how these basic properties of
language arise from broader principles of efficient communication under
information processing constraints. Here we show that natural-language-like
systematicity arises from minimization of excess entropy, a measure of
statistical complexity that represents the minimum amount of information
necessary for predicting the future of a sequence based on its past. In
simulations, we show that codes that minimize excess entropy factorize their
source distributions into approximately independent components, and then
express those components systematically and locally. Next, in a series of
massively cross-linguistic corpus studies, we show that human languages are
structured to have low excess entropy at the level of phonology, morphology,
syntax, and semantics. Our result suggests that human language performs a
sequential generalization of Independent Components Analysis on the statistical
distribution over meanings that need to be expressed. It establishes a link
between the statistical and algebraic structure of human language, and
reinforces the idea that the structure of human language may have evolved to
minimize cognitive load while maximizing communicative expressiveness.

摘要：人類語言是自然界中一種獨特的溝通形式，
以其結構化的性質為特色。最根本的是，它是系統性的，
這表示符號可以分解成個別有意義的組成部分——大致上，
就是單字——這些單字以規則的方式組合成句子。此外，這些部分組合的方式
維持著一種局部性：單字通常會串聯在一起，並形成連續的片語，
讓句子的相關部分緊密相連。我們探討了如何理解這些語言基本屬性
在資訊處理限制下，如何從有效溝通的更廣泛原則中產生。在這裡，我們展示了
類自然語言的系統性來自於過剩熵的最小化，一種統計複雜性的測量，
它表示根據序列的過去預測其未來的必要資訊最小量。在
模擬中，我們展示了最小化過剩熵的碼將其來源分佈分解成
近似獨立的組成部分，然後以系統且局部的形式表達這些組成部分。接下來，
在一系列的大規模跨語言語料庫研究中，我們展示了人類語言的結構
在音韻、形態、句法和語義的層級上具有低過剩熵。我們的結果表明，
人類語言對需要表達的意義的統計分佈執行獨立成分分析的順序概化。它建立了
人類語言的統計和代數結構之間的連結，並強化了人類語言的結構可能演化為
最小化認知負擔，同時最大化溝通表達力的想法。

##### **Imp: Highly Capable Large Multimodal Models for Mobile Devices**
2405.12107v1 by Zhenwei Shao, Zhou Yu, Jun Yu, Xuecheng Ouyang, Lihao Zheng, Zhenbiao Gai, Mingyang Wang, Jiajun Ding

By harnessing the capabilities of large language models (LLMs), recent large
multimodal models (LMMs) have shown remarkable versatility in open-world
multimodal understanding. Nevertheless, they are usually parameter-heavy and
computation-intensive, thus hindering their applicability in
resource-constrained scenarios. To this end, several lightweight LMMs have been
proposed successively to maximize the capabilities under constrained scale
(e.g., 3B). Despite the encouraging results achieved by these methods, most of
them only focus on one or two aspects of the design space, and the key design
choices that influence model capability have not yet been thoroughly
investigated. In this paper, we conduct a systematic study for lightweight LMMs
from the aspects of model architecture, training strategy, and training data.
Based on our findings, we obtain Imp -- a family of highly capable LMMs at the
2B-4B scales. Notably, our Imp-3B model steadily outperforms all the existing
lightweight LMMs of similar size, and even surpasses the state-of-the-art LMMs
at the 13B scale. With low-bit quantization and resolution reduction
techniques, our Imp model can be deployed on a Qualcomm Snapdragon 8Gen3 mobile
chip with a high inference speed of about 13 tokens/s.

摘要：<paragraph>透過利用大型語言模型 (LLM) 的能力，最近的大型多模態模型 (LMM) 在開放世界多模態理解中展現了驚人的多功能性。儘管如此，它們通常參數繁多且計算密集，因此阻礙了它們在資源受限場景中的應用。為了解決這個問題，已經陸續提出了幾種輕量級 LMM，以最大化受限規模（例如 3B）下的能力。儘管這些方法取得了令人鼓舞的成果，但它們大多只關注設計空間的一個或兩個方面，而影響模型能力的關鍵設計選擇尚未得到徹底研究。在本文中，我們從模型架構、訓練策略和訓練數據等方面對輕量級 LMM 進行了系統性研究。根據我們的研究結果，我們獲得了 Imp——一系列在 2B-4B 規模上具有高度能力的 LMM。值得注意的是，我們的 Imp-3B 模型穩定地優於所有現有類似規模的輕量級 LMM，甚至超越了 13B 規模的最新 LMM。透過低位元量化和解析度降低技術，我們的 Imp 模型可以部署在 Qualcomm Snapdragon 8Gen3 行動晶片上，具有約 13 個符號/秒的高推論速度。</paragraph>

##### **DOP: Diagnostic-Oriented Prompting for Large Language Models in Mathematical Correction**
2405.12100v1 by Hao Chen, Biaojie Zeng, Xin Lin, Liang He, Aimin Zhou

Math world problems correction(MWPC) is a novel task dedicated to rectifying
reasoning errors in the process of solving mathematical problems. In this
paper, leveraging the advancements in large language models (LLMs), we address
two key objectives:(1) Distinguishing between mathematical reasoning and error
correction; (2) Exploring strategies to enhance the error correction
capabilities of LLMs in mathematics to solve MWPC task. We noticed that, in
real-time education,assisting students in recognizing their mistakes is more
crucial than simply providing correct answers. However, current research tends
to prioritize obtaining accurate solutions to math problems rather than
correcting potentially incorrect ones. Therefore, we modify the research
paradigm, demonstrating that improving mathematical reasoning abilities does
not equate to mastery in error correction. Meanwhile, we propose a novel method
called diagnostic-oriented promping(DOP) aimed at facilitating LLMs to excel in
error correction. In experiments, DOP has shown outstanding performance,
highlighting its significant impact. We argue that in mathematical education,
the demand for outstanding correctors surpasses that for proficient reasoners.
Codes and data are available on
https://github.com/ChenhaoEcnuCS/Reason-Correct.

摘要：數學世界問題修正 (MWPC) 是一項新穎的任務，專門用於糾正解決數學問題過程中的推理錯誤。在本文中，利用大型語言模型 (LLM) 的進步，我們解決了兩個關鍵目標：(1) 區分數學推理和錯誤修正；(2) 探索增強 LLM 在數學中錯誤修正能力以解決 MWPC 任務的策略。我們注意到，在實時教育中，協助學生認識他們的錯誤比僅提供正確答案更為關鍵。然而，目前的研究所傾向於優先取得數學問題的準確解，而不是糾正潛在的錯誤解。因此，我們修改了研究範例，證明改進數學推理能力並不等於精通錯誤修正。同時，我們提出了一種稱為診斷導向提示 (DOP) 的新方法，旨在促進 LLM 在錯誤修正方面表現出色。在實驗中，DOP 已展現出傑出的效能，突顯其顯著影響。我們認為在數學教育中，對傑出修正者的需求超越了對熟練推理者的需求。程式碼和資料可在 https://github.com/ChenhaoEcnuCS/Reason-Correct 取得。

##### **Distributional Semantics, Holism, and the Instability of Meaning**
2405.12084v1 by Jumbly Grindrod, J. D. Porter, Nat Hansen

Current language models are built on the so-called distributional semantic
approach to linguistic meaning that has the distributional hypothesis at its
core. The distributional hypothesis involves a holistic conception of word
meaning: the meaning of a word depends upon its relations to other words in the
model. A standard objection to meaning holism is the charge of instability: any
change in the meaning properties of a linguistic system (a human speaker, for
example) would lead to many changes or possibly a complete change in the entire
system. When the systems in question are trying to communicate with each other,
it has been argued that instability of this kind makes communication impossible
(Fodor and Lepore 1992, 1996, 1999). In this article, we examine whether the
instability objection poses a problem for distributional models of meaning.
First, we distinguish between distinct forms of instability that these models
could exhibit, and we argue that only one such form is relevant for
understanding the relation between instability and communication: what we call
differential instability. Differential instability is variation in the relative
distances between points in a space, rather than variation in the absolute
position of those points. We distinguish differential and absolute instability
by constructing two of our own models, a toy model constructed from the text of
two novels, and a more sophisticated model constructed using the Word2vec
algorithm from a combination of Wikipedia and SEP articles. We demonstrate the
two forms of instability by showing how these models change as the corpora they
are constructed from increase in size.

摘要：當前語言模型建立在所謂的分配語義方法上，以語言意義為核心，分配假設為其核心。分配假設涉及單詞意義的整體概念：單詞的意義取決於它與模型中其他單詞的關係。對意義整體論的標準反對意見是不穩定性的指控：語言系統（例如人類說話者）的意義屬性中的任何變化都會導致許多變化，或者可能導致整個系統的完全變化。當有問題的系統嘗試相互通信時，有人認為這種不穩定性使得通信變得不可能（Fodor and Lepore 1992, 1996, 1999）。在本文中，我們探討了不穩定性反對意見是否對意義的分配模型構成問題。首先，我們區分這些模型可能表現出的不同形式的不穩定性，我們認為只有一種形式與理解不穩定性和通信之間的關係相關：我們稱之為差異不穩定性。差異不穩定性是空間中各點之間相對距離的變化，而不是這些點絕對位置的變化。我們通過構建我們自己的兩個模型來區分差異和絕對不穩定性，一個玩具模型由兩部小說的文本構建，一個更精緻的模型由 Word2vec 演算法使用維基百科和 SEP 文章的組合構建。我們通過展示這些模型如何隨著構建它們的語料庫大小的增加而改變，來證明這兩種形式的不穩定性。

##### **Selective Annotation via Data Allocation: These Data Should Be Triaged to Experts for Annotation Rather Than the Model**
2405.12081v1 by Chen Huang, Yang Deng, Wenqiang Lei, Jiancheng Lv, Ido Dagan

To obtain high-quality annotations under limited budget, semi-automatic
annotation methods are commonly used, where a portion of the data is annotated
by experts and a model is then trained to complete the annotations for the
remaining data. However, these methods mainly focus on selecting informative
data for expert annotations to improve the model predictive ability (i.e.,
triage-to-human data), while the rest of the data is indiscriminately assigned
to model annotation (i.e., triage-to-model data). This may lead to
inefficiencies in budget allocation for annotations, as easy data that the
model could accurately annotate may be unnecessarily assigned to the expert,
and hard data may be misclassified by the model. As a result, the overall
annotation quality may be compromised. To address this issue, we propose a
selective annotation framework called SANT. It effectively takes advantage of
both the triage-to-human and triage-to-model data through the proposed
error-aware triage and bi-weighting mechanisms. As such, informative or hard
data is assigned to the expert for annotation, while easy data is handled by
the model. Experimental results show that SANT consistently outperforms other
baselines, leading to higher-quality annotation through its proper allocation
of data to both expert and model workers. We provide pioneering work on data
annotation within budget constraints, establishing a landmark for future
triage-based annotation studies.

摘要：為了在有限的預算下取得高品質的註解，通常會使用半自動註解方法，其中一部分資料由專家註解，然後訓練模型來完成其餘資料的註解。然而，這些方法主要著重於選擇具資訊性的資料進行專家註解，以提升模型的預測能力（亦即，分流到人類的資料），而其餘資料則不加區別地分配給模型註解（亦即，分流到模型的資料）。這可能會導致註解預算分配的低效率，因為模型可以準確註解的容易資料可能會不必要地分配給專家，而困難的資料可能會被模型錯誤分類。因此，整體註解品質可能會受到影響。為了解決這個問題，我們提出了一個稱為 SANT 的選擇性註解架構。它有效地利用了分流到人類和分流到模型的資料，透過提出的錯誤感知分流和雙重加權機制。因此，具資訊性或困難的資料會分配給專家進行註解，而容易的資料則由模型處理。實驗結果顯示，SANT 持續優於其他基準，透過適當地將資料分配給專家和模型工作人員，產生更高品質的註解。我們提供了在預算限制下進行資料註解的開創性工作，為未來的基於分流的註解研究建立了一個里程碑。

##### **AutoSoccerPose: Automated 3D posture Analysis of Soccer Shot Movements**
2405.12070v1 by Calvin Yeung, Kenjiro Ide, Keisuke Fujii

Image understanding is a foundational task in computer vision, with recent
applications emerging in soccer posture analysis. However, existing publicly
available datasets lack comprehensive information, notably in the form of
posture sequences and 2D pose annotations. Moreover, current analysis models
often rely on interpretable linear models (e.g., PCA and regression), limiting
their capacity to capture non-linear spatiotemporal relationships in complex
and diverse scenarios. To address these gaps, we introduce the 3D Shot Posture
(3DSP) dataset in soccer broadcast videos, which represents the most extensive
sports image dataset with 2D pose annotations to our knowledge. Additionally,
we present the 3DSP-GRAE (Graph Recurrent AutoEncoder) model, a non-linear
approach for embedding pose sequences. Furthermore, we propose AutoSoccerPose,
a pipeline aimed at semi-automating 2D and 3D pose estimation and posture
analysis. While achieving full automation proved challenging, we provide a
foundational baseline, extending its utility beyond the scope of annotated
data. We validate AutoSoccerPose on SoccerNet and 3DSP datasets, and present
posture analysis results based on 3DSP. The dataset, code, and models are
available at: https://github.com/calvinyeungck/3D-Shot-Posture-Dataset.

摘要：影像理解是電腦視覺中的基礎任務，最近在足球姿勢分析中出現了新的應用。然而，現有的公開可用資料集缺乏全面的資訊，特別是姿勢序列和 2D 姿勢註解的形式。此外，目前的分析模型通常依賴於可解釋的線性模型（例如，PCA 和回歸），這限制了它們在複雜且多樣化的場景中捕捉非線性時空關係的能力。為了解決這些差距，我們在足球廣播影片中引入了 3D 射門姿勢 (3DSP) 資料集，它代表了我們所知最廣泛的具有 2D 姿勢註解的運動影像資料集。此外，我們提出了 3DSP-GRAE（圖形遞迴自動編碼器）模型，這是一種用於嵌入姿勢序列的非線性方法。此外，我們提出了 AutoSoccerPose，這是一個旨在半自動化 2D 和 3D 姿勢估計和姿勢分析的管道。儘管實現完全自動化被證明具有挑戰性，但我們提供了一個基礎基準，將其效用擴展到註解資料的範圍之外。我們在 SoccerNet 和 3DSP 資料集上驗證了 AutoSoccerPose，並根據 3DSP 呈現姿勢分析結果。資料集、程式碼和模型可在以下位置取得：https://github.com/calvinyeungck/3D-Shot-Posture-Dataset。

##### **CLAMBER: A Benchmark of Identifying and Clarifying Ambiguous Information Needs in Large Language Models**
2405.12063v1 by Tong Zhang, Peixin Qin, Yang Deng, Chen Huang, Wenqiang Lei, Junhong Liu, Dingnan Jin, Hongru Liang, Tat-Seng Chua

Large language models (LLMs) are increasingly used to meet user information
needs, but their effectiveness in dealing with user queries that contain
various types of ambiguity remains unknown, ultimately risking user trust and
satisfaction. To this end, we introduce CLAMBER, a benchmark for evaluating
LLMs using a well-organized taxonomy. Building upon the taxonomy, we construct
~12K high-quality data to assess the strengths, weaknesses, and potential risks
of various off-the-shelf LLMs. Our findings indicate the limited practical
utility of current LLMs in identifying and clarifying ambiguous user queries,
even enhanced by chain-of-thought (CoT) and few-shot prompting. These
techniques may result in overconfidence in LLMs and yield only marginal
enhancements in identifying ambiguity. Furthermore, current LLMs fall short in
generating high-quality clarifying questions due to a lack of conflict
resolution and inaccurate utilization of inherent knowledge. In this paper,
CLAMBER presents a guidance and promotes further research on proactive and
trustworthy LLMs. Our dataset is available at
https://github.com/zt991211/CLAMBER

摘要：大型語言模型 (LLM) 愈來愈常被用於滿足使用者的資訊需求，但它們在處理包含各種歧義的使用者查詢時的有效性仍不得而知，最終會影響使用者的信任和滿意度。為此，我們引入了 CLAMBER，一個用於使用井然有序的分類法評估 LLM 的基準。在分類法的基礎上，我們建構了約 12K 個高品質的資料，以評估各種現成的 LLM 的優點、缺點和潛在風險。我們的研究結果顯示，現有 LLM 在識別和釐清有歧義的使用者查詢方面的實際效用有限，即使透過思考鏈 (CoT) 和少量提示加以增強。這些技術可能會導致對 LLM 過度自信，而且在識別歧義方面僅能帶來邊際改善。此外，現有 LLM 在產生高品質的澄清問題方面也有所不足，原因是缺乏衝突解決和不準確利用內在知識。在本文中，CLAMBER 提供了一個指導方針，並促進對主動且值得信賴的 LLM 的進一步研究。我們的資料集可在 https://github.com/zt991211/CLAMBER 取得

##### **STYLE: Improving Domain Transferability of Asking Clarification Questions in Large Language Model Powered Conversational Agents**
2405.12059v1 by Yue Chen, Chen Huang, Yang Deng, Wenqiang Lei, Dingnan Jin, Jia Liu, Tat-Seng Chua

Equipping a conversational search engine with strategies regarding when to
ask clarification questions is becoming increasingly important across various
domains. Attributing to the context understanding capability of LLMs and their
access to domain-specific sources of knowledge, LLM-based clarification
strategies feature rapid transfer to various domains in a post-hoc manner.
However, they still struggle to deliver promising performance on unseen
domains, struggling to achieve effective domain transferability. We take the
first step to investigate this issue and existing methods tend to produce
one-size-fits-all strategies across diverse domains, limiting their search
effectiveness. In response, we introduce a novel method, called Style, to
achieve effective domain transferability. Our experimental results indicate
that Style bears strong domain transferability, resulting in an average search
performance improvement of ~10% on four unseen domains.

摘要：隨著對話式搜尋引擎在各種領域中日益重要，因此需要為其配備有關何時提出澄清問題的策略。基於 LLM 對脈絡理解的能力及其存取特定領域知識來源的能力，基於 LLM 的澄清策略在事後方式中具備快速轉移至各種領域的功能。然而，它們仍然難以在未見過的領域中提供有前途的效能，難以達成有效的領域可轉移性。我們採取第一步來探討這個問題，現有方法傾向於在各種領域中產生一體適用的策略，限制其搜尋效果。為了解決這個問題，我們引進一種稱為 Style 的新方法，以達成有效的領域可轉移性。我們的實驗結果顯示，Style 具有強大的領域可轉移性，導致在四個未見過的領域中平均搜尋效能提升約 10%。

##### **Unveiling factors influencing judgment variation in Sentiment Analysis with Natural Language Processing and Statistics**
2405.12055v1 by Olga Kellert, Carlos Gómez-Rodríguez, Mahmud Uz Zaman

TripAdvisor reviews and comparable data sources play an important role in
many tasks in Natural Language Processing (NLP), providing a data basis for the
identification and classification of subjective judgments, such as hotel or
restaurant reviews, into positive or negative polarities. This study explores
three important factors influencing variation in crowdsourced polarity
judgments, focusing on TripAdvisor reviews in Spanish. Three hypotheses are
tested: the role of Part Of Speech (POS), the impact of sentiment words such as
"tasty", and the influence of neutral words like "ok" on judgment variation.
The study's methodology employs one-word titles, demonstrating their efficacy
in studying polarity variation of words. Statistical tests on mean equality are
performed on word groups of our interest. The results of this study reveal that
adjectives in one-word titles tend to result in lower judgment variation
compared to other word types or POS. Sentiment words contribute to lower
judgment variation as well, emphasizing the significance of sentiment words in
research on polarity judgments, and neutral words are associated with higher
judgment variation as expected. However, these effects cannot be always
reproduced in longer titles, which suggests that longer titles do not represent
the best data source for testing the ambiguity of single words due to the
influence on word polarity by other words like negation in longer titles. This
empirical investigation contributes valuable insights into the factors
influencing polarity variation of words, providing a foundation for NLP
practitioners that aim to capture and predict polarity judgments in Spanish and
for researchers that aim to understand factors influencing judgment variation.

摘要：<paragraph>TripAdvisor 評論和類似資料來源在自然語言處理 (NLP) 的許多任務中扮演重要角色，提供資料基礎，用於識別和分類主觀判斷，例如飯店或餐廳評論，為正向或負向極性。此研究探討影響群眾外包極性判斷變化的三個重要因素，重點在於西班牙文的 TripAdvisor 評論。測試了三個假設：詞性 (POS) 的角色、美味等情感詞的影響，以及像「ok」等中性詞對判斷變化的影響。此研究的方法採用單字標題，證明其在研究詞彙極性變化的效能。對我們感興趣的詞群執行平均相等性統計檢定。此研究的結果顯示，單字標題中的形容詞傾向於造成較低的判斷變化，相較於其他詞類或詞性。情感詞也有助於降低判斷變化，強調情感詞在極性判斷研究中的重要性，而中性詞則預期會與較高的判斷變化相關。然而，這些效應無法總是在較長的標題中重現，這表示較長的標題並非測試單字歧義的最佳資料來源，因為在較長的標題中，否定等其他詞彙會影響詞彙極性。這項實證研究提供了有價值的見解，了解影響詞彙極性變化的因素，為 NLP 從業人員奠定基礎，目標在於擷取和預測西班牙文的極性判斷，以及為研究人員奠定基礎，目標在於了解影響判斷變化的因素。</paragraph>

##### **EXACT: Towards a platform for empirically benchmarking Machine Learning model explanation methods**
2405.12261v1 by Benedict Clark, Rick Wilming, Artur Dox, Paul Eschenbach, Sami Hached, Daniel Jin Wodke, Michias Taye Zewdie, Uladzislau Bruila, Marta Oliveira, Hjalmar Schulz, Luca Matteo Cornils, Danny Panknin, Ahcène Boubekki, Stefan Haufe

The evolving landscape of explainable artificial intelligence (XAI) aims to
improve the interpretability of intricate machine learning (ML) models, yet
faces challenges in formalisation and empirical validation, being an inherently
unsupervised process. In this paper, we bring together various benchmark
datasets and novel performance metrics in an initial benchmarking platform, the
Explainable AI Comparison Toolkit (EXACT), providing a standardised foundation
for evaluating XAI methods. Our datasets incorporate ground truth explanations
for class-conditional features, and leveraging novel quantitative metrics, this
platform assesses the performance of post-hoc XAI methods in the quality of the
explanations they produce. Our recent findings have highlighted the limitations
of popular XAI methods, as they often struggle to surpass random baselines,
attributing significance to irrelevant features. Moreover, we show the
variability in explanations derived from different equally performing model
architectures. This initial benchmarking platform therefore aims to allow XAI
researchers to test and assure the high quality of their newly developed
methods.

摘要：可解釋人工智慧 (XAI) 不斷演進的領域旨在改善複雜機器學習 (ML) 模型的可解釋性，但由於其本質上不受監督的程序，因此在形式化和經驗驗證方面面臨挑戰。在本文中，我們在一個初始基準測試平台中彙集了各種基準資料集和新穎的效能指標，即可解釋 AI 比較工具包 (EXACT)，為評估 XAI 方法提供標準化的基礎。我們的資料集結合了類條件特徵的基本事實解釋，並利用新穎的量化指標，此平台評估事後 XAI 方法在它們產生的解釋品質中的效能。我們最近的發現強調了流行的 XAI 方法的限制，因為它們經常難以超越隨機基準線，將重要性歸因於無關的特徵。此外，我們展示了從不同性能相同的模型架構中得出的解釋中的變異性。因此，此初始基準測試平台旨在讓 XAI 研究人員測試並確保其新開發方法的高品質。

##### **KG-RAG: Bridging the Gap Between Knowledge and Creativity**
2405.12035v1 by Diego Sanmartin

Ensuring factual accuracy while maintaining the creative capabilities of
Large Language Model Agents (LMAs) poses significant challenges in the
development of intelligent agent systems. LMAs face prevalent issues such as
information hallucinations, catastrophic forgetting, and limitations in
processing long contexts when dealing with knowledge-intensive tasks. This
paper introduces a KG-RAG (Knowledge Graph-Retrieval Augmented Generation)
pipeline, a novel framework designed to enhance the knowledge capabilities of
LMAs by integrating structured Knowledge Graphs (KGs) with the functionalities
of LLMs, thereby significantly reducing the reliance on the latent knowledge of
LLMs. The KG-RAG pipeline constructs a KG from unstructured text and then
performs information retrieval over the newly created graph to perform KGQA
(Knowledge Graph Question Answering). The retrieval methodology leverages a
novel algorithm called Chain of Explorations (CoE) which benefits from LLMs
reasoning to explore nodes and relationships within the KG sequentially.
Preliminary experiments on the ComplexWebQuestions dataset demonstrate notable
improvements in the reduction of hallucinated content and suggest a promising
path toward developing intelligent systems adept at handling
knowledge-intensive tasks.

摘要：在確保事實準確性的同時，保持大型語言模型代理（LMA）的創建能力，對智慧型代理系統的開發構成了重大的挑戰。LMA 面臨普遍的問題，例如資訊幻覺、災難性遺忘，以及在處理知識密集型任務時處理長脈絡的限制。本文介紹了 KG-RAG（知識圖譜檢索增強生成）管道，這是一個新穎的框架，旨在透過將結構化的知識圖譜（KG）與 LLM 的功能整合在一起，來增強 LMA 的知識能力，從而顯著減少對 LLM 潛在知識的依賴。KG-RAG 管道從非結構化文字中建構一個 KG，然後對新建立的圖譜執行資訊檢索，以執行 KGQA（知識圖譜問答）。檢索方法利用了一種稱為探索鏈（CoE）的新演算法，該演算法受益於 LLM 推理，以循序探索 KG 中的節點和關係。在 ComplexWebQuestions 資料集上的初步實驗證明了在減少幻覺內容方面有顯著的改進，並暗示了一條有希望的道路，朝著開發擅長處理知識密集型任務的智慧型系統邁進。

##### **Can AI Relate: Testing Large Language Model Response for Mental Health Support**
2405.12021v1 by Saadia Gabriel, Isha Puri, Xuhai Xu, Matteo Malgaroli, Marzyeh Ghassemi

Large language models (LLMs) are already being piloted for clinical use in
hospital systems like NYU Langone, Dana-Farber and the NHS. A proposed
deployment use case is psychotherapy, where a LLM-powered chatbot can treat a
patient undergoing a mental health crisis. Deployment of LLMs for mental health
response could hypothetically broaden access to psychotherapy and provide new
possibilities for personalizing care. However, recent high-profile failures,
like damaging dieting advice offered by the Tessa chatbot to patients with
eating disorders, have led to doubt about their reliability in high-stakes and
safety-critical settings.
  In this work, we develop an evaluation framework for determining whether LLM
response is a viable and ethical path forward for the automation of mental
health treatment. Using human evaluation with trained clinicians and automatic
quality-of-care metrics grounded in psychology research, we compare the
responses provided by peer-to-peer responders to those provided by a
state-of-the-art LLM.
  We show that LLMs like GPT-4 use implicit and explicit cues to infer patient
demographics like race. We then show that there are statistically significant
discrepancies between patient subgroups: Responses to Black posters
consistently have lower empathy than for any other demographic group (2%-13%
lower than the control group). Promisingly, we do find that the manner in which
responses are generated significantly impacts the quality of the response. We
conclude by proposing safety guidelines for the potential deployment of LLMs
for mental health response.

摘要：大型語言模型 (LLM) 已在紐約大學朗格尼、達納法伯和英國國家醫療服務體系等醫院系統中試行用於臨床用途。建議的部署用例是心理治療，其中由 LLM 驅動的聊天機器人可以治療正在經歷心理健康危機的患者。假設 LLM 部署於心理健康應對，可以擴大心理治療的普及度，並提供新的可能性來實現個性化護理。然而，最近備受矚目的失敗，例如 Tessa 聊天機器人為飲食失調患者提供的有害飲食建議，讓人們對其在高風險和安全關鍵環境中的可靠性產生了懷疑。
  在這項工作中，我們開發了一個評估框架，用於確定 LLM 回應是否是一個可行且合乎道德的途徑，用於自動化心理健康治療。我們利用經過培訓的臨床醫生進行的人類評估和基於心理學研究的自動質量護理指標，比較了點對點回應者提供的回應與最先進的 LLM 提供的回應。
  我們展示了 GPT-4 等 LLM 使用隱式和顯式線索來推斷患者人口統計資料，例如種族。然後我們展示了患者亞組之間存在統計上顯著的差異：對黑人海報的回應始終低於任何其他人口統計組（比對照組低 2%-13%）。可喜的是，我們確實發現回應的生成方式會顯著影響回應的品質。最後，我們提出 LLM 在心理健康應對中潛在部署的安全指南。

##### **Scrutinize What We Ignore: Reining Task Representation Shift In Context-Based Offline Meta Reinforcement Learning**
2405.12001v1 by Hai Zhang, Boyuan Zheng, Anqi Guo, Tianying Ji, Pheng-Ann Heng, Junqiao Zhao, Lanqing Li

Offline meta reinforcement learning (OMRL) has emerged as a promising
approach for interaction avoidance and strong generalization performance by
leveraging pre-collected data and meta-learning techniques. Previous
context-based approaches predominantly rely on the intuition that maximizing
the mutual information between the task and the task representation ($I(Z;M)$)
can lead to performance improvements. Despite achieving attractive results, the
theoretical justification of performance improvement for such intuition has
been lacking. Motivated by the return discrepancy scheme in the model-based RL
field, we find that maximizing $I(Z;M)$ can be interpreted as consistently
raising the lower bound of the expected return for a given policy conditioning
on the optimal task representation. However, this optimization process ignores
the task representation shift between two consecutive updates, which may lead
to performance improvement collapse. To address this problem, we turn to use
the framework of performance difference bound to consider the impacts of task
representation shift explicitly. We demonstrate that by reining the task
representation shift, it is possible to achieve monotonic performance
improvements, thereby showcasing the advantage against previous approaches. To
make it practical, we design an easy yet highly effective algorithm RETRO
(\underline{RE}ining \underline{T}ask \underline{R}epresentation shift in
context-based \underline{O}ffline meta reinforcement learning) with only adding
one line of code compared to the backbone. Empirical results validate its
state-of-the-art (SOTA) asymptotic performance, training stability and
training-time consumption on MuJoCo and MetaWorld benchmarks.

摘要：離線元增強學習 (OMRL) 已成為一種有前途的方法，它透過利用預先收集的資料和元學習技術，來避免互動並提升強大的泛化效能。先前的基於脈絡的方法主要依賴於一個直覺，即最大化任務與任務表示之間的互信息 ($I(Z;M)$) 可以提升效能。儘管獲得了令人滿意的結果，但對於這種直覺的效能提升，卻缺乏理論依據。在基於模型的 RL 領域的回報差異方案的啟發下，我們發現最大化 $I(Z;M)$ 可以解釋為一致地提高給定策略在最佳任務表示上的條件預期回報的下限。然而，這個最佳化程序忽略了兩個連續更新之間的任務表示轉移，這可能會導致效能提升崩潰。為了解決這個問題，我們轉而使用效能差異界限的架構，來明確考慮任務表示轉移的影響。我們證明，透過約束任務表示轉移，可以實現單調的效能提升，從而展示出相較於先前方法的優勢。為了使其更實用，我們設計了一個簡單但高效率的演算法 RETRO（在基於脈絡的離線元增強學習中約束任務表示轉移），它與主幹相比只增加了程式碼的一行。經驗結果驗證了其在 MuJoCo 和 MetaWorld 基準上的最先進 (SOTA) 的漸近效能、訓練穩定性和訓練時間消耗。

##### **A review on the use of large language models as virtual tutors**
2405.11983v1 by Silvia García-Méndez, Francisco de Arriba-Pérez, María del Carmen Somoza-López

Transformer architectures contribute to managing long-term dependencies for
Natural Language Processing, representing one of the most recent changes in the
field. These architectures are the basis of the innovative, cutting-edge Large
Language Models (LLMs) that have produced a huge buzz in several fields and
industrial sectors, among the ones education stands out. Accordingly, these
generative Artificial Intelligence-based solutions have directed the change in
techniques and the evolution in educational methods and contents, along with
network infrastructure, towards high-quality learning. Given the popularity of
LLMs, this review seeks to provide a comprehensive overview of those solutions
designed specifically to generate and evaluate educational materials and which
involve students and teachers in their design or experimental plan. To the best
of our knowledge, this is the first review of educational applications (e.g.,
student assessment) of LLMs. As expected, the most common role of these systems
is as virtual tutors for automatic question generation. Moreover, the most
popular models are GTP-3 and BERT. However, due to the continuous launch of new
generative models, new works are expected to be published shortly.

摘要：Transformer 架構有助於管理自然語言處理的長期依賴性，代表該領域最新變革之一。這些架構是創新、尖端的巨量語言模型 (LLM) 的基礎，這些模型在多個領域和產業部門引起極大迴響，其中教育領域尤為突出。因此，這些基於生成式人工智慧的解決方案引導了技術變革，以及教育方法和內容的演進，以及網路基礎設施，朝向高品質學習。鑑於 LLM 的普及性，本篇評論旨在提供對這些解決方案的全面概述，這些解決方案專門設計用於產生和評估教育材料，並讓學生和教師參與其設計或實驗計畫。據我們所知，這是第一篇 LLM 教育應用（例如學生評量）的評論。不出所料，這些系統最常見的角色是作為自動產生問題的虛擬導師。此外，最受歡迎的模型是 GTP-3 和 BERT。然而，由於持續推出新的生成式模型，預計不久後將會發表新的作品。

##### **Robust Deep Reinforcement Learning with Adaptive Adversarial Perturbations in Action Space**
2405.11982v1 by Qianmei Liu, Yufei Kuang, Jie Wang

Deep reinforcement learning (DRL) algorithms can suffer from modeling errors
between the simulation and the real world. Many studies use adversarial
learning to generate perturbation during training process to model the
discrepancy and improve the robustness of DRL. However, most of these
approaches use a fixed parameter to control the intensity of the adversarial
perturbation, which can lead to a trade-off between average performance and
robustness. In fact, finding the optimal parameter of the perturbation is
challenging, as excessive perturbations may destabilize training and compromise
agent performance, while insufficient perturbations may not impart enough
information to enhance robustness. To keep the training stable while improving
robustness, we propose a simple but effective method, namely, Adaptive
Adversarial Perturbation (A2P), which can dynamically select appropriate
adversarial perturbations for each sample. Specifically, we propose an adaptive
adversarial coefficient framework to adjust the effect of the adversarial
perturbation during training. By designing a metric for the current intensity
of the perturbation, our method can calculate the suitable perturbation levels
based on the current relative performance. The appealing feature of our method
is that it is simple to deploy in real-world applications and does not require
accessing the simulator in advance. The experiments in MuJoCo show that our
method can improve the training stability and learn a robust policy when
migrated to different test environments. The code is available at
https://github.com/Lqm00/A2P-SAC.

摘要：深度強化學習 (DRL) 演算法可能會受到模擬與真實世界之間的建模誤差影響。許多研究使用對抗學習在訓練過程中產生擾動，以模擬差異並改善 DRL 的穩健性。然而，這些方法大多使用固定參數來控制對抗擾動的強度，這可能導致平均效能和穩健性之間的取捨。事實上，找到擾動的最佳參數具有挑戰性，因為過度的擾動可能會破壞訓練並損害代理效能，而不足的擾動可能無法提供足夠的資訊來增強穩健性。為了在改善穩健性的同時保持訓練穩定，我們提出了一個簡單但有效的方法，即自適應對抗擾動 (A2P)，它可以動態地為每個樣本選擇適當的對抗擾動。具體來說，我們提出了一個自適應對抗係數框架，以調整訓練過程中對抗擾動的影響。透過設計一個用於測量擾動當前強度的指標，我們的模型可以根據當前的相對效能計算適當的擾動級別。我們的方法具有吸引力的特點是，它易於部署在實際應用中，並且不需要事先存取模擬器。MuJoCo 中的實驗表明，當我們的模型轉移到不同的測試環境時，它可以改善訓練穩定性並學習穩健的政策。程式碼可在 https://github.com/Lqm00/A2P-SAC 取得。

##### **SM-DTW: Stability Modulated Dynamic Time Warping for signature verification**
2405.11978v1 by Antonio Parziale, Moises Diaz, Miguel A. Ferrer, Angelo Marcelli

Building upon findings in computational model of handwriting learning and
execution, we introduce the concept of stability to explain the difference
between the actual movements performed during multiple execution of the
subject's signature, and conjecture that the most stable parts of the signature
should play a paramount role in evaluating the similarity between a questioned
signature and the reference ones during signature verification. We then
introduce the Stability Modulated Dynamic Time Warping algorithm for
incorporating the stability regions, i.e. the most similar parts between two
signatures, into the distance measure between a pair of signatures computed by
the Dynamic Time Warping for signature verification. Experiments were conducted
on two datasets largely adopted for performance evaluation. Experimental
results show that the proposed algorithm improves the performance of the
baseline system and compares favourably with other top performing signature
verification systems.

摘要：建立在手寫學習和執行運算模型的發現上，我們引入穩定性的概念來解釋在主體簽名多次執行期間實際執行的動作之間的差異，並推測簽名中最穩定的部分應在簽名驗證期間評估有疑問的簽名與參考簽名之間的相似性時發揮至關重要的作用。然後，我們引入穩定性調製動態時間規整演算法，以將穩定區域（即兩個簽名之間最相似的部分）納入由動態時間規整演算法計算出的簽名對之間的距離測量中，以進行簽名驗證。在兩個廣泛採用於效能評估的資料集上進行了實驗。實驗結果顯示，所提出的演算法改善了基準系統的效能，並且與其他頂尖的簽名驗證系統相比之下表現良好。

##### **Conditional Shift-Robust Conformal Prediction for Graph Neural Network**
2405.11968v1 by S. Akansha

Graph Neural Networks (GNNs) have emerged as potent tools for predicting
outcomes in graph-structured data. Despite their efficacy, a significant
drawback of GNNs lies in their limited ability to provide robust uncertainty
estimates, posing challenges to their reliability in contexts where errors
carry significant consequences. Moreover, GNNs typically excel in
in-distribution settings, assuming that training and test data follow identical
distributions: a condition often unmet in real-world graph data scenarios. In
this article, we leverage conformal prediction, a widely recognized statistical
technique for quantifying uncertainty by transforming predictive model outputs
into prediction sets, to address uncertainty quantification in GNN predictions
amidst conditional shift \footnote{Representing the change in conditional
probability distribution $P(label |input)$ from source domain to target
domain.} in graph-based semi-supervised learning (SSL). Additionally, we
propose a novel loss function aimed at refining model predictions by minimizing
conditional shift in latent stages. Termed Conditional Shift Robust (CondSR)
conformal prediction for GNNs, our approach CondSR is model-agnostic and
adaptable to various classification models. We validate the effectiveness of
our method on standard graph benchmark datasets, integrating it with
state-of-the-art GNNs in node classification tasks. The code implementation is
publicly available for further exploration and experimentation.

摘要：圖形神經網路 (GNN) 已成為預測圖形結構資料中結果的強大工具。儘管其有效，但 GNN 的一個重大缺點在於其提供穩健不確定性估計的能力有限，這對其在錯誤會造成重大後果的環境中的可靠性構成挑戰。此外，GNN 通常在同分佈設定中表現出色，假設訓練和測試資料遵循相同的分配：這是一個在現實世界圖形資料場景中經常無法滿足的條件。在本文中，我們利用共形預測，這是一種廣泛認可的統計技術，透過將預測模型輸出轉換為預測集合來量化不確定性，以解決在圖形半監督學習 (SSL) 中條件轉移下 GNN 預測中的不確定性量化問題\footnote{表示條件機率分佈 $P(label |input)$ 從來源網域到目標網域的變化。}。此外，我們提出了一種新的損失函數，旨在透過最小化潛在階段中的條件轉移來改善模型預測。我們的 CondSR 方法稱為條件轉移穩健 (CondSR) 共形預測，適用於 GNN，它與模型無關，且適用於各種分類模型。我們在標準圖形基準資料集上驗證了我們方法的有效性，並將其與節點分類任務中的最先進 GNN 整合。程式碼實作已公開，可供進一步探索和實驗。

##### **Recommender Algorithm for Supporting Self-Management of CVD Risk Factors in an Adult Population at Home**
2405.11967v1 by Tatiana V. Afanasieva, Pavel V. Platov, Anastasia I. Medvedeva

One of the new trends in the development of recommendation algorithms is the
dissemination of their capabilities to support the population in managing their
health. This article focuses on the problem of improving the effectiveness of
cardiovascular diseases (CVD) prevention, since CVD is the leading cause of
death worldwide. To address this issue, a knowledge-based recommendation
algorithm was proposed to support self-management of CVD risk factors in adults
at home. The proposed algorithm is based on the original multidimensional
recommendation model and on a new user profile model, which includes predictive
assessments of CVD health in addition to its current ones as outlined in
official guidelines. The main feature of the proposed algorithm is the
combination of rule-based logic with the capabilities of a large language model
in generating human-like text for explanatory component of multidimensional
recommendation. The verification and evaluation of the proposed algorithm
showed the usefulness of the proposed recommendation algorithm for supporting
adults in self-management of their CVD risk factors at home. As follows from
the comparison with similar knowledge-based recommendation algorithms, the
proposed algorithm evaluates a larger number of CVD risk factors and has a
greater information and semantic capacity of the generated recommendations.

摘要：推薦演算法發展的新趨勢之一是傳播其能力，以協助民眾管理自身健康。本文重點探討改善心血管疾病（CVD）預防的有效性，因為 CVD 是全球主要的死亡原因。為了解決這個問題，提出了一種基於知識的推薦演算法，以在家中支援成人自我管理 CVD 風險因子。所提出的演算法基於原始的多維度推薦模型和新的使用者輪廓模型，其中除了官方指南中概述的現有評估外，還包括 CVD 健康的預測評估。所提出的演算法主要特色是將基於規則的邏輯與大型語言模型的能力相結合，以產生類人文字，作為多維度推薦的說明性組成部分。所提出的演算法的驗證和評估顯示，所提出的推薦演算法在協助成人在家中自我管理其 CVD 風險因子方面很有用。從與類似的基於知識的推薦演算法的比較中得知，所提出的演算法評估了更多 CVD 風險因子，並且產生的建議具有更大的資訊和語義容量。

