{"2412.17316": {"publish_time": "2024-12-23", "title": "Fast Gradient Computation for RoPE Attention in Almost Linear Time", "paper_summary": "The Rotary Position Embedding (RoPE) mechanism has become a powerful\nenhancement to the Transformer architecture, which enables models to capture\ntoken relationships when encoding positional information. However, the RoPE\nmechanisms make the computations of attention mechanisms more complicated,\nwhich makes efficient algorithms challenging. Earlier research introduced\nalmost linear time, i.e., $n^{1+o(1)}$ where $n$ is the number of input tokens,\nalgorithms for the forward computation under specific parameter settings.\nHowever, achieving a subquadratic time algorithm for other parameter regimes\nremains impossible unless the widely accepted Strong Exponential Time\nHypothesis (SETH) is disproven. In this work, we develop the first almost\nlinear time algorithm for backward computations in the RoPE-based attention\nunder bounded entries. Our approach builds on recent advancements in fast RoPE\nattention computations, utilizing a novel combination of the polynomial method\nand the Fast Fourier Transform. Furthermore, we show that with lower bounds\nderived from the SETH, the bounded entry condition is necessary for\nsubquadratic performance.", "paper_summary_zh": "\u65cb\u8f49\u4f4d\u7f6e\u5d4c\u5165 (RoPE) \u6a5f\u5236\u5df2\u6210\u70ba Transformer \u67b6\u69cb\u7684\u4e00\u9805\u5f37\u5927\u5f37\u5316\u529f\u80fd\uff0c\u5b83\u80fd\u8b93\u6a21\u578b\u5728\u7de8\u78bc\u4f4d\u7f6e\u8cc7\u8a0a\u6642\u64f7\u53d6\u6a19\u8a18\u95dc\u806f\u3002\u7136\u800c\uff0cRoPE \u6a5f\u5236\u8b93\u6ce8\u610f\u529b\u6a5f\u5236\u7684\u904b\u7b97\u66f4\u70ba\u8907\u96dc\uff0c\u9019\u4f7f\u5f97\u9ad8\u6548\u6f14\u7b97\u6cd5\u5145\u6eff\u6311\u6230\u3002\u7a0d\u65e9\u7684\u7814\u7a76\u5f15\u5165\u4e86\u8fd1\u4f3c\u7dda\u6027\u6642\u9593\uff0c\u5373 $n^{1+o(1)}$\uff0c\u5176\u4e2d $n$ \u662f\u8f38\u5165\u6a19\u8a18\u7684\u6578\u91cf\uff0c\u6f14\u7b97\u6cd5\u7528\u65bc\u5728\u7279\u5b9a\u53c3\u6578\u8a2d\u5b9a\u4e0b\u7684\u524d\u5411\u904b\u7b97\u3002\u7136\u800c\uff0c\u9664\u975e\u5ee3\u6cdb\u63a5\u53d7\u7684\u5f37\u6307\u6578\u6642\u9593\u5047\u8a2d (SETH) \u88ab\u8b49\u507d\uff0c\u5426\u5247\u7121\u6cd5\u70ba\u5176\u4ed6\u53c3\u6578\u7bc4\u570d\u9054\u6210\u6b21\u5e73\u65b9\u6642\u9593\u6f14\u7b97\u6cd5\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u958b\u767c\u51fa\u7b2c\u4e00\u500b\u8fd1\u4f3c\u7dda\u6027\u6642\u9593\u6f14\u7b97\u6cd5\uff0c\u7528\u65bc\u5728\u6709\u754c\u8f38\u5165\u4e0b\u7684 RoPE \u57fa\u790e\u6ce8\u610f\u529b\u4e2d\u9032\u884c\u5f8c\u5411\u904b\u7b97\u3002\u6211\u5011\u7684\u505a\u6cd5\u5efa\u7acb\u5728\u5feb\u901f RoPE \u6ce8\u610f\u529b\u904b\u7b97\u7684\u6700\u65b0\u9032\u5c55\u4e0a\uff0c\u5229\u7528\u591a\u9805\u5f0f\u65b9\u6cd5\u548c\u5feb\u901f\u5085\u7acb\u8449\u8f49\u63db\u7684\u65b0\u7a4e\u7d44\u5408\u3002\u6b64\u5916\uff0c\u6211\u5011\u8b49\u660e\uff0c\u6839\u64da SETH \u63a8\u5c0e\u51fa\u7684\u4e0b\u754c\uff0c\u6709\u754c\u8f38\u5165\u689d\u4ef6\u5c0d\u65bc\u6b21\u5e73\u65b9\u6548\u80fd\u800c\u8a00\u662f\u5fc5\u8981\u7684\u3002", "author": "Yifang Chen et.al.", "authors": "Yifang Chen, Jiayan Huo, Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song", "id": "2412.17316v1", "paper_url": "http://arxiv.org/abs/2412.17316v1", "repo": "null"}}