{"2412.18125": {"publish_time": "2024-12-24", "title": "Exact Acceleration of Subgraph Graph Neural Networks by Eliminating Computation Redundancy", "paper_summary": "Graph neural networks (GNNs) have become a prevalent framework for graph\ntasks. Many recent studies have proposed the use of graph convolution methods\nover the numerous subgraphs of each graph, a concept known as subgraph graph\nneural networks (subgraph GNNs), to enhance GNNs' ability to distinguish\nnon-isomorphic graphs. To maximize the expressiveness, subgraph GNNs often\nrequire each subgraph to have equal size to the original graph. Despite their\nimpressive performance, subgraph GNNs face challenges due to the vast number\nand large size of subgraphs which lead to a surge in training data, resulting\nin both storage and computational inefficiencies. In response to this problem,\nthis paper introduces Ego-Nets-Fit-All (ENFA), a model that uniformly takes the\nsmaller ego nets as subgraphs, thereby providing greater storage and\ncomputational efficiency, while at the same time guarantees identical outputs\nto the original subgraph GNNs even taking the whole graph as subgraphs. The key\nis to identify and eliminate the redundant computation among subgraphs. For\nexample, a node $v_i$ may appear in multiple subgraphs but is far away from all\nof their centers (the unsymmetric part between subgraphs). Therefore, its first\nfew rounds of message passing within each subgraph can be computed once in the\noriginal graph instead of being computed multiple times within each subgraph.\nSuch strategy enables our ENFA to accelerate subgraph GNNs in an exact way,\nunlike previous sampling approaches that often lose the performance. Extensive\nexperiments across various datasets reveal that compared with the conventional\nsubgraph GNNs, ENFA can reduce storage space by 29.0% to 84.5% and improve\ntraining efficiency by up to 1.66x.", "paper_summary_zh": "\u5716\u5f62\u795e\u7d93\u7db2\u7d61 (GNN) \u5df2\u6210\u70ba\u5716\u5f62\u4efb\u52d9\u7684\u6d41\u884c\u6846\u67b6\u3002\u8a31\u591a\u8fd1\u671f\u7814\u7a76\u5efa\u8b70\u5728\u6bcf\u500b\u5716\u5f62\u7684\u773e\u591a\u5b50\u5716\u4e0a\u4f7f\u7528\u5716\u5f62\u5377\u7a4d\u65b9\u6cd5\uff0c\u9019\u662f\u4e00\u500b\u7a31\u70ba\u5b50\u5716\u5716\u5f62\u795e\u7d93\u7db2\u7d61 (subgraph GNN) \u7684\u6982\u5ff5\uff0c\u7528\u4ee5\u63d0\u5347 GNN \u5340\u5206\u975e\u540c\u69cb\u5716\u5f62\u7684\u80fd\u529b\u3002\u70ba\u4e86\u6700\u5927\u5316\u8868\u9054\u529b\uff0c\u5b50\u5716 GNN \u901a\u5e38\u8981\u6c42\u6bcf\u500b\u5b50\u5716\u7684\u5927\u5c0f\u8207\u539f\u59cb\u5716\u5f62\u76f8\u540c\u3002\u5118\u7ba1\u6548\u80fd\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\uff0c\u4f46\u7531\u65bc\u5b50\u5716\u6578\u91cf\u9f90\u5927\u4e14\u5927\u5c0f\u4e0d\u4e00\uff0c\u5c0e\u81f4\u8a13\u7df4\u8cc7\u6599\u6fc0\u589e\uff0c\u9020\u6210\u5132\u5b58\u548c\u904b\u7b97\u6548\u7387\u4e0d\u5f70\uff0c\u56e0\u6b64\u5b50\u5716 GNN \u9762\u81e8\u6311\u6230\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u500b\u554f\u984c\uff0c\u672c\u6587\u4ecb\u7d39\u4e86 Ego-Nets-Fit-All (ENFA)\uff0c\u9019\u662f\u4e00\u500b\u6a21\u578b\uff0c\u5b83\u5c07\u8f03\u5c0f\u7684\u81ea\u6211\u7db2\u8def\u8996\u70ba\u5b50\u5716\uff0c\u5f9e\u800c\u63d0\u4f9b\u66f4\u5927\u7684\u5132\u5b58\u548c\u904b\u7b97\u6548\u7387\uff0c\u540c\u6642\u4fdd\u8b49\u8207\u539f\u59cb\u5b50\u5716 GNN \u76f8\u540c\u7684\u8f38\u51fa\uff0c\u5373\u4f7f\u5c07\u6574\u500b\u5716\u5f62\u8996\u70ba\u5b50\u5716\u3002\u95dc\u9375\u5728\u65bc\u8b58\u5225\u548c\u6d88\u9664\u5b50\u5716\u4e4b\u9593\u7684\u91cd\u8907\u904b\u7b97\u3002\u4f8b\u5982\uff0c\u7bc0\u9ede $v_i$ \u53ef\u80fd\u51fa\u73fe\u5728\u591a\u500b\u5b50\u5716\u4e2d\uff0c\u4f46\u8ddd\u96e2\u6240\u6709\u5b50\u5716\u4e2d\u5fc3\u90fd\u5f88\u9060\uff08\u5b50\u5716\u4e4b\u9593\u7684\u4e0d\u5c0d\u7a31\u90e8\u5206\uff09\u3002\u56e0\u6b64\uff0c\u5b83\u5728\u6bcf\u500b\u5b50\u5716\u4e2d\u7684\u524d\u5e7e\u8f2a\u8a0a\u606f\u50b3\u905e\u53ef\u4ee5\u5728\u539f\u59cb\u5716\u5f62\u4e2d\u8a08\u7b97\u4e00\u6b21\uff0c\u800c\u4e0d\u662f\u5728\u6bcf\u500b\u5b50\u5716\u4e2d\u8a08\u7b97\u591a\u6b21\u3002\u9019\u7a2e\u7b56\u7565\u4f7f\u6211\u5011\u7684 ENFA \u80fd\u5920\u4ee5\u7cbe\u78ba\u7684\u65b9\u5f0f\u52a0\u901f\u5b50\u5716 GNN\uff0c\u9019\u8207\u901a\u5e38\u6703\u964d\u4f4e\u6548\u80fd\u7684\u5148\u524d\u62bd\u6a23\u65b9\u6cd5\u4e0d\u540c\u3002\u5728\u5404\u7a2e\u8cc7\u6599\u96c6\u4e0a\u7684\u5ee3\u6cdb\u5be6\u9a57\u986f\u793a\uff0c\u8207\u50b3\u7d71\u7684\u5b50\u5716 GNN \u76f8\u6bd4\uff0cENFA \u53ef\u5c07\u5132\u5b58\u7a7a\u9593\u6e1b\u5c11 29.0% \u81f3 84.5%\uff0c\u4e26\u5c07\u8a13\u7df4\u6548\u7387\u63d0\u5347\u591a\u9054 1.66 \u500d\u3002", "author": "Qian Tao et.al.", "authors": "Qian Tao, Xiyuan Wang, Muhan Zhang, Shuxian Hu, Wenyuan Yu, Jingren Zhou", "id": "2412.18125v1", "paper_url": "http://arxiv.org/abs/2412.18125v1", "repo": "null"}}