{"2412.09025": {"publish_time": "2024-12-12", "title": "Shiksha: A Technical Domain focused Translation Dataset and Model for Indian Languages", "paper_summary": "Neural Machine Translation (NMT) models are typically trained on datasets\nwith limited exposure to Scientific, Technical and Educational domains.\nTranslation models thus, in general, struggle with tasks that involve\nscientific understanding or technical jargon. Their performance is found to be\neven worse for low-resource Indian languages. Finding a translation dataset\nthat tends to these domains in particular, poses a difficult challenge. In this\npaper, we address this by creating a multilingual parallel corpus containing\nmore than 2.8 million rows of English-to-Indic and Indic-to-Indic high-quality\ntranslation pairs across 8 Indian languages. We achieve this by bitext mining\nhuman-translated transcriptions of NPTEL video lectures. We also finetune and\nevaluate NMT models using this corpus and surpass all other publicly available\nmodels at in-domain tasks. We also demonstrate the potential for generalizing\nto out-of-domain translation tasks by improving the baseline by over 2 BLEU on\naverage for these Indian languages on the Flores+ benchmark. We are pleased to\nrelease our model and dataset via this link: https://huggingface.co/SPRINGLab.", "paper_summary_zh": "\u795e\u7d93\u6a5f\u5668\u7ffb\u8b6f (NMT) \u6a21\u578b\u901a\u5e38\u5728\u5c0d\u79d1\u5b78\u3001\u6280\u8853\u548c\u6559\u80b2\u9818\u57df\u63a5\u89f8\u6709\u9650\u7684\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u8a13\u7df4\u3002\u56e0\u6b64\uff0c\u7ffb\u8b6f\u6a21\u578b\u901a\u5e38\u96e3\u4ee5\u61c9\u4ed8\u6d89\u53ca\u79d1\u5b78\u7406\u89e3\u6216\u6280\u8853\u8853\u8a9e\u7684\u4efb\u52d9\u3002\u5c0d\u65bc\u8cc7\u6e90\u8f03\u5c11\u7684\u5370\u5ea6\u8a9e\u8a00\uff0c\u5176\u8868\u73fe\u66f4\u70ba\u7cdf\u7cd5\u3002\u627e\u5230\u7279\u5225\u91dd\u5c0d\u9019\u4e9b\u9818\u57df\u7684\u7ffb\u8b6f\u8cc7\u6599\u96c6\u662f\u4e00\u500b\u8271\u96e3\u7684\u6311\u6230\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u901a\u904e\u5efa\u7acb\u4e00\u500b\u591a\u8a9e\u8a00\u5e73\u884c\u8a9e\u6599\u5eab\u4f86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u5176\u4e2d\u5305\u542b\u8d85\u904e 280 \u842c\u5217\u9ad8\u54c1\u8cea\u7684\u82f1\u5370\u548c\u5370\u5370\u7ffb\u8b6f\u5c0d\uff0c\u6db5\u84cb 8 \u7a2e\u5370\u5ea6\u8a9e\u8a00\u3002\u6211\u5011\u901a\u904e\u5c0d NPTEL \u8996\u983b\u8ab2\u7a0b\u7684\u4eba\u5de5\u7ffb\u8b6f\u8f49\u9304\u9032\u884c\u96d9\u8a9e\u6587\u672c\u6316\u6398\u4f86\u5be6\u73fe\u9019\u4e00\u9ede\u3002\u6211\u5011\u9084\u4f7f\u7528\u9019\u500b\u8a9e\u6599\u5eab\u5c0d NMT \u6a21\u578b\u9032\u884c\u5fae\u8abf\u548c\u8a55\u4f30\uff0c\u4e26\u5728\u9818\u57df\u5167\u4efb\u52d9\u4e2d\u8d85\u8d8a\u6240\u6709\u5176\u4ed6\u516c\u958b\u53ef\u7528\u7684\u6a21\u578b\u3002\u6211\u5011\u9084\u5c55\u793a\u4e86\u901a\u904e\u5728 Flores+ \u57fa\u6e96\u4e0a\u5e73\u5747\u63d0\u9ad8\u9019\u4e9b\u5370\u5ea6\u8a9e\u8a00\u7684 BLEU \u8d85\u904e 2 \u500b\u9ede\u4f86\u6982\u62ec\u5230\u9818\u57df\u5916\u7ffb\u8b6f\u4efb\u52d9\u7684\u6f5b\u529b\u3002\u6211\u5011\u5f88\u69ae\u5e78\u901a\u904e\u4ee5\u4e0b\u9023\u7d50\u767c\u5e03\u6211\u5011\u7684\u6a21\u578b\u548c\u8cc7\u6599\u96c6\uff1ahttps://huggingface.co/SPRINGLab\u3002", "author": "Advait Joglekar et.al.", "authors": "Advait Joglekar, Srinivasan Umesh", "id": "2412.09025v1", "paper_url": "http://arxiv.org/abs/2412.09025v1", "repo": "null"}}