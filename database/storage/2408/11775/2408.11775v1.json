{"2408.11775": {"publish_time": "2024-08-21", "title": "Leveraging Fine-Tuned Retrieval-Augmented Generation with Long-Context Support: For 3GPP Standards", "paper_summary": "Recent studies show that large language models (LLMs) struggle with technical\nstandards in telecommunications. We propose a fine-tuned retrieval-augmented\ngeneration (RAG) system based on the Phi-2 small language model (SLM) to serve\nas an oracle for communication networks. Our developed system leverages\nforward-looking semantic chunking to adaptively determine parsing breakpoints\nbased on embedding similarity, enabling effective processing of diverse\ndocument formats. To handle the challenge of multiple similar contexts in\ntechnical standards, we employ a re-ranking algorithm to prioritize the most\nrelevant retrieved chunks. Recognizing the limitations of Phi-2's small context\nwindow, we implement a recent technique, namely SelfExtend, to expand the\ncontext window during inference, which not only boosts the performance but also\ncan accommodate a wider range of user queries and design requirements from\ncustomers to specialized technicians. For fine-tuning, we utilize the low-rank\nadaptation (LoRA) technique to enhance computational efficiency during training\nand enable effective fine-tuning on small datasets. Our comprehensive\nexperiments demonstrate substantial improvements over existing\nquestion-answering approaches in the telecom domain, achieving performance that\nexceeds larger language models such as GPT-4 (which is about 880 times larger\nin size). This work presents a novel approach to leveraging SLMs for\ncommunication networks, offering a balance of efficiency and performance. This\nwork can serve as a foundation towards agentic language models for networks.", "paper_summary_zh": "<paragraph>\u6700\u8fd1\u7684\u7814\u7a76\u8868\u660e\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u96fb\u4fe1\u6280\u8853\u6a19\u6e96\u65b9\u9762\u5b58\u5728\u56f0\u96e3\u3002\u6211\u5011\u63d0\u51fa\u4e00\u500b\u57fa\u65bc Phi-2 \u5c0f\u578b\u8a9e\u8a00\u6a21\u578b (SLM) \u7684\u5fae\u8abf\u6aa2\u7d22\u589e\u5f37\u751f\u6210 (RAG) \u7cfb\u7d71\uff0c\u4f5c\u70ba\u901a\u4fe1\u7db2\u8def\u7684\u9810\u8a00\u6a5f\u3002\u6211\u5011\u958b\u767c\u7684\u7cfb\u7d71\u5229\u7528\u524d\u77bb\u8a9e\u7fa9\u5207\u584a\uff0c\u6839\u64da\u5d4c\u5165\u76f8\u4f3c\u6027\u81ea\u9069\u61c9\u5730\u78ba\u5b9a\u89e3\u6790\u65b7\u9ede\uff0c\u5f9e\u800c\u6709\u6548\u8655\u7406\u591a\u6a23\u5316\u7684\u6587\u4ef6\u683c\u5f0f\u3002\u70ba\u4e86\u61c9\u5c0d\u6280\u8853\u6a19\u6e96\u4e2d\u591a\u500b\u76f8\u4f3c\u8a9e\u5883\u7684\u6311\u6230\uff0c\u6211\u5011\u63a1\u7528\u91cd\u65b0\u6392\u5e8f\u6f14\u7b97\u6cd5\uff0c\u4ee5\u512a\u5148\u8003\u616e\u6700\u76f8\u95dc\u7684\u6aa2\u7d22\u5340\u584a\u3002\u8a8d\u8b58\u5230 Phi-2 \u7684\u5c0f\u8a9e\u5883\u8996\u7a97\u7684\u9650\u5236\uff0c\u6211\u5011\u5be6\u4f5c\u4e86\u4e00\u7a2e\u65b0\u7684\u6280\u8853\uff0c\u5373 SelfExtend\uff0c\u4ee5\u5728\u63a8\u7406\u671f\u9593\u64f4\u5c55\u8a9e\u5883\u8996\u7a97\uff0c\u9019\u4e0d\u50c5\u63d0\u5347\u4e86\u6548\u80fd\uff0c\u9084\u80fd\u5bb9\u7d0d\u66f4\u5ee3\u6cdb\u7684\u4f7f\u7528\u8005\u67e5\u8a62\u548c\u4f86\u81ea\u5ba2\u6236\u5230\u5c08\u696d\u6280\u8853\u4eba\u54e1\u7684\u8a2d\u8a08\u9700\u6c42\u3002\u5c0d\u65bc\u5fae\u8abf\uff0c\u6211\u5011\u5229\u7528\u4f4e\u79e9\u9069\u61c9 (LoRA) \u6280\u8853\u4f86\u63d0\u5347\u8a13\u7df4\u671f\u9593\u7684\u904b\u7b97\u6548\u7387\uff0c\u4e26\u5728\u5c0f\u578b\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u6709\u6548\u7684\u5fae\u8abf\u3002\u6211\u5011\u5168\u9762\u7684\u5be6\u9a57\u8b49\u660e\u4e86\u96fb\u4fe1\u9818\u57df\u73fe\u6709\u554f\u7b54\u65b9\u6cd5\u7684\u986f\u8457\u6539\u9032\uff0c\u9054\u5230\u4e86\u8d85\u8d8a\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08\u4f8b\u5982 GPT-4\uff0c\u5176\u5927\u5c0f\u7d04\u70ba\u5176 880 \u500d\uff09\u7684\u6548\u80fd\u3002\u9019\u9805\u5de5\u4f5c\u63d0\u51fa\u4e86\u4e00\u7a2e\u5229\u7528 SLM \u4f86\u9032\u884c\u901a\u4fe1\u7db2\u8def\u7684\u65b0\u65b9\u6cd5\uff0c\u5728\u6548\u7387\u548c\u6548\u80fd\u4e4b\u9593\u53d6\u5f97\u5e73\u8861\u3002\u9019\u9805\u5de5\u4f5c\u53ef\u4ee5\u4f5c\u70ba\u7db2\u8def\u4ee3\u7406\u8a9e\u8a00\u6a21\u578b\u7684\u57fa\u790e\u3002</paragraph>", "author": "Omar Erak et.al.", "authors": "Omar Erak, Nouf Alabbasi, Omar Alhussein, Ismail Lotfi, Amr Hussein, Sami Muhaidat, Merouane Debbah", "id": "2408.11775v1", "paper_url": "http://arxiv.org/abs/2408.11775v1", "repo": "https://github.com/Nouf-Alabbasi/oKUmura_AI_Telecom_challenge"}}