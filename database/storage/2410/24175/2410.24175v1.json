{"2410.24175": {"publish_time": "2024-10-31", "title": "Constraint Back-translation Improves Complex Instruction Following of Large Language Models", "paper_summary": "Large language models (LLMs) struggle to follow instructions with complex\nconstraints in format, length, etc. Following the conventional\ninstruction-tuning practice, previous works conduct post-training on complex\ninstruction-response pairs generated by feeding complex instructions to\nadvanced LLMs. However, even advanced LLMs cannot follow complex instructions\nwell, thus limiting the quality of generated data. In this work, we find that\nexisting datasets inherently contain implicit complex constraints and propose a\nnovel data generation technique, constraint back-translation. Specifically, we\ntake the high-quality instruction-response pairs in existing datasets and only\nadopt advanced LLMs to add complex constraints already met by the responses to\nthe instructions, which naturally reduces costs and data noise. In the\nexperiments, we adopt Llama3-70B-Instruct to back-translate constraints and\ncreate a high-quality complex instruction-response dataset, named CRAB. We\npresent that post-training on CRAB improves multiple backbone LLMs' complex\ninstruction-following ability, evaluated on extensive instruction-following\nbenchmarks. We further find that constraint back-translation also serves as a\nuseful auxiliary training objective in post-training. Our code, data, and\nmodels will be released to facilitate future research.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u96e3\u4ee5\u9075\u5faa\u683c\u5f0f\u3001\u9577\u5ea6\u7b49\u65b9\u9762\u7684\u8907\u96dc\u7d04\u675f\u8aaa\u660e\u3002\u9075\u5faa\u6163\u4f8b\u7684\u8aaa\u660e\u8abf\u6574\u5be6\u52d9\uff0c\u5148\u524d\u7684\u7814\u7a76\u5728\u9032\u968e LLM \u4e2d\u8f38\u5165\u8907\u96dc\u7684\u8aaa\u660e\u4f86\u7522\u751f\u8907\u96dc\u7684\u8aaa\u660e\u56de\u61c9\u914d\u5c0d\uff0c\u4e26\u5728\u8a13\u7df4\u5f8c\u9032\u884c\u8655\u7406\u3002\u7136\u800c\uff0c\u5373\u4f7f\u662f\u9032\u968e LLM \u4e5f\u7121\u6cd5\u9075\u5faa\u8907\u96dc\u7684\u8aaa\u660e\uff0c\u56e0\u6b64\u9650\u5236\u4e86\u7522\u751f\u8cc7\u6599\u7684\u54c1\u8cea\u3002\u5728\u9019\u9805\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u767c\u73fe\u73fe\u6709\u7684\u8cc7\u6599\u96c6\u672c\u8eab\u5c31\u5305\u542b\u4e86\u96b1\u542b\u7684\u8907\u96dc\u7d04\u675f\uff0c\u4e26\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7684\u8cc7\u6599\u7522\u751f\u6280\u8853\uff0c\u7d04\u675f\u53cd\u5411\u7ffb\u8b6f\u3002\u5177\u9ad4\u800c\u8a00\uff0c\u6211\u5011\u63a1\u7528\u73fe\u6709\u8cc7\u6599\u96c6\u4e2d\u9ad8\u54c1\u8cea\u7684\u8aaa\u660e\u56de\u61c9\u914d\u5c0d\uff0c\u4e26\u50c5\u63a1\u7528\u9032\u968e LLM \u4f86\u589e\u52a0\u56de\u61c9\u5df2\u6eff\u8db3\u7684\u8907\u96dc\u7d04\u675f\uff0c\u9019\u81ea\u7136\u6703\u964d\u4f4e\u6210\u672c\u548c\u8cc7\u6599\u96dc\u8a0a\u3002\u5728\u5be6\u9a57\u4e2d\uff0c\u6211\u5011\u63a1\u7528 Llama3-70B-Instruct \u4f86\u53cd\u5411\u7ffb\u8b6f\u7d04\u675f\uff0c\u4e26\u5efa\u7acb\u4e00\u500b\u9ad8\u54c1\u8cea\u7684\u8907\u96dc\u8aaa\u660e\u56de\u61c9\u8cc7\u6599\u96c6\uff0c\u7a31\u70ba CRAB\u3002\u6211\u5011\u63d0\u51fa\u5728 CRAB \u4e0a\u9032\u884c\u8a13\u7df4\u5f8c\uff0c\u53ef\u4ee5\u6539\u5584\u591a\u500b\u4e3b\u5e79 LLM \u7684\u8907\u96dc\u8aaa\u660e\u9075\u5faa\u80fd\u529b\uff0c\u4e26\u5728\u5ee3\u6cdb\u7684\u8aaa\u660e\u9075\u5faa\u57fa\u6e96\u4e0a\u9032\u884c\u8a55\u4f30\u3002\u6211\u5011\u9032\u4e00\u6b65\u767c\u73fe\uff0c\u7d04\u675f\u53cd\u5411\u7ffb\u8b6f\u5728\u8a13\u7df4\u5f8c\u4e5f\u53ef\u7528\u4f5c\u6709\u7528\u7684\u8f14\u52a9\u8a13\u7df4\u76ee\u6a19\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u3001\u8cc7\u6599\u548c\u6a21\u578b\u5c07\u6703\u767c\u5e03\uff0c\u4ee5\u5229\u672a\u4f86\u7684\u7814\u7a76\u3002", "author": "Yunjia Qi et.al.", "authors": "Yunjia Qi, Hao Peng, Xiaozhi Wang, Bin Xu, Lei Hou, Juanzi Li", "id": "2410.24175v1", "paper_url": "http://arxiv.org/abs/2410.24175v1", "repo": "null"}}