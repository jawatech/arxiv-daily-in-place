{"2405.20978": {"publish_time": "2024-05-31", "title": "Enhancing Noise Robustness of Retrieval-Augmented Language Models with Adaptive Adversarial Training", "paper_summary": "Large Language Models (LLMs) exhibit substantial capabilities yet encounter\nchallenges, including hallucination, outdated knowledge, and untraceable\nreasoning processes. Retrieval-augmented generation (RAG) has emerged as a\npromising solution, integrating knowledge from external databases to mitigate\nthese challenges. However, inappropriate retrieved passages can potentially\nhinder the LLMs' capacity to generate comprehensive and high-quality responses.\nPrior RAG studies on the robustness of retrieval noises often confine\nthemselves to a limited set of noise types, deviating from real-world retrieval\nenvironments and limiting practical applicability. In this study, we initially\ninvestigate retrieval noises and categorize them into three distinct types,\nreflecting real-world environments. We analyze the impact of these various\nretrieval noises on the robustness of LLMs. Subsequently, we propose a novel\nRAG approach known as Retrieval-augmented Adaptive Adversarial Training (RAAT).\nRAAT leverages adaptive adversarial training to dynamically adjust the model's\ntraining process in response to retrieval noises. Concurrently, it employs\nmulti-task learning to ensure the model's capacity to internally recognize\nnoisy contexts. Extensive experiments demonstrate that the LLaMA-2 7B model\ntrained using RAAT exhibits significant improvements in F1 and EM scores under\ndiverse noise conditions. For reproducibility, we release our code and data at:\nhttps://github.com/calubkk/RAAT.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5177\u5099\u5f37\u5927\u7684\u529f\u80fd\uff0c\u537b\u4e5f\u9762\u81e8\u6311\u6230\uff0c\u5305\u62ec\u5e7b\u89ba\u3001\u77e5\u8b58\u904e\u6642\uff0c\u4ee5\u53ca\u96e3\u4ee5\u8ffd\u8e64\u7684\u63a8\u7406\u904e\u7a0b\u3002\u6aa2\u7d22\u589e\u5f37\u751f\u6210 (RAG) \u5df2\u6210\u70ba\u4e00\u7a2e\u6709\u524d\u666f\u7684\u89e3\u6c7a\u65b9\u6848\uff0c\u5b83\u6574\u5408\u4f86\u81ea\u5916\u90e8\u8cc7\u6599\u5eab\u7684\u77e5\u8b58\u4ee5\u6e1b\u8f15\u9019\u4e9b\u6311\u6230\u3002\u7136\u800c\uff0c\u4e0d\u9069\u7576\u7684\u6aa2\u7d22\u6bb5\u843d\u53ef\u80fd\u6703\u963b\u7919 LLM \u751f\u6210\u5168\u9762\u4e14\u9ad8\u54c1\u8cea\u56de\u61c9\u7684\u80fd\u529b\u3002\u5148\u524d\u91dd\u5c0d\u6aa2\u7d22\u96dc\u8a0a\u7a69\u5065\u6027\u7684 RAG \u7814\u7a76\u901a\u5e38\u4fb7\u9650\u65bc\u6709\u9650\u7684\u96dc\u8a0a\u985e\u578b\uff0c\u504f\u96e2\u771f\u5be6\u4e16\u754c\u7684\u6aa2\u7d22\u74b0\u5883\uff0c\u4e26\u9650\u5236\u4e86\u5be6\u969b\u61c9\u7528\u6027\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u6700\u521d\u63a2\u8a0e\u6aa2\u7d22\u96dc\u8a0a\uff0c\u4e26\u5c07\u5176\u5206\u985e\u70ba\u4e09\u7a2e\u985e\u578b\uff0c\u53cd\u6620\u771f\u5be6\u4e16\u754c\u7684\u74b0\u5883\u3002\u6211\u5011\u5206\u6790\u4e86\u9019\u4e9b\u4e0d\u540c\u6aa2\u7d22\u96dc\u8a0a\u5c0d LLM \u7a69\u5065\u6027\u7684\u5f71\u97ff\u3002\u96a8\u5f8c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u7a31\u70ba\u6aa2\u7d22\u589e\u5f37\u9069\u61c9\u5c0d\u6297\u8a13\u7df4 (RAAT) \u7684\u65b0 RAG \u65b9\u6cd5\u3002RAAT \u5229\u7528\u9069\u61c9\u5c0d\u6297\u8a13\u7df4\u52d5\u614b\u8abf\u6574\u6a21\u578b\u7684\u8a13\u7df4\u904e\u7a0b\uff0c\u4ee5\u61c9\u5c0d\u6aa2\u7d22\u96dc\u8a0a\u3002\u540c\u6642\uff0c\u5b83\u63a1\u7528\u591a\u4efb\u52d9\u5b78\u7fd2\uff0c\u4ee5\u78ba\u4fdd\u6a21\u578b\u80fd\u5920\u5167\u90e8\u8fa8\u8b58\u96dc\u8a0a\u74b0\u5883\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u8b49\u660e\uff0c\u4f7f\u7528 RAAT \u8a13\u7df4\u7684 LLaMA-2 7B \u6a21\u578b\u5728\u4e0d\u540c\u7684\u96dc\u8a0a\u689d\u4ef6\u4e0b\uff0cF1 \u548c EM \u5206\u6578\u90fd\u6709\u986f\u8457\u7684\u63d0\u5347\u3002\u70ba\u4e86\u91cd\u73fe\u6027\uff0c\u6211\u5011\u5728\u4ee5\u4e0b\u4f4d\u7f6e\u91cb\u51fa\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\uff1ahttps://github.com/calubkk/RAAT\u3002", "author": "Feiteng Fang et.al.", "authors": "Feiteng Fang, Yuelin Bai, Shiwen Ni, Min Yang, Xiaojun Chen, Ruifeng Xu", "id": "2405.20978v1", "paper_url": "http://arxiv.org/abs/2405.20978v1", "repo": "null"}}