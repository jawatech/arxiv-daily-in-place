{"2406.14477": {"publish_time": "2024-06-20", "title": "SafeSora: Towards Safety Alignment of Text2Video Generation via a Human Preference Dataset", "paper_summary": "To mitigate the risk of harmful outputs from large vision models (LVMs), we\nintroduce the SafeSora dataset to promote research on aligning text-to-video\ngeneration with human values. This dataset encompasses human preferences in\ntext-to-video generation tasks along two primary dimensions: helpfulness and\nharmlessness. To capture in-depth human preferences and facilitate structured\nreasoning by crowdworkers, we subdivide helpfulness into 4 sub-dimensions and\nharmlessness into 12 sub-categories, serving as the basis for pilot\nannotations. The SafeSora dataset includes 14,711 unique prompts, 57,333 unique\nvideos generated by 4 distinct LVMs, and 51,691 pairs of preference annotations\nlabeled by humans. We further demonstrate the utility of the SafeSora dataset\nthrough several applications, including training the text-video moderation\nmodel and aligning LVMs with human preference by fine-tuning a prompt\naugmentation module or the diffusion model. These applications highlight its\npotential as the foundation for text-to-video alignment research, such as human\npreference modeling and the development and validation of alignment algorithms.", "paper_summary_zh": "\u70ba\u4e86\u964d\u4f4e\u5927\u578b\u8996\u89ba\u6a21\u578b (LVM) \u6709\u5bb3\u7522\u51fa\u7684\u98a8\u96aa\uff0c\u6211\u5011\u5f15\u5165\u4e86 SafeSora \u8cc7\u6599\u96c6\uff0c\u4ee5\u4fc3\u9032\u6587\u672c\u8f49\u5f71\u7247\u751f\u6210\u8207\u4eba\u985e\u50f9\u503c\u89c0\u4e00\u81f4\u6027\u7684\u7814\u7a76\u3002\u6b64\u8cc7\u6599\u96c6\u5305\u542b\u6587\u672c\u8f49\u5f71\u7247\u751f\u6210\u4efb\u52d9\u4e2d\u7684\u4eba\u985e\u504f\u597d\uff0c\u6cbf\u8457\u5169\u500b\u4e3b\u8981\u9762\u5411\uff1a\u6709\u5e6b\u52a9\u6027\u548c\u7121\u5bb3\u6027\u3002\u70ba\u4e86\u6355\u6349\u6df1\u5165\u7684\u4eba\u985e\u504f\u597d\u4e26\u4fc3\u9032\u7fa4\u773e\u5de5\u4f5c\u8005\u7684\u7d50\u69cb\u5316\u63a8\u7406\uff0c\u6211\u5011\u5c07\u6709\u5e6b\u52a9\u6027\u7d30\u5206\u70ba 4 \u500b\u5b50\u9762\u5411\uff0c\u5c07\u7121\u5bb3\u6027\u7d30\u5206\u70ba 12 \u500b\u5b50\u985e\u5225\uff0c\u4f5c\u70ba\u8a66\u9a57\u6a19\u8a3b\u7684\u57fa\u790e\u3002SafeSora \u8cc7\u6599\u96c6\u5305\u542b 14,711 \u500b\u7368\u7279\u63d0\u793a\u30014 \u500b\u4e0d\u540c\u7684 LVM \u751f\u6210\u7684 57,333 \u500b\u7368\u7279\u5f71\u7247\uff0c\u4ee5\u53ca\u4eba\u985e\u6a19\u8a3b\u7684 51,691 \u5c0d\u504f\u597d\u6a19\u8a3b\u3002\u6211\u5011\u9032\u4e00\u6b65\u900f\u904e\u591a\u9805\u61c9\u7528\u5c55\u793a SafeSora \u8cc7\u6599\u96c6\u7684\u6548\u7528\uff0c\u5305\u62ec\u8a13\u7df4\u6587\u672c\u5f71\u7247\u5be9\u6838\u6a21\u578b\uff0c\u4ee5\u53ca\u900f\u904e\u5fae\u8abf\u63d0\u793a\u64f4\u5145\u6a21\u7d44\u6216\u64f4\u6563\u6a21\u578b\uff0c\u4f7f LVM \u8207\u4eba\u985e\u504f\u597d\u4e00\u81f4\u3002\u9019\u4e9b\u61c9\u7528\u7a81\u986f\u4e86\u5176\u4f5c\u70ba\u6587\u672c\u8f49\u5f71\u7247\u5c0d\u9f4a\u7814\u7a76\u57fa\u790e\u7684\u6f5b\u529b\uff0c\u4f8b\u5982\u4eba\u985e\u504f\u597d\u5efa\u6a21\u548c\u5c0d\u9f4a\u6f14\u7b97\u6cd5\u7684\u958b\u767c\u8207\u9a57\u8b49\u3002", "author": "Josef Dai et.al.", "authors": "Josef Dai, Tianle Chen, Xuyao Wang, Ziran Yang, Taiye Chen, Jiaming Ji, Yaodong Yang", "id": "2406.14477v1", "paper_url": "http://arxiv.org/abs/2406.14477v1", "repo": "https://github.com/pku-alignment/safe-sora"}}