{"2412.18224": {"publish_time": "2024-12-24", "title": "Expand VSR Benchmark for VLLM to Expertize in Spatial Rules", "paper_summary": "Distinguishing spatial relations is a basic part of human cognition which\nrequires fine-grained perception on cross-instance. Although benchmarks like\nMME, MMBench and SEED comprehensively have evaluated various capabilities which\nalready include visual spatial reasoning(VSR). There is still a lack of\nsufficient quantity and quality evaluation and optimization datasets for Vision\nLarge Language Models(VLLMs) specifically targeting visual positional\nreasoning. To handle this, we first diagnosed current VLLMs with the VSR\ndataset and proposed a unified test set. We found current VLLMs to exhibit a\ncontradiction of over-sensitivity to language instructions and\nunder-sensitivity to visual positional information. By expanding the original\nbenchmark from two aspects of tunning data and model structure, we mitigated\nthis phenomenon. To our knowledge, we expanded spatially positioned image data\ncontrollably using diffusion models for the first time and integrated original\nvisual encoding(CLIP) with other 3 powerful visual encoders(SigLIP, SAM and\nDINO). After conducting combination experiments on scaling data and models, we\nobtained a VLLM VSR Expert(VSRE) that not only generalizes better to different\ninstructions but also accurately distinguishes differences in visual positional\ninformation. VSRE achieved over a 27\\% increase in accuracy on the VSR test\nset. It becomes a performant VLLM on the position reasoning of both the VSR\ndataset and relevant subsets of other evaluation benchmarks. We open-sourced\nthe expanded model with data and Appendix at\n\\url{https://github.com/peijin360/vsre} and hope it will accelerate\nadvancements in VLLM on VSR learning.", "paper_summary_zh": "\u5340\u5206\u7a7a\u9593\u95dc\u4fc2\u662f\u4eba\u985e\u8a8d\u77e5\u7684\u57fa\u672c\u90e8\u5206\uff0c\u9019\u9700\u8981\u8de8\u4f8b\u5b50\u7684\u7cbe\u7d30\u611f\u77e5\u3002\u5118\u7ba1\u50cf MME\u3001MMBench \u548c SEED \u9019\u6a23\u7684\u57fa\u6e96\u5168\u9762\u8a55\u4f30\u4e86\u5404\u7a2e\u80fd\u529b\uff0c\u5176\u4e2d\u5df2\u5305\u542b\u8996\u89ba\u7a7a\u9593\u63a8\u7406 (VSR)\u3002\u4f46\u4ecd\u7136\u7f3a\u4e4f\u91dd\u5c0d\u8996\u89ba\u4f4d\u7f6e\u63a8\u7406\u7684\u3001\u6578\u91cf\u548c\u8cea\u91cf\u8db3\u5920\u7684\u8a55\u4f30\u548c\u512a\u5316\u8cc7\u6599\u96c6\uff0c\u7279\u5225\u662f\u91dd\u5c0d\u8996\u89ba\u5927\u578b\u8a9e\u8a00\u6a21\u578b (VLLM)\u3002\u70ba\u4e86\u8655\u7406\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u9996\u5148\u4f7f\u7528 VSR \u8cc7\u6599\u96c6\u8a3a\u65b7\u4e86\u76ee\u524d\u7684 VLLM\uff0c\u4e26\u63d0\u51fa\u4e86\u4e00\u500b\u7d71\u4e00\u7684\u6e2c\u8a66\u96c6\u3002\u6211\u5011\u767c\u73fe\u76ee\u524d\u7684 VLLM \u8868\u73fe\u51fa\u5c0d\u8a9e\u8a00\u6307\u4ee4\u904e\u5ea6\u654f\u611f\u548c\u5c0d\u8996\u89ba\u4f4d\u7f6e\u8cc7\u8a0a\u904e\u5ea6\u4e0d\u654f\u611f\u7684\u77db\u76fe\u73fe\u8c61\u3002\u900f\u904e\u5f9e\u8abf\u6574\u8cc7\u6599\u548c\u6a21\u578b\u7d50\u69cb\u5169\u500b\u65b9\u9762\u64f4\u5c55\u539f\u59cb\u57fa\u6e96\uff0c\u6211\u5011\u6e1b\u8f15\u4e86\u9019\u7a2e\u73fe\u8c61\u3002\u64da\u6211\u5011\u6240\u77e5\uff0c\u6211\u5011\u9996\u6b21\u4f7f\u7528\u64f4\u6563\u6a21\u578b\u53ef\u63a7\u5730\u64f4\u5c55\u4e86\u7a7a\u9593\u5b9a\u4f4d\u7684\u5f71\u50cf\u8cc7\u6599\uff0c\u4e26\u5c07\u539f\u59cb\u8996\u89ba\u7de8\u78bc (CLIP) \u8207\u5176\u4ed6 3 \u500b\u5f37\u5927\u7684\u8996\u89ba\u7de8\u78bc\u5668 (SigLIP\u3001SAM \u548c DINO) \u6574\u5408\u5728\u4e00\u8d77\u3002\u5728\u5c0d\u8cc7\u6599\u548c\u6a21\u578b\u7684\u64f4\u5145\u9032\u884c\u7d44\u5408\u5be6\u9a57\u5f8c\uff0c\u6211\u5011\u7372\u5f97\u4e86\u4e00\u500b VLLM VSR \u5c08\u5bb6 (VSRE)\uff0c\u5b83\u4e0d\u50c5\u80fd\u5c0d\u4e0d\u540c\u7684\u6307\u4ee4\u9032\u884c\u66f4\u597d\u7684\u6982\u62ec\uff0c\u9084\u80fd\u6e96\u78ba\u5340\u5206\u8996\u89ba\u4f4d\u7f6e\u8cc7\u8a0a\u7684\u5dee\u7570\u3002VSRE \u5728 VSR \u6e2c\u8a66\u96c6\u4e2d\u6e96\u78ba\u7387\u63d0\u9ad8\u4e86 27% \u4ee5\u4e0a\u3002\u5b83\u6210\u70ba\u4e86 VSR \u8cc7\u6599\u96c6\u548c\u5176\u5b83\u8a55\u4f30\u57fa\u6e96\u76f8\u95dc\u5b50\u96c6\u7684\u5b9a\u4f4d\u63a8\u7406\u4e2d\u6548\u80fd\u826f\u597d\u7684 VLLM\u3002\u6211\u5011\u5728 \\url{https://github.com/peijin360/vsre} \u958b\u6e90\u4e86\u64f4\u5c55\u6a21\u578b\u3001\u8cc7\u6599\u548c\u9644\u9304\uff0c\u4e26\u5e0c\u671b\u5b83\u80fd\u52a0\u901f VLLM \u5728 VSR \u5b78\u7fd2\u65b9\u9762\u7684\u9032\u5c55\u3002", "author": "Peijin Xie et.al.", "authors": "Peijin Xie, Lin Sun, Bingquan Liu, Dexin Wang, Xiangzheng Zhang, Chengjie Sun, Jiajia Zhang", "id": "2412.18224v1", "paper_url": "http://arxiv.org/abs/2412.18224v1", "repo": "https://github.com/peijin360/vsre"}}