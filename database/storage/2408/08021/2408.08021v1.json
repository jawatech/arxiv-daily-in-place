{"2408.08021": {"publish_time": "2024-08-15", "title": "DIVE: Towards Descriptive and Diverse Visual Commonsense Generation", "paper_summary": "Towards human-level visual understanding, visual commonsense generation has\nbeen introduced to generate commonsense inferences beyond images. However,\ncurrent research on visual commonsense generation has overlooked an important\nhuman cognitive ability: generating descriptive and diverse inferences. In this\nwork, we propose a novel visual commonsense generation framework, called DIVE,\nwhich aims to improve the descriptiveness and diversity of generated\ninferences. DIVE involves two methods, generic inference filtering and\ncontrastive retrieval learning, which address the limitations of existing\nvisual commonsense resources and training objectives. Experimental results\nverify that DIVE outperforms state-of-the-art models for visual commonsense\ngeneration in terms of both descriptiveness and diversity, while showing a\nsuperior quality in generating unique and novel inferences. Notably, DIVE\nachieves human-level descriptiveness and diversity on Visual Commonsense\nGraphs. Furthermore, human evaluations confirm that DIVE aligns closely with\nhuman judgments on descriptiveness and diversity\\footnote{Our code and dataset\nare available at https://github.com/Park-ing-lot/DIVE.", "paper_summary_zh": "\u70ba\u4e86\u9054\u5230\u4eba\u985e\u5c64\u7d1a\u7684\u8996\u89ba\u7406\u89e3\uff0c\u8996\u89ba\u5e38\u8b58\u751f\u6210\u5df2\u7d93\u88ab\u5f15\u5165\uff0c\u4ee5\u7522\u751f\u8d85\u8d8a\u5716\u50cf\u7684\u5e38\u8b58\u63a8\u8ad6\u3002\u7136\u800c\uff0c\u76ee\u524d\u95dc\u65bc\u8996\u89ba\u5e38\u8b58\u751f\u6210\u7684\u7684\u7814\u7a76\u5ffd\u7565\u4e86\u4e00\u7a2e\u91cd\u8981\u7684\u4eba\u985e\u8a8d\u77e5\u80fd\u529b\uff1a\u7522\u751f\u63cf\u8ff0\u6027\u548c\u591a\u6a23\u6027\u7684\u63a8\u8ad6\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7a4e\u7684\u8996\u89ba\u5e38\u8b58\u751f\u6210\u6846\u67b6\uff0c\u7a31\u70ba DIVE\uff0c\u5176\u76ee\u6a19\u662f\u63d0\u9ad8\u751f\u6210\u63a8\u8ad6\u7684\u63cf\u8ff0\u6027\u548c\u591a\u6a23\u6027\u3002DIVE \u6d89\u53ca\u5169\u7a2e\u65b9\u6cd5\uff0c\u5373\u901a\u7528\u63a8\u8ad6\u904e\u6ffe\u548c\u5c0d\u6bd4\u6aa2\u7d22\u5b78\u7fd2\uff0c\u5b83\u5011\u89e3\u6c7a\u4e86\u73fe\u6709\u8996\u89ba\u5e38\u8b58\u8cc7\u6e90\u548c\u8a13\u7df4\u76ee\u6a19\u7684\u9650\u5236\u3002\u5be6\u9a57\u7d50\u679c\u9a57\u8b49\u4e86 DIVE \u5728\u63cf\u8ff0\u6027\u548c\u591a\u6a23\u6027\u65b9\u9762\u512a\u65bc\u8996\u89ba\u5e38\u8b58\u751f\u6210\u7684\u6700\u65b0\u6a21\u578b\uff0c\u540c\u6642\u5728\u751f\u6210\u7368\u7279\u548c\u65b0\u7a4e\u7684\u63a8\u8ad6\u65b9\u9762\u8868\u73fe\u51fa\u512a\u7570\u7684\u54c1\u8cea\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cDIVE \u5728\u8996\u89ba\u5e38\u8b58\u5716\u4e0a\u9054\u5230\u4e86\u4eba\u985e\u5c64\u7d1a\u7684\u63cf\u8ff0\u6027\u548c\u591a\u6a23\u6027\u3002\u6b64\u5916\uff0c\u4eba\u985e\u8a55\u4f30\u8b49\u5be6\uff0cDIVE \u5728\u63cf\u8ff0\u6027\u548c\u591a\u6a23\u6027\u65b9\u9762\u8207\u4eba\u985e\u5224\u65b7\u7dca\u5bc6\u4e00\u81f4\u3002", "author": "Jun-Hyung Park et.al.", "authors": "Jun-Hyung Park, Hyuntae Park, Youjin Kang, Eojin Jeon, SangKeun Lee", "id": "2408.08021v1", "paper_url": "http://arxiv.org/abs/2408.08021v1", "repo": "https://github.com/park-ing-lot/dive"}}