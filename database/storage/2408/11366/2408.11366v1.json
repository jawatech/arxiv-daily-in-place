{"2408.11366": {"publish_time": "2024-08-21", "title": "GeoReasoner: Reasoning On Geospatially Grounded Context For Natural Language Understanding", "paper_summary": "In human reading and communication, individuals tend to engage in geospatial\nreasoning, which involves recognizing geographic entities and making informed\ninferences about their interrelationships. To mimic such cognitive process,\ncurrent methods either utilize conventional natural language understanding\ntoolkits, or directly apply models pretrained on geo-related natural language\ncorpora. However, these methods face two significant challenges: i) they do not\ngeneralize well to unseen geospatial scenarios, and ii) they overlook the\nimportance of integrating geospatial context from geographical databases with\nlinguistic information from the Internet. To handle these challenges, we\npropose GeoReasoner, a language model capable of reasoning on geospatially\ngrounded natural language. Specifically, it first leverages Large Language\nModels (LLMs) to generate a comprehensive location description based on\nlinguistic and geospatial information. It also encodes direction and distance\ninformation into spatial embedding via treating them as pseudo-sentences.\nConsequently, the model is trained on both anchor-level and neighbor-level\ninputs to learn geo-entity representation. Extensive experimental results\ndemonstrate GeoReasoner's superiority in three tasks: toponym recognition,\ntoponym linking, and geo-entity typing, compared to the state-of-the-art\nbaselines.", "paper_summary_zh": "\u5728\u4eba\u985e\u7684\u95b1\u8b80\u548c\u6e9d\u901a\u4e2d\uff0c\u500b\u4eba\u50be\u5411\u65bc\u5f9e\u4e8b\u5730\u7406\u7a7a\u9593\u63a8\u7406\uff0c\u9019\u6d89\u53ca\u8b58\u5225\u5730\u7406\u5be6\u9ad4\u4e26\u5c0d\u5b83\u5011\u7684\u76f8\u4e92\u95dc\u4fc2\u505a\u51fa\u660e\u667a\u7684\u63a8\u8ad6\u3002\u70ba\u4e86\u6a21\u64ec\u9019\u7a2e\u8a8d\u77e5\u904e\u7a0b\uff0c\u7576\u524d\u7684\u505a\u6cd5\u662f\u5229\u7528\u50b3\u7d71\u7684\u81ea\u7136\u8a9e\u8a00\u7406\u89e3\u5de5\u5177\u5305\uff0c\u6216\u76f4\u63a5\u61c9\u7528\u9810\u5148\u5728\u8207\u5730\u7406\u76f8\u95dc\u7684\u81ea\u7136\u8a9e\u8a00\u8a9e\u6599\u5eab\u4e0a\u8a13\u7df4\u7684\u6a21\u578b\u3002\u7136\u800c\uff0c\u9019\u4e9b\u65b9\u6cd5\u9762\u81e8\u8457\u5169\u500b\u91cd\u5927\u7684\u6311\u6230\uff1ai) \u5b83\u5011\u7121\u6cd5\u5f88\u597d\u5730\u63a8\u5ee3\u5230\u672a\u898b\u904e\u7684\u5730\u7406\u7a7a\u9593\u5834\u666f\uff0c\u4ee5\u53ca ii) \u5b83\u5011\u5ffd\u8996\u4e86\u5c07\u4f86\u81ea\u5730\u7406\u8cc7\u6599\u5eab\u7684\u5730\u7406\u7a7a\u9593\u80cc\u666f\u8207\u4f86\u81ea\u7db2\u969b\u7db2\u8def\u7684\u8a9e\u8a00\u8cc7\u8a0a\u6574\u5408\u8d77\u4f86\u7684\u91cd\u8981\u6027\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa\u4e86 GeoReasoner\uff0c\u9019\u662f\u4e00\u500b\u80fd\u5920\u5c0d\u5730\u7406\u7a7a\u9593\u57fa\u790e\u81ea\u7136\u8a9e\u8a00\u9032\u884c\u63a8\u7406\u7684\u8a9e\u8a00\u6a21\u578b\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u5b83\u9996\u5148\u5229\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6839\u64da\u8a9e\u8a00\u548c\u5730\u7406\u7a7a\u9593\u8cc7\u8a0a\u751f\u6210\u5168\u9762\u7684\u4f4d\u7f6e\u63cf\u8ff0\u3002\u5b83\u9084\u5c07\u65b9\u5411\u548c\u8ddd\u96e2\u8cc7\u8a0a\u7de8\u78bc\u5230\u7a7a\u9593\u5d4c\u5165\u4e2d\uff0c\u5c07\u5b83\u5011\u8996\u70ba\u507d\u53e5\u5b50\u3002\u56e0\u6b64\uff0c\u8a72\u6a21\u578b\u5728\u9328\u9ede\u7d1a\u5225\u548c\u9130\u5c45\u7d1a\u5225\u7684\u8f38\u5165\u4e0a\u9032\u884c\u8a13\u7df4\uff0c\u4ee5\u5b78\u7fd2\u5730\u7406\u5be6\u9ad4\u8868\u793a\u3002\u5927\u91cf\u7684\u5be6\u9a57\u7d50\u679c\u8b49\u660e\u4e86 GeoReasoner \u5728\u4e09\u9805\u4efb\u52d9\u4e2d\u7684\u512a\u8d8a\u6027\uff1a\u5730\u540d\u8b58\u5225\u3001\u5730\u540d\u9023\u7d50\u548c\u5730\u7406\u5be6\u9ad4\u985e\u578b\uff0c\u8207\u6700\u5148\u9032\u7684\u57fa\u6e96\u76f8\u6bd4\u3002", "author": "Yibo Yan et.al.", "authors": "Yibo Yan, Joey Lee", "id": "2408.11366v1", "paper_url": "http://arxiv.org/abs/2408.11366v1", "repo": "null"}}