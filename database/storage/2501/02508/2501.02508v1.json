{"2501.02508": {"publish_time": "2025-01-05", "title": "PTEENet: Post-Trained Early-Exit Neural Networks Augmentation for Inference Cost Optimization", "paper_summary": "For many practical applications, a high computational cost of inference over\ndeep network architectures might be unacceptable. A small degradation in the\noverall inference accuracy might be a reasonable price to pay for a significant\nreduction in the required computational resources. In this work, we describe a\nmethod for introducing \"shortcuts\" into the DNN feedforward inference process\nby skipping costly feedforward computations whenever possible. The proposed\nmethod is based on the previously described BranchyNet (Teerapittayanon et al.,\n2016) and the EEnet (Demir, 2019) architectures that jointly train the main\nnetwork and early exit branches. We extend those methods by attaching branches\nto pre-trained models and, thus, eliminating the need to alter the original\nweights of the network. We also suggest a new branch architecture based on\nconvolutional building blocks to allow enough training capacity when applied on\nlarge DNNs. The proposed architecture includes confidence heads that are used\nfor predicting the confidence level in the corresponding early exits. By\ndefining adjusted thresholds on these confidence extensions, we can control in\nreal-time the amount of data exiting from each branch and the overall tradeoff\nbetween speed and accuracy of our model. In our experiments, we evaluate our\nmethod using image datasets (SVHN and CIFAR10) and several DNN architectures\n(ResNet, DenseNet, VGG) with varied depth. Our results demonstrate that the\nproposed method enables us to reduce the average inference computational cost\nand further controlling the tradeoff between the model accuracy and the\ncomputation cost.", "paper_summary_zh": "\u5c0d\u65bc\u8a31\u591a\u5be6\u7528\u7684\u61c9\u7528\uff0c\u6df1\u5ea6\u7db2\u8def\u67b6\u69cb\u4e2d\u63a8\u8ad6\u7684\u9ad8\u904b\u7b97\u6210\u672c\u53ef\u80fd\u7121\u6cd5\u63a5\u53d7\u3002\u6574\u9ad4\u63a8\u8ad6\u7cbe\u5ea6\u7684\u4e9b\u5fae\u964d\u4f4e\u53ef\u80fd\u662f\u70ba\u5927\u5e45\u6e1b\u5c11\u6240\u9700\u7684\u904b\u7b97\u8cc7\u6e90\u6240\u4ed8\u51fa\u7684\u5408\u7406\u4ee3\u50f9\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63cf\u8ff0\u4e00\u7a2e\u65b9\u6cd5\uff0c\u900f\u904e\u5728\u53ef\u80fd\u7684\u60c5\u6cc1\u4e0b\u7565\u904e\u6602\u8cb4\u7684\u994b\u9001\u524d\u5411\u904b\u7b97\uff0c\u5c07\u300c\u6377\u5f91\u300d\u5f15\u5165 DNN \u994b\u9001\u524d\u5411\u63a8\u8ad6\u7a0b\u5e8f\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u57fa\u65bc\u5148\u524d\u63cf\u8ff0\u7684 BranchyNet\uff08Teerapittayanon \u7b49\u4eba\uff0c2016 \u5e74\uff09\u548c EEnet\uff08Demir\uff0c2019 \u5e74\uff09\u67b6\u69cb\uff0c\u9019\u4e9b\u67b6\u69cb\u6703\u806f\u5408\u8a13\u7df4\u4e3b\u7db2\u8def\u548c\u65e9\u671f\u9000\u51fa\u5206\u652f\u3002\u6211\u5011\u900f\u904e\u5c07\u5206\u652f\u9644\u52a0\u5230\u9810\u8a13\u7df4\u6a21\u578b\u4f86\u5ef6\u4f38\u9019\u4e9b\u65b9\u6cd5\uff0c\u56e0\u6b64\u6d88\u9664\u4e86\u8b8a\u66f4\u7db2\u8def\u539f\u59cb\u6b0a\u91cd\u7684\u9700\u8981\u3002\u6211\u5011\u4e5f\u5efa\u8b70\u4e00\u7a2e\u65b0\u7684\u5206\u652f\u67b6\u69cb\uff0c\u57fa\u65bc\u5377\u7a4d\u5efa\u69cb\u5340\u584a\uff0c\u4ee5\u4fbf\u5728\u61c9\u7528\u65bc\u5927\u578b DNN \u6642\u5141\u8a31\u8db3\u5920\u7684\u8a13\u7df4\u5bb9\u91cf\u3002\u6240\u63d0\u51fa\u7684\u67b6\u69cb\u5305\u542b\u7528\u65bc\u9810\u6e2c\u5c0d\u61c9\u65e9\u671f\u9000\u51fa\u7684\u4fe1\u5fc3\u6c34\u6e96\u7684\u4fe1\u5fc3\u5340\u584a\u3002\u900f\u904e\u5b9a\u7fa9\u9019\u4e9b\u4fe1\u5fc3\u5ef6\u4f38\u7684\u8abf\u6574\u95be\u503c\uff0c\u6211\u5011\u53ef\u4ee5\u5728\u57f7\u884c\u968e\u6bb5\u63a7\u5236\u5f9e\u6bcf\u500b\u5206\u652f\u9000\u51fa\u7684\u8cc7\u6599\u91cf\uff0c\u4ee5\u53ca\u6a21\u578b\u7684\u901f\u5ea6\u8207\u7cbe\u5ea6\u7684\u6574\u9ad4\u53d6\u6368\u3002\u5728\u6211\u5011\u7684\u5be6\u9a57\u4e2d\uff0c\u6211\u5011\u4f7f\u7528\u5f71\u50cf\u8cc7\u6599\u96c6\uff08SVHN \u548c CIFAR10\uff09\u548c\u5404\u7a2e\u6df1\u5ea6\uff08ResNet\u3001DenseNet\u3001VGG\uff09\u7684 DNN \u67b6\u69cb\u4f86\u8a55\u4f30\u6211\u5011\u7684\u6a21\u578b\u3002\u6211\u5011\u7684\u7d50\u679c\u986f\u793a\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u8b93\u6211\u5011\u6e1b\u5c11\u5e73\u5747\u63a8\u8ad6\u904b\u7b97\u6210\u672c\uff0c\u4e26\u9032\u4e00\u6b65\u63a7\u5236\u6a21\u578b\u7cbe\u5ea6\u8207\u904b\u7b97\u6210\u672c\u4e4b\u9593\u7684\u53d6\u6368\u3002", "author": "Assaf Lahiany et.al.", "authors": "Assaf Lahiany, Yehudit Aperstein", "id": "2501.02508v1", "paper_url": "http://arxiv.org/abs/2501.02508v1", "repo": "null"}}