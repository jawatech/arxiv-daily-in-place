{"2502.13019": {"publish_time": "2025-02-18", "title": "Oreo: A Plug-in Context Reconstructor to Enhance Retrieval-Augmented Generation", "paper_summary": "Despite the remarkable capabilities of Large Language Models (LLMs) in\nvarious NLP tasks, they remain vulnerable to hallucinations due to their\nlimited parametric knowledge and lack of domain-specific expertise.\nRetrieval-Augmented Generation (RAG) addresses this challenge by incorporating\nexternal document retrieval to augment the knowledge base of LLMs. In this\napproach, RAG retrieves document chunks from an external corpus in response to\na query, which are then used as context for the downstream language model to\ngenerate an answer. However, these retrieved knowledge sources often include\nirrelevant or erroneous information, undermining the effectiveness of RAG in\ndownstream tasks. To overcome this limitation, we introduce a compact,\nefficient, and pluggable module designed to refine external knowledge sources\nbefore feeding them to the generator. The module reconstructs retrieved content\nby extracting the most relevant and supportive information and reorganising it\ninto a concise, query-specific format. Through a three-stage training paradigm\n- comprising supervised fine-tuning, contrastive multi-task learning, and\nreinforcement learning-based alignment - it prioritises critical knowledge and\naligns it with the generator's preferences. This method enables LLMs to produce\noutputs that are more accurate, reliable, and contextually appropriate.", "paper_summary_zh": "\u5118\u7ba1\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u5404\u7a2e\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4efb\u52d9\u4e2d\u5177\u5099\u5353\u8d8a\u7684\u80fd\u529b\uff0c\u4f46\u7531\u65bc\u5176\u53c3\u6578\u77e5\u8b58\u6709\u9650\u4e14\u7f3a\u4e4f\u7279\u5b9a\u9818\u57df\u7684\u5c08\u696d\u77e5\u8b58\uff0c\u56e0\u6b64\u5b83\u5011\u4ecd\u7136\u5bb9\u6613\u51fa\u73fe\u5e7b\u89ba\u3002\u6aa2\u7d22\u589e\u5f37\u5f0f\u751f\u6210 (RAG) \u900f\u904e\u7d0d\u5165\u5916\u90e8\u6587\u4ef6\u6aa2\u7d22\u4f86\u64f4\u5145 LLM \u7684\u77e5\u8b58\u5eab\uff0c\u4ee5\u61c9\u5c0d\u6b64\u9805\u6311\u6230\u3002\u5728\u6b64\u65b9\u6cd5\u4e2d\uff0cRAG \u6703\u6839\u64da\u67e5\u8a62\u6aa2\u7d22\u5916\u90e8\u8a9e\u6599\u5eab\u4e2d\u7684\u6587\u4ef6\u5340\u584a\uff0c\u7136\u5f8c\u5c07\u5176\u7528\u4f5c\u4e0b\u6e38\u8a9e\u8a00\u6a21\u578b\u7684\u80cc\u666f\uff0c\u4ee5\u7522\u751f\u7b54\u6848\u3002\u7136\u800c\uff0c\u9019\u4e9b\u6aa2\u7d22\u5230\u7684\u77e5\u8b58\u4f86\u6e90\u901a\u5e38\u5305\u542b\u4e0d\u76f8\u95dc\u6216\u932f\u8aa4\u7684\u8cc7\u8a0a\uff0c\u56e0\u800c\u640d\u5bb3\u4e86 RAG \u5728\u4e0b\u6e38\u4efb\u52d9\u4e2d\u7684\u6548\u80fd\u3002\u70ba\u4e86\u514b\u670d\u6b64\u9805\u9650\u5236\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u7cbe\u7c21\u3001\u6709\u6548\u7387\u4e14\u53ef\u63d2\u5165\u7684\u6a21\u7d44\uff0c\u7528\u65bc\u5728\u5c07\u5916\u90e8\u77e5\u8b58\u4f86\u6e90\u63d0\u4f9b\u7d66\u751f\u6210\u5668\u4e4b\u524d\u5c0d\u5176\u9032\u884c\u7cbe\u7149\u3002\u6b64\u6a21\u7d44\u900f\u904e\u63d0\u53d6\u6700\u76f8\u95dc\u4e14\u6709\u7528\u7684\u8cc7\u8a0a\u4e26\u5c07\u5176\u91cd\u65b0\u7d44\u7e54\u6210\u7c21\u6f54\u4e14\u7279\u5b9a\u65bc\u67e5\u8a62\u7684\u683c\u5f0f\uff0c\u4f86\u91cd\u5efa\u6aa2\u7d22\u5230\u7684\u5167\u5bb9\u3002\u900f\u904e\u4e09\u968e\u6bb5\u8a13\u7df4\u7bc4\u4f8b - \u5305\u542b\u76e3\u7763\u5fae\u8abf\u3001\u5c0d\u6bd4\u591a\u4efb\u52d9\u5b78\u7fd2\u4ee5\u53ca\u57fa\u65bc\u5f37\u5316\u5b78\u7fd2\u7684\u6bd4\u5c0d - \u5b83\u512a\u5148\u8003\u91cf\u95dc\u9375\u77e5\u8b58\uff0c\u4e26\u4f7f\u5176\u8207\u751f\u6210\u5668\u7684\u504f\u597d\u76f8\u7b26\u3002\u6b64\u65b9\u6cd5\u53ef\u8b93 LLM \u7522\u751f\u66f4\u6e96\u78ba\u3001\u53ef\u9760\u4e14\u5728\u8a9e\u5883\u4e0a\u66f4\u9069\u7576\u7684\u8f38\u51fa\u3002", "author": "Sha Li et.al.", "authors": "Sha Li, Naren Ramarkrishnan", "id": "2502.13019v1", "paper_url": "http://arxiv.org/abs/2502.13019v1", "repo": "null"}}