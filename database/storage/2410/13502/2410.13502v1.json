{"2410.13502": {"publish_time": "2024-10-17", "title": "MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily Complex Proofs", "paper_summary": "Large language models (LLMs) can solve arithmetic word problems with high\naccuracy, but little is known about how well they generalize to problems that\nare more complex than the ones on which they have been trained. Empirical\ninvestigations of such questions are impeded by two major flaws of current\nevaluations: (i) much of the evaluation data is contaminated, in the sense that\nit has already been seen during training, and (ii) benchmark datasets do not\ncapture how problem proofs may be arbitrarily complex in various ways. As a\nstep towards addressing these issues, we present a framework for evaluating\nLLMs on problems that have arbitrarily complex arithmetic proofs, called\nMathGAP. MathGAP generates problems that follow fixed proof specifications --\nalong with chain-of-thought reasoning annotations -- enabling systematic\nstudies on generalization with respect to arithmetic proof complexity. We apply\nMathGAP to analyze how in-context learning interacts with generalization to\nproblems that have more complex proofs. We find that among the models tested,\nmost show a significant decrease in performance as proofs get deeper and wider.\nThis effect is more pronounced in complex, nonlinear proof structures, which\nare challenging even for GPT-4o. Surprisingly, providing in-context examples\nfrom the same distribution as the test set is not always beneficial for\nperformance. In particular, zero-shot prompting as well as demonstrating a\ndiverse range of examples that are less complex than the test data sometimes\nyield similar or higher accuracies.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u80fd\u4ee5\u6975\u9ad8\u7684\u6e96\u78ba\u5ea6\u89e3\u6c7a\u7b97\u8853\u5b57\u8a5e\u554f\u984c\uff0c\u4f46\u5c0d\u65bc\u5b83\u5011\u5728\u6bd4\u8a13\u7df4\u8cc7\u6599\u66f4\u8907\u96dc\u7684\u554f\u984c\u4e2d\u80fd\u6709\u591a\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u6211\u5011\u6240\u77e5\u751a\u5c11\u3002\u76ee\u524d\u8a55\u4f30\u7684\u5169\u5927\u4e3b\u8981\u7f3a\u9677\u963b\u7919\u4e86\u5c0d\u6b64\u985e\u554f\u984c\u7684\u7d93\u9a57\u8abf\u67e5\uff1a(i) \u5927\u90e8\u5206\u8a55\u4f30\u8cc7\u6599\u90fd\u53d7\u5230\u6c61\u67d3\uff0c\u56e0\u70ba\u5b83\u5011\u5728\u8a13\u7df4\u671f\u9593\u5df2\u7d93\u88ab\u770b\u904e\uff0c\u800c\u4e14 (ii) \u57fa\u6e96\u8cc7\u6599\u96c6\u7121\u6cd5\u6355\u6349\u5230\u554f\u984c\u8b49\u660e\u5728\u5404\u65b9\u9762\u53ef\u80fd\u4efb\u610f\u8907\u96dc\u7684\u60c5\u6cc1\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u6846\u67b6\uff0c\u7528\u65bc\u8a55\u4f30 LLM \u5728\u5177\u6709\u4efb\u610f\u8907\u96dc\u7b97\u8853\u8b49\u660e\u7684\u554f\u984c\u4e0a\uff0c\u7a31\u70ba MathGAP\u3002MathGAP \u6703\u7522\u751f\u9075\u5faa\u56fa\u5b9a\u8b49\u660e\u898f\u683c\u7684\u554f\u984c\uff0c\u4e26\u9644\u4e0a\u601d\u8003\u93c8\u63a8\u7406\u8a3b\u89e3\uff0c\u5f9e\u800c\u80fd\u91dd\u5c0d\u7b97\u8853\u8b49\u660e\u8907\u96dc\u5ea6\u9032\u884c\u7cfb\u7d71\u5316\u6cdb\u5316\u7814\u7a76\u3002\u6211\u5011\u904b\u7528 MathGAP \u4f86\u5206\u6790\u60c5\u5883\u5167\u5b78\u7fd2\u5982\u4f55\u8207\u6cdb\u5316\u5230\u5177\u6709\u66f4\u8907\u96dc\u8b49\u660e\u7684\u554f\u984c\u9032\u884c\u4ea4\u4e92\u4f5c\u7528\u3002\u6211\u5011\u767c\u73fe\uff0c\u5728\u6e2c\u8a66\u7684\u6a21\u578b\u4e2d\uff0c\u5927\u591a\u6578\u6a21\u578b\u5728\u8b49\u660e\u8b8a\u5f97\u66f4\u6df1\u66f4\u5ee3\u6642\uff0c\u6548\u80fd\u6703\u5927\u5e45\u4e0b\u964d\u3002\u9019\u7a2e\u6548\u61c9\u5728\u8907\u96dc\u7684\u975e\u7dda\u6027\u8b49\u660e\u7d50\u69cb\u4e2d\u66f4\u70ba\u660e\u986f\uff0c\u5373\u4f7f\u5c0d GPT-4o \u4f86\u8aaa\u4e5f\u662f\u4e00\u500b\u6311\u6230\u3002\u4ee4\u4eba\u9a5a\u8a1d\u7684\u662f\uff0c\u63d0\u4f9b\u8207\u6e2c\u8a66\u96c6\u76f8\u540c\u5206\u4f48\u7684\u60c5\u5883\u5167\u7bc4\u4f8b\uff0c\u5c0d\u65bc\u6548\u80fd\u4e26\u4e0d\u7e3d\u662f\u6703\u6709\u5e6b\u52a9\u3002\u7279\u5225\u662f\uff0c\u96f6\u6b21\u63d0\u793a\u4ee5\u53ca\u5c55\u793a\u6bd4\u6e2c\u8a66\u8cc7\u6599\u4e0d\u90a3\u9ebc\u8907\u96dc\u7684\u5404\u7a2e\u7bc4\u4f8b\uff0c\u6709\u6642\u6703\u7522\u751f\u76f8\u4f3c\u6216\u66f4\u9ad8\u7684\u6e96\u78ba\u5ea6\u3002", "author": "Andreas Opedal et.al.", "authors": "Andreas Opedal, Haruki Shirakami, Bernhard Sch\u00f6lkopf, Abulhair Saparov, Mrinmaya Sachan", "id": "2410.13502v1", "paper_url": "http://arxiv.org/abs/2410.13502v1", "repo": "null"}}