{"2410.21131": {"publish_time": "2024-10-28", "title": "Towards Unifying Evaluation of Counterfactual Explanations: Leveraging Large Language Models for Human-Centric Assessments", "paper_summary": "As machine learning models evolve, maintaining transparency demands more\nhuman-centric explainable AI techniques. Counterfactual explanations, with\nroots in human reasoning, identify the minimal input changes needed to obtain a\ngiven output and, hence, are crucial for supporting decision-making. Despite\ntheir importance, the evaluation of these explanations often lacks grounding in\nuser studies and remains fragmented, with existing metrics not fully capturing\nhuman perspectives. To address this challenge, we developed a diverse set of 30\ncounterfactual scenarios and collected ratings across 8 evaluation metrics from\n206 respondents. Subsequently, we fine-tuned different Large Language Models\n(LLMs) to predict average or individual human judgment across these metrics.\nOur methodology allowed LLMs to achieve an accuracy of up to 63% in zero-shot\nevaluations and 85% (over a 3-classes prediction) with fine-tuning across all\nmetrics. The fine-tuned models predicting human ratings offer better\ncomparability and scalability in evaluating different counterfactual\nexplanation frameworks.", "paper_summary_zh": "\u96a8\u8457\u6a5f\u5668\u5b78\u7fd2\u6a21\u578b\u7684\u6f14\u9032\uff0c\u7dad\u8b77\u900f\u660e\u5ea6\u9700\u8981\u66f4\u591a\u4ee5\u4eba\u70ba\u4e2d\u5fc3\u7684\u89e3\u91cb\u6027\u4eba\u5de5\u667a\u6167\u6280\u8853\u3002\u53cd\u4e8b\u5be6\u89e3\u91cb\u690d\u6839\u65bc\u4eba\u985e\u63a8\u7406\uff0c\u627e\u51fa\u53d6\u5f97\u7279\u5b9a\u8f38\u51fa\u6240\u9700\u7684\u6700\u5c0f\u8f38\u5165\u8b8a\u66f4\uff0c\u56e0\u6b64\u5c0d\u65bc\u652f\u63f4\u6c7a\u7b56\u5236\u5b9a\u81f3\u95dc\u91cd\u8981\u3002\u5118\u7ba1\u5b83\u5011\u5f88\u91cd\u8981\uff0c\u4f46\u9019\u4e9b\u89e3\u91cb\u7684\u8a55\u4f30\u901a\u5e38\u7f3a\u4e4f\u4f7f\u7528\u8005\u7814\u7a76\u7684\u57fa\u790e\uff0c\u800c\u4e14\u4ecd\u7136\u652f\u96e2\u7834\u788e\uff0c\u73fe\u6709\u7684\u6307\u6a19\u7121\u6cd5\u5b8c\u5168\u6355\u6349\u4eba\u985e\u89c0\u9ede\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e00\u6311\u6230\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u7d44\u591a\u5143\u5316\u7684 30 \u500b\u53cd\u4e8b\u5be6\u5834\u666f\uff0c\u4e26\u5f9e 206 \u540d\u53d7\u8a2a\u8005\u6536\u96c6\u4e86 8 \u9805\u8a55\u4f30\u6307\u6a19\u7684\u8a55\u5206\u3002\u96a8\u5f8c\uff0c\u6211\u5011\u5fae\u8abf\u4e86\u4e0d\u540c\u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\uff0c\u4ee5\u9810\u6e2c\u9019\u4e9b\u6307\u6a19\u4e2d\u7684\u4eba\u985e\u5e73\u5747\u6216\u500b\u5225\u5224\u65b7\u3002\u6211\u5011\u7684\u6280\u8853\u4f7f LLM \u80fd\u5920\u5728\u96f6\u6b21\u5b78\u7fd2\u8a55\u4f30\u4e2d\u5be6\u73fe\u9ad8\u9054 63% \u7684\u6e96\u78ba\u5ea6\uff0c\u4e26\u5728\u6240\u6709\u6307\u6a19\u4e0a\u9032\u884c\u5fae\u8abf\u5f8c\u5be6\u73fe 85%\uff08\u8d85\u904e 3 \u985e\u9810\u6e2c\uff09\u3002\u9810\u6e2c\u4eba\u985e\u8a55\u5206\u7684\u5fae\u8abf\u6a21\u578b\u5728\u8a55\u4f30\u4e0d\u540c\u7684\u53cd\u4e8b\u5be6\u89e3\u91cb\u6846\u67b6\u6642\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u53ef\u6bd4\u6027\u548c\u53ef\u64f4\u5145\u6027\u3002", "author": "Marharyta Domnich et.al.", "authors": "Marharyta Domnich, Julius Valja, Rasmus Moorits Veski, Giacomo Magnifico, Kadi Tulver, Eduard Barbu, Raul Vicente", "id": "2410.21131v1", "paper_url": "http://arxiv.org/abs/2410.21131v1", "repo": "null"}}