{"2409.03444": {"publish_time": "2024-09-05", "title": "Fine-tuning large language models for domain adaptation: Exploration of training strategies, scaling, model merging and synergistic capabilities", "paper_summary": "The advancement of Large Language Models (LLMs) for domain applications in\nfields such as materials science and engineering depends on the development of\nfine-tuning strategies that adapt models for specialized, technical\ncapabilities. In this work, we explore the effects of Continued Pretraining\n(CPT), Supervised Fine-Tuning (SFT), and various preference-based optimization\napproaches, including Direct Preference Optimization (DPO) and Odds Ratio\nPreference Optimization (ORPO), on fine-tuned LLM performance. Our analysis\nshows how these strategies influence model outcomes and reveals that the\nmerging of multiple fine-tuned models can lead to the emergence of capabilities\nthat surpass the individual contributions of the parent models. We find that\nmodel merging leads to new functionalities that neither parent model could\nachieve alone, leading to improved performance in domain-specific assessments.\nExperiments with different model architectures are presented, including Llama\n3.1 8B and Mistral 7B models, where similar behaviors are observed. Exploring\nwhether the results hold also for much smaller models, we use a tiny LLM with\n1.7 billion parameters and show that very small LLMs do not necessarily feature\nemergent capabilities under model merging, suggesting that model scaling may be\na key component. In open-ended yet consistent chat conversations between a\nhuman and AI models, our assessment reveals detailed insights into how\ndifferent model variants perform and show that the smallest model achieves a\nhigh intelligence score across key criteria including reasoning depth,\ncreativity, clarity, and quantitative precision. Other experiments include the\ndevelopment of image generation prompts based on disparate biological material\ndesign concepts, to create new microstructures, architectural concepts, and\nurban design based on biological materials-inspired construction principles.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u6750\u6599\u79d1\u5b78\u548c\u5de5\u7a0b\u7b49\u9818\u57df\u7684\u9818\u57df\u61c9\u7528\u9032\u6b65\u53d6\u6c7a\u65bc\u5fae\u8abf\u7b56\u7565\u7684\u767c\u5c55\uff0c\u9019\u4e9b\u7b56\u7565\u53ef\u8abf\u6574\u6a21\u578b\u4ee5\u9069\u61c9\u5c08\u696d\u7684\u6280\u8853\u80fd\u529b\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u6301\u7e8c\u9810\u8a13\u7df4 (CPT)\u3001\u76e3\u7763\u5fae\u8abf (SFT) \u548c\u5404\u7a2e\u57fa\u65bc\u504f\u597d\u7684\u6700\u4f73\u5316\u65b9\u6cd5\uff08\u5305\u62ec\u76f4\u63a5\u504f\u597d\u6700\u4f73\u5316 (DPO) \u548c\u6a5f\u7387\u6bd4\u504f\u597d\u6700\u4f73\u5316 (ORPO)\uff09\u5c0d\u5fae\u8abf\u5f8c\u7684 LLM \u6548\u80fd\u7684\u5f71\u97ff\u3002\u6211\u5011\u7684\u5206\u6790\u986f\u793a\u9019\u4e9b\u7b56\u7565\u5982\u4f55\u5f71\u97ff\u6a21\u578b\u7d50\u679c\uff0c\u4e26\u63ed\u793a\u591a\u500b\u5fae\u8abf\u6a21\u578b\u7684\u5408\u4f75\u53ef\u80fd\u5c0e\u81f4\u51fa\u73fe\u8d85\u8d8a\u7236\u6a21\u578b\u500b\u5225\u8ca2\u737b\u7684\u80fd\u529b\u3002\u6211\u5011\u767c\u73fe\u6a21\u578b\u5408\u4f75\u5c0e\u81f4\u65b0\u7684\u529f\u80fd\uff0c\u800c\u4efb\u4f55\u7236\u6a21\u578b\u90fd\u7121\u6cd5\u55ae\u7368\u5be6\u73fe\uff0c\u5f9e\u800c\u63d0\u9ad8\u7279\u5b9a\u9818\u57df\u8a55\u4f30\u7684\u6548\u80fd\u3002\u6211\u5011\u5c55\u793a\u4e86\u4f7f\u7528\u4e0d\u540c\u6a21\u578b\u67b6\u69cb\u7684\u5be6\u9a57\uff0c\u5305\u62ec Llama 3.1 8B \u548c Mistral 7B \u6a21\u578b\uff0c\u5176\u4e2d\u89c0\u5bdf\u5230\u985e\u4f3c\u7684\u884c\u70ba\u3002\u70ba\u4e86\u63a2\u8a0e\u7d50\u679c\u662f\u5426\u4e5f\u9069\u7528\u65bc\u66f4\u5c0f\u7684\u6a21\u578b\uff0c\u6211\u5011\u4f7f\u7528\u4e00\u500b\u53ea\u6709 17 \u5104\u500b\u53c3\u6578\u7684\u5c0f\u578b LLM\uff0c\u4e26\u986f\u793a\u975e\u5e38\u5c0f\u7684 LLM \u5728\u6a21\u578b\u5408\u4f75\u4e0b\u4e0d\u4e00\u5b9a\u5177\u6709\u6d6e\u73fe\u7684\u80fd\u529b\uff0c\u9019\u8868\u793a\u6a21\u578b\u7e2e\u653e\u53ef\u80fd\u662f\u95dc\u9375\u7d44\u6210\u90e8\u5206\u3002\u5728\u4eba\u985e\u548c AI \u6a21\u578b\u4e4b\u9593\u958b\u653e\u5f0f\u4f46\u4e00\u81f4\u7684\u804a\u5929\u5c0d\u8a71\u4e2d\uff0c\u6211\u5011\u7684\u8a55\u4f30\u63ed\u793a\u4e86\u4e0d\u540c\u6a21\u578b\u8b8a\u9ad4\u7684\u57f7\u884c\u65b9\u5f0f\u7684\u8a73\u7d30\u898b\u89e3\uff0c\u4e26\u986f\u793a\u6700\u5c0f\u7684\u6a21\u578b\u5728\u5305\u62ec\u63a8\u7406\u6df1\u5ea6\u3001\u5275\u9020\u529b\u3001\u6e05\u6670\u5ea6\u548c\u5b9a\u91cf\u7cbe\u78ba\u5ea6\u7b49\u95dc\u9375\u6a19\u6e96\u4e2d\u90fd\u7372\u5f97\u4e86\u5f88\u9ad8\u7684\u667a\u529b\u5206\u6578\u3002\u5176\u4ed6\u5be6\u9a57\u5305\u62ec\u57fa\u65bc\u4e0d\u540c\u7684\u751f\u7269\u6750\u6599\u8a2d\u8a08\u6982\u5ff5\u958b\u767c\u5716\u50cf\u751f\u6210\u63d0\u793a\uff0c\u4ee5\u6839\u64da\u53d7\u751f\u7269\u6750\u6599\u555f\u767c\u7684\u5efa\u7bc9\u539f\u7406\u5efa\u7acb\u65b0\u7684\u5fae\u7d50\u69cb\u3001\u5efa\u7bc9\u6982\u5ff5\u548c\u57ce\u5e02\u8a2d\u8a08\u3002", "author": "Wei Lu et.al.", "authors": "Wei Lu, Rachel K. Luu, Markus J. Buehler", "id": "2409.03444v1", "paper_url": "http://arxiv.org/abs/2409.03444v1", "repo": "https://github.com/lamm-mit/llm-finetuning"}}