{"2409.07440": {"publish_time": "2024-09-11", "title": "SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories", "paper_summary": "Given that Large Language Models (LLMs) have made significant progress in\nwriting code, can they now be used to autonomously reproduce results from\nresearch repositories? Such a capability would be a boon to the research\ncommunity, helping researchers validate, understand, and extend prior work. To\nadvance towards this goal, we introduce SUPER, the first benchmark designed to\nevaluate the capability of LLMs in setting up and executing tasks from research\nrepositories. SUPERaims to capture the realistic challenges faced by\nresearchers working with Machine Learning (ML) and Natural Language Processing\n(NLP) research repositories. Our benchmark comprises three distinct problem\nsets: 45 end-to-end problems with annotated expert solutions, 152 sub problems\nderived from the expert set that focus on specific challenges (e.g.,\nconfiguring a trainer), and 602 automatically generated problems for\nlarger-scale development. We introduce various evaluation measures to assess\nboth task success and progress, utilizing gold solutions when available or\napproximations otherwise. We show that state-of-the-art approaches struggle to\nsolve these problems with the best model (GPT-4o) solving only 16.3% of the\nend-to-end set, and 46.1% of the scenarios. This illustrates the challenge of\nthis task, and suggests that SUPER can serve as a valuable resource for the\ncommunity to make and measure progress.", "paper_summary_zh": "\u9274\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u5728\u7f16\u5199\u4ee3\u7801\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u5b83\u4eec\u73b0\u5728\u53ef\u5426\u7528\u4e8e\u81ea\u4e3b\u590d\u5236\u7814\u7a76\u5b58\u50a8\u5e93\u4e2d\u7684\u7ed3\u679c\uff1f\u8fd9\u79cd\u80fd\u529b\u5c06\u5bf9\u7814\u7a76\u754c\u5927\u6709\u88e8\u76ca\uff0c\u6709\u52a9\u4e8e\u7814\u7a76\u4eba\u5458\u9a8c\u8bc1\u3001\u7406\u89e3\u548c\u6269\u5c55\u5148\u524d\u7684\u5de5\u4f5c\u3002\u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\uff0c\u6211\u4eec\u5f15\u5165\u4e86 SUPER\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u65e8\u5728\u8bc4\u4f30 LLM \u5728\u8bbe\u7f6e\u548c\u6267\u884c\u7814\u7a76\u5b58\u50a8\u5e93\u4e2d\u7684\u4efb\u52a1\u7684\u80fd\u529b\u7684\u57fa\u51c6\u3002SUPER \u65e8\u5728\u89e3\u51b3\u7814\u7a76\u4eba\u5458\u5728\u4f7f\u7528\u673a\u5668\u5b66\u4e60 (ML) \u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406 (NLP) \u7814\u7a76\u5b58\u50a8\u5e93\u65f6\u9762\u4e34\u7684\u5b9e\u9645\u6311\u6218\u3002\u6211\u4eec\u7684\u57fa\u51c6\u5305\u542b\u4e09\u4e2a\u4e0d\u540c\u7684\u95ee\u9898\u96c6\uff1a45 \u4e2a\u5e26\u6709\u4e13\u5bb6\u89e3\u51b3\u65b9\u6848\u6ce8\u91ca\u7684\u7aef\u5230\u7aef\u95ee\u9898\u3001152 \u4e2a\u4ece\u4e13\u5bb6\u96c6\u4e2d\u6d3e\u751f\u51fa\u6765\u7684\u5b50\u95ee\u9898\uff0c\u8fd9\u4e9b\u5b50\u95ee\u9898\u4fa7\u91cd\u4e8e\u7279\u5b9a\u6311\u6218\uff08\u4f8b\u5982\u914d\u7f6e\u8bad\u7ec3\u5668\uff09\uff0c\u4ee5\u53ca 602 \u4e2a\u4e3a\u66f4\u5927\u89c4\u6a21\u5f00\u53d1\u81ea\u52a8\u751f\u6210\u7684\u95ee\u9898\u3002\u6211\u4eec\u5f15\u5165\u4e86\u5404\u79cd\u8bc4\u4f30\u63aa\u65bd\u6765\u8bc4\u4f30\u4efb\u52a1\u6210\u529f\u548c\u8fdb\u5ea6\uff0c\u5728\u6709\u9ec4\u91d1\u89e3\u51b3\u65b9\u6848\u65f6\u4f7f\u7528\u9ec4\u91d1\u89e3\u51b3\u65b9\u6848\uff0c\u5426\u5219\u4f7f\u7528\u8fd1\u4f3c\u503c\u3002\u6211\u4eec\u8868\u660e\uff0c\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u96be\u4ee5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u6700\u597d\u7684\u6a21\u578b (GPT-4o) \u4ec5\u89e3\u51b3\u4e86 16.3% \u7684\u7aef\u5230\u7aef\u96c6\u548c 46.1% \u7684\u573a\u666f\u3002\u8fd9\u8bf4\u660e\u4e86\u8fd9\u9879\u4efb\u52a1\u7684\u6311\u6218\u6027\uff0c\u5e76\u8868\u660e SUPER \u53ef\u4ee5\u4f5c\u4e3a\u793e\u533a\u505a\u51fa\u548c\u8861\u91cf\u8fdb\u6b65\u7684\u5b9d\u8d35\u8d44\u6e90\u3002", "author": "Ben Bogin et.al.", "authors": "Ben Bogin, Kejuan Yang, Shashank Gupta, Kyle Richardson, Erin Bransom, Peter Clark, Ashish Sabharwal, Tushar Khot", "id": "2409.07440v1", "paper_url": "http://arxiv.org/abs/2409.07440v1", "repo": "https://github.com/allenai/super-benchmark"}}