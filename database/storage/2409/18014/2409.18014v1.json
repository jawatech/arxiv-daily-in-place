{"2409.18014": {"publish_time": "2024-09-26", "title": "Role-RL: Online Long-Context Processing with Role Reinforcement Learning for Distinct LLMs in Their Optimal Roles", "paper_summary": "Large language models (LLMs) with long-context processing are still\nchallenging because of their implementation complexity, training efficiency and\ndata sparsity. To address this issue, a new paradigm named Online Long-context\nProcessing (OLP) is proposed when we process a document of unlimited length,\nwhich typically occurs in the information reception and organization of diverse\nstreaming media such as automated news reporting, live e-commerce, and viral\nshort videos. Moreover, a dilemma was often encountered when we tried to select\nthe most suitable LLM from a large number of LLMs amidst explosive growth\naiming for outstanding performance, affordable prices, and short response\ndelays. In view of this, we also develop Role Reinforcement Learning (Role-RL)\nto automatically deploy different LLMs in their respective roles within the OLP\npipeline according to their actual performance. Extensive experiments are\nconducted on our OLP-MINI dataset and it is found that OLP with Role-RL\nframework achieves OLP benchmark with an average recall rate of 93.2% and the\nLLM cost saved by 79.4%. The code and dataset are publicly available at:\nhttps://anonymous.4open.science/r/Role-RL.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5177\u6709\u9577\u8a9e\u5883\u8655\u7406\u80fd\u529b\uff0c\u4f46\u7531\u65bc\u5176\u8907\u96dc\u7684\u5be6\u4f5c\u3001\u8a13\u7df4\u6548\u7387\u548c\u8cc7\u6599\u7a00\u758f\u6027\uff0c\u4ecd\u9762\u81e8\u6311\u6230\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u7576\u6211\u5011\u8655\u7406\u9577\u5ea6\u4e0d\u9650\u7684\u6587\u4ef6\u6642\uff0c\u63d0\u51fa\u4e86\u4e00\u7a2e\u540d\u70ba\u7dda\u4e0a\u9577\u8a9e\u5883\u8655\u7406 (OLP) \u7684\u65b0\u7bc4\u4f8b\uff0c\u9019\u901a\u5e38\u767c\u751f\u5728\u81ea\u52d5\u5316\u65b0\u805e\u5831\u5c0e\u3001\u76f4\u64ad\u96fb\u5b50\u5546\u52d9\u548c\u75c5\u6bd2\u5f0f\u77ed\u5f71\u7247\u7b49\u5404\u7a2e\u4e32\u6d41\u5a92\u9ad4\u7684\u8cc7\u8a0a\u63a5\u6536\u548c\u7d44\u7e54\u4e2d\u3002\u6b64\u5916\uff0c\u5728\u7206\u70b8\u6027\u7684\u6210\u9577\u4e2d\uff0c\u6211\u5011\u5617\u8a66\u5f9e\u5927\u91cf\u7684 LLM \u4e2d\u9078\u64c7\u6700\u5408\u9069\u7684 LLM \u6642\uff0c\u7d93\u5e38\u6703\u9047\u5230\u5169\u96e3\u7684\u5c40\u9762\uff0c\u76ee\u6a19\u662f\u8ffd\u6c42\u5091\u51fa\u7684\u6548\u80fd\u3001\u8ca0\u64d4\u5f97\u8d77\u7684\u50f9\u683c\u548c\u77ed\u66ab\u7684\u56de\u61c9\u5ef6\u9072\u3002\u6709\u9451\u65bc\u6b64\uff0c\u6211\u5011\u4e5f\u958b\u767c\u4e86\u89d2\u8272\u5f37\u5316\u5b78\u7fd2 (Role-RL) \u4ee5\u6839\u64da\u5176\u5be6\u969b\u6548\u80fd\uff0c\u5728 OLP \u7ba1\u7dda\u4e2d\u81ea\u52d5\u90e8\u7f72\u4e0d\u540c\u7684 LLM \u5230\u5404\u81ea\u7684\u89d2\u8272\u4e2d\u3002\u5728\u6211\u5011\u7684 OLP-MINI \u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u767c\u73fe\u63a1\u7528\u89d2\u8272\u5f37\u5316\u5b78\u7fd2\u67b6\u69cb\u7684 OLP \u9054\u5230\u4e86 OLP \u8a55\u91cf\u6a19\u6e96\uff0c\u5e73\u5747\u53ec\u56de\u7387\u70ba 93.2%\uff0c\u4e14 LLM \u6210\u672c\u7bc0\u7701\u4e86 79.4%\u3002\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\u96c6\u5df2\u516c\u958b\u65bc\uff1ahttps://anonymous.4open.science/r/Role-RL\u3002", "author": "Lewei He et.al.", "authors": "Lewei He, Tianyu Shi, Pengran Huang, Bingzhi Chen, Qianglong Chen, Jiahui Pan", "id": "2409.18014v1", "paper_url": "http://arxiv.org/abs/2409.18014v1", "repo": "null"}}