{"2412.09263": {"publish_time": "2024-12-12", "title": "First Train to Generate, then Generate to Train: UnitedSynT5 for Few-Shot NLI", "paper_summary": "Natural Language Inference (NLI) tasks require identifying the relationship\nbetween sentence pairs, typically classified as entailment, contradiction, or\nneutrality. While the current state-of-the-art (SOTA) model, Entailment\nFew-Shot Learning (EFL), achieves a 93.1% accuracy on the Stanford Natural\nLanguage Inference (SNLI) dataset, further advancements are constrained by the\ndataset's limitations. To address this, we propose a novel approach leveraging\nsynthetic data augmentation to enhance dataset diversity and complexity. We\npresent UnitedSynT5, an advanced extension of EFL that leverages a T5-based\ngenerator to synthesize additional premise-hypothesis pairs, which are\nrigorously cleaned and integrated into the training data. These augmented\nexamples are processed within the EFL framework, embedding labels directly into\nhypotheses for consistency. We train a GTR-T5-XL model on this expanded\ndataset, achieving a new benchmark of 94.7% accuracy on the SNLI dataset,\n94.01% accuracy on the E-SNLI dataset, and 92.57% accuracy on the MultiNLI\ndataset, surpassing the previous SOTA models. This research demonstrates the\npotential of synthetic data augmentation in improving NLI models, offering a\npath forward for further advancements in natural language understanding tasks.", "paper_summary_zh": "\u81ea\u7136\u8a9e\u8a00\u63a8\u8ad6 (NLI) \u4efb\u52d9\u9700\u8981\u8fa8\u8b58\u53e5\u5b50\u5c0d\u4e4b\u9593\u7684\u95dc\u4fc2\uff0c\u901a\u5e38\u5206\u985e\u70ba\u860a\u6db5\u3001\u77db\u76fe\u6216\u4e2d\u7acb\u3002\u96d6\u7136\u7576\u524d\u6700\u5148\u9032 (SOTA) \u7684\u6a21\u578b\uff0c\u860a\u6db5\u5c11\u767c\u5b78\u7fd2 (EFL)\uff0c\u5728\u53f2\u4e39\u4f5b\u81ea\u7136\u8a9e\u8a00\u63a8\u8ad6 (SNLI) \u8cc7\u6599\u96c6\u4e0a\u9054\u5230\u4e86 93.1% \u7684\u6e96\u78ba\u5ea6\uff0c\u4f46\u9032\u4e00\u6b65\u7684\u9032\u5c55\u53d7\u5230\u8cc7\u6599\u96c6\u9650\u5236\u7684\u7d04\u675f\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u5408\u6210\u8cc7\u6599\u64f4\u5145\u4f86\u589e\u5f37\u8cc7\u6599\u96c6\u7684\u591a\u6a23\u6027\u548c\u8907\u96dc\u6027\u3002\u6211\u5011\u63d0\u51fa\u4e86 UnitedSynT5\uff0c\u9019\u662f\u4e00\u7a2e EFL \u7684\u9032\u968e\u64f4\u5145\uff0c\u5b83\u5229\u7528\u57fa\u65bc T5 \u7684\u751f\u6210\u5668\u4f86\u5408\u6210\u984d\u5916\u7684\u524d\u63d0\u5047\u8a2d\u5c0d\uff0c\u9019\u4e9b\u5c0d\u7d93\u904e\u56b4\u683c\u7684\u6e05\u7406\u4e26\u6574\u5408\u5230\u8a13\u7df4\u8cc7\u6599\u4e2d\u3002\u9019\u4e9b\u64f4\u5145\u7684\u7bc4\u4f8b\u5728 EFL \u67b6\u69cb\u4e2d\u9032\u884c\u8655\u7406\uff0c\u5c07\u6a19\u7c64\u76f4\u63a5\u5d4c\u5165\u5047\u8a2d\u4e2d\u4ee5\u78ba\u4fdd\u4e00\u81f4\u6027\u3002\u6211\u5011\u5728\u9019\u500b\u64f4\u5145\u7684\u8cc7\u6599\u96c6\u4e0a\u8a13\u7df4\u4e86\u4e00\u500b GTR-T5-XL \u6a21\u578b\uff0c\u5728 SNLI \u8cc7\u6599\u96c6\u4e0a\u9054\u5230\u4e86 94.7% \u7684\u6e96\u78ba\u5ea6\u65b0\u57fa\u6e96\uff0c\u5728 E-SNLI \u8cc7\u6599\u96c6\u4e0a\u9054\u5230\u4e86 94.01% \u7684\u6e96\u78ba\u5ea6\uff0c\u5728 MultiNLI \u8cc7\u6599\u96c6\u4e0a\u9054\u5230\u4e86 92.57% \u7684\u6e96\u78ba\u5ea6\uff0c\u8d85\u8d8a\u4e86\u4e4b\u524d\u7684 SOTA \u6a21\u578b\u3002\u9019\u9805\u7814\u7a76\u5c55\u793a\u4e86\u5408\u6210\u8cc7\u6599\u64f4\u5145\u5728\u6539\u5584 NLI \u6a21\u578b\u4e2d\u7684\u6f5b\u529b\uff0c\u70ba\u81ea\u7136\u8a9e\u8a00\u7406\u89e3\u4efb\u52d9\u7684\u9032\u4e00\u6b65\u9032\u5c55\u63d0\u4f9b\u4e86\u524d\u9032\u7684\u9053\u8def\u3002", "author": "Sourav Banerjee et.al.", "authors": "Sourav Banerjee, Anush Mahajan, Ayushi Agarwal, Eishkaran Singh", "id": "2412.09263v1", "paper_url": "http://arxiv.org/abs/2412.09263v1", "repo": "null"}}