{"2410.19230": {"publish_time": "2024-10-25", "title": "Humanizing the Machine: Proxy Attacks to Mislead LLM Detectors", "paper_summary": "The advent of large language models (LLMs) has revolutionized the field of\ntext generation, producing outputs that closely mimic human-like writing.\nAlthough academic and industrial institutions have developed detectors to\nprevent the malicious usage of LLM-generated texts, other research has doubt\nabout the robustness of these systems. To stress test these detectors, we\nintroduce a proxy-attack strategy that effortlessly compromises LLMs, causing\nthem to produce outputs that align with human-written text and mislead\ndetection systems. Our method attacks the source model by leveraging a\nreinforcement learning (RL) fine-tuned humanized small language model (SLM) in\nthe decoding phase. Through an in-depth analysis, we demonstrate that our\nattack strategy is capable of generating responses that are indistinguishable\nto detectors, preventing them from differentiating between machine-generated\nand human-written text. We conduct systematic evaluations on extensive datasets\nusing proxy-attacked open-source models, including Llama2-13B, Llama3-70B, and\nMixtral-8*7B in both white- and black-box settings. Our findings show that the\nproxy-attack strategy effectively deceives the leading detectors, resulting in\nan average AUROC drop of 70.4% across multiple datasets, with a maximum drop of\n90.3% on a single dataset. Furthermore, in cross-discipline scenarios, our\nstrategy also bypasses these detectors, leading to a significant relative\ndecrease of up to 90.9%, while in cross-language scenario, the drop reaches\n91.3%. Despite our proxy-attack strategy successfully bypassing the detectors\nwith such significant relative drops, we find that the generation quality of\nthe attacked models remains preserved, even within a modest utility budget,\nwhen compared to the text produced by the original, unattacked source model.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u51fa\u73fe\u5fb9\u5e95\u6539\u8b8a\u4e86\u6587\u672c\u751f\u6210\u9818\u57df\uff0c\u7522\u751f\u7684\u8f38\u51fa\u8207\u4eba\u985e\u5beb\u4f5c\u975e\u5e38\u63a5\u8fd1\u3002\u5118\u7ba1\u5b78\u8853\u548c\u7522\u696d\u6a5f\u69cb\u5df2\u958b\u767c\u51fa\u5075\u6e2c\u5668\uff0c\u4ee5\u9632\u6b62\u60e1\u610f\u4f7f\u7528 LLM \u751f\u6210\u7684\u6587\u672c\uff0c\u4f46\u5176\u4ed6\u7814\u7a76\u5c0d\u9019\u4e9b\u7cfb\u7d71\u7684\u5065\u5168\u6027\u8868\u793a\u61f7\u7591\u3002\u70ba\u4e86\u5c0d\u9019\u4e9b\u5075\u6e2c\u5668\u9032\u884c\u58d3\u529b\u6e2c\u8a66\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4ee3\u7406\u653b\u64ca\u7b56\u7565\uff0c\u8a72\u7b56\u7565\u6beb\u4e0d\u8cbb\u529b\u5730\u5371\u5bb3 LLM\uff0c\u5c0e\u81f4\u5b83\u5011\u7522\u751f\u7684\u8f38\u51fa\u8207\u4eba\u985e\u64b0\u5beb\u7684\u6587\u672c\u4e00\u81f4\uff0c\u4e26\u8aa4\u5c0e\u5075\u6e2c\u7cfb\u7d71\u3002\u6211\u5011\u7684\u653b\u64ca\u65b9\u6cd5\u900f\u904e\u5728\u89e3\u78bc\u968e\u6bb5\u5229\u7528\u5f37\u5316\u5b78\u7fd2 (RL) \u5fae\u8abf\u7684\u4eba\u6027\u5316\u5c0f\u578b\u8a9e\u8a00\u6a21\u578b (SLM) \u4f86\u653b\u64ca\u539f\u59cb\u6a21\u578b\u3002\u900f\u904e\u6df1\u5165\u5206\u6790\uff0c\u6211\u5011\u8b49\u660e\u6211\u5011\u7684\u653b\u64ca\u7b56\u7565\u80fd\u5920\u7522\u751f\u8207\u5075\u6e2c\u5668\u7121\u6cd5\u5340\u5206\u7684\u56de\u61c9\uff0c\u4f7f\u5b83\u5011\u7121\u6cd5\u5340\u5206\u6a5f\u5668\u7522\u751f\u7684\u6587\u672c\u548c\u4eba\u985e\u64b0\u5beb\u7684\u6587\u672c\u3002\u6211\u5011\u5728\u5ee3\u6cdb\u7684\u8cc7\u6599\u96c6\u4e0a\u4f7f\u7528\u4ee3\u7406\u653b\u64ca\u7684\u958b\u6e90\u6a21\u578b\uff08\u5305\u62ec Llama2-13B\u3001Llama3-70B \u548c Mixtral-8*7B\uff09\u9032\u884c\u7cfb\u7d71\u8a55\u4f30\uff0c\u5305\u62ec\u767d\u76d2\u548c\u9ed1\u76d2\u8a2d\u5b9a\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u986f\u793a\uff0c\u4ee3\u7406\u653b\u64ca\u7b56\u7565\u6709\u6548\u5730\u6b3a\u9a19\u4e86\u9818\u5148\u7684\u5075\u6e2c\u5668\uff0c\u5c0e\u81f4\u591a\u500b\u8cc7\u6599\u96c6\u7684\u5e73\u5747 AUROC \u4e0b\u964d 70.4%\uff0c\u5728\u55ae\u4e00\u8cc7\u6599\u96c6\u4e0a\u7684\u6700\u5927\u4e0b\u964d\u70ba 90.3%\u3002\u6b64\u5916\uff0c\u5728\u8de8\u5b78\u79d1\u5834\u666f\u4e2d\uff0c\u6211\u5011\u7684\u7b56\u7565\u4e5f\u7e5e\u904e\u4e86\u9019\u4e9b\u5075\u6e2c\u5668\uff0c\u5c0e\u81f4\u986f\u8457\u7684\u76f8\u5c0d\u4e0b\u964d\uff0c\u6700\u9ad8\u9054 90.9%\uff0c\u800c\u5728\u8de8\u8a9e\u8a00\u5834\u666f\u4e2d\uff0c\u4e0b\u964d\u5e45\u5ea6\u9054\u5230 91.3%\u3002\u5118\u7ba1\u6211\u5011\u7684\u4ee3\u7406\u653b\u64ca\u7b56\u7565\u6210\u529f\u5730\u7e5e\u904e\u4e86\u5075\u6e2c\u5668\uff0c\u4e26\u7522\u751f\u5982\u6b64\u986f\u8457\u7684\u76f8\u5c0d\u4e0b\u964d\uff0c\u4f46\u6211\u5011\u767c\u73fe\uff0c\u8207\u539f\u59cb\u672a\u653b\u64ca\u7684\u539f\u59cb\u6a21\u578b\u7522\u751f\u7684\u6587\u672c\u76f8\u6bd4\uff0c\u5373\u4f7f\u5728\u9069\u5ea6\u7684\u5be6\u7528\u9810\u7b97\u5167\uff0c\u88ab\u653b\u64ca\u6a21\u578b\u7684\u751f\u6210\u54c1\u8cea\u4ecd\u7136\u4fdd\u6301\u4e0d\u8b8a\u3002", "author": "Tianchun Wang et.al.", "authors": "Tianchun Wang, Yuanzhou Chen, Zichuan Liu, Zhanwen Chen, Haifeng Chen, Xiang Zhang, Wei Cheng", "id": "2410.19230v1", "paper_url": "http://arxiv.org/abs/2410.19230v1", "repo": "null"}}