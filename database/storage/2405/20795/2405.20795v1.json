{"2405.20795": {"publish_time": "2024-05-31", "title": "InsightSee: Advancing Multi-agent Vision-Language Models for Enhanced Visual Understanding", "paper_summary": "Accurate visual understanding is imperative for advancing autonomous systems\nand intelligent robots. Despite the powerful capabilities of vision-language\nmodels (VLMs) in processing complex visual scenes, precisely recognizing\nobscured or ambiguously presented visual elements remains challenging. To\ntackle such issues, this paper proposes InsightSee, a multi-agent framework to\nenhance VLMs' interpretative capabilities in handling complex visual\nunderstanding scenarios. The framework comprises a description agent, two\nreasoning agents, and a decision agent, which are integrated to refine the\nprocess of visual information interpretation. The design of these agents and\nthe mechanisms by which they can be enhanced in visual information processing\nare presented. Experimental results demonstrate that the InsightSee framework\nnot only boosts performance on specific visual tasks but also retains the\noriginal models' strength. The proposed framework outperforms state-of-the-art\nalgorithms in 6 out of 9 benchmark tests, with a substantial advancement in\nmultimodal understanding.", "paper_summary_zh": "\u6e96\u78ba\u7684\u8996\u89ba\u7406\u89e3\u5c0d\u65bc\u63a8\u9032\u81ea\u4e3b\u7cfb\u7d71\u548c\u667a\u6167\u6a5f\u5668\u4eba\u81f3\u95dc\u91cd\u8981\u3002\u5118\u7ba1\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM) \u5728\u8655\u7406\u8907\u96dc\u8996\u89ba\u5834\u666f\u65b9\u9762\u5177\u6709\u5f37\u5927\u7684\u80fd\u529b\uff0c\u4f46\u7cbe\u78ba\u8b58\u5225\u6a21\u7cca\u6216\u542b\u7cca\u5448\u73fe\u7684\u8996\u89ba\u5143\u7d20\u4ecd\u7136\u5177\u6709\u6311\u6230\u6027\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u672c\u6587\u63d0\u51fa\u4e86 InsightSee\uff0c\u4e00\u500b\u591a\u4ee3\u7406\u67b6\u69cb\uff0c\u4ee5\u589e\u5f37 VLM \u5728\u8655\u7406\u8907\u96dc\u8996\u89ba\u7406\u89e3\u5834\u666f\u65b9\u9762\u7684\u89e3\u91cb\u80fd\u529b\u3002\u8a72\u67b6\u69cb\u5305\u542b\u4e00\u500b\u63cf\u8ff0\u4ee3\u7406\u3001\u5169\u500b\u63a8\u7406\u4ee3\u7406\u548c\u4e00\u500b\u6c7a\u7b56\u4ee3\u7406\uff0c\u9019\u4e9b\u4ee3\u7406\u88ab\u6574\u5408\u8d77\u4f86\u4ee5\u512a\u5316\u8996\u89ba\u8cc7\u8a0a\u89e3\u91cb\u7684\u904e\u7a0b\u3002\u9019\u4e9b\u4ee3\u7406\u7684\u8a2d\u8a08\u4ee5\u53ca\u5b83\u5011\u5728\u8996\u89ba\u8cc7\u8a0a\u8655\u7406\u4e2d\u53ef\u4ee5\u589e\u5f37\u7684\u6a5f\u5236\u90fd\u5df2\u63d0\u51fa\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0cInsightSee \u6846\u67b6\u4e0d\u50c5\u63d0\u5347\u4e86\u7279\u5b9a\u8996\u89ba\u4efb\u52d9\u7684\u6548\u80fd\uff0c\u800c\u4e14\u9084\u4fdd\u7559\u4e86\u539f\u59cb\u6a21\u578b\u7684\u512a\u52e2\u3002\u6240\u63d0\u51fa\u7684\u6846\u67b6\u5728 9 \u9805\u57fa\u6e96\u6e2c\u8a66\u4e2d\u7684 6 \u9805\u4e2d\u512a\u65bc\u6700\u5148\u9032\u7684\u6f14\u7b97\u6cd5\uff0c\u5728\u591a\u6a21\u614b\u7406\u89e3\u65b9\u9762\u53d6\u5f97\u4e86\u986f\u8457\u9032\u5c55\u3002", "author": "Huaxiang Zhang et.al.", "authors": "Huaxiang Zhang, Yaojia Mu, Guo-Niu Zhu, Zhongxue Gan", "id": "2405.20795v1", "paper_url": "http://arxiv.org/abs/2405.20795v1", "repo": "null"}}