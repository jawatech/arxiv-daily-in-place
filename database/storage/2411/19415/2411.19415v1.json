{"2411.19415": {"publish_time": "2024-11-28", "title": "AMO Sampler: Enhancing Text Rendering with Overshooting", "paper_summary": "Achieving precise alignment between textual instructions and generated images\nin text-to-image generation is a significant challenge, particularly in\nrendering written text within images. Sate-of-the-art models like Stable\nDiffusion 3 (SD3), Flux, and AuraFlow still struggle with accurate text\ndepiction, resulting in misspelled or inconsistent text. We introduce a\ntraining-free method with minimal computational overhead that significantly\nenhances text rendering quality. Specifically, we introduce an overshooting\nsampler for pretrained rectified flow (RF) models, by alternating between\nover-simulating the learned ordinary differential equation (ODE) and\nreintroducing noise. Compared to the Euler sampler, the overshooting sampler\neffectively introduces an extra Langevin dynamics term that can help correct\nthe compounding error from successive Euler steps and therefore improve the\ntext rendering. However, when the overshooting strength is high, we observe\nover-smoothing artifacts on the generated images. To address this issue, we\npropose an Attention Modulated Overshooting sampler (AMO), which adaptively\ncontrols the strength of overshooting for each image patch according to their\nattention score with the text content. AMO demonstrates a 32.3% and 35.9%\nimprovement in text rendering accuracy on SD3 and Flux without compromising\noverall image quality or increasing inference cost.", "paper_summary_zh": "\u5728\u6587\u672c\u5230\u56fe\u50cf\u7684\u751f\u6210\u4e2d\uff0c\u5b9e\u73b0\u6587\u672c\u8bf4\u660e\u4e0e\u751f\u6210\u7684\u56fe\u50cf\u4e4b\u95f4\u7684\u7cbe\u786e\u5bf9\u9f50\u662f\u4e00\u9879\u91cd\u5927\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u56fe\u50cf\u4e2d\u5448\u73b0\u4e66\u9762\u6587\u672c\u65f6\u3002\u6700\u5148\u8fdb\u7684\u6a21\u578b\uff0c\u5982 Stable Diffusion 3 (SD3)\u3001Flux \u548c AuraFlow \u4ecd\u7136\u96be\u4ee5\u51c6\u786e\u63cf\u7ed8\u6587\u672c\uff0c\u5bfc\u81f4\u6587\u672c\u62fc\u5199\u9519\u8bef\u6216\u4e0d\u4e00\u81f4\u3002\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u8bad\u7ec3\u81ea\u7531\u7684\u65b9\u6cd5\uff0c\u8ba1\u7b97\u5f00\u9500\u6700\u5c0f\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u6587\u672c\u6e32\u67d3\u8d28\u91cf\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u4e3a\u9884\u8bad\u7ec3\u7684\u6574\u6d41\u6d41 (RF) \u6a21\u578b\u5f15\u5165\u4e86\u4e00\u4e2a\u8fc7\u51b2\u91c7\u6837\u5668\uff0c\u901a\u8fc7\u5728\u8fc7\u5ea6\u6a21\u62df\u5df2\u5b66\u4e60\u7684\u5e38\u5fae\u5206\u65b9\u7a0b (ODE) \u548c\u91cd\u65b0\u5f15\u5165\u566a\u58f0\u4e4b\u95f4\u4ea4\u66ff\u8fdb\u884c\u3002\u4e0e\u6b27\u62c9\u91c7\u6837\u5668\u76f8\u6bd4\uff0c\u8fc7\u51b2\u91c7\u6837\u5668\u6709\u6548\u5730\u5f15\u5165\u4e86\u4e00\u4e2a\u989d\u5916\u7684\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\u9879\uff0c\u53ef\u4ee5\u5e2e\u52a9\u4fee\u6b63\u8fde\u7eed\u6b27\u62c9\u6b65\u9aa4\u7684\u590d\u5408\u8bef\u5dee\uff0c\u4ece\u800c\u6539\u5584\u6587\u672c\u6e32\u67d3\u3002\u4f46\u662f\uff0c\u5f53\u8fc7\u51b2\u5f3a\u5ea6\u8f83\u9ad8\u65f6\uff0c\u6211\u4eec\u89c2\u5bdf\u5230\u751f\u6210\u56fe\u50cf\u4e0a\u5b58\u5728\u8fc7\u5ea6\u5e73\u6ed1\u7684\u4f2a\u5f71\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u6ce8\u610f\u529b\u8c03\u5236\u8fc7\u51b2\u91c7\u6837\u5668 (AMO)\uff0c\u5b83\u6839\u636e\u56fe\u50cf\u5757\u4e0e\u5176\u6587\u672c\u5185\u5bb9\u7684\u6ce8\u610f\u529b\u5206\u6570\u81ea\u9002\u5e94\u5730\u63a7\u5236\u6bcf\u4e2a\u56fe\u50cf\u5757\u7684\u8fc7\u51b2\u5f3a\u5ea6\u3002AMO \u5728 SD3 \u548c Flux \u4e0a\u5c55\u793a\u4e86\u6587\u672c\u6e32\u67d3\u51c6\u786e\u5ea6\u63d0\u9ad8\u4e86 32.3% \u548c 35.9%\uff0c\u800c\u4e0d\u4f1a\u635f\u5bb3\u6574\u4f53\u56fe\u50cf\u8d28\u91cf\u6216\u589e\u52a0\u63a8\u7406\u6210\u672c\u3002", "author": "Xixi Hu et.al.", "authors": "Xixi Hu, Keyang Xu, Bo Liu, Qiang Liu, Hongliang Fei", "id": "2411.19415v1", "paper_url": "http://arxiv.org/abs/2411.19415v1", "repo": "null"}}