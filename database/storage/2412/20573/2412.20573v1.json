{"2412.20573": {"publish_time": "2024-12-29", "title": "The intrinsic motivation of reinforcement and imitation learning for sequential tasks", "paper_summary": "This work in the field of developmental cognitive robotics aims to devise a\nnew domain bridging between reinforcement learning and imitation learning, with\na model of the intrinsic motivation for learning agents to learn with guidance\nfrom tutors multiple tasks, including sequential tasks. The main contribution\nhas been to propose a common formulation of intrinsic motivation based on\nempirical progress for a learning agent to choose automatically its learning\ncurriculum by actively choosing its learning strategy for simple or sequential\ntasks: which task to learn, between autonomous exploration or imitation\nlearning, between low-level actions or task decomposition, between several\ntutors. The originality is to design a learner that benefits not only passively\nfrom data provided by tutors, but to actively choose when to request tutoring\nand what and whom to ask. The learner is thus more robust to the quality of the\ntutoring and learns faster with fewer demonstrations. We developed the\nframework of socially guided intrinsic motivation with machine learning\nalgorithms to learn multiple tasks by taking advantage of the generalisability\nproperties of human demonstrations in a passive manner or in an active manner\nthrough requests of demonstrations from the best tutor for simple and composing\nsubtasks. The latter relies on a representation of subtask composition proposed\nfor a construction process, which should be refined by representations used for\nobservational processes of analysing human movements and activities of daily\nliving. With the outlook of a language-like communication with the tutor, we\ninvestigated the emergence of a symbolic representation of the continuous\nsensorimotor space and of tasks using intrinsic motivation. We proposed within\nthe reinforcement learning framework, a reward function for interacting with\ntutors for automatic curriculum learning in multi-task learning.", "paper_summary_zh": "<paragraph>\u9019\u9805\u5728\u767c\u5c55\u8a8d\u77e5\u6a5f\u5668\u4eba\u5b78\u9818\u57df\u4e2d\u7684\u7814\u7a76\u65e8\u5728\u8a2d\u8a08\u4e00\u500b\u65b0\u7684\u9818\u57df\uff0c\u5728\u5f37\u5316\u5b78\u7fd2\u548c\u6a21\u4eff\u5b78\u7fd2\u4e4b\u9593\u67b6\u8d77\u6a4b\u6a11\uff0c\u4e26\u4f7f\u7528\u4e00\u500b\u5167\u5728\u52d5\u6a5f\u6a21\u578b\uff0c\u8b93\u5b78\u7fd2\u4ee3\u7406\u4eba\u5f9e\u591a\u4f4d\u5c0e\u5e2b\u7684\u6307\u5c0e\u4e2d\u5b78\u7fd2\u591a\u9805\u4efb\u52d9\uff0c\u5305\u62ec\u9806\u5e8f\u4efb\u52d9\u3002\u4e3b\u8981\u8ca2\u737b\u5728\u65bc\u63d0\u51fa\u4e00\u500b\u57fa\u65bc\u7d93\u9a57\u9032\u5c55\u7684\u5167\u5728\u52d5\u6a5f\u5171\u901a\u7528\u5f0f\uff0c\u8b93\u5b78\u7fd2\u4ee3\u7406\u4eba\u80fd\u5920\u81ea\u52d5\u9078\u64c7\u5176\u5b78\u7fd2\u8ab2\u7a0b\uff0c\u4e26\u7a4d\u6975\u9078\u64c7\u5176\u5728\u7c21\u55ae\u6216\u9806\u5e8f\u4efb\u52d9\u4e2d\u7684\u5b78\u7fd2\u7b56\u7565\uff1a\u5728\u81ea\u4e3b\u63a2\u7d22\u6216\u6a21\u4eff\u5b78\u7fd2\u3001\u5728\u4f4e\u5c64\u7d1a\u52d5\u4f5c\u6216\u4efb\u52d9\u5206\u89e3\u3001\u5728\u591a\u4f4d\u5c0e\u5e2b\u4e4b\u9593\u9078\u64c7\u8981\u5b78\u7fd2\u7684\u4efb\u52d9\u3002\u5176\u7368\u5275\u6027\u5728\u65bc\u8a2d\u8a08\u4e00\u500b\u5b78\u7fd2\u8005\uff0c\u4e0d\u50c5\u80fd\u88ab\u52d5\u5730\u5f9e\u5c0e\u5e2b\u63d0\u4f9b\u7684\u8cc7\u6599\u4e2d\u53d7\u76ca\uff0c\u9084\u80fd\u4e3b\u52d5\u9078\u64c7\u4f55\u6642\u8acb\u6c42\u6307\u5c0e\uff0c\u4ee5\u53ca\u5411\u8ab0\u8a62\u554f\u4ec0\u9ebc\u3002\u56e0\u6b64\uff0c\u5b78\u7fd2\u8005\u5c0d\u6307\u5c0e\u54c1\u8cea\u7684\u8010\u53d7\u6027\u66f4\u9ad8\uff0c\u4e26\u80fd\u4ee5\u66f4\u5c11\u7684\u793a\u7bc4\u66f4\u5feb\u5730\u5b78\u7fd2\u3002\u6211\u5011\u958b\u767c\u4e86\u793e\u6703\u5f15\u5c0e\u5167\u5728\u52d5\u6a5f\u67b6\u69cb\uff0c\u4f7f\u7528\u6a5f\u5668\u5b78\u7fd2\u6f14\u7b97\u6cd5\u5b78\u7fd2\u591a\u9805\u4efb\u52d9\uff0c\u4e26\u5229\u7528\u4eba\u985e\u793a\u7bc4\u5728\u88ab\u52d5\u6216\u4e3b\u52d5\u65b9\u5f0f\u4e2d\u7684\u6982\u62ec\u6027\uff0c\u900f\u904e\u5411\u6700\u9069\u5408\u7684\u5c0e\u5e2b\u8acb\u6c42\u793a\u7bc4\u4f86\u5b78\u7fd2\u7c21\u55ae\u548c\u7d44\u6210\u5b50\u4efb\u52d9\u3002\u5f8c\u8005\u4f9d\u8cf4\u65bc\u70ba\u5efa\u69cb\u904e\u7a0b\u63d0\u51fa\u7684\u5b50\u4efb\u52d9\u7d44\u6210\u8868\u793a\uff0c\u8a72\u8868\u793a\u61c9\u900f\u904e\u7528\u65bc\u5206\u6790\u4eba\u985e\u52d5\u4f5c\u548c\u65e5\u5e38\u751f\u6d3b\u6d3b\u52d5\u7684\u89c0\u5bdf\u904e\u7a0b\u7684\u8868\u793a\u9032\u884c\u7cbe\u7149\u3002\u6211\u5011\u4ee5\u8207\u5c0e\u5e2b\u9032\u884c\u8a9e\u8a00\u5f0f\u6e9d\u901a\u7684\u89c0\u9ede\uff0c\u63a2\u8a0e\u4e86\u9023\u7e8c\u611f\u5b98\u904b\u52d5\u7a7a\u9593\u548c\u4efb\u52d9\u7684\u7b26\u865f\u8868\u793a\u5728\u5167\u5728\u52d5\u6a5f\u4e2d\u7684\u51fa\u73fe\u3002\u6211\u5011\u5728\u5f37\u5316\u5b78\u7fd2\u67b6\u69cb\u4e2d\u63d0\u51fa\u4e86\u4e00\u500b\u734e\u52f5\u51fd\u6578\uff0c\u7528\u65bc\u8207\u5c0e\u5e2b\u4e92\u52d5\uff0c\u4ee5\u5728\u591a\u4efb\u52d9\u5b78\u7fd2\u4e2d\u9032\u884c\u81ea\u52d5\u8ab2\u7a0b\u5b78\u7fd2\u3002</paragraph>", "author": "Sao Mai Nguyen et.al.", "authors": "Sao Mai Nguyen", "id": "2412.20573v1", "paper_url": "http://arxiv.org/abs/2412.20573v1", "repo": "null"}}