{"2412.11605": {"publish_time": "2024-12-16", "title": "SPaR: Self-Play with Tree-Search Refinement to Improve Instruction-Following in Large Language Models", "paper_summary": "Instruction-following is a fundamental capability of language models,\nrequiring the model to recognize even the most subtle requirements in the\ninstructions and accurately reflect them in its output. Such an ability is\nwell-suited for and often optimized by preference learning. However, existing\nmethods often directly sample multiple independent responses from the model\nwhen creating preference pairs. Such practice can introduce content variations\nirrelevant to whether the instruction is precisely followed (e.g., different\nexpressions about the same semantic), interfering with the goal of teaching\nmodels to recognize the key differences that lead to improved instruction\nfollowing. In light of this, we introduce SPaR, a self-play framework\nintegrating tree-search self-refinement to yield valid and comparable\npreference pairs free from distractions. By playing against itself, an LLM\nemploys a tree-search strategy to refine its previous responses with respect to\nthe instruction while minimizing unnecessary variations. Our experiments show\nthat a LLaMA3-8B model, trained over three iterations guided by SPaR, surpasses\nGPT-4-Turbo on the IFEval benchmark without losing general capabilities.\nFurthermore, SPaR demonstrates promising scalability and transferability,\ngreatly enhancing models like GLM-4-9B and LLaMA3-70B. We also identify how\ninference scaling in tree search would impact model performance. Our code and\ndata are publicly available at https://github.com/thu-coai/SPaR.", "paper_summary_zh": "\u6307\u4ee4\u9075\u5faa\u662f\u8bed\u8a00\u6a21\u578b\u7684\u4e00\u9879\u57fa\u672c\u80fd\u529b\uff0c\u8981\u6c42\u6a21\u578b\u8bc6\u522b\u6307\u4ee4\u4e2d\u5373\u4f7f\u662f\u6700\u7ec6\u5fae\u7684\u8981\u6c42\uff0c\u5e76\u5728\u5176\u8f93\u51fa\u4e2d\u51c6\u786e\u53cd\u6620\u8fd9\u4e9b\u8981\u6c42\u3002\u8fd9\u79cd\u80fd\u529b\u975e\u5e38\u9002\u5408\u4e8e\u504f\u597d\u5b66\u4e60\uff0c\u5e76\u4e14\u901a\u5e38\u901a\u8fc7\u504f\u597d\u5b66\u4e60\u8fdb\u884c\u4f18\u5316\u3002\u7136\u800c\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u521b\u5efa\u504f\u597d\u5bf9\u65f6\uff0c\u901a\u5e38\u76f4\u63a5\u4ece\u6a21\u578b\u4e2d\u91c7\u6837\u591a\u4e2a\u72ec\u7acb\u7684\u54cd\u5e94\u3002\u8fd9\u79cd\u505a\u6cd5\u53ef\u80fd\u4f1a\u5f15\u5165\u4e0e\u6307\u4ee4\u662f\u5426\u88ab\u7cbe\u786e\u9075\u5faa\u65e0\u5173\u7684\u5185\u5bb9\u53d8\u5316\uff08\u4f8b\u5982\uff0c\u5173\u4e8e\u76f8\u540c\u8bed\u4e49\u7684\u4e0d\u540c\u8868\u8fbe\uff09\uff0c\u4ece\u800c\u5e72\u6270\u6559\u5bfc\u6a21\u578b\u8bc6\u522b\u5bfc\u81f4\u6539\u8fdb\u6307\u4ee4\u9075\u5faa\u7684\u5173\u952e\u5dee\u5f02\u7684\u76ee\u6807\u3002\u6709\u9274\u4e8e\u6b64\uff0c\u6211\u4eec\u5f15\u5165\u4e86 SPaR\uff0c\u4e00\u4e2a\u81ea\u73a9\u6846\u67b6\uff0c\u96c6\u6210\u4e86\u6811\u641c\u7d22\u81ea\u4f18\u5316\uff0c\u4ee5\u4ea7\u751f\u6709\u6548\u4e14\u53ef\u6bd4\u8f83\u7684\u504f\u597d\u5bf9\uff0c\u4e0d\u53d7\u5e72\u6270\u3002\u901a\u8fc7\u4e0e\u81ea\u5df1\u5bf9\u6218\uff0cLLM \u91c7\u7528\u6811\u641c\u7d22\u7b56\u7565\uff0c\u9488\u5bf9\u6307\u4ee4\u4f18\u5316\u5176\u5148\u524d\u7684\u54cd\u5e94\uff0c\u540c\u65f6\u6700\u5927\u7a0b\u5ea6\u5730\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u53d8\u5316\u3002\u6211\u4eec\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5728 SPaR \u6307\u5bfc\u4e0b\u7ecf\u8fc7\u4e09\u8f6e\u8fed\u4ee3\u8bad\u7ec3\u7684 LLaMA3-8B \u6a21\u578b\u5728 IFEval \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4e86 GPT-4-Turbo\uff0c\u800c\u6ca1\u6709\u4e27\u5931\u4e00\u822c\u80fd\u529b\u3002\u6b64\u5916\uff0cSPaR \u5c55\u793a\u4e86\u6709\u5e0c\u671b\u7684\u53ef\u6269\u5c55\u6027\u548c\u53ef\u8fc1\u79fb\u6027\uff0c\u6781\u5927\u5730\u589e\u5f3a\u4e86 GLM-4-9B \u548c LLaMA3-70B \u7b49\u6a21\u578b\u3002\u6211\u4eec\u8fd8\u786e\u5b9a\u4e86\u6811\u641c\u7d22\u4e2d\u7684\u63a8\u7406\u7f29\u653e\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3002\u6211\u4eec\u7684\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5728 https://github.com/thu-coai/SPaR \u4e0a\u516c\u5f00\u3002", "author": "Jiale Cheng et.al.", "authors": "Jiale Cheng, Xiao Liu, Cunxiang Wang, Xiaotao Gu, Yida Lu, Dan Zhang, Yuxiao Dong, Jie Tang, Hongning Wang, Minlie Huang", "id": "2412.11605v1", "paper_url": "http://arxiv.org/abs/2412.11605v1", "repo": "https://github.com/thu-coai/spar"}}