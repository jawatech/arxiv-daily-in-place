{"2411.10083": {"publish_time": "2024-11-15", "title": "Xmodel-1.5: An 1B-scale Multilingual LLM", "paper_summary": "We introduce Xmodel-1.5, a novel 1-billion-parameter multilingual large model\npretrained on approximately 2 trillion tokens. The model demonstrates strong\nperformance across several languages, with particularly notable results in\nThai, Arabic, and French, alongside its effectiveness in Chinese and English.\nIn addition, we contribute to the research community by releasing a Thai\nevaluation dataset, which includes hundreds of questions annotated by students\nfrom Chulalongkorn University's School of Integrated Innovation. While the\nresults are promising, we acknowledge that there is still room for improvement.\nWe hope this work advances ongoing efforts in multilingual AI research and\npromotes better cross-linguistic understanding in various natural language\nprocessing tasks. Our models and code are publicly available on GitHub at\nhttps://github.com/XiaoduoAILab/XmodelLM.", "paper_summary_zh": "\u6211\u5011\u63a8\u51fa Xmodel-1.5\uff0c\u4e00\u500b\u65b0\u7a4e\u7684 10 \u5104\u53c3\u6578\u591a\u8a9e\u8a00\u5927\u578b\u6a21\u578b\uff0c\u9810\u8a13\u7df4\u7d04 2 \u5146\u500b\u7b26\u865f\u3002\u8a72\u6a21\u578b\u5728\u591a\u7a2e\u8a9e\u8a00\u4e2d\u5c55\u73fe\u5f37\u52c1\u7684\u6548\u80fd\uff0c\u5728\u6cf0\u8a9e\u3001\u963f\u62c9\u4f2f\u8a9e\u548c\u6cd5\u8a9e\u4e2d\u6709\u7279\u5225\u986f\u8457\u7684\u7d50\u679c\uff0c\u540c\u6642\u5728\u4e2d\u6587\u548c\u82f1\u6587\u65b9\u9762\u4e5f\u5341\u5206\u6709\u6548\u3002\u6b64\u5916\uff0c\u6211\u5011\u900f\u904e\u91cb\u51fa\u6cf0\u8a9e\u8a55\u4f30\u8cc7\u6599\u96c6\u4f86\u70ba\u7814\u7a76\u793e\u7fa4\u505a\u51fa\u8ca2\u737b\uff0c\u5176\u4e2d\u5305\u542b\u6578\u767e\u500b\u7531\u6731\u62c9\u9686\u529f\u5927\u5b78\u7d9c\u5408\u5275\u65b0\u5b78\u9662\u5b78\u751f\u8a3b\u89e3\u7684\u554f\u984c\u3002\u5118\u7ba1\u7d50\u679c\u4ee4\u4eba\u632f\u596e\uff0c\u6211\u5011\u627f\u8a8d\u4ecd\u6709\u9032\u6b65\u7a7a\u9593\u3002\u6211\u5011\u5e0c\u671b\u9019\u9805\u5de5\u4f5c\u80fd\u4fc3\u9032\u591a\u8a9e\u8a00 AI \u7814\u7a76\u7684\u6301\u7e8c\u52aa\u529b\uff0c\u4e26\u5728\u5404\u7a2e\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4efb\u52d9\u4e2d\u4fc3\u9032\u66f4\u597d\u7684\u8de8\u8a9e\u8a00\u7406\u89e3\u3002\u6211\u5011\u7684\u6a21\u578b\u548c\u7a0b\u5f0f\u78bc\u5df2\u516c\u958b\u767c\u5e03\u5728 GitHub \u4e0a\uff0c\u7db2\u5740\u70ba https://github.com/XiaoduoAILab/XmodelLM\u3002", "author": "Wang Qun et.al.", "authors": "Wang Qun, Liu Yang, Lin Qingquan, Jiang Ling", "id": "2411.10083v1", "paper_url": "http://arxiv.org/abs/2411.10083v1", "repo": "https://github.com/xiaoduoailab/xmodellm"}}