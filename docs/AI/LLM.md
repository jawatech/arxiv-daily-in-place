
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-01**|**MM-Vet v2: A Challenging Benchmark to Evaluate Large Multimodal Models for Integrated Capabilities**|Weihao Yu et.al.|[2408.00765v1](http://arxiv.org/abs/2408.00765v1)|null|
|**2024-08-01**|**AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation**|Mengkang Hu et.al.|[2408.00764v1](http://arxiv.org/abs/2408.00764v1)|null|
|**2024-08-01**|**Tamper-Resistant Safeguards for Open-Weight LLMs**|Rishub Tamirisa et.al.|[2408.00761v1](http://arxiv.org/abs/2408.00761v1)|null|
|**2024-08-01**|**Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention**|Susung Hong et.al.|[2408.00760v1](http://arxiv.org/abs/2408.00760v1)|null|
|**2024-08-01**|**Segment anything model 2: an application to 2D and 3D medical images**|Haoyu Dong et.al.|[2408.00756v1](http://arxiv.org/abs/2408.00756v1)|null|
|**2024-08-01**|**DynamoLLM: Designing LLM Inference Clusters for Performance and Energy Efficiency**|Jovan Stojkovic et.al.|[2408.00741v1](http://arxiv.org/abs/2408.00741v1)|null|
|**2024-08-01**|**CERT-ED: Certifiably Robust Text Classification for Edit Distance**|Zhuoqun Huang et.al.|[2408.00728v1](http://arxiv.org/abs/2408.00728v1)|null|
|**2024-08-01**|**Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions**|Guangzhi Xiong et.al.|[2408.00727v1](http://arxiv.org/abs/2408.00727v1)|null|
|**2024-08-01**|**An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models**|Yangzhen Wu et.al.|[2408.00724v1](http://arxiv.org/abs/2408.00724v1)|null|
|**2024-08-01**|**Pathway to Secure and Trustworthy 6G for LLMs: Attacks, Defense, and Opportunities**|Sunder Ali Khowaja et.al.|[2408.00722v1](http://arxiv.org/abs/2408.00722v1)|null|
|**2024-08-01**|**SAM 2: Segment Anything in Images and Videos**|Nikhila Ravi et.al.|[2408.00714v1](http://arxiv.org/abs/2408.00714v1)|null|
|**2024-08-01**|**Investigating Brain Connectivity and Regional Statistics from EEG for early stage Parkinson's Classification**|Amarpal Sahota et.al.|[2408.00711v1](http://arxiv.org/abs/2408.00711v1)|null|
|**2024-08-01**|**Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM**|Xiaofeng Liu et.al.|[2408.00706v1](http://arxiv.org/abs/2408.00706v1)|null|
|**2024-08-01**|**Future of Artificial Intelligence in Agile Software Development**|Mariyam Mahboob et.al.|[2408.00703v1](http://arxiv.org/abs/2408.00703v1)|null|
|**2024-08-01**|**Improving Text Embeddings for Smaller Language Models Using Contrastive Fine-tuning**|Trapoom Ukarapol et.al.|[2408.00690v1](http://arxiv.org/abs/2408.00690v1)|null|
|**2024-08-01**|**Can Developers Prompt? A Controlled Experiment for Code Documentation Generation**|Hans-Alexander Kruse et.al.|[2408.00686v1](http://arxiv.org/abs/2408.00686v1)|null|
|**2024-08-01**|**Assessing the Variety of a Concept Space Using an Unbiased Estimate of Rao's Quadratic Index**|Anubhab Majumder et.al.|[2408.00684v1](http://arxiv.org/abs/2408.00684v1)|null|
|**2024-08-01**|**Learning in Multi-Objective Public Goods Games with Non-Linear Utilities**|Nicole Orzan et.al.|[2408.00682v1](http://arxiv.org/abs/2408.00682v1)|null|
|**2024-08-01**|**Leveraging Entailment Judgements in Cross-Lingual Summarisation**|Huajian Zhang et.al.|[2408.00675v1](http://arxiv.org/abs/2408.00675v1)|null|
|**2024-08-01**|**SentenceVAE: Faster, Longer and More Accurate Inference with Next-sentence Prediction for Large Language Models**|Hongjun An et.al.|[2408.00655v1](http://arxiv.org/abs/2408.00655v1)|null|
|**2024-08-01**|**AMAES: Augmented Masked Autoencoder Pretraining on Public Brain MRI Data for 3D-Native Segmentation**|Asbjørn Munk et.al.|[2408.00640v1](http://arxiv.org/abs/2408.00640v1)|null|
|**2024-08-01**|**DisTrack: a new Tool for Semi-automatic Misinformation Tracking in Online Social Networks**|Guillermo Villar-Rodríguez et.al.|[2408.00633v1](http://arxiv.org/abs/2408.00633v1)|null|
|**2024-08-01**|**SynesLM: A Unified Approach for Audio-visual Speech Recognition and Translation via Language Model and Synthetic Data**|Yichen Lu et.al.|[2408.00624v1](http://arxiv.org/abs/2408.00624v1)|null|
|**2024-08-01**|**Are Bigger Encoders Always Better in Vision Large Models?**|Bozhou Li et.al.|[2408.00620v1](http://arxiv.org/abs/2408.00620v1)|null|
|**2024-08-01**|**Unlocking Fair Use in the Generative AI Supply Chain: A Systematized Literature Review**|Amruta Mahuli et.al.|[2408.00613v1](http://arxiv.org/abs/2408.00613v1)|null|
|**2024-08-01**|**Downstream bias mitigation is all you need**|Arkadeep Baksi et.al.|[2408.00612v1](http://arxiv.org/abs/2408.00612v1)|null|
|**2024-08-01**|**Non Verbis, Sed Rebus: Large Language Models are Weak Solvers of Italian Rebuses**|Gabriele Sarti et.al.|[2408.00584v1](http://arxiv.org/abs/2408.00584v1)|null|
|**2024-08-01**|**Alleviating Hallucination in Large Vision-Language Models with Active Retrieval Augmentation**|Xiaoye Qu et.al.|[2408.00555v1](http://arxiv.org/abs/2408.00555v1)|null|
|**2024-08-01**|**Mitigating Multilingual Hallucination in Large Vision-Language Models**|Xiaoye Qu et.al.|[2408.00550v1](http://arxiv.org/abs/2408.00550v1)|null|
|**2024-08-01**|**Illustrating Classic Brazilian Books using a Text-To-Image Diffusion Model**|Felipe Mahlow et.al.|[2408.00544v1](http://arxiv.org/abs/2408.00544v1)|null|
|**2024-08-01**|**The Energy Cost of Artificial Intelligence of Things Lifecycle**|Shih-Kai Chou et.al.|[2408.00540v1](http://arxiv.org/abs/2408.00540v1)|null|
|**2024-08-01**|**Intermittent Semi-working Mask: A New Masking Paradigm for LLMs**|Mingcong Lu et.al.|[2408.00539v1](http://arxiv.org/abs/2408.00539v1)|null|
|**2024-08-01**|**The Monetisation of Toxicity: Analysing YouTube Content Creators and Controversy-Driven Engagement**|Thales Bertaglia et.al.|[2408.00534v1](http://arxiv.org/abs/2408.00534v1)|null|
|**2024-08-01**|**Jailbreaking Text-to-Image Models with LLM-Based Agents**|Yingkai Dong et.al.|[2408.00523v1](http://arxiv.org/abs/2408.00523v1)|null|
|**2024-08-01**|**A new approach for encoding code and assisting code understanding**|Mengdan Fan et.al.|[2408.00521v1](http://arxiv.org/abs/2408.00521v1)|null|
|**2024-08-01**|**GalleryGPT: Analyzing Paintings with Large Multimodal Models**|Yi Bin et.al.|[2408.00491v1](http://arxiv.org/abs/2408.00491v1)|null|
|**2024-08-01**|**Graph Representation Learning via Causal Diffusion for Out-of-Distribution Recommendation**|Chu Zhao et.al.|[2408.00490v1](http://arxiv.org/abs/2408.00490v1)|null|
|**2024-08-01**|**A Systematic Review on Long-Tailed Learning**|Chongsheng Zhang et.al.|[2408.00483v1](http://arxiv.org/abs/2408.00483v1)|null|
|**2024-08-01**|**HBot: A Chatbot for Healthcare Applications in Traditional Chinese Medicine Based on Human Body 3D Visualization**|Bolin Zhang et.al.|[2408.00481v1](http://arxiv.org/abs/2408.00481v1)|null|
|**2024-08-01**|**Towards Explainable and Interpretable Musical Difficulty Estimation: A Parameter-efficient Approach**|Pedro Ramoneda et.al.|[2408.00473v1](http://arxiv.org/abs/2408.00473v1)|null|
|**2024-08-01**|**DiscipLink: Unfolding Interdisciplinary Information Seeking Process via Human-AI Co-Exploration**|Chengbo Zheng et.al.|[2408.00447v1](http://arxiv.org/abs/2408.00447v1)|null|
|**2024-08-01**|**Ontological Relations from Word Embeddings**|Mathieu d'Aquin et.al.|[2408.00444v1](http://arxiv.org/abs/2408.00444v1)|null|
|**2024-08-01**|**Focus, Distinguish, and Prompt: Unleashing CLIP for Efficient and Flexible Scene Text Retrieval**|Gangyan Zeng et.al.|[2408.00441v1](http://arxiv.org/abs/2408.00441v1)|null|
|**2024-08-01**|**A Qualitative Study on Using ChatGPT for Software Security: Perception vs. Practicality**|M. Mehdi Kholoosi et.al.|[2408.00435v1](http://arxiv.org/abs/2408.00435v1)|null|
|**2024-08-01**|**CARMIL: Context-Aware Regularization on Multiple Instance Learning models for Whole Slide Images**|Thiziri Nait Saada et.al.|[2408.00427v1](http://arxiv.org/abs/2408.00427v1)|null|
|**2024-08-01**|**MPT-PAR:Mix-Parameters Transformer for Panoramic Activity Recognition**|Wenqing Gan et.al.|[2408.00420v1](http://arxiv.org/abs/2408.00420v1)|null|
|**2024-08-01**|**DriveArena: A Closed-loop Generative Simulation Platform for Autonomous Driving**|Xuemeng Yang et.al.|[2408.00415v1](http://arxiv.org/abs/2408.00415v1)|null|
|**2024-08-01**|**In-Context Example Selection via Similarity Search Improves Low-Resource Machine Translation**|Armel Zebaze et.al.|[2408.00397v1](http://arxiv.org/abs/2408.00397v1)|null|
|**2024-08-01**|**Enhancing Whole Slide Pathology Foundation Models through Stain Normalization**|Juseung Yun et.al.|[2408.00380v1](http://arxiv.org/abs/2408.00380v1)|null|
|**2024-08-01**|**On the Limitations and Prospects of Machine Unlearning for Generative AI**|Shiji Zhou et.al.|[2408.00376v1](http://arxiv.org/abs/2408.00376v1)|null|
|**2024-08-01**|**Conformal Trajectory Prediction with Multi-View Data Integration in Cooperative Driving**|Xi Chen et.al.|[2408.00374v1](http://arxiv.org/abs/2408.00374v1)|null|
|**2024-08-01**|**DiM-Gesture: Co-Speech Gesture Generation with Adaptive Layer Normalization Mamba-2 framework**|Fan Zhang et.al.|[2408.00370v1](http://arxiv.org/abs/2408.00370v1)|null|
|**2024-08-01**|**Multimodal Fusion and Coherence Modeling for Video Topic Segmentation**|Hai Yu et.al.|[2408.00365v1](http://arxiv.org/abs/2408.00365v1)|null|
|**2024-08-01**|**DeliLaw: A Chinese Legal Counselling System Based on a Large Language Model**|Nan Xie et.al.|[2408.00357v1](http://arxiv.org/abs/2408.00357v1)|null|
|**2024-08-01**|**DNTextSpotter: Arbitrary-Shaped Scene Text Spotting via Improved Denoising Training**|Yu Xie et.al.|[2408.00355v1](http://arxiv.org/abs/2408.00355v1)|null|
|**2024-08-01**|**A Simple Background Augmentation Method for Object Detection with Diffusion Model**|Yuhang Li et.al.|[2408.00350v1](http://arxiv.org/abs/2408.00350v1)|null|
|**2024-08-01**|**Advancing Medical Image Segmentation: Morphology-Driven Learning with Diffusion Transformer**|Sungmin Kang et.al.|[2408.00347v1](http://arxiv.org/abs/2408.00347v1)|null|
|**2024-08-01**|**Neural Graph Matching for Video Retrieval in Large-Scale Video-driven E-commerce**|Houye Ji et.al.|[2408.00346v1](http://arxiv.org/abs/2408.00346v1)|null|
|**2024-08-01**|**OTAD: An Optimal Transport-Induced Robust Model for Agnostic Adversarial Attack**|Kuo Gai et.al.|[2408.00329v1](http://arxiv.org/abs/2408.00329v1)|null|
|**2024-08-01**|**ADBM: Adversarial diffusion bridge model for reliable adversarial purification**|Xiao Li et.al.|[2408.00315v1](http://arxiv.org/abs/2408.00315v1)|null|
|**2024-08-01**|**ABC Align: Large Language Model Alignment for Safety & Accuracy**|Gareth Seneque et.al.|[2408.00307v1](http://arxiv.org/abs/2408.00307v1)|null|
|**2024-08-01**|**Contrastive Graph Representation Learning with Adversarial Cross-view Reconstruction and Information Bottleneck**|Yuntao Shou et.al.|[2408.00295v1](http://arxiv.org/abs/2408.00295v1)|null|
|**2024-08-01**|**Multi-Modal Parameter-Efficient Fine-tuning via Graph Neural Network**|Bin Cheng et.al.|[2408.00290v1](http://arxiv.org/abs/2408.00290v1)|null|
|**2024-08-01**|**Gradient Harmonization in Unsupervised Domain Adaptation**|Fuxiang Huang et.al.|[2408.00288v1](http://arxiv.org/abs/2408.00288v1)|null|
|**2024-08-01**|**Bailing-TTS: Chinese Dialectal Speech Synthesis Towards Human-like Spontaneous Representation**|Xinhan Di et.al.|[2408.00284v1](http://arxiv.org/abs/2408.00284v1)|null|
|**2024-08-01**|**Navigating Text-to-Image Generative Bias across Indic Languages**|Surbhi Mittal et.al.|[2408.00283v1](http://arxiv.org/abs/2408.00283v1)|null|
|**2024-08-01**|**QUITO: Accelerating Long-Context Reasoning through Query-Guided Context Compression**|Wenshan Wang et.al.|[2408.00274v1](http://arxiv.org/abs/2408.00274v1)|null|
|**2024-08-01**|**Clover-2: Accurate Inference for Regressive Lightweight Speculative Decoding**|Bin Xiao et.al.|[2408.00264v1](http://arxiv.org/abs/2408.00264v1)|null|
|**2024-08-01**|**RoCo:Robust Collaborative Perception By Iterative Object Matching and Pose Adjustment**|Zhe Huang et.al.|[2408.00257v1](http://arxiv.org/abs/2408.00257v1)|null|
|**2024-08-01**|**Enhanced Structured State Space Models via Grouped FIR Filtering and Attention Sink Mechanisms**|Tian Meng et.al.|[2408.00244v1](http://arxiv.org/abs/2408.00244v1)|null|
|**2024-08-01**|**Lost in Translation: Latent Concept Misalignment in Text-to-Image Diffusion Models**|Juntu Zhao et.al.|[2408.00230v1](http://arxiv.org/abs/2408.00230v1)|null|
|**2024-08-01**|**Sentence-wise Speech Summarization: Task, Datasets, and End-to-End Modeling with LM Knowledge Distillation**|Kohei Matsuura et.al.|[2408.00205v1](http://arxiv.org/abs/2408.00205v1)|null|
|**2024-08-01**|**OmniParser for Pure Vision Based GUI Agent**|Yadong Lu et.al.|[2408.00203v1](http://arxiv.org/abs/2408.00203v1)|null|
|**2024-07-31**|**Automated Software Vulnerability Static Code Analysis Using Generative Pre-Trained Transformer Models**|Elijah Pelofske et.al.|[2408.00197v1](http://arxiv.org/abs/2408.00197v1)|null|
|**2024-07-31**|**S-SYNTH: Knowledge-Based, Synthetic Generation of Skin Images**|Andrea Kim et.al.|[2408.00191v1](http://arxiv.org/abs/2408.00191v1)|null|
|**2024-07-31**|**Finch: Prompt-guided Key-Value Cache Compression**|Giulio Corallo et.al.|[2408.00167v1](http://arxiv.org/abs/2408.00167v1)|null|
|**2024-07-31**|**A Taxonomy of Stereotype Content in Large Language Models**|Gandalf Nicolas et.al.|[2408.00162v1](http://arxiv.org/abs/2408.00162v1)|null|
|**2024-07-31**|**Automatic Generation of Behavioral Test Cases For Natural Language Processing Using Clustering and Prompting**|Ying Li et.al.|[2408.00161v1](http://arxiv.org/abs/2408.00161v1)|null|
|**2024-07-31**|**StyleRF-VolVis: Style Transfer of Neural Radiance Fields for Expressive Volume Visualization**|Kaiyuan Tang et.al.|[2408.00150v1](http://arxiv.org/abs/2408.00150v1)|null|
|**2024-07-31**|**Formal Ethical Obligations in Reinforcement Learning Agents: Verification and Policy Updates**|Colin Shea-Blymyer et.al.|[2408.00147v1](http://arxiv.org/abs/2408.00147v1)|null|
|**2024-07-31**|**Distributed In-Context Learning under Non-IID Among Clients**|Siqi Liang et.al.|[2408.00144v1](http://arxiv.org/abs/2408.00144v1)|null|
|**2024-07-31**|**Correcting Negative Bias in Large Language Models through Negative Attention Score Alignment**|Sangwon Yu et.al.|[2408.00137v1](http://arxiv.org/abs/2408.00137v1)|null|
|**2024-07-31**|**Distributionally Robust Optimization as a Scalable Framework to Characterize Extreme Value Distributions**|Patrick Kuiper et.al.|[2408.00131v1](http://arxiv.org/abs/2408.00131v1)|null|
|**2024-07-31**|**Semantic Codebook Learning for Dynamic Recommendation Models**|Zheqi Lv et.al.|[2408.00123v1](http://arxiv.org/abs/2408.00123v1)|null|
|**2024-07-31**|**A Course Shared Task on Evaluating LLM Output for Clinical Questions**|Yufang Hou et.al.|[2408.00122v1](http://arxiv.org/abs/2408.00122v1)|null|
|**2024-07-31**|**Gemma 2: Improving Open Language Models at a Practical Size**|Gemma Team et.al.|[2408.00118v1](http://arxiv.org/abs/2408.00118v1)|null|
|**2024-07-31**|**Inductive or Deductive? Rethinking the Fundamental Reasoning Abilities of LLMs**|Kewei Cheng et.al.|[2408.00114v1](http://arxiv.org/abs/2408.00114v1)|null|
|**2024-07-31**|**Measuring Progress in Dictionary Learning for Language Model Interpretability with Board Game Models**|Adam Karvonen et.al.|[2408.00113v1](http://arxiv.org/abs/2408.00113v1)|null|
|**2024-07-31**|**Preference-Based Abstract Argumentation for Case-Based Reasoning (with-Appendix)**|Adam Gould et.al.|[2408.00108v1](http://arxiv.org/abs/2408.00108v1)|null|
|**2024-07-31**|**WAS: Dataset and Methods for Artistic Text Segmentation**|Xudong Xie et.al.|[2408.00106v1](http://arxiv.org/abs/2408.00106v1)|null|
|**2024-07-31**|**ReLiK: Retrieve and LinK, Fast and Accurate Entity Linking and Relation Extraction on an Academic Budget**|Riccardo Orlando et.al.|[2408.00103v1](http://arxiv.org/abs/2408.00103v1)|null|
|**2024-07-31**|**From Attributes to Natural Language: A Survey and Foresight on Text-based Person Re-identification**|Fanzhi Jiang et.al.|[2408.00096v1](http://arxiv.org/abs/2408.00096v1)|null|
|**2024-07-31**|**Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey**|Atsuyuki Miyai et.al.|[2407.21794v1](http://arxiv.org/abs/2407.21794v1)|null|
|**2024-07-31**|**Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress?**|Richard Ren et.al.|[2407.21792v1](http://arxiv.org/abs/2407.21792v1)|null|
|**2024-07-31**|**Vision-Language Model Based Handwriting Verification**|Mihir Chauhan et.al.|[2407.21788v1](http://arxiv.org/abs/2407.21788v1)|null|
|**2024-07-31**|**Large Language Monkeys: Scaling Inference Compute with Repeated Sampling**|Bradley Brown et.al.|[2407.21787v1](http://arxiv.org/abs/2407.21787v1)|null|
|**2024-07-31**|**The Llama 3 Herd of Models**|Abhimanyu Dubey et.al.|[2407.21783v1](http://arxiv.org/abs/2407.21783v1)|null|
|**2024-07-31**|**Tulip Agent -- Enabling LLM-Based Agents to Solve Tasks Using Large Tool Libraries**|Felix Ocker et.al.|[2407.21778v1](http://arxiv.org/abs/2407.21778v1)|null|
|**2024-07-31**|**ShieldGemma: Generative AI Content Moderation Based on Gemma**|Wenjun Zeng et.al.|[2407.21772v1](http://arxiv.org/abs/2407.21772v1)|null|
|**2024-07-31**|**MoMa: Efficient Early-Fusion Pre-training with Mixture of Modality-Aware Experts**|Xi Victoria Lin et.al.|[2407.21770v1](http://arxiv.org/abs/2407.21770v1)|null|

#### Abstracts
##### **MM-Vet v2: A Challenging Benchmark to Evaluate Large Multimodal Models for Integrated Capabilities**
2408.00765v1 by Weihao Yu, Zhengyuan Yang, Linfeng Ren, Linjie Li, Jianfeng Wang, Kevin Lin, Chung-Ching Lin, Zicheng Liu, Lijuan Wang, Xinchao Wang

MM-Vet, with open-ended vision-language questions targeting at evaluating
integrated capabilities, has become one of the most popular benchmarks for
large multimodal model evaluation. MM-Vet assesses six core vision-language
(VL) capabilities: recognition, knowledge, spatial awareness, language
generation, OCR, and math. However, its question format is restricted to single
image-text pairs, lacking the interleaved image and text sequences prevalent in
real-world scenarios. To address this limitation, we introduce MM-Vet v2, which
includes a new VL capability called "image-text sequence understanding",
evaluating models' ability to process VL sequences. Furthermore, we maintain
the high quality of evaluation samples while further expanding the evaluation
set size. Using MM-Vet v2 to benchmark large multimodal models, we found that
Claude 3.5 Sonnet is the best model with a score of 71.8, slightly
outperforming GPT-4o which scored 71.0. Among open-weight models,
InternVL2-Llama3-76B leads with a score of 68.4.

摘要：MM-Vet 透過針對評估整合能力而設計的開放式視覺語言問題，已成為大型多模態模型評估最受歡迎的基準之一。MM-Vet 評估六項核心視覺語言 (VL) 能力：辨識、知識、空間意識、語言生成、OCR 和數學。然而，其問題格式僅限於單一影像文字對，缺乏真實世界場景中普遍存在的交錯影像和文字序列。為了解決此限制，我們引入了 MM-Vet v2，其中包含稱為「影像文字序列理解」的新 VL 能力，用於評估模型處理 VL 序列的能力。此外，我們在進一步擴充評估集大小的同時，維持評估範例的高品質。我們使用 MM-Vet v2 對大型多模態模型進行基準測試，發現 Claude 3.5 Sonnet 是最佳模型，得分為 71.8，略優於 GPT-4o 的 71.0 分。在開放權重模型中，InternVL2-Llama3-76B 以 68.4 分領先。

##### **AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation**
2408.00764v1 by Mengkang Hu, Pu Zhao, Can Xu, Qingfeng Sun, Jianguang Lou, Qingwei Lin, Ping Luo, Saravan Rajmohan, Dongmei Zhang

Large Language Model (LLM) based agents have garnered significant attention
and are becoming increasingly popular. Furthermore, planning ability is a
crucial component of an LLM-based agent, involving interaction with the
environment and executing actions to complete a planning task, which generally
entails achieving a desired goal from an initial state. This paper investigates
enhancing the planning abilities of LLMs through instruction tuning, referred
to as agent training. Recent studies have demonstrated that utilizing
expert-level trajectory for instruction-tuning LLMs effectively enhances their
planning capabilities. However, existing work primarily focuses on synthesizing
trajectories from manually designed planning tasks and environments. The
labor-intensive nature of creating these environments and tasks impedes the
generation of sufficiently varied and extensive trajectories. To address this
limitation, this paper explores the automated synthesis of diverse environments
and a gradual range of planning tasks, from easy to difficult. We introduce a
framework, AgentGen, that leverages LLMs first to generate environments and
subsequently generate planning tasks conditioned on these environments.
Specifically, to improve environmental diversity, we propose using an
inspiration corpus composed of various domain-specific text segments as the
context for synthesizing environments. Moreover, to increase the difficulty
diversity of generated planning tasks, we propose a bidirectional evolution
method, Bi-Evol, that evolves planning tasks from easier and harder directions
to synthesize a task set with a smoother difficulty curve. The evaluation
results derived from AgentBoard show that AgentGen greatly improves LLMs'
planning ability, e.g., the AgentGen instruction-tuned Llama-3 8B surpasses
GPT-3.5 in overall performance. Moreover, in certain tasks, it even outperforms
GPT-4.

摘要：大型語言模型 (LLM) 基於代理已引起廣泛關注，並正變得越來越流行。此外，規劃能力是 LLM 基於代理的重要組成部分，涉及與環境互動並執行動作以完成規劃任務，這通常需要從初始狀態實現預期目標。本文探討了通過指令調整來增強 LLM 的規劃能力，稱為代理訓練。最近的研究表明，利用專家級軌跡進行指令調整 LLM 有效地增強了其規劃能力。然而，現有工作主要集中於從人工設計的規劃任務和環境中合成軌跡。創建這些環境和任務的勞動密集性阻礙了產生足夠多樣化和廣泛的軌跡。為了解決這個限制，本文探討了多樣化環境和從容易到困難的逐步規劃任務的自動合成。我們引入了一個框架 AgentGen，它利用 LLM 首先生成環境，然後根據這些環境生成規劃任務。具體來說，為了提高環境的多樣性，我們建議使用由各種特定領域文本片段組成的靈感語料庫作為合成環境的背景。此外，為了增加生成規劃任務的難度多樣性，我們提出了一種雙向演化方法 Bi-Evol，它從更容易和更困難的方向演化規劃任務，以合成一個具有更平滑難度曲線的任務集。從 AgentBoard 衍生的評估結果表明，AgentGen 大大提高了 LLM 的規劃能力，例如，AgentGen 指令調整的 Llama-3 8B 在整體性能上超過了 GPT-3.5。此外，在某些任務中，它甚至優於 GPT-4。

##### **Tamper-Resistant Safeguards for Open-Weight LLMs**
2408.00761v1 by Rishub Tamirisa, Bhrugu Bharathi, Long Phan, Andy Zhou, Alice Gatti, Tarun Suresh, Maxwell Lin, Justin Wang, Rowan Wang, Ron Arel, Andy Zou, Dawn Song, Bo Li, Dan Hendrycks, Mantas Mazeika

Rapid advances in the capabilities of large language models (LLMs) have
raised widespread concerns regarding their potential for malicious use.
Open-weight LLMs present unique challenges, as existing safeguards lack
robustness to tampering attacks that modify model weights. For example, recent
works have demonstrated that refusal and unlearning safeguards can be trivially
removed with a few steps of fine-tuning. These vulnerabilities necessitate new
approaches for enabling the safe release of open-weight LLMs. We develop a
method, called TAR, for building tamper-resistant safeguards into open-weight
LLMs such that adversaries cannot remove the safeguards even after thousands of
steps of fine-tuning. In extensive evaluations and red teaming analyses, we
find that our method greatly improves tamper-resistance while preserving benign
capabilities. Our results demonstrate that tamper-resistance is a tractable
problem, opening up a promising new avenue to improve the safety and security
of open-weight LLMs.

摘要：大型語言模型 (LLM) 的功能快速進步，引發了人們對其潛在惡意使用感到普遍擔憂。開放權重的 LLM 提出獨特挑戰，因為現有保障措施缺乏對修改模型權重的竄改攻擊的健全性。例如，最近的研究表明，拒絕和遺忘保障措施可以用微調的幾個步驟輕鬆移除。這些漏洞需要新的方法來實現開放權重 LLM 的安全發布。我們開發了一種稱為 TAR 的方法，用於將防篡改保障措施建置到開放權重 LLM 中，這樣即使經過數千次微調步驟，對手也無法移除保障措施。在廣泛的評估和紅隊分析中，我們發現我們的這種方法大幅提高了防篡改能力，同時保留了良性功能。我們的結果表明，防篡改是一個易於解決的問題，為改善開放權重 LLM 的安全性和安全性開闢了一條新的途徑。

##### **Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention**
2408.00760v1 by Susung Hong

Conditional diffusion models have shown remarkable success in visual content
generation, producing high-quality samples across various domains, largely due
to classifier-free guidance (CFG). Recent attempts to extend guidance to
unconditional models have relied on heuristic techniques, resulting in
suboptimal generation quality and unintended effects. In this work, we propose
Smoothed Energy Guidance (SEG), a novel training- and condition-free approach
that leverages the energy-based perspective of the self-attention mechanism to
enhance image generation. By defining the energy of self-attention, we
introduce a method to reduce the curvature of the energy landscape of attention
and use the output as the unconditional prediction. Practically, we control the
curvature of the energy landscape by adjusting the Gaussian kernel parameter
while keeping the guidance scale parameter fixed. Additionally, we present a
query blurring method that is equivalent to blurring the entire attention
weights without incurring quadratic complexity in the number of tokens. In our
experiments, SEG achieves a Pareto improvement in both quality and the
reduction of side effects. The code is available at
\url{https://github.com/SusungHong/SEG-SDXL}.

摘要：條件擴散模型在視覺內容生成方面展現出顯著的成功，在各種領域產生高品質的範例，這在很大程度上歸功於無分類器引導 (CFG)。最近嘗試將引導擴展到無條件模型依賴於啟發式技術，導致次優的生成品質和意外的影響。在這項工作中，我們提出平滑能量引導 (SEG)，一種新穎的訓練和條件無關的方法，它利用自注意力機制的基於能量的觀點來增強影像生成。透過定義自注意力的能量，我們引入一種方法來減少注意力的能量景觀的曲率，並使用輸出作為無條件預測。實際上，我們透過調整高斯核參數來控制能量景觀的曲率，同時保持引導規模參數固定。此外，我們提出一個查詢模糊方法，這等同於模糊整個注意力權重，而不會產生二次複雜度，令牌數量也不受影響。在我們的實驗中，SEG 在品質和副作用的減少方面都達到了帕累托改善。程式碼可在 \url{https://github.com/SusungHong/SEG-SDXL} 取得。

##### **Segment anything model 2: an application to 2D and 3D medical images**
2408.00756v1 by Haoyu Dong, Hanxue Gu, Yaqian Chen, Jichen Yang, Maciej A. Mazurowski

Segment Anything Model (SAM) has gained significant attention because of its
ability to segment a variety of objects in images given a prompt. The recently
developed SAM 2 has extended this ability to video inputs. This opens an
opportunity to apply SAM to 3D images, one of the fundamental tasks in the
medical imaging field. In this paper, we provide an extensive evaluation of SAM
2's ability to segment both 2D and 3D medical images. We collect 18 medical
imaging datasets, including common 3D modalities such as computed tomography
(CT), magnetic resonance imaging (MRI), and positron emission tomography (PET)
as well as 2D modalities such as X-ray and ultrasound. We consider two
evaluation pipelines of SAM 2: (1) multi-frame 3D segmentation, where prompts
are provided to one or multiple slice(s) selected from the volume, and (2)
single-frame 2D segmentation, where prompts are provided to each slice. The
former is only applicable to 3D modalities, while the latter applies to both 2D
and 3D modalities. We learn that SAM 2 exhibits similar performance as SAM
under single-frame 2D segmentation, and has variable performance under
multi-frame 3D segmentation depending on the choices of slices to annotate, the
direction of the propagation, the predictions utilized during the propagation,
etc.

摘要：分段任何模型 (SAM) 因其在給定提示的情況下分段圖像中各種物體的能力而備受關注。最近開發的 SAM 2 已將此能力擴展到影片輸入。這開啟了一個將 SAM 應用於 3D 影像的機會，這是醫學影像領域的基礎任務之一。在本文中，我們對 SAM 2 分段 2D 和 3D 醫學影像的能力進行了廣泛評估。我們收集了 18 個醫學影像資料集，包括常見的 3D 方式，例如電腦斷層掃描 (CT)、磁振造影 (MRI) 和正子發射斷層掃描 (PET)，以及 2D 方式，例如 X 光和超音波。我們考慮了 SAM 2 的兩個評估管道：(1) 多幀 3D 分段，其中提示提供給從體積中選取的一個或多個切片，以及 (2) 單幀 2D 分段，其中提示提供給每個切片。前者僅適用於 3D 方式，而後者適用於 2D 和 3D 方式。我們了解到，在單幀 2D 分段下，SAM 2 表現出與 SAM 相似的效能，而在多幀 3D 分段下則表現出不同的效能，具體取決於標記切片的選擇、傳播方向、傳播期間使用的預測等。

##### **DynamoLLM: Designing LLM Inference Clusters for Performance and Energy Efficiency**
2408.00741v1 by Jovan Stojkovic, Chaojie Zhang, Íñigo Goiri, Josep Torrellas, Esha Choukse

The rapid evolution and widespread adoption of generative large language
models (LLMs) have made them a pivotal workload in various applications. Today,
LLM inference clusters receive a large number of queries with strict Service
Level Objectives (SLOs). To achieve the desired performance, these models
execute on power-hungry GPUs causing the inference clusters to consume large
amount of energy and, consequently, result in excessive carbon emissions.
Fortunately, we find that there is a great opportunity to exploit the
heterogeneity in inference compute properties and fluctuations in inference
workloads, to significantly improve energy-efficiency. However, such a diverse
and dynamic environment creates a large search-space where different system
configurations (e.g., number of instances, model parallelism, and GPU
frequency) translate into different energy-performance trade-offs. To address
these challenges, we propose DynamoLLM, the first energy-management framework
for LLM inference environments. DynamoLLM automatically and dynamically
reconfigures the inference cluster to optimize for energy and cost of LLM
serving under the service's performance SLOs. We show that at a service-level,
DynamoLLM conserves 53% energy and 38% operational carbon emissions, and
reduces 61% cost to the customer, while meeting the latency SLOs.

摘要：生成式大型语言模型 (LLM) 的快速发展和广泛采用，使其成为各种应用程序中的关键工作负载。如今，LLM 推理集群会收到大量具有严格服务级别目标 (SLO) 的查询。为了实现所需的性能，这些模型在耗电的 GPU 上执行，导致推理集群消耗大量的能量，从而导致过度的碳排放。幸运的是，我们发现有很大的机会利用推理计算特性和推理工作负载的波动中的异质性，以显著提高能效。然而，如此多样化和动态的环境创造了一个巨大的搜索空间，其中不同的系统配置（例如，实例数量、模型并行性和 GPU 频率）转化为不同的能效权衡。为了应对这些挑战，我们提出了 DynamoLLM，这是 LLM 推理环境的第一个能源管理框架。DynamoLLM 会自动动态地重新配置推理集群，以优化 LLM 服务的能源和成本，同时满足服务的性能 SLO。我们表明，在服务级别，DynamoLLM 节省了 53% 的能源和 38% 的运营碳排放，并为客户节省了 61% 的成本，同时满足了延迟 SLO。

##### **CERT-ED: Certifiably Robust Text Classification for Edit Distance**
2408.00728v1 by Zhuoqun Huang, Neil G Marchant, Olga Ohrimenko, Benjamin I. P. Rubinstein

With the growing integration of AI in daily life, ensuring the robustness of
systems to inference-time attacks is crucial. Among the approaches for
certifying robustness to such adversarial examples, randomized smoothing has
emerged as highly promising due to its nature as a wrapper around arbitrary
black-box models. Previous work on randomized smoothing in natural language
processing has primarily focused on specific subsets of edit distance
operations, such as synonym substitution or word insertion, without exploring
the certification of all edit operations. In this paper, we adapt Randomized
Deletion (Huang et al., 2023) and propose, CERTified Edit Distance defense
(CERT-ED) for natural language classification. Through comprehensive
experiments, we demonstrate that CERT-ED outperforms the existing Hamming
distance method RanMASK (Zeng et al., 2023) in 4 out of 5 datasets in terms of
both accuracy and the cardinality of the certificate. By covering various
threat models, including 5 direct and 5 transfer attacks, our method improves
empirical robustness in 38 out of 50 settings.

摘要：隨著 AI 在日常生活中整合度不斷提高，確保系統在推理時間攻擊中的穩健性至關重要。在用於驗證對此類對抗範例的穩健性的方法中，隨機平滑因其作為任意黑盒模型的包裝器的特性而備受矚目。先前針對自然語言處理中隨機平滑的研究主要集中在編輯距離操作的特定子集上，例如同義詞替換或詞彙插入，而沒有探索所有編輯操作的驗證。在本文中，我們調整了隨機刪除（Huang et al., 2023）並提出了自然語言分類的 CERTified 編輯距離防禦（CERT-ED）。透過全面的實驗，我們證明 CERT-ED 在準確性和證書基數方面，在 5 個資料集中有 4 個資料集優於現有的漢明距離方法 RanMASK（Zeng et al., 2023）。透過涵蓋各種威脅模型，包括 5 次直接攻擊和 5 次傳輸攻擊，我們的模型在 50 個設定中有 38 個設定改進了經驗穩健性。

##### **Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions**
2408.00727v1 by Guangzhi Xiong, Qiao Jin, Xiao Wang, Minjia Zhang, Zhiyong Lu, Aidong Zhang

The emergent abilities of large language models (LLMs) have demonstrated
great potential in solving medical questions. They can possess considerable
medical knowledge, but may still hallucinate and are inflexible in the
knowledge updates. While Retrieval-Augmented Generation (RAG) has been proposed
to enhance the medical question-answering capabilities of LLMs with external
knowledge bases, it may still fail in complex cases where multiple rounds of
information-seeking are required. To address such an issue, we propose
iterative RAG for medicine (i-MedRAG), where LLMs can iteratively ask follow-up
queries based on previous information-seeking attempts. In each iteration of
i-MedRAG, the follow-up queries will be answered by a vanilla RAG system and
they will be further used to guide the query generation in the next iteration.
Our experiments show the improved performance of various LLMs brought by
i-MedRAG compared with vanilla RAG on complex questions from clinical vignettes
in the United States Medical Licensing Examination (USMLE), as well as various
knowledge tests in the Massive Multitask Language Understanding (MMLU) dataset.
Notably, our zero-shot i-MedRAG outperforms all existing prompt engineering and
fine-tuning methods on GPT-3.5, achieving an accuracy of 69.68\% on the MedQA
dataset. In addition, we characterize the scaling properties of i-MedRAG with
different iterations of follow-up queries and different numbers of queries per
iteration. Our case studies show that i-MedRAG can flexibly ask follow-up
queries to form reasoning chains, providing an in-depth analysis of medical
questions. To the best of our knowledge, this is the first-of-its-kind study on
incorporating follow-up queries into medical RAG.

摘要：大型語言模型（LLM）的新興能力已證明在解決醫療問題方面具有巨大潛力。它們可能擁有大量的醫療知識，但仍可能產生幻覺，並且在知識更新方面缺乏靈活性。雖然已提出檢索增強生成（RAG）以利用外部知識庫增強 LLM 的醫療問題解答能力，但在需要多輪信息檢索的複雜情況下，它仍可能失敗。為了解決這個問題，我們提出了用於醫療的迭代 RAG（i-MedRAG），其中 LLM 可以根據先前的信息檢索嘗試反覆詢問後續查詢。在 i-MedRAG 的每次迭代中，後續查詢將由基本的 RAG 系統回答，並且它們將進一步用於指導下一次迭代中的查詢生成。我們的實驗表明，與美國醫學執照考試（USMLE）中臨床小插圖中的複雜問題以及 Massive Multitask Language Understanding（MMLU）數據集中各種知識測試中的基本 RAG 相比，i-MedRAG 帶來的各種 LLM 的改進性能。值得注意的是，我們的零次學習 i-MedRAG 在 GPT-3.5 上優於所有現有的提示工程和微調方法，在 MedQA 數據集上達到了 69.68% 的準確率。此外，我們描述了 i-MedRAG 的擴展屬性，包括不同的後續查詢迭代和每個迭代的不同查詢數量。我們的案例研究表明，i-MedRAG 可以靈活地詢問後續查詢以形成推理鏈，從而對醫療問題進行深入分析。據我們所知，這是第一個將後續查詢納入醫療 RAG 的同類研究。

##### **An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models**
2408.00724v1 by Yangzhen Wu, Zhiqing Sun, Shanda Li, Sean Welleck, Yiming Yang

The optimal training configurations of large language models (LLMs) with
respect to model sizes and compute budgets have been extensively studied. But
how to optimally configure LLMs during inference has not been explored in
sufficient depth. We study compute-optimal inference: designing models and
inference strategies that optimally trade off additional inference-time compute
for improved performance. As a first step towards understanding and designing
compute-optimal inference methods, we assessed the effectiveness and
computational efficiency of multiple inference strategies such as Greedy
Search, Majority Voting, Best-of-N, Weighted Voting, and their variants on two
different Tree Search algorithms, involving different model sizes and
computational budgets. We found that a smaller language model with a novel tree
search algorithm typically achieves a Pareto-optimal trade-off. These results
highlight the potential benefits of deploying smaller models equipped with more
sophisticated decoding algorithms in budget-constrained scenarios, e.g., on
end-devices, to enhance problem-solving accuracy. For instance, we show that
the Llemma-7B model can achieve competitive accuracy to a Llemma-34B model on
MATH500 while using $2\times$ less FLOPs. Our findings could potentially apply
to any generation task with a well-defined measure of success.

摘要：對於大型語言模型 (LLM) 的最佳訓練組態，無論是模型大小或運算預算，都已廣泛研究過。但如何最佳組態 LLM 在推論期間尚未深入探討。我們研究計算最佳推論：設計模型和推論策略，最佳折衷額外的推論時間計算以提升效能。作為了解和設計計算最佳推論方法的第一步，我們評估多種推論策略的效能和計算效率，例如貪婪搜尋、多數決、N 中最佳、加權投票，以及它們在兩種不同樹狀搜尋演算法上的變體，涉及不同模型大小和計算預算。我們發現，具備新穎樹狀搜尋演算法的較小語言模型通常能達成帕雷托最佳折衷。這些結果突顯在預算受限的情況下，部署配備更精緻解碼演算法的小型模型的潛在好處，例如在終端裝置上，以提升問題解決的準確度。例如，我們顯示 Llemma-7B 模型在 MATH500 上能達成與 Llemma-34B 模型競爭的準確度，同時使用少 $2\times$ 的 FLOP。我們的發現潛在可應用於任何具有明確成功衡量標準的產生任務。

##### **Pathway to Secure and Trustworthy 6G for LLMs: Attacks, Defense, and Opportunities**
2408.00722v1 by Sunder Ali Khowaja, Parus Khuwaja, Kapal Dev, Hussam Al Hamadi, Engin Zeydan

Recently, large language models (LLMs) have been gaining a lot of interest
due to their adaptability and extensibility in emerging applications, including
communication networks. It is anticipated that 6G mobile edge computing
networks will be able to support LLMs as a service, as they provide ultra
reliable low-latency communications and closed loop massive connectivity.
However, LLMs are vulnerable to data and model privacy issues that affect the
trustworthiness of LLMs to be deployed for user-based services. In this paper,
we explore the security vulnerabilities associated with fine-tuning LLMs in 6G
networks, in particular the membership inference attack. We define the
characteristics of an attack network that can perform a membership inference
attack if the attacker has access to the fine-tuned model for the downstream
task. We show that the membership inference attacks are effective for any
downstream task, which can lead to a personal data breach when using LLM as a
service. The experimental results show that the attack success rate of maximum
92% can be achieved on named entity recognition task. Based on the experimental
analysis, we discuss possible defense mechanisms and present possible research
directions to make the LLMs more trustworthy in the context of 6G networks.

摘要：<paragraph>最近，大型语言模型 (LLM) 因其在包括通信网络在内的新兴应用中的适应性和可扩展性而备受关注。预计 6G 移动边缘计算网络将能够支持 LLM 作为一项服务，因为它们提供了超可靠的低延迟通信和闭环大规模连接。然而，LLM 容易受到数据和模型隐私问题的影响，这些问题会影响 LLM 被部署用于基于用户的服务的可信度。在本文中，我们探讨了在 6G 网络中微调 LLM 相关的安全漏洞，特别是成员推断攻击。我们定义了攻击网络的特征，如果攻击者可以访问下游任务的微调模型，则该攻击网络可以执行成员推断攻击。我们表明，成员推断攻击对任何下游任务都是有效的，这在使用 LLM 作为服务时可能导致个人数据泄露。实验结果表明，在命名实体识别任务上可以实现最高 92% 的攻击成功率。基于实验分析，我们讨论了可能的防御机制，并提出了可能的的研究方向，以使 LLM 在 6G 网络的背景下更值得信赖。</paragraph>

##### **SAM 2: Segment Anything in Images and Videos**
2408.00714v1 by Nikhila Ravi, Valentin Gabeur, Yuan-Ting Hu, Ronghang Hu, Chaitanya Ryali, Tengyu Ma, Haitham Khedr, Roman Rädle, Chloe Rolland, Laura Gustafson, Eric Mintun, Junting Pan, Kalyan Vasudev Alwala, Nicolas Carion, Chao-Yuan Wu, Ross Girshick, Piotr Dollár, Christoph Feichtenhofer

We present Segment Anything Model 2 (SAM 2), a foundation model towards
solving promptable visual segmentation in images and videos. We build a data
engine, which improves model and data via user interaction, to collect the
largest video segmentation dataset to date. Our model is a simple transformer
architecture with streaming memory for real-time video processing. SAM 2
trained on our data provides strong performance across a wide range of tasks.
In video segmentation, we observe better accuracy, using 3x fewer interactions
than prior approaches. In image segmentation, our model is more accurate and 6x
faster than the Segment Anything Model (SAM). We believe that our data, model,
and insights will serve as a significant milestone for video segmentation and
related perception tasks. We are releasing a version of our model, the dataset
and an interactive demo.

摘要：我們提出「區段任何東西模型 2」(SAM 2)，這是一個基礎模型，用於解決影像和影片中的可提示視覺區段。我們建構了一個資料引擎，透過使用者互動來改善模型和資料，以收集迄今為止最大的影片區段資料集。我們的模型是一種簡單的轉換器架構，具有串流記憶體，可進行即時影片處理。在我們的資料上訓練的 SAM 2 在廣泛的任務中提供了強大的效能。在影片區段中，我們觀察到更高的準確度，與先前的做法相比，互動次數減少了 3 倍。在影像區段中，我們的模型比「區段任何東西模型」(SAM) 更準確，速度快了 6 倍。我們相信我們的資料、模型和見解將成為影片區段和相關感知任務的重要里程碑。我們正在釋出我們模型的一個版本、資料集和一個互動示範。

##### **Investigating Brain Connectivity and Regional Statistics from EEG for early stage Parkinson's Classification**
2408.00711v1 by Amarpal Sahota, Amber Roguski, Matthew W Jones, Zahraa S. Abdallah, Raul Santos-Rodriguez

We evaluate the effectiveness of combining brain connectivity metrics with
signal statistics for early stage Parkinson's Disease (PD) classification using
electroencephalogram data (EEG). The data is from 5 arousal states - wakeful
and four sleep stages (N1, N2, N3 and REM). Our pipeline uses an Ada Boost
model for classification on a challenging early stage PD classification task
with with only 30 participants (11 PD , 19 Healthy Control). Evaluating 9 brain
connectivity metrics we find the best connectivity metric to be different for
each arousal state with Phase Lag Index achieving the highest individual
classification accuracy of 86\% on N1 data. Further to this our pipeline using
regional signal statistics achieves an accuracy of 78\%, using brain
connectivity only achieves an accuracy of 86\% whereas combining the two
achieves a best accuracy of 91\%. This best performance is achieved on N1 data
using Phase Lag Index (PLI) combined with statistics derived from the frequency
characteristics of the EEG signal. This model also achieves a recall of 80 \%
and precision of 96\%. Furthermore we find that on data from each arousal
state, combining PLI with regional signal statistics improves classification
accuracy versus using signal statistics or brain connectivity alone. Thus we
conclude that combining brain connectivity statistics with regional EEG
statistics is optimal for classifier performance on early stage Parkinson's.
Additionally, we find outperformance of N1 EEG for classification of
Parkinson's and expect this could be due to disrupted N1 sleep in PD. This
should be explored in future work.

摘要：<paragraph>我們評估將腦連接性指標與訊號統計資料結合起來對早期帕金森氏症 (PD) 分類的有效性，使用腦電圖資料 (EEG)。資料來自 5 種喚醒狀態 - 清醒和四個睡眠階段 (N1、N2、N3 和 REM)。我們的管道使用 Ada Boost 模型對具有挑戰性的早期 PD 分類任務進行分類，僅有 30 位參與者 (11 位 PD，19 位健康對照組)。評估 9 種腦連接性指標，我們發現最佳連接性指標因每種喚醒狀態而異，相位滯後指標在 N1 資料上達到最高的個別分類準確度 86%。此外，我們的管道使用區域訊號統計資料達到 78% 的準確度，僅使用腦連接性達到 86% 的準確度，而將兩者結合起來達到最佳 91% 的準確度。此最佳效能是在 N1 資料上使用相位滯後指標 (PLI) 結合從 EEG 訊號的頻率特性衍生的統計資料時所達成。此模型也達到 80% 的召回率和 96% 的精確度。此外，我們發現，在來自每種喚醒狀態的資料上，將 PLI 與區域訊號統計資料結合起來，可提升分類準確度，優於僅使用訊號統計資料或腦連接性。因此，我們得出結論，將腦連接性統計資料與區域 EEG 統計資料結合起來，對於早期帕金森氏症的分類器效能而言是最佳的。此外，我們發現 N1 EEG 在帕金森氏症的分類上有優異表現，並預期這可能是由於 PD 中 N1 睡眠中斷所致。這應在未來的研究中加以探討。</paragraph>

##### **Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM**
2408.00706v1 by Xiaofeng Liu, Jonghye Woo, Chao Ma, Jinsong Ouyang, Georges El Fakhri

Delineating lesions and anatomical structure is important for image-guided
interventions. Point-supervised medical image segmentation (PSS) has great
potential to alleviate costly expert delineation labeling. However, due to the
lack of precise size and boundary guidance, the effectiveness of PSS often
falls short of expectations. Although recent vision foundational models, such
as the medical segment anything model (MedSAM), have made significant
advancements in bounding-box-prompted segmentation, it is not straightforward
to utilize point annotation, and is prone to semantic ambiguity. In this
preliminary study, we introduce an iterative framework to facilitate
semantic-aware point-supervised MedSAM. Specifically, the semantic box-prompt
generator (SBPG) module has the capacity to convert the point input into
potential pseudo bounding box suggestions, which are explicitly refined by the
prototype-based semantic similarity. This is then succeeded by a prompt-guided
spatial refinement (PGSR) module that harnesses the exceptional
generalizability of MedSAM to infer the segmentation mask, which also updates
the box proposal seed in SBPG. Performance can be progressively improved with
adequate iterations. We conducted an evaluation on BraTS2018 for the
segmentation of whole brain tumors and demonstrated its superior performance
compared to traditional PSS methods and on par with box-supervised methods.

摘要：描繪病灶和解剖結構對於影像導引介入非常重要。點監督醫學影像分割（PSS）具有減輕昂貴的專家描繪標籤的巨大潛力。然而，由於缺乏精確的大小和邊界引導，PSS 的有效性通常低於預期。儘管最近的視覺基礎模型，例如醫學分割任何模型（MedSAM），在邊界框提示分割方面取得了重大進展，但利用點註釋並不容易，而且容易產生語義歧義。在這項初步研究中，我們引入了一個迭代框架來促進語義感知點監督 MedSAM。具體來說，語義框提示生成器（SBPG）模組能夠將點輸入轉換為潛在的偽邊界框建議，這些建議由基於原型的語義相似性明確細化。然後，由提示引導的空間細化（PGSR）模組繼承，它利用 MedSAM 的出色可概化性來推斷分割蒙版，這也會更新 SBPG 中的框建議種子。通過充分的迭代可以逐步提高性能。我們對 BraTS2018 進行了全腦腫瘤分割評估，並證明其性能優於傳統的 PSS 方法，並且與框監督方法相當。

##### **Future of Artificial Intelligence in Agile Software Development**
2408.00703v1 by Mariyam Mahboob, Mohammed Rayyan Uddin Ahmed, Zoiba Zia, Mariam Shakeel Ali, Ayman Khaleel Ahmed

The advent of Artificial intelligence has promising advantages that can be
utilized to transform the landscape of software project development. The
Software process framework consists of activities that constantly require
routine human interaction, leading to the possibility of errors and
uncertainties. AI can assist software development managers, software testers,
and other team members by leveraging LLMs, GenAI models, and AI agents to
perform routine tasks, risk analysis and prediction, strategy recommendations,
and support decision making. AI has the potential to increase efficiency and
reduce the risks encountered by the project management team while increasing
the project success rates. Additionally, it can also break down complex notions
and development processes for stakeholders to make informed decisions. In this
paper, we propose an approach in which AI tools and technologies can be
utilized to bestow maximum assistance for agile software projects, which have
become increasingly favored in the industry in recent years.

摘要：人工智慧的出現具有可帶來優勢，可望用於轉換軟體專案開發的樣貌。軟體流程架構包含持續需要常規人類互動的活動，導致可能產生錯誤和不確定性。人工智慧能協助軟體開發經理、軟體測試人員和其他團隊成員，透過利用大型語言模型 (LLM)、生成式人工智慧模型和人工智慧代理程式來執行常規工作、風險分析和預測、策略建議和支援決策制定。人工智慧有潛力提升效率和降低專案管理團隊遭遇的風險，同時提升專案成功率。此外，人工智慧還能為利害關係人分解複雜的概念和開發流程，以做出明智的決策。在本文中，我們提出一個方法，其中人工智慧工具和技術可望用於賦予敏捷軟體專案最大的協助，這些專案近年來在產業中越來越受到青睞。

##### **Improving Text Embeddings for Smaller Language Models Using Contrastive Fine-tuning**
2408.00690v1 by Trapoom Ukarapol, Zhicheng Lee, Amy Xin

While Large Language Models show remarkable performance in natural language
understanding, their resource-intensive nature makes them less accessible. In
contrast, smaller language models such as MiniCPM offer more sustainable
scalability, but often underperform without specialized optimization. In this
paper, we explore the enhancement of smaller language models through the
improvement of their text embeddings. We select three language models, MiniCPM,
Phi-2, and Gemma, to conduct contrastive fine-tuning on the NLI dataset. Our
results demonstrate that this fine-tuning method enhances the quality of text
embeddings for all three models across various benchmarks, with MiniCPM showing
the most significant improvements of an average 56.33\% performance gain. The
contrastive fine-tuning code is publicly available at
https://github.com/trapoom555/Language-Model-STS-CFT.

摘要：雖然大型語言模型在自然語言理解方面展現出卓越的效能，但其資源密集的本質使其較難以取得。相較之下，像 MiniCPM 等較小的語言模型提供了更永續的可擴充性，但通常在沒有特殊最佳化的情況下表現不佳。在本文中，我們探討了透過改善其文字嵌入來增強較小語言模型的方法。我們選取了三個語言模型，MiniCPM、Phi-2 和 Gemma，在 NLI 資料集上進行對比微調。我們的結果證明，這種微調方法提升了所有三個模型在各種基準上的文字嵌入品質，其中 MiniCPM 顯示出最顯著的改進，平均效能提升了 56.33%。對比微調程式碼已公開在 https://github.com/trapoom555/Language-Model-STS-CFT。

##### **Can Developers Prompt? A Controlled Experiment for Code Documentation Generation**
2408.00686v1 by Hans-Alexander Kruse, Tim Puhlfürß, Walid Maalej

Large language models (LLMs) bear great potential for automating tedious
development tasks such as creating and maintaining code documentation. However,
it is unclear to what extent developers can effectively prompt LLMs to create
concise and useful documentation. We report on a controlled experiment with 20
professionals and 30 computer science students tasked with code documentation
generation for two Python functions. The experimental group freely entered
ad-hoc prompts in a ChatGPT-like extension of Visual Studio Code, while the
control group executed a predefined few-shot prompt. Our results reveal that
professionals and students were unaware of or unable to apply prompt
engineering techniques. Especially students perceived the documentation
produced from ad-hoc prompts as significantly less readable, less concise, and
less helpful than documentation from prepared prompts. Some professionals
produced higher quality documentation by just including the keyword Docstring
in their ad-hoc prompts. While students desired more support in formulating
prompts, professionals appreciated the flexibility of ad-hoc prompting.
Participants in both groups rarely assessed the output as perfect. Instead,
they understood the tools as support to iteratively refine the documentation.
Further research is needed to understand which prompting skills and preferences
developers have and which support they need for certain tasks.

摘要：大型語言模型 (LLM) 具有自動化繁瑣開發任務（例如建立和維護程式碼文件）的巨大潛力。然而，目前尚不清楚開發人員在多大程度上可以有效地提示 LLM 建立簡潔且有用的文件。我們報告了一項受控實驗，有 20 位專業人員和 30 位電腦科學系學生負責為兩個 Python 函數建立程式碼文件。實驗組在類似 ChatGPT 的 Visual Studio Code 擴充功能中自由輸入臨時提示，而對照組則執行預先定義的少量提示。我們的結果顯示，專業人員和學生不知道或無法應用提示工程技術。特別是學生認為根據臨時提示產生的文件顯著低於根據準備好的提示產生的文件，可讀性、簡潔性和有幫助性都較低。一些專業人員僅在臨時提示中加入 Docstring 關鍵字，就產生了更高品質的文件。雖然學生希望在制定提示時獲得更多支援，但專業人員則欣賞臨時提示的靈活性。這兩組的參與者很少將輸出評估為完美。相反地，他們將這些工具視為反覆修改文件的支援。需要進一步研究以了解開發人員具備哪些提示技能和偏好，以及他們在某些任務中需要哪些支援。

##### **Assessing the Variety of a Concept Space Using an Unbiased Estimate of Rao's Quadratic Index**
2408.00684v1 by Anubhab Majumder, Ujjwal Pal, Amaresh Chakrabarti

Past research relates design creativity to 'divergent thinking,' i.e., how
well the concept space is explored during the early phase of design.
Researchers have argued that generating several concepts would increase the
chances of producing better design solutions. 'Variety' is one of the
parameters by which one can quantify the breadth of a concept space explored by
the designers. It is useful to assess variety at the conceptual design stage
because, at this stage, designers have the freedom to explore different
solution principles so as to satisfy a design problem with substantially novel
concepts. This article elaborates on and critically examines the existing
variety metrics from the engineering design literature, discussing their
limitations. A new distance-based variety metric is proposed, along with a
prescriptive framework to support the assessment process. This framework uses
the SAPPhIRE model of causality as a knowledge representation scheme to measure
the real-valued distance between two design concepts. The proposed framework is
implemented in a software tool called 'VariAnT.' Furthermore, the tool's
application is demonstrated through an illustrative example.

摘要：過去的研究將設計創意與「發散性思考」聯繫起來，亦即在設計的早期階段，概念空間探索得有多好。研究人員主張，產生多個概念將增加產生更好設計解決方案的機會。「多樣性」是其中一個參數，設計人員可以用來量化他們探索的概念空間廣度。在概念設計階段評估多樣性很有用，因為在這個階段，設計人員有自由探索不同的解決方案原則，以滿足實質上具有新穎概念的設計問題。本文詳細說明並批判性地審查工程設計文獻中現有的多樣性指標，並討論它們的限制。提出了一種新的基於距離的多樣性指標，以及一個規範性框架來支持評估過程。這個框架使用 SAPPhIRE 因果關係模型作為知識表示方案，來測量兩個設計概念之間的實值距離。所提出的框架在稱為「VariAnT」的軟體工具中實作。此外，透過一個說明性範例展示了該工具的應用。

##### **Learning in Multi-Objective Public Goods Games with Non-Linear Utilities**
2408.00682v1 by Nicole Orzan, Erman Acar, Davide Grossi, Patrick Mannion, Roxana Rădulescu

Addressing the question of how to achieve optimal decision-making under risk
and uncertainty is crucial for enhancing the capabilities of artificial agents
that collaborate with or support humans. In this work, we address this question
in the context of Public Goods Games. We study learning in a novel
multi-objective version of the Public Goods Game where agents have different
risk preferences, by means of multi-objective reinforcement learning. We
introduce a parametric non-linear utility function to model risk preferences at
the level of individual agents, over the collective and individual reward
components of the game. We study the interplay between such preference
modelling and environmental uncertainty on the incentive alignment level in the
game. We demonstrate how different combinations of individual preferences and
environmental uncertainties sustain the emergence of cooperative patterns in
non-cooperative environments (i.e., where competitive strategies are dominant),
while others sustain competitive patterns in cooperative environments (i.e.,
where cooperative strategies are dominant).

摘要：探討如何在風險和不確定性下達成最佳決策，對於提升與人類合作或支援人類的人工智慧代理能力至關重要。在這項研究中，我們在公共財博弈的背景下探討這個問題。我們透過多目標強化學習，研究在公共財博弈的新穎多目標版本中學習。我們引入一個參數非線性效用函數，以在個人代理層級對風險偏好進行建模，涵蓋博弈的集體和個人獎勵組成部分。我們研究此類偏好建模與環境不確定性在博弈中激勵對齊層級之間的交互作用。我們展示了個人偏好和環境不確定性的不同組合如何在非合作環境中維持合作模式的出現（即競爭策略佔主導地位），而其他組合如何在合作環境中維持競爭模式（即合作策略佔主導地位）。

##### **Leveraging Entailment Judgements in Cross-Lingual Summarisation**
2408.00675v1 by Huajian Zhang, Laura Perez-Beltrachini

Synthetically created Cross-Lingual Summarisation (CLS) datasets are prone to
include document-summary pairs where the reference summary is unfaithful to the
corresponding document as it contains content not supported by the document
(i.e., hallucinated content). This low data quality misleads model learning and
obscures evaluation results. Automatic ways to assess hallucinations and
improve training have been proposed for monolingual summarisation,
predominantly in English. For CLS, we propose to use off-the-shelf
cross-lingual Natural Language Inference (X-NLI) to evaluate faithfulness of
reference and model generated summaries. Then, we study training approaches
that are aware of faithfulness issues in the training data and propose an
approach that uses unlikelihood loss to teach a model about unfaithful summary
sequences. Our results show that it is possible to train CLS models that yield
more faithful summaries while maintaining comparable or better informativess.

摘要：合成建立的跨語言摘要 (CLS) 資料集容易包含文件摘要對，其中參考摘要對應文件不忠實，因為它包含文件不支援的內容（即幻覺內容）。這種低資料品質會誤導模型學習，並掩蓋評估結果。已經提出用於單語言摘要的自動方法來評估幻覺並改善訓練，主要用於英文。對於 CLS，我們建議使用現成的跨語言自然語言推論 (X-NLI) 來評估參考和模型產生的摘要的忠實度。然後，我們研究了訓練方法，這些方法了解訓練資料中的忠實度問題，並提出了一種使用不似然損失來教導模型有關不忠實摘要序列的方法。我們的結果表明，訓練 CLS 模型是可能的，這些模型會產生更忠實的摘要，同時保持可比性或更好的資訊性。

##### **SentenceVAE: Faster, Longer and More Accurate Inference with Next-sentence Prediction for Large Language Models**
2408.00655v1 by Hongjun An, Yifan Chen, Xiaozhen Qiao, Zhe Sun, Xuelong Li

Contemporary large language models (LLMs) predominantly utilize a next-token
prediction method for inference, which significantly impedes their processing
speed. In this paper, we introduce a novel inference methodology termed
next-sentence prediction, aimed at enhancing the inference efficiency of LLMs.
We present SentenceVAE, a tiny model consisting of an encoder and a decoder.
The encoder effectively condenses the information within a sentence into a
singular token, while the decoder reconstructs this compressed data back into
its original sentential form. By integrating SentenceVAE into the input and
output layers of LLMs, we develop Sentence-level LLMs (SLLMs) that employ a
sentence-by-sentence inference approach, markedly accelerating inference
speeds. SentenceVAE also maintains the integrity of the original semantic
content by segmenting the text into sentences, thereby preserving accuracy
while boosting inference speeds. Compared to traditional LLMs, SLLMs process
fewer tokens over equivalent context lengths, significantly reducing memory
demands for Self-Attention computations and facilitating the handling of longer
contexts. Our experimental findings reveal that this method can increase
inference speeds by 204~365%, reduce perplexity (PPL) to 46~75% of its original
metric, and decrease memory overhead by 86~91% for the same context length. The
advantages of this approach are further amplified with increases in model
parameters.

摘要：當代大型語言模型 (LLM) 主要利用下一個代碼預測方法進行推論，這顯著地阻礙了它們的處理速度。在本文中，我們介紹了一種新的推論方法，稱為下一個句子預測，旨在提高 LLM 的推論效率。我們提出了 SentenceVAE，這是一個由編碼器和解碼器組成的小模型。編碼器有效地將句子中的資訊壓縮成一個單一代碼，而解碼器將這些壓縮資料解構回其原始的句子形式。透過將 SentenceVAE 整合到 LLM 的輸入和輸出層，我們開發了句子層級 LLM (SLLM)，它採用逐句推論方法，顯著地加速了推論速度。SentenceVAE 也透過將文字分段成句子來維護原始語義內容的完整性，從而提升推論速度的同時也維持準確性。與傳統的 LLM 相比，SLLM 處理較少代碼，但具有等效的內容長度，大幅減少自注意力計算的記憶體需求，並促進處理較長的內容。我們的實驗結果顯示，這種方法可以將推論速度提升 204~365%，將困惑度 (PPL) 降低到其原始指標的 46~75%，並在相同的內容長度下將記憶體開銷減少 86~91%。隨著模型參數的增加，這種方法的優勢進一步擴大。

##### **AMAES: Augmented Masked Autoencoder Pretraining on Public Brain MRI Data for 3D-Native Segmentation**
2408.00640v1 by Asbjørn Munk, Jakob Ambsdorf, Sebastian Llambias, Mads Nielsen

This study investigates the impact of self-supervised pretraining of 3D
semantic segmentation models on a large-scale, domain-specific dataset. We
introduce BRAINS-45K, a dataset of 44,756 brain MRI volumes from public
sources, the largest public dataset available, and revisit a number of design
choices for pretraining modern segmentation architectures by simplifying and
optimizing state-of-the-art methods, and combining them with a novel
augmentation strategy. The resulting AMAES framework is based on
masked-image-modeling and intensity-based augmentation reversal and balances
memory usage, runtime, and finetuning performance. Using the popular U-Net and
the recent MedNeXt architecture as backbones, we evaluate the effect of
pretraining on three challenging downstream tasks, covering single-sequence,
low-resource settings, and out-of-domain generalization. The results highlight
that pretraining on the proposed dataset with AMAES significantly improves
segmentation performance in the majority of evaluated cases, and that it is
beneficial to pretrain the model with augmentations, despite pretraing on a
large-scale dataset. Code and model checkpoints for reproducing results, as
well as the BRAINS-45K dataset are available at
\url{https://github.com/asbjrnmunk/amaes}.

摘要：本研究調查了 3D 語意分割模型的自我監督預訓練對大型特定領域資料集的影響。我們引入了 BRAINS-45K，這是一個包含來自公共來源的 44,756 個大腦 MRI 卷的資料集，是最大的公開資料集，並重新審視了現代分割架構預訓練的許多設計選擇，透過簡化和最佳化最先進的方法，並將其與新穎的擴充策略相結合。由此產生的 AMAES 框架基於遮罩影像建模和基於強度的擴充反轉，並平衡了記憶體使用量、執行時間和微調效能。使用流行的 U-Net 和最近的 MedNeXt 架構作為主幹，我們評估了預訓練對三個具有挑戰性的下游任務的影響，涵蓋單一序列、低資源設定和領域外概化。結果強調了使用 AMAES 在建議的資料集上進行預訓練，在評估案例中大部分顯著改善了分割效能，並且儘管在大規模資料集上進行預訓練，但使用擴充預訓練模型是有益的。重製結果的程式碼和模型檢查點，以及 BRAINS-45K 資料集可在\url{https://github.com/asbjrnmunk/amaes} 取得。

##### **DisTrack: a new Tool for Semi-automatic Misinformation Tracking in Online Social Networks**
2408.00633v1 by Guillermo Villar-Rodríguez, Álvaro Huertas-García, Alejandro Martín, Javier Huertas-Tato, David Camacho

Introduction: This article introduces DisTrack, a methodology and a tool
developed for tracking and analyzing misinformation within Online Social
Networks (OSNs). DisTrack is designed to combat the spread of misinformation
through a combination of Natural Language Processing (NLP) Social Network
Analysis (SNA) and graph visualization. The primary goal is to detect
misinformation, track its propagation, identify its sources, and assess the
influence of various actors within the network.
  Methods: DisTrack's architecture incorporates a variety of methodologies
including keyword search, semantic similarity assessments, and graph generation
techniques. These methods collectively facilitate the monitoring of
misinformation, the categorization of content based on alignment with known
false claims, and the visualization of dissemination cascades through detailed
graphs. The tool is tailored to capture and analyze the dynamic nature of
misinformation spread in digital environments.
  Results: The effectiveness of DisTrack is demonstrated through three case
studies focused on different themes: discredit/hate speech, anti-vaccine
misinformation, and false narratives about the Russia-Ukraine conflict. These
studies show DisTrack's capabilities in distinguishing posts that propagate
falsehoods from those that counteract them, and tracing the evolution of
misinformation from its inception.
  Conclusions: The research confirms that DisTrack is a valuable tool in the
field of misinformation analysis. It effectively distinguishes between
different types of misinformation and traces their development over time. By
providing a comprehensive approach to understanding and combating
misinformation in digital spaces, DisTrack proves to be an essential asset for
researchers and practitioners working to mitigate the impact of false
information in online social environments.

摘要：<paragraph>引言：本文介紹 DisTrack，這是一種方法和工具，用於追蹤和分析線上社交網路（OSN）中的錯誤資訊。DisTrack 的設計目的是透過結合自然語言處理（NLP）、社交網路分析（SNA）和圖形視覺化來對抗錯誤資訊的散布。主要目標是偵測錯誤資訊、追蹤其傳播、找出其來源，並評估網路中各個參與者的影響力。
方法：DisTrack 的架構結合了多種方法，包括關鍵字搜尋、語意相似性評估和圖形產生技術。這些方法共同促進了錯誤資訊的監控、基於與已知虛假說法的比對來分類內容，以及透過詳細圖形視覺化傳播層疊。此工具經過量身打造，用於擷取和分析數位環境中錯誤資訊散布的動態特性。
結果：DisTrack 的效能透過三個案例研究獲得驗證，這些研究專注於不同的主題：貶低/仇恨言論、反疫苗錯誤資訊，以及關於俄羅斯-烏克蘭衝突的虛假敘述。這些研究顯示出 DisTrack 在區分傳播虛假資訊和反制虛假資訊的貼文，以及追蹤錯誤資訊從其開端演變的過程中所具備的能力。
結論：研究證實 DisTrack 是錯誤資訊分析領域中一個有價值的工具。它有效區分了不同類型的錯誤資訊，並追蹤其隨著時間推移的發展。透過提供一種全面的方法來理解和對抗數位空間中的錯誤資訊，DisTrack 證明了自己是協助研究人員和實務工作者減輕線上社交環境中虛假資訊影響力的重要資產。</paragraph>

##### **SynesLM: A Unified Approach for Audio-visual Speech Recognition and Translation via Language Model and Synthetic Data**
2408.00624v1 by Yichen Lu, Jiaqi Song, Xuankai Chang, Hengwei Bian, Soumi Maiti, Shinji Watanabe

In this work, we present SynesLM, an unified model which can perform three
multimodal language understanding tasks: audio-visual automatic speech
recognition(AV-ASR) and visual-aided speech/machine translation(VST/VMT).
Unlike previous research that focused on lip motion as visual cues for speech
signals, our work explores more general visual information within entire
frames, such as objects and actions. Additionally, we use synthetic image data
to enhance the correlation between image and speech data. We benchmark SynesLM
against the How2 dataset, demonstrating performance on par with
state-of-the-art (SOTA) models dedicated to AV-ASR while maintaining our
multitasking framework. Remarkably, for zero-shot AV-ASR, SynesLM achieved SOTA
performance by lowering the Word Error Rate (WER) from 43.4% to 39.4% on the
VisSpeech Dataset. Furthermore, our results in VST and VMT outperform the
previous results, improving the BLEU score to 43.5 from 37.2 for VST, and to
54.8 from 54.4 for VMT.

摘要：在這項工作中，我們展示了 SynesLM，一個統一的模型，可以執行三項多模態語言理解任務：音訊視覺自動語音辨識 (AV-ASR) 和視覺輔助語音/機器翻譯 (VST/VMT)。與以往專注於唇部動作作為語音訊號視覺線索的研究不同，我們的研究探索了整個畫面中更通用的視覺資訊，例如物件和動作。此外，我們使用合成影像資料來增強影像和語音資料之間的關聯性。我們以 How2 資料集來評量 SynesLM，證明其效能與專門用於 AV-ASR 的最新 (SOTA) 模型相當，同時維持我們的多任務架構。值得注意的是，對於零次學習 AV-ASR，SynesLM 在 VisSpeech 資料集上將字元錯誤率 (WER) 從 43.4% 降低到 39.4%，達到了 SOTA 效能。此外，我們在 VST 和 VMT 中的結果優於先前的結果，將 VST 的 BLEU 分數從 37.2 提升到 43.5，將 VMT 的 BLEU 分數從 54.4 提升到 54.8。

##### **Are Bigger Encoders Always Better in Vision Large Models?**
2408.00620v1 by Bozhou Li, Hao Liang, Zimo Meng, Wentao Zhang

In recent years, multimodal large language models (MLLMs) have shown strong
potential in real-world applications. They are developing rapidly due to their
remarkable ability to comprehend multimodal information and their inherent
powerful cognitive and reasoning capabilities. Among MLLMs, vision language
models (VLM) stand out for their ability to understand vision information.
However, the scaling trend of VLMs under the current mainstream paradigm has
not been extensively studied. Whether we can achieve better performance by
training even larger models is still unclear. To address this issue, we
conducted experiments on the pretraining stage of MLLMs. We conduct our
experiment using different encoder sizes and large language model (LLM) sizes.
Our findings indicate that merely increasing the size of encoders does not
necessarily enhance the performance of VLMs. Moreover, we analyzed the effects
of LLM backbone parameter size and data quality on the pretraining outcomes.
Additionally, we explored the differences in scaling laws between LLMs and
VLMs.

摘要：近年來，多模態大型語言模型（MLLM）在實際應用中展現強大的潛力。由於其理解多模態資訊的非凡能力，以及其內在強大的認知和推理能力，它們正快速發展。在 MLLM 中，視覺語言模型（VLM）因其理解視覺資訊的能力而脫穎而出。然而，在目前的主流範例下，VLM 的擴充趨勢尚未廣泛研究。我們是否能透過訓練更大規模的模型來獲得更好的效能，仍不清楚。為了解決這個問題，我們對 MLLM 的預訓練階段進行了實驗。我們使用不同的編碼器大小和大型語言模型（LLM）大小來進行實驗。我們的研究結果表明，單純增加編碼器的規模並不會必然提升 VLM 的效能。此外，我們分析了 LLM 主幹參數大小和資料品質對預訓練結果的影響。此外，我們探討了 LLM 和 VLM 之間的擴充法則差異。

##### **Unlocking Fair Use in the Generative AI Supply Chain: A Systematized Literature Review**
2408.00613v1 by Amruta Mahuli, Asia Biega

Through a systematization of generative AI (GenAI) stakeholder goals and
expectations, this work seeks to uncover what value different stakeholders see
in their contributions to the GenAI supply line. This valuation enables us to
understand whether fair use advocated by GenAI companies to train model
progresses the copyright law objective of promoting science and arts. While
assessing the validity and efficacy of the fair use argument, we uncover
research gaps and potential avenues for future works for researchers and
policymakers to address.

摘要：透過系統化生成式 AI (GenAI) 利益相關者的目標和預期，這項工作試圖揭示不同利益相關者在對 GenAI 供應鏈的貢獻中看到的價值。這種估值使我們能夠了解 GenAI 公司提倡的合理使用是否能促進科學和藝術的著作權法目標，以訓練模型進度。在評估合理使用論點的有效性和效能時，我們發現了研究差距和研究人員和政策制定者未來工作的潛在途徑，以加以解決。

##### **Downstream bias mitigation is all you need**
2408.00612v1 by Arkadeep Baksi, Rahul Singh, Tarun Joshi

The advent of transformer-based architectures and large language models
(LLMs) have significantly advanced the performance of natural language
processing (NLP) models. Since these LLMs are trained on huge corpuses of data
from the web and other sources, there has been a major concern about harmful
prejudices that may potentially be transferred from the data. In many
applications, these pre-trained LLMs are fine-tuned on task specific datasets,
which can further contribute to biases. This paper studies the extent of biases
absorbed by LLMs during pre-training as well as task-specific behaviour after
fine-tuning. We found that controlled interventions on pre-trained LLMs, prior
to fine-tuning, have minimal effect on lowering biases in classifiers. However,
the biases present in domain-specific datasets play a much bigger role, and
hence mitigating them at this stage has a bigger impact. While pre-training
does matter, but after the model has been pre-trained, even slight changes to
co-occurrence rates in the fine-tuning dataset has a significant effect on the
bias of the model.

摘要：隨著基於Transformer的架構和大語言模型 (LLM) 的出現，自然語言處理 (NLP) 模型的效能已大幅提升。由於這些 LLM 是根據網際網路和其他來源的大量資料庫訓練的，因此對於可能從資料傳遞的有害偏見存在著重大的疑慮。在許多應用程式中，這些預先訓練的 LLM 會針對特定任務的資料集進行微調，這可能會進一步造成偏見。本文探討 LLM 在預先訓練期間吸收的偏見程度，以及微調後的特定任務行為。我們發現，在微調之前對預先訓練的 LLM 進行受控介入，對於降低分類器的偏見影響甚微。然而，特定領域資料集中存在的偏見扮演了更重要的角色，因此在此階段減輕這些偏見會產生更大的影響。雖然預先訓練很重要，但在模型預先訓練後，即使微調資料集中共現率的微小變化也會對模型的偏見產生顯著影響。

##### **Non Verbis, Sed Rebus: Large Language Models are Weak Solvers of Italian Rebuses**
2408.00584v1 by Gabriele Sarti, Tommaso Caselli, Malvina Nissim, Arianna Bisazza

Rebuses are puzzles requiring constrained multi-step reasoning to identify a
hidden phrase from a set of images and letters. In this work, we introduce a
large collection of verbalized rebuses for the Italian language and use it to
assess the rebus-solving capabilities of state-of-the-art large language
models. While general-purpose systems such as LLaMA-3 and GPT-4o perform poorly
on this task, ad-hoc fine-tuning seems to improve models' performance. However,
we find that performance gains from training are largely motivated by
memorization. Our results suggest that rebus solving remains a challenging test
bed to evaluate large language models' linguistic proficiency and sequential
instruction-following skills.

摘要：謎語是需要受限多步驟推理才能從一組圖像和字母中找出隱藏短語的謎題。在本文中，我們引進了一大批義大利語的文字謎語，並用它來評估最先進的大語言模型的謎語解題能力。儘管 LLaMA-3 和 GPT-4o 等通用系統在此任務上的表現不佳，但特別微調似乎能提升模型的表現。然而，我們發現訓練產生的表現提升，在很大程度上是由於記憶。我們的結果顯示，謎語解題仍然是大語言模型語言能力和循序指令遵循技能評估的嚴峻考驗。

##### **Alleviating Hallucination in Large Vision-Language Models with Active Retrieval Augmentation**
2408.00555v1 by Xiaoye Qu, Qiyuan Chen, Wei Wei, Jishuo Sun, Jianfeng Dong

Despite the remarkable ability of large vision-language models (LVLMs) in
image comprehension, these models frequently generate plausible yet factually
incorrect responses, a phenomenon known as hallucination.Recently, in large
language models (LLMs), augmenting LLMs by retrieving information from external
knowledge resources has been proven as a promising solution to mitigate
hallucinations.However, the retrieval augmentation in LVLM significantly lags
behind the widespread applications of LVLM. Moreover, when transferred to
augmenting LVLMs, sometimes the hallucination degree of the model is even
exacerbated.Motivated by the research gap and counter-intuitive phenomenon, we
introduce a novel framework, the Active Retrieval-Augmented large
vision-language model (ARA), specifically designed to address hallucinations by
incorporating three critical dimensions: (i) dissecting the retrieval targets
based on the inherent hierarchical structures of images. (ii) pinpointing the
most effective retrieval methods and filtering out the reliable retrieval
results. (iii) timing the retrieval process to coincide with episodes of low
certainty, while circumventing unnecessary retrieval during periods of high
certainty. To assess the capability of our proposed ARA model in reducing
hallucination, we employ three widely used LVLM models (LLaVA-1.5, Qwen-VL, and
mPLUG-Owl2) across four benchmarks. Our empirical observations suggest that by
utilizing fitting retrieval mechanisms and timing the retrieval judiciously, we
can effectively mitigate the hallucination problem. We hope that this study can
provide deeper insights into how to adapt the retrieval augmentation to LVLMs
for reducing hallucinations with more effective retrieval and minimal retrieval
occurrences.

摘要：儘管大型視覺語言模型 (LVLMs) 在影像理解方面擁有非凡能力，但這些模型經常產生看似合理卻事實上不正確的回應，這種現象稱為幻覺。最近，在大型語言模型 (LLMs) 中，透過從外部知識資源擷取資訊來擴充 LLM 已被證明是一種減輕幻覺的有前途的解決方案。然而，LVLM 中的擷取擴充顯著落後於 LVLM 的廣泛應用。此外，當轉移到擴充 LVLMs 時，有時模型的幻覺程度甚至會加劇。在研究差距和反直覺現象的激勵下，我們引入了新穎的架構，主動擷取擴充大型視覺語言模型 (ARA)，專門設計用於透過納入三個關鍵面向來解決幻覺問題：(i) 根據影像的內在階層結構剖析擷取目標。(ii) 精確找出最有效的擷取方法，並過濾出可靠的擷取結果。(iii) 安排擷取流程與低確定性事件一致，同時在高確定性期間迴避不必要的擷取。為了評估我們提出的 ARA 模型在減少幻覺方面的能力，我們在四個基準測試中採用了三個廣泛使用的 LVLM 模型 (LLaVA-1.5、Qwen-VL 和 mPLUG-Owl2)。我們的經驗觀察表明，透過善用合適的擷取機制並明智安排擷取時機，我們可以有效減輕幻覺問題。我們希望這項研究可以提供更深入的見解，說明如何調整擷取擴充以適用於 LVLMs，以更有效的擷取和最少的擷取發生次數來減少幻覺。

##### **Mitigating Multilingual Hallucination in Large Vision-Language Models**
2408.00550v1 by Xiaoye Qu, Mingyang Song, Wei Wei, Jianfeng Dong, Yu Cheng

While Large Vision-Language Models (LVLMs) have exhibited remarkable
capabilities across a wide range of tasks, they suffer from hallucination
problems, where models generate plausible yet incorrect answers given the input
image-query pair. This hallucination phenomenon is even more severe when
querying the image in non-English languages, while existing methods for
mitigating hallucinations in LVLMs only consider the English scenarios. In this
paper, we make the first attempt to mitigate this important multilingual
hallucination in LVLMs. With thorough experiment analysis, we found that
multilingual hallucination in LVLMs is a systemic problem that could arise from
deficiencies in multilingual capabilities or inadequate multimodal abilities.
To this end, we propose a two-stage Multilingual Hallucination Removal (MHR)
framework for LVLMs, aiming to improve resistance to hallucination for both
high-resource and low-resource languages. Instead of relying on the intricate
manual annotations of multilingual resources, we fully leverage the inherent
capabilities of the LVLM and propose a novel cross-lingual alignment method,
which generates multiple responses for each image-query input and then
identifies the hallucination-aware pairs for each language. These data pairs
are finally used for direct preference optimization to prompt the LVLMs to
favor non-hallucinating responses. Experimental results show that our MHR
achieves a substantial reduction in hallucination generation for LVLMs.
Notably, on our extended multilingual POPE benchmark, our framework delivers an
average increase of 19.0% in accuracy across 13 different languages. Our code
and model weights are available at https://github.com/ssmisya/MHR

摘要：<paragraph>儘管大型視覺語言模型 (LVLMs) 在各種任務中展現出非凡的能力，但它們卻飽受幻覺問題所苦，也就是模型根據輸入的影像查詢對產生看似合理但實際上不正確的答案。這種幻覺現象在以非英語語言查詢影像時會更加嚴重，而現有針對 LVLMs 中幻覺問題的緩解方法僅考慮英語情境。在本文中，我們首次嘗試緩解 LVLMs 中這種重要的多語言幻覺問題。透過徹底的實驗分析，我們發現 LVLMs 中的多語言幻覺是一個系統性問題，可能源自多語言能力的不足或多模態能力的不足。有鑑於此，我們針對 LVLMs 提出一個兩階段的多語言幻覺移除 (MHR) 架構，目標是提升高資源語言和低資源語言對幻覺的抵抗力。我們並未依賴多語言資源的複雜手動註解，而是充分利用 LVLM 的內在能力，並提出一個創新的跨語言對齊方法，為每個影像查詢輸入產生多個回應，然後針對每種語言找出具備幻覺感知能力的配對。這些資料配對最後用於直接偏好最佳化，促使 LVLMs 偏好非幻覺的回應。實驗結果顯示，我們的 MHR 大幅減少了 LVLMs 中的幻覺產生。值得注意的是，在我們擴充的多語言 POPE 基準測試中，我們的架構在 13 種不同語言中平均提升了 19.0% 的準確度。我們的程式碼和模型權重可在 https://github.com/ssmisya/MHR 取得</paragraph>

##### **Illustrating Classic Brazilian Books using a Text-To-Image Diffusion Model**
2408.00544v1 by Felipe Mahlow, André Felipe Zanella, William Alberto Cruz Castañeda, Regilene Aparecida Sarzi-Ribeiro

In recent years, Generative Artificial Intelligence (GenAI) has undergone a
profound transformation in addressing intricate tasks involving diverse
modalities such as textual, auditory, visual, and pictorial generation. Within
this spectrum, text-to-image (TTI) models have emerged as a formidable approach
to generating varied and aesthetically appealing compositions, spanning
applications from artistic creation to realistic facial synthesis, and
demonstrating significant advancements in computer vision, image processing,
and multimodal tasks. The advent of Latent Diffusion Models (LDMs) signifies a
paradigm shift in the domain of AI capabilities. This article delves into the
feasibility of employing the Stable Diffusion LDM to illustrate literary works.
For this exploration, seven classic Brazilian books have been selected as case
studies. The objective is to ascertain the practicality of this endeavor and to
evaluate the potential of Stable Diffusion in producing illustrations that
augment and enrich the reader's experience. We will outline the beneficial
aspects, such as the capacity to generate distinctive and contextually
pertinent images, as well as the drawbacks, including any shortcomings in
faithfully capturing the essence of intricate literary depictions. Through this
study, we aim to provide a comprehensive assessment of the viability and
efficacy of utilizing AI-generated illustrations in literary contexts,
elucidating both the prospects and challenges encountered in this pioneering
application of technology.

摘要：近年来，生成式人工智能（GenAI）在解决涉及文本、听觉、视觉和图像生成等不同模态的复杂任务方面经历了深刻的变革。在这个范围内，文本到图像（TTI）模型已经成为一种强大的方法，可以生成各种美观动人的构图，跨越从艺术创作到逼真的面部合成等应用，并在计算机视觉、图像处理和多模态任务方面展示了重大进展。潜在扩散模型（LDM）的出现标志着人工智能能力领域的一个范式转变。本文深入探讨了采用 Stable Diffusion LDM 来阐释文学作品的可行性。对于这项探索，选择了七本经典的巴西书籍作为案例研究。目的是确定这项工作的实用性，并评估 Stable Diffusion 在制作插图方面的潜力，以增强和丰富读者的体验。我们将概述有益的方面，例如生成独特且在上下文上相关的图像的能力，以及缺点，包括忠实捕捉复杂文学描绘的精髓方面的任何缺陷。通过这项研究，我们旨在对在文学语境中使用人工智能生成插图的可行性和有效性进行全面评估，阐明在这项开创性的技术应用中遇到的前景和挑战。

##### **The Energy Cost of Artificial Intelligence of Things Lifecycle**
2408.00540v1 by Shih-Kai Chou, Jernej Hribar, Mihael Mohorčič, Carolina Fortuna

Artificial intelligence (AI)coupled with existing Internet of Things (IoT)
enables more streamlined and autonomous operations across various economic
sectors. Consequently, the paradigm of Artificial Intelligence of Things (AIoT)
having AI techniques at its core implies additional energy and carbon costs
that may become significant with more complex neural architectures. To better
understand the energy and Carbon Footprint (CF) of some AIoT components, very
recent studies employ conventional metrics. However, these metrics are not
designed to capture energy efficiency aspects of inference. In this paper, we
propose a new metric, the Energy Cost of AIoT Lifecycle (eCAL) to capture the
overall energy cost of inference over the lifecycle of an AIoT system. We
devise a new methodology for determining eCAL of an AIoT system by analyzing
the complexity of data manipulation in individual components involved in the
AIoT lifecycle and derive the overall and per bit energy consumption. With eCAL
we show that the better a model is and the more it is used, the more energy
efficient an inference is. For an example AIoT configuration, eCAL for making
$100$ inferences is $1.43$ times higher than for $1000$ inferences. We also
evaluate the CF of the AIoT system by calculating the equivalent CO$_{2}$
emissions based on the energy consumption and the Carbon Intensity (CI) across
different countries. Using 2023 renewable data, our analysis reveals that
deploying an AIoT system in Germany results in emitting $4.62$ times higher
CO$_2$ than in Finland, due to latter using more low-CI energy sources.

摘要：人工智慧 (AI) 搭配現有的物聯網 (IoT)
能使各種經濟部門的運作更流暢且更自主。因此，以人工智慧技術為核心的物聯網人工智慧 (AIoT) 典範，暗示著額外的能源與碳成本，而這可能會隨著更複雜的神經架構而顯著增加。為了更了解一些 AIoT 元件的能源與碳足跡 (CF)，最近的研究採用傳統的指標。然而，這些指標並非設計用來捕捉推理的能源效率面向。在本文中，我們提出一個新的指標，即 AIoT 生命周期能源成本 (eCAL)，以捕捉 AIoT 系統生命周期中推理的整體能源成本。我們設計了一種新的方法來確定 AIoT 系統的 eCAL，方法是分析參與 AIoT 生命周期中個別元件中資料處理的複雜性，並推導出整體和每位元能源消耗。有了 eCAL，我們表明模型越好且使用越多，推理的能源效率就越高。對於範例 AIoT 組態，進行 100 次推理的 eCAL 比進行 1000 次推理高出 1.43 倍。我們也透過計算基於不同國家/地區的能源消耗和碳強度 (CI) 的等效 CO2 排放量，來評估 AIoT 系統的 CF。我們的分析使用 2023 年可再生能源資料，揭示在德國部署 AIoT 系統會排放比芬蘭高出 4.62 倍的 CO2，這是因為後者使用更多低 CI 能源。

##### **Intermittent Semi-working Mask: A New Masking Paradigm for LLMs**
2408.00539v1 by Mingcong Lu, Jiangcai Zhu, Wang Hao, Zheng Li, Shusheng Zhang, Kailai Shao, Chao Chen, Nan Li, Feng Wang, Xin Lu

Multi-turn dialogues are a key interaction method between humans and Large
Language Models (LLMs), as conversations extend over multiple rounds, keeping
LLMs' high generation quality and low latency is a challenge. Mainstream LLMs
can be grouped into two categories based on masking strategy: causal LLM and
prefix LLM. Several works have demonstrated that prefix LLMs tend to outperform
causal ones in scenarios that heavily depend on historical context such as
multi-turn dialogues or in-context learning, thanks to their bidirectional
attention on prefix sequences. However, prefix LLMs have an inherent
inefficient training problem in multi-turn dialogue datasets. In addition, the
attention mechanism of prefix LLM makes it unable to reuse Key-Value Cache (KV
Cache) across dialogue rounds to reduce generation latency. In this paper, we
propose a novel masking scheme called Intermittent Semi-working Mask (ISM) to
address these problems. Specifically, we apply alternate bidirectional and
unidirectional attention on queries and answers in the dialogue history. In
this way, ISM is able to maintain the high quality of prefix LLM and low
generation latency of causal LLM, simultaneously. Extensive experiments
illustrate that our ISM achieves significant performance.

摘要：多輪對話是人類與大型語言模型 (LLM) 之間的一種關鍵互動方法，由於對話會持續多輪，因此維持 LLM 的高生成品質和低延遲是一項挑戰。主流 LLM 可以根據遮罩策略分為兩類：因果 LLM 和前綴 LLM。多項研究已證明，前綴 LLM 在高度依賴歷史脈絡的場景中往往優於因果 LLM，例如多輪對話或情境學習，這要歸功於它們對前綴序列的雙向關注。然而，前綴 LLM 在多輪對話資料集中存在固有低效率的訓練問題。此外，前綴 LLM 的注意力機制使其無法在對話回合中重複使用鍵值快取 (KV 快取) 來降低生成延遲。在本文中，我們提出了一種稱為間歇半工作遮罩 (ISM) 的新遮罩方案來解決這些問題。具體來說，我們對對話記錄中的查詢和答案套用交替的雙向和單向注意力。透過這種方式，ISM 能夠同時維持前綴 LLM 的高品質和因果 LLM 的低生成延遲。廣泛的實驗說明我們的 ISM 獲得了顯著的效能。

##### **The Monetisation of Toxicity: Analysing YouTube Content Creators and Controversy-Driven Engagement**
2408.00534v1 by Thales Bertaglia, Catalina Goanta, Adriana Iamnitchi

YouTube is a major social media platform that plays a significant role in
digital culture, with content creators at its core. These creators often engage
in controversial behaviour to drive engagement, which can foster toxicity. This
paper presents a quantitative analysis of controversial content on YouTube,
focusing on the relationship between controversy, toxicity, and monetisation.
We introduce a curated dataset comprising 20 controversial YouTube channels
extracted from Reddit discussions, including 16,349 videos and more than 105
million comments. We identify and categorise monetisation cues from video
descriptions into various models, including affiliate marketing and direct
selling, using lists of URLs and keywords. Additionally, we train a machine
learning model to measure the toxicity of comments in these videos. Our
findings reveal that while toxic comments correlate with higher engagement,
they negatively impact monetisation, indicating that controversy-driven
interaction does not necessarily lead to financial gain. We also observed
significant variation in monetisation strategies, with some creators showing
extensive monetisation despite high toxicity levels. Our study introduces a
curated dataset, lists of URLs and keywords to categorise monetisation, a
machine learning model to measure toxicity, and is a significant step towards
understanding the complex relationship between controversy, engagement, and
monetisation on YouTube. The lists used for detecting and categorising
monetisation cues are available on https://github.com/thalesbertaglia/toxmon.

摘要：YouTube 是一个重要的社交媒體平台，在數位文化中扮演著重要的角色，而內容創作者則是其核心。這些創作者經常參與有爭議的行為以推動參與，這可能會助長毒性。本文提出對 YouTube 上有爭議內容的量化分析，重點關注爭議、毒性和獲利之間的關係。我們引入了一個精選的資料集，其中包含從 Reddit 討論中提取的 20 個有爭議的 YouTube 頻道，包括 16,349 個影片和超過 1.05 億則留言。我們從影片說明中識別並分類出各種獲利線索，包括聯盟行銷和直接銷售，並使用 URL 和關鍵字清單。此外，我們訓練了一個機器學習模型來衡量這些影片中留言的毒性。我們的研究結果顯示，雖然有毒的留言與較高的參與度相關，但它們會對獲利產生負面影響，這表示由爭議驅動的互動不一定會帶來財務收益。我們還觀察到獲利策略有顯著差異，一些創作者即使毒性程度很高，也表現出廣泛的獲利。我們的研究引入了精選的資料集、用於分類獲利的 URL 和關鍵字清單、用於衡量毒性的機器學習模型，並且是了解 YouTube 上爭議、參與度和獲利之間複雜關係的重要一步。用於偵測和分類獲利線索的清單可在 https://github.com/thalesbertaglia/toxmon 上取得。

##### **Jailbreaking Text-to-Image Models with LLM-Based Agents**
2408.00523v1 by Yingkai Dong, Zheng Li, Xiangtao Meng, Ning Yu, Shanqing Guo

Recent advancements have significantly improved automated task-solving
capabilities using autonomous agents powered by large language models (LLMs).
However, most LLM-based agents focus on dialogue, programming, or specialized
domains, leaving gaps in addressing generative AI safety tasks. These gaps are
primarily due to the challenges posed by LLM hallucinations and the lack of
clear guidelines. In this paper, we propose Atlas, an advanced LLM-based
multi-agent framework that integrates an efficient fuzzing workflow to target
generative AI models, specifically focusing on jailbreak attacks against
text-to-image (T2I) models with safety filters. Atlas utilizes a
vision-language model (VLM) to assess whether a prompt triggers the T2I model's
safety filter. It then iteratively collaborates with both LLM and VLM to
generate an alternative prompt that bypasses the filter. Atlas also enhances
the reasoning abilities of LLMs in attack scenarios by leveraging multi-agent
communication, in-context learning (ICL) memory mechanisms, and the
chain-of-thought (COT) approach. Our evaluation demonstrates that Atlas
successfully jailbreaks several state-of-the-art T2I models in a black-box
setting, which are equipped with multi-modal safety filters. In addition, Atlas
outperforms existing methods in both query efficiency and the quality of the
generated images.

摘要：<paragraph>最近的進展已經大幅改進了自動任務解決能力，使用大型語言模型（LLM）驅動的自主代理。然而，大多數基於 LLM 的代理專注於對話、程式設計或專業領域，在解決生成式 AI 安全任務方面留下了空白。這些空白主要是由於 LLM 幻覺帶來的挑戰和缺乏明確的指導方針。在本文中，我們提出 Atlas，一個基於 LLM 的先進多代理框架，它整合了一個高效的模糊測試工作流程來針對生成式 AI 模型，特別關注對具有安全過濾器的文字到圖像（T2I）模型的越獄攻擊。Atlas 利用視覺語言模型（VLM）來評估提示是否觸發了 T2I 模型的安全過濾器。然後，它與 LLM 和 VLM 進行反覆協作，以生成一個繞過過濾器的替代提示。Atlas 還通過利用多代理通信、情境學習（ICL）記憶機制和思維鏈（COT）方法，增強了 LLM 在攻擊場景中的推理能力。我們的評估表明，Atlas 在黑盒設置中成功越獄了幾個最先進的 T2I 模型，這些模型配備了多模式安全過濾器。此外，Atlas 在查詢效率和生成圖像的品質方面都優於現有方法。</paragraph>

##### **A new approach for encoding code and assisting code understanding**
2408.00521v1 by Mengdan Fan, Wei Zhang, Haiyan Zhao, Zhi Jin

Some companies(e.g., Microsoft Research and Google DeepMind) have discovered
some of the limitations of GPTs autoregressive paradigm next-word prediction,
manifested in the model lack of planning, working memory, backtracking, and
reasoning skills. GPTs rely on a local and greedy process of generating the
next word, without a global understanding of the task or the output.We have
confirmed the above limitations through specialized empirical studies of code
comprehension. Although GPT4 is good at producing fluent and coherent text, it
cannot handle complex logic and generate new code that haven not been seen, and
it relies too much on the formatting of the prompt to generate the correct
code.We propose a new paradigm for code understanding that goes beyond the
next-word prediction paradigm, inspired by the successful application of
diffusion techniques to image generation(Dalle2, Sora) and protein structure
generation(AlphaFold3), which have no autoregressive constraints.Instead of
encoding the code in a form that mimics natural language, we encode the code as
a heterogeneous image paradigm with a memory of global information that mimics
both images and protein structures.We then refer to Sora's CLIP upstream
text-to-image encoder model to design a text-to-code encoder model that can be
applied to various downstream code understanding tasks.The model learns the
global understanding of code under the new paradigm heterogeneous image,
connects the encoding space of text and code, and encodes the input of text
into the vector of code most similar to it.Using self-supervised comparative
learning on 456,360 text-code pairs, the model achieved a zero-shot prediction
of new data. This work is the basis for future work on code generation using
diffusion techniques under a new paradigm to avoid autoregressive limitations.

摘要：一些公司（例如 Microsoft Research 和 Google DeepMind）已經發現 GPT 自動迴歸範例中的一些限制，即下一個字詞預測，體現在模型缺乏規劃、工作記憶、回溯和推理技能。GPT 依賴於產生下一個字詞的局部和貪婪過程，而沒有對任務或輸出的全局理解。我們已經通過程式碼理解的專門經驗研究確認了上述限制。儘管 GPT4 擅長產生流暢且連貫的文字，但它無法處理複雜的邏輯和產生未曾見過的新程式碼，而且它過於依賴提示的格式來產生正確的程式碼。我們提出了超越下一個字詞預測範例的程式碼理解新範例，靈感來自擴散技術成功應用於影像產生（Dalle2、Sora）和蛋白質結構產生（AlphaFold3），它們沒有自動迴歸約束。我們沒有使用模仿自然語言的形式對程式碼進行編碼，而是將程式碼編碼為異質影像範例，其中包含模仿影像和蛋白質結構的全局資訊記憶體。然後，我們參考 Sora 的 CLIP 上游文字轉影像編碼器模型，設計一個文字轉程式碼編碼器模型，該模型可應用於各種下游程式碼理解任務。該模型在新的範例異質影像下學習程式碼的全局理解，連接文字和程式碼的編碼空間，並將文字輸入編碼成與其最相似的程式碼向量。使用 456,360 個文字程式碼對上的自我監督比較學習，該模型實現了新資料的零次學習預測。這項工作是使用擴散技術在新的範例下進行程式碼產生的未來工作的基礎，以避免自動迴歸限制。

##### **GalleryGPT: Analyzing Paintings with Large Multimodal Models**
2408.00491v1 by Yi Bin, Wenhao Shi, Yujuan Ding, Zhiqiang Hu, Zheng Wang, Yang Yang, See-Kiong Ng, Heng Tao Shen

Artwork analysis is important and fundamental skill for art appreciation,
which could enrich personal aesthetic sensibility and facilitate the critical
thinking ability. Understanding artworks is challenging due to its subjective
nature, diverse interpretations, and complex visual elements, requiring
expertise in art history, cultural background, and aesthetic theory. However,
limited by the data collection and model ability, previous works for
automatically analyzing artworks mainly focus on classification, retrieval, and
other simple tasks, which is far from the goal of AI. To facilitate the
research progress, in this paper, we step further to compose comprehensive
analysis inspired by the remarkable perception and generation ability of large
multimodal models. Specifically, we first propose a task of composing paragraph
analysis for artworks, i.e., painting in this paper, only focusing on visual
characteristics to formulate more comprehensive understanding of artworks. To
support the research on formal analysis, we collect a large dataset
PaintingForm, with about 19k painting images and 50k analysis paragraphs. We
further introduce a superior large multimodal model for painting analysis
composing, dubbed GalleryGPT, which is slightly modified and fine-tuned based
on LLaVA architecture leveraging our collected data. We conduct formal analysis
generation and zero-shot experiments across several datasets to assess the
capacity of our model. The results show remarkable performance improvements
comparing with powerful baseline LMMs, demonstrating its superb ability of art
analysis and generalization. \textcolor{blue}{The codes and model are available
at: https://github.com/steven640pixel/GalleryGPT.

摘要：<paragraph>藝術品分析是藝術鑑賞的重要且基本的技能，
它可以豐富個人的美學素養，促進批判性思考能力。由於其主觀性、多樣化的詮釋和複雜的視覺元素，理解藝術品具有挑戰性，需要藝術史、文化背景和美學理論方面的專業知識。然而，受限於數據收集和模型能力，以往自動化分析藝術品的相關研究主要集中於分類、檢索和其他簡單的任務，這遠遠達不到 AI 的目標。為了促進研究進展，本文進一步提出由大型多模態模型卓越的感知和生成能力所激發的綜合分析。具體來說，我們首先提出了一個針對藝術品（本文中為繪畫）撰寫段落分析的任務，僅專注於視覺特徵，以制定對藝術品的更全面理解。為了支持形式分析的研究，我們收集了一個大型數據集 PaintingForm，其中包含約 19k 幅繪畫圖像和 50k 段分析段落。我們進一步引入了一個用於繪畫分析撰寫的優越大型多模態模型 GalleryGPT，該模型基於 LLaVA 架構並利用我們收集的數據進行了微調和微調。我們在幾個數據集上進行了形式分析生成和零樣本實驗，以評估我們模型的能力。結果顯示，與強大的基線 LMM 相比，我們的模型取得了顯著的性能改進，證明了其在藝術分析和泛化方面的卓越能力。\textcolor{blue}{代碼和模型可在以下位置獲得：https://github.com/steven640pixel/GalleryGPT。</paragraph>

##### **Graph Representation Learning via Causal Diffusion for Out-of-Distribution Recommendation**
2408.00490v1 by Chu Zhao, Enneng Yang, Yuliang Liang, Pengxiang Lan, Yuting Liu, Jianzhe Zhao, Guibing Guo, Xingwei Wang

Graph Neural Networks (GNNs)-based recommendation algorithms typically assume
that training and testing data are drawn from independent and identically
distributed (IID) spaces. However, this assumption often fails in the presence
of out-of-distribution (OOD) data, resulting in significant performance
degradation. In this study, we construct a Structural Causal Model (SCM) to
analyze interaction data, revealing that environmental confounders (e.g., the
COVID-19 pandemic) lead to unstable correlations in GNN-based models, thus
impairing their generalization to OOD data. To address this issue, we propose a
novel approach, graph representation learning via causal diffusion
(CausalDiffRec) for OOD recommendation. This method enhances the model's
generalization on OOD data by eliminating environmental confounding factors and
learning invariant graph representations. Specifically, we use backdoor
adjustment and variational inference to infer the real environmental
distribution, thereby eliminating the impact of environmental confounders. This
inferred distribution is then used as prior knowledge to guide the
representation learning in the reverse phase of the diffusion process to learn
the invariant representation. In addition, we provide a theoretical derivation
that proves optimizing the objective function of CausalDiffRec can encourage
the model to learn environment-invariant graph representations, thereby
achieving excellent generalization performance in recommendations under
distribution shifts. Our extensive experiments validate the effectiveness of
CausalDiffRec in improving the generalization of OOD data, and the average
improvement is up to 10.69% on Food, 18.83% on KuaiRec, 22.41% on Yelp2018, and
11.65% on Douban datasets.

摘要：<paragraph>基於圖神經網路 (GNN) 的推薦演算法通常假設訓練和測試資料是從獨立同分布 (IID) 空間中提取的。然而，這個假設在存在非分布 (OOD) 資料時常常會失敗，導致效能大幅下降。在本研究中，我們建構了一個結構因果模型 (SCM) 來分析互動資料，揭示環境混雜因子（例如，COVID-19 大流行）會導致基於 GNN 的模型中出現不穩定的相關性，進而損害其對 OOD 資料的泛化。為了解決這個問題，我們提出了一種創新的方法，即透過因果擴散進行圖表示學習（CausalDiffRec），以進行 OOD 推薦。此方法透過消除環境混雜因子和學習不變圖表示，增強模型對 OOD 資料的泛化。具體來說，我們使用後門調整和變異推論來推論真實的環境分佈，從而消除環境混雜因子的影響。然後將這個推論出的分佈用作先驗知識，以引導擴散過程的反向階段中的表示學習，以學習不變表示。此外，我們提供了理論推導，證明最佳化 CausalDiffRec 的目標函數可以促使模型學習與環境無關的圖表示，從而在分佈轉移下實現出色的推薦泛化效能。我們廣泛的實驗驗證了 CausalDiffRec 在改善 OOD 資料泛化方面的有效性，在 Food 上的平均改善幅度高達 10.69%，在 KuaiRec 上為 18.83%，在 Yelp2018 上為 22.41%，在 Douban 資料集上為 11.65%。</paragraph>

##### **A Systematic Review on Long-Tailed Learning**
2408.00483v1 by Chongsheng Zhang, George Almpanidis, Gaojuan Fan, Binquan Deng, Yanbo Zhang, Ji Liu, Aouaidjia Kamel, Paolo Soda, João Gama

Long-tailed data is a special type of multi-class imbalanced data with a very
large amount of minority/tail classes that have a very significant combined
influence. Long-tailed learning aims to build high-performance models on
datasets with long-tailed distributions, which can identify all the classes
with high accuracy, in particular the minority/tail classes. It is a
cutting-edge research direction that has attracted a remarkable amount of
research effort in the past few years. In this paper, we present a
comprehensive survey of latest advances in long-tailed visual learning. We
first propose a new taxonomy for long-tailed learning, which consists of eight
different dimensions, including data balancing, neural architecture, feature
enrichment, logits adjustment, loss function, bells and whistles, network
optimization, and post hoc processing techniques. Based on our proposed
taxonomy, we present a systematic review of long-tailed learning methods,
discussing their commonalities and alignable differences. We also analyze the
differences between imbalance learning and long-tailed learning approaches.
Finally, we discuss prospects and future directions in this field.

摘要：長尾數據是一種特殊類型，具有大量少數/尾部類別的多類別不平衡數據，這些類別具有非常顯著的綜合影響。長尾學習旨在建立具有長尾分佈的數據集的高性能模型，該模型可以識別所有類別，特別是少數/尾部類別，具有很高的準確度。這是一個尖端的的研究方向，在過去幾年中吸引了大量的研究工作。在本文中，我們對長尾視覺學習的最新進展進行了全面的調查。我們首先提出了長尾學習的新分類法，其中包括八個不同的維度，包括數據平衡、神經架構、特徵豐富、對數調整、損失函數、花裡胡哨、網路最佳化和事後處理技術。根據我們提出的分類法，我們對長尾學習方法進行了系統的回顧，討論了它們的共性和可比性差異。我們還分析了不平衡學習和長尾學習方法之間的差異。最後，我們討論了該領域的前景和未來方向。

##### **HBot: A Chatbot for Healthcare Applications in Traditional Chinese Medicine Based on Human Body 3D Visualization**
2408.00481v1 by Bolin Zhang, Zhiwei Yi, Jiahao Wang, Dianbo Sui, Zhiying Tu, Dianhui Chu

The unique diagnosis and treatment techniques and remarkable clinical
efficacy of traditional Chinese medicine (TCM) make it play an important role
in the field of elderly care and healthcare, especially in the rehabilitation
of some common chronic diseases of the elderly. Therefore, building a TCM
chatbot for healthcare application will help users obtain consultation services
in a direct and natural way. However, concepts such as acupuncture points
(acupoints) and meridians involved in TCM always appear in the consultation,
which cannot be displayed intuitively. To this end, we develop a
\textbf{h}ealthcare chat\textbf{bot} (HBot) based on a human body model in 3D
and knowledge graph, which provides conversational services such as knowledge
Q\&A, prescription recommendation, moxibustion therapy recommendation, and
acupoint search. When specific acupoints are involved in the conversations
between user and HBot, the 3D body will jump to the corresponding acupoints and
highlight them. Moreover, Hbot can also be used in training scenarios to
accelerate the teaching process of TCM by intuitively displaying acupuncture
points and knowledge cards. The demonstration video is available at
https://www.youtube.com/watch?v=UhQhutSKkTU . Our code and dataset are publicly
available at Gitee: https://gitee.com/plabrolin/interactive-3d-acup.git

摘要：中醫獨特的診治手法和顯著的臨床療效，在老年照護與保健領域中扮演著重要的角色，特別是在老年人常見慢性疾病的復健上。因此，建構一個中醫醫療照護聊天機器人，將有助於使用者以直接且自然的方式取得諮詢服務。然而，中醫所涉及的穴位、經絡等概念，在諮詢時總是會出現，而這些無法直觀地顯示出來。為了解決這個問題，我們開發了一個基於 3D 人體模型和知識圖譜的醫療照護聊天機器人（HBot），它提供了知識問答、處方推薦、艾灸療法推薦和穴位查詢等對話服務。當使用者與 HBot 的對話中涉及到具體穴位時，3D 人體會跳轉到對應的穴位並將其高亮顯示。此外，HBot 還可以用於培訓場景中，通過直觀地顯示穴位和知識卡片，來加速中醫教學的進程。示範影片可於 https://www.youtube.com/watch?v=UhQhutSKkTU 取得。我們的程式碼和資料集已於 Gitee 公開：https://gitee.com/plabrolin/interactive-3d-acup.git

##### **Towards Explainable and Interpretable Musical Difficulty Estimation: A Parameter-efficient Approach**
2408.00473v1 by Pedro Ramoneda, Vsevolod Eremenko, Alexandre D'Hooge, Emilia Parada-Cabaleiro, Xavier Serra

Estimating music piece difficulty is important for organizing educational
music collections. This process could be partially automatized to facilitate
the educator's role. Nevertheless, the decisions performed by prevalent
deep-learning models are hardly understandable, which may impair the acceptance
of such a technology in music education curricula. Our work employs explainable
descriptors for difficulty estimation in symbolic music representations.
Furthermore, through a novel parameter-efficient white-box model, we outperform
previous efforts while delivering interpretable results. These comprehensible
outcomes emulate the functionality of a rubric, a tool widely used in music
education. Our approach, evaluated in piano repertoire categorized in 9
classes, achieved 41.4% accuracy independently, with a mean squared error (MSE)
of 1.7, showing precise difficulty estimation. Through our baseline, we
illustrate how building on top of past research can offer alternatives for
music difficulty assessment which are explainable and interpretable. With this,
we aim to promote a more effective communication between the Music Information
Retrieval (MIR) community and the music education one.

摘要：評估音樂作品的難度對於組織教學音樂合集來說非常重要。這個過程可以部分自動化，以促進教育者的角色。儘管如此，流行的深度學習模型做出的決定難以理解，這可能會損害這種技術在音樂教育課程中的接受度。我們的作品採用可解釋的描述符來估計符號音樂表示中的難度。此外，通過一個新的參數有效的白盒模型，我們在提供可解釋的結果的同時，超越了以往的努力。這些可理解的結果模擬了評分標準的功能，評分標準是音樂教育中廣泛使用的一種工具。我們的做法在分為 9 类的鋼琴曲目中進行了評估，獨立實現了 41.4% 的準確率，均方誤差 (MSE) 為 1.7，顯示出精確的難度估計。通過我們的基準，我們說明了如何建立在過去的研究之上，可以提供可解釋和可理解的音樂難度評估的替代方案。通過這個，我們旨在促進音樂信息檢索 (MIR) 社群與音樂教育社群之間更有效的溝通。

##### **DiscipLink: Unfolding Interdisciplinary Information Seeking Process via Human-AI Co-Exploration**
2408.00447v1 by Chengbo Zheng, Yuanhao Zhang, Zeyu Huang, Chuhan Shi, Minrui Xu, Xiaojuan Ma

Interdisciplinary studies often require researchers to explore literature in
diverse branches of knowledge. Yet, navigating through the highly scattered
knowledge from unfamiliar disciplines poses a significant challenge. In this
paper, we introduce DiscipLink, a novel interactive system that facilitates
collaboration between researchers and large language models (LLMs) in
interdisciplinary information seeking (IIS). Based on users' topics of
interest, DiscipLink initiates exploratory questions from the perspectives of
possible relevant fields of study, and users can further tailor these
questions. DiscipLink then supports users in searching and screening papers
under selected questions by automatically expanding queries with
disciplinary-specific terminologies, extracting themes from retrieved papers,
and highlighting the connections between papers and questions. Our evaluation,
comprising a within-subject comparative experiment and an open-ended
exploratory study, reveals that DiscipLink can effectively support researchers
in breaking down disciplinary boundaries and integrating scattered knowledge in
diverse fields. The findings underscore the potential of LLM-powered tools in
fostering information-seeking practices and bolstering interdisciplinary
research.

摘要：跨領域研究往往需要研究人員探索不同知識領域的文獻。然而，在不熟悉的領域中穿梭於高度分散的知識，構成了一項重大的挑戰。在本文中，我們介紹了 DiscipLink，一個新穎的互動式系統，它促進了研究人員與大型語言模型 (LLM) 在跨領域資訊搜尋 (IIS) 中的協作。根據使用者的興趣主題，DiscipLink 從可能相關的研究領域的角度提出探索性問題，而使用者可以進一步調整這些問題。接著，DiscipLink 透過自動擴充查詢，使用特定於領域的術語，從檢索到的論文中萃取主題，並強調論文與問題之間的關聯，來支援使用者在所選問題之下搜尋和篩選論文。我們的評量包含一個受試者內比較實驗和一個開放式的探索性研究，結果顯示 DiscipLink 能有效地支援研究人員打破學科界線，並整合不同領域中分散的知識。這些發現強調了 LLM 驅動工具在促進資訊搜尋實務和強化跨領域研究方面的潛力。

##### **Ontological Relations from Word Embeddings**
2408.00444v1 by Mathieu d'Aquin, Emmanuel Nauer

It has been reliably shown that the similarity of word embeddings obtained
from popular neural models such as BERT approximates effectively a form of
semantic similarity of the meaning of those words. It is therefore natural to
wonder if those embeddings contain enough information to be able to connect
those meanings through ontological relationships such as the one of
subsumption. If so, large knowledge models could be built that are capable of
semantically relating terms based on the information encapsulated in word
embeddings produced by pre-trained models, with implications not only for
ontologies (ontology matching, ontology evolution, etc.) but also on the
ability to integrate ontological knowledge in neural models. In this paper, we
test how embeddings produced by several pre-trained models can be used to
predict relations existing between classes and properties of popular
upper-level and general ontologies. We show that even a simple feed-forward
architecture on top of those embeddings can achieve promising accuracies, with
varying generalisation abilities depending on the input data. To achieve that,
we produce a dataset that can be used to further enhance those models, opening
new possibilities for applications integrating knowledge from web ontologies.

摘要：可靠地表明，从流行神经模型（例如 BERT）获得的词嵌入的相似性有效地近似了这些词的意义的语义相似性。因此，自然会想知道这些嵌入是否包含足够的信息，以便能够通过本体关系（例如从属关系）来连接这些含义。如果是这样，则可以构建大型知识模型，这些模型能够基于预训练模型产生的词嵌入中封装的信息在语义上关联术语，不仅对本体（本体匹配、本体演化等）产生影响，而且对在神经模型中集成本体知识的能力产生影响。在本文中，我们测试了由几个预训练模型产生的嵌入如何用于预测流行的上层和通用本体的类和属性之间存在的关联。我们表明，即使在这些嵌入之上建立一个简单的前馈架构也能实现有希望的准确性，其泛化能力因输入数据而异。为了实现这一目标，我们生成了一个数据集，可用于进一步增强这些模型，为集成来自 Web 本体知识的应用程序开辟了新的可能性。

##### **Focus, Distinguish, and Prompt: Unleashing CLIP for Efficient and Flexible Scene Text Retrieval**
2408.00441v1 by Gangyan Zeng, Yuan Zhang, Jin Wei, Dongbao Yang, Peng Zhang, Yiwen Gao, Xugong Qin, Yu Zhou

Scene text retrieval aims to find all images containing the query text from
an image gallery. Current efforts tend to adopt an Optical Character
Recognition (OCR) pipeline, which requires complicated text detection and/or
recognition processes, resulting in inefficient and inflexible retrieval.
Different from them, in this work we propose to explore the intrinsic potential
of Contrastive Language-Image Pre-training (CLIP) for OCR-free scene text
retrieval. Through empirical analysis, we observe that the main challenges of
CLIP as a text retriever are: 1) limited text perceptual scale, and 2)
entangled visual-semantic concepts. To this end, a novel model termed FDP
(Focus, Distinguish, and Prompt) is developed. FDP first focuses on scene text
via shifting the attention to the text area and probing the hidden text
knowledge, and then divides the query text into content word and function word
for processing, in which a semantic-aware prompting scheme and a distracted
queries assistance module are utilized. Extensive experiments show that FDP
significantly enhances the inference speed while achieving better or
competitive retrieval accuracy compared to existing methods. Notably, on the
IIIT-STR benchmark, FDP surpasses the state-of-the-art model by 4.37% with a 4
times faster speed. Furthermore, additional experiments under phrase-level and
attribute-aware scene text retrieval settings validate FDP's particular
advantages in handling diverse forms of query text. The source code will be
publicly available at https://github.com/Gyann-z/FDP.

摘要：場景文字檢索旨在從圖像庫中找出所有包含查詢文字的圖像。目前的努力傾向於採用光學字元辨識 (OCR) 管線，這需要複雜的文字偵測和/或辨識過程，導致檢索效率低下且不靈活。與它們不同，在這項工作中，我們提議探索對比式語言影像預訓練 (CLIP) 在無 OCR 場景文字檢索中的內在潛力。透過實證分析，我們觀察到 CLIP 作為文字檢索器的主要挑戰有：1) 受限的文字感知規模，以及 2) 糾纏的視覺語義概念。為此，開發了一個稱為 FDP（專注、區分和提示）的新穎模型。FDP 首先透過將注意力轉移到文字區域並探查隱藏的文字知識來專注於場景文字，然後將查詢文字分成內容字和功能字進行處理，其中利用了語義感知提示方案和分散查詢輔助模組。廣泛的實驗顯示，與現有方法相比，FDP 大幅提升了推論速度，同時達到了更好或具有競爭力的檢索準確度。值得注意的是，在 IIIT-STR 基準上，FDP 以快 4 倍的速度超越了最先進的模型，達到了 4.37%。此外，在詞組級別和屬性感知場景文字檢索設定下的額外實驗驗證了 FDP 在處理多樣化的查詢文字形式方面的特殊優勢。原始碼將公開在 https://github.com/Gyann-z/FDP。

##### **A Qualitative Study on Using ChatGPT for Software Security: Perception vs. Practicality**
2408.00435v1 by M. Mehdi Kholoosi, M. Ali Babar, Roland Croft

Artificial Intelligence (AI) advancements have enabled the development of
Large Language Models (LLMs) that can perform a variety of tasks with
remarkable semantic understanding and accuracy. ChatGPT is one such LLM that
has gained significant attention due to its impressive capabilities for
assisting in various knowledge-intensive tasks. Due to the knowledge-intensive
nature of engineering secure software, ChatGPT's assistance is expected to be
explored for security-related tasks during the development/evolution of
software. To gain an understanding of the potential of ChatGPT as an emerging
technology for supporting software security, we adopted a two-fold approach.
Initially, we performed an empirical study to analyse the perceptions of those
who had explored the use of ChatGPT for security tasks and shared their views
on Twitter. It was determined that security practitioners view ChatGPT as
beneficial for various software security tasks, including vulnerability
detection, information retrieval, and penetration testing. Secondly, we
designed an experiment aimed at investigating the practicality of this
technology when deployed as an oracle in real-world settings. In particular, we
focused on vulnerability detection and qualitatively examined ChatGPT outputs
for given prompts within this prominent software security task. Based on our
analysis, responses from ChatGPT in this task are largely filled with generic
security information and may not be appropriate for industry use. To prevent
data leakage, we performed this analysis on a vulnerability dataset compiled
after the OpenAI data cut-off date from real-world projects covering 40
distinct vulnerability types and 12 programming languages. We assert that the
findings from this study would contribute to future research aimed at
developing and evaluating LLMs dedicated to software security.

摘要：<paragraph>人工智慧 (AI) 的進步促成了大型語言模型 (LLM) 的發展，此模型可以執行各種任務，具備卓越的語意理解和準確度。ChatGPT 就是其中一個大型語言模型，由於其在協助各種知識密集型任務方面具有令人印象深刻的能力，因此備受關注。由於工程安全軟體的知識密集性，預計在軟體開發/演進過程中，將探索 ChatGPT 的協助，以執行與安全相關的任務。為了了解 ChatGPT 作為支援軟體安全的新興技術的潛力，我們採取了雙管齊下的方法。最初，我們進行了一項實證研究，以分析那些已經探索將 ChatGPT 用於安全任務的人的看法，並在 Twitter 上分享他們的觀點。確定安全從業人員將 ChatGPT 視為對各種軟體安全任務有益，包括漏洞偵測、資訊擷取和滲透測試。其次，我們設計了一個實驗，旨在調查在現實世界中將此技術部署為神諭時的實用性。特別是，我們專注於漏洞偵測，並在這個突出的軟體安全任務中，對 ChatGPT 對於給定提示的輸出進行定性檢查。根據我們的分析，ChatGPT 在此任務中的回應在很大程度上充斥著一般的安全資訊，可能不適合產業使用。為了防止資料外洩，我們在 OpenAI 資料截止日期後編譯的漏洞資料集上執行此分析，該資料集涵蓋了來自現實世界專案的 40 種不同的漏洞類型和 12 種程式語言。我們斷言，這項研究的發現將有助於未來的研究，目的是開發和評估專門用於軟體安全的 LLM。</paragraph>

##### **CARMIL: Context-Aware Regularization on Multiple Instance Learning models for Whole Slide Images**
2408.00427v1 by Thiziri Nait Saada, Valentina Di-Proietto, Benoit Schmauch, Katharina Von Loga, Lucas Fidon

Multiple Instance Learning (MIL) models have proven effective for cancer
prognosis from Whole Slide Images. However, the original MIL formulation
incorrectly assumes the patches of the same image to be independent, leading to
a loss of spatial context as information flows through the network.
Incorporating contextual knowledge into predictions is particularly important
given the inclination for cancerous cells to form clusters and the presence of
spatial indicators for tumors. State-of-the-art methods often use attention
mechanisms eventually combined with graphs to capture spatial knowledge. In
this paper, we take a novel and transversal approach, addressing this issue
through the lens of regularization. We propose Context-Aware Regularization for
Multiple Instance Learning (CARMIL), a versatile regularization scheme designed
to seamlessly integrate spatial knowledge into any MIL model. Additionally, we
present a new and generic metric to quantify the Context-Awareness of any MIL
model when applied to Whole Slide Images, resolving a previously unexplored gap
in the field. The efficacy of our framework is evaluated for two survival
analysis tasks on glioblastoma (TCGA GBM) and colon cancer data (TCGA COAD).

摘要：多实例学习 (MIL) 模型已证明对全切片图像的癌症预后有效。然而，原始的 MIL 公式错误地假设同一图像的补丁是独立的，导致空间上下文在信息流经网络时丢失。考虑到癌细胞形成簇的倾向和肿瘤的空间指标，将上下文知识纳入预测中尤为重要。最先进的方法通常使用注意力机制，最终与图结合来捕获空间知识。在本文中，我们采用了一种新颖且横向的方法，通过正则化的视角来解决这个问题。我们提出了用于多实例学习的上下文感知正则化 (CARMIL)，这是一种通用正则化方案，旨在将空间知识无缝集成到任何 MIL 模型中。此外，我们提出了一个新的通用指标来量化任何 MIL 模型在应用于全切片图像时的上下文感知度，从而解决了该领域以前未探索的差距。我们的框架的有效性在胶质母细胞瘤 (TCGA GBM) 和结肠癌数据 (TCGA COAD) 的两个生存分析任务中得到评估。

##### **MPT-PAR:Mix-Parameters Transformer for Panoramic Activity Recognition**
2408.00420v1 by Wenqing Gan, Yan Sun, Feiran Liu, Xiangfeng Luo

The objective of the panoramic activity recognition task is to identify
behaviors at various granularities within crowded and complex environments,
encompassing individual actions, social group activities, and global
activities. Existing methods generally use either parameter-independent modules
to capture task-specific features or parameter-sharing modules to obtain common
features across all tasks. However, there is often a strong interrelatedness
and complementary effect between tasks of different granularities that previous
methods have yet to notice. In this paper, we propose a model called MPT-PAR
that considers both the unique characteristics of each task and the synergies
between different tasks simultaneously, thereby maximizing the utilization of
features across multi-granularity activity recognition. Furthermore, we
emphasize the significance of temporal and spatial information by introducing a
spatio-temporal relation-enhanced module and a scene representation learning
module, which integrate the the spatio-temporal context of action and global
scene into the feature map of each granularity. Our method achieved an overall
F1 score of 47.5\% on the JRDB-PAR dataset, significantly outperforming all the
state-of-the-art methods.

摘要：全景活动识别任务的目的是识别在拥挤而复杂的环境中各种粒度下的行为，包括个人动作、社交团体活动和全局活动。现有方法通常使用与参数无关的模块来捕获特定任务特征，或使用参数共享模块来获取所有任务的共同特征。然而，不同粒度任务之间通常存在很强的相互关联性和互补效应，而之前的研究尚未注意到这一点。在本文中，我们提出了一个名为 MPT-PAR 的模型，该模型同时考虑了每个任务的独特特征和不同任务之间的协同作用，从而最大化了多粒度活动识别中特征的利用率。此外，我们通过引入时空关系增强模块和场景表示学习模块来强调时间和空间信息的重要性，该模块将动作和全局场景的时空上下文整合到每个粒度的特征图中。我们的方法在 JRDB-PAR 数据集上的总体 F1 得分为 47.5%，明显优于所有最先进的方法。

##### **DriveArena: A Closed-loop Generative Simulation Platform for Autonomous Driving**
2408.00415v1 by Xuemeng Yang, Licheng Wen, Yukai Ma, Jianbiao Mei, Xin Li, Tiantian Wei, Wenjie Lei, Daocheng Fu, Pinlong Cai, Min Dou, Botian Shi, Liang He, Yong Liu, Yu Qiao

This paper presented DriveArena, the first high-fidelity closed-loop
simulation system designed for driving agents navigating in real scenarios.
DriveArena features a flexible, modular architecture, allowing for the seamless
interchange of its core components: Traffic Manager, a traffic simulator
capable of generating realistic traffic flow on any worldwide street map, and
World Dreamer, a high-fidelity conditional generative model with infinite
autoregression. This powerful synergy empowers any driving agent capable of
processing real-world images to navigate in DriveArena's simulated environment.
The agent perceives its surroundings through images generated by World Dreamer
and output trajectories. These trajectories are fed into Traffic Manager,
achieving realistic interactions with other vehicles and producing a new scene
layout. Finally, the latest scene layout is relayed back into World Dreamer,
perpetuating the simulation cycle. This iterative process fosters closed-loop
exploration within a highly realistic environment, providing a valuable
platform for developing and evaluating driving agents across diverse and
challenging scenarios. DriveArena signifies a substantial leap forward in
leveraging generative image data for the driving simulation platform, opening
insights for closed-loop autonomous driving. Code will be available soon on
GitHub: https://github.com/PJLab-ADG/DriveArena

摘要：本文展示了 DriveArena，這是第一個專為在真實場景中導航的駕駛代理而設計的高保真閉環模擬系統。
DriveArena 採用靈活的模組化架構，允許其核心組件無縫交換：Traffic Manager，一個能夠在全球任何街道地圖上產生逼真交通流的交通模擬器，以及 World Dreamer，一個具有無限自迴歸的高保真條件式生成模型。這個強大的協同效應讓任何能夠處理真實世界影像的駕駛代理都能在 DriveArena 的模擬環境中導航。
代理透過 World Dreamer 生成的影像感知其周圍環境並輸出軌跡。這些軌跡被輸入 Traffic Manager，與其他車輛進行逼真的互動並產生新的場景佈局。最後，最新的場景佈局被傳遞回 World Dreamer，持續進行模擬循環。這個反覆的過程促進了在高度逼真環境中的閉環探索，為在各種具有挑戰性的場景中開發和評估駕駛代理提供了有價值的平台。DriveArena 標誌著在利用生成影像資料進行駕駛模擬平台方面取得了重大進展，為閉環自動駕駛開啟了新的見解。代碼將很快在 GitHub 上提供：https://github.com/PJLab-ADG/DriveArena

##### **In-Context Example Selection via Similarity Search Improves Low-Resource Machine Translation**
2408.00397v1 by Armel Zebaze, Benoît Sagot, Rachel Bawden

The ability of generative large language models (LLMs) to perform in-context
learning has given rise to a large body of research into how best to prompt
models for various natural language processing tasks. In this paper, we focus
on machine translation (MT), a task that has been shown to benefit from
in-context translation examples. However no systematic studies have been
published on how best to select examples, and mixed results have been reported
on the usefulness of similarity-based selection over random selection. We
provide a study covering multiple LLMs and multiple in-context example
retrieval strategies, comparing multilingual sentence embeddings. We cover
several language directions, representing different levels of language
resourcedness (English into French, German, Swahili and Wolof). Contrarily to
previously published results, we find that sentence embedding similarity can
improve MT, especially for low-resource language directions, and discuss the
balance between selection pool diversity and quality. We also highlight
potential problems with the evaluation of LLM-based MT and suggest a more
appropriate evaluation protocol, adapting the COMET metric to the evaluation of
LLMs. Code and outputs are freely available at
https://github.com/ArmelRandy/ICL-MT.

摘要：生成式大型语言模型 (LLM) 在语境中进行学习的能力催生了许多关于如何最好地提示模型执行各种自然语言处理任务的研究。在本文中，我们重点关注机器翻译 (MT)，一项已被证明可以从语境翻译示例中受益的任务。然而，还没有关于如何最好地选择示例的系统性研究，并且已经报道了基于相似性的选择优于随机选择的用处。我们提供了一项涵盖多个 LLM 和多个语境示例检索策略的研究，比较了多语言句子嵌入。我们涵盖了几个语言方向，代表了不同级别的语言资源（英语到法语、德语、斯瓦希里语和沃洛夫语）。与先前公布的结果相反，我们发现句子嵌入相似性可以改善机器翻译，特别是对于低资源语言方向，并讨论了选择池多样性和质量之间的平衡。我们还强调了基于 LLM 的机器翻译评估的潜在问题，并提出了一个更合适的评估协议，将 COMET 指标调整为评估 LLM。代码和输出可在 https://github.com/ArmelRandy/ICL-MT 免费获得。

##### **Enhancing Whole Slide Pathology Foundation Models through Stain Normalization**
2408.00380v1 by Juseung Yun, Yi Hu, Jinhyung Kim, Jongseong Jang, Soonyoung Lee

Recent advancements in digital pathology have led to the development of
numerous foundational models that utilize self-supervised learning on patches
extracted from gigapixel whole slide images (WSIs). While this approach
leverages vast amounts of unlabeled data, we have discovered a significant
issue: features extracted from these self-supervised models tend to cluster by
individual WSIs, a phenomenon we term WSI-specific feature collapse. This
problem can potentially limit the model's generalization ability and
performance on various downstream tasks. To address this issue, we introduce
Stain Normalized Pathology Foundational Model, a novel foundational model
trained on patches that have undergone stain normalization. Stain normalization
helps reduce color variability arising from different laboratories and
scanners, enabling the model to learn more consistent features. Stain
Normalized Pathology Foundational Model is trained using 285,153,903 patches
extracted from a total of 34,795 WSIs, combining data from The Cancer Genome
Atlas (TCGA) and the Genotype-Tissue Expression (GTEx) project. Our experiments
demonstrate that Stain Normalized Pathology Foundational Model significantly
mitigates the feature collapse problem, indicating that the model has learned
more generalized features rather than overfitting to individual WSI
characteristics. We compared Stain Normalized Pathology Foundational Model with
state-of-the-art models across six downstream task datasets, and our results
show that \name{} achieves excellent performance relative to the number of WSIs
used and the model's parameter count. This suggests that the application of
stain normalization has substantially improved the model's efficiency and
generalization capabilities.

摘要：<paragraph>數位病理學的最新進展促成了許多基礎模型的開發，這些模型利用自監督學習來處理從千兆像素全玻片影像 (WSI) 中提取的區塊。儘管這種方法利用了大量的未標籤資料，我們發現了一個重大的問題：從這些自監督模型中提取的特徵傾向於按個別 WSI 分群，我們將這種現象稱為 WSI 特定特徵崩潰。此問題可能會限制模型的泛化能力和在各種下游任務上的效能。為了解決這個問題，我們引入了染色標準化病理基礎模型，這是一個新穎的基礎模型，針對經過染色標準化處理的區塊進行訓練。染色標準化有助於減少來自不同實驗室和掃描儀的色彩變異性，使模型能夠學習更一致的特徵。染色標準化病理基礎模型使用從總共 34,795 個 WSI 中提取的 285,153,903 個區塊進行訓練，結合了癌症基因組圖譜 (TCGA) 和基因型組織表達 (GTEx) 專案的資料。我們的實驗證明，染色標準化病理基礎模型顯著減輕了特徵崩潰問題，這表示模型已經學習到更廣義的特徵，而不是過度擬合到個別 WSI 特徵。我們在六個下游任務資料集上將染色標準化病理基礎模型與最先進的模型進行比較，我們的結果顯示，\name{} 相對於所使用的 WSI 數量和模型的參數數量，達到了極佳的效能。這表明染色標準化的應用大幅提升了模型的效率和泛化能力。</paragraph>

##### **On the Limitations and Prospects of Machine Unlearning for Generative AI**
2408.00376v1 by Shiji Zhou, Lianzhe Wang, Jiangnan Ye, Yongliang Wu, Heng Chang

Generative AI (GenAI), which aims to synthesize realistic and diverse data
samples from latent variables or other data modalities, has achieved remarkable
results in various domains, such as natural language, images, audio, and
graphs. However, they also pose challenges and risks to data privacy, security,
and ethics. Machine unlearning is the process of removing or weakening the
influence of specific data samples or features from a trained model, without
affecting its performance on other data or tasks. While machine unlearning has
shown significant efficacy in traditional machine learning tasks, it is still
unclear if it could help GenAI become safer and aligned with human desire. To
this end, this position paper provides an in-depth discussion of the machine
unlearning approaches for GenAI. Firstly, we formulate the problem of machine
unlearning tasks on GenAI and introduce the background. Subsequently, we
systematically examine the limitations of machine unlearning on GenAI models by
focusing on the two representative branches: LLMs and image generative
(diffusion) models. Finally, we provide our prospects mainly from three
aspects: benchmark, evaluation metrics, and utility-unlearning trade-off, and
conscientiously advocate for the future development of this field.

摘要：生成式 AI (GenAI) 旨在從潛在變數或其他資料模式中合成逼真且多樣化的資料範例，已在自然語言、影像、音訊和圖形等各種領域中取得顯著成果。然而，它們也對資料隱私、安全性與道德構成挑戰和風險。機器遺忘是移除或減弱特定資料範例或特徵對已訓練模型的影響，同時不影響其在其他資料或任務上的效能。雖然機器遺忘已在傳統機器學習任務中展現顯著的功效，但仍不清楚它是否能協助 GenAI 變得更安全且符合人類的期望。為此，本立場文件深入探討了 GenAI 的機器遺忘方法。首先，我們制定 GenAI 上機器遺忘任務的問題，並介紹背景。接著，我們有系統地檢視機器遺忘在 GenAI 模型上的限制，重點放在兩個代表性的分支：LLM 和影像生成（擴散）模型。最後，我們主要從基準、評估指標和效用遺忘權衡三個面向提供我們的展望，並審慎倡議該領域的未來發展。

##### **Conformal Trajectory Prediction with Multi-View Data Integration in Cooperative Driving**
2408.00374v1 by Xi Chen, Rahul Bhadani, Larry Head

Current research on trajectory prediction primarily relies on data collected
by onboard sensors of an ego vehicle. With the rapid advancement in connected
technologies, such as vehicle-to-vehicle (V2V) and vehicle-to-infrastructure
(V2I) communication, valuable information from alternate views becomes
accessible via wireless networks. The integration of information from
alternative views has the potential to overcome the inherent limitations
associated with a single viewpoint, such as occlusions and limited field of
view. In this work, we introduce V2INet, a novel trajectory prediction
framework designed to model multi-view data by extending existing single-view
models. Unlike previous approaches where the multi-view data is manually fused
or formulated as a separate training stage, our model supports end-to-end
training, enhancing both flexibility and performance. Moreover, the predicted
multimodal trajectories are calibrated by a post-hoc conformal prediction
module to get valid and efficient confidence regions. We evaluated the entire
framework using the real-world V2I dataset V2X-Seq. Our results demonstrate
superior performance in terms of Final Displacement Error (FDE) and Miss Rate
(MR) using a single GPU. The code is publicly available at:
\url{https://github.com/xichennn/V2I_trajectory_prediction}.

摘要：目前關於軌跡預測的研究主要依賴於自我車輛上搭載感測器所收集的資料。隨著車聯網技術的快速發展，例如車對車 (V2V) 和車對基礎設施 (V2I) 通訊，來自備用視角的寶貴資訊可透過無線網路存取。整合來自備用視角的資訊有潛力克服與單一視角相關的固有限制，例如遮擋和受限視野。在這項工作中，我們引進 V2INet，這是一個新穎的軌跡預測架構，旨在透過擴充現有的單一視角模型來建構多視角資料。與先前的做法不同，先前的做法是手動融合多視角資料或將其制定為一個獨立的訓練階段，我們的模型支援端對端的訓練，提升了彈性和效能。此外，預測的多模態軌跡由事後共形預測模組校正，以取得有效且精確的信心區域。我們使用真實世界的 V2I 資料集 V2X-Seq 評估了整個架構。我們的結果證明，使用單一 GPU 時，在最終位移誤差 (FDE) 和遺漏率 (MR) 方面表現出優異的效能。程式碼已公開於：\url{https://github.com/xichennn/V2I_trajectory_prediction}。

##### **DiM-Gesture: Co-Speech Gesture Generation with Adaptive Layer Normalization Mamba-2 framework**
2408.00370v1 by Fan Zhang, Naye Ji, Fuxing Gao, Bozuo Zhao, Jingmei Wu, Yanbing Jiang, Hui Du, Zhenqing Ye, Jiayang Zhu, WeiFan Zhong, Leyao Yan, Xiaomeng Ma

Speech-driven gesture generation is an emerging domain within virtual human
creation, where current methods predominantly utilize Transformer-based
architectures that necessitate extensive memory and are characterized by slow
inference speeds. In response to these limitations, we propose
\textit{DiM-Gestures}, a novel end-to-end generative model crafted to create
highly personalized 3D full-body gestures solely from raw speech audio,
employing Mamba-based architectures. This model integrates a Mamba-based fuzzy
feature extractor with a non-autoregressive Adaptive Layer Normalization
(AdaLN) Mamba-2 diffusion architecture. The extractor, leveraging a Mamba
framework and a WavLM pre-trained model, autonomously derives implicit,
continuous fuzzy features, which are then unified into a singular latent
feature. This feature is processed by the AdaLN Mamba-2, which implements a
uniform conditional mechanism across all tokens to robustly model the interplay
between the fuzzy features and the resultant gesture sequence. This innovative
approach guarantees high fidelity in gesture-speech synchronization while
maintaining the naturalness of the gestures. Employing a diffusion model for
training and inference, our framework has undergone extensive subjective and
objective evaluations on the ZEGGS and BEAT datasets. These assessments
substantiate our model's enhanced performance relative to contemporary
state-of-the-art methods, demonstrating competitive outcomes with the DiTs
architecture (Persona-Gestors) while optimizing memory usage and accelerating
inference speed.

摘要：語音驅動手勢生成是虛擬人類創造中一個新興領域，其中當前方法主要利用 Transformer 架構，需要大量的記憶體，並且特徵是推論速度慢。為了應對這些限制，我們提出了 \textit{DiM-Gestures}，這是一個新穎的端到端生成模型，專門用於僅從原始語音音訊建立高度個人化的 3D 全身手勢，使用基於 Mamba 的架構。此模型將基於 Mamba 的模糊特徵萃取器與非自迴歸適應層正規化 (AdaLN) Mamba-2 擴散架構整合在一起。萃取器利用 Mamba 框架和 WavLM 預訓練模型，自主地推導出隱含的、連續的模糊特徵，然後將這些特徵統一成一個單一的潛在特徵。此特徵由 AdaLN Mamba-2 處理，它在所有標記之間實作一個統一的條件機制，以穩健地模擬模糊特徵與結果手勢序列之間的交互作用。這種創新的方法保證了手勢語音同步的高保真度，同時保持手勢的自然性。透過採用擴散模型進行訓練和推論，我們的框架在 ZEGGS 和 BEAT 資料集上進行了廣泛的主觀和客觀評估。這些評估證實了我們的模型相對於當代最先進方法的增強效能，展示了與 DiTs 架構（Persona-Gestors）具有競爭力的成果，同時優化了記憶體使用量並加速了推論速度。

##### **Multimodal Fusion and Coherence Modeling for Video Topic Segmentation**
2408.00365v1 by Hai Yu, Chong Deng, Qinglin Zhang, Jiaqing Liu, Qian Chen, Wen Wang

The video topic segmentation (VTS) task segments videos into intelligible,
non-overlapping topics, facilitating efficient comprehension of video content
and quick access to specific content. VTS is also critical to various
downstream video understanding tasks. Traditional VTS methods using shallow
features or unsupervised approaches struggle to accurately discern the nuances
of topical transitions. Recently, supervised approaches have achieved superior
performance on video action or scene segmentation over unsupervised approaches.
In this work, we improve supervised VTS by thoroughly exploring multimodal
fusion and multimodal coherence modeling. Specifically, (1) we enhance
multimodal fusion by exploring different architectures using cross-attention
and mixture of experts. (2) To generally strengthen multimodality alignment and
fusion, we pre-train and fine-tune the model with multimodal contrastive
learning. (3) We propose a new pre-training task tailored for the VTS task, and
a novel fine-tuning task for enhancing multimodal coherence modeling for VTS.
We evaluate the proposed approaches on educational videos, in the form of
lectures, due to the vital role of topic segmentation of educational videos in
boosting learning experiences. Additionally, we introduce a large-scale Chinese
lecture video dataset to augment the existing English corpus, promoting further
research in VTS. Experiments on both English and Chinese lecture datasets
demonstrate that our model achieves superior VTS performance compared to
competitive unsupervised and supervised baselines.

摘要：影片主題分段 (VTS) 任務將影片分段成可理解且不重疊的主題，有助於有效理解影片內容並快速存取特定內容。VTS 對於各種下游影片理解任務也至關重要。使用淺層特徵或非監督式方法的傳統 VTS 方法難以準確辨別主題轉換的細微差別。最近，監督式方法在影片動作或場景分段方面已獲得優於非監督式方法的卓越效能。在這項工作中，我們透過徹底探索多模態融合和多模態相干性模型來改善監督式 VTS。具體來說，(1) 我們透過使用跨注意力和專家混合來探索不同架構，以增強多模態融合。(2) 為了普遍強化多模態對齊和融合，我們使用多模態對比學習預先訓練並微調模型。(3) 我們提出一個專門針對 VTS 任務量身打造的新預訓練任務，以及一個用於增強 VTS 多模態相干性模型的新微調任務。我們在教育影片（以演講形式呈現）上評估所提出的方法，因為主題分段在提升學習體驗中扮演至關重要的角色。此外，我們引進一個大規模的中文演講影片資料集，以擴充現有的英文語料庫，促進 VTS 的進一步研究。在英文和中文演講資料集上的實驗證明，與具有競爭力的非監督式和監督式基準線相比，我們的模型達到了卓越的 VTS 效能。

##### **DeliLaw: A Chinese Legal Counselling System Based on a Large Language Model**
2408.00357v1 by Nan Xie, Yuelin Bai, Hengyuan Gao, Feiteng Fang, Qixuan Zhao, Zhijian Li, Ziqiang Xue, Liang Zhu, Shiwen Ni, Min Yang

Traditional legal retrieval systems designed to retrieve legal documents,
statutes, precedents, and other legal information are unable to give
satisfactory answers due to lack of semantic understanding of specific
questions. Large Language Models (LLMs) have achieved excellent results in a
variety of natural language processing tasks, which inspired us that we train a
LLM in the legal domain to help legal retrieval. However, in the Chinese legal
domain, due to the complexity of legal questions and the rigour of legal
articles, there is no legal large model with satisfactory practical application
yet. In this paper, we present DeliLaw, a Chinese legal counselling system
based on a large language model. DeliLaw integrates a legal retrieval module
and a case retrieval module to overcome the model hallucination. Users can
consult professional legal questions, search for legal articles and relevant
judgement cases, etc. on the DeliLaw system in a dialogue mode. In addition,
DeliLaw supports the use of English for counseling. we provide the address of
the system: https://data.delilegal.com/lawQuestion.

摘要：傳統的法律檢索系統旨在檢索法律文件、法規、判例和其他法律資訊，由於缺乏對特定問題的語義理解，無法給出令人滿意的答案。大型語言模型 (LLM) 在各種自然語言處理任務中取得了優異的成果，這啟發我們在法律領域訓練一個 LLM 來幫助法律檢索。然而，在中文法律領域，由於法律問題的複雜性和法律條文的嚴謹性，目前還沒有令人滿意的實用應用法律大模型。在本文中，我們提出了 DeliLaw，一個基於大型語言模型的中文法律諮詢系統。DeliLaw 整合了一個法律檢索模組和一個案例檢索模組來克服模型幻覺。使用者可以在 DeliLaw 系統上以對話模式諮詢專業法律問題、搜尋法律條文和相關判決案例等。此外，DeliLaw 支援使用英文進行諮詢。我們提供系統網址：https://data.delilegal.com/lawQuestion。

##### **DNTextSpotter: Arbitrary-Shaped Scene Text Spotting via Improved Denoising Training**
2408.00355v1 by Yu Xie, Qian Qiao, Jun Gao, Tianxiang Wu, Shaoyao Huang, Jiaqing Fan, Ziqiang Cao, Zili Wang, Yue Zhang, Jielei Zhang, Huyang Sun

More and more end-to-end text spotting methods based on Transformer
architecture have demonstrated superior performance. These methods utilize a
bipartite graph matching algorithm to perform one-to-one optimal matching
between predicted objects and actual objects. However, the instability of
bipartite graph matching can lead to inconsistent optimization targets, thereby
affecting the training performance of the model. Existing literature applies
denoising training to solve the problem of bipartite graph matching instability
in object detection tasks. Unfortunately, this denoising training method cannot
be directly applied to text spotting tasks, as these tasks need to perform
irregular shape detection tasks and more complex text recognition tasks than
classification. To address this issue, we propose a novel denoising training
method (DNTextSpotter) for arbitrary-shaped text spotting. Specifically, we
decompose the queries of the denoising part into noised positional queries and
noised content queries. We use the four Bezier control points of the Bezier
center curve to generate the noised positional queries. For the noised content
queries, considering that the output of the text in a fixed positional order is
not conducive to aligning position with content, we employ a masked character
sliding method to initialize noised content queries, thereby assisting in the
alignment of text content and position. To improve the model's perception of
the background, we further utilize an additional loss function for background
characters classification in the denoising training part.Although DNTextSpotter
is conceptually simple, it outperforms the state-of-the-art methods on four
benchmarks (Total-Text, SCUT-CTW1500, ICDAR15, and Inverse-Text), especially
yielding an improvement of 11.3% against the best approach in Inverse-Text
dataset.

摘要：越來越多的基於 Transformer 架構的端到端文字偵測方法已經展示出優異的效能。這些方法利用二部圖匹配演算法，在預測物件和實際物件之間執行一對一最佳匹配。然而，二部圖匹配的不穩定性可能導致不一致的最佳化目標，進而影響模型的訓練效能。現有的文獻將去噪訓練應用於解決物件偵測任務中二部圖匹配不穩定的問題。不幸的是，這種去噪訓練方法無法直接應用於文字偵測任務，因為這些任務需要執行不規則形狀偵測任務和比分類更複雜的文字辨識任務。為了解決這個問題，我們提出了一種針對任意形狀文字偵測的新穎去噪訓練方法 (DNTextSpotter)。具體來說，我們將去噪部分的查詢分解為有雜訊的位置查詢和有雜訊的內容查詢。我們使用貝茲中心曲線的四個貝茲控制點來生成有雜訊的位置查詢。對於有雜訊的內容查詢，考慮到以固定位置順序輸出的文字不利於將位置與內容對齊，我們採用遮罩字元滑動方法來初始化有雜訊的內容查詢，從而協助文字內容和位置的對齊。為了改善模型對背景的感知，我們進一步在去噪訓練部分中利用一個額外的損失函數進行背景字元分類。儘管 DNTextSpotter 在概念上很簡單，但在四個基準（Total-Text、SCUT-CTW1500、ICDAR15 和 Inverse-Text）上都優於最先進的方法，特別是在 Inverse-Text 資料集上相較於最佳方法提升了 11.3%。

##### **A Simple Background Augmentation Method for Object Detection with Diffusion Model**
2408.00350v1 by Yuhang Li, Xin Dong, Chen Chen, Weiming Zhuang, Lingjuan Lyu

In computer vision, it is well-known that a lack of data diversity will
impair model performance. In this study, we address the challenges of enhancing
the dataset diversity problem in order to benefit various downstream tasks such
as object detection and instance segmentation. We propose a simple yet
effective data augmentation approach by leveraging advancements in generative
models, specifically text-to-image synthesis technologies like Stable
Diffusion. Our method focuses on generating variations of labeled real images,
utilizing generative object and background augmentation via inpainting to
augment existing training data without the need for additional annotations. We
find that background augmentation, in particular, significantly improves the
models' robustness and generalization capabilities. We also investigate how to
adjust the prompt and mask to ensure the generated content comply with the
existing annotations. The efficacy of our augmentation techniques is validated
through comprehensive evaluations of the COCO dataset and several other key
object detection benchmarks, demonstrating notable enhancements in model
performance across diverse scenarios. This approach offers a promising solution
to the challenges of dataset enhancement, contributing to the development of
more accurate and robust computer vision models.

摘要：在電腦視覺中，眾所周知資料的多樣性不足會影響模型的效能。在本研究中，我們探討了提升資料集多樣性問題的挑戰，以利於各種下游任務，例如物件偵測和實例分割。我們提出一個簡單但有效的資料擴充方法，利用生成模型的進展，特別是文字轉圖像合成技術，例如 Stable Diffusion。我們的做法專注於產生標記真實影像的變化，利用生成物件和背景擴充，透過修補來擴充現有的訓練資料，而無需額外的註解。我們發現背景擴充，特別是顯著地改善了模型的穩健性和泛化能力。我們還探討如何調整提示和遮罩，以確保產生的內容符合現有的註解。我們透過 COCO 資料集和幾個其他關鍵物件偵測基準的全面評估，驗證了我們的擴充技術的效能，展示了在各種場景中模型效能的顯著提升。這種方法為資料集增強的挑戰提供了有希望的解決方案，有助於開發更準確和穩健的電腦視覺模型。

##### **Advancing Medical Image Segmentation: Morphology-Driven Learning with Diffusion Transformer**
2408.00347v1 by Sungmin Kang, Jaeha Song, Jihie Kim

Understanding the morphological structure of medical images and precisely
segmenting the region of interest or abnormality is an important task that can
assist in diagnosis. However, the unique properties of medical imaging make
clear segmentation difficult, and the high cost and time-consuming task of
labeling leads to a coarse-grained representation of ground truth. Facing with
these problems, we propose a novel Diffusion Transformer Segmentation (DTS)
model for robust segmentation in the presence of noise. We propose an
alternative to the dominant Denoising U-Net encoder through experiments
applying a transformer architecture, which captures global dependency through
self-attention. Additionally, we propose k-neighbor label smoothing, reverse
boundary attention, and self-supervised learning with morphology-driven
learning to improve the ability to identify complex structures. Our model,
which analyzes the morphological representation of images, shows better results
than the previous models in various medical imaging modalities, including CT,
MRI, and lesion images.

摘要：了解醫學影像的形態結構並精確分割感興趣或異常區域是一項重要的任務，有助於診斷。然而，醫學影像的獨特屬性使得清晰的分割變得困難，而標籤的高成本和耗時任務導致了地面實況的粗略表示。面對這些問題，我們提出了一個新的擴散Transformer分割（DTS）模型，用於在有噪聲的情況下進行穩健分割。我們通過應用捕獲全局依賴性的自注意力Transformer架構，提出了一個替代主流去噪 U-Net 編碼器的方案。此外，我們提出了 k 近鄰標籤平滑、反向邊界注意力，以及使用形態驅動學習的自監督學習，以提高識別複雜結構的能力。我們的模型分析了影像的形態表示，在各種醫學影像方式中顯示出比以前模型更好的結果，包括 CT、MRI 和病灶影像。

##### **Neural Graph Matching for Video Retrieval in Large-Scale Video-driven E-commerce**
2408.00346v1 by Houye Ji, Ye Tang, Zhaoxin Chen, Lixi Deng, Jun Hu, Lei Su

With the rapid development of the short video industry, traditional
e-commerce has encountered a new paradigm, video-driven e-commerce, which
leverages attractive videos for product showcases and provides both video and
item services for users. Benefitting from the dynamic and visualized
introduction of items,video-driven e-commerce has shown huge potential in
stimulating consumer confidence and promoting sales. In this paper, we focus on
the video retrieval task, facing the following challenges: (1) Howto handle the
heterogeneities among users, items, and videos? (2)How to mine the
complementarity between items and videos for better user understanding? In this
paper, we first leverage the dual graph to model the co-existing of user-video
and user-item interactions in video-driven e-commerce and innovatively reduce
user preference understanding to a graph matching problem. To solve it, we
further propose a novel bi-level Graph Matching Network(GMN), which mainly
consists of node- and preference-level graph matching. Given a user, node-level
graph matching aims to match videos and items, while preference-level graph
matching aims to match multiple user preferences extracted from both videos and
items. Then the proposed GMN can generate and improve user embedding by
aggregating matched nodes or preferences from the dual graph in a bi-level
manner. Comprehensive experiments show the superiority of the proposed GMN with
significant improvements over state-of-the-art approaches (e.g., AUC+1.9% and
CTR+7.15%). We have developed it on a well-known video-driven e-commerce
platform, serving hundreds of millions of users every day

摘要：<paragraph>隨著短影音產業的快速發展，傳統電商迎來新典範「影音電商」，其利用吸睛的影片進行商品展示，並為使用者提供影音與商品服務。影音電商受益於動態且視覺化的商品介紹，在提升消費者信心及促進銷售上展現龐大潛力。本論文聚焦於影音檢索任務，面臨的挑戰如下：(1)如何處理使用者、商品與影片間的異質性？(2)如何挖掘商品與影片間的互補性，以更佳理解使用者？本論文首先利用雙圖模型化影音電商中使用者-影片與使用者-商品互動的共存，並創新地將使用者偏好理解化約為圖形配對問題。為了解決此問題，我們進一步提出一個新穎的雙層圖形配對網路(GMN)，其主要包含節點層級與偏好層級圖形配對。針對一個使用者，節點層級圖形配對旨在配對影片與商品，而偏好層級圖形配對旨在配對從影片與商品中萃取出的多重使用者偏好。接著，所提出的GMN可以透過雙層方式彙總雙圖中配對的節點或偏好，以產生並改善使用者嵌入。綜合實驗顯示，所提出的GMN優於現有技術方法，並有顯著的進步(例如，AUC+1.9%和CTR+7.15%)。我們已於一個知名的影音電商平台上開發此方法，每天服務上億名使用者</paragraph>

##### **OTAD: An Optimal Transport-Induced Robust Model for Agnostic Adversarial Attack**
2408.00329v1 by Kuo Gai, Sicong Wang, Shihua Zhang

Deep neural networks (DNNs) are vulnerable to small adversarial perturbations
of the inputs, posing a significant challenge to their reliability and
robustness. Empirical methods such as adversarial training can defend against
particular attacks but remain vulnerable to more powerful attacks.
Alternatively, Lipschitz networks provide certified robustness to unseen
perturbations but lack sufficient expressive power. To harness the advantages
of both approaches, we design a novel two-step Optimal Transport induced
Adversarial Defense (OTAD) model that can fit the training data accurately
while preserving the local Lipschitz continuity. First, we train a DNN with a
regularizer derived from optimal transport theory, yielding a discrete optimal
transport map linking data to its features. By leveraging the map's inherent
regularity, we interpolate the map by solving the convex integration problem
(CIP) to guarantee the local Lipschitz property. OTAD is extensible to diverse
architectures of ResNet and Transformer, making it suitable for complex data.
For efficient computation, the CIP can be solved through training neural
networks. OTAD opens a novel avenue for developing reliable and secure deep
learning systems through the regularity of optimal transport maps. Empirical
results demonstrate that OTAD can outperform other robust models on diverse
datasets.

摘要：深度神經網路 (DNN) 容易受到輸入的小幅對抗性擾動影響，對其可靠性和穩健性構成重大挑戰。對抗訓練等經驗方法可以抵禦特定攻擊，但仍然容易受到更強大的攻擊。或者，Lipschitz 網路提供對未見擾動的認證穩健性，但缺乏足夠的表達能力。為了利用兩種方法的優點，我們設計了一個新穎的兩步驟最佳傳輸誘導對抗防禦 (OTAD) 模型，該模型可以準確擬合訓練數據，同時保持局部 Lipschitz 連續性。首先，我們使用源自最佳傳輸理論的正則化器訓練 DNN，產生將數據連結到其特徵的離散最佳傳輸映射。通過利用映射的固有規律性，我們通過求解凸積分問題 (CIP) 來插值映射，以保證局部 Lipschitz 屬性。OTAD 可擴展到 ResNet 和 Transformer 的各種架構，使其適用於複雜數據。為了有效計算，CIP 可以通過訓練神經網路來求解。OTAD 通過最佳傳輸映射的規律性，為開發可靠且安全的深度學習系統開闢了一條新途徑。經驗結果表明，OTAD 在各種數據集上可以優於其他穩健模型。

##### **ADBM: Adversarial diffusion bridge model for reliable adversarial purification**
2408.00315v1 by Xiao Li, Wenxuan Sun, Huanran Chen, Qiongxiu Li, Yining Liu, Yingzhe He, Jie Shi, Xiaolin Hu

Recently Diffusion-based Purification (DiffPure) has been recognized as an
effective defense method against adversarial examples. However, we find
DiffPure which directly employs the original pre-trained diffusion models for
adversarial purification, to be suboptimal. This is due to an inherent
trade-off between noise purification performance and data recovery quality.
Additionally, the reliability of existing evaluations for DiffPure is
questionable, as they rely on weak adaptive attacks. In this work, we propose a
novel Adversarial Diffusion Bridge Model, termed ADBM. ADBM directly constructs
a reverse bridge from the diffused adversarial data back to its original clean
examples, enhancing the purification capabilities of the original diffusion
models. Through theoretical analysis and experimental validation across various
scenarios, ADBM has proven to be a superior and robust defense mechanism,
offering significant promise for practical applications.

摘要：最近，基于扩散的净化（DiffPure）已被公认为对抗对抗性示例的有效防御方法。然而，我们发现 DiffPure 直接使用原始预训练扩散模型进行对抗性净化，这是次优的。这是由于噪声净化性能和数据恢复质量之间固有的权衡。此外，现有对 DiffPure 的评估的可靠性值得怀疑，因为它们依赖于弱自适应攻击。在这项工作中，我们提出了一种新颖的对抗性扩散桥接模型，称为 ADBM。ADBM 直接从扩散对抗数据构建一个反向桥，回到其原始干净的示例，增强了原始扩散模型的净化能力。通过各种场景的理论分析和实验验证，ADBM 已被证明是一种卓越且稳健的防御机制，为实际应用提供了重要的前景。

##### **ABC Align: Large Language Model Alignment for Safety & Accuracy**
2408.00307v1 by Gareth Seneque, Lap-Hang Ho, Ariel Kuperman, Nafise Erfanian Saeedi, Jeffrey Molendijk

Alignment of Large Language Models (LLMs) remains an unsolved problem. Human
preferences are highly distributed and can be captured at multiple levels of
abstraction, from the individual to diverse populations. Organisational
preferences, represented by standards and principles, are defined to mitigate
reputational risk or meet legislative obligations. In this paper, we present
ABC Align, a novel alignment methodology for LLMs that enables integration of
the standards and preferences of a large media organisation into the LLM
itself. We combine a set of data and methods that build on recent breakthroughs
in synthetic data generation, preference optimisation, and post-training model
quantisation. Our unified approach mitigates bias and improves accuracy, while
preserving reasoning capability, as measured against standard benchmarks.

摘要：大型語言模型 (LLM) 的對齊仍然是一個未解決的問題。人類的偏好高度分散，並且可以在從個人到不同族群的多個抽象層級中被捕捉。由標準和原則所代表的組織偏好被定義為減輕信譽風險或符合法定義務。在本文中，我們提出了 ABC Align，這是一種 LLM 的新對齊方法，它能夠將大型媒體組織的標準和偏好整合到 LLM 本身中。我們結合了一組數據和方法，這些數據和方法建立在合成數據生成、偏好最佳化和訓練後模型量化方面的最新突破之上。我們的統一方法減輕了偏差並提高了準確性，同時保持了推理能力，這是根據標準基準衡量的。

##### **Contrastive Graph Representation Learning with Adversarial Cross-view Reconstruction and Information Bottleneck**
2408.00295v1 by Yuntao Shou, Haozhi Lan, Xiangyong Cao

Graph Neural Networks (GNNs) have received extensive research attention due
to their powerful information aggregation capabilities. Despite the success of
GNNs, most of them suffer from the popularity bias issue in a graph caused by a
small number of popular categories. Additionally, real graph datasets always
contain incorrect node labels, which hinders GNNs from learning effective node
representations. Graph contrastive learning (GCL) has been shown to be
effective in solving the above problems for node classification tasks. Most
existing GCL methods are implemented by randomly removing edges and nodes to
create multiple contrasting views, and then maximizing the mutual information
(MI) between these contrasting views to improve the node feature
representation. However, maximizing the mutual information between multiple
contrasting views may lead the model to learn some redundant information
irrelevant to the node classification task. To tackle this issue, we propose an
effective Contrastive Graph Representation Learning with Adversarial Cross-view
Reconstruction and Information Bottleneck (CGRL) for node classification, which
can adaptively learn to mask the nodes and edges in the graph to obtain the
optimal graph structure representation. Furthermore, we innovatively introduce
the information bottleneck theory into GCLs to remove redundant information in
multiple contrasting views while retaining as much information as possible
about node classification. Moreover, we add noise perturbations to the original
views and reconstruct the augmented views by constructing adversarial views to
improve the robustness of node feature representation. Extensive experiments on
real-world public datasets demonstrate that our method significantly
outperforms existing state-of-the-art algorithms.

摘要：圖神經網路 (GNN) 因其強大的資訊彙總能力而受到廣泛的研究關注。儘管 GNN 取得成功，但大多數 GNN 都會受到圖形中少數熱門類別所造成的熱門偏誤問題。此外，實際圖形資料集總是包含不正確的節點標籤，這會阻礙 GNN 學習有效的節點表示。圖對比學習 (GCL) 已被證明可有效解決節點分類任務中的上述問題。大多數現有的 GCL 方法都是透過隨機移除邊緣和節點來建立多個對比視圖，然後最大化這些對比視圖之間的互信息 (MI)，以改善節點特徵表示。然而，最大化多個對比視圖之間的互信息可能會導致模型學習到一些與節點分類任務無關的冗餘資訊。為了解決這個問題，我們提出了一個有效的對比圖形表示學習，帶有對抗性跨視圖重建和資訊瓶頸 (CGRL) 的節點分類，它可以自適應地學習遮蔽圖形中的節點和邊緣，以取得最佳的圖形結構表示。此外，我們創新地將資訊瓶頸理論引入 GCL，以移除多個對比視圖中的冗餘資訊，同時保留盡可能多的節點分類資訊。此外，我們在原始視圖中加入雜訊擾動，並透過建構對抗性視圖來重建擴增的視圖，以改善節點特徵表示的穩健性。在真實世界公開資料集上的廣泛實驗證明，我們的模型顯著優於現有的最先進演算法。

##### **Multi-Modal Parameter-Efficient Fine-tuning via Graph Neural Network**
2408.00290v1 by Bin Cheng, Jiaxuan Lu

With the advent of the era of foundation models, pre-training and fine-tuning
have become common paradigms. Recently, parameter-efficient fine-tuning has
garnered widespread attention due to its better balance between the number of
learnable parameters and performance. However, some current parameter-efficient
fine-tuning methods only model a single modality and lack the utilization of
structural knowledge in downstream tasks. To address this issue, this paper
proposes a multi-modal parameter-efficient fine-tuning method based on graph
networks. Each image is fed into a multi-modal large language model (MLLM) to
generate a text description. The image and its corresponding text description
are then processed by a frozen image encoder and text encoder to generate image
features and text features, respectively. A graph is constructed based on the
similarity of the multi-modal feature nodes, and knowledge and relationships
relevant to these features are extracted from each node. Additionally, Elastic
Weight Consolidation (EWC) regularization is incorporated into the loss
function to mitigate the problem of forgetting during task learning. The
proposed model achieves test accuracies on the OxfordPets, Flowers102, and
Food101 datasets that improve by 4.45%, 2.92%, and 0.23%, respectively. The
code is available at https://github.com/yunche0/GA-Net/tree/master.

摘要：隨著基礎模型時代的到來，預訓練和微調已成為常見的範例。最近，由於參數有效微調在可學習參數數量和效能之間取得更好的平衡，因此備受關注。然而，一些目前的參數有效微調方法僅建模單一模態，且缺乏在下游任務中利用結構知識。為了解決此問題，本文提出了一種基於圖形網路的多模態參數有效微調方法。每個影像都會輸入到多模態大型語言模型 (MLLM) 中，以產生文字描述。然後，影像及其對應的文字描述會由凍結的影像編碼器和文字編碼器處理，分別產生影像特徵和文字特徵。根據多模態特徵節點的相似性建構一個圖形，並從每個節點中萃取出與這些特徵相關的知識和關係。此外，彈性權重整合 (EWC) 正則化會納入損失函數中，以減輕在任務學習期間遺忘的問題。所提出的模型在 OxfordPets、Flowers102 和 Food101 資料集上達成的測試準確度分別提升了 4.45%、2.92% 和 0.23%。程式碼可在 https://github.com/yunche0/GA-Net/tree/master 取得。

##### **Gradient Harmonization in Unsupervised Domain Adaptation**
2408.00288v1 by Fuxiang Huang, Suqi Song, Lei Zhang

Unsupervised domain adaptation (UDA) intends to transfer knowledge from a
labeled source domain to an unlabeled target domain. Many current methods focus
on learning feature representations that are both discriminative for
classification and invariant across domains by simultaneously optimizing domain
alignment and classification tasks. However, these methods often overlook a
crucial challenge: the inherent conflict between these two tasks during
gradient-based optimization. In this paper, we delve into this issue and
introduce two effective solutions known as Gradient Harmonization, including GH
and GH++, to mitigate the conflict between domain alignment and classification
tasks. GH operates by altering the gradient angle between different tasks from
an obtuse angle to an acute angle, thus resolving the conflict and trade-offing
the two tasks in a coordinated manner. Yet, this would cause both tasks to
deviate from their original optimization directions. We thus further propose an
improved version, GH++, which adjusts the gradient angle between tasks from an
obtuse angle to a vertical angle. This not only eliminates the conflict but
also minimizes deviation from the original gradient directions. Finally, for
optimization convenience and efficiency, we evolve the gradient harmonization
strategies into a dynamically weighted loss function using an integral operator
on the harmonized gradient. Notably, GH/GH++ are orthogonal to UDA and can be
seamlessly integrated into most existing UDA models. Theoretical insights and
experimental analyses demonstrate that the proposed approaches not only enhance
popular UDA baselines but also improve recent state-of-the-art models.

摘要：無監督域適應 (UDA) 旨在將知識從標記的來源域轉移到未標記的目標域。許多現有方法專注於學習特徵表徵，這些表徵既可區分分類，又可透過同時最佳化域對齊和分類任務而在域間保持不變。然而，這些方法經常忽略一個關鍵的挑戰：在基於梯度的最佳化過程中，這兩個任務之間的固有衝突。在本文中，我們深入探討這個問題，並提出兩種稱為梯度調和的有效解決方案，包括 GH 和 GH++，以減輕域對齊和分類任務之間的衝突。GH 的運作方式是將不同任務之間的梯度角從鈍角改為銳角，從而解決衝突，並以協調的方式對這兩個任務進行權衡。然而，這將導致兩個任務都偏離其原始最佳化方向。因此，我們進一步提出一個改進版本 GH++，它將任務之間的梯度角從鈍角調整為垂直角。這不僅消除了衝突，還將原始梯度方向的偏差最小化。最後，為了最佳化的便利性和效率，我們將梯度調和策略演變為一個動態加權損失函數，使用調和梯度上的積分運算子。值得注意的是，GH/GH++ 與 UDA 正交，並且可以無縫整合到大多數現有的 UDA 模型中。理論見解和實驗分析表明，所提出的方法不僅增強了流行的 UDA 基準，而且改進了最近的最新模型。

##### **Bailing-TTS: Chinese Dialectal Speech Synthesis Towards Human-like Spontaneous Representation**
2408.00284v1 by Xinhan Di, Zihao Chen, Yunming Liang, Junjie Zheng, Yihua Wang, Chaofan Ding

Large-scale text-to-speech (TTS) models have made significant progress
recently.However, they still fall short in the generation of Chinese dialectal
speech. Toaddress this, we propose Bailing-TTS, a family of large-scale TTS
models capable of generating high-quality Chinese dialectal speech. Bailing-TTS
serves as a foundation model for Chinese dialectal speech generation. First,
continual semi-supervised learning is proposed to facilitate the alignment of
text tokens and speech tokens. Second, the Chinese dialectal representation
learning is developed using a specific transformer architecture and multi-stage
training processes. With the proposed design of novel network architecture and
corresponding strategy, Bailing-TTS is able to generate Chinese dialectal
speech from text effectively and efficiently. Experiments demonstrate that
Bailing-TTS generates Chinese dialectal speech towards human-like spontaneous
representation. Readers are encouraged to listen to demos at
\url{https://c9412600.github.io/bltts_tech_report/index.html}.

摘要：大型文字轉語音 (TTS) 模型最近取得顯著進展。然而，它們在生成中文方言語音方面仍有不足。為了解決此問題，我們提出了 Bailing-TTS，這是一個大型 TTS 模型系列，能夠生成高品質的中文方言語音。Bailing-TTS 可作為中文方言語音生成的基礎模型。首先，提出持續的半監督式學習，以利於文字符號和語音符號的對齊。其次，使用特定轉換器架構和多階段訓練流程開發中文方言表徵學習。透過新穎網路架構和對應策略的設計，Bailing-TTS 能夠有效率地從文字生成中文方言語音。實驗證明 Bailing-TTS 能夠產生接近人類自然表現的中文方言語音。建議讀者前往 \url{https://c9412600.github.io/bltts_tech_report/index.html} 試聽示範。

##### **Navigating Text-to-Image Generative Bias across Indic Languages**
2408.00283v1 by Surbhi Mittal, Arnav Sudan, Mayank Vatsa, Richa Singh, Tamar Glaser, Tal Hassner

This research investigates biases in text-to-image (TTI) models for the Indic
languages widely spoken across India. It evaluates and compares the generative
performance and cultural relevance of leading TTI models in these languages
against their performance in English. Using the proposed IndicTTI benchmark, we
comprehensively assess the performance of 30 Indic languages with two
open-source diffusion models and two commercial generation APIs. The primary
objective of this benchmark is to evaluate the support for Indic languages in
these models and identify areas needing improvement. Given the linguistic
diversity of 30 languages spoken by over 1.4 billion people, this benchmark
aims to provide a detailed and insightful analysis of TTI models' effectiveness
within the Indic linguistic landscape. The data and code for the IndicTTI
benchmark can be accessed at
https://iab-rubric.org/resources/other-databases/indictti.

摘要：這項研究調查了印度廣泛使用的指示語言中文字轉圖像 (TTI) 模型的偏見。它評估並比較了這些語言中領先的 TTI 模型的生成效能和文化相關性，並與它們在英語中的效能進行比較。使用建議的 IndicTTI 基準，我們全面評估了 30 種指示語言的效能，並使用兩個開源擴散模型和兩個商業生成 API。此基準的主要目標是評估這些模型對指示語言的支援，並找出需要改進的地方。由於 30 種語言的語言多樣性，由超過 14 億人使用，此基準旨在提供對指示語言環境中 TTI 模型有效性的詳細且有見地的分析。IndicTTI 基準的資料和程式碼可於 https://iab-rubric.org/resources/other-databases/indictti 取得。

##### **QUITO: Accelerating Long-Context Reasoning through Query-Guided Context Compression**
2408.00274v1 by Wenshan Wang, Yihang Wang, Yixing Fan, Huaming Liao, Jiafeng Guo

In-context learning (ICL) capabilities are foundational to the success of
large language models (LLMs). Recently, context compression has attracted
growing interest since it can largely reduce reasoning complexities and
computation costs of LLMs. In this paper, we introduce a novel Query-gUIded
aTtention cOmpression (QUITO) method, which leverages attention of the question
over the contexts to filter useless information. Specifically, we take a
trigger token to calculate the attention distribution of the context in
response to the question. Based on the distribution, we propose three different
filtering methods to satisfy the budget constraints of the context length. We
evaluate the QUITO using two widely-used datasets, namely, NaturalQuestions and
ASQA. Experimental results demonstrate that QUITO significantly outperforms
established baselines across various datasets and downstream LLMs, underscoring
its effectiveness. Our code is available at
https://github.com/Wenshansilvia/attention_compressor.

摘要：脈絡學習 (ICL) 能力是大型語言模型 (LLM) 成功發展的基礎。最近，脈絡壓縮引起了越來越多的關注，因為它可以大幅降低 LLM 的推理複雜度和計算成本。在本文中，我們介紹了一種新穎的 Query 引導式注意力壓縮 (QUITO) 方法，它利用問題對脈絡的關注來過濾無用的資訊。具體來說，我們採用觸發詞彙來計算脈絡在回應問題時的注意力分佈。根據分佈，我們提出三種不同的過濾方法來滿足脈絡長度的預算限制。我們使用兩個廣泛使用的資料集，即 NaturalQuestions 和 ASQA，來評估 QUITO。實驗結果表明，QUITO 在各種資料集和下游 LLM 中都明顯優於已建立的基準，突顯了其有效性。我們的程式碼可在 https://github.com/Wenshansilvia/attention_compressor 取得。

##### **Clover-2: Accurate Inference for Regressive Lightweight Speculative Decoding**
2408.00264v1 by Bin Xiao, Lujun Gui, Lei Su, Weipeng Chen

Large Language Models (LLMs) frequently suffer from inefficiencies, largely
attributable to the discord between the requirements of auto-regressive
decoding and the architecture of contemporary GPUs. Recently, regressive
lightweight speculative decoding has garnered attention for its notable
efficiency improvements in text generation tasks. This approach utilizes a
lightweight regressive draft model, like a Recurrent Neural Network (RNN) or a
single transformer decoder layer, leveraging sequential information to
iteratively predict potential tokens. Specifically, RNN draft models are
computationally economical but tend to deliver lower accuracy, while attention
decoder layer models exhibit the opposite traits. This paper presents Clover-2,
an advanced iteration of Clover, an RNN-based draft model designed to achieve
comparable accuracy to that of attention decoder layer models while maintaining
minimal computational overhead. Clover-2 enhances the model architecture and
incorporates knowledge distillation to increase Clover's accuracy and improve
overall efficiency. We conducted experiments using the open-source Vicuna 7B
and LLaMA3-Instruct 8B models. The results demonstrate that Clover-2 surpasses
existing methods across various model architectures, showcasing its efficacy
and robustness.

摘要：大型語言模型 (LLM) 經常會出現低效率的問題，這在很大程度上是歸因於自迴歸解碼的要求與當代 GPU 架構之間的不協調。最近，回歸輕量級推測性解碼因其在文本生成任務中顯著的效率提升而備受關注。此方法利用輕量級回歸草稿模型（例如遞迴神經網路 (RNN) 或單一Transformer解碼器層），利用序列資訊來反覆預測潛在的符號。具體來說，RNN 草稿模型在計算上很經濟，但往往會提供較低的準確度，而注意力解碼器層模型則表現出相反的特徵。本文介紹了 Clover-2，這是基於 RNN 的草稿模型 Clover 的進階迭代，旨在實現與注意力解碼器層模型相當的準確度，同時維持最小的計算開銷。Clover-2 增強了模型架構，並結合了知識蒸餾，以提高 Clover 的準確度並改善整體效率。我們使用開源的 Vicuna 7B 和 LLaMA3-Instruct 8B 模型進行了實驗。結果表明，Clover-2 在各種模型架構中都超越了現有方法，展示了其效能和穩健性。

##### **RoCo:Robust Collaborative Perception By Iterative Object Matching and Pose Adjustment**
2408.00257v1 by Zhe Huang, Shuo Wang, Yongcai Wang, Wanting Li, Deying Li, Lei Wang

Collaborative autonomous driving with multiple vehicles usually requires the
data fusion from multiple modalities. To ensure effective fusion, the data from
each individual modality shall maintain a reasonably high quality. However, in
collaborative perception, the quality of object detection based on a modality
is highly sensitive to the relative pose errors among the agents. It leads to
feature misalignment and significantly reduces collaborative performance. To
address this issue, we propose RoCo, a novel unsupervised framework to conduct
iterative object matching and agent pose adjustment. To the best of our
knowledge, our work is the first to model the pose correction problem in
collaborative perception as an object matching task, which reliably associates
common objects detected by different agents. On top of this, we propose a graph
optimization process to adjust the agent poses by minimizing the alignment
errors of the associated objects, and the object matching is re-done based on
the adjusted agent poses. This process is carried out iteratively until
convergence. Experimental study on both simulated and real-world datasets
demonstrates that the proposed framework RoCo consistently outperforms existing
relevant methods in terms of the collaborative object detection performance,
and exhibits highly desired robustness when the pose information of agents is
with high-level noise. Ablation studies are also provided to show the impact of
its key parameters and components. The code is released at
https://github.com/HuangZhe885/RoCo.

摘要：多車輛協作自動駕駛通常需要來自多種模態的資料融合。為了確保融合有效，來自每個單獨模態的資料應維持相當高的品質。然而，在協作感知中，基於模態的物件偵測品質對代理之間的相對位姿誤差高度敏感。這會導致特徵未對齊，並顯著降低協作效能。為了解決這個問題，我們提出 RoCo，一種新的無監督架構，用於執行反覆物件配對和代理位姿調整。據我們所知，我們的研究率先將協作感知中的位姿校正問題建模為物件配對任務，它會可靠地關聯由不同代理偵測到的共同物件。此外，我們提出一個圖形最佳化流程，藉由最小化關聯物件的對齊誤差來調整代理位姿，並根據調整後的代理位姿重新執行物件配對。這個流程會反覆執行，直到收斂。在模擬和真實世界資料集上的實驗研究顯示，所提出的 RoCo 架構在協作物件偵測效能方面始終優於現有的相關方法，並且在代理的位姿資訊具有高層級雜訊時展現高度的穩健性。也提供了消融研究，以顯示其關鍵參數和組成的影響。程式碼已於 https://github.com/HuangZhe885/RoCo 發布。

##### **Enhanced Structured State Space Models via Grouped FIR Filtering and Attention Sink Mechanisms**
2408.00244v1 by Tian Meng, Yang Tao, Wuliang Yin

Structured State Space Models (SSMs) have emerged as compelling alternatives
to Transformer architectures, offering linear-time complexity and superior
performance in various sequence modeling tasks. Despite their advantages, SSMs
like the original Mamba-2 face training difficulties due to the sensitivities
introduced by the extended series of recurrent matrix multiplications. In this
paper, we propose an advanced architecture that mitigates these challenges by
decomposing A-multiplications into multiple groups and optimizing positional
encoding through Grouped Finite Impulse Response (FIR) filtering. This new
structure, denoted as Grouped FIR-enhanced SSM (GFSSM), employs semiseparable
matrices for efficient computation. Furthermore, inspired by the "attention
sink" phenomenon identified in streaming language models, we incorporate a
similar mechanism to enhance the stability and performance of our model over
extended sequences. Our approach further bridges the gap between SSMs and
Transformer architectures, offering a viable path forward for scalable and
high-performing sequence modeling.

摘要：結構化狀態空間模型 (SSM) 已成為 Transformer 架構的引人注目的替代方案，在各種序列建模任務中提供線性時間複雜度和卓越的效能。儘管有這些優點，但像原始 Mamba-2 這樣的 SSM 會因遞迴矩陣乘法的延伸序列所帶來的敏感性而面臨訓練難題。在本文中，我們提出了一種先進的架構，透過將 A 乘法分解成多個群組並透過群組有限脈衝響應 (FIR) 濾波最佳化位置編碼來減輕這些挑戰。這個新的結構稱為群組 FIR 增強 SSM (GFSSM)，採用半可分離矩陣進行有效率的運算。此外，受到串流語言模型中識別出的「注意力接收器」現象的啟發，我們納入了一個類似的機制來增強我們模型在延伸序列中的穩定性和效能。我們的做法進一步縮小了 SSM 與 Transformer 架構之間的差距，為可擴充且高執行效能的序列建模提供了可行的前進道路。

##### **Lost in Translation: Latent Concept Misalignment in Text-to-Image Diffusion Models**
2408.00230v1 by Juntu Zhao, Junyu Deng, Yixin Ye, Chongxuan Li, Zhijie Deng, Dequan Wang

Advancements in text-to-image diffusion models have broadened extensive
downstream practical applications, but such models often encounter misalignment
issues between text and image. Taking the generation of a combination of two
disentangled concepts as an example, say given the prompt "a tea cup of iced
coke", existing models usually generate a glass cup of iced coke because the
iced coke usually co-occurs with the glass cup instead of the tea one during
model training. The root of such misalignment is attributed to the confusion in
the latent semantic space of text-to-image diffusion models, and hence we refer
to the "a tea cup of iced coke" phenomenon as Latent Concept Misalignment
(LC-Mis). We leverage large language models (LLMs) to thoroughly investigate
the scope of LC-Mis, and develop an automated pipeline for aligning the latent
semantics of diffusion models to text prompts. Empirical assessments confirm
the effectiveness of our approach, substantially reducing LC-Mis errors and
enhancing the robustness and versatility of text-to-image diffusion models. Our
code and dataset have been available online for reference.

摘要：文本到图像扩散模型的进步拓宽了广泛的下游实际应用，但此类模型通常会遇到文本和图像之间的错位问题。以生成两个分离概念的组合为例，例如给定提示“一杯冰可乐”，现有的模型通常会生成一杯玻璃杯装的冰可乐，因为在模型训练期间，冰可乐通常与玻璃杯同时出现，而不是茶杯。这种错位问题的根源归因于文本到图像扩散模型的潜在语义空间中的混乱，因此我们将“一杯冰可乐”现象称为潜在概念错位 (LC-Mis)。我们利用大型语言模型 (LLM) 彻底调查 LC-Mis 的范围，并开发了一个自动管道来将扩散模型的潜在语义与文本提示对齐。经验评估证实了我们方法的有效性，大幅减少了 LC-Mis 错误，并增强了文本到图像扩散模型的鲁棒性和通用性。我们的代码和数据集已在线提供以供参考。

##### **Sentence-wise Speech Summarization: Task, Datasets, and End-to-End Modeling with LM Knowledge Distillation**
2408.00205v1 by Kohei Matsuura, Takanori Ashihara, Takafumi Moriya, Masato Mimura, Takatomo Kano, Atsunori Ogawa, Marc Delcroix

This paper introduces a novel approach called sentence-wise speech
summarization (Sen-SSum), which generates text summaries from a spoken document
in a sentence-by-sentence manner. Sen-SSum combines the real-time processing of
automatic speech recognition (ASR) with the conciseness of speech
summarization. To explore this approach, we present two datasets for Sen-SSum:
Mega-SSum and CSJ-SSum. Using these datasets, our study evaluates two types of
Transformer-based models: 1) cascade models that combine ASR and strong text
summarization models, and 2) end-to-end (E2E) models that directly convert
speech into a text summary. While E2E models are appealing to develop
compute-efficient models, they perform worse than cascade models. Therefore, we
propose knowledge distillation for E2E models using pseudo-summaries generated
by the cascade models. Our experiments show that this proposed knowledge
distillation effectively improves the performance of the E2E model on both
datasets.

摘要：本文介紹一種稱為句子式語音摘要 (Sen-SSum) 的新方法，它以逐句的方式從口語文件中產生文字摘要。Sen-SSum 結合了自動語音辨識 (ASR) 的即時處理，以及語音摘要的簡潔性。為了探索此方法，我們為 Sen-SSum 呈現兩個資料集：Mega-SSum 和 CSJ-SSum。我們的研究使用這些資料集，評估了兩種基於 Transformer 的模型：1) 將 ASR 和強大的文字摘要模型結合起來的串聯模型，以及 2) 直接將語音轉換成文字摘要的端到端 (E2E) 模型。雖然 E2E 模型對於開發運算效率高的模型很有吸引力，但它們的表現不如串聯模型。因此，我們針對 E2E 模型提出知識蒸餾，使用由串聯模型產生的擬摘要。我們的實驗顯示，所提出的知識蒸餾有效地改善了 E2E 模型在兩個資料集上的表現。

##### **OmniParser for Pure Vision Based GUI Agent**
2408.00203v1 by Yadong Lu, Jianwei Yang, Yelong Shen, Ahmed Awadallah

The recent success of large vision language models shows great potential in
driving the agent system operating on user interfaces. However, we argue that
the power multimodal models like GPT-4V as a general agent on multiple
operating systems across different applications is largely underestimated due
to the lack of a robust screen parsing technique capable of: 1) reliably
identifying interactable icons within the user interface, and 2) understanding
the semantics of various elements in a screenshot and accurately associate the
intended action with the corresponding region on the screen. To fill these
gaps, we introduce \textsc{OmniParser}, a comprehensive method for parsing user
interface screenshots into structured elements, which significantly enhances
the ability of GPT-4V to generate actions that can be accurately grounded in
the corresponding regions of the interface. We first curated an interactable
icon detection dataset using popular webpages and an icon description dataset.
These datasets were utilized to fine-tune specialized models: a detection model
to parse interactable regions on the screen and a caption model to extract the
functional semantics of the detected elements. \textsc{OmniParser}
significantly improves GPT-4V's performance on ScreenSpot benchmark. And on
Mind2Web and AITW benchmark, \textsc{OmniParser} with screenshot only input
outperforms the GPT-4V baselines requiring additional information outside of
screenshot.

摘要：最近大型视觉语言模型的成功显示出在用户界面上操作代理系统时巨大的潜力。然而，我们认为，由于缺乏一种强大的屏幕解析技术，GPT-4V 等多模态模型作为多个操作系统上跨不同应用程序的通用代理的能力在很大程度上被低估了：1）可靠地识别用户界面中的可交互图标，以及 2）理解屏幕截图中各种元素的语义，并将预期动作准确地与屏幕上的相应区域关联起来。为了填补这些空白，我们引入了 \textsc{OmniParser}，这是一种将用户界面屏幕截图解析为结构化元素的综合方法，它大大增强了 GPT-4V 生成动作的能力，这些动作可以准确地基于界面的相应区域。我们首先使用流行的网页和图标描述数据集整理了一个可交互图标检测数据集。这些数据集被用来微调专门的模型：一个用于解析屏幕上可交互区域的检测模型和一个用于提取检测元素的功能语义的标题模型。\textsc{OmniParser} 大大提高了 GPT-4V 在 ScreenSpot 基准上的性能。并且在 Mind2Web 和 AITW 基准上，仅输入屏幕截图的 \textsc{OmniParser} 优于需要屏幕截图外部附加信息的 GPT-4V 基线。

##### **Automated Software Vulnerability Static Code Analysis Using Generative Pre-Trained Transformer Models**
2408.00197v1 by Elijah Pelofske, Vincent Urias, Lorie M. Liebrock

Generative Pre-Trained Transformer models have been shown to be surprisingly
effective at a variety of natural language processing tasks -- including
generating computer code. We evaluate the effectiveness of open source GPT
models for the task of automatic identification of the presence of vulnerable
code syntax (specifically targeting C and C++ source code). This task is
evaluated on a selection of 36 source code examples from the NIST SARD dataset,
which are specifically curated to not contain natural English that indicates
the presence, or lack thereof, of a particular vulnerability. The NIST SARD
source code dataset contains identified vulnerable lines of source code that
are examples of one out of the 839 distinct Common Weakness Enumerations (CWE),
allowing for exact quantification of the GPT output classification error rate.
A total of 5 GPT models are evaluated, using 10 different inference
temperatures and 100 repetitions at each setting, resulting in 5,000 GPT
queries per vulnerable source code analyzed. Ultimately, we find that the GPT
models that we evaluated are not suitable for fully automated vulnerability
scanning because the false positive and false negative rates are too high to
likely be useful in practice. However, we do find that the GPT models perform
surprisingly well at automated vulnerability detection for some of the test
cases, in particular surpassing random sampling, and being able to identify the
exact lines of code that are vulnerable albeit at a low success rate. The best
performing GPT model result found was Llama-2-70b-chat-hf with inference
temperature of 0.1 applied to NIST SARD test case 149165 (which is an example
of a buffer overflow vulnerability), which had a binary classification recall
score of 1.0 and a precision of 1.0 for correctly and uniquely identifying the
vulnerable line of code and the correct CWE number.

摘要：生成式预训练 Transformer 模型已被证明在各种自然语言处理任务中出人意料地有效——包括生成计算机代码。我们评估了开源 GPT 模型在自动识别易受攻击的代码语法（具体针对 C 和 C++ 源代码）的任务中的有效性。此任务在 NIST SARD 数据集中的 36 个源代码示例中进行评估，这些示例经过专门整理，不包含表示存在或不存在特定漏洞的自然英语。NIST SARD 源代码数据集包含已识别的易受攻击的源代码行，这些行是 839 个不同的通用弱点枚举 (CWE) 中的一个示例，允许对 GPT 输出分类错误率进行精确量化。总共评估了 5 个 GPT 模型，每个设置使用 10 个不同的推理温度和 100 次重复，导致每分析一个易受攻击的源代码有 5,000 个 GPT 查询。最终，我们发现我们评估的 GPT 模型不适用于全自动漏洞扫描，因为误报率和漏报率太高，在实践中可能没有用。然而，我们确实发现 GPT 模型在某些测试用例的自动漏洞检测中表现出惊人的良好表现，特别是超过了随机抽样，并且能够识别出易受攻击的确切代码行，尽管成功率较低。发现表现最好的 GPT 模型结果是 Llama-2-70b-chat-hf，其推理温度为 0.1，应用于 NIST SARD 测试用例 149165（这是一个缓冲区溢出漏洞的示例），其二元分类召回得分为 1.0，正确且唯一地识别出易受攻击的代码行和正确的 CWE 编号的精确度为 1.0。

##### **S-SYNTH: Knowledge-Based, Synthetic Generation of Skin Images**
2408.00191v1 by Andrea Kim, Niloufar Saharkhiz, Elena Sizikova, Miguel Lago, Berkman Sahiner, Jana Delfino, Aldo Badano

Development of artificial intelligence (AI) techniques in medical imaging
requires access to large-scale and diverse datasets for training and
evaluation. In dermatology, obtaining such datasets remains challenging due to
significant variations in patient populations, illumination conditions, and
acquisition system characteristics. In this work, we propose S-SYNTH, the first
knowledge-based, adaptable open-source skin simulation framework to rapidly
generate synthetic skin, 3D models and digitally rendered images, using an
anatomically inspired multi-layer, multi-component skin and growing lesion
model. The skin model allows for controlled variation in skin appearance, such
as skin color, presence of hair, lesion shape, and blood fraction among other
parameters. We use this framework to study the effect of possible variations on
the development and evaluation of AI models for skin lesion segmentation, and
show that results obtained using synthetic data follow similar comparative
trends as real dermatologic images, while mitigating biases and limitations
from existing datasets including small dataset size, lack of diversity, and
underrepresentation.

摘要：人工智慧 (AI) 技術在醫學影像方面的發展需要取得大規模且多元的資料集，以進行訓練和評估。在皮膚科中，取得此類資料集仍然具有挑戰性，原因在於患者族群、照明條件和取得系統特性有顯著的變化。在這項工作中，我們提出 S-SYNTH，這是第一個基於知識、可適應的開放原始碼皮膚模擬架構，可使用解剖學啟發的多層、多組成皮膚和生長病灶模型，快速產生合成皮膚、3D 模型和數位渲染影像。皮膚模型允許控制皮膚外觀的變化，例如膚色、毛髮存在、病灶形狀和血液比例等參數。我們使用這個架構來研究可能的變化對皮膚病灶分割 AI 模型的開發和評估的影響，並顯示使用合成資料取得的結果遵循與真實皮膚科影像類似的比較趨勢，同時減輕現有資料集的偏差和限制，包括資料集規模小、缺乏多元性以及代表性不足。

##### **Finch: Prompt-guided Key-Value Cache Compression**
2408.00167v1 by Giulio Corallo, Paolo Papotti

Recent large language model applications, such as Retrieval-Augmented
Generation and chatbots, have led to an increased need to process longer input
contexts. However, this requirement is hampered by inherent limitations.
Architecturally, models are constrained by a context window defined during
training. Additionally, processing extensive texts requires substantial GPU
memory. We propose a novel approach, Finch, to compress the input context by
leveraging the pre-trained model weights of the self-attention. Given a prompt
and a long text, Finch iteratively identifies the most relevant Key (K) and
Value (V) pairs over chunks of the text conditioned on the prompt. Only such
pairs are stored in the KV cache, which, within the space constrained by the
context window, ultimately contains a compressed version of the long text. Our
proposal enables models to consume large inputs even with high compression (up
to 93x) while preserving semantic integrity without the need for fine-tuning.

摘要：最近的大型语言模型应用，例如检索增强生成和聊天机器人，导致了处理更长的输入语境的需要增加。然而，此项需求受到固有局限性的阻碍。在架构上，模型受到训练期间定义的上下文窗口的约束。此外，处理大文本需要大量的 GPU 内存。我们提出了一种新颖的方法 Finch，通过利用自注意力的预训练模型权重来压缩输入上下文。给定一个提示和一个长文本，Finch 根据提示对文本块进行迭代识别最相关的键 (K) 和值 (V) 对。只有此类对存储在 KV 缓存中，该缓存受上下文窗口约束的空间内最终包含长文本的压缩版本。我们的提议使模型能够消耗大量输入，即使在高压缩（高达 93 倍）的情况下，也能在无需微调的情况下保持语义完整性。

##### **A Taxonomy of Stereotype Content in Large Language Models**
2408.00162v1 by Gandalf Nicolas, Aylin Caliskan

This study introduces a taxonomy of stereotype content in contemporary large
language models (LLMs). We prompt ChatGPT 3.5, Llama 3, and Mixtral 8x7B, three
powerful and widely used LLMs, for the characteristics associated with 87
social categories (e.g., gender, race, occupations). We identify 14 stereotype
dimensions (e.g., Morality, Ability, Health, Beliefs, Emotions), accounting for
~90% of LLM stereotype associations. Warmth and Competence facets were the most
frequent content, but all other dimensions were significantly prevalent.
Stereotypes were more positive in LLMs (vs. humans), but there was significant
variability across categories and dimensions. Finally, the taxonomy predicted
the LLMs' internal evaluations of social categories (e.g., how
positively/negatively the categories were represented), supporting the
relevance of a multidimensional taxonomy for characterizing LLM stereotypes.
Our findings suggest that high-dimensional human stereotypes are reflected in
LLMs and must be considered in AI auditing and debiasing to minimize
unidentified harms from reliance in low-dimensional views of bias in LLMs.

摘要：本研究針對當代大型語言模型 (LLM) 中的刻板印象內容進行分類。我們提示 ChatGPT 3.5、Llama 3 和 Mixtral 8x7B 這三種強大且廣泛使用的 LLM，了解與 87 個社會類別（例如性別、種族、職業）相關的特徵。我們識別出 14 個刻板印象面向（例如道德、能力、健康、信仰、情緒），約佔 LLM 刻板印象關聯的 90%。溫暖和能力面向是最頻繁的內容，但所有其他面向都很普遍。LLM 中的刻板印象比人類更正面，但不同類別和面向之間存在顯著差異。最後，分類法預測了 LLM 對社會類別的內部評估（例如類別的正面/負面呈現方式），支持了使用多維分類法來表徵 LLM 刻板印象的相關性。我們的研究結果表明，高維度的人類刻板印象反映在 LLM 中，並且必須在 AI 稽核和消除偏見中加以考慮，以將依賴 LLM 中偏見的低維度觀點造成的未識別危害降到最低。

##### **Automatic Generation of Behavioral Test Cases For Natural Language Processing Using Clustering and Prompting**
2408.00161v1 by Ying Li, Rahul Singh, Tarun Joshi, Agus Sudjianto

Recent work in behavioral testing for natural language processing (NLP)
models, such as Checklist, is inspired by related paradigms in software
engineering testing. They allow evaluation of general linguistic capabilities
and domain understanding, hence can help evaluate conceptual soundness and
identify model weaknesses. However, a major challenge is the creation of test
cases. The current packages rely on semi-automated approach using manual
development which requires domain expertise and can be time consuming. This
paper introduces an automated approach to develop test cases by exploiting the
power of large language models and statistical techniques. It clusters the text
representations to carefully construct meaningful groups and then apply
prompting techniques to automatically generate Minimal Functionality Tests
(MFT). The well-known Amazon Reviews corpus is used to demonstrate our
approach. We analyze the behavioral test profiles across four different
classification algorithms and discuss the limitations and strengths of those
models.

摘要：自然語言處理 (NLP) 行為測試的最新研究，例如 Checklist，是受軟體工程測試中相關範例所啟發。它們允許評估一般語言能力和領域理解，因此有助於評估概念健全性並找出模型的弱點。然而，一個主要的挑戰是如何建立測試案例。目前的套件依賴於使用手動開發的半自動化方法，這需要領域專業知識，而且可能很耗時。本文介紹了一種自動化方法，透過利用大型語言模型和統計技術來開發測試案例。它會將文本表示分群，以仔細建構有意義的群組，然後套用提示技術來自動產生最小功能測試 (MFT)。我們使用著名的 Amazon Reviews 語料庫來展示我們的做法。我們會分析四種不同分類演算法的行為測試輪廓，並討論這些模型的限制和優點。

##### **StyleRF-VolVis: Style Transfer of Neural Radiance Fields for Expressive Volume Visualization**
2408.00150v1 by Kaiyuan Tang, Chaoli Wang

In volume visualization, visualization synthesis has attracted much attention
due to its ability to generate novel visualizations without following the
conventional rendering pipeline. However, existing solutions based on
generative adversarial networks often require many training images and take
significant training time. Still, issues such as low quality, consistency, and
flexibility persist. This paper introduces StyleRF-VolVis, an innovative style
transfer framework for expressive volume visualization (VolVis) via neural
radiance field (NeRF). The expressiveness of StyleRF-VolVis is upheld by its
ability to accurately separate the underlying scene geometry (i.e., content)
and color appearance (i.e., style), conveniently modify color, opacity, and
lighting of the original rendering while maintaining visual content consistency
across the views, and effectively transfer arbitrary styles from reference
images to the reconstructed 3D scene. To achieve these, we design a base NeRF
model for scene geometry extraction, a palette color network to classify
regions of the radiance field for photorealistic editing, and an unrestricted
color network to lift the color palette constraint via knowledge distillation
for non-photorealistic editing. We demonstrate the superior quality,
consistency, and flexibility of StyleRF-VolVis by experimenting with various
volume rendering scenes and reference images and comparing StyleRF-VolVis
against other image-based (AdaIN), video-based (ReReVST), and NeRF-based (ARF
and SNeRF) style rendering solutions.

摘要：在體積可視化中，可視化合成因其能夠生成新穎的可視化而備受關注，而無需遵循傳統的渲染管道。然而，現有的基於生成對抗網路的解決方案通常需要大量的訓練影像，並且需要大量的訓練時間。儘管如此，諸如低品質、一致性和靈活性等問題仍然存在。本文介紹了 StyleRF-VolVis，這是一個創新的樣式轉移框架，用於通過神經輻射場 (NeRF) 進行富有表現力的體積可視化 (VolVis)。StyleRF-VolVis 的表現力通過其準確分離底層場景幾何形狀（即內容）和色彩外觀（即樣式）的能力得到提升，方便地修改原始渲染的色彩、不透明度和光照，同時保持視覺內容在視圖間的一致性，並有效地將任意樣式從參考影像轉移到重建的 3D 場景。為了實現這些目標，我們設計了一個用於場景幾何形狀提取的基本 NeRF 模型、一個用於對輻射場區域進行分類以進行逼真編輯的調色板色彩網路，以及一個用於通過知識蒸餾解除色彩調色板約束的無限制色彩網路，以進行非逼真編輯。我們通過使用各種體積渲染場景和參考影像進行實驗，並將 StyleRF-VolVis 與其他基於影像（AdaIN）、基於影片（ReReVST）和基於 NeRF（ARF 和 SNeRF）的樣式渲染解決方案進行比較，展示了 StyleRF-VolVis 的優越品質、一致性和靈活性。

##### **Formal Ethical Obligations in Reinforcement Learning Agents: Verification and Policy Updates**
2408.00147v1 by Colin Shea-Blymyer, Houssam Abbas

When designing agents for operation in uncertain environments, designers need
tools to automatically reason about what agents ought to do, how that conflicts
with what is actually happening, and how a policy might be modified to remove
the conflict. These obligations include ethical and social obligations,
permissions and prohibitions, which constrain how the agent achieves its
mission and executes its policy. We propose a new deontic logic, Expected Act
Utilitarian deontic logic, for enabling this reasoning at design time: for
specifying and verifying the agent's strategic obligations, then modifying its
policy from a reference policy to meet those obligations. Unlike approaches
that work at the reward level, working at the logical level increases the
transparency of the trade-offs. We introduce two algorithms: one for
model-checking whether an RL agent has the right strategic obligations, and one
for modifying a reference decision policy to make it meet obligations expressed
in our logic. We illustrate our algorithms on DAC-MDPs which accurately
abstract neural decision policies, and on toy gridworld environments.

摘要：在為不確定環境中的運作設計代理時，設計師需要
工具來自動推論代理應做什麼，這與實際發生的事如何衝突，以及如何修改策略以消除
衝突。這些義務包括道德和社會義務、
許可和禁止，它們限制了代理如何實現其
任務並執行其政策。我們提出了一種新的義務邏輯，預期行為
功利主義義務邏輯，用於在設計時啟用這種推理：用於
指定和驗證代理的策略義務，然後修改其
政策從參考政策來履行這些義務。與在獎勵層級運作的方法不同，在邏輯層級運作會增加
權衡的透明度。我們引入了兩種演算法：一種用於
模型檢查 RL 代理是否具有正確的策略義務，另一種用於
修改參考決策政策以使其符合我們的邏輯中表達的義務。我們在準確
抽象神經決策政策的 DAC-MDP 和玩具格狀世界環境中說明我們的演算法。

##### **Distributed In-Context Learning under Non-IID Among Clients**
2408.00144v1 by Siqi Liang, Sumyeong Ahn, Jiayu Zhou

Advancements in large language models (LLMs) have shown their effectiveness
in multiple complicated natural language reasoning tasks. A key challenge
remains in adapting these models efficiently to new or unfamiliar tasks.
In-context learning (ICL) provides a promising solution for few-shot adaptation
by retrieving a set of data points relevant to a query, called in-context
examples (ICE), from a training dataset and providing them during the inference
as context. Most existing studies utilize a centralized training dataset, yet
many real-world datasets may be distributed among multiple clients, and remote
data retrieval can be associated with costs. Especially when the client data
are non-identical independent distributions (non-IID), retrieving from clients
a proper set of ICEs needed for a test query presents critical challenges. In
this paper, we first show that in this challenging setting, test queries will
have different preferences among clients because of non-IIDness, and equal
contribution often leads to suboptimal performance. We then introduce a novel
approach to tackle the distributed non-IID ICL problem when a data usage budget
is present. The principle is that each client's proper contribution (budget)
should be designed according to the preference of each query for that client.
Our approach uses a data-driven manner to allocate a budget for each client,
tailored to each test query. Through extensive empirical studies on diverse
datasets, our framework demonstrates superior performance relative to competing
baselines.

摘要：大型語言模型 (LLM) 的進展已展現其在多重複雜自然語言推理任務中的有效性。一個關鍵挑戰在於有效地將這些模型適應於新的或不熟悉的任務。情境內學習 (ICL) 提供了一個有希望的解決方案，用於少量適應，方法是從訓練資料集中擷取一組與查詢相關的資料點，稱為情境內範例 (ICE)，並在推理過程中將它們提供為情境。大多數現有研究利用一個集中式訓練資料集，然而許多真實世界的資料集可能分佈在多個用戶端中，而且遠端資料擷取可能會產生成本。特別是當用戶端資料是非相同獨立分佈 (non-IID) 時，從用戶端擷取一個適當的 ICE 集合以供測試查詢會帶來重大的挑戰。在本文中，我們首先展示，在這個具挑戰性的設定中，測試查詢將會因為非相同獨立分佈而有不同的用戶端偏好，而相等的貢獻通常會導致次佳效能。接著，我們介紹一種新穎的方法來解決有資料使用預算時的分散式非相同獨立分佈 ICL 問題。原則是每個用戶端的適當貢獻 (預算) 應根據每個查詢對該用戶端的偏好來設計。我們的做法使用資料驅動的方式為每個用戶端分配預算，並針對每個測試查詢量身打造。透過在不同資料集上進行廣泛的實證研究，我們的架構展現出優於競爭基準的卓越效能。

##### **Correcting Negative Bias in Large Language Models through Negative Attention Score Alignment**
2408.00137v1 by Sangwon Yu, Jongyoon Song, Bongkyu Hwang, Hoyoung Kang, Sooah Cho, Junhwa Choi, Seongho Joe, Taehee Lee, Youngjune L. Gwon, Sungroh Yoon

A binary decision task, like yes-no questions or answer verification,
reflects a significant real-world scenario such as where users look for
confirmation about the correctness of their decisions on specific issues. In
this work, we observe that language models exhibit a negative bias in the
binary decisions of complex reasoning tasks. Based on our observations and the
rationale about attention-based model dynamics, we propose a negative attention
score (NAS) to systematically and quantitatively formulate negative bias. Based
on NAS, we identify attention heads that attend to negative tokens provided in
the instructions as answer candidate of binary decisions, regardless of the
question in the prompt, and validate their association with the negative bias.
Additionally, we propose the negative attention score alignment (NASA) method,
which is a parameter-efficient fine-tuning technique to address the extracted
negatively biased attention heads. Experimental results from various domains of
reasoning tasks and large model search space demonstrate that NASA
significantly reduces the gap between precision and recall caused by negative
bias while preserving their generalization abilities. Our codes are available
at \url{https://github.com/ysw1021/NASA}.

摘要：二元決策任務，例如是非題或答案驗證，反映了一個重要的真實世界場景，例如使用者在特定問題上尋求對其決策正確性的確認。在本文中，我們觀察到語言模型在複雜推理任務的二元決策中表現出負面偏見。根據我們的觀察和基於注意力的模型動態的基本原理，我們提出了一個負面注意力分數 (NAS) 來系統且量化地制定負面偏見。基於 NAS，我們識別出在提示中的問題中，無論如何，都注意二元決策中提供的負面標記（作為答案候選）的注意力頭，並驗證它們與負面偏見的關聯性。此外，我們提出了負面注意力分數對齊 (NASA) 方法，這是一種參數高效的微調技術，用於解決提取的負面偏見注意力頭。來自各種推理任務領域和大型模型搜尋空間的實驗結果表明，NASA 在保留其泛化能力的同時，顯著縮小了由負面偏見造成的精確度和召回率之間的差距。我們的程式碼可在 \url{https://github.com/ysw1021/NASA} 取得。

##### **Distributionally Robust Optimization as a Scalable Framework to Characterize Extreme Value Distributions**
2408.00131v1 by Patrick Kuiper, Ali Hasan, Wenhao Yang, Yuting Ng, Hoda Bidkhori, Jose Blanchet, Vahid Tarokh

The goal of this paper is to develop distributionally robust optimization
(DRO) estimators, specifically for multidimensional Extreme Value Theory (EVT)
statistics. EVT supports using semi-parametric models called max-stable
distributions built from spatial Poisson point processes. While powerful, these
models are only asymptotically valid for large samples. However, since extreme
data is by definition scarce, the potential for model misspecification error is
inherent to these applications, thus DRO estimators are natural. In order to
mitigate over-conservative estimates while enhancing out-of-sample performance,
we study DRO estimators informed by semi-parametric max-stable constraints in
the space of point processes. We study both tractable convex formulations for
some problems of interest (e.g. CVaR) and more general neural network based
estimators. Both approaches are validated using synthetically generated data,
recovering prescribed characteristics, and verifying the efficacy of the
proposed techniques. Additionally, the proposed method is applied to a real
data set of financial returns for comparison to a previous analysis. We
established the proposed model as a novel formulation in the multivariate EVT
domain, and innovative with respect to performance when compared to relevant
alternate proposals.

摘要：本文的目標是開發分布穩健最佳化 (DRO) 估計量，特別是針對多維極值理論 (EVT) 統計量。EVT 支援使用由空間泊松點過程建立的半參數模型，稱為極大穩定分佈。儘管功能強大，但這些模型僅對大型樣本具有漸近有效性。然而，由於極端資料的定義是稀少的，因此模型錯誤規範的潛力是這些應用程式固有的，因此 DRO 估計量是自然的。為了減輕過於保守的估計，同時增強樣本外效能，我們研究了由點過程空間中的半參數極大穩定約束所告知的 DRO 估計量。我們研究了針對一些感興趣問題（例如 CVaR）的可處理凸公式，以及更通用的基於神經網路的估計量。兩種方法都使用合成產生的資料驗證，恢復規定的特徵，並驗證所提出技術的效能。此外，所提出的方法應用於一組真實的財務報酬資料集，以與先前的分析進行比較。我們將所提出的模型建立為多元 EVT 領域中的創新公式，並且在與相關替代方案相比時，在效能方面具有創新性。

##### **Semantic Codebook Learning for Dynamic Recommendation Models**
2408.00123v1 by Zheqi Lv, Shaoxuan He, Tianyu Zhan, Shengyu Zhang, Wenqiao Zhang, Jingyuan Chen, Zhou Zhao, Fei Wu

Dynamic sequential recommendation (DSR) can generate model parameters based
on user behavior to improve the personalization of sequential recommendation
under various user preferences. However, it faces the challenges of large
parameter search space and sparse and noisy user-item interactions, which
reduces the applicability of the generated model parameters. The Semantic
Codebook Learning for Dynamic Recommendation Models (SOLID) framework presents
a significant advancement in DSR by effectively tackling these challenges. By
transforming item sequences into semantic sequences and employing a dual
parameter model, SOLID compresses the parameter generation search space and
leverages homogeneity within the recommendation system. The introduction of the
semantic metacode and semantic codebook, which stores disentangled item
representations, ensures robust and accurate parameter generation. Extensive
experiments demonstrates that SOLID consistently outperforms existing DSR,
delivering more accurate, stable, and robust recommendations.

摘要：動態順序推薦 (DSR) 能根據使用者行為產生模型參數，以改善在各種使用者偏好下的順序推薦個人化。然而，它面臨大型參數搜尋空間以及稀疏且有雜訊的使用者-項目互動的挑戰，這降低了所產生模型參數的適用性。語意碼本學習用於動態推薦模型 (SOLID) 架構提出了一個重大進展，能有效地應對這些挑戰。透過將項目序列轉換為語意序列並採用雙重參數模型，SOLID 壓縮參數產生搜尋空間，並利用推薦系統內的同質性。語意元碼和語意碼本的引入，儲存了解開的項目表示，確保了穩健且準確的參數產生。廣泛的實驗證明，SOLID 持續優於現有的 DSR，提供更準確、穩定且穩健的推薦。

##### **A Course Shared Task on Evaluating LLM Output for Clinical Questions**
2408.00122v1 by Yufang Hou, Thy Thy Tran, Doan Nam Long Vu, Yiwen Cao, Kai Li, Lukas Rohde, Iryna Gurevych

This paper presents a shared task that we organized at the Foundations of
Language Technology (FoLT) course in 2023/2024 at the Technical University of
Darmstadt, which focuses on evaluating the output of Large Language Models
(LLMs) in generating harmful answers to health-related clinical questions. We
describe the task design considerations and report the feedback we received
from the students. We expect the task and the findings reported in this paper
to be relevant for instructors teaching natural language processing (NLP) and
designing course assignments.

摘要：這篇論文介紹了一個我們在2023/2024年於達姆施塔特工業大學語言技術基礎（FoLT）課程中組織的共享任務，重點在於評估大型語言模型（LLM）在產生對健康相關臨床問題的有害答案時的輸出。我們描述了任務設計考量，並報告了我們從學生那裡收到的回饋。我們預期這項任務和本文中報告的發現與教授自然語言處理（NLP）並設計課程作業的講師相關。

##### **Gemma 2: Improving Open Language Models at a Practical Size**
2408.00118v1 by Gemma Team, Morgane Riviere, Shreya Pathak, Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupatiraju, Léonard Hussenot, Thomas Mesnard, Bobak Shahriari, Alexandre Ramé, Johan Ferret, Peter Liu, Pouya Tafti, Abe Friesen, Michelle Casbon, Sabela Ramos, Ravin Kumar, Charline Le Lan, Sammy Jerome, Anton Tsitsulin, Nino Vieillard, Piotr Stanczyk, Sertan Girgin, Nikola Momchev, Matt Hoffman, Shantanu Thakoor, Jean-Bastien Grill, Behnam Neyshabur, Alanna Walton, Aliaksei Severyn, Alicia Parrish, Aliya Ahmad, Allen Hutchison, Alvin Abdagic, Amanda Carl, Amy Shen, Andy Brock, Andy Coenen, Anthony Laforge, Antonia Paterson, Ben Bastian, Bilal Piot, Bo Wu, Brandon Royal, Charlie Chen, Chintu Kumar, Chris Perry, Chris Welty, Christopher A. Choquette-Choo, Danila Sinopalnikov, David Weinberger, Dimple Vijaykumar, Dominika Rogozińska, Dustin Herbison, Elisa Bandy, Emma Wang, Eric Noland, Erica Moreira, Evan Senter, Evgenii Eltyshev, Francesco Visin, Gabriel Rasskin, Gary Wei, Glenn Cameron, Gus Martins, Hadi Hashemi, Hanna Klimczak-Plucińska, Harleen Batra, Harsh Dhand, Ivan Nardini, Jacinda Mein, Jack Zhou, James Svensson, Jeff Stanway, Jetha Chan, Jin Zhou, Joana Carrasqueira, Joana Iljazi, Jocelyn Becker, Joe Fernandez, Joost van Amersfoort, Josh Gordon, Josh Lipschultz, Josh Newlan, Ju-yeong Ji, Kareem Mohamed, Kartikeya Badola, Kat Black, Katie Millican, Keelin McDonell, Kelvin Nguyen, Kiranbir Sodhia, Kish Greene, Lars Lowe Sjoesund, Lauren Usui, Laurent Sifre, Lena Heuermann, Leticia Lago, Lilly McNealus, Livio Baldini Soares, Logan Kilpatrick, Lucas Dixon, Luciano Martins, Machel Reid, Manvinder Singh, Mark Iverson, Martin Görner, Mat Velloso, Mateo Wirth, Matt Davidow, Matt Miller, Matthew Rahtz, Matthew Watson, Meg Risdal, Mehran Kazemi, Michael Moynihan, Ming Zhang, Minsuk Kahng, Minwoo Park, Mofi Rahman, Mohit Khatwani, Natalie Dao, Nenshad Bardoliwalla, Nesh Devanathan, Neta Dumai, Nilay Chauhan, Oscar Wahltinez, Pankil Botarda, Parker Barnes, Paul Barham, Paul Michel, Pengchong Jin, Petko Georgiev, Phil Culliton, Pradeep Kuppala, Ramona Comanescu, Ramona Merhej, Reena Jana, Reza Ardeshir Rokni, Rishabh Agarwal, Ryan Mullins, Samaneh Saadat, Sara Mc Carthy, Sarah Perrin, Sébastien Arnold, Sebastian Krause, Shengyang Dai, Shruti Garg, Shruti Sheth, Sue Ronstrom, Susan Chan, Timothy Jordan, Ting Yu, Tom Eccles, Tom Hennigan, Tomas Kocisky, Tulsee Doshi, Vihan Jain, Vikas Yadav, Vilobh Meshram, Vishal Dharmadhikari, Warren Barkley, Wei Wei, Wenming Ye, Woohyun Han, Woosuk Kwon, Xiang Xu, Zhe Shen, Zhitao Gong, Zichuan Wei, Victor Cotruta, Phoebe Kirk, Anand Rao, Minh Giang, Ludovic Peran, Tris Warkentin, Eli Collins, Joelle Barral, Zoubin Ghahramani, Raia Hadsell, D. Sculley, Jeanine Banks, Anca Dragan, Slav Petrov, Oriol Vinyals, Jeff Dean, Demis Hassabis, Koray Kavukcuoglu, Clement Farabet, Elena Buchatskaya, Sebastian Borgeaud, Noah Fiedel, Armand Joulin, Kathleen Kenealy, Robert Dadashi, Alek Andreev

In this work, we introduce Gemma 2, a new addition to the Gemma family of
lightweight, state-of-the-art open models, ranging in scale from 2 billion to
27 billion parameters. In this new version, we apply several known technical
modifications to the Transformer architecture, such as interleaving
local-global attentions (Beltagy et al., 2020a) and group-query attention
(Ainslie et al., 2023). We also train the 2B and 9B models with knowledge
distillation (Hinton et al., 2015) instead of next token prediction. The
resulting models deliver the best performance for their size, and even offer
competitive alternatives to models that are 2-3 times bigger. We release all
our models to the community.

摘要：在本文中，我們介紹了 Gemma 2，它是 Gemma 系列輕量級、最先進的開放模型的新成員，規模從 20 億到 270 億個參數不等。在此新版本中，我們對 Transformer 架構應用了一些已知的技術修改，例如交錯局部全局注意力（Beltagy 等人，2020a）和組查詢注意力（Ainslie 等人，2023）。我們還使用知識蒸餾（Hinton 等人，2015）而不是下一個令牌預測來訓練 2B 和 9B 模型。由此產生的模型提供了與其規模相符的最佳性能，甚至提供了比大 2-3 倍的模型更有競爭力的替代方案。我們將所有模型發布給社區。

##### **Inductive or Deductive? Rethinking the Fundamental Reasoning Abilities of LLMs**
2408.00114v1 by Kewei Cheng, Jingfeng Yang, Haoming Jiang, Zhengyang Wang, Binxuan Huang, Ruirui Li, Shiyang Li, Zheng Li, Yifan Gao, Xian Li, Bing Yin, Yizhou Sun

Reasoning encompasses two typical types: deductive reasoning and inductive
reasoning. Despite extensive research into the reasoning capabilities of Large
Language Models (LLMs), most studies have failed to rigorously differentiate
between inductive and deductive reasoning, leading to a blending of the two.
This raises an essential question: In LLM reasoning, which poses a greater
challenge - deductive or inductive reasoning? While the deductive reasoning
capabilities of LLMs, (i.e. their capacity to follow instructions in reasoning
tasks), have received considerable attention, their abilities in true inductive
reasoning remain largely unexplored. To delve into the true inductive reasoning
capabilities of LLMs, we propose a novel framework, SolverLearner. This
framework enables LLMs to learn the underlying function (i.e., $y = f_w(x)$),
that maps input data points $(x)$ to their corresponding output values $(y)$,
using only in-context examples. By focusing on inductive reasoning and
separating it from LLM-based deductive reasoning, we can isolate and
investigate inductive reasoning of LLMs in its pure form via SolverLearner. Our
observations reveal that LLMs demonstrate remarkable inductive reasoning
capabilities through SolverLearner, achieving near-perfect performance with ACC
of 1 in most cases. Surprisingly, despite their strong inductive reasoning
abilities, LLMs tend to relatively lack deductive reasoning capabilities,
particularly in tasks involving ``counterfactual'' reasoning.

摘要：推理包含兩種典型類型：演繹推理和歸納推理。儘管對大型語言模型 (LLM) 的推理能力進行了廣泛的研究，但大多數研究未能嚴格區分演繹推理和歸納推理，導致兩者混為一談。這引發了一個基本問題：在 LLM 推理中，演繹推理還是歸納推理構成更大的挑戰？儘管 LLM 的演繹推理能力（即它們在推理任務中遵循指令的能力）受到了相當多的關注，但它們在真正的歸納推理中的能力在很大程度上仍未得到探索。為了深入探討 LLM 的真正歸納推理能力，我們提出了一個新框架 SolverLearner。此框架使 LLM 能夠學習底層函數（即 $y = f_w(x)$），它將輸入數據點 $(x)$ 映射到它們對應的輸出值 $(y)$，僅使用上下文中的範例。通過專注於歸納推理並將其與基於 LLM 的演繹推理分開，我們可以通過 SolverLearner 孤立和研究 LLM 的歸納推理的純粹形式。我們的觀察表明，LLM 通過 SolverLearner 展示了非凡的歸納推理能力，在大多數情況下以 1 的 ACC 達到了接近完美的性能。令人驚訝的是，儘管 LLM 具有強大的歸納推理能力，但它們往往相對缺乏演繹推理能力，特別是在涉及「反事實」推理的任務中。

##### **Measuring Progress in Dictionary Learning for Language Model Interpretability with Board Game Models**
2408.00113v1 by Adam Karvonen, Benjamin Wright, Can Rager, Rico Angell, Jannik Brinkmann, Logan Smith, Claudio Mayrink Verdun, David Bau, Samuel Marks

What latent features are encoded in language model (LM) representations?
Recent work on training sparse autoencoders (SAEs) to disentangle interpretable
features in LM representations has shown significant promise. However,
evaluating the quality of these SAEs is difficult because we lack a
ground-truth collection of interpretable features that we expect good SAEs to
recover. We thus propose to measure progress in interpretable dictionary
learning by working in the setting of LMs trained on chess and Othello
transcripts. These settings carry natural collections of interpretable features
-- for example, "there is a knight on F3" -- which we leverage into
$\textit{supervised}$ metrics for SAE quality. To guide progress in
interpretable dictionary learning, we introduce a new SAE training technique,
$\textit{p-annealing}$, which improves performance on prior unsupervised
metrics as well as our new metrics.

摘要：語言模型（LM）表徵中編碼了哪些潛在特徵？
最近關於訓練稀疏自動編碼器（SAE）以解開 LM 表徵中可解釋特徵的研究顯示出顯著的成果。然而，評估這些 SAE 的品質很困難，因為我們缺乏預期良好 SAE 能夠恢復的可解釋特徵的真實資料集。因此，我們提議透過在針對西洋棋和奧賽羅棋譜訓練的 LM 設定中工作來衡量可解釋字典學習的進度。這些設定包含自然的可解釋特徵集合，例如「F3 上有一個騎士」，我們將其運用到 SAE 品質的「監督式」指標中。為了引導可解釋字典學習的進度，我們引入了一種新的 SAE 訓練技術「p 退火」，它改善了先前非監督式指標以及我們的新指標的效能。

##### **Preference-Based Abstract Argumentation for Case-Based Reasoning (with-Appendix)**
2408.00108v1 by Adam Gould, Guilherme Paulino-Passos, Seema Dadhania, Matthew Williams, Francesca Toni

In the pursuit of enhancing the efficacy and flexibility of interpretable,
data-driven classification models, this work introduces a novel incorporation
of user-defined preferences with Abstract Argumentation and Case-Based
Reasoning (CBR). Specifically, we introduce Preference-Based Abstract
Argumentation for Case-Based Reasoning (which we call AA-CBR-P), allowing users
to define multiple approaches to compare cases with an ordering that specifies
their preference over these comparison approaches. We prove that the model
inherently follows these preferences when making predictions and show that
previous abstract argumentation for case-based reasoning approaches are
insufficient at expressing preferences over constituents of an argument. We
then demonstrate how this can be applied to a real-world medical dataset
sourced from a clinical trial evaluating differing assessment methods of
patients with a primary brain tumour. We show empirically that our approach
outperforms other interpretable machine learning models on this dataset.

摘要：為了提升可解釋、資料驅動分類模型的效能與靈活性，本研究提出了一種將使用者定義的偏好結合抽象論證與案例基礎推理 (CBR) 的新穎整合方式。具體來說，我們引入了偏好基礎抽象論證，用於案例基礎推理 (我們稱之為 AA-CBR-P)，允許使用者定義多種方法來比較案例，並透過設定順序來指定他們對這些比較方法的偏好。我們證明了此模型在進行預測時會固有地遵循這些偏好，並說明先前用於案例基礎推理的抽象論證不足以表達對論證組成部分的偏好。接著，我們展示如何將此方法應用於一個真實世界的醫療資料集，該資料集來自一項臨床試驗，評估了對原發性腦瘤患者的不同評估方法。我們透過實證證明，我們的做法在這個資料集上優於其他可解釋機器學習模型。

##### **WAS: Dataset and Methods for Artistic Text Segmentation**
2408.00106v1 by Xudong Xie, Yuzhe Li, Yang Liu, Zhifei Zhang, Zhaowen Wang, Wei Xiong, Xiang Bai

Accurate text segmentation results are crucial for text-related generative
tasks, such as text image generation, text editing, text removal, and text
style transfer. Recently, some scene text segmentation methods have made
significant progress in segmenting regular text. However, these methods perform
poorly in scenarios containing artistic text. Therefore, this paper focuses on
the more challenging task of artistic text segmentation and constructs a real
artistic text segmentation dataset. One challenge of the task is that the local
stroke shapes of artistic text are changeable with diversity and complexity. We
propose a decoder with the layer-wise momentum query to prevent the model from
ignoring stroke regions of special shapes. Another challenge is the complexity
of the global topological structure. We further design a skeleton-assisted head
to guide the model to focus on the global structure. Additionally, to enhance
the generalization performance of the text segmentation model, we propose a
strategy for training data synthesis, based on the large multi-modal model and
the diffusion model. Experimental results show that our proposed method and
synthetic dataset can significantly enhance the performance of artistic text
segmentation and achieve state-of-the-art results on other public datasets.

摘要：準確的文字分割結果對於文字相關的生成任務至關重要，例如文字影像生成、文字編輯、文字移除和文字樣式轉移。最近，一些場景文字分割方法在分割規則文字方面取得了顯著進展。然而，這些方法在包含藝術文字的場景中表現不佳。因此，本文重點關注更具挑戰性的藝術文字分割任務，並構建了一個真實的藝術文字分割資料集。該任務的一個挑戰是藝術文字的局部筆畫形狀會隨著多樣性和複雜性而改變。我們提出了一個具有逐層動量查詢的解碼器，以防止模型忽略特殊形狀的筆畫區域。另一個挑戰是全局拓撲結構的複雜性。我們進一步設計了一個骨架輔助頭部，以引導模型關注全局結構。此外，為了增強文字分割模型的泛化效能，我們提出了一種基於大型多模態模型和擴散模型的訓練資料合成策略。實驗結果表明，我們提出的方法和合成資料集可以顯著增強藝術文字分割的效能，並在其他公開資料集上取得最先進的結果。

##### **ReLiK: Retrieve and LinK, Fast and Accurate Entity Linking and Relation Extraction on an Academic Budget**
2408.00103v1 by Riccardo Orlando, Pere-Lluis Huguet-Cabot, Edoardo Barba, Roberto Navigli

Entity Linking (EL) and Relation Extraction (RE) are fundamental tasks in
Natural Language Processing, serving as critical components in a wide range of
applications. In this paper, we propose ReLiK, a Retriever-Reader architecture
for both EL and RE, where, given an input text, the Retriever module undertakes
the identification of candidate entities or relations that could potentially
appear within the text. Subsequently, the Reader module is tasked to discern
the pertinent retrieved entities or relations and establish their alignment
with the corresponding textual spans. Notably, we put forward an innovative
input representation that incorporates the candidate entities or relations
alongside the text, making it possible to link entities or extract relations in
a single forward pass and to fully leverage pre-trained language models
contextualization capabilities, in contrast with previous
Retriever-Reader-based methods, which require a forward pass for each
candidate. Our formulation of EL and RE achieves state-of-the-art performance
in both in-domain and out-of-domain benchmarks while using academic budget
training and with up to 40x inference speed compared to competitors. Finally,
we show how our architecture can be used seamlessly for Information Extraction
(cIE), i.e. EL + RE, and setting a new state of the art by employing a shared
Reader that simultaneously extracts entities and relations.

摘要：實體連結 (EL) 和關係抽取 (RE) 是自然語言處理中的基本任務，在廣泛的應用中擔任關鍵組成部分。在本文中，我們提出 ReLiK，一種用於 EL 和 RE 的檢索器-閱讀器架構，其中，在給定輸入文字時，檢索器模組承擔潛在可能出現在文字中的候選實體或關係的識別。隨後，閱讀器模組被指派辨別相關的檢索實體或關係，並建立它們與對應文字區間的對齊。值得注意的是，我們提出了創新的輸入表示，將候選實體或關係與文字結合在一起，使得在單一前向傳遞中連結實體或抽取關係，並充分利用預先訓練的語言模型情境化能力成為可能，這與先前的檢索器-閱讀器方法形成對比，後者需要針對每個候選進行前向傳遞。我們對 EL 和 RE 的公式化在領域內和領域外基準測試中都達到了最先進的效能，同時使用學術預算訓練，並且與競爭者相比，推論速度高達 40 倍。最後，我們展示了我們的架構如何能無縫地用於資訊抽取 (cIE)，即 EL + RE，並透過採用同時抽取實體和關係的共用閱讀器來設定新的最先進技術。

##### **From Attributes to Natural Language: A Survey and Foresight on Text-based Person Re-identification**
2408.00096v1 by Fanzhi Jiang, Su Yang, Mark W. Jones, Liumei Zhang

Text-based person re-identification (Re-ID) is a challenging topic in the
field of complex multimodal analysis, its ultimate aim is to recognize specific
pedestrians by scrutinizing attributes/natural language descriptions. Despite
the wide range of applicable areas such as security surveillance, video
retrieval, person tracking, and social media analytics, there is a notable
absence of comprehensive reviews dedicated to summarizing the text-based person
Re-ID from a technical perspective. To address this gap, we propose to
introduce a taxonomy spanning Evaluation, Strategy, Architecture, and
Optimization dimensions, providing a comprehensive survey of the text-based
person Re-ID task. We start by laying the groundwork for text-based person
Re-ID, elucidating fundamental concepts related to attribute/natural
language-based identification. Then a thorough examination of existing
benchmark datasets and metrics is presented. Subsequently, we further delve
into prevalent feature extraction strategies employed in text-based person
Re-ID research, followed by a concise summary of common network architectures
within the domain. Prevalent loss functions utilized for model optimization and
modality alignment in text-based person Re-ID are also scrutinized. To
conclude, we offer a concise summary of our findings, pinpointing challenges in
text-based person Re-ID. In response to these challenges, we outline potential
avenues for future open-set text-based person Re-ID and present a baseline
architecture for text-based pedestrian image generation-guided
re-identification(TBPGR).

摘要：<paragraph>基於文字的行人再辨識 (Re-ID) 是複雜多模態分析領域中一個具有挑戰性的課題，其最終目標是透過檢視屬性/自然語言描述來辨識特定行人。儘管在安全監控、影片擷取、人物追蹤和社群媒體分析等廣泛的應用領域中，但鮮少有全面的評論專門從技術角度總結基於文字的行人再辨識。為了填補這個缺口，我們提出了一個涵蓋評估、策略、架構和最佳化面向的分類法，提供基於文字的行人再辨識任務的全面調查。我們首先為基於文字的行人再辨識奠定基礎，闡明與屬性/基於自然語言的辨識相關的基本概念。接著徹底檢視現有的基準資料集和指標。隨後，我們進一步探討基於文字的行人再辨識研究中採用的流行特徵萃取策略，接著簡要總結該領域中常見的網路架構。基於文字的行人再辨識中用於模型最佳化和模態對齊的流行損失函數也受到仔細檢視。最後，我們簡要總結我們的發現，精確指出基於文字的行人再辨識的挑戰。針對這些挑戰，我們概述了未來開放式基於文字的行人再辨識的潛在途徑，並提出了基於文字的行人影像生成導向再辨識 (TBPGR) 的基準架構。</paragraph>

##### **Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey**
2407.21794v1 by Atsuyuki Miyai, Jingkang Yang, Jingyang Zhang, Yifei Ming, Yueqian Lin, Qing Yu, Go Irie, Shafiq Joty, Yixuan Li, Hai Li, Ziwei Liu, Toshihiko Yamasaki, Kiyoharu Aizawa

Detecting out-of-distribution (OOD) samples is crucial for ensuring the
safety of machine learning systems and has shaped the field of OOD detection.
Meanwhile, several other problems are closely related to OOD detection,
including anomaly detection (AD), novelty detection (ND), open set recognition
(OSR), and outlier detection (OD). To unify these problems, a generalized OOD
detection framework was proposed, taxonomically categorizing these five
problems. However, Vision Language Models (VLMs) such as CLIP have
significantly changed the paradigm and blurred the boundaries between these
fields, again confusing researchers. In this survey, we first present a
generalized OOD detection v2, encapsulating the evolution of AD, ND, OSR, OOD
detection, and OD in the VLM era. Our framework reveals that, with some field
inactivity and integration, the demanding challenges have become OOD detection
and AD. In addition, we also highlight the significant shift in the definition,
problem settings, and benchmarks; we thus feature a comprehensive review of the
methodology for OOD detection, including the discussion over other related
tasks to clarify their relationship to OOD detection. Finally, we explore the
advancements in the emerging Large Vision Language Model (LVLM) era, such as
GPT-4V. We conclude this survey with open challenges and future directions.

摘要：偵測異常樣本 (OOD) 對於確保機器學習系統的安全性至關重要，並形塑了 OOD 偵測領域。同時，還有許多其他問題與 OOD 偵測息息相關，包括異常偵測 (AD)、新穎性偵測 (ND)、開放集識別 (OSR) 和離群值偵測 (OD)。為了統一這些問題，提出了廣義的 OOD 偵測架構，將這五個問題分類。然而，像 CLIP 等視覺語言模型 (VLM) 已大幅改變典範，並模糊了這些領域之間的界線，再次讓研究人員感到困惑。在這項調查中，我們首先提出廣義的 OOD 偵測 v2，概括了 AD、ND、OSR、OOD 偵測和 OD 在 VLM 時代的演進。我們的架構揭示，由於某些領域的不活躍和整合，具有挑戰性的問題已成為 OOD 偵測和 AD。此外，我們也重點說明定義、問題設定和基準的重大轉變；因此，我們對 OOD 偵測的方法論進行全面檢視，包括討論其他相關任務以釐清它們與 OOD 偵測的關係。最後，我們探討新興的大型視覺語言模型 (LVLM) 時代的進展，例如 GPT-4V。我們以開放挑戰和未來方向作為這項調查的結論。

##### **Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress?**
2407.21792v1 by Richard Ren, Steven Basart, Adam Khoja, Alice Gatti, Long Phan, Xuwang Yin, Mantas Mazeika, Alexander Pan, Gabriel Mukobi, Ryan H. Kim, Stephen Fitz, Dan Hendrycks

As artificial intelligence systems grow more powerful, there has been
increasing interest in "AI safety" research to address emerging and future
risks. However, the field of AI safety remains poorly defined and
inconsistently measured, leading to confusion about how researchers can
contribute. This lack of clarity is compounded by the unclear relationship
between AI safety benchmarks and upstream general capabilities (e.g., general
knowledge and reasoning). To address these issues, we conduct a comprehensive
meta-analysis of AI safety benchmarks, empirically analyzing their correlation
with general capabilities across dozens of models and providing a survey of
existing directions in AI safety. Our findings reveal that many safety
benchmarks highly correlate with upstream model capabilities, potentially
enabling "safetywashing" -- where capability improvements are misrepresented as
safety advancements. Based on these findings, we propose an empirical
foundation for developing more meaningful safety metrics and define AI safety
in a machine learning research context as a set of clearly delineated research
goals that are empirically separable from generic capabilities advancements. In
doing so, we aim to provide a more rigorous framework for AI safety research,
advancing the science of safety evaluations and clarifying the path towards
measurable progress.

摘要：隨著人工智慧系統變得越來越強大，對於「AI 安全」的研究興趣也與日俱增，以因應新興和未來的風險。然而，AI 安全領域的定義仍然很模糊，衡量標準也不一致，導致研究人員如何做出貢獻感到困惑。AI 安全基準與上游一般能力（例如一般知識和推理）之間關係不明確，進一步加劇了這種不確定性。為了解決這些問題，我們對 AI 安全基準進行了全面的後設分析，根據數十個模型實證分析它們與一般能力的相關性，並對 AI 安全中的現有方向進行調查。我們的研究結果顯示，許多安全基準與上游模型能力高度相關，這可能會導致「安全漂白」——將能力的提升誤認為是安全性的進步。根據這些研究結果，我們提出了一個實證基礎，用於開發更有意義的安全指標，並在機器學習研究背景下將 AI 安全定義為一組明確界定的研究目標，這些目標在實證上可以與一般能力的進步區分開來。透過這麼做，我們旨在為 AI 安全研究提供一個更嚴謹的架構，推進安全評估的科學，並釐清邁向可衡量進展的道路。

##### **Vision-Language Model Based Handwriting Verification**
2407.21788v1 by Mihir Chauhan, Abhishek Satbhai, Mohammad Abuzar Hashemi, Mir Basheer Ali, Bina Ramamurthy, Mingchen Gao, Siwei Lyu, Sargur Srihari

Handwriting Verification is a critical in document forensics. Deep learning
based approaches often face skepticism from forensic document examiners due to
their lack of explainability and reliance on extensive training data and
handcrafted features. This paper explores using Vision Language Models (VLMs),
such as OpenAI's GPT-4o and Google's PaliGemma, to address these challenges. By
leveraging their Visual Question Answering capabilities and 0-shot
Chain-of-Thought (CoT) reasoning, our goal is to provide clear,
human-understandable explanations for model decisions. Our experiments on the
CEDAR handwriting dataset demonstrate that VLMs offer enhanced
interpretability, reduce the need for large training datasets, and adapt better
to diverse handwriting styles. However, results show that the CNN-based
ResNet-18 architecture outperforms the 0-shot CoT prompt engineering approach
with GPT-4o (Accuracy: 70%) and supervised fine-tuned PaliGemma (Accuracy:
71%), achieving an accuracy of 84% on the CEDAR AND dataset. These findings
highlight the potential of VLMs in generating human-interpretable decisions
while underscoring the need for further advancements to match the performance
of specialized deep learning models.

摘要：手寫驗證在文件鑑識中至關重要。基於深度學習的方法通常會受到文件鑑識專家的懷疑，原因在於它們缺乏可解釋性，並且依賴於大量的訓練資料和手工特徵。本文探討使用視覺語言模型 (VLM)，例如 OpenAI 的 GPT-4o 和 Google 的 PaliGemma，來解決這些挑戰。通過利用它們的視覺問答能力和 0-shot 思想鏈 (CoT) 推理，我們的目標是為模型決策提供清晰、人類可以理解的解釋。我們在 CEDAR 手寫資料集上的實驗表明，VLM 提供了增強的可解釋性，減少了對大型訓練資料集的需求，並且可以更好地適應不同的手寫風格。然而，結果表明，基於 CNN 的 ResNet-18 架構優於使用 GPT-4o（準確率：70%）和監督微調 PaliGemma（準確率：71%）的 0-shot CoT 提示工程方法，在 CEDAR AND 資料集上達到了 84% 的準確率。這些發現突顯了 VLM 在產生人類可以理解的決策方面的潛力，同時也強調了進一步提升與專業深度學習模型相匹配的效能的必要性。

##### **Large Language Monkeys: Scaling Inference Compute with Repeated Sampling**
2407.21787v1 by Bradley Brown, Jordan Juravsky, Ryan Ehrlich, Ronald Clark, Quoc V. Le, Christopher Ré, Azalia Mirhoseini

Scaling the amount of compute used to train language models has dramatically
improved their capabilities. However, when it comes to inference, we often
limit the amount of compute to only one attempt per problem. Here, we explore
inference compute as another axis for scaling by increasing the number of
generated samples. Across multiple tasks and models, we observe that coverage -
the fraction of problems solved by any attempt - scales with the number of
samples over four orders of magnitude. In domains like coding and formal
proofs, where all answers can be automatically verified, these increases in
coverage directly translate into improved performance. When we apply repeated
sampling to SWE-bench Lite, the fraction of issues solved with
DeepSeek-V2-Coder-Instruct increases from 15.9% with one sample to 56% with 250
samples, outperforming the single-attempt state-of-the-art of 43% which uses
more capable frontier models. Moreover, using current API pricing, amplifying
the cheaper DeepSeek model with five samples is more cost-effective and solves
more issues than paying a premium for one sample from GPT-4o or Claude 3.5
Sonnet. Interestingly, the relationship between coverage and the number of
samples is often log-linear and can be modelled with an exponentiated power
law, suggesting the existence of inference-time scaling laws. Finally, we find
that identifying correct samples out of many generations remains an important
direction for future research in domains without automatic verifiers. When
solving math word problems from GSM8K and MATH, coverage with Llama-3 models
grows to over 95% with 10,000 samples. However, common methods to pick correct
solutions from a sample collection, such as majority voting or reward models,
plateau beyond several hundred samples and fail to fully scale with the sample
budget.

摘要：<paragraph>擴大用於訓練語言模型的運算量已大幅提升其功能。然而，在進行推論時，我們通常將運算量限制在每個問題僅嘗試一次。在此，我們將推論運算視為另一種擴展軸，藉由增加生成範例的數量來進行擴展。在多個任務和模型中，我們觀察到覆蓋率（任何嘗試解決問題的分數）會隨著範例數量而擴展，超過四個數量級。在編碼和形式化證明等領域中，所有答案都可以自動驗證，這些覆蓋率的增加會直接轉化為效能的提升。當我們將重複抽樣套用於 SWE-bench Lite 時，使用 DeepSeek-V2-Coder-Instruct 解決問題的分數從一個範例的 15.9% 提升到 250 個範例的 56%，優於使用功能更強大的前沿模型而達到的 43% 單次嘗試最先進水準。此外，使用目前的 API 定價，以五個範例擴充較便宜的 DeepSeek 模型比支付溢價取得 GPT-4o 或 Claude 3.5 Sonnet 的一個範例更具成本效益，且能解決更多問題。有趣的是，覆蓋率與範例數量之間的關係通常是對數線性的，且可用指數冪律建模，這表示存在推論時間擴展律。最後，我們發現從許多世代中找出正確範例仍然是沒有自動驗證器的領域中未來研究的重要方向。在解決 GSM8K 和 MATH 的數學文字題時，使用 Llama-3 模型的覆蓋率會在 10,000 個範例中成長到超過 95%。然而，從範例集合中挑選正確解答的常見方法（例如多數決或獎勵模型）會在數百個範例後達到平穩期，且無法完全隨著範例預算而擴展。</paragraph>

##### **The Llama 3 Herd of Models**
2407.21783v1 by Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, Anirudh Goyal, Anthony Hartshorn, Aobo Yang, Archi Mitra, Archie Sravankumar, Artem Korenev, Arthur Hinsvark, Arun Rao, Aston Zhang, Aurelien Rodriguez, Austen Gregerson, Ava Spataru, Baptiste Roziere, Bethany Biron, Binh Tang, Bobbie Chern, Charlotte Caucheteux, Chaya Nayak, Chloe Bi, Chris Marra, Chris McConnell, Christian Keller, Christophe Touret, Chunyang Wu, Corinne Wong, Cristian Canton Ferrer, Cyrus Nikolaidis, Damien Allonsius, Daniel Song, Danielle Pintz, Danny Livshits, David Esiobu, Dhruv Choudhary, Dhruv Mahajan, Diego Garcia-Olano, Diego Perino, Dieuwke Hupkes, Egor Lakomkin, Ehab AlBadawy, Elina Lobanova, Emily Dinan, Eric Michael Smith, Filip Radenovic, Frank Zhang, Gabriel Synnaeve, Gabrielle Lee, Georgia Lewis Anderson, Graeme Nail, Gregoire Mialon, Guan Pang, Guillem Cucurell, Hailey Nguyen, Hannah Korevaar, Hu Xu, Hugo Touvron, Iliyan Zarov, Imanol Arrieta Ibarra, Isabel Kloumann, Ishan Misra, Ivan Evtimov, Jade Copet, Jaewon Lee, Jan Geffert, Jana Vranes, Jason Park, Jay Mahadeokar, Jeet Shah, Jelmer van der Linde, Jennifer Billock, Jenny Hong, Jenya Lee, Jeremy Fu, Jianfeng Chi, Jianyu Huang, Jiawen Liu, Jie Wang, Jiecao Yu, Joanna Bitton, Joe Spisak, Jongsoo Park, Joseph Rocca, Joshua Johnstun, Joshua Saxe, Junteng Jia, Kalyan Vasuden Alwala, Kartikeya Upasani, Kate Plawiak, Ke Li, Kenneth Heafield, Kevin Stone, Khalid El-Arini, Krithika Iyer, Kshitiz Malik, Kuenley Chiu, Kunal Bhalla, Lauren Rantala-Yeary, Laurens van der Maaten, Lawrence Chen, Liang Tan, Liz Jenkins, Louis Martin, Lovish Madaan, Lubo Malo, Lukas Blecher, Lukas Landzaat, Luke de Oliveira, Madeline Muzzi, Mahesh Pasupuleti, Mannat Singh, Manohar Paluri, Marcin Kardas, Mathew Oldham, Mathieu Rita, Maya Pavlova, Melanie Kambadur, Mike Lewis, Min Si, Mitesh Kumar Singh, Mona Hassan, Naman Goyal, Narjes Torabi, Nikolay Bashlykov, Nikolay Bogoychev, Niladri Chatterji, Olivier Duchenne, Onur Çelebi, Patrick Alrassy, Pengchuan Zhang, Pengwei Li, Petar Vasic, Peter Weng, Prajjwal Bhargava, Pratik Dubal, Praveen Krishnan, Punit Singh Koura, Puxin Xu, Qing He, Qingxiao Dong, Ragavan Srinivasan, Raj Ganapathy, Ramon Calderer, Ricardo Silveira Cabral, Robert Stojnic, Roberta Raileanu, Rohit Girdhar, Rohit Patel, Romain Sauvestre, Ronnie Polidoro, Roshan Sumbaly, Ross Taylor, Ruan Silva, Rui Hou, Rui Wang, Saghar Hosseini, Sahana Chennabasappa, Sanjay Singh, Sean Bell, Seohyun Sonia Kim, Sergey Edunov, Shaoliang Nie, Sharan Narang, Sharath Raparthy, Sheng Shen, Shengye Wan, Shruti Bhosale, Shun Zhang, Simon Vandenhende, Soumya Batra, Spencer Whitman, Sten Sootla, Stephane Collot, Suchin Gururangan, Sydney Borodinsky, Tamar Herman, Tara Fowler, Tarek Sheasha, Thomas Georgiou, Thomas Scialom, Tobias Speckbacher, Todor Mihaylov, Tong Xiao, Ujjwal Karn, Vedanuj Goswami, Vibhor Gupta, Vignesh Ramanathan, Viktor Kerkez, Vincent Gonguet, Virginie Do, Vish Vogeti, Vladan Petrovic, Weiwei Chu, Wenhan Xiong, Wenyin Fu, Whitney Meers, Xavier Martinet, Xiaodong Wang, Xiaoqing Ellen Tan, Xinfeng Xie, Xuchao Jia, Xuewei Wang, Yaelle Goldschlag, Yashesh Gaur, Yasmine Babaei, Yi Wen, Yiwen Song, Yuchen Zhang, Yue Li, Yuning Mao, Zacharie Delpierre Coudert, Zheng Yan, Zhengxing Chen, Zoe Papakipos, Aaditya Singh, Aaron Grattafiori, Abha Jain, Adam Kelsey, Adam Shajnfeld, Adithya Gangidi, Adolfo Victoria, Ahuva Goldstand, Ajay Menon, Ajay Sharma, Alex Boesenberg, Alex Vaughan, Alexei Baevski, Allie Feinstein, Amanda Kallet, Amit Sangani, Anam Yunus, Andrei Lupu, Andres Alvarado, Andrew Caples, Andrew Gu, Andrew Ho, Andrew Poulton, Andrew Ryan, Ankit Ramchandani, Annie Franco, Aparajita Saraf, Arkabandhu Chowdhury, Ashley Gabriel, Ashwin Bharambe, Assaf Eisenman, Azadeh Yazdan, Beau James, Ben Maurer, Benjamin Leonhardi, Bernie Huang, Beth Loyd, Beto De Paola, Bhargavi Paranjape, Bing Liu, Bo Wu, Boyu Ni, Braden Hancock, Bram Wasti, Brandon Spence, Brani Stojkovic, Brian Gamido, Britt Montalvo, Carl Parker, Carly Burton, Catalina Mejia, Changhan Wang, Changkyu Kim, Chao Zhou, Chester Hu, Ching-Hsiang Chu, Chris Cai, Chris Tindal, Christoph Feichtenhofer, Damon Civin, Dana Beaty, Daniel Kreymer, Daniel Li, Danny Wyatt, David Adkins, David Xu, Davide Testuggine, Delia David, Devi Parikh, Diana Liskovich, Didem Foss, Dingkang Wang, Duc Le, Dustin Holland, Edward Dowling, Eissa Jamil, Elaine Montgomery, Eleonora Presani, Emily Hahn, Emily Wood, Erik Brinkman, Esteban Arcaute, Evan Dunbar, Evan Smothers, Fei Sun, Felix Kreuk, Feng Tian, Firat Ozgenel, Francesco Caggioni, Francisco Guzmán, Frank Kanayet, Frank Seide, Gabriela Medina Florez, Gabriella Schwarz, Gada Badeer, Georgia Swee, Gil Halpern, Govind Thattai, Grant Herman, Grigory Sizov, Guangyi, Zhang, Guna Lakshminarayanan, Hamid Shojanazeri, Han Zou, Hannah Wang, Hanwen Zha, Haroun Habeeb, Harrison Rudolph, Helen Suk, Henry Aspegren, Hunter Goldman, Igor Molybog, Igor Tufanov, Irina-Elena Veliche, Itai Gat, Jake Weissman, James Geboski, James Kohli, Japhet Asher, Jean-Baptiste Gaya, Jeff Marcus, Jeff Tang, Jennifer Chan, Jenny Zhen, Jeremy Reizenstein, Jeremy Teboul, Jessica Zhong, Jian Jin, Jingyi Yang, Joe Cummings, Jon Carvill, Jon Shepard, Jonathan McPhie, Jonathan Torres, Josh Ginsburg, Junjie Wang, Kai Wu, Kam Hou U, Karan Saxena, Karthik Prasad, Kartikay Khandelwal, Katayoun Zand, Kathy Matosich, Kaushik Veeraraghavan, Kelly Michelena, Keqian Li, Kun Huang, Kunal Chawla, Kushal Lakhotia, Kyle Huang, Lailin Chen, Lakshya Garg, Lavender A, Leandro Silva, Lee Bell, Lei Zhang, Liangpeng Guo, Licheng Yu, Liron Moshkovich, Luca Wehrstedt, Madian Khabsa, Manav Avalani, Manish Bhatt, Maria Tsimpoukelli, Martynas Mankus, Matan Hasson, Matthew Lennie, Matthias Reso, Maxim Groshev, Maxim Naumov, Maya Lathi, Meghan Keneally, Michael L. Seltzer, Michal Valko, Michelle Restrepo, Mihir Patel, Mik Vyatskov, Mikayel Samvelyan, Mike Clark, Mike Macey, Mike Wang, Miquel Jubert Hermoso, Mo Metanat, Mohammad Rastegari, Munish Bansal, Nandhini Santhanam, Natascha Parks, Natasha White, Navyata Bawa, Nayan Singhal, Nick Egebo, Nicolas Usunier, Nikolay Pavlovich Laptev, Ning Dong, Ning Zhang, Norman Cheng, Oleg Chernoguz, Olivia Hart, Omkar Salpekar, Ozlem Kalinli, Parkin Kent, Parth Parekh, Paul Saab, Pavan Balaji, Pedro Rittner, Philip Bontrager, Pierre Roux, Piotr Dollar, Polina Zvyagina, Prashant Ratanchandani, Pritish Yuvraj, Qian Liang, Rachad Alao, Rachel Rodriguez, Rafi Ayub, Raghotham Murthy, Raghu Nayani, Rahul Mitra, Raymond Li, Rebekkah Hogan, Robin Battey, Rocky Wang, Rohan Maheswari, Russ Howes, Ruty Rinott, Sai Jayesh Bondu, Samyak Datta, Sara Chugh, Sara Hunt, Sargun Dhillon, Sasha Sidorov, Satadru Pan, Saurabh Verma, Seiji Yamamoto, Sharadh Ramaswamy, Shaun Lindsay, Shaun Lindsay, Sheng Feng, Shenghao Lin, Shengxin Cindy Zha, Shiva Shankar, Shuqiang Zhang, Shuqiang Zhang, Sinong Wang, Sneha Agarwal, Soji Sajuyigbe, Soumith Chintala, Stephanie Max, Stephen Chen, Steve Kehoe, Steve Satterfield, Sudarshan Govindaprasad, Sumit Gupta, Sungmin Cho, Sunny Virk, Suraj Subramanian, Sy Choudhury, Sydney Goldman, Tal Remez, Tamar Glaser, Tamara Best, Thilo Kohler, Thomas Robinson, Tianhe Li, Tianjun Zhang, Tim Matthews, Timothy Chou, Tzook Shaked, Varun Vontimitta, Victoria Ajayi, Victoria Montanez, Vijai Mohan, Vinay Satish Kumar, Vishal Mangla, Vlad Ionescu, Vlad Poenaru, Vlad Tiberiu Mihailescu, Vladimir Ivanov, Wei Li, Wenchen Wang, Wenwen Jiang, Wes Bouaziz, Will Constable, Xiaocheng Tang, Xiaofang Wang, Xiaojian Wu, Xiaolan Wang, Xide Xia, Xilun Wu, Xinbo Gao, Yanjun Chen, Ye Hu, Ye Jia, Ye Qi, Yenda Li, Yilin Zhang, Ying Zhang, Yossi Adi, Youngjin Nam, Yu, Wang, Yuchen Hao, Yundi Qian, Yuzi He, Zach Rait, Zachary DeVito, Zef Rosnbrick, Zhaoduo Wen, Zhenyu Yang, Zhiwei Zhao

Modern artificial intelligence (AI) systems are powered by foundation models.
This paper presents a new set of foundation models, called Llama 3. It is a
herd of language models that natively support multilinguality, coding,
reasoning, and tool usage. Our largest model is a dense Transformer with 405B
parameters and a context window of up to 128K tokens. This paper presents an
extensive empirical evaluation of Llama 3. We find that Llama 3 delivers
comparable quality to leading language models such as GPT-4 on a plethora of
tasks. We publicly release Llama 3, including pre-trained and post-trained
versions of the 405B parameter language model and our Llama Guard 3 model for
input and output safety. The paper also presents the results of experiments in
which we integrate image, video, and speech capabilities into Llama 3 via a
compositional approach. We observe this approach performs competitively with
the state-of-the-art on image, video, and speech recognition tasks. The
resulting models are not yet being broadly released as they are still under
development.

摘要：現代人工智慧 (AI) 系統由基礎模型提供動力。
本文提出了一組新的基礎模型，稱為 Llama 3。它是一群語言模型，本機支援多語言、編碼、推理和工具使用。我們最大的模型是一個具有 405B 參數和最多 128K 令牌的上下文視窗的密集Transformer。本文提供了對 Llama 3 的廣泛實證評估。我們發現 Llama 3 在大量任務上提供了與 GPT-4 等領先語言模型相當的品質。我們公開發布 Llama 3，包括 405B 參數語言模型的預訓練和後訓練版本，以及我們的 Llama Guard 3 模型，用於輸入和輸出安全性。本文還提供了將影像、影片和語音功能整合到 Llama 3 中的實驗結果，方法是採用組合式方法。我們觀察到這種方法在影像、影片和語音辨識任務上表現出與最先進技術相當的競爭力。由於這些模型仍處於開發階段，因此尚未廣泛發布。

##### **Tulip Agent -- Enabling LLM-Based Agents to Solve Tasks Using Large Tool Libraries**
2407.21778v1 by Felix Ocker, Daniel Tanneberg, Julian Eggert, Michael Gienger

We introduce tulip agent, an architecture for autonomous LLM-based agents
with Create, Read, Update, and Delete access to a tool library containing a
potentially large number of tools. In contrast to state-of-the-art
implementations, tulip agent does not encode the descriptions of all available
tools in the system prompt, which counts against the model's context window, or
embed the entire prompt for retrieving suitable tools. Instead, the tulip agent
can recursively search for suitable tools in its extensible tool library,
implemented exemplarily as a vector store. The tulip agent architecture
significantly reduces inference costs, allows using even large tool libraries,
and enables the agent to adapt and extend its set of tools. We evaluate the
architecture with several ablation studies in a mathematics context and
demonstrate its generalizability with an application to robotics. A reference
implementation and the benchmark are available at
github.com/HRI-EU/tulip_agent.

摘要：我們介紹了 Tulip 代理，一種基於自主 LLM 的代理架構，可以對包含大量工具的工具庫進行建立、讀取、更新和刪除存取。與最先進的實作相反，Tulip 代理不會將所有可用工具的描述編碼在系統提示中，這會計入模型的內容視窗，或嵌入整個提示以擷取合適的工具。相反地，Tulip 代理可以在其可延伸工具庫中遞迴搜尋合適的工具，範例實作為向量儲存。Tulip 代理架構大幅降低了推論成本，允許使用甚至大型工具庫，並讓代理調整和延伸其工具組。我們在數學背景中使用多項消融研究評估架構，並透過機器人應用程式展示其概括性。可以在 github.com/HRI-EU/tulip_agent 取得參考實作和基準。

##### **ShieldGemma: Generative AI Content Moderation Based on Gemma**
2407.21772v1 by Wenjun Zeng, Yuchi Liu, Ryan Mullins, Ludovic Peran, Joe Fernandez, Hamza Harkous, Karthik Narasimhan, Drew Proud, Piyush Kumar, Bhaktipriya Radharapu, Olivia Sturman, Oscar Wahltinez

We present ShieldGemma, a comprehensive suite of LLM-based safety content
moderation models built upon Gemma2. These models provide robust,
state-of-the-art predictions of safety risks across key harm types (sexually
explicit, dangerous content, harassment, hate speech) in both user input and
LLM-generated output. By evaluating on both public and internal benchmarks, we
demonstrate superior performance compared to existing models, such as Llama
Guard (+10.8\% AU-PRC on public benchmarks) and WildCard (+4.3\%).
Additionally, we present a novel LLM-based data curation pipeline, adaptable to
a variety of safety-related tasks and beyond. We have shown strong
generalization performance for model trained mainly on synthetic data. By
releasing ShieldGemma, we provide a valuable resource to the research
community, advancing LLM safety and enabling the creation of more effective
content moderation solutions for developers.

摘要：我們展示 ShieldGemma，這是一套建構於 Gemma2 的全面 LLM 安全內容審核模型套件。這些模型提供健全、最先進的安全性風險預測，涵蓋使用者輸入和 LLM 產生的輸出中的主要危害類型（露骨性內容、危險內容、騷擾、仇恨言論）。透過在公開和內部基準上進行評估，我們展示出優於現有模型的卓越效能，例如 Llama Guard（在公開基準上 +10.8% AU-PRC）和 WildCard（+4.3%）。此外，我們提出一個新穎的 LLM 資料策管流程，適用於各種安全相關任務及其他任務。我們已展示出對於主要訓練在合成資料上的模型的強大泛化效能。透過釋出 ShieldGemma，我們為研究社群提供了寶貴的資源，推進 LLM 安全性並協助開發人員建立更有效的內容審核解決方案。

##### **MoMa: Efficient Early-Fusion Pre-training with Mixture of Modality-Aware Experts**
2407.21770v1 by Xi Victoria Lin, Akshat Shrivastava, Liang Luo, Srinivasan Iyer, Mike Lewis, Gargi Gosh, Luke Zettlemoyer, Armen Aghajanyan

We introduce MoMa, a novel modality-aware mixture-of-experts (MoE)
architecture designed for pre-training mixed-modal, early-fusion language
models. MoMa processes images and text in arbitrary sequences by dividing
expert modules into modality-specific groups. These groups exclusively process
designated tokens while employing learned routing within each group to maintain
semantically informed adaptivity. Our empirical results reveal substantial
pre-training efficiency gains through this modality-specific parameter
allocation. Under a 1-trillion-token training budget, the MoMa 1.4B model,
featuring 4 text experts and 4 image experts, achieves impressive FLOPs
savings: 3.7x overall, with 2.6x for text and 5.2x for image processing
compared to a compute-equivalent dense baseline, measured by pre-training loss.
This outperforms the standard expert-choice MoE with 8 mixed-modal experts,
which achieves 3x overall FLOPs savings (3x for text, 2.8x for image).
Combining MoMa with mixture-of-depths (MoD) further improves pre-training FLOPs
savings to 4.2x overall (text: 3.4x, image: 5.3x), although this combination
hurts performance in causal inference due to increased sensitivity to router
accuracy. These results demonstrate MoMa's potential to significantly advance
the efficiency of mixed-modal, early-fusion language model pre-training, paving
the way for more resource-efficient and capable multimodal AI systems.

摘要：<paragraph>我們介紹 MoMa，一種新穎的模態感知混合專家 (MoE) 架構，專為混合模態、早期融合語言模型的預訓練而設計。MoMa 透過將專家模組分為模態特定群組，以任意順序處理影像和文字。這些群組會獨自處理指定的代碼，同時在每個群組內使用已學習的路由，以維持語義適應性。我們的實證結果顯示，透過這種模態特定參數配置，可大幅提升預訓練效率。在 1 兆個代碼的訓練預算下，MoMa 1.4B 模型配備 4 個文字專家和 4 個影像專家，可節省令人驚豔的 FLOP：整體而言為 3.7 倍，文字處理為 2.6 倍，影像處理為 5.2 倍，這是以預訓練損失測量，並與運算等效的密集基準線相比較。這優於標準的專家選擇 MoE，後者配備 8 個混合模態專家，可節省整體 FLOP 3 倍（文字為 3 倍，影像為 2.8 倍）。將 MoMa 與混合深度 (MoD) 結合，可進一步將預訓練 FLOP 節省提升至整體 4.2 倍（文字：3.4 倍，影像：5.3 倍），儘管這種組合會因路由器精確度敏感度增加而損害因果推理的效能。這些結果證明了 MoMa 在提升混合模態、早期融合語言模型預訓練效率方面的潛力，為更具資源效率且功能強大的多模態 AI 系統鋪路。</paragraph>

