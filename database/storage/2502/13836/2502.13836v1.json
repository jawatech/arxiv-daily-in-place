{"2502.13836": {"publish_time": "2025-02-19", "title": "Quantifying Memorization and Retriever Performance in Retrieval-Augmented Vision-Language Models", "paper_summary": "Large Language Models (LLMs) demonstrate remarkable capabilities in question\nanswering (QA), but metrics for assessing their reliance on memorization versus\nretrieval remain underdeveloped. Moreover, while finetuned models are\nstate-of-the-art on closed-domain tasks, general-purpose models like GPT-4o\nexhibit strong zero-shot performance. This raises questions about the\ntrade-offs between memorization, generalization, and retrieval. In this work,\nwe analyze the extent to which multimodal retrieval-augmented VLMs memorize\ntraining data compared to baseline VLMs. Using the WebQA benchmark, we contrast\nfinetuned models with baseline VLMs on multihop retrieval and question\nanswering, examining the impact of finetuning on data memorization. To quantify\nmemorization in end-to-end retrieval and QA systems, we propose several proxy\nmetrics by investigating instances where QA succeeds despite retrieval failing.\nOur results reveal the extent to which finetuned models rely on memorization.\nIn contrast, retrieval-augmented VLMs have lower memorization scores, at the\ncost of accuracy (72% vs 52% on WebQA test set). As such, our measures pose a\nchallenge for future work to reconcile memorization and generalization in both\nOpen-Domain QA and joint Retrieval-QA tasks.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u554f\u7b54\uff08QA\uff09\u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u9a5a\u4eba\u7684\u80fd\u529b\uff0c\u4f46\u7528\u65bc\u8a55\u4f30\u5176\u4f9d\u8cf4\u8a18\u61b6\u800c\u975e\u6aa2\u7d22\u7684\u6307\u6a19\u4ecd\u672a\u767c\u5c55\u6210\u719f\u3002\u6b64\u5916\uff0c\u96d6\u7136\u5fae\u8abf\u6a21\u578b\u5728\u5c01\u9589\u9818\u57df\u4efb\u52d9\u4e2d\u662f\u76ee\u524d\u6700\u5148\u9032\u7684\u6280\u8853\uff0c\u4f46\u50cf GPT-4o \u9019\u6a23\u7684\u901a\u7528\u6a21\u578b\u5c55\u73fe\u51fa\u5f37\u5927\u7684\u96f6\u6b21\u5b78\u7fd2\u6548\u80fd\u3002\u9019\u5f15\u767c\u4e86\u95dc\u65bc\u8a18\u61b6\u3001\u6982\u5316\u548c\u6aa2\u7d22\u4e4b\u9593\u6b0a\u8861\u53d6\u6368\u7684\u554f\u984c\u3002\u5728\u9019\u9805\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u5206\u6790\u4e86\u591a\u6a21\u614b\u6aa2\u7d22\u589e\u5f37 VLM \u8207\u57fa\u6e96 VLM \u76f8\u6bd4\uff0c\u8a18\u61b6\u8a13\u7df4\u8cc7\u6599\u7684\u7a0b\u5ea6\u3002\u4f7f\u7528 WebQA \u57fa\u6e96\uff0c\u6211\u5011\u5728\u591a\u8df3\u6aa2\u7d22\u548c\u554f\u7b54\u65b9\u9762\u6bd4\u8f03\u4e86\u5fae\u8abf\u6a21\u578b\u548c\u57fa\u6e96 VLM\uff0c\u4e26\u63a2\u8a0e\u5fae\u8abf\u5c0d\u8cc7\u6599\u8a18\u61b6\u7684\u5f71\u97ff\u3002\u70ba\u4e86\u91cf\u5316\u7aef\u5230\u7aef\u6aa2\u7d22\u548c QA \u7cfb\u7d71\u4e2d\u7684\u8a18\u61b6\uff0c\u6211\u5011\u900f\u904e\u63a2\u8a0e\u6aa2\u7d22\u5931\u6557\u4f46 QA \u6210\u529f\u7684\u60c5\u6cc1\uff0c\u63d0\u51fa\u4e86\u5e7e\u500b\u4ee3\u7406\u6307\u6a19\u3002\u6211\u5011\u7684\u7d50\u679c\u63ed\u793a\u4e86\u5fae\u8abf\u6a21\u578b\u4f9d\u8cf4\u8a18\u61b6\u7684\u7a0b\u5ea6\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u6aa2\u7d22\u589e\u5f37 VLM \u7684\u8a18\u61b6\u5206\u6578\u8f03\u4f4e\uff0c\u4f46\u4ee3\u50f9\u662f\u6e96\u78ba\u5ea6\uff08\u5728 WebQA \u6e2c\u8a66\u96c6\u4e2d\u70ba 72% \u5c0d 52%\uff09\u3002\u56e0\u6b64\uff0c\u6211\u5011\u7684\u6e2c\u91cf\u5c0d\u672a\u4f86\u7684\u7814\u7a76\u63d0\u51fa\u4e86\u6311\u6230\uff0c\u4ee5\u8abf\u548c\u958b\u653e\u9818\u57df QA \u548c\u806f\u5408\u6aa2\u7d22-QA \u4efb\u52d9\u4e2d\u7684\u8a18\u61b6\u548c\u6982\u5316\u3002", "author": "Peter Carragher et.al.", "authors": "Peter Carragher, Abhinand Jha, R Raghav, Kathleen M. Carley", "id": "2502.13836v1", "paper_url": "http://arxiv.org/abs/2502.13836v1", "repo": "null"}}