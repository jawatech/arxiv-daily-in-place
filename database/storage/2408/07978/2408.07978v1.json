{"2408.07978": {"publish_time": "2024-08-15", "title": "Coupling without Communication and Drafter-Invariant Speculative Decoding", "paper_summary": "Suppose Alice has a distribution $P$ and Bob has a distribution $Q$. Alice\nwants to generate a sample $a\\sim P$ and Bob a sample $b \\sim Q$ such that $a =\nb$ with has as high of probability as possible. It is well-known that, by\nsampling from an optimal coupling between the distributions, Alice and Bob can\nachieve $Pr[a = b] = 1 - D_{TV}(P,Q)$, where $D_{TV}(P,Q)$ is the total\nvariation distance. What if Alice and Bob must solve this same problem without\ncommunicating at all? Perhaps surprisingly, with access to public randomness,\nthey can still achieve $Pr[a = b] \\geq \\frac{1 - D_{TV}(P,Q)}{1 + D_{TV}(P,Q)}\n\\geq 1-2D_{TV}(P,Q)$. In fact, this bound can be obtained using a simple\nprotocol based on the Weighted MinHash algorithm. In this work, we explore the\ncommunication-free coupling in greater depth. First, we show that an equally\nsimple protocol based on Gumbel sampling matches the worst-case guarantees of\nthe Weighted MinHash approach, but tends to perform better in practice.\nConversely, we prove that both approaches are actually sharp: no\ncommunication-free protocol can achieve $Pr[a=b]>\\frac{1 - D_{TV}(P,Q)}{1 +\nD_{TV}(P,Q)}$ in the worst-case. Finally, we prove that, for distributions over\n$n$ items, there exists a scheme that uses just $O(\\log(n/\\epsilon))$ bits of\ncommunication to achieve $Pr[a = b] = 1 - D_{TV}(P,Q) - \\epsilon$, i.e. to\nessentially match optimal coupling. Beyond our theoretical results, we\ndemonstrate an application of communication-free coupling to speculative\ndecoding, a recent method for accelerating autoregressive large language models\n[Leviathan, Kalman, Matias, ICML 2023]. We show that communication-free\nprotocols yield a variant of speculative decoding that we call\nDrafter-Invariant Speculative Decoding, which has the desirable property that\nthe output of the method is fixed given a fixed random seed, regardless of what\ndrafter is used for speculation.", "paper_summary_zh": "<paragraph>\u5047\u8bbe Alice \u6709\u4e00\u4e2a\u5206\u5e03 $P$\uff0cBob \u6709\u4e00\u4e2a\u5206\u5e03 $Q$\u3002Alice \u5e0c\u671b\u751f\u6210\u4e00\u4e2a\u6837\u672c $a\\sim P$\uff0cBob \u751f\u6210\u4e00\u4e2a\u6837\u672c $b \\sim Q$\uff0c\u4f7f\u5f97 $a = b$ \u7684\u6982\u7387\u5c3d\u53ef\u80fd\u9ad8\u3002\u4f17\u6240\u5468\u77e5\uff0c\u901a\u8fc7\u4ece\u5206\u5e03\u4e4b\u95f4\u7684\u6700\u4f18\u8026\u5408\u4e2d\u8fdb\u884c\u91c7\u6837\uff0cAlice \u548c Bob \u53ef\u4ee5\u5b9e\u73b0 $Pr[a = b] = 1 - D_{TV}(P,Q)$\uff0c\u5176\u4e2d $D_{TV}(P,Q)$ \u662f\u603b\u53d8\u5f02\u8ddd\u79bb\u3002\u5982\u679c Alice \u548c Bob \u5fc5\u987b\u5728\u5b8c\u5168\u4e0d\u901a\u4fe1\u7684\u60c5\u51b5\u4e0b\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u5462\uff1f\u4e5f\u8bb8\u4ee4\u4eba\u60ca\u8bb6\u7684\u662f\uff0c\u5728\u53ef\u4ee5\u8bbf\u95ee\u516c\u5171\u968f\u673a\u6027\u7684\u60c5\u51b5\u4e0b\uff0c\u4ed6\u4eec\u4ecd\u7136\u53ef\u4ee5\u5b9e\u73b0 $Pr[a = b] \\geq \\frac{1 - D_{TV}(P,Q)}{1 + D_{TV}(P,Q)} \\geq 1-2D_{TV}(P,Q)$\u3002\u4e8b\u5b9e\u4e0a\uff0c\u53ef\u4ee5\u4f7f\u7528\u57fa\u4e8e\u52a0\u6743\u6700\u5c0f\u54c8\u5e0c\u7b97\u6cd5\u7684\u7b80\u5355\u534f\u8bae\u83b7\u5f97\u6b64\u754c\u9650\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u66f4\u6df1\u5165\u5730\u63a2\u8ba8\u4e86\u65e0\u901a\u4fe1\u8026\u5408\u3002\u9996\u5148\uff0c\u6211\u4eec\u8868\u660e\uff0c\u57fa\u4e8e Gumbel \u91c7\u6837\u7684\u540c\u6837\u7b80\u5355\u7684\u534f\u8bae\u4e0e\u52a0\u6743\u6700\u5c0f\u54c8\u5e0c\u65b9\u6cd5\u7684\u6700\u574f\u60c5\u51b5\u4fdd\u8bc1\u76f8\u5339\u914d\uff0c\u4f46\u5728\u5b9e\u8df5\u4e2d\u5f80\u5f80\u8868\u73b0\u5f97\u66f4\u597d\u3002\u76f8\u53cd\uff0c\u6211\u4eec\u8bc1\u660e\u8fd9\u4e24\u79cd\u65b9\u6cd5\u5b9e\u9645\u4e0a\u90fd\u5f88\u4e25\u683c\uff1a\u5728\u6700\u574f\u7684\u60c5\u51b5\u4e0b\uff0c\u6ca1\u6709\u4efb\u4f55\u65e0\u901a\u4fe1\u534f\u8bae\u53ef\u4ee5\u5b9e\u73b0 $Pr[a=b]>\\frac{1 - D_{TV}(P,Q)}{1 + D_{TV}(P,Q)}$\u3002\u6700\u540e\uff0c\u6211\u4eec\u8bc1\u660e\u5bf9\u4e8e $n$ \u4e2a\u9879\u76ee\u7684\u5206\u5e03\uff0c\u5b58\u5728\u4e00\u4e2a\u65b9\u6848\uff0c\u53ea\u9700\u4f7f\u7528 $O(\\log(n/\\epsilon))$ \u4f4d\u901a\u4fe1\u5373\u53ef\u5b9e\u73b0 $Pr[a = b] = 1 - D_{TV}(P,Q) - \\epsilon$\uff0c\u5373\u57fa\u672c\u4e0a\u5339\u914d\u6700\u4f18\u8026\u5408\u3002\u9664\u4e86\u6211\u4eec\u7684\u7406\u8bba\u7ed3\u679c\u4e4b\u5916\uff0c\u6211\u4eec\u8fd8\u5c55\u793a\u4e86\u65e0\u901a\u4fe1\u8026\u5408\u5728\u63a8\u6d4b\u89e3\u7801\u4e2d\u7684\u5e94\u7528\uff0c\u8fd9\u662f\u4e00\u79cd\u52a0\u901f\u81ea\u56de\u5f52\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6700\u65b0\u65b9\u6cd5 [Leviathan, Kalman, Matias, ICML 2023]\u3002\u6211\u4eec\u8868\u660e\uff0c\u65e0\u901a\u4fe1\u534f\u8bae\u4ea7\u751f\u4e86\u4e00\u79cd\u63a8\u6d4b\u89e3\u7801\u53d8\u4f53\uff0c\u6211\u4eec\u79f0\u4e4b\u4e3a\u8d77\u8349\u8005\u4e0d\u53d8\u63a8\u6d4b\u89e3\u7801\uff0c\u5b83\u5177\u6709\u7406\u60f3\u7684\u7279\u6027\uff0c\u5373\u8be5\u65b9\u6cd5\u7684\u8f93\u51fa\u5728\u7ed9\u5b9a\u56fa\u5b9a\u968f\u673a\u79cd\u5b50\u65f6\u662f\u56fa\u5b9a\u7684\uff0c\u65e0\u8bba\u4f7f\u7528\u4ec0\u4e48\u8d77\u8349\u8005\u8fdb\u884c\u63a8\u6d4b\u3002</paragraph>", "author": "Majid Daliri et.al.", "authors": "Majid Daliri, Christopher Musco, Ananda Theertha Suresh", "id": "2408.07978v1", "paper_url": "http://arxiv.org/abs/2408.07978v1", "repo": "null"}}