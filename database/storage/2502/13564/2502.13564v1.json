{"2502.13564": {"publish_time": "2025-02-19", "title": "PRIV-QA: Privacy-Preserving Question Answering for Cloud Large Language Models", "paper_summary": "The rapid development of large language models (LLMs) is redefining the\nlandscape of human-computer interaction, and their integration into various\nuser-service applications is becoming increasingly prevalent. However,\ntransmitting user data to cloud-based LLMs presents significant risks of data\nbreaches and unauthorized access to personal identification information. In\nthis paper, we propose a privacy preservation pipeline for protecting privacy\nand sensitive information during interactions between users and LLMs in\npractical LLM usage scenarios. We construct SensitiveQA, the first privacy\nopen-ended question-answering dataset. It comprises 57k interactions in Chinese\nand English, encompassing a diverse range of user-sensitive information within\nthe conversations. Our proposed solution employs a multi-stage strategy aimed\nat preemptively securing user information while simultaneously preserving the\nresponse quality of cloud-based LLMs. Experimental validation underscores our\nmethod's efficacy in balancing privacy protection with maintaining robust\ninteraction quality. The code and dataset are available at\nhttps://github.com/ligw1998/PRIV-QA.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5feb\u901f\u767c\u5c55\u91cd\u65b0\u5b9a\u7fa9\u4e86\u4eba\u6a5f\u4e92\u52d5\u7684\u683c\u5c40\uff0c\u5b83\u5011\u8207\u5404\u7a2e\u4f7f\u7528\u8005\u670d\u52d9\u61c9\u7528\u7a0b\u5f0f\u6574\u5408\u7684\u73fe\u8c61\u4e5f\u8d8a\u4f86\u8d8a\u666e\u904d\u3002\u7136\u800c\uff0c\u5c07\u4f7f\u7528\u8005\u8cc7\u6599\u50b3\u8f38\u5230\u96f2\u7aef LLM \u6703\u9020\u6210\u8cc7\u6599\u5916\u6d29\u548c\u500b\u4eba\u8b58\u5225\u8cc7\u8a0a\u906d\u5230\u672a\u7d93\u6388\u6b0a\u5b58\u53d6\u7684\u91cd\u5927\u98a8\u96aa\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u96b1\u79c1\u4fdd\u8b77\u7ba1\u7dda\uff0c\u7528\u65bc\u5728\u5be6\u969b LLM \u4f7f\u7528\u60c5\u5883\u4e2d\u4fdd\u8b77\u4f7f\u7528\u8005\u548c LLM \u4e92\u52d5\u6642\u7684\u96b1\u79c1\u548c\u654f\u611f\u8cc7\u8a0a\u3002\u6211\u5011\u5efa\u69cb\u4e86 SensitiveQA\uff0c\u9019\u662f\u7b2c\u4e00\u500b\u96b1\u79c1\u958b\u653e\u5f0f\u554f\u7b54\u8cc7\u6599\u96c6\u3002\u5b83\u5305\u542b 57k \u500b\u4e2d\u6587\u548c\u82f1\u6587\u4e92\u52d5\uff0c\u6db5\u84cb\u4e86\u5c0d\u8a71\u4e2d\u5404\u7a2e\u4f7f\u7528\u8005\u7684\u654f\u611f\u8cc7\u8a0a\u3002\u6211\u5011\u63d0\u51fa\u7684\u89e3\u6c7a\u65b9\u6848\u63a1\u7528\u591a\u968e\u6bb5\u7b56\u7565\uff0c\u65e8\u5728\u9810\u5148\u4fdd\u8b77\u4f7f\u7528\u8005\u8cc7\u8a0a\uff0c\u540c\u6642\u4fdd\u7559\u96f2\u7aef LLM \u7684\u56de\u61c9\u54c1\u8cea\u3002\u5be6\u9a57\u9a57\u8b49\u5f37\u8abf\u4e86\u6211\u5011\u7684\u65b9\u6cd5\u5728\u5e73\u8861\u96b1\u79c1\u4fdd\u8b77\u548c\u7dad\u6301\u7a69\u5065\u4e92\u52d5\u54c1\u8cea\u65b9\u9762\u7684\u6548\u80fd\u3002\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\u96c6\u53ef\u5728 https://github.com/ligw1998/PRIV-QA \u53d6\u5f97\u3002", "author": "Guangwei Li et.al.", "authors": "Guangwei Li, Yuansen Zhang, Yinggui Wang, Shoumeng Yan, Lei Wang, Tao Wei", "id": "2502.13564v1", "paper_url": "http://arxiv.org/abs/2502.13564v1", "repo": "null"}}