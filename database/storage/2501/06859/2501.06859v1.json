{"2501.06859": {"publish_time": "2025-01-12", "title": "A Comprehensive Evaluation of Large Language Models on Mental Illnesses in Arabic Context", "paper_summary": "Mental health disorders pose a growing public health concern in the Arab\nworld, emphasizing the need for accessible diagnostic and intervention tools.\nLarge language models (LLMs) offer a promising approach, but their application\nin Arabic contexts faces challenges including limited labeled datasets,\nlinguistic complexity, and translation biases. This study comprehensively\nevaluates 8 LLMs, including general multi-lingual models, as well as bi-lingual\nones, on diverse mental health datasets (such as AraDepSu, Dreaddit, MedMCQA),\ninvestigating the impact of prompt design, language configuration (native\nArabic vs. translated English, and vice versa), and few-shot prompting on\ndiagnostic performance. We find that prompt engineering significantly\ninfluences LLM scores mainly due to reduced instruction following, with our\nstructured prompt outperforming a less structured variant on multi-class\ndatasets, with an average difference of 14.5\\%. While language influence on\nperformance was modest, model selection proved crucial: Phi-3.5 MoE excelled in\nbalanced accuracy, particularly for binary classification, while Mistral NeMo\nshowed superior performance in mean absolute error for severity prediction\ntasks. Few-shot prompting consistently improved performance, with particularly\nsubstantial gains observed for GPT-4o Mini on multi-class classification,\nboosting accuracy by an average factor of 1.58. These findings underscore the\nimportance of prompt optimization, multilingual analysis, and few-shot learning\nfor developing culturally sensitive and effective LLM-based mental health tools\nfor Arabic-speaking populations.", "paper_summary_zh": "<paragraph>\u5fc3\u7406\u5065\u5eb7\u969c\u7919\u5728\u963f\u62c9\u4f2f\u4e16\u754c\u4e2d\u69cb\u6210\u65e5\u76ca\u56b4\u91cd\u7684\u516c\u5171\u885b\u751f\u554f\u984c\uff0c\u5f37\u8abf\u4e86\u5c0d\u53ef\u53ca\u7684\u8a3a\u65b7\u548c\u5e72\u9810\u5de5\u5177\u7684\u9700\u6c42\u3002\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u63d0\u4f9b\u4e86\u4e00\u7a2e\u6709\u524d\u9014\u7684\u65b9\u6cd5\uff0c\u4f46\u5b83\u5011\u5728\u963f\u62c9\u4f2f\u8a9e\u74b0\u5883\u4e2d\u7684\u61c9\u7528\u9762\u81e8\u8457\u6311\u6230\uff0c\u5305\u62ec\u6a19\u8a18\u8cc7\u6599\u96c6\u6709\u9650\u3001\u8a9e\u8a00\u8907\u96dc\u6027\u548c\u7ffb\u8b6f\u504f\u5dee\u3002\u672c\u7814\u7a76\u5168\u9762\u8a55\u4f30\u4e86 8 \u500b LLM\uff0c\u5305\u62ec\u4e00\u822c\u591a\u8a9e\u8a00\u6a21\u578b\u548c\u96d9\u8a9e\u6a21\u578b\uff0c\u5728\u4e0d\u540c\u7684\u5fc3\u7406\u5065\u5eb7\u8cc7\u6599\u96c6\uff08\u4f8b\u5982 AraDepSu\u3001Dreaddit\u3001MedMCQA\uff09\u4e0a\uff0c\u63a2\u8a0e\u63d0\u793a\u8a2d\u8a08\u3001\u8a9e\u8a00\u914d\u7f6e\uff08\u963f\u62c9\u4f2f\u8a9e\u539f\u6587\u8207\u7ffb\u8b6f\u5f8c\u7684\u82f1\u8a9e\uff0c\u53cd\u4e4b\u4ea6\u7136\uff09\u548c\u5c11\u6b21\u63d0\u793a\u5c0d\u8a3a\u65b7\u8868\u73fe\u7684\u5f71\u97ff\u3002\u6211\u5011\u767c\u73fe\u63d0\u793a\u5de5\u7a0b\u986f\u8457\u5f71\u97ff LLM \u5206\u6578\uff0c\u4e3b\u8981\u662f\u7531\u65bc\u6e1b\u5c11\u4e86\u8aaa\u660e\u9075\u5faa\uff0c\u6211\u5011\u7684\u7d50\u69cb\u5316\u63d0\u793a\u5728\u591a\u985e\u8cc7\u6599\u96c6\u4e0a\u512a\u65bc\u7d50\u69cb\u8f03\u4e0d\u56b4\u8b39\u7684\u8b8a\u9ad4\uff0c\u5e73\u5747\u5dee\u7570\u70ba 14.5%\u3002\u96d6\u7136\u8a9e\u8a00\u5c0d\u8868\u73fe\u7684\u5f71\u97ff\u4e0d\u5927\uff0c\u4f46\u6a21\u578b\u9078\u64c7\u88ab\u8b49\u660e\u81f3\u95dc\u91cd\u8981\uff1aPhi-3.5 MoE \u5728\u5e73\u8861\u6e96\u78ba\u5ea6\u65b9\u9762\u8868\u73fe\u51fa\u8272\uff0c\u7279\u5225\u662f\u5728\u4e8c\u5143\u5206\u985e\u65b9\u9762\uff0c\u800c Mistral NeMo \u5728\u56b4\u91cd\u6027\u9810\u6e2c\u4efb\u52d9\u7684\u5e73\u5747\u7d55\u5c0d\u8aa4\u5dee\u65b9\u9762\u8868\u73fe\u51fa\u512a\u7570\u7684\u8868\u73fe\u3002\u5c11\u6b21\u63d0\u793a\u59cb\u7d42\u6539\u5584\u8868\u73fe\uff0c\u7279\u5225\u662f\u5728 GPT-4o Mini \u4e0a\u89c0\u5bdf\u5230\u591a\u985e\u5206\u985e\u7684\u986f\u8457\u589e\u76ca\uff0c\u5c07\u6e96\u78ba\u5ea6\u63d0\u9ad8\u4e86\u5e73\u5747 1.58 \u500d\u3002\u9019\u4e9b\u767c\u73fe\u5f37\u8abf\u4e86\u63d0\u793a\u6700\u4f73\u5316\u3001\u591a\u8a9e\u8a00\u5206\u6790\u548c\u5c11\u6b21\u5b78\u7fd2\u5c0d\u65bc\u958b\u767c\u9069\u5408\u6587\u5316\u4e14\u6709\u6548\u7684\u57fa\u65bc LLM \u7684\u5fc3\u7406\u5065\u5eb7\u5de5\u5177\u4ee5\u670d\u52d9\u963f\u62c9\u4f2f\u8a9e\u4eba\u53e3\u7684\u91cd\u8981\u6027\u3002</paragraph>", "author": "Noureldin Zahran et.al.", "authors": "Noureldin Zahran, Aya E. Fouda, Radwa J. Hanafy, Mohammed E. Fouda", "id": "2501.06859v1", "paper_url": "http://arxiv.org/abs/2501.06859v1", "repo": "null"}}