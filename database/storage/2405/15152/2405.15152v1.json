{"2405.15152": {"publish_time": "2024-05-24", "title": "Machine Unlearning in Large Language Models", "paper_summary": "Machine unlearning, a novel area within artificial intelligence, focuses on\naddressing the challenge of selectively forgetting or reducing undesirable\nknowledge or behaviors in machine learning models, particularly in the context\nof large language models (LLMs). This paper introduces a methodology to align\nLLMs, such as Open Pre-trained Transformer Language Models, with ethical,\nprivacy, and safety standards by leveraging the gradient ascent algorithm for\nknowledge unlearning. Our approach aims to selectively erase or modify learned\ninformation in LLMs, targeting harmful responses and copyrighted content. This\npaper presents a dual-pronged approach to enhance the ethical and safe behavior\nof large language models (LLMs) by addressing the issues of harmful responses\nand copyrighted content. To mitigate harmful responses, we applied gradient\nascent on the PKU dataset, achieving a 75\\% reduction in harmful responses for\nOpen Pre-trained Transformer Language Models (OPT1.3b and OPT2.7b)\n\\citet{zhang2022opt} while retaining previous knowledge using the TruthfulQA\ndataset \\citet{DBLP:journals/corr/abs-2109-07958}. For handling copyrighted\ncontent, we constructed a custom dataset based on the Lord of the Rings corpus\nand aligned LLMs (OPT1.3b and OPT2.7b) \\citet{zhang2022opt} through LoRA:\nLow-Rank Adaptation of Large Language Models\n\\citet{DBLP:journals/corr/abs-2106-09685} finetuning. Subsequently, we employed\ngradient ascent to unlearn the Lord of the Rings content, resulting in a\nremarkable reduction in the presence of copyrighted material. To maintain a\ndiverse knowledge base, we utilized the Book Corpus dataset. Additionally, we\npropose a new evaluation technique for assessing the effectiveness of harmful\nunlearning.", "paper_summary_zh": "\u6a5f\u5668\u53bb\u5b78\u7fd2\uff0c\u4eba\u5de5\u667a\u6167\u7684\u4e00\u500b\u65b0\u9818\u57df\uff0c\u5c08\u6ce8\u65bc\u8655\u7406\u9078\u64c7\u6027\u907a\u5fd8\u6216\u6e1b\u5c11\u6a5f\u5668\u5b78\u7fd2\u6a21\u578b\u4e2d\u4e0d\u826f\u7684\u77e5\u8b58\u6216\u884c\u70ba\u7684\u6311\u6230\uff0c\u5c24\u5176\u662f\u5728\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u60c5\u6cc1\u4e0b\u3002\u672c\u6587\u4ecb\u7d39\u4e86\u4e00\u7a2e\u65b9\u6cd5\uff0c\u53ef\u4ee5\u901a\u904e\u5229\u7528\u68af\u5ea6\u4e0a\u5347\u6f14\u7b97\u6cd5\u9032\u884c\u77e5\u8b58\u53bb\u5b78\u7fd2\uff0c\u5c07 LLM\uff08\u4f8b\u5982 Open Pre-trained Transformer Language Models\uff09\u8207\u9053\u5fb7\u3001\u96b1\u79c1\u548c\u5b89\u5168\u6a19\u6e96\u4fdd\u6301\u4e00\u81f4\u3002\u6211\u5011\u7684\u65b9\u6cd5\u65e8\u5728\u9078\u64c7\u6027\u5730\u522a\u9664\u6216\u4fee\u6539 LLM \u4e2d\u5b78\u7fd2\u5230\u7684\u8cc7\u8a0a\uff0c\u9396\u5b9a\u6709\u5bb3\u7684\u56de\u61c9\u548c\u53d7\u7248\u6b0a\u4fdd\u8b77\u7684\u5167\u5bb9\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u7a2e\u96d9\u7ba1\u9f4a\u4e0b\u7684\u65b9\u6cd5\uff0c\u901a\u904e\u89e3\u6c7a\u6709\u5bb3\u56de\u61c9\u548c\u53d7\u7248\u6b0a\u4fdd\u8b77\u7684\u5167\u5bb9\u554f\u984c\uff0c\u4f86\u589e\u5f37\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u9053\u5fb7\u548c\u5b89\u5168\u884c\u70ba\u3002\u70ba\u4e86\u6e1b\u8f15\u6709\u5bb3\u7684\u56de\u61c9\uff0c\u6211\u5011\u5728 PKU \u8cc7\u6599\u96c6\u4e0a\u61c9\u7528\u68af\u5ea6\u4e0a\u5347\uff0c\u4f7f Open Pre-trained Transformer Language Models (OPT1.3b \u548c OPT2.7b) \u7684\u6709\u5bb3\u56de\u61c9\u6e1b\u5c11\u4e86 75%\uff0c\u540c\u6642\u4f7f\u7528 TruthfulQA \u8cc7\u6599\u96c6\u4fdd\u7559\u4e86\u5148\u524d\u7684\u77e5\u8b58\\citet{zhang2022opt}\u3002\u5c0d\u65bc\u8655\u7406\u53d7\u7248\u6b0a\u4fdd\u8b77\u7684\u5167\u5bb9\uff0c\u6211\u5011\u6839\u64da\u9b54\u6212\u8a9e\u6599\u5eab\u69cb\u5efa\u4e86\u4e00\u500b\u81ea\u8a02\u8cc7\u6599\u96c6\uff0c\u4e26\u900f\u904e LoRA\uff1a\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u4f4e\u79e9\u9069\u61c9\u8abf\u6574 LLM\uff08OPT1.3b \u548c OPT2.7b\uff09\\citet{DBLP:journals/corr/abs-2106-09685}\u3002\u96a8\u5f8c\uff0c\u6211\u5011\u63a1\u7528\u68af\u5ea6\u4e0a\u5347\u4f86\u53d6\u6d88\u5b78\u7fd2\u9b54\u6212\u7684\u5167\u5bb9\uff0c\u5f9e\u800c\u986f\u8457\u6e1b\u5c11\u4e86\u53d7\u7248\u6b0a\u4fdd\u8b77\u7684\u6750\u6599\u7684\u5b58\u5728\u3002\u70ba\u4e86\u7dad\u8b77\u591a\u5143\u5316\u7684\u77e5\u8b58\u5eab\uff0c\u6211\u5011\u5229\u7528\u4e86 Book Corpus \u8cc7\u6599\u96c6\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7684\u8a55\u4f30\u6280\u8853\uff0c\u7528\u65bc\u8a55\u4f30\u6709\u5bb3\u53bb\u5b78\u7fd2\u7684\u6709\u6548\u6027\u3002", "author": "Saaketh Koundinya Gundavarapu et.al.", "authors": "Saaketh Koundinya Gundavarapu, Shreya Agarwal, Arushi Arora, Chandana Thimmalapura Jagadeeshaiah", "id": "2405.15152v1", "paper_url": "http://arxiv.org/abs/2405.15152v1", "repo": "https://github.com/shreya1313/llm-unlearning"}}