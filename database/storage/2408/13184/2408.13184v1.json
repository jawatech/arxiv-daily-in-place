{"2408.13184": {"publish_time": "2024-08-23", "title": "Can LLM be a Good Path Planner based on Prompt Engineering? Mitigating the Hallucination for Path Planning", "paper_summary": "Spatial reasoning in Large Language Models (LLMs) is the foundation for\nembodied intelligence. However, even in simple maze environments, LLMs still\nencounter challenges in long-term path-planning, primarily influenced by their\nspatial hallucination and context inconsistency hallucination by long-term\nreasoning. To address this challenge, this study proposes an innovative model,\nSpatial-to-Relational Transformation and Curriculum Q-Learning (S2RCQL). To\naddress the spatial hallucination of LLMs, we propose the Spatial-to-Relational\napproach, which transforms spatial prompts into entity relations and paths\nrepresenting entity relation chains. This approach fully taps the potential of\nLLMs in terms of sequential thinking. As a result, we design a path-planning\nalgorithm based on Q-learning to mitigate the context inconsistency\nhallucination, which enhances the reasoning ability of LLMs. Using the Q-value\nof state-action as auxiliary information for prompts, we correct the\nhallucinations of LLMs, thereby guiding LLMs to learn the optimal path.\nFinally, we propose a reverse curriculum learning technique based on LLMs to\nfurther mitigate the context inconsistency hallucination. LLMs can rapidly\naccumulate successful experiences by reducing task difficulty and leveraging\nthem to tackle more complex tasks. We performed comprehensive experiments based\non Baidu's self-developed LLM: ERNIE-Bot 4.0. The results showed that our\nS2RCQL achieved a 23%--40% improvement in both success and optimality rates\ncompared with advanced prompt engineering.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4e2d\u7684\u7a7a\u9593\u63a8\u7406\u662f\u5177\u8eab\u667a\u80fd\u7684\u57fa\u790e\u3002\u7136\u800c\uff0c\u5373\u4f7f\u5728\u7c21\u55ae\u7684\u8ff7\u5bae\u74b0\u5883\u4e2d\uff0cLLM \u4ecd\u7136\u5728\u9577\u671f\u8def\u5f91\u898f\u5283\u4e2d\u9047\u5230\u6311\u6230\uff0c\u9019\u4e3b\u8981\u662f\u53d7\u5176\u9577\u671f\u63a8\u7406\u7522\u751f\u7684\u7a7a\u9593\u5e7b\u89ba\u548c\u8a9e\u5883\u4e0d\u4e00\u81f4\u5e7b\u89ba\u5f71\u97ff\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e00\u6311\u6230\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u7a2e\u5275\u65b0\u7684\u6a21\u578b\uff0c\u5373\u7a7a\u9593\u5230\u95dc\u4fc2\u8f49\u63db\u548c\u8ab2\u7a0b Q \u5b78\u7fd2 (S2RCQL)\u3002\u70ba\u4e86\u89e3\u6c7a LLM \u7684\u7a7a\u9593\u5e7b\u89ba\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u7a7a\u9593\u5230\u95dc\u4fc2\u65b9\u6cd5\uff0c\u5b83\u5c07\u7a7a\u9593\u63d0\u793a\u8f49\u63db\u70ba\u8868\u793a\u5be6\u9ad4\u95dc\u4fc2\u93c8\u7684\u5be6\u9ad4\u95dc\u4fc2\u548c\u8def\u5f91\u3002\u9019\u7a2e\u65b9\u6cd5\u5145\u5206\u767c\u63ee\u4e86 LLM \u5728\u9806\u5e8f\u601d\u8003\u65b9\u9762\u7684\u6f5b\u529b\u3002\u56e0\u6b64\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u57fa\u65bc Q \u5b78\u7fd2\u7684\u8def\u5f91\u898f\u5283\u6f14\u7b97\u6cd5\uff0c\u4ee5\u6e1b\u8f15\u8a9e\u5883\u4e0d\u4e00\u81f4\u5e7b\u89ba\uff0c\u5f9e\u800c\u589e\u5f37 LLM \u7684\u63a8\u7406\u80fd\u529b\u3002\u5229\u7528\u72c0\u614b\u52d5\u4f5c\u7684 Q \u503c\u4f5c\u70ba\u63d0\u793a\u7684\u8f14\u52a9\u8cc7\u8a0a\uff0c\u6211\u5011\u7cfe\u6b63\u4e86 LLM \u7684\u5e7b\u89ba\uff0c\u5f9e\u800c\u5f15\u5c0e LLM \u5b78\u7fd2\u6700\u4f73\u8def\u5f91\u3002\u6700\u5f8c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u57fa\u65bc LLM \u7684\u53cd\u5411\u8ab2\u7a0b\u5b78\u7fd2\u6280\u8853\uff0c\u4ee5\u9032\u4e00\u6b65\u6e1b\u8f15\u8a9e\u5883\u4e0d\u4e00\u81f4\u5e7b\u89ba\u3002LLM \u53ef\u4ee5\u901a\u904e\u964d\u4f4e\u4efb\u52d9\u96e3\u5ea6\u4e26\u5229\u7528\u5b83\u5011\u4f86\u61c9\u5c0d\u66f4\u8907\u96dc\u7684\u4efb\u52d9\uff0c\u5f9e\u800c\u5feb\u901f\u7d2f\u7a4d\u6210\u529f\u7684\u7d93\u9a57\u3002\u6211\u5011\u57fa\u65bc\u767e\u5ea6\u81ea\u7814\u7684 LLM\uff1aERNIE-Bot 4.0 \u9032\u884c\u4e86\u5168\u9762\u7684\u5be6\u9a57\u3002\u7d50\u679c\u8868\u660e\uff0c\u8207\u5148\u9032\u7684\u63d0\u793a\u5de5\u7a0b\u76f8\u6bd4\uff0c\u6211\u5011\u7684 S2RCQL \u5728\u6210\u529f\u7387\u548c\u6700\u512a\u7387\u65b9\u9762\u90fd\u53d6\u5f97\u4e86 23%--40% \u7684\u63d0\u5347\u3002", "author": "Hourui Deng et.al.", "authors": "Hourui Deng, Hongjie Zhang, Jie Ou, Chaosheng Feng", "id": "2408.13184v1", "paper_url": "http://arxiv.org/abs/2408.13184v1", "repo": "null"}}