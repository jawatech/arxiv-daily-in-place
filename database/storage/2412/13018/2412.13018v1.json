{"2412.13018": {"publish_time": "2024-12-17", "title": "OmniEval: An Omnidirectional and Automatic RAG Evaluation Benchmark in Financial Domain", "paper_summary": "As a typical and practical application of Large Language Models (LLMs),\nRetrieval-Augmented Generation (RAG) techniques have gained extensive\nattention, particularly in vertical domains where LLMs may lack domain-specific\nknowledge. In this paper, we introduce an omnidirectional and automatic RAG\nbenchmark, OmniEval, in the financial domain. Our benchmark is characterized by\nits multi-dimensional evaluation framework, including (1) a matrix-based RAG\nscenario evaluation system that categorizes queries into five task classes and\n16 financial topics, leading to a structured assessment of diverse query\nscenarios; (2) a multi-dimensional evaluation data generation approach, which\ncombines GPT-4-based automatic generation and human annotation, achieving an\n87.47\\% acceptance ratio in human evaluations on generated instances; (3) a\nmulti-stage evaluation system that evaluates both retrieval and generation\nperformance, result in a comprehensive evaluation on the RAG pipeline; and (4)\nrobust evaluation metrics derived from rule-based and LLM-based ones, enhancing\nthe reliability of assessments through manual annotations and supervised\nfine-tuning of an LLM evaluator. Our experiments demonstrate the\ncomprehensiveness of OmniEval, which includes extensive test datasets and\nhighlights the performance variations of RAG systems across diverse topics and\ntasks, revealing significant opportunities for RAG models to improve their\ncapabilities in vertical domains. We open source the code of our benchmark in\n\\href{https://github.com/RUC-NLPIR/OmniEval}{https://github.com/RUC-NLPIR/OmniEval}.", "paper_summary_zh": "<paragraph>\u4f5c\u70ba\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5178\u578b\u4e14\u5be6\u969b\u61c9\u7528\uff0c\u6aa2\u7d22\u589e\u5f37\u751f\u6210 (RAG) \u6280\u8853\u5df2\u7372\u5f97\u5ee3\u6cdb\u95dc\u6ce8\uff0c\u7279\u5225\u662f\u5728 LLM \u53ef\u80fd\u7f3a\u4e4f\u7279\u5b9a\u9818\u57df\u77e5\u8b58\u7684\u5782\u76f4\u9818\u57df\u4e2d\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5728\u91d1\u878d\u9818\u57df\u4e2d\u5f15\u5165\u4e86\u4e00\u500b\u5168\u65b9\u4f4d\u4e14\u81ea\u52d5\u5316\u7684 RAG \u57fa\u6e96 OmniEval\u3002\u6211\u5011\u7684\u57fa\u6e96\u7684\u7279\u9ede\u5728\u65bc\u5176\u591a\u7dad\u8a55\u4f30\u6846\u67b6\uff0c\u5305\u62ec\uff1a(1) \u4e00\u500b\u57fa\u65bc\u77e9\u9663\u7684 RAG \u5834\u666f\u8a55\u4f30\u7cfb\u7d71\uff0c\u5b83\u5c07\u67e5\u8a62\u5206\u985e\u70ba\u4e94\u500b\u4efb\u52d9\u985e\u5225\u548c 16 \u500b\u8ca1\u52d9\u4e3b\u984c\uff0c\u5f9e\u800c\u5c0d\u4e0d\u540c\u7684\u67e5\u8a62\u5834\u666f\u9032\u884c\u7d50\u69cb\u5316\u8a55\u4f30\uff1b(2) \u4e00\u7a2e\u591a\u7dad\u8a55\u4f30\u6578\u64da\u751f\u6210\u65b9\u6cd5\uff0c\u5b83\u7d50\u5408\u4e86\u57fa\u65bc GPT-4 \u7684\u81ea\u52d5\u751f\u6210\u548c\u4eba\u5de5\u6a19\u8a3b\uff0c\u5728\u751f\u6210\u5be6\u4f8b\u7684\u4eba\u5de5\u8a55\u4f30\u4e2d\u5be6\u73fe\u4e86 87.47% \u7684\u63a5\u53d7\u7387\uff1b(3) \u4e00\u500b\u591a\u968e\u6bb5\u8a55\u4f30\u7cfb\u7d71\uff0c\u5b83\u8a55\u4f30\u6aa2\u7d22\u548c\u751f\u6210\u6027\u80fd\uff0c\u5c0d RAG \u7ba1\u9053\u9032\u884c\u5168\u9762\u8a55\u4f30\uff1b\u4ee5\u53ca (4) \u5f9e\u57fa\u65bc\u898f\u5247\u548c\u57fa\u65bc LLM \u7684\u8a55\u4f30\u6307\u6a19\u4e2d\u884d\u751f\u7684\u7a69\u5065\u8a55\u4f30\u6307\u6a19\uff0c\u901a\u904e\u4eba\u5de5\u6a19\u8a3b\u548c LLM \u8a55\u4f30\u5668\u7684\u76e3\u7763\u5fae\u8abf\u4f86\u589e\u5f37\u8a55\u4f30\u7684\u53ef\u9760\u6027\u3002\u6211\u5011\u7684\u5be6\u9a57\u8b49\u660e\u4e86 OmniEval \u7684\u5168\u9762\u6027\uff0c\u5b83\u5305\u62ec\u5ee3\u6cdb\u7684\u6e2c\u8a66\u6578\u64da\u96c6\uff0c\u4e26\u7a81\u51fa\u4e86 RAG \u7cfb\u7d71\u5728\u4e0d\u540c\u4e3b\u984c\u548c\u4efb\u52d9\u4e2d\u7684\u6027\u80fd\u5dee\u7570\uff0c\u63ed\u793a\u4e86 RAG \u6a21\u578b\u5728\u5782\u76f4\u9818\u57df\u4e2d\u6539\u9032\u5176\u80fd\u529b\u7684\u91cd\u5927\u6a5f\u6703\u3002\u6211\u5011\u5728 \\href{https://github.com/RUC-NLPIR/OmniEval}{https://github.com/RUC-NLPIR/OmniEval} \u958b\u6e90\u4e86\u6211\u5011\u57fa\u6e96\u7684\u4ee3\u78bc\u3002</paragraph>", "author": "Shuting Wang et.al.", "authors": "Shuting Wang, Jiejun Tan, Zhicheng Dou, Ji-Rong Wen", "id": "2412.13018v1", "paper_url": "http://arxiv.org/abs/2412.13018v1", "repo": "https://github.com/ruc-nlpir/omnieval"}}