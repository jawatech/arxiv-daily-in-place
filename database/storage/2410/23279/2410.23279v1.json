{"2410.23279": {"publish_time": "2024-10-30", "title": "A Neural Transformer Framework for Simultaneous Tasks of Segmentation, Classification, and Caller Identification of Marmoset Vocalization", "paper_summary": "Marmoset, a highly vocalized primate, has become a popular animal model for\nstudying social-communicative behavior and its underlying mechanism. In the\nstudy of vocal communication, it is vital to know the caller identities, call\ncontents, and vocal exchanges. Previous work of a CNN has achieved a joint\nmodel for call segmentation, classification, and caller identification for\nmarmoset vocalizations. However, the CNN has limitations in modeling long-range\nacoustic patterns; the Transformer architecture that has been shown to\noutperform CNNs, utilizes the self-attention mechanism that efficiently\nsegregates information parallelly over long distances and captures the global\nstructure of marmoset vocalization. We propose using the Transformer to jointly\nsegment and classify the marmoset calls and identify the callers for each\nvocalization.", "paper_summary_zh": "\u72e8\u7334\u662f\u4e00\u79cd\u975e\u5e38\u5584\u4e8e\u53d1\u58f0\u7684\u7075\u957f\u7c7b\u52a8\u7269\uff0c\u5df2\u6210\u4e3a\u7814\u7a76\u793e\u4f1a\u4ea4\u6d41\u884c\u4e3a\u53ca\u5176\u6f5c\u5728\u673a\u5236\u7684\u6d41\u884c\u52a8\u7269\u6a21\u578b\u3002\u5728\u8bed\u97f3\u4ea4\u6d41\u7684\u7814\u7a76\u4e2d\uff0c\u4e86\u89e3\u547c\u53eb\u8005\u7684\u8eab\u4efd\u3001\u547c\u53eb\u5185\u5bb9\u548c\u8bed\u97f3\u4ea4\u6d41\u81f3\u5173\u91cd\u8981\u3002\u5148\u524d\u5173\u4e8e CNN \u7684\u7814\u7a76\u5df2\u9488\u5bf9\u72e8\u7334\u53d1\u58f0\u5b9e\u73b0\u4e86\u547c\u53eb\u5206\u5272\u3001\u5206\u7c7b\u548c\u547c\u53eb\u8005\u8bc6\u522b\u7684\u8054\u5408\u6a21\u578b\u3002\u7136\u800c\uff0cCNN \u5728\u5efa\u6a21\u8fdc\u7a0b\u58f0\u5b66\u6a21\u5f0f\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff1b\u5df2\u8bc1\u660e\u4f18\u4e8e CNN \u7684 Transformer \u67b6\u6784\u5229\u7528\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u8be5\u673a\u5236\u6709\u6548\u5730\u5c06\u4fe1\u606f\u5e76\u884c\u9694\u79bb\u5728\u8fdc\u8ddd\u79bb\u4e0a\uff0c\u5e76\u6355\u83b7\u72e8\u7334\u53d1\u58f0\u7684\u5168\u5c40\u7ed3\u6784\u3002\u6211\u4eec\u5efa\u8bae\u4f7f\u7528 Transformer \u6765\u8054\u5408\u5206\u5272\u548c\u5206\u7c7b\u72e8\u7334\u547c\u53eb\uff0c\u5e76\u8bc6\u522b\u6bcf\u4e2a\u53d1\u58f0\u7684\u547c\u53eb\u8005\u3002", "author": "Bin Wu et.al.", "authors": "Bin Wu, Sakriani Sakti, Shinnosuke Takamichi, Satoshi Nakamura", "id": "2410.23279v1", "paper_url": "http://arxiv.org/abs/2410.23279v1", "repo": "null"}}