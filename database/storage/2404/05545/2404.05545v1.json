{"2404.05545": {"publish_time": "2024-04-08", "title": "Evaluating Interventional Reasoning Capabilities of Large Language Models", "paper_summary": "Numerous decision-making tasks require estimating causal effects under\ninterventions on different parts of a system. As practitioners consider using\nlarge language models (LLMs) to automate decisions, studying their causal\nreasoning capabilities becomes crucial. A recent line of work evaluates LLMs\nability to retrieve commonsense causal facts, but these evaluations do not\nsufficiently assess how LLMs reason about interventions. Motivated by the role\nthat interventions play in causal inference, in this paper, we conduct\nempirical analyses to evaluate whether LLMs can accurately update their\nknowledge of a data-generating process in response to an intervention. We\ncreate benchmarks that span diverse causal graphs (e.g., confounding,\nmediation) and variable types, and enable a study of intervention-based\nreasoning. These benchmarks allow us to isolate the ability of LLMs to\naccurately predict changes resulting from their ability to memorize facts or\nfind other shortcuts. Our analysis on four LLMs highlights that while GPT- 4\nmodels show promising accuracy at predicting the intervention effects, they\nremain sensitive to distracting factors in the prompts.", "paper_summary_zh": "\u8a31\u591a\u6c7a\u7b56\u5236\u5b9a\u4efb\u52d9\u9700\u8981\u5728\u7cfb\u7d71\u4e0d\u540c\u90e8\u5206\u7684\u5e72\u9810\u4e0b\u4f30\u8a08\u56e0\u679c\u6548\u61c9\u3002\u7531\u65bc\u5be6\u52d9\u5de5\u4f5c\u8005\u8003\u616e\u4f7f\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4f86\u81ea\u52d5\u5316\u6c7a\u7b56\uff0c\u7814\u7a76\u5176\u56e0\u679c\u63a8\u7406\u80fd\u529b\u8b8a\u5f97\u81f3\u95dc\u91cd\u8981\u3002\u6700\u8fd1\u4e00\u9023\u4e32\u7684\u7814\u7a76\u8a55\u4f30\u4e86 LLM \u64f7\u53d6\u5e38\u8b58\u56e0\u679c\u4e8b\u5be6\u7684\u80fd\u529b\uff0c\u4f46\u9019\u4e9b\u8a55\u4f30\u4e26\u672a\u5145\u5206\u8a55\u4f30 LLM \u5982\u4f55\u5c0d\u5e72\u9810\u9032\u884c\u63a8\u7406\u3002\u5728\u56e0\u679c\u63a8\u8ad6\u4e2d\u5e72\u9810\u6240\u626e\u6f14\u7684\u89d2\u8272\u7684\u555f\u767c\u4e0b\uff0c\u6211\u5011\u5728\u672c\u6587\u4e2d\u9032\u884c\u5be6\u8b49\u5206\u6790\uff0c\u4ee5\u8a55\u4f30 LLM \u662f\u5426\u80fd\u6e96\u78ba\u66f4\u65b0\u5176\u5c0d\u8cc7\u6599\u7522\u751f\u7a0b\u5e8f\u7684\u4e86\u89e3\u4ee5\u56de\u61c9\u5e72\u9810\u3002\u6211\u5011\u5efa\u7acb\u4e86\u6db5\u84cb\u5404\u7a2e\u56e0\u679c\u5716\u5f62\uff08\u4f8b\u5982\u6df7\u6dc6\u3001\u4e2d\u4ecb\uff09\u548c\u8b8a\u6578\u985e\u578b\u7684\u57fa\u6e96\uff0c\u4e26\u80fd\u7814\u7a76\u57fa\u65bc\u5e72\u9810\u7684\u63a8\u7406\u3002\u9019\u4e9b\u57fa\u6e96\u8b93\u6211\u5011\u80fd\u5b64\u7acb LLM \u6e96\u78ba\u9810\u6e2c\u8b8a\u5316\u7684\u80fd\u529b\uff0c\u56e0\u70ba\u5b83\u5011\u80fd\u8a18\u61b6\u4e8b\u5be6\u6216\u627e\u5230\u5176\u4ed6\u6377\u5f91\u3002\u6211\u5011\u5c0d\u56db\u500b LLM \u7684\u5206\u6790\u5f37\u8abf\uff0c\u5118\u7ba1 GPT-4 \u6a21\u578b\u5728\u9810\u6e2c\u5e72\u9810\u6548\u679c\u65b9\u9762\u8868\u73fe\u51fa\u4ee4\u4eba\u6eff\u610f\u7684\u6e96\u78ba\u6027\uff0c\u4f46\u5b83\u5011\u4ecd\u7136\u5c0d\u63d0\u793a\u4e2d\u7684\u5e72\u64fe\u56e0\u7d20\u5f88\u654f\u611f\u3002", "author": "Tejas Kasetty et.al.", "authors": "Tejas Kasetty, Divyat Mahajan, Gintare Karolina Dziugaite, Alexandre Drouin, Dhanya Sridhar", "id": "2404.05545v1", "paper_url": "http://arxiv.org/abs/2404.05545v1", "repo": "null"}}