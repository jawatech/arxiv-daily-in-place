{"2501.01037": {"publish_time": "2025-01-02", "title": "MSC-Bench: Benchmarking and Analyzing Multi-Sensor Corruption for Driving Perception", "paper_summary": "Multi-sensor fusion models play a crucial role in autonomous driving\nperception, particularly in tasks like 3D object detection and HD map\nconstruction. These models provide essential and comprehensive static\nenvironmental information for autonomous driving systems. While camera-LiDAR\nfusion methods have shown promising results by integrating data from both\nmodalities, they often depend on complete sensor inputs. This reliance can lead\nto low robustness and potential failures when sensors are corrupted or missing,\nraising significant safety concerns. To tackle this challenge, we introduce the\nMulti-Sensor Corruption Benchmark (MSC-Bench), the first comprehensive\nbenchmark aimed at evaluating the robustness of multi-sensor autonomous driving\nperception models against various sensor corruptions. Our benchmark includes 16\ncombinations of corruption types that disrupt both camera and LiDAR inputs,\neither individually or concurrently. Extensive evaluations of six 3D object\ndetection models and four HD map construction models reveal substantial\nperformance degradation under adverse weather conditions and sensor failures,\nunderscoring critical safety issues. The benchmark toolkit and affiliated code\nand model checkpoints have been made publicly accessible.", "paper_summary_zh": "\u591a\u611f\u6e2c\u5668\u878d\u5408\u6a21\u578b\u5728\u81ea\u52d5\u99d5\u99db\u611f\u77e5\u4e2d\u626e\u6f14\u8457\u81f3\u95dc\u91cd\u8981\u7684\u89d2\u8272\uff0c\u7279\u5225\u662f\u5728 3D \u7269\u9ad4\u5075\u6e2c\u548c HD \u5730\u5716\u5efa\u69cb\u7b49\u4efb\u52d9\u4e2d\u3002\u9019\u4e9b\u6a21\u578b\u70ba\u81ea\u52d5\u99d5\u99db\u7cfb\u7d71\u63d0\u4f9b\u4e86\u5fc5\u8981\u4e14\u5168\u9762\u7684\u975c\u614b\u74b0\u5883\u8cc7\u8a0a\u3002\u96d6\u7136\u76f8\u6a5f-LiDAR \u878d\u5408\u65b9\u6cd5\u900f\u904e\u6574\u5408\u4f86\u81ea\u5169\u7a2e\u65b9\u5f0f\u7684\u8cc7\u6599\u800c\u5c55\u73fe\u51fa\u6709\u524d\u666f\u7684\u6210\u679c\uff0c\u4f46\u5b83\u5011\u901a\u5e38\u4f9d\u8cf4\u65bc\u5b8c\u6574\u7684\u611f\u6e2c\u5668\u8f38\u5165\u3002\u9019\u7a2e\u4f9d\u8cf4\u6027\u53ef\u80fd\u5c0e\u81f4\u611f\u6e2c\u5668\u640d\u58de\u6216\u907a\u5931\u6642\u7684\u4f4e\u5065\u58ef\u6027\u548c\u6f5b\u5728\u6545\u969c\uff0c\u5f15\u767c\u91cd\u5927\u7684\u5b89\u5168\u554f\u984c\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u500b\u6311\u6230\uff0c\u6211\u5011\u5f15\u5165\u4e86\u591a\u611f\u6e2c\u5668\u640d\u58de\u57fa\u6e96 (MSC-Bench)\uff0c\u9019\u662f\u7b2c\u4e00\u500b\u65e8\u5728\u8a55\u4f30\u591a\u611f\u6e2c\u5668\u81ea\u52d5\u99d5\u99db\u611f\u77e5\u6a21\u578b\u5c0d\u5404\u7a2e\u611f\u6e2c\u5668\u640d\u58de\u7684\u5065\u58ef\u6027\u7684\u7d9c\u5408\u57fa\u6e96\u3002\u6211\u5011\u7684\u57fa\u6e96\u5305\u62ec 16 \u7a2e\u640d\u58de\u985e\u578b\u7684\u7d44\u5408\uff0c\u9019\u4e9b\u640d\u58de\u6703\u7834\u58de\u76f8\u6a5f\u548c LiDAR \u8f38\u5165\uff0c\u7121\u8ad6\u662f\u55ae\u7368\u9084\u662f\u540c\u6642\u9032\u884c\u3002\u5c0d\u516d\u500b 3D \u7269\u9ad4\u5075\u6e2c\u6a21\u578b\u548c\u56db\u500b HD \u5730\u5716\u5efa\u69cb\u6a21\u578b\u7684\u5ee3\u6cdb\u8a55\u4f30\u63ed\u793a\u4e86\u5728\u60e1\u52a3\u5929\u6c23\u689d\u4ef6\u548c\u611f\u6e2c\u5668\u6545\u969c\u4e0b\u7684\u986f\u8457\u6548\u80fd\u4e0b\u964d\uff0c\u7a81\u986f\u4e86\u95dc\u9375\u7684\u5b89\u5168\u554f\u984c\u3002\u57fa\u6e96\u5de5\u5177\u7d44\u548c\u9644\u5c6c\u7a0b\u5f0f\u78bc\u8207\u6a21\u578b\u6aa2\u67e5\u9ede\u5df2\u516c\u958b\u63d0\u4f9b\u3002", "author": "Xiaoshuai Hao et.al.", "authors": "Xiaoshuai Hao, Guanqun Liu, Yuting Zhao, Yuheng Ji, Mengchuan Wei, Haimei Zhao, Lingdong Kong, Rong Yin, Yu Liu", "id": "2501.01037v1", "paper_url": "http://arxiv.org/abs/2501.01037v1", "repo": "null"}}