{"2501.04377": {"publish_time": "2025-01-08", "title": "On Computational Limits and Provably Efficient Criteria of Visual Autoregressive Models: A Fine-Grained Complexity Analysis", "paper_summary": "Recently, Visual Autoregressive ($\\mathsf{VAR}$) Models introduced a\ngroundbreaking advancement in the field of image generation, offering a\nscalable approach through a coarse-to-fine \"next-scale prediction\" paradigm.\nHowever, the state-of-the-art algorithm of $\\mathsf{VAR}$ models in [Tian,\nJiang, Yuan, Peng and Wang, NeurIPS 2024] takes $O(n^4)$ time, which is\ncomputationally inefficient. In this work, we analyze the computational limits\nand efficiency criteria of $\\mathsf{VAR}$ Models through a fine-grained\ncomplexity lens. Our key contribution is identifying the conditions under which\n$\\mathsf{VAR}$ computations can achieve sub-quadratic time complexity.\nSpecifically, we establish a critical threshold for the norm of input matrices\nused in $\\mathsf{VAR}$ attention mechanisms. Above this threshold, assuming the\nStrong Exponential Time Hypothesis ($\\mathsf{SETH}$) from fine-grained\ncomplexity theory, a sub-quartic time algorithm for $\\mathsf{VAR}$ models is\nimpossible. To substantiate our theoretical findings, we present efficient\nconstructions leveraging low-rank approximations that align with the derived\ncriteria. This work initiates the study of the computational efficiency of the\n$\\mathsf{VAR}$ model from a theoretical perspective. Our technique will shed\nlight on advancing scalable and efficient image generation in $\\mathsf{VAR}$\nframeworks.", "paper_summary_zh": "\u6700\u8fd1\uff0c\u89c6\u89c9\u81ea\u56de\u5f52 ($\\mathsf{VAR}$) \u6a21\u578b\u5728\u56fe\u50cf\u751f\u6210\u9886\u57df\u5f15\u5165\u4e86\u4e00\u9879\u5f00\u521b\u6027\u7684\u8fdb\u6b65\uff0c\u901a\u8fc7\u7c97\u5230\u7ec6\u7684\u201c\u4e0b\u4e00\u5c3a\u5ea6\u9884\u6d4b\u201d\u8303\u4f8b\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u3002\u7136\u800c\uff0c$\\mathsf{VAR}$ \u6a21\u578b\u5728 [Tian, Jiang, Yuan, Peng \u548c Wang, NeurIPS 2024] \u4e2d\u7684\u6700\u5148\u8fdb\u7b97\u6cd5\u9700\u8981 $O(n^4)$ \u65f6\u95f4\uff0c\u8fd9\u5728\u8ba1\u7b97\u4e0a\u662f\u4f4e\u6548\u7684\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u901a\u8fc7\u7ec6\u7c92\u5ea6\u7684\u590d\u6742\u6027\u900f\u955c\u5206\u6790\u4e86 $\\mathsf{VAR}$ \u6a21\u578b\u7684\u8ba1\u7b97\u9650\u5236\u548c\u6548\u7387\u6807\u51c6\u3002\u6211\u4eec\u7684\u5173\u952e\u8d21\u732e\u662f\u786e\u5b9a $\\mathsf{VAR}$ \u8ba1\u7b97\u53ef\u4ee5\u5728\u5176\u4e2d\u5b9e\u73b0\u6b21\u4e8c\u6b21\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u6761\u4ef6\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u4e3a $\\mathsf{VAR}$ \u6ce8\u610f\u529b\u673a\u5236\u4e2d\u4f7f\u7528\u7684\u8f93\u5165\u77e9\u9635\u8303\u6570\u5efa\u7acb\u4e86\u4e00\u4e2a\u4e34\u754c\u9608\u503c\u3002\u5728\u6b64\u9608\u503c\u4e4b\u4e0a\uff0c\u5047\u8bbe\u6765\u81ea\u7ec6\u7c92\u5ea6\u590d\u6742\u6027\u7406\u8bba\u7684\u5f3a\u6307\u6570\u65f6\u95f4\u5047\u8bbe ($\\mathsf{SETH}$)\uff0c\u5219 $\\mathsf{VAR}$ \u6a21\u578b\u7684\u6b21\u56db\u6b21\u65f6\u95f4\u7b97\u6cd5\u662f\u4e0d\u53ef\u80fd\u7684\u3002\u4e3a\u4e86\u8bc1\u5b9e\u6211\u4eec\u7684\u7406\u8bba\u53d1\u73b0\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u5229\u7528\u4f4e\u79e9\u8fd1\u4f3c\u7684\u9ad8\u6548\u6784\u9020\uff0c\u8fd9\u4e9b\u8fd1\u4f3c\u4e0e\u6d3e\u751f\u6807\u51c6\u76f8\u4e00\u81f4\u3002\u8fd9\u9879\u5de5\u4f5c\u4ece\u7406\u8bba\u89d2\u5ea6\u5f00\u59cb\u7814\u7a76 $\\mathsf{VAR}$ \u6a21\u578b\u7684\u8ba1\u7b97\u6548\u7387\u3002\u6211\u4eec\u7684\u6280\u672f\u5c06\u9610\u660e\u5728 $\\mathsf{VAR}$ \u6846\u67b6\u4e2d\u63a8\u8fdb\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u56fe\u50cf\u751f\u6210\u3002", "author": "Yekun Ke et.al.", "authors": "Yekun Ke, Xiaoyu Li, Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song", "id": "2501.04377v1", "paper_url": "http://arxiv.org/abs/2501.04377v1", "repo": "null"}}