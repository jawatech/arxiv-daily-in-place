{"2412.02141": {"publish_time": "2024-12-03", "title": "WSI-LLaVA: A Multimodal Large Language Model for Whole Slide Image", "paper_summary": "Recent advancements in computational pathology have produced patch-level\nMulti-modal Large Language Models (MLLMs), but these models are limited by\ntheir inability to analyze whole slide images (WSIs) comprehensively and their\ntendency to bypass crucial morphological features that pathologists rely on for\ndiagnosis. To address these challenges, we first introduce WSI-Bench, a\nlarge-scale morphology-aware benchmark containing 180k VQA pairs from 9,850\nWSIs across 30 cancer types, designed to evaluate MLLMs' understanding of\nmorphological characteristics crucial for accurate diagnosis. Building upon\nthis benchmark, we present WSI-LLaVA, a novel framework for gigapixel WSI\nunderstanding that employs a three-stage training approach: WSI-text alignment,\nfeature space alignment, and task-specific instruction tuning. To better assess\nmodel performance in pathological contexts, we develop two specialized WSI\nmetrics: WSI-Precision and WSI-Relevance. Experimental results demonstrate that\nWSI-LLaVA outperforms existing models across all capability dimensions, with a\nsignificant improvement in morphological analysis, establishing a clear\ncorrelation between morphological understanding and diagnostic accuracy.", "paper_summary_zh": "\u8fd1\u671f\u5728\u8a08\u7b97\u75c5\u7406\u5b78\u7684\u9032\u5c55\u4e2d\uff0c\u7522\u751f\u4e86\u5340\u584a\u5c64\u7d1a\u7684\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM)\uff0c\u4f46\u9019\u4e9b\u6a21\u578b\u7684\u9650\u5236\u5728\u65bc\u7121\u6cd5\u5168\u9762\u5206\u6790\u5168\u5207\u7247\u5f71\u50cf (WSI)\uff0c\u4e14\u50be\u5411\u65bc\u5ffd\u7565\u75c5\u7406\u5b78\u5bb6\u5728\u8a3a\u65b7\u6642\u4f9d\u8cf4\u7684\u91cd\u8981\u5f62\u614b\u7279\u5fb5\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u9996\u5148\u63a8\u51fa WSI-Bench\uff0c\u4e00\u500b\u5927\u578b\u4e14\u91cd\u8996\u5f62\u614b\u7684\u57fa\u6e96\uff0c\u5305\u542b\u4f86\u81ea 30 \u7a2e\u764c\u75c7\u985e\u578b\u30019,850 \u500b WSI \u7684 18 \u842c\u500b VQA \u914d\u5c0d\uff0c\u65e8\u5728\u8a55\u4f30 MLLM \u5c0d\u5f62\u614b\u7279\u5fb5\u7684\u7406\u89e3\uff0c\u9019\u4e9b\u7279\u5fb5\u5c0d\u65bc\u6e96\u78ba\u8a3a\u65b7\u81f3\u95dc\u91cd\u8981\u3002\u5728\u6b64\u57fa\u6e96\u4e4b\u4e0a\uff0c\u6211\u5011\u63d0\u51fa WSI-LLaVA\uff0c\u4e00\u500b\u7528\u65bc\u7406\u89e3\u5409\u50cf\u7d20 WSI \u7684\u65b0\u6846\u67b6\uff0c\u63a1\u7528\u4e09\u968e\u6bb5\u8a13\u7df4\u65b9\u6cd5\uff1aWSI-\u6587\u672c\u6bd4\u5c0d\u3001\u7279\u5fb5\u7a7a\u9593\u6bd4\u5c0d\u548c\u7279\u5b9a\u4efb\u52d9\u6307\u4ee4\u8abf\u6574\u3002\u70ba\u4e86\u5728\u75c5\u7406\u5b78\u80cc\u666f\u4e0b\u66f4\u597d\u5730\u8a55\u4f30\u6a21\u578b\u6548\u80fd\uff0c\u6211\u5011\u958b\u767c\u4e86\u5169\u500b\u5c08\u9580\u7684 WSI \u6307\u6a19\uff1aWSI-\u7cbe\u6e96\u5ea6\u548c WSI-\u76f8\u95dc\u6027\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0cWSI-LLaVA \u5728\u6240\u6709\u6548\u80fd\u9762\u5411\u90fd\u512a\u65bc\u73fe\u6709\u6a21\u578b\uff0c\u5728\u5f62\u614b\u5206\u6790\u65b9\u9762\u6709\u986f\u8457\u7684\u9032\u6b65\uff0c\u78ba\u7acb\u4e86\u5f62\u614b\u7406\u89e3\u8207\u8a3a\u65b7\u6e96\u78ba\u6027\u4e4b\u9593\u7684\u660e\u78ba\u95dc\u806f\u6027\u3002", "author": "Yuci Liang et.al.", "authors": "Yuci Liang, Xinheng Lyu, Meidan Ding, Wenting Chen, Jipeng Zhang, Yuexiang Ren, Xiangjian He, Song Wu, Sen Yang, Xiyue Wang, Xiaohan Xing, Linlin Shen", "id": "2412.02141v1", "paper_url": "http://arxiv.org/abs/2412.02141v1", "repo": "null"}}