
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-13**|**Dataset Distillation via Committee Voting**|Jiacheng Cui et.al.|[2501.07575v1](http://arxiv.org/abs/2501.07575v1)|[link](https://github.com/jiacheng8/cv-dd)|
|**2025-01-13**|**UnCommon Objects in 3D**|Xingchen Liu et.al.|[2501.07574v1](http://arxiv.org/abs/2501.07574v1)|[link](https://github.com/facebookresearch/uco3d)|
|**2025-01-13**|**WebWalker: Benchmarking LLMs in Web Traversal**|Jialong Wu et.al.|[2501.07572v1](http://arxiv.org/abs/2501.07572v1)|[link](https://github.com/alibaba-nlp/webwalker)|
|**2025-01-13**|**SST-EM: Advanced Metrics for Evaluating Semantic, Spatial and Temporal Aspects in Video Editing**|Varun Biyyala et.al.|[2501.07554v1](http://arxiv.org/abs/2501.07554v1)|[link](https://github.com/custommetrics-sst/sst_customevaluationmetrics)|
|**2025-01-13**|**Imagine while Reasoning in Space: Multimodal Visualization-of-Thought**|Chengzu Li et.al.|[2501.07542v1](http://arxiv.org/abs/2501.07542v1)|null|
|**2025-01-13**|**Investigating Large Language Models in Inferring Personality Traits from User Conversations**|Jianfeng Zhu et.al.|[2501.07532v1](http://arxiv.org/abs/2501.07532v1)|null|
|**2025-01-13**|**Evaluating Agent-based Program Repair at Google**|Pat Rondon et.al.|[2501.07531v1](http://arxiv.org/abs/2501.07531v1)|null|
|**2025-01-13**|**RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment**|Difei Gu et.al.|[2501.07525v1](http://arxiv.org/abs/2501.07525v1)|[link](https://github.com/difeigu/radalign)|
|**2025-01-13**|**Parallel Key-Value Cache Fusion for Position Invariant RAG**|Philhoon Oh et.al.|[2501.07523v1](http://arxiv.org/abs/2501.07523v1)|null|
|**2025-01-13**|**RbRL2.0: Integrated Reward and Policy Learning for Rating-based Reinforcement Learning**|Mingkang Wu et.al.|[2501.07502v1](http://arxiv.org/abs/2501.07502v1)|null|
|**2025-01-13**|**Data and System Perspectives of Sustainable Artificial Intelligence**|Tao Xie et.al.|[2501.07487v1](http://arxiv.org/abs/2501.07487v1)|null|
|**2025-01-13**|**Smart Learning in the 21st Century: Advancing Constructionism Across Three Digital Epochs**|Ilya Levin et.al.|[2501.07486v1](http://arxiv.org/abs/2501.07486v1)|null|
|**2025-01-13**|**TiEBe: A Benchmark for Assessing the Current Knowledge of Large Language Models**|Thales Sales Almeida et.al.|[2501.07482v1](http://arxiv.org/abs/2501.07482v1)|null|
|**2025-01-13**|**Estimating Musical Surprisal in Audio**|Mathias Rose Bjare et.al.|[2501.07474v1](http://arxiv.org/abs/2501.07474v1)|null|
|**2025-01-13**|**A Survey of Embodied AI in Healthcare: Techniques, Applications, and Opportunities**|Yihao Liu et.al.|[2501.07468v1](http://arxiv.org/abs/2501.07468v1)|null|
|**2025-01-13**|**Understanding and Benchmarking Artificial Intelligence: OpenAI's o3 Is Not AGI**|Rolf Pfister et.al.|[2501.07458v1](http://arxiv.org/abs/2501.07458v1)|null|
|**2025-01-13**|**Attention when you need**|Lokesh Boominathan et.al.|[2501.07440v1](http://arxiv.org/abs/2501.07440v1)|null|
|**2025-01-13**|**Diff-Ensembler: Learning to Ensemble 2D Diffusion Models for Volume-to-Volume Medical Image Translation**|Xiyue Zhu et.al.|[2501.07430v1](http://arxiv.org/abs/2501.07430v1)|null|
|**2025-01-13**|**An Investigation into Seasonal Variations in Energy Forecasting for Student Residences**|Muhammad Umair Danish et.al.|[2501.07423v1](http://arxiv.org/abs/2501.07423v1)|null|
|**2025-01-13**|**Initial Findings on Sensor based Open Vocabulary Activity Recognition via Text Embedding Inversion**|Lala Shakti Swarup Ray et.al.|[2501.07408v1](http://arxiv.org/abs/2501.07408v1)|null|
|**2025-01-13**|**PROTECT: Protein circadian time prediction using unsupervised learning**|Aram Ansary Ogholbake et.al.|[2501.07405v1](http://arxiv.org/abs/2501.07405v1)|null|
|**2025-01-13**|**Enhancing Retrieval-Augmented Generation: A Study of Best Practices**|Siran Li et.al.|[2501.07391v1](http://arxiv.org/abs/2501.07391v1)|[link](https://github.com/ali-bahrainian/rag_best_practices)|
|**2025-01-13**|**Emergent effects of scaling on the functional hierarchies within large language models**|Paul C. Bogdan et.al.|[2501.07359v1](http://arxiv.org/abs/2501.07359v1)|null|
|**2025-01-13**|**TempoGPT: Enhancing Temporal Reasoning via Quantizing Embedding**|Haochuan Zhang et.al.|[2501.07335v1](http://arxiv.org/abs/2501.07335v1)|null|
|**2025-01-13**|**Anonymization of Documents for Law Enforcement with Machine Learning**|Manuel Eberhardinger et.al.|[2501.07334v1](http://arxiv.org/abs/2501.07334v1)|null|
|**2025-01-13**|**Joint Automatic Speech Recognition And Structure Learning For Better Speech Understanding**|Jiliang Hu et.al.|[2501.07329v1](http://arxiv.org/abs/2501.07329v1)|null|
|**2025-01-13**|**Evaluation of Artificial Intelligence Methods for Lead Time Prediction in Non-Cycled Areas of Automotive Production**|Cornelius Hake et.al.|[2501.07317v1](http://arxiv.org/abs/2501.07317v1)|null|
|**2025-01-13**|**FinerWeb-10BT: Refining Web Data with LLM-Based Line-Level Filtering**|Erik Henriksson et.al.|[2501.07314v1](http://arxiv.org/abs/2501.07314v1)|[link](https://github.com/turkunlp/finerweb-10bt)|
|**2025-01-13**|**The Lessons of Developing Process Reward Models in Mathematical Reasoning**|Zhenru Zhang et.al.|[2501.07301v1](http://arxiv.org/abs/2501.07301v1)|null|
|**2025-01-13**|**Comparative analysis of optical character recognition methods for Sámi texts from the National Library of Norway**|Tita Enstad et.al.|[2501.07300v1](http://arxiv.org/abs/2501.07300v1)|[link](https://github.com/sprakbanken/synthetic_text_images)|
|**2025-01-13**|**LLM-Net: Democratizing LLMs-as-a-Service through Blockchain-based Expert Networks**|Zan-Kai Chong et.al.|[2501.07288v1](http://arxiv.org/abs/2501.07288v1)|null|
|**2025-01-13**|**Lifelong Learning of Large Language Model based Agents: A Roadmap**|Junhao Zheng et.al.|[2501.07278v1](http://arxiv.org/abs/2501.07278v1)|[link](https://github.com/qianlima-lab/awesome-lifelong-llm-agent)|
|**2025-01-13**|**Bridging Smart Meter Gaps: A Benchmark of Statistical, Machine Learning and Time Series Foundation Models for Data Imputation**|Amir Sartipi et.al.|[2501.07276v1](http://arxiv.org/abs/2501.07276v1)|null|
|**2025-01-13**|**Skip Mamba Diffusion for Monocular 3D Semantic Scene Completion**|Li Liang et.al.|[2501.07260v1](http://arxiv.org/abs/2501.07260v1)|[link](https://github.com/xrkong/skimba)|
|**2025-01-13**|**Audio-CoT: Exploring Chain-of-Thought Reasoning in Large Audio Language Model**|Ziyang Ma et.al.|[2501.07246v1](http://arxiv.org/abs/2501.07246v1)|null|
|**2025-01-13**|**Can Vision-Language Models Evaluate Handwritten Math?**|Oikantik Nath et.al.|[2501.07244v1](http://arxiv.org/abs/2501.07244v1)|null|
|**2025-01-13**|**Lessons From Red Teaming 100 Generative AI Products**|Blake Bullwinkel et.al.|[2501.07238v1](http://arxiv.org/abs/2501.07238v1)|null|
|**2025-01-13**|**Breaking Memory Limits: Gradient Wavelet Transform Enhances LLMs Training**|Ziqing Wen et.al.|[2501.07237v1](http://arxiv.org/abs/2501.07237v1)|[link](https://github.com/zqouo/gwt)|
|**2025-01-13**|**Exploring the Use of Contrastive Language-Image Pre-Training for Human Posture Classification: Insights from Yoga Pose Analysis**|Andrzej D. Dobrzycki et.al.|[2501.07221v1](http://arxiv.org/abs/2501.07221v1)|null|
|**2025-01-13**|**When lies are mostly truthful: automated verbal deception detection for embedded lies**|Riccardo Loconte et.al.|[2501.07217v1](http://arxiv.org/abs/2501.07217v1)|null|
|**2025-01-13**|**Multi-face emotion detection for effective Human-Robot Interaction**|Mohamed Ala Yahyaoui et.al.|[2501.07213v1](http://arxiv.org/abs/2501.07213v1)|null|
|**2025-01-13**|**Generalizable Graph Neural Networks for Robust Power Grid Topology Control**|Matthijs de Jong et.al.|[2501.07186v1](http://arxiv.org/abs/2501.07186v1)|null|
|**2025-01-13**|**Kriging and Gaussian Process Interpolation for Georeferenced Data Augmentation**|Frédérick Fabre Ferber et.al.|[2501.07183v1](http://arxiv.org/abs/2501.07183v1)|null|
|**2025-01-13**|**BIOMEDICA: An Open Biomedical Image-Caption Archive, Dataset, and Vision-Language Models Derived from Scientific Literature**|Alejandro Lozano et.al.|[2501.07171v1](http://arxiv.org/abs/2501.07171v1)|[link](https://github.com/minwoosun/biomedica-etl)|
|**2025-01-13**|**Natural Language-Assisted Multi-modal Medication Recommendation**|Jie Tan et.al.|[2501.07166v1](http://arxiv.org/abs/2501.07166v1)|[link](https://github.com/jtan1102/nla-mmr_cikm_2024)|
|**2025-01-13**|**QuantuneV2: Compiler-Based Local Metric-Driven Mixed Precision Quantization for Practical Embedded AI Applications**|Jeongseok Kim et.al.|[2501.07161v1](http://arxiv.org/abs/2501.07161v1)|null|
|**2025-01-13**|**CureGraph: Contrastive Multi-Modal Graph Representation Learning for Urban Living Circle Health Profiling and Prediction**|Jinlin Li et.al.|[2501.07157v1](http://arxiv.org/abs/2501.07157v1)|[link](https://github.com/jinlin2021/curegraph)|
|**2025-01-13**|**TIMRL: A Novel Meta-Reinforcement Learning Framework for Non-Stationary and Multi-Task Environments**|Chenyang Qi et.al.|[2501.07146v1](http://arxiv.org/abs/2501.07146v1)|null|
|**2025-01-13**|**FlexQuant: Elastic Quantization Framework for Locally Hosted LLM on Edge Devices**|Yuji Chai et.al.|[2501.07139v1](http://arxiv.org/abs/2501.07139v1)|null|
|**2025-01-13**|**ListConRanker: A Contrastive Text Reranker with Listwise Encoding**|Junlong Liu et.al.|[2501.07111v1](http://arxiv.org/abs/2501.07111v1)|null|
|**2025-01-13**|**How GPT learns layer by layer**|Jason Du et.al.|[2501.07108v1](http://arxiv.org/abs/2501.07108v1)|[link](https://github.com/alt-js/othellosae)|
|**2025-01-13**|**AdaCS: Adaptive Normalization for Enhanced Code-Switching ASR**|The Chuong Chu et.al.|[2501.07102v1](http://arxiv.org/abs/2501.07102v1)|null|
|**2025-01-13**|**Collaborative Learning for 3D Hand-Object Reconstruction and Compositional Action Recognition from Egocentric RGB Videos Using Superquadrics**|Tze Ho Elden Tse et.al.|[2501.07100v1](http://arxiv.org/abs/2501.07100v1)|null|
|**2025-01-13**|**MathReader : Text-to-Speech for Mathematical Documents**|Sieun Hyeon et.al.|[2501.07088v1](http://arxiv.org/abs/2501.07088v1)|[link](https://github.com/hyeonsieun/mathreader)|
|**2025-01-13**|**Video Quality Assessment for Online Processing: From Spatial to Temporal Sampling**|Jiebin Yan et.al.|[2501.07087v1](http://arxiv.org/abs/2501.07087v1)|null|
|**2025-01-13**|**Boosting Text-To-Image Generation via Multilingual Prompting in Large Multimodal Models**|Yongyu Mu et.al.|[2501.07086v1](http://arxiv.org/abs/2501.07086v1)|[link](https://github.com/takagi97/pmt2i)|
|**2025-01-13**|**ADKGD: Anomaly Detection in Knowledge Graphs with Dual-Channel Training**|Jiayang Wu et.al.|[2501.07078v1](http://arxiv.org/abs/2501.07078v1)|[link](https://github.com/csjywu1/adkgd)|
|**2025-01-13**|**Representation Learning of Point Cloud Upsampling in Global and Local Inputs**|Tongxu Zhang et.al.|[2501.07076v1](http://arxiv.org/abs/2501.07076v1)|null|
|**2025-01-13**|**Value Compass Leaderboard: A Platform for Fundamental and Validated Evaluation of LLMs Values**|Jing Yao et.al.|[2501.07071v1](http://arxiv.org/abs/2501.07071v1)|null|
|**2025-01-13**|**Research on the Online Update Method for Retrieval-Augmented Generation (RAG) Model with Incremental Learning**|Yuxin Fan et.al.|[2501.07063v1](http://arxiv.org/abs/2501.07063v1)|null|
|**2025-01-13**|**Logic Meets Magic: LLMs Cracking Smart Contract Vulnerabilities**|ZeKe Xiao et.al.|[2501.07058v1](http://arxiv.org/abs/2501.07058v1)|null|
|**2025-01-13**|**PoAct: Policy and Action Dual-Control Agent for Generalized Applications**|Guozhi Yuan et.al.|[2501.07054v1](http://arxiv.org/abs/2501.07054v1)|null|
|**2025-01-13**|**Unveiling the Potential of Text in High-Dimensional Time Series Forecasting**|Xin Zhou et.al.|[2501.07048v1](http://arxiv.org/abs/2501.07048v1)|[link](https://github.com/xinzzzhou/textfusionhts)|
|**2025-01-13**|**ACCon: Angle-Compensated Contrastive Regularizer for Deep Regression**|Botao Zhao et.al.|[2501.07045v1](http://arxiv.org/abs/2501.07045v1)|null|
|**2025-01-13**|**A Proposed Large Language Model-Based Smart Search for Archive System**|Ha Dung Nguyen et.al.|[2501.07024v1](http://arxiv.org/abs/2501.07024v1)|null|
|**2025-01-13**|**Neural Probabilistic Circuits: Enabling Compositional and Interpretable Predictions through Logical Reasoning**|Weixin Chen et.al.|[2501.07021v1](http://arxiv.org/abs/2501.07021v1)|null|
|**2025-01-13**|**ViSoLex: An Open-Source Repository for Vietnamese Social Media Lexical Normalization**|Anh Thi-Hoang Nguyen et.al.|[2501.07020v1](http://arxiv.org/abs/2501.07020v1)|[link](https://github.com/hadung2002/visolex)|
|**2025-01-13**|**A Multi-Modal Deep Learning Framework for Pan-Cancer Prognosis**|Binyu Zhang et.al.|[2501.07016v1](http://arxiv.org/abs/2501.07016v1)|[link](https://github.com/binging512/umpsnet)|
|**2025-01-13**|**AlgoRxplorers | Precision in Mutation -- Enhancing Drug Design with Advanced Protein Stability Prediction Tools**|Karishma Thakrar et.al.|[2501.07014v1](http://arxiv.org/abs/2501.07014v1)|null|
|**2025-01-13**|**Likelihood Training of Cascaded Diffusion Models via Hierarchical Volume-preserving Maps**|Henry Li et.al.|[2501.06999v1](http://arxiv.org/abs/2501.06999v1)|[link](https://github.com/lihenryhfl/pcdm)|
|**2025-01-13**|**LEO: Boosting Mixture of Vision Encoders for Multimodal Large Language Models**|Mozhgan Nasr Azadani et.al.|[2501.06986v1](http://arxiv.org/abs/2501.06986v1)|[link](https://github.com/mozhgan91/leo)|
|**2025-01-13**|**Graph Contrastive Learning on Multi-label Classification for Recommendations**|Jiayang Wu et.al.|[2501.06985v1](http://arxiv.org/abs/2501.06985v1)|null|
|**2025-01-13**|**Data Enrichment Work and AI Labor in Latin America and the Caribbean**|Gianna Williams et.al.|[2501.06981v1](http://arxiv.org/abs/2501.06981v1)|null|
|**2025-01-13**|**Combining LLM decision and RL action selection to improve RL policy for adaptive interventions**|Karine Karine et.al.|[2501.06980v1](http://arxiv.org/abs/2501.06980v1)|null|
|**2025-01-12**|**Kolmogorov-Arnold Recurrent Network for Short Term Load Forecasting Across Diverse Consumers**|Muhammad Umair Danish et.al.|[2501.06965v1](http://arxiv.org/abs/2501.06965v1)|null|
|**2025-01-12**|**Enhancing Patient-Centric Communication: Leveraging LLMs to Simulate Patient Perspectives**|Xinyao Ma et.al.|[2501.06964v1](http://arxiv.org/abs/2501.06964v1)|null|
|**2025-01-12**|**Compact Bayesian Neural Networks via pruned MCMC sampling**|Ratneel Deo et.al.|[2501.06962v1](http://arxiv.org/abs/2501.06962v1)|null|
|**2025-01-12**|**The Einstein Test: Towards a Practical Test of a Machine's Ability to Exhibit Superintelligence**|David Benrimoh et.al.|[2501.06948v1](http://arxiv.org/abs/2501.06948v1)|null|
|**2025-01-12**|**An Empirical Study of Deep Reinforcement Learning in Continuing Tasks**|Yi Wan et.al.|[2501.06937v1](http://arxiv.org/abs/2501.06937v1)|[link](https://github.com/facebookresearch/deeprl-continuing-tasks)|
|**2025-01-12**|**Harnessing Large Language Models for Disaster Management: A Survey**|Zhenyu Lei et.al.|[2501.06932v1](http://arxiv.org/abs/2501.06932v1)|null|
|**2025-01-12**|**Why are we living the age of AI applications right now? The long innovation path from AI's birth to a child's bedtime magic**|Tapio Pitkäranta et.al.|[2501.06929v1](http://arxiv.org/abs/2501.06929v1)|null|
|**2025-01-12**|**Risk-Averse Finetuning of Large Language Models**|Sapana Chaudhary et.al.|[2501.06911v1](http://arxiv.org/abs/2501.06911v1)|[link](https://github.com/sapanachaudhary/ra-rlhf)|
|**2025-01-12**|**Language Fusion for Parameter-Efficient Cross-lingual Transfer**|Philipp Borchert et.al.|[2501.06892v1](http://arxiv.org/abs/2501.06892v1)|null|
|**2025-01-12**|**MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis**|Sadia Kamal et.al.|[2501.06887v1](http://arxiv.org/abs/2501.06887v1)|null|
|**2025-01-12**|**Defect Detection Network In PCB Circuit Devices Based on GAN Enhanced YOLOv11**|Jiayi Huang et.al.|[2501.06879v1](http://arxiv.org/abs/2501.06879v1)|null|
|**2025-01-12**|**Causal Claims in Economics**|Prashant Garg et.al.|[2501.06873v1](http://arxiv.org/abs/2501.06873v1)|null|
|**2025-01-12**|**A Foundational Generative Model for Breast Ultrasound Image Analysis**|Haojun Yu et.al.|[2501.06869v1](http://arxiv.org/abs/2501.06869v1)|null|
|**2025-01-12**|**Transfer Learning of Tabular Data by Finetuning Large Language Models**|Shourav B. Rabbani et.al.|[2501.06863v1](http://arxiv.org/abs/2501.06863v1)|null|
|**2025-01-12**|**LarvSeg: Exploring Image Classification Data For Large Vocabulary Semantic Segmentation via Category-wise Attentive Classifier**|Haojun Yu et.al.|[2501.06862v1](http://arxiv.org/abs/2501.06862v1)|[link](https://github.com/haojunyu1998/larvseg)|
|**2025-01-12**|**A Comprehensive Evaluation of Large Language Models on Mental Illnesses in Arabic Context**|Noureldin Zahran et.al.|[2501.06859v1](http://arxiv.org/abs/2501.06859v1)|null|
|**2025-01-12**|**What Is a Counterfactual Cause in Action Theories?**|Daxin Liu et.al.|[2501.06857v1](http://arxiv.org/abs/2501.06857v1)|null|
|**2025-01-12**|**A General Framework for Inference-time Scaling and Steering of Diffusion Models**|Raghav Singhal et.al.|[2501.06848v1](http://arxiv.org/abs/2501.06848v1)|[link](https://github.com/zacharyhorvitz/fk-diffusion-steering)|
|**2025-01-12**|**SPAM: Spike-Aware Adam with Momentum Reset for Stable LLM Training**|Tianjin Huang et.al.|[2501.06842v1](http://arxiv.org/abs/2501.06842v1)|null|
|**2025-01-12**|**An efficient approach to represent enterprise web application structure using Large Language Model in the service of Intelligent Quality Engineering**|Zaber Al Hassan Ayon et.al.|[2501.06837v1](http://arxiv.org/abs/2501.06837v1)|null|
|**2025-01-12**|**LLMs Model Non-WEIRD Populations: Experiments with Synthetic Cultural Agents**|Augusto Gonzalez-Bonorino et.al.|[2501.06834v1](http://arxiv.org/abs/2501.06834v1)|null|
|**2025-01-12**|**Towards Counterfactual and Contrastive Explainability and Transparency of DCNN Image Classifiers**|Syed Ali Tariq et.al.|[2501.06831v1](http://arxiv.org/abs/2501.06831v1)|null|
|**2025-01-12**|**Leveraging Taxonomy and LLMs for Improved Multimodal Hierarchical Classification**|Shijing Chen et.al.|[2501.06827v1](http://arxiv.org/abs/2501.06827v1)|null|
|**2025-01-12**|**Correcting Annotator Bias in Training Data: Population-Aligned Instance Replication (PAIR)**|Stephanie Eckman et.al.|[2501.06826v1](http://arxiv.org/abs/2501.06826v1)|null|
|**2025-01-12**|**Event Argument Extraction with Enriched Prompts**|Chen Liang et.al.|[2501.06825v1](http://arxiv.org/abs/2501.06825v1)|[link](https://github.com/cs-liangchen-work/eaeprompt)|
|**2025-01-12**|**MEXA-CTP: Mode Experts Cross-Attention for Clinical Trial Outcome Prediction**|Yiqing Zhang et.al.|[2501.06823v1](http://arxiv.org/abs/2501.06823v1)|null|

#### Abstracts
##### **Dataset Distillation via Committee Voting**
2501.07575v1 by Jiacheng Cui, Zhaoyi Li, Xiaochen Ma, Xinyue Bi, Yaxin Luo, Zhiqiang Shen

Dataset distillation aims to synthesize a smaller, representative dataset
that preserves the essential properties of the original data, enabling
efficient model training with reduced computational resources. Prior work has
primarily focused on improving the alignment or matching process between
original and synthetic data, or on enhancing the efficiency of distilling large
datasets. In this work, we introduce ${\bf C}$ommittee ${\bf V}$oting for ${\bf
D}$ataset ${\bf D}$istillation (CV-DD), a novel and orthogonal approach that
leverages the collective wisdom of multiple models or experts to create
high-quality distilled datasets. We start by showing how to establish a strong
baseline that already achieves state-of-the-art accuracy through leveraging
recent advancements and thoughtful adjustments in model design and optimization
processes. By integrating distributions and predictions from a committee of
models while generating high-quality soft labels, our method captures a wider
spectrum of data features, reduces model-specific biases and the adverse
effects of distribution shifts, leading to significant improvements in
generalization. This voting-based strategy not only promotes diversity and
robustness within the distilled dataset but also significantly reduces
overfitting, resulting in improved performance on post-eval tasks. Extensive
experiments across various datasets and IPCs (images per class) demonstrate
that Committee Voting leads to more reliable and adaptable distilled data
compared to single/multi-model distillation methods, demonstrating its
potential for efficient and accurate dataset distillation. Code is available
at: https://github.com/Jiacheng8/CV-DD.

摘要：<paragraph>資料集蒸餾旨在合成一個較小、具代表性的資料集，以保留原始資料的基本屬性，並能以減少的運算資源進行有效率的模型訓練。先前的研究主要集中在改善原始資料與合成資料之間的對齊或比對程序，或提升大型資料集蒸餾的效率。在這項研究中，我們引入了資料集蒸餾委員會投票 (CV-DD)，這是一種新穎且正交的方法，它利用多個模型或專家的集體智慧來建立高品質的蒸餾資料集。我們首先展示如何建立一個強大的基準，它透過利用模型設計和最佳化程序中的最新進展和深思熟慮的調整，已經達到了最先進的準確度。透過整合模型委員會的分布和預測，同時產生高品質的軟標籤，我們的模型擷取了更廣泛的資料特徵，減少了模型特定的偏差和分布轉移的不利影響，從而大幅改善了泛化能力。這種基於投票的策略不僅促進了蒸餾資料集中的多樣性和穩健性，也大幅減少了過度擬合，進而改善了後評估任務的效能。跨越各種資料集和 IPC（每類別的影像）的廣泛實驗證明，與單一/多模型蒸餾方法相比，委員會投票產生了更可靠且更具適應性的蒸餾資料，證明了其在有效率且準確的資料集蒸餾方面的潛力。程式碼可在以下網址取得：https://github.com/Jiacheng8/CV-DD。</paragraph>

##### **UnCommon Objects in 3D**
2501.07574v1 by Xingchen Liu, Piyush Tayal, Jianyuan Wang, Jesus Zarzar, Tom Monnier, Konstantinos Tertikas, Jiali Duan, Antoine Toisoul, Jason Y. Zhang, Natalia Neverova, Andrea Vedaldi, Roman Shapovalov, David Novotny

We introduce Uncommon Objects in 3D (uCO3D), a new object-centric dataset for
3D deep learning and 3D generative AI. uCO3D is the largest publicly-available
collection of high-resolution videos of objects with 3D annotations that
ensures full-360$^{\circ}$ coverage. uCO3D is significantly more diverse than
MVImgNet and CO3Dv2, covering more than 1,000 object categories. It is also of
higher quality, due to extensive quality checks of both the collected videos
and the 3D annotations. Similar to analogous datasets, uCO3D contains
annotations for 3D camera poses, depth maps and sparse point clouds. In
addition, each object is equipped with a caption and a 3D Gaussian Splat
reconstruction. We train several large 3D models on MVImgNet, CO3Dv2, and uCO3D
and obtain superior results using the latter, showing that uCO3D is better for
learning applications.

摘要：我們介紹 3D 中的不常見物件 (uCO3D)，這是一個新的以物件為中心的資料集，用於 3D 深度學習和 3D 生成式 AI。uCO3D 是公開可用的最大高解析度物件影片集合，其中包含可確保完整 360 度覆蓋範圍的 3D 標註。uCO3D 比 MVImgNet 和 CO3Dv2 多元得多，涵蓋超過 1,000 個物件類別。由於對收集的影片和 3D 標註進行廣泛的品質檢查，因此品質也較高。與類似資料集類似，uCO3D 包含 3D 相機姿勢、深度圖和稀疏點雲的標註。此外，每個物件都配有標題和 3D 高斯 Splat 重建。我們在 MVImgNet、CO3Dv2 和 uCO3D 上訓練了幾個大型 3D 模型，並使用後者獲得了更好的結果，這表示 uCO3D 更適合用於學習應用程式。

##### **WebWalker: Benchmarking LLMs in Web Traversal**
2501.07572v1 by Jialong Wu, Wenbiao Yin, Yong Jiang, Zhenglin Wang, Zekun Xi, Runnan Fang, Deyu Zhou, Pengjun Xie, Fei Huang

Retrieval-augmented generation (RAG) demonstrates remarkable performance
across tasks in open-domain question-answering. However, traditional search
engines may retrieve shallow content, limiting the ability of LLMs to handle
complex, multi-layered information. To address it, we introduce WebWalkerQA, a
benchmark designed to assess the ability of LLMs to perform web traversal. It
evaluates the capacity of LLMs to traverse a website's subpages to extract
high-quality data systematically. We propose WebWalker, which is a multi-agent
framework that mimics human-like web navigation through an explore-critic
paradigm. Extensive experimental results show that WebWalkerQA is challenging
and demonstrates the effectiveness of RAG combined with WebWalker, through the
horizontal and vertical integration in real-world scenarios.

摘要：檢索增強生成（RAG）在開放領域問答任務中展現出卓越的效能。然而，傳統的搜尋引擎可能會檢索到較淺層的內容，限制 LLM 處理複雜、多層級資訊的能力。為了解決此問題，我們引入了 WebWalkerQA，這是一個基準測試，用於評估 LLM 執行網路瀏覽的能力。它評估 LLM 瀏覽網站子頁面的能力，以系統性地萃取高品質的資料。我們提出了 WebWalker，這是一個多代理架構，透過探索-批評範式模擬人類般的網路瀏覽。廣泛的實驗結果顯示，WebWalkerQA 具有挑戰性，並透過在真實世界情境中進行水平和垂直整合，證明了結合 WebWalker 的 RAG 的效能。

##### **SST-EM: Advanced Metrics for Evaluating Semantic, Spatial and Temporal Aspects in Video Editing**
2501.07554v1 by Varun Biyyala, Bharat Chanderprakash Kathuria, Jialu Li, Youshan Zhang

Video editing models have advanced significantly, but evaluating their
performance remains challenging. Traditional metrics, such as CLIP text and
image scores, often fall short: text scores are limited by inadequate training
data and hierarchical dependencies, while image scores fail to assess temporal
consistency. We present SST-EM (Semantic, Spatial, and Temporal Evaluation
Metric), a novel evaluation framework that leverages modern Vision-Language
Models (VLMs), Object Detection, and Temporal Consistency checks. SST-EM
comprises four components: (1) semantic extraction from frames using a VLM, (2)
primary object tracking with Object Detection, (3) focused object refinement
via an LLM agent, and (4) temporal consistency assessment using a Vision
Transformer (ViT). These components are integrated into a unified metric with
weights derived from human evaluations and regression analysis. The name SST-EM
reflects its focus on Semantic, Spatial, and Temporal aspects of video
evaluation. SST-EM provides a comprehensive evaluation of semantic fidelity and
temporal smoothness in video editing. The source code is available in the
\textbf{\href{https://github.com/custommetrics-sst/SST_CustomEvaluationMetrics.git}{GitHub
Repository}}.

摘要：影片編輯模型已大幅進步，但評估其效能仍具挑戰性。傳統指標，例如 CLIP 文字和影像分數，常有不足之處：文字分數受限於訓練資料不足和階層化依賴性，而影像分數無法評估時間一致性。我們提出 SST-EM（語意、空間和時間評估指標），這是一個新穎的評估架構，它利用現代視覺語言模型 (VLM)、物件偵測和時間一致性檢查。SST-EM 包含四個組成部分：(1) 使用 VLM 從畫面中萃取語意，(2) 使用物件偵測進行主要物件追蹤，(3) 透過 LLM 代理進行聚焦物件精煉，以及 (4) 使用視覺轉換器 (ViT) 進行時間一致性評估。這些組成部分整合到一個統一的指標中，權重來自人類評估和回歸分析。SST-EM 這個名稱反映出它專注於影片評估的語意、空間和時間面向。SST-EM 提供對影片編輯中語意保真度和時間流暢度的全面評估。原始碼可在 \textbf{\href{https://github.com/custommetrics-sst/SST_CustomEvaluationMetrics.git}{GitHub 儲存庫}} 中取得。

##### **Imagine while Reasoning in Space: Multimodal Visualization-of-Thought**
2501.07542v1 by Chengzu Li, Wenshan Wu, Huanyu Zhang, Yan Xia, Shaoguang Mao, Li Dong, Ivan Vulić, Furu Wei

Chain-of-Thought (CoT) prompting has proven highly effective for enhancing
complex reasoning in Large Language Models (LLMs) and Multimodal Large Language
Models (MLLMs). Yet, it struggles in complex spatial reasoning tasks.
Nonetheless, human cognition extends beyond language alone, enabling the
remarkable capability to think in both words and images. Inspired by this
mechanism, we propose a new reasoning paradigm, Multimodal
Visualization-of-Thought (MVoT). It enables visual thinking in MLLMs by
generating image visualizations of their reasoning traces. To ensure
high-quality visualization, we introduce token discrepancy loss into
autoregressive MLLMs. This innovation significantly improves both visual
coherence and fidelity. We validate this approach through several dynamic
spatial reasoning tasks. Experimental results reveal that MVoT demonstrates
competitive performance across tasks. Moreover, it exhibits robust and reliable
improvements in the most challenging scenarios where CoT fails. Ultimately,
MVoT establishes new possibilities for complex reasoning tasks where visual
thinking can effectively complement verbal reasoning.

摘要：鏈式思考 (CoT) 提示已被證實對於增強大型語言模型 (LLM) 和多模態大型語言模型 (MLLM) 中的複雜推理非常有效。然而，它在複雜的空間推理任務中卻很吃力。儘管如此，人類的認知不僅限於語言，還能以言語和影像思考。受到此機制的啟發，我們提出了一種新的推理範例，即多模態思想視覺化 (MVoT)。它能讓 MLLM 產生推理軌跡的影像視覺化，從而實現視覺思考。為了確保高品質的視覺化，我們將標記差異損失引入自迴歸 MLLM。這項創新顯著提升了視覺一致性和保真度。我們透過多項動態空間推理任務驗證了此方法。實驗結果顯示，MVoT 在各種任務中展現出具有競爭力的效能。此外，在 CoT 失效的最具挑戰性場景中，它展現出強健且可靠的進步。最終，MVoT 為視覺思考能有效補充語言推理的複雜推理任務建立了新的可能性。

##### **Investigating Large Language Models in Inferring Personality Traits from User Conversations**
2501.07532v1 by Jianfeng Zhu, Ruoming Jin, Karin G. Coifman

Large Language Models (LLMs) are demonstrating remarkable human like
capabilities across diverse domains, including psychological assessment. This
study evaluates whether LLMs, specifically GPT-4o and GPT-4o mini, can infer
Big Five personality traits and generate Big Five Inventory-10 (BFI-10) item
scores from user conversations under zero-shot prompting conditions. Our
findings reveal that incorporating an intermediate step--prompting for BFI-10
item scores before calculating traits--enhances accuracy and aligns more
closely with the gold standard than direct trait inference. This structured
approach underscores the importance of leveraging psychological frameworks in
improving predictive precision. Additionally, a group comparison based on
depressive symptom presence revealed differential model performance.
Participants were categorized into two groups: those experiencing at least one
depressive symptom and those without symptoms. GPT-4o mini demonstrated
heightened sensitivity to depression-related shifts in traits such as
Neuroticism and Conscientiousness within the symptom-present group, whereas
GPT-4o exhibited strengths in nuanced interpretation across groups. These
findings underscore the potential of LLMs to analyze real-world psychological
data effectively, offering a valuable foundation for interdisciplinary research
at the intersection of artificial intelligence and psychology.

摘要：大型語言模型 (LLM) 在各種領域展現出人類般的驚人能力，包括心理評估。本研究評估 LLM，特別是 GPT-4o 和 GPT-4o mini，是否能在零次提示條件下，從使用者對話中推論出大五人格特質並產生大五人格問卷-10 (BFI-10) 題目分數。我們的研究結果顯示，加入一個中間步驟，即在計算特質之前提示 BFI-10 題目分數，可以提高準確度，並且比直接推論特質更符合黃金標準。這種結構化的做法強調了利用心理框架來提高預測精度的重要性。此外，基於憂鬱症狀存在的群體比較，揭示了不同的模型表現。參與者被分為兩組：至少經歷一種憂鬱症狀的人和沒有症狀的人。GPT-4o mini 證明了對症狀存在組中神經質和盡責性等特質的憂鬱症相關變化具有高度敏感性，而 GPT-4o 則展現了跨群體細微解讀的優勢。這些發現強調了 LLM 有效分析真實世界心理數據的潛力，為人工智慧和心理學交會處的跨領域研究提供了有價值的基礎。

##### **Evaluating Agent-based Program Repair at Google**
2501.07531v1 by Pat Rondon, Renyao Wei, José Cambronero, Jürgen Cito, Aaron Sun, Siddhant Sanyam, Michele Tufano, Satish Chandra

Agent-based program repair offers to automatically resolve complex bugs
end-to-end by combining the planning, tool use, and code generation abilities
of modern LLMs. Recent work has explored the use of agent-based repair
approaches on the popular open-source SWE-Bench, a collection of bugs from
highly-rated GitHub Python projects. In addition, various agentic approaches
such as SWE-Agent have been proposed to solve bugs in this benchmark. This
paper explores the viability of using an agentic approach to address bugs in an
enterprise context. To investigate this, we curate an evaluation set of 178
bugs drawn from Google's issue tracking system. This dataset spans both
human-reported (78) and machine-reported bugs (100).
  To establish a repair performance baseline on this benchmark, we implement
Passerine, an agent similar in spirit to SWE-Agent that can work within
Google's development environment. We show that with 20 trajectory samples and
Gemini 1.5 Pro, Passerine can produce a patch that passes bug tests (i.e.,
plausible) for 73% of machine-reported and 25.6% of human-reported bugs in our
evaluation set. After manual examination, we found that 43% of machine-reported
bugs and 17.9% of human-reported bugs have at least one patch that is
semantically equivalent to the ground-truth patch.
  These results establish a baseline on an industrially relevant benchmark,
which as we show, contains bugs drawn from a different distribution -- in terms
of language diversity, size, and spread of changes, etc. -- compared to those
in the popular SWE-Bench dataset.

摘要：<paragraph>基於代理程式程式修復提供自動解決複雜錯誤的方法，
透過結合現代大型語言模型的規劃、工具使用和程式碼生成能力，
從頭到尾解決問題。最近的研究探索在廣受歡迎的開源 SWE-Bench 上使用基於代理程式的修復方法，
這是從 GitHub Python 專案中收集的錯誤集合。此外，
已經提出各種代理方法，例如 SWE-Agent，來解決此基準中的錯誤。這篇論文探討使用代理方法來解決企業環境中的錯誤的可行性。為了調查這一點，
我們整理了一個由 Google 問題追蹤系統中提取的 178 個錯誤的評估集。此資料集涵蓋人工回報的錯誤 (78) 和機器回報的錯誤 (100)。
為了建立此基準的修復效能基準，我們實作 Passerine，一種與 SWE-Agent 精神相似的代理程式，可以在 Google 的開發環境中工作。我們展示，使用 20 個軌跡樣本和 Gemini 1.5 Pro，Passerine 可以產生一個通過錯誤測試的修補程式 (即，看似合理的) 適用於我們評估集中 73% 的機器回報錯誤和 25.6% 的人工回報錯誤。經過手動檢查，我們發現 43% 的機器回報錯誤和 17.9% 的人工回報錯誤至少有一個修補程式在語意上等同於真實修補程式。
這些結果在與產業相關的基準上建立了一個基準，正如我們所展示的，包含從不同分佈中提取的錯誤--就語言多樣性、大小和變更範圍等方面來說--與廣受歡迎的 SWE-Bench 資料集中的錯誤相比。</paragraph>

##### **RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment**
2501.07525v1 by Difei Gu, Yunhe Gao, Yang Zhou, Mu Zhou, Dimitris Metaxas

Automated chest radiographs interpretation requires both accurate disease
classification and detailed radiology report generation, presenting a
significant challenge in the clinical workflow. Current approaches either focus
on classification accuracy at the expense of interpretability or generate
detailed but potentially unreliable reports through image captioning
techniques. In this study, we present RadAlign, a novel framework that combines
the predictive accuracy of vision-language models (VLMs) with the reasoning
capabilities of large language models (LLMs). Inspired by the radiologist's
workflow, RadAlign first employs a specialized VLM to align visual features
with key medical concepts, achieving superior disease classification with an
average AUC of 0.885 across multiple diseases. These recognized medical
conditions, represented as text-based concepts in the aligned visual-language
space, are then used to prompt LLM-based report generation. Enhanced by a
retrieval-augmented generation mechanism that grounds outputs in similar
historical cases, RadAlign delivers superior report quality with a GREEN score
of 0.678, outperforming state-of-the-art methods' 0.634. Our framework
maintains strong clinical interpretability while reducing hallucinations,
advancing automated medical imaging and report analysis through integrated
predictive and generative AI. Code is available at
https://github.com/difeigu/RadAlign.

摘要：自動化胸部 X 光片解讀需要精準的疾病分類和詳細的放射科報告生成，這對臨床工作流程構成重大挑戰。目前的做法要不就是以犧牲可解讀性為代價專注於分類準確性，要不就是透過影像標題技術產生詳細但可能不可靠的報告。在這項研究中，我們提出 RadAlign，一個結合了視覺語言模型 (VLM) 的預測準確性和大型語言模型 (LLM) 的推理能力的新穎架構。受到放射科醫師工作流程的啟發，RadAlign 首先採用專門的 VLM 將視覺特徵與關鍵醫療概念對齊，在多種疾病中達成優異的疾病分類，平均 AUC 為 0.885。這些識別出的醫療狀況會在對齊的視覺語言空間中表示為基於文字的概念，然後用來提示基於 LLM 的報告生成。透過一種將輸出結果建立在類似過往案例中的檢索增強生成機制，RadAlign 提供優異的報告品質，GREEN 分數為 0.678，優於最先進方法的 0.634。我們的架構維持強大的臨床可解讀性，同時減少幻覺，透過整合預測和生成式 AI，推進自動化醫學影像和報告分析。程式碼可於 https://github.com/difeigu/RadAlign 取得。

##### **Parallel Key-Value Cache Fusion for Position Invariant RAG**
2501.07523v1 by Philhoon Oh, Jinwoo Shin, James Thorne

Recent advancements in Large Language Models (LLMs) underscore the necessity
of Retrieval Augmented Generation (RAG) to leverage external information.
However, LLMs are sensitive to the position of relevant information within
contexts and tend to generate incorrect responses when such information is
placed in the middle, known as `Lost in the Middle' phenomenon. In this paper,
we introduce a framework that generates consistent outputs for decoder-only
models, irrespective of the input context order. Experimental results for three
open domain question answering tasks demonstrate position invariance, where the
model is not sensitive to input context order, and superior robustness to
irrelevent passages compared to prevailing approaches for RAG pipelines.

摘要：大型語言模型 (LLM) 的最新進展強調了檢索增強生成 (RAG) 利用外部資訊的必要性。然而，LLM 對相關資訊在上下文中的位置很敏感，並且當此類資訊置於中間時，往往會產生不正確的回應，這稱為「迷失在中間」現象。在本文中，我們介紹了一個框架，可為僅解碼器模型產生一致的輸出，而與輸入上下文順序無關。針對三個開放領域問題回答任務的實驗結果證明了位置不變性，其中模型對輸入上下文順序不敏感，並且與 RAG 管線的現行方法相比，對無關段落具有更強大的穩健性。

##### **RbRL2.0: Integrated Reward and Policy Learning for Rating-based Reinforcement Learning**
2501.07502v1 by Mingkang Wu, Devin White, Vernon Lawhern, Nicholas R. Waytowich, Yongcan Cao

Reinforcement learning (RL), a common tool in decision making, learns
policies from various experiences based on the associated cumulative
return/rewards without treating them differently. On the contrary, humans often
learn to distinguish from different levels of performance and extract the
underlying trends towards improving their decision making for best performance.
Motivated by this, this paper proposes a novel RL method that mimics humans'
decision making process by differentiating among collected experiences for
effective policy learning. The main idea is to extract important directional
information from experiences with different performance levels, named ratings,
so that policies can be updated towards desired deviation from these
experiences with different ratings. Specifically, we propose a new policy loss
function that penalizes distribution similarities between the current policy
and failed experiences with different ratings, and assign different weights to
the penalty terms based on the rating classes. Meanwhile, reward learning from
these rated samples can be integrated with the new policy loss towards an
integrated reward and policy learning from rated samples. Optimizing the
integrated reward and policy loss function will lead to the discovery of
directions for policy improvement towards maximizing cumulative rewards and
penalizing most from the lowest performance level while least from the highest
performance level. To evaluate the effectiveness of the proposed method, we
present results for experiments on a few typical environments that show
improved convergence and overall performance over the existing rating-based
reinforcement learning method with only reward learning.

摘要：強化學習 (RL) 是決策制定中常見的工具，它根據相關的累積回報/獎勵從各種經驗中學習策略，而不會對它們進行不同的處理。相反，人類通常學會區分不同的表現層級，並提取改善決策制定以獲得最佳表現的潛在趨勢。受此啟發，本文提出了一種新的 RL 方法，它模擬人類的決策制定過程，通過區分收集的經驗來進行有效的策略學習。其主要思想是從具有不同表現層級的經驗中提取重要的方向性資訊，稱為評分，以便可以針對這些具有不同評分的經驗更新策略，朝著所需的偏差方向發展。具體來說，我們提出了一種新的策略損失函數，它懲罰當前策略與具有不同評分的失敗經驗之間的分配相似性，並根據評分類別為懲罰項分配不同的權重。同時，從這些評分樣本中學習獎勵可以與新的策略損失整合，從而從評分樣本中獲得整合的獎勵和策略學習。最佳化整合的獎勵和策略損失函數將導致發現策略改進的方向，朝著最大化累積獎勵和對最低表現層級進行最嚴厲的懲罰，而對最高表現層級進行最輕微的懲罰。為了評估所提出方法的有效性，我們展示了在幾個典型環境中進行的實驗結果，這些結果顯示出比僅使用獎勵學習的現有基於評分的強化學習方法有更好的收斂性和整體表現。

##### **Data and System Perspectives of Sustainable Artificial Intelligence**
2501.07487v1 by Tao Xie, David Harel, Dezhi Ran, Zhenwen Li, Maoliang Li, Zhi Yang, Leye Wang, Xiang Chen, Ying Zhang, Wentao Zhang, Meng Li, Chen Zhang, Linyi Li, Assaf Marron

Sustainable AI is a subfield of AI for concerning developing and using AI
systems in ways of aiming to reduce environmental impact and achieve
sustainability. Sustainable AI is increasingly important given that training of
and inference with AI models such as large langrage models are consuming a
large amount of computing power. In this article, we discuss current issues,
opportunities and example solutions for addressing these issues, and future
challenges to tackle, from the data and system perspectives, related to data
acquisition, data processing, and AI model training and inference.

摘要：永續 AI 是 AI 的子領域，關注於開發和使用 AI 系統，以減少環境影響並達成永續性。永續 AI 變得越來越重要，因為訓練大型語言模型等 AI 模型和進行推論會消耗大量的運算能力。在本文中，我們將討論從資料和系統觀點來看，在資料取得、資料處理、AI 模型訓練和推論等方面，因應這些問題的現況議題、機會和範例解決方案，以及未來需要克服的挑戰。

##### **Smart Learning in the 21st Century: Advancing Constructionism Across Three Digital Epochs**
2501.07486v1 by Ilya Levin, Alexei L. Semenov, Mikael Gorsky

This article explores the evolution of constructionism as an educational
framework, tracing its relevance and transformation across three pivotal eras:
the advent of personal computing, the networked society, and the current era of
generative AI. Rooted in Seymour Papert constructionist philosophy, this study
examines how constructionist principles align with the expanding role of
digital technology in personal and collective learning. We discuss the
transformation of educational environments from hierarchical instructionism to
constructionist models that emphasize learner autonomy and interactive,
creative engagement. Central to this analysis is the concept of an expanded
personality, wherein digital tools and AI integration fundamentally reshape
individual self-perception and social interactions. By integrating
constructionism into the paradigm of smart education, we propose it as a
foundational approach to personalized and democratized learning. Our findings
underscore constructionism enduring relevance in navigating the complexities of
technology-driven education, providing insights for educators and policymakers
seeking to harness digital innovations to foster adaptive, student-centered
learning experiences.

摘要：這篇文章探討建構主義作為教育架構的演變，追溯其在三個關鍵時代中的相關性和轉變：個人運算的出現、網路社會和當前的生成式 AI 時代。本研究根植於西摩·帕普特建構主義哲學，探討建構主義原則如何與數位科技在個人和集體學習中日益擴大的角色相符。我們討論教育環境從階層式教學主義轉變為建構主義模式，強調學習者的自主性和互動、有創意的參與。本分析的核心概念是擴展人格，其中數位工具和 AI 整合從根本上重塑個體的自我認知和社會互動。藉由將建構主義整合到智慧教育的典範中，我們提出建構主義作為個人化和民主化學習的一種基礎方法。我們的研究結果強調建構主義在應對科技驅動教育的複雜性方面歷久彌新的相關性，為尋求利用數位創新來培養適應性、以學生為中心的學習體驗的教育工作者和政策制定者提供見解。

##### **TiEBe: A Benchmark for Assessing the Current Knowledge of Large Language Models**
2501.07482v1 by Thales Sales Almeida, Giovana Kerche Bonás, João Guilherme Alves Santos, Hugo Abonizio, Rodrigo Nogueira

In a rapidly evolving knowledge landscape and the increasing adoption of
large language models, a need has emerged to keep these models continuously
updated with current events. While existing benchmarks evaluate general factual
recall, they often overlook two critical aspects: the ability of models to
integrate evolving knowledge through continual learning and the significant
regional disparities in their performance. To address these gaps, we introduce
the Timely Events Benchmark (TiEBe), a dataset containing over 11,000
question-answer pairs focused on globally and regionally significant events.
TiEBe leverages structured retrospective data from Wikipedia, enabling
continuous updates to assess LLMs' knowledge of evolving global affairs and
their understanding of events across different regions. Our benchmark
demonstrates that LLMs exhibit substantial geographic disparities in factual
recall, emphasizing the need for more balanced global knowledge representation.
Furthermore, TiEBe serves as a tool for evaluating continual learning
strategies, providing insights into models' ability to acquire new information
without forgetting past knowledge.

摘要：在快速演變的知識領域和大型語言模型的採用日益增加的情況下，出現了持續使用當前事件更新這些模型的需求。現有的基準評估一般的事實回憶，但它們往往忽視兩個關鍵方面：模型通過持續學習整合不斷演變的知識的能力以及它們在效能上的顯著區域差異。為了解決這些差距，我們引入了及時事件基準 (TiEBe)，這是一個包含超過 11,000 個問題答案對的資料集，重點關注全球和區域重要事件。TiEBe 採用來自維基百科的結構化回顧性資料，能夠持續更新以評估 LLM 對不斷演變的全球事務的了解以及它們對不同區域事件的理解。我們的基準證明，LLM 在事實回憶中表現出顯著的地理差異，強調了對更平衡的全球知識表示的需求。此外，TiEBe 可作為評估持續學習策略的工具，提供對模型在不忘記過去知識的情況下獲取新資訊的能力的見解。

##### **Estimating Musical Surprisal in Audio**
2501.07474v1 by Mathias Rose Bjare, Giorgia Cantisani, Stefan Lattner, Gerhard Widmer

In modeling musical surprisal expectancy with computational methods, it has
been proposed to use the information content (IC) of one-step predictions from
an autoregressive model as a proxy for surprisal in symbolic music. With an
appropriately chosen model, the IC of musical events has been shown to
correlate with human perception of surprise and complexity aspects, including
tonal and rhythmic complexity. This work investigates whether an analogous
methodology can be applied to music audio. We train an autoregressive
Transformer model to predict compressed latent audio representations of a
pretrained autoencoder network. We verify learning effects by estimating the
decrease in IC with repetitions. We investigate the mean IC of musical segment
types (e.g., A or B) and find that segment types appearing later in a piece
have a higher IC than earlier ones on average. We investigate the IC's relation
to audio and musical features and find it correlated with timbral variations
and loudness and, to a lesser extent, dissonance, rhythmic complexity, and
onset density related to audio and musical features. Finally, we investigate if
the IC can predict EEG responses to songs and thus model humans' surprisal in
music. We provide code for our method on github.com/sonycslparis/audioic.

摘要：在使用计算方法对音乐惊奇预期进行建模时，有人提出使用自回归模型中一步预测的信息内容 (IC) 作为符号音乐中惊奇的代理。通过适当选择模型，音乐事件的 IC 已被证明与人类对惊奇和复杂性方面的感知相关，包括音调和节奏复杂性。这项工作研究了类似的方法是否可以应用于音乐音频。我们训练了一个自回归 Transformer 模型来预测预训练自动编码器网络的压缩潜在音频表示。我们通过估计重复时的 IC 减少来验证学习效果。我们研究了音乐片段类型（例如 A 或 B）的平均 IC，发现出现在作品中后期的片段类型平均比早期的片段类型具有更高的 IC。我们研究了 IC 与音频和音乐特征的关系，发现它与音色变化和响度相关，在较小程度上与不和谐、节奏复杂性和与音频和音乐特征相关的发音密度相关。最后，我们研究了 IC 是否可以预测对歌曲的脑电图反应，从而模拟人类对音乐的惊奇。我们在 github.com/sonycslparis/audioic 上提供了我们方法的代码。

##### **A Survey of Embodied AI in Healthcare: Techniques, Applications, and Opportunities**
2501.07468v1 by Yihao Liu, Xu Cao, Tingting Chen, Yankai Jiang, Junjie You, Minghua Wu, Xiaosong Wang, Mengling Feng, Yaochu Jin, Jintai Chen

Healthcare systems worldwide face persistent challenges in efficiency,
accessibility, and personalization. Powered by modern AI technologies such as
multimodal large language models and world models, Embodied AI (EmAI)
represents a transformative frontier, offering enhanced autonomy and the
ability to interact with the physical world to address these challenges. As an
interdisciplinary and rapidly evolving research domain, "EmAI in healthcare"
spans diverse fields such as algorithms, robotics, and biomedicine. This
complexity underscores the importance of timely reviews and analyses to track
advancements, address challenges, and foster cross-disciplinary collaboration.
In this paper, we provide a comprehensive overview of the "brain" of EmAI for
healthcare, wherein we introduce foundational AI algorithms for perception,
actuation, planning, and memory, and focus on presenting the healthcare
applications spanning clinical interventions, daily care & companionship,
infrastructure support, and biomedical research. Despite its promise, the
development of EmAI for healthcare is hindered by critical challenges such as
safety concerns, gaps between simulation platforms and real-world applications,
the absence of standardized benchmarks, and uneven progress across
interdisciplinary domains. We discuss the technical barriers and explore
ethical considerations, offering a forward-looking perspective on the future of
EmAI in healthcare. A hierarchical framework of intelligent levels for EmAI
systems is also introduced to guide further development. By providing
systematic insights, this work aims to inspire innovation and practical
applications, paving the way for a new era of intelligent, patient-centered
healthcare.

摘要：<paragraph>全球醫療保健系統在效率、可及性和個人化方面持續面臨挑戰。體現式 AI (EmAI) 由多模態大型語言模型和世界模型等現代 AI 技術提供支持，代表了一個轉型前沿，提供增強的自主性，以及與物理世界互動以應對這些挑戰的能力。作為一個跨學科且快速發展的研究領域，「醫療保健中的 EmAI」涵蓋了演算法、機器人和生物醫學等多元領域。這種複雜性突顯了及時審查和分析的重要性，以追蹤進展、應對挑戰並促進跨學科合作。在本文中，我們提供了 EmAI 在醫療保健中的「大腦」的全面概述，我們在其中介紹了感知、執行、規劃和記憶的基本 AI 演算法，並專注於呈現涵蓋臨床干預、日常照護和陪伴、基礎設施支援和生物醫學研究的醫療保健應用。儘管前景看好，但 EmAI 在醫療保健中的發展受到關鍵挑戰的阻礙，例如安全問題、模擬平台和實際應用之間的差距、缺乏標準化基準，以及跨學科領域進展不均。我們討論了技術障礙並探討了道德考量，對 EmAI 在醫療保健中的未來提供了前瞻性的觀點。還引入了 EmAI 系統的智慧層級架構，以指導進一步的發展。透過提供系統性的見解，這項工作旨在激發創新和實用應用，為智慧且以患者為中心的醫療保健新時代鋪路。</paragraph>

##### **Understanding and Benchmarking Artificial Intelligence: OpenAI's o3 Is Not AGI**
2501.07458v1 by Rolf Pfister, Hansueli Jud

OpenAI's o3 achieves a high score of 87.5 % on ARC-AGI, a benchmark proposed
to measure intelligence. This raises the question whether systems based on
Large Language Models (LLMs), particularly o3, demonstrate intelligence and
progress towards artificial general intelligence (AGI). Building on the
distinction between skills and intelligence made by Fran\c{c}ois Chollet, the
creator of ARC-AGI, a new understanding of intelligence is introduced: an agent
is the more intelligent, the more efficiently it can achieve the more diverse
goals in the more diverse worlds with the less knowledge. An analysis of the
ARC-AGI benchmark shows that its tasks represent a very specific type of
problem that can be solved by massive trialling of combinations of predefined
operations. This method is also applied by o3, achieving its high score through
the extensive use of computing power. However, for most problems in the
physical world and in the human domain, solutions cannot be tested in advance
and predefined operations are not available. Consequently, massive trialling of
predefined operations, as o3 does, cannot be a basis for AGI - instead, new
approaches are required that can reliably solve a wide variety of problems
without existing skills. To support this development, a new benchmark for
intelligence is outlined that covers a much higher diversity of unknown tasks
to be solved, thus enabling a comprehensive assessment of intelligence and of
progress towards AGI.

摘要：OpenAI 的 o3 在 ARC-AGI 上取得了 87.5% 的高分，ARC-AGI 是衡量智能的基準。這引發了一個問題，即基於大型語言模型 (LLM) 的系統，尤其是 o3，是否表現出智能並朝著人工通用智能 (AGI) 邁進。基於 ARC-AGI 的創建者 Fran\c{c}ois Chollet 對技能和智能的區分，引入了一種新的智能理解：智能體越能有效地以較少的知識在更多元的世界中實現更多元化的目標，就越智能。對 ARC-AGI 基準的分析表明，其任務代表了一種類型的問題，該問題可以通過對預定義操作組合進行大量的試驗來解決。o3 也採用了這種方法，通過廣泛使用運算能力來獲得高分。然而，對於物理世界和人類領域中的大多數問題，無法預先測試解決方案，並且無法使用預定義的操作。因此，像 o3 那樣大量試驗預定義的操作不能成為 AGI 的基礎——相反，需要能夠在沒有現有技能的情況下可靠地解決各種問題的新方法。為了支持這一發展，概述了一個新的智能基準，涵蓋了更多樣化的未知任務，從而能夠對智能和朝著 AGI 邁進的進展進行全面評估。

##### **Attention when you need**
2501.07440v1 by Lokesh Boominathan, Yizhou Chen, Matthew McGinley, Xaq Pitkow

Being attentive to task-relevant features can improve task performance, but
paying attention comes with its own metabolic cost. Therefore, strategic
allocation of attention is crucial in performing the task efficiently. This
work aims to understand this strategy. Recently, de Gee et al. conducted
experiments involving mice performing an auditory sustained attention-value
task. This task required the mice to exert attention to identify whether a
high-order acoustic feature was present amid the noise. By varying the trial
duration and reward magnitude, the task allows us to investigate how an agent
should strategically deploy their attention to maximize their benefits and
minimize their costs. In our work, we develop a reinforcement learning-based
normative model of the mice to understand how it balances attention cost
against its benefits. The model is such that at each moment the mice can choose
between two levels of attention and decide when to take costly actions that
could obtain rewards. Our model suggests that efficient use of attentional
resources involves alternating blocks of high attention with blocks of low
attention. In the extreme case where the agent disregards sensory input during
low attention states, we see that high attention is used rhythmically. Our
model provides evidence about how one should deploy attention as a function of
task utility, signal statistics, and how attention affects sensory evidence.

摘要：專注於與任務相關的特徵可以提升任務效能，但專注會帶來自身的代謝成本。因此，策略性地分配注意力對於有效執行任務至關重要。這項工作旨在了解此策略。最近，de Gee 等人進行了實驗，讓老鼠執行聽覺持續注意價值任務。此任務要求老鼠專注於辨識高階音響特徵是否出現在雜訊中。藉由改變試驗持續時間和獎勵幅度，此任務讓我們得以探討代理人應如何策略性地運用注意力，以最大化其效益並最小化其成本。在我們的研究中，我們開發了一個基於強化學習的標準老鼠模型，以了解老鼠如何平衡注意力成本和效益。此模型的特點是，老鼠在每個時刻可以在兩個層級的注意力之間選擇，並決定何時採取可能獲得獎勵的昂貴行動。我們的模型顯示，有效利用注意力資源包括交替進行高注意力區塊和低注意力區塊。在極端情況下，當代理人在低注意力狀態下忽視感官輸入時，我們會發現高注意力會以有節奏的方式使用。我們的模型提供了證據，說明一個人應如何根據任務效用、訊號統計資料以及注意力如何影響感官證據來運用注意力。

##### **Diff-Ensembler: Learning to Ensemble 2D Diffusion Models for Volume-to-Volume Medical Image Translation**
2501.07430v1 by Xiyue Zhu, Dou Hoon Kwark, Ruike Zhu, Kaiwen Hong, Yiqi Tao, Shirui Luo, Yudu Li, Zhi-Pei Liang, Volodymyr Kindratenko

Despite success in volume-to-volume translations in medical images, most
existing models struggle to effectively capture the inherent volumetric
distribution using 3D representations. The current state-of-the-art approach
combines multiple 2D-based networks through weighted averaging, thereby
neglecting the 3D spatial structures. Directly training 3D models in medical
imaging presents significant challenges due to high computational demands and
the need for large-scale datasets. To address these challenges, we introduce
Diff-Ensembler, a novel hybrid 2D-3D model for efficient and effective
volumetric translations by ensembling perpendicularly trained 2D diffusion
models with a 3D network in each diffusion step. Moreover, our model can
naturally be used to ensemble diffusion models conditioned on different
modalities, allowing flexible and accurate fusion of input conditions.
Extensive experiments demonstrate that Diff-Ensembler attains superior accuracy
and volumetric realism in 3D medical image super-resolution and modality
translation. We further demonstrate the strength of our model's volumetric
realism using tumor segmentation as a downstream task.

摘要：儘管在醫學影像中體積到體積的翻譯取得成功，但現有的模型大多難以有效地使用 3D 呈現來擷取固有的體積分佈。目前最先進的方法是透過加權平均來結合多個基於 2D 的網路，因此忽略了 3D 空間結構。在醫學影像中直接訓練 3D 模型會產生顯著的挑戰，原因在於高運算需求和大規模資料集的需求。為了應對這些挑戰，我們引入了 Diff-Ensembler，這是一個新穎的混合 2D-3D 模型，可透過在每個擴散步驟中將垂直訓練的 2D 擴散模型與 3D 網路結合，來有效率且有效地進行體積轉換。此外，我們的模型可以自然地用於結合基於不同形式的擴散模型，從而靈活且準確地融合輸入條件。廣泛的實驗證明，Diff-Ensembler 在 3D 醫學影像超解析度和形式轉換中達到了更高的準確度和體積真實感。我們進一步使用腫瘤分割作為下游任務，來證明我們模型的體積真實感。

##### **An Investigation into Seasonal Variations in Energy Forecasting for Student Residences**
2501.07423v1 by Muhammad Umair Danish, Mathumitha Sureshkumar, Thanuri Fonseka, Umeshika Uthayakumar, Vinura Galwaduge

This research provides an in-depth evaluation of various machine learning
models for energy forecasting, focusing on the unique challenges of seasonal
variations in student residential settings. The study assesses the performance
of baseline models, such as LSTM and GRU, alongside state-of-the-art
forecasting methods, including Autoregressive Feedforward Neural Networks,
Transformers, and hybrid approaches. Special attention is given to predicting
energy consumption amidst challenges like seasonal patterns, vacations,
meteorological changes, and irregular human activities that cause sudden
fluctuations in usage. The findings reveal that no single model consistently
outperforms others across all seasons, emphasizing the need for season-specific
model selection or tailored designs. Notably, the proposed Hyper Network based
LSTM and MiniAutoEncXGBoost models exhibit strong adaptability to seasonal
variations, effectively capturing abrupt changes in energy consumption during
summer months. This study advances the energy forecasting field by emphasizing
the critical role of seasonal dynamics and model-specific behavior in achieving
accurate predictions.

摘要：本研究針對能源預測的各種機器學習模型進行深入評估，重點關注學生住宅環境中季節性變化的獨特挑戰。本研究評估基準模型（例如 LSTM 和 GRU）與最先進的預測方法（包括自迴歸前饋神經網路、Transformer和混合方法）的效能。特別注意在季節性模式、假期、氣象變化和導致使用量突然波動的不規則人類活動等挑戰中預測能源消耗。研究結果顯示，沒有單一模型在所有季節都能持續優於其他模型，這強調了需要根據季節選擇特定模型或量身打造設計。值得注意的是，所提出的基於超網路的 LSTM 和 MiniAutoEncXGBoost 模型展現出對季節性變化的強大適應力，有效捕捉夏季月份能源消耗的突然變化。本研究透過強調季節動態和特定模型行為在達成準確預測中扮演的關鍵角色，推動了能源預測領域的進步。

##### **Initial Findings on Sensor based Open Vocabulary Activity Recognition via Text Embedding Inversion**
2501.07408v1 by Lala Shakti Swarup Ray, Bo Zhou, Sungho Suh, Paul Lukowicz

Conventional human activity recognition (HAR) relies on classifiers trained
to predict discrete activity classes, inherently limiting recognition to
activities explicitly present in the training set. Such classifiers would
invariably fail, putting zero likelihood, when encountering unseen activities.
We propose Open Vocabulary HAR (OV-HAR), a framework that overcomes this
limitation by first converting each activity into natural language and breaking
it into a sequence of elementary motions. This descriptive text is then encoded
into a fixed-size embedding. The model is trained to regress this embedding,
which is subsequently decoded back into natural language using a pre-trained
embedding inversion model. Unlike other works that rely on auto-regressive
large language models (LLMs) at their core, OV-HAR achieves open vocabulary
recognition without the computational overhead of such models. The generated
text can be transformed into a single activity class using LLM prompt
engineering. We have evaluated our approach on different modalities, including
vision (pose), IMU, and pressure sensors, demonstrating robust generalization
across unseen activities and modalities, offering a fundamentally different
paradigm from contemporary classifiers.

摘要：傳統的人類活動識別 (HAR) 依賴於訓練好的分類器來預測離散的活動類別，本質上將識別限制在訓練集中明確呈現的活動。此類分類器在遇到未見過的活動時，會一律失敗，並給出零機率。我們提出開放詞彙 HAR (OV-HAR)，一個透過先將每個活動轉換為自然語言並將其分解成一系列基本動作來克服此限制的架構。接著將此描述文字編碼成固定大小的內嵌。此模型經過訓練以回歸此內嵌，隨後再使用預先訓練好的內嵌反轉模型將其解碼回自然語言。與其他依賴於核心自迴歸大型語言模型 (LLM) 的作品不同，OV-HAR 在沒有此類模型的運算負擔下，就能達成開放詞彙識別。產生的文字可以使用 LLM 提示工程轉換成單一活動類別。我們已在不同的模式上評估我們的做法，包括視覺 (姿勢)、IMU 和壓力感測器，展示了在未見過的活動和模式中穩健的泛化，提供了一個與當代分類器截然不同的範例。

##### **PROTECT: Protein circadian time prediction using unsupervised learning**
2501.07405v1 by Aram Ansary Ogholbake, Qiang Cheng

Circadian rhythms regulate the physiology and behavior of humans and animals.
Despite advancements in understanding these rhythms and predicting circadian
phases at the transcriptional level, predicting circadian phases from proteomic
data remains elusive. This challenge is largely due to the scarcity of time
labels in proteomic datasets, which are often characterized by small sample
sizes, high dimensionality, and significant noise. Furthermore, existing
methods for predicting circadian phases from transcriptomic data typically rely
on prior knowledge of known rhythmic genes, making them unsuitable for
proteomic datasets. To address this gap, we developed a novel computational
method using unsupervised deep learning techniques to predict circadian sample
phases from proteomic data without requiring time labels or prior knowledge of
proteins or genes. Our model involves a two-stage training process optimized
for robust circadian phase prediction: an initial greedy one-layer-at-a-time
pre-training which generates informative initial parameters followed by
fine-tuning. During fine-tuning, a specialized loss function guides the model
to align protein expression levels with circadian patterns, enabling it to
accurately capture the underlying rhythmic structure within the data. We tested
our method on both time-labeled and unlabeled proteomic data. For labeled data,
we compared our predictions to the known time labels, achieving high accuracy,
while for unlabeled human datasets, including postmortem brain regions and
urine samples, we explored circadian disruptions. Notably, our analysis
identified disruptions in rhythmic proteins between Alzheimer's disease and
control subjects across these samples.

摘要：生理時鐘調節著人類和動物的生理和行為。
儘管在理解這些生理時鐘和預測轉錄層級的生理時鐘階段方面已有進展，但從蛋白質組數據預測生理時鐘階段仍然難以捉摸。這個挑戰在很大程度上是由于蛋白質組數據集中時間標籤的稀缺性，這些數據集通常以小樣本量、高維度和顯著的噪聲為特徵。此外，現有的從轉錄組數據預測生理時鐘階段的方法通常依賴于已知節律基因的先驗知識，這使得它們不適合用于蛋白質組數據集。為了解決這個差距，我們開發了一種新穎的計算方法，使用無監督深度學習技術從蛋白質組數據中預測生理時鐘樣本階段，而不需要時間標籤或對蛋白質或基因的先驗知識。我們的模型涉及一個兩階段的訓練過程，針對穩健的生理時鐘階段預測進行了優化：一個初始的貪婪的逐層預訓練，它生成信息豐富的初始參數，然後進行微調。在微調過程中，一個專門的損失函數引導模型將蛋白質表達水平與生理時鐘模式對齊，使其能夠準確地捕捉數據中的底層節律結構。我們在帶時間標籤和不帶時間標籤的蛋白質組數據上測試了我們的模型。對於帶標籤的數據，我們將我們的預測與已知的時間標籤進行比較，取得了很高的準確性，而對於不帶標籤的人類數據集，包括驗屍腦區和尿液樣本，我們探索了生理時鐘的紊亂。值得注意的是，我們的分析發現了阿爾茨海默病和這些樣本中的對照受試者之間節律蛋白的紊亂。

##### **Enhancing Retrieval-Augmented Generation: A Study of Best Practices**
2501.07391v1 by Siran Li, Linus Stenzel, Carsten Eickhoff, Seyed Ali Bahrainian

Retrieval-Augmented Generation (RAG) systems have recently shown remarkable
advancements by integrating retrieval mechanisms into language models,
enhancing their ability to produce more accurate and contextually relevant
responses. However, the influence of various components and configurations
within RAG systems remains underexplored. A comprehensive understanding of
these elements is essential for tailoring RAG systems to complex retrieval
tasks and ensuring optimal performance across diverse applications. In this
paper, we develop several advanced RAG system designs that incorporate query
expansion, various novel retrieval strategies, and a novel Contrastive
In-Context Learning RAG. Our study systematically investigates key factors,
including language model size, prompt design, document chunk size, knowledge
base size, retrieval stride, query expansion techniques, Contrastive In-Context
Learning knowledge bases, multilingual knowledge bases, and Focus Mode
retrieving relevant context at sentence-level. Through extensive
experimentation, we provide a detailed analysis of how these factors influence
response quality. Our findings offer actionable insights for developing RAG
systems, striking a balance between contextual richness and
retrieval-generation efficiency, thereby paving the way for more adaptable and
high-performing RAG frameworks in diverse real-world scenarios. Our code and
implementation details are publicly available.

摘要：檢索增強生成（RAG）系統最近透過將檢索機制整合到語言模型中，展現了顯著的進展，提升了它們產生更準確且與脈絡相關回應的能力。然而，各種元件和配置在 RAG 系統中的影響仍未獲得充分探討。全面了解這些元素對於調整 RAG 系統以符合複雜的檢索任務，並確保在各種應用中達到最佳效能至關重要。在本文中，我們開發了幾個進階的 RAG 系統設計，納入了查詢擴充、各種新穎的檢索策略，以及一個新穎的對比式脈絡學習 RAG。我們的研究系統性地探討了關鍵因素，包括語言模型大小、提示設計、文件區塊大小、知識庫大小、檢索步幅、查詢擴充技術、對比式脈絡學習知識庫、多語言知識庫，以及在句子層級檢索相關脈絡的焦點模式。透過廣泛的實驗，我們提供了這些因素如何影響回應品質的詳細分析。我們的研究結果為開發 RAG 系統提供了可操作的見解，在脈絡豐富性和檢索產生效率之間取得平衡，從而為在各種真實世界場景中更具適應性和高性能的 RAG 框架鋪平道路。我們的程式碼和實作細節公開提供。

##### **Emergent effects of scaling on the functional hierarchies within large language models**
2501.07359v1 by Paul C. Bogdan

Large language model (LLM) architectures are often described as functionally
hierarchical: Early layers process syntax, middle layers begin to parse
semantics, and late layers integrate information. The present work revisits
these ideas. This research submits simple texts to an LLM (e.g., "A church and
organ") and extracts the resulting activations. Then, for each layer, support
vector machines and ridge regressions are fit to predict a text's label and
thus examine whether a given layer encodes some information. Analyses using a
small model (Llama-3.2-3b; 28 layers) partly bolster the common hierarchical
perspective: Item-level semantics are most strongly represented early (layers
2-7), then two-item relations (layers 8-12), and then four-item analogies
(layers 10-15). Afterward, the representation of items and simple relations
gradually decreases in deeper layers that focus on more global information.
However, several findings run counter to a steady hierarchy view: First,
although deep layers can represent document-wide abstractions, deep layers also
compress information from early portions of the context window without
meaningful abstraction. Second, when examining a larger model
(Llama-3.3-70b-Instruct), stark fluctuations in abstraction level appear: As
depth increases, two-item relations and four-item analogies initially increase
in their representation, then markedly decrease, and afterward increase again
momentarily. This peculiar pattern consistently emerges across several
experiments. Third, another emergent effect of scaling is coordination between
the attention mechanisms of adjacent layers. Across multiple experiments using
the larger model, adjacent layers fluctuate between what information they each
specialize in representing. In sum, an abstraction hierarchy often manifests
across layers, but large models also deviate from this structure in curious
ways.

摘要：大型語言模型 (LLM) 架構通常被描述為功能分層：早期層處理語法，中間層開始解析語義，晚期層整合資訊。本研究重新探討這些想法。本研究將簡單文字提交給 LLM（例如，「一間教堂和管風琴」），並萃取產生的活化。然後，對於每個層，支援向量機和嶺迴歸適用於預測文字標籤，並進而檢視特定層是否編碼某些資訊。使用小型模型（Llama-3.2-3b；28 層）的分析部分支持常見的分層觀點：項目層級語義在早期（層 2-7）最有力地被表示，然後是兩個項目的關係（層 8-12），然後是四個項目的類比（層 10-15）。之後，項目和簡單關係的表示在較深層逐漸減少，這些層專注於更多全球資訊。然而，一些發現與穩定的階層觀點相反：首先，儘管深層可以表示文件範圍的抽象，但深層也會壓縮來自內容視窗早期部分的資訊，而沒有有意義的抽象。其次，在檢視較大的模型（Llama-3.3-70b-Instruct）時，抽象層級出現明顯的波動：隨著深度的增加，兩個項目的關係和四個項目的類比最初在它們的表示中增加，然後顯著減少，之後又再次增加。這種奇特的模式在多個實驗中持續出現。第三，規模化的另一個新興效應是相鄰層的注意力機制之間的協調。在使用較大模型的多次實驗中，相鄰層在它們各自專門表示的資訊之間波動。總之，抽象階層通常在各層中表現出來，但大型模型也會以奇特的方式偏離這個結構。

##### **TempoGPT: Enhancing Temporal Reasoning via Quantizing Embedding**
2501.07335v1 by Haochuan Zhang, Chunhua Yang, Jie Han, Liyang Qin, Xiaoli Wang

Multi-modal language model has made advanced progress in vision and audio,
but still faces significant challenges in dealing with complex reasoning tasks
in the time series domain. The reasons are twofold. First, labels for
multi-modal time series data are coarse and devoid of analysis or reasoning
processes. Training with these data cannot improve the model's reasoning
capabilities. Second, due to the lack of precise tokenization in processing
time series, the representation patterns for temporal and textual information
are inconsistent, which hampers the effectiveness of multi-modal alignment. To
address these challenges, we propose a multi-modal time series data
construction approach and a multi-modal time series language model (TLM),
TempoGPT. Specially, we construct multi-modal data for complex reasoning tasks
by analyzing the variable-system relationships within a white-box system.
Additionally, proposed TempoGPT achieves consistent representation between
temporal and textual information by quantizing temporal embeddings, where
temporal embeddings are quantized into a series of discrete tokens using a
predefined codebook; subsequently, a shared embedding layer processes both
temporal and textual tokens. Extensive experiments demonstrate that TempoGPT
accurately perceives temporal information, logically infers conclusions, and
achieves state-of-the-art in the constructed complex time series reasoning
tasks. Moreover, we quantitatively demonstrate the effectiveness of quantizing
temporal embeddings in enhancing multi-modal alignment and the reasoning
capabilities of TLMs. Code and data are available at
https://github.com/zhanghaochuan20/TempoGPT.

摘要：<paragraph>多模态语言模型在视觉和音频方面取得了长足的进步，
但在处理时间序列域中的复杂推理任务时仍面临着严峻的挑战。原因有二。首先，
多模态时间序列数据的标签粗糙，且缺乏分析或推理
过程。使用这些数据进行训练无法提高模型的推理
能力。其次，由于在处理中缺乏精确的标记化
时间序列，时间和文本信息的表示模式不一致，这阻碍了多模态对齐的有效性。为了
应对这些挑战，我们提出了一种多模态时间序列数据
构建方法和一种多模态时间序列语言模型 (TLM)，
TempoGPT。特别地，我们通过分析白盒系统中的变量系统关系来构建复杂推理任务的多模态数据。
此外，提出的 TempoGPT 通过量化时间嵌入实现了时间和文本信息之间的一致表示，其中
时间嵌入使用预定义的代码簿被量化为一系列离散标记；随后，一个共享嵌入层处理
时间和文本标记。大量的实验表明，TempoGPT
准确地感知时间信息，合乎逻辑地推断结论，并在构建的复杂时间序列推理中达到最先进的水平
任务。此外，我们定量证明了量化时间嵌入在增强多模态对齐和 TLM 的推理能力方面的有效性。代码和数据可在
https://github.com/zhanghaochuan20/TempoGPT.</paragraph>

##### **Anonymization of Documents for Law Enforcement with Machine Learning**
2501.07334v1 by Manuel Eberhardinger, Patrick Takenaka, Daniel Grießhaber, Johannes Maucher

The steadily increasing utilization of data-driven methods and approaches in
areas that handle sensitive personal information such as in law enforcement
mandates an ever increasing effort in these institutions to comply with data
protection guidelines. In this work, we present a system for automatically
anonymizing images of scanned documents, reducing manual effort while ensuring
data protection compliance. Our method considers the viability of further
forensic processing after anonymization by minimizing automatically redacted
areas by combining automatic detection of sensitive regions with knowledge from
a manually anonymized reference document. Using a self-supervised image model
for instance retrieval of the reference document, our approach requires only
one anonymized example to efficiently redact all documents of the same type,
significantly reducing processing time. We show that our approach outperforms
both a purely automatic redaction system and also a naive copy-paste scheme of
the reference anonymization to other documents on a hand-crafted dataset of
ground truth redactions.

摘要：隨著資料驅動方法和做法在處理敏感個人資訊（例如執法）等領域的利用率穩定提升，這些機構必須更加努力才能符合資料保護方針。在本文中，我們提出一個系統，可自動匿名化掃描文件影像，減少手動工作量，同時確保符合資料保護規定。我們的做法考量匿名化後進一步進行鑑識處理的可行性，方法是結合自動偵測敏感區域以及從手動匿名化參考文件獲得的知識，將自動塗黑區域減至最低。我們的做法使用自監督影像模型來擷取參考文件的實例，因此只需要一個匿名化範例就能有效塗黑同類型文件，大幅減少處理時間。我們證明我們的做法優於純自動塗黑系統，也優於將參考文件匿名化後天真地複製貼上至其他文件的做法，方法是在手工打造的真實塗黑資料集上進行測試。

##### **Joint Automatic Speech Recognition And Structure Learning For Better Speech Understanding**
2501.07329v1 by Jiliang Hu, Zuchao Li, Mengjia Shen, Haojun Ai, Sheng Li, Jun Zhang

Spoken language understanding (SLU) is a structure prediction task in the
field of speech. Recently, many works on SLU that treat it as a
sequence-to-sequence task have achieved great success. However, This method is
not suitable for simultaneous speech recognition and understanding. In this
paper, we propose a joint speech recognition and structure learning framework
(JSRSL), an end-to-end SLU model based on span, which can accurately transcribe
speech and extract structured content simultaneously. We conduct experiments on
name entity recognition and intent classification using the Chinese dataset
AISHELL-NER and the English dataset SLURP. The results show that our proposed
method not only outperforms the traditional sequence-to-sequence method in both
transcription and extraction capabilities but also achieves state-of-the-art
performance on the two datasets.

摘要：口語理解 (SLU) 是語音領域中的結構預測任務。最近，許多將 SLU 視為序列對序列任務的研究都取得了巨大的成功。然而，此方法不適用於同時進行語音識別和理解。在本文中，我們提出了一個聯合語音識別和結構學習框架 (JSRSL)，這是一個基於 span 的端到端 SLU 模型，可以準確地轉錄語音並同時提取結構化內容。我們使用中文數據集 AISHELL-NER 和英文數據集 SLURP 進行了命名實體識別和意圖分類的實驗。結果表明，我們提出的方法不僅在轉錄和提取能力方面都優於傳統的序列對序列方法，而且在兩個數據集上都達到了最先進的性能。

##### **Evaluation of Artificial Intelligence Methods for Lead Time Prediction in Non-Cycled Areas of Automotive Production**
2501.07317v1 by Cornelius Hake, Jonas Weigele, Frederik Reichert, Christian Friedrich

The present study examines the effectiveness of applying Artificial
Intelligence methods in an automotive production environment to predict unknown
lead times in a non-cycle-controlled production area. Data structures are
analyzed to identify contextual features and then preprocessed using one-hot
encoding. Methods selection focuses on supervised machine learning techniques.
In supervised learning methods, regression and classification methods are
evaluated. Continuous regression based on target size distribution is not
feasible. Classification methods analysis shows that Ensemble Learning and
Support Vector Machines are the most suitable. Preliminary study results
indicate that gradient boosting algorithms LightGBM, XGBoost, and CatBoost
yield the best results. After further testing and extensive hyperparameter
optimization, the final method choice is the LightGBM algorithm. Depending on
feature availability and prediction interval granularity, relative prediction
accuracies of up to 90% can be achieved. Further tests highlight the importance
of periodic retraining of AI models to accurately represent complex production
processes using the database. The research demonstrates that AI methods can be
effectively applied to highly variable production data, adding business value
by providing an additional metric for various control tasks while outperforming
current non AI-based systems.

摘要：本研究探討了在汽車生產環境中應用人工智慧方法的有效性，以預測非循環控制生產區域中未知的前置時間。分析數據結構以識別情境特徵，然後使用獨熱編碼進行預處理。方法選擇著重於監督式機器學習技術。在監督式學習方法中，評估回歸和分類方法。基於目標大小分佈的連續回歸不可行。分類方法分析表明，集成學習和支持向量機是最合適的。初步研究結果表明，梯度提升演算法 LightGBM、XGBoost 和 CatBoost 產生了最佳結果。經過進一步測試和廣泛的超參數最佳化後，最終方法選擇是 LightGBM 演算法。根據特徵可用性和預測區間粒度，可以實現高達 90% 的相對預測準確度。進一步的測試強調了定期重新訓練 AI 模型以準確表示使用資料庫的複雜生產流程的重要性。研究表明，AI 方法可以有效地應用於高度變化的生產資料，透過提供各種控制任務的額外指標，同時優於當前非 AI 系統，從而增加業務價值。

##### **FinerWeb-10BT: Refining Web Data with LLM-Based Line-Level Filtering**
2501.07314v1 by Erik Henriksson, Otto Tarkka, Filip Ginter

Data quality is crucial for training Large Language Models (LLMs).
Traditional heuristic filters often miss low-quality text or mistakenly remove
valuable content. In this paper, we introduce an LLM-based line-level filtering
method to enhance training data quality. We use GPT-4o mini to label a
20,000-document sample from FineWeb at the line level, allowing the model to
create descriptive labels for low-quality lines. These labels are grouped into
nine main categories, and we train a DeBERTa-v3 classifier to scale the
filtering to a 10B-token subset of FineWeb. To test the impact of our
filtering, we train GPT-2 models on both the original and the filtered
datasets. The results show that models trained on the filtered data achieve
higher accuracy on the HellaSwag benchmark and reach their performance targets
faster, even with up to 25\% less data. This demonstrates that LLM-based
line-level filtering can significantly improve data quality and training
efficiency for LLMs. We release our quality-annotated dataset, FinerWeb-10BT,
and the codebase to support further work in this area.

摘要：資料品質對於訓練大型語言模型 (LLM) 至關重要。
傳統的啟發式篩選器常常會錯過低品質文字或錯誤地移除有價值的內容。在本文中，我們介紹了一種基於 LLM 的行級篩選方法，以增強訓練資料品質。我們使用 GPT-4o mini 在行級標記了來自 FineWeb 的 20,000 份文件範例，讓模型能為低品質行建立描述性標籤。這些標籤被分為九大類，我們訓練了一個 DeBERTa-v3 分類器，將篩選縮放到 FineWeb 的 10B-token 子集。為了測試我們篩選的影響，我們在原始資料集和篩選後的資料集上訓練了 GPT-2 模型。結果顯示，在篩選後的資料上訓練的模型在 HellaSwag 基準上獲得了更高的準確度，並更快地達到了效能目標，即使資料減少了 25%。這證明了基於 LLM 的行級篩選可以顯著改善資料品質，並提高 LLM 的訓練效率。我們釋出了我們品質註解的資料集 FinerWeb-10BT，以及程式碼庫，以支持此領域的後續工作。

##### **The Lessons of Developing Process Reward Models in Mathematical Reasoning**
2501.07301v1 by Zhenru Zhang, Chujie Zheng, Yangzhen Wu, Beichen Zhang, Runji Lin, Bowen Yu, Dayiheng Liu, Jingren Zhou, Junyang Lin

Process Reward Models (PRMs) emerge as a promising approach for process
supervision in mathematical reasoning of Large Language Models (LLMs), which
aim to identify and mitigate intermediate errors in the reasoning processes.
However, the development of effective PRMs faces significant challenges,
particularly in data annotation and evaluation methodologies. In this paper,
through extensive experiments, we demonstrate that commonly used Monte Carlo
(MC) estimation-based data synthesis for PRMs typically yields inferior
performance and generalization compared to LLM-as-a-judge and human annotation
methods. MC estimation relies on completion models to evaluate current-step
correctness, leading to inaccurate step verification. Furthermore, we identify
potential biases in conventional Best-of-N (BoN) evaluation strategies for
PRMs: (1) The unreliable policy models generate responses with correct answers
but flawed processes, leading to a misalignment between the evaluation criteria
of BoN and the PRM objectives of process verification. (2) The tolerance of
PRMs of such responses leads to inflated BoN scores. (3) Existing PRMs have a
significant proportion of minimum scores concentrated on the final answer
steps, revealing the shift from process to outcome-based assessment in BoN
Optimized PRMs. To address these challenges, we develop a consensus filtering
mechanism that effectively integrates MC estimation with LLM-as-a-judge and
advocates a more comprehensive evaluation framework that combines
response-level and step-level metrics. Based on the mechanisms, we
significantly improve both model performance and data efficiency in the BoN
evaluation and the step-wise error identification task. Finally, we release a
new state-of-the-art PRM that outperforms existing open-source alternatives and
provides practical guidelines for future research in building process
supervision models.

摘要：<paragraph>流程獎勵模型 (PRM) 是一種有前途的方法，用於大型語言模型 (LLM) 的數學推理中的流程監督，旨在識別和減輕推理過程中發生的中間錯誤。然而，有效 PRM 的開發面臨著重大的挑戰，特別是在數據標註和評估方法方面。在本文中，通過大量的實驗，我們證明了常用的基於蒙特卡羅 (MC) 估計的 PRM 數據合成通常會產生較差的性能和泛化性，而 LLM 作為評審和人工標註方法則不然。MC 估計依賴於完成功能模型來評估當前步驟的正確性，從而導致不準確的步驟驗證。此外，我們在傳統的 N 中最佳 (BoN) PRM 評估策略中發現了潛在偏差：(1) 不可靠的策略模型會產生具有正確答案但流程有缺陷的回應，從而導致 BoN 的評估標準與 PRM 的流程驗證目標之間出現偏差。(2) PRM 對此類回應的容忍度導致 BoN 分數被誇大。(3) 現有的 PRM 在最後的答案步驟中具有相當比例的最低分數，這揭示了 BoN 優化的 PRM 從流程評估向基於結果的評估的轉變。為了應對這些挑戰，我們開發了一種共識過濾機制，該機制有效地將 MC 估計與 LLM 作為評審相結合，並倡導一個更全面的評估框架，該框架結合了響應級別和步驟級別的指標。基於這些機制，我們顯著提高了 BoN 評估和逐步錯誤識別任務中的模型性能和數據效率。最後，我們發布了一個新的最先進的 PRM，其性能優於現有的開源替代方案，並為構建流程監督模型的未來研究提供了實用的指導。</paragraph>

##### **Comparative analysis of optical character recognition methods for Sámi texts from the National Library of Norway**
2501.07300v1 by Tita Enstad, Trond Trosterud, Marie Iversdatter Røsok, Yngvil Beyer, Marie Roald

Optical Character Recognition (OCR) is crucial to the National Library of
Norway's (NLN) digitisation process as it converts scanned documents into
machine-readable text. However, for the S\'ami documents in NLN's collection,
the OCR accuracy is insufficient. Given that OCR quality affects downstream
processes, evaluating and improving OCR for text written in S\'ami languages is
necessary to make these resources accessible. To address this need, this work
fine-tunes and evaluates three established OCR approaches, Transkribus,
Tesseract and TrOCR, for transcribing S\'ami texts from NLN's collection. Our
results show that Transkribus and TrOCR outperform Tesseract on this task,
while Tesseract achieves superior performance on an out-of-domain dataset.
Furthermore, we show that fine-tuning pre-trained models and supplementing
manual annotations with machine annotations and synthetic text images can yield
accurate OCR for S\'ami languages, even with a moderate amount of manually
annotated data.

摘要：光學字元辨識 (OCR) 對挪威國家圖書館 (NLN) 的數位化流程至關重要，因為它能將掃描文件轉換成機器可讀的文字。然而，對於 NLN 館藏中的薩米語文件，OCR 的準確度不足。考量到 OCR 品質會影響後續流程，因此評估和改善薩米語文字的 OCR 是必要的，才能讓這些資源易於取得。為了滿足這個需求，這項研究針對三種既有的 OCR 方法進行微調和評估，分別是 Transkribus、Tesseract 和 TrOCR，用於轉錄 NLN 館藏的薩米語文字。我們的結果顯示，針對這項任務，Transkribus 和 TrOCR 的表現優於 Tesseract，而 Tesseract 在非領域資料集上則有較佳的表現。此外，我們證明了微調預先訓練的模型，並用機器標註和合成文字影像補充手動標註，即使手動標註資料量適中，也能產生準確的薩米語 OCR。

##### **LLM-Net: Democratizing LLMs-as-a-Service through Blockchain-based Expert Networks**
2501.07288v1 by Zan-Kai Chong, Hiroyuki Ohsaki, Bryan Ng

The centralization of Large Language Models (LLMs) development has created
significant barriers to AI advancement, limiting the democratization of these
powerful technologies. This centralization, coupled with the scarcity of
high-quality training data and mounting complexity of maintaining comprehensive
expertise across rapidly expanding knowledge domains, poses critical challenges
to the continued growth of LLMs. While solutions like Retrieval-Augmented
Generation (RAG) offer potential remedies, maintaining up-to-date expert
knowledge across diverse domains remains a significant challenge, particularly
given the exponential growth of specialized information. This paper introduces
LLMs Networks (LLM-Net), a blockchain-based framework that democratizes
LLMs-as-a-Service through a decentralized network of specialized LLM providers.
By leveraging collective computational resources and distributed domain
expertise, LLM-Net incorporates fine-tuned expert models for various specific
domains, ensuring sustained knowledge growth while maintaining service quality
through collaborative prompting mechanisms. The framework's robust design
includes blockchain technology for transparent transaction and performance
validation, establishing an immutable record of service delivery. Our
simulation, built on top of state-of-the-art LLMs such as Claude 3.5 Sonnet,
Llama 3.1, Grok-2, and GPT-4o, validates the effectiveness of the
reputation-based mechanism in maintaining service quality by selecting
high-performing respondents (LLM providers). Thereby it demonstrates the
potential of LLM-Net to sustain AI advancement through the integration of
decentralized expertise and blockchain-based accountability.

摘要：大型語言模型 (LLM) 開發的集中化已為 AI 進展製造了重大的障礙，限制了這些強大技術的民主化。這種集中化，加上高品質訓練資料的稀缺以及跨快速擴展的知識領域維護全面專業知識的複雜性，對 LLM 的持續成長造成重大的挑戰。雖然像檢索增強生成 (RAG) 等解決方案提供了潛在的補救措施，但跨不同領域維護最新的專家知識仍然是一項重大挑戰，特別是考慮到專業資訊的指數級成長。本文介紹了 LLM 網路 (LLM-Net)，一個基於區塊鏈的框架，透過分散的專業 LLM 提供者網路將 LLM-as-a-Service 民主化。透過利用集體的運算資源和分散的領域專業知識，LLM-Net 結合了針對各種特定領域微調的專家模型，確保持續的知識成長，同時透過協作提示機制維持服務品質。此框架的強健設計包含區塊鏈技術，用於透明的事務和效能驗證，建立不可變的服務交付記錄。我們的模擬建立在最先進的 LLM 之上，例如 Claude 3.5 Sonnet、Llama 3.1、Grok-2 和 GPT-4o，驗證了基於信譽的機制在維持服務品質方面的有效性，方法是選出表現良好的回應者 (LLM 提供者)。因此，它展示了 LLM-Net 透過整合分散的專業知識和基於區塊鏈的問責制來維持 AI 進展的潛力。

##### **Lifelong Learning of Large Language Model based Agents: A Roadmap**
2501.07278v1 by Junhao Zheng, Chengming Shi, Xidi Cai, Qiuke Li, Duzhen Zhang, Chenxing Li, Dong Yu, Qianli Ma

Lifelong learning, also known as continual or incremental learning, is a
crucial component for advancing Artificial General Intelligence (AGI) by
enabling systems to continuously adapt in dynamic environments. While large
language models (LLMs) have demonstrated impressive capabilities in natural
language processing, existing LLM agents are typically designed for static
systems and lack the ability to adapt over time in response to new challenges.
This survey is the first to systematically summarize the potential techniques
for incorporating lifelong learning into LLM-based agents. We categorize the
core components of these agents into three modules: the perception module for
multimodal input integration, the memory module for storing and retrieving
evolving knowledge, and the action module for grounded interactions with the
dynamic environment. We highlight how these pillars collectively enable
continuous adaptation, mitigate catastrophic forgetting, and improve long-term
performance. This survey provides a roadmap for researchers and practitioners
working to develop lifelong learning capabilities in LLM agents, offering
insights into emerging trends, evaluation metrics, and application scenarios.
Relevant literature and resources are available at \href{this
url}{https://github.com/qianlima-lab/awesome-lifelong-llm-agent}.

摘要：終身學習，也稱為持續或增量學習，是通過使系統能夠在動態環境中持續適應來推進人工通用智慧 (AGI) 的關鍵組成部分。雖然大型語言模型 (LLM) 在自然語言處理中展示了令人印象深刻的能力，但現有的 LLM 代理通常設計用於靜態系統，並且缺乏隨著時間推移適應新挑戰的能力。這項調查首次系統性地總結了將終身學習整合到基於 LLM 的代理中的潛在技術。我們將這些代理的核心組成部分分類為三個模組：用於多模式輸入整合的感知模組、用於儲存和檢索不斷演變的知識的記憶體模組，以及用於與動態環境進行基礎互動的動作模組。我們強調這些支柱如何共同實現持續適應、減輕災難性遺忘症，並提高長期效能。這項調查為致力於開發 LLM 代理中的終身學習能力的研究人員和從業人員提供了路線圖，提供了對新興趨勢、評估指標和應用場景的見解。相關文獻和資源可在 \href{this
url}{https://github.com/qianlima-lab/awesome-lifelong-llm-agent} 中找到。

##### **Bridging Smart Meter Gaps: A Benchmark of Statistical, Machine Learning and Time Series Foundation Models for Data Imputation**
2501.07276v1 by Amir Sartipi, Joaquin Delgado Fernandez, Sergio Potenciano Menci, Alessio Magitteri

The integrity of time series data in smart grids is often compromised by
missing values due to sensor failures, transmission errors, or disruptions.
Gaps in smart meter data can bias consumption analyses and hinder reliable
predictions, causing technical and economic inefficiencies. As smart meter data
grows in volume and complexity, conventional techniques struggle with its
nonlinear and nonstationary patterns. In this context, Generative Artificial
Intelligence offers promising solutions that may outperform traditional
statistical methods. In this paper, we evaluate two general-purpose Large
Language Models and five Time Series Foundation Models for smart meter data
imputation, comparing them with conventional Machine Learning and statistical
models. We introduce artificial gaps (30 minutes to one day) into an anonymized
public dataset to test inference capabilities. Results show that Time Series
Foundation Models, with their contextual understanding and pattern recognition,
could significantly enhance imputation accuracy in certain cases. However, the
trade-off between computational cost and performance gains remains a critical
consideration.

摘要：智慧電網中時間序列資料的完整性經常因感測器故障、傳輸錯誤或中斷而受到影響。
智慧電表資料的缺口會造成消耗分析的偏差，並阻礙可靠的預測，導致技術和經濟上的低效率。隨著智慧電表資料的數量和複雜性增加，傳統的技術難以應付其非線性和非平穩模式。在此背景下，生成式人工智慧提供了有望超越傳統統計方法的解決方案。在本文中，我們評估了兩個通用的大型語言模型和五個時序基礎模型，用於智慧電表資料填補，並將它們與傳統的機器學習和統計模型進行比較。我們在匿名公開資料集中引入了人工缺口（30 分鐘至一天），以測試推論能力。結果顯示，時序基礎模型具備情境理解和模式識別能力，在某些情況下可以顯著提高填補準確度。然而，計算成本和效能提升之間的權衡仍然是一個重要的考量因素。

##### **Skip Mamba Diffusion for Monocular 3D Semantic Scene Completion**
2501.07260v1 by Li Liang, Naveed Akhtar, Jordan Vice, Xiangrui Kong, Ajmal Saeed Mian

3D semantic scene completion is critical for multiple downstream tasks in
autonomous systems. It estimates missing geometric and semantic information in
the acquired scene data. Due to the challenging real-world conditions, this
task usually demands complex models that process multi-modal data to achieve
acceptable performance. We propose a unique neural model, leveraging advances
from the state space and diffusion generative modeling to achieve remarkable 3D
semantic scene completion performance with monocular image input. Our technique
processes the data in the conditioned latent space of a variational autoencoder
where diffusion modeling is carried out with an innovative state space
technique. A key component of our neural network is the proposed Skimba (Skip
Mamba) denoiser, which is adept at efficiently processing long-sequence data.
The Skimba diffusion model is integral to our 3D scene completion network,
incorporating a triple Mamba structure, dimensional decomposition residuals and
varying dilations along three directions. We also adopt a variant of this
network for the subsequent semantic segmentation stage of our method. Extensive
evaluation on the standard SemanticKITTI and SSCBench-KITTI360 datasets show
that our approach not only outperforms other monocular techniques by a large
margin, it also achieves competitive performance against stereo methods. The
code is available at https://github.com/xrkong/skimba

摘要：3D 語意場景完成對於自主系統中的多個下游任務至關重要。它估計獲取的場景資料中遺失的幾何和語意資訊。由於具有挑戰性的真實世界條件，此任務通常需要處理多模式資料的複雜模型才能達到可接受的效能。我們提出了一個獨特的類神經網路模型，利用狀態空間和擴散生成模型的進展，以單眼影像輸入實現卓越的 3D 語意場景完成效能。我們的技術在變異自動編碼器的條件潛在空間中處理資料，其中擴散建模是使用創新的狀態空間技術進行的。我們的神經網路的一個關鍵組成部分是提出的 Skimba（Skip Mamba）去噪器，它擅長有效處理長序列資料。Skimba 擴散模型是我們 3D 場景完成網路中不可或缺的一部分，它結合了三重 Mamba 結構、維度分解殘差和沿三個方向的不同膨脹。我們也採用此網路的一個變體作為我們方法後續的語意分割階段。在標準 SemanticKITTI 和 SSCBench-KITTI360 資料集上的廣泛評估顯示，我們的做法不僅大幅優於其他單眼技術，而且還實現了與立體方法競爭的效能。程式碼可在 https://github.com/xrkong/skimba 取得

##### **Audio-CoT: Exploring Chain-of-Thought Reasoning in Large Audio Language Model**
2501.07246v1 by Ziyang Ma, Zhuo Chen, Yuping Wang, Eng Siong Chng, Xie Chen

Large Audio-Language Models (LALMs) have demonstrated remarkable performance
in tasks involving audio perception and understanding, such as speech
recognition and audio captioning. However, their reasoning capabilities -
critical for solving complex real-world problems - remain underexplored. In
this work, we conduct the first exploration into integrating Chain-of-Thought
(CoT) reasoning into LALMs to enhance their reasoning ability across auditory
modalities. We evaluate representative CoT methods, analyzing their performance
in both information extraction and reasoning tasks across sound, music, and
speech domains. Our findings reveal that CoT methods significantly improve
performance on easy and medium tasks but encounter challenges with hard tasks,
where reasoning chains can confuse the model rather than improve accuracy.
Additionally, we identify a positive correlation between reasoning path length
and accuracy, demonstrating the potential of scaling inference for advanced
instruction-following and reasoning. This study not only highlights the promise
of CoT in enhancing LALM reasoning capabilities but also identifies key
limitations and provides actionable directions for future research.

摘要：大型語言音訊模型 (LALM) 在涉及音訊感知和理解的任務中展現出顯著的效能，例如語音辨識和音訊標題。然而，它們的推理能力對於解決複雜的現實世界問題至關重要，但仍未得到充分的探討。在這項工作中，我們進行了首次探索，將思考鏈 (CoT) 推理整合到 LALM 中，以增強它們跨聽覺模式的推理能力。我們評估了具有代表性的 CoT 方法，分析了它們在聲音、音樂和語音領域的信息提取和推理任務中的表現。我們的研究結果表明，CoT 方法顯著改善了簡單和中等任務的表現，但在困難的任務中遇到了挑戰，在這些任務中，推理鏈會混淆模型，而不是提高準確性。此外，我們發現推理路徑長度和準確性之間存在正相關，這證明了擴展推理以進行高級指令遵循和推理的潛力。這項研究不僅強調了 CoT 在增強 LALM 推理能力方面的潛力，還指出了關鍵限制，並為未來的研究提供了可行的方向。

##### **Can Vision-Language Models Evaluate Handwritten Math?**
2501.07244v1 by Oikantik Nath, Hanani Bathina, Mohammed Safi Ur Rahman Khan, Mitesh M. Khapra

Recent advancements in Vision-Language Models (VLMs) have opened new
possibilities in automatic grading of handwritten student responses,
particularly in mathematics. However, a comprehensive study to test the ability
of VLMs to evaluate and reason over handwritten content remains absent. To
address this gap, we introduce FERMAT, a benchmark designed to assess the
ability of VLMs to detect, localize and correct errors in handwritten
mathematical content. FERMAT spans four key error dimensions - computational,
conceptual, notational, and presentation - and comprises over 2,200 handwritten
math solutions derived from 609 manually curated problems from grades 7-12 with
intentionally introduced perturbations. Using FERMAT we benchmark nine VLMs
across three tasks: error detection, localization, and correction. Our results
reveal significant shortcomings in current VLMs in reasoning over handwritten
text, with Gemini-1.5-Pro achieving the highest error correction rate (77%). We
also observed that some models struggle with processing handwritten content, as
their accuracy improves when handwritten inputs are replaced with printed text
or images. These findings highlight the limitations of current VLMs and reveal
new avenues for improvement. We release FERMAT and all the associated resources
in the open-source to drive further research.

摘要：近期在視覺語言模型 (VLM) 的進展為手寫學生作業的自動評分開啟了新的可能性，特別是在數學領域。然而，仍缺乏一項全面的研究來測試 VLM 評估和推理手寫內容的能力。為了解決這個差距，我們引入了 FERMAT，一個基準測試，旨在評估 VLM 偵測、定位和修正手寫數學內容錯誤的能力。FERMAT 涵蓋了四個主要的錯誤面向：計算、概念、符號和呈現，並包含超過 2,200 個手寫數學解答，這些解答來自 609 個 7-12 年級的手動策劃問題，並故意引入了擾動。我們使用 FERMAT 對九個 VLM 進行了三個任務的基準測試：錯誤偵測、定位和修正。我們的結果揭示了當前 VLM 在推理手寫文本方面存在顯著的缺點，其中 Gemini-1.5-Pro 達到了最高的錯誤修正率 (77%)。我們還觀察到，一些模型在處理手寫內容時會遇到困難，因為當手寫輸入被印刷文字或圖像取代時，它們的準確度會提高。這些發現突顯了當前 VLM 的限制，並揭示了改進的新途徑。我們發布了 FERMAT 和所有相關資源，以推動進一步的研究。

##### **Lessons From Red Teaming 100 Generative AI Products**
2501.07238v1 by Blake Bullwinkel, Amanda Minnich, Shiven Chawla, Gary Lopez, Martin Pouliot, Whitney Maxwell, Joris de Gruyter, Katherine Pratt, Saphir Qi, Nina Chikanov, Roman Lutz, Raja Sekhar Rao Dheekonda, Bolor-Erdene Jagdagdorj, Eugenia Kim, Justin Song, Keegan Hines, Daniel Jones, Giorgio Severi, Richard Lundeen, Sam Vaughan, Victoria Westerhoff, Pete Bryan, Ram Shankar Siva Kumar, Yonatan Zunger, Chang Kawaguchi, Mark Russinovich

In recent years, AI red teaming has emerged as a practice for probing the
safety and security of generative AI systems. Due to the nascency of the field,
there are many open questions about how red teaming operations should be
conducted. Based on our experience red teaming over 100 generative AI products
at Microsoft, we present our internal threat model ontology and eight main
lessons we have learned:
  1. Understand what the system can do and where it is applied
  2. You don't have to compute gradients to break an AI system
  3. AI red teaming is not safety benchmarking
  4. Automation can help cover more of the risk landscape
  5. The human element of AI red teaming is crucial
  6. Responsible AI harms are pervasive but difficult to measure
  7. LLMs amplify existing security risks and introduce new ones
  8. The work of securing AI systems will never be complete
  By sharing these insights alongside case studies from our operations, we
offer practical recommendations aimed at aligning red teaming efforts with real
world risks. We also highlight aspects of AI red teaming that we believe are
often misunderstood and discuss open questions for the field to consider.

摘要：近年來，AI 紅隊已成為探測生成式 AI 系統安全性的實務。由於該領域尚處於初期階段，因此關於如何執行紅隊操作，仍有許多未解問題。根據我們在 Microsoft 對超過 100 個生成式 AI 產品進行紅隊測試的經驗，我們提出了我們的內部威脅模型本體論和我們學到的八個主要教訓：
1. 了解系統能做什麼以及它在哪裡應用
2. 您不必計算梯度就能破解 AI 系統
3. AI 紅隊測試並非安全基準測試
4. 自動化有助於涵蓋更多風險情況
5. AI 紅隊測試的人為因素至關重要
6. 負責任的 AI 危害普遍存在，但難以衡量
7. LLM 放大了現有的安全風險，並引入了新的風險
8. 保護 AI 系統的工作永遠不會完成
透過分享這些見解以及我們運作的案例研究，我們提供了實用的建議，旨在將紅隊測試工作與實際風險相結合。我們也強調了我們認為常被誤解的 AI 紅隊測試面向，並討論了該領域應考慮的未解問題。

##### **Breaking Memory Limits: Gradient Wavelet Transform Enhances LLMs Training**
2501.07237v1 by Ziqing Wen, Ping Luo, Jiahuan Wang, Xiaoge Deng, Jinping Zou, Kun Yuan, Tao Sun, Dongsheng Li

Large language models (LLMs) have shown impressive performance across a range
of natural language processing tasks. However, their vast number of parameters
introduces significant memory challenges during training, particularly when
using memory-intensive optimizers like Adam. Existing memory-efficient
algorithms often rely on techniques such as singular value decomposition
projection or weight freezing. While these approaches help alleviate memory
constraints, they generally produce suboptimal results compared to full-rank
updates. In this paper, we investigate the memory-efficient method beyond
low-rank training, proposing a novel solution called Gradient Wavelet Transform
(GWT), which applies wavelet transforms to gradients in order to significantly
reduce the memory requirements for maintaining optimizer states. We demonstrate
that GWT can be seamlessly integrated with memory-intensive optimizers,
enabling efficient training without sacrificing performance. Through extensive
experiments on both pre-training and fine-tuning tasks, we show that GWT
achieves state-of-the-art performance compared with advanced memory-efficient
optimizers and full-rank approaches in terms of both memory usage and training
performance.

摘要：大型語言模型 (LLM) 在各種自然語言處理任務中展現出令人印象深刻的效能。然而，它們龐大的參數數量在訓練過程中會造成顯著的記憶體挑戰，特別是在使用像 Adam 這種耗費大量記憶體的最佳化器時。現有的記憶體高效演算法通常仰賴奇異值分解投影或權重凍結等技術。雖然這些方法有助於減輕記憶體限制，但與全秩更新相比，它們通常會產生次佳的結果。在本文中，我們探討了超越低秩訓練的記憶體高效方法，提出了一種稱為梯度小波轉換 (GWT) 的創新解決方案，它將小波轉換應用於梯度，以大幅降低維護最佳化器狀態所需的記憶體。我們證明了 GWT 可以與耗費大量記憶體的最佳化器無縫整合，在不犧牲效能的情況下實現高效訓練。透過在預訓練和微調任務上進行廣泛的實驗，我們展示了 GWT 在記憶體使用和訓練效能方面，與先進的記憶體高效最佳化器和全秩方法相比，達到了最先進的效能。

##### **Exploring the Use of Contrastive Language-Image Pre-Training for Human Posture Classification: Insights from Yoga Pose Analysis**
2501.07221v1 by Andrzej D. Dobrzycki, Ana M. Bernardos, Luca Bergesio, Andrzej Pomirski, Daniel Sáez-Trigueros

Accurate human posture classification in images and videos is crucial for
automated applications across various fields, including work safety, physical
rehabilitation, sports training, or daily assisted living. Recently, multimodal
learning methods, such as Contrastive Language-Image Pretraining (CLIP), have
advanced significantly in jointly understanding images and text. This study
aims to assess the effectiveness of CLIP in classifying human postures,
focusing on its application in yoga. Despite the initial limitations of the
zero-shot approach, applying transfer learning on 15,301 images (real and
synthetic) with 82 classes has shown promising results. The article describes
the full procedure for fine-tuning, including the choice for image description
syntax, models and hyperparameters adjustment. The fine-tuned CLIP model,
tested on 3826 images, achieves an accuracy of over 85%, surpassing the current
state-of-the-art of previous works on the same dataset by approximately 6%, its
training time being 3.5 times lower than what is needed to fine-tune a
YOLOv8-based model. For more application-oriented scenarios, with smaller
datasets of six postures each, containing 1301 and 401 training images, the
fine-tuned models attain an accuracy of 98.8% and 99.1%, respectively.
Furthermore, our experiments indicate that training with as few as 20 images
per pose can yield around 90% accuracy in a six-class dataset. This study
demonstrates that this multimodal technique can be effectively used for yoga
pose classification, and possibly for human posture classification, in general.
Additionally, CLIP inference time (around 7 ms) supports that the model can be
integrated into automated systems for posture evaluation, e.g., for developing
a real-time personal yoga assistant for performance assessment.

摘要：在图像和视频中准确地对人体姿势进行分类对于各个领域的自动化应用程序至关重要，包括工作安全、身体康复、体育训练或日常辅助生活。最近，多模态学习方法（如对比语言图像预训练 (CLIP)）在联合理解图像和文本方面取得了显著进展。本研究旨在评估 CLIP 在人体姿势分类中的有效性，重点关注其在瑜伽中的应用。尽管零样本学习方法最初存在局限性，但对 15,301 张图像（真实和合成）应用迁移学习，并使用 82 个类别，已显示出有希望的结果。本文描述了微调的完整过程，包括图像描述语法、模型和超参数调整的选择。经过微调的 CLIP 模型在 3826 张图像上进行测试，准确率超过 85%，比以前在同一数据集上进行的研究的当前最先进水平高出约 6%，其训练时间比微调基于 YOLOv8 的模型所需时间低 3.5 倍。对于更面向应用程序的场景，每个姿势的数据集较小，各包含 1301 张和 401 张训练图像，微调后的模型分别达到 98.8% 和 99.1% 的准确率。此外，我们的实验表明，每个姿势仅使用 20 张图像进行训练，在六类数据集中的准确率可达到约 90%。本研究表明，这种多模态技术可有效用于瑜伽姿势分类，甚至可用于一般的人体姿势分类。此外，CLIP 推断时间（约 7 毫秒）支持将该模型集成到姿势评估的自动化系统中，例如，用于开发用于性能评估的实时个人瑜伽助手。

##### **When lies are mostly truthful: automated verbal deception detection for embedded lies**
2501.07217v1 by Riccardo Loconte, Bennett Kleinberg

Background: Verbal deception detection research relies on narratives and
commonly assumes statements as truthful or deceptive. A more realistic
perspective acknowledges that the veracity of statements exists on a continuum
with truthful and deceptive parts being embedded within the same statement.
However, research on embedded lies has been lagging behind. Methods: We
collected a novel dataset of 2,088 truthful and deceptive statements with
annotated embedded lies. Using a within-subjects design, participants provided
a truthful account of an autobiographical event. They then rewrote their
statement in a deceptive manner by including embedded lies, which they
highlighted afterwards and judged on lie centrality, deceptiveness, and source.
Results: We show that a fined-tuned language model (Llama-3-8B) can classify
truthful statements and those containing embedded lies with 64% accuracy.
Individual differences, linguistic properties and explainability analysis
suggest that the challenge of moving the dial towards embedded lies stems from
their resemblance to truthful statements. Typical deceptive statements
consisted of 2/3 truthful information and 1/3 embedded lies, largely derived
from past personal experiences and with minimal linguistic differences with
their truthful counterparts. Conclusion: We present this dataset as a novel
resource to address this challenge and foster research on embedded lies in
verbal deception detection.

摘要：背景：言語欺騙偵測研究依賴於敘事，並且通常假設陳述是真實或欺騙性的。一個更實際的觀點承認陳述的真實性存在於一個連續統上，其中真實和欺騙的部分被嵌入在同一個陳述中。然而，對於嵌入式謊言的研究一直落後。方法：我們收集了一個新穎的數據集，其中包含 2,088 個真實和欺騙性的陳述，並註釋了嵌入式謊言。參與者使用受試者內設計，提供了自傳事件的真實描述。然後，他們通過包含嵌入式謊言以欺騙的方式改寫他們的陳述，他們隨後強調並判斷謊言的中心性、欺騙性和來源。結果：我們表明，微調語言模型 (Llama-3-8B) 可以對真實陳述和包含嵌入式謊言的陳述進行分類，準確率為 64%。個體差異、語言特性和可解釋性分析表明，將刻度盤轉向嵌入式謊言的挑戰源於它們與真實陳述的相似性。典型的欺騙性陳述包含 2/3 的真實信息和 1/3 的嵌入式謊言，這些謊言主要來自過去的個人經歷，並且與其真實對應項在語言上幾乎沒有差異。結論：我們將此數據集作為一種新穎的資源，以應對這一挑戰，並促進對言語欺騙偵測中嵌入式謊言的研究。

##### **Multi-face emotion detection for effective Human-Robot Interaction**
2501.07213v1 by Mohamed Ala Yahyaoui, Mouaad Oujabour, Leila Ben Letaifa, Amine Bohi

The integration of dialogue interfaces in mobile devices has become
ubiquitous, providing a wide array of services. As technology progresses,
humanoid robots designed with human-like features to interact effectively with
people are gaining prominence, and the use of advanced human-robot dialogue
interfaces is continually expanding. In this context, emotion recognition plays
a crucial role in enhancing human-robot interaction by enabling robots to
understand human intentions. This research proposes a facial emotion detection
interface integrated into a mobile humanoid robot, capable of displaying
real-time emotions from multiple individuals on a user interface. To this end,
various deep neural network models for facial expression recognition were
developed and evaluated under consistent computer-based conditions, yielding
promising results. Afterwards, a trade-off between accuracy and memory
footprint was carefully considered to effectively implement this application on
a mobile humanoid robot.

摘要：對話式介面整合在行動裝置中已變得無所不在，提供廣泛的服務。隨著技術進步，具備類人特徵以有效與人互動的人形機器人正日益普及，而進階的人機對話式介面的使用也不斷擴展。在此背景下，情緒辨識在提升人機互動中扮演著關鍵角色，讓機器人能夠理解人類意圖。本研究提出一個整合在行動人形機器人中的臉部情緒偵測介面，能夠在使用者介面上即時顯示多位個體的情緒。為此，開發了各種深度神經網路模型用於臉部表情辨識，並在一致的電腦環境下進行評估，獲得了有前景的結果。之後，仔細考量了準確度和記憶體佔用空間的權衡，以在行動人形機器人上有效實作此應用程式。

##### **Generalizable Graph Neural Networks for Robust Power Grid Topology Control**
2501.07186v1 by Matthijs de Jong, Jan Viebahn, Yuliya Shapovalova

The energy transition necessitates new congestion management methods. One
such method is controlling the grid topology with machine learning (ML). This
approach has gained popularity following the Learning to Run a Power Network
(L2RPN) competitions. Graph neural networks (GNNs) are a class of ML models
that reflect graph structure in their computation, which makes them suitable
for power grid modeling. Various GNN approaches for topology control have thus
been proposed. We propose the first GNN model for grid topology control that
uses only GNN layers. Additionally, we identify the busbar information
asymmetry problem that the popular homogeneous graph representation suffers
from, and propose a heterogeneous graph representation to resolve it. We train
both homogeneous and heterogeneous GNNs and fully connected neural networks
(FCNN) baselines on an imitation learning task. We evaluate the models
according to their classification accuracy and grid operation ability. We find
that the heterogeneous GNNs perform best on in-distribution networks, followed
by the FCNNs, and lastly, the homogeneous GNNs. We also find that both GNN
types generalize better to out-of-distribution networks than FCNNs.

摘要：能源轉型需要新的壅塞管理方法。一種這樣的做法是使用機器學習 (ML) 控制電網拓撲。這種方法在學習運行電力網路 (L2RPN) 競賽後獲得普及。圖形神經網路 (GNN) 是一類 ML 模型，其在運算中反映圖形結構，這使得它們適用於電力網路建模。因此，已經提出各種用於拓撲控制的 GNN 方法。我們提出了第一個僅使用 GNN 層進行電網拓撲控制的 GNN 模型。此外，我們找出流行的同質圖形表示法所遭受的母線資訊不對稱問題，並提出異質圖形表示法來解決它。我們在模仿學習任務中訓練同質和異質 GNN 以及全連接神經網路 (FCNN) 基準。我們根據模型的分類準確度和電網操作能力對模型進行評估。我們發現，異質 GNN 在分佈內網路中表現最佳，其次是 FCNN，最後是同質 GNN。我們還發現，與 FCNN 相比，兩種 GNN 類型都能更好地推廣到分佈外網路。

##### **Kriging and Gaussian Process Interpolation for Georeferenced Data Augmentation**
2501.07183v1 by Frédérick Fabre Ferber, Dominique Gay, Jean-Christophe Soulié, Jean Diatta, Odalric-Ambrym Maillard

Data augmentation is a crucial step in the development of robust supervised
learning models, especially when dealing with limited datasets. This study
explores interpolation techniques for the augmentation of geo-referenced data,
with the aim of predicting the presence of Commelina benghalensis L. in
sugarcane plots in La R{\'e}union. Given the spatial nature of the data and the
high cost of data collection, we evaluated two interpolation approaches:
Gaussian processes (GPs) with different kernels and kriging with various
variograms. The objectives of this work are threefold: (i) to identify which
interpolation methods offer the best predictive performance for various
regression algorithms, (ii) to analyze the evolution of performance as a
function of the number of observations added, and (iii) to assess the spatial
consistency of augmented datasets. The results show that GP-based methods, in
particular with combined kernels (GP-COMB), significantly improve the
performance of regression algorithms while requiring less additional data.
Although kriging shows slightly lower performance, it is distinguished by a
more homogeneous spatial coverage, a potential advantage in certain contexts.

摘要：資料擴充是穩健監督學習模型開發中至關重要的一步，特別是在處理有限資料集時。本研究探討了地理參考資料擴充的內插技術，目的是預測留尼旺甘蔗田中的孟加拉鳶尾花 L. 的存在。鑑於資料的空間性質和資料收集的高成本，我們評估了兩種內插方法：具有不同核心的高斯過程 (GP) 和具有不同變異函數組的克里金法。這項工作的目標有三方面：(i) 找出哪種內插方法為各種回歸演算法提供最佳預測效能，(ii) 分析效能隨著新增觀測數的演變，以及 (iii) 評估擴充資料集的空間一致性。結果顯示，基於 GP 的方法，特別是具有組合核心的方法 (GP-COMB)，顯著提升了回歸演算法的效能，同時需要較少額外資料。儘管克里金法顯示出稍低的效能，但其特點是空間覆蓋範圍更均勻，在某些情況下可能是一個優勢。

##### **BIOMEDICA: An Open Biomedical Image-Caption Archive, Dataset, and Vision-Language Models Derived from Scientific Literature**
2501.07171v1 by Alejandro Lozano, Min Woo Sun, James Burgess, Liangyu Chen, Jeffrey J Nirschl, Jeffrey Gu, Ivan Lopez, Josiah Aklilu, Austin Wolfgang Katzer, Collin Chiu, Anita Rau, Xiaohan Wang, Yuhui Zhang, Alfred Seunghoon Song, Robert Tibshirani, Serena Yeung-Levy

The development of vision-language models (VLMs) is driven by large-scale and
diverse multimodal datasets. However, progress toward generalist biomedical
VLMs is limited by the lack of annotated, publicly accessible datasets across
biology and medicine. Existing efforts are restricted to narrow domains,
missing the full diversity of biomedical knowledge encoded in scientific
literature. To address this gap, we introduce BIOMEDICA, a scalable,
open-source framework to extract, annotate, and serialize the entirety of the
PubMed Central Open Access subset into an easy-to-use, publicly accessible
dataset.Our framework produces a comprehensive archive with over 24 million
unique image-text pairs from over 6 million articles. Metadata and
expert-guided annotations are also provided. We demonstrate the utility and
accessibility of our resource by releasing BMCA-CLIP, a suite of CLIP-style
models continuously pre-trained on the BIOMEDICA dataset via streaming,
eliminating the need to download 27 TB of data locally.On average, our models
achieve state-of-the-art performance across 40 tasks - spanning pathology,
radiology, ophthalmology, dermatology, surgery, molecular biology,
parasitology, and cell biology - excelling in zero-shot classification with a
6.56% average improvement (as high as 29.8% and 17.5% in dermatology and
ophthalmology, respectively), and stronger image-text retrieval, all while
using 10x less compute. To foster reproducibility and collaboration, we release
our codebase and dataset for the broader research community.

摘要：<paragraph>視覺語言模型 (VLM) 的發展是由大規模且多元的多模態資料集推動的。然而，由於缺乏在生物學和醫學領域中註解且公開存取的資料集，因此限制了通用生物醫學 VLM 的進展。現有的努力僅限於狹窄的領域，錯失了科學文獻中編碼的生物醫學知識的全部多樣性。為了解決這個差距，我們引入了 BIOMEDICA，這是一個可擴充、開放原始碼的架構，用於擷取、註解和序列化 PubMed Central 開放取用子集，並將其轉換成易於使用且公開存取的資料集。我們的架構產生了一個全面的檔案庫，其中包含來自 600 多萬篇文章的 2400 多萬個獨特的影像文字對。也提供了元資料和專家指導的註解。我們透過釋出 BMCA-CLIP 來展示我們資源的實用性和可存取性，這是一套 CLIP 風格的模型，透過串流連續預先訓練於 BIOMEDICA 資料集，消除了在本地下載 27 TB 資料的需求。平均而言，我們的模型在 40 項任務中達到了最先進的效能，涵蓋了病理學、放射學、眼科、皮膚科、外科、分子生物學、寄生蟲學和細胞生物學，在零次分類中表現出色，平均提升了 6.56%（分別在皮膚科和眼科中高達 29.8% 和 17.5%），並增強了影像文字檢索，同時使用少 10 倍的運算。為了促進可複製性和協作，我們針對更廣泛的研究社群釋出了我們的程式碼庫和資料集。</paragraph>

##### **Natural Language-Assisted Multi-modal Medication Recommendation**
2501.07166v1 by Jie Tan, Yu Rong, Kangfei Zhao, Tian Bian, Tingyang Xu, Junzhou Huang, Hong Cheng, Helen Meng

Combinatorial medication recommendation(CMR) is a fundamental task of
healthcare, which offers opportunities for clinical physicians to provide more
precise prescriptions for patients with intricate health conditions,
particularly in the scenarios of long-term medical care. Previous research
efforts have sought to extract meaningful information from electronic health
records (EHRs) to facilitate combinatorial medication recommendations. Existing
learning-based approaches further consider the chemical structures of
medications, but ignore the textual medication descriptions in which the
functionalities are clearly described. Furthermore, the textual knowledge
derived from the EHRs of patients remains largely underutilized. To address
these issues, we introduce the Natural Language-Assisted Multi-modal Medication
Recommendation(NLA-MMR), a multi-modal alignment framework designed to learn
knowledge from the patient view and medication view jointly. Specifically,
NLA-MMR formulates CMR as an alignment problem from patient and medication
modalities. In this vein, we employ pretrained language models(PLMs) to extract
in-domain knowledge regarding patients and medications, serving as the
foundational representation for both modalities. In the medication modality, we
exploit both chemical structures and textual descriptions to create medication
representations. In the patient modality, we generate the patient
representations based on textual descriptions of diagnosis, procedure, and
symptom. Extensive experiments conducted on three publicly accessible datasets
demonstrate that NLA-MMR achieves new state-of-the-art performance, with a
notable average improvement of 4.72% in Jaccard score. Our source code is
publicly available on https://github.com/jtan1102/NLA-MMR_CIKM_2024.

摘要：組合式藥物推薦 (CMR) 是醫療保健的一項基本任務，它為臨床醫生提供了針對具有複雜健康狀況的患者提供更精確處方的機會，特別是在長期醫療保健的情況下。先前的研究工作試圖從電子健康記錄 (EHR) 中提取有意義的資訊，以促進組合式藥物推薦。現有的基於學習的方法進一步考慮了藥物的化學結構，但忽略了功能清楚描述於其中的文本藥物說明。此外，從患者的 EHR 中衍生的文本知識在很大程度上仍未得到充分利用。為了解決這些問題，我們引入了自然語言輔助多模式藥物推薦 (NLA-MMR)，這是一個多模式對齊框架，旨在從患者視角和藥物視角共同學習知識。具體來說，NLA-MMR 將 CMR 構建為患者和藥物模式的對齊問題。在此脈絡中，我們採用預訓練語言模型 (PLM) 來提取有關患者和藥物的領域內知識，作為這兩種模式的基本表示。在藥物模式中，我們利用化學結構和文本說明來建立藥物表示。在患者模式中，我們根據診斷、程序和症狀的文字說明來生成患者表示。在三個公開存取的資料集上進行的廣泛實驗表明，NLA-MMR 達到了新的最先進效能，傑卡德指數平均改進了 4.72%。我們的原始碼公開於 https://github.com/jtan1102/NLA-MMR_CIKM_2024。

##### **QuantuneV2: Compiler-Based Local Metric-Driven Mixed Precision Quantization for Practical Embedded AI Applications**
2501.07161v1 by Jeongseok Kim, Jemin Lee, Yongin Kwon, Daeyoung Kim

Mixed-precision quantization methods have been proposed to reduce model size
while minimizing accuracy degradation. However, existing studies require
retraining and do not consider the computational overhead and intermediate
representations (IR) generated during the compilation process, limiting their
application at the compiler level. This computational overhead refers to the
runtime latency caused by frequent quantization and dequantization operations
during inference. Performing these operations at the individual operator level
causes significant runtime delays. To address these issues, we propose
QuantuneV2, a compiler-based mixed-precision quantization method designed for
practical embedded AI applications. QuantuneV2 performs inference only twice,
once before quantization and once after quantization, and operates with a
computational complexity of O(n) that increases linearly with the number of
model parameters. We also made the sensitivity analysis more stable by using
local metrics like weights, activation values, the Signal to Quantization Noise
Ratio, and the Mean Squared Error. We also cut down on computational overhead
by choosing the best IR and using operator fusion. Experimental results show
that QuantuneV2 achieved up to a 10.28 percent improvement in accuracy and a
12.52 percent increase in speed compared to existing methods across five
models: ResNet18v1, ResNet50v1, SqueezeNetv1, VGGNet, and MobileNetv2. This
demonstrates that QuantuneV2 enhances model performance while maintaining
computational efficiency, making it suitable for deployment in embedded AI
environments.

摘要：<paragraph>為了減小模型大小，同時將準確度下降降到最低，已提出混合精度量化方法。然而，現有研究需要重新訓練，而且沒有考慮編譯過程中產生的運算開銷和中間表示 (IR)，限制了它們在編譯器層級的應用。此運算開銷是指推論期間頻繁量化和反量化運算造成的執行時間延遲。在個別運算子層級執行這些運算會造成顯著的執行時間延遲。為了解決這些問題，我們提出 QuantuneV2，一種基於編譯器的混合精度量化方法，專為實用的嵌入式 AI 應用而設計。QuantuneV2 只執行兩次推論，一次在量化之前，一次在量化之後，並以 O(n) 的運算複雜度運作，該複雜度會隨著模型參數的數量線性增加。我們也透過使用權重、啟用值、訊號對量化雜訊比和均方誤差等局部指標，讓敏感度分析更穩定。我們也透過選擇最佳 IR 和使用運算子融合來減少運算開銷。實驗結果顯示，與現有方法相比，QuantuneV2 在五種模型中（ResNet18v1、ResNet50v1、SqueezeNetv1、VGGNet 和 MobileNetv2）的準確度提升了 10.28%，速度提升了 12.52%。這表示 QuantuneV2 提升了模型效能，同時維持運算效率，使其適合部署在嵌入式 AI 環境中。</paragraph>

##### **CureGraph: Contrastive Multi-Modal Graph Representation Learning for Urban Living Circle Health Profiling and Prediction**
2501.07157v1 by Jinlin Li, Xiao Zhou

The early detection and prediction of health status decline among the elderly
at the neighborhood level are of great significance for urban planning and
public health policymaking. While existing studies affirm the connection
between living environments and health outcomes, most rely on single data
modalities or simplistic feature concatenation of multi-modal information,
limiting their ability to comprehensively profile the health-oriented urban
environments. To fill this gap, we propose CureGraph, a contrastive multi-modal
representation learning framework for urban health prediction that employs
graph-based techniques to infer the prevalence of common chronic diseases among
the elderly within the urban living circles of each neighborhood. CureGraph
leverages rich multi-modal information, including photos and textual reviews of
residential areas and their surrounding points of interest, to generate urban
neighborhood embeddings. By integrating pre-trained visual and textual encoders
with graph modeling techniques, CureGraph captures cross-modal spatial
dependencies, offering a comprehensive understanding of urban environments
tailored to elderly health considerations. Extensive experiments on real-world
datasets demonstrate that CureGraph improves the best baseline by $28\%$ on
average in terms of $R^2$ across elderly disease risk prediction tasks.
Moreover, the model enables the identification of stage-wise chronic disease
progression and supports comparative public health analysis across
neighborhoods, offering actionable insights for sustainable urban development
and enhanced quality of life. The code is publicly available at
https://github.com/jinlin2021/CureGraph.

摘要：在鄰里層級早期偵測和預測老年人的健康狀況下降對城市規劃和公共衛生政策制定具有重大意義。儘管現有研究肯定了生活環境與健康結果之間的關聯性，但大多依賴單一資料模式或多模式資訊的簡化特徵串接，限制了他們全面描繪以健康為導向的城市環境的能力。為了填補這個差距，我們提出了 CureGraph，一個用於城市健康預測的對比式多模式表示學習架構，它採用基於圖形技術來推論每個鄰里城市生活圈中老年人常見慢性疾病的流行率。CureGraph 利用豐富的多模式資訊，包括住宅區及其周圍景點的照片和文字評論，來產生城市鄰里嵌入。透過整合預先訓練的視覺和文字編碼器與圖形建模技術，CureGraph 捕捉跨模式空間依賴性，提供對城市環境的全面理解，專門針對老年人的健康考量。在真實世界資料集上的廣泛實驗證明，CureGraph 在老年人疾病風險預測任務中，平均在 R2 方面將最佳基準線提高了 28%。此外，該模型能夠識別階段性的慢性疾病進程，並支援跨鄰里的比較公共衛生分析，為永續的城市發展和提升生活品質提供可行的見解。程式碼已公開於 https://github.com/jinlin2021/CureGraph。

##### **TIMRL: A Novel Meta-Reinforcement Learning Framework for Non-Stationary and Multi-Task Environments**
2501.07146v1 by Chenyang Qi, Huiping Li, Panfeng Huang

In recent years, meta-reinforcement learning (meta-RL) algorithm has been
proposed to improve sample efficiency in the field of decision-making and
control, enabling agents to learn new knowledge from a small number of samples.
However, most research uses the Gaussian distribution to extract task
representation, which is poorly adapted to tasks that change in non-stationary
environment. To address this problem, we propose a novel meta-reinforcement
learning method by leveraging Gaussian mixture model and the transformer
network to construct task inference model. The Gaussian mixture model is
utilized to extend the task representation and conduct explicit encoding of
tasks. Specifically, the classification of tasks is encoded through transformer
network to determine the Gaussian component corresponding to the task. By
leveraging task labels, the transformer network is trained using supervised
learning. We validate our method on MuJoCo benchmarks with non-stationary and
multi-task environments. Experimental results demonstrate that the proposed
method dramatically improves sample efficiency and accurately recognizes the
classification of the tasks, while performing excellently in the environment.

摘要：近年来，元强化学习（元 RL）算法被提出以提高决策和控制领域的样本效率，使智能体能够从小样本中学习新知识。然而，大多数研究使用高斯分布来提取任务表示，这很难适应在非平稳环境中发生变化的任务。为了解决这个问题，我们提出了一种新的元强化学习方法，通过利用高斯混合模型和 transformer 网络来构建任务推理模型。高斯混合模型用于扩展任务表示并对任务进行显式编码。具体来说，任务的分类通过 transformer 网络进行编码，以确定对应于任务的高斯分量。通过利用任务标签，transformer 网络使用监督学习进行训练。我们在具有非平稳和多任务环境的 MuJoCo 基准上验证了我们的方法。实验结果表明，所提出的方法极大地提高了样本效率，并准确识别了任务的分类，同时在环境中表现出色。

##### **FlexQuant: Elastic Quantization Framework for Locally Hosted LLM on Edge Devices**
2501.07139v1 by Yuji Chai, Mujin Kwen, David Brooks, Gu-Yeon Wei

Deploying LLMs on edge devices presents serious technical challenges. Memory
elasticity is crucial for edge devices with unified memory, where memory is
shared and fluctuates dynamically. Existing solutions suffer from either poor
transition granularity or high storage costs. We propose FlexQuant, a novel
elasticity framework that generates an ensemble of quantized models, providing
an elastic hosting solution with 15x granularity improvement and 10x storage
reduction compared to SoTA methods. FlexQuant works with most quantization
methods and creates a family of trade-off options under various storage limits
through our pruning method. It brings great performance and flexibility to the
edge deployment of LLMs.

摘要：在邊緣裝置上部署 LLM 會帶來嚴峻的技術挑戰。記憶體彈性對具備統一記憶體的邊緣裝置至關重要，其中記憶體會被共享並且動態波動。現有的解決方案不是轉換粒度差就是儲存成本高。我們提出 FlexQuant，一種創新的彈性架構，可產生量化模型的合奏，提供彈性託管解決方案，與 SoTA 方法相比，粒度提升 15 倍，儲存減少 10 倍。FlexQuant 可搭配大多數量化方法，並透過我們的修剪方法在各種儲存限制下建立一系列折衷選項。它為 LLM 的邊緣部署帶來極佳的效能和彈性。

##### **ListConRanker: A Contrastive Text Reranker with Listwise Encoding**
2501.07111v1 by Junlong Liu, Yue Ma, Ruihui Zhao, Junhao Zheng, Qianli Ma, Yangyang Kang

Reranker models aim to re-rank the passages based on the semantics similarity
between the given query and passages, which have recently received more
attention due to the wide application of the Retrieval-Augmented Generation.
Most previous methods apply pointwise encoding, meaning that it can only encode
the context of the query for each passage input into the model. However, for
the reranker model, given a query, the comparison results between passages are
even more important, which is called listwise encoding. Besides, previous
models are trained using the cross-entropy loss function, which leads to issues
of unsmooth gradient changes during training and low training efficiency. To
address these issues, we propose a novel Listwise-encoded Contrastive text
reRanker (ListConRanker). It can help the passage to be compared with other
passages during the encoding process, and enhance the contrastive information
between positive examples and between positive and negative examples. At the
same time, we use the circle loss to train the model to increase the
flexibility of gradients and solve the problem of training efficiency.
Experimental results show that ListConRanker achieves state-of-the-art
performance on the reranking benchmark of Chinese Massive Text Embedding
Benchmark, including the cMedQA1.0, cMedQA2.0, MMarcoReranking, and T2Reranking
datasets.

摘要：重新排序模型旨在根据给定查询和段落之间的语义相似性对段落进行重新排序，由于检索增强生成技术的广泛应用，该模型最近受到更多关注。
大多数先前的方法应用逐点编码，这意味着它只能对输入模型的每个段落的查询上下文进行编码。然而，对于重新排序模型，给定一个查询，段落之间的比较结果更为重要，这被称为列表编码。此外，先前的模型使用交叉熵损失函数进行训练，这会导致训练期间梯度变化不平滑和训练效率低的问题。为了解决这些问题，我们提出了一种新颖的列表编码对比文本重新排序器 (ListConRanker)。它可以帮助段落与其他段落进行比较在编码过程中，增强正例之间以及正例和反例之间的对比信息。同时，我们使用圆损失来训练模型以增加梯度的灵活性并解决训练效率问题。实验结果表明，ListConRanker 在中文海量文本嵌入基准的重新排序基准上实现了最先进的性能，包括 cMedQA1.0、cMedQA2.0、MMarcoReranking 和 T2Reranking 数据集。

##### **How GPT learns layer by layer**
2501.07108v1 by Jason Du, Kelly Hong, Alishba Imran, Erfan Jahanparast, Mehdi Khfifi, Kaichun Qiao

Large Language Models (LLMs) excel at tasks like language processing,
strategy games, and reasoning but struggle to build generalizable internal
representations essential for adaptive decision-making in agents. For agents to
effectively navigate complex environments, they must construct reliable world
models. While LLMs perform well on specific benchmarks, they often fail to
generalize, leading to brittle representations that limit their real-world
effectiveness. Understanding how LLMs build internal world models is key to
developing agents capable of consistent, adaptive behavior across tasks. We
analyze OthelloGPT, a GPT-based model trained on Othello gameplay, as a
controlled testbed for studying representation learning. Despite being trained
solely on next-token prediction with random valid moves, OthelloGPT shows
meaningful layer-wise progression in understanding board state and gameplay.
Early layers capture static attributes like board edges, while deeper layers
reflect dynamic tile changes. To interpret these representations, we compare
Sparse Autoencoders (SAEs) with linear probes, finding that SAEs offer more
robust, disentangled insights into compositional features, whereas linear
probes mainly detect features useful for classification. We use SAEs to decode
features related to tile color and tile stability, a previously unexamined
feature that reflects complex gameplay concepts like board control and
long-term planning. We study the progression of linear probe accuracy and tile
color using both SAE's and linear probes to compare their effectiveness at
capturing what the model is learning. Although we begin with a smaller language
model, OthelloGPT, this study establishes a framework for understanding the
internal representations learned by GPT models, transformers, and LLMs more
broadly. Our code is publicly available: https://github.com/ALT-JS/OthelloSAE.

摘要：大型語言模型 (LLM) 在語言處理、策略遊戲和推理等任務中表現出色，但難以建立可適應代理決策制定中不可或缺的概括性內部表徵。代理要有效地應對複雜的環境，他們必須建構可靠的世界模型。雖然 LLM 在特定基準上表現良好，但它們常常無法概括，導致脆弱的表徵，限制了它們在現實世界中的有效性。了解 LLM 如何建構內部世界模型是開發在各項任務中具有一致、適應性行為的代理的關鍵。我們分析了 OthelloGPT，一個基於 GPT 的模型，它接受奧賽羅遊戲訓練，作為研究表徵學習的受控測試平台。儘管僅接受隨機有效移動的下一代預測訓練，OthelloGPT 仍顯示出在理解棋盤狀態和遊戲玩法方面有意義的逐層進展。早期層次捕捉靜態屬性，如棋盤邊緣，而較深層次則反映動態圖塊變化。為了詮釋這些表徵，我們將稀疏自動編碼器 (SAE) 與線性探測進行比較，發現 SAE 提供了對組成特徵更強健、更解開的見解，而線性探測主要檢測對分類有用的特徵。我們使用 SAE 來解碼與圖塊顏色和圖塊穩定性相關的特徵，這是一個以前未經檢驗的特徵，它反映了複雜的遊戲概念，如棋盤控制和長期規劃。我們使用 SAE 和線性探測研究線性探測準確度和圖塊顏色的進展，以比較它們在捕捉模型學習內容方面的有效性。雖然我們從較小的語言模型 OthelloGPT 開始，但這項研究為理解 GPT 模型、Transformer和 LLM 更廣泛學習的內部表徵建立了一個框架。我們的程式碼公開可用：https://github.com/ALT-JS/OthelloSAE。

##### **AdaCS: Adaptive Normalization for Enhanced Code-Switching ASR**
2501.07102v1 by The Chuong Chu, Vu Tuan Dat Pham, Kien Dao, Hoang Nguyen, Quoc Hung Truong

Intra-sentential code-switching (CS) refers to the alternation between
languages that happens within a single utterance and is a significant challenge
for Automatic Speech Recognition (ASR) systems. For example, when a Vietnamese
speaker uses foreign proper names or specialized terms within their speech. ASR
systems often struggle to accurately transcribe intra-sentential CS due to
their training on monolingual data and the unpredictable nature of CS. This
issue is even more pronounced for low-resource languages, where limited data
availability hinders the development of robust models. In this study, we
propose AdaCS, a normalization model integrates an adaptive bias attention
module (BAM) into encoder-decoder network. This novel approach provides a
robust solution to CS ASR in unseen domains, thereby significantly enhancing
our contribution to the field. By utilizing BAM to both identify and normalize
CS phrases, AdaCS enhances its adaptive capabilities with a biased list of
words provided during inference. Our method demonstrates impressive performance
and the ability to handle unseen CS phrases across various domains. Experiments
show that AdaCS outperforms previous state-of-the-art method on Vietnamese CS
ASR normalization by considerable WER reduction of 56.2% and 36.8% on the two
proposed test sets.

摘要：句內碼轉換 (CS) 指在單一句話內交替使用語言，對自動語音辨識 (ASR) 系統來說是一項重大挑戰。例如，當越南語使用者在說話時使用外來專有名詞或專門術語。由於 ASR 系統訓練時使用的是單一語言資料，且 CS 的性質難以預測，因此 ASR 系統在準確轉錄句內 CS 時常會遇到困難。對於資源較少的語言來說，這個問題更為嚴重，因為資料有限，會阻礙穩健模型的開發。在本研究中，我們提出 AdaCS，一種正規化模型，將適應性偏差注意力模組 (BAM) 整合到編碼器解碼器網路中。這種新方法為未知領域的 CS ASR 提供了一個穩健的解決方案，進而大幅提升我們對這個領域的貢獻。AdaCS 利用 BAM 來辨識和正規化 CS 片語，並透過在推論期間提供的偏差詞彙清單，增強其適應性。我們的這項方法展現了令人印象深刻的效能，以及處理各種領域中未知 CS 片語的能力。實驗顯示，AdaCS 在越南語 CS ASR 正規化方面優於先前的最新方法，在兩個提議的測試集中，WER 分別降低了 56.2% 和 36.8%。

##### **Collaborative Learning for 3D Hand-Object Reconstruction and Compositional Action Recognition from Egocentric RGB Videos Using Superquadrics**
2501.07100v1 by Tze Ho Elden Tse, Runyang Feng, Linfang Zheng, Jiho Park, Yixing Gao, Jihie Kim, Ales Leonardis, Hyung Jin Chang

With the availability of egocentric 3D hand-object interaction datasets,
there is increasing interest in developing unified models for hand-object pose
estimation and action recognition. However, existing methods still struggle to
recognise seen actions on unseen objects due to the limitations in representing
object shape and movement using 3D bounding boxes. Additionally, the reliance
on object templates at test time limits their generalisability to unseen
objects. To address these challenges, we propose to leverage superquadrics as
an alternative 3D object representation to bounding boxes and demonstrate their
effectiveness on both template-free object reconstruction and action
recognition tasks. Moreover, as we find that pure appearance-based methods can
outperform the unified methods, the potential benefits from 3D geometric
information remain unclear. Therefore, we study the compositionality of actions
by considering a more challenging task where the training combinations of verbs
and nouns do not overlap with the testing split. We extend H2O and FPHA
datasets with compositional splits and design a novel collaborative learning
framework that can explicitly reason about the geometric relations between
hands and the manipulated object. Through extensive quantitative and
qualitative evaluations, we demonstrate significant improvements over the
state-of-the-arts in (compositional) action recognition.

摘要：隨著自我中心 3D 手部物件互動資料集的可用性，
開發統一模型以進行手部物件姿勢
估計和動作辨識的興趣與日俱增。然而，現有方法仍難以
辨識未見物件上的動作，原因在於使用 3D 邊界框表示
物件形狀和動作的限制。此外，在測試時間依賴物件範本
會限制其對未見物件的概括性。為了應對這些挑戰，我們提議
利用超二次曲面作為邊界框的替代 3D 物件表示，並證明其
在無範本物件重建和動作辨識任務上的有效性。此外，由於我們發現
純外觀方法可以優於統一方法，因此 3D 幾何
資訊的潛在好處仍不明確。因此，我們透過考慮一個更具挑戰性的任務來研究動作的組合性，其中動詞
和名詞的訓練組合不會與測試分割重疊。我們使用組合分割擴充 H2O 和 FPHA
資料集，並設計一個新穎的協作學習
架構，可以明確推論手部和被操作物件之間的幾何關係。透過廣泛的量化和
定性評估，我們證明了在（組合）動作辨識中，我們相較於現有技術有顯著的進步。

##### **MathReader : Text-to-Speech for Mathematical Documents**
2501.07088v1 by Sieun Hyeon, Kyudan Jung, Nam-Joon Kim, Hyun Gon Ryu, Jaeyoung Do

TTS (Text-to-Speech) document reader from Microsoft, Adobe, Apple, and OpenAI
have been serviced worldwide. They provide relatively good TTS results for
general plain text, but sometimes skip contents or provide unsatisfactory
results for mathematical expressions. This is because most modern academic
papers are written in LaTeX, and when LaTeX formulas are compiled, they are
rendered as distinctive text forms within the document. However, traditional
TTS document readers output only the text as it is recognized, without
considering the mathematical meaning of the formulas. To address this issue, we
propose MathReader, which effectively integrates OCR, a fine-tuned T5 model,
and TTS. MathReader demonstrated a lower Word Error Rate (WER) than existing
TTS document readers, such as Microsoft Edge and Adobe Acrobat, when processing
documents containing mathematical formulas. MathReader reduced the WER from
0.510 to 0.281 compared to Microsoft Edge, and from 0.617 to 0.281 compared to
Adobe Acrobat. This will significantly contribute to alleviating the
inconvenience faced by users who want to listen to documents, especially those
who are visually impaired. The code is available at
https://github.com/hyeonsieun/MathReader.

摘要：微軟、Adobe、蘋果和 OpenAI 的 TTS（文字轉語音）文件朗讀器已在全球提供服務。對於一般的純文字，它們提供相對良好的 TTS 結果，但有時會跳過內容或對於數學表達式提供不令人滿意的結果。這是因為大多數現代學術論文都是用 LaTeX 編寫的，當編譯 LaTeX 公式時，它們會在文件內呈現為獨特的文字形式。然而，傳統的 TTS 文件朗讀器只會輸出它所識別的文字，而不會考慮公式的數學含義。為了解決這個問題，我們提出了 MathReader，它有效地整合了 OCR、微調的 T5 模型和 TTS。在處理包含數學公式的文件時，MathReader 展示出比現有的 TTS 文件朗讀器（例如 Microsoft Edge 和 Adobe Acrobat）更低的字元錯誤率 (WER)。與 Microsoft Edge 相比，MathReader 將 WER 從 0.510 降低到 0.281，與 Adobe Acrobat 相比，將 WER 從 0.617 降低到 0.281。這將顯著有助於減輕想要聆聽文件（尤其是視障人士）的用戶所面臨的不便。程式碼可在 https://github.com/hyeonsieun/MathReader 取得。

##### **Video Quality Assessment for Online Processing: From Spatial to Temporal Sampling**
2501.07087v1 by Jiebin Yan, Lei Wu, Yuming Fang, Xuelin Liu, Xue Xia, Weide Liu

With the rapid development of multimedia processing and deep learning
technologies, especially in the field of video understanding, video quality
assessment (VQA) has achieved significant progress. Although researchers have
moved from designing efficient video quality mapping models to various research
directions, in-depth exploration of the effectiveness-efficiency trade-offs of
spatio-temporal modeling in VQA models is still less sufficient. Considering
the fact that videos have highly redundant information, this paper investigates
this problem from the perspective of joint spatial and temporal sampling,
aiming to seek the answer to how little information we should keep at least
when feeding videos into the VQA models while with acceptable performance
sacrifice. To this end, we drastically sample the video's information from both
spatial and temporal dimensions, and the heavily squeezed video is then fed
into a stable VQA model. Comprehensive experiments regarding joint spatial and
temporal sampling are conducted on six public video quality databases, and the
results demonstrate the acceptable performance of the VQA model when throwing
away most of the video information. Furthermore, with the proposed joint
spatial and temporal sampling strategy, we make an initial attempt to design an
online VQA model, which is instantiated by as simple as possible a spatial
feature extractor, a temporal feature fusion module, and a global quality
regression module. Through quantitative and qualitative experiments, we verify
the feasibility of online VQA model by simplifying itself and reducing input.

摘要：隨著多媒體處理和深度學習技術的快速發展，特別是在影片理解領域，影片品質評估 (VQA) 已取得顯著進展。儘管研究人員已從設計高效的影片品質對應模型轉向各項研究方向，但對於 VQA 模型中時空建模的效能效率權衡，深入探討仍顯不足。考量到影片具有高度冗餘資訊，本文從聯合時空採樣的觀點探討此問題，旨在找出在不影響影片品質下，將影片輸入 VQA 模型時，我們至少應保留多麼少的資訊。為此，我們大幅度地從時空維度採樣影片資訊，然後將大幅壓縮的影片輸入穩定的 VQA 模型。對於聯合時空採樣的全面實驗是在六個公開影片品質資料庫上進行，結果證明在捨棄大部分影片資訊的情況下，VQA 模型的效能仍可接受。此外，透過所提出的聯合時空採樣策略，我們初步嘗試設計一個線上 VQA 模型，其實例化方式盡可能簡單，包括一個時空特徵萃取器、一個時序特徵融合模組，以及一個全域品質回歸模組。透過量化和定性的實驗，我們驗證了簡化自身和減少輸入後，線上 VQA 模型的可行性。

##### **Boosting Text-To-Image Generation via Multilingual Prompting in Large Multimodal Models**
2501.07086v1 by Yongyu Mu, Hengyu Li, Junxin Wang, Xiaoxuan Zhou, Chenglong Wang, Yingfeng Luo, Qiaozhi He, Tong Xiao, Guocheng Chen, Jingbo Zhu

Previous work on augmenting large multimodal models (LMMs) for text-to-image
(T2I) generation has focused on enriching the input space of in-context
learning (ICL). This includes providing a few demonstrations and optimizing
image descriptions to be more detailed and logical. However, as demand for more
complex and flexible image descriptions grows, enhancing comprehension of input
text within the ICL paradigm remains a critical yet underexplored area. In this
work, we extend this line of research by constructing parallel multilingual
prompts aimed at harnessing the multilingual capabilities of LMMs. More
specifically, we translate the input text into several languages and provide
the models with both the original text and the translations. Experiments on two
LMMs across 3 benchmarks show that our method, PMT2I, achieves superior
performance in general, compositional, and fine-grained assessments, especially
in human preference alignment. Additionally, with its advantage of generating
more diverse images, PMT2I significantly outperforms baseline prompts when
incorporated with reranking methods. Our code and parallel multilingual data
can be found at https://github.com/takagi97/PMT2I.

摘要：先前的研究集中於擴充大型多模態模型 (LMM) 以進行文字轉影像 (T2I) 生成，重點在於豐富情境學習 (ICL) 的輸入空間。這包括提供一些示範和最佳化影像描述，使其更詳細且更具邏輯性。然而，隨著對更複雜且更靈活的影像描述的需求增加，在 ICL 典範中增強對輸入文字的理解仍然是一個關鍵但尚未充分探索的領域。在此研究中，我們透過建構平行多語言提示來擴展這條研究路線，旨在利用 LMM 的多語言能力。更具體地說，我們將輸入文字翻譯成多種語言，並向模型提供原始文字和翻譯。在 3 個基準上對兩個 LMM 進行的實驗顯示，我們的 PMT2I 方法在一般、構成和細緻的評估中都能獲得優異的效能，特別是在人類偏好對齊方面。此外，PMT2I 具有產生更多樣化影像的優勢，在與重新排序方法結合使用時，其效能顯著優於基線提示。我們的程式碼和平行多語言資料可以在 https://github.com/takagi97/PMT2I 找到。

##### **ADKGD: Anomaly Detection in Knowledge Graphs with Dual-Channel Training**
2501.07078v1 by Jiayang Wu, Wensheng Gan, Jiahao Zhang, Philip S. Yu

In the current development of large language models (LLMs), it is important
to ensure the accuracy and reliability of the underlying data sources. LLMs are
critical for various applications, but they often suffer from hallucinations
and inaccuracies due to knowledge gaps in the training data. Knowledge graphs
(KGs), as a powerful structural tool, could serve as a vital external
information source to mitigate the aforementioned issues. By providing a
structured and comprehensive understanding of real-world data, KGs enhance the
performance and reliability of LLMs. However, it is common that errors exist in
KGs while extracting triplets from unstructured data to construct KGs. This
could lead to degraded performance in downstream tasks such as
question-answering and recommender systems. Therefore, anomaly detection in KGs
is essential to identify and correct these errors. This paper presents an
anomaly detection algorithm in knowledge graphs with dual-channel learning
(ADKGD). ADKGD leverages a dual-channel learning approach to enhance
representation learning from both the entity-view and triplet-view
perspectives. Furthermore, using a cross-layer approach, our framework
integrates internal information aggregation and context information
aggregation. We introduce a kullback-leibler (KL)-loss component to improve the
accuracy of the scoring function between the dual channels. To evaluate ADKGD's
performance, we conduct empirical studies on three real-world KGs: WN18RR,
FB15K, and NELL-995. Experimental results demonstrate that ADKGD outperforms
the state-of-the-art anomaly detection algorithms. The source code and datasets
are publicly available at https://github.com/csjywu1/ADKGD.

摘要：<paragraph>在大語言模型（LLM）的當前發展中，確保基礎數據來源的準確性和可靠性非常重要。LLM 對於各種應用至關重要，但由於訓練數據中的知識差距，它們經常會出現幻覺和不準確的情況。知識圖譜 (KG) 作為一種強大的結構化工具，可以作為一個重要的外部信息來源，以減輕上述問題。通過提供對現實世界數據的結構化和全面理解，KG 提高了 LLM 的性能和可靠性。然而，在從非結構化數據中提取三元組以構建 KG 時，KG 中存在錯誤是很常見的。這可能會導致下游任務（例如問答和推薦系統）的性能下降。因此，KG 中的異常檢測對於識別和糾正這些錯誤至關重要。本文提出了一個具有雙通道學習的知識圖譜異常檢測算法 (ADKGD)。ADKGD 利用雙通道學習方法從實體視角和三元組視角增強表示學習。此外，我們的框架使用跨層方法整合了內部信息聚合和上下文信息聚合。我們引入了 Kullback-Leibler (KL) 損失組件，以提高雙通道之間評分函數的準確性。為了評估 ADKGD 的性能，我們對三個真實世界 KG：WN18RR、FB15K 和 NELL-995 進行了實證研究。實驗結果表明，ADKGD 優於最先進的異常檢測算法。源代碼和數據集可在 https://github.com/csjywu1/ADKGD 公開獲得。</paragraph>

##### **Representation Learning of Point Cloud Upsampling in Global and Local Inputs**
2501.07076v1 by Tongxu Zhang, Bei Wang

In recent years, point cloud upsampling has been widely applied in fields
such as 3D reconstruction. Our study investigates the factors influencing point
cloud upsampling on both global and local levels through representation
learning. Specifically, the paper inputs global and local information of the
same point cloud model object into two encoders to extract these features,
fuses them, and then feeds the combined features into an upsampling decoder.
The goal is to address issues of sparsity and noise in point clouds by
leveraging prior knowledge from both global and local inputs. And the proposed
framework can be applied to any state-of-the-art point cloud upsampling neural
network. Experiments were conducted on a series of autoencoder-based models
utilizing deep learning, yielding interpretability for both global and local
inputs, and it has been proven in the results that our proposed framework can
further improve the upsampling effect in previous SOTA works. At the same time,
the Saliency Map reflects the differences between global and local feature
inputs, as well as the effectiveness of training with both inputs in parallel.

摘要：近年来，点云上采样已广泛应用于3D重建等领域。我们的研究通过表示学习，调查了影响点云上采样在全局和局部层面的因素。具体来说，本文将同一点云模型对象的全局和局部信息输入到两个编码器中以提取这些特征，对其进行融合，然后将组合后的特征馈送到上采样解码器中。目标是通过利用来自全局和局部输入的先验知识来解决点云中的稀疏性和噪声问题。并且所提出的框架可以应用于任何最先进的点云上采样神经网络。在利用深度学习的一系列基于自动编码器的模型上进行了实验，对全局和局部输入产生了可解释性，并且在结果中已经证明，我们提出的框架可以进一步提高以前SOTA工作中的上采样效果。同时，显着性图反映了全局和局部特征输入之间的差异，以及同时使用这两个输入进行训练的有效性。

##### **Value Compass Leaderboard: A Platform for Fundamental and Validated Evaluation of LLMs Values**
2501.07071v1 by Jing Yao, Xiaoyuan Yi, Shitong Duan, Jindong Wang, Yuzhuo Bai, Muhua Huang, Peng Zhang, Tun Lu, Zhicheng Dou, Maosong Sun, Xing Xie

As Large Language Models (LLMs) achieve remarkable breakthroughs, aligning
their values with humans has become imperative for their responsible
development and customized applications. However, there still lack evaluations
of LLMs values that fulfill three desirable goals. (1) Value Clarification: We
expect to clarify the underlying values of LLMs precisely and comprehensively,
while current evaluations focus narrowly on safety risks such as bias and
toxicity. (2) Evaluation Validity: Existing static, open-source benchmarks are
prone to data contamination and quickly become obsolete as LLMs evolve.
Additionally, these discriminative evaluations uncover LLMs' knowledge about
values, rather than valid assessments of LLMs' behavioral conformity to values.
(3) Value Pluralism: The pluralistic nature of human values across individuals
and cultures is largely ignored in measuring LLMs value alignment. To address
these challenges, we presents the Value Compass Leaderboard, with three
correspondingly designed modules. It (i) grounds the evaluation on
motivationally distinct \textit{basic values to clarify LLMs' underlying values
from a holistic view; (ii) applies a \textit{generative evolving evaluation
framework with adaptive test items for evolving LLMs and direct value
recognition from behaviors in realistic scenarios; (iii) propose a metric that
quantifies LLMs alignment with a specific value as a weighted sum over multiple
dimensions, with weights determined by pluralistic values.

摘要：隨著大型語言模型 (LLM) 取得顯著突破，讓它們的價值觀與人類價值觀一致，對於它們負責任的開發和客製化應用已變得勢在必行。然而，目前仍缺乏符合三個理想目標的 LLM 價值觀評估。(1) 價值觀澄清：我們期望精確且全面地釐清 LLM 的基本價值觀，而目前的評估則狹隘地關注於偏見和毒性等安全風險。(2) 評估效度：現有的靜態開源基準容易受到資料污染，而且隨著 LLM 的演進而迅速過時。此外，這些區辨性評估揭露的是 LLM 對於價值觀的知識，而非對 LLM 行為是否符合價值觀的有效評估。(3) 價值觀多元性：在衡量 LLM 價值觀一致性時，很大程度上忽略了人類價值觀在個人和文化之間的多元性。為了應對這些挑戰，我們提出了價值指南排行榜，其中包含三個相應設計的模組。它 (i) 將評估建立在動機上截然不同的「基本價值觀」上，以全面釐清 LLM 的基本價值觀；(ii) 應用「生成式演化評估架構」，其中包含適應性測驗項目，用於評估演化的 LLM，並從實際情境中的行為直接辨識價值觀；(iii) 提出一個量化指標，將 LLM 與特定價值觀的一致性量化為多個面向的加權總和，而權重則由多元價值觀決定。

##### **Research on the Online Update Method for Retrieval-Augmented Generation (RAG) Model with Incremental Learning**
2501.07063v1 by Yuxin Fan, Yuxiang Wang, Lipeng Liu, Xirui Tang, Na Sun, Zidong Yu

In the contemporary context of rapid advancements in information technology
and the exponential growth of data volume, language models are confronted with
significant challenges in effectively navigating the dynamic and ever-evolving
information landscape to update and adapt to novel knowledge in real time. In
this work, an online update method is proposed, which is based on the existing
Retrieval Enhanced Generation (RAG) model with multiple innovation mechanisms.
Firstly, the dynamic memory is used to capture the emerging data samples, and
then gradually integrate them into the core model through a tunable knowledge
distillation strategy. At the same time, hierarchical indexing and multi-layer
gating mechanism are introduced into the retrieval module to ensure that the
retrieved content is more targeted and accurate. Finally, a multi-stage network
structure is established for different types of inputs in the generation stage,
and cross-attention matching and screening are carried out on the intermediate
representations of each stage to ensure the effective integration and iterative
update of new and old knowledge. Experimental results show that the proposed
method is better than the existing mainstream comparison models in terms of
knowledge retention and inference accuracy.

摘要：在信息技术飞速发展和数据量呈指数级增长的当代背景下，语言模型面临着在动态且不断演化的信息环境中有效导航以实时更新和适应新知识的重大挑战。在这项工作中，提出了一种在线更新方法，该方法基于现有的检索增强生成 (RAG) 模型，并具有多种创新机制。首先，使用动态存储器来捕获新兴的数据样本，然后通过可调谐知识蒸馏策略逐步将它们集成到核心模型中。同时，在检索模块中引入了分层索引和多层门控机制，以确保检索到的内容更有针对性和准确性。最后，为生成阶段的不同类型的输入建立了多阶段网络结构，并对每个阶段的中间表示进行交叉注意匹配和筛选，以确保新旧知识的有效集成和迭代更新。实验结果表明，所提出的方法在知识保留和推理准确性方面优于现有的主流比较模型。

##### **Logic Meets Magic: LLMs Cracking Smart Contract Vulnerabilities**
2501.07058v1 by ZeKe Xiao, Qin Wang, Hammond Pearce, Shiping Chen

Smart contract vulnerabilities caused significant economic losses in
blockchain applications. Large Language Models (LLMs) provide new possibilities
for addressing this time-consuming task. However, state-of-the-art LLM-based
detection solutions are often plagued by high false-positive rates.
  In this paper, we push the boundaries of existing research in two key ways.
First, our evaluation is based on Solidity v0.8, offering the most up-to-date
insights compared to prior studies that focus on older versions (v0.4). Second,
we leverage the latest five LLM models (across companies), ensuring
comprehensive coverage across the most advanced capabilities in the field.
  We conducted a series of rigorous evaluations. Our experiments demonstrate
that a well-designed prompt can reduce the false-positive rate by over 60%.
Surprisingly, we also discovered that the recall rate for detecting some
specific vulnerabilities in Solidity v0.8 has dropped to just 13% compared to
earlier versions (i.e., v0.4). Further analysis reveals the root cause of this
decline: the reliance of LLMs on identifying changes in newly introduced
libraries and frameworks during detection.

摘要：智慧合約漏洞會造成區塊鏈應用程式的重大經濟損失。大型語言模型 (LLM) 提供了應對這項耗時任務的新可能性。然而，最先進的基於 LLM 的偵測解決方案經常受到高偽陽性率的困擾。
  在本文中，我們從兩個關鍵方式推動現有研究的界限。
首先，我們的評估基於 Solidity v0.8，與專注於舊版本 (v0.4) 的先前研究相比，提供了最新的見解。其次，
我們運用來自各公司的最新五個 LLM 模型，確保涵蓋該領域最先進的能力。
  我們進行了一系列嚴謹的評估。我們的實驗證明，精心設計的提示可以將偽陽性率降低 60% 以上。
令人驚訝的是，我們還發現，與早期版本 (即 v0.4) 相比，偵測 Solidity v0.8 中某些特定漏洞的召回率已降至僅 13%。進一步的分析揭示了這種下降的根本原因：LLM 在偵測過程中依賴識別新引入的函式庫和架構中的變更。

##### **PoAct: Policy and Action Dual-Control Agent for Generalized Applications**
2501.07054v1 by Guozhi Yuan, Youfeng Liu, Jingli Yang, Wei Jia, Kai Lin, Yansong Gao, Shan He, Zilin Ding, Haitao Li

Based on their superior comprehension and reasoning capabilities, Large
Language Model (LLM) driven agent frameworks have achieved significant success
in numerous complex reasoning tasks. ReAct-like agents can solve various
intricate problems step-by-step through progressive planning and tool calls,
iteratively optimizing new steps based on environmental feedback. However, as
the planning capabilities of LLMs improve, the actions invoked by tool calls in
ReAct-like frameworks often misalign with complex planning and challenging data
organization. Code Action addresses these issues while also introducing the
challenges of a more complex action space and more difficult action
organization. To leverage Code Action and tackle the challenges of its
complexity, this paper proposes Policy and Action Dual-Control Agent (PoAct)
for generalized applications. The aim is to achieve higher-quality code actions
and more accurate reasoning paths by dynamically switching reasoning policies
and modifying the action space. Experimental results on the Agent Benchmark for
both legal and generic scenarios demonstrate the superior reasoning
capabilities and reduced token consumption of our approach in complex tasks. On
the LegalAgentBench, our method shows a 20 percent improvement over the
baseline while requiring fewer tokens. We conducted experiments and analyses on
the GPT-4o and GLM-4 series models, demonstrating the significant potential and
scalability of our approach to solve complex problems.

摘要：基於其卓越的理解和推理能力，大型語言模型 (LLM) 驅動的代理架構在許多複雜的推理任務中取得顯著的成功。類似 ReAct 的代理可以透過漸進式規劃和工具呼叫逐步解決各種複雜的問題，並根據環境回饋反覆最佳化新的步驟。然而，隨著 LLM 的規劃能力提升，類似 ReAct 架構中工具呼叫所引發的動作通常與複雜的規劃和具有挑戰性的資料組織不一致。Code Action 處理這些問題，同時也引入了更複雜的動作空間和更困難的動作組織的挑戰。為了善用 Code Action 並應對其複雜性的挑戰，本文提出政策和動作雙重控制代理 (PoAct)，用於廣泛的應用。目的是透過動態切換推理政策和修改動作空間來達成更高品質的程式碼動作和更準確的推理路徑。在法律和一般情境中，針對代理基準的實驗結果證明了我們的方法在複雜任務中卓越的推理能力和降低的代碼消耗。在 LegalAgentBench 上，我們的模型比基準線進步 20%，同時需要較少的代碼。我們對 GPT-4o 和 GLM-4 系列模型進行了實驗和分析，證明了我們的方法在解決複雜問題上具有的顯著潛力和可擴充性。

##### **Unveiling the Potential of Text in High-Dimensional Time Series Forecasting**
2501.07048v1 by Xin Zhou, Weiqing Wang, Shilin Qu, Zhiqiang Zhang, Christoph Bergmeir

Time series forecasting has traditionally focused on univariate and
multivariate numerical data, often overlooking the benefits of incorporating
multimodal information, particularly textual data. In this paper, we propose a
novel framework that integrates time series models with Large Language Models
to improve high-dimensional time series forecasting. Inspired by multimodal
models, our method combines time series and textual data in the dual-tower
structure. This fusion of information creates a comprehensive representation,
which is then processed through a linear layer to generate the final forecast.
Extensive experiments demonstrate that incorporating text enhances
high-dimensional time series forecasting performance. This work paves the way
for further research in multimodal time series forecasting.

摘要：時間序列預測傳統上專注於單變量和多變量數值數據，常常忽略整合多模態資訊，特別是文字數據的好處。在本文中，我們提出了一個新的框架，將時間序列模型與大型語言模型整合，以改善高維時間序列預測。受到多模態模型的啟發，我們的模型在雙塔結構中結合了時間序列和文字數據。這種資訊融合創造了一個全面的表示，然後透過線性層處理以產生最終預測。廣泛的實驗表明，整合文字可以增強高維時間序列預測的效能。這項工作為多模態時間序列預測的進一步研究鋪路。

##### **ACCon: Angle-Compensated Contrastive Regularizer for Deep Regression**
2501.07045v1 by Botao Zhao, Xiaoyang Qu, Zuheng Kang, Junqing Peng, Jing Xiao, Jianzong Wang

In deep regression, capturing the relationship among continuous labels in
feature space is a fundamental challenge that has attracted increasing
interest. Addressing this issue can prevent models from converging to
suboptimal solutions across various regression tasks, leading to improved
performance, especially for imbalanced regression and under limited sample
sizes. However, existing approaches often rely on order-aware representation
learning or distance-based weighting. In this paper, we hypothesize a linear
negative correlation between label distances and representation similarities in
regression tasks. To implement this, we propose an angle-compensated
contrastive regularizer for deep regression, which adjusts the cosine distance
between anchor and negative samples within the contrastive learning framework.
Our method offers a plug-and-play compatible solution that extends most
existing contrastive learning methods for regression tasks. Extensive
experiments and theoretical analysis demonstrate that our proposed
angle-compensated contrastive regularizer not only achieves competitive
regression performance but also excels in data efficiency and effectiveness on
imbalanced datasets.

摘要：在深度迴歸中，捕捉特徵空間中連續標籤間的關係是一項基本挑戰，且已引起越來越多的關注。解決此問題可以防止模型在各種迴歸任務中收斂至次佳解，從而提升效能，特別是在不平衡迴歸和樣本大小有限的情況下。然而，現有方法通常依賴於順序感知表示學習或基於距離的加權。在本文中，我們假設迴歸任務中標籤距離與表示相似性之間存在線性負相關。為實作這一點，我們提出了一個針對深度迴歸的角度補償對比正規化器，它調整對比學習架構中錨定和負樣本之間的餘弦距離。我們的模型提供了一個即插即用的相容解，可將大多數現有對比學習方法延伸至迴歸任務。廣泛的實驗和理論分析表明，我們提出的角度補償對比正規化器不僅可達成具競爭力的迴歸效能，還能提升不平衡資料集上的資料效率和有效性。

##### **A Proposed Large Language Model-Based Smart Search for Archive System**
2501.07024v1 by Ha Dung Nguyen, Thi-Hoang Anh Nguyen, Thanh Binh Nguyen

This study presents a novel framework for smart search in digital archival
systems, leveraging the capabilities of Large Language Models (LLMs) to enhance
information retrieval. By employing a Retrieval-Augmented Generation (RAG)
approach, the framework enables the processing of natural language queries and
transforming non-textual data into meaningful textual representations. The
system integrates advanced metadata generation techniques, a hybrid retrieval
mechanism, a router query engine, and robust response synthesis, the results
proved search precision and relevance. We present the architecture and
implementation of the system and evaluate its performance in four experiments
concerning LLM efficiency, hybrid retrieval optimizations, multilingual query
handling, and the impacts of individual components. Obtained results show
significant improvements over conventional approaches and have demonstrated the
potential of AI-powered systems to transform modern archival practices.

摘要：本研究提出了一個智慧搜尋的新框架，用於數位檔案系統，利用大型語言模型 (LLM) 的功能來增強資訊檢索。透過採用檢索增強生成 (RAG) 的方法，此框架能處理自然語言查詢，並將非文字資料轉換為有意義的文字表示。此系統整合了先進的元資料生成技術、混合檢索機制、路由器查詢引擎和強大的回應合成，結果證明了搜尋精準度和相關性。我們展示了系統的架構和實作，並在四個實驗中評估其效能，包括 LLM 效率、混合檢索最佳化、多語言查詢處理和個別元件的影響。取得的結果顯示，與傳統方法相比有顯著的改善，並證明了 AI 驅動系統轉變現代檔案實務的潛力。

##### **Neural Probabilistic Circuits: Enabling Compositional and Interpretable Predictions through Logical Reasoning**
2501.07021v1 by Weixin Chen, Simon Yu, Huajie Shao, Lui Sha, Han Zhao

End-to-end deep neural networks have achieved remarkable success across
various domains but are often criticized for their lack of interpretability.
While post hoc explanation methods attempt to address this issue, they often
fail to accurately represent these black-box models, resulting in misleading or
incomplete explanations. To overcome these challenges, we propose an inherently
transparent model architecture called Neural Probabilistic Circuits (NPCs),
which enable compositional and interpretable predictions through logical
reasoning. In particular, an NPC consists of two modules: an attribute
recognition model, which predicts probabilities for various attributes, and a
task predictor built on a probabilistic circuit, which enables logical
reasoning over recognized attributes to make class predictions. To train NPCs,
we introduce a three-stage training algorithm comprising attribute recognition,
circuit construction, and joint optimization. Moreover, we theoretically
demonstrate that an NPC's error is upper-bounded by a linear combination of the
errors from its modules. To further demonstrate the interpretability of NPC, we
provide both the most probable explanations and the counterfactual
explanations. Empirical results on four benchmark datasets show that NPCs
strike a balance between interpretability and performance, achieving results
competitive even with those of end-to-end black-box models while providing
enhanced interpretability.

摘要：端到端深度神經網路在各種領域都取得了顯著的成功，但卻經常因其缺乏可解釋性而受到批評。雖然事後解釋方法試圖解決這個問題，但它們常常無法準確地表示這些黑盒模型，導致誤導或不完整的解釋。為了克服這些挑戰，我們提出了一個本質上透明的模型架構，稱為神經概率電路 (NPC)，它能通過邏輯推理實現組合和可解釋的預測。具體來說，NPC 由兩個模組組成：屬性識別模型，它預測各種屬性的機率，以及建立在概率電路上的任務預測器，它能對識別出的屬性進行邏輯推理，做出類別預測。為了訓練 NPC，我們引入了一個包含屬性識別、電路建構和聯合優化的三階段訓練演算法。此外，我們從理論上證明，NPC 的誤差由其模組誤差的線性組合上限。為了進一步證明 NPC 的可解釋性，我們提供了最可能的解釋和反事實解釋。在四個基準資料集上的實證結果表明，NPC 在可解釋性和效能之間取得了平衡，即使與端到端黑盒模型相比，也能取得具有競爭力的結果，同時提供增強的可解釋性。

##### **ViSoLex: An Open-Source Repository for Vietnamese Social Media Lexical Normalization**
2501.07020v1 by Anh Thi-Hoang Nguyen, Dung Ha Nguyen, Kiet Van Nguyen

ViSoLex is an open-source system designed to address the unique challenges of
lexical normalization for Vietnamese social media text. The platform provides
two core services: Non-Standard Word (NSW) Lookup and Lexical Normalization,
enabling users to retrieve standard forms of informal language and standardize
text containing NSWs. ViSoLex's architecture integrates pre-trained language
models and weakly supervised learning techniques to ensure accurate and
efficient normalization, overcoming the scarcity of labeled data in Vietnamese.
This paper details the system's design, functionality, and its applications for
researchers and non-technical users. Additionally, ViSoLex offers a flexible,
customizable framework that can be adapted to various datasets and research
requirements. By publishing the source code, ViSoLex aims to contribute to the
development of more robust Vietnamese natural language processing tools and
encourage further research in lexical normalization. Future directions include
expanding the system's capabilities for additional languages and improving the
handling of more complex non-standard linguistic patterns.

摘要：ViSoLex 是一個開放原始碼系統，旨在解決越南社群媒體文字的詞彙正規化獨特挑戰。此平台提供兩項核心服務：非標準詞彙 (NSW) 查詢和詞彙正規化，讓使用者能夠擷取非正式語言的標準形式，並標準化包含 NSW 的文字。ViSoLex 的架構整合了預先訓練好的語言模型和弱監督學習技術，以確保正規化準確且有效率，克服越南語標記資料的稀少性。本文詳細說明系統的設計、功能，以及其在研究人員和非技術使用者的應用。此外，ViSoLex 提供一個彈性、可自訂的架構，可以調整成各種資料集和研究需求。透過發布原始程式碼，ViSoLex 旨在為更強大的越南自然語言處理工具開發做出貢獻，並鼓勵進一步研究詞彙正規化。未來的方向包括擴展系統對其他語言的能力，以及改善處理更複雜的非標準語言模式。

##### **A Multi-Modal Deep Learning Framework for Pan-Cancer Prognosis**
2501.07016v1 by Binyu Zhang, Shichao Li, Junpeng Jian, Zhu Meng, Limei Guo, Zhicheng Zhao

Prognostic task is of great importance as it closely related to the survival
analysis of patients, the optimization of treatment plans and the allocation of
resources. The existing prognostic models have shown promising results on
specific datasets, but there are limitations in two aspects. On the one hand,
they merely explore certain types of modal data, such as patient histopathology
WSI and gene expression analysis. On the other hand, they adopt the
per-cancer-per-model paradigm, which means the trained models can only predict
the prognostic effect of a single type of cancer, resulting in weak
generalization ability. In this paper, a deep-learning based model, named
UMPSNet, is proposed. Specifically, to comprehensively understand the condition
of patients, in addition to constructing encoders for histopathology images and
genomic expression profiles respectively, UMPSNet further integrates four types
of important meta data (demographic information, cancer type information,
treatment protocols, and diagnosis results) into text templates, and then
introduces a text encoder to extract textual features. In addition, the optimal
transport OT-based attention mechanism is utilized to align and fuse features
of different modalities. Furthermore, a guided soft mixture of experts (GMoE)
mechanism is introduced to effectively address the issue of distribution
differences among multiple cancer datasets. By incorporating the multi-modality
of patient data and joint training, UMPSNet outperforms all SOTA approaches,
and moreover, it demonstrates the effectiveness and generalization ability of
the proposed learning paradigm of a single model for multiple cancer types. The
code of UMPSNet is available at https://github.com/binging512/UMPSNet.

摘要：預後任務非常重要，因為它與病患的存活分析、治療計畫的最佳化和資源分配密切相關。現有的預後模型在特定資料集上已展現出有希望的結果，但有兩個方面的限制。一方面，它們僅探討特定類型的模式資料，例如病患組織病理學 WSI 和基因表現分析。另一方面，它們採用「每種癌症對應一個模型」的模式，這表示訓練出來的模型只能預測單一種類癌症的預後效應，導致概化能力不足。在本文中，提出了一個名為 UMPSNet 的深度學習模型。具體來說，為了全面了解病患的狀況，除了分別建構組織病理學影像和基因體表現特徵的編碼器之外，UMPSNet 還進一步將四種類型的重要元資料（人口統計資訊、癌症類型資訊、治療方案和診斷結果）整合到文字範本中，然後引入文字編碼器來萃取文字特徵。此外，利用最佳傳輸 OT 為基礎的注意力機制來對齊和融合不同模式的特徵。此外，引入了引導式軟性專家混合 (GMoE) 機制，以有效解決多個癌症資料集之間的分配差異問題。透過整合病患資料的多模式和聯合訓練，UMPSNet 優於所有 SOTA 方法，而且證明了單一模型對多種癌症類型的學習範例的有效性和概化能力。UMPSNet 的程式碼可在 https://github.com/binging512/UMPSNet 取得。

##### **AlgoRxplorers | Precision in Mutation -- Enhancing Drug Design with Advanced Protein Stability Prediction Tools**
2501.07014v1 by Karishma Thakrar, Jiangqin Ma, Max Diamond, Akash Patel

Predicting the impact of single-point amino acid mutations on protein
stability is essential for understanding disease mechanisms and advancing drug
development. Protein stability, quantified by changes in Gibbs free energy
($\Delta\Delta G$), is influenced by these mutations. However, the scarcity of
data and the complexity of model interpretation pose challenges in accurately
predicting stability changes. This study proposes the application of deep
neural networks, leveraging transfer learning and fusing complementary
information from different models, to create a feature-rich representation of
the protein stability landscape. We developed four models, with our third
model, ThermoMPNN+, demonstrating the best performance in predicting
$\Delta\Delta G$ values. This approach, which integrates diverse feature sets
and embeddings through latent transfusion techniques, aims to refine
$\Delta\Delta G$ predictions and contribute to a deeper understanding of
protein dynamics, potentially leading to advancements in disease research and
drug discovery.

摘要：預測單點胺基酸突變對蛋白質穩定性的影響對於了解疾病機制和推進藥物開發至關重要。蛋白質穩定性，由吉布斯自由能變化（$ \Delta \Delta G $）量化，受這些突變的影響。然而，數據的稀缺性和模型解釋的複雜性對準確預測穩定性變化構成了挑戰。本研究提出應用深度神經網路，利用遷移學習並融合來自不同模型的互補資訊，以建立蛋白質穩定性格局的豐富特徵表示。我們開發了四個模型，其中我們的第三個模型 ThermoMPNN+ 在預測 $ \Delta \Delta G $ 值方面表現最佳。這種方法透過潛在輸血技術整合了多樣化的特徵集和嵌入，旨在優化 $ \Delta \Delta G $ 預測，並有助於更深入地了解蛋白質動力學，潛在地促進疾病研究和藥物發現。

##### **Likelihood Training of Cascaded Diffusion Models via Hierarchical Volume-preserving Maps**
2501.06999v1 by Henry Li, Ronen Basri, Yuval Kluger

Cascaded models are multi-scale generative models with a marked capacity for
producing perceptually impressive samples at high resolutions. In this work, we
show that they can also be excellent likelihood models, so long as we overcome
a fundamental difficulty with probabilistic multi-scale models: the
intractability of the likelihood function. Chiefly, in cascaded models each
intermediary scale introduces extraneous variables that cannot be tractably
marginalized out for likelihood evaluation. This issue vanishes by modeling the
diffusion process on latent spaces induced by a class of transformations we
call hierarchical volume-preserving maps, which decompose spatially structured
data in a hierarchical fashion without introducing local distortions in the
latent space. We demonstrate that two such maps are well-known in the
literature for multiscale modeling: Laplacian pyramids and wavelet transforms.
Not only do such reparameterizations allow the likelihood function to be
directly expressed as a joint likelihood over the scales, we show that the
Laplacian pyramid and wavelet transform also produces significant improvements
to the state-of-the-art on a selection of benchmarks in likelihood modeling,
including density estimation, lossless compression, and out-of-distribution
detection. Investigating the theoretical basis of our empirical gains we
uncover deep connections to score matching under the Earth Mover's Distance
(EMD), which is a well-known surrogate for perceptual similarity. Code can be
found at \href{https://github.com/lihenryhfl/pcdm}{this https url}.

摘要：層疊模型是一種多尺度生成模型，具有以高解析度產生令人印象深刻的樣本的顯著能力。在這項工作中，我們表明它們也可以成為出色的可能性模型，只要我們克服概率多尺度模型的一個基本難題：可能性函數的難以處理性。最重要的是，在層疊模型中，每個中間尺度都會引入額外的變數，這些變數無法被合理地邊緣化以進行可能性評估。通過對由我們稱之為分層體積保持映射的一類轉換誘導的潛在空間上的擴散過程進行建模，這個問題消失了，這種轉換以分層方式分解空間結構化的資料，而不會在潛在空間中引入局部失真。我們證明了這類映射中有兩個在多尺度建模的文獻中很有名：拉普拉斯金字塔和波段轉換。這種重新參數化不僅允許可能性函數直接表示為尺度上的聯合可能性，我們還表明，拉普拉斯金字塔和波段轉換也對可能性建模基準中的一系列最先進技術產生了顯著改進，包括密度估計、無損壓縮和分佈外檢測。在探討我們經驗收益的理論基礎時，我們發現了與地球移動距離 (EMD) 下的得分匹配的深層聯繫，而地球移動距離 (EMD) 是感知相似性的眾所周知的替代方法。可以在 \href{https://github.com/lihenryhfl/pcdm}{這個 https 網址} 找到程式碼。

##### **LEO: Boosting Mixture of Vision Encoders for Multimodal Large Language Models**
2501.06986v1 by Mozhgan Nasr Azadani, James Riddell, Sean Sedwards, Krzysztof Czarnecki

Enhanced visual understanding serves as a cornerstone for multimodal large
language models (MLLMs). Recent hybrid MLLMs incorporate a mixture of vision
experts to address the limitations of using a single vision encoder and
excessively long visual tokens. Despite the progress of these MLLMs, a research
gap remains in effectively integrating diverse vision encoders. This work
explores fusion strategies of visual tokens for hybrid MLLMs, leading to the
design of LEO, a novel MLLM with a dual-branch vision encoder framework that
incorporates a post-adaptation fusion strategy and adaptive tiling: for each
segmented tile of the input images, LEO sequentially interleaves the visual
tokens from its two vision encoders. Extensive evaluation across 13
vision-language benchmarks reveals that LEO outperforms state-of-the-art
open-source MLLMs and hybrid MLLMs on the majority of tasks. Furthermore, we
show that LEO can be adapted to the specialized domain of autonomous driving
without altering the model architecture or training recipe, achieving
competitive performance compared to existing baselines. The code and model will
be publicly available.

摘要：增強的視覺理解是多模態大型語言模型 (MLLM) 的基石。最近的混合 MLLM 結合了視覺專家的混合，以解決使用單一視覺編碼器和過長的視覺符號的限制。儘管這些 MLLM 取得了進展，但有效整合不同的視覺編碼器仍然存在研究空白。這項工作探討了混合 MLLM 的視覺符號融合策略，從而設計出 LEO，一種具有雙分支視覺編碼器框架的新型 MLLM，它結合了後適應融合策略和自適應平鋪：對於輸入影像的每個分割平鋪，LEO 依序交織其兩個視覺編碼器的視覺符號。在 13 個視覺語言基準上的廣泛評估顯示，LEO 在大多數任務上優於最先進的開源 MLLM 和混合 MLLM。此外，我們展示了 LEO 可以適應自動駕駛的專業領域，而無需改變模型架構或訓練配方，與現有的基準相比，實現了競爭力。代碼和模型將公開提供。

##### **Graph Contrastive Learning on Multi-label Classification for Recommendations**
2501.06985v1 by Jiayang Wu, Wensheng Gan, Huashen Lu, Philip S. Yu

In business analysis, providing effective recommendations is essential for
enhancing company profits. The utilization of graph-based structures, such as
bipartite graphs, has gained popularity for their ability to analyze complex
data relationships. Link prediction is crucial for recommending specific items
to users. Traditional methods in this area often involve identifying patterns
in the graph structure or using representational techniques like graph neural
networks (GNNs). However, these approaches encounter difficulties as the volume
of data increases. To address these challenges, we propose a model called Graph
Contrastive Learning for Multi-label Classification (MCGCL). MCGCL leverages
contrastive learning to enhance recommendation effectiveness. The model
incorporates two training stages: a main task and a subtask. The main task is
holistic user-item graph learning to capture user-item relationships. The
homogeneous user-user (item-item) subgraph is constructed to capture user-user
and item-item relationships in the subtask. We assessed the performance using
real-world datasets from Amazon Reviews in multi-label classification tasks.
Comparative experiments with state-of-the-art methods confirm the effectiveness
of MCGCL, highlighting its potential for improving recommendation systems.

摘要：<paragraph>在商業分析中，提供有效的建議對於提高公司利潤至關重要。圖形化結構（例如二分圖）的使用越來越受歡迎，因為它們能夠分析複雜的數據關係。連結預測對於向用戶推薦特定項目至關重要。此領域的傳統方法通常涉及識別圖形結構中的模式或使用圖形神經網路 (GNN) 等表示技術。然而，隨著數據量的增加，這些方法會遇到困難。為了應對這些挑戰，我們提出了一個名為圖形對比學習多標籤分類 (MCGCL) 的模型。MCGCL 利用對比學習來增強推薦效果。該模型包含兩個訓練階段：主任務和子任務。主任務是整體使用者-項目圖形學習，用於擷取使用者-項目關係。同質使用者-使用者（項目-項目）子圖被構造出來，用於在子任務中擷取使用者-使用者和項目-項目關係。我們使用來自 Amazon 評論的多標籤分類任務中的真實世界資料集評估了效能。與最先進方法的比較實驗證實了 MCGCL 的有效性，突出了其改進推薦系統的潛力。</paragraph>

##### **Data Enrichment Work and AI Labor in Latin America and the Caribbean**
2501.06981v1 by Gianna Williams, Maya De Los Santos, Alexandra To, Saiph Savage

The global AI surge demands crowdworkers from diverse languages and cultures.
They are pivotal in labeling data for enabling global AI systems. Despite
global significance, research has primarily focused on understanding the
perspectives and experiences of US and India crowdworkers, leaving a notable
gap. To bridge this, we conducted a survey with 100 crowdworkers across 16
Latin American and Caribbean countries. We discovered that these workers
exhibited pride and respect for their digital labor, with strong support and
admiration from their families. Notably, crowd work was also seen as a stepping
stone to financial and professional independence. Surprisingly, despite wanting
more connection, these workers also felt isolated from peers and doubtful of
others' labor quality. They resisted collaboration and gender-based tools,
valuing gender-neutrality. Our work advances HCI understanding of Latin
American and Caribbean crowdwork, offering insights for digital resistance
tools for the region.

摘要：全球 AI 的激增需要来自不同語言和文化的群眾工作者。
他們在標記數據以啟用全球 AI 系統方面發揮著關鍵作用。儘管
具有全球意義，但研究主要集中於了解美國和印度群眾工作者的觀點和經驗，留下了顯著的
差距。為了彌合這一差距，我們對 16 個拉丁美洲和加勒比國家的 100 名群眾工作者進行了一項調查。我們發現這些工人
對他們的數位勞動表現出自豪和尊重，並得到家人的大力支持和讚賞。值得注意的是，群眾工作也被視為邁向財務和專業獨立的踏腳石。令人驚訝的是，儘管想要更多聯繫，但這些工人也感到與同儕隔離，並對他人的勞動品質感到懷疑。他們抵制協作和基於性別的工具，重視性別中立。我們的研究推動了 HCI 對拉丁美洲和加勒比海群眾工作的理解，為該地區的數位抵抗工具提供了見解。

##### **Combining LLM decision and RL action selection to improve RL policy for adaptive interventions**
2501.06980v1 by Karine Karine, Benjamin M. Marlin

Reinforcement learning (RL) is increasingly being used in the healthcare
domain, particularly for the development of personalized health adaptive
interventions. Inspired by the success of Large Language Models (LLMs), we are
interested in using LLMs to update the RL policy in real time, with the goal of
accelerating personalization. We use the text-based user preference to
influence the action selection on the fly, in order to immediately incorporate
the user preference. We use the term "user preference" as a broad term to refer
to a user personal preference, constraint, health status, or a statement
expressing like or dislike, etc. Our novel approach is a hybrid method that
combines the LLM response and the RL action selection to improve the RL policy.
Given an LLM prompt that incorporates the user preference, the LLM acts as a
filter in the typical RL action selection. We investigate different prompting
strategies and action selection strategies. To evaluate our approach, we
implement a simulation environment that generates the text-based user
preferences and models the constraints that impact behavioral dynamics. We show
that our approach is able to take into account the text-based user preferences,
while improving the RL policy, thus improving personalization in adaptive
intervention.

摘要：強化學習（RL）在醫療領域的應用日益廣泛，特別是用於開發個人化健康適應性干預措施。受到大型語言模型（LLM）成功的啟發，我們有興趣使用 LLM 即時更新 RL 政策，目標是加速個人化。我們使用基於文字的使用者偏好來影響行動選擇，以便立即納入使用者偏好。我們使用「使用者偏好」一詞作為廣義詞，用來指使用者的個人偏好、限制、健康狀況或表達好惡的陳述等。我們的新穎方法是一種混合方法，結合了 LLM 回應和 RL 行動選擇以改善 RL 政策。給定包含使用者偏好的 LLM 提示，LLM 在典型的 RL 行動選擇中充當過濾器。我們研究了不同的提示策略和行動選擇策略。為了評估我們的做法，我們實作了一個模擬環境，用於產生基於文字的使用者偏好，並對影響行為動態的限制進行建模。我們展示了我們的做法能夠考量基於文字的使用者偏好，同時改善 RL 政策，從而改善適應性干預中的個人化。

##### **Kolmogorov-Arnold Recurrent Network for Short Term Load Forecasting Across Diverse Consumers**
2501.06965v1 by Muhammad Umair Danish, Katarina Grolinger

Load forecasting plays a crucial role in energy management, directly
impacting grid stability, operational efficiency, cost reduction, and
environmental sustainability. Traditional Vanilla Recurrent Neural Networks
(RNNs) face issues such as vanishing and exploding gradients, whereas
sophisticated RNNs such as LSTMs have shown considerable success in this
domain. However, these models often struggle to accurately capture complex and
sudden variations in energy consumption, and their applicability is typically
limited to specific consumer types, such as offices or schools. To address
these challenges, this paper proposes the Kolmogorov-Arnold Recurrent Network
(KARN), a novel load forecasting approach that combines the flexibility of
Kolmogorov-Arnold Networks with RNN's temporal modeling capabilities. KARN
utilizes learnable temporal spline functions and edge-based activations to
better model non-linear relationships in load data, making it adaptable across
a diverse range of consumer types. The proposed KARN model was rigorously
evaluated on a variety of real-world datasets, including student residences,
detached homes, a home with electric vehicle charging, a townhouse, and
industrial buildings. Across all these consumer categories, KARN consistently
outperformed traditional Vanilla RNNs, while it surpassed LSTM and Gated
Recurrent Units (GRUs) in six buildings. The results demonstrate KARN's
superior accuracy and applicability, making it a promising tool for enhancing
load forecasting in diverse energy management scenarios.

摘要：負載預測在能源管理中扮演至關重要的角色，直接影響電網穩定性、營運效率、成本降低和環境永續性。傳統的香草遞迴神經網路 (RNN) 面臨消失與爆炸梯度等問題，而 LSTM 等精密的 RNN 已在此領域展現顯著的成功。然而，這些模型通常難以精確捕捉能源消耗中複雜且突然的變化，且其適用性通常僅限於特定類型的消費者，例如辦公室或學校。為了應對這些挑戰，本文提出柯爾莫哥洛夫-阿諾德遞迴網路 (KARN)，這是一種新穎的負載預測方法，結合了柯爾莫哥洛夫-阿諾德網路的靈活性與 RNN 的時間建模能力。KARN 利用可學習的時間樣條函數和基於邊緣的激活，以更好地對負載資料中的非線性關係進行建模，使其適用於各種消費者類型。所提出的 KARN 模型在各種真實世界資料集上經過嚴格評估，包括學生宿舍、獨立住宅、配有電動車充電功能的住宅、聯排住宅和工業建築。在所有這些消費者類別中，KARN 持續優於傳統的香草 RNN，同時在六棟建築中超越 LSTM 和門控遞迴單元 (GRU)。結果證明了 KARN 的優異準確性和適用性，使其成為在各種能源管理情境中增強負載預測的有前途工具。

##### **Enhancing Patient-Centric Communication: Leveraging LLMs to Simulate Patient Perspectives**
2501.06964v1 by Xinyao Ma, Rui Zhu, Zihao Wang, Jingwei Xiong, Qingyu Chen, Haixu Tang, L. Jean Camp, Lucila Ohno-Machado

Large Language Models (LLMs) have demonstrated impressive capabilities in
role-playing scenarios, particularly in simulating domain-specific experts
using tailored prompts. This ability enables LLMs to adopt the persona of
individuals with specific backgrounds, offering a cost-effective and efficient
alternative to traditional, resource-intensive user studies. By mimicking human
behavior, LLMs can anticipate responses based on concrete demographic or
professional profiles. In this paper, we evaluate the effectiveness of LLMs in
simulating individuals with diverse backgrounds and analyze the consistency of
these simulated behaviors compared to real-world outcomes. In particular, we
explore the potential of LLMs to interpret and respond to discharge summaries
provided to patients leaving the Intensive Care Unit (ICU). We evaluate and
compare with human responses the comprehensibility of discharge summaries among
individuals with varying educational backgrounds, using this analysis to assess
the strengths and limitations of LLM-driven simulations. Notably, when LLMs are
primed with educational background information, they deliver accurate and
actionable medical guidance 88% of the time. However, when other information is
provided, performance significantly drops, falling below random chance levels.
This preliminary study shows the potential benefits and pitfalls of
automatically generating patient-specific health information from diverse
populations. While LLMs show promise in simulating health personas, our results
highlight critical gaps that must be addressed before they can be reliably used
in clinical settings. Our findings suggest that a straightforward
query-response model could outperform a more tailored approach in delivering
health information. This is a crucial first step in understanding how LLMs can
be optimized for personalized health communication while maintaining accuracy.

摘要：大型語言模型（LLM）在角色扮演場景中展現了令人印象深刻的能力，特別是在模擬特定領域的專家時，會使用量身打造的提示。這種能力使 LLM 能夠採用具有特定背景的個人角色，提供一種經濟實惠且有效率的替代方案，用於傳統且資源密集的使用者研究。透過模擬人類行為，LLM 能夠根據具體的人口統計或專業特徵預測反應。在本文中，我們評估了 LLM 在模擬具有不同背景的個人方面的有效性，並分析了這些模擬行為與實際結果相比的一致性。特別是，我們探討了 LLM 解釋和回應提供給離開加護病房 (ICU) 患者的出院摘要的潛力。我們評估並與人類的反應比較了不同教育背景的個人對出院摘要的可理解性，並使用此分析來評估 LLM 驅動模擬的優點和限制。值得注意的是，當 LLM 被植入教育背景資訊時，他們在 88% 的時間內都能提供準確且可行的醫療指導。但是，當提供其他資訊時，效能會顯著下降，低於隨機機會的等級。這項初步研究顯示了自動產生來自不同群體的特定於患者的健康資訊的潛在好處和缺點。儘管 LLM 在模擬健康角色方面顯示出前景，但我們的結果突出了在臨床環境中可靠使用之前必須解決的關鍵差距。我們的研究結果表明，在提供健康資訊方面，一個直接的查詢回應模型可以優於一個更量身打造的方法。這是了解如何針對個人化健康溝通優化 LLM 同時維持準確性的第一步。

##### **Compact Bayesian Neural Networks via pruned MCMC sampling**
2501.06962v1 by Ratneel Deo, Scott Sisson, Jody M. Webster, Rohitash Chandra

Bayesian Neural Networks (BNNs) offer robust uncertainty quantification in
model predictions, but training them presents a significant computational
challenge. This is mainly due to the problem of sampling multimodal posterior
distributions using Markov Chain Monte Carlo (MCMC) sampling and variational
inference algorithms. Moreover, the number of model parameters scales
exponentially with additional hidden layers, neurons, and features in the
dataset. Typically, a significant portion of these densely connected parameters
are redundant and pruning a neural network not only improves portability but
also has the potential for better generalisation capabilities. In this study,
we address some of the challenges by leveraging MCMC sampling with network
pruning to obtain compact probabilistic models having removed redundant
parameters. We sample the posterior distribution of model parameters (weights
and biases) and prune weights with low importance, resulting in a compact
model. We ensure that the compact BNN retains its ability to estimate
uncertainty via the posterior distribution while retaining the model training
and generalisation performance accuracy by adapting post-pruning resampling. We
evaluate the effectiveness of our MCMC pruning strategy on selected benchmark
datasets for regression and classification problems through empirical result
analysis. We also consider two coral reef drill-core lithology classification
datasets to test the robustness of the pruning model in complex real-world
datasets. We further investigate if refining compact BNN can retain any loss of
performance. Our results demonstrate the feasibility of training and pruning
BNNs using MCMC whilst retaining generalisation performance with over 75%
reduction in network size. This paves the way for developing compact BNN models
that provide uncertainty estimates for real-world applications.

摘要：貝氏神經網路 (BNN) 提供模型預測中穩健的不確定量化，但訓練它們提出了顯著的計算挑戰。這主要是由於使用馬可夫鏈蒙地卡羅 (MCMC) 採樣和變異推論演算法來採樣多模態後驗分佈的問題。此外，模型參數的數量會隨著資料集中額外的隱藏層、神經元和特徵呈指數級擴展。通常，這些密集連接參數中很大一部分是冗餘的，而修剪神經網路不僅可以提高可移植性，而且也有潛力獲得更好的泛化能力。在這項研究中，我們透過利用 MCMC 採樣和網路修剪來解決一些挑戰，以獲得移除冗餘參數的緊湊機率模型。我們對模型參數 (權重和偏差) 的後驗分佈進行採樣，並修剪重要性低的權重，從而產生一個緊湊的模型。我們確保緊湊的 BNN 保留其透過後驗分佈估計不確定性的能力，同時透過調整後修剪重新採樣來保留模型訓練和泛化效能的準確性。我們透過經驗結果分析，評估我們的 MCMC 修剪策略在選定的基準資料集上的迴歸和分類問題的有效性。我們也考慮了兩個珊瑚礁鑽孔岩性分類資料集，以測試修剪模型在複雜的真實世界資料集中的穩健性。我們進一步探討精煉緊湊的 BNN 是否可以保留任何效能損失。我們的結果證明了使用 MCMC 訓練和修剪 BNN 的可行性，同時在網路大小減少超過 75% 的情況下保留泛化效能。這為開發提供真實世界應用不確定性估計的緊湊 BNN 模型鋪平了道路。

##### **The Einstein Test: Towards a Practical Test of a Machine's Ability to Exhibit Superintelligence**
2501.06948v1 by David Benrimoh, Nace Mikus, Ariel Rosenfeld

Creative and disruptive insights (CDIs), such as the development of the
theory of relativity, have punctuated human history, marking pivotal shifts in
our intellectual trajectory. Recent advancements in artificial intelligence
(AI) have sparked debates over whether state of the art models possess the
capacity to generate CDIs. We argue that the ability to create CDIs should be
regarded as a significant feature of machine superintelligence (SI).To this
end, we propose a practical test to evaluate whether an approach to AI
targeting SI can yield novel insights of this kind. We propose the Einstein
test: given the data available prior to the emergence of a known CDI, can an AI
independently reproduce that insight (or one that is formally equivalent)? By
achieving such a milestone, a machine can be considered to at least match
humanity's past top intellectual achievements, and therefore to have the
potential to surpass them.

摘要：創造性和破壞性見解（CDI），例如相對論的發展，點綴了人類歷史，標誌著我們智力軌跡的關鍵轉折。最近人工智能（AI）的進展引發了關於最先進模型是否具有產生 CDI 的能力的爭論。我們認為，創造 CDI 的能力應該被視為機器超級智能（SI）的一個重要特徵。為此，我們提出了一個實用的測試來評估一種針對 SI 的 AI 方法是否能產生這種新穎的見解。我們提出了愛因斯坦測試：在已知 CDI 出現之前可用的數據中，AI 能否獨立地再現該見解（或與之形式等效的見解）？通過實現這樣的里程碑，機器可以被認為至少與人類過去的頂尖智力成就相匹配，因此具有超越它們的潛力。

##### **An Empirical Study of Deep Reinforcement Learning in Continuing Tasks**
2501.06937v1 by Yi Wan, Dmytro Korenkevych, Zheqing Zhu

In reinforcement learning (RL), continuing tasks refer to tasks where the
agent-environment interaction is ongoing and can not be broken down into
episodes. These tasks are suitable when environment resets are unavailable,
agent-controlled, or predefined but where all rewards-including those beyond
resets-are critical. These scenarios frequently occur in real-world
applications and can not be modeled by episodic tasks. While modern deep RL
algorithms have been extensively studied and well understood in episodic tasks,
their behavior in continuing tasks remains underexplored. To address this gap,
we provide an empirical study of several well-known deep RL algorithms using a
suite of continuing task testbeds based on Mujoco and Atari environments,
highlighting several key insights concerning continuing tasks. Using these
testbeds, we also investigate the effectiveness of a method for improving
temporal-difference-based RL algorithms in continuing tasks by centering
rewards, as introduced by Naik et al. (2024). While their work primarily
focused on this method in conjunction with Q-learning, our results extend their
findings by demonstrating that this method is effective across a broader range
of algorithms, scales to larger tasks, and outperforms two other
reward-centering approaches.

摘要：在強化學習 (RL) 中，持續任務是指代理環境互動正在進行且無法分解為各個事件的任務。當環境重置不可用、受代理控制或預先定義但所有獎勵（包括重置後的獎勵）都很重要時，這些任務很合適。這些場景經常發生在真實世界的應用中，且無法透過事件任務建模。儘管現代深度 RL 演算法已經在事件任務中廣泛研究且廣為了解，它們在持續任務中的行為仍未充分探討。為了解決這個差距，我們提供了一項使用基於 Mujoco 和 Atari 環境的一組持續任務測試平台的幾種眾所周知的深度 RL 演算法的實證研究，重點說明了幾個關於持續任務的重要見解。使用這些測試平台，我們還研究了一種方法的有效性，該方法透過集中獎勵來改善持續任務中的基於時間差分的 RL 演算法，正如 Naik 等人 (2024) 所介紹的那樣。儘管他們的工作主要集中於結合 Q 學習的這種方法，但我們的結果透過證明這種方法在更廣泛的演算法中有效、擴展到更大的任務，且優於其他兩種獎勵中心化方法，來擴展他們的發現。

##### **Harnessing Large Language Models for Disaster Management: A Survey**
2501.06932v1 by Zhenyu Lei, Yushun Dong, Weiyu Li, Rong Ding, Qi Wang, Jundong Li

Large language models (LLMs) have revolutionized scientific research with
their exceptional capabilities and transformed various fields. Among their
practical applications, LLMs have been playing a crucial role in mitigating
threats to human life, infrastructure, and the environment. Despite growing
research in disaster LLMs, there remains a lack of systematic review and
in-depth analysis of LLMs for natural disaster management. To address the gap,
this paper presents a comprehensive survey of existing LLMs in natural disaster
management, along with a taxonomy that categorizes existing works based on
disaster phases and application scenarios. By collecting public datasets and
identifying key challenges and opportunities, this study aims to guide the
professional community in developing advanced LLMs for disaster management to
enhance the resilience against natural disasters.

摘要：大型語言模型 (LLM) 以其卓越的能力徹底改變了科學研究，並轉變了各個領域。在其實際應用中，LLM 在減輕對人類生命、基礎設施和環境的威脅方面發揮了至關重要的作用。儘管對災害 LLM 的研究不斷增加，但仍缺乏對自然災害管理 LLM 的系統性回顧和深入分析。為了彌補這一差距，本文對自然災害管理中現有的 LLM 進行了全面的調查，並提出了基於災害階段和應用場景對現有工作進行分類的分類法。通過收集公共數據集並確定關鍵挑戰和機會，本研究旨在指導專業社群開發用於災害管理的高級 LLM，以增強抵禦自然災害的能力。

##### **Why are we living the age of AI applications right now? The long innovation path from AI's birth to a child's bedtime magic**
2501.06929v1 by Tapio Pitkäranta

Today a four-year-old child who does not know how to read or write can now
create bedtime stories with graphical illustrations and narrated audio, using
AI tools that seamlessly transform speech into text, generate visuals, and
convert text back into speech in a natural and engaging manner. This remarkable
example demonstrates why we are living in the age of AI applications. This
paper examines contemporary leading AI applications and traces their historical
development, highlighting the major advancements that have enabled their
realization. Five key factors are identified: 1) The evolution of computational
hardware (CPUs and GPUs), enabling the training of complex AI models 2) The
vast digital archives provided by the World Wide Web, which serve as a
foundational data resource for AI systems 3) The ubiquity of mobile computing,
with smartphones acting as powerful, accessible small computers in the hands of
billions 4) The rise of industrial-scale cloud infrastructures, offering
elastic computational power for AI training and deployment 5) Breakthroughs in
AI research, including neural networks, backpropagation, and the "Attention is
All You Need" framework, which underpin modern AI capabilities. These
innovations have elevated AI from solving narrow tasks to enabling applications
like ChatGPT that are adaptable for numerous use cases, redefining
human-computer interaction. By situating these developments within a historical
context, the paper highlights the critical milestones that have made AI's
current capabilities both possible and widely accessible, offering profound
implications for society.

摘要：<paragraph>如今，一个不会读写的小孩，现在可以使用 AI 工具，将语音无缝地转换为文字、生成视觉效果，并将文字自然且引人入胜地转换回语音，来创作带有图形插图和叙述音频的睡前故事。这个非凡的例子展示了我们为何生活在 AI 应用的时代。本文探讨了当代领先的 AI 应用，并追溯了它们的历史发展，重点介绍了促成其实现的重大进步。确定了五个关键因素：1) 计算硬件（CPU 和 GPU）的演进，能够训练复杂的 AI 模型 2) 万维网提供的庞大数字档案，作为 AI 系统的基础数据资源 3) 移动计算的普及，智能手机作为数十亿人手中的强大、易于访问的小型计算机 4) 工业规模云基础设施的兴起，为 AI 训练和部署提供弹性计算能力 5) AI 研究的突破，包括神经网络、反向传播和“注意力就是你需要的一切”框架，它支撑了现代 AI 能力。这些创新将 AI 从解决狭窄的任务提升到了启用像 ChatGPT 这样的应用程序，这些应用程序可以适应多种用例，重新定义人机交互。通过将这些发展置于历史背景中，本文重点介绍了使 AI 的当前能力成为可能且广泛可用的关键里程碑，为社会带来了深远的影响。</paragraph>

##### **Risk-Averse Finetuning of Large Language Models**
2501.06911v1 by Sapana Chaudhary, Ujwal Dinesha, Dileep Kalathil, Srinivas Shakkottai

We consider the challenge of mitigating the generation of negative or toxic
content by the Large Language Models (LLMs) in response to certain prompts. We
propose integrating risk-averse principles into LLM fine-tuning to minimize the
occurrence of harmful outputs, particularly rare but significant events. By
optimizing the risk measure of Conditional Value at Risk (CVaR), our
methodology trains LLMs to exhibit superior performance in avoiding toxic
outputs while maintaining effectiveness in generative tasks. Empirical
evaluations on sentiment modification and toxicity mitigation tasks demonstrate
the efficacy of risk-averse reinforcement learning with human feedback (RLHF)
in promoting a safer and more constructive online discourse environment.

摘要：我們考慮應對特定提示時，大型語言模型 (LLM) 產出負面或有毒內容的挑戰。我們建議將風險規避原則整合到 LLM 微調中，以將有害輸出的發生機率降至最低，特別是罕見但重大的事件。透過最佳化風險衡量條件風險值 (CVaR)，我們的做法訓練 LLM 在避免有毒輸出的同時，展現優異的生成任務效能。情緒修改和毒性緩解任務的經驗評估證明，在促進更安全、更具建設性的線上討論環境中，風險規避強化學習與人類回饋 (RLHF) 的效能。

##### **Language Fusion for Parameter-Efficient Cross-lingual Transfer**
2501.06892v1 by Philipp Borchert, Ivan Vulić, Marie-Francine Moens, Jochen De Weerdt

Limited availability of multilingual text corpora for training language
models often leads to poor performance on downstream tasks due to undertrained
representation spaces for languages other than English. This
'under-representation' has motivated recent cross-lingual transfer methods to
leverage the English representation space by e.g. mixing English and
'non-English' tokens at the input level or extending model parameters to
accommodate new languages. However, these approaches often come at the cost of
increased computational complexity. We propose Fusion forLanguage
Representations (FLARE) in adapters, a novel method that enhances
representation quality and downstream performance for languages other than
English while maintaining parameter efficiency. FLARE integrates source and
target language representations within low-rank (LoRA) adapters using
lightweight linear transformations, maintaining parameter efficiency while
improving transfer performance. A series of experiments across representative
cross-lingual natural language understanding tasks, including natural language
inference, question-answering and sentiment analysis, demonstrate FLARE's
effectiveness. FLARE achieves performance improvements of 4.9% for Llama 3.1
and 2.2% for Gemma~2 compared to standard LoRA fine-tuning on
question-answering tasks, as measured by the exact match metric.

摘要：由於可用於訓練語言模型的多語言文字語料庫有限，因此對於非英語語言而言，由於未充分訓練的表徵空間，下游任務的表現通常很差。這種「表徵不足」促使最近的跨語言轉移方法利用英語表徵空間，例如在輸入層級混合英語和「非英語」標記，或擴充模型參數以容納新語言。然而，這些方法通常會增加運算複雜度。我們在適配器中提出融合語言表徵 (FLARE)，這是一種創新的方法，可提升非英語語言的表徵品質和下游表現，同時維持參數效率。FLARE 使用輕量級線性轉換，在低階 (LoRA) 適配器中整合來源和目標語言表徵，在提升轉移表現的同時維持參數效率。一系列針對具代表性的跨語言自然語言理解任務的實驗，包括自然語言推論、問答和情緒分析，都證明了 FLARE 的有效性。根據確切匹配指標衡量，在問答任務上，與標準 LoRA 微調相比，FLARE 讓 Llama 3.1 的表現提升了 4.9%，而 Gemma~2 則提升了 2.2%。

##### **MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis**
2501.06887v1 by Sadia Kamal, Tim Oates

As deep learning models gain attraction in medical data, ensuring transparent
and trustworthy decision-making is essential. In skin cancer diagnosis, while
advancements in lesion detection and classification have improved accuracy, the
black-box nature of these methods poses challenges in understanding their
decision processes, leading to trust issues among physicians. This study
leverages the CLIP (Contrastive Language-Image Pretraining) model, trained on
different skin lesion datasets, to capture meaningful relationships between
visual features and diagnostic criteria terms. To further enhance transparency,
we propose a method called MedGrad E-CLIP, which builds on gradient-based
E-CLIP by incorporating a weighted entropy mechanism designed for complex
medical imaging like skin lesions. This approach highlights critical image
regions linked to specific diagnostic descriptions. The developed integrated
pipeline not only classifies skin lesions by matching corresponding
descriptions but also adds an essential layer of explainability developed
especially for medical data. By visually explaining how different features in
an image relates to diagnostic criteria, this approach demonstrates the
potential of advanced vision-language models in medical image analysis,
ultimately improving transparency, robustness, and trust in AI-driven
diagnostic systems.

摘要：随着深度学习模型在医学数据中获得关注，确保透明且值得信赖的决策至关重要。在皮肤癌诊断中，虽然病灶检测和分类的进步提高了准确性，但这些方法的黑盒性质对理解其决策过程构成了挑战，导致医生之间的信任问题。本研究利用在不同皮肤病变数据集上训练的 CLIP（对比语言图像预训练）模型，以捕捉视觉特征和诊断标准术语之间的有意义关系。为了进一步提高透明度，我们提出了一种名为 MedGrad E-CLIP 的方法，该方法通过结合专为皮肤病变等复杂医学影像设计的加权熵机制，建立在基于梯度的 E-CLIP 之上。此方法突出了与特定诊断描述相关联的关键图像区域。开发的集成管道不仅通过匹配相应的描述对皮肤病变进行分类，还添加了一层专门为医学数据开发的基本可解释性。通过直观地解释图像中不同特征与诊断标准的关系，这种方法展示了高级视觉语言模型在医学图像分析中的潜力，最终提高了透明度、稳健性和对人工智能驱动的诊断系统的信任。

##### **Defect Detection Network In PCB Circuit Devices Based on GAN Enhanced YOLOv11**
2501.06879v1 by Jiayi Huang, Feiyun Zhao, Lieyang Chen

This study proposes an advanced method for surface defect detection in
printed circuit boards (PCBs) using an improved YOLOv11 model enhanced with a
generative adversarial network (GAN). The approach focuses on identifying six
common defect types: missing hole, rat bite, open circuit, short circuit, burr,
and virtual welding. By employing GAN to generate synthetic defect images, the
dataset is augmented with diverse and realistic patterns, improving the model's
ability to generalize, particularly for complex and infrequent defects like
burrs. The enhanced YOLOv11 model is evaluated on a PCB defect dataset,
demonstrating significant improvements in accuracy, recall, and robustness,
especially when dealing with defects in complex environments or small targets.
This research contributes to the broader field of electronic design automation
(EDA), where efficient defect detection is a crucial step in ensuring
high-quality PCB manufacturing. By integrating advanced deep learning
techniques, this approach enhances the automation and precision of defect
detection, reducing reliance on manual inspection and accelerating
design-to-production workflows. The findings underscore the importance of
incorporating GAN-based data augmentation and optimized detection architectures
in EDA processes, providing valuable insights for improving reliability and
efficiency in PCB defect detection within industrial applications.

摘要：本研究提出了一種先進的方法，使用改進的 YOLOv11 模型，並結合生成對抗網路 (GAN) 來進行印刷電路板 (PCB) 的表面缺陷檢測。此方法專注於識別六種常見的缺陷類型：孔洞缺失、鼠咬、開路、短路、毛邊和虛擬焊接。透過使用 GAN 來產生合成缺陷影像，資料集會加入多樣化且逼真的樣式，進而提升模型的泛化能力，特別是對於毛邊等複雜且不常見的缺陷。增強後的 YOLOv11 模型在 PCB 缺陷資料集上進行評估，證明在準確度、召回率和穩健性方面有顯著的提升，特別是在處理複雜環境或小目標中的缺陷時。這項研究有助於電子設計自動化 (EDA) 的廣泛領域，其中有效的缺陷檢測是確保高品質 PCB 製造的關鍵步驟。透過整合先進的深度學習技術，此方法增強了缺陷檢測的自動化和精確度，減少對人工檢查的依賴，並加速從設計到生產的工作流程。研究結果強調了在 EDA 製程中加入基於 GAN 的資料擴充和最佳化的檢測架構的重要性，為提升產業應用中 PCB 缺陷檢測的可靠性和效率提供了寶貴的見解。

##### **Causal Claims in Economics**
2501.06873v1 by Prashant Garg, Thiemo Fetzer

We analyze over 44,000 NBER and CEPR working papers from 1980 to 2023 using a
custom language model to construct knowledge graphs that map economic concepts
and their relationships. We distinguish between general claims and those
documented via causal inference methods (e.g., DiD, IV, RDD, RCTs). We document
a substantial rise in the share of causal claims-from roughly 4% in 1990 to
nearly 28% in 2020-reflecting the growing influence of the "credibility
revolution." We find that causal narrative complexity (e.g., the depth of
causal chains) strongly predicts both publication in top-5 journals and higher
citation counts, whereas non-causal complexity tends to be uncorrelated or
negatively associated with these outcomes. Novelty is also pivotal for top-5
publication, but only when grounded in credible causal methods: introducing
genuinely new causal edges or paths markedly increases both the likelihood of
acceptance at leading outlets and long-run citations, while non-causal novelty
exhibits weak or even negative effects. Papers engaging with central, widely
recognized concepts tend to attract more citations, highlighting a divergence
between factors driving publication success and long-term academic impact.
Finally, bridging underexplored concept pairs is rewarded primarily when
grounded in causal methods, yet such gap filling exhibits no consistent link
with future citations. Overall, our findings suggest that methodological rigor
and causal innovation are key drivers of academic recognition, but sustained
impact may require balancing novel contributions with conceptual integration
into established economic discourse.

摘要：<paragraph>我們使用自訂語言模型分析了 1980 年至 2023 年超過 44,000 份 NBER 和 CEPR 工作論文，以建構知識圖譜，對經濟概念及其關係進行對應。我們區分一般性論述和透過因果推論方法（例如 DiD、IV、RDD、RCT）記錄的論述。我們記錄到因果論述的份額大幅上升，從 1990 年的約 4% 上升到 2020 年的近 28%，反映了「可信度革命」的影響力日益增強。我們發現因果敘述的複雜性（例如因果鏈的深度）強烈預測了在頂尖 5 大期刊的發表和較高的引用次數，而非因果複雜性則往往與這些結果無關或呈負相關。新穎性對於頂尖 5 大期刊的發表也至關重要，但前提是建立在可信的因果方法的基礎上：引入真正新的因果邊緣或路徑顯著增加了在頂尖媒體上被接受的可能性和長期引用，而非因果新穎性則表現出微弱甚至負面的影響。探討中心、廣泛認可的概念的論文往往會吸引更多引用，突顯出推動發表成功和長期學術影響的因素之間的差異。最後，填補探索不足的概念對時，主要是建立在因果方法的基礎上，但這種差距填補並未表現出與未來引用的一致關聯。總的來說，我們的研究結果表明，方法論嚴謹性和因果創新是學術認可的主要驅動力，但持續的影響可能需要平衡新穎貢獻與融入既定的經濟論述中的概念整合。</paragraph>

##### **A Foundational Generative Model for Breast Ultrasound Image Analysis**
2501.06869v1 by Haojun Yu, Youcheng Li, Nan Zhang, Zihan Niu, Xuantong Gong, Yanwen Luo, Haotian Ye, Siyu He, Quanlin Wu, Wangyan Qin, Mengyuan Zhou, Jie Han, Jia Tao, Ziwei Zhao, Di Dai, Di He, Dong Wang, Binghui Tang, Ling Huo, James Zou, Qingli Zhu, Yong Wang, Liwei Wang

Foundational models have emerged as powerful tools for addressing various
tasks in clinical settings. However, their potential development to breast
ultrasound analysis remains untapped. In this paper, we present BUSGen, the
first foundational generative model specifically designed for breast ultrasound
image analysis. Pretrained on over 3.5 million breast ultrasound images, BUSGen
has acquired extensive knowledge of breast structures, pathological features,
and clinical variations. With few-shot adaptation, BUSGen can generate
repositories of realistic and informative task-specific data, facilitating the
development of models for a wide range of downstream tasks. Extensive
experiments highlight BUSGen's exceptional adaptability, significantly
exceeding real-data-trained foundational models in breast cancer screening,
diagnosis, and prognosis. In breast cancer early diagnosis, our approach
outperformed all board-certified radiologists (n=9), achieving an average
sensitivity improvement of 16.5% (P-value<0.0001). Additionally, we
characterized the scaling effect of using generated data which was as effective
as the collected real-world data for training diagnostic models. Moreover,
extensive experiments demonstrated that our approach improved the
generalization ability of downstream models. Importantly, BUSGen protected
patient privacy by enabling fully de-identified data sharing, making progress
forward in secure medical data utilization. An online demo of BUSGen is
available at https://aibus.bio.

摘要：基礎模型已成為解決臨床環境中各種任務的強大工具。然而，它們在乳房超音波分析的潛在發展仍未開發。在本文中，我們提出 BUSGen，這是第一個專門設計用於乳房超音波影像分析的基礎生成模型。BUSGen 在超過 350 萬張乳房超音波影像上進行預訓練，已獲得乳房結構、病理特徵和臨床變異的廣泛知識。透過少量適應，BUSGen 可以產生逼真且具有資訊性的特定任務資料儲存庫，促進開發廣泛的下游任務模型。廣泛的實驗突顯了 BUSGen 的出色適應性，在乳癌篩檢、診斷和預後方面顯著超越以真實資料訓練的基礎模型。在乳癌早期診斷中，我們的做法優於所有通過認證的放射科醫師 (n=9)，平均敏感度提高了 16.5%（P 值 <0.0001）。此外，我們描述了使用生成資料的規模效應，其與收集的真實世界資料一樣有效，可用於訓練診斷模型。此外，廣泛的實驗證明，我們的做法改善了下游模型的泛化能力。重要的是，BUSGen 保護了患者隱私，因為它能夠完全去識別資料共享，在安全醫療資料利用方面取得進展。BUSGen 的線上示範可在 https://aibus.bio 取得。

##### **Transfer Learning of Tabular Data by Finetuning Large Language Models**
2501.06863v1 by Shourav B. Rabbani, Ibna Kowsar, Manar D. Samad

Despite the artificial intelligence (AI) revolution, deep learning has yet to
achieve much success with tabular data due to heterogeneous feature space and
limited sample sizes without viable transfer learning. The new era of
generative AI, powered by large language models (LLM), brings unprecedented
learning opportunities to diverse data and domains. This paper investigates the
effectiveness of an LLM application programming interface (API) and transfer
learning of LLM in tabular data classification. LLM APIs respond to input text
prompts with tokenized data and instructions, whereas transfer learning
finetunes an LLM for a target classification task. This paper proposes an
end-to-end finetuning of LLM to demonstrate cross-data transfer learning on ten
benchmark data sets when large pre-trained tabular data models do not exist to
facilitate transfer learning. The proposed LLM finetuning method outperforms
state-of-the-art machine and deep learning methods on tabular data with less
than ten features - a standard feature size for tabular data sets. The transfer
learning approach uses a fraction of the computational cost of other deep
learning or API-based solutions while ensuring competitive or superior
classification performance.

摘要：儘管有 AI 革命，深度學習仍未在表格資料中獲得巨大成功，原因在於異質特徵空間和沒有可行轉移學習的有限樣本大小。由大型語言模型 (LLM) 驅動的生成式 AI 新時代，為各種資料和領域帶來前所未有的學習機會。本文探討 LLM 應用程式介面 (API) 的效能和 LLM 在表格資料分類中的轉移學習。LLM API 會回應輸入文字提示，並提供記號化資料和說明，而轉移學習則會微調 LLM 以進行目標分類任務。本文提出 LLM 的端對端微調，以在沒有大型預訓練表格資料模型可用於促進轉移學習時，展示跨資料轉移學習的十個基準資料集。所提出的 LLM 微調方法在特徵少於十個（表格資料集的標準特徵大小）的表格資料中，優於最先進的機器學習和深度學習方法。轉移學習方法使用的運算成本，僅為其他深度學習或基於 API 的解決方案的一小部分，同時確保具有競爭力或更佳的分類效能。

##### **LarvSeg: Exploring Image Classification Data For Large Vocabulary Semantic Segmentation via Category-wise Attentive Classifier**
2501.06862v1 by Haojun Yu, Di Dai, Ziwei Zhao, Di He, Han Hu, Liwei Wang

Scaling up the vocabulary of semantic segmentation models is extremely
challenging because annotating large-scale mask labels is labour-intensive and
time-consuming. Recently, language-guided segmentation models have been
proposed to address this challenge. However, their performance drops
significantly when applied to out-of-distribution categories. In this paper, we
propose a new large vocabulary semantic segmentation framework, called LarvSeg.
Different from previous works, LarvSeg leverages image classification data to
scale the vocabulary of semantic segmentation models as large-vocabulary
classification datasets usually contain balanced categories and are much easier
to obtain. However, for classification tasks, the category is image-level,
while for segmentation we need to predict the label at pixel level. To address
this issue, we first propose a general baseline framework to incorporate
image-level supervision into the training process of a pixel-level segmentation
model, making the trained network perform semantic segmentation on newly
introduced categories in the classification data. We then observe that a model
trained on segmentation data can group pixel features of categories beyond the
training vocabulary. Inspired by this finding, we design a category-wise
attentive classifier to apply supervision to the precise regions of
corresponding categories to improve the model performance. Extensive
experiments demonstrate that LarvSeg significantly improves the large
vocabulary semantic segmentation performance, especially in the categories
without mask labels. For the first time, we provide a 21K-category semantic
segmentation model with the help of ImageNet21K. The code is available at
https://github.com/HaojunYu1998/large_voc_seg.

摘要：<paragraph>擴展語意分割模型的詞彙極具挑戰性，因為標註大規模遮罩標籤需要大量勞動力且耗時。最近，語言引導分割模型已被提出以解決此挑戰。然而，當應用於分布外類別時，其效能會顯著下降。在本文中，我們提出一個新的大型詞彙語意分割框架，稱為 LarvSeg。與先前的研究不同，LarvSeg 利用影像分類資料來擴展語意分割模型的詞彙，因為大型詞彙分類資料集通常包含平衡的類別且更容易取得。然而，對於分類任務，類別是影像層級的，而對於分割，我們需要在畫素層級預測標籤。為了解決這個問題，我們首先提出一個通用的基準架構，將影像層級監督納入畫素層級分割模型的訓練過程中，讓訓練好的網路對分類資料中新引入的類別執行語意分割。然後我們觀察到，在分割資料上訓練的模型可以將類別的畫素特徵分組到訓練詞彙之外。受到這個發現的啟發，我們設計了一個類別明智的注意力分類器，將監督應用於對應類別的精確區域以改善模型效能。廣泛的實驗證明，LarvSeg 大幅改善了大型詞彙語意分割效能，特別是在沒有遮罩標籤的類別中。我們首次在 ImageNet21K 的幫助下提供了 21K 類別的語意分割模型。程式碼可在 https://github.com/HaojunYu1998/large_voc_seg 取得。</paragraph>

##### **A Comprehensive Evaluation of Large Language Models on Mental Illnesses in Arabic Context**
2501.06859v1 by Noureldin Zahran, Aya E. Fouda, Radwa J. Hanafy, Mohammed E. Fouda

Mental health disorders pose a growing public health concern in the Arab
world, emphasizing the need for accessible diagnostic and intervention tools.
Large language models (LLMs) offer a promising approach, but their application
in Arabic contexts faces challenges including limited labeled datasets,
linguistic complexity, and translation biases. This study comprehensively
evaluates 8 LLMs, including general multi-lingual models, as well as bi-lingual
ones, on diverse mental health datasets (such as AraDepSu, Dreaddit, MedMCQA),
investigating the impact of prompt design, language configuration (native
Arabic vs. translated English, and vice versa), and few-shot prompting on
diagnostic performance. We find that prompt engineering significantly
influences LLM scores mainly due to reduced instruction following, with our
structured prompt outperforming a less structured variant on multi-class
datasets, with an average difference of 14.5\%. While language influence on
performance was modest, model selection proved crucial: Phi-3.5 MoE excelled in
balanced accuracy, particularly for binary classification, while Mistral NeMo
showed superior performance in mean absolute error for severity prediction
tasks. Few-shot prompting consistently improved performance, with particularly
substantial gains observed for GPT-4o Mini on multi-class classification,
boosting accuracy by an average factor of 1.58. These findings underscore the
importance of prompt optimization, multilingual analysis, and few-shot learning
for developing culturally sensitive and effective LLM-based mental health tools
for Arabic-speaking populations.

摘要：<paragraph>心理健康障礙在阿拉伯世界中構成日益嚴重的公共衛生問題，強調了對可及的診斷和干預工具的需求。大型語言模型 (LLM) 提供了一種有前途的方法，但它們在阿拉伯語環境中的應用面臨著挑戰，包括標記資料集有限、語言複雜性和翻譯偏差。本研究全面評估了 8 個 LLM，包括一般多語言模型和雙語模型，在不同的心理健康資料集（例如 AraDepSu、Dreaddit、MedMCQA）上，探討提示設計、語言配置（阿拉伯語原文與翻譯後的英語，反之亦然）和少次提示對診斷表現的影響。我們發現提示工程顯著影響 LLM 分數，主要是由於減少了說明遵循，我們的結構化提示在多類資料集上優於結構較不嚴謹的變體，平均差異為 14.5%。雖然語言對表現的影響不大，但模型選擇被證明至關重要：Phi-3.5 MoE 在平衡準確度方面表現出色，特別是在二元分類方面，而 Mistral NeMo 在嚴重性預測任務的平均絕對誤差方面表現出優異的表現。少次提示始終改善表現，特別是在 GPT-4o Mini 上觀察到多類分類的顯著增益，將準確度提高了平均 1.58 倍。這些發現強調了提示最佳化、多語言分析和少次學習對於開發適合文化且有效的基於 LLM 的心理健康工具以服務阿拉伯語人口的重要性。</paragraph>

##### **What Is a Counterfactual Cause in Action Theories?**
2501.06857v1 by Daxin Liu, Vaishak Belle

Since the proposal by Halpern and Pearl, reasoning about actual causality has
gained increasing attention in artificial intelligence, ranging from domains
such as model-checking and verification to reasoning about actions and
knowledge. More recently, Batusov and Soutchanski proposed a notion of actual
achievement cause in the situation calculus, amongst others, they can determine
the cause of quantified effects in a given action history. While intuitively
appealing, this notion of cause is not defined in a counterfactual perspective.
In this paper, we propose a notion of cause based on counterfactual analysis.
In the context of action history, we show that our notion of cause generalizes
naturally to a notion of achievement cause. We analyze the relationship between
our notion of the achievement cause and the achievement cause by Batusov and
Soutchanski. Finally, we relate our account of cause to Halpern and Pearl's
account of actual causality. Particularly, we note some nuances in applying a
counterfactual viewpoint to disjunctive goals, a common thorn to definitions of
actual causes.

摘要：自 Halpern 和 Pearl 提出以來，關於實際因果關係的推理在人工智慧中獲得越來越多的關注，範圍從模型檢查和驗證等領域到關於動作和知識的推理。最近，Batusov 和 Soutchanski 提出了一個關於情境演算中的實際達成原因的概念，其中，他們可以確定特定動作歷史中量化效果的原因。儘管直觀上很有吸引力，但這個原因的概念並未在反事實觀點中定義。在本文中，我們提出了一個基於反事實分析的原因概念。在動作歷史的背景下，我們表明我們的原因概念自然而然地概括為達成原因的概念。我們分析了我們對達成原因的概念與 Batusov 和 Soutchanski 的達成原因之間的關係。最後，我們將我們對原因的說明與 Halpern 和 Pearl 對實際因果關係的說明聯繫起來。特別是，我們注意到在將反事實觀點應用於析取目標（實際原因定義的常見難題）時的一些細微差別。

##### **A General Framework for Inference-time Scaling and Steering of Diffusion Models**
2501.06848v1 by Raghav Singhal, Zachary Horvitz, Ryan Teehan, Mengye Ren, Zhou Yu, Kathleen McKeown, Rajesh Ranganath

Diffusion models produce impressive results in modalities ranging from images
and video to protein design and text. However, generating samples with
user-specified properties remains a challenge. Recent research proposes
fine-tuning models to maximize rewards that capture desired properties, but
these methods require expensive training and are prone to mode collapse. In
this work, we propose Feynman Kac (FK) steering, an inference-time framework
for steering diffusion models with reward functions. FK steering works by
sampling a system of multiple interacting diffusion processes, called
particles, and resampling particles at intermediate steps based on scores
computed using functions called potentials. Potentials are defined using
rewards for intermediate states and are selected such that a high value
indicates that the particle will yield a high-reward sample. We explore various
choices of potentials, intermediate rewards, and samplers. We evaluate FK
steering on text-to-image and text diffusion models. For steering text-to-image
models with a human preference reward, we find that FK steering a 0.8B
parameter model outperforms a 2.6B parameter fine-tuned model on prompt
fidelity, with faster sampling and no training. For steering text diffusion
models with rewards for text quality and specific text attributes, we find that
FK steering generates lower perplexity, more linguistically acceptable outputs
and enables gradient-free control of attributes like toxicity. Our results
demonstrate that inference-time scaling and steering of diffusion models, even
with off-the-shelf rewards, can provide significant sample quality gains and
controllability benefits. Code is available at
https://github.com/zacharyhorvitz/Fk-Diffusion-Steering .

摘要：擴散模型在影像、影片、蛋白設計和文字等模式中產生令人印象深刻的結果。然而，產生具有使用者指定屬性的樣本仍然是一項挑戰。最近的研究提出微調模型以最大化捕捉所需屬性的獎勵，但這些方法需要昂貴的訓練且容易崩潰。在這項工作中，我們提出費曼卡克 (FK) 導引，一個用於使用獎勵函數導引擴散模型的推論時間架構。FK 導引透過取樣一個由多個交互擴散過程組成的系統（稱為粒子）來運作，並根據使用稱為勢函數的函數計算的分數在中間步驟中重新取樣粒子。勢函數使用中間狀態的獎勵來定義，並選擇一個高值表示粒子將產生高獎勵樣本。我們探索各種勢函數、中間獎勵和取樣器的選擇。我們評估文本到影像和文本擴散模型上的 FK 導引。對於使用人類偏好獎勵來導引文本到影像模型，我們發現 FK 導引一個 0.8B 參數模型在提示保真度上優於一個 2.6B 參數微調模型，且取樣速度更快且無需訓練。對於使用文本品質和特定文本屬性獎勵來導引文本擴散模型，我們發現 FK 導引產生較低的困惑度、更具語言可接受性的輸出，並能對毒性等屬性進行無梯度控制。我們的結果證明，即使使用現成的獎勵，擴散模型的推論時間縮放和導引也能提供顯著的樣本品質提升和可控性優勢。程式碼可在 https://github.com/zacharyhorvitz/Fk-Diffusion-Steering 取得。

##### **SPAM: Spike-Aware Adam with Momentum Reset for Stable LLM Training**
2501.06842v1 by Tianjin Huang, Ziquan Zhu, Gaojie Jin, Lu Liu, Zhangyang Wang, Shiwei Liu

Large Language Models (LLMs) have demonstrated exceptional performance across
diverse tasks, yet their training remains highly resource-intensive and
susceptible to critical challenges such as training instability. A predominant
source of this instability stems from gradient and loss spikes, which disrupt
the learning process, often leading to costly interventions like checkpoint
recovery and experiment restarts, further amplifying inefficiencies. This paper
presents a comprehensive investigation into gradient spikes observed during LLM
training, revealing their prevalence across multiple architectures and
datasets. Our analysis shows that these spikes can be up to $1000\times$ larger
than typical gradients, substantially deteriorating model performance. To
address this issue, we propose Spike-Aware Adam with Momentum Reset SPAM, a
novel optimizer designed to counteract gradient spikes through momentum reset
and spike-aware gradient clipping. Extensive experiments, including both
pre-training and fine-tuning, demonstrate that SPAM consistently surpasses Adam
and its variants across various tasks, including (1) LLM pre-training from 60M
to 1B, (2) 4-bit LLM pre-training,(3) reinforcement learning, and (4) Time
Series Forecasting. Additionally, SPAM facilitates memory-efficient training by
enabling sparse momentum, where only a subset of momentum terms are maintained
and updated. When operating under memory constraints, SPAM outperforms
state-of-the-art memory-efficient optimizers such as GaLore and Adam-Mini. Our
work underscores the importance of mitigating gradient spikes in LLM training
and introduces an effective optimization strategy that enhances both training
stability and resource efficiency at scale. Code is available at
https://github.com/TianjinYellow/SPAM-Optimizer.git

摘要：大型語言模型 (LLM) 在各種任務中表現出非凡的性能，但其訓練仍然高度依賴資源，且容易受到訓練不穩定等關鍵挑戰的影響。這種不穩定的主要來源來自於梯度和損失尖峰，這會破壞學習過程，通常導致代價高昂的介入，如檢查點恢復和實驗重新啟動，進一步擴大低效率。本文對 LLM 訓練期間觀察到的梯度尖峰進行了全面調查，揭示了它們在多個架構和數據集中的普遍性。我們的分析表明，這些尖峰可能比典型梯度大 $1000\times$，這會大幅降低模型性能。為了解決這個問題，我們提出了帶動量重置的 Spike-Aware Adam（SPAM），這是一種新穎的優化器，旨在通過動量重置和感知尖峰的梯度裁剪來抵消梯度尖峰。包括預訓練和微調在內的廣泛實驗表明，SPAM 在各種任務中始終優於 Adam 及其變體，包括 (1) 從 60M 到 1B 的 LLM 預訓練，(2) 4 位元 LLM 預訓練，(3) 強化學習，以及 (4) 時間序列預測。此外，SPAM 通過啟用稀疏動量（其中只維護和更新動量項的子集）來促進記憶體高效訓練。在記憶體受限的情況下，SPAM 優於最先進的記憶體高效優化器，例如 GaLore 和 Adam-Mini。我們的研究強調了減輕 LLM 訓練中梯度尖峰的重要性，並引入了一種有效的最佳化策略，它可以大規模提升訓練穩定性和資源效率。程式碼可在 https://github.com/TianjinYellow/SPAM-Optimizer.git 取得

##### **An efficient approach to represent enterprise web application structure using Large Language Model in the service of Intelligent Quality Engineering**
2501.06837v1 by Zaber Al Hassan Ayon, Gulam Husain, Roshankumar Bisoi, Waliur Rahman, Dr Tom Osborn

This paper presents a novel approach to represent enterprise web application
structures using Large Language Models (LLMs) to enable intelligent quality
engineering at scale. We introduce a hierarchical representation methodology
that optimizes the few-shot learning capabilities of LLMs while preserving the
complex relationships and interactions within web applications. The approach
encompasses five key phases: comprehensive DOM analysis, multi-page synthesis,
test suite generation, execution, and result analysis. Our methodology
addresses existing challenges around usage of Generative AI techniques in
automated software testing by developing a structured format that enables LLMs
to understand web application architecture through in-context learning. We
evaluated our approach using two distinct web applications: an e-commerce
platform (Swag Labs) and a healthcare application (MediBox) which is deployed
within Atalgo engineering environment. The results demonstrate success rates of
90\% and 70\%, respectively, in achieving automated testing, with high
relevance scores for test cases across multiple evaluation criteria. The
findings suggest that our representation approach significantly enhances LLMs'
ability to generate contextually relevant test cases and provide better quality
assurance overall, while reducing the time and effort required for testing.

摘要：本文提出一個創新的方法，使用大型語言模型 (LLM) 來表示企業 Web 應用程式結構，以在規模上實現智慧品質工程。我們引入一個階層表示方法，它最佳化了 LLM 的少量學習能力，同時保留 Web 應用程式中的複雜關係和互動。此方法包含五個關鍵階段：全面的 DOM 分析、多頁合成、測試套件產生、執行和結果分析。我們的做法解決了自動化軟體測試中生成式 AI 技術使用方面的現有挑戰，方法是開發一種結構化格式，讓 LLM 能透過情境學習來了解 Web 應用程式架構。我們使用兩個不同的 Web 應用程式來評估我們的做法：一個電子商務平台 (Swag Labs) 和一個醫療保健應用程式 (MediBox)，它部署在 Atalgo 工程環境中。結果顯示，在自動化測試中分別達到 90% 和 70% 的成功率，在多個評估標準中，測試案例都有很高的相關性分數。研究結果表明，我們的表示方法顯著增強了 LLM 產生與情境相關的測試案例的能力，並提供了更好的整體品質保證，同時減少了測試所需的時間和精力。

##### **LLMs Model Non-WEIRD Populations: Experiments with Synthetic Cultural Agents**
2501.06834v1 by Augusto Gonzalez-Bonorino, Monica Capra, Emilio Pantoja

Despite its importance, studying economic behavior across diverse, non-WEIRD
(Western, Educated, Industrialized, Rich, and Democratic) populations presents
significant challenges. We address this issue by introducing a novel
methodology that uses Large Language Models (LLMs) to create synthetic cultural
agents (SCAs) representing these populations. We subject these SCAs to classic
behavioral experiments, including the dictator and ultimatum games. Our results
demonstrate substantial cross-cultural variability in experimental behavior.
Notably, for populations with available data, SCAs' behaviors qualitatively
resemble those of real human subjects. For unstudied populations, our method
can generate novel, testable hypotheses about economic behavior. By integrating
AI into experimental economics, this approach offers an effective and ethical
method to pilot experiments and refine protocols for hard-to-reach populations.
Our study provides a new tool for cross-cultural economic studies and
demonstrates how LLMs can help experimental behavioral research.

摘要：儘管經濟行為研究在多元的非 WEIRD（西方、受過教育、工業化、富裕且民主）族群中非常重要，但仍面臨重大的挑戰。我們透過引進一種創新的方法來解決此問題，該方法使用大型語言模型 (LLM) 來建立代表這些族群的合成文化代理人 (SCA)。我們讓這些 SCA 參與經典行為實驗，包括獨裁者遊戲和最後通牒遊戲。我們的結果證明了實驗行為中存在顯著的跨文化變異性。值得注意的是，對於有可用資料的族群，SCA 的行為在質量上類似於真實的人類受試者。對於未研究的族群，我們的方法可以產生關於經濟行為的新穎且可測試的假設。透過將人工智慧整合到實驗經濟學中，此方法提供了一種有效且合乎道德的方式，可以試驗實驗並改進難以接觸族群的協定。我們的研究為跨文化經濟研究提供了新的工具，並展示了 LLM 如何協助實驗行為研究。

##### **Towards Counterfactual and Contrastive Explainability and Transparency of DCNN Image Classifiers**
2501.06831v1 by Syed Ali Tariq, Tehseen Zia, Mubeen Ghafoor

Explainability of deep convolutional neural networks (DCNNs) is an important
research topic that tries to uncover the reasons behind a DCNN model's
decisions and improve their understanding and reliability in high-risk
environments. In this regard, we propose a novel method for generating
interpretable counterfactual and contrastive explanations for DCNN models. The
proposed method is model intrusive that probes the internal workings of a DCNN
instead of altering the input image to generate explanations. Given an input
image, we provide contrastive explanations by identifying the most important
filters in the DCNN representing features and concepts that separate the
model's decision between classifying the image to the original inferred class
or some other specified alter class. On the other hand, we provide
counterfactual explanations by specifying the minimal changes necessary in such
filters so that a contrastive output is obtained.
  Using these identified filters and concepts, our method can provide
contrastive and counterfactual reasons behind a model's decisions and makes the
model more transparent. One of the interesting applications of this method is
misclassification analysis, where we compare the identified concepts from a
particular input image and compare them with class-specific concepts to
establish the validity of the model's decisions. The proposed method is
compared with state-of-the-art and evaluated on the Caltech-UCSD Birds (CUB)
2011 dataset to show the usefulness of the explanations provided.

摘要：深度卷積神經網路 (DCNN) 的可解釋性是一個重要的研究主題，它試圖揭開 DCNN 模型決策背後的原因，並提高它們在高風險環境中的理解度和可靠性。在這方面，我們提出了一種新的方法，用於為 DCNN 模型生成可解釋的反事實和對比解釋。所提出的方法是模型侵入性的，它探測 DCNN 的內部運作，而不是改變輸入影像來生成解釋。給定一個輸入影像，我們通過識別 DCNN 中表示特徵和概念的最重要過濾器來提供對比解釋，這些特徵和概念區分了模型在將影像分類到原始推斷類別或其他一些指定替換類別之間的決策。另一方面，我們通過指定此類過濾器中必要的最小變更來提供反事實解釋，以便獲得對比輸出。使用這些識別的過濾器和概念，我們的方法可以提供模型決策背後對比和反事實的原因，並使模型更透明。此方法的其中一個有趣應用是錯誤分類分析，在其中我們比較從特定輸入影像識別的概念，並將它們與類別特定概念進行比較，以建立模型決策的有效性。將所提出的方法與最先進的方法進行比較，並在 Caltech-UCSD Birds (CUB) 2011 資料集上進行評估，以顯示所提供解釋的效用。

##### **Leveraging Taxonomy and LLMs for Improved Multimodal Hierarchical Classification**
2501.06827v1 by Shijing Chen, Mohamed Reda Bouadjenek, Shoaib Jameel, Usman Naseem, Basem Suleiman, Flora D. Salim, Hakim Hacid, Imran Razzak

Multi-level Hierarchical Classification (MLHC) tackles the challenge of
categorizing items within a complex, multi-layered class structure. However,
traditional MLHC classifiers often rely on a backbone model with independent
output layers, which tend to ignore the hierarchical relationships between
classes. This oversight can lead to inconsistent predictions that violate the
underlying taxonomy. Leveraging Large Language Models (LLMs), we propose a
novel taxonomy-embedded transitional LLM-agnostic framework for multimodality
classification. The cornerstone of this advancement is the ability of models to
enforce consistency across hierarchical levels. Our evaluations on the MEP-3M
dataset - a multi-modal e-commerce product dataset with various hierarchical
levels - demonstrated a significant performance improvement compared to
conventional LLM structures.

摘要：多層級階層分類 (MLHC) 應對了在複雜、多層級類別結構中對項目進行分類的挑戰。然而，傳統的 MLHC 分類器通常依賴於具有獨立輸出層的主幹模型，這往往會忽略類別之間的階層關係。這種疏忽可能導致不一致的預測，從而違反底層分類法。利用大型語言模型 (LLM)，我們提出了一個新穎的分類嵌入過渡式 LLM 不可知框架，用於多模態分類。這一進步的基石在於模型在階層級別間執行一致性的能力。我們對 MEP-3M 資料集（一個具有多種階層級別的多模態電子商務產品資料集）的評估表明，與傳統 LLM 結構相比，其性能有了顯著提升。

##### **Correcting Annotator Bias in Training Data: Population-Aligned Instance Replication (PAIR)**
2501.06826v1 by Stephanie Eckman, Bolei Ma, Christoph Kern, Rob Chew, Barbara Plank, Frauke Kreuter

Models trained on crowdsourced labels may not reflect broader population
views when annotator pools are not representative. Since collecting
representative labels is challenging, we propose Population-Aligned Instance
Replication (PAIR), a method to address this bias through statistical
adjustment. Using a simulation study of hate speech and offensive language
detection, we create two types of annotators with different labeling tendencies
and generate datasets with varying proportions of the types. Models trained on
unbalanced annotator pools show poor calibration compared to those trained on
representative data. However, PAIR, which duplicates labels from
underrepresented annotator groups to match population proportions,
significantly reduces bias without requiring new data collection. These results
suggest statistical techniques from survey research can help align model
training with target populations even when representative annotator pools are
unavailable. We conclude with three practical recommendations for improving
training data quality.

摘要：由群眾外包標籤訓練的模型可能無法反映更廣泛的人口觀點，因為註解者群體並非具有代表性。由於收集具有代表性的標籤具有挑戰性，我們提出了人口對齊實例複製 (PAIR)，這是一種透過統計調整來解決此偏差的方法。使用仇恨言論和攻擊性語言偵測的模擬研究，我們建立了兩種具有不同標籤傾向的註解者，並產生具有不同比例類型的資料集。在不平衡的註解者群體上訓練的模型與在具有代表性的資料上訓練的模型相比，顯示出較差的校準。然而，PAIR 從代表性不足的註解者群組複製標籤以匹配人口比例，大幅減少了偏差，而不需要收集新的資料。這些結果表明，來自調查研究的統計技術有助於將模型訓練與目標人口對齊，即使無法取得具有代表性的註解者群體。我們總結了三項改善訓練資料品質的實用建議。

##### **Event Argument Extraction with Enriched Prompts**
2501.06825v1 by Chen Liang

This work aims to delve deeper into prompt-based event argument extraction
(EAE) models. We explore the impact of incorporating various types of
information into the prompt on model performance, including trigger, other role
arguments for the same event, and role arguments across multiple events within
the same document. Further, we provide the best possible performance that the
prompt-based EAE model can attain and demonstrate such models can be further
optimized from the perspective of the training objective. Experiments are
carried out on three small language models and two large language models in
RAMS.

摘要：此工作旨在深入探討基於提示的事件論元抽取 (EAE) 模型。我們探討了將各種資訊納入提示中對模型效能的影響，包括觸發器、相同事件的其他角色論元，以及同一文件中多個事件的角色論元。此外，我們提供了基於提示的 EAE 模型所能達到的最佳效能，並展示了此類模型可以從訓練目標的角度進一步最佳化。實驗在 RAMS 中的三個小型語言模型和兩個大型語言模型上進行。

##### **MEXA-CTP: Mode Experts Cross-Attention for Clinical Trial Outcome Prediction**
2501.06823v1 by Yiqing Zhang, Xiaozhong Liu, Fabricio Murai

Clinical trials are the gold standard for assessing the effectiveness and
safety of drugs for treating diseases. Given the vast design space of drug
molecules, elevated financial cost, and multi-year timeline of these trials,
research on clinical trial outcome prediction has gained immense traction.
Accurate predictions must leverage data of diverse modes such as drug
molecules, target diseases, and eligibility criteria to infer successes and
failures. Previous Deep Learning approaches for this task, such as HINT, often
require wet lab data from synthesized molecules and/or rely on prior knowledge
to encode interactions as part of the model architecture. To address these
limitations, we propose a light-weight attention-based model, MEXA-CTP, to
integrate readily-available multi-modal data and generate effective
representations via specialized modules dubbed "mode experts", while avoiding
human biases in model design. We optimize MEXA-CTP with the Cauchy loss to
capture relevant interactions across modes. Our experiments on the Trial
Outcome Prediction (TOP) benchmark demonstrate that MEXA-CTP improves upon
existing approaches by, respectively, up to 11.3% in F1 score, 12.2% in PR-AUC,
and 2.5% in ROC-AUC, compared to HINT. Ablation studies are provided to
quantify the effectiveness of each component in our proposed method.

摘要：臨床試驗是評估治療疾病的藥物有效性和安全性的黃金標準。鑑於藥物分子的廣泛設計空間、高昂的財務成本和這些試驗多年的時間表，臨床試驗結果預測的研究獲得了巨大的關注。準確的預測必須利用藥物分子、目標疾病和符合資格標準等多種模式的數據來推斷成功和失敗。此任務的先前深度學習方法（例如 HINT）通常需要合成分子的濕實驗室數據和/或依賴於先驗知識將交互編碼為模型架構的一部分。為了解決這些限制，我們提出了一個輕量級的基於注意力的模型 MEXA-CTP，以整合現成的多模式數據並通過稱為「模式專家」的專用模組產生有效的表示，同時避免模型設計中的人為偏差。我們使用柯西損失函數最佳化 MEXA-CTP，以捕捉跨模式相關的交互。我們在試驗結果預測 (TOP) 基準上的實驗表明，與 HINT 相比，MEXA-CTP 分別在 F1 分數上提高了 11.3%、PR-AUC 上提高了 12.2%、ROC-AUC 上提高了 2.5%。提供了消融研究來量化我們提出的方法中每個組件的有效性。

