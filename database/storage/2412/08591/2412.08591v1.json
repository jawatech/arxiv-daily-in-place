{"2412.08591": {"publish_time": "2024-12-11", "title": "RoomTour3D: Geometry-Aware Video-Instruction Tuning for Embodied Navigation", "paper_summary": "Vision-and-Language Navigation (VLN) suffers from the limited diversity and\nscale of training data, primarily constrained by the manual curation of\nexisting simulators. To address this, we introduce RoomTour3D, a\nvideo-instruction dataset derived from web-based room tour videos that capture\nreal-world indoor spaces and human walking demonstrations. Unlike existing VLN\ndatasets, RoomTour3D leverages the scale and diversity of online videos to\ngenerate open-ended human walking trajectories and open-world navigable\ninstructions. To compensate for the lack of navigation data in online videos,\nwe perform 3D reconstruction and obtain 3D trajectories of walking paths\naugmented with additional information on the room types, object locations and\n3D shape of surrounding scenes. Our dataset includes $\\sim$100K open-ended\ndescription-enriched trajectories with $\\sim$200K instructions, and 17K\naction-enriched trajectories from 1847 room tour environments. We demonstrate\nexperimentally that RoomTour3D enables significant improvements across multiple\nVLN tasks including CVDN, SOON, R2R, and REVERIE. Moreover, RoomTour3D\nfacilitates the development of trainable zero-shot VLN agents, showcasing the\npotential and challenges of advancing towards open-world navigation.", "paper_summary_zh": "\u8996\u89ba\u8a9e\u8a00\u5c0e\u822a (VLN) \u53d7\u5230\u8a13\u7df4\u8cc7\u6599\u7684\u591a\u6a23\u6027\u548c\u898f\u6a21\u9650\u5236\uff0c\u9019\u4e3b\u8981\u662f\u53d7\u5230\u73fe\u6709\u6a21\u64ec\u5668\u624b\u52d5\u7b56\u5283\u7684\u7d04\u675f\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86 RoomTour3D\uff0c\u4e00\u500b\u5f9e\u7db2\u8def\u4e0a\u7684\u623f\u9593\u5c0e\u89bd\u5f71\u7247\u4e2d\u884d\u751f\u7684\u5f71\u7247\u6307\u4ee4\u8cc7\u6599\u96c6\uff0c\u8a72\u8cc7\u6599\u96c6\u64f7\u53d6\u4e86\u771f\u5be6\u4e16\u754c\u7684\u5ba4\u5167\u7a7a\u9593\u548c\u4eba\u985e\u884c\u8d70\u793a\u7bc4\u3002\u8207\u73fe\u6709\u7684 VLN \u8cc7\u6599\u96c6\u4e0d\u540c\uff0cRoomTour3D \u5229\u7528\u7dda\u4e0a\u5f71\u7247\u7684\u898f\u6a21\u548c\u591a\u6a23\u6027\u4f86\u7522\u751f\u958b\u653e\u5f0f\u7684\u884c\u8d70\u8ecc\u8de1\u548c\u958b\u653e\u4e16\u754c\u7684\u5c0e\u822a\u6307\u4ee4\u3002\u70ba\u4e86\u5f4c\u88dc\u7dda\u4e0a\u5f71\u7247\u4e2d\u5c0e\u822a\u8cc7\u6599\u7684\u4e0d\u8db3\uff0c\u6211\u5011\u57f7\u884c 3D \u91cd\u5efa\uff0c\u4e26\u53d6\u5f97\u884c\u8d70\u8def\u5f91\u7684 3D \u8ecc\u8de1\uff0c\u4e26\u52a0\u4e0a\u623f\u9593\u985e\u578b\u3001\u7269\u4ef6\u4f4d\u7f6e\u548c\u5468\u570d\u5834\u666f\u7684 3D \u5f62\u72c0\u7b49\u984d\u5916\u8cc7\u8a0a\u3002\u6211\u5011\u7684\u8cc7\u6599\u96c6\u5305\u542b\u5927\u7d04 10 \u842c\u500b\u958b\u653e\u5f0f\u63cf\u8ff0\u8c50\u5bcc\u7684\u8ecc\u8de1\uff0c\u5176\u4e2d\u6709\u5927\u7d04 20 \u842c\u500b\u6307\u4ee4\uff0c\u4ee5\u53ca\u4f86\u81ea 1847 \u500b\u623f\u9593\u5c0e\u89bd\u74b0\u5883\u7684 1 \u842c 7 \u5343\u500b\u52d5\u4f5c\u8c50\u5bcc\u7684\u8ecc\u8de1\u3002\u6211\u5011\u900f\u904e\u5be6\u9a57\u8b49\u660e\uff0cRoomTour3D \u80fd\u5728\u591a\u500b VLN \u4efb\u52d9\u4e2d\u5e36\u4f86\u986f\u8457\u7684\u6539\u5584\uff0c\u5305\u62ec CVDN\u3001SOON\u3001R2R \u548c REVERIE\u3002\u6b64\u5916\uff0cRoomTour3D \u4fc3\u9032\u4e86\u53ef\u8a13\u7df4\u7684\u96f6\u6b21\u5b78\u7fd2 VLN \u4ee3\u7406\u7684\u958b\u767c\uff0c\u5c55\u793a\u4e86\u9081\u5411\u958b\u653e\u4e16\u754c\u5c0e\u822a\u7684\u6f5b\u529b\u548c\u6311\u6230\u3002", "author": "Mingfei Han et.al.", "authors": "Mingfei Han, Liang Ma, Kamila Zhumakhanova, Ekaterina Radionova, Jingyi Zhang, Xiaojun Chang, Xiaodan Liang, Ivan Laptev", "id": "2412.08591v1", "paper_url": "http://arxiv.org/abs/2412.08591v1", "repo": "null"}}