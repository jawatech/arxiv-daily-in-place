
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-04**|**RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins (early version)**|Yao Mu et.al.|[2409.02920v1](http://arxiv.org/abs/2409.02920v1)|null|
|**2024-09-04**|**UC-NeRF: Uncertainty-aware Conditional Neural Radiance Fields from Endoscopic Sparse Views**|Jiaxin Guo et.al.|[2409.02917v1](http://arxiv.org/abs/2409.02917v1)|[link](https://github.com/wrld/uc-nerf)|
|**2024-09-04**|**Masked Diffusion Models are Secretly Time-Agnostic Masked Models and Exploit Inaccurate Categorical Sampling**|Kaiwen Zheng et.al.|[2409.02908v1](http://arxiv.org/abs/2409.02908v1)|null|
|**2024-09-04**|**LongCite: Enabling LLMs to Generate Fine-grained Citations in Long-context QA**|Jiajie Zhang et.al.|[2409.02897v2](http://arxiv.org/abs/2409.02897v2)|null|
|**2024-09-04**|**LongLLaVA: Scaling Multi-modal LLMs to 1000 Images Efficiently via Hybrid Architecture**|Xidong Wang et.al.|[2409.02889v1](http://arxiv.org/abs/2409.02889v1)|[link](https://github.com/freedomintelligence/longllava)|
|**2024-09-04**|**Multi-stream deep learning framework to predict mild cognitive impairment with Rey Complex Figure Test**|Junyoung Park et.al.|[2409.02883v1](http://arxiv.org/abs/2409.02883v1)|null|
|**2024-09-04**|**Configurable Foundation Models: Building LLMs from a Modular Perspective**|Chaojun Xiao et.al.|[2409.02877v1](http://arxiv.org/abs/2409.02877v1)|null|
|**2024-09-04**|**Hybrid Imitation-Learning Motion Planner for Urban Driving**|Cristian Gariboldi et.al.|[2409.02871v1](http://arxiv.org/abs/2409.02871v1)|null|
|**2024-09-04**|**Historical German Text Normalization Using Type- and Token-Based Language Modeling**|Anton Ehrmanntraut et.al.|[2409.02841v1](http://arxiv.org/abs/2409.02841v1)|null|
|**2024-09-04**|**R2GQA: Retriever-Reader-Generator Question Answering System to Support Students Understanding Legal Regulations in Higher Education**|Phuc-Tinh Pham Do et.al.|[2409.02840v1](http://arxiv.org/abs/2409.02840v1)|null|
|**2024-09-04**|**Exploring Sentiment Dynamics and Predictive Behaviors in Cryptocurrency Discussions by Few-Shot Learning with Large Language Models**|Moein Shahiki Tash et.al.|[2409.02836v1](http://arxiv.org/abs/2409.02836v1)|null|
|**2024-09-04**|**CMM-Math: A Chinese Multimodal Math Dataset To Evaluate and Enhance the Mathematics Reasoning of Large Multimodal Models**|Wentao Liu et.al.|[2409.02834v1](http://arxiv.org/abs/2409.02834v1)|null|
|**2024-09-04**|**MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding Benchmark**|Xiang Yue et.al.|[2409.02813v1](http://arxiv.org/abs/2409.02813v1)|null|
|**2024-09-04**|**A hybrid FEM-PINN method for time-dependent partial differential equations**|Xiaodong Feng et.al.|[2409.02810v1](http://arxiv.org/abs/2409.02810v1)|null|
|**2024-09-04**|**Towards a Unified View of Preference Learning for Large Language Models: A Survey**|Bofei Gao et.al.|[2409.02795v1](http://arxiv.org/abs/2409.02795v1)|null|
|**2024-09-04**|**An incremental preference elicitation-based approach to learning potentially non-monotonic preferences in multi-criteria sorting**|Zhuolin Li et.al.|[2409.02760v1](http://arxiv.org/abs/2409.02760v1)|null|
|**2024-09-04**|**A Comparative Study of Pre-training and Self-training**|Yiheng Wang et.al.|[2409.02751v1](http://arxiv.org/abs/2409.02751v1)|null|
|**2024-09-04**|**Tractable Offline Learning of Regular Decision Processes**|Ahana Deb et.al.|[2409.02747v1](http://arxiv.org/abs/2409.02747v1)|null|
|**2024-09-04**|**Pooling And Attention: What Are Effective Designs For LLM-Based Embedding Models?**|Yixuan Tang et.al.|[2409.02727v2](http://arxiv.org/abs/2409.02727v2)|[link](https://github.com/yixuantt/poolingandattn)|
|**2024-09-04**|**Pre-training data selection for biomedical domain adaptation using journal impact metrics**|Mathieu Laï-king et.al.|[2409.02725v1](http://arxiv.org/abs/2409.02725v1)|null|
|**2024-09-04**|**Alignment-Aware Model Extraction Attacks on Large Language Models**|Zi Liang et.al.|[2409.02718v1](http://arxiv.org/abs/2409.02718v1)|null|
|**2024-09-04**|**A Data Selection Approach for Enhancing Low Resource Machine Translation Using Cross-Lingual Sentence Representations**|Nidhi Kowtal et.al.|[2409.02712v1](http://arxiv.org/abs/2409.02712v1)|null|
|**2024-09-04**|**Creating a Gen-AI based Track and Trace Assistant MVP (SuperTracy) for PostNL**|Mohammad Reshadati et.al.|[2409.02711v1](http://arxiv.org/abs/2409.02711v1)|null|
|**2024-09-04**|**Incorporating Like-Minded Peers to Overcome Friend Data Sparsity in Session-Based Social Recommendations**|Chunyan An et.al.|[2409.02702v1](http://arxiv.org/abs/2409.02702v1)|null|
|**2024-09-04**|**LLM-Assisted Visual Analytics: Opportunities and Challenges**|Maeve Hutchinson et.al.|[2409.02691v1](http://arxiv.org/abs/2409.02691v1)|null|
|**2024-09-04**|**Detecting Calls to Action in Multimodal Content: Analysis of the 2021 German Federal Election Campaign on Instagram**|Michael Achmann-Denkler et.al.|[2409.02690v1](http://arxiv.org/abs/2409.02690v1)|null|
|**2024-09-04**|**Deconfounded Causality-aware Parameter-Efficient Fine-Tuning for Problem-Solving Improvement of LLMs**|Ruoyu Wang et.al.|[2409.02686v1](http://arxiv.org/abs/2409.02686v1)|null|
|**2024-09-04**|**RouterRetriever: Exploring the Benefits of Routing over Multiple Expert Embedding Models**|Hyunji Lee et.al.|[2409.02685v1](http://arxiv.org/abs/2409.02685v1)|null|
|**2024-09-04**|**Neural Networks with LSTM and GRU in Modeling Active Fires in the Amazon**|Ramon Tavares et.al.|[2409.02681v1](http://arxiv.org/abs/2409.02681v1)|null|
|**2024-09-04**|**Causality-Aware Transformer Networks for Robotic Navigation**|Ruoyu Wang et.al.|[2409.02669v1](http://arxiv.org/abs/2409.02669v1)|null|
|**2024-09-04**|**Creating Domain-Specific Translation Memories for Machine Translation Fine-tuning: The TRENCARD Bilingual Cardiology Corpus**|Gokhan Dogru et.al.|[2409.02667v1](http://arxiv.org/abs/2409.02667v1)|null|
|**2024-09-04**|**PoseTalk: Text-and-Audio-based Pose Control and Motion Refinement for One-Shot Talking Head Generation**|Jun Ling et.al.|[2409.02657v1](http://arxiv.org/abs/2409.02657v1)|null|
|**2024-09-04**|**OpenFact at CheckThat! 2024: Combining Multiple Attack Methods for Effective Adversarial Text Generation**|Włodzimierz Lewoniewski et.al.|[2409.02649v2](http://arxiv.org/abs/2409.02649v2)|null|
|**2024-09-04**|**A Survey on Emergent Language**|Jannik Peters et.al.|[2409.02645v1](http://arxiv.org/abs/2409.02645v1)|null|
|**2024-09-04**|**Evaluating Environments Using Exploratory Agents**|Bobby Khaleque et.al.|[2409.02632v1](http://arxiv.org/abs/2409.02632v1)|null|
|**2024-09-04**|**AdvSecureNet: A Python Toolkit for Adversarial Machine Learning**|Melih Catal et.al.|[2409.02629v1](http://arxiv.org/abs/2409.02629v1)|[link](https://github.com/melihcatal/advsecurenet)|
|**2024-09-04**|**PUB: Plot Understanding Benchmark and Dataset for Evaluating Large Language Models on Synthetic Visual Data Interpretation**|Aneta Pawelec et.al.|[2409.02617v1](http://arxiv.org/abs/2409.02617v1)|null|
|**2024-09-04**|**SurgTrack: CAD-Free 3D Tracking of Real-world Surgical Instruments**|Wenwu Guo et.al.|[2409.02598v1](http://arxiv.org/abs/2409.02598v1)|[link](https://github.com/wenwucode/surgtrack)|
|**2024-09-04**|**Solving Video Inverse Problems Using Image Diffusion Models**|Taesung Kwon et.al.|[2409.02574v1](http://arxiv.org/abs/2409.02574v1)|null|
|**2024-09-04**|**Advancing Cyber Incident Timeline Analysis Through Rule Based AI and Large Language Models**|Fatma Yasmine Loumachi et.al.|[2409.02572v1](http://arxiv.org/abs/2409.02572v1)|null|
|**2024-09-04**|**More is More: Addition Bias in Large Language Models**|Luca Santagata et.al.|[2409.02569v1](http://arxiv.org/abs/2409.02569v1)|null|
|**2024-09-04**|**Vision-Language Navigation with Continual Learning**|Zhiyuan Li et.al.|[2409.02561v1](http://arxiv.org/abs/2409.02561v1)|null|
|**2024-09-04**|**Low-Resolution Object Recognition with Cross-Resolution Relational Contrastive Distillation**|Kangkai Zhang et.al.|[2409.02555v1](http://arxiv.org/abs/2409.02555v1)|null|
|**2024-09-04**|**A Sequential Decision-Making Model for Perimeter Identification**|Ayal Taitler et.al.|[2409.02549v2](http://arxiv.org/abs/2409.02549v2)|null|
|**2024-09-04**|**Understanding eGFR Trajectories and Kidney Function Decline via Large Multimodal Models**|Chih-Yuan Li et.al.|[2409.02530v1](http://arxiv.org/abs/2409.02530v1)|null|
|**2024-09-04**|**Cog-GA: A Large Language Models-based Generative Agent for Vision-Language Navigation in Continuous Environments**|Zhiyuan Li et.al.|[2409.02522v1](http://arxiv.org/abs/2409.02522v1)|null|
|**2024-09-04**|**Language is Scary when Over-Analyzed: Unpacking Implied Misogynistic Reasoning with Argumentation Theory-Driven Prompts**|Arianna Muti et.al.|[2409.02519v1](http://arxiv.org/abs/2409.02519v1)|null|
|**2024-09-04**|**Continual Diffuser (CoD): Mastering Continual Offline Reinforcement Learning with Experience Rehearsal**|Jifeng Hu et.al.|[2409.02512v1](http://arxiv.org/abs/2409.02512v1)|null|
|**2024-09-04**|**CoAst: Validation-Free Contribution Assessment for Federated Learning based on Cross-Round Valuation**|Hao Wu et.al.|[2409.02495v1](http://arxiv.org/abs/2409.02495v1)|null|
|**2024-09-04**|**NeuroSpex: Neuro-Guided Speaker Extraction with Cross-Modal Attention**|Dashanka De Silva et.al.|[2409.02489v1](http://arxiv.org/abs/2409.02489v1)|null|
|**2024-09-04**|**Boosting Generalizability towards Zero-Shot Cross-Dataset Single-Image Indoor Depth by Meta-Initialization**|Cho-Ying Wu et.al.|[2409.02486v1](http://arxiv.org/abs/2409.02486v1)|null|
|**2024-09-04**|**TASAR: Transferable Attack on Skeletal Action Recognition**|Yunfeng Diao et.al.|[2409.02483v1](http://arxiv.org/abs/2409.02483v1)|null|
|**2024-09-04**|**Word and Phrase Features in Graph Convolutional Network for Automatic Question Classification**|Junyoung Lee et.al.|[2409.02481v1](http://arxiv.org/abs/2409.02481v1)|null|
|**2024-09-04**|**A Comparative Study on Large Language Models for Log Parsing**|Merve Astekin et.al.|[2409.02474v1](http://arxiv.org/abs/2409.02474v1)|null|
|**2024-09-04**|**DetectiveQA: Evaluating Long-Context Reasoning on Detective Novels**|Zhe Xu et.al.|[2409.02465v1](http://arxiv.org/abs/2409.02465v1)|null|
|**2024-09-04**|**Fast, High-Quality and Parameter-Efficient Articulatory Synthesis using Differentiable DSP**|Yisi Liu et.al.|[2409.02451v1](http://arxiv.org/abs/2409.02451v1)|null|
|**2024-09-04**|**What is lost in Normalization? Exploring Pitfalls in Multilingual ASR Model Evaluations**|Kavya Manohar et.al.|[2409.02449v1](http://arxiv.org/abs/2409.02449v1)|null|
|**2024-09-04**|**Detecting Korean Food Using Image using Hierarchical Model**|Hoang Khanh Lam et.al.|[2409.02448v1](http://arxiv.org/abs/2409.02448v1)|[link](https://github.com/LHKode/NameyYourFood)|
|**2024-09-04**|**Large Language Models as Efficient Reward Function Searchers for Custom-Environment Multi-Objective Reinforcement Learning**|Guanwen Xie et.al.|[2409.02428v1](http://arxiv.org/abs/2409.02428v1)|null|
|**2024-09-04**|**Accelerating Large Language Model Training with Hybrid GPU-based Compression**|Lang Xu et.al.|[2409.02423v1](http://arxiv.org/abs/2409.02423v1)|null|
|**2024-09-04**|**Abstractive Text Summarization: State of the Art, Challenges, and Improvements**|Hassan Shakil et.al.|[2409.02413v1](http://arxiv.org/abs/2409.02413v1)|null|
|**2024-09-04**|**Learning Privacy-Preserving Student Networks via Discriminative-Generative Distillation**|Shiming Ge et.al.|[2409.02404v1](http://arxiv.org/abs/2409.02404v1)|null|
|**2024-09-04**|**Determination of language families using deep learning**|Peter B. Lerner et.al.|[2409.02393v1](http://arxiv.org/abs/2409.02393v1)|null|
|**2024-09-04**|**Scaling Laws for Economic Productivity: Experimental Evidence in LLM-Assisted Translation**|Ali Merali et.al.|[2409.02391v1](http://arxiv.org/abs/2409.02391v1)|null|
|**2024-09-04**|**Neural Dynamics Model of Visual Decision-Making: Learning from Human Experts**|Jie Su et.al.|[2409.02390v1](http://arxiv.org/abs/2409.02390v1)|null|
|**2024-09-04**|**Multi-modal Situated Reasoning in 3D Scenes**|Xiongkun Linghu et.al.|[2409.02389v1](http://arxiv.org/abs/2409.02389v1)|null|
|**2024-09-04**|**Large Language Models and Cognitive Science: A Comprehensive Review of Similarities, Differences, and Challenges**|Qian Niu et.al.|[2409.02387v2](http://arxiv.org/abs/2409.02387v2)|null|
|**2024-09-04**|**STAB: Speech Tokenizer Assessment Benchmark**|Shikhar Vashishth et.al.|[2409.02384v1](http://arxiv.org/abs/2409.02384v1)|null|
|**2024-09-04**|**Coral Model Generation from Single Images for Virtual Reality Applications**|Jie Fu et.al.|[2409.02376v1](http://arxiv.org/abs/2409.02376v1)|null|
|**2024-09-04**|**How Privacy-Savvy Are Large Language Models? A Case Study on Compliance and Privacy Technical Review**|Xichou Zhu et.al.|[2409.02375v1](http://arxiv.org/abs/2409.02375v1)|null|
|**2024-09-04**|**Do Large Language Models Possess Sensitive to Sentiment?**|Yang Liu et.al.|[2409.02370v1](http://arxiv.org/abs/2409.02370v1)|null|
|**2024-09-04**|**NUDGE: Lightweight Non-Parametric Fine-Tuning of Embeddings for Retrieval**|Sepanta Zeighami et.al.|[2409.02343v1](http://arxiv.org/abs/2409.02343v1)|null|
|**2024-09-03**|**Coaching a Robotic Sonographer: Learning Robotic Ultrasound with Sparse Expert's Feedback**|Deepak Raina et.al.|[2409.02337v1](http://arxiv.org/abs/2409.02337v1)|null|
|**2024-09-03**|**Arctic-SnowCoder: Demystifying High-Quality Data in Code Pretraining**|Yuxiang Wei et.al.|[2409.02326v1](http://arxiv.org/abs/2409.02326v1)|null|
|**2024-09-03**|**TimeDiT: General-purpose Diffusion Transformers for Time Series Foundation Model**|Defu Cao et.al.|[2409.02322v1](http://arxiv.org/abs/2409.02322v1)|null|
|**2024-09-03**|**On the Benefits of Memory for Modeling Time-Dependent PDEs**|Ricardo Buitrago Ruiz et.al.|[2409.02313v1](http://arxiv.org/abs/2409.02313v1)|null|
|**2024-09-03**|**Speech Foundation Model Ensembles for the Controlled Singing Voice Deepfake Detection (CtrSVDD) Challenge 2024**|Anmol Guragain et.al.|[2409.02302v1](http://arxiv.org/abs/2409.02302v1)|[link](https://github.com/anmol2059/svdd2024)|
|**2024-09-03**|**Initial Development and Evaluation of the Creative Artificial Intelligence through Recurring Developments and Determinations (CAIRDD) System**|Jeremy Straub et.al.|[2409.02291v1](http://arxiv.org/abs/2409.02291v1)|null|
|**2024-09-03**|**Reinforcement Learning-enabled Satellite Constellation Reconfiguration and Retasking for Mission-Critical Applications**|Hassan El Alami et.al.|[2409.02270v1](http://arxiv.org/abs/2409.02270v1)|null|
|**2024-09-03**|**Optimal L-Systems for Stochastic L-system Inference Problems**|Ali Lotfi et.al.|[2409.02259v1](http://arxiv.org/abs/2409.02259v1)|null|
|**2024-09-03**|**MMLU-Pro+: Evaluating Higher-Order Reasoning and Shortcut Learning in LLMs**|Saeid Asgari Taghanaki et.al.|[2409.02257v1](http://arxiv.org/abs/2409.02257v1)|null|
|**2024-09-03**|**NoiseAttack: An Evasive Sample-Specific Multi-Targeted Backdoor Attack Through White Gaussian Noise**|Abdullah Arafat Miah et.al.|[2409.02251v1](http://arxiv.org/abs/2409.02251v1)|[link](https://github.com/sisl-uri/noiseattack)|
|**2024-09-03**|**FastVoiceGrad: One-step Diffusion-Based Voice Conversion with Adversarial Conditional Diffusion Distillation**|Takuhiro Kaneko et.al.|[2409.02245v1](http://arxiv.org/abs/2409.02245v1)|null|
|**2024-09-03**|**Therapy as an NLP Task: Psychologists' Comparison of LLMs and Human Peers in CBT**|Zainab Iftikhar et.al.|[2409.02244v1](http://arxiv.org/abs/2409.02244v1)|null|
|**2024-09-03**|**Temporal Order Preserved Optimal Transport-based Cross-modal Knowledge Transfer Learning for ASR**|Xugang Lu et.al.|[2409.02239v2](http://arxiv.org/abs/2409.02239v2)|null|
|**2024-09-03**|**Unforgettable Generalization in Language Models**|Eric Zhang et.al.|[2409.02228v1](http://arxiv.org/abs/2409.02228v1)|null|
|**2024-09-03**|**Visually Grounded Speech Models for Low-resource Languages and Cognitive Modelling**|Leanne Nortje et.al.|[2409.02865v1](http://arxiv.org/abs/2409.02865v1)|null|
|**2024-09-03**|**CRAFT Your Dataset: Task-Specific Synthetic Dataset Generation Through Corpus Retrieval and Augmentation**|Ingo Ziegler et.al.|[2409.02098v1](http://arxiv.org/abs/2409.02098v1)|null|
|**2024-09-03**|**DepthCrafter: Generating Consistent Long Depth Sequences for Open-world Videos**|Wenbo Hu et.al.|[2409.02095v1](http://arxiv.org/abs/2409.02095v1)|null|
|**2024-09-03**|**Political DEBATE: Efficient Zero-shot and Few-shot Classifiers for Political Text**|Michael Burnham et.al.|[2409.02078v1](http://arxiv.org/abs/2409.02078v1)|null|
|**2024-09-03**|**Spinning the Golden Thread: Benchmarking Long-Form Generation in Language Models**|Yuhao Wu et.al.|[2409.02076v1](http://arxiv.org/abs/2409.02076v1)|null|
|**2024-09-03**|**OLMoE: Open Mixture-of-Experts Language Models**|Niklas Muennighoff et.al.|[2409.02060v1](http://arxiv.org/abs/2409.02060v1)|null|
|**2024-09-03**|**Enhancing Code-Switching Speech Recognition with LID-Based Collaborative Mixture of Experts Model**|Hukai Huang et.al.|[2409.02050v2](http://arxiv.org/abs/2409.02050v2)|null|
|**2024-09-03**|**Low-Resolution Face Recognition via Adaptable Instance-Relation Distillation**|Ruixin Shi et.al.|[2409.02049v1](http://arxiv.org/abs/2409.02049v1)|null|
|**2024-09-03**|**AllWeatherNet:Unified Image enhancement for autonomous driving under adverse weather and lowlight-conditions**|Chenghao Qian et.al.|[2409.02045v1](http://arxiv.org/abs/2409.02045v1)|null|
|**2024-09-03**|**BEAVER: An Enterprise Benchmark for Text-to-SQL**|Peter Baile Chen et.al.|[2409.02038v1](http://arxiv.org/abs/2409.02038v1)|null|
|**2024-09-03**|**Foundations of Large Language Model Compression -- Part 1: Weight Quantization**|Sean I. Young et.al.|[2409.02026v1](http://arxiv.org/abs/2409.02026v1)|[link](https://github.com/seannz/cvxq)|
|**2024-09-03**|**TransDAE: Dual Attention Mechanism in a Hierarchical Transformer for Efficient Medical Image Segmentation**|Bobby Azad et.al.|[2409.02018v1](http://arxiv.org/abs/2409.02018v1)|null|
|**2024-09-03**|**vec2wav 2.0: Advancing Voice Conversion via Discrete Token Vocoders**|Yiwei Guo et.al.|[2409.01995v1](http://arxiv.org/abs/2409.01995v1)|null|
|**2024-09-03**|**Planning to avoid ambiguous states through Gaussian approximations to non-linear sensors in active inference agents**|Wouter M. Kouw et.al.|[2409.01974v1](http://arxiv.org/abs/2409.01974v1)|null|

#### Abstracts
##### **RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins (early version)**
2409.02920v1 by Yao Mu, Tianxing Chen, Shijia Peng, Zanxin Chen, Zeyu Gao, Yude Zou, Lunkai Lin, Zhiqiang Xie, Ping Luo

Effective collaboration of dual-arm robots and their tool use capabilities
are increasingly important areas in the advancement of robotics. These skills
play a significant role in expanding robots' ability to operate in diverse
real-world environments. However, progress is impeded by the scarcity of
specialized training data. This paper introduces RoboTwin, a novel benchmark
dataset combining real-world teleoperated data with synthetic data from digital
twins, designed for dual-arm robotic scenarios. Using the COBOT Magic platform,
we have collected diverse data on tool usage and human-robot interaction. We
present a innovative approach to creating digital twins using AI-generated
content, transforming 2D images into detailed 3D models. Furthermore, we
utilize large language models to generate expert-level training data and
task-specific pose sequences oriented toward functionality. Our key
contributions are: 1) the RoboTwin benchmark dataset, 2) an efficient
real-to-simulation pipeline, and 3) the use of language models for automatic
expert-level data generation. These advancements are designed to address the
shortage of robotic training data, potentially accelerating the development of
more capable and versatile robotic systems for a wide range of real-world
applications. The project page is available at
https://robotwin-benchmark.github.io/early-version/

摘要：雙臂機器人的有效協作及其工具使用能力在機器人技術的進步中越來越重要。這些技能在擴展機器人在各種現實世界環境中運作的能力方面發揮著重要作用。然而，進展受到專業訓練資料缺乏的阻礙。本文介紹了 RoboTwin，一個新穎的基準資料集，結合了來自數位雙胞胎的真實世界遙控操作資料和合成資料，專為雙臂機器人場景而設計。使用 COBOT Magic 平台，我們收集了有關工具使用和人機互動的各種資料。我們提出了一種創新的方法來使用 AI 生成的內容建立數位雙胞胎，將 2D 影像轉換為詳細的 3D 模型。此外，我們利用大型語言模型來產生專家級的訓練資料和面向功能的特定任務姿勢序列。我們的關鍵貢獻包括：1) RoboTwin 基準資料集，2) 一個高效的真實到模擬的管道，以及 3) 使用語言模型進行自動專家級資料生成。這些進展旨在解決機器人訓練資料短缺的問題，有可能加速開發更強大、更通用的機器人系統，以應用于廣泛的現實世界應用。專案頁面可於 https://robotwin-benchmark.github.io/early-version/ 獲得

##### **UC-NeRF: Uncertainty-aware Conditional Neural Radiance Fields from Endoscopic Sparse Views**
2409.02917v1 by Jiaxin Guo, Jiangliu Wang, Ruofeng Wei, Di Kang, Qi Dou, Yun-hui Liu

Visualizing surgical scenes is crucial for revealing internal anatomical
structures during minimally invasive procedures. Novel View Synthesis is a
vital technique that offers geometry and appearance reconstruction, enhancing
understanding, planning, and decision-making in surgical scenes. Despite the
impressive achievements of Neural Radiance Field (NeRF), its direct application
to surgical scenes produces unsatisfying results due to two challenges:
endoscopic sparse views and significant photometric inconsistencies. In this
paper, we propose uncertainty-aware conditional NeRF for novel view synthesis
to tackle the severe shape-radiance ambiguity from sparse surgical views. The
core of UC-NeRF is to incorporate the multi-view uncertainty estimation to
condition the neural radiance field for modeling the severe photometric
inconsistencies adaptively. Specifically, our UC-NeRF first builds a
consistency learner in the form of multi-view stereo network, to establish the
geometric correspondence from sparse views and generate uncertainty estimation
and feature priors. In neural rendering, we design a base-adaptive NeRF network
to exploit the uncertainty estimation for explicitly handling the photometric
inconsistencies. Furthermore, an uncertainty-guided geometry distillation is
employed to enhance geometry learning. Experiments on the SCARED and Hamlyn
datasets demonstrate our superior performance in rendering appearance and
geometry, consistently outperforming the current state-of-the-art approaches.
Our code will be released at \url{https://github.com/wrld/UC-NeRF}.

摘要：視覺化手術場景對於在微創手術中揭露內部解剖結構至關重要。新穎視圖合成是一種重要的技術，提供幾何和外觀重建，增強對手術場景的理解、規劃和決策制定。儘管神經輻照場 (NeRF) 取得了令人印象深刻的成就，但由於兩個挑戰：內視鏡稀疏視圖和顯著的光度不一致，其直接應用於手術場景會產生不令人滿意的結果。在本文中，我們提出了一種不確定性感知條件 NeRF，用於新視圖合成，以解決稀疏手術視圖中的嚴重形狀輻照度模糊性。UC-NeRF 的核心是將多視圖不確定性估計納入條件神經輻照度場，以自適應地建模嚴重的光度不一致性。具體來說，我們的 UC-NeRF 首先以多視圖立體網路的形式構建一致性學習器，以建立稀疏視圖的幾何對應關係，並生成不確定性估計和特徵先驗。在神經渲染中，我們設計了一個基於自適應的 NeRF 網路，以利用不確定性估計來明確處理光度不一致性。此外，採用不確定性引導的幾何蒸餾來增強幾何學習。在 SCARED 和 Hamlyn 資料集上的實驗證明了我們在渲染外觀和幾何方面的卓越效能，始終優於當前最先進的方法。我們的程式碼將在 \url{https://github.com/wrld/UC-NeRF} 發布。

##### **Masked Diffusion Models are Secretly Time-Agnostic Masked Models and Exploit Inaccurate Categorical Sampling**
2409.02908v1 by Kaiwen Zheng, Yongxin Chen, Hanzi Mao, Ming-Yu Liu, Jun Zhu, Qinsheng Zhang

Masked diffusion models (MDMs) have emerged as a popular research topic for
generative modeling of discrete data, thanks to their superior performance over
other discrete diffusion models, and are rivaling the auto-regressive models
(ARMs) for language modeling tasks. The recent effort in simplifying the masked
diffusion framework further leads to alignment with continuous-space diffusion
models and more principled training and sampling recipes. In this paper,
however, we reveal that both training and sampling of MDMs are theoretically
free from the time variable, arguably the key signature of diffusion models,
and are instead equivalent to masked models. The connection on the sampling
aspect is drawn by our proposed first-hitting sampler (FHS). Specifically, we
show that the FHS is theoretically equivalent to MDMs' original generation
process while significantly alleviating the time-consuming categorical sampling
and achieving a 20$\times$ speedup. In addition, our investigation challenges
previous claims that MDMs can surpass ARMs in generative perplexity. We
identify, for the first time, an underlying numerical issue, even with the
32-bit floating-point precision, which results in inaccurate categorical
sampling. We show that the numerical issue lowers the effective temperature
both theoretically and empirically, leading to unfair assessments of MDMs'
generation results in the previous literature.

摘要：遮罩擴散模型 (MDM) 已成為離散資料生成模型的熱門研究主題，這要歸功於其優於其他離散擴散模型的卓越效能，並且在語言建模任務中與自迴歸模型 (ARM) 相抗衡。簡化遮罩擴散架構的最新努力進一步導致與連續空間擴散模型和更有原則的訓練和採樣配方保持一致。然而，在本文中，我們揭示了 MDM 的訓練和採樣在理論上都不受時間變數的約束，這可以說是擴散模型的主要特徵，而等同於遮罩模型。採樣方面的關聯性是由我們提出的首次命中採樣器 (FHS) 繪製的。具體來說，我們表明 FHS 在理論上等同於 MDM 的原始生成過程，同時顯著減輕了耗時的分類採樣，並實現了 20 倍的加速。此外，我們的調查挑戰了先前的說法，即 MDM 可以超越 ARM 的生成困惑度。我們首次發現了一個潛在的數值問題，即使使用 32 位浮點精度，也會導致不準確的分類採樣。我們表明，這個數值問題在理論上和經驗上都會降低有效溫度，導致對先前文獻中 MDM 的生成結果進行不公平的評估。

##### **LongCite: Enabling LLMs to Generate Fine-grained Citations in Long-context QA**
2409.02897v2 by Jiajie Zhang, Yushi Bai, Xin Lv, Wanjun Gu, Danqing Liu, Minhao Zou, Shulin Cao, Lei Hou, Yuxiao Dong, Ling Feng, Juanzi Li

Though current long-context large language models (LLMs) have demonstrated
impressive capacities in answering user questions based on extensive text, the
lack of citations in their responses makes user verification difficult, leading
to concerns about their trustworthiness due to their potential hallucinations.
In this work, we aim to enable long-context LLMs to generate responses with
fine-grained sentence-level citations, improving their faithfulness and
verifiability. We first introduce LongBench-Cite, an automated benchmark for
assessing current LLMs' performance in Long-Context Question Answering with
Citations (LQAC), revealing considerable room for improvement. To this end, we
propose CoF (Coarse to Fine), a novel pipeline that utilizes off-the-shelf LLMs
to automatically generate long-context QA instances with precise sentence-level
citations, and leverage this pipeline to construct LongCite-45k, a large-scale
SFT dataset for LQAC. Finally, we train LongCite-8B and LongCite-9B using the
LongCite-45k dataset, successfully enabling their generation of accurate
responses and fine-grained sentence-level citations in a single output. The
evaluation results on LongBench-Cite show that our trained models achieve
state-of-the-art citation quality, surpassing advanced proprietary models
including GPT-4o.

摘要：儘管目前的長語境大型語言模型 (LLM) 已展現出根據廣泛文本回答使用者問題的驚人能力，但其回應中缺乏引文，使得使用者驗證困難，並因其潛在的幻覺而對其可信度產生疑慮。在此研究中，我們旨在讓長語境 LLM 能夠產生具有細緻句子層級引文的回應，進而提升其真實性和可驗證性。我們首先介紹 LongBench-Cite，這是一個自動化基準，用於評估目前 LLM 在長語境問答帶引文 (LQAC) 中的表現，揭露有待改進的空間。為此，我們提出 CoF（粗到細），這是一個新穎的管道，利用現成的 LLM 自動產生具有精確句子層級引文的長語境問答實例，並利用此管道建構 LongCite-45k，這是一個用於 LQAC 的大規模 SFT 資料集。最後，我們使用 LongCite-45k 資料集訓練 LongCite-8B 和 LongCite-9B，成功讓它們能夠在單一輸出中產生精確的回應和細緻的句子層級引文。在 LongBench-Cite 上的評估結果顯示，我們訓練的模型達到了最先進的引文品質，超越了包括 GPT-4o 在內的進階專有模型。

##### **LongLLaVA: Scaling Multi-modal LLMs to 1000 Images Efficiently via Hybrid Architecture**
2409.02889v1 by Xidong Wang, Dingjie Song, Shunian Chen, Chen Zhang, Benyou Wang

Expanding the long-context capabilities of Multi-modal Large Language
Models~(MLLMs) is crucial for video understanding, high-resolution image
understanding, and multi-modal agents. This involves a series of systematic
optimizations, including model architecture, data construction and training
strategy, particularly addressing challenges such as \textit{degraded
performance with more images} and \textit{high computational costs}. In this
paper, we adapt the model architecture to a hybrid of Mamba and Transformer
blocks, approach data construction with both temporal and spatial dependencies
among multiple images and employ a progressive training strategy. The released
model \textbf{LongLLaVA}~(\textbf{Long}-Context \textbf{L}arge
\textbf{L}anguage \textbf{a}nd \textbf{V}ision \textbf{A}ssistant) is the first
hybrid MLLM, which achieved a better balance between efficiency and
effectiveness. LongLLaVA not only achieves competitive results across various
benchmarks, but also maintains high throughput and low memory consumption.
Especially, it could process nearly a thousand images on a single A100 80GB
GPU, showing promising application prospects for a wide range of tasks.

摘要：擴展多模態大型語言模型 (MLLM) 的長文本能力對於影片理解、高解析度影像理解和多模態代理來說至關重要。這涉及一系列的系統性最佳化，包括模型架構、資料建置和訓練策略，特別是解決諸如「隨著影像增加而降低效能」和「高運算成本」等挑戰。在本文中，我們將模型架構調整為 Mamba 和 Transformer 區塊的混合體，使用多個影像之間的時序和空間依賴性來建置資料，並採用漸進式訓練策略。所發布的模型 \textbf{LongLLaVA}（\textbf{Long}-Context \textbf{L}arge \textbf{L}anguage \textbf{a}nd \textbf{V}ision \textbf{A}ssistant）是第一個混合 MLLM，在效率和效能之間取得更好的平衡。LongLLaVA 不僅在各種基準測試中取得競爭力的結果，還能維持高處理量和低記憶體消耗。特別是，它可以在單一 A100 80GB GPU 上處理近千張影像，展現出廣泛任務的應用前景。

##### **Multi-stream deep learning framework to predict mild cognitive impairment with Rey Complex Figure Test**
2409.02883v1 by Junyoung Park, Eun Hyun Seo, Sunjun Kim, SangHak Yi, Kun Ho Lee, Sungho Won

Drawing tests like the Rey Complex Figure Test (RCFT) are widely used to
assess cognitive functions such as visuospatial skills and memory, making them
valuable tools for detecting mild cognitive impairment (MCI). Despite their
utility, existing predictive models based on these tests often suffer from
limitations like small sample sizes and lack of external validation, which
undermine their reliability. We developed a multi-stream deep learning
framework that integrates two distinct processing streams: a multi-head
self-attention based spatial stream using raw RCFT images and a scoring stream
employing a previously developed automated scoring system. Our model was
trained on data from 1,740 subjects in the Korean cohort and validated on an
external hospital dataset of 222 subjects from Korea. The proposed multi-stream
model demonstrated superior performance over baseline models (AUC = 0.872,
Accuracy = 0.781) in external validation. The integration of both spatial and
scoring streams enables the model to capture intricate visual details from the
raw images while also incorporating structured scoring data, which together
enhance its ability to detect subtle cognitive impairments. This dual approach
not only improves predictive accuracy but also increases the robustness of the
model, making it more reliable in diverse clinical settings. Our model has
practical implications for clinical settings, where it could serve as a
cost-effective tool for early MCI screening.

摘要：雷氏複雜圖形測驗 (RCFT) 等繪畫測驗廣泛用於評估視覺空間技能和記憶力等認知功能，使其成為檢測輕度認知障礙 (MCI) 的寶貴工具。儘管它們很有用，但基於這些測驗的現有預測模型通常會受到樣本量小和缺乏外部驗證等限制，這會損害其可靠性。我們開發了一個多串流深度學習框架，它整合了兩個不同的處理串流：一個基於多頭自注意力，使用原始 RCFT 影像的空間串流，以及一個採用先前開發的自動評分系統的評分串流。我們的模型在韓國群組中 1,740 名受試者的資料上進行訓練，並在來自韓國的 222 名受試者的外部醫院資料集上進行驗證。所提出的多串流模型在外部驗證中表現出優於基準模型的效能 (AUC = 0.872，準確率 = 0.781)。空間和評分串流的整合使模型能夠從原始影像擷取複雜的視覺細節，同時也能納入結構化的評分資料，這共同增強了它檢測細微認知障礙的能力。這種雙重方法不僅提高了預測準確性，也增加了模型的穩健性，使其在不同的臨床環境中更可靠。我們的模型對臨床環境有實際的意義，它可以在其中作為早期 MCI 篩檢的具成本效益的工具。

##### **Configurable Foundation Models: Building LLMs from a Modular Perspective**
2409.02877v1 by Chaojun Xiao, Zhengyan Zhang, Chenyang Song, Dazhi Jiang, Feng Yao, Xu Han, Xiaozhi Wang, Shuo Wang, Yufei Huang, Guanyu Lin, Yingfa Chen, Weilin Zhao, Yuge Tu, Zexuan Zhong, Ao Zhang, Chenglei Si, Khai Hao Moo, Chenyang Zhao, Huimin Chen, Yankai Lin, Zhiyuan Liu, Jingbo Shang, Maosong Sun

Advancements in LLMs have recently unveiled challenges tied to computational
efficiency and continual scalability due to their requirements of huge
parameters, making the applications and evolution of these models on devices
with limited computation resources and scenarios requiring various abilities
increasingly cumbersome. Inspired by modularity within the human brain, there
is a growing tendency to decompose LLMs into numerous functional modules,
allowing for inference with part of modules and dynamic assembly of modules to
tackle complex tasks, such as mixture-of-experts. To highlight the inherent
efficiency and composability of the modular approach, we coin the term brick to
represent each functional module, designating the modularized structure as
configurable foundation models. In this paper, we offer a comprehensive
overview and investigation of the construction, utilization, and limitation of
configurable foundation models. We first formalize modules into emergent bricks
- functional neuron partitions that emerge during the pre-training phase, and
customized bricks - bricks constructed via additional post-training to improve
the capabilities and knowledge of LLMs. Based on diverse functional bricks, we
further present four brick-oriented operations: retrieval and routing, merging,
updating, and growing. These operations allow for dynamic configuration of LLMs
based on instructions to handle complex tasks. To verify our perspective, we
conduct an empirical analysis on widely-used LLMs. We find that the FFN layers
follow modular patterns with functional specialization of neurons and
functional neuron partitions. Finally, we highlight several open issues and
directions for future research. Overall, this paper aims to offer a fresh
modular perspective on existing LLM research and inspire the future creation of
more efficient and scalable foundational models.

摘要：<paragraph>大型語言模型 (LLM) 的進展最近揭示了由於需要龐大的參數而導致的計算效率和持續可擴充性的挑戰，這使得在計算資源有限的裝置上應用和演進這些模型以及需要各種能力的場景變得越來越繁瑣。受人類大腦中模組化的啟發，將 LLM 分解成許多功能模組的趨勢正在增長，允許使用部分模組進行推理和動態組裝模組來處理複雜任務，例如專家混合。為了突顯模組化方法的內在效率和可組合性，我們創造了「磚塊」一詞來表示每個功能模組，將模組化結構指定為可配置基礎模型。在本文中，我們對可配置基礎模型的構建、利用和限制提供了全面的概述和探討。我們首先將模組形式化為新興磚塊 - 在預訓練階段出現的功能神經元分割，以及自訂磚塊 - 透過額外的後續訓練來構建的磚塊，以改善 LLM 的能力和知識。基於不同的功能磚塊，我們進一步提出了四項面向磚塊的操作：擷取和路由、合併、更新和成長。這些操作允許根據指令動態配置 LLM 以處理複雜任務。為了驗證我們的觀點，我們對廣泛使用的 LLM 進行了實證分析。我們發現 FFN 層遵循模組模式，具有神經元和功能神經元分割的功能專門化。最後，我們重點介紹了幾個未解決的問題和未來研究的方向。總體而言，本文旨在對現有的 LLM 研究提供新的模組化觀點，並激勵未來創造更有效率和可擴充性的基礎模型。</paragraph>

##### **Hybrid Imitation-Learning Motion Planner for Urban Driving**
2409.02871v1 by Cristian Gariboldi, Matteo Corno, Beng Jin

With the release of open source datasets such as nuPlan and Argoverse, the
research around learning-based planners has spread a lot in the last years.
Existing systems have shown excellent capabilities in imitating the human
driver behaviour, but they struggle to guarantee safe closed-loop driving.
Conversely, optimization-based planners offer greater security in short-term
planning scenarios. To confront this challenge, in this paper we propose a
novel hybrid motion planner that integrates both learning-based and
optimization-based techniques. Initially, a multilayer perceptron (MLP)
generates a human-like trajectory, which is then refined by an
optimization-based component. This component not only minimizes tracking errors
but also computes a trajectory that is both kinematically feasible and
collision-free with obstacles and road boundaries. Our model effectively
balances safety and human-likeness, mitigating the trade-off inherent in these
objectives. We validate our approach through simulation experiments and further
demonstrate its efficacy by deploying it in real-world self-driving vehicles.

摘要：隨著 nuPlan 和 Argoverse 等開源資料集的釋出，近年來基於學習的規劃器的研究已廣泛展開。
現有系統已展現出模仿人類駕駛行為的出色能力，但仍難以保證安全閉環駕駛。
相反地，基於最佳化的規劃器在短期規劃情境中提供了更高的安全性。
為了應對這項挑戰，我們在這篇論文中提出了一種新的混合運動規劃器，它整合了基於學習和基於最佳化的技術。
最初，多層感知器 (MLP) 會產生類似人類的軌跡，然後由基於最佳化的組件加以精煉。
此組件不僅會將追蹤誤差降至最低，還會計算出在運動學上可行且不會與障礙物和道路邊界發生碰撞的軌跡。
我們的模型有效地平衡了安全性與類人化，減輕了這些目標中固有的取捨。
我們透過模擬實驗驗證了我們的做法，並進一步透過在真實世界的自動駕駛車輛中部署它來證明其效能。

##### **Historical German Text Normalization Using Type- and Token-Based Language Modeling**
2409.02841v1 by Anton Ehrmanntraut

Historic variations of spelling poses a challenge for full-text search or
natural language processing on historical digitized texts. To minimize the gap
between the historic orthography and contemporary spelling, usually an
automatic orthographic normalization of the historical source material is
pursued. This report proposes a normalization system for German literary texts
from c. 1700-1900, trained on a parallel corpus. The proposed system makes use
of a machine learning approach using Transformer language models, combining an
encoder-decoder model to normalize individual word types, and a pre-trained
causal language model to adjust these normalizations within their context. An
extensive evaluation shows that the proposed system provides state-of-the-art
accuracy, comparable with a much larger fully end-to-end sentence-based
normalization system, fine-tuning a pre-trained Transformer large language
model. However, the normalization of historical text remains a challenge due to
difficulties for models to generalize, and the lack of extensive high-quality
parallel data.

摘要：歷史拼寫的變化對歷史數位化文本的全文字搜尋或自然語言處理構成挑戰。為了縮小歷史正寫法和當代拼寫之間的差距，通常會對歷史來源資料進行自動正寫法標準化。本報告提出了一個針對德語文學文本的標準化系統，訓練資料取自一個平行語料庫，時間範圍為 1700-1900 年。所提出的系統採用使用 Transformer 語言模型的機器學習方法，結合編碼器-解碼器模型來標準化個別字詞類型，以及預先訓練的因果語言模型來調整這些標準化內容的語境。廣泛的評估顯示，所提出的系統提供了最先進的準確度，堪比一個更大規模的端到端句子式標準化系統，微調預先訓練好的 Transformer 大型語言模型。然而，歷史文本的標準化仍然是一個挑戰，因為模型難以概括，而且缺乏大量高品質的平行資料。

##### **R2GQA: Retriever-Reader-Generator Question Answering System to Support Students Understanding Legal Regulations in Higher Education**
2409.02840v1 by Phuc-Tinh Pham Do, Duy-Ngoc Dinh Cao, Khanh Quoc Tran, Kiet Van Nguyen

In this article, we propose the R2GQA system, a Retriever-Reader-Generator
Question Answering system, consisting of three main components: Document
Retriever, Machine Reader, and Answer Generator. The Retriever module employs
advanced information retrieval techniques to extract the context of articles
from a dataset of legal regulation documents. The Machine Reader module
utilizes state-of-the-art natural language understanding algorithms to
comprehend the retrieved documents and extract answers. Finally, the Generator
module synthesizes the extracted answers into concise and informative responses
to questions of students regarding legal regulations. Furthermore, we built the
ViRHE4QA dataset in the domain of university training regulations, comprising
9,758 question-answer pairs with a rigorous construction process. This is the
first Vietnamese dataset in the higher regulations domain with various types of
answers, both extractive and abstractive. In addition, the R2GQA system is the
first system to offer abstractive answers in Vietnamese. This paper discusses
the design and implementation of each module within the R2GQA system on the
ViRHE4QA dataset, highlighting their functionalities and interactions.
Furthermore, we present experimental results demonstrating the effectiveness
and utility of the proposed system in supporting the comprehension of students
of legal regulations in higher education settings. In general, the R2GQA system
and the ViRHE4QA dataset promise to contribute significantly to related
research and help students navigate complex legal documents and regulations,
empowering them to make informed decisions and adhere to institutional policies
effectively. Our dataset is available for research purposes.

摘要：<paragraph>在本文中，我們提出 R2GQA 系統，一個檢索器-閱讀器-產生器問答系統，由三個主要組成部分組成：文件檢索器、機器閱讀器和答案產生器。檢索器模組採用進階資訊檢索技術，從法律法規文件資料集中擷取文章的內容。機器閱讀器模組利用最先進的自然語言理解演算法，理解擷取的文件並擷取答案。最後，產生器模組將擷取的答案綜合成簡潔且具資訊性的回應，以回答學生有關法律法規的問題。此外，我們在大學訓練法規領域中建構了 ViRHE4QA 資料集，包含 9,758 個問題答案對，並採用嚴謹的建構程序。這是高等法規領域中第一個包含各種答案類型的越南語資料集，包括萃取式和抽象式。此外，R2GQA 系統是第一個提供越南語抽象答案的系統。本文討論了 R2GQA 系統中每個模組在 ViRHE4QA 資料集上的設計和實作，重點說明它們的功能和互動。此外，我們提供了實驗結果，證明了所提出的系統在支援高等教育環境中學生理解法律法規方面的有效性和實用性。總的來說，R2GQA 系統和 ViRHE4QA 資料集有望為相關研究做出重大貢獻，並幫助學生瀏覽複雜的法律文件和法規，讓他們能夠做出明智的決策並有效遵守機構政策。我們的資料集可供研究用途。</paragraph>

##### **Exploring Sentiment Dynamics and Predictive Behaviors in Cryptocurrency Discussions by Few-Shot Learning with Large Language Models**
2409.02836v1 by Moein Shahiki Tash, Zahra Ahani, Mohim Tash, Olga Kolesnikova, Grigori Sidorov

This study performs analysis of Predictive statements, Hope speech, and
Regret Detection behaviors within cryptocurrency-related discussions,
leveraging advanced natural language processing techniques. We introduce a
novel classification scheme named "Prediction statements," categorizing
comments into Predictive Incremental, Predictive Decremental, Predictive
Neutral, or Non-Predictive categories. Employing GPT-4o, a cutting-edge large
language model, we explore sentiment dynamics across five prominent
cryptocurrencies: Cardano, Binance, Matic, Fantom, and Ripple. Our analysis
reveals distinct patterns in predictive sentiments, with Matic demonstrating a
notably higher propensity for optimistic predictions. Additionally, we
investigate hope and regret sentiments, uncovering nuanced interplay between
these emotions and predictive behaviors. Despite encountering limitations
related to data volume and resource availability, our study reports valuable
discoveries concerning investor behavior and sentiment trends within the
cryptocurrency market, informing strategic decision-making and future research
endeavors.

摘要：本研究利用先進的自然語言處理技術，對加密貨幣相關討論中的預測性陳述、希望言論和遺憾檢測行為進行分析。我們引入一個名為「預測性陳述」的新分類方案，將評論分類為預測性遞增、預測性遞減、預測性中立或非預測性類別。採用 GPT-4o，一種尖端的巨量語言模型，我們探討了五種主要加密貨幣（Cardano、Binance、Matic、Fantom 和 Ripple）的情緒動態。我們的分析揭示了預測性情緒的不同模式，Matic 表現出明顯更高的樂觀預測傾向。此外，我們研究了希望和遺憾情緒，揭示了這些情緒與預測行為之間細微的相互作用。儘管遇到了與數據量和資源可用性相關的限制，但我們的研究報告了有關投資者行為和加密貨幣市場情緒趨勢的寶貴發現，為戰略決策制定和未來的研究工作提供信息。

##### **CMM-Math: A Chinese Multimodal Math Dataset To Evaluate and Enhance the Mathematics Reasoning of Large Multimodal Models**
2409.02834v1 by Wentao Liu, Qianjun Pan, Yi Zhang, Zhuo Liu, Ji Wu, Jie Zhou, Aimin Zhou, Qin Chen, Bo Jiang, Liang He

Large language models (LLMs) have obtained promising results in mathematical
reasoning, which is a foundational skill for human intelligence. Most previous
studies focus on improving and measuring the performance of LLMs based on
textual math reasoning datasets (e.g., MATH, GSM8K). Recently, a few
researchers have released English multimodal math datasets (e.g., MATHVISTA and
MATH-V) to evaluate the effectiveness of large multimodal models (LMMs). In
this paper, we release a Chinese multimodal math (CMM-Math) dataset, including
benchmark and training parts, to evaluate and enhance the mathematical
reasoning of LMMs. CMM-Math contains over 28,000 high-quality samples,
featuring a variety of problem types (e.g., multiple-choice, fill-in-the-blank,
and so on) with detailed solutions across 12 grade levels from elementary to
high school in China. Specifically, the visual context may be present in the
questions or opinions, which makes this dataset more challenging. Through
comprehensive analysis, we discover that state-of-the-art LMMs on the CMM-Math
dataset face challenges, emphasizing the necessity for further improvements in
LMM development. We also propose a Multimodal Mathematical LMM (Math-LMM) to
handle the problems with mixed input of multiple images and text segments. We
train our model using three stages, including foundational pre-training,
foundational fine-tuning, and mathematical fine-tuning. The extensive
experiments indicate that our model effectively improves math reasoning
performance by comparing it with the SOTA LMMs over three multimodal
mathematical datasets.

摘要：<paragraph>大型語言模型 (LLM) 在數學推理方面取得了可觀的成果，而數學推理是人類智慧的一項基礎技能。大多數先前的研究專注於改進和衡量 LLM 在基於文字數學推理資料集（例如 MATH、GSM8K）上的效能。最近，一些研究人員發布了英文多模態數學資料集（例如 MATHVISTA 和 MATH-V），以評估大型多模態模型 (LMM) 的效能。在本文中，我們發布了一個中文多模態數學 (CMM-Math) 資料集，其中包含基準和訓練部分，以評估和增強 LMM 的數學推理能力。CMM-Math 包含超過 28,000 個高品質樣本，具有多種問題類型（例如多選題、填空題等），並提供從中國小學到高中的 12 個年級的詳細解答。具體來說，視覺脈絡可能存在於問題或意見中，這使得這個資料集更具挑戰性。透過全面的分析，我們發現 CMM-Math 資料集上的最先進 LMM 面臨挑戰，強調進一步改進 LMM 開發的必要性。我們還提出了一個多模態數學 LMM (Math-LMM) 來處理多個影像和文字區段混合輸入的問題。我們使用三個階段訓練我們的模型，包括基礎預訓練、基礎微調和數學微調。廣泛的實驗表明，我們的模型透過與三個多模態數學資料集上的 SOTA LMM 進行比較，有效地改進了數學推理效能。</paragraph>

##### **MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding Benchmark**
2409.02813v1 by Xiang Yue, Tianyu Zheng, Yuansheng Ni, Yubo Wang, Kai Zhang, Shengbang Tong, Yuxuan Sun, Ming Yin, Botao Yu, Ge Zhang, Huan Sun, Yu Su, Wenhu Chen, Graham Neubig

This paper introduces MMMU-Pro, a robust version of the Massive
Multi-discipline Multimodal Understanding and Reasoning (MMMU) benchmark.
MMMU-Pro rigorously assesses multimodal models' true understanding and
reasoning capabilities through a three-step process based on MMMU: (1)
filtering out questions answerable by text-only models, (2) augmenting
candidate options, and (3) introducing a vision-only input setting where
questions are embedded within images. This setting challenges AI to truly "see"
and "read" simultaneously, testing a fundamental human cognitive skill of
seamlessly integrating visual and textual information. Results show that model
performance is substantially lower on MMMU-Pro than on MMMU, ranging from 16.8%
to 26.9% across models. We explore the impact of OCR prompts and Chain of
Thought (CoT) reasoning, finding that OCR prompts have minimal effect while CoT
generally improves performance. MMMU-Pro provides a more rigorous evaluation
tool, closely mimicking real-world scenarios and offering valuable directions
for future research in multimodal AI.

摘要：本文介紹 MMMU-Pro，這是大規模多領域多模態理解與推理 (MMMU) 評量的強化版本。MMMU-Pro 透過以下基於 MMMU 的三步驟流程，嚴謹評估多模態模型的真正理解與推理能力：(1) 過濾出僅靠文字模型即可回答的問題，(2) 增加候選選項，以及 (3) 引入僅限視覺輸入的設定，其中問題會嵌入在影像中。此設定挑戰 AI 同時「觀看」和「閱讀」，測試人類無縫整合視覺和文字資訊的基本認知技能。結果顯示，模型在 MMMU-Pro 的表現大幅低於 MMMU，各模型的表現範圍從 16.8% 到 26.9%。我們探討 OCR 提示和思考鏈 (CoT) 推理的影響，發現 OCR 提示的影響很小，而 CoT 通常會提升表現。MMMU-Pro 提供更嚴謹的評量工具，能精確模擬真實世界的場景，並為多模態 AI 的未來研究提供有價值的方向。

##### **A hybrid FEM-PINN method for time-dependent partial differential equations**
2409.02810v1 by Xiaodong Feng, Haojiong Shangguan, Tao Tang, Xiaoliang Wan, Tao Zhou

In this work, we present a hybrid numerical method for solving evolution
partial differential equations (PDEs) by merging the time finite element method
with deep neural networks. In contrast to the conventional deep learning-based
formulation where the neural network is defined on a spatiotemporal domain, our
methodology utilizes finite element basis functions in the time direction where
the space-dependent coefficients are defined as the output of a neural network.
We then apply the Galerkin or collocation projection in the time direction to
obtain a system of PDEs for the space-dependent coefficients which is
approximated in the framework of PINN. The advantages of such a hybrid
formulation are twofold: statistical errors are avoided for the integral in the
time direction, and the neural network's output can be regarded as a set of
reduced spatial basis functions. To further alleviate the difficulties from
high dimensionality and low regularity, we have developed an adaptive sampling
strategy that refines the training set. More specifically, we use an explicit
density model to approximate the distribution induced by the PDE residual and
then augment the training set with new time-dependent random samples given by
the learned density model. The effectiveness and efficiency of our proposed
method have been demonstrated through a series of numerical experiments.

摘要：在這項工作中，我們提出了一種混合數值方法，用於通過將時有限元方法與深度神經網路合併來求解演化偏微分方程式 (PDE)。與傳統的深度學習公式不同，其中神經網路定義在時空域上，我們的技術在時間方向上利用有限元基底函數，其中與空間相關的係數定義為神經網路的輸出。然後我們在時間方向上應用 Galerkin 或搭配投影，以獲得時空相關係數的 PDE 系統，該系統在 PINN 框架中得到近似。這種混合公式的優點有兩個：避免了時間方向積分的統計誤差，並且可以將神經網路的輸出視為一組約化的空間基底函數。為了進一步緩解高維度和低規則性的困難，我們開發了一種自適應抽樣策略，用於修正訓練集。更具體地說，我們使用一個明確的密度模型來近似由 PDE residual 誘導的分配，然後使用學習到的密度模型提供的新的時間相關隨機樣本來擴充訓練集。我們提出的方法的有效性和效率已通過一系列數值實驗得到證明。

##### **Towards a Unified View of Preference Learning for Large Language Models: A Survey**
2409.02795v1 by Bofei Gao, Feifan Song, Yibo Miao, Zefan Cai, Zhe Yang, Liang Chen, Helan Hu, Runxin Xu, Qingxiu Dong, Ce Zheng, Wen Xiao, Ge Zhang, Daoguang Zan, Keming Lu, Bowen Yu, Dayiheng Liu, Zeyu Cui, Jian Yang, Lei Sha, Houfeng Wang, Zhifang Sui, Peiyi Wang, Tianyu Liu, Baobao Chang

Large Language Models (LLMs) exhibit remarkably powerful capabilities. One of
the crucial factors to achieve success is aligning the LLM's output with human
preferences. This alignment process often requires only a small amount of data
to efficiently enhance the LLM's performance. While effective, research in this
area spans multiple domains, and the methods involved are relatively complex to
understand. The relationships between different methods have been
under-explored, limiting the development of the preference alignment. In light
of this, we break down the existing popular alignment strategies into different
components and provide a unified framework to study the current alignment
strategies, thereby establishing connections among them. In this survey, we
decompose all the strategies in preference learning into four components:
model, data, feedback, and algorithm. This unified view offers an in-depth
understanding of existing alignment algorithms and also opens up possibilities
to synergize the strengths of different strategies. Furthermore, we present
detailed working examples of prevalent existing algorithms to facilitate a
comprehensive understanding for the readers. Finally, based on our unified
perspective, we explore the challenges and future research directions for
aligning large language models with human preferences.

摘要：大型語言模型 (LLM) 展現了強大的功能。其中一個成功的關鍵因素是將 LLM 的輸出與人類偏好保持一致。此調整過程通常只需要少量資料就能有效提升 LLM 的效能。雖然有效，但這方面的研究橫跨多個領域，且所涉及的方法相對複雜難懂。不同方法之間的關係尚未充分探討，這限制了偏好調整的發展。有鑑於此，我們將現有的熱門調整策略分解成不同的組成部分，並提供一個統一的架構來研究目前的調整策略，從而建立它們之間的聯繫。在此調查中，我們將偏好學習中的所有策略分解成四個組成部分：模型、資料、回饋和演算法。此統一觀點提供了對現有調整演算法的深入了解，也開啟了協調不同策略優勢的可能性。此外，我們提供了現有盛行演算法的詳細工作範例，以促進讀者全面了解。最後，根據我們的統一觀點，我們探討了與人類偏好調整大型語言模型的挑戰和未來的研究方向。

##### **An incremental preference elicitation-based approach to learning potentially non-monotonic preferences in multi-criteria sorting**
2409.02760v1 by Zhuolin Li, Zhen Zhang, Witold Pedrycz

This paper introduces a novel incremental preference elicitation-based
approach to learning potentially non-monotonic preferences in multi-criteria
sorting (MCS) problems, enabling decision makers to progressively provide
assignment example preference information. Specifically, we first construct a
max-margin optimization-based model to model potentially non-monotonic
preferences and inconsistent assignment example preference information in each
iteration of the incremental preference elicitation process. Using the optimal
objective function value of the max-margin optimization-based model, we devise
information amount measurement methods and question selection strategies to
pinpoint the most informative alternative in each iteration within the
framework of uncertainty sampling in active learning. Once the termination
criterion is satisfied, the sorting result for non-reference alternatives can
be determined through the use of two optimization models, i.e., the max-margin
optimization-based model and the complexity controlling optimization model.
Subsequently, two incremental preference elicitation-based algorithms are
developed to learn potentially non-monotonic preferences, considering different
termination criteria. Ultimately, we apply the proposed approach to a credit
rating problem to elucidate the detailed implementation steps, and perform
computational experiments on both artificial and real-world data sets to
compare the proposed question selection strategies with several benchmark
strategies.

摘要：本文提出了一種基於漸進偏好引導的創新方法，用於學習多準則排序 (MCS) 問題中潛在的非單調偏好，使決策者能夠逐步提供指派範例偏好資訊。具體而言，我們首先建構一個基於最大邊際優化的模型，以建模在漸進偏好引導過程的每次反覆運算中潛在的非單調偏好和不一致的指派範例偏好資訊。使用基於最大邊際優化的模型的最佳目標函數值，我們設計資訊量測量方法和問題選擇策略，以在主動學習的不確定性抽樣架構中精確找出每次反覆運算中最具資訊性的替代方案。一旦滿足終止準則，就可以透過使用兩個最佳化模型（即基於最大邊際優化的模型和複雜度控制最佳化模型）來確定非參考替代方案的排序結果。隨後，開發了兩種基於漸進偏好引導的演算法來學習潛在的非單調偏好，考量不同的終止準則。最後，我們將提出的方法應用於信用評級問題，以闡明詳細的實作步驟，並針對人工和真實世界資料集執行運算實驗，以將提出的問題選擇策略與多個基準策略進行比較。

##### **A Comparative Study of Pre-training and Self-training**
2409.02751v1 by Yiheng Wang, Jiayu Lin, Zuoquan Lin

Pre-training and self-training are two approaches to semi-supervised
learning. The comparison between pre-training and self-training has been
explored. However, the previous works led to confusing findings: self-training
outperforms pre-training experienced on some tasks in computer vision, and
contrarily, pre-training outperforms self-training experienced on some tasks in
natural language processing, under certain conditions of incomparable settings.
We propose, comparatively and exhaustively, an ensemble method to empirical
study all feasible training paradigms combining pre-training, self-training,
and fine-tuning within consistent foundational settings comparable to data
augmentation. We conduct experiments on six datasets, four data augmentation,
and imbalanced data for sentiment analysis and natural language inference
tasks. Our findings confirm that the pre-training and fine-tuning paradigm
yields the best overall performances. Moreover, self-training offers no
additional benefits when combined with semi-supervised pre-training.

摘要：預訓練和自訓練是半監督式學習的兩種方法。預訓練和自訓練之間的比較已經被探討過。然而，先前的研究導致令人困惑的發現：在某些電腦視覺任務中，自訓練優於預訓練，相反地，在某些自然語言處理任務中，預訓練優於自訓練，在某些無法比較的設定條件下。我們提出一個整體方法，比較並詳盡地進行經驗研究，在與資料擴充相當的一致基礎設定中，結合預訓練、自訓練和微調的所有可行訓練範例。我們對六個資料集、四種資料擴充和不平衡資料進行了情緒分析和自然語言推論任務的實驗。我們的發現證實預訓練和微調範例產生了最佳的整體表現。此外，自訓練與半監督式預訓練結合時，沒有提供額外的優點。

##### **Tractable Offline Learning of Regular Decision Processes**
2409.02747v1 by Ahana Deb, Roberto Cipollone, Anders Jonsson, Alessandro Ronca, Mohammad Sadegh Talebi

This work studies offline Reinforcement Learning (RL) in a class of
non-Markovian environments called Regular Decision Processes (RDPs). In RDPs,
the unknown dependency of future observations and rewards from the past
interactions can be captured by some hidden finite-state automaton. For this
reason, many RDP algorithms first reconstruct this unknown dependency using
automata learning techniques. In this paper, we show that it is possible to
overcome two strong limitations of previous offline RL algorithms for RDPs,
notably RegORL. This can be accomplished via the introduction of two original
techniques: the development of a new pseudometric based on formal languages,
which removes a problematic dependency on
$L_\infty^\mathsf{p}$-distinguishability parameters, and the adoption of
Count-Min-Sketch (CMS), instead of naive counting. The former reduces the
number of samples required in environments that are characterized by a low
complexity in language-theoretic terms. The latter alleviates the memory
requirements for long planning horizons. We derive the PAC sample complexity
bounds associated to each of these techniques, and we validate the approach
experimentally.

摘要：本研究探討非馬可夫環境中的一類離線強化學習 (RL)，稱為規則決策過程 (RDP)。在 RDP 中，未來觀察和獎勵對過去互動的未知依賴性可以由一些隱藏的有限狀態自動機捕獲。因此，許多 RDP 演算法會先使用自動機學習技術重建此未知依賴性。在本文中，我們證明可以克服先前 RDP 離線 RL 演算法的兩個重大限制，特別是 RegORL。這可以透過導入兩種原始技術來達成：基於形式語言開發新的偽度量，這消除了對$L_\infty^\mathsf{p}$可區分性參數的有問題依賴性，以及採用 Count-Min-Sketch (CMS) 代替天真的計數。前者減少了在語言理論術語中以低複雜度為特徵的環境中所需的樣本數量。後者減輕了長期規劃範圍的記憶體需求。我們推導出與這些技術相關的 PAC 樣本複雜度界限，並透過實驗驗證方法。

##### **Pooling And Attention: What Are Effective Designs For LLM-Based Embedding Models?**
2409.02727v2 by Yixuan Tang, Yi Yang

The significant advancements of Large Language Models (LLMs) in generative
tasks have led to a growing body of work exploring LLM-based embedding models.
While these models, employing different pooling and attention strategies, have
achieved state-of-the-art performance on public embedding benchmarks, questions
still arise about what constitutes an effective design for LLM-based embedding
models. However, these models are often trained on different datasets, using
different LLM base models or training settings. Moreover, evaluations on public
embedding benchmarks often fail to report statistical significance, making it
difficult to determine which designs truly contribute to final performance.
This complicates the process for practitioners seeking optimal training recipes
for LLM-based embedding models. In this study, we conduct a large-scale
experiment by training a series of LLM-based embedding models using the same
training data and base model but differing in their pooling and attention
strategies. The results show that there is no one-size-fits-all solution: while
bidirectional attention and an additional trainable pooling layer outperform in
text similarity and information retrieval tasks, they do not significantly
surpass simpler designs like EOS-last token pooling and default causal
attention in clustering and classification tasks. Furthermore, we propose a new
pooling strategy, Multi-Layers Trainable Pooling, which transforms the outputs
of all hidden layers, rather than just the last layer, using a cross-attention
network. This method proves to be statistically superior in text similarity and
retrieval tasks compared to existing pooling methods. Overall, this paper sheds
light on effective training strategies for LLM-based embedding models.

摘要：大型語言模型 (LLM) 在生成任務中的顯著進展，導致了越來越多研究探索基於 LLM 的嵌入模型。
雖然這些模型採用不同的匯總和注意力策略，已在公開嵌入基準測試中達到最先進的性能，但關於什麼構成了基於 LLM 的嵌入模型的有效設計，仍然存在疑問。
然而，這些模型通常在不同的資料集上訓練，使用不同的 LLM 基礎模型或訓練設定。
此外，對公開嵌入基準測試的評估通常未能報告統計顯著性，這使得難以確定哪些設計真正有助於最終性能。
這使得從業者尋求基於 LLM 的嵌入模型的最佳訓練配方變得複雜。
在本研究中，我們通過使用相同的訓練資料和基礎模型，但匯總和注意力策略不同的訓練一系列基於 LLM 的嵌入模型，進行了大規模實驗。
結果表明，沒有通用的解決方案：雖然雙向注意力和一個額外的可訓練匯總層在文本相似性和資訊檢索任務中表現出色，但它們並沒有顯著超過在聚類和分類任務中較簡單的設計，例如 EOS 最後標記匯總和預設因果注意力。
此外，我們提出了一種新的匯總策略，多層可訓練匯總，它使用交叉注意力網路轉換所有隱藏層的輸出，而不仅仅是最後一層。
與現有的匯總方法相比，這種方法在文本相似性和檢索任務中被證明具有統計優勢。
總的來說，本文闡明了基於 LLM 的嵌入模型的有效訓練策略。

##### **Pre-training data selection for biomedical domain adaptation using journal impact metrics**
2409.02725v1 by Mathieu Laï-king, Patrick Paroubek

Domain adaptation is a widely used method in natural language processing
(NLP) to improve the performance of a language model within a specific domain.
This method is particularly common in the biomedical domain, which sees regular
publication of numerous scientific articles. PubMed, a significant corpus of
text, is frequently used in the biomedical domain. The primary objective of
this study is to explore whether refining a pre-training dataset using specific
quality metrics for scientific papers can enhance the performance of the
resulting model. To accomplish this, we employ two straightforward journal
impact metrics and conduct experiments by continually pre-training BERT on
various subsets of the complete PubMed training set, we then evaluate the
resulting models on biomedical language understanding tasks from the BLURB
benchmark. Our results show that pruning using journal impact metrics is not
efficient. But we also show that pre-training using fewer abstracts (but with
the same number of training steps) does not necessarily decrease the resulting
model's performance.

摘要：領域適應是一種廣泛用於自然語言處理 (NLP) 中的方法，用於提升語言模型在特定領域中的表現。
此方法特別常在生物醫學領域中使用，該領域會定期發表許多科學文章。PubMed 是生物醫學領域中一個重要的語料庫，經常被使用。
本研究的主要目標是探討使用特定科學論文品質指標來精煉預訓練資料集，是否能提升所產生的模型的表現。
為達成此目標，我們採用兩個簡單的期刊影響力指標，並透過持續在 PubMed 完整訓練集的各種子集上預訓練 BERT 來進行實驗，然後在 BLURB 基準中的生物醫學語言理解任務上評估所產生的模型。
我們的結果顯示，使用期刊影響力指標進行剪枝並非有效率。
但我們也顯示，使用較少的摘要 (但訓練步驟數相同) 進行預訓練，並不會一定會降低所產生的模型的表現。

##### **Alignment-Aware Model Extraction Attacks on Large Language Models**
2409.02718v1 by Zi Liang, Qingqing Ye, Yanyun Wang, Sen Zhang, Yaxin Xiao, Ronghua Li, Jianliang Xu, Haibo Hu

Model extraction attacks (MEAs) on large language models (LLMs) have received
increasing research attention lately. Existing attack methods on LLMs inherit
the extraction strategies from those designed for deep neural networks (DNNs)
yet neglect the inconsistency of training tasks between MEA and LLMs'
alignments. As such, they result in poor attack performances. To tackle this
issue, we present Locality Reinforced Distillation (LoRD), a novel model
extraction attack algorithm specifically for LLMs. In particular, we design a
policy-gradient-style training task, which utilizes victim models' responses as
a signal to guide the crafting of preference for the local model. Theoretical
analysis has shown that i) LoRD's convergence procedure in MEAs is consistent
with the alignments of LLMs, and ii) LoRD can reduce query complexity while
mitigating watermark protection through exploration-based stealing. Extensive
experiments on domain-specific extractions demonstrate the superiority of our
method by examining the extraction of various state-of-the-art commercial LLMs.

摘要：大型語言模型 (LLM) 上的模型萃取攻擊 (MEA) 近來受到越來越多的研究關注。現有的 LLM 攻擊方法承襲了為深度神經網路 (DNN) 設計的萃取策略，但忽略了 MEA 與 LLM 對齊之間的訓練任務不一致性。因此，它們導致攻擊效能不佳。為了解決這個問題，我們提出了 Locality Reinforced Distillation (LoRD)，這是一種專門針對 LLM 的新型態模型萃取攻擊演算法。特別是，我們設計了一種策略梯度樣式的訓練任務，它利用受害者模型的回應作為引導偏好製作本地模型的訊號。理論分析顯示，i) LoRD 在 MEA 中的收斂程序與 LLM 的對齊一致，以及 ii) LoRD 可以透過探索式竊取降低查詢複雜度，同時減輕浮水印保護。針對特定領域萃取的廣泛實驗，透過檢視各種最先進的商業 LLM 的萃取，證明了我們方法的優越性。

##### **A Data Selection Approach for Enhancing Low Resource Machine Translation Using Cross-Lingual Sentence Representations**
2409.02712v1 by Nidhi Kowtal, Tejas Deshpande, Raviraj Joshi

Machine translation in low-resource language pairs faces significant
challenges due to the scarcity of parallel corpora and linguistic resources.
This study focuses on the case of English-Marathi language pairs, where
existing datasets are notably noisy, impeding the performance of machine
translation models. To mitigate the impact of data quality issues, we propose a
data filtering approach based on cross-lingual sentence representations. Our
methodology leverages a multilingual SBERT model to filter out problematic
translations in the training data. Specifically, we employ an IndicSBERT
similarity model to assess the semantic equivalence between original and
translated sentences, allowing us to retain linguistically correct translations
while discarding instances with substantial deviations. The results demonstrate
a significant improvement in translation quality over the baseline
post-filtering with IndicSBERT. This illustrates how cross-lingual sentence
representations can reduce errors in machine translation scenarios with limited
resources. By integrating multilingual sentence BERT models into the
translation pipeline, this research contributes to advancing machine
translation techniques in low-resource environments. The proposed method not
only addresses the challenges in English-Marathi language pairs but also
provides a valuable framework for enhancing translation quality in other
low-resource language translation tasks.

摘要：機器翻譯在低資源語言配對中由於平行語料和語言資源的稀缺而面臨重大挑戰。這項研究專注於英語-馬拉提語語言配對，其中現有的資料集明顯有雜訊，阻礙了機器翻譯模型的執行。為了減輕資料品質問題的影響，我們提出一個基於跨語言句子表示的資料過濾方法。我們的做法利用多語言 SBERT 模型來過濾掉訓練資料中的有問題翻譯。具體來說，我們採用 IndicSBERT 相似性模型來評估原始句子和翻譯句子的語義等效性，讓我們得以保留語言上正確的翻譯，同時捨棄有重大偏差的實例。結果表明，使用 IndicSBERT 過濾後翻譯品質大幅提升。這說明了跨語言句子表示如何能減少資源有限的機器翻譯場景中的錯誤。藉由將多語言句子 BERT 模型整合到翻譯管道中，這項研究有助於推進低資源環境中的機器翻譯技術。所提議的方法不僅解決了英語-馬拉提語語言配對中的挑戰，也提供了一個有價值的架構，用於提升其他低資源語言翻譯任務的翻譯品質。

##### **Creating a Gen-AI based Track and Trace Assistant MVP (SuperTracy) for PostNL**
2409.02711v1 by Mohammad Reshadati

The developments in the field of generative AI has brought a lot of
opportunities for companies, for instance to improve efficiency in customer
service and automating tasks. PostNL, the biggest parcel and E-commerce
corporation of the Netherlands wants to use generative AI to enhance the
communication around track and trace of parcels. During the internship a
Minimal Viable Product (MVP) is created to showcase the value of using
generative AI technologies, to enhance parcel tracking, analyzing the parcel's
journey and being able to communicate about it in an easy to understand manner.
The primary goal was to develop an in-house LLM-based system, reducing
dependency on external platforms and establishing the feasibility of a
dedicated generative AI team within the company. This multi-agent LLM based
system aimed to construct parcel journey stories and identify logistical
disruptions with heightened efficiency and accuracy. The research involved
deploying a sophisticated AI-driven communication system, employing
Retrieval-Augmented Generation (RAG) for enhanced response precision, and
optimizing large language models (LLMs) tailored to domain specific tasks.
  The MVP successfully implemented a multi-agent open-source LLM system, called
SuperTracy. SuperTracy is capable of autonomously managing a broad spectrum of
user inquiries and improving internal knowledge handling. Results and
evaluation demonstrated technological innovation and feasibility, notably in
communication about the track and trace of a parcel, which exceeded initial
expectations. These advancements highlight the potential of AI-driven solutions
in logistics, suggesting many opportunities for further refinement and broader
implementation within PostNL operational framework.

摘要：<paragraph>生成式 AI 領域的發展為企業帶來許多機會，例如提升客服效率和自動化任務。荷蘭最大的包裹和電子商務公司 PostNL 希望使用生成式 AI 來加強包裹追蹤的溝通。實習期間，建立一個可行性最低產品 (MVP) 以展示使用生成式 AI 技術的價值，以加強包裹追蹤、分析包裹旅程並能夠以易於理解的方式進行溝通。主要目標是開發一個內部 LLM 為基礎的系統，減少對外部平台的依賴，並建立公司內專門的生成式 AI 團隊的可行性。這個多代理的 LLM 為基礎的系統旨在建構包裹旅程故事並識別後勤中斷，且效率和準確性都更高。研究涉及部署一個由 AI 驅動的先進溝通系統，採用檢索增強生成 (RAG) 以增強回應的精準度，並針對特定領域任務最佳化大型語言模型 (LLM)。MVP 成功實施了一個多代理的開源 LLM 系統，稱為 SuperTracy。SuperTracy 能夠自主管理廣泛的使用者詢問，並改善內部知識處理。結果和評估證明了技術創新和可行性，特別是在包裹追蹤的溝通方面，超出了最初的預期。這些進展突顯了 AI 驅動解決方案在物流方面的潛力，這表示有許多機會可以進一步改善並在 PostNL 的營運架構中更廣泛地實施。</paragraph>

##### **Incorporating Like-Minded Peers to Overcome Friend Data Sparsity in Session-Based Social Recommendations**
2409.02702v1 by Chunyan An, Yunhan Li, Qiang Yang, Winston K. G. Seah, Zhixu Li, Conghao Yanga

Session-based Social Recommendation (SSR) leverages social relationships
within online networks to enhance the performance of Session-based
Recommendation (SR). However, existing SSR algorithms often encounter the
challenge of ``friend data sparsity''. Moreover, significant discrepancies can
exist between the purchase preferences of social network friends and those of
the target user, reducing the influence of friends relative to the target
user's own preferences. To address these challenges, this paper introduces the
concept of ``Like-minded Peers'' (LMP), representing users whose preferences
align with the target user's current session based on their historical
sessions. This is the first work, to our knowledge, that uses LMP to enhance
the modeling of social influence in SSR. This approach not only alleviates the
problem of friend data sparsity but also effectively incorporates users with
similar preferences to the target user. We propose a novel model named
Transformer Encoder with Graph Attention Aggregator Recommendation (TEGAARec),
which includes the TEGAA module and the GAT-based social aggregation module.
The TEGAA module captures and merges both long-term and short-term interests
for target users and LMP users. Concurrently, the GAT-based social aggregation
module is designed to aggregate the target users' dynamic interests and social
influence in a weighted manner. Extensive experiments on four real-world
datasets demonstrate the efficacy and superiority of our proposed model and
ablation studies are done to illustrate the contributions of each component in
TEGAARec.

摘要：<paragraph>基於會話的社交推薦 (SSR) 利用線上網路中的社交關係來提升基於會話的推薦 (SR) 的效能。然而，現有的 SSR 演算法經常會遭遇「好友資料稀疏性」的挑戰。此外，社交網路好友的購買偏好與目標使用者之間可能存在顯著差異，降低了好友相對於目標使用者自身偏好的影響力。為了應對這些挑戰，本文引入了「志同道合的同儕」(LMP) 的概念，代表其偏好與目標使用者基於其歷史會話的當前會話相符的使用者。據我們所知，這是第一個使用 LMP 來增強 SSR 中社交影響力建模的研究。這種方法不僅可以緩解好友資料稀疏性的問題，還能有效地納入與目標使用者具有類似偏好的使用者。我們提出了一個名為 Transformer 編碼器與圖形注意力聚合器推薦 (TEGAARec) 的新模型，其中包括 TEGAA 模組和基於 GAT 的社交聚合模組。TEGAA 模組擷取並合併目標使用者和 LMP 使用者的長期和短期興趣。同時，基於 GAT 的社交聚合模組旨在以加權方式聚合目標使用者的動態興趣和社交影響力。在四個真實世界的資料集上進行的廣泛實驗證明了我們提出的模型的有效性和優越性，並進行了消融研究來說明 TEGAARec 中每個組成的貢獻。</paragraph>

##### **LLM-Assisted Visual Analytics: Opportunities and Challenges**
2409.02691v1 by Maeve Hutchinson, Radu Jianu, Aidan Slingsby, Pranava Madhyastha

We explore the integration of large language models (LLMs) into visual
analytics (VA) systems to transform their capabilities through intuitive
natural language interactions. We survey current research directions in this
emerging field, examining how LLMs are integrated into data management,
language interaction, visualisation generation, and language generation
processes. We highlight the new possibilities that LLMs bring to VA, especially
how they can change VA processes beyond the usual use cases. We especially
highlight building new visualisation-language models, allowing access of a
breadth of domain knowledge, multimodal interaction, and opportunities with
guidance. Finally, we carefully consider the prominent challenges of using
current LLMs in VA tasks. Our discussions in this paper aim to guide future
researchers working on LLM-assisted VA systems and help them navigate common
obstacles when developing these systems.

摘要：我們探討將大型語言模型 (LLM) 整合到視覺分析 (VA) 系統中，以透過直觀的自然語言互動來轉換其功能。我們調查這個新興領域中當前的研究方向，探討 LLM 如何整合到資料管理、語言互動、視覺化產生和語言產生過程中。我們重點說明 LLM 為 VA 帶來的各種新可能性，特別是它們如何改變 VA 過程，超越一般常見的用例。我們特別強調建立新的視覺化語言模型，允許存取廣泛的領域知識、多模態互動和指導機會。最後，我們仔細考量在 VA 任務中使用目前 LLM 的顯著挑戰。我們在本文中的討論旨在引導未來研究人員從事 LLM 輔助的 VA 系統，並幫助他們在開發這些系統時克服常見的障礙。

##### **Detecting Calls to Action in Multimodal Content: Analysis of the 2021 German Federal Election Campaign on Instagram**
2409.02690v1 by Michael Achmann-Denkler, Jakob Fehle, Mario Haim, Christian Wolff

This study investigates the automated classification of Calls to Action
(CTAs) within the 2021 German Instagram election campaign to advance the
understanding of mobilization in social media contexts. We analyzed over 2,208
Instagram stories and 712 posts using fine-tuned BERT models and OpenAI's GPT-4
models. The fine-tuned BERT model incorporating synthetic training data
achieved a macro F1 score of 0.93, demonstrating a robust classification
performance. Our analysis revealed that 49.58% of Instagram posts and 10.64% of
stories contained CTAs, highlighting significant differences in mobilization
strategies between these content types. Additionally, we found that FDP and the
Greens had the highest prevalence of CTAs in posts, whereas CDU and CSU led in
story CTAs.

摘要：本研究調查 2021 年德國 Instagram 選舉活動中行動呼籲 (CTA) 的自動分類，以促進對社交媒體背景中動員的理解。我們使用微調後的 BERT 模型和 OpenAI 的 GPT-4 模型分析了超過 2,208 個 Instagram 限時動態和 712 篇貼文。結合合成訓練資料的微調 BERT 模型達到了 0.93 的巨觀 F1 分數，證明了穩健的分類效能。我們的分析顯示，49.58% 的 Instagram 貼文和 10.64% 的限時動態包含 CTA，突顯了這些內容類型之間動員策略的顯著差異。此外，我們發現 FDP 和綠黨在貼文中 CTA 的盛行率最高，而 CDU 和 CSU 則在限時動態 CTA 中領先。

##### **Deconfounded Causality-aware Parameter-Efficient Fine-Tuning for Problem-Solving Improvement of LLMs**
2409.02686v1 by Ruoyu Wang, Xiaoxuan Li, Lina Yao

Large Language Models (LLMs) have demonstrated remarkable efficiency in
tackling various tasks based on human instructions, but recent studies reveal
that these models often fail to achieve satisfactory results on questions
involving reasoning, such as mathematics or physics questions. This phenomenon
is usually attributed to the uncertainty regarding whether these models could
genuinely comprehend the knowledge embedded in the text or merely learn to
replicate the token distribution without a true understanding of the content.
In this paper, we delve into this problem and aim to enhance the reasoning
capabilities of LLMs. First, we investigate if the model has genuine reasoning
capabilities by visualizing the text generation process at the attention and
representation level. Then, we formulate the reasoning process of LLMs into a
causal framework, which provides a formal explanation of the problems we
observe in the visualization. Finally, building upon this causal framework, we
propose Deconfounded Causal Adaptation (DCA), a novel parameter-efficient
fine-tuning (PEFT) method to enhance the model's reasoning capabilities by
encouraging the model to extract the general problem-solving skills and apply
these skills to different questions. Experiments show that our method
outperforms the baseline consistently across multiple benchmarks, and with only
1.2M tunable parameters, we achieve better or comparable results to other
fine-tuning methods. This demonstrates the effectiveness and efficiency of our
method in improving the overall accuracy and reliability of LLMs.

摘要：大型語言模型 (LLM) 已證明在根據人類指示處理各種任務方面具有顯著的效率，但最近的研究表明，這些模型在涉及推理的問題（例如數學或物理問題）上常常無法獲得令人滿意的結果。這種現象通常歸因於不確定性，即這些模型是否可以真正理解嵌入在文本中的知識，或者僅僅學會複製符號分佈而沒有真正理解內容。在本文中，我們深入探討這個問題，並旨在增強 LLM 的推理能力。首先，我們通過在關注和表示層面視覺化文本生成過程，來調查模型是否具有真正的推理能力。然後，我們將 LLM 的推理過程制定為因果框架，這對我們在視覺化中觀察到的問題提供了正式解釋。最後，在此因果框架的基礎上，我們提出了去混淆因果適應 (DCA)，這是一種新穎的參數高效微調 (PEFT) 方法，通過鼓勵模型提取一般問題解決技能並將這些技能應用於不同的問題，來增強模型的推理能力。實驗表明，我們的模型在多個基準上始終優於基準，並且僅使用 120 萬個可調參數，我們就獲得了比其他微調方法更好或相當的結果。這證明了我們的方法在提高 LLM 的整體準確性和可靠性方面的有效性和效率。

##### **RouterRetriever: Exploring the Benefits of Routing over Multiple Expert Embedding Models**
2409.02685v1 by Hyunji Lee, Luca Soldaini, Arman Cohan, Minjoon Seo, Kyle Lo

Information retrieval methods often rely on a single embedding model trained
on large, general-domain datasets like MSMARCO. While this approach can produce
a retriever with reasonable overall performance, models trained on
domain-specific data often yield better results within their respective
domains. While prior work in information retrieval has tackled this through
multi-task training, the topic of combining multiple domain-specific expert
retrievers remains unexplored, despite its popularity in language model
generation. In this work, we introduce RouterRetriever, a retrieval model that
leverages multiple domain-specific experts along with a routing mechanism to
select the most appropriate expert for each query. It is lightweight and allows
easy addition or removal of experts without additional training. Evaluation on
the BEIR benchmark demonstrates that RouterRetriever outperforms both
MSMARCO-trained (+2.1 absolute nDCG@10) and multi-task trained (+3.2) models.
This is achieved by employing our routing mechanism, which surpasses other
routing techniques (+1.8 on average) commonly used in language modeling.
Furthermore, the benefit generalizes well to other datasets, even in the
absence of a specific expert on the dataset. To our knowledge, RouterRetriever
is the first work to demonstrate the advantages of using multiple
domain-specific expert embedding models with effective routing over a single,
general-purpose embedding model in retrieval tasks.

摘要：資訊檢索方法通常依賴於大型通用領域資料集（例如 MSMARCO）上訓練的單一嵌入模型。雖然這種方法可以產生具有合理整體效能的檢索器，但針對特定領域資料訓練的模型通常會在其各自的領域中產生更好的結果。雖然先前的資訊檢索工作已透過多任務訓練來解決此問題，但儘管在語言模型產生中很受歡迎，結合多個特定領域專家檢索器的議題仍未被探討。在這項工作中，我們介紹 RouterRetriever，這是一個檢索模型，它利用多個特定領域專家以及路由機制來為每個查詢選擇最合適的專家。它很輕量，且允許輕鬆新增或移除專家，而無需額外訓練。在 BEIR 基準上的評估顯示，RouterRetriever 優於 MSMARCO 訓練的（+2.1 絕對 nDCG@10）和多任務訓練的（+3.2）模型。這是透過採用我們的路由機制來實現的，該機制優於語言建模中常用的其他路由技術（平均 +1.8）。此外，這種優點很好地推廣到其他資料集，即使在資料集中沒有特定專家的情況下也是如此。據我們所知，RouterRetriever 是第一個展示在檢索任務中使用多個特定領域專家嵌入模型與有效路由優於單一通用嵌入模型的優點的工作。

##### **Neural Networks with LSTM and GRU in Modeling Active Fires in the Amazon**
2409.02681v1 by Ramon Tavares

This study presents a comprehensive methodology for modeling and forecasting
the historical time series of fire spots detected by the AQUA_M-T satellite in
the Amazon, Brazil. The approach utilizes a mixed Recurrent Neural Network
(RNN) model, combining Long Short-Term Memory (LSTM) and Gated Recurrent Unit
(GRU) architectures to predict monthly accumulations of daily detected fire
spots. A summary of the data revealed a consistent seasonality over time, with
annual maximum and minimum fire spot values tending to repeat at the same
periods each year. The primary objective is to verify whether the forecasts
capture this inherent seasonality through rigorous statistical analysis. The
methodology involved careful data preparation, model configuration, and
training using cross-validation with two seeds, ensuring that the data
generalizes well to the test and validation sets, and confirming the
convergence of the model parameters. The results indicate that the mixed LSTM
and GRU model offers improved accuracy in forecasting 12 months ahead,
demonstrating its effectiveness in capturing complex temporal patterns and
modeling the observed time series. This research significantly contributes to
the application of deep learning techniques in environmental monitoring,
specifically in fire spot forecasting. In addition to improving forecast
accuracy, the proposed approach highlights the potential for adaptation to
other time series forecasting challenges, opening new avenues for research and
development in machine learning and natural phenomenon prediction. Keywords:
Time Series Forecasting, Recurrent Neural Networks, Deep Learning.

摘要：本研究提出了一個全面的方法，用於建模和預測巴西亞馬遜地區由 AQUA_M-T 衛星偵測到的歷史火災點時間序列。該方法採用混合遞迴神經網路 (RNN) 模型，結合長短期記憶 (LSTM) 和門控遞迴單元 (GRU) 架構，以預測每日偵測火災點的月累計值。對資料的摘要顯示出隨著時間推移而出現的一致季節性，每年的年度最大和最小火災點值傾向於在同一時期重複出現。主要目標是透過嚴謹的統計分析驗證預測是否捕捉到這種固有的季節性。該方法涉及仔細的資料準備、模型配置，以及使用兩個種子的交叉驗證進行訓練，確保資料能很好地推廣到測試和驗證集，並確認模型參數的收斂性。結果表明，混合 LSTM 和 GRU 模型在預測 12 個月後提供了更高的準確度，證明了其在捕捉複雜時間模式和建模觀測時間序列方面的有效性。本研究顯著地促进了深度學習技術在環境監測中的應用，特別是在火災點預測方面。除了提高預測準確度外，所提出的方法還強調了適應其他時間序列預測挑戰的潛力，為機器學習和自然現象預測的研究和開發開闢了新的途徑。關鍵字：時間序列預測、遞迴神經網路、深度學習。

##### **Causality-Aware Transformer Networks for Robotic Navigation**
2409.02669v1 by Ruoyu Wang, Yao Liu, Yuanjiang Cao, Lina Yao

Recent advances in machine learning algorithms have garnered growing interest
in developing versatile Embodied AI systems. However, current research in this
domain reveals opportunities for improvement. First, the direct adoption of
RNNs and Transformers often overlooks the specific differences between Embodied
AI and traditional sequential data modelling, potentially limiting its
performance in Embodied AI tasks. Second, the reliance on task-specific
configurations, such as pre-trained modules and dataset-specific logic,
compromises the generalizability of these methods. We address these constraints
by initially exploring the unique differences between Embodied AI tasks and
other sequential data tasks through the lens of Causality, presenting a causal
framework to elucidate the inadequacies of conventional sequential methods for
Embodied AI. By leveraging this causal perspective, we propose Causality-Aware
Transformer (CAT) Networks for Navigation, featuring a Causal Understanding
Module to enhance the models's Environmental Understanding capability.
Meanwhile, our method is devoid of task-specific inductive biases and can be
trained in an End-to-End manner, which enhances the method's generalizability
across various contexts. Empirical evaluations demonstrate that our methodology
consistently surpasses benchmark performances across a spectrum of settings,
tasks and simulation environments. Extensive ablation studies reveal that the
performance gains can be attributed to the Causal Understanding Module, which
demonstrates effectiveness and efficiency in both Reinforcement Learning and
Supervised Learning settings.

摘要：機器學習演算法的最新進展引起了人們對開發通用具身 AI 系統的興趣。然而，目前在這個領域的研究顯示有改進的機會。首先，直接採用 RNN 和 Transformer 通常會忽略具身 AI 和傳統序列資料建模之間的具體差異，可能會限制其在具身 AI 任務中的效能。其次，依賴任務特定的組態，例如預先訓練的模組和特定於資料集的邏輯，會影響這些方法的概括性。我們透過因果關係的視角，探討具身 AI 任務和其他序列資料任務之間的獨特差異，來解決這些限制，並提出一個因果架構來說明傳統序列方法在具身 AI 中的不足。透過利用這個因果觀點，我們提出用於導航的因果感知 Transformer (CAT) 網路，其中具備因果理解模組來增強模型的環境理解能力。同時，我們的方法沒有任務特定的歸納偏差，並且可以用端到端的方式進行訓練，這增強了該方法在各種情境中的概括性。經驗評估顯示，我們的技術在各種設定、任務和模擬環境中，始終超越基準效能。廣泛的消融研究表明，效能提升可以歸因於因果理解模組，這在強化學習和監督式學習設定中都展現了有效性和效率。

##### **Creating Domain-Specific Translation Memories for Machine Translation Fine-tuning: The TRENCARD Bilingual Cardiology Corpus**
2409.02667v1 by Gokhan Dogru

This article investigates how translation memories (TM) can be created by
translators or other language professionals in order to compile domain-specific
parallel corpora , which can then be used in different scenarios, such as
machine translation training and fine-tuning, TM leveraging, and/or large
language model fine-tuning. The article introduces a semi-automatic TM
preparation methodology leveraging primarily translation tools used by
translators in favor of data quality and control by the translators. This
semi-automatic methodology is then used to build a cardiology-based Turkish ->
English corpus from bilingual abstracts of Turkish cardiology journals. The
resulting corpus called TRENCARD Corpus has approximately 800,000 source words
and 50,000 sentences. Using this methodology, translators can build their
custom TMs in a reasonable time and use them in their bilingual data requiring
tasks.

摘要：本文探討了翻譯人員或其他語言專業人員如何建立翻譯記憶體 (TM)，以編譯特定領域的平行語料庫，然後可將其用於不同的場景，例如機器翻譯訓練和微調、TM 利用和/或大型語言模型微調。本文介紹了一種半自動 TM 準備方法，主要利用翻譯人員使用的翻譯工具，有利於翻譯人員的資料品質和控制。然後使用這種半自動方法從土耳其心臟病學期刊的雙語摘要建立一個以心臟病學為基礎的土耳其語 -> 英語語料庫。所產生的語料庫稱為 TRENCARD 語料庫，大約有 800,000 個來源字詞和 50,000 個句子。使用這種方法，翻譯人員可以在合理的時間內建立自己的自訂 TM，並將其用於需要雙語資料的任務中。

##### **PoseTalk: Text-and-Audio-based Pose Control and Motion Refinement for One-Shot Talking Head Generation**
2409.02657v1 by Jun Ling, Yiwen Wang, Han Xue, Rong Xie, Li Song

While previous audio-driven talking head generation (THG) methods generate
head poses from driving audio, the generated poses or lips cannot match the
audio well or are not editable. In this study, we propose \textbf{PoseTalk}, a
THG system that can freely generate lip-synchronized talking head videos with
free head poses conditioned on text prompts and audio. The core insight of our
method is using head pose to connect visual, linguistic, and audio signals.
First, we propose to generate poses from both audio and text prompts, where the
audio offers short-term variations and rhythm correspondence of the head
movements and the text prompts describe the long-term semantics of head
motions. To achieve this goal, we devise a Pose Latent Diffusion (PLD) model to
generate motion latent from text prompts and audio cues in a pose latent space.
Second, we observe a loss-imbalance problem: the loss for the lip region
contributes less than 4\% of the total reconstruction loss caused by both pose
and lip, making optimization lean towards head movements rather than lip
shapes. To address this issue, we propose a refinement-based learning strategy
to synthesize natural talking videos using two cascaded networks, i.e.,
CoarseNet, and RefineNet. The CoarseNet estimates coarse motions to produce
animated images in novel poses and the RefineNet focuses on learning finer lip
motions by progressively estimating lip motions from low-to-high resolutions,
yielding improved lip-synchronization performance. Experiments demonstrate our
pose prediction strategy achieves better pose diversity and realness compared
to text-only or audio-only, and our video generator model outperforms
state-of-the-art methods in synthesizing talking videos with natural head
motions. Project: https://junleen.github.io/projects/posetalk.

摘要：<paragraph>儘管先前的音訊驅動說話頭部生成 (THG) 方法可從驅動音訊中生成頭部姿勢，但生成的姿勢或嘴唇無法與音訊良好匹配，或無法編輯。在本研究中，我們提出一個 THG 系統 \textbf{PoseTalk}，該系統可以自由生成與文字提示和音訊相符的唇部同步說話頭部影片，且具有自由的頭部姿勢。我們方法的核心見解是使用頭部姿勢連接視覺、語言和音訊訊號。首先，我們建議從音訊和文字提示中生成姿勢，其中音訊提供頭部動作的短期變化和節奏對應，而文字提示則描述頭部動作的長期語意。為達成此目標，我們設計了一個姿勢潛在擴散 (PLD) 模型，在姿勢潛在空間中從文字提示和音訊提示中生成動作潛在。其次，我們觀察到損失不平衡的問題：嘴唇區域的損失小於姿勢和嘴唇造成的總重建損失的 4%，這使得最佳化傾向於頭部動作，而不是嘴唇形狀。為了解決此問題，我們提出一個基於精煉的學習策略，使用兩個串聯網路合成自然說話影片，即 CoarseNet 和 RefineNet。CoarseNet 估計粗略動作以產生新姿勢的動畫影像，而 RefineNet 則專注於透過從低解析度到高解析度逐步估計嘴唇動作來學習更精細的嘴唇動作，進而改善唇部同步效能。實驗證明，與僅文字或僅音訊相比，我們的姿勢預測策略可獲得更好的姿勢多樣性和真實性，而我們的影片生成器模型在合成具有自然頭部動作的說話影片方面優於最先進的方法。專案：https://junleen.github.io/projects/posetalk。</paragraph>

##### **OpenFact at CheckThat! 2024: Combining Multiple Attack Methods for Effective Adversarial Text Generation**
2409.02649v2 by Włodzimierz Lewoniewski, Piotr Stolarski, Milena Stróżyna, Elzbieta Lewańska, Aleksandra Wojewoda, Ewelina Księżniak, Marcin Sawiński

This paper presents the experiments and results for the CheckThat! Lab at
CLEF 2024 Task 6: Robustness of Credibility Assessment with Adversarial
Examples (InCrediblAE). The primary objective of this task was to generate
adversarial examples in five problem domains in order to evaluate the
robustness of widely used text classification methods (fine-tuned BERT, BiLSTM,
and RoBERTa) when applied to credibility assessment issues.
  This study explores the application of ensemble learning to enhance
adversarial attacks on natural language processing (NLP) models. We
systematically tested and refined several adversarial attack methods, including
BERT-Attack, Genetic algorithms, TextFooler, and CLARE, on five datasets across
various misinformation tasks. By developing modified versions of BERT-Attack
and hybrid methods, we achieved significant improvements in attack
effectiveness. Our results demonstrate the potential of modification and
combining multiple methods to create more sophisticated and effective
adversarial attack strategies, contributing to the development of more robust
and secure systems.

摘要：這篇論文呈現了 CLEF 2024 任務 6 中 CheckThat！實驗室的實驗和結果：對抗範例的信譽評估的穩健性 (InCrediblAE)。此任務的主要目標是在五個問題領域中產生對抗範例，以評估廣泛使用的文本分類方法（微調過的 BERT、BiLSTM 和 RoBERTa）在應用於信譽評估問題時的穩健性。
此研究探討了套件學習的應用，以增強對自然語言處理 (NLP) 模型的對抗攻擊。我們系統性地測試和改進了幾種對抗攻擊方法，包括 BERT-Attack、遺傳演算法、TextFooler 和 CLARE，針對五個資料集，跨越各種錯誤訊息任務。透過開發 BERT-Attack 和混合方法的修改版本，我們在攻擊效能方面獲得了顯著的進步。我們的結果證明了修改和結合多種方法以建立更精緻且有效的對抗攻擊策略的潛力，有助於開發更穩健且安全的系統。

##### **A Survey on Emergent Language**
2409.02645v1 by Jannik Peters, Constantin Waubert de Puiseau, Hasan Tercan, Arya Gopikrishnan, Gustavo Adolpho Lucas De Carvalho, Christian Bitter, Tobias Meisen

The field of emergent language represents a novel area of research within the
domain of artificial intelligence, particularly within the context of
multi-agent reinforcement learning. Although the concept of studying language
emergence is not new, early approaches were primarily concerned with explaining
human language formation, with little consideration given to its potential
utility for artificial agents. In contrast, studies based on reinforcement
learning aim to develop communicative capabilities in agents that are
comparable to or even superior to human language. Thus, they extend beyond the
learned statistical representations that are common in natural language
processing research. This gives rise to a number of fundamental questions, from
the prerequisites for language emergence to the criteria for measuring its
success. This paper addresses these questions by providing a comprehensive
review of 181 scientific publications on emergent language in artificial
intelligence. Its objective is to serve as a reference for researchers
interested in or proficient in the field. Consequently, the main contributions
are the definition and overview of the prevailing terminology, the analysis of
existing evaluation methods and metrics, and the description of the identified
research gaps.

摘要：新興語言領域代表人工智慧研究中一個新穎的研究領域，特別是在多重代理強化學習的脈絡中。儘管研究語言新興的概念並非新鮮事，但早期的方法主要關注於解釋人類語言的形成，鮮少考量其對人工代理的潛在效用。相反地，基於強化學習的研究旨在開發代理的溝通能力，使其與人類語言相當甚至優於人類語言。因此，它們超越了自然語言處理研究中常見的已學習統計表徵。這引發了一系列基本問題，從語言新興的先決條件到衡量其成功的標準。本文透過提供對人工智慧中新興語言的 181 篇科學出版品進行全面回顧來探討這些問題。其目標是作為對該領域感興趣或精通的研究人員的參考。因此，主要的貢獻在於定義並概述流行的術語、分析現有的評估方法和指標，以及描述已識別的研究差距。

##### **Evaluating Environments Using Exploratory Agents**
2409.02632v1 by Bobby Khaleque, Mike Cook, Jeremy Gow

Exploration is a key part of many video games. We investigate the using an
exploratory agent to provide feedback on the design of procedurally generated
game levels, 5 engaging levels and 5 unengaging levels. We expand upon a
framework introduced in previous research which models motivations for
exploration and introduce a fitness function for evaluating an environment's
potential for exploration. Our study showed that our exploratory agent can
clearly distinguish between engaging and unengaging levels. The findings
suggest that our agent has the potential to serve as an effective tool for
assessing procedurally generated levels, in terms of exploration. This work
contributes to the growing field of AI-driven game design by offering new
insights into how game environments can be evaluated and optimised for player
exploration.

摘要：探索是許多電子遊戲的關鍵部分。我們研究使用探索代理來提供程序生成遊戲關卡設計的回饋，5 個引人入勝的關卡和 5 個無趣的關卡。我們擴展了先前研究中引入的架構，該架構建構探索的動機模型，並引入一個適應度函數來評估環境的探索潛力。我們的研究表明，我們的探索代理可以清楚地區分引人入勝和無趣的關卡。研究結果表明，我們的代理程式有潛力作為評估程序生成關卡的有效工具，就探索而言。這項工作透過提供有關如何評估和最佳化遊戲環境以利玩家探索的新見解，為 AI 驅動的遊戲設計成長領域做出貢獻。

##### **AdvSecureNet: A Python Toolkit for Adversarial Machine Learning**
2409.02629v1 by Melih Catal, Manuel Günther

Machine learning models are vulnerable to adversarial attacks. Several tools
have been developed to research these vulnerabilities, but they often lack
comprehensive features and flexibility. We introduce AdvSecureNet, a PyTorch
based toolkit for adversarial machine learning that is the first to natively
support multi-GPU setups for attacks, defenses, and evaluation. It is the first
toolkit that supports both CLI and API interfaces and external YAML
configuration files to enhance versatility and reproducibility. The toolkit
includes multiple attacks, defenses and evaluation metrics. Rigiorous software
engineering practices are followed to ensure high code quality and
maintainability. The project is available as an open-source project on GitHub
at https://github.com/melihcatal/advsecurenet and installable via PyPI.

摘要：機器學習模型容易受到對抗性攻擊。已經開發了多種工具來研究這些漏洞，但它們通常缺乏全面的功能和靈活性。我們介紹 AdvSecureNet，這是一個基於 PyTorch 的對抗式機器學習工具包，它率先原生支援多 GPU 設定，用於攻擊、防禦和評估。它是第一個同時支援 CLI 和 API 介面和外部 YAML 設定檔的工具包，以增強多功能性和可複製性。該工具包包含多種攻擊、防禦和評估指標。遵循嚴格的軟體工程實務，以確保高程式碼品質和可維護性。該專案可作為 GitHub 上的開源專案取得，網址為 https://github.com/melihcatal/advsecurenet，並可透過 PyPI 安裝。

##### **PUB: Plot Understanding Benchmark and Dataset for Evaluating Large Language Models on Synthetic Visual Data Interpretation**
2409.02617v1 by Aneta Pawelec, Victoria Sara Wesołowska, Zuzanna Bączek, Piotr Sankowski

The ability of large language models (LLMs) to interpret visual
representations of data is crucial for advancing their application in data
analysis and decision-making processes. This paper presents a novel synthetic
dataset designed to evaluate the proficiency of LLMs in interpreting various
forms of data visualizations, including plots like time series, histograms,
violins, boxplots, and clusters. Our dataset is generated using controlled
parameters to ensure comprehensive coverage of potential real-world scenarios.
We employ multimodal text prompts with questions related to visual data in
images to benchmark several state-of-the-art models like ChatGPT or Gemini,
assessing their understanding and interpretative accuracy.
  To ensure data integrity, our benchmark dataset is generated automatically,
making it entirely new and free from prior exposure to the models being tested.
This strategy allows us to evaluate the models' ability to truly interpret and
understand the data, eliminating possibility of pre-learned responses, and
allowing for an unbiased evaluation of the models' capabilities. We also
introduce quantitative metrics to assess the performance of the models,
providing a robust and comprehensive evaluation tool.
  Benchmarking several state-of-the-art LLMs with this dataset reveals varying
degrees of success, highlighting specific strengths and weaknesses in
interpreting diverse types of visual data. The results provide valuable
insights into the current capabilities of LLMs and identify key areas for
improvement. This work establishes a foundational benchmark for future research
and development aimed at enhancing the visual interpretative abilities of
language models. In the future, improved LLMs with robust visual interpretation
skills can significantly aid in automated data analysis, scientific research,
educational tools, and business intelligence applications.

摘要：大型語言模型 (LLM) 解釋資料視覺化呈現的能力對於提升其在資料分析和決策制定流程中的應用至關重要。本文提出一個新穎的合成資料集，旨在評估 LLM 解釋各種資料視覺化形式的能力，包括時序圖、直方圖、小提琴圖、箱型圖和群集等。我們的資料集是使用受控參數生成的，以確保全面涵蓋潛在的真實世界場景。我們採用多模態文字提示，其中包含與圖像中視覺資料相關的問題，以評量多個最先進的模型，例如 ChatGPT 或 Gemini，評估其理解力與詮釋準確性。
為了確保資料完整性，我們的基準資料集是自動產生的，使其完全新穎且不受測試模型先前接觸的影響。此策略讓我們得以評估模型真正詮釋和理解資料的能力，消除了預先學習的回應的可能性，並能公正評估模型的能力。我們也引進量化指標來評估模型的效能，提供一個穩健且全面的評估工具。
使用此資料集評量多個最先進的 LLM，揭示出不同程度的成功，突顯出詮釋不同類型視覺資料的特定優勢和劣勢。結果提供了寶貴的見解，了解 LLM 目前的能力，並找出關鍵的改進領域。這項工作為未來的研究和開發奠定了一個基礎基準，旨在提升語言模型的視覺詮釋能力。未來，具有強大視覺詮釋技能的改良 LLM 可以顯著協助自動化資料分析、科學研究、教育工具和商業智慧應用。

##### **SurgTrack: CAD-Free 3D Tracking of Real-world Surgical Instruments**
2409.02598v1 by Wenwu Guo, Jinlin Wu, Zhen Chen, Qingxiang Zhao, Miao Xu, Zhen Lei, Hongbin Liu

Vision-based surgical navigation has received increasing attention due to its
non-invasive, cost-effective, and flexible advantages. In particular, a
critical element of the vision-based navigation system is tracking surgical
instruments. Compared with 2D instrument tracking methods, 3D instrument
tracking has broader value in clinical practice, but is also more challenging
due to weak texture, occlusion, and lack of Computer-Aided Design (CAD) models
for 3D registration. To solve these challenges, we propose the SurgTrack, a
two-stage 3D instrument tracking method for CAD-free and robust real-world
applications. In the first registration stage, we incorporate an Instrument
Signed Distance Field (SDF) modeling the 3D representation of instruments,
achieving CAD-freed 3D registration. Due to this, we can obtain the location
and orientation of instruments in the 3D space by matching the video stream
with the registered SDF model. In the second tracking stage, we devise a
posture graph optimization module, leveraging the historical tracking results
of the posture memory pool to optimize the tracking results and improve the
occlusion robustness. Furthermore, we collect the Instrument3D dataset to
comprehensively evaluate the 3D tracking of surgical instruments. The extensive
experiments validate the superiority and scalability of our SurgTrack, by
outperforming the state-of-the-arts with a remarkable improvement. The code and
dataset are available at https://github.com/wenwucode/SurgTrack.

摘要：<paragraph>基於視覺的外科導航由於其非侵入性、成本效益和靈活性優勢而受到越來越多的關注。特別是，基於視覺的導航系統的一個關鍵元素是追蹤手術器械。與 2D 器械追蹤方法相比，3D 器械追蹤在臨床實務中具有更廣泛的價值，但由於紋理弱、遮擋和缺乏用於 3D 配準的電腦輔助設計 (CAD) 模型，因此也更具挑戰性。為了解決這些挑戰，我們提出 SurgTrack，一種適用於無 CAD 和穩健的真實世界應用程式的兩階段 3D 器械追蹤方法。在第一個配準階段，我們整合一個器械簽署距離場 (SDF)，對器械的 3D 表徵進行建模，實現無 CAD 的 3D 配準。因此，我們可以透過將視訊串流與已配準的 SDF 模型進行匹配，取得器械在 3D 空間中的位置和方向。在第二個追蹤階段，我們設計一個姿勢圖最佳化模組，利用姿勢記憶池的歷史追蹤結果來最佳化追蹤結果並改善遮擋的穩健性。此外，我們收集 Instrument3D 資料集，以全面評估手術器械的 3D 追蹤。廣泛的實驗驗證了我們 SurgTrack 的優越性和可擴充性，以顯著的改進優於現有技術。程式碼和資料集可在 https://github.com/wenwucode/SurgTrack 取得。</paragraph>

##### **Solving Video Inverse Problems Using Image Diffusion Models**
2409.02574v1 by Taesung Kwon, Jong Chul Ye

Recently, diffusion model-based inverse problem solvers (DIS) have emerged as
state-of-the-art approaches for addressing inverse problems, including image
super-resolution, deblurring, inpainting, etc. However, their application to
video inverse problems arising from spatio-temporal degradation remains largely
unexplored due to the challenges in training video diffusion models. To address
this issue, here we introduce an innovative video inverse solver that leverages
only image diffusion models. Specifically, by drawing inspiration from the
success of the recent decomposed diffusion sampler (DDS), our method treats the
time dimension of a video as the batch dimension of image diffusion models and
solves spatio-temporal optimization problems within denoised spatio-temporal
batches derived from each image diffusion model. Moreover, we introduce a
batch-consistent diffusion sampling strategy that encourages consistency across
batches by synchronizing the stochastic noise components in image diffusion
models. Our approach synergistically combines batch-consistent sampling with
simultaneous optimization of denoised spatio-temporal batches at each reverse
diffusion step, resulting in a novel and efficient diffusion sampling strategy
for video inverse problems. Experimental results demonstrate that our method
effectively addresses various spatio-temporal degradations in video inverse
problems, achieving state-of-the-art reconstructions. Project page:
https://solving-video-inverse.github.io/main/

摘要：近來，基於擴散模型的反問題求解器 (DIS) 已成為解決反問題的最新方法，包括影像超解析度、去模糊、填補等。然而，由於訓練影片擴散模型的挑戰性，它們在因時空退化而產生的影片反問題中的應用仍未廣泛探討。為了解決這個問題，我們在此介紹一種創新的影片反問題求解器，它僅利用影像擴散模型。具體來說，我們的模型從最近分解擴散採樣器 (DDS) 的成功中汲取靈感，將影片的時間維度視為影像擴散模型的批次維度，並在從每個影像擴散模型衍生的去噪時空批次中解決時空最佳化問題。此外，我們引入了一種批次一致的擴散採樣策略，透過同步影像擴散模型中的隨機雜訊組成，來促進批次間的一致性。我們的模型協同結合了批次一致的採樣，以及在每個反向擴散步驟中同時最佳化去噪時空批次，產生了一種新穎且有效的影片反問題擴散採樣策略。實驗結果表明，我們的模型有效地解決了影片反問題中的各種時空退化，達到了最先進的重建效果。專案頁面：
https://solving-video-inverse.github.io/main/

##### **Advancing Cyber Incident Timeline Analysis Through Rule Based AI and Large Language Models**
2409.02572v1 by Fatma Yasmine Loumachi, Mohamed Chahine Ghanem

Timeline Analysis (TA) is a key part of Timeline Forensics (TF) in Digital
Forensics (DF), focusing primarily on examining and analysing temporal digital
artefacts such as timestamps, derived from event logs, file metadata, and other
related data to correlate events resulting from cyber incidents and reconstruct
their chronological timeline. Traditional tools often struggle to efficiently
process the vast volume and variety of data acquired during DF investigations
and Incident Response (IR) processes. This paper presents a novel framework,
GenDFIR, that combines Rule-Based Artificial Intelligence (R-BAI) algorithms
with Large Language Models (LLMs) to advance and automate the TA process. Our
approach consists of two main stages (1) We use R-BAI to identify and select
anomalous digital artefacts based on predefined rules. (2) The selected
artefacts are then converted into embeddings for processing by an LLM with the
help of a Retrieval-Augmented Generation (RAG) agent. The LLM consequently
leverages its capabilities to perform automated TA on the artefacts and predict
potential incident scenarios. To validate our framework, we evaluate GenDFIR
performance, efficiency, and reliability using various metrics across synthetic
cyber incident simulation scenarios. This paper presents a proof of concept,
where the findings demonstrate the significant potential of integrating R-BAI
and LLMs for TA. This novel approach highlights the power of Generative AI
(GenAI), specifically LLMs, and opens new avenues for advanced threat detection
and incident reconstruction, representing a significant step forward in the
field.

摘要：時間軸分析 (TA) 是數位鑑識 (DF) 中時間軸鑑識 (TF) 的關鍵部分，主要專注於檢查和分析時間數位製品，例如時間戳記、從事件記錄、檔案元資料和其它相關資料衍生而來的時間戳記，以關聯網路事件造成的事件並重建其時間軸。傳統工具常常難以有效率地處理 DF 調查和事件回應 (IR) 程序中取得的龐大資料量和種類。這篇論文提出一個新穎的架構 GenDFIR，結合基於規則的人工智慧 (R-BAI) 演算法和大語言模型 (LLM)，以推進和自動化 TA 程序。我們的做法包含兩個主要階段：(1) 我們使用 R-BAI 來識別和選取基於預先定義規則的異常數位製品。(2) 接著將選取的製品轉換為嵌入，以在檢索增強生成 (RAG) 代理的協助下，由 LLM 處理。因此，LLM 利用其功能對製品執行自動化 TA，並預測潛在的事件場景。為了驗證我們的架構，我們使用各種指標，針對合成網路事件模擬場景評估 GenDFIR 的效能、效率和可靠性。這篇論文提出一個概念驗證，其中發現展示整合 R-BAI 和 LLM 進行 TA 的重大潛力。這種新穎的做法強調生成式 AI (GenAI)，特別是 LLM 的力量，並為進階威脅偵測和事件重建開啟新途徑，代表該領域向前邁進一大步。

##### **More is More: Addition Bias in Large Language Models**
2409.02569v1 by Luca Santagata, Cristiano De Nobili

In this paper, we investigate the presence of additive bias in Large Language
Models (LLMs), drawing a parallel to the cognitive bias observed in humans
where individuals tend to favor additive over subtractive changes. Using a
series of controlled experiments, we tested various LLMs, including GPT-3.5
Turbo, Claude 3.5 Sonnet, Mistral, Math$\Sigma$tral, and Llama 3.1, on tasks
designed to measure their propensity for additive versus subtractive
modifications. Our findings demonstrate a significant preference for additive
changes across all tested models. For example, in a palindrome creation task,
Llama 3.1 favored adding letters 97.85% of the time over removing them.
Similarly, in a Lego tower balancing task, GPT-3.5 Turbo chose to add a brick
76.38% of the time rather than remove one. In a text summarization task,
Mistral 7B produced longer summaries in 59.40% to 75.10% of cases when asked to
improve its own or others' writing. These results indicate that, similar to
humans, LLMs exhibit a marked additive bias, which might have implications when
LLMs are used on a large scale. Addittive bias might increase resource use and
environmental impact, leading to higher economic costs due to overconsumption
and waste. This bias should be considered in the development and application of
LLMs to ensure balanced and efficient problem-solving approaches.

摘要：<paragraph>在本文中，我們探討大型語言模型 (LLM) 中加法偏差的存在，並與人類認知偏差進行比較，其中個人傾向於偏好加法而非減法變更。我們使用一系列受控實驗，測試了各種 LLM，包括 GPT-3.5 Turbo、Claude 3.5 Sonnet、Mistral、Math$\Sigma$tral 和 Llama 3.1，這些任務旨在衡量它們對加法與減法修改的傾向性。我們的研究結果顯示，所有測試模型都顯著偏好加法變更。例如，在迴文創建任務中，Llama 3.1 有 97.85% 的時間偏好新增字母，而不是移除字母。類似地，在樂高積木平衡任務中，GPT-3.5 Turbo 有 76.38% 的時間選擇新增積木，而不是移除積木。在文字摘要任務中，Mistral 7B 在 59.40% 到 75.10% 的情況下產生較長的摘要，當被要求改善其自身或他人的寫作時。這些結果表明，與人類類似，LLM 表現出明顯的加法偏差，這在 LLM 大規模使用時可能會產生影響。加法偏差可能會增加資源使用和環境影響，從而導致因過度消費和浪費而產生的較高經濟成本。在開發和應用 LLM 時應考慮這種偏差，以確保平衡且有效率的解決問題方法。</paragraph>

##### **Vision-Language Navigation with Continual Learning**
2409.02561v1 by Zhiyuan Li, Yanfeng Lv, Ziqin Tu, Di Shang, Hong Qiao

Vision-language navigation (VLN) is a critical domain within embedded
intelligence, requiring agents to navigate 3D environments based on natural
language instructions. Traditional VLN research has focused on improving
environmental understanding and decision accuracy. However, these approaches
often exhibit a significant performance gap when agents are deployed in novel
environments, mainly due to the limited diversity of training data. Expanding
datasets to cover a broader range of environments is impractical and costly. We
propose the Vision-Language Navigation with Continual Learning (VLNCL) paradigm
to address this challenge. In this paradigm, agents incrementally learn new
environments while retaining previously acquired knowledge. VLNCL enables
agents to maintain an environmental memory and extract relevant knowledge,
allowing rapid adaptation to new environments while preserving existing
information. We introduce a novel dual-loop scenario replay method (Dual-SR)
inspired by brain memory replay mechanisms integrated with VLN agents. This
method facilitates consolidating past experiences and enhances generalization
across new tasks. By utilizing a multi-scenario memory buffer, the agent
efficiently organizes and replays task memories, thereby bolstering its ability
to adapt quickly to new environments and mitigating catastrophic forgetting.
Our work pioneers continual learning in VLN agents, introducing a novel
experimental setup and evaluation metrics. We demonstrate the effectiveness of
our approach through extensive evaluations and establish a benchmark for the
VLNCL paradigm. Comparative experiments with existing continual learning and
VLN methods show significant improvements, achieving state-of-the-art
performance in continual learning ability and highlighting the potential of our
approach in enabling rapid adaptation while preserving prior knowledge.

摘要：視覺語言導航 (VLN) 是嵌入式智慧中的一個關鍵領域，要求代理根據自然語言指令在 3D 環境中導航。傳統的 VLN 研究一直專注於改善環境理解和決策準確度。然而，當代理部署在新的環境中時，這些方法經常表現出顯著的效能差距，這主要是因為訓練資料的多樣性有限。擴展資料集以涵蓋更廣泛的環境既不切實際又昂貴。我們提出具備持續學習的視覺語言導航 (VLNCL) 典範來應對這一挑戰。在此典範中，代理逐漸學習新的環境，同時保留先前獲得的知識。VLNCL 使代理能夠維護環境記憶體並提取相關知識，從而允許快速適應新環境，同時保留現有資訊。我們引入了一種新穎的雙迴路場景重播方法 (Dual-SR)，其靈感來自與 VLN 代理整合的腦記憶重播機制。此方法有助於整合過去的經驗並增強跨新任務的概括性。透過利用多場景記憶體緩衝區，代理有效地組織和重播任務記憶體，從而增強其快速適應新環境和減輕災難性遺忘的能力。我們的研究開創了 VLN 代理中的持續學習，引入了新穎的實驗設置和評估指標。我們透過廣泛的評估證明了我們方法的有效性，並為 VLNCL 典範建立了一個基準。與現有的持續學習和 VLN 方法進行的比較實驗顯示出顯著的改進，在持續學習能力方面取得了最先進的效能，並突出了我們方法在保留先前知識的同時實現快速適應的潛力。

##### **Low-Resolution Object Recognition with Cross-Resolution Relational Contrastive Distillation**
2409.02555v1 by Kangkai Zhang, Shiming Ge, Ruixin Shi, Dan Zeng

Recognizing objects in low-resolution images is a challenging task due to the
lack of informative details. Recent studies have shown that knowledge
distillation approaches can effectively transfer knowledge from a
high-resolution teacher model to a low-resolution student model by aligning
cross-resolution representations. However, these approaches still face
limitations in adapting to the situation where the recognized objects exhibit
significant representation discrepancies between training and testing images.
In this study, we propose a cross-resolution relational contrastive
distillation approach to facilitate low-resolution object recognition. Our
approach enables the student model to mimic the behavior of a well-trained
teacher model which delivers high accuracy in identifying high-resolution
objects. To extract sufficient knowledge, the student learning is supervised
with contrastive relational distillation loss, which preserves the similarities
in various relational structures in contrastive representation space. In this
manner, the capability of recovering missing details of familiar low-resolution
objects can be effectively enhanced, leading to a better knowledge transfer.
Extensive experiments on low-resolution object classification and
low-resolution face recognition clearly demonstrate the effectiveness and
adaptability of our approach.

摘要：辨識低解析度影像中的物體是一項具有挑戰性的任務，原因在於缺乏有意義的細節。最近的研究顯示，知識蒸餾方法可以透過比對跨解析度表徵，有效地將知識從高解析度教師模型轉移到低解析度學生模型。然而，這些方法在適應辨識物體在訓練和測試影像之間展現顯著表徵差異的情況時，仍然面臨限制。在本研究中，我們提出一個跨解析度關係對比蒸餾方法，以促進低解析度物體辨識。我們的做法讓學生模型能夠模仿訓練良好的教師模型的行為，該模型在辨識高解析度物體時能提供高準確度。為了萃取足夠的知識，學生學習受到對比關係蒸餾損失的監督，這保留了對比表徵空間中各種關係結構中的相似性。透過這種方式，可以有效地增強恢復熟悉低解析度物體遺失細節的能力，進而達到更好的知識轉移。在低解析度物體分類和低解析度人臉辨識上的廣泛實驗清楚地證明了我們方法的有效性和適應性。

##### **A Sequential Decision-Making Model for Perimeter Identification**
2409.02549v2 by Ayal Taitler

Perimeter identification involves ascertaining the boundaries of a designated
area or zone, requiring traffic flow monitoring, control, or optimization.
Various methodologies and technologies exist for accurately defining these
perimeters; however, they often necessitate specialized equipment, precise
mapping, or comprehensive data for effective problem delineation. In this
study, we propose a sequential decision-making framework for perimeter search,
designed to operate efficiently in real-time and require only publicly
accessible information. We conceptualize the perimeter search as a game between
a playing agent and an artificial environment, where the agent's objective is
to identify the optimal perimeter by sequentially improving the current
perimeter. We detail the model for the game and discuss its adaptability in
determining the definition of an optimal perimeter. Ultimately, we showcase the
model's efficacy through a real-world scenario, highlighting the identification
of corresponding optimal perimeters.

摘要：周界識別涉及確定指定區域或區域的邊界，需要交通流量監控、控制或最佳化。
存在各種方法和技術來準確定義這些周界；然而，它們通常需要專業設備、精確對應或全面數據才能有效描述問題。在本研究中，我們提出了一個用於周界搜尋的順序決策制定框架，旨在實時高效運行，並且僅需要公開可用的資訊。我們將周界搜尋概念化為一個玩家代理和人工環境之間的遊戲，其中代理的目標是通過順序改善當前周界來識別最佳周界。我們詳細說明了遊戲模型，並討論了其在確定最佳周界定義方面的適應性。最終，我們通過一個真實世界的場景展示了模型的效能，重點說明了對應最佳周界的識別。

##### **Understanding eGFR Trajectories and Kidney Function Decline via Large Multimodal Models**
2409.02530v1 by Chih-Yuan Li, Jun-Ting Wu, Chan Hsu, Ming-Yen Lin, Yihuang Kang

The estimated Glomerular Filtration Rate (eGFR) is an essential indicator of
kidney function in clinical practice. Although traditional equations and
Machine Learning (ML) models using clinical and laboratory data can estimate
eGFR, accurately predicting future eGFR levels remains a significant challenge
for nephrologists and ML researchers. Recent advances demonstrate that Large
Language Models (LLMs) and Large Multimodal Models (LMMs) can serve as robust
foundation models for diverse applications. This study investigates the
potential of LMMs to predict future eGFR levels with a dataset consisting of
laboratory and clinical values from 50 patients. By integrating various
prompting techniques and ensembles of LMMs, our findings suggest that these
models, when combined with precise prompts and visual representations of eGFR
trajectories, offer predictive performance comparable to existing ML models.
This research extends the application of foundation models and suggests avenues
for future studies to harness these models in addressing complex medical
forecasting challenges.

摘要：估計的腎小球過濾率 (eGFR) 是臨床實務中腎臟功能的重要指標。雖然傳統方程式和使用臨床與實驗室資料的機器學習 (ML) 模型可以估計 eGFR，但準確預測未來 eGFR 水平仍然是腎臟科醫師和 ML 研究人員的一大挑戰。最近的研究進展顯示，大型語言模型 (LLM) 和大型多模態模型 (LMM) 可以作為各種應用程式的強健基礎模型。本研究探討 LMM 預測未來 eGFR 水平的潛力，其資料集包含 50 位病患的實驗室和臨床數值。透過整合各種提示技術和 LMM 的合奏，我們的研究結果顯示，這些模型在結合精確提示和 eGFR 軌跡的視覺化表示時，可提供與現有 ML 模型相近的預測效能。這項研究擴展了基礎模型的應用，並為未來研究利用這些模型來應對複雜的醫療預測挑戰提供了途徑。

##### **Cog-GA: A Large Language Models-based Generative Agent for Vision-Language Navigation in Continuous Environments**
2409.02522v1 by Zhiyuan Li, Yanfeng Lu, Yao Mu, Hong Qiao

Vision Language Navigation in Continuous Environments (VLN-CE) represents a
frontier in embodied AI, demanding agents to navigate freely in unbounded 3D
spaces solely guided by natural language instructions. This task introduces
distinct challenges in multimodal comprehension, spatial reasoning, and
decision-making. To address these challenges, we introduce Cog-GA, a generative
agent founded on large language models (LLMs) tailored for VLN-CE tasks. Cog-GA
employs a dual-pronged strategy to emulate human-like cognitive processes.
Firstly, it constructs a cognitive map, integrating temporal, spatial, and
semantic elements, thereby facilitating the development of spatial memory
within LLMs. Secondly, Cog-GA employs a predictive mechanism for waypoints,
strategically optimizing the exploration trajectory to maximize navigational
efficiency. Each waypoint is accompanied by a dual-channel scene description,
categorizing environmental cues into 'what' and 'where' streams as the brain.
This segregation enhances the agent's attentional focus, enabling it to discern
pertinent spatial information for navigation. A reflective mechanism
complements these strategies by capturing feedback from prior navigation
experiences, facilitating continual learning and adaptive replanning. Extensive
evaluations conducted on VLN-CE benchmarks validate Cog-GA's state-of-the-art
performance and ability to simulate human-like navigation behaviors. This
research significantly contributes to the development of strategic and
interpretable VLN-CE agents.

摘要：<paragraph>在連續環境中進行視覺語言導航 (VLN-CE) 代表著具身 AI 的前沿，要求代理在僅由自然語言指令引導的無界 3D 空間中自由導航。此任務在多模態理解、空間推理和決策制定方面帶來了不同的挑戰。為了應對這些挑戰，我們引入了 Cog-GA，這是一個生成式代理，建立在專門針對 VLN-CE 任務的大型語言模型 (LLM) 之上。Cog-GA 採用雙管齊下的策略來模擬類人認知過程。首先，它構建了一個認知地圖，整合了時間、空間和語義元素，從而促進了 LLM 中空間記憶的發展。其次，Cog-GA 採用了一個用於路徑點的預測機制，策略性地優化探索軌跡以最大化導航效率。每個路徑點都附帶一個雙通道場景描述，將環境線索分類為「什麼」和「在哪裡」流，就像大腦一樣。這種分離增強了代理的注意力焦點，使其能夠辨別與導航相關的空間信息。一個反射機制通過捕捉先前導航經驗的回饋來補充這些策略，促進持續學習和適應性重新規劃。在 VLN-CE 基準上進行的廣泛評估驗證了 Cog-GA 的最新技術和模擬類人導航行為的能力。這項研究極大地促进了策略性和可解釋性 VLN-CE 代理的發展。</paragraph>

##### **Language is Scary when Over-Analyzed: Unpacking Implied Misogynistic Reasoning with Argumentation Theory-Driven Prompts**
2409.02519v1 by Arianna Muti, Federico Ruggeri, Khalid Al-Khatib, Alberto Barrón-Cedeño, Tommaso Caselli

We propose misogyny detection as an Argumentative Reasoning task and we
investigate the capacity of large language models (LLMs) to understand the
implicit reasoning used to convey misogyny in both Italian and English. The
central aim is to generate the missing reasoning link between a message and the
implied meanings encoding the misogyny. Our study uses argumentation theory as
a foundation to form a collection of prompts in both zero-shot and few-shot
settings. These prompts integrate different techniques, including
chain-of-thought reasoning and augmented knowledge. Our findings show that LLMs
fall short on reasoning capabilities about misogynistic comments and that they
mostly rely on their implicit knowledge derived from internalized common
stereotypes about women to generate implied assumptions, rather than on
inductive reasoning.

摘要：我們將厭女情結偵測視為一種論證推理任務，並探討大型語言模型 (LLM) 理解用於傳達義大利語和英語中厭女情結的隱含推理的能力。核心目標是產生訊息與編碼厭女情結的隱含意義之間遺失的推理連結。我們的研究以論證理論為基礎，在零次學習和少次學習設定中形成一系列提示。這些提示整合了不同的技術，包括思考鏈推理和增強知識。我們的研究結果顯示，LLM 在推理厭女評論的能力上有所不足，而且它們主要依賴於從內化女性的常見刻板印象中衍生的隱含知識來產生隱含假設，而非歸納推理。

##### **Continual Diffuser (CoD): Mastering Continual Offline Reinforcement Learning with Experience Rehearsal**
2409.02512v1 by Jifeng Hu, Li Shen, Sili Huang, Zhejian Yang, Hechang Chen, Lichao Sun, Yi Chang, Dacheng Tao

Artificial neural networks, especially recent diffusion-based models, have
shown remarkable superiority in gaming, control, and QA systems, where the
training tasks' datasets are usually static. However, in real-world
applications, such as robotic control of reinforcement learning (RL), the tasks
are changing, and new tasks arise in a sequential order. This situation poses
the new challenge of plasticity-stability trade-off for training an agent who
can adapt to task changes and retain acquired knowledge. In view of this, we
propose a rehearsal-based continual diffusion model, called Continual Diffuser
(CoD), to endow the diffuser with the capabilities of quick adaptation
(plasticity) and lasting retention (stability). Specifically, we first
construct an offline benchmark that contains 90 tasks from multiple domains.
Then, we train the CoD on each task with sequential modeling and conditional
generation for making decisions. Next, we preserve a small portion of previous
datasets as the rehearsal buffer and replay it to retain the acquired
knowledge. Extensive experiments on a series of tasks show CoD can achieve a
promising plasticity-stability trade-off and outperform existing
diffusion-based methods and other representative baselines on most tasks.

摘要：人工神經網路，尤其是近期基於擴散的模型，在遊戲、控制和問答系統中展現出卓越的優越性，其中訓練任務的資料集通常是靜態的。然而，在真實世界的應用中，例如強化學習 (RL) 的機器人控制，任務會發生變化，而且會按順序出現新任務。這種情況對訓練代理人適應任務變化並保留習得知識提出了可塑性穩定性權衡的新挑戰。有鑑於此，我們提出了一個基於複習的持續擴散模型，稱為持續擴散器 (CoD)，賦予擴散器快速適應（可塑性）和持久保留（穩定性）的能力。具體來說，我們首先構建一個包含來自多個領域的 90 個任務的離線基準。然後，我們使用順序建模和條件生成對每個任務訓練 CoD 以做出決策。接下來，我們保留一小部分先前的資料集作為複習緩衝區，並重播它以保留習得的知識。在一系列任務上進行的廣泛實驗表明，CoD 可以實現有前景的可塑性穩定性權衡，並在多數任務上優於現有的基於擴散的方法和其他代表性基準。

##### **CoAst: Validation-Free Contribution Assessment for Federated Learning based on Cross-Round Valuation**
2409.02495v1 by Hao Wu, Likun Zhang, Shucheng Li, Fengyuan Xu, Sheng Zhong

In the federated learning (FL) process, since the data held by each
participant is different, it is necessary to figure out which participant has a
higher contribution to the model performance. Effective contribution assessment
can help motivate data owners to participate in the FL training. Research works
in this field can be divided into two directions based on whether a validation
dataset is required. Validation-based methods need to use representative
validation data to measure the model accuracy, which is difficult to obtain in
practical FL scenarios. Existing validation-free methods assess the
contribution based on the parameters and gradients of local models and the
global model in a single training round, which is easily compromised by the
stochasticity of model training. In this work, we propose CoAst, a practical
method to assess the FL participants' contribution without access to any
validation data. The core idea of CoAst involves two aspects: one is to only
count the most important part of model parameters through a weights
quantization, and the other is a cross-round valuation based on the similarity
between the current local parameters and the global parameter updates in
several subsequent communication rounds. Extensive experiments show that CoAst
has comparable assessment reliability to existing validation-based methods and
outperforms existing validation-free methods.

摘要：在联邦学习 (FL) 过程中，由于每个参与者所掌握的数据不同，因此有必要找出对模型性能贡献较高的参与者。有效的贡献评估可以帮助激励数据所有者参与 FL 培训。根据是否需要验证数据集，该领域的的研究工作可分为两个方向。基于验证的方法需要使用有代表性的验证数据来衡量模型准确度，这在实际的 FL 场景中很难获得。现有的无验证方法根据单次训练轮中的局部模型和全局模型的参数和梯度来评估贡献，很容易受到模型训练随机性的影响。在这项工作中，我们提出了 CoAst，这是一种无需访问任何验证数据即可评估 FL 参与者贡献的实用方法。CoAst 的核心思想涉及两个方面：一是通过权重量化仅计算模型参数中最重要的部分，另一个是基于当前局部参数与全局参数更新在几个后续通信轮次中的相似性进行跨轮次估值。大量实验表明，CoAst 具有与现有基于验证的方法相当的评估可靠性，并且优于现有的无验证方法。

##### **NeuroSpex: Neuro-Guided Speaker Extraction with Cross-Modal Attention**
2409.02489v1 by Dashanka De Silva, Siqi Cai, Saurav Pahuja, Tanja Schultz, Haizhou Li

In the study of auditory attention, it has been revealed that there exists a
robust correlation between attended speech and elicited neural responses,
measurable through electroencephalography (EEG). Therefore, it is possible to
use the attention information available within EEG signals to guide the
extraction of the target speaker in a cocktail party computationally. In this
paper, we present a neuro-guided speaker extraction model, i.e. NeuroSpex,
using the EEG response of the listener as the sole auxiliary reference cue to
extract attended speech from monaural speech mixtures. We propose a novel EEG
signal encoder that captures the attention information. Additionally, we
propose a cross-attention (CA) mechanism to enhance the speech feature
representations, generating a speaker extraction mask. Experimental results on
a publicly available dataset demonstrate that our proposed model outperforms
two baseline models across various evaluation metrics.

摘要：在聽覺注意力的研究中，已經發現被關注的言語和引發的神經反應之間存在穩固的關聯性，這可以用腦電圖 (EEG) 來測量。因此，可以利用 EEG 訊號中可用的注意力資訊，在計算雞尾酒會中引導目標說話者的提取。在本文中，我們提出了一個神經引導的說話者提取模型，即 NeuroSpex，它使用聽眾的 EEG 反應作為唯一的輔助參考線索，從單聲道語音混合中提取被關注的言語。我們提出了一個新穎的 EEG 訊號編碼器，它可以擷取注意力資訊。此外，我們提出了一個交叉注意力 (CA) 機制，以增強語音特徵表徵，生成說話者提取遮罩。在公開可用的資料集上的實驗結果表明，我們提出的模型在各種評估指標上都優於兩個基準模型。

##### **Boosting Generalizability towards Zero-Shot Cross-Dataset Single-Image Indoor Depth by Meta-Initialization**
2409.02486v1 by Cho-Ying Wu, Yiqi Zhong, Junying Wang, Ulrich Neumann

Indoor robots rely on depth to perform tasks like navigation or obstacle
detection, and single-image depth estimation is widely used to assist
perception. Most indoor single-image depth prediction focuses less on model
generalizability to unseen datasets, concerned with in-the-wild robustness for
system deployment. This work leverages gradient-based meta-learning to gain
higher generalizability on zero-shot cross-dataset inference. Unlike the
most-studied meta-learning of image classification associated with explicit
class labels, no explicit task boundaries exist for continuous depth values
tied to highly varying indoor environments regarding object arrangement and
scene composition. We propose fine-grained task that treats each RGB-D
mini-batch as a task in our meta-learning formulation. We first show that our
method on limited data induces a much better prior (max 27.8% in RMSE). Then,
finetuning on meta-learned initialization consistently outperforms baselines
without the meta approach. Aiming at generalization, we propose zero-shot
cross-dataset protocols and validate higher generalizability induced by our
meta-initialization, as a simple and useful plugin to many existing depth
estimation methods. The work at the intersection of depth and meta-learning
potentially drives both research to step closer to practical robotic and
machine perception usage.

摘要：室內機器人依賴深度來執行導航或障礙物偵測等任務，而單一影像深度估計廣泛用於協助感知。大多數室內單一影像深度預測較少關注模型對未見資料集的概化能力，而關注系統部署的實際穩健性。本研究利用基於梯度的元學習，在零次學習跨資料集推論中獲得更高的概化能力。與最常研究的影像分類元學習相關聯的明確類別標籤不同，對於與物件配置和場景組成相關的高度變異室內環境，沒有明確的任務界線存在於連續深度值中。我們提出細緻的任務，將每個 RGB-D 迷你批次視為我們元學習公式中的任務。我們首先展示我們的有限資料方法會產生更好的先驗（RMSE 中最多 27.8%）。然後，在元學習初始化上進行微調始終優於沒有元方法的基準。為了概化，我們提出零次學習跨資料集協定，並驗證由我們的元初始化產生的更高概化能力，作為許多現有深度估計方法的簡單且有用的外掛程式。深度和元學習的交叉研究，潛在地推動兩項研究更接近實用的機器人和機器感知應用。

##### **TASAR: Transferable Attack on Skeletal Action Recognition**
2409.02483v1 by Yunfeng Diao, Baiqi Wu, Ruixuan Zhang, Ajian Liu, Xingxing Wei, Meng Wang, He Wang

Skeletal sequences, as well-structured representations of human behaviors,
are crucial in Human Activity Recognition (HAR). The transferability of
adversarial skeletal sequences enables attacks in real-world HAR scenarios,
such as autonomous driving, intelligent surveillance, and human-computer
interactions. However, existing Skeleton-based HAR (S-HAR) attacks exhibit weak
adversarial transferability and, therefore, cannot be considered true
transfer-based S-HAR attacks. More importantly, the reason for this failure
remains unclear. In this paper, we study this phenomenon through the lens of
loss surface, and find that its sharpness contributes to the poor
transferability in S-HAR. Inspired by this observation, we assume and
empirically validate that smoothening the rugged loss landscape could
potentially improve adversarial transferability in S-HAR. To this end, we
propose the first Transfer-based Attack on Skeletal Action Recognition, TASAR.
TASAR explores the smoothed model posterior without re-training the pre-trained
surrogates, which is achieved by a new post-train Dual Bayesian optimization
strategy. Furthermore, unlike previous transfer-based attacks that treat each
frame independently and overlook temporal coherence within sequences, TASAR
incorporates motion dynamics into the Bayesian attack gradient, effectively
disrupting the spatial-temporal coherence of S-HARs. To exhaustively evaluate
the effectiveness of existing methods and our method, we build the first
large-scale robust S-HAR benchmark, comprising 7 S-HAR models, 10 attack
methods, 3 S-HAR datasets and 2 defense models. Extensive results demonstrate
the superiority of TASAR. Our benchmark enables easy comparisons for future
studies, with the code available in the supplementary material.

摘要：骨架序列作为人类行为的结构化表示，在人类活动识别 (HAR) 中至关重要。对抗骨架序列的可迁移性使得在现实世界的 HAR 场景中能够进行攻击，例如自动驾驶、智能监控和人机交互。然而，现有的基于骨架的 HAR (S-HAR) 攻击表现出较弱的对抗可迁移性，因此不能被认为是真正的基于迁移的 S-HAR 攻击。更重要的是，这种失败的原因仍然不明确。在本文中，我们通过损失面的视角研究了这种现象，发现其尖锐性导致了 S-HAR 中的可迁移性较差。受此观察结果的启发，我们假设并通过实验证明，平滑崎岖的损失面貌似可以提高 S-HAR 中的对抗可迁移性。为此，我们提出了第一个基于迁移的骨架动作识别攻击 TASAR。TASAR 探索平滑模型后验，而无需重新训练预训练的代理，这是通过新的后训练双贝叶斯优化策略实现的。此外，与将每个帧独立处理并忽略序列中时间连贯性的以前基于迁移的攻击不同，TASAR 将运动动态纳入贝叶斯攻击梯度，有效地破坏了 S-HAR 的时空连贯性。为了全面评估现有方法和我们方法的有效性，我们构建了第一个大规模鲁棒 S-HAR 基准，包括 7 个 S-HAR 模型、10 个攻击方法、3 个 S-HAR 数据集和 2 个防御模型。广泛的结果证明了 TASAR 的优越性。我们的基准使未来的研究能够轻松进行比较，代码可在补充材料中获得。

##### **Word and Phrase Features in Graph Convolutional Network for Automatic Question Classification**
2409.02481v1 by Junyoung Lee, Ninad Dixit, Kaustav Chakrabarti, S. Supraja

Effective question classification is crucial for AI-driven educational tools,
enabling adaptive learning systems to categorize questions by skill area,
difficulty level, and competence. This classification not only supports
educational diagnostics and analytics but also enhances complex tasks like
information retrieval and question answering by associating questions with
relevant categories. Traditional methods, often based on word embeddings and
conventional classifiers, struggle to capture the nuanced relationships in
natural language, leading to suboptimal performance. To address this, we
propose a novel approach leveraging graph convolutional networks (GCNs), named
Phrase Question-Graph Convolutional Network (PQ-GCN) to better model the
inherent structure of questions. By representing questions as graphs -- where
nodes signify words or phrases and edges denote syntactic or semantic
relationships -- our method allows GCNs to learn from the interconnected nature
of language more effectively. Additionally, we explore the incorporation of
phrase-based features to enhance classification accuracy, especially in
low-resource settings. Our findings demonstrate that GCNs, augmented with these
features, offer a promising solution for more accurate and context-aware
question classification, bridging the gap between graph neural network research
and practical educational applications.

摘要：有效的問題分類對於 AI 驅動的教育工具至關重要，
讓適應性學習系統能依據技能領域、
難度等級和能力對問題進行分類。這種分類不僅支援
教育診斷和分析，還能透過將問題與
相關類別關聯起來，增強資訊檢索和問題解答等複雜任務。傳統方法通常建立在詞嵌入和
傳統分類器上，難以捕捉自然語言中的細微關係，導致次佳效能。為了解決這個問題，我們
提出了一種創新的方法，利用圖形卷積網路 (GCN)，稱為
Phrase Question-Graph Convolutional Network (PQ-GCN) 來更好地建模問題的內在結構。透過將問題表示為圖形——其中
節點表示詞或詞組，邊緣表示語法或語義關係——我們的模型允許 GCN 更有效地從語言的相互連結性質中學習。此外，我們探索了整合
基於詞組的特徵以增強分類準確度，特別是在
低資源設定中。我們的研究結果表明，GCN 在這些
特徵的增強下，為更準確且具備情境感知能力的問題分類提供了一個有前途的解決方案，縮小了圖形神經網路研究
與實際教育應用之間的差距。

##### **A Comparative Study on Large Language Models for Log Parsing**
2409.02474v1 by Merve Astekin, Max Hort, Leon Moonen

Background: Log messages provide valuable information about the status of
software systems. This information is provided in an unstructured fashion and
automated approaches are applied to extract relevant parameters. To ease this
process, log parsing can be applied, which transforms log messages into
structured log templates. Recent advances in language models have led to
several studies that apply ChatGPT to the task of log parsing with promising
results. However, the performance of other state-of-the-art large language
models (LLMs) on the log parsing task remains unclear.
  Aims: In this study, we investigate the current capability of
state-of-the-art LLMs to perform log parsing.
  Method: We select six recent LLMs, including both paid proprietary (GPT-3.5,
Claude 2.1) and four free-to-use open models, and compare their performance on
system logs obtained from a selection of mature open-source projects. We design
two different prompting approaches and apply the LLMs on 1, 354 log templates
across 16 different projects. We evaluate their effectiveness, in the number of
correctly identified templates, and the syntactic similarity between the
generated templates and the ground truth.
  Results: We found that free-to-use models are able to compete with paid
models, with CodeLlama extracting 10% more log templates correctly than
GPT-3.5. Moreover, we provide qualitative insights into the usability of
language models (e.g., how easy it is to use their responses).
  Conclusions: Our results reveal that some of the smaller, free-to-use LLMs
can considerably assist log parsing compared to their paid proprietary
competitors, especially code-specialized models.

摘要：<paragraph>背景：記錄訊息提供有關軟體系統狀態的寶貴資訊。此資訊以非結構化方式提供，並套用自動化方法來擷取相關參數。為了簡化此流程，可以套用記錄剖析，將記錄訊息轉換成結構化的記錄範本。語言模型的最新進展已導致多項研究，將 ChatGPT 套用於記錄剖析任務，並獲得有希望的結果。然而，其他最先進的大型語言模型 (LLM) 在記錄剖析任務上的效能仍不清楚。
目標：在本研究中，我們探討最先進 LLM 執行記錄剖析的當前能力。
方法：我們選出六個最新的 LLM，包括付費專有（GPT-3.5、Claude 2.1）和四個免費開放模型，並比較它們在從一系列成熟的開源專案取得的系統記錄上的效能。我們設計兩種不同的提示方法，並將 LLM 套用於 16 個不同專案的 1,354 個記錄範本。我們評估其有效性，包括正確辨識的範本數量，以及產生的範本與真實結果之間的語法相似性。
結果：我們發現免費模型能夠與付費模型競爭，CodeLlama 正確擷取的記錄範本比 GPT-3.5 多 10%。此外，我們提供語言模型可用性的品質見解（例如，多容易使用其回應）。
結論：我們的結果顯示，一些較小的免費 LLM 與付費專有競爭者相比，可以大幅協助記錄剖析，特別是專門用於程式碼的模型。</paragraph>

##### **DetectiveQA: Evaluating Long-Context Reasoning on Detective Novels**
2409.02465v1 by Zhe Xu, Jiasheng Ye, Xiangyang Liu, Tianxiang Sun, Xiaoran Liu, Qipeng Guo, Linlin Li, Qun Liu, Xuanjing Huang, Xipeng Qiu

With the rapid advancement of Large Language Models (LLMs), long-context
information understanding and processing have become a hot topic in academia
and industry. However, benchmarks for evaluating the ability of LLMs to handle
long-context information do not seem to have kept pace with the development of
LLMs. Despite the emergence of various long-context evaluation benchmarks, the
types of capability assessed are still limited, without new capability
dimensions. In this paper, we introduce DetectiveQA, a narrative reasoning
benchmark featured with an average context length of over 100K tokens.
DetectiveQA focuses on evaluating the long-context reasoning ability of LLMs,
which not only requires a full understanding of context but also requires
extracting important evidences from the context and reasoning according to
extracted evidences to answer the given questions. This is a new dimension of
capability evaluation, which is more in line with the current intelligence
level of LLMs. We use detective novels as data sources, which naturally have
various reasoning elements. Finally, we manually annotated 600 questions in
Chinese and then also provided an English edition of the context information
and questions. We evaluate many long-context LLMs on DetectiveQA, including
commercial and open-sourced models, and the results indicate that existing
long-context LLMs still require significant advancements to effectively process
true long-context dependency questions.

摘要：隨著大型語言模型 (LLM) 快速發展，長語境資訊理解與處理已成為學界與產業的熱門議題。然而，用於評估 LLM 處理長語境資訊能力的基準似乎並未與 LLM 的發展同步。儘管出現了各種長語境評估基準，但評估的能力類型仍然有限，沒有新的能力面向。在本文中，我們介紹了 DetectiveQA，一個敘事推理基準，其特點是平均語境長度超過 100K 個詞元。DetectiveQA 專注於評估 LLM 的長語境推理能力，這不僅需要對語境有充分的理解，還需要從語境中提取重要的證據，並根據提取的證據進行推理以回答給定的問題。這是一個能力評估的新面向，更符合 LLM 目前的智慧水準。我們使用偵探小說作為數據來源，其中自然包含各種推理元素。最後，我們手動標註了 600 個中文問題，並提供了語境資訊和問題的英文版本。我們在 DetectiveQA 上評估了許多長語境 LLM，包括商業和開源模型，結果表明現有的長語境 LLM 仍需要顯著進展才能有效處理真正的長語境依賴性問題。

##### **Fast, High-Quality and Parameter-Efficient Articulatory Synthesis using Differentiable DSP**
2409.02451v1 by Yisi Liu, Bohan Yu, Drake Lin, Peter Wu, Cheol Jun Cho, Gopala Krishna Anumanchipalli

Articulatory trajectories like electromagnetic articulography (EMA) provide a
low-dimensional representation of the vocal tract filter and have been used as
natural, grounded features for speech synthesis. Differentiable digital signal
processing (DDSP) is a parameter-efficient framework for audio synthesis.
Therefore, integrating low-dimensional EMA features with DDSP can significantly
enhance the computational efficiency of speech synthesis. In this paper, we
propose a fast, high-quality, and parameter-efficient DDSP articulatory vocoder
that can synthesize speech from EMA, F0, and loudness. We incorporate several
techniques to solve the harmonics / noise imbalance problem, and add a
multi-resolution adversarial loss for better synthesis quality. Our model
achieves a transcription word error rate (WER) of 6.67% and a mean opinion
score (MOS) of 3.74, with an improvement of 1.63% and 0.16 compared to the
state-of-the-art (SOTA) baseline. Our DDSP vocoder is 4.9x faster than the
baseline on CPU during inference, and can generate speech of comparable quality
with only 0.4M parameters, in contrast to the 9M parameters required by the
SOTA.

摘要：語音軌跡，例如電磁關節描記術 (EMA)，提供聲道濾波器的低維度表示，並已用作語音合成的自然、基礎特徵。可微分數位訊號處理 (DDSP) 是一種參數效率高的音訊合成架構。因此，將低維度 EMA 特徵與 DDSP 整合，可以大幅提升語音合成的運算效率。在本文中，我們提出一個快速、高品質且參數效率高的 DDSP 關節語音編碼器，可從 EMA、F0 和響度合成語音。我們結合了多種技術來解決諧波/雜訊不平衡問題，並加入一個多解析度對抗損失，以獲得更好的合成品質。我們的模型在轉錄字元錯誤率 (WER) 達到 6.67%，平均意見分數 (MOS) 達到 3.74，與現有技術 (SOTA) 基準相比，分別提升了 1.63% 和 0.16。我們的 DDSP 語音編碼器在推論期間比 CPU 上的基準快 4.9 倍，且僅使用 0.4M 個參數就能產生品質相當的語音，這與 SOTA 所需的 9M 個參數形成對比。

##### **What is lost in Normalization? Exploring Pitfalls in Multilingual ASR Model Evaluations**
2409.02449v1 by Kavya Manohar, Leena G Pillai

This paper explores the pitfalls in evaluating multilingual automatic speech
recognition (ASR) models, with a particular focus on Indic language scripts. We
investigate the text normalization routine employed by leading ASR models,
including OpenAI Whisper, Meta's MMS, Seamless, and Assembly AI's Conformer,
and their unintended consequences on performance metrics. Our research reveals
that current text normalization practices, while aiming to standardize ASR
outputs for fair comparison, by removing inconsistencies such as variations in
spelling, punctuation, and special characters, are fundamentally flawed when
applied to Indic scripts. Through empirical analysis using text similarity
scores and in-depth linguistic examination, we demonstrate that these flaws
lead to artificially inflated performance metrics for Indic languages. We
conclude by proposing a shift towards developing normalization routines that
leverage native linguistic expertise, ensuring more robust and accurate
evaluations of multilingual ASR models.

摘要：這篇論文探討了評估多語言自動語音辨識 (ASR) 模型的陷阱，特別著重於印度語言腳本。我們研究了領先的 ASR 模型所採用的文字正規化例程，包括 OpenAI Whisper、Meta 的 MMS、Seamless 和 Assembly AI 的 Conformer，以及它們對效能指標的意外後果。我們的研究顯示，目前的文字正規化做法雖然旨在標準化 ASR 輸出以進行公平比較，藉由移除拼寫、標點符號和特殊字元等不一致性，但在應用於印度腳本時卻存在根本缺陷。透過使用文字相似度分數和深入的語言學檢查進行實證分析，我們證明了這些缺陷導致印度語言的效能指標被人工抬高。我們最後提出轉向開發利用原生語言專業知識的正規化例程，以確保對多語言 ASR 模型進行更強健且準確的評估。

##### **Detecting Korean Food Using Image using Hierarchical Model**
2409.02448v1 by Hoang Khanh Lam, Kahandakanaththage Maduni Pramuditha Perera

A solution was made available for Korean Food lovers who have dietary
restrictions to identify the Korean food before consuming. Just by uploading a
clear photo of the dish, people can get to know what they are eating. Image
processing techniques together with machine learning helped to come up with
this solution.

摘要：對於有飲食限制的韓國料理愛好者，現已提供一種解決方案，讓他們在食用韓國料理之前就能辨識出該料理。只要上傳料理的清晰照片，人們就能知道自己吃的是什麼。影像處理技術加上機器學習，協助提出此解決方案。

##### **Large Language Models as Efficient Reward Function Searchers for Custom-Environment Multi-Objective Reinforcement Learning**
2409.02428v1 by Guanwen Xie, Jingzehua Xu, Yiyuan Yang, Shuai Zhang

Leveraging large language models (LLMs) for designing reward functions
demonstrates significant potential. However, achieving effective design and
improvement of reward functions in reinforcement learning (RL) tasks with
complex custom environments and multiple requirements presents considerable
challenges. In this paper, we enable LLMs to be effective white-box searchers,
highlighting their advanced semantic understanding capabilities. Specifically,
we generate reward components for each explicit user requirement and employ the
reward critic to identify the correct code form. Then, LLMs assign weights to
the reward components to balance their values and iteratively search and
optimize these weights based on the context provided by the training log
analyzer, while adaptively determining the search step size. We applied the
framework to an underwater information collection RL task without direct human
feedback or reward examples (zero-shot). The reward critic successfully correct
the reward code with only one feedback for each requirement, effectively
preventing irreparable errors that can occur when reward function feedback is
provided in aggregate. The effective initialization of weights enables the
acquisition of different reward functions within the Pareto solution set
without weight search. Even in the case where a weight is 100 times off, fewer
than four iterations are needed to obtain solutions that meet user
requirements. The framework also works well with most prompts utilizing GPT-3.5
Turbo, since it does not require advanced numerical understanding or
calculation.

摘要：利用大型语言模型 (LLM) 来设计奖励函数显示出巨大的潜力。然而，在具有复杂自定义环境和多重要求的强化学习 (RL) 任务中实现奖励函数的有效设计和改进提出了相当大的挑战。在本文中，我们使 LLM 成为有效的白盒搜索器，突出了它们先进的语义理解能力。具体来说，我们为每个明确的用户需求生成奖励组件，并使用奖励批评者来识别正确的代码形式。然后，LLM 为奖励组件分配权重以平衡其价值，并基于训练日志分析器提供的上下文迭代搜索和优化这些权重，同时自适应地确定搜索步长。我们将该框架应用于水下信息收集 RL 任务，无需直接的人工反馈或奖励示例（零次学习）。奖励批评者仅使用每个要求的一个反馈就成功地纠正了奖励代码，有效地防止了在汇总提供奖励函数反馈时可能发生的不可修复的错误。权重的有效初始化使得无需权重搜索即可在帕累托解集中获取不同的奖励函数。即使在权重相差 100 倍的情况下，也只需要不到四次迭代即可获得满足用户需求的解决方案。该框架还适用于使用 GPT-3.5 Turbo 的大多数提示，因为它不需要高级的数字理解或计算。

##### **Accelerating Large Language Model Training with Hybrid GPU-based Compression**
2409.02423v1 by Lang Xu, Quentin Anthony, Qinghua Zhou, Nawras Alnaasan, Radha R. Gulhane, Aamir Shafi, Hari Subramoni, Dhabaleswar K. Panda

Data Parallelism (DP), Tensor Parallelism (TP), and Pipeline Parallelism (PP)
are the three strategies widely adopted to enable fast and efficient Large
Language Model (LLM) training. However, these approaches rely on data-intensive
communication routines to collect, aggregate, and re-distribute gradients,
activations, and other important model information, which pose significant
overhead. Co-designed with GPU-based compression libraries, MPI libraries have
been proven to reduce message size significantly, and leverage interconnect
bandwidth, thus increasing training efficiency while maintaining acceptable
accuracy.
  In this work, we investigate the efficacy of compression-assisted MPI
collectives under the context of distributed LLM training using 3D parallelism
and ZeRO optimizations. We scaled up to 192 V100 GPUs on the Lassen
supercomputer. First, we enabled a na\"ive compression scheme across all
collectives and observed a 22.5\% increase in TFLOPS per GPU and a 23.6\%
increase in samples per second for GPT-NeoX-20B training. Nonetheless, such a
strategy ignores the sparsity discrepancy among messages communicated in each
parallelism degree, thus introducing more errors and causing degradation in
training loss. Therefore, we incorporated hybrid compression settings toward
each parallel dimension and adjusted the compression intensity accordingly.
Given their low-rank structure (arXiv:2301.02654), we apply aggressive
compression on gradients when performing DP All-reduce. We adopt milder
compression to preserve precision while communicating activations, optimizer
states, and model parameters in TP and PP. Using the adjusted hybrid
compression scheme, we demonstrate a 17.3\% increase in TFLOPS per GPU and a
12.7\% increase in samples per second while reaching baseline loss convergence.

摘要：資料平行（DP）、張量平行（TP）和管道平行（PP）是廣泛採用的三種策略，用於實現快速且高效的大語言模型（LLM）訓練。然而，這些方法依賴於資料密集型通訊例程來收集、彙總和重新分配梯度、激活和其他重要的模型資訊，這會造成顯著的額外負擔。MPI 庫與基於 GPU 的壓縮庫共同設計，已證明可以顯著減少訊息大小，並利用互連頻寬，從而提高訓練效率，同時保持可接受的準確度。
在這項工作中，我們探討了在使用 3D 平行和 ZeRO 最佳化進行分散式 LLM 訓練的背景下，壓縮輔助 MPI 集合的功效。我們在 Lassen 超級電腦上擴充到 192 個 V100 GPU。首先，我們在所有集合中啟用了一個「天真的」壓縮方案，並觀察到 GPT-NeoX-20B 訓練的每秒 TFLOPS 增加 22.5%，每秒樣本增加 23.6%。儘管如此，這種策略忽略了在每個平行度中傳達的訊息之間的稀疏差異，從而引入了更多錯誤並導致訓練損失下降。因此，我們針對每個平行維度納入了混合壓縮設定，並相應調整壓縮強度。
鑑於它們的低秩結構（arXiv:2301.02654），我們在執行 DP 全部減少時對梯度應用激進壓縮。我們採用較溫和的壓縮來保留精度，同時在 TP 和 PP 中傳達激活、最佳化器狀態和模型參數。使用調整後的混合壓縮方案，我們展示了每秒 TFLOPS 增加 17.3%，每秒樣本增加 12.7%，同時達到基線損失收斂。

##### **Abstractive Text Summarization: State of the Art, Challenges, and Improvements**
2409.02413v1 by Hassan Shakil, Ahmad Farooq, Jugal Kalita

Specifically focusing on the landscape of abstractive text summarization, as
opposed to extractive techniques, this survey presents a comprehensive
overview, delving into state-of-the-art techniques, prevailing challenges, and
prospective research directions. We categorize the techniques into traditional
sequence-to-sequence models, pre-trained large language models, reinforcement
learning, hierarchical methods, and multi-modal summarization. Unlike prior
works that did not examine complexities, scalability and comparisons of
techniques in detail, this review takes a comprehensive approach encompassing
state-of-the-art methods, challenges, solutions, comparisons, limitations and
charts out future improvements - providing researchers an extensive overview to
advance abstractive summarization research. We provide vital comparison tables
across techniques categorized - offering insights into model complexity,
scalability and appropriate applications. The paper highlights challenges such
as inadequate meaning representation, factual consistency, controllable text
summarization, cross-lingual summarization, and evaluation metrics, among
others. Solutions leveraging knowledge incorporation and other innovative
strategies are proposed to address these challenges. The paper concludes by
highlighting emerging research areas like factual inconsistency,
domain-specific, cross-lingual, multilingual, and long-document summarization,
as well as handling noisy data. Our objective is to provide researchers and
practitioners with a structured overview of the domain, enabling them to better
understand the current landscape and identify potential areas for further
research and improvement.

摘要：<paragraph>特別關注抽象文本摘要的領域，與萃取技術相反，這項調查提供了一個全面的概述，深入探討最先進的技術、普遍的挑戰和預期的研究方向。我們將這些技術分類為傳統的序列到序列模型、預先訓練的大語言模型、強化學習、階層式方法和多模態摘要。與先前未詳細探討技術的複雜性、可擴充性和比較的作品不同，此評論採用全面性的方法，涵蓋最先進的方法、挑戰、解決方案、比較、限制，並規劃未來的改進 - 為研究人員提供廣泛的概述以推進抽象摘要研究。我們提供跨技術類別的重要比較表 - 提供對模型複雜性、可擴充性和適當應用程式的見解。本文重點介紹了挑戰，例如不充分的意義表示、事實一致性、可控制的文本摘要、跨語言摘要和評估指標等。提出了利用知識整合和其他創新策略的解決方案來應對這些挑戰。本文最後強調了新興的研究領域，例如事實不一致、特定領域、跨語言、多語言和長文件摘要，以及處理雜訊資料。我們的目標是為研究人員和實務工作者提供該領域的結構化概述，使他們能夠更深入了解目前的現況，並找出進一步研究和改進的潛在領域。</paragraph>

##### **Learning Privacy-Preserving Student Networks via Discriminative-Generative Distillation**
2409.02404v1 by Shiming Ge, Bochao Liu, Pengju Wang, Yong Li, Dan Zeng

While deep models have proved successful in learning rich knowledge from
massive well-annotated data, they may pose a privacy leakage risk in practical
deployment. It is necessary to find an effective trade-off between high utility
and strong privacy. In this work, we propose a discriminative-generative
distillation approach to learn privacy-preserving deep models. Our key idea is
taking models as bridge to distill knowledge from private data and then
transfer it to learn a student network via two streams. First, discriminative
stream trains a baseline classifier on private data and an ensemble of teachers
on multiple disjoint private subsets, respectively. Then, generative stream
takes the classifier as a fixed discriminator and trains a generator in a
data-free manner. After that, the generator is used to generate massive
synthetic data which are further applied to train a variational autoencoder
(VAE). Among these synthetic data, a few of them are fed into the teacher
ensemble to query labels via differentially private aggregation, while most of
them are embedded to the trained VAE for reconstructing synthetic data.
Finally, a semi-supervised student learning is performed to simultaneously
handle two tasks: knowledge transfer from the teachers with distillation on few
privately labeled synthetic data, and knowledge enhancement with tangent-normal
adversarial regularization on many triples of reconstructed synthetic data. In
this way, our approach can control query cost over private data and mitigate
accuracy degradation in a unified manner, leading to a privacy-preserving
student model. Extensive experiments and analysis clearly show the
effectiveness of the proposed approach.

摘要：<paragraph>儘管深度模型已被證明可以從大量標註良好的資料中學習豐富的知識，但它們在實際部署中可能會構成隱私外洩的風險。必須在高實用性和強隱私之間找到有效的折衷方案。在這項工作中，我們提出了一種區分生成蒸餾方法來學習隱私保護深度模型。我們的關鍵想法是將模型作為橋樑，從私人資料中提取知識，然後透過兩個串流將其傳遞給學習學生網路。首先，區分串流分別在私人資料上訓練基線分類器和在多個不相交的私人子集中訓練一組教師。然後，生成串流將分類器作為固定的區分器，並以無資料的方式訓練生成器。在那之後，生成器用於產生大量合成資料，這些資料進一步用於訓練變異自動編碼器 (VAE)。在這些合成資料中，其中一些會被輸入教師組，以透過差異化隱私聚合查詢標籤，而大多數會被嵌入訓練過的 VAE 以重建合成資料。最後，執行半監督學生學習以同時處理兩個任務：透過蒸餾在少數標有私人標籤的合成資料上從教師傳遞知識，以及透過在許多三元組重建合成資料上進行切線正規對抗正規化來增強知識。透過這種方式，我們的做法可以統一控制私人資料的查詢成本並減輕準確性下降，從而產生一個隱私保護學生模型。廣泛的實驗和分析清楚地顯示了所提出方法的有效性。</paragraph>

##### **Determination of language families using deep learning**
2409.02393v1 by Peter B. Lerner

We use a c-GAN (convolutional generative adversarial) neural network to
analyze transliterated text fragments of extant, dead comprehensible, and one
dead non-deciphered (Cypro-Minoan) language to establish linguistic affinities.
The paper is agnostic with respect to translation and/or deciphering. However,
there is hope that the proposed approach can be useful for decipherment with
more sophisticated neural network techniques.

摘要：我們使用 c-GAN（卷積生成對抗）神經網路來分析現存、已死亡且可理解，以及一種已死亡且無法破譯（塞浦路斯-米諾斯）語言的音譯文字片段，以建立語言親緣關係。
這篇論文對於翻譯和/或破譯保持中立。然而，我們有希望所提出的方法可以透過更精密的網路技術，用於破譯。

##### **Scaling Laws for Economic Productivity: Experimental Evidence in LLM-Assisted Translation**
2409.02391v1 by Ali Merali

This paper derives 'scaling laws' -- empirical relationships between the
amount of training compute used for a Large Language Model (LLM) and its
performance -- for economic outcomes. In a preregistered experiment, 300
professional translators completed 1800 tasks with access to one of thirteen
LLMs with differing model training compute sizes (or a control). Our results
show that model scaling substantially raises productivity: for every 10x
increase in model compute, translators completed tasks 12.3% quicker, received
0.18 s.d. higher grades, and earned 16.1% more per minute (including bonus
payments). Further, the gains from model scaling are much higher for
lower-skilled workers who gain a 4x larger improvement in task completion
speed. These results imply further frontier model scaling -- which is currently
estimated at 4x increase per year -- may have significant economic
implications.

摘要：這篇論文推導出「規模定律」-- 大型語言模型 (LLM) 所使用的訓練運算量與其效能之間的經驗關係 -- 以用於經濟成果。在預先註冊的實驗中，300 位專業翻譯人員使用 13 個 LLM 中的一個（或對照組）完成了 1800 項任務，這些 LLM 具有不同的模型訓練運算量大小。我們的結果顯示，模型擴充大幅提升生產力：每增加 10 倍模型運算量，翻譯人員完成任務的速度快 12.3%，獲得 0.18 標準差的高分，並且每分鐘賺取多 16.1%（包括獎金）。此外，對於技能較低的員工來說，模型擴充的收益更高，他們的任務完成速度提升了 4 倍。這些結果意味著進一步的前沿模型擴充 -- 目前估計每年增加 4 倍 -- 可能具有重大的經濟影響。

##### **Neural Dynamics Model of Visual Decision-Making: Learning from Human Experts**
2409.02390v1 by Jie Su, Fang Cai, Shu-Kuo Zhao, Xin-Yi Wang, Tian-Yi Qian, Da-Hui Wang, Bo Hong

Uncovering the fundamental neural correlates of biological intelligence,
developing mathematical models, and conducting computational simulations are
critical for advancing new paradigms in artificial intelligence (AI). In this
study, we implemented a comprehensive visual decision-making model that spans
from visual input to behavioral output, using a neural dynamics modeling
approach. Drawing inspiration from the key components of the dorsal visual
pathway in primates, our model not only aligns closely with human behavior but
also reflects neural activities in primates, and achieving accuracy comparable
to convolutional neural networks (CNNs). Moreover, magnetic resonance imaging
(MRI) identified key neuroimaging features such as structural connections and
functional connectivity that are associated with performance in perceptual
decision-making tasks. A neuroimaging-informed fine-tuning approach was
introduced and applied to the model, leading to performance improvements that
paralleled the behavioral variations observed among subjects. Compared to
classical deep learning models, our model more accurately replicates the
behavioral performance of biological intelligence, relying on the structural
characteristics of biological neural networks rather than extensive training
data, and demonstrating enhanced resilience to perturbation.

摘要：揭示生物智能的基本神经相關性、開發數學模型和進行計算模擬對於推進人工智慧 (AI) 的新範例至關重要。在本研究中，我們實作了一個全面的視覺決策模型，涵蓋從視覺輸入到行為輸出的範圍，並使用神經動力學建模方法。從靈長類動物的背側視覺路徑的關鍵組成部分汲取靈感，我們的模型不僅與人類行為密切對齊，而且還反映了靈長類動物的神經活動，並達到了與卷積神經網路 (CNN) 相當的準確度。此外，磁振造影 (MRI) 識別出關鍵的神經影像特徵，例如與知覺決策任務中的表現相關的結構連接和功能連接。引入了神經影像知情微調方法並應用於模型，從而導致效能改善，與在受試者中觀察到的行為變異相平行。與經典的深度學習模型相比，我們的模型更準確地複製了生物智能的行為表現，依賴於生物神經網路的結構特徵，而不是廣泛的訓練資料，並展示出增強的抗擾動能力。

##### **Multi-modal Situated Reasoning in 3D Scenes**
2409.02389v1 by Xiongkun Linghu, Jiangyong Huang, Xuesong Niu, Xiaojian Ma, Baoxiong Jia, Siyuan Huang

Situation awareness is essential for understanding and reasoning about 3D
scenes in embodied AI agents. However, existing datasets and benchmarks for
situated understanding are limited in data modality, diversity, scale, and task
scope. To address these limitations, we propose Multi-modal Situated Question
Answering (MSQA), a large-scale multi-modal situated reasoning dataset,
scalably collected leveraging 3D scene graphs and vision-language models (VLMs)
across a diverse range of real-world 3D scenes. MSQA includes 251K situated
question-answering pairs across 9 distinct question categories, covering
complex scenarios within 3D scenes. We introduce a novel interleaved
multi-modal input setting in our benchmark to provide text, image, and point
cloud for situation and question description, resolving ambiguity in previous
single-modality convention (e.g., text). Additionally, we devise the
Multi-modal Situated Next-step Navigation (MSNN) benchmark to evaluate models'
situated reasoning for navigation. Comprehensive evaluations on MSQA and MSNN
highlight the limitations of existing vision-language models and underscore the
importance of handling multi-modal interleaved inputs and situation modeling.
Experiments on data scaling and cross-domain transfer further demonstrate the
efficacy of leveraging MSQA as a pre-training dataset for developing more
powerful situated reasoning models.

摘要：情境感知對於理解和推理具身 AI 代理中的 3D 場景至關重要。然而，現有的資料集和基準在資料模態、多樣性、規模和任務範圍方面對於情境理解來說是有限的。為了解決這些限制，我們提出了多模態情境問答 (MSQA)，這是一個大型多模態情境推理資料集，可透過利用 3D 場景圖和視覺語言模型 (VLM) 在各種真實世界 3D 場景中進行可擴充收集。MSQA 包含 251K 個情境問答對，涵蓋 9 個不同的問題類別，涵蓋 3D 場景中的複雜場景。我們在基準中引入了一種新穎的交錯多模態輸入設定，以提供文字、影像和點雲，用於情境和問題描述，解決以前單一模態慣例（例如文字）中的歧義。此外，我們設計了多模態情境下一步導航 (MSNN) 基準，以評估模型的導航情境推理。MSQA 和 MSNN 的綜合評估突顯了現有視覺語言模型的限制，並強調了處理多模態交錯輸入和情境建模的重要性。資料擴充和跨領域轉移的實驗進一步證明了利用 MSQA 作為預訓練資料集來開發更強大的情境推理模型的有效性。

##### **Large Language Models and Cognitive Science: A Comprehensive Review of Similarities, Differences, and Challenges**
2409.02387v2 by Qian Niu, Junyu Liu, Ziqian Bi, Pohsun Feng, Benji Peng, Keyu Chen

This comprehensive review explores the intersection of Large Language Models
(LLMs) and cognitive science, examining similarities and differences between
LLMs and human cognitive processes. We analyze methods for evaluating LLMs
cognitive abilities and discuss their potential as cognitive models. The review
covers applications of LLMs in various cognitive fields, highlighting insights
gained for cognitive science research. We assess cognitive biases and
limitations of LLMs, along with proposed methods for improving their
performance. The integration of LLMs with cognitive architectures is examined,
revealing promising avenues for enhancing artificial intelligence (AI)
capabilities. Key challenges and future research directions are identified,
emphasizing the need for continued refinement of LLMs to better align with
human cognition. This review provides a balanced perspective on the current
state and future potential of LLMs in advancing our understanding of both
artificial and human intelligence.

摘要：這篇綜合評論探討了大型語言模型 (LLM) 和認知科學的交集，探討了 LLM 與人類認知過程之間的異同。我們分析了評估 LLM 認知能力的方法，並討論了它們作為認知模型的潛力。這篇評論涵蓋了 LLM 在各種認知領域的應用，重點說明了對認知科學研究的見解。我們評估了 LLM 的認知偏差和局限性，以及提出的改善其效能的方法。探討了 LLM 與認知架構的整合，揭示了增強人工智慧 (AI) 能力的有希望的途徑。確定了關鍵挑戰和未來的研究方向，強調需要持續改進 LLM，以更好地與人類認知保持一致。這篇評論提供了對 LLM 在促進我們對人工和人類智慧的理解方面的現狀和未來潛力的平衡觀點。

##### **STAB: Speech Tokenizer Assessment Benchmark**
2409.02384v1 by Shikhar Vashishth, Harman Singh, Shikhar Bharadwaj, Sriram Ganapathy, Chulayuth Asawaroengchai, Kartik Audhkhasi, Andrew Rosenberg, Ankur Bapna, Bhuvana Ramabhadran

Representing speech as discrete tokens provides a framework for transforming
speech into a format that closely resembles text, thus enabling the use of
speech as an input to the widely successful large language models (LLMs).
Currently, while several speech tokenizers have been proposed, there is
ambiguity regarding the properties that are desired from a tokenizer for
specific downstream tasks and its overall generalizability. Evaluating the
performance of tokenizers across different downstream tasks is a
computationally intensive effort that poses challenges for scalability. To
circumvent this requirement, we present STAB (Speech Tokenizer Assessment
Benchmark), a systematic evaluation framework designed to assess speech
tokenizers comprehensively and shed light on their inherent characteristics.
This framework provides a deeper understanding of the underlying mechanisms of
speech tokenization, thereby offering a valuable resource for expediting the
advancement of future tokenizer models and enabling comparative analysis using
a standardized benchmark. We evaluate the STAB metrics and correlate this with
downstream task performance across a range of speech tasks and tokenizer
choices.

摘要：將語音表示為離散符號提供了一個架構，可將語音轉換為與文字非常相似的格式，從而能夠將語音用作廣泛成功的巨量語言模型 (LLM) 的輸入。目前，儘管已經提出了多種語音分詞器，但對於特定下游任務的分詞器所需的屬性和其整體概括性仍然存在歧義。評估分詞器在不同下游任務中的性能是一項計算密集型工作，對可擴展性構成挑戰。為了迴避此要求，我們提出了 STAB（語音分詞器評估基準），這是一個系統性的評估框架，旨在全面評估語音分詞器並闡明其內在特徵。此框架提供了對語音分詞基本機制的更深入理解，從而為加速未來分詞器模型的開發和使用標準基準進行比較分析提供了寶貴的資源。我們評估了 STAB 指標，並將其與一系列語音任務和分詞器選項中的下游任務性能相關聯。

##### **Coral Model Generation from Single Images for Virtual Reality Applications**
2409.02376v1 by Jie Fu, Shun Fu, Mick Grierson

With the rapid development of VR technology, the demand for high-quality 3D
models is increasing. Traditional methods struggle with efficiency and quality
in large-scale customization. This paper introduces a deep-learning framework
that generates high-precision 3D coral models from a single image. Using the
Coral dataset, the framework extracts geometric and texture features, performs
3D reconstruction, and optimizes design and material blending. Advanced
optimization and polygon count control ensure shape accuracy, detail retention,
and flexible output for various complexities, catering to high-quality
rendering and real-time interaction needs.The project incorporates Explainable
AI (XAI) to transform AI-generated models into interactive "artworks," best
viewed in VR and XR. This enhances model interpretability and human-machine
collaboration. Real-time feedback in VR interactions displays information like
coral species and habitat, enriching user experience. The generated models
surpass traditional methods in detail, visual quality, and efficiency. This
research offers an intelligent approach to 3D content creation for VR, lowering
production barriers, and promoting widespread VR applications. Additionally,
integrating XAI provides new insights into AI-generated visual content and
advances research in 3D vision interpretability.

摘要：<paragraph>隨著 VR 技術的快速發展，對高品質 3D 模型的需求與日俱增。傳統方法在處理大規模客製化時，面臨效率和品質的難題。本文提出一個深度學習架構，能從單一影像產生高精度的 3D 珊瑚模型。架構使用 Coral 資料集，萃取幾何和紋理特徵，執行 3D 重建，並最佳化設計和材質混合。進階的最佳化和多邊形數量控制，確保形狀準確性、細節保留，以及針對各種複雜度的彈性輸出，滿足高品質渲染和即時互動的需求。此專案結合可解釋 AI (XAI)，將 AI 生成的模型轉換成互動的「藝術作品」，最適合在 VR 和 XR 中觀看。這增強了模型的可解釋性，以及人機協作。VR 互動中的即時回饋，會顯示珊瑚物種和棲息地等資訊，豐富了使用者體驗。生成的模型在細節、視覺品質和效率方面，都超越了傳統方法。此研究為 VR 的 3D 內容創作提供了一個智慧化的途徑，降低了製作門檻，並推廣了 VR 應用。此外，整合 XAI 為 AI 生成的視覺內容提供了新的見解，並推進了 3D 視覺可解釋性的研究。</paragraph>

##### **How Privacy-Savvy Are Large Language Models? A Case Study on Compliance and Privacy Technical Review**
2409.02375v1 by Xichou Zhu, Yang Liu, Zhou Shen, Yi Liu, Min Li, Yujun Chen, Benzi John, Zhenzhen Ma, Tao Hu, Bolong Yang, Manman Wang, Zongxing Xie, Peng Liu, Dan Cai, Junhui Wang

The recent advances in large language models (LLMs) have significantly
expanded their applications across various fields such as language generation,
summarization, and complex question answering. However, their application to
privacy compliance and technical privacy reviews remains under-explored,
raising critical concerns about their ability to adhere to global privacy
standards and protect sensitive user data. This paper seeks to address this gap
by providing a comprehensive case study evaluating LLMs' performance in
privacy-related tasks such as privacy information extraction (PIE), legal and
regulatory key point detection (KPD), and question answering (QA) with respect
to privacy policies and data protection regulations. We introduce a Privacy
Technical Review (PTR) framework, highlighting its role in mitigating privacy
risks during the software development life-cycle. Through an empirical
assessment, we investigate the capacity of several prominent LLMs, including
BERT, GPT-3.5, GPT-4, and custom models, in executing privacy compliance checks
and technical privacy reviews. Our experiments benchmark the models across
multiple dimensions, focusing on their precision, recall, and F1-scores in
extracting privacy-sensitive information and detecting key regulatory
compliance points. While LLMs show promise in automating privacy reviews and
identifying regulatory discrepancies, significant gaps persist in their ability
to fully comply with evolving legal standards. We provide actionable
recommendations for enhancing LLMs' capabilities in privacy compliance,
emphasizing the need for robust model improvements and better integration with
legal and regulatory requirements. This study underscores the growing
importance of developing privacy-aware LLMs that can both support businesses in
compliance efforts and safeguard user privacy rights.

摘要：大型語言模型 (LLM) 最近的進展已大幅擴展其在各種領域的應用，例如語言生成、摘要和複雜問題解答。然而，它們在隱私合規性和技術隱私審查中的應用仍未得到充分探討，引發了它們是否能遵守全球隱私標準和保護敏感用戶數據的能力的關鍵問題。本文旨在通過提供一個全面的案例研究來解決這個差距，評估 LLM 在隱私相關任務中的表現，例如隱私資訊萃取 (PIE)、法律和法規重點偵測 (KPD) 以及與隱私政策和資料保護法規相關的問題解答 (QA)。我們引入了隱私技術審查 (PTR) 框架，強調其在軟體開發生命週期中減輕隱私風險中的作用。透過實證評估，我們探討了包括 BERT、GPT-3.5、GPT-4 和自訂模型在內的幾個著名 LLM 在執行隱私合規性檢查和技術隱私審查中的能力。我們的實驗對這些模型進行了多面向的基準測試，重點關注它們在萃取隱私敏感資訊和偵測關鍵法規合規點時的準確度、召回率和 F1 分數。儘管 LLM 在自動化隱私審查和識別法規差異方面顯示出前景，但它們在完全遵守不斷變化的法律標準的能力方面仍存在顯著差距。我們提供了可行的建議，以增強 LLM 在隱私合規性方面的能力，強調需要強大的模型改進和與法律和法規要求的更好整合。本研究強調了開發具隱私意識的 LLM 的重要性，這些 LLM 既能支援企業的合規工作，又能保障使用者的隱私權。

##### **Do Large Language Models Possess Sensitive to Sentiment?**
2409.02370v1 by Yang Liu, Xichou Zhu, Zhou Shen, Yi Liu, Min Li, Yujun Chen, Benzi John, Zhenzhen Ma, Tao Hu, Zhiyang Xu, Wei Luo, Junhui Wang

Large Language Models (LLMs) have recently displayed their extraordinary
capabilities in language understanding. However, how to comprehensively assess
the sentiment capabilities of LLMs continues to be a challenge. This paper
investigates the ability of LLMs to detect and react to sentiment in text
modal. As the integration of LLMs into diverse applications is on the rise, it
becomes highly critical to comprehend their sensitivity to emotional tone, as
it can influence the user experience and the efficacy of sentiment-driven
tasks. We conduct a series of experiments to evaluate the performance of
several prominent LLMs in identifying and responding appropriately to
sentiments like positive, negative, and neutral emotions. The models' outputs
are analyzed across various sentiment benchmarks, and their responses are
compared with human evaluations. Our discoveries indicate that although LLMs
show a basic sensitivity to sentiment, there are substantial variations in
their accuracy and consistency, emphasizing the requirement for further
enhancements in their training processes to better capture subtle emotional
cues. Take an example in our findings, in some cases, the models might wrongly
classify a strongly positive sentiment as neutral, or fail to recognize sarcasm
or irony in the text. Such misclassifications highlight the complexity of
sentiment analysis and the areas where the models need to be refined. Another
aspect is that different LLMs might perform differently on the same set of
data, depending on their architecture and training datasets. This variance
calls for a more in-depth study of the factors that contribute to the
performance differences and how they can be optimized.

摘要：大型語言模型 (LLM) 近期展現出它們在語言理解方面的非凡能力。然而，如何全面評估 LLM 的情緒能力仍然是一項挑戰。本文探討 LLM 在文字模式中偵測和回應情緒的能力。由於 LLM 整合到各種應用程式的趨勢日益盛行，理解它們對情緒語氣的敏感度變得至關重要，因為它會影響使用者體驗和情緒驅動任務的效能。我們進行了一系列實驗，以評估幾個著名的 LLM 在識別和適當回應正面、負面和中立情緒等情緒方面的表現。我們在各種情緒基準上分析模型的輸出，並將其回應與人類評估進行比較。我們的發現表明，儘管 LLM 對情緒表現出基本的敏感性，但它們的準確性和一致性存在很大差異，這強調了需要進一步加強其訓練過程以更好地捕捉微妙的情緒線索。以我們的發現為例，在某些情況下，模型可能會錯誤地將強烈的正面情緒歸類為中立，或者無法識別文字中的諷刺或反諷。這種錯誤分類突顯了情緒分析的複雜性以及模型需要改進的領域。另一個方面是，不同的 LLM 在同一組資料上的表現可能不同，具體取決於它們的架構和訓練資料集。這種差異要求更深入地研究導致效能差異的因素，以及如何對其進行最佳化。

##### **NUDGE: Lightweight Non-Parametric Fine-Tuning of Embeddings for Retrieval**
2409.02343v1 by Sepanta Zeighami, Zac Wellmer, Aditya Parameswaran

$k$-Nearest Neighbor search on dense vector embeddings ($k$-NN retrieval)
from pre-trained embedding models is the predominant retrieval method for text
and images, as well as Retrieval-Augmented Generation (RAG) pipelines. In
practice, application developers often fine-tune the embeddings to improve
their accuracy on the dataset and query workload in hand. Existing approaches
either fine-tune the pre-trained model itself or, more efficiently, but at the
cost of accuracy, train adaptor models to transform the output of the
pre-trained model. We present NUDGE, a family of novel non-parametric embedding
fine-tuning approaches that are significantly more accurate and efficient than
both sets of existing approaches. NUDGE directly modifies the embeddings of
data records to maximize the accuracy of $k$-NN retrieval. We present a
thorough theoretical and experimental study of NUDGE's non-parametric approach.
We show that even though the underlying problem is NP-Hard, constrained
variations can be solved efficiently. These constraints additionally ensure
that the changes to the embeddings are modest, avoiding large distortions to
the semantics learned during pre-training. In experiments across five
pre-trained models and nine standard text and image retrieval datasets, NUDGE
runs in minutes and often improves NDCG@10 by more than 10% over existing
fine-tuning methods. On average, NUDGE provides 3.3x and 4.3x higher increase
in accuracy and runs 200x and 3x faster, respectively, over fine-tuning the
pre-trained model and training adaptors.

摘要：預先訓練嵌入模型的稠密向量嵌入上的 $k$-最近鄰搜尋（$k$-NN 檢索）是文本和圖像以及檢索增強生成（RAG）管線的主要檢索方法。在實務上，應用程式開發人員經常微調嵌入，以提高其在手邊的資料集和查詢工作負載上的準確度。現有方法會微調預先訓練模型本身，或者更有效率，但以準確度為代價，訓練適配器模型來轉換預先訓練模型的輸出。我們提出 NUDGE，這是一系列新穎的非參數嵌入微調方法，其準確度和效率都顯著高於兩組現有方法。NUDGE 直接修改資料記錄的嵌入，以最大化 $k$-NN 檢索的準確度。我們提出對 NUDGE 的非參數方法進行徹底的理論和實驗研究。我們表明，即使基礎問題是 NP-Hard，約束變異也可以有效解決。這些約束另外確保嵌入的變更適度，避免對預訓練期間學習到的語義造成大幅失真。在五個預先訓練模型和九個標準文本和圖像檢索資料集的實驗中，NUDGE 在幾分鐘內執行，並且經常將 NDCG@10 提升超過 10%，優於現有的微調方法。平均而言，與微調預先訓練模型和訓練適配器相比，NUDGE 分別提供了 3.3 倍和 4.3 倍更高的準確度提升，並且執行速度分別快了 200 倍和 3 倍。

##### **Coaching a Robotic Sonographer: Learning Robotic Ultrasound with Sparse Expert's Feedback**
2409.02337v1 by Deepak Raina, Mythra V. Balakuntala, Byung Wook Kim, Juan Wachs, Richard Voyles

Ultrasound is widely employed for clinical intervention and diagnosis, due to
its advantages of offering non-invasive, radiation-free, and real-time imaging.
However, the accessibility of this dexterous procedure is limited due to the
substantial training and expertise required of operators. The robotic
ultrasound (RUS) offers a viable solution to address this limitation;
nonetheless, achieving human-level proficiency remains challenging. Learning
from demonstrations (LfD) methods have been explored in RUS, which learns the
policy prior from a dataset of offline demonstrations to encode the mental
model of the expert sonographer. However, active engagement of experts, i.e.
Coaching, during the training of RUS has not been explored thus far. Coaching
is known for enhancing efficiency and performance in human training. This paper
proposes a coaching framework for RUS to amplify its performance. The framework
combines DRL (self-supervised practice) with sparse expert's feedback through
coaching. The DRL employs an off-policy Soft Actor-Critic (SAC) network, with a
reward based on image quality rating. The coaching by experts is modeled as a
Partially Observable Markov Decision Process (POMDP), which updates the policy
parameters based on the correction by the expert. The validation study on
phantoms showed that coaching increases the learning rate by $25\%$ and the
number of high-quality image acquisition by $74.5\%$.

摘要：超音波因其提供非侵入性、無輻射且即時影像的優點，而廣泛用於臨床介入和診斷。
然而，由於操作員需要大量的訓練和專業知識，限制了此靈活程序的可及性。機器人超音波 (RUS) 提供了一個可行的解決方案來解決此限制；
儘管如此，要達到人類等級的熟練度仍然具有挑戰性。學習示範 (LfD) 方法已在 RUS 中進行探討，它從離線示範的資料集學習先驗策略，以編碼專家超音波檢查員的心智模型。然而，迄今尚未探討專家在 RUS 訓練期間的積極參與，即指導。指導已知可以提高人類訓練的效率和績效。本文提出了一個 RUS 指導架構，以提升其績效。此架構結合了 DRL（自我監督實務）與透過指導提供的專家稀疏回饋。DRL 使用離線策略軟性動作-評論 (SAC) 網路，並根據影像品質評分給予獎勵。專家的指導被建模為部分可觀察馬可夫決策過程 (POMDP)，它根據專家的修正來更新策略參數。在模擬人體模型上的驗證研究顯示，指導將學習率提高了 $25\%$，高品質影像擷取數量提高了 $74.5\%$。

##### **Arctic-SnowCoder: Demystifying High-Quality Data in Code Pretraining**
2409.02326v1 by Yuxiang Wei, Hojae Han, Rajhans Samdani

Recent studies have been increasingly demonstrating that high-quality data is
crucial for effective pretraining of language models. However, the precise
definition of "high-quality" remains underexplored. Focusing on the code
domain, we introduce Arctic-SnowCoder-1.3B, a data-efficient base code model
pretrained on 555B tokens through three phases of progressively refined data:
(1) general pretraining with 500B standard-quality code tokens, preprocessed
through basic filtering, deduplication, and decontamination, (2) continued
pretraining with 50B high-quality tokens, selected from phase one by a
BERT-style quality annotator trained to distinguish good code from random data,
using positive examples drawn from high-quality code files, along with
instruction data from Magicoder and StarCoder2-Instruct, and (3) enhanced
pretraining with 5B synthetic data created by Llama-3.1-70B using phase two
data as seeds, adapting the Magicoder approach for pretraining. Despite being
trained on a limited dataset, Arctic-SnowCoder achieves state-of-the-art
performance on BigCodeBench, a coding benchmark focusing on practical and
challenging programming tasks, compared to similarly sized models trained on no
more than 1T tokens, outperforming Phi-1.5-1.3B by 36%. Across all evaluated
benchmarks, Arctic-SnowCoder-1.3B beats StarCoderBase-3B pretrained on 1T
tokens. Additionally, it matches the performance of leading small base code
models trained on trillions of tokens. For example, Arctic-SnowCoder-1.3B
surpasses StarCoder2-3B, pretrained on over 3.3T tokens, on HumanEval+, a
benchmark that evaluates function-level code generation, and remains
competitive on BigCodeBench. Our evaluation presents a comprehensive analysis
justifying various design choices for Arctic-SnowCoder. Most importantly, we
find that the key to high-quality data is its alignment with the distribution
of downstream applications.

摘要：<paragraph>最近的研究越來越證明，高品質的資料對於語言模型的有效預訓練至關重要。然而，「高品質」的精確定義仍未被充分探討。專注於程式碼領域，我們引入了 Arctic-SnowCoder-1.3B，這是一個資料有效率的基本程式碼模型，透過三個階段的漸進式精煉資料進行預訓練，總計 555B 個符號：(1) 使用 500B 標準品質程式碼符號進行一般預訓練，透過基本過濾、重複資料刪除和去汙染進行預處理，(2) 繼續使用 50B 高品質符號進行預訓練，從第一階段中由 BERT 風格品質註解器選出，該註解器經過訓練，可以區分良好程式碼和隨機資料，使用從高品質程式碼檔案中擷取的正面範例，以及來自 Magicoder 和 StarCoder2-Instruct 的指令資料，(3) 使用 Llama-3.1-70B 使用第二階段資料作為種子，透過調整 Magicoder 預訓練方法，進一步使用 5B 合成資料進行預訓練。儘管訓練資料集有限，但與訓練資料量不超過 1T 個符號的類似大小模型相比，Arctic-SnowCoder 在 BigCodeBench 上達到了最先進的效能，比 Phi-1.5-1.3B 高出 36%。在所有評估基準中，Arctic-SnowCoder-1.3B 都勝過在 1T 個符號上進行預訓練的 StarCoderBase-3B。此外，它還與在數兆個符號上訓練的主要小型基本程式碼模型效能相匹配。例如，Arctic-SnowCoder-1.3B 在 HumanEval+ 上超越了在超過 3.3T 個符號上進行預訓練的 StarCoder2-3B，HumanEval+ 是評估函式層級程式碼產生的基準，並且在 BigCodeBench 上保持競爭力。我們的評估提供了全面的分析，證明了 Arctic-SnowCoder 的各種設計選擇。最重要的是，我們發現高品質資料的關鍵在於它與下游應用程式的分佈一致。</paragraph>

##### **TimeDiT: General-purpose Diffusion Transformers for Time Series Foundation Model**
2409.02322v1 by Defu Cao, Wen Ye, Yizhou Zhang, Yan Liu

With recent advances in building foundation models for texts and video data,
there is a surge of interest in foundation models for time series. A family of
models have been developed, utilizing a temporal auto-regressive generative
Transformer architecture, whose effectiveness has been proven in Large Language
Models. While the empirical results are promising, almost all existing time
series foundation models have only been tested on well-curated ``benchmark''
datasets very similar to texts. However, real-world time series exhibit unique
challenges, such as variable channel sizes across domains, missing values, and
varying signal sampling intervals due to the multi-resolution nature of
real-world data. Additionally, the uni-directional nature of temporally
auto-regressive decoding limits the incorporation of domain knowledge, such as
physical laws expressed as partial differential equations (PDEs). To address
these challenges, we introduce the Time Diffusion Transformer (TimeDiT), a
general foundation model for time series that employs a denoising diffusion
paradigm instead of temporal auto-regressive generation. TimeDiT leverages the
Transformer architecture to capture temporal dependencies and employs diffusion
processes to generate high-quality candidate samples without imposing stringent
assumptions on the target distribution via novel masking schemes and a channel
alignment strategy. Furthermore, we propose a finetuning-free model editing
strategy that allows the seamless integration of external knowledge during the
sampling process without updating any model parameters. Extensive experiments
conducted on a varity of tasks such as forecasting, imputation, and anomaly
detection, demonstrate the effectiveness of TimeDiT.

摘要：<paragraph>隨著近期在文字和影片資料建立基礎模型的進展，
對於時間序列的基礎模型產生了激增的興趣。已經開發出一系列
模型，利用時間自迴歸生成式 Transformer 架構，其有效性已在大型語言
模型中得到證明。儘管經驗結果令人振奮，但幾乎所有現有的時間
序列基礎模型都只在與文字非常類似的精心整理的「基準」
資料集上進行了測試。然而，真實世界的時間序列展現出獨特的
挑戰，例如跨領域的變量通道大小、遺失值以及由於真實世界資料的多解析度性質而產生的不同訊號採樣間隔。此外，時間自迴歸解碼的單向性質限制了領域知識的整合，例如表達為偏微分方程式 (PDE) 的物理定律。為了應對
這些挑戰，我們引入了時間擴散Transformer (TimeDiT)，這是一種時間序列的通用基礎模型，採用去噪擴散範例，而不是時間自迴歸生成。TimeDiT 藉由Transformer架構來擷取時間依賴性，並採用擴散程序來產生高品質的候選樣本，而不會透過新穎的遮罩方案和通道對齊策略對目標分佈施加嚴格的假設。此外，我們提出了一個微調免費的模型編輯策略，允許在採樣過程中無縫整合外部知識，而無需更新任何模型參數。在預測、內插和異常偵測等各種任務上進行的廣泛實驗，證明了 TimeDiT 的有效性。</paragraph>

##### **On the Benefits of Memory for Modeling Time-Dependent PDEs**
2409.02313v1 by Ricardo Buitrago Ruiz, Tanya Marwah, Albert Gu, Andrej Risteski

Data-driven techniques have emerged as a promising alternative to traditional
numerical methods for solving partial differential equations (PDEs). These
techniques frequently offer a better trade-off between computational cost and
accuracy for many PDE families of interest. For time-dependent PDEs, existing
methodologies typically treat PDEs as Markovian systems, i.e., the evolution of
the system only depends on the ``current state'', and not the past states.
However, distortion of the input signals -- e.g., due to discretization or
low-pass filtering -- can render the evolution of the distorted signals
non-Markovian. In this work, motivated by the Mori-Zwanzig theory of model
reduction, we investigate the impact of architectures with memory for modeling
PDEs: that is, when past states are explicitly used to predict the future. We
introduce Memory Neural Operator (MemNO), a network based on the recent SSM
architectures and Fourier Neural Operator (FNO). We empirically demonstrate on
a variety of PDE families of interest that when the input is given on a
low-resolution grid, MemNO significantly outperforms the baselines without
memory, achieving more than 6 times less error on unseen PDEs. Via a
combination of theory and experiments, we show that the effect of memory is
particularly significant when the solution of the PDE has high frequency
Fourier components (e.g., low-viscosity fluid dynamics), and it also increases
robustness to observation noise.

摘要：<paragraph>資料驅動技術已成為解決偏微分方程式 (PDE) 的傳統數值方法的替代方案，且前景看好。對於許多 PDE 族，這些技術通常在運算成本和準確性之間提供更好的折衷方案。對於時間依賴的 PDE，現有的方法通常將 PDE 視為馬可夫系統，即系統的演化僅取決於「當前狀態」，而非過去的狀態。然而，輸入訊號的失真（例如，由於離散化或低通濾波）會導致失真訊號的演化成為非馬可夫。在這項工作中，受到 Mori-Zwanzig 模型簡化的理論啟發，我們探討了具有記憶的架構對 PDE 建模的影響：也就是說，當過去的狀態被明確用於預測未來時。我們引入了記憶神經算子 (MemNO)，一個基於近期 SSM 架構和傅立葉神經算子 (FNO) 的網路。我們在各種 PDE 族上實證展示，當輸入給定在低解析度網格上時，MemNO 明顯優於沒有記憶的基準，在未見的 PDE 上達到了 6 倍以上的誤差降低。透過理論和實驗的結合，我們表明了當 PDE 的解具有高頻率傅立葉分量（例如，低黏度流體力學）時，記憶的效應特別顯著，並且它也增加了對觀測雜訊的魯棒性。</paragraph>

##### **Speech Foundation Model Ensembles for the Controlled Singing Voice Deepfake Detection (CtrSVDD) Challenge 2024**
2409.02302v1 by Anmol Guragain, Tianchi Liu, Zihan Pan, Hardik B. Sailor, Qiongqiong Wang

This work details our approach to achieving a leading system with a 1.79%
pooled equal error rate (EER) on the evaluation set of the Controlled Singing
Voice Deepfake Detection (CtrSVDD). The rapid advancement of generative AI
models presents significant challenges for detecting AI-generated deepfake
singing voices, attracting increased research attention. The Singing Voice
Deepfake Detection (SVDD) Challenge 2024 aims to address this complex task. In
this work, we explore the ensemble methods, utilizing speech foundation models
to develop robust singing voice anti-spoofing systems. We also introduce a
novel Squeeze-and-Excitation Aggregation (SEA) method, which efficiently and
effectively integrates representation features from the speech foundation
models, surpassing the performance of our other individual systems. Evaluation
results confirm the efficacy of our approach in detecting deepfake singing
voices. The codes can be accessed at https://github.com/Anmol2059/SVDD2024.

摘要：本研究詳述我們的方法，以在受控歌唱語音深度偽造檢測 (CtrSVDD) 的評估集中實現 1.79% 池化等錯誤率 (EER) 的領先系統。生成式 AI 模型的快速進展為偵測 AI 生成的深度偽造歌唱語音帶來重大挑戰，吸引了越來越多的研究關注。歌唱語音深度偽造檢測 (SVDD) 挑戰 2024 年旨在解決這項複雜的任務。在這項研究中，我們探討了整體方法，利用語音基礎模型來開發強健的歌唱語音反欺騙系統。我們還引入了一種新穎的擠壓和激勵聚合 (SEA) 方法，該方法有效且高效地整合了語音基礎模型的表示特徵，超越了我們其他個別系統的效能。評估結果證實了我們的方法在偵測深度偽造歌唱語音方面的效力。可以在 https://github.com/Anmol2059/SVDD2024 取得程式碼。

##### **Initial Development and Evaluation of the Creative Artificial Intelligence through Recurring Developments and Determinations (CAIRDD) System**
2409.02291v1 by Jeremy Straub, Zach Johnson

Computer system creativity is a key step on the pathway to artificial general
intelligence (AGI). It is elusive, however, due to the fact that human
creativity is not fully understood and, thus, it is difficult to develop this
capability in software. Large language models (LLMs) provide a facsimile of
creativity and the appearance of sentience, while not actually being either
creative or sentient. While LLMs have created bona fide new content, in some
cases - such as with harmful hallucinations - inadvertently, their deliberate
creativity is seen by some to not match that of humans. In response to this
challenge, this paper proposes a technique for enhancing LLM output creativity
via an iterative process of concept injection and refinement. Initial work on
the development of the Creative Artificial Intelligence through Recurring
Developments and Determinations (CAIRDD) system is presented and the efficacy
of key system components is evaluated.

摘要：電腦系統的創造力是通往人工通用智慧 (AGI) 的關鍵一步。然而，由於人類的創造力尚未被完全理解，因此它難以捉摸，而且在軟體中開發這種能力也十分困難。大型語言模型 (LLM) 提供了創造力的複製品和知覺的表象，但實際上既不具創造力也不具知覺。雖然 LLM 在某些情況下（例如有害的幻覺）無意間創造了真正的全新內容，但有些人認為它們的刻意創造力無法與人類相提並論。為了應對這個挑戰，本文提出了一種透過概念注入和優化的反覆運算過程來增強 LLM 輸出創造力的技術。本文介紹了透過反覆開發和決策 (CAIRDD) 系統開發創造性人工智慧的初步工作，並評估了關鍵系統組件的效能。

##### **Reinforcement Learning-enabled Satellite Constellation Reconfiguration and Retasking for Mission-Critical Applications**
2409.02270v1 by Hassan El Alami, Danda B. Rawat

The development of satellite constellation applications is rapidly advancing
due to increasing user demands, reduced operational costs, and technological
advancements. However, a significant gap in the existing literature concerns
reconfiguration and retasking issues within satellite constellations, which is
the primary focus of our research. In this work, we critically assess the
impact of satellite failures on constellation performance and the associated
task requirements. To facilitate this analysis, we introduce a system modeling
approach for GPS satellite constellations, enabling an investigation into
performance dynamics and task distribution strategies, particularly in
scenarios where satellite failures occur during mission-critical operations.
Additionally, we introduce reinforcement learning (RL) techniques, specifically
Q-learning, Policy Gradient, Deep Q-Network (DQN), and Proximal Policy
Optimization (PPO), for managing satellite constellations, addressing the
challenges posed by reconfiguration and retasking following satellite failures.
Our results demonstrate that DQN and PPO achieve effective outcomes in terms of
average rewards, task completion rates, and response times.

摘要：由於使用者需求增加、營運成本降低和技術進步，衛星星座應用程式的開發正快速進展中。然而，現有文獻中的一個重大差距在於衛星星座內的重新組態和重新任務問題，這是我們研究的主要焦點。在這項工作中，我們批判性地評估衛星故障對星座效能和相關任務需求的影響。為了促進此分析，我們引入了一個用於 GPS 衛星星座的系統建模方法，可以用於調查效能動態和任務分配策略，特別是在任務關鍵操作期間發生衛星故障的情況。此外，我們引入了強化學習 (RL) 技術，特別是 Q 學習、策略梯度、深度 Q 網路 (DQN) 和近端策略最佳化 (PPO)，用於管理衛星星座，解決衛星故障後重新組態和重新任務帶來的挑戰。我們的結果表明，DQN 和 PPO 在平均獎勵、任務完成率和回應時間方面取得了有效的成果。

##### **Optimal L-Systems for Stochastic L-system Inference Problems**
2409.02259v1 by Ali Lotfi, Ian McQuillan

This paper presents two novel theorems that address two open problems in
stochastic Lindenmayer-system (L-system) inference, specifically focusing on
the construction of an optimal stochastic L-system capable of generating a
given sequence of strings. The first theorem delineates a method for crafting a
stochastic L-system that maximizes the likelihood of producing a given sequence
of words through a singular derivation. Furthermore, the second theorem
determines the stochastic L-systems with the highest probability of producing a
given sequence of words with multiple possible derivations. From these, we
introduce an algorithm to infer an optimal stochastic L-system from a given
sequence. This algorithm incorporates sophisticated optimization techniques,
such as interior point methods, ensuring production of a stochastically optimal
stochastic L-system suitable for generating the given sequence. This allows for
the use of using stochastic L-systems as model for machine learning using only
positive data for training.

摘要：本文提出了兩個新定理，用於解決隨機林登梅爾系統 (L 系統) 推論中的兩個開放問題，特別關注構建一個最佳隨機 L 系統，能夠生成給定的字串序列。第一個定理描述了一種方法，用於製作一個隨機 L 系統，通過單一推導最大化產生給定字詞序列的可能性。此外，第二個定理確定了在多個可能的推導下，產生給定字詞序列的機率最高的隨機 L 系統。從這些，我們引入了演算法，從給定的序列推論出最佳隨機 L 系統。此演算法結合了先進的最佳化技術，例如內點法，確保產生適合用於生成給定序列的最佳隨機 L 系統。這允許使用隨機 L 系統作為機器學習模型，僅使用正向資料進行訓練。

##### **MMLU-Pro+: Evaluating Higher-Order Reasoning and Shortcut Learning in LLMs**
2409.02257v1 by Saeid Asgari Taghanaki, Aliasgahr Khani, Amir Khasahmadi

Existing benchmarks for large language models (LLMs) increasingly struggle to
differentiate between top-performing models, underscoring the need for more
challenging evaluation frameworks. We introduce MMLU-Pro+, an enhanced
benchmark building upon MMLU-Pro to assess shortcut learning and higher-order
reasoning in LLMs. By incorporating questions with multiple correct answers
across diverse domains, MMLU-Pro+ tests LLMs' ability to engage in complex
reasoning and resist simplistic problem-solving strategies. Our results show
that MMLU-Pro+ maintains MMLU-Pro's difficulty while providing a more rigorous
test of model discrimination, particularly in multi-correct answer scenarios.
We introduce novel metrics like shortcut selection ratio and correct pair
identification ratio, offering deeper insights into model behavior and
anchoring bias. Evaluations of five state-of-the-art LLMs reveal significant
performance gaps, highlighting variations in reasoning abilities and bias
susceptibility. We release the dataset and evaluation codes at
\url{https://github.com/asgsaeid/mmlu-pro-plus}.

摘要：現有的大型語言模型 (LLM) 基準越來越難以區分效能最佳的模型，這突顯了對更具挑戰性的評估架構的需求。我們引入了 MMLU-Pro+，一個建構於 MMLU-Pro 之上的增強式基準，用於評估 LLM 中的捷徑學習和高階推理。透過納入跨不同領域且具有多個正確答案的問題，MMLU-Pro+ 測試了 LLM 進行複雜推理和抵禦簡化問題解決策略的能力。我們的結果顯示，MMLU-Pro+ 保留了 MMLU-Pro 的難度，同時提供了更嚴謹的模型區分測試，特別是在多個正確答案的情況下。我們引入了捷徑選擇比率和正確配對識別比率等新穎的指標，提供了對模型行為和錨定偏差更深入的見解。對五個最先進的 LLM 的評估揭示了顯著的效能差距，突顯了推理能力和偏差敏感性的差異。我們在 \url{https://github.com/asgsaeid/mmlu-pro-plus} 釋出了資料集和評估程式碼。

##### **NoiseAttack: An Evasive Sample-Specific Multi-Targeted Backdoor Attack Through White Gaussian Noise**
2409.02251v1 by Abdullah Arafat Miah, Kaan Icer, Resit Sendag, Yu Bi

Backdoor attacks pose a significant threat when using third-party data for
deep learning development. In these attacks, data can be manipulated to cause a
trained model to behave improperly when a specific trigger pattern is applied,
providing the adversary with unauthorized advantages. While most existing works
focus on designing trigger patterns in both visible and invisible to poison the
victim class, they typically result in a single targeted class upon the success
of the backdoor attack, meaning that the victim class can only be converted to
another class based on the adversary predefined value. In this paper, we
address this issue by introducing a novel sample-specific multi-targeted
backdoor attack, namely NoiseAttack. Specifically, we adopt White Gaussian
Noise (WGN) with various Power Spectral Densities (PSD) as our underlying
triggers, coupled with a unique training strategy to execute the backdoor
attack. This work is the first of its kind to launch a vision backdoor attack
with the intent to generate multiple targeted classes with minimal input
configuration. Furthermore, our extensive experimental results demonstrate that
NoiseAttack can achieve a high attack success rate against popular network
architectures and datasets, as well as bypass state-of-the-art backdoor
detection methods. Our source code and experiments are available at
https://github.com/SiSL-URI/NoiseAttack/tree/main.

摘要：後門攻擊在使用第三方資料進行深度學習開發時，會構成重大威脅。在這些攻擊中，資料可能會被竄改，導致訓練後的模型在套用特定觸發模式時行為不當，讓對手獲得未經授權的優勢。雖然大多數現有研究都專注於設計可見和不可見的觸發模式，以毒化受害者類別，但它們通常在後門攻擊成功後只會導致單一目標類別，表示受害者類別只能根據對手預先定義的值轉換成另一個類別。在本文中，我們透過引入一種新穎的樣本特定多目標後門攻擊，也就是 NoiseAttack，來解決這個問題。具體來說，我們採用具有各種功率譜密度 (PSD) 的白高斯雜訊 (WGN) 作為我們的基礎觸發器，並結合獨特的訓練策略來執行後門攻擊。這項研究是首度發起視覺後門攻擊，目的是在最少的輸入設定下產生多個目標類別。此外，我們廣泛的實驗結果證明，NoiseAttack 可以對流行的網路架構和資料集達成很高的攻擊成功率，而且可以繞過最先進的後門偵測方法。我們的原始碼和實驗可於 https://github.com/SiSL-URI/NoiseAttack/tree/main 取得。

##### **FastVoiceGrad: One-step Diffusion-Based Voice Conversion with Adversarial Conditional Diffusion Distillation**
2409.02245v1 by Takuhiro Kaneko, Hirokazu Kameoka, Kou Tanaka, Yuto Kondo

Diffusion-based voice conversion (VC) techniques such as VoiceGrad have
attracted interest because of their high VC performance in terms of speech
quality and speaker similarity. However, a notable limitation is the slow
inference caused by the multi-step reverse diffusion. Therefore, we propose
FastVoiceGrad, a novel one-step diffusion-based VC that reduces the number of
iterations from dozens to one while inheriting the high VC performance of the
multi-step diffusion-based VC. We obtain the model using adversarial
conditional diffusion distillation (ACDD), leveraging the ability of generative
adversarial networks and diffusion models while reconsidering the initial
states in sampling. Evaluations of one-shot any-to-any VC demonstrate that
FastVoiceGrad achieves VC performance superior to or comparable to that of
previous multi-step diffusion-based VC while enhancing the inference speed.
Audio samples are available at
https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/fastvoicegrad/.

摘要：<paragraph>基於擴散的語音轉換 (VC) 技術，例如 VoiceGrad，因其在語音品質和說話者相似度方面的出色 VC 效能而備受關注。然而，一個顯著的限制是多步驟反向擴散所造成的緩慢推論。因此，我們提出 FastVoiceGrad，一種新穎的單步驟基於擴散的 VC，它將迭代次數從數十次減少到一次，同時繼承了基於多步驟擴散的 VC 的高 VC 效能。我們使用對抗條件擴散蒸餾 (ACDD) 獲取模型，利用生成對抗網路和擴散模型的能力，同時重新考慮採樣中的初始狀態。單次任意到任意 VC 的評估表明，FastVoiceGrad 達到了優於或等於先前基於多步驟擴散的 VC 的 VC 效能，同時提高了推論速度。音訊範例可在 https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/fastvoicegrad/ 取得。</paragraph>

##### **Therapy as an NLP Task: Psychologists' Comparison of LLMs and Human Peers in CBT**
2409.02244v1 by Zainab Iftikhar, Sean Ransom, Amy Xiao, Jeff Huang

Wider access to therapeutic care is one of the biggest challenges in mental
health treatment. Due to institutional barriers, some people seeking mental
health support have turned to large language models (LLMs) for personalized
therapy, even though these models are largely unsanctioned and untested. We
investigate the potential and limitations of using LLMs as providers of
evidence-based therapy by using mixed methods clinical metrics. Using HELPERT,
a prompt run on a large language model using the same process and training as a
comparative group of peer counselors, we replicated publicly accessible mental
health conversations rooted in Cognitive Behavioral Therapy (CBT) to compare
session dynamics and counselor's CBT-based behaviors between original peer
support sessions and their reconstructed HELPERT sessions. Two licensed,
CBT-trained clinical psychologists evaluated the sessions using the Cognitive
Therapy Rating Scale and provided qualitative feedback. Our findings show that
the peer sessions are characterized by empathy, small talk, therapeutic
alliance, and shared experiences but often exhibit therapist drift. Conversely,
HELPERT reconstructed sessions exhibit minimal therapist drift and higher
adherence to CBT methods but display a lack of collaboration, empathy, and
cultural understanding. Through CTRS ratings and psychologists' feedback, we
highlight the importance of human-AI collaboration for scalable mental health.
Our work outlines the ethical implication of imparting human-like subjective
qualities to LLMs in therapeutic settings, particularly the risk of deceptive
empathy, which may lead to unrealistic patient expectations and potential harm.

摘要：擴大治療照護管道是心理健康治療中最大的挑戰之一。由於制度障礙，一些尋求心理健康支持的人轉向大型語言模型 (LLM) 進行個人化治療，儘管這些模型在很大程度上未經批准且未經測試。我們使用混合方法臨床指標來探討使用 LLM 作為循證療法提供者的潛力和限制。使用 HELPERT，在大型語言模型上執行提示，使用與比較組的同儕諮詢師相同的流程和訓練，我們複製了基於認知行為療法 (CBT) 的公開心理健康對話，以比較原始同儕支持會話和其重建的 HELPERT 會話之間的會話動態和諮詢師基於 CBT 的行為。兩位經過許可的、受過 CBT 訓練的臨床心理學家使用認知治療評分量表評估這些會話，並提供定性回饋。我們的研究結果顯示，同儕會話的特徵是同理心、閒聊、治療聯盟和共同經驗，但經常表現出治療師漂移。相反，HELPERT 重建的會話表現出最小的治療師漂移和對 CBT 方法的更高依循性，但缺乏協作、同理心和文化理解。透過 CTRS 評分和心理學家的回饋，我們強調了人機協作對於可擴展心理健康的重要性。我們的研究概述了在治療環境中賦予 LLM 類人主觀品質的倫理影響，特別是具有欺騙性同理心的風險，這可能會導致不切實際的患者期望和潛在危害。

##### **Temporal Order Preserved Optimal Transport-based Cross-modal Knowledge Transfer Learning for ASR**
2409.02239v2 by Xugang Lu, Peng Shen, Yu Tsao, Hisashi Kawai

Transferring linguistic knowledge from a pretrained language model (PLM) to
an acoustic model has been shown to greatly improve the performance of
automatic speech recognition (ASR). However, due to the heterogeneous feature
distributions in cross-modalities, designing an effective model for feature
alignment and knowledge transfer between linguistic and acoustic sequences
remains a challenging task. Optimal transport (OT), which efficiently measures
probability distribution discrepancies, holds great potential for aligning and
transferring knowledge between acoustic and linguistic modalities. Nonetheless,
the original OT treats acoustic and linguistic feature sequences as two
unordered sets in alignment and neglects temporal order information during OT
coupling estimation. Consequently, a time-consuming pretraining stage is
required to learn a good alignment between the acoustic and linguistic
representations. In this paper, we propose a Temporal Order Preserved OT
(TOT)-based Cross-modal Alignment and Knowledge Transfer (CAKT) (TOT-CAKT) for
ASR. In the TOT-CAKT, local neighboring frames of acoustic sequences are
smoothly mapped to neighboring regions of linguistic sequences, preserving
their temporal order relationship in feature alignment and matching. With the
TOT-CAKT model framework, we conduct Mandarin ASR experiments with a pretrained
Chinese PLM for linguistic knowledge transfer. Our results demonstrate that the
proposed TOT-CAKT significantly improves ASR performance compared to several
state-of-the-art models employing linguistic knowledge transfer, and addresses
the weaknesses of the original OT-based method in sequential feature alignment
for ASR.

摘要：將語言知識從預訓練語言模型 (PLM) 轉移到聲學模型已證實能大幅提升自動語音辨識 (ASR) 的效能。然而，由於跨模態異質特徵分佈，設計一個用於特徵比對和在語言及聲學序列間知識轉移的有效模型仍是一項艱鉅的任務。最佳傳輸 (OT) 能有效測量機率分佈差異，對於比對和在聲學和語言模態間轉移知識具有極大的潛力。儘管如此，原始 OT 將聲學和語言特徵序列視為比對中的兩個無序集合，且在 OT 耦合估計期間忽略時間順序資訊。因此，需要一個耗時的預訓練階段來學習聲學和語言表示間良好的比對。在本文中，我們提出一個基於時間順序保留 OT (TOT) 的跨模態比對和知識轉移 (CAKT) (TOT-CAKT) 用於 ASR。在 TOT-CAKT 中，聲學序列的局部相鄰幀會平滑地對應到語言序列的相鄰區域，在特徵比對和匹配中保留它們的時間順序關係。運用 TOT-CAKT 模型架構，我們使用預訓練的中文 PLM 進行國語 ASR 實驗以進行語言知識轉移。我們的結果證明，與採用語言知識轉移的幾個最先進模型相比，所提出的 TOT-CAKT 能大幅提升 ASR 效能，並解決了原始基於 OT 的方法在 ASR 中進行序列特徵比對的弱點。

##### **Unforgettable Generalization in Language Models**
2409.02228v1 by Eric Zhang, Leshem Chosen, Jacob Andreas

When language models (LMs) are trained to forget (or "unlearn'') a skill, how
precisely does their behavior change? We study the behavior of transformer LMs
in which tasks have been forgotten via fine-tuning on randomized labels. Such
LMs learn to generate near-random predictions for individual examples in the
"training'' set used for forgetting. Across tasks, however, LMs exhibit extreme
variability in whether LM predictions change on examples outside the training
set. In some tasks (like entailment classification), forgetting generalizes
robustly, and causes models to produce uninformative predictions on new task
instances; in other tasks (like physical commonsense reasoning and scientific
question answering) forgetting affects only the training examples, and models
continue to perform the "forgotten'' task accurately even for examples very
similar to those that appeared in the training set. Dataset difficulty is not
predictive of whether a behavior can be forgotten; instead, generalization in
forgetting is (weakly) predicted by the confidence of LMs' initial task
predictions and the variability of LM representations of training data, with
low confidence and low variability both associated with greater generalization.
Perhaps most surprisingly, random-label forgetting appears to be somewhat
insensitive to the contents of the training set: for example, models trained on
science questions with random labels continue to answer other science questions
accurately, but begin to produce random labels on entailment classification
tasks. Finally, we show that even generalizable forgetting is shallow: linear
probes trained on LMs' representations can still perform tasks reliably after
forgetting. Our results highlight the difficulty and unpredictability of
performing targeted skill removal from models via fine-tuning.

摘要：當語言模型 (LM) 被訓練去遺忘 (或「遺失」) 一項技能時，它們的行為會如何精準地改變？我們研究了Transformer LM 的行為，在這些行為中，任務已被遺忘，並透過在隨機標籤上進行微調。此類 LM 學會為「訓練」集中用於遺忘的個別範例產生近乎隨機的預測。然而，在各項任務中，LM 在 LM 預測是否會改變訓練集外的範例方面表現出極大的變異性。在某些任務中（例如蘊涵分類），遺忘會強健地概化，並導致模型對新的任務實例產生無意義的預測；在其他任務中（例如物理常識推理和科學問題解答），遺忘只會影響訓練範例，而模型仍能準確執行「被遺忘」的任務，即使對於那些出現在訓練集中與之非常類似的範例也是如此。資料集的難度無法預測某種行為是否能被遺忘；相反地，遺忘中的概化是由 LM 初始任務預測的信心和 LM 訓練資料表徵的變異性（弱地）預測的，而低信心和低變異性都與更大的概化相關。也許最令人驚訝的是，隨機標籤遺忘似乎對訓練集的內容有些遲鈍：例如，在使用隨機標籤訓練科學問題的模型會繼續準確回答其他科學問題，但會開始在蘊涵分類任務中產生隨機標籤。最後，我們展示了即使是可概化的遺忘也是膚淺的：在 LM 表徵上訓練的線性探測仍可以在遺忘後可靠地執行任務。我們的結果突出了透過微調從模型中執行目標技能移除的困難性和不可預測性。

##### **Visually Grounded Speech Models for Low-resource Languages and Cognitive Modelling**
2409.02865v1 by Leanne Nortje

This dissertation examines visually grounded speech (VGS) models that learn
from unlabelled speech paired with images. It focuses on applications for
low-resource languages and understanding human language acquisition. We
introduce a task called visually prompted keyword localisation to detect and
localise keywords in speech using images. We demonstrate the effectiveness of
VGS models in few-shot learning scenarios for low-resource languages like
Yoruba. Additionally, we examine the mutual exclusivity bias in VGS models. Our
monolingual VGS model exhibits this bias, but we found that multilingualism
does not affect the bias in this VGS model similarly to what is observed in
children.

摘要：本論文探討視覺基礎語言 (VGS) 模型，此模型從與影像配對的未標註語言中學習。它專注於低資源語言的應用和理解人類語言習得。我們引入一項名為視覺提示關鍵字定位的任務，以使用影像偵測和定位語言中的關鍵字。我們展示了 VGS 模型在少次學習場景中對低資源語言（例如約魯巴語）的有效性。此外，我們探討了 VGS 模型中的互斥偏誤。我們的單語 VGS 模型展現了此偏誤，但我們發現多語並不會影響此 VGS 模型中的偏誤，這與在兒童中觀察到的情況類似。

##### **CRAFT Your Dataset: Task-Specific Synthetic Dataset Generation Through Corpus Retrieval and Augmentation**
2409.02098v1 by Ingo Ziegler, Abdullatif Köksal, Desmond Elliott, Hinrich Schütze

Building high-quality datasets for specialized tasks is a time-consuming and
resource-intensive process that often requires specialized domain knowledge. We
propose Corpus Retrieval and Augmentation for Fine-Tuning (CRAFT), a method for
generating synthetic datasets, given a small number of user-written few-shots
that demonstrate the task to be performed. Given the few-shot examples, we use
large-scale public web-crawled corpora and similarity-based document retrieval
to find other relevant human-written documents. Lastly, instruction-tuned large
language models (LLMs) augment the retrieved documents into custom-formatted
task samples, which then can be used for fine-tuning. We demonstrate that CRAFT
can efficiently generate large-scale task-specific training datasets for four
diverse tasks: biology question-answering (QA), medicine QA and commonsense QA
as well as summarization. Our experiments show that CRAFT-based models
outperform or achieve comparable performance to general LLMs for QA tasks,
while CRAFT-based summarization models outperform models trained on
human-curated data by 46 preference points.

摘要：建立高质量数据集以用于专门任务是一个耗时且资源密集的过程，通常需要专门的领域知识。我们提出语料检索和增强微调（CRAFT），这是一种生成合成数据集的方法，给定少量用户编写的少镜头演示要执行的任务。鉴于少镜头示例，我们使用大规模公共网络爬取语料库和基于相似性的文档检索来查找其他相关的人工编写的文档。最后，经过指令调整的大语言模型 (LLM) 将检索到的文档增强为定制格式的任务样本，然后可用于微调。我们证明 CRAFT 可以有效地生成针对四个不同任务的大规模特定任务训练数据集：生物学问答 (QA)、医学 QA 和常识 QA 以及摘要。我们的实验表明，对于 QA 任务，基于 CRAFT 的模型优于或达到与通用 LLM 相当的性能，而基于 CRAFT 的摘要模型则优于在人工整理数据上训练的模型，偏好得分提高了 46 分。

##### **DepthCrafter: Generating Consistent Long Depth Sequences for Open-world Videos**
2409.02095v1 by Wenbo Hu, Xiangjun Gao, Xiaoyu Li, Sijie Zhao, Xiaodong Cun, Yong Zhang, Long Quan, Ying Shan

Despite significant advancements in monocular depth estimation for static
images, estimating video depth in the open world remains challenging, since
open-world videos are extremely diverse in content, motion, camera movement,
and length. We present DepthCrafter, an innovative method for generating
temporally consistent long depth sequences with intricate details for
open-world videos, without requiring any supplementary information such as
camera poses or optical flow. DepthCrafter achieves generalization ability to
open-world videos by training a video-to-depth model from a pre-trained
image-to-video diffusion model, through our meticulously designed three-stage
training strategy with the compiled paired video-depth datasets. Our training
approach enables the model to generate depth sequences with variable lengths at
one time, up to 110 frames, and harvest both precise depth details and rich
content diversity from realistic and synthetic datasets. We also propose an
inference strategy that processes extremely long videos through segment-wise
estimation and seamless stitching. Comprehensive evaluations on multiple
datasets reveal that DepthCrafter achieves state-of-the-art performance in
open-world video depth estimation under zero-shot settings. Furthermore,
DepthCrafter facilitates various downstream applications, including depth-based
visual effects and conditional video generation.

摘要：儘管靜態影像的單眼深度估計技術已大幅進步，但開放世界中的影片深度估計仍是一項挑戰，因為開放世界的影片在內容、動作、相機移動和長度上極為多樣化。我們提出 DepthCrafter，這是一種創新方法，用於為開放世界的影片產生具有複雜細節且在時間上一致的長深度序列，而不需要任何補充資訊，例如相機姿勢或光流。DepthCrafter 透過我們精心設計的三階段訓練策略，從預先訓練好的影像到影片擴散模型訓練影片到深度模型，進而達成對開放世界影片的泛化能力，並編譯配對的影片深度資料集。我們的訓練方法使模型能夠一次產生長度可變的深度序列，最多可達 110 幀，並從逼真和合成資料集中擷取精確的深度細節和豐富的內容多樣性。我們還提出了一種推理策略，透過分段估計和無縫拼接來處理極長的影片。在多個資料集上的全面評估顯示，DepthCrafter 在零次學習設定下，在開放世界的影片深度估計中達到了最先進的效能。此外，DepthCrafter 促進了各種下游應用，包括基於深度的視覺效果和條件式影片產生。

##### **Political DEBATE: Efficient Zero-shot and Few-shot Classifiers for Political Text**
2409.02078v1 by Michael Burnham, Kayla Kahn, Ryan Yank Wang, Rachel X. Peng

Social scientists quickly adopted large language models due to their ability
to annotate documents without supervised training, an ability known as
zero-shot learning. However, due to their compute demands, cost, and often
proprietary nature, these models are often at odds with replication and open
science standards. This paper introduces the Political DEBATE (DeBERTa
Algorithm for Textual Entailment) language models for zero-shot and few-shot
classification of political documents. These models are not only as good, or
better than, state-of-the art large language models at zero and few-shot
classification, but are orders of magnitude more efficient and completely open
source. By training the models on a simple random sample of 10-25 documents,
they can outperform supervised classifiers trained on hundreds or thousands of
documents and state-of-the-art generative models with complex, engineered
prompts. Additionally, we release the PolNLI dataset used to train these models
-- a corpus of over 200,000 political documents with highly accurate labels
across over 800 classification tasks.

摘要：<paragraph>社會科學家很快便採用大型語言模型，因為它們能夠在沒有監督訓練的情況下註解文件，這項能力稱為零次學習。然而，由於它們的運算需求、成本，以及通常的專有性質，這些模型通常與複製和開放科學標準相衝突。本文介紹了用於零次和少量政治文件分類的政治辯論（文本含義的 DeBERTa 演算法）語言模型。這些模型不僅與最先進的大型語言模型在零次和少量分類中一樣好，甚至更好，而且它們的效率高出幾個數量級，並且完全開放原始碼。通過在 10-25 份文件的簡單隨機樣本上訓練模型，它們可以優於在數百或數千份文件上訓練的監督分類器，以及具有複雜工程提示的最先進生成模型。此外，我們發布了用於訓練這些模型的 PolNLI 資料集——一個包含超過 200,000 份政治文件的主體，這些文件在 800 多個分類任務中具有高度準確的標籤。</paragraph>

##### **Spinning the Golden Thread: Benchmarking Long-Form Generation in Language Models**
2409.02076v1 by Yuhao Wu, Ming Shan Hee, Zhiqing Hu, Roy Ka-Wei Lee

The abilities of long-context language models (LMs) are often evaluated using
the "Needle-in-a-Haystack" (NIAH) test, which comprises tasks designed to
assess a model's ability to identify specific information ("needle") within
large text sequences ("haystack"). While these benchmarks measure how well
models understand long-context input sequences, they do not effectively gauge
the quality of long-form text generation--a critical aspect for applications
such as design proposals and creative writing. To address this gap, we have
introduced a new long-form text evaluation benchmark, Spinning the Golden
Thread (SGT), which tests models' ability to identify specific events within
generated long text sequences. In this benchmark, we prompt long-context LMs to
create long-form text that must include particular events or constraints and
evaluate their ability to incorporate these elements. We evaluated ten
long-context LMs across four distinct scenarios, three types of prompt
instructions, and two different generation-length settings (16K and 32K).
Although these models perform well on NIAH benchmarks, none demonstrated
satisfactory performance on the Spinning the Golden Thread, raising concerns
about their ability to generate coherent long-form text that follows
instructions. Additionally, as the length of the generated text increases, all
models exhibit a significant drop in performance.

摘要：長語境語言模型 (LM) 的能力通常使用「大海撈針」(NIAH) 測試來評估，其中包含旨在評估模型在大型文字序列（「乾草堆」）中識別特定資訊（「針」）的能力的任務。雖然這些基準衡量模型對長語境輸入序列的理解程度，但它們無法有效評估長篇文字生成的品質，這對於設計提案和創意寫作等應用來說是一個至關重要的面向。為了解決這個差距，我們引進了一個新的長篇文字評估基準，稱為紡金線（SGT），它測試模型在生成的長文字序列中識別特定事件的能力。在此基準中，我們提示長語境 LM 建立必須包含特定事件或限制的長篇文字，並評估它們納入這些元素的能力。我們在四個不同的情境、三種類型的提示說明和兩種不同的生成長度設定（16K 和 32K）中評估了十個長語境 LM。儘管這些模型在 NIAH 基準上表現良好，但沒有任何一個模型在紡金線測試中展現出令人滿意的表現，這引發了人們對它們生成遵循說明的連貫長篇文字的能力的疑慮。此外，隨著生成的文字長度增加，所有模型的表現都大幅下降。

##### **OLMoE: Open Mixture-of-Experts Language Models**
2409.02060v1 by Niklas Muennighoff, Luca Soldaini, Dirk Groeneveld, Kyle Lo, Jacob Morrison, Sewon Min, Weijia Shi, Pete Walsh, Oyvind Tafjord, Nathan Lambert, Yuling Gu, Shane Arora, Akshita Bhagia, Dustin Schwenk, David Wadden, Alexander Wettig, Binyuan Hui, Tim Dettmers, Douwe Kiela, Ali Farhadi, Noah A. Smith, Pang Wei Koh, Amanpreet Singh, Hannaneh Hajishirzi

We introduce OLMoE, a fully open, state-of-the-art language model leveraging
sparse Mixture-of-Experts (MoE). OLMoE-1B-7B has 7 billion (B) parameters but
uses only 1B per input token. We pretrain it on 5 trillion tokens and further
adapt it to create OLMoE-1B-7B-Instruct. Our models outperform all available
models with similar active parameters, even surpassing larger ones like
Llama2-13B-Chat and DeepSeekMoE-16B. We present various experiments on MoE
training, analyze routing in our model showing high specialization, and
open-source all aspects of our work: model weights, training data, code, and
logs.

摘要：我們推出 OLMoE，一種完全開放的最新語言模型，利用稀疏的混合專家 (MoE)。OLMoE-1B-7B 有 70 億個參數，但每個輸入代幣只使用 10 億個。我們對 5 兆個代幣進行預訓練，並進一步調整以建立 OLMoE-1B-7B-Instruct。我們的模型優於所有具有類似活動參數的可用模型，甚至超越了較大的模型，例如 Llama2-13B-Chat 和 DeepSeekMoE-16B。我們對 MoE 訓練提出各種實驗，分析我們模型中的路由，顯示出高度專業化，並開放我們工作的各個方面：模型權重、訓練數據、代碼和日誌。

##### **Enhancing Code-Switching Speech Recognition with LID-Based Collaborative Mixture of Experts Model**
2409.02050v2 by Hukai Huang, Jiayan Lin, Kaidi Wang, Yishuang Li, Wenhao Guan, Lin Li, Qingyang Hong

Due to the inherent difficulty in modeling phonetic similarities across
different languages, code-switching speech recognition presents a formidable
challenge. This study proposes a Collaborative-MoE, a Mixture of Experts (MoE)
model that leverages a collaborative mechanism among expert groups. Initially,
a preceding routing network explicitly learns Language Identification (LID)
tasks and selects experts based on acquired LID weights. This process ensures
robust routing information to the MoE layer, mitigating interference from
diverse language domains on expert network parameter updates. The LID weights
are also employed to facilitate inter-group collaboration, enabling the
integration of language-specific representations. Furthermore, within each
language expert group, a gating network operates unsupervised to foster
collaboration on attributes beyond language. Extensive experiments demonstrate
the efficacy of our approach, achieving significant performance enhancements
compared to alternative methods. Importantly, our method preserves the
efficient inference capabilities characteristic of MoE models without
necessitating additional pre-training.

摘要：由於跨語言建模音相似性的內在困難，代碼切換語音辨識呈現出一個艱鉅的挑戰。本研究提出協作式 MoE，一種專家混合 (MoE) 模型，該模型利用專家群組之間的協作機制。最初，先行路由網路明確學習語言辨識 (LID) 任務，並根據取得的 LID 權重選擇專家。此程序確保穩健的路由資訊傳送至 MoE 層，減輕來自不同語言領域的干擾，影響專家網路參數更新。LID 權重也用於促進群組間協作，讓語言特定表示得以整合。此外，在每個語言專家群組中，一個閘控網路會在沒有監督的情況下運作，以促進語言以外屬性的協作。廣泛的實驗證明了我們方法的效能，與其他方法相比，達到了顯著的效能提升。重要的是，我們的方法保留了 MoE 模型特有的高效推論能力，而無需額外的預訓練。

##### **Low-Resolution Face Recognition via Adaptable Instance-Relation Distillation**
2409.02049v1 by Ruixin Shi, Weijia Guo, Shiming Ge

Low-resolution face recognition is a challenging task due to the missing of
informative details. Recent approaches based on knowledge distillation have
proven that high-resolution clues can well guide low-resolution face
recognition via proper knowledge transfer. However, due to the distribution
difference between training and testing faces, the learned models often suffer
from poor adaptability. To address that, we split the knowledge transfer
process into distillation and adaptation steps, and propose an adaptable
instance-relation distillation approach to facilitate low-resolution face
recognition. In the approach, the student distills knowledge from
high-resolution teacher in both instance level and relation level, providing
sufficient cross-resolution knowledge transfer. Then, the learned student can
be adaptable to recognize low-resolution faces with adaptive batch
normalization in inference. In this manner, the capability of recovering
missing details of familiar low-resolution faces can be effectively enhanced,
leading to a better knowledge transfer. Extensive experiments on low-resolution
face recognition clearly demonstrate the effectiveness and adaptability of our
approach.

摘要：低分辨率人脸识别因缺少信息细节而成为一项具有挑战性的任务。基于知识蒸馏的最新方法已经证明，高分辨率线索可以通过适当的知识转移很好地指导低分辨率人脸识别。然而，由于训练和测试人脸之间的分布差异，学习模型常常适应性差。为了解决这个问题，我们将知识转移过程拆分为蒸馏和适应步骤，并提出了一种可适应的实例关系蒸馏方法来促进低分辨率人脸识别。在该方法中，学生从高分辨率教师那里蒸馏知识，既在实例层面又在关系层面，提供充分的跨分辨率知识转移。然后，学习的学生可以通过推理中的自适应批处理归一化适应识别低分辨率人脸。通过这种方式，可以有效增强恢复熟悉低分辨率人脸缺失细节的能力，从而实现更好的知识转移。在低分辨率人脸识别上的广泛实验清楚地证明了我们方法的有效性和适应性。

##### **AllWeatherNet:Unified Image enhancement for autonomous driving under adverse weather and lowlight-conditions**
2409.02045v1 by Chenghao Qian, Mahdi Rezaei, Saeed Anwar, Wenjing Li, Tanveer Hussain, Mohsen Azarmi, Wei Wang

Adverse conditions like snow, rain, nighttime, and fog, pose challenges for
autonomous driving perception systems. Existing methods have limited
effectiveness in improving essential computer vision tasks, such as semantic
segmentation, and often focus on only one specific condition, such as removing
rain or translating nighttime images into daytime ones. To address these
limitations, we propose a method to improve the visual quality and clarity
degraded by such adverse conditions. Our method, AllWeather-Net, utilizes a
novel hierarchical architecture to enhance images across all adverse
conditions. This architecture incorporates information at three semantic
levels: scene, object, and texture, by discriminating patches at each level.
Furthermore, we introduce a Scaled Illumination-aware Attention Mechanism
(SIAM) that guides the learning towards road elements critical for autonomous
driving perception. SIAM exhibits robustness, remaining unaffected by changes
in weather conditions or environmental scenes. AllWeather-Net effectively
transforms images into normal weather and daytime scenes, demonstrating
superior image enhancement results and subsequently enhancing the performance
of semantic segmentation, with up to a 5.3% improvement in mIoU in the trained
domain. We also show our model's generalization ability by applying it to
unseen domains without re-training, achieving up to 3.9% mIoU improvement. Code
can be accessed at: https://github.com/Jumponthemoon/AllWeatherNet.

摘要：惡劣天氣條件，例如雪、雨、夜間和霧，對自動駕駛感知系統構成挑戰。現有方法在改善必要的電腦視覺任務（例如語義分割）方面的效果有限，而且通常只專注於一個特定條件，例如去除雨水或將夜間影像轉換為日間影像。為了解決這些限制，我們提出了一種方法來改善因這些惡劣條件而降低的視覺品質和清晰度。我們的 AllWeather-Net 方法採用一種新穎的分層架構來增強所有惡劣條件下的影像。此架構透過區分每個層級的區塊，來整合場景、物件和紋理這三個語義層級的資訊。此外，我們引入了一個縮放照明感知注意力機制 (SIAM)，它引導學習朝向對自動駕駛感知至關重要的道路元素。SIAM 具有穩健性，不受天氣條件或環境場景變化的影響。AllWeather-Net 有效地將影像轉換為正常天氣和日間場景，展現出優異的影像增強結果，並進一步增強語義分割的效能，在訓練領域中 mIoU 改善幅度高達 5.3%。我們還透過將模型應用於未見過的領域，而無需重新訓練，來展示模型的泛化能力，達到了 3.9% 的 mIoU 改善幅度。程式碼可於以下網址取得：https://github.com/Jumponthemoon/AllWeatherNet。

##### **BEAVER: An Enterprise Benchmark for Text-to-SQL**
2409.02038v1 by Peter Baile Chen, Fabian Wenz, Yi Zhang, Moe Kayali, Nesime Tatbul, Michael Cafarella, Çağatay Demiralp, Michael Stonebraker

Existing text-to-SQL benchmarks have largely been constructed using publicly
available tables from the web with human-generated tests containing question
and SQL statement pairs. They typically show very good results and lead people
to think that LLMs are effective at text-to-SQL tasks. In this paper, we apply
off-the-shelf LLMs to a benchmark containing enterprise data warehouse data. In
this environment, LLMs perform poorly, even when standard prompt engineering
and RAG techniques are utilized. As we will show, the reasons for poor
performance are largely due to three characteristics: (1) public LLMs cannot
train on enterprise data warehouses because they are largely in the "dark web",
(2) schemas of enterprise tables are more complex than the schemas in public
data, which leads the SQL-generation task innately harder, and (3)
business-oriented questions are often more complex, requiring joins over
multiple tables and aggregations. As a result, we propose a new dataset BEAVER,
sourced from real enterprise data warehouses together with natural language
queries and their correct SQL statements which we collected from actual user
history. We evaluated this dataset using recent LLMs and demonstrated their
poor performance on this task. We hope this dataset will facilitate future
researchers building more sophisticated text-to-SQL systems which can do better
on this important class of data.

摘要：現有的文字轉 SQL 評量基準在很大程度上是使用網路上公開的表格建構，其中包含人類產生的測試，包含問題和 SQL 語句配對。它們通常顯示非常好的結果，並讓人們認為 LLM 在文字轉 SQL 任務中很有效。在本文中，我們將現成的 LLM 應用於包含企業資料倉儲資料的評量基準。在此環境中，即使使用了標準提示工程和 RAG 技術，LLM 的表現也很差。正如我們將展示的，表現不佳的原因在很大程度上是基於三個特徵：(1) 公共 LLM 無法訓練企業資料倉儲，因為它們在很大程度上屬於「暗網」，(2) 企業表格的架構比公共資料中的架構更複雜，這使得 SQL 生成任務天生就更困難，以及 (3) 面向業務的問題通常更複雜，需要跨多個表格和聚合進行聯結。因此，我們提出一個新的資料集 BEAVER，它來自實際的企業資料倉儲，以及我們從實際使用者記錄中收集的自然語言查詢及其正確的 SQL 語句。我們使用最近的 LLM 評估此資料集，並證明它們在此任務上的表現不佳。我們希望這個資料集將有助於未來的研究人員建構更精密的文字轉 SQL 系統，以便在這個重要的資料類別上表現得更好。

##### **Foundations of Large Language Model Compression -- Part 1: Weight Quantization**
2409.02026v1 by Sean I. Young

In recent years, compression of large language models (LLMs) has emerged as
an important problem to allow language model deployment on resource-constrained
devices, reduce computational costs, and mitigate the environmental footprint
of large-scale AI infrastructure. In this paper, we present the foundations of
LLM quantization from a convex optimization perspective and propose a
quantization method that builds on these foundations and outperforms previous
methods. Our quantization framework, CVXQ, scales to models containing hundreds
of billions of weight parameters and provides users with the flexibility to
compress models to any specified model size, post-training. A reference
implementation of CVXQ can be obtained from https://github.com/seannz/cvxq.

摘要：近年来，大语言模型（LLM）的压缩已成为一项重要课题，可让语言模型部署在资源受限的装置上，降低运算成本，并减轻大规模 AI 基础设施对环境造成的影响。本文从凸优化角度介绍 LLM 量化的基础，并提出一种建立在这些基础上的量化方法，其效能优于以往的方法。我们的量化框架 CVXQ 可扩展到包含数百亿个权重参数的模型，并提供使用者弹性，可在训练后将模型压缩至任何指定大小。CVXQ 的参考实作可从 https://github.com/seannz/cvxq 取得。

##### **TransDAE: Dual Attention Mechanism in a Hierarchical Transformer for Efficient Medical Image Segmentation**
2409.02018v1 by Bobby Azad, Pourya Adibfar, Kaiqun Fu

In healthcare, medical image segmentation is crucial for accurate disease
diagnosis and the development of effective treatment strategies. Early
detection can significantly aid in managing diseases and potentially prevent
their progression. Machine learning, particularly deep convolutional neural
networks, has emerged as a promising approach to addressing segmentation
challenges. Traditional methods like U-Net use encoding blocks for local
representation modeling and decoding blocks to uncover semantic relationships.
However, these models often struggle with multi-scale objects exhibiting
significant variations in texture and shape, and they frequently fail to
capture long-range dependencies in the input data. Transformers designed for
sequence-to-sequence predictions have been proposed as alternatives, utilizing
global self-attention mechanisms. Yet, they can sometimes lack precise
localization due to insufficient granular details. To overcome these
limitations, we introduce TransDAE: a novel approach that reimagines the
self-attention mechanism to include both spatial and channel-wise associations
across the entire feature space, while maintaining computational efficiency.
Additionally, TransDAE enhances the skip connection pathway with an inter-scale
interaction module, promoting feature reuse and improving localization
accuracy. Remarkably, TransDAE outperforms existing state-of-the-art methods on
the Synaps multi-organ dataset, even without relying on pre-trained weights.

摘要：在医疗保健领域，医学影像分割对于准确的疾病诊断和有效治疗策略的开发至关重要。早期检测可以极大地帮助控制疾病，并可能防止疾病进展。机器学习，尤其是深度卷积神经网络，已成为解决分割挑战的一种有前途的方法。U-Net 等传统方法使用编码块进行局部表示建模和解码块来揭示语义关系。然而，这些模型通常难以处理在纹理和形状上表现出显着变化的多尺度对象，并且它们经常无法捕获输入数据中的远程依赖关系。专为序列到序列预测而设计的 Transformer 已被提出作为替代方案，利用全局自注意力机制。然而，由于粒度细节不足，它们有时可能缺乏精确的定位。为了克服这些限制，我们引入了 TransDAE：一种新颖的方法，它重新构想了自注意力机制，以包含整个特征空间中的空间和通道关联，同时保持计算效率。此外，TransDAE 通过尺度间交互模块增强了跳跃连接路径，促进了特征重用并提高了定位精度。值得注意的是，即使不依赖预训练权重，TransDAE 在 Synaps 多器官数据集上也优于现有的最先进方法。

##### **vec2wav 2.0: Advancing Voice Conversion via Discrete Token Vocoders**
2409.01995v1 by Yiwei Guo, Zhihan Li, Junjie Li, Chenpeng Du, Hankun Wang, Shuai Wang, Xie Chen, Kai Yu

We propose a new speech discrete token vocoder, vec2wav 2.0, which advances
voice conversion (VC). We use discrete tokens from speech self-supervised
models as the content features of source speech, and treat VC as a prompted
vocoding task. To amend the loss of speaker timbre in the content tokens,
vec2wav 2.0 utilizes the WavLM features to provide strong timbre-dependent
information. A novel adaptive Snake activation function is proposed to better
incorporate timbre into the waveform reconstruction process. In this way,
vec2wav 2.0 learns to alter the speaker timbre appropriately given different
reference prompts. Also, no supervised data is required for vec2wav 2.0 to be
effectively trained. Experimental results demonstrate that vec2wav 2.0
outperforms all other baselines to a considerable margin in terms of audio
quality and speaker similarity in any-to-any VC. Ablation studies verify the
effects made by the proposed techniques. Moreover, vec2wav 2.0 achieves
competitive cross-lingual VC even only trained on monolingual corpus. Thus,
vec2wav 2.0 shows timbre can potentially be manipulated only by speech token
vocoders, pushing the frontiers of VC and speech synthesis.

摘要：我們提出一個新的語音離散符號聲碼器，vec2wav 2.0，它推動了語音轉換 (VC)。我們使用來自語音自監督模型的離散符號作為原始語音的內容特徵，並將 VC 視為一個提示式聲碼任務。為了修正內容符號中說話者音色的損失，vec2wav 2.0 利用 WavLM 特徵來提供強大的音色依賴性資訊。提出了一個新穎的自適應 Snake 激活函數，以更好地將音色納入波形重建過程中。這樣一來，vec2wav 2.0 學習在給定不同的參考提示時適當地改變說話者音色。此外，vec2wav 2.0 不需要監督資料就能有效地進行訓練。實驗結果表明，vec2wav 2.0 在任何到任何 VC 的音訊品質和說話者相似度方面都以相當大的幅度優於所有其他基準。消融研究驗證了所提出的技術所產生的效果。此外，vec2wav 2.0 甚至只在單語料庫上訓練，也能實現有競爭力的跨語言 VC。因此，vec2wav 2.0 顯示音色有可能僅通過語音符號聲碼器來操縱，從而推動 VC 和語音合成的前沿。

##### **Planning to avoid ambiguous states through Gaussian approximations to non-linear sensors in active inference agents**
2409.01974v1 by Wouter M. Kouw

In nature, active inference agents must learn how observations of the world
represent the state of the agent. In engineering, the physics behind sensors is
often known reasonably accurately and measurement functions can be incorporated
into generative models. When a measurement function is non-linear, the
transformed variable is typically approximated with a Gaussian distribution to
ensure tractable inference. We show that Gaussian approximations that are
sensitive to the curvature of the measurement function, such as a second-order
Taylor approximation, produce a state-dependent ambiguity term. This induces a
preference over states, based on how accurately the state can be inferred from
the observation. We demonstrate this preference with a robot navigation
experiment where agents plan trajectories.

摘要：在自然界中，主动推理代理必须学习世界观察如何表示代理的状态。在工程学中，传感器的物理原理通常已知得相当准确，测量功能可以整合到生成模型中。当测量函数是非线性的时，通常用高斯分布近似变换变量，以确保推理的可行性。我们表明，对测量函数曲率敏感的高斯近似，例如二阶泰勒近似，会产生一个状态相关的模糊项。这会根据可以从观察中推断出状态的准确程度，导致对状态的偏好。我们通过机器人导航实验演示了这种偏好，其中代理计划轨迹。

