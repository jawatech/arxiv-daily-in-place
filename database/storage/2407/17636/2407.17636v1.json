{"2407.17636": {"publish_time": "2024-07-24", "title": "IgnitionInnovators at \"Discharge Me!\": Chain-of-Thought Instruction Finetuning Large Language Models for Discharge Summaries", "paper_summary": "This paper presents our proposed approach to the Discharge Me! shared task,\ncollocated with the 23th Workshop on Biomedical Natural Language Processing\n(BioNLP). In this work, we develop an LLM-based framework for solving the\nDischarge Summary Documentation (DSD) task, i.e., generating the two critical\ntarget sections `Brief Hospital Course' and `Discharge Instructions' in the\ndischarge summary. By streamlining the recent instruction-finetuning process on\nLLMs, we explore several prompting strategies for optimally adapting LLMs to\nspecific generation task of DSD. Experimental results show that providing a\nclear output structure, complimented by a set of comprehensive\nChain-of-Thoughts (CoT) questions, effectively improves the model's reasoning\ncapability, and thereby, enhancing the structural correctness and faithfulness\nof clinical information in the generated text. Source code is available at:\nhttps://github.com/antangrocket1312/Discharge_LLM", "paper_summary_zh": "\u672c\u6587\u4ecb\u7d39\u6211\u5011\u63d0\u51fa\u7684\u300cDischarge Me\uff01\u300d\u5171\u4eab\u4efb\u52d9\u65b9\u6cd5\uff0c\u8207\u7b2c 23 \u5c46\u751f\u7269\u91ab\u5b78\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u5de5\u4f5c\u574a (BioNLP) \u4e26\u5217\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u57fa\u65bc LLM \u7684\u67b6\u69cb\uff0c\u7528\u65bc\u89e3\u6c7a\u51fa\u9662\u6458\u8981\u6587\u4ef6 (DSD) \u4efb\u52d9\uff0c\u4e5f\u5c31\u662f\u7522\u751f\u51fa\u9662\u6458\u8981\u4e2d\u5169\u500b\u91cd\u8981\u7684\u76ee\u6a19\u90e8\u5206\u300c\u7c21\u8981\u4f4f\u9662\u75c5\u7a0b\u300d\u548c\u300c\u51fa\u9662\u6307\u793a\u300d\u3002\u900f\u904e\u7c21\u5316 LLM \u4e0a\u6700\u8fd1\u7684\u6307\u4ee4\u5fae\u8abf\u6d41\u7a0b\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u591a\u7a2e\u63d0\u793a\u7b56\u7565\uff0c\u4ee5\u6700\u4f73\u5316\u8abf\u6574 LLM \u4f86\u57f7\u884c DSD \u7684\u7279\u5b9a\u751f\u6210\u4efb\u52d9\u3002\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0c\u63d0\u4f9b\u660e\u78ba\u7684\u8f38\u51fa\u7d50\u69cb\uff0c\u4e26\u642d\u914d\u4e00\u7d44\u5168\u9762\u7684\u601d\u8003\u93c8 (CoT) \u554f\u984c\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u63d0\u5347\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u9032\u800c\u589e\u5f37\u6240\u751f\u6210\u6587\u5b57\u4e2d\u81e8\u5e8a\u8cc7\u8a0a\u7684\u7d50\u69cb\u6b63\u78ba\u6027\u548c\u771f\u5be6\u6027\u3002\u539f\u59cb\u78bc\u53ef\u5728\u4ee5\u4e0b\u7db2\u5740\u53d6\u5f97\uff1ahttps://github.com/antangrocket1312/Discharge_LLM", "author": "An Quang Tang et.al.", "authors": "An Quang Tang, Xiuzhen Zhang, Minh Ngoc Dinh", "id": "2407.17636v1", "paper_url": "http://arxiv.org/abs/2407.17636v1", "repo": "https://github.com/antangrocket1312/discharge_llm"}}