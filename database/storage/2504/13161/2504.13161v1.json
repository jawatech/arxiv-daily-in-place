{"2504.13161": {"publish_time": "2025-04-17", "title": "CLIMB: CLustering-based Iterative Data Mixture Bootstrapping for Language Model Pre-training", "paper_summary": "Pre-training datasets are typically collected from web content and lack\ninherent domain divisions. For instance, widely used datasets like Common Crawl\ndo not include explicit domain labels, while manually curating labeled datasets\nsuch as The Pile is labor-intensive. Consequently, identifying an optimal\npre-training data mixture remains a challenging problem, despite its\nsignificant benefits for pre-training performance. To address these challenges,\nwe propose CLustering-based Iterative Data Mixture Bootstrapping (CLIMB), an\nautomated framework that discovers, evaluates, and refines data mixtures in a\npre-training setting. Specifically, CLIMB embeds and clusters large-scale\ndatasets in a semantic space and then iteratively searches for optimal mixtures\nusing a smaller proxy model and a predictor. When continuously trained on 400B\ntokens with this mixture, our 1B model exceeds the state-of-the-art\nLlama-3.2-1B by 2.0%. Moreover, we observe that optimizing for a specific\ndomain (e.g., Social Sciences) yields a 5% improvement over random sampling.\nFinally, we introduce ClimbLab, a filtered 1.2-trillion-token corpus with 20\nclusters as a research playground, and ClimbMix, a compact yet powerful\n400-billion-token dataset designed for efficient pre-training that delivers\nsuperior performance under an equal token budget. We analyze the final data\nmixture, elucidating the characteristics of an optimal data mixture. Our data\nis available at: https://research.nvidia.com/labs/lpr/climb/", "paper_summary_zh": "\u9810\u8a13\u7df4\u8cc7\u6599\u96c6\u901a\u5e38\u662f\u5f9e\u7db2\u8def\u5167\u5bb9\u4e2d\u6536\u96c6\u800c\u4f86\u7684\uff0c\u7f3a\u4e4f\u56fa\u6709\u7684\u9818\u57df\u5283\u5206\u3002\u4f8b\u5982\uff0c\u5ee3\u6cdb\u4f7f\u7528\u7684\u8cc7\u6599\u96c6\uff0c\u50cf\u662f Common Crawl\u5c31\u6c92\u6709\u660e\u78ba\u7684\u9818\u57df\u6a19\u7c64\uff0c\u800c\u624b\u52d5\u6574\u7406\u5e36\u6a19\u7c64\u7684\u8cc7\u6599\u96c6\uff08\u4f8b\u5982 The Pile\uff09\u5247\u76f8\u7576\u8017\u8cbb\u4eba\u529b\u3002\u56e0\u6b64\uff0c\u5118\u7ba1\u5c0d\u9810\u8a13\u7df4\u6548\u80fd\u6709\u986f\u8457\u7684\u76ca\u8655\uff0c\u4f46\u8981\u627e\u51fa\u6700\u4f73\u7684\u9810\u8a13\u7df4\u8cc7\u6599\u7d44\u5408\u4ecd\u7136\u662f\u4e00\u9805\u6311\u6230\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u57fa\u65bc\u5206\u7fa4\u7684\u8fed\u4ee3\u5f0f\u8cc7\u6599\u7d44\u5408\u5f15\u5c0e\u6cd5\uff08CLIMB\uff09\uff0c\u9019\u662f\u4e00\u500b\u5728\u9810\u8a13\u7df4\u74b0\u5883\u4e2d\u63a2\u7d22\u3001\u8a55\u4f30\u548c\u7cbe\u7149\u8cc7\u6599\u7d44\u5408\u7684\u81ea\u52d5\u5316\u6846\u67b6\u3002\u5177\u9ad4\u4f86\u8aaa\uff0cCLIMB \u6703\u5c07\u5927\u898f\u6a21\u8cc7\u6599\u96c6\u5d4c\u5165\u5230\u8a9e\u7fa9\u7a7a\u9593\u4e2d\u4e26\u9032\u884c\u5206\u7fa4\uff0c\u7136\u5f8c\u4f7f\u7528\u8f03\u5c0f\u7684\u4ee3\u7406\u6a21\u578b\u548c\u9810\u6e2c\u5668\u8fed\u4ee3\u641c\u5c0b\u6700\u4f73\u7d44\u5408\u3002\u7576\u4f7f\u7528\u6b64\u7d44\u5408\u9023\u7e8c\u8a13\u7df4 400B \u500b token \u6642\uff0c\u6211\u5011\u7684 1B \u6a21\u578b\u7684\u6548\u80fd\u8d85\u8d8a\u4e86\u6700\u5148\u9032\u7684Llama-3.2-1B \u6a21\u578b 2.0%\u3002\u6b64\u5916\uff0c\u6211\u5011\u89c0\u5bdf\u5230\u91dd\u5c0d\u7279\u5b9a\u9818\u57df\uff08\u4f8b\u5982\u793e\u6703\u79d1\u5b78\uff09\u9032\u884c\u512a\u5316\uff0c\u76f8\u6bd4\u96a8\u6a5f\u53d6\u6a23\uff0c\u6548\u80fd\u63d0\u5347\u4e86 5%\u3002\u6700\u5f8c\uff0c\u6211\u5011\u63a8\u51fa\u4e86 ClimbLab\uff0c\u4e00\u500b\u7d93\u904e\u7be9\u9078\u7684 1.2 \u5146 token \u7684\u8a9e\u6599\u5eab\uff0c\u5305\u542b 20 \u500b\u53e2\u96c6\uff0c\u4f5c\u70ba\u7814\u7a76\u7684\u5e73\u53f0\uff1b\u4ee5\u53ca ClimbMix\uff0c\u4e00\u500b\u7cbe\u7c21\u4f46\u529f\u80fd\u5f37\u5927\u76844000 \u5104 token \u7684\u8cc7\u6599\u96c6\uff0c\u5c08\u70ba\u9ad8\u6548\u9810\u8a13\u7df4\u800c\u8a2d\u8a08\uff0c\u5728\u76f8\u540c\u7684 token \u9810\u7b97\u4e0b\u53ef\u63d0\u4f9b\u5353\u8d8a\u7684\u6548\u80fd\u3002\u6211\u5011\u5206\u6790\u4e86\u6700\u7d42\u7684\u8cc7\u6599\u7d44\u5408\uff0c\u95e1\u660e\u4e86\u6700\u4f73\u8cc7\u6599\u7d44\u5408\u7684\u7279\u5fb5\u3002\u6211\u5011\u7684\u8cc7\u6599\u53ef\u5728\u4ee5\u4e0b\u7db2\u5740\u53d6\u5f97\uff1ahttps://research.nvidia.com/labs/lpr/climb/\n", "author": "Shizhe Diao et.al.", "authors": "Shizhe Diao, Yu Yang, Yonggan Fu, Xin Dong, Dan Su, Markus Kliegl, Zijia Chen, Peter Belcak, Yoshi Suhara, Hongxu Yin, Mostofa Patwary, Yingyan, Lin, Jan Kautz, Pavlo Molchanov", "id": "2504.13161v1", "paper_url": "http://arxiv.org/abs/2504.13161v1", "repo": "null"}}