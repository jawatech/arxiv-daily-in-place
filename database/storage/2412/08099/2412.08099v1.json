{"2412.08099": {"publish_time": "2024-12-11", "title": "Adversarial Vulnerabilities in Large Language Models for Time Series Forecasting", "paper_summary": "Large Language Models (LLMs) have recently demonstrated significant potential\nin the field of time series forecasting, offering impressive capabilities in\nhandling complex temporal data. However, their robustness and reliability in\nreal-world applications remain under-explored, particularly concerning their\nsusceptibility to adversarial attacks. In this paper, we introduce a targeted\nadversarial attack framework for LLM-based time series forecasting. By\nemploying both gradient-free and black-box optimization methods, we generate\nminimal yet highly effective perturbations that significantly degrade the\nforecasting accuracy across multiple datasets and LLM architectures. Our\nexperiments, which include models like TimeGPT and LLM-Time with GPT-3.5,\nGPT-4, LLaMa, and Mistral, show that adversarial attacks lead to much more\nsevere performance degradation than random noise, and demonstrate the broad\neffectiveness of our attacks across different LLMs. The results underscore the\ncritical vulnerabilities of LLMs in time series forecasting, highlighting the\nneed for robust defense mechanisms to ensure their reliable deployment in\npractical applications.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8fd1\u671f\u5728\u6642\u9593\u5e8f\u5217\u9810\u6e2c\u9818\u57df\u5c55\u793a\u4e86\u986f\u8457\u7684\u6f5b\u529b\uff0c\u5728\u8655\u7406\u8907\u96dc\u6642\u9593\u6578\u64da\u65b9\u9762\u5c55\u73fe\u4e86\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u80fd\u529b\u3002\u7136\u800c\uff0c\u5b83\u5011\u5728\u5be6\u969b\u61c9\u7528\u4e2d\u7684\u7a69\u5065\u6027\u548c\u53ef\u9760\u6027\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u8a0e\uff0c\u7279\u5225\u662f\u95dc\u65bc\u5b83\u5011\u5c0d\u5c0d\u6297\u6027\u653b\u64ca\u7684\u654f\u611f\u6027\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u91dd\u5c0d LLM \u6642\u9593\u5e8f\u5217\u9810\u6e2c\u7684\u76ee\u6a19\u5c0d\u6297\u6027\u653b\u64ca\u6846\u67b6\u3002\u901a\u904e\u63a1\u7528\u7121\u68af\u5ea6\u548c\u9ed1\u76d2\u512a\u5316\u65b9\u6cd5\uff0c\u6211\u5011\u751f\u6210\u4e86\u6975\u5c0f\u4f46\u9ad8\u6548\u7387\u7684\u64fe\u52d5\uff0c\u9019\u4e9b\u64fe\u52d5\u6703\u986f\u8457\u964d\u4f4e\u591a\u500b\u8cc7\u6599\u96c6\u548c LLM \u67b6\u69cb\u7684\u9810\u6e2c\u6e96\u78ba\u5ea6\u3002\u6211\u5011\u7684\u5be6\u9a57\u5305\u62ec TimeGPT \u548c LLM-Time \u7b49\u6a21\u578b\uff0c\u4ee5\u53ca GPT-3.5\u3001GPT-4\u3001LLaMa \u548c Mistral\uff0c\u7d50\u679c\u986f\u793a\u5c0d\u6297\u6027\u653b\u64ca\u5c0e\u81f4\u7684\u6548\u80fd\u4e0b\u964d\u9060\u6bd4\u96a8\u6a5f\u96dc\u8a0a\u56b4\u91cd\uff0c\u4e26\u8b49\u660e\u4e86\u6211\u5011\u7684\u653b\u64ca\u5728\u4e0d\u540c LLM \u4e2d\u7684\u5ee3\u6cdb\u6709\u6548\u6027\u3002\u9019\u4e9b\u7d50\u679c\u5f37\u8abf\u4e86 LLM \u5728\u6642\u9593\u5e8f\u5217\u9810\u6e2c\u4e2d\u7684\u95dc\u9375\u6f0f\u6d1e\uff0c\u7a81\u986f\u4e86\u5728\u5be6\u969b\u61c9\u7528\u4e2d\u78ba\u4fdd\u5b83\u5011\u53ef\u9760\u90e8\u7f72\u7684\u5fc5\u8981\u6027\u3002", "author": "Fuqiang Liu et.al.", "authors": "Fuqiang Liu, Sicong Jiang, Luis Miranda-Moreno, Seongjin Choi, Lijun Sun", "id": "2412.08099v1", "paper_url": "http://arxiv.org/abs/2412.08099v1", "repo": "null"}}