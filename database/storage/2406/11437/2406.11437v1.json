{"2406.11437": {"publish_time": "2024-06-17", "title": "Analysing the Behaviour of Tree-Based Neural Networks in Regression Tasks", "paper_summary": "The landscape of deep learning has vastly expanded the frontiers of source\ncode analysis, particularly through the utilization of structural\nrepresentations such as Abstract Syntax Trees (ASTs). While these methodologies\nhave demonstrated effectiveness in classification tasks, their efficacy in\nregression applications, such as execution time prediction from source code,\nremains underexplored. This paper endeavours to decode the behaviour of\ntree-based neural network models in the context of such regression challenges.\nWe extend the application of established models--tree-based Convolutional\nNeural Networks (CNNs), Code2Vec, and Transformer-based methods--to predict the\nexecution time of source code by parsing it to an AST. Our comparative analysis\nreveals that while these models are benchmarks in code representation, they\nexhibit limitations when tasked with regression. To address these deficiencies,\nwe propose a novel dual-transformer approach that operates on both source code\ntokens and AST representations, employing cross-attention mechanisms to enhance\ninterpretability between the two domains. Furthermore, we explore the\nadaptation of Graph Neural Networks (GNNs) to this tree-based problem,\ntheorizing the inherent compatibility due to the graphical nature of ASTs.\nEmpirical evaluations on real-world datasets showcase that our dual-transformer\nmodel outperforms all other tree-based neural networks and the GNN-based\nmodels. Moreover, our proposed dual transformer demonstrates remarkable\nadaptability and robust performance across diverse datasets.", "paper_summary_zh": "\u6df1\u5ea6\u5b78\u7fd2\u7684\u9818\u57df\u5df2\u7d93\u5927\u5e45\u64f4\u5c55\u4e86\u539f\u59cb\u78bc\u5206\u6790\u7684\u7586\u754c\uff0c\u7279\u5225\u662f\u900f\u904e\u4f7f\u7528\u7d50\u69cb\u5316\u8868\u793a\u6cd5\uff0c\u4f8b\u5982\u62bd\u8c61\u8a9e\u6cd5\u6a39 (AST)\u3002\u5118\u7ba1\u9019\u4e9b\u65b9\u6cd5\u5df2\u8b49\u660e\u5728\u5206\u985e\u4efb\u52d9\u4e2d\u6709\u6548\uff0c\u4f46\u5b83\u5011\u5728\u56de\u6b78\u61c9\u7528\u4e2d\u7684\u6548\u80fd\uff0c\u4f8b\u5982\u5f9e\u539f\u59cb\u78bc\u4e2d\u9810\u6e2c\u57f7\u884c\u6642\u9593\uff0c\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u8a0e\u3002\u672c\u6587\u8a66\u5716\u89e3\u78bc\u6a39\u72c0\u795e\u7d93\u7db2\u8def\u6a21\u578b\u5728\u9019\u7a2e\u56de\u6b78\u6311\u6230\u4e2d\u7684\u884c\u70ba\u3002\u6211\u5011\u64f4\u5c55\u4e86\u65e2\u5b9a\u6a21\u578b\u7684\u61c9\u7528\u2014\u2014\u57fa\u65bc\u6a39\u72c0\u7684\u5377\u7a4d\u795e\u7d93\u7db2\u8def (CNN)\u3001Code2Vec \u548c\u57fa\u65bc Transformer \u7684\u65b9\u6cd5\u2014\u2014\u900f\u904e\u5c07\u539f\u59cb\u78bc\u89e3\u6790\u6210 AST \u4f86\u9810\u6e2c\u5176\u57f7\u884c\u6642\u9593\u3002\u6211\u5011\u7684\u6bd4\u8f03\u5206\u6790\u986f\u793a\uff0c\u5118\u7ba1\u9019\u4e9b\u6a21\u578b\u662f\u7a0b\u5f0f\u78bc\u8868\u793a\u6cd5\u7684\u57fa\u6e96\uff0c\u4f46\u5b83\u5011\u5728\u57f7\u884c\u56de\u6b78\u4efb\u52d9\u6642\u8868\u73fe\u51fa\u9650\u5236\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u7f3a\u9677\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u96d9 Transformer \u65b9\u6cd5\uff0c\u5b83\u540c\u6642\u4f5c\u7528\u65bc\u539f\u59cb\u78bc\u4ee3\u78bc\u548c AST \u8868\u793a\u6cd5\uff0c\u4e26\u63a1\u7528\u8de8\u6ce8\u610f\u529b\u6a5f\u5236\u4f86\u589e\u5f37\u5169\u500b\u9818\u57df\u4e4b\u9593\u7684\u53ef\u89e3\u91cb\u6027\u3002\u6b64\u5916\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u5c07\u5716\u795e\u7d93\u7db2\u8def (GNN) \u9069\u61c9\u5230\u9019\u500b\u57fa\u65bc\u6a39\u72c0\u7684\u554f\u984c\uff0c\u4e26\u6839\u64da AST \u7684\u5716\u5f62\u6027\u8cea\uff0c\u7406\u8ad6\u5316\u5176\u5167\u5728\u76f8\u5bb9\u6027\u3002\u5728\u771f\u5be6\u4e16\u754c\u8cc7\u6599\u96c6\u4e0a\u7684\u5be6\u8b49\u8a55\u4f30\u986f\u793a\uff0c\u6211\u5011\u7684\u96d9 Transformer \u6a21\u578b\u512a\u65bc\u6240\u6709\u5176\u4ed6\u57fa\u65bc\u6a39\u72c0\u7684\u795e\u7d93\u7db2\u8def\u548c\u57fa\u65bc GNN \u7684\u6a21\u578b\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u7684\u96d9 Transformer \u5728\u4e0d\u540c\u7684\u8cc7\u6599\u96c6\u4e0a\u5c55\u73fe\u51fa\u986f\u8457\u7684\u9069\u61c9\u6027\u548c\u7a69\u5065\u7684\u6548\u80fd\u3002", "author": "Peter Samoaa et.al.", "authors": "Peter Samoaa, Mehrdad Farahani, Antonio Longa, Philipp Leitner, Morteza Haghir Chehreghani", "id": "2406.11437v1", "paper_url": "http://arxiv.org/abs/2406.11437v1", "repo": "https://github.com/petersamoaa/tree_based_nn_error_analysis"}}