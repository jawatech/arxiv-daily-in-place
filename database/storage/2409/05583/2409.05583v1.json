{"2409.05583": {"publish_time": "2024-09-09", "title": "Spatially-Aware Speaker for Vision-and-Language Navigation Instruction Generation", "paper_summary": "Embodied AI aims to develop robots that can \\textit{understand} and execute\nhuman language instructions, as well as communicate in natural languages. On\nthis front, we study the task of generating highly detailed navigational\ninstructions for the embodied robots to follow. Although recent studies have\ndemonstrated significant leaps in the generation of step-by-step instructions\nfrom sequences of images, the generated instructions lack variety in terms of\ntheir referral to objects and landmarks. Existing speaker models learn\nstrategies to evade the evaluation metrics and obtain higher scores even for\nlow-quality sentences. In this work, we propose SAS (Spatially-Aware Speaker),\nan instruction generator or \\textit{Speaker} model that utilises both\nstructural and semantic knowledge of the environment to produce richer\ninstructions. For training, we employ a reward learning method in an\nadversarial setting to avoid systematic bias introduced by language evaluation\nmetrics. Empirically, our method outperforms existing instruction generation\nmodels, evaluated using standard metrics. Our code is available at\n\\url{https://github.com/gmuraleekrishna/SAS}.", "paper_summary_zh": "\u5177\u8eab AI \u65e8\u5728\u5f00\u53d1\u80fd\u591f\u7406\u89e3\u548c\u6267\u884c\u4eba\u7c7b\u8bed\u8a00\u6307\u4ee4\uff0c\u4ee5\u53ca\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u8fdb\u884c\u4ea4\u6d41\u7684\u673a\u5668\u4eba\u3002\u5728\u8fd9\u4e00\u65b9\u9762\uff0c\u6211\u4eec\u7814\u7a76\u4e86\u4e3a\u5177\u8eab\u673a\u5668\u4eba\u751f\u6210\u9ad8\u5ea6\u8be6\u7ec6\u7684\u5bfc\u822a\u6307\u4ee4\u7684\u4efb\u52a1\u3002\u5c3d\u7ba1\u6700\u8fd1\u7684\u7814\u7a76\u8868\u660e\uff0c\u4ece\u4e00\u7cfb\u5217\u56fe\u50cf\u751f\u6210\u5206\u6b65\u6307\u4ee4\u65b9\u9762\u53d6\u5f97\u4e86\u91cd\u5927\u8fdb\u5c55\uff0c\u4f46\u751f\u6210\u7684\u6307\u4ee4\u5728\u5bf9\u7269\u4f53\u548c\u5730\u6807\u7684\u5f15\u7528\u65b9\u9762\u7f3a\u4e4f\u591a\u6837\u6027\u3002\u73b0\u6709\u7684\u8bf4\u8bdd\u8005\u6a21\u578b\u5b66\u4e60\u7b56\u7565\u6765\u89c4\u907f\u8bc4\u4f30\u6307\u6807\uff0c\u5373\u4f7f\u5bf9\u4e8e\u4f4e\u8d28\u91cf\u7684\u53e5\u5b50\u4e5f\u80fd\u83b7\u5f97\u66f4\u9ad8\u7684\u5206\u6570\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 SAS\uff08\u7a7a\u95f4\u611f\u77e5\u8bf4\u8bdd\u8005\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u6307\u4ee4\u751f\u6210\u5668\u6216\u8bf4\u8bdd\u8005\u6a21\u578b\uff0c\u5b83\u5229\u7528\u73af\u5883\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u77e5\u8bc6\u6765\u751f\u6210\u66f4\u4e30\u5bcc\u7684\u6307\u4ee4\u3002\u5bf9\u4e8e\u8bad\u7ec3\uff0c\u6211\u4eec\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u91c7\u7528\u5956\u52b1\u5b66\u4e60\u65b9\u6cd5\uff0c\u4ee5\u907f\u514d\u8bed\u8a00\u8bc4\u4f30\u6307\u6807\u5f15\u5165\u7684\u7cfb\u7edf\u504f\u5dee\u3002\u6839\u636e\u7ecf\u9a8c\u8bc1\u636e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u7684\u6307\u4ee4\u751f\u6210\u6a21\u578b\uff0c\u4f7f\u7528\u6807\u51c6\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\u3002\u6211\u4eec\u7684\u4ee3\u7801\u53ef\u5728 \\url{https://github.com/gmuraleekrishna/SAS} \u83b7\u5f97\u3002", "author": "Muraleekrishna Gopinathan et.al.", "authors": "Muraleekrishna Gopinathan, Martin Masek, Jumana Abu-Khalaf, David Suter", "id": "2409.05583v1", "paper_url": "http://arxiv.org/abs/2409.05583v1", "repo": "https://github.com/gmuraleekrishna/sas"}}