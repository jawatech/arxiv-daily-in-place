{"2501.05662": {"publish_time": "2025-01-10", "title": "Cascaded Self-Evaluation Augmented Training for Efficient Multimodal Large Language Models", "paper_summary": "Efficient Multimodal Large Language Models (EMLLMs) have rapidly advanced\nrecently. Incorporating Chain-of-Thought (CoT) reasoning and step-by-step\nself-evaluation has improved their performance. However, limited parameters\noften hinder EMLLMs from effectively using self-evaluation during inference.\nKey challenges include synthesizing evaluation data, determining its quantity,\noptimizing training and inference strategies, and selecting appropriate\nprompts.\n  To address these issues, we introduce Self-Evaluation Augmented Training\n(SEAT). SEAT uses more powerful EMLLMs for CoT reasoning, data selection, and\nevaluation generation, then trains EMLLMs with the synthesized data. However,\nhandling long prompts and maintaining CoT reasoning quality are problematic.\nTherefore, we propose Cascaded Self-Evaluation Augmented Training (Cas-SEAT),\nwhich breaks down lengthy prompts into shorter, task-specific cascaded prompts\nand reduces costs for resource-limited settings. During data synthesis, we\nemploy open-source 7B-parameter EMLLMs and annotate a small dataset with short\nprompts.\n  Experiments demonstrate that Cas-SEAT significantly boosts EMLLMs'\nself-evaluation abilities, improving performance by 19.68%, 55.57%, and 46.79%\non the MathVista, Math-V, and We-Math datasets, respectively. Additionally, our\nCas-SEAT Dataset serves as a valuable resource for future research in enhancing\nEMLLM self-evaluation.", "paper_summary_zh": "<paragraph>\u9ad8\u6548\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b (EMLLM) \u8fd1\u671f\u5feb\u901f\u53d1\u5c55\u3002\u7eb3\u5165\u601d\u7ef4\u94fe (CoT) \u63a8\u7406\u548c\u9010\u6b65\u81ea\u6211\u8bc4\u4f30\u5df2\u6539\u5584\u5176\u6027\u80fd\u3002\u7136\u800c\uff0c\u6709\u9650\u7684\u53c2\u6570\u901a\u5e38\u4f1a\u963b\u788d EMLLM \u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u6709\u6548\u5730\u4f7f\u7528\u81ea\u6211\u8bc4\u4f30\u3002\u4e3b\u8981\u6311\u6218\u5305\u62ec\u7efc\u5408\u8bc4\u4f30\u6570\u636e\u3001\u786e\u5b9a\u5176\u6570\u91cf\u3001\u4f18\u5316\u8bad\u7ec3\u548c\u63a8\u7406\u7b56\u7565\u4ee5\u53ca\u9009\u62e9\u9002\u5f53\u7684\u63d0\u793a\u3002\n\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u81ea\u6211\u8bc4\u4f30\u589e\u5f3a\u8bad\u7ec3 (SEAT)\u3002SEAT \u4f7f\u7528\u66f4\u5f3a\u5927\u7684 EMLLM \u8fdb\u884c CoT \u63a8\u7406\u3001\u6570\u636e\u9009\u62e9\u548c\u8bc4\u4f30\u751f\u6210\uff0c\u7136\u540e\u4f7f\u7528\u7efc\u5408\u6570\u636e\u8bad\u7ec3 EMLLM\u3002\u7136\u800c\uff0c\u5904\u7406\u957f\u63d0\u793a\u548c\u7ef4\u6301 CoT \u63a8\u7406\u8d28\u91cf\u662f\u6709\u95ee\u9898\u7684\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u7ea7\u8054\u81ea\u6211\u8bc4\u4f30\u589e\u5f3a\u8bad\u7ec3 (Cas-SEAT)\uff0c\u5b83\u5c06\u5197\u957f\u7684\u63d0\u793a\u5206\u89e3\u4e3a\u66f4\u77ed\u3001\u7279\u5b9a\u4e8e\u4efb\u52a1\u7684\u7ea7\u8054\u63d0\u793a\uff0c\u5e76\u964d\u4f4e\u4e86\u5bf9\u8d44\u6e90\u6709\u9650\u7684\u8bbe\u7f6e\u7684\u6210\u672c\u3002\u5728\u6570\u636e\u7efc\u5408\u671f\u95f4\uff0c\u6211\u4eec\u91c7\u7528\u5f00\u6e90 7B \u53c2\u6570 EMLLM\uff0c\u5e76\u4f7f\u7528\u77ed\u63d0\u793a\u6ce8\u91ca\u4e00\u4e2a\u5c0f\u6570\u636e\u96c6\u3002\n\u5b9e\u9a8c\u8868\u660e\uff0cCas-SEAT \u663e\u7740\u63d0\u9ad8\u4e86 EMLLM \u7684\u81ea\u6211\u8bc4\u4f30\u80fd\u529b\uff0c\u5206\u522b\u5728 MathVista\u3001Math-V \u548c We-Math \u6570\u636e\u96c6\u4e0a\u5c06\u6027\u80fd\u63d0\u9ad8\u4e86 19.68%\u300155.57% \u548c 46.79%\u3002\u6b64\u5916\uff0c\u6211\u4eec\u7684 Cas-SEAT \u6570\u636e\u96c6\u53ef\u4f5c\u4e3a\u589e\u5f3a EMLLM \u81ea\u6211\u8bc4\u4f30\u7684\u672a\u6765\u7814\u7a76\u7684\u5b9d\u8d35\u8d44\u6e90\u3002</paragraph>", "author": "Zheqi Lv et.al.", "authors": "Zheqi Lv, Wenkai Wang, Jiawei Wang, Shengyu Zhang, Fei Wu", "id": "2501.05662v1", "paper_url": "http://arxiv.org/abs/2501.05662v1", "repo": "null"}}