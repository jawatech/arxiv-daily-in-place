{"2406.08050": {"publish_time": "2024-06-12", "title": "Adversarial Evasion Attack Efficiency against Large Language Models", "paper_summary": "Large Language Models (LLMs) are valuable for text classification, but their\nvulnerabilities must not be disregarded. They lack robustness against\nadversarial examples, so it is pertinent to understand the impacts of different\ntypes of perturbations, and assess if those attacks could be replicated by\ncommon users with a small amount of perturbations and a small number of queries\nto a deployed LLM. This work presents an analysis of the effectiveness,\nefficiency, and practicality of three different types of adversarial attacks\nagainst five different LLMs in a sentiment classification task. The obtained\nresults demonstrated the very distinct impacts of the word-level and\ncharacter-level attacks. The word attacks were more effective, but the\ncharacter and more constrained attacks were more practical and required a\nreduced number of perturbations and queries. These differences need to be\nconsidered during the development of adversarial defense strategies to train\nmore robust LLMs for intelligent text classification applications.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5c0d\u65bc\u6587\u672c\u5206\u985e\u5f88\u6709\u50f9\u503c\uff0c\u4f46\u4e0d\u80fd\u5ffd\u8996\u5176\u6f0f\u6d1e\u3002\u5b83\u5011\u7f3a\u4e4f\u5c0d\u6297\u7bc4\u4f8b\u7684\u5065\u58ef\u6027\uff0c\u56e0\u6b64\u4e86\u89e3\u4e0d\u540c\u985e\u578b\u64fe\u52d5\u7684\u5f71\u97ff\uff0c\u4e26\u8a55\u4f30\u666e\u901a\u7528\u6236\u662f\u5426\u53ef\u4ee5\u7528\u5c11\u91cf\u7684\u64fe\u52d5\u548c\u5c11\u91cf\u7684\u67e5\u8a62\u5c0d\u5df2\u90e8\u7f72\u7684 LLM \u8907\u88fd\u9019\u4e9b\u653b\u64ca\u975e\u5e38\u91cd\u8981\u3002\u9019\u9805\u5de5\u4f5c\u5206\u6790\u4e86\u5728\u60c5\u7dd2\u5206\u985e\u4efb\u52d9\u4e2d\u5c0d\u6297\u4e94\u500b\u4e0d\u540c LLM \u7684\u4e09\u7a2e\u985e\u578b\u5c0d\u6297\u653b\u64ca\u7684\u6709\u6548\u6027\u3001\u6548\u7387\u548c\u5be6\u7528\u6027\u3002\u7372\u5f97\u7684\u7d50\u679c\u8b49\u660e\u4e86\u5b57\u7d1a\u548c\u5b57\u5143\u7d1a\u653b\u64ca\u7684\u5f71\u97ff\u975e\u5e38\u4e0d\u540c\u3002\u5b57\u5143\u653b\u64ca\u66f4\u6709\u6548\uff0c\u4f46\u5b57\u5143\u548c\u66f4\u53d7\u9650\u7684\u653b\u64ca\u66f4\u5be6\u7528\uff0c\u4e26\u4e14\u9700\u8981\u8f03\u5c11\u7684\u64fe\u52d5\u548c\u67e5\u8a62\u3002\u5728\u958b\u767c\u5c0d\u6297\u9632\u79a6\u7b56\u7565\u4ee5\u8a13\u7df4\u66f4\u5f37\u5927\u7684 LLM \u4ee5\u7528\u65bc\u667a\u6167\u6587\u672c\u5206\u985e\u61c9\u7528\u7a0b\u5f0f\u6642\uff0c\u9700\u8981\u8003\u616e\u9019\u4e9b\u5dee\u7570\u3002", "author": "Jo\u00e3o Vitorino et.al.", "authors": "Jo\u00e3o Vitorino, Eva Maia, Isabel Pra\u00e7a", "id": "2406.08050v1", "paper_url": "http://arxiv.org/abs/2406.08050v1", "repo": "null"}}