{"2501.05952": {"publish_time": "2025-01-10", "title": "Scalable Vision Language Model Training via High Quality Data Curation", "paper_summary": "In this paper, we introduce SAIL-VL (ScAlable Vision Language Model TraIning\nvia High QuaLity Data Curation), an open-source vision language model (VLM) of\nstate-of-the-art (SOTA) performance with 2B parameters. We introduce three key\nimprovements that contribute to SAIL-VL's leading performance: (1) Scalable\nhigh-quality visual understanding data construction: We implement a visual\nunderstanding data construction pipeline, which enables hundred-million-scale\nhigh-quality recaption data annotation. Equipped with this pipeline, we curate\nSAIL-Caption, a large-scale caption dataset with large quantity and the highest\ndata quality compared with opensource caption datasets. (2) Scalable\nPretraining with High-Quality Visual Understanding Data: We scale SAIL-VL's\npretraining budget up to 131B tokens and show that even a 2B VLM benefits from\nscaled up training data sizes, exhibiting expected data size scaling laws in\nvisual understanding and instruction following performance. (3) Scalable SFT\nvia quantity and quality scaling: We introduce general guidance for instruction\ndata curation to scale up instruction data continuously, allowing us to\nconstruct a large SFT dataset with the highest quality. To further improve\nSAIL-VL's performance, we propose quality scaling, a multi-stage training\nrecipe with curriculum learning, to improve model performance scaling curves\nw.r.t. data sizes from logarithmic to be near-linear. SAIL-VL obtains the\nhighest average score in 19 commonly used benchmarks in our evaluation and\nachieves top1 performance among VLMs of comparable sizes on OpenCompass\n(https://rank.opencompass.org.cn/leaderboard-multimodal). We release our\nSAIL-VL-2B model at HuggingFace\n(https://huggingface.co/BytedanceDouyinContent/SAIL-VL-2B).", "paper_summary_zh": "<paragraph>\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 SAIL-VL\uff08\u901a\u904e\u9ad8\u54c1\u8cea\u6578\u64da\u7b56\u5c55\u9032\u884c\u53ef\u64f4\u5c55\u7684\u8996\u89ba\u8a9e\u8a00\u6a21\u578b\u8a13\u7df4\uff09\uff0c\u9019\u662f\u4e00\u500b\u5177\u6709 2B \u53c3\u6578\u7684\u6700\u65b0\u6280\u8853 (SOTA) \u6027\u80fd\u7684\u958b\u6e90\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM)\u3002\u6211\u5011\u4ecb\u7d39\u4e86\u6709\u52a9\u65bc SAIL-VL \u9818\u5148\u6027\u80fd\u7684\u4e09\u9805\u95dc\u9375\u6539\u9032\uff1a(1) \u53ef\u64f4\u5c55\u7684\u9ad8\u54c1\u8cea\u8996\u89ba\u7406\u89e3\u6578\u64da\u69cb\u5efa\uff1a\u6211\u5011\u5be6\u4f5c\u4e86\u4e00\u500b\u8996\u89ba\u7406\u89e3\u6578\u64da\u69cb\u5efa\u7ba1\u9053\uff0c\u53ef\u4ee5\u9032\u884c\u5104\u7d1a\u898f\u6a21\u7684\u9ad8\u54c1\u8cea\u91cd\u65b0\u6a19\u984c\u6578\u64da\u8a3b\u89e3\u3002\u5229\u7528\u9019\u500b\u7ba1\u9053\uff0c\u6211\u5011\u7b56\u5283\u4e86 SAIL-Caption\uff0c\u9019\u662f\u4e00\u500b\u8207\u958b\u6e90\u6a19\u984c\u6578\u64da\u96c6\u76f8\u6bd4\uff0c\u6578\u91cf\u9f90\u5927\u4e14\u6578\u64da\u54c1\u8cea\u6700\u9ad8\u7684\u5927\u898f\u6a21\u6a19\u984c\u6578\u64da\u96c6\u3002(2) \u4f7f\u7528\u9ad8\u54c1\u8cea\u8996\u89ba\u7406\u89e3\u6578\u64da\u9032\u884c\u53ef\u64f4\u5c55\u9810\u8a13\u7df4\uff1a\u6211\u5011\u5c07 SAIL-VL \u7684\u9810\u8a13\u7df4\u9810\u7b97\u64f4\u5c55\u5230 131B \u500b\u7b26\u865f\uff0c\u4e26\u986f\u793a\u5373\u4f7f\u662f 2B VLM \u4e5f\u80fd\u5f9e\u64f4\u5c55\u7684\u8a13\u7df4\u6578\u64da\u898f\u6a21\u4e2d\u53d7\u76ca\uff0c\u5728\u8996\u89ba\u7406\u89e3\u548c\u6307\u4ee4\u9075\u5faa\u6027\u80fd\u65b9\u9762\u8868\u73fe\u51fa\u9810\u671f\u7684\u6578\u64da\u898f\u6a21\u64f4\u5c55\u5b9a\u5f8b\u3002(3) \u901a\u904e\u6578\u91cf\u548c\u54c1\u8cea\u64f4\u5c55\u7684\u53ef\u64f4\u5c55 SFT\uff1a\u6211\u5011\u70ba\u6307\u4ee4\u6578\u64da\u7b56\u5c55\u5f15\u5165\u4e86\u901a\u7528\u6307\u5c0e\uff0c\u4ee5\u6301\u7e8c\u64f4\u5c55\u6307\u4ee4\u6578\u64da\uff0c\u8b93\u6211\u5011\u80fd\u5920\u69cb\u5efa\u4e00\u500b\u54c1\u8cea\u6700\u9ad8\u7684 SFT \u6578\u64da\u96c6\u3002\u70ba\u4e86\u9032\u4e00\u6b65\u63d0\u5347 SAIL-VL \u7684\u6027\u80fd\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u54c1\u8cea\u64f4\u5c55\uff0c\u4e00\u7a2e\u5177\u6709\u8ab2\u7a0b\u5b78\u7fd2\u7684\u591a\u968e\u6bb5\u8a13\u7df4\u914d\u65b9\uff0c\u4ee5\u6539\u5584\u6a21\u578b\u6027\u80fd\u64f4\u5c55\u66f2\u7dda\uff0c\u5f9e\u5c0d\u6578\u5230\u63a5\u8fd1\u7dda\u6027\uff0c\u76f8\u5c0d\u65bc\u6578\u64da\u898f\u6a21\u3002SAIL-VL \u5728\u6211\u5011\u7684\u8a55\u4f30\u4e2d\u7372\u5f97\u4e86 19 \u500b\u5e38\u7528\u57fa\u6e96\u6e2c\u8a66\u4e2d\u7684\u6700\u9ad8\u5e73\u5747\u5206\uff0c\u4e26\u5728 OpenCompass\uff08https://rank.opencompass.org.cn/leaderboard-multimodal\uff09\u4e0a\u53d6\u5f97\u4e86\u8207\u540c\u7b49\u898f\u6a21\u7684 VLM \u76f8\u6bd4\u7684\u9802\u5c16\u6027\u80fd\u3002\u6211\u5011\u5728 HuggingFace\uff08https://huggingface.co/BytedanceDouyinContent/SAIL-VL-2B\uff09\u4e0a\u767c\u5e03\u4e86\u6211\u5011\u7684 SAIL-VL-2B \u6a21\u578b\u3002</paragraph>", "author": "Hongyuan Dong et.al.", "authors": "Hongyuan Dong, Zijian Kang, Weijie Yin, Xiao Liang, Chao Feng, Jiao Ran", "id": "2501.05952v1", "paper_url": "http://arxiv.org/abs/2501.05952v1", "repo": "null"}}