{"2411.19652": {"publish_time": "2024-11-29", "title": "Uniform Attention Maps: Boosting Image Fidelity in Reconstruction and Editing", "paper_summary": "Text-guided image generation and editing using diffusion models have achieved\nremarkable advancements. Among these, tuning-free methods have gained attention\nfor their ability to perform edits without extensive model adjustments,\noffering simplicity and efficiency. However, existing tuning-free approaches\noften struggle with balancing fidelity and editing precision. Reconstruction\nerrors in DDIM Inversion are partly attributed to the cross-attention mechanism\nin U-Net, which introduces misalignments during the inversion and\nreconstruction process. To address this, we analyze reconstruction from a\nstructural perspective and propose a novel approach that replaces traditional\ncross-attention with uniform attention maps, significantly enhancing image\nreconstruction fidelity. Our method effectively minimizes distortions caused by\nvarying text conditions during noise prediction. To complement this\nimprovement, we introduce an adaptive mask-guided editing technique that\nintegrates seamlessly with our reconstruction approach, ensuring consistency\nand accuracy in editing tasks. Experimental results demonstrate that our\napproach not only excels in achieving high-fidelity image reconstruction but\nalso performs robustly in real image composition and editing scenarios. This\nstudy underscores the potential of uniform attention maps to enhance the\nfidelity and versatility of diffusion-based image processing methods. Code is\navailable at https://github.com/Mowenyii/Uniform-Attention-Maps.", "paper_summary_zh": "\u6587\u672c\u5f15\u5bfc\u7684\u56fe\u50cf\u751f\u6210\u548c\u7f16\u8f91\u4f7f\u7528\u6269\u6563\u6a21\u578b\u5df2\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\u3002\u5176\u4e2d\uff0c\u65e0\u8c03\u4f18\u65b9\u6cd5\u56e0\u5176\u65e0\u9700\u5927\u91cf\u6a21\u578b\u8c03\u6574\u5373\u53ef\u6267\u884c\u7f16\u8f91\u7684\u80fd\u529b\u800c\u5907\u53d7\u5173\u6ce8\uff0c\u63d0\u4f9b\u4e86\u7b80\u5355\u6027\u548c\u6548\u7387\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u65e0\u8c03\u4f18\u65b9\u6cd5\u901a\u5e38\u96be\u4ee5\u5e73\u8861\u4fdd\u771f\u5ea6\u548c\u7f16\u8f91\u7cbe\u5ea6\u3002DDIM \u53cd\u6f14\u4e2d\u7684\u91cd\u5efa\u8bef\u5dee\u90e8\u5206\u5f52\u56e0\u4e8e U-Net \u4e2d\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\uff0c\u8be5\u673a\u5236\u5728\u53cd\u6f14\u548c\u91cd\u5efa\u8fc7\u7a0b\u4e2d\u5f15\u5165\u4e86\u9519\u4f4d\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u4ece\u7ed3\u6784\u7684\u89d2\u5ea6\u5206\u6790\u91cd\u5efa\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u7528\u7edf\u4e00\u7684\u6ce8\u610f\u529b\u56fe\u66ff\u6362\u4f20\u7edf\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u56fe\u50cf\u91cd\u5efa\u4fdd\u771f\u5ea6\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u6709\u6548\u5730\u6700\u5c0f\u5316\u4e86\u566a\u58f0\u9884\u6d4b\u8fc7\u7a0b\u4e2d\u4e0d\u540c\u6587\u672c\u6761\u4ef6\u5f15\u8d77\u7684\u5931\u771f\u3002\u4e3a\u4e86\u8865\u5145\u8fd9\u4e00\u6539\u8fdb\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u906e\u7f69\u5f15\u5bfc\u7f16\u8f91\u6280\u672f\uff0c\u8be5\u6280\u672f\u4e0e\u6211\u4eec\u7684\u91cd\u5efa\u65b9\u6cd5\u65e0\u7f1d\u96c6\u6210\uff0c\u786e\u4fdd\u4e86\u7f16\u8f91\u4efb\u52a1\u7684\u4e00\u81f4\u6027\u548c\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u4e0d\u4ec5\u5728\u5b9e\u73b0\u9ad8\u4fdd\u771f\u56fe\u50cf\u91cd\u5efa\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u800c\u4e14\u5728\u771f\u5b9e\u56fe\u50cf\u5408\u6210\u548c\u7f16\u8f91\u573a\u666f\u4e2d\u4e5f\u8868\u73b0\u5f97\u5f88\u7a33\u5065\u3002\u672c\u7814\u7a76\u5f3a\u8c03\u4e86\u7edf\u4e00\u6ce8\u610f\u529b\u56fe\u5728\u589e\u5f3a\u57fa\u4e8e\u6269\u6563\u7684\u56fe\u50cf\u5904\u7406\u65b9\u6cd5\u7684\u4fdd\u771f\u5ea6\u548c\u591a\u529f\u80fd\u6027\u65b9\u9762\u7684\u6f5c\u529b\u3002\u4ee3\u7801\u53ef\u5728 https://github.com/Mowenyii/Uniform-Attention-Maps \u83b7\u5f97\u3002", "author": "Wenyi Mo et.al.", "authors": "Wenyi Mo, Tianyu Zhang, Yalong Bai, Bing Su, Ji-Rong Wen", "id": "2411.19652v1", "paper_url": "http://arxiv.org/abs/2411.19652v1", "repo": "https://github.com/mowenyii/uniform-attention-maps"}}