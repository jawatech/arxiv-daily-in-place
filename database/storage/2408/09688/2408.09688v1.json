{"2408.09688": {"publish_time": "2024-08-19", "title": "Recording for Eyes, Not Echoing to Ears: Contextualized Spoken-to-Written Conversion of ASR Transcripts", "paper_summary": "Automatic Speech Recognition (ASR) transcripts exhibit recognition errors and\nvarious spoken language phenomena such as disfluencies, ungrammatical\nsentences, and incomplete sentences, hence suffering from poor readability. To\nimprove readability, we propose a Contextualized Spoken-to-Written conversion\n(CoS2W) task to address ASR and grammar errors and also transfer the informal\ntext into the formal style with content preserved, utilizing contexts and\nauxiliary information. This task naturally matches the in-context learning\ncapabilities of Large Language Models (LLMs). To facilitate comprehensive\ncomparisons of various LLMs, we construct a document-level Spoken-to-Written\nconversion of ASR Transcripts Benchmark (SWAB) dataset. Using SWAB, we study\nthe impact of different granularity levels on the CoS2W performance, and\npropose methods to exploit contexts and auxiliary information to enhance the\noutputs. Experimental results reveal that LLMs have the potential to excel in\nthe CoS2W task, particularly in grammaticality and formality, our methods\nachieve effective understanding of contexts and auxiliary information by LLMs.\nWe further investigate the effectiveness of using LLMs as evaluators and find\nthat LLM evaluators show strong correlations with human evaluations on rankings\nof faithfulness and formality, which validates the reliability of LLM\nevaluators for the CoS2W task.", "paper_summary_zh": "\u81ea\u52d5\u8a9e\u97f3\u8fa8\u8b58 (ASR) \u8f49\u9304\u6703\u51fa\u73fe\u8fa8\u8b58\u932f\u8aa4\u548c\u5404\u7a2e\u53e3\u8a9e\u73fe\u8c61\uff0c\u4f8b\u5982\u8a00\u8a9e\u4e0d\u6d41\u66a2\u3001\u4e0d\u7b26\u5408\u6587\u6cd5\u7684\u53e5\u5b50\u548c\u4e0d\u5b8c\u6574\u7684\u53e5\u5b50\uff0c\u56e0\u6b64\u53ef\u8b80\u6027\u5f88\u5dee\u3002\u70ba\u4e86\u6539\u5584\u53ef\u8b80\u6027\uff0c\u6211\u5011\u63d0\u51fa\u8a9e\u5883\u5316\u53e3\u8a9e\u8f49\u66f8\u5beb\u8f49\u63db (CoS2W) \u4efb\u52d9\u4f86\u89e3\u6c7a ASR \u548c\u6587\u6cd5\u932f\u8aa4\uff0c\u4e26\u5728\u4fdd\u7559\u5167\u5bb9\u7684\u60c5\u6cc1\u4e0b\u5c07\u975e\u6b63\u5f0f\u6587\u5b57\u8f49\u63db\u70ba\u6b63\u5f0f\u98a8\u683c\uff0c\u5229\u7528\u8a9e\u5883\u548c\u8f14\u52a9\u8cc7\u8a0a\u3002\u6b64\u4efb\u52d9\u81ea\u7136\u7b26\u5408\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u8a9e\u5883\u5b78\u7fd2\u80fd\u529b\u3002\u70ba\u4e86\u4fc3\u9032\u5c0d\u5404\u7a2e LLM \u7684\u5168\u9762\u6bd4\u8f03\uff0c\u6211\u5011\u5efa\u69cb\u4e86 ASR \u8f49\u9304\u57fa\u6e96 (SWAB) \u8cc7\u6599\u96c6\u7684\u6587\u6a94\u7d1a\u53e3\u8a9e\u8f49\u66f8\u5beb\u8f49\u63db\u3002\u4f7f\u7528 SWAB\uff0c\u6211\u5011\u7814\u7a76\u4e86\u4e0d\u540c\u7c92\u5ea6\u5c64\u7d1a\u5c0d CoS2W \u6548\u80fd\u7684\u5f71\u97ff\uff0c\u4e26\u63d0\u51fa\u5229\u7528\u8a9e\u5883\u548c\u8f14\u52a9\u8cc7\u8a0a\u4f86\u589e\u5f37\u8f38\u51fa\u7684\u65b9\u6cd5\u3002\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0cLLM \u6709\u6f5b\u529b\u5728 CoS2W \u4efb\u52d9\u4e2d\u8868\u73fe\u51fa\u8272\uff0c\u7279\u5225\u662f\u5728\u6587\u6cd5\u548c\u6b63\u5f0f\u6027\u65b9\u9762\uff0c\u6211\u5011\u7684\u9019\u4e9b\u65b9\u6cd5\u8b93 LLM \u6709\u6548\u7406\u89e3\u8a9e\u5883\u548c\u8f14\u52a9\u8cc7\u8a0a\u3002\u6211\u5011\u9032\u4e00\u6b65\u63a2\u8a0e\u5c07 LLM \u7528\u4f5c\u8a55\u4f30\u5668\u7684\u6709\u6548\u6027\uff0c\u767c\u73fe LLM \u8a55\u4f30\u5668\u5728\u5fe0\u5be6\u5ea6\u548c\u6b63\u5f0f\u6027\u7684\u6392\u540d\u4e0a\u8207\u4eba\u985e\u8a55\u4f30\u6709\u5f88\u5f37\u7684\u76f8\u95dc\u6027\uff0c\u9019\u9a57\u8b49\u4e86 LLM \u8a55\u4f30\u5668\u5728 CoS2W \u4efb\u52d9\u4e2d\u7684\u53ef\u9760\u6027\u3002", "author": "Jiaqing Liu et.al.", "authors": "Jiaqing Liu, Chong Deng, Qinglin Zhang, Qian Chen, Hai Yu, Wen Wang", "id": "2408.09688v1", "paper_url": "http://arxiv.org/abs/2408.09688v1", "repo": "null"}}