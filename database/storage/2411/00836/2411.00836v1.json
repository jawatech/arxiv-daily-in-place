{"2411.00836": {"publish_time": "2024-10-29", "title": "DynaMath: A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models", "paper_summary": "The rapid advancements in Vision-Language Models (VLMs) have shown great\npotential in tackling mathematical reasoning tasks that involve visual context.\nUnlike humans who can reliably apply solution steps to similar problems with\nminor modifications, we found that SOTA VLMs like GPT-4o can consistently fail\nin these scenarios, revealing limitations in their mathematical reasoning\ncapabilities. In this paper, we investigate the mathematical reasoning\nrobustness in VLMs and evaluate how well these models perform under different\nvariants of the same question, such as changes in visual numerical values or\nfunction graphs. While several vision-based math benchmarks have been developed\nto assess VLMs' problem-solving capabilities, these benchmarks contain only\nstatic sets of problems and cannot easily evaluate mathematical reasoning\nrobustness. To fill this gap, we introduce DynaMath, a dynamic visual math\nbenchmark designed for in-depth assessment of VLMs. DynaMath includes 501\nhigh-quality, multi-topic seed questions, each represented as a Python program.\nThose programs are carefully designed and annotated to enable the automatic\ngeneration of a much larger set of concrete questions, including many different\ntypes of visual and textual variations. DynaMath allows us to evaluate the\ngeneralization ability of VLMs, by assessing their performance under varying\ninput conditions of a seed question. We evaluated 14 SOTA VLMs with 5,010\ngenerated concrete questions. Our results show that the worst-case model\naccuracy, defined as the percentage of correctly answered seed questions in all\n10 variants, is significantly lower than the average-case accuracy. Our\nanalysis emphasizes the need to study the robustness of VLMs' reasoning\nabilities, and DynaMath provides valuable insights to guide the development of\nmore reliable models for mathematical reasoning.", "paper_summary_zh": "<paragraph>\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM) \u7684\u5feb\u901f\u9032\u6b65\u5728\u89e3\u6c7a\u6d89\u53ca\u8996\u89ba\u80cc\u666f\u7684\u6578\u5b78\u63a8\u7406\u4efb\u52d9\u65b9\u9762\u5c55\u73fe\u4e86\u5de8\u5927\u7684\u6f5b\u529b\u3002\u8207\u4eba\u985e\u53ef\u4ee5\u5c07\u89e3\u6c7a\u6b65\u9a5f\u53ef\u9760\u5730\u61c9\u7528\u65bc\u985e\u4f3c\u554f\u984c\uff08\u4e26\u9032\u884c\u5fae\u5c0f\u7684\u4fee\u6539\uff09\u4e0d\u540c\uff0c\u6211\u5011\u767c\u73fe\u50cf GPT-4o \u7b49 SOTA VLM \u5728\u9019\u4e9b\u5834\u666f\u4e2d\u53ef\u80fd\u6703\u6301\u7e8c\u5931\u6557\uff0c\u63ed\u9732\u4e86\u5176\u6578\u5b78\u63a8\u7406\u80fd\u529b\u7684\u9650\u5236\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u7814\u7a76\u4e86 VLM \u4e2d\u7684\u6578\u5b78\u63a8\u7406\u7a69\u5065\u6027\uff0c\u4e26\u8a55\u4f30\u4e86\u9019\u4e9b\u6a21\u578b\u5728\u540c\u4e00\u554f\u984c\u7684\u4e0d\u540c\u8b8a\u9ad4\uff08\u4f8b\u5982\u8996\u89ba\u6578\u503c\u6216\u51fd\u6578\u5716\u5f62\u7684\u8b8a\u5316\uff09\u4e0b\u7684\u8868\u73fe\u3002\u96d6\u7136\u5df2\u7d93\u958b\u767c\u4e86\u591a\u500b\u57fa\u65bc\u8996\u89ba\u7684\u6578\u5b78\u57fa\u6e96\u4f86\u8a55\u4f30 VLM \u7684\u554f\u984c\u89e3\u6c7a\u80fd\u529b\uff0c\u4f46\u9019\u4e9b\u57fa\u6e96\u53ea\u5305\u542b\u975c\u614b\u554f\u984c\u96c6\uff0c\u7121\u6cd5\u8f15\u9b06\u8a55\u4f30\u6578\u5b78\u63a8\u7406\u7a69\u5065\u6027\u3002\u70ba\u4e86\u586b\u88dc\u9019\u4e00\u7a7a\u767d\uff0c\u6211\u5011\u5f15\u5165\u4e86 DynaMath\uff0c\u9019\u662f\u4e00\u500b\u52d5\u614b\u8996\u89ba\u6578\u5b78\u57fa\u6e96\uff0c\u5c08\u9580\u7528\u65bc\u6df1\u5165\u8a55\u4f30 VLM\u3002DynaMath \u5305\u542b 501 \u500b\u9ad8\u54c1\u8cea\u3001\u591a\u4e3b\u984c\u7a2e\u5b50\u554f\u984c\uff0c\u6bcf\u500b\u554f\u984c\u90fd\u8868\u793a\u70ba\u4e00\u500b Python \u7a0b\u5f0f\u3002\u9019\u4e9b\u7a0b\u5f0f\u7d93\u904e\u4ed4\u7d30\u8a2d\u8a08\u548c\u8a3b\u89e3\uff0c\u4ee5\u4fbf\u81ea\u52d5\u7522\u751f\u4e00\u7d44\u66f4\u5927\u7684\u5177\u9ad4\u554f\u984c\uff0c\u5305\u62ec\u8a31\u591a\u4e0d\u540c\u985e\u578b\u7684\u8996\u89ba\u548c\u6587\u5b57\u8b8a\u9ad4\u3002DynaMath \u5141\u8a31\u6211\u5011\u8a55\u4f30 VLM \u7684\u6cdb\u5316\u80fd\u529b\uff0c\u65b9\u6cd5\u662f\u5728\u7a2e\u5b50\u554f\u984c\u7684\u4e0d\u540c\u8f38\u5165\u689d\u4ef6\u4e0b\u8a55\u4f30\u5176\u8868\u73fe\u3002\u6211\u5011\u4f7f\u7528 5,010 \u500b\u751f\u6210\u7684\u5177\u9ad4\u554f\u984c\u8a55\u4f30\u4e86 14 \u500b SOTA VLM\u3002\u6211\u5011\u7684\u7d50\u679c\u986f\u793a\uff0c\u6700\u5dee\u60c5\u6cc1\u7684\u6a21\u578b\u6e96\u78ba\u5ea6\uff08\u5b9a\u7fa9\u70ba\u5728\u6240\u6709 10 \u500b\u8b8a\u9ad4\u4e2d\u6b63\u78ba\u56de\u7b54\u7684\u7a2e\u5b50\u554f\u984c\u7684\u767e\u5206\u6bd4\uff09\u986f\u8457\u4f4e\u65bc\u5e73\u5747\u60c5\u6cc1\u6e96\u78ba\u5ea6\u3002\u6211\u5011\u7684\u5206\u6790\u5f37\u8abf\u4e86\u7814\u7a76 VLM \u63a8\u7406\u80fd\u529b\u7a69\u5065\u6027\u7684\u5fc5\u8981\u6027\uff0c\u800c DynaMath \u63d0\u4f9b\u4e86\u6709\u50f9\u503c\u7684\u898b\u89e3\uff0c\u4ee5\u6307\u5c0e\u958b\u767c\u66f4\u53ef\u9760\u7684\u6578\u5b78\u63a8\u7406\u6a21\u578b\u3002</paragraph>", "author": "Chengke Zou et.al.", "authors": "Chengke Zou, Xingang Guo, Rui Yang, Junyu Zhang, Bin Hu, Huan Zhang", "id": "2411.00836v1", "paper_url": "http://arxiv.org/abs/2411.00836v1", "repo": "null"}}