{"2501.01422": {"publish_time": "2025-01-02", "title": "Multi-Modal Video Feature Extraction for Popularity Prediction", "paper_summary": "This work aims to predict the popularity of short videos using the videos\nthemselves and their related features. Popularity is measured by four key\nengagement metrics: view count, like count, comment count, and share count.\nThis study employs video classification models with different architectures and\ntraining methods as backbone networks to extract video modality features.\nMeanwhile, the cleaned video captions are incorporated into a carefully\ndesigned prompt framework, along with the video, as input for video-to-text\ngeneration models, which generate detailed text-based video content\nunderstanding. These texts are then encoded into vectors using a pre-trained\nBERT model. Based on the six sets of vectors mentioned above, a neural network\nis trained for each of the four prediction metrics. Moreover, the study\nconducts data mining and feature engineering based on the video and tabular\ndata, constructing practical features such as the total frequency of hashtag\nappearances, the total frequency of mention appearances, video duration, frame\ncount, frame rate, and total time online. Multiple machine learning models are\ntrained, and the most stable model, XGBoost, is selected. Finally, the\npredictions from the neural network and XGBoost models are averaged to obtain\nthe final result.", "paper_summary_zh": "\u672c\u7814\u7a76\u65e8\u5728\u5229\u7528\u5f71\u7247\u672c\u8eab\u53ca\u5176\u76f8\u95dc\u529f\u80fd\u4f86\u9810\u6e2c\u77ed\u5f71\u7247\u7684\u71b1\u9580\u7a0b\u5ea6\u3002\u71b1\u9580\u7a0b\u5ea6\u7531\u56db\u500b\u95dc\u9375\u53c3\u8207\u6307\u6a19\u8861\u91cf\uff1a\u89c0\u770b\u6b21\u6578\u3001\u6309\u8b9a\u6b21\u6578\u3001\u7559\u8a00\u6b21\u6578\u548c\u5206\u4eab\u6b21\u6578\u3002\u672c\u7814\u7a76\u63a1\u7528\u5177\u6709\u4e0d\u540c\u67b6\u69cb\u548c\u8a13\u7df4\u65b9\u6cd5\u7684\u5f71\u7247\u5206\u985e\u6a21\u578b\u4f5c\u70ba\u4e3b\u5e79\u7db2\u8def\uff0c\u4ee5\u8403\u53d6\u5f71\u7247\u5f62\u5f0f\u7279\u5fb5\u3002\u540c\u6642\uff0c\u5c07\u6574\u7406\u5f8c\u7684\u5f71\u7247\u5b57\u5e55\u8207\u5f71\u7247\u4e00\u8d77\u7d0d\u5165\u7cbe\u5fc3\u8a2d\u8a08\u7684\u63d0\u793a\u67b6\u69cb\u4e2d\uff0c\u4f5c\u70ba\u5f71\u7247\u5230\u6587\u5b57\u751f\u6210\u6a21\u578b\u7684\u8f38\u5165\uff0c\u4ee5\u7522\u751f\u8a73\u7d30\u7684\u6587\u5b57\u5316\u5f71\u7247\u5167\u5bb9\u7406\u89e3\u3002\u7136\u5f8c\uff0c\u4f7f\u7528\u9810\u5148\u8a13\u7df4\u7684 BERT \u6a21\u578b\u5c07\u9019\u4e9b\u6587\u5b57\u7de8\u78bc\u6210\u5411\u91cf\u3002\u6839\u64da\u4e0a\u8ff0\u516d\u7d44\u5411\u91cf\uff0c\u91dd\u5c0d\u56db\u500b\u9810\u6e2c\u6307\u6a19\u4e2d\u7684\u6bcf\u4e00\u500b\u8a13\u7df4\u4e00\u500b\u795e\u7d93\u7db2\u8def\u3002\u6b64\u5916\uff0c\u672c\u7814\u7a76\u6839\u64da\u5f71\u7247\u548c\u8868\u683c\u8cc7\u6599\u9032\u884c\u8cc7\u6599\u63a2\u52d8\u548c\u7279\u5fb5\u5de5\u7a0b\uff0c\u5efa\u69cb\u5be6\u7528\u7684\u7279\u5fb5\uff0c\u4f8b\u5982\u6a19\u7c64\u51fa\u73fe\u7684\u7e3d\u983b\u7387\u3001\u63d0\u53ca\u51fa\u73fe\u7684\u7e3d\u983b\u7387\u3001\u5f71\u7247\u9577\u5ea6\u3001\u5f71\u683c\u6578\u3001\u5f71\u683c\u7387\u548c\u7dda\u4e0a\u7e3d\u6642\u9593\u3002\u8a13\u7df4\u591a\u500b\u6a5f\u5668\u5b78\u7fd2\u6a21\u578b\uff0c\u4e26\u9078\u51fa\u6700\u7a69\u5b9a\u7684\u6a21\u578b XGBoost\u3002\u6700\u5f8c\uff0c\u5c07\u795e\u7d93\u7db2\u8def\u548c XGBoost \u6a21\u578b\u7684\u9810\u6e2c\u7d50\u679c\u53d6\u5e73\u5747\u503c\uff0c\u4ee5\u53d6\u5f97\u6700\u7d42\u7d50\u679c\u3002", "author": "Haixu Liu et.al.", "authors": "Haixu Liu, Wenning Wang, Haoxiang Zheng, Penghao Jiang, Qirui Wang, Ruiqing Yan, Qiuzhuang Sun", "id": "2501.01422v1", "paper_url": "http://arxiv.org/abs/2501.01422v1", "repo": "null"}}