{"2406.07544": {"publish_time": "2024-06-11", "title": "Situational Awareness Matters in 3D Vision Language Reasoning", "paper_summary": "Being able to carry out complicated vision language reasoning tasks in 3D\nspace represents a significant milestone in developing household robots and\nhuman-centered embodied AI. In this work, we demonstrate that a critical and\ndistinct challenge in 3D vision language reasoning is situational awareness,\nwhich incorporates two key components: (1) The autonomous agent grounds its\nself-location based on a language prompt. (2) The agent answers open-ended\nquestions from the perspective of its calculated position. To address this\nchallenge, we introduce SIG3D, an end-to-end Situation-Grounded model for 3D\nvision language reasoning. We tokenize the 3D scene into sparse voxel\nrepresentation and propose a language-grounded situation estimator, followed by\na situated question answering module. Experiments on the SQA3D and ScanQA\ndatasets show that SIG3D outperforms state-of-the-art models in situation\nestimation and question answering by a large margin (e.g., an enhancement of\nover 30% on situation estimation accuracy). Subsequent analysis corroborates\nour architectural design choices, explores the distinct functions of visual and\ntextual tokens, and highlights the importance of situational awareness in the\ndomain of 3D question answering.", "paper_summary_zh": "\u80fd\u5920\u5728 3D \u7a7a\u9593\u4e2d\u57f7\u884c\u8907\u96dc\u7684\u8996\u89ba\u8a9e\u8a00\u63a8\u7406\u4efb\u52d9\uff0c\u4ee3\u8868\u4e86\u5bb6\u7528\u6a5f\u5668\u4eba\u548c\u4ee5\u4eba\u70ba\u4e2d\u5fc3\u7684\u5177\u9ad4 AI \u767c\u5c55\u4e2d\u7684\u91cd\u8981\u91cc\u7a0b\u7891\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u8b49\u660e\u4e86 3D \u8996\u89ba\u8a9e\u8a00\u63a8\u7406\u4e2d\u4e00\u9805\u95dc\u9375\u4e14\u7368\u7279\u7684\u6311\u6230\u5728\u65bc\u60c5\u5883\u611f\u77e5\uff0c\u5b83\u5305\u542b\u5169\u500b\u95dc\u9375\u7d44\u6210\u90e8\u5206\uff1a(1) \u81ea\u4e3b\u4ee3\u7406\u6839\u64da\u8a9e\u8a00\u63d0\u793a\u78ba\u5b9a\u5176\u81ea\u6211\u4f4d\u7f6e\u3002(2) \u4ee3\u7406\u5f9e\u5176\u8a08\u7b97\u51fa\u7684\u4f4d\u7f6e\u7684\u89d2\u5ea6\u56de\u7b54\u958b\u653e\u5f0f\u554f\u984c\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e00\u6311\u6230\uff0c\u6211\u5011\u5f15\u5165\u4e86 SIG3D\uff0c\u9019\u662f\u4e00\u500b\u7aef\u5230\u7aef\u7684 3D \u8996\u89ba\u8a9e\u8a00\u63a8\u7406\u60c5\u5883\u57fa\u790e\u6a21\u578b\u3002\u6211\u5011\u5c07 3D \u5834\u666f\u6a19\u8a18\u5316\u70ba\u7a00\u758f\u9ad4\u7d20\u8868\u793a\uff0c\u4e26\u63d0\u51fa\u4e00\u500b\u8a9e\u8a00\u57fa\u790e\u7684\u60c5\u5883\u4f30\u8a08\u5668\uff0c\u96a8\u5f8c\u662f\u4e00\u500b\u60c5\u5883\u554f\u984c\u56de\u7b54\u6a21\u7d44\u3002\u5c0d SQA3D \u548c ScanQA \u8cc7\u6599\u96c6\u7684\u5be6\u9a57\u8868\u660e\uff0cSIG3D \u5728\u60c5\u5883\u4f30\u8a08\u548c\u554f\u984c\u56de\u7b54\u65b9\u9762\u5927\u5e45\u512a\u65bc\u6700\u5148\u9032\u7684\u6a21\u578b\uff08\u4f8b\u5982\uff0c\u60c5\u5883\u4f30\u8a08\u6e96\u78ba\u5ea6\u63d0\u9ad8\u4e86 30% \u4ee5\u4e0a\uff09\u3002\u5f8c\u7e8c\u5206\u6790\u8b49\u5be6\u4e86\u6211\u5011\u7684\u67b6\u69cb\u8a2d\u8a08\u9078\u64c7\uff0c\u63a2\u8a0e\u4e86\u8996\u89ba\u548c\u6587\u5b57\u6a19\u8a18\u7684\u4e0d\u540c\u529f\u80fd\uff0c\u4e26\u5f37\u8abf\u4e86\u60c5\u5883\u611f\u77e5\u5728 3D \u554f\u984c\u56de\u7b54\u9818\u57df\u4e2d\u7684\u91cd\u8981\u6027\u3002", "author": "Yunze Man et.al.", "authors": "Yunze Man, Liang-Yan Gui, Yu-Xiong Wang", "id": "2406.07544v1", "paper_url": "http://arxiv.org/abs/2406.07544v1", "repo": "null"}}