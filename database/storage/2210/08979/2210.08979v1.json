{"2210.08979": {"publish_time": "2022-09-30", "title": "An Interactive Interpretability System for Breast Cancer Screening with Deep Learning", "paper_summary": "Deep learning methods, in particular convolutional neural networks, have\nemerged as a powerful tool in medical image computing tasks. While these\ncomplex models provide excellent performance, their black-box nature may hinder\nreal-world adoption in high-stakes decision-making. In this paper, we propose\nan interactive system to take advantage of state-of-the-art interpretability\ntechniques to assist radiologists with breast cancer screening. Our system\nintegrates a deep learning model into the radiologists' workflow and provides\nnovel interactions to promote understanding of the model's decision-making\nprocess. Moreover, we demonstrate that our system can take advantage of user\ninteractions progressively to provide finer-grained explainability reports with\nlittle labeling overhead. Due to the generic nature of the adopted\ninterpretability technique, our system is domain-agnostic and can be used for\nmany different medical image computing tasks, presenting a novel perspective on\nhow we can leverage visual analytics to transform originally static\ninterpretability techniques to augment human decision making and promote the\nadoption of medical AI.", "paper_summary_zh": "", "author": "Yuzhe Lu et.al.", "authors": "Yuzhe Lu,Adam Perer", "id": "2210.08979v1", "paper_url": "http://arxiv.org/abs/2210.08979v1", "repo": "null"}}