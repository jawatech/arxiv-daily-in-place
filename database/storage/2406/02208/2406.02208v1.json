{"2406.02208": {"publish_time": "2024-06-04", "title": "Why Only Text: Empowering Vision-and-Language Navigation with Multi-modal Prompts", "paper_summary": "Current Vision-and-Language Navigation (VLN) tasks mainly employ textual\ninstructions to guide agents. However, being inherently abstract, the same\ntextual instruction can be associated with different visual signals, causing\nsevere ambiguity and limiting the transfer of prior knowledge in the vision\ndomain from the user to the agent. To fill this gap, we propose\nVision-and-Language Navigation with Multi-modal Prompts (VLN-MP), a novel task\naugmenting traditional VLN by integrating both natural language and images in\ninstructions. VLN-MP not only maintains backward compatibility by effectively\nhandling text-only prompts but also consistently shows advantages with\ndifferent quantities and relevance of visual prompts. Possible forms of visual\nprompts include both exact and similar object images, providing adaptability\nand versatility in diverse navigation scenarios. To evaluate VLN-MP under a\nunified framework, we implement a new benchmark that offers: (1) a\ntraining-free pipeline to transform textual instructions into multi-modal forms\nwith landmark images; (2) diverse datasets with multi-modal instructions for\ndifferent downstream tasks; (3) a novel module designed to process various\nimage prompts for seamless integration with state-of-the-art VLN models.\nExtensive experiments on four VLN benchmarks (R2R, RxR, REVERIE, CVDN) show\nthat incorporating visual prompts significantly boosts navigation performance.\nWhile maintaining efficiency with text-only prompts, VLN-MP enables agents to\nnavigate in the pre-explore setting and outperform text-based models, showing\nits broader applicability.", "paper_summary_zh": "\u76ee\u524d\u7684\u8996\u89ba\u8a9e\u8a00\u5c0e\u822a (VLN) \u4efb\u52d9\u4e3b\u8981\u4f7f\u7528\u6587\u5b57\u6307\u4ee4\u4f86\u5f15\u5c0e\u4ee3\u7406\u3002\u7136\u800c\uff0c\u7531\u65bc\u6587\u5b57\u6307\u4ee4\u672c\u8eab\u5177\u6709\u62bd\u8c61\u6027\uff0c\u76f8\u540c\u7684\u6587\u5b57\u6307\u4ee4\u53ef\u80fd\u6703\u8207\u4e0d\u540c\u7684\u8996\u89ba\u8a0a\u865f\u7522\u751f\u95dc\u806f\uff0c\u5c0e\u81f4\u56b4\u91cd\u7684\u6b67\u7fa9\uff0c\u4e26\u9650\u5236\u4e86\u4f7f\u7528\u8005\u5c07\u5148\u524d\u7684\u8996\u89ba\u9818\u57df\u77e5\u8b58\u50b3\u905e\u7d66\u4ee3\u7406\u7684\u53ef\u80fd\u6027\u3002\u70ba\u4e86\u586b\u88dc\u9019\u500b\u7a7a\u767d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u591a\u6a21\u614b\u63d0\u793a\u8996\u89ba\u8a9e\u8a00\u5c0e\u822a (VLN-MP)\uff0c\u9019\u662f\u4e00\u500b\u900f\u904e\u5728\u6307\u4ee4\u4e2d\u6574\u5408\u81ea\u7136\u8a9e\u8a00\u548c\u5f71\u50cf\u7684\u65b0\u4efb\u52d9\uff0c\u4f86\u64f4\u5145\u50b3\u7d71\u7684 VLN\u3002VLN-MP \u4e0d\u50c5\u900f\u904e\u6709\u6548\u8655\u7406\u7d14\u6587\u5b57\u63d0\u793a\uff0c\u7dad\u6301\u4e86\u5411\u5f8c\u76f8\u5bb9\u6027\uff0c\u800c\u4e14\u5728\u4e0d\u540c\u6578\u91cf\u7684\u8996\u89ba\u63d0\u793a\u548c\u76f8\u95dc\u6027\u65b9\u9762\u4e5f\u6301\u7e8c\u5c55\u73fe\u512a\u52e2\u3002\u8996\u89ba\u63d0\u793a\u7684\u53ef\u80fd\u5f62\u5f0f\u5305\u62ec\u78ba\u5207\u548c\u985e\u4f3c\u7684\u7269\u4ef6\u5f71\u50cf\uff0c\u5728\u4e0d\u540c\u7684\u5c0e\u822a\u5834\u666f\u4e2d\u63d0\u4f9b\u4e86\u9069\u61c9\u6027\u548c\u591a\u529f\u80fd\u6027\u3002\u70ba\u4e86\u5728\u7d71\u4e00\u67b6\u69cb\u4e0b\u8a55\u4f30 VLN-MP\uff0c\u6211\u5011\u5be6\u4f5c\u4e86\u4e00\u500b\u65b0\u7684\u57fa\u6e96\uff0c\u63d0\u4f9b\uff1a(1) \u5c07\u6587\u5b57\u6307\u4ee4\u8f49\u63db\u6210\u5305\u542b\u5730\u6a19\u5f71\u50cf\u7684\u591a\u6a21\u614b\u5f62\u5f0f\u7684\u7121\u8a13\u7df4\u7ba1\u9053\uff1b(2) \u91dd\u5c0d\u4e0d\u540c\u4e0b\u6e38\u4efb\u52d9\u7684\u591a\u6a21\u614b\u6307\u4ee4\u7684\u591a\u5143\u8cc7\u6599\u96c6\uff1b(3) \u4e00\u500b\u65b0\u7a4e\u7684\u6a21\u7d44\uff0c\u7528\u65bc\u8655\u7406\u5404\u7a2e\u5f71\u50cf\u63d0\u793a\uff0c\u4ee5\u8207\u6700\u5148\u9032\u7684 VLN \u6a21\u578b\u7121\u7e2b\u6574\u5408\u3002\u5728\u56db\u500b VLN \u57fa\u6e96 (R2R\u3001RxR\u3001REVERIE\u3001CVDN) \u4e0a\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u986f\u793a\uff0c\u52a0\u5165\u8996\u89ba\u63d0\u793a\u986f\u8457\u63d0\u5347\u4e86\u5c0e\u822a\u6548\u80fd\u3002VLN-MP \u5728\u7dad\u6301\u7d14\u6587\u5b57\u63d0\u793a\u7684\u6548\u7387\u7684\u540c\u6642\uff0c\u8b93\u4ee3\u7406\u80fd\u5920\u5728\u9810\u5148\u63a2\u7d22\u7684\u8a2d\u5b9a\u4e2d\u5c0e\u822a\uff0c\u4e26\u512a\u65bc\u57fa\u65bc\u6587\u5b57\u7684\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u5176\u66f4\u5ee3\u6cdb\u7684\u9069\u7528\u6027\u3002", "author": "Haodong Hong et.al.", "authors": "Haodong Hong, Sen Wang, Zi Huang, Qi Wu, Jiajun Liu", "id": "2406.02208v1", "paper_url": "http://arxiv.org/abs/2406.02208v1", "repo": "https://github.com/honghd16/vln-mp"}}