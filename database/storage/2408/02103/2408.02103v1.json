{"2408.02103": {"publish_time": "2024-08-04", "title": "Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process", "paper_summary": "In-context learning (ICL) is a few-shot learning paradigm that involves\nlearning mappings through input-output pairs and appropriately applying them to\nnew instances. Despite the remarkable ICL capabilities demonstrated by Large\nLanguage Models (LLMs), existing works are highly dependent on large-scale\nlabeled support sets, not always feasible in practical scenarios. To refine\nthis approach, we focus primarily on an innovative selective annotation\nmechanism, which precedes the standard demonstration retrieval. We introduce\nthe Language Model-based Determinant Point Process (LM-DPP) that simultaneously\nconsiders the uncertainty and diversity of unlabeled instances for optimal\nselection. Consequently, this yields a subset for annotation that strikes a\ntrade-off between the two factors. We apply LM-DPP to various language models,\nincluding GPT-J, LlaMA, and GPT-3. Experimental results on 9 NLU and 2\nGeneration datasets demonstrate that LM-DPP can effectively select canonical\nexamples. Further analysis reveals that LLMs benefit most significantly from\nsubsets that are both low uncertainty and high diversity.", "paper_summary_zh": "\u60c5\u5883\u5b78\u7fd2 (ICL) \u662f\u4e00\u7a2e\u5c0f\u6a23\u672c\u5b78\u7fd2\u7bc4\u4f8b\uff0c\u6d89\u53ca\u900f\u904e\u8f38\u5165\u8f38\u51fa\u914d\u5c0d\u5b78\u7fd2\u5c0d\u61c9\uff0c\u4e26\u9069\u7576\u5730\u5c07\u5176\u61c9\u7528\u65bc\u65b0\u500b\u9ad4\u3002\u5118\u7ba1\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5c55\u793a\u4e86\u975e\u51e1\u7684 ICL \u80fd\u529b\uff0c\u4f46\u73fe\u6709\u5de5\u4f5c\u9ad8\u5ea6\u4f9d\u8cf4\u65bc\u5927\u898f\u6a21\u6a19\u7c64\u652f\u63f4\u96c6\uff0c\u9019\u5728\u5be6\u969b\u5834\u666f\u4e2d\u4e26\u975e\u7e3d\u662f\u53ef\u884c\u3002\u70ba\u4e86\u512a\u5316\u6b64\u65b9\u6cd5\uff0c\u6211\u5011\u4e3b\u8981\u95dc\u6ce8\u5275\u65b0\u7684\u9078\u64c7\u6027\u6a19\u8a3b\u6a5f\u5236\uff0c\u5b83\u5148\u65bc\u6a19\u6e96\u793a\u7bc4\u6aa2\u7d22\u3002\u6211\u5011\u5f15\u5165\u4e86\u57fa\u65bc\u8a9e\u8a00\u6a21\u578b\u7684\u78ba\u5b9a\u9ede\u904e\u7a0b (LM-DPP)\uff0c\u5b83\u540c\u6642\u8003\u616e\u4e86\u672a\u6a19\u7c64\u500b\u9ad4\u7684\u4e0d\u78ba\u5b9a\u6027\u548c\u591a\u6a23\u6027\uff0c\u4ee5\u9032\u884c\u6700\u4f73\u9078\u64c7\u3002\u56e0\u6b64\uff0c\u9019\u6703\u7522\u751f\u4e00\u500b\u6a19\u8a3b\u5b50\u96c6\uff0c\u5728\u5169\u500b\u56e0\u7d20\u4e4b\u9593\u53d6\u5f97\u6298\u8877\u3002\u6211\u5011\u5c07 LM-DPP \u61c9\u7528\u65bc\u5404\u7a2e\u8a9e\u8a00\u6a21\u578b\uff0c\u5305\u62ec GPT-J\u3001LlaMA \u548c GPT-3\u3002\u5728 9 \u500b NLU \u548c 2 \u500b\u751f\u6210\u8cc7\u6599\u96c6\u4e0a\u7684\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0cLM-DPP \u53ef\u4ee5\u6709\u6548\u5730\u9078\u64c7\u5178\u578b\u7bc4\u4f8b\u3002\u9032\u4e00\u6b65\u7684\u5206\u6790\u8868\u660e\uff0cLLM \u6700\u53d7\u76ca\u65bc\u4e0d\u78ba\u5b9a\u6027\u4f4e\u4e14\u591a\u6a23\u6027\u9ad8\u7684\u5b50\u96c6\u3002", "author": "Peng Wang et.al.", "authors": "Peng Wang, Xiaobin Wang, Chao Lou, Shengyu Mao, Pengjun Xie, Yong Jiang", "id": "2408.02103v1", "paper_url": "http://arxiv.org/abs/2408.02103v1", "repo": "null"}}