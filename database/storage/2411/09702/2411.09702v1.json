{"2411.09702": {"publish_time": "2024-11-14", "title": "On the Surprising Effectiveness of Attention Transfer for Vision Transformers", "paper_summary": "Conventional wisdom suggests that pre-training Vision Transformers (ViT)\nimproves downstream performance by learning useful representations. Is this\nactually true? We investigate this question and find that the features and\nrepresentations learned during pre-training are not essential. Surprisingly,\nusing only the attention patterns from pre-training (i.e., guiding how\ninformation flows between tokens) is sufficient for models to learn high\nquality features from scratch and achieve comparable downstream performance. We\nshow this by introducing a simple method called attention transfer, where only\nthe attention patterns from a pre-trained teacher ViT are transferred to a\nstudent, either by copying or distilling the attention maps. Since attention\ntransfer lets the student learn its own features, ensembling it with a\nfine-tuned teacher also further improves accuracy on ImageNet. We\nsystematically study various aspects of our findings on the sufficiency of\nattention maps, including distribution shift settings where they underperform\nfine-tuning. We hope our exploration provides a better understanding of what\npre-training accomplishes and leads to a useful alternative to the standard\npractice of fine-tuning", "paper_summary_zh": "\u50b3\u7d71\u89c0\u5ff5\u8a8d\u70ba\u9810\u8a13\u7df4\u8996\u89baTransformer\uff08ViT\uff09\n\u900f\u904e\u5b78\u7fd2\u6709\u7528\u7684\u8868\u5fb5\u4f86\u63d0\u5347\u4e0b\u6e38\u6548\u80fd\u3002\u9019\n\u662f\u5426\u5c6c\u5be6\uff1f\u6211\u5011\u63a2\u8a0e\u9019\u500b\u554f\u984c\uff0c\u767c\u73fe\u9810\u8a13\u7df4\u671f\u9593\u5b78\u7fd2\u5230\u7684\u7279\u5fb5\u548c\n\u8868\u5fb5\u4e26\u975e\u5fc5\u8981\u7684\u3002\u4ee4\u4eba\u9a5a\u8a1d\u7684\u662f\uff0c\u50c5\u4f7f\u7528\u9810\u8a13\u7df4\u7684\u6ce8\u610f\u529b\u6a21\u5f0f\uff08\u4e5f\n\u5c31\u662f\u5f15\u5c0e\u8cc7\u8a0a\u5982\u4f55\u5728\u7b26\u865f\u4e4b\u9593\u6d41\u52d5\uff09\u5c31\u8db3\u4ee5\u8b93\u6a21\u578b\u5f9e\u982d\u5b78\u7fd2\u9ad8\n\u54c1\u8cea\u7684\u7279\u5fb5\uff0c\u4e26\u9054\u6210\u76f8\u8fd1\u7684\u4e0b\u6e38\u6548\u80fd\u3002\u6211\u5011\u900f\u904e\u5f15\u5165\u4e00\u7a2e\u7a31\u70ba\u6ce8\n\u610f\u529b\u8f49\u79fb\u7684\u7c21\u55ae\u65b9\u6cd5\u4f86\u8b49\u660e\u9019\u4e00\u9ede\uff0c\u5176\u4e2d\u50c5\u5c07\u9810\u8a13\u7df4\u6559\u5e2b ViT \u7684\n\u6ce8\u610f\u529b\u6a21\u5f0f\u8f49\u79fb\u7d66\u5b78\u751f\uff0c\u65b9\u6cd5\u662f\u8907\u88fd\u6216\u8403\u53d6\u6ce8\u610f\u529b\u5716\u3002\u7531\u65bc\u6ce8\n\u610f\u529b\u8f49\u79fb\u8b93\u5b78\u751f\u5b78\u7fd2\u81ea\u5df1\u7684\u7279\u5fb5\uff0c\u56e0\u6b64\u5c07\u5176\u8207\u5fae\u8abf\u6559\u5e2b\u7d50\u5408\u4e5f\n\u9032\u4e00\u6b65\u63d0\u5347\u4e86 ImageNet \u7684\u6e96\u78ba\u5ea6\u3002\u6211\u5011\u7cfb\u7d71\u6027\u5730\u7814\u7a76\u4e86\u6211\u5011\u5728\n\u6ce8\u610f\u529b\u5716\u7684\u5145\u5206\u6027\u65b9\u9762\u7684\u767c\u73fe\u7684\u5404\u500b\u9762\u5411\uff0c\u5305\u62ec\u5b83\u5011\u8868\u73fe\u4e0d\u5982\u5fae\n\u8abf\u7684\u5206\u914d\u8f49\u79fb\u8a2d\u5b9a\u3002\u6211\u5011\u5e0c\u671b\u6211\u5011\u7684\u63a2\u7d22\u80fd\u63d0\u4f9b\u5c0d\u9810\u8a13\u7df4\u9054\u6210\n\u4ec0\u9ebc\u76ee\u6a19\u7684\u66f4\u6df1\u5165\u7406\u89e3\uff0c\u4e26\u63d0\u4f9b\u4e00\u7a2e\u6709\u7528\u7684\u66ff\u4ee3\u65b9\u6848\u4f86\u53d6\u4ee3\u5fae\u8abf\n\u7684\u6a19\u6e96\u505a\u6cd5", "author": "Alexander C. Li et.al.", "authors": "Alexander C. Li, Yuandong Tian, Beidi Chen, Deepak Pathak, Xinlei Chen", "id": "2411.09702v1", "paper_url": "http://arxiv.org/abs/2411.09702v1", "repo": "null"}}