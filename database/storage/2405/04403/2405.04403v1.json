{"2405.04403": {"publish_time": "2024-05-07", "title": "Learning To See But Forgetting To Follow: Visual Instruction Tuning Makes LLMs More Prone To Jailbreak Attacks", "paper_summary": "Augmenting Large Language Models (LLMs) with image-understanding capabilities\nhas resulted in a boom of high-performing Vision-Language models (VLMs). While\nstudying the alignment of LLMs to human values has received widespread\nattention, the safety of VLMs has not received the same attention. In this\npaper, we explore the impact of jailbreaking on three state-of-the-art VLMs,\neach using a distinct modeling approach. By comparing each VLM to their\nrespective LLM backbone, we find that each VLM is more susceptible to\njailbreaking. We consider this as an undesirable outcome from visual\ninstruction-tuning, which imposes a forgetting effect on an LLM's safety\nguardrails. Therefore, we provide recommendations for future work based on\nevaluation strategies that aim to highlight the weaknesses of a VLM, as well as\ntake safety measures into account during visual instruction tuning.", "paper_summary_zh": "\u64f4\u589e\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5f71\u50cf\u7406\u89e3\u80fd\u529b\uff0c\u5df2\u5c0e\u81f4\u9ad8\u6027\u80fd\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM) \u7684\u84ec\u52c3\u767c\u5c55\u3002\u5118\u7ba1\u7814\u7a76 LLM \u8207\u4eba\u985e\u50f9\u503c\u89c0\u7684\u4e00\u81f4\u6027\u5df2\u53d7\u5230\u5ee3\u6cdb\u95dc\u6ce8\uff0c\u4f46 VLM \u7684\u5b89\u5168\u6027\u5c1a\u672a\u7372\u5f97\u540c\u7b49\u7684\u95dc\u6ce8\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u8d8a\u7344\u5c0d\u4e09\u500b\u6700\u5148\u9032\u7684 VLM \u7684\u5f71\u97ff\uff0c\u6bcf\u500b VLM \u90fd\u4f7f\u7528\u4e0d\u540c\u7684\u5efa\u6a21\u65b9\u6cd5\u3002\u900f\u904e\u5c07\u6bcf\u500b VLM \u8207\u5176\u5404\u81ea\u7684 LLM \u4e3b\u5e79\u9032\u884c\u6bd4\u8f03\uff0c\u6211\u5011\u767c\u73fe\u6bcf\u500b VLM \u90fd\u66f4\u5bb9\u6613\u53d7\u5230\u8d8a\u7344\u7684\u5f71\u97ff\u3002\u6211\u5011\u5c07\u6b64\u8996\u70ba\u8996\u89ba\u6307\u4ee4\u8abf\u6574\u7684\u4e00\u500b\u4e0d\u826f\u7d50\u679c\uff0c\u9019\u5c0d LLM \u7684\u5b89\u5168\u9632\u8b77\u63aa\u65bd\u65bd\u52a0\u4e86\u907a\u5fd8\u6548\u61c9\u3002\u56e0\u6b64\uff0c\u6211\u5011\u6839\u64da\u8a55\u4f30\u7b56\u7565\u63d0\u4f9b\u672a\u4f86\u5de5\u4f5c\u7684\u5efa\u8b70\uff0c\u9019\u4e9b\u7b56\u7565\u65e8\u5728\u7a81\u986f VLM \u7684\u5f31\u9ede\uff0c\u4e26\u5728\u8996\u89ba\u6307\u4ee4\u8abf\u6574\u671f\u9593\u8003\u91cf\u5b89\u5168\u63aa\u65bd\u3002", "author": "Georgios Pantazopoulos et.al.", "authors": "Georgios Pantazopoulos, Amit Parekh, Malvina Nikandrou, Alessandro Suglia", "id": "2405.04403v1", "paper_url": "http://arxiv.org/abs/2405.04403v1", "repo": "https://github.com/gpantaz/vl_jailbreak"}}