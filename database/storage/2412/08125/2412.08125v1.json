{"2412.08125": {"publish_time": "2024-12-11", "title": "Progressive Multi-granular Alignments for Grounded Reasoning in Large Vision-Language Models", "paper_summary": "Existing Large Vision-Language Models (LVLMs) excel at matching concepts\nacross multi-modal inputs but struggle with compositional concepts and\nhigh-level relationships between entities. This paper introduces Progressive\nmulti-granular Vision-Language alignments (PromViL), a novel framework to\nenhance LVLMs' ability in performing grounded compositional visual reasoning\ntasks. Our approach constructs a hierarchical structure of multi-modal\nalignments, ranging from simple to complex concepts. By progressively aligning\ntextual descriptions with corresponding visual regions, our model learns to\nleverage contextual information from lower levels to inform higher-level\nreasoning. To facilitate this learning process, we introduce a data generation\nprocess that creates a novel dataset derived from Visual Genome, providing a\nwide range of nested compositional vision-language pairs. Experimental results\ndemonstrate that our PromViL framework significantly outperforms baselines on\nvarious visual grounding and compositional question answering tasks.", "paper_summary_zh": "\u73fe\u6709\u7684\u5927\u578b\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (LVLMs) \u64c5\u9577\u6bd4\u5c0d\u8de8\u591a\u6a21\u5f0f\u8f38\u5165\u7684\u6982\u5ff5\uff0c\u4f46\u5728\u7d44\u5408\u6982\u5ff5\u548c\u5be6\u9ad4\u4e4b\u9593\u7684\u9ad8\u5c64\u7d1a\u95dc\u4fc2\u4e0a\u537b\u6709\u56f0\u96e3\u3002\u672c\u6587\u4ecb\u7d39\u6f38\u9032\u5f0f\u591a\u7c92\u5ea6\u8996\u89ba\u8a9e\u8a00\u5c0d\u9f4a (PromViL)\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u67b6\u69cb\uff0c\u7528\u65bc\u589e\u5f37 LVLMs \u5728\u57f7\u884c\u57fa\u790e\u7d44\u5408\u8996\u89ba\u63a8\u7406\u4efb\u52d9\u7684\u80fd\u529b\u3002\u6211\u5011\u7684\u505a\u6cd5\u5efa\u69cb\u4e86\u4e00\u500b\u591a\u6a21\u5f0f\u5c0d\u9f4a\u7684\u5206\u5c64\u7d50\u69cb\uff0c\u5f9e\u7c21\u55ae\u5230\u8907\u96dc\u7684\u6982\u5ff5\u3002\u900f\u904e\u6f38\u9032\u5f0f\u5730\u5c07\u6587\u5b57\u63cf\u8ff0\u8207\u5c0d\u61c9\u7684\u8996\u89ba\u5340\u57df\u5c0d\u9f4a\uff0c\u6211\u5011\u7684\u6a21\u578b\u5b78\u7fd2\u5229\u7528\u8f03\u4f4e\u5c64\u7d1a\u7684\u8108\u7d61\u8cc7\u8a0a\uff0c\u4f86\u544a\u77e5\u8f03\u9ad8\u5c64\u7d1a\u7684\u63a8\u7406\u3002\u70ba\u4e86\u4fc3\u9032\u9019\u500b\u5b78\u7fd2\u904e\u7a0b\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u8cc7\u6599\u7522\u751f\u7a0b\u5e8f\uff0c\u9019\u500b\u7a0b\u5e8f\u6703\u5efa\u7acb\u4e00\u500b\u65b0\u7a4e\u7684\u8cc7\u6599\u96c6\uff0c\u884d\u751f\u81ea Visual Genome\uff0c\u63d0\u4f9b\u5ee3\u6cdb\u7684\u5d4c\u5957\u7d44\u5408\u8996\u89ba\u8a9e\u8a00\u914d\u5c0d\u3002\u5be6\u9a57\u7d50\u679c\u8b49\u660e\uff0c\u6211\u5011\u7684 PromViL \u67b6\u69cb\u5728\u5404\u7a2e\u8996\u89ba\u57fa\u790e\u548c\u7d44\u5408\u5f0f\u554f\u7b54\u4efb\u52d9\u4e0a\uff0c\u90fd\u986f\u8457\u512a\u65bc\u57fa\u6e96\u3002", "author": "Quang-Hung Le et.al.", "authors": "Quang-Hung Le, Long Hoang Dang, Ngan Le, Truyen Tran, Thao Minh Le", "id": "2412.08125v1", "paper_url": "http://arxiv.org/abs/2412.08125v1", "repo": "null"}}