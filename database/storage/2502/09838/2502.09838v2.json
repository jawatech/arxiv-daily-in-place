{"2502.09838": {"publish_time": "2025-02-14", "title": "HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation via Heterogeneous Knowledge Adaptation", "paper_summary": "We present HealthGPT, a powerful Medical Large Vision-Language Model\n(Med-LVLM) that integrates medical visual comprehension and generation\ncapabilities within a unified autoregressive paradigm. Our bootstrapping\nphilosophy is to progressively adapt heterogeneous comprehension and generation\nknowledge to pre-trained large language models (LLMs). This is achieved through\na novel heterogeneous low-rank adaptation (H-LoRA) technique, which is\ncomplemented by a tailored hierarchical visual perception approach and a\nthree-stage learning strategy. To effectively learn the HealthGPT, we devise a\ncomprehensive medical domain-specific comprehension and generation dataset\ncalled VL-Health. Experimental results demonstrate exceptional performance and\nscalability of HealthGPT in medical visual unified tasks. Our project can be\naccessed at https://github.com/DCDmllm/HealthGPT.", "paper_summary_zh": "\u6211\u5011\u63d0\u51fa HealthGPT\uff0c\u4e00\u7a2e\u5f37\u5927\u7684\u91ab\u5b78\u5927\u578b\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (Med-LVLM)\uff0c\u5b83\u6574\u5408\u4e86\u91ab\u5b78\u8996\u89ba\u7406\u89e3\u548c\u751f\u6210\u80fd\u529b\u65bc\u4e00\u500b\u7d71\u4e00\u7684\u81ea\u52d5\u8ff4\u6b78\u7bc4\u4f8b\u4e2d\u3002\u6211\u5011\u7684\u5f15\u5c0e\u54f2\u5b78\u662f\u9010\u6b65\u8abf\u6574\u7570\u8cea\u7406\u89e3\u548c\u751f\u6210\u77e5\u8b58\u4ee5\u9810\u5148\u8a13\u7df4\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\u3002\u9019\u662f\u901a\u904e\u4e00\u7a2e\u65b0\u7a4e\u7684\u7570\u8cea\u4f4e\u79e9\u9069\u61c9 (H-LoRA) \u6280\u8853\u5be6\u73fe\u7684\uff0c\u8a72\u6280\u8853\u7531\u91cf\u8eab\u5b9a\u5236\u7684\u5206\u5c64\u8996\u89ba\u611f\u77e5\u65b9\u6cd5\u548c\u4e09\u968e\u6bb5\u5b78\u7fd2\u7b56\u7565\u88dc\u5145\u3002\u70ba\u4e86\u6709\u6548\u5b78\u7fd2 HealthGPT\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u5168\u9762\u7684\u91ab\u5b78\u9818\u57df\u7279\u5b9a\u7406\u89e3\u548c\u751f\u6210\u6578\u64da\u96c6\uff0c\u7a31\u70ba VL-Health\u3002\u5be6\u9a57\u7d50\u679c\u8b49\u660e\u4e86 HealthGPT \u5728\u91ab\u5b78\u8996\u89ba\u7d71\u4e00\u4efb\u52d9\u4e2d\u7684\u5353\u8d8a\u6027\u80fd\u548c\u53ef\u64f4\u5c55\u6027\u3002\u6211\u5011\u7684\u9805\u76ee\u53ef\u4ee5\u5728 https://github.com/DCDmllm/HealthGPT \u4e2d\u8a2a\u554f\u3002", "author": "Tianwei Lin et.al.", "authors": "Tianwei Lin, Wenqiao Zhang, Sijing Li, Yuqian Yuan, Binhe Yu, Haoyuan Li, Wanggui He, Hao Jiang, Mengze Li, Xiaohui Song, Siliang Tang, Jun Xiao, Hui Lin, Yueting Zhuang, Beng Chin Ooi", "id": "2502.09838v2", "paper_url": "http://arxiv.org/abs/2502.09838v2", "repo": "null"}}