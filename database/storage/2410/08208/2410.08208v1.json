{"2410.08208": {"publish_time": "2024-10-10", "title": "SPA: 3D Spatial-Awareness Enables Effective Embodied Representation", "paper_summary": "In this paper, we introduce SPA, a novel representation learning framework\nthat emphasizes the importance of 3D spatial awareness in embodied AI. Our\napproach leverages differentiable neural rendering on multi-view images to\nendow a vanilla Vision Transformer (ViT) with intrinsic spatial understanding.\nWe present the most comprehensive evaluation of embodied representation\nlearning to date, covering 268 tasks across 8 simulators with diverse policies\nin both single-task and language-conditioned multi-task scenarios. The results\nare compelling: SPA consistently outperforms more than 10 state-of-the-art\nrepresentation methods, including those specifically designed for embodied AI,\nvision-centric tasks, and multi-modal applications, while using less training\ndata. Furthermore, we conduct a series of real-world experiments to confirm its\neffectiveness in practical scenarios. These results highlight the critical role\nof 3D spatial awareness for embodied representation learning. Our strongest\nmodel takes more than 6000 GPU hours to train and we are committed to\nopen-sourcing all code and model weights to foster future research in embodied\nrepresentation learning. Project Page: https://haoyizhu.github.io/spa/.", "paper_summary_zh": "<paragraph>\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39 SPA\uff0c\u4e00\u7a2e\u65b0\u7a4e\u7684\u8868\u5fb5\u5b78\u7fd2\u6846\u67b6\uff0c\u5f37\u8abf\u4e86 3D \u7a7a\u9593\u611f\u77e5\u5728\u5177\u8eab AI \u4e2d\u7684\u91cd\u8981\u6027\u3002\u6211\u5011\u7684\u505a\u6cd5\u5229\u7528\u591a\u8996\u5716\u5f71\u50cf\u4e0a\u7684\u53ef\u5fae\u5206\u795e\u7d93\u6e32\u67d3\uff0c\u8ce6\u4e88 vanilla \u8996\u89ba Transformer (ViT) \u5167\u5728\u7684\u7a7a\u9593\u7406\u89e3\u3002\u6211\u5011\u5c55\u793a\u4e86\u8fc4\u4eca\u70ba\u6b62\u6700\u5168\u9762\u7684\u5177\u8eab\u8868\u5fb5\u5b78\u7fd2\u8a55\u4f30\uff0c\u6db5\u84cb\u4e86 8 \u500b\u6a21\u64ec\u5668\u4e2d\u7684 268 \u500b\u4efb\u52d9\uff0c\u5728\u55ae\u4e00\u4efb\u52d9\u548c\u8a9e\u8a00\u689d\u4ef6\u7684\u591a\u4efb\u52d9\u5834\u666f\u4e2d\u63a1\u7528\u4e0d\u540c\u7684\u7b56\u7565\u3002\u7d50\u679c\u4ee4\u4eba\u4fe1\u670d\uff1aSPA \u6301\u7e8c\u512a\u65bc 10 \u7a2e\u4ee5\u4e0a\u7684\u6700\u65b0\u8868\u5fb5\u65b9\u6cd5\uff0c\u5305\u62ec\u5c08\u9580\u70ba\u5177\u8eab AI\u3001\u4ee5\u8996\u89ba\u70ba\u4e2d\u5fc3\u7684\u4efb\u52d9\u548c\u591a\u6a21\u614b\u61c9\u7528\u7a0b\u5f0f\u8a2d\u8a08\u7684\u65b9\u6cd5\uff0c\u540c\u6642\u4f7f\u7528\u8f03\u5c11\u7684\u8a13\u7df4\u8cc7\u6599\u3002\u6b64\u5916\uff0c\u6211\u5011\u9032\u884c\u4e86\u4e00\u7cfb\u5217\u771f\u5be6\u4e16\u754c\u7684\u5be6\u9a57\uff0c\u4ee5\u78ba\u8a8d\u5176\u5728\u5be6\u969b\u5834\u666f\u4e2d\u7684\u6709\u6548\u6027\u3002\u9019\u4e9b\u7d50\u679c\u7a81\u51fa\u4e86 3D \u7a7a\u9593\u611f\u77e5\u5c0d\u65bc\u5177\u8eab\u8868\u5fb5\u5b78\u7fd2\u7684\u95dc\u9375\u4f5c\u7528\u3002\u6211\u5011\u6700\u5f37\u5927\u7684\u6a21\u578b\u9700\u8981\u8d85\u904e 6000 \u500b GPU \u5c0f\u6642\u624d\u80fd\u8a13\u7df4\uff0c\u6211\u5011\u81f4\u529b\u65bc\u958b\u653e\u539f\u59cb\u78bc\u548c\u6240\u6709\u6a21\u578b\u6b0a\u91cd\uff0c\u4ee5\u4fc3\u9032\u5177\u8eab\u8868\u5fb5\u5b78\u7fd2\u7684\u672a\u4f86\u7814\u7a76\u3002\u5c08\u6848\u9801\u9762\uff1ahttps://haoyizhu.github.io/spa/\u3002</paragraph>", "author": "Haoyi Zhu et.al.", "authors": "Haoyi Zhu, Honghui Yang, Yating Wang, Jiange Yang, Limin Wang, Tong He", "id": "2410.08208v1", "paper_url": "http://arxiv.org/abs/2410.08208v1", "repo": "null"}}