{"2502.13137": {"publish_time": "2025-02-18", "title": "Theorem Prover as a Judge for Synthetic Data Generation", "paper_summary": "The demand for synthetic data in mathematical reasoning has increased due to\nits potential to enhance the mathematical capabilities of large language models\n(LLMs). However, ensuring the validity of intermediate reasoning steps remains\na significant challenge, affecting data quality. While formal verification via\ntheorem provers effectively validates LLM reasoning, the autoformalisation of\nmathematical proofs remains error-prone. In response, we introduce iterative\nautoformalisation, an approach that iteratively refines theorem prover\nformalisation to mitigate errors, thereby increasing the execution rate on the\nLean prover from 60% to 87%. Building upon that, we introduce Theorem Prover as\na Judge (TP-as-a-Judge), a method that employs theorem prover formalisation to\nrigorously assess LLM intermediate reasoning, effectively integrating\nautoformalisation with synthetic data generation. Finally, we present\nReinforcement Learning from Theorem Prover Feedback (RLTPF), a framework that\nreplaces human annotation with theorem prover feedback in Reinforcement\nLearning from Human Feedback (RLHF). Across multiple LLMs, applying\nTP-as-a-Judge and RLTPF improves benchmarks with only 3,508 samples, achieving\n5.56% accuracy gain on Mistral-7B for MultiArith, 6.00% on Llama-2-7B for\nSVAMP, and 3.55% on Llama-3.1-8B for AQUA.", "paper_summary_zh": "<paragraph>\u7531\u65bc\u5408\u6210\u8cc7\u6599\u5728\u6578\u5b78\u63a8\u7406\u4e2d\u5177\u6709\u589e\u5f37\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6578\u5b78\u80fd\u529b\u7684\u6f5b\u529b\uff0c\u5c0d\u5408\u6210\u8cc7\u6599\u7684\u9700\u6c42\u5df2\u589e\u52a0\u3002\u7136\u800c\uff0c\u78ba\u4fdd\u4e2d\u9593\u63a8\u7406\u6b65\u9a5f\u7684\u6709\u6548\u6027\u4ecd\u7136\u662f\u4e00\u9805\u91cd\u5927\u7684\u6311\u6230\uff0c\u5f71\u97ff\u8cc7\u6599\u54c1\u8cea\u3002\u96d6\u7136\u900f\u904e\u5b9a\u7406\u8b49\u660e\u5668\u9032\u884c\u5f62\u5f0f\u9a57\u8b49\u53ef\u6709\u6548\u9a57\u8b49 LLM \u63a8\u7406\uff0c\u4f46\u6578\u5b78\u8b49\u660e\u81ea\u52d5\u5f62\u5f0f\u5316\u4ecd\u7136\u5bb9\u6613\u51fa\u932f\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86\u8fed\u4ee3\u81ea\u52d5\u5f62\u5f0f\u5316\uff0c\u9019\u662f\u4e00\u7a2e\u8fed\u4ee3\u512a\u5316\u5b9a\u7406\u8b49\u660e\u5668\u5f62\u5f0f\u5316\u4ee5\u6e1b\u5c11\u932f\u8aa4\u7684\u65b9\u6cd5\uff0c\u5f9e\u800c\u5c07 Lean \u8b49\u660e\u5668\u7684\u57f7\u884c\u7387\u5f9e 60% \u63d0\u9ad8\u5230 87%\u3002\u5728\u6b64\u57fa\u790e\u4e0a\uff0c\u6211\u5011\u5f15\u5165\u4e86\u5b9a\u7406\u8b49\u660e\u5668\u4f5c\u70ba\u8a55\u5be9 (TP-as-a-Judge)\uff0c\u9019\u662f\u4e00\u7a2e\u63a1\u7528\u5b9a\u7406\u8b49\u660e\u5668\u5f62\u5f0f\u5316\u4f86\u56b4\u683c\u8a55\u4f30 LLM \u4e2d\u9593\u63a8\u7406\u7684\u65b9\u6cd5\uff0c\u6709\u6548\u5730\u5c07\u81ea\u52d5\u5f62\u5f0f\u5316\u8207\u5408\u6210\u8cc7\u6599\u7522\u751f\u6574\u5408\u3002\u6700\u5f8c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u5b9a\u7406\u8b49\u660e\u5668\u56de\u994b\u5f37\u5316\u5b78\u7fd2 (RLTPF)\uff0c\u9019\u662f\u4e00\u500b\u6846\u67b6\uff0c\u7528\u5b9a\u7406\u8b49\u660e\u5668\u56de\u994b\u53d6\u4ee3\u4eba\u985e\u6a19\u8a3b\uff0c\u4ee5\u9032\u884c\u4eba\u985e\u56de\u994b\u5f37\u5316\u5b78\u7fd2 (RLHF)\u3002\u5728\u591a\u500b LLM \u4e2d\uff0c\u61c9\u7528 TP-as-a-Judge \u548c RLTPF \u53ef\u900f\u904e\u50c5 3,508 \u500b\u6a23\u672c\u6539\u5584\u57fa\u6e96\uff0c\u5728 MultiArith \u4e0a\u7372\u5f97 5.56% \u7684\u6e96\u78ba\u5ea6\u63d0\u5347\uff0c\u5728 SVAMP \u4e0a\u7372\u5f97 Llama-2-7B \u7684 6.00% \u63d0\u5347\uff0c\u5728 AQUA \u4e0a\u7372\u5f97 Llama-3.1-8B \u7684 3.55% \u63d0\u5347\u3002</paragraph>", "author": "Joshua Ong Jun Leang et.al.", "authors": "Joshua Ong Jun Leang, Giwon Hong, Wenda Li, Shay B. Cohen", "id": "2502.13137v1", "paper_url": "http://arxiv.org/abs/2502.13137v1", "repo": "null"}}