{"2502.14777": {"publish_time": "2025-02-20", "title": "Making Universal Policies Universal", "paper_summary": "The development of a generalist agent capable of solving a wide range of\nsequential decision-making tasks remains a significant challenge. We address\nthis problem in a cross-agent setup where agents share the same observation\nspace but differ in their action spaces. Our approach builds on the universal\npolicy framework, which decouples policy learning into two stages: a\ndiffusion-based planner that generates observation sequences and an inverse\ndynamics model that assigns actions to these plans. We propose a method for\ntraining the planner on a joint dataset composed of trajectories from all\nagents. This method offers the benefit of positive transfer by pooling data\nfrom different agents, while the primary challenge lies in adapting shared\nplans to each agent's unique constraints. We evaluate our approach on the\nBabyAI environment, covering tasks of varying complexity, and demonstrate\npositive transfer across agents. Additionally, we examine the planner's\ngeneralisation ability to unseen agents and compare our method to traditional\nimitation learning approaches. By training on a pooled dataset from multiple\nagents, our universal policy achieves an improvement of up to $42.20\\%$ in task\ncompletion accuracy compared to a policy trained on a dataset from a single\nagent.", "paper_summary_zh": "\u958b\u767c\u4e00\u7a2e\u80fd\u5920\u89e3\u6c7a\u5ee3\u6cdb\u9806\u5e8f\u6c7a\u7b56\u4efb\u52d9\u7684\u901a\u624d\u4ee3\u7406\u4ecd\u7136\u662f\u4e00\u9805\u91cd\u5927\u6311\u6230\u3002\u6211\u5011\u5728\u8de8\u4ee3\u7406\u8a2d\u7f6e\u4e2d\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u5176\u4e2d\u4ee3\u7406\u5171\u4eab\u76f8\u540c\u7684\u89c0\u5bdf\u7a7a\u9593\uff0c\u4f46\u5728\u5176\u52d5\u4f5c\u7a7a\u9593\u4e2d\u6709\u6240\u4e0d\u540c\u3002\u6211\u5011\u7684\u505a\u6cd5\u5efa\u7acb\u5728\u901a\u7528\u7b56\u7565\u6846\u67b6\u4e4b\u4e0a\uff0c\u8a72\u6846\u67b6\u5c07\u7b56\u7565\u5b78\u7fd2\u89e3\u8026\u70ba\u5169\u500b\u968e\u6bb5\uff1a\u751f\u6210\u89c0\u5bdf\u5e8f\u5217\u7684\u57fa\u65bc\u64f4\u6563\u7684\u898f\u5283\u5668\u548c\u5c07\u52d5\u4f5c\u5206\u914d\u7d66\u9019\u4e9b\u8a08\u5283\u7684\u9006\u52d5\u614b\u6a21\u578b\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u5728\u7531\u6240\u6709\u4ee3\u7406\u7684\u8ecc\u8de1\u7d44\u6210\u7684\u806f\u5408\u6578\u64da\u96c6\u4e0a\u8a13\u7df4\u898f\u5283\u5668\u7684\u65b9\u6cd5\u3002\u9019\u7a2e\u65b9\u6cd5\u63d0\u4f9b\u4e86\u901a\u904e\u5f59\u7e3d\u4f86\u81ea\u4e0d\u540c\u4ee3\u7406\u7684\u6578\u64da\u4f86\u9032\u884c\u6b63\u5411\u50b3\u8f38\u7684\u597d\u8655\uff0c\u800c\u4e3b\u8981\u7684\u6311\u6230\u5728\u65bc\u5c07\u5171\u4eab\u8a08\u5283\u9069\u61c9\u65bc\u6bcf\u500b\u4ee3\u7406\u7684\u552f\u4e00\u7d04\u675f\u3002\u6211\u5011\u5728 BabyAI \u74b0\u5883\u4e2d\u8a55\u4f30\u4e86\u6211\u5011\u7684\u505a\u6cd5\uff0c\u6db5\u84cb\u4e86\u4e0d\u540c\u8907\u96dc\u7a0b\u5ea6\u7684\u4efb\u52d9\uff0c\u4e26\u5c55\u793a\u4e86\u8de8\u4ee3\u7406\u7684\u6b63\u5411\u50b3\u8f38\u3002\u6b64\u5916\uff0c\u6211\u5011\u6aa2\u67e5\u4e86\u898f\u5283\u5668\u5c0d\u672a\u898b\u4ee3\u7406\u7684\u6982\u62ec\u80fd\u529b\uff0c\u4e26\u5c07\u6211\u5011\u7684\u505a\u6cd5\u8207\u50b3\u7d71\u7684\u6a21\u4eff\u5b78\u7fd2\u65b9\u6cd5\u9032\u884c\u4e86\u6bd4\u8f03\u3002\u901a\u904e\u5728\u4f86\u81ea\u591a\u500b\u4ee3\u7406\u7684\u5f59\u7e3d\u6578\u64da\u96c6\u4e0a\u9032\u884c\u8a13\u7df4\uff0c\u6211\u5011\u7684\u901a\u7528\u7b56\u7565\u5728\u4efb\u52d9\u5b8c\u6210\u6e96\u78ba\u5ea6\u65b9\u9762\u5be6\u73fe\u4e86\u9ad8\u9054 42.20% \u7684\u6539\u9032\uff0c\u800c\u5f9e\u55ae\u500b\u4ee3\u7406\u7684\u6578\u64da\u96c6\u4e0a\u8a13\u7df4\u7684\u7b56\u7565\u3002", "author": "Niklas H\u00f6pner et.al.", "authors": "Niklas H\u00f6pner, David Kuric, Herke van Hoof", "id": "2502.14777v1", "paper_url": "http://arxiv.org/abs/2502.14777v1", "repo": "null"}}