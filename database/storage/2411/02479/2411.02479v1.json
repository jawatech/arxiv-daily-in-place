{"2411.02479": {"publish_time": "2024-11-04", "title": "Digitizing Touch with an Artificial Multimodal Fingertip", "paper_summary": "Touch is a crucial sensing modality that provides rich information about\nobject properties and interactions with the physical environment. Humans and\nrobots both benefit from using touch to perceive and interact with the\nsurrounding environment (Johansson and Flanagan, 2009; Li et al., 2020;\nCalandra et al., 2017). However, no existing systems provide rich, multi-modal\ndigital touch-sensing capabilities through a hemispherical compliant\nembodiment. Here, we describe several conceptual and technological innovations\nto improve the digitization of touch. These advances are embodied in an\nartificial finger-shaped sensor with advanced sensing capabilities.\nSignificantly, this fingertip contains high-resolution sensors (~8.3 million\ntaxels) that respond to omnidirectional touch, capture multi-modal signals, and\nuse on-device artificial intelligence to process the data in real time.\nEvaluations show that the artificial fingertip can resolve spatial features as\nsmall as 7 um, sense normal and shear forces with a resolution of 1.01 mN and\n1.27 mN, respectively, perceive vibrations up to 10 kHz, sense heat, and even\nsense odor. Furthermore, it embeds an on-device AI neural network accelerator\nthat acts as a peripheral nervous system on a robot and mimics the reflex arc\nfound in humans. These results demonstrate the possibility of digitizing touch\nwith superhuman performance. The implications are profound, and we anticipate\npotential applications in robotics (industrial, medical, agricultural, and\nconsumer-level), virtual reality and telepresence, prosthetics, and e-commerce.\nToward digitizing touch at scale, we open-source a modular platform to\nfacilitate future research on the nature of touch.", "paper_summary_zh": "\u89f8\u89ba\u662f\u4e00\u7a2e\u81f3\u95dc\u91cd\u8981\u7684\u611f\u6e2c\u65b9\u5f0f\uff0c\u53ef\u63d0\u4f9b\u95dc\u65bc\u7269\u9ad4\u5c6c\u6027\u548c\u8207\u7269\u7406\u74b0\u5883\u4ea4\u4e92\u4f5c\u7528\u7684\u8c50\u5bcc\u8cc7\u8a0a\u3002\u4eba\u985e\u548c\u6a5f\u5668\u4eba\u90fd\u53d7\u76ca\u65bc\u4f7f\u7528\u89f8\u89ba\u4f86\u611f\u77e5\u548c\u8207\u5468\u570d\u74b0\u5883\u4e92\u52d5\uff08Johansson and Flanagan, 2009; Li et al., 2020; Calandra et al., 2017\uff09\u3002\u7136\u800c\uff0c\u6c92\u6709\u73fe\u6709\u7cfb\u7d71\u900f\u904e\u534a\u7403\u5f62\u9806\u61c9\u6027\u5177\u8eab\u5316\u63d0\u4f9b\u8c50\u5bcc\u7684\u591a\u6a21\u5f0f\u6578\u4f4d\u89f8\u89ba\u611f\u6e2c\u529f\u80fd\u3002\u5728\u6b64\uff0c\u6211\u5011\u63cf\u8ff0\u4e86\u5e7e\u500b\u6982\u5ff5\u548c\u6280\u8853\u5275\u65b0\uff0c\u4ee5\u6539\u5584\u89f8\u89ba\u7684\u6578\u4f4d\u5316\u3002\u9019\u4e9b\u9032\u5c55\u9ad4\u73fe\u5728\u5177\u5099\u5148\u9032\u611f\u6e2c\u529f\u80fd\u7684\u4eba\u5de5\u624b\u6307\u5f62\u611f\u6e2c\u5668\u4e2d\u3002\u91cd\u8981\u7684\u662f\uff0c\u9019\u500b\u6307\u5c16\u5305\u542b\u9ad8\u89e3\u6790\u5ea6\u611f\u6e2c\u5668\uff08\u7d04 830 \u842c\u500b\u89f8\u89ba\u9ede\uff09\uff0c\u53ef\u5c0d\u5168\u65b9\u4f4d\u89f8\u89ba\u505a\u51fa\u53cd\u61c9\u3001\u64f7\u53d6\u591a\u6a21\u5f0f\u8a0a\u865f\uff0c\u4e26\u4f7f\u7528\u88dd\u7f6e\u4e0a\u7684\u4eba\u5de5\u667a\u6167\u5373\u6642\u8655\u7406\u8cc7\u6599\u3002\u8a55\u4f30\u986f\u793a\uff0c\u4eba\u5de5\u6307\u5c16\u53ef\u4ee5\u89e3\u6790\u5c0f\u81f3 7 \u5fae\u7c73\u7684\u7a7a\u9593\u7279\u5fb5\uff0c\u4ee5 1.01 \u6beb\u725b\u9813\u548c 1.27 \u6beb\u725b\u9813\u7684\u89e3\u6790\u5ea6\u611f\u6e2c\u6cd5\u5411\u529b\u548c\u526a\u5207\u529b\uff0c\u611f\u77e5\u9ad8\u9054 10 \u5343\u8d6b\u7684\u632f\u52d5\u3001\u611f\u6e2c\u71b1\uff0c\u751a\u81f3\u611f\u6e2c\u6c23\u5473\u3002\u6b64\u5916\uff0c\u5b83\u5167\u5d4c\u4e86\u4e00\u500b\u88dd\u7f6e\u4e0a\u7684 AI \u795e\u7d93\u7db2\u8def\u52a0\u901f\u5668\uff0c\u4f5c\u70ba\u6a5f\u5668\u4eba\u7684\u5468\u908a\u795e\u7d93\u7cfb\u7d71\uff0c\u4e26\u6a21\u4eff\u4eba\u985e\u7684\u53cd\u5c04\u5f27\u3002\u9019\u4e9b\u7d50\u679c\u8b49\u660e\u4e86\u4ee5\u8d85\u4eba\u985e\u6548\u80fd\u6578\u4f4d\u5316\u89f8\u89ba\u7684\u53ef\u80fd\u6027\u3002\u5176\u5f71\u97ff\u6df1\u9060\uff0c\u6211\u5011\u9810\u671f\u5728\u6a5f\u5668\u4eba\u6280\u8853\uff08\u5de5\u696d\u3001\u91ab\u7642\u3001\u8fb2\u696d\u548c\u6d88\u8cbb\u8005\u5c64\u7d1a\uff09\u3001\u865b\u64ec\u5be6\u5883\u548c\u9060\u8ddd\u81e8\u5834\u3001\u5047\u80a2\u548c\u96fb\u5b50\u5546\u52d9\u4e2d\u6f5b\u5728\u7684\u61c9\u7528\u3002\u70ba\u4e86\u5927\u898f\u6a21\u6578\u4f4d\u5316\u89f8\u89ba\uff0c\u6211\u5011\u958b\u653e\u539f\u59cb\u78bc\u4e00\u500b\u6a21\u7d44\u5316\u5e73\u53f0\uff0c\u4ee5\u4fc3\u9032\u672a\u4f86\u5c0d\u89f8\u89ba\u672c\u8cea\u7684\u7814\u7a76\u3002", "author": "Mike Lambeta et.al.", "authors": "Mike Lambeta, Tingfan Wu, Ali Sengul, Victoria Rose Most, Nolan Black, Kevin Sawyer, Romeo Mercado, Haozhi Qi, Alexander Sohn, Byron Taylor, Norb Tydingco, Gregg Kammerer, Dave Stroud, Jake Khatha, Kurt Jenkins, Kyle Most, Neal Stein, Ricardo Chavira, Thomas Craven-Bartle, Eric Sanchez, Yitian Ding, Jitendra Malik, Roberto Calandra", "id": "2411.02479v1", "paper_url": "http://arxiv.org/abs/2411.02479v1", "repo": "https://github.com/facebookresearch/digit360"}}