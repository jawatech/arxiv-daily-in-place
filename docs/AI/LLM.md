
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-06-06**|**Verbalized Machine Learning: Revisiting Machine Learning with Language Models**|Tim Z. Xiao et.al.|[2406.04344v1](http://arxiv.org/abs/2406.04344v1)|null|
|**2024-06-06**|**Physics3D: Learning Physical Properties of 3D Gaussians via Video Diffusion**|Fangfu Liu et.al.|[2406.04338v2](http://arxiv.org/abs/2406.04338v2)|null|
|**2024-06-06**|**Coherent Zero-Shot Visual Instruction Generation**|Quynh Phung et.al.|[2406.04337v1](http://arxiv.org/abs/2406.04337v1)|null|
|**2024-06-06**|**PaCE: Parsimonious Concept Engineering for Large Language Models**|Jinqi Luo et.al.|[2406.04331v1](http://arxiv.org/abs/2406.04331v1)|[link](https://github.com/peterljq/parsimonious-concept-engineering)|
|**2024-06-06**|**ATraDiff: Accelerating Online Reinforcement Learning with Imaginary Trajectories**|Qianlan Yang et.al.|[2406.04323v1](http://arxiv.org/abs/2406.04323v1)|null|
|**2024-06-06**|**Chimera: Effectively Modeling Multivariate Time Series with 2-Dimensional State Space Models**|Ali Behrouz et.al.|[2406.04320v1](http://arxiv.org/abs/2406.04320v1)|null|
|**2024-06-06**|**Improving Alignment and Robustness with Short Circuiting**|Andy Zou et.al.|[2406.04313v1](http://arxiv.org/abs/2406.04313v1)|[link](https://github.com/blackswan-ai/short-circuiting)|
|**2024-06-06**|**Semantically Diverse Language Generation for Uncertainty Estimation in Language Models**|Lukas Aichberger et.al.|[2406.04306v1](http://arxiv.org/abs/2406.04306v1)|[link](https://github.com/ml-jku/SDLG)|
|**2024-06-06**|**Vision-LSTM: xLSTM as Generic Vision Backbone**|Benedikt Alkin et.al.|[2406.04303v1](http://arxiv.org/abs/2406.04303v1)|null|
|**2024-06-06**|**VISTA: Visualized Text Embedding For Universal Multi-Modal Retrieval**|Junjie Zhou et.al.|[2406.04292v1](http://arxiv.org/abs/2406.04292v1)|[link](https://github.com/flagopen/flagembedding)|
|**2024-06-06**|**What Languages are Easy to Language-Model? A Perspective from Learning Probabilistic Regular Languages**|Nadav Borenstein et.al.|[2406.04289v2](http://arxiv.org/abs/2406.04289v2)|null|
|**2024-06-06**|**ABEX: Data Augmentation for Low-Resource NLU via Expanding Abstract Descriptions**|Sreyan Ghosh et.al.|[2406.04286v1](http://arxiv.org/abs/2406.04286v1)|[link](https://github.com/sreyan88/abex)|
|**2024-06-06**|**Characterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People**|Dun-Ming Huang et.al.|[2406.04278v1](http://arxiv.org/abs/2406.04278v1)|[link](https://github.com/jacobyn/SamplingTonesACL)|
|**2024-06-06**|**Generative AI-in-the-loop: Integrating LLMs and GPTs into the Next Generation Networks**|Han Zhang et.al.|[2406.04276v1](http://arxiv.org/abs/2406.04276v1)|null|
|**2024-06-06**|**Self-Play with Adversarial Critic: Provable and Scalable Offline Alignment for Language Models**|Xiang Ji et.al.|[2406.04274v1](http://arxiv.org/abs/2406.04274v1)|null|
|**2024-06-06**|**Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models**|Ling Yang et.al.|[2406.04271v1](http://arxiv.org/abs/2406.04271v1)|[link](https://github.com/yangling0818/buffer-of-thought-llm)|
|**2024-06-06**|**Open-Endedness is Essential for Artificial Superhuman Intelligence**|Edward Hughes et.al.|[2406.04268v1](http://arxiv.org/abs/2406.04268v1)|null|
|**2024-06-06**|**Transformers need glasses! Information over-squashing in language tasks**|Federico Barbero et.al.|[2406.04267v1](http://arxiv.org/abs/2406.04267v1)|null|
|**2024-06-06**|**MLVU: A Comprehensive Benchmark for Multi-Task Long Video Understanding**|Junjie Zhou et.al.|[2406.04264v1](http://arxiv.org/abs/2406.04264v1)|null|
|**2024-06-06**|**GeoGen: Geometry-Aware Generative Modeling via Signed Distance Functions**|Salvatore Esposito et.al.|[2406.04254v2](http://arxiv.org/abs/2406.04254v2)|null|
|**2024-06-06**|**Benchmark Data Contamination of Large Language Models: A Survey**|Cheng Xu et.al.|[2406.04244v1](http://arxiv.org/abs/2406.04244v1)|null|
|**2024-06-06**|**Hypernetworks for Personalizing ASR to Atypical Speech**|Max Mueller-Eberstein et.al.|[2406.04240v2](http://arxiv.org/abs/2406.04240v2)|null|
|**2024-06-06**|**FairytaleQA Translated: Enabling Educational Question and Answer Generation in Less-Resourced Languages**|Bernardo Leite et.al.|[2406.04233v1](http://arxiv.org/abs/2406.04233v1)|[link](https://github.com/bernardoleite/fairytaleqa-translated)|
|**2024-06-06**|**Quantifying Misalignment Between Agents**|Aidan Kierans et.al.|[2406.04231v1](http://arxiv.org/abs/2406.04231v1)|null|
|**2024-06-06**|**M3LEO: A Multi-Modal, Multi-Label Earth Observation Dataset Integrating Interferometric SAR and RGB Data**|Matthew J Allen et.al.|[2406.04230v1](http://arxiv.org/abs/2406.04230v1)|[link](https://github.com/spaceml-org/m3leo)|
|**2024-06-06**|**The CLRS-Text Algorithmic Reasoning Language Benchmark**|Larisa Markeeva et.al.|[2406.04229v1](http://arxiv.org/abs/2406.04229v1)|[link](https://github.com/google-deepmind/clrs)|
|**2024-06-06**|**BEADs: Bias Evaluation Across Domains**|Shaina Raza et.al.|[2406.04220v2](http://arxiv.org/abs/2406.04220v2)|null|
|**2024-06-06**|**Rethinking LLM and Linguistic Steganalysis: An Efficient Detection of Strongly Concealed Stego**|Yifan Tang et.al.|[2406.04218v1](http://arxiv.org/abs/2406.04218v1)|null|
|**2024-06-06**|**What Do Language Models Learn in Context? The Structured Task Hypothesis**|Jiaoda Li et.al.|[2406.04216v1](http://arxiv.org/abs/2406.04216v1)|null|
|**2024-06-06**|**mCSQA: Multilingual Commonsense Reasoning Dataset with Unified Creation Strategy by Language Models and Humans**|Yusuke Sakai et.al.|[2406.04215v1](http://arxiv.org/abs/2406.04215v1)|null|
|**2024-06-06**|**ValueBench: Towards Comprehensively Evaluating Value Orientations and Understanding of Large Language Models**|Yuanyi Ren et.al.|[2406.04214v1](http://arxiv.org/abs/2406.04214v1)|[link](https://github.com/value4ai/valuebench)|
|**2024-06-06**|**Aligning Agents like Large Language Models**|Adam Jelley et.al.|[2406.04208v1](http://arxiv.org/abs/2406.04208v1)|null|
|**2024-06-06**|**Legal Documents Drafting with Fine-Tuned Pre-Trained Large Language Model**|Chun-Hsien Lin et.al.|[2406.04202v1](http://arxiv.org/abs/2406.04202v1)|[link](https://huggingface.co/jslin09/bloom-560m-finetuned-fraud)|
|**2024-06-06**|**DICE: Detecting In-distribution Contamination in LLM's Fine-tuning Phase for Math Reasoning**|Shangqing Tu et.al.|[2406.04197v1](http://arxiv.org/abs/2406.04197v1)|[link](https://github.com/thu-keg/dice)|
|**2024-06-06**|**Shield Synthesis for LTL Modulo Theories**|Andoni Rodriguez et.al.|[2406.04184v1](http://arxiv.org/abs/2406.04184v1)|null|
|**2024-06-06**|**Confabulation: The Surprising Value of Large Language Model Hallucinations**|Peiqi Sui et.al.|[2406.04175v1](http://arxiv.org/abs/2406.04175v1)|null|
|**2024-06-06**|**Pointer-Guided Pre-Training: Infusing Large Language Models with Paragraph-Level Contextual Awareness**|Lars Hillebrand et.al.|[2406.04156v1](http://arxiv.org/abs/2406.04156v1)|[link](https://github.com/LarsHill/pointer-guided-pre-training)|
|**2024-06-06**|**AgentGym: Evolving Large Language Model-based Agents across Diverse Environments**|Zhiheng Xi et.al.|[2406.04151v1](http://arxiv.org/abs/2406.04151v1)|[link](https://github.com/woooodyy/agentgym)|
|**2024-06-06**|**Characterizing segregation in blast rock piles a deep-learning approach leveraging aerial image analysis**|Chengeng Liu et.al.|[2406.04149v1](http://arxiv.org/abs/2406.04149v1)|null|
|**2024-06-06**|**Towards Understanding Task-agnostic Debiasing Through the Lenses of Intrinsic Bias and Forgetfulness**|Guangliang Liu et.al.|[2406.04146v1](http://arxiv.org/abs/2406.04146v1)|null|
|**2024-06-06**|**Every Answer Matters: Evaluating Commonsense with Probabilistic Measures**|Qi Cheng et.al.|[2406.04145v1](http://arxiv.org/abs/2406.04145v1)|null|
|**2024-06-06**|**Do Language Models Understand Morality? Towards a Robust Detection of Moral Content**|Luana Bulla et.al.|[2406.04143v1](http://arxiv.org/abs/2406.04143v1)|[link](https://github.com/LuanaBulla/Detection-of-Morality-in-Text)|
|**2024-06-06**|**Legal Judgment Reimagined: PredEx and the Rise of Intelligent AI Interpretation in Indian Courts**|Shubham Kumar Nigam et.al.|[2406.04136v1](http://arxiv.org/abs/2406.04136v1)|null|
|**2024-06-06**|**Are We Done with MMLU?**|Aryo Pradipta Gema et.al.|[2406.04127v2](http://arxiv.org/abs/2406.04127v2)|null|
|**2024-06-06**|**Promoting Fairness and Diversity in Speech Datasets for Mental Health and Neurological Disorders Research**|Eleonora Mancini et.al.|[2406.04116v1](http://arxiv.org/abs/2406.04116v1)|null|
|**2024-06-06**|**Uncovering Limitations of Large Language Models in Information Seeking from Tables**|Chaoxu Pang et.al.|[2406.04113v1](http://arxiv.org/abs/2406.04113v1)|[link](https://github.com/coszero/TabIS)|
|**2024-06-06**|**Compressible Dynamics in Deep Overparameterized Low-Rank Learning & Adaptation**|Can Yaras et.al.|[2406.04112v1](http://arxiv.org/abs/2406.04112v1)|[link](https://github.com/cjyaras/deep-lora-transformers)|
|**2024-06-06**|**Intention and Face in Dialog**|Adil Soubki et.al.|[2406.04109v1](http://arxiv.org/abs/2406.04109v1)|[link](https://github.com/cogstates/2024-lrec-coling-faceacts)|
|**2024-06-06**|**Explainability and Hate Speech: Structured Explanations Make Social Media Moderators Faster**|Agostina Calabrese et.al.|[2406.04106v1](http://arxiv.org/abs/2406.04106v1)|[link](https://github.com/Ago3/structured_explanations_make_moderators_faster)|
|**2024-06-06**|**Multistep Distillation of Diffusion Models via Moment Matching**|Tim Salimans et.al.|[2406.04103v1](http://arxiv.org/abs/2406.04103v1)|null|
|**2024-06-06**|**Enhancing Weather Predictions: Super-Resolution via Deep Diffusion Models**|Jan Martinů et.al.|[2406.04099v1](http://arxiv.org/abs/2406.04099v1)|null|
|**2024-06-06**|**Scaling and evaluating sparse autoencoders**|Leo Gao et.al.|[2406.04093v1](http://arxiv.org/abs/2406.04093v1)|[link](https://github.com/openai/sparse_autoencoder)|
|**2024-06-06**|**On Limitation of Transformer for Learning HMMs**|Jiachen Hu et.al.|[2406.04089v1](http://arxiv.org/abs/2406.04089v1)|null|
|**2024-06-06**|**Batch-in-Batch: a new adversarial training framework for initial perturbation and sample selection**|Yinting Wu et.al.|[2406.04070v1](http://arxiv.org/abs/2406.04070v1)|[link](https://github.com/Yinting-Wu/Batch-in-Batch)|
|**2024-06-06**|**Ask LLMs Directly, "What shapes your bias?": Measuring Social Bias in Large Language Models**|Jisu Shin et.al.|[2406.04064v1](http://arxiv.org/abs/2406.04064v1)|null|
|**2024-06-06**|**Leveraging SPD Matrices on Riemannian Manifolds in Quantum Classical Hybrid Models for Structural Health Monitoring**|Azadeh Alavi et.al.|[2406.04055v1](http://arxiv.org/abs/2406.04055v1)|null|
|**2024-06-06**|**Multivector Neurons: Better and Faster O(n)-Equivariant Clifford Graph Neural Networks**|Cong Liu et.al.|[2406.04052v1](http://arxiv.org/abs/2406.04052v1)|[link](https://github.com/congliuUvA/Multivector-Neurons)|
|**2024-06-06**|**ActionReasoningBench: Reasoning about Actions with and without Ramification Constraints**|Divij Handa et.al.|[2406.04046v1](http://arxiv.org/abs/2406.04046v1)|null|
|**2024-06-06**|**Shaping History: Advanced Machine Learning Techniques for the Analysis and Dating of Cuneiform Tablets over Three Millennia**|Danielle Kapon et.al.|[2406.04039v1](http://arxiv.org/abs/2406.04039v1)|null|
|**2024-06-06**|**Spatio-temporal Early Prediction based on Multi-objective Reinforcement Learning**|Wei Shao et.al.|[2406.04035v1](http://arxiv.org/abs/2406.04035v1)|[link](https://github.com/coco0106/MO-STEP)|
|**2024-06-06**|**Pre-trained Transformer Uncovers Meaningful Patterns in Human Mobility Data**|Alameen Najjar et.al.|[2406.04029v1](http://arxiv.org/abs/2406.04029v1)|null|
|**2024-06-06**|**The syntax-semantics interface in a child's path: A study of 3- to 11-year-olds' elicited production of Mandarin recursive relative clauses**|Caimei Yang et.al.|[2406.04025v1](http://arxiv.org/abs/2406.04025v1)|null|
|**2024-06-06**|**American Sign Language Handshapes Reflect Pressures for Communicative Efficiency**|Kayo Yin et.al.|[2406.04024v1](http://arxiv.org/abs/2406.04024v1)|null|
|**2024-06-06**|**HackAtari: Atari Learning Environments for Robust and Continual Reinforcement Learning**|Quentin Delfosse et.al.|[2406.03997v1](http://arxiv.org/abs/2406.03997v1)|[link](https://github.com/k4ntz/HackAtari)|
|**2024-06-06**|**AC4MPC: Actor-Critic Reinforcement Learning for Nonlinear Model Predictive Control**|Rudolf Reiter et.al.|[2406.03995v1](http://arxiv.org/abs/2406.03995v1)|null|
|**2024-06-06**|**Assessing LLMs for Zero-shot Abstractive Summarization Through the Lens of Relevance Paraphrasing**|Hadi Askari et.al.|[2406.03993v1](http://arxiv.org/abs/2406.03993v1)|null|
|**2024-06-06**|**On The Persona-based Summarization of Domain-Specific Documents**|Ankan Mullick et.al.|[2406.03986v1](http://arxiv.org/abs/2406.03986v1)|[link](https://github.com/ankan2/persona-healthcare)|
|**2024-06-06**|**A + B: A General Generator-Reader Framework for Optimizing LLMs to Unleash Synergy Potential**|Wei Tang et.al.|[2406.03963v1](http://arxiv.org/abs/2406.03963v1)|null|
|**2024-06-06**|**Tox-BART: Leveraging Toxicity Attributes for Explanation Generation of Implicit Hate Speech**|Neemesh Yadav et.al.|[2406.03953v1](http://arxiv.org/abs/2406.03953v1)|null|
|**2024-06-06**|**UltraMedical: Building Specialized Generalists in Biomedicine**|Kaiyan Zhang et.al.|[2406.03949v1](http://arxiv.org/abs/2406.03949v1)|[link](https://github.com/tsinghuac3i/ultramedical)|
|**2024-06-06**|**Culturally Aware and Adapted NLP: A Taxonomy and a Survey of the State of the Art**|Chen Cecilia Liu et.al.|[2406.03930v1](http://arxiv.org/abs/2406.03930v1)|null|
|**2024-06-06**|**Vectorized Conditional Neural Fields: A Framework for Solving Time-dependent Parametric Partial Differential Equations**|Jan Hagnberger et.al.|[2406.03919v1](http://arxiv.org/abs/2406.03919v1)|[link](https://github.com/jhagnberger/vcnef)|
|**2024-06-06**|**ArMeme: Propagandistic Content in Arabic Memes**|Firoj Alam et.al.|[2406.03916v1](http://arxiv.org/abs/2406.03916v1)|null|
|**2024-06-06**|**GenSafe: A Generalizable Safety Enhancer for Safe Reinforcement Learning Algorithms Based on Reduced Order Markov Decision Process Model**|Zhehua Zhou et.al.|[2406.03912v1](http://arxiv.org/abs/2406.03912v1)|null|
|**2024-06-06**|**HeSum: a Novel Dataset for Abstractive Text Summarization in Hebrew**|Tzuf Paz-Argaman et.al.|[2406.03897v1](http://arxiv.org/abs/2406.03897v1)|[link](https://github.com/OnlpLab/HeSum)|
|**2024-06-06**|**How Good is Zero-Shot MT Evaluation for Low Resource Indian Languages?**|Anushka Singh et.al.|[2406.03893v1](http://arxiv.org/abs/2406.03893v1)|null|
|**2024-06-06**|**Spontaneous Speech-Based Suicide Risk Detection Using Whisper and Large Language Models**|Ziyun Cui et.al.|[2406.03882v1](http://arxiv.org/abs/2406.03882v1)|null|
|**2024-06-06**|**Evaluating the IWSLT2023 Speech Translation Tasks: Human Annotations, Automatic Metrics, and Segmentation**|Matthias Sperber et.al.|[2406.03881v1](http://arxiv.org/abs/2406.03881v1)|null|
|**2024-06-06**|**Memorization in deep learning: A survey**|Jiaheng Wei et.al.|[2406.03880v1](http://arxiv.org/abs/2406.03880v1)|null|
|**2024-06-06**|**Decoder-only Streaming Transformer for Simultaneous Translation**|Shoutao Guo et.al.|[2406.03878v1](http://arxiv.org/abs/2406.03878v1)|[link](https://github.com/ictnlp/DST)|
|**2024-06-06**|**Quantum Implicit Neural Representations**|Jiaming Zhao et.al.|[2406.03873v1](http://arxiv.org/abs/2406.03873v1)|[link](https://github.com/GGorMM1/QIREN)|
|**2024-06-06**|**BLSP-Emo: Towards Empathetic Large Speech-Language Models**|Chen Wang et.al.|[2406.03872v1](http://arxiv.org/abs/2406.03872v1)|[link](https://github.com/cwang621/blsp-emo)|
|**2024-06-06**|**Recovering document annotations for sentence-level bitext**|Rachel Wicks et.al.|[2406.03869v1](http://arxiv.org/abs/2406.03869v1)|null|
|**2024-06-06**|**Semantic Similarity Score for Measuring Visual Similarity at Semantic Level**|Senran Fan et.al.|[2406.03865v1](http://arxiv.org/abs/2406.03865v1)|null|
|**2024-06-06**|**MuJo: Multimodal Joint Feature Space Learning for Human Activity Recognition**|Stefan Gerd Fritsch et.al.|[2406.03857v1](http://arxiv.org/abs/2406.03857v1)|null|
|**2024-06-06**|**Performance of large language models in numerical vs. semantic medical knowledge: Benchmarking on evidence-based Q&As**|Eden Avnat et.al.|[2406.03855v1](http://arxiv.org/abs/2406.03855v1)|null|
|**2024-06-06**|**Speculative Decoding via Early-exiting for Faster LLM Inference with Thompson Sampling Control Mechanism**|Jiahao Liu et.al.|[2406.03853v1](http://arxiv.org/abs/2406.03853v1)|null|
|**2024-06-06**|**Lean Workbook: A large-scale Lean problem set formalized from natural language math problems**|Huaiyuan Ying et.al.|[2406.03847v2](http://arxiv.org/abs/2406.03847v2)|[link](https://github.com/internlm/internlm-math)|
|**2024-06-06**|**POEM: Interactive Prompt Optimization for Enhancing Multimodal Reasoning of Large Language Models**|Jianben He et.al.|[2406.03843v1](http://arxiv.org/abs/2406.03843v1)|null|
|**2024-06-06**|**Proactive Detection of Physical Inter-rule Vulnerabilities in IoT Services Using a Deep Learning Approach**|Bing Huang et.al.|[2406.03836v1](http://arxiv.org/abs/2406.03836v1)|null|
|**2024-06-06**|**Chaos with Keywords: Exposing Large Language Models Sycophancy to Misleading Keywords and Evaluating Defense Strategies**|Aswin RRV et.al.|[2406.03827v1](http://arxiv.org/abs/2406.03827v1)|[link](https://github.com/3rdAT/ChaosWithKeywords)|
|**2024-06-06**|**A Survey on Intelligent Internet of Things: Applications, Security, Privacy, and Future Directions**|Ons Aouedi et.al.|[2406.03820v1](http://arxiv.org/abs/2406.03820v1)|null|
|**2024-06-06**|**ReST-MCTS*: LLM Self-Training via Process Reward Guided Tree Search**|Dan Zhang et.al.|[2406.03816v1](http://arxiv.org/abs/2406.03816v1)|[link](https://github.com/THUDM/ReST-MCTS)|
|**2024-06-06**|**Improving Zero-Shot Chinese-English Code-Switching ASR with kNN-CTC and Gated Monolingual Datastores**|Jiaming Zhou et.al.|[2406.03814v1](http://arxiv.org/abs/2406.03814v1)|null|
|**2024-06-06**|**Cross-variable Linear Integrated ENhanced Transformer for Photovoltaic power forecasting**|Jiaxin Gao et.al.|[2406.03808v1](http://arxiv.org/abs/2406.03808v1)|null|
|**2024-06-06**|**Tool-Planner: Dynamic Solution Tree Planning for Large Language Model with Tool Clustering**|Yanming Liu et.al.|[2406.03807v1](http://arxiv.org/abs/2406.03807v1)|null|
|**2024-06-06**|**Enhanced Semantic Segmentation Pipeline for WeatherProof Dataset Challenge**|Nan Zhang et.al.|[2406.03799v2](http://arxiv.org/abs/2406.03799v2)|[link](https://github.com/kaneigi/weatherproofchallenge)|
|**2024-06-06**|**Light-PEFT: Lightening Parameter-Efficient Fine-Tuning via Early Pruning**|Naibin Gu et.al.|[2406.03792v1](http://arxiv.org/abs/2406.03792v1)|null|
|**2024-06-06**|**End-to-End Trainable Soft Retriever for Low-resource Relation Extraction**|Kohei Makino et.al.|[2406.03790v1](http://arxiv.org/abs/2406.03790v1)|null|
|**2024-06-06**|**Enhancing Graph U-Nets for Mesh-Agnostic Spatio-Temporal Flow Prediction**|Sunwoong Yang et.al.|[2406.03789v1](http://arxiv.org/abs/2406.03789v1)|null|

#### Abstracts
##### **Verbalized Machine Learning: Revisiting Machine Learning with Language Models**
2406.04344v1 by Tim Z. Xiao, Robert Bamler, Bernhard Schölkopf, Weiyang Liu

Motivated by the large progress made by large language models (LLMs), we
introduce the framework of verbalized machine learning (VML). In contrast to
conventional machine learning models that are typically optimized over a
continuous parameter space, VML constrains the parameter space to be
human-interpretable natural language. Such a constraint leads to a new
perspective of function approximation, where an LLM with a text prompt can be
viewed as a function parameterized by the text prompt. Guided by this
perspective, we revisit classical machine learning problems, such as regression
and classification, and find that these problems can be solved by an
LLM-parameterized learner and optimizer. The major advantages of VML include
(1) easy encoding of inductive bias: prior knowledge about the problem and
hypothesis class can be encoded in natural language and fed into the
LLM-parameterized learner; (2) automatic model class selection: the optimizer
can automatically select a concrete model class based on data and verbalized
prior knowledge, and it can update the model class during training; and (3)
interpretable learner updates: the LLM-parameterized optimizer can provide
explanations for why each learner update is performed. We conduct several
studies to empirically evaluate the effectiveness of VML, and hope that VML can
serve as a stepping stone to stronger interpretability and trustworthiness in
ML.

摘要：受大型語言模型 (LLM) 取得的巨大進展的激勵，我們引入了言語化機器學習 (VML) 框架。與通常在連續參數空間上進行優化的傳統機器學習模型相比，VML 將參數空間約束為人類可解讀的自然語言。這種約束導致了函數逼近的新觀點，其中具有文本提示的 LLM 可以被視為由文本提示參數化的函數。受此觀點的指導，我們重新審視了經典的機器學習問題，例如迴歸和分類，並發現這些問題可以用 LLM 參數化的學習器和優化器來解決。VML 的主要優點包括：(1) 歸納偏誤的簡便編碼：關於問題和假設類別的先驗知識可以用自然語言編碼並輸入到 LLM 參數化的學習器中；(2) 自動模型類別選擇：優化器可以根據數據和言語化的先驗知識自動選擇具體的模型類別，並且可以在訓練期間更新模型類別；(3) 可解釋的學習器更新：LLM 參數化的優化器可以提供對每個學習器更新執行原因的解釋。我們進行了多項研究以實證評估 VML 的有效性，並希望 VML 可以作為邁向 ML 中更強的可解釋性和可信度的墊腳石。

##### **Physics3D: Learning Physical Properties of 3D Gaussians via Video Diffusion**
2406.04338v2 by Fangfu Liu, Hanyang Wang, Shunyu Yao, Shengjun Zhang, Jie Zhou, Yueqi Duan

In recent years, there has been rapid development in 3D generation models,
opening up new possibilities for applications such as simulating the dynamic
movements of 3D objects and customizing their behaviors. However, current 3D
generative models tend to focus only on surface features such as color and
shape, neglecting the inherent physical properties that govern the behavior of
objects in the real world. To accurately simulate physics-aligned dynamics, it
is essential to predict the physical properties of materials and incorporate
them into the behavior prediction process. Nonetheless, predicting the diverse
materials of real-world objects is still challenging due to the complex nature
of their physical attributes. In this paper, we propose \textbf{Physics3D}, a
novel method for learning various physical properties of 3D objects through a
video diffusion model. Our approach involves designing a highly generalizable
physical simulation system based on a viscoelastic material model, which
enables us to simulate a wide range of materials with high-fidelity
capabilities. Moreover, we distill the physical priors from a video diffusion
model that contains more understanding of realistic object materials. Extensive
experiments demonstrate the effectiveness of our method with both elastic and
plastic materials. Physics3D shows great potential for bridging the gap between
the physical world and virtual neural space, providing a better integration and
application of realistic physical principles in virtual environments. Project
page: https://liuff19.github.io/Physics3D.

摘要：近年來，3D 生成模型快速發展，為模擬 3D 物體的動態運動和客製化其行為等應用開啟了新的可能性。然而，目前的 3D 生成模型往往只關注表面特徵，例如顏色和形狀，而忽略了支配真實世界中物體行為的固有物理特性。為了精確模擬與物理定律一致的動態，預測材料的物理特性並將其納入行為預測過程中至關重要。儘管如此，由於真實世界物體的物理屬性複雜，預測其多樣化的材料仍然具有挑戰性。在本文中，我們提出 \textbf{Physics3D}，一種透過影片擴散模型學習 3D 物體各種物理特性的新方法。我們的做法包括基於粘彈性材料模型設計一個高度可概括化的物理模擬系統，使我們能夠以高保真能力模擬各種材料。此外，我們從包含更多對真實物體材料理解的影片擴散模型中提取物理先驗。廣泛的實驗證明了我們的方法對彈性和塑性材料的有效性。Physics3D 顯現了極大的潛力，可以彌合物理世界和虛擬神經空間之間的差距，在虛擬環境中提供更佳的整合和應用真實物理原理。專案頁面：https://liuff19.github.io/Physics3D。

##### **Coherent Zero-Shot Visual Instruction Generation**
2406.04337v1 by Quynh Phung, Songwei Ge, Jia-Bin Huang

Despite the advances in text-to-image synthesis, particularly with diffusion
models, generating visual instructions that require consistent representation
and smooth state transitions of objects across sequential steps remains a
formidable challenge. This paper introduces a simple, training-free framework
to tackle the issues, capitalizing on the advancements in diffusion models and
large language models (LLMs). Our approach systematically integrates text
comprehension and image generation to ensure visual instructions are visually
appealing and maintain consistency and accuracy throughout the instruction
sequence. We validate the effectiveness by testing multi-step instructions and
comparing the text alignment and consistency with several baselines. Our
experiments show that our approach can visualize coherent and visually pleasing
instructions

摘要：儘管文字轉影像合成技術進步，特別是使用擴散模型，但生成需要一致呈現且在連續步驟中物件狀態轉換流暢的視覺說明，仍是一項艱鉅的挑戰。本文介紹一個簡單且無需訓練的架構來解決這些問題，並利用擴散模型和大型語言模型 (LLM) 的進展。我們的做法系統性地整合文字理解和影像生成，以確保視覺說明在視覺上具有吸引力，並在整個說明順序中保持一致性和準確性。我們透過測試多步驟說明，並與多個基準比較文字對齊和一致性，來驗證其有效性。我們的實驗顯示，我們的做法可以視覺化連貫且視覺上令人愉悅的說明

##### **PaCE: Parsimonious Concept Engineering for Large Language Models**
2406.04331v1 by Jinqi Luo, Tianjiao Ding, Kwan Ho Ryan Chan, Darshan Thaker, Aditya Chattopadhyay, Chris Callison-Burch, René Vidal

Large Language Models (LLMs) are being used for a wide variety of tasks.
While they are capable of generating human-like responses, they can also
produce undesirable output including potentially harmful information, racist or
sexist language, and hallucinations. Alignment methods are designed to reduce
such undesirable output, via techniques such as fine-tuning, prompt
engineering, and representation engineering. However, existing methods face
several challenges: some require costly fine-tuning for every alignment task;
some do not adequately remove undesirable concepts, failing alignment; some
remove benign concepts, lowering the linguistic capabilities of LLMs. To
address these issues, we propose Parsimonious Concept Engineering (PaCE), a
novel activation engineering framework for alignment. First, to sufficiently
model the concepts, we construct a large-scale concept dictionary in the
activation space, in which each atom corresponds to a semantic concept. Then,
given any alignment task, we instruct a concept partitioner to efficiently
annotate the concepts as benign or undesirable. Finally, at inference time, we
decompose the LLM activations along the concept dictionary via sparse coding,
to accurately represent the activation as a linear combination of the benign
and undesirable components. By removing the latter ones from the activation, we
reorient the behavior of LLMs towards alignment goals. We conduct experiments
on tasks such as response detoxification, faithfulness enhancement, and
sentiment revising, and show that PaCE achieves state-of-the-art alignment
performance while maintaining linguistic capabilities.

摘要：大型語言模型 (LLM) 已用於各種任務。
雖然它們能夠產生類似人類的回應，但它們也可能
產生不良的輸出，包括潛在有害訊息、種族或
性別歧視語言以及幻覺。對齊方法旨在透過微調等技術減少
這種不良輸出，提示工程和表示工程。然而，現有方法面臨
一些挑戰：有些需要為每個對齊任務進行昂貴的微調；
有些無法充分移除不良概念，導致對齊失敗；有些
移除良性概念，降低 LLM 的語言能力。為了
解決這些問題，我們提出簡約概念工程 (PaCE)，一種
用於對齊的新型激活工程框架。首先，為了充分
建構概念模型，我們在激活空間中建構一個大型概念字典，其中每個原子對應一個語義概念。然後，
針對任何對齊任務，我們指示概念分割器有效地
將概念註解為良性或不良。最後，在推理時間，我們
透過稀疏編碼分解 LLM 激活，沿著概念字典進行，
以準確地將激活表示為良性和不良組成的線性組合。透過移除後者從激活中，我們
重新導向 LLM 的行為以朝向對齊目標。我們在回應解毒、忠實度增強和
情緒修正等任務上進行實驗，並顯示 PaCE 達到最先進的對齊
效能，同時維持語言能力。

##### **ATraDiff: Accelerating Online Reinforcement Learning with Imaginary Trajectories**
2406.04323v1 by Qianlan Yang, Yu-Xiong Wang

Training autonomous agents with sparse rewards is a long-standing problem in
online reinforcement learning (RL), due to low data efficiency. Prior work
overcomes this challenge by extracting useful knowledge from offline data,
often accomplished through the learning of action distribution from offline
data and utilizing the learned distribution to facilitate online RL. However,
since the offline data are given and fixed, the extracted knowledge is
inherently limited, making it difficult to generalize to new tasks. We propose
a novel approach that leverages offline data to learn a generative diffusion
model, coined as Adaptive Trajectory Diffuser (ATraDiff). This model generates
synthetic trajectories, serving as a form of data augmentation and consequently
enhancing the performance of online RL methods. The key strength of our
diffuser lies in its adaptability, allowing it to effectively handle varying
trajectory lengths and mitigate distribution shifts between online and offline
data. Because of its simplicity, ATraDiff seamlessly integrates with a wide
spectrum of RL methods. Empirical evaluation shows that ATraDiff consistently
achieves state-of-the-art performance across a variety of environments, with
particularly pronounced improvements in complicated settings. Our code and demo
video are available at https://atradiff.github.io .

摘要：在在线强化学习 (RL) 中，使用稀疏奖励来训练自主代理是一个长期存在的问题，这是由于数据效率低。以前的工作通过从离线数据中提取有用的知识来克服这一挑战，通常是通过从离线数据学习动作分布并利用学习到的分布来促进在线 RL 来实现的。然而，由于离线数据是给定的并且是固定的，因此提取的知识本质上是有限的，这使得难以推广到新任务。我们提出了一种新颖的方法，该方法利用离线数据来学习生成扩散模型，称为自适应轨迹扩散器 (ATraDiff)。此模型生成合成轨迹，作为数据扩充的一种形式，从而提高在线 RL 方法的性能。我们扩散器的关键优势在于其适应性，使其能够有效地处理不同的轨迹长度并减轻在线和离线数据之间的分布偏移。由于其简单性，ATraDiff 可以与广泛的 RL 方法无缝集成。经验评估表明，ATraDiff 在各种环境中始终如一地达到最先进的性能，特别是在复杂设置中表现出显着的改进。我们的代码和演示视频可在 https://atradiff.github.io 获得。

##### **Chimera: Effectively Modeling Multivariate Time Series with 2-Dimensional State Space Models**
2406.04320v1 by Ali Behrouz, Michele Santacatterina, Ramin Zabih

Modeling multivariate time series is a well-established problem with a wide
range of applications from healthcare to financial markets. Traditional State
Space Models (SSMs) are classical approaches for univariate time series
modeling due to their simplicity and expressive power to represent linear
dependencies. They, however, have fundamentally limited expressive power to
capture non-linear dependencies, are slow in practice, and fail to model the
inter-variate information flow. Despite recent attempts to improve the
expressive power of SSMs by using deep structured SSMs, the existing methods
are either limited to univariate time series, fail to model complex patterns
(e.g., seasonal patterns), fail to dynamically model the dependencies of
variate and time dimensions, and/or are input-independent. We present Chimera
that uses two input-dependent 2-D SSM heads with different discretization
processes to learn long-term progression and seasonal patterns. To improve the
efficiency of complex 2D recurrence, we present a fast training using a new
2-dimensional parallel selective scan. We further present and discuss
2-dimensional Mamba and Mamba-2 as the spacial cases of our 2D SSM. Our
experimental evaluation shows the superior performance of Chimera on extensive
and diverse benchmarks, including ECG and speech time series classification,
long-term and short-term time series forecasting, and time series anomaly
detection.

摘要：多變量時間序列建模是一個完善的問題，在從醫療保健到金融市場的廣泛應用中都有應用。傳統的狀態空間模型 (SSM) 由於其簡潔性和表示線性依賴性的表達能力，是單變量時間序列建模的經典方法。然而，它們在捕捉非線性依賴性方面基本上表現力有限，在實踐中速度較慢，並且無法對變量間的信息流進行建模。儘管最近嘗試通過使用深度結構化 SSM 來提高 SSM 的表現力，但現有方法要么僅限於單變量時間序列，無法對複雜模式（例如季節模式）進行建模，無法動態對變量和時間維度的依賴性進行建模，和/或與輸入無關。我們展示了 Chimera，它使用兩個輸入依賴的 2-D SSM 頭部，具有不同的離散化過程來學習長期進展和季節模式。為了提高複雜的 2D 遞歸的效率，我們使用新的 2 維並行選擇性掃描來展示快速訓練。我們進一步展示並討論了 2 維 Mamba 和 Mamba-2 作為我們 2D SSM 的空間案例。我們的實驗評估顯示了 Chimera 在廣泛且多樣化的基準測試中的卓越性能，包括 ECG 和語音時間序列分類、長期和短期時間序列預測以及時間序列異常檢測。

##### **Improving Alignment and Robustness with Short Circuiting**
2406.04313v1 by Andy Zou, Long Phan, Justin Wang, Derek Duenas, Maxwell Lin, Maksym Andriushchenko, Rowan Wang, Zico Kolter, Matt Fredrikson, Dan Hendrycks

AI systems can take harmful actions and are highly vulnerable to adversarial
attacks. We present an approach, inspired by recent advances in representation
engineering, that "short-circuits" models as they respond with harmful outputs.
Existing techniques aimed at improving alignment, such as refusal training, are
often bypassed. Techniques such as adversarial training try to plug these holes
by countering specific attacks. As an alternative to refusal training and
adversarial training, short-circuiting directly controls the representations
that are responsible for harmful outputs in the first place. Our technique can
be applied to both text-only and multimodal language models to prevent the
generation of harmful outputs without sacrificing utility -- even in the
presence of powerful unseen attacks. Notably, while adversarial robustness in
standalone image recognition remains an open challenge, short-circuiting allows
the larger multimodal system to reliably withstand image "hijacks" that aim to
produce harmful content. Finally, we extend our approach to AI agents,
demonstrating considerable reductions in the rate of harmful actions when they
are under attack. Our approach represents a significant step forward in the
development of reliable safeguards to harmful behavior and adversarial attacks.

摘要：AI 系統可能會採取有害的行動，而且極容易受到對抗性攻擊。我們提出了一種方法，靈感來自最近在表示工程方面的進展，這種方法可以「短路」模型，因為它們會產生有害的輸出。旨在改善對齊的現有技術，例如拒絕訓練，通常會被繞過。對抗性訓練等技術試圖通過反制特定攻擊來填補這些漏洞。作為拒絕訓練和對抗性訓練的替代方案，短路直接控制最初對有害輸出負責的表示。我們的技術可以應用於純文本和多模態語言模型，以防止產生有害輸出，而不會犧牲效用——即使在存在強大的未知攻擊的情況下也是如此。值得注意的是，儘管獨立圖像識別中的對抗性魯棒性仍然是一個未解決的挑戰，但短路允許更大的多模態系統可靠地承受旨在產生有害內容的圖像「劫持」。最後，我們將我們的技術擴展到 AI 代理，證明了在受到攻擊時有害行為的發生率大幅降低。我們的做法代表了在開發針對有害行為和對抗性攻擊的可靠防護措施方面邁出的重要一步。

##### **Semantically Diverse Language Generation for Uncertainty Estimation in Language Models**
2406.04306v1 by Lukas Aichberger, Kajetan Schweighofer, Mykyta Ielanskyi, Sepp Hochreiter

Large language models (LLMs) can suffer from hallucinations when generating
text. These hallucinations impede various applications in society and industry
by making LLMs untrustworthy. Current LLMs generate text in an autoregressive
fashion by predicting and appending text tokens. When an LLM is uncertain about
the semantic meaning of the next tokens to generate, it is likely to start
hallucinating. Thus, it has been suggested that hallucinations stem from
predictive uncertainty. We introduce Semantically Diverse Language Generation
(SDLG) to quantify predictive uncertainty in LLMs. SDLG steers the LLM to
generate semantically diverse yet likely alternatives for an initially
generated text. This approach provides a precise measure of aleatoric semantic
uncertainty, detecting whether the initial text is likely to be hallucinated.
Experiments on question-answering tasks demonstrate that SDLG consistently
outperforms existing methods while being the most computationally efficient,
setting a new standard for uncertainty estimation in LLMs.

摘要：大型語言模型 (LLM) 在生成文本時可能會出現幻覺。這些幻覺會讓 LLM 失去可信度，進而阻礙社會和產業中的各種應用。目前的 LLM 以自迴歸的方式生成文本，透過預測和附加文本符號來進行。當 LLM 不確定下一個要生成的符號的語義含義時，它很有可能會開始產生幻覺。因此，有人提出幻覺源自於預測的不確定性。我們引入了語義多樣化語言生成 (SDLG) 來量化 LLM 中的預測不確定性。SDLG 引導 LLM 為最初生成的文本生成語義多樣但合理的替代方案。此方法提供了對隨機語義不確定性的精確衡量，用以檢測最初的文本是否可能出現幻覺。問答任務的實驗證明，SDLG 在始終優於現有方法的同時，也是運算效率最高的，為 LLM 中的不確定性估計設定了新的標準。

##### **Vision-LSTM: xLSTM as Generic Vision Backbone**
2406.04303v1 by Benedikt Alkin, Maximilian Beck, Korbinian Pöppel, Sepp Hochreiter, Johannes Brandstetter

Transformers are widely used as generic backbones in computer vision, despite
initially introduced for natural language processing. Recently, the Long
Short-Term Memory (LSTM) has been extended to a scalable and performant
architecture - the xLSTM - which overcomes long-standing LSTM limitations via
exponential gating and parallelizable matrix memory structure. In this report,
we introduce Vision-LSTM (ViL), an adaption of the xLSTM building blocks to
computer vision. ViL comprises a stack of xLSTM blocks where odd blocks process
the sequence of patch tokens from top to bottom while even blocks go from
bottom to top. Experiments show that ViL holds promise to be further deployed
as new generic backbone for computer vision architectures.

摘要：儘管最初是為自然語言處理而引入的，但 Transformers 已廣泛用於電腦視覺中的通用主幹。最近，長期短期記憶 (LSTM) 已擴展到可擴充且效能良好的架構 - xLSTM - 它透過指數閘控和可並行化矩陣記憶體結構克服了 LSTM 的長期限制。在此報告中，我們介紹了 Vision-LSTM (ViL)，一種將 xLSTM 建構區塊調整為電腦視覺的技術。ViL 包含一個 xLSTM 區塊堆疊，其中奇數區塊從上到下處理區塊標記的序列，而偶數區塊則從下到上進行處理。實驗顯示，ViL 有望進一步部署為電腦視覺架構的新通用主幹。

##### **VISTA: Visualized Text Embedding For Universal Multi-Modal Retrieval**
2406.04292v1 by Junjie Zhou, Zheng Liu, Shitao Xiao, Bo Zhao, Yongping Xiong

Multi-modal retrieval becomes increasingly popular in practice. However, the
existing retrievers are mostly text-oriented, which lack the capability to
process visual information. Despite the presence of vision-language models like
CLIP, the current methods are severely limited in representing the text-only
and image-only data. In this work, we present a new embedding model VISTA for
universal multi-modal retrieval. Our work brings forth threefold technical
contributions. Firstly, we introduce a flexible architecture which extends a
powerful text encoder with the image understanding capability by introducing
visual token embeddings. Secondly, we develop two data generation strategies,
which bring high-quality composed image-text to facilitate the training of the
embedding model. Thirdly, we introduce a multi-stage training algorithm, which
first aligns the visual token embedding with the text encoder using massive
weakly labeled data, and then develops multi-modal representation capability
using the generated composed image-text data. In our experiments, VISTA
achieves superior performances across a variety of multi-modal retrieval tasks
in both zero-shot and supervised settings. Our model, data, and source code are
available at https://github.com/FlagOpen/FlagEmbedding.

摘要：多模态检索在实践中变得越来越流行。然而，现有的检索器大多是文本导向的，缺乏处理视觉信息的能力。尽管有 CLIP 等视觉语言模型，但当前的方法在表示仅文本和仅图像数据方面受到严重限制。在这项工作中，我们提出了一个新的嵌入模型 VISTA，用于通用多模态检索。我们的工作带来了三方面的技术贡献。首先，我们引入了一个灵活的架构，通过引入视觉标记嵌入，将一个强大的文本编码器扩展为具有图像理解能力。其次，我们开发了两种数据生成策略，这些策略带来了高质量的组合图像文本，以促进嵌入模型的训练。第三，我们引入了一个多阶段训练算法，该算法首先使用大量弱标记数据将视觉标记嵌入与文本编码器对齐，然后使用生成的组合图像文本数据开发多模态表示能力。在我们的实验中，VISTA 在各种多模态检索任务中实现了卓越的性能，既适用于零样本设置，也适用于有监督设置。我们的模型、数据和源代码可在 https://github.com/FlagOpen/FlagEmbedding 获得。

##### **What Languages are Easy to Language-Model? A Perspective from Learning Probabilistic Regular Languages**
2406.04289v2 by Nadav Borenstein, Anej Svete, Robin Chan, Josef Valvoda, Franz Nowak, Isabelle Augenstein, Eleanor Chodroff, Ryan Cotterell

What can large language models learn? By definition, language models (LM) are
distributions over strings. Therefore, an intuitive way of addressing the above
question is to formalize it as a matter of learnability of classes of
distributions over strings. While prior work in this direction focused on
assessing the theoretical limits, in contrast, we seek to understand the
empirical learnability. Unlike prior empirical work, we evaluate neural LMs on
their home turf-learning probabilistic languages-rather than as classifiers of
formal languages. In particular, we investigate the learnability of regular LMs
(RLMs) by RNN and Transformer LMs. We empirically test the learnability of RLMs
as a function of various complexity parameters of the RLM and the hidden state
size of the neural LM. We find that the RLM rank, which corresponds to the size
of linear space spanned by the logits of its conditional distributions, and the
expected length of sampled strings are strong and significant predictors of
learnability for both RNNs and Transformers. Several other predictors also
reach significance, but with differing patterns between RNNs and Transformers.

摘要：大型語言模型能學到什麼？根據定義，語言模型 (LM) 是字串上的分佈。因此，一個直觀的解決上述問題的方法是將其形式化為字串上分佈類別的可學習性問題。雖然先前朝這個方向進行的研究專注於評估理論限制，但我們反而試圖了解經驗可學習性。與先前的經驗性研究不同，我們在神經語言模型的主場——學習機率語言——上評估神經語言模型，而不是作為形式語言的分類器。特別是，我們探討了遞迴神經網路和 Transformer 語言模型對正則語言模型 (RLM) 的可學習性。我們根據 RLM 的各種複雜度參數和神經語言模型的隱藏狀態大小，經驗性地測試 RLM 的可學習性。我們發現 RLM 等級（對應於其條件分佈的 logit 所跨越的線性空間大小）和採樣字串的預期長度是 RNN 和 Transformer 可學習性的強大且重要的預測因子。其他幾個預測因子也達到顯著性，但在 RNN 和 Transformer 之間有不同的模式。

##### **ABEX: Data Augmentation for Low-Resource NLU via Expanding Abstract Descriptions**
2406.04286v1 by Sreyan Ghosh, Utkarsh Tyagi, Sonal Kumar, C. K. Evuru, S Ramaneswaran, S Sakshi, Dinesh Manocha

We present ABEX, a novel and effective generative data augmentation
methodology for low-resource Natural Language Understanding (NLU) tasks. ABEX
is based on ABstract-and-EXpand, a novel paradigm for generating diverse forms
of an input document -- we first convert a document into its concise, abstract
description and then generate new documents based on expanding the resultant
abstraction. To learn the task of expanding abstract descriptions, we first
train BART on a large-scale synthetic dataset with abstract-document pairs.
Next, to generate abstract descriptions for a document, we propose a simple,
controllable, and training-free method based on editing AMR graphs. ABEX brings
the best of both worlds: by expanding from abstract representations, it
preserves the original semantic properties of the documents, like style and
meaning, thereby maintaining alignment with the original label and data
distribution. At the same time, the fundamental process of elaborating on
abstract descriptions facilitates diverse generations. We demonstrate the
effectiveness of ABEX on 4 NLU tasks spanning 12 datasets and 4 low-resource
settings. ABEX outperforms all our baselines qualitatively with improvements of
0.04% - 38.8%. Qualitatively, ABEX outperforms all prior methods from
literature in terms of context and length diversity.

摘要：我們提出 ABEX，一種新穎且有效的生成式資料擴增方法，適用於低資源自然語言理解 (NLU) 任務。ABEX 建立在 ABstract-and-EXpand 之上，這是一種用於產生輸入文件不同形式的新穎範例 - 我們首先將文件轉換成簡潔的抽象描述，然後根據擴展所得抽象產生新文件。為了學習擴展抽象描述的任務，我們首先在具有抽象文件配對的大規模合成資料集上訓練 BART。接下來，為了產生文件的抽象描述，我們提出一個簡單、可控且無需訓練的方法，該方法基於編輯 AMR 圖表。ABEX 帶來了兩全其美的優點：通過從抽象表示中擴展，它保留了文件的原始語義屬性，例如風格和意義，從而保持與原始標籤和資料分佈的一致性。同時，闡述抽象描述的基本過程促進了多樣化的生成。我們在橫跨 12 個資料集和 4 個低資源設定的 4 個 NLU 任務上展示了 ABEX 的有效性。ABEX 在質量上優於我們所有的基準，改進了 0.04% - 38.8%。在質量上，ABEX 在背景和長度多樣性方面優於文獻中的所有先前方法。

##### **Characterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People**
2406.04278v1 by Dun-Ming Huang, Pol Van Rijn, Ilia Sucholutsky, Raja Marjieh, Nori Jacoby

Conversational tones -- the manners and attitudes in which speakers
communicate -- are essential to effective communication. Amidst the increasing
popularization of Large Language Models (LLMs) over recent years, it becomes
necessary to characterize the divergences in their conversational tones
relative to humans. However, existing investigations of conversational
modalities rely on pre-existing taxonomies or text corpora, which suffer from
experimenter bias and may not be representative of real-world distributions for
the studies' psycholinguistic domains. Inspired by methods from cognitive
science, we propose an iterative method for simultaneously eliciting
conversational tones and sentences, where participants alternate between two
tasks: (1) one participant identifies the tone of a given sentence and (2) a
different participant generates a sentence based on that tone. We run 100
iterations of this process with human participants and GPT-4, then obtain a
dataset of sentences and frequent conversational tones. In an additional
experiment, humans and GPT-4 annotated all sentences with all tones. With data
from 1,339 human participants, 33,370 human judgments, and 29,900 GPT-4
queries, we show how our approach can be used to create an interpretable
geometric representation of relations between conversational tones in humans
and GPT-4. This work demonstrates how combining ideas from machine learning and
cognitive science can address challenges in human-computer interactions.

摘要：對話語氣——說話者在溝通中表現出的禮儀和態度——對於有效的溝通至關重要。近年來，隨著大型語言模型 (LLM) 的普及，有必要描述它們的對話語氣與人類之間的差異。然而，現有的對話模式研究依賴於現有的分類法或文本語料庫，這些分類法或語料庫存在實驗者偏差，且可能無法代表研究的心理語言學領域的真實世界分佈。受認知科學方法的啟發，我們提出了一種迭代方法，用於同時引出對話語氣和句子，參與者在兩項任務之間交替進行：(1) 一位參與者識別給定句子的語氣，(2) 另一位參與者根據該語氣生成一個句子。我們與人類參與者和 GPT-4 一起運行此過程的 100 次迭代，然後獲得一個句子和頻繁對話語氣的數據集。在額外的實驗中，人類和 GPT-4 用所有語氣註釋了所有句子。利用來自 1,339 位人類參與者、33,370 個人類判斷和 29,900 個 GPT-4 查詢的數據，我們展示了我們的方法如何用於創建人類和 GPT-4 中對話語氣之間關係的可解釋幾何表示。這項工作展示了如何結合機器學習和認知科學的理念來應對人機交互中的挑戰。

##### **Generative AI-in-the-loop: Integrating LLMs and GPTs into the Next Generation Networks**
2406.04276v1 by Han Zhang, Akram Bin Sediq, Ali Afana, Melike Erol-Kantarci

In recent years, machine learning (ML) techniques have created numerous
opportunities for intelligent mobile networks and have accelerated the
automation of network operations. However, complex network tasks may involve
variables and considerations even beyond the capacity of traditional ML
algorithms. On the other hand, large language models (LLMs) have recently
emerged, demonstrating near-human-level performance in cognitive tasks across
various fields. However, they remain prone to hallucinations and often lack
common sense in basic tasks. Therefore, they are regarded as assistive tools
for humans. In this work, we propose the concept of "generative AI-in-the-loop"
and utilize the semantic understanding, context awareness, and reasoning
abilities of LLMs to assist humans in handling complex or unforeseen situations
in mobile communication networks. We believe that combining LLMs and ML models
allows both to leverage their respective capabilities and achieve better
results than either model alone. To support this idea, we begin by analyzing
the capabilities of LLMs and compare them with traditional ML algorithms. We
then explore potential LLM-based applications in line with the requirements of
next-generation networks. We further examine the integration of ML and LLMs,
discussing how they can be used together in mobile networks. Unlike existing
studies, our research emphasizes the fusion of LLMs with traditional ML-driven
next-generation networks and serves as a comprehensive refinement of existing
surveys. Finally, we provide a case study to enhance ML-based network intrusion
detection with synthesized data generated by LLMs. Our case study further
demonstrates the advantages of our proposed idea.

摘要：近年來，機器學習 (ML) 技術為智慧型行動網路創造了許多機會，並加速了網路運作的自動化。然而，複雜的網路任務可能涉及的變數和考量，甚至超出傳統 ML 演算法的能力。另一方面，大型語言模型 (LLM) 近期浮現，在各個領域的認知任務中展現出接近人類水準的表現。然而，它們仍然容易產生幻覺，而且在基本任務中常常缺乏常識。因此，它們被視為人類的輔助工具。在這項工作中，我們提出「生成式 AI-in-the-loop」的概念，並利用 LLM 的語意理解、脈絡感知和推理能力，協助人類處理行動通訊網路中複雜或無法預見的情況。我們相信，結合 LLM 和 ML 模型，可以讓兩者都能發揮各自的能力，並達成比單一模型更好的結果。為了支持這個想法，我們首先分析 LLM 的能力，並將它們與傳統的 ML 演算法進行比較。接著，我們探索潛在的基於 LLM 的應用，以符合次世代網路的需求。我們進一步探討 ML 和 LLM 的整合，討論如何將它們一起用於行動網路中。與現有的研究不同，我們的研究強調將 LLM 與傳統 ML 驅動的次世代網路融合，並作為現有調查的全面精進。最後，我們提供一個案例研究，以使用 LLM 生成的合成資料來增強基於 ML 的網路入侵偵測。我們的案例研究進一步證明了我們所提出的想法的優點。

##### **Self-Play with Adversarial Critic: Provable and Scalable Offline Alignment for Language Models**
2406.04274v1 by Xiang Ji, Sanjeev Kulkarni, Mengdi Wang, Tengyang Xie

This work studies the challenge of aligning large language models (LLMs) with
offline preference data. We focus on alignment by Reinforcement Learning from
Human Feedback (RLHF) in particular. While popular preference optimization
methods exhibit good empirical performance in practice, they are not
theoretically guaranteed to converge to the optimal policy and can provably
fail when the data coverage is sparse by classical offline reinforcement
learning (RL) results. On the other hand, a recent line of work has focused on
theoretically motivated preference optimization methods with provable
guarantees, but these are not computationally efficient for large-scale
applications like LLM alignment. To bridge this gap, we propose SPAC, a new
offline preference optimization method with self-play, inspired by the
on-average pessimism technique from the offline RL literature, to be the first
provable and scalable approach to LLM alignment. We both provide theoretical
analysis for its convergence under single-policy concentrability for the
general function approximation setting and demonstrate its competitive
empirical performance for LLM alignment on a 7B Mistral model with Open LLM
Leaderboard evaluations.

摘要：这项工作研究了将大型语言模型 (LLM) 与离线偏好数据对齐的挑战。我们专注于通过人类反馈强化学习 (RLHF) 进行对齐。虽然流行的偏好优化方法在实践中表现出良好的经验性能，但它们在理论上并不能保证收敛到最优策略，并且当数据覆盖率稀疏时，可以证明会失败，这是经典离线强化学习 (RL) 的结果。另一方面，最近的一系列工作集中在具有可证明保证的理论上动机的偏好优化方法上，但这些方法对于 LLM 对齐等大规模应用程序来说在计算上效率低下。为了弥合这一差距，我们提出了 SPAC，这是一种新的离线偏好优化方法，具有自博弈，灵感来自离线 RL 文献中的平均悲观技术，成为 LLM 对齐的第一个可证明且可扩展的方法。我们针对其在一般函数逼近设置下针对单策略集中性的收敛性提供了理论分析，并展示了其在具有开放式 LLM 排行榜评估的 7B Mistral 模型上的 LLM 对齐的竞争性经验性能。

##### **Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models**
2406.04271v1 by Ling Yang, Zhaochen Yu, Tianjun Zhang, Shiyi Cao, Minkai Xu, Wentao Zhang, Joseph E. Gonzalez, Bin Cui

We introduce Buffer of Thoughts (BoT), a novel and versatile
thought-augmented reasoning approach for enhancing accuracy, efficiency and
robustness of large language models (LLMs). Specifically, we propose
meta-buffer to store a series of informative high-level thoughts, namely
thought-template, distilled from the problem-solving processes across various
tasks. Then for each problem, we retrieve a relevant thought-template and
adaptively instantiate it with specific reasoning structures to conduct
efficient reasoning. To guarantee the scalability and stability, we further
propose buffer-manager to dynamically update the meta-buffer, thus enhancing
the capacity of meta-buffer as more tasks are solved. We conduct extensive
experiments on 10 challenging reasoning-intensive tasks, and achieve
significant performance improvements over previous SOTA methods: 11% on Game of
24, 20% on Geometric Shapes and 51% on Checkmate-in-One. Further analysis
demonstrate the superior generalization ability and model robustness of our
BoT, while requiring only 12% of the cost of multi-query prompting methods
(e.g., tree/graph of thoughts) on average. Notably, we find that our
Llama3-8B+BoT has the potential to surpass Llama3-70B model. Our project is
available at: https://github.com/YangLing0818/buffer-of-thought-llm

摘要：<paragraph>我們介紹了思想緩衝區 (BoT)，這是一種新穎且通用的思想增強推理方法，用於提升大型語言模型 (LLM) 的準確性、效率和穩健性。具體來說，我們提出元緩衝區，用於儲存一系列有意義的高階思想，即思想範本，從各種任務的解決問題過程中提煉出來。然後，對於每個問題，我們會擷取一個相關的思想範本，並以特定的推理結構自適應地實例化它，以進行有效率的推理。為了保證可擴充性和穩定性，我們進一步提出了緩衝區管理員，用於動態更新元緩衝區，從而隨著更多任務的解決而提升元緩衝區的容量。我們在 10 項具有挑戰性的推理密集型任務上進行了廣泛的實驗，並且相較於先前的 SOTA 方法取得了顯著的效能提升：24 的遊戲提升了 11%，幾何形狀提升了 20%，一招將死提升了 51%。進一步的分析證明了我們 BoT 的優異泛化能力和模型穩健性，同時平均只需要多查詢提示方法（例如思想樹/圖）成本的 12%。值得注意的是，我們發現我們的 Llama3-8B+BoT 有可能超越 Llama3-70B 模型。我們的專案可於以下網址取得：https://github.com/YangLing0818/buffer-of-thought-llm</paragraph>

##### **Open-Endedness is Essential for Artificial Superhuman Intelligence**
2406.04268v1 by Edward Hughes, Michael Dennis, Jack Parker-Holder, Feryal Behbahani, Aditi Mavalankar, Yuge Shi, Tom Schaul, Tim Rocktaschel

In recent years there has been a tremendous surge in the general capabilities
of AI systems, mainly fuelled by training foundation models on internetscale
data. Nevertheless, the creation of openended, ever self-improving AI remains
elusive. In this position paper, we argue that the ingredients are now in place
to achieve openendedness in AI systems with respect to a human observer.
Furthermore, we claim that such open-endedness is an essential property of any
artificial superhuman intelligence (ASI). We begin by providing a concrete
formal definition of open-endedness through the lens of novelty and
learnability. We then illustrate a path towards ASI via open-ended systems
built on top of foundation models, capable of making novel, humanrelevant
discoveries. We conclude by examining the safety implications of
generally-capable openended AI. We expect that open-ended foundation models
will prove to be an increasingly fertile and safety-critical area of research
in the near future.

摘要：近年来，人工智能系统的整体能力大幅提升，这主要归功于在互联网规模的数据上训练基础模型。然而，创建开放式、不断自我完善的人工智能仍然难以实现。在本文中，我们认为现在已经具备了在人类观察者方面实现人工智能系统开放性的条件。此外，我们认为这种开放性是任何人工智能超人类智能 (ASI) 的本质属性。我们首先通过新颖性和可学习性的视角对开放性提供一个具体的形式化定义。然后，我们通过建立在基础模型之上的开放式系统，展示了一条通往 ASI 的道路，该系统能够进行新颖的、与人类相关的发现。最后，我们通过检查通用开放式人工智能的安全影响来结束本文。我们预计开放式基础模型将在不久的将来被证明是一个越来越肥沃且对安全至关重要的研究领域。

##### **Transformers need glasses! Information over-squashing in language tasks**
2406.04267v1 by Federico Barbero, Andrea Banino, Steven Kapturowski, Dharshan Kumaran, João G. M. Araújo, Alex Vitvitskyi, Razvan Pascanu, Petar Veličković

We study how information propagates in decoder-only Transformers, which are
the architectural backbone of most existing frontier large language models
(LLMs). We rely on a theoretical signal propagation analysis -- specifically,
we analyse the representations of the last token in the final layer of the
Transformer, as this is the representation used for next-token prediction. Our
analysis reveals a representational collapse phenomenon: we prove that certain
distinct sequences of inputs to the Transformer can yield arbitrarily close
representations in the final token. This effect is exacerbated by the
low-precision floating-point formats frequently used in modern LLMs. As a
result, the model is provably unable to respond to these sequences in different
ways -- leading to errors in, e.g., tasks involving counting or copying.
Further, we show that decoder-only Transformer language models can lose
sensitivity to specific tokens in the input, which relates to the well-known
phenomenon of over-squashing in graph neural networks. We provide empirical
evidence supporting our claims on contemporary LLMs. Our theory also points to
simple solutions towards ameliorating these issues.

摘要：我們研究資訊在僅解碼器 Transformer 中如何傳播，而僅解碼器 Transformer 是現有最前沿大型語言模型 (LLM) 的架構主幹。我們依賴於理論訊號傳播分析，特別是，我們分析 Transformer 最後一層中最後一個代幣的表徵，因為這是用於下一個代幣預測的表徵。我們的分析揭示了一個表徵崩潰現象：我們證明輸入到 Transformer 的某些不同順序序列可以在最後一個代幣中產生任意接近的表徵。這種效應會因現代 LLM 中經常使用的低精度浮點格式而加劇。結果，該模型無法對這些序列以不同的方式做出回應，導致錯誤，例如涉及計數或複製的任務。此外，我們表明僅解碼器 Transformer 語言模型可能會對輸入中的特定代幣失去敏感性，這與圖神經網路中眾所周知的過度壓縮現象有關。我們提供經驗證據支持我們對當代 LLM 的說法。我們的理論也指出了改善這些問題的簡單解決方案。

##### **MLVU: A Comprehensive Benchmark for Multi-Task Long Video Understanding**
2406.04264v1 by Junjie Zhou, Yan Shu, Bo Zhao, Boya Wu, Shitao Xiao, Xi Yang, Yongping Xiong, Bo Zhang, Tiejun Huang, Zheng Liu

The evaluation of Long Video Understanding (LVU) performance poses an
important but challenging research problem. Despite previous efforts, the
existing video understanding benchmarks are severely constrained by several
issues, especially the insufficient lengths of videos, a lack of diversity in
video types and evaluation tasks, and the inappropriateness for evaluating LVU
performances. To address the above problems, we propose a new benchmark, called
MLVU (Multi-task Long Video Understanding Benchmark), for the comprehensive and
in-depth evaluation of LVU. MLVU presents the following critical values: 1) The
substantial and flexible extension of video lengths, which enables the
benchmark to evaluate LVU performance across a wide range of durations. 2) The
inclusion of various video genres, e.g., movies, surveillance footage,
egocentric videos, cartoons, game videos, etc., which reflects the models' LVU
performances in different scenarios. 3) The development of diversified
evaluation tasks, which enables a comprehensive examination of MLLMs' key
abilities in long-video understanding. The empirical study with 20 latest MLLMs
reveals significant room for improvement in today's technique, as all existing
methods struggle with most of the evaluation tasks and exhibit severe
performance degradation when handling longer videos. Additionally, it suggests
that factors such as context length, image-understanding quality, and the
choice of LLM backbone can play critical roles in future advancements. We
anticipate that MLVU will advance the research of long video understanding by
providing a comprehensive and in-depth analysis of MLLMs.

摘要：長影片理解 (LVU) 效能的評估提出一個重要但具挑戰性的研究問題。儘管先前已做出努力，現有的影片理解基準受到幾個問題的嚴重限制，特別是影片長度不足、影片類型和評估任務缺乏多樣性，以及不適合評估 LVU 效能。為了解決上述問題，我們提出一個新的基準，稱為 MLVU（多任務長影片理解基準），用於全面深入評估 LVU。MLVU 呈現以下幾個關鍵價值：1) 影片長度的實質且彈性延伸，使基準能夠評估各種時長的 LVU 效能。2) 納入各種影片類型，例如電影、監視錄影、自拍影片、卡通、遊戲影片等，反映模型在不同場景中的 LVU 效能。3) 開發多樣化的評估任務，全面檢視 MLLM 在長影片理解中的關鍵能力。針對 20 個最新 MLLM 進行的實證研究顯示，當今技術有顯著進步空間，因為所有現有方法在大部分評估任務中都面臨困難，且在處理較長影片時效能嚴重下降。此外，研究指出，例如脈絡長度、影像理解品質和 LLM 主幹的選擇等因素，在未來的進展中可能扮演關鍵角色。我們預期 MLVU 將透過提供 MLLM 的全面深入分析，推進長影片理解的研究。

##### **GeoGen: Geometry-Aware Generative Modeling via Signed Distance Functions**
2406.04254v2 by Salvatore Esposito, Qingshan Xu, Kacper Kania, Charlie Hewitt, Octave Mariotti, Lohit Petikam, Julien Valentin, Arno Onken, Oisin Mac Aodha

We introduce a new generative approach for synthesizing 3D geometry and
images from single-view collections. Most existing approaches predict
volumetric density to render multi-view consistent images. By employing
volumetric rendering using neural radiance fields, they inherit a key
limitation: the generated geometry is noisy and unconstrained, limiting the
quality and utility of the output meshes. To address this issue, we propose
GeoGen, a new SDF-based 3D generative model trained in an end-to-end manner.
Initially, we reinterpret the volumetric density as a Signed Distance Function
(SDF). This allows us to introduce useful priors to generate valid meshes.
However, those priors prevent the generative model from learning details,
limiting the applicability of the method to real-world scenarios. To alleviate
that problem, we make the transformation learnable and constrain the rendered
depth map to be consistent with the zero-level set of the SDF. Through the lens
of adversarial training, we encourage the network to produce higher fidelity
details on the output meshes. For evaluation, we introduce a synthetic dataset
of human avatars captured from 360-degree camera angles, to overcome the
challenges presented by real-world datasets, which often lack 3D consistency
and do not cover all camera angles. Our experiments on multiple datasets show
that GeoGen produces visually and quantitatively better geometry than the
previous generative models based on neural radiance fields.

摘要：我們提出了一種新的生成式方法，用於從單視圖集合中合成 3D 幾何和影像。大多數現有方法預測體積密度以渲染多視圖一致的影像。透過使用神經輻照場的體積渲染，它們繼承了一個關鍵限制：生成的幾何形狀有雜訊且不受約束，限制了輸出網格的品質和效用。為了解決這個問題，我們提出了 GeoGen，這是一個新的基於 SDF 的 3D 生成模型，以端到端的方式進行訓練。最初，我們將體積密度重新詮釋為有號距離函數 (SDF)。這讓我們能夠引入有用的先驗條件來生成有效的網格。然而，這些先驗條件會阻止生成模型學習細節，限制了該方法在真實世界場景中的適用性。為了緩解這個問題，我們讓轉換可學習，並約束渲染的深度圖與 SDF 的零級集合一致。透過對抗訓練的觀點，我們鼓勵網路在輸出網格上產生更高保真的細節。為了評估，我們引入了一個由 360 度相機角度捕捉的人類頭像合成資料集，以克服真實世界資料集帶來的挑戰，這些資料集通常缺乏 3D 一致性，且無法涵蓋所有相機角度。我們在多個資料集上的實驗表明，GeoGen 產生的視覺和量化幾何比基於神經輻照場的先前生成模型更好。

##### **Benchmark Data Contamination of Large Language Models: A Survey**
2406.04244v1 by Cheng Xu, Shuhao Guan, Derek Greene, M-Tahar Kechadi

The rapid development of Large Language Models (LLMs) like GPT-4, Claude-3,
and Gemini has transformed the field of natural language processing. However,
it has also resulted in a significant issue known as Benchmark Data
Contamination (BDC). This occurs when language models inadvertently incorporate
evaluation benchmark information from their training data, leading to
inaccurate or unreliable performance during the evaluation phase of the
process. This paper reviews the complex challenge of BDC in LLM evaluation and
explores alternative assessment methods to mitigate the risks associated with
traditional benchmarks. The paper also examines challenges and future
directions in mitigating BDC risks, highlighting the complexity of the issue
and the need for innovative solutions to ensure the reliability of LLM
evaluation in real-world applications.

摘要：大型語言模型（LLM）如 GPT-4、Claude-3 和 Gemini 的快速發展已經轉變了自然語言處理的領域。然而，它也導致了一個稱為基準資料污染（BDC）的重大問題。這發生在語言模型無意中將評估基準資訊納入其訓練資料時，導致在處理的評估階段中產生不準確或不可靠的效能。本文探討了 LLM 評估中 BDC 的複雜挑戰，並探討了替代評估方法以降低與傳統基準相關的風險。本文也探討了減輕 BDC 風險的挑戰和未來方向，強調了此問題的複雜性，以及需要創新的解決方案來確保 LLM 評估在實際應用中的可靠性。

##### **Hypernetworks for Personalizing ASR to Atypical Speech**
2406.04240v2 by Max Mueller-Eberstein, Dianna Yee, Karren Yang, Gautam Varma Mantena, Colin Lea

Parameter-efficient fine-tuning (PEFT) for personalizing automatic speech
recognition (ASR) has recently shown promise for adapting general population
models to atypical speech. However, these approaches assume a priori knowledge
of the atypical speech disorder being adapted for -- the diagnosis of which
requires expert knowledge that is not always available. Even given this
knowledge, data scarcity and high inter/intra-speaker variability further limit
the effectiveness of traditional fine-tuning. To circumvent these challenges,
we first identify the minimal set of model parameters required for ASR
adaptation. Our analysis of each individual parameter's effect on adaptation
performance allows us to reduce Word Error Rate (WER) by half while adapting
0.03% of all weights. Alleviating the need for cohort-specific models, we next
propose the novel use of a meta-learned hypernetwork to generate highly
individualized, utterance-level adaptations on-the-fly for a diverse set of
atypical speech characteristics. Evaluating adaptation at the global, cohort
and individual-level, we show that hypernetworks generalize better to
out-of-distribution speakers, while maintaining an overall relative WER
reduction of 75.2% using 0.1% of the full parameter budget.

摘要：參數高效微調 (PEFT) 用於個人化自動語音辨識 (ASR)，最近已顯示出將一般族群模型調整為非典型語音的希望。然而，這些方法假設先驗知識，即非典型語音障礙正在適應——診斷需要專家知識，而這並不總是可用的。即使有這些知識，資料稀少和高跨/內說話者變異性進一步限制了傳統微調的有效性。為了克服這些挑戰，我們首先找出 ASR 適應所需的最小模型參數組。我們對每個個別參數對適應效能的影響分析，使我們能夠在適應所有權重的 0.03% 時將字元錯誤率 (WER) 減少一半。為了減輕對特定於群體的模型的需求，我們接著提出了一種新穎的元學習超網路使用方式，以動態產生高度個性化、語句層級的適應，以適應各種非典型語音特徵。在全球、群體和個人層級評估適應時，我們發現超網路能更好地概括到分布外的說話者，同時使用 0.1% 的完整參數預算，維持整體相對 WER 減少 75.2%。

##### **FairytaleQA Translated: Enabling Educational Question and Answer Generation in Less-Resourced Languages**
2406.04233v1 by Bernardo Leite, Tomás Freitas Osório, Henrique Lopes Cardoso

Question Answering (QA) datasets are crucial in assessing reading
comprehension skills for both machines and humans. While numerous datasets have
been developed in English for this purpose, a noticeable void exists in
less-resourced languages. To alleviate this gap, our paper introduces
machine-translated versions of FairytaleQA, a renowned QA dataset designed to
assess and enhance narrative comprehension skills in young children. By
employing fine-tuned, modest-scale models, we establish benchmarks for both
Question Generation (QG) and QA tasks within the translated datasets. In
addition, we present a case study proposing a model for generating
question-answer pairs, with an evaluation incorporating quality metrics such as
question well-formedness, answerability, relevance, and children suitability.
Our evaluation prioritizes quantifying and describing error cases, along with
providing directions for future work. This paper contributes to the advancement
of QA and QG research in less-resourced languages, promoting accessibility and
inclusivity in the development of these models for reading comprehension. The
code and data is publicly available at
github.com/bernardoleite/fairytaleqa-translated.

摘要：問答（QA）資料集對於評估機器和人類的閱讀理解能力至關重要。雖然已經為此目的開發了許多英文資料集，但在資源較少的語言中存在明顯的空白。為了縮小這個差距，我們的論文介紹了 FairytaleQA 的機器翻譯版本，FairytaleQA 是旨在評估和增強幼童敘事理解能力的著名 QA 資料集。通過採用微調的小規模模型，我們為翻譯資料集中的問題產生（QG）和 QA 任務建立了基準。此外，我們提出了一個案例研究，提出了一個生成問題答案對的模型，並進行評估，其中包含問題格式良好性、可回答性、相關性和兒童適用性等品質指標。我們的評估優先量化和描述錯誤案例，並為未來的研究提供方向。本文有助於推動資源較少語言中的 QA 和 QG 研究，促進這些閱讀理解模型的開發的可及性和包容性。代碼和資料可在 github.com/bernardoleite/fairytaleqa-translated 公開獲得。

##### **Quantifying Misalignment Between Agents**
2406.04231v1 by Aidan Kierans, Avijit Ghosh, Hananel Hazan, Shiri Dori-Hacohen

Growing concerns about the AI alignment problem have emerged in recent years,
with previous work focusing mainly on (1) qualitative descriptions of the
alignment problem; (2) attempting to align AI actions with human interests by
focusing on value specification and learning; and/or (3) focusing on a single
agent or on humanity as a singular unit. Recent work in sociotechnical AI
alignment has made some progress in defining alignment inclusively, but the
field as a whole still lacks a systematic understanding of how to specify,
describe, and analyze misalignment among entities, which may include individual
humans, AI agents, and complex compositional entities such as corporations,
nation-states, and so forth. Previous work on controversy in computational
social science offers a mathematical model of contention among populations (of
humans). In this paper, we adapt this contention model to the alignment
problem, and show how misalignment can vary depending on the population of
agents (human or otherwise) being observed, the domain in question, and the
agents' probability-weighted preferences between possible outcomes. Our model
departs from value specification approaches and focuses instead on the morass
of complex, interlocking, sometimes contradictory goals that agents may have in
practice. We apply our model by analyzing several case studies ranging from
social media moderation to autonomous vehicle behavior. By applying our model
with appropriately representative value data, AI engineers can ensure that
their systems learn values maximally aligned with diverse human interests.

摘要：近年來，對於 AI 對齊問題的擔憂日益增加，
先前的研究主要集中於 (1) 對齊問題的定性描述；(2) 嘗試透過專注於價值規格和學習，將 AI 行動與人類利益保持一致；和/或 (3) 專注於單一代理或將人類視為單一單位。最近在社會技術 AI 對齊方面的工作在定義包容性對齊方面取得了一些進展，但整體領域仍缺乏系統性理解，不知道如何具體說明、描述和分析實體之間的不對齊，其中可能包括個人人類、AI 代理和複雜的組合實體，例如公司、民族國家等等。先前提出的計算社會科學爭議研究提供了人群（人類）之間爭議的數學模型。在本文中，我們將此爭議模型調整為對齊問題，並說明不對齊如何根據所觀察的代理人群（人類或其他）、有問題的領域以及代理在可能結果之間的機率加權偏好而有所不同。我們的模型偏離了價值規格方法，而專注於代理在實務中可能擁有的複雜、相互關聯、有時相互矛盾的目標。我們透過分析從社群媒體審核到自動駕駛行為等多個案例研究，來應用我們的模型。透過使用適當的代表性價值資料應用我們的模型，AI 工程師可以確保他們的系統學習到與多元人類利益最大程度對齊的價值觀。

##### **M3LEO: A Multi-Modal, Multi-Label Earth Observation Dataset Integrating Interferometric SAR and RGB Data**
2406.04230v1 by Matthew J Allen, Francisco Dorr, Joseph Alejandro Gallego Mejia, Laura Martínez-Ferrer, Anna Jungbluth, Freddie Kalaitzis, Raúl Ramos-Pollán

Satellite-based remote sensing has revolutionised the way we address global
challenges in a rapidly evolving world. Huge quantities of Earth Observation
(EO) data are generated by satellite sensors daily, but processing these large
datasets for use in ML pipelines is technically and computationally
challenging. Specifically, different types of EO data are often hosted on a
variety of platforms, with differing availability for Python preprocessing
tools. In addition, spatial alignment across data sources and data tiling can
present significant technical hurdles for novice users. While some preprocessed
EO datasets exist, their content is often limited to optical or near-optical
wavelength data, which is ineffective at night or in adverse weather
conditions. Synthetic Aperture Radar (SAR), an active sensing technique based
on microwave length radiation, offers a viable alternative. However, the
application of machine learning to SAR has been limited due to a lack of
ML-ready data and pipelines, particularly for the full diversity of SAR data,
including polarimetry, coherence and interferometry. We introduce M3LEO, a
multi-modal, multi-label EO dataset that includes polarimetric,
interferometric, and coherence SAR data derived from Sentinel-1, alongside
Sentinel-2 RGB imagery and a suite of labelled tasks for model evaluation.
M3LEO spans 17.5TB and contains approximately 10M data chips across six
geographic regions. The dataset is complemented by a flexible PyTorch Lightning
framework, with configuration management using Hydra. We provide tools to
process any dataset available on popular platforms such as Google Earth Engine
for integration with our framework. Initial experiments validate the utility of
our data and framework, showing that SAR imagery contains information
additional to that extractable from RGB data. Data at huggingface.co/M3LEO, and
code at github.com/spaceml-org/M3LEO.

摘要：<paragraph>基於衛星的遙測技術徹底改變了我們在快速變遷的世界中應對全球挑戰的方式。衛星感測器每天產生大量的地球觀測 (EO) 資料，但處理這些大型資料集以用於 ML 管線在技術和計算上都具有挑戰性。具體來說，不同類型的 EO 資料通常會儲存在各種平台上，且 Python 預處理工具的可用性不同。此外，資料來源和資料切片的空間對齊可能會對新手使用者造成重大的技術障礙。雖然存在一些預處理過的 EO 資料集，但其內容通常僅限於光學或近光學波長資料，這在夜間或惡劣的天氣條件下是無效的。合成孔徑雷達 (SAR) 是一種基於微波長輻射的主動感測技術，提供了一個可行的替代方案。然而，由於缺乏 ML 就緒的資料和管線，機器學習在 SAR 中的應用受到限制，特別是對於 SAR 資料的全部多樣性，包括極化測量、相干性和干涉測量。我們引入了 M3LEO，這是一個多模態、多標籤 EO 資料集，其中包括從 Sentinel-1 衍生的極化測量、干涉測量和相干性 SAR 資料，以及 Sentinel-2 RGB 影像和一套用於模型評估的標籤任務。M3LEO 跨越 17.5TB，並包含六個地理區域中約 1000 萬個資料晶片。該資料集由一個靈活的 PyTorch Lightning 框架補充，並使用 Hydra 進行配置管理。我們提供工具來處理任何可在熱門平台（例如 Google Earth Engine）上獲得的資料集，以與我們的框架整合。初步實驗驗證了我們的資料和框架的效用，表明 SAR 影像包含了從 RGB 資料中提取的額外資訊。資料位於 huggingface.co/M3LEO，程式碼位於 github.com/spaceml-org/M3LEO。</paragraph>

##### **The CLRS-Text Algorithmic Reasoning Language Benchmark**
2406.04229v1 by Larisa Markeeva, Sean McLeish, Borja Ibarz, Wilfried Bounsi, Olga Kozlova, Alex Vitvitskyi, Charles Blundell, Tom Goldstein, Avi Schwarzschild, Petar Veličković

Eliciting reasoning capabilities from language models (LMs) is a critical
direction on the path towards building intelligent systems. Most recent studies
dedicated to reasoning focus on out-of-distribution performance on
procedurally-generated synthetic benchmarks, bespoke-built to evaluate specific
skills only. This trend makes results hard to transfer across publications,
slowing down progress. Three years ago, a similar issue was identified and
rectified in the field of neural algorithmic reasoning, with the advent of the
CLRS benchmark. CLRS is a dataset generator comprising graph execution traces
of classical algorithms from the Introduction to Algorithms textbook. Inspired
by this, we propose CLRS-Text -- a textual version of these algorithmic traces.
Out of the box, CLRS-Text is capable of procedurally generating trace data for
thirty diverse, challenging algorithmic tasks across any desirable input
distribution, while offering a standard pipeline in which any additional
algorithmic tasks may be created in the benchmark. We fine-tune and evaluate
various LMs as generalist executors on this benchmark, validating prior work
and revealing a novel, interesting challenge for the LM reasoning community.
Our code is available at
https://github.com/google-deepmind/clrs/tree/master/clrs/_src/clrs_text.

摘要：引出语言模型 (LM) 的推理能力是建构智能系统路径上的关键方向。大多数最近专注于推理的研究都关注程序生成合成基准的分布外性能，仅为评估特定技能而定制构建。这种趋势使得结果难以在出版物之间转移，从而减缓了进度。三年前，在神经算法推理领域发现了类似的问题并加以纠正，随着 CLRS 基准的出现。CLRS 是一个数据集生成器，包含来自算法导论教科书的经典算法的图形执行轨迹。受此启发，我们提出了 CLRS-Text——这些算法轨迹的文本版本。开箱即用，CLRS-Text 能够为三十个不同的、具有挑战性的算法任务程序生成轨迹数据，跨越任何理想的输入分布，同时提供一个标准管道，可以在基准中创建任何其他算法任务。我们对各种 LM 进行微调和评估，作为此基准上的通才执行器，验证了先前的工作并揭示了 LM 推理社区一个新颖、有趣的挑战。我们的代码可在 https://github.com/google-deepmind/clrs/tree/master/clrs/_src/clrs_text 获得。

##### **BEADs: Bias Evaluation Across Domains**
2406.04220v2 by Shaina Raza, Mizanur Rahman, Michael R. Zhang

Recent improvements in large language models (LLMs) have significantly
enhanced natural language processing (NLP) applications. However, these models
can also inherit and perpetuate biases from their training data. Addressing
this issue is crucial, yet many existing datasets do not offer evaluation
across diverse NLP tasks. To tackle this, we introduce the Bias Evaluations
Across Domains (BEADs) dataset, designed to support a wide range of NLP tasks,
including text classification, bias entity recognition, bias quantification,
and benign language generation. BEADs uses AI-driven annotation combined with
experts' verification to provide reliable labels. This method overcomes the
limitations of existing datasets that typically depend on crowd-sourcing,
expert-only annotations with limited bias evaluations, or unverified AI
labeling. Our empirical analysis shows that BEADs is effective in detecting and
reducing biases across different language models, with smaller models
fine-tuned on BEADs often outperforming LLMs in bias classification tasks.
However, these models may still exhibit biases towards certain demographics.
Fine-tuning LLMs with our benign language data also reduces biases while
preserving the models' knowledge. Our findings highlight the importance of
comprehensive bias evaluation and the potential of targeted fine-tuning for
reducing the bias of LLMs. We are making BEADs publicly available at
https://huggingface.co/datasets/shainar/BEAD
  Warning: This paper contains examples that may be considered offensive.

摘要：大型語言模型（LLM）最近的改進顯著增強了自然語言處理（NLP）應用程式。然而，這些模型也可能繼承和延續其訓練資料中的偏見。解決這個問題至關重要，但許多現有資料集並未針對各種 NLP 任務提供評估。為了解決這個問題，我們引入了跨領域偏見評估（BEAD）資料集，旨在支援各種 NLP 任務，包括文字分類、偏見實體辨識、偏見量化和良性語言產生。BEAD 使用 AI 驅動的註解，結合專家的驗證，提供可靠的標籤。此方法克服了現有資料集的限制，這些資料集通常依賴群眾外包、僅專家註解（偏見評估有限）或未驗證的 AI 標籤。我們的實證分析顯示，BEAD 在偵測和減少不同語言模型的偏見方面有效，針對 BEAD 微調的小型模型在偏見分類任務中通常優於 LLM。然而，這些模型可能仍對某些人口統計資料表現出偏見。使用我們的良性語言資料微調 LLM 也能減少偏見，同時保留模型的知識。我們的研究結果突顯了全面偏見評估的重要性，以及針對性微調在減少 LLM 偏見方面的潛力。我們在 https://huggingface.co/datasets/shainar/BEAD 公開提供 BEAD。警告：此論文包含可能被視為冒犯性的範例。

##### **Rethinking LLM and Linguistic Steganalysis: An Efficient Detection of Strongly Concealed Stego**
2406.04218v1 by Yifan Tang, Yihao Wang, Ru Zhang, Jianyi Liu

To detect stego (steganographic text) in complex scenarios, linguistic
steganalysis (LS) with various motivations has been proposed and achieved
excellent performance. However, with the development of generative
steganography, some stegos have strong concealment, especially after the
emergence of LLMs-based steganography, the existing LS has low detection or
even cannot detect them. We designed a novel LS with two modes called LSGC. In
the generation mode, we created an LS-task "description" and used the
generation ability of LLM to explain whether texts to be detected are stegos.
On this basis, we rethought the principle of LS and LLMs, and proposed the
classification mode. In this mode, LSGC deleted the LS-task "description" and
changed the "causalLM" LLMs to the "sequenceClassification" architecture. The
LS features can be extracted by only one pass of the model, and a linear layer
with initialization weights is added to obtain the classification probability.
Experiments on strongly concealed stegos show that LSGC significantly improves
detection and reaches SOTA performance. Additionally, LSGC in classification
mode greatly reduces training time while maintaining high performance.

摘要：為了在複雜場景中偵測隱寫（隱寫文本），已經提出具有各種動機的語言學隱寫分析（LS），並獲得了極佳的效能。然而，隨著生成式隱寫術的發展，有些隱寫具有強大的隱藏性，特別是在基於 LLM 的隱寫術出現後，現有的 LS 偵測能力低，甚至無法偵測到它們。我們設計了一個具有兩種模式的新穎 LS，稱為 LSGC。在生成模式中，我們創建了一個 LS 任務「描述」，並使用 LLM 的生成能力來解釋待偵測的文本是否為隱寫。在此基礎上，我們重新思考了 LS 和 LLM 的原理，並提出了分類模式。在此模式中，LSGC 刪除了 LS 任務「描述」，並將「causalLM」LLM 改為「sequenceClassification」架構。只需模型執行一次，即可提取 LS 特徵，並新增一個具有初始化權重的線性層來取得分類機率。針對隱藏性強的隱寫的實驗顯示，LSGC 大幅提升了偵測能力，並達到了 SOTA 效能。此外，分類模式中的 LSGC 大幅縮短了訓練時間，同時維持了高效能。

##### **What Do Language Models Learn in Context? The Structured Task Hypothesis**
2406.04216v1 by Jiaoda Li, Yifan Hou, Mrinmaya Sachan, Ryan Cotterell

Large language models (LLMs) exhibit an intriguing ability to learn a novel
task from in-context examples presented in a demonstration, termed in-context
learning (ICL). Understandably, a swath of research has been dedicated to
uncovering the theories underpinning ICL. One popular hypothesis explains ICL
by task selection. LLMs identify the task based on the demonstration and
generalize it to the prompt. Another popular hypothesis is that ICL is a form
of meta-learning, i.e., the models learn a learning algorithm at pre-training
time and apply it to the demonstration. Finally, a third hypothesis argues that
LLMs use the demonstration to select a composition of tasks learned during
pre-training to perform ICL. In this paper, we empirically explore these three
hypotheses that explain LLMs' ability to learn in context with a suite of
experiments derived from common text classification tasks. We invalidate the
first two hypotheses with counterexamples and provide evidence in support of
the last hypothesis. Our results suggest an LLM could learn a novel task in
context via composing tasks learned during pre-training.

摘要：大型語言模型 (LLM) 展現出從示範中以脈絡中的範例學習新任務的有趣能力，稱為脈絡中學習 (ICL)。可以理解的是，大量的研究致力於揭示支撐 ICL 的理論。一個流行的假設通過任務選擇來解釋 ICL。LLM 根據示範識別任務並將其概括為提示。另一個流行的假設是 ICL 是元學習的一種形式，即模型在預訓練時學習學習演算法並將其應用於示範。最後，第三個假設認為 LLM 使用示範來選擇在預訓練期間學習的任務組合以執行 ICL。在本文中，我們根據常見文字分類任務衍生的一系列實驗，實證探討這三個解釋 LLM 在脈絡中學習能力的假設。我們使用反例推翻前兩個假設，並提供證據支持最後一個假設。我們的結果表明，LLM 可以透過組合預訓練期間學習的任務，在脈絡中學習新的任務。

##### **mCSQA: Multilingual Commonsense Reasoning Dataset with Unified Creation Strategy by Language Models and Humans**
2406.04215v1 by Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe

It is very challenging to curate a dataset for language-specific knowledge
and common sense in order to evaluate natural language understanding
capabilities of language models. Due to the limitation in the availability of
annotators, most current multilingual datasets are created through translation,
which cannot evaluate such language-specific aspects. Therefore, we propose
Multilingual CommonsenseQA (mCSQA) based on the construction process of CSQA
but leveraging language models for a more efficient construction, e.g., by
asking LM to generate questions/answers, refine answers and verify QAs followed
by reduced human efforts for verification. Constructed dataset is a benchmark
for cross-lingual language-transfer capabilities of multilingual LMs, and
experimental results showed high language-transfer capabilities for questions
that LMs could easily solve, but lower transfer capabilities for questions
requiring deep knowledge or commonsense. This highlights the necessity of
language-specific datasets for evaluation and training. Finally, our method
demonstrated that multilingual LMs could create QA including language-specific
knowledge, significantly reducing the dataset creation cost compared to manual
creation. The datasets are available at
https://huggingface.co/datasets/yusuke1997/mCSQA.

摘要：對於語言特定的知識和常識，要策展一個資料集以便評估語言模型的自然語言理解能力，是一件非常具有挑戰性的事情。由於標註員的可用性有限，目前大多數多語言資料集都是透過翻譯建立的，而翻譯無法評估此類語言特定的面向。因此，我們提出了多語言常識問答 (mCSQA)，其建立過程是基於 CSQA，但利用語言模型來進行更有效率的建立，例如讓語言模型產生問題/答案、精煉答案，並驗證 QA，然後再減少人工驗證的工作。建立的資料集是多語言語言模型跨語言語言轉移能力的基準，而實驗結果顯示，對於語言模型可以輕易解決的問題，其語言轉移能力很高，但對於需要深入知識或常識的問題，其轉移能力較低。這突顯了語言特定資料集對於評估和訓練的必要性。最後，我們的方法證明了多語言語言模型可以建立包含語言特定知識的 QA，與人工建立相比，大幅降低了資料集建立成本。資料集可在 https://huggingface.co/datasets/yusuke1997/mCSQA 取得。

##### **ValueBench: Towards Comprehensively Evaluating Value Orientations and Understanding of Large Language Models**
2406.04214v1 by Yuanyi Ren, Haoran Ye, Hanjun Fang, Xin Zhang, Guojie Song

Large Language Models (LLMs) are transforming diverse fields and gaining
increasing influence as human proxies. This development underscores the urgent
need for evaluating value orientations and understanding of LLMs to ensure
their responsible integration into public-facing applications. This work
introduces ValueBench, the first comprehensive psychometric benchmark for
evaluating value orientations and value understanding in LLMs. ValueBench
collects data from 44 established psychometric inventories, encompassing 453
multifaceted value dimensions. We propose an evaluation pipeline grounded in
realistic human-AI interactions to probe value orientations, along with novel
tasks for evaluating value understanding in an open-ended value space. With
extensive experiments conducted on six representative LLMs, we unveil their
shared and distinctive value orientations and exhibit their ability to
approximate expert conclusions in value-related extraction and generation
tasks. ValueBench is openly accessible at
https://github.com/Value4AI/ValueBench.

摘要：大型語言模型 (LLM) 正在轉變各種領域，並作為人類代理人獲得越來越大的影響力。這種發展強調了評估價值取向和理解 LLM 的迫切需要，以確保它們負責任地整合到面向公眾的應用程式中。這項工作引入了 ValueBench，這是第一個全面的心理測量基準，用於評估 LLM 中的價值取向和價值理解。ValueBench 從 44 份既定的心理測量清單中收集資料，涵蓋 453 個多面向的價值維度。我們提出了一個評估管道，它以現實的人工智慧互動為基礎，用於探討價值取向，以及評估開放式價值空間中價值理解的新任務。透過對六個具代表性的 LLM 進行廣泛的實驗，我們揭示了它們的共同和獨特價值取向，並展示了它們在與價值相關的萃取和生成任務中逼近專家結論的能力。ValueBench 可在 https://github.com/Value4AI/ValueBench 公開取得。

##### **Aligning Agents like Large Language Models**
2406.04208v1 by Adam Jelley, Yuhan Cao, Dave Bignell, Sam Devlin, Tabish Rashid

Training agents to behave as desired in complex 3D environments from
high-dimensional sensory information is challenging. Imitation learning from
diverse human behavior provides a scalable approach for training an agent with
a sensible behavioral prior, but such an agent may not perform the specific
behaviors of interest when deployed. To address this issue, we draw an analogy
between the undesirable behaviors of imitation learning agents and the
unhelpful responses of unaligned large language models (LLMs). We then
investigate how the procedure for aligning LLMs can be applied to aligning
agents in a 3D environment from pixels. For our analysis, we utilize an
academically illustrative part of a modern console game in which the human
behavior distribution is multi-modal, but we want our agent to imitate a single
mode of this behavior. We demonstrate that we can align our agent to
consistently perform the desired mode, while providing insights and advice for
successfully applying this approach to training agents. Project webpage at
https://adamjelley.github.io/aligning-agents-like-llms .

摘要：訓練代理人根據高維度感官資訊在複雜的 3D 環境中表現出如預期般的行為是一項挑戰。從多樣化的人類行為中進行模仿學習提供了一個可擴充的途徑，用於訓練具備明智行為先驗的代理人，但這樣的代理人在部署時可能無法執行特定的感興趣行為。為了解決這個問題，我們將模仿學習代理人的不良行為與未對齊大型語言模型 (LLM) 的無益回應之間畫上類比。然後我們探討如何將對齊 LLM 的程序應用於從像素中對齊 3D 環境中的代理人。對於我們的分析，我們利用現代遊戲機遊戲中一個學術上具有說明性的部分，其中人類行為分佈是多模態的，但我們希望我們的代理人模仿此行為的單一模式。我們展示了我們可以將我們的代理人對齊，以持續執行所需的模式，同時提供見解和建議，以成功將此方法應用於訓練代理人。專案網頁：https://adamjelley.github.io/aligning-agents-like-llms。

##### **Legal Documents Drafting with Fine-Tuned Pre-Trained Large Language Model**
2406.04202v1 by Chun-Hsien Lin, Pu-Jen Cheng

With the development of large-scale Language Models (LLM), fine-tuning
pre-trained LLM has become a mainstream paradigm for solving downstream tasks
of natural language processing. However, training a language model in the legal
field requires a large number of legal documents so that the language model can
learn legal terminology and the particularity of the format of legal documents.
The typical NLP approaches usually rely on many manually annotated data sets
for training. However, in the legal field application, it is difficult to
obtain a large number of manually annotated data sets, which restricts the
typical method applied to the task of drafting legal documents. The
experimental results of this paper show that not only can we leverage a large
number of annotation-free legal documents without Chinese word segmentation to
fine-tune a large-scale language model, but more importantly, it can fine-tune
a pre-trained LLM on the local computer to achieve the generating legal
document drafts task, and at the same time achieve the protection of
information privacy and to improve information security issues.

摘要：隨著大規模語言模型 (LLM) 的發展，微調預先訓練的 LLM 已成為解決自然語言處理下游任務的主流範例。然而，在法律領域訓練語言模型需要大量的法律文件，以便語言模型可以學習法律術語和法律文件格式的特殊性。典型的 NLP 方法通常依賴於許多手動註釋的資料集進行訓練。然而，在法律領域應用中，很難獲得大量的、手動註釋的資料集，這限制了典型方法應用於法律文件起草任務。本文的實驗結果表明，我們不僅可以利用大量沒有中文分詞的無註釋法律文件來微調大規模語言模型，更重要的是，可以在本地電腦上微調預先訓練的 LLM 以達成產生法律文件草稿任務，同時達成資訊隱私保護和提升資訊安全問題。

##### **DICE: Detecting In-distribution Contamination in LLM's Fine-tuning Phase for Math Reasoning**
2406.04197v1 by Shangqing Tu, Kejian Zhu, Yushi Bai, Zijun Yao, Lei Hou, Juanzi Li

The advancement of large language models (LLMs) relies on evaluation using
public benchmarks, but data contamination can lead to overestimated
performance. Previous researches focus on detecting contamination by
determining whether the model has seen the exact same data during training. In
this work, we argue that even training on data similar to benchmark data
inflates performance on in-distribution tasks without improving overall
capacity, which we called In-distribution contamination. To effectively detect
in-distribution contamination, we propose DICE, a novel method that leverages
the internal states of LLMs to locate-then-detect the contamination. DICE first
identifies the most sensitive layer to contamination, then trains a classifier
based on the internal states of that layer. Experiments reveal DICE's high
accuracy in detecting in-distribution contamination across various LLMs and
math reasoning datasets. We also show the generalization capability of the
trained DICE detector, which is able to detect contamination across multiple
benchmarks with similar distributions. Additionally, we find that the DICE
detection scores are positively correlated with the performance of ten LLMs
fine-tuned by either us or other organizations on four math reasoning datasets
(with $R^2$ values between 0.6 and 0.75). This indicates that the
in-distribution contamination problem potentially lead to an overestimation of
the true capabilities of many existing models. The code and data are available
at https://github.com/THU-KEG/DICE.

摘要：大型語言模型（LLM）的進展依賴於使用公共基準進行評估，但資料污染可能會導致高估效能。先前的研究專注於透過判斷模型在訓練期間是否看到完全相同的資料來偵測污染。在這項工作中，我們主張即使訓練與基準資料類似的資料也會提升對分佈內任務的效能，而不會改善整體容量，我們稱之為分佈內污染。為了有效偵測分佈內污染，我們提出 DICE，這是一種新方法，利用 LLM 的內部狀態來定位並偵測污染。DICE 首先找出對污染最敏感的層，然後根據該層的內部狀態訓練分類器。實驗顯示 DICE 在偵測各種 LLM 和數學推理資料集中的分佈內污染時具有高度準確性。我們還展示了訓練好的 DICE 偵測器的泛化能力，它能夠偵測具有類似分佈的各種基準中的污染。此外，我們發現 DICE 偵測分數與我們或其他組織在四個數學推理資料集上微調的十個 LLM 的效能呈正相關（$R^2$ 值在 0.6 到 0.75 之間）。這表示分佈內污染問題可能導致高估許多現有模型的真正能力。程式碼和資料可以在 https://github.com/THU-KEG/DICE 找到。

##### **Shield Synthesis for LTL Modulo Theories**
2406.04184v1 by Andoni Rodriguez, Guy Amir, Davide Corsi, Cesar Sanchez, Guy Katz

In recent years, Machine Learning (ML) models have achieved remarkable
success in various domains. However, these models also tend to demonstrate
unsafe behaviors, precluding their deployment in safety-critical systems. To
cope with this issue, ample research focuses on developing methods that
guarantee the safe behaviour of a given ML model. A prominent example is
shielding which incorporates an external component (a "shield") that blocks
unwanted behavior. Despite significant progress, shielding suffers from a main
setback: it is currently geared towards properties encoded solely in
propositional logics (e.g., LTL) and is unsuitable for richer logics. This, in
turn, limits the widespread applicability of shielding in many real-world
systems. In this work, we address this gap, and extend shielding to LTL modulo
theories, by building upon recent advances in reactive synthesis modulo
theories. This allowed us to develop a novel approach for generating shields
conforming to complex safety specifications in these more expressive, logics.
We evaluated our shields and demonstrate their ability to handle rich data with
temporal dynamics. To the best of our knowledge, this is the first approach for
synthesizing shields for such expressivity.

摘要：近年來，機器學習 (ML) 模型在各個領域都取得了顯著的成功。然而，這些模型也傾向於表現出不安全的行為，這使得它們無法部署在安全關鍵系統中。為了應對這個問題，大量的研究專注於開發保證給定 ML 模型安全行為的方法。一個突出的例子是防護，它包含一個外部組件（一個「防護罩」），可以阻止不需要的行為。儘管取得了顯著進展，防護仍然存在一個主要的挫折：它目前針對的是僅在命題邏輯（例如，LTL）中編碼的屬性，並不適合於更豐富的邏輯。這反過來又限制了防護在許多現實世界系統中的廣泛適用性。在這項工作中，我們解決了這個差距，並通過建立在反應式合成模組化理論的最新進展之上，將防護擴展到 LTL 模組化理論。這使我們能夠開發一種新穎的方法，用於生成符合這些更具表現力的邏輯中複雜安全規範的防護罩。我們評估了我們的防護罩，並展示了它們處理具有時間動態的豐富數據的能力。據我們所知，這是第一種用於合成具有這種表現力的防護罩的方法。

##### **Confabulation: The Surprising Value of Large Language Model Hallucinations**
2406.04175v1 by Peiqi Sui, Eamon Duede, Sophie Wu, Richard Jean So

This paper presents a systematic defense of large language model (LLM)
hallucinations or 'confabulations' as a potential resource instead of a
categorically negative pitfall. The standard view is that confabulations are
inherently problematic and AI research should eliminate this flaw. In this
paper, we argue and empirically demonstrate that measurable semantic
characteristics of LLM confabulations mirror a human propensity to utilize
increased narrativity as a cognitive resource for sense-making and
communication. In other words, it has potential value. Specifically, we analyze
popular hallucination benchmarks and reveal that hallucinated outputs display
increased levels of narrativity and semantic coherence relative to veridical
outputs. This finding reveals a tension in our usually dismissive
understandings of confabulation. It suggests, counter-intuitively, that the
tendency for LLMs to confabulate may be intimately associated with a positive
capacity for coherent narrative-text generation.

摘要：本文系統性地論述了大型語言模型 (LLM) 的幻覺或「捏造」，將其視為一種潛在資源，而非絕對負面的陷阱。標準觀點認為捏造本質上是有問題的，人工智慧研究應消除此缺陷。在本文中，我們論證並實證證明，LLM 捏造的可測量語義特徵反映了人類傾向於利用增加的敘事性作為理解和溝通的認知資源。換句話說，它具有潛在價值。具體來說，我們分析了流行的幻覺基準，並揭示了幻覺輸出的敘事性和語義一致性高於真實輸出的層級。此發現揭示了我們通常對捏造的不屑理解中的緊張關係。它反直覺地表明，LLM 捏造的傾向可能與連貫敘事文本生成的正面能力密切相關。

##### **Pointer-Guided Pre-Training: Infusing Large Language Models with Paragraph-Level Contextual Awareness**
2406.04156v1 by Lars Hillebrand, Prabhupad Pradhan, Christian Bauckhage, Rafet Sifa

We introduce "pointer-guided segment ordering" (SO), a novel pre-training
technique aimed at enhancing the contextual understanding of paragraph-level
text representations in large language models. Our methodology leverages a
self-attention-driven pointer network to restore the original sequence of
shuffled text segments, addressing the challenge of capturing the structural
coherence and contextual dependencies within documents. This pre-training
approach is complemented by a fine-tuning methodology that incorporates dynamic
sampling, augmenting the diversity of training instances and improving sample
efficiency for various downstream applications. We evaluate our method on a
diverse set of datasets, demonstrating its efficacy in tasks requiring
sequential text classification across scientific literature and financial
reporting domains. Our experiments show that pointer-guided pre-training
significantly enhances the model's ability to understand complex document
structures, leading to state-of-the-art performance in downstream
classification tasks.

摘要：我們引入「指標引導片段排序」(SO)，一種新穎的預訓練技術，旨在提升大型語言模型中段落層級文本表徵的語境理解能力。我們的技術方法利用自注意力驅動的指標網路，來還原打亂順序的文字片段的原始順序，以解決捕捉文件中的結構連貫性和語境依賴性的挑戰。此預訓練方法搭配了結合動態取樣的微調技術，擴增訓練實例的多樣性，並提升各種下游應用程式的取樣效率。我們在各種資料集上評估我們的模型，證明了它在需要序列文字分類的任務中的效能，涵蓋科學文獻和財務報告領域。我們的實驗顯示，指標引導預訓練大幅提升模型理解複雜文件結構的能力，在後續分類任務中達到最先進的效能。

##### **AgentGym: Evolving Large Language Model-based Agents across Diverse Environments**
2406.04151v1 by Zhiheng Xi, Yiwen Ding, Wenxiang Chen, Boyang Hong, Honglin Guo, Junzhe Wang, Dingwen Yang, Chenyang Liao, Xin Guo, Wei He, Songyang Gao, Lu Chen, Rui Zheng, Yicheng Zou, Tao Gui, Qi Zhang, Xipeng Qiu, Xuanjing Huang, Zuxuan Wu, Yu-Gang Jiang

Building generalist agents that can handle diverse tasks and evolve
themselves across different environments is a long-term goal in the AI
community. Large language models (LLMs) are considered a promising foundation
to build such agents due to their generalized capabilities. Current approaches
either have LLM-based agents imitate expert-provided trajectories step-by-step,
requiring human supervision, which is hard to scale and limits environmental
exploration; or they let agents explore and learn in isolated environments,
resulting in specialist agents with limited generalization. In this paper, we
take the first step towards building generally-capable LLM-based agents with
self-evolution ability. We identify a trinity of ingredients: 1) diverse
environments for agent exploration and learning, 2) a trajectory set to equip
agents with basic capabilities and prior knowledge, and 3) an effective and
scalable evolution method. We propose AgentGym, a new framework featuring a
variety of environments and tasks for broad, real-time, uni-format, and
concurrent agent exploration. AgentGym also includes a database with expanded
instructions, a benchmark suite, and high-quality trajectories across
environments. Next, we propose a novel method, AgentEvol, to investigate the
potential of agent self-evolution beyond previously seen data across tasks and
environments. Experimental results show that the evolved agents can achieve
results comparable to SOTA models. We release the AgentGym suite, including the
platform, dataset, benchmark, checkpoints, and algorithm implementations. The
AgentGym suite is available on https://github.com/WooooDyy/AgentGym.

摘要：建立能夠處理各種任務並在不同環境中自我演化的通才代理是 AI 社群中的長期目標。由於大型語言模型 (LLM) 具有廣泛的能力，因此被認為是建立此類代理的有希望的基礎。目前的做法要么讓基於 LLM 的代理逐步驟模仿專家提供的軌跡，需要人工監督，這難以擴展且會限制環境探索；或者讓代理在孤立的環境中探索和學習，導致專家代理的概化能力有限。在本文中，我們邁出了建立具有自我演化能力的通用 LLM 基礎代理的第一步。我們確定了三項要素：1) 代理探索和學習的多元環境，2) 賦予代理基本能力和先驗知識的軌跡集，以及 3) 一種有效且可擴展的演化方法。我們提出了 AgentGym，這是一個新的框架，具有多種環境和任務，可進行廣泛、實時、統一格式和並發代理探索。AgentGym 還包括一個包含擴展指令、基準套件和跨環境的高質量軌跡的資料庫。接下來，我們提出了一種新方法 AgentEvol，以探索代理在任務和環境中超越先前所見數據的自我演化潛力。實驗結果表明，演化後的代理可以實現與 SOTA 模型相當的結果。我們發布了 AgentGym 套件，包括平台、數據集、基準、檢查點和演算法實作。AgentGym 套件可在 https://github.com/WooooDyy/AgentGym 上取得。

##### **Characterizing segregation in blast rock piles a deep-learning approach leveraging aerial image analysis**
2406.04149v1 by Chengeng Liu, Sihong Liu, Chaomin Shen, Yupeng Gao, Yuxuan Liu

Blasted rock material serves a critical role in various engineering
applications, yet the phenomenon of segregation-where particle sizes vary
significantly along the gradient of a quarry pile-presents challenges for
optimizing quarry material storage and handling. This study introduces an
advanced image analysis methodology to characterize such segregation of rock
fragments. The accurate delineation of detailed rock fragment size
distributions was achieved through the analysis of drone-captured imagery,
coupled with the application of an enhanced Unet semantic segmentation model
integrated with an expansion-based post-processing technique. The quarry slope
was stratified into four vertical sections, with the size distribution of each
section quantified via ellipsoid shape approximations. Our results disclose
pronounced vertical segregation patterns, with finer particles concentrated in
the upper slope regions and coarser particles in the lower. Utilizing relative
characteristic diameters, we offered insight into the degree of segregation,
thereby illustrating the spatial heterogeneity in fragment size more clearly.
The techniques outlined in this study deliver a scalable and accurate method
for assessing fragment size distribution, with the potential to better inform
resource management and operational decisions in quarry management.

摘要：爆破岩石材料在各种工程应用中发挥着至关重要的作用，然而，偏析现象——其中粒度在采石场堆积的梯度上差异显著——对优化采石场材料的储存和处理提出了挑战。本研究引入了一种先进的图像分析方法来表征岩石碎块的这种偏析。通过分析无人机拍摄的图像，并结合应用了一种增强的 Unet 语义分割模型以及基于扩展的后处理技术，准确地描绘了详细的岩石碎块尺寸分布。采石场斜坡被分层为四个垂直部分，每个部分的尺寸分布通过椭球形状近似来量化。我们的结果揭示了明显的垂直偏析模式，其中较细的颗粒集中在较高的斜坡区域，而较粗的颗粒集中在较低的斜坡区域。利用相对特征直径，我们深入了解了偏析程度，从而更清楚地说明了碎块尺寸的空间异质性。本研究中概述的技术提供了一种可扩展且准确的方法来评估碎块尺寸分布，有可能更好地为采石场管理中的资源管理和运营决策提供信息。

##### **Towards Understanding Task-agnostic Debiasing Through the Lenses of Intrinsic Bias and Forgetfulness**
2406.04146v1 by Guangliang Liu, Milad Afshari, Xitong Zhang, Zhiyu Xue, Avrajit Ghosh, Bidhan Bashyal, Rongrong Wang, Kristen Johnson

While task-agnostic debiasing provides notable generalizability and reduced
reliance on downstream data, its impact on language modeling ability and the
risk of relearning social biases from downstream task-specific data remain as
the two most significant challenges when debiasing Pretrained Language Models
(PLMs). The impact on language modeling ability can be alleviated given a
high-quality and long-contextualized debiasing corpus, but there remains a
deficiency in understanding the specifics of relearning biases. We empirically
ascertain that the effectiveness of task-agnostic debiasing hinges on the
quantitative bias level of both the task-specific data used for downstream
applications and the debiased model. We empirically show that the lower bound
of the bias level of the downstream fine-tuned model can be approximated by the
bias level of the debiased model, in most practical cases. To gain more
in-depth understanding about how the parameters of PLMs change during
fine-tuning due to the forgetting issue of PLMs, we propose a novel framework
which can Propagate Socially-fair Debiasing to Downstream Fine-tuning,
ProSocialTuning. Our proposed framework can push the fine-tuned model to
approach the bias lower bound during downstream fine-tuning, indicating that
the ineffectiveness of debiasing can be alleviated by overcoming the forgetting
issue through regularizing successfully debiased attention heads based on the
PLMs' bias levels from stages of pretraining and debiasing.

摘要：<paragraph>儘管與任務無關的去偏見提供了顯著的概括性並減少了對下游資料的依賴，但它對語言建模能力的影響以及從下游特定任務資料重新學習社會偏見的風險仍然是去偏見預訓練語言模型 (PLM) 時兩個最重要的挑戰。在給定高品質且長時間脈絡化的去偏見語料庫的情況下，可以減輕對語言建模能力的影響，但對於重新學習偏見的具體情況仍缺乏理解。我們憑經驗確定與任務無關的去偏見的有效性取決於用於下游應用程式和去偏見模型的特定任務資料的量化偏見程度。我們憑經驗表明，在大多數實際情況下，下游微調模型的偏見程度的下限可以近似於去偏見模型的偏見程度。為了更深入地瞭解 PLM 的參數在微調過程中如何因 PLM 的遺忘問題而改變，我們提出了一個新的框架，可以將社會公平去偏見傳播到下游微調，即 ProSocialTuning。我們提出的框架可以在下游微調過程中推動微調模型接近偏見下限，這表明透過根據 PLM 在預訓練和去偏見階段的偏見程度，規範成功去偏見的注意力頭，可以克服遺忘問題，從而減輕去偏見的無效性。</paragraph>

##### **Every Answer Matters: Evaluating Commonsense with Probabilistic Measures**
2406.04145v1 by Qi Cheng, Michael Boratko, Pranay Kumar Yelugam, Tim O'Gorman, Nalini Singh, Andrew McCallum, Xiang Lorraine Li

Large language models have demonstrated impressive performance on commonsense
tasks; however, these tasks are often posed as multiple-choice questions,
allowing models to exploit systematic biases. Commonsense is also inherently
probabilistic with multiple correct answers. The purpose of "boiling water"
could be making tea and cooking, but it also could be killing germs. Existing
tasks do not capture the probabilistic nature of common sense. To this end, we
present commonsense frame completion (CFC), a new generative task that
evaluates common sense via multiple open-ended generations. We also propose a
method of probabilistic evaluation that strongly correlates with human
judgments. Humans drastically outperform strong language model baselines on our
dataset, indicating this approach is both a challenging and useful evaluation
of machine common sense.

摘要：大型語言模型在常識任務上表現出色；然而，這些任務通常被表述為多選題，允許模型利用系統性偏差。常識本質上也是機率性的，有多個正確答案。「煮沸水」的目的可能是泡茶和烹飪，但也可能是殺死細菌。現有的任務並未捕捉到常識的機率性。為此，我們提出常識框架完成 (CFC)，這是一種新的生成任務，透過多個開放式生成來評估常識。我們還提出了一種機率性評估方法，與人類的判斷密切相關。人類在我們的資料集上大幅優於強大的語言模型基準，這表示這種方法既具有挑戰性，又是對機器常識有用的評估。

##### **Do Language Models Understand Morality? Towards a Robust Detection of Moral Content**
2406.04143v1 by Luana Bulla, Aldo Gangemi, Misael Mongiovì

The task of detecting moral values in text has significant implications in
various fields, including natural language processing, social sciences, and
ethical decision-making. Previously proposed supervised models often suffer
from overfitting, leading to hyper-specialized moral classifiers that struggle
to perform well on data from different domains. To address this issue, we
introduce novel systems that leverage abstract concepts and common-sense
knowledge acquired from Large Language Models and Natural Language Inference
models during previous stages of training on multiple data sources. By doing
so, we aim to develop versatile and robust methods for detecting moral values
in real-world scenarios. Our approach uses the GPT 3.5 model as a zero-shot
ready-made unsupervised multi-label classifier for moral values detection,
eliminating the need for explicit training on labeled data. We compare it with
a smaller NLI-based zero-shot model. The results show that the NLI approach
achieves competitive results compared to the Davinci model. Furthermore, we
conduct an in-depth investigation of the performance of supervised systems in
the context of cross-domain multi-label moral value detection. This involves
training supervised models on different domains to explore their effectiveness
in handling data from different sources and comparing their performance with
the unsupervised methods. Our contributions encompass a thorough analysis of
both supervised and unsupervised methodologies for cross-domain value
detection. We introduce the Davinci model as a state-of-the-art zero-shot
unsupervised moral values classifier, pushing the boundaries of moral value
detection without the need for explicit training on labeled data. Additionally,
we perform a comparative evaluation of our approach with the supervised models,
shedding light on their respective strengths and weaknesses.

摘要：<paragraph>偵測文字中的道德價值這項任務在各種領域都有重要的影響，包括自然語言處理、社會科學和道德決策制定。先前提出的監督式模型常常會過度擬合，導致高度專業化的道德分類器難以在不同領域的資料上表現良好。為了解決這個問題，我們引進了創新的系統，它利用了大型語言模型和自然語言推論模型在先前訓練階段從多個資料來源中獲得的抽象概念和常識知識。透過這樣做，我們旨在開發出多功能且強健的方法，用於偵測現實世界中的道德價值。我們的做法是使用 GPT 3.5 模型作為道德價值偵測的零次學習現成非監督式多標籤分類器，無需對標籤資料進行明確的訓練。我們將它與一個較小的基於 NLI 的零次學習模型進行比較。結果顯示，與 Davinci 模型相比，NLI 方法達到了競爭性的結果。此外，我們對監督式系統在跨領域多標籤道德價值偵測中的表現進行了深入調查。這包括在不同領域訓練監督式模型，以探索它們在處理來自不同來源的資料時的有效性，並將它們的表現與非監督式方法進行比較。我們的貢獻包括對跨領域價值偵測的監督式和非監督式方法進行徹底的分析。我們引進 Davinci 模型作為最先進的零次學習非監督式道德價值分類器，在無需對標籤資料進行明確訓練的情況下，推動了道德價值偵測的界限。此外，我們對我們的做法與監督式模型進行了比較評估，說明了它們各自的優缺點。</paragraph>

##### **Legal Judgment Reimagined: PredEx and the Rise of Intelligent AI Interpretation in Indian Courts**
2406.04136v1 by Shubham Kumar Nigam, Anurag Sharma, Danush Khanna, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya

In the era of Large Language Models (LLMs), predicting judicial outcomes
poses significant challenges due to the complexity of legal proceedings and the
scarcity of expert-annotated datasets. Addressing this, we introduce
\textbf{Pred}iction with \textbf{Ex}planation (\texttt{PredEx}), the largest
expert-annotated dataset for legal judgment prediction and explanation in the
Indian context, featuring over 15,000 annotations. This groundbreaking corpus
significantly enhances the training and evaluation of AI models in legal
analysis, with innovations including the application of instruction tuning to
LLMs. This method has markedly improved the predictive accuracy and explanatory
depth of these models for legal judgments. We employed various
transformer-based models, tailored for both general and Indian legal contexts.
Through rigorous lexical, semantic, and expert assessments, our models
effectively leverage \texttt{PredEx} to provide precise predictions and
meaningful explanations, establishing it as a valuable benchmark for both the
legal profession and the NLP community.

摘要：在大語言模型 (LLM) 的時代，預測法律結果由於法律程序的複雜性和專家註解資料集的稀少性而面臨重大挑戰。為了解決這個問題，我們引入了「預測」與「解釋」（PredEx），這是印度語境中最大的法律判決預測和解釋專家註解資料集，具有超過 15,000 個註解。這個開創性的語料庫顯著地增強了法律分析中 AI 模型的訓練和評估，創新之處包括將指令調整應用於 LLM。此方法顯著提高了這些模型對法律判決的預測準確度和解釋深度。我們採用了各種基於Transformer的模型，針對一般和印度法律背景進行調整。透過嚴謹的詞彙、語義和專家評估，我們的模型有效地利用 PredEx 提供精確的預測和有意義的解釋，使其成為法律專業和 NLP 社群的寶貴基準。

##### **Are We Done with MMLU?**
2406.04127v2 by Aryo Pradipta Gema, Joshua Ong Jun Leang, Giwon Hong, Alessio Devoto, Alberto Carlo Maria Mancino, Rohit Saxena, Xuanli He, Yu Zhao, Xiaotang Du, Mohammad Reza Ghasemi Madani, Claire Barale, Robert McHardy, Joshua Harris, Jean Kaddour, Emile van Krieken, Pasquale Minervini

Maybe not. We identify and analyse errors in the popular Massive Multitask
Language Understanding (MMLU) benchmark. Even though MMLU is widely adopted,
our analysis demonstrates numerous ground truth errors that obscure the true
capabilities of LLMs. For example, we find that 57% of the analysed questions
in the Virology subset contain errors. To address this issue, we introduce a
comprehensive framework for identifying dataset errors using a novel error
taxonomy. Then, we create MMLU-Redux, which is a subset of 3,000 manually
re-annotated questions across 30 MMLU subjects. Using MMLU-Redux, we
demonstrate significant discrepancies with the model performance metrics that
were originally reported. Our results strongly advocate for revising MMLU's
error-ridden questions to enhance its future utility and reliability as a
benchmark. Therefore, we open up MMLU-Redux for additional annotation
https://huggingface.co/datasets/edinburgh-dawg/mmlu-redux.

摘要：也許不是。我們識別和分析了流行的大規模多任務語言理解 (MMLU) 基準中的錯誤。儘管 MMLU 被廣泛採用，但我們的分析證明了許多掩蓋了 LLM 真正能力的真實錯誤。例如，我們發現病毒學子集中 57% 的分析問題包含錯誤。為了解決這個問題，我們引入了一個使用新錯誤分類法識別資料集錯誤的綜合框架。然後，我們建立了 MMLU-Redux，它是 30 個 MMLU 主題中 3,000 個手動重新註釋問題的子集。使用 MMLU-Redux，我們展示了與最初報告的模型效能指標有顯著差異。我們的結果強烈主張修改 MMLU 充滿錯誤的問題，以增強其作為基準的未來效用和可靠性。因此，我們開放 MMLU-Redux 以進行額外註釋 https://huggingface.co/datasets/edinburgh-dawg/mmlu-redux。

##### **Promoting Fairness and Diversity in Speech Datasets for Mental Health and Neurological Disorders Research**
2406.04116v1 by Eleonora Mancini, Ana Tanevska, Andrea Galassi, Alessio Galatolo, Federico Ruggeri, Paolo Torroni

Current research in machine learning and artificial intelligence is largely
centered on modeling and performance evaluation, less so on data collection.
However, recent research demonstrated that limitations and biases in data may
negatively impact trustworthiness and reliability. These aspects are
particularly impactful on sensitive domains such as mental health and
neurological disorders, where speech data are used to develop AI applications
aimed at improving the health of patients and supporting healthcare providers.
In this paper, we chart the landscape of available speech datasets for this
domain, to highlight possible pitfalls and opportunities for improvement and
promote fairness and diversity. We present a comprehensive list of desiderata
for building speech datasets for mental health and neurological disorders and
distill it into a checklist focused on ethical concerns to foster more
responsible research.

摘要：目前的機器學習和人工智慧研究主要集中在建模和效能評估上，較少著重於資料收集。然而，最近的研究表明，資料中的限制和偏見可能會對可信度和可靠性產生負面影響。這些面向在心理健康和神經疾病等敏感領域中特別具有影響力，在這些領域中，語音資料用於開發人工智慧應用程式，旨在改善患者健康並支援醫療保健提供者。在本文中，我們繪製了此領域可用的語音資料集概況，以強調可能的陷阱和改進機會，並促進公平性和多樣性。我們提供了一個全面的清單，說明了建立心理健康和神經疾病語音資料集的理想條件，並將其濃縮成一個專注於道德考量的檢查清單，以促進更負責任的研究。

##### **Uncovering Limitations of Large Language Models in Information Seeking from Tables**
2406.04113v1 by Chaoxu Pang, Yixuan Cao, Chunhao Yang, Ping Luo

Tables are recognized for their high information density and widespread
usage, serving as essential sources of information. Seeking information from
tables (TIS) is a crucial capability for Large Language Models (LLMs), serving
as the foundation of knowledge-based Q&A systems. However, this field presently
suffers from an absence of thorough and reliable evaluation. This paper
introduces a more reliable benchmark for Table Information Seeking (TabIS). To
avoid the unreliable evaluation caused by text similarity-based metrics, TabIS
adopts a single-choice question format (with two options per question) instead
of a text generation format. We establish an effective pipeline for generating
options, ensuring their difficulty and quality. Experiments conducted on 12
LLMs reveal that while the performance of GPT-4-turbo is marginally
satisfactory, both other proprietary and open-source models perform
inadequately. Further analysis shows that LLMs exhibit a poor understanding of
table structures, and struggle to balance between TIS performance and
robustness against pseudo-relevant tables (common in retrieval-augmented
systems). These findings uncover the limitations and potential challenges of
LLMs in seeking information from tables. We release our data and code to
facilitate further research in this field.

摘要：表格因其信息密度高和使用广泛而受到认可，是信息的重要来源。从表格中寻求信息 (TIS) 是大型语言模型 (LLM) 的一项关键能力，是基于知识的问答系统的基础。然而，该领域目前缺乏彻底且可靠的评估。本文为表格信息检索 (TabIS) 引入了一个更可靠的基准。为了避免基于文本相似性的指标造成的不可靠评估，TabIS 采用单选题格式（每个问题有两个选项），而不是文本生成格式。我们建立了一个有效的管道来生成选项，确保其难度和质量。对 12 个 LLM 进行的实验表明，虽然 GPT-4-turbo 的性能勉强令人满意，但其他专有模型和开源模型的性能都不够。进一步的分析表明，LLM 对表格结构的理解较差，并且难以在 TIS 性能和对伪相关表格（在检索增强系统中很常见）的鲁棒性之间取得平衡。这些发现揭示了 LLM 在从表格中寻求信息方面的局限性和潜在挑战。我们发布我们的数据和代码，以促进该领域的进一步研究。

##### **Compressible Dynamics in Deep Overparameterized Low-Rank Learning & Adaptation**
2406.04112v1 by Can Yaras, Peng Wang, Laura Balzano, Qing Qu

While overparameterization in machine learning models offers great benefits
in terms of optimization and generalization, it also leads to increased
computational requirements as model sizes grow. In this work, we show that by
leveraging the inherent low-dimensional structures of data and compressible
dynamics within the model parameters, we can reap the benefits of
overparameterization without the computational burdens. In practice, we
demonstrate the effectiveness of this approach for deep low-rank matrix
completion as well as fine-tuning language models. Our approach is grounded in
theoretical findings for deep overparameterized low-rank matrix recovery, where
we show that the learning dynamics of each weight matrix are confined to an
invariant low-dimensional subspace. Consequently, we can construct and train
compact, highly compressed factorizations possessing the same benefits as their
overparameterized counterparts. In the context of deep matrix completion, our
technique substantially improves training efficiency while retaining the
advantages of overparameterization. For language model fine-tuning, we propose
a method called "Deep LoRA", which improves the existing low-rank adaptation
(LoRA) technique, leading to reduced overfitting and a simplified
hyperparameter setup, while maintaining comparable efficiency. We validate the
effectiveness of Deep LoRA on natural language tasks, particularly when
fine-tuning with limited data.

摘要：雖然機器學習模型中的過度參數化在最佳化和泛化方面提供了極大的好處，但隨著模型大小的增加，它也導致運算需求增加。在這項工作中，我們展示了透過利用資料的內在低維度結構和模型參數中的可壓縮動態，我們可以在沒有運算負擔的情況下獲得過度參數化的優點。在實務上，我們展示了這種方法對於深度低秩矩陣完成功能以及微調語言模型的有效性。我們的做法奠基於深度過度參數化低秩矩陣復原的理論發現，我們在其中展示了每個權重矩陣的學習動態都侷限於不變的低維度子空間。因此，我們可以建構並訓練出緊湊、高度壓縮的分解，它們具有與過度參數化對應項相同的好處。在深度矩陣完成功能的背景下，我們的技術大幅改善了訓練效率，同時保留了過度參數化的優點。對於語言模型微調，我們提出了一種稱為「深度 LoRA」的方法，它改進了現有的低秩適應 (LoRA) 技術，導致過度擬合減少和簡化的超參數設定，同時維持相當的效率。我們驗證了深度 LoRA 在自然語言任務中的有效性，特別是在使用有限資料進行微調時。

##### **Intention and Face in Dialog**
2406.04109v1 by Adil Soubki, Owen Rambow

The notion of face described by Brown and Levinson (1987) has been studied in
great detail, but a critical aspect of the framework, that which focuses on how
intentions mediate the planning of turns which impose upon face, has received
far less attention. We present an analysis of three computational systems
trained for classifying both intention and politeness, focusing on how the
former influences the latter. In politeness theory, agents attend to the desire
to have their wants appreciated (positive face), and a complementary desire to
act unimpeded and maintain freedom (negative face). Similar to speech acts,
utterances can perform so-called face acts which can either raise or threaten
the positive or negative face of the speaker or hearer. We begin by using an
existing corpus to train a model which classifies face acts, achieving a new
SoTA in the process. We then observe that every face act has an underlying
intention that motivates it and perform additional experiments integrating
dialog act annotations to provide these intentions by proxy. Our analysis finds
that dialog acts improve performance on face act detection for minority classes
and points to a close relationship between aspects of face and intent.

摘要：布朗和莱文森 (1987) 所描述的面子概念已获得详细研究，但该框架的一个关键方面，即关注意图如何调解强加于面的轮流计划，却鲜受关注。我们对三个计算系统进行了分析，这些系统经过训练可以对意图和礼貌进行分类，重点关注前者如何影响后者。在礼貌理论中，代理人会关注希望得到欣赏的愿望（积极的面子），以及不受阻碍和保持自由的互补愿望（消极的面子）。与言语行为类似，话语可以执行所谓的言语行为，这些行为可以提升或威胁说话者或听者的积极或消极面子。我们首先使用现有语料库来训练一个模型，该模型对言语行为进行分类，在此过程中实现了新的 SoTA。然后我们观察到，每个言语行为都有一个潜在的意图来激励它，并执行额外的实验，整合对话行为注释以通过代理提供这些意图。我们的分析发现，对话行为提高了少数类别的言语行为检测性能，并指出了面部和意图方面之间的密切关系。

##### **Explainability and Hate Speech: Structured Explanations Make Social Media Moderators Faster**
2406.04106v1 by Agostina Calabrese, Leonardo Neves, Neil Shah, Maarten W. Bos, Björn Ross, Mirella Lapata, Francesco Barbieri

Content moderators play a key role in keeping the conversation on social
media healthy. While the high volume of content they need to judge represents a
bottleneck to the moderation pipeline, no studies have explored how models
could support them to make faster decisions. There is, by now, a vast body of
research into detecting hate speech, sometimes explicitly motivated by a desire
to help improve content moderation, but published research using real content
moderators is scarce. In this work we investigate the effect of explanations on
the speed of real-world moderators. Our experiments show that while generic
explanations do not affect their speed and are often ignored, structured
explanations lower moderators' decision making time by 7.4%.

摘要：內容審核員在維持社群媒體對話的健康方面扮演著關鍵角色。儘管他們需要判斷的內容數量龐大，對審核流程來說是一大瓶頸，但沒有任何研究探討模型如何協助他們做出更快速的決定。到目前為止，針對仇恨言論偵測的研究已相當廣泛，有時明確地受到改善內容審核的願望所驅動，但使用真實內容審核員的已發表研究卻相當稀少。在這項工作中，我們探討解釋對真實世界審核員速度的影響。我們的實驗顯示，儘管一般性的解釋不會影響他們的速度，且經常被忽略，但結構化的解釋可以將審核員的決策時間縮短 7.4%。

##### **Multistep Distillation of Diffusion Models via Moment Matching**
2406.04103v1 by Tim Salimans, Thomas Mensink, Jonathan Heek, Emiel Hoogeboom

We present a new method for making diffusion models faster to sample. The
method distills many-step diffusion models into few-step models by matching
conditional expectations of the clean data given noisy data along the sampling
trajectory. Our approach extends recently proposed one-step methods to the
multi-step case, and provides a new perspective by interpreting these
approaches in terms of moment matching. By using up to 8 sampling steps, we
obtain distilled models that outperform not only their one-step versions but
also their original many-step teacher models, obtaining new state-of-the-art
results on the Imagenet dataset. We also show promising results on a large
text-to-image model where we achieve fast generation of high resolution images
directly in image space, without needing autoencoders or upsamplers.

摘要：我們提出了一種新的方法來加快擴散模型的取樣速度。該方法通過匹配沿著取樣軌跡給定雜訊資料的乾淨資料的條件期望，將多步驟擴散模型轉化為少步驟模型。我們的做法將最近提出的單步驟方法擴展到多步驟情況，並通過根據矩匹配來解釋這些方法，提供了一個新的觀點。通過使用多達 8 個取樣步驟，我們獲得了優於其單步驟版本以及其原始多步驟教師模型的精煉模型，在 Imagenet 資料集上獲得了新的最先進的結果。我們還展示了大型文字到影像模型上的有希望的結果，我們在影像空間中直接快速生成高解析度影像，而不需要自動編碼器或上採樣器。

##### **Enhancing Weather Predictions: Super-Resolution via Deep Diffusion Models**
2406.04099v1 by Jan Martinů, Petr Šimánek

This study investigates the application of deep-learning diffusion models for
the super-resolution of weather data, a novel approach aimed at enhancing the
spatial resolution and detail of meteorological variables. Leveraging the
capabilities of diffusion models, specifically the SR3 and ResDiff
architectures, we present a methodology for transforming low-resolution weather
data into high-resolution outputs. Our experiments, conducted using the
WeatherBench dataset, focus on the super-resolution of the two-meter
temperature variable, demonstrating the models' ability to generate detailed
and accurate weather maps. The results indicate that the ResDiff model, further
improved by incorporating physics-based modifications, significantly
outperforms traditional SR3 methods in terms of Mean Squared Error (MSE),
Structural Similarity Index (SSIM), and Peak Signal-to-Noise Ratio (PSNR). This
research highlights the potential of diffusion models in meteorological
applications, offering insights into their effectiveness, challenges, and
prospects for future advancements in weather prediction and climate analysis.

摘要：本研究探討了深度學習擴散模型在天氣資料超解析度中的應用，這是一種旨在增強氣象變數空間解析度和細節的新方法。利用擴散模型的能力，特別是 SR3 和 ResDiff 架構，我們提出了一種將低解析度天氣資料轉換為高解析度輸出的方法。我們的實驗使用 WeatherBench 資料集進行，重點放在兩公尺溫度變數的超解析度，展示了模型生成詳細且準確天氣圖的能力。結果表明，ResDiff 模型進一步結合了基於物理的修改，在均方誤差 (MSE)、結構相似性指標 (SSIM) 和峰值信噪比 (PSNR) 方面顯著優於傳統的 SR3 方法。這項研究突出了擴散模型在氣象應用中的潛力，提供了對其有效性、挑戰和未來天氣預測和氣候分析進展前景的見解。

##### **Scaling and evaluating sparse autoencoders**
2406.04093v1 by Leo Gao, Tom Dupré la Tour, Henk Tillman, Gabriel Goh, Rajan Troll, Alec Radford, Ilya Sutskever, Jan Leike, Jeffrey Wu

Sparse autoencoders provide a promising unsupervised approach for extracting
interpretable features from a language model by reconstructing activations from
a sparse bottleneck layer. Since language models learn many concepts,
autoencoders need to be very large to recover all relevant features. However,
studying the properties of autoencoder scaling is difficult due to the need to
balance reconstruction and sparsity objectives and the presence of dead
latents. We propose using k-sparse autoencoders [Makhzani and Frey, 2013] to
directly control sparsity, simplifying tuning and improving the
reconstruction-sparsity frontier. Additionally, we find modifications that
result in few dead latents, even at the largest scales we tried. Using these
techniques, we find clean scaling laws with respect to autoencoder size and
sparsity. We also introduce several new metrics for evaluating feature quality
based on the recovery of hypothesized features, the explainability of
activation patterns, and the sparsity of downstream effects. These metrics all
generally improve with autoencoder size. To demonstrate the scalability of our
approach, we train a 16 million latent autoencoder on GPT-4 activations for 40
billion tokens. We release training code and autoencoders for open-source
models, as well as a visualizer.

摘要：稀疏自動編碼器提供了一種有前途的非監督式方法，可以通過重建稀疏瓶頸層的激活來從語言模型中提取可解釋特徵。由於語言模型學習了很多概念，因此自動編碼器需要非常大才能恢復所有相關特徵。然而，由於需要平衡重建和稀疏性目標以及存在死潛在變量，因此研究自動編碼器擴展的屬性很困難。我們建議使用 k 稀疏自動編碼器 [Makhzani 和 Frey，2013] 來直接控制稀疏性，簡化調整並改善重建稀疏性前沿。此外，我們發現即使在我們嘗試的最大規模下，修改也會導致很少的死潛在變量。使用這些技術，我們發現了關於自動編碼器大小和稀疏性的清晰擴展定律。我們還引入了幾個新的指標，用於基於假設特徵的恢復、激活模式的可解釋性和下游影響的稀疏性來評估特徵質量。這些指標通常隨著自動編碼器的大小而提高。為了證明我們方法的可擴展性，我們在 GPT-4 激活上訓練了一個 1600 萬潛在自動編碼器，用於 400 億個符號。我們發布了用於開源模型的訓練代碼和自動編碼器，以及一個可視化器。

##### **On Limitation of Transformer for Learning HMMs**
2406.04089v1 by Jiachen Hu, Qinghua Liu, Chi Jin

Despite the remarkable success of Transformer-based architectures in various
sequential modeling tasks, such as natural language processing, computer
vision, and robotics, their ability to learn basic sequential models, like
Hidden Markov Models (HMMs), is still unclear. This paper investigates the
performance of Transformers in learning HMMs and their variants through
extensive experimentation and compares them to Recurrent Neural Networks
(RNNs). We show that Transformers consistently underperform RNNs in both
training speed and testing accuracy across all tested HMM models. There are
even challenging HMM instances where Transformers struggle to learn, while RNNs
can successfully do so. Our experiments further reveal the relation between the
depth of Transformers and the longest sequence length it can effectively learn,
based on the types and the complexity of HMMs. To address the limitation of
transformers in modeling HMMs, we demonstrate that a variant of the
Chain-of-Thought (CoT), called $\textit{block CoT}$ in the training phase, can
help transformers to reduce the evaluation error and to learn longer sequences
at a cost of increasing the training time. Finally, we complement our empirical
findings by theoretical results proving the expressiveness of transformers in
approximating HMMs with logarithmic depth.

摘要：儘管 Transformer 基礎架構在各種序列建模任務中獲得顯著的成功，例如自然語言處理、電腦視覺和機器人技術，但它們學習基本序列模型（例如隱藏馬可夫模型 (HMM)）的能力仍不清楚。本文透過廣泛的實驗調查 Transformer 在學習 HMM 及其變體方面的效能，並將它們與遞迴神經網路 (RNN) 進行比較。我們表明，在所有測試的 HMM 模型中，Transformer 在訓練速度和測試準確度方面都持續表現不如 RNN。甚至有一些具有挑戰性的 HMM 實例讓 Transformer 難以學習，而 RNN 可以成功做到。我們的實驗進一步揭示了 Transformer 的深度與它可以有效學習的最長序列長度之間的關係，這取決於 HMM 的類型和複雜性。為了解決 Transformer 在建模 HMM 方面的限制，我們證明了在訓練階段稱為 $\textit{區塊 CoT}$ 的思維鏈 (CoT) 變體，可以幫助 Transformer 減少評估誤差並在增加訓練時間的代價下學習更長的序列。最後，我們透過證明 Transformer 在使用對數深度近似 HMM 時的表現力，以理論結果補充我們的經驗發現。

##### **Batch-in-Batch: a new adversarial training framework for initial perturbation and sample selection**
2406.04070v1 by Yinting Wu, Pai Peng, Bo Cai, Le Li, .

Adversarial training methods commonly generate independent initial
perturbation for adversarial samples from a simple uniform distribution, and
obtain the training batch for the classifier without selection. In this work,
we propose a simple yet effective training framework called Batch-in-Batch (BB)
to enhance models robustness. It involves specifically a joint construction of
initial values that could simultaneously generates $m$ sets of perturbations
from the original batch set to provide more diversity for adversarial samples;
and also includes various sample selection strategies that enable the trained
models to have smoother losses and avoid overconfident outputs. Through
extensive experiments on three benchmark datasets (CIFAR-10, SVHN, CIFAR-100)
with two networks (PreActResNet18 and WideResNet28-10) that are used in both
the single-step (Noise-Fast Gradient Sign Method, N-FGSM) and multi-step
(Projected Gradient Descent, PGD-10) adversarial training, we show that models
trained within the BB framework consistently have higher adversarial accuracy
across various adversarial settings, notably achieving over a 13% improvement
on the SVHN dataset with an attack radius of 8/255 compared to the N-FGSM
baseline model. Furthermore, experimental analysis of the efficiency of both
the proposed initial perturbation method and sample selection strategies
validates our insights. Finally, we show that our framework is cost-effective
in terms of computational resources, even with a relatively large value of $m$.

摘要：對抗訓練方法通常會從簡單的均勻分佈中為對抗樣本生成獨立的初始擾動，並在沒有選擇的情況下為分類器取得訓練批次。在這項工作中，我們提出了一個簡單但有效的訓練框架，稱為批次中的批次 (BB)，以增強模型的魯棒性。它特別涉及初始值的聯合構造，可以同時從原始批次集中生成 $m$ 組擾動，以提供更多樣化的對抗樣本；還包括各種樣本選擇策略，使訓練後的模型具有更平滑的損失並避免過度自信的輸出。通過在三個基準數據集 (CIFAR-10、SVHN、CIFAR-100) 上進行廣泛的實驗，使用兩個網路 (PreActResNet18 和 WideResNet28-10)，這些網路用於單步 (Noise-Fast Gradient Sign Method, N-FGSM) 和多步 (Projected Gradient Descent, PGD-10) 對抗訓練，我們表明在 BB 框架內訓練的模型在各種對抗設置中始終具有更高的對抗準確度，特別是在攻擊半徑為 8/255 的 SVHN 數據集上實現了超過 13% 的改進，與 N-FGSM 基準模型相比。此外，對所提出的初始擾動方法和樣本選擇策略的效率的實驗分析驗證了我們的見解。最後，我們表明我們的框架在計算資源方面具有成本效益，即使 $m$ 的值相對較大。

##### **Ask LLMs Directly, "What shapes your bias?": Measuring Social Bias in Large Language Models**
2406.04064v1 by Jisu Shin, Hoyun Song, Huije Lee, Soyeong Jeong, Jong C. Park

Social bias is shaped by the accumulation of social perceptions towards
targets across various demographic identities. To fully understand such social
bias in large language models (LLMs), it is essential to consider the composite
of social perceptions from diverse perspectives among identities. Previous
studies have either evaluated biases in LLMs by indirectly assessing the
presence of sentiments towards demographic identities in the generated text or
measuring the degree of alignment with given stereotypes. These methods have
limitations in directly quantifying social biases at the level of distinct
perspectives among identities. In this paper, we aim to investigate how social
perceptions from various viewpoints contribute to the development of social
bias in LLMs. To this end, we propose a novel strategy to intuitively quantify
these social perceptions and suggest metrics that can evaluate the social
biases within LLMs by aggregating diverse social perceptions. The experimental
results show the quantitative demonstration of the social attitude in LLMs by
examining social perception. The analysis we conducted shows that our proposed
metrics capture the multi-dimensional aspects of social bias, enabling a
fine-grained and comprehensive investigation of bias in LLMs.

摘要：社會偏見是由社會對各種人口特徵身分目標的社會認知累積所形塑。要完全了解大型語言模型 (LLM) 中的此類社會偏見，必須考量身分之間來自不同觀點的社會認知組合。先前的研究已透過間接評估產生文字中對人口特徵身分的觀點存在，或衡量與既定刻板印象的一致程度，來評估 LLM 中的偏見。這些方法在直接量化身分之間不同觀點層級的社會偏見方面有其限制。在本文中，我們旨在探討來自不同觀點的社會認知如何促成 LLM 中社會偏見的發展。為此，我們提出了一種新穎的策略來直觀量化這些社會認知，並提出可透過彙總不同的社會認知來評估 LLM 中社會偏見的指標。實驗結果透過檢視社會認知，顯示 LLM 中社會態度的量化證明。我們進行的分析顯示，我們提出的指標捕捉了社會偏見的多面向面向，進而能對 LLM 中的偏見進行細緻且全面的探討。

##### **Leveraging SPD Matrices on Riemannian Manifolds in Quantum Classical Hybrid Models for Structural Health Monitoring**
2406.04055v1 by Azadeh Alavi, Sanduni Jayasinghe

Realtime finite element modeling of bridges assists modern structural health
monitoring systems by providing comprehensive insights into structural
integrity. This capability is essential for ensuring the safe operation of
bridges and preventing sudden catastrophic failures. However, FEM computational
cost and the need for realtime analysis pose significant challenges.
Additionally, the input data is a 7 dimensional vector, while the output is a
1017 dimensional vector, making accurate and efficient analysis particularly
difficult. In this study, we propose a novel hybrid quantum classical
Multilayer Perceptron pipeline leveraging Symmetric Positive Definite matrices
and Riemannian manifolds for effective data representation. To maintain the
integrity of the qubit structure, we utilize SPD matrices, ensuring data
representation is well aligned with the quantum computational framework.
Additionally, the method leverages polynomial feature expansion to capture
nonlinear relationships within the data. The proposed pipeline combines
classical fully connected neural network layers with quantum circuit layers to
enhance model performance and efficiency. Our experiments focused on various
configurations of such hybrid models to identify the optimal structure for
accurate and efficient realtime analysis. The best performing model achieved a
Mean Squared Error of 0.00031, significantly outperforming traditional methods.

摘要：橋樑的即時有限元素建模透過提供結構完整性的全面見解，協助現代結構健康監控系統。此功能對於確保橋樑安全操作和防止突然災難性故障至關重要。然而，有限元素方法的運算成本和即時分析的需求帶來了重大挑戰。此外，輸入資料是 7 維向量，而輸出是 1017 維向量，這使得準確而有效的分析特別困難。在本研究中，我們提出了一種新穎的混合量子經典多層感知器管道，利用對稱正定矩陣和黎曼流形進行有效的資料表示。為了維護量子位元結構的完整性，我們利用對稱正定矩陣，確保資料表示與量子運算框架完全一致。此外，此方法利用多項式特徵展開來擷取資料中的非線性關係。所提出的管道結合了經典全連接神經網路層和量子電路層，以增強模型效能和效率。我們的實驗專注於此類混合模型的各種配置，以識別準確且有效的即時分析的最佳結構。效能最佳的模型達到了 0.00031 的平均平方誤差，顯著優於傳統方法。

##### **Multivector Neurons: Better and Faster O(n)-Equivariant Clifford Graph Neural Networks**
2406.04052v1 by Cong Liu, David Ruhe, Patrick Forré

Most current deep learning models equivariant to $O(n)$ or $SO(n)$ either
consider mostly scalar information such as distances and angles or have a very
high computational complexity. In this work, we test a few novel message
passing graph neural networks (GNNs) based on Clifford multivectors, structured
similarly to other prevalent equivariant models in geometric deep learning. Our
approach leverages efficient invariant scalar features while simultaneously
performing expressive learning on multivector representations, particularly
through the use of the equivariant geometric product operator. By integrating
these elements, our methods outperform established efficient baseline models on
an N-Body simulation task and protein denoising task while maintaining a high
efficiency. In particular, we push the state-of-the-art error on the N-body
dataset to 0.0035 (averaged over 3 runs); an 8% improvement over recent
methods. Our implementation is available on Github.

摘要：目前大多數深度學習模型等變於 $O(n)$ 或 $SO(n)$，
主要考慮距離和角度等標量資訊或具有非常高的計算複雜度。在這項工作中，我們測試了幾個新穎的訊息傳遞圖神經網路 (GNN)，其基於克利福德多元向量，結構類似於幾何深度學習中其他流行的等變模型。我們的做法利用了有效的標量不變特徵，同時對多元向量表示進行表達性學習，特別是透過使用等變幾何乘積算子。透過整合這些元素，我們的模型在 N 體模擬任務和蛋白質去噪任務上優於既定的有效基準模型，同時保持高效率。特別是，我們將 N 體資料集上的最新錯誤推至 0.0035（在 3 次執行中取平均值）；比最近的方法進步了 8%。我們的實作可在 Github 上取得。

##### **ActionReasoningBench: Reasoning about Actions with and without Ramification Constraints**
2406.04046v1 by Divij Handa, Pavel Dolin, Shrinidhi Kumbhar, Chitta Baral, Tran Cao Son

Reasoning about actions and change (RAC) has historically driven the
development of many early AI challenges, such as the frame problem, and many AI
disciplines, including non-monotonic and commonsense reasoning. The role of RAC
remains important even now, particularly for tasks involving dynamic
environments, interactive scenarios, and commonsense reasoning. Despite the
progress of Large Language Models (LLMs) in various AI domains, their
performance on RAC is underexplored. To address this gap, we introduce a new
benchmark, ActionReasoningBench, encompassing 13 domains and rigorously
evaluating LLMs across eight different areas of RAC. These include - Object
Tracking, Fluent Tracking, State Tracking, Action Executability, Effects of
Actions, Numerical RAC, Hallucination Detection, and Composite Questions.
Furthermore, we also investigate the indirect effect of actions due to
ramification constraints for every domain. Finally, we evaluate our benchmark
using open-sourced and commercial state-of-the-art LLMs, including GPT-4o,
Gemini-1.0-Pro, Llama2-7b-chat, Llama2-13b-chat, Llama3-8b-instruct,
Gemma-2b-instruct, and Gemma-7b-instruct. Our findings indicate that these
models face significant challenges across all categories included in our
benchmark.

摘要：推理动作和变化 (RAC) 在历史上推动了许多早期人工智能挑战的发展，例如框架问题，以及许多人工智能学科，包括非单调推理和常识推理。RAC 的作用即使现在仍然很重要，特别是对于涉及动态环境、交互场景和常识推理的任务。尽管大型语言模型 (LLM) 在各个人工智能领域取得了进展，但它们在 RAC 上的性能却鲜为人知。为了解决这一差距，我们引入了一个新的基准 ActionReasoningBench，它涵盖 13 个领域，并严格评估了 LLM 在 RAC 的八个不同领域。其中包括 - 对象跟踪、流利跟踪、状态跟踪、动作可执行性、动作效果、数值 RAC、幻觉检测和复合问题。此外，我们还研究了由于每个域的分支约束而导致的动作的间接影响。最后，我们使用开源和商业最先进的 LLM（包括 GPT-4o、Gemini-1.0-Pro、Llama2-7b-chat、Llama2-13b-chat、Llama3-8b-instruct、Gemma-2b-instruct 和 Gemma-7b-instruct）评估了我们的基准。我们的研究结果表明，这些模型在我们基准中包含的所有类别中都面临着重大挑战。

##### **Shaping History: Advanced Machine Learning Techniques for the Analysis and Dating of Cuneiform Tablets over Three Millennia**
2406.04039v1 by Danielle Kapon, Michael Fire, Shai Gordin

Cuneiform tablets, emerging in ancient Mesopotamia around the late fourth
millennium BCE, represent one of humanity's earliest writing systems.
Characterized by wedge-shaped marks on clay tablets, these artifacts provided
insight into Mesopotamian civilization across various domains. Traditionally,
the analysis and dating of these tablets rely on subjective assessment of shape
and writing style, leading to uncertainties in pinpointing their exact temporal
origins. Recent advances in digitization have revolutionized the study of
cuneiform by enhancing accessibility and analytical capabilities. Our research
uniquely focuses on the silhouette of tablets as significant indicators of
their historical periods, diverging from most studies that concentrate on
textual content. Utilizing an unprecedented dataset of over 94,000 images from
the Cuneiform Digital Library Initiative collection, we apply deep learning
methods to classify cuneiform tablets, covering over 3,000 years of history. By
leveraging statistical, computational techniques, and generative modeling
through Variational Auto-Encoders (VAEs), we achieve substantial advancements
in the automatic classification of these ancient documents, focusing on the
tablets' silhouettes as key predictors. Our classification approach begins with
a Decision Tree using height-to-width ratios and culminates with a ResNet50
model, achieving a 61% macro F1-score for tablet silhouettes. Moreover, we
introduce novel VAE-powered tools to enhance explainability and enable
researchers to explore changes in tablet shapes across different eras and
genres. This research contributes to document analysis and diplomatics by
demonstrating the value of large-scale data analysis combined with statistical
methods. These insights offer valuable tools for historians and epigraphists,
enriching our understanding of cuneiform tablets and the cultures that produced
them.

摘要：<paragraph>楔形文字泥板，出现于大约公元前四千年末的古代美索不达米亚，代表了人类最早的书写系统之一。这些文物以泥板上的楔形标记为特征，为我们提供了对美索不达米亚文明各个领域的见解。传统上，对这些泥板的分析和断代依赖于对形状和书写风格的主观评估，这导致了在精确定位其确切时间起源方面的不确定性。最近数字化方面的进步通过增强可访问性和分析能力，彻底改变了对楔形文字的研究。我们的研究独特地关注泥板的轮廓作为其历史时期的重要指标，不同于大多数专注于文本内容的研究。利用来自楔形文字数字图书馆计划收藏的超过 94,000 张图像的空前数据集，我们应用深度学习方法对楔形文字泥板进行分类，涵盖了 3,000 多年的历史。通过利用统计、计算技术和通过变分自动编码器 (VAE) 进行生成建模，我们在这些古代文献的自动分类方面取得了实质性进展，重点关注泥板的轮廓作为关键预测指标。我们的分类方法从使用高宽比的决策树开始，并以 ResNet50 模型结束，为平板轮廓实现了 61% 的宏观 F1 分数。此外，我们引入了新颖的 VAE 驱动工具来增强可解释性，并使研究人员能够探索不同时代和类型中平板形状的变化。本研究通过展示大规模数据分析与统计方法相结合的价值，为文献分析和外交学做出了贡献。这些见解为历史学家和铭文学家提供了有价值的工具，丰富了我们对楔形文字泥板及其产生它们的文化的理解。</paragraph>

##### **Spatio-temporal Early Prediction based on Multi-objective Reinforcement Learning**
2406.04035v1 by Wei Shao, Yufan Kang, Ziyan Peng, Xiao Xiao, Lei Wang, Yuhui Yang, Flora D Salim

Accuracy and timeliness are indeed often conflicting goals in prediction
tasks. Premature predictions may yield a higher rate of false alarms, whereas
delaying predictions to gather more information can render them too late to be
useful. In applications such as wildfires, crimes, and traffic jams, timely
predictions are vital for safeguarding human life and property. Consequently,
finding a balance between accuracy and timeliness is crucial. In this paper, we
propose a spatio-temporal early prediction model based on Multi-Objective
reinforcement learning that can either implement an optimal policy given a
preference or infer the preference based on a small number of samples. The
model addresses two primary challenges: 1) enhancing the accuracy of early
predictions and 2) providing the optimal policy for determining the most
suitable prediction time for each area. Our method demonstrates superior
performance on three large-scale real-world datasets, surpassing existing
methods in early spatio-temporal prediction tasks.

摘要：在預測任務中，準確性和及時性往往是相互衝突的目標。過早的預測可能會產生較高的誤報率，而延遲預測以收集更多資訊可能會導致預測過於遲到而失去用處。在野火、犯罪和交通堵塞等應用中，及時的預測對於保障人命和財產至關重要。因此，在準確性和及時性之間取得平衡至關重要。在本文中，我們提出了一個基於多目標強化學習的時空早期預測模型，該模型可以根據偏好實施最佳策略，或根據少量樣本推斷偏好。該模型解決了兩個主要的挑戰：1）提高早期預測的準確性，以及 2）提供最佳策略來確定每個區域最合適的預測時間。我們的模型在三個大型真實世界資料集上展示了卓越的效能，在早期時空預測任務中超越了現有方法。

##### **Pre-trained Transformer Uncovers Meaningful Patterns in Human Mobility Data**
2406.04029v1 by Alameen Najjar

We empirically demonstrate that a transformer pre-trained on country-scale
unlabeled human mobility data learns embeddings capable, through fine-tuning,
of developing a deep understanding of the target geography and its
corresponding mobility patterns. Utilizing an adaptation framework, we evaluate
the performance of our pre-trained embeddings in encapsulating a broad spectrum
of concepts directly and indirectly related to human mobility. This includes
basic notions, such as geographic location and distance, and extends to more
complex constructs, such as administrative divisions and land cover. Our
extensive empirical analysis reveals a substantial performance boost gained
from pre-training, reaching up to 38% in tasks such as tree-cover regression.
We attribute this result to the ability of the pre-training to uncover
meaningful patterns hidden in the raw data, beneficial for modeling relevant
high-level concepts. The pre-trained embeddings emerge as robust
representations of regions and trajectories, potentially valuable for a wide
range of downstream applications.

摘要：我們透過實證證明，在國家級規模未標註人類流動性資料上預先訓練的轉換器，學習了能夠透過微調，發展對目標地理及其對應流動性模式的深入理解的嵌入。利用適應架構，我們評估了預先訓練的嵌入在概括與人類流動性直接和間接相關的廣泛概念方面的效能。這包括基本概念，例如地理位置和距離，並延伸到更複雜的結構，例如行政區劃和土地覆蓋。我們廣泛的實證分析揭示了從預訓練中獲得的顯著效能提升，在樹木覆蓋回歸等任務中達到 38%。我們將此結果歸因於預訓練揭示原始資料中隱藏的意義模式的能力，這有助於建模相關的高階概念。預先訓練的嵌入成為區域和軌跡的強健表示，對於廣泛的下游應用潛在有價值。

##### **The syntax-semantics interface in a child's path: A study of 3- to 11-year-olds' elicited production of Mandarin recursive relative clauses**
2406.04025v1 by Caimei Yang, Qihang Yang, Xingzhi Su, Chenxi Fu, Xiaoyi Wang, Ying Yan, Zaijiang Man

There have been apparently conflicting claims over the syntax-semantics
relationship in child acquisition. However, few of them have assessed the
child's path toward the acquisition of recursive relative clauses (RRCs). The
authors of the current paper did experiments to investigate 3- to 11-year-olds'
most-structured elicited production of eight Mandarin RRCs in a 4 (syntactic
types)*2 (semantic conditions) design. The four syntactic types were RRCs with
a subject-gapped RC embedded in an object-gapped RC (SORRCs), RRCs with an
object-gapped RC embedded in another object-gapped RC (OORRCs), RRCs with an
object-gapped RC embedded in a subject-gapped RC (OSRRCs), and RRCs with a
subject-gapped RC embedded in another subject-gapped RC (SSRRCs). Each
syntactic type was put in two conditions differing in internal semantics:
irreversible internal semantics (IIS) and reversible internal semantics (RIS).
For example, "the balloon that [the girl that _ eats the banana] holds _" is
SORRCs in the IIS condition; "the monkey that [the dog that _ bites the pig]
hits_" is SORRCs in the RIS condition. For each target, the participants were
provided with a speech-visual stimulus constructing a condition of irreversible
external semantics (IES). The results showed that SSRRCs, OSRRCs and SORRCs in
the IIS-IES condition were produced two years earlier than their counterparts
in the RIS-IES condition. Thus, a 2-stage development path is proposed: the
language acquisition device starts with the interface between (irreversible)
syntax and IIS, and ends with the interface between syntax and IES, both
abiding by the syntax-semantic interface principle.

摘要：<paragraph>在兒童習得過程中，對於語法語意關係一直存在著明顯的爭議性說法。然而，很少有人評估兒童習得遞歸關係子句 (RRC) 的途徑。本文作者進行了實驗，以調查 3 至 11 歲兒童在 4（語法類型）*2（語義條件）設計中對八個漢語 RRC 最結構化的引發性產生。四種語法類型是 RRC，其中一個主語間隙 RC 嵌入在一個賓語間隙 RC（SORRC）中，RRC，其中一個賓語間隙 RC 嵌入在另一個賓語間隙 RC（OORRC）中，RRC，其中一個賓語間隙 RC 嵌入在一個主語間隙 RC（OSRRC）中，以及 RRC，其中一個主語間隙 RC 嵌入在另一個主語間隙 RC（SSRRC）中。每種類型的語法都被置於兩個在內部語義上不同的條件中：不可逆內部語義（IIS）和可逆內部語義（RIS）。例如，「[那個女孩吃香蕉]拿著的那個氣球」在 IIS 條件下是 SORRC；「[那條狗咬豬]打的那隻猴子」在 RIS 條件下是 SORRC。對於每個目標，參與者都被提供了一個構建不可逆外部語義（IES）條件的語音視覺刺激。結果表明，在 IIS-IES 條件下的 SSRRC、OSRRC 和 SORRC 比在 RIS-IES 條件下的對應條件早兩年產生。因此，提出了 2 階段發展路徑：語言習得裝置從（不可逆）語法和 IIS 之間的介面開始，並以語法和 IES 之間的介面結束，兩者都遵守語法語義介面原則。</paragraph>

##### **American Sign Language Handshapes Reflect Pressures for Communicative Efficiency**
2406.04024v1 by Kayo Yin, Terry Regier, Dan Klein

Communicative efficiency is a prominent theory in linguistics and cognitive
science. While numerous studies have shown how the pressure to save energy is
reflected in the form of spoken languages, few have explored this phenomenon in
signed languages. In this paper, we show how handshapes in American Sign
Language (ASL) reflect these efficiency pressures and we present new evidence
of communicative efficiency in the visual-gestural modality.
  We focus on handshapes that are used in both native ASL signs and signs
borrowed from English to compare efficiency pressures from both ASL and
English. First, we design new methodologies to quantify the articulatory effort
required to produce handshapes as well as the perceptual effort needed to
recognize them. Then, we compare correlations between communicative effort and
usage statistics in ASL and English. Our findings reveal that frequent ASL
handshapes are easier to produce and that pressures for communicative
efficiency mostly come from ASL usage, not from English lexical borrowing.

摘要：溝通效率是語言學和認知科學中一項顯著的理論。雖然許多研究已表明節省能量的壓力如何反映在口語形式中，但很少有人在手語中探討這種現象。在本文中，我們展示了美國手語 (ASL) 中的手勢如何反映這些效率壓力，並且我們提供了視覺手勢模式中溝通效率的新證據。
我們專注於在 ASL 手勢和從英語借來的符號中使用的形狀，以比較來自 ASL 和英語的效率壓力。首先，我們設計新的方法來量化產生手勢所需的發音努力以及識別手勢所需的感知努力。然後，我們比較了 ASL 和英語中溝通努力和使用統計數據之間的相關性。我們的發現表明，常見的 ASL 手勢更容易產生，而且溝通效率的壓力主要來自 ASL 使用，而不是來自英語詞彙借用。

##### **HackAtari: Atari Learning Environments for Robust and Continual Reinforcement Learning**
2406.03997v1 by Quentin Delfosse, Jannis Blüml, Bjarne Gregori, Kristian Kersting

Artificial agents' adaptability to novelty and alignment with intended
behavior is crucial for their effective deployment. Reinforcement learning (RL)
leverages novelty as a means of exploration, yet agents often struggle to
handle novel situations, hindering generalization. To address these issues, we
propose HackAtari, a framework introducing controlled novelty to the most
common RL benchmark, the Atari Learning Environment. HackAtari allows us to
create novel game scenarios (including simplification for curriculum learning),
to swap the game elements' colors, as well as to introduce different reward
signals for the agent. We demonstrate that current agents trained on the
original environments include robustness failures, and evaluate HackAtari's
efficacy in enhancing RL agents' robustness and aligning behavior through
experiments using C51 and PPO. Overall, HackAtari can be used to improve the
robustness of current and future RL algorithms, allowing Neuro-Symbolic RL,
curriculum RL, causal RL, as well as LLM-driven RL. Our work underscores the
significance of developing interpretable in RL agents.

摘要：人工代理的适应新穎性和與預期行為一致對其有效部署至關重要。強化學習 (RL) 利用新穎性作為探索的手段，但代理通常難以應對新穎情況，阻礙泛化。為了解決這些問題，我們提出了 HackAtari，一個在最常見的 RL 基準 Atari 學習環境中引入受控新穎性的框架。HackAtari 允許我們創建新穎的遊戲場景（包括簡化課程學習）、交換遊戲元素的顏色，以及為代理引入不同的獎勵信號。我們證明了在原始環境中訓練的當前代理包括穩健性故障，並通過使用 C51 和 PPO 的實驗評估了 HackAtari 在增強 RL 代理的穩健性和調整行為方面的功效。總的來說，HackAtari 可用於提高當前和未來 RL 演算法的穩健性，允許神經符號 RL、課程 RL、因果 RL，以及 LLM 驅動的 RL。我們的研究強調了在 RL 代理中開發可解釋性的重要性。

##### **AC4MPC: Actor-Critic Reinforcement Learning for Nonlinear Model Predictive Control**
2406.03995v1 by Rudolf Reiter, Andrea Ghezzi, Katrin Baumgärtner, Jasper Hoffmann, Robert D. McAllister, Moritz Diehl

\Ac{MPC} and \ac{RL} are two powerful control strategies with, arguably,
complementary advantages. In this work, we show how actor-critic \ac{RL}
techniques can be leveraged to improve the performance of \ac{MPC}. The \ac{RL}
critic is used as an approximation of the optimal value function, and an actor
roll-out provides an initial guess for primal variables of the \ac{MPC}. A
parallel control architecture is proposed where each \ac{MPC} instance is
solved twice for different initial guesses. Besides the actor roll-out
initialization, a shifted initialization from the previous solution is used.
Thereafter, the actor and the critic are again used to approximately evaluate
the infinite horizon cost of these trajectories. The control actions from the
lowest-cost trajectory are applied to the system at each time step. We
establish that the proposed algorithm is guaranteed to outperform the original
\ac{RL} policy plus an error term that depends on the accuracy of the critic
and decays with the horizon length of the \ac{MPC} formulation. Moreover, we do
not require globally optimal solutions for these guarantees to hold. The
approach is demonstrated on an illustrative toy example and an \ac{AD}
overtaking scenario.

摘要：\Ac{MPC} 和 \ac{RL} 是两种强大的控制策略，可以争辩说，具有互补的优势。在这项工作中，我们展示了如何利用 actor-critic \ac{RL} 技术来提高 \ac{MPC} 的性能。\ac{RL} 评论者用作最优值函数的近似值，并且 actor roll-out 为 \ac{MPC} 的原始变量提供初始猜测。提出了一种并行控制架构，其中每个 \ac{MPC} 实例针对不同的初始猜测求解两次。除了 actor roll-out 初始化之外，还使用了前一个解的偏移初始化。此后，actor 和评论者再次用于近似评估这些轨迹的无限范围成本。来自最低成本轨迹的控制动作在每个时间步长应用于系统。我们确定所提出的算法保证优于原始 \ac{RL} 策略，加上一个误差项，该误差项取决于评论者的准确性，并随着 \ac{MPC} 公式的范围长度而衰减。此外，我们不需要全局最优解来保持这些保证。该方法在一个说明性玩具示例和一个 \ac{AD} 超车场景中得到证明。

##### **Assessing LLMs for Zero-shot Abstractive Summarization Through the Lens of Relevance Paraphrasing**
2406.03993v1 by Hadi Askari, Anshuman Chhabra, Muhao Chen, Prasant Mohapatra

Large Language Models (LLMs) have achieved state-of-the-art performance at
zero-shot generation of abstractive summaries for given articles. However,
little is known about the robustness of such a process of zero-shot
summarization. To bridge this gap, we propose relevance paraphrasing, a simple
strategy that can be used to measure the robustness of LLMs as summarizers. The
relevance paraphrasing approach identifies the most relevant sentences that
contribute to generating an ideal summary, and then paraphrases these inputs to
obtain a minimally perturbed dataset. Then, by evaluating model performance for
summarization on both the original and perturbed datasets, we can assess the
LLM's one aspect of robustness. We conduct extensive experiments with relevance
paraphrasing on 4 diverse datasets, as well as 4 LLMs of different sizes
(GPT-3.5-Turbo, Llama-2-13B, Mistral-7B, and Dolly-v2-7B). Our results indicate
that LLMs are not consistent summarizers for the minimally perturbed articles,
necessitating further improvements.

摘要：大型語言模型 (LLM) 在特定文章的抽象摘要的零次學習生成中達到了最先進的性能。然而，對於這種零次學習摘要的過程的穩健性知之甚少。為了彌合這一差距，我們提出了相關性改述，這是一種可用于衡量 LLM 作為摘要的穩健性的簡單策略。相關性改述方法識別出對生成理想摘要貢獻最大的相關句子，然後改述這些輸入以獲取最小程度擾動的數據集。然後，通過評估模型在原始和擾動數據集上的摘要性能，我們可以評估 LLM 的穩健性的一個方面。我們對 4 個不同的數據集以及 4 個不同規模的 LLM（GPT-3.5-Turbo、Llama-2-13B、Mistral-7B 和 Dolly-v2-7B）進行了廣泛的相關性改述實驗。我們的結果表明，對於最小程度擾動的文章，LLM 不是一致的摘要，這需要進一步改進。

##### **On The Persona-based Summarization of Domain-Specific Documents**
2406.03986v1 by Ankan Mullick, Sombit Bose, Rounak Saha, Ayan Kumar Bhowmick, Pawan Goyal, Niloy Ganguly, Prasenjit Dey, Ravi Kokku

In an ever-expanding world of domain-specific knowledge, the increasing
complexity of consuming, and storing information necessitates the generation of
summaries from large information repositories. However, every persona of a
domain has different requirements of information and hence their summarization.
For example, in the healthcare domain, a persona-based (such as Doctor, Nurse,
Patient etc.) approach is imperative to deliver targeted medical information
efficiently. Persona-based summarization of domain-specific information by
humans is a high cognitive load task and is generally not preferred. The
summaries generated by two different humans have high variability and do not
scale in cost and subject matter expertise as domains and personas grow.
Further, AI-generated summaries using generic Large Language Models (LLMs) may
not necessarily offer satisfactory accuracy for different domains unless they
have been specifically trained on domain-specific data and can also be very
expensive to use in day-to-day operations. Our contribution in this paper is
two-fold: 1) We present an approach to efficiently fine-tune a domain-specific
small foundation LLM using a healthcare corpus and also show that we can
effectively evaluate the summarization quality using AI-based critiquing. 2) We
further show that AI-based critiquing has good concordance with Human-based
critiquing of the summaries. Hence, such AI-based pipelines to generate
domain-specific persona-based summaries can be easily scaled to other domains
such as legal, enterprise documents, education etc. in a very efficient and
cost-effective manner.

摘要：<paragraph>在不斷擴展的領域特定知識世界中，消耗和儲存資訊的複雜性日益增加，這使得必須從大型資訊儲存庫中產生摘要。然而，一個領域的每個人格對資訊有不同的需求，因此他們的摘要也不同。例如，在醫療保健領域，基於人格（例如醫生、護士、病人等）的方法對於有效傳遞有針對性的醫療資訊至關重要。由人類進行基於人格的領域特定資訊摘要是一種認知負擔很高的任務，通常不受青睞。由兩個人類產生的摘要有很高的可變性，並且隨著領域和人格的增長，在成本和主題專業知識方面無法擴展。此外，使用通用大型語言模型 (LLM) 生成的 AI 摘要可能無法為不同的領域提供令人滿意的準確性，除非它們經過特定領域資料的專門訓練，並且在日常操作中使用起來也可能非常昂貴。我們在這篇論文中的貢獻有兩個方面：1) 我們提出了一種使用醫療語料庫有效微調特定領域的小型基礎 LLM 的方法，並展示了我們可以使用基於 AI 的批評有效評估摘要品質。2) 我們進一步表明，基於 AI 的批評與基於人類的摘要批評具有良好的符合度。因此，這種基於 AI 的管道可以非常有效且具有成本效益地輕鬆擴展到其他領域，例如法律、企業文件、教育等，以產生特定領域的基於人格的摘要。</paragraph>

##### **A + B: A General Generator-Reader Framework for Optimizing LLMs to Unleash Synergy Potential**
2406.03963v1 by Wei Tang, Yixin Cao, Jiahao Ying, Bo Wang, Yuyue Zhao, Yong Liao, Pengyuan Zhou

Retrieval-Augmented Generation (RAG) is an effective solution to supplement
necessary knowledge to large language models (LLMs). Targeting its bottleneck
of retriever performance, "generate-then-read" pipeline is proposed to replace
the retrieval stage with generation from the LLM itself. Although promising,
this research direction is underexplored and still cannot work in the scenario
when source knowledge is given. In this paper, we formalize a general "A + B"
framework with varying combinations of foundation models and types for
systematic investigation. We explore the efficacy of the base and chat versions
of LLMs and found their different functionalities suitable for generator A and
reader B, respectively. Their combinations consistently outperform single
models, especially in complex scenarios. Furthermore, we extend the application
of the "A + B" framework to scenarios involving source documents through
continuous learning, enabling the direct integration of external knowledge into
LLMs. This approach not only facilitates effective acquisition of new knowledge
but also addresses the challenges of safety and helpfulness post-adaptation.
The paper underscores the versatility of the "A + B" framework, demonstrating
its potential to enhance the practical application of LLMs across various
domains.

摘要：擷取增強生成（RAG）是一種有效的解決方案，可以為大型語言模型（LLM）補充必要的知識。針對其擷取器效能的瓶頸，提議使用「先產生再閱讀」管線，以 LLM 本身的產生取代擷取階段。儘管很有前景，但這個研究方向仍未被充分探討，而且在提供來源知識的情況下仍然無法運作。在本文中，我們正式制定了一個通用的「A + B」架構，其中包含基礎模型和類型不同的組合，以進行系統性的調查。我們探討了 LLM 的基礎版本和聊天機器人版本的功效，並發現它們不同的功能分別適用於產生器 A 和閱讀器 B。它們的組合始終優於單一模型，尤其是在複雜的場景中。此外，我們透過持續學習將「A + B」架構的應用擴展到涉及來源文件的場景，讓外部知識能夠直接整合到 LLM 中。這種方法不僅有助於有效獲取新知識，還能解決適應後安全性與有益性的挑戰。本文強調了「A + B」架構的多功能性，展示了其在各種領域增強 LLM 實際應用的潛力。

##### **Tox-BART: Leveraging Toxicity Attributes for Explanation Generation of Implicit Hate Speech**
2406.03953v1 by Neemesh Yadav, Sarah Masud, Vikram Goyal, Vikram Goyal, Md Shad Akhtar, Tanmoy Chakraborty

Employing language models to generate explanations for an incoming implicit
hate post is an active area of research. The explanation is intended to make
explicit the underlying stereotype and aid content moderators. The training
often combines top-k relevant knowledge graph (KG) tuples to provide world
knowledge and improve performance on standard metrics. Interestingly, our study
presents conflicting evidence for the role of the quality of KG tuples in
generating implicit explanations. Consequently, simpler models incorporating
external toxicity signals outperform KG-infused models. Compared to the
KG-based setup, we observe a comparable performance for SBIC (LatentHatred)
datasets with a performance variation of +0.44 (+0.49), +1.83 (-1.56), and
-4.59 (+0.77) in BLEU, ROUGE-L, and BERTScore. Further human evaluation and
error analysis reveal that our proposed setup produces more precise
explanations than zero-shot GPT-3.5, highlighting the intricate nature of the
task.

摘要：利用語言模型為一個暗示性的仇恨文章產生解釋是一個活躍的研究領域。這個解釋的目的是要明確潛在的刻板印象並協助內容管理員。訓練通常結合前 k 個相關知識圖譜 (KG) 元組以提供世界知識並改善標準指標的效能。有趣的是，我們的研究提出矛盾的證據，說明 KG 元組的品質在產生暗示性解釋中所扮演的角色。因此，結合外部毒性訊號的較簡單模型優於融入 KG 的模型。與基於 KG 的設定相比，我們觀察到 SBIC (LatentHatred) 資料集有相近的效能，在 BLEU、ROUGE-L 和 BERTScore 中效能變化為 +0.44 (+0.49)、+1.83 (-1.56) 和 -4.59 (+0.77)。進一步的人類評估和錯誤分析顯示，我們提出的設定產生比零次學習 GPT-3.5 更精確的解釋，突顯出此任務的複雜本質。

##### **UltraMedical: Building Specialized Generalists in Biomedicine**
2406.03949v1 by Kaiyan Zhang, Sihang Zeng, Ermo Hua, Ning Ding, Zhang-Ren Chen, Zhiyuan Ma, Haoxin Li, Ganqu Cui, Biqing Qi, Xuekai Zhu, Xingtai Lv, Hu Jinfang, Zhiyuan Liu, Bowen Zhou

Large Language Models (LLMs) have demonstrated remarkable capabilities across
various domains and are moving towards more specialized areas. Recent advanced
proprietary models such as GPT-4 and Gemini have achieved significant
advancements in biomedicine, which have also raised privacy and security
challenges. The construction of specialized generalists hinges largely on
high-quality datasets, enhanced by techniques like supervised fine-tuning and
reinforcement learning from human or AI feedback, and direct preference
optimization. However, these leading technologies (e.g., preference learning)
are still significantly limited in the open source community due to the
scarcity of specialized data. In this paper, we present the UltraMedical
collections, which consist of high-quality manual and synthetic datasets in the
biomedicine domain, featuring preference annotations across multiple advanced
LLMs. By utilizing these datasets, we fine-tune a suite of specialized medical
models based on Llama-3 series, demonstrating breathtaking capabilities across
various medical benchmarks. Moreover, we develop powerful reward models skilled
in biomedical and general reward benchmark, enhancing further online preference
learning within the biomedical LLM community.

摘要：大型語言模型 (LLM) 已在各種領域展現出非凡的能力，並正朝向更專業的領域邁進。最近進步的專有模型，例如 GPT-4 和 Gemini，在生物醫學領域取得顯著進展，但也引發了隱私和安全挑戰。專門通才的建構在很大程度上取決於高品質的資料集，並透過監督微調和人類或 AI 回饋的強化學習等技術加以增強，以及直接偏好最佳化。然而，這些領先技術（例如偏好學習）由於缺乏專門資料，在開源社群中仍受到顯著限制。在本文中，我們提出了 UltraMedical 資料集，其中包含生物醫學領域的高品質手動和合成資料集，具有跨多個進階 LLM 的偏好標註。透過利用這些資料集，我們微調了一系列基於 Llama-3 系列的專業醫療模型，展示了跨各種醫療基準的驚人能力。此外，我們開發了在生物醫學和一般回饋基準方面技術高超的強大回饋模型，進一步增強了生物醫學 LLM 社群內的線上偏好學習。

##### **Culturally Aware and Adapted NLP: A Taxonomy and a Survey of the State of the Art**
2406.03930v1 by Chen Cecilia Liu, Iryna Gurevych, Anna Korhonen

The surge of interest in culturally aware and adapted Natural Language
Processing (NLP) has inspired much recent research. However, the lack of common
understanding of the concept of "culture" has made it difficult to evaluate
progress in this emerging area. Drawing on prior research in NLP and related
fields, we propose an extensive taxonomy of elements of culture that can
provide a systematic framework for analyzing and understanding research
progress. Using the taxonomy, we survey existing resources and models for
culturally aware and adapted NLP, providing an overview of the state of the art
and the research gaps that still need to be filled.

摘要：近年來，對文化感知和適應的自然語言處理 (NLP) 的興趣激增，激發了許多近期研究。然而，由於對「文化」概念缺乏共識，使得難以評估這個新興領域的進展。我們借鑑了 NLP 及相關領域先前的研究，提出了一個廣泛的文化元素分類法，可以提供一個系統性的架構來分析和理解研究進度。使用這個分類法，我們調查了現有的資源和模型，以了解文化感知和適應的 NLP，概述了當前技術水準和仍需要填補的研究空白。

##### **Vectorized Conditional Neural Fields: A Framework for Solving Time-dependent Parametric Partial Differential Equations**
2406.03919v1 by Jan Hagnberger, Marimuthu Kalimuthu, Daniel Musekamp, Mathias Niepert

Transformer models are increasingly used for solving Partial Differential
Equations (PDEs). Several adaptations have been proposed, all of which suffer
from the typical problems of Transformers, such as quadratic memory and time
complexity. Furthermore, all prevalent architectures for PDE solving lack at
least one of several desirable properties of an ideal surrogate model, such as
(i) generalization to PDE parameters not seen during training, (ii) spatial and
temporal zero-shot super-resolution, (iii) continuous temporal extrapolation,
(iv) support for 1D, 2D, and 3D PDEs, and (v) efficient inference for longer
temporal rollouts. To address these limitations, we propose Vectorized
Conditional Neural Fields (VCNeFs), which represent the solution of
time-dependent PDEs as neural fields. Contrary to prior methods, however,
VCNeFs compute, for a set of multiple spatio-temporal query points, their
solutions in parallel and model their dependencies through attention
mechanisms. Moreover, VCNeF can condition the neural field on both the initial
conditions and the parameters of the PDEs. An extensive set of experiments
demonstrates that VCNeFs are competitive with and often outperform existing
ML-based surrogate models.

摘要：Transformer模型日益用於求解偏微分方程式 (PDE)。已經提出多種改編，所有這些都遭受Transformer的典型問題，例如二次記憶體和時間複雜度。此外，所有流行的 PDE 求解架構都至少缺少理想代理模型的幾個理想屬性，例如 (i) 推廣到訓練期間未見的 PDE 參數，(ii) 空間和時間零次超解析度，(iii) 連續時間外推，(iv) 支援 1D、2D 和 3D PDE，以及 (v) 對較長時間滾動的有效推論。為了解決這些限制，我們提出向量化條件神經場 (VCNeF)，它將時間相關 PDE 的解表示為神經場。然而，與先前的辦法相反，VCNeF 對一組多重時空查詢點計算它們的解，並透過注意力機制建模它們的依賴性。此外，VCNeF 可以將神經場設定在 PDE 的初始條件和參數上。大量的實驗證明，VCNeF 與現有的基於 ML 的代理模型具有競爭力，而且通常表現優異。

##### **ArMeme: Propagandistic Content in Arabic Memes**
2406.03916v1 by Firoj Alam, Abul Hasnat, Fatema Ahmed, Md Arid Hasan, Maram Hasanain

With the rise of digital communication, memes have become a significant
medium for cultural and political expression that is often used to mislead
audiences. Identification of such misleading and persuasive multimodal content
has become more important among various stakeholders, including social media
platforms, policymakers, and the broader society as they often cause harm to
individuals, organizations, and/or society. While there has been effort to
develop AI-based automatic systems for resource-rich languages (e.g., English),
it is relatively little to none for medium to low resource languages. In this
study, we focused on developing an Arabic memes dataset with manual annotations
of propagandistic content. We annotated ~6K Arabic memes collected from various
social media platforms, which is a first resource for Arabic multimodal
research. We provide a comprehensive analysis aiming to develop computational
tools for their detection. We will make them publicly available for the
community.

摘要：隨著數位通訊的興起，迷因已成為文化和政治表達的重要媒介，常被用於誤導受眾。識別此類具有誤導性和說服力的多模態內容已成為各利益相關者之間更重要的事，包括社群媒體平台、政策制定者和廣大社會，因為它們通常會對個人、組織和/或社會造成傷害。雖然已努力為資源豐富的語言（例如英語）開發基於 AI 的自動系統，但對於中低資源語言來說卻相對較少甚至沒有。在本研究中，我們專注於開發具有宣傳內容手動註解的阿拉伯迷因資料集。我們註解了從各種社群媒體平台收集的約 6K 個阿拉伯迷因，這是阿拉伯多模態研究的第一個資源。我們提供全面的分析，旨在為其偵測開發運算工具。我們將讓它們公開提供給社群。

##### **GenSafe: A Generalizable Safety Enhancer for Safe Reinforcement Learning Algorithms Based on Reduced Order Markov Decision Process Model**
2406.03912v1 by Zhehua Zhou, Xuan Xie, Jiayang Song, Zhan Shu, Lei Ma

Although deep reinforcement learning has demonstrated impressive achievements
in controlling various autonomous systems, e.g., autonomous vehicles or
humanoid robots, its inherent reliance on random exploration raises safety
concerns in their real-world applications. To improve system safety during the
learning process, a variety of Safe Reinforcement Learning (SRL) algorithms
have been proposed, which usually incorporate safety constraints within the
Constrained Markov Decision Process (CMDP) framework. However, the efficacy of
these SRL algorithms often relies on accurate function approximations, a task
that is notably challenging to accomplish in the early learning stages due to
data insufficiency. To address this problem, we introduce a Genralizable Safety
enhancer (GenSafe) in this work. Leveraging model order reduction techniques,
we first construct a Reduced Order Markov Decision Process (ROMDP) as a
low-dimensional proxy for the original cost function in CMDP. Then, by solving
ROMDP-based constraints that are reformulated from the original cost
constraints, the proposed GenSafe refines the actions taken by the agent to
enhance the possibility of constraint satisfaction. Essentially, GenSafe acts
as an additional safety layer for SRL algorithms, offering broad compatibility
across diverse SRL approaches. The performance of GenSafe is examined on
multiple SRL benchmark problems. The results show that, it is not only able to
improve the safety performance, especially in the early learning phases, but
also to maintain the task performance at a satisfactory level.

摘要：儘管深度強化學習在控制各種自主系統中已展現令人印象深刻的成就，例如，自主車輛或類人機器人，其對隨機探索的內在依賴性卻在實際應用中引發了安全疑慮。為了在學習過程中提升系統安全性，已經提出多種安全強化學習 (SRL) 演算法，這些演算法通常在受限馬可夫決策過程 (CMDP) 架構中納入安全約束。然而，這些 SRL 演算法的效能通常依賴於精確的函數近似值，而這項任務在早期學習階段由於資料不足而難以達成。為了解決這個問題，我們在這項工作中引入了可概化安全性增強器 (GenSafe)。我們首先利用模型階數簡化技術，將受限馬可夫決策過程 (ROMDP) 建構為 CMDP 中原始成本函數的低維度代理。然後，透過求解從原始成本約束重新制定的基於 ROMDP 的約束，所提出的 GenSafe 會修正代理採取的動作，以提升約束滿足的可能性。GenSafe 本質上作為 SRL 演算法的額外安全層，在各種 SRL 方法中提供廣泛的相容性。GenSafe 的效能已在多個 SRL 基準問題中得到檢驗。結果顯示，它不僅能夠提升安全性效能，特別是在早期學習階段，還能將任務效能維持在令人滿意的水準。

##### **HeSum: a Novel Dataset for Abstractive Text Summarization in Hebrew**
2406.03897v1 by Tzuf Paz-Argaman, Itai Mondshine, Asaf Achi Mordechai, Reut Tsarfaty

While large language models (LLMs) excel in various natural language tasks in
English, their performance in lower-resourced languages like Hebrew, especially
for generative tasks such as abstractive summarization, remains unclear. The
high morphological richness in Hebrew adds further challenges due to the
ambiguity in sentence comprehension and the complexities in meaning
construction. In this paper, we address this resource and evaluation gap by
introducing HeSum, a novel benchmark specifically designed for abstractive text
summarization in Modern Hebrew. HeSum consists of 10,000 article-summary pairs
sourced from Hebrew news websites written by professionals. Linguistic analysis
confirms HeSum's high abstractness and unique morphological challenges. We show
that HeSum presents distinct difficulties for contemporary state-of-the-art
LLMs, establishing it as a valuable testbed for generative language technology
in Hebrew, and MRLs generative challenges in general.

摘要：儘管大型語言模型 (LLM) 在英語的各種自然語言任務中表現出色，但它們在希伯來語等資源較少的語言中的表現，特別是在抽象摘要等生成任務中，仍不明朗。希伯來語中豐富的形態豐富性增加了進一步的挑戰，因為句子理解中的含糊性以及意義建構的複雜性。在本文中，我們通過引入 HeSum 來解決這個資源和評估差距，HeSum 是一個專門為現代希伯來語的抽象文本摘要而設計的新基準。HeSum 包含 10,000 對文章摘要，這些摘要來自由專業人士撰寫的希伯來語新聞網站。語言分析證實了 HeSum 的高度抽象性和獨特的形態挑戰。我們表明，HeSum 對當代最先進的 LLM 構成了不同的困難，使其成為希伯來語生成語言技術的寶貴測試平台，以及一般 MRL 生成挑戰。

##### **How Good is Zero-Shot MT Evaluation for Low Resource Indian Languages?**
2406.03893v1 by Anushka Singh, Ananya B. Sai, Raj Dabre, Ratish Puduppully, Anoop Kunchukuttan, Mitesh M Khapra

While machine translation evaluation has been studied primarily for
high-resource languages, there has been a recent interest in evaluation for
low-resource languages due to the increasing availability of data and models.
In this paper, we focus on a zero-shot evaluation setting focusing on
low-resource Indian languages, namely Assamese, Kannada, Maithili, and Punjabi.
We collect sufficient Multi-Dimensional Quality Metrics (MQM) and Direct
Assessment (DA) annotations to create test sets and meta-evaluate a plethora of
automatic evaluation metrics. We observe that even for learned metrics, which
are known to exhibit zero-shot performance, the Kendall Tau and Pearson
correlations with human annotations are only as high as 0.32 and 0.45.
Synthetic data approaches show mixed results and overall do not help close the
gap by much for these languages. This indicates that there is still a long way
to go for low-resource evaluation.

摘要：儘管機器翻譯評估主要針對高資源語言進行研究，但由於資料和模型的可用性增加，最近開始有人關注低資源語言的評估。在本文中，我們專注於零次評估設定，重點放在低資源印度語言，即阿薩姆語、卡納達語、邁蒂利語和旁遮普語。我們收集足夠的多維度品質指標 (MQM) 和直接評估 (DA) 標註，以建立測試集並對大量自動評估指標進行元評估。我們觀察到，即使對於已學習的指標（已知會表現出零次效能），與人類標註的 Kendall Tau 和 Pearson 相關性也僅高達 0.32 和 0.45。合成資料方法顯示出不同的結果，而且整體而言，對於這些語言並未縮小差距太多。這表示低資源評估仍有很長一段路要走。

##### **Spontaneous Speech-Based Suicide Risk Detection Using Whisper and Large Language Models**
2406.03882v1 by Ziyun Cui, Chang Lei, Wen Wu, Yinan Duan, Diyang Qu, Ji Wu, Runsen Chen, Chao Zhang

The early detection of suicide risk is important since it enables the
intervention to prevent potential suicide attempts. This paper studies the
automatic detection of suicide risk based on spontaneous speech from
adolescents, and collects a Mandarin dataset with 15 hours of suicide speech
from more than a thousand adolescents aged from ten to eighteen for our
experiments. To leverage the diverse acoustic and linguistic features embedded
in spontaneous speech, both the Whisper speech model and textual large language
models (LLMs) are used for suicide risk detection. Both all-parameter
finetuning and parameter-efficient finetuning approaches are used to adapt the
pre-trained models for suicide risk detection, and multiple audio-text fusion
approaches are evaluated to combine the representations of Whisper and the LLM.
The proposed system achieves a detection accuracy of 0.807 and an F1-score of
0.846 on the test set with 119 subjects, indicating promising potential for
real suicide risk detection applications.

摘要：早期發現自殺風險非常重要，因為它能讓干預措施預防潛在的自殺企圖。本文研究了基於青少年自發性語言的自殺風險自動檢測，並收集了一個包含來自一千多名年齡在十到十八歲的青少年 15 小時的自殺語音的普通話數據集，以進行我們的實驗。為了利用自發性語言中嵌入的多樣化聲學和語言特徵，Whisper 語音模型和文本大型語言模型 (LLM) 都被用於自殺風險檢測。所有參數微調和參數高效微調方法都用於調整預訓練模型以進行自殺風險檢測，並評估了多種音頻文本融合方法以結合 Whisper 和 LLM 的表徵。所提出的系統在包含 119 名受試者的測試集中實現了 0.807 的檢測準確率和 0.846 的 F1 分數，表明了對真實自殺風險檢測應用具有良好的潛力。

##### **Evaluating the IWSLT2023 Speech Translation Tasks: Human Annotations, Automatic Metrics, and Segmentation**
2406.03881v1 by Matthias Sperber, Ondřej Bojar, Barry Haddow, Dávid Javorský, Xutai Ma, Matteo Negri, Jan Niehues, Peter Polák, Elizabeth Salesky, Katsuhito Sudoh, Marco Turchi

Human evaluation is a critical component in machine translation system
development and has received much attention in text translation research.
However, little prior work exists on the topic of human evaluation for speech
translation, which adds additional challenges such as noisy data and
segmentation mismatches. We take first steps to fill this gap by conducting a
comprehensive human evaluation of the results of several shared tasks from the
last International Workshop on Spoken Language Translation (IWSLT 2023). We
propose an effective evaluation strategy based on automatic resegmentation and
direct assessment with segment context. Our analysis revealed that: 1) the
proposed evaluation strategy is robust and scores well-correlated with other
types of human judgements; 2) automatic metrics are usually, but not always,
well-correlated with direct assessment scores; and 3) COMET as a slightly
stronger automatic metric than chrF, despite the segmentation noise introduced
by the resegmentation step systems. We release the collected human-annotated
data in order to encourage further investigation.

摘要：人工評估是機器翻譯系統開發中的關鍵組成部分，並在文本翻譯研究中受到廣泛關注。
然而，對於語音翻譯的人工評估主題，目前幾乎沒有先前的研究，而語音翻譯增加了額外的挑戰，例如有雜訊的資料和分段不匹配。我們採取第一步來填補這一空白，對來自上屆國際口語語言翻譯研討會 (IWSLT 2023) 的幾個共享任務的結果進行全面的人工評估。我們提出了一種基於自動重新分段和直接評估與分段上下文相關的有效評估策略。我們的分析顯示：1) 提出的評估策略強健且評分與其他類型的人工判斷具有良好的相關性；2) 自動化指標通常（但並非總是）與直接評估分數具有良好的相關性；3) COMET 是一個略強於 chrF 的自動化指標，儘管重新分段步驟系統引入了分段雜訊。我們發布收集到的人工標註資料，以鼓勵進一步的研究。

##### **Memorization in deep learning: A survey**
2406.03880v1 by Jiaheng Wei, Yanjun Zhang, Leo Yu Zhang, Ming Ding, Chao Chen, Kok-Leong Ong, Jun Zhang, Yang Xiang

Deep Learning (DL) powered by Deep Neural Networks (DNNs) has revolutionized
various domains, yet understanding the intricacies of DNN decision-making and
learning processes remains a significant challenge. Recent investigations have
uncovered an interesting memorization phenomenon in which DNNs tend to memorize
specific details from examples rather than learning general patterns, affecting
model generalization, security, and privacy. This raises critical questions
about the nature of generalization in DNNs and their susceptibility to security
breaches. In this survey, we present a systematic framework to organize
memorization definitions based on the generalization and security/privacy
domains and summarize memorization evaluation methods at both the example and
model levels. Through a comprehensive literature review, we explore DNN
memorization behaviors and their impacts on security and privacy. We also
introduce privacy vulnerabilities caused by memorization and the phenomenon of
forgetting and explore its connection with memorization. Furthermore, we
spotlight various applications leveraging memorization and forgetting
mechanisms, including noisy label learning, privacy preservation, and model
enhancement. This survey offers the first-in-kind understanding of memorization
in DNNs, providing insights into its challenges and opportunities for enhancing
AI development while addressing critical ethical concerns.

摘要：深度學習 (DL) 由深度神經網路 (DNN) 所驅動，已徹底改變了各個領域，然而要了解 DNN 決策制定和學習過程的複雜性仍然是一項重大的挑戰。最近的研究發現了一個有趣的記憶現象，DNN 傾向於記住範例中的特定細節，而不是學習一般模式，影響模型的概化、安全性與隱私。這引發了關於 DNN 中概化的本質及其對安全漏洞的敏感性的關鍵問題。在這項調查中，我們提出一個系統性架構來整理基於概化與安全/隱私領域的記憶定義，並在範例和模型層級總結記憶評估方法。透過全面的文獻回顧，我們探討 DNN 記憶行為及其對安全與隱私的影響。我們也介紹由記憶所造成的隱私漏洞和遺忘現象，並探討它與記憶的關聯。此外，我們重點介紹利用記憶和遺忘機制的各種應用，包括雜訊標籤學習、隱私保護和模型增強。這項調查提供了第一個關於 DNN 中記憶的理解，提供對其挑戰和機會的見解，以增強 AI 開發，同時解決關鍵的倫理問題。

##### **Decoder-only Streaming Transformer for Simultaneous Translation**
2406.03878v1 by Shoutao Guo, Shaolei Zhang, Yang Feng

Simultaneous Machine Translation (SiMT) generates translation while reading
source tokens, essentially producing the target prefix based on the source
prefix. To achieve good performance, it leverages the relationship between
source and target prefixes to exact a policy to guide the generation of
translations. Although existing SiMT methods primarily focus on the
Encoder-Decoder architecture, we explore the potential of Decoder-only
architecture, owing to its superior performance in various tasks and its
inherent compatibility with SiMT. However, directly applying the Decoder-only
architecture to SiMT poses challenges in terms of training and inference. To
alleviate the above problems, we propose the first Decoder-only SiMT model,
named Decoder-only Streaming Transformer (DST). Specifically, DST separately
encodes the positions of the source and target prefixes, ensuring that the
position of the target prefix remains unaffected by the expansion of the source
prefix. Furthermore, we propose a Streaming Self-Attention (SSA) mechanism
tailored for the Decoder-only architecture. It is capable of obtaining
translation policy by assessing the sufficiency of input source information and
integrating with the soft-attention mechanism to generate translations.
Experiments demonstrate that our approach achieves state-of-the-art performance
on three translation tasks.

摘要：同時間機器翻譯 (SiMT) 在讀取原始語言符號時產生翻譯，基本上根據原始語言前綴產生目標語言前綴。為了達到良好的效能，它利用原始語言和目標語言前綴之間的關係來制定一個準則，以引導翻譯的產生。儘管現有的 SiMT 方法主要關注編碼器-解碼器架構，但我們探索了僅解碼器架構的潛力，因為它在各種任務中具有卓越的效能，並且與 SiMT 具有內在相容性。然而，將僅解碼器架構直接應用於 SiMT 在訓練和推論方面會帶來挑戰。為了緩解上述問題，我們提出了第一個僅解碼器 SiMT 模型，稱為僅解碼器串流轉換器 (DST)。具體來說，DST 分別對原始語言和目標語言前綴的位置進行編碼，確保目標語言前綴的位置不受原始語言前綴的擴充影響。此外，我們提出了一個專為僅解碼器架構量身打造的串流自我注意力 (SSA) 機制。它能夠透過評估輸入原始語言資訊的充分性並與軟注意力機制整合來產生翻譯，從而獲得翻譯準則。實驗表明，我們的方法在三項翻譯任務上達到了最先進的效能。

##### **Quantum Implicit Neural Representations**
2406.03873v1 by Jiaming Zhao, Wenbo Qiao, Peng Zhang, Hui Gao

Implicit neural representations have emerged as a powerful paradigm to
represent signals such as images and sounds. This approach aims to utilize
neural networks to parameterize the implicit function of the signal. However,
when representing implicit functions, traditional neural networks such as
ReLU-based multilayer perceptrons face challenges in accurately modeling
high-frequency components of signals. Recent research has begun to explore the
use of Fourier Neural Networks (FNNs) to overcome this limitation. In this
paper, we propose Quantum Implicit Representation Network (QIREN), a novel
quantum generalization of FNNs. Furthermore, through theoretical analysis, we
demonstrate that QIREN possesses a quantum advantage over classical FNNs.
Lastly, we conducted experiments in signal representation, image
superresolution, and image generation tasks to show the superior performance of
QIREN compared to state-of-the-art (SOTA) models. Our work not only
incorporates quantum advantages into implicit neural representations but also
uncovers a promising application direction for Quantum Neural Networks.

摘要：隱式神經表徵已成為表徵影像和聲音等訊號的強大範例。此方法旨在利用神經網路來參數化訊號的隱式函數。然而，在表徵隱式函數時，傳統的神經網路（例如基於 ReLU 的多層感知器）在精確建模訊號的高頻率組成部分時面臨挑戰。最近的研究已開始探討使用傅立葉神經網路 (FNN) 來克服此限制。在本文中，我們提出量子隱式表徵網路 (QIREN)，這是一種 FNN 的新型量子概括。此外，透過理論分析，我們證明 QIREN 擁有優於傳統 FNN 的量子優勢。最後，我們在訊號表徵、影像超解析度和影像生成任務中進行實驗，以顯示 QIREN 與最先進 (SOTA) 模型相比的優異效能。我們的研究不僅將量子優勢納入隱式神經表徵，也揭示了量子神經網路一個有前景的應用方向。

##### **BLSP-Emo: Towards Empathetic Large Speech-Language Models**
2406.03872v1 by Chen Wang, Minpeng Liao, Zhongqiang Huang, Junhong Wu, Chengqing Zong, Jiajun Zhang

The recent release of GPT-4o showcased the potential of end-to-end multimodal
models, not just in terms of low latency but also in their ability to
understand and generate expressive speech with rich emotions. While the details
are unknown to the open research community, it likely involves significant
amounts of curated data and compute, neither of which is readily accessible. In
this paper, we present BLSP-Emo (Bootstrapped Language-Speech Pretraining with
Emotion support), a novel approach to developing an end-to-end speech-language
model capable of understanding both semantics and emotions in speech and
generate empathetic responses. BLSP-Emo utilizes existing speech recognition
(ASR) and speech emotion recognition (SER) datasets through a two-stage
process. The first stage focuses on semantic alignment, following recent work
on pretraining speech-language models using ASR data. The second stage performs
emotion alignment with the pretrained speech-language model on an emotion-aware
continuation task constructed from SER data. Our experiments demonstrate that
the BLSP-Emo model excels in comprehending speech and delivering empathetic
responses, both in instruction-following tasks and conversations.

摘要：GPT-4o 最近發布展示了端到端多模態模型的潛力，不僅在低延遲方面，還在理解和生成具有豐富情感的表達性語言方面。雖然細節對開放研究社群而言未知，但它可能涉及大量的策展資料和運算，而這兩者都不是容易取得的。在本文中，我們提出 BLSP-Emo（引導語言語音預訓練，具備情感支援），這是一種開發端到端語音語言模型的新方法，能夠理解語音中的語意和情感，並產生同理心的回應。BLSP-Emo 透過兩階段流程利用現有的語音辨識 (ASR) 和語音情感辨識 (SER) 資料集。第一階段著重於語意對齊，遵循最近使用 ASR 資料預訓練語音語言模型的研究。第二階段使用從 SER 資料建構的情感感知延續任務，對預訓練的語音語言模型執行情感對齊。我們的實驗證明，BLSP-Emo 模型在理解語音和提供同理心回應方面表現出色，無論是在遵循指令的任務或對話中。

##### **Recovering document annotations for sentence-level bitext**
2406.03869v1 by Rachel Wicks, Matt Post, Philipp Koehn

Data availability limits the scope of any given task. In machine translation,
historical models were incapable of handling longer contexts, so the lack of
document-level datasets was less noticeable. Now, despite the emergence of
long-sequence methods, we remain within a sentence-level paradigm and without
data to adequately approach context-aware machine translation. Most large-scale
datasets have been processed through a pipeline that discards document-level
metadata. In this work, we reconstruct document-level information for three
(ParaCrawl, News Commentary, and Europarl) large datasets in German, French,
Spanish, Italian, Polish, and Portuguese (paired with English). We then
introduce a document-level filtering technique as an alternative to traditional
bitext filtering. We present this filtering with analysis to show that this
method prefers context-consistent translations rather than those that may have
been sentence-level machine translated. Last we train models on these longer
contexts and demonstrate improvement in document-level translation without
degradation of sentence-level translation. We release our dataset, ParaDocs,
and resulting models as a resource to the community.

摘要：<paragraph>資料可得性限制了任何特定任務的範圍。在機器翻譯中，歷史模型無法處理較長的語境，因此較不重視文件層級資料集的缺乏。現在，儘管出現了長序列方法，我們仍處於句子層級的範例中，且沒有足夠的資料來適當地進行考量語境的機器翻譯。大多數大型資料集已透過會捨棄文件層級元資料的管道進行處理。在這項工作中，我們針對德文、法文、西班牙文、義大利文、波蘭文和葡萄牙文（與英文配對）的三個大型資料集（ParaCrawl、新聞評論和歐議會）重建文件層級資訊。然後，我們引入文件層級篩選技術，作為傳統雙語文本篩選的替代方案。我們提出此篩選並進行分析，以顯示此方法偏好語境一致的翻譯，而不是可能已進行句子層級機器翻譯的翻譯。最後，我們針對這些較長的語境訓練模型，並證明文件層級翻譯有所進步，而句子層級翻譯並未下降。我們將我們的資料集 ParaDocs 和產生的模型釋出，作為社群的資源。</paragraph>

##### **Semantic Similarity Score for Measuring Visual Similarity at Semantic Level**
2406.03865v1 by Senran Fan, Zhicheng Bao, Chen Dong, Haotai Liang, Xiaodong Xu, Ping Zhang

Semantic communication, as a revolutionary communication architecture, is
considered a promising novel communication paradigm. Unlike traditional
symbol-based error-free communication systems, semantic-based visual
communication systems extract, compress, transmit, and reconstruct images at
the semantic level. However, widely used image similarity evaluation metrics,
whether pixel-based MSE or PSNR or structure-based MS-SSIM, struggle to
accurately measure the loss of semantic-level information of the source during
system transmission. This presents challenges in evaluating the performance of
visual semantic communication systems, especially when comparing them with
traditional communication systems. To address this, we propose a semantic
evaluation metric -- SeSS (Semantic Similarity Score), based on Scene Graph
Generation and graph matching, which shifts the similarity scores between
images into semantic-level graph matching scores. Meanwhile, semantic
similarity scores for tens of thousands of image pairs are manually annotated
to fine-tune the hyperparameters in the graph matching algorithm, aligning the
metric more closely with human semantic perception. The performance of the SeSS
is tested on different datasets, including (1)images transmitted by traditional
and semantic communication systems at different compression rates, (2)images
transmitted by traditional and semantic communication systems at different
signal-to-noise ratios, (3)images generated by large-scale model with different
noise levels introduced, and (4)cases of images subjected to certain special
transformations. The experiments demonstrate the effectiveness of SeSS,
indicating that the metric can measure the semantic-level differences in
semantic-level information of images and can be used for evaluation in visual
semantic communication systems.

摘要：语义通信作为一种革命性的通信架构，被认为是一种很有前途的新型通信范式。与传统的基于符号的无差错通信系统不同，基于语义的视觉通信系统在语义层提取、压缩、传输和重建图像。然而，广泛使用的图像相似度评估指标，无论是基于像素的 MSE 或 PSNR，还是基于结构的 MS-SSIM，在系统传输过程中都难以准确测量源语义级信息的损失。这给评估视觉语义通信系统的性能带来了挑战，尤其是在将它们与传统通信系统进行比较时。为了解决这个问题，我们提出了一种语义评估指标——SeSS（语义相似度得分），它基于场景图生成和图匹配，将图像之间的相似度得分转换为语义级图匹配得分。同时，手动注释了数万对图像的语义相似度得分，以微调图匹配算法中的超参数，使该指标更贴近人类的语义感知。SeSS 的性能在不同的数据集上进行了测试，包括（1）传统和语义通信系统在不同压缩率下传输的图像，（2）传统和语义通信系统在不同信噪比下传输的图像，（3）大规模模型生成的不同噪声水平下的图像，以及（4）图像经过某些特殊变换的情况。实验表明了 SeSS 的有效性，表明该指标可以测量图像语义级信息中的语义级差异，并可用于视觉语义通信系统中的评估。

##### **MuJo: Multimodal Joint Feature Space Learning for Human Activity Recognition**
2406.03857v1 by Stefan Gerd Fritsch, Cennet Oguz, Vitor Fortes Rey, Lala Ray, Maximilian Kiefer-Emmanouilidis, Paul Lukowicz

Human Activity Recognition is a longstanding problem in AI with applications
in a broad range of areas: from healthcare, sports and fitness, security, and
human computer interaction to robotics. The performance of HAR in real-world
settings is strongly dependent on the type and quality of the input signal that
can be acquired. Given an unobstructed, high-quality camera view of a scene,
computer vision systems, in particular in conjunction with foundational models
(e.g., CLIP), can today fairly reliably distinguish complex activities. On the
other hand, recognition using modalities such as wearable sensors (which are
often more broadly available, e.g, in mobile phones and smartwatches) is a more
difficult problem, as the signals often contain less information and labeled
training data is more difficult to acquire. In this work, we show how we can
improve HAR performance across different modalities using multimodal
contrastive pretraining. Our approach MuJo (Multimodal Joint Feature Space
Learning), learns a multimodal joint feature space with video, language, pose,
and IMU sensor data. The proposed approach combines contrastive and multitask
learning methods and analyzes different multitasking strategies for learning a
compact shared representation. A large dataset with parallel video, language,
pose, and sensor data points is also introduced to support the research, along
with an analysis of the robustness of the multimodal joint space for
modal-incomplete and low-resource data. On the MM-Fit dataset, our model
achieves an impressive Macro F1-Score of up to 0.992 with only 2% of the train
data and 0.999 when using all available training data for classification tasks.
Moreover, in the scenario where the MM-Fit dataset is unseen, we demonstrate a
generalization performance of up to 0.638.

摘要：人類活動辨識是人工智慧領域中長久存在的問題，在廣泛的領域中都有應用：從醫療保健、運動和健身、安全和人機互動到機器人技術。HAR 在真實世界中的表現高度依賴於輸入訊號的類型和品質，而輸入訊號是可以被擷取的。給定一個場景的無障礙、高品質的相機視角，電腦視覺系統，特別是結合基礎模型（例如 CLIP），如今可以相當可靠地區分複雜的活動。另一方面，使用可穿戴式感測器（例如在行動電話和智慧手錶中更廣泛可用的）等方式進行辨識是一個更困難的問題，因為訊號通常包含較少資訊，而且標記訓練資料更難以取得。在這項工作中，我們展示了如何使用多模態對比預訓練來改善不同模態的 HAR 效能。我們的 MuJo（多模態聯合特徵空間學習）方法，學習一個包含影片、語言、姿勢和 IMU 感測器資料的多模態聯合特徵空間。所提出的方法結合了對比和多任務學習方法，並分析了不同的多任務策略，以學習一個緊湊的共享表示。一個包含平行影片、語言、姿勢和感測器資料點的大型資料集也被引入，以支援研究，同時分析多模態聯合空間對模式不完整和低資源資料的穩健性。在 MM-Fit 資料集上，我們的模型僅使用 2% 的訓練資料就達到了令人印象深刻的 0.992 巨集 F1 分數，而使用所有可用的訓練資料進行分類任務時，則達到了 0.999。此外，在 MM-Fit 資料集未見的情況下，我們展示了高達 0.638 的泛化效能。

##### **Performance of large language models in numerical vs. semantic medical knowledge: Benchmarking on evidence-based Q&As**
2406.03855v1 by Eden Avnat, Michal Levy, Daniel Herstain, Elia Yanko, Daniel Ben Joya, Michal Tzuchman Katz, Dafna Eshel, Sahar Laros, Yael Dagan, Shahar Barami, Joseph Mermelstein, Shahar Ovadia, Noam Shomron, Varda Shalev, Raja-Elie E. Abdulnour

Clinical problem-solving requires processing of semantic medical knowledge
such as illness scripts and numerical medical knowledge of diagnostic tests for
evidence-based decision-making. As large language models (LLMs) show promising
results in many aspects of language-based clinical practice, their ability to
generate non-language evidence-based answers to clinical questions is
inherently limited by tokenization. Therefore, we evaluated LLMs' performance
on two question types: numeric (correlating findings) and semantic
(differentiating entities) while examining differences within and between LLMs
in medical aspects and comparing their performance to humans. To generate
straightforward multi-choice questions and answers (QAs) based on
evidence-based medicine (EBM), we used a comprehensive medical knowledge graph
(encompassed data from more than 50,00 peer-reviewed articles) and created the
"EBMQA". EBMQA contains 105,000 QAs labeled with medical and non-medical topics
and classified into numerical or semantic questions. We benchmarked this
dataset using more than 24,500 QAs on two state-of-the-art LLMs: Chat-GPT4 and
Claude3-Opus. We evaluated the LLMs accuracy on semantic and numerical question
types and according to sub-labeled topics. For validation, six medical experts
were tested on 100 numerical EBMQA questions. We found that both LLMs excelled
more in semantic than numerical QAs, with Claude3 surpassing GPT4 in numerical
QAs. However, both LLMs showed inter and intra gaps in different medical
aspects and remained inferior to humans. Thus, their medical advice should be
addressed carefully.

摘要：<paragraph>臨床問題解決需要處理語義醫學知識，例如疾病腳本和用於循證決策的診斷測試的數值醫學知識。隨著大型語言模型 (LLM) 在語言基礎臨床實務的許多方面顯示出令人滿意的結果，它們產生非語言循證答案的能力在於臨床問題本質上受到標記化的限制。因此，我們評估了 LLM 在兩種問題類型上的表現：數值（相關發現）和語義（區分實體），同時檢查 LLM 在醫學方面的差異，並將其表現與人類進行比較。為了根據循證醫學 (EBM) 產生直接的多選題和答案 (QA)，我們使用了一個全面的醫學知識圖譜（包含來自 50,000 多篇同行評審文章的資料），並建立了「EBMQA」。EBMQA 包含 105,000 個標記有醫學和非醫學主題的 QA，並分類為數值或語義問題。我們使用超過 24,500 個 QA 在兩個最先進的 LLM：Chat-GPT4 和 Claude3-Opus 上對此資料集進行基準測試。我們評估了 LLM 在語義和數值問題類型以及根據次標籤主題的準確性。為了驗證，六位醫學專家接受了 100 個數值 EBMQA 問題的測試。我們發現這兩個 LLM 在語義 QA 上都比在數值 QA 上表現得更出色，而 Claude3 在數值 QA 上超越了 GPT4。然而，這兩個 LLM 在不同的醫學方面都表現出內部和外部的差距，並且仍然遜於人類。因此，它們的醫療建議應謹慎對待。</paragraph>

##### **Speculative Decoding via Early-exiting for Faster LLM Inference with Thompson Sampling Control Mechanism**
2406.03853v1 by Jiahao Liu, Qifan Wang, Jingang Wang, Xunliang Cai

The recent advancements in large language models (LLMs) have been
extraordinary, yet the escalating inference costs associated with them present
challenges in real-world applications. To address these challenges, we propose
a novel approach called Early-exiting Speculative Decoding (EESD) with lossless
acceleration. Specifically, EESD utilizes a segment of the LLM to generate
draft tokens, incorporating Early-exiting structures after the first N layers.
To enhance the quality of draft tokens, a self-distillation method is
integrated. This early-exiting design not only reduces deployment and training
costs but also significantly accelerates the token generation speed. Moreover,
we introduce a novel sampling mechanism that leverages Thompson Sampling to
regulate the generation processes, automatically determining the quantity of
draft tokens in each round. The original LLM is then employed to validate these
draft tokens through a single forward pass, and thus guarantees that the final
output text maintains a distribution consistent with vanilla auto-regressive
decoding. The experimental results on both 13B and 70B models demonstrate that
our approach decodes tokens at a markedly accelerated rate compared to prior
methods, showing the effectiveness of our approach.

摘要：大型語言模型 (LLM) 近期的進展非凡，但與之相關的推論成本不斷增加，對實際應用構成了挑戰。為了應對這些挑戰，我們提出了一種名為早期退出推論解碼 (EESD) 的新方法，具有無損加速功能。具體來說，EESD 利用 LLM 的一部分來生成草稿代幣，並在第一個 N 層之後加入早期退出結構。為了提高草稿代幣的品質，整合了一種自蒸餾方法。這種早期退出的設計不僅降低了部署和訓練成本，還顯著加快了代幣生成速度。此外，我們引入了一種新穎的抽樣機制，它利用 Thompson 抽樣來調節生成過程，自動確定每一輪中草稿代幣的數量。然後使用原始 LLM 通過單次前向傳遞來驗證這些草稿代幣，從而保證最終輸出文本保持與香草自迴歸解碼一致的分布。在 13B 和 70B 模型上的實驗結果表明，與先前的技術相比，我們的技術以顯著加速的速度解碼代幣，顯示了我們技術的有效性。

##### **Lean Workbook: A large-scale Lean problem set formalized from natural language math problems**
2406.03847v2 by Huaiyuan Ying, Zijian Wu, Yihan Geng, Jiayu Wang, Dahua Lin, Kai Chen

Large language models have demonstrated impressive capabilities across
various natural language processing tasks, especially in solving mathematical
problems. However, large language models are not good at math theorem proving
using formal languages like Lean. A significant challenge in this area is the
scarcity of training data available in these formal languages. To address this
issue, we propose a novel pipeline that iteratively generates and filters
synthetic data to translate natural language mathematical problems into Lean 4
statements, and vice versa. Our results indicate that the synthetic data
pipeline can provide useful training data and improve the performance of LLMs
in translating and understanding complex mathematical problems and proofs. Our
final dataset contains about 57K formal-informal question pairs along with
searched proof from the math contest forum and 21 new IMO questions. We
open-source our code at https://github.com/InternLM/InternLM-Math and our data
at https://huggingface.co/datasets/InternLM/Lean-Workbook.

摘要：大型語言模型已在各種自然語言處理任務中展現出令人印象深刻的能力，尤其是在解決數學問題上。然而，大型語言模型並不擅長使用 Lean 等形式語言來證明數學定理。這個領域的一大挑戰是這些形式語言中可用訓練資料的稀缺性。為了解決這個問題，我們提出了一個創新的管道，它會反覆產生和過濾合成資料，以將自然語言的數學問題轉換成 Lean 4 陳述式，反之亦然。我們的結果表明，合成資料管道可以提供有用的訓練資料，並提高大型語言模型在轉換和理解複雜數學問題和證明方面的效能。我們的最終資料集包含約 57K 個形式非形式問題對，以及從數學競賽論壇中搜尋到的證明和 21 個新的國際數學奧林匹克競賽問題。我們在 https://github.com/InternLM/InternLM-Math 開源我們的程式碼，並在 https://huggingface.co/datasets/InternLM/Lean-Workbook 開源我們的資料。

##### **POEM: Interactive Prompt Optimization for Enhancing Multimodal Reasoning of Large Language Models**
2406.03843v1 by Jianben He, Xingbo Wang, Shiyi Liu, Guande Wu, Claudio Silva, Huamin Qu

Large language models (LLMs) have exhibited impressive abilities for
multimodal content comprehension and reasoning with proper prompting in zero-
or few-shot settings. Despite the proliferation of interactive systems
developed to support prompt engineering for LLMs across various tasks, most
have primarily focused on textual or visual inputs, thus neglecting the complex
interplay between modalities within multimodal inputs. This oversight hinders
the development of effective prompts that guide model multimodal reasoning
processes by fully exploiting the rich context provided by multiple modalities.
In this paper, we present POEM, a visual analytics system to facilitate
efficient prompt engineering for enhancing the multimodal reasoning performance
of LLMs. The system enables users to explore the interaction patterns across
modalities at varying levels of detail for a comprehensive understanding of the
multimodal knowledge elicited by various prompts. Through diverse
recommendations of demonstration examples and instructional principles, POEM
supports users in iteratively crafting and refining prompts to better align and
enhance model knowledge with human insights. The effectiveness and efficiency
of our system are validated through two case studies and interviews with
experts.

摘要：大型語言模型 (LLM) 在多模態內容理解和推理方面表現出令人印象深刻的能力，並在零次或少次嘗試的設定中適當地提示。儘管開發了許多互動式系統來支援 LLM 的提示工程，但大多數主要集中在文字或視覺輸入，因此忽略了多模態輸入中模態之間的複雜交互作用。這種疏忽阻礙了有效提示的發展，這些提示通過充分利用多種模態提供的豐富背景來指導模型多模態推理過程。在本文中，我們提出了 POEM，這是一個視覺分析系統，用於促進有效的提示工程，以增強 LLM 的多模態推理效能。該系統使用戶能夠探索不同層級細節中跨模態的交互模式，以全面了解各種提示引發的多模態知識。透過示範範例和教學原則的多樣化建議，POEM 支援使用者反覆建構和調整提示，以更好地與人類見解對齊並增強模型知識。我們系統的有效性和效率已通過兩個案例研究和專家訪談得到驗證。

##### **Proactive Detection of Physical Inter-rule Vulnerabilities in IoT Services Using a Deep Learning Approach**
2406.03836v1 by Bing Huang, Chen Chen, Kwok-Yan Lam, Fuqun Huang

Emerging Internet of Things (IoT) platforms provide sophisticated
capabilities to automate IoT services by enabling occupants to create
trigger-action rules. Multiple trigger-action rules can physically interact
with each other via shared environment channels, such as temperature, humidity,
and illumination. We refer to inter-rule interactions via shared environment
channels as a physical inter-rule vulnerability. Such vulnerability can be
exploited by attackers to launch attacks against IoT systems. We propose a new
framework to proactively discover possible physical inter-rule interactions
from user requirement specifications (i.e., descriptions) using a deep learning
approach. Specifically, we utilize the Transformer model to generate
trigger-action rules from their associated descriptions. We discover two types
of physical inter-rule vulnerabilities and determine associated environment
channels using natural language processing (NLP) tools. Given the extracted
trigger-action rules and associated environment channels, an approach is
proposed to identify hidden physical inter-rule vulnerabilities among them. Our
experiment on 27983 IFTTT style rules shows that the Transformer can
successfully extract trigger-action rules from descriptions with 95.22%
accuracy. We also validate the effectiveness of our approach on 60 SmartThings
official IoT apps and discover 99 possible physical inter-rule vulnerabilities.

摘要：新興的物聯網 (IoT) 平台提供先進的功能，可通過讓使用者建立觸發動作規則來自動化 IoT 服務。多個觸發動作規則可透過共用環境通道（例如溫度、濕度和照明）彼此進行實體互動。我們將透過共用環境通道的規則間互動稱為實體規則間漏洞。攻擊者可以利用此類漏洞對 IoT 系統發動攻擊。我們提出一個新的架構，以使用深度學習方法從使用者需求規格（即描述）中主動發現可能的實體規則間互動。具體來說，我們利用 Transformer 模型從其相關描述中產生觸發動作規則。我們發現兩種類型的實體規則間漏洞，並使用自然語言處理 (NLP) 工具確定相關的環境通道。針對提取的觸發動作規則和相關環境通道，提出一個方法來識別它們之間隱藏的實體規則間漏洞。我們對 27983 個 IFTTT 風格規則的實驗顯示，Transformer 可以從描述中成功提取觸發動作規則，準確度為 95.22%。我們還驗證了我們的方法對 60 個 SmartThings 官方 IoT 應用程式的有效性，並發現 99 個可能的實體規則間漏洞。

##### **Chaos with Keywords: Exposing Large Language Models Sycophancy to Misleading Keywords and Evaluating Defense Strategies**
2406.03827v1 by Aswin RRV, Nemika Tyagi, Md Nayem Uddin, Neeraj Varshney, Chitta Baral

This study explores the sycophantic tendencies of Large Language Models
(LLMs), where these models tend to provide answers that match what users want
to hear, even if they are not entirely correct. The motivation behind this
exploration stems from the common behavior observed in individuals searching
the internet for facts with partial or misleading knowledge. Similar to using
web search engines, users may recall fragments of misleading keywords and
submit them to an LLM, hoping for a comprehensive response. Our empirical
analysis of several LLMs shows the potential danger of these models amplifying
misinformation when presented with misleading keywords. Additionally, we
thoroughly assess four existing hallucination mitigation strategies to reduce
LLMs sycophantic behavior. Our experiments demonstrate the effectiveness of
these strategies for generating factually correct statements. Furthermore, our
analyses delve into knowledge-probing experiments on factual keywords and
different categories of sycophancy mitigation.

摘要：本研究探討大型語言模型 (LLM) 的趨炎附勢傾向，這些模型傾向於提供符合使用者想要聽到的答案，即使這些答案並非完全正確。這項探討的動機來自於個人在網路上搜尋事實時，常會出現部分或誤導性的知識。使用者可能會記住誤導性關鍵字的片段，並將它們提交給 LLM，希望能獲得全面的回應，這類似於使用網路搜尋引擎。我們對多個 LLM 進行的實證分析顯示，當提供誤導性關鍵字時，這些模型放大錯誤資訊的潛在危險。此外，我們徹底評估了四種現有的幻覺緩解策略，以減少 LLM 的趨炎附勢行為。我們的實驗證明了這些策略在產生事實正確的陳述方面的有效性。此外，我們的分析深入探討了對事實關鍵字和不同類別的趨炎附勢緩解進行的知識探測實驗。

##### **A Survey on Intelligent Internet of Things: Applications, Security, Privacy, and Future Directions**
2406.03820v1 by Ons Aouedi, Thai-Hoc Vu, Alessio Sacco, Dinh C. Nguyen, Kandaraj Piamrat, Guido Marchetto, Quoc-Viet Pham

The rapid advances in the Internet of Things (IoT) have promoted a revolution
in communication technology and offered various customer services. Artificial
intelligence (AI) techniques have been exploited to facilitate IoT operations
and maximize their potential in modern application scenarios. In particular,
the convergence of IoT and AI has led to a new networking paradigm called
Intelligent IoT (IIoT), which has the potential to significantly transform
businesses and industrial domains. This paper presents a comprehensive survey
of IIoT by investigating its significant applications in mobile networks, as
well as its associated security and privacy issues. Specifically, we explore
and discuss the roles of IIoT in a wide range of key application domains, from
smart healthcare and smart cities to smart transportation and smart industries.
Through such extensive discussions, we investigate important security issues in
IIoT networks, where network attacks, confidentiality, integrity, and intrusion
are analyzed, along with a discussion of potential countermeasures. Privacy
issues in IIoT networks were also surveyed and discussed, including data,
location, and model privacy leakage. Finally, we outline several key challenges
and highlight potential research directions in this important area.

摘要：物联网 (IoT) 的快速进步促进了通信技术的革命，并提供了各种客户服务。人工智能 (AI) 技术已被用来促进物联网操作，并在现代应用场景中最大化其潜力。特别是，物联网和人工智能的融合催生了一种称为智能物联网 (IIoT) 的新网络范例，它有可能极大地改变商业和工业领域。本文通过调查 IIoT 在移动网络中的重要应用及其相关的安全和隐私问题，对 IIoT 进行了全面的调查。具体来说，我们探讨并讨论了 IIoT 在广泛的关键应用领域中的作用，从智能医疗保健和智慧城市到智能交通和智能产业。通过如此广泛的讨论，我们调查了 IIoT 网络中的重要安全问题，其中分析了网络攻击、机密性、完整性和入侵，并讨论了潜在的对策。还对 IIoT 网络中的隐私问题进行了调查和讨论，包括数据、位置和模型隐私泄露。最后，我们概述了几个关键挑战，并重点介绍了这一重要领域的潜在研究方向。

##### **ReST-MCTS*: LLM Self-Training via Process Reward Guided Tree Search**
2406.03816v1 by Dan Zhang, Sining Zhoubian, Yisong Yue, Yuxiao Dong, Jie Tang

Recent methodologies in LLM self-training mostly rely on LLM generating
responses and filtering those with correct output answers as training data.
This approach often yields a low-quality fine-tuning training set (e.g.,
incorrect plans or intermediate reasoning). In this paper, we develop a
reinforced self-training approach, called ReST-MCTS*, based on integrating
process reward guidance with tree search MCTS* for collecting higher-quality
reasoning traces as well as per-step value to train policy and reward models.
ReST-MCTS* circumvents the per-step manual annotation typically used to train
process rewards by tree-search-based reinforcement learning: Given oracle final
correct answers, ReST-MCTS* is able to infer the correct process rewards by
estimating the probability this step can help lead to the correct answer. These
inferred rewards serve dual purposes: they act as value targets for further
refining the process reward model and also facilitate the selection of
high-quality traces for policy model self-training. We first show that the
tree-search policy in ReST-MCTS* achieves higher accuracy compared with prior
LLM reasoning baselines such as Best-of-N and Tree-of-Thought, within the same
search budget. We then show that by using traces searched by this tree-search
policy as training data, we can continuously enhance the three language models
for multiple iterations, and outperform other self-training algorithms such as
ReST$^\text{EM}$ and Self-Rewarding LM.

摘要：最近 LLM 自我训练的方法主要依赖于 LLM 生成响应，并过滤那些具有正确输出答案的响应作为训练数据。这种方法通常会产生低质量的微调训练集（例如，不正确的计划或中间推理）。在本文中，我们开发了一种称为 ReST-MCTS* 的强化自我训练方法，该方法基于将过程奖励指导与树搜索 MCTS* 相结合，以收集更高质量的推理轨迹以及用于训练策略和奖励模型的每步价值。ReST-MCTS* 通过基于树搜索的强化学习绕过了通常用于训练过程奖励的每步人工注释：给定 oracle 最终正确答案，ReST-MCTS* 能够通过估计此步骤有助于得出正确答案的概率来推断正确的过程奖励。这些推断出的奖励具有双重目的：它们充当进一步优化过程奖励模型的价值目标，并且还有助于为策略模型自我训练选择高质量的轨迹。我们首先表明，与先前的 LLM 推理基准（如 Best-of-N 和 Tree-of-Thought）相比，ReST-MCTS* 中的树搜索策略在相同的搜索预算内实现了更高的准确性。然后我们表明，通过使用此树搜索策略搜索的轨迹作为训练数据，我们可以持续增强三个语言模型以进行多次迭代，并且优于其他自我训练算法，如 ReST$^\text{EM}$ 和 Self-Rewarding LM。

##### **Improving Zero-Shot Chinese-English Code-Switching ASR with kNN-CTC and Gated Monolingual Datastores**
2406.03814v1 by Jiaming Zhou, Shiwan Zhao, Hui Wang, Tian-Hao Zhang, Haoqin Sun, Xuechen Wang, Yong Qin

The kNN-CTC model has proven to be effective for monolingual automatic speech
recognition (ASR). However, its direct application to multilingual scenarios
like code-switching, presents challenges. Although there is potential for
performance improvement, a kNN-CTC model utilizing a single bilingual datastore
can inadvertently introduce undesirable noise from the alternative language. To
address this, we propose a novel kNN-CTC-based code-switching ASR (CS-ASR)
framework that employs dual monolingual datastores and a gated datastore
selection mechanism to reduce noise interference. Our method selects the
appropriate datastore for decoding each frame, ensuring the injection of
language-specific information into the ASR process. We apply this framework to
cutting-edge CTC-based models, developing an advanced CS-ASR system. Extensive
experiments demonstrate the remarkable effectiveness of our gated datastore
mechanism in enhancing the performance of zero-shot Chinese-English CS-ASR.

摘要：kNN-CTC 模型已證明對單語自動語音辨識 (ASR) 有效。然而，它直接應用於多語環境（例如代碼切換）時會產生挑戰。儘管有潛力改善效能，但使用單一雙語資料儲存庫的 kNN-CTC 模型可能會無意間從另一種語言引入不必要的雜訊。為了解決這個問題，我們提出一個新的基於 kNN-CTC 的代碼切換 ASR (CS-ASR) 架構，它採用雙重單語資料儲存庫和一個閘控資料儲存庫選擇機制來減少雜訊干擾。我們的模型會針對解碼每個框架選擇適當的資料儲存庫，確保將特定語言的資訊注入 ASR 處理程序。我們將這個架構套用於尖端的基於 CTC 的模型，開發出進階的 CS-ASR 系統。廣泛的實驗證明了我們的閘控資料儲存庫機制在提升零次學習中英 CS-ASR 效能方面的顯著效用。

##### **Cross-variable Linear Integrated ENhanced Transformer for Photovoltaic power forecasting**
2406.03808v1 by Jiaxin Gao, Qinglong Cao, Yuntian Chen, Dongxiao Zhang

Photovoltaic (PV) power forecasting plays a crucial role in optimizing the
operation and planning of PV systems, thereby enabling efficient energy
management and grid integration. However, un certainties caused by fluctuating
weather conditions and complex interactions between different variables pose
significant challenges to accurate PV power forecasting. In this study, we
propose PV-Client (Cross-variable Linear Integrated ENhanced Transformer for
Photovoltaic power forecasting) to address these challenges and enhance PV
power forecasting accuracy. PV-Client employs an ENhanced Transformer module to
capture complex interactions of various features in PV systems, and utilizes a
linear module to learn trend information in PV power. Diverging from
conventional time series-based Transformer models that use cross-time Attention
to learn dependencies between different time steps, the Enhanced Transformer
module integrates cross-variable Attention to capture dependencies between PV
power and weather factors. Furthermore, PV-Client streamlines the embedding and
position encoding layers by replacing the Decoder module with a projection
layer. Experimental results on three real-world PV power datasets affirm
PV-Client's state-of-the-art (SOTA) performance in PV power forecasting.
Specifically, PV-Client surpasses the second-best model GRU by 5.3% in MSE
metrics and 0.9% in accuracy metrics at the Jingang Station. Similarly,
PV-Client outperforms the second-best model SVR by 10.1% in MSE metrics and
0.2% in accuracy metrics at the Xinqingnian Station, and PV-Client exhibits
superior performance compared to the second-best model SVR with enhancements of
3.4% in MSE metrics and 0.9% in accuracy metrics at the Hongxing Station.

摘要：光伏 (PV) 電力預測在最佳化光伏系統的運作和規劃中扮演著至關重要的角色，進而能進行有效率的能源管理和電網整合。然而，由於天氣狀況多變以及不同變數之間複雜的交互作用所造成的各種不確定性，對準確的光伏電力預測構成了重大的挑戰。在這項研究中，我們提出 PV-Client（光伏電力預測的跨變數線性整合強化 Transformer），以應對這些挑戰並提升光伏電力預測的準確度。PV-Client 採用強化 Transformer 模組來擷取光伏系統中各種特徵的複雜交互作用，並利用線性模組來學習光伏電力的趨勢資訊。有別於使用跨時間注意力來學習不同時間步長之間依賴關係的傳統基於時間序列的 Transformer 模型，強化 Transformer 模組整合了跨變數注意力，以擷取光伏電力與天氣因素之間的依賴關係。此外，PV-Client 透過將解碼器模組替換成投影層，簡化了嵌入和位置編碼層。在三個真實世界光伏電力資料集上的實驗結果證實了 PV-Client 在光伏電力預測中具有最先進 (SOTA) 的效能。具體而言，在景港站，PV-Client 在 MSE 指標上超越了第二佳模型 GRU 5.3%，在準確度指標上超越了 0.9%。同樣地，在信青年間，PV-Client 在 MSE 指標上超越了第二佳模型 SVR 10.1%，在準確度指標上超越了 0.2%，而在紅星站，PV-Client 在 MSE 指標上超越了第二佳模型 SVR 3.4%，在準確度指標上超越了 0.9%，展現了卓越的效能。

##### **Tool-Planner: Dynamic Solution Tree Planning for Large Language Model with Tool Clustering**
2406.03807v1 by Yanming Liu, Xinyue Peng, Yuwei Zhang, Jiannan Cao, Xuhong Zhang, Sheng Cheng, Xun Wang, Jianwei Yin, Tianyu Du

Large language models (LLMs) have demonstrated exceptional reasoning
capabilities, enabling them to solve various complex problems. Recently, this
ability has been applied to the paradigm of tool learning. Tool learning
involves providing examples of tool usage and their corresponding functions,
allowing LLMs to formulate plans and demonstrate the process of invoking and
executing each tool. LLMs can address tasks that they cannot complete
independently, thereby enhancing their potential across different tasks.
However, this approach faces two key challenges. First, redundant error
correction leads to unstable planning and long execution time. Additionally,
designing a correct plan among multiple tools is also a challenge in tool
learning. To address these issues, we propose Tool-Planner, a task-processing
framework based on toolkits. Tool-Planner groups tools based on the API
functions with the same function into a toolkit and allows LLMs to implement
planning across the various toolkits. When a tool error occurs, the language
model can reselect and adjust tools based on the toolkit. Experiments show that
our approach demonstrates a high pass and win rate across different datasets
and optimizes the planning scheme for tool learning in models such as GPT-4 and
Claude 3, showcasing the potential of our method.

摘要：大型語言模型 (LLM) 已展現出卓越的推理能力，讓它們能夠解決各種複雜的問題。最近，此能力已應用於工具學習範例中。工具學習涉及提供工具使用範例及其對應功能，讓 LLM 能夠制定計畫並展示呼叫和執行每個工具的流程。LLM 能夠處理它們無法獨立完成的任務，從而提升它們在不同任務中的潛力。然而，此方法面臨兩項主要挑戰。首先，重複的錯誤修正會導致不穩定的規劃和冗長的執行時間。此外，在多個工具中設計一個正確的計畫也是工具學習中的挑戰。為了解決這些問題，我們提出 Tool-Planner，一個基於工具組的任務處理架構。Tool-Planner 會根據具有相同功能的 API 功能將工具分組到工具組中，並允許 LLM 在各種工具組中實作規劃。當工具發生錯誤時，語言模型可以根據工具組重新選擇和調整工具。實驗顯示，我們的做法在不同的資料集上展現出高通過率和獲勝率，並最佳化 GPT-4 和 Claude 3 等模型中的工具學習規劃架構，展示了我們方法的潛力。

##### **Enhanced Semantic Segmentation Pipeline for WeatherProof Dataset Challenge**
2406.03799v2 by Nan Zhang, Xidan Zhang, Jianing Wei, Fangjun Wang, Zhiming Tan

This report describes the winning solution to the WeatherProof Dataset
Challenge (CVPR 2024 UG2+ Track 3). Details regarding the challenge are
available at https://cvpr2024ug2challenge.github.io/track3.html. We propose an
enhanced semantic segmentation pipeline for this challenge. Firstly, we improve
semantic segmentation models, using backbone pretrained with Depth Anything to
improve UperNet model and SETRMLA model, and adding language guidance based on
both weather and category information to InternImage model. Secondly, we
introduce a new dataset WeatherProofExtra with wider viewing angle and employ
data augmentation methods, including adverse weather and super-resolution.
Finally, effective training strategies and ensemble method are applied to
improve final performance further. Our solution is ranked 1st on the final
leaderboard. Code will be available at
https://github.com/KaneiGi/WeatherProofChallenge.

摘要：本報告描述了 WeatherProof 資料集挑戰賽（CVPR 2024 UG2+ 軌道 3）的獲勝解決方案。有關挑戰賽的詳細資訊可在 https://cvpr2024ug2challenge.github.io/track3.html 找到。我們為此挑戰賽提出了一個增強的語義分割管道。首先，我們使用預先訓練 Depth Anything 的主幹來改善語義分割模型，以改善 UperNet 模型和 SETRMLA 模型，並根據天氣和類別資訊將語言指導新增到 InternImage 模型中。其次，我們引入了一個新的資料集 WeatherProofExtra，它具有更廣的視角，並採用資料擴充方法，包括惡劣天氣和超解析度。最後，應用有效的訓練策略和整體方法進一步改善最終效能。我們的解決方案在最終排行榜上排名第 1。程式碼將在 https://github.com/KaneiGi/WeatherProofChallenge 提供。

##### **Light-PEFT: Lightening Parameter-Efficient Fine-Tuning via Early Pruning**
2406.03792v1 by Naibin Gu, Peng Fu, Xiyu Liu, Bowen Shen, Zheng Lin, Weiping Wang

Parameter-efficient fine-tuning (PEFT) has emerged as the predominant
technique for fine-tuning in the era of large language models. However,
existing PEFT methods still have inadequate training efficiency. Firstly, the
utilization of large-scale foundation models during the training process is
excessively redundant for certain fine-tuning tasks. Secondly, as the model
size increases, the growth in trainable parameters of empirically added PEFT
modules becomes non-negligible and redundant, leading to inefficiency. To
achieve task-specific efficient fine-tuning, we propose the Light-PEFT
framework, which includes two methods: Masked Early Pruning of the Foundation
Model and Multi-Granularity Early Pruning of PEFT. The Light-PEFT framework
allows for the simultaneous estimation of redundant parameters in both the
foundation model and PEFT modules during the early stage of training. These
parameters can then be pruned for more efficient fine-tuning. We validate our
approach on GLUE, SuperGLUE, QA tasks, and various models. With Light-PEFT,
parameters of the foundation model can be pruned by up to over 40%, while still
controlling trainable parameters to be only 25% of the original PEFT method.
Compared to utilizing the PEFT method directly, Light-PEFT achieves training
and inference speedup, reduces memory usage, and maintains comparable
performance and the plug-and-play feature of PEFT.

摘要：參數高效微調 (PEFT) 已成為大型語言模型時代微調的主要技術。然而，現有的 PEFT 方法仍有訓練效率不足的問題。首先，在訓練過程中使用大規模基礎模型對於某些微調任務來說過於冗餘。其次，隨著模型規模的增加，經驗性添加的 PEFT 模組中可訓練參數的增長變得不可忽視且冗餘，導致效率低下。為了實現特定任務的高效微調，我們提出了 Light-PEFT 框架，其中包含兩種方法：基礎模型的遮罩早期剪枝和 PEFT 的多粒度早期剪枝。Light-PEFT 框架允許在訓練的早期階段同時估計基礎模型和 PEFT 模組中的冗餘參數。然後可以剪枝這些參數以實現更有效的微調。我們在 GLUE、SuperGLUE、QA 任務和各種模型上驗證了我們的做法。使用 Light-PEFT，基礎模型的參數可以剪枝多達 40%，同時仍將可訓練參數控制在原始 PEFT 方法的 25%。與直接使用 PEFT 方法相比，Light-PEFT 可加快訓練和推論速度、減少記憶體使用量，並維持 PEFT 的可比效能和即插即用功能。

##### **End-to-End Trainable Soft Retriever for Low-resource Relation Extraction**
2406.03790v1 by Kohei Makino, Makoto Miwa, Yutaka Sasaki

This study addresses a crucial challenge in instance-based relation
extraction using text generation models: end-to-end training in target relation
extraction task is not applicable to retrievers due to the non-differentiable
nature of instance selection. We propose a novel End-to-end TRAinable Soft
K-nearest neighbor retriever (ETRASK) by the neural prompting method that
utilizes a soft, differentiable selection of the $k$ nearest instances. This
approach enables the end-to-end training of retrievers in target tasks. On the
TACRED benchmark dataset with a low-resource setting where the training data
was reduced to 10\%, our method achieved a state-of-the-art F1 score of 71.5\%.
Moreover, ETRASK consistently improved the baseline model by adding instances
for all settings. These results highlight the efficacy of our approach in
enhancing relation extraction performance, especially in resource-constrained
environments. Our findings offer a promising direction for future research with
extraction and the broader application of text generation in natural language
processing.

摘要：本研究探討了基於實例的關係抽取中使用文本生成模型時的一個關鍵挑戰：目標關係抽取任務中的端到端訓練由於實例選擇的不可微分性質而不適用於檢索器。我們提出了一種新的端到端可訓練軟 K 最近鄰檢索器 (ETRASK)，採用神經提示方法，利用軟的、可微分的 $k$ 個最近實例選擇。這種方法能夠在目標任務中對檢索器進行端到端訓練。在訓練資料減少到 10% 的低資源設置的 TACRED 基準資料集上，我們的模型達到了 71.5% 的最先進 F1 分數。此外，ETRASK 通過為所有設置添加實例，始終如一地改進了基準模型。這些結果突出了我們的模型在增強關係抽取性能方面的效能，特別是在資源受限的環境中。我們的發現為未來的研究提供了有希望的方向，包括抽取和文本生成在自然語言處理中的更廣泛應用。

##### **Enhancing Graph U-Nets for Mesh-Agnostic Spatio-Temporal Flow Prediction**
2406.03789v1 by Sunwoong Yang, Ricardo Vinuesa, Namwoo Kang

This study aims to overcome the conventional deep-learning approaches based
on convolutional neural networks, whose applicability to complex geometries and
unstructured meshes is limited due to their inherent mesh dependency. We
propose novel approaches to improve mesh-agnostic spatio-temporal prediction of
transient flow fields using graph U-Nets, enabling accurate prediction on
diverse mesh configurations. Key enhancements to the graph U-Net architecture,
including the Gaussian mixture model convolutional operator and noise injection
approaches, provide increased flexibility in modeling node dynamics: the former
reduces prediction error by 95\% compared to conventional convolutional
operators, while the latter improves long-term prediction robustness, resulting
in an error reduction of 86\%. We also investigate transductive and
inductive-learning perspectives of graph U-Nets with proposed improvements. In
the transductive setting, they effectively predict quantities for unseen nodes
within the trained graph. In the inductive setting, they successfully perform
in mesh scenarios with different vortex-shedding periods, showing 98\%
improvement in predicting the future flow fields compared to a model trained
without the inductive settings. It is found that graph U-Nets without pooling
operations, i.e. without reducing and restoring the node dimensionality of the
graph data, perform better in inductive settings due to their ability to learn
from the detailed structure of each graph. Meanwhile, we also discover that the
choice of normalization technique significantly impacts graph U-Net
performance.

摘要：本研究旨在克服基於卷積神經網路的傳統深度學習方法，由於其對複雜幾何和非結構網格的適用性受限於其固有的網格依賴性。我們提出新的方法，使用圖形 U-Net 來改善網格不可知時空預測暫態流場，從而能夠對不同的網格配置進行準確預測。圖形 U-Net 架構的主要改進，包括高斯混合模型卷積算子與雜訊注入方法，提供了建模節點動態的靈活性：前者與傳統卷積算子相比，將預測誤差減少了 95%，而後者改善了長期預測的穩健性，從而將誤差減少了 86%。我們還研究了圖形 U-Net 的轉導學習和歸納學習觀點，並提出改進建議。在轉導設置中，它們有效地預測了訓練圖形中未見節點的數量。在歸納設置中，它們成功地在具有不同渦旋脫落週期的網格場景中執行，與未經歸納設置訓練的模型相比，預測未來流場的準確度提高了 98%。我們發現，沒有池化操作的圖形 U-Net，即沒有減少和恢復圖形數據節點維度的圖形 U-Net，由於它們能夠從每個圖形的詳細結構中學習，因此在歸納設置中表現得更好。同時，我們還發現，正規化技術的選擇會顯著影響圖形 U-Net 的性能。

