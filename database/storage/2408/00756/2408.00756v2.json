{"2408.00756": {"publish_time": "2024-08-01", "title": "Segment anything model 2: an application to 2D and 3D medical images", "paper_summary": "Segment Anything Model (SAM) has gained significant attention because of its\nability to segment varous objects in images given a prompt. The recently\ndeveloped SAM 2 has extended this ability to video inputs. This opens an\nopportunity to apply SAM to 3D images, one of the fundamental tasks in the\nmedical imaging field. In this paper, we extensively evaluate SAM 2's ability\nto segment both 2D and 3D medical images by first collecting 18 medical imaging\ndatasets, including common 3D modalities such as computed tomography (CT),\nmagnetic resonance imaging (MRI), and positron emission tomography (PET) as\nwell as 2D modalities such as X-ray and ultrasound. Two evaluation pipelines of\nSAM 2 are considered: (1) multi-frame 3D segmentation, where prompts are\nprovided to one or multiple slice(s) selected from the volume, and (2)\nsingle-frame 2D segmentation, where prompts are provided to each slice. The\nformer is only applicable to 3D modalities, while the latter applies to both 2D\nand 3D modalities. Our results show that SAM 2 exhibits similar performance as\nSAM under single-frame 2D segmentation, and has variable performance under\nmulti-frame 3D segmentation depending on the choices of slices to annotate, the\ndirection of the propagation, the predictions utilized during the propagation,\netc.", "paper_summary_zh": "\u5206\u6bb5\u4efb\u4f55\u6a21\u578b (SAM) \u56e0\u5176\u6839\u64da\u63d0\u793a\u5206\u6bb5\u5716\u50cf\u4e2d\u7684\u4e0d\u540c\u7269\u4ef6\u7684\u80fd\u529b\u800c\u53d7\u5230\u5ee3\u6cdb\u95dc\u6ce8\u3002\u6700\u8fd1\u958b\u767c\u7684 SAM 2 \u5df2\u5c07\u6b64\u80fd\u529b\u64f4\u5c55\u5230\u5f71\u7247\u8f38\u5165\u3002\u9019\u70ba\u5c07 SAM \u61c9\u7528\u65bc 3D \u5f71\u50cf\u958b\u555f\u4e86\u6a5f\u6703\uff0c\u9019\u662f\u91ab\u5b78\u5f71\u50cf\u9818\u57df\u7684\u57fa\u672c\u4efb\u52d9\u4e4b\u4e00\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5ee3\u6cdb\u8a55\u4f30\u4e86 SAM 2 \u5206\u6bb5 2D \u548c 3D \u91ab\u5b78\u5f71\u50cf\u7684\u80fd\u529b\uff0c\u9996\u5148\u6536\u96c6\u4e86 18 \u500b\u91ab\u5b78\u5f71\u50cf\u8cc7\u6599\u96c6\uff0c\u5305\u62ec\u5e38\u898b\u7684 3D \u6a21\u5f0f\uff0c\u4f8b\u5982\u96fb\u8166\u65b7\u5c64\u6383\u63cf (CT)\u3001\u78c1\u632f\u9020\u5f71 (MRI) \u548c\u6b63\u5b50\u767c\u5c04\u65b7\u5c64\u6383\u63cf (PET)\uff0c\u4ee5\u53ca 2D \u6a21\u5f0f\uff0c\u4f8b\u5982 X \u5c04\u7dda\u548c\u8d85\u97f3\u6ce2\u3002\u8003\u616e\u4e86 SAM 2 \u7684\u5169\u500b\u8a55\u4f30\u7ba1\u9053\uff1a(1) \u591a\u5e40 3D \u5206\u6bb5\uff0c\u5176\u4e2d\u63d0\u793a\u63d0\u4f9b\u7d66\u5f9e\u9ad4\u7a4d\u4e2d\u9078\u64c7\u7684\u4e00\u500b\u6216\u591a\u500b\u5207\u7247\uff0c\u4ee5\u53ca (2) \u55ae\u5e40 2D \u5206\u6bb5\uff0c\u5176\u4e2d\u63d0\u793a\u63d0\u4f9b\u7d66\u6bcf\u500b\u5207\u7247\u3002\u524d\u8005\u50c5\u9069\u7528\u65bc 3D \u6a21\u5f0f\uff0c\u800c\u5f8c\u8005\u9069\u7528\u65bc 2D \u548c 3D \u6a21\u5f0f\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0cSAM 2 \u5728\u55ae\u5e40 2D \u5206\u6bb5\u4e0b\u7684\u8868\u73fe\u8207 SAM \u985e\u4f3c\uff0c\u4e26\u4e14\u5728\u591a\u5e40 3D \u5206\u6bb5\u4e0b\u7684\u8868\u73fe\u6703\u6839\u64da\u8981\u6a19\u8a3b\u7684\u5207\u7247\u9078\u64c7\u3001\u50b3\u64ad\u65b9\u5411\u3001\u50b3\u64ad\u671f\u9593\u4f7f\u7528\u7684\u9810\u6e2c\u7b49\u800c\u6709\u6240\u4e0d\u540c\u3002", "author": "Haoyu Dong et.al.", "authors": "Haoyu Dong, Hanxue Gu, Yaqian Chen, Jichen Yang, Maciej A. Mazurowski", "id": "2408.00756v2", "paper_url": "http://arxiv.org/abs/2408.00756v2", "repo": "null"}}