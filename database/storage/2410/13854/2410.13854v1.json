{"2410.13854": {"publish_time": "2024-10-17", "title": "Can MLLMs Understand the Deep Implication Behind Chinese Images?", "paper_summary": "As the capabilities of Multimodal Large Language Models (MLLMs) continue to\nimprove, the need for higher-order capability evaluation of MLLMs is\nincreasing. However, there is a lack of work evaluating MLLM for higher-order\nperception and understanding of Chinese visual content. To fill the gap, we\nintroduce the **C**hinese **I**mage **I**mplication understanding\n**Bench**mark, **CII-Bench**, which aims to assess the higher-order perception\nand understanding capabilities of MLLMs for Chinese images. CII-Bench stands\nout in several ways compared to existing benchmarks. Firstly, to ensure the\nauthenticity of the Chinese context, images in CII-Bench are sourced from the\nChinese Internet and manually reviewed, with corresponding answers also\nmanually crafted. Additionally, CII-Bench incorporates images that represent\nChinese traditional culture, such as famous Chinese traditional paintings,\nwhich can deeply reflect the model's understanding of Chinese traditional\nculture. Through extensive experiments on CII-Bench across multiple MLLMs, we\nhave made significant findings. Initially, a substantial gap is observed\nbetween the performance of MLLMs and humans on CII-Bench. The highest accuracy\nof MLLMs attains 64.4%, where as human accuracy averages 78.2%, peaking at an\nimpressive 81.0%. Subsequently, MLLMs perform worse on Chinese traditional\nculture images, suggesting limitations in their ability to understand\nhigh-level semantics and lack a deep knowledge base of Chinese traditional\nculture. Finally, it is observed that most models exhibit enhanced accuracy\nwhen image emotion hints are incorporated into the prompts. We believe that\nCII-Bench will enable MLLMs to gain a better understanding of Chinese semantics\nand Chinese-specific images, advancing the journey towards expert artificial\ngeneral intelligence (AGI). Our project is publicly available at\nhttps://cii-bench.github.io/.", "paper_summary_zh": "\u96a8\u8457\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM) \u7684\u80fd\u529b\u6301\u7e8c\u63d0\u5347\uff0c\u5c0d MLLM \u9032\u884c\u9ad8\u968e\u80fd\u529b\u8a55\u4f30\u7684\u9700\u6c42\u4e5f\u8207\u65e5\u4ff1\u589e\u3002\u7136\u800c\uff0c\u76ee\u524d\u7f3a\u4e4f\u91dd\u5c0d MLLM \u9032\u884c\u9ad8\u968e\u611f\u77e5\u548c\u7406\u89e3\u4e2d\u6587\u8996\u89ba\u5167\u5bb9\u7684\u8a55\u4f30\u5de5\u4f5c\u3002\u70ba\u4e86\u586b\u88dc\u9019\u500b\u7f3a\u53e3\uff0c\u6211\u5011\u63a8\u51fa\u4e86 **\u4e2d**\u6587 **\u5716**\u50cf **\u610f**\u6db5\u7406\u89e3**\u57fa**\u6e96\uff0c**CII-Bench**\uff0c\u65e8\u5728\u8a55\u4f30 MLLM \u5c0d\u4e2d\u6587\u5716\u50cf\u7684\u9ad8\u968e\u611f\u77e5\u548c\u7406\u89e3\u80fd\u529b\u3002\u8207\u73fe\u6709\u7684\u57fa\u6e96\u76f8\u6bd4\uff0cCII-Bench \u5728\u5e7e\u500b\u65b9\u9762\u812b\u7a4e\u800c\u51fa\u3002\u9996\u5148\uff0c\u70ba\u4e86\u78ba\u4fdd\u4e2d\u6587\u8a9e\u5883\u7684\u771f\u5be6\u6027\uff0cCII-Bench \u4e2d\u7684\u5716\u50cf\u4f86\u81ea\u65bc\u4e2d\u6587\u7db2\u8def\uff0c\u4e26\u7d93\u904e\u4eba\u5de5\u5be9\u67e5\uff0c\u5c0d\u61c9\u7684\u7b54\u6848\u4e5f\u7531\u4eba\u5de5\u7de8\u5beb\u3002\u6b64\u5916\uff0cCII-Bench \u7d0d\u5165\u4e86\u4ee3\u8868\u4e2d\u570b\u50b3\u7d71\u6587\u5316\u7684\u5716\u50cf\uff0c\u4f8b\u5982\u8457\u540d\u7684\u4e2d\u570b\u50b3\u7d71\u7e6a\u756b\uff0c\u9019\u53ef\u4ee5\u6df1\u5165\u53cd\u6620\u6a21\u578b\u5c0d\u4e2d\u570b\u50b3\u7d71\u6587\u5316\u7684\u7406\u89e3\u3002\u900f\u904e\u5728\u591a\u500b MLLM \u4e0a\u5c0d CII-Bench \u9032\u884c\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u6211\u5011\u7372\u5f97\u4e86\u91cd\u8981\u7684\u767c\u73fe\u3002\u6700\u521d\uff0c\u5728 CII-Bench \u4e0a\u89c0\u5bdf\u5230 MLLM \u548c\u4eba\u985e\u7684\u8868\u73fe\u4e4b\u9593\u5b58\u5728\u986f\u8457\u5dee\u8ddd\u3002MLLM \u7684\u6700\u9ad8\u6e96\u78ba\u5ea6\u9054\u5230 64.4%\uff0c\u800c\u4eba\u985e\u6e96\u78ba\u5ea6\u7684\u5e73\u5747\u503c\u70ba 78.2%\uff0c\u6700\u9ad8\u9054\u5230\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684 81.0%\u3002\u96a8\u5f8c\uff0cMLLM \u5728\u4e2d\u570b\u50b3\u7d71\u6587\u5316\u5716\u50cf\u4e0a\u7684\u8868\u73fe\u8f03\u5dee\uff0c\u9019\u8868\u660e\u5b83\u5011\u5728\u7406\u89e3\u9ad8\u968e\u8a9e\u7fa9\u548c\u7f3a\u4e4f\u4e2d\u570b\u50b3\u7d71\u6587\u5316\u6df1\u539a\u77e5\u8b58\u5eab\u65b9\u9762\u5b58\u5728\u9650\u5236\u3002\u6700\u5f8c\uff0c\u6211\u5011\u89c0\u5bdf\u5230\uff0c\u7576\u5c07\u5716\u50cf\u60c5\u7dd2\u63d0\u793a\u7d0d\u5165\u63d0\u793a\u6642\uff0c\u5927\u591a\u6578\u6a21\u578b\u7684\u6e96\u78ba\u5ea6\u90fd\u6703\u63d0\u5347\u3002\u6211\u5011\u76f8\u4fe1 CII-Bench \u5c07\u4f7f MLLM \u80fd\u5920\u66f4\u597d\u5730\u7406\u89e3\u4e2d\u6587\u8a9e\u7fa9\u548c\u7279\u5b9a\u65bc\u4e2d\u6587\u7684\u5716\u50cf\uff0c\u63a8\u52d5\u5c08\u5bb6\u7d1a\u4eba\u5de5\u901a\u7528\u667a\u6167 (AGI) \u7684\u767c\u5c55\u3002\u6211\u5011\u7684\u5c08\u6848\u53ef\u5728 https://cii-bench.github.io/ \u516c\u958b\u53d6\u5f97\u3002", "author": "Chenhao Zhang et.al.", "authors": "Chenhao Zhang, Xi Feng, Yuelin Bai, Xinrun Du, Jinchang Hou, Kaixin Deng, Guangzeng Han, Qinrui Li, Bingli Wang, Jiaheng Liu, Xingwei Qu, Yifei Zhang, Qixuan Zhao, Yiming Liang, Ziqiang Liu, Feiteng Fang, Min Yang, Wenhao Huang, Chenghua Lin, Ge Zhang, Shiwen Ni", "id": "2410.13854v1", "paper_url": "http://arxiv.org/abs/2410.13854v1", "repo": "null"}}