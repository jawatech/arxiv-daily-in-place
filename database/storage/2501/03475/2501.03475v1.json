{"2501.03475": {"publish_time": "2025-01-07", "title": "Reading with Intent -- Neutralizing Intent", "paper_summary": "Queries to large language models (LLMs) can be divided into two parts: the\ninstruction/question and the accompanying context. The context for\nretrieval-augmented generation (RAG) systems in most benchmarks comes from\nWikipedia or Wikipedia-like texts which are written in a neutral and factual\ntone. However, when RAG systems retrieve internet-based content, they encounter\ntext with diverse tones and linguistic styles, introducing challenges for\ndownstream tasks. The Reading with Intent task addresses this issue by\nevaluating how varying tones in context passages affect model performance.\nBuilding on prior work that focused on sarcasm, we extend this paradigm by\nconstructing a dataset where context passages are transformed to $11$ distinct\nemotions using a better synthetic data generation approach. Using this dataset,\nwe train an emotion translation model to systematically adapt passages to\nspecified emotional tones. The human evaluation shows that the LLM fine-tuned\nto become the emotion-translator benefited from the synthetically generated\ndata. Finally, the emotion-translator is used in the Reading with Intent task\nto transform the passages to a neutral tone. By neutralizing the passages, it\nmitigates the challenges posed by sarcastic passages and improves overall\nresults on this task by about $3\\%$.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u67e5\u8a62\u53ef\u4ee5\u5206\u70ba\u5169\u90e8\u5206\uff1a\u6307\u4ee4/\u554f\u984c\u548c\u9644\u5e36\u7684\u5167\u5bb9\u3002\u5728\u5927\u591a\u6578\u57fa\u6e96\u6e2c\u8a66\u4e2d\uff0c\u7528\u65bc\u6aa2\u7d22\u589e\u5f37\u751f\u6210 (RAG) \u7cfb\u7d71\u7684\u5167\u5bb9\u4f86\u81ea\u7dad\u57fa\u767e\u79d1\u6216\u985e\u4f3c\u7dad\u57fa\u767e\u79d1\u7684\u6587\u672c\uff0c\u9019\u4e9b\u6587\u672c\u4ee5\u4e2d\u7acb\u4e14\u5ba2\u89c0\u7684\u8a9e\u6c23\u64b0\u5beb\u3002\u7136\u800c\uff0c\u7576 RAG \u7cfb\u7d71\u6aa2\u7d22\u57fa\u65bc\u7db2\u8def\u7684\u5167\u5bb9\u6642\uff0c\u5b83\u5011\u6703\u9047\u5230\u8a9e\u6c23\u548c\u8a9e\u8a00\u98a8\u683c\u591a\u6a23\u7684\u6587\u5b57\uff0c\u5c0d\u4e0b\u6e38\u4efb\u52d9\u9020\u6210\u6311\u6230\u3002\u95b1\u8b80\u610f\u5716\u4efb\u52d9\u900f\u904e\u8a55\u4f30\u8a9e\u5883\u6bb5\u843d\u4e2d\u7684\u4e0d\u540c\u8a9e\u6c23\u5982\u4f55\u5f71\u97ff\u6a21\u578b\u6548\u80fd\u4f86\u89e3\u6c7a\u9019\u500b\u554f\u984c\u3002\u5728\u5c08\u6ce8\u65bc\u8af7\u523a\u7684\u5148\u524d\u5de5\u4f5c\u57fa\u790e\u4e0a\uff0c\u6211\u5011\u900f\u904e\u5efa\u69cb\u4e00\u500b\u8cc7\u6599\u96c6\u4f86\u5ef6\u4f38\u9019\u500b\u7bc4\u4f8b\uff0c\u5176\u4e2d\u8a9e\u5883\u6bb5\u843d\u4f7f\u7528\u66f4\u597d\u7684\u5408\u6210\u8cc7\u6599\u751f\u6210\u65b9\u6cd5\u8f49\u63db\u70ba 11 \u7a2e\u4e0d\u540c\u7684\u60c5\u7dd2\u3002\u4f7f\u7528\u9019\u500b\u8cc7\u6599\u96c6\uff0c\u6211\u5011\u8a13\u7df4\u4e00\u500b\u60c5\u7dd2\u7ffb\u8b6f\u6a21\u578b\u4f86\u7cfb\u7d71\u6027\u5730\u8abf\u6574\u6bb5\u843d\u4ee5\u7b26\u5408\u6307\u5b9a\u7684\u60c5\u7dd2\u8a9e\u6c23\u3002\u4eba\u985e\u8a55\u4f30\u986f\u793a\uff0c\u7d93\u904e\u5fae\u8abf\u4ee5\u6210\u70ba\u60c5\u7dd2\u7ffb\u8b6f\u5668\u7684 LLM \u53d7\u76ca\u65bc\u5408\u6210\u7522\u751f\u7684\u8cc7\u6599\u3002\u6700\u5f8c\uff0c\u60c5\u7dd2\u7ffb\u8b6f\u5668\u7528\u65bc\u95b1\u8b80\u610f\u5716\u4efb\u52d9\uff0c\u5c07\u6bb5\u843d\u8f49\u63db\u70ba\u4e2d\u7acb\u8a9e\u6c23\u3002\u900f\u904e\u4e2d\u548c\u6bb5\u843d\uff0c\u5b83\u6e1b\u8f15\u4e86\u8af7\u523a\u6bb5\u843d\u5e36\u4f86\u7684\u6311\u6230\uff0c\u4e26\u5c07\u6b64\u4efb\u52d9\u7684\u6574\u9ad4\u7d50\u679c\u63d0\u5347\u4e86\u7d04 3%\u3002", "author": "Benjamin Reichman et.al.", "authors": "Benjamin Reichman, Adar Avsian, Larry Heck", "id": "2501.03475v1", "paper_url": "http://arxiv.org/abs/2501.03475v1", "repo": "null"}}