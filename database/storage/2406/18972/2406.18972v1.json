{"2406.18972": {"publish_time": "2024-06-27", "title": "Applying LLMs for Rescoring N-best ASR Hypotheses of Casual Conversations: Effects of Domain Adaptation and Context Carry-over", "paper_summary": "Large language models (LLMs) have been successfully applied for rescoring\nautomatic speech recognition (ASR) hypotheses. However, their ability to\nrescore ASR hypotheses of casual conversations has not been sufficiently\nexplored. In this study, we reveal it by performing N-best ASR hypotheses\nrescoring using Llama2 on the CHiME-7 distant ASR (DASR) task. Llama2 is one of\nthe most representative LLMs, and the CHiME-7 DASR task provides datasets of\ncasual conversations between multiple participants. We investigate the effects\nof domain adaptation of the LLM and context carry-over when performing N-best\nrescoring. Experimental results show that, even without domain adaptation,\nLlama2 outperforms a standard-size domain-adapted Transformer-LM, especially\nwhen using a long context. Domain adaptation shortens the context length needed\nwith Llama2 to achieve its best performance, i.e., it reduces the computational\ncost of Llama2.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u6210\u529f\u61c9\u7528\u65bc\u91cd\u65b0\u8a55\u5206\u81ea\u52d5\u8a9e\u97f3\u8fa8\u8b58 (ASR) \u5047\u8a2d\u3002\u7136\u800c\uff0c\u5b83\u5011\u91cd\u65b0\u8a55\u5206\u975e\u6b63\u5f0f\u5c0d\u8a71\u7684 ASR \u5047\u8a2d\u7684\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u901a\u904e\u5728 CHiME-7 \u9060\u7a0b ASR (DASR) \u4efb\u52d9\u4e0a\u4f7f\u7528 Llama2 \u57f7\u884c N \u500b\u6700\u4f73 ASR \u5047\u8a2d\u91cd\u65b0\u8a55\u5206\u4f86\u63ed\u793a\u5b83\u3002Llama2 \u662f\u6700\u5177\u4ee3\u8868\u6027\u7684 LLM \u4e4b\u4e00\uff0c\u800c CHiME-7 DASR \u4efb\u52d9\u63d0\u4f9b\u4e86\u591a\u500b\u53c3\u8207\u8005\u4e4b\u9593\u7684\u975e\u6b63\u5f0f\u5c0d\u8a71\u7684\u8cc7\u6599\u96c6\u3002\u6211\u5011\u5728\u57f7\u884c N \u500b\u6700\u4f73\u91cd\u65b0\u8a55\u5206\u6642\u7814\u7a76\u4e86 LLM \u7684\u9818\u57df\u9069\u61c9\u548c\u4e0a\u4e0b\u6587\u5ef6\u7e8c\u7684\u5f71\u97ff\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u5373\u4f7f\u6c92\u6709\u9818\u57df\u9069\u61c9\uff0cLlama2 \u4e5f\u512a\u65bc\u6a19\u6e96\u5927\u5c0f\u7684\u9818\u57df\u9069\u61c9 Transformer-LM\uff0c\u7279\u5225\u662f\u5728\u4f7f\u7528\u9577\u4e0a\u4e0b\u6587\u6642\u3002\u9818\u57df\u9069\u61c9\u7e2e\u77ed\u4e86 Llama2 \u9054\u5230\u5176\u6700\u4f73\u6027\u80fd\u6240\u9700\u7684\u4e0a\u4e0b\u6587\u9577\u5ea6\uff0c\u5373\u5b83\u964d\u4f4e\u4e86 Llama2 \u7684\u904b\u7b97\u6210\u672c\u3002", "author": "Atsunori Ogawa et.al.", "authors": "Atsunori Ogawa, Naoyuki Kamo, Kohei Matsuura, Takanori Ashihara, Takafumi Moriya, Takatomo Kano, Naohiro Tawara, Marc Delcroix", "id": "2406.18972v1", "paper_url": "http://arxiv.org/abs/2406.18972v1", "repo": "null"}}