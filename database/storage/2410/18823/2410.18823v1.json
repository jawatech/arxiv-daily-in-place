{"2410.18823": {"publish_time": "2024-10-24", "title": "Towards Visual Text Design Transfer Across Languages", "paper_summary": "Visual text design plays a critical role in conveying themes, emotions, and\natmospheres in multimodal formats such as film posters and album covers.\nTranslating these visual and textual elements across languages extends the\nconcept of translation beyond mere text, requiring the adaptation of aesthetic\nand stylistic features. To address this, we introduce a novel task of\nMultimodal Style Translation (MuST-Bench), a benchmark designed to evaluate the\nability of visual text generation models to perform translation across\ndifferent writing systems while preserving design intent. Our initial\nexperiments on MuST-Bench reveal that existing visual text generation models\nstruggle with the proposed task due to the inadequacy of textual descriptions\nin conveying visual design. In response, we introduce SIGIL, a framework for\nmultimodal style translation that eliminates the need for style descriptions.\nSIGIL enhances image generation models through three innovations: glyph latent\nfor multilingual settings, pretrained VAEs for stable style guidance, and an\nOCR model with reinforcement learning feedback for optimizing readable\ncharacter generation. SIGIL outperforms existing baselines by achieving\nsuperior style consistency and legibility while maintaining visual fidelity,\nsetting itself apart from traditional description-based approaches. We release\nMuST-Bench publicly for broader use and exploration\nhttps://huggingface.co/datasets/yejinc/MuST-Bench.", "paper_summary_zh": "\u8996\u89ba\u6587\u5b57\u8a2d\u8a08\u5728\u50b3\u9054\u96fb\u5f71\u6d77\u5831\u548c\u5c08\u8f2f\u5c01\u9762\u7b49\u591a\u6a21\u614b\u683c\u5f0f\u4e2d\u7684\u4e3b\u984c\u3001\u60c5\u7dd2\u548c\u6c1b\u570d\u65b9\u9762\u767c\u63ee\u8457\u95dc\u9375\u4f5c\u7528\u3002\u8de8\u8a9e\u8a00\u7ffb\u8b6f\u9019\u4e9b\u8996\u89ba\u548c\u6587\u672c\u5143\u7d20\u5c07\u7ffb\u8b6f\u7684\u6982\u5ff5\u64f4\u5c55\u5230\u7d14\u6587\u672c\u4e4b\u5916\uff0c\u9700\u8981\u6539\u7de8\u7f8e\u5b78\u548c\u98a8\u683c\u7279\u5fb5\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u9805\u591a\u6a21\u614b\u6a23\u5f0f\u7ffb\u8b6f (MuST-Bench) \u7684\u65b0\u4efb\u52d9\uff0c\u9019\u662f\u4e00\u500b\u57fa\u6e96\uff0c\u65e8\u5728\u8a55\u4f30\u8996\u89ba\u6587\u5b57\u751f\u6210\u6a21\u578b\u5728\u4e0d\u540c\u66f8\u5beb\u7cfb\u7d71\u4e4b\u9593\u57f7\u884c\u7ffb\u8b6f\u7684\u80fd\u529b\uff0c\u540c\u6642\u4fdd\u7559\u8a2d\u8a08\u610f\u5716\u3002\u6211\u5011\u5728 MuST-Bench \u4e0a\u7684\u521d\u6b65\u5be6\u9a57\u8868\u660e\uff0c\u73fe\u6709\u7684\u8996\u89ba\u6587\u5b57\u751f\u6210\u6a21\u578b\u7531\u65bc\u6587\u672c\u63cf\u8ff0\u4e0d\u8db3\u4ee5\u50b3\u9054\u8996\u89ba\u8a2d\u8a08\u800c\u96e3\u4ee5\u61c9\u5c0d\u63d0\u51fa\u7684\u4efb\u52d9\u3002\u4f5c\u70ba\u56de\u61c9\uff0c\u6211\u5011\u5f15\u5165\u4e86 SIGIL\uff0c\u9019\u662f\u4e00\u500b\u591a\u6a21\u614b\u6a23\u5f0f\u7ffb\u8b6f\u6846\u67b6\uff0c\u6d88\u9664\u4e86\u5c0d\u6a23\u5f0f\u63cf\u8ff0\u7684\u9700\u6c42\u3002SIGIL \u901a\u904e\u4e09\u9805\u5275\u65b0\u589e\u5f37\u4e86\u5716\u50cf\u751f\u6210\u6a21\u578b\uff1a\u591a\u8a9e\u8a00\u8a2d\u7f6e\u7684\u5b57\u5f62\u6f5b\u5728\u8b8a\u6578\u3001\u7528\u65bc\u7a69\u5b9a\u6a23\u5f0f\u6307\u5c0e\u7684\u9810\u8a13\u7df4 VAE\uff0c\u4ee5\u53ca\u5177\u6709\u589e\u5f37\u5b78\u7fd2\u53cd\u994b\u7684 OCR \u6a21\u578b\uff0c\u7528\u65bc\u6700\u4f73\u5316\u53ef\u8b80\u5b57\u5143\u751f\u6210\u3002SIGIL \u5728\u4fdd\u6301\u8996\u89ba\u4fdd\u771f\u5ea6\u7684\u540c\u6642\uff0c\u901a\u904e\u5be6\u73fe\u5353\u8d8a\u7684\u6a23\u5f0f\u4e00\u81f4\u6027\u548c\u53ef\u8b80\u6027\uff0c\u512a\u65bc\u73fe\u6709\u7684\u57fa\u6e96\uff0c\u4f7f\u5176\u6709\u5225\u65bc\u50b3\u7d71\u7684\u57fa\u65bc\u63cf\u8ff0\u7684\u65b9\u6cd5\u3002\u6211\u5011\u516c\u958b\u767c\u5e03 MuST-Bench \u4ee5\u4f9b\u66f4\u5ee3\u6cdb\u5730\u4f7f\u7528\u548c\u63a2\u7d22 https://huggingface.co/datasets/yejinc/MuST-Bench\u3002", "author": "Yejin Choi et.al.", "authors": "Yejin Choi, Jiwan Chung, Sumin Shim, Giyeong Oh, Youngjae Yu", "id": "2410.18823v1", "paper_url": "http://arxiv.org/abs/2410.18823v1", "repo": "null"}}