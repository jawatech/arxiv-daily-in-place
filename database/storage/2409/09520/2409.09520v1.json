{"2409.09520": {"publish_time": "2024-09-14", "title": "Enhancing Skin Disease Diagnosis: Interpretable Visual Concept Discovery with SAM Empowerment", "paper_summary": "Current AI-assisted skin image diagnosis has achieved dermatologist-level\nperformance in classifying skin cancer, driven by rapid advancements in deep\nlearning architectures. However, unlike traditional vision tasks, skin images\nin general present unique challenges due to the limited availability of\nwell-annotated datasets, complex variations in conditions, and the necessity\nfor detailed interpretations to ensure patient safety. Previous segmentation\nmethods have sought to reduce image noise and enhance diagnostic performance,\nbut these techniques require fine-grained, pixel-level ground truth masks for\ntraining. In contrast, with the rise of foundation models, the Segment Anything\nModel (SAM) has been introduced to facilitate promptable segmentation, enabling\nthe automation of the segmentation process with simple yet effective prompts.\nEfforts applying SAM predominantly focus on dermatoscopy images, which present\nmore easily identifiable lesion boundaries than clinical photos taken with\nsmartphones. This limitation constrains the practicality of these approaches to\nreal-world applications. To overcome the challenges posed by noisy clinical\nphotos acquired via non-standardized protocols and to improve diagnostic\naccessibility, we propose a novel Cross-Attentive Fusion framework for\ninterpretable skin lesion diagnosis. Our method leverages SAM to generate\nvisual concepts for skin diseases using prompts, integrating local visual\nconcepts with global image features to enhance model performance. Extensive\nevaluation on two skin disease datasets demonstrates our proposed method's\neffectiveness on lesion diagnosis and interpretability.", "paper_summary_zh": "\u76ee\u524d\u7531 AI \u8f14\u52a9\u7684\u76ae\u819a\u5f71\u50cf\u8a3a\u65b7\u5df2\u5728\u76ae\u819a\u764c\u5206\u985e\u4e2d\u9054\u5230\u76ae\u819a\u79d1\u91ab\u5e2b\u7b49\u7d1a\u7684\u8868\u73fe\uff0c\u9019\u6b78\u529f\u65bc\u6df1\u5ea6\u5b78\u7fd2\u67b6\u69cb\u7684\u5feb\u901f\u9032\u5c55\u3002\u7136\u800c\uff0c\u8207\u50b3\u7d71\u7684\u8996\u89ba\u4efb\u52d9\u4e0d\u540c\uff0c\u4e00\u822c\u76ae\u819a\u5f71\u50cf\u7531\u65bc\u6a19\u8a3b\u826f\u597d\u7684\u8cc7\u6599\u96c6\u53d6\u5f97\u4e0d\u6613\u3001\u72c0\u6cc1\u8907\u96dc\u591a\u8b8a\uff0c\u4ee5\u53ca\u78ba\u4fdd\u60a3\u8005\u5b89\u5168\u6240\u9700\u7684\u8a73\u7d30\u8a6e\u91cb\uff0c\u56e0\u6b64\u5448\u73fe\u51fa\u7368\u7279\u7684\u6311\u6230\u3002\u5148\u524d\u7684\u5206\u5272\u65b9\u6cd5\u8a66\u5716\u964d\u4f4e\u5f71\u50cf\u96dc\u8a0a\u4e26\u63d0\u5347\u8a3a\u65b7\u8868\u73fe\uff0c\u4f46\u9019\u4e9b\u6280\u8853\u9700\u8981\u7d30\u7dfb\u7684\u756b\u7d20\u7d1a\u5730\u9762\u5be6\u6cc1\u906e\u7f69\u4f86\u8a13\u7df4\u3002\u76f8\u5c0d\u5730\uff0c\u96a8\u8457\u57fa\u790e\u6a21\u578b\u7684\u8208\u8d77\uff0c\u5df2\u5c0e\u5165 Segment Anything Model (SAM) \u4ee5\u5229\u65bc\u63d0\u793a\u5f0f\u5206\u5272\uff0c\u4f7f\u7528\u7c21\u55ae\u537b\u6709\u6548\u7684\u63d0\u793a\u81ea\u52d5\u5316\u5206\u5272\u6d41\u7a0b\u3002\u61c9\u7528 SAM \u7684\u5de5\u4f5c\u4e3b\u8981\u96c6\u4e2d\u65bc\u76ae\u819a\u93e1\u5f71\u50cf\uff0c\u5176\u75c5\u7076\u908a\u754c\u6bd4\u4f7f\u7528\u667a\u6167\u578b\u624b\u6a5f\u62cd\u651d\u7684\u81e8\u5e8a\u7167\u7247\u66f4\u5bb9\u6613\u8fa8\u8b58\u3002\u6b64\u9650\u5236\u6703\u7d04\u675f\u9019\u4e9b\u65b9\u6cd5\u5728\u5be6\u969b\u61c9\u7528\u4e2d\u7684\u5be6\u7528\u6027\u3002\u70ba\u4e86\u514b\u670d\u975e\u6a19\u6e96\u5316\u7a0b\u5e8f\u53d6\u5f97\u7684\u96dc\u8a0a\u81e8\u5e8a\u7167\u7247\u6240\u9020\u6210\u7684\u6311\u6230\uff0c\u4e26\u6539\u5584\u8a3a\u65b7\u7684\u53ef\u8fd1\u6027\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u65b0\u7a4e\u7684\u8de8\u6ce8\u610f\u529b\u878d\u5408\u67b6\u69cb\uff0c\u7528\u65bc\u53ef\u8a6e\u91cb\u7684\u76ae\u819a\u75c5\u7076\u8a3a\u65b7\u3002\u6211\u5011\u7684\u65b9\u6cd5\u5229\u7528 SAM \u4f7f\u7528\u63d0\u793a\u4f86\u7522\u751f\u76ae\u819a\u75be\u75c5\u7684\u8996\u89ba\u6982\u5ff5\uff0c\u5c07\u5c40\u90e8\u8996\u89ba\u6982\u5ff5\u8207\u6574\u9ad4\u5f71\u50cf\u7279\u5fb5\u6574\u5408\uff0c\u4ee5\u63d0\u5347\u6a21\u578b\u8868\u73fe\u3002\u5728\u5169\u500b\u76ae\u819a\u75be\u75c5\u8cc7\u6599\u96c6\u4e0a\u7684\u5ee3\u6cdb\u8a55\u4f30\u986f\u793a\uff0c\u6211\u5011\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u75c5\u7076\u8a3a\u65b7\u548c\u53ef\u8a6e\u91cb\u6027\u4e0a\u90fd\u5177\u6709\u6210\u6548\u3002", "author": "Xin Hu et.al.", "authors": "Xin Hu, Janet Wang, Jihun Hamm, Rie R Yotsu, Zhengming Ding", "id": "2409.09520v1", "paper_url": "http://arxiv.org/abs/2409.09520v1", "repo": "null"}}