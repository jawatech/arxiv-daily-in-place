{"2404.16621": {"publish_time": "2024-04-25", "title": "Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare", "paper_summary": "The integration of Large Language Models (LLMs) into healthcare promises to\ntransform medical diagnostics, research, and patient care. Yet, the progression\nof medical LLMs faces obstacles such as complex training requirements, rigorous\nevaluation demands, and the dominance of proprietary models that restrict\nacademic exploration. Transparent, comprehensive access to LLM resources is\nessential for advancing the field, fostering reproducibility, and encouraging\ninnovation in healthcare AI. We present Hippocrates, an open-source LLM\nframework specifically developed for the medical domain. In stark contrast to\nprevious efforts, it offers unrestricted access to its training datasets,\ncodebase, checkpoints, and evaluation protocols. This open approach is designed\nto stimulate collaborative research, allowing the community to build upon,\nrefine, and rigorously evaluate medical LLMs within a transparent ecosystem.\nAlso, we introduce Hippo, a family of 7B models tailored for the medical\ndomain, fine-tuned from Mistral and LLaMA2 through continual pre-training,\ninstruction tuning, and reinforcement learning from human and AI feedback. Our\nmodels outperform existing open medical LLMs models by a large-margin, even\nsurpassing models with 70B parameters. Through Hippocrates, we aspire to unlock\nthe full potential of LLMs not just to advance medical knowledge and patient\ncare but also to democratize the benefits of AI research in healthcare, making\nthem available across the globe.", "paper_summary_zh": "", "author": "Emre Can Acikgoz et.al.", "authors": "Emre Can Acikgoz,Osman Batur \u0130nce,Rayene Bench,Arda An\u0131l Boz,\u0130lker Kesen,Aykut Erdem,Erkut Erdem", "id": "2404.16621v1", "paper_url": "http://arxiv.org/abs/2404.16621v1", "repo": "https://github.com/hiyouga/llama-factory"}}