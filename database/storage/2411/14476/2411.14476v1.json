{"2411.14476": {"publish_time": "2024-11-19", "title": "StreetviewLLM: Extracting Geographic Information Using a Chain-of-Thought Multimodal Large Language Model", "paper_summary": "Geospatial predictions are crucial for diverse fields such as disaster\nmanagement, urban planning, and public health. Traditional machine learning\nmethods often face limitations when handling unstructured or multi-modal data\nlike street view imagery. To address these challenges, we propose\nStreetViewLLM, a novel framework that integrates a large language model with\nthe chain-of-thought reasoning and multimodal data sources. By combining street\nview imagery with geographic coordinates and textual data, StreetViewLLM\nimproves the precision and granularity of geospatial predictions. Using\nretrieval-augmented generation techniques, our approach enhances geographic\ninformation extraction, enabling a detailed analysis of urban environments. The\nmodel has been applied to seven global cities, including Hong Kong, Tokyo,\nSingapore, Los Angeles, New York, London, and Paris, demonstrating superior\nperformance in predicting urban indicators, including population density,\naccessibility to healthcare, normalized difference vegetation index, building\nheight, and impervious surface. The results show that StreetViewLLM\nconsistently outperforms baseline models, offering improved predictive accuracy\nand deeper insights into the built environment. This research opens new\nopportunities for integrating the large language model into urban analytics,\ndecision-making in urban planning, infrastructure management, and environmental\nmonitoring.", "paper_summary_zh": "\u5730\u7406\u7a7a\u9593\u9810\u6e2c\u5c0d\u65bc\u5404\u500b\u9818\u57df\u81f3\u95dc\u91cd\u8981\uff0c\u4f8b\u5982\u707d\u5bb3\u7ba1\u7406\u3001\u90fd\u5e02\u898f\u5283\u548c\u516c\u5171\u885b\u751f\u3002\u50b3\u7d71\u6a5f\u5668\u5b78\u7fd2\u65b9\u6cd5\u5728\u8655\u7406\u975e\u7d50\u69cb\u5316\u6216\u591a\u6a21\u614b\u8cc7\u6599\uff08\u4f8b\u5982\u8857\u666f\u5f71\u50cf\uff09\u6642\uff0c\u901a\u5e38\u6703\u9762\u81e8\u9650\u5236\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa\u4e86 StreetViewLLM\uff0c\u9019\u662f\u4e00\u500b\u5275\u65b0\u7684\u67b6\u69cb\uff0c\u5b83\u5c07\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u8207\u601d\u8003\u93c8\u63a8\u7406\u548c\u591a\u6a21\u614b\u8cc7\u6599\u4f86\u6e90\u6574\u5408\u5728\u4e00\u8d77\u3002\u900f\u904e\u7d50\u5408\u8857\u666f\u5f71\u50cf\u3001\u5730\u7406\u5ea7\u6a19\u548c\u6587\u5b57\u8cc7\u6599\uff0cStreetViewLLM \u63d0\u5347\u4e86\u5730\u7406\u7a7a\u9593\u9810\u6e2c\u7684\u7cbe\u6e96\u5ea6\u548c\u8a73\u7d30\u7a0b\u5ea6\u3002\u6211\u5011\u7684\u505a\u6cd5\u4f7f\u7528\u4e86\u6aa2\u7d22\u589e\u5f37\u751f\u6210\u6280\u8853\uff0c\u589e\u5f37\u4e86\u5730\u7406\u8cc7\u8a0a\u8403\u53d6\uff0c\u80fd\u8a73\u7d30\u5206\u6790\u90fd\u5e02\u74b0\u5883\u3002\u9019\u500b\u6a21\u578b\u5df2\u7d93\u61c9\u7528\u65bc\u4e03\u500b\u5168\u7403\u57ce\u5e02\uff0c\u5305\u62ec\u9999\u6e2f\u3001\u6771\u4eac\u3001\u65b0\u52a0\u5761\u3001\u6d1b\u6749\u78ef\u3001\u7d10\u7d04\u3001\u502b\u6566\u548c\u5df4\u9ece\uff0c\u5728\u9810\u6e2c\u90fd\u5e02\u6307\u6a19\uff08\u5305\u62ec\u4eba\u53e3\u5bc6\u5ea6\u3001\u91ab\u7642\u4fdd\u5065\u53ef\u53ca\u6027\u3001\u6b63\u898f\u5316\u5dee\u7570\u690d\u88ab\u6307\u6578\u3001\u5efa\u7bc9\u7269\u9ad8\u5ea6\u548c\u4e0d\u900f\u6c34\u8868\u9762\uff09\u65b9\u9762\u5c55\u73fe\u51fa\u512a\u7570\u7684\u6548\u80fd\u3002\u7d50\u679c\u986f\u793a StreetViewLLM \u6301\u7e8c\u512a\u65bc\u57fa\u6e96\u6a21\u578b\uff0c\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u9810\u6e2c\u6e96\u78ba\u5ea6\uff0c\u4e26\u5c0d\u5df2\u5efa\u6210\u7684\u74b0\u5883\u6709\u66f4\u6df1\u5165\u7684\u898b\u89e3\u3002\u9019\u9805\u7814\u7a76\u70ba\u5c07\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u6574\u5408\u5230\u90fd\u5e02\u5206\u6790\u3001\u90fd\u5e02\u898f\u5283\u7684\u6c7a\u7b56\u5236\u5b9a\u3001\u57fa\u790e\u8a2d\u65bd\u7ba1\u7406\u548c\u74b0\u5883\u76e3\u63a7\u4e2d\uff0c\u958b\u555f\u4e86\u65b0\u7684\u5951\u6a5f\u3002", "author": "Zongrong Li et.al.", "authors": "Zongrong Li, Junhao Xu, Siqin Wang, Yifan Wu, Haiyang Li", "id": "2411.14476v1", "paper_url": "http://arxiv.org/abs/2411.14476v1", "repo": "null"}}