{"2405.07682": {"publish_time": "2024-05-13", "title": "FastSAG: Towards Fast Non-Autoregressive Singing Accompaniment Generation", "paper_summary": "Singing Accompaniment Generation (SAG), which generates instrumental music to\naccompany input vocals, is crucial to developing human-AI symbiotic art\ncreation systems. The state-of-the-art method, SingSong, utilizes a multi-stage\nautoregressive (AR) model for SAG, however, this method is extremely slow as it\ngenerates semantic and acoustic tokens recursively, and this makes it\nimpossible for real-time applications. In this paper, we aim to develop a Fast\nSAG method that can create high-quality and coherent accompaniments. A non-AR\ndiffusion-based framework is developed, which by carefully designing the\nconditions inferred from the vocal signals, generates the Mel spectrogram of\nthe target accompaniment directly. With diffusion and Mel spectrogram modeling,\nthe proposed method significantly simplifies the AR token-based SingSong\nframework, and largely accelerates the generation. We also design semantic\nprojection, prior projection blocks as well as a set of loss functions, to\nensure the generated accompaniment has semantic and rhythm coherence with the\nvocal signal. By intensive experimental studies, we demonstrate that the\nproposed method can generate better samples than SingSong, and accelerate the\ngeneration by at least 30 times. Audio samples and code are available at\nhttps://fastsag.github.io/.", "paper_summary_zh": "\u6b4c\u5531\u4f34\u594f\u751f\u6210 (SAG) \u6703\u7522\u751f\u5668\u6a02\uff0c\u4ee5\u642d\u914d\u8f38\u5165\u7684\u6b4c\u8072\uff0c\u5c0d\u65bc\u958b\u767c\u4eba\u985e\u8207\u4eba\u5de5\u667a\u6167\u5171\u751f\u7684\u85dd\u8853\u5275\u4f5c\u7cfb\u7d71\u81f3\u95dc\u91cd\u8981\u3002\u6700\u5148\u9032\u7684\u65b9\u6cd5 SingSong \u4f7f\u7528\u591a\u968e\u6bb5\u81ea\u8ff4\u6b78 (AR) \u6a21\u578b\u9032\u884c SAG\uff0c\u7136\u800c\uff0c\u6b64\u65b9\u6cd5\u6975\u70ba\u7de9\u6162\uff0c\u56e0\u70ba\u5b83\u6703\u905e\u8ff4\u7522\u751f\u8a9e\u7fa9\u548c\u8072\u5b78\u7b26\u865f\uff0c\u9019\u4f7f\u5f97\u5b83\u7121\u6cd5\u7528\u65bc\u5373\u6642\u61c9\u7528\u7a0b\u5f0f\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u65e8\u5728\u958b\u767c\u4e00\u7a2e\u5feb\u901f SAG \u65b9\u6cd5\uff0c\u53ef\u4ee5\u5275\u9020\u51fa\u9ad8\u54c1\u8cea\u4e14\u9023\u8cab\u7684\u4f34\u594f\u3002\u958b\u767c\u4e86\u4e00\u500b\u57fa\u65bc\u975e AR \u64f4\u6563\u7684\u67b6\u69cb\uff0c\u900f\u904e\u4ed4\u7d30\u8a2d\u8a08\u5f9e\u4eba\u8072\u8a0a\u865f\u63a8\u65b7\u51fa\u7684\u689d\u4ef6\uff0c\u76f4\u63a5\u7522\u751f\u76ee\u6a19\u4f34\u594f\u7684 Mel \u983b\u8b5c\u5716\u3002\u900f\u904e\u64f4\u6563\u548c Mel \u983b\u8b5c\u5716\u5efa\u6a21\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5927\u5e45\u7c21\u5316\u4e86\u57fa\u65bc AR \u7b26\u865f\u7684 SingSong \u67b6\u69cb\uff0c\u4e26\u5927\u5e45\u52a0\u901f\u4e86\u751f\u6210\u3002\u6211\u5011\u9084\u8a2d\u8a08\u4e86\u8a9e\u7fa9\u6295\u5f71\u3001\u5148\u9a57\u6295\u5f71\u5340\u584a\u4ee5\u53ca\u4e00\u7d44\u640d\u5931\u51fd\u6578\uff0c\u4ee5\u78ba\u4fdd\u7522\u751f\u7684\u4f34\u594f\u5728\u8a9e\u7fa9\u548c\u7bc0\u594f\u4e0a\u8207\u4eba\u8072\u8a0a\u865f\u76f8\u7b26\u3002\u900f\u904e\u5bc6\u96c6\u7684\u5be6\u9a57\u7814\u7a76\uff0c\u6211\u5011\u8b49\u660e\u4e86\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u4ee5\u7522\u751f\u6bd4 SingSong \u66f4\u597d\u7684\u7bc4\u4f8b\uff0c\u4e26\u5c07\u751f\u6210\u901f\u5ea6\u81f3\u5c11\u52a0\u5feb 30 \u500d\u3002\u97f3\u8a0a\u7bc4\u4f8b\u548c\u7a0b\u5f0f\u78bc\u53ef\u5728 https://fastsag.github.io/ \u53d6\u5f97\u3002", "author": "Jianyi Chen et.al.", "authors": "Jianyi Chen, Wei Xue, Xu Tan, Zhen Ye, Qifeng Liu, Yike Guo", "id": "2405.07682v1", "paper_url": "http://arxiv.org/abs/2405.07682v1", "repo": "null"}}