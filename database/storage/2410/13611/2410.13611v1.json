{"2410.13611": {"publish_time": "2024-10-17", "title": "H2OVL-Mississippi Vision Language Models Technical Report", "paper_summary": "Smaller vision-language models (VLMs) are becoming increasingly important for\nprivacy-focused, on-device applications due to their ability to run efficiently\non consumer hardware for processing enterprise commercial documents and images.\nThese models require strong language understanding and visual capabilities to\nenhance human-machine interaction. To address this need, we present\nH2OVL-Mississippi, a pair of small VLMs trained on 37 million image-text pairs\nusing 240 hours of compute on 8 x H100 GPUs. H2OVL-Mississippi-0.8B is a tiny\nmodel with 0.8 billion parameters that specializes in text recognition,\nachieving state of the art performance on the Text Recognition portion of\nOCRBench and surpassing much larger models in this area. Additionally, we are\nreleasing H2OVL-Mississippi-2B, a 2 billion parameter model for general use\ncases, exhibiting highly competitive metrics across various academic\nbenchmarks. Both models build upon our prior work with H2O-Danube language\nmodels, extending their capabilities into the visual domain. We release them\nunder the Apache 2.0 license, making VLMs accessible to everyone, democratizing\ndocument AI and visual LLMs.", "paper_summary_zh": "\u8f03\u5c0f\u7684\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM) \u5c0d\u65bc\u6ce8\u91cd\u96b1\u79c1\u7684\u88dd\u7f6e\u61c9\u7528\u7a0b\u5f0f\u8d8a\u4f86\u8d8a\u91cd\u8981\uff0c\u56e0\u70ba\u5b83\u5011\u80fd\u5920\u5728\u6d88\u8cbb\u6027\u786c\u9ad4\u4e0a\u6709\u6548\u57f7\u884c\uff0c\u4ee5\u8655\u7406\u4f01\u696d\u5546\u696d\u6587\u4ef6\u548c\u5f71\u50cf\u3002\u9019\u4e9b\u6a21\u578b\u9700\u8981\u5f37\u5927\u7684\u8a9e\u8a00\u7406\u89e3\u548c\u8996\u89ba\u80fd\u529b\uff0c\u624d\u80fd\u589e\u5f37\u4eba\u6a5f\u4e92\u52d5\u3002\u70ba\u4e86\u6eff\u8db3\u9019\u500b\u9700\u6c42\uff0c\u6211\u5011\u63d0\u51fa\u4e86 H2OVL-Mississippi\uff0c\u9019\u662f\u4e00\u5c0d\u5c0f\u578b VLM\uff0c\u4f7f\u7528 8 x H100 GPU \u57f7\u884c 240 \u5c0f\u6642\u7684\u904b\u7b97\uff0c\u5728 3700 \u842c\u500b\u5f71\u50cf\u6587\u5b57\u914d\u5c0d\u4e0a\u8a13\u7df4\u800c\u6210\u3002H2OVL-Mississippi-0.8B \u662f\u4e00\u500b\u5fae\u5c0f\u7684\u6a21\u578b\uff0c\u64c1\u6709 0.8 \u5104\u500b\u53c3\u6578\uff0c\u5c08\u7cbe\u65bc\u6587\u5b57\u8fa8\u8b58\uff0c\u5728 OCRBench \u7684\u6587\u5b57\u8fa8\u8b58\u90e8\u5206\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u9032\u7684\u6548\u80fd\uff0c\u4e26\u5728\u9019\u500b\u9818\u57df\u8d85\u8d8a\u4e86\u8a31\u591a\u66f4\u5927\u7684\u6a21\u578b\u3002\u6b64\u5916\uff0c\u6211\u5011\u6b63\u5728\u91cb\u51fa H2OVL-Mississippi-2B\uff0c\u9019\u662f\u4e00\u500b\u64c1\u6709 20 \u5104\u500b\u53c3\u6578\u7684\u6a21\u578b\uff0c\u9069\u7528\u65bc\u4e00\u822c\u7528\u9014\uff0c\u5728\u5404\u7a2e\u5b78\u8853\u57fa\u6e96\u4e2d\u5c55\u73fe\u9ad8\u5ea6\u7af6\u722d\u529b\u7684\u6307\u6a19\u3002\u9019\u5169\u500b\u6a21\u578b\u90fd\u5efa\u7acb\u5728\u6211\u5011\u4e4b\u524d\u4f7f\u7528 H2O-Danube \u8a9e\u8a00\u6a21\u578b\u6240\u505a\u7684\u5de5\u4f5c\u4e0a\uff0c\u5c07\u5b83\u5011\u7684\u80fd\u529b\u5ef6\u4f38\u5230\u8996\u89ba\u9818\u57df\u3002\u6211\u5011\u5728 Apache 2.0 \u6388\u6b0a\u4e0b\u91cb\u51fa\u5b83\u5011\uff0c\u8b93\u6240\u6709\u4eba\u7686\u53ef\u4f7f\u7528 VLM\uff0c\u6c11\u4e3b\u5316\u6587\u4ef6 AI \u548c\u8996\u89ba LLM\u3002", "author": "Shaikat Galib et.al.", "authors": "Shaikat Galib, Shanshan Wang, Guanshuo Xu, Pascal Pfeiffer, Ryan Chesler, Mark Landry, Sri Satish Ambati", "id": "2410.13611v1", "paper_url": "http://arxiv.org/abs/2410.13611v1", "repo": "null"}}