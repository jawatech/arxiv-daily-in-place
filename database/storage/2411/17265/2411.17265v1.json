{"2411.17265": {"publish_time": "2024-11-26", "title": "A Topic-level Self-Correctional Approach to Mitigate Hallucinations in MLLMs", "paper_summary": "Aligning the behaviors of Multimodal Large Language Models (MLLMs) with human\npreferences is crucial for developing robust and trustworthy AI systems. While\nrecent attempts have employed human experts or powerful auxiliary AI systems to\nprovide more accurate preference feedback, such as determining the preferable\nresponses from MLLMs or directly rewriting hallucination-free responses,\nextensive resource overhead compromise the scalability of the feedback\ncollection. In this work, we introduce Topic-level Preference Overwriting\n(TPO), a self-correctional approach that guide the model itself to mitigate its\nown hallucination at the topic level. Through a deconfounded strategy that\nreplaces each topic within the response with the best or worst alternatives\ngenerated by the model itself, TPO creates more contrasting pairwise preference\nfeedback, enhancing the feedback quality without human or proprietary model\nintervention. Notably, the experimental results demonstrate proposed TPO\nachieves state-of-the-art performance in trustworthiness, significantly\nreducing the object hallucinations by 92% and overall hallucinations by 38%.\nCode, model and data will be released.", "paper_summary_zh": "\u5c0d\u9f4a\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM) \u7684\u884c\u70ba\u8207\u4eba\u985e\u504f\u597d\u5c0d\u65bc\u958b\u767c\u5f37\u5065\u4e14\u503c\u5f97\u4fe1\u8cf4\u7684 AI \u7cfb\u7d71\u81f3\u95dc\u91cd\u8981\u3002\u96d6\u7136\u8fd1\u671f\u5617\u8a66\u5df2\u63a1\u7528\u4eba\u985e\u5c08\u5bb6\u6216\u5f37\u5927\u7684\u8f14\u52a9 AI \u7cfb\u7d71\u63d0\u4f9b\u66f4\u6e96\u78ba\u7684\u504f\u597d\u56de\u994b\uff0c\u4f8b\u5982\u5f9e MLLM \u4e2d\u6c7a\u5b9a\u8f03\u4f73\u7684\u56de\u61c9\u6216\u76f4\u63a5\u6539\u5beb\u6c92\u6709\u5e7b\u89ba\u7684\u56de\u61c9\uff0c\u4f46\u5ee3\u6cdb\u7684\u8cc7\u6e90\u958b\u92b7\u6703\u5f71\u97ff\u56de\u994b\u6536\u96c6\u7684\u53ef\u64f4\u5145\u6027\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e3b\u984c\u5c64\u7d1a\u504f\u597d\u8986\u5beb (TPO)\uff0c\u9019\u662f\u4e00\u7a2e\u81ea\u6211\u4fee\u6b63\u65b9\u6cd5\uff0c\u53ef\u5f15\u5c0e\u6a21\u578b\u672c\u8eab\u5728\u4e3b\u984c\u5c64\u7d1a\u6e1b\u8f15\u5176\u5e7b\u89ba\u3002\u900f\u904e\u4e00\u7a2e\u53bb\u6df7\u6dc6\u7684\u7b56\u7565\uff0c\u7528\u6a21\u578b\u672c\u8eab\u7522\u751f\u7684\u6700\u4f73\u6216\u6700\u5dee\u7684\u66ff\u4ee3\u65b9\u6848\u53d6\u4ee3\u56de\u61c9\u4e2d\u7684\u6bcf\u500b\u4e3b\u984c\uff0cTPO \u6703\u5275\u9020\u51fa\u66f4\u591a\u5c0d\u6bd4\u7684\u6210\u5c0d\u504f\u597d\u56de\u994b\uff0c\u5728\u6c92\u6709\u4eba\u985e\u6216\u5c08\u6709\u6a21\u578b\u4ecb\u5165\u7684\u60c5\u6cc1\u4e0b\u63d0\u5347\u56de\u994b\u54c1\u8cea\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5be6\u9a57\u7d50\u679c\u8b49\u660e\u6240\u63d0\u51fa\u7684 TPO \u5728\u503c\u5f97\u4fe1\u8cf4\u5ea6\u65b9\u9762\u9054\u5230\u4e86\u6700\u5148\u9032\u7684\u6548\u80fd\uff0c\u5927\u5e45\u6e1b\u5c11\u4e86 92% \u7684\u7269\u4ef6\u5e7b\u89ba\u548c 38% \u7684\u6574\u9ad4\u5e7b\u89ba\u3002\u7a0b\u5f0f\u78bc\u3001\u6a21\u578b\u548c\u8cc7\u6599\u5c07\u6703\u91cb\u51fa\u3002", "author": "Lehan He et.al.", "authors": "Lehan He, Zeren Chen, Zhelun Shi, Tianyu Yu, Jing Shao, Lu Sheng", "id": "2411.17265v1", "paper_url": "http://arxiv.org/abs/2411.17265v1", "repo": "null"}}