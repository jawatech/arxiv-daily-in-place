{"2406.07862": {"publish_time": "2024-06-12", "title": "Self-Distillation Learning Based on Temporal-Spatial Consistency for Spiking Neural Networks", "paper_summary": "Spiking neural networks (SNNs) have attracted considerable attention for\ntheir event-driven, low-power characteristics and high biological\ninterpretability. Inspired by knowledge distillation (KD), recent research has\nimproved the performance of the SNN model with a pre-trained teacher model.\nHowever, additional teacher models require significant computational resources,\nand it is tedious to manually define the appropriate teacher network\narchitecture. In this paper, we explore cost-effective self-distillation\nlearning of SNNs to circumvent these concerns. Without an explicit defined\nteacher, the SNN generates pseudo-labels and learns consistency during\ntraining. On the one hand, we extend the timestep of the SNN during training to\ncreate an implicit temporal ``teacher\" that guides the learning of the original\n``student\", i.e., the temporal self-distillation. On the other hand, we guide\nthe output of the weak classifier at the intermediate stage by the final output\nof the SNN, i.e., the spatial self-distillation. Our temporal-spatial\nself-distillation (TSSD) learning method does not introduce any inference\noverhead and has excellent generalization ability. Extensive experiments on the\nstatic image datasets CIFAR10/100 and ImageNet as well as the neuromorphic\ndatasets CIFAR10-DVS and DVS-Gesture validate the superior performance of the\nTSSD method. This paper presents a novel manner of fusing SNNs with KD,\nproviding insights into high-performance SNN learning methods.", "paper_summary_zh": "\u5c16\u5cf0\u795e\u7ecf\u7db2\u8def (SNN) \u56e0\u5176\u4e8b\u4ef6\u9a45\u52d5\u3001\u4f4e\u529f\u8017\u7279\u6027\u548c\u9ad8\u751f\u7269\u53ef\u89e3\u91cb\u6027\u800c\u5099\u53d7\u95dc\u6ce8\u3002\u53d7\u5230\u77e5\u8b58\u8403\u53d6 (KD) \u7684\u555f\u767c\uff0c\u6700\u8fd1\u7684\u7814\u7a76\u5df2\u900f\u904e\u9810\u5148\u8a13\u7df4\u597d\u7684\u6559\u5e2b\u6a21\u578b\u6539\u5584 SNN \u6a21\u578b\u7684\u6548\u80fd\u3002\u7136\u800c\uff0c\u984d\u5916\u7684\u6559\u5e2b\u6a21\u578b\u9700\u8981\u5927\u91cf\u7684\u904b\u7b97\u8cc7\u6e90\uff0c\u800c\u4e14\u624b\u52d5\u5b9a\u7fa9\u9069\u7576\u7684\u6559\u5e2b\u7db2\u8def\u67b6\u69cb\u5f88\u7e41\u7463\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e SNN \u7684\u5177\u6210\u672c\u6548\u76ca\u7684\u81ea\u8403\u53d6\u5b78\u7fd2\uff0c\u4ee5\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\u3002\u5728\u6c92\u6709\u660e\u78ba\u5b9a\u7fa9\u7684\u6559\u5e2b\u60c5\u6cc1\u4e0b\uff0cSNN \u6703\u7522\u751f\u507d\u6a19\u7c64\u4e26\u5728\u8a13\u7df4\u671f\u9593\u5b78\u7fd2\u4e00\u81f4\u6027\u3002\u4e00\u65b9\u9762\uff0c\u6211\u5011\u5728\u8a13\u7df4\u671f\u9593\u5ef6\u4f38 SNN \u7684\u6642\u9593\u6b65\u9577\uff0c\u4ee5\u5efa\u7acb\u4e00\u500b\u96b1\u542b\u7684\u6642\u9593\u300c\u6559\u5e2b\u300d\uff0c\u5f15\u5c0e\u539f\u59cb\u300c\u5b78\u751f\u300d\u7684\u5b78\u7fd2\uff0c\u5373\u6642\u9593\u81ea\u8403\u53d6\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u6211\u5011\u900f\u904e SNN \u7684\u6700\u7d42\u8f38\u51fa\u5f15\u5c0e\u4e2d\u9593\u968e\u6bb5\u7684\u5f31\u5206\u985e\u5668\u8f38\u51fa\uff0c\u5373\u7a7a\u9593\u81ea\u8403\u53d6\u3002\u6211\u5011\u7684\u6642\u9593\u7a7a\u9593\u81ea\u8403\u53d6 (TSSD) \u5b78\u7fd2\u65b9\u6cd5\u4e0d\u6703\u5f15\u5165\u4efb\u4f55\u63a8\u8ad6\u8ca0\u64d4\uff0c\u4e14\u5177\u5099\u6975\u4f73\u7684\u6cdb\u5316\u80fd\u529b\u3002\u5728\u975c\u614b\u5f71\u50cf\u8cc7\u6599\u96c6 CIFAR10/100 \u548c ImageNet\uff0c\u4ee5\u53ca\u795e\u7d93\u5f62\u614b\u8cc7\u6599\u96c6 CIFAR10-DVS \u548c DVS-Gesture \u4e0a\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u9a57\u8b49\u4e86 TSSD \u65b9\u6cd5\u7684\u512a\u7570\u6548\u80fd\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u7a2e\u5c07 SNN \u8207 KD \u878d\u5408\u7684\u65b0\u7a4e\u65b9\u5f0f\uff0c\u63d0\u4f9b\u5c0d\u9ad8\u6027\u80fd SNN \u5b78\u7fd2\u65b9\u6cd5\u7684\u898b\u89e3\u3002", "author": "Lin Zuo et.al.", "authors": "Lin Zuo, Yongqi Ding, Mengmeng Jing, Kunshan Yang, Yunqian Yu", "id": "2406.07862v1", "paper_url": "http://arxiv.org/abs/2406.07862v1", "repo": "null"}}