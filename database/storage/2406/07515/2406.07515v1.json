{"2406.07515": {"publish_time": "2024-06-11", "title": "Beyond Model Collapse: Scaling Up with Synthesized Data Requires Reinforcement", "paper_summary": "Synthesized data from generative models is increasingly considered as an\nalternative to human-annotated data for fine-tuning Large Language Models. This\nraises concerns about model collapse: a drop in performance of models\nfine-tuned on generated data. Considering that it is easier for both humans and\nmachines to tell between good and bad examples than to generate high-quality\nsamples, we investigate the use of feedback on synthesized data to prevent\nmodel collapse. We derive theoretical conditions under which a Gaussian mixture\nclassification model can achieve asymptotically optimal performance when\ntrained on feedback-augmented synthesized data, and provide supporting\nsimulations for finite regimes. We illustrate our theoretical predictions on\ntwo practical problems: computing matrix eigenvalues with transformers and news\nsummarization with large language models, which both undergo model collapse\nwhen trained on model-generated data. We show that training from\nfeedback-augmented synthesized data, either by pruning incorrect predictions or\nby selecting the best of several guesses, can prevent model collapse,\nvalidating popular approaches like RLHF.", "paper_summary_zh": "\u5408\u6210\u8cc7\u6599\u4f86\u81ea\u751f\u6210\u6a21\u578b\uff0c\u8d8a\u4f86\u8d8a\u88ab\u8996\u70ba\u7528\u65bc\u5fae\u8abf\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u771f\u4eba\u6a19\u8a3b\u8cc7\u6599\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u9019\u5f15\u8d77\u4e86\u6a21\u578b\u5d29\u6f70\u7684\u64d4\u6182\uff1a\u5728\u751f\u6210\u8cc7\u6599\u4e0a\u5fae\u8abf\u6a21\u578b\u7684\u6548\u80fd\u4e0b\u964d\u3002\u8003\u616e\u5230\u4eba\u985e\u548c\u6a5f\u5668\u6bd4\u751f\u6210\u9ad8\u54c1\u8cea\u7bc4\u4f8b\u66f4\u5bb9\u6613\u5206\u8fa8\u597d\u58de\u7bc4\u4f8b\uff0c\u6211\u5011\u7814\u7a76\u5728\u5408\u6210\u8cc7\u6599\u4e0a\u4f7f\u7528\u56de\u994b\u4ee5\u9632\u6b62\u6a21\u578b\u5d29\u6f70\u3002\u6211\u5011\u63a8\u5c0e\u51fa\u9ad8\u65af\u6df7\u5408\u5206\u985e\u6a21\u578b\u5728\u8a13\u7df4\u65bc\u56de\u994b\u589e\u5f37\u5408\u6210\u8cc7\u6599\u6642\uff0c\u53ef\u4ee5\u5728\u6f38\u8fd1\u6700\u4f73\u6548\u80fd\u4e0b\u9054\u6210\u7684\u7406\u8ad6\u689d\u4ef6\uff0c\u4e26\u63d0\u4f9b\u6709\u9650\u72c0\u614b\u7684\u652f\u63f4\u6a21\u64ec\u3002\u6211\u5011\u5728\u5169\u500b\u5be6\u969b\u554f\u984c\u4e0a\u8aaa\u660e\u6211\u5011\u7684\u7406\u8ad6\u9810\u6e2c\uff1a\u4f7f\u7528\u8f49\u63db\u5668\u8a08\u7b97\u77e9\u9663\u7279\u5fb5\u503c\u548c\u4f7f\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u9032\u884c\u65b0\u805e\u6458\u8981\uff0c\u9019\u5169\u500b\u554f\u984c\u5728\u8a13\u7df4\u65bc\u6a21\u578b\u751f\u6210\u7684\u8cc7\u6599\u6642\u90fd\u6703\u767c\u751f\u6a21\u578b\u5d29\u6f70\u3002\u6211\u5011\u8868\u660e\uff0c\u900f\u904e\u4fee\u526a\u4e0d\u6b63\u78ba\u7684\u9810\u6e2c\u6216\u9078\u64c7\u591a\u500b\u731c\u6e2c\u4e2d\u7684\u6700\u4f73\u731c\u6e2c\uff0c\u5f9e\u56de\u994b\u589e\u5f37\u5408\u6210\u8cc7\u6599\u9032\u884c\u8a13\u7df4\u53ef\u4ee5\u9632\u6b62\u6a21\u578b\u5d29\u6f70\uff0c\u9a57\u8b49\u4e86 RLHF \u7b49\u71b1\u9580\u65b9\u6cd5\u3002", "author": "Yunzhen Feng et.al.", "authors": "Yunzhen Feng, Elvis Dohmatob, Pu Yang, Francois Charton, Julia Kempe", "id": "2406.07515v1", "paper_url": "http://arxiv.org/abs/2406.07515v1", "repo": "null"}}