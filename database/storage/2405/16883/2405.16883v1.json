{"2405.16883": {"publish_time": "2024-05-27", "title": "Scorch: A Library for Sparse Deep Learning", "paper_summary": "The rapid growth in the size of deep learning models strains the capabilities\nof traditional dense computation paradigms. Leveraging sparse computation has\nbecome increasingly popular for training and deploying large-scale models, but\nexisting deep learning frameworks lack extensive support for sparse operations.\nTo bridge this gap, we introduce Scorch, a library that seamlessly integrates\nefficient sparse tensor computation into the PyTorch ecosystem, with an initial\nfocus on inference workloads on CPUs. Scorch provides a flexible and intuitive\ninterface for sparse tensors, supporting diverse sparse data structures. Scorch\nintroduces a compiler stack that automates key optimizations, including\nautomatic loop ordering, tiling, and format inference. Combined with a runtime\nthat adapts its execution to both dense and sparse data, Scorch delivers\nsubstantial speedups over hand-written PyTorch Sparse (torch.sparse) operations\nwithout sacrificing usability. More importantly, Scorch enables efficient\ncomputation of complex sparse operations that lack hand-optimized PyTorch\nimplementations. This flexibility is crucial for exploring novel sparse\narchitectures. We demonstrate Scorch's ease of use and performance gains on\ndiverse deep learning models across multiple domains. With only minimal code\nchanges, Scorch achieves 1.05-5.78x speedups over PyTorch Sparse on end-to-end\ntasks. Scorch's seamless integration and performance gains make it a valuable\naddition to the PyTorch ecosystem. We believe Scorch will enable wider\nexploration of sparsity as a tool for scaling deep learning and inform the\ndevelopment of other sparse libraries.", "paper_summary_zh": "\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\u7684\u898f\u6a21\u5feb\u901f\u589e\u9577\uff0c\u5c0d\u50b3\u7d71\u5bc6\u96c6\u904b\u7b97\u7bc4\u4f8b\u7684\u80fd\u529b\u9020\u6210\u58d3\u529b\u3002\u5229\u7528\u7a00\u758f\u904b\u7b97\u5df2\u7d93\u8b8a\u5f97\u8d8a\u4f86\u8d8a\u6d41\u884c\uff0c\u7528\u65bc\u8a13\u7df4\u548c\u90e8\u7f72\u5927\u898f\u6a21\u6a21\u578b\uff0c\u4f46\u73fe\u6709\u7684\u6df1\u5ea6\u5b78\u7fd2\u6846\u67b6\u7f3a\u4e4f\u5c0d\u7a00\u758f\u904b\u7b97\u7684\u5ee3\u6cdb\u652f\u63f4\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u5dee\u8ddd\uff0c\u6211\u5011\u5f15\u5165\u4e86 Scorch\uff0c\u9019\u662f\u4e00\u500b\u5c07\u9ad8\u6548\u7a00\u758f\u5f35\u91cf\u904b\u7b97\u7121\u7e2b\u6574\u5408\u5230 PyTorch \u751f\u614b\u7cfb\u7d71\u4e2d\u7684\u51fd\u5f0f\u5eab\uff0c\u6700\u521d\u91cd\u9ede\u653e\u5728 CPU \u4e0a\u7684\u63a8\u8ad6\u5de5\u4f5c\u8ca0\u8f09\u3002Scorch \u70ba\u7a00\u758f\u5f35\u91cf\u63d0\u4f9b\u4e86\u4e00\u500b\u9748\u6d3b\u4e14\u76f4\u89c0\u7684\u4ecb\u9762\uff0c\u652f\u63f4\u591a\u6a23\u5316\u7684\u7a00\u758f\u8cc7\u6599\u7d50\u69cb\u3002Scorch \u5f15\u5165\u4e86\u7de8\u8b6f\u5668\u5806\u758a\uff0c\u81ea\u52d5\u5316\u4e86\u95dc\u9375\u6700\u4f73\u5316\uff0c\u5305\u62ec\u81ea\u52d5\u8ff4\u5708\u6392\u5e8f\u3001\u5e73\u92ea\u548c\u683c\u5f0f\u63a8\u8ad6\u3002\u7d50\u5408\u9069\u61c9\u5bc6\u96c6\u548c\u7a00\u758f\u8cc7\u6599\u7684\u57f7\u884c\u6642\u9593\uff0cScorch \u63d0\u4f9b\u4e86\u6bd4\u624b\u5beb PyTorch Sparse (torch.sparse) \u904b\u7b97\u66f4\u5927\u5e45\u5ea6\u7684\u52a0\u901f\uff0c\u540c\u6642\u4e0d\u72a7\u7272\u53ef\u7528\u6027\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0cScorch \u80fd\u5920\u6709\u6548\u7387\u5730\u8a08\u7b97\u7f3a\u5c11\u624b\u52d5\u6700\u4f73\u5316 PyTorch \u5be6\u4f5c\u7684\u8907\u96dc\u7a00\u758f\u904b\u7b97\u3002\u9019\u7a2e\u9748\u6d3b\u6027\u5c0d\u65bc\u63a2\u7d22\u65b0\u7a4e\u7684\u7a00\u758f\u67b6\u69cb\u81f3\u95dc\u91cd\u8981\u3002\u6211\u5011\u5c55\u793a\u4e86 Scorch \u5728\u591a\u500b\u9818\u57df\u7684\u5404\u7a2e\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\u4e0a\u7684\u6613\u7528\u6027\u548c\u6548\u80fd\u63d0\u5347\u3002\u53ea\u9700\u6700\u5c0f\u7684\u7a0b\u5f0f\u78bc\u8b8a\u66f4\uff0cScorch \u5728\u7aef\u5230\u7aef\u4efb\u52d9\u4e0a\u5c31\u80fd\u6bd4 PyTorch Sparse \u5feb 1.05-5.78 \u500d\u3002Scorch \u7684\u7121\u7e2b\u6574\u5408\u548c\u6548\u80fd\u63d0\u5347\u4f7f\u5176\u6210\u70ba PyTorch \u751f\u614b\u7cfb\u7d71\u7684\u5bf6\u8cb4\u88dc\u5145\u3002\u6211\u5011\u76f8\u4fe1 Scorch \u5c07\u4f7f\u7a00\u758f\u6027\u4f5c\u70ba\u64f4\u5c55\u6df1\u5ea6\u5b78\u7fd2\u7684\u5de5\u5177\u5f97\u5230\u66f4\u5ee3\u6cdb\u7684\u63a2\u7d22\uff0c\u4e26\u70ba\u5176\u4ed6\u7a00\u758f\u51fd\u5f0f\u5eab\u7684\u958b\u767c\u63d0\u4f9b\u8cc7\u8a0a\u3002", "author": "Bobby Yan et.al.", "authors": "Bobby Yan, Alexander J. Root, Trevor Gale, David Broman, Fredrik Kjolstad", "id": "2405.16883v1", "paper_url": "http://arxiv.org/abs/2405.16883v1", "repo": "null"}}