{"2407.05550": {"publish_time": "2024-07-08", "title": "MEEG and AT-DGNN: Advancing EEG Emotion Recognition with Music and Graph Learning", "paper_summary": "Recent advances in neuroscience have elucidated the crucial role of\ncoordinated brain region activities during cognitive tasks. To explore the\ncomplexity, we introduce the MEEG dataset, a comprehensive multi-modal\nmusic-induced electroencephalogram (EEG) dataset and the Attention-based\nTemporal Learner with Dynamic Graph Neural Network (AT-DGNN), a novel framework\nfor EEG-based emotion recognition. The MEEG dataset captures a wide range of\nemotional responses to music, enabling an in-depth analysis of brainwave\npatterns in musical contexts. The AT-DGNN combines an attention-based temporal\nlearner with a dynamic graph neural network (DGNN) to accurately model the\nlocal and global graph dynamics of EEG data across varying brain network\ntopology. Our evaluations show that AT-DGNN achieves superior performance, with\nan accuracy (ACC) of 83.06\\% in arousal and 85.31\\% in valence, outperforming\nstate-of-the-art (SOTA) methods on the MEEG dataset. Comparative analyses with\ntraditional datasets like DEAP highlight the effectiveness of our approach and\nunderscore the potential of music as a powerful medium for emotion induction.\nThis study not only advances our understanding of the brain emotional\nprocessing, but also enhances the accuracy of emotion recognition technologies\nin brain-computer interfaces (BCI), leveraging both graph-based learning and\nthe emotional impact of music. The source code and dataset are available at\n\\textit{https://github.com/xmh1011/AT-DGNN}.", "paper_summary_zh": "<paragraph>\u795e\u7d93\u79d1\u5b78\u7684\u6700\u65b0\u9032\u5c55\u95e1\u660e\u4e86\u8a8d\u77e5\u4efb\u52d9\u671f\u9593\u5354\u8abf\u8166\u5340\u6d3b\u52d5\u7684\u95dc\u9375\u4f5c\u7528\u3002\u70ba\u4e86\u63a2\u8a0e\u5176\u8907\u96dc\u6027\uff0c\u6211\u5011\u5f15\u5165\u4e86 MEEG \u8cc7\u6599\u96c6\uff0c\u4e00\u500b\u5168\u9762\u7684\u591a\u6a21\u614b\u97f3\u6a02\u8a98\u767c\u8166\u96fb\u5716 (EEG) \u8cc7\u6599\u96c6\u548c\u57fa\u65bc\u6ce8\u610f\u529b\u7684\u6642\u614b\u5b78\u7fd2\u5668\u8207\u52d5\u614b\u5716\u5f62\u795e\u7d93\u7db2\u8def (AT-DGNN)\uff0c\u4e00\u500b\u7528\u65bc\u57fa\u65bc EEG \u7684\u60c5\u7dd2\u8b58\u5225\u7684\u65b0\u7a4e\u6846\u67b6\u3002MEEG \u8cc7\u6599\u96c6\u6355\u6349\u4e86\u5c0d\u97f3\u6a02\u7684\u5404\u7a2e\u60c5\u7dd2\u53cd\u61c9\uff0c\u4f7f\u6211\u5011\u80fd\u5920\u6df1\u5165\u5206\u6790\u97f3\u6a02\u80cc\u666f\u4e0b\u7684\u8166\u6ce2\u6a21\u5f0f\u3002AT-DGNN \u7d50\u5408\u4e86\u57fa\u65bc\u6ce8\u610f\u529b\u7684\u6642\u614b\u5b78\u7fd2\u5668\u8207\u52d5\u614b\u5716\u5f62\u795e\u7d93\u7db2\u8def (DGNN)\uff0c\u4ee5\u6e96\u78ba\u5efa\u6a21 EEG \u8cc7\u6599\u5728\u4e0d\u540c\u8166\u7db2\u8def\u62d3\u64b2\u4e2d\u7684\u5c40\u90e8\u548c\u5168\u5c40\u5716\u5f62\u52d5\u614b\u3002\u6211\u5011\u7684\u8a55\u4f30\u986f\u793a\uff0cAT-DGNN \u9054\u5230\u4e86\u512a\u7570\u7684\u6548\u80fd\uff0c\u5728\u559a\u9192\u65b9\u9762\u6e96\u78ba\u7387 (ACC) \u70ba 83.06%\uff0c\u5728\u6548\u50f9\u65b9\u9762\u6e96\u78ba\u7387\u70ba 85.31%\uff0c\u5728 MEEG \u8cc7\u6599\u96c6\u4e0a\u512a\u65bc\u6700\u5148\u9032 (SOTA) \u7684\u65b9\u6cd5\u3002\u8207 DEAP \u7b49\u50b3\u7d71\u8cc7\u6599\u96c6\u7684\u6bd4\u8f03\u5206\u6790\u7a81\u986f\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e26\u5f37\u8abf\u4e86\u97f3\u6a02\u4f5c\u70ba\u60c5\u7dd2\u8a98\u767c\u7684\u6709\u529b\u5a92\u4ecb\u7684\u6f5b\u529b\u3002\u9019\u9805\u7814\u7a76\u4e0d\u50c5\u589e\u9032\u4e86\u6211\u5011\u5c0d\u5927\u8166\u60c5\u7dd2\u8655\u7406\u7684\u7406\u89e3\uff0c\u9084\u63d0\u9ad8\u4e86\u8166\u6a5f\u4ecb\u9762 (BCI) \u4e2d\u60c5\u7dd2\u8b58\u5225\u6280\u8853\u7684\u6e96\u78ba\u6027\uff0c\u540c\u6642\u5229\u7528\u4e86\u57fa\u65bc\u5716\u5f62\u7684\u5b78\u7fd2\u548c\u97f3\u6a02\u7684\u60c5\u7dd2\u5f71\u97ff\u3002\u539f\u59cb\u78bc\u548c\u8cc7\u6599\u96c6\u53ef\u5728 \\textit{https://github.com/xmh1011/AT-DGNN} \u53d6\u5f97\u3002</paragraph>", "author": "Minghao Xiao et.al.", "authors": "Minghao Xiao, Zhengxi Zhu, Wenyu Wang, Meixia Qu", "id": "2407.05550v1", "paper_url": "http://arxiv.org/abs/2407.05550v1", "repo": "null"}}