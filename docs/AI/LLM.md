
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-23**|**Stress-Testing Long-Context Language Models with Lifelong ICL and Task Haystack**|Xiaoyue Xu et.al.|[2407.16695v1](http://arxiv.org/abs/2407.16695v1)|null|
|**2024-07-23**|**Explanation Regularisation through the Lens of Attributions**|Pedro Ferreira et.al.|[2407.16693v1](http://arxiv.org/abs/2407.16693v1)|null|
|**2024-07-23**|**Can Large Language Models Automatically Jailbreak GPT-4V?**|Yuanwei Wu et.al.|[2407.16686v1](http://arxiv.org/abs/2407.16686v1)|null|
|**2024-07-23**|**KAN or MLP: A Fairer Comparison**|Runpeng Yu et.al.|[2407.16674v1](http://arxiv.org/abs/2407.16674v1)|[link](https://github.com/yu-rp/kanbefair)|
|**2024-07-23**|**RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent**|Huiyu Xu et.al.|[2407.16667v1](http://arxiv.org/abs/2407.16667v1)|null|
|**2024-07-23**|**Towards scalable efficient on-device ASR with transfer learning**|Laxmi Pandey et.al.|[2407.16664v1](http://arxiv.org/abs/2407.16664v1)|null|
|**2024-07-23**|**Course-Correction: Safety Alignment Using Synthetic Preferences**|Rongwu Xu et.al.|[2407.16637v1](http://arxiv.org/abs/2407.16637v1)|null|
|**2024-07-23**|**Knowledge-driven AI-generated data for accurate and interpretable breast ultrasound diagnoses**|Haojun Yu et.al.|[2407.16634v1](http://arxiv.org/abs/2407.16634v1)|null|
|**2024-07-23**|**Semantic Change Characterization with LLMs using Rhetorics**|Jader Martins Camboim de Sá et.al.|[2407.16624v1](http://arxiv.org/abs/2407.16624v1)|null|
|**2024-07-23**|**Lawma: The Power of Specialization for Legal Tasks**|Ricardo Dominguez-Olmedo et.al.|[2407.16615v1](http://arxiv.org/abs/2407.16615v1)|null|
|**2024-07-23**|**No-brainer: Morphological Computation driven Adaptive Behavior in Soft Robots**|Alican Mertan et.al.|[2407.16613v1](http://arxiv.org/abs/2407.16613v1)|null|
|**2024-07-23**|**Local vs Global continual learning**|Giulia Lanzillotta et.al.|[2407.16611v1](http://arxiv.org/abs/2407.16611v1)|null|
|**2024-07-23**|**Deep Bayesian segmentation for colon polyps: Well-calibrated predictions in medical imaging**|Daniela L. Ramos et.al.|[2407.16608v1](http://arxiv.org/abs/2407.16608v1)|null|
|**2024-07-23**|**Data Mixture Inference: What do BPE Tokenizers Reveal about their Training Data?**|Jonathan Hayase et.al.|[2407.16607v1](http://arxiv.org/abs/2407.16607v1)|null|
|**2024-07-23**|**Shared Imagination: LLMs Hallucinate Alike**|Yilun Zhou et.al.|[2407.16604v1](http://arxiv.org/abs/2407.16604v1)|null|
|**2024-07-23**|**GenRec: A Flexible Data Generator for Recommendations**|Erica Coppolillo et.al.|[2407.16594v1](http://arxiv.org/abs/2407.16594v1)|null|
|**2024-07-23**|**A Comparative Study on Patient Language across Therapeutic Domains for Effective Patient Voice Classification in Online Health Discussions**|Giorgos Lysandrou et.al.|[2407.16593v1](http://arxiv.org/abs/2407.16593v1)|null|
|**2024-07-23**|**TLCR: Token-Level Continuous Reward for Fine-grained Reinforcement Learning from Human Feedback**|Eunseop Yoon et.al.|[2407.16574v1](http://arxiv.org/abs/2407.16574v1)|null|
|**2024-07-23**|**Retrieve, Generate, Evaluate: A Case Study for Medical Paraphrases Generation with Small Language Models**|Ioana Buhnila et.al.|[2407.16565v1](http://arxiv.org/abs/2407.16565v1)|null|
|**2024-07-23**|**Audio Prompt Adapter: Unleashing Music Editing Abilities for Text-to-Music with Lightweight Finetuning**|Fang-Duo Tsai et.al.|[2407.16564v1](http://arxiv.org/abs/2407.16564v1)|[link](https://github.com/fundwotsai2001/ap-adapter)|
|**2024-07-23**|**Patched RTC: evaluating LLMs for diverse software development tasks**|Asankhaya Sharma et.al.|[2407.16557v1](http://arxiv.org/abs/2407.16557v1)|null|
|**2024-07-23**|**Quantifying the Role of Textual Predictability in Automatic Speech Recognition**|Sean Robertson et.al.|[2407.16537v1](http://arxiv.org/abs/2407.16537v1)|null|
|**2024-07-23**|**HAPFI: History-Aware Planning based on Fused Information**|Sujin Jeon et.al.|[2407.16533v1](http://arxiv.org/abs/2407.16533v1)|null|
|**2024-07-23**|**Imperfect Vision Encoders: Efficient and Robust Tuning for Vision-Language Models**|Aristeidis Panos et.al.|[2407.16526v1](http://arxiv.org/abs/2407.16526v1)|null|
|**2024-07-23**|**AMONGAGENTS: Evaluating Large Language Models in the Interactive Text-Based Social Deduction Game**|Yizhou Chi et.al.|[2407.16521v1](http://arxiv.org/abs/2407.16521v1)|null|
|**2024-07-23**|**Assessing In-context Learning and Fine-tuning for Topic Classification of German Web Data**|Julian Schelb et.al.|[2407.16516v1](http://arxiv.org/abs/2407.16516v1)|null|
|**2024-07-23**|**Is 3D Convolution with 5D Tensors Really Necessary for Video Analysis?**|Habib Hajimolahoseini et.al.|[2407.16514v1](http://arxiv.org/abs/2407.16514v1)|null|
|**2024-07-23**|**Articulation Work and Tinkering for Fairness in Machine Learning**|Miriam Fahimi et.al.|[2407.16496v1](http://arxiv.org/abs/2407.16496v1)|null|
|**2024-07-23**|**Learning General Continuous Constraint from Demonstrations via Positive-Unlabeled Learning**|Baiyu Peng et.al.|[2407.16485v1](http://arxiv.org/abs/2407.16485v1)|null|
|**2024-07-23**|**BONES: a Benchmark fOr Neural Estimation of Shapley values**|Davide Napolitano et.al.|[2407.16482v1](http://arxiv.org/abs/2407.16482v1)|[link](https://github.com/davidenapolitano/bones)|
|**2024-07-23**|**Machine Translation Hallucination Detection for Low and High Resource Languages using Large Language Models**|Kenza Benkirane et.al.|[2407.16470v1](http://arxiv.org/abs/2407.16470v1)|null|
|**2024-07-23**|**Side-Channel Analysis of OpenVINO-based Neural Network Models**|Dirmanto Jap et.al.|[2407.16467v1](http://arxiv.org/abs/2407.16467v1)|null|
|**2024-07-23**|**Psychomatics -- A Multidisciplinary Framework for Understanding Artificial Minds**|Giuseppe Riva et.al.|[2407.16444v1](http://arxiv.org/abs/2407.16444v1)|null|
|**2024-07-23**|**Enhancing LLM's Cognition via Structurization**|Kai Liu et.al.|[2407.16434v1](http://arxiv.org/abs/2407.16434v1)|null|
|**2024-07-23**|**FairFlow: An Automated Approach to Model-based Counterfactual Data Augmentation For NLP**|Ewoenam Kwaku Tokpo et.al.|[2407.16431v1](http://arxiv.org/abs/2407.16431v1)|null|
|**2024-07-23**|**On ADMM in Heterogeneous Federated Learning: Personalization, Robustness, and Fairness**|Shengkun Zhu et.al.|[2407.16397v1](http://arxiv.org/abs/2407.16397v1)|[link](https://github.com/zsk66/flame)|
|**2024-07-23**|**TookaBERT: A Step Forward for Persian NLU**|MohammadAli SadraeiJavaheri et.al.|[2407.16382v1](http://arxiv.org/abs/2407.16382v1)|null|
|**2024-07-23**|**Ranking protein-protein models with large language models and graph neural networks**|Xiaotong Xu et.al.|[2407.16375v1](http://arxiv.org/abs/2407.16375v1)|[link](https://github.com/haddocking/deeprank-gnn-esm)|
|**2024-07-23**|**Evolutionary Prompt Design for LLM-Based Post-ASR Error Correction**|Rithik Sachdev et.al.|[2407.16370v1](http://arxiv.org/abs/2407.16370v1)|null|
|**2024-07-23**|**TWIN V2: Scaling Ultra-Long User Behavior Sequence Modeling for Enhanced CTR Prediction at Kuaishou**|Zihua Si et.al.|[2407.16357v1](http://arxiv.org/abs/2407.16357v1)|null|
|**2024-07-23**|**FACTTRACK: Time-Aware World State Tracking in Story Outlines**|Zhiheng Lyu et.al.|[2407.16347v1](http://arxiv.org/abs/2407.16347v1)|null|
|**2024-07-23**|**SOAP: Enhancing Spatio-Temporal Relation and Motion Information Capturing for Few-Shot Action Recognition**|Wenbo Huang et.al.|[2407.16344v1](http://arxiv.org/abs/2407.16344v1)|[link](https://github.com/wenbohuang1002/soap)|
|**2024-07-23**|**PhenoFlow: A Human-LLM Driven Visual Analytics System for Exploring Large and Complex Stroke Datasets**|Jaeyoung Kim et.al.|[2407.16329v1](http://arxiv.org/abs/2407.16329v1)|null|
|**2024-07-23**|**PrimeGuard: Safe and Helpful LLMs through Tuning-Free Routing**|Blazej Manczak et.al.|[2407.16318v1](http://arxiv.org/abs/2407.16318v1)|[link](https://github.com/dynamofl/primeguard)|
|**2024-07-23**|**Quantum Computing for Climate Resilience and Sustainability Challenges**|Kin Tung Michael Ho et.al.|[2407.16296v1](http://arxiv.org/abs/2407.16296v1)|null|
|**2024-07-23**|**Visual Stereotypes of Autism Spectrum in DALL-E, Stable Diffusion, SDXL, and Midjourney**|Maciej Wodziński et.al.|[2407.16292v1](http://arxiv.org/abs/2407.16292v1)|null|
|**2024-07-23**|**Federated Learning for Face Recognition via Intra-subject Self-supervised Learning**|Hansol Kim et.al.|[2407.16289v1](http://arxiv.org/abs/2407.16289v1)|null|
|**2024-07-23**|**A deeper look at depth pruning of LLMs**|Shoaib Ahmed Siddiqui et.al.|[2407.16286v1](http://arxiv.org/abs/2407.16286v1)|[link](https://github.com/shoaibahmed/llm_depth_pruning)|
|**2024-07-23**|**Efficient Detection of Commutative Factors in Factor Graphs**|Malte Luttermann et.al.|[2407.16280v1](http://arxiv.org/abs/2407.16280v1)|[link](https://github.com/StatisticalRelationalAI/DECOR)|
|**2024-07-23**|**Beyond Binary Gender: Evaluating Gender-Inclusive Machine Translation with Ambiguous Attitude Words**|Yijie Chen et.al.|[2407.16266v1](http://arxiv.org/abs/2407.16266v1)|[link](https://github.com/pppa2019/ambgimt)|
|**2024-07-23**|**Self-Reasoning Assistant Learning for non-Abelian Gauge Fields Design**|Jinyang Sun et.al.|[2407.16255v1](http://arxiv.org/abs/2407.16255v1)|null|
|**2024-07-23**|**LawLuo: A Chinese Law Firm Co-run by LLM Agents**|Jingyun Sun et.al.|[2407.16252v1](http://arxiv.org/abs/2407.16252v1)|null|
|**2024-07-23**|**HSVLT: Hierarchical Scale-Aware Vision-Language Transformer for Multi-Label Image Classification**|Shuyi Ouyang et.al.|[2407.16244v1](http://arxiv.org/abs/2407.16244v1)|null|
|**2024-07-23**|**OriGen:Enhancing RTL Code Generation with Code-to-Code Augmentation and Self-Reflection**|Fan Cui et.al.|[2407.16237v1](http://arxiv.org/abs/2407.16237v1)|null|
|**2024-07-23**|**Comparison of Static Application Security Testing Tools and Large Language Models for Repo-level Vulnerability Detection**|Xin Zhou et.al.|[2407.16235v1](http://arxiv.org/abs/2407.16235v1)|null|
|**2024-07-23**|**A Multi-view Mask Contrastive Learning Graph Convolutional Neural Network for Age Estimation**|Yiping Zhang et.al.|[2407.16234v1](http://arxiv.org/abs/2407.16234v1)|null|
|**2024-07-23**|**PreAlign: Boosting Cross-Lingual Transfer by Early Establishment of Multilingual Alignment**|Jiahuan Li et.al.|[2407.16222v1](http://arxiv.org/abs/2407.16222v1)|null|
|**2024-07-23**|**Do LLMs Know When to NOT Answer? Investigating Abstention Abilities of Large Language Models**|Nishanth Madhusudhan et.al.|[2407.16221v1](http://arxiv.org/abs/2407.16221v1)|null|
|**2024-07-23**|**A Comprehensive Survey of LLM Alignment Techniques: RLHF, RLAIF, PPO, DPO and More**|Zhichao Wang et.al.|[2407.16216v1](http://arxiv.org/abs/2407.16216v1)|null|
|**2024-07-23**|**Graph-Structured Speculative Decoding**|Zhuocheng Gong et.al.|[2407.16207v1](http://arxiv.org/abs/2407.16207v1)|null|
|**2024-07-23**|**Figure it Out: Analyzing-based Jailbreak Attack on Large Language Models**|Shi Lin et.al.|[2407.16205v1](http://arxiv.org/abs/2407.16205v1)|null|
|**2024-07-23**|**MCTS Based Dispatch of Autonomous Vehicles under Operational Constraints for Continuous Transportation**|Milan Tomy et.al.|[2407.16200v1](http://arxiv.org/abs/2407.16200v1)|null|
|**2024-07-23**|**INF-LLaVA: Dual-perspective Perception for High-Resolution Multimodal Large Language Model**|Yiwei Ma et.al.|[2407.16198v1](http://arxiv.org/abs/2407.16198v1)|[link](https://github.com/weihuanglin/inf-llava)|
|**2024-07-23**|**How to Leverage Personal Textual Knowledge for Personalized Conversational Information Retrieval**|Fengran Mo et.al.|[2407.16192v1](http://arxiv.org/abs/2407.16192v1)|null|
|**2024-07-23**|**Artificial Agency and Large Language Models**|Maud Van Lier et.al.|[2407.16190v1](http://arxiv.org/abs/2407.16190v1)|null|
|**2024-07-23**|**Structural Optimization Ambiguity and Simplicity Bias in Unsupervised Neural Grammar Induction**|Jinwook Park et.al.|[2407.16181v1](http://arxiv.org/abs/2407.16181v1)|null|
|**2024-07-23**|**Pixel Embedding: Fully Quantized Convolutional Neural Network with Differentiable Lookup Table**|Hiroyuki Tokunaga et.al.|[2407.16174v1](http://arxiv.org/abs/2407.16174v1)|null|
|**2024-07-23**|**Learning Trimodal Relation for AVQA with Missing Modality**|Kyu Ri Park et.al.|[2407.16171v1](http://arxiv.org/abs/2407.16171v1)|[link](https://github.com/visualaikhu/missing-avqa)|
|**2024-07-23**|**Robust Privacy Amidst Innovation with Large Language Models Through a Critical Assessment of the Risks**|Yao-Shun Chuang et.al.|[2407.16166v1](http://arxiv.org/abs/2407.16166v1)|null|
|**2024-07-23**|**Representation Magnitude has a Liability to Privacy Vulnerability**|Xingli Fang et.al.|[2407.16164v1](http://arxiv.org/abs/2407.16164v1)|[link](https://github.com/jekimlab/aies2024_srcm)|
|**2024-07-23**|**UniMEL: A Unified Framework for Multimodal Entity Linking with Large Language Models**|Liu Qi et.al.|[2407.16160v1](http://arxiv.org/abs/2407.16160v1)|null|
|**2024-07-23**|**DDK: Distilling Domain Knowledge for Efficient Large Language Models**|Jiaheng Liu et.al.|[2407.16154v1](http://arxiv.org/abs/2407.16154v1)|null|
|**2024-07-23**|**Predicting Stock Prices with FinBERT-LSTM: Integrating News Sentiment Analysis**|Wenjun Gu et.al.|[2407.16150v1](http://arxiv.org/abs/2407.16150v1)|null|
|**2024-07-23**|**CHIME: LLM-Assisted Hierarchical Organization of Scientific Studies for Literature Review Support**|Chao-Chun Hsu et.al.|[2407.16148v1](http://arxiv.org/abs/2407.16148v1)|null|
|**2024-07-23**|**Diffusion Models as Optimizers for Efficient Planning in Offline RL**|Renming Huang et.al.|[2407.16142v1](http://arxiv.org/abs/2407.16142v1)|[link](https://github.com/renming-huang/trajectorydiffuser)|
|**2024-07-23**|**FoRA: Low-Rank Adaptation Model beyond Multimodal Siamese Network**|Weiying Xie et.al.|[2407.16129v1](http://arxiv.org/abs/2407.16129v1)|[link](https://github.com/zyszxhy/fora)|
|**2024-07-23**|**Advancing Brain Imaging Analysis Step-by-step via Progressive Self-paced Learning**|Yanwu Yang et.al.|[2407.16128v1](http://arxiv.org/abs/2407.16128v1)|[link](https://github.com/hrychen7/pspd)|
|**2024-07-23**|**Finetuning Generative Large Language Models with Discrimination Instructions for Knowledge Graph Completion**|Yang Liu et.al.|[2407.16127v1](http://arxiv.org/abs/2407.16127v1)|[link](https://github.com/nju-websoft/dift)|
|**2024-07-23**|**Uncertainty-Aware Deep Neural Representations for Visual Analysis of Vector Field Data**|Atul Kumar et.al.|[2407.16119v1](http://arxiv.org/abs/2407.16119v1)|null|
|**2024-07-23**|**Transformer-based Graph Neural Networks for Battery Range Prediction in AIoT Battery-Swap Services**|Zhao Li et.al.|[2407.16115v1](http://arxiv.org/abs/2407.16115v1)|null|
|**2024-07-22**|**Modelling brain connectomes networks: Solv is a worthy competitor to hyperbolic geometry!**|Dorota Celińska-Kopczyńska et.al.|[2407.16077v1](http://arxiv.org/abs/2407.16077v1)|null|
|**2024-07-22**|**KaPQA: Knowledge-Augmented Product Question-Answering**|Swetha Eppalapally et.al.|[2407.16073v1](http://arxiv.org/abs/2407.16073v1)|null|
|**2024-07-22**|**LCA-on-the-Line: Benchmarking Out-of-Distribution Generalization with Class Taxonomies**|Jia Shi et.al.|[2407.16067v1](http://arxiv.org/abs/2407.16067v1)|null|
|**2024-07-22**|**Leveraging Large Language Models to Geolocate Linguistic Variations in Social Media Posts**|Davide Savarro et.al.|[2407.16047v1](http://arxiv.org/abs/2407.16047v1)|[link](https://github.com/dawoz/geolingit-biss2024)|
|**2024-07-22**|**Generalizing Teacher Networks for Effective Knowledge Distillation Across Student Architectures**|Kuluhan Binici et.al.|[2407.16040v1](http://arxiv.org/abs/2407.16040v1)|null|
|**2024-07-22**|**Enhancing Temporal Understanding in LLMs for Semi-structured Tables**|Irwin Deng et.al.|[2407.16030v1](http://arxiv.org/abs/2407.16030v1)|null|
|**2024-07-22**|**KWT-Tiny: RISC-V Accelerated, Embedded Keyword Spotting Transformer**|Aness Al-Qawlaq et.al.|[2407.16026v1](http://arxiv.org/abs/2407.16026v1)|null|
|**2024-07-22**|**Exploring and Addressing Reward Confusion in Offline Preference Learning**|Xin Chen et.al.|[2407.16025v1](http://arxiv.org/abs/2407.16025v1)|null|
|**2024-07-22**|**AIDE: Antithetical, Intent-based, and Diverse Example-Based Explanations**|Ikhtiyor Nematov et.al.|[2407.16010v1](http://arxiv.org/abs/2407.16010v1)|null|
|**2024-07-22**|**Boosting Reward Model with Preference-Conditional Multi-Aspect Synthetic Data Generation**|Jiaming Shen et.al.|[2407.16008v1](http://arxiv.org/abs/2407.16008v1)|null|
|**2024-07-22**|**SocialQuotes: Learning Contextual Roles of Social Media Quotes on the Web**|John Palowitch et.al.|[2407.16007v1](http://arxiv.org/abs/2407.16007v1)|null|
|**2024-07-22**|**Multimodal Input Aids a Bayesian Model of Phonetic Learning**|Sophia Zhi et.al.|[2407.15992v1](http://arxiv.org/abs/2407.15992v1)|null|
|**2024-07-22**|**AI for Handball: predicting and explaining the 2024 Olympic Games tournament with Deep Learning and Large Language Models**|Florian Felice et.al.|[2407.15987v1](http://arxiv.org/abs/2407.15987v1)|null|
|**2024-07-22**|**Multilingual Fine-Grained News Headline Hallucination Detection**|Jiaming Shen et.al.|[2407.15975v1](http://arxiv.org/abs/2407.15975v1)|null|
|**2024-07-22**|**LLMmap: Fingerprinting For Large Language Models**|Dario Pasquini et.al.|[2407.15847v1](http://arxiv.org/abs/2407.15847v1)|null|
|**2024-07-22**|**Reconstructing Training Data From Real World Models Trained with Transfer Learning**|Yakir Oz et.al.|[2407.15845v1](http://arxiv.org/abs/2407.15845v1)|null|
|**2024-07-22**|**CarFormer: Self-Driving with Learned Object-Centric Representations**|Shadi Hamdan et.al.|[2407.15843v1](http://arxiv.org/abs/2407.15843v1)|null|
|**2024-07-22**|**Importance Sampling-Guided Meta-Training for Intelligent Agents in Highly Interactive Environments**|Mansur Arief et.al.|[2407.15839v1](http://arxiv.org/abs/2407.15839v1)|null|
|**2024-07-22**|**Towards Latent Masked Image Modeling for Self-Supervised Visual Representation Learning**|Yibing Wei et.al.|[2407.15837v1](http://arxiv.org/abs/2407.15837v1)|[link](https://github.com/yibingwei-1/latentmim)|
|**2024-07-22**|**dMel: Speech Tokenization made Simple**|He Bai et.al.|[2407.15835v1](http://arxiv.org/abs/2407.15835v1)|null|

#### Abstracts
##### **Stress-Testing Long-Context Language Models with Lifelong ICL and Task Haystack**
2407.16695v1 by Xiaoyue Xu, Qinyuan Ye, Xiang Ren

We introduce Lifelong ICL, a problem setting that challenges long-context
language models (LMs) to learn from a sequence of language tasks through
in-context learning (ICL). We further introduce Task Haystack, an evaluation
suite dedicated to assessing and diagnosing how long-context LMs utilizes
contexts in Lifelong ICL. When given a task instruction and test inputs,
long-context LMs are expected to leverage the relevant demonstrations in the
Lifelong ICL prompt, avoid distraction and interference from other tasks, and
achieve test accuracies that are not significantly worse than the Single-task
ICL baseline.
  Task Haystack draws inspiration from the widely-adopted
"needle-in-a-haystack" (NIAH) evaluation, but presents new and unique
challenges. It demands that models (1) utilize the contexts with deeper
understanding, rather than resorting to simple copying and pasting; (2)
navigate through long streams of evolving topics and tasks, which closely
approximates the complexities of real-world usage of long-context LMs.
Additionally, Task Haystack inherits the controllability aspect of NIAH,
providing model developers with tools and visualizations to identify model
vulnerabilities effectively.
  We benchmark 12 long-context LMs using Task Haystack. We find that
state-of-the-art closed models such as GPT-4o still struggle in this setting,
failing 15% of the cases on average, while all open-weight models we evaluate
further lack behind by a large margin, failing up to 61% of the cases. In our
controlled analysis, we identify factors such as distraction and recency bias
as contributors to these failure cases. Further, we observe declines in
performance when task instructions are paraphrased at test time or when ICL
demonstrations are repeated excessively, raising concerns about the robustness,
instruction understanding, and true context utilization of current long-context
LMs.

摘要：<paragraph>我們引入了終身 ICL，這是一個挑戰問題設置，讓長期語境語言模型 (LM) 能夠透過語境學習 (ICL) 從一系列語言任務中學習。我們進一步引入了任務乾草堆，這是一個評估套件，專門用於評估和診斷長期語境 LM 如何在終身 ICL 中使用語境。當給定任務說明和測試輸入時，預期長期語境 LM 將利用終身 ICL 提示中的相關示範，避免其他任務的干擾和干擾，並達到與單任務 ICL 基準線相差不大的測試準確度。
任務乾草堆從廣泛採用的「大海撈針」(NIAH) 評估中汲取靈感，但提出了新的獨特挑戰。它要求模型 (1) 以更深入的理解利用語境，而不是訴諸於簡單的複製和貼上；(2) 瀏覽不斷變化的主題和任務的長串流，這與長期語境 LM 在現實世界中的使用複雜性非常接近。此外，任務乾草堆繼承了 NIAH 的可控性方面，為模型開發人員提供了工具和可視化效果，以有效識別模型漏洞。
我們使用任務乾草堆對 12 個長期語境 LM 進行基準測試。我們發現，GPT-4o 等最先進的封閉模型在此設置中仍然舉步維艱，平均有 15% 的案例失敗，而我們評估的所有開放權重模型進一步落後一大截，有高達 61% 的案例失敗。在我們的受控分析中，我們將分心和近期偏誤等因素確定為這些失敗案例的成因。此外，我們觀察到，當任務說明在測試時被改寫，或當 ICL 示範被過度重複時，性能會下降，這引起了人們對當前長期語境 LM 的健壯性、指令理解和真實語境利用的擔憂。</paragraph>

##### **Explanation Regularisation through the Lens of Attributions**
2407.16693v1 by Pedro Ferreira, Wilker Aziz, Ivan Titov

Explanation regularisation (ER) has been introduced as a way to guide models
to make their predictions in a manner more akin to humans, i.e., making their
attributions "plausible". This is achieved by introducing an auxiliary
explanation loss, that measures how well the output of an input attribution
technique for the model agrees with relevant human-annotated rationales. One
positive outcome of using ER appears to be improved performance in
out-of-domain (OOD) settings, presumably due to an increased reliance on
"plausible" tokens. However, previous work has under-explored the impact of the
ER objective on model attributions, in particular when obtained with techniques
other than the one used to train ER. In this work, we contribute a study of
ER's effectiveness at informing classification decisions on plausible tokens,
and the relationship between increased plausibility and robustness to OOD
conditions. Through a series of analyses, we find that the connection between
ER and the ability of a classifier to rely on plausible features has been
overstated and that a stronger reliance on plausible tokens does not seem to be
the cause for any perceived OOD improvements.

摘要：說明規範化（ER）被引入作為引導模型以更類似人類的方式做出預測的方法，即讓模型的歸因「合理」。這透過引入輔助說明損失來達成，該損失衡量模型的輸入歸因技術的輸出與相關的人工標記依據吻合程度。使用 ER 的一個正面結果似乎是在領域外（OOD）設定中改善效能，這可能是由於更依賴於「合理」的標記。然而，先前的工作並未充分探討 ER 目標對模型歸因的影響，特別是在使用與訓練 ER 不同的技術取得歸因時。在這項工作中，我們貢獻了一項研究，探討 ER 在根據合理標記做出分類決策方面的有效性，以及增加合理性與對 OOD 條件的穩健性之間的關係。透過一系列的分析，我們發現 ER 與分類器依賴合理特徵的能力之間的關聯被誇大了，而且更依賴合理的標記似乎並非任何感知到的 OOD 改進的原因。

##### **Can Large Language Models Automatically Jailbreak GPT-4V?**
2407.16686v1 by Yuanwei Wu, Yue Huang, Yixin Liu, Xiang Li, Pan Zhou, Lichao Sun

GPT-4V has attracted considerable attention due to its extraordinary capacity
for integrating and processing multimodal information. At the same time, its
ability of face recognition raises new safety concerns of privacy leakage.
Despite researchers' efforts in safety alignment through RLHF or preprocessing
filters, vulnerabilities might still be exploited. In our study, we introduce
AutoJailbreak, an innovative automatic jailbreak technique inspired by prompt
optimization. We leverage Large Language Models (LLMs) for red-teaming to
refine the jailbreak prompt and employ weak-to-strong in-context learning
prompts to boost efficiency. Furthermore, we present an effective search method
that incorporates early stopping to minimize optimization time and token
expenditure. Our experiments demonstrate that AutoJailbreak significantly
surpasses conventional methods, achieving an Attack Success Rate (ASR)
exceeding 95.3\%. This research sheds light on strengthening GPT-4V security,
underscoring the potential for LLMs to be exploited in compromising GPT-4V
integrity.

摘要：GPT-4V 因其整合和處理多模態資訊的非凡能力而備受關注。同時，其人臉識別能力也引發了新的隱私洩露安全問題。儘管研究人員透過 RLHF 或預處理過濾器在安全調整方面做出了努力，但漏洞仍可能被利用。在我們的研究中，我們引入了 AutoJailbreak，這是一種創新的自動越獄技術，靈感來自提示最佳化。我們利用大型語言模型 (LLM) 進行紅隊演練，以優化越獄提示，並使用弱到強的上下文學習提示來提高效率。此外，我們提出了一種有效的方法，結合了早期停止以最小化最佳化時間和符號支出。我們的實驗表明，AutoJailbreak 明顯優於傳統方法，攻擊成功率 (ASR) 超過 95.3%。這項研究有助於加強 GPT-4V 安全性，強調了 LLM 在破壞 GPT-4V 完整性方面被利用的潛力。

##### **KAN or MLP: A Fairer Comparison**
2407.16674v1 by Runpeng Yu, Weihao Yu, Xinchao Wang

This paper does not introduce a novel method. Instead, it offers a fairer and
more comprehensive comparison of KAN and MLP models across various tasks,
including machine learning, computer vision, audio processing, natural language
processing, and symbolic formula representation. Specifically, we control the
number of parameters and FLOPs to compare the performance of KAN and MLP. Our
main observation is that, except for symbolic formula representation tasks, MLP
generally outperforms KAN. We also conduct ablation studies on KAN and find
that its advantage in symbolic formula representation mainly stems from its
B-spline activation function. When B-spline is applied to MLP, performance in
symbolic formula representation significantly improves, surpassing or matching
that of KAN. However, in other tasks where MLP already excels over KAN,
B-spline does not substantially enhance MLP's performance. Furthermore, we find
that KAN's forgetting issue is more severe than that of MLP in a standard
class-incremental continual learning setting, which differs from the findings
reported in the KAN paper. We hope these results provide insights for future
research on KAN and other MLP alternatives. Project link:
https://github.com/yu-rp/KANbeFair

摘要：本文并未引入新方法。相反，它对 KAN 和 MLP 模型在各个任务中的表现进行了更公平、更全面的比较，包括机器学习、计算机视觉、音频处理、自然语言处理和符号公式表示。具体来说，我们控制参数和 FLOP 的数量来比较 KAN 和 MLP 的性能。我们的主要观察结果是，除了符号公式表示任务之外，MLP 通常优于 KAN。我们还对 KAN 进行了消融研究，发现其在符号公式表示中的优势主要源于其 B 样条激活函数。当 B 样条应用于 MLP 时，符号公式表示的性能显着提高，超过或匹配 KAN。然而，在 MLP 已经优于 KAN 的其他任务中，B 样条并没有实质性地提高 MLP 的性能。此外，我们发现 KAN 的遗忘问题比 MLP 在标准类增量持续学习设置中更严重，这与 KAN 论文中报告的发现不同。我们希望这些结果为未来对 KAN 和其他 MLP 替代方案的研究提供见解。项目链接：https://github.com/yu-rp/KANbeFair

##### **RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent**
2407.16667v1 by Huiyu Xu, Wenhui Zhang, Zhibo Wang, Feng Xiao, Rui Zheng, Yunhe Feng, Zhongjie Ba, Kui Ren

Recently, advanced Large Language Models (LLMs) such as GPT-4 have been
integrated into many real-world applications like Code Copilot. These
applications have significantly expanded the attack surface of LLMs, exposing
them to a variety of threats. Among them, jailbreak attacks that induce toxic
responses through jailbreak prompts have raised critical safety concerns. To
identify these threats, a growing number of red teaming approaches simulate
potential adversarial scenarios by crafting jailbreak prompts to test the
target LLM. However, existing red teaming methods do not consider the unique
vulnerabilities of LLM in different scenarios, making it difficult to adjust
the jailbreak prompts to find context-specific vulnerabilities. Meanwhile,
these methods are limited to refining jailbreak templates using a few mutation
operations, lacking the automation and scalability to adapt to different
scenarios. To enable context-aware and efficient red teaming, we abstract and
model existing attacks into a coherent concept called "jailbreak strategy" and
propose a multi-agent LLM system named RedAgent that leverages these strategies
to generate context-aware jailbreak prompts. By self-reflecting on contextual
feedback in an additional memory buffer, RedAgent continuously learns how to
leverage these strategies to achieve effective jailbreaks in specific contexts.
Extensive experiments demonstrate that our system can jailbreak most black-box
LLMs in just five queries, improving the efficiency of existing red teaming
methods by two times. Additionally, RedAgent can jailbreak customized LLM
applications more efficiently. By generating context-aware jailbreak prompts
towards applications on GPTs, we discover 60 severe vulnerabilities of these
real-world applications with only two queries per vulnerability. We have
reported all found issues and communicated with OpenAI and Meta for bug fixes.

摘要：<paragraph>最近，先进的大语言模型（LLM），例如 GPT-4，已整合到许多实际应用中，例如 Code Copilot。这些应用显著扩大了 LLM 的攻击面，使它们面临各种威胁。其中，通过越狱提示诱发有害反应的越狱攻击引发了关键的安全问题。为了识别这些威胁，越来越多的红队方法通过精心制作越狱提示来模拟潜在的对抗场景，以测试目标 LLM。然而，现有的红队方法并未考虑 LLM 在不同场景中的独特漏洞，这使得难以调整越狱提示来查找特定于上下文的漏洞。同时，这些方法仅限于使用少数变异操作来优化越狱模板，缺乏适应不同场景的自动化和可扩展性。为了实现上下文感知和高效的红队，我们将现有的攻击抽象并建模为一个连贯的概念，称为“越狱策略”，并提出一个名为 RedAgent 的多代理 LLM 系统，该系统利用这些策略来生成上下文感知的越狱提示。通过在附加的内存缓冲区中自省上下文反馈，RedAgent 持续学习如何利用这些策略在特定上下文中实现有效的越狱。广泛的实验表明，我们的系统仅在五次查询中就能越狱大多数黑盒 LLM，从而将现有红队方法的效率提高了两倍。此外，RedAgent 可以更有效地越狱定制的 LLM 应用程序。通过针对 GPT 上的应用程序生成上下文感知的越狱提示，我们仅通过每个漏洞两次查询就发现了这些实际应用程序的 60 个严重漏洞。我们已报告所有发现的问题，并与 OpenAI 和 Meta 沟通以修复错误。</paragraph>

##### **Towards scalable efficient on-device ASR with transfer learning**
2407.16664v1 by Laxmi Pandey, Ke Li, Jinxi Guo, Debjyoti Paul, Arthur Guo, Jay Mahadeokar, Xuedong Zhang

Multilingual pretraining for transfer learning significantly boosts the
robustness of low-resource monolingual ASR models. This study systematically
investigates three main aspects: (a) the impact of transfer learning on model
performance during initial training or fine-tuning, (b) the influence of
transfer learning across dataset domains and languages, and (c) the effect on
rare-word recognition compared to non-rare words. Our finding suggests that
RNNT-loss pretraining, followed by monolingual fine-tuning with Minimum Word
Error Rate (MinWER) loss, consistently reduces Word Error Rates (WER) across
languages like Italian and French. WER Reductions (WERR) reach 36.2% and 42.8%
compared to monolingual baselines for MLS and in-house datasets. Out-of-domain
pretraining leads to 28% higher WERR than in-domain pretraining. Both rare and
non-rare words benefit, with rare words showing greater improvements with
out-of-domain pretraining, and non-rare words with in-domain pretraining.

摘要：多語言預訓練用於遷移學習，可顯著提升低資源單語 ASR 模型的穩健性。本研究系統性地探討了三個主要面向：(a) 遷移學習對模型效能的影響，無論是在初始訓練或微調期間，(b) 遷移學習對資料集網域和語言的影響，以及 (c) 對罕見字辨識與非罕見字辨識的影響。我們的發現顯示，RNNT 損失預訓練，接著進行使用最小字元錯誤率 (MinWER) 損失的單語微調，會持續降低義大利語和法語等語言的字元錯誤率 (WER)。與 MLS 和內部資料集的單語基線相比，WER 降低幅度 (WERR) 達到 36.2% 和 42.8%。領域外預訓練導致 WERR 比領域內預訓練高出 28%。罕見字和非罕見字均受惠，罕見字在領域外預訓練中表現出較大的進步，而非罕見字則在領域內預訓練中表現出較大的進步。

##### **Course-Correction: Safety Alignment Using Synthetic Preferences**
2407.16637v1 by Rongwu Xu, Yishuo Cai, Zhenhong Zhou, Renjie Gu, Haiqin Weng, Yan Liu, Tianwei Zhang, Wei Xu, Han Qiu

The risk of harmful content generated by large language models (LLMs) becomes
a critical concern. This paper presents a systematic study on assessing and
improving LLMs' capability to perform the task of \textbf{course-correction},
\ie, the model can steer away from generating harmful content autonomously. To
start with, we introduce the \textsc{C$^2$-Eval} benchmark for quantitative
assessment and analyze 10 popular LLMs, revealing varying proficiency of
current safety-tuned LLMs in course-correction. To improve, we propose
fine-tuning LLMs with preference learning, emphasizing the preference for
timely course-correction. Using an automated pipeline, we create
\textsc{C$^2$-Syn}, a synthetic dataset with 750K pairwise preferences, to
teach models the concept of timely course-correction through data-driven
preference learning. Experiments on 2 LLMs, \textsc{Llama2-Chat 7B} and
\textsc{Qwen2 7B}, show that our method effectively enhances course-correction
skills without affecting general performance. Additionally, it effectively
improves LLMs' safety, particularly in resisting jailbreak attacks.

摘要：大型语言模型 (LLM) 产生的有害内容风险已成为一个关键问题。本文对评估和改进 LLM 执行“路径校正”任务的能力进行了系统性研究，即模型可以自主地避免生成有害内容。首先，我们引入了用于定量评估的 \textsc{C$^2$-Eval} 基准，并分析了 10 个流行的 LLM，揭示了当前安全调整的 LLM 在路径校正方面的熟练程度各不相同。为了改进，我们建议使用偏好学习对 LLM 进行微调，强调及时路径校正的偏好。我们使用自动化管道创建了 \textsc{C$^2$-Syn}，这是一个包含 750K 对偏好的合成数据集，以通过数据驱动的偏好学习向模型传授及时路径校正的概念。对 2 个 LLM（\textsc{Llama2-Chat 7B} 和 \textsc{Qwen2 7B}）的实验表明，我们的方法有效地增强了路径校正技能，而不会影响一般性能。此外，它有效地提高了 LLM 的安全性，尤其是在抵御越狱攻击方面。

##### **Knowledge-driven AI-generated data for accurate and interpretable breast ultrasound diagnoses**
2407.16634v1 by Haojun Yu, Youcheng Li, Nan Zhang, Zihan Niu, Xuantong Gong, Yanwen Luo, Quanlin Wu, Wangyan Qin, Mengyuan Zhou, Jie Han, Jia Tao, Ziwei Zhao, Di Dai, Di He, Dong Wang, Binghui Tang, Ling Huo, Qingli Zhu, Yong Wang, Liwei Wang

Data-driven deep learning models have shown great capabilities to assist
radiologists in breast ultrasound (US) diagnoses. However, their effectiveness
is limited by the long-tail distribution of training data, which leads to
inaccuracies in rare cases. In this study, we address a long-standing challenge
of improving the diagnostic model performance on rare cases using long-tailed
data. Specifically, we introduce a pipeline, TAILOR, that builds a
knowledge-driven generative model to produce tailored synthetic data. The
generative model, using 3,749 lesions as source data, can generate millions of
breast-US images, especially for error-prone rare cases. The generated data can
be further used to build a diagnostic model for accurate and interpretable
diagnoses. In the prospective external evaluation, our diagnostic model
outperforms the average performance of nine radiologists by 33.5% in
specificity with the same sensitivity, improving their performance by providing
predictions with an interpretable decision-making process. Moreover, on ductal
carcinoma in situ (DCIS), our diagnostic model outperforms all radiologists by
a large margin, with only 34 DCIS lesions in the source data. We believe that
TAILOR can potentially be extended to various diseases and imaging modalities.

摘要：資料驅動的深度學習模型已展現出極佳的能力，協助放射科醫師進行乳房超音波 (US) 診斷。然而，其有效性受到訓練資料長尾分佈的限制，導致在罕見案例中出現不準確的情況。在本研究中，我們解決了使用長尾資料改善罕見案例診斷模型效能的長期挑戰。具體來說，我們引入了一條名為 TAILOR 的管線，它建立了一個知識驅動的生成模型來產生客製化的合成資料。生成模型使用 3,749 個病灶作為原始資料，可以產生數百萬個乳房超音波影像，特別是針對容易出錯的罕見案例。產生的資料可進一步用於建立診斷模型，以進行準確且可解釋的診斷。在預測外部評估中，我們的診斷模型在特異性方面以相同的敏感性優於九位放射科醫師的平均表現 33.5%，透過提供具有可解釋決策過程的預測來提升他們的表現。此外，在原位導管癌 (DCIS) 中，我們的診斷模型以極大的幅度優於所有放射科醫師，而原始資料中只有 34 個 DCIS 病灶。我們相信 TAILOR 潛在可擴充至各種疾病和影像模式。

##### **Semantic Change Characterization with LLMs using Rhetorics**
2407.16624v1 by Jader Martins Camboim de Sá, Marcos Da Silveira, Cédric Pruski

Languages continually evolve in response to societal events, resulting in new
terms and shifts in meanings. These changes have significant implications for
computer applications, including automatic translation and chatbots, making it
essential to characterize them accurately. The recent development of LLMs has
notably advanced natural language understanding, particularly in sense
inference and reasoning. In this paper, we investigate the potential of LLMs in
characterizing three types of semantic change: dimension, relation, and
orientation. We achieve this by combining LLMs' Chain-of-Thought with
rhetorical devices and conducting an experimental assessment of our approach
using newly created datasets. Our results highlight the effectiveness of LLMs
in capturing and analyzing semantic changes, providing valuable insights to
improve computational linguistic applications.

摘要：語言會持續隨著社會事件而演變，產生新詞彙和意義轉換。這些變化對電腦應用程式有重大的影響，包括自動翻譯和聊天機器人，因此精確地描述它們至關重要。大型語言模型 (LLM) 的最新發展顯著提升了自然語言理解，特別是在意義推論和推理方面。在本文中，我們探討了 LLM 在描述三種類型的語義變化（維度、關係和方向）方面的潛力。我們透過結合 LLM 的思考鏈、修辭裝置，並使用新建立的資料集對我們的做法進行實驗評估來達成這項任務。我們的結果突顯了 LLM 在捕捉和分析語義變化方面的效能，為改進計算語言應用程式提供了寶貴的見解。

##### **Lawma: The Power of Specialization for Legal Tasks**
2407.16615v1 by Ricardo Dominguez-Olmedo, Vedant Nanda, Rediet Abebe, Stefan Bechtold, Christoph Engel, Jens Frankenreiter, Krishna Gummadi, Moritz Hardt, Michael Livermore

Annotation and classification of legal text are central components of
empirical legal research. Traditionally, these tasks are often delegated to
trained research assistants. Motivated by the advances in language modeling,
empirical legal scholars are increasingly turning to prompting commercial
models, hoping that it will alleviate the significant cost of human annotation.
Despite growing use, our understanding of how to best utilize large language
models for legal tasks remains limited. We conduct a comprehensive study of 260
legal text classification tasks, nearly all new to the machine learning
community. Starting from GPT-4 as a baseline, we show that it has non-trivial
but highly varied zero-shot accuracy, often exhibiting performance that may be
insufficient for legal work. We then demonstrate that a lightly fine-tuned
Llama 3 model vastly outperforms GPT-4 on almost all tasks, typically by
double-digit percentage points. We find that larger models respond better to
fine-tuning than smaller models. A few tens to hundreds of examples suffice to
achieve high classification accuracy. Notably, we can fine-tune a single model
on all 260 tasks simultaneously at a small loss in accuracy relative to having
a separate model for each task. Our work points to a viable alternative to the
predominant practice of prompting commercial models. For concrete legal tasks
with some available labeled data, researchers are better off using a fine-tuned
open-source model.

摘要：法律文本的註解和分類是實證法律研究的核心組成部分。傳統上，這些任務通常委派給受過訓練的研究助理。在語言模型進步的推動下，實證法律學者正日益求助於提示商業模型，希望這將減輕人工註解的顯著成本。儘管使用日益廣泛，我們對如何最佳利用大型語言模型來執行法律任務的理解仍然有限。我們對 260 項法律文本分類任務進行了一項全面研究，其中幾乎所有任務對機器學習社群來說都是新的。從 GPT-4 作為基準開始，我們表明它具有非平凡但變化極大的零次學習準確度，通常表現出的效能可能不足以應付法律工作。然後我們展示了一個經過微調的 Llama 3 模型在幾乎所有任務上都大大優於 GPT-4，通常高出兩位數個百分點。我們發現，與較小的模型相比，較大的模型對微調的反應更好。幾十到幾百個範例就足以達到很高的分類準確度。值得注意的是，我們可以同時對所有 260 項任務微調單一模型，而準確度損失很小，相較於為每個任務使用單獨的模型。我們的研究指出了一個可行的替代方案，以取代提示商業模型的普遍做法。對於具有一些可用標記資料的具體法律任務，研究人員最好使用經過微調的開源模型。

##### **No-brainer: Morphological Computation driven Adaptive Behavior in Soft Robots**
2407.16613v1 by Alican Mertan, Nick Cheney

It is prevalent in contemporary AI and robotics to separately postulate a
brain modeled by neural networks and employ it to learn intelligent and
adaptive behavior. While this method has worked very well for many types of
tasks, it isn't the only type of intelligence that exists in nature. In this
work, we study the ways in which intelligent behavior can be created without a
separate and explicit brain for robot control, but rather solely as a result of
the computation occurring within the physical body of a robot. Specifically, we
show that adaptive and complex behavior can be created in voxel-based virtual
soft robots by using simple reactive materials that actively change the shape
of the robot, and thus its behavior, under different environmental cues. We
demonstrate a proof of concept for the idea of closed-loop morphological
computation, and show that in our implementation, it enables behavior mimicking
logic gates, enabling us to demonstrate how such behaviors may be combined to
build up more complex collective behaviors.

摘要：在當代的人工智慧與機器人領域中，普遍的做法是分別假設一個由神經網路建模的大腦，並使用它來學習智慧且適應性的行為。雖然這種方法在許多類型的任務中運作良好，但它並非自然界中存在的唯一智慧類型。在本研究中，我們探討了在沒有機器人控制的獨立且明確大腦的情況下，智慧行為可以如何被創造出來，而僅僅是機器人實體內部運算的結果。具體來說，我們展示了適應性和複雜的行為可以在基於體素的虛擬軟機器人中被創造出來，方法是使用簡單的反應材料，這些材料會積極改變機器人的形狀，並因此在不同的環境提示下改變其行為。我們展示了一個封閉迴路形態運算概念的驗證，並展示在我們的實作中，它能讓行為模擬邏輯閘，使我們能夠展示如何將這些行為組合起來，以建立更複雜的集體行為。

##### **Local vs Global continual learning**
2407.16611v1 by Giulia Lanzillotta, Sidak Pal Singh, Benjamin F. Grewe, Thomas Hofmann

Continual learning is the problem of integrating new information in a model
while retaining the knowledge acquired in the past. Despite the tangible
improvements achieved in recent years, the problem of continual learning is
still an open one. A better understanding of the mechanisms behind the
successes and failures of existing continual learning algorithms can unlock the
development of new successful strategies. In this work, we view continual
learning from the perspective of the multi-task loss approximation, and we
compare two alternative strategies, namely local and global approximations. We
classify existing continual learning algorithms based on the approximation
used, and we assess the practical effects of this distinction in common
continual learning settings.Additionally, we study optimal continual learning
objectives in the case of local polynomial approximations and we provide
examples of existing algorithms implementing the optimal objectives

摘要：持續學習是整合模型中新資訊的問題，同時保留過去獲得的知識。儘管近年來取得了顯著的進展，但持續學習的問題仍然是一個開放的問題。對現有持續學習演算法成功與失敗背後機制的更深入了解，可以開啟新的成功策略的發展。在這項工作中，我們從多任務損失近似的角度來看持續學習，並比較了兩種替代策略，即局部和全局近似。我們根據所使用的近似對現有的持續學習演算法進行分類，並評估了這種區別在常見持續學習設定中的實際效果。此外，我們研究了局部多項式近似情況下的最佳持續學習目標，並提供了實作最佳目標的現有演算法範例

##### **Deep Bayesian segmentation for colon polyps: Well-calibrated predictions in medical imaging**
2407.16608v1 by Daniela L. Ramos, Hector J. Hortua

Colorectal polyps are generally benign alterations that, if not identified
promptly and managed successfully, can progress to cancer and cause
affectations on the colon mucosa, known as adenocarcinoma. Today advances in
Deep Learning have demonstrated the ability to achieve significant performance
in image classification and detection in medical diagnosis applications.
Nevertheless, these models are prone to overfitting, and making decisions based
only on point estimations may provide incorrect predictions. Thus, to obtain a
more informed decision, we must consider point estimations along with their
reliable uncertainty quantification. In this paper, we built different Bayesian
neural network approaches based on the flexibility of posterior distribution to
develop semantic segmentation of colorectal polyp images. We found that these
models not only provide state-of-the-art performance on the segmentation of
this medical dataset but also, yield accurate uncertainty estimates. We applied
multiplicative normalized flows(MNF) and reparameterization trick on the UNET,
FPN, and LINKNET architectures tested with multiple backbones in deterministic
and Bayesian versions. We report that the FPN + EfficientnetB7 architecture
with MNF is the most promising option given its IOU of 0.94 and Expected
Calibration Error (ECE) of 0.004, combined with its superiority in identifying
difficult-to-detect colorectal polyps, which is effective in clinical areas
where early detection prevents the development of colon cancer.

摘要：大腸息肉通常是良性病變，如果不及時發現並成功處理，可能會演變成癌症並導致大腸粘膜受累，即腺癌。如今，深度學習的進展已證明有能力在醫療診斷應用中實現圖像分類和檢測的顯著性能。儘管如此，這些模型容易過度擬合，並且僅基於點估計做出決策可能會提供不正確的預測。因此，為了獲得更明智的決策，我們必須考慮點估計及其可靠的不確定性量化。在本文中，我們基於後驗分佈的靈活性構建了不同的貝葉斯神經網絡方法，以開發大腸息肉圖像的語義分割。我們發現這些模型不僅在這個醫療數據集的分割上提供了最先進的性能，而且還產生了準確的不確定性估計。我們在確定性和貝葉斯版本中使用多個主幹測試的 UNET、FPN 和 LINKNET 架構上應用乘法歸一化流 (MNF) 和重新參數化技巧。我們報告說，具有 MNF 的 FPN + EfficientnetB7 架構是最有希望的選擇，因為它的 IOU 為 0.94，預期的校準誤差 (ECE) 為 0.004，並且在識別難以檢測的大腸息肉方面具有優越性，這在早期檢測可以防止結腸癌發展的臨床領域是有效的。

##### **Data Mixture Inference: What do BPE Tokenizers Reveal about their Training Data?**
2407.16607v1 by Jonathan Hayase, Alisa Liu, Yejin Choi, Sewoong Oh, Noah A. Smith

The pretraining data of today's strongest language models is opaque. In
particular, little is known about the proportions of various domains or
languages represented. In this work, we tackle a task which we call data
mixture inference, which aims to uncover the distributional make-up of training
data. We introduce a novel attack based on a previously overlooked source of
information -- byte-pair encoding (BPE) tokenizers, used by the vast majority
of modern language models. Our key insight is that the ordered list of merge
rules learned by a BPE tokenizer naturally reveals information about the token
frequencies in its training data: the first merge is the most common byte pair,
the second is the most common pair after merging the first token, and so on.
Given a tokenizer's merge list along with data samples for each category of
interest, we formulate a linear program that solves for the proportion of each
category in the tokenizer's training set. Importantly, to the extent to which
tokenizer training data is representative of the pretraining data, we
indirectly learn about the pretraining data. In controlled experiments, we show
that our attack recovers mixture ratios with high precision for tokenizers
trained on known mixtures of natural languages, programming languages, and data
sources. We then apply our approach to off-the-shelf tokenizers released with
recent LMs. We confirm much publicly disclosed information about these models,
and also make several new inferences: GPT-4o's tokenizer is much more
multilingual than its predecessors, training on 39% non-English data; Llama3
extends GPT-3.5's tokenizer primarily for multilingual (48%) use; GPT-3.5's and
Claude's tokenizers are trained on predominantly code (~60%). We hope our work
sheds light on current design practices for pretraining data, and inspires
continued research into data mixture inference for LMs.

摘要：<paragraph>當前最強大的語言模型的預訓練數據是模糊不清的。特別是，對於各種領域或語言所占比例的了解甚少。在這項工作中，我們處理了一項稱為數據混合推論的任務，旨在揭示訓練數據的分布式組成。我們引入了一種新穎的攻擊方法，該方法基於一個以前被忽視的信息來源——字節對編碼 (BPE) 分詞器，它被絕大多數現代語言模型使用。我們的關鍵見解是，BPE 分詞器學習到的合併規則的有序列表自然地揭示了其訓練數據中詞頻的信息：第一次合併是最常見的字節對，第二次合併是最常見的對，依此類推。給定分詞器的合併列表以及每個感興趣類別的數據樣本，我們制定了一個線性規劃，用於求解分詞器訓練集中每個類別的比例。重要的是，在分詞器訓練數據代表預訓練數據的範圍內，我們間接了解了預訓練數據。在受控實驗中，我們表明我們的攻擊以高精度恢復了在已知自然語言、編程語言和數據源混合物上訓練的分詞器的混合比例。然後，我們將我們的做法應用於最近發布的開箱即用分詞器與 LMs。我們確認了關於這些模型的許多公開披露的信息，還做出了幾個新的推論：GPT-4o 的分詞器比其前輩更加多語言，在 39% 的非英語數據上進行訓練；Llama3 主要為多語言（48%）使用擴展了 GPT-3.5 的分詞器；GPT-3.5 和 Claude 的分詞器主要在代碼（~60%）上進行訓練。我們希望我們的工作能為預訓練數據的當前設計實務提供啟示，並激勵繼續研究 LMs 的數據混合推論。</paragraph>

##### **Shared Imagination: LLMs Hallucinate Alike**
2407.16604v1 by Yilun Zhou, Caiming Xiong, Silvio Savarese, Chien-Sheng Wu

Despite the recent proliferation of large language models (LLMs), their
training recipes -- model architecture, pre-training data and optimization
algorithm -- are often very similar. This naturally raises the question of the
similarity among the resulting models. In this paper, we propose a novel
setting, imaginary question answering (IQA), to better understand model
similarity. In IQA, we ask one model to generate purely imaginary questions
(e.g., on completely made-up concepts in physics) and prompt another model to
answer. Surprisingly, despite the total fictionality of these questions, all
models can answer each other's questions with remarkable success, suggesting a
"shared imagination space" in which these models operate during such
hallucinations. We conduct a series of investigations into this phenomenon and
discuss implications on model homogeneity, hallucination, and computational
creativity.

摘要：儘管大型語言模型 (LLM) 近期大量湧現，但其訓練配方（模型架構、預訓練資料和最佳化演算法）通常非常相似。這自然會引發對所產生模型間相似性的疑問。在本文中，我們提出了一種新穎的設定，即虛擬問答 (IQA)，以更好地了解模型相似性。在 IQA 中，我們要求一個模型產生純粹虛擬的問題（例如，關於物理學中完全虛構的概念），並提示另一個模型回答。令人驚訝的是，儘管這些問題完全是虛構的，但所有模型都能以顯著的成功率回答彼此的問題，這表明這些模型在產生這些幻覺時運作於一個「共享想像空間」中。我們對此現象進行了一系列調查，並討論了對模型同質性、幻覺和計算創造力的影響。

##### **GenRec: A Flexible Data Generator for Recommendations**
2407.16594v1 by Erica Coppolillo, Simone Mungari, Ettore Ritacco, Giuseppe Manco

The scarcity of realistic datasets poses a significant challenge in
benchmarking recommender systems and social network analysis methods and
techniques. A common and effective solution is to generate synthetic data that
simulates realistic interactions. However, although various methods have been
proposed, the existing literature still lacks generators that are fully
adaptable and allow easy manipulation of the underlying data distributions and
structural properties. To address this issue, the present work introduces
GenRec, a novel framework for generating synthetic user-item interactions that
exhibit realistic and well-known properties observed in recommendation
scenarios. The framework is based on a stochastic generative process based on
latent factor modeling. Here, the latent factors can be exploited to yield
long-tailed preference distributions, and at the same time they characterize
subpopulations of users and topic-based item clusters. Notably, the proposed
framework is highly flexible and offers a wide range of hyper-parameters for
customizing the generation of user-item interactions. The code used to perform
the experiments is publicly available at
https://anonymous.4open.science/r/GenRec-DED3.

摘要：現實資料集的稀缺性在推薦系統和社交網路分析方法和技術的基準測試中構成重大挑戰。一個常見且有效的解決方案是生成模擬現實互動的合成資料。然而，儘管已經提出各種方法，現有文獻仍缺乏完全適應且允許輕鬆操作基礎資料分佈和結構屬性的產生器。為了解決這個問題，本研究引入了 GenRec，這是一個用於生成合成使用者一項目互動的新框架，該互動展現了在推薦情境中觀察到的現實且眾所周知的屬性。該框架基於一個基於潛在因子建模的隨機生成過程。在此，潛在因子可被利用以產生長尾偏好分佈，同時它們也表徵使用者次族群和基於主題的項目叢集。值得注意的是，所提出的框架非常靈活，並提供廣泛的超參數以自訂使用者一項目互動的生成。用於執行實驗的程式碼在 https://anonymous.4open.science/r/GenRec-DED3 公開提供。

##### **A Comparative Study on Patient Language across Therapeutic Domains for Effective Patient Voice Classification in Online Health Discussions**
2407.16593v1 by Giorgos Lysandrou, Roma English Owen, Vanja Popovic, Grant Le Brun, Aryo Pradipta Gema, Beatrice Alex, Elizabeth A. L. Fairley

There exists an invisible barrier between healthcare professionals'
perception of a patient's clinical experience and the reality. This barrier may
be induced by the environment that hinders patients from sharing their
experiences openly with healthcare professionals. As patients are observed to
discuss and exchange knowledge more candidly on social media, valuable insights
can be leveraged from these platforms. However, the abundance of non-patient
posts on social media necessitates filtering out such irrelevant content to
distinguish the genuine voices of patients, a task we refer to as patient voice
classification. In this study, we analyse the importance of linguistic
characteristics in accurately classifying patient voices. Our findings
underscore the essential role of linguistic and statistical text similarity
analysis in identifying common patterns among patient groups. These results
allude to even starker differences in the way patients express themselves at a
disease level and across various therapeutic domains. Additionally, we
fine-tuned a pre-trained Language Model on the combined datasets with similar
linguistic patterns, resulting in a highly accurate automatic patient voice
classification. Being the pioneering study on the topic, our focus on
extracting authentic patient experiences from social media stands as a crucial
step towards advancing healthcare standards and fostering a patient-centric
approach.

摘要：醫療保健專業人員對於患者臨床經驗的認知與實際情況之間存在著一道無形的障礙。此障礙可能是由環境所造成，阻礙患者與醫療保健專業人員公開分享他們的經驗。由於觀察到患者在社群媒體上更坦率地討論和交換知識，因此可以從這些平台獲得有價值的見解。然而，社群媒體上充斥著非患者貼文，因此有必要過濾掉這些不相關的內容，以區分患者的真實聲音，我們將此任務稱為患者聲音分類。在本研究中，我們分析了語言特徵在準確分類患者聲音中的重要性。我們的研究結果強調了語言和統計文字相似性分析在識別患者群組之間共同模式中的重要角色。這些結果暗示了患者在疾病層級和各種治療領域中表達自己的方式存在著更明顯的差異。此外，我們根據具有類似語言模式的合併資料集微調了預先訓練好的語言模型，進而產生高度準確的自動患者聲音分類。作為這項主題的開創性研究，我們專注於從社群媒體中提取真實的患者經驗，這是邁向提升醫療保健標準和培養以患者為中心的途徑的關鍵一步。

##### **TLCR: Token-Level Continuous Reward for Fine-grained Reinforcement Learning from Human Feedback**
2407.16574v1 by Eunseop Yoon, Hee Suk Yoon, SooHwan Eom, Gunsoo Han, Daniel Wontae Nam, Daejin Jo, Kyoung-Woon On, Mark A. Hasegawa-Johnson, Sungwoong Kim, Chang D. Yoo

Reinforcement Learning from Human Feedback (RLHF) leverages human preference
data to train language models to align more closely with human essence. These
human preference data, however, are labeled at the sequence level, creating a
mismatch between sequence-level preference labels and tokens, which are
autoregressively generated from the language model. Although several recent
approaches have tried to provide token-level (i.e., dense) rewards for each
individual token, these typically rely on predefined discrete reward values
(e.g., positive: +1, negative: -1, neutral: 0), failing to account for varying
degrees of preference inherent to each token. To address this limitation, we
introduce TLCR (Token-Level Continuous Reward) for RLHF, which incorporates a
discriminator trained to distinguish positive and negative tokens, and the
confidence of the discriminator is used to assign continuous rewards to each
token considering the context. Extensive experiments show that our proposed
TLCR leads to consistent performance improvements over previous sequence-level
or token-level discrete rewards on open-ended generation benchmarks.

摘要：強化學習來自人類回饋 (RLHF) 利用人類偏好資料訓練語言模型，以更貼近人類本質。然而，這些人類偏好資料是在序列層級標記，造成序列層級偏好標籤與由語言模型自迴歸產生的符號之間的不匹配。雖然最近有幾種方法嘗試為每個個別符號提供符號層級（即密集）獎勵，但這些方法通常依賴於預定義的離散獎勵值（例如，正面：+1，負面：-1，中立：0），未能考量每個符號固有的不同偏好程度。為了解決這個限制，我們針對 RLHF 引入了 TLCR（符號層級連續獎勵），它結合了一個訓練用於區分正面和負面符號的判別器，並且判別器的信心用於根據上下文為每個符號分配連續獎勵。廣泛的實驗顯示，我們提出的 TLCR 在開放式生成基準上，相較於先前的序列層級或符號層級離散獎勵，帶來了一致的效能提升。

##### **Retrieve, Generate, Evaluate: A Case Study for Medical Paraphrases Generation with Small Language Models**
2407.16565v1 by Ioana Buhnila, Aman Sinha, Mathieu Constant

Recent surge in the accessibility of large language models (LLMs) to the
general population can lead to untrackable use of such models for
medical-related recommendations. Language generation via LLMs models has two
key problems: firstly, they are prone to hallucination and therefore, for any
medical purpose they require scientific and factual grounding; secondly, LLMs
pose tremendous challenge to computational resources due to their gigantic
model size. In this work, we introduce pRAGe, a pipeline for Retrieval
Augmented Generation and evaluation of medical paraphrases generation using
Small Language Models (SLM). We study the effectiveness of SLMs and the impact
of external knowledge base for medical paraphrase generation in French.

摘要：大型語言模型（LLM）最近對一般民眾的可用性激增，可能會導致無法追蹤這些模型用於與醫療相關的建議。透過 LLM 模型產生的語言有兩個主要問題：首先，它們容易產生幻覺，因此，對於任何醫療目的，它們都需要科學和事實依據；其次，由於 LLM 龐大的模型規模，對運算資源造成極大的挑戰。在這項工作中，我們介紹了 pRAGe，一個用於檢索擴充產生和使用小型語言模型（SLM）評估醫療釋義產生的管道。我們研究了 SLM 的有效性以及外部知識庫對法語醫療釋義產生的影響。

##### **Audio Prompt Adapter: Unleashing Music Editing Abilities for Text-to-Music with Lightweight Finetuning**
2407.16564v1 by Fang-Duo Tsai, Shih-Lun Wu, Haven Kim, Bo-Yu Chen, Hao-Chung Cheng, Yi-Hsuan Yang

Text-to-music models allow users to generate nearly realistic musical audio
with textual commands. However, editing music audios remains challenging due to
the conflicting desiderata of performing fine-grained alterations on the audio
while maintaining a simple user interface. To address this challenge, we
propose Audio Prompt Adapter (or AP-Adapter), a lightweight addition to
pretrained text-to-music models. We utilize AudioMAE to extract features from
the input audio, and construct attention-based adapters to feedthese features
into the internal layers of AudioLDM2, a diffusion-based text-to-music model.
With 22M trainable parameters, AP-Adapter empowers users to harness both global
(e.g., genre and timbre) and local (e.g., melody) aspects of music, using the
original audio and a short text as inputs. Through objective and subjective
studies, we evaluate AP-Adapter on three tasks: timbre transfer, genre
transfer, and accompaniment generation. Additionally, we demonstrate its
effectiveness on out-of-domain audios containing unseen instruments during
training.

摘要：文字轉音樂模型允許使用者使用文字指令產生近乎真實的音樂音訊。然而，編輯音樂音訊仍然具有挑戰性，因為在音訊上進行細微的變更與維持簡單的使用者介面之間存在衝突的期望。為了應對這個挑戰，我們提出音訊提示適配器（或 AP-Adapter），這是預先訓練好的文字轉音樂模型的輕量級附加功能。我們利用 AudioMAE 從輸入音訊中萃取特徵，並建構基於注意力的適配器，將這些特徵輸入到基於擴散的文字轉音樂模型 AudioLDM2 的內部層級。AP-Adapter 擁有 22M 個可訓練參數，讓使用者能夠利用原始音訊和簡短文字作為輸入，同時運用音樂的全局（例如，類型和音色）和局部（例如，旋律）面向。透過客觀和主觀研究，我們在三個任務上評估 AP-Adapter：音色轉移、類型轉移和伴奏產生。此外，我們展示了它在訓練期間包含未見樂器的領域外音訊上的有效性。

##### **Patched RTC: evaluating LLMs for diverse software development tasks**
2407.16557v1 by Asankhaya Sharma

This paper introduces Patched Round-Trip Correctness (Patched RTC), a novel
evaluation technique for Large Language Models (LLMs) applied to diverse
software development tasks, particularly focusing on "outer loop" activities
such as bug fixing, code review, and documentation updates. Patched RTC extends
the original Round-Trip Correctness method to work with any LLM and downstream
task, offering a self-evaluating framework that measures consistency and
robustness of model responses without human intervention. The study
demonstrates a correlation between Patched RTC scores and task-specific
accuracy metrics, presenting it as an alternative to the LLM-as-Judge paradigm
for open-domain task evaluation. We implement Patched RTC in an open-source
framework called patchwork, allowing for transparent evaluation during
inference across various patchflows. Experiments comparing GPT-3.5 and GPT-4
models across different software development tasks reveal that Patched RTC
effectively distinguishes model performance and task difficulty. The paper also
explores the impact of consistency prompts on improving model accuracy,
suggesting that Patched RTC can guide prompt refinement and model selection for
complex software development workflows.

摘要：本文介绍了修补往返正确性（修补 RTC），这是一种针对应用于各种软件开发任务的大语言模型（LLM）的新颖评估技术，尤其注重“外部循环”活动，例如错误修复、代码审查和文档更新。修补 RTC 扩展了原始往返正确性方法，使其适用于任何 LLM 和下游任务，提供了一个自评估框架，用于衡量模型响应的一致性和鲁棒性，而无需人工干预。该研究展示了修补 RTC 分数与特定任务准确性指标之间的相关性，将其作为 LLM 即评判范式的一种替代方案，用于开放域任务评估。我们在一个名为 patchwork 的开源框架中实现了修补 RTC，允许在各种补丁流中进行推理期间进行透明评估。比较 GPT-3.5 和 GPT-4 模型在不同软件开发任务中的实验表明，修补 RTC 可以有效地区分模型性能和任务难度。本文还探讨了一致性提示对提高模型准确性的影响，表明修补 RTC 可以指导提示细化和模型选择，以用于复杂的软件开发工作流。

##### **Quantifying the Role of Textual Predictability in Automatic Speech Recognition**
2407.16537v1 by Sean Robertson, Gerald Penn, Ewan Dunbar

A long-standing question in automatic speech recognition research is how to
attribute errors to the ability of a model to model the acoustics, versus its
ability to leverage higher-order context (lexicon, morphology, syntax,
semantics). We validate a novel approach which models error rates as a function
of relative textual predictability, and yields a single number, $k$, which
measures the effect of textual predictability on the recognizer. We use this
method to demonstrate that a Wav2Vec 2.0-based model makes greater stronger use
of textual context than a hybrid ASR model, in spite of not using an explicit
language model, and also use it to shed light on recent results demonstrating
poor performance of standard ASR systems on African-American English. We
demonstrate that these mostly represent failures of acoustic--phonetic
modelling. We show how this approach can be used straightforwardly in
diagnosing and improving ASR.

摘要：長期以來，自動語音辨識研究中的問題是如何將錯誤歸因於模型建構音響的能力，相對於它利用高階脈絡（詞彙、形態、句法、語義）的能力。我們驗證了一種新穎的方法，將錯誤率建模為相對文本可預測性的函數，並產生一個單一數字 $k$，用於衡量文本可預測性對辨識器的影響。我們使用此方法證明，基於 Wav2Vec 2.0 的模型比混合 ASR 模型更能有效利用文本脈絡，儘管沒有使用明確的語言模型，並用它來闡明最近的結果，證明標準 ASR 系統在非裔美國英語上的表現不佳。我們證明，這些大多代表音響語音建模的失敗。我們展示了這種方法如何直接用於診斷和改進 ASR。

##### **HAPFI: History-Aware Planning based on Fused Information**
2407.16533v1 by Sujin Jeon, Suyeon Shin, Byoung-Tak Zhang

Embodied Instruction Following (EIF) is a task of planning a long sequence of
sub-goals given high-level natural language instructions, such as "Rinse a
slice of lettuce and place on the white table next to the fork". To
successfully execute these long-term horizon tasks, we argue that an agent must
consider its past, i.e., historical data, when making decisions in each step.
Nevertheless, recent approaches in EIF often neglects the knowledge from
historical data and also do not effectively utilize information across the
modalities. To this end, we propose History-Aware Planning based on Fused
Information (HAPFI), effectively leveraging the historical data from diverse
modalities that agents collect while interacting with the environment.
Specifically, HAPFI integrates multiple modalities, including historical RGB
observations, bounding boxes, sub-goals, and high-level instructions, by
effectively fusing modalities via our Mutually Attentive Fusion method. Through
experiments with diverse comparisons, we show that an agent utilizing
historical multi-modal information surpasses all the compared methods that
neglect the historical data in terms of action planning capability, enabling
the generation of well-informed action plans for the next step. Moreover, we
provided qualitative evidence highlighting the significance of leveraging
historical multi-modal data, particularly in scenarios where the agent
encounters intermediate failures, showcasing its robust re-planning
capabilities.

摘要：具身指令遵循 (EIF) 是一項規劃一系列長遠子目標的任務，這些目標來自於高階自然語言指令，例如「沖洗一片萵苣，並將其放在叉子旁邊的白色桌子上」。為了成功執行這些長期任務，我們認為代理人必須在每一步做出決策時，考慮其過去，也就是歷史資料。然而，EIF 中最近的方法通常忽略歷史資料中的知識，而且也沒有有效利用跨模態的資訊。為此，我們提出基於融合資訊的歷史感知規劃 (HAPFI)，有效利用代理人在與環境互動時收集到的來自不同模態的歷史資料。具體來說，HAPFI 整合了多種模態，包括歷史 RGB 觀察、邊界框、子目標和高階指令，通過我們相互注意融合方法有效融合模態。通過與不同比較項的實驗，我們展示了一個利用歷史多模態資訊的代理人，在動作規劃能力方面超越了所有忽略歷史資料的比較方法，能夠為下一步生成見解豐富的動作計畫。此外，我們提供了定性證據，強調利用歷史多模態資料的重要性，特別是在代理人遇到中間失敗的情況下，展示其強大的重新規劃能力。

##### **Imperfect Vision Encoders: Efficient and Robust Tuning for Vision-Language Models**
2407.16526v1 by Aristeidis Panos, Rahaf Aljundi, Daniel Olmeda Reino, Richard E Turner

Vision language models (VLMs) demonstrate impressive capabilities in visual
question answering and image captioning, acting as a crucial link between
visual and language models. However, existing open-source VLMs heavily rely on
pretrained and frozen vision encoders (such as CLIP). Despite CLIP's robustness
across diverse domains, it still exhibits non-negligible image understanding
errors. These errors propagate to the VLM responses, resulting in sub-optimal
performance. In our work, we propose an efficient and robust method for
updating vision encoders within VLMs. Our approach selectively and locally
updates encoders, leading to substantial performance improvements on data where
previous mistakes occurred, while maintaining overall robustness. Furthermore,
we demonstrate the effectiveness of our method during continual few-shot
updates. Theoretical grounding, generality, and computational efficiency
characterize our approach.

摘要：視覺語言模型 (VLM) 在視覺問答和影像標題說明中展現令人印象深刻的能力，扮演視覺與語言模型之間的關鍵連結。然而，現有的開放原始碼 VLM 嚴重依賴預先訓練且凍結的視覺編碼器 (例如 CLIP)。儘管 CLIP 在各種領域中展現穩健性，但仍會出現不可忽略的影像理解錯誤。這些錯誤會傳播到 VLM 回應中，導致次佳效能。在我們的研究中，我們提出一個有效且穩健的方法，用於更新 VLM 中的視覺編碼器。我們的做法選擇性且局部地更新編碼器，讓先前發生錯誤的資料大幅提升效能，同時維持整體的穩健性。此外，我們在持續少次學習更新期間，展現我們方法的有效性。理論基礎、通用性和運算效率是我們方法的特徵。

##### **AMONGAGENTS: Evaluating Large Language Models in the Interactive Text-Based Social Deduction Game**
2407.16521v1 by Yizhou Chi, Lingjun Mao, Zineng Tang

Strategic social deduction games serve as valuable testbeds for evaluating
the understanding and inference skills of language models, offering crucial
insights into social science, artificial intelligence, and strategic gaming.
This paper focuses on creating proxies of human behavior in simulated
environments, with \textit{Among Us} utilized as a tool for studying simulated
human behavior.
  The study introduces a text-based game environment, named AmongAgent, that
mirrors the dynamics of \textit{Among Us}. Players act as crew members aboard a
spaceship, tasked with identifying impostors who are sabotaging the ship and
eliminating the crew. Within this environment, the behavior of simulated
language agents is analyzed. The experiments involve diverse game sequences
featuring different configurations of Crewmates and Impostor personality
archetypes. Our work demonstrates that state-of-the-art large language models
(LLMs) can effectively grasp the game rules and make decisions based on the
current context. This work aims to promote further exploration of LLMs in
goal-oriented games with incomplete information and complex action spaces, as
these settings offer valuable opportunities to assess language model
performance in socially driven scenarios.

摘要：策略性社交推理遊戲可作為評估語言模型理解和推理技能的寶貴測試平台，提供對社會科學、人工智慧和策略遊戲的重要見解。本文重點在於在模擬環境中建立人類行為的代理，並以《Among Us》作為研究模擬人類行為的工具。本研究引入一個名為 AmongAgent 的文字遊戲環境，它反映了《Among Us》的動態。玩家扮演太空船上的船員，任務是找出破壞船隻並消滅船員的冒名頂替者。在這個環境中，分析模擬語言代理的行為。實驗涉及不同的遊戲序列，其中包含船員和冒名頂替者人格原型的不同配置。我們的研究表明，最先進的大型語言模型 (LLM) 可以有效掌握遊戲規則，並根據當前背景做出決策。這項工作旨在促進進一步探索 LLM 在具有不完整資訊和複雜動作空間的目標導向遊戲中的應用，因為這些設定提供了在社會驅動情境中評估語言模型效能的寶貴機會。

##### **Assessing In-context Learning and Fine-tuning for Topic Classification of German Web Data**
2407.16516v1 by Julian Schelb, Roberto Ulloa, Andreas Spitz

Researchers in the political and social sciences often rely on classification
models to analyze trends in information consumption by examining browsing
histories of millions of webpages. Automated scalable methods are necessary due
to the impracticality of manual labeling. In this paper, we model the detection
of topic-related content as a binary classification task and compare the
accuracy of fine-tuned pre-trained encoder models against in-context learning
strategies. Using only a few hundred annotated data points per topic, we detect
content related to three German policies in a database of scraped webpages. We
compare multilingual and monolingual models, as well as zero and few-shot
approaches, and investigate the impact of negative sampling strategies and the
combination of URL & content-based features. Our results show that a small
sample of annotated data is sufficient to train an effective classifier.
Fine-tuning encoder-based models yields better results than in-context
learning. Classifiers using both URL & content-based features perform best,
while using URLs alone provides adequate results when content is unavailable.

摘要：政治和社會科學的研究人員經常依賴分類模型來分析透過檢視數百萬個網頁的瀏覽記錄來了解資訊消費的趨勢。由於人工標記不切實際，因此需要自動化且可擴充的方法。在本文中，我們將主題相關內容的偵測建模為二元分類任務，並將微調過的預訓練編碼器模型的準確度與情境學習策略進行比較。我們只使用每主題數百個註解資料點，就能在一個抓取網頁的資料庫中偵測到與三個德國政策相關的內容。我們比較了多語言和單一語言模型，以及零次和少次學習方法，並探討了負面抽樣策略和 URL 與基於內容特徵的組合的影響。我們的結果顯示，少量的註解資料就足以訓練出一個有效的分類器。微調基於編碼器的模型會產生比情境學習更好的結果。同時使用 URL 和基於內容特徵的分類器表現最佳，而當內容不可用時，僅使用 URL 也可以提供足夠的結果。

##### **Is 3D Convolution with 5D Tensors Really Necessary for Video Analysis?**
2407.16514v1 by Habib Hajimolahoseini, Walid Ahmed, Austin Wen, Yang Liu

In this paper, we present a comprehensive study and propose several novel
techniques for implementing 3D convolutional blocks using 2D and/or 1D
convolutions with only 4D and/or 3D tensors. Our motivation is that 3D
convolutions with 5D tensors are computationally very expensive and they may
not be supported by some of the edge devices used in real-time applications
such as robots. The existing approaches mitigate this by splitting the 3D
kernels into spatial and temporal domains, but they still use 3D convolutions
with 5D tensors in their implementations. We resolve this issue by introducing
some appropriate 4D/3D tensor reshaping as well as new combination techniques
for spatial and temporal splits. The proposed implementation methods show
significant improvement both in terms of efficiency and accuracy. The
experimental results confirm that the proposed spatio-temporal processing
structure outperforms the original model in terms of speed and accuracy using
only 4D tensors with fewer parameters.

摘要：在本文中，我們提出了一個全面的研究，並提出幾種使用 2D 和/或 1D 捲積僅使用 4D 和/或 3D 張量來實現 3D 捲積塊的新技術。我們的動機是 5D 張量的 3D 捲積在計算上非常昂貴，並且它們可能不受用於實時應用（例如機器人）的一些邊緣設備支持。現有方法通過將 3D 核心拆分成空間和時間域來緩解此問題，但它們在其實現中仍然使用 5D 張量的 3D 捲積。我們通過引入一些適當的 4D/3D 張量重塑以及新的空間和時間分割組合技術來解決此問題。所提出的實作方法在效率和準確性方面均顯示出顯著的改善。實驗結果證實，所提出的時空處理結構在速度和準確性方面優於原始模型，僅使用具有較少參數的 4D 張量。

##### **Articulation Work and Tinkering for Fairness in Machine Learning**
2407.16496v1 by Miriam Fahimi, Mayra Russo, Kristen M. Scott, Maria-Esther Vidal, Bettina Berendt, Katharina Kinder-Kurlanda

The field of fair AI aims to counter biased algorithms through computational
modelling. However, it faces increasing criticism for perpetuating the use of
overly technical and reductionist methods. As a result, novel approaches appear
in the field to address more socially-oriented and interdisciplinary (SOI)
perspectives on fair AI. In this paper, we take this dynamic as the starting
point to study the tension between computer science (CS) and SOI research. By
drawing on STS and CSCW theory, we position fair AI research as a matter of
'organizational alignment': what makes research 'doable' is the successful
alignment of three levels of work organization (the social world, the
laboratory and the experiment). Based on qualitative interviews with CS
researchers, we analyze the tasks, resources, and actors required for doable
research in the case of fair AI. We find that CS researchers engage with SOI to
some extent, but organizational conditions, articulation work, and ambiguities
of the social world constrain the doability of SOI research. Based on our
findings, we identify and discuss problems for aligning CS and SOI as fair AI
continues to evolve.

摘要：公平 AI 领域旨在通过计算建模来对抗有偏差的算法。然而，它因延续使用过于技术化和还原论的方法而面临越来越多的批评。因此，该领域出现了新的方法来解决公平 AI 的更具社会导向性和跨学科 (SOI) 的观点。在本文中，我们将这种动态作为研究计算机科学 (CS) 和 SOI 研究之间紧张关系的出发点。通过借鉴 STS 和 CSCW 理论，我们将公平 AI 研究定位为“组织协调”问题：使研究“可行”的是三个层次的工作组织（社会世界、实验室和实验）的成功协调。基于对 CS 研究人员的定性访谈，我们分析了公平 AI 情况下可行研究所需的任务、资源和参与者。我们发现 CS 研究人员在一定程度上参与了 SOI，但组织条件、表达工作和社会世界的模糊性限制了 SOI 研究的可行性。基于我们的研究结果，我们确定并讨论了在公平 AI 持续发展过程中协调 CS 和 SOI 的问题。

##### **Learning General Continuous Constraint from Demonstrations via Positive-Unlabeled Learning**
2407.16485v1 by Baiyu Peng, Aude Billard

Planning for a wide range of real-world tasks necessitates to know and write
all constraints. However, instances exist where these constraints are either
unknown or challenging to specify accurately. A possible solution is to infer
the unknown constraints from expert demonstration. The majority of prior works
limit themselves to learning simple linear constraints, or require strong
knowledge of the true constraint parameterization or environmental model. To
mitigate these problems, this paper presents a positive-unlabeled (PU) learning
approach to infer a continuous, arbitrary and possibly nonlinear, constraint
from demonstration. From a PU learning view, We treat all data in
demonstrations as positive (feasible) data, and learn a (sub)-optimal policy to
generate high-reward-winning but potentially infeasible trajectories, which
serve as unlabeled data containing both feasible and infeasible states. Under
an assumption on data distribution, a feasible-infeasible classifier (i.e.,
constraint model) is learned from the two datasets through a postprocessing PU
learning technique. The entire method employs an iterative framework
alternating between updating the policy, which generates and selects
higher-reward policies, and updating the constraint model. Additionally, a
memory buffer is introduced to record and reuse samples from previous
iterations to prevent forgetting. The effectiveness of the proposed method is
validated in two Mujoco environments, successfully inferring continuous
nonlinear constraints and outperforming a baseline method in terms of
constraint accuracy and policy safety.

摘要：<paragraph>要規劃廣泛的真實世界任務，必須知道並寫下所有限制條件。然而，存在這些限制條件未知或難以精確指定的實例。一個可能的解決方案是從專家示範中推斷未知的限制條件。大多數先前的工作僅限於學習簡單的線性限制條件，或需要對真正的限制條件參數化或環境模型有深入的了解。為了緩解這些問題，本文提出了一種正未標記 (PU) 學習方法，以從示範中推斷出連續、任意且可能是非線性的限制條件。從 PU 學習的角度來看，我們將示範中的所有數據視為正 (可行) 數據，並學習一個 (次) 最佳策略來產生高獎勵獲勝但潛在不可行的軌跡，這些軌跡作為包含可行和不可行狀態的未標記數據。在數據分佈的假設下，通過後處理 PU 學習技術從兩個數據集中學習可行不可行分類器 (即約束模型)。整個方法採用了一種迭代框架，在更新策略（生成和選擇更高獎勵策略）和更新約束模型之間交替進行。此外，引入了記憶體緩衝區來記錄和重複使用前一次迭代的樣本，以防止遺忘。所提出的方法的有效性在兩個 Mujoco 環境中得到驗證，成功推斷出連續的非線性約束，並在約束準確性和策略安全性方面優於基線方法。</paragraph>

##### **BONES: a Benchmark fOr Neural Estimation of Shapley values**
2407.16482v1 by Davide Napolitano, Luca Cagliero

Shapley Values are concepts established for eXplainable AI. They are used to
explain black-box predictive models by quantifying the features' contributions
to the model's outcomes. Since computing the exact Shapley Values is known to
be computationally intractable on real-world datasets, neural estimators have
emerged as alternative, more scalable approaches to get approximated Shapley
Values estimates. However, experiments with neural estimators are currently
hard to replicate as algorithm implementations, explainer evaluators, and
results visualizations are neither standardized nor promptly usable. To bridge
this gap, we present BONES, a new benchmark focused on neural estimation of
Shapley Value. It provides researchers with a suite of state-of-the-art neural
and traditional estimators, a set of commonly used benchmark datasets, ad hoc
modules for training black-box models, as well as specific functions to easily
compute the most popular evaluation metrics and visualize results. The purpose
is to simplify XAI model usage, evaluation, and comparison. In this paper, we
showcase BONES results and visualizations for XAI model benchmarking on both
tabular and image data. The open-source library is available at the following
link: https://github.com/DavideNapolitano/BONES.

摘要：Shapley 值是為可解釋 AI 而建立的概念。它們用於透過量化特徵對模型結果的貢獻來解釋黑盒預測模型。由於計算確切的 Shapley 值已知在真實世界資料集上在計算上難以處理，因此神經估計器已成為獲得近似 Shapley 值估計值的替代、更具可擴充性的方法。然而，目前難以複製使用神經估計器的實驗，因為演算法實作、說明器評估器和結果視覺化既未標準化也無法立即使用。為了彌合這個差距，我們提出 BONES，一個專注於 Shapley 值神經估計的新基準。它為研究人員提供了一套最先進的神經和傳統估計器、一組常用的基準資料集、訓練黑盒模型的特殊模組，以及輕鬆計算最熱門評估指標和視覺化結果的特定功能。目的是簡化 XAI 模型的使用、評估和比較。在本文中，我們展示了 BONES 結果和視覺化，用於在表格和影像資料上進行 XAI 模型基準測試。開放原始碼程式庫可在以下連結取得：https://github.com/DavideNapolitano/BONES。

##### **Machine Translation Hallucination Detection for Low and High Resource Languages using Large Language Models**
2407.16470v1 by Kenza Benkirane, Laura Gongas, Shahar Pelles, Naomi Fuchs, Joshua Darmon, Pontus Stenetorp, David Ifeoluwa Adelani, Eduardo Sanchez

Recent advancements in massively multilingual machine translation systems
have significantly enhanced translation accuracy; however, even the best
performing systems still generate hallucinations, severely impacting user
trust. Detecting hallucinations in Machine Translation (MT) remains a critical
challenge, particularly since existing methods excel with High-Resource
Languages (HRLs) but exhibit substantial limitations when applied to
Low-Resource Languages (LRLs). This paper evaluates hallucination detection
approaches using Large Language Models (LLMs) and semantic similarity within
massively multilingual embeddings. Our study spans 16 language directions,
covering HRLs, LRLs, with diverse scripts. We find that the choice of model is
essential for performance. On average, for HRLs, Llama3-70B outperforms the
previous state of the art by as much as 0.16 MCC (Matthews Correlation
Coefficient). However, for LRLs we observe that Claude Sonnet outperforms other
LLMs on average by 0.03 MCC. The key takeaway from our study is that LLMs can
achieve performance comparable or even better than previously proposed models,
despite not being explicitly trained for any machine translation task. However,
their advantage is less significant for LRLs.

摘要：<paragraph>大型多語言機器翻譯系統的最新進展已大幅提升翻譯的準確性；然而，即使是效能最佳的系統仍會產生幻覺，嚴重影響使用者的信任。在機器翻譯 (MT) 中偵測幻覺仍然是一項重大的挑戰，特別是因為現有的方法在高資源語言 (HRL) 中表現出色，但應用在低資源語言 (LRL) 時卻有很大的限制。本文評估使用大型語言模型 (LLM) 和大量多語言嵌入中的語義相似性來進行幻覺偵測的方法。我們的研究涵蓋 16 種語言方向，包括使用不同文字系統的 HRL 和 LRL。我們發現模型的選擇對於效能至關重要。平均而言，對於 HRL，Llama3-70B 的表現優於先前的技術水準，馬修斯相關係數 (MCC) 提高了 0.16。然而，對於 LRL，我們觀察到 Claude Sonnet 的表現平均優於其他 LLM，MCC 提高了 0.03。我們研究的關鍵結論是，儘管 LLM 並未針對任何機器翻譯任務進行明確訓練，但它們仍能達到與先前提出的模型相當甚至更好的效能。然而，它們在 LRL 的優勢較不顯著。</paragraph>

##### **Side-Channel Analysis of OpenVINO-based Neural Network Models**
2407.16467v1 by Dirmanto Jap, Jakub Breier, Zdenko Lehocký, Shivam Bhasin, Xiaolu Hou

Embedded devices with neural network accelerators offer great versatility for
their users, reducing the need to use cloud-based services. At the same time,
they introduce new security challenges in the area of hardware attacks, the
most prominent being side-channel analysis (SCA). It was shown that SCA can
recover model parameters with a high accuracy, posing a threat to entities that
wish to keep their models confidential. In this paper, we explore the
susceptibility of quantized models implemented in OpenVINO, an embedded
framework for deploying neural networks on embedded and Edge devices. We show
that it is possible to recover model parameters with high precision, allowing
the recovered model to perform very close to the original one. Our experiments
on GoogleNet v1 show only a 1% difference in the Top 1 and a 0.64% difference
in the Top 5 accuracies.

摘要：嵌入式裝置搭配神經網路加速器，能為使用者帶來極大的便利性，減少使用雲端服務的需求。同時，它們也帶來硬體攻擊領域的新安全挑戰，其中最著名的就是側信道分析 (SCA)。研究指出，SCA 能夠以極高的準確度還原模型參數，對希望保持模型機密性的實體構成威脅。在本文中，我們探討在 OpenVINO 中實作的量化模型的敏感性，OpenVINO 是用於在嵌入式和邊緣裝置上部署神經網路的嵌入式架構。我們證明了以高準確度還原模型參數是可行的，讓還原的模型能執行得非常接近原始模型。我們在 GoogleNet v1 上的實驗顯示，Top 1 準確度只有 1% 的差異，而 Top 5 準確度則有 0.64% 的差異。

##### **Psychomatics -- A Multidisciplinary Framework for Understanding Artificial Minds**
2407.16444v1 by Giuseppe Riva, Fabrizia Mantovani, Brenda K. Wiederhold, Antonella Marchetti, Andrea Gaggioli

Although LLMs and other artificial intelligence systems demonstrate cognitive
skills similar to humans, like concept learning and language acquisition, the
way they process information fundamentally differs from biological cognition.
To better understand these differences this paper introduces Psychomatics, a
multidisciplinary framework bridging cognitive science, linguistics, and
computer science. It aims to better understand the high-level functioning of
LLMs, focusing specifically on how LLMs acquire, learn, remember, and use
information to produce their outputs. To achieve this goal, Psychomatics will
rely on a comparative methodology, starting from a theory-driven research
question - is the process of language development and use different in humans
and LLMs? - drawing parallels between LLMs and biological systems. Our analysis
shows how LLMs can map and manipulate complex linguistic patterns in their
training data. Moreover, LLMs can follow Grice's Cooperative Principle to
provide relevant and informative responses. However, human cognition draws from
multiple sources of meaning, including experiential, emotional, and imaginative
facets, which transcend mere language processing and are rooted in our social
and developmental trajectories. Moreover, current LLMs lack physical
embodiment, reducing their ability to make sense of the intricate interplay
between perception, action, and cognition that shapes human understanding and
expression. Ultimately, Psychomatics holds the potential to yield
transformative insights into the nature of language, cognition, and
intelligence, both artificial and biological. Moreover, by drawing parallels
between LLMs and human cognitive processes, Psychomatics can inform the
development of more robust and human-like AI systems.

摘要：儘管大型語言模型和其他人工智慧系統展現出類似人類的概念學習和語言習得等認知技能，但它們處理資訊的方式與生物認知有根本上的不同。為了更了解這些差異，本文介紹了心身學，一個橋接認知科學、語言學和電腦科學的多領域架構。它旨在更了解大型語言模型的高階功能，特別專注於大型語言模型如何取得、學習、記憶和使用資訊來產生它們的輸出。為了達成這個目標，心身學將依賴比較方法，從理論驅動的研究問題開始——人類和大型語言模型的語言發展和使用過程是否不同？——在大型語言模型和生物系統之間畫出平行線。我們的分析顯示大型語言模型如何對其訓練資料中的複雜語言模式進行對應和操作。此外，大型語言模型可以遵循格萊斯的合作原則來提供相關且有資訊的回應。然而，人類認知從多種意義來源汲取，包括經驗、情緒和想像層面，這超越了單純的語言處理，並根植於我們的社會和發展軌跡。此外，當前的大型語言模型缺乏物理具身性，降低了它們理解形塑人類理解和表達的知覺、行動和認知之間複雜交互作用的能力。最終，心身學具有潛力對語言、認知和智慧的本質產生變革性的見解，無論是人工的還是生物的。此外，透過在大型語言模型和人類認知過程之間畫出平行線，心身學可以為更強大且更類似人類的 AI 系統的發展提供資訊。

##### **Enhancing LLM's Cognition via Structurization**
2407.16434v1 by Kai Liu, Zhihang Fu, Chao Chen, Wei Zhang, Rongxin Jiang, Fan Zhou, Yaowu Chen, Yue Wu, Jieping Ye

When reading long-form text, human cognition is complex and structurized.
While large language models (LLMs) process input contexts through a causal and
sequential perspective, this approach can potentially limit their ability to
handle intricate and complex inputs effectively. To enhance LLM's cognition
capability, this paper presents a novel concept of context structurization.
Specifically, we transform the plain, unordered contextual sentences into
well-ordered and hierarchically structurized elements. By doing so, LLMs can
better grasp intricate and extended contexts through precise attention and
information-seeking along the organized structures. Extensive evaluations are
conducted across various model architectures and sizes (including several 7B-
to 72B-size auto-regressive LLMs as well as BERT-like masking models) on a
diverse set of NLP tasks (e.g., context-based question-answering, exhaustive
hallucination evaluation, and passage-level dense retrieval). Empirical results
show consistent and significant performance gains afforded by a single-round
structurization. In particular, we boost a 72B-parameter open-source model to
achieve comparable performance against GPT-3.5-Turbo as the hallucination
evaluator. Besides, we show the feasibility of distilling advanced LLMs'
language processing abilities to a smaller yet effective StruXGPT-7B to execute
structurization, addressing the practicality of our approach. Code will be made
public soon.

摘要：在閱讀長篇文字時，人類認知是複雜且結構化的。
雖然大型語言模型 (LLM) 透過因果和順序觀點處理輸入背景，但這種方法可能會限制其有效處理複雜且錯綜複雜輸入的能力。為了增強 LLM 的認知能力，本文提出了一種新的背景結構化概念。
具體來說，我們將純粹的、無序的上下文句子轉換為井然有序且層次結構化的元素。藉此，LLM 可以透過沿著組織結構進行精確的注意和資訊搜尋，更好地掌握複雜且廣泛的背景。在各種模型架構和大小（包括幾個 7B 至 72B 大小的自迴歸 LLM 以及類似 BERT 的遮罩模型）上進行了廣泛的評估，針對各種 NLP 任務（例如，基於背景的問題解答、詳盡的幻覺評估和段落層級的密集檢索）進行評估。經驗結果顯示，單輪結構化提供了持續且顯著的效能提升。特別是，我們提升了一個 72B 參數的開源模型，以達到與 GPT-3.5-Turbo 相當的效能，作為幻覺評估器。此外，我們展示了將先進 LLM 的語言處理能力提煉到更小但有效的 StruXGPT-7B 以執行結構化的可行性，解決了我們方法的實用性。代碼將很快公開。

##### **FairFlow: An Automated Approach to Model-based Counterfactual Data Augmentation For NLP**
2407.16431v1 by Ewoenam Kwaku Tokpo, Toon Calders

Despite the evolution of language models, they continue to portray harmful
societal biases and stereotypes inadvertently learned from training data. These
inherent biases often result in detrimental effects in various applications.
Counterfactual Data Augmentation (CDA), which seeks to balance demographic
attributes in training data, has been a widely adopted approach to mitigate
bias in natural language processing. However, many existing CDA approaches rely
on word substitution techniques using manually compiled word-pair dictionaries.
These techniques often lead to out-of-context substitutions, resulting in
potential quality issues. The advancement of model-based techniques, on the
other hand, has been challenged by the need for parallel training data. Works
in this area resort to manually generated parallel data that are expensive to
collect and are consequently limited in scale. This paper proposes FairFlow, an
automated approach to generating parallel data for training counterfactual text
generator models that limits the need for human intervention. Furthermore, we
show that FairFlow significantly overcomes the limitations of dictionary-based
word-substitution approaches whilst maintaining good performance.

摘要：儘管語言模型不斷演進，它們仍會在無意間從訓練資料中習得有害的社會偏見和刻板印象。這些內在偏見通常會對各種應用程式造成不利影響。反事實資料擴充（CDA）旨在平衡訓練資料中的人口屬性，一直是廣泛採用的方法，用於減輕自然語言處理中的偏見。然而，許多現有的 CDA 方法依賴於使用手動編譯的字詞對字典進行字詞替換技術。這些技術通常會導致語境外替換，造成潛在的品質問題。另一方面，基於模型的技術進步受到平行訓練資料需求的挑戰。此領域的工作訴諸於手動產生的平行資料，而這些資料的收集成本高昂，因此規模有限。本文提出 FairFlow，一種自動化方法，用於產生平行資料，以訓練反事實文字產生器模型，並減少對人工介入的需求。此外，我們證明 FairFlow 明顯克服了基於字典的字詞替換方法的限制，同時維持良好的效能。

##### **On ADMM in Heterogeneous Federated Learning: Personalization, Robustness, and Fairness**
2407.16397v1 by Shengkun Zhu, Jinshan Zeng, Sheng Wang, Yuan Sun, Xiaodong Li, Yuan Yao, Zhiyong Peng

Statistical heterogeneity is a root cause of tension among accuracy,
fairness, and robustness of federated learning (FL), and is key in paving a
path forward. Personalized FL (PFL) is an approach that aims to reduce the
impact of statistical heterogeneity by developing personalized models for
individual users, while also inherently providing benefits in terms of fairness
and robustness. However, existing PFL frameworks focus on improving the
performance of personalized models while neglecting the global model. Moreover,
these frameworks achieve sublinear convergence rates and rely on strong
assumptions. In this paper, we propose FLAME, an optimization framework by
utilizing the alternating direction method of multipliers (ADMM) to train
personalized and global models. We propose a model selection strategy to
improve performance in situations where clients have different types of
heterogeneous data. Our theoretical analysis establishes the global convergence
and two kinds of convergence rates for FLAME under mild assumptions. We
theoretically demonstrate that FLAME is more robust and fair than the
state-of-the-art methods on a class of linear problems. Our experimental
findings show that FLAME outperforms state-of-the-art methods in convergence
and accuracy, and it achieves higher test accuracy under various attacks and
performs more uniformly across clients.

摘要：統計異質性是聯邦學習（FL）中準確性、公平性和穩健性之間緊張關係的根源，並且是鋪平前進道路的關鍵。個性化 FL（PFL）是一種旨在通過為個別用戶開發個性化模型來減少統計異質性的影響的方法，同時在公平性和穩健性方面也固有地提供好處。然而，現有的 PFL 框架側重於提高個性化模型的性能，同時忽視了全局模型。此外，這些框架實現了次線性收斂率，並依賴於強有力的假設。在本文中，我們提出了 FLAME，一個優化框架，利用乘法器交替方向方法 (ADMM) 來訓練個性化和全局模型。我們提出了一種模型選擇策略，以提高在客戶端具有不同類型異質數據的情況下的性能。我們的理論分析建立了 FLAME 在溫和假設下的全局收斂和兩種收斂率。我們從理論上證明了 FLAME 在一類線性問題上比最先進的方法更強大、更公平。我們的實驗結果表明，FLAME 在收斂性和準確性方面優於最先進的方法，並且在各種攻擊下實現了更高的測試準確性，並且在客戶端之間表現得更均勻。

##### **TookaBERT: A Step Forward for Persian NLU**
2407.16382v1 by MohammadAli SadraeiJavaheri, Ali Moghaddaszadeh, Milad Molazadeh, Fariba Naeiji, Farnaz Aghababaloo, Hamideh Rafiee, Zahra Amirmahani, Tohid Abedini, Fatemeh Zahra Sheikhi, Amirmohammad Salehoof

The field of natural language processing (NLP) has seen remarkable
advancements, thanks to the power of deep learning and foundation models.
Language models, and specifically BERT, have been key players in this progress.
In this study, we trained and introduced two new BERT models using Persian
data. We put our models to the test, comparing them to seven existing models
across 14 diverse Persian natural language understanding (NLU) tasks. The
results speak for themselves: our larger model outperforms the competition,
showing an average improvement of at least +2.8 points. This highlights the
effectiveness and potential of our new BERT models for Persian NLU tasks.

摘要：自然語言處理 (NLP) 領域已見證顯著進展，這歸功於深度學習和基礎模型的力量。語言模型，特別是 BERT，一直是這項進展中的關鍵參與者。在此研究中，我們使用波斯語資料訓練並引入了兩個新的 BERT 模型。我們對模型進行測試，將它們與 14 項不同的波斯語自然語言理解 (NLU) 任務中的七個現有模型進行比較。結果不言自明：我們較大的模型優於競爭對手，平均進步至少 +2.8 分。這突顯了我們新的 BERT 模型在波斯語 NLU 任務中的有效性和潛力。

##### **Ranking protein-protein models with large language models and graph neural networks**
2407.16375v1 by Xiaotong Xu, Alexandre M. J. J. Bonvin

Protein-protein interactions (PPIs) are associated with various diseases,
including cancer, infections, and neurodegenerative disorders. Obtaining
three-dimensional structural information on these PPIs serves as a foundation
to interfere with those or to guide drug design. Various strategies can be
followed to model those complexes, all typically resulting in a large number of
models. A challenging step in this process is the identification of good models
(near-native PPI conformations) from the large pool of generated models. To
address this challenge, we previously developed DeepRank-GNN-esm, a graph-based
deep learning algorithm for ranking modelled PPI structures harnessing the
power of protein language models. Here, we detail the use of our software with
examples. DeepRank-GNN-esm is freely available at
https://github.com/haddocking/DeepRank-GNN-esm

摘要：蛋白-蛋白交互作用 (PPI) 與各種疾病相關，包括癌症、感染和神經退化性疾病。取得這些 PPI 的三維結構資訊，作為干擾它們或引導藥物設計的基礎。可以遵循各種策略來建模這些複合體，所有這些策略通常會產生大量的模型。此過程中的挑戰性步驟，是從大量產生的模型中找出好的模型（接近原生 PPI 構象）。為了應對這個挑戰，我們之前開發了 DeepRank-GNN-esm，這是一種基於圖形的深度學習演算法，用於對建模的 PPI 結構進行排名，利用蛋白質語言模型的力量。在這裡，我們詳細說明了我們軟體的使用範例。DeepRank-GNN-esm 可在 https://github.com/haddocking/DeepRank-GNN-esm 免費取得

##### **Evolutionary Prompt Design for LLM-Based Post-ASR Error Correction**
2407.16370v1 by Rithik Sachdev, Zhong-Qiu Wang, Chao-Han Huck Yang

Building upon the strength of modern large language models (LLMs), generative
error correction (GEC) has emerged as a promising paradigm that can elevate the
performance of modern automatic speech recognition (ASR) systems. One
representative approach is to leverage in-context learning to prompt LLMs so
that a better hypothesis can be generated by the LLMs based on a
carefully-designed prompt and an $N$-best list of hypotheses produced by ASR
systems. However, it is yet unknown whether the existing prompts are the most
effective ones for the task of post-ASR error correction. In this context, this
paper first explores alternative prompts to identify an initial set of
effective prompts, and then proposes to employ an evolutionary prompt
optimization algorithm to refine the initial prompts. Evaluations results on
the CHiME-4 subset of the Task $1$ of the SLT $2024$ GenSEC challenge show the
effectiveness and potential of the proposed algorithms.

摘要：建立在現代大型語言模型 (LLM) 的優勢上，生成式錯誤修正 (GEC) 已成為一種有前途的範例，可以提升現代自動語音辨識 (ASR) 系統的效能。一種具代表性的方法是利用情境學習提示 LLM，以便 LLM 能根據精心設計的提示和 ASR 系統產生的 N 個最佳假設清單，產生更好的假設。然而，目前尚不知道現有的提示是否最適合於 ASR 後錯誤修正任務。在此背景下，本文首先探討替代提示以找出初始的一組有效提示，然後提出採用演化提示最佳化演算法來改善初始提示。在 SLT 2024 GenSEC 挑戰任務 1 的 CHiME-4 子集上進行的評量結果顯示了所提出的演算法的有效性和潛力。

##### **TWIN V2: Scaling Ultra-Long User Behavior Sequence Modeling for Enhanced CTR Prediction at Kuaishou**
2407.16357v1 by Zihua Si, Lin Guan, ZhongXiang Sun, Xiaoxue Zang, Jing Lu, Yiqun Hui, Xingchao Cao, Zeyu Yang, Yichen Zheng, Dewei Leng, Kai Zheng, Chenbin Zhang, Yanan Niu, Yang Song, Kun Gai

The significance of modeling long-term user interests for CTR prediction
tasks in large-scale recommendation systems is progressively gaining attention
among researchers and practitioners. Existing work, such as SIM and TWIN,
typically employs a two-stage approach to model long-term user behavior
sequences for efficiency concerns. The first stage rapidly retrieves a subset
of sequences related to the target item from a long sequence using a
search-based mechanism namely the General Search Unit (GSU), while the second
stage calculates the interest scores using the Exact Search Unit (ESU) on the
retrieved results. Given the extensive length of user behavior sequences
spanning the entire life cycle, potentially reaching up to 10^6 in scale, there
is currently no effective solution for fully modeling such expansive user
interests. To overcome this issue, we introduced TWIN-V2, an enhancement of
TWIN, where a divide-and-conquer approach is applied to compress life-cycle
behaviors and uncover more accurate and diverse user interests. Specifically, a
hierarchical clustering method groups items with similar characteristics in
life-cycle behaviors into a single cluster during the offline phase. By
limiting the size of clusters, we can compress behavior sequences well beyond
the magnitude of 10^5 to a length manageable for online inference in GSU
retrieval. Cluster-aware target attention extracts comprehensive and
multi-faceted long-term interests of users, thereby making the final
recommendation results more accurate and diverse. Extensive offline experiments
on a multi-billion-scale industrial dataset and online A/B tests have
demonstrated the effectiveness of TWIN-V2. Under an efficient deployment
framework, TWIN-V2 has been successfully deployed to the primary traffic that
serves hundreds of millions of daily active users at Kuaishou.

摘要：長期使用者興趣建模對於大規模推薦系統中的點擊率預測任務的重要性，正逐漸受到研究人員和實務工作者的關注。現有的工作，例如 SIM 和 TWIN，通常採用兩階段方法來建模長期使用者行為序列，以考量效率問題。第一階段使用基於搜尋的機制（即通用搜尋單元 (GSU)）從長序列中快速擷取與目標項目相關的子序列，而第二階段則使用精確搜尋單元 (ESU) 計算擷取結果中的興趣分數。考量到使用者行為序列的廣泛長度涵蓋整個生命週期，潛在規模可能達到 10^6，目前沒有有效的解決方案可以完全建模如此廣泛的使用者興趣。為了克服這個問題，我們引入了 TWIN-V2，它是 TWIN 的增強版本，其中應用分而治之的方法來壓縮生命週期行為，並揭示更準確且多樣化的使用者興趣。具體來說，分層式群集方法在離線階段將生命週期行為中具有類似特徵的項目分組到單一群集中。透過限制群集大小，我們可以將行為序列壓縮到遠遠超過 10^5 的數量，以達到 GSU 擷取中線上推論可以管理的長度。具群集意識的目標注意提取使用者全面且多面向的長期興趣，從而使最終的推薦結果更準確且多樣化。在多達數十億規模的產業資料集和線上 A/B 測試上的廣泛離線實驗已證明 TWIN-V2 的有效性。在一個高效的部署架構下，TWIN-V2 已成功部署到主要流量，每天為快手數億活躍使用者提供服務。

##### **FACTTRACK: Time-Aware World State Tracking in Story Outlines**
2407.16347v1 by Zhiheng Lyu, Kevin Yang, Lingpeng Kong, Daniel Klein

While accurately detecting and correcting factual contradictions in language
model outputs has become increasingly important as their capabilities improve,
doing so is highly challenging. We propose a novel method, FACTTRACK, for
tracking atomic facts and addressing factual contradictions. Crucially,
FACTTRACK also maintains time-aware validity intervals for each fact, allowing
for change over time. At a high level, FACTTRACK consists of a four-step
pipeline to update a world state data structure for each new event: (1)
decompose the event into directional atomic facts; (2) determine the validity
interval of each atomic fact using the world state; (3) detect contradictions
with existing facts in the world state; and finally (4) add new facts to the
world state and update existing atomic facts. When we apply FACTTRACK to
contradiction detection on structured story outlines, we find that FACTTRACK
using LLaMA2-7B-Chat substantially outperforms a fair baseline using
LLaMA2-7B-Chat, and achieves performance comparable to a GPT4 baseline.
Moreover, when using GPT4, FACTTRACK significantly outperforms the GPT4
baseline.

摘要：随着语言模型输出中事实矛盾的准确检测和纠正变得越来越重要，执行此操作极具挑战性。我们提出了一种新方法 FACTTRACK，用于跟踪原子事实并解决事实矛盾。至关重要的是，FACTTRACK 还为每个事实维护时间感知的有效性间隔，从而允许随着时间的推移而发生变化。在高层次上，FACTTRACK 由一个四步管道组成，用于为每个新事件更新世界状态数据结构：(1) 将事件分解为方向原子事实；(2) 使用世界状态确定每个原子事实的有效性间隔；(3) 检测与世界状态中现有事实的矛盾；最后 (4) 将新事实添加到世界状态并更新现有的原子事实。当我们将 FACTTRACK 应用于结构化故事大纲中的矛盾检测时，我们发现使用 LLaMA2-7B-Chat 的 FACTTRACK 明显优于使用 LLaMA2-7B-Chat 的公平基线，并且实现了与 GPT4 基线相当的性能。此外，在使用 GPT4 时，FACTTRACK 明显优于 GPT4 基线。

##### **SOAP: Enhancing Spatio-Temporal Relation and Motion Information Capturing for Few-Shot Action Recognition**
2407.16344v1 by Wenbo Huang, Jinghui Zhang, Xuwei Qian, Zhen Wu, Meng Wang, Lei Zhang

High frame-rate (HFR) videos of action recognition improve fine-grained
expression while reducing the spatio-temporal relation and motion information
density. Thus, large amounts of video samples are continuously required for
traditional data-driven training. However, samples are not always sufficient in
real-world scenarios, promoting few-shot action recognition (FSAR) research. We
observe that most recent FSAR works build spatio-temporal relation of video
samples via temporal alignment after spatial feature extraction, cutting apart
spatial and temporal features within samples. They also capture motion
information via narrow perspectives between adjacent frames without considering
density, leading to insufficient motion information capturing. Therefore, we
propose a novel plug-and-play architecture for FSAR called Spatio-tempOral
frAme tuPle enhancer (SOAP) in this paper. The model we designed with such
architecture refers to SOAP-Net. Temporal connections between different feature
channels and spatio-temporal relation of features are considered instead of
simple feature extraction. Comprehensive motion information is also captured,
using frame tuples with multiple frames containing more motion information than
adjacent frames. Combining frame tuples of diverse frame counts further
provides a broader perspective. SOAP-Net achieves new state-of-the-art
performance across well-known benchmarks such as SthSthV2, Kinetics, UCF101,
and HMDB51. Extensive empirical evaluations underscore the competitiveness,
pluggability, generalization, and robustness of SOAP. The code is released at
https://github.com/wenbohuang1002/SOAP.

摘要：高帧率 (HFR) 动作识别影片改善了细微表情，同时降低了时空关系和动作信息密度。因此，传统数据驱动训练持续需要大量的影片样本。然而，在实际场景中，样本并不总是足够，促进了少样本动作识别 (FSAR) 研究。我们观察到，最近的大多数 FSAR 工作在空间特征提取后通过时间对齐建立影片样本的时空关系，切分样本内的空间和时间特征。它们还通过相邻帧之间的狭窄视角捕捉动作信息，而不考虑密度，导致动作信息捕捉不足。因此，我们在本文中提出了一种用于 FSAR 的新型即插即用架构，称为时空帧元组增强器 (SOAP)。我们使用这种架构设计的模型称为 SOAP-Net。它考虑了不同特征通道之间的临时连接和特征的时空关系，而不是简单的特征提取。它还使用包含比相邻帧更多动作信息的多个帧的帧元组捕获全面的动作信息。进一步组合不同帧数的帧元组提供了更广阔的视角。SOAP-Net 在 SthSthV2、Kinetics、UCF101 和 HMDB51 等知名基准测试中取得了新的最先进性能。广泛的实证评估突出了 SOAP 的竞争力、可插拔性、泛化性和鲁棒性。代码已在 https://github.com/wenbohuang1002/SOAP 发布。

##### **PhenoFlow: A Human-LLM Driven Visual Analytics System for Exploring Large and Complex Stroke Datasets**
2407.16329v1 by Jaeyoung Kim, Sihyeon Lee, Hyeon Jeon, Keon-Joo Lee, Hee-Joon Bae, Bohyoung Kim, Jinwook Seo

Acute stroke demands prompt diagnosis and treatment to achieve optimal
patient outcomes. However, the intricate and irregular nature of clinical data
associated with acute stroke, particularly blood pressure (BP) measurements,
presents substantial obstacles to effective visual analytics and
decision-making. Through a year-long collaboration with experienced
neurologists, we developed PhenoFlow, a visual analytics system that leverages
the collaboration between human and Large Language Models (LLMs) to analyze the
extensive and complex data of acute ischemic stroke patients. PhenoFlow
pioneers an innovative workflow, where the LLM serves as a data wrangler while
neurologists explore and supervise the output using visualizations and natural
language interactions. This approach enables neurologists to focus more on
decision-making with reduced cognitive load. To protect sensitive patient
information, PhenoFlow only utilizes metadata to make inferences and synthesize
executable codes, without accessing raw patient data. This ensures that the
results are both reproducible and interpretable while maintaining patient
privacy. The system incorporates a slice-and-wrap design that employs temporal
folding to create an overlaid circular visualization. Combined with a linear
bar graph, this design aids in exploring meaningful patterns within irregularly
measured BP data. Through case studies, PhenoFlow has demonstrated its
capability to support iterative analysis of extensive clinical datasets,
reducing cognitive load and enabling neurologists to make well-informed
decisions. Grounded in long-term collaboration with domain experts, our
research demonstrates the potential of utilizing LLMs to tackle current
challenges in data-driven clinical decision-making for acute ischemic stroke
patients.

摘要：<paragraph>急性中風需要迅速診斷和治療，才能達到最佳的病人治療結果。然而，與急性中風相關的臨床資料複雜且不規則，特別是血壓 (BP) 測量，對有效的視覺分析和決策制定構成重大障礙。透過與經驗豐富的神經科醫師長達一年的合作，我們開發了 PhenoFlow，這是一個視覺分析系統，利用人與大型語言模型 (LLM) 之間的協作來分析急性缺血性中風患者的廣泛且複雜資料。PhenoFlow 開創了一種創新的工作流程，其中 LLM 擔任資料整理員，而神經科醫師則使用視覺化和自然語言互動來探索和監督輸出。這種方法使神經科醫師能夠更專注於決策制定，同時降低認知負擔。為了保護敏感的病人資訊，PhenoFlow 僅利用元資料進行推論並合成可執行程式碼，而不會存取原始病人資料。這確保了結果既可重現又可解釋，同時維護病人的隱私。該系統採用分段和包裝設計，採用時間摺疊來建立疊加的圓形視覺化。結合線性長條圖，此設計有助於探索不規則測量血壓資料中的有意義模式。透過案例研究，PhenoFlow 已證明其支援對廣泛臨床資料集進行反覆分析的能力，降低認知負擔並使神經科醫師能夠做出明智的決策。我們的研究以與領域專家長期合作為基礎，證明了利用 LLM 來應對當前急性缺血性中風患者資料驅動臨床決策制定挑戰的潛力。</paragraph>

##### **PrimeGuard: Safe and Helpful LLMs through Tuning-Free Routing**
2407.16318v1 by Blazej Manczak, Eliott Zemour, Eric Lin, Vaikkunth Mugunthan

Deploying language models (LMs) necessitates outputs to be both high-quality
and compliant with safety guidelines. Although Inference-Time Guardrails (ITG)
offer solutions that shift model output distributions towards compliance, we
find that current methods struggle in balancing safety with helpfulness. ITG
Methods that safely address non-compliant queries exhibit lower helpfulness
while those that prioritize helpfulness compromise on safety. We refer to this
trade-off as the guardrail tax, analogous to the alignment tax. To address
this, we propose PrimeGuard, a novel ITG method that utilizes structured
control flow.
  PrimeGuard routes requests to different self-instantiations of the LM with
varying instructions, leveraging its inherent instruction-following
capabilities and in-context learning. Our tuning-free approach dynamically
compiles system-designer guidelines for each query. We construct and release
safe-eval, a diverse red-team safety benchmark. Extensive evaluations
demonstrate that PrimeGuard, without fine-tuning, overcomes the guardrail tax
by (1) significantly increasing resistance to iterative jailbreak attacks and
(2) achieving state-of-the-art results in safety guardrailing while (3)
matching helpfulness scores of alignment-tuned models. Extensive evaluations
demonstrate that PrimeGuard, without fine-tuning, outperforms all competing
baselines and overcomes the guardrail tax by improving the fraction of safe
responses from 61% to 97% and increasing average helpfulness scores from 4.17
to 4.29 on the largest models, while reducing attack success rate from 100% to
8%.
  PrimeGuard implementation is available at
https://github.com/dynamofl/PrimeGuard and safe-eval dataset is available at
https://huggingface.co/datasets/dynamoai/safe_eval.

摘要：<paragraph>部署語言模型 (LM) 需要輸出既要高品質，又要符合安全準則。儘管推論時間護欄 (ITG) 提供了解決方案，將模型輸出分佈轉移到合規性，我們發現當前方法在平衡安全性與實用性方面遇到困難。ITG 方法安全地處理不符合規範的查詢，表現出較低的實用性，而優先考慮實用性的方法則會影響安全性。我們將這種權衡稱為護欄稅，類似於對齊稅。為了解決這個問題，我們提出了 PrimeGuard，這是一種利用結構化控制流的新型 ITG 方法。
PrimeGuard 將請求路由到 LM 的不同自實例化，並附有不同的指示，利用其固有的指令遵循能力和情境學習。我們的無調校方法會動態編譯每個查詢的系統設計人員指南。我們構建並發布 safe-eval，這是一個多樣化的紅隊安全基準。廣泛的評估表明，PrimeGuard 在沒有微調的情況下，通過 (1) 大幅提高對反覆越獄攻擊的抵抗力，以及 (2) 在安全護欄中取得最先進的成果，同時 (3) 匹配對齊調整模型的實用性分數，克服了護欄稅。廣泛的評估表明，PrimeGuard 在沒有微調的情況下，優於所有競爭基準，並通過將安全回應的比例從 61% 提高到 97%，並將平均實用性分數從 4.17 提高到 4.29（在最大的模型上），同時將攻擊成功率從 100% 降低到 8%，克服了護欄稅。
PrimeGuard 實作可以在 https://github.com/dynamofl/PrimeGuard 取得，而 safe-eval 資料集可以在 https://huggingface.co/datasets/dynamoai/safe_eval 取得。</paragraph>

##### **Quantum Computing for Climate Resilience and Sustainability Challenges**
2407.16296v1 by Kin Tung Michael Ho, Kuan-Cheng Chen, Lily Lee, Felix Burt, Shang Yu, Po-Heng, Lee

The escalating impacts of climate change and the increasing demand for
sustainable development and natural resource management necessitate innovative
technological solutions. Quantum computing (QC) has emerged as a promising tool
with the potential to revolutionize these critical areas. This review explores
the application of quantum machine learning and optimization techniques for
climate change prediction and enhancing sustainable development. Traditional
computational methods often fall short in handling the scale and complexity of
climate models and natural resource management. Quantum advancements, however,
offer significant improvements in computational efficiency and problem-solving
capabilities. By synthesizing the latest research and developments, this paper
highlights how QC and quantum machine learning can optimize
multi-infrastructure systems towards climate neutrality. The paper also
evaluates the performance of current quantum algorithms and hardware in
practical applications and presents realistic cases, i.e., waste-to-energy in
anaerobic digestion, disaster prevention in flooding prediction, and new
material development for carbon capture. The integration of these quantum
technologies promises to drive significant advancements in achieving climate
resilience and sustainable development.

摘要：氣候變遷影響日益升高，加上永續發展與自然資源管理需求日增，使得創新的科技解決方案勢在必行。量子運算 (QC) 已成為一項充滿希望的工具，有潛力革新這些關鍵領域。本篇評論探討量子機器學習和最佳化技術在氣候變遷預測和加強永續發展中的應用。傳統的計算方法通常無法處理氣候模型和自然資源管理的規模和複雜性。然而，量子技術的進步在計算效率和問題解決能力方面提供了顯著的提升。透過綜合最新的研究和發展，本文重點說明 QC 和量子機器學習如何最佳化多基礎架構系統以邁向氣候中立。本文也評估了當前量子演算法和硬體在實際應用中的效能，並提出實際案例，例如厭氧消化中的廢棄物轉能、洪水預測中的災害預防，以及碳捕捉的新材料開發。整合這些量子技術有望推動氣候復原力和永續發展的重大進展。

##### **Visual Stereotypes of Autism Spectrum in DALL-E, Stable Diffusion, SDXL, and Midjourney**
2407.16292v1 by Maciej Wodziński, Marcin Rządeczka, Anastazja Szuła, Marta Sokół, Marcin Moskalewicz

Avoiding systemic discrimination requires investigating AI models' potential
to propagate stereotypes resulting from the inherent biases of training
datasets. Our study investigated how text-to-image models unintentionally
perpetuate non-rational beliefs regarding autism. The research protocol
involved generating images based on 53 prompts aimed at visualizing concrete
objects and abstract concepts related to autism across four models: DALL-E,
Stable Diffusion, SDXL, and Midjourney (N=249). Expert assessment of results
was performed via a framework of 10 deductive codes representing common
stereotypes contested by the community regarding their presence and spatial
intensity, quantified on ordinal scales and subject to statistical analysis of
inter-rater reliability and size effects. The models frequently utilised
controversial themes and symbols which were unevenly distributed, however, with
striking homogeneity in terms of skin colour, gender, and age, with autistic
individuals portrayed as engaged in solitary activities, interacting with
objects rather than people, and displaying stereotypical emotional expressions
such as pale, anger, or sad. Secondly we observed representational
insensitivity regarding autism images despite directional prompting aimed at
falsifying the above results. Additionally, DALL-E explicitly denied
perpetuating stereotypes. We interpret this as ANNs mirroring the human
cognitive architecture regarding the discrepancy between background and
reflective knowledge, as justified by our previous research on autism-related
stereotypes in humans.

摘要：避免系統性歧視需要調查 AI 模型潛在的風險，以宣傳由訓練資料集的內在偏差所產生的刻板印象。我們的研究調查了文字轉圖像模型如何無意間延續了關於自閉症的非理性信念。研究協定包括根據 53 個提示產生圖像，旨在視覺化具體物體和與自閉症相關的抽象概念，涉及四個模型：DALL-E、Stable Diffusion、SDXL 和 Midjourney (N=249)。結果的專家評估是透過一個包含 10 個演繹碼的架構進行，代表常見的刻板印象，這些刻板印象受到社群挑戰，質疑其存在和空間強度，在序數尺度上量化，並受制於評分者間信度和效應量統計分析。這些模型經常使用有爭議的主題和符號，但分佈不均，然而，在膚色、性別和年齡方面具有驚人的同質性，自閉症患者被描繪成從事單獨活動、與物體而非人互動，並表現出刻板的情緒表達，例如蒼白、憤怒或悲傷。其次，我們觀察到關於自閉症圖像的表徵麻木不仁，儘管有針對性的提示旨在證偽上述結果。此外，DALL-E 明確否認了延續刻板印象。我們將此解釋為 ANN 反映了人類認知架構，涉及背景和反思知識之間的差異，正如我們之前對人類自閉症相關刻板印象的研究所證明的。

##### **Federated Learning for Face Recognition via Intra-subject Self-supervised Learning**
2407.16289v1 by Hansol Kim, Hoyeol Choi, Youngjun Kwak

Federated Learning (FL) for face recognition aggregates locally optimized
models from individual clients to construct a generalized face recognition
model. However, previous studies present two major challenges: insufficient
incorporation of self-supervised learning and the necessity for clients to
accommodate multiple subjects. To tackle these limitations, we propose FedFS
(Federated Learning for personalized Face recognition via intra-subject
Self-supervised learning framework), a novel federated learning architecture
tailored to train personalized face recognition models without imposing
subjects. Our proposed FedFS comprises two crucial components that leverage
aggregated features of the local and global models to cooperate with
representations of an off-the-shelf model. These components are (1) adaptive
soft label construction, utilizing dot product operations to reformat labels
within intra-instances, and (2) intra-subject self-supervised learning,
employing cosine similarity operations to strengthen robust intra-subject
representations. Additionally, we introduce a regularization loss to prevent
overfitting and ensure the stability of the optimized model. To assess the
effectiveness of FedFS, we conduct comprehensive experiments on the DigiFace-1M
and VGGFace datasets, demonstrating superior performance compared to previous
methods.

摘要：联邦学习 (FL) 用于人脸识别，它聚合来自各个客户端的局部优化模型，以构建一个通用的人脸识别模型。然而，先前的研究提出了两个主要挑战：自监督学习的整合不足，以及客户端必须适应多个主题的必要性。为了解决这些限制，我们提出了 FedFS（用于通过主题内自监督学习框架进行个性化人脸识别的联邦学习），这是一种新颖的联邦学习架构，专门用于训练个性化人脸识别模型，而无需强加主题。我们提出的 FedFS 包含两个关键组件，它们利用局部模型和全局模型的聚合特征与现成模型的表示进行协作。这些组件是 (1) 自适应软标签构建，利用点积运算来重新格式化实例内部的标签，以及 (2) 主题内自监督学习，利用余弦相似性运算来加强稳健的主题内表示。此外，我们引入了一个正则化损失来防止过度拟合并确保优化模型的稳定性。为了评估 FedFS 的有效性，我们对 DigiFace-1M 和 VGGFace 数据集进行了全面的实验，与以前的方法相比，展示了卓越的性能。

##### **A deeper look at depth pruning of LLMs**
2407.16286v1 by Shoaib Ahmed Siddiqui, Xin Dong, Greg Heinrich, Thomas Breuel, Jan Kautz, David Krueger, Pavlo Molchanov

Large Language Models (LLMs) are not only resource-intensive to train but
even more costly to deploy in production. Therefore, recent work has attempted
to prune blocks of LLMs based on cheap proxies for estimating block importance,
effectively removing 10% of blocks in well-trained LLaMa-2 and Mistral 7b
models without any significant degradation of downstream metrics. In this
paper, we explore different block importance metrics by considering adaptive
metrics such as Shapley value in addition to static ones explored in prior
work. We show that adaptive metrics exhibit a trade-off in performance between
tasks i.e., improvement on one task may degrade performance on the other due to
differences in the computed block influences. Furthermore, we extend this
analysis from a complete block to individual self-attention and feed-forward
layers, highlighting the propensity of the self-attention layers to be more
amendable to pruning, even allowing removal of upto 33% of the self-attention
layers without incurring any performance degradation on MMLU for Mistral 7b
(significant reduction in costly maintenance of KV-cache). Finally, we look at
simple performance recovery techniques to emulate the pruned layers by training
lightweight additive bias or low-rank linear adapters. Performance recovery
using emulated updates avoids performance degradation for the initial blocks
(up to 5% absolute improvement on MMLU), which is either competitive or
superior to the learning-based technique.

摘要：大型語言模型 (LLM) 不僅訓練資源密集，部署至生產環境的成本更高。因此，最近的研究嘗試根據估計區塊重要性的廉價代理來修剪 LLM 區塊，有效地移除了訓練良好的 LLaMa-2 和 Mistral 7b 模型中 10% 的區塊，而不會顯著降低下游指標。在本文中，我們除了探討先前研究中探索的靜態指標外，還考慮了 Shapley 值等自適應指標，來探索不同的區塊重要性指標。我們展示了自適應指標在任務之間的性能權衡，即在一個任務上的改進可能會由於計算的區塊影響的差異而降低在另一個任務上的性能。此外，我們將此分析從一個完整區塊擴展到個別自注意力和前饋層，突出了自注意力層更容易進行修剪的傾向，甚至允許移除多達 33% 的自注意力層，而不會對 Mistral 7b 的 MMLU 造成任何性能下降（大幅減少 KV 快取的昂貴維護）。最後，我們探討了簡單的性能恢復技術，通過訓練輕量級加性偏差或低秩線性適配器來模擬修剪的層。使用模擬更新的性能恢復避免了初始區塊的性能下降（在 MMLU 上絕對提升高達 5%），這與基於學習的技術相比具有競爭力或優勢。

##### **Efficient Detection of Commutative Factors in Factor Graphs**
2407.16280v1 by Malte Luttermann, Johann Machemer, Marcel Gehrke

Lifted probabilistic inference exploits symmetries in probabilistic graphical
models to allow for tractable probabilistic inference with respect to domain
sizes. To exploit symmetries in, e.g., factor graphs, it is crucial to identify
commutative factors, i.e., factors having symmetries within themselves due to
their arguments being exchangeable. The current state of the art to check
whether a factor is commutative with respect to a subset of its arguments
iterates over all possible subsets of the factor's arguments, i.e., $O(2^n)$
iterations for a factor with $n$ arguments in the worst case. In this paper, we
efficiently solve the problem of detecting commutative factors in a factor
graph. In particular, we introduce the detection of commutative factors (DECOR)
algorithm, which allows us to drastically reduce the computational effort for
checking whether a factor is commutative in practice. We prove that DECOR
efficiently identifies restrictions to drastically reduce the number of
required iterations and validate the efficiency of DECOR in our empirical
evaluation.

摘要：提升的概率推理利用概率图形模型中的对称性，以允许对于域大小进行易于处理的概率推理。为了利用对称性，例如，因子图，至关重要的是识别可交换因子，即，由于其自变量可交换而自身具有对称性的因子。当前最先进的检查因子是否相对于其自变量的子集可交换的方法是对因子的所有可能子集进行迭代，即，对于最坏情况下的具有 n 个自变量的因子，进行 O(2^n) 次迭代。在本文中，我们有效地解决了在因子图中检测可交换因子的问题。具体而言，我们引入了可交换因子检测 (DECOR) 算法，该算法使我们能够大幅减少在实践中检查因子是否可交换的计算工作量。我们证明了 DECOR 有效地识别限制以大幅减少所需的迭代次数，并在我们的经验评估中验证了 DECOR 的效率。

##### **Beyond Binary Gender: Evaluating Gender-Inclusive Machine Translation with Ambiguous Attitude Words**
2407.16266v1 by Yijie Chen, Yijin Liu, Fandong Meng, Jinan Xu, Yufeng Chen, Jie Zhou

Gender bias has been a focal point in the study of bias in machine
translation and language models. Existing machine translation gender bias
evaluations are primarily focused on male and female genders, limiting the
scope of the evaluation. To assess gender bias accurately, these studies often
rely on calculating the accuracy of gender pronouns or the masculine and
feminine attributes of grammatical gender via the stereotypes triggered by
occupations or sentiment words ({\em i.e.}, clear positive or negative
attitude), which cannot extend to non-binary groups. This study presents a
benchmark AmbGIMT (Gender-Inclusive Machine Translation with Ambiguous attitude
words), which assesses gender bias beyond binary gender. Meanwhile, we propose
a novel process to evaluate gender bias based on the Emotional Attitude Score
(EAS), which is used to quantify ambiguous attitude words. In evaluating three
recent and effective open-source LLMs and one powerful multilingual
translation-specific model, our main observations are: (1) The translation
performance within non-binary gender contexts is markedly inferior in terms of
translation quality and exhibits more negative attitudes than binary-gender
contexts. (2) The analysis experiments indicate that incorporating constraint
context in prompts for gender identity terms can substantially reduce
translation bias, while the bias remains evident despite the presence of the
constraints. The code is publicly available at
\url{https://github.com/pppa2019/ambGIMT}.

摘要：性別偏見一直是機器翻譯和語言模型中偏見研究的焦點。現有的機器翻譯性別偏見評估主要集中在男性和女性性別上，限制了評估的範圍。為了準確評估性別偏見，這些研究通常依賴於計算性別代詞的準確性或語法性別的陽性和陰性屬性，通過職業或情感詞（即明顯的正面或負面態度）觸發的刻板印象，這無法擴展到非二元群體。本研究提出了 AmbGIMT（含義模糊態度詞的性別包容機器翻譯）基準，它評估了超越二元性別的性別偏見。同時，我們提出了一個基於情緒態度分數 (EAS) 的新過程來評估性別偏見，該分數用於量化含義模糊的態度詞。在評估三個最新且有效的開源 LLM 和一個強大的多語言翻譯特定模型時，我們的觀察結果如下：(1) 非二元性別語境中的翻譯性能明顯低於翻譯品質，並且表現出比二元性別語境更消極的態度。(2) 分析實驗表明，在性別認同術語的提示中加入約束語境可以大幅減少翻譯偏見，而儘管存在約束，偏見仍然很明顯。代碼可在 \url{https://github.com/pppa2019/ambGIMT} 公開獲得。

##### **Self-Reasoning Assistant Learning for non-Abelian Gauge Fields Design**
2407.16255v1 by Jinyang Sun, Xi Chen, Xiumei Wang, Dandan Zhu, Xingping Zhou

Non-Abelian braiding has attracted substantial attention because of its
pivotal role in describing the exchange behaviour of anyons, in which the input
and outcome of non-Abelian braiding are connected by a unitary matrix.
Implementing braiding in a classical system can assist the experimental
investigation of non-Abelian physics. However, the design of non-Abelian gauge
fields faces numerous challenges stemmed from the intricate interplay of group
structures, Lie algebra properties, representation theory, topology, and
symmetry breaking. The extreme diversity makes it a powerful tool for the study
of condensed matter physics. Whereas the widely used artificial intelligence
with data-driven approaches has greatly promoted the development of physics,
most works are limited on the data-to-data design. Here we propose a
self-reasoning assistant learning framework capable of directly generating
non-Abelian gauge fields. This framework utilizes the forward diffusion process
to capture and reproduce the complex patterns and details inherent in the
target distribution through continuous transformation. Then the reverse
diffusion process is used to make the generated data closer to the distribution
of the original situation. Thus, it owns strong self-reasoning capabilities,
allowing to automatically discover the feature representation and capture more
subtle relationships from the dataset. Moreover, the self-reasoning eliminates
the need for manual feature engineering and simplifies the process of model
building. Our framework offers a disruptive paradigm shift to parse complex
physical processes, automatically uncovering patterns from massive datasets.

摘要：非阿貝爾編織因其在描述任意子的交換行為中扮演的關鍵角色而備受關注，其中非阿貝爾編織的輸入和輸出由一個酉矩陣連接。在經典系統中實施編織可以協助非阿貝爾物理的實驗研究。然而，非阿貝爾規範場的設計面臨許多挑戰，這些挑戰源於群結構、李代數性質、表示理論、拓撲和對稱性破缺的複雜相互作用。極端的多樣性使其成為研究凝聚態物理的有力工具。儘管廣泛使用的人工智慧和數據驅動方法極大地促进了物理學的發展，但大多數工作都局限於數據到數據的設計。在此，我們提出了一個自推理輔助學習框架，能夠直接生成非阿貝爾規範場。此框架利用正向擴散過程來捕獲和重現目標分佈中固有的複雜模式和細節，通過連續轉換。然後使用反向擴散過程使生成的數據更接近原始情況的分布。因此，它擁有強大的自推理能力，可以自動發現特徵表示並從數據集中捕獲更微妙的關係。此外，自推理消除了對手動特徵工程的需求，並簡化了模型構建的過程。我們的框架提供了一個顛覆性的範式轉變，用於解析複雜的物理過程，自動從海量數據集中發現模式。

##### **LawLuo: A Chinese Law Firm Co-run by LLM Agents**
2407.16252v1 by Jingyun Sun, Chengxiao Dai, Zhongze Luo, Yangbo Chang, Yang Li

Large Language Models (LLMs) demonstrate substantial potential in delivering
legal consultation services to users without a legal background, attributed to
their superior text comprehension and generation capabilities. Nonetheless,
existing Chinese legal LLMs limit interaction to a single model-user dialogue,
unlike the collaborative consultations typical of law firms, where multiple
staff members contribute to a single consultation. This limitation prevents an
authentic consultation experience. Additionally, extant Chinese legal LLMs
suffer from critical limitations: (1) insufficient control over the quality of
instruction fine-tuning data; (2) increased model hallucination resulting from
users' ambiguous queries; and (3) a reduction in the model's ability to follow
instructions over multiple dialogue turns. In response to these challenges, we
propose a novel legal dialogue framework that leverages the collaborative
capabilities of multiple LLM agents, termed LawLuo. This framework encompasses
four agents: a receptionist, a lawyer, a secretary, and a boss, each
responsible for different functionalities, collaboratively providing a
comprehensive legal consultation to users. Additionally, we constructed two
high-quality legal dialogue datasets, KINLED and MURLED, and fine-tuned
ChatGLM-3-6b using these datasets. We propose a legal query clarification
algorithm called ToLC. Experimental results demonstrate that LawLuo outperforms
baseline LLMs, including GPT-4, across three dimensions: lawyer-like language
style, the usefulness of legal advice, and the accuracy of legal knowledge. Our
code and datasets are available at https://github.com/NEFUJing/LawLuo.

摘要：大型語言模型 (LLM) 在為沒有法律背景的使用者提供法律諮詢服務方面展現出巨大的潛力，這要歸功於它們卓越的文本理解和產生能力。儘管如此，現有的中文法律 LLM 將互動限制在單一的模型使用者對話中，這與律師事務所常見的協作諮詢不同，在律師事務所中，多位員工會共同參與單一諮詢。這種限制阻礙了真實的諮詢體驗。此外，現有的中文法律 LLM 存在嚴重的限制：(1) 對指令微調資料品質的控制不足；(2) 使用者模稜兩可的查詢導致模型出現更多幻覺；(3) 模型在多個對話回合中遵循指令的能力下降。為了應對這些挑戰，我們提出了一個新穎的法律對話框架，利用多個 LLM 代理的協作能力，稱為 LawLuo。此框架包含四個代理：接待員、律師、秘書和老闆，每個代理負責不同的功能，共同為使用者提供全面的法律諮詢。此外，我們構建了兩個高品質的法律對話資料集，KINLED 和 MURLED，並使用這些資料集微調了 ChatGLM-3-6b。我們提出了一種稱為 ToLC 的法律查詢澄清演算法。實驗結果表明，LawLuo 在三個面向：律師語言風格、法律建議的實用性和法律知識的準確性上，都優於基線 LLM，包括 GPT-4。我們的程式碼和資料集可在 https://github.com/NEFUJing/LawLuo 取得。

##### **HSVLT: Hierarchical Scale-Aware Vision-Language Transformer for Multi-Label Image Classification**
2407.16244v1 by Shuyi Ouyang, Hongyi Wang, Ziwei Niu, Zhenjia Bai, Shiao Xie, Yingying Xu, Ruofeng Tong, Yen-Wei Chen, Lanfen Lin

The task of multi-label image classification involves recognizing multiple
objects within a single image. Considering both valuable semantic information
contained in the labels and essential visual features presented in the image,
tight visual-linguistic interactions play a vital role in improving
classification performance. Moreover, given the potential variance in object
size and appearance within a single image, attention to features of different
scales can help to discover possible objects in the image. Recently,
Transformer-based methods have achieved great success in multi-label image
classification by leveraging the advantage of modeling long-range dependencies,
but they have several limitations. Firstly, existing methods treat visual
feature extraction and cross-modal fusion as separate steps, resulting in
insufficient visual-linguistic alignment in the joint semantic space.
Additionally, they only extract visual features and perform cross-modal fusion
at a single scale, neglecting objects with different characteristics. To
address these issues, we propose a Hierarchical Scale-Aware Vision-Language
Transformer (HSVLT) with two appealing designs: (1)~A hierarchical multi-scale
architecture that involves a Cross-Scale Aggregation module, which leverages
joint multi-modal features extracted from multiple scales to recognize objects
of varying sizes and appearances in images. (2)~Interactive Visual-Linguistic
Attention, a novel attention mechanism module that tightly integrates
cross-modal interaction, enabling the joint updating of visual, linguistic and
multi-modal features. We have evaluated our method on three benchmark datasets.
The experimental results demonstrate that HSVLT surpasses state-of-the-art
methods with lower computational cost.

摘要：多標籤影像分類的任務包含辨識單一影像中的多個物件。考量標籤中包含有價值的語意資訊，以及影像中呈現的必要視覺特徵，緊密的視覺語言互動在提升分類效能中扮演至關重要的角色。此外，考量單一影像中物件大小和外觀的潛在差異，注意不同比例的特徵有助於發現影像中可能的物件。最近，基於 Transformer 的方法透過利用建模長程依賴關係的優勢，在多標籤影像分類中取得極佳的成效，但它們有幾個限制。首先，現有方法將視覺特徵萃取和跨模態融合視為獨立的步驟，導致在聯合語意空間中視覺語言對齊不足。此外，它們僅萃取視覺特徵，並在單一比例下執行跨模態融合，忽略具有不同特徵的物件。為了解決這些問題，我們提出具有兩個吸引人設計的分層比例感知視覺語言 Transformer (HSVLT)：(1) 涉及跨比例聚合模組的分層多比例架構，它利用從多個比例中萃取的聯合多模態特徵，以辨識影像中大小和外觀不同的物件。(2) 交互式視覺語言注意力，一種緊密整合跨模態互動的新穎注意力機制模組，可讓視覺、語言和多模態特徵聯合更新。我們在三個基準資料集上評估了我們的方法。實驗結果證明，HSVLT 以較低的運算成本超越了最先進的方法。

##### **OriGen:Enhancing RTL Code Generation with Code-to-Code Augmentation and Self-Reflection**
2407.16237v1 by Fan Cui, Chenyang Yin, Kexing Zhou, Youwei Xiao, Guangyu Sun, Qiang Xu, Qipeng Guo, Demin Song, Dahua Lin, Xingcheng Zhang, Yun, Liang

Recent studies have illuminated that Large Language Models (LLMs) exhibit
substantial potential in the realm of RTL (Register Transfer Level) code
generation, with notable advancements evidenced by commercial models such as
GPT-4 and Claude3-Opus. Despite their proficiency, these commercial LLMs often
raise concerns regarding privacy and security. Conversely, open-source LLMs,
which offer solutions to these concerns, have inferior performance in RTL code
generation tasks to commercial models due to the lack of highquality
open-source RTL datasets. To address this issue, we introduce OriGen, a fully
open-source framework featuring self-reflection capabilities and a dataset
augmentation methodology for generating high-quality, large-scale RTL code. We
propose a novel code-to-code augmentation methodology that leverages knowledge
distillation to enhance the quality of the open-source RTL code datasets.
Additionally, OriGen is capable of correcting syntactic errors by leveraging a
self-reflection process based on feedback from the compiler. The
self-reflection ability of the model is facilitated by a carefully constructed
dataset, which comprises a comprehensive collection of samples. Experimental
results demonstrate that OriGen remarkably outperforms other open-source
alternatives in RTL code generation, surpassing the previous best-performing
LLM by 9.8% on the VerilogEval-Human benchmark. Furthermore, OriGen exhibits
superior capabilities in self-reflection and error rectification, surpassing
GPT-4 by 18.1% on the benchmark designed to evaluate the capability of
self-reflection.

摘要：<paragraph>最近的研究表明，大型语言模型 (LLM) 在 RTL（寄存器传输层）代码生成领域展现出巨大的潜力，由 GPT-4 和 Claude3-Opus 等商业模型证明的显着进步。尽管它们很熟练，但这些商业 LLM 经常引发有关隐私和安全的担忧。相反，开源 LLM 提供了针对这些担忧的解决方案，但在 RTL 代码生成任务中，由于缺少高质量的开源 RTL 数据集，其性能不如商业模型。为了解决这个问题，我们引入了 OriGen，这是一个完全开源的框架，具有自省能力和一个数据集增强方法，用于生成高质量、大规模的 RTL 代码。我们提出了一种新颖的代码到代码增强方法，该方法利用知识蒸馏来提高开源 RTL 代码数据集的质量。此外，OriGen 能够通过利用基于编译器反馈的自省过程来纠正语法错误。模型的自省能力是由精心构建的数据集促进的，其中包含一个全面的样本集合。实验结果表明，OriGen 在 RTL 代码生成方面明显优于其他开源替代方案，在 VerilogEval-Human 基准测试中比之前表现最好的 LLM 高出 9.8%。此外，OriGen 在自省和错误纠正方面表现出卓越的能力，在评估自省能力的基准测试中比 GPT-4 高出 18.1%。</paragraph>

##### **Comparison of Static Application Security Testing Tools and Large Language Models for Repo-level Vulnerability Detection**
2407.16235v1 by Xin Zhou, Duc-Manh Tran, Thanh Le-Cong, Ting Zhang, Ivana Clairine Irsan, Joshua Sumarlin, Bach Le, David Lo

Software vulnerabilities pose significant security challenges and potential
risks to society, necessitating extensive efforts in automated vulnerability
detection. There are two popular lines of work to address automated
vulnerability detection. On one hand, Static Application Security Testing
(SAST) is usually utilized to scan source code for security vulnerabilities,
especially in industries. On the other hand, deep learning (DL)-based methods,
especially since the introduction of large language models (LLMs), have
demonstrated their potential in software vulnerability detection. However,
there is no comparative study between SAST tools and LLMs, aiming to determine
their effectiveness in vulnerability detection, understand the pros and cons of
both SAST and LLMs, and explore the potential combination of these two families
of approaches.
  In this paper, we compared 15 diverse SAST tools with 12 popular or
state-of-the-art open-source LLMs in detecting software vulnerabilities from
repositories of three popular programming languages: Java, C, and Python. The
experimental results showed that SAST tools obtain low vulnerability detection
rates with relatively low false positives, while LLMs can detect up 90\% to
100\% of vulnerabilities but suffer from high false positives. By further
ensembling the SAST tools and LLMs, the drawbacks of both SAST tools and LLMs
can be mitigated to some extent. Our analysis sheds light on both the current
progress and future directions for software vulnerability detection.

摘要：軟體漏洞造成嚴重的安全挑戰和潛在的社會風險，因此需要廣泛的自動化漏洞偵測技術。有兩種常見的工作方式來處理自動化漏洞偵測。一方面，靜態應用程式安全測試 (SAST) 通常用於掃描原始碼以找出安全漏洞，特別是在產業中。另一方面，深度學習 (DL) 方法，特別是在引入大型語言模型 (LLMs) 之後，已證明其在軟體漏洞偵測中的潛力。然而，SAST 工具和 LLM 之間沒有比較研究，目的是確定它們在漏洞偵測中的有效性，了解 SAST 和 LLM 的優缺點，並探討這兩類方法的潛在組合。
在本文中，我們比較了 15 種不同的 SAST 工具和 12 種流行或最先進的開源 LLM，以從三種流行程式語言：Java、C 和 Python 的儲存庫中偵測軟體漏洞。實驗結果顯示，SAST 工具以相對較低的誤報率獲得較低的漏洞偵測率，而 LLM 可以偵測高達 90% 到 100% 的漏洞，但會產生較高的誤報率。進一步結合 SAST 工具和 LLM，可以一定程度地減輕 SAST 工具和 LLM 的缺點。我們的分析揭示了軟體漏洞偵測的當前進度和未來方向。

##### **A Multi-view Mask Contrastive Learning Graph Convolutional Neural Network for Age Estimation**
2407.16234v1 by Yiping Zhang, Yuntao Shou, Tao Meng, Wei Ai, Keqin Li

The age estimation task aims to use facial features to predict the age of
people and is widely used in public security, marketing, identification, and
other fields. However, the features are mainly concentrated in facial
keypoints, and existing CNN and Transformer-based methods have inflexibility
and redundancy for modeling complex irregular structures. Therefore, this paper
proposes a Multi-view Mask Contrastive Learning Graph Convolutional Neural
Network (MMCL-GCN) for age estimation. Specifically, the overall structure of
the MMCL-GCN network contains a feature extraction stage and an age estimation
stage. In the feature extraction stage, we introduce a graph structure to
construct face images as input and then design a Multi-view Mask Contrastive
Learning (MMCL) mechanism to learn complex structural and semantic information
about face images. The learning mechanism employs an asymmetric siamese network
architecture, which utilizes an online encoder-decoder structure to reconstruct
the missing information from the original graph and utilizes the target encoder
to learn latent representations for contrastive learning. Furthermore, to
promote the two learning mechanisms better compatible and complementary, we
adopt two augmentation strategies and optimize the joint losses. In the age
estimation stage, we design a Multi-layer Extreme Learning Machine (ML-IELM)
with identity mapping to fully use the features extracted by the online
encoder. Then, a classifier and a regressor were constructed based on ML-IELM,
which were used to identify the age grouping interval and accurately estimate
the final age. Extensive experiments show that MMCL-GCN can effectively reduce
the error of age estimation on benchmark datasets such as Adience, MORPH-II,
and LAP-2016.

摘要：年齡估計任務旨在使用面部特徵來預測人們的年齡，並廣泛用於公共安全、行銷、識別和其他領域。然而，這些特徵主要集中在面部關鍵點，現有的 CNN 和 Transformer 為基礎的方法對於建模複雜的不規則結構缺乏靈活性且存在冗餘。因此，本文提出了一個多視圖遮罩對比學習圖卷積神經網路 (MMCL-GCN) 來進行年齡估計。具體來說，MMCL-GCN 網路的整體結構包含一個特徵提取階段和一個年齡估計階段。在特徵提取階段，我們引入一個圖形結構將人臉圖像作為輸入，然後設計一個多視圖遮罩對比學習 (MMCL) 機制來學習人臉圖像的複雜結構和語義信息。學習機制採用非對稱連體網路架構，它利用在線編碼器-解碼器結構來重建原始圖形中缺失的信息，並利用目標編碼器來學習對比學習的潛在表示。此外，為了促進這兩種學習機制更好地相容和互補，我們採用兩種擴充策略並最佳化聯合損失。在年齡估計階段，我們設計了一個帶有恆等映射的多層極限學習機 (ML-IELM) 來充分利用在線編碼器提取的特徵。然後，基於 ML-IELM 構建一個分類器和一個回歸器，用於識別年齡組間隔並準確估計最終年齡。大量的實驗表明，MMCL-GCN 可以有效降低 Adience、MORPH-II 和 LAP-2016 等基準資料集上的年齡估計誤差。

##### **PreAlign: Boosting Cross-Lingual Transfer by Early Establishment of Multilingual Alignment**
2407.16222v1 by Jiahuan Li, Shujian Huang, Xinyu Dai, Jiajun Chen

Large language models demonstrate reasonable multilingual abilities, despite
predominantly English-centric pretraining. However, the spontaneous
multilingual alignment in these models is shown to be weak, leading to
unsatisfactory cross-lingual transfer and knowledge sharing. Previous works
attempt to address this issue by explicitly injecting multilingual alignment
information during or after pretraining. Thus for the early stage in
pretraining, the alignment is weak for sharing information or knowledge across
languages. In this paper, we propose PreAlign, a framework that establishes
multilingual alignment prior to language model pretraining. PreAlign injects
multilingual alignment by initializing the model to generate similar
representations of aligned words and preserves this alignment using a
code-switching strategy during pretraining. Extensive experiments in a
synthetic English to English-Clone setting demonstrate that PreAlign
significantly outperforms standard multilingual joint training in language
modeling, zero-shot cross-lingual transfer, and cross-lingual knowledge
application. Further experiments in real-world scenarios further validate
PreAlign's effectiveness across various model sizes.

摘要：大型語言模型展現出合理的跨語言能力，儘管預訓練以英語為主。然而，這些模型中的自發跨語言對齊被證明很弱，導致不令人滿意的跨語言轉移和知識共享。先前的研究嘗試透過在預訓練期間或之後明確注入多語言對齊資訊來解決這個問題。因此，在預訓練的早期階段，對齊很弱，無法跨語言共享資訊或知識。在本文中，我們提出 PreAlign，一個在語言模型預訓練之前建立多語言對齊的框架。PreAlign 透過將模型初始化為產生對齊字詞的類似表示，並在預訓練期間使用代碼轉換策略保留此對齊，來注入多語言對齊。在英語到英語複製的合成設定中進行的廣泛實驗證明，PreAlign 在語言建模、零次方跨語言轉移和跨語言知識應用中明顯優於標準多語言聯合訓練。在真實世界場景中的進一步實驗進一步驗證了 PreAlign 在各種模型規模中的有效性。

##### **Do LLMs Know When to NOT Answer? Investigating Abstention Abilities of Large Language Models**
2407.16221v1 by Nishanth Madhusudhan, Sathwik Tejaswi Madhusudhan, Vikas Yadav, Masoud Hashemi

As Large Language Models (LLMs) achieve remarkable performance across various
NLP tasks, their reliability becomes essential for widespread adoption. This
paper focuses on Abstention Ability (AA), a critical yet under explored aspect
of reliability - the ability of LLMs to refrain from answering questions when
they are uncertain or when definitive answer is not possible, while maintaining
question-answering (QA) task performance. While previous works have focused on
understanding the recollection abilities of LLMs or their ability to identify
imponderable/unanswerable questions, we believe there is a need for an
effective AA evaluation method. Therefore, we propose a black-box evaluation
methodology to examine and understand the AA of LLMs across a variety of
multiple-choice QA tasks. We measure AA by rewarding models for abstaining from
answering when their predictions are incorrect or when the questions are
inherently unanswerable. We investigate three strategies, Strict Prompting,
Verbal Confidence Thresholding, and Chain-of-Thought (CoT), to understand their
impact on abstention across different LLMs. Our findings reveal that while even
state-of-the-art LLMs like GPT-4 struggle with abstention, strategic prompting
such as CoT, can significantly enhance this ability. Furthermore, we
demonstrate that improving AA also leads to better overall QA task performance,
underscoring the importance of evaluating AA in LLMs.

摘要：隨著大型語言模型 (LLM) 在各種自然語言處理任務中取得顯著進展，其可靠性對於廣泛採用至關重要。本文重點探討戒除能力 (AA)，這是可靠性中一個關鍵但尚未充分探討的面向 - LLM 在不確定或無法提供明確答案時，在維持問答 (QA) 任務表現的同時，拒絕回答問題的能力。儘管先前的研究重點在於了解 LLM 的回憶能力或其識別不可思議/無解問題的能力，但我們相信需要一種有效的 AA 評估方法。因此，我們提出了一種黑盒評估方法，用於檢查和了解 LLM 在各種多選題 QA 任務中的 AA。我們通過獎勵模型在預測不正確或問題本質上無法回答時拒絕回答來衡量 AA。我們研究了嚴格提示、言語信心閾值和思維鏈 (CoT) 三種策略，以了解它們對不同 LLM 中戒除的影響。我們的研究結果表明，儘管像 GPT-4 這樣的最先進 LLM 也在戒除方面苦苦掙扎，但 CoT 等策略提示可以顯著增強這種能力。此外，我們證明改進 AA 也有助於提高整體 QA 任務表現，這強調了評估 LLM 中 AA 的重要性。

##### **A Comprehensive Survey of LLM Alignment Techniques: RLHF, RLAIF, PPO, DPO and More**
2407.16216v1 by Zhichao Wang, Bin Bi, Shiva Kumar Pentyala, Kiran Ramnath, Sougata Chaudhuri, Shubham Mehrotra, Zixu, Zhu, Xiang-Bo Mao, Sitaram Asur, Na, Cheng

With advancements in self-supervised learning, the availability of trillions
tokens in a pre-training corpus, instruction fine-tuning, and the development
of large Transformers with billions of parameters, large language models (LLMs)
are now capable of generating factual and coherent responses to human queries.
However, the mixed quality of training data can lead to the generation of
undesired responses, presenting a significant challenge. Over the past two
years, various methods have been proposed from different perspectives to
enhance LLMs, particularly in aligning them with human expectation. Despite
these efforts, there has not been a comprehensive survey paper that categorizes
and details these approaches. In this work, we aim to address this gap by
categorizing these papers into distinct topics and providing detailed
explanations of each alignment method, thereby helping readers gain a thorough
understanding of the current state of the field.

摘要：隨著自監督式學習的進展、數兆個標記在預訓練語料庫中的可用性、指令微調以及開發具有數十億個參數的大型 Transformer，大型語言模型 (LLM) 現在能夠對人類查詢產生事實且連貫的回應。
然而，訓練資料品質參差不齊可能會導致產生不想要的回應，這是一個重大的挑戰。在過去兩年，從不同的觀點提出了各種方法來增強 LLM，特別是在將它們與人類期望保持一致方面。儘管做出了這些努力，但還沒有全面性的調查報告對這些方法進行分類和詳細說明。在這項工作中，我們旨在透過將這些論文分類為不同的主題並提供每種對齊方法的詳細說明來解決這個差距，從而幫助讀者深入了解該領域的現狀。

##### **Graph-Structured Speculative Decoding**
2407.16207v1 by Zhuocheng Gong, Jiahao Liu, Ziyue Wang, Pengfei Wu, Jingang Wang, Xunliang Cai, Dongyan Zhao, Rui Yan

Speculative decoding has emerged as a promising technique to accelerate the
inference of Large Language Models (LLMs) by employing a small language model
to draft a hypothesis sequence, which is then validated by the LLM. The
effectiveness of this approach heavily relies on the balance between
performance and efficiency of the draft model. In our research, we focus on
enhancing the proportion of draft tokens that are accepted to the final output
by generating multiple hypotheses instead of just one. This allows the LLM more
options to choose from and select the longest sequence that meets its
standards. Our analysis reveals that hypotheses produced by the draft model
share many common token sequences, suggesting a potential for optimizing
computation. Leveraging this observation, we introduce an innovative approach
utilizing a directed acyclic graph (DAG) to manage the drafted hypotheses. This
structure enables us to efficiently predict and merge recurring token
sequences, vastly reducing the computational demands of the draft model. We
term this approach Graph-structured Speculative Decoding (GSD). We apply GSD
across a range of LLMs, including a 70-billion parameter LLaMA-2 model, and
observe a remarkable speedup of 1.73$\times$ to 1.96$\times$, significantly
surpassing standard speculative decoding.

摘要：<paragraph>推測性解碼已成為一種有前途的技術，可通過使用小型語言模型起草假設序列，然後由大型語言模型 (LLM) 驗證該序列，從而加速大型語言模型 (LLM) 的推理。此方法的有效性在很大程度上取決於草稿模型的性能和效率之間的平衡。在我們的研究中，我們專注於通過生成多個假設而不是只生成一個假設來提高被接受為最終輸出的草稿令牌的比例。這允許 LLM 從中選擇更多選項，並選擇符合其標準的最長序列。我們的分析表明，草稿模型產生的假設共享許多公共令牌序列，這表明優化計算的可能性。利用這一觀察結果，我們引入了一種創新的方法，利用有向無環圖 (DAG) 來管理已編制的假設。這種結構使我們能夠有效地預測和合併重複的令牌序列，從而大大降低了草稿模型的計算需求。我們將這種方法稱為圖結構推測性解碼 (GSD)。我們將 GSD 應用於一系列 LLM，包括一個 700 億參數的 LLaMA-2 模型，並觀察到顯著的加速，從 1.73 倍到 1.96 倍，顯著超過標準推測性解碼。</paragraph>

##### **Figure it Out: Analyzing-based Jailbreak Attack on Large Language Models**
2407.16205v1 by Shi Lin, Rongchang Li, Xun Wang, Changting Lin, Wenpeng Xing, Meng Han

The rapid development of Large Language Models (LLMs) has brought remarkable
generative capabilities across diverse tasks. However, despite the impressive
achievements, these models still have numerous security vulnerabilities,
particularly when faced with jailbreak attacks. Therefore, by investigating
jailbreak attacks, we can uncover hidden weaknesses in LLMs and guide us in
developing more robust defense mechanisms to fortify their security. In this
paper, we further explore the boundary of jailbreak attacks on LLMs and propose
Analyzing-based Jailbreak (ABJ). This effective jailbreak attack method takes
advantage of LLMs' growing analyzing and reasoning capability and reveals their
underlying vulnerabilities when facing analysis-based tasks. We conduct a
detailed evaluation of ABJ across various open-source and closed-source LLMs,
which achieves 94.8% Attack Success Rate (ASR) and 1.06 Attack Efficiency (AE)
on GPT-4-turbo-0409, demonstrating state-of-the-art attack effectiveness and
efficiency. Our research highlights the importance of prioritizing and
enhancing the safety of LLMs to mitigate the risks of misuse.

摘要：大型語言模型 (LLM) 的快速發展帶來跨越不同任務的非凡生成能力。然而，儘管取得令人印象深刻的成就，這些模型仍然存在許多安全漏洞，特別是在面對越獄攻擊時。因此，通過調查越獄攻擊，我們可以發現 LLM 中隱藏的弱點，並指導我們開發更強大的防禦機制來加強其安全性。在本文中，我們進一步探索 LLM 上越獄攻擊的邊界，並提出基於分析的越獄 (ABJ)。這種有效的越獄攻擊方法利用了 LLM 不斷增長的分析和推理能力，並揭示了它們在面對基於分析的任務時潛在的漏洞。我們對各種開源和閉源 LLM 進行了詳細的 ABJ 評估，在 GPT-4-turbo-0409 上實現了 94.8% 的攻擊成功率 (ASR) 和 1.06 的攻擊效率 (AE)，展示了最先進的攻擊有效性和效率。我們的研究強調了優先考慮和加強 LLM 安全性的重要性，以減輕濫用的風險。

##### **MCTS Based Dispatch of Autonomous Vehicles under Operational Constraints for Continuous Transportation**
2407.16200v1 by Milan Tomy, Konstantin M. Seiler, Andrew J. Hill

Continuous transportation of material in the mining industry is achieved by
the dispatch of autonomous haul-trucks with discrete haulage capacities.
Recently, Monte Carlo Tree Search (MCTS) was successfully deployed in tackling
challenges of long-run optimality, scalability and adaptability in haul-truck
dispatch. Typically, operational constraints imposed on the mine site are
satisfied by heuristic controllers or human operators independent of the
dispatch planning. This article incorporates operational constraint
satisfaction into the dispatch planning by utilising the MCTS based dispatch
planner Flow-Achieving Scheduling Tree (FAST). Operational constraint violation
and satisfaction are modelled as opportunity costs in the combinatorial
optimisation problem of dispatch. Explicit cost formulations are avoided by
utilising MCTS generator models to derive opportunity costs. Experimental
studies with four types of operational constraints demonstrate the success of
utilising opportunity costs for constraint satisfaction, and the effectiveness
of integrating constraints into dispatch planning.

摘要：透過派遣具備離散運輸能力的自動化運輸車輛，可達成採礦產業中材料的持續運輸。
最近，蒙地卡羅樹狀搜尋 (MCTS) 已成功部署於解決運輸車輛調度中的長期最佳化、可擴充性和適應性挑戰。通常，礦場施加於作業的限制，會由啟發式控制器或人為操作員獨立於調度規劃來滿足。本文透過利用基於 MCTS 的調度規劃器 Flow-Achieving Scheduling Tree (FAST)，將作業限制滿足納入調度規劃中。作業限制違規和滿足會建模為調度組合最佳化問題中的機會成本。透過利用 MCTS 生成器模型來推導機會成本，可避免明確的成本公式。透過四種類型的作業限制進行的實驗研究，證明了利用機會成本來滿足限制的成功性，以及將限制整合到調度規劃中的有效性。

##### **INF-LLaVA: Dual-perspective Perception for High-Resolution Multimodal Large Language Model**
2407.16198v1 by Yiwei Ma, Zhibin Wang, Xiaoshuai Sun, Weihuang Lin, Qiang Zhou, Jiayi Ji, Rongrong Ji

With advancements in data availability and computing resources, Multimodal
Large Language Models (MLLMs) have showcased capabilities across various
fields. However, the quadratic complexity of the vision encoder in MLLMs
constrains the resolution of input images. Most current approaches mitigate
this issue by cropping high-resolution images into smaller sub-images, which
are then processed independently by the vision encoder. Despite capturing
sufficient local details, these sub-images lack global context and fail to
interact with one another. To address this limitation, we propose a novel MLLM,
INF-LLaVA, designed for effective high-resolution image perception. INF-LLaVA
incorporates two innovative components. First, we introduce a Dual-perspective
Cropping Module (DCM), which ensures that each sub-image contains continuous
details from a local perspective and comprehensive information from a global
perspective. Second, we introduce Dual-perspective Enhancement Module (DEM) to
enable the mutual enhancement of global and local features, allowing INF-LLaVA
to effectively process high-resolution images by simultaneously capturing
detailed local information and comprehensive global context. Extensive ablation
studies validate the effectiveness of these components, and experiments on a
diverse set of benchmarks demonstrate that INF-LLaVA outperforms existing
MLLMs. Code and pretrained model are available at
https://github.com/WeihuangLin/INF-LLaVA.

摘要：隨著數據可用性和運算資源的進步，多模態大型語言模型 (MLLM) 已在各個領域展示其能力。然而，MLLM 中視覺編碼器的二次複雜度限制了輸入影像解析度。目前大多數方法透過將高解析度影像裁切成較小的子影像來緩解此問題，然後由視覺編碼器獨立處理。儘管捕捉到足夠的局部細節，但這些子影像缺乏全局脈絡，且無法彼此互動。為了解決此限制，我們提出一個新穎的 MLLM，INF-LLaVA，旨在有效感知高解析度影像。INF-LLaVA 結合了兩個創新的組成部分。首先，我們引入一個雙視角裁切模組 (DCM)，確保每個子影像從局部視角包含連續的細節，並從全局視角包含全面的資訊。其次，我們引入雙視角增強模組 (DEM)，以實現全局和局部特徵的相互增強，讓 INF-LLaVA 能夠同時捕捉詳細的局部資訊和全面的全局脈絡，有效處理高解析度影像。廣泛的消融研究驗證了這些組成部分的有效性，且在各種基準測試上的實驗證明 INF-LLaVA 優於現有的 MLLM。程式碼和預訓練模型可在 https://github.com/WeihuangLin/INF-LLaVA 取得。

##### **How to Leverage Personal Textual Knowledge for Personalized Conversational Information Retrieval**
2407.16192v1 by Fengran Mo, Longxiang Zhao, Kaiyu Huang, Yue Dong, Degen Huang, Jian-Yun Nie

Personalized conversational information retrieval (CIR) combines
conversational and personalizable elements to satisfy various users' complex
information needs through multi-turn interaction based on their backgrounds.
The key promise is that the personal textual knowledge base (PTKB) can improve
the CIR effectiveness because the retrieval results can be more related to the
user's background. However, PTKB is noisy: not every piece of knowledge in PTKB
is relevant to the specific query at hand. In this paper, we explore and test
several ways to select knowledge from PTKB and use it for query reformulation
by using a large language model (LLM). The experimental results show the PTKB
might not always improve the search results when used alone, but LLM can help
generate a more appropriate personalized query when high-quality guidance is
provided.

摘要：個人化對話式資訊檢索 (CIR) 結合對話式和個人化元素，透過基於使用者背景的多輪互動來滿足各種使用者的複雜資訊需求。其關鍵承諾是個人化文字知識庫 (PTKB) 能提升 CIR 的效果，因為檢索結果可以更貼近使用者的背景。然而，PTKB 存在雜訊：PTKB 中的每一則知識並不都與手邊的特定查詢相關。在本文中，我們探討並測試多種從 PTKB 中選取知識並使用它來重新表述查詢的方法，方法是使用大型語言模型 (LLM)。實驗結果顯示，PTKB 獨自使用時可能無法總是提升搜尋結果，但當提供高品質的引導時，LLM 能協助產生更適當的個人化查詢。

##### **Artificial Agency and Large Language Models**
2407.16190v1 by Maud Van Lier, Gorka Muñoz-Gil

The arrival of Large Language Models (LLMs) has stirred up philosophical
debates about the possibility of realizing agency in an artificial manner. In
this work we contribute to the debate by presenting a theoretical model that
can be used as a threshold conception for artificial agents. The model defines
agents as systems whose actions and goals are always influenced by a dynamic
framework of factors that consists of the agent's accessible history, its
adaptive repertoire and its external environment. This framework, in turn, is
influenced by the actions that the agent takes and the goals that it forms. We
show with the help of the model that state-of-the-art LLMs are not agents yet,
but that there are elements to them that suggest a way forward. The paper
argues that a combination of the agent architecture presented in Park et al.
(2023) together with the use of modules like the Coscientist in Boiko et al.
(2023) could potentially be a way to realize agency in an artificial manner. We
end the paper by reflecting on the obstacles one might face in building such an
artificial agent and by presenting possible directions for future research.

摘要：大型語言模型 (LLM) 的出現激起了關於以人工方式實現能動性的可能性之哲學辯論。在這項工作中，我們透過提出一個理論模型來為辯論做出貢獻，該模型可用作人工代理的閾值概念。該模型將代理定義為其行為和目標始終受到由代理的可存取歷史、其適應性曲目及其外部環境組成的動態因素框架影響的系統。反過來，這個框架又受到代理採取的行動和它形成的目標的影響。我們在模型的幫助下表明，最先進的 LLM 還不是代理，但其中有一些元素暗示了一種前進的方式。本文認為，將 Park 等人提出的代理架構與 Boiko 等人中的 Coscientist 等模組結合使用，有可能以人工方式實現能動性。(2023) 可能是一種以人工方式實現能動性的方法。我們透過反思在構建這種人工代理時可能面臨的障礙，並提出未來研究的可能方向，來結束本文。

##### **Structural Optimization Ambiguity and Simplicity Bias in Unsupervised Neural Grammar Induction**
2407.16181v1 by Jinwook Park, Kangil Kim

Neural parameterization has significantly advanced unsupervised grammar
induction. However, training these models with a traditional likelihood loss
for all possible parses exacerbates two issues: 1) $\textit{structural
optimization ambiguity}$ that arbitrarily selects one among structurally
ambiguous optimal grammars despite the specific preference of gold parses, and
2) $\textit{structural simplicity bias}$ that leads a model to underutilize
rules to compose parse trees. These challenges subject unsupervised neural
grammar induction (UNGI) to inevitable prediction errors, high variance, and
the necessity for extensive grammars to achieve accurate predictions. This
paper tackles these issues, offering a comprehensive analysis of their origins.
As a solution, we introduce $\textit{sentence-wise parse-focusing}$ to reduce
the parse pool per sentence for loss evaluation, using the structural bias from
pre-trained parsers on the same dataset. In unsupervised parsing benchmark
tests, our method significantly improves performance while effectively reducing
variance and bias toward overly simplistic parses. Our research promotes
learning more compact, accurate, and consistent explicit grammars, facilitating
better interpretability.

摘要：神經參數化大幅提升了非監督文法歸納。然而，針對所有可能的解析訓練這些模型時，傳統的可能性損失會加劇兩個問題：1) $\textit{結構最佳化模糊性}$，儘管金解析的特定偏好，但在結構上模糊的最佳文法中任意選擇一個；以及 2) $\textit{結構簡潔偏差}$，導致模型無法充分利用規則來組合解析樹。這些挑戰會讓非監督神經文法歸納 (UNGI) 產生無法避免的預測錯誤、高變異性，以及需要廣泛的文法才能達成準確預測。本文探討這些問題，並全面分析其起源。作為解決方案，我們引入了 $\textit{句子層級解析聚焦}$，以減少每個句子的解析池，用於損失評估，使用相同資料集上預訓練解析器的結構偏差。在非監督解析基準測試中，我們的模型大幅提升效能，同時有效降低變異性和對過度簡化的解析的偏差。我們的研究促進學習更精簡、準確且一致的明確文法，有助於更好的可解釋性。

##### **Pixel Embedding: Fully Quantized Convolutional Neural Network with Differentiable Lookup Table**
2407.16174v1 by Hiroyuki Tokunaga, Joel Nicholls, Daria Vazhenina, Atsunori Kanemura

By quantizing network weights and activations to low bitwidth, we can obtain
hardware-friendly and energy-efficient networks. However, existing quantization
techniques utilizing the straight-through estimator and piecewise constant
functions face the issue of how to represent originally high-bit input data
with low-bit values. To fully quantize deep neural networks, we propose pixel
embedding, which replaces each float-valued input pixel with a vector of
quantized values by using a lookup table. The lookup table or low-bit
representation of pixels is differentiable and trainable by backpropagation.
Such replacement of inputs with vectors is similar to word embedding in the
natural language processing field. Experiments on ImageNet and CIFAR-100 show
that pixel embedding reduces the top-5 error gap caused by quantizing the
floating points at the first layer to only 1% for the ImageNet dataset, and the
top-1 error gap caused by quantizing first and last layers to slightly over 1%
for the CIFAR-100 dataset. The usefulness of pixel embedding is further
demonstrated by inference time measurements, which demonstrate over 1.7 times
speedup compared to floating point precision first layer.

摘要：透過將網路權重和啟用量化為低位元寬度，我們可以獲得硬體友善且節能的網路。然而，現有的量化技術利用直通估計器和分段常數函數，面臨如何用低位元值表示原本高位元輸入資料的問題。為了完全量化深度神經網路，我們提出像素嵌入，它用查找表將每個浮點值輸入像素替換為量化值的向量。查找表或像素的低位元表示是可微分的，並可透過反向傳播進行訓練。這種用向量替換輸入的方式類似於自然語言處理領域中的詞嵌入。在 ImageNet 和 CIFAR-100 上的實驗顯示，像素嵌入將 ImageNet 資料集第一層浮點數位量化造成的 top-5 錯誤差距減少到僅 1%，而對於 CIFAR-100 資料集，將第一層和最後一層量化造成的 top-1 錯誤差距減少到略高於 1%。像素嵌入的效用進一步透過推論時間測量得到證明，與浮點精度第一層相比，速度提升超過 1.7 倍。

##### **Learning Trimodal Relation for AVQA with Missing Modality**
2407.16171v1 by Kyu Ri Park, Hong Joo Lee, Jung Uk Kim

Recent Audio-Visual Question Answering (AVQA) methods rely on complete visual
and audio input to answer questions accurately. However, in real-world
scenarios, issues such as device malfunctions and data transmission errors
frequently result in missing audio or visual modality. In such cases, existing
AVQA methods suffer significant performance degradation. In this paper, we
propose a framework that ensures robust AVQA performance even when a modality
is missing. First, we propose a Relation-aware Missing Modal (RMM) generator
with Relation-aware Missing Modal Recalling (RMMR) loss to enhance the ability
of the generator to recall missing modal information by understanding the
relationships and context among the available modalities. Second, we design an
Audio-Visual Relation-aware (AVR) diffusion model with Audio-Visual Enhancing
(AVE) loss to further enhance audio-visual features by leveraging the
relationships and shared cues between the audio-visual modalities. As a result,
our method can provide accurate answers by effectively utilizing available
information even when input modalities are missing. We believe our method holds
potential applications not only in AVQA research but also in various
multi-modal scenarios.

摘要：最近的音視覺問答（AVQA）方法依賴於完整的視覺和音訊輸入，才能準確回答問題。然而，在現實世界的場景中，諸如裝置故障和資料傳輸錯誤等問題經常導致音訊或視覺模式遺失。在這種情況下，現有的 AVQA 方法會遭受顯著的效能下降。在本文中，我們提出了一個框架，即使在模式遺失的情況下也能確保穩健的 AVQA 效能。首先，我們提出了一個具有關係感知遺失模式回憶（RMMR）損失的關係感知遺失模式（RMM）生成器，以增強生成器透過理解可用模式之間的關係和背景來回憶遺失模式資訊的能力。其次，我們設計了一個具有音視覺增強（AVE）損失的音視覺關係感知（AVR）擴散模型，以進一步增強音視覺特徵，方法是利用音視覺模式之間的關係和共享提示。因此，即使輸入模式遺失，我們的模型也能透過有效利用可用資訊提供準確的答案。我們相信我們的模型不僅在 AVQA 研究中具有潛在應用，在各種多模式場景中也具有潛在應用。

##### **Robust Privacy Amidst Innovation with Large Language Models Through a Critical Assessment of the Risks**
2407.16166v1 by Yao-Shun Chuang, Atiquer Rahman Sarkar, Noman Mohammed, Xiaoqian Jiang

This study examines integrating EHRs and NLP with large language models
(LLMs) to improve healthcare data management and patient care. It focuses on
using advanced models to create secure, HIPAA-compliant synthetic patient notes
for biomedical research. The study used de-identified and re-identified MIMIC
III datasets with GPT-3.5, GPT-4, and Mistral 7B to generate synthetic notes.
Text generation employed templates and keyword extraction for contextually
relevant notes, with one-shot generation for comparison. Privacy assessment
checked PHI occurrence, while text utility was tested using an ICD-9 coding
task. Text quality was evaluated with ROUGE and cosine similarity metrics to
measure semantic similarity with source notes. Analysis of PHI occurrence and
text utility via the ICD-9 coding task showed that the keyword-based method had
low risk and good performance. One-shot generation showed the highest PHI
exposure and PHI co-occurrence, especially in geographic location and date
categories. The Normalized One-shot method achieved the highest classification
accuracy. Privacy analysis revealed a critical balance between data utility and
privacy protection, influencing future data use and sharing. Re-identified data
consistently outperformed de-identified data. This study demonstrates the
effectiveness of keyword-based methods in generating privacy-protecting
synthetic clinical notes that retain data usability, potentially transforming
clinical data-sharing practices. The superior performance of re-identified over
de-identified data suggests a shift towards methods that enhance utility and
privacy by using dummy PHIs to perplex privacy attacks.

摘要：本研究探討整合電子病歷 (EHR) 和自然語言處理 (NLP) 與大型語言模型 (LLM)，以改善醫療保健資料管理和患者照護。其重點在於使用進階模型來建立安全且符合 HIPAA 規範的合成病患紀錄，以供生物醫學研究使用。本研究使用去識別化且重新識別的 MIMIC III 資料集，並搭配 GPT-3.5、GPT-4 和 Mistral 7B 來產生合成紀錄。文字產生採用範本和關鍵字萃取，以產生與脈絡相關的紀錄，並使用一次性產生進行比較。隱私評估檢查 PHI 的出現，而文字效用則使用 ICD-9 編碼任務進行測試。文字品質使用 ROUGE 和餘弦相似度指標進行評估，以測量與原始紀錄的語義相似度。透過 ICD-9 編碼任務分析 PHI 的出現和文字效用，顯示基於關鍵字的方法風險低且效能良好。一次性產生顯示出最高的 PHI 曝光和 PHI 共現，特別是在地理位置和日期類別中。正規化一次性方法達到最高的分類準確度。隱私分析揭示了資料效用和隱私保護之間的關鍵平衡，影響未來的資料使用和分享。重新識別的資料始終優於去識別化的資料。本研究證明了基於關鍵字的方法在產生保護隱私的合成臨床紀錄方面是有效的，這些紀錄保留了資料可用性，並有可能轉變臨床資料分享實務。重新識別的資料優於去識別化資料的優異效能，這表示朝向使用虛擬 PHI 來混淆隱私攻擊，以增強效用和隱私的方法邁進。

##### **Representation Magnitude has a Liability to Privacy Vulnerability**
2407.16164v1 by Xingli Fang, Jung-Eun Kim

The privacy-preserving approaches to machine learning (ML) models have made
substantial progress in recent years. However, it is still opaque in which
circumstances and conditions the model becomes privacy-vulnerable, leading to a
challenge for ML models to maintain both performance and privacy. In this
paper, we first explore the disparity between member and non-member data in the
representation of models under common training frameworks. We identify how the
representation magnitude disparity correlates with privacy vulnerability and
address how this correlation impacts privacy vulnerability. Based on the
observations, we propose Saturn Ring Classifier Module (SRCM), a plug-in
model-level solution to mitigate membership privacy leakage. Through a confined
yet effective representation space, our approach ameliorates models' privacy
vulnerability while maintaining generalizability. The code of this work can be
found here: \url{https://github.com/JEKimLab/AIES2024_SRCM}

摘要：近年來，機器學習 (ML) 模型的隱私保護方法已取得顯著進展。然而，在哪些情況和條件下，模型會變得容易受到隱私侵害，仍然不透明，這對 ML 模型同時維持效能和隱私構成挑戰。在本文中，我們首先探討在常見訓練架構下，成員和非成員資料在模型表徵中的差異。我們找出表徵幅度差異如何與隱私漏洞相關，並說明這種相關性如何影響隱私漏洞。根據這些觀察，我們提出土星環分類器模組 (SRCM)，這是一個插入模型層級的解決方案，用於減輕成員隱私外洩。透過受限但有效的表徵空間，我們的做法改善了模型的隱私漏洞，同時維持了可概化性。這項工作的程式碼可以在這裡找到：\url{https://github.com/JEKimLab/AIES2024_SRCM}

##### **UniMEL: A Unified Framework for Multimodal Entity Linking with Large Language Models**
2407.16160v1 by Liu Qi, He Yongyi, Lian Defu, Zheng Zhi, Xu Tong, Liu Che, Chen Enhong

Multimodal Entity Linking (MEL) is a crucial task that aims at linking
ambiguous mentions within multimodal contexts to the referent entities in a
multimodal knowledge base, such as Wikipedia. Existing methods focus heavily on
using complex mechanisms and extensive model tuning methods to model the
multimodal interaction on specific datasets. However, these methods
overcomplicate the MEL task and overlook the visual semantic information, which
makes them costly and hard to scale. Moreover, these methods can not solve the
issues like textual ambiguity, redundancy, and noisy images, which severely
degrade their performance. Fortunately, the advent of Large Language Models
(LLMs) with robust capabilities in text understanding and reasoning,
particularly Multimodal Large Language Models (MLLMs) that can process
multimodal inputs, provides new insights into addressing this challenge.
However, how to design a universally applicable LLMs-based MEL approach remains
a pressing challenge. To this end, we propose UniMEL, a unified framework which
establishes a new paradigm to process multimodal entity linking tasks using
LLMs. In this framework, we employ LLMs to augment the representation of
mentions and entities individually by integrating textual and visual
information and refining textual information. Subsequently, we employ the
embedding-based method for retrieving and re-ranking candidate entities. Then,
with only ~0.26% of the model parameters fine-tuned, LLMs can make the final
selection from the candidate entities. Extensive experiments on three public
benchmark datasets demonstrate that our solution achieves state-of-the-art
performance, and ablation studies verify the effectiveness of all modules. Our
code is available at https://anonymous.4open.science/r/UniMEL/.

摘要：多模態實體連結 (MEL) 是一項重要的任務，旨在將多模態語境中的模糊提及連結到多模態知識庫（例如維基百科）中的指涉實體。現有方法非常依賴使用複雜的機制和廣泛的模型調整方法，對特定資料集上的多模態互動進行建模。然而，這些方法過於複雜化 MEL 任務，並且忽略了視覺語義資訊，這使得它們成本高昂且難以擴展。此外，這些方法無法解決文本歧義、冗餘和雜訊影像等問題，這嚴重降低了它們的效能。幸運的是，具有強大文字理解和推理能力的大語言模型 (LLM) 的出現，特別是可以處理多模態輸入的多模態大語言模型 (MLLM)，為解決此挑戰提供了新的見解。然而，如何設計一個普遍適用的基於 LLM 的 MEL 方法仍然是一個迫切的挑戰。為此，我們提出了 UniMEL，一個統一的框架，它建立了一個新的範例，使用 LLM 處理多模態實體連結任務。在此框架中，我們使用 LLM 來擴充提及和實體的表示，分別透過整合文字和視覺資訊，以及精煉文字資訊。隨後，我們採用基於嵌入的方法來檢索和重新排列候選實體。然後，在僅微調了約 0.26% 的模型參數後，LLM 可以從候選實體中做出最終選擇。在三個公開基準資料集上的廣泛實驗證明，我們的解決方案達到了最先進的效能，而消融研究驗證了所有模組的有效性。我們的程式碼可在 https://anonymous.4open.science/r/UniMEL/ 取得。

##### **DDK: Distilling Domain Knowledge for Efficient Large Language Models**
2407.16154v1 by Jiaheng Liu, Chenchen Zhang, Jinyang Guo, Yuanxing Zhang, Haoran Que, Ken Deng, Zhiqi Bai, Jie Liu, Ge Zhang, Jiakai Wang, Yanan Wu, Congnan Liu, Wenbo Su, Jiamang Wang, Lin Qu, Bo Zheng

Despite the advanced intelligence abilities of large language models (LLMs)
in various applications, they still face significant computational and storage
demands. Knowledge Distillation (KD) has emerged as an effective strategy to
improve the performance of a smaller LLM (i.e., the student model) by
transferring knowledge from a high-performing LLM (i.e., the teacher model).
Prevailing techniques in LLM distillation typically use a black-box model API
to generate high-quality pretrained and aligned datasets, or utilize white-box
distillation by altering the loss function to better transfer knowledge from
the teacher LLM. However, these methods ignore the knowledge differences
between the student and teacher LLMs across domains. This results in excessive
focus on domains with minimal performance gaps and insufficient attention to
domains with large gaps, reducing overall performance. In this paper, we
introduce a new LLM distillation framework called DDK, which dynamically
adjusts the composition of the distillation dataset in a smooth manner
according to the domain performance differences between the teacher and student
models, making the distillation process more stable and effective. Extensive
evaluations show that DDK significantly improves the performance of student
models, outperforming both continuously pretrained baselines and existing
knowledge distillation methods by a large margin.

摘要：儘管大型語言模型 (LLM) 在各種應用中具備先進的智能能力，但它們仍然面臨龐大的運算和儲存需求。知識蒸餾 (KD) 已成為一種有效策略，可透過從高性能 LLM (即教師模型) 傳輸知識，來提升較小型 LLM (即學生模型) 的效能。LLM 蒸餾中普遍採用的技術，通常會使用黑盒模型 API 來產生高品質的預訓練和對齊資料集，或透過改變損失函數來利用白盒蒸餾，以從教師 LLM 更有效地傳輸知識。然而，這些方法忽略了學生和教師 LLM 在不同領域之間的知識差異。這導致過度專注於效能差距最小的領域，而對差距較大的領域關注不足，進而降低整體效能。在本文中，我們介紹一個名為 DDK 的新型 LLM 蒸餾架構，它會根據教師和學生模型之間的領域效能差異，以平穩的方式動態調整蒸餾資料集的組成，讓蒸餾過程更穩定且有效。廣泛的評估顯示，DDK 大幅提升了學生模型的效能，大幅優於持續預訓練的基準和現有的知識蒸餾方法。

##### **Predicting Stock Prices with FinBERT-LSTM: Integrating News Sentiment Analysis**
2407.16150v1 by Wenjun Gu, Yihao Zhong, Shizun Li, Changsong Wei, Liting Dong, Zhuoyue Wang, Chao Yan

The stock market's ascent typically mirrors the flourishing state of the
economy, whereas its decline is often an indicator of an economic downturn.
Therefore, for a long time, significant correlation elements for predicting
trends in financial stock markets have been widely discussed, and people are
becoming increasingly interested in the task of financial text mining. The
inherent instability of stock prices makes them acutely responsive to
fluctuations within the financial markets. In this article, we use deep
learning networks, based on the history of stock prices and articles of
financial, business, technical news that introduce market information to
predict stock prices. We illustrate the enhancement of predictive precision by
integrating weighted news categories into the forecasting model. We developed a
pre-trained NLP model known as FinBERT, designed to discern the sentiments
within financial texts. Subsequently, we advanced this model by incorporating
the sophisticated Long Short Term Memory (LSTM) architecture, thus constructing
the innovative FinBERT-LSTM model. This model utilizes news categories related
to the stock market structure hierarchy, namely market, industry, and stock
related news categories, combined with the stock market's stock price situation
in the previous week for prediction. We selected NASDAQ-100 index stock data
and trained the model on Benzinga news articles, and utilized Mean Absolute
Error (MAE), Mean Absolute Percentage Error (MAPE), and Accuracy as the key
metrics for the assessment and comparative analysis of the model's performance.
The results indicate that FinBERT-LSTM performs the best, followed by LSTM, and
DNN model ranks third in terms of effectiveness.

摘要：股票市場的上升通常反映經濟的繁榮，而其下降通常是經濟衰退的一個指標。因此，長期以來，用於預測金融股票市場趨勢的重要相關元素已被廣泛討論，人們對金融文本挖掘任務的興趣也越來越大。股票價格固有的不穩定性使其對金融市場的波動極為敏感。在本文中，我們使用深度學習網路，基於股票價格的歷史和介紹市場信息的金融、商業、技術新聞文章來預測股票價格。我們通過將加權新聞類別整合到預測模型中來說明預測精度的提高。我們開發了一個稱為 FinBERT 的預訓練 NLP 模型，旨在辨別金融文本中的情緒。隨後，我們通過整合複雜的長短期記憶 (LSTM) 架構來改進這個模型，從而構建創新的 FinBERT-LSTM 模型。此模型利用與股票市場結構層次相關的新聞類別，即市場、行業和股票相關新聞類別，結合前一周的股票市場股價狀況進行預測。我們選擇了 NASDAQ-100 指數股票數據，並在 Benzinga 新聞文章上訓練模型，並利用平均絕對誤差 (MAE)、平均絕對百分比誤差 (MAPE) 和準確度作為模型性能評估和比較分析的關鍵指標。結果表明，FinBERT-LSTM 表現最佳，其次是 LSTM，DNN 模型在有效性方面排名第三。

##### **CHIME: LLM-Assisted Hierarchical Organization of Scientific Studies for Literature Review Support**
2407.16148v1 by Chao-Chun Hsu, Erin Bransom, Jenna Sparks, Bailey Kuehl, Chenhao Tan, David Wadden, Lucy Lu Wang, Aakanksha Naik

Literature review requires researchers to synthesize a large amount of
information and is increasingly challenging as the scientific literature
expands. In this work, we investigate the potential of LLMs for producing
hierarchical organizations of scientific studies to assist researchers with
literature review. We define hierarchical organizations as tree structures
where nodes refer to topical categories and every node is linked to the studies
assigned to that category. Our naive LLM-based pipeline for hierarchy
generation from a set of studies produces promising yet imperfect hierarchies,
motivating us to collect CHIME, an expert-curated dataset for this task focused
on biomedicine. Given the challenging and time-consuming nature of building
hierarchies from scratch, we use a human-in-the-loop process in which experts
correct errors (both links between categories and study assignment) in
LLM-generated hierarchies. CHIME contains 2,174 LLM-generated hierarchies
covering 472 topics, and expert-corrected hierarchies for a subset of 100
topics. Expert corrections allow us to quantify LLM performance, and we find
that while they are quite good at generating and organizing categories, their
assignment of studies to categories could be improved. We attempt to train a
corrector model with human feedback which improves study assignment by 12.6 F1
points. We release our dataset and models to encourage research on developing
better assistive tools for literature review.

摘要：文獻回顧需要研究人員綜合大量資訊，隨著科學文獻的擴展，這項任務也越來越具有挑戰性。在這項工作中，我們探討了 LLM 在產生科學研究的階層組織以協助研究人員進行文獻回顧的潛力。我們將階層組織定義為樹狀結構，其中節點指的是主題類別，而每個節點都連結到指派給該類別的研究。我們從一組研究中產生階層的單純 LLM 管線產生了有希望但並不完美的階層，這促使我們收集 CHIME，這是一個針對此任務的專家策展資料集，重點在生物醫學。鑑於從頭建立階層具有挑戰性且耗時，我們使用人員參與的流程，其中專家更正 LLM 產生的階層中的錯誤（類別之間的連結和研究指派）。CHIME 包含 2,174 個 LLM 產生的階層，涵蓋 472 個主題，以及 100 個主題子集的專家更正階層。專家更正讓我們能夠量化 LLM 的效能，我們發現雖然它們在產生和組織類別方面相當出色，但它們將研究指派到類別的方式可以改進。我們嘗試訓練一個具備人類回饋的校正模型，這將研究指派改進了 12.6 個 F1 點。我們釋出我們的資料集和模型，以鼓勵研究人員開發更好的文獻回顧輔助工具。

##### **Diffusion Models as Optimizers for Efficient Planning in Offline RL**
2407.16142v1 by Renming Huang, Yunqiang Pei, Guoqing Wang, Yangming Zhang, Yang Yang, Peng Wang, Hengtao Shen

Diffusion models have shown strong competitiveness in offline reinforcement
learning tasks by formulating decision-making as sequential generation.
However, the practicality of these methods is limited due to the lengthy
inference processes they require. In this paper, we address this problem by
decomposing the sampling process of diffusion models into two decoupled
subprocesses: 1) generating a feasible trajectory, which is a time-consuming
process, and 2) optimizing the trajectory. With this decomposition approach, we
are able to partially separate efficiency and quality factors, enabling us to
simultaneously gain efficiency advantages and ensure quality assurance. We
propose the Trajectory Diffuser, which utilizes a faster autoregressive model
to handle the generation of feasible trajectories while retaining the
trajectory optimization process of diffusion models. This allows us to achieve
more efficient planning without sacrificing capability. To evaluate the
effectiveness and efficiency of the Trajectory Diffuser, we conduct experiments
on the D4RL benchmarks. The results demonstrate that our method achieves $\it
3$-$\it 10 \times$ faster inference speed compared to previous sequence
modeling methods, while also outperforming them in terms of overall
performance. https://github.com/RenMing-Huang/TrajectoryDiffuser
  Keywords: Reinforcement Learning and Efficient Planning and Diffusion Model

摘要：擴散模型透過將決策制定表述為順序生成，在離線強化學習任務中展現強勁的競爭力。然而，這些方法的實用性受到其所需的冗長推論過程所限制。在本文中，我們透過將擴散模型的採樣過程分解為兩個解耦的子程序來解決此問題：1) 生成可行的軌跡，這是一個耗時費力的過程，以及 2) 最佳化軌跡。透過這種分解方法，我們能夠部分地將效率和品質因素分開，讓我們能夠同時獲得效率優勢並確保品質保證。我們提出軌跡擴散器，它利用更快速的自動迴歸模型來處理可行軌跡的生成，同時保留擴散模型的軌跡最佳化過程。這讓我們能夠在不犧牲能力的情況下實現更有效的規劃。為了評估軌跡擴散器的有效性和效率，我們在 D4RL 基準上進行實驗。結果表明，與先前的序列建模方法相比，我們的模型實現了快 $\it 3$-$\it 10 \times$ 倍的推論速度，同時在整體效能方面也優於它們。https://github.com/RenMing-Huang/TrajectoryDiffuser
關鍵字：強化學習與高效規劃與擴散模型

##### **FoRA: Low-Rank Adaptation Model beyond Multimodal Siamese Network**
2407.16129v1 by Weiying Xie, Yusi Zhang, Tianlin Hui, Jiaqing Zhang, Jie Lei, Yunsong Li

Multimodal object detection offers a promising prospect to facilitate robust
detection in various visual conditions. However, existing two-stream backbone
networks are challenged by complex fusion and substantial parameter increments.
This is primarily due to large data distribution biases of multimodal
homogeneous information. In this paper, we propose a novel multimodal object
detector, named Low-rank Modal Adaptors (LMA) with a shared backbone. The
shared parameters enhance the consistency of homogeneous information, while
lightweight modal adaptors focus on modality unique features. Furthermore, we
design an adaptive rank allocation strategy to adapt to the varying
heterogeneity at different feature levels. When applied to two multimodal
object detection datasets, experiments validate the effectiveness of our
method. Notably, on DroneVehicle, LMA attains a 10.4% accuracy improvement over
the state-of-the-art method with a 149M-parameters reduction. The code is
available at https://github.com/zyszxhy/FoRA.
  Our work was submitted to ACM MM in April 2024, but was rejected. We will
continue to refine our work and paper writing next, mainly including proof of
theory and multi-task applications of FoRA.

摘要：多模态物体检测为在各种视觉条件下促进稳健检测提供了有希望的前景。然而，现有的双流骨干网络面临着复杂的融合和大量的参数增量。这主要是由于多模态同质信息的巨大数据分布偏差。在本文中，我们提出了一种新颖的多模态物体检测器，名为低秩模态适配器（LMA），它具有共享的骨干。共享参数增强了同质信息的稠密性，而轻量级模态适配器则专注于模态的独特特征。此外，我们设计了一种自适应秩分配策略来适应不同特征级别上的不同异质性。当应用于两个多模态物体检测数据集时，实验验证了我们方法的有效性。值得注意的是，在 DroneVehicle 上，LMA 在减少 149M 参数的情况下，比最先进的方法提高了 10.4% 的准确度。代码可在 https://github.com/zyszxhy/FoRA 获得。我们的工作已于 2024 年 4 月提交至 ACM MM，但被拒。接下来，我们将继续完善我们的工作和论文写作，主要包括 FoRA 的理论证明和多任务应用。

##### **Advancing Brain Imaging Analysis Step-by-step via Progressive Self-paced Learning**
2407.16128v1 by Yanwu Yang, Hairui Chen, Jiesi Hu, Xutao Guo, Ting Ma

Recent advancements in deep learning have shifted the development of brain
imaging analysis. However, several challenges remain, such as heterogeneity,
individual variations, and the contradiction between the high dimensionality
and small size of brain imaging datasets. These issues complicate the learning
process, preventing models from capturing intrinsic, meaningful patterns and
potentially leading to suboptimal performance due to biases and overfitting.
Curriculum learning (CL) presents a promising solution by organizing training
examples from simple to complex, mimicking the human learning process, and
potentially fostering the development of more robust and accurate models.
Despite its potential, the inherent limitations posed by small initial training
datasets present significant challenges, including overfitting and poor
generalization. In this paper, we introduce the Progressive Self-Paced
Distillation (PSPD) framework, employing an adaptive and progressive pacing and
distillation mechanism. This allows for dynamic curriculum adjustments based on
the states of both past and present models. The past model serves as a teacher,
guiding the current model with gradually refined curriculum knowledge and
helping prevent the loss of previously acquired knowledge. We validate PSPD's
efficacy and adaptability across various convolutional neural networks using
the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset, underscoring
its superiority in enhancing model performance and generalization capabilities.
The source code for this approach will be released at
https://github.com/Hrychen7/PSPD.

摘要：深度學習最近的進展改變了大腦影像分析的發展。然而，仍有許多挑戰，例如異質性、個別差異，以及大腦影像資料集的高維度與小規模之間的矛盾。這些問題使學習過程複雜化，導致模型無法擷取內在且有意義的模式，並可能因偏差和過度擬合而導致次佳的效能。課程學習 (CL) 透過從簡單到複雜組織訓練範例，模仿人類的學習過程，並可能促進更強健且精確的模型發展，提供一個有希望的解決方案。儘管有其潛力，小型初始訓練資料集所造成的固有限制仍會帶來重大的挑戰，包括過度擬合和不佳的概化。在本文中，我們介紹漸進式自訂步調蒸餾 (PSPD) 架構，採用適應性和漸進式步調以及蒸餾機制。這允許根據過去和現在模型的狀態進行動態課程調整。過去的模型擔任教師，以逐漸精煉的課程知識引導目前的模型，並有助於防止先前獲得的知識流失。我們使用阿茲海默症神經影像計畫 (ADNI) 資料集，驗證 PSPD 在各種卷積神經網路的效能和適應性，強調其在增強模型效能和概化能力方面的優越性。此方法的原始程式碼將在 https://github.com/Hrychen7/PSPD 發布。

##### **Finetuning Generative Large Language Models with Discrimination Instructions for Knowledge Graph Completion**
2407.16127v1 by Yang Liu, Xiaobin Tian, Zequn Sun, Wei Hu

Traditional knowledge graph (KG) completion models learn embeddings to
predict missing facts. Recent works attempt to complete KGs in a
text-generation manner with large language models (LLMs). However, they need to
ground the output of LLMs to KG entities, which inevitably brings errors. In
this paper, we present a finetuning framework, DIFT, aiming to unleash the KG
completion ability of LLMs and avoid grounding errors. Given an incomplete
fact, DIFT employs a lightweight model to obtain candidate entities and
finetunes an LLM with discrimination instructions to select the correct one
from the given candidates. To improve performance while reducing instruction
data, DIFT uses a truncated sampling method to select useful facts for
finetuning and injects KG embeddings into the LLM. Extensive experiments on
benchmark datasets demonstrate the effectiveness of our proposed framework.

摘要：傳統知識圖譜（KG）完成功能模型學習嵌入，以預測遺失的事實。最近的工作嘗試以大型語言模型（LLM）以文字生成的方式完成 KG。然而，他們需要將 LLM 的輸出基礎建立在 KG 實體上，這不可避免地會帶來錯誤。在本文中，我們提出了一個微調框架 DIFT，旨在釋放 LLM 的 KG 完成功能，並避免基礎錯誤。給定一個不完整的事實，DIFT 使用一個輕量級模型來獲得候選實體，並微調一個 LLM，並使用辨別指令從給定的候選項中選擇正確的實體。為了在減少指令數據的同時提升效能，DIFT 使用一個截斷抽樣方法來選擇有用的事實以進行微調，並將 KG 嵌入注入到 LLM 中。在基準資料集上的廣泛實驗證明了我們提出的框架的有效性。

##### **Uncertainty-Aware Deep Neural Representations for Visual Analysis of Vector Field Data**
2407.16119v1 by Atul Kumar, Siddharth Garg, Soumya Dutta

The widespread use of Deep Neural Networks (DNNs) has recently resulted in
their application to challenging scientific visualization tasks. While advanced
DNNs demonstrate impressive generalization abilities, understanding factors
like prediction quality, confidence, robustness, and uncertainty is crucial.
These insights aid application scientists in making informed decisions.
However, DNNs lack inherent mechanisms to measure prediction uncertainty,
prompting the creation of distinct frameworks for constructing robust
uncertainty-aware models tailored to various visualization tasks. In this work,
we develop uncertainty-aware implicit neural representations to model
steady-state vector fields effectively. We comprehensively evaluate the
efficacy of two principled deep uncertainty estimation techniques: (1) Deep
Ensemble and (2) Monte Carlo Dropout, aimed at enabling uncertainty-informed
visual analysis of features within steady vector field data. Our detailed
exploration using several vector data sets indicate that uncertainty-aware
models generate informative visualization results of vector field features.
Furthermore, incorporating prediction uncertainty improves the resilience and
interpretability of our DNN model, rendering it applicable for the analysis of
non-trivial vector field data sets.

摘要：深度神经网络（DNN）的广泛使用最近导致其应用于具有挑战性的科学可视化任务。虽然先进的 DNN 展示了令人印象深刻的泛化能力，但了解预测质量、置信度、鲁棒性和不确定性等因素至关重要。这些见解有助于应用科学家做出明智的决策。然而，DNN 缺乏衡量预测不确定性的内在机制，促使创建不同的框架来构建针对各种可视化任务量身定制的鲁棒的不确定性感知模型。在这项工作中，我们开发了不确定性感知的隐式神经表示来有效地对稳态矢量场进行建模。我们全面评估了两种原则性深度不确定性估计技术的有效性：(1) 深度集成和 (2) 蒙特卡洛丢弃，旨在实现对稳态矢量场数据中特征的不确定性知情视觉分析。我们使用几个矢量数据集进行的详细探索表明，不确定性感知模型生成了矢量场特征的信息可视化结果。此外，纳入预测不确定性提高了我们 DNN 模型的弹性和可解释性，使其适用于分析非平凡矢量场数据集。

##### **Transformer-based Graph Neural Networks for Battery Range Prediction in AIoT Battery-Swap Services**
2407.16115v1 by Zhao Li, Yang Liu, Chuan Zhou, Xuanwu Liu, Xuming Pan, Buqing Cao, Xindong Wu

The concept of the sharing economy has gained broad recognition, and within
this context, Sharing E-Bike Battery (SEB) have emerged as a focal point of
societal interest. Despite the popularity, a notable discrepancy remains
between user expectations regarding the remaining battery range of SEBs and the
reality, leading to a pronounced inclination among users to find an available
SEB during emergency situations. In response to this challenge, the integration
of Artificial Intelligence of Things (AIoT) and battery-swap services has
surfaced as a viable solution. In this paper, we propose a novel structural
Transformer-based model, referred to as the SEB-Transformer, designed
specifically for predicting the battery range of SEBs. The scenario is
conceptualized as a dynamic heterogeneous graph that encapsulates the
interactions between users and bicycles, providing a comprehensive framework
for analysis. Furthermore, we incorporate the graph structure into the
SEB-Transformer to facilitate the estimation of the remaining e-bike battery
range, in conjunction with mean structural similarity, enhancing the prediction
accuracy. By employing the predictions made by our model, we are able to
dynamically adjust the optimal cycling routes for users in real-time, while
also considering the strategic locations of charging stations, thereby
optimizing the user experience. Empirically our results on real-world datasets
demonstrate the superiority of our model against nine competitive baselines.
These innovations, powered by AIoT, not only bridge the gap between user
expectations and the physical limitations of battery range but also
significantly improve the operational efficiency and sustainability of SEB
services. Through these advancements, the shared electric bicycle ecosystem is
evolving, making strides towards a more reliable, user-friendly, and
sustainable mode of transportation.

摘要：共享經濟的概念已經獲得廣泛的認可，在此背景下，共享電動自行車電池（SEB）已成為社會關注的焦點。儘管很受歡迎，但使用者對於 SEB 剩餘電池續航力的期望與現實之間仍存在顯著的差異，這導致使用者在緊急情況下強烈傾向於尋找可用的 SEB。為了應對這一挑戰，物聯網人工智慧（AIoT）和換電服務的整合浮現為可行的解決方案。在本文中，我們提出了一個新穎的基於 Transformer 的模型，稱為 SEB-Transformer，專門設計用於預測 SEB 的電池續航力。該場景被概念化为一個動態異構圖，它概括了使用者和自行車之間的交互，提供了一個全面的分析框架。此外，我們將圖結構納入 SEB-Transformer，以促進估計剩餘電動自行車電池續航力，結合平均結構相似性，提高預測準確度。通過採用我們模型做出的預測，我們能夠動態調整使用者的最佳騎行路線，同時也考慮充電站的策略位置，從而優化使用者體驗。我們在真實世界數據集上的實證結果證明了我們的模型優於九個競爭基線。這些由 AIoT 提供支持的創新不僅彌合了使用者期望與電池續航力的物理限制之間的差距，而且還顯著提高了 SEB 服務的運營效率和可持續性。通過這些進步，共享電動自行車生態系統正在不斷發展，朝著更可靠、更使用者友善和更可持續的交通方式邁進。

##### **Modelling brain connectomes networks: Solv is a worthy competitor to hyperbolic geometry!**
2407.16077v1 by Dorota Celińska-Kopczyńska, Eryk Kopczyński

Finding suitable embeddings for connectomes (spatially embedded complex
networks that map neural connections in the brain) is crucial for analyzing and
understanding cognitive processes. Recent studies have found two-dimensional
hyperbolic embeddings superior to Euclidean embeddings in modeling connectomes
across species, especially human connectomes. However, those studies had
limitations: geometries other than Euclidean, hyperbolic, or spherical were not
considered. Following William Thurston's suggestion that the networks of
neurons in the brain could be successfully represented in Solv geometry, we
study the goodness-of-fit of the embeddings for 21 connectome networks (8
species). To this end, we suggest an embedding algorithm based on Simulating
Annealing that allows us to embed connectomes to Euclidean, Spherical,
Hyperbolic, Solv, Nil, and product geometries. Our algorithm tends to find
better embeddings than the state-of-the-art, even in the hyperbolic case. Our
findings suggest that while three-dimensional hyperbolic embeddings yield the
best results in many cases, Solv embeddings perform reasonably well.

摘要：尋找適合連接體的嵌入（空間嵌入複雜網路，用於繪製大腦中的神經連接）對於分析和理解認知過程至關重要。最近的研究發現，在跨物種建模連接體時，雙曲線嵌入優於歐幾里得嵌入，特別是人類連接體。然而，這些研究存在局限性：歐幾里得、雙曲線或球面以外的幾何形狀並未被考慮。根據 William Thurston 的建議，大腦中的神經網路可以用 Solv 幾何成功表示，我們研究了 21 個連接體網路（8 個物種）的嵌入擬合優度。為此，我們提出了一種基於模擬退火的嵌入演算法，它允許我們將連接體嵌入到歐幾里得、球面、雙曲線、Solv、Nil 和乘積幾何中。我們的演算法傾向於找到比最先進的技術更好的嵌入，即使在雙曲線情況下也是如此。我們的研究結果表明，儘管三維雙曲線嵌入在許多情況下產生最佳結果，但 Solv 嵌入表現得相當好。

##### **KaPQA: Knowledge-Augmented Product Question-Answering**
2407.16073v1 by Swetha Eppalapally, Daksh Dangi, Chaithra Bhat, Ankita Gupta, Ruiyi Zhang, Shubham Agarwal, Karishma Bagga, Seunghyun Yoon, Nedim Lipka, Ryan A. Rossi, Franck Dernoncourt

Question-answering for domain-specific applications has recently attracted
much interest due to the latest advancements in large language models (LLMs).
However, accurately assessing the performance of these applications remains a
challenge, mainly due to the lack of suitable benchmarks that effectively
simulate real-world scenarios. To address this challenge, we introduce two
product question-answering (QA) datasets focused on Adobe Acrobat and Photoshop
products to help evaluate the performance of existing models on domain-specific
product QA tasks. Additionally, we propose a novel knowledge-driven RAG-QA
framework to enhance the performance of the models in the product QA task. Our
experiments demonstrated that inducing domain knowledge through query
reformulation allowed for increased retrieval and generative performance when
compared to standard RAG-QA methods. This improvement, however, is slight, and
thus illustrates the challenge posed by the datasets introduced.

摘要：由於大型語言模型 (LLM) 的最新進展，特定領域應用程式的問答最近引起了極大的興趣。然而，準確評估這些應用程式的效能仍然是一項挑戰，主要是由於缺乏能有效模擬真實世界場景的合適基準測試。為了應對這項挑戰，我們引入了兩個產品問答 (QA) 資料集，專注於 Adobe Acrobat 和 Photoshop 產品，以幫助評估現有模型在特定領域產品 QA 任務上的效能。此外，我們提出了一個新穎的知識驅動 RAG-QA 架構，以增強模型在產品 QA 任務中的效能。我們的實驗表明，與標準 RAG-QA 方法相比，透過查詢重新制定來誘導領域知識，可以提高檢索和生成效能。然而，這種改進很小，因此說明了所引入資料集所帶來的挑戰。

##### **LCA-on-the-Line: Benchmarking Out-of-Distribution Generalization with Class Taxonomies**
2407.16067v1 by Jia Shi, Gautam Gare, Jinjin Tian, Siqi Chai, Zhiqiu Lin, Arun Vasudevan, Di Feng, Francesco Ferroni, Shu Kong

We tackle the challenge of predicting models' Out-of-Distribution (OOD)
performance using in-distribution (ID) measurements without requiring OOD data.
Existing evaluations with "Effective Robustness", which use ID accuracy as an
indicator of OOD accuracy, encounter limitations when models are trained with
diverse supervision and distributions, such as class labels (Vision Models,
VMs, on ImageNet) and textual descriptions (Visual-Language Models, VLMs, on
LAION). VLMs often generalize better to OOD data than VMs despite having
similar or lower ID performance. To improve the prediction of models' OOD
performance from ID measurements, we introduce the Lowest Common Ancestor
(LCA)-on-the-Line framework. This approach revisits the established concept of
LCA distance, which measures the hierarchical distance between labels and
predictions within a predefined class hierarchy, such as WordNet. We assess 75
models using ImageNet as the ID dataset and five significantly shifted OOD
variants, uncovering a strong linear correlation between ID LCA distance and
OOD top-1 accuracy. Our method provides a compelling alternative for
understanding why VLMs tend to generalize better. Additionally, we propose a
technique to construct a taxonomic hierarchy on any dataset using K-means
clustering, demonstrating that LCA distance is robust to the constructed
taxonomic hierarchy. Moreover, we demonstrate that aligning model predictions
with class taxonomies, through soft labels or prompt engineering, can enhance
model generalization. Open source code in our Project Page:
https://elvishelvis.github.io/papers/lca/.

摘要：<paragraph>我們使用分佈內 (ID) 度量來解決預測模型的分布外 (OOD) 效能的挑戰，而不需要 OOD 資料。
現有的「有效魯棒性」評估將 ID 精確度用作 OOD 精確度的指標，當模型使用不同的監督和分佈（例如類別標籤（視覺模型，VM，在 ImageNet 上）和文字描述（視覺語言模型，VLM，在 LAION 上））訓練時會遇到限制。儘管具有相似或較低的 ID 效能，但 VLM 通常比 VM 更能概括到 OOD 資料。為了從 ID 度量改進模型的 OOD 效能預測，我們引入了線性上的最低共同祖先 (LCA) 架構。此方法重新審視了已建立的 LCA 距離概念，該概念測量標籤和預測之間的層次距離，在預定義的類別層次結構中，例如 WordNet。我們使用 ImageNet 作為 ID 資料集和五個顯著轉移的 OOD 變體評估了 75 個模型，發現 ID LCA 距離和 OOD 前 1 精確度之間存在強烈的線性相關性。我們的模型提供了一個令人信服的替代方案，用於了解為什麼 VLM 傾向於更好地概括。此外，我們提出了一種使用 K 均值聚類在任何資料集上構建分類層次結構的技術，證明 LCA 距離對構建的分類層次結構具有魯棒性。此外，我們證明了通過軟標籤或提示工程將模型預測與類別分類保持一致，可以增強模型概括。開放原始碼在我們的專案頁面：
https://elvishelvis.github.io/papers/lca/。</paragraph>

##### **Leveraging Large Language Models to Geolocate Linguistic Variations in Social Media Posts**
2407.16047v1 by Davide Savarro, Davide Zago, Stefano Zoia

Geolocalization of social media content is the task of determining the
geographical location of a user based on textual data, that may show linguistic
variations and informal language. In this project, we address the GeoLingIt
challenge of geolocalizing tweets written in Italian by leveraging large
language models (LLMs). GeoLingIt requires the prediction of both the region
and the precise coordinates of the tweet. Our approach involves fine-tuning
pre-trained LLMs to simultaneously predict these geolocalization aspects. By
integrating innovative methodologies, we enhance the models' ability to
understand the nuances of Italian social media text to improve the
state-of-the-art in this domain. This work is conducted as part of the Large
Language Models course at the Bertinoro International Spring School 2024. We
make our code publicly available on GitHub
https://github.com/dawoz/geolingit-biss2024.

摘要：社交媒體內容的地理定位是根據可能顯示語言變異和非正式語言的文字資料，來確定使用者的地理位置的任務。在這個專案中，我們透過利用大型語言模型 (LLM) 來處理以義大利文撰寫的推文地理定位的 GeoLingIt 挑戰。GeoLingIt 需要預測推文的區域和精確座標。我們的做法包括微調預先訓練的 LLM，以同時預測這些地理定位面向。透過整合創新的方法，我們增強模型了解義大利文社交媒體文字細微差别的能力，以提升這個領域的最新技術。這項工作是作為 2024 年貝爾蒂諾羅國際春季學校的大型語言模型課程的一部分進行的。我們在 GitHub 上公開我們的程式碼 https://github.com/dawoz/geolingit-biss2024。

##### **Generalizing Teacher Networks for Effective Knowledge Distillation Across Student Architectures**
2407.16040v1 by Kuluhan Binici, Weiming Wu, Tulika Mitra

Knowledge distillation (KD) is a model compression method that entails
training a compact student model to emulate the performance of a more complex
teacher model. However, the architectural capacity gap between the two models
limits the effectiveness of knowledge transfer. Addressing this issue, previous
works focused on customizing teacher-student pairs to improve compatibility, a
computationally expensive process that needs to be repeated every time either
model changes. Hence, these methods are impractical when a teacher model has to
be compressed into different student models for deployment on multiple hardware
devices with distinct resource constraints. In this work, we propose Generic
Teacher Network (GTN), a one-off KD-aware training to create a generic teacher
capable of effectively transferring knowledge to any student model sampled from
a given finite pool of architectures. To this end, we represent the student
pool as a weight-sharing supernet and condition our generic teacher to align
with the capacities of various student architectures sampled from this
supernet. Experimental evaluation shows that our method both improves overall
KD effectiveness and amortizes the minimal additional training cost of the
generic teacher across students in the pool.

摘要：知识蒸馏 (KD) 是一种模型压缩方法，它需要
训练一个紧凑的学生模型来模拟一个更复杂的
教师模型的性能。然而，这两个模型之间的架构容量差距
限制了知识转移的有效性。为了解决这个问题，以前
的工作重点是定制师生对以提高兼容性，这是一个
计算成本很高的过程，需要在每次模型更改时重复进行。因此，这些方法在教师模型必须
被压缩成不同的学生模型以在具有不同资源约束的多个硬件
设备上部署时是不切实际的。在这项工作中，我们提出了通用
教师网络 (GTN)，一种一次性的 KD 感知训练，用于创建通用教师
能够有效地将知识转移到从
给定的有限架构池中采样的任何学生模型。为此，我们将学生
池表示为一个权重共享的超网络，并对我们的通用教师进行条件设置，使其与容量保持一致
从这个超网络中采样的各种学生架构。实验评估表明，我们的方法既提高了整体
KD 的有效性，并且摊销了通用教师在池中的学生之间的最低额外训练成本。

##### **Enhancing Temporal Understanding in LLMs for Semi-structured Tables**
2407.16030v1 by Irwin Deng, Kushagra Dixit, Vivek Gupta, Dan Roth

Temporal reasoning over tabular data presents substantial challenges for
large language models (LLMs), as evidenced by recent research. In this study,
we conduct a comprehensive analysis of temporal datasets to pinpoint the
specific limitations of LLMs. Our investigation leads to enhancements in
TempTabQA, a dataset specifically designed for tabular temporal question
answering. We provide critical insights for improving LLM performance in
temporal reasoning tasks with tabular data. Furthermore, we introduce a novel
approach, C.L.E.A.R to strengthen LLM capabilities in this domain. Our findings
demonstrate that our method significantly improves evidence-based reasoning
across various models. Additionally, our experimental results reveal that
indirect supervision with auxiliary data substantially boosts model performance
in these tasks. This work contributes to a deeper understanding of LLMs'
temporal reasoning abilities over tabular data and promotes advancements in
their application across diverse fields.

摘要：基於表格資料的時序推理對大型語言模型 (LLM) 構成重大挑戰，最近的研究已證實這一點。在此研究中，我們對時序資料集進行全面分析，以精確找出 LLM 的具體限制。我們的調查促成了 TempTabQA 的改進，TempTabQA 是專門為表格時序問題解答而設計的資料集。我們提供關鍵見解，以提升 LLM 在使用表格資料進行時序推理任務時的效能。此外，我們提出了一種新方法 C.L.E.A.R，以強化 LLM 在此領域的能力。我們的發現證明，我們的方法顯著改善了各種模型的基於證據的推理。此外，我們的實驗結果顯示，使用輔助資料進行間接監督會大幅提升模型在這些任務中的效能。這項工作有助於更深入了解 LLM 對表格資料的時序推理能力，並促使它們在不同領域的應用進一步發展。

##### **KWT-Tiny: RISC-V Accelerated, Embedded Keyword Spotting Transformer**
2407.16026v1 by Aness Al-Qawlaq, Ajay Kumar M, Deepu John

This paper explores the adaptation of Transformerbased models for edge
devices through the quantisation and hardware acceleration of the ARM Keyword
Transformer (KWT) model on a RISC-V platform. The model was targeted to run on
64kB RAM in bare-metal C using a custom-developed edge AI library. KWT-1 was
retrained to be 369 times smaller, with only a 10% loss in accuracy through
reducing output classes from 35 to 2. The retraining and quantisation reduced
model size from 2.42 MB to 1.65 kB. The integration of custom RISC-V
instructions that accelerated GELU and SoftMax operations enabled a 5x speedup
and thus ~5x power reduction in inference, with inference clock cycle counts
decreasing from 26 million to 5.5 million clock cycles while incurring a small
area overhead of approximately 29%. The results demonstrate a viable method for
porting and accelerating Transformer-based models in low-power IoT devices.

摘要：本文探討了透過量化和硬體加速 ARM 關鍵字轉換器 (KWT) 模型於 RISC-V 平台上，將基於 Transformer 的模型調整到邊緣裝置。該模型目標在於使用自訂開發的邊緣 AI 函式庫，以裸機 C 語言在 64kB RAM 上執行。KWT-1 重新訓練後縮小為 369 倍，但輸出類別從 35 減少到 2，僅損失 10% 的準確度。重新訓練和量化將模型大小從 2.42 MB 縮小到 1.65 kB。整合自訂 RISC-V 指令加速 GELU 和 SoftMax 運算，使推論速度提升 5 倍，進而將推論功耗降低約 5 倍，推論時脈週期數從 2600 萬減少到 550 萬時脈週期，同時增加約 29% 的小面積開銷。結果證明了將基於 Transformer 的模型移植到低功耗 IoT 裝置並加速其運作的可行方法。

##### **Exploring and Addressing Reward Confusion in Offline Preference Learning**
2407.16025v1 by Xin Chen, Sam Toyer, Florian Shkurti

Spurious correlations in a reward model's training data can prevent
Reinforcement Learning from Human Feedback (RLHF) from identifying the desired
goal and induce unwanted behaviors. This paper shows that offline RLHF is
susceptible to reward confusion, especially in the presence of spurious
correlations in offline data. We create a benchmark to study this problem and
propose a method that can significantly reduce reward confusion by leveraging
transitivity of preferences while building a global preference chain with
active learning.

摘要：在獎勵模型的訓練資料中，虛假的關聯性可能會阻止從人類回饋中進行強化學習 (RLHF) 來識別所需的目標，並誘發不需要的行為。本文顯示，離線 RLHF 容易受到獎勵混淆的影響，特別是在離線資料中存在虛假關聯性的情況下。我們建立一個基準來研究這個問題，並提出一個方法，該方法可以透過在建立具有主動學習的全局偏好鏈時利用偏好的遞移性，來大幅減少獎勵混淆。

##### **AIDE: Antithetical, Intent-based, and Diverse Example-Based Explanations**
2407.16010v1 by Ikhtiyor Nematov, Dimitris Sacharidis, Tomer Sagi, Katja Hose

For many use-cases, it is often important to explain the prediction of a
black-box model by identifying the most influential training data samples.
Existing approaches lack customization for user intent and often provide a
homogeneous set of explanation samples, failing to reveal the model's reasoning
from different angles.
  In this paper, we propose AIDE, an approach for providing antithetical (i.e.,
contrastive), intent-based, diverse explanations for opaque and complex models.
AIDE distinguishes three types of explainability intents: interpreting a
correct, investigating a wrong, and clarifying an ambiguous prediction. For
each intent, AIDE selects an appropriate set of influential training samples
that support or oppose the prediction either directly or by contrast. To
provide a succinct summary, AIDE uses diversity-aware sampling to avoid
redundancy and increase coverage of the training data.
  We demonstrate the effectiveness of AIDE on image and text classification
tasks, in three ways: quantitatively, assessing correctness and continuity;
qualitatively, comparing anecdotal evidence from AIDE and other example-based
approaches; and via a user study, evaluating multiple aspects of AIDE. The
results show that AIDE addresses the limitations of existing methods and
exhibits desirable traits for an explainability method.

摘要：對於許多使用案例，透過找出最具影響力的訓練資料範例，解釋黑盒子模型的預測通常很重要。
現有的方法缺乏針對使用者意圖的客製化，且經常提供一組同質的解釋範例，無法從不同角度揭示模型的推理。
在本文中，我們提出 AIDE，一種為不透明且複雜的模型提供對立（即對比）、基於意圖、多樣化的解釋的方法。
AIDE 區分三種類型的可解釋性意圖：解釋正確、調查錯誤、澄清模稜兩可的預測。對於每個意圖，AIDE 選擇一組適當的影響力訓練範例，直接或對比地支持或反對預測。為了提供簡潔的摘要，AIDE 使用考慮多樣性的抽樣來避免冗餘並增加訓練資料的覆蓋率。
我們以三種方式展示 AIDE 在圖像和文字分類任務上的有效性：定量評估正確性和連續性；定性比較 AIDE 和其他基於範例的方法的軼事證據；以及透過使用者研究評估 AIDE 的多個面向。結果顯示 AIDE 解决了現有方法的限制，並展示了解釋性方法所需的理想特質。

##### **Boosting Reward Model with Preference-Conditional Multi-Aspect Synthetic Data Generation**
2407.16008v1 by Jiaming Shen, Ran Xu, Yennie Jun, Zhen Qin, Tianqi Liu, Carl Yang, Yi Liang, Simon Baumgartner, Michael Bendersky

Reward models (RMs) are crucial for aligning large language models (LLMs)
with human preferences. They are trained using preference datasets where each
example consists of one input prompt, two responses, and a preference label. As
curating a high-quality human labeled preference dataset is both time-consuming
and expensive, people often rely on existing powerful LLMs for preference label
generation. This can potentially introduce noise and impede RM training. In
this work, we present RMBoost, a novel synthetic preference data generation
paradigm to boost reward model quality. Unlike traditional methods, which
generate two responses before obtaining the preference label, RMBoost first
generates one response and selects a preference label, followed by generating
the second more (or less) preferred response conditioned on the pre-selected
preference label and the first response. This approach offers two main
advantages. First, RMBoost reduces labeling noise since preference pairs are
constructed intentionally. Second, RMBoost facilitates the creation of more
diverse responses by incorporating various quality aspects (e.g., helpfulness,
relevance, completeness) into the prompts. We conduct extensive experiments
across three diverse datasets and demonstrate that RMBoost outperforms other
synthetic preference data generation techniques and significantly boosts the
performance of four distinct reward models.

摘要：獎勵模型 (RM) 對於將大型語言模型 (LLM) 與人類偏好對齊至關重要。它們使用偏好資料集進行訓練，其中每個範例包含一個輸入提示、兩個回應和一個偏好標籤。由於策劃一個高品質的人類標記偏好資料集既耗時又昂貴，因此人們通常依賴現有的強大 LLM 來產生偏好標籤。這可能會引入雜訊並阻礙 RM 訓練。在這項工作中，我們提出了 RMBoost，這是一種新穎的合成偏好資料產生範例，用於提升獎勵模型品質。與在取得偏好標籤之前產生兩個回應的傳統方法不同，RMBoost 首先產生一個回應並選擇一個偏好標籤，然後在預先選取的偏好標籤和第一個回應的條件下產生第二個更（或更不）偏好的回應。這種方法提供了兩個主要優點。首先，RMBoost 減少了標記雜訊，因為偏好對是故意建構的。其次，RMBoost 透過將各種品質面向（例如，有用性、相關性、完整性）納入提示中，促進了更多樣化回應的產生。我們在三個不同的資料集上進行了廣泛的實驗，並證明 RMBoost 優於其他合成偏好資料產生技術，並顯著提升了四個不同獎勵模型的效能。

##### **SocialQuotes: Learning Contextual Roles of Social Media Quotes on the Web**
2407.16007v1 by John Palowitch, Hamidreza Alvari, Mehran Kazemi, Tanvir Amin, Filip Radlinski

Web authors frequently embed social media to support and enrich their
content, creating the potential to derive web-based, cross-platform social
media representations that can enable more effective social media retrieval
systems and richer scientific analyses. As step toward such capabilities, we
introduce a novel language modeling framework that enables automatic annotation
of roles that social media entities play in their embedded web context. Using
related communication theory, we liken social media embeddings to quotes,
formalize the page context as structured natural language signals, and identify
a taxonomy of roles for quotes within the page context. We release
SocialQuotes, a new data set built from the Common Crawl of over 32 million
social quotes, 8.3k of them with crowdsourced quote annotations. Using
SocialQuotes and the accompanying annotations, we provide a role classification
case study, showing reasonable performance with modern-day LLMs, and exposing
explainable aspects of our framework via page content ablations. We also
classify a large batch of un-annotated quotes, revealing interesting
cross-domain, cross-platform role distributions on the web.

摘要：網頁作者經常嵌入社群媒體以支援並豐富其內容，創造出衍生出基於網路、跨平台社群媒體表述的可能性，這些表述能建構更有效率的社群媒體檢索系統和更豐富的科學分析。作為朝向此類能力邁進的一步，我們提出一個新穎的語言模型架構，讓社群媒體實體在其嵌入的網路脈絡中扮演的角色能自動註解。利用相關的溝通理論，我們將社群媒體嵌入比擬為引述，將網頁脈絡形式化為結構化的自然語言訊號，並找出網頁脈絡中引述角色的分類法。我們釋出 SocialQuotes，一個從超過 3200 萬筆社群引述的 Common Crawl 建立的新資料集，其中 8.3k 筆有眾包引述註解。利用 SocialQuotes 和附帶的註解，我們提供了一個角色分類案例研究，展示出使用現代 LLM 的合理效能，並透過網頁內容消融揭露我們架構的可解釋面向。我們也分類了一大批未註解引述，揭露網路上跨網域、跨平台的角色分佈。

##### **Multimodal Input Aids a Bayesian Model of Phonetic Learning**
2407.15992v1 by Sophia Zhi, Roger P. Levy, Stephan C. Meylan

One of the many tasks facing the typically-developing child language learner
is learning to discriminate between the distinctive sounds that make up words
in their native language. Here we investigate whether multimodal
information--specifically adult speech coupled with video frames of speakers'
faces--benefits a computational model of phonetic learning. We introduce a
method for creating high-quality synthetic videos of speakers' faces for an
existing audio corpus. Our learning model, when both trained and tested on
audiovisual inputs, achieves up to a 8.1% relative improvement on a phoneme
discrimination battery compared to a model trained and tested on audio-only
input. It also outperforms the audio model by up to 3.9% when both are tested
on audio-only data, suggesting that visual information facilitates the
acquisition of acoustic distinctions. Visual information is especially
beneficial in noisy audio environments, where an audiovisual model closes 67%
of the loss in discrimination performance of the audio model in noise relative
to a non-noisy environment. These results demonstrate that visual information
benefits an ideal learner and illustrate some of the ways that children might
be able to leverage visual cues when learning to discriminate speech sounds.

摘要：對於一般發展中的兒童語言學習者來說，其中一項重大的任務，是學會區分構成其母語單字的獨特聲音。我們在此探討多模式資訊（特別是成人語音搭配說話者臉部的影片畫面）是否對語音學習的運算模型有幫助。我們提出一個方法，用於為現有的音訊語料庫製作高品質的說話者臉部合成影片。我們的學習模型在接受音訊視覺輸入的訓練和測試後，在音素辨別電池上獲得高達 8.1% 的相對進步，與僅接受音訊輸入訓練和測試的模型相比。當兩者都接受音訊輸入的測試時，我們的學習模型也比音訊模型高出 3.9%，這表示視覺資訊有助於獲得音訊區別。在有雜訊的音訊環境中，視覺資訊特別有幫助，在這種環境中，音訊視覺模型彌補了音訊模型在有雜訊環境中，辨別效能相對於無雜訊環境的 67% 損失。這些結果證明視覺資訊對理想的學習者有幫助，並說明了兒童在學習辨別語音時，可能如何利用視覺提示。

##### **AI for Handball: predicting and explaining the 2024 Olympic Games tournament with Deep Learning and Large Language Models**
2407.15987v1 by Florian Felice

Over summer 2024, the world will be looking at Paris to encourage their
favorite athletes win the Olympic gold medal. In handball, few nations will
fight hard to win the precious metal with speculations predicting the victory
for France or Denmark for men and France or Norway for women. However, there is
so far no scientific method proposed to predict the final results of the
competition. In this work, we leverage a deep learning model to predict the
results of the handball tournament of the 2024 Olympic Games. This model,
coupled with explainable AI (xAI) techniques, allows us to extract insightful
information about the main factors influencing the outcome of each match.
Notably, xAI helps sports experts understand how factors like match information
or individual athlete performance contribute to the predictions. Furthermore,
we integrate Large Language Models (LLMs) to generate human-friendly
explanations that highlight the most important factors impacting the match
results. By providing human-centric explanations, our approach offers a deeper
understanding of the AI predictions, making them more actionable for coaches
and analysts.

摘要：2024 年夏季，全世界將關注巴黎，為他們最喜愛的運動員加油，希望他們贏得奧運金牌。在手球比賽中，少數國家將竭盡全力爭奪這塊珍貴的獎牌，預測法國或丹麥將贏得男子組冠軍，法國或挪威將贏得女子組冠軍。然而，到目前為止，還沒有提出任何科學方法來預測比賽的最終結果。在這項工作中，我們利用深度學習模型來預測 2024 年奧運會手球比賽的結果。此模型結合可解釋 AI (xAI) 技術，讓我們能夠提取有關影響每場比賽結果的主要因素的深入資訊。值得注意的是，xAI 幫助體育專家了解比賽資訊或個別運動員表現等因素如何影響預測。此外，我們整合大型語言模型 (LLM) 來產生友善的解釋，強調影響比賽結果最重要的因素。透過提供以人為中心的解釋，我們的做法提供了對 AI 預測更深入的了解，讓教練和分析師可以採取更多行動。

##### **Multilingual Fine-Grained News Headline Hallucination Detection**
2407.15975v1 by Jiaming Shen, Tianqi Liu, Jialu Liu, Zhen Qin, Jay Pavagadhi, Simon Baumgartner, Michael Bendersky

The popularity of automated news headline generation has surged with
advancements in pre-trained language models. However, these models often suffer
from the ``hallucination'' problem, where the generated headline is not fully
supported by its source article. Efforts to address this issue have
predominantly focused on English, using over-simplistic classification schemes
that overlook nuanced hallucination types. In this study, we introduce the
first multilingual, fine-grained news headline hallucination detection dataset
that contains over 11 thousand pairs in 5 languages, each annotated with
detailed hallucination types by experts. We conduct extensive experiments on
this dataset under two settings. First, we implement several supervised
fine-tuning approaches as preparatory solutions and demonstrate this dataset's
challenges and utilities. Second, we test various large language models'
in-context learning abilities and propose two novel techniques,
language-dependent demonstration selection and coarse-to-fine prompting, to
boost the few-shot hallucination detection performance in terms of the
example-F1 metric. We release this dataset to foster further research in
multilingual, fine-grained headline hallucination detection.

摘要：隨著預訓練語言模型的進步，自動新聞標題生成的熱門程度大幅飆升。然而，這些模型常常會出現「幻覺」問題，也就是產生的標題並未獲得其原始文章的充分支持。解決此問題的努力主要集中在英語上，使用過於簡化的分類架構，忽視了細微的幻覺類型。在本研究中，我們引入了第一個多語言、細粒度的新聞標題幻覺偵測資料集，其中包含 5 種語言的 11,000 多個成對資料，每個資料都由專家加上詳細的幻覺類型註解。我們在兩種設定下對此資料集進行了廣泛的實驗。首先，我們實作了幾種監督式微調方法作為準備性解決方案，並展示了此資料集的挑戰和效用。其次，我們測試了各種大型語言模型的語境學習能力，並提出了兩種新技術，即語言依賴式示範選擇和粗到細提示，以提升少次學習幻覺偵測效能，以範例 F1 指標來衡量。我們釋出此資料集以促進多語言、細粒度標題幻覺偵測的後續研究。

##### **LLMmap: Fingerprinting For Large Language Models**
2407.15847v1 by Dario Pasquini, Evgenios M. Kornaropoulos, Giuseppe Ateniese

We introduce LLMmap, a first-generation fingerprinting attack targeted at
LLM-integrated applications. LLMmap employs an active fingerprinting approach,
sending carefully crafted queries to the application and analyzing the
responses to identify the specific LLM model in use. With as few as 8
interactions, LLMmap can accurately identify LLMs with over 95% accuracy. More
importantly, LLMmap is designed to be robust across different application
layers, allowing it to identify LLMs operating under various system prompts,
stochastic sampling hyperparameters, and even complex generation frameworks
such as RAG or Chain-of-Thought.

摘要：我們介紹 LLMmap，這是一種針對整合 LLM 的應用程式所進行的第一代指紋攻擊。LLMmap 採用主動式指紋辨識方法，將精心設計的查詢傳送至應用程式，並分析回應以識別所使用的特定 LLM 模型。透過僅 8 次互動，LLMmap 便能以超過 95% 的準確度準確識別 LLM。更重要的是，LLMmap 被設計為能夠在不同的應用程式層面中保持穩健性，這使其能夠識別在各種系統提示、隨機抽樣超參數，甚至是複雜生成架構（例如 RAG 或 Chain-of-Thought）下運作的 LLM。

##### **Reconstructing Training Data From Real World Models Trained with Transfer Learning**
2407.15845v1 by Yakir Oz, Gilad Yehudai, Gal Vardi, Itai Antebi, Michal Irani, Niv Haim

Current methods for reconstructing training data from trained classifiers are
restricted to very small models, limited training set sizes, and low-resolution
images. Such restrictions hinder their applicability to real-world scenarios.
In this paper, we present a novel approach enabling data reconstruction in
realistic settings for models trained on high-resolution images. Our method
adapts the reconstruction scheme of arXiv:2206.07758 to real-world scenarios --
specifically, targeting models trained via transfer learning over image
embeddings of large pre-trained models like DINO-ViT and CLIP. Our work employs
data reconstruction in the embedding space rather than in the image space,
showcasing its applicability beyond visual data. Moreover, we introduce a novel
clustering-based method to identify good reconstructions from thousands of
candidates. This significantly improves on previous works that relied on
knowledge of the training set to identify good reconstructed images. Our
findings shed light on a potential privacy risk for data leakage from models
trained using transfer learning.

摘要：目前的訓練資料從訓練好的分類器中重建方法僅限於非常小的模型、有限的訓練集大小和低解析度的影像。這些限制妨礙其適用於真實世界的場景。在本文中，我們提出了一種新的方法，可以在高解析度影像訓練的模型中進行資料重建，以適應真實世界的場景。我們的模型將 arXiv:2206.07758 的重建方案調整到真實世界的場景中——特別是針對透過大型預訓練模型（如 DINO-ViT 和 CLIP）的影像嵌入進行遷移學習訓練的模型。我們的模型在嵌入空間中進行資料重建，而不在影像空間中，展示了其在視覺資料之外的適用性。此外，我們引入了一種新的基於群集的方法，從數千個候選者中找出良好的重建。這顯著改善了以往依賴訓練集知識來找出良好重建影像的方法。我們的研究結果揭示了使用遷移學習訓練的模型中資料外洩的潛在隱私風險。

##### **CarFormer: Self-Driving with Learned Object-Centric Representations**
2407.15843v1 by Shadi Hamdan, Fatma Güney

The choice of representation plays a key role in self-driving. Bird's eye
view (BEV) representations have shown remarkable performance in recent years.
In this paper, we propose to learn object-centric representations in BEV to
distill a complex scene into more actionable information for self-driving. We
first learn to place objects into slots with a slot attention model on BEV
sequences. Based on these object-centric representations, we then train a
transformer to learn to drive as well as reason about the future of other
vehicles. We found that object-centric slot representations outperform both
scene-level and object-level approaches that use the exact attributes of
objects. Slot representations naturally incorporate information about objects
from their spatial and temporal context such as position, heading, and speed
without explicitly providing it. Our model with slots achieves an increased
completion rate of the provided routes and, consequently, a higher driving
score, with a lower variance across multiple runs, affirming slots as a
reliable alternative in object-centric approaches. Additionally, we validate
our model's performance as a world model through forecasting experiments,
demonstrating its capability to predict future slot representations accurately.
The code and the pre-trained models can be found at
https://kuis-ai.github.io/CarFormer/.

摘要：表示的選擇在自動駕駛中扮演著關鍵的角色。鳥瞰圖 (BEV) 表示在近年來展現了卓越的表現。在本文中，我們提出學習 BEV 中以物體為中心的表示，以將複雜的場景提煉成更具可操作性的資訊，用於自動駕駛。我們首先學習使用 BEV 序列上的插槽注意力模型將物體放入插槽中。根據這些以物體為中心的表示，我們接著訓練一個轉換器來學習駕駛，以及推論其他車輛的未來。我們發現以物體為中心的插槽表示優於使用物體確切屬性的場景級別和物體級別方法。插槽表示自然地結合了來自物體空間和時間脈絡的資訊，例如位置、航向和速度，而無需明確提供。我們帶有插槽的模型提高了所提供路線的完成率，因此提高了駕駛分數，並且在多次執行中的差異較低，證實插槽是以物體為中心的方法中可靠的替代方案。此外，我們透過預測實驗驗證了我們模型作為世界模型的效能，證明了其準確預測未來插槽表示的能力。程式碼和預訓練模型可以在 https://kuis-ai.github.io/CarFormer/ 找到。

##### **Importance Sampling-Guided Meta-Training for Intelligent Agents in Highly Interactive Environments**
2407.15839v1 by Mansur Arief, Mike Timmerman, Jiachen Li, David Isele, Mykel J Kochenderfer

Training intelligent agents to navigate highly interactive environments
presents significant challenges. While guided meta reinforcement learning (RL)
approach that first trains a guiding policy to train the ego agent has proven
effective in improving generalizability across various levels of interaction,
the state-of-the-art method tends to be overly sensitive to extreme cases,
impairing the agents' performance in the more common scenarios. This study
introduces a novel training framework that integrates guided meta RL with
importance sampling (IS) to optimize training distributions for navigating
highly interactive driving scenarios, such as T-intersections. Unlike
traditional methods that may underrepresent critical interactions or
overemphasize extreme cases during training, our approach strategically adjusts
the training distribution towards more challenging driving behaviors using IS
proposal distributions and applies the importance ratio to de-bias the result.
By estimating a naturalistic distribution from real-world datasets and
employing a mixture model for iterative training refinements, the framework
ensures a balanced focus across common and extreme driving scenarios.
Experiments conducted with both synthetic dataset and T-intersection scenarios
from the InD dataset demonstrate not only accelerated training but also
improvement in agent performance under naturalistic conditions, showcasing the
efficacy of combining IS with meta RL in training reliable autonomous agents
for highly interactive navigation tasks.

摘要：訓練智能代理程式在高度互動的環境中導航，會面臨重大挑戰。雖然引導元強化學習 (RL) 方法先訓練引導政策來訓練自我代理程式，已被證明可以有效提升在不同互動層級之間的泛化性，但最先進的方法往往對極端案例過度敏感，損害代理程式在更常見場景中的效能。本研究提出一個新的訓練架構，將引導元 RL 與重要性抽樣 (IS) 整合，以最佳化訓練分佈，用於導航高度互動的駕駛場景，例如 T 型路口。與傳統方法不同，傳統方法在訓練過程中可能低估關鍵互動或過度強調極端案例，我們的做法策略性地調整訓練分佈，使用 IS 提議分佈朝向更具挑戰性的駕駛行為，並套用重要性比率來消除結果偏差。透過從真實世界資料集估計自然分佈，並採用混合模型進行反覆訓練調整，該架構確保在常見和極端駕駛場景之間取得平衡的關注。使用合成資料集和 InD 資料集中的 T 型路口場景進行的實驗，不僅證明了訓練加速，也證明了在自然條件下代理程式效能的提升，展示了在訓練可靠的自主代理程式以執行高度互動導航任務時，結合 IS 和元 RL 的效能。

##### **Towards Latent Masked Image Modeling for Self-Supervised Visual Representation Learning**
2407.15837v1 by Yibing Wei, Abhinav Gupta, Pedro Morgado

Masked Image Modeling (MIM) has emerged as a promising method for deriving
visual representations from unlabeled image data by predicting missing pixels
from masked portions of images. It excels in region-aware learning and provides
strong initializations for various tasks, but struggles to capture high-level
semantics without further supervised fine-tuning, likely due to the low-level
nature of its pixel reconstruction objective. A promising yet unrealized
framework is learning representations through masked reconstruction in latent
space, combining the locality of MIM with the high-level targets. However, this
approach poses significant training challenges as the reconstruction targets
are learned in conjunction with the model, potentially leading to trivial or
suboptimal solutions.Our study is among the first to thoroughly analyze and
address the challenges of such framework, which we refer to as Latent MIM.
Through a series of carefully designed experiments and extensive analysis, we
identify the source of these challenges, including representation collapsing
for joint online/target optimization, learning objectives, the high region
correlation in latent space and decoding conditioning. By sequentially
addressing these issues, we demonstrate that Latent MIM can indeed learn
high-level representations while retaining the benefits of MIM models.

摘要：遮蔽影像建模 (MIM) 已成為一種有前途的方法，可用於透過預測影像遮蔽部分的遺失像素，從未標記的影像資料中衍生視覺表示。它在區域感知學習方面表現出色，並為各種任務提供強大的初始設定，但卻難以在沒有進一步監督微調的情況下捕捉到高層次語意，這可能是由於其像素重建目標的低層次本質所致。一個有前途但尚未實現的架構是透過潛在空間中的遮蔽重建來學習表示，結合 MIM 的局部性與高層次目標。然而，這種方法會帶來重大的訓練挑戰，因為重建目標是與模型結合學習的，可能會導致微不足道或次佳的解決方案。我們的研究是第一批徹底分析和解決此類架構挑戰的研究之一，我們稱之為潛在 MIM。透過一系列精心設計的實驗和廣泛的分析，我們找出這些挑戰的根源，包括聯合線上/目標最佳化、學習目標、潛在空間中的高區域相關性和解碼條件的表示崩潰。透過循序漸進地解決這些問題，我們證明潛在 MIM 確實可以在保留 MIM 模型優點的同時學習高層次表示。

##### **dMel: Speech Tokenization made Simple**
2407.15835v1 by He Bai, Tatiana Likhomanenko, Ruixiang Zhang, Zijin Gu, Zakaria Aldeneh, Navdeep Jaitly

Large language models have revolutionized natural language processing by
leveraging self-supervised pretraining on vast textual data. Inspired by this
success, researchers have investigated complicated speech tokenization methods
to discretize continuous speech signals so that language modeling techniques
can be applied to speech data. However, existing approaches either model
semantic tokens, potentially losing acoustic information, or model acoustic
tokens, risking the loss of semantic information. Having multiple token types
also complicates the architecture and requires additional pretraining. Here we
show that discretizing mel-filterbank channels into discrete intensity bins
produces a simple representation (dMel), that performs better than other
existing speech tokenization methods. Using a transformer decoder-only
architecture for speech-text modeling, we comprehensively evaluate different
speech tokenization methods on speech recognition (ASR), speech synthesis
(TTS). Our results demonstrate the effectiveness of dMel in achieving high
performance on both tasks within a unified framework, paving the way for
efficient and effective joint modeling of speech and text.

摘要：大型語言模型透過在大量的文本資料上利用自我監督預訓練，徹底改變了自然語言處理。受到這項成功的啟發，研究人員調查了複雜的語音標記化方法，以便將連續的語音訊號離散化，讓語言建模技術可以應用於語音資料。然而，現有的方法不是對語義標記建模（可能遺失音訊資訊），就是對音訊標記建模（有遺失語義資訊的風險）。擁有多種類型的標記也會使架構複雜化，並需要額外的預訓練。在此，我們展示將梅爾濾波器組通道離散化為離散強度區塊，會產生一個簡單的表示（dMel），其效能優於其他現有的語音標記化方法。我們使用僅具轉換器解碼器的架構進行語音轉文字建模，在語音辨識 (ASR)、語音合成 (TTS) 上全面評估不同的語音標記化方法。我們的結果證明了 dMel 在統一架構中達成這兩個任務的高效能，為有效率且有效的語音和文字聯合建模鋪路。

