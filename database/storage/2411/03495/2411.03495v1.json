{"2411.03495": {"publish_time": "2024-11-05", "title": "Automatic Generation of Question Hints for Mathematics Problems using Large Language Models in Educational Technology", "paper_summary": "The automatic generation of hints by Large Language Models (LLMs) within\nIntelligent Tutoring Systems (ITSs) has shown potential to enhance student\nlearning. However, generating pedagogically sound hints that address student\nmisconceptions and adhere to specific educational objectives remains\nchallenging. This work explores using LLMs (GPT-4o and Llama-3-8B-instruct) as\nteachers to generate effective hints for students simulated through LLMs\n(GPT-3.5-turbo, Llama-3-8B-Instruct, or Mistral-7B-instruct-v0.3) tackling math\nexercises designed for human high-school students, and designed using cognitive\nscience principles. We present here the study of several dimensions: 1)\nidentifying error patterns made by simulated students on secondary-level math\nexercises; 2) developing various prompts for GPT-4o as a teacher and evaluating\ntheir effectiveness in generating hints that enable simulated students to\nself-correct; and 3) testing the best-performing prompts, based on their\nability to produce relevant hints and facilitate error correction, with\nLlama-3-8B-Instruct as the teacher, allowing for a performance comparison with\nGPT-4o. The results show that model errors increase with higher temperature\nsettings. Notably, when hints are generated by GPT-4o, the most effective\nprompts include prompts tailored to specific errors as well as prompts\nproviding general hints based on common mathematical errors. Interestingly,\nLlama-3-8B-Instruct as a teacher showed better overall performance than GPT-4o.\nAlso the problem-solving and response revision capabilities of the LLMs as\nstudents, particularly GPT-3.5-turbo, improved significantly after receiving\nhints, especially at lower temperature settings. However, models like\nMistral-7B-Instruct demonstrated a decline in performance as the temperature\nincreased.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u667a\u6167\u578b\u6559\u5b78\u7cfb\u7d71 (ITS) \u4e2d\u81ea\u52d5\u7522\u751f\u63d0\u793a\uff0c\u5df2\u986f\u793a\u51fa\u589e\u9032\u5b78\u751f\u5b78\u7fd2\u7684\u6f5b\u529b\u3002\u7136\u800c\uff0c\u7522\u751f\u7b26\u5408\u6559\u5b78\u6cd5\u7684\u63d0\u793a\uff0c\u4ee5\u89e3\u6c7a\u5b78\u751f\u7684\u8aa4\u89e3\u4e26\u9075\u5faa\u7279\u5b9a\u7684\u6559\u80b2\u76ee\u6a19\uff0c\u4ecd\u7136\u5177\u6709\u6311\u6230\u6027\u3002\u9019\u9805\u5de5\u4f5c\u63a2\u8a0e\u4f7f\u7528 LLM\uff08GPT-4o \u548c Llama-3-8B-instruct\uff09\u4f5c\u70ba\u8001\u5e2b\uff0c\u70ba\u6a21\u64ec\u900f\u904e LLM\uff08GPT-3.5-turbo\u3001Llama-3-8B-Instruct \u6216 Mistral-7B-instruct-v0.3\uff09\u89e3\u6c7a\u5c08\u70ba\u4eba\u985e\u9ad8\u4e2d\u751f\u8a2d\u8a08\u7684\u6578\u5b78\u7df4\u7fd2\uff0c\u4e26\u4f7f\u7528\u8a8d\u77e5\u79d1\u5b78\u539f\u7406\u9032\u884c\u8a2d\u8a08\u7684\u5b78\u751f\u7684\u7522\u751f\u6709\u6548\u63d0\u793a\u3002\u6211\u5011\u5728\u6b64\u63d0\u51fa\u5c0d\u5e7e\u500b\u9762\u5411\u7684\u7814\u7a76\uff1a1\uff09\u627e\u51fa\u6a21\u64ec\u5b78\u751f\u5728\u4e2d\u5b78\u6578\u5b78\u7df4\u7fd2\u4e2d\u7522\u751f\u7684\u932f\u8aa4\u6a21\u5f0f\uff1b2\uff09\u70ba GPT-4o \u4f5c\u70ba\u8001\u5e2b\u958b\u767c\u5404\u7a2e\u63d0\u793a\uff0c\u4e26\u8a55\u4f30\u5b83\u5011\u5728\u7522\u751f\u63d0\u793a\u4ee5\u4f7f\u6a21\u64ec\u5b78\u751f\u80fd\u5920\u81ea\u6211\u4fee\u6b63\u65b9\u9762\u7684\u6709\u6548\u6027\uff1b3\uff09\u6e2c\u8a66\u57fa\u65bc\u7522\u751f\u76f8\u95dc\u63d0\u793a\u548c\u4fc3\u9032\u932f\u8aa4\u4fee\u6b63\u7684\u80fd\u529b\uff0c\u8868\u73fe\u6700\u4f73\u7684\u63d0\u793a\uff0c\u7531 Llama-3-8B-Instruct \u4f5c\u70ba\u8001\u5e2b\uff0c\u5141\u8a31\u8207 GPT-4o \u9032\u884c\u6548\u80fd\u6bd4\u8f03\u3002\u7d50\u679c\u986f\u793a\uff0c\u6a21\u578b\u932f\u8aa4\u6703\u96a8\u8457\u8f03\u9ad8\u7684\u6eab\u5ea6\u8a2d\u5b9a\u800c\u589e\u52a0\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u7576\u63d0\u793a\u662f\u7531 GPT-4o \u7522\u751f\u6642\uff0c\u6700\u6709\u6548\u7684\u63d0\u793a\u5305\u62ec\u91dd\u5c0d\u7279\u5b9a\u932f\u8aa4\u91cf\u8eab\u6253\u9020\u7684\u63d0\u793a\uff0c\u4ee5\u53ca\u6839\u64da\u5e38\u898b\u6578\u5b78\u932f\u8aa4\u63d0\u4f9b\u4e00\u822c\u63d0\u793a\u7684\u63d0\u793a\u3002\u6709\u8da3\u7684\u662f\uff0c\u4f5c\u70ba\u8001\u5e2b\u7684 Llama-3-8B-Instruct \u986f\u793a\u51fa\u6bd4 GPT-4o \u66f4\u597d\u7684\u6574\u9ad4\u8868\u73fe\u3002\u6b64\u5916\uff0c\u7279\u5225\u662f GPT-3.5-turbo\uff0cLLM \u4f5c\u70ba\u5b78\u751f\u7684\u554f\u984c\u89e3\u6c7a\u548c\u56de\u61c9\u4fee\u6b63\u80fd\u529b\u5728\u6536\u5230\u63d0\u793a\u5f8c\u986f\u8457\u63d0\u5347\uff0c\u5c24\u5176\u662f\u5728\u8f03\u4f4e\u7684\u6eab\u5ea6\u8a2d\u5b9a\u4e0b\u3002\u7136\u800c\uff0c\u96a8\u8457\u6eab\u5ea6\u5347\u9ad8\uff0cMistral-7B-Instruct \u7b49\u6a21\u578b\u7684\u6548\u80fd\u8868\u73fe\u51fa\u4e0b\u964d\u3002", "author": "Junior Cedric Tonga et.al.", "authors": "Junior Cedric Tonga, Benjamin Clement, Pierre-Yves Oudeyer", "id": "2411.03495v1", "paper_url": "http://arxiv.org/abs/2411.03495v1", "repo": "null"}}