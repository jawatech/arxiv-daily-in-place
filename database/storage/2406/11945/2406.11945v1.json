{"2406.11945": {"publish_time": "2024-06-17", "title": "GAugLLM: Improving Graph Contrastive Learning for Text-Attributed Graphs with Large Language Models", "paper_summary": "This work studies self-supervised graph learning for text-attributed graphs\n(TAGs) where nodes are represented by textual attributes. Unlike traditional\ngraph contrastive methods that perturb the numerical feature space and alter\nthe graph's topological structure, we aim to improve view generation through\nlanguage supervision. This is driven by the prevalence of textual attributes in\nreal applications, which complement graph structures with rich semantic\ninformation. However, this presents challenges because of two major reasons.\nFirst, text attributes often vary in length and quality, making it difficulty\nto perturb raw text descriptions without altering their original semantic\nmeanings. Second, although text attributes complement graph structures, they\nare not inherently well-aligned. To bridge the gap, we introduce GAugLLM, a\nnovel framework for augmenting TAGs. It leverages advanced large language\nmodels like Mistral to enhance self-supervised graph learning. Specifically, we\nintroduce a mixture-of-prompt-expert technique to generate augmented node\nfeatures. This approach adaptively maps multiple prompt experts, each of which\nmodifies raw text attributes using prompt engineering, into numerical feature\nspace. Additionally, we devise a collaborative edge modifier to leverage\nstructural and textual commonalities, enhancing edge augmentation by examining\nor building connections between nodes. Empirical results across five benchmark\ndatasets spanning various domains underscore our framework's ability to enhance\nthe performance of leading contrastive methods as a plug-in tool. Notably, we\nobserve that the augmented features and graph structure can also enhance the\nperformance of standard generative methods, as well as popular graph neural\nnetworks. The open-sourced implementation of our GAugLLM is available at\nGithub.", "paper_summary_zh": "<paragraph>\u672c\u7814\u7a76\u63a2\u8a0e\u4e86\u6587\u5b57\u5c6c\u6027\u5716 (TAG) \u7684\u81ea\u6211\u76e3\u7763\u5716\u5b78\u7fd2\uff0c\u5176\u4e2d\u7bc0\u9ede\u7531\u6587\u5b57\u5c6c\u6027\u8868\u793a\u3002\u8207\u64fe\u52d5\u6578\u503c\u7279\u5fb5\u7a7a\u9593\u548c\u6539\u8b8a\u5716\u5f62\u62d3\u64b2\u7d50\u69cb\u7684\u50b3\u7d71\u5716\u5f62\u5c0d\u6bd4\u65b9\u6cd5\u4e0d\u540c\uff0c\u6211\u5011\u65e8\u5728\u900f\u904e\u8a9e\u8a00\u76e3\u7763\u4f86\u6539\u5584\u8996\u5716\u751f\u6210\u3002\u9019\u662f\u56e0\u70ba\u6587\u5b57\u5c6c\u6027\u5728\u5be6\u969b\u61c9\u7528\u4e2d\u5f88\u666e\u904d\uff0c\u5b83\u4ee5\u8c50\u5bcc\u7684\u8a9e\u7fa9\u8cc7\u8a0a\u88dc\u5145\u5716\u5f62\u7d50\u69cb\u3002\u7136\u800c\uff0c\u9019\u6703\u5e36\u4f86\u6311\u6230\uff0c\u539f\u56e0\u6709\u5169\u500b\u3002\u9996\u5148\uff0c\u6587\u5b57\u5c6c\u6027\u901a\u5e38\u9577\u5ea6\u548c\u54c1\u8cea\u4e0d\u540c\uff0c\u9019\u4f7f\u5f97\u5728\u4e0d\u6539\u8b8a\u539f\u59cb\u8a9e\u7fa9\u610f\u7fa9\u7684\u60c5\u6cc1\u4e0b\u64fe\u52d5\u539f\u59cb\u6587\u5b57\u63cf\u8ff0\u8b8a\u5f97\u56f0\u96e3\u3002\u5176\u6b21\uff0c\u5118\u7ba1\u6587\u5b57\u5c6c\u6027\u88dc\u5145\u4e86\u5716\u5f62\u7d50\u69cb\uff0c\u4f46\u5b83\u5011\u4e26\u975e\u5929\u751f\u5c31\u5f88\u597d\u5730\u5c0d\u9f4a\u3002\u70ba\u4e86\u5f4c\u5408\u5dee\u8ddd\uff0c\u6211\u5011\u5f15\u5165\u4e86 GAugLLM\uff0c\u9019\u662f\u4e00\u500b\u7528\u65bc\u64f4\u5145 TAG \u7684\u65b0\u6846\u67b6\u3002\u5b83\u5229\u7528\u4e86 Mistral \u7b49\u5148\u9032\u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u4f86\u589e\u5f37\u81ea\u6211\u76e3\u7763\u5716\u5f62\u5b78\u7fd2\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u7a2e\u6df7\u5408\u63d0\u793a\u5c08\u5bb6\u7684\u6280\u8853\u4f86\u751f\u6210\u64f4\u5145\u7684\u7bc0\u9ede\u7279\u5fb5\u3002\u9019\u7a2e\u65b9\u6cd5\u81ea\u9069\u61c9\u5730\u5c07\u591a\u500b\u63d0\u793a\u5c08\u5bb6\u6620\u5c04\u5230\u6578\u503c\u7279\u5fb5\u7a7a\u9593\uff0c\u6bcf\u500b\u63d0\u793a\u5c08\u5bb6\u90fd\u4f7f\u7528\u63d0\u793a\u5de5\u7a0b\u4fee\u6539\u539f\u59cb\u6587\u5b57\u5c6c\u6027\u3002\u6b64\u5916\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u5354\u4f5c\u908a\u7de3\u4fee\u6539\u5668\u4f86\u5229\u7528\u7d50\u69cb\u548c\u6587\u5b57\u7684\u5171\u6027\uff0c\u901a\u904e\u6aa2\u67e5\u6216\u5efa\u7acb\u7bc0\u9ede\u4e4b\u9593\u7684\u9023\u63a5\u4f86\u589e\u5f37\u908a\u7de3\u64f4\u5145\u3002\u8de8\u8d8a\u5404\u7a2e\u9818\u57df\u7684\u4e94\u500b\u57fa\u6e96\u8cc7\u6599\u96c6\u7684\u7d93\u9a57\u7d50\u679c\u5f37\u8abf\u4e86\u6211\u5011\u7684\u6846\u67b6\u4f5c\u70ba\u5916\u639b\u5de5\u5177\u589e\u5f37\u9818\u5148\u5c0d\u6bd4\u65b9\u6cd5\u6548\u80fd\u7684\u80fd\u529b\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u6211\u5011\u89c0\u5bdf\u5230\u64f4\u5145\u7684\u7279\u5fb5\u548c\u5716\u5f62\u7d50\u69cb\u4e5f\u53ef\u4ee5\u589e\u5f37\u6a19\u6e96\u751f\u6210\u65b9\u6cd5\u4ee5\u53ca\u6d41\u884c\u7684\u5716\u5f62\u795e\u7d93\u7db2\u8def\u7684\u6548\u80fd\u3002\u6211\u5011\u7684 GAugLLM \u7684\u958b\u6e90\u5be6\u73fe\u53ef\u4ee5\u5728 Github \u4e0a\u627e\u5230\u3002</paragraph>", "author": "Yi Fang et.al.", "authors": "Yi Fang, Dongzhe Fan, Daochen Zha, Qiaoyu Tan", "id": "2406.11945v1", "paper_url": "http://arxiv.org/abs/2406.11945v1", "repo": "null"}}