{"2410.15642": {"publish_time": "2024-10-21", "title": "Resource-Efficient Medical Report Generation using Large Language Models", "paper_summary": "Medical report generation is the task of automatically writing radiology\nreports for chest X-ray images. Manually composing these reports is a\ntime-consuming process that is also prone to human errors. Generating medical\nreports can therefore help reduce the burden on radiologists. In other words,\nwe can promote greater clinical automation in the medical domain. In this work,\nwe propose a new framework leveraging vision-enabled Large Language Models\n(LLM) for the task of medical report generation. We introduce a lightweight\nsolution that achieves better or comparative performance as compared to\nprevious solutions on the task of medical report generation. We conduct\nextensive experiments exploring different model sizes and enhancement\napproaches, such as prefix tuning to improve the text generation abilities of\nthe LLMs. We evaluate our approach on a prominent large-scale radiology report\ndataset - MIMIC-CXR. Our results demonstrate the capability of our\nresource-efficient framework to generate patient-specific reports with strong\nmedical contextual understanding and high precision.", "paper_summary_zh": "\u91ab\u7642\u5831\u544a\u751f\u6210\u662f\u81ea\u52d5\u64b0\u5beb\u80f8\u90e8 X \u5149\u5f71\u50cf\u7684\u653e\u5c04\u79d1\u5831\u544a\u7684\u4efb\u52d9\u3002\u624b\u52d5\u64b0\u5beb\u9019\u4e9b\u5831\u544a\u662f\u4e00\u500b\u8017\u6642\u7684\u904e\u7a0b\uff0c\u800c\u4e14\u5bb9\u6613\u767c\u751f\u4eba\u70ba\u932f\u8aa4\u3002\u56e0\u6b64\uff0c\u751f\u6210\u91ab\u7642\u5831\u544a\u53ef\u4ee5\u5e6b\u52a9\u6e1b\u8f15\u653e\u5c04\u79d1\u91ab\u5e2b\u7684\u8ca0\u64d4\u3002\u63db\u53e5\u8a71\u8aaa\uff0c\u6211\u5011\u53ef\u4ee5\u5728\u91ab\u7642\u9818\u57df\u63a8\u5ee3\u66f4\u5ee3\u6cdb\u7684\u81e8\u5e8a\u81ea\u52d5\u5316\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u65b0\u7684\u6846\u67b6\uff0c\u5229\u7528\u652f\u63f4\u5f71\u50cf\u7684\u5927\u8a9e\u8a00\u6a21\u578b (LLM) \u4f86\u57f7\u884c\u91ab\u7642\u5831\u544a\u751f\u6210\u7684\u4efb\u52d9\u3002\u6211\u5011\u5f15\u5165\u4e00\u500b\u8f15\u91cf\u7d1a\u7684\u89e3\u6c7a\u65b9\u6848\uff0c\u8207\u5148\u524d\u5728\u91ab\u7642\u5831\u544a\u751f\u6210\u4efb\u52d9\u4e0a\u7684\u89e3\u6c7a\u65b9\u6848\u76f8\u6bd4\uff0c\u53ef\u4ee5\u9054\u5230\u66f4\u597d\u6216\u76f8\u7576\u7684\u6548\u80fd\u3002\u6211\u5011\u9032\u884c\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u63a2\u8a0e\u4e0d\u540c\u7684\u6a21\u578b\u5927\u5c0f\u548c\u5f37\u5316\u65b9\u6cd5\uff0c\u4f8b\u5982\u524d\u7db4\u8abf\u6574\uff0c\u4ee5\u63d0\u5347 LLM \u7684\u6587\u5b57\u751f\u6210\u80fd\u529b\u3002\u6211\u5011\u5728\u4e00\u500b\u8457\u540d\u7684\u3001\u5927\u898f\u6a21\u7684\u653e\u5c04\u79d1\u5831\u544a\u8cc7\u6599\u96c6 - MIMIC-CXR \u4e0a\u8a55\u4f30\u6211\u5011\u7684\u505a\u6cd5\u3002\u6211\u5011\u7684\u7d50\u679c\u8b49\u660e\u4e86\u6211\u5011\u8cc7\u6e90\u7bc0\u7701\u578b\u6846\u67b6\u751f\u6210\u5177\u6709\u5f37\u5927\u91ab\u7642\u80cc\u666f\u7406\u89e3\u548c\u9ad8\u7cbe\u78ba\u5ea6\u7684\u60a3\u8005\u7279\u5b9a\u5831\u544a\u7684\u80fd\u529b\u3002", "author": "Abdullah et.al.", "authors": "Abdullah, Ameer Hamza, Seong Tae Kim", "id": "2410.15642v1", "paper_url": "http://arxiv.org/abs/2410.15642v1", "repo": "null"}}