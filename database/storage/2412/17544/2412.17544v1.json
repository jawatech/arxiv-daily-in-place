{"2412.17544": {"publish_time": "2024-12-23", "title": "Retention Score: Quantifying Jailbreak Risks for Vision Language Models", "paper_summary": "The emergence of Vision-Language Models (VLMs) is a significant advancement\nin integrating computer vision with Large Language Models (LLMs) to enhance\nmulti-modal machine learning capabilities. However, this progress has also made\nVLMs vulnerable to sophisticated adversarial attacks, raising concerns about\ntheir reliability. The objective of this paper is to assess the resilience of\nVLMs against jailbreak attacks that can compromise model safety compliance and\nresult in harmful outputs. To evaluate a VLM's ability to maintain its\nrobustness against adversarial input perturbations, we propose a novel metric\ncalled the \\textbf{Retention Score}. Retention Score is a multi-modal\nevaluation metric that includes Retention-I and Retention-T scores for\nquantifying jailbreak risks in visual and textual components of VLMs. Our\nprocess involves generating synthetic image-text pairs using a conditional\ndiffusion model. These pairs are then predicted for toxicity score by a VLM\nalongside a toxicity judgment classifier. By calculating the margin in toxicity\nscores, we can quantify the robustness of the VLM in an attack-agnostic manner.\nOur work has four main contributions. First, we prove that Retention Score can\nserve as a certified robustness metric. Second, we demonstrate that most VLMs\nwith visual components are less robust against jailbreak attacks than the\ncorresponding plain VLMs. Additionally, we evaluate black-box VLM APIs and find\nthat the security settings in Google Gemini significantly affect the score and\nrobustness. Moreover, the robustness of GPT4V is similar to the medium settings\nof Gemini. Finally, our approach offers a time-efficient alternative to\nexisting adversarial attack methods and provides consistent model robustness\nrankings when evaluated on VLMs including MiniGPT-4, InstructBLIP, and LLaVA.", "paper_summary_zh": "\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM) \u7684\u51fa\u73fe\u662f\u5c07\u96fb\u8166\u8996\u89ba\u8207\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6574\u5408\u7684\u91cd\u5927\u9032\u5c55\uff0c\u4ee5\u589e\u5f37\u591a\u6a21\u614b\u6a5f\u5668\u5b78\u7fd2\u529f\u80fd\u3002\u7136\u800c\uff0c\u6b64\u9032\u5c55\u4e5f\u8b93 VLM \u5bb9\u6613\u53d7\u5230\u7cbe\u5bc6\u5c0d\u6297\u653b\u64ca\uff0c\u5f15\u8d77\u4eba\u5011\u5c0d\u5176\u53ef\u9760\u6027\u7684\u64d4\u6182\u3002\u672c\u6587\u7684\u76ee\u6a19\u662f\u8a55\u4f30 VLM \u5c0d\u8d8a\u7344\u653b\u64ca\u7684\u97cc\u6027\uff0c\u8d8a\u7344\u653b\u64ca\u53ef\u80fd\u6703\u640d\u5bb3\u6a21\u578b\u5b89\u5168\u5408\u898f\u6027\uff0c\u4e26\u5c0e\u81f4\u6709\u5bb3\u7684\u8f38\u51fa\u3002\u70ba\u4e86\u8a55\u4f30 VLM \u5728\u5c0d\u6297\u8f38\u5165\u64fe\u52d5\u4e0b\u7dad\u6301\u5176\u7a69\u5065\u6027\u7684\u80fd\u529b\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u540d\u70ba\u300c\u4fdd\u7559\u5206\u6578\u300d\u7684\u65b0\u6307\u6a19\u3002\u4fdd\u7559\u5206\u6578\u662f\u4e00\u7a2e\u591a\u6a21\u614b\u8a55\u4f30\u6307\u6a19\uff0c\u5305\u542b\u4fdd\u7559\u5206\u6578 I \u548c\u4fdd\u7559\u5206\u6578 T\uff0c\u7528\u65bc\u91cf\u5316 VLM \u8996\u89ba\u548c\u6587\u672c\u7d44\u4ef6\u4e2d\u7684\u8d8a\u7344\u98a8\u96aa\u3002\u6211\u5011\u7684\u6d41\u7a0b\u6d89\u53ca\u4f7f\u7528\u689d\u4ef6\u64f4\u6563\u6a21\u578b\u751f\u6210\u5408\u6210\u5716\u50cf\u6587\u5b57\u5c0d\u3002\u63a5\u8457\uff0cVLM \u6703\u9810\u6e2c\u9019\u4e9b\u5c0d\u7684\u6bd2\u6027\u5206\u6578\uff0c\u540c\u6642\u4f7f\u7528\u6bd2\u6027\u5224\u65b7\u5206\u985e\u5668\u3002\u900f\u904e\u8a08\u7b97\u6bd2\u6027\u5206\u6578\u4e2d\u7684\u908a\u969b\u503c\uff0c\u6211\u5011\u53ef\u4ee5\u91cf\u5316 VLM \u5728\u4e0d\u53ef\u77e5\u653b\u64ca\u7684\u65b9\u5f0f\u4e2d\u7684\u7a69\u5065\u6027\u3002\u6211\u5011\u7684\u7814\u7a76\u6709\u56db\u9805\u4e3b\u8981\u8ca2\u737b\u3002\u9996\u5148\uff0c\u6211\u5011\u8b49\u660e\u4fdd\u7559\u5206\u6578\u53ef\u7528\u4f5c\u8a8d\u8b49\u7a69\u5065\u6027\u6307\u6a19\u3002\u5176\u6b21\uff0c\u6211\u5011\u8b49\u660e\u5927\u591a\u6578\u5177\u6709\u8996\u89ba\u7d44\u4ef6\u7684 VLM \u6bd4\u5c0d\u61c9\u7684\u7d14\u7cb9 VLM \u5c0d\u8d8a\u7344\u653b\u64ca\u7684\u7a69\u5065\u6027\u8f03\u4f4e\u3002\u6b64\u5916\uff0c\u6211\u5011\u8a55\u4f30\u9ed1\u76d2 VLM API\uff0c\u767c\u73fe Google Gemini \u4e2d\u7684\u5b89\u5168\u8a2d\u5b9a\u6703\u986f\u8457\u5f71\u97ff\u5206\u6578\u548c\u7a69\u5065\u6027\u3002\u6b64\u5916\uff0cGPT4V \u7684\u7a69\u5065\u6027\u985e\u4f3c\u65bc Gemini \u7684\u4e2d\u968e\u8a2d\u5b9a\u3002\u6700\u5f8c\uff0c\u6211\u5011\u7684\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u500b\u6bd4\u73fe\u6709\u5c0d\u6297\u653b\u64ca\u65b9\u6cd5\u66f4\u7701\u6642\u7684\u65b9\u6cd5\uff0c\u4e26\u5728\u8a55\u4f30\u5305\u62ec MiniGPT-4\u3001InstructBLIP \u548c LLaVA \u5728\u5167\u7684 VLM \u6642\u63d0\u4f9b\u4e00\u81f4\u7684\u6a21\u578b\u7a69\u5065\u6027\u6392\u540d\u3002", "author": "Zaitang Li et.al.", "authors": "Zaitang Li, Pin-Yu Chen, Tsung-Yi Ho", "id": "2412.17544v1", "paper_url": "http://arxiv.org/abs/2412.17544v1", "repo": "null"}}