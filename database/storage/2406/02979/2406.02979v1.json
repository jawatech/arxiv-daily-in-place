{"2406.02979": {"publish_time": "2024-06-05", "title": "Efficient User Sequence Learning for Online Services via Compressed Graph Neural Networks", "paper_summary": "Learning representations of user behavior sequences is crucial for various\nonline services, such as online fraudulent transaction detection mechanisms.\nGraph Neural Networks (GNNs) have been extensively applied to model sequence\nrelationships, and extract information from similar sequences. While user\nbehavior sequence data volume is usually huge for online applications, directly\napplying GNN models may lead to substantial computational overhead during both\nthe training and inference stages and make it challenging to meet real-time\nrequirements for online services. In this paper, we leverage graph compression\ntechniques to alleviate the efficiency issue. Specifically, we propose a novel\nunified framework called ECSeq, to introduce graph compression techniques into\nrelation modeling for user sequence representation learning. The key module of\nECSeq is sequence relation modeling, which explores relationships among\nsequences to enhance sequence representation learning, and employs graph\ncompression algorithms to achieve high efficiency and scalability. ECSeq also\nexhibits plug-and-play characteristics, seamlessly augmenting pre-trained\nsequence representation models without modifications. Empirical experiments on\nboth sequence classification and regression tasks demonstrate the effectiveness\nof ECSeq. Specifically, with an additional training time of tens of seconds in\ntotal on 100,000+ sequences and inference time preserved within $10^{-4}$\nseconds/sample, ECSeq improves the prediction R@P$_{0.9}$ of the widely used\nLSTM by $\\sim 5\\%$.", "paper_summary_zh": "\u5b78\u7fd2\u4f7f\u7528\u8005\u884c\u70ba\u5e8f\u5217\u7684\u8868\u793a\u5c0d\u65bc\u5404\u7a2e\u7dda\u4e0a\u670d\u52d9\u81f3\u95dc\u91cd\u8981\uff0c\u4f8b\u5982\u7dda\u4e0a\u8a50\u9a19\u4ea4\u6613\u5075\u6e2c\u6a5f\u5236\u3002\u5716\u795e\u7d93\u7db2\u8def (GNN) \u5df2\u5ee3\u6cdb\u61c9\u7528\u65bc\u6a21\u578b\u5e8f\u5217\u95dc\u4fc2\uff0c\u4e26\u5f9e\u985e\u4f3c\u5e8f\u5217\u4e2d\u63d0\u53d6\u8cc7\u8a0a\u3002\u96d6\u7136\u4f7f\u7528\u8005\u884c\u70ba\u5e8f\u5217\u8cc7\u6599\u91cf\u5c0d\u65bc\u7dda\u4e0a\u61c9\u7528\u4f86\u8aaa\u901a\u5e38\u5f88\u5927\uff0c\u4f46\u76f4\u63a5\u61c9\u7528 GNN \u6a21\u578b\u53ef\u80fd\u6703\u5728\u8a13\u7df4\u548c\u63a8\u8ad6\u968e\u6bb5\u5c0e\u81f4\u5927\u91cf\u7684\u8a08\u7b97\u8ca0\u64d4\uff0c\u4e26\u4f7f\u5f97\u6eff\u8db3\u7dda\u4e0a\u670d\u52d9\u7684\u5373\u6642\u9700\u6c42\u8b8a\u5f97\u5177\u6709\u6311\u6230\u6027\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5229\u7528\u5716\u58d3\u7e2e\u6280\u8853\u4f86\u6e1b\u8f15\u6548\u7387\u554f\u984c\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u540d\u70ba ECSeq \u7684\u65b0\u7d71\u4e00\u67b6\u69cb\uff0c\u5c07\u5716\u58d3\u7e2e\u6280\u8853\u5f15\u5165\u95dc\u4fc2\u5efa\u6a21\u4e2d\uff0c\u4ee5\u9032\u884c\u4f7f\u7528\u8005\u5e8f\u5217\u8868\u793a\u5b78\u7fd2\u3002ECSeq \u7684\u95dc\u9375\u6a21\u7d44\u662f\u5e8f\u5217\u95dc\u4fc2\u5efa\u6a21\uff0c\u5b83\u63a2\u7d22\u5e8f\u5217\u4e4b\u9593\u7684\u95dc\u4fc2\u4ee5\u589e\u5f37\u5e8f\u5217\u8868\u793a\u5b78\u7fd2\uff0c\u4e26\u63a1\u7528\u5716\u58d3\u7e2e\u6f14\u7b97\u6cd5\u4f86\u5be6\u73fe\u9ad8\u6548\u7387\u548c\u53ef\u64f4\u5145\u6027\u3002ECSeq \u9084\u5c55\u73fe\u4e86\u5373\u63d2\u5373\u7528\u7684\u7279\u6027\uff0c\u7121\u9700\u4fee\u6539\u5373\u53ef\u7121\u7e2b\u5730\u64f4\u5145\u9810\u5148\u8a13\u7df4\u7684\u5e8f\u5217\u8868\u793a\u6a21\u578b\u3002\u5728\u5e8f\u5217\u5206\u985e\u548c\u56de\u6b78\u4efb\u52d9\u4e0a\u7684\u5be6\u8b49\u5be6\u9a57\u8b49\u660e\u4e86 ECSeq \u7684\u6709\u6548\u6027\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u5728 100,000 \u591a\u500b\u5e8f\u5217\u4e0a\u7e3d\u5171\u984d\u5916\u8a13\u7df4\u6578\u5341\u79d2\uff0c\u4e26\u4e14\u63a8\u8ad6\u6642\u9593\u4fdd\u6301\u5728 $10^{-4}$ \u79d2/\u6a23\u672c\u5167\uff0cECSeq \u5c07\u5ee3\u6cdb\u4f7f\u7528\u7684 LSTM \u7684\u9810\u6e2c R@P$_{0.9}$ \u63d0\u5347\u4e86\u7d04 5%\u3002", "author": "Yucheng Wu et.al.", "authors": "Yucheng Wu, Liyue Chen, Yu Cheng, Shuai Chen, Jinyu Xu, Leye Wang", "id": "2406.02979v1", "paper_url": "http://arxiv.org/abs/2406.02979v1", "repo": "https://github.com/wuyucheng2002/ecseq"}}