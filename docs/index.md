# arxiv-daily
 Automated deployment @ 2024-10-18 09:05:59 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-16**|**FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression**|Zhenheng Tang et.al.|[2410.12707v1](http://arxiv.org/abs/2410.12707v1)|null|
|**2024-10-16**|**The Best of Both Worlds: Bridging Quality and Diversity in Data Selection with Bipartite Graph**|Minghao Wu et.al.|[2410.12458v1](http://arxiv.org/abs/2410.12458v1)|null|
|**2024-10-16**|**PRefLexOR: Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking**|Markus J. Buehler et.al.|[2410.12375v1](http://arxiv.org/abs/2410.12375v1)|[link](https://github.com/lamm-mit/PRefLexOR)|
|**2024-10-16**|**Pyramid-Driven Alignment: Pyramid Principle Guided Integration of Large Language Models and Knowledge Graphs**|Lei Sun et.al.|[2410.12298v2](http://arxiv.org/abs/2410.12298v2)|null|
|**2024-10-16**|**Towards LLM-based Cognitive Models of Students with Misconceptions**|Shashank Sonkar et.al.|[2410.12294v1](http://arxiv.org/abs/2410.12294v1)|null|
|**2024-10-16**|**Comprehending Knowledge Graphs with Large Language Models for Recommender Systems**|Ziqiang Cui et.al.|[2410.12229v1](http://arxiv.org/abs/2410.12229v1)|null|
|**2024-10-16**|**Triple Modality Fusion: Aligning Visual, Textual, and Graph Data with Large Language Models for Multi-Behavior Recommendations**|Luyi Ma et.al.|[2410.12228v1](http://arxiv.org/abs/2410.12228v1)|null|
|**2024-10-16**|**Iter-AHMCL: Alleviate Hallucination for Large Language Model via Iterative Model-level Contrastive Learning**|Huiwen Wu et.al.|[2410.12130v1](http://arxiv.org/abs/2410.12130v1)|null|
|**2024-10-15**|**Bridging Large Language Models and Graph Structure Learning Models for Robust Representation Learning**|Guangxin Su et.al.|[2410.12096v1](http://arxiv.org/abs/2410.12096v1)|null|
|**2024-10-15**|**A Survey on Deep Tabular Learning**|Shriyank Somvanshi et.al.|[2410.12034v1](http://arxiv.org/abs/2410.12034v1)|null|
|**2024-10-15**|**Causal Reasoning in Large Language Models: A Knowledge Graph Approach**|Yejin Kim et.al.|[2410.11588v1](http://arxiv.org/abs/2410.11588v1)|null|
|**2024-10-15**|**Y-Mol: A Multiscale Biomedical Knowledge-Guided Large Language Model for Drug Development**|Tengfei Ma et.al.|[2410.11550v1](http://arxiv.org/abs/2410.11550v1)|null|
|**2024-10-15**|**AGENTiGraph: An Interactive Knowledge Graph Platform for LLM-based Chatbots Utilizing Private Data**|Xinjie Zhao et.al.|[2410.11531v1](http://arxiv.org/abs/2410.11531v1)|null|
|**2024-10-15**|**Do LLMs Have the Generalization Ability in Conducting Causal Inference?**|Chen Wang et.al.|[2410.11385v1](http://arxiv.org/abs/2410.11385v1)|[link](https://github.com/prayingsociety/ci_bench)|
|**2024-10-15**|**Enhance Graph Alignment for Large Language Models**|Haitong Luo et.al.|[2410.11370v1](http://arxiv.org/abs/2410.11370v1)|null|
|**2024-10-15**|**Unleashing the Power of LLMs as Multi-Modal Encoders for Text and Graph-Structured Data**|Jiacheng Lin et.al.|[2410.11235v1](http://arxiv.org/abs/2410.11235v1)|null|
|**2024-10-15**|**Tree of Attributes Prompt Learning for Vision-Language Models**|Tong Ding et.al.|[2410.11201v1](http://arxiv.org/abs/2410.11201v1)|null|
|**2024-10-14**|**Graph of Records: Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs**|Haozhen Zhang et.al.|[2410.11001v1](http://arxiv.org/abs/2410.11001v1)|[link](https://github.com/ulab-uiuc/gor)|
|**2024-10-14**|**NT-LLM: A Novel Node Tokenizer for Integrating Graph Structure into Large Language Models**|Yanbiao Ji et.al.|[2410.10743v1](http://arxiv.org/abs/2410.10743v1)|null|
|**2024-10-14**|**GraphCLIP: Enhancing Transferability in Graph Foundation Models for Text-Attributed Graphs**|Yun Zhu et.al.|[2410.10329v2](http://arxiv.org/abs/2410.10329v2)|[link](https://github.com/zhuyun97/graphclip)|
|**2024-10-14**|**Unified Representation of Genomic and Biomedical Concepts through Multi-Task, Multi-Source Contrastive Learning**|Hongyi Yuan et.al.|[2410.10144v1](http://arxiv.org/abs/2410.10144v1)|null|
|**2024-10-14**|**Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?**|Yifan Feng et.al.|[2410.10083v2](http://arxiv.org/abs/2410.10083v2)|[link](https://github.com/imoonlab/llm4hypergraph)|
|**2024-10-13**|**Dynamic and Textual Graph Generation Via Large-Scale LLM-based Agent Simulation**|Jiarui Ji et.al.|[2410.09824v1](http://arxiv.org/abs/2410.09824v1)|null|
|**2024-10-13**|**A Mixed-Language Multi-Document News Summarization Dataset and a Graphs-Based Extract-Generate Model**|Shengxiang Gao et.al.|[2410.09773v1](http://arxiv.org/abs/2410.09773v1)|null|
|**2024-10-13**|**Honest AI: Fine-Tuning "Small" Language Models to Say "I Don't Know", and Reducing Hallucination in RAG**|Xinxi Chen et.al.|[2410.09699v1](http://arxiv.org/abs/2410.09699v1)|null|
|**2024-10-12**|**LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning**|Jiachun Li et.al.|[2410.09541v1](http://arxiv.org/abs/2410.09541v1)|[link](https://github.com/bugmakerzzz/linked_code)|
|**2024-10-12**|**Text Classification using Graph Convolutional Networks: A Comprehensive Survey**|Syed Mustafa Haider Rizvi et.al.|[2410.09399v1](http://arxiv.org/abs/2410.09399v1)|null|
|**2024-10-12**|**Generative Subgraph Retrieval for Knowledge Graph-Grounded Dialog Generation**|Jinyoung Park et.al.|[2410.09350v1](http://arxiv.org/abs/2410.09350v1)|null|
|**2024-10-11**|**Natural Language Counterfactual Explanations for Graphs Using Large Language Models**|Flavio Giorgi et.al.|[2410.09295v1](http://arxiv.org/abs/2410.09295v1)|[link](https://github.com/flaat/llm-graph-cf)|
|**2024-10-11**|**ReasonPlanner: Enhancing Autonomous Planning in Dynamic Environments with Temporal Knowledge Graphs and LLMs**|Minh Pham Dinh et.al.|[2410.09252v1](http://arxiv.org/abs/2410.09252v1)|null|
|**2024-10-11**|**Towards Trustworthy Knowledge Graph Reasoning: An Uncertainty Aware Perspective**|Bo Ni et.al.|[2410.08985v1](http://arxiv.org/abs/2410.08985v1)|null|
|**2024-10-11**|**When Graph meets Multimodal: Benchmarking on Multimodal Attributed Graphs Learning**|Hao Yan et.al.|[2410.09132v1](http://arxiv.org/abs/2410.09132v1)|[link](https://github.com/sktsherlock/atg)|
|**2024-10-11**|**GIVE: Structured Reasoning with Knowledge Graph Inspired Veracity Extrapolation**|Jiashu He et.al.|[2410.08475v1](http://arxiv.org/abs/2410.08475v1)|null|
|**2024-10-10**|**Privately Learning from Graphs with Applications in Fine-tuning Large Language Models**|Haoteng Yin et.al.|[2410.08299v1](http://arxiv.org/abs/2410.08299v1)|[link](https://github.com/graph-com/pvgalm)|
|**2024-10-10**|**Can Knowledge Graphs Make Large Language Models More Trustworthy? An Empirical Study over Open-ended Question Answering**|Yuan Sui et.al.|[2410.08085v1](http://arxiv.org/abs/2410.08085v1)|null|
|**2024-10-10**|**Disease Entity Recognition and Normalization is Improved with Large Language Model Derived Synthetic Normalized Mentions**|Kuleen Sasse et.al.|[2410.07951v1](http://arxiv.org/abs/2410.07951v1)|null|
|**2024-10-10**|**Benchmarking Agentic Workflow Generation**|Shuofei Qiao et.al.|[2410.07869v1](http://arxiv.org/abs/2410.07869v1)|null|
|**2024-10-10**|**KRAG Framework for Enhancing LLMs in the Legal Domain**|Nguyen Ha Thanh et.al.|[2410.07551v1](http://arxiv.org/abs/2410.07551v1)|null|
|**2024-10-10**|**MKGL: Mastery of a Three-Word Language**|Lingbing Guo et.al.|[2410.07526v1](http://arxiv.org/abs/2410.07526v1)|null|
|**2024-10-09**|**InstructG2I: Synthesizing Images from Multimodal Attributed Graphs**|Bowen Jin et.al.|[2410.07157v1](http://arxiv.org/abs/2410.07157v1)|[link](https://github.com/PeterGriffinJin/InstructG2I)|
|**2024-10-09**|**CSSL: Contrastive Self-Supervised Learning for Dependency Parsing on Relatively Free Word Ordered and Morphologically Rich Low Resource Languages**|Pretam Ray et.al.|[2410.06944v1](http://arxiv.org/abs/2410.06944v1)|null|
|**2024-10-09**|**Tree of Problems: Improving structured problem solving with compositionality**|Armel Zebaze et.al.|[2410.06634v1](http://arxiv.org/abs/2410.06634v1)|null|
|**2024-10-09**|**Multi-Task Program Error Repair and Explanatory Diagnosis**|Zhenyu Xu et.al.|[2410.07271v1](http://arxiv.org/abs/2410.07271v1)|null|
|**2024-10-08**|**Counterfactual Causal Inference in Natural Language with Large Language Models**|Gaël Gendron et.al.|[2410.06392v1](http://arxiv.org/abs/2410.06392v1)|[link](https://github.com/strong-ai-lab/counterfactual-llm-inference)|
|**2024-10-08**|**Less is More: Making Smaller Language Models Competent Subgraph Retrievers for Multi-hop KGQA**|Wenyu Huang et.al.|[2410.06121v1](http://arxiv.org/abs/2410.06121v1)|null|
|**2024-10-08**|**LLM-based SPARQL Query Generation from Natural Language over Federated Knowledge Graphs**|Vincent Emonet et.al.|[2410.06062v2](http://arxiv.org/abs/2410.06062v2)|null|
|**2024-10-08**|**Jet Expansions of Residual Computation**|Yihong Chen et.al.|[2410.06024v1](http://arxiv.org/abs/2410.06024v1)|null|
|**2024-10-08**|**A large collection of bioinformatics question-query pairs over federated knowledge graphs: methodology and applications**|Jerven Bolleman et.al.|[2410.06010v1](http://arxiv.org/abs/2410.06010v1)|null|
|**2024-10-08**|**LightRAG: Simple and Fast Retrieval-Augmented Generation**|Zirui Guo et.al.|[2410.05779v1](http://arxiv.org/abs/2410.05779v1)|[link](https://github.com/hkuds/lightrag)|
|**2024-10-08**|**Information Discovery in e-Commerce**|Zhaochun Ren et.al.|[2410.05763v2](http://arxiv.org/abs/2410.05763v2)|null|
|**2024-10-08**|**Vector-ICL: In-context Learning with Continuous Vector Representations**|Yufan Zhuang et.al.|[2410.05629v1](http://arxiv.org/abs/2410.05629v1)|[link](https://github.com/EvanZhuang/vector-icl)|
|**2024-10-07**|**Narrative-of-Thought: Improving Temporal Reasoning of Large Language Models via Recounted Narratives**|Xinliang Frederick Zhang et.al.|[2410.05558v1](http://arxiv.org/abs/2410.05558v1)|null|
|**2024-10-07**|**Scalable and Accurate Graph Reasoning with LLM-based Multi-Agents**|Yuwei Hu et.al.|[2410.05130v1](http://arxiv.org/abs/2410.05130v1)|null|
|**2024-10-07**|**Leverage Knowledge Graph and Large Language Model for Law Article Recommendation: A Case Study of Chinese Criminal Law**|Yongming Chen et.al.|[2410.04949v1](http://arxiv.org/abs/2410.04949v1)|null|
|**2024-10-07**|**GARLIC: LLM-Guided Dynamic Progress Control with Hierarchical Weighted Graph for Long Document QA**|Xinyu Wang et.al.|[2410.04790v1](http://arxiv.org/abs/2410.04790v1)|null|
|**2024-10-06**|**Reasoning-Enhanced Healthcare Predictions with Knowledge Graph Community Retrieval**|Pengcheng Jiang et.al.|[2410.04585v1](http://arxiv.org/abs/2410.04585v1)|[link](https://github.com/pat-jj/KARE)|
|**2024-10-06**|**Mitigating Hallucinations Using Ensemble of Knowledge Graph and Vector Store in Large Language Models to Enhance Mental Health Support**|Abdul Muqtadir et.al.|[2410.10853v1](http://arxiv.org/abs/2410.10853v1)|null|
|**2024-10-04**|**Leveraging Social Determinants of Health in Alzheimer's Research Using LLM-Augmented Literature Mining and Knowledge Graphs**|Tianqi Shang et.al.|[2410.09080v1](http://arxiv.org/abs/2410.09080v1)|null|
|**2024-10-04**|**Empowering Domain-Specific Language Models with Graph-Oriented Databases: A Paradigm Shift in Performance and Model Maintenance**|Ricardo Di Pasquale et.al.|[2410.03867v1](http://arxiv.org/abs/2410.03867v1)|null|
|**2024-10-04**|**GraphRouter: A Graph-based Router for LLM Selections**|Tao Feng et.al.|[2410.03834v1](http://arxiv.org/abs/2410.03834v1)|null|
|**2024-10-04**|**Should Cross-Lingual AMR Parsing go Meta? An Empirical Assessment of Meta-Learning and Joint Learning AMR Parsing**|Jeongwoo Kang et.al.|[2410.03357v1](http://arxiv.org/abs/2410.03357v1)|[link](https://github.com/Emvista/Meta-XAMR-2024)|
|**2024-10-04**|**Enriching Ontologies with Disjointness Axioms using Large Language Models**|Elias Crum et.al.|[2410.03235v1](http://arxiv.org/abs/2410.03235v1)|[link](https://github.com/n28div/llm-disjointness)|
|**2024-10-04**|**How Do Large Language Models Understand Graph Patterns? A Benchmark for Graph Pattern Comprehension**|Xinnan Dai et.al.|[2410.05298v1](http://arxiv.org/abs/2410.05298v1)|null|
|**2024-10-03**|**LLMCO2: Advancing Accurate Carbon Footprint Prediction for LLM Inferences**|Zhenxiao Fu et.al.|[2410.02950v1](http://arxiv.org/abs/2410.02950v1)|null|
|**2024-10-03**|**Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization**|Ryan C. Barron et.al.|[2410.02721v1](http://arxiv.org/abs/2410.02721v1)|null|
|**2024-10-03**|**A Schema-aware Logic Reformulation for Graph Reachability**|Davide Di Pierro et.al.|[2410.02533v1](http://arxiv.org/abs/2410.02533v1)|null|
|**2024-10-03**|**Language Models are Graph Learners**|Zhe Xu et.al.|[2410.02296v1](http://arxiv.org/abs/2410.02296v1)|null|
|**2024-10-03**|**GraphIC: A Graph-Based In-Context Example Retrieval Model for Multi-Step Reasoning**|Jiale Fu et.al.|[2410.02203v1](http://arxiv.org/abs/2410.02203v1)|null|
|**2024-10-03**|**G2T-LLM: Graph-to-Tree Text Encoding for Molecule Generation with Fine-Tuned Large Language Models**|Zhaoning Yu et.al.|[2410.02198v1](http://arxiv.org/abs/2410.02198v1)|null|
|**2024-10-02**|**FLAG: Financial Long Document Classification via AMR-based GNN**|Bolun "Namir" Xia et.al.|[2410.02024v2](http://arxiv.org/abs/2410.02024v2)|[link](https://github.com/namir0806/flag)|
|**2024-10-02**|**Lost-in-Distance: Impact of Contextual Proximity on LLM Performance in Graph Tasks**|Hamed Firooz et.al.|[2410.01985v1](http://arxiv.org/abs/2410.01985v1)|null|
|**2024-10-02**|**LLM+KG@VLDB'24 Workshop Summary**|Arijit Khan et.al.|[2410.01978v1](http://arxiv.org/abs/2410.01978v1)|null|
|**2024-10-02**|**Conformal Generative Modeling with Improved Sample Efficiency through Sequential Greedy Filtering**|Klaus-Rudolf Kladny et.al.|[2410.01660v1](http://arxiv.org/abs/2410.01660v1)|null|
|**2024-10-02**|**HiReview: Hierarchical Taxonomy-Driven Automatic Literature Review Generation**|Yuntong Hu et.al.|[2410.03761v1](http://arxiv.org/abs/2410.03761v1)|null|
|**2024-10-02**|**LEGO: Learnable Expansion of Graph Operators for Multi-Modal Feature Fusion**|Dexuan Ding et.al.|[2410.01506v2](http://arxiv.org/abs/2410.01506v2)|null|
|**2024-10-02**|**Question-guided Knowledge Graph Re-scoring and Injection for Knowledge Graph Question Answering**|Yu Zhang et.al.|[2410.01401v1](http://arxiv.org/abs/2410.01401v1)|[link](https://github.com/EchoDreamer/Q-KGR)|
|**2024-10-02**|**Unveiling Language Skills under Circuits**|Hang Chen et.al.|[2410.01334v1](http://arxiv.org/abs/2410.01334v1)|[link](https://github.com/zodiark-ch/language-skill-of-llms)|
|**2024-10-01**|**From Natural Language to SQL: Review of LLM-based Text-to-SQL Systems**|Ali Mohammadjafari et.al.|[2410.01066v1](http://arxiv.org/abs/2410.01066v1)|null|
|**2024-09-30**|**GUNDAM: Aligning Large Language Models with Graph Understanding**|Sheng Ouyang et.al.|[2409.20053v2](http://arxiv.org/abs/2409.20053v2)|null|
|**2024-09-30**|**Enhancing High-order Interaction Awareness in LLM-based Recommender Model**|Xinfeng Wang et.al.|[2409.19979v2](http://arxiv.org/abs/2409.19979v2)|[link](https://github.com/WangXFng/ELMRec)|
|**2024-09-29**|**CoTKR: Chain-of-Thought Enhanced Knowledge Rewriting for Complex Knowledge Graph Question Answering**|Yike Wu et.al.|[2409.19753v2](http://arxiv.org/abs/2409.19753v2)|[link](https://github.com/wuyike2000/CoTKR)|
|**2024-09-29**|**Can Large Language Models Analyze Graphs like Professionals? A Benchmark, Datasets and Models**|Xin Li et.al.|[2409.19667v1](http://arxiv.org/abs/2409.19667v1)|[link](https://github.com/bupt-gamma/prograph)|
|**2024-09-28**|**Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs**|Zheng Wang et.al.|[2409.19401v1](http://arxiv.org/abs/2409.19401v1)|null|
|**2024-09-27**|**CLLMate: A Multimodal LLM for Weather and Climate Events Forecasting**|Haobo Li et.al.|[2409.19058v1](http://arxiv.org/abs/2409.19058v1)|null|
|**2024-09-27**|**AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow**|Huizi Yu et.al.|[2409.18924v2](http://arxiv.org/abs/2409.18924v2)|null|
|**2024-09-27**|**Soft Measures for Extracting Causal Collective Intelligence**|Maryam Berijanian et.al.|[2409.18911v1](http://arxiv.org/abs/2409.18911v1)|[link](https://github.com/kuldeep7688/soft-measures-causal-intelligence)|
|**2024-09-27**|**OpenObject-NAV: Open-Vocabulary Object-Oriented Navigation Based on Dynamic Carrier-Relationship Scene Graph**|Yujie Tang et.al.|[2409.18743v1](http://arxiv.org/abs/2409.18743v1)|null|
|**2024-09-27**|**Rehearsing Answers to Probable Questions with Perspective-Taking**|Yung-Yu Shih et.al.|[2409.18678v1](http://arxiv.org/abs/2409.18678v1)|null|
|**2024-09-26**|**LowREm: A Repository of Word Embeddings for 87 Low-Resource Languages Enhanced with Multilingual Graph Knowledge**|Daniil Gurgurov et.al.|[2409.18193v1](http://arxiv.org/abs/2409.18193v1)|null|
|**2024-09-26**|**A Survey of Spatio-Temporal EEG data Analysis: from Models to Applications**|Pengfei Wang et.al.|[2410.08224v1](http://arxiv.org/abs/2410.08224v1)|null|
|**2024-09-26**|**Enhancing Structured-Data Retrieval with GraphRAG: Soccer Data Case Study**|Zahra Sepasdar et.al.|[2409.17580v1](http://arxiv.org/abs/2409.17580v1)|null|
|**2024-09-25**|**Probing Omissions and Distortions in Transformer-based RDF-to-Text Models**|Juliette Faille et.al.|[2409.16707v1](http://arxiv.org/abs/2409.16707v1)|null|
|**2024-09-25**|**GraphLoRA: Structure-Aware Contrastive Low-Rank Adaptation for Cross-Graph Transfer Learning**|Zhe-Rui Yang et.al.|[2409.16670v1](http://arxiv.org/abs/2409.16670v1)|null|
|**2024-09-24**|**Cyber Knowledge Completion Using Large Language Models**|Braden K Webb et.al.|[2409.16176v1](http://arxiv.org/abs/2409.16176v1)|null|
|**2024-09-24**|**Konstruktor: A Strong Baseline for Simple Knowledge Graph Question Answering**|Maria Lysyuk et.al.|[2409.15902v1](http://arxiv.org/abs/2409.15902v1)|[link](https://github.com/s-nlp/konstruktor)|
|**2024-09-24**|**Symmetries and Expressive Requirements for Learning General Policies**|Dominik Drexler et.al.|[2409.15892v1](http://arxiv.org/abs/2409.15892v1)|null|
|**2024-09-23**|**GEM-RAG: Graphical Eigen Memories For Retrieval Augmented Generation**|Brendan Hogan Rappazzo et.al.|[2409.15566v1](http://arxiv.org/abs/2409.15566v1)|null|
|**2024-09-23**|**KARMA: Augmenting Embodied AI Agents with Long-and-short Term Memory Systems**|Zixuan Wang et.al.|[2409.14908v1](http://arxiv.org/abs/2409.14908v1)|null|
|**2024-09-23**|**End-to-End Graph Flattening Method for Large Language Models**|Bin Hong et.al.|[2409.14880v1](http://arxiv.org/abs/2409.14880v1)|null|
|**2024-09-22**|**RACOON: An LLM-based Framework for Retrieval-Augmented Column Type Annotation with a Knowledge Graph**|Linxi Wei et.al.|[2409.14556v1](http://arxiv.org/abs/2409.14556v1)|null|

#### Abstracts
##### **FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression**
2410.12707v1 by Zhenheng Tang, Xueze Kang, Yiming Yin, Xinglin Pan, Yuxin Wang, Xin He, Qiang Wang, Rongfei Zeng, Kaiyong Zhao, Shaohuai Shi, Amelie Chi Zhou, Bo Li, Bingsheng He, Xiaowen Chu

To alleviate hardware scarcity in training large deep neural networks (DNNs),
particularly large language models (LLMs), we present FusionLLM, a
decentralized training system designed and implemented for training DNNs using
geo-distributed GPUs across different computing clusters or individual devices.
Decentralized training faces significant challenges regarding system design and
efficiency, including: 1) the need for remote automatic differentiation (RAD),
2) support for flexible model definitions and heterogeneous software, 3)
heterogeneous hardware leading to low resource utilization or the straggler
problem, and 4) slow network communication. To address these challenges, in the
system design, we represent the model as a directed acyclic graph of operators
(OP-DAG). Each node in the DAG represents the operator in the DNNs, while the
edge represents the data dependency between operators. Based on this design, 1)
users are allowed to customize any DNN without caring low-level operator
implementation; 2) we enable the task scheduling with the more fine-grained
sub-tasks, offering more optimization space; 3) a DAG runtime executor can
implement RAD withour requiring the consistent low-level ML framework versions.
  To enhance system efficiency, we implement a workload estimator and design an
OP-Fence scheduler to cluster devices with similar bandwidths together and
partition the DAG to increase throughput. Additionally, we propose an AdaTopK
compressor to adaptively compress intermediate activations and gradients at the
slowest communication links. To evaluate the convergence and efficiency of our
system and algorithms, we train ResNet-101 and GPT-2 on three real-world
testbeds using 48 GPUs connected with 8 Mbps~10 Gbps networks. Experimental
results demonstrate that our system and method can achieve 1.45 - 9.39x speedup
compared to baseline methods while ensuring convergence.

摘要：<paragraph>為了減輕訓練大型深度神經網路 (DNN) 的硬體短缺問題，尤其是大型語言模型 (LLM)，我們提出了 FusionLLM，一個分散式訓練系統，其設計和實作是用於訓練跨不同運算叢集或個別裝置的地理分散式 GPU 的 DNN。分散式訓練在系統設計和效率方面面臨重大挑戰，包括：1) 需要遠端自動微分 (RAD)，2) 支援彈性的模型定義和異質軟體，3) 異質硬體導致資源利用率低或落後問題，以及 4) 網路通訊速度慢。為了應對這些挑戰，在系統設計中，我們將模型表示為一個有向非循環圖 (OP-DAG) 的運算子。DAG 中的每個節點代表 DNN 中的運算子，而邊緣代表運算子之間的資料依賴性。基於此設計，1) 使用者可以自訂任何 DNN，而不用考慮低階運算子實作；2) 我們啟用任務排程，並使用更細緻的子任務，提供更多最佳化空間；3) DAG 執行時間執行器可以實作 RAD，而不需要一致的低階 ML 架構版本。為了提升系統效率，我們實作一個工作負載估計器，並設計一個 OP-Fence 排程器，將頻寬類似的裝置分組在一起，並分割 DAG 以增加處理量。此外，我們提出一個 AdaTopK 壓縮器，以自適應方式壓縮最慢通訊連結上的中間啟動和梯度。為了評估我們系統和演算法的收斂性和效率，我們在三個真實世界的測試平台上訓練 ResNet-101 和 GPT-2，使用 48 個 GPU 連接到 8 Mbps~10 Gbps 網路。實驗結果表明，我們的系統和方法可以比基準方法快 1.45 - 9.39 倍，同時確保收斂。</paragraph>

##### **The Best of Both Worlds: Bridging Quality and Diversity in Data Selection with Bipartite Graph**
2410.12458v1 by Minghao Wu, Thuy-Trang Vu, Lizhen Qu, Gholamreza Haffari

The performance of large language models (LLMs) in natural language
processing (NLP) tasks is significantly influenced by the quality and diversity
of data used for supervised fine-tuning (SFT). Current data selection methods
often focus solely on quality or diversity, leading to underperforming models
due to suboptimal training data. In this paper, we introduce GraphFilter, a
novel method that represents the dataset as a bipartite graph, linking
sentences to their constituent n-grams. This representation effectively
captures the relationships between sentences and linguistic patterns,
facilitating the selection of sentences that enhance n-gram diversity. To
balance quality and diversity during selection, we propose a priority function
that combines the quality metric with the diversity metric in a multiplicative
manner. GraphFilter iteratively selects high-priority sentences, updates the
bipartite graph by removing covered n-grams, and re-calculates priorities to
reflect the evolving data landscape. We conduct extensive experiments using
three model backbones across six widely used benchmarks. The results
demonstrate that GraphFilter outperforms all nine baseline approaches,
achieving superior model performance and computational efficiency. Our analyses
validate the effectiveness of our design choices, examine the subsets selected
by GraphFilter and other methods, highlight the importance of instruction
diversity, and explore the role of quality and diversity in relation to subset
sizes. GraphFilter establishes a new foundation for effective data selection
strategies, encouraging further research in data selection for LLMs.

摘要：大型語言模型 (LLM) 在自然語言處理 (NLP) 任務中的表現，受到用於監督微調 (SFT) 的資料品質和多樣性顯著影響。目前的資料選取方法通常只關注品質或多樣性，導致訓練資料次佳，進而造成模型表現不佳。在本文中，我們介紹 GraphFilter，一種新穎的方法，它將資料集表示為二部圖，將句子連結到其組成 n-gram。這種表示方式有效捕捉句子和語言模式之間的關係，有助於選擇能提升 n-gram 多樣性的句子。為了在選取過程中平衡品質和多樣性，我們提出優先函數，以乘法方式結合品質指標和多樣性指標。GraphFilter 迭代選取高優先級句子，透過移除已涵蓋 n-gram 來更新二部圖，並重新計算優先級以反映不斷變化的資料樣貌。我們使用三個模型主幹在六個廣泛使用的基準上進行廣泛的實驗。結果顯示，GraphFilter 優於所有九種基線方法，達到卓越的模型效能和運算效率。我們的分析驗證了我們設計選擇的有效性，檢驗 GraphFilter 和其他方法選取的子集，強調指令多樣性的重要性，並探討品質和多樣性與子集大小的關係。GraphFilter 為有效的資料選取策略奠定新的基礎，鼓勵進一步研究 LLM 的資料選取。

##### **PRefLexOR: Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking**
2410.12375v1 by Markus J. Buehler

PRefLexOR (Preference-based Recursive Language Modeling for Exploratory
Optimization of Reasoning) combines preference optimization with concepts from
Reinforcement Learning to enable models to self-teach through iterative
reasoning improvements. We propose a recursive learning approach that engages
the model in multi-step reasoning, revisiting, and refining intermediate steps
before producing a final output in training and inference phases. Through
multiple training stages, the model first learns to align its reasoning with
accurate decision paths by optimizing the log odds between preferred and
non-preferred responses. During this process, PRefLexOR builds a dynamic
knowledge graph by generating questions from random text chunks and
retrieval-augmentation to contextualize relevant details from the entire
training corpus. In the second stage, preference optimization enhances model
performance by using rejection sampling to fine-tune reasoning quality by
continually producing in-situ training data while masking the reasoning steps.
Recursive optimization within a thinking token framework introduces iterative
feedback loops, where the model refines reasoning, achieving deeper coherence,
consistency, and adaptability. Implemented in small language models with only 3
billion parameters, we should that even tiny models can iteratively teach
themselves to reason with greater depth and reflectivity. Our implementation is
straightforward and can be incorporated into any existing pretrained LLM. We
focus our examples on applications in biological materials science and
demonstrate the method in a variety of case studies that range from in-domain
to cross-domain applications. Using reasoning strategies that include thinking
and reflection modalities we build a multi-agent recursive self-improving
inference approach to successively improve responses via repeated sampling in
inference time.

摘要：PRefLexOR（用於探索性推理優化的基於偏好的遞迴語言建模）將偏好優化與強化學習中的概念相結合，使模型能夠通過反覆推理改進來自我教學。我們提出了一種遞迴學習方法，讓模型參與多步驟推理、重新審視和改進中間步驟，然後在訓練和推理階段產生最終輸出。通過多個訓練階段，模型首先學習通過優化首選和非首選響應之間的對數幾率，使其推理與準確的決策路徑保持一致。在此過程中，PRefLexOR 通過從隨機文本塊生成問題和檢索增強來構建一個動態知識圖，從整個訓練語料庫中提取相關細節以進行語境化。在第二階段，偏好優化通過使用拒絕採樣來微調推理質量，從而增強模型性能，同時連續產生原位訓練數據，同時掩蓋推理步驟。在思考令牌框架內進行遞迴優化會引入迭代反饋迴路，其中模型會改進推理，從而實現更深入的連貫性、一致性和適應性。在只有 30 億個參數的小語言模型中實現，我們應該讓即使是很小的模型也能通過迭代的方式教會自己以更大的深度和反思能力進行推理。我們的實現非常直接，可以整合到任何現有的預訓練 LLM 中。我們將我們的示例重點放在生物材料科學應用上，並在從域內到跨域應用等各種案例研究中演示了該方法。使用包括思考和反思模式在內的推理策略，我們構建了一個多代理遞迴自我改進推理方法，以通過在推理時間重複採樣來連續改進響應。

##### **Pyramid-Driven Alignment: Pyramid Principle Guided Integration of Large Language Models and Knowledge Graphs**
2410.12298v2 by Lei Sun, Xinchen Wang, Youdi Li

Large Language Models (LLMs) possess impressive reasoning abilities but are
prone to generating incorrect information, often referred to as hallucinations.
While incorporating external Knowledge Graphs (KGs) can partially mitigate this
issue, existing methods primarily treat KGs as static knowledge repositories,
overlooking the critical disparity between KG and LLM knowledge, and failing to
fully exploit the reasoning capabilities inherent in KGs. To address these
limitations, we propose Pyramid-Driven Alignment (PDA), a novel framework for
seamlessly integrating LLMs with KGs. PDA utilizes Pyramid Principle analysis
to construct a hierarchical pyramid structure. This structure is designed to
reflect the input question and generate more validated deductive knowledge,
thereby enhancing the alignment of LLMs and KGs and ensuring more cohesive
integration. Furthermore, PDA employs a recursive mechanism to harness the
underlying reasoning abilities of KGs, resulting in more accurate knowledge
retrieval for question-answering tasks. Our experimental results reveal a
substantial performance advantage of PDA over state-of-the-art baselines, with
improvements reaching 26.70% and 26.78%.

摘要：大型語言模型 (LLM) 擁有令人印象深刻的推理能力，但容易產生不正確的資訊，通常稱為幻覺。
儘管結合外部知識圖譜 (KG) 可以部分緩解這個問題，但現有方法主要將 KG 視為靜態知識儲存庫，忽視 KG 和 LLM 知識之間的關鍵差異，並且未能充分利用 KG 中固有的推理能力。為了解決這些限制，我們提出金字塔驅動對齊 (PDA)，這是一個將 LLM 與 KG 無縫整合的新穎架構。PDA 利用金字塔原則分析來建構一個階層式金字塔結構。此結構旨在反映輸入問題並產生更多經過驗證的演繹知識，從而增強 LLM 和 KG 的對齊，並確保更緊密的整合。此外，PDA 採用遞迴機制來利用 KG 的底層推理能力，從而更準確地檢索知識以進行問答任務。我們的實驗結果顯示，PDA 相較於最先進的基準，具有顯著的效能優勢，改進幅度達到 26.70% 和 26.78%。

##### **Towards LLM-based Cognitive Models of Students with Misconceptions**
2410.12294v1 by Shashank Sonkar, Xinghe Chen, Naiming Liu, Richard G. Baraniuk, Mrinmaya Sachan

Accurately modeling student cognition is crucial for developing effective
AI-driven educational technologies. A key challenge is creating realistic
student models that satisfy two essential properties: (1) accurately
replicating specific misconceptions, and (2) correctly solving problems where
these misconceptions are not applicable. This dual requirement reflects the
complex nature of student understanding, where misconceptions coexist with
correct knowledge. This paper investigates whether Large Language Models (LLMs)
can be instruction-tuned to meet this dual requirement and effectively simulate
student thinking in algebra. We introduce MalAlgoPy, a novel Python library
that generates datasets reflecting authentic student solution patterns through
a graph-based representation of algebraic problem-solving. Utilizing MalAlgoPy,
we define and examine Cognitive Student Models (CSMs) - LLMs instruction tuned
to faithfully emulate realistic student behavior. Our findings reveal that LLMs
trained on misconception examples can efficiently learn to replicate errors.
However, the training diminishes the model's ability to solve problems
correctly, particularly for problem types where the misconceptions are not
applicable, thus failing to satisfy second property of CSMs. We demonstrate
that by carefully calibrating the ratio of correct to misconception examples in
the training data - sometimes as low as 0.25 - it is possible to develop CSMs
that satisfy both properties. Our insights enhance our understanding of
AI-based student models and pave the way for effective adaptive learning
systems.

摘要：準確建模學生的認知對於開發有效的 AI 驅動教育技術至關重要。一個關鍵挑戰是建立符合以下兩個基本屬性的逼真學生模型：(1) 準確複製特定錯誤觀念，以及 (2) 正確解決這些錯誤觀念不適用的問題。此雙重需求反映了學生理解的複雜性，其中錯誤觀念與正確知識並存。本文探討大型語言模型 (LLM) 是否可以針對指令進行調整，以滿足此雙重需求，並有效模擬學生在代數中的思考。我們引入了 MalAlgoPy，這是一個新穎的 Python 函式庫，透過代數問題解決的圖形化表示，產生反映真實學生解決模式的資料集。利用 MalAlgoPy，我們定義並檢視認知學生模型 (CSM)，也就是針對指令進行調整的 LLM，以忠實地模擬真實學生的行為。我們的研究結果顯示，針對錯誤觀念範例進行訓練的 LLM 可以有效地學習複製錯誤。然而，訓練會降低模型正確解決問題的能力，特別是對於錯誤觀念不適用的問題類型，因此無法滿足 CSM 的第二個屬性。我們證明，透過仔細校準訓練資料中正確範例與錯誤觀念範例的比例（有時低至 0.25），可以開發同時滿足這兩個屬性的 CSM。我們的見解增進了我們對基於 AI 的學生模型的理解，並為有效的適應性學習系統鋪路。

##### **Comprehending Knowledge Graphs with Large Language Models for Recommender Systems**
2410.12229v1 by Ziqiang Cui, Yunpeng Weng, Xing Tang, Fuyuan Lyu, Dugang Liu, Xiuqiang He, Chen Ma

Recently, the introduction of knowledge graphs (KGs) has significantly
advanced recommender systems by facilitating the discovery of potential
associations between items. However, existing methods still face several
limitations. First, most KGs suffer from missing facts or limited scopes. This
can lead to biased knowledge representations, thereby constraining the model's
performance. Second, existing methods typically convert textual information
into IDs, resulting in the loss of natural semantic connections between
different items. Third, existing methods struggle to capture high-order
relationships in global KGs due to their inefficient layer-by-layer information
propagation mechanisms, which are prone to introducing significant noise. To
address these limitations, we propose a novel method called CoLaKG, which
leverages large language models (LLMs) for knowledge-aware recommendation. The
extensive world knowledge and remarkable reasoning capabilities of LLMs enable
them to supplement KGs. Additionally, the strong text comprehension abilities
of LLMs allow for a better understanding of semantic information. Based on
this, we first extract subgraphs centered on each item from the KG and convert
them into textual inputs for the LLM. The LLM then outputs its comprehension of
these item-centered subgraphs, which are subsequently transformed into semantic
embeddings. Furthermore, to utilize the global information of the KG, we
construct an item-item graph using these semantic embeddings, which can
directly capture higher-order associations between items. Both the semantic
embeddings and the structural information from the item-item graph are
effectively integrated into the recommendation model through our designed
representation alignment and neighbor augmentation modules. Extensive
experiments on four real-world datasets demonstrate the superiority of our
method.

摘要：<paragraph>最近，知識圖譜 (KG) 的引入透過促進項目之間潛在關聯的發現，顯著提升推薦系統。然而，現有方法仍面臨幾個限制。首先，大多數 KG 都存在事實缺失或範圍受限的問題。這可能導致有偏差的知識表徵，進而限制模型的效能。其次，現有方法通常會將文字資訊轉換為 ID，導致不同項目之間自然語義連結的遺失。第三，現有方法難以捕捉全球 KG 中的高階關係，原因在於其低效率的逐層資訊傳播機制容易引入顯著雜訊。為了解決這些限制，我們提出了一種稱為 CoLaKG 的新方法，它利用大型語言模型 (LLM) 進行知識感知推薦。LLM 廣泛的世界知識和卓越的推理能力使它們能夠補充 KG。此外，LLM 強大的文字理解能力有助於更深入地理解語義資訊。基於此，我們首先從 KG 中擷取以每個項目為中心的子圖，並將它們轉換為 LLM 的文字輸入。然後，LLM 會輸出其對這些以項目為中心的子圖的理解，這些理解接著會轉換為語義嵌入。此外，為了利用 KG 的全球資訊，我們使用這些語義嵌入建構一個項目-項目圖，它可以直接捕捉項目之間的高階關聯。語義嵌入和來自項目-項目圖的結構資訊都會透過我們設計的表徵比對和鄰域擴充模組有效地整合到推薦模型中。在四個真實世界資料集上進行的廣泛實驗證明了我們方法的優越性。</paragraph>

##### **Triple Modality Fusion: Aligning Visual, Textual, and Graph Data with Large Language Models for Multi-Behavior Recommendations**
2410.12228v1 by Luyi Ma, Xiaohan Li, Zezhong Fan, Jianpeng Xu, Jason Cho, Praveen Kanumala, Kaushiki Nag, Sushant Kumar, Kannan Achan

Integrating diverse data modalities is crucial for enhancing the performance
of personalized recommendation systems. Traditional models, which often rely on
singular data sources, lack the depth needed to accurately capture the
multifaceted nature of item features and user behaviors. This paper introduces
a novel framework for multi-behavior recommendations, leveraging the fusion of
triple-modality, which is visual, textual, and graph data through alignment
with large language models (LLMs). By incorporating visual information, we
capture contextual and aesthetic item characteristics; textual data provides
insights into user interests and item features in detail; and graph data
elucidates relationships within the item-behavior heterogeneous graphs. Our
proposed model called Triple Modality Fusion (TMF) utilizes the power of LLMs
to align and integrate these three modalities, achieving a comprehensive
representation of user behaviors. The LLM models the user's interactions
including behaviors and item features in natural languages. Initially, the LLM
is warmed up using only natural language-based prompts. We then devise the
modality fusion module based on cross-attention and self-attention mechanisms
to integrate different modalities from other models into the same embedding
space and incorporate them into an LLM. Extensive experiments demonstrate the
effectiveness of our approach in improving recommendation accuracy. Further
ablation studies validate the effectiveness of our model design and benefits of
the TMF.

摘要：整合各種資料型態對於提升個人化推薦系統的效能至關重要。傳統模型經常依賴單一資料來源，缺乏捕捉項目特徵和使用者行為多面向本質所需的深度。本文介紹了一個創新的多行為推薦架構，利用視覺、文字和圖形資料的三重型態融合，透過與大型語言模型 (LLM) 對齊來實現。透過納入視覺資訊，我們捕捉脈絡和美學項目特徵；文字資料詳細提供使用者興趣和項目特徵的見解；圖形資料闡明項目行為異質圖形中的關係。我們提出的模型稱為三重型態融合 (TMF)，利用 LLM 的力量來對齊和整合這三種型態，達成使用者行為的全面表徵。LLM 以自然語言建模使用者的互動，包括行為和項目特徵。最初，LLM 僅使用基於自然語言的提示進行熱身。然後我們根據交叉注意力和自我注意力機制設計型態融合模組，將來自其他模型的不同型態整合到相同的嵌入空間，並將它們納入 LLM。廣泛的實驗證明了我們的方法在提升推薦準確度方面的有效性。進一步的消融研究驗證了我們模型設計的有效性以及 TMF 的好處。

##### **Iter-AHMCL: Alleviate Hallucination for Large Language Model via Iterative Model-level Contrastive Learning**
2410.12130v1 by Huiwen Wu, Xiaohan Li, Xiaogang Xu, Jiafei Wu, Deyi Zhang, Zhe Liu

The development of Large Language Models (LLMs) has significantly advanced
various AI applications in commercial and scientific research fields, such as
scientific literature summarization, writing assistance, and knowledge graph
construction. However, a significant challenge is the high risk of
hallucination during LLM inference, which can lead to security concerns like
factual inaccuracies, inconsistent information, and fabricated content. To
tackle this issue, it is essential to develop effective methods for reducing
hallucination while maintaining the original capabilities of the LLM. This
paper introduces a novel approach called Iterative Model-level Contrastive
Learning (Iter-AHMCL) to address hallucination. This method modifies the
representation layers of pre-trained LLMs by using contrastive `positive' and
`negative' models, trained on data with and without hallucinations. By
leveraging the differences between these two models, we create a more
straightforward pathway to eliminate hallucinations, and the iterative nature
of contrastive learning further enhances performance. Experimental validation
on four pre-trained foundation LLMs (LLaMA2, Alpaca, LLaMA3, and Qwen)
finetuning with a specially designed dataset shows that our approach achieves
an average improvement of 10.1 points on the TruthfulQA benchmark.
Comprehensive experiments demonstrate the effectiveness of Iter-AHMCL in
reducing hallucination while maintaining the general capabilities of LLMs.

摘要：大型語言模型 (LLM) 的發展在商業和科學研究領域顯著推動了各種 AI 應用，例如科學文獻摘要、寫作輔助和知識圖譜建構。然而，一個重大的挑戰是 LLM 推論中幻覺的高風險，這可能會導致安全問題，例如事實不正確、資訊不一致和捏造內容。為了解決這個問題，開發有效的方法來減少幻覺，同時保持 LLM 的原始功能至關重要。本文介紹了一種稱為反覆模型層級對比學習 (Iter-AHMCL) 的新方法來解決幻覺。此方法透過使用對比的「正向」和「負向」模型來修改預先訓練的 LLM 的表示層，這些模型是在有和沒有幻覺的資料上訓練的。透過利用這兩個模型之間的差異，我們創造了一條更直接的途徑來消除幻覺，而對比學習的迭代性質進一步增強了效能。在四個預先訓練的基礎 LLM (LLaMA2、Alpaca、LLaMA3 和 Qwen) 上進行的實驗驗證，使用特別設計的資料集進行微調，顯示我們的做法在 TruthfulQA 基準上平均提升了 10.1 分。全面的實驗證明了 Iter-AHMCL 在減少幻覺的同時，維持 LLM 一般功能的有效性。

##### **Bridging Large Language Models and Graph Structure Learning Models for Robust Representation Learning**
2410.12096v1 by Guangxin Su, Yifan Zhu, Wenjie Zhang, Hanchen Wang, Ying Zhang

Graph representation learning, involving both node features and graph
structures, is crucial for real-world applications but often encounters
pervasive noise. State-of-the-art methods typically address noise by focusing
separately on node features with large language models (LLMs) and on graph
structures with graph structure learning models (GSLMs). In this paper, we
introduce LangGSL, a robust framework that integrates the complementary
strengths of pre-trained language models and GSLMs to jointly enhance both node
feature and graph structure learning. In LangGSL, we first leverage LLMs to
filter noise in the raw data and extract valuable cleaned information as
features, enhancing the synergy of downstream models. During the mutual
learning phase in LangGSL, the core idea is to leverage the relatively small
language model (LM) to process local attributes and generate reliable
pseudo-labels and informative node embeddings, which are then integrated into
the GSLM's prediction phase. This approach enriches the global context and
enhances overall performance. Meanwhile, GSLM refines the evolving graph
structure constructed from the LM's output, offering updated labels back to the
LM as additional guidance, thus facilitating a more effective mutual learning
process. The LM and GSLM work synergistically, complementing each other's
strengths and offsetting weaknesses within a variational information-maximizing
framework, resulting in enhanced node features and a more robust graph
structure. Extensive experiments on diverse graph datasets of varying scales
and across different task scenarios demonstrate the scalability and
effectiveness of the proposed approach.

摘要：圖表表示學習既涉及節點特徵又涉及圖形結構，對於現實世界的應用至關重要，但經常會遇到普遍的噪音。最先進的方法通常通過分別關注具有大型語言模型 (LLM) 的節點特徵和具有圖形結構學習模型 (GSLM) 的圖形結構來解決噪音問題。在本文中，我們介紹了 LangGSL，這是一個強大的框架，它整合了預訓練語言模型和 GSLM 的互補優勢，以共同增強節點特徵和圖形結構學習。在 LangGSL 中，我們首先利用 LLM 來過濾原始數據中的噪音，並提取有價值的已清理信息作為特徵，增強下游模型的協同作用。在 LangGSL 中的相互學習階段，核心思想是利用相對較小的語言模型 (LM) 來處理局部屬性並生成可靠的偽標籤和信息豐富的節點嵌入，然後將它們集成到 GSLM 的預測階段。這種方法豐富了全局上下文並增強了整體性能。同時，GSLM 優化了從 LM 輸出構建的演化圖形結構，將更新的標籤作為附加指導反饋給 LM，從而促進更有效的相互學習過程。LM 和 GSLM 協同工作，在變分信息最大化框架內互補各自的優勢並彌補弱點，從而增強節點特徵並形成更強大的圖形結構。在不同規模和不同任務場景的多樣化圖形數據集上進行的廣泛實驗證明了所提出方法的可擴展性和有效性。

##### **A Survey on Deep Tabular Learning**
2410.12034v1 by Shriyank Somvanshi, Subasish Das, Syed Aaqib Javed, Gian Antariksa, Ahmed Hossain

Tabular data, widely used in industries like healthcare, finance, and
transportation, presents unique challenges for deep learning due to its
heterogeneous nature and lack of spatial structure. This survey reviews the
evolution of deep learning models for tabular data, from early fully connected
networks (FCNs) to advanced architectures like TabNet, SAINT, TabTranSELU, and
MambaNet. These models incorporate attention mechanisms, feature embeddings,
and hybrid architectures to address tabular data complexities. TabNet uses
sequential attention for instance-wise feature selection, improving
interpretability, while SAINT combines self-attention and intersample attention
to capture complex interactions across features and data points, both advancing
scalability and reducing computational overhead. Hybrid architectures such as
TabTransformer and FT-Transformer integrate attention mechanisms with
multi-layer perceptrons (MLPs) to handle categorical and numerical data, with
FT-Transformer adapting transformers for tabular datasets. Research continues
to balance performance and efficiency for large datasets. Graph-based models
like GNN4TDL and GANDALF combine neural networks with decision trees or graph
structures, enhancing feature representation and mitigating overfitting in
small datasets through advanced regularization techniques. Diffusion-based
models like the Tabular Denoising Diffusion Probabilistic Model (TabDDPM)
generate synthetic data to address data scarcity, improving model robustness.
Similarly, models like TabPFN and Ptab leverage pre-trained language models,
incorporating transfer learning and self-supervised techniques into tabular
tasks. This survey highlights key advancements and outlines future research
directions on scalability, generalization, and interpretability in diverse
tabular data applications.

摘要：<paragraph>表格資料廣泛應用於醫療保健、金融和運輸等產業，由於其異質性且缺乏空間結構，因此對深度學習提出了獨特的挑戰。這項調查回顧了表格資料深度學習模型的演進，從早期的全連接網路 (FCN) 到 TabNet、SAINT、TabTranSELU 和 MambaNet 等先進架構。這些模型結合了注意力機制、特徵嵌入和混合架構，以解決表格資料的複雜性。TabNet 使用序列注意力進行逐例特徵選取，提升可解釋性，而 SAINT 結合了自我注意力和跨樣本注意力，以捕捉特徵和資料點之間的複雜互動，同時提升可擴充性並減少運算負擔。TabTransformer 和 FT-Transformer 等混合架構將注意力機制與多層感知器 (MLP) 整合，以處理類別資料和數值資料，其中 FT-Transformer 將 transformer 適應到表格資料集。研究持續在大型資料集的效能和效率之間取得平衡。基於圖形的模型，例如 GNN4TDL 和 GANDALF，將神經網路與決策樹或圖形結構結合，透過先進的正則化技術增強特徵表示並減輕小資料集中的過度擬合。基於擴散的模型，例如表格去噪擴散機率模型 (TabDDPM)，會產生合成資料以解決資料稀少的問題，進而提升模型的穩健性。類似地，TabPFN 和 Ptab 等模型利用預先訓練的語言模型，將遷移學習和自我監督技術融入表格任務中。這項調查重點說明了關鍵進展，並概述了在各種表格資料應用中可擴充性、概括性和可解釋性的未來研究方向。</paragraph>

##### **Causal Reasoning in Large Language Models: A Knowledge Graph Approach**
2410.11588v1 by Yejin Kim, Eojin Kang, Juae Kim, H. Howie Huang

Large language models (LLMs) typically improve performance by either
retrieving semantically similar information, or enhancing reasoning abilities
through structured prompts like chain-of-thought. While both strategies are
considered crucial, it remains unclear which has a greater impact on model
performance or whether a combination of both is necessary. This paper answers
this question by proposing a knowledge graph (KG)-based random-walk reasoning
approach that leverages causal relationships. We conduct experiments on the
commonsense question answering task that is based on a KG. The KG inherently
provides both relevant information, such as related entity keywords, and a
reasoning structure through the connections between nodes. Experimental results
show that the proposed KG-based random-walk reasoning method improves the
reasoning ability and performance of LLMs. Interestingly, incorporating three
seemingly irrelevant sentences into the query using KG-based random-walk
reasoning enhances LLM performance, contrary to conventional wisdom. These
findings suggest that integrating causal structures into prompts can
significantly improve reasoning capabilities, providing new insights into the
role of causality in optimizing LLM performance.

摘要：大型語言模型 (LLM) 通常透過擷取語意上相似的資訊，或透過鏈式思考等結構化提示增強推理能力，來提升效能。儘管這兩種策略都被認為至關重要，但目前仍不清楚哪一種對模型效能影響較大，或是否需要結合兩者。本文透過提出一個基於知識圖譜 (KG) 的隨機漫步推理方法，來回答這個問題，這個方法利用了因果關係。我們在基於 KG 的常識問答任務上進行實驗。KG 本身就提供了相關資訊，例如相關實體關鍵字，以及透過節點之間的連結提供的推理結構。實驗結果顯示，提出的基於 KG 的隨機漫步推理方法改善了 LLM 的推理能力和效能。有趣的是，與傳統觀念相反，使用基於 KG 的隨機漫步推理將三個看似無關的句子納入查詢中，可以提升 LLM 的效能。這些發現表明，將因果結構整合到提示中可以顯著提升推理能力，並為因果關係在最佳化 LLM 效能中所扮演的角色提供新的見解。

##### **Y-Mol: A Multiscale Biomedical Knowledge-Guided Large Language Model for Drug Development**
2410.11550v1 by Tengfei Ma, Xuan Lin, Tianle Li, Chaoyi Li, Long Chen, Peng Zhou, Xibao Cai, Xinyu Yang, Daojian Zeng, Dongsheng Cao, Xiangxiang Zeng

Large Language Models (LLMs) have recently demonstrated remarkable
performance in general tasks across various fields. However, their
effectiveness within specific domains such as drug development remains
challenges. To solve these challenges, we introduce \textbf{Y-Mol}, forming a
well-established LLM paradigm for the flow of drug development. Y-Mol is a
multiscale biomedical knowledge-guided LLM designed to accomplish tasks across
lead compound discovery, pre-clinic, and clinic prediction. By integrating
millions of multiscale biomedical knowledge and using LLaMA2 as the base LLM,
Y-Mol augments the reasoning capability in the biomedical domain by learning
from a corpus of publications, knowledge graphs, and expert-designed synthetic
data. The capability is further enriched with three types of drug-oriented
instructions: description-based prompts from processed publications,
semantic-based prompts for extracting associations from knowledge graphs, and
template-based prompts for understanding expert knowledge from biomedical
tools. Besides, Y-Mol offers a set of LLM paradigms that can autonomously
execute the downstream tasks across the entire process of drug development,
including virtual screening, drug design, pharmacological properties
prediction, and drug-related interaction prediction. Our extensive evaluations
of various biomedical sources demonstrate that Y-Mol significantly outperforms
general-purpose LLMs in discovering lead compounds, predicting molecular
properties, and identifying drug interaction events.

摘要：大型語言模型 (LLM) 近期在各個領域的通用任務中展示出顯著的表現。然而，它們在特定領域（例如藥物開發）中的效能仍有待加強。為了解決這些挑戰，我們引入了 **Y-Mol**，形成了一個完善的 LLM 典範，用於藥物開發流程。Y-Mol 是一個多尺度的生物醫學知識引導 LLM，旨在完成先導化合物發現、臨床前和臨床預測等任務。透過整合數百萬個多尺度的生物醫學知識，並使用 LLaMA2 作為基礎 LLM，Y-Mol 從出版物、知識圖譜和專家設計的合成資料中學習，增強了生物醫學領域的推理能力。其能力進一步透過三種類型的藥物導向指令得到豐富：已處理出版物的基於描述的提示、用於從知識圖譜中提取關聯的基於語義的提示，以及用於理解生物醫學工具中專家知識的基於範本的提示。此外，Y-Mol 提供了一組 LLM 典範，可以在整個藥物開發過程中自主執行下游任務，包括虛擬篩選、藥物設計、藥理特性預測和藥物相關交互預測。我們對各種生物醫學來源的廣泛評估表明，Y-Mol 在發現先導化合物、預測分子特性和識別藥物交互事件方面顯著優於通用 LLM。

##### **AGENTiGraph: An Interactive Knowledge Graph Platform for LLM-based Chatbots Utilizing Private Data**
2410.11531v1 by Xinjie Zhao, Moritz Blum, Rui Yang, Boming Yang, Luis Márquez Carpintero, Mónica Pina-Navarro, Tony Wang, Xin Li, Huitao Li, Yanran Fu, Rongrong Wang, Juntao Zhang, Irene Li

Large Language Models~(LLMs) have demonstrated capabilities across various
applications but face challenges such as hallucination, limited reasoning
abilities, and factual inconsistencies, especially when tackling complex,
domain-specific tasks like question answering~(QA). While Knowledge
Graphs~(KGs) have been shown to help mitigate these issues, research on the
integration of LLMs with background KGs remains limited. In particular, user
accessibility and the flexibility of the underlying KG have not been thoroughly
explored. We introduce AGENTiGraph (Adaptive Generative ENgine for Task-based
Interaction and Graphical Representation), a platform for knowledge management
through natural language interaction. It integrates knowledge extraction,
integration, and real-time visualization. AGENTiGraph employs a multi-agent
architecture to dynamically interpret user intents, manage tasks, and integrate
new knowledge, ensuring adaptability to evolving user requirements and data
contexts. Our approach demonstrates superior performance in knowledge graph
interactions, particularly for complex domain-specific tasks. Experimental
results on a dataset of 3,500 test cases show AGENTiGraph significantly
outperforms state-of-the-art zero-shot baselines, achieving 95.12\% accuracy in
task classification and 90.45\% success rate in task execution. User studies
corroborate its effectiveness in real-world scenarios. To showcase versatility,
we extended AGENTiGraph to legislation and healthcare domains, constructing
specialized KGs capable of answering complex queries in legal and medical
contexts.

摘要：大型語言模型 (LLM) 已在各種應用中展現其能力，但仍面臨幻覺、推理能力有限和事實不一致等挑戰，尤其是在處理複雜的特定領域任務，例如問答 (QA) 時。雖然知識圖譜 (KG) 已被證明有助於緩解這些問題，但 LLM 與背景 KG 整合的研究仍然有限。特別是，使用者的可及性和底層 KG 的靈活性尚未得到徹底探討。我們引入了 AGENTiGraph（用於任務型互動和圖形表示的自適應生成引擎），一個透過自然語言互動進行知識管理的平台。它整合了知識萃取、整合和即時視覺化。AGENTiGraph 採用多代理架構，以動態解讀使用者的意圖、管理任務並整合新知識，確保適應不斷變化的使用者需求和資料脈絡。我們的做法在知識圖譜互動中展現出優異的效能，特別是對於複雜的特定領域任務。在 3,500 個測試案例的資料集上進行的實驗結果顯示，AGENTiGraph 明顯優於最先進的零次學習基準，在任務分類中達到 95.12% 的準確度，在任務執行中達到 90.45% 的成功率。使用者研究證實了它在真實世界場景中的有效性。為了展示其多功能性，我們將 AGENTiGraph 延伸到法律和醫療保健領域，建構了能夠回答法律和醫療脈絡中複雜查詢的專業知識圖譜。

##### **Do LLMs Have the Generalization Ability in Conducting Causal Inference?**
2410.11385v1 by Chen Wang, Dongming Zhao, Bo Wang, Ruifang He, Yuexian Hou

In causal inference, generalization capability refers to the ability to
conduct causal inference methods on new data to estimate the causal-effect
between unknown phenomenon, which is crucial for expanding the boundaries of
knowledge. Studies have evaluated the causal inference capabilities of Large
Language Models (LLMs) concerning known phenomena, yet the generalization
capabilities of LLMs concerning unseen phenomena remain unexplored. In this
paper, we selected four tasks: Causal Path Discovery (CP), Backdoor Adjustment
(BA), Factual Inference (FI), and Counterfactual Inference (CI) as
representatives of causal inference tasks. To generate evaluation questions
about previously unseen phenomena in new data on the four tasks, we propose a
benchmark generation framework, which employs randomly generated graphs and
node names to formulate questions within hypothetical new causal scenarios.
Based on this framework, we compile a benchmark dataset of varying levels of
question complexity. We extensively tested the generalization capabilities of
five leading LLMs across four tasks. Experiment results reveal that while LLMs
exhibit good generalization performance in solving simple CP, FI, and complex
CI questions, they encounter difficulties when tackling BA questions and face
obvious performance fluctuations as the problem complexity changes.
Furthermore, when the names of phenomena incorporate existing terms, even if
these names are entirely novel, their generalization performance can still be
hindered by interference from familiar terms.

摘要：在因果推論中，泛化能力是指在新的資料上執行因果推論方法以估計未知現象之間的因果關係的能力，這對於擴展知識的界限至關重要。研究已經評估了大型語言模型 (LLM) 關於已知現象的因果推論能力，但 LLM 關於未知現象的泛化能力仍未被探討。在本文中，我們選擇了四個任務：因果路徑發現 (CP)、後門調整 (BA)、事實推論 (FI) 和反事實推論 (CI) 作為因果推論任務的代表。為了產生關於新資料中以前未見現象的評估問題，我們提出了基準生成框架，該框架採用隨機生成的圖形和節點名稱在假設的新因果場景中制定問題。基於此框架，我們編制了一個問題複雜程度不同的基準數據集。我們廣泛測試了五個領先的 LLM 在四個任務中的泛化能力。實驗結果表明，雖然 LLM 在解決簡單的 CP、FI 和複雜的 CI 問題時表現出良好的泛化性能，但在解決 BA 問題時遇到困難，並且隨著問題複雜性的變化而面臨明顯的性能波動。此外，當現象的名稱包含現有術語時，即使這些名稱是完全新穎的，其泛化性能仍然會受到熟悉術語的干擾。

##### **Enhance Graph Alignment for Large Language Models**
2410.11370v1 by Haitong Luo, Xuying Meng, Suhang Wang, Tianxiang Zhao, Fali Wang, Hanyun Cao, Yujun Zhang

Graph-structured data is prevalent in the real world. Recently, due to the
powerful emergent capabilities, Large Language Models (LLMs) have shown
promising performance in modeling graphs. The key to effectively applying LLMs
on graphs is converting graph data into a format LLMs can comprehend.
Graph-to-token approaches are popular in enabling LLMs to process graph
information. They transform graphs into sequences of tokens and align them with
text tokens through instruction tuning, where self-supervised instruction
tuning helps LLMs acquire general knowledge about graphs, and supervised
fine-tuning specializes LLMs for the downstream tasks on graphs. Despite their
initial success, we find that existing methods have a misalignment between
self-supervised tasks and supervised downstream tasks, resulting in negative
transfer from self-supervised fine-tuning to downstream tasks. To address these
issues, we propose Graph Alignment Large Language Models (GALLM) to benefit
from aligned task templates. In the self-supervised tuning stage, we introduce
a novel text matching task using templates aligned with downstream tasks. In
the task-specific tuning stage, we propose two category prompt methods that
learn supervision information from additional explanation with further aligned
templates. Experimental evaluations on four datasets demonstrate substantial
improvements in supervised learning, multi-dataset generalizability, and
particularly in zero-shot capability, highlighting the model's potential as a
graph foundation model.

摘要：圖形結構的資料在現實世界中很常見。最近，由於強大的新興能力，大型語言模型 (LLM) 在圖形建模方面展現出令人滿意的效能。有效將 LLM 應用於圖形的關鍵是將圖形資料轉換成 LLM 可以理解的格式。圖形到標記的方法很流行，讓 LLM 可以處理圖形資訊。它們將圖形轉換成標記序列，並透過指令調整與文字標記對齊，其中自我監督的指令調整有助於 LLM 獲得關於圖形的常識，而監督微調則專門針對圖形上的下游任務調整 LLM。儘管它們最初很成功，我們發現現有方法在自我監督任務和監督下游任務之間存在錯位，導致自我監督微調對下游任務產生負面影響。為了解決這些問題，我們提出圖形對齊大型語言模型 (GALLM) 以從對齊的任務範本中受益。在自我監督調整階段，我們使用與下游任務對齊的範本，引入一個新穎的文字比對任務。在特定任務的調整階段，我們提出兩種類別提示方法，從進一步對齊範本的額外說明中學習監督資訊。在四個資料集上的實驗評估證明了監督式學習、多資料集的概括性，特別是在零次學習能力方面有顯著的進步，突顯了該模型作為圖形基礎模型的潛力。

##### **Unleashing the Power of LLMs as Multi-Modal Encoders for Text and Graph-Structured Data**
2410.11235v1 by Jiacheng Lin, Kun Qian, Haoyu Han, Nurendra Choudhary, Tianxin Wei, Zhongruo Wang, Sahika Genc, Edward W Huang, Sheng Wang, Karthik Subbian, Danai Koutra, Jimeng Sun

Graph-structured information offers rich contextual information that can
enhance language models by providing structured relationships and hierarchies,
leading to more expressive embeddings for various applications such as
retrieval, question answering, and classification. However, existing methods
for integrating graph and text embeddings, often based on Multi-layer
Perceptrons (MLPs) or shallow transformers, are limited in their ability to
fully exploit the heterogeneous nature of these modalities. To overcome this,
we propose Janus, a simple yet effective framework that leverages Large
Language Models (LLMs) to jointly encode text and graph data. Specifically,
Janus employs an MLP adapter to project graph embeddings into the same space as
text embeddings, allowing the LLM to process both modalities jointly. Unlike
prior work, we also introduce contrastive learning to align the graph and text
spaces more effectively, thereby improving the quality of learned joint
embeddings. Empirical results across six datasets spanning three tasks,
knowledge graph-contextualized question answering, graph-text pair
classification, and retrieval, demonstrate that Janus consistently outperforms
existing baselines, achieving significant improvements across multiple
datasets, with gains of up to 11.4% in QA tasks. These results highlight
Janus's effectiveness in integrating graph and text data. Ablation studies
further validate the effectiveness of our method.

摘要：圖形結構化資訊提供豐富的脈絡資訊，可以透過提供結構化的關係和階層來增強語言模型，進而為各種應用程式（例如檢索、問答和分類）產生更具表現力的嵌入。然而，現有的圖形和文字嵌入整合方法，通常基於多層感知器 (MLP) 或淺層轉換器，在充分利用這些模態的異質性方面能力有限。為了克服這一點，我們提出了 Janus，一個簡單但有效的框架，它利用大型語言模型 (LLM) 來聯合編碼文字和圖形資料。具體來說，Janus 使用 MLP 適配器將圖形嵌入投影到與文字嵌入相同的空間，允許 LLM 聯合處理這兩種模態。與先前的研究不同，我們還引入了對比學習，以更有效地對齊圖形和文字空間，從而提高學習到的聯合嵌入的品質。跨越六個資料集的實證結果涵蓋了三個任務，知識圖譜脈絡化問答、圖形文字對分類和檢索，證明 Janus 持續優於現有基準，在多個資料集上取得顯著進步，在 QA 任務中獲得高達 11.4% 的提升。這些結果突顯了 Janus 在整合圖形和文字資料方面的有效性。消融研究進一步驗證了我們方法的有效性。

##### **Tree of Attributes Prompt Learning for Vision-Language Models**
2410.11201v1 by Tong Ding, Wanhua Li, Zhongqi Miao, Hanspeter Pfister

Prompt learning has proven effective in adapting vision language models for
downstream tasks. However, existing methods usually append learnable prompt
tokens solely with the category names to obtain textual features, which fails
to fully leverage the rich context indicated in the category name. To address
this issue, we propose the Tree of Attributes Prompt learning (TAP), which
first instructs LLMs to generate a tree of attributes with a "concept -
attribute - description" structure for each category, and then learn the
hierarchy with vision and text prompt tokens. Unlike existing methods that
merely augment category names with a set of unstructured descriptions, our
approach essentially distills structured knowledge graphs associated with class
names from LLMs. Furthermore, our approach introduces text and vision prompts
designed to explicitly learn the corresponding visual attributes, effectively
serving as domain experts. Additionally, the general and diverse descriptions
generated based on the class names may be wrong or absent in the specific given
images. To address this misalignment, we further introduce a vision-conditional
pooling module to extract instance-specific text features. Extensive
experimental results demonstrate that our approach outperforms state-of-the-art
methods on the zero-shot base-to-novel generalization, cross-dataset transfer,
as well as few-shot classification across 11 diverse datasets.

摘要：提示學習已被證明有效地將視覺語言模型適應於下游任務。然而，現有方法通常僅將可學習的提示令牌附加到類別名稱以獲取文本特徵，這未能充分利用類別名稱中指示的豐富上下文。為了解決這個問題，我們提出了屬性提示學習樹 (TAP)，它首先指示 LLM 為每個類別生成一個具有「概念 - 屬性 - 描述」結構的屬性樹，然後使用視覺和文本提示令牌學習層次結構。與僅使用一組非結構化描述來擴充類別名稱的現有方法不同，我們的做法實質上從 LLM 中提煉出與類別名稱相關的結構化知識圖。此外，我們的做法引入了文本和視覺提示，旨在明確學習對應的視覺屬性，有效地充當領域專家。此外，根據類別名稱生成的通用且多樣的描述在給定的特定影像中可能是錯誤的或不存在的。為了解決這種錯位，我們進一步引入了一個視覺條件池化模組來提取特定於實例的文本特徵。廣泛的實驗結果表明，我們的做法在零次學習基礎到新穎的概化、跨資料集傳輸以及 11 個不同資料集的少次學習分類上優於最先進的方法。

##### **Graph of Records: Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs**
2410.11001v1 by Haozhen Zhang, Tao Feng, Jiaxuan You

Retrieval-augmented generation (RAG) has revitalized Large Language Models
(LLMs) by injecting non-parametric factual knowledge. Compared with
long-context LLMs, RAG is considered an effective summarization tool in a more
concise and lightweight manner, which can interact with LLMs multiple times
using diverse queries to get comprehensive responses. However, the
LLM-generated historical responses, which contain potentially insightful
information, are largely neglected and discarded by existing approaches,
leading to suboptimal results. In this paper, we propose \textit{graph of
records} (\textbf{GoR}), which leverages historical responses generated by LLMs
to enhance RAG for long-context global summarization. Inspired by the
\textit{retrieve-then-generate} paradigm of RAG, we construct a graph by
establishing an edge between the retrieved text chunks and the corresponding
LLM-generated response. To further uncover the intricate correlations between
them, GoR further features a \textit{graph neural network} and an elaborately
designed \textit{BERTScore}-based objective for self-supervised model training,
enabling seamless supervision signal backpropagation between reference
summaries and node embeddings. We comprehensively compare GoR with 12 baselines
across four long-context summarization datasets, and the results indicate that
our proposed method reaches the best performance e.g., 15\%, 8\%, and 19\%
improvement over retrievers w.r.t. Rouge-L, Rouge-1, and Rouge-2 on the WCEP
dataset). Extensive experiments further demonstrate the effectiveness of GoR.
Code is available at https://github.com/ulab-uiuc/GoR

摘要：检索增强生成 (RAG) 透过注入非参数事实知识，让大型语言模型 (LLM) 重获生机。与长文本 LLM 相比，RAG 被视为一种更简洁、轻量级的有效摘要工具，它可以使用不同的查询与 LLM 多次互动，以获得全面的响应。然而，现有的方法在很大程度上忽略并舍弃了 LLM 生成的历史响应，其中包含潜在的有见解的信息，从而导致次优的结果。在本文中，我们提出了「记录图」(**GoR**)，它利用 LLM 生成的历史响应来增强 RAG，以进行长文本全局摘要。受 RAG 的「先检索后生成」范例启发，我们通过在检索到的文本块和相应的 LLM 生成的响应之间建立边来构建图。为了进一步揭示它们之间的复杂相关性，GoR 进一步采用了「图神经网络」和精心设计的基于「BERTScore」的目标，用于自我监督模型训练，从而在参考摘要和节点嵌入之间实现无缝的监督信号反向传播。我们对 GoR 与 12 个基准进行了全面比较，涵盖了四个长文本摘要数据集，结果表明我们提出的方法达到了最佳性能，例如，在 WCEP 数据集上，相对于检索器，Rouge-L、Rouge-1 和 Rouge-2 分别提高了 15%、8% 和 19%。广泛的实验进一步证明了 GoR 的有效性。代码可在 https://github.com/ulab-uiuc/GoR 获得

##### **NT-LLM: A Novel Node Tokenizer for Integrating Graph Structure into Large Language Models**
2410.10743v1 by Yanbiao Ji, Chang Liu, Xin Chen, Yue Ding, Dan Luo, Mei Li, Wenqing Lin, Hongtao Lu

Graphs are a fundamental data structure for representing relationships in
real-world scenarios. With the success of Large Language Models (LLMs) across
various natural language processing (NLP) tasks, there has been growing
interest in integrating LLMs for graph learning. However, applying LLMs to
graph-related tasks poses significant challenges, as these models are not
inherently designed to capture the complex structural information present in
graphs. Existing approaches address this challenge through two strategies: the
chain of tasks approach, which uses Graph Neural Networks (GNNs) to encode the
graph structure so that LLMs are relieved from understanding spatial positions;
and Graph-to-Text Conversion, which translates graph structures into semantic
text representations that LLMs can process. Despite their progress, these
methods often struggle to fully preserve the topological information of graphs
or require extensive computational resources, limiting their practical
applicability.
  In this work, we introduce Node Tokenizer for Large Language Models (NT-LLM),
a novel framework that efficiently encodes graph structures by selecting key
nodes as anchors and representing each node based on its relative distance to
these anchors. This position-anchored encoding effectively captures the graph
topology, enabling enhanced reasoning capabilities in LLMs over graph data.
Additionally, we implement a task-specific tuning procedure to further improve
structural understanding within LLMs. Through extensive empirical evaluations,
NT-LLM demonstrates significant performance improvements across a variety of
graph-related tasks.

摘要：圖形是一種基本資料結構，用於表示現實世界場景中的關係。隨著大型語言模型 (LLM) 在各種自然語言處理 (NLP) 任務中的成功，整合 LLM 以進行圖形學習的興趣日益濃厚。然而，將 LLM 應用於與圖形相關的任務會帶來重大挑戰，因為這些模型並非天生就設計成用來擷取圖形中存在的複雜結構資訊。現有方法透過兩種策略來應對此挑戰：任務鏈方法，它使用圖形神經網路 (GNN) 編碼圖形結構，以便減輕 LLM 理解空間位置的負擔；以及圖形轉文字轉換，它將圖形結構轉換成 LLM 可以處理的語意文字表示。儘管這些方法取得了進展，但它們通常難以完全保留圖形的拓撲資訊，或者需要大量的運算資源，限制了它們的實際應用性。
在本文中，我們介紹了大型語言模型節點標記器 (NT-LLM)，這是一個新穎的框架，它透過選擇關鍵節點作為錨點，並根據每個節點與這些錨點的相對距離來表示每個節點，從而有效地編碼圖形結構。這種基於位置的錨點編碼有效地擷取了圖形拓撲，讓 LLM 能夠對圖形資料進行增強的推理。此外，我們實作了一個特定於任務的調整程序，以進一步改善 LLM 中的結構理解。透過廣泛的實證評估，NT-LLM 在各種與圖形相關的任務中都展示出顯著的效能提升。

##### **GraphCLIP: Enhancing Transferability in Graph Foundation Models for Text-Attributed Graphs**
2410.10329v2 by Yun Zhu, Haizhou Shi, Xiaotang Wang, Yongchao Liu, Yaoke Wang, Boci Peng, Chuntao Hong, Siliang Tang

Recently, research on Text-Attributed Graphs (TAGs) has gained significant
attention due to the prevalence of free-text node features in real-world
applications and the advancements in Large Language Models (LLMs) that bolster
TAG methodologies. However, current TAG approaches face two primary challenges:
(i) Heavy reliance on label information and (ii) Limited cross-domain
zero/few-shot transferability. These issues constrain the scaling of both data
and model size, owing to high labor costs and scaling laws, complicating the
development of graph foundation models with strong transferability. In this
work, we propose the GraphCLIP framework to address these challenges by
learning graph foundation models with strong cross-domain zero/few-shot
transferability through a self-supervised contrastive graph-summary pretraining
method. Specifically, we generate and curate large-scale graph-summary pair
data with the assistance of LLMs, and introduce a novel graph-summary
pretraining method, combined with invariant learning, to enhance graph
foundation models with strong cross-domain zero-shot transferability. For
few-shot learning, we propose a novel graph prompt tuning technique aligned
with our pretraining objective to mitigate catastrophic forgetting and minimize
learning costs. Extensive experiments show the superiority of GraphCLIP in both
zero-shot and few-shot settings, while evaluations across various downstream
tasks confirm the versatility of GraphCLIP. Our code is available at:
https://github.com/ZhuYun97/GraphCLIP

摘要：最近，文本属性图（TAG）的研究由于现实世界应用中自由文本节点特征的普遍性以及支持 TAG 方法的大语言模型（LLM）的进步而备受关注。然而，当前的 TAG 方法面临两大主要挑战：(i) 对标签信息的严重依赖，以及 (ii) 跨域零/小样本可迁移性的受限。由于高昂的人力成本和规模化定律，这些问题限制了数据和模型规模的扩展，使得具有强大可迁移性的图基础模型的开发变得复杂。在这项工作中，我们提出了 GraphCLIP 框架，通过自监督对比图摘要预训练方法来学习具有强大跨域零/小样本可迁移性的图基础模型，以应对这些挑战。具体来说，我们借助 LLM 生成并整理了大规模图摘要对数据，并引入了一种新颖的图摘要预训练方法，结合不变性学习，以增强具有强大跨域零样本可迁移性的图基础模型。对于小样本学习，我们提出了一种新颖的图提示调整技术，该技术与我们的预训练目标一致，以减轻灾难性遗忘并最大程度地降低学习成本。大量的实验表明，GraphCLIP 在零样本和小样本设置中都具有优越性，同时对各种下游任务的评估证实了 GraphCLIP 的多功能性。我们的代码可在以下位置获得：
https://github.com/ZhuYun97/GraphCLIP

##### **Unified Representation of Genomic and Biomedical Concepts through Multi-Task, Multi-Source Contrastive Learning**
2410.10144v1 by Hongyi Yuan, Suqi Liu, Kelly Cho, Katherine Liao, Alexandre Pereira, Tianxi Cai

We introduce GENomic Encoding REpresentation with Language Model (GENEREL), a
framework designed to bridge genetic and biomedical knowledge bases. What sets
GENEREL apart is its ability to fine-tune language models to infuse biological
knowledge behind clinical concepts such as diseases and medications. This
fine-tuning enables the model to capture complex biomedical relationships more
effectively, enriching the understanding of how genomic data connects to
clinical outcomes. By constructing a unified embedding space for biomedical
concepts and a wide range of common SNPs from sources such as patient-level
data, biomedical knowledge graphs, and GWAS summaries, GENEREL aligns the
embeddings of SNPs and clinical concepts through multi-task contrastive
learning. This allows the model to adapt to diverse natural language
representations of biomedical concepts while bypassing the limitations of
traditional code mapping systems across different data sources. Our experiments
demonstrate GENEREL's ability to effectively capture the nuanced relationships
between SNPs and clinical concepts. GENEREL also emerges to discern the degree
of relatedness, potentially allowing for a more refined identification of
concepts. This pioneering approach in constructing a unified embedding system
for both SNPs and biomedical concepts enhances the potential for data
integration and discovery in biomedical research.

摘要：<paragraph>我們介紹 GENomic Encoding REpresentation with Language Model (GENEREL)，一個旨在橋接遺傳和生物醫學知識庫的框架。GENEREL 的獨特之處在於它微調語言模型，以灌輸疾病和藥物等臨床概念背後的生物知識。這種微調使模型能夠更有效地捕捉複雜的生物醫學關係，豐富對基因組數據如何連接臨床結果的理解。通過構建一個統一的生物醫學概念嵌入空間和來自患者級別數據、生物醫學知識圖譜和 GWAS 總結等來源的廣泛常見 SNP，GENEREL 通過多任務對比學習對齊 SNP 和臨床概念的嵌入。這允許模型適應生物醫學概念的多元自然語言表示，同時繞過不同數據源中傳統代碼映射系統的限制。我們的實驗證明了 GENEREL 有效捕捉 SNP 和臨床概念之間細微關係的能力。GENEREL 也出現了辨別相關程度，潛在地允許更精確地識別概念。這種構建 SNP 和生物醫學概念統一嵌入系統的先驅方法增強了生物醫學研究中數據整合和發現的潛力。</paragraph>

##### **Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?**
2410.10083v2 by Yifan Feng, Chengwu Yang, Xingliang Hou, Shaoyi Du, Shihui Ying, Zongze Wu, Yue Gao

Existing benchmarks like NLGraph and GraphQA evaluate LLMs on graphs by
focusing mainly on pairwise relationships, overlooking the high-order
correlations found in real-world data. Hypergraphs, which can model complex
beyond-pairwise relationships, offer a more robust framework but are still
underexplored in the context of LLMs. To address this gap, we introduce
LLM4Hypergraph, the first comprehensive benchmark comprising 21,500 problems
across eight low-order, five high-order, and two isomorphism tasks, utilizing
both synthetic and real-world hypergraphs from citation networks and protein
structures. We evaluate six prominent LLMs, including GPT-4o, demonstrating our
benchmark's effectiveness in identifying model strengths and weaknesses. Our
specialized prompting framework incorporates seven hypergraph languages and
introduces two novel techniques, Hyper-BAG and Hyper-COT, which enhance
high-order reasoning and achieve an average 4% (up to 9%) performance
improvement on structure classification tasks. This work establishes a
foundational testbed for integrating hypergraph computational capabilities into
LLMs, advancing their comprehension. The source codes are at
https://github.com/iMoonLab/LLM4Hypergraph.

摘要：現有的 NLGraph 和 GraphQA 等基準主要關注成對關係，而忽略了在現實世界資料中發現的高階相關性，從而對圖形中的 LLM 進行評估。超圖可以建模複雜的超越成對關係，提供更強大的框架，但在 LLM 的背景下仍未得到充分探索。為了解決這個差距，我們引入了 LLM4Hypergraph，這是第一個綜合基準，包含 21,500 個問題，涵蓋八個低階、五個高階和兩個同構任務，利用來自引文網路和蛋白質結構的合成和真實世界超圖。我們評估了六個著名的 LLM，包括 GPT-4o，證明了我們的基準在識別模型優勢和劣勢方面的有效性。我們專業的提示框架包含七種超圖語言，並引入了兩種新技術 Hyper-BAG 和 Hyper-COT，它們增強了高階推理，並在結構分類任務上實現了平均 4%（最高 9%）的性能改進。這項工作為將超圖計算能力整合到 LLM 中建立了一個基礎測試平台，從而提升了它們的理解力。源代碼位於 https://github.com/iMoonLab/LLM4Hypergraph。

##### **Dynamic and Textual Graph Generation Via Large-Scale LLM-based Agent Simulation**
2410.09824v1 by Jiarui Ji, Runlin Lei, Jialing Bi, Zhewei Wei, Yankai Lin, Xuchen Pan, Yaliang Li, Bolin Ding

Graph generation is a fundamental task that has been extensively studied in
social, technological, and scientific analysis. For modeling the dynamic graph
evolution process, traditional rule-based methods struggle to capture community
structures within graphs, while deep learning methods only focus on fitting
training graphs. This limits existing graph generators to producing graphs that
adhere to predefined rules or closely resemble training datasets, achieving
poor performance in dynamic graph generation. Given that graphs are abstract
representations arising from pairwise interactions in human activities, a
realistic simulation of human-wise interaction could provide deeper insights
into the graph evolution mechanism. With the increasing recognition of large
language models (LLMs) in simulating human behavior, we introduce
GraphAgent-Generator (GAG), a novel simulation-based framework for dynamic
graph generation. Without training or fine-tuning process of LLM, our framework
effectively replicates seven macro-level structural characteristics in
established network science theories while surpassing existing baselines in
graph expansion tasks by 31\% on specific evaluation metrics. Through node
classification task, we validate GAG effectively preserves characteristics of
real-world network for node-wise textual features in generated text-rich graph.
Furthermore, by incorporating parallel acceleration, GAG supports generating
graphs with up to nearly 100,000 nodes or 10 million edges through large-scale
LLM-based agent simulation, with a minimum speed-up of 90.4\%. The source code
is available at https://anonymous.4open.science/r/GraphAgent-2206.

摘要：圖表生成是一項基本任務，已在社會、技術和科學分析中廣泛研究。對於建模動態圖表演化過程，傳統基於規則的方法難以捕捉圖表中的社群結構，而深度學習方法僅專注於擬合訓練圖表。這限制了現有的圖表生成器產生符合預定義規則或與訓練資料集非常相似的圖表，在動態圖表生成中表現不佳。由於圖表是源自人類活動中成對互動的抽象表示，因此對人類互動的逼真模擬可以提供對圖表演化機制的更深入見解。隨著大型語言模型 (LLM) 在模擬人類行為方面獲得越來越多的認可，我們引入了 GraphAgent-Generator (GAG)，這是一個用於動態圖表生成的創新基於模擬的框架。在沒有 LLM 的訓練或微調過程中，我們的框架有效地複製了已建立的網路科學理論中的七個巨觀層級結構特徵，同時在具體評估指標上超越了現有的基準，圖表擴充任務提高了 31%。透過節點分類任務，我們驗證 GAG 有效地保留了生成文字豐富圖表中節點文字特徵的真實世界網路特徵。此外，透過結合並行加速，GAG 支援透過大規模 LLM 基於代理的模擬生成多達近 100,000 個節點或 1,000 萬條邊的圖表，速度提升至少 90.4%。原始碼可在 https://anonymous.4open.science/r/GraphAgent-2206 取得。

##### **A Mixed-Language Multi-Document News Summarization Dataset and a Graphs-Based Extract-Generate Model**
2410.09773v1 by Shengxiang Gao, Fang nan, Yongbing Zhang, Yuxin Huang, Kaiwen Tan, Zhengtao Yu

Existing research on news summarization primarily focuses on single-language
single-document (SLSD), single-language multi-document (SLMD) or cross-language
single-document (CLSD). However, in real-world scenarios, news about a
international event often involves multiple documents in different languages,
i.e., mixed-language multi-document (MLMD). Therefore, summarizing MLMD news is
of great significance. However, the lack of datasets for MLMD news
summarization has constrained the development of research in this area. To fill
this gap, we construct a mixed-language multi-document news summarization
dataset (MLMD-news), which contains four different languages and 10,992 source
document cluster and target summary pairs. Additionally, we propose a
graph-based extract-generate model and benchmark various methods on the
MLMD-news dataset and publicly release our dataset and
code\footnote[1]{https://github.com/Southnf9/MLMD-news}, aiming to advance
research in summarization within MLMD scenarios.

摘要：現有新聞摘要的研究主要集中在單語言單文件 (SLSD)、單語言多文件 (SLMD) 或跨語言單文件 (CLSD)。然而，在現實世界的場景中，國際事件的新聞通常涉及不同語言的多個文件，即混合語言多文件 (MLMD)。因此，對 MLMD 新聞進行摘要具有重大意義。然而，缺乏 MLMD 新聞摘要的數據集限制了這一領域的研究發展。為了填補這一空白，我們構建了一個混合語言多文件新聞摘要數據集 (MLMD-news)，其中包含四種不同的語言和 10,992 個源文件群集和目標摘要對。此外，我們提出了一個基於圖的提取生成模型，並在 MLMD-news 數據集上對各種方法進行了基準測試，並公開發布我們的數據集和代碼\footnote[1]{https://github.com/Southnf9/MLMD-news}，旨在推進 MLMD 場景中的摘要研究。

##### **Honest AI: Fine-Tuning "Small" Language Models to Say "I Don't Know", and Reducing Hallucination in RAG**
2410.09699v1 by Xinxi Chen, Li Wang, Wei Wu, Qi Tang, Yiyao Liu

Hallucination is a key roadblock for applications of Large Language Models
(LLMs), particularly for enterprise applications that are sensitive to
information accuracy. To address this issue, two general approaches have been
explored: Retrieval-Augmented Generation (RAG) to supply LLMs with updated
information as context, and fine-tuning the LLMs with new information and
desired output styles. In this paper, we propose Honest AI: a novel strategy to
fine-tune "small" language models to say "I don't know" to reduce
hallucination, along with several alternative RAG approaches. The solution
ranked 1st in Task 2 for the false premise question. The alternative approaches
include using RAG with search engine and knowledge graph results, fine-tuning
base LLMs with new information and combinations of both approaches. Although
all approaches improve the performance of the LLMs, RAG alone does not
significantly improve the performance and fine-tuning is needed for better
results. Finally, the hybrid approach achieved the highest score in the CRAG
benchmark. In addition, our approach emphasizes the use of relatively small
models with fewer than 10 billion parameters, promoting resource efficiency.

摘要：幻覺是大型語言模型 (LLM) 應用程式的一大障礙，特別是對資訊準確度敏感的企業應用程式。為了解決此問題，已探討兩種一般方法：檢索擴充生成 (RAG) 以提供 LLM 更新的資訊作為背景，以及微調 LLM 以獲得新的資訊和期望的輸出樣式。在本文中，我們提出 Honest AI：一種新穎的策略，微調「小型」語言模型以表達「我不知道」以減少幻覺，以及其他幾種替代的 RAG 方法。該解決方案在虛假前提問題的任務 2 中排名第 1。替代方法包括使用 RAG 搭配搜尋引擎和知識圖譜結果、微調基礎 LLM 以獲得新的資訊，以及結合這兩種方法。雖然所有方法都改善了 LLM 的效能，但僅使用 RAG 無法顯著改善效能，需要微調才能獲得更好的結果。最後，混合方法在 CRAG 基準測試中獲得最高分。此外，我們的做法強調使用參數少於 100 億的小型模型，以促進資源效率。

##### **LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning**
2410.09541v1 by Jiachun Li, Pengfei Cao, Chenhao Wang, Zhuoran Jin, Yubo Chen, Kang Liu, Xiaojian Jiang, Jiexin Xu, Jun Zhao

Large language models (LLMs) sometimes demonstrate poor performance on
knowledge-intensive tasks, commonsense reasoning is one of them. Researchers
typically address these issues by retrieving related knowledge from knowledge
graphs or employing self-enhancement methods to elicit knowledge in LLMs.
However, noisy knowledge and invalid reasoning issues hamper their ability to
answer questions accurately. To this end, we propose a novel method named
eliciting, filtering and integrating knowledge in large language model
(LINKED). In it, we design a reward model to filter out the noisy knowledge and
take the marginal consistent reasoning module to reduce invalid reasoning. With
our comprehensive experiments on two complex commonsense reasoning benchmarks,
our method outperforms SOTA baselines (up to 9.0% improvement of accuracy).
Besides, to measure the positive and negative impact of the injected knowledge,
we propose a new metric called effectiveness-preservation score for the
knowledge enhancement works. Finally, through extensive experiments, we conduct
an in-depth analysis and find many meaningful conclusions about LLMs in
commonsense reasoning tasks.

摘要：大型語言模型（LLM）有時在知識密集型任務上表現不佳，常識推理就是其中之一。研究人員通常通過從知識圖譜中檢索相關知識或採用自我增強方法來引發 LLM 中的知識來解決這些問題。然而，嘈雜的知識和無效的推理問題阻礙了它們準確回答問題的能力。為此，我們提出了一種名為大型語言模型中知識的引出、過濾和整合（LINKED）的新方法。在其中，我們設計了一個獎勵模型來過濾掉嘈雜的知識，並採用邊際一致推理模組來減少無效推理。通過我們在兩個複雜的常識推理基準上的全面實驗，我們的模型優於 SOTA 基準（準確率提高了 9.0%）。此外，為了衡量注入知識的正面和負面影響，我們提出了一種新的指標，稱為知識增強工作的有效性保留分數。最後，通過大量的實驗，我們進行了深入的分析，並在常識推理任務中發現了許多關於 LLM 的有意義的結論。

##### **Text Classification using Graph Convolutional Networks: A Comprehensive Survey**
2410.09399v1 by Syed Mustafa Haider Rizvi, Ramsha Imran, Arif Mahmood

Text classification is a quintessential and practical problem in natural
language processing with applications in diverse domains such as sentiment
analysis, fake news detection, medical diagnosis, and document classification.
A sizable body of recent works exists where researchers have studied and
tackled text classification from different angles with varying degrees of
success. Graph convolution network (GCN)-based approaches have gained a lot of
traction in this domain over the last decade with many implementations
achieving state-of-the-art performance in more recent literature and thus,
warranting the need for an updated survey. This work aims to summarize and
categorize various GCN-based Text Classification approaches with regard to the
architecture and mode of supervision. It identifies their strengths and
limitations and compares their performance on various benchmark datasets. We
also discuss future research directions and the challenges that exist in this
domain.

摘要：文本分類是自然語言處理中一個經典且實用的問題，在情緒分析、假新聞偵測、醫療診斷和文件分類等領域中都有應用。最近有大量的研究探討文本分類，並從不同的角度著手，獲得了不同程度的成功。圖形卷積網路 (GCN) 方法在過去十年中在這領域獲得了許多關注，許多實作在最近的文獻中達到了最先進的效能，因此有必要進行更新的調查。這項工作旨在針對架構和監督模式，總結和分類各種基於 GCN 的文本分類方法。它找出它們的優缺點，並比較它們在各種基準資料集上的效能。我們也討論了未來研究方向和這個領域中存在的挑戰。

##### **Generative Subgraph Retrieval for Knowledge Graph-Grounded Dialog Generation**
2410.09350v1 by Jinyoung Park, Minseok Joo, Joo-Kyung Kim, Hyunwoo J. Kim

Knowledge graph-grounded dialog generation requires retrieving a
dialog-relevant subgraph from the given knowledge base graph and integrating it
with the dialog history. Previous works typically represent the graph using an
external encoder, such as graph neural networks, and retrieve relevant triplets
based on the similarity between single-vector representations of triplets and
the dialog history. However, these external encoders fail to leverage the rich
knowledge of pretrained language models, and the retrieval process is also
suboptimal due to the information bottleneck caused by the single-vector
abstraction of the dialog history. In this work, we propose Dialog generation
with Generative Subgraph Retrieval (DialogGSR), which retrieves relevant
knowledge subgraphs by directly generating their token sequences on top of
language models. For effective generative subgraph retrieval, we introduce two
key methods: (i) structure-aware knowledge graph linearization with
self-supervised graph-specific tokens and (ii) graph-constrained decoding
utilizing graph structural proximity-based entity informativeness scores for
valid and relevant generative retrieval. DialogGSR achieves state-of-the-art
performance in knowledge graph-grounded dialog generation, as demonstrated on
OpenDialKG and KOMODIS datasets.

摘要：知識圖譜對話生成需要從給定的知識庫圖譜中擷取與對話相關的子圖，並將其與對話記錄整合。先前的研究通常使用外部編碼器（例如圖形神經網路）來表示圖形，並根據三元組的單向量表示與對話記錄之間的相似性來擷取相關的三元組。然而，這些外部編碼器無法利用預訓練語言模型的豐富知識，而擷取過程也因對話記錄的單向量抽象化造成的資訊瓶頸而次於最佳。在這項工作中，我們提出帶有生成子圖擷取的對話生成（DialogGSR），它直接在語言模型之上生成其標記序列來擷取相關的知識子圖。為了有效地生成子圖擷取，我們引入了兩種關鍵方法：（一）具有自我監督圖形特定標記的結構感知知識圖形線性化，以及（二）利用圖形結構鄰近度為基礎的實體資訊性分數進行圖形約束解碼，以進行有效且相關的生成性擷取。DialogGSR 在知識圖譜對話生成中實現了最先進的效能，如 OpenDialKG 和 KOMODIS 資料集所示。

##### **Natural Language Counterfactual Explanations for Graphs Using Large Language Models**
2410.09295v1 by Flavio Giorgi, Cesare Campagnano, Fabrizio Silvestri, Gabriele Tolomei

Explainable Artificial Intelligence (XAI) has emerged as a critical area of
research to unravel the opaque inner logic of (deep) machine learning models.
Among the various XAI techniques proposed in the literature, counterfactual
explanations stand out as one of the most promising approaches. However, these
``what-if'' explanations are frequently complex and technical, making them
difficult for non-experts to understand and, more broadly, challenging for
humans to interpret. To bridge this gap, in this work, we exploit the power of
open-source Large Language Models to generate natural language explanations
when prompted with valid counterfactual instances produced by state-of-the-art
explainers for graph-based models. Experiments across several graph datasets
and counterfactual explainers show that our approach effectively produces
accurate natural language representations of counterfactual instances, as
demonstrated by key performance metrics.

摘要：可解釋人工智慧 (XAI) 已成為研究領域中一個重要的領域，用以解開（深度）機器學習模型的內部邏輯。在文獻中提出的各種 XAI 技術中，反事實解釋被認為是最有前途的方法之一。然而，這些「假設性」解釋通常複雜且技術性，這使得非專家難以理解，更廣泛地說，人類難以解釋。為了彌合這個差距，在這項工作中，我們利用開源大型語言模型的力量，在提示由最先進的圖形模型解釋器產生的有效反事實實例時，產生自然語言解釋。跨越幾個圖形資料集和反事實解釋器的實驗表明，我們的做法有效地產生反事實實例的準確自然語言表示，這由關鍵效能指標所證明。

##### **ReasonPlanner: Enhancing Autonomous Planning in Dynamic Environments with Temporal Knowledge Graphs and LLMs**
2410.09252v1 by Minh Pham Dinh, Munira Syed, Michael G Yankoski, Trenton W. Ford

Planning and performing interactive tasks, such as conducting experiments to
determine the melting point of an unknown substance, is straightforward for
humans but poses significant challenges for autonomous agents. We introduce
ReasonPlanner, a novel generalist agent designed for reflective thinking,
planning, and interactive reasoning. This agent leverages LLMs to plan
hypothetical trajectories by building a World Model based on a Temporal
Knowledge Graph. The agent interacts with the environment using a natural
language actor-critic module, where the actor translates the imagined
trajectory into a sequence of actionable steps, and the critic determines if
replanning is necessary. ReasonPlanner significantly outperforms previous
state-of-the-art prompting-based methods on the ScienceWorld benchmark by more
than 1.8 times, while being more sample-efficient and interpretable. It relies
solely on frozen weights thus requiring no gradient updates. ReasonPlanner can
be deployed and utilized without specialized knowledge of Machine Learning,
making it accessible to a wide range of users.

摘要：規劃和執行互動任務，例如進行實驗以確定未知物質的熔點，對人類來說很簡單，但對自主代理來說卻構成重大挑戰。我們引入了 ReasonPlanner，這是一個新穎的通才代理，專門用於反思性思考、規劃和互動推理。此代理利用 LLM 透過建立基於時序知識圖表的 World Model 來規劃假設性軌跡。代理使用自然語言的動作-評論模組與環境互動，其中動作將想像的軌跡轉換為一系列可操作的步驟，而評論則確定是否需要重新規劃。ReasonPlanner 在 ScienceWorld 基準上大幅優於先前的最先進提示式方法，優於 1.8 倍，同時更具樣本效率和可解釋性。它僅依賴凍結權重，因此不需要梯度更新。ReasonPlanner 可以部署和使用，而無需機器學習的專業知識，讓廣泛的使用者都能使用。

##### **Towards Trustworthy Knowledge Graph Reasoning: An Uncertainty Aware Perspective**
2410.08985v1 by Bo Ni, Yu Wang, Lu Cheng, Erik Blasch, Tyler Derr

Recently, Knowledge Graphs (KGs) have been successfully coupled with Large
Language Models (LLMs) to mitigate their hallucinations and enhance their
reasoning capability, such as in KG-based retrieval-augmented frameworks.
However, current KG-LLM frameworks lack rigorous uncertainty estimation,
limiting their reliable deployment in high-stakes applications. Directly
incorporating uncertainty quantification into KG-LLM frameworks presents
challenges due to their complex architectures and the intricate interactions
between the knowledge graph and language model components. To address this gap,
we propose a new trustworthy KG-LLM framework, Uncertainty Aware
Knowledge-Graph Reasoning (UAG), which incorporates uncertainty quantification
into the KG-LLM framework. We design an uncertainty-aware multi-step reasoning
framework that leverages conformal prediction to provide a theoretical
guarantee on the prediction set. To manage the error rate of the multi-step
process, we additionally introduce an error rate control module to adjust the
error rate within the individual components. Extensive experiments show that
our proposed UAG can achieve any pre-defined coverage rate while reducing the
prediction set/interval size by 40% on average over the baselines.

摘要：最近，知识图谱 (KG) 已成功与大型语言模型 (LLM) 结合，以减轻其幻觉并增强其推理能力，例如基于 KG 的检索增强框架。
然而，当前的 KG-LLM 框架缺乏严格的不确定性估计，限制了它们在高风险应用程序中的可靠部署。由于其复杂的架构以及知识图谱与语言模型组件之间的复杂交互，将不确定性量化直接纳入 KG-LLM 框架提出了挑战。为了解决这一差距，我们提出了一种新的可信赖 KG-LLM 框架，即不确定性感知知识图推理 (UAG)，它将不确定性量化纳入 KG-LLM 框架。我们设计了一个不确定性感知多步骤推理框架，它利用共形预测为预测集提供理论保证。为了管理多步骤过程的错误率，我们另外引入了一个错误率控制模块，以调整各个组件内的错误率。大量实验表明，我们提出的 UAG 可以达到任何预定义的覆盖率，同时将预测集/区间大小平均减少 40%，高于基线。

##### **When Graph meets Multimodal: Benchmarking on Multimodal Attributed Graphs Learning**
2410.09132v1 by Hao Yan, Chaozhuo Li, Zhigang Yu, Jun Yin, Ruochen Liu, Peiyan Zhang, Weihao Han, Mingzheng Li, Zhengxin Zeng, Hao Sun, Weiwei Deng, Feng Sun, Qi Zhang, Senzhang Wang

Multimodal attributed graphs (MAGs) are prevalent in various real-world
scenarios and generally contain two kinds of knowledge: (a) Attribute knowledge
is mainly supported by the attributes of different modalities contained in
nodes (entities) themselves, such as texts and images. (b) Topology knowledge,
on the other hand, is provided by the complex interactions posed between nodes.
The cornerstone of MAG representation learning lies in the seamless integration
of multimodal attributes and topology. Recent advancements in Pre-trained
Language/Vision models (PLMs/PVMs) and Graph neural networks (GNNs) have
facilitated effective learning on MAGs, garnering increased research interest.
However, the absence of meaningful benchmark datasets and standardized
evaluation procedures for MAG representation learning has impeded progress in
this field. In this paper, we propose Multimodal Attribute Graph Benchmark
(MAGB)}, a comprehensive and diverse collection of challenging benchmark
datasets for MAGs. The MAGB datasets are notably large in scale and encompass a
wide range of domains, spanning from e-commerce networks to social networks. In
addition to the brand-new datasets, we conduct extensive benchmark experiments
over MAGB with various learning paradigms, ranging from GNN-based and PLM-based
methods, to explore the necessity and feasibility of integrating multimodal
attributes and graph topology. In a nutshell, we provide an overview of the MAG
datasets, standardized evaluation procedures, and present baseline experiments.
The entire MAGB project is publicly accessible at
https://github.com/sktsherlock/ATG.

摘要：<paragraph>多模態屬性圖 (MAG) 在各種真實世界的場景中很常見，通常包含兩種類型的知識：(a) 屬性知識主要由節點（實體）本身所包含的不同模態的屬性提供支援，例如文字和圖像。(b) 另一方面，拓撲知識則是由節點之間提出的複雜互動提供。MAG 表示式學習的基石在於多模態屬性和拓撲的無縫整合。預訓練語言/視覺模型 (PLM/PVM) 和圖形神經網路 (GNN) 的最新進展促進了對 MAG 的有效學習，引起了越來越多的研究興趣。然而，缺乏有意義的基準資料集和標準化的 MAG 表示式學習評估程序阻礙了該領域的進展。在本文中，我們提出了多模態屬性圖基準 (MAGB)，這是針對 MAG 的全面且多樣化的挑戰性基準資料集集合。MAGB 資料集的規模顯著龐大，涵蓋了從電子商務網路到社交網路的廣泛領域。除了全新的資料集外，我們還使用各種學習範例對 MAGB 進行了廣泛的基準實驗，從基於 GNN 和基於 PLM 的方法，以探索整合多模態屬性和圖形拓撲的必要性和可行性。簡而言之，我們提供了 MAG 資料集、標準化評估程序的概述，並提出了基準實驗。整個 MAGB 專案可在 https://github.com/sktsherlock/ATG 公開取得。</paragraph>

##### **GIVE: Structured Reasoning with Knowledge Graph Inspired Veracity Extrapolation**
2410.08475v1 by Jiashu He, Mingyu Derek Ma, Jinxuan Fan, Dan Roth, Wei Wang, Alejandro Ribeiro

Existing retrieval-based reasoning approaches for large language models
(LLMs) heavily rely on the density and quality of the non-parametric knowledge
source to provide domain knowledge and explicit reasoning chain. However,
inclusive knowledge sources are expensive and sometimes infeasible to build for
scientific or corner domains. To tackle the challenges, we introduce Graph
Inspired Veracity Extrapolation (GIVE), a novel reasoning framework that
integrates the parametric and non-parametric memories to enhance both knowledge
retrieval and faithful reasoning processes on very sparse knowledge graphs. By
leveraging the external structured knowledge to inspire LLM to model the
interconnections among relevant concepts, our method facilitates a more logical
and step-wise reasoning approach akin to experts' problem-solving, rather than
gold answer retrieval. Specifically, the framework prompts LLMs to decompose
the query into crucial concepts and attributes, construct entity groups with
relevant entities, and build an augmented reasoning chain by probing potential
relationships among node pairs across these entity groups. Our method
incorporates both factual and extrapolated linkages to enable comprehensive
understanding and response generation. Extensive experiments on
reasoning-intense benchmarks on biomedical and commonsense QA demonstrate the
effectiveness of our proposed method. Specifically, GIVE enables GPT3.5-turbo
to outperform advanced models like GPT4 without any additional training cost,
thereby underscoring the efficacy of integrating structured information and
internal reasoning ability of LLMs for tackling specialized tasks with limited
external resources.

摘要：現有的基於檢索的推理方法對於大型語言模型 (LLM) 嚴重依賴非參數知識來源的密度和品質，以提供領域知識和明確的推理鏈。然而，包容性的知識來源很昂貴，有時對於科學或角落領域來說，建立起來也不可行。為了應對這些挑戰，我們引入了圖形啟發真實推斷 (GIVE)，這是一個新穎的推理架構，它整合了參數和非參數記憶體，以增強在非常稀疏的知識圖譜上進行知識檢索和忠實推理過程。透過利用外部結構化知識來激勵 LLM 模擬相關概念之間的相互關聯，我們的技術促進了一種更合乎邏輯且循序漸進的推理方法，類似於專家的問題解決，而不是黃金答案檢索。具體來說，該架構提示 LLM 將查詢分解為關鍵概念和屬性，使用相關實體建構實體群組，並透過探查這些實體群組中節點對之間的潛在關係來建立增強的推理鏈。我們的技術結合了事實和外推關聯，以實現全面的理解和回應產生。在生物醫學和常識問答上對推理密集基準進行的廣泛實驗證明了我們提出的方法的有效性。具體來說，GIVE 使 GPT3.5-turbo 能夠在沒有任何額外訓練成本的情況下優於 GPT4 等進階模型，從而強調了整合結構化資訊和 LLM 內部推理能力對於處理具有有限外部資源的專業任務的效能。

##### **Privately Learning from Graphs with Applications in Fine-tuning Large Language Models**
2410.08299v1 by Haoteng Yin, Rongzhe Wei, Eli Chien, Pan Li

Graphs offer unique insights into relationships and interactions between
entities, complementing data modalities like text, images, and videos. By
incorporating relational information from graph data, AI models can extend
their capabilities beyond traditional tasks. However, relational data in
sensitive domains such as finance and healthcare often contain private
information, making privacy preservation crucial. Existing privacy-preserving
methods, such as DP-SGD, which rely on gradient decoupling assumptions, are not
well-suited for relational learning due to the inherent dependencies between
coupled training samples. To address this challenge, we propose a
privacy-preserving relational learning pipeline that decouples dependencies in
sampled relations during training, ensuring differential privacy through a
tailored application of DP-SGD. We apply this method to fine-tune large
language models (LLMs) on sensitive graph data, and tackle the associated
computational complexities. Our approach is evaluated on LLMs of varying sizes
(e.g., BERT, Llama2) using real-world relational data from four text-attributed
graphs. The results demonstrate significant improvements in relational learning
tasks, all while maintaining robust privacy guarantees during training.
Additionally, we explore the trade-offs between privacy, utility, and
computational efficiency, offering insights into the practical deployment of
our approach. Code is available at https://github.com/Graph-COM/PvGaLM.

摘要：圖表提供關於實體之間關係和互動的獨特見解，補充了文本、影像和影片等資料模式。透過納入來自圖表資料的關係資訊，AI 模型可以將其功能延伸到傳統任務之外。然而，敏感領域（例如金融和醫療保健）中的關係資料通常包含私人資訊，因此隱私保護至關重要。現有的隱私保護方法（例如 DP-SGD），依賴於梯度解耦假設，由於耦合訓練樣本之間的內在依賴性，並不適合關係學習。為了應對這個挑戰，我們提出一個隱私保護關係學習管道，在訓練期間解耦取樣關係中的依賴性，透過客製化應用 DP-SGD 來確保差異隱私。我們將此方法應用於敏感圖表資料上微調大型語言模型 (LLM)，並解決相關的計算複雜性。我們的方法在不同大小的 LLM（例如 BERT、Llama2）上進行評估，使用來自四個文字屬性圖表的真實世界關係資料。結果證明關係學習任務有顯著的進步，同時在訓練期間維持強大的隱私保證。此外，我們探討隱私、效用和計算效率之間的權衡，提供對我們方法實際部署的見解。程式碼可在 https://github.com/Graph-COM/PvGaLM 取得。

##### **Can Knowledge Graphs Make Large Language Models More Trustworthy? An Empirical Study over Open-ended Question Answering**
2410.08085v1 by Yuan Sui, Bryan Hooi

Recent works integrating Knowledge Graphs (KGs) have led to promising
improvements in enhancing reasoning accuracy of Large Language Models (LLMs).
However, current benchmarks mainly focus on closed tasks, leaving a gap in the
assessment of more complex, real-world scenarios. This gap has also obscured
the evaluation of KGs' potential to mitigate the problem of hallucination in
LLMs. To fill the gap, we introduce OKGQA, a new benchmark specifically
designed to assess LLMs enhanced with KGs under open-ended, real-world question
answering scenarios. OKGQA is designed to closely reflect the complexities of
practical applications using questions from different types, and incorporates
specific metrics to measure both the reduction in hallucinations and the
enhancement in reasoning capabilities. To consider the scenario in which KGs
may have varying levels of mistakes, we further propose another experiment
setting OKGQA-P to assess model performance when the semantics and structure of
KGs are deliberately perturbed and contaminated. OKGQA aims to (1) explore
whether KGs can make LLMs more trustworthy in an open-ended setting, and (2)
conduct a comparative analysis to shed light on methods and future directions
for leveraging KGs to reduce LLMs' hallucination. We believe that this study
can facilitate a more complete performance comparison and encourage continuous
improvement in integrating KGs with LLMs.

摘要：近期的知识图谱 (KG) 整合研究，已提升大型语言模型 (LLM) 推理准确度的表现。
然而，现有的基准测试主要着重于封闭式任务，在评估更复杂、更实际的场景时存在缺口。此缺口也模糊了知识图谱在减轻 LLM 幻觉问题上的潜力评估。为了填补此缺口，我们引入了 OKGQA，这是一个专门设计用来评估在开放式、实际问答场景中，增强了知识图谱的 LLM 的新基准测试。OKGQA 旨在紧密反映实际应用中的复杂性，使用不同类型的题目，并纳入特定指标来衡量幻觉的减少和推理能力的增强。为了考虑知识图谱可能存在不同程度错误的场景，我们进一步提出了另一个实验设置 OKGQA-P，以评估当知识图谱的语义和结构被故意扰动和污染时的模型性能。OKGQA 旨在 (1) 探索知识图谱是否能使 LLM 在开放式设置中更值得信赖，以及 (2) 进行比较分析，以阐明利用知识图谱来减少 LLM 幻觉的方法和未来方向。我们相信这项研究可以促进更完整的性能比较，并鼓励持续改进知识图谱与 LLM 的整合。

##### **Disease Entity Recognition and Normalization is Improved with Large Language Model Derived Synthetic Normalized Mentions**
2410.07951v1 by Kuleen Sasse, Shinjitha Vadlakonda, Richard E. Kennedy, John D. Osborne

Background: Machine learning methods for clinical named entity recognition
and entity normalization systems can utilize both labeled corpora and Knowledge
Graphs (KGs) for learning. However, infrequently occurring concepts may have
few mentions in training corpora and lack detailed descriptions or synonyms,
even in large KGs. For Disease Entity Recognition (DER) and Disease Entity
Normalization (DEN), this can result in fewer high quality training examples
relative to the number of known diseases. Large Language Model (LLM) generation
of synthetic training examples could improve performance in these information
extraction tasks.
  Methods: We fine-tuned a LLaMa-2 13B Chat LLM to generate a synthetic corpus
containing normalized mentions of concepts from the Unified Medical Language
System (UMLS) Disease Semantic Group. We measured overall and Out of
Distribution (OOD) performance for DER and DEN, with and without synthetic data
augmentation. We evaluated performance on 3 different disease corpora using 4
different data augmentation strategies, assessed using BioBERT for DER and
SapBERT and KrissBERT for DEN.
  Results: Our synthetic data yielded a substantial improvement for DEN, in all
3 training corpora the top 1 accuracy of both SapBERT and KrissBERT improved by
3-9 points in overall performance and by 20-55 points in OOD data. A small
improvement (1-2 points) was also seen for DER in overall performance, but only
one dataset showed OOD improvement.
  Conclusion: LLM generation of normalized disease mentions can improve DEN
relative to normalization approaches that do not utilize LLMs to augment data
with synthetic mentions. Ablation studies indicate that performance gains for
DEN were only partially attributable to improvements in OOD performance. The
same approach has only a limited ability to improve DER. We make our software
and dataset publicly available.

摘要：<paragraph>背景：臨床命名實體識別的機器學習方法和實體正規化系統可以利用標記語料庫和知識圖譜 (KG) 來學習。然而，在訓練語料庫中很少出現的概念可能只有少數提及，即使在大型知識圖譜中也缺乏詳細的描述或同義詞。對於疾病實體識別 (DER) 和疾病實體正規化 (DEN)，相對於已知疾病的數量，這可能會導致較少的高品質訓練範例。大型語言模型 (LLM) 生成的合成訓練範例可以提升這些資訊擷取任務的效能。
方法：我們微調了一個 LLaMa-2 13B 聊天 LLM，以產生一個合成語料庫，其中包含來自統一醫學語言系統 (UMLS) 疾病語義群的標準化概念提及。我們衡量了 DER 和 DEN 的整體和分布外 (OOD) 效能，有和沒有合成資料擴充。我們使用 4 種不同的資料擴充策略評估了 3 個不同疾病語料庫的效能，使用 BioBERT 評估 DER，使用 SapBERT 和 KrissBERT 評估 DEN。
結果：我們的合成資料對 DEN 產生了顯著的改善，在所有 3 個訓練語料庫中，SapBERT 和 KrissBERT 的前 1 名準確率在整體效能上提高了 3-9 個百分點，在 OOD 資料中提高了 20-55 個百分點。在 DER 的整體效能上也看到了微小的改善（1-2 個百分點），但只有一組資料顯示出 OOD 改善。
結論：與不利用 LLM 擴充資料以合成提及的正規化方法相比，LLM 生成的標準化疾病提及可以改善 DEN。消融研究表明，DEN 的效能提升僅部分歸因於 OOD 效能的改善。相同的方法對於改善 DER 的能力有限。我們公開我們的軟體和資料集。</paragraph>

##### **Benchmarking Agentic Workflow Generation**
2410.07869v1 by Shuofei Qiao, Runnan Fang, Zhisong Qiu, Xiaobin Wang, Ningyu Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen

Large Language Models (LLMs), with their exceptional ability to handle a wide
range of tasks, have driven significant advancements in tackling reasoning and
planning tasks, wherein decomposing complex problems into executable workflows
is a crucial step in this process. Existing workflow evaluation frameworks
either focus solely on holistic performance or suffer from limitations such as
restricted scenario coverage, simplistic workflow structures, and lax
evaluation standards. To this end, we introduce WorFBench, a unified workflow
generation benchmark with multi-faceted scenarios and intricate graph workflow
structures. Additionally, we present WorFEval, a systemic evaluation protocol
utilizing subsequence and subgraph matching algorithms to accurately quantify
the LLM agent's workflow generation capabilities. Through comprehensive
evaluations across different types of LLMs, we discover distinct gaps between
the sequence planning capabilities and graph planning capabilities of LLM
agents, with even GPT-4 exhibiting a gap of around 15%. We also train two
open-source models and evaluate their generalization abilities on held-out
tasks. Furthermore, we observe that the generated workflows can enhance
downstream tasks, enabling them to achieve superior performance with less time
during inference. Code and dataset will be available at
https://github.com/zjunlp/WorFBench.

摘要：大型語言模型 (LLM) 擁有處理各種任務的非凡能力，推動了解決推理和規劃任務的顯著進展，其中將複雜問題分解為可執行工作流程是此過程中至關重要的一步。現有的工作流程評估框架只專注於整體效能，或受到情境涵蓋範圍受限、工作流程結構簡化和評估標準寬鬆等限制。為此，我們引入了 WorFBench，一個統一的工作流程生成基準，具有多方面的場景和複雜的圖形工作流程結構。此外，我們提出了 WorFEval，一個利用子序列和子圖匹配演算法來準確量化 LLM 代理工作流程生成能力的系統性評估協定。透過對不同類型 LLM 的全面評估，我們發現 LLM 代理的序列規劃能力和圖形規劃能力之間存在明顯的差距，即使是 GPT-4 也表現出約 15% 的差距。我們還訓練了兩個開源模型，並評估了它們在保留任務上的泛化能力。此外，我們觀察到生成的的工作流程可以增強下游任務，讓它們在推理期間以更少的時間獲得更好的效能。程式碼和資料集將在 https://github.com/zjunlp/WorFBench 上提供。

##### **KRAG Framework for Enhancing LLMs in the Legal Domain**
2410.07551v1 by Nguyen Ha Thanh, Ken Satoh

This paper introduces Knowledge Representation Augmented Generation (KRAG), a
novel framework designed to enhance the capabilities of Large Language Models
(LLMs) within domain-specific applications. KRAG points to the strategic
inclusion of critical knowledge entities and relationships that are typically
absent in standard data sets and which LLMs do not inherently learn. In the
context of legal applications, we present Soft PROLEG, an implementation model
under KRAG, which uses inference graphs to aid LLMs in delivering structured
legal reasoning, argumentation, and explanations tailored to user inquiries.
The integration of KRAG, either as a standalone framework or in tandem with
retrieval augmented generation (RAG), markedly improves the ability of language
models to navigate and solve the intricate challenges posed by legal texts and
terminologies. This paper details KRAG's methodology, its implementation
through Soft PROLEG, and potential broader applications, underscoring its
significant role in advancing natural language understanding and processing in
specialized knowledge domains.

摘要：本文介紹知識表徵增強生成 (KRAG)，一個新穎的架構，旨在增強大型語言模型 (LLM) 在特定領域應用中的能力。KRAG 指出策略性地納入關鍵知識實體和關係，這些實體和關係通常不存在於標準資料集中，而 LLM 也無法固有地學習。在法律應用方面，我們提出 Soft PROLEG，這是一個在 KRAG 下的實作模型，它使用推理圖來協助 LLM 提供結構化的法律推理、論證和解釋，以滿足使用者的詢問。整合 KRAG，無論是作為獨立架構或與檢索增強生成 (RAG) 結合使用，都能顯著提升語言模型導航和解決法律文本和術語所帶來的複雜挑戰的能力。本文詳述 KRAG 的方法論、透過 Soft PROLEG 的實作，以及潛在的更廣泛應用，強調其在推進專業知識領域的自然語言理解和處理中扮演的重要角色。

##### **MKGL: Mastery of a Three-Word Language**
2410.07526v1 by Lingbing Guo, Zhongpu Bo, Zhuo Chen, Yichi Zhang, Jiaoyan Chen, Yarong Lan, Mengshu Sun, Zhiqiang Zhang, Yangyifei Luo, Qian Li, Qiang Zhang, Wen Zhang, Huajun Chen

Large language models (LLMs) have significantly advanced performance across a
spectrum of natural language processing (NLP) tasks. Yet, their application to
knowledge graphs (KGs), which describe facts in the form of triplets and allow
minimal hallucinations, remains an underexplored frontier. In this paper, we
investigate the integration of LLMs with KGs by introducing a specialized KG
Language (KGL), where a sentence precisely consists of an entity noun, a
relation verb, and ends with another entity noun. Despite KGL's unfamiliar
vocabulary to the LLM, we facilitate its learning through a tailored dictionary
and illustrative sentences, and enhance context understanding via real-time KG
context retrieval and KGL token embedding augmentation. Our results reveal that
LLMs can achieve fluency in KGL, drastically reducing errors compared to
conventional KG embedding methods on KG completion. Furthermore, our enhanced
LLM shows exceptional competence in generating accurate three-word sentences
from an initial entity and interpreting new unseen terms out of KGs.

摘要：大型語言模型 (LLM) 已大幅提升各種自然語言處理 (NLP) 任務的效能。然而，它們在知識圖譜 (KG) 的應用上仍有待開發，知識圖譜以三元組形式描述事實，並允許最小的幻覺。在本文中，我們透過引入一種專業的 KG 語言 (KGL) 來探討 LLM 與 KG 的整合，其中一個句子精確地包含一個實體名詞、一個關係動詞，並以另一個實體名詞結尾。儘管 LLM 對 KGL 的詞彙不熟悉，但我們透過量身打造的字典和說明性句子來促進它的學習，並透過即時 KG 背景擷取和 KGL 代幣嵌入強化來提升背景理解。我們的結果顯示，LLM 能夠流暢使用 KGL，大幅減少錯誤，優於 KG 完成中傳統的 KG 嵌入方法。此外，我們增強的 LLM 在從初始實體生成準確的三字詞句子，以及從 KG 解釋新的未見術語方面展現出卓越的能力。

##### **InstructG2I: Synthesizing Images from Multimodal Attributed Graphs**
2410.07157v1 by Bowen Jin, Ziqi Pang, Bingjun Guo, Yu-Xiong Wang, Jiaxuan You, Jiawei Han

In this paper, we approach an overlooked yet critical task Graph2Image:
generating images from multimodal attributed graphs (MMAGs). This task poses
significant challenges due to the explosion in graph size, dependencies among
graph entities, and the need for controllability in graph conditions. To
address these challenges, we propose a graph context-conditioned diffusion
model called InstructG2I. InstructG2I first exploits the graph structure and
multimodal information to conduct informative neighbor sampling by combining
personalized page rank and re-ranking based on vision-language features. Then,
a Graph-QFormer encoder adaptively encodes the graph nodes into an auxiliary
set of graph prompts to guide the denoising process of diffusion. Finally, we
propose graph classifier-free guidance, enabling controllable generation by
varying the strength of graph guidance and multiple connected edges to a node.
Extensive experiments conducted on three datasets from different domains
demonstrate the effectiveness and controllability of our approach. The code is
available at https://github.com/PeterGriffinJin/InstructG2I.

摘要：在本文中，我们探讨一项被忽视但至关重要的任务 Graph2Image：
从多模态属性图 (MMAG) 生成图像。由于图大小激增、图实体之间的依赖关系以及对图条件的可控性需求，此任务带来了重大挑战。为了应对这些挑战，我们提出了一种称为 InstructG2I 的图上下文条件扩散模型。InstructG2I 首先利用图结构和多模态信息，通过结合个性化页面排名和基于视觉语言特征的重新排名来执行信息丰富的邻居采样。然后，Graph-QFormer 编码器将图节点自适应地编码为一组辅助图提示，以指导扩散的去噪过程。最后，我们提出了无图分类器指导，通过改变图指导的强度和与节点的多个连接边来实现可控生成。在来自不同领域的三组数据集上进行的广泛实验证明了我们方法的有效性和可控性。代码可在 https://github.com/PeterGriffinJin/InstructG2I 获得。

##### **CSSL: Contrastive Self-Supervised Learning for Dependency Parsing on Relatively Free Word Ordered and Morphologically Rich Low Resource Languages**
2410.06944v1 by Pretam Ray, Jivnesh Sandhan, Amrith Krishna, Pawan Goyal

Neural dependency parsing has achieved remarkable performance for low
resource morphologically rich languages. It has also been well-studied that
morphologically rich languages exhibit relatively free word order. This prompts
a fundamental investigation: Is there a way to enhance dependency parsing
performance, making the model robust to word order variations utilizing the
relatively free word order nature of morphologically rich languages? In this
work, we examine the robustness of graph-based parsing architectures on 7
relatively free word order languages. We focus on scrutinizing essential
modifications such as data augmentation and the removal of position encoding
required to adapt these architectures accordingly. To this end, we propose a
contrastive self-supervised learning method to make the model robust to word
order variations. Furthermore, our proposed modification demonstrates a
substantial average gain of 3.03/2.95 points in 7 relatively free word order
languages, as measured by the UAS/LAS Score metric when compared to the best
performing baseline.

摘要：神經依賴解析對於資源較少的形態豐富語言已達到顯著的效能。形態豐富語言展現相對自由的語序，這點也已獲得深入探討。這引發了一項基礎調查：是否有方法可以提升依賴解析效能，讓模型能透過運用形態豐富語言相對自由的語序特質，對語序變化具有穩健性？在這項工作中，我們檢視了 7 種相對自由語序語言中基於圖表的解析架構的穩健性。我們專注於審視必要的修改，例如資料擴充和移除位置編碼，以適當地調整這些架構。為此，我們提出對比自我監督學習方法，讓模型對語序變化具有穩健性。此外，我們提出的修改在 7 種相對自由語序語言中展現了 3.03/2.95 點的顯著平均增益，這是根據 UAS/LAS 分數指標，與效能最佳的基準線進行比較後得出的結果。

##### **Tree of Problems: Improving structured problem solving with compositionality**
2410.06634v1 by Armel Zebaze, Benoît Sagot, Rachel Bawden

Large Language Models (LLMs) have demonstrated remarkable performance across
multiple tasks through in-context learning. For complex reasoning tasks that
require step-by-step thinking, Chain-of-Thought (CoT) prompting has given
impressive results, especially when combined with self-consistency.
Nonetheless, some tasks remain particularly difficult for LLMs to solve. Tree
of Thoughts (ToT) and Graph of Thoughts (GoT) emerged as alternatives, dividing
the complex problem into paths of subproblems. In this paper, we propose Tree
of Problems (ToP), a simpler version of ToT, which we hypothesise can work
better for complex tasks that can be divided into identical subtasks. Our
empirical results show that our approach outperforms ToT and GoT, and in
addition performs better than CoT on complex reasoning tasks. All code for this
paper is publicly available here:
https://github.com/ArmelRandy/tree-of-problems.

摘要：大型语言模型 (LLM) 已通过情境学习在多项任务中展示出非凡的性能。对于需要循序渐进思考的复杂推理任务，思维链 (CoT) 提示已取得令人印象深刻的结果，尤其是在与自洽性相结合时。尽管如此，LLM 仍然难以解决某些任务。思维树 (ToT) 和思维图 (GoT) 作为替代方案出现，将复杂问题划分为子问题的路径。在本文中，我们提出了思维树 (ToP)，它是 ToT 的一个更简单的版本，我们假设它可以更好地适用于可以划分为相同子任务的复杂任务。我们的实证结果表明，我们的方法优于 ToT 和 GoT，并且在复杂推理任务上的表现也优于 CoT。本文的所有代码在此公开提供：
https://github.com/ArmelRandy/tree-of-problems。

##### **Multi-Task Program Error Repair and Explanatory Diagnosis**
2410.07271v1 by Zhenyu Xu, Victor S. Sheng

Program errors can occur in any type of programming, and can manifest in a
variety of ways, such as unexpected output, crashes, or performance issues. And
program error diagnosis can often be too abstract or technical for developers
to understand, especially for beginners. The goal of this paper is to present a
novel machine-learning approach for Multi-task Program Error Repair and
Explanatory Diagnosis (mPRED). A pre-trained language model is used to encode
the source code, and a downstream model is specifically designed to identify
and repair errors. Programs and test cases will be augmented and optimized from
several perspectives. Additionally, our approach incorporates a "chain of
thoughts" method, which enables the models to produce intermediate reasoning
explanations before providing the final correction. To aid in visualizing and
analyzing the program structure, we use a graph neural network for program
structure visualization. Overall, our approach offers a promising approach for
repairing program errors across different programming languages and providing
helpful explanations to programmers.

摘要：程式錯誤可能發生在任何類型的程式設計中，並可能以各種方式呈現，例如意外輸出、當機或效能問題。程式錯誤診斷通常對開發人員來說過於抽象或技術性，特別是對於初學者而言。本文的目的是提出一個新穎的多任務程式錯誤修復與解釋性診斷 (mPRED) 機器學習方法。預先訓練的語言模型用於編碼原始碼，而下游模型則專門設計用於識別和修復錯誤。程式和測試案例將從多個角度進行擴充和最佳化。此外，我們的做法包含「思考鏈」方法，使模型能夠在提供最終修正之前產生中間推理說明。為了幫助視覺化和分析程式結構，我們使用圖形神經網路進行程式結構視覺化。總的來說，我們的做法提供了一個有前景的方法，可以用於修復不同程式語言中的程式錯誤，並向程式設計師提供有用的說明。

##### **Counterfactual Causal Inference in Natural Language with Large Language Models**
2410.06392v1 by Gaël Gendron, Jože M. Rožanec, Michael Witbrock, Gillian Dobbie

Causal structure discovery methods are commonly applied to structured data
where the causal variables are known and where statistical testing can be used
to assess the causal relationships. By contrast, recovering a causal structure
from unstructured natural language data such as news articles contains numerous
challenges due to the absence of known variables or counterfactual data to
estimate the causal links. Large Language Models (LLMs) have shown promising
results in this direction but also exhibit limitations. This work investigates
LLM's abilities to build causal graphs from text documents and perform
counterfactual causal inference. We propose an end-to-end causal structure
discovery and causal inference method from natural language: we first use an
LLM to extract the instantiated causal variables from text data and build a
causal graph. We merge causal graphs from multiple data sources to represent
the most exhaustive set of causes possible. We then conduct counterfactual
inference on the estimated graph. The causal graph conditioning allows
reduction of LLM biases and better represents the causal estimands. We use our
method to show that the limitations of LLMs in counterfactual causal reasoning
come from prediction errors and propose directions to mitigate them. We
demonstrate the applicability of our method on real-world news articles.

摘要：因果结构发现方法通常应用于结构化数据，其中因果变量是已知的，并且可以使用统计检验来评估因果关系。相比之下，从新闻文章等非结构化的自然语言数据中恢复因果结构由于缺少已知变量或反事实数据来估计因果关系而包含众多挑战。大型语言模型 (LLM) 在这个方向上显示出有希望的结果，但也表现出局限性。这项工作调查了 LLM 从文本文档构建因果图和执行反事实因果推理的能力。我们提出了一种从自然语言中进行端到端因果结构发现和因果推理的方法：我们首先使用 LLM 从文本数据中提取实例化的因果变量并构建因果图。我们合并来自多个数据源的因果图，以表示可能的最详尽的因果集。然后，我们对估计图进行反事实推理。因果图条件允许减少 LLM 偏差并更好地表示因果估计量。我们使用我们的方法表明 LLM 在反事实因果推理中的局限性来自预测误差，并提出减轻它们的措施。我们在现实世界的新闻文章中展示了我们方法的适用性。

##### **Less is More: Making Smaller Language Models Competent Subgraph Retrievers for Multi-hop KGQA**
2410.06121v1 by Wenyu Huang, Guancheng Zhou, Hongru Wang, Pavlos Vougiouklis, Mirella Lapata, Jeff Z. Pan

Retrieval-Augmented Generation (RAG) is widely used to inject external
non-parametric knowledge into large language models (LLMs). Recent works
suggest that Knowledge Graphs (KGs) contain valuable external knowledge for
LLMs. Retrieving information from KGs differs from extracting it from document
sets. Most existing approaches seek to directly retrieve relevant subgraphs,
thereby eliminating the need for extensive SPARQL annotations, traditionally
required by semantic parsing methods. In this paper, we model the subgraph
retrieval task as a conditional generation task handled by small language
models. Specifically, we define a subgraph identifier as a sequence of
relations, each represented as a special token stored in the language models.
Our base generative subgraph retrieval model, consisting of only 220M
parameters, achieves competitive retrieval performance compared to
state-of-the-art models relying on 7B parameters, demonstrating that small
language models are capable of performing the subgraph retrieval task.
Furthermore, our largest 3B model, when plugged with an LLM reader, sets new
SOTA end-to-end performance on both the WebQSP and CWQ benchmarks. Our model
and data will be made available online: https://github.com/hwy9855/GSR.

摘要：檢索增強生成 (RAG) 廣泛用於將外部非參數知識注入大型語言模型 (LLM)。最近的研究表明，知識圖 (KG) 包含對 LLM 有價值的外部知識。從 KG 中擷取資訊與從文件集中擷取資訊不同。大多數現有方法尋求直接擷取相關子圖，從而消除了對語義解析方法傳統上所需的廣泛 SPARQL 註解的需求。在本文中，我們將子圖擷取任務建模為由小型語言模型處理的條件生成任務。具體來說，我們將子圖識別符定義為關係序列，每個關係都表示為儲存在語言模型中的特殊標記。我們的基礎生成式子圖擷取模型僅包含 220M 參數，與依賴 7B 參數的最新模型相比，達到了具有競爭力的擷取效能，證明小型語言模型能夠執行子圖擷取任務。此外，當我們最大的 3B 模型與 LLM 閱讀器結合使用時，在 WebQSP 和 CWQ 基準上設定了新的端到端效能 SOTA。我們的模型和資料將在線上公開：https://github.com/hwy9855/GSR。

##### **LLM-based SPARQL Query Generation from Natural Language over Federated Knowledge Graphs**
2410.06062v2 by Vincent Emonet, Jerven Bolleman, Severine Duvaud, Tarcisio Mendes de Farias, Ana Claudia Sima

We introduce a Retrieval-Augmented Generation (RAG) system for translating
user questions into accurate federated SPARQL queries over bioinformatics
knowledge graphs (KGs) leveraging Large Language Models (LLMs). To enhance
accuracy and reduce hallucinations in query generation, our system utilises
metadata from the KGs, including query examples and schema information, and
incorporates a validation step to correct generated queries. The system is
available online at chat.expasy.org.

摘要：我們引入檢索增強生成 (RAG) 系統，用於將使用者問題翻譯成準確的聯合 SPARQL 查詢，以利用大型語言模型 (LLM) 進行生物資訊學知識圖 (KG)。為了增強準確性並減少查詢生成中的幻覺，我們的系統利用來自 KG 的元資料，包括查詢範例和架構資訊，並結合驗證步驟來修正已生成的查詢。該系統可在 chat.expasy.org 上線使用。

##### **Jet Expansions of Residual Computation**
2410.06024v1 by Yihong Chen, Xiangxiang Xu, Yao Lu, Pontus Stenetorp, Luca Franceschi

We introduce a framework for expanding residual computational graphs using
jets, operators that generalize truncated Taylor series. Our method provides a
systematic approach to disentangle contributions of different computational
paths to model predictions. In contrast to existing techniques such as
distillation, probing, or early decoding, our expansions rely solely on the
model itself and requires no data, training, or sampling from the model. We
demonstrate how our framework grounds and subsumes logit lens, reveals a
(super-)exponential path structure in the recursive residual depth and opens up
several applications. These include sketching a transformer large language
model with $n$-gram statistics extracted from its computations, and indexing
the models' levels of toxicity knowledge. Our approach enables data-free
analysis of residual computation for model interpretability, development, and
evaluation.

摘要：我們引入了一個框架，用噴射流擴展殘差計算圖，噴射流是一種將截斷的泰勒級數泛化的運算子。我們的這個方法提供了一個系統化的途徑，用來解開不同計算路徑對模型預測的貢獻。與現有的技術（例如蒸餾、探測或早期解碼）相反，我們的擴展僅依賴於模型本身，不需要從模型中獲取數據、訓練或取樣。我們展示了我們的框架如何奠定和概括邏輯透鏡，揭示了遞歸殘差深度中的（超）指數路徑結構，並打開了幾個應用。這些應用包括用從其計算中提取的 n-gram 統計數據繪製一個Transformer大型語言模型，並索引模型的毒性知識級別。我們的這種方法能夠對殘差計算進行無數據分析，用於模型的可解釋性、開發和評估。

##### **A large collection of bioinformatics question-query pairs over federated knowledge graphs: methodology and applications**
2410.06010v1 by Jerven Bolleman, Vincent Emonet, Adrian Altenhoff, Amos Bairoch, Marie-Claude Blatter, Alan Bridge, Severine Duvaud, Elisabeth Gasteiger, Dmitry Kuznetsov, Sebastien Moretti, Pierre-Andre Michel, Anne Morgat, Marco Pagni, Nicole Redaschi, Monique Zahn-Zabal, Tarcisio Mendes de Farias, Ana Claudia Sima

Background. In the last decades, several life science resources have
structured data using the same framework and made these accessible using the
same query language to facilitate interoperability. Knowledge graphs have seen
increased adoption in bioinformatics due to their advantages for representing
data in a generic graph format. For example, yummydata.org catalogs more than
60 knowledge graphs accessible through SPARQL, a technical query language.
Although SPARQL allows powerful, expressive queries, even across physically
distributed knowledge graphs, formulating such queries is a challenge for most
users. Therefore, to guide users in retrieving the relevant data, many of these
resources provide representative examples. These examples can also be an
important source of information for machine learning, if a sufficiently large
number of examples are provided and published in a common, machine-readable and
standardized format across different resources.
  Findings. We introduce a large collection of human-written natural language
questions and their corresponding SPARQL queries over federated bioinformatics
knowledge graphs (KGs) collected for several years across different research
groups at the SIB Swiss Institute of Bioinformatics. The collection comprises
more than 1000 example questions and queries, including 65 federated queries.
We propose a methodology to uniformly represent the examples with minimal
metadata, based on existing standards. Furthermore, we introduce an extensive
set of open-source applications, including query graph visualizations and smart
query editors, easily reusable by KG maintainers who adopt the proposed
methodology.
  Conclusions. We encourage the community to adopt and extend the proposed
methodology, towards richer KG metadata and improved Semantic Web services.

摘要：<paragraph>背景。在過去幾十年，許多生命科學資源使用相同的架構來建構資料，並使用相同的查詢語言來存取這些資料，以促進互操作性。知識圖譜由於其以通用圖形格式表示資料的優點，因此在生物資訊學中獲得了越來越廣泛的採用。例如，yummydata.org 編錄了超過 60 個可透過技術查詢語言 SPARQL 存取的知識圖譜。儘管 SPARQL 允許進行強大且具表達力的查詢，甚至跨越實體分布的知識圖譜，但對大多數使用者來說，制定此類查詢是一項挑戰。因此，為了指導使用者擷取相關資料，其中許多資源提供了具代表性的範例。如果提供了足夠大量的範例，並以跨不同資源的通用、機器可讀且標準化的格式發布，這些範例也可以成為機器學習的重要資訊來源。
  發現。我們引入了大量由人類撰寫的自然語言問題及其對應的 SPARQL 查詢，這些查詢是多年來在 SIB 瑞士生物資訊學研究所的不同研究小組中收集的，涵蓋了聯邦生物資訊學知識圖譜 (KG)。該集合包含 1000 多個範例問題和查詢，包括 65 個聯邦查詢。我們提出了一種方法，基於現有標準，以最少的元資料統一表示這些範例。此外，我們還引入了一套廣泛的開源應用程式，包括查詢圖形視覺化和智慧查詢編輯器，這些應用程式很容易被採用所提出方法的 KG 維護人員重複使用。
  結論。我們鼓勵社群採用並擴充所提出的方法，以獲得更豐富的 KG 元資料和改善的語意網路服務。</paragraph>

##### **LightRAG: Simple and Fast Retrieval-Augmented Generation**
2410.05779v1 by Zirui Guo, Lianghao Xia, Yanhua Yu, Tu Ao, Chao Huang

Retrieval-Augmented Generation (RAG) systems enhance large language models
(LLMs) by integrating external knowledge sources, enabling more accurate and
contextually relevant responses tailored to user needs. However, existing RAG
systems have significant limitations, including reliance on flat data
representations and inadequate contextual awareness, which can lead to
fragmented answers that fail to capture complex inter-dependencies. To address
these challenges, we propose LightRAG, which incorporates graph structures into
text indexing and retrieval processes. This innovative framework employs a
dual-level retrieval system that enhances comprehensive information retrieval
from both low-level and high-level knowledge discovery. Additionally, the
integration of graph structures with vector representations facilitates
efficient retrieval of related entities and their relationships, significantly
improving response times while maintaining contextual relevance. This
capability is further enhanced by an incremental update algorithm that ensures
the timely integration of new data, allowing the system to remain effective and
responsive in rapidly changing data environments. Extensive experimental
validation demonstrates considerable improvements in retrieval accuracy and
efficiency compared to existing approaches. We have made our LightRAG
open-source and available at the link: https://github.com/HKUDS/LightRAG.

摘要：檢索增強生成 (RAG) 系統透過整合外部知識來源來增強大型語言模型 (LLM)，能針對使用者需求提供更準確且與脈絡相關的回應。然而，現有的 RAG 系統有很大的限制，包括依賴平面資料表示和不足的脈絡感知，這可能會導致無法捕捉複雜相互依賴性的片段式答案。為了應對這些挑戰，我們提出 LightRAG，它將圖形結構納入文字索引和檢索流程中。這個創新架構採用雙層檢索系統，能從低層級和高層級知識發現中增強全面的資訊檢索。此外，將圖形結構與向量表示整合，有助於有效檢索相關實體及其關係，大幅改善回應時間，同時維持脈絡相關性。此功能進一步透過增量更新演算法增強，可確保及時整合新資料，讓系統在快速變化的資料環境中保持有效且即時回應。廣泛的實驗驗證顯示，與現有方法相比，檢索準確度和效率都有顯著的改善。我們已開放 LightRAG 原始碼，並提供以下連結：https://github.com/HKUDS/LightRAG。

##### **Information Discovery in e-Commerce**
2410.05763v2 by Zhaochun Ren, Xiangnan He, Dawei Yin, Maarten de Rijke

Electronic commerce, or e-commerce, is the buying and selling of goods and
services, or the transmitting of funds or data online. E-commerce platforms
come in many kinds, with global players such as Amazon, Airbnb, Alibaba, eBay
and platforms targeting specific geographic regions. Information retrieval has
a natural role to play in e-commerce, especially in connecting people to goods
and services. Information discovery in e-commerce concerns different types of
search (e.g., exploratory search vs. lookup tasks), recommender systems, and
natural language processing in e-commerce portals. The rise in popularity of
e-commerce sites has made research on information discovery in e-commerce an
increasingly active research area. This is witnessed by an increase in
publications and dedicated workshops in this space. Methods for information
discovery in e-commerce largely focus on improving the effectiveness of
e-commerce search and recommender systems, on enriching and using knowledge
graphs to support e-commerce, and on developing innovative question answering
and bot-based solutions that help to connect people to goods and services. In
this survey, an overview is given of the fundamental infrastructure,
algorithms, and technical solutions for information discovery in e-commerce.
The topics covered include user behavior and profiling, search, recommendation,
and language technology in e-commerce.

摘要：電子商務，或稱電子商務，是買賣商品和服務，或在線上傳輸資金或資料。電子商務平台種類繁多，包括 Amazon、Airbnb、Alibaba、eBay 等全球性業者，以及鎖定特定地理區域的平台。資訊檢索在電子商務中扮演自然的角色，特別是在將人們與商品和服務連結起來方面。電子商務中的資訊發現涉及不同類型的搜尋（例如探索性搜尋與查詢任務）、推薦系統，以及電子商務入口網站中的自然語言處理。電子商務網站的普及使電子商務中的資訊發現研究成為一個越來越活躍的研究領域。這點可以從這方面的出版品和專門研討會的增加看出。電子商務中的資訊發現方法主要著重於改善電子商務搜尋和推薦系統的效能，豐富並使用知識圖表來支援電子商務，以及開發創新的問題解答和機器人解決方案，以協助將人們與商品和服務連結起來。在這項調查中，概述了電子商務中資訊發現的基本架構、演算法和技術解決方案。所涵蓋的主題包括電子商務中的使用者行為和設定檔、搜尋、推薦和語言技術。

##### **Vector-ICL: In-context Learning with Continuous Vector Representations**
2410.05629v1 by Yufan Zhuang, Chandan Singh, Liyuan Liu, Jingbo Shang, Jianfeng Gao

Large language models (LLMs) have shown remarkable in-context learning (ICL)
capabilities on textual data. We explore whether these capabilities can be
extended to continuous vectors from diverse domains, obtained from black-box
pretrained encoders. By aligning input data with an LLM's embedding space
through lightweight projectors, we observe that LLMs can effectively process
and learn from these projected vectors, which we term Vector-ICL. In
particular, we find that pretraining projectors with general language modeling
objectives enables Vector-ICL, while task-specific finetuning further enhances
performance. In our experiments across various tasks and modalities, including
text reconstruction, numerical function regression, text classification,
summarization, molecule captioning, time-series classification, graph
classification, and fMRI decoding, Vector-ICL often surpasses both few-shot ICL
and domain-specific model or tuning. We further conduct analyses and case
studies, indicating the potential of LLMs to process vector representations
beyond traditional token-based paradigms.

摘要：大型語言模型 (LLM) 在文本資料上展現出顯著的語境學習 (ICL) 能力。我們探討這些能力是否可以擴展到從不同領域取得，並由黑箱預訓練編碼器獲得的連續向量。透過輕量級投影器將輸入資料與 LLM 的嵌入空間對齊，我們觀察到 LLM 可以有效地處理和學習這些投影向量，我們稱之為 Vector-ICL。特別是，我們發現使用一般語言建模目標預訓練投影器可以啟用 Vector-ICL，而特定任務的微調進一步提升了效能。在我們跨越各種任務和模態的實驗中，包括文字重建、數值函數回歸、文字分類、摘要、分子標題、時間序列分類、圖形分類和 fMRI 解碼，Vector-ICL 通常都優於少次數 ICL 和特定領域模型或調整。我們進一步進行分析和案例研究，指出 LLM 處理向量表示的潛力，超越傳統的基於標記的範例。

##### **Narrative-of-Thought: Improving Temporal Reasoning of Large Language Models via Recounted Narratives**
2410.05558v1 by Xinliang Frederick Zhang, Nick Beauchamp, Lu Wang

Reasoning about time and temporal relations is an integral aspect of human
cognition, essential for perceiving the world and navigating our experiences.
Though large language models (LLMs) have demonstrated impressive performance in
many reasoning tasks, temporal reasoning remains challenging due to its
intrinsic complexity. In this work, we first study an essential task of
temporal reasoning -- temporal graph generation, to unveil LLMs' inherent,
global reasoning capabilities. We show that this task presents great challenges
even for the most powerful LLMs, such as GPT-3.5/4. We also notice a
significant performance gap by small models (<10B) that lag behind LLMs by 50%.
Next, we study how to close this gap with a budget constraint, e.g., not using
model finetuning. We propose a new prompting technique tailored for temporal
reasoning, Narrative-of-Thought (NoT), that first converts the events set to a
Python class, then prompts a small model to generate a temporally grounded
narrative, guiding the final generation of a temporal graph. Extensive
experiments showcase the efficacy of NoT in improving various metrics. Notably,
NoT attains the highest F1 on the Schema-11 evaluation set, while securing an
overall F1 on par with GPT-3.5. NoT also achieves the best structural
similarity across the board, even compared with GPT-3.5/4. Our code is
available at https://github.com/launchnlp/NoT.

摘要：推理時間和時間關係是人類認知中不可或缺的一環，對於感知世界和導航我們的經驗至關重要。儘管大型語言模型 (LLM) 在許多推理任務中表現出色，但由於時間推理的內在複雜性，因此仍然具有挑戰性。在這項工作中，我們首先研究時間推理的一項基本任務——時間圖表生成，以揭示 LLM 固有的全局推理能力。我們表明，即使對於功能最强大的 LLM，例如 GPT-3.5/4，此任務也提出了巨大的挑戰。我們還注意到，落後於 LLM 50% 的小型模型 (<10B) 存在顯著的性能差距。接下來，我們研究如何在預算約束下縮小這種差距，例如不使用模型微調。我們提出了一種針對時間推理量身定制的新提示技術，即思考敘事 (NoT)，它首先將事件集轉換為 Python 類，然後提示一個小型模型生成一個時間依據的敘事，指導時間圖表的最終生成。大量的實驗展示了 NoT 在改善各種指標方面的功效。值得注意的是，NoT 在 Schema-11 評估集中獲得了最高的 F1，同時確保了與 GPT-3.5 相當的整體 F1。即使與 GPT-3.5/4 相比，NoT 也在各方面實現了最佳結構相似性。我們的代碼可在 https://github.com/launchnlp/NoT 中獲得。

##### **Scalable and Accurate Graph Reasoning with LLM-based Multi-Agents**
2410.05130v1 by Yuwei Hu, Runlin Lei, Xinyi Huang, Zhewei Wei, Yongchao Liu

Recent research has explored the use of Large Language Models (LLMs) for
tackling complex graph reasoning tasks. However, due to the intricacies of
graph structures and the inherent limitations of LLMs in handling long text,
current approaches often fail to deliver satisfactory accuracy, even on
small-scale graphs and simple tasks. To address these challenges, we introduce
GraphAgent-Reasoner, a fine-tuning-free framework that utilizes a multi-agent
collaboration strategy for explicit and precise graph reasoning. Inspired by
distributed graph computation theory, our framework decomposes graph problems
into smaller, node-centric tasks that are distributed among multiple agents.
The agents collaborate to solve the overall problem, significantly reducing the
amount of information and complexity handled by a single LLM, thus enhancing
the accuracy of graph reasoning. By simply increasing the number of agents,
GraphAgent-Reasoner can efficiently scale to accommodate larger graphs with
over 1,000 nodes. Evaluated on the GraphInstruct dataset, our framework
demonstrates near-perfect accuracy on polynomial-time graph reasoning tasks,
significantly outperforming the best available models, both closed-source and
fine-tuned open-source variants. Our framework also demonstrates the capability
to handle real-world graph reasoning applications such as webpage importance
analysis.

摘要：近期研究已探討使用大型語言模型 (LLM) 來處理複雜的圖形推理任務。然而，由於圖形結構的複雜性和 LLM 在處理長文本時固有的限制，現有方法通常無法提供令人滿意的準確性，即使是在小規模圖形和簡單任務上。為了應對這些挑戰，我們引入了 GraphAgent-Reasoner，這是一個無需微調的框架，它利用多主體協作策略進行明確且精確的圖形推理。我們的框架受到分散式圖形計算理論的啟發，將圖形問題分解成更小的以節點為中心的任務，並將這些任務分配給多個主體。這些主體協作解決整體問題，大幅減少單個 LLM 處理的資訊量和複雜度，從而提升圖形推理的準確性。透過單純增加主體數量，GraphAgent-Reasoner 可以有效擴充以容納節點超過 1,000 個的大型圖形。在 GraphInstruct 資料集上進行評估，我們的框架在多項式時間圖形推理任務上展現出近乎完美的準確性，大幅優於市面上最好的模型，包含閉源和微調開源版本。我們的框架也展現出處理真實世界圖形推理應用程式的能力，例如網頁重要性分析。

##### **Leverage Knowledge Graph and Large Language Model for Law Article Recommendation: A Case Study of Chinese Criminal Law**
2410.04949v1 by Yongming Chen, Miner Chen, Ye Zhu, Juan Pei, Siyu Chen, Yu Zhou, Yi Wang, Yifan Zhou, Hao Li, Songan Zhang

Court efficiency is vital for social stability. However, in most countries
around the world, the grassroots courts face case backlogs, with decisions
relying heavily on judicial personnel's cognitive labor, lacking intelligent
tools to improve efficiency. To address this issue, we propose an efficient law
article recommendation approach utilizing a Knowledge Graph (KG) and a Large
Language Model (LLM). Firstly, we propose a Case-Enhanced Law Article Knowledge
Graph (CLAKG) as a database to store current law statutes, historical case
information, and correspondence between law articles and historical cases.
Additionally, we introduce an automated CLAKG construction method based on LLM.
On this basis, we propose a closed-loop law article recommendation method.
Finally, through a series of experiments using judgment documents from the
website "China Judgements Online", we have improved the accuracy of law article
recommendation in cases from 0.549 to 0.694, demonstrating that our proposed
method significantly outperforms baseline approaches.

摘要：法院效率對於社會穩定至關重要。然而，在世界大多數國家中，基層法院面臨案件積壓，判決嚴重依賴司法人員的認知勞動，缺乏提高效率的智能工具。為了解決這個問題，我們提出了一個利用知識圖譜 (KG) 和大型語言模型 (LLM) 的高效法律條文推薦方法。首先，我們提出一個案例增強法律條文知識圖譜 (CLAKG) 作為一個資料庫，用於儲存現行法律法規、歷史案例資訊和法律條文與歷史案例之間的對應關係。此外，我們引入一個基於 LLM 的自動化 CLAKG 構建方法。在此基礎上，我們提出了一個閉環法律條文推薦方法。最後，透過一連串使用來自網站「中國裁判文書網」的裁判文書的實驗，我們將案件中法律條文推薦的準確率從 0.549 提升至 0.694，證明我們提出的方法顯著優於基準方法。

##### **GARLIC: LLM-Guided Dynamic Progress Control with Hierarchical Weighted Graph for Long Document QA**
2410.04790v1 by Xinyu Wang, Yanzheng Xiang, Lin Gui, Yulan He

In the past, Retrieval-Augmented Generation (RAG) methods split text into
chunks to enable language models to handle long documents. Recent tree-based
RAG methods are able to retrieve detailed information while preserving global
context. However, with the advent of more powerful LLMs, such as Llama 3.1,
which offer better comprehension and support for longer inputs, we found that
even recent tree-based RAG methods perform worse than directly feeding the
entire document into Llama 3.1, although RAG methods still hold an advantage in
reducing computational costs. In this paper, we propose a new retrieval method,
called LLM-Guided Dynamic Progress Control with Hierarchical Weighted Graph
(GARLIC), which outperforms previous state-of-the-art baselines, including
Llama 3.1, while retaining the computational efficiency of RAG methods. Our
method introduces several improvements: (1) Rather than using a tree structure,
we construct a Hierarchical Weighted Directed Acyclic Graph with many-to-many
summarization, where the graph edges are derived from attention mechanisms, and
each node focuses on a single event or very few events. (2) We introduce a
novel retrieval method that leverages the attention weights of LLMs rather than
dense embedding similarity. Our method allows for searching the graph along
multiple paths and can terminate at any depth. (3) We use the LLM to control
the retrieval process, enabling it to dynamically adjust the amount and depth
of information retrieved for different queries. Experimental results show that
our method outperforms previous state-of-the-art baselines, including Llama
3.1, on two single-document and two multi-document QA datasets, while
maintaining similar computational complexity to traditional RAG methods.

摘要：<paragraph>在過去，檢索增強生成 (RAG) 方法會將文字切割成塊，以使語言模型能夠處理長篇文件。最近的基於樹的 RAG 方法能夠在保留整體脈絡的同時檢索詳細資訊。然而，隨著功能更強大的 LLM（例如 Llama 3.1）的出現，這些 LLM 提供了更好的理解力和對更長輸入的支援，我們發現即使是最近的基於樹的 RAG 方法也比直接將整個文件輸入 Llama 3.1 的表現更差，儘管 RAG 方法在降低運算成本方面仍具備優勢。在本文中，我們提出了一種新的檢索方法，稱為具有分層加權圖的 LLM 引導動態進度控制 (GARLIC)，它優於先前的最先進基準，包括 Llama 3.1，同時保留了 RAG 方法的運算效率。我們的改進方法引入了多項改進：(1) 我們沒有使用樹狀結構，而是構建了一個具有多對多摘要的分層加權有向無環圖，其中圖邊緣源自注意力機制，每個節點都專注於單一事件或極少數事件。(2) 我們引入了一種新穎的檢索方法，它利用 LLM 的注意力權重，而不是密集嵌入相似性。我們的改進方法允許沿多個路徑搜尋圖，並且可以在任何深度終止。(3) 我們使用 LLM 來控制檢索過程，使其能夠動態調整為不同查詢檢索的資訊量和深度。實驗結果表明，我們的改進方法在兩個單文件和兩個多文件問答資料集上優於先前的最先進基準，包括 Llama 3.1，同時維持與傳統 RAG 方法類似的運算複雜度。</paragraph>

##### **Reasoning-Enhanced Healthcare Predictions with Knowledge Graph Community Retrieval**
2410.04585v1 by Pengcheng Jiang, Cao Xiao, Minhao Jiang, Parminder Bhatia, Taha Kass-Hout, Jimeng Sun, Jiawei Han

Large language models (LLMs) have demonstrated significant potential in
clinical decision support. Yet LLMs still suffer from hallucinations and lack
fine-grained contextual medical knowledge, limiting their high-stake healthcare
applications such as clinical diagnosis. Traditional retrieval-augmented
generation (RAG) methods attempt to address these limitations but frequently
retrieve sparse or irrelevant information, undermining prediction accuracy. We
introduce KARE, a novel framework that integrates knowledge graph (KG)
community-level retrieval with LLM reasoning to enhance healthcare predictions.
KARE constructs a comprehensive multi-source KG by integrating biomedical
databases, clinical literature, and LLM-generated insights, and organizes it
using hierarchical graph community detection and summarization for precise and
contextually relevant information retrieval. Our key innovations include: (1) a
dense medical knowledge structuring approach enabling accurate retrieval of
relevant information; (2) a dynamic knowledge retrieval mechanism that enriches
patient contexts with focused, multi-faceted medical insights; and (3) a
reasoning-enhanced prediction framework that leverages these enriched contexts
to produce both accurate and interpretable clinical predictions. Extensive
experiments demonstrate that KARE outperforms leading models by up to
10.8-15.0% on MIMIC-III and 12.6-12.7% on MIMIC-IV for mortality and
readmission predictions. In addition to its impressive prediction accuracy, our
framework leverages the reasoning capabilities of LLMs, enhancing the
trustworthiness of clinical predictions.

摘要：大型語言模型 (LLM) 已在臨床決策支援中展現出顯著的潛力。然而，LLM 仍有幻覺且缺乏細緻的背景醫療知識，限制了它們在高風險醫療保健應用中的使用，例如臨床診斷。傳統的檢索增強生成 (RAG) 方法試圖解決這些限制，但經常檢索稀疏或無關的資訊，損害預測準確度。我們引入了 KARE，這是一個新穎的架構，整合了知識圖譜 (KG) 社群層級檢索與 LLM 推理，以增強醫療保健預測。KARE 透過整合生物醫學資料庫、臨床文獻和 LLM 生成的見解，建構了一個全面的多來源 KG，並使用階層式圖形社群偵測和摘要進行組織，以進行精確且與背景相關的資訊檢索。我們的關鍵創新包括：(1) 一種密集的醫療知識結構化方法，能夠準確檢索相關資訊；(2) 一種動態知識檢索機制，它使用有焦點、多面向的醫療見解來豐富患者背景；以及 (3) 一個推理增強預測架構，它利用這些豐富的背景來產生準確且可解釋的臨床預測。廣泛的實驗證明，KARE 在 MIMIC-III 上的死亡率和再入院預測中比領先模型高出 10.8-15.0%，在 MIMIC-IV 上高出 12.6-12.7%。除了令人印象深刻的預測準確度外，我們的架構還利用了 LLM 的推理能力，增強了臨床預測的可信度。

##### **Mitigating Hallucinations Using Ensemble of Knowledge Graph and Vector Store in Large Language Models to Enhance Mental Health Support**
2410.10853v1 by Abdul Muqtadir, Hafiz Syed Muhammad Bilal, Ayesha Yousaf, Hafiz Farooq Ahmed, Jamil Hussain

This research work delves into the manifestation of hallucination within
Large Language Models (LLMs) and its consequential impacts on applications
within the domain of mental health. The primary objective is to discern
effective strategies for curtailing hallucinatory occurrences, thereby
bolstering the dependability and security of LLMs in facilitating mental health
interventions such as therapy, counseling, and the dissemination of pertinent
information. Through rigorous investigation and analysis, this study seeks to
elucidate the underlying mechanisms precipitating hallucinations in LLMs and
subsequently propose targeted interventions to alleviate their occurrence. By
addressing this critical issue, the research endeavors to foster a more robust
framework for the utilization of LLMs within mental health contexts, ensuring
their efficacy and reliability in aiding therapeutic processes and delivering
accurate information to individuals seeking mental health support.

摘要：本研究探討大型語言模型 (LLM) 中幻覺的表現，及其對心理健康領域應用產生的後續影響。主要目標是辨別遏制幻覺發生的有效策略，從而加強 LLM 在促進心理健康干預措施（例如治療、諮詢和傳播相關資訊）方面的可靠性和安全性。透過嚴謹的調查和分析，本研究試圖闡明導致 LLM 產生幻覺的潛在機制，並進一步提出有針對性的干預措施來減輕其發生。透過解決這個關鍵問題，本研究致力於建立一個更穩健的架構，以便在心理健康情境中使用 LLM，確保其在協助治療過程和向尋求心理健康支持的個人提供準確資訊方面的效能和可靠性。

##### **Leveraging Social Determinants of Health in Alzheimer's Research Using LLM-Augmented Literature Mining and Knowledge Graphs**
2410.09080v1 by Tianqi Shang, Shu Yang, Weiqing He, Tianhua Zhai, Dawei Li, Bojian Hou, Tianlong Chen, Jason H. Moore, Marylyn D. Ritchie, Li Shen

Growing evidence suggests that social determinants of health (SDoH), a set of
nonmedical factors, affect individuals' risks of developing Alzheimer's disease
(AD) and related dementias. Nevertheless, the etiological mechanisms underlying
such relationships remain largely unclear, mainly due to difficulties in
collecting relevant information. This study presents a novel, automated
framework that leverages recent advancements of large language model (LLM) and
natural language processing techniques to mine SDoH knowledge from extensive
literature and integrate it with AD-related biological entities extracted from
the general-purpose knowledge graph PrimeKG. Utilizing graph neural networks,
we performed link prediction tasks to evaluate the resultant SDoH-augmented
knowledge graph. Our framework shows promise for enhancing knowledge discovery
in AD and can be generalized to other SDoH-related research areas, offering a
new tool for exploring the impact of social determinants on health outcomes.
Our code is available at: https://github.com/hwq0726/SDoHenPKG

摘要：越來越多的證據表明，社會健康決定因素 (SDoH) 是一組非醫療因素，會影響個人罹患阿茲海默症 (AD) 和相關失智症的風險。然而，這種關係背後的基本機制在很大程度上仍不清楚，主要是因為難以收集相關資訊。本研究提出一個新穎的自動化架構，利用大型語言模型 (LLM) 和自然語言處理技術的最新進展，從廣泛的文獻中挖掘 SDoH 知識，並將其與從通用知識圖 PrimeKG 中提取的 AD 相關生物實體整合在一起。利用圖神經網路，我們執行連結預測任務，以評估生成的 SDoH 擴充知識圖。我們的架構顯示出增強 AD 中知識發現的希望，並且可以推廣到其他與 SDoH 相關的研究領域，提供一個探索社會決定因素對健康結果影響的新工具。我們的程式碼可在 https://github.com/hwq0726/SDoHenPKG 取得

##### **Empowering Domain-Specific Language Models with Graph-Oriented Databases: A Paradigm Shift in Performance and Model Maintenance**
2410.03867v1 by Ricardo Di Pasquale, Soledad Represa

In an era dominated by data, the management and utilization of
domain-specific language have emerged as critical challenges in various
application domains, particularly those with industry-specific requirements.
Our work is driven by the need to effectively manage and process large volumes
of short text documents inherent in specific application domains. By leveraging
domain-specific knowledge and expertise, our approach aims to shape factual
data within these domains, thereby facilitating enhanced utilization and
understanding by end-users. Central to our methodology is the integration of
domain-specific language models with graph-oriented databases, facilitating
seamless processing, analysis, and utilization of textual data within targeted
domains. Our work underscores the transformative potential of the partnership
of domain-specific language models and graph-oriented databases. This
cooperation aims to assist researchers and engineers in metric usage,
mitigation of latency issues, boosting explainability, enhancing debug and
improving overall model performance. Moving forward, we envision our work as a
guide AI engineers, providing valuable insights for the implementation of
domain-specific language models in conjunction with graph-oriented databases,
and additionally provide valuable experience in full-life cycle maintenance of
this kind of products.

摘要：在資料當道的時代，特定領域語言的管理和應用已成為各應用領域中的關鍵挑戰，尤其是那些具有產業特定需求的領域。我們的研究動機是有效管理和處理特定應用領域中固有的海量簡短文本文件。透過運用特定領域的知識和專業知識，我們的做法旨在形塑這些領域中的事實資料，進而促進最終使用者增強利用和理解。我們方法的核心是將特定領域的語言模型與圖形導向資料庫整合，促進目標領域中文字資料的無縫處理、分析和利用。我們的研究強調了特定領域語言模型與圖形導向資料庫合作的轉型潛力。這種合作旨在協助研究人員和工程師進行指標使用、減輕延遲問題、提升可解釋性、增強除錯，並改善整體模型效能。展望未來，我們預期我們的研究將成為人工智慧工程師的指南，提供有價值的見解，供他們將特定領域語言模型與圖形導向資料庫結合實作，並進一步提供此類產品全生命週期維護的寶貴經驗。

##### **GraphRouter: A Graph-based Router for LLM Selections**
2410.03834v1 by Tao Feng, Yanzhen Shen, Jiaxuan You

The rapidly growing number and variety of Large Language Models (LLMs)
present significant challenges in efficiently selecting the appropriate LLM for
a given query, especially considering the trade-offs between performance and
computational cost. Current LLM selection methods often struggle to generalize
across new LLMs and different tasks because of their limited ability to
leverage contextual interactions among tasks, queries, and LLMs, as well as
their dependence on a transductive learning framework. To address these
shortcomings, we introduce a novel inductive graph framework, named as
GraphRouter, which fully utilizes the contextual information among tasks,
queries, and LLMs to enhance the LLM selection process. GraphRouter constructs
a heterogeneous graph comprising task, query, and LLM nodes, with interactions
represented as edges, which efficiently captures the contextual information
between the query's requirements and the LLM's capabilities. Through an
innovative edge prediction mechanism, GraphRouter is able to predict attributes
(the effect and cost of LLM response) of potential edges, allowing for
optimized recommendations that adapt to both existing and newly introduced LLMs
without requiring retraining. Comprehensive experiments across three distinct
effect-cost weight scenarios have shown that GraphRouter substantially
surpasses existing routers, delivering a minimum performance improvement of
12.3%. In addition, it achieves enhanced generalization across new LLMs
settings and supports diverse tasks with at least a 9.5% boost in effect and a
significant reduction in computational demands. This work endeavors to apply a
graph-based approach for the contextual and adaptive selection of LLMs,
offering insights for real-world applications. Our codes for GraphRouter will
soon be released at https://github.com/ulab-uiuc/GraphRouter.

摘要：<paragraph>大型語言模型 (LLM) 的數量和種類快速增長，在有效地針對特定查詢選擇適當的 LLM 時會帶來重大的挑戰，特別是考慮到效能和運算成本之間的權衡。目前的 LLM 選擇方法通常難以概括到新的 LLM 和不同的任務，因為它們在利用任務、查詢和 LLM 之間的脈絡互動方面的能力有限，而且依賴於轉導學習架構。為了解決這些缺點，我們引進了一個名為 GraphRouter 的新歸納圖形架構，它充分利用任務、查詢和 LLM 之間的脈絡資訊來增強 LLM 選擇流程。GraphRouter 構建了一個異質圖形，包含任務、查詢和 LLM 節點，並將互動表示為邊緣，有效地擷取查詢需求和 LLM 能力之間的脈絡資訊。透過創新的邊緣預測機制，GraphRouter 能夠預測潛在邊緣的屬性（LLM 回應的效果和成本），允許最佳化建議，以適應現有和新推出的 LLM，而無需重新訓練。在三個不同的效果成本權重情境中進行的全面實驗顯示，GraphRouter 明顯超越現有的路由器，效能至少提升 12.3%。此外，它在新的 LLM 設定中實現了增強的概括性，並支援多樣化的任務，效果至少提升 9.5%，並大幅降低運算需求。這項工作致力於應用基於圖形的方法，以進行 LLM 的脈絡和適應性選擇，為真實世界的應用提供見解。我們的 GraphRouter 程式碼將很快在 https://github.com/ulab-uiuc/GraphRouter 發布。</paragraph>

##### **Should Cross-Lingual AMR Parsing go Meta? An Empirical Assessment of Meta-Learning and Joint Learning AMR Parsing**
2410.03357v1 by Jeongwoo Kang, Maximin Coavoux, Cédric Lopez, Didier Schwab

Cross-lingual AMR parsing is the task of predicting AMR graphs in a target
language when training data is available only in a source language. Due to the
small size of AMR training data and evaluation data, cross-lingual AMR parsing
has only been explored in a small set of languages such as English, Spanish,
German, Chinese, and Italian. Taking inspiration from Langedijk et al. (2022),
who apply meta-learning to tackle cross-lingual syntactic parsing, we
investigate the use of meta-learning for cross-lingual AMR parsing. We evaluate
our models in $k$-shot scenarios (including 0-shot) and assess their
effectiveness in Croatian, Farsi, Korean, Chinese, and French. Notably, Korean
and Croatian test sets are developed as part of our work, based on the existing
The Little Prince English AMR corpus, and made publicly available. We
empirically study our method by comparing it to classical joint learning. Our
findings suggest that while the meta-learning model performs slightly better in
0-shot evaluation for certain languages, the performance gain is minimal or
absent when $k$ is higher than 0.

摘要：跨語言 AMR 解析是一項任務，在僅在源語言中提供訓練資料時，預測目標語言中的 AMR 圖形。由於 AMR 訓練資料和評估資料的規模很小，因此跨語言 AMR 解析僅在少數語言中進行過探索，例如英語、西班牙語、德語、中文和義大利語。受到 Langedijk 等人 (2022) 的啟發，他們應用元學習來處理跨語言句法解析，我們研究了使用元學習進行跨語言 AMR 解析。我們在 $k$-shot 場景（包括 0-shot）中評估我們的模型，並評估它們在克羅埃西亞語、波斯語、韓語、中文和法語中的有效性。值得注意的是，韓語和克羅埃西亞語測試集是根據現有的《小王子》英語 AMR 語料庫開發的，並公開提供。我們通過將我們的模型與傳統聯合學習進行比較，對我們的模型進行實證研究。我們的研究結果表明，雖然元學習模型在某些語言的 0-shot 評估中表現略好，但是當 $k$ 高於 0 時，效能提升很小或沒有。

##### **Enriching Ontologies with Disjointness Axioms using Large Language Models**
2410.03235v1 by Elias Crum, Antonio De Santis, Manon Ovide, Jiaxin Pan, Alessia Pisu, Nicolas Lazzari, Sebastian Rudolph

Ontologies often lack explicit disjointness declarations between classes,
despite their usefulness for sophisticated reasoning and consistency checking
in Knowledge Graphs. In this study, we explore the potential of Large Language
Models (LLMs) to enrich ontologies by identifying and asserting class
disjointness axioms. Our approach aims at leveraging the implicit knowledge
embedded in LLMs, using prompt engineering to elicit this knowledge for
classifying ontological disjointness. We validate our methodology on the
DBpedia ontology, focusing on open-source LLMs. Our findings suggest that LLMs,
when guided by effective prompt strategies, can reliably identify disjoint
class relationships, thus streamlining the process of ontology completion
without extensive manual input. For comprehensive disjointness enrichment, we
propose a process that takes logical relationships between disjointness and
subclass statements into account in order to maintain satisfiability and reduce
the number of calls to the LLM. This work provides a foundation for future
applications of LLMs in automated ontology enhancement and offers insights into
optimizing LLM performance through strategic prompt design. Our code is
publicly available on GitHub at https://github.com/n28div/llm-disjointness.

摘要：本体論通常缺乏類別之間明確的不相交聲明，儘管它們對於知識圖譜中的精密推理和一致性檢查很有用。在本研究中，我們探討了大型語言模型 (LLM) 的潛力，通過識別和斷言類別不相交公理來豐富本体論。我們的做法旨在利用嵌入在 LLM 中的隱式知識，利用提示工程來引出這種知識以分類本体論不相交。我們在 DBpedia 本体論上驗證了我們的方法，重點關注開源 LLM。我們的研究結果表明，LLM 在有效提示策略的指導下，可以可靠地識別不相交類別關係，從而簡化本体論完成過程，而無需大量手動輸入。對於全面的不相交豐富，我們提出了一個過程，該過程考慮了不相交和子類別陳述之間的邏輯關係，以維持可滿足性並減少對 LLM 的調用次數。這項工作為 LLM 在自動本体論增強中的未來應用奠定了基礎，並提供了通過策略提示設計優化 LLM 性能的見解。我們的代碼在 GitHub 上公開，網址為 https://github.com/n28div/llm-disjointness。

##### **How Do Large Language Models Understand Graph Patterns? A Benchmark for Graph Pattern Comprehension**
2410.05298v1 by Xinnan Dai, Haohao Qu, Yifen Shen, Bohang Zhang, Qihao Wen, Wenqi Fan, Dongsheng Li, Jiliang Tang, Caihua Shan

Benchmarking the capabilities and limitations of large language models (LLMs)
in graph-related tasks is becoming an increasingly popular and crucial area of
research. Recent studies have shown that LLMs exhibit a preliminary ability to
understand graph structures and node features. However, the potential of LLMs
in graph pattern mining remains largely unexplored. This is a key component in
fields such as computational chemistry, biology, and social network analysis.
To bridge this gap, this work introduces a comprehensive benchmark to assess
LLMs' capabilities in graph pattern tasks. We have developed a benchmark that
evaluates whether LLMs can understand graph patterns based on either
terminological or topological descriptions. Additionally, our benchmark tests
the LLMs' capacity to autonomously discover graph patterns from data. The
benchmark encompasses both synthetic and real datasets, and a variety of
models, with a total of 11 tasks and 7 models. Our experimental framework is
designed for easy expansion to accommodate new models and datasets. Our
findings reveal that: (1) LLMs have preliminary abilities to understand graph
patterns, with O1-mini outperforming in the majority of tasks; (2) Formatting
input data to align with the knowledge acquired during pretraining can enhance
performance; (3) The strategies employed by LLMs may differ from those used in
conventional algorithms.

摘要：評量大型語言模型 (LLM) 在圖形相關任務中的能力和限制，正成為一個越來越受歡迎且至關重要的研究領域。最近的研究表明，LLM 展現出初步理解圖形結構和節點特徵的能力。然而，LLM 在圖形模式挖掘中的潛力仍未被廣泛探索。這是計算化學、生物學和社交網路分析等領域的關鍵組成部分。為了彌合這個差距，這項工作提出了一個全面的基準來評估 LLM 在圖形模式任務中的能力。我們開發了一個基準，用來評估 LLM 能否根據術語或拓撲描述來理解圖形模式。此外，我們的基準測試 LLM 從資料中自主發現圖形模式的能力。該基準涵蓋了合成和真實資料集，以及各種模型，總共有 11 項任務和 7 個模型。我們的實驗架構設計為易於擴充，以容納新的模型和資料集。我們的研究結果顯示：(1) LLM 具有初步理解圖形模式的能力，其中 O1-mini 在大多數任務中表現優異；(2) 將輸入資料格式化為與預訓練期間習得的知識一致，可以增強效能；(3) LLM 使用的策略可能與傳統演算法中使用的策略不同。

##### **LLMCO2: Advancing Accurate Carbon Footprint Prediction for LLM Inferences**
2410.02950v1 by Zhenxiao Fu, Fan Chen, Shan Zhou, Haitong Li, Lei Jiang

Throughout its lifecycle, a large language model (LLM) generates a
substantially larger carbon footprint during inference than training. LLM
inference requests vary in batch size, prompt length, and token generation
number, while cloud providers employ different GPU types and quantities to meet
diverse service-level objectives for accuracy and latency. It is crucial for
both users and cloud providers to have a tool that quickly and accurately
estimates the carbon impact of LLM inferences based on a combination of
inference request and hardware configurations before execution. Estimating the
carbon footprint of LLM inferences is more complex than training due to lower
and highly variable model FLOPS utilization, rendering previous equation-based
models inaccurate. Additionally, existing machine learning (ML) prediction
methods either lack accuracy or demand extensive training data, as they
inadequately handle the distinct prefill and decode phases, overlook
hardware-specific features, and inefficiently sample uncommon inference
configurations. We introduce \coo, a graph neural network (GNN)-based model
that greatly improves the accuracy of LLM inference carbon footprint
predictions compared to previous methods.

摘要：在整個生命週期中，大型語言模型 (LLM) 在推理期間產生的碳足跡遠大於訓練期間。LLM 推理請求在批次大小、提示長度和權杖生成數量方面有所不同，而雲端供應商採用不同的 GPU 類型和數量來滿足準確性和延遲的各種服務層級目標。對於使用者和雲端供應商來說，在執行前根據推理請求和硬體配置組合快速且準確地估計 LLM 推理的碳影響至關重要。估計 LLM 推理的碳足跡比訓練更複雜，因為模型 FLOPS 利用率較低且變化很大，導致先前的基於方程式的模型不準確。此外，現有的機器學習 (ML) 預測方法要么缺乏準確性，要么需要大量的訓練資料，因為它們無法充分處理不同的預填充和解碼階段，忽略硬體特定的功能，並且低效率地取樣不常見的推理配置。我們引入了 \coo，這是一個基於圖神經網路 (GNN) 的模型，與先前的模型相比，它大大提高了 LLM 推理碳足跡預測的準確性。

##### **Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization**
2410.02721v1 by Ryan C. Barron, Ves Grantcharov, Selma Wanna, Maksim E. Eren, Manish Bhattarai, Nicholas Solovyev, George Tompkins, Charles Nicholas, Kim Ø. Rasmussen, Cynthia Matuszek, Boian S. Alexandrov

Large Language Models (LLMs) are pre-trained on large-scale corpora and excel
in numerous general natural language processing (NLP) tasks, such as question
answering (QA). Despite their advanced language capabilities, when it comes to
domain-specific and knowledge-intensive tasks, LLMs suffer from hallucinations,
knowledge cut-offs, and lack of knowledge attributions. Additionally, fine
tuning LLMs' intrinsic knowledge to highly specific domains is an expensive and
time consuming process. The retrieval-augmented generation (RAG) process has
recently emerged as a method capable of optimization of LLM responses, by
referencing them to a predetermined ontology. It was shown that using a
Knowledge Graph (KG) ontology for RAG improves the QA accuracy, by taking into
account relevant sub-graphs that preserve the information in a structured
manner. In this paper, we introduce SMART-SLIC, a highly domain-specific LLM
framework, that integrates RAG with KG and a vector store (VS) that store
factual domain specific information. Importantly, to avoid hallucinations in
the KG, we build these highly domain-specific KGs and VSs without the use of
LLMs, but via NLP, data mining, and nonnegative tensor factorization with
automatic model selection. Pairing our RAG with a domain-specific: (i) KG
(containing structured information), and (ii) VS (containing unstructured
information) enables the development of domain-specific chat-bots that
attribute the source of information, mitigate hallucinations, lessen the need
for fine-tuning, and excel in highly domain-specific question answering tasks.
We pair SMART-SLIC with chain-of-thought prompting agents. The framework is
designed to be generalizable to adapt to any specific or specialized domain. In
this paper, we demonstrate the question answering capabilities of our framework
on a corpus of scientific publications on malware analysis and anomaly
detection.

摘要：大型語言模型 (LLM) 經過大量語料庫的預先訓練，在許多一般自然語言處理 (NLP) 任務中表現出色，例如問題解答 (QA)。儘管它們具有先進的語言能力，但 LLM 在特定領域和知識密集型任務方面會出現幻覺、知識斷層和缺乏知識歸因。此外，微調 LLM 的內在知識以適應高度特定領域是一個昂貴且耗時的過程。檢索增強生成 (RAG) 流程最近已成為一種優化 LLM 回應的方法，方法是將它們參照預先確定的本体。研究表明，將知識圖譜 (KG) 本体用於 RAG 可透過考慮以結構化方式保留資訊的相關子圖，來提高 QA 的準確性。在本文中，我們介紹了 SMART-SLIC，這是一個高度特定領域的 LLM 框架，它將 RAG 與 KG 和一個儲存事實特定領域資訊的向量儲存 (VS) 整合在一起。重要的是，為了避免 KG 中的幻覺，我們在不使用 LLM 的情況下建立了這些高度特定領域的 KG 和 VS，而是透過 NLP、資料探勘和具有自動模型選擇的非負張量分解。將我們的 RAG 與特定領域配對：(i) KG（包含結構化資訊），和 (ii) VS（包含非結構化資訊）能夠開發特定領域的聊天機器人，這些聊天機器人會歸因於資訊來源、減輕幻覺、減少微調的需要，並在高度特定領域的問題解答任務中表現出色。我們將 SMART-SLIC 與思考鏈提示代理配對。該框架被設計成可概括以適應任何特定或專業領域。在本文中，我們在惡意軟體分析和異常偵測的科學出版物語料庫上展示了我們框架的問題解答能力。

##### **A Schema-aware Logic Reformulation for Graph Reachability**
2410.02533v1 by Davide Di Pierro, Stefano Ferilli

Graph reachability is the task of understanding whether two distinct points
in a graph are interconnected by arcs to which in general a semantic is
attached. Reachability has plenty of applications, ranging from motion planning
to routing. Improving reachability requires structural knowledge of relations
so as to avoid the complexity of traditional depth-first and breadth-first
strategies, implemented in logic languages. In some contexts, graphs are
enriched with their schema definitions establishing domain and range for every
arc. The introduction of a schema-aware formalization for guiding the search
may result in a sensitive improvement by cutting out unuseful paths and
prioritising those that, in principle, reach the target earlier. In this work,
we propose a strategy to automatically exclude and sort certain graph paths by
exploiting the higher-level conceptualization of instances. The aim is to
obtain a new first-order logic reformulation of the graph reachability
scenario, capable of improving the traditional algorithms in terms of time,
space requirements, and number of backtracks. The experiments exhibit the
expected advantages of the approach in reducing the number of backtracks during
the search strategy, resulting in saving time and space as well.

摘要：圖形可達性是了解圖形中兩個不同點是否由弧線相互連接的任務，這些弧線通常附帶語義。可達性有很多應用，從運動規劃到路由。提高可達性需要結構關係知識，以避免邏輯語言中實現的傳統深度優先和廣度優先策略的複雜性。在某些情況下，圖形會通過其架構定義得到豐富，為每個弧線建立域和範圍。引入架構感知形式化以指導搜尋可能會通過切斷無用的路徑和優先考慮原則上較早到達目標的路徑而產生顯著的改進。在這項工作中，我們提出了一種策略，通過利用實例的高階概念化來自動排除和排序某些圖形路徑。目的是獲得圖形可達性場景的新一階邏輯重新表述，能夠在時間、空間需求和回溯次數方面改進傳統演算法。實驗展示了該方法在減少搜尋策略期間回溯次數方面的預期優點，從而節省了時間和空間。

##### **Language Models are Graph Learners**
2410.02296v1 by Zhe Xu, Kaveh Hassani, Si Zhang, Hanqing Zeng, Michihiro Yasunaga, Limei Wang, Dongqi Fu, Ning Yao, Bo Long, Hanghang Tong

Language Models (LMs) are increasingly challenging the dominance of
domain-specific models, including Graph Neural Networks (GNNs) and Graph
Transformers (GTs), in graph learning tasks. Following this trend, we propose a
novel approach that empowers off-the-shelf LMs to achieve performance
comparable to state-of-the-art GNNs on node classification tasks, without
requiring any architectural modification. By preserving the LM's original
architecture, our approach retains a key benefit of LM instruction tuning: the
ability to jointly train on diverse datasets, fostering greater flexibility and
efficiency. To achieve this, we introduce two key augmentation strategies: (1)
Enriching LMs' input using topological and semantic retrieval methods, which
provide richer contextual information, and (2) guiding the LMs' classification
process through a lightweight GNN classifier that effectively prunes class
candidates. Our experiments on real-world datasets show that backbone Flan-T5
models equipped with these augmentation strategies outperform state-of-the-art
text-output node classifiers and are comparable to top-performing vector-output
node classifiers. By bridging the gap between specialized task-specific node
classifiers and general LMs, this work paves the way for more versatile and
widely applicable graph learning models. We will open-source the code upon
publication.

摘要：語言模型（LM）正日益挑戰特定領域模型在圖形學習任務中的主導地位，包括圖形神經網路（GNN）和圖形轉換器（GT）。遵循此趨勢，我們提出了一種創新方法，使現成的 LM 能夠在節點分類任務中實現與最先進的 GNN 相當的效能，而無需任何架構修改。透過保留 LM 的原始架構，我們的做法保留了 LM 指令調整的一項主要優點：能夠在不同的資料集上進行聯合訓練，促進更大的靈活性和效率。為此，我們引入了兩個主要的擴充策略：(1) 使用拓撲和語義檢索方法豐富 LM 的輸入，提供更豐富的上下文資訊，以及 (2) 透過輕量級 GNN 分類器引導 LM 的分類過程，有效地修剪類別候選。我們在真實世界資料集上的實驗表明，配備這些擴充策略的主幹 Flan-T5 模型優於最先進的文字輸出節點分類器，並且與效能最佳的向量輸出節點分類器相當。透過縮小專門的特定任務節點分類器和一般 LM 之間的差距，這項工作為更多元化且廣泛適用的圖形學習模型鋪平了道路。我們將在出版後開源程式碼。

##### **GraphIC: A Graph-Based In-Context Example Retrieval Model for Multi-Step Reasoning**
2410.02203v1 by Jiale Fu, Yaqing Wang, Simeng Han, Jiaming Fan, Chen Si, Xu Yang

In-context learning (ICL) enables large language models (LLMs) to generalize
to new tasks by incorporating a few in-context examples (ICEs) directly in the
input, without updating parameters. However, the effectiveness of ICL heavily
relies on the selection of ICEs, and conventional text-based embedding methods
are often inadequate for tasks that require multi-step reasoning, such as
mathematical and logical problem solving. This is due to the bias introduced by
shallow semantic similarities that fail to capture the deeper reasoning
structures required for these tasks. We present GraphIC, a novel approach that
leverages graph-based representations of reasoning processes, coupled with
Bayesian Networks (BNs) to select ICEs. Graph structures inherently filter out
shallow semantics while preserving the core reasoning structure. Importantly,
BNs capture the dependency of a node's attributes on its parent nodes, closely
mirroring the hierarchical nature of human cognition-where each thought is
shaped by preceding ones. This makes BNs particularly well-suited for
multi-step reasoning tasks, aligning the process more closely with human-like
reasoning. Extensive experiments across three types of reasoning tasks
(mathematical reasoning, code generation, and logical reasoning) demonstrate
that GraphIC outperforms both training-free and training-based models in
selecting ICEs, excelling in terms of both effectiveness and efficiency. We
show that GraphIC enhances ICL's performance and interoperability,
significantly advancing ICE selection for multi-step reasoning tasks.

摘要：<paragraph>情境學習 (ICL) 讓大型語言模型 (LLM) 能夠透過直接在輸入中加入少數情境範例 (ICE)，而無需更新參數，來概化到新的任務中。然而，ICL 的有效性極度仰賴 ICE 的選擇，而傳統的基於文字的嵌入方法通常不足以應付需要多步驟推理的任務，例如數學和邏輯問題解決。這是由於淺層語意相似性帶來的偏差，而這種偏差無法捕捉這些任務所需的更深入推理結構。我們提出 GraphIC，這是一種創新的方法，它利用推理過程的圖形化表徵，結合貝氏網路 (BN) 來選擇 ICE。圖形結構會固有地濾除淺層語意，同時保留核心推理結構。重要的是，BN 捕捉節點屬性對其父節點的依賴性，緊密反映人類認知的階層性質，其中每個想法都是由前一個想法所形塑。這使得 BN 特別適合多步驟推理任務，讓流程更貼近類似人類的推理。橫跨三種類型的推理任務（數學推理、程式碼產生和邏輯推理）的大量實驗證明，GraphIC 在選擇 ICE 時優於無訓練和基於訓練的模型，在有效性和效率方面都表現出色。我們展示了 GraphIC 增強了 ICL 的效能和互操作性，顯著地推進了多步驟推理任務的 ICE 選擇。</paragraph>

##### **G2T-LLM: Graph-to-Tree Text Encoding for Molecule Generation with Fine-Tuned Large Language Models**
2410.02198v1 by Zhaoning Yu, Xiangyang Xu, Hongyang Gao

We introduce G2T-LLM, a novel approach for molecule generation that uses
graph-to-tree text encoding to transform graph-based molecular structures into
a hierarchical text format optimized for large language models (LLMs). This
encoding converts complex molecular graphs into tree-structured formats, such
as JSON and XML, which LLMs are particularly adept at processing due to their
extensive pre-training on these types of data. By leveraging the flexibility of
LLMs, our approach allows for intuitive interaction using natural language
prompts, providing a more accessible interface for molecular design. Through
supervised fine-tuning, G2T-LLM generates valid and coherent chemical
structures, addressing common challenges like invalid outputs seen in
traditional graph-based methods. While LLMs are computationally intensive, they
offer superior generalization and adaptability, enabling the generation of
diverse molecular structures with minimal task-specific customization. The
proposed approach achieved comparable performances with state-of-the-art
methods on various benchmark molecular generation datasets, demonstrating its
potential as a flexible and innovative tool for AI-driven molecular design.

摘要：我們介紹 G2T-LLM，一種針對分子生成的創新方法，它使用圖形轉樹狀文字編碼，將基於圖形的分子結構轉換為階層式文字格式，針對大型語言模型 (LLM) 進行最佳化。此編碼會將複雜的分子圖形轉換為樹狀結構格式，例如 JSON 和 XML，由於 LLM 在這些類型資料的廣泛預先訓練，因此特別擅長處理這些格式。透過利用 LLM 的靈活性，我們的做法允許使用自然語言提示進行直覺式互動，提供一個更容易存取的分子設計介面。透過監督微調，G2T-LLM 會產生有效且連貫的化學結構，解決傳統基於圖形方法中常見的無效輸出等挑戰。雖然 LLM 在計算上很密集，但它們提供優異的概括性和適應性，能夠產生多樣化的分子結構，且任務特定自訂化需求極低。所提出的方法在各種基準分子生成資料集上達到了與最先進方法相當的效能，證明了其作為 AI 驅動分子設計的靈活且創新的工具的潛力。

##### **FLAG: Financial Long Document Classification via AMR-based GNN**
2410.02024v2 by Bolun "Namir" Xia, Mohammed J. Zaki, Aparna Gupta

The advent of large language models (LLMs) has initiated much research into
their various financial applications. However, in applying LLMs on long
documents, semantic relations are not explicitly incorporated, and a full or
arbitrarily sparse attention operation is employed. In recent years, progress
has been made in Abstract Meaning Representation (AMR), which is a graph-based
representation of text to preserve its semantic relations. Since AMR can
represent semantic relationships at a deeper level, it can be beneficially
utilized by graph neural networks (GNNs) for constructing effective
document-level graph representations built upon LLM embeddings to predict
target metrics in the financial domain. We propose FLAG: Financial Long
document classification via AMR-based GNN, an AMR graph based framework to
generate document-level embeddings for long financial document classification.
We construct document-level graphs from sentence-level AMR graphs, endow them
with specialized LLM word embeddings in the financial domain, apply a deep
learning mechanism that utilizes a GNN, and examine the efficacy of our
AMR-based approach in predicting labeled target data from long financial
documents. Extensive experiments are conducted on a dataset of quarterly
earnings calls transcripts of companies in various sectors of the economy, as
well as on a corpus of more recent earnings calls of companies in the S&P 1500
Composite Index. We find that our AMR-based approach outperforms fine-tuning
LLMs directly on text in predicting stock price movement trends at different
time horizons in both datasets. Our work also outperforms previous work
utilizing document graphs and GNNs for text classification.

摘要：大型語言模型 (LLM) 的出現，開啟了對其各種財務應用的大量研究。然而，在長篇文件中應用 LLM 時，語義關係並未被明確納入，並且採用了完全或任意稀疏的注意操作。近年來，抽象意義表示 (AMR) 已取得進展，這是一種基於圖表的文字表示形式，用於保留其語義關係。由於 AMR 能在更深層次表示語義關係，因此可以由圖形神經網路 (GNN) 有效地利用，用於建構建立在 LLM 嵌入上的有效文件級圖形表示，以預測財務領域的目標指標。我們提出 FLAG：透過基於 AMR 的 GNN 進行財務長文件分類，這是一個基於 AMR 圖表的架構，用於為長篇財務文件分類產生文件級嵌入。我們從句子級 AMR 圖表建構文件級圖表，在財務領域賦予它們專業的 LLM 字詞嵌入，應用利用 GNN 的深度學習機制，並檢驗我們基於 AMR 的方法在預測長篇財務文件標記目標資料方面的效能。我們在一個資料集上進行了廣泛的實驗，該資料集包含各個經濟部門公司的每季收益電話會議記錄，以及標普 1500 綜合指數公司最近收益電話會議的語料庫。我們發現，我們的基於 AMR 的方法在預測兩個資料集中的不同時間範圍內的股價變動趨勢方面，優於直接對文字進行微調的 LLM。我們的研究也優於先前利用文件圖表和 GNN 進行文字分類的研究。

##### **Lost-in-Distance: Impact of Contextual Proximity on LLM Performance in Graph Tasks**
2410.01985v1 by Hamed Firooz, Maziar Sanjabi, Wenlong Jiang, Xiaoling Zhai

Despite significant advancements, Large Language Models (LLMs) exhibit blind
spots that impair their ability to retrieve and process relevant contextual
data effectively. We demonstrate that LLM performance in graph tasks with
complexities beyond the "needle-in-a-haystack" scenario-where solving the
problem requires cross-referencing and reasoning across multiple subproblems
jointly-is influenced by the proximity of relevant information within the
context, a phenomenon we term "lost-in-distance". We examine two fundamental
graph tasks: identifying common connections between two nodes and assessing
similarity among three nodes, and show that the model's performance in these
tasks significantly depends on the relative positioning of common edges. We
evaluate three publicly available LLMs-Llama-3-8B, Llama-3-70B, and GPT-4-using
various graph encoding techniques that represent graph structures for LLM
input. We propose a formulation for the lost-in-distance phenomenon and
demonstrate that lost-in-distance and lost-in-the middle phenomenas occur
independently. Results indicate that model accuracy can decline by up to 6x as
the distance between node connections increases, independent of graph encoding
and model size.

摘要：儘管有顯著的進展，大型語言模型（LLM）仍存在盲點，會損害它們有效擷取和處理相關脈絡資料的能力。我們證明了 LLM 在圖形任務中的表現，其複雜度超出了「大海撈針」情境，其中解決問題需要跨多個子問題進行交叉參照和推理，並受到脈絡中相關資訊的接近程度影響，我們將此現象稱為「失之距離」。我們檢驗了兩個基本的圖形任務：識別兩個節點之間的共同連接，以及評估三個節點之間的相似性，並顯示模型在這些任務中的表現顯著地取決於共同邊緣的相對位置。我們評估了三個公開可用的 LLM，分別為 Llama-3-8B、Llama-3-70B 和 GPT-4，使用各種圖形編碼技術，這些技術表示 LLM 輸入的圖形結構。我們提出了失之距離現象的公式，並證明了失之距離和失之於中間現象會獨立發生。結果表明，隨著節點連接之間的距離增加，模型準確度最多可能會下降 6 倍，與圖形編碼和模型大小無關。

##### **LLM+KG@VLDB'24 Workshop Summary**
2410.01978v1 by Arijit Khan, Tianxing Wu, Xi Chen

The unification of large language models (LLMs) and knowledge graphs (KGs)
has emerged as a hot topic. At the LLM+KG'24 workshop, held in conjunction with
VLDB 2024 in Guangzhou, China, one of the key themes explored was important
data management challenges and opportunities due to the effective interaction
between LLMs and KGs. This report outlines the major directions and approaches
presented by various speakers during the LLM+KG'24 workshop.

摘要：大型語言模型 (LLM) 和知識圖譜 (KG) 的統一已成為熱門話題。在中國廣州舉行的 2024 年 VLDB 會議期間舉辦的 LLM+KG'24 研討會上，探索的一個關鍵主題是 LLM 和 KG 之間的有效互動所帶來的重要的數據管理挑戰和機遇。本報告概述了 LLM+KG'24 研討會期間各演講者提出的主要方向和方法。

##### **Conformal Generative Modeling with Improved Sample Efficiency through Sequential Greedy Filtering**
2410.01660v1 by Klaus-Rudolf Kladny, Bernhard Schölkopf, Michael Muehlebach

Generative models lack rigorous statistical guarantees for their outputs and
are therefore unreliable in safety-critical applications. In this work, we
propose Sequential Conformal Prediction for Generative Models (SCOPE-Gen), a
sequential conformal prediction method producing prediction sets that satisfy a
rigorous statistical guarantee called conformal admissibility control. This
guarantee states that with high probability, the prediction sets contain at
least one admissible (or valid) example. To this end, our method first samples
an initial set of i.i.d. examples from a black box generative model. Then, this
set is iteratively pruned via so-called greedy filters. As a consequence of the
iterative generation procedure, admissibility of the final prediction set
factorizes as a Markov chain. This factorization is crucial, because it allows
to control each factor separately, using conformal prediction. In comparison to
prior work, our method demonstrates a large reduction in the number of
admissibility evaluations during calibration. This reduction is important in
safety-critical applications, where these evaluations must be conducted
manually by domain experts and are therefore costly and time consuming. We
highlight the advantages of our method in terms of admissibility evaluations
and cardinality of the prediction sets through experiments in natural language
generation and molecular graph extension tasks.

摘要：生成模型缺乏對其輸出進行嚴格的統計保證，因此在安全關鍵應用中不可靠。在這項工作中，我們提出了生成模型的順序共形預測 (SCOPE-Gen)，這是一種順序共形預測方法，產生滿足稱為共形可採性控制的嚴格統計保證的預測集。此保證表示，預測集在高機率下至少包含一個可採 (或有效) 的範例。為此，我們的模型首先從黑盒生成模型中抽取一組 i.i.d. 範例。然後，透過所謂的貪婪過濾器反覆修剪此組。作為反覆生成程序的結果，最終預測集的可採性分解為馬可夫鏈。此分解至關重要，因為它允許使用共形預測分別控制每個因子。與先前的工作相比，我們的模型顯示在校準過程中可大幅減少可採性評估的數量。此減少在安全關鍵應用中很重要，在這些應用中，這些評估必須由領域專家手動進行，因此成本高昂且耗時。我們透過自然語言生成和分子圖形延伸任務中的實驗，突顯我們的模型在可採性評估和預測集基數方面的優點。

##### **HiReview: Hierarchical Taxonomy-Driven Automatic Literature Review Generation**
2410.03761v1 by Yuntong Hu, Zhuofeng Li, Zheng Zhang, Chen Ling, Raasikh Kanjiani, Boxin Zhao, Liang Zhao

In this work, we present HiReview, a novel framework for hierarchical
taxonomy-driven automatic literature review generation. With the exponential
growth of academic documents, manual literature reviews have become
increasingly labor-intensive and time-consuming, while traditional
summarization models struggle to generate comprehensive document reviews
effectively. Large language models (LLMs), with their powerful text processing
capabilities, offer a potential solution; however, research on incorporating
LLMs for automatic document generation remains limited. To address key
challenges in large-scale automatic literature review generation (LRG), we
propose a two-stage taxonomy-then-generation approach that combines graph-based
hierarchical clustering with retrieval-augmented LLMs. First, we retrieve the
most relevant sub-community within the citation network, then generate a
hierarchical taxonomy tree by clustering papers based on both textual content
and citation relationships. In the second stage, an LLM generates coherent and
contextually accurate summaries for clusters or topics at each hierarchical
level, ensuring comprehensive coverage and logical organization of the
literature. Extensive experiments demonstrate that HiReview significantly
outperforms state-of-the-art methods, achieving superior hierarchical
organization, content relevance, and factual accuracy in automatic literature
review generation tasks.

摘要：在本文中，我們提出了 HiReview，一個用於分層分類驅動的自動文獻回顧生成的全新框架。隨著學術文獻的指數級增長，手動文獻回顧變得越來越勞動密集且耗時，而傳統的摘要模型難以有效地生成全面的文件回顧。大型語言模型 (LLM) 憑藉其強大的文本處理能力提供了一個潛在的解決方案；然而，將 LLM 納入自動文件生成的研究仍然有限。為了應對大規模自動文獻回顧生成 (LRG) 中的主要挑戰，我們提出了一種兩階段的分類再生成方法，該方法將基於圖形的層次聚類與檢索增強的 LLM 相結合。首先，我們檢索引文網路中最相關的子社群，然後根據文本內容和引文關係對論文進行聚類，生成一個分層分類樹。在第二階段，LLM 為每個層級的群集或主題生成連貫且在語境上準確的摘要，確保文獻的全面覆蓋和邏輯組織。廣泛的實驗表明，HiReview 明顯優於最先進的方法，在自動文獻回顧生成任務中實現了出色的層次組織、內容相關性和事實準確性。

##### **LEGO: Learnable Expansion of Graph Operators for Multi-Modal Feature Fusion**
2410.01506v2 by Dexuan Ding, Lei Wang, Liyun Zhu, Tom Gedeon, Piotr Koniusz

In computer vision tasks, features often come from diverse representations,
domains, and modalities, such as text, images, and videos. Effectively fusing
these features is essential for robust performance, especially with the
availability of powerful pre-trained models like vision-language models.
However, common fusion methods, such as concatenation, element-wise operations,
and non-linear techniques, often fail to capture structural relationships, deep
feature interactions, and suffer from inefficiency or misalignment of features
across domains. In this paper, we shift from high-dimensional feature space to
a lower-dimensional, interpretable graph space by constructing similarity
graphs that encode feature relationships at different levels, e.g., clip,
frame, patch, token, etc. To capture deeper interactions, we use graph power
expansions and introduce a learnable graph fusion operator to combine these
graph powers for more effective fusion. Our approach is relationship-centric,
operates in a homogeneous space, and is mathematically principled, resembling
element-wise similarity score aggregation via multilinear polynomials. We
demonstrate the effectiveness of our graph-based fusion method on video anomaly
detection, showing strong performance across multi-representational,
multi-modal, and multi-domain feature fusion tasks.

摘要：<paragraph>在電腦視覺任務中，特徵通常來自不同的表示、
領域和模式，例如文字、影像和影片。有效融合
這些特徵對於強健的效能至關重要，特別是在
具備強大預訓練模型（例如視覺語言模型）的情況下。
然而，常見的融合方法，例如串接、逐元素運算，
和非線性技術，通常無法捕捉結構關係、深度
特徵互動，並且會受到非效率或特徵在不同領域中未對齊的影響。在本文中，我們從高維特徵空間轉移到
低維、可解釋的圖形空間，透過建構相似性
圖形來編碼不同層級的特徵關係，例如剪輯、
影格、貼片、標記等。為了捕捉更深入的互動，我們使用圖形冪
展開，並引入可學習的圖形融合運算子，以結合這些
圖形冪，以實現更有效的融合。我們的做法以關係為中心，
在同質空間中運作，並且具有數學原理，類似於
透過多線性多項式進行逐元素相似度分數聚合。我們
在影片異常偵測中展示了基於圖形的融合方法的有效性，在多表示、
多模式和多領域特徵融合任務中展現強大的效能。</paragraph>

##### **Question-guided Knowledge Graph Re-scoring and Injection for Knowledge Graph Question Answering**
2410.01401v1 by Yu Zhang, Kehai Chen, Xuefeng Bai, zhao kang, Quanjiang Guo, Min Zhang

Knowledge graph question answering (KGQA) involves answering natural language
questions by leveraging structured information stored in a knowledge graph.
Typically, KGQA initially retrieve a targeted subgraph from a large-scale
knowledge graph, which serves as the basis for reasoning models to address
queries. However, the retrieved subgraph inevitably brings distraction
information for knowledge utilization, impeding the model's ability to perform
accurate reasoning. To address this issue, we propose a Question-guided
Knowledge Graph Re-scoring method (Q-KGR) to eliminate noisy pathways for the
input question, thereby focusing specifically on pertinent factual knowledge.
Moreover, we introduce Knowformer, a parameter-efficient method for injecting
the re-scored knowledge graph into large language models to enhance their
ability to perform factual reasoning. Extensive experiments on multiple KGQA
benchmarks demonstrate the superiority of our method over existing systems.

摘要：知識圖表問答 (KGQA) 涉及利用儲存在知識圖表中的結構化資訊來回答自然語言問題。通常，KGQA 最初會從大規模知識圖表中擷取目標子圖，作為推理模型處理查詢的基礎。然而，擷取的子圖難免會帶來雜訊資訊，阻礙模型執行精確推理的能力。為了解決這個問題，我們提出了一個問題導向知識圖表重新評分方法 (Q-KGR)，以消除輸入問題的雜訊路徑，從而專注於相關的事實知識。此外，我們引入了 Knowformer，這是一種參數效率高的方法，用於將重新評分的知識圖表注入大型語言模型，以增強它們執行事實推理的能力。在多個 KGQA 基準上的廣泛實驗證明了我們的方法優於現有系統。

##### **Unveiling Language Skills under Circuits**
2410.01334v1 by Hang Chen, Jiaying Zhu, Xinyu Yang, Wenya Wang

The exploration of language skills in language models (LMs) has always been
one of the central goals in mechanistic interpretability. However, existing
circuit analyses often fall short in representing the full functional scope of
these models, primarily due to the exclusion of Feed-Forward layers.
Additionally, isolating the effect of a single language skill from a text,
which inherently involves multiple entangled skills, poses a significant
challenge. To address these gaps, we introduce a novel concept, Memory Circuit,
a minimum unit that fully and independently manipulates the memory-reading
functionality of a language model, and disentangle the transformer model
precisely into a circuit graph which is an ensemble of paths connecting
different memory circuits. Based on this disentanglement, we identify salient
circuit paths, named as skill paths, responsible for three crucial language
skills, i.e., the Previous Token Skill, Induction Skill and In-Context Learning
(ICL) Skill, leveraging causal effect estimation through interventions and
counterfactuals. Our experiments on various datasets confirm the correspondence
between our identified skill paths and language skills, and validate three
longstanding hypotheses: 1) Language skills are identifiable through circuit
dissection; 2) Simple language skills reside in shallow layers, whereas complex
language skills are found in deeper layers; 3) Complex language skills are
formed on top of simpler language skills. Our codes are available at:
https://github.com/Zodiark-ch/Language-Skill-of-LLMs.

摘要：<paragraph>在語言模型 (LM) 中探索語言技能一直是機械可解釋性的核心目標之一。然而，現有的電路分析往往無法表示這些模型的全部功能範圍，主要是由於排除了前饋層。此外，從文本中分離出單一語言技能的影響（這本質上涉及多種糾纏的技能）構成了一項重大挑戰。為了解決這些差距，我們引入了 Memory Circuit，這是一個新穎的概念，它是一個最小單元，可以完整且獨立地操作語言模型的記憶體讀取功能，並將 Transformer 模型精確地解開成一個電路圖，它是一個連接不同記憶體電路的路徑集合。基於這種解開，我們識別出顯著的電路路徑，稱為技能路徑，它負責三項關鍵的語言技能，即前一個符號技能、歸納技能和語境學習 (ICL) 技能，利用因果效應估計通過干預和反事實。我們在各種資料集上的實驗證實了我們識別出的技能路徑與語言技能之間的對應關係，並驗證了三個長期的假設：1) 語言技能可以透過電路解剖來識別；2) 簡單的語言技能存在於淺層中，而複雜的語言技能則存在於深層中；3) 複雜的語言技能建立在更簡單的語言技能之上。我們的程式碼可在 https://github.com/Zodiark-ch/Language-Skill-of-LLMs 取得。</paragraph>

##### **From Natural Language to SQL: Review of LLM-based Text-to-SQL Systems**
2410.01066v1 by Ali Mohammadjafari, Anthony S. Maida, Raju Gottumukkala

Since the onset of LLMs, translating natural language queries to structured
SQL commands is assuming increasing. Unlike the previous reviews, this survey
provides a comprehensive study of the evolution of LLM-based text-to-SQL
systems, from early rule-based models to advanced LLM approaches, and how LLMs
impacted this field. We discuss benchmarks, evaluation methods and evaluation
metrics. Also, we uniquely study the role of integration of knowledge graphs
for better contextual accuracy and schema linking in these systems. The current
techniques fall into two categories: in-context learning of corpus and
fine-tuning, which then leads to approaches such as zero-shot, few-shot
learning from the end, and data augmentation. Finally, we highlight key
challenges such as computational efficiency, model robustness, and data privacy
with perspectives toward their development and improvements in potential areas
for future of LLM-based text-to-SQL system.

摘要：自 LLM 出現以來，將自然語言查詢轉換為結構化 SQL 指令正變得越來越普遍。與先前的評論不同，本調查對基於 LLM 的文字轉 SQL 系統的演變進行了全面的研究，從早期的基於規則的模型到先進的 LLM 方法，以及 LLM 如何影響這個領域。我們討論了基準、評估方法和評估指標。此外，我們還獨特地研究了知識圖譜整合在這些系統中發揮的作用，以提高語境準確性和模式連結。目前的技術分為兩類：語料庫的語境學習和微調，這進而導致了零次學習、少次學習等方法，最後是資料擴充。最後，我們重點介紹了計算效率、模型穩健性和資料隱私等關鍵挑戰，並展望了它們在未來基於 LLM 的文字轉 SQL 系統的發展和改進的潛在領域。

##### **GUNDAM: Aligning Large Language Models with Graph Understanding**
2409.20053v2 by Sheng Ouyang, Yulan Hu, Ge Chen, Yong Liu

Large Language Models (LLMs) have achieved impressive results in processing
text data, which has sparked interest in applying these models beyond textual
data, such as graphs. In the field of graph learning, there is a growing
interest in harnessing LLMs to comprehend and manipulate graph-structured data.
Existing research predominantly focuses on graphs with rich textual features,
such as knowledge graphs or text attribute graphs, leveraging LLMs' ability to
process text but inadequately addressing graph structure. This work
specifically aims to assess and enhance LLMs' abilities to comprehend and
utilize the structural knowledge inherent in graph data itself, rather than
focusing solely on graphs rich in textual content. To achieve this, we
introduce the \textbf{G}raph \textbf{U}nderstanding for \textbf{N}atural
Language \textbf{D}riven \textbf{A}nalytical \textbf{M}odel (\model). This
model adapts LLMs to better understand and engage with the structure of graph
data, enabling them to perform complex reasoning tasks by leveraging the
graph's structure itself. Our experimental evaluations on graph reasoning
benchmarks not only substantiate that \model~ outperforms the SOTA baselines
for comparisons. But also reveals key factors affecting the graph reasoning
capabilities of LLMs. Moreover, we provide a theoretical analysis illustrating
how reasoning paths can enhance LLMs' reasoning capabilities.

摘要：大型語言模型 (LLM) 在處理文字資料方面取得令人印象深刻的成果，這激發了將這些模型應用於文字資料以外領域的興趣，例如圖表。在圖表學習領域，利用 LLM 來理解和處理圖形結構資料的興趣與日俱增。現有的研究主要集中於具有豐富文字特徵的圖表，例如知識圖表或文字屬性圖表，利用 LLM 處理文字的能力，但未能充分解決圖表結構。這項工作特別旨在評估和增強 LLM 理解和利用圖表資料本身固有結構知識的能力，而不是僅專注於富含文字內容的圖表。為此，我們引入了自然語言驅動分析模型 (\model) 的圖表理解。此模型調整 LLM 以便更好地理解和參與圖表資料的結構，使它們能夠通過利用圖表的結構本身來執行複雜的推理任務。我們在圖表推理基準上的實驗評估不僅證實 \model~ 優於比較中的 SOTA 基準。還揭示了影響 LLM 圖表推理能力的主要因素。此外，我們提供了理論分析，說明推理路徑如何增強 LLM 的推理能力。

##### **Enhancing High-order Interaction Awareness in LLM-based Recommender Model**
2409.19979v2 by Xinfeng Wang, Jin Cui, Fumiyo Fukumoto, Yoshimi Suzuki

Large language models (LLMs) have demonstrated prominent reasoning
capabilities in recommendation tasks by transforming them into text-generation
tasks. However, existing approaches either disregard or ineffectively model the
user-item high-order interactions. To this end, this paper presents an enhanced
LLM-based recommender (ELMRec). We enhance whole-word embeddings to
substantially enhance LLMs' interpretation of graph-constructed interactions
for recommendations, without requiring graph pre-training. This finding may
inspire endeavors to incorporate rich knowledge graphs into LLM-based
recommenders via whole-word embedding. We also found that LLMs often recommend
items based on users' earlier interactions rather than recent ones, and present
a reranking solution. Our ELMRec outperforms state-of-the-art (SOTA) methods in
both direct and sequential recommendations.

摘要：大型語言模型 (LLM) 已證明在推薦任務中具有顯著的推理能力，方法是將其轉換為文本生成任務。然而，現有方法不是忽略用戶項目高階互動，就是對其建模效果不佳。為此，本文提出了一種增強的基於 LLM 的推薦器 (ELMRec)。我們增強了全詞嵌入，以大幅增強 LLM 對圖形構建互動的解讀，用於推薦，而不需要圖形預訓練。這一發現可能會激勵將豐富的知識圖譜通過全詞嵌入整合到基於 LLM 的推薦器中的努力。我們還發現，LLM 通常根據用戶早期的互動而非最近的互動來推薦項目，並提出了一種重新排序的解決方案。我們的 ELMRec 在直接和順序推薦中都優於最先進 (SOTA) 方法。

##### **CoTKR: Chain-of-Thought Enhanced Knowledge Rewriting for Complex Knowledge Graph Question Answering**
2409.19753v2 by Yike Wu, Yi Huang, Nan Hu, Yuncheng Hua, Guilin Qi, Jiaoyan Chen, Jeff Z. Pan

Recent studies have explored the use of Large Language Models (LLMs) with
Retrieval Augmented Generation (RAG) for Knowledge Graph Question Answering
(KGQA). They typically require rewriting retrieved subgraphs into natural
language formats comprehensible to LLMs. However, when tackling complex
questions, the knowledge rewritten by existing methods may include irrelevant
information, omit crucial details, or fail to align with the question's
semantics. To address them, we propose a novel rewriting method CoTKR,
Chain-of-Thought Enhanced Knowledge Rewriting, for generating reasoning traces
and corresponding knowledge in an interleaved manner, thereby mitigating the
limitations of single-step knowledge rewriting. Additionally, to bridge the
preference gap between the knowledge rewriter and the question answering (QA)
model, we propose a training strategy PAQAF, Preference Alignment from Question
Answering Feedback, for leveraging feedback from the QA model to further
optimize the knowledge rewriter. We conduct experiments using various LLMs
across several KGQA benchmarks. Experimental results demonstrate that, compared
with previous knowledge rewriting methods, CoTKR generates the most beneficial
knowledge representation for QA models, which significantly improves the
performance of LLMs in KGQA.

摘要：最近的研究探索了將大型語言模型 (LLM) 與檢索擴增生成 (RAG) 結合用於知識圖表問答 (KGQA)。它們通常需要將檢索到的子圖改寫成 LLM 可以理解的自然語言格式。然而，在處理複雜問題時，現有方法改寫的知識可能包含不相關的資訊、遺漏關鍵細節，或無法與問題的語義對齊。為了解決這些問題，我們提出了一種新的改寫方法 CoTKR，即基於思考鏈的知識增強改寫，用於交錯生成推理軌跡和對應的知識，從而減輕單步知識改寫的限制。此外，為了彌合知識改寫器和問答 (QA) 模型之間的偏好差距，我們提出了一種訓練策略 PAQAF，即基於問答回饋的偏好對齊，用於利用 QA 模型的回饋進一步最佳化知識改寫器。我們使用各種 LLM 在多個 KGQA 基準上進行了實驗。實驗結果表明，與先前的知識改寫方法相比，CoTKR 為 QA 模型生成了最有益的知識表示，這顯著提高了 LLM 在 KGQA 中的效能。

##### **Can Large Language Models Analyze Graphs like Professionals? A Benchmark, Datasets and Models**
2409.19667v1 by Xin Li, Weize Chen, Qizhi Chu, Haopeng Li, Zhaojun Sun, Ran Li, Chen Qian, Yiwei Wei, Zhiyuan Liu, Chuan Shi, Maosong Sun, Cheng Yang

The need to analyze graphs is ubiquitous across various fields, from social
networks to biological research and recommendation systems. Therefore, enabling
the ability of large language models (LLMs) to process graphs is an important
step toward more advanced general intelligence. However, current LLM benchmarks
on graph analysis require models to directly reason over the prompts describing
graph topology, and are thus limited to small graphs with only a few dozens of
nodes. In contrast, human experts typically write programs based on popular
libraries for task solving, and can thus handle graphs with different scales.
To this end, a question naturally arises: can LLMs analyze graphs like
professionals? In this paper, we introduce ProGraph, a manually crafted
benchmark containing 3 categories of graph tasks. The benchmark expects
solutions based on programming instead of directly reasoning over raw inputs.
Our findings reveal that the performance of current LLMs is unsatisfactory,
with the best model achieving only 36% accuracy. To bridge this gap, we propose
LLM4Graph datasets, which include crawled documents and auto-generated codes
based on 6 widely used graph libraries. By augmenting closed-source LLMs with
document retrieval and fine-tuning open-source ones on the codes, we show
11-32% absolute improvements in their accuracies. Our results underscore that
the capabilities of LLMs in handling structured data are still under-explored,
and show the effectiveness of LLM4Graph in enhancing LLMs' proficiency of graph
analysis. The benchmark, datasets and enhanced open-source models are available
at https://github.com/BUPT-GAMMA/ProGraph.

摘要：<paragraph>在從社交網路到生物研究和推薦系統的各種領域中，分析圖形的需求無處不在。因此，賦予大型語言模型 (LLM) 處理圖形的能力，是邁向更先進的通用智慧的重要一步。然而，目前圖形分析上的 LLM 基準要求模型直接對描述圖形拓撲結構的提示進行推理，因此僅限於只有數十個節點的小型圖形。相比之下，人類專家通常會根據流行的函式庫撰寫程式來解決任務，因此可以處理不同規模的圖形。為此，自然會產生一個問題：LLM 能像專業人士一樣分析圖形嗎？在本文中，我們介紹 ProGraph，一個包含 3 類圖形任務的手工製作基準。該基準預期解決方案是基於程式設計，而不是直接對原始輸入進行推理。我們的發現顯示，目前 LLM 的效能並不令人滿意，最佳模型僅達到 36% 的準確度。為了彌補這個差距，我們提出了 LLM4Graph 資料集，其中包含根據 6 個廣泛使用的圖形函式庫爬取的的文件和自動生成的程式碼。透過使用文件檢索來擴充閉源 LLM，並針對程式碼微調開源 LLM，我們展示了準確度提升了 11-32%。我們的結果強調，LLM 在處理結構化資料方面的能力仍未被充分探索，並顯示了 LLM4Graph 在提升 LLM 圖形分析能力方面的有效性。基準、資料集和增強的開源模型可在 https://github.com/BUPT-GAMMA/ProGraph 取得。</paragraph>

##### **Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs**
2409.19401v1 by Zheng Wang, Zhongyang Li, Zeren Jiang, Dandan Tu, Wei Shi

In the age of mobile internet, user data, often referred to as memories, is
continuously generated on personal devices. Effectively managing and utilizing
this data to deliver services to users is a compelling research topic. In this
paper, we introduce a novel task of crafting personalized agents powered by
large language models (LLMs), which utilize a user's smartphone memories to
enhance downstream applications with advanced LLM capabilities. To achieve this
goal, we introduce EMG-RAG, a solution that combines Retrieval-Augmented
Generation (RAG) techniques with an Editable Memory Graph (EMG). This approach
is further optimized using Reinforcement Learning to address three distinct
challenges: data collection, editability, and selectability. Extensive
experiments on a real-world dataset validate the effectiveness of EMG-RAG,
achieving an improvement of approximately 10% over the best existing approach.
Additionally, the personalized agents have been transferred into a real
smartphone AI assistant, which leads to enhanced usability.

摘要：在行動網路時代，使用者資料（常稱為記憶）會持續在個人裝置上產生。有效管理並利用這些資料，為使用者提供服務，是一個引人入勝的研究主題。在本文中，我們介紹了一項創新的任務，即利用大型語言模型（LLM）打造個人化代理，利用使用者的智慧型手機記憶體，以進階 LLM 功能強化下游應用程式。為了達成這個目標，我們介紹了 EMG-RAG，一種結合檢索擴充生成（RAG）技術與可編輯記憶圖（EMG）的解決方案。這種方法進一步透過強化學習進行最佳化，以解決三個不同的挑戰：資料收集、可編輯性與可選擇性。在真實世界資料集上的廣泛實驗驗證了 EMG-RAG 的有效性，比現有最佳方法提升了約 10%。此外，個人化代理已轉移到真正的智慧型手機 AI 助理中，這提升了可用性。

##### **CLLMate: A Multimodal LLM for Weather and Climate Events Forecasting**
2409.19058v1 by Haobo Li, Zhaowei Wang, Jiachen Wang, Alexis Kai Hon Lau, Huamin Qu

Forecasting weather and climate events is crucial for making appropriate
measures to mitigate environmental hazards and minimize associated losses.
Previous research on environmental forecasting focuses on predicting numerical
meteorological variables related to closed-set events rather than forecasting
open-set events directly, which limits the comprehensiveness of event
forecasting. We propose Weather and Climate Event Forecasting (WCEF), a new
task that leverages meteorological raster data and textual event data to
predict potential weather and climate events. However, due to difficulties in
aligning multimodal data and the lack of sufficient supervised datasets, this
task is challenging to accomplish. Therefore, we first propose a framework to
align historical meteorological data with past weather and climate events using
the large language model (LLM). In this framework, we construct a knowledge
graph by using LLM to extract information about weather and climate events from
a corpus of over 41k highly environment-focused news articles. Subsequently, we
mapped these events with meteorological raster data, creating a supervised
dataset, which is the largest and most novel for LLM tuning on the WCEF task.
Finally, we introduced our aligned models, CLLMate (LLM for climate), a
multimodal LLM to forecast weather and climate events using meteorological
raster data. In evaluating CLLMate, we conducted extensive experiments. The
results indicate that CLLMate surpasses both the baselines and other multimodal
LLMs, showcasing the potential of utilizing LLM to align weather and climate
events with meteorological data and highlighting the promising future for
research on the WCEF task.

摘要：預測天氣和氣候事件對於採取適當措施減輕環境危害和將相關損失降至最低至關重要。
先前有關環境預測的研究著重於預測與封閉集事件相關的數值氣象變數，而非直接預測開放集事件，這限制了事件預測的全面性。
我們提出天氣和氣候事件預測 (WCEF)，這是一項利用氣象柵格資料和文字事件資料來預測潛在天氣和氣候事件的新任務。
然而，由於多模態資料對齊的困難以及缺乏足夠的監督式資料集，因此此任務難以達成。
因此，我們首先提出一個架構，使用大型語言模型 (LLM) 將歷史氣象資料與過去的天氣和氣候事件對齊。
在此架構中，我們透過使用 LLM 從超過 41,000 篇高度關注環境的新聞文章中擷取有關天氣和氣候事件的資訊來建構知識圖譜。
隨後，我們將這些事件對應到氣象柵格資料，建立一個監督式資料集，這是 LLM 在 WCEF 任務上調整中最大且最新穎的資料集。
最後，我們引入了我們的對齊模型，CLLMate（氣候的 LLM），這是一個多模態 LLM，使用氣象柵格資料來預測天氣和氣候事件。
在評估 CLLMate 時，我們進行了大量的實驗。
結果表明，CLLMate 超越了基準和其他的多模態 LLM，展示了利用 LLM 將天氣和氣候事件與氣象資料對齊的潛力，並強調了 WCEF 任務研究的未來前景。

##### **AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow**
2409.18924v2 by Huizi Yu, Jiayan Zhou, Lingyao Li, Shan Chen, Jack Gallifant, Anye Shi, Xiang Li, Wenyue Hua, Mingyu Jin, Guang Chen, Yang Zhou, Zhao Li, Trisha Gupte, Ming-Li Chen, Zahra Azizi, Yongfeng Zhang, Themistocles L. Assimes, Xin Ma, Danielle S. Bitterman, Lin Lu, Lizhou Fan

Simulated patient systems play a crucial role in modern medical education and
research, providing safe, integrative learning environments and enabling
clinical decision-making simulations. Large Language Models (LLM) could advance
simulated patient systems by replicating medical conditions and patient-doctor
interactions with high fidelity and low cost. However, ensuring the
effectiveness and trustworthiness of these systems remains a challenge, as they
require a large, diverse, and precise patient knowledgebase, along with a
robust and stable knowledge diffusion to users. Here, we developed AIPatient,
an advanced simulated patient system with AIPatient Knowledge Graph (AIPatient
KG) as the input and the Reasoning Retrieval-Augmented Generation (Reasoning
RAG) agentic workflow as the generation backbone. AIPatient KG samples data
from Electronic Health Records (EHRs) in the Medical Information Mart for
Intensive Care (MIMIC)-III database, producing a clinically diverse and
relevant cohort of 1,495 patients with high knowledgebase validity (F1 0.89).
Reasoning RAG leverages six LLM powered agents spanning tasks including
retrieval, KG query generation, abstraction, checker, rewrite, and
summarization. This agentic framework reaches an overall accuracy of 94.15% in
EHR-based medical Question Answering (QA), outperforming benchmarks that use
either no agent or only partial agent integration. Our system also presents
high readability (median Flesch Reading Ease 77.23; median Flesch Kincaid Grade
5.6), robustness (ANOVA F-value 0.6126, p>0.1), and stability (ANOVA F-value
0.782, p>0.1). The promising performance of the AIPatient system highlights its
potential to support a wide range of applications, including medical education,
model evaluation, and system integration.

摘要：模擬病人系統在現代醫學教育和研究中扮演著至關重要的角色，提供安全、整合的學習環境，並能進行臨床決策模擬。大型語言模型 (LLM) 能透過高保真度和低成本複製醫療狀況和醫病互動，進而提升模擬病人系統。然而，確保這些系統的有效性和可信度仍然是一項挑戰，因為它們需要一個龐大、多元且精確的病人知識庫，以及穩健且穩定的知識傳播給使用者。在此，我們開發了 AIPatient，一個進階的模擬病人系統，以 AIPatient 知識圖譜 (AIPatient KG) 作為輸入，並以推理檢索增強生成 (Reasoning RAG) 代理工作流程作為生成主幹。AIPatient KG 從重症監護醫學資訊中心 (MIMIC)-III 資料庫中的電子健康紀錄 (EHR) 中抽取資料，產生一個臨床多樣且相關的 1,495 名病患群組，具有很高的知識庫效度 (F1 0.89)。推理 RAG 槓桿了六個 LLM 驅動的代理，跨越檢索、KG 查詢產生、抽象、檢查器、重寫和摘要等任務。這個代理框架在基於 EHR 的醫療問答 (QA) 中達到了 94.15% 的整體準確度，優於不使用代理或僅部分代理整合的基準。我們的系統還具有很高的可讀性 (Flesch 閱讀簡便性中位數 77.23；Flesch Kincaid 等級中位數 5.6)、穩健性 (ANOVA F 值 0.6126，p>0.1) 和穩定性 (ANOVA F 值 0.782，p>0.1)。AIPatient 系統的出色表現突顯了它在支援各種應用程式的潛力，包括醫學教育、模型評估和系統整合。

##### **Soft Measures for Extracting Causal Collective Intelligence**
2409.18911v1 by Maryam Berijanian, Spencer Dork, Kuldeep Singh, Michael Riley Millikan, Ashlin Riggs, Aadarsh Swaminathan, Sarah L. Gibbs, Scott E. Friedman, Nathan Brugnone

Understanding and modeling collective intelligence is essential for
addressing complex social systems. Directed graphs called fuzzy cognitive maps
(FCMs) offer a powerful tool for encoding causal mental models, but extracting
high-integrity FCMs from text is challenging. This study presents an approach
using large language models (LLMs) to automate FCM extraction. We introduce
novel graph-based similarity measures and evaluate them by correlating their
outputs with human judgments through the Elo rating system. Results show
positive correlations with human evaluations, but even the best-performing
measure exhibits limitations in capturing FCM nuances. Fine-tuning LLMs
improves performance, but existing measures still fall short. This study
highlights the need for soft similarity measures tailored to FCM extraction,
advancing collective intelligence modeling with NLP.

摘要：了解和建模集体智慧对于解决复杂的社会系统至关重要。称为模糊认知图（FCM）的有向图提供了一种强大的工具来编码因果心智模型，但从文本中提取高完整性的 FCM 具有挑战性。本研究提出了一种使用大型语言模型（LLM）来自动化 FCM 提取的方法。我们引入了新颖的基于图的相似性度量，并通过通过 Elo 评级系统将其输出与人类判断相关联来评估它们。结果表明与人类评估呈正相关，但即使是表现最好的度量在捕捉 FCM 细微差别方面也表现出局限性。微调 LLM 可以提高性能，但现有措施仍然不足。本研究强调了针对 FCM 提取量身定制的软相似性度量的必要性，通过 NLP 推进了集体智能建模。

##### **OpenObject-NAV: Open-Vocabulary Object-Oriented Navigation Based on Dynamic Carrier-Relationship Scene Graph**
2409.18743v1 by Yujie Tang, Meiling Wang, Yinan Deng, Zibo Zheng, Jiagui Zhong, Yufeng Yue

In everyday life, frequently used objects like cups often have unfixed
positions and multiple instances within the same category, and their carriers
frequently change as well. As a result, it becomes challenging for a robot to
efficiently navigate to a specific instance. To tackle this challenge, the
robot must capture and update scene changes and plans continuously. However,
current object navigation approaches primarily focus on semantic-level and lack
the ability to dynamically update scene representation. This paper captures the
relationships between frequently used objects and their static carriers. It
constructs an open-vocabulary Carrier-Relationship Scene Graph (CRSG) and
updates the carrying status during robot navigation to reflect the dynamic
changes of the scene. Based on the CRSG, we further propose an instance
navigation strategy that models the navigation process as a Markov Decision
Process. At each step, decisions are informed by Large Language Model's
commonsense knowledge and visual-language feature similarity. We designed a
series of long-sequence navigation tasks for frequently used everyday items in
the Habitat simulator. The results demonstrate that by updating the CRSG, the
robot can efficiently navigate to moved targets. Additionally, we deployed our
algorithm on a real robot and validated its practical effectiveness.

摘要：日常生活中，經常使用的物品（例如杯子）通常沒有固定的位置，而且同一類別中有多個實例，其承載者也經常變更。因此，機器人要有效地導航到特定實例變得具有挑戰性。為了應對這一挑戰，機器人必須不斷捕捉和更新場景變更和計畫。然而，目前的物件導航方法主要集中在語義層級，並且缺乏動態更新場景表示的能力。本文捕捉了經常使用的物件及其靜態承載者之間的關係。它構建了一個開放詞彙的承載者關係場景圖 (CRSG)，並在機器人導航期間更新承載狀態以反映場景的動態變化。基於 CRSG，我們進一步提出了一種將導航過程建模為馬可夫決策過程的實例導航策略。在每一步中，決策都由大型語言模型的常識知識和視覺語言特徵相似性來告知。我們為 Habitat 模擬器中的日常常用物品設計了一系列長序列導航任務。結果表明，通過更新 CRSG，機器人可以有效地導航到移動的目標。此外，我們在真實機器人上部署了我們的演算法，並驗證了其實際效能。

##### **Rehearsing Answers to Probable Questions with Perspective-Taking**
2409.18678v1 by Yung-Yu Shih, Ziwei Xu, Hiroya Takamura, Yun-Nung Chen, Chung-Chi Chen

Question answering (QA) has been a long-standing focus in the NLP field,
predominantly addressing reading comprehension and common sense QA. However,
scenarios involving the preparation of answers to probable questions during
professional oral presentations remain underexplored. In this paper, we pioneer
the examination of this crucial yet overlooked topic by utilizing real-world QA
conversation transcripts between company managers and professional analysts. We
explore the proposed task using three causal knowledge graphs (KGs) and three
large language models (LLMs). This work provides foundational insights into the
application of LLMs in professional QA scenarios, highlighting the importance
of causal KGs and perspective-taking in generating effective responses.

摘要：問題解答 (QA) 一直是自然語言處理 (NLP) 領域的長期關注重點，
主要解決閱讀理解和常識問題解答。然而，
在專業口頭簡報中準備回答可能問題的場景仍未得到充分探討。在本文中，我們率先
利用公司經理和專業分析師之間的真實世界問答對話記錄，探討這個至關重要但被忽視的主題。我們
使用三個因果知識圖譜 (KG) 和三個大型語言模型 (LLM) 來探討提出的任務。這項工作為 LLM 在專業問答場景中的應用提供了基礎見解，強調了因果 KG 和觀點採取在產生有效回應中的重要性。

##### **LowREm: A Repository of Word Embeddings for 87 Low-Resource Languages Enhanced with Multilingual Graph Knowledge**
2409.18193v1 by Daniil Gurgurov, Rishu Kumar, Simon Ostermann

Contextualized embeddings based on large language models (LLMs) are available
for various languages, but their coverage is often limited for lower resourced
languages. Training LLMs for such languages is often difficult due to
insufficient data and high computational cost. Especially for very low resource
languages, static word embeddings thus still offer a viable alternative. There
is, however, a notable lack of comprehensive repositories with such embeddings
for diverse languages. To address this, we present LowREm, a centralized
repository of static embeddings for 87 low-resource languages. We also propose
a novel method to enhance GloVe-based embeddings by integrating multilingual
graph knowledge, utilizing another source of knowledge. We demonstrate the
superior performance of our enhanced embeddings as compared to contextualized
embeddings extracted from XLM-R on sentiment analysis. Our code and data are
publicly available under https://huggingface.co/DFKI.

摘要：基於大型語言模型 (LLM) 的語境化嵌入可供各種語言使用，但其涵蓋範圍通常僅限於資源較少的語言。由於資料不足和高運算成本，為此類語言訓練 LLM 通常很困難。特別是對於資源非常少的語言，因此靜態字詞嵌入仍提供可行的替代方案。然而，對於各種語言來說，此類嵌入缺乏全面的儲存庫。為了解決這個問題，我們提出了 LowREm，一個針對 87 種低資源語言的靜態嵌入集中式儲存庫。我們還提出了一種新方法，透過整合多語言圖形知識來增強基於 GloVe 的嵌入，利用另一個知識來源。我們展示了我們增強的嵌入在情緒分析上優於從 XLM-R 提取的語境化嵌入。我們的程式碼和資料已公開在 https://huggingface.co/DFKI 下。

##### **A Survey of Spatio-Temporal EEG data Analysis: from Models to Applications**
2410.08224v1 by Pengfei Wang, Huanran Zheng, Silong Dai, Yiqiao Wang, Xiaotian Gu, Yuanbin Wu, Xiaoling Wang

In recent years, the field of electroencephalography (EEG) analysis has
witnessed remarkable advancements, driven by the integration of machine
learning and artificial intelligence. This survey aims to encapsulate the
latest developments, focusing on emerging methods and technologies that are
poised to transform our comprehension and interpretation of brain activity. We
delve into self-supervised learning methods that enable the robust
representation of brain signals, which are fundamental for a variety of
downstream applications. We also explore emerging discriminative methods,
including graph neural networks (GNN), foundation models, and large language
models (LLMs)-based approaches. Furthermore, we examine generative technologies
that harness EEG data to produce images or text, offering novel perspectives on
brain activity visualization and interpretation. The survey provides an
extensive overview of these cutting-edge techniques, their current
applications, and the profound implications they hold for future research and
clinical practice. The relevant literature and open-source materials have been
compiled and are consistently being refreshed at
\url{https://github.com/wpf535236337/LLMs4TS}

摘要：近年來，腦電圖 (EEG) 分析領域見證了顯著的進展，這要歸功於機器學習和人工智能的整合。本調查旨在概括最新發展，重點關注新興方法和技術，這些方法和技術有望轉變我們對大腦活動的理解和詮釋。我們深入探討自監督學習方法，這些方法能讓大腦信號的表示變得穩健，這對各種下游應用至關重要。我們還探討新興的判別方法，包括圖神經網路 (GNN)、基礎模型和大語言模型 (LLM) 為基礎的方法。此外，我們檢視利用 EEG 資料產生影像或文字的生成式技術，為大腦活動視覺化和詮釋提供了新的觀點。本調查對這些尖端技術、它們目前的應用以及它們對未來研究和臨床實務的深遠影響提供了廣泛的概述。相關文獻和開放原始碼資料已編譯，並持續更新於
\url{https://github.com/wpf535236337/LLMs4TS}

##### **Enhancing Structured-Data Retrieval with GraphRAG: Soccer Data Case Study**
2409.17580v1 by Zahra Sepasdar, Sushant Gautam, Cise Midoglu, Michael A. Riegler, Pål Halvorsen

Extracting meaningful insights from large and complex datasets poses
significant challenges, particularly in ensuring the accuracy and relevance of
retrieved information. Traditional data retrieval methods such as sequential
search and index-based retrieval often fail when handling intricate and
interconnected data structures, resulting in incomplete or misleading outputs.
To overcome these limitations, we introduce Structured-GraphRAG, a versatile
framework designed to enhance information retrieval across structured datasets
in natural language queries. Structured-GraphRAG utilizes multiple knowledge
graphs, which represent data in a structured format and capture complex
relationships between entities, enabling a more nuanced and comprehensive
retrieval of information. This graph-based approach reduces the risk of errors
in language model outputs by grounding responses in a structured format,
thereby enhancing the reliability of results. We demonstrate the effectiveness
of Structured-GraphRAG by comparing its performance with that of a recently
published method using traditional retrieval-augmented generation. Our findings
show that Structured-GraphRAG significantly improves query processing
efficiency and reduces response times. While our case study focuses on soccer
data, the framework's design is broadly applicable, offering a powerful tool
for data analysis and enhancing language model applications across various
structured domains.

摘要：從龐大且複雜的資料集中萃取出有意義的見解會帶來顯著的挑戰，特別是在確保擷取資訊的準確性和相關性方面。傳統的資料擷取方法，例如順序搜尋和基於索引的擷取，在處理複雜且相互連結的資料結構時，常常會失敗，導致不完整或誤導性的輸出。為了克服這些限制，我們引入了結構化圖形 RAG，這是一個通用框架，旨在增強自然語言查詢中結構化資料集的資訊擷取。結構化圖形 RAG 利用多個知識圖形，它們以結構化格式表示資料，並擷取實體之間的複雜關係，從而實現更細緻且全面的資訊擷取。這種基於圖形的做法透過以結構化格式為基礎回應，降低語言模型輸出中出現錯誤的風險，從而提高結果的可靠性。我們透過將結構化圖形 RAG 的效能與最近發表的傳統擷取增強生成方法進行比較，來證明其有效性。我們的研究結果顯示，結構化圖形 RAG 大幅提升了查詢處理效率，並縮短了回應時間。雖然我們的案例研究專注於足球資料，但這個架構的設計具有廣泛的適用性，提供了一個強大的資料分析工具，並增強了各種結構化領域的語言模型應用。

##### **Probing Omissions and Distortions in Transformer-based RDF-to-Text Models**
2409.16707v1 by Juliette Faille, Albert Gatt, Claire Gardent

In Natural Language Generation (NLG), important information is sometimes
omitted in the output text. To better understand and analyse how this type of
mistake arises, we focus on RDF-to-Text generation and explore two methods of
probing omissions in the encoder output of BART (Lewis et al, 2020) and of T5
(Raffel et al, 2019): (i) a novel parameter-free probing method based on the
computation of cosine similarity between embeddings of RDF graphs and of RDF
graphs in which we removed some entities and (ii) a parametric probe which
performs binary classification on the encoder embeddings to detect omitted
entities. We also extend our analysis to distorted entities, i.e. entities that
are not fully correctly mentioned in the generated text (e.g. misspelling of
entity, wrong units of measurement). We found that both omitted and distorted
entities can be probed in the encoder's output embeddings. This suggests that
the encoder emits a weaker signal for these entities and therefore is
responsible for some loss of information. This also shows that probing methods
can be used to detect mistakes in the output of NLG models.

摘要：在自然語言生成 (NLG) 中，重要資訊有時會在輸出文字中被省略。為了更了解並分析這類錯誤是如何產生的，我們專注於 RDF 轉文字的生成，並探討兩種探測 BART (Lewis 等人，2020) 和 T5 (Raffel 等人，2019) 的編碼器輸出中遺漏的方法：(i) 一種基於 RDF 圖形嵌入和我們移除一些實體的 RDF 圖形之間的餘弦相似度計算的新型無參數探測方法，以及 (ii) 一種在編碼器嵌入中執行二元分類以偵測遺漏實體的參數化探測。我們也將我們的分析延伸到扭曲的實體，也就是在產生的文字中沒有被完全正確提及的實體 (例如實體拼寫錯誤、測量單位錯誤)。我們發現遺漏和扭曲的實體都可以被探測到在編碼器的輸出嵌入中。這表示編碼器針對這些實體發射較弱的訊號，因此導致一些資訊遺失。這也顯示探測方法可以用於偵測 NLG 模型輸出中的錯誤。

##### **GraphLoRA: Structure-Aware Contrastive Low-Rank Adaptation for Cross-Graph Transfer Learning**
2409.16670v1 by Zhe-Rui Yang, Jindong Han, Chang-Dong Wang, Hao Liu

Graph Neural Networks (GNNs) have demonstrated remarkable proficiency in
handling a range of graph analytical tasks across various domains, such as
e-commerce and social networks. Despite their versatility, GNNs face
significant challenges in transferability, limiting their utility in real-world
applications. Existing research in GNN transfer learning overlooks
discrepancies in distribution among various graph datasets, facing challenges
when transferring across different distributions. How to effectively adopt a
well-trained GNN to new graphs with varying feature and structural
distributions remains an under-explored problem. Taking inspiration from the
success of Low-Rank Adaptation (LoRA) in adapting large language models to
various domains, we propose GraphLoRA, an effective and parameter-efficient
method for transferring well-trained GNNs to diverse graph domains.
Specifically, we first propose a Structure-aware Maximum Mean Discrepancy
(SMMD) to align divergent node feature distributions across source and target
graphs. Moreover, we introduce low-rank adaptation by injecting a small
trainable GNN alongside the pre-trained one, effectively bridging structural
distribution gaps while mitigating the catastrophic forgetting. Additionally, a
structure-aware regularization objective is proposed to enhance the
adaptability of the pre-trained GNN to target graph with scarce supervision
labels. Extensive experiments on six real-world datasets demonstrate the
effectiveness of GraphLoRA against eleven baselines by tuning only 20% of
parameters, even across disparate graph domains. The code is available at
https://anonymous.4open.science/r/GraphLoRA.

摘要：圖形神經網路 (GNN) 已展現出在各種領域處理一系列圖形分析任務的卓越能力，例如電子商務和社群網路。儘管 GNN 具有多功能性，但在可轉移性方面仍面臨重大挑戰，限制了它們在現實世界應用中的效用。現有的 GNN 轉移學習研究忽視了各種圖形資料集之間的分布差異，在跨不同分布轉移時面臨挑戰。如何有效地將訓練良好的 GNN 應用於具有不同特徵和結構分布的新圖形，仍然是一個尚未充分探討的問題。從低秩適應 (LoRA) 在將大型語言模型適應到各種領域方面獲得的成功中汲取靈感，我們提出了 GraphLoRA，這是一種有效且參數效率高的方法，可用於將訓練良好的 GNN 轉移到不同的圖形領域。具體來說，我們首先提出一個結構感知最大平均差異 (SMMD) 來調整來源和目標圖形中的不同節點特徵分布。此外，我們通過在預先訓練的 GNN 旁邊注入一個小的可訓練 GNN 來引入低秩適應，從而有效地彌合結構分布差距，同時減輕災難性遺忘。此外，還提出了結構感知正則化目標，以增強預先訓練的 GNN 對具有稀疏監督標籤的目標圖形的適應性。在六個真實世界資料集上的大量實驗證明了 GraphLoRA 的有效性，它僅調整了 20% 的參數，即使在不同的圖形領域中也能夠勝過十一種基準。程式碼可在 https://anonymous.4open.science/r/GraphLoRA 取得。

##### **Cyber Knowledge Completion Using Large Language Models**
2409.16176v1 by Braden K Webb, Sumit Purohit, Rounak Meyur

The integration of the Internet of Things (IoT) into Cyber-Physical Systems
(CPSs) has expanded their cyber-attack surface, introducing new and
sophisticated threats with potential to exploit emerging vulnerabilities.
Assessing the risks of CPSs is increasingly difficult due to incomplete and
outdated cybersecurity knowledge. This highlights the urgent need for
better-informed risk assessments and mitigation strategies. While previous
efforts have relied on rule-based natural language processing (NLP) tools to
map vulnerabilities, weaknesses, and attack patterns, recent advancements in
Large Language Models (LLMs) present a unique opportunity to enhance
cyber-attack knowledge completion through improved reasoning, inference, and
summarization capabilities. We apply embedding models to encapsulate
information on attack patterns and adversarial techniques, generating mappings
between them using vector embeddings. Additionally, we propose a
Retrieval-Augmented Generation (RAG)-based approach that leverages pre-trained
models to create structured mappings between different taxonomies of threat
patterns. Further, we use a small hand-labeled dataset to compare the proposed
RAG-based approach to a baseline standard binary classification model. Thus,
the proposed approach provides a comprehensive framework to address the
challenge of cyber-attack knowledge graph completion.

摘要：物聯網 (IoT) 與網路實體系統 (CPS) 的整合擴大了其網路攻擊面，引入了新的和複雜的威脅，具有利用新興漏洞的潛力。由於網路安全知識不完整且過時，評估 CPS 的風險變得越來越困難。這突顯了迫切需要更完善的風險評估和緩解策略。雖然先前的努力依賴於基於規則的自然語言處理 (NLP) 工具來繪製漏洞、弱點和攻擊模式，但大型語言模型 (LLM) 的最新進展提供了一個獨特的機會，可以透過改進的推理、推論和摘要能力來增強網路攻擊知識的完成度。我們應用嵌入模型來封裝有關攻擊模式和對抗技術的資訊，使用向量嵌入在它們之間產生對應關係。此外，我們提出了一個基於檢索增強生成 (RAG) 的方法，該方法利用預先訓練的模型在威脅模式的不同分類法之間建立結構化的對應關係。此外，我們使用一個小型的手動標記資料集來比較所提出的基於 RAG 的方法與基線標準二元分類模型。因此，所提出的方法提供了一個全面的架構來解決網路攻擊知識圖完成的挑戰。

##### **Konstruktor: A Strong Baseline for Simple Knowledge Graph Question Answering**
2409.15902v1 by Maria Lysyuk, Mikhail Salnikov, Pavel Braslavski, Alexander Panchenko

While being one of the most popular question types, simple questions such as
"Who is the author of Cinderella?", are still not completely solved.
Surprisingly, even the most powerful modern Large Language Models are prone to
errors when dealing with such questions, especially when dealing with rare
entities. At the same time, as an answer may be one hop away from the question
entity, one can try to develop a method that uses structured knowledge graphs
(KGs) to answer such questions. In this paper, we introduce Konstruktor - an
efficient and robust approach that breaks down the problem into three steps:
(i) entity extraction and entity linking, (ii) relation prediction, and (iii)
querying the knowledge graph. Our approach integrates language models and
knowledge graphs, exploiting the power of the former and the interpretability
of the latter. We experiment with two named entity recognition and entity
linking methods and several relation detection techniques. We show that for
relation detection, the most challenging step of the workflow, a combination of
relation classification/generation and ranking outperforms other methods. We
report Konstruktor's strong results on four datasets.

摘要：儘管是最常見的問題類型之一，但諸如「灰姑娘的作者是誰？」這類簡單的問題仍未完全獲得解答。令人驚訝的是，即使是最強大的現代大型語言模型在處理此類問題時也容易出錯，特別是在處理罕見實體時。與此同時，由於答案可能距離問題實體僅一步之遙，因此可以嘗試開發一種使用結構化知識圖譜 (KG) 來回答此類問題的方法。在本文中，我們介紹 Konstruktor - 一種高效且強大的方法，它將問題分解為三個步驟：(i) 實體萃取和實體連結、(ii) 關係預測以及 (iii) 查詢知識圖譜。我們的做法整合了語言模型和知識圖譜，發揮了前者的能力和後者的可解釋性。我們實驗了兩種命名實體識別和實體連結方法以及多種關係偵測技術。我們表明，對於關係偵測，也就是工作流程中最具挑戰性的步驟，關係分類/生成和排名相結合的組合優於其他方法。我們報告了 Konstruktor 在四個資料集上的強勁成果。

##### **Symmetries and Expressive Requirements for Learning General Policies**
2409.15892v1 by Dominik Drexler, Simon Ståhlberg, Blai Bonet, Hector Geffner

State symmetries play an important role in planning and generalized planning.
In the first case, state symmetries can be used to reduce the size of the
search; in the second, to reduce the size of the training set. In the case of
general planning, however, it is also critical to distinguish non-symmetric
states, i.e., states that represent non-isomorphic relational structures.
However, while the language of first-order logic distinguishes non-symmetric
states, the languages and architectures used to represent and learn general
policies do not. In particular, recent approaches for learning general policies
use state features derived from description logics or learned via graph neural
networks (GNNs) that are known to be limited by the expressive power of C_2,
first-order logic with two variables and counting. In this work, we address the
problem of detecting symmetries in planning and generalized planning and use
the results to assess the expressive requirements for learning general policies
over various planning domains. For this, we map planning states to plain
graphs, run off-the-shelf algorithms to determine whether two states are
isomorphic with respect to the goal, and run coloring algorithms to determine
if C_2 features computed logically or via GNNs distinguish non-isomorphic
states. Symmetry detection results in more effective learning, while the
failure to detect non-symmetries prevents general policies from being learned
at all in certain domains.

摘要：狀態對稱性在規劃和廣義規劃中扮演著重要的角色。
在第一種情況中，狀態對稱性可用於縮小搜尋的規模；在第二種情況中，可用於縮小訓練集的規模。然而，在廣義規劃的情況中，區分非對稱狀態（即表示非同構關係結構的狀態）也很重要。然而，雖然一階邏輯的語言區分了非對稱狀態，但用於表示和學習一般策略的語言和架構卻沒有。特別是，最近用於學習一般策略的方法使用從描述邏輯中衍生的狀態特徵，或通過圖神經網路 (GNN) 學習，已知這些特徵受到具有兩個變數和計數的一階邏輯 C_2 的表達能力限制。在這項工作中，我們解決了在規劃和廣義規劃中檢測對稱性的問題，並使用結果評估在各種規劃領域中學習一般策略的表達需求。為此，我們將規劃狀態映射到平面圖形，執行現成的演算法來確定兩個狀態是否相對於目標同構，並執行著色演算法來確定透過邏輯或 GNN 計算的 C_2 特徵是否區分非同構狀態。對稱性檢測會帶來更有效的學習，而無法檢測非對稱性則會完全阻止在某些領域中學習一般策略。

##### **GEM-RAG: Graphical Eigen Memories For Retrieval Augmented Generation**
2409.15566v1 by Brendan Hogan Rappazzo, Yingheng Wang, Aaron Ferber, Carla Gomes

The ability to form, retrieve, and reason about memories in response to
stimuli serves as the cornerstone for general intelligence - shaping entities
capable of learning, adaptation, and intuitive insight. Large Language Models
(LLMs) have proven their ability, given the proper memories or context, to
reason and respond meaningfully to stimuli. However, they are still unable to
optimally encode, store, and retrieve memories - the ability to do this would
unlock their full ability to operate as AI agents, and to specialize to niche
domains. To remedy this, one promising area of research is Retrieval Augmented
Generation (RAG), which aims to augment LLMs by providing them with rich
in-context examples and information. In question-answering (QA) applications,
RAG methods embed the text of interest in chunks, and retrieve the most
relevant chunks for a prompt using text embeddings. Motivated by human memory
encoding and retrieval, we aim to improve over standard RAG methods by
generating and encoding higher-level information and tagging the chunks by
their utility to answer questions. We introduce Graphical Eigen Memories For
Retrieval Augmented Generation (GEM-RAG). GEM-RAG works by tagging each chunk
of text in a given text corpus with LLM generated ``utility'' questions,
connecting chunks in a graph based on the similarity of both their text and
utility questions, and then using the eigendecomposition of the memory graph to
build higher level summary nodes that capture the main themes of the text. We
evaluate GEM-RAG, using both UnifiedQA and GPT-3.5 Turbo as the LLMs, with
SBERT, and OpenAI's text encoders on two standard QA tasks, showing that
GEM-RAG outperforms other state-of-the-art RAG methods on these tasks. We also
discuss the implications of having a robust RAG system and future directions.

摘要：<paragraph>根據刺激形成、檢索和推理記憶的能力是通用智慧的基石，塑造了具備學習、適應和直覺洞察力的實體。大型語言模型 (LLM) 已證明其能力，在適當的記憶或背景下，對刺激進行推理和有意義地回應。然而，它們仍然無法最佳地編碼、儲存和檢索記憶，執行此操作的能力將解鎖它們作為 AI 代理運作並專門化為利基領域的全部能力。為了補救此問題，一個有前景的研究領域是檢索增強生成 (RAG)，其目標是透過提供豐富的上下文範例和資訊來擴充 LLM。在問答 (QA) 應用程式中，RAG 方法將感興趣的文字分塊嵌入，並使用文字嵌入為提示檢索最相關的區塊。受人類記憶編碼和檢索的啟發，我們旨在透過產生和編碼更高級別的資訊並根據區塊回答問題的效用標記區塊，從而改進標準 RAG 方法。我們引入了用於檢索增強生成的圖形特徵記憶 (GEM-RAG)。GEM-RAG 的工作原理是使用 LLM 生成的「效用」問題標記給定文字語料庫中每個文字區塊，根據文字和效用問題的相似性將區塊連接在圖形中，然後使用記憶圖形的特徵分解來建立擷取文字主題的高階摘要節點。我們使用 UnifiedQA 和 GPT-3.5 Turbo 作為 LLM，以及 SBERT 和 OpenAI 的文字編碼器，在兩個標準 QA 任務中評估 GEM-RAG，顯示 GEM-RAG 在這些任務中優於其他最先進的 RAG 方法。我們還討論了擁有強大的 RAG 系統的含意和未來的方向。</paragraph>

##### **KARMA: Augmenting Embodied AI Agents with Long-and-short Term Memory Systems**
2409.14908v1 by Zixuan Wang, Bo Yu, Junzhe Zhao, Wenhao Sun, Sai Hou, Shuai Liang, Xing Hu, Yinhe Han, Yiming Gan

Embodied AI agents responsible for executing interconnected, long-sequence
household tasks often face difficulties with in-context memory, leading to
inefficiencies and errors in task execution. To address this issue, we
introduce KARMA, an innovative memory system that integrates long-term and
short-term memory modules, enhancing large language models (LLMs) for planning
in embodied agents through memory-augmented prompting. KARMA distinguishes
between long-term and short-term memory, with long-term memory capturing
comprehensive 3D scene graphs as representations of the environment, while
short-term memory dynamically records changes in objects' positions and states.
This dual-memory structure allows agents to retrieve relevant past scene
experiences, thereby improving the accuracy and efficiency of task planning.
Short-term memory employs strategies for effective and adaptive memory
replacement, ensuring the retention of critical information while discarding
less pertinent data. Compared to state-of-the-art embodied agents enhanced with
memory, our memory-augmented embodied AI agent improves success rates by 1.3x
and 2.3x in Composite Tasks and Complex Tasks within the AI2-THOR simulator,
respectively, and enhances task execution efficiency by 3.4x and 62.7x.
Furthermore, we demonstrate that KARMA's plug-and-play capability allows for
seamless deployment on real-world robotic systems, such as mobile manipulation
platforms.Through this plug-and-play memory system, KARMA significantly
enhances the ability of embodied agents to generate coherent and contextually
appropriate plans, making the execution of complex household tasks more
efficient. The experimental videos from the work can be found at
https://youtu.be/4BT7fnw9ehs.

摘要：負責執行相互連接的長序列家庭任務的具身化 AI 代理經常面臨情境記憶的困難，導致任務執行效率低下和錯誤。為了解決這個問題，我們引入了 KARMA，這是一個創新的記憶系統，它整合了長期和短期記憶模組，透過記憶增強提示，增強具身化代理中用於規劃的大語言模型 (LLM)。KARMA 區分長期和短期記憶，長期記憶擷取全面的 3D 場景圖形作為環境的表示，而短期記憶則動態記錄物件位置和狀態的變化。這種雙重記憶結構允許代理擷取相關的過去場景經驗，從而提高任務規劃的準確性和效率。短期記憶採用策略來進行有效和適應性的記憶替換，確保保留關鍵資訊，同時捨棄較不相關的資料。與具備增強記憶功能的最新具身化代理相比，我們的記憶增強具身化 AI 代理在 AI2-THOR 模擬器中的複合任務和複雜任務中，分別將成功率提高了 1.3 倍和 2.3 倍，並將任務執行效率提高了 3.4 倍和 62.7 倍。此外，我們證明了 KARMA 的即插即用功能允許在真實世界的機器人系統上進行無縫部署，例如行動操作平台。透過這個即插即用記憶系統，KARMA 大幅增強了具身化代理產生一致且符合情境的計畫的能力，使複雜家庭任務的執行更有效率。這項工作的實驗影片可以在 https://youtu.be/4BT7fnw9ehs 找到。

##### **End-to-End Graph Flattening Method for Large Language Models**
2409.14880v1 by Bin Hong, Jinze Wu, Jiayu Liu, Liang Ding, Jing Sha, Kai Zhang, Shijin Wang, Zhenya Huang

In recent years, the breakthrough of Large Language Models (LLMs) offers new
ideas for achieving universal methods on graph data. The common practice of
converting graphs into natural language for LLMs, which refers to graph
flattening, exhibits good generalizability and interpretability. However, the
poor organization of the textual format results in poor performance in
long-distance scenario understanding. Inspired by human cognitive reasoning
habits, we propose a novel method for graph flattening to fit LLMs, termed as
End-to-End DAG-Path prompting (EEDP). Experiments on real-world datasets show
that EEDP enhances the reasoning performance of LLMs in long-distance scenarios
while maintaining excellent performance in short-distance scenarios,
demonstrating good robustness in the face of distance variations.

摘要：近年來，大型語言模型 (LLM) 的突破為在圖形資料中達成通用方法提供了新想法。將圖形轉換為自然語言以供 LLM 使用的常見做法，即圖形扁平化，展現出良好的通用性和可解釋性。然而，文本格式組織不佳導致在長距離場景理解中表現不佳。受到人類認知推理習慣的啟發，我們提出了一種新穎的方法來進行圖形扁平化以配合 LLM，稱為端到端 DAG 路徑提示 (EEDP)。在真實世界資料集上的實驗表明，EEDP 增強了 LLM 在長距離場景中的推理性能，同時在短距離場景中保持了出色的性能，在面對距離變化時表現出良好的魯棒性。

##### **RACOON: An LLM-based Framework for Retrieval-Augmented Column Type Annotation with a Knowledge Graph**
2409.14556v1 by Linxi Wei, Guorui Xiao, Magdalena Balazinska

As an important component of data exploration and integration, Column Type
Annotation (CTA) aims to label columns of a table with one or more semantic
types. With the recent development of Large Language Models (LLMs), researchers
have started to explore the possibility of using LLMs for CTA, leveraging their
strong zero-shot capabilities. In this paper, we build on this promising work
and improve on LLM-based methods for CTA by showing how to use a Knowledge
Graph (KG) to augment the context information provided to the LLM. Our
approach, called RACOON, combines both pre-trained parametric and
non-parametric knowledge during generation to improve LLMs' performance on CTA.
Our experiments show that RACOON achieves up to a 0.21 micro F-1 improvement
compared against vanilla LLM inference.

摘要：作為資料探勘與整合的重要組成部分，欄位類型註解 (CTA) 的目標是使用一個或多個語意類型標記表格欄位。隨著大型語言模型 (LLM) 的近期發展，研究人員已開始探討使用 LLM 來進行 CTA 的可能性，並利用其強大的零次學習能力。在本文中，我們建立在這個有前景的研究上，並透過展示如何使用知識圖譜 (KG) 來擴充提供給 LLM 的脈絡資訊，進而改善基於 LLM 的 CTA 方法。我們的方法稱為 RACOON，它在生成過程中結合預先訓練的參數式和非參數式知識，以改善 LLM 在 CTA 上的效能。我們的實驗顯示，與純粹的 LLM 推論相比，RACOON 在微型 F-1 上的進步高達 0.21。


### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-15**|**Explainable AI Methods for Multi-Omics Analysis: A Survey**|Ahmad Hussein et.al.|[2410.11910v1](http://arxiv.org/abs/2410.11910v1)|null|
|**2024-10-14**|**Study on the Helpfulness of Explainable Artificial Intelligence**|Tobias Labarta et.al.|[2410.11896v1](http://arxiv.org/abs/2410.11896v1)|null|
|**2024-10-12**|**Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**|Abdullah Mamun et.al.|[2410.09635v1](http://arxiv.org/abs/2410.09635v1)|[link](https://github.com/ab9mamun/aimen)|
|**2024-10-10**|**Artificial intelligence techniques in inherited retinal diseases: A review**|Han Trinh et.al.|[2410.09105v1](http://arxiv.org/abs/2410.09105v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|null|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v1](http://arxiv.org/abs/2410.01855v1)|null|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v2](http://arxiv.org/abs/2409.12087v2)|null|
|**2024-09-09**|**Explainable AI: Definition and attributes of a good explanation for health AI**|Evangelia Kyrimi et.al.|[2409.15338v1](http://arxiv.org/abs/2409.15338v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v2](http://arxiv.org/abs/2407.15851v2)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. Zając et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel Miró-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|Séamus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Cause and Effect: Can Large Language Models Truly Understand Causality?**|Swagata Ashwani et.al.|[2402.18139v3](http://arxiv.org/abs/2402.18139v3)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|Timothée Schmude et.al.|[2401.13324v5](http://arxiv.org/abs/2401.13324v5)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v3](http://arxiv.org/abs/2311.12573v3)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|
|**2023-11-03**|**Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**|Emma A. M. Stanley et.al.|[2311.02115v2](http://arxiv.org/abs/2311.02115v2)|[link](https://github.com/estanley16/simba)|
|**2023-10-29**|**Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**|Adam White et.al.|[2310.19174v1](http://arxiv.org/abs/2310.19174v1)|null|
|**2023-10-03**|**Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**|Hossein Shreim et.al.|[2310.01828v2](http://arxiv.org/abs/2310.01828v2)|[link](https://github.com/geoaigroup/geoai-ecrs2023)|
|**2023-09-26**|**Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**|Muhammad Aurangzeb Ahmad et.al.|[2311.01463v1](http://arxiv.org/abs/2311.01463v1)|null|
|**2023-09-20**|**When to Trust AI: Advances and Challenges for Certification of Neural Networks**|Marta Kwiatkowska et.al.|[2309.11196v1](http://arxiv.org/abs/2309.11196v1)|null|
|**2023-09-19**|**Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**|Juan M. García-Gómez et.al.|[2309.10424v1](http://arxiv.org/abs/2309.10424v1)|null|
|**2023-09-19**|**QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**|Thanveer Shaik et.al.|[2309.10293v3](http://arxiv.org/abs/2309.10293v3)|null|
|**2023-09-18**|**Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**|Adarsa Sivaprasad et.al.|[2309.09917v1](http://arxiv.org/abs/2309.09917v1)|null|
|**2023-08-28**|**Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**|Yanjun Gao et.al.|[2308.14321v1](http://arxiv.org/abs/2308.14321v1)|null|
|**2023-08-18**|**Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**|Yun Xin Teoh et.al.|[2308.09380v1](http://arxiv.org/abs/2308.09380v1)|null|
|**2023-08-16**|**Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**|Munib Mesinovic et.al.|[2308.08407v1](http://arxiv.org/abs/2308.08407v1)|null|
|**2023-08-11**|**FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**|Karim Lekadir et.al.|[2309.12325v3](http://arxiv.org/abs/2309.12325v3)|null|

#### Abstracts
##### **Explainable AI Methods for Multi-Omics Analysis: A Survey**
2410.11910v1 by Ahmad Hussein, Mukesh Prasad, Ali Braytee

Advancements in high-throughput technologies have led to a shift from
traditional hypothesis-driven methodologies to data-driven approaches.
Multi-omics refers to the integrative analysis of data derived from multiple
'omes', such as genomics, proteomics, transcriptomics, metabolomics, and
microbiomics. This approach enables a comprehensive understanding of biological
systems by capturing different layers of biological information. Deep learning
methods are increasingly utilized to integrate multi-omics data, offering
insights into molecular interactions and enhancing research into complex
diseases. However, these models, with their numerous interconnected layers and
nonlinear relationships, often function as black boxes, lacking transparency in
decision-making processes. To overcome this challenge, explainable artificial
intelligence (xAI) methods are crucial for creating transparent models that
allow clinicians to interpret and work with complex data more effectively. This
review explores how xAI can improve the interpretability of deep learning
models in multi-omics research, highlighting its potential to provide
clinicians with clear insights, thereby facilitating the effective application
of such models in clinical settings.

摘要：高通量技術的進步導致從傳統的假設驅動方法轉變為資料驅動的方法。多組學是指整合分析來自多個「組學」的資料，例如基因組學、蛋白質組學、轉錄組學、代謝組學和微生物組學。此方法透過擷取生物資訊的不同層面，能全面了解生物系統。深度學習方法愈來愈常被用於整合多組學資料，提供分子交互作用的洞察力，並加強對複雜疾病的研究。然而，這些模型具有許多相互連接的層級和非線性關係，通常會像黑盒子一樣運作，缺乏決策過程的透明度。為了克服此挑戰，可解釋人工智慧 (xAI) 方法對於建立透明模型至關重要，讓臨床醫生可以更有效地解釋和處理複雜資料。此評論探討 xAI 如何能改善多組學研究中深度學習模型的可解釋性，強調其提供臨床醫生明確見解的潛力，進而促進此類模型在臨床環境中的有效應用。

##### **Study on the Helpfulness of Explainable Artificial Intelligence**
2410.11896v1 by Tobias Labarta, Elizaveta Kulicheva, Ronja Froelian, Christian Geißler, Xenia Melman, Julian von Klitzing

Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.

摘要：可解釋人工智慧 (XAI) 對於建構先進的機器學習驅動應用程式至關重要，特別是在醫療診斷或自動駕駛等關鍵領域。法律、商業和倫理要求促使使用有效的 XAI，但數量日益增加的不同方法使得挑選正確的方法具有挑戰性。此外，由於解釋高度依賴於背景，在沒有使用者的情況下衡量 XAI 方法的有效性只能揭示有限的資訊，排除人類因素，例如理解它的能力。我們建議透過使用者成功執行代理任務的能力來評估 XAI 方法，設計使得良好的執行表現是解釋提供有用資訊的指標。換句話說，我們探討 XAI 對人類決策制定的幫助。此外，對最先進的方法進行使用者研究，顯示出它們在產生信任和懷疑的能力以及正確判斷 AI 決策是否正確的能力方面存在差異。根據結果，我們強烈建議使用和擴充這種方法，以進行更多以目標為基礎的人為中心使用者研究，以終端到終端的方式衡量 XAI 效能。

##### **Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**
2410.09635v1 by Abdullah Mamun, Lawrence D. Devoe, Mark I. Evans, David W. Britt, Judith Klein-Seetharaman, Hassan Ghasemzadeh

Early detection of intrapartum risk enables interventions to potentially
prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently,
there is no accurate automated system to predict such events to assist with
clinical decision-making. To fill this gap, we propose "Artificial Intelligence
(AI) for Modeling and Explaining Neonatal Health" (AIMEN), a deep learning
framework that not only predicts adverse labor outcomes from maternal, fetal,
obstetrical, and intrapartum risk factors but also provides the model's
reasoning behind the predictions made. The latter can provide insights into
what modifications in the input variables of the model could have changed the
predicted outcome. We address the challenges of imbalance and small datasets by
synthesizing additional training data using Adaptive Synthetic Sampling
(ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN
uses an ensemble of fully-connected neural networks as the backbone for its
classification with the data augmentation supported by either ADASYN or CTGAN.
AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in
classification. AIMEN can predict a high risk for adverse labor outcomes with
an average F1 score of 0.784. It also provides counterfactual explanations that
can be achieved by changing 2 to 3 attributes on average. Resources available:
https://github.com/ab9mamun/AIMEN.

摘要：產程中風險的早期偵測有助於進行干預措施，以預防或減輕不利的生產結果，例如腦性麻痺。目前，沒有準確的自動化系統可以預測此類事件，以協助臨床決策。為了填補這一空白，我們提出「用於建模和解釋新生兒健康的人工智慧」(AIMEN)，這是一個深度學習架構，它不僅可以根據孕產婦、胎兒、產科和產程風險因素預測不利的生產結果，還能提供模型做出預測背後的原因。後者可以提供見解，說明模型輸入變數中的哪些修改可能會改變預測結果。我們透過使用適應性合成抽樣 (ADASYN) 和條件表格生成對抗網路 (CTGAN) 來合成額外的訓練資料，以解決不平衡和小型資料集的挑戰。AIMEN 使用全連接神經網路的集合作為其分類的骨幹，並透過 ADASYN 或 CTGAN 支援資料擴充。由 CTGAN 支援的 AIMEN 在分類方面優於由 ADASYN 支援的 AIMEN。AIMEN 可以預測不利的生產結果的高風險，平均 F1 分數為 0.784。它還提供反事實解釋，可透過平均變更 2 至 3 個屬性來達成。可用資源：https://github.com/ab9mamun/AIMEN。

##### **Artificial intelligence techniques in inherited retinal diseases: A review**
2410.09105v1 by Han Trinh, Jordan Vice, Jason Charng, Zahra Tajbakhsh, Khyber Alam, Fred K. Chen, Ajmal Mian

Inherited retinal diseases (IRDs) are a diverse group of genetic disorders
that lead to progressive vision loss and are a major cause of blindness in
working-age adults. The complexity and heterogeneity of IRDs pose significant
challenges in diagnosis, prognosis, and management. Recent advancements in
artificial intelligence (AI) offer promising solutions to these challenges.
However, the rapid development of AI techniques and their varied applications
have led to fragmented knowledge in this field. This review consolidates
existing studies, identifies gaps, and provides an overview of AI's potential
in diagnosing and managing IRDs. It aims to structure pathways for advancing
clinical applications by exploring AI techniques like machine learning and deep
learning, particularly in disease detection, progression prediction, and
personalized treatment planning. Special focus is placed on the effectiveness
of convolutional neural networks in these areas. Additionally, the integration
of explainable AI is discussed, emphasizing its importance in clinical settings
to improve transparency and trust in AI-based systems. The review addresses the
need to bridge existing gaps in focused studies on AI's role in IRDs, offering
a structured analysis of current AI techniques and outlining future research
directions. It concludes with an overview of the challenges and opportunities
in deploying AI for IRDs, highlighting the need for interdisciplinary
collaboration and the continuous development of robust, interpretable AI models
to advance clinical applications.

摘要：遺傳性視網膜疾病 (IRD) 是一組多樣化的遺傳疾病，
會導致視力逐漸喪失，是工作年齡成人失明的主要原因。IRD 的複雜性和異質性對診斷、預後和管理提出了重大挑戰。最近人工智能 (AI) 的進步為這些挑戰提供了有希望的解決方案。
然而，AI 技術的快速發展及其多種應用導致了該領域的知識分散。本綜述整合了現有研究，找出差距，並概述了 AI 在診斷和管理 IRD 中的潛力。它旨在通過探索機器學習和深度學習等 AI 技術，特別是在疾病檢測、進程預測和個性化治療計劃中，為推進臨床應用構建途徑。特別關注這些領域中卷積神經網路的有效性。此外，討論了可解釋 AI 的整合，強調了其在臨床環境中提高透明度和對基於 AI 的系統的信任的重要性。該綜述解決了彌合 AI 在 IRD 中作用的重點研究中現有差距的必要性，提供了對當前 AI 技術的結構化分析，並概述了未來的研究方向。最後概述了在 IRD 中部署 AI 的挑戰和機遇，強調了跨學科合作和持續開發強大、可解釋的 AI 模型以推進臨床應用的必要性。

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

摘要：解釋人工智慧 (AI) 的決策是現在 AI 的一項重大挑戰，特別是應用於像醫學和法律等敏感情境時。然而，解釋決策背後理由的需求也是基於人類的考量的一個主要問題，因為有必要證明為什麼做出某個決策。例如，住院醫師不僅需要提供（可能是正確的）診斷，還需要解釋他們如何達成某個結論。因此，開發新的工具來幫助住院醫師訓練他們的解釋技巧是教育中 AI 的一項核心目標。在本文中，我們遵循這個方向，並且根據我們的了解，提出第一個多語言醫學問答資料集，其中臨床病例的正確和不正確診斷都附有由醫生撰寫的自然語言解釋。這些解釋已使用論證組成（即前提、主張）和論證關係（即攻擊、支持）進行手動註解，產生多語言 CasiMedicos-Arg 資料集，其中包含 558 個具有解釋的四種語言（英語、西班牙語、法語、義大利語）的臨床病例，我們註解了 5021 個主張、2313 個前提、2431 個支持關係和 1106 個攻擊關係。我們最後展示了競爭基準如何針對論證探勘任務執行此具挑戰性的資料集。

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v1 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

摘要：診斷預測是醫療保健中的一項關鍵任務，及時且準確地識別醫療狀況會對患者的結果產生重大影響。傳統機器學習和深度學習模型已在此領域取得顯著成功，但通常缺乏可解釋性，這是臨床環境中的關鍵要求。在本研究中，我們探討了神經符號方法，特別是邏輯神經網路 (LNN)，以開發可解釋的診斷預測模型。基本上，我們設計並實作了基於 LNN 的模型，該模型透過邏輯規則和可學習的閾值整合領域特定的知識。我們的模型，特別是 $M_{\text{multi-pathway}}$ 和 $M_{\text{comprehensive}}$，表現出優於傳統模型（如邏輯迴歸、SVM 和隨機森林）的卓越效能，在糖尿病預測的案例研究中，達到了更高的準確度（高達 80.52%）和 AUROC 分數（高達 0.8457）。LNN 模型中學習的權重和閾值提供了對特徵貢獻的直接見解，增強了可解釋性，同時不損害預測能力。這些發現突顯了神經符號方法在彌合醫療保健 AI 應用中準確性和可解釋性差距方面的潛力。透過提供透明且適應性強的診斷模型，我們的研究有助於精準醫療的進步，並支援公平醫療保健解決方案的開發。未來的研究將專注於將這些方法擴展到更大且更多樣化的資料集，以進一步驗證其在不同醫療狀況和人群中的適用性。

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

摘要：人工智慧 (AI) 的快速進展徹底改變了智慧醫療保健，推動了可穿戴技術、持續監控裝置和智慧診斷系統的創新。然而，安全性、可解釋性、穩健性和效能最佳化挑戰仍然是臨床環境中廣泛採用的關鍵障礙。本研究提出一個創新的演算法方法，使用自適應特徵評估器 (AFE) 演算法來改善醫療保健資料集中的特徵選取並克服問題。AFE 整合了遺傳演算法 (GA)、可解釋人工智慧 (XAI) 和排列組合技術 (PCT)，該演算法最佳化了臨床決策支援系統 (CDSS)，從而提高了預測準確性和可解釋性。所提出的方法使用六種不同的機器學習演算法驗證了三個不同的醫療保健資料集，證明了其穩健性和優於傳統特徵選取技術。結果強調了 AFE 在智慧醫療保健中的轉變潛力，實現了個人化和透明的患者照護。值得注意的是，AFE 演算法與多層感知器 (MLP) 結合使用時，準確度高達 98.5%，突顯了其改善實際醫療保健應用中臨床決策制定流程的能力。

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

摘要：人工智慧 (AI) 系統已大幅改善皮膚科醫師對黑色素瘤的診斷準確度，而可解釋 AI (XAI) 系統進一步提升臨床醫師對 AI 驅動決策的信心與信賴。儘管有這些進展，對於皮膚科醫師如何使用 AI 和 XAI 工具，仍有客觀評估的迫切需求。在這項研究中，76 位皮膚科醫師參與了一項讀者研究，使用 XAI 系統診斷 16 張黑色素瘤和痣的皮膚鏡影像，該系統提供詳細的領域特定說明。採用眼球追蹤技術來評估他們的互動。將診斷表現與缺乏說明功能的標準 AI 系統進行比較。我們的研究結果顯示，XAI 系統相較於標準 AI，將平衡診斷準確度提升了 2.8 個百分點。此外，與 AI/XAI 系統的診斷分歧和複雜的病灶與認知負擔升高有關，這由增加的眼睛注視次數所證實。這些見解對臨床實務、視覺任務 AI 工具的設計和醫學診斷中 XAI 的廣泛發展具有重大意義。

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

摘要：自閉症譜系障礙 (ASD) 的早期診斷和介入已被證實能顯著改善自閉症患者的生活品質。然而，ASD 的診斷方法依賴於基於臨床表現的評估，容易產生偏見，且可能難以做出早期診斷。有必要找出 ASD 的客觀生物標記，以幫助提高診斷準確性。深度學習 (DL) 在從醫學影像資料診斷疾病和病症方面取得傑出的表現。已經針對建立使用靜態功能性磁振造影 (fMRI) 資料對 ASD 進行分類的模型進行廣泛的研究。然而，現有的模型缺乏可解釋性。本研究旨在透過建立一個不僅能準確分類 ASD，還能提供可解釋見解說明其運作原理的 DL 模型，來改善 ASD 診斷的準確性和可解釋性。所使用的資料集是自閉症大腦影像資料交換 (ABIDE) 的預處理版本，包含 884 個樣本。我們的研究結果顯示，該模型能準確分類 ASD，並強調 ASD 與典型對照組之間存在差異的關鍵腦區，對於 ASD 的早期診斷和神經基礎的理解具有潛在的意義。這些研究結果已由使用不同資料集和方式的文獻研究驗證，證實該模型實際上學習了 ASD 的特徵，而不僅僅是資料集。本研究透過提供一個強健且可解釋的模型，推動了醫學影像中可解釋 AI 的領域，從而為未來提供客觀且可靠的 ASD 診斷做出貢獻。

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, Clément Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

摘要：尿路鏡檢查中腎結石類型的體內識別將是泌尿科的一項重大進展，因為它可以減少繁瑣的腎結石取出過程的時間，同時降低感染風險。此外，這種自動化程序將使立即開立抗復發治療成為可能。如今，只有少數經驗豐富的泌尿科醫生能夠在內視鏡檢查期間屏幕上顯示的視頻圖像中識別腎結石類型。因此，最近已提出多種深度學習 (DL) 模型，以使用輸尿管鏡圖像自動識別腎結石類型。然而，這些 DL 模型本質上是黑盒子，這限制了它們在臨床環境中的應用性。本文提出了一個基於案例推理的 DL 模型，它使用原型部分 (PP) 並生成局部和全局描述符。PP 為每種類型（即腎結石類型）編碼視覺特徵信息（色調、飽和度、強度和紋理），類似於生物學家使用的信息。由於在模型訓練期間使用的新損失函數，PP 得到了最佳生成。此外，PP 的局部和全局描述符允許以生物學家和泌尿科醫生可以理解的方式解釋決策（“什麼”信息，“圖像中的什麼位置”）。所提出的 DL 模型已在一個包含六種最廣泛的腎結石類型圖像的數據庫上進行了測試。總體平均分類準確率為 90.37。將此結果與腎結石最先進的八個其他 DL 模型的結果進行比較時，可以看出，可解釋性的寶貴增益並未以準確性為代價，甚至略有增加與文獻中最好的方法 (88.2) 相比。這些有希望且可解釋的結果也鼓勵泌尿科醫生相信基於人工智能的解決方案。

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v2 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

摘要：本研究探討利用行政申報數據的潛力，結合進階機器學習和深度學習技術，以預測慢性腎臟疾病 (CKD) 進展至末期腎臟疾病 (ESRD)。我們分析一家大型健康保險組織提供的 10 年綜合數據集，以開發使用傳統機器學習方法（例如隨機森林和 XGBoost）以及深度學習方法（例如長短期記憶 (LSTM) 網路）的多個觀察窗口的預測模型。我們的研究結果表明，LSTM 模型，特別是在 24 個月的觀察窗口中，在預測 ESRD 進展方面表現優異，優於文獻中的現有模型。我們進一步應用 SHapley Additive exPlanations (SHAP) 分析來增強可解釋性，提供對個別特徵對個別患者層級預測影響的見解。本研究強調了利用行政申報數據進行 CKD 管理和預測 ESRD 進展的價值。

##### **Explainable AI: Definition and attributes of a good explanation for health AI**
2409.15338v1 by Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group

Proposals of artificial intelligence (AI) solutions based on increasingly
complex and accurate predictive models are becoming ubiquitous across many
disciplines. As the complexity of these models grows, transparency and users'
understanding often diminish. This suggests that accurate prediction alone is
insufficient for making an AI-based solution truly useful. In the development
of healthcare systems, this introduces new issues related to accountability and
safety. Understanding how and why an AI system makes a recommendation may
require complex explanations of its inner workings and reasoning processes.
Although research on explainable AI (XAI) has significantly increased in recent
years and there is high demand for XAI in medicine, defining what constitutes a
good explanation remains ad hoc, and providing adequate explanations continues
to be challenging. To fully realize the potential of AI, it is critical to
address two fundamental questions about explanations for safety-critical AI
applications, such as health-AI: (1) What is an explanation in health-AI? and
(2) What are the attributes of a good explanation in health-AI? In this study,
we examined published literature and gathered expert opinions through a
two-round Delphi study. The research outputs include (1) a definition of what
constitutes an explanation in health-AI and (2) a comprehensive list of
attributes that characterize a good explanation in health-AI.

摘要：隨著越來越複雜且準確的預測模型，基於人工智慧 (AI) 解決方案的提案在許多領域中變得無處不在。隨著這些模型複雜性的增加，透明度和使用者的理解力往往會降低。這表示僅有準確的預測並不足以讓 AI 解決方案真正有用。在醫療保健系統的開發中，這引入了與問責制和安全性相關的新問題。瞭解 AI 系統如何以及為何提出建議可能需要對其內部運作和推理過程進行複雜的說明。儘管近年來對可解釋 AI (XAI) 的研究已大幅增加，且醫學領域對 XAI 有很高的需求，但定義什麼構成一個好的解釋仍是臨時性的，而提供適當的解釋仍然具有挑戰性。為了充分發揮 AI 的潛力，對於安全關鍵型 AI 應用（例如健康 AI）的解釋，探討兩個基本問題至關重要：(1) 什麼是健康 AI 中的解釋？以及 (2) 健康 AI 中一個好的解釋有哪些屬性？在本研究中，我們檢視了已發表的文獻，並透過兩輪德爾菲研究收集了專家意見。研究成果包括：(1) 健康 AI 中什麼構成解釋的定義，以及 (2) 健康 AI 中一個好解釋的屬性清單。

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

摘要：<paragraph>近年來，已經引進各種方法來解釋「黑箱」AI 模型的輸出。然而，目前並不清楚使用者是否實際理解和信任這些解釋。在本文中，我們專注於評估癌症風險的回歸工具的解釋，並探討解釋的內容和格式對以使用者為中心的理解和信任指標的影響。關於內容，我們實驗了兩種解釋方法：流行的 SHAP，基於博弈論概念，因此對於日常使用者來說可能很複雜，以及基於特徵遮蔽的 occlusion-1，可能更易於理解。關於格式，我們將 SHAP 解釋呈現為圖表 (SC)，這是慣例，而將 occlusion-1 解釋呈現為圖表 (OC) 以及文字 (OT)，其較為簡單的性質也適用於此。這些實驗等同於使用者研究，詢問參與者，具有兩種不同程度的專業知識（一般民眾和具備一些醫學訓練的人），他們對回歸工具輸出解釋的主觀和客觀理解和信任。在兩項研究中，我們發現，在基於內容進行比較時，一般來說，occlusion-1 優於 SHAP 解釋，在主觀理解和信任方面有明顯的偏好。然而，在僅控制格式的情況下直接比較解釋，在大多數情況下只顯示 OT 優於 SC 解釋的證據，這表明 occlusion-1 優於 SHAP 解釋的主導地位可能是由偏好文字而非圖表作為解釋所驅動的。最後，我們沒有發現解釋類型在客觀理解方面的差異證據。因此，總體而言，對解釋的內容和格式的選擇需要仔細注意，因為在某些情況下，格式而非內容，可能在改善使用者體驗方面發揮關鍵作用。</paragraph>

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro Liò, Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

摘要：大型語言模型 (LLM) 的最新突破提供了前所未有的自然語言理解和生成能力。然而，現有關於生物醫學中 LLM 的調查通常專注於特定應用或模型架構，缺乏整合各種生物醫學領域最新進展的全面分析。本綜述基於對來自 PubMed、Web of Science 和 arXiv 等數據庫的 484 篇出版物的分析，深入探討了生物醫學中 LLM 的當前現況、應用、挑戰和前景，其特點是關注這些模型在現實世界生物醫學背景中的實際應用。首先，我們探討了 LLM 在廣泛的生物醫學任務中的零次學習能力，包括診斷輔助、藥物發現和個性化醫療等，並從 137 項關鍵研究中汲取見解。然後，我們討論了 LLM 的適應策略，包括單模態和多模態 LLM 的微調方法，以增強它們在零次學習無法實現的專業生物醫學背景中的性能，例如醫療問題解答和生物醫學文獻的有效處理。最後，我們討論了 LLM 在生物醫學領域面臨的挑戰，包括數據隱私問題、模型可解釋性有限、數據集質量問題以及由於生物醫學數據的敏感性、對高度可靠模型輸出的需求以及在醫療保健中部署 AI 的倫理影響而產生的倫理問題。為了應對這些挑戰，我們還確定了生物醫學中 LLM 未來的研究方向，包括用於保護數據隱私的聯合學習方法以及整合可解釋 AI 方法以增強 LLM 的透明度。

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

摘要：人工智慧（AI）在醫療和保健應用中投入了大量的投資和開發，進而導致醫療技術中的先進控制系統。然而，AI 系統的不透明性引發了對此類敏感應用中所需基本特性的擔憂，例如透明度和可信度。我們的研究透過調查一個程序來解決這些問題，用於選擇最充分的可解釋 AI（XAI）方法，以符合歐盟法規在醫療器材的智慧型生物電子學中的說明要求。採用的方法從透過其控制機制（開迴路、閉迴路和半閉迴路系統）對智慧型裝置進行分類，並深入探討其技術開始。然後，我們分析這些法規以定義其對各種裝置和相關目標的可解釋性要求。同時，我們透過其說明目標對 XAI 方法進行分類。這允許將法律可解釋性要求與 XAI 說明目標相匹配，並確定適當的 XAI 演算法來達成它們。我們的研究結果提供了對哪些 XAI 演算法更符合歐盟法規以適用於不同類型的醫療器材的細緻理解。我們透過不同神經植入物的實際案例研究來證明這一點，從慢性疾病管理到先進的義肢。這項研究填補了將生物電子學中的 XAI 應用與歐盟法規的嚴格規定相符的重要空白。它為開發人員和研究人員提供了一個實用的架構，確保其 AI 創新能促進醫療技術並遵守法律和道德標準。

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

摘要：我們探索深度生成模型，在醫療聯邦學習設置中生成基於案例的說明。透過基於案例的可解釋性來解釋 AI 模型決策，對於增加信任並允許 AI 在臨床實務中廣泛採用至關重要。然而，醫療 AI 訓練範例正轉向聯邦學習設置，以符合資料保護法規。在聯邦情境中，過去的資料對目前的使用者而言是無法取得的。因此，我們使用深度生成模型來產生保護隱私和解釋決策的合成範例。我們的概念驗證著重於胸腔積液診斷，並使用公開可取得的胸部 X 光資料。

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. Gruühagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

摘要：軟組織和骨骼腫瘤（STBT）是罕見、診斷具有挑戰性的病灶，其臨床行為和治療方法各不相同。這篇系統性回顧提供了使用放射影像進行診斷和預後的人工智慧 (AI) 方法的概觀，重點說明了臨床轉譯的挑戰，並評估研究與醫療影像 AI 核查表 (CLAIM) 和 FUTURE-AI 可信賴且可部署 AI 的國際共識準則的一致性，以促進 AI 方法的臨床轉譯。這篇回顧涵蓋了幾個書目資料庫中的文獻，包括在 2024 年 7 月 17 日之前發表的論文。納入了以放射為基礎的 AI 診斷或預後原發性 STBT 的同行評審期刊中的原始研究。排除標準是動物、屍體或實驗室研究，以及非英文論文。摘要由三位獨立審查員中的兩位篩選資格。合格的論文由三位獨立審查員中的一位根據準則進行評估。搜索識別出 15,015 篇摘要，其中 325 篇文章被納入評估。大多數研究在 CLAIM 中表現中等，平均得分為 53 分中的 28.9±7.5 分，但在 FUTURE-AI 中表現不佳，平均得分為 30 分中的 5.1±2.1 分。STBT 的影像 AI 工具仍處於概念驗證階段，表明有顯著的改進空間。AI 開發人員未來的努力應集中在設計（例如定義未滿足的臨床需求、預期的臨床環境以及 AI 如何整合到臨床工作流程中）、開發（例如建立在先前的工作、可解釋性）、評估（例如評估和解決偏差、評估 AI 與最佳實務）、以及數據可複製性和可用性（公開提供文件化的代碼和數據）。遵循這些建議可以改善 AI 方法的臨床轉譯。

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga Strümke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

摘要：腦性麻痺 (CP) 的早期偵測對於有效的介入和監測至關重要。本文測試了可解釋 AI (XAI) 方法的可靠性和適用性，使用深度學習方法，透過分析從嬰兒動作影片記錄中提取的骨骼資料來預測 CP。具體來說，我們使用 XAI 評估指標（即忠實度和穩定性）來量化評估類別激活映射 (CAM) 和梯度加權類別激活映射 (Grad-CAM) 在這個特定醫療應用中的可靠性。我們利用一個獨特的嬰兒動作資料集，並應用骨骼資料擾動，而不會扭曲嬰兒動作的原始動力。我們的 CP 預測模型利用整體方法，因此我們評估了整體整體和個別模型的 XAI 指標表現。我們的研究結果表明，兩種 XAI 方法都能有效識別影響 CP 預測的關鍵身體部位，並且這些解釋對於微小的資料擾動具有魯棒性。Grad-CAM 在 RISv 指標中顯著優於 CAM，該指標衡量速度方面的穩定性。相比之下，CAM 在 RISb 指標中表現得更好，該指標與骨骼穩定性有關，而 RRS 指標則評估內部表示的魯棒性。整體中的個別模型顯示出不同的結果，CAM 和 Grad-CAM 都不一致地優於另一種，整體方法提供了其組成模型結果的表示。

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

摘要：最近的全球估計表明，多達 24.1 億人有
健康狀況可從復健服務中受益。居家
物理治療 (PT) 在提供互動式
回饋和有意義的觀察方面面臨重大挑戰，供治療師和患者使用。為了填補這
個缺口，我們提出 MicroXercise，它將微動作分析與
可穿戴式感測器整合在一起，為治療師和患者提供一個全面的
回饋介面，包括影片、文字和分數。至關重要的是，它採用
多維動態時間規整 (DTW) 和基於歸因的可解釋
方法來分析監控運動中現有的深度學習神經網路，專注於運動的高粒度。這種協同
方法至關重要，提供與輸入大小匹配的輸出，以精確地
突出 PT 中關鍵的細微差別和動作，從而將複雜的 AI
分析轉換為清晰、可操作的回饋。透過在不同指標中突顯這些微動作，例如穩定性和動作範圍，MicroXercise
顯著提升最終使用者對回饋的理解和相關性。比較效能指標強調其優於
傳統方法的有效性，例如特徵互惠資訊 (FMI) 和連續性分別提升了 39% 和 42%。MicroXercise 在居家
物理治療方面更進一步，提供技術先進且直覺有用的
解決方案，以提升患者照護和結果。

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah Rösman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

摘要：系統性文獻回顧是研究中證據品質最高的。然而，回顧過程受到顯著資源和資料限制的阻礙。文獻回顧網路 (LRN) 是第一個遵循 PRISMA 2020 標準的可解釋 AI 平台，旨在自動化整個文獻回顧過程。LRN 在外科手套實務領域中進行評估，使用專家開發的 3 個搜尋字串來查詢 PubMed。非專家訓練所有 LRN 模型。效能以專家手動回顧作為基準。可解釋性和效能指標評估 LRN 複製專家回顧的能力。一致性以 Jaccard 指數和混淆矩陣測量。研究人員在研究完成前對彼此的結果保密。重疊的研究整合到 LRN 生成的系統性回顧中。LRN 模型在沒有專家訓練的情況下展現出優異的分類準確率，達到 84.78% 和 85.71% 的準確率。效能最高的模型達到了高評分者間信賴度 (k = 0.4953) 和可解釋性指標，將「減少」、「意外」和「銳利」與「雙重戴手套」連結在一起。另一個 LRN 模型涵蓋了 91.51% 的相關文獻，儘管與非專家的判斷不同 (k = 0.2174)，但包含了「乳膠」、「雙重」（手套）和「適應症」等詞彙。LRN 優於手動回顧（11 個月超過 19,920 分鐘），將整個過程縮短為 5 天超過 288.6 分鐘。這項研究顯示，可解釋的 AI 不需要專家訓練即可成功進行專家等級的 PRISMA 相容系統性文獻回顧。LRN 總結了外科手套研究的結果，並找出與臨床研究人員發現幾乎相同的主题。可解釋的 AI 可以準確地加快我們對臨床實務的理解，有潛力革新醫療保健研究。

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

摘要：本研究使用盒子學框架分析混合人工智慧系統的設計模式及其在臨床決策中的有效性。它分類並比較結合機器學習和基於規則的推理的各種架構，以深入了解其結構基礎和醫療保健應用。針對兩個主要問題，如何根據既定的設計模式對這些系統進行分類，以及如何通過比較分析提取見解，本研究使用軟體工程中的設計模式來了解和優化醫療保健人工智慧系統。盒子學有助於識別共性並建立可重複使用的解決方案，從而增強這些系統的可擴充性、可靠性和效能。檢查了五種主要的架構：REML、MLRB、RBML、RMLT 和 PERML。每種架構都有獨特的優缺點，強調了在臨床任務中需要量身打造的方法。REML 在資料有限的資料集中表現出高精度的預測；MLRB 在處理大型資料集和複雜資料整合方面表現出色；RBML 在可解釋性和可信度方面表現出色；RMLT 在管理高維資料方面表現出色；而 PERML 儘管在分析方面有限，但在緊急照護場景中表現出潛力。本研究引入了四種新模式，建立了五種抽象分類模式，並進一步將這五種模式細化為具體的系統。這些貢獻增強了盒子學的分類組織，並提供了將專家知識與機器學習整合的新方法。盒子學的結構化、模組化方法在開發和分析混合人工智慧系統、揭示共性以及推廣可重複使用的解決方案方面具有顯著優勢。總之，本研究強調了混合人工智慧系統在推進醫療保健中的關鍵作用，以及盒子學在推動人工智慧整合進一步創新方面的潛力，最終改善臨床決策支援和患者的治療成果。

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

摘要：由於其強大的預測能力，深度學習已成為許多產業中不可或缺的工具，包括醫療保健。然而，傳統的深度學習模型通常缺乏可解釋性，並且忽略了將預測不確定性納入考量，而這兩個因素是臨床決策制定的關鍵組成部分。為了產生可解釋且具有不確定性意識的預測，本研究提出了一個名為貝氏柯爾莫哥洛夫阿諾德網路 (BKAN) 的新架構，它結合了柯爾莫哥洛夫阿諾德網路的表達能力與貝氏推論。我們在兩個醫學資料集上使用 BKAN，這些資料集是評估機器學習模型在醫學診斷中的廣泛使用基準：皮馬印第安人糖尿病資料集和克里夫蘭心臟病資料集。我們的模型提供了對預測信心和決策邊界的有益見解，並且在預測準確度方面優於傳統的深度學習模型。此外，BKAN 表現隨機和認識不確定性的能力，可確保醫生獲得更可靠且值得信賴的決策支援。根據實驗結果，我們的貝氏策略提高了模型的可解釋性，並大幅減少了過度擬合，這對於小型且不平衡的醫學資料集非常重要。我們提出了可能的擴充功能，以進一步將 BKAN 用於更複雜的多模式資料集，並探討這些發現對於未來建立可靠的醫療保健 AI 系統研究的重要性。這項工作為深度學習模型部署在透明度和可靠性至關重要的重要領域中開啟了一個新的典範。

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

摘要：在現代醫療保健中，解決準確疾病預測和個性化建議的複雜性既至關重要又具有挑戰性。本研究引入了 MLtoGAI，它將語義網路技術與機器學習 (ML) 相結合，以增強疾病預測並透過 ChatGPT 提供使用者友善的說明。該系統包含三個關鍵組成部分：一個可重複使用的疾病本体，其中包含有關各種疾病的詳細知識；一個診斷分類模型，它使用患者症狀來準確檢測特定疾病；以及語義網路規則語言 (SWRL) 與本体和 ChatGPT 的整合，以產生清晰、個性化的健康建議。這種方法顯著提高了預測準確性，並確保了易於理解的結果，解決了疾病和不同症狀的複雜性。MLtoGAI 系統展示了準確性和使用者滿意度的實質性進步，有助於開發更智慧且更易於取得的醫療保健解決方案。這種創新的方法結合了 ML 演算法的優點，以及透過 ChatGPT 提供透明且人類可以理解的說明的能力，在預測準確性和使用者理解方面取得了顯著的進步。透過利用語義技術和可解釋的 AI，該系統提高了疾病預測的準確性，並確保了建議與個別患者相關且易於理解。我們的研究強調了整合先進技術以克服醫療診斷中現有挑戰的潛力，為智慧醫療保健系統的未來發展鋪路。此外，該系統使用 200 個合成患者資料記錄進行驗證，確保了穩健的效能和可靠性。

##### **Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

摘要：可解釋人工智慧 (XAI) 是將人工智慧 (AI) 和機器學習 (ML) 演算法整合到臨床實務中的辯論核心。高執行效能的 AI/ML 模型，例如整體學習器和深度神經網路，通常缺乏可解釋性，阻礙臨床醫生對其預測的信任。為了解決這個問題，正在開發 XAI 技術，以人類可以理解的術語描述 AI/ML 預測。一個有希望的方向是採用敏感度分析 (SA) 和全球敏感度分析 (GSA)，它們本質上會依據模型輸入對預測的影響來對其進行排名。在此，我們介紹一種新的 delta-XAI 方法，透過擴充 GSA 指標 delta 指數來提供 ML 模型預測的局部解釋。delta-XAI 指數評估每個特徵值對回歸和分類問題中個別例項的預測輸出之影響。我們將 delta-XAI 指數形式化，並提供其實作的程式碼。使用線性回歸模型對模擬情境評估 delta-XAI 方法，並以 Shapley 值作為基準。結果顯示 delta-XAI 指數通常與 Shapley 值一致，但在具有高度影響力或極端特徵值的模型中存在顯著差異。delta-XAI 指數在偵測主要特徵和處理極端特徵值方面表現出更高的敏感度。定性地來說，delta-XAI 透過利用機率密度函數提供直觀的解釋，使特徵排名更清晰且對從業人員來說更具可解釋性。總體而言，delta-XAI 方法對於穩健地取得 ML 模型預測的局部解釋似乎很有希望。將在真實世界的臨床環境中進行進一步調查，以評估其對 AI 輔助臨床工作流程的影響。

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

摘要：失智症是一種影響全球數百萬人的衰弱性神經疾病，在診斷上具有重大挑戰。在這項工作中，我們提出了一種新的方法，用於對失智和非失智老年患者進行分類，使用 3D 大腦磁振造影 (MRI) 掃描。我們的做法採用了一種獨特技術，用於選擇性處理 MRI 切片，重點關注最相關的大腦區域，並排除信息量較少的部分。這種方法由一個基於信心的分類委員會補充，該委員會由三個自定義深度學習模型組成：Dem3D ResNet、Dem3D CNN 和 Dem3D EfficientNet。這些模型協同工作以增強決策的準確性，利用它們的集體優勢。在影像研究開放存取系列 (OASIS) 資料集上進行測試，我們的模型達到了 94.12% 的驚人準確度，超過了現有方法。此外，在阿茲海默症神經影像倡議 (ADNI) 資料集上的驗證證實了我們方法的穩健性和普遍性。可解釋 AI (XAI) 技術和全面的消融研究進一步證實了我們技術的有效性，提供了對決策過程和我們方法重要性的見解。這項研究為失智症診斷提供了重大進展，為臨床應用提供了一個高度準確且高效的工具。

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

摘要：藉由智慧環境中不引人注目的感測器辨識日常活動，能啟用各種醫療保健應用。監控受試者在家中如何執行活動，以及其隨著時間的變化，可以揭示健康問題的早期症狀，例如認知能力下降。此領域中的大多數方法都使用深度學習模型，這些模型通常被視為將感測器資料對應至活動的黑盒子。然而，非專家使用者（例如臨床醫師）需要信任並了解這些模型的輸出。因此，人類活動辨識的可解釋 AI (XAI) 方法應運而生，以提供來自這些模型的直覺自然語言說明。不同的 XAI 方法會產生不同的說明，而其有效性通常透過使用者調查來評估，這在成本和公平性方面通常具有挑戰性。本文提出使用大型語言模型 (LLM) 的自動評估方法，以在候選者中找出最適合非專家使用者的 XAI 方法。我們的初步結果表明，LLM 評估與使用者調查一致。

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

摘要：工業 5.0 著重於人類與人工智慧 (AI) 合作執行製造中的不同任務，涉及更多機器人、物聯網 (IoT) 裝置和互連、擴增/虛擬實境 (AR) 和其他智慧裝置。這些裝置和互連在經濟、醫療保健、教育和國防系統等各種關鍵領域的廣泛參與，引發了多種類型的潛在安全漏洞。AI 本身已被證明是網路安全不同領域中非常有效且強大的工具，例如入侵偵測、惡意軟體偵測和網路釣魚偵測等。就像在許多應用領域一樣，網路安全專業人員不願意接受黑盒 ML 解決方案來應用於網路安全。這種不願意促使可解釋人工智慧 (XAI) 作為一種工具被採用，有助於說明在基於 ML 的系統中如何做出決策。在這項調查中，我們對工業 5.0 的不同基於 XAI 的入侵偵測系統進行了全面的研究，並且我們也透過對抗式 XIDS (Adv-XIDS) 方法的觀點來探討可解釋性和可詮釋性對網路安全實務的影響。此外，我們分析了工業 5.0 的 XAI 網路安全系統中可能存在的機會和挑戰，引發了未來針對 XAI 基礎解決方案的研究，以供高風險的工業 5.0 應用採用。我們相信這項嚴謹的分析將為指定領域內的後續研究工作建立基礎架構。

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

摘要：本研究旨在探討將自然語言處理 (NLP) 和機器學習 (ML) 技術實作於醫療信函編碼自動化，並具備視覺化說明能力和輕量化的本地電腦設定。目前在臨床環境中，編碼是一種手動流程，涉及為病患文件中的每項病症、程序和藥物指派代碼 (例如，使用 SNOMED CT 代碼 56265001 表示心臟病)。此領域有使用最新 ML 模型進行自動編碼的初步研究；然而，由於模型的複雜性和大小，並未實現實際部署。為了進一步促進自動編碼實務的可能性，我們在本地電腦設定中探討了一些解決方案；此外，我們探討了說明功能在 AI 模型透明度中的功能。我們使用公開的 MIMIC-III 資料庫和 HAN/HLAN 網路模型進行 ICD 代碼預測。我們還試驗了 ICD 和 SNOMED CT 知識庫之間的對應。在我們的實驗中，這些模型提供了 97.98% 代碼的有用資訊。這項調查結果可以為實務中的自動臨床編碼實作提供一些見解，例如在醫院環境中，由臨床醫生使用的本地電腦，專案頁面 \url{https://github.com/Glenj01/Medical-Coding}。

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

摘要：人工智能 (AI) 支持的決策制定是未來 6G 網路中的關鍵元素，其中將引入原生 AI 的概念。此外，AI 廣泛用於不同的關鍵應用中，例如自動駕駛和醫療診斷。在這些應用中，使用 AI 作為黑盒模型是有風險且具有挑戰性的。因此，理解和信任這些模型做出的決策至關重要。解決此問題的方法是開發可解釋 AI (XAI) 架構，旨在解釋黑盒模型行為背後的邏輯，從而確保其有效且安全的部署。最近，我們提出了一個新的基於擾動的 XAI-CHEST 框架，該框架面向無線通信中的信道估計。XAI-CHEST 框架的核心思想是通過在無關輸入上引入高噪聲來識別相關模型輸入。這份手稿提供了 XAI-CHEST 框架的詳細理論基礎。特別是，我們推導了 XAI-CHEST 損失函數和噪聲閾值微調優化問題的解析表達式。因此，設計的 XAI-CHEST 提供了一種智能輸入特徵選擇方法，可以在優化所用模型的架構的同時進一步提高整體性能。模擬結果表明，XAI-CHEST 框架提供了有效的解釋，在降低所需的計算複雜度的同時，提供了改進的比特錯誤率性能，而這與基於傳統 DL 的信道估計相比。

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

摘要：这篇论文提出了用于从视网膜眼底图像进行疾病分类的扩张残差网络 (ResNet) 模型。扩张卷积滤波器用于替换 ResNet 模型较高层中的正常卷积滤波器（扩张 ResNet），以改善感知场，从而针对疾病分类对正常 ResNet 模型进行改进。本研究引入了采用深度学习的计算机辅助诊断工具，并通过可解释的 AI 技术进行了增强。这些技术旨在使该工具的决策过程透明化，从而使医学专业人士能够理解和信任 AI 的诊断决策。它们与当今的医疗保健领域尤为相关，在该领域，对 AI 应用的透明度需求不断增长，以确保其可靠性和合乎道德的使用。扩张 ResNet 用作正常 ResNet 的替代品，以提高视网膜眼部疾病的分类准确性并减少所需的计算时间。本工作中使用的数据集是眼科疾病智能识别 (ODIR) 数据集，这是一个结构化的眼科数据库，包含八类涵盖大多数常见视网膜眼部疾病。本工作中使用的评估指标包括精确度、召回率、准确度和 F1 得分。在这项工作中，对 ResNet-18、ResNet-34、ResNet-50、ResNet-101 和 ResNet-152 五个变体的正常 ResNet 模型和扩张 ResNet 模型进行了比较研究。与正常 ResNet 相比，扩张 ResNet 模型显示出有希望的结果，在 ODIR 多类疾病分类中，上述各个变体的平均 F1 得分为 0.71、0.70、0.69、0.67 和 0.70。

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v2 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
existing surveys on the trustworthiness of foundation models do not adequately
address their specific variations and applications within the medical imaging
domain. This survey aims to fill that gap by presenting a novel taxonomy of
foundation models used in medical imaging and analyzing the key motivations for
ensuring their trustworthiness. We review current research on foundation models
in major medical imaging applications, focusing on segmentation, medical report
generation, medical question and answering (Q\&A), and disease diagnosis. These
areas are highlighted because they have seen a relatively mature and
substantial number of foundation models compared to other applications. We
focus on literature that discusses trustworthiness in medical image analysis
manuscripts. We explore the complex challenges of building trustworthy
foundation models for each application, summarizing current concerns and
strategies for enhancing trustworthiness. Furthermore, we examine the potential
of these models to revolutionize patient care. Our analysis underscores the
imperative for advancing towards trustworthy AI in medical image analysis,
advocating for a balanced approach that fosters innovation while ensuring
ethical and equitable healthcare delivery.

摘要：基礎模型在醫學影像方面的快速進展，代表著在加強診斷準確性和個人化治療方面邁出一大步。然而，基礎模型在醫療保健中的部署需要對其可信度進行嚴格的審查，包括隱私、穩健性、可靠性、可解釋性和公平性。目前關於醫學影像中基礎模型的調查文獻中顯示出相當大的差距，特別是在可信度方面。此外，現有關於基礎模型可信度的調查並未充分解決其在醫學影像領域中的特定變化和應用。本調查旨在通過提出醫學影像中使用的基礎模型的新分類法並分析確保其可信度的關鍵動機，來填補這一空白。我們回顧了基礎模型在主要醫學影像應用中的當前研究，重點關注分割、醫療報告生成、醫療問題和回答 (Q&A) 以及疾病診斷。這些領域之所以被強調，是因為與其他應用相比，它們已經看到相對成熟且大量的基礎模型。我們專注於探討醫學影像分析手稿中可信度的文獻。我們探討了為每個應用構建可信基礎模型的複雜挑戰，總結了當前關注點和增強可信度的策略。此外，我們探討了這些模型在革新患者護理方面的潛力。我們的分析強調了在醫學影像分析中朝著可信賴的人工智慧邁進的必要性，並倡導一種平衡的方法，既能促進創新，又能確保道德和公平的醫療保健服務。

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

摘要：床邊超音波 (POCUS) 是臨床醫師在患者床邊進行和解讀超音波掃描的實務。然而，解讀這些影像所需的專業知識相當可觀，而且在緊急情況下可能並非隨時具備。這種現實情況使得機器學習分類器等演算法對於加強人類決策變得極為有價值。POCUS 裝置正以合理成本推出，尺寸為手機大小。將 POCUS 裝置轉變為救生工具的挑戰在於，解讀超音波影像需要專門訓練和經驗。不幸的是，取得正向訓練影像的困難度代表著建置有效率且準確的分類器的一大障礙。因此，我們嘗試探討的問題是如何探索策略，以提高使用稀疏資料訓練的分類器的準確度。我們假設使用少數資料實例進行訓練可能不足以讓分類器概括，導致它們過度擬合。我們的做法使用可解釋 AI 增強方法，以協助演算法從較少的資料中學習更多，並潛在協助分類器更好地概括。

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

摘要：近年來，美國見證了電子煙或電子香菸使用率大幅激增，導致電子煙和電子煙使用相關肺損傷 (EVALI) 病例顯著增加，在 2019 年 EVALI 爆發期間造成住院和死亡，凸顯了理解電子煙行為和制定有效戒菸策略的迫切性。由於社群媒體平台的普及，全球超過 47 億使用者使用它們進行連結、溝通、新聞和娛樂，其中很大一部分與健康相關，因此將社群媒體資料建立為公共衛生研究中無價的有機資料資源。在本研究中，我們從 Reddit 上一個電子煙子社群中提取一個範例資料集，以分析使用者的戒電子煙意圖。利用 OpenAI 最新的大型語言模型 GPT-4 進行句子層級的戒電子煙意圖偵測，本研究比較了此模型的結果與外行人和臨床專家註解。使用不同的提示策略，例如零次學習、一次學習、少次學習和思考鏈提示，我們開發了 8 個提示，詳細程度不同，向 GPT-4 解釋任務，並評估這些策略彼此之間的效能。這些初步發現強調了 GPT-4 在社群媒體資料分析中的潛力，特別是在識別人類偵測可能無法察覺的使用者微妙意圖方面。

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

摘要：<paragraph>人工智慧（AI）目前在很大程度上依賴於缺乏可解釋性的黑盒機器學習模型。可解釋性人工智慧（XAI）領域致力於解決這個主要問題，這在金融、法律和健康等高風險領域至關重要。
我們提出了一種基於範疇論定義 AI 模型及其可解釋性的方法。為此，我們採用組合模型的概念，它以形式弦圖的形式看待模型，這些弦圖捕獲了模型的抽象結構及其具體實現。這種綜合觀點包含了確定性、概率性和量子模型。我們將各種 AI 模型作為組合模型進行比較，包括線性和基於規則的模型、（遞迴）神經網路、Transformer、VAE，以及因果和 DisCoCirc 模型。
接下來，我們根據模型的組合結構給出模型解釋的定義，展示如何分析模型的可解釋性，並使用它來澄清 XAI 中的常見主題。我們發現，讓標準的「內在可解釋」模型如此透明的原因在圖表中表現得最為清楚。這引導我們得出更一般的組合可解釋（CI）模型概念，它另外還包括因果、概念空間和 DisCoCirc 模型。
接下來，我們展示了 CI 模型的可解釋性優勢。首先，它們的組合結構允許計算其他感興趣的量，並可能通過匹配模型的結構來促進從模型到被建模現象的推理。其次，它們允許對其行為進行圖解說明，這些說明基於影響約束、圖解手術和重寫說明。最後，我們討論了這種方法的許多未來方向，提出了如何在實踐中學習這種有意義的結構化模型的問題。</paragraph>

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

摘要：元宇宙的概念在各個領域都備受關注，其重要應用之一便是醫療保健。元宇宙有巨大的潛力透過改變病患照護、醫學教育，以及教學/學習和研究的方式來轉型醫療保健。本研究的目的是提供元宇宙基本概念和基礎技術的介紹。本文探討了元宇宙在醫療保健背景下的優缺點，並從技術和 AI 的角度分析其潛力。特別是，討論了機器學習方法的角色；我們將說明如何將機器學習演算法應用於元宇宙產生的資料，以獲得醫療保健應用方面的更佳見解。此外，我們透過探討區塊鏈等新興技術，並解決隱私問題，來探討元宇宙在醫療保健方面的未來願景。本研究的發現有助於更深入地了解元宇宙在醫療保健中的應用，以及其在醫療服務提供方面發揮革命性變革的潛力。

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

摘要：慢性腎臟病（CKD）是一種廣泛的慢性疾病，沒有已知的最終療法且發病率很高。研究表明，進行性慢性腎臟病（CKD）是一種異質性疾病，會顯著影響腎臟結構和功能，最終導致腎衰竭。隨著時間的推移，慢性腎臟病已從影響少數人的致命疾病轉變為一種嚴重程度不同的常見疾病。本研究的目標是使用集成學習和可解釋的 AI 進行早期預後和 CKD 檢測，並視覺化主導特徵、特徵分數和表現出的值。為此，提出了一種 AI 驅動的預測分析方法，以幫助臨床醫生為個別患者開具生活方式修改建議，以降低這種疾病的進展速度。我們的數據集是從 CKD 患者和健康受試者的身體生命體徵中收集的，以準確開發我們提出的 AI 驅動的解決方案。在這方面，提供了血液和尿液檢測結果，並應用基於集成樹的機器學習模型來預測未發現的 CKD 病例。我們的研究結果經過與腎臟科醫生的長期諮詢後得到驗證。我們的實驗和解釋結果與各種醫療保健領域中現有的可解釋 AI 應用進行了比較，包括 CKD。比較表明，我們開發的 AI 模型，特別是隨機森林模型，已經確定了比 XgBoost 更多作為重要貢獻者的特徵。可解釋性 (I) 衡量重要特徵與掩蓋特徵的比率，表明我們的 XgBoost 模型在這個指標中獲得了更高的分數，特別是 98% 的保真度，並且在 FII 指數中自然高於競爭模型。

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

摘要：心理健康構成了一項複雜且普遍的全球挑戰，影響了數百萬人的生活，並經常導致嚴重的後果。在本文中，我們進行了一項徹底的調查，以探索數據科學、人工智慧和心理保健的交集，重點關注通過線上社交媒體 (OSM) 進行心理疾病檢測的最新發展。很大一部分人口積極參與 OSM 平台，創造了一個龐大的人員資料庫，對心理健康分析具有巨大的潛力。本文探討了傳統的診斷方法、最先進的資料和 AI 驅動的研究，以及心理保健中可解釋 AI (XAI) 模型的出現。我們回顧了最先進的機器學習方法，特別是那些基於現代深度學習的方法，同時強調了醫療保健 AI 模型中可解釋性的必要性。實驗設計部分提供了對普遍做法的見解，包括可用的資料集和評估方法。我們還找出該領域的主要問題和挑戰，並提出了有希望的未來研究方向。由於心理健康決策需要透明度、可解釋性和道德考量，本文有助於推進心理保健中透過社交媒體推進 XAI 的持續討論。這裡提出的全面概述旨在引導研究人員、從業人員和政策制定者發展心理疾病檢測領域。

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

摘要：<paragraph>醫療照護中需要 AI 輔助的臨床診斷。現有的深度學習模型缺乏可解釋性，並且主要專注於影像分析。最近開發的動態不確定因果關係圖 (DUCG) 方法是因果驅動的、可解釋的，並且在不同的應用場景中是不變的，沒有資料收集、標記、擬合、隱私、偏見、概化、高成本和高能耗的問題。通過臨床專家和 DUCG 技術人員之間的密切合作，構建了涵蓋 54 個主訴的 46 個 DUCG 模型。可以在沒有分流的情況下診斷出 1,000 多種疾病。在應用於實際世界之前，46 個 DUCG 模型已由第三方醫院回溯性驗證。驗證的診斷精度不低於 95%，其中包括罕見疾病在內的每種疾病的診斷精度不低於 80%。驗證後，46 個 DUCG 模型已在中國實際應用。已經執行了超過一百萬個真實診斷案例，僅發現 17 個不正確的診斷。由於 DUCG 的透明性，發現並糾正了導致不正確診斷的錯誤。頻繁應用 DUCG 的臨床醫生的診斷能力得到了顯著提高。在介紹了前面提出的 DUCG 方法論之後，提出了潛在健康檢查的推薦演算法，並提取了 DUCG 的關鍵思想。</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

摘要：精確且及時地偵測乳癌對於改善患者預後至關重要。診斷方法傳統上依賴於單一模式方法；然而，醫療資料分析正在整合超越傳統影像的各種資料來源。使用整合影像和非影像資料的多模式技術，標誌著乳癌診斷的變革性進展。本篇綜述的目的是探討多模式技術的新興領域，特別是將組織病理學影像與非影像資料融合。此外，可解釋人工智慧 (XAI) 將用於闡明複雜演算法的決策過程，強調診斷過程中可解釋性的必要性。本綜述利用多模式資料並強調可解釋性，以提高診斷準確性、臨床醫師的信心和患者參與度，最終促進乳癌更個人化的治療策略，同時也找出多模式和可解釋性的研究差距，引導未來的研究，並為該領域的策略方向做出貢獻。

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

摘要：自注意力機制已被採用於多個廣泛使用的訊息傳遞神經網路 (MPNN)（例如 GAT），它可以自適應地控制沿著底層圖形邊緣流動的資訊量。這種注意力的使用使得此類模型成為可解釋 AI (XAI) 研究的基線，因為透過注意力的詮釋已在各種領域（例如自然語言處理和電腦視覺）中普及。然而，現有的研究通常使用天真的計算方法從注意力中推導出歸因分數，並且沒有考慮到邊緣歸因的精確且仔細的計算。在我們的研究中，我們旨在填補注意力啟用 MPNN 的廣泛使用與它們在很大程度上未被充分探索的可解釋性之間的差距，這個主題已在其他領域積極研究。為此，作為第一次嘗試，我們將 GNN 中注意力權重的邊緣歸因問題形式化。然後，我們提出 GATT，一種建立在計算樹上的邊緣歸因計算方法。透過全面的實驗，我們展示了我們提出的方法在評估 GAT 的歸因時所具有的效果。相反地，我們憑經驗驗證了僅對圖注意力層上的注意力權重取平均值不足以詮釋 GAT 模型的行為。程式碼已公開於 https://github.com/jordan7186/GAtt/tree/main。

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

摘要：新生兒期是大腦發育最脆弱的時期，容易出現癲癇發作。大腦發育不成熟時出現癲癇發作會造成不良後果，因此需要及早診斷。目前新生兒癲癇發作的黃金標準依賴於連續的視訊腦電圖 (EEG) 監測；其中包括在新生兒加護病房 (NICU) 內同時進行多頻道腦電圖 (EEG) 記錄和即時視訊監控。然而，視訊腦電圖監控技術需要臨床專業知識，而且通常僅限於技術先進且資源豐富的環境。具成本效益的新技術可以幫助醫療界準確診斷並立即提倡治療。在這項工作中，提出了一個新穎的可解釋深度學習模型，以自動化新生兒癲癇發作偵測過程，並採用減少的腦電圖裝置，其中採用了卷積神經網路、圖形注意力層和全連接層。除了能夠使用減少的裝置即時偵測癲癇發作外，此模型還提供了即時可解釋性的獨特優勢。透過在 Zenodo 資料集上使用 10 倍交叉驗證評估效能，所提出的模型在曲線下面積 (AUC) 和召回率方面分別達到了 8.31% 和 42.86% 的絕對改善。

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

摘要：乳癌 (BC) 是影響全球女性最常見的惡性腫瘤之一，因此需要進步的診斷方法，以改善臨床結果。本文全面探討了可解釋人工智慧 (XAI) 技術在乳癌偵測和診斷中的應用。隨著人工智慧 (AI) 技術持續滲透醫療保健領域，特別是在腫瘤學中，透明且可解釋的模型需求變得勢在必行，以增強臨床決策制定和患者照護。此篇評論探討了各種 XAI 方法的整合，例如 SHAP、LIME、Grad-CAM 等，以及用於乳癌偵測和分類的機器學習和深度學習模型。透過探討乳癌資料集的模式，包括乳房攝影、超音波及其在 AI 中的處理，本文重點說明 XAI 如何能導致更準確的診斷和個人化治療計畫。它也探討了實施這些技術的挑戰，以及制定標準化評量指標以評估 XAI 在臨床環境中的有效性的重要性。透過詳細的分析和討論，本文旨在強調 XAI 在縮小複雜 AI 模型與實務醫療保健應用之間差距的潛力，進而促進醫療專業人員之間的信任與理解，並改善患者的結果。

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

摘要：語音情緒辨識 (SER) 由於其在心理健康、教育和人機互動等多個應用領域而備受關注。然而，SER 系統的準確性受到高維特徵集的阻礙，這些特徵集可能包含不相關和冗餘的資訊。為了克服這個挑戰，本研究提出了一種用於 SER 的迭代特徵提升方法，該方法強調特徵相關性和可解釋性，以增強機器學習模型的效能。我們的做法涉及仔細的特徵選擇和分析，以建立高效的 SER 系統。為了透過模型可解釋性解決我們的核心問題，我們採用了具有 Shapley 值的特徵評估迴圈，以反覆改善特徵集。這個過程在模型效能和透明度之間取得平衡，這使得我們能夠全面了解模型的預測。所提出的方法提供了多項優點，包括識別和移除不相關和冗餘的特徵，從而建立更有效的模型。此外，它促進了可解釋性，有助於理解模型的預測以及識別情緒決定的關鍵特徵。所提出的方法的有效性已在多倫多情緒語音集 (TESS)、柏林情緒語音資料庫 (EMO-DB)、賴爾森音訊視覺情緒語音和歌曲資料庫 (RAVDESS) 和薩里音訊視覺表達情緒 (SAVEE) 資料集的 SER 基準上得到驗證，其效能優於現有方法。據我們所知，這是第一個將模型可解釋性納入 SER 架構的研究。本文的原始碼可透過此連結公開取得：https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition。

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, Héloïse de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

摘要：可解释性通常对于人工智能 (AI) 的可接受实施至关重要。在医疗保健领域，这一点尤为重要，因为决策直接影响患者，并且对 AI 系统的信任至关重要。这种信任通常建立在 AI 提供的解释和诠释之上。尽管 AI 可解释性取得了重大进展，但仍然需要明确的指导方针，说明在医疗环境中何时以及在多大程度上需要解释。我们提出了一种新颖的分类系统，该系统具有四种不同的解释必要性类别，指导所需的解释级别：患者或样本（局部）级别、队列或数据集（全局）级别，或两个级别。我们引入了一个数学公式，该公式区分了这些类别，并为研究人员提供了一个实用框架，以确定医疗 AI 应用中所需的解释的必要性和深度。考虑了三个关键因素：评估协议的稳健性、专家观察的可变性以及应用程序的表示维数。从这个角度来看，我们解决了这个问题：AI 医疗应用何时需要解释，以及需要解释到何种程度？

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

摘要：人工智慧 (AI) 領域正快速影響著健康與醫療保健，但對於面臨廣泛結構性壓迫的人群來說，偏見和不良表現依然存在。先前的研究已清楚說明，需要更嚴格地注意資料代表性和模型效能，以促進公平性並減少偏見。然而，我們有機會透過運用社會流行病學和健康公平的最佳實務，來改善 AI 的可解釋性，以幫助我們針對發現的關聯性，發展假設。在本文中，我們專注於可解釋 AI (XAI)，並描述一個跨領域專家小組審查架構，以從多重觀點討論和批判性評估 AI 模型的解釋，並找出偏見領域和未來研究的方向。我們強調跨領域專家小組對於產生更準確、公平的詮釋至關重要，而這些詮釋是根據歷史和脈絡而來的。跨領域小組討論有助於減少偏見、找出潛在的混淆因素，並在文獻中有缺口時找出額外研究的機會。反過來，這些見解可以建議 AI 模型改進的機會。

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. Zając, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

摘要：人工智慧（AI）在實驗室實驗中不斷地與放射科醫師匹敵或表現得更出色。然而，發現放射科 AI 為基礎系統的實際執行幾乎沒有提供臨床價值。本文探討如何為 AI 設計在不同情境中臨床上的效用。我們根據功能性 AI 為基礎原型的三次迭代，在丹麥和肯亞的 7 個臨床場域與 13 位放射科醫師進行了 19 次設計會議和設計介入。十個社會技術依賴關係被認為對於放射科中 AI 的設計至關重要。我們概念化了四個技術面向，必須根據預期的臨床使用情境進行設定：AI 功能、AI 醫療重點、AI 決策門檻，以及 AI 可解釋性。我們提出四項設計建議，說明如何處理與醫療知識、診所類型、使用者專業知識等級、患者情境，以及影響這些技術面向設定的使用者情境相關的依賴關係。

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

摘要：隨著先進的 AI/ML，對可解釋 AI (XAI) 的研究不斷增加，以及關於人類如何與 AI 和 XAI 互動以進行有效的人工智慧協作決策制定。然而，我們仍然缺乏對 AI 系統和 XAI 應如何首先呈現給沒有技術背景的用戶的了解。在本文中，我們展示了與醫療專業人員 (n=12) 和主修醫學和健康的學生 (n=4) 進行半結構化訪談的結果，以研究如何改善 AI 和 XAI 的入門。對於訪談，我們建立在人機互動準則之上，為中風康復評估和 AI 解釋的 AI 系統創建入門材料，並將它們介紹給參與者。我們的研究結果表明，除了呈現傳統的 AI 性能指標外，參與者還希望基准信息、AI 的實際好處以及交互試驗，以更好地將 AI 性能情境化，並完善 AI 的目標和性能。根據這些發現，我們強調了改進 AI 和 XAI 以及人機協作決策制定的入門方向。

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

摘要：本文使用機器學習 (ML) 和可解釋人工智慧 (XAI) 技術來探討營養狀況與阿茲海默症 (AD) 相關的死亡率之間的關係。採用第三次全國健康與營養檢查調查 (NHANES III) 資料庫進行分析。選擇隨機森林模型作為 XAI 分析的基礎模型，並使用 Shapley Additive Explanations (SHAP) 方法來評估特徵重要性。結果突顯了重要的營養因素，例如血清維生素 B12 和糖化血紅蛋白。該研究證明了隨機森林在預測 AD 死亡率方面相較於其他疾病的有效性。本研究提供了營養對 AD 的影響的見解，並有助於更深入地了解疾病的進展。

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

摘要：<paragraph>初級保健提供者對於最初的分流和轉診到專科照護至關重要。在青光眼的情況下，無症狀且快速惡化可能導致視力喪失，因此需要及時轉診給專家。然而，初級眼科保健提供者可能無法識別緊急情況，可能會延誤照護。提供解釋的人工智慧 (AI) 可以加強他們的轉診決策。我們研究各種 AI 解釋如何幫助提供者區分需要立即或非緊急專科轉診的患者。我們建立了解釋性 AI 演算法，以從例行眼科護理資料預測青光眼手術需求，作為識別高風險患者的代理。我們納入了內在和事後解釋性，並與驗光師進行了一項線上研究，以評估人機團隊的表現，衡量轉診準確度並分析與 AI 的互動，包括同意率、任務時間和使用者體驗感知。在 87 名參與者中，AI 支援提高了轉診準確度（使用 AI/未使用的比例為 59.9%/50.8%），儘管人機團隊的表現不如單獨使用 AI。參與者認為他們在使用內在模型時更多地納入了 AI 建議，並認為它更有用且更有希望。沒有解釋，AI 建議的偏差會增加。AI 支援並未增加工作量、信心和信任，但減少了挑戰。在一個單獨的測試集中，我們的黑盒子和內在模型在預測手術結果方面分別達到了 77% 和 71% 的準確度。我們找出在初級眼科保健中，人機團隊合作管理青光眼的機會，並注意到雖然 AI 提高了轉診準確度，但即使有解釋，它也顯示出與單獨使用 AI 相比的效能差距。人類參與在醫療決策中仍然至關重要，這強調了未來研究優化協作、確保正面經驗和安全使用 AI 的必要性。</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

摘要：在醫學影像中，特別是在早期疾病檢測和預後任務中，辨別 AI 模型預測背後的原理對於評估其決策的可靠性至關重要。傳統的解釋方法在識別醫學影像分類中可識別的決定性特徵時面臨挑戰，其中區別性特徵很微妙或並不明顯。為了彌合這一差距，我們提出了一個可解釋的模型，該模型具備決策推理和特徵識別能力。我們的做法不僅檢測有影響力的影像模式，還揭示了推動模型最終預測的決定性特徵。通過實施我們的模型，我們可以有效識別和視覺化由數據驅動模型利用的類特定特徵，從而深入了解深度學習模型的決策過程。我們在要求嚴格的醫學預後任務領域驗證了我們的模型，展示了其在提高 AI 在醫療保健中的可靠性和發現預後理解受限疾病的新知識方面的功效和潛力。

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

摘要：本研究探討線上健康社群中尋求資訊支持的問題、回應，以及有幫助的評分之間的關係。我們建立了一組標記的問答配對資料集，並開發了多模態機器學習和深度學習模型，以可靠地預測資訊支持問題和回應。我們採用可解釋的 AI 來揭示資訊支持交流中蘊含的情緒，證明情緒在提供資訊支持中的重要性。這種情緒支持和資訊支持之間的複雜交互作用以前並未被研究過。本研究改進了社會支持理論，並為使用者決策輔助工具的開發奠定了基礎。討論了進一步的影響。

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

摘要：在科技飛速發展的時代，一位意外的訪客已在全球教室中佔有一席之地，那就是人工智慧。生成式 AI，例如 ChatGPT，承諾在教育領域掀起一場革命，但它卻是一把雙面刃。它在個人化學習方面的潛力，卻因作弊、不準確以及教育工作者難以將其有效融入教學設計等問題而抵銷。我們正站在這教育前沿的邊緣，顯然我們需要非常小心地探索這片領域。這是一個重大的挑戰，可能會損害我們教育過程的完整性和價值。那麼，我們如何將這些挑戰轉化為機遇？當不適當地使用時，AI 工具可能會成為複製貼上心態的完美工具，並迅速腐蝕批判性思維、創造力和深入理解，這些都是我們快速變化的世界中最重要的技能。教師們覺得他們沒有能力利用這項技術，這擴大了教育工作者和機構之間的數位鴻溝。解決這些問題需要深入的研究方法。我們將採用實證研究，借鑑技術接受模型，來評估教育工作者和學生對生成式 AI 的態度。了解他們的看法、使用模式和障礙是創造有效解決方案的第一個關鍵步驟。本研究將作為未來研究人員應用的流程手冊，根據此處說明的步驟運行他們自己的數據

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike Grüne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, André Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

摘要：隨著醫療保健系統的數位化，人工智慧在醫學領域中變得更加普及。特別是機器學習在時間序列分類等複雜任務中展現出極大的潛力，但通常是以透明度和可理解性為代價。這導致人類缺乏信任，從而阻礙了其積極使用。可解釋的人工智慧試圖通過提供對決策過程的洞察來彌補這一差距，但其不同方法的實際效用尚不清楚。本文提出了一個基於使用者研究的評估，其中包含了 Grad-CAM 解釋方法，並將其應用於神經網路以分類時間序列新生兒呼吸數據中的呼吸。我們展示了不同利益相關者對可解釋性方法的感知效用，揭示了實現實際透明度的難度，以及許多參與者希望獲得更深入的解釋。

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

摘要：大型語言模型 (LLM) 與醫療診斷整合
為臨床決策提供了一個有前景的途徑。本研究概述了一種新穎方法的開發，用於零次學習/少量學習情境學習 (ICL)，方法是使用多層結構化提示整合醫療領域知識。我們還探討了使用者與 LLM 之間兩種溝通方式的功效：數值對話 (NC) 方式，它會逐步處理資料，以及自然語言單回合 (NL-ST) 方式，它會使用長篇敘事提示。
我們的研究系統性地評估了診斷準確性和風險因子，包括性別偏見和假陰性率，使用了一個包含 920 個患者記錄的資料集，採用各種少量學習情境。結果表明，傳統的臨床機器學習 (ML) 模型通常在零次學習和少量學習設定中表現優於 LLM。然而，當使用少量學習範例以及有效的可解釋 AI (XAI) 方法作為領域知識來源時，效能差距會顯著縮小。此外，隨著時間充足和範例數量增加，對話方式 (NC) 幾乎可以媲美 ML 模型的效能。最值得注意的是，LLM 相對於 ML 模型展現出相當或更佳的成本敏感準確度。
本研究證實，透過適當的領域知識和量身打造的溝通策略，LLM 可以顯著增強診斷程序。這些發現突顯了最佳化訓練範例數量和溝通方式的重要性，以提高準確度並減少 LLM 應用中的偏差。

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel Miró-Nicolau, Gabriel Moyà-Alcover, Antoni Jaume-i-Capó, Manuel González-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

摘要：隨著對深度學習模型依賴性的增加，加上其固有的透明度不足，促使一個新的研究領域發展，稱為可解釋 AI (XAI) 方法。這些方法旨在透過深入了解決策背後的原理，來提升最終使用者對自動化系統的信賴。本文提出了一種衡量使用者對 XAI 系統信賴度的新穎方法，允許對其進行改進。我們提出的指標結合了客觀觀點下的效能指標和信賴指標。為了驗證這個新穎的方法，我們在一個真實的醫療場景中進行了一個案例研究：使用 XAI 系統從 X 光影像中偵測肺炎。

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

摘要：COVID-19 疫情對全球公共衛生造成壓力，必須進行準確的診斷和干預，以控制疾病傳播並降低死亡率。本文介紹了一個可解釋的深度生存預測模型，專門設計用於透過胸部 X 光 (CXR) 影像改善對 COVID-19 預後的理解和信賴。透過整合大規模預訓練影像編碼器、風險特定 Grad-CAM 和解剖區域偵測技術，我們的做法產生區域可解釋的結果，有效捕捉必要的疾病特徵，同時專注於罕見但關鍵的異常區域。我們的模型預測結果透過風險區域定位提供增強的清晰度和透明度，讓臨床醫生能夠在更了解預後見解的情況下，就 COVID-19 診斷做出明智的決策。我們在多中心生存資料集上評估所提出的方法，並透過量化和質化評估證明其有效性，達到優異的 C 指數（0.764 和 0.727）和時間相關 AUC（0.799 和 0.691）。這些結果表明，我們可解釋的深度生存預測模型在風險預測方面超越傳統的生存分析方法，提升臨床決策的解釋性，並增強 AI 系統的信賴度。

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

摘要：<paragraph>在過去幾年，臨床決策支援系統 (CDSS) 中的人工智慧 (AI) 在利用機器學習和深度學習架構方面發揮了關鍵作用。儘管 AI 模型具有令人滿意的能力，但缺乏透明度和可解釋性，特別是在可靠性為必要考量的醫療背景下，這帶來了重大的挑戰。在不影響預測精準度的情況下實現透明度仍然是一項關鍵挑戰。本文提出了一種新方法，即 Rad4XCNN，以增強 CNN 衍生特徵的預測能力，同時具備放射特徵固有的可解釋性。Rad4XCNN 不同於基於顯著性圖的傳統方法，它通過放射組學將可理解的含義與 CNN 衍生特徵關聯起來，為超越視覺化圖表的解釋方法提供了新的觀點。我們以乳癌分類任務作為案例研究，在超音波影像資料集上評估 Rad4XCNN，包括一個線上資料集和兩個用於內部和外部驗證的內部資料集。一些關鍵結果如下：i) 與 ViT 衍生特徵和放射特徵相比，CNN 衍生特徵保證了更穩健的準確度；ii) 傳統的視覺化圖解釋方法存在一些缺陷；iii) Rad4XCNN 沒有犧牲模型準確度來換取其可解釋性；iv) Rad4XCNN 提供了全局解釋見解，使醫師能夠分析模型輸出和發現。此外，我們強調將可解釋性整合到 AI 模型中對於增強臨床實務中的信任和採用至關重要，並強調了我們的方法如何能緩解與可解釋 AI 方法相關的一些疑慮。</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

摘要：隨著人工智慧 (AI) 的普及整合，在涉及 AI 驅動系統的事故中，責任和義務歸屬產生了複雜的挑戰。這些系統的互連性、AI 引發事故的倫理問題，加上 AI 技術的不確定性和缺乏相應法規，使得傳統責任歸屬面臨挑戰。為此，本研究提出了一種計算反思均衡 (CRE) 方法，以建立一個連貫且在倫理上可接受的責任歸屬架構，適用於所有利害關係人。計算方法提供了結構化的分析，克服了概念方法在處理動態且多面向情境時的限制，展示了該架構在責任歸屬過程中具備的可解釋性、連貫性和適應性。我們探討了與均衡計算中索賠相關的初始啟動層級的關鍵作用。我們以 AI 輔助醫療決策支援系統為案例研究，說明不同的初始化如何導致不同的責任分配。該架構提供了對 AI 引發事故中問責制的寶貴見解，透過持續監控、修訂和反思，促進了永續且有韌性的系統發展。

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

摘要：人工智慧透過預測模型協助醫療專業人員，大幅轉變了臨床決策制定。本研究探討了在醫療保健中使用人工智慧應用程式時公平性和可解釋性的關鍵需求，以確保在不同的患者人口統計資料中獲得公平的結果。透過專注於敗血症相關死亡率的預測模型，我們提出了一種方法，該方法會學習一個效能最佳化的預測模型，然後採用轉移學習過程來產生一個具有更好公平性的模型。我們的模型還引入了一種新穎的基於排列的特徵重要性演算法，旨在闡明每個特徵在增強預測公平性方面的貢獻。與現有的可解釋性方法專注於解釋特徵對預測效能的貢獻不同，我們提出的方法獨特地彌補了理解每個特徵如何有助於公平性的差距。這項進展至關重要，因為敗血症的死亡率很高，且在三分之一的醫院死亡中扮演著角色。我們的模型不僅有助於識別和減輕預測模型中的偏差，還能透過提高模型預測的透明度和公平性來培養醫療保健利益相關者之間的信任，進而有助於提供更公平且值得信賴的醫療保健服務。

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

摘要：現今，憂鬱症是一個重要的議題。根據世界衛生組織 (WHO) 的資料，在 2023 年，超過 2.8 億人正在與憂鬱症搏鬥。這是一個龐大的數字；如果不認真看待，這些數字將會快速增加。大約有 48.9 億人是社群媒體使用者。人們在 Twitter、Facebook、Reddit、Instagram 等平台上表達自己的感受和情緒。這些平台包含有價值的資訊，可用於研究目的。已經在各種社群媒體平台上進行了大量的研究。然而，這些努力仍存在某些限制。特別是，先前的研究僅專注於偵測推文中的憂鬱症和憂鬱症的強度。此外，資料集標籤中存在不準確的情況。在這項研究工作中，使用基於詞彙標籤的 Twitter 資料庫中的推文預測了五種類型的憂鬱症（雙極型、重度、精神病型、非典型和產後）。可解釋的 AI 用於透過強調代表憂鬱症類型的推文部分來提供推理。從 Transformers（BERT）中提取的雙向編碼器表示用於特徵提取和訓練。機器學習和深度學習方法用於訓練模型。BERT 模型呈現出最有希望的結果，達到 0.96 的整體準確度。

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

摘要：深度学习正大幅轉變醫學影像和放射線學領域，能辨識醫學影像中的病理，包括電腦斷層掃描 (CT) 和 X 光掃描。然而，深度學習模型的效能，特別是在分割任務中，常常受到廣泛註解資料集需求的限制。為了應對此挑戰，透過可解釋 AI 和反事實解釋的產生，探索弱監督語意分割的能力。本研究的範圍是開發一種新的反事實內插方法 (COIN)，該方法使用生成模型將預測的分類標籤從異常翻轉為正常。例如，如果分類器將輸入的醫學影像 X 視為異常，表示存在病理，則生成模型旨在內插異常區域，從而逆轉分類器的原始預測標籤。此方法使我們能夠產生病理的精確分割，而無需依賴於預先存在的分割遮罩。至關重要的是，利用影像層級標籤，這比建立詳細的分割遮罩容易取得。該方法的有效性透過分割合成目標和從愛沙尼亞塔爾圖大學醫院取得的 CT 影像中的實際腎臟腫瘤來證明。研究結果表明，COIN 遠遠超過已建立的歸因方法，例如 RISE、ScoreCAM 和 LayerCAM，以及 Singla 等人提出的另一種反事實解釋方法。此證據表明，COIN 是一種很有前途的 CT 影像中腫瘤語意分割方法，並在醫療保健中讓深度學習應用更易於取得和更有效率邁進一步，其中註解資料很稀少。

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

摘要：在本文中，我們探討數位人文學科 (DH) 作為一門學科與混合智能 (HI) 作為一個研究典範之間的協同作用。在 DH 研究中，數位方法的使用，特別是人工智慧的使用，受到一系列要求和限制。我們認為這些要求和限制獲得 HI 的能力和目標的充分支持。我們的貢獻包括找出五個這樣的 DH 要求：成功的 AI 系統需要能夠 1) 與（人類）學者合作；2) 支援資料批評；3) 支援工具批評；4) 察覺並迎合各種觀點；5) 支援遠距和近距離閱讀。我們將混合智能的 CARE 原則（協作、適應、負責和可解釋）作為理論架構，並將這些原則對應到 DH 要求。在此對應中，我們納入範例研究專案。最後，我們探討如何將 DH 的見解應用於 HI，並討論結合這兩個學科的開放挑戰。

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

摘要：基礎模型 (FM) 具有徹底改變醫學影像的巨大潛力。然而，它們在現實世界臨床環境中的部署需要廣泛的倫理考量。本文旨在強調與 FM 相關的倫理問題，並提出一個框架來指導它們在醫學中的負責任開發和實施。我們仔細審查了倫理問題，例如患者數據隱私、偏差緩解、演算法透明度、可解釋性和問責制。所提出的框架旨在優先考慮患者福利、減輕潛在風險，並培養對 AI 輔助醫療保健的信任。

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

摘要：甲狀腺癌是一種日益嚴重的全球健康問題，需要先進的診斷方法。本篇評論探討了人工智能與放射特徵分析在甲狀腺癌診斷中的應用。在符合 PRISMA 指南的情況下，對多個資料庫進行了回顧，直到 2023 年 10 月。通過結合關鍵字，發現了一篇關於甲狀腺癌和相關主題的英文學術出版物。在移除 109 篇重複文獻後，原始搜尋共回傳 267 篇論文。在根據預先確定的標準，淘汰了 124 篇文章的摘要和標題後，選出了相關研究。在進行全面分析後，額外排除了六項研究。在納入的 28 項研究中，結合超音波 (US) 影像的放射特徵分析，證明了其在診斷甲狀腺癌方面的有效性。研究結果不一，有些研究提出了優於現狀的新策略。文獻強調了人工智能模型面臨的各種挑戰，包括可解釋性問題、資料集限制和操作員依賴性。28 項納入研究的綜合發現提到，需要標準化工作和前瞻性多中心研究來解決這些問題。此外，還確定了克服這些障礙的方法，例如可解釋人工智能技術和個人化醫療技術的進步。本篇評論重點探討了人工智能和放射特徵分析如何轉變甲狀腺癌的診斷和治療。儘管存在挑戰，但未來對多學科合作、臨床適用性驗證和演算法改進的研究，仍有潛力改善甲狀腺癌治療中的患者預後和診斷精準度。

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

摘要：<paragraph>近年來，乳癌的盛行率迅速增加，使其成為全球主要的死亡原因之一。在所有癌症中，乳癌迄今為止是最常見的。手動診斷此疾病需要大量的時間和專業知識。由於乳癌的檢測過程耗時，因此透過建立機器學習模型來預測，有助於防止其進一步擴散。機器學習和可解釋 AI 在分類中至關重要，因為它們不僅可以提供準確的預測，還可以深入了解模型如何做出決策，有助於理解和信賴分類結果。在此研究中，我們評估並比較了五種不同的機器學習方法的分類準確度、精確度、召回率和 F1 分數，使用了一個主要的資料集（達卡醫學院醫院的 500 名患者）。五種不同的監督式機器學習技術，包括決策樹、隨機森林、邏輯迴歸、朴素貝氏和 XGBoost，已用於在我們的資料集上取得最佳結果。此外，本研究將 SHAP 分析應用於 XGBoost 模型，以解釋模型的預測並了解每個特徵對模型輸出的影響。我們比較了幾種演算法對資料進行分類的準確度，並與該領域的其他文獻進行對比。在最後評估後，本研究發現 XGBoost 達到了最佳的模型準確度，為 97%。</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

摘要：深度學習 (DL) 用於從乳房攝影術影像診斷乳癌的模型通常以「黑盒子」方式運作，這使得醫療保健專業人員難以信任和理解其決策過程。本研究提出一個整合架構，結合卷積神經網路 (CNN) 和可解釋人工智慧 (XAI)，以使用 CBIS-DDSM 資料集增強乳癌的診斷。方法包含一個精細的資料前處理管線和進階資料擴充技術，以對抗資料集限制，並採用預先訓練的網路（例如 VGG-16、Inception-V3 和 ResNet）進行遷移學習。我們研究的重點是評估 XAI 在解釋模型預測中的有效性，重點利用豪斯多夫測度量化評估 AI 生成的解釋和專家註解之間的一致性。這種方法對於 XAI 在促進 AI 輔助診斷中的可信度和倫理公平性至關重要。我們研究的發現說明了 CNN 和 XAI 在推進乳癌診斷方法中的有效協作，從而促進了先進 AI 技術在臨床環境中的更順暢整合。透過增強 AI 驅動決策的可解釋性，這項工作為 AI 系統和醫療從業人員之間的改善協作奠定了基礎，最終豐富了患者照護。此外，我們研究的影響遠遠超出了目前的技術。它鼓勵進一步研究如何結合多模式資料並改善 AI 解釋，以滿足臨床實務的需求。

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

摘要：本研究提出了一種創新的多模態數據融合方法，用於疼痛行為識別，將統計相關分析與以人為中心的見解相結合。我們的做法引入了兩項關鍵創新：1) 將數據驅動的統計相關權重整合到融合策略中，以有效利用來自異質模態的補充信息，以及 2) 將以人為中心的運動特徵納入多模態表示學習中，以詳細建模疼痛行為。我們的模型在各種深度學習架構中得到驗證，展示了卓越的性能和廣泛的適用性。我們提出了一個可自定義的框架，根據統計顯著性將每個模態與合適的分類器對齊，推進個性化和有效的多模態融合。此外，我們的模型提供對多模態數據的可解釋分析，有助於醫療保健中的可解釋和可解釋 AI。通過強調數據多樣性和模態特定表示的重要性，我們增強了傳統的融合技術，並為識別複雜的疼痛行為設定了新的標準。我們的發現對促進以患者為中心的醫療保健干預和支持可解釋的臨床決策制定具有重要意義。

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

摘要：以人为本的可解释 AI (HCXAI) 倡导将社会层面整合到 AI 解释中。HCXAI 话语的核心是社会透明度 (ST) 框架，其目标是让 AI 系统的社会组织背景对用户来说是可理解的。在这项工作中，我们建议扩展 ST 框架以解决大型语言模型 (LLM) 中社会错误归因的风险，尤其是在心理健康等敏感领域。事实上，LLM 能够出色地模拟角色和人格，这可能导致设计者的意图和用户对社会属性的认知之间出现错配，从而有风险促进情绪操纵和危险行为、认知不公正和不合理的信任。为了解决这些问题，我们建议用第五个“W 问题”来增强 ST 框架，以明确设计者和用户赋予 LLM 的具体社会属性。此补充旨在弥合 LLM 能力和用户认知之间的差距，促进基于 LLM 的技术在道德上负责任地开发和使用。

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

摘要：<paragraph>背景：氣胸是一種因肺部與胸壁之間異常集氣所引起的急性胸腔疾病。為了解決深度學習（DL）模型經常伴隨的不透明性，可解釋人工智慧（XAI）方法已被引入，用於概述與 DL 模型做出的氣胸診斷相關的區域。然而，這些解釋有時會與實際病灶區域有所出入，突顯出進一步改進的必要性。方法：我們提出了一種模板引導式方法，將氣胸的臨床知識納入 XAI 方法產生的模型解釋中，從而提升這些解釋的品質。利用放射科醫師建立的病灶描繪，我們的做法首先產生一個模板，用於表示氣胸可能發生的區域。然後將此模板疊加在模型解釋上，以篩選出超出模板邊界的無關解釋。為了驗證其效力，我們對三種 XAI 方法進行了比較分析，在兩個真實世界資料集中解釋兩個 DL 模型時，分別採用和不採用我們的模板引導。結果：所提出的方法在建立於三種 XAI 方法、兩個 DL 模型和兩個資料集的十二種基準情境中，始終改善了基準 XAI 方法。在比較模型解釋和真實病灶區域時，透過基準效能的效能改進計算出的平均增量百分比為交集比（IoU）的 97.8% 和骰子相似性係數（DSC）的 94.1%。結論：在氣胸診斷的背景下，我們提出了一種模板引導式方法，用於改善 AI 解釋。我們預期我們的模板引導將透過整合臨床領域專業知識，為闡明 AI 模型建立一種新方法。</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by Séamus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

摘要：<paragraph>在當前機器翻譯 (MT) 領域中，Transformer 架構脫穎而出，成為黃金標準，特別是對於高資源語言對。本研究探討其對低資源語言對的效能，包括英語↔愛爾蘭語和英語↔馬拉地語語言對。值得注意的是，本研究識別出最佳超參數和子詞模型類型，以顯著提高 Transformer 模型對低資源語言對的翻譯品質。
低資源語言的平行資料集的稀缺會阻礙 MT 的發展。為了解決這個問題，開發了 gaHealth，這是愛爾蘭語的第一個雙語健康資料語料庫。專注於健康領域，使用此域內資料集開發的模型在 BLEU 得分方面表現出非常顯著的進步，與 LoResMT2021 共享任務中的模型相比。隨後使用多維品質指標錯誤分類法進行的人工評估顯示，與基於 RNN 的對應模型相比，Transformer 系統在減少準確性和流暢性錯誤方面表現出優異的性能。
此外，本論文介紹了 adaptNMT 和 adaptMLLM，這兩個開源應用程式簡化了神經機器翻譯模型的開發、微調和部署。這些工具大幅簡化了設定和評估流程，讓 MT 更容易讓開發人員和翻譯人員使用。值得注意的是，adaptNMT 以 OpenNMT 生態系統為基礎，通過強調模型開發的環境足跡來促進生態友好的自然語言處理研究。與 LoResMT2021 共享任務中的基準相比，adaptMLLM 對 MLLM 的微調證明了英語↔愛爾蘭語和英語↔馬拉地語這兩個低資源語言對的翻譯性能進步。</paragraph>

##### **Cause and Effect: Can Large Language Models Truly Understand Causality?**
2402.18139v3 by Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Mayank Jindal, Dushyant Singh Sengar, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, Aman Chadha

With the rise of Large Language Models(LLMs), it has become crucial to
understand their capabilities and limitations in deciphering and explaining the
complex web of causal relationships that language entails. Current methods use
either explicit or implicit causal reasoning, yet there is a strong need for a
unified approach combining both to tackle a wide array of causal relationships
more effectively. This research proposes a novel architecture called Context
Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to
enhance causal reasoning and explainability. The proposed framework
incorporates an explicit causal detection module with ConceptNet and
counterfactual statements, as well as implicit causal detection through LLMs.
Our framework goes one step further with a layer of counterfactual explanations
to accentuate LLMs understanding of causality. The knowledge from ConceptNet
enhances the performance of multiple causal reasoning tasks such as causal
discovery, causal identification and counterfactual reasoning. The
counterfactual sentences add explicit knowledge of the not caused by scenarios.
By combining these powerful modules, our model aims to provide a deeper
understanding of causal relationships, enabling enhanced interpretability.
Evaluation of benchmark datasets shows improved performance across all metrics,
such as accuracy, precision, recall, and F1 scores. We also introduce
CausalNet, a new dataset accompanied by our code, to facilitate further
research in this domain.

摘要：隨著大型語言模型 (LLM) 的興起，了解它們在解碼和解釋語言所蘊含的複雜因果關係網路中的能力和限制變得至關重要。目前的技術使用明確或隱含的因果推理，但強烈需要一種統一的方法，結合兩者以更有效地處理廣泛的因果關係。本研究提出了一種稱為情境感知推理增強與反事實分析 (CARE CA) 框架的新架構，以增強因果推理和可解釋性。提出的框架結合了使用 ConceptNet 和反事實陳述的明確因果檢測模組，以及透過 LLM 進行的隱含因果檢測。我們的框架更進一步，加入一層反事實解釋，以強調 LLM 對因果關係的理解。來自 ConceptNet 的知識增強了多項因果推理任務的執行，例如因果發現、因果識別和反事實推理。反事實句加入了未由情境造成的明確知識。透過結合這些強大的模組，我們的模型旨在提供對因果關係更深入的理解，實現增強的可解釋性。基準資料集的評估顯示在所有指標（例如準確度、精確度、召回率和 F1 分數）上都有所提升。我們還引入了 CausalNet，一個新的資料集，並附上了我們的程式碼，以促進在這個領域的進一步研究。

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

摘要：糖尿病（DM）使患者容易出現血管併發症。
視網膜影像和血管反映身體的微血管和巨血管健康狀況。它們可用於診斷糖尿病併發症，包括糖尿病視網膜病變（DR）、神經病變、腎病和動脈粥樣硬化性心血管疾病，以及預測心血管事件的風險。為使用數位化視網膜影像進行高通量 DR 檢測而開發的人工智慧（AI）啟用系統已在臨床採用。除了 DR 篩檢外，AI 整合也具有巨大的潛力來應對與糖尿病患者整體照護相關的挑戰。在這項工作中，我們旨在全面回顧基於視網膜影像的 AI 應用相關研究的文獻，這些研究與糖尿病的診斷、預後和管理有關。我們將描述整體 AI 輔助糖尿病照護的發現，包括但不限於 DR 篩檢，並討論實施此類系統的障礙，包括與倫理、資料隱私、公平存取和可解釋性有關的問題。透過評估患者的健康狀況，同時考量糖尿病併發症以及未來心血管併發症的風險預後，AI 輔助視網膜影像分析有潛力成為糖尿病患者現代化個人化醫療的中心工具。

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

摘要：這項研究從多個利害關係人的角度探討不同的人工智慧 (AI) 應用在教育上的可接受性，包括學生、老師和家長。承認 AI 在教育上的轉型潛力，它解決了與資料隱私、AI 代理、透明度、可解釋性和 AI 的道德部署相關的疑慮。透過小插曲方法，參與者被呈現了四種情境，其中 AI 的代理、透明度、可解釋性和隱私受到操縱。在每個情境後，參與者完成了一項調查，該調查捕捉了他們對 AI 的整體效用、個人效用、正義、信心、風險和如果可用，使用每個情境的 AI 的意圖的看法。資料蒐集包含來自合作機構和社群媒體活動的 1198 位多利害關係人參與者的最終樣本，並專注於對四個 AI 使用案例的個別回應。對資料的調解分析表明，對 AI 的接受度和信任在利害關係人團體之間有顯著差異。我們發現，AI 的代理、透明度和可解釋性高低程度之間的關鍵調解者，以及使用不同教育 AI 的意圖，包括感知到的整體效用、正義和信心。這項研究強調，接受 AI 在教育上的應用是一個微妙且多面向的問題，除了不同的利害關係人的看法外，還需要仔細考慮具體的 AI 應用及其特徵。

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

摘要：<paragraph>基於可穿戴式單導程心電圖 (ECG) 裝置的遠端病患監測在早期偵測心臟疾病方面具有顯著的潛力，特別是與用於自動化心臟疾病偵測的人工智慧 (AI) 方法結合使用時。先前已有研究應用基於深度學習的 AI 方法進行心臟疾病偵測。然而，這些模型尚未被廣泛接受為臨床診斷的可靠輔助工具，部分原因在於圍繞許多 AI 演算法的當前黑箱感知。特別是，有必要找出有助於做出準確診斷的 ECG 訊號關鍵特徵，從而增強模型的可解釋性。在本研究中，我們開發了一種視覺轉換器方法，以根據單導程 ECG 資料找出心房顫動。殘差網路 (ResNet) 方法也已開發出來，以便與視覺轉換器方法進行比較。這些模型應用於 Chapman-Shaoxing 資料集，以分類心房顫動，以及另一種常見的心律不整，竇性心動過緩，和正常竇性心律的心跳。這些模型能夠找出決定最終分類的心跳關鍵區域，並強調 P 波和 T 波，以及心跳持續時間和訊號振幅在區分正常竇性心律與心房顫動和竇性心動過緩方面的重要性。</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

摘要：本文介紹了一種使用先進大型語言模型 (LLM) 進行憂鬱症偵測和治療的新模式：生成式預訓練Transformer 4 (GPT-4)、Llama 2 聊天機器人和 Gemini。這些 LLM 經過微調，具備專業提示，可診斷、解釋並建議憂鬱症的治療介入方法。一種獨特的少次提示方法增強了模型根據 DSM-5 標準分析和解釋憂鬱症狀的能力。在互動階段，這些模型會參與同理心對話管理，從 PsychDB 和認知行為療法 (CBT) 指南等資源中汲取，促進與經歷重度憂鬱症的人們的支持性互動。此外，這項研究還介紹了 Illuminate 資料庫，其中包含各種 CBT 模組，有助於個性化治療建議。這項研究使用 F1 分數、準確率、召回率、餘弦相似度和面向召回率的 Gisting 評估替身 (ROUGE) 等指標，在不同的測試集中評估 LLM 的表現，證明了它們的有效性。這種綜合方法結合了尖端的 AI 與既定的心理方法，為心理保健提供了新的可能性，並展示了 LLM 在革新憂鬱症診斷和治療策略方面的潛力。

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v5 by Timothée Schmude, Laura Koesten, Torsten Möller, Sebastian Tschiatschek

Every AI system that makes decisions about people has a group of stakeholders
that are personally affected by these decisions. However, explanations of AI
systems rarely address the information needs of this stakeholder group, who
often are AI novices. This creates a gap between conveyed information and
information that matters to those who are impacted by the system's decisions,
such as domain experts and decision subjects. To address this, we present the
"XAI Novice Question Bank," an extension of the XAI Question Bank containing a
catalog of information needs from AI novices in two use cases: employment
prediction and health monitoring. The catalog covers the categories of data,
system context, system usage, and system specifications. We gathered
information needs through task-based interviews where participants asked
questions about two AI systems to decide on their adoption and received verbal
explanations in response. Our analysis showed that participants' confidence
increased after receiving explanations but that their understanding faced
challenges. These included difficulties in locating information and in
assessing their own understanding, as well as attempts to outsource
understanding. Additionally, participants' prior perceptions of the systems'
risks and benefits influenced their information needs. Participants who
perceived high risks sought explanations about the intentions behind a system's
deployment, while those who perceived low risks rather asked about the system's
operation. Our work aims to support the inclusion of AI novices in
explainability efforts by highlighting their information needs, aims, and
challenges. We summarize our findings as five key implications that can inform
the design of future explanations for lay stakeholder audiences.

摘要：<paragraph>每個對人進行決策的 AI 系統都有一群個人受到這些決策影響的利益關係人。然而，AI 系統的說明很少針對這群利益關係人的資訊需求，他們通常是 AI 新手。這在傳達的資訊和對受系統決策影響的人來說重要的資訊之間，造成了一道鴻溝，例如領域專家和決策主體。為了解決這個問題，我們提出了「XAI 新手問題庫」，這是 XAI 問題庫的延伸，包含來自兩個使用案例中 AI 新手的資訊需求目錄：就業預測和健康監控。目錄涵蓋了資料、系統背景、系統使用和系統規格等類別。我們透過任務型訪談收集資訊需求，參與者在其中詢問了兩個 AI 系統的問題，以決定採用與否，並收到口頭說明作為回應。我們的分析顯示，參與者在收到說明後，信心有所提升，但他們的理解面臨挑戰。這些挑戰包括難以找到資訊和評估自己的理解，以及試圖外包理解。此外，參與者對系統風險和好處的先前認知影響了他們的資訊需求。認為風險高的人尋求有關系統部署背後意圖的說明，而認為風險低的人則詢問系統的運作。我們的研究旨在透過強調他們的資訊需求、目標和挑戰，來支持將 AI 新手納入可解釋性工作。我們將我們的研究結果總結為五個關鍵影響，這些影響可以為未來針對非專業利益相關者受眾的說明設計提供參考。</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet Gürkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

摘要：人工智慧 (AI) 的快速演進，尤其是在大型語言模型 (LLM) 和生成式 AI 的領域，為各個領域的應用開啟了新途徑，但其在商業教育中的角色仍未被充分探討。本研究首次引入了基準，用以評估七個主要 LLM 的效能，包括 OpenAI 的模型 (GPT-3.5 Turbo、GPT-4 和 GPT-4 Turbo)、Google 的模型 (PaLM 2、Gemini 1.0 Pro) 和 Anthropic 的模型 (Claude 2 和 Claude 2.1)，這些模型將用於研究生商業課程入學程序中的關鍵考試 GMAT。我們的分析顯示，大多數 LLM 的表現都優於人類考生，其中 GPT-4 Turbo 不僅優於其他模型，更超越了頂尖商學院的研究生平均分數。透過案例研究，本研究探討了 GPT-4 Turbo 在解釋答案、評估回應、辨識錯誤、調整說明和產生替代情境方面的能力。與前一代版本相比，最新的 LLM 版本 GPT-4 Turbo、Claude 2.1 和 Gemini 1.0 Pro 在推理任務方面有顯著的進步，凸顯了其在解決複雜問題方面的潛力。儘管 AI 在教育、評量和輔導方面的承諾很明確，但仍有挑戰存在。我們的研究不僅闡明了 LLM 的學術潛力，也強調了在教育中審慎開發和應用 AI 的必要性。隨著 AI 技術的進步，建立 AI 互動的架構和協定、驗證 AI 生成的內容的準確性、確保全球各地多元學習者的存取權，以及創造一個 AI 支持人類專業知識的教育環境至關重要。本研究為進一步探索負責任地使用 AI 來豐富教育體驗並改善考試準備和評量方法奠定了基礎。

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

摘要：預測加護病房 (ICU) 病患的院內死亡率是最終臨床結果的關鍵。AI 已展現出優異的準確度，但卻缺乏可解釋性。為了解決這個問題，本文提出了一個可解釋的多模式死亡率預測器 (X-MMP)，採用有效且可解釋的 AI 方式，藉由多模式 ICU 資料來預測院內死亡率。我們在架構中採用多模式學習，可以接收來自臨床資料的異質輸入並做出決策。此外，我們引入了一個可解釋的方法，也就是分層傳播至 Transformer，作為 LRP 方法適當地延伸至 Transformer，對多模式輸入產生解釋，並揭露歸因於預測的顯著特徵。此外，每個模式對臨床結果的貢獻可以視覺化，協助臨床醫師了解決策背後的理由。我們根據 MIMIC-III 和 MIMIC-III 波形資料庫比對子集建構了一個多模式資料集。在基準資料集上的全面實驗證明，我們提出的架構可以達成合理的詮釋，並具備競爭力的預測準確度。特別是，我們的架構可以輕鬆地轉移到其他臨床任務，這有助於在醫療保健研究中發現關鍵因素。

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian Geißler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, Björn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias Küster, André Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

摘要：在過去的十年中，病理學中的人工智慧 (AI) 方法已大幅進步。然而，由於許多挑戰，包括將研究結果轉化為臨床診斷產品在技術和法規方面的障礙，以及缺乏標準化介面，導致整合到常規臨床實務中進展緩慢。開放且與供應商無關的 EMPAIA 計畫應對了這些挑戰。在此，我們提供 EMPAIA 的成就和經驗教訓的概述。EMPAIA 整合了病理學 AI 生態系統的各個利害關係人，即病理學家、電腦科學家和產業。在密切合作下，我們制定了技術互通性標準、AI 測試和產品開發建議，以及可解釋性方法。我們實作了模組化且開放原始碼的 EMPAIA 平臺，並成功整合了來自 8 個不同供應商的 14 個基於 AI 的影像分析應用程式，展示了不同的應用程式如何使用單一的標準化介面。我們優先考慮需求，並評估了 AI 在歐洲和亞洲的 14 個不同病理實驗室中的實際臨床應用。除了技術開發外，我們還為所有利害關係人建立了一個論壇，以分享數位病理學和 AI 的資訊和經驗。商業、臨床和學術利害關係人現在可以採用 EMPAIA 的常見開放原始碼介面，這為大規模標準化和簡化流程提供了獨特的機會。需要進一步的努力才能有效且廣泛地建立例行實驗室使用中的 AI 輔助。為此，已成立非營利協會 EMPAIA International，以作為永續基礎架構，繼續進行標準化，並支援廣泛實作和倡導 AI 輔助數位病理學的未來。

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

摘要：反事實解釋 (CE) 技術已引起關注，作為一種為與 AI 系統互動的使用者提供見解的方法。雖然在醫學影像和自動駕駛汽車等領域廣泛研究，圖形反事實解釋 (GCE) 方法相對較少被探索。GCE 會產生一個類似於原始圖形的新圖形，並根據基礎預測模型產生不同的結果。在這些 GCE 技術中，儘管在其他領域（例如藝術風格和自然語言建模）中展現出令人印象深刻的成就，但植基於生成機制的技術獲得的關注相對有限。對生成式解釋器的偏好源於它們在推理期間產生反事實實例的能力，利用輸入圖形的自主獲取擾動。基於上述理由，我們的研究引入了 RSGG-CE，一種用於反事實解釋的新型穩健隨機圖形生成器，能夠從學習到的潛在空間中產生反事實範例，考慮部分有序的生成序列。此外，我們進行定量和定性分析，以比較 RSGG-CE 的效能與 SoA 生成式解釋器，強調其增強了產生合理解釋候選的能力。

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

摘要：可解釋 AI 的動機之一是讓人們在使用和部署 AI 模型時做出更好、更明智的決策。但需要仔細評估以評估是否已達到此預期。目前的評估主要集中在解釋的演算法特性，而涉及人類受試者的評估通常採用主觀問題來測試人類對解釋有用性的看法，而沒有基於客觀指標和測量。在這項工作中，我們評估解釋是否可以在機器學習模型開發的實際場景中改善人類決策制定。我們進行了一項涉及影像資料的混合方法使用者研究，以評估 SmoothGrad、GradCAM 和預言解釋在兩個任務中產生的顯著性圖：模型選擇和反事實模擬。令人驚訝的是，我們沒有發現任何顯著性圖（即使是設計為易於理解且高度指示答案的合成預言解釋）能讓使用者在這些任務上顯著改善的證據。儘管如此，解釋確實有助於使用者更準確地描述模型。這些發現提示我們要對基於顯著性的解釋中可能存在誤解的有用性保持謹慎。

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

摘要：可解釋性和安全性建立信任。這些需要一個模型來展示一致性和可靠性。為了實現這些，有必要使用和分析數據和知識，並使用與 AI 應用相關的統計和符號 AI 方法 - 單獨使用任何一種方法都不會奏效。因此，我們主張並試圖證明 NeuroSymbolic AI 方法更適合於使 AI 成為受信任的 AI 系統。我們提出了 CREST 框架，展示了一致性、可靠性、使用者層級的可解釋性和安全性是如何建立在 NeuroSymbolic 方法上的，該方法使用數據和知識來支持關鍵應用（例如健康和福祉）的要求。本文重點關注大型語言模型 (LLM)，因為它是 CREST 框架中選擇的 AI 系統。LLM 因其在處理廣泛的自然語言處理 (NLP) 場景方面的多功能性而備受研究人員的關注。例如，ChatGPT 和 Google 的 MedPaLM 已成為提供一般和健康相關查詢信息的極有希望的平台。儘管如此，這些模型仍然是黑盒子，儘管納入了人類反饋和指令引導的調整。例如，儘管制定了安全防護措施，ChatGPT 仍可能產生不安全的回應。CREST 提出了一種合理的方法，在 NeuroSymbolic 框架中利用程序和基於圖表的知識，以闡明與 LLM 相關的挑戰。

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

摘要：本研究调查了在 COVID-19 疫情期间及以后预测死亡率时，已部署人工智能 (AI) 模型的性能、可解释性和稳健性。作为同类研究中的首例，我们发现贝叶斯神经网络 (BNN) 和智能训练技术让我们的模型在数据发生重大变化时仍能保持性能。我们的结果强调了开发稳健的 AI 模型的重要性，即使在具有挑战性的条件下，这些模型也能匹配或超越临床医生的预测。我们对模型可解释性的探索表明，随机模型会产生更多样化且个性化的解释，从而突出了在现实世界的临床环境中提供详细且个性化见解的 AI 模型的必要性。此外，我们强调了量化 AI 模型中不确定性的重要性，这使临床医生能够根据可靠的预测做出更明智的决策。我们的研究提倡在医疗保健的 AI 研究中优先考虑实施科学，并确保 AI 解决方案在现实世界的临床环境中实用、有益且可持续。通过解决医疗保健环境中的独特挑战和复杂性，研究人员可以开发出有效改善临床实践和患者预后的 AI 模型。

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

摘要：肺癌占英國癌症死亡人數的 21%，五年存活率很大程度取決於癌症被發現的階段。最近的研究已證明人工智能方法具有從例行掃描中準確及早診斷肺癌的能力。然而，此證據尚未轉化為臨床實務，其中一個障礙是缺乏可解釋的模型。本研究探討了應用變分自動編碼器 (VAE)，一種生成式人工智能模型，於肺癌病灶。將提出的模型訓練於從 LIDC-IDRI 公共數據集中提取的 3D 電腦斷層掃描病灶。通過聚類探索了 VAE 生成的 2D 切片的潛在向量表示，以證明其品質，並用於肺癌診斷的 MLP 分類器模型，最佳模型達到了 AUC 0.98 和 93.1% 準確度的最先進指標。聚類分析顯示，VAE 潛在空間根據有意義的特徵組成（包括腫瘤大小、形狀、患者和惡性類別）將惡性和良性病灶的數據集分開。我們還包括標準高斯 VAE (GVAE) 和更新的狄利克雷 VAE (DirVAE) 的比較分析，後者用狄利克雷分佈取代先驗，以促進具有解開特徵表示的更具可解釋性的潛在空間。最後，我們展示了與臨床有意義的特徵變化相應的潛在空間橫越的潛力。

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

摘要：現有的圖像分類器輸出解釋工具可分為依賴於模型內部存取權限的白盒，以及與模型無關的黑盒。隨著 AI 在醫療領域的使用增加，可解釋性工具的使用也隨之增加。現有醫學影像解釋的工作重點在於白盒工具，例如 gradcam。然而，切換到黑盒工具有明顯的優點，包括能夠與任何分類器一起使用，以及廣泛的黑盒工具可供選擇。在標準影像上，黑盒工具與白盒一樣精確。在本文中，我們比較了多種黑盒方法在腦癌 MRI 資料集上與 gradcam 的效能。我們證明大多數黑盒工具不適合解釋醫學影像分類，並詳細分析其缺點的原因。我們還表明一種黑盒工具，基於因果可解釋性的 rex，表現與 \gradcam 一樣好。

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v3 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

摘要：AI 開發社群日益利用 Hugging Face 等託管中介機構提供用戶上傳的模型和訓練資料的簡易存取權限。這些模型市集降低了數十萬名用戶的技術部署障礙，但可能會被用於許多潛在有害和非法的方式。在本文中，我們說明 AI 系統既可以「包含」內容，又可以作為開放式工具，這提出了迄今為止最棘手的平台治理挑戰之一。我們提供 Hugging Face、GitHub 和 Civitai 等三個說明性平台上數起事件的案例研究，以檢視模型市集如何審核模型。根據此分析，我們概述產業為回應審核需求而開發的重要（但仍有限）實務：授權、存取和使用限制、自動化內容審核和開放政策制定。雖然當前政策挑戰相當可觀，我們最後提出一些構想，說明平台如何能更好地動員資源，作為謹慎、公平且適度的法規存取點。

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

摘要：<paragraph>背景和目標：通過提取這些資訊，機器或深度學習 (ML/DL) 基於自主數據分析工具可以協助臨床醫生和癌症研究人員從複雜的數據集中發現模式和關係。最近已發表許多基於 DL 的卵巢癌 (OC) 數據分析。這些分析在癌症的各個方面（例如，它們涉及的子領域和癌症類型）和數據分析功能方面高度多樣化。然而，目前缺乏對這些分析在這些特徵和 AI 保證 (AIA) 方面的全面理解。這篇系統性回顧旨在通過檢視現有文獻並明確關注關鍵特徵和 AI 保證觀點，來填補這個空白。方法：使用 PRISMA 架構在三個期刊資料庫中進行全面搜尋。分析僅包括 2015 年至 2023 年間發表於同行評審期刊的研究。結果：在回顧中，總共檢視了 96 項由 DL 驅動的分析。研究結果揭示了幾個關於由 DL 驅動的卵巢癌數據分析的重要見解：- 大多數研究 71%（96 項中有 68 項）專注於檢測和診斷，而沒有研究探討 OC 的預測和預防。- 這些分析主要基於來自非多元族群的樣本（75%（96 項研究中的 72 項）），僅限於某個地理位置或國家。- 只有少部分研究（僅 33%（96 項研究中的 32 項）執行整合分析，其中大多數使用同質數據（臨床或組學）。- 值得注意的是，只有 8.3%（96 項研究中的 8 項）使用外部和多元數據集驗證了其模型，強調了加強模型驗證的必要性，以及- 將 AIA 納入癌症數據分析仍處於非常早期的階段；只有 2.1%（96 項研究中的 2 項）透過可解釋性明確探討了 AIA。</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

摘要：<paragraph>解釋性是深度學習中長期的挑戰，特別是在醫療保健等高風險領域。常見的解釋性方法會強調驅動 AI 模型決策的影像區域。然而，人類很大程度依賴語言來傳達不僅是「在哪裡」，還有「是什麼」的解釋。此外，大多數解釋性方法都專注於解釋個別 AI 預測，而不是描述 AI 模型一般使用的特徵。後者對於模型和資料集稽核特別有用，甚至可能在 AI 愈來愈用於新穎任務時產生知識。在此，我們提出一個使用視覺語言模型來辨識視覺分類任務的語言描述符的解釋性策略。透過利用影像和文字之間預先訓練的聯合嵌入空間，我們的做法將新的分類任務估計為一個線性文字組合，導致每個文字都有權重，表示它與基於視覺的分類器對齊。我們使用兩個醫學影像分類任務來評估我們的做法，我們發現產生的描述符在很大程度上與臨床知識一致，儘管缺乏特定領域的語言訓練。然而，我們的做法也發現了所用公開資料集中的「捷徑連線」的可能性。為了達到解釋性的功能性衡量，我們進行了一項試驗讀者研究，發現 AI 識別的文字能讓非專家人類在非平凡的層級執行專業的醫療任務。總之，我們的結果強調了使用多模式基礎模型來提供直觀的、基於語言的視覺任務解釋的潛力。</paragraph>

##### **Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**
2311.02115v2 by Emma A. M. Stanley, Raissa Souza, Anthony Winder, Vedant Gulve, Kimberly Amador, Matthias Wilms, Nils D. Forkert

Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.

摘要：<paragraph>使用醫療影像訓練的人工智慧 (AI) 模型，用於臨床任務時，常會在效能上展現出次群體之間的差異，形成偏見。由於並非所有真實世界醫療影像資料中的偏見來源都容易辨識，因此全面評估這些偏見是如何編碼到模型中，以及偏見緩解方法在改善效能差異方面的能力，是一項挑戰。在本文中，我們介紹了一個新穎的分析架構，用於系統化且客觀地調查醫療影像中的偏見對 AI 模型的影響。我們開發並測試了這個架構，以進行受控的電腦模擬試驗，使用一個工具來評估醫療影像 AI 中的偏見，該工具用於產生具有已知疾病影響和偏見來源的合成磁共振影像。可行性透過使用三個反事實偏見情境來衡量模擬偏見效應對卷積神經網路 (CNN) 分類器和三個偏見緩解策略的影響，並展示出來。分析顯示，當 CNN 在合成資料集上受訓時，模擬偏見會導致預期的次群體效能差異。此外，重新加權被認為是此設定中最成功的偏見緩解策略，我們展示了解釋性 AI 方法如何協助使用這個架構調查模型中偏見的表現。開發公平的 AI 模型是一項重大的挑戰，因為醫療影像資料集中可能存在許多且經常未知的偏見來源。在這項工作中，我們提出了一種新穎的方法，用於客觀地研究偏見和緩解策略對深度學習管線的影響，這可以支援健全且負責任的臨床 AI 的開發。</paragraph>

##### **Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**
2310.19174v1 by Adam White, Margarita Saranti, Artur d'Avila Garcez, Thomas M. H. Hope, Cathy J. Price, Howard Bowman

Machine learning offers great potential for automated prediction of
post-stroke symptoms and their response to rehabilitation. Major challenges for
this endeavour include the very high dimensionality of neuroimaging data, the
relatively small size of the datasets available for learning, and how to
effectively combine neuroimaging and tabular data (e.g. demographic information
and clinical characteristics). This paper evaluates several solutions based on
two strategies. The first is to use 2D images that summarise MRI scans. The
second is to select key features that improve classification accuracy.
Additionally, we introduce the novel approach of training a convolutional
neural network (CNN) on images that combine regions-of-interest extracted from
MRIs, with symbolic representations of tabular data. We evaluate a series of
CNN architectures (both 2D and a 3D) that are trained on different
representations of MRI and tabular data, to predict whether a composite measure
of post-stroke spoken picture description ability is in the aphasic or
non-aphasic range. MRI and tabular data were acquired from 758 English speaking
stroke survivors who participated in the PLORAS study. The classification
accuracy for a baseline logistic regression was 0.678 for lesion size alone,
rising to 0.757 and 0.813 when initial symptom severity and recovery time were
successively added. The highest classification accuracy 0.854 was observed when
8 regions-of-interest was extracted from each MRI scan and combined with lesion
size, initial severity and recovery time in a 2D Residual Neural Network.Our
findings demonstrate how imaging and tabular data can be combined for high
post-stroke classification accuracy, even when the dataset is small in machine
learning terms. We conclude by proposing how the current models could be
improved to achieve even higher levels of accuracy using images from hospital
scanners.

摘要：機器學習為自動預測中風後症狀及其對復健的反應提供了極大的潛力。這項工作的重大挑戰包括神經影像資料的維度非常高、可用於學習的資料集規模相對較小，以及如何有效結合神經影像和表格資料（例如人口統計資訊和臨床特徵）。本文根據兩種策略評估了多種解決方案。第一種是使用總結 MRI 掃描的 2D 影像。第二種是選擇有助於提高分類精確度的關鍵特徵。此外，我們引入了在結合從 MRI 中提取的感興趣區域與表格資料的符號表示的影像上訓練卷積神經網路 (CNN) 的新穎方法。我們評估了一系列 CNN 架構（2D 和 3D），這些架構在 MRI 和表格資料的不同表示上進行訓練，以預測中風後口述圖片描述能力的綜合測量是否在失語症或非失語症範圍內。MRI 和表格資料來自 758 名參與 PLORAS 研究的英語中風倖存者。僅針對病灶大小的基線邏輯迴歸分類準確度為 0.678，當依序加入初始症狀嚴重程度和恢復時間時，上升至 0.757 和 0.813。在從每個 MRI 掃描中提取 8 個感興趣區域並在 2D 殘差神經網路中與病灶大小、初始嚴重程度和恢復時間結合時，觀察到最高的分類準確度 0.854。我們的研究結果展示了如何將影像和表格資料結合起來以獲得高於中風後分類準確度，即使在機器學習術語中資料集很小的情況下也是如此。最後，我們提出如何改進目前的模型，以使用來自醫院掃描儀的影像來實現更高的準確度。

##### **Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**
2310.01828v2 by Hossein Shreim, Abdul Karim Gizzini, Ali J. Ghandour

eXplainable Artificial Intelligence (XAI) has emerged as an essential
requirement when dealing with mission-critical applications, ensuring
transparency and interpretability of the employed black box AI models. The
significance of XAI spans various domains, from healthcare to finance, where
understanding the decision-making process of deep learning algorithms is
essential. Most AI-based computer vision models are often black boxes; hence,
providing explainability of deep neural networks in image processing is crucial
for their wide adoption and deployment in medical image analysis, autonomous
driving, and remote sensing applications. Recently, several XAI methods for
image classification tasks have been introduced. On the contrary, image
segmentation has received comparatively less attention in the context of
explainability, although it is a fundamental task in computer vision
applications, especially in remote sensing. Only some research proposes
gradient-based XAI algorithms for image segmentation. This paper adapts the
recent gradient-free Sobol XAI method for semantic segmentation. To measure the
performance of the Sobol method for segmentation, we propose a quantitative XAI
evaluation method based on a learnable noise model. The main objective of this
model is to induce noise on the explanation maps, where higher induced noise
signifies low accuracy and vice versa. A benchmark analysis is conducted to
evaluate and compare performance of three XAI methods, including Seg-Grad-CAM,
Seg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation
technique. This constitutes the first attempt to run and evaluate XAI methods
using high-resolution satellite images.

摘要：可解釋人工智慧 (XAI) 已成為處理任務關鍵應用程式時的一項基本需求，確保採用黑盒 AI 模型的透明度和可解釋性。XAI 的重要性涵蓋從醫療保健到金融的各種領域，在這些領域中，了解深度學習演算法的決策制定過程至關重要。大多數基於 AI 的電腦視覺模型通常是黑盒子；因此，在影像處理中提供深度神經網路的可解釋性對於其在醫學影像分析、自動駕駛和遙測應用中的廣泛採用和部署至關重要。最近，已針對影像分類任務引入了多種 XAI 方法。相反地，影像分割在可解釋性的背景下受到的關注相對較少，儘管它是電腦視覺應用中的一項基本任務，特別是在遙測中。只有部分研究提出用於影像分割的基於梯度的 XAI 演算法。本文改編了最近的無梯度 Sobol XAI 方法以進行語意分割。為了衡量 Sobol 方法在分割中的效能，我們提出了一種基於可學習雜訊模型的定量 XAI 評估方法。此模型的主要目的是在解釋圖上誘發雜訊，其中較高的誘發雜訊表示較低的準確度，反之亦然。進行基準分析以評估和比較三種 XAI 方法的效能，包括 Seg-Grad-CAM、Seg-Grad-CAM++ 和 Seg-Sobol，並使用所提出的基於雜訊的評估技術。這構成了使用高解析度衛星影像執行和評估 XAI 方法的首次嘗試。

##### **Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**
2311.01463v1 by Muhammad Aurangzeb Ahmad, Ilker Yaramis, Taposh Dutta Roy

Large language models have proliferated across multiple domains in as short
period of time. There is however hesitation in the medical and healthcare
domain towards their adoption because of issues like factuality, coherence, and
hallucinations. Give the high stakes nature of healthcare, many researchers
have even cautioned against its usage until these issues are resolved. The key
to the implementation and deployment of LLMs in healthcare is to make these
models trustworthy, transparent (as much possible) and explainable. In this
paper we describe the key elements in creating reliable, trustworthy, and
unbiased models as a necessary condition for their adoption in healthcare.
Specifically we focus on the quantification, validation, and mitigation of
hallucinations in the context in healthcare. Lastly, we discuss how the future
of LLMs in healthcare may look like.

摘要：大型語言模型在短時間內已在多個領域中大量激增。然而，由於事實性、連貫性和幻覺等問題，醫療和保健領域對其採用猶豫不決。鑑於醫療保健的高風險性質，許多研究人員甚至警告不要使用它，直到這些問題得到解決。在醫療保健中實施和部署 LLM 的關鍵是使這些模型值得信賴、透明（盡可能多）且可解釋。在本文中，我們描述了建立可靠、值得信賴和無偏見模型的關鍵要素，作為它們在醫療保健中得到採用的必要條件。具體來說，我們專注於在醫療保健背景下對幻覺進行量化、驗證和緩解。最後，我們討論了 LLM 在醫療保健中的未來可能是什麼樣子。

##### **When to Trust AI: Advances and Challenges for Certification of Neural Networks**
2309.11196v1 by Marta Kwiatkowska, Xiyue Zhang

Artificial intelligence (AI) has been advancing at a fast pace and it is now
poised for deployment in a wide range of applications, such as autonomous
systems, medical diagnosis and natural language processing. Early adoption of
AI technology for real-world applications has not been without problems,
particularly for neural networks, which may be unstable and susceptible to
adversarial examples. In the longer term, appropriate safety assurance
techniques need to be developed to reduce potential harm due to avoidable
system failures and ensure trustworthiness. Focusing on certification and
explainability, this paper provides an overview of techniques that have been
developed to ensure safety of AI decisions and discusses future challenges.

摘要：人工智慧（AI）已快速進步，現已準備部署於廣泛的應用程式中，例如自主系統、醫療診斷和自然語言處理。及早採用 AI 技術於實際應用程式並非沒有問題，特別是對於神經網路，它可能不穩定且容易受到對抗性範例的影響。從長遠來看，需要開發適當的安全保證技術，以減少因可避免的系統故障而造成的潛在傷害，並確保可信賴性。本文著重於認證和可解釋性，概述了已開發用於確保 AI 決策安全的技術，並討論未來的挑戰。

##### **Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**
2309.10424v1 by Juan M. García-Gómez, Vicent Blanes-Selva, José Carlos de Bartolomé Cenzano, Jaime Cebolla-Cornejo, Ascensión Doñate-Martínez

The Directorate General for Parliamentary Research Services of the European
Parliament has prepared a report to the Members of the European Parliament
where they enumerate seven main risks of Artificial Intelligence (AI) in
medicine and healthcare: patient harm due to AI errors, misuse of medical AI
tools, bias in AI and the perpetuation of existing inequities, lack of
transparency, privacy and security issues, gaps in accountability, and
obstacles in implementation.
  In this study, we propose fourteen functional requirements that AI systems
may implement to reduce the risks associated with their medical purpose: AI
passport, User management, Regulation check, Academic use only disclaimer, data
quality assessment, Clinicians double check, Continuous performance evaluation,
Audit trail, Continuous usability test, Review of retrospective/simulated
cases, Bias check, eXplainable AI, Encryption and use of field-tested
libraries, and Semantic interoperability.
  Our intention here is to provide specific high-level specifications of
technical solutions to ensure continuous good performance and use of AI systems
to benefit patients in compliance with the future EU regulatory framework.

摘要：歐洲議會議會研究服務總局已為歐洲議會議員準備了一份報告，其中列舉了人工智能 (AI) 在醫療保健領域的七項主要風險：AI 錯誤導致患者受到傷害、醫療 AI 工具被濫用、AI 存在偏見並導致現有 inequities 持續存在、缺乏透明度、隱私和安全問題、問責差距以及實施障礙。
  在這項研究中，我們提出了十四項功能性要求，AI 系統可以實施這些要求來降低與其醫療目的相關的風險：AI 護照、使用者管理、法規檢查、僅限學術用途免責聲明、資料品質評估、臨床醫生雙重檢查、持續效能評估、稽核追蹤、持續可用性測試、回顧回溯/模擬案例、偏見檢查、可解釋 AI、加密和使用經過實地測試的程式庫，以及語意互通性。
  我們在此的目的是提供技術解決方案的特定高階規格，以確保持續良好的效能，並使用 AI 系統，以符合未來的歐盟法規架構，從而使患者受益。

##### **QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**
2309.10293v3 by Thanveer Shaik, Xiaohui Tao, Haoran Xie, Lin Li, Juan D. Velasquez, Niall Higgins

Artificial Intelligence techniques can be used to classify a patient's
physical activities and predict vital signs for remote patient monitoring.
Regression analysis based on non-linear models like deep learning models has
limited explainability due to its black-box nature. This can require
decision-makers to make blind leaps of faith based on non-linear model results,
especially in healthcare applications. In non-invasive monitoring, patient data
from tracking sensors and their predisposing clinical attributes act as input
features for predicting future vital signs. Explaining the contributions of
various features to the overall output of the monitoring application is
critical for a clinician's decision-making. In this study, an Explainable AI
for Quantitative analysis (QXAI) framework is proposed with post-hoc model
explainability and intrinsic explainability for regression and classification
tasks in a supervised learning approach. This was achieved by utilizing the
Shapley values concept and incorporating attention mechanisms in deep learning
models. We adopted the artificial neural networks (ANN) and attention-based
Bidirectional LSTM (BiLSTM) models for the prediction of heart rate and
classification of physical activities based on sensor data. The deep learning
models achieved state-of-the-art results in both prediction and classification
tasks. Global explanation and local explanation were conducted on input data to
understand the feature contribution of various patient data. The proposed QXAI
framework was evaluated using PPG-DaLiA data to predict heart rate and mobile
health (MHEALTH) data to classify physical activities based on sensor data.
Monte Carlo approximation was applied to the framework to overcome the time
complexity and high computation power requirements required for Shapley value
calculations.

摘要：人工智慧技術可用於分類病患的身體活動並預測遠距病患監控的重要生命徵象。基於深度學習模型等非線性模型的回歸分析由於其黑盒子的性質而具有有限的可解釋性。這可能需要決策者根據非線性模型結果做出盲目的信仰飛躍，特別是在醫療保健應用中。在非侵入性監控中，來自追蹤感測器和其易感臨床屬性的病患資料充當預測未來生命徵象的輸入特徵。解釋各種特徵對監控應用程式整體輸出的貢獻對於臨床醫生的決策至關重要。在本研究中，提出了一個用於量化分析的可解釋人工智慧 (QXAI) 架構，該架構具有監督式學習方法中回歸和分類任務的事後模型可解釋性和內在可解釋性。這透過利用 Shapley 值概念並將注意力機制納入深度學習模型來實現。我們採用人工神經網路 (ANN) 和基於注意力的雙向 LSTM (BiLSTM) 模型，根據感測器資料預測心率和分類身體活動。深度學習模型在預測和分類任務中都取得了最先進的成果。對輸入資料進行全局解釋和局部解釋，以了解各種病患資料的特徵貢獻。所提出的 QXAI 架構使用 PPG-DaLiA 資料評估，以預測心率，並使用行動健康 (MHEALTH) 資料根據感測器資料對身體活動進行分類。蒙地卡羅近似法應用於該架構，以克服 Shapley 值計算所需的時間複雜度和高運算能力需求。

##### **Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**
2309.09917v1 by Adarsa Sivaprasad, Ehud Reiter, Nava Tintarev, Nir Oren

In explainable artificial intelligence (XAI) research, the predominant focus
has been on interpreting models for experts and practitioners. Model agnostic
and local explanation approaches are deemed interpretable and sufficient in
many applications. However, in domains like healthcare, where end users are
patients without AI or domain expertise, there is an urgent need for model
explanations that are more comprehensible and instil trust in the model's
operations. We hypothesise that generating model explanations that are
narrative, patient-specific and global(holistic of the model) would enable
better understandability and enable decision-making. We test this using a
decision tree model to generate both local and global explanations for patients
identified as having a high risk of coronary heart disease. These explanations
are presented to non-expert users. We find a strong individual preference for a
specific type of explanation. The majority of participants prefer global
explanations, while a smaller group prefers local explanations. A task based
evaluation of mental models of these participants provide valuable feedback to
enhance narrative global explanations. This, in turn, guides the design of
health informatics systems that are both trustworthy and actionable.

摘要：在可解释人工智能 (XAI) 研究中，主要重点在于为专家和从业者解释模型。模型不可知和局部解释方法在许多应用中被认为是可解释且足够的。然而，在医疗保健等领域，最终用户是缺乏人工智能或领域专业知识的患者，因此迫切需要更易于理解且能激发对模型操作的信任的模型解释。我们假设生成叙述性、患者特定且全局（模型整体）的模型解释将能够提高可理解性并支持决策制定。我们使用决策树模型对此进行测试，为被识别为患有冠心病高风险的患者生成局部和全局解释。这些解释会呈现给非专家用户。我们发现用户强烈偏好特定类型的解释。大多数参与者偏好全局解释，而较小的一组参与者偏好局部解释。基于任务的心理模型评估为这些参与者提供了有价值的反馈，以增强叙述性全局解释。这反过来又指导了既值得信赖又可操作的健康信息学系统的设计。

##### **Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**
2308.14321v1 by Yanjun Gao, Ruizhe Li, John Caskey, Dmitriy Dligach, Timothy Miller, Matthew M. Churpek, Majid Afshar

Electronic Health Records (EHRs) and routine documentation practices play a
vital role in patients' daily care, providing a holistic record of health,
diagnoses, and treatment. However, complex and verbose EHR narratives overload
healthcare providers, risking diagnostic inaccuracies. While Large Language
Models (LLMs) have showcased their potential in diverse language tasks, their
application in the healthcare arena needs to ensure the minimization of
diagnostic errors and the prevention of patient harm. In this paper, we outline
an innovative approach for augmenting the proficiency of LLMs in the realm of
automated diagnosis generation, achieved through the incorporation of a medical
knowledge graph (KG) and a novel graph model: Dr.Knows, inspired by the
clinical diagnostic reasoning process. We derive the KG from the National
Library of Medicine's Unified Medical Language System (UMLS), a robust
repository of biomedical knowledge. Our method negates the need for
pre-training and instead leverages the KG as an auxiliary instrument aiding in
the interpretation and summarization of complex medical concepts. Using
real-world hospital datasets, our experimental results demonstrate that the
proposed approach of combining LLMs with KG has the potential to improve the
accuracy of automated diagnosis generation. More importantly, our approach
offers an explainable diagnostic pathway, edging us closer to the realization
of AI-augmented diagnostic decision support systems.

摘要：電子健康紀錄 (EHR) 和例行文件記錄實務在病患的日常照護中扮演著至關重要的角色，提供健康、診斷和治療的整體紀錄。然而，複雜且冗長的 EHR 敘述會讓醫療保健提供者超載，有診斷不準確的風險。大型語言模型 (LLM) 已展現其在各種語言任務上的潛力，但其在醫療保健領域的應用需要確保將診斷錯誤降到最低，並防止病患受到傷害。在本文中，我們概述一種創新的方法，透過整合醫學知識圖譜 (KG) 和一種新穎的圖譜模型：Dr.Knows（靈感來自臨床診斷推理過程），來增強 LLM 在自動化診斷產生領域的能力。我們從美國國家醫學圖書館的統一醫學語言系統 (UMLS) 中衍生出 KG，這是一個強大的生物醫學知識儲存庫。我們的做法否定了預先訓練的需要，而是將 KG 作為輔助工具，協助解釋和總結複雜的醫學概念。使用真實世界的醫院資料集，我們的實驗結果證明，將 LLM 與 KG 結合的建議方法有潛力提高自動化診斷產生的準確性。更重要的是，我們的做法提供了一條可解釋的診斷途徑，讓我們更接近實現 AI 增強的診斷決策支援系統。

##### **Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**
2308.09380v1 by Yun Xin Teoh, Alice Othmani, Siew Li Goh, Juliana Usman, Khin Wee Lai

Existing artificial intelligence (AI) models for diagnosing knee
osteoarthritis (OA) have faced criticism for their lack of transparency and
interpretability, despite achieving medical-expert-like performance. This
opacity makes them challenging to trust in clinical practice. Recently,
explainable artificial intelligence (XAI) has emerged as a specialized
technique that can provide confidence in the model's prediction by revealing
how the prediction is derived, thus promoting the use of AI systems in
healthcare. This paper presents the first survey of XAI techniques used for
knee OA diagnosis. The XAI techniques are discussed from two perspectives: data
interpretability and model interpretability. The aim of this paper is to
provide valuable insights into XAI's potential towards a more reliable knee OA
diagnosis approach and encourage its adoption in clinical practice.

摘要：現有的用於診斷膝骨關節炎 (OA) 的人工智慧 (AI) 模型因其缺乏透明度和可解釋性而受到批評，儘管它們達到了類似醫學專家的表現。這種不透明性使得它們在臨床實務中難以被信任。最近，可解釋人工智慧 (XAI) 已成為一種專門技術，它能透過揭示預測的推導方式來提供對模型預測的信心，從而促進在醫療保健中使用 AI 系統。本文提供了針對膝骨關節炎診斷所使用的 XAI 技術的第一份調查。XAI 技術從兩個角度進行討論：資料可解釋性和模型可解釋性。本文的目的是提供對 XAI 在更可靠的膝骨關節炎診斷方法中的潛力的寶貴見解，並鼓勵在臨床實務中採用它。

##### **Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**
2308.08407v1 by Munib Mesinovic, Peter Watkinson, Tingting Zhu

Recent advancements in AI applications to healthcare have shown incredible
promise in surpassing human performance in diagnosis and disease prognosis.
With the increasing complexity of AI models, however, concerns regarding their
opacity, potential biases, and the need for interpretability. To ensure trust
and reliability in AI systems, especially in clinical risk prediction models,
explainability becomes crucial. Explainability is usually referred to as an AI
system's ability to provide a robust interpretation of its decision-making
logic or the decisions themselves to human stakeholders. In clinical risk
prediction, other aspects of explainability like fairness, bias, trust, and
transparency also represent important concepts beyond just interpretability. In
this review, we address the relationship between these concepts as they are
often used together or interchangeably. This review also discusses recent
progress in developing explainable models for clinical risk prediction,
highlighting the importance of quantitative and clinical evaluation and
validation across multiple common modalities in clinical practice. It
emphasizes the need for external validation and the combination of diverse
interpretability methods to enhance trust and fairness. Adopting rigorous
testing, such as using synthetic datasets with known generative factors, can
further improve the reliability of explainability methods. Open access and
code-sharing resources are essential for transparency and reproducibility,
enabling the growth and trustworthiness of explainable research. While
challenges exist, an end-to-end approach to explainability in clinical risk
prediction, incorporating stakeholders from clinicians to developers, is
essential for success.

摘要：最近在醫療保健中的人工智慧應用進展顯示出令人難以置信的承諾，在診斷和疾病預後方面超越人類表現。然而，隨著人工智能模型的日益複雜，人們對其不透明性、潛在偏差和對可解釋性的需求感到擔憂。為了確保人工智能系統的信任和可靠性，尤其是在臨床風險預測模型中，可解釋性變得至關重要。可解釋性通常被稱為人工智能系統提供其決策邏輯或決策本身對人類利益相關者的強有力解釋的能力。在臨床風險預測中，可解釋性的其他方面，如公平性、偏見、信任和透明度，也代表了超越可解釋性的重要概念。在本次審查中，我們探討了這些概念之間的關係，因為它們經常一起或互換使用。本審查還討論了為臨床風險預測開發可解釋模型的最新進展，強調了在臨床實踐中對多種常見模式進行定量和臨床評估和驗證的重要性。它強調了外部驗證和多樣化可解釋性方法相結合的必要性，以增強信任和公平性。採用嚴格的測試，例如使用具有已知生成因素的合成數據集，可以進一步提高可解釋性方法的可靠性。開放獲取和代碼共享資源對於透明度和可重複性至關重要，從而促進可解釋研究的增長和可信度。儘管存在挑戰，但從臨床醫生到開發人員，採用端到端的可解釋性方法對於臨床風險預測的成功至關重要。

##### **FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**
2309.12325v3 by Karim Lekadir, Aasa Feragen, Abdul Joseph Fofanah, Alejandro F Frangi, Alena Buyx, Anais Emelie, Andrea Lara, Antonio R Porras, An-Wen Chan, Arcadi Navarro, Ben Glocker, Benard O Botwe, Bishesh Khanal, Brigit Beger, Carol C Wu, Celia Cintas, Curtis P Langlotz, Daniel Rueckert, Deogratias Mzurikwao, Dimitrios I Fotiadis, Doszhan Zhussupov, Enzo Ferrante, Erik Meijering, Eva Weicken, Fabio A González, Folkert W Asselbergs, Fred Prior, Gabriel P Krestin, Gary Collins, Geletaw S Tegenaw, Georgios Kaissis, Gianluca Misuraca, Gianna Tsakou, Girish Dwivedi, Haridimos Kondylakis, Harsha Jayakody, Henry C Woodruf, Horst Joachim Mayer, Hugo JWL Aerts, Ian Walsh, Ioanna Chouvarda, Irène Buvat, Isabell Tributsch, Islem Rekik, James Duncan, Jayashree Kalpathy-Cramer, Jihad Zahir, Jinah Park, John Mongan, Judy W Gichoya, Julia A Schnabel, Kaisar Kushibar, Katrine Riklund, Kensaku Mori, Kostas Marias, Lameck M Amugongo, Lauren A Fromont, Lena Maier-Hein, Leonor Cerdá Alberich, Leticia Rittner, Lighton Phiri, Linda Marrakchi-Kacem, Lluís Donoso-Bach, Luis Martí-Bonmatí, M Jorge Cardoso, Maciej Bobowicz, Mahsa Shabani, Manolis Tsiknakis, Maria A Zuluaga, Maria Bielikova, Marie-Christine Fritzsche, Marina Camacho, Marius George Linguraru, Markus Wenzel, Marleen De Bruijne, Martin G Tolsgaard, Marzyeh Ghassemi, Md Ashrafuzzaman, Melanie Goisauf, Mohammad Yaqub, Mónica Cano Abadía, Mukhtar M E Mahmoud, Mustafa Elattar, Nicola Rieke, Nikolaos Papanikolaou, Noussair Lazrak, Oliver Díaz, Olivier Salvado, Oriol Pujol, Ousmane Sall, Pamela Guevara, Peter Gordebeke, Philippe Lambin, Pieta Brown, Purang Abolmaesumi, Qi Dou, Qinghua Lu, Richard Osuala, Rose Nakasi, S Kevin Zhou, Sandy Napel, Sara Colantonio, Shadi Albarqouni, Smriti Joshi, Stacy Carter, Stefan Klein, Steffen E Petersen, Susanna Aussó, Suyash Awate, Tammy Riklin Raviv, Tessa Cook, Tinashe E M Mutsvangwa, Wendy A Rogers, Wiro J Niessen, Xènia Puig-Bosch, Yi Zeng, Yunusa G Mohammed, Yves Saint James Aquino, Zohaib Salahuddin, Martijn P A Starmans

Despite major advances in artificial intelligence (AI) for medicine and
healthcare, the deployment and adoption of AI technologies remain limited in
real-world clinical practice. In recent years, concerns have been raised about
the technical, clinical, ethical and legal risks associated with medical AI. To
increase real world adoption, it is essential that medical AI tools are trusted
and accepted by patients, clinicians, health organisations and authorities.
This work describes the FUTURE-AI guideline as the first international
consensus framework for guiding the development and deployment of trustworthy
AI tools in healthcare. The FUTURE-AI consortium was founded in 2021 and
currently comprises 118 inter-disciplinary experts from 51 countries
representing all continents, including AI scientists, clinicians, ethicists,
and social scientists. Over a two-year period, the consortium defined guiding
principles and best practices for trustworthy AI through an iterative process
comprising an in-depth literature review, a modified Delphi survey, and online
consensus meetings. The FUTURE-AI framework was established based on 6 guiding
principles for trustworthy AI in healthcare, i.e. Fairness, Universality,
Traceability, Usability, Robustness and Explainability. Through consensus, a
set of 28 best practices were defined, addressing technical, clinical, legal
and socio-ethical dimensions. The recommendations cover the entire lifecycle of
medical AI, from design, development and validation to regulation, deployment,
and monitoring. FUTURE-AI is a risk-informed, assumption-free guideline which
provides a structured approach for constructing medical AI tools that will be
trusted, deployed and adopted in real-world practice. Researchers are
encouraged to take the recommendations into account in proof-of-concept stages
to facilitate future translation towards clinical practice of medical AI.

摘要：儘管在醫學和醫療保健方面的人工智慧 (AI) 有重大的進展，但 AI 技術的部署和採用在現實世界的臨床實務中仍然有限。近年來，人們對於與醫療 AI 相關的技術、臨床、倫理和法律風險提出了疑慮。為了增加現實世界的採用率，醫療 AI 工具必須獲得患者、臨床醫生、醫療機構和當局的信任和接受。這項工作將 FUTURE-AI 指南描述為指導醫療保健中可信賴 AI 工具開發和部署的第一個國際共識架構。FUTURE-AI 聯盟成立於 2021 年，目前由來自 51 個國家的 118 位跨領域專家組成，代表所有洲，包括 AI 科學家、臨床醫生、倫理學家和社會科學家。在兩年的時間裡，該聯盟通過一個反覆運算的過程定義了可信賴 AI 的指導原則和最佳實務，包括深入的文獻回顧、修改後的德爾菲調查和線上共識會議。FUTURE-AI 架構是基於醫療保健中可信賴 AI 的 6 項指導原則建立的，即公平性、普遍性、可追溯性、可用性、穩健性和可解釋性。通過共識，定義了一組 28 項最佳實務，涵蓋技術、臨床、法律和社會倫理層面。建議涵蓋了醫療 AI 的整個生命週期，從設計、開發和驗證到法規、部署和監控。FUTURE-AI 是一個基於風險、無假設的指南，提供了一個結構化的方法，用於建構將在現實世界實務中受到信任、部署和採用的醫療 AI 工具。鼓勵研究人員在概念驗證階段考慮這些建議，以促進未來將醫療 AI 轉化為臨床實務。


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-16**|**Identifying Task Groupings for Multi-Task Learning Using Pointwise V-Usable Information**|Yingya Li et.al.|[2410.12774v1](http://arxiv.org/abs/2410.12774v1)|null|
|**2024-10-16**|**FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression**|Zhenheng Tang et.al.|[2410.12707v1](http://arxiv.org/abs/2410.12707v1)|null|
|**2024-10-16**|**Automatic Mapping of Anatomical Landmarks from Free-Text Using Large Language Models: Insights from Llama-2**|Mohamad Abdi et.al.|[2410.12686v1](http://arxiv.org/abs/2410.12686v1)|null|
|**2024-10-16**|**Cascade learning in multi-task encoder-decoder networks for concurrent bone segmentation and glenohumeral joint assessment in shoulder CT scans**|Luca Marsilio et.al.|[2410.12641v1](http://arxiv.org/abs/2410.12641v1)|null|
|**2024-10-16**|**NSSI-Net: Multi-Concept Generative Adversarial Network for Non-Suicidal Self-Injury Detection Using High-Dimensional EEG Signals in a Semi-Supervised Learning Framework**|Zhen Liang et.al.|[2410.12159v1](http://arxiv.org/abs/2410.12159v1)|null|
|**2024-10-15**|**SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding**|Ying Chen et.al.|[2410.11761v1](http://arxiv.org/abs/2410.11761v1)|null|
|**2024-10-15**|**RS-MOCO: A deep learning-based topology-preserving image registration method for cardiac T1 mapping**|Chiyi Huang et.al.|[2410.11651v1](http://arxiv.org/abs/2410.11651v1)|null|
|**2024-10-15**|**Y-Mol: A Multiscale Biomedical Knowledge-Guided Large Language Model for Drug Development**|Tengfei Ma et.al.|[2410.11550v1](http://arxiv.org/abs/2410.11550v1)|null|
|**2024-10-15**|**AGENTiGraph: An Interactive Knowledge Graph Platform for LLM-based Chatbots Utilizing Private Data**|Xinjie Zhao et.al.|[2410.11531v1](http://arxiv.org/abs/2410.11531v1)|null|
|**2024-10-15**|**Explainable AI Methods for Multi-Omics Analysis: A Survey**|Ahmad Hussein et.al.|[2410.11910v1](http://arxiv.org/abs/2410.11910v1)|null|
|**2024-10-15**|**HR-Agent: A Task-Oriented Dialogue (TOD) LLM Agent Tailored for HR Applications**|Weijie Xu et.al.|[2410.11239v1](http://arxiv.org/abs/2410.11239v1)|null|
|**2024-10-15**|**SplitSEE: A Splittable Self-supervised Framework for Single-Channel EEG Representation Learning**|Rikuto Kotoge et.al.|[2410.11200v1](http://arxiv.org/abs/2410.11200v1)|null|
|**2024-10-14**|**EchoApex: A General-Purpose Vision Foundation Model for Echocardiography**|Abdoul Aziz Amadou et.al.|[2410.11092v1](http://arxiv.org/abs/2410.11092v1)|null|
|**2024-10-14**|**Parsing altered brain connectivity in neurodevelopmental disorders by integrating graph-based normative modeling and deep generative networks**|Rui Sherry Shen et.al.|[2410.11064v1](http://arxiv.org/abs/2410.11064v1)|null|
|**2024-10-14**|**Thinking LLMs: General Instruction Following with Thought Generation**|Tianhao Wu et.al.|[2410.10630v1](http://arxiv.org/abs/2410.10630v1)|null|
|**2024-10-14**|**BrainMVP: Multi-modal Vision Pre-training for Brain Image Analysis using Multi-parametric MRI**|Shaohao Rui et.al.|[2410.10604v1](http://arxiv.org/abs/2410.10604v1)|null|
|**2024-10-14**|**Reproducible Machine Learning-based Voice Pathology Detection: Introducing the Pitch Difference Feature**|Jan Vrba et.al.|[2410.10537v1](http://arxiv.org/abs/2410.10537v1)|[link](https://github.com/aailab-uct/automated-robust-and-reproducible-voice-pathology-detection)|
|**2024-10-14**|**Study on the Helpfulness of Explainable Artificial Intelligence**|Tobias Labarta et.al.|[2410.11896v1](http://arxiv.org/abs/2410.11896v1)|null|
|**2024-10-14**|**Advancing Newborn Care: Precise Birth Time Detection Using AI-Driven Thermal Imaging with Adaptive Normalization**|Jorge García-Torres et.al.|[2410.10483v1](http://arxiv.org/abs/2410.10483v1)|[link](https://github.com/jtorres258/image-based-tob)|
|**2024-10-14**|**Affinity-Graph-Guided Contractive Learning for Pretext-Free Medical Image Segmentation with Minimal Annotation**|Zehua Cheng et.al.|[2410.10366v1](http://arxiv.org/abs/2410.10366v1)|null|
|**2024-10-14**|**Unified Representation of Genomic and Biomedical Concepts through Multi-Task, Multi-Source Contrastive Learning**|Hongyi Yuan et.al.|[2410.10144v1](http://arxiv.org/abs/2410.10144v1)|null|
|**2024-10-14**|**REHRSeg: Unleashing the Power of Self-Supervised Super-Resolution for Resource-Efficient 3D MRI Segmentation**|Zhiyun Song et.al.|[2410.10097v1](http://arxiv.org/abs/2410.10097v1)|null|
|**2024-10-13**|**Adaptive Reasoning and Acting in Medical Language Agents**|Abhishek Dutta et.al.|[2410.10020v1](http://arxiv.org/abs/2410.10020v1)|null|
|**2024-10-13**|**Improving 3D Few-Shot Segmentation with Inference-Time Pseudo-Labeling**|Mohammad Mozafari et.al.|[2410.09967v1](http://arxiv.org/abs/2410.09967v1)|null|
|**2024-10-13**|**Retrieval Instead of Fine-tuning: A Retrieval-based Parameter Ensemble for Zero-shot Learning**|Pengfei Jin et.al.|[2410.09908v1](http://arxiv.org/abs/2410.09908v1)|null|
|**2024-10-13**|**Equitable Access to Justice: Logical LLMs Show Promise**|Manuj Kant et.al.|[2410.09904v1](http://arxiv.org/abs/2410.09904v1)|null|
|**2024-10-13**|**Large-Scale 3D Medical Image Pre-training with Geometric Context Priors**|Linshan Wu et.al.|[2410.09890v1](http://arxiv.org/abs/2410.09890v1)|[link](https://github.com/luffy03/large-scale-medical)|
|**2024-10-13**|**HypomimiaCoach: An AU-based Digital Therapy System for Hypomimia Detection & Rehabilitation with Parkinson's Disease**|Yingjing Xu et.al.|[2410.09772v1](http://arxiv.org/abs/2410.09772v1)|null|
|**2024-10-13**|**STA-Unet: Rethink the semantic redundant for Medical Imaging Segmentation**|Vamsi Krishna Vasa et.al.|[2410.11578v1](http://arxiv.org/abs/2410.11578v1)|null|
|**2024-10-13**|**MIRAGE: Multimodal Identification and Recognition of Annotations in Indian General Prescriptions**|Tavish Mankash et.al.|[2410.09729v1](http://arxiv.org/abs/2410.09729v1)|null|
|**2024-10-13**|**3DS: Decomposed Difficulty Data Selection's Case Study on LLM Medical Domain Adaptation**|Hongxin Ding et.al.|[2410.10901v1](http://arxiv.org/abs/2410.10901v1)|null|
|**2024-10-12**|**Multimodal Physical Activity Forecasting in Free-Living Clinical Settings: Hunting Opportunities for Just-in-Time Interventions**|Abdullah Mamun et.al.|[2410.09643v1](http://arxiv.org/abs/2410.09643v1)|[link](https://github.com/ab9mamun/movesense)|
|**2024-10-12**|**Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**|Abdullah Mamun et.al.|[2410.09635v1](http://arxiv.org/abs/2410.09635v1)|[link](https://github.com/ab9mamun/aimen)|
|**2024-10-11**|**AuD-Former: A Hierarchical Transformer Network for Multimodal Audio-Based Disease Prediction**|Jinjin Cai et.al.|[2410.09289v1](http://arxiv.org/abs/2410.09289v1)|null|
|**2024-10-11**|**Developing a Pragmatic Benchmark for Assessing Korean Legal Language Understanding in Large Language Models**|Yeeun Kim et.al.|[2410.08731v1](http://arxiv.org/abs/2410.08731v1)|null|
|**2024-10-11**|**ViT3D Alignment of LLaMA3: 3D Medical Image Report Generation**|Siyou Li et.al.|[2410.08588v1](http://arxiv.org/abs/2410.08588v1)|null|
|**2024-10-11**|**oRetrieval Augmented Generation for 10 Large Language Models and its Generalizability in Assessing Medical Fitness**|Yu He Ke et.al.|[2410.08431v1](http://arxiv.org/abs/2410.08431v1)|null|
|**2024-10-10**|**VoxelPrompt: A Vision-Language Agent for Grounded Medical Image Analysis**|Andrew Hoopes et.al.|[2410.08397v1](http://arxiv.org/abs/2410.08397v1)|null|
|**2024-10-10**|**Optimizing Vital Sign Monitoring in Resource-Constrained Maternal Care: An RL-Based Restless Bandit Approach**|Niclas Boehmer et.al.|[2410.08377v1](http://arxiv.org/abs/2410.08377v1)|null|
|**2024-10-10**|**ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation**|Léo Machado et.al.|[2410.07908v2](http://arxiv.org/abs/2410.07908v2)|null|
|**2024-10-10**|**Exploring ASR-Based Wav2Vec2 for Automated Speech Disorder Assessment: Insights and Analysis**|Tuan Nguyen et.al.|[2410.08250v1](http://arxiv.org/abs/2410.08250v1)|null|
|**2024-10-10**|**Forecasting mortality associated emergency department crowding**|Jalmari Nevanlinna et.al.|[2410.08247v1](http://arxiv.org/abs/2410.08247v1)|null|
|**2024-10-10**|**Flex-MoE: Modeling Arbitrary Modality Combination via the Flexible Mixture-of-Experts**|Sukwon Yun et.al.|[2410.08245v1](http://arxiv.org/abs/2410.08245v1)|[link](https://github.com/unites-lab/flex-moe)|
|**2024-10-10**|**Artificial intelligence techniques in inherited retinal diseases: A review**|Han Trinh et.al.|[2410.09105v1](http://arxiv.org/abs/2410.09105v1)|null|
|**2024-10-10**|**Offline Inverse Constrained Reinforcement Learning for Safe-Critical Decision Making in Healthcare**|Nan Fang et.al.|[2410.07525v2](http://arxiv.org/abs/2410.07525v2)|null|
|**2024-10-09**|**Unlocking Real-Time Fluorescence Lifetime Imaging: Multi-Pixel Parallelism for FPGA-Accelerated Processing**|Ismail Erbas et.al.|[2410.07364v1](http://arxiv.org/abs/2410.07364v1)|null|
|**2024-10-09**|**Taking a turn for the better: Conversation redirection throughout the course of mental-health therapy**|Vivian Nguyen et.al.|[2410.07147v1](http://arxiv.org/abs/2410.07147v1)|null|
|**2024-10-09**|**Mental Disorders Detection in the Era of Large Language Models**|Gleb Kuzmin et.al.|[2410.07129v2](http://arxiv.org/abs/2410.07129v2)|null|
|**2024-10-09**|**MentalArena: Self-play Training of Language Models for Diagnosis and Treatment of Mental Health Disorders**|Cheng Li et.al.|[2410.06845v1](http://arxiv.org/abs/2410.06845v1)|[link](https://github.com/scarelette/mentalarena)|
|**2024-10-09**|**An Improved Approach for Cardiac MRI Segmentation based on 3D UNet Combined with Papillary Muscle Exclusion**|Narjes Benameur et.al.|[2410.06818v1](http://arxiv.org/abs/2410.06818v1)|null|
|**2024-10-09**|**Deep Learning for Surgical Instrument Recognition and Segmentation in Robotic-Assisted Surgeries: A Systematic Review**|Fatimaelzahraa Ali Ahmed et.al.|[2410.07269v1](http://arxiv.org/abs/2410.07269v1)|null|
|**2024-10-08**|**Multimodal Representation Learning using Adaptive Graph Construction**|Weichen Huang et.al.|[2410.06395v1](http://arxiv.org/abs/2410.06395v1)|null|
|**2024-10-08**|**Skin Cancer Machine Learning Model Tone Bias**|James Pope et.al.|[2410.06385v1](http://arxiv.org/abs/2410.06385v1)|null|
|**2024-10-08**|**HumVI: A Multilingual Dataset for Detecting Violent Incidents Impacting Humanitarian Aid**|Hemank Lamba et.al.|[2410.06370v2](http://arxiv.org/abs/2410.06370v2)|[link](https://github.com/dataminr-ai/humvi-dataset)|
|**2024-10-08**|**A Comparative Study of Hybrid Models in Health Misinformation Text Classification**|Mkululi Sikosana et.al.|[2410.06311v1](http://arxiv.org/abs/2410.06311v1)|null|
|**2024-10-08**|**Application of NotebookLM, a Large Language Model with Retrieval-Augmented Generation, for Lung Cancer Staging**|Ryota Tozuka et.al.|[2410.10869v1](http://arxiv.org/abs/2410.10869v1)|null|
|**2024-10-08**|**CodeUnlearn: Amortized Zero-Shot Machine Unlearning in Language Models Using Discrete Concept**|YuXuan Wu et.al.|[2410.10866v1](http://arxiv.org/abs/2410.10866v1)|null|
|**2024-10-08**|**KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server**|Wenhao Wang et.al.|[2410.05725v2](http://arxiv.org/abs/2410.05725v2)|[link](https://github.com/wwh0411/knowledgesg)|
|**2024-10-08**|**Copiloting Diagnosis of Autism in Real Clinical Scenarios via LLMs**|Yi Jiang et.al.|[2410.05684v2](http://arxiv.org/abs/2410.05684v2)|null|
|**2024-10-08**|**NegMerge: Consensual Weight Negation for Strong Machine Unlearning**|Hyoseo Kim et.al.|[2410.05583v1](http://arxiv.org/abs/2410.05583v1)|[link](https://github.com/naver-ai/negmerge)|
|**2024-10-07**|**AI-Driven Early Mental Health Screening with Limited Data: Analyzing Selfies of Pregnant Women**|Gustavo A. Basílio et.al.|[2410.05450v1](http://arxiv.org/abs/2410.05450v1)|null|
|**2024-10-07**|**Improving Predictor Reliability with Selective Recalibration**|Thomas P. Zollo et.al.|[2410.05407v1](http://arxiv.org/abs/2410.05407v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|null|
|**2024-10-07**|**RespLLM: Unifying Audio and Text with Multimodal LLMs for Generalized Respiratory Health Prediction**|Yuwei Zhang et.al.|[2410.05361v1](http://arxiv.org/abs/2410.05361v1)|null|
|**2024-10-07**|**Synthetic Generation of Dermatoscopic Images with GAN and Closed-Form Factorization**|Rohan Reddy Mekala et.al.|[2410.05114v1](http://arxiv.org/abs/2410.05114v1)|null|
|**2024-10-07**|**Named Clinical Entity Recognition Benchmark**|Wadood M Abdul et.al.|[2410.05046v1](http://arxiv.org/abs/2410.05046v1)|[link](https://github.com/wadoodabdul/clinical_ner_benchmark)|
|**2024-10-07**|**Learning Interpretable Hierarchical Dynamical Systems Models from Time Series Data**|Manuel Brenner et.al.|[2410.04814v1](http://arxiv.org/abs/2410.04814v1)|null|
|**2024-10-07**|**$\textbf{Only-IF}$:Revealing the Decisive Effect of Instruction Diversity on Generalization**|Dylan Zhang et.al.|[2410.04717v2](http://arxiv.org/abs/2410.04717v2)|null|
|**2024-10-07**|**Rule-based Data Selection for Large Language Models**|Xiaomin Li et.al.|[2410.04715v1](http://arxiv.org/abs/2410.04715v1)|null|
|**2024-10-07**|**Knowledge Graph Based Agent for Complex, Knowledge-Intensive QA in Medicine**|Xiaorui Su et.al.|[2410.04660v1](http://arxiv.org/abs/2410.04660v1)|null|
|**2024-10-06**|**Comparing Zealous and Restrained AI Recommendations in a Real-World Human-AI Collaboration Task**|Chengyuan Xu et.al.|[2410.11860v1](http://arxiv.org/abs/2410.11860v1)|null|
|**2024-10-06**|**Multi-Tiered Self-Contrastive Learning for Medical Microwave Radiometry (MWR) Breast Cancer Detection**|Christoforos Galazis et.al.|[2410.04636v1](http://arxiv.org/abs/2410.04636v1)|[link](https://github.com/cgalaz01/self_contrastive_mwr)|
|**2024-10-06**|**Semi-Markovian Planning to Coordinate Aerial and Maritime Medical Evacuation Platforms**|Mahdi Al-Husseini et.al.|[2410.04523v1](http://arxiv.org/abs/2410.04523v1)|null|
|**2024-10-06**|**Mitigating Hallucinations Using Ensemble of Knowledge Graph and Vector Store in Large Language Models to Enhance Mental Health Support**|Abdul Muqtadir et.al.|[2410.10853v1](http://arxiv.org/abs/2410.10853v1)|null|
|**2024-10-06**|**On the Reliability of Large Language Models to Misinformed and Demographically-Informed Prompts**|Toluwani Aremu et.al.|[2410.10850v2](http://arxiv.org/abs/2410.10850v2)|null|
|**2024-10-06**|**RespDiff: An End-to-End Multi-scale RNN Diffusion Model for Respiratory Waveform Estimation from PPG Signals**|Yuyang Miao et.al.|[2410.04366v1](http://arxiv.org/abs/2410.04366v1)|null|
|**2024-10-05**|**Applying Quantum Autoencoders for Time Series Anomaly Detection**|Robin Frehner et.al.|[2410.04154v2](http://arxiv.org/abs/2410.04154v2)|null|
|**2024-10-05**|**DAMMI:Daily Activities in a Psychologically Annotated Multi-Modal IoT dataset**|Mohsen Falah Rad et.al.|[2410.04152v1](http://arxiv.org/abs/2410.04152v1)|null|
|**2024-10-05**|**From Hospital to Portables: A Universal ECG Foundation Model Built on 10+ Million Diverse Recordings**|Jun Li et.al.|[2410.04133v1](http://arxiv.org/abs/2410.04133v1)|null|
|**2024-10-05**|**Taming the Tail: Leveraging Asymmetric Loss and Pade Approximation to Overcome Medical Image Long-Tailed Class Imbalance**|Pankhi Kashyap et.al.|[2410.04084v1](http://arxiv.org/abs/2410.04084v1)|null|
|**2024-10-04**|**Leveraging Social Determinants of Health in Alzheimer's Research Using LLM-Augmented Literature Mining and Knowledge Graphs**|Tianqi Shang et.al.|[2410.09080v1](http://arxiv.org/abs/2410.09080v1)|null|
|**2024-10-04**|**Still Not Quite There! Evaluating Large Language Models for Comorbid Mental Health Diagnosis**|Amey Hengle et.al.|[2410.03908v1](http://arxiv.org/abs/2410.03908v1)|null|
|**2024-10-04**|**Not All Diffusion Model Activations Have Been Evaluated as Discriminative Features**|Benyuan Meng et.al.|[2410.03558v2](http://arxiv.org/abs/2410.03558v2)|[link](https://github.com/darkbblue/generic-diffusion-feature)|
|**2024-10-04**|**Towards Real-time Intrahepatic Vessel Identification in Intraoperative Ultrasound-Guided Liver Surgery**|Karl-Philippe Beaudet et.al.|[2410.03420v2](http://arxiv.org/abs/2410.03420v2)|null|
|**2024-10-04**|**Make Interval Bound Propagation great again**|Patryk Krukowski et.al.|[2410.03373v1](http://arxiv.org/abs/2410.03373v1)|[link](https://github.com/gmum/make-interval-bound-propagation-great-again)|
|**2024-10-04**|**An Enhanced Harmonic Densely Connected Hybrid Transformer Network Architecture for Chronic Wound Segmentation Utilising Multi-Colour Space Tensor Merging**|Bill Cassidy et.al.|[2410.03359v1](http://arxiv.org/abs/2410.03359v1)|null|
|**2024-10-04**|**Comparative Analysis and Ensemble Enhancement of Leading CNN Architectures for Breast Cancer Classification**|Gary Murphy et.al.|[2410.03333v1](http://arxiv.org/abs/2410.03333v1)|null|
|**2024-10-04**|**Manikin-Recorded Cardiopulmonary Sounds Dataset Using Digital Stethoscope**|Yasaman Torabi et.al.|[2410.03280v1](http://arxiv.org/abs/2410.03280v1)|[link](https://github.com/torabiy/hls-cmds)|
|**2024-10-04**|**Looking into Concept Explanation Methods for Diabetic Retinopathy Classification**|Andrea M. Storås et.al.|[2410.03188v1](http://arxiv.org/abs/2410.03188v1)|[link](https://github.com/andreastoraas/conceptexplanations_dr_grading)|
|**2024-10-04**|**Remaining Useful Life Prediction: A Study on Multidimensional Industrial Signal Processing and Efficient Transfer Learning Based on Large Language Models**|Yan Chen et.al.|[2410.03134v1](http://arxiv.org/abs/2410.03134v1)|null|
|**2024-10-04**|**Image First or Text First? Optimising the Sequencing of Modalities in Large Language Model Prompting and Reasoning Tasks**|Grant Wardle et.al.|[2410.03062v1](http://arxiv.org/abs/2410.03062v1)|null|
|**2024-10-03**|**Is Your Paper Being Reviewed by an LLM? Investigating AI Text Detectability in Peer Review**|Sungduk Yu et.al.|[2410.03019v1](http://arxiv.org/abs/2410.03019v1)|null|
|**2024-10-03**|**DailyDilemmas: Revealing Value Preferences of LLMs with Quandaries of Daily Life**|Yu Ying Chiu et.al.|[2410.02683v1](http://arxiv.org/abs/2410.02683v1)|null|
|**2024-10-03**|**Plots Unlock Time-Series Understanding in Multimodal Models**|Mayank Daswani et.al.|[2410.02637v1](http://arxiv.org/abs/2410.02637v1)|null|
|**2024-10-03**|**IC3M: In-Car Multimodal Multi-object Monitoring for Abnormal Status of Both Driver and Passengers**|Zihan Fang et.al.|[2410.02592v3](http://arxiv.org/abs/2410.02592v3)|null|
|**2024-10-03**|**Deep Regression 2D-3D Ultrasound Registration for Liver Motion Correction in Focal Tumor Thermal Ablation**|Shuwei Xing et.al.|[2410.02579v1](http://arxiv.org/abs/2410.02579v1)|[link](https://github.com/xingorno/deepregs2v)|
|**2024-10-03**|**ColaCare: Enhancing Electronic Health Record Modeling through Large Language Model-Driven Multi-Agent Collaboration**|Zixiang Wang et.al.|[2410.02551v1](http://arxiv.org/abs/2410.02551v1)|null|
|**2024-10-03**|**SAFLEX: Self-Adaptive Augmentation via Feature Label Extrapolation**|Mucong Ding et.al.|[2410.02512v1](http://arxiv.org/abs/2410.02512v1)|null|
|**2024-10-03**|**Clinnova Federated Learning Proof of Concept: Key Takeaways from a Cross-border Collaboration**|Julia Alekseenko et.al.|[2410.02443v1](http://arxiv.org/abs/2410.02443v1)|null|
|**2024-10-03**|**A Comprehensive Survey of Mamba Architectures for Medical Image Analysis: Classification, Segmentation, Restoration and Beyond**|Shubhi Bansal et.al.|[2410.02362v1](http://arxiv.org/abs/2410.02362v1)|[link](https://github.com/madhavaprasath23/awesome-mamba-papers-on-medical-domain)|

#### Abstracts
##### **Identifying Task Groupings for Multi-Task Learning Using Pointwise V-Usable Information**
2410.12774v1 by Yingya Li, Timothy Miller, Steven Bethard, Guergana Savova

The success of multi-task learning can depend heavily on which tasks are
grouped together. Naively grouping all tasks or a random set of tasks can
result in negative transfer, with the multi-task models performing worse than
single-task models. Though many efforts have been made to identify task
groupings and to measure the relatedness among different tasks, it remains a
challenging research topic to define a metric to identify the best task
grouping out of a pool of many potential task combinations. We propose a metric
of task relatedness based on task difficulty measured by pointwise V-usable
information (PVI). PVI is a recently proposed metric to estimate how much
usable information a dataset contains given a model. We hypothesize that tasks
with not statistically different PVI estimates are similar enough to benefit
from the joint learning process. We conduct comprehensive experiments to
evaluate the feasibility of this metric for task grouping on 15 NLP datasets in
the general, biomedical, and clinical domains. We compare the results of the
joint learners against single learners, existing baseline methods, and recent
large language models, including Llama 2 and GPT-4. The results show that by
grouping tasks with similar PVI estimates, the joint learners yielded
competitive results with fewer total parameters, with consistent performance
across domains.

摘要：多任務學習的成功很大程度上取決於將哪些任務分組在一起。天真地將所有任務或一組隨機任務分組可能會導致負向遷移，多任務模型的表現會比單任務模型差。儘管已做出許多努力來識別任務分組並衡量不同任務之間的關聯性，但定義一個指標以從許多潛在任務組合中識別出最佳任務分組仍然是一個具有挑戰性的研究課題。我們提出了一個基於點式 V 可用資訊 (PVI) 衡量的任務難度來衡量任務相關性的指標。PVI 是一個最近提出的指標，用於估計給定模型資料集包含多少可用資訊。我們假設 PVI 估計在統計上沒有差異的任務足夠相似，可以從聯合學習過程中受益。我們進行了全面的實驗，以評估此指標在 15 個一般、生物醫學和臨床領域的 NLP 資料集上進行任務分組的可行性。我們將聯合學習者的結果與單一學習者、現有的基準方法和最近的大語言模型（包括 Llama 2 和 GPT-4）進行比較。結果表明，通過將具有相似 PVI 估計值的任務分組，聯合學習者以較少的總參數產生了具有競爭力的結果，並且在各個領域中表現一致。

##### **FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression**
2410.12707v1 by Zhenheng Tang, Xueze Kang, Yiming Yin, Xinglin Pan, Yuxin Wang, Xin He, Qiang Wang, Rongfei Zeng, Kaiyong Zhao, Shaohuai Shi, Amelie Chi Zhou, Bo Li, Bingsheng He, Xiaowen Chu

To alleviate hardware scarcity in training large deep neural networks (DNNs),
particularly large language models (LLMs), we present FusionLLM, a
decentralized training system designed and implemented for training DNNs using
geo-distributed GPUs across different computing clusters or individual devices.
Decentralized training faces significant challenges regarding system design and
efficiency, including: 1) the need for remote automatic differentiation (RAD),
2) support for flexible model definitions and heterogeneous software, 3)
heterogeneous hardware leading to low resource utilization or the straggler
problem, and 4) slow network communication. To address these challenges, in the
system design, we represent the model as a directed acyclic graph of operators
(OP-DAG). Each node in the DAG represents the operator in the DNNs, while the
edge represents the data dependency between operators. Based on this design, 1)
users are allowed to customize any DNN without caring low-level operator
implementation; 2) we enable the task scheduling with the more fine-grained
sub-tasks, offering more optimization space; 3) a DAG runtime executor can
implement RAD withour requiring the consistent low-level ML framework versions.
  To enhance system efficiency, we implement a workload estimator and design an
OP-Fence scheduler to cluster devices with similar bandwidths together and
partition the DAG to increase throughput. Additionally, we propose an AdaTopK
compressor to adaptively compress intermediate activations and gradients at the
slowest communication links. To evaluate the convergence and efficiency of our
system and algorithms, we train ResNet-101 and GPT-2 on three real-world
testbeds using 48 GPUs connected with 8 Mbps~10 Gbps networks. Experimental
results demonstrate that our system and method can achieve 1.45 - 9.39x speedup
compared to baseline methods while ensuring convergence.

摘要：<paragraph>為了減輕訓練大型深度神經網路 (DNN) 的硬體短缺問題，尤其是大型語言模型 (LLM)，我們提出了 FusionLLM，一個分散式訓練系統，其設計和實作是用於訓練跨不同運算叢集或個別裝置的地理分散式 GPU 的 DNN。分散式訓練在系統設計和效率方面面臨重大挑戰，包括：1) 需要遠端自動微分 (RAD)，2) 支援彈性的模型定義和異質軟體，3) 異質硬體導致資源利用率低或落後問題，以及 4) 網路通訊速度慢。為了應對這些挑戰，在系統設計中，我們將模型表示為一個有向非循環圖 (OP-DAG) 的運算子。DAG 中的每個節點代表 DNN 中的運算子，而邊緣代表運算子之間的資料依賴性。基於此設計，1) 使用者可以自訂任何 DNN，而不用考慮低階運算子實作；2) 我們啟用任務排程，並使用更細緻的子任務，提供更多最佳化空間；3) DAG 執行時間執行器可以實作 RAD，而不需要一致的低階 ML 架構版本。為了提升系統效率，我們實作一個工作負載估計器，並設計一個 OP-Fence 排程器，將頻寬類似的裝置分組在一起，並分割 DAG 以增加處理量。此外，我們提出一個 AdaTopK 壓縮器，以自適應方式壓縮最慢通訊連結上的中間啟動和梯度。為了評估我們系統和演算法的收斂性和效率，我們在三個真實世界的測試平台上訓練 ResNet-101 和 GPT-2，使用 48 個 GPU 連接到 8 Mbps~10 Gbps 網路。實驗結果表明，我們的系統和方法可以比基準方法快 1.45 - 9.39 倍，同時確保收斂。</paragraph>

##### **Automatic Mapping of Anatomical Landmarks from Free-Text Using Large Language Models: Insights from Llama-2**
2410.12686v1 by Mohamad Abdi, Gerardo Hemosillo Valadez, Halid Ziya Yerebakan

Anatomical landmarks are vital in medical imaging for navigation and anomaly
detection. Modern large language models (LLMs), like Llama-2, offer promise for
automating the mapping of these landmarks in free-text radiology reports to
corresponding positions in image data. Recent studies propose LLMs may develop
coherent representations of generative processes. Motivated by these insights,
we investigated whether LLMs accurately represent the spatial positions of
anatomical landmarks. Through experiments with Llama-2 models, we found that
they can linearly represent anatomical landmarks in space with considerable
robustness to different prompts. These results underscore the potential of LLMs
to enhance the efficiency and accuracy of medical imaging workflows.

摘要：解剖標誌在醫學影像中對於導航和異常偵測至關重要。像 Llama-2 等現代大型語言模型 (LLM) 有望自動化將這些標誌對應到影像資料中相應位置的自由文字放射線學報告的對應。最近的研究提出，LLM 可能會發展出生成式過程的連貫表徵。受到這些見解的啟發，我們調查了 LLM 是否能準確表示解剖標誌的空間位置。透過 Llama-2 模型的實驗，我們發現它們可以用線性方式表示空間中的解剖標誌，並對不同的提示具有相當的穩健性。這些結果強調了 LLM 提高醫學影像工作流程效率和準確性的潛力。

##### **Cascade learning in multi-task encoder-decoder networks for concurrent bone segmentation and glenohumeral joint assessment in shoulder CT scans**
2410.12641v1 by Luca Marsilio, Davide Marzorati, Matteo Rossi, Andrea Moglia, Luca Mainardi, Alfonso Manzotti, Pietro Cerveri

Osteoarthritis is a degenerative condition affecting bones and cartilage,
often leading to osteophyte formation, bone density loss, and joint space
narrowing. Treatment options to restore normal joint function vary depending on
the severity of the condition. This work introduces an innovative deep-learning
framework processing shoulder CT scans. It features the semantic segmentation
of the proximal humerus and scapula, the 3D reconstruction of bone surfaces,
the identification of the glenohumeral (GH) joint region, and the staging of
three common osteoarthritic-related pathologies: osteophyte formation (OS), GH
space reduction (JS), and humeroscapular alignment (HSA). The pipeline
comprises two cascaded CNN architectures: 3D CEL-UNet for segmentation and 3D
Arthro-Net for threefold classification. A retrospective dataset of 571 CT
scans featuring patients with various degrees of GH osteoarthritic-related
pathologies was used to train, validate, and test the pipeline. Root mean
squared error and Hausdorff distance median values for 3D reconstruction were
0.22mm and 1.48mm for the humerus and 0.24mm and 1.48mm for the scapula,
outperforming state-of-the-art architectures and making it potentially suitable
for a PSI-based shoulder arthroplasty preoperative plan context. The
classification accuracy for OS, JS, and HSA consistently reached around 90%
across all three categories. The computational time for the inference pipeline
was less than 15s, showcasing the framework's efficiency and compatibility with
orthopedic radiology practice. The outcomes represent a promising advancement
toward the medical translation of artificial intelligence tools. This progress
aims to streamline the preoperative planning pipeline delivering high-quality
bone surfaces and supporting surgeons in selecting the most suitable surgical
approach according to the unique patient joint conditions.

摘要：骨關節炎是一種退化性疾病，會影響骨骼和軟骨，
通常會導致骨贅形成、骨密度流失和關節間隙變窄。治療選項會根據病情的嚴重程度而有所不同，以恢復正常的關節功能。這項工作介紹了一個創新的深度學習架構，用於處理肩部 CT 掃描。它的特點是近端肱骨和肩胛骨的語義分割、骨表面的 3D 重建、盂肱 (GH) 關節區域的識別，以及三種常見骨關節炎相關病理的分類：骨贅形成 (OS)、GH 間隙縮小 (JS) 和肱骨肩胛骨對齊 (HSA)。該管道包含兩個串聯的 CNN 架構：用於分割的 3D CEL-UNet 和用於三分類的 3D Arthro-Net。一個包含 571 例 CT 掃描的回顧性數據集，其中包括患有不同程度 GH 骨關節炎相關病理的患者，用於訓練、驗證和測試該管道。肱骨的 3D 重建的均方根誤差和 Hausdorff 距離中值為 0.22mm 和 1.48mm，肩胛骨的均方根誤差和 Hausdorff 距離中值為 0.24mm 和 1.48mm，優於最先進的架構，使其潛在地適用於基於 PSI 的肩部關節置換術術前計劃背景。OS、JS 和 HSA 的分類準確率在所有三類中始終達到約 90%。推理管道的計算時間不到 15 秒，展示了該框架的效率和與骨科放射學實踐的相容性。結果代表了人工智慧工具醫學轉化的有希望的進展。這項進展旨在簡化術前計劃管道，提供高品質的骨表面，並支持外科醫生根據患者獨特的關節狀況選擇最合適的手術方法。

##### **NSSI-Net: Multi-Concept Generative Adversarial Network for Non-Suicidal Self-Injury Detection Using High-Dimensional EEG Signals in a Semi-Supervised Learning Framework**
2410.12159v1 by Zhen Liang, Weishan Ye, Qile Liu, Li Zhang, Gan Huang, Yongjie Zhou

Non-suicidal self-injury (NSSI) is a serious threat to the physical and
mental health of adolescents, significantly increasing the risk of suicide and
attracting widespread public concern. Electroencephalography (EEG), as an
objective tool for identifying brain disorders, holds great promise. However,
extracting meaningful and reliable features from high-dimensional EEG data,
especially by integrating spatiotemporal brain dynamics into informative
representations, remains a major challenge. In this study, we introduce an
advanced semi-supervised adversarial network, NSSI-Net, to effectively model
EEG features related to NSSI. NSSI-Net consists of two key modules: a
spatial-temporal feature extraction module and a multi-concept discriminator.
In the spatial-temporal feature extraction module, an integrated 2D
convolutional neural network (2D-CNN) and a bi-directional Gated Recurrent Unit
(BiGRU) are used to capture both spatial and temporal dynamics in EEG data. In
the multi-concept discriminator, signal, gender, domain, and disease levels are
fully explored to extract meaningful EEG features, considering individual,
demographic, disease variations across a diverse population. Based on
self-collected NSSI data (n=114), the model's effectiveness and reliability are
demonstrated, with a 7.44% improvement in performance compared to existing
machine learning and deep learning methods. This study advances the
understanding and early diagnosis of NSSI in adolescents with depression,
enabling timely intervention. The source code is available at
https://github.com/Vesan-yws/NSSINet.

摘要：非自杀性自伤 (NSSI) 对青少年的身心健康构成严重威胁，显著增加了自杀风险，并引起了广泛的公众关注。脑电图 (EEG) 作为一种识别脑部疾病的客观工具，具有广阔的前景。然而，从高维 EEG 数据中提取有意义且可靠的特征，特别是通过将时空脑动态整合到信息表示中，仍然是一项重大挑战。在这项研究中，我们介绍了一个先进的半监督对抗网络 NSSI-Net，以有效建模与 NSSI 相关的 EEG 特征。NSSI-Net 由两个关键模块组成：时空特征提取模块和多概念判别器。在时空特征提取模块中，集成的二维卷积神经网络 (2D-CNN) 和双向门控循环单元 (BiGRU) 用于捕捉 EEG 数据中的空间和时间动态。在多概念判别器中，充分探索信号、性别、域和疾病水平，以提取有意义的 EEG 特征，考虑不同人群中的个体、人口统计学、疾病变异。基于自收集的 NSSI 数据 (n=114)，该模型的有效性和可靠性得到证实，与现有的机器学习和深度学习方法相比，性能提高了 7.44%。这项研究促进了对患有抑郁症的青少年 NSSI 的理解和早期诊断，实现了及时的干预。源代码可在 https://github.com/Vesan-yws/NSSINet 获得。

##### **SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding**
2410.11761v1 by Ying Chen, Guoan Wang, Yuanfeng Ji, Yanjun Li, Jin Ye, Tianbin Li, Bin Zhang, Nana Pei, Rongshan Yu, Yu Qiao, Junjun He

Despite the progress made by multimodal large language models (MLLMs) in
computational pathology, they remain limited by a predominant focus on
patch-level analysis, missing essential contextual information at the
whole-slide level. The lack of large-scale instruction datasets and the
gigapixel scale of whole slide images (WSIs) pose significant developmental
challenges. In this paper, we present SlideChat, the first vision-language
assistant capable of understanding gigapixel whole-slide images, exhibiting
excellent multimodal conversational capability and response complex instruction
across diverse pathology scenarios. To support its development, we created
SlideInstruction, the largest instruction-following dataset for WSIs consisting
of 4.2K WSI captions and 176K VQA pairs with multiple categories. Furthermore,
we propose SlideBench, a multimodal benchmark that incorporates captioning and
VQA tasks to assess SlideChat's capabilities in varied clinical settings such
as microscopy, diagnosis. Compared to both general and specialized MLLMs,
SlideChat exhibits exceptional capabilities achieving state-of-the-art
performance on 18 of 22 tasks. For example, it achieved an overall accuracy of
81.17% on SlideBench-VQA (TCGA), and 54.15% on SlideBench-VQA (BCNB). We will
fully release SlideChat, SlideInstruction and SlideBench as open-source
resources to facilitate research and development in computational pathology.

摘要：儘管多模態大型語言模型 (MLLM) 在計算病理學方面取得了進展，但它們仍然受限於對區塊級分析的關注，錯失了全幻燈片級別的必要脈絡資訊。缺乏大規模的指令資料集和全幻燈片影像 (WSI) 的吉像素規模，構成了重大的開發挑戰。在本文中，我們提出了 SlideChat，這是第一個能夠理解吉像素全幻燈片影像的視覺語言助理，展現出優秀的多模態對話能力和對各種病理情境的複雜指令回應。為了支援其開發，我們建立了 SlideInstruction，這是最大的 WSI 指令遵循資料集，包含 4.2K WSI 標題和 176K 個具有多個類別的 VQA 配對。此外，我們提出了 SlideBench，這是一個多模態基準，結合了標題和 VQA 任務，以評估 SlideChat 在顯微鏡檢查、診斷等不同臨床設定中的能力。與一般和專門的 MLLM 相比，SlideChat 展現了卓越的能力，在 22 個任務中的 18 個任務中達到了最先進的效能。例如，它在 SlideBench-VQA (TCGA) 上達到了 81.17% 的整體準確度，在 SlideBench-VQA (BCNB) 上達到了 54.15%。我們將全面釋出 SlideChat、SlideInstruction 和 SlideBench 作為開放原始碼資源，以促進計算病理學的研究和開發。

##### **RS-MOCO: A deep learning-based topology-preserving image registration method for cardiac T1 mapping**
2410.11651v1 by Chiyi Huang, Longwei Sun, Dong Liang, Haifeng Liang, Hongwu Zeng, Yanjie Zhu

Cardiac T1 mapping can evaluate various clinical symptoms of myocardial
tissue. However, there is currently a lack of effective, robust, and efficient
methods for motion correction in cardiac T1 mapping. In this paper, we propose
a deep learning-based and topology-preserving image registration framework for
motion correction in cardiac T1 mapping. Notably, our proposed implicit
consistency constraint dubbed BLOC, to some extent preserves the image topology
in registration by bidirectional consistency constraint and local anti-folding
constraint. To address the contrast variation issue, we introduce a weighted
image similarity metric for multimodal registration of cardiac T1-weighted
images. Besides, a semi-supervised myocardium segmentation network and a
dual-domain attention module are integrated into the framework to further
improve the performance of the registration. Numerous comparative experiments,
as well as ablation studies, demonstrated the effectiveness and high robustness
of our method. The results also indicate that the proposed weighted image
similarity metric, specifically crafted for our network, contributes a lot to
the enhancement of the motion correction efficacy, while the bidirectional
consistency constraint combined with the local anti-folding constraint ensures
a more desirable topology-preserving registration mapping.

摘要：心肌 T1 對比度成像可評估心肌組織的各種臨床表現。然而，目前在心肌 T1 對比度成像中，缺乏有效、穩健且高效的運動校正方法。在本文中，我們提出一個基於深度學習且保留拓撲的影像配準架構，用於心肌 T1 對比度成像中的運動校正。值得注意的是，我們提出的隱式一致性約束稱為 BLOC，在某種程度上透過雙向一致性約束和局部抗摺疊約束，在配準中保留影像拓撲。為了解決對比度變化問題，我們引入加權影像相似性度量，用於心肌 T1 加權影像的多模式配準。此外，一個半監督心肌分割網路和一個雙域注意力模組被整合到架構中，以進一步提升配準效能。大量的比較實驗和消融研究證明了我們方法的有效性和高穩健性。結果也表明，專門為我們的網路設計的提出的加權影像相似性度量，對運動校正效能的提升有很大貢獻，而雙向一致性約束結合局部抗摺疊約束，可確保更理想的保留拓撲配準對應。

##### **Y-Mol: A Multiscale Biomedical Knowledge-Guided Large Language Model for Drug Development**
2410.11550v1 by Tengfei Ma, Xuan Lin, Tianle Li, Chaoyi Li, Long Chen, Peng Zhou, Xibao Cai, Xinyu Yang, Daojian Zeng, Dongsheng Cao, Xiangxiang Zeng

Large Language Models (LLMs) have recently demonstrated remarkable
performance in general tasks across various fields. However, their
effectiveness within specific domains such as drug development remains
challenges. To solve these challenges, we introduce \textbf{Y-Mol}, forming a
well-established LLM paradigm for the flow of drug development. Y-Mol is a
multiscale biomedical knowledge-guided LLM designed to accomplish tasks across
lead compound discovery, pre-clinic, and clinic prediction. By integrating
millions of multiscale biomedical knowledge and using LLaMA2 as the base LLM,
Y-Mol augments the reasoning capability in the biomedical domain by learning
from a corpus of publications, knowledge graphs, and expert-designed synthetic
data. The capability is further enriched with three types of drug-oriented
instructions: description-based prompts from processed publications,
semantic-based prompts for extracting associations from knowledge graphs, and
template-based prompts for understanding expert knowledge from biomedical
tools. Besides, Y-Mol offers a set of LLM paradigms that can autonomously
execute the downstream tasks across the entire process of drug development,
including virtual screening, drug design, pharmacological properties
prediction, and drug-related interaction prediction. Our extensive evaluations
of various biomedical sources demonstrate that Y-Mol significantly outperforms
general-purpose LLMs in discovering lead compounds, predicting molecular
properties, and identifying drug interaction events.

摘要：大型語言模型 (LLM) 近期在各個領域的通用任務中展示出顯著的表現。然而，它們在特定領域（例如藥物開發）中的效能仍有待加強。為了解決這些挑戰，我們引入了 **Y-Mol**，形成了一個完善的 LLM 典範，用於藥物開發流程。Y-Mol 是一個多尺度的生物醫學知識引導 LLM，旨在完成先導化合物發現、臨床前和臨床預測等任務。透過整合數百萬個多尺度的生物醫學知識，並使用 LLaMA2 作為基礎 LLM，Y-Mol 從出版物、知識圖譜和專家設計的合成資料中學習，增強了生物醫學領域的推理能力。其能力進一步透過三種類型的藥物導向指令得到豐富：已處理出版物的基於描述的提示、用於從知識圖譜中提取關聯的基於語義的提示，以及用於理解生物醫學工具中專家知識的基於範本的提示。此外，Y-Mol 提供了一組 LLM 典範，可以在整個藥物開發過程中自主執行下游任務，包括虛擬篩選、藥物設計、藥理特性預測和藥物相關交互預測。我們對各種生物醫學來源的廣泛評估表明，Y-Mol 在發現先導化合物、預測分子特性和識別藥物交互事件方面顯著優於通用 LLM。

##### **AGENTiGraph: An Interactive Knowledge Graph Platform for LLM-based Chatbots Utilizing Private Data**
2410.11531v1 by Xinjie Zhao, Moritz Blum, Rui Yang, Boming Yang, Luis Márquez Carpintero, Mónica Pina-Navarro, Tony Wang, Xin Li, Huitao Li, Yanran Fu, Rongrong Wang, Juntao Zhang, Irene Li

Large Language Models~(LLMs) have demonstrated capabilities across various
applications but face challenges such as hallucination, limited reasoning
abilities, and factual inconsistencies, especially when tackling complex,
domain-specific tasks like question answering~(QA). While Knowledge
Graphs~(KGs) have been shown to help mitigate these issues, research on the
integration of LLMs with background KGs remains limited. In particular, user
accessibility and the flexibility of the underlying KG have not been thoroughly
explored. We introduce AGENTiGraph (Adaptive Generative ENgine for Task-based
Interaction and Graphical Representation), a platform for knowledge management
through natural language interaction. It integrates knowledge extraction,
integration, and real-time visualization. AGENTiGraph employs a multi-agent
architecture to dynamically interpret user intents, manage tasks, and integrate
new knowledge, ensuring adaptability to evolving user requirements and data
contexts. Our approach demonstrates superior performance in knowledge graph
interactions, particularly for complex domain-specific tasks. Experimental
results on a dataset of 3,500 test cases show AGENTiGraph significantly
outperforms state-of-the-art zero-shot baselines, achieving 95.12\% accuracy in
task classification and 90.45\% success rate in task execution. User studies
corroborate its effectiveness in real-world scenarios. To showcase versatility,
we extended AGENTiGraph to legislation and healthcare domains, constructing
specialized KGs capable of answering complex queries in legal and medical
contexts.

摘要：大型語言模型 (LLM) 已在各種應用中展現其能力，但仍面臨幻覺、推理能力有限和事實不一致等挑戰，尤其是在處理複雜的特定領域任務，例如問答 (QA) 時。雖然知識圖譜 (KG) 已被證明有助於緩解這些問題，但 LLM 與背景 KG 整合的研究仍然有限。特別是，使用者的可及性和底層 KG 的靈活性尚未得到徹底探討。我們引入了 AGENTiGraph（用於任務型互動和圖形表示的自適應生成引擎），一個透過自然語言互動進行知識管理的平台。它整合了知識萃取、整合和即時視覺化。AGENTiGraph 採用多代理架構，以動態解讀使用者的意圖、管理任務並整合新知識，確保適應不斷變化的使用者需求和資料脈絡。我們的做法在知識圖譜互動中展現出優異的效能，特別是對於複雜的特定領域任務。在 3,500 個測試案例的資料集上進行的實驗結果顯示，AGENTiGraph 明顯優於最先進的零次學習基準，在任務分類中達到 95.12% 的準確度，在任務執行中達到 90.45% 的成功率。使用者研究證實了它在真實世界場景中的有效性。為了展示其多功能性，我們將 AGENTiGraph 延伸到法律和醫療保健領域，建構了能夠回答法律和醫療脈絡中複雜查詢的專業知識圖譜。

##### **Explainable AI Methods for Multi-Omics Analysis: A Survey**
2410.11910v1 by Ahmad Hussein, Mukesh Prasad, Ali Braytee

Advancements in high-throughput technologies have led to a shift from
traditional hypothesis-driven methodologies to data-driven approaches.
Multi-omics refers to the integrative analysis of data derived from multiple
'omes', such as genomics, proteomics, transcriptomics, metabolomics, and
microbiomics. This approach enables a comprehensive understanding of biological
systems by capturing different layers of biological information. Deep learning
methods are increasingly utilized to integrate multi-omics data, offering
insights into molecular interactions and enhancing research into complex
diseases. However, these models, with their numerous interconnected layers and
nonlinear relationships, often function as black boxes, lacking transparency in
decision-making processes. To overcome this challenge, explainable artificial
intelligence (xAI) methods are crucial for creating transparent models that
allow clinicians to interpret and work with complex data more effectively. This
review explores how xAI can improve the interpretability of deep learning
models in multi-omics research, highlighting its potential to provide
clinicians with clear insights, thereby facilitating the effective application
of such models in clinical settings.

摘要：高通量技術的進步導致從傳統的假設驅動方法轉變為資料驅動的方法。多組學是指整合分析來自多個「組學」的資料，例如基因組學、蛋白質組學、轉錄組學、代謝組學和微生物組學。此方法透過擷取生物資訊的不同層面，能全面了解生物系統。深度學習方法愈來愈常被用於整合多組學資料，提供分子交互作用的洞察力，並加強對複雜疾病的研究。然而，這些模型具有許多相互連接的層級和非線性關係，通常會像黑盒子一樣運作，缺乏決策過程的透明度。為了克服此挑戰，可解釋人工智慧 (xAI) 方法對於建立透明模型至關重要，讓臨床醫生可以更有效地解釋和處理複雜資料。此評論探討 xAI 如何能改善多組學研究中深度學習模型的可解釋性，強調其提供臨床醫生明確見解的潛力，進而促進此類模型在臨床環境中的有效應用。

##### **HR-Agent: A Task-Oriented Dialogue (TOD) LLM Agent Tailored for HR Applications**
2410.11239v1 by Weijie Xu, Jay Desai, Fanyou Wu, Josef Valvoda, Srinivasan H. Sengamedu

Recent LLM (Large Language Models) advancements benefit many fields such as
education and finance, but HR has hundreds of repetitive processes, such as
access requests, medical claim filing and time-off submissions, which are
unaddressed. We relate these tasks to the LLM agent, which has addressed tasks
such as writing assisting and customer support. We present HR-Agent, an
efficient, confidential, and HR-specific LLM-based task-oriented dialogue
system tailored for automating repetitive HR processes such as medical claims
and access requests. Since conversation data is not sent to an LLM during
inference, it preserves confidentiality required in HR-related tasks.

摘要：近期的 LLM（大型语言模型）进步惠及了许多领域，例如教育和金融，但人力资源有数百个重复性的流程，例如存取要求、医疗索赔申报和休假提交，这些问题尚未解决。我们将这些任务与 LLM 代理联系起来，该代理已解决诸如写作辅助和客户支持之类的任务。我们提出 HR-Agent，这是一个高效、保密且针对人力资源的特定 LLM 为基础的任务导向对话系统，专为自动化重复性人力资源流程（例如医疗索赔和存取请求）而设计。由于对话数据在推理过程中不会发送到 LLM，因此它保留了人力资源相关任务所需的机密性。

##### **SplitSEE: A Splittable Self-supervised Framework for Single-Channel EEG Representation Learning**
2410.11200v1 by Rikuto Kotoge, Zheng Chen, Tasuku Kimura, Yasuko Matsubara, Takufumi Yanagisawa, Haruhiko Kishima, Yasushi Sakurai

While end-to-end multi-channel electroencephalography (EEG) learning
approaches have shown significant promise, their applicability is often
constrained in neurological diagnostics, such as intracranial EEG resources.
When provided with a single-channel EEG, how can we learn representations that
are robust to multi-channels and scalable across varied tasks, such as seizure
prediction? In this paper, we present SplitSEE, a structurally splittable
framework designed for effective temporal-frequency representation learning in
single-channel EEG. The key concept of SplitSEE is a self-supervised framework
incorporating a deep clustering task. Given an EEG, we argue that the time and
frequency domains are two distinct perspectives, and hence, learned
representations should share the same cluster assignment. To this end, we first
propose two domain-specific modules that independently learn domain-specific
representation and address the temporal-frequency tradeoff issue in
conventional spectrogram-based methods. Then, we introduce a novel clustering
loss to measure the information similarity. This encourages representations
from both domains to coherently describe the same input by assigning them a
consistent cluster. SplitSEE leverages a pre-training-to-fine-tuning framework
within a splittable architecture and has following properties: (a)
Effectiveness: it learns representations solely from single-channel EEG but has
even outperformed multi-channel baselines. (b) Robustness: it shows the
capacity to adapt across different channels with low performance variance.
Superior performance is also achieved with our collected clinical dataset. (c)
Scalability: With just one fine-tuning epoch, SplitSEE achieves high and stable
performance using partial model layers.

摘要：<paragraph>雖然端到端多通道腦電圖 (EEG) 學習方法已展現出顯著的希望，但其適用性在神經診斷，例如顱內 EEG 資源中，通常受到限制。當提供單通道 EEG 時，我們如何學習對多通道穩健且可擴展到各種任務（例如癲癇預測）的表徵？在本文中，我們提出 SplitSEE，一個結構可分割的框架，專為在單通道 EEG 中進行有效的時頻表徵學習而設計。SplitSEE 的關鍵概念是一個自監督的框架，結合了一個深度聚類任務。給定一個 EEG，我們認為時間和頻率域是兩個不同的觀點，因此，學習到的表徵應該共享相同的叢集分配。為此，我們首先提出兩個特定於領域的模組，它們獨立學習特定於領域的表徵，並解決傳統基於時譜圖的方法中的時頻權衡問題。然後，我們引入一個新的聚類損失來衡量資訊相似性。這鼓勵來自兩個領域的表徵通過將它們分配到一致的叢集來一致地描述相同的輸入。SplitSEE 在可分割的架構中利用預訓練到微調的框架，並具有以下特性：(a) 有效性：它僅從單通道 EEG 學習表徵，但甚至優於多通道基準。 (b) 穩健性：它顯示出以低效能變異適應不同通道的能力。使用我們收集的臨床資料集也獲得了優異的效能。 (c) 可擴展性：只使用一個微調時期，SplitSEE 使用部分模型層即可達到高且穩定的效能。</paragraph>

##### **EchoApex: A General-Purpose Vision Foundation Model for Echocardiography**
2410.11092v1 by Abdoul Aziz Amadou, Yue Zhang, Sebastien Piat, Paul Klein, Ingo Schmuecking, Tiziano Passerini, Puneet Sharma

Quantitative evaluation of echocardiography is essential for precise
assessment of cardiac condition, monitoring disease progression, and guiding
treatment decisions. The diverse nature of echo images, including variations in
probe types, manufacturers, and pathologies, poses challenges for developing
artificial intelligent models that can generalize across different clinical
practice. We introduce EchoApex, the first general-purpose vision foundation
model echocardiography with applications on a variety of clinical practice.
Leveraging self-supervised learning, EchoApex is pretrained on over 20 million
echo images from 11 clinical centres. By incorporating task-specific decoders
and adapter modules, we demonstrate the effectiveness of EchoApex on 4
different kind of clinical applications with 28 sub-tasks, including view
classification, interactive structure segmentation, left ventricle hypertrophy
detection and automated ejection fraction estimation from view sequences.
Compared to state-of-the-art task-specific models, EchoApex attains improved
performance with a unified image encoding architecture, demonstrating the
benefits of model pretraining at scale with in-domain data. Furthermore,
EchoApex illustrates the potential for developing a general-purpose vision
foundation model tailored specifically for echocardiography, capable of
addressing a diverse range of clinical applications with high efficiency and
efficacy.

摘要：定量評估超音波心動圖對於精確評估心臟狀況、監控疾病進程和指導治療決策至關重要。超音波影像的多樣性，包括探頭類型、製造商和病理的變化，對開發能夠在不同臨床實務中通用的 AI 模型構成挑戰。我們介紹 EchoApex，這是第一個通用視覺基礎模型超音波心動圖，可應用於各種臨床實務。透過利用自我監督學習，EchoApex 在來自 11 個臨床中心的 2000 多萬張超音波影像上進行預先訓練。透過整合特定於任務的解碼器和適配器模組，我們展示了 EchoApex 在 4 種不同類型的臨床應用中擁有 28 個子任務的效能，包括影像分類、互動結構分割、左心室肥大偵測和根據影像序列自動估計射血分數。與最先進的特定於任務的模型相比，EchoApex 透過統一的影像編碼架構獲得更好的效能，證明了在特定領域資料中大規模預先訓練模型的好處。此外，EchoApex 說明了開發專門針對超音波心動圖的通用視覺基礎模型的潛力，能夠以高效率和效能解決各種臨床應用。

##### **Parsing altered brain connectivity in neurodevelopmental disorders by integrating graph-based normative modeling and deep generative networks**
2410.11064v1 by Rui Sherry Shen, Yusuf Osmanlıoğlu, Drew Parker, Darien Aunapu, Benjamin E. Yerys, Birkan Tunç, Ragini Verma

Many neurodevelopmental disorders can be understood as divergent patterns of
neural interactions during brain development. Advances in neuroimaging have
illuminated these patterns by modeling the brain as a network structure using
diffution MRI tractography. However, characterizing and quantifying individual
heterogeneity in neurodevelopmental disorders within these highly complex brain
networks remains a significant challenge. In this paper, we present for the
first time, a framework that integrates deep generative models with graph-based
normative modeling to characterize brain network development in the
neurotypical population, which can then be used to quantify the
individual-level neurodivergence associated with disorders. Our deep generative
model incorporates bio-inspired wiring constraints to effectively capture the
developmental trajectories of neurotypical brain networks. Neurodivergence is
quantified by comparing individuals to this neurotypical trajectory, enabling
the creation of region-wise divergence maps that reveal latent developmental
differences at each brain regions, along with overall neurodivergence scores
based on predicted brain age gaps. We demonstrate the clinical utility of this
framework by applying it to a large sample of children with autism spectrum
disorders, showing that the individualized region-wise maps help parse the
heterogeneity in autism, and the neurodivergence scores correlate with clinical
assessments. Together, we provide powerful tools for quantifying
neurodevelopmental divergence in brain networks, paying the way for developing
imaging markers that will support disorder stratification, monitor progression,
and evaluate therapeutic effectiveness.

摘要：許多神經發育障礙可以理解為大腦發育過程中神經交互作用模式的差異。神經影像學的進步通過使用擴散磁振造影纖維束攝影術將大腦建模為網路結構，闡明了這些模式。然而，在這些高度複雜的大腦網路中，描述和量化神經發育障礙的個體異質性仍然是一個重大的挑戰。在本文中，我們首次提出了一個框架，該框架將深度生成模型與基於圖形的規範模型相結合，以描述神經典型人群中的大腦網路發展，然後可以用於量化與障礙相關的個體神經分歧。我們的深度生成模型結合了受生物啟發的接線約束，以有效捕捉神經典型大腦網路的發展軌跡。神經分歧通過將個體與這種神經典型軌跡進行比較來量化，從而能夠創建區域分歧圖，揭示每個大腦區域的潛在發育差異，以及基於預測腦齡差距的整體神經分歧得分。我們通過將此框架應用於大量自閉症譜系障礙兒童樣本，展示了這種臨床效用，表明個性化的區域分歧圖有助於解析自閉症的異質性，並且神經分歧得分與臨床評估相關。總之，我們提供了強大的工具來量化大腦網路中的神經發育分歧，為開發成像標記鋪平了道路，這些標記將支持障礙分層、監控進展和評估治療效果。

##### **Thinking LLMs: General Instruction Following with Thought Generation**
2410.10630v1 by Tianhao Wu, Janice Lan, Weizhe Yuan, Jiantao Jiao, Jason Weston, Sainbayar Sukhbaatar

LLMs are typically trained to answer user questions or follow instructions
similarly to how human experts respond. However, in the standard alignment
framework they lack the basic ability of explicit thinking before answering.
Thinking is important for complex questions that require reasoning and planning
-- but can be applied to any task. We propose a training method for equipping
existing LLMs with such thinking abilities for general instruction following
without use of additional human data. We achieve this by an iterative search
and optimization procedure that explores the space of possible thought
generations, allowing the model to learn how to think without direct
supervision. For each instruction, the thought candidates are scored using a
judge model to evaluate their responses only, and then optimized via preference
optimization. We show that this procedure leads to superior performance on
AlpacaEval and Arena-Hard, and shows gains from thinking on non-reasoning
categories such as marketing, health and general knowledge, in addition to more
traditional reasoning & problem-solving tasks.

摘要：LLM 通常被训练成回答用户的提问或遵循指令，类似于人类专家如何回应。然而，在标准对齐框架中，它们缺乏在回答之前进行明确思考的基本能力。思考对于需要推理和规划的复杂问题非常重要，但它可以应用于任何任务。我们提出了一种训练方法，为现有的 LLM 提供这种思考能力，以便在没有使用额外人类数据的情况下遵循一般指令。我们通过一种迭代搜索和优化程序来实现这一点，该程序探索可能的思想生成空间，允许模型学习如何在没有直接监督的情况下进行思考。对于每条指令，思想候选者使用评判模型进行评分，仅评估其响应，然后通过偏好优化进行优化。我们表明，此程序在 AlpacaEval 和 Arena-Hard 上表现出卓越的性能，并且除了更传统的推理和解决问题任务之外，还展示了在非推理类别（例如营销、健康和一般知识）上的思考收益。

##### **BrainMVP: Multi-modal Vision Pre-training for Brain Image Analysis using Multi-parametric MRI**
2410.10604v1 by Shaohao Rui, Lingzhi Chen, Zhenyu Tang, Lilong Wang, Mianxin Liu, Shaoting Zhang, Xiaosong Wang

Accurate diagnosis of brain abnormalities is greatly enhanced by the
inclusion of complementary multi-parametric MRI imaging data. There is
significant potential to develop a universal pre-training model that can be
quickly adapted for image modalities and various clinical scenarios. However,
current models often rely on uni-modal image data, neglecting the cross-modal
correlations among different image modalities or struggling to scale up
pre-training in the presence of missing modality data. In this paper, we
propose BrainMVP, a multi-modal vision pre-training framework for brain image
analysis using multi-parametric MRI scans. First, we collect 16,022 brain MRI
scans (over 2.4 million images), encompassing eight MRI modalities sourced from
a diverse range of centers and devices. Then, a novel pre-training paradigm is
proposed for the multi-modal MRI data, addressing the issue of missing
modalities and achieving multi-modal information fusion. Cross-modal
reconstruction is explored to learn distinctive brain image embeddings and
efficient modality fusion capabilities. A modality-wise data distillation
module is proposed to extract the essence representation of each MR image
modality for both the pre-training and downstream application purposes.
Furthermore, we introduce a modality-aware contrastive learning module to
enhance the cross-modality association within a study. Extensive experiments on
downstream tasks demonstrate superior performance compared to state-of-the-art
pre-training methods in the medical domain, with Dice Score improvement of
0.28%-14.47% across six segmentation benchmarks and a consistent accuracy
improvement of 0.65%-18.07% in four individual classification tasks.

摘要：<paragraph>準確診斷腦部異常會透過加入互補的多參數 MRI 影像資料而大幅提升。開發一個通用預訓練模型具有相當大的潛力，而此模型可以快速調整以符合影像形式和各種臨床場景。然而，目前的模型通常仰賴單一形式的影像資料，忽略了不同影像形式之間的跨形式關聯性，或是難以在缺乏形式資料的情況下擴展預訓練。在本文中，我們提出 BrainMVP，一個用於腦部影像分析的多形式視覺預訓練架構，使用多參數 MRI 掃描。首先，我們收集了 16,022 個腦部 MRI 掃描（超過 240 萬張影像），涵蓋了八種 MRI 形式，這些形式來自於各種不同的中心和裝置。接著，針對多形式 MRI 資料提出了一個新穎的預訓練範例，解決了缺乏形式的問題，並達到了多形式資訊融合。探索了跨形式重建，以學習獨特的腦部影像嵌入和有效率的形式融合能力。提出了一個形式明智的資料萃取模組，用於萃取每個 MR 影像形式的本質表徵，以符合預訓練和下游應用目的。此外，我們引入了形式感知對比學習模組，以加強研究中的跨形式關聯性。針對下游任務進行的廣泛實驗證明了與醫療領域中現有最先進的預訓練方法相比，其具有優異的效能，在六個分割基準中骰子分數提升了 0.28%-14.47%，在四個個別分類任務中精確度一致提升了 0.65%-18.07%。</paragraph>

##### **Reproducible Machine Learning-based Voice Pathology Detection: Introducing the Pitch Difference Feature**
2410.10537v1 by Jan Vrba, Jakub Steinbach, Tomáš Jirsa, Laura Verde, Roberta De Fazio, Noriyasu Homma, Yuwen Zeng, Key Ichiji, Lukáš Hájek, Zuzana Sedláková, Jan Mareš

In this study, we propose a robust set of features derived from a thorough
research of contemporary practices in voice pathology detection. The feature
set is based on the combination of acoustic handcrafted features. Additionally,
we introduce pitch difference as a novel feature. We combine this feature set,
containing data from the publicly available Saarbr\"ucken Voice Database (SVD),
with preprocessing using the K-Means Synthetic Minority Over-Sampling Technique
algorithm to address class imbalance.
  Moreover, we applied multiple ML models as binary classifiers. We utilized
support vector machine, k-nearest neighbors, naive Bayes, decision tree, random
forest and AdaBoost classifiers. To determine the best classification approach,
we performed grid search on feasible hyperparameters of respective classifiers
and subsections of features.
  Our approach has achieved the state-of-the-art performance, measured by
unweighted average recall in voice pathology detection on SVD database. We
intentionally omit accuracy as it is highly biased metric in case of unbalanced
data compared to aforementioned metrics. The results are further enhanced by
eliminating the potential overestimation of the results with repeated
stratified cross-validation. This advancement demonstrates significant
potential for the clinical deployment of ML methods, offering a valuable tool
for an objective examination of voice pathologies. To support our claims, we
provide a publicly available GitHub repository with DOI
10.5281/zenodo.13771573. Finally, we provide REFORMS checklist.

摘要：<paragraph>在這項研究中，我們提出了一組穩健的功能，這些功能源自對當代語音病理檢測實務的透徹研究。這組功能基於聲學手工特徵的組合。此外，我們將音高差引入作為一項新穎的功能。我們將這組功能（包含來自公開的薩爾布呂肯語音資料庫 (SVD) 的資料）與使用 K-Means 合成少數過採樣技術演算法進行預處理結合，以解決類別不平衡的問題。
  此外，我們將多個 ML 模型應用為二元分類器。我們利用支援向量機、k-最近鄰、樸素貝氏、決策樹、隨機森林和 AdaBoost 分類器。為了確定最佳分類方法，我們對各個分類器的可行超參數和功能子集執行網格搜尋。
  我們的做法已達成最先進的效能，由 SVD 資料庫中語音病理檢測的未加權平均召回率測量。我們故意省略準確度，因為與上述指標相比，在資料不平衡的情況下，準確度是一個高度偏頗的指標。透過重複分層交叉驗證消除結果的潛在高估，進一步改善了結果。這項進展展示了 ML 方法在臨床部署上的巨大潛力，為客觀檢查語音病理提供了一個有價值的工具。為了支持我們的說法，我們提供了一個公開的 GitHub 儲存庫，其 DOI 為 10.5281/zenodo.13771573。最後，我們提供了 REFORMS 核對清單。</paragraph>

##### **Study on the Helpfulness of Explainable Artificial Intelligence**
2410.11896v1 by Tobias Labarta, Elizaveta Kulicheva, Ronja Froelian, Christian Geißler, Xenia Melman, Julian von Klitzing

Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.

摘要：可解釋人工智慧 (XAI) 對於建構先進的機器學習驅動應用程式至關重要，特別是在醫療診斷或自動駕駛等關鍵領域。法律、商業和倫理要求促使使用有效的 XAI，但數量日益增加的不同方法使得挑選正確的方法具有挑戰性。此外，由於解釋高度依賴於背景，在沒有使用者的情況下衡量 XAI 方法的有效性只能揭示有限的資訊，排除人類因素，例如理解它的能力。我們建議透過使用者成功執行代理任務的能力來評估 XAI 方法，設計使得良好的執行表現是解釋提供有用資訊的指標。換句話說，我們探討 XAI 對人類決策制定的幫助。此外，對最先進的方法進行使用者研究，顯示出它們在產生信任和懷疑的能力以及正確判斷 AI 決策是否正確的能力方面存在差異。根據結果，我們強烈建議使用和擴充這種方法，以進行更多以目標為基礎的人為中心使用者研究，以終端到終端的方式衡量 XAI 效能。

##### **Advancing Newborn Care: Precise Birth Time Detection Using AI-Driven Thermal Imaging with Adaptive Normalization**
2410.10483v1 by Jorge García-Torres, Øyvind Meinich-Bache, Anders Johannessen, Siren Rettedal, Vilde Kolstad, Kjersti Engan

Around 5-10\% of newborns need assistance to start breathing. Currently,
there is a lack of evidence-based research, objective data collection, and
opportunities for learning from real newborn resuscitation emergency events.
Generating and evaluating automated newborn resuscitation algorithm activity
timelines relative to the Time of Birth (ToB) offers a promising opportunity to
enhance newborn care practices. Given the importance of prompt resuscitation
interventions within the "golden minute" after birth, having an accurate ToB
with second precision is essential for effective subsequent analysis of newborn
resuscitation episodes. Instead, ToB is generally registered manually, often
with minute precision, making the process inefficient and susceptible to error
and imprecision. In this work, we explore the fusion of Artificial Intelligence
(AI) and thermal imaging to develop the first AI-driven ToB detector. The use
of temperature information offers a promising alternative to detect the newborn
while respecting the privacy of healthcare providers and mothers. However, the
frequent inconsistencies in thermal measurements, especially in a multi-camera
setup, make normalization strategies critical. Our methodology involves a
three-step process: first, we propose an adaptive normalization method based on
Gaussian mixture models (GMM) to mitigate issues related to temperature
variations; second, we implement and deploy an AI model to detect the presence
of the newborn within the thermal video frames; and third, we evaluate and
post-process the model's predictions to estimate the ToB. A precision of 88.1\%
and a recall of 89.3\% are reported in the detection of the newborn within
thermal frames during performance evaluation. Our approach achieves an absolute
median deviation of 2.7 seconds in estimating the ToB relative to the manual
annotations.

摘要：<paragraph>約 5-10% 的新生兒需要協助才能開始呼吸。目前，缺乏基於證據的研究、客觀的資料蒐集，以及從實際新生兒復甦緊急事件中學習的機會。生成並評估自動新生兒復甦演算法活動時間表，相對於出生時間 (ToB)，提供了一個有希望的機會，可以增強新生兒照護實務。鑑於在出生後的「黃金一分鐘」內進行立即復甦干預的重要性，擁有準確到秒的 ToB 對於有效分析新生兒復甦事件至關重要。然而，ToB 通常是手動記錄的，通常只有分鐘的精確度，這使得這個過程效率低下，容易出錯且不精確。在這項工作中，我們探討人工智慧 (AI) 和熱影像融合，以開發第一個由 AI 驅動的 ToB 偵測器。溫度資訊的使用提供了一個有希望的替代方案，可以在尊重醫療保健提供者和母親隱私的同時偵測新生兒。然而，熱量測量中的頻繁不一致，尤其是在多鏡頭設定中，使得正規化策略至關重要。我們的做法包括一個三步驟流程：首先，我們提出一個基於高斯混合模型 (GMM) 的自適應正規化方法，以減輕與溫度變化相關的問題；其次，我們實作並部署一個 AI 模型，以偵測新生兒在熱影像框中的存在；第三，我們評估並後處理模型的預測，以估計 ToB。在效能評估期間，在熱影像框中偵測新生兒時，準確度為 88.1%，召回率為 89.3%。我們的做法在估計相對於手動註解的 ToB 時，達到 2.7 秒的絕對中位數偏差。</paragraph>

##### **Affinity-Graph-Guided Contractive Learning for Pretext-Free Medical Image Segmentation with Minimal Annotation**
2410.10366v1 by Zehua Cheng, Di Yuan, Thomas Lukasiewicz

The combination of semi-supervised learning (SemiSL) and contrastive learning
(CL) has been successful in medical image segmentation with limited
annotations. However, these works often rely on pretext tasks that lack the
specificity required for pixel-level segmentation, and still face overfitting
issues due to insufficient supervision signals resulting from too few
annotations. Therefore, this paper proposes an affinity-graph-guided
semi-supervised contrastive learning framework (Semi-AGCL) by establishing
additional affinity-graph-based supervision signals between the student and
teacher network, to achieve medical image segmentation with minimal annotations
without pretext. The framework first designs an average-patch-entropy-driven
inter-patch sampling method, which can provide a robust initial feature space
without relying on pretext tasks. Furthermore, the framework designs an
affinity-graph-guided loss function, which can improve the quality of the
learned representation and the model generalization ability by exploiting the
inherent structure of the data, thus mitigating overfitting. Our experiments
indicate that with merely 10% of the complete annotation set, our model
approaches the accuracy of the fully annotated baseline, manifesting a marginal
deviation of only 2.52%. Under the stringent conditions where only 5% of the
annotations are employed, our model exhibits a significant enhancement in
performance surpassing the second best baseline by 23.09% on the dice metric
and achieving an improvement of 26.57% on the notably arduous CRAG and ACDC
datasets.

摘要：半监督学习 (SemiSL) 和对比学习 (CL) 的结合已成功用于医疗图像分割，且标注有限。然而，这些工作通常依赖于缺乏像素级分割所需特异性的借口任务，并且由于标注太少导致监督信号不足，仍然面临过度拟合问题。因此，本文通过在学生网络和教师网络之间建立基于亲和图的附加监督信号，提出了一种亲和图引导的半监督对比学习框架 (Semi-AGCL)，以在没有借口的情况下实现医疗图像分割，且标注最少。该框架首先设计了一种平均补丁熵驱动的补丁间采样方法，该方法可以在不依赖借口任务的情况下提供鲁棒的初始特征空间。此外，该框架设计了一个亲和图引导的损失函数，该函数可以通过利用数据的固有结构来提高学习表示和模型泛化能力，从而减轻过度拟合。我们的实验表明，我们的模型仅使用 10% 的完整标注集，就接近了完全标注基准的准确度，仅有 2.52% 的边际偏差。在仅使用 5% 标注的严格条件下，我们的模型在性能上表现出显着提升，在骰子指标上比第二好的基准高出 23.09%，并在非常艰巨的 CRAG 和 ACDC 数据集上提高了 26.57%。

##### **Unified Representation of Genomic and Biomedical Concepts through Multi-Task, Multi-Source Contrastive Learning**
2410.10144v1 by Hongyi Yuan, Suqi Liu, Kelly Cho, Katherine Liao, Alexandre Pereira, Tianxi Cai

We introduce GENomic Encoding REpresentation with Language Model (GENEREL), a
framework designed to bridge genetic and biomedical knowledge bases. What sets
GENEREL apart is its ability to fine-tune language models to infuse biological
knowledge behind clinical concepts such as diseases and medications. This
fine-tuning enables the model to capture complex biomedical relationships more
effectively, enriching the understanding of how genomic data connects to
clinical outcomes. By constructing a unified embedding space for biomedical
concepts and a wide range of common SNPs from sources such as patient-level
data, biomedical knowledge graphs, and GWAS summaries, GENEREL aligns the
embeddings of SNPs and clinical concepts through multi-task contrastive
learning. This allows the model to adapt to diverse natural language
representations of biomedical concepts while bypassing the limitations of
traditional code mapping systems across different data sources. Our experiments
demonstrate GENEREL's ability to effectively capture the nuanced relationships
between SNPs and clinical concepts. GENEREL also emerges to discern the degree
of relatedness, potentially allowing for a more refined identification of
concepts. This pioneering approach in constructing a unified embedding system
for both SNPs and biomedical concepts enhances the potential for data
integration and discovery in biomedical research.

摘要：<paragraph>我們介紹 GENomic Encoding REpresentation with Language Model (GENEREL)，一個旨在橋接遺傳和生物醫學知識庫的框架。GENEREL 的獨特之處在於它微調語言模型，以灌輸疾病和藥物等臨床概念背後的生物知識。這種微調使模型能夠更有效地捕捉複雜的生物醫學關係，豐富對基因組數據如何連接臨床結果的理解。通過構建一個統一的生物醫學概念嵌入空間和來自患者級別數據、生物醫學知識圖譜和 GWAS 總結等來源的廣泛常見 SNP，GENEREL 通過多任務對比學習對齊 SNP 和臨床概念的嵌入。這允許模型適應生物醫學概念的多元自然語言表示，同時繞過不同數據源中傳統代碼映射系統的限制。我們的實驗證明了 GENEREL 有效捕捉 SNP 和臨床概念之間細微關係的能力。GENEREL 也出現了辨別相關程度，潛在地允許更精確地識別概念。這種構建 SNP 和生物醫學概念統一嵌入系統的先驅方法增強了生物醫學研究中數據整合和發現的潛力。</paragraph>

##### **REHRSeg: Unleashing the Power of Self-Supervised Super-Resolution for Resource-Efficient 3D MRI Segmentation**
2410.10097v1 by Zhiyun Song, Yinjie Zhao, Xiaomin Li, Manman Fei, Xiangyu Zhao, Mengjun Liu, Cunjian Chen, Chung-Hsing Yeh, Qian Wang, Guoyan Zheng, Songtao Ai, Lichi Zhang

High-resolution (HR) 3D magnetic resonance imaging (MRI) can provide detailed
anatomical structural information, enabling precise segmentation of regions of
interest for various medical image analysis tasks. Due to the high demands of
acquisition device, collection of HR images with their annotations is always
impractical in clinical scenarios. Consequently, segmentation results based on
low-resolution (LR) images with large slice thickness are often unsatisfactory
for subsequent tasks. In this paper, we propose a novel Resource-Efficient
High-Resolution Segmentation framework (REHRSeg) to address the above-mentioned
challenges in real-world applications, which can achieve HR segmentation while
only employing the LR images as input. REHRSeg is designed to leverage
self-supervised super-resolution (self-SR) to provide pseudo supervision,
therefore the relatively easier-to-acquire LR annotated images generated by 2D
scanning protocols can be directly used for model training. The main
contribution to ensure the effectiveness in self-SR for enhancing segmentation
is three-fold: (1) We mitigate the data scarcity problem in the medical field
by using pseudo-data for training the segmentation model. (2) We design an
uncertainty-aware super-resolution (UASR) head in self-SR to raise the
awareness of segmentation uncertainty as commonly appeared on the ROI
boundaries. (3) We align the spatial features for self-SR and segmentation
through structural knowledge distillation to enable a better capture of region
correlations. Experimental results demonstrate that REHRSeg achieves
high-quality HR segmentation without intensive supervision, while also
significantly improving the baseline performance for LR segmentation.

摘要：高解析度 (HR) 3D 磁共振造影 (MRI) 可提供詳細的解剖結構資訊，能針對各種醫學影像分析任務精確分割感興趣的區域。由於取得設備要求高，在臨床場景中總是難以收集帶有註解的 HR 影像。因此，基於切片厚度大的低解析度 (LR) 影像的分割結果往往無法令人滿意，無法用於後續任務。在本文中，我們提出了一個新穎的資源有效高解析度分割架構 (REHRSeg)，以解決實際應用中上述挑戰，該架構僅使用 LR 影像作為輸入就能實現 HR 分割。REHRSeg 被設計為利用自監督超解析度 (self-SR) 來提供偽監督，因此可以直接使用 2D 掃描協議產生的相對容易取得的 LR 註解影像來進行模型訓練。確保自監督超解析度 (self-SR) 在增強分割中有效性的主要貢獻有三點：(1) 我們透過使用偽資料來訓練分割模型，以緩解醫療領域中的資料稀少問題。(2) 我們在自監督超解析度 (self-SR) 中設計了一個不確定性感知超解析度 (UASR) 頭，以提高對分割不確定性的感知，這種不確定性通常出現在感興趣區域 (ROI) 邊界上。(3) 我們透過結構知識蒸餾將自監督超解析度 (self-SR) 和分割的空間特徵對齊，以更好地捕捉區域關聯性。實驗結果表明，REHRSeg 在沒有密集監督的情況下實現了高品質的 HR 分割，同時也顯著提高了 LR 分割的基準效能。

##### **Adaptive Reasoning and Acting in Medical Language Agents**
2410.10020v1 by Abhishek Dutta, Yen-Che Hsiao

This paper presents an innovative large language model (LLM) agent framework
for enhancing diagnostic accuracy in simulated clinical environments using the
AgentClinic benchmark. The proposed automatic correction enables doctor agents
to iteratively refine their reasoning and actions following incorrect
diagnoses, fostering improved decision-making over time. Experiments show that
the implementation of the adaptive LLM-based doctor agents achieve correct
diagnoses through dynamic interactions with simulated patients. The evaluations
highlight the capacity of autonomous agents to adapt and improve in complex
medical scenarios. Future enhancements will focus on refining the algorithm and
expanding its applicability across a wider range of tasks and different large
language models.

摘要：本文提出了一個創新的大型語言模型 (LLM) 代理架構，用於使用 AgentClinic 基準提高模擬臨床環境中的診斷準確度。建議的自動校正使醫生代理能夠在不正確的診斷後反覆調整其推理和行動，從而隨著時間的推移促進改善決策。實驗表明，基於自適應 LLM 的醫生代理的實施通過與模擬患者的動態互動實現了正確的診斷。評估強調了自主代理在複雜醫療場景中適應和改進的能力。未來的改進將重點放在調整算法和擴展其在更廣泛的任務和不同的大型語言模型中的適用性上。

##### **Improving 3D Few-Shot Segmentation with Inference-Time Pseudo-Labeling**
2410.09967v1 by Mohammad Mozafari, Hosein Hasani, Reza Vahidimajd, Mohamadreza Fereydooni, Mahdieh Soleymani Baghshah

In recent years, few-shot segmentation (FSS) models have emerged as a
promising approach in medical imaging analysis, offering remarkable
adaptability to segment novel classes with limited annotated data. Existing
approaches to few-shot segmentation have often overlooked the potential of the
query itself, failing to fully utilize the valuable information it contains.
However, treating the query as unlabeled data provides an opportunity to
enhance prediction accuracy. Specifically in the domain of medical imaging, the
volumetric structure of queries offers a considerable source of valuable
information that can be used to improve the target slice segmentation. In this
work, we present a novel strategy to efficiently leverage the intrinsic
information of the query sample for final segmentation during inference. First,
we use the support slices from a reference volume to generate an initial
segmentation score for the query slices through a prototypical approach.
Subsequently, we apply a confidence-aware pseudo-labeling procedure to transfer
the most informative parts of query slices to the support set. The final
prediction is performed based on the new expanded support set, enabling the
prediction of a more accurate segmentation mask for the query volume. Extensive
experiments show that the proposed method can effectively boost performance
across diverse settings and datasets.

摘要：近年來，小樣本分割 (FSS) 模型已成為醫學影像分析中一種前景看好的方法，它為使用有限標註資料分割新類別提供了顯著的適應性。現有的小樣本分割方法通常忽略了查詢本身的潛力，未能充分利用其中包含的寶貴資訊。然而，將查詢視為未標註資料提供了增強預測精確度的機會。特別是在醫學影像領域，查詢的體積結構提供了大量的寶貴資訊來源，可用於改善目標切片分割。在這項研究中，我們提出了一種新策略，在推論期間有效利用查詢樣本的內在資訊進行最終分割。首先，我們使用參考體積中的支援切片，透過原型化方法為查詢切片產生初始分割分數。隨後，我們應用一個具備識別能力的偽標籤程序，將查詢切片中最具資訊性的部分轉移到支援集中。最終預測是根據新的擴充支援集進行的，這使得能夠為查詢體積預測出更準確的分割遮罩。廣泛的實驗表明，所提出的方法可以在不同的設定和資料集上有效提升效能。

##### **Retrieval Instead of Fine-tuning: A Retrieval-based Parameter Ensemble for Zero-shot Learning**
2410.09908v1 by Pengfei Jin, Peng Shu, Sekeun Kim, Qing Xiao, Sifan Song, Cheng Chen, Tianming Liu, Xiang Li, Quanzheng Li

Foundation models have become a cornerstone in deep learning, with techniques
like Low-Rank Adaptation (LoRA) offering efficient fine-tuning of large models.
Similarly, methods such as Retrieval-Augmented Generation (RAG), which leverage
vectorized databases, have further improved model performance by grounding
outputs in external information. While these approaches have demonstrated
notable success, they often require extensive training or labeled data, which
can limit their adaptability in resource-constrained environments. To address
these challenges, we introduce Retrieval-based Parameter Ensemble (RPE), a new
method that creates a vectorized database of LoRAs, enabling efficient
retrieval and application of model adaptations to new tasks. RPE minimizes the
need for extensive training and eliminates the requirement for labeled data,
making it particularly effective for zero-shot learning. Additionally, RPE is
well-suited for privacy-sensitive domains like healthcare, as it modifies model
parameters without accessing raw data. When applied to tasks such as medical
report generation and image segmentation, RPE not only proved effective but
also surpassed supervised fine-tuning methods in certain cases, highlighting
its potential to enhance both computational efficiency and privacy in deep
learning applications.

摘要：基礎模型已成為深度學習的基石，其中低秩適應 (LoRA) 等技術提供大型模型的有效微調。
類似地，利用向量化資料庫的檢索擴充生成 (RAG) 等方法，透過在外部資訊中建立輸出，進一步改善模型效能。雖然這些方法已展現顯著的成功，但它們通常需要大量的訓練或標記資料，這可能會限制它們在資源受限環境中的適應性。為了應對這些挑戰，我們引進基於檢索的參數集合 (RPE)，一種建立 LoRA 向量化資料庫的新方法，能有效地檢索和將模型改編應用於新任務。RPE 將大量訓練的需求降至最低，並消除了對標記資料的需求，使其在零次學習中特別有效。此外，RPE 非常適合醫療保健等注重隱私的領域，因為它修改模型參數而不會存取原始資料。當應用於醫療報告生成和影像分割等任務時，RPE 不僅被證明有效，在某些情況下還超越了有監督的微調方法，突顯出它在深度學習應用中提升運算效率和隱私的潛力。

##### **Equitable Access to Justice: Logical LLMs Show Promise**
2410.09904v1 by Manuj Kant, Manav Kant, Marzieh Nabi, Preston Carlson, Megan Ma

The costs and complexity of the American judicial system limit access to
legal solutions for many Americans. Large language models (LLMs) hold great
potential to improve access to justice. However, a major challenge in applying
AI and LLMs in legal contexts, where consistency and reliability are crucial,
is the need for System 2 reasoning. In this paper, we explore the integration
of LLMs with logic programming to enhance their ability to reason, bringing
their strategic capabilities closer to that of a skilled lawyer. Our objective
is to translate laws and contracts into logic programs that can be applied to
specific legal cases, with a focus on insurance contracts. We demonstrate that
while GPT-4o fails to encode a simple health insurance contract into logical
code, the recently released OpenAI o1-preview model succeeds, exemplifying how
LLMs with advanced System 2 reasoning capabilities can expand access to
justice.

摘要：美國司法體系的成本和複雜性限制了許多美國人獲得法律解決方案的機會。大型語言模型 (LLM) 具有改善司法管道取得管道取得管道管道管道取得管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道取得管道管道管道管道管道管道管道管道管道取得管道管道管道管道管道取得管道管道管道

##### **Large-Scale 3D Medical Image Pre-training with Geometric Context Priors**
2410.09890v1 by Linshan Wu, Jiaxin Zhuang, Hao Chen

The scarcity of annotations poses a significant challenge in medical image
analysis. Large-scale pre-training has emerged as a promising label-efficient
solution, owing to the utilization of large-scale data, large models, and
advanced pre-training techniques. However, its development in medical images
remains underexplored. The primary challenge lies in harnessing large-scale
unlabeled data and learning high-level semantics without annotations. We
observe that 3D medical images exhibit consistent geometric context, i.e.,
consistent geometric relations between different organs, which leads to a
promising way for learning consistent representations. Motivated by this, we
introduce a simple-yet-effective Volume Contrast (VoCo) framework to leverage
geometric context priors for self-supervision. Given an input volume, we
extract base crops from different regions to construct positive and negative
pairs for contrastive learning. Then we predict the contextual position of a
random crop by contrasting its similarity to the base crops. In this way, VoCo
encodes the inherent geometric context into model representations, facilitating
high-level semantic learning without annotations. Specifically, we (1)
introduce the largest medical pre-training dataset PreCT-160K; (2) investigate
scaling laws and propose guidelines for tailoring different model sizes to
various medical tasks; (3) build a benchmark encompassing 48 medical tasks.
Extensive experiments highlight the superiority of VoCo. Codes at
https://github.com/Luffy03/Large-Scale-Medical.

摘要：<paragraph>標註的稀缺性對醫學影像分析構成重大挑戰。由於利用大規模數據、大型模型和先進的預訓練技術，大規模預訓練已成為一種有前途的標籤效率解決方案。然而，其在醫學影像中的發展仍未得到充分探索。主要的挑戰在於利用大規模未標註數據並在沒有標註的情況下學習高級語義。我們觀察到 3D 醫學影像表現出一致的幾何背景，即不同器官之間的一致幾何關係，這為學習一致的表示提供了一種有前途的方法。受此啟發，我們引入了一個簡單而有效的體積對比 (VoCo) 框架，以利用幾何背景先驗進行自我監督。給定一個輸入體積，我們從不同的區域提取基礎裁剪，以構造對比學習的正負對。然後，我們通過對比其與基礎裁剪的相似性來預測隨機裁剪的上下文位置。通過這種方式，VoCo 將固有的幾何背景編碼到模型表示中，從而促進了在沒有標註的情況下進行高級語義學習。具體來說，我們 (1) 引入了最大的醫學預訓練數據集 PreCT-160K；(2) 調查縮放定律並提出指導方針，以根據不同的醫療任務調整不同的模型大小；(3) 構建了一個涵蓋 48 個醫療任務的基準。大量的實驗突出了 VoCo 的優越性。代碼見 https://github.com/Luffy03/Large-Scale-Medical。</paragraph>

##### **HypomimiaCoach: An AU-based Digital Therapy System for Hypomimia Detection & Rehabilitation with Parkinson's Disease**
2410.09772v1 by Yingjing Xu, Xueyan Cai, Zihong Zhou, Mengru Xue, Bo Wang, Haotian Wang, Zhengke Li, Chentian Weng, Wei Luo, Cheng Yao, Bo Lin, Jianwei Yin

Hypomimia is a non-motor symptom of Parkinson's disease that manifests as
delayed facial movements and expressions, along with challenges in articulation
and emotion. Currently, subjective evaluation by neurologists is the primary
method for hypomimia detection, and conventional rehabilitation approaches
heavily rely on verbal prompts from rehabilitation physicians. There remains a
deficiency in accessible, user-friendly and scientifically rigorous assistive
tools for hypomimia treatments. To investigate this, we developed
HypomimaCoach, an Action Unit (AU)-based digital therapy system for hypomimia
detection and rehabilitation in Parkinson's disease. The HypomimaCoach system
was designed to facilitate engagement through the incorporation of both relaxed
and controlled rehabilitation exercises, while also stimulating initiative
through the integration of digital therapies that incorporated traditional face
training methods. We extract action unit(AU) features and their relationship
for hypomimia detection. In order to facilitate rehabilitation, a series of
training programmes have been devised based on the Action Units (AUs) and
patients are provided with real-time feedback through an additional AU
recognition model, which guides them through their training routines. A pilot
study was conducted with seven participants in China, all of whom exhibited
symptoms of Parkinson's disease hypomimia. The results of the pilot study
demonstrated a positive impact on participants' self-efficacy, with favourable
feedback received. Furthermore, physician evaluations validated the system's
applicability in a therapeutic setting for patients with Parkinson's disease,
as well as its potential value in clinical applications.

摘要：<paragraph>顏面表情減少症是帕金森氏症的一種非運動症狀，表現為面部動作和表情遲緩，以及言語表達和情緒表達困難。目前，神經科醫師的主觀評估是顏面表情減少症檢測的主要方法，傳統的復健方法高度依賴復健醫師的言語提示。顏面表情減少症治療中仍然缺乏可取得、使用者友善且科學嚴謹的輔助工具。為了解決這個問題，我們開發了 HypomimaCoach，一種基於動作單元 (AU) 的數位治療系統，用於帕金森氏症的顏面表情減少症檢測和復健。HypomimaCoach 系統旨在透過整合放鬆和控制的復健運動來促進參與，同時透過整合傳統面部訓練方法的數位治療來激勵主動性。我們萃取動作單元 (AU) 特徵及其與顏面表情減少症檢測的關係。為了促進復健，我們根據動作單元 (AU) 設計了一系列訓練計畫，並透過一個額外的 AU 辨識模型提供患者即時回饋，引導他們進行訓練。我們在中國對七位參與者進行了試驗研究，所有參與者均表現出帕金森氏症顏面表情減少症的症狀。試驗研究的結果顯示對參與者的自我效能產生了正面的影響，並獲得了正面的回饋。此外，醫師評估驗證了該系統在帕金森氏症患者治療環境中的適用性，以及其在臨床應用中的潛在價值。</paragraph>

##### **STA-Unet: Rethink the semantic redundant for Medical Imaging Segmentation**
2410.11578v1 by Vamsi Krishna Vasa, Wenhui Zhu, Xiwen Chen, Peijie Qiu, Xuanzhao Dong, Yalin Wang

In recent years, significant progress has been made in the medical image
analysis domain using convolutional neural networks (CNNs). In particular, deep
neural networks based on a U-shaped architecture (UNet) with skip connections
have been adopted for several medical imaging tasks, including organ
segmentation. Despite their great success, CNNs are not good at learning global
or semantic features. Especially ones that require human-like reasoning to
understand the context. Many UNet architectures attempted to adjust with the
introduction of Transformer-based self-attention mechanisms, and notable gains
in performance have been noted. However, the transformers are inherently flawed
with redundancy to learn at shallow layers, which often leads to an increase in
the computation of attention from the nearby pixels offering limited
information. The recently introduced Super Token Attention (STA) mechanism
adapts the concept of superpixels from pixel space to token space, using super
tokens as compact visual representations. This approach tackles the redundancy
by learning efficient global representations in vision transformers, especially
for the shallow layers. In this work, we introduce the STA module in the UNet
architecture (STA-UNet), to limit redundancy without losing rich information.
Experimental results on four publicly available datasets demonstrate the
superiority of STA-UNet over existing state-of-the-art architectures in terms
of Dice score and IOU for organ segmentation tasks. The code is available at
\url{https://github.com/Retinal-Research/STA-UNet}.

摘要：<paragraph>近年來，使用卷積神經網路 (CNN) 在醫學影像分析領域中取得顯著進展。特別是，基於 U 形架構 (UNet) 的深度神經網路，具有跳躍連接，已被採用於多項醫學影像任務，包括器官分割。儘管 CNN 獲得巨大的成功，但它們並不擅長學習全局或語義特徵。尤其是那些需要類似人類的推理才能理解脈絡的特徵。許多 UNet 架構嘗試透過導入基於 Transformer 的自我注意機制進行調整，並已注意到效能的顯著提升。然而，Transformer 在本質上存在學習淺層的冗餘缺陷，這通常會導致計算來自附近像素的注意，而這些像素提供的資訊有限。最近推出的超標記注意 (STA) 機制將超像素的概念從像素空間調整到標記空間，使用超標記作為緊湊的視覺表示。這種方法透過學習視覺 Transformer 中有效率的全局表示，特別是對於淺層，來解決冗餘問題。在這項工作中，我們在 UNet 架構 (STA-UNet) 中導入 STA 模組，以限制冗餘，同時不遺失豐富的資訊。在四個公開可用的資料集上的實驗結果證明了 STA-UNet 在器官分割任務的 Dice 分數和 IOU 方面優於現有的最先進架構。程式碼可在 \url{https://github.com/Retinal-Research/STA-UNet} 取得。</paragraph>

##### **MIRAGE: Multimodal Identification and Recognition of Annotations in Indian General Prescriptions**
2410.09729v1 by Tavish Mankash, V. S. Chaithanya Kota, Anish De, Praveen Prakash, Kshitij Jadhav

Hospitals generate thousands of handwritten prescriptions, a practice that
remains prevalent despite the availability of Electronic Medical Records (EMR).
This method of record-keeping hinders the examination of long-term medication
effects, impedes statistical analysis, and makes the retrieval of records
challenging. Handwritten prescriptions pose a unique challenge, requiring
specialized data for training models to recognize medications and their
patterns of recommendation. While current handwriting recognition approaches
typically employ 2-D LSTMs, recent studies have explored the use of Large
Language Models (LLMs) for Optical Character Recognition (OCR). Building on
this approach, we focus on extracting medication names from medical records.
Our methodology MIRAGE (Multimodal Identification and Recognition of
Annotations in indian GEneral prescriptions) involves fine-tuning the LLaVA 1.6
and Idefics2 models. Our research utilizes a dataset provided by Medyug
Technology, consisting of 743,118 fully annotated high-resolution simulated
medical records from 1,133 doctors across India. We demonstrate that our
methodology exhibits 82% accuracy in medication name and dosage extraction. We
provide a detailed account of our research methodology and results, notes about
HWR with Multimodal LLMs, and release a small dataset of 100 medical records
with labels.

摘要：醫院會產生數千份手寫處方，儘管有電子病歷 (EMR) 可用，但這種做法仍然很普遍。這種記錄保存方式會阻礙長期藥物效果的檢查，妨礙統計分析，並讓記錄的檢索變得困難。手寫處方構成了一項獨特的挑戰，需要專業的資料來訓練模型以辨識藥物及其推薦模式。雖然目前的辨識手寫字方法通常採用 2-D LSTM，但最近的研究已探討使用大型語言模型 (LLM) 進行光學字元辨識 (OCR)。根據此方法，我們專注於從病歷中擷取藥物名稱。我們的 MIRAGE 方法（印度一般處方中的多模式註解辨識與辨識）涉及微調 LLaVA 1.6 和 Idefics2 模型。我們的研究使用 Medyug Technology 提供的資料集，其中包含來自印度 1,133 位醫生的 743,118 份經過完整註解的高解析度模擬病歷。我們證明我們的技術在藥物名稱和劑量擷取方面展現出 82% 的準確度。我們詳細說明了我們的研究方法和結果，以及有關使用多模式 LLM 的 HWR 的注意事項，並發布了一小部分包含標籤的 100 份病歷資料集。

##### **3DS: Decomposed Difficulty Data Selection's Case Study on LLM Medical Domain Adaptation**
2410.10901v1 by Hongxin Ding, Yue Fang, Runchuan Zhu, Xinke Jiang, Jinyang Zhang, Yongxin Xu, Xu Chu, Junfeng Zhao, Yasha Wang

Large Language Models(LLMs) excel in general tasks but struggle in
specialized domains like healthcare due to limited domain-specific
knowledge.Supervised Fine-Tuning(SFT) data construction for domain adaptation
often relies on heuristic methods, such as GPT-4 annotation or manual data
selection, with a data-centric focus on presumed diverse, high-quality
datasets. However, these methods overlook the model's inherent knowledge
distribution, introducing noise, redundancy, and irrelevant data, leading to a
mismatch between the selected data and the model's learning task, resulting in
suboptimal performance. To address this, we propose a two-stage model-centric
data selection framework, Decomposed Difficulty Data Selection (3DS), which
aligns data with the model's knowledge distribution for optimized adaptation.
In Stage1, we apply Prompt-Driven Data Selection via Explicit Alignment, where
the the model filters irrelevant or redundant data based on its internal
knowledge. In Stage2, we perform Decomposed Difficulty Data Selection, where
data selection is guided by our defined difficulty decomposition, using three
metrics: Instruction Understanding, Response Confidence, and Response
Correctness. Additionally, an attention-based importance weighting mechanism
captures token importance for more accurate difficulty calibration. This
two-stage approach ensures the selected data is not only aligned with the
model's knowledge and preferences but also appropriately challenging for the
model to learn, leading to more effective and targeted domain adaptation. In
the case study of the medical domain, our extensive experiments on real-world
healthcare datasets demonstrate the superiority of 3DS over exisiting methods
in accuracy by over 5.29%. Our dataset and code will be open-sourced at
https://anonymous.4open.science/r/3DS-E67F.

摘要：大型语言模型 (LLM) 在一般任务中表现出色，但在医疗保健等专业领域中却表现不佳，因为缺乏特定领域的知识。领域适应的监督微调 (SFT) 数据构建通常依赖启发式方法，例如 GPT-4 注释或手动数据选择，其数据中心化重点在于假定的多样化、高质量数据集。然而，这些方法忽略了模型固有的知识分布，引入了噪音、冗余和无关数据，导致所选数据与模型的学习任务不匹配，从而导致性能不佳。为了解决这个问题，我们提出了一种两阶段以模型为中心的数据选择框架，即分解难度数据选择 (3DS)，它使数据与模型的知识分布保持一致，以进行优化适应。在第 1 阶段，我们通过显式对齐应用提示驱动的基于数据的选择，其中模型根据其内部知识过滤无关或冗余的数据。在第 2 阶段，我们执行分解难度数据选择，其中数据选择由我们定义的难度分解指导，使用三个指标：指令理解、响应置信度和响应正确性。此外，基于注意力的重要性加权机制捕获标记重要性，以便更准确地校准难度。这种两阶段方法确保所选数据不仅与模型的知识和偏好保持一致，而且对模型学习而言也具有适当的挑战性，从而实现更有效和更有针对性的领域适应。在医学领域的案例研究中，我们在真实世界医疗保健数据集上进行的广泛实验表明，3DS 在准确性方面比现有方法高出 5.29%。我们的数据集和代码将在 https://anonymous.4open.science/r/3DS-E67F 开源。

##### **Multimodal Physical Activity Forecasting in Free-Living Clinical Settings: Hunting Opportunities for Just-in-Time Interventions**
2410.09643v1 by Abdullah Mamun, Krista S. Leonard, Megan E. Petrov, Matthew P. Buman, Hassan Ghasemzadeh

Objective: This research aims to develop a lifestyle intervention system,
called MoveSense, that forecasts a patient's activity behavior to allow for
early and personalized interventions in real-world clinical environments.
Methods: We conducted two clinical studies involving 58 prediabetic veterans
and 60 patients with obstructive sleep apnea to gather multimodal behavioral
data using wearable devices. We develop multimodal long short-term memory
(LSTM) network models, which are capable of forecasting the number of step
counts of a patient up to 24 hours in advance by examining data from activity
and engagement modalities. Furthermore, we design goal-based forecasting models
to predict whether a person's next-day steps will be over a certain threshold.
Results: Multimodal LSTM with early fusion achieves 33% and 37% lower mean
absolute errors than linear regression and ARIMA respectively on the
prediabetes dataset. LSTM also outperforms linear regression and ARIMA with a
margin of 13% and 32% on the sleep dataset. Multimodal forecasting models also
perform with 72% and 79% accuracy on the prediabetes dataset and sleep dataset
respectively on goal-based forecasting. Conclusion: Our experiments conclude
that multimodal LSTM models with early fusion are better than multimodal LSTM
with late fusion and unimodal LSTM models and also than ARIMA and linear
regression models. Significance: We address an important and challenging task
of time-series forecasting in uncontrolled environments. Effective forecasting
of a person's physical activity can aid in designing adaptive behavioral
interventions to keep the user engaged and adherent to a prescribed routine.

摘要：目標：本研究旨在開發一種生活型態介入系統，稱為 MoveSense，可預測病患的活動行為，以便在現實世界的臨床環境中進行早期且個人化的介入。
方法：我們進行了兩項臨床研究，涉及 58 位糖尿病前期退伍軍人和 60 位阻塞性睡眠呼吸中止症患者，以使用穿戴式裝置收集多模式行為數據。我們開發了多模式長短期記憶 (LSTM) 網路模型，它能夠透過檢查活動和參與模式的數據，預測病患在 24 小時內踏出的步數。此外，我們設計了基於目標的預測模型，以預測某人的隔日步數是否會超過某個閾值。
結果：多模式 LSTM 與早期融合在糖尿病前期數據集上實現的平均絕對誤差比線性回歸和 ARIMA 分別低 33% 和 37%。LSTM 在睡眠數據集上也以 13% 和 32% 的幅度優於線性回歸和 ARIMA。多模式預測模型在糖尿病前期數據集和睡眠數據集上也分別以 72% 和 79% 的準確度執行基於目標的預測。結論：我們的實驗得出結論，具有早期融合的多模式 LSTM 模型比具有後期融合的多模式 LSTM 模型和單模式 LSTM 模型更好，也比 ARIMA 和線性回歸模型更好。意義：我們解決了在不受控環境中進行時間序列預測的一項重要且具有挑戰性的任務。有效預測個人的身體活動有助於設計適應性行為介入措施，以保持使用者參與並遵守規定的例行公事。

##### **Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**
2410.09635v1 by Abdullah Mamun, Lawrence D. Devoe, Mark I. Evans, David W. Britt, Judith Klein-Seetharaman, Hassan Ghasemzadeh

Early detection of intrapartum risk enables interventions to potentially
prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently,
there is no accurate automated system to predict such events to assist with
clinical decision-making. To fill this gap, we propose "Artificial Intelligence
(AI) for Modeling and Explaining Neonatal Health" (AIMEN), a deep learning
framework that not only predicts adverse labor outcomes from maternal, fetal,
obstetrical, and intrapartum risk factors but also provides the model's
reasoning behind the predictions made. The latter can provide insights into
what modifications in the input variables of the model could have changed the
predicted outcome. We address the challenges of imbalance and small datasets by
synthesizing additional training data using Adaptive Synthetic Sampling
(ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN
uses an ensemble of fully-connected neural networks as the backbone for its
classification with the data augmentation supported by either ADASYN or CTGAN.
AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in
classification. AIMEN can predict a high risk for adverse labor outcomes with
an average F1 score of 0.784. It also provides counterfactual explanations that
can be achieved by changing 2 to 3 attributes on average. Resources available:
https://github.com/ab9mamun/AIMEN.

摘要：產程中風險的早期偵測有助於進行干預措施，以預防或減輕不利的生產結果，例如腦性麻痺。目前，沒有準確的自動化系統可以預測此類事件，以協助臨床決策。為了填補這一空白，我們提出「用於建模和解釋新生兒健康的人工智慧」(AIMEN)，這是一個深度學習架構，它不僅可以根據孕產婦、胎兒、產科和產程風險因素預測不利的生產結果，還能提供模型做出預測背後的原因。後者可以提供見解，說明模型輸入變數中的哪些修改可能會改變預測結果。我們透過使用適應性合成抽樣 (ADASYN) 和條件表格生成對抗網路 (CTGAN) 來合成額外的訓練資料，以解決不平衡和小型資料集的挑戰。AIMEN 使用全連接神經網路的集合作為其分類的骨幹，並透過 ADASYN 或 CTGAN 支援資料擴充。由 CTGAN 支援的 AIMEN 在分類方面優於由 ADASYN 支援的 AIMEN。AIMEN 可以預測不利的生產結果的高風險，平均 F1 分數為 0.784。它還提供反事實解釋，可透過平均變更 2 至 3 個屬性來達成。可用資源：https://github.com/ab9mamun/AIMEN。

##### **AuD-Former: A Hierarchical Transformer Network for Multimodal Audio-Based Disease Prediction**
2410.09289v1 by Jinjin Cai, Ruiqi Wang, Dezhong Zhao, Ziqin Yuan, Victoria McKenna, Aaron Friedman, Rachel Foot, Susan Storey, Ryan Boente, Sudip Vhaduri, Byung-Cheol Min

Audio-based disease prediction is emerging as a promising supplement to
traditional medical diagnosis methods, facilitating early, convenient, and
non-invasive disease detection and prevention. Multimodal fusion, which
integrates features from various domains within or across bio-acoustic
modalities, has proven effective in enhancing diagnostic performance. However,
most existing methods in the field employ unilateral fusion strategies that
focus solely on either intra-modal or inter-modal fusion. This approach limits
the full exploitation of the complementary nature of diverse acoustic feature
domains and bio-acoustic modalities. Additionally, the inadequate and isolated
exploration of latent dependencies within modality-specific and modality-shared
spaces curtails their capacity to manage the inherent heterogeneity in
multimodal data. To fill these gaps, we propose AuD-Former, a hierarchical
transformer network designed for general multimodal audio-based disease
prediction. Specifically, we seamlessly integrate intra-modal and inter-modal
fusion in a hierarchical manner and proficiently encode the necessary
intra-modal and inter-modal complementary correlations, respectively.
Comprehensive experiments demonstrate that AuD-Former achieves state-of-the-art
performance in predicting three diseases: COVID-19, Parkinson's disease, and
pathological dysarthria, showcasing its promising potential in a broad context
of audio-based disease prediction tasks. Additionally, extensive ablation
studies and qualitative analyses highlight the significant benefits of each
main component within our model.

摘要：<paragraph>基於音訊的疾病預測正逐漸成為傳統醫療診斷方法的有力補充，有助於早期、便利且非侵入式地偵測和預防疾病。多模態融合整合來自生物聲學模式內部或跨模式的各種領域的特徵，已被證實能有效提升診斷效能。然而，現有大多數方法採用單邊融合策略，僅專注於模式內或模式間融合。這種方法限制了對不同聲學特徵領域和生物聲學模式的互補特性的充分利用。此外，對模式特定和模式共享空間內潛在依賴性不足且孤立的探索，也限制了其管理多模態資料中固有異質性的能力。為了填補這些空白，我們提出 AuD-Former，一個階層式Transformer網路，專為一般多模態基於音訊的疾病預測而設計。具體來說，我們以階層方式無縫整合模式內和模式間融合，並分別熟練地編碼必要的模式內和模式間互補關聯。全面的實驗證明，AuD-Former 在預測三種疾病（COVID-19、帕金森氏症和病理性構音障礙）方面達到了最先進的效能，展示了其在廣泛的基於音訊的疾病預測任務中的潛力。此外，廣泛的消融研究和定性分析突出了我們模型中每個主要組成的顯著優點。</paragraph>

##### **Developing a Pragmatic Benchmark for Assessing Korean Legal Language Understanding in Large Language Models**
2410.08731v1 by Yeeun Kim, Young Rok Choi, Eunkyung Choi, Jinhwan Choi, Hai Jin Park, Wonseok Hwang

Large language models (LLMs) have demonstrated remarkable performance in the
legal domain, with GPT-4 even passing the Uniform Bar Exam in the U.S. However
their efficacy remains limited for non-standardized tasks and tasks in
languages other than English. This underscores the need for careful evaluation
of LLMs within each legal system before application. Here, we introduce KBL, a
benchmark for assessing the Korean legal language understanding of LLMs,
consisting of (1) 7 legal knowledge tasks (510 examples), (2) 4 legal reasoning
tasks (288 examples), and (3) the Korean bar exam (4 domains, 53 tasks, 2,510
examples). First two datasets were developed in close collaboration with
lawyers to evaluate LLMs in practical scenarios in a certified manner.
Furthermore, considering legal practitioners' frequent use of extensive legal
documents for research, we assess LLMs in both a closed book setting, where
they rely solely on internal knowledge, and a retrieval-augmented generation
(RAG) setting, using a corpus of Korean statutes and precedents. The results
indicate substantial room and opportunities for improvement.

摘要：大型語言模型 (LLM) 已在法律領域展現出卓越的表現，GPT-4 甚至通過了美國的統一律師考試。然而，其效能對於非標準化任務和非英語語言任務仍然有限。這凸顯了在應用 LLM 之前，需要仔細評估每個法律制度的必要性。在此，我們介紹 KBL，一個用於評估 LLM 韓語法律語言理解力的基準，包含 (1) 7 項法律知識任務（510 個範例）、(2) 4 項法律推理任務（288 個範例）和 (3) 韓國律師考試（4 個領域，53 項任務，2,510 個範例）。前兩個資料集是與律師密切合作開發，以認證的方式評估 LLM 在實際情境中的表現。此外，考量到法律從業人員經常使用大量的法律文件進行研究，我們在封閉式設定中評估 LLM，其中他們僅依賴內部知識，以及使用韓國法規和判例語料庫的檢索增強生成 (RAG) 設定。結果顯示仍有大幅進步的空間和機會。

##### **ViT3D Alignment of LLaMA3: 3D Medical Image Report Generation**
2410.08588v1 by Siyou Li, Beining Xu, Yihao Luo, Dong Nie, Le Zhang

Automatic medical report generation (MRG), which aims to produce detailed
text reports from medical images, has emerged as a critical task in this
domain. MRG systems can enhance radiological workflows by reducing the time and
effort required for report writing, thereby improving diagnostic efficiency. In
this work, we present a novel approach for automatic MRG utilizing a multimodal
large language model. Specifically, we employed the 3D Vision Transformer
(ViT3D) image encoder introduced from M3D-CLIP to process 3D scans and use the
Asclepius-Llama3-8B as the language model to generate the text reports by
auto-regressive decoding. The experiment shows our model achieved an average
Green score of 0.3 on the MRG task validation set and an average accuracy of
0.61 on the visual question answering (VQA) task validation set, outperforming
the baseline model. Our approach demonstrates the effectiveness of the ViT3D
alignment of LLaMA3 for automatic MRG and VQA tasks by tuning the model on a
small dataset.

摘要：自動化醫療報告生成 (MRG) 的目標是根據醫學影像產生詳細的文字報告，已成為此領域的一項重要任務。MRG 系統可以減少撰寫報告所需的時間和精力，從而提升放射科的工作流程，進而改善診斷效率。在這項工作中，我們提出了一種利用多模態大型語言模型進行自動化 MRG 的新方法。具體來說，我們採用了從 M3D-CLIP 引入的 3D 視覺Transformer (ViT3D) 影像編碼器來處理 3D 掃描，並使用 Asclepius-Llama3-8B 作為語言模型，透過自迴歸解碼來產生文字報告。實驗顯示，我們的模型在 MRG 任務驗證集上達到了平均 0.3 的 Green 分數，在視覺問答 (VQA) 任務驗證集上達到了平均 0.61 的準確率，優於基線模型。我們的做法證明了 ViT3D 對齊 LLaMA3 在自動化 MRG 和 VQA 任務中的有效性，方法是在小型資料集上調整模型。

##### **oRetrieval Augmented Generation for 10 Large Language Models and its Generalizability in Assessing Medical Fitness**
2410.08431v1 by Yu He Ke, Liyuan Jin, Kabilan Elangovan, Hairil Rizal Abdullah, Nan Liu, Alex Tiong Heng Sia, Chai Rick Soh, Joshua Yi Min Tung, Jasmine Chiat Ling Ong, Chang-Fu Kuo, Shao-Chun Wu, Vesela P. Kovacheva, Daniel Shu Wei Ting

Large Language Models (LLMs) show potential for medical applications but
often lack specialized clinical knowledge. Retrieval Augmented Generation (RAG)
allows customization with domain-specific information, making it suitable for
healthcare. This study evaluates the accuracy, consistency, and safety of RAG
models in determining fitness for surgery and providing preoperative
instructions. We developed LLM-RAG models using 35 local and 23 international
preoperative guidelines and tested them against human-generated responses. A
total of 3,682 responses were evaluated. Clinical documents were processed
using Llamaindex, and 10 LLMs, including GPT3.5, GPT4, and Claude-3, were
assessed. Fourteen clinical scenarios were analyzed, focusing on seven aspects
of preoperative instructions. Established guidelines and expert judgment were
used to determine correct responses, with human-generated answers serving as
comparisons. The LLM-RAG models generated responses within 20 seconds,
significantly faster than clinicians (10 minutes). The GPT4 LLM-RAG model
achieved the highest accuracy (96.4% vs. 86.6%, p=0.016), with no
hallucinations and producing correct instructions comparable to clinicians.
Results were consistent across both local and international guidelines. This
study demonstrates the potential of LLM-RAG models for preoperative healthcare
tasks, highlighting their efficiency, scalability, and reliability.

摘要：大型語言模型 (LLM) 顯示出在醫療應用方面的潛力，但通常缺乏專業的臨床知識。檢索擴充生成 (RAG) 允許使用特定領域的資訊進行自訂，使其適用於醫療保健。本研究評估 RAG 模型在確定手術適應症和提供術前說明方面的準確性、一致性和安全性。我們使用 35 份當地和 23 份國際術前指南開發了 LLM-RAG 模型，並將它們與人為產生的回應進行了測試。總共評估了 3,682 份回應。臨床文件使用 Llamaindex 處理，並評估了 10 個 LLM，包括 GPT3.5、GPT4 和 Claude-3。分析了 14 個臨床場景，重點關注術前說明的七個方面。使用既定的指南和專家判斷來確定正確的回應，並以人為產生的答案作為比較。LLM-RAG 模型在 20 秒內產生回應，顯著快於臨床醫生 (10 分鐘)。GPT4 LLM-RAG 模型達到了最高的準確度 (96.4% 對比 86.6%，p=0.016)，沒有出現幻覺，並產生了與臨床醫生相當的正確說明。結果在當地和國際指南中是一致的。本研究展示了 LLM-RAG 模型在術前醫療保健任務中的潛力，突出了它們的效率、可擴充性和可靠性。

##### **VoxelPrompt: A Vision-Language Agent for Grounded Medical Image Analysis**
2410.08397v1 by Andrew Hoopes, Victor Ion Butoi, John V. Guttag, Adrian V. Dalca

We present VoxelPrompt, an agent-driven vision-language framework that
tackles diverse radiological tasks through joint modeling of natural language,
image volumes, and analytical metrics. VoxelPrompt is multi-modal and
versatile, leveraging the flexibility of language interaction while providing
quantitatively grounded image analysis. Given a variable number of 3D medical
volumes, such as MRI and CT scans, VoxelPrompt employs a language agent that
iteratively predicts executable instructions to solve a task specified by an
input prompt. These instructions communicate with a vision network to encode
image features and generate volumetric outputs (e.g., segmentations).
VoxelPrompt interprets the results of intermediate instructions and plans
further actions to compute discrete measures (e.g., tumor growth across a
series of scans) and present relevant outputs to the user. We evaluate this
framework in a sandbox of diverse neuroimaging tasks, and we show that the
single VoxelPrompt model can delineate hundreds of anatomical and pathological
features, measure many complex morphological properties, and perform
open-language analysis of lesion characteristics. VoxelPrompt carries out these
objectives with accuracy similar to that of fine-tuned, single-task models for
segmentation and visual question-answering, while facilitating a much larger
range of tasks. Therefore, by supporting accurate image processing with
language interaction, VoxelPrompt provides comprehensive utility for numerous
imaging tasks that traditionally require specialized models to address.

摘要：<paragraph>我們提出 VoxelPrompt，一種由代理驅動的視覺語言框架，它透過自然語言、影像體積和分析指標的聯合建模，來處理多樣的放射學任務。VoxelPrompt 是多模態且多功能的，它利用語言互動的靈活性，同時提供量化基礎的影像分析。給定可變數量的 3D 醫學體積，例如 MRI 和 CT 掃描，VoxelPrompt 使用語言代理，反覆預測可執行指令，以解決由輸入提示指定的任務。這些指令與視覺網路溝通，以編碼影像特徵並產生體積輸出（例如，分割）。VoxelPrompt 解釋中間指令的結果，並規劃進一步的動作，以計算離散測量（例如，一系列掃描中的腫瘤生長），並向使用者提供相關輸出。我們在一個多樣化的神經影像任務沙盒中評估這個框架，我們表明單一的 VoxelPrompt 模型可以描述數百個解剖和病理特徵，測量許多複雜的形態屬性，並執行病灶特徵的開放語言分析。VoxelPrompt 執行這些目標的準確度與針對分割和視覺問答進行微調的單一任務模型類似，同時促進了更大的任務範圍。因此，透過支援使用語言互動的準確影像處理，VoxelPrompt 為傳統上需要專門模型來處理的眾多影像任務提供了全面的實用性。</paragraph>

##### **Optimizing Vital Sign Monitoring in Resource-Constrained Maternal Care: An RL-Based Restless Bandit Approach**
2410.08377v1 by Niclas Boehmer, Yunfan Zhao, Guojun Xiong, Paula Rodriguez-Diaz, Paola Del Cueto Cibrian, Joseph Ngonzi, Adeline Boatin, Milind Tambe

Maternal mortality remains a significant global public health challenge. One
promising approach to reducing maternal deaths occurring during facility-based
childbirth is through early warning systems, which require the consistent
monitoring of mothers' vital signs after giving birth. Wireless vital sign
monitoring devices offer a labor-efficient solution for continuous monitoring,
but their scarcity raises the critical question of how to allocate them most
effectively. We devise an allocation algorithm for this problem by modeling it
as a variant of the popular Restless Multi-Armed Bandit (RMAB) paradigm. In
doing so, we identify and address novel, previously unstudied constraints
unique to this domain, which render previous approaches for RMABs unsuitable
and significantly increase the complexity of the learning and planning problem.
To overcome these challenges, we adopt the popular Proximal Policy Optimization
(PPO) algorithm from reinforcement learning to learn an allocation policy by
training a policy and value function network. We demonstrate in simulations
that our approach outperforms the best heuristic baseline by up to a factor of
$4$.

摘要：產婦死亡率仍然是全球公共衛生的重大挑戰。一種有望減少在醫療機構生產過程中產婦死亡的方法是透過預警系統，這需要在產後持續監測產婦的生命徵象。無線生命徵象監測裝置提供了一種省力的連續監測解決方案，但其稀缺性引發了一個關鍵問題，即如何最有效地分配這些裝置。我們為這個問題設計了一個分配演算法，將其建模為流行的不耐煩多臂賭徒 (RMAB) 範例的變體。在這樣做的過程中，我們識別並解決了這個領域獨有的、以前未研究過的新約束，這些約束讓先前針對 RMAB 的方法變得不適用，並顯著增加了學習和規劃問題的複雜性。為了克服這些挑戰，我們採用了強化學習中流行的近端策略最佳化 (PPO) 演算法，透過訓練策略和價值函數網路來學習分配策略。我們在模擬中證明，我們的做法比最佳啟發式基準高出 $4$ 倍。

##### **ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation**
2410.07908v2 by Léo Machado, Hélène Philippe, Élodie Ferreres, Julien Khlaut, Julie Dupuis, Korentin Le Floch, Denis Habip Gatenyo, Pascal Roux, Jules Grégory, Maxime Ronot, Corentin Dancette, Daniel Tordjman, Pierre Manceron, Paul Hérent

Carcinogenesis is a proteiform phenomenon, with tumors emerging in various
locations and displaying complex, diverse shapes. At the crucial intersection
of research and clinical practice, it demands precise and flexible assessment.
However, current biomarkers, such as RECIST 1.1's long and short axis
measurements, fall short of capturing this complexity, offering an approximate
estimate of tumor burden and a simplistic representation of a more intricate
process. Additionally, existing supervised AI models face challenges in
addressing the variability in tumor presentations, limiting their clinical
utility. These limitations arise from the scarcity of annotations and the
models' focus on narrowly defined tasks.
  To address these challenges, we developed ONCOPILOT, an interactive
radiological foundation model trained on approximately 7,500 CT scans covering
the whole body, from both normal anatomy and a wide range of oncological cases.
ONCOPILOT performs 3D tumor segmentation using visual prompts like point-click
and bounding boxes, outperforming state-of-the-art models (e.g., nnUnet) and
achieving radiologist-level accuracy in RECIST 1.1 measurements. The key
advantage of this foundation model is its ability to surpass state-of-the-art
performance while keeping the radiologist in the loop, a capability that
previous models could not achieve. When radiologists interactively refine the
segmentations, accuracy improves further. ONCOPILOT also accelerates
measurement processes and reduces inter-reader variability, facilitating
volumetric analysis and unlocking new biomarkers for deeper insights.
  This AI assistant is expected to enhance the precision of RECIST 1.1
measurements, unlock the potential of volumetric biomarkers, and improve
patient stratification and clinical care, while seamlessly integrating into the
radiological workflow.

摘要：<paragraph>致癌作用是一種變形現象，腫瘤出現在不同位置，並呈現出複雜、多樣的形狀。在研究和臨床實務的重要交會點，它需要精確且靈活的評估。然而，目前的生物標記，例如 RECIST 1.1 的長軸和短軸測量，未能捕捉到這種複雜性，僅提供腫瘤負擔的近似估計值，以及對更複雜過程的簡化表示。此外，現有的監督式 AI 模型在處理腫瘤表現的變異性時面臨挑戰，限制了它們的臨床效用。這些限制來自於標註的稀少性，以及模型專注於狹義定義的任務。
為了應對這些挑戰，我們開發了 ONCOPILOT，這是一個互動式放射學基礎模型，訓練於大約 7,500 個涵蓋全身的 CT 掃描，包括正常解剖結構和各種腫瘤病例。ONCOPILOT 使用視覺提示（例如點選和邊界框）執行 3D 腫瘤分割，優於最先進的模型（例如 nnUnet），並在 RECIST 1.1 測量中達到放射科醫師等級的準確度。這個基礎模型的主要優點是它能夠超越最先進的效能，同時讓放射科醫師參與其中，這是以前的模型無法達到的能力。當放射科醫師互動式地調整分割時，準確度會進一步提高。ONCOPILOT 也加速了測量過程並減少了讀者間的變異性，促進了體積分析，並解鎖了新的生物標記，以獲得更深入的見解。
預計這個 AI 助理將提高 RECIST 1.1 測量的準確度，釋放體積生物標記的潛力，並改善患者分層和臨床照護，同時無縫整合到放射學工作流程中。</paragraph>

##### **Exploring ASR-Based Wav2Vec2 for Automated Speech Disorder Assessment: Insights and Analysis**
2410.08250v1 by Tuan Nguyen, Corinne Fredouille, Alain Ghio, Mathieu Balaguer, Virginie Woisard

With the rise of SSL and ASR technologies, the Wav2Vec2 ASR-based model has
been fine-tuned for automated speech disorder quality assessment tasks,
yielding impressive results and setting a new baseline for Head and Neck Cancer
speech contexts. This demonstrates that the ASR dimension from Wav2Vec2 closely
aligns with assessment dimensions. Despite its effectiveness, this system
remains a black box with no clear interpretation of the connection between the
model ASR dimension and clinical assessments. This paper presents the first
analysis of this baseline model for speech quality assessment, focusing on
intelligibility and severity tasks. We conduct a layer-wise analysis to
identify key layers and compare different SSL and ASR Wav2Vec2 models based on
pre-trained data. Additionally, post-hoc XAI methods, including Canonical
Correlation Analysis (CCA) and visualization techniques, are used to track
model evolution and visualize embeddings for enhanced interpretability.

摘要：隨著 SSL 和 ASR 技術的興起，基於 Wav2Vec2 的 ASR 模型已針對自動化語言障礙品質評估任務進行微調，產生令人印象深刻的結果，並為頭頸癌語音環境設定新的基準。這證明了 Wav2Vec2 的 ASR 維度與評估維度緊密對齊。儘管這個系統很有效，但它仍然是一個黑盒子，無法清楚解釋模型 ASR 維度與臨床評估之間的關聯。本文提出了第一個針對語音品質評估的基準模型分析，重點放在清晰度和嚴重性任務上。我們進行逐層分析，以識別關鍵層，並根據預訓練數據比較不同的 SSL 和 ASR Wav2Vec2 模型。此外，事後 XAI 方法（包括典型相關分析 (CCA) 和視覺化技術）用於追蹤模型演化，並視覺化嵌入以增強可解釋性。

##### **Forecasting mortality associated emergency department crowding**
2410.08247v1 by Jalmari Nevanlinna, Anna Eidstø, Jari Ylä-Mattila, Teemu Koivistoinen, Niku Oksala, Juho Kanniainen, Ari Palomäki, Antti Roine

Emergency department (ED) crowding is a global public health issue that has
been repeatedly associated with increased mortality. Predicting future service
demand would enable preventative measures aiming to eliminate crowding along
with it's detrimental effects. Recent findings in our ED indicate that
occupancy ratios exceeding 90% are associated with increased 10-day mortality.
In this paper, we aim to predict these crisis periods using retrospective data
from a large Nordic ED with a LightGBM model. We provide predictions for the
whole ED and individually for it's different operational sections. We
demonstrate that afternoon crowding can be predicted at 11 a.m. with an AUC of
0.82 (95% CI 0.78-0.86) and at 8 a.m. with an AUC up to 0.79 (95% CI
0.75-0.83). Consequently we show that forecasting mortality-associated crowding
using anonymous administrative data is feasible.

摘要：急診室（ED）擁擠是全球公共衛生問題，已反覆與死亡率上升相關。預測未來的服務需求將有助於採取預防措施，以消除擁擠及其不利影響。我們急診室的最新發現表明，入住率超過 90% 與 10 天死亡率增加相關。在本文中，我們旨在使用來自大型北歐急診室的回顧性數據和 LightGBM 模型來預測這些危機時期。我們提供整個急診室的預測，並分別針對其不同的運作部門進行預測。我們證明下午擁擠可以在上午 11 點預測，AUC 為 0.82（95% CI 0.78-0.86），在上午 8 點預測，AUC 高達 0.79（95% CI 0.75-0.83）。因此，我們表明使用匿名管理數據預測與死亡率相關的擁擠是可行的。

##### **Flex-MoE: Modeling Arbitrary Modality Combination via the Flexible Mixture-of-Experts**
2410.08245v1 by Sukwon Yun, Inyoung Choi, Jie Peng, Yangfan Wu, Jingxuan Bao, Qiyiwen Zhang, Jiayi Xin, Qi Long, Tianlong Chen

Multimodal learning has gained increasing importance across various fields,
offering the ability to integrate data from diverse sources such as images,
text, and personalized records, which are frequently observed in medical
domains. However, in scenarios where some modalities are missing, many existing
frameworks struggle to accommodate arbitrary modality combinations, often
relying heavily on a single modality or complete data. This oversight of
potential modality combinations limits their applicability in real-world
situations. To address this challenge, we propose Flex-MoE (Flexible
Mixture-of-Experts), a new framework designed to flexibly incorporate arbitrary
modality combinations while maintaining robustness to missing data. The core
idea of Flex-MoE is to first address missing modalities using a new missing
modality bank that integrates observed modality combinations with the
corresponding missing ones. This is followed by a uniquely designed Sparse MoE
framework. Specifically, Flex-MoE first trains experts using samples with all
modalities to inject generalized knowledge through the generalized router
($\mathcal{G}$-Router). The $\mathcal{S}$-Router then specializes in handling
fewer modality combinations by assigning the top-1 gate to the expert
corresponding to the observed modality combination. We evaluate Flex-MoE on the
ADNI dataset, which encompasses four modalities in the Alzheimer's Disease
domain, as well as on the MIMIC-IV dataset. The results demonstrate the
effectiveness of Flex-MoE highlighting its ability to model arbitrary modality
combinations in diverse missing modality scenarios. Code is available at
https://github.com/UNITES-Lab/flex-moe.

摘要：多模态学习在各个领域中获得越来越多的重视，
它提供了整合来自图像、
文本和个性化记录等不同来源的数据的能力，这些数据通常在医学
领域中观察到。然而，在某些模态缺失的情况下，许多现有的
框架难以适应任意模态组合，通常严重依赖于单一模态或完整数据。这种对
潜在模态组合的忽视限制了它们在现实世界中的适用性
情况。为了应对这一挑战，我们提出了 Flex-MoE（灵活
专家混合），一个旨在灵活地纳入任意
模态组合，同时保持对缺失数据的鲁棒性。Flex-MoE 的核心
思想是首先使用新的缺失模态库来解决缺失模态，该库将观察到的模态组合与
相应的缺失模态相结合。接下来是一个独特设计的稀疏 MoE
框架。具体来说，Flex-MoE 首先使用具有所有
模态的样本训练专家，以通过广义路由器注入广义知识
（$\mathcal{G}$-Router）。然后，$\mathcal{S}$-Router 通过将 top-1 门分配给专家来专门处理较少的模态组合
对应于观察到的模态组合。我们在
ADNI 数据集上评估 Flex-MoE，该数据集包含阿尔茨海默病中的四种模态
领域，以及 MIMIC-IV 数据集。结果证明了
Flex-MoE 的有效性，突出了其在不同缺失模态场景中对任意模态组合进行建模的能力。代码可在
https://github.com/UNITES-Lab/flex-moe 获得。

##### **Artificial intelligence techniques in inherited retinal diseases: A review**
2410.09105v1 by Han Trinh, Jordan Vice, Jason Charng, Zahra Tajbakhsh, Khyber Alam, Fred K. Chen, Ajmal Mian

Inherited retinal diseases (IRDs) are a diverse group of genetic disorders
that lead to progressive vision loss and are a major cause of blindness in
working-age adults. The complexity and heterogeneity of IRDs pose significant
challenges in diagnosis, prognosis, and management. Recent advancements in
artificial intelligence (AI) offer promising solutions to these challenges.
However, the rapid development of AI techniques and their varied applications
have led to fragmented knowledge in this field. This review consolidates
existing studies, identifies gaps, and provides an overview of AI's potential
in diagnosing and managing IRDs. It aims to structure pathways for advancing
clinical applications by exploring AI techniques like machine learning and deep
learning, particularly in disease detection, progression prediction, and
personalized treatment planning. Special focus is placed on the effectiveness
of convolutional neural networks in these areas. Additionally, the integration
of explainable AI is discussed, emphasizing its importance in clinical settings
to improve transparency and trust in AI-based systems. The review addresses the
need to bridge existing gaps in focused studies on AI's role in IRDs, offering
a structured analysis of current AI techniques and outlining future research
directions. It concludes with an overview of the challenges and opportunities
in deploying AI for IRDs, highlighting the need for interdisciplinary
collaboration and the continuous development of robust, interpretable AI models
to advance clinical applications.

摘要：遺傳性視網膜疾病 (IRD) 是一組多樣化的遺傳疾病，
會導致視力逐漸喪失，是工作年齡成人失明的主要原因。IRD 的複雜性和異質性對診斷、預後和管理提出了重大挑戰。最近人工智能 (AI) 的進步為這些挑戰提供了有希望的解決方案。
然而，AI 技術的快速發展及其多種應用導致了該領域的知識分散。本綜述整合了現有研究，找出差距，並概述了 AI 在診斷和管理 IRD 中的潛力。它旨在通過探索機器學習和深度學習等 AI 技術，特別是在疾病檢測、進程預測和個性化治療計劃中，為推進臨床應用構建途徑。特別關注這些領域中卷積神經網路的有效性。此外，討論了可解釋 AI 的整合，強調了其在臨床環境中提高透明度和對基於 AI 的系統的信任的重要性。該綜述解決了彌合 AI 在 IRD 中作用的重點研究中現有差距的必要性，提供了對當前 AI 技術的結構化分析，並概述了未來的研究方向。最後概述了在 IRD 中部署 AI 的挑戰和機遇，強調了跨學科合作和持續開發強大、可解釋的 AI 模型以推進臨床應用的必要性。

##### **Offline Inverse Constrained Reinforcement Learning for Safe-Critical Decision Making in Healthcare**
2410.07525v2 by Nan Fang, Guiliang Liu, Wei Gong

Reinforcement Learning (RL) applied in healthcare can lead to unsafe medical
decisions and treatment, such as excessive dosages or abrupt changes, often due
to agents overlooking common-sense constraints. Consequently, Constrained
Reinforcement Learning (CRL) is a natural choice for safe decisions. However,
specifying the exact cost function is inherently difficult in healthcare.
Recent Inverse Constrained Reinforcement Learning (ICRL) is a promising
approach that infers constraints from expert demonstrations. ICRL algorithms
model Markovian decisions in an interactive environment. These settings do not
align with the practical requirement of a decision-making system in healthcare,
where decisions rely on historical treatment recorded in an offline dataset. To
tackle these issues, we propose the Constraint Transformer (CT). Specifically,
1) we utilize a causal attention mechanism to incorporate historical decisions
and observations into the constraint modeling, while employing a Non-Markovian
layer for weighted constraints to capture critical states. 2) A generative
world model is used to perform exploratory data augmentation, enabling offline
RL methods to simulate unsafe decision sequences. In multiple medical
scenarios, empirical results demonstrate that CT can capture unsafe states and
achieve strategies that approximate lower mortality rates, reducing the
occurrence probability of unsafe behaviors.

摘要：強化學習 (RL) 應用於醫療保健可能會導致不安全的醫療決策和治療，例如過量劑量或突然改變，通常是因為代理人忽視常識限制。因此，受約束強化學習 (CRL) 是安全決策的自然選擇。然而，在醫療保健中明確指定確切的成本函數本質上很困難。最近的反向受約束強化學習 (ICRL) 是一種有前景的方法，它從專家示範中推斷出約束。ICRL 演算法在互動環境中建構馬可夫決策。這些設定與醫療保健中決策系統的實際要求不符，在醫療保健中，決策依賴於離線資料集中記錄的歷史治療。為了解決這些問題，我們提出了約束轉換器 (CT)。具體來說，1) 我們利用因果注意機制將歷史決策和觀察納入約束建模，同時採用非馬可夫層，以加權約束來捕捉關鍵狀態。2) 生成式世界模型用於執行探索性資料擴充，使離線 RL 方法能夠模擬不安全的決策序列。在多種醫療場景中，實證結果表明，CT 可以捕捉不安全的狀態，並實現近似降低死亡率的策略，從而降低不安全行為發生的機率。

##### **Unlocking Real-Time Fluorescence Lifetime Imaging: Multi-Pixel Parallelism for FPGA-Accelerated Processing**
2410.07364v1 by Ismail Erbas, Aporva Amarnath, Vikas Pandey, Karthik Swaminathan, Naigang Wang, Xavier Intes

Fluorescence lifetime imaging (FLI) is a widely used technique in the
biomedical field for measuring the decay times of fluorescent molecules,
providing insights into metabolic states, protein interactions, and
ligand-receptor bindings. However, its broader application in fast biological
processes, such as dynamic activity monitoring, and clinical use, such as in
guided surgery, is limited by long data acquisition times and computationally
demanding data processing. While deep learning has reduced post-processing
times, time-resolved data acquisition remains a bottleneck for real-time
applications. To address this, we propose a method to achieve real-time FLI
using an FPGA-based hardware accelerator. Specifically, we implemented a
GRU-based sequence-to-sequence (Seq2Seq) model on an FPGA board compatible with
time-resolved cameras. The GRU model balances accurate processing with the
resource constraints of FPGAs, which have limited DSP units and BRAM. The
limited memory and computational resources on the FPGA require efficient
scheduling of operations and memory allocation to deploy deep learning models
for low-latency applications. We address these challenges by using STOMP, a
queue-based discrete-event simulator that automates and optimizes task
scheduling and memory management on hardware. By integrating a GRU-based
Seq2Seq model and its compressed version, called Seq2SeqLite, generated through
knowledge distillation, we were able to process multiple pixels in parallel,
reducing latency compared to sequential processing. We explore various levels
of parallelism to achieve an optimal balance between performance and resource
utilization. Our results indicate that the proposed techniques achieved a 17.7x
and 52.0x speedup over manual scheduling for the Seq2Seq model and the
Seq2SeqLite model, respectively.

摘要：螢光生命週期影像 (FLI) 是生物醫學領域中廣泛使用的技術，用於測量螢光分子的衰變時間，提供代謝狀態、蛋白質交互作用和配體受體結合的見解。然而，其在快速生物過程（例如動態活動監測）和臨床用途（例如引導式手術）中的廣泛應用受到長時間資料擷取和計算需求高的資料處理的限制。儘管深度學習減少了後處理時間，但時間解析資料擷取仍然是即時應用程式的瓶頸。為了解決這個問題，我們提出了一種使用基於 FPGA 的硬體加速器來實現即時 FLI 的方法。具體來說，我們在與時間解析相機相容的 FPGA 板上實作了基於 GRU 的序列對序列 (Seq2Seq) 模型。GRU 模型平衡了準確的處理與 FPGA 的資源限制，FPGA 的 DSP 單元和 BRAM 有限。FPGA 上有限的記憶體和計算資源需要有效地排程作業和記憶體配置，才能部署深度學習模型以進行低延遲應用程式。我們透過使用 STOMP 來解決這些挑戰，這是一個基於佇列的離散事件模擬器，可自動化和最佳化硬體上的任務排程和記憶體管理。透過整合基於 GRU 的 Seq2Seq 模型及其壓縮版本 Seq2SeqLite（透過知識萃取產生），我們能夠平行處理多個像素，與順序處理相比，可減少延遲。我們探索了各種平行層級，以在效能和資源利用率之間取得最佳平衡。我們的結果表明，與 Seq2Seq 模型和 Seq2SeqLite 模型的手動排程相比，所提出的技術分別達到了 17.7 倍和 52.0 倍的加速。

##### **Taking a turn for the better: Conversation redirection throughout the course of mental-health therapy**
2410.07147v1 by Vivian Nguyen, Sang Min Jung, Lillian Lee, Thomas D. Hull, Cristian Danescu-Niculescu-Mizil

Mental-health therapy involves a complex conversation flow in which patients
and therapists continuously negotiate what should be talked about next. For
example, therapists might try to shift the conversation's direction to keep the
therapeutic process on track and avoid stagnation, or patients might push the
discussion towards issues they want to focus on.
  How do such patient and therapist redirections relate to the development and
quality of their relationship? To answer this question, we introduce a
probabilistic measure of the extent to which a certain utterance immediately
redirects the flow of the conversation, accounting for both the intention and
the actual realization of such a change. We apply this new measure to
characterize the development of patient-therapist relationships over multiple
sessions in a very large, widely-used online therapy platform. Our analysis
reveals that (1) patient control of the conversation's direction generally
increases relative to that of the therapist as their relationship progresses;
and (2) patients who have less control in the first few sessions are
significantly more likely to eventually express dissatisfaction with their
therapist and terminate the relationship.

摘要：心理健康治療涉及複雜的對話流程，其中患者和治療師持續協商接下來應討論什麼。例如，治療師可能會嘗試改變對話方向，以使治療過程保持在正軌並避免停滯，或者患者可能會將討論引向他們想關注的問題。
患者和治療師的這種重新定向與他們關係的發展和品質有何關係？為了回答這個問題，我們引入了一個機率測量，用於衡量某個話語在多大程度上立即重新定向對話流程，同時考量此類變化的意圖和實際實現。我們將此新測量應用於描述患者-治療師關係在一個非常龐大、廣泛使用的線上治療平台上，在多個療程中的發展。我們的分析顯示，(1) 隨著患者與治療師關係的進展，患者對對話方向的控制通常會相對於治療師而增加；(2) 在最初幾次療程中控制較少的患者，最終顯著更有可能對其治療師表達不滿並終止關係。

##### **Mental Disorders Detection in the Era of Large Language Models**
2410.07129v2 by Gleb Kuzmin, Petr Strepetov, Maksim Stankevich, Artem Shelmanov, Ivan Smirnov

This paper compares the effectiveness of traditional machine learning
methods, encoder-based models, and large language models (LLMs) on the task of
detecting depression and anxiety. Five datasets were considered, each differing
in format and the method used to define the target pathology class. We tested
AutoML models based on linguistic features, several variations of encoder-based
Transformers such as BERT, and state-of-the-art LLMs as pathology
classification models. The results demonstrated that LLMs outperform
traditional methods, particularly on noisy and small datasets where training
examples vary significantly in text length and genre. However, psycholinguistic
features and encoder-based models can achieve performance comparable to
language models when trained on texts from individuals with clinically
confirmed depression, highlighting their potential effectiveness in targeted
clinical applications.

摘要：本文比較了傳統機器學習方法、編碼器模型和大型語言模型 (LLM) 在偵測憂鬱症和焦慮症任務上的有效性。考慮了五個資料集，每個資料集在格式和用於定義目標病理類別的方法上都不同。我們測試了基於語言特徵的 AutoML 模型、多種編碼器模型的變體，例如 BERT，以及作為病理分類模型的最新 LLM。結果表明，LLM 優於傳統方法，特別是在訓練範例在文字長度和類型上差異很大的嘈雜且小型資料集上。然而，當在臨床上確診罹患憂鬱症的個體的文字上進行訓練時，心理語言學特徵和編碼器模型可以達到與語言模型相當的效能，突顯了其在目標臨床應用中的潛在有效性。

##### **MentalArena: Self-play Training of Language Models for Diagnosis and Treatment of Mental Health Disorders**
2410.06845v1 by Cheng Li, May Fung, Qingyun Wang, Chi Han, Manling Li, Jindong Wang, Heng Ji

Mental health disorders are one of the most serious diseases in the world.
Most people with such a disease lack access to adequate care, which highlights
the importance of training models for the diagnosis and treatment of mental
health disorders. However, in the mental health domain, privacy concerns limit
the accessibility of personalized treatment data, making it challenging to
build powerful models. In this paper, we introduce MentalArena, a self-play
framework to train language models by generating domain-specific personalized
data, where we obtain a better model capable of making a personalized diagnosis
and treatment (as a therapist) and providing information (as a patient). To
accurately model human-like mental health patients, we devise Symptom Encoder,
which simulates a real patient from both cognition and behavior perspectives.
To address intent bias during patient-therapist interactions, we propose
Symptom Decoder to compare diagnosed symptoms with encoded symptoms, and
dynamically manage the dialogue between patient and therapist according to the
identified deviations. We evaluated MentalArena against 6 benchmarks, including
biomedicalQA and mental health tasks, compared to 6 advanced models. Our
models, fine-tuned on both GPT-3.5 and Llama-3-8b, significantly outperform
their counterparts, including GPT-4o. We hope that our work can inspire future
research on personalized care. Code is available in
https://github.com/Scarelette/MentalArena/tree/main

摘要：心理健康障礙是世界上最嚴重的疾病之一。
大多數患有這種疾病的人無法獲得適當的照護，這凸顯了訓練模型以診斷和治療心理健康障礙的重要性。然而，在心理健康領域，隱私問題限制了個人化治療資料的可及性，這使得建立強大的模型變得具有挑戰性。在本文中，我們介紹了 MentalArena，一個自玩框架，通過生成特定領域的個人化資料來訓練語言模型，在其中我們獲得了一個更好的模型，能夠進行個人化診斷和治療（作為治療師）並提供資訊（作為患者）。為了準確模擬類似人類的心理健康患者，我們設計了症狀編碼器，它從認知和行為的角度模擬一個真實的患者。為了解決患者與治療師互動期間的意圖偏差，我們提出了症狀解碼器，將診斷出的症狀與編碼症狀進行比較，並根據識別出的偏差動態管理患者與治療師之間的對話。我們針對 6 個基準對 MentalArena 進行了評估，包括生物醫學問答和心理健康任務，並與 6 個先進模型進行了比較。我們的模型在 GPT-3.5 和 Llama-3-8b 上都進行了微調，顯著優於其對應模型，包括 GPT-4o。我們希望我們的研究能激勵未來對個人化照護的研究。程式碼可在 https://github.com/Scarelette/MentalArena/tree/main 中獲得

##### **An Improved Approach for Cardiac MRI Segmentation based on 3D UNet Combined with Papillary Muscle Exclusion**
2410.06818v1 by Narjes Benameur, Ramzi Mahmoudi, Mohamed Deriche, Amira fayouka, Imene Masmoudi, Nessrine Zoghlami

Left ventricular ejection fraction (LVEF) is the most important clinical
parameter of cardiovascular function. The accuracy in estimating this parameter
is highly dependent upon the precise segmentation of the left ventricle (LV)
structure at the end diastole and systole phases. Therefore, it is crucial to
develop robust algorithms for the precise segmentation of the heart structure
during different phases. Methodology: In this work, an improved 3D UNet model
is introduced to segment the myocardium and LV, while excluding papillary
muscles, as per the recommendation of the Society for Cardiovascular Magnetic
Resonance. For the practical testing of the proposed framework, a total of
8,400 cardiac MRI images were collected and analysed from the military hospital
in Tunis (HMPIT), as well as the popular ACDC public dataset. As performance
metrics, we used the Dice coefficient and the F1 score for validation/testing
of the LV and the myocardium segmentation. Results: The data was split into
70%, 10%, and 20% for training, validation, and testing, respectively. It is
worth noting that the proposed segmentation model was tested across three axis
views: basal, medio basal and apical at two different cardiac phases: end
diastole and end systole instances. The experimental results showed a Dice
index of 0.965 and 0.945, and an F1 score of 0.801 and 0.799, at the end
diastolic and systolic phases, respectively. Additionally, clinical evaluation
outcomes revealed a significant difference in the LVEF and other clinical
parameters when the papillary muscles were included or excluded.

摘要：左心室射血分數 (LVEF) 是心血管功能最重要的臨床參數。估計此參數的準確性高度依賴於左心室 (LV) 結構在舒張末期和收縮期的精確分割。因此，開發用於精確分割不同時期心臟結構的強健演算法至關重要。方法：在此工作中，引進了一個改良的 3D UNet 模型來分割心肌和左心室，同時根據心血管磁共振學會的建議排除乳頭肌。為了對提出的架構進行實際測試，從突尼斯的軍事醫院 (HMPIT) 和流行的 ACDC 公共資料集收集並分析了總共 8,400 張心臟 MRI 影像。作為效能指標，我們使用 Dice 係數和 F1 分數來驗證/測試左心室和心肌分割。結果：資料被分成 70%、10% 和 20% 分別用於訓練、驗證和測試。值得注意的是，所提出的分割模型在三個軸向視圖中進行了測試：基底、中基底和心尖，在兩個不同的心臟時期：舒張末期和收縮末期。實驗結果顯示，在舒張末期和收縮期，Dice 指數分別為 0.965 和 0.945，F1 分數分別為 0.801 和 0.799。此外，臨床評估結果顯示，當乳頭肌被納入或排除時，LVEF 和其他臨床參數存在顯著差異。

##### **Deep Learning for Surgical Instrument Recognition and Segmentation in Robotic-Assisted Surgeries: A Systematic Review**
2410.07269v1 by Fatimaelzahraa Ali Ahmed, Mahmoud Yousef, Mariam Ali Ahmed, Hasan Omar Ali, Anns Mahboob, Hazrat Ali, Zubair Shah, Omar Aboumarzouk, Abdulla Al Ansari, Shidin Balakrishnan

Applying deep learning (DL) for annotating surgical instruments in
robot-assisted minimally invasive surgeries (MIS) represents a significant
advancement in surgical technology. This systematic review examines 48 studies
that and advanced DL methods and architectures. These sophisticated DL models
have shown notable improvements in the precision and efficiency of detecting
and segmenting surgical tools. The enhanced capabilities of these models
support various clinical applications, including real-time intraoperative
guidance, comprehensive postoperative evaluations, and objective assessments of
surgical skills. By accurately identifying and segmenting surgical instruments
in video data, DL models provide detailed feedback to surgeons, thereby
improving surgical outcomes and reducing complication risks. Furthermore, the
application of DL in surgical education is transformative. The review
underscores the significant impact of DL on improving the accuracy of skill
assessments and the overall quality of surgical training programs. However,
implementing DL in surgical tool detection and segmentation faces challenges,
such as the need for large, accurately annotated datasets to train these models
effectively. The manual annotation process is labor-intensive and
time-consuming, posing a significant bottleneck. Future research should focus
on automating the detection and segmentation process and enhancing the
robustness of DL models against environmental variations. Expanding the
application of DL models across various surgical specialties will be essential
to fully realize this technology's potential. Integrating DL with other
emerging technologies, such as augmented reality (AR), also offers promising
opportunities to further enhance the precision and efficacy of surgical
procedures.

摘要：應用深度學習 (DL) 來註解機器人輔助微創手術 (MIS) 中的外科器械代表了外科技術的重大進步。這項系統性回顧審查了 48 項研究，這些研究採用先進的 DL 方法和架構。這些複雜的 DL 模型在偵測和分割外科手術工具的精準度和效率方面已展現出顯著的進步。這些模型增強的功能支援各種臨床應用，包括即時術中引導、全面的術後評估和外科技術的客觀評估。透過在影片資料中精確識別和分割外科器械，DL 模型能提供詳細的回饋給外科醫生，進而改善手術結果並降低併發症風險。此外，DL 在外科教育中的應用具有變革性。這項回顧強調了 DL 在改善技能評估準確度和整體外科訓練計畫品質方面的重大影響。然而，在外科工具偵測和分割中實施 DL 面臨挑戰，例如需要大量準確註解的資料集才能有效訓練這些模型。手動註解過程耗時且費力，構成了一項重大的瓶頸。未來的研究應專注於自動化偵測和分割流程，並增強 DL 模型對環境變化的魯棒性。擴展 DL 模型在各種外科專科的應用對於充分實現這項技術的潛力至關重要。將 DL 與其他新興技術（例如擴增實境 (AR)）整合也提供了有望進一步增強外科手術精準度和效率的機會。

##### **Multimodal Representation Learning using Adaptive Graph Construction**
2410.06395v1 by Weichen Huang

Multimodal contrastive learning train neural networks by levergaing data from
heterogeneous sources such as images and text. Yet, many current multimodal
learning architectures cannot generalize to an arbitrary number of modalities
and need to be hand-constructed. We propose AutoBIND, a novel contrastive
learning framework that can learn representations from an arbitrary number of
modalites through graph optimization. We evaluate AutoBIND on Alzhiemer's
disease detection because it has real-world medical applicability and it
contains a broad range of data modalities. We show that AutoBIND outperforms
previous methods on this task, highlighting the generalizablility of the
approach.

摘要：多模態對比學習透過利用來自異質來源（例如圖像和文字）的資料來訓練神經網路。然而，許多目前的多模態學習架構無法推廣到任意數量的模態，並且需要手動建構。我們提出了 AutoBIND，一個新穎的對比學習架構，它可以透過圖形最佳化從任意數量的模態中學習表徵。我們在阿茲海默症的偵測上評估 AutoBIND，因為它具有實際的醫療應用性，而且它包含廣泛的資料模態。我們展示 AutoBIND 在這項任務上優於先前的各種方法，突顯了此方法的泛化能力。

##### **Skin Cancer Machine Learning Model Tone Bias**
2410.06385v1 by James Pope, Md Hassanuzzaman, Mingmar Sherpa, Omar Emara, Ayush Joshi, Nirmala Adhikari

Background: Many open-source skin cancer image datasets are the result of
clinical trials conducted in countries with lighter skin tones. Due to this
tone imbalance, machine learning models derived from these datasets can perform
well at detecting skin cancer for lighter skin tones. Any tone bias in these
models could introduce fairness concerns and reduce public trust in the
artificial intelligence health field.
  Methods: We examine a subset of images from the International Skin Imaging
Collaboration (ISIC) archive that provide tone information. The subset has a
significant tone imbalance. These imbalances could explain a model's tone bias.
To address this, we train models using the imbalanced dataset and a balanced
dataset to compare against. The datasets are used to train a deep convolutional
neural network model to classify the images as malignant or benign. We then
evaluate the models' disparate impact, based on selection rate, relative to
dark or light skin tone.
  Results: Using the imbalanced dataset, we found that the model is
significantly better at detecting malignant images in lighter tone resulting in
a disparate impact of 0.577. Using the balanced dataset, we found that the
model is also significantly better at detecting malignant images in lighter
versus darker tones with a disparate impact of 0.684. Using the imbalanced or
balanced dataset to train the model still results in a disparate impact well
below the standard threshold of 0.80 which suggests the model is biased with
respect to skin tone.
  Conclusion: The results show that typical skin cancer machine learning models
can be tone biased. These results provide evidence that diagnosis or tone
imbalance is not the cause of the bias. Other techniques will be necessary to
identify and address the bias in these models, an area of future investigation.

摘要：<paragraph>背景：許多開放原始碼皮膚癌圖像資料集是根據在膚色較淺的國家進行的臨床試驗的結果。由於這種色調不平衡，從這些資料集派生的機器學習模型在檢測膚色較淺的皮膚癌方面表現良好。這些模型中的任何色調偏差都可能引發公平性的問題，並降低公眾對人工智慧健康領域的信任。
方法：我們檢查了國際皮膚影像合作組織 (ISIC) 檔案庫中提供色調資訊的圖像子集。該子集具有顯著的色調不平衡。這些不平衡可能解釋了模型的色調偏差。為了解決這個問題，我們使用不平衡的資料集和平衡的資料集訓練模型，以便進行比較。這些資料集用於訓練深度卷積神經網路模型，將影像分類為惡性或良性。然後，我們根據選擇率評估模型的不同影響，相對於深色或淺色膚色。
結果：使用不平衡的資料集，我們發現該模型在檢測淺色色調中的惡性影像方面顯著優於在深色色調中檢測惡性影像，導致 0.577 的不同影響。使用平衡的資料集，我們發現該模型在檢測淺色色調中的惡性影像方面也顯著優於深色色調，不同影響為 0.684。使用不平衡或平衡的資料集訓練模型仍然會導致不同影響，遠低於 0.80 的標準閾值，這表明模型在膚色方面有偏差。
結論：結果表明，典型的皮膚癌機器學習模型可能會產生色調偏差。這些結果提供了證據表明，診斷或色調不平衡並非造成偏差的原因。需要其他技術來識別和解決這些模型中的偏差，這是未來研究的一個領域。</paragraph>

##### **HumVI: A Multilingual Dataset for Detecting Violent Incidents Impacting Humanitarian Aid**
2410.06370v2 by Hemank Lamba, Anton Abilov, Ke Zhang, Elizabeth M. Olson, Henry k. Dambanemuya, João c. Bárcia, David S. Batista, Christina Wille, Aoife Cahill, Joel Tetreault, Alex Jaimes

Humanitarian organizations can enhance their effectiveness by analyzing data
to discover trends, gather aggregated insights, manage their security risks,
support decision-making, and inform advocacy and funding proposals. However,
data about violent incidents with direct impact and relevance for humanitarian
aid operations is not readily available. An automatic data collection and
NLP-backed classification framework aligned with humanitarian perspectives can
help bridge this gap. In this paper, we present HumVI - a dataset comprising
news articles in three languages (English, French, Arabic) containing instances
of different types of violent incidents categorized by the humanitarian sector
they impact, e.g., aid security, education, food security, health, and
protection. Reliable labels were obtained for the dataset by partnering with a
data-backed humanitarian organization, Insecurity Insight. We provide multiple
benchmarks for the dataset, employing various deep learning architectures and
techniques, including data augmentation and mask loss, to address different
task-related challenges, e.g., domain expansion. The dataset is publicly
available at https://github.com/dataminr-ai/humvi-dataset.

摘要：人道主義組織可透過分析資料來提升其成效，以找出趨勢、收集彙整的見解、管理其安全風險、支援決策制定，以及告知倡議和募款提案。不過，與人道主義援助行動直接相關且具影響力的暴力事件資料並不容易取得。一個與人道主義觀點一致的自動資料收集和 NLP 支援分類架構，有助於彌補這個差距。在本文中，我們提出 HumVI - 一個包含三種語言（英語、法語、阿拉伯語）新聞文章的資料集，其中包含人道主義部門分類的不同類型暴力事件實例，例如援助安全、教育、糧食安全、健康和保護。我們透過與資料支援的人道主義組織 Insecurity Insight 合作，取得資料集的可靠標籤。我們為資料集提供多個基準，採用各種深度學習架構和技術，包括資料擴充和遮罩損失，以應對不同的任務相關挑戰，例如領域擴充。資料集已於 https://github.com/dataminr-ai/humvi-dataset 公開。

##### **A Comparative Study of Hybrid Models in Health Misinformation Text Classification**
2410.06311v1 by Mkululi Sikosana, Oluwaseun Ajao, Sean Maudsley-Barton

This study evaluates the effectiveness of machine learning (ML) and deep
learning (DL) models in detecting COVID-19-related misinformation on online
social networks (OSNs), aiming to develop more effective tools for countering
the spread of health misinformation during the pan-demic. The study trained and
tested various ML classifiers (Naive Bayes, SVM, Random Forest, etc.), DL
models (CNN, LSTM, hybrid CNN+LSTM), and pretrained language models
(DistilBERT, RoBERTa) on the "COVID19-FNIR DATASET". These models were
evaluated for accuracy, F1 score, recall, precision, and ROC, and used
preprocessing techniques like stemming and lemmatization. The results showed
SVM performed well, achieving a 94.41% F1-score. DL models with Word2Vec
embeddings exceeded 98% in all performance metrics (accuracy, F1 score, recall,
precision & ROC). The CNN+LSTM hybrid models also exceeded 98% across
performance metrics, outperforming pretrained models like DistilBERT and
RoBERTa. Our study concludes that DL and hybrid DL models are more effective
than conventional ML algorithms for detecting COVID-19 misinformation on OSNs.
The findings highlight the importance of advanced neural network approaches and
large-scale pretraining in misinformation detection. Future research should
optimize these models for various misinformation types and adapt to changing
OSNs, aiding in combating health misinformation.

摘要：這項研究評估機器學習 (ML) 和深度學習 (DL) 模型在偵測線上社群網路 (OSN) 上與 COVID-19 相關的錯誤訊息的有效性，目標是開發更有效的工具來對抗大流行期間健康錯誤訊息的散布。這項研究訓練並測試了各種 ML 分類器（樸素貝氏、SVM、隨機森林等）、DL 模型（CNN、LSTM、混合 CNN+LSTM）和預訓練語言模型（DistilBERT、RoBERTa）在「COVID19-FNIR 資料集」上。這些模型經過評估，標準為準確度、F1 分數、召回率、精確度和 ROC，並使用了詞幹化和詞形還原等前處理技術。結果顯示 SVM 表現良好，達到 94.41% 的 F1 分數。使用 Word2Vec 嵌入的 DL 模型在所有效能指標（準確度、F1 分數、召回率、精確度和 ROC）中都超過 98%。CNN+LSTM 混合模型在所有效能指標中也超過 98%，優於 DistilBERT 和 RoBERTa 等預訓練模型。我們的研究結論是，DL 和混合 DL 模型比傳統 ML 演算法更能有效偵測 OSN 上的 COVID-19 錯誤訊息。這些發現突顯了進階神經網路方法和錯誤訊息偵測中大規模預訓練的重要性。未來的研究應針對各種錯誤訊息類型最佳化這些模型，並適應不斷變化的 OSN，協助打擊健康錯誤訊息。

##### **Application of NotebookLM, a Large Language Model with Retrieval-Augmented Generation, for Lung Cancer Staging**
2410.10869v1 by Ryota Tozuka, Hisashi Johno, Akitomo Amakawa, Junichi Sato, Mizuki Muto, Shoichiro Seki, Atsushi Komaba, Hiroshi Onishi

Purpose: In radiology, large language models (LLMs), including ChatGPT, have
recently gained attention, and their utility is being rapidly evaluated.
However, concerns have emerged regarding their reliability in clinical
applications due to limitations such as hallucinations and insufficient
referencing. To address these issues, we focus on the latest technology,
retrieval-augmented generation (RAG), which enables LLMs to reference reliable
external knowledge (REK). Specifically, this study examines the utility and
reliability of a recently released RAG-equipped LLM (RAG-LLM), NotebookLM, for
staging lung cancer.
  Materials and methods: We summarized the current lung cancer staging
guideline in Japan and provided this as REK to NotebookLM. We then tasked
NotebookLM with staging 100 fictional lung cancer cases based on CT findings
and evaluated its accuracy. For comparison, we performed the same task using a
gold-standard LLM, GPT-4 Omni (GPT-4o), both with and without the REK.
  Results: NotebookLM achieved 86% diagnostic accuracy in the lung cancer
staging experiment, outperforming GPT-4o, which recorded 39% accuracy with the
REK and 25% without it. Moreover, NotebookLM demonstrated 95% accuracy in
searching reference locations within the REK.
  Conclusion: NotebookLM successfully performed lung cancer staging by
utilizing the REK, demonstrating superior performance compared to GPT-4o.
Additionally, it provided highly accurate reference locations within the REK,
allowing radiologists to efficiently evaluate the reliability of NotebookLM's
responses and detect possible hallucinations. Overall, this study highlights
the potential of NotebookLM, a RAG-LLM, in image diagnosis.

摘要：<paragraph>目的：在放射學中，大型語言模型 (LLM)，包括 ChatGPT，最近受到關注，並且它們的效用正被迅速評估。然而，由於幻覺和參考不足等限制，人們開始關注它們在臨床應用中的可靠性。為了解決這些問題，我們專注於最新的技術，檢索增強生成 (RAG)，它使 LLM 能夠參考可靠的外部知識 (REK)。具體來說，這項研究探討了最近發布的配備 RAG 的 LLM (RAG-LLM)，NotebookLM，在肺癌分期的效用和可靠性。材料和方法：我們總結了日本當前的肺癌分期指南，並將其作為 REK 提供給 NotebookLM。然後我們讓 NotebookLM 根據 CT 結果對 100 個虛構的肺癌病例進行分期，並評估其準確性。為了進行比較，我們使用黃金標準 LLM，GPT-4 Omni (GPT-4o) 執行相同的任務，有和沒有 REK 的情況下。結果：NotebookLM 在肺癌分期實驗中實現了 86% 的診斷準確度，優於 GPT-4o，後者在有 REK 的情況下準確度為 39%，沒有 REK 的情況下準確度為 25%。此外，NotebookLM 在 REK 中搜索參考位置的準確度為 95%。結論：NotebookLM 通過利用 REK 成功地進行了肺癌分期，與 GPT-4o 相比表現出優越的性能。此外，它在 REK 中提供了高度準確的參考位置，使放射科醫生能夠有效地評估 NotebookLM 的響應的可靠性並檢測可能的幻覺。總的來說，這項研究突出了 NotebookLM，一種 RAG-LLM，在影像診斷中的潛力。</paragraph>

##### **CodeUnlearn: Amortized Zero-Shot Machine Unlearning in Language Models Using Discrete Concept**
2410.10866v1 by YuXuan Wu, Bonaventure F. P. Dossou, Dianbo Liu

Large Language Models (LLMs) offer extensive knowledge across various
domains, but they may inadvertently memorize sensitive, unauthorized, or
malicious data, such as personal information in the medical and financial
sectors. Machine unlearning methods aim to remove specific information from
models after training to address this. However, current approaches require
additional model training or struggle to effectively erase particular data
points and their associated context due to LLMs' complex, dense, and continuous
nature. In this study, we propose a novel amortized unlearning approach using
codebook features and Sparse Autoencoders (SAEs). By leveraging a bottleneck to
decompose the activation space and regulate information flow, our method
efficiently unlearns targeted information while preserving the model's
performance on unrelated data. To the best of our knowledge, this is the first
work that successfully enables unlearning specific topics with contextual
relevance in an LLM, marking a significant step towards real-world applications
of machine unlearning.

摘要：大型語言模型 (LLM) 可提供跨不同領域的廣泛知識，但它們可能會不經意地記住敏感、未經授權或惡意的資料，例如醫療和金融領域的個人資訊。機器取消學習方法旨在透過在訓練後從模型中移除特定資訊來解決此問題。然而，目前的作法需要額外模型訓練，或因 LLM 複雜、密集且持續的特性而難以有效地清除特定資料點及其關聯脈絡。在本研究中，我們提出一個新穎的攤銷取消學習方法，使用碼本特徵和稀疏自動編碼器 (SAE)。透過利用瓶頸來分解啟用空間和規範資訊流，我們的模型可以有效地取消學習目標資訊，同時保留模型在不相關資料上的效能。據我們所知，這是第一個成功讓 LLM 取消學習特定主題及其脈絡相關性的作品，為機器取消學習的實際應用邁出一大步。

##### **KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server**
2410.05725v2 by Wenhao Wang, Xiaoyu Liang, Rui Ye, Jingyi Chai, Siheng Chen, Yanfeng Wang

The success of large language models (LLMs) facilitate many parties to
fine-tune LLMs on their own private data. However, this practice raises privacy
concerns due to the memorization of LLMs. Existing solutions, such as utilizing
synthetic data for substitution, struggle to simultaneously improve performance
and preserve privacy. They either rely on a local model for generation,
resulting in a performance decline, or take advantage of APIs, directly
exposing the data to API servers. To address this issue, we propose
KnowledgeSG, a novel client-server framework which enhances synthetic data
quality and improves model performance while ensuring privacy. We achieve this
by learning local knowledge from the private data with differential privacy
(DP) and distilling professional knowledge from the server. Additionally,
inspired by federated learning, we transmit models rather than data between the
client and server to prevent privacy leakage. Extensive experiments in medical
and financial domains demonstrate the effectiveness of KnowledgeSG. Our code is
now publicly available at https://github.com/wwh0411/KnowledgeSG.

摘要：大型語言模型 (LLM) 的成功讓許多人可以微調 LLM 以符合他們的私人資料。然而，由於 LLM 的記憶功能，此做法引發了隱私問題。現有的解決方案，例如使用合成資料進行替換，難以同時改善效能並維護隱私。它們依賴於區域模型進行產生，導致效能下降，或利用 API，直接將資料公開給 API 伺服器。為了解決此問題，我們提出 KnowledgeSG，一種新穎的客戶端伺服器架構，它能提升合成資料品質並改善模型效能，同時確保隱私。我們透過使用差分隱私 (DP) 從私人資料中學習區域知識，並從伺服器中萃取專業知識來達成此目標。此外，受到聯邦學習的啟發，我們傳輸模型而非資料在客戶端和伺服器之間，以防止隱私外洩。在醫療和金融領域的廣泛實驗證明了 KnowledgeSG 的有效性。我們的程式碼現在公開於 https://github.com/wwh0411/KnowledgeSG。

##### **Copiloting Diagnosis of Autism in Real Clinical Scenarios via LLMs**
2410.05684v2 by Yi Jiang, Qingyang Shen, Shuzhong Lai, Shunyu Qi, Qian Zheng, Lin Yao, Yueming Wang, Gang Pan

Autism spectrum disorder(ASD) is a pervasive developmental disorder that
significantly impacts the daily functioning and social participation of
individuals. Despite the abundance of research focused on supporting the
clinical diagnosis of ASD, there is still a lack of systematic and
comprehensive exploration in the field of methods based on Large Language
Models (LLMs), particularly regarding the real-world clinical diagnostic
scenarios based on Autism Diagnostic Observation Schedule, Second Edition
(ADOS-2). Therefore, we have proposed a framework called ADOS-Copilot, which
strikes a balance between scoring and explanation and explored the factors that
influence the performance of LLMs in this task. The experimental results
indicate that our proposed framework is competitive with the diagnostic results
of clinicians, with a minimum MAE of 0.4643, binary classification F1-score of
81.79\%, and ternary classification F1-score of 78.37\%. Furthermore, we have
systematically elucidated the strengths and limitations of current LLMs in this
task from the perspectives of ADOS-2, LLMs' capabilities, language, and model
scale aiming to inspire and guide the future application of LLMs in a broader
fields of mental health disorders. We hope for more research to be transferred
into real clinical practice, opening a window of kindness to the world for
eccentric children.

摘要：自閉症譜系障礙 (ASD) 是一種廣泛的發展障礙，會顯著影響個體的日常生活功能和社交參與。儘管有大量的研究專注於支持 ASD 的臨床診斷，但在基於大型語言模型 (LLM) 的方法領域中，仍然缺乏系統且全面的探索，特別是關於基於自閉症診斷觀察量表第二版的真實世界臨床診斷情境 (ADOS-2)。因此，我們提出了一個名為 ADOS-Copilot 的框架，它在評分和解釋之間取得平衡，並探討了影響 LLM 在此任務中表現的因素。實驗結果表明，我們提出的框架與臨床醫生的診斷結果具有競爭力，MAE 最小為 0.4643，二元分類 F1 分數為 81.79%，三元分類 F1 分數為 78.37%。此外，我們從 ADOS-2、LLM 的能力、語言和模型規模的角度系統地闡明了當前 LLM 在此任務中的優勢和局限性，旨在激勵和指導 LLM 在更廣泛的精神疾病領域中的未來應用。我們希望更多的研究能轉化為真正的臨床實踐，為古怪的孩子們打開一扇通往世界的善意之窗。

##### **NegMerge: Consensual Weight Negation for Strong Machine Unlearning**
2410.05583v1 by Hyoseo Kim, Dongyoon Han, Junsuk Choe

Machine unlearning aims to selectively remove specific knowledge from a
model. Current methods, such as task arithmetic, rely on fine-tuning models on
the forget set, generating a task vector, and subtracting it from the original
model. However, we argue the effectiveness of this approach is highly sensitive
to hyperparameter selection, necessitating careful validation to identify the
best model among many fine-tuned candidates. In this paper, we propose a novel
method that leverages all given fine-tuned models rather than selecting a
single one. By constructing task vectors from models trained with varied
hyperparameters and merging only the components of the task vectors with
consistent signs, we perform unlearning by negating the merged task vector from
the original model. Given that existing methods also utilize multiple
fine-tuned models, our approach delivers more effective unlearning without
incurring additional computational costs. We demonstrate the effectiveness of
our method on both vision-language models and standard image classification
models, showing improved unlearning performance with minimal degradation on the
retain set, outperforming state-of-the-art techniques.

摘要：機器去學習旨在選擇性地從模型中移除特定知識。目前的方法，例如任務算術，依賴於在遺忘集上微調模型，生成任務向量，並從原始模型中減去它。然而，我們認為這種方法的有效性對超參數選擇高度敏感，需要仔細驗證以在許多微調候選者中找出最佳模型。在本文中，我們提出了一種新方法，該方法利用所有給定的微調模型，而不是選擇一個。通過使用具有不同超參數訓練的模型構建任務向量，並僅合併具有相同符號的任務向量的組成部分，我們通過從原始模型中否定合併的任務向量來執行去學習。鑑於現有方法也利用多個微調模型，我們的做法在不產生額外計算成本的情況下提供了更有效的去學習。我們在視覺語言模型和標準圖像分類模型上展示了我們方法的有效性，顯示出改進的去學習性能，同時對保留集的下降幅度最小，優於最先進的技術。

##### **AI-Driven Early Mental Health Screening with Limited Data: Analyzing Selfies of Pregnant Women**
2410.05450v1 by Gustavo A. Basílio, Thiago B. Pereira, Alessandro L. Koerich, Ludmila Dias, Maria das Graças da S. Teixeira, Rafael T. Sousa, Wilian H. Hisatugu, Amanda S. Mota, Anilton S. Garcia, Marco Aurélio K. Galletta, Hermano Tavares, Thiago M. Paixão

Major Depressive Disorder and anxiety disorders affect millions globally,
contributing significantly to the burden of mental health issues. Early
screening is crucial for effective intervention, as timely identification of
mental health issues can significantly improve treatment outcomes. Artificial
intelligence (AI) can be valuable for improving the screening of mental
disorders, enabling early intervention and better treatment outcomes. AI-driven
screening can leverage the analysis of multiple data sources, including facial
features in digital images. However, existing methods often rely on controlled
environments or specialized equipment, limiting their broad applicability. This
study explores the potential of AI models for ubiquitous depression-anxiety
screening given face-centric selfies. The investigation focuses on high-risk
pregnant patients, a population that is particularly vulnerable to mental
health issues. To cope with limited training data resulting from our clinical
setup, pre-trained models were utilized in two different approaches:
fine-tuning convolutional neural networks (CNNs) originally designed for facial
expression recognition and employing vision-language models (VLMs) for
zero-shot analysis of facial expressions. Experimental results indicate that
the proposed VLM-based method significantly outperforms CNNs, achieving an
accuracy of 77.6% and an F1-score of 56.0%. Although there is significant room
for improvement, the results suggest that VLMs can be a promising approach for
mental health screening, especially in scenarios with limited data.

摘要：重度憂鬱症和焦慮症影響全球數百萬人，
對心理健康問題的負擔有顯著的影響。早期
篩檢對於有效干預至關重要，因為及時識別
心理健康問題可以顯著改善治療結果。人工
智慧 (AI) 可以為改善心理疾病的篩檢提供有價值的幫助，
實現早期干預和更好的治療結果。AI 驅動的
篩檢可以利用多個數據來源的分析，包括數位影像中的臉部
特徵。然而，現有方法通常依賴受控
環境或專業設備，限制了它們的廣泛適用性。本
研究探討 AI 模型在無所不在的憂鬱症焦慮症
篩檢中，以臉部為中心的自拍的潛力。調查重點關注高風險
孕婦，這是一個特別容易受到心理健康問題影響的人群。為了應對因我們的臨床
設置而產生的有限訓練資料，預先訓練的模型被用於兩種不同的方法：
微調原本設計用於臉部表情辨識的卷積神經網路 (CNN)，並採用視覺語言模型 (VLM) 進行
零次學習的臉部表情分析。實驗結果表明
提出的基於 VLM 的方法顯著優於 CNN，達到 77.6% 的準確率和 56.0% 的 F1 分數。儘管有顯著的改進空間，
結果表明 VLM 可以成為心理健康篩檢的一種有前途的方法，特別是在資料有限的情況下。

##### **Improving Predictor Reliability with Selective Recalibration**
2410.05407v1 by Thomas P. Zollo, Zhun Deng, Jake C. Snell, Toniann Pitassi, Richard Zemel

A reliable deep learning system should be able to accurately express its
confidence with respect to its predictions, a quality known as calibration. One
of the most effective ways to produce reliable confidence estimates with a
pre-trained model is by applying a post-hoc recalibration method. Popular
recalibration methods like temperature scaling are typically fit on a small
amount of data and work in the model's output space, as opposed to the more
expressive feature embedding space, and thus usually have only one or a handful
of parameters. However, the target distribution to which they are applied is
often complex and difficult to fit well with such a function. To this end we
propose \textit{selective recalibration}, where a selection model learns to
reject some user-chosen proportion of the data in order to allow the
recalibrator to focus on regions of the input space that can be well-captured
by such a model. We provide theoretical analysis to motivate our algorithm, and
test our method through comprehensive experiments on difficult medical imaging
and zero-shot classification tasks. Our results show that selective
recalibration consistently leads to significantly lower calibration error than
a wide range of selection and recalibration baselines.

摘要：一個可靠的深度學習系統應該能夠準確地表達其對預測的信心，這項品質稱為校準。使用預先訓練的模型產生可靠的信心估計值最有效的方法之一是應用事後重新校準方法。熱門的重新校準方法（例如溫度縮放）通常適用於少量資料，並在模型的輸出空間中運作，而不是更具表現力的特徵嵌入空間，因此通常只有一個或少數幾個參數。然而，它們所應用的目標分佈通常很複雜，且難以用此類函數做良好的擬合。為此，我們提出「選擇性重新校準」，其中選擇模型會學習拒絕使用者選擇的某些資料比例，以允許重新校準器專注於輸入空間中能被此類模型良好捕捉到的區域。我們提供理論分析來激勵我們的演算法，並透過在困難的醫學影像和零次分類任務中進行全面的實驗來測試我們的模型。我們的結果顯示，選擇性重新校準持續導致校準誤差顯著低於各種選擇和重新校準基線。

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

摘要：解釋人工智慧 (AI) 的決策是現在 AI 的一項重大挑戰，特別是應用於像醫學和法律等敏感情境時。然而，解釋決策背後理由的需求也是基於人類的考量的一個主要問題，因為有必要證明為什麼做出某個決策。例如，住院醫師不僅需要提供（可能是正確的）診斷，還需要解釋他們如何達成某個結論。因此，開發新的工具來幫助住院醫師訓練他們的解釋技巧是教育中 AI 的一項核心目標。在本文中，我們遵循這個方向，並且根據我們的了解，提出第一個多語言醫學問答資料集，其中臨床病例的正確和不正確診斷都附有由醫生撰寫的自然語言解釋。這些解釋已使用論證組成（即前提、主張）和論證關係（即攻擊、支持）進行手動註解，產生多語言 CasiMedicos-Arg 資料集，其中包含 558 個具有解釋的四種語言（英語、西班牙語、法語、義大利語）的臨床病例，我們註解了 5021 個主張、2313 個前提、2431 個支持關係和 1106 個攻擊關係。我們最後展示了競爭基準如何針對論證探勘任務執行此具挑戰性的資料集。

##### **RespLLM: Unifying Audio and Text with Multimodal LLMs for Generalized Respiratory Health Prediction**
2410.05361v1 by Yuwei Zhang, Tong Xia, Aaqib Saeed, Cecilia Mascolo

The high incidence and mortality rates associated with respiratory diseases
underscores the importance of early screening. Machine learning models can
automate clinical consultations and auscultation, offering vital support in
this area. However, the data involved, spanning demographics, medical history,
symptoms, and respiratory audio, are heterogeneous and complex. Existing
approaches are insufficient and lack generalizability, as they typically rely
on limited training data, basic fusion techniques, and task-specific models. In
this paper, we propose RespLLM, a novel multimodal large language model (LLM)
framework that unifies text and audio representations for respiratory health
prediction. RespLLM leverages the extensive prior knowledge of pretrained LLMs
and enables effective audio-text fusion through cross-modal attentions.
Instruction tuning is employed to integrate diverse data from multiple sources,
ensuring generalizability and versatility of the model. Experiments on five
real-world datasets demonstrate that RespLLM outperforms leading baselines by
an average of 4.6% on trained tasks, 7.9% on unseen datasets, and facilitates
zero-shot predictions for new tasks. Our work lays the foundation for
multimodal models that can perceive, listen to, and understand heterogeneous
data, paving the way for scalable respiratory health diagnosis.

摘要：高發生率和死亡率的呼吸道疾病突顯了早期篩檢的重要性。機器學習模型可以自動化臨床諮詢和聽診，在此領域提供重要的支援。然而，所涉及的資料涵蓋人口統計、病史、症狀和呼吸音訊，既異質又複雜。現有的方法不足且缺乏概括性，因為它們通常依賴於有限的訓練資料、基本的融合技術和特定於任務的模型。在本文中，我們提出 RespLLM，這是一個新穎的多模態大型語言模型 (LLM) 框架，它統一了文本和音訊表示，以進行呼吸道健康預測。RespLLM 利用預訓練 LLM 的廣泛先驗知識，並透過跨模態注意力實現有效的音訊文本融合。指示調整用於整合來自多個來源的不同資料，確保模型的概括性和多功能性。在五個真實世界資料集上的實驗表明，RespLLM 在訓練任務上比領先的基準高出平均 4.6%，在未見資料集上高出 7.9%，並促進新任務的零次學習預測。我們的研究為多模態模型奠定了基礎，這些模型可以感知、聆聽和理解異質資料，為可擴充的呼吸道健康診斷鋪平道路。

##### **Synthetic Generation of Dermatoscopic Images with GAN and Closed-Form Factorization**
2410.05114v1 by Rohan Reddy Mekala, Frederik Pahde, Simon Baur, Sneha Chandrashekar, Madeline Diep, Markus Wenzel, Eric L. Wisotzky, Galip Ümit Yolcu, Sebastian Lapuschkin, Jackie Ma, Peter Eisert, Mikael Lindvall, Adam Porter, Wojciech Samek

In the realm of dermatological diagnoses, where the analysis of dermatoscopic
and microscopic skin lesion images is pivotal for the accurate and early
detection of various medical conditions, the costs associated with creating
diverse and high-quality annotated datasets have hampered the accuracy and
generalizability of machine learning models. We propose an innovative
unsupervised augmentation solution that harnesses Generative Adversarial
Network (GAN) based models and associated techniques over their latent space to
generate controlled semiautomatically-discovered semantic variations in
dermatoscopic images. We created synthetic images to incorporate the semantic
variations and augmented the training data with these images. With this
approach, we were able to increase the performance of machine learning models
and set a new benchmark amongst non-ensemble based models in skin lesion
classification on the HAM10000 dataset; and used the observed analytics and
generated models for detailed studies on model explainability, affirming the
effectiveness of our solution.

摘要：在皮膚科診斷領域，皮膚鏡檢查和顯微鏡皮膚病變影像的分析對於準確且早期偵測各種醫療狀況至關重要，但建立多樣化且高品質的標記資料集相關成本已阻礙機器學習模型的準確性和普遍性。我們提出創新的非監督式擴充解決方案，利用生成對抗網路 (GAN) 基礎模型及其在潛在空間上的相關技術，以在皮膚鏡影像中產生受控的半自動發現語義變化。我們建立合成影像以納入語義變化，並使用這些影像擴充訓練資料。透過此方法，我們得以提升機器學習模型的效能，並在 HAM10000 資料集的皮膚病變分類中設定非整體式模型的新基準；並使用觀察到的分析和建立的模型進行模型可解釋性的詳細研究，確認我們解決方案的有效性。

##### **Named Clinical Entity Recognition Benchmark**
2410.05046v1 by Wadood M Abdul, Marco AF Pimentel, Muhammad Umar Salman, Tathagata Raha, Clément Christophe, Praveen K Kanithi, Nasir Hayat, Ronnie Rajan, Shadab Khan

This technical report introduces a Named Clinical Entity Recognition
Benchmark for evaluating language models in healthcare, addressing the crucial
natural language processing (NLP) task of extracting structured information
from clinical narratives to support applications like automated coding,
clinical trial cohort identification, and clinical decision support.
  The leaderboard provides a standardized platform for assessing diverse
language models, including encoder and decoder architectures, on their ability
to identify and classify clinical entities across multiple medical domains. A
curated collection of openly available clinical datasets is utilized,
encompassing entities such as diseases, symptoms, medications, procedures, and
laboratory measurements. Importantly, these entities are standardized according
to the Observational Medical Outcomes Partnership (OMOP) Common Data Model,
ensuring consistency and interoperability across different healthcare systems
and datasets, and a comprehensive evaluation of model performance. Performance
of models is primarily assessed using the F1-score, and it is complemented by
various assessment modes to provide comprehensive insights into model
performance. The report also includes a brief analysis of models evaluated to
date, highlighting observed trends and limitations.
  By establishing this benchmarking framework, the leaderboard aims to promote
transparency, facilitate comparative analyses, and drive innovation in clinical
entity recognition tasks, addressing the need for robust evaluation methods in
healthcare NLP.

摘要：這份技術報告介紹了一個命名臨床實體辨識基準，用於評估醫療保健中的語言模型，解決從臨床敘述中萃取結構化資訊的關鍵自然語言處理 (NLP) 任務，以支援自動編碼、臨床試驗群組識別和臨床決策支援等應用程式。
排行榜提供一個標準化平台，用於評估各種語言模型，包括編碼器和解碼器架構，以及它們跨多個醫療領域識別和分類臨床實體的能力。利用精心整理的公開臨床資料集，涵蓋疾病、症狀、藥物、程序和實驗室測量等實體。重要的是，這些實體根據觀察性醫療結果合作夥伴關係 (OMOP) 常見資料模型標準化，確保不同醫療保健系統和資料集之間的一致性和互通性，以及模型效能的全面評估。模型效能主要使用 F1 分數評估，並輔以各種評估模式，提供對模型效能的全面見解。報告還包括對迄今評估模型的簡要分析，重點說明觀察到的趨勢和限制。
透過建立此基準架構，排行榜旨在促進透明度、促進比較分析，並推動臨床實體辨識任務的創新，滿足醫療保健 NLP 中對健全評估方法的需求。

##### **Learning Interpretable Hierarchical Dynamical Systems Models from Time Series Data**
2410.04814v1 by Manuel Brenner, Elias Weber, Georgia Koppe, Daniel Durstewitz

In science, we are often interested in obtaining a generative model of the
underlying system dynamics from observed time series. While powerful methods
for dynamical systems reconstruction (DSR) exist when data come from a single
domain, how to best integrate data from multiple dynamical regimes and leverage
it for generalization is still an open question. This becomes particularly
important when individual time series are short, and group-level information
may help to fill in for gaps in single-domain data. At the same time, averaging
is not an option in DSR, as it will wipe out crucial dynamical properties
(e.g., limit cycles in one domain vs. chaos in another). Hence, a framework is
needed that enables to efficiently harvest group-level (multi-domain)
information while retaining all single-domain dynamical characteristics. Here
we provide such a hierarchical approach and showcase it on popular DSR
benchmarks, as well as on neuroscientific and medical time series. In addition
to faithful reconstruction of all individual dynamical regimes, our
unsupervised methodology discovers common low-dimensional feature spaces in
which datasets with similar dynamics cluster. The features spanning these
spaces were further dynamically highly interpretable, surprisingly in often
linear relation to control parameters that govern the dynamics of the
underlying system. Finally, we illustrate transfer learning and generalization
to new parameter regimes.

摘要：在科學中，我們常常有興趣從觀察到的時間序列中獲得基礎系統動態的生成模型。雖然當資料來自單一領域時，強大的動態系統重建 (DSR) 方法已經存在，但如何最佳整合來自多個動態機制的資料並利用它進行概括仍然是一個開放的問題。當個別時間序列很短時，這一點尤其重要，而且群組層級的資訊可能有助於填補單一領域資料中的空白。同時，平均化並非 DSR 中的選項，因為它會消除關鍵的動態特性（例如，一個領域中的極限週期相對於另一個領域中的混亂）。因此，需要一個框架，能夠有效收集群組層級（多領域）資訊，同時保留所有單一領域動態特性。在這裡，我們提供這種階層式方法，並在流行的 DSR 基準以及神經科學和醫學時間序列中展示它。除了忠實重建所有個別動態機制之外，我們的非監督方法還發現了常見的低維特徵空間，其中具有相似動態的資料集會成群。跨越這些空間的特徵在動態上進一步具有高度可解釋性，令人驚訝的是，它們通常與控制基礎系統動態的控制參數呈線性關係。最後，我們說明了遷移式學習和對新參數機制的概括。

##### **$\textbf{Only-IF}$:Revealing the Decisive Effect of Instruction Diversity on Generalization**
2410.04717v2 by Dylan Zhang, Justin Wang, Francois Charton

Understanding and accurately following instructions is critical for large
language models (LLMs) to be effective across diverse tasks. In this work, we
rigorously examine the key factors that enable models to generalize to unseen
instructions, providing insights to guide the collection of data for
instruction-tuning. Through controlled experiments, inspired by the
Turing-complete Markov algorithm, we demonstrate that such generalization
$\textbf{only emerges}$ when training data is diversified enough across
semantic domains. Our findings also reveal that merely diversifying within
limited domains fails to ensure robust generalization. In contrast,
cross-domain data diversification, even under constrained data budgets,
significantly enhances a model's adaptability. We further extend our analysis
to real-world scenarios, including fine-tuning of
$\textit{$\textbf{specialist}$}$ and $\textit{$\textbf{generalist}$}$ models.
In both cases, we demonstrate that 1) better performance can be achieved by
increasing the diversity of an established dataset while keeping the data size
constant, and 2) when scaling up the data, diversifying the semantics of
instructions is more effective than simply increasing the quantity of similar
data. Our research provides important insights for dataset collation,
particularly when optimizing model performance by expanding training data for
both specialist and generalist scenarios. We show that careful consideration of
data diversification is key: training specialist models with data extending
beyond their core domain leads to significant performance improvements, while
generalist models benefit from diverse data mixtures that enhance their overall
instruction-following capabilities across a wide range of applications. Our
results highlight the critical role of strategic diversification and offer
clear guidelines for improving data quality.

摘要：理解並準確遵循指示對於大型語言模型 (LLM) 在各種任務中發揮作用至關重要。在這項工作中，我們嚴格審查了使模型能夠概括為未見指示的關鍵因素，並提供見解以指導收集用於指示微調的數據。通過受圖靈完備馬可夫演算法啟發的受控實驗，我們證明了這種概括僅在訓練數據在語義領域中足夠多樣化時才會出現。我們的研究結果還表明，僅在有限的領域內進行多樣化不足以確保穩健的概括。相反，即使在受限的數據預算下，跨領域數據多樣化也會顯著增強模型的適應性。我們進一步將我們的分析擴展到現實世界的場景，包括微調專家和通才模型。在兩種情況下，我們都證明了 1) 可以在保持數據大小不變的情況下通過增加既有數據集的多樣性來實現更好的性能，以及 2) 在擴展數據時，多樣化指示的語義比簡單地增加類似數據的數量更有效。我們的研究為數據集整理提供了重要的見解，特別是在通過擴展專家和通才場景的訓練數據來優化模型性能時。我們表明仔細考慮數據多樣化至關重要：使用超出其核心領域的數據訓練專家模型會導致顯著的性能改進，而通才模型受益於多樣化的數據混合，這些混合增強了它們在廣泛應用中的整體指令遵循能力。我們的結果突出了策略性多樣化的關鍵作用，並為提高數據質量提供了明確的指導方針。

##### **Rule-based Data Selection for Large Language Models**
2410.04715v1 by Xiaomin Li, Mingye Gao, Zhiwei Zhang, Chang Yue, Hong Hu

The quality of training data significantly impacts the performance of large
language models (LLMs). There are increasing studies using LLMs to rate and
select data based on several human-crafted metrics (rules). However, these
conventional rule-based approaches often depend too heavily on human
heuristics, lack effective metrics for assessing rules, and exhibit limited
adaptability to new tasks. In our study, we introduce an innovative rule-based
framework that utilizes the orthogonality of score vectors associated with
rules as a novel metric for rule evaluations. Our approach includes an
automated pipeline that first uses LLMs to generate a diverse set of rules,
encompassing various rating dimensions to evaluate data quality. Then it rates
a batch of data based on these rules and uses the determinantal point process
(DPP) from random matrix theory to select the most orthogonal score vectors,
thereby identifying a set of independent rules. These rules are subsequently
used to evaluate all data, selecting samples with the highest average scores
for downstream tasks such as LLM training. We verify the effectiveness of our
method through two experimental setups: 1) comparisons with ground truth
ratings and 2) benchmarking LLMs trained with the chosen data. Our
comprehensive experiments cover a range of scenarios, including general
pre-training and domain-specific fine-tuning in areas such as IMDB, Medical,
Math, and Code. The outcomes demonstrate that our DPP-based rule rating method
consistently outperforms other approaches, including rule-free rating, uniform
sampling, importance resampling, and QuRating, in terms of both rating
precision and model performance.

摘要：訓練資料的品質會顯著影響大型語言模型 (LLM) 的效能。有愈來愈多研究使用 LLM 來評分並根據多項人為建立的指標 (規則) 選擇資料。然而，這些傳統的基於規則的方法通常過度依賴人類的啟發法，缺乏評估規則的有效指標，且在適應新任務方面展現出有限的靈活性。在我們的研究中，我們引進一個創新的基於規則的架構，它利用與規則相關聯的分數向量的正交性作為規則評估的新指標。我們的做法包括一個自動化流程，該流程首先使用 LLM 產生一組多樣化的規則，涵蓋各種評分面向以評估資料品質。接著，它根據這些規則評分一批資料，並使用隨機矩陣理論中的行列式點過程 (DPP) 來選出最正交的分數向量，從而找出獨立規則的集合。這些規則隨後用於評估所有資料，針對下游任務（例如 LLM 訓練）選出平均分數最高的樣本。我們透過兩個實驗設定驗證我們方法的有效性：1) 與真實評分進行比較，以及 2) 對使用所選資料訓練的 LLM 進行基準測試。我們全面的實驗涵蓋一系列情境，包括在 IMDB、醫學、數學和程式碼等領域的一般預訓練和特定領域的微調。結果顯示，我們的基於 DPP 的規則評分方法在評分精準度和模型效能方面始終優於其他方法，包括無規則評分、均勻抽樣、重要性再抽樣和 QuRating。

##### **Knowledge Graph Based Agent for Complex, Knowledge-Intensive QA in Medicine**
2410.04660v1 by Xiaorui Su, Yibo Wang, Shanghua Gao, Xiaolong Liu, Valentina Giunchiglia, Djork-Arné Clevert, Marinka Zitnik

Biomedical knowledge is uniquely complex and structured, requiring distinct
reasoning strategies compared to other scientific disciplines like physics or
chemistry. Biomedical scientists do not rely on a single approach to reasoning;
instead, they use various strategies, including rule-based, prototype-based,
and case-based reasoning. This diversity calls for flexible approaches that
accommodate multiple reasoning strategies while leveraging in-domain knowledge.
We introduce KGARevion, a knowledge graph (KG) based agent designed to address
the complexity of knowledge-intensive medical queries. Upon receiving a query,
KGARevion generates relevant triplets by using the knowledge base of the LLM.
These triplets are then verified against a grounded KG to filter out erroneous
information and ensure that only accurate, relevant data contribute to the
final answer. Unlike RAG-based models, this multi-step process ensures
robustness in reasoning while adapting to different models of medical
reasoning. Evaluations on four gold-standard medical QA datasets show that
KGARevion improves accuracy by over 5.2%, outperforming 15 models in handling
complex medical questions. To test its capabilities, we curated three new
medical QA datasets with varying levels of semantic complexity, where KGARevion
achieved a 10.4% improvement in accuracy.

摘要：生物医学知識獨特地複雜且結構化，需要與其他科學領域（如物理或化學）不同的推理策略。生物醫學科學家不依賴單一的推理方法；相反，他們使用各種策略，包括基於規則、基於原型和基於案例的推理。這種多樣性需要靈活的方法，同時利用領域知識來適應多種推理策略。我們介紹了 KGARevion，這是一個基於知識圖譜 (KG) 的代理，旨在解決知識密集型醫療查詢的複雜性。在收到查詢後，KGARevion 使用 LLM 的知識庫生成相關的三元組。然後將這些三元組與基礎 KG 進行驗證，以過濾掉錯誤信息並確保只有準確、相關的數據有助於最終答案。與基於 RAG 的模型不同，這種多步驟過程確保了推理的穩健性，同時適應不同的醫療推理模型。對四個黃金標準醫療 QA 數據集的評估表明，KGARevion 將準確率提高了 5.2%，在處理複雜的醫療問題方面優於 15 個模型。為了測試其能力，我們策劃了三個新的醫療 QA 數據集，具有不同的語義複雜性，其中 KGARevion 在準確率上提高了 10.4%。

##### **Comparing Zealous and Restrained AI Recommendations in a Real-World Human-AI Collaboration Task**
2410.11860v1 by Chengyuan Xu, Kuo-Chin Lien, Tobias Höllerer

When designing an AI-assisted decision-making system, there is often a
tradeoff between precision and recall in the AI's recommendations. We argue
that careful exploitation of this tradeoff can harness the complementary
strengths in the human-AI collaboration to significantly improve team
performance. We investigate a real-world video anonymization task for which
recall is paramount and more costly to improve. We analyze the performance of
78 professional annotators working with a) no AI assistance, b) a
high-precision "restrained" AI, and c) a high-recall "zealous" AI in over 3,466
person-hours of annotation work. In comparison, the zealous AI helps human
teammates achieve significantly shorter task completion time and higher recall.
In a follow-up study, we remove AI assistance for everyone and find negative
training effects on annotators trained with the restrained AI. These findings
and our analysis point to important implications for the design of AI
assistance in recall-demanding scenarios.

摘要：在設計 AI 輔助決策系統時，AI 建議中的精準度與召回率之間通常存在取捨。我們主張，小心利用這種取捨可以利用人機協作中的互補優勢，顯著提升團隊績效。我們研究了一項真實世界的影片匿名化任務，召回率至關重要且更難以提升。我們分析了 78 位專業註解員的表現，他們分別使用 a) 沒有 AI 協助、b) 高精準度的「約束」AI，以及 c) 高召回率的「熱心」AI，進行超過 3,466 人小時的註解工作。相較之下，熱心 AI 能幫助人類隊友顯著縮短任務完成時間，並提高召回率。在後續研究中，我們移除所有人的 AI 協助，發現對使用約束 AI 進行訓練的註解員產生負面的訓練效果。這些發現和我們的分析指出，在要求召回率的情境中設計 AI 協助具有重要的意義。

##### **Multi-Tiered Self-Contrastive Learning for Medical Microwave Radiometry (MWR) Breast Cancer Detection**
2410.04636v1 by Christoforos Galazis, Huiyi Wu, Igor Goryanin

The pursuit of enhanced breast cancer detection and monitoring techniques is
a paramount healthcare objective, driving the need for innovative imaging
technologies and diagnostic approaches. This study introduces a novel
multi-tiered self-contrastive model tailored for the application of microwave
radiometry (MWR) breast cancer detection. Our approach encompasses three
distinct models: Local-MWR (L-MWR), Regional-MWR (R-MWR), and Global-MWR
(G-MWR), each engineered to analyze varying sub-regional comparisons within the
breasts. These models are cohesively integrated through the Joint-MWR (J-MWR)
network, which leverages the self-contrastive data generated at each analytical
level to enhance detection capabilities. Employing a dataset comprising 4,932
cases of female patients, our research showcases the effectiveness of our
proposed models. Notably, the J-MWR model distinguishes itself by achieving a
Matthews correlation coefficient of 0.74 $\pm$ 0.018, surpassing existing MWR
neural networks and contrastive methods. These results highlight the
significant potential of self-contrastive learning techniques in improving both
the diagnostic accuracy and generalizability of MWR-based breast cancer
detection processes. Such advancements hold considerable promise for further
investigative and clinical endeavors. The source code is available at:
https://github.com/cgalaz01/self_contrastive_mwr

摘要：追求增強乳癌檢測和監測技術是一項至關重要的醫療保健目標，推動了創新影像技術和診斷方法的需求。本研究介紹了一種新穎的多層自對比模型，專門用於微波輻射測量 (MWR) 乳癌檢測。我們的做法包含三個不同的模型：局部 MWR (L-MWR)、區域 MWR (R-MWR) 和全局 MWR (G-MWR)，每個模型都設計用於分析乳房內不同的次區域比較。這些模型通過聯合 MWR (J-MWR) 網路緊密整合，利用在每個分析層級產生的自對比資料來增強檢測能力。我們的研究採用包含 4,932 例女性患者的資料集，展示了我們提出的模型的有效性。值得注意的是，J-MWR 模型以達到 0.74 ± 0.018 的馬修斯相關係數而區別於其他模型，超越了現有的 MWR 神經網路和對比方法。這些結果突顯了自對比學習技術在改善基於 MWR 的乳癌檢測程序的診斷準確性和概括性方面具有顯著的潛力。這些進展為進一步的調查和臨床工作提供了相當大的希望。原始碼可在以下網址取得：https://github.com/cgalaz01/self_contrastive_mwr

##### **Semi-Markovian Planning to Coordinate Aerial and Maritime Medical Evacuation Platforms**
2410.04523v1 by Mahdi Al-Husseini, Kyle H. Wray, Mykel J. Kochenderfer

The transfer of patients between two aircraft using an underway watercraft
increases medical evacuation reach and flexibility in maritime environments.
The selection of any one of multiple underway watercraft for patient exchange
is complicated by participating aircraft utilization history and a
participating watercraft position and velocity. The selection problem is
modeled as a semi-Markov decision process with an action space including both
fixed land and moving watercraft exchange points. Monte Carlo tree search with
root parallelization is used to select optimal exchange points and determine
aircraft dispatch times. Model parameters are varied in simulation to identify
representative scenarios where watercraft exchange points reduce incident
response times. We find that an optimal policy with watercraft exchange points
outperforms an optimal policy without watercraft exchange points and a greedy
policy by 35% and 40%, respectively. In partnership with the United States
Army, we deploy for the first time the watercraft exchange point by executing a
mock patient transfer with a manikin between two HH-60M medical evacuation
helicopters and an underway Army Logistic Support Vessel south of the Hawaiian
island of Oahu. Both helicopters were dispatched in accordance with our
optimized decision strategy.

摘要：使用航行中的水上交通工具在两架飞机之间转运患者，可增加海上环境中的医疗后送范围和灵活性。
由于参与飞机的使用历史以及参与水上交通工具的位置和速度，选择多个航行中的水上交通工具中的任何一个进行患者交换变得复杂。选择问题被建模为半马尔可夫决策过程，其动作空间包括固定陆地和移动水上交通工具交换点。使用根并行化的蒙特卡罗树搜索来选择最佳交换点并确定飞机调度时间。在仿真中改变模型参数，以识别水上交通工具交换点减少事件响应时间的代表性场景。我们发现，具有水上交通工具交换点的最优策略比没有水上交通工具交换点的最优策略和贪婪策略分别高出 35% 和 40%。与美国陆军合作，我们首次通过在两架 HH-60M 医疗后送直升机和夏威夷欧胡岛南部航行中的陆军后勤支援船之间执行模拟患者转运，部署了水上交通工具交换点。两架直升机均按照我们优化的决策策略进行调度。

##### **Mitigating Hallucinations Using Ensemble of Knowledge Graph and Vector Store in Large Language Models to Enhance Mental Health Support**
2410.10853v1 by Abdul Muqtadir, Hafiz Syed Muhammad Bilal, Ayesha Yousaf, Hafiz Farooq Ahmed, Jamil Hussain

This research work delves into the manifestation of hallucination within
Large Language Models (LLMs) and its consequential impacts on applications
within the domain of mental health. The primary objective is to discern
effective strategies for curtailing hallucinatory occurrences, thereby
bolstering the dependability and security of LLMs in facilitating mental health
interventions such as therapy, counseling, and the dissemination of pertinent
information. Through rigorous investigation and analysis, this study seeks to
elucidate the underlying mechanisms precipitating hallucinations in LLMs and
subsequently propose targeted interventions to alleviate their occurrence. By
addressing this critical issue, the research endeavors to foster a more robust
framework for the utilization of LLMs within mental health contexts, ensuring
their efficacy and reliability in aiding therapeutic processes and delivering
accurate information to individuals seeking mental health support.

摘要：本研究探討大型語言模型 (LLM) 中幻覺的表現，及其對心理健康領域應用產生的後續影響。主要目標是辨別遏制幻覺發生的有效策略，從而加強 LLM 在促進心理健康干預措施（例如治療、諮詢和傳播相關資訊）方面的可靠性和安全性。透過嚴謹的調查和分析，本研究試圖闡明導致 LLM 產生幻覺的潛在機制，並進一步提出有針對性的干預措施來減輕其發生。透過解決這個關鍵問題，本研究致力於建立一個更穩健的架構，以便在心理健康情境中使用 LLM，確保其在協助治療過程和向尋求心理健康支持的個人提供準確資訊方面的效能和可靠性。

##### **On the Reliability of Large Language Models to Misinformed and Demographically-Informed Prompts**
2410.10850v2 by Toluwani Aremu, Oluwakemi Akinwehinmi, Chukwuemeka Nwagu, Syed Ishtiaque Ahmed, Rita Orji, Pedro Arnau Del Amo, Abdulmotaleb El Saddik

We investigate and observe the behaviour and performance of Large Language
Model (LLM)-backed chatbots in addressing misinformed prompts and questions
with demographic information within the domains of Climate Change and Mental
Health. Through a combination of quantitative and qualitative methods, we
assess the chatbots' ability to discern the veracity of statements, their
adherence to facts, and the presence of bias or misinformation in their
responses. Our quantitative analysis using True/False questions reveals that
these chatbots can be relied on to give the right answers to these close-ended
questions. However, the qualitative insights, gathered from domain experts,
shows that there are still concerns regarding privacy, ethical implications,
and the necessity for chatbots to direct users to professional services. We
conclude that while these chatbots hold significant promise, their deployment
in sensitive areas necessitates careful consideration, ethical oversight, and
rigorous refinement to ensure they serve as a beneficial augmentation to human
expertise rather than an autonomous solution.

摘要：我們調查並觀察大型語言模型 (LLM) 支持的聊天機器人在氣候變遷和心理健康領域中處理錯誤訊息提示和問題的行為和表現。透過結合量化和質性方法，我們評估聊天機器人辨別陳述真實性的能力、他們對事實的堅持，以及他們回應中偏見或錯誤訊息的存在。我們使用真/假問題的量化分析顯示，可以依賴這些聊天機器人對這些封閉式問題給出正確答案。然而，從領域專家收集的質性見解顯示，對於隱私、倫理影響以及聊天機器人將使用者導向專業服務的必要性仍有疑慮。我們得出結論，儘管這些聊天機器人極具前景，但在敏感領域部署它們需要仔細考量、道德監督和嚴格改進，以確保它們作為人類專業知識的有益擴充，而不是自主解決方案。

##### **RespDiff: An End-to-End Multi-scale RNN Diffusion Model for Respiratory Waveform Estimation from PPG Signals**
2410.04366v1 by Yuyang Miao, Zehua Chen, Chang Li, Danilo Mandic

Respiratory rate (RR) is a critical health indicator often monitored under
inconvenient scenarios, limiting its practicality for continuous monitoring.
Photoplethysmography (PPG) sensors, increasingly integrated into wearable
devices, offer a chance to continuously estimate RR in a portable manner. In
this paper, we propose RespDiff, an end-to-end multi-scale RNN diffusion model
for respiratory waveform estimation from PPG signals. RespDiff does not require
hand-crafted features or the exclusion of low-quality signal segments, making
it suitable for real-world scenarios. The model employs multi-scale encoders,
to extract features at different resolutions, and a bidirectional RNN to
process PPG signals and extract respiratory waveform. Additionally, a spectral
loss term is introduced to optimize the model further. Experiments conducted on
the BIDMC dataset demonstrate that RespDiff outperforms notable previous works,
achieving a mean absolute error (MAE) of 1.18 bpm for RR estimation while
others range from 1.66 to 2.15 bpm, showing its potential for robust and
accurate respiratory monitoring in real-world applications.

摘要：呼吸速率 (RR) 是一項重要的健康指標，通常在不方便的情況下進行監測，這限制了其在持續監測中的實用性。光電容積描記法 (PPG) 感測器日益整合到可穿戴裝置中，提供了一種以可攜式方式持續估計 RR 的機會。在本文中，我們提出了 RespDiff，這是一個端到端的多分辨率 RNN 擴散模型，用於從 PPG 訊號中估計呼吸波形。RespDiff 不需要人工特徵或排除低品質訊號片段，使其適用於實際場景。該模型採用多分辨率編碼器，以不同解析度提取特徵，並採用雙向 RNN 來處理 PPG 訊號和提取呼吸波形。此外，還引入了頻譜損失項以進一步最佳化模型。在 BIDMC 資料集上進行的實驗表明，RespDiff 優於之前的顯著研究，在 RR 估計中實現了 1.18 bpm 的平均絕對誤差 (MAE)，而其他誤差範圍從 1.66 到 2.15 bpm，顯示了其在實際應用中進行穩健且準確的呼吸監測的潛力。

##### **Applying Quantum Autoencoders for Time Series Anomaly Detection**
2410.04154v2 by Robin Frehner, Kurt Stockinger

Anomaly detection is an important problem with applications in various
domains such as fraud detection, pattern recognition or medical diagnosis.
Several algorithms have been introduced using classical computing approaches.
However, using quantum computing for solving anomaly detection problems in time
series data is a widely unexplored research field.
  This paper explores the application of quantum autoencoders to time series
anomaly detection. We investigate two primary techniques for classifying
anomalies: (1) Analyzing the reconstruction error generated by the quantum
autoencoder and (2) latent representation analysis. Our simulated experimental
results, conducted across various ansaetze, demonstrate that quantum
autoencoders consistently outperform classical deep learning-based autoencoders
across multiple datasets. Specifically, quantum autoencoders achieve superior
anomaly detection performance while utilizing 60-230 times fewer parameters and
requiring five times fewer training iterations. In addition, we implement our
quantum encoder on real quantum hardware. Our experimental results demonstrate
that quantum autoencoders achieve anomaly detection performance on par with
their simulated counterparts.

摘要：異常偵測是一個重要的問題，在各個領域都有應用，例如詐欺偵測、模式辨識或醫療診斷。
已經有使用傳統運算方法提出的多種演算法。
然而，使用量子運算來解決時間序列資料中的異常偵測問題是一個廣泛未開發的研究領域。
本文探討量子自動編碼器在時間序列異常偵測的應用。我們研究了兩種分類異常的主要技術：(1) 分析量子自動編碼器產生的重建誤差，以及 (2) 潛在表示分析。我們在各種 ansaetze 下進行模擬實驗，結果表明，量子自動編碼器在多個資料集上始終優於基於經典深度學習的自動編碼器。具體來說，量子自動編碼器在使用少 60-230 倍的參數和需要少五倍的訓練反覆運算的情況下，實現了卓越的異常偵測效能。此外，我們在真實量子硬體上實現了我們的量子編碼器。我們的實驗結果表明，量子自動編碼器實現了與其模擬對應物相當的異常偵測效能。

##### **DAMMI:Daily Activities in a Psychologically Annotated Multi-Modal IoT dataset**
2410.04152v1 by Mohsen Falah Rad, Kamrad Khoshhal Roudposhti, Mohammad Hassan Khoobkar, Mohsen Shirali, Zahra Ahmadi, Carlos Fernandez-Llatas

The growth in the elderly population and the shift in the age pyramid have
increased the demand for healthcare and well-being services. To address this
concern, alongside the rising cost of medical care, the concept of ageing at
home has emerged, driven by recent advances in medical and technological
solutions. Experts in computer science, communication technology, and
healthcare have collaborated to develop affordable health solutions by
employing sensors in living environments, wearable devices, and smartphones, in
association with advanced data mining and intelligent systems with learning
capabilities, to monitor, analyze, and predict the health status of elderly
individuals. However, implementing intelligent healthcare systems and
developing analytical techniques requires testing and evaluating algorithms on
real-world data. Despite the need, there is a shortage of publicly available
datasets that meet these requirements. To address this gap, we present the
DAMMI dataset in this work, designed to support researchers in the field. The
dataset includes daily activity data of an elderly individual collected via
home-installed sensors, smartphone data, and a wristband over 146 days. It also
contains daily psychological reports provided by a team of psychologists.
Furthermore, the data collection spans significant events such as the COVID-19
pandemic, New Year's holidays, and the religious month of Ramadan, offering
additional opportunities for analysis. In this paper, we outline detailed
information about the data collection system, the types of data recorded, and
pre-processed event logs. This dataset is intended to assist professionals in
IoT and data mining in evaluating and implementing their research ideas.

摘要：隨著老年人口的增長和年齡金字塔的轉變，對醫療保健和福祉服務的需求也隨之增加。為了解決這個問題，加上醫療保健成本的上升，在家中老化的概念應運而生，這得益於醫療和技術解決方案的最新進展。電腦科學、通訊技術和醫療保健方面的專家合作開發了經濟實惠的健康解決方案，方法是在生活環境中使用感測器、穿戴式裝置和智慧型手機，並結合先進的資料探勘和具備學習能力的智慧系統，來監控、分析和預測老年人的健康狀況。然而，實施智慧型醫療保健系統和開發分析技術需要在真實世界資料上測試和評估演算法。儘管有這個需求，但符合這些要求的公開可用資料集卻很缺乏。為了解決這個差距，我們在這項工作中提出了 DAMMI 資料集，旨在支援該領域的研究人員。該資料集包括透過安裝在家的感測器、智慧型手機資料和一個手環在 146 天內收集到的老年人日常活動資料。它還包含由心理學家團隊提供的每日心理報告。此外，資料收集涵蓋了重要的事件，例如 COVID-19 大流行、新年假期和齋戒月，為分析提供了額外的機會。在本文中，我們概述了有關資料收集系統、記錄的資料類型和預處理事件記錄的詳細資訊。此資料集旨在協助物聯網和資料探勘方面的專業人員評估和實施其研究構想。

##### **From Hospital to Portables: A Universal ECG Foundation Model Built on 10+ Million Diverse Recordings**
2410.04133v1 by Jun Li, Aaron Aguirre, Junior Moura, Che Liu, Lanhai Zhong, Chenxi Sun, Gari Clifford, Brandon Westover, Shenda Hong

Artificial Intelligence (AI) has shown great promise in electrocardiogram
(ECG) analysis and cardiovascular disease detection. However, developing a
general AI-ECG model has been challenging due to inter-individual variability
and the diversity of ECG diagnoses, limiting existing models to specific
diagnostic tasks and datasets. Moreover, current AI-ECG models struggle to
achieve comparable performance between single-lead and 12-lead ECGs, limiting
the application of AI-ECG to portable and wearable ECG devices. To address
these limitations, we introduce an ECG Foundation Model (ECGFounder), a
general-purpose model that leverages real-world ECG annotations from cardiology
experts to broaden the diagnostic capabilities of ECG analysis. ECGFounder is
trained on over 10 million ECGs with 150 label categories from the
Harvard-Emory ECG Database, enabling comprehensive cardiovascular disease
diagnosis through ECG analysis. The model is designed to be both effective
out-of-the-box and fine-tunable for downstream tasks, maximizing usability.
More importantly, we extend its application to single-lead ECGs, enabling
complex condition diagnoses and supporting various downstream tasks in mobile
and remote monitoring scenarios. Experimental results demonstrate that
ECGFounder achieves expert-level performance on internal validation sets for
both 12-lead and single-lead ECGs, while also exhibiting strong classification
performance and generalization across various diagnoses on external validation
sets. When fine-tuned, ECGFounder outperforms baseline models in demographics
detection, clinical event detection, and cross-modality cardiac rhythm
diagnosis. The trained model and data will be publicly released upon
publication through the bdsp.io. Our code is available at
https://github.com/bdsp-core/ECGFounder.

摘要：人工智慧（AI）在心電圖（ECG）分析和心血管疾病檢測方面已展現極佳的前景。然而，由於個體間變異性和 ECG 診斷的多樣性，開發通用 AI-ECG 模型一直是一項挑戰，這限制了現有模型只能用於特定的診斷任務和資料集。此外，目前的 AI-ECG 模型難以在單導程和 12 導程 ECG 之間取得相當的效能，這限制了 AI-ECG 應用於可攜式和可穿戴 ECG 裝置。為了克服這些限制，我們引進了一種 ECG 基礎模型（ECGFounder），這是一種通用模型，它利用來自心臟病專家的真實世界 ECG 標註，以擴展 ECG 分析的診斷能力。ECGFounder 經由哈佛-艾默里 ECG 資料庫中超過 1 千萬個 ECG 和 150 個標籤類別進行訓練，能透過 ECG 分析進行全面的心血管疾病診斷。該模型被設計為開箱即用且可微調以進行下游任務，以最大化可用性。更重要的是，我們將其應用延伸至單導程 ECG，能進行複雜狀況診斷，並支援行動和遠端監控情境中的各種下游任務。實驗結果顯示，ECGFounder 在 12 導程和單導程 ECG 的內部驗證集中達到了專家級的效能，同時在外部驗證集中對各種診斷也展現出強大的分類效能和泛化能力。經過微調後，ECGFounder 在人口統計資料檢測、臨床事件檢測和跨模態心律診斷方面優於基準模型。訓練好的模型和資料將在出版後透過 bdsp.io 公開發布。我們的程式碼可在 https://github.com/bdsp-core/ECGFounder 取得。

##### **Taming the Tail: Leveraging Asymmetric Loss and Pade Approximation to Overcome Medical Image Long-Tailed Class Imbalance**
2410.04084v1 by Pankhi Kashyap, Pavni Tandon, Sunny Gupta, Abhishek Tiwari, Ritwik Kulkarni, Kshitij Sharad Jadhav

Long-tailed problems in healthcare emerge from data imbalance due to
variability in the prevalence and representation of different medical
conditions, warranting the requirement of precise and dependable classification
methods. Traditional loss functions such as cross-entropy and binary
cross-entropy are often inadequate due to their inability to address the
imbalances between the classes with high representation and the classes with
low representation found in medical image datasets. We introduce a novel
polynomial loss function based on Pade approximation, designed specifically to
overcome the challenges associated with long-tailed classification. This
approach incorporates asymmetric sampling techniques to better classify
under-represented classes. We conducted extensive evaluations on three publicly
available medical datasets and a proprietary medical dataset. Our
implementation of the proposed loss function is open-sourced in the public
repository:https://github.com/ipankhi/ALPA.

摘要：醫療保健中的長尾問題源於數據不平衡，這是由於不同醫療狀況的流行率和表現存在變異性，這保證了對精確且可靠的分類方法的需求。傳統損失函數（例如交叉熵和二元交叉熵）通常不足，因為它們無法解決醫療影像資料集中表示率高的類別與表示率低的類別之間的不平衡。我們引入了一種基於 Pade 近似的多項式損失函數，專門設計用於克服與長尾分類相關的挑戰。此方法結合了非對稱抽樣技術，以更好地對代表性不足的類別進行分類。我們對三個公開的醫療資料集和一個專有醫療資料集進行了廣泛的評估。我們對提議損失函數的實作已在公共儲存庫中開源：https://github.com/ipankhi/ALPA。

##### **Leveraging Social Determinants of Health in Alzheimer's Research Using LLM-Augmented Literature Mining and Knowledge Graphs**
2410.09080v1 by Tianqi Shang, Shu Yang, Weiqing He, Tianhua Zhai, Dawei Li, Bojian Hou, Tianlong Chen, Jason H. Moore, Marylyn D. Ritchie, Li Shen

Growing evidence suggests that social determinants of health (SDoH), a set of
nonmedical factors, affect individuals' risks of developing Alzheimer's disease
(AD) and related dementias. Nevertheless, the etiological mechanisms underlying
such relationships remain largely unclear, mainly due to difficulties in
collecting relevant information. This study presents a novel, automated
framework that leverages recent advancements of large language model (LLM) and
natural language processing techniques to mine SDoH knowledge from extensive
literature and integrate it with AD-related biological entities extracted from
the general-purpose knowledge graph PrimeKG. Utilizing graph neural networks,
we performed link prediction tasks to evaluate the resultant SDoH-augmented
knowledge graph. Our framework shows promise for enhancing knowledge discovery
in AD and can be generalized to other SDoH-related research areas, offering a
new tool for exploring the impact of social determinants on health outcomes.
Our code is available at: https://github.com/hwq0726/SDoHenPKG

摘要：越來越多的證據表明，社會健康決定因素 (SDoH) 是一組非醫療因素，會影響個人罹患阿茲海默症 (AD) 和相關失智症的風險。然而，這種關係背後的基本機制在很大程度上仍不清楚，主要是因為難以收集相關資訊。本研究提出一個新穎的自動化架構，利用大型語言模型 (LLM) 和自然語言處理技術的最新進展，從廣泛的文獻中挖掘 SDoH 知識，並將其與從通用知識圖 PrimeKG 中提取的 AD 相關生物實體整合在一起。利用圖神經網路，我們執行連結預測任務，以評估生成的 SDoH 擴充知識圖。我們的架構顯示出增強 AD 中知識發現的希望，並且可以推廣到其他與 SDoH 相關的研究領域，提供一個探索社會決定因素對健康結果影響的新工具。我們的程式碼可在 https://github.com/hwq0726/SDoHenPKG 取得

##### **Still Not Quite There! Evaluating Large Language Models for Comorbid Mental Health Diagnosis**
2410.03908v1 by Amey Hengle, Atharva Kulkarni, Shantanu Patankar, Madhumitha Chandrasekaran, Sneha D'Silva, Jemima Jacob, Rashmi Gupta

In this study, we introduce ANGST, a novel, first-of-its kind benchmark for
depression-anxiety comorbidity classification from social media posts. Unlike
contemporary datasets that often oversimplify the intricate interplay between
different mental health disorders by treating them as isolated conditions,
ANGST enables multi-label classification, allowing each post to be
simultaneously identified as indicating depression and/or anxiety. Comprising
2876 meticulously annotated posts by expert psychologists and an additional
7667 silver-labeled posts, ANGST posits a more representative sample of online
mental health discourse. Moreover, we benchmark ANGST using various
state-of-the-art language models, ranging from Mental-BERT to GPT-4. Our
results provide significant insights into the capabilities and limitations of
these models in complex diagnostic scenarios. While GPT-4 generally outperforms
other models, none achieve an F1 score exceeding 72% in multi-class comorbid
classification, underscoring the ongoing challenges in applying language models
to mental health diagnostics.

摘要：在這項研究中，我們介紹 ANGST，這是一個新穎的、同類首創的基準，用於從社群媒體貼文中分類憂鬱症和焦慮症共病。與當代的資料集不同，當代的資料集通常會過度簡化不同心理健康障礙之間的複雜交互作用，將它們視為孤立的狀況，而 ANGST 能夠進行多標籤分類，讓每則貼文都能同時被辨識為表示憂鬱症和/或焦慮症。ANGST 包含了 2876 則由專家心理學家仔細註解的貼文，以及另外 7667 則標記為銀級的貼文，它提出了更具代表性的線上心理健康論述範例。此外，我們使用從 Mental-BERT 到 GPT-4 等各種最先進的語言模型對 ANGST 進行基準測試。我們的結果提供了重要的見解，說明了這些模型在複雜的診斷情境中的能力和限制。雖然 GPT-4 通常優於其他模型，但沒有任何模型在多類共病分類中達到超過 72% 的 F1 分數，這凸顯了將語言模型應用於心理健康診斷的持續挑戰。

##### **Not All Diffusion Model Activations Have Been Evaluated as Discriminative Features**
2410.03558v2 by Benyuan Meng, Qianqian Xu, Zitai Wang, Xiaochun Cao, Qingming Huang

Diffusion models are initially designed for image generation. Recent research
shows that the internal signals within their backbones, named activations, can
also serve as dense features for various discriminative tasks such as semantic
segmentation. Given numerous activations, selecting a small yet effective
subset poses a fundamental problem. To this end, the early study of this field
performs a large-scale quantitative comparison of the discriminative ability of
the activations. However, we find that many potential activations have not been
evaluated, such as the queries and keys used to compute attention scores.
Moreover, recent advancements in diffusion architectures bring many new
activations, such as those within embedded ViT modules. Both combined,
activation selection remains unresolved but overlooked. To tackle this issue,
this paper takes a further step with a much broader range of activations
evaluated. Considering the significant increase in activations, a full-scale
quantitative comparison is no longer operational. Instead, we seek to
understand the properties of these activations, such that the activations that
are clearly inferior can be filtered out in advance via simple qualitative
evaluation. After careful analysis, we discover three properties universal
among diffusion models, enabling this study to go beyond specific models. On
top of this, we present effective feature selection solutions for several
popular diffusion models. Finally, the experiments across multiple
discriminative tasks validate the superiority of our method over the SOTA
competitors. Our code is available at
https://github.com/Darkbblue/generic-diffusion-feature.

摘要：擴散模型最初是為影像生成而設計。最近的研究顯示，其主幹中的內部訊號（稱為激活）也可以作為各種判別任務（例如語意分割）的稠密特徵。在給定大量激活的情況下，選擇一個小但有效的子集是一個基本問題。為此，此領域的早期研究對激活的判別能力進行了大規模的定量比較。然而，我們發現許多潛在的激活尚未經過評估，例如用於計算注意力分數的查詢和鍵。此外，擴散架構的最新進展帶來了許多新的激活，例如嵌入式 ViT 模組中的那些。兩者結合，激活選擇仍然未解決，但被忽視了。為了解決這個問題，本文採用更廣泛的激活評估範圍，進一步邁出了一步。考慮到激活的顯著增加，全面定量比較不再可行。相反，我們尋求了解這些激活的特性，以便可以透過簡單的定性評估事先篩選出明顯較差的激活。經過仔細分析，我們發現擴散模型中普遍存在三個特性，使本研究能夠超越特定模型。除此之外，我們針對幾種流行的擴散模型提出了有效的特徵選擇解決方案。最後，跨多個判別任務的實驗驗證了我們的方法優於 SOTA 競爭對手。我們的程式碼可在 https://github.com/Darkbblue/generic-diffusion-feature 取得。

##### **Towards Real-time Intrahepatic Vessel Identification in Intraoperative Ultrasound-Guided Liver Surgery**
2410.03420v2 by Karl-Philippe Beaudet, Alexandros Karargyris, Sidaty El Hadramy, Stéphane Cotin, Jean-Paul Mazellier, Nicolas Padoy, Juan Verde

While laparoscopic liver resection is less prone to complications and
maintains patient outcomes compared to traditional open surgery, its complexity
hinders widespread adoption due to challenges in representing the liver's
internal structure. Laparoscopic intraoperative ultrasound offers efficient,
cost-effective and radiation-free guidance. Our objective is to aid physicians
in identifying internal liver structures using laparoscopic intraoperative
ultrasound. We propose a patient-specific approach using preoperative 3D
ultrasound liver volume to train a deep learning model for real-time
identification of portal tree and branch structures. Our personalized AI model,
validated on ex vivo swine livers, achieved superior precision (0.95) and
recall (0.93) compared to surgeons, laying groundwork for precise vessel
identification in ultrasound-based liver resection. Its adaptability and
potential clinical impact promise to advance surgical interventions and improve
patient care.

摘要：腹腔鏡肝切除術與傳統開放式手術相比，較不易產生併發症，且能維持患者的治療結果，但其複雜性阻礙了廣泛採用，原因在於難以呈現肝臟的內部結構。腹腔鏡術中超音波提供有效、經濟且無輻射的導引。我們的目標是協助醫師使用腹腔鏡術中超音波來辨識肝臟的內部結構。我們提出一個使用術前 3D 超音波肝臟體積來訓練深度學習模型，以即時辨識門脈樹和分支結構的患者特定方法。我們的個人化人工智慧模型在離體豬肝臟上驗證，與外科醫師相比，達到了更高的精確度 (0.95) 和召回率 (0.93)，為基於超音波的肝臟切除術中精確血管辨識奠定了基礎。其適應性和潛在的臨床影響有望推進外科手術，並改善患者照護。

##### **Make Interval Bound Propagation great again**
2410.03373v1 by Patryk Krukowski, Daniel Wilczak, Jacek Tabor, Anna Bielawska, Przemysław Spurek

In various scenarios motivated by real life, such as medical data analysis,
autonomous driving, and adversarial training, we are interested in robust deep
networks. A network is robust when a relatively small perturbation of the input
cannot lead to drastic changes in output (like change of class, etc.). This
falls under the broader scope field of Neural Network Certification (NNC). Two
crucial problems in NNC are of profound interest to the scientific community:
how to calculate the robustness of a given pre-trained network and how to
construct robust networks. The common approach to constructing robust networks
is Interval Bound Propagation (IBP). This paper demonstrates that IBP is
sub-optimal in the first case due to its susceptibility to the wrapping effect.
Even for linear activation, IBP gives strongly sub-optimal bounds.
Consequently, one should use strategies immune to the wrapping effect to obtain
bounds close to optimal ones. We adapt two classical approaches dedicated to
strict computations -- Dubleton Arithmetic and Affine Arithmetic -- to mitigate
the wrapping effect in neural networks. These techniques yield precise results
for networks with linear activation functions, thus resisting the wrapping
effect. As a result, we achieve bounds significantly closer to the optimal
level than IBPs.

摘要：在各種受現實生活激勵的場景中，例如醫學數據分析、自動駕駛和對抗性訓練，我們對強健的深度網路感興趣。當輸入的微小擾動不會導致輸出發生劇烈變化（例如類別改變等）時，網路就是強健的。這屬於神經網路認證 (NNC) 的廣泛範疇。NNC 中的兩個關鍵問題引起了科學界的濃厚興趣：如何計算給定預訓練網路的強健性，以及如何構建強健網路。構建強健網路的常見方法是區間邊界傳播 (IBP)。本文證明，由於 IBP 容易受到包覆效應的影響，因此在第一種情況下它是次優的。即使對於線性激活，IBP 也會給出強烈的次優邊界。因此，應使用對包覆效應免疫的策略來獲得接近最優邊界的邊界。我們調整了專門用於嚴格計算的兩種經典方法——雙元運算和仿射運算——以減輕神經網路中的包覆效應。這些技術對具有線性激活函數的網路產生精確的結果，從而抵抗包覆效應。因此，我們實現的邊界顯著接近於 IBP 的最優級別。

##### **An Enhanced Harmonic Densely Connected Hybrid Transformer Network Architecture for Chronic Wound Segmentation Utilising Multi-Colour Space Tensor Merging**
2410.03359v1 by Bill Cassidy, Christian Mcbride, Connah Kendrick, Neil D. Reeves, Joseph M. Pappachan, Cornelius J. Fernandez, Elias Chacko, Raphael Brüngel, Christoph M. Friedrich, Metib Alotaibi, Abdullah Abdulaziz AlWabel, Mohammad Alderwish, Kuan-Ying Lai, Moi Hoon Yap

Chronic wounds and associated complications present ever growing burdens for
clinics and hospitals world wide. Venous, arterial, diabetic, and pressure
wounds are becoming increasingly common globally. These conditions can result
in highly debilitating repercussions for those affected, with limb amputations
and increased mortality risk resulting from infection becoming more common. New
methods to assist clinicians in chronic wound care are therefore vital to
maintain high quality care standards. This paper presents an improved HarDNet
segmentation architecture which integrates a contrast-eliminating component in
the initial layers of the network to enhance feature learning. We also utilise
a multi-colour space tensor merging process and adjust the harmonic shape of
the convolution blocks to facilitate these additional features. We train our
proposed model using wound images from light-skinned patients and test the
model on two test sets (one set with ground truth, and one without) comprising
only darker-skinned cases. Subjective ratings are obtained from clinical wound
experts with intraclass correlation coefficient used to determine inter-rater
reliability. For the dark-skin tone test set with ground truth, we demonstrate
improvements in terms of Dice similarity coefficient (+0.1221) and intersection
over union (+0.1274). Qualitative analysis showed high expert ratings, with
improvements of >3% demonstrated when comparing the baseline model with the
proposed model. This paper presents the first study to focus on darker-skin
tones for chronic wound segmentation using models trained only on wound images
exhibiting lighter skin. Diabetes is highly prevalent in countries where
patients have darker skin tones, highlighting the need for a greater focus on
such cases. Additionally, we conduct the largest qualitative study to date for
chronic wound segmentation.

摘要：<paragraph>慢性傷口及其併發症對全球診所和醫院而言，帶來日益沉重的負擔。靜脈性、動脈性、糖尿病性和壓瘡在全球愈來愈普遍。這些疾病會對患者造成高度衰弱的影響，截肢和因感染而導致的死亡風險也日益普遍。因此，新的方法協助臨床醫生進行慢性傷口照護至關重要，以維持高品質的照護標準。本文提出一個改良的 HarDNet 分割架構，將對比消除元件整合到網路的初始層，以增強特徵學習。我們也利用多色彩空間張量合併程序，並調整卷積區塊的諧波形狀，以利於這些額外特徵。我們使用淺膚色患者的傷口影像訓練我們提出的模型，並在兩個測試組（一個組有基本事實，一個組沒有）上測試模型，這些組僅包含較深膚色的病例。從臨床傷口專家取得主觀評分，並使用類內相關係數來確定評分者間信賴度。對於有基本事實的深膚色測試組，我們展示了骰子相似係數 (+0.1221) 和聯集比交集 (+0.1274) 的改進。定性分析顯示專家評分很高，與基準模型相比，提出的模型顯示出 >3% 的改進。本文提出第一個研究，專注於使用僅在表現出較淺膚色的傷口影像上訓練的模型，進行深膚色慢性傷口分割。糖尿病在患者膚色較深的國家非常普遍，強調需要更多關注此類病例。此外，我們進行了迄今為止最大的慢性傷口分割定性研究。</paragraph>

##### **Comparative Analysis and Ensemble Enhancement of Leading CNN Architectures for Breast Cancer Classification**
2410.03333v1 by Gary Murphy, Raghubir Singh

This study introduces a novel and accurate approach to breast cancer
classification using histopathology images. It systematically compares leading
Convolutional Neural Network (CNN) models across varying image datasets,
identifies their optimal hyperparameters, and ranks them based on
classification efficacy. To maximize classification accuracy for each model we
explore, the effects of data augmentation, alternative fully-connected layers,
model training hyperparameter settings, and, the advantages of retraining
models versus using pre-trained weights. Our methodology includes several
original concepts, including serializing generated datasets to ensure
consistent data conditions across training runs and significantly reducing
training duration. Combined with automated curation of results, this enabled
the exploration of over 2,000 training permutations -- such a comprehensive
comparison is as yet unprecedented. Our findings establish the settings
required to achieve exceptional classification accuracy for standalone CNN
models and rank them by model efficacy. Based on these results, we propose
ensemble architectures that stack three high-performing standalone CNN models
together with diverse classifiers, resulting in improved classification
accuracy. The ability to systematically run so many model permutations to get
the best outcomes gives rise to very high quality results, including 99.75% for
BreakHis x40 and BreakHis x200 and 95.18% for the Bach datasets when split into
train, validation and test datasets. The Bach Online blind challenge, yielded
89% using this approach. Whilst this study is based on breast cancer
histopathology image datasets, the methodology is equally applicable to other
medical image datasets.

摘要：本研究引入了一種新穎且準確的方法，使用組織病理學影像來對乳癌進行分類。它系統性地比較了在不同影像資料集中的領先卷積神經網路 (CNN) 模型，找出它們最佳的超參數，並根據分類效能對它們進行排名。為了最大化我們探索的每個模型的分類準確度，我們探討了資料擴充、替代全連接層、模型訓練超參數設定，以及重新訓練模型與使用預訓練權重的優點。我們的做法包含了幾個原始概念，包括序列化產生的資料集，以確保在訓練過程中資料條件一致，並大幅縮短訓練時間。結合自動化結果整理，這使得我們能夠探索超過 2,000 個訓練排列組合——如此全面的比較在目前為止是前所未有的。我們的發現建立了達成傑出分類準確度所需的設定，並根據模型效能對獨立的 CNN 模型進行排名。根據這些結果，我們提出了將三個高性能獨立 CNN 模型與不同的分類器堆疊在一起的整體架構，進而提升了分類準確度。系統性地執行這麼多模型排列組合以獲得最佳結果的能力，產生了非常高品質的結果，包括將 BreakHis x40 和 BreakHis x200 分割成訓練、驗證和測試資料集時，準確度達到 99.75%，而 Bach 資料集的準確度達到 95.18%。使用這種方法，Bach Online 盲測的準確度達到 89%。雖然本研究是基於乳癌組織病理學影像資料集，但此方法同樣適用於其他醫學影像資料集。

##### **Manikin-Recorded Cardiopulmonary Sounds Dataset Using Digital Stethoscope**
2410.03280v1 by Yasaman Torabi, Shahram Shirani, James P. Reilly

Heart and lung sounds are crucial for healthcare monitoring. Recent
improvements in stethoscope technology have made it possible to capture patient
sounds with enhanced precision. In this dataset, we used a digital stethoscope
to capture both heart and lung sounds, including individual and mixed
recordings. To our knowledge, this is the first dataset to offer both separate
and mixed cardiorespiratory sounds. The recordings were collected from a
clinical manikin, a patient simulator designed to replicate human physiological
conditions, generating clean heart and lung sounds at different body locations.
This dataset includes both normal sounds and various abnormalities (i.e.,
murmur, atrial fibrillation, tachycardia, atrioventricular block, third and
fourth heart sound, wheezing, crackles, rhonchi, pleural rub, and gurgling
sounds). The dataset includes audio recordings of chest examinations performed
at different anatomical locations, as determined by specialist nurses. Each
recording has been enhanced using frequency filters to highlight specific sound
types. This dataset is useful for applications in artificial intelligence, such
as automated cardiopulmonary disease detection, sound classification,
unsupervised separation techniques, and deep learning algorithms related to
audio signal processing.

摘要：心臟與肺部聲音對於醫療保健監測至關重要。最近在聽診器技術方面的進步，使得以更高的精準度擷取患者聲音成為可能。在這個資料集中，我們使用數位聽診器擷取心臟與肺部聲音，包括個別和混合的錄音。據我們所知，這是第一個提供個別和混合的心肺聲音的資料集。這些錄音是從臨床假人收集的，臨床假人是一種模擬人體生理狀況的患者模擬器，可在不同身體部位產生乾淨的心臟和肺部聲音。這個資料集包含正常聲音和各種異常（例如，雜音、心房顫動、心動過速、房室傳導阻滯、第三和第四心音、喘鳴、爆裂音、囉音、胸膜摩擦音和咕嚕聲）。這個資料集包含在不同解剖位置進行胸部檢查的音訊錄音，由專科護理師確定。每個錄音都使用頻率濾波器進行加強，以突顯特定的聲音類型。這個資料集對於人工智慧的應用很有用，例如自動心肺疾病偵測、聲音分類、無監督分離技術和與音訊訊號處理相關的深度學習演算法。

##### **Looking into Concept Explanation Methods for Diabetic Retinopathy Classification**
2410.03188v1 by Andrea M. Storås, Josefine V. Sundgaard

Diabetic retinopathy is a common complication of diabetes, and monitoring the
progression of retinal abnormalities using fundus imaging is crucial. Because
the images must be interpreted by a medical expert, it is infeasible to screen
all individuals with diabetes for diabetic retinopathy. Deep learning has shown
impressive results for automatic analysis and grading of fundus images. One
drawback is, however, the lack of interpretability, which hampers the
implementation of such systems in the clinic. Explainable artificial
intelligence methods can be applied to explain the deep neural networks.
Explanations based on concepts have shown to be intuitive for humans to
understand, but have not yet been explored in detail for diabetic retinopathy
grading. This work investigates and compares two concept-based explanation
techniques for explaining deep neural networks developed for automatic
diagnosis of diabetic retinopathy: Quantitative Testing with Concept Activation
Vectors and Concept Bottleneck Models. We found that both methods have
strengths and weaknesses, and choice of method should take the available data
and the end user's preferences into account.

摘要：糖尿病視網膜病變是糖尿病的常見併發症，使用眼底成像監控視網膜異常的進展至關重要。由於影像必須由醫療專家解釋，因此不可能篩選出所有患有糖尿病視網膜病變的糖尿病患者。深度學習已在眼底影像的自動分析和分級方面展現出令人印象深刻的成果。然而，其中一個缺點是缺乏可解釋性，這阻礙了此類系統在臨床上的實施。可解釋的人工智慧方法可應用於解釋深度神經網路。基於概念的解釋已被證明對人類來說直觀易懂，但尚未詳細探討糖尿病視網膜病變分級。這項工作探討並比較了兩種基於概念的解釋技術，用於解釋為糖尿病視網膜病變自動診斷而開發的深度神經網路：使用概念激活向量進行的定量測試和概念瓶頸模型。我們發現這兩種方法各有優缺點，方法的選擇應考慮可用的資料和最終使用者的偏好。

##### **Remaining Useful Life Prediction: A Study on Multidimensional Industrial Signal Processing and Efficient Transfer Learning Based on Large Language Models**
2410.03134v1 by Yan Chen, Cheng Liu

Remaining useful life (RUL) prediction is crucial for maintaining modern
industrial systems, where equipment reliability and operational safety are
paramount. Traditional methods, based on small-scale deep learning or
physical/statistical models, often struggle with complex, multidimensional
sensor data and varying operating conditions, limiting their generalization
capabilities. To address these challenges, this paper introduces an innovative
regression framework utilizing large language models (LLMs) for RUL prediction.
By leveraging the modeling power of LLMs pre-trained on corpus data, the
proposed model can effectively capture complex temporal dependencies and
improve prediction accuracy. Extensive experiments on the Turbofan engine's RUL
prediction task show that the proposed model surpasses state-of-the-art (SOTA)
methods on the challenging FD002 and FD004 subsets and achieves near-SOTA
results on the other subsets. Notably, different from previous research, our
framework uses the same sliding window length and all sensor signals for all
subsets, demonstrating strong consistency and generalization. Moreover,
transfer learning experiments reveal that with minimal target domain data for
fine-tuning, the model outperforms SOTA methods trained on full target domain
data. This research highlights the significant potential of LLMs in industrial
signal processing and RUL prediction, offering a forward-looking solution for
health management in future intelligent industrial systems.

摘要：剩餘使用壽命 (RUL) 預測對於維護現代工業系統至關重要，在這些系統中，設備可靠性和操作安全至上。傳統方法基於小規模深度學習或物理/統計模型，通常難以處理複雜、多維度的感測器資料和不同的操作條件，限制了它們的泛化能力。為了應對這些挑戰，本文介紹了一個創新的回歸架構，利用大型語言模型 (LLM) 來進行 RUL 預測。通過利用在語料資料上預先訓練的 LLM 的建模能力，所提出的模型可以有效地捕捉複雜的時間依賴性並提高預測準確度。在渦輪風扇引擎的 RUL 預測任務上進行的廣泛實驗表明，所提出的模型在具有挑戰性的 FD002 和 FD004 子集中超越了最先進 (SOTA) 的方法，並在其他子集中達到了接近 SOTA 的結果。值得注意的是，與先前的研究不同，我們的框架對所有子集都使用相同的滑動窗口長度和所有感測器訊號，展示了強大的相容性和泛化能力。此外，轉移學習實驗表明，透過對微調進行最少的目標網域資料，該模型的表現優於在完整目標網域資料上訓練的 SOTA 方法。這項研究突顯了 LLM 在工業訊號處理和 RUL 預測中的巨大潛力，為未來智慧工業系統中的健康管理提供了前瞻性的解決方案。

##### **Image First or Text First? Optimising the Sequencing of Modalities in Large Language Model Prompting and Reasoning Tasks**
2410.03062v1 by Grant Wardle, Teo Susnjak

This paper examines how the sequencing of images and text within multi-modal
prompts influences the reasoning performance of large language models (LLMs).
We performed empirical evaluations using three commercial LLMs. Our results
demonstrate that the order in which modalities are presented can significantly
affect performance, particularly in tasks of varying complexity. For simpler
tasks involving a single image, modality sequencing had a clear impact on
accuracy. However, in more complex tasks involving multiple images and
intricate reasoning steps, the effect of sequencing diminished, likely due to
the increased cognitive demands of the task. Our findings also highlight the
importance of question/prompt structure. In nested and multi-step reasoning
tasks, modality sequencing played a key role in shaping model performance.
While LLMs excelled in the initial stages of reasoning, they struggled to
re-incorporate earlier information, underscoring the challenges of multi-hop
reasoning within transformer architectures. This suggests that aligning the
sequence of modalities with the logical flow of reasoning steps is more
critical than modality order alone. These insights offer valuable implications
for improving multi-modal prompt design, with broader applications across
fields such as education, medical imaging, and cross-modal learning.

摘要：本文探討在多模態提示中影像和文字的順序如何影響大型語言模型 (LLM) 的推理表現。我們使用三個商用 LLM 進行實證評估。我們的結果表明，模態呈現的順序會顯著影響表現，特別是在不同複雜度任務中。對於涉及單一影像的較簡單任務，模態順序對準確度有明顯影響。然而，在涉及多個影像和複雜推理步驟的較複雜任務中，順序的影響減弱，這可能是由於任務的認知需求增加。我們的發現也突顯了問題/提示結構的重要性。在嵌套和多步驟推理任務中，模態順序在塑造模型表現中扮演關鍵角色。雖然 LLM 在推理的初始階段表現出色，但它們難以重新整合早期的資訊，這凸顯了Transformer架構中多跳推理的挑戰。這表明將模態順序與推理步驟的邏輯流程對齊比單獨的模態順序更為重要。這些見解為改善多模態提示設計提供了寶貴的啟示，並在教育、醫學影像和跨模態學習等領域有更廣泛的應用。

##### **Is Your Paper Being Reviewed by an LLM? Investigating AI Text Detectability in Peer Review**
2410.03019v1 by Sungduk Yu, Man Luo, Avinash Madasu, Vasudev Lal, Phillip Howard

Peer review is a critical process for ensuring the integrity of published
scientific research. Confidence in this process is predicated on the assumption
that experts in the relevant domain give careful consideration to the merits of
manuscripts which are submitted for publication. With the recent rapid
advancements in the linguistic capabilities of large language models (LLMs), a
new potential risk to the peer review process is that negligent reviewers will
rely on LLMs to perform the often time consuming process of reviewing a paper.
In this study, we investigate the ability of existing AI text detection
algorithms to distinguish between peer reviews written by humans and different
state-of-the-art LLMs. Our analysis shows that existing approaches fail to
identify many GPT-4o written reviews without also producing a high number of
false positive classifications. To address this deficiency, we propose a new
detection approach which surpasses existing methods in the identification of
GPT-4o written peer reviews at low levels of false positive classifications.
Our work reveals the difficulty of accurately identifying AI-generated text at
the individual review level, highlighting the urgent need for new tools and
methods to detect this type of unethical application of generative AI.

摘要：同儕審查是確保已發表的科學研究的完整性的關鍵過程。對此過程的信心建立在一個假設之上，即相關領域的專家會仔細考慮提交出版的稿件的優點。隨著大型語言模型 (LLM) 的語言能力最近的快速進展，對同儕審查過程的一個新的潛在風險是，疏忽的審查員會依賴 LLM 來執行審查論文這個常常很耗時的過程。在本研究中，我們調查了現有 AI 文字偵測演算法區分由人類撰寫的同儕審查和不同的最先進 LLM 的能力。我們的分析顯示，現有的方法無法識別許多 GPT-4o 寫的評論，同時也不會產生大量的假陽性分類。為了解決這個缺陷，我們提出了一種新的偵測方法，它在低水平的假陽性分類中超越了現有的方法，識別 GPT-4o 寫的同儕審查。我們的研究揭示了在個別審查層級準確識別 AI 生成的文字的難度，強調了迫切需要新的工具和方法來偵測這種不道德的生成式 AI 應用。

##### **DailyDilemmas: Revealing Value Preferences of LLMs with Quandaries of Daily Life**
2410.02683v1 by Yu Ying Chiu, Liwei Jiang, Yejin Choi

As we increasingly seek guidance from LLMs for decision-making in daily life,
many of these decisions are not clear-cut and depend significantly on the
personal values and ethical standards of the users. We present DailyDilemmas, a
dataset of 1,360 moral dilemmas encountered in everyday life. Each dilemma
includes two possible actions and with each action, the affected parties and
human values invoked. Based on these dilemmas, we consolidated a set of human
values across everyday topics e.g., interpersonal relationships, workplace, and
environmental issues. We evaluated LLMs on these dilemmas to determine what
action they will take and the values represented by these actions. Then, we
analyzed these values through the lens of five popular theories inspired by
sociology, psychology and philosophy. These theories are: World Value Survey,
Moral Foundation Theory, Maslow's Hierarchy of Needs, Aristotle's Virtues, and
Plutchik Wheel of Emotion. We find that LLMs are most aligned with the
self-expression over survival values in terms of World Value Survey, care over
loyalty in Moral Foundation Theory. Interestingly, we find large preferences
differences in models for some core values such as truthfulness e.g.,
Mixtral-8x7B model tends to neglect it by 9.7% while GPT-4-turbo model tends to
select it by 9.4%. We also study the recent guidance released by OpenAI
(ModelSpec), and Anthropic (Constitutional AI) to understand how their released
principles reflect their actual value prioritization when facing nuanced moral
reasoning in daily-life settings. We find that end users cannot effectively
steer such prioritization using system prompts.

摘要：<paragraph>隨著我們在日常生活中越來越依賴 LLM 來進行決策，
其中許多決策並非明確，而且在很大程度上取決於
使用者的個人價值觀和道德標準。我們提出了日常困境，一個
在日常生活中遇到的 1,360 個道德困境的數據集。每個困境
包含兩個可能的行動，並針對每個行動，受到影響的各方和
引發的人類價值觀。根據這些困境，我們彙整了一組人類
價值觀，涵蓋日常主題，例如人際關係、職場和
環境問題。我們針對這些困境評估 LLM，以確定它們將採取什麼
行動以及這些行動所代表的價值觀。接著，我們
透過社會學、心理學和哲學啟發的五種流行理論來分析這些價值觀。這些理論為：世界價值觀調查、
道德基礎理論、馬斯洛需求層次理論、亞里斯多德美德，以及
普拉契克情緒之輪。我們發現 LLM 在世界價值觀調查中與
生存價值觀相比，更傾向於自我表達；在道德基礎理論中，更傾向於關懷而非忠誠。有趣的是，我們發現對於某些核心價值觀，例如誠實，不同模型之間存在很大的偏好差異，例如，
Mixtral-8x7B 模型傾向於忽略它 9.7%，而 GPT-4-turbo 模型傾向於選擇它 9.4%。我們還研究了 OpenAI
(ModelSpec) 和 Anthropic (Constitutional AI) 最近發布的指導方針，以了解他們發布的原則如何在面對日常生活中微妙的道德推理時反映他們的實際價值優先順序。我們發現，最終使用者無法有效地
使用系統提示來引導此類優先順序。</paragraph>

##### **Plots Unlock Time-Series Understanding in Multimodal Models**
2410.02637v1 by Mayank Daswani, Mathias M. J. Bellaiche, Marc Wilson, Desislav Ivanov, Mikhail Papkov, Eva Schnider, Jing Tang, Kay Lamerigts, Gabriela Botea, Michael A. Sanchez, Yojan Patel, Shruthi Prabhakara, Shravya Shetty, Umesh Telang

While multimodal foundation models can now natively work with data beyond
text, they remain underutilized in analyzing the considerable amounts of
multi-dimensional time-series data in fields like healthcare, finance, and
social sciences, representing a missed opportunity for richer, data-driven
insights. This paper proposes a simple but effective method that leverages the
existing vision encoders of these models to "see" time-series data via plots,
avoiding the need for additional, potentially costly, model training. Our
empirical evaluations show that this approach outperforms providing the raw
time-series data as text, with the additional benefit that visual time-series
representations demonstrate up to a 90% reduction in model API costs. We
validate our hypothesis through synthetic data tasks of increasing complexity,
progressing from simple functional form identification on clean data, to
extracting trends from noisy scatter plots. To demonstrate generalizability
from synthetic tasks with clear reasoning steps to more complex, real-world
scenarios, we apply our approach to consumer health tasks - specifically fall
detection, activity recognition, and readiness assessment - which involve
heterogeneous, noisy data and multi-step reasoning. The overall success in plot
performance over text performance (up to an 120% performance increase on
zero-shot synthetic tasks, and up to 150% performance increase on real-world
tasks), across both GPT and Gemini model families, highlights our approach's
potential for making the best use of the native capabilities of foundation
models.

摘要：儘管多模態基礎模型現在可以原生處理文字以外的資料，但它們在分析醫療保健、金融和社會科學等領域中大量多維時間序列資料時仍未被充分利用，這代表錯失了獲得更豐富資料驅動見解的機會。本文提出了一種簡單但有效的方法，利用這些模型現有的視覺編碼器透過圖表「查看」時間序列資料，避免需要額外且可能昂貴的模型訓練。我們的經驗評估顯示，這種方法優於提供原始時間序列資料作為文字，額外的好處是視覺時間序列表示可以減少高達 90% 的模型 API 成本。我們透過日益複雜的合成資料任務驗證我們的假設，從乾淨資料上的簡單函數形式識別，到從雜訊散佈圖中萃取趨勢。為了證明從具有明確推理步驟的合成任務到更複雜的真實世界場景的概括性，我們將我們的做法應用於消費者健康任務，特別是跌倒偵測、活動識別和準備評估，這些任務涉及異質、雜訊資料和多步驟推理。在 GPT 和 Gemini 模型系列中，圖表表現優於文字表現的整體成功（在零次學習合成任務中表現提升高達 120%，在真實世界任務中表現提升高達 150%），突顯了我們的方法在最佳利用基礎模型原生功能方面的潛力。

##### **IC3M: In-Car Multimodal Multi-object Monitoring for Abnormal Status of Both Driver and Passengers**
2410.02592v3 by Zihan Fang, Zheng Lin, Senkang Hu, Hangcheng Cao, Yiqin Deng, Xianhao Chen, Yuguang Fang

Recently, in-car monitoring has emerged as a promising technology for
detecting early-stage abnormal status of the driver and providing timely alerts
to prevent traffic accidents. Although training models with multimodal data
enhances the reliability of abnormal status detection, the scarcity of labeled
data and the imbalance of class distribution impede the extraction of critical
abnormal state features, significantly deteriorating training performance.
Furthermore, missing modalities due to environment and hardware limitations
further exacerbate the challenge of abnormal status identification. More
importantly, monitoring abnormal health conditions of passengers, particularly
in elderly care, is of paramount importance but remains underexplored. To
address these challenges, we introduce our IC3M, an efficient
camera-rotation-based multimodal framework for monitoring both driver and
passengers in a car. Our IC3M comprises two key modules: an adaptive threshold
pseudo-labeling strategy and a missing modality reconstruction. The former
customizes pseudo-labeling thresholds for different classes based on the class
distribution, generating class-balanced pseudo labels to guide model training
effectively, while the latter leverages crossmodality relationships learned
from limited labels to accurately recover missing modalities by distribution
transferring from available modalities. Extensive experimental results
demonstrate that IC3M outperforms state-of-the-art benchmarks in accuracy,
precision, and recall while exhibiting superior robustness under limited
labeled data and severe missing modality.

摘要：<paragraph>最近，車載監控已成為一種有前途的技術，用於檢測駕駛員的早期異常狀態，並提供及時警報以防止交通事故。儘管使用多模態數據訓練模型增強了異常狀態檢測的可靠性，但標記數據的稀缺性和類別分佈的不平衡阻礙了關鍵異常狀態特徵的提取，顯著降低了訓練性能。此外，由於環境和硬體限制而導致的模態缺失進一步加劇了異常狀態識別的挑戰。更重要的是，監控乘客的異常健康狀況，特別是在老年護理中，至關重要，但仍未得到充分探索。為了應對這些挑戰，我們引入了我們的 IC3M，這是一個基於相機旋轉的高效多模態框架，用於監控汽車中的駕駛員和乘客。我們的 IC3M 包含兩個關鍵模組：自適應閾值偽標籤策略和缺失模態重建。前者根據類別分佈為不同的類別自訂偽標籤閾值，生成類別平衡的偽標籤以有效地指導模型訓練，而後者則利用從有限標籤中學習到的跨模態關係，通過從可用模態進行分佈轉移來準確恢復缺失的模態。廣泛的實驗結果表明，IC3M 在準確性、精確度和召回率方面優於最先進的基準，同時在標記數據有限和嚴重缺失模態的情況下表現出卓越的魯棒性。</paragraph>

##### **Deep Regression 2D-3D Ultrasound Registration for Liver Motion Correction in Focal Tumor Thermal Ablation**
2410.02579v1 by Shuwei Xing, Derek W. Cool, David Tessier, Elvis C. S. Chen, Terry M. Peters, Aaron Fenster

Liver tumor ablation procedures require accurate placement of the needle
applicator at the tumor centroid. The lower-cost and real-time nature of
ultrasound (US) has advantages over computed tomography (CT) for applicator
guidance, however, in some patients, liver tumors may be occult on US and tumor
mimics can make lesion identification challenging. Image registration
techniques can aid in interpreting anatomical details and identifying tumors,
but their clinical application has been hindered by the tradeoff between
alignment accuracy and runtime performance, particularly when compensating for
liver motion due to patient breathing or movement. Therefore, we propose a
2D-3D US registration approach to enable intra-procedural alignment that
mitigates errors caused by liver motion. Specifically, our approach can
correlate imbalanced 2D and 3D US image features and use continuous 6D rotation
representations to enhance the model's training stability. The dataset was
divided into 2388, 196 and 193 image pairs for training, validation and
testing, respectively. Our approach achieved a mean Euclidean distance error of
2.28 mm $\pm$ 1.81 mm and a mean geodesic angular error of 2.99$^{\circ}$ $\pm$
1.95$^{\circ}$, with a runtime of 0.22 seconds per 2D-3D US image pair. These
results demonstrate that our approach can achieve accurate alignment and
clinically acceptable runtime, indicating potential for clinical translation.

摘要：肝臟腫瘤消融手術需要將針頭施用器精準置於腫瘤中心點。超音波 (US) 成本較低且為即時影像，相較於電腦斷層掃描 (CT)，在施用器導引方面有優勢，然而，對於某些患者，肝臟腫瘤在超音波影像上可能不明顯，而腫瘤模擬會讓病灶辨識更具挑戰性。影像配準技術有助於解讀解剖細節和辨識腫瘤，但由於平衡校準準確度和執行效能，其臨床應用受到阻礙，特別是在補償因患者呼吸或移動而產生的肝臟運動時。因此，我們提出 2D-3D 超音波配準方法，以進行術中校準，減輕因肝臟運動而產生的誤差。具體來說，我們的做法可以關聯失衡的 2D 和 3D 超音波影像特徵，並使用連續的 6D 旋轉表示來增強模型的訓練穩定度。資料集分為 2388、196 和 193 影像對，分別用於訓練、驗證和測試。我們的做法達成平均歐氏距離誤差 2.28 mm $\pm$ 1.81 mm，以及平均測地角誤差 2.99$^{\circ}$ $\pm$ 1.95$^{\circ}$，執行時間為每 2D-3D 超音波影像對 0.22 秒。這些結果證明我們的做法可以達成精準校準和臨床上可接受的執行時間，顯示出臨床轉譯的潛力。

##### **ColaCare: Enhancing Electronic Health Record Modeling through Large Language Model-Driven Multi-Agent Collaboration**
2410.02551v1 by Zixiang Wang, Yinghao Zhu, Huiya Zhao, Xiaochen Zheng, Tianlong Wang, Wen Tang, Yasha Wang, Chengwei Pan, Ewen M. Harrison, Junyi Gao, Liantao Ma

We introduce ColaCare, a framework that enhances Electronic Health Record
(EHR) modeling through multi-agent collaboration driven by Large Language
Models (LLMs). Our approach seamlessly integrates domain-specific expert models
with LLMs to bridge the gap between structured EHR data and text-based
reasoning. Inspired by clinical consultations, ColaCare employs two types of
agents: DoctorAgent and MetaAgent, which collaboratively analyze patient data.
Expert models process and generate predictions from numerical EHR data, while
LLM agents produce reasoning references and decision-making reports within the
collaborative consultation framework. We additionally incorporate the Merck
Manual of Diagnosis and Therapy (MSD) medical guideline within a
retrieval-augmented generation (RAG) module for authoritative evidence support.
Extensive experiments conducted on four distinct EHR datasets demonstrate
ColaCare's superior performance in mortality prediction tasks, underscoring its
potential to revolutionize clinical decision support systems and advance
personalized precision medicine. The code, complete prompt templates, more case
studies, etc. are publicly available at the anonymous link:
https://colacare.netlify.app.

摘要：我們推出 ColaCare，一個透過大型語言模型 (LLM) 驅動的多重代理協作，來增強電子健康紀錄 (EHR) 建模的框架。我們的做法將領域特定專家模型與 LLM 無縫整合，以彌合結構化 EHR 資料與基於文字的推理之間的差距。ColaCare 受到臨床諮詢的啟發，採用了兩種代理：DoctorAgent 和 MetaAgent，它們協作分析患者資料。專家模型處理並從數值 EHR 資料產生預測，而 LLM 代理則在協作諮詢框架內產生推理參考和決策報告。我們另外在一個檢索增強生成 (RAG) 模組中納入了默克診斷與治療手冊 (MSD) 醫療指南，以獲得權威證據支持。在四個不同的 EHR 資料集上進行的廣泛實驗證明了 ColaCare 在死亡率預測任務中的優異效能，強調了其革新臨床決策支援系統和推進個人化精準醫療的潛力。程式碼、完整的提示範本、更多案例研究等，都可以在匿名連結中公開取得：https://colacare.netlify.app。

##### **SAFLEX: Self-Adaptive Augmentation via Feature Label Extrapolation**
2410.02512v1 by Mucong Ding, Bang An, Yuancheng Xu, Anirudh Satheesh, Furong Huang

Data augmentation, a cornerstone technique in deep learning, is crucial in
enhancing model performance, especially with scarce labeled data. While
traditional techniques are effective, their reliance on hand-crafted methods
limits their applicability across diverse data types and tasks. Although modern
learnable augmentation methods offer increased adaptability, they are
computationally expensive and challenging to incorporate within prevalent
augmentation workflows. In this work, we present a novel, efficient method for
data augmentation, effectively bridging the gap between existing augmentation
strategies and emerging datasets and learning tasks. We introduce SAFLEX
(Self-Adaptive Augmentation via Feature Label EXtrapolation), which learns the
sample weights and soft labels of augmented samples provided by any given
upstream augmentation pipeline, using a specifically designed efficient bilevel
optimization algorithm. Remarkably, SAFLEX effectively reduces the noise and
label errors of the upstream augmentation pipeline with a marginal
computational cost. As a versatile module, SAFLEX excels across diverse
datasets, including natural and medical images and tabular data, showcasing its
prowess in few-shot learning and out-of-distribution generalization. SAFLEX
seamlessly integrates with common augmentation strategies like RandAug, CutMix,
and those from large pre-trained generative models like stable diffusion and is
also compatible with frameworks such as CLIP's fine-tuning. Our findings
highlight the potential to adapt existing augmentation pipelines for new data
types and tasks, signaling a move towards more adaptable and resilient training
frameworks.

摘要：資料擴充是深度學習的基石技術，在提升模型效能方面至關重要，特別是在標籤資料稀少的情況下。雖然傳統技術很有效，但它們依賴於手工製作的方法，限制了它們在不同資料類型和任務中的適用性。儘管現代可學習的擴充方法提供了更高的適應性，但它們在計算上很昂貴，並且難以整合到普遍的擴充工作流程中。在這項工作中，我們提出了一種新穎、有效率的資料擴充方法，有效地彌合了現有擴充策略與新興資料集和學習任務之間的差距。我們引入了 SAFLEX（透過特徵標籤外推進行自適應擴充），它使用專門設計的有效雙層次最佳化演算法，學習由任何給定的上游擴充管道提供的擴充樣本的樣本權重和軟標籤。值得注意的是，SAFLEX 有效地降低了上游擴充管道的雜訊和標籤錯誤，且計算成本很低。作為一個多功能模組，SAFLEX 在各種資料集中表現出色，包括自然和醫學影像以及表格資料，展示了它在少樣本學習和分布外概括中的優異能力。SAFLEX 與常見的擴充策略（如 RandAug、CutMix，以及來自大型預訓練生成模型（如穩定擴散）的擴充策略）無縫整合，並且也相容於 CLIP 的微調等框架。我們的研究結果突顯了調整現有擴充管道以適應新資料類型和任務的潛力，標誌著朝向更具適應性和韌性的訓練框架邁進。

##### **Clinnova Federated Learning Proof of Concept: Key Takeaways from a Cross-border Collaboration**
2410.02443v1 by Julia Alekseenko, Bram Stieltjes, Michael Bach, Melanie Boerries, Oliver Opitz, Alexandros Karargyris, Nicolas Padoy

Clinnova, a collaborative initiative involving France, Germany, Switzerland,
and Luxembourg, is dedicated to unlocking the power of precision medicine
through data federation, standardization, and interoperability. This European
Greater Region initiative seeks to create an interoperable European standard
using artificial intelligence (AI) and data science to enhance healthcare
outcomes and efficiency. Key components include multidisciplinary research
centers, a federated biobanking strategy, a digital health innovation platform,
and a federated AI strategy. It targets inflammatory bowel disease, rheumatoid
diseases, and multiple sclerosis (MS), emphasizing data quality to develop AI
algorithms for personalized treatment and translational research.
  The IHU Strasbourg (Institute of Minimal-invasive Surgery) has the lead in
this initiative to develop the federated learning (FL) proof of concept (POC)
that will serve as a foundation for advancing AI in healthcare. At its core,
Clinnova-MS aims to enhance MS patient care by using FL to develop more
accurate models that detect disease progression, guide interventions, and
validate digital biomarkers across multiple sites. This technical report
presents insights and key takeaways from the first cross-border federated POC
on MS segmentation of MRI images within the Clinnova framework. While our work
marks a significant milestone in advancing MS segmentation through cross-border
collaboration, it also underscores the importance of addressing technical,
logistical, and ethical considerations to realize the full potential of FL in
healthcare settings.

摘要：Clinnova 是一項由法國、德國、瑞士和盧森堡合作發起的計畫，致力於透過資料聯合、標準化和互通性來釋放精準醫療的力量。這個歐洲大區計畫旨在使用人工智慧 (AI) 和資料科學建立一個可互通的歐洲標準，以提升醫療保健成果和效率。主要組成部分包括跨領域研究中心、聯合生物銀行策略、數位健康創新平台和聯合 AI 策略。它針對發炎性腸道疾病、類風濕性疾病和多發性硬化症 (MS) 進行研究，強調資料品質以開發 AI 演算法，用於個人化治療和轉譯研究。
史特拉斯堡 IHU（微創手術研究所）在這個計畫中領先開發聯合學習 (FL) 概念驗證 (POC)，這將作為在醫療保健中推進 AI 的基礎。Clinnova-MS 的核心目標是透過使用 FL 來提升 MS 患者照護，以開發更精確的模型來偵測疾病進程、引導介入措施，並驗證多個地點的數位生物標記。這份技術報告提供了 Clinnova 架構內 MS 磁振造影影像分割首次跨境聯合 POC 的見解和主要結論。雖然我們的成果在透過跨境合作推進 MS 分割方面是一個重要的里程碑，但也強調了在醫療保健環境中實現 FL 的全部潛力時，解決技術、後勤和倫理考量的必要性。

##### **A Comprehensive Survey of Mamba Architectures for Medical Image Analysis: Classification, Segmentation, Restoration and Beyond**
2410.02362v1 by Shubhi Bansal, Sreeharish A, Madhava Prasath J, Manikandan S, Sreekanth Madisetty, Mohammad Zia Ur Rehman, Chandravardhan Singh Raghaw, Gaurav Duggal, Nagendra Kumar

Mamba, a special case of the State Space Model, is gaining popularity as an
alternative to template-based deep learning approaches in medical image
analysis. While transformers are powerful architectures, they have drawbacks,
including quadratic computational complexity and an inability to address
long-range dependencies efficiently. This limitation affects the analysis of
large and complex datasets in medical imaging, where there are many spatial and
temporal relationships. In contrast, Mamba offers benefits that make it
well-suited for medical image analysis. It has linear time complexity, which is
a significant improvement over transformers. Mamba processes longer sequences
without attention mechanisms, enabling faster inference and requiring less
memory. Mamba also demonstrates strong performance in merging multimodal data,
improving diagnosis accuracy and patient outcomes. The organization of this
paper allows readers to appreciate the capabilities of Mamba in medical imaging
step by step. We begin by defining core concepts of SSMs and models, including
S4, S5, and S6, followed by an exploration of Mamba architectures such as pure
Mamba, U-Net variants, and hybrid models with convolutional neural networks,
transformers, and Graph Neural Networks. We also cover Mamba optimizations,
techniques and adaptations, scanning, datasets, applications, experimental
results, and conclude with its challenges and future directions in medical
imaging. This review aims to demonstrate the transformative potential of Mamba
in overcoming existing barriers within medical imaging while paving the way for
innovative advancements in the field. A comprehensive list of Mamba
architectures applied in the medical field, reviewed in this work, is available
at Github.

摘要：Mamba 是一種特殊類型的狀態空間模型，逐漸受到重視，成為醫學影像分析中基於範本的深度學習方法的替代方案。儘管Transformer是強大的架構，但它們有缺點，包括二次計算複雜度，以及無法有效處理長距離依賴性。這種限制會影響醫學影像中大型複雜資料集的分析，其中有許多空間和時間關係。相比之下，Mamba 提供的優點使其非常適合醫學影像分析。它具有線性時間複雜度，這是一個比Transformer顯著的改進。Mamba 在沒有注意機制的情況下處理更長的序列，從而實現更快的推理並需要更少的記憶體。Mamba 在合併多模態數據方面也表現出強大的效能，提高了診斷準確性和患者預後。本文的組織方式讓讀者可以逐步了解 Mamba 在醫學影像中的功能。我們從定義 SSM 和模型的核心概念開始，包括 S4、S5 和 S6，然後探討 Mamba 架構，例如純 Mamba、U-Net 變體，以及帶有卷積神經網路、Transformer和圖神經網路的混合模型。我們還涵蓋了 Mamba 最佳化、技術和改編、掃描、資料集、應用、實驗結果，並以其在醫學影像中的挑戰和未來方向作為結論。本篇評論旨在展示 Mamba 在克服醫學影像中現有障礙方面的轉型潛力，同時為該領域的創新進步鋪平道路。在這項工作中回顧的應用於醫學領域的 Mamba 架構的綜合清單可在 Github 上取得。


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-16**|**Context is Key(NMF): Modelling Topical Information Dynamics in Chinese Diaspora Media**|Ross Deans Kristensen-McLachlan et.al.|[2410.12791v1](http://arxiv.org/abs/2410.12791v1)|null|
|**2024-10-16**|**Meta-Chunking: Learning Efficient Text Segmentation via Logical Perception**|Jihao Zhao et.al.|[2410.12788v1](http://arxiv.org/abs/2410.12788v1)|null|
|**2024-10-16**|**JudgeBench: A Benchmark for Evaluating LLM-based Judges**|Sijun Tan et.al.|[2410.12784v1](http://arxiv.org/abs/2410.12784v1)|null|
|**2024-10-16**|**In-Context Learning Enables Robot Action Prediction in LLMs**|Yida Yin et.al.|[2410.12782v1](http://arxiv.org/abs/2410.12782v1)|null|
|**2024-10-16**|**Meta-Unlearning on Diffusion Models: Preventing Relearning Unlearned Concepts**|Hongcheng Gao et.al.|[2410.12777v1](http://arxiv.org/abs/2410.12777v1)|null|
|**2024-10-16**|**Identifying Task Groupings for Multi-Task Learning Using Pointwise V-Usable Information**|Yingya Li et.al.|[2410.12774v1](http://arxiv.org/abs/2410.12774v1)|null|
|**2024-10-16**|**Harmon: Whole-Body Motion Generation of Humanoid Robots from Language Descriptions**|Zhenyu Jiang et.al.|[2410.12773v1](http://arxiv.org/abs/2410.12773v1)|null|
|**2024-10-16**|**Vaccinating Federated Learning for Robust Modulation Classification in Distributed Wireless Networks**|Hunmin Lee et.al.|[2410.12772v1](http://arxiv.org/abs/2410.12772v1)|null|
|**2024-10-16**|**Open Materials 2024 (OMat24) Inorganic Materials Dataset and Models**|Luis Barroso-Luque et.al.|[2410.12771v1](http://arxiv.org/abs/2410.12771v1)|null|
|**2024-10-16**|**SAFREE: Training-Free and Adaptive Guard for Safe Text-to-Image And Video Generation**|Jaehong Yoon et.al.|[2410.12761v1](http://arxiv.org/abs/2410.12761v1)|null|
|**2024-10-16**|**Unitary Multi-Margin BERT for Robust Natural Language Processing**|Hao-Yuan Chang et.al.|[2410.12759v1](http://arxiv.org/abs/2410.12759v1)|null|
|**2024-10-16**|**StyleDistance: Stronger Content-Independent Style Embeddings with Synthetic Parallel Examples**|Ajay Patel et.al.|[2410.12757v1](http://arxiv.org/abs/2410.12757v1)|null|
|**2024-10-16**|**Comparative Analysis of Extrinsic Factors for NER in French**|Grace Yang et.al.|[2410.12750v1](http://arxiv.org/abs/2410.12750v1)|null|
|**2024-10-16**|**CREAM: Consistency Regularized Self-Rewarding Language Models**|Zhaoyang Wang et.al.|[2410.12735v2](http://arxiv.org/abs/2410.12735v2)|null|
|**2024-10-16**|**Counterfactual Generative Modeling with Variational Causal Inference**|Yulun Wu et.al.|[2410.12730v1](http://arxiv.org/abs/2410.12730v1)|null|
|**2024-10-16**|**Transformer based super-resolution downscaling for regional reanalysis: Full domain vs tiling approaches**|Antonio Pérez et.al.|[2410.12728v1](http://arxiv.org/abs/2410.12728v1)|null|
|**2024-10-16**|**WorldMedQA-V: a multilingual, multimodal medical examination dataset for multimodal language models evaluation**|João Matos et.al.|[2410.12722v1](http://arxiv.org/abs/2410.12722v1)|null|
|**2024-10-16**|**HEnRY: A Multi-Agent System Framework for Multi-Domain Contexts**|Emmanuele Lacavalla et.al.|[2410.12720v1](http://arxiv.org/abs/2410.12720v1)|[link](https://github.com/2mmanu/henry)|
|**2024-10-16**|**FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression**|Zhenheng Tang et.al.|[2410.12707v1](http://arxiv.org/abs/2410.12707v1)|null|
|**2024-10-16**|**WorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines**|Genta Indra Winata et.al.|[2410.12705v1](http://arxiv.org/abs/2410.12705v1)|null|
|**2024-10-16**|**Sarcasm Detection in a Less-Resourced Language**|Lazar Đoković et.al.|[2410.12704v1](http://arxiv.org/abs/2410.12704v1)|null|
|**2024-10-16**|**Embedding an Ethical Mind: Aligning Text-to-Image Synthesis via Lightweight Value Optimization**|Xingqi Wang et.al.|[2410.12700v1](http://arxiv.org/abs/2410.12700v1)|[link](https://github.com/achernarwang/LiVO)|
|**2024-10-16**|**VividMed: Vision Language Model with Versatile Visual Grounding for Medicine**|Lingxiao Luo et.al.|[2410.12694v1](http://arxiv.org/abs/2410.12694v1)|null|
|**2024-10-16**|**Building Better: Avoiding Pitfalls in Developing Language Resources when Data is Scarce**|Nedjma Ousidhoum et.al.|[2410.12691v1](http://arxiv.org/abs/2410.12691v1)|null|
|**2024-10-16**|**Automatic Mapping of Anatomical Landmarks from Free-Text Using Large Language Models: Insights from Llama-2**|Mohamad Abdi et.al.|[2410.12686v1](http://arxiv.org/abs/2410.12686v1)|null|
|**2024-10-16**|**Context Matters: Leveraging Contextual Features for Time Series Forecasting**|Sameep Chattopadhyay et.al.|[2410.12672v2](http://arxiv.org/abs/2410.12672v2)|null|
|**2024-10-16**|**Hamiltonian bridge: A physics-driven generative framework for targeted pattern control**|Vishaal Krishnan et.al.|[2410.12665v1](http://arxiv.org/abs/2410.12665v1)|null|
|**2024-10-16**|**Cross-Modal Safety Mechanism Transfer in Large Vision-Language Models**|Shicheng Xu et.al.|[2410.12662v1](http://arxiv.org/abs/2410.12662v1)|null|
|**2024-10-16**|**Evaluating Morphological Compositional Generalization in Large Language Models**|Mete Ismayilzada et.al.|[2410.12656v1](http://arxiv.org/abs/2410.12656v1)|null|
|**2024-10-16**|**Constrained Posterior Sampling: Time Series Generation with Hard Constraints**|Sai Shankar Narasimhan et.al.|[2410.12652v1](http://arxiv.org/abs/2410.12652v1)|null|
|**2024-10-16**|**Explainable Moral Values: a neuro-symbolic approach to value classification**|Nicolas Lazzari et.al.|[2410.12631v1](http://arxiv.org/abs/2410.12631v1)|null|
|**2024-10-16**|**From Measurement Instruments to Data: Leveraging Theory-Driven Synthetic Training Data for Classifying Social Constructs**|Lukas Birkenmaier et.al.|[2410.12622v2](http://arxiv.org/abs/2410.12622v2)|null|
|**2024-10-16**|**Weak-to-Strong Generalization beyond Accuracy: a Pilot Study in Safety, Toxicity, and Legal Reasoning**|Ruimeng Ye et.al.|[2410.12621v1](http://arxiv.org/abs/2410.12621v1)|null|
|**2024-10-16**|**Exploring Model Kinship for Merging Large Language Models**|Yedi Hu et.al.|[2410.12613v1](http://arxiv.org/abs/2410.12613v1)|null|
|**2024-10-16**|**Towards Graph Foundation Models: The Perspective of Zero-shot Reasoning on Knowledge Graphs**|Kai Wang et.al.|[2410.12609v1](http://arxiv.org/abs/2410.12609v1)|null|
|**2024-10-16**|**Not All Votes Count! Programs as Verifiers Improve Self-Consistency of Language Models for Math Reasoning**|Vernon Y. H. Toh et.al.|[2410.12608v1](http://arxiv.org/abs/2410.12608v1)|null|
|**2024-10-16**|**Low-Rank Adversarial PGD Attack**|Dayana Savostianova et.al.|[2410.12607v1](http://arxiv.org/abs/2410.12607v1)|null|
|**2024-10-16**|**CCSBench: Evaluating Compositional Controllability in LLMs for Scientific Document Summarization**|Yixi Ding et.al.|[2410.12601v1](http://arxiv.org/abs/2410.12601v1)|null|
|**2024-10-16**|**On the Risk of Evidence Pollution for Malicious Social Text Detection in the Era of LLMs**|Herun Wan et.al.|[2410.12600v1](http://arxiv.org/abs/2410.12600v1)|null|
|**2024-10-16**|**Expand and Compress: Exploring Tuning Principles for Continual Spatio-Temporal Graph Forecasting**|Wei Chen et.al.|[2410.12593v1](http://arxiv.org/abs/2410.12593v1)|null|
|**2024-10-16**|**Rethinking Visual Counterfactual Explanations Through Region Constraint**|Bartlomiej Sobieski et.al.|[2410.12591v1](http://arxiv.org/abs/2410.12591v1)|null|
|**2024-10-16**|**Can We Reverse In-Context Knowledge Edits?**|Paul Youssef et.al.|[2410.12586v1](http://arxiv.org/abs/2410.12586v1)|null|
|**2024-10-16**|**STRUX: An LLM for Decision-Making with Structured Explanations**|Yiming Lu et.al.|[2410.12583v1](http://arxiv.org/abs/2410.12583v1)|null|
|**2024-10-16**|**On the Utility of Domain Modeling Assistance with Large Language Models**|Meriem Ben Chaaben et.al.|[2410.12577v1](http://arxiv.org/abs/2410.12577v1)|null|
|**2024-10-16**|**Robust RL with LLM-Driven Data Synthesis and Policy Adaptation for Autonomous Driving**|Sihao Wu et.al.|[2410.12568v1](http://arxiv.org/abs/2410.12568v1)|null|
|**2024-10-16**|**Development of Image Collection Method Using YOLO and Siamese Network**|Chan Young Shin et.al.|[2410.12561v1](http://arxiv.org/abs/2410.12561v1)|null|
|**2024-10-16**|**A Claim Decomposition Benchmark for Long-form Answer Verification**|Zhihao Zhang et.al.|[2410.12558v1](http://arxiv.org/abs/2410.12558v1)|null|
|**2024-10-16**|**LLM-based Translation Inference with Iterative Bilingual Understanding**|Andong Chen et.al.|[2410.12543v2](http://arxiv.org/abs/2410.12543v2)|null|
|**2024-10-16**|**Counterfactual Effect Decomposition in Multi-Agent Sequential Decision Making**|Stelios Triantafyllou et.al.|[2410.12539v1](http://arxiv.org/abs/2410.12539v1)|null|
|**2024-10-16**|**Characterizing Behavioral Differences and Adaptations of Automated Vehicles and Human Drivers at Unsignalized Intersections: Insights from Waymo and Lyft Open Datasets**|Saeed Rahmani et.al.|[2410.12538v1](http://arxiv.org/abs/2410.12538v1)|[link](https://github.com/SaeedRahmani/Unsignalized_AV_HV)|
|**2024-10-16**|**Is Complex Query Answering Really Complex?**|Cosimo Gregucci et.al.|[2410.12537v1](http://arxiv.org/abs/2410.12537v1)|null|
|**2024-10-16**|**MedAide: Towards an Omni Medical Aide via Specialized LLM-based Multi-Agent Collaboration**|Jinjie Wei et.al.|[2410.12532v2](http://arxiv.org/abs/2410.12532v2)|null|
|**2024-10-16**|**Spectrum Sharing using Deep Reinforcement Learning in Vehicular Networks**|Riya Dinesh Deshpande et.al.|[2410.12521v1](http://arxiv.org/abs/2410.12521v1)|null|
|**2024-10-16**|**FiRST: Finetuning Router-Selective Transformers for Input-Adaptive Latency Reduction**|Akriti Jain et.al.|[2410.12513v1](http://arxiv.org/abs/2410.12513v1)|null|
|**2024-10-16**|**Advancing Fairness in Natural Language Processing: From Traditional Methods to Explainability**|Fanny Jourdan et.al.|[2410.12511v1](http://arxiv.org/abs/2410.12511v1)|null|
|**2024-10-16**|**Benchmarking Defeasible Reasoning with Large Language Models -- Initial Experiments and Future Directions**|Ilias Tachmazidis et.al.|[2410.12509v1](http://arxiv.org/abs/2410.12509v1)|null|
|**2024-10-16**|**DH-VTON: Deep Text-Driven Virtual Try-On via Hybrid Attention Learning**|Jiabao Wei et.al.|[2410.12501v1](http://arxiv.org/abs/2410.12501v1)|null|
|**2024-10-16**|**With a Grain of SALT: Are LLMs Fair Across Social Dimensions?**|Samee Arif et.al.|[2410.12499v1](http://arxiv.org/abs/2410.12499v1)|null|
|**2024-10-16**|**End-to-end Planner Training for Language Modeling**|Nathan Cornille et.al.|[2410.12492v1](http://arxiv.org/abs/2410.12492v1)|null|
|**2024-10-16**|**Insights from the Inverse: Reconstructing LLM Training Goals Through Inverse RL**|Jared Joselowitz et.al.|[2410.12491v1](http://arxiv.org/abs/2410.12491v1)|null|
|**2024-10-16**|**Stabilize the Latent Space for Image Autoregressive Modeling: A Unified Perspective**|Yongxin Zhu et.al.|[2410.12490v1](http://arxiv.org/abs/2410.12490v1)|[link](https://github.com/DAMO-NLP-SG/DiGIT)|
|**2024-10-16**|**SAC-GLAM: Improving Online RL for LLM agents with Soft Actor-Critic and Hindsight Relabeling**|Loris Gaven et.al.|[2410.12481v1](http://arxiv.org/abs/2410.12481v1)|null|
|**2024-10-16**|**KcMF: A Knowledge-compliant Framework for Schema and Entity Matching with Fine-tuning-free LLMs**|Yongqin Xu et.al.|[2410.12480v1](http://arxiv.org/abs/2410.12480v1)|null|
|**2024-10-16**|**MlingConf: A Comprehensive Study of Multilingual Confidence Estimation on Large Language Models**|Boyang Xue et.al.|[2410.12478v1](http://arxiv.org/abs/2410.12478v1)|null|
|**2024-10-16**|**Retrieval-Reasoning Large Language Model-based Synthetic Clinical Trial Generation**|Zerui Xu et.al.|[2410.12476v1](http://arxiv.org/abs/2410.12476v1)|null|
|**2024-10-16**|**Unifying Economic and Language Models for Enhanced Sentiment Analysis of the Oil Market**|Himmet Kaplan et.al.|[2410.12473v1](http://arxiv.org/abs/2410.12473v1)|null|
|**2024-10-16**|**Learning to Predict Usage Options of Product Reviews with LLM-Generated Labels**|Leo Kohlenberg et.al.|[2410.12470v1](http://arxiv.org/abs/2410.12470v1)|null|
|**2024-10-16**|**Evaluating Software Development Agents: Patch Patterns, Code Quality, and Issue Complexity in Real-World GitHub Scenarios**|Zhi Chen et.al.|[2410.12468v1](http://arxiv.org/abs/2410.12468v1)|null|
|**2024-10-16**|**Bridging the Language Gaps in Large Language Models with Inference-Time Cross-Lingual Intervention**|Weixuan Wang et.al.|[2410.12462v1](http://arxiv.org/abs/2410.12462v1)|null|
|**2024-10-16**|**The Best of Both Worlds: Bridging Quality and Diversity in Data Selection with Bipartite Graph**|Minghao Wu et.al.|[2410.12458v1](http://arxiv.org/abs/2410.12458v1)|null|
|**2024-10-16**|**Sharpness-Aware Black-Box Optimization**|Feiyang Ye et.al.|[2410.12457v1](http://arxiv.org/abs/2410.12457v1)|null|
|**2024-10-16**|**Open Ko-LLM Leaderboard2: Bridging Foundational and Practical Evaluation for Korean LLMs**|Hyeonwoo Kim et.al.|[2410.12445v1](http://arxiv.org/abs/2410.12445v1)|null|
|**2024-10-16**|**Expanding Chatbot Knowledge in Customer Service: Context-Aware Similar Question Generation Using Large Language Models**|Mengze Hong et.al.|[2410.12444v1](http://arxiv.org/abs/2410.12444v1)|null|
|**2024-10-16**|**Reconstruction of Differentially Private Text Sanitization via Large Language Models**|Shuchao Pang et.al.|[2410.12443v1](http://arxiv.org/abs/2410.12443v1)|null|
|**2024-10-16**|**Conformity in Large Language Models**|Xiaochen Zhu et.al.|[2410.12428v1](http://arxiv.org/abs/2410.12428v1)|null|
|**2024-10-16**|**Theoretical Analysis of Hierarchical Language Recognition and Generation by Transformers without Positional Encoding**|Daichi Hayakawa et.al.|[2410.12413v1](http://arxiv.org/abs/2410.12413v1)|null|
|**2024-10-16**|**Revealing the Barriers of Language Agents in Planning**|Jian Xie et.al.|[2410.12409v1](http://arxiv.org/abs/2410.12409v1)|null|
|**2024-10-16**|**Beyond Coarse-Grained Matching in Video-Text Retrieval**|Aozhu Chen et.al.|[2410.12407v1](http://arxiv.org/abs/2410.12407v1)|null|
|**2024-10-16**|**ProSA: Assessing and Understanding the Prompt Sensitivity of LLMs**|Jingming Zhuo et.al.|[2410.12405v1](http://arxiv.org/abs/2410.12405v1)|null|
|**2024-10-16**|**Tracking Universal Features Through Fine-Tuning and Model Merging**|Niels Horn et.al.|[2410.12391v1](http://arxiv.org/abs/2410.12391v1)|null|
|**2024-10-16**|**A Fast Convoluted Story: Scaling Probabilistic Inference for Integer Arithmetic**|Lennert De Smet et.al.|[2410.12389v1](http://arxiv.org/abs/2410.12389v1)|null|
|**2024-10-16**|**Prompt Compression for Large Language Models: A Survey**|Zongqian Li et.al.|[2410.12388v2](http://arxiv.org/abs/2410.12388v2)|[link](https://github.com/zongqianli/promptcompression-survey)|
|**2024-10-16**|**HumanEval-V: Evaluating Visual Understanding and Reasoning Abilities of Large Multimodal Models Through Coding Tasks**|Fengji Zhang et.al.|[2410.12381v1](http://arxiv.org/abs/2410.12381v1)|null|
|**2024-10-16**|**Evaluation of Attribution Bias in Retrieval-Augmented Large Language Models**|Amin Abolghasemi et.al.|[2410.12380v1](http://arxiv.org/abs/2410.12380v1)|null|
|**2024-10-16**|**HerO at AVeriTeC: The Herd of Open Large Language Models for Verifying Real-World Claims**|Yejun Yoon et.al.|[2410.12377v1](http://arxiv.org/abs/2410.12377v1)|null|
|**2024-10-16**|**ShapefileGPT: A Multi-Agent Large Language Model Framework for Automated Shapefile Processing**|Qingming Lin et.al.|[2410.12376v1](http://arxiv.org/abs/2410.12376v1)|null|
|**2024-10-16**|**PRefLexOR: Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking**|Markus J. Buehler et.al.|[2410.12375v1](http://arxiv.org/abs/2410.12375v1)|[link](https://github.com/lamm-mit/PRefLexOR)|
|**2024-10-16**|**Proactive Agent: Shifting LLM Agents from Reactive Responses to Active Assistance**|Yaxi Lu et.al.|[2410.12361v1](http://arxiv.org/abs/2410.12361v1)|null|
|**2024-10-16**|**Towards Neural Scaling Laws for Time Series Foundation Models**|Qingren Yao et.al.|[2410.12360v1](http://arxiv.org/abs/2410.12360v1)|null|
|**2024-10-16**|**GECTurk WEB: An Explainable Online Platform for Turkish Grammatical Error Detection and Correction**|Ali Gebeşçe et.al.|[2410.12350v1](http://arxiv.org/abs/2410.12350v1)|null|
|**2024-10-16**|**TAS: Distilling Arbitrary Teacher and Student via a Hybrid Assistant**|Guopeng Li et.al.|[2410.12342v1](http://arxiv.org/abs/2410.12342v1)|null|
|**2024-10-16**|**A linguistic analysis of undesirable outcomes in the era of generative AI**|Daniele Gambetta et.al.|[2410.12341v1](http://arxiv.org/abs/2410.12341v1)|null|
|**2024-10-16**|**Understanding the Role of LLMs in Multimodal Evaluation Benchmarks**|Botian Jiang et.al.|[2410.12329v1](http://arxiv.org/abs/2410.12329v1)|null|
|**2024-10-16**|**Neuron-based Personality Trait Induction in Large Language Models**|Jia Deng et.al.|[2410.12327v1](http://arxiv.org/abs/2410.12327v1)|null|
|**2024-10-16**|**Optimizing Low-Resource Language Model Training: Comprehensive Analysis of Multi-Epoch, Multi-Lingual, and Two-Stage Approaches**|Kosuke Akimoto et.al.|[2410.12325v1](http://arxiv.org/abs/2410.12325v1)|null|
|**2024-10-16**|**Reversal of Thought: Enhancing Large Language Models with Preference-Guided Reverse Reasoning Warm-up**|Jiahao Yuan et.al.|[2410.12323v1](http://arxiv.org/abs/2410.12323v1)|null|
|**2024-10-16**|**UTF:Undertrained Tokens as Fingerprints A Novel Approach to LLM Identification**|Jiacheng Cai et.al.|[2410.12318v1](http://arxiv.org/abs/2410.12318v1)|null|
|**2024-10-16**|**FaceChain-FACT: Face Adapter with Decoupled Training for Identity-preserved Personalization**|Cheng Yu et.al.|[2410.12312v1](http://arxiv.org/abs/2410.12312v1)|null|
|**2024-10-16**|**Open Domain Question Answering with Conflicting Contexts**|Siyi Liu et.al.|[2410.12311v1](http://arxiv.org/abs/2410.12311v1)|null|
|**2024-10-16**|**Semantics-Adaptive Activation Intervention for LLMs via Dynamic Steering Vectors**|Weixuan Wang et.al.|[2410.12299v1](http://arxiv.org/abs/2410.12299v1)|null|

#### Abstracts
##### **Context is Key(NMF): Modelling Topical Information Dynamics in Chinese Diaspora Media**
2410.12791v1 by Ross Deans Kristensen-McLachlan, Rebecca M. M. Hicke, Márton Kardos, Mette Thunø

Does the People's Republic of China (PRC) interfere with European elections
through ethnic Chinese diaspora media? This question forms the basis of an
ongoing research project exploring how PRC narratives about European elections
are represented in Chinese diaspora media, and thus the objectives of PRC news
media manipulation. In order to study diaspora media efficiently and at scale,
it is necessary to use techniques derived from quantitative text analysis, such
as topic modelling. In this paper, we present a pipeline for studying
information dynamics in Chinese media. Firstly, we present KeyNMF, a new
approach to static and dynamic topic modelling using transformer-based
contextual embedding models. We provide benchmark evaluations to demonstrate
that our approach is competitive on a number of Chinese datasets and metrics.
Secondly, we integrate KeyNMF with existing methods for describing information
dynamics in complex systems. We apply this pipeline to data from five news
sites, focusing on the period of time leading up to the 2024 European
parliamentary elections. Our methods and results demonstrate the effectiveness
of KeyNMF for studying information dynamics in Chinese media and lay groundwork
for further work addressing the broader research questions.

摘要：中华人民共和国（PRC）是否通过海外华文媒体干预欧洲选举？这个问题构成了一个正在进行的研究项目的基础，该项目探讨了有关欧洲选举的中华人民共和国叙述是如何在海外华文媒体中呈现的，以及中华人民共和国新闻媒体操纵的目标。为了有效且大规模地研究海外媒体，有必要使用源自定量文本分析的技术，例如主题建模。在本文中，我们提出了一个用于研究中文媒体中信息动态的管道。首先，我们提出了 KeyNMF，这是一种使用基于 Transformer 的上下文嵌入模型进行静态和动态主题建模的新方法。我们提供了基准评估来证明我们的方法在许多中文数据集和指标上具有竞争力。其次，我们将 KeyNMF 与描述复杂系统中信息动态的现有方法相集成。我们将此管道应用于来自五个新闻网站的数据，重点关注 2024 年欧洲议会选举前的这段时间。我们的方法和结果证明了 KeyNMF 在研究中文媒体中信息动态方面的有效性，并为进一步解决更广泛的研究问题奠定了基础。

##### **Meta-Chunking: Learning Efficient Text Segmentation via Logical Perception**
2410.12788v1 by Jihao Zhao, Zhiyuan Ji, Pengnian Qi, Simin Niu, Bo Tang, Feiyu Xiong, Zhiyu Li

Retrieval-Augmented Generation (RAG), while serving as a viable complement to
large language models (LLMs), often overlooks the crucial aspect of text
chunking within its pipeline, which impacts the quality of knowledge-intensive
tasks. This paper introduces the concept of Meta-Chunking, which refers to a
granularity between sentences and paragraphs, consisting of a collection of
sentences within a paragraph that have deep linguistic logical connections. To
implement Meta-Chunking, we designed two strategies based on LLMs: Margin
Sampling Chunking and Perplexity Chunking. The former employs LLMs to perform
binary classification on whether consecutive sentences need to be segmented,
making decisions based on the probability difference obtained from margin
sampling. The latter precisely identifies text chunk boundaries by analyzing
the characteristics of perplexity distribution. Additionally, considering the
inherent complexity of different texts, we propose a strategy that combines
Meta-Chunking with dynamic merging to achieve a balance between fine-grained
and coarse-grained text chunking. Experiments conducted on eleven datasets
demonstrate that Meta-Chunking can more efficiently improve the performance of
single-hop and multi-hop question answering based on RAG. For instance, on the
2WikiMultihopQA dataset, it outperforms similarity chunking by 1.32 while only
consuming 45.8% of the time. Our code is available at
https://github.com/IAAR-Shanghai/Meta-Chunking.

摘要：檢索增強生成 (RAG) 雖然是大型語言模型 (LLM) 的可行補充，但其管道中經常忽略文本分塊的關鍵方面，這會影響知識密集型任務的品質。本文介紹了元分塊的概念，它指的是句子和段落之間的粒度，由段落中具備深入語言邏輯關聯的一系列句子組成。為了實作元分塊，我們基於 LLM 設計了兩種策略：邊緣取樣分塊和困惑度分塊。前者採用 LLM 對連續的句子是否需要分段進行二元分類，根據邊緣取樣獲得的機率差異做出決策。後者透過分析困惑度分佈的特徵精確識別文本塊界線。此外，考量到不同文本的固有複雜性，我們提出了一種結合元分塊與動態合併的策略，以在細粒度和粗粒度文本分塊之間取得平衡。在 11 個資料集上進行的實驗證明，元分塊可以更有效地提升基於 RAG 的單跳和多跳問題解答效能。例如，在 2WikiMultihopQA 資料集上，它比相似性分塊高出 1.32 個百分點，同時僅耗費 45.8% 的時間。我們的程式碼可在 https://github.com/IAAR-Shanghai/Meta-Chunking 取得。

##### **JudgeBench: A Benchmark for Evaluating LLM-based Judges**
2410.12784v1 by Sijun Tan, Siyuan Zhuang, Kyle Montgomery, William Y. Tang, Alejandro Cuadron, Chenguang Wang, Raluca Ada Popa, Ion Stoica

LLM-based judges have emerged as a scalable alternative to human evaluation
and are increasingly used to assess, compare, and improve models. However, the
reliability of LLM-based judges themselves is rarely scrutinized. As LLMs
become more advanced, their responses grow more sophisticated, requiring
stronger judges to evaluate them. Existing benchmarks primarily focus on a
judge's alignment with human preferences, but often fail to account for more
challenging tasks where crowdsourced human preference is a poor indicator of
factual and logical correctness. To address this, we propose a novel evaluation
framework to objectively evaluate LLM-based judges. Based on this framework, we
propose JudgeBench, a benchmark for evaluating LLM-based judges on challenging
response pairs spanning knowledge, reasoning, math, and coding. JudgeBench
leverages a novel pipeline for converting existing difficult datasets into
challenging response pairs with preference labels reflecting objective
correctness. Our comprehensive evaluation on a collection of prompted judges,
fine-tuned judges, multi-agent judges, and reward models shows that JudgeBench
poses a significantly greater challenge than previous benchmarks, with many
strong models (e.g., GPT-4o) performing just slightly better than random
guessing. Overall, JudgeBench offers a reliable platform for assessing
increasingly advanced LLM-based judges. Data and code are available at
https://github.com/ScalerLab/JudgeBench .

摘要：<paragraph>基於 LLM 的評審已成為人類評估的可擴充替代方案，且愈來愈常被用於評估、比較和改善模型。然而，基於 LLM 的評審本身的可靠性卻鮮少受到審查。隨著 LLM 變得更先進，其回應也變得更複雜，需要更強大的評審來評估它們。現有的基準主要關注評審與人類偏好的吻合度，但通常無法考量更具挑戰性的任務，其中群眾外包的人類偏好是事實和邏輯正確性的不良指標。為了解決這個問題，我們提出一個新穎的評估架構，以客觀評估基於 LLM 的評審。根據這個架構，我們提出 JudgeBench，一個用於評估基於 LLM 的評審在跨越知識、推理、數學和編碼的具挑戰性回應配對上的基準。JudgeBench 藉由一個新穎的管道，將現有的困難資料集轉換成具挑戰性的回應配對，其中偏好標籤反映出客觀正確性。我們對一系列提示式評審、微調評審、多重代理評審和獎勵模型進行的全面評估顯示，JudgeBench 構成的挑戰顯著大於先前的基準，許多強大的模型（例如 GPT-4o）的表現僅比隨機猜測好一點。總體而言，JudgeBench 提供了一個可靠的平台，用於評估愈來愈先進的基於 LLM 的評審。資料和程式碼可於 https://github.com/ScalerLab/JudgeBench 取得。</paragraph>

##### **In-Context Learning Enables Robot Action Prediction in LLMs**
2410.12782v1 by Yida Yin, Zekai Wang, Yuvan Sharma, Dantong Niu, Trevor Darrell, Roei Herzig

Recently, Large Language Models (LLMs) have achieved remarkable success using
in-context learning (ICL) in the language domain. However, leveraging the ICL
capabilities within LLMs to directly predict robot actions remains largely
unexplored. In this paper, we introduce RoboPrompt, a framework that enables
off-the-shelf text-only LLMs to directly predict robot actions through ICL
without training. Our approach first heuristically identifies keyframes that
capture important moments from an episode. Next, we extract end-effector
actions from these keyframes as well as the estimated initial object poses, and
both are converted into textual descriptions. Finally, we construct a
structured template to form ICL demonstrations from these textual descriptions
and a task instruction. This enables an LLM to directly predict robot actions
at test time. Through extensive experiments and analysis, RoboPrompt shows
stronger performance over zero-shot and ICL baselines in simulated and
real-world settings.

摘要：近期，大型语言模型 (LLM) 在语言领域使用情境学习 (ICL) 取得了显著的成功。然而，利用 LLM 内的 ICL 能力直接预测机器人动作在很大程度上仍未得到探索。在本文中，我们介绍了 RoboPrompt，这是一个框架，它使现成的纯文本 LLM 能够通过 ICL 直接预测机器人动作，而无需训练。我们的方法首先启发式地识别关键帧，以捕捉剧集中的重要时刻。接下来，我们从这些关键帧中提取末端执行器动作以及估计的初始物体姿态，并将两者转换为文本描述。最后，我们构建了一个结构化模板，以根据这些文本描述和任务说明形成 ICL 演示。这使 LLM 能够在测试时直接预测机器人动作。通过广泛的实验和分析，RoboPrompt 在模拟和实际环境中显示出比零样本和 ICL 基线更强的性能。

##### **Meta-Unlearning on Diffusion Models: Preventing Relearning Unlearned Concepts**
2410.12777v1 by Hongcheng Gao, Tianyu Pang, Chao Du, Taihang Hu, Zhijie Deng, Min Lin

With the rapid progress of diffusion-based content generation, significant
efforts are being made to unlearn harmful or copyrighted concepts from
pretrained diffusion models (DMs) to prevent potential model misuse. However,
it is observed that even when DMs are properly unlearned before release,
malicious finetuning can compromise this process, causing DMs to relearn the
unlearned concepts. This occurs partly because certain benign concepts (e.g.,
"skin") retained in DMs are related to the unlearned ones (e.g., "nudity"),
facilitating their relearning via finetuning. To address this, we propose
meta-unlearning on DMs. Intuitively, a meta-unlearned DM should behave like an
unlearned DM when used as is; moreover, if the meta-unlearned DM undergoes
malicious finetuning on unlearned concepts, the related benign concepts
retained within it will be triggered to self-destruct, hindering the relearning
of unlearned concepts. Our meta-unlearning framework is compatible with most
existing unlearning methods, requiring only the addition of an
easy-to-implement meta objective. We validate our approach through empirical
experiments on meta-unlearning concepts from Stable Diffusion models (SD-v1-4
and SDXL), supported by extensive ablation studies. Our code is available at
https://github.com/sail-sg/Meta-Unlearning.

摘要：<paragraph>隨著基於擴散的內容生成技術的快速進展，人們正致力於解除預訓練擴散模型 (DM) 中有害或受版權保護的概念，以防止潛在的模型誤用。然而，觀察發現，即使在 DM 在發布前已適當地解除學習，惡意的微調仍可能損害此程序，導致 DM 重新學習已解除學習的概念。這部分是因為 DM 中保留的某些良性概念（例如「皮膚」）與已解除學習的概念（例如「裸露」）相關，從而通過微調促進它們的重新學習。為了解決這個問題，我們提出對 DM 進行元解除學習。直觀地說，一個經過元解除學習的 DM 在按原樣使用時應該表現得像一個未解除學習的 DM；此外，如果經過元解除學習的 DM 對未解除學習的概念進行惡意微調，其中保留的相關良性概念將被觸發自毀，從而阻礙重新學習未解除學習的概念。我們的元解除學習框架與大多數現有的解除學習方法相容，只需要新增一個易於實現的元目標。我們通過對 Stable Diffusion 模型（SD-v1-4 和 SDXL）的元解除學習概念進行實證實驗來驗證我們的做法，並得到廣泛的消融研究的支援。我們的程式碼可在 https://github.com/sail-sg/Meta-Unlearning 取得。</paragraph>

##### **Identifying Task Groupings for Multi-Task Learning Using Pointwise V-Usable Information**
2410.12774v1 by Yingya Li, Timothy Miller, Steven Bethard, Guergana Savova

The success of multi-task learning can depend heavily on which tasks are
grouped together. Naively grouping all tasks or a random set of tasks can
result in negative transfer, with the multi-task models performing worse than
single-task models. Though many efforts have been made to identify task
groupings and to measure the relatedness among different tasks, it remains a
challenging research topic to define a metric to identify the best task
grouping out of a pool of many potential task combinations. We propose a metric
of task relatedness based on task difficulty measured by pointwise V-usable
information (PVI). PVI is a recently proposed metric to estimate how much
usable information a dataset contains given a model. We hypothesize that tasks
with not statistically different PVI estimates are similar enough to benefit
from the joint learning process. We conduct comprehensive experiments to
evaluate the feasibility of this metric for task grouping on 15 NLP datasets in
the general, biomedical, and clinical domains. We compare the results of the
joint learners against single learners, existing baseline methods, and recent
large language models, including Llama 2 and GPT-4. The results show that by
grouping tasks with similar PVI estimates, the joint learners yielded
competitive results with fewer total parameters, with consistent performance
across domains.

摘要：多任務學習的成功很大程度上取決於將哪些任務分組在一起。天真地將所有任務或一組隨機任務分組可能會導致負向遷移，多任務模型的表現會比單任務模型差。儘管已做出許多努力來識別任務分組並衡量不同任務之間的關聯性，但定義一個指標以從許多潛在任務組合中識別出最佳任務分組仍然是一個具有挑戰性的研究課題。我們提出了一個基於點式 V 可用資訊 (PVI) 衡量的任務難度來衡量任務相關性的指標。PVI 是一個最近提出的指標，用於估計給定模型資料集包含多少可用資訊。我們假設 PVI 估計在統計上沒有差異的任務足夠相似，可以從聯合學習過程中受益。我們進行了全面的實驗，以評估此指標在 15 個一般、生物醫學和臨床領域的 NLP 資料集上進行任務分組的可行性。我們將聯合學習者的結果與單一學習者、現有的基準方法和最近的大語言模型（包括 Llama 2 和 GPT-4）進行比較。結果表明，通過將具有相似 PVI 估計值的任務分組，聯合學習者以較少的總參數產生了具有競爭力的結果，並且在各個領域中表現一致。

##### **Harmon: Whole-Body Motion Generation of Humanoid Robots from Language Descriptions**
2410.12773v1 by Zhenyu Jiang, Yuqi Xie, Jinhan Li, Ye Yuan, Yifeng Zhu, Yuke Zhu

Humanoid robots, with their human-like embodiment, have the potential to
integrate seamlessly into human environments. Critical to their coexistence and
cooperation with humans is the ability to understand natural language
communications and exhibit human-like behaviors. This work focuses on
generating diverse whole-body motions for humanoid robots from language
descriptions. We leverage human motion priors from extensive human motion
datasets to initialize humanoid motions and employ the commonsense reasoning
capabilities of Vision Language Models (VLMs) to edit and refine these motions.
Our approach demonstrates the capability to produce natural, expressive, and
text-aligned humanoid motions, validated through both simulated and real-world
experiments. More videos can be found at
https://ut-austin-rpl.github.io/Harmon/.

摘要：類人機器人，具有類人的體現，具有無縫整合到人類環境中的潛力。對於它們與人類的共存和合作至關重要的是理解自然語言溝通並表現出類人的行為的能力。這項工作重點在於根據語言描述為類人機器人產生多樣化的全身動作。我們利用來自廣泛人類動作數據集的人類動作先驗來初始化類人動作，並採用 Vision Language Models (VLMs) 的常識推理能力來編輯和完善這些動作。我們的做法展示了產生自然、富有表現力和與文本對齊的類人動作的能力，通過模擬和現實世界的實驗得到驗證。更多影片可以在 https://ut-austin-rpl.github.io/Harmon/ 找到。

##### **Vaccinating Federated Learning for Robust Modulation Classification in Distributed Wireless Networks**
2410.12772v1 by Hunmin Lee, Hongju Seong, Wonbin Kim, Hyeokchan Kwon, Daehee Seo

Automatic modulation classification (AMC) serves a vital role in ensuring
efficient and reliable communication services within distributed wireless
networks. Recent developments have seen a surge in interest in deep neural
network (DNN)-based AMC models, with Federated Learning (FL) emerging as a
promising framework. Despite these advancements, the presence of various noises
within the signal exerts significant challenges while optimizing models to
capture salient features. Furthermore, existing FL-based AMC models commonly
rely on linear aggregation strategies, which face notable difficulties in
integrating locally fine-tuned parameters within practical non-IID (Independent
and Identically Distributed) environments, thereby hindering optimal learning
convergence. To address these challenges, we propose FedVaccine, a novel FL
model aimed at improving generalizability across signals with varying noise
levels by deliberately introducing a balanced level of noise. This is
accomplished through our proposed harmonic noise resilience approach, which
identifies an optimal noise tolerance for DNN models, thereby regulating the
training process and mitigating overfitting. Additionally, FedVaccine overcomes
the limitations of existing FL-based AMC models' linear aggregation by
employing a split-learning strategy using structural clustering topology and
local queue data structure, enabling adaptive and cumulative updates to local
models. Our experimental results, including IID and non-IID datasets as well as
ablation studies, confirm FedVaccine's robust performance and superiority over
existing FL-based AMC approaches across different noise levels. These findings
highlight FedVaccine's potential to enhance the reliability and performance of
AMC systems in practical wireless network environments.

摘要：<paragraph>自動調變分類 (AMC) 在確保分布式無線網路中的通訊服務有效率且可靠方面扮演至關重要的角色。近期發展已看到對基於深度神經網路 (DNN) 的 AMC 模型的興趣激增，其中聯合學習 (FL) 成為一個有前途的架構。儘管有這些進展，但訊號中存在各種雜訊在最佳化模型以擷取顯著特徵時造成重大挑戰。此外，現有的基於 FL 的 AMC 模型通常依賴線性聚合策略，在整合實際非 IID（獨立且同分布）環境中的局部微調參數時面臨顯著困難，從而阻礙最佳學習收斂。為了應對這些挑戰，我們提出 FedVaccine，一種新的 FL 模型，旨在透過刻意引入平衡程度的雜訊來改善不同雜訊層級訊號間的泛化能力。這透過我們提出的諧波雜訊復原力方法來達成，該方法識別 DNN 模型的最佳雜訊容忍度，從而規範訓練過程並減輕過度擬合。此外，FedVaccine 透過使用結構化叢集拓撲和局部佇列資料結構來採用分割學習策略，克服現有基於 FL 的 AMC 模型線性聚合的限制，讓局部模型能夠進行適應性和累積性更新。我們的實驗結果，包括 IID 和非 IID 資料集以及消融研究，確認 FedVaccine 在不同雜訊層級中表現強健，且優於現有的基於 FL 的 AMC 方法。這些發現突顯 FedVaccine 提升實際無線網路環境中 AMC 系統可靠性和效能的潛力。</paragraph>

##### **Open Materials 2024 (OMat24) Inorganic Materials Dataset and Models**
2410.12771v1 by Luis Barroso-Luque, Muhammed Shuaibi, Xiang Fu, Brandon M. Wood, Misko Dzamba, Meng Gao, Ammar Rizvi, C. Lawrence Zitnick, Zachary W. Ulissi

The ability to discover new materials with desirable properties is critical
for numerous applications from helping mitigate climate change to advances in
next generation computing hardware. AI has the potential to accelerate
materials discovery and design by more effectively exploring the chemical space
compared to other computational methods or by trial-and-error. While
substantial progress has been made on AI for materials data, benchmarks, and
models, a barrier that has emerged is the lack of publicly available training
data and open pre-trained models. To address this, we present a Meta FAIR
release of the Open Materials 2024 (OMat24) large-scale open dataset and an
accompanying set of pre-trained models. OMat24 contains over 110 million
density functional theory (DFT) calculations focused on structural and
compositional diversity. Our EquiformerV2 models achieve state-of-the-art
performance on the Matbench Discovery leaderboard and are capable of predicting
ground-state stability and formation energies to an F1 score above 0.9 and an
accuracy of 20 meV/atom, respectively. We explore the impact of model size,
auxiliary denoising objectives, and fine-tuning on performance across a range
of datasets including OMat24, MPtraj, and Alexandria. The open release of the
OMat24 dataset and models enables the research community to build upon our
efforts and drive further advancements in AI-assisted materials science.

摘要：發現具有理想特性的新材料的能力對於從幫助減緩氣候變遷到推進下一代運算硬體的眾多應用至關重要。與其他運算方法或試錯法相比，人工智慧有潛力透過更有效地探索化學空間來加速材料發現和設計。儘管在材料資料、基準和模型方面的人工智慧已取得實質進展，但出現了一個障礙，那就是缺乏公開可用的訓練資料和開放的預訓練模型。為了解決這個問題，我們提出了 Meta FAIR 發布的開放材料 2024 (OMat24) 大型開放資料集和一組配套的預訓練模型。OMat24 包含超過 1.1 億個密度泛函理論 (DFT) 計算，重點在於結構和組成多樣性。我們的 EquiformerV2 模型在 Matbench Discovery 排行榜上取得了最先進的效能，並且能夠預測基態穩定性和形成能，分別達到 0.9 以上的 F1 分數和 20 meV/atom 的準確度。我們探討了模型大小、輔助去噪目標和微調對 OMat24、MPtraj 和 Alexandria 等一系列資料集效能的影響。OMat24 資料集和模型的開放發布使研究社群能夠建立在我們的努力之上，並推動人工智慧輔助材料科學的進一步發展。

##### **SAFREE: Training-Free and Adaptive Guard for Safe Text-to-Image And Video Generation**
2410.12761v1 by Jaehong Yoon, Shoubin Yu, Vaidehi Patil, Huaxiu Yao, Mohit Bansal

Recent advances in diffusion models have significantly enhanced their ability
to generate high-quality images and videos, but they have also increased the
risk of producing unsafe content. Existing unlearning/editing-based methods for
safe generation remove harmful concepts from models but face several
challenges: (1) They cannot instantly remove harmful concepts without training.
(2) Their safe generation capabilities depend on collected training data. (3)
They alter model weights, risking degradation in quality for content unrelated
to toxic concepts. To address these, we propose SAFREE, a novel, training-free
approach for safe T2I and T2V, that does not alter the model's weights.
Specifically, we detect a subspace corresponding to a set of toxic concepts in
the text embedding space and steer prompt embeddings away from this subspace,
thereby filtering out harmful content while preserving intended semantics. To
balance the trade-off between filtering toxicity and preserving safe concepts,
SAFREE incorporates a novel self-validating filtering mechanism that
dynamically adjusts the denoising steps when applying the filtered embeddings.
Additionally, we incorporate adaptive re-attention mechanisms within the
diffusion latent space to selectively diminish the influence of features
related to toxic concepts at the pixel level. In the end, SAFREE ensures
coherent safety checking, preserving the fidelity, quality, and safety of the
output. SAFREE achieves SOTA performance in suppressing unsafe content in T2I
generation compared to training-free baselines and effectively filters targeted
concepts while maintaining high-quality images. It also shows competitive
results against training-based methods. We extend SAFREE to various T2I
backbones and T2V tasks, showcasing its flexibility and generalization. SAFREE
provides a robust and adaptable safeguard for ensuring safe visual generation.

摘要：最近擴散模型的進展顯著提升了它們生成高品質影像和影片的能力，但它們也增加了產生不安全內容的風險。現有的基於遺忘/編輯的方法用於安全生成，會從模型中移除有害的概念，但面臨幾個挑戰：(1) 它們無法在沒有訓練的情況下立即移除有害概念。(2) 它們的安全生成能力取決於收集到的訓練資料。(3) 它們會改變模型權重，冒著與有毒概念無關的內容品質下降的風險。為了解決這些問題，我們提出 SAFREE，一種新穎的、免訓練的安全 T2I 和 T2V 方法，不會改變模型的權重。具體來說，我們在文字嵌入空間中偵測一個對應於一組有毒概念的子空間，並引導提示嵌入遠離這個子空間，從而過濾掉有害內容，同時保留預期的語義。為了平衡過濾毒性和保留安全概念之間的取捨，SAFREE 結合了一種新穎的自驗證過濾機制，在應用過濾嵌入時動態調整去噪步驟。此外，我們在擴散潛在空間中結合了自適應重新注意機制，以選擇性地減弱與像素級別的有毒概念相關特徵的影響。最後，SAFREE 確保了一致的安全檢查，保留了輸出的保真度、品質和安全性。與免訓練基線相比，SAFREE 在抑制 T2I 生成中的不安全內容方面實現了 SOTA 效能，並有效過濾目標概念，同時保持高品質的影像。它也顯示出與基於訓練的方法相比具有競爭力的結果。我們將 SAFREE 延伸到各種 T2I 主幹和 T2V 任務，展示了它的靈活性與泛化性。SAFREE 為確保安全的視覺生成提供了一個強健且適應性強的保障。

##### **Unitary Multi-Margin BERT for Robust Natural Language Processing**
2410.12759v1 by Hao-Yuan Chang, Kang L. Wang

Recent developments in adversarial attacks on deep learning leave many
mission-critical natural language processing (NLP) systems at risk of
exploitation. To address the lack of computationally efficient adversarial
defense methods, this paper reports a novel, universal technique that
drastically improves the robustness of Bidirectional Encoder Representations
from Transformers (BERT) by combining the unitary weights with the multi-margin
loss. We discover that the marriage of these two simple ideas amplifies the
protection against malicious interference. Our model, the unitary multi-margin
BERT (UniBERT), boosts post-attack classification accuracies significantly by
5.3% to 73.8% while maintaining competitive pre-attack accuracies. Furthermore,
the pre-attack and post-attack accuracy tradeoff can be adjusted via a single
scalar parameter to best fit the design requirements for the target
applications.

摘要：深度學習中對抗攻擊的最新發展讓許多任務關鍵的自然語言處理 (NLP) 系統面臨被利用的風險。為了解決缺乏計算效率高的對抗防禦方法，本文報告了一種新穎、通用的技術，它透過結合單元權重和多邊界損失，大幅提升了來自 Transformer 的雙向編碼器表示 (BERT) 的穩健性。我們發現這兩個簡單想法的結合放大了對惡意干擾的防護。我們的模型，單元多邊界 BERT (UniBERT)，將後攻擊分類準確率大幅提升了 5.3% 至 73.8%，同時維持有競爭力的前攻擊準確率。此外，前攻擊和後攻擊準確率的權衡可以透過單一標量參數進行調整，以最佳符合目標應用程式的設計需求。

##### **StyleDistance: Stronger Content-Independent Style Embeddings with Synthetic Parallel Examples**
2410.12757v1 by Ajay Patel, Jiacheng Zhu, Justin Qiu, Zachary Horvitz, Marianna Apidianaki, Kathleen McKeown, Chris Callison-Burch

Style representations aim to embed texts with similar writing styles closely
and texts with different styles far apart, regardless of content. However, the
contrastive triplets often used for training these representations may vary in
both style and content, leading to potential content leakage in the
representations. We introduce StyleDistance, a novel approach to training
stronger content-independent style embeddings. We use a large language model to
create a synthetic dataset of near-exact paraphrases with controlled style
variations, and produce positive and negative examples across 40 distinct style
features for precise contrastive learning. We assess the quality of our
synthetic data and embeddings through human and automatic evaluations.
StyleDistance enhances the content-independence of style embeddings, which
generalize to real-world benchmarks and outperform leading style
representations in downstream applications. Our model can be found at
https://huggingface.co/StyleDistance/styledistance .

摘要：風格表示旨在將具有相似寫作風格的文本緊密嵌入，而將具有不同風格的文本遠遠分開，而不管內容如何。然而，通常用於訓練這些表示的對比三元組可能在風格和內容上有所不同，從而導致表示中潛在的內容洩漏。我們引入了 StyleDistance，這是一種訓練更強大的與內容無關的風格嵌入的新方法。我們使用一個大型語言模型來創建一個具有受控風格變化的近似同義詞的合成數據集，並針對 40 個不同的風格特徵產生正例和反例，以進行精確的對比學習。我們通過人工和自動評估來評估我們合成數據和嵌入的質量。StyleDistance 增強了風格嵌入的內容獨立性，它可以推廣到現實世界的基準，並且在下游應用中優於領先的風格表示。我們的模型可以在 https://huggingface.co/StyleDistance/styledistance 找到。

##### **Comparative Analysis of Extrinsic Factors for NER in French**
2410.12750v1 by Grace Yang, Zhiyi Li, Yandong Liu, Jungyeul Park

Named entity recognition (NER) is a crucial task that aims to identify
structured information, which is often replete with complex, technical terms
and a high degree of variability. Accurate and reliable NER can facilitate the
extraction and analysis of important information. However, NER for other than
English is challenging due to limited data availability, as the high expertise,
time, and expenses are required to annotate its data. In this paper, by using
the limited data, we explore various factors including model structure, corpus
annotation scheme and data augmentation techniques to improve the performance
of a NER model for French. Our experiments demonstrate that these approaches
can significantly improve the model's F1 score from original CRF score of 62.41
to 79.39. Our findings suggest that considering different extrinsic factors and
combining these techniques is a promising approach for improving NER
performance where the size of data is limited.

摘要：命名實體辨識 (NER) 是一項關鍵的任務，旨在辨識結構化的資訊，這些資訊通常充斥著複雜的技術術語和高度的可變性。準確且可靠的 NER 能夠促進重要資訊的萃取和分析。然而，除了英文之外的 NER 具有挑戰性，因為資料的取得有限，而且標註資料需要高度的專業知識、時間和金錢成本。在本文中，我們透過使用有限的資料，探討各種因素，包括模型結構、語料標註方案和資料擴充技術，以提升法語 NER 模型的效能。我們的實驗證明，這些方法可以顯著地提升模型的 F1 分數，從原本的 CRF 分數 62.41 提升至 79.39。我們的研究結果顯示，考慮不同的外在因素並結合這些技術，對於提升資料量有限情況下的 NER 效能而言是一種有前途的方法。

##### **CREAM: Consistency Regularized Self-Rewarding Language Models**
2410.12735v2 by Zhaoyang Wang, Weilei He, Zhiyuan Liang, Xuchao Zhang, Chetan Bansal, Ying Wei, Weitong Zhang, Huaxiu Yao

Recent self-rewarding large language models (LLM) have successfully applied
LLM-as-a-Judge to iteratively improve the alignment performance without the
need of human annotations for preference data. These methods commonly utilize
the same LLM to act as both the policy model (which generates responses) and
the reward model (which scores and ranks those responses). The ranked responses
are then used as preference pairs to train the LLM via direct alignment
technologies (e.g. DPO). However, it is noteworthy that throughout this
process, there is no guarantee of accuracy in the rewarding and ranking, which
is critical for ensuring accurate rewards and high-quality preference data.
Empirical results from relatively small LLMs (e.g., 7B parameters) also
indicate that improvements from self-rewarding may diminish after several
iterations in certain situations, which we hypothesize is due to accumulated
bias in the reward system. This bias can lead to unreliable preference data for
training the LLM. To address this issue, we first formulate and analyze the
generalized iterative preference fine-tuning framework for self-rewarding
language model. We then introduce the regularization to this generalized
framework to mitigate the overconfident preference labeling in the
self-rewarding process. Based on this theoretical insight, we propose a
Consistency Regularized sElf-rewarding lAnguage Model (CREAM) that leverages
the rewarding consistency across different iterations to regularize the
self-rewarding training, helping the model to learn from more reliable
preference data. With this explicit regularization, our empirical results
demonstrate the superiority of CREAM in improving both reward consistency and
alignment performance. The code is publicly available at
https://github.com/Raibows/CREAM.

摘要：<paragraph>最近的自獎勵大型語言模型 (LLM) 已成功應用 LLM-as-a-Judge 迭代改善比對效能，無需人工標註偏好資料。這些方法通常利用相同的 LLM 作為政策模型 (產生回應) 和獎勵模型 (評分和排名這些回應)。排名後的回應接著用作偏好對，透過直接比對技術 (例如 DPO) 來訓練 LLM。然而，值得注意的是，在整個過程中，獎勵和排名並無保證準確，這對於確保準確的獎勵和高品質的偏好資料至關重要。來自相對較小 LLM (例如 7B 參數) 的經驗結果也顯示，在某些情況下，經過幾次迭代後，自獎勵的改善可能減弱，我們假設這是由於獎勵系統中累積的偏差。此偏差可能導致用於訓練 LLM 的偏好資料不可靠。為了解決此問題，我們首先制定並分析自獎勵語言模型的廣義迭代偏好微調架構。然後，我們將正則化引入此廣義架構，以減輕自獎勵過程中過度自信的偏好標籤。根據此理論見解，我們提出了一致性正則化自我獎勵語言模型 (CREAM)，它利用不同迭代間的獎勵一致性來正則化自獎勵訓練，幫助模型從更可靠的偏好資料中學習。透過此明確的正則化，我們的經驗結果證明 CREAM 在改善獎勵一致性和比對效能方面具有優越性。程式碼已公開於 https://github.com/Raibows/CREAM。</paragraph>

##### **Counterfactual Generative Modeling with Variational Causal Inference**
2410.12730v1 by Yulun Wu, Louie McConnell, Claudia Iriondo

Estimating an individual's potential outcomes under counterfactual treatments
is a challenging task for traditional causal inference and supervised learning
approaches when the outcome is high-dimensional (e.g. gene expressions, facial
images) and covariates are relatively limited. In this case, to predict one's
outcomes under counterfactual treatments, it is crucial to leverage individual
information contained in its high-dimensional observed outcome in addition to
the covariates. Prior works using variational inference in counterfactual
generative modeling have been focusing on neural adaptations and model variants
within the conditional variational autoencoder formulation, which we argue is
fundamentally ill-suited to the notion of counterfactual in causal inference.
In this work, we present a novel variational Bayesian causal inference
framework and its theoretical backings to properly handle counterfactual
generative modeling tasks, through which we are able to conduct counterfactual
supervision end-to-end during training without any counterfactual samples, and
encourage latent disentanglement that aids the correct identification of causal
effect in counterfactual generations. In experiments, we demonstrate the
advantage of our framework compared to state-of-the-art models in
counterfactual generative modeling on multiple benchmarks.

摘要：在結果為高維度（例如基因表達、人臉影像）且協變數相對有限時，估計個體在反事實處理下的潛在結果，對於傳統因果推論和監督式學習方法而言是一項艱鉅的任務。在這種情況下，為了預測某人在反事實處理下的結果，除了協變數外，還必須利用其高維度觀察結果中包含的個別資訊。先前使用變異推論在反事實生成式建模中的研究，一直專注於條件變異自動編碼器公式中的神經適應和模型變異，我們認為這從根本上不適合因果推論中的反事實概念。在這項研究中，我們提出了一個新穎的變異貝氏因果推論架構及其理論基礎，以適當處理反事實生成式建模任務，透過這個架構，我們能夠在訓練過程中進行反事實監督，而無需任何反事實樣本，並鼓勵潛在解開，有助於正確識別反事實生成中的因果效應。在實驗中，我們展示了我們架構的優點，與最先進的模型相比，在多個基準上進行反事實生成式建模。

##### **Transformer based super-resolution downscaling for regional reanalysis: Full domain vs tiling approaches**
2410.12728v1 by Antonio Pérez, Mario Santa Cruz, Daniel San Martín, José Manuel Gutiérrez

Super-resolution (SR) is a promising cost-effective downscaling methodology
for producing high-resolution climate information from coarser counterparts. A
particular application is downscaling regional reanalysis outputs (predictand)
from the driving global counterparts (predictor). This study conducts an
intercomparison of various SR downscaling methods focusing on temperature and
using the CERRA reanalysis (5.5 km resolution, produced with a regional
atmospheric model driven by ERA5) as example. The method proposed in this work
is the Swin transformer and two alternative methods are used as benchmark
(fully convolutional U-Net and convolutional and dense DeepESD) as well as the
simple bicubic interpolation. We compare two approaches, the standard one using
the full domain as input and a more scalable tiling approach, dividing the full
domain into tiles that are used as input. The methods are trained to downscale
CERRA surface temperature, based on temperature information from the driving
ERA5; in addition, the tiling approach includes static orographic information.
We show that the tiling approach, which requires spatial transferability, comes
at the cost of a lower performance (although it outperforms some full-domain
benchmarks), but provides an efficient scalable solution that allows SR
reduction on a pan-European scale and is valuable for real-time applications.

摘要：超解析度 (SR) 是一種有前途且具成本效益的降採樣方法，可根據較粗略的對應資料產生高解析度的氣候資訊。一種特定應用是將區域再分析輸出 (預測值) 從驅動的全球對應資料 (預測器) 降採樣。本研究針對各種 SR 降採樣方法進行比對，重點在於溫度，並以 CERRA 再分析 (5.5 公里解析度，由區域大氣模式驅動，ERA5 產生) 為例。本研究提出的方法是 Swin Transformer，並使用兩種替代方法作為基準 (全卷積 U-Net 及卷積和密集 DeepESD)，以及簡單的雙三次插值。我們比較兩種方法，一種是使用完整網域作為輸入的標準方法，另一種是更具可擴充性的切片方法，將完整網域分割成用作輸入的切片。這些方法經過訓練，可根據驅動 ERA5 的溫度資訊，將 CERRA 地表溫度降採樣；此外，切片方法包括靜態地形資訊。我們顯示，需要空間可傳輸性的切片方法，會以較低效能為代價 (雖然它優於某些完整網域基準)，但提供了有效的可擴充性解決方案，允許在泛歐洲規模上進行 SR 縮減，並對即時應用有價值。

##### **WorldMedQA-V: a multilingual, multimodal medical examination dataset for multimodal language models evaluation**
2410.12722v1 by João Matos, Shan Chen, Siena Placino, Yingya Li, Juan Carlos Climent Pardo, Daphna Idan, Takeshi Tohyama, David Restrepo, Luis F. Nakayama, Jose M. M. Pascual-Leone, Guergana Savova, Hugo Aerts, Leo A. Celi, A. Ian Wong, Danielle S. Bitterman, Jack Gallifant

Multimodal/vision language models (VLMs) are increasingly being deployed in
healthcare settings worldwide, necessitating robust benchmarks to ensure their
safety, efficacy, and fairness. Multiple-choice question and answer (QA)
datasets derived from national medical examinations have long served as
valuable evaluation tools, but existing datasets are largely text-only and
available in a limited subset of languages and countries. To address these
challenges, we present WorldMedQA-V, an updated multilingual, multimodal
benchmarking dataset designed to evaluate VLMs in healthcare. WorldMedQA-V
includes 568 labeled multiple-choice QAs paired with 568 medical images from
four countries (Brazil, Israel, Japan, and Spain), covering original languages
and validated English translations by native clinicians, respectively. Baseline
performance for common open- and closed-source models are provided in the local
language and English translations, and with and without images provided to the
model. The WorldMedQA-V benchmark aims to better match AI systems to the
diverse healthcare environments in which they are deployed, fostering more
equitable, effective, and representative applications.

摘要：多模态/视觉语言模型 (VLM) 正越来越多地部署在全球医疗环境中，因此需要稳健的基准来确保其安全性、有效性和公平性。从国家医学考试中衍生的多项选择问答 (QA) 数据集长期以来一直作为有价值的评估工具，但现有数据集在很大程度上仅限于文本，并且仅在有限的语言和国家/地区中可用。为了应对这些挑战，我们提出了 WorldMedQA-V，这是一个更新的多语言、多模态基准数据集，旨在评估医疗保健中的 VLM。WorldMedQA-V 包括 568 个标记的多项选择问答，以及来自巴西、以色列、日本和西班牙四个国家的 568 张医学图像，涵盖原始语言和经过当地临床医生验证的英语翻译。常见开放源代码和闭源代码模型的基线性能以当地语言和英语翻译提供，并根据是否向模型提供图像而提供。WorldMedQA-V 基准旨在更好地将人工智能系统与部署它们的各种医疗保健环境相匹配，从而促进更公平、更有效和更具代表性的应用程序。

##### **HEnRY: A Multi-Agent System Framework for Multi-Domain Contexts**
2410.12720v1 by Emmanuele Lacavalla, Shuyi Yang, Riccardo Crupi, Joseph E. Gonzalez

This project, named HEnRY, aims to introduce a Multi-Agent System (MAS) into
Intesa Sanpaolo. The name HEnRY summarizes the project's core principles: the
Hierarchical organization of agents in a layered structure for efficient
resource management; Efficient optimization of resources and operations to
enhance overall performance; Reactive ability of agents to quickly respond to
environmental stimuli; and Yielding adaptability and flexibility of agents to
handle unexpected situations. The discussion covers two distinct research
paths: the first focuses on the system architecture, and the second on the
collaboration between agents. This work is not limited to the specific
structure of the Intesa Sanpaolo context; instead, it leverages existing
research in MAS to introduce a new solution. Since Intesa Sanpaolo is organized
according to a model that aligns with international corporate governance best
practices, this approach could also be relevant to similar scenarios.

摘要：此專案名為 HEnRY，旨在為 Intesa Sanpaolo 引入多代理系統 (MAS)。HEnRY 這個名稱總結了專案的核心原則：以分層結構分層組織代理，以有效管理資源；有效最佳化資源和作業，以提升整體效能；代理的反應能力，能快速回應環境刺激；以及代理的適應力和靈活性，以處理意外情況。討論涵蓋兩條不同的研究途徑：第一個專注於系統架構，第二個專注於代理之間的協作。這項工作不限於 Intesa Sanpaolo 背景的特定結構；相反地，它利用 MAS 中現有的研究來引進新的解決方案。由於 Intesa Sanpaolo 的組織方式符合國際公司治理最佳實務，因此此方法也可能與類似情境相關。

##### **FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression**
2410.12707v1 by Zhenheng Tang, Xueze Kang, Yiming Yin, Xinglin Pan, Yuxin Wang, Xin He, Qiang Wang, Rongfei Zeng, Kaiyong Zhao, Shaohuai Shi, Amelie Chi Zhou, Bo Li, Bingsheng He, Xiaowen Chu

To alleviate hardware scarcity in training large deep neural networks (DNNs),
particularly large language models (LLMs), we present FusionLLM, a
decentralized training system designed and implemented for training DNNs using
geo-distributed GPUs across different computing clusters or individual devices.
Decentralized training faces significant challenges regarding system design and
efficiency, including: 1) the need for remote automatic differentiation (RAD),
2) support for flexible model definitions and heterogeneous software, 3)
heterogeneous hardware leading to low resource utilization or the straggler
problem, and 4) slow network communication. To address these challenges, in the
system design, we represent the model as a directed acyclic graph of operators
(OP-DAG). Each node in the DAG represents the operator in the DNNs, while the
edge represents the data dependency between operators. Based on this design, 1)
users are allowed to customize any DNN without caring low-level operator
implementation; 2) we enable the task scheduling with the more fine-grained
sub-tasks, offering more optimization space; 3) a DAG runtime executor can
implement RAD withour requiring the consistent low-level ML framework versions.
  To enhance system efficiency, we implement a workload estimator and design an
OP-Fence scheduler to cluster devices with similar bandwidths together and
partition the DAG to increase throughput. Additionally, we propose an AdaTopK
compressor to adaptively compress intermediate activations and gradients at the
slowest communication links. To evaluate the convergence and efficiency of our
system and algorithms, we train ResNet-101 and GPT-2 on three real-world
testbeds using 48 GPUs connected with 8 Mbps~10 Gbps networks. Experimental
results demonstrate that our system and method can achieve 1.45 - 9.39x speedup
compared to baseline methods while ensuring convergence.

摘要：<paragraph>為了減輕訓練大型深度神經網路 (DNN) 的硬體短缺問題，尤其是大型語言模型 (LLM)，我們提出了 FusionLLM，一個分散式訓練系統，其設計和實作是用於訓練跨不同運算叢集或個別裝置的地理分散式 GPU 的 DNN。分散式訓練在系統設計和效率方面面臨重大挑戰，包括：1) 需要遠端自動微分 (RAD)，2) 支援彈性的模型定義和異質軟體，3) 異質硬體導致資源利用率低或落後問題，以及 4) 網路通訊速度慢。為了應對這些挑戰，在系統設計中，我們將模型表示為一個有向非循環圖 (OP-DAG) 的運算子。DAG 中的每個節點代表 DNN 中的運算子，而邊緣代表運算子之間的資料依賴性。基於此設計，1) 使用者可以自訂任何 DNN，而不用考慮低階運算子實作；2) 我們啟用任務排程，並使用更細緻的子任務，提供更多最佳化空間；3) DAG 執行時間執行器可以實作 RAD，而不需要一致的低階 ML 架構版本。為了提升系統效率，我們實作一個工作負載估計器，並設計一個 OP-Fence 排程器，將頻寬類似的裝置分組在一起，並分割 DAG 以增加處理量。此外，我們提出一個 AdaTopK 壓縮器，以自適應方式壓縮最慢通訊連結上的中間啟動和梯度。為了評估我們系統和演算法的收斂性和效率，我們在三個真實世界的測試平台上訓練 ResNet-101 和 GPT-2，使用 48 個 GPU 連接到 8 Mbps~10 Gbps 網路。實驗結果表明，我們的系統和方法可以比基準方法快 1.45 - 9.39 倍，同時確保收斂。</paragraph>

##### **WorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines**
2410.12705v1 by Genta Indra Winata, Frederikus Hudi, Patrick Amadeus Irawan, David Anugraha, Rifki Afina Putri, Yutong Wang, Adam Nohejl, Ubaidillah Ariq Prathama, Nedjma Ousidhoum, Afifa Amriani, Anar Rzayev, Anirban Das, Ashmari Pramodya, Aulia Adila, Bryan Wilie, Candy Olivia Mawalim, Ching Lam Cheng, Daud Abolade, Emmanuele Chersoni, Enrico Santus, Fariz Ikhwantri, Garry Kuwanto, Hanyang Zhao, Haryo Akbarianto Wibowo, Holy Lovenia, Jan Christian Blaise Cruz, Jan Wira Gotama Putra, Junho Myung, Lucky Susanto, Maria Angelica Riera Machin, Marina Zhukova, Michael Anugraha, Muhammad Farid Adilazuarda, Natasha Santosa, Peerat Limkonchotiwat, Raj Dabre, Rio Alexander Audino, Samuel Cahyawijaya, Shi-Xiong Zhang, Stephanie Yulia Salim, Yi Zhou, Yinxuan Gui, David Ifeoluwa Adelani, En-Shiun Annie Lee, Shogo Okada, Ayu Purwarianti, Alham Fikri Aji, Taro Watanabe, Derry Tanti Wijaya, Alice Oh, Chong-Wah Ngo

Vision Language Models (VLMs) often struggle with culture-specific knowledge,
particularly in languages other than English and in underrepresented cultural
contexts. To evaluate their understanding of such knowledge, we introduce
WorldCuisines, a massive-scale benchmark for multilingual and multicultural,
visually grounded language understanding. This benchmark includes a visual
question answering (VQA) dataset with text-image pairs across 30 languages and
dialects, spanning 9 language families and featuring over 1 million data
points, making it the largest multicultural VQA benchmark to date. It includes
tasks for identifying dish names and their origins. We provide evaluation
datasets in two sizes (12k and 60k instances) alongside a training dataset (1
million instances). Our findings show that while VLMs perform better with
correct location context, they struggle with adversarial contexts and
predicting specific regional cuisines and languages. To support future
research, we release a knowledge base with annotated food entries and images
along with the VQA data.

摘要：視覺語言模型 (VLM) 經常在文化特定知識上遇到困難，特別是在英語以外的語言和代表性不足的文化背景中。為了評估他們對此類知識的理解，我們引入了 WorldCuisines，這是一個用於多語言和多元文化、視覺基礎語言理解的大規模基準測試。此基準測試包括一個視覺問答 (VQA) 資料集，其中包含 30 種語言和方言的文字影像對，涵蓋 9 個語言家族，並擁有超過 100 萬個資料點，使其成為迄今為止最大的多元文化 VQA 基準測試。它包括識別菜餚名稱及其來源的任務。我們提供了兩種大小（12k 和 60k 個例項）的評估資料集以及一個訓練資料集（100 萬個例項）。我們的研究結果表明，雖然 VLM 在正確的位置背景下表現得更好，但它們在對抗背景下以及預測特定區域美食和語言時遇到困難。為了支持未來的研究，我們發布了一個包含註釋食物條目和影像的知識庫以及 VQA 資料。

##### **Sarcasm Detection in a Less-Resourced Language**
2410.12704v1 by Lazar Đoković, Marko Robnik-Šikonja

The sarcasm detection task in natural language processing tries to classify
whether an utterance is sarcastic or not. It is related to sentiment analysis
since it often inverts surface sentiment. Because sarcastic sentences are
highly dependent on context, and they are often accompanied by various
non-verbal cues, the task is challenging. Most of related work focuses on
high-resourced languages like English. To build a sarcasm detection dataset for
a less-resourced language, such as Slovenian, we leverage two modern
techniques: a machine translation specific medium-size transformer model, and a
very large generative language model. We explore the viability of translated
datasets and how the size of a pretrained transformer affects its ability to
detect sarcasm. We train ensembles of detection models and evaluate models'
performance. The results show that larger models generally outperform smaller
ones and that ensembling can slightly improve sarcasm detection performance.
Our best ensemble approach achieves an $\text{F}_1$-score of 0.765 which is
close to annotators' agreement in the source language.

摘要：自然語言處理中的諷刺偵測任務嘗試分類一段話是否具有諷刺意味。這與情緒分析有關，因為它通常會反轉表面情緒。由於諷刺句子高度依賴於上下文，而且通常伴隨著各種非語言線索，因此這項任務具有挑戰性。大多數相關工作都專注於英語等資源豐富的語言。為了建立一個較少資源的語言（例如斯洛維尼亞語）的諷刺偵測資料集，我們利用了兩種現代技術：一個機器翻譯專用的中型Transformer模型，以及一個非常大的生成式語言模型。我們探討了翻譯資料集的可行性，以及預訓練Transformer的規模如何影響其偵測諷刺的能力。我們訓練了偵測模型的集合，並評估模型的效能。結果顯示，較大的模型通常優於較小的模型，而且集合可以稍微提升諷刺偵測效能。我們最好的集合方法達到了 0.765 的 $\text{F}_1$- 分數，這接近於來源語言中註解者的一致性。

##### **Embedding an Ethical Mind: Aligning Text-to-Image Synthesis via Lightweight Value Optimization**
2410.12700v1 by Xingqi Wang, Xiaoyuan Yi, Xing Xie, Jia Jia

Recent advancements in diffusion models trained on large-scale data have
enabled the generation of indistinguishable human-level images, yet they often
produce harmful content misaligned with human values, e.g., social bias, and
offensive content. Despite extensive research on Large Language Models (LLMs),
the challenge of Text-to-Image (T2I) model alignment remains largely
unexplored. Addressing this problem, we propose LiVO (Lightweight Value
Optimization), a novel lightweight method for aligning T2I models with human
values. LiVO only optimizes a plug-and-play value encoder to integrate a
specified value principle with the input prompt, allowing the control of
generated images over both semantics and values. Specifically, we design a
diffusion model-tailored preference optimization loss, which theoretically
approximates the Bradley-Terry model used in LLM alignment but provides a more
flexible trade-off between image quality and value conformity. To optimize the
value encoder, we also develop a framework to automatically construct a
text-image preference dataset of 86k (prompt, aligned image, violating image,
value principle) samples. Without updating most model parameters and through
adaptive value selection from the input prompt, LiVO significantly reduces
harmful outputs and achieves faster convergence, surpassing several strong
baselines and taking an initial step towards ethically aligned T2I models.

摘要：近期在大型资料训练的扩散模型有了重大进展，使得生成难以分辨的人类等级影像成为可能，但它们经常产生与人类价值观相悖的有害内容，例如社会偏见和攻击性内容。尽管对大型语言模型 (LLM) 进行了广泛研究，文本到图像 (T2I) 模型对齐的挑战在很大程度上仍未得到探索。为了解决这个问题，我们提出了 LiVO（轻量级价值优化），这是一种新颖的轻量级方法，用于将 T2I 模型与人类价值观对齐。LiVO 仅优化即插即用的值编码器，以将指定的值原则与输入提示整合在一起，从而允许对生成图像进行语义和价值控制。具体来说，我们设计了一个针对扩散模型量身定制的偏好优化损失，它在理论上近似于用于 LLM 对齐的 Bradley-Terry 模型，但在图像质量和价值一致性之间提供了一个更灵活的权衡。为了优化值编码器，我们还开发了一个框架，以自动构建一个包含 86k（提示、对齐图像、违规图像、价值原则）样本的文本图像偏好数据集。在不更新大多数模型参数的情况下，并且通过从输入提示中自适应地选择值，LiVO 大幅减少了有害输出并实现了更快的收敛，超越了几个强大的基准，并朝着符合道德标准的 T2I 模型迈出了第一步。

##### **VividMed: Vision Language Model with Versatile Visual Grounding for Medicine**
2410.12694v1 by Lingxiao Luo, Bingda Tang, Xuanzhong Chen, Rong Han, Ting Chen

Recent advancements in Vision Language Models (VLMs) have demonstrated
remarkable promise in generating visually grounded responses. However, their
application in the medical domain is hindered by unique challenges. For
instance, most VLMs rely on a single method of visual grounding, whereas
complex medical tasks demand more versatile approaches. Additionally, while
most VLMs process only 2D images, a large portion of medical images are 3D. The
lack of medical data further compounds these obstacles. To address these
challenges, we present VividMed, a vision language model with versatile visual
grounding for medicine. Our model supports generating both semantic
segmentation masks and instance-level bounding boxes, and accommodates various
imaging modalities, including both 2D and 3D data. We design a three-stage
training procedure and an automatic data synthesis pipeline based on open
datasets and models. Besides visual grounding tasks, VividMed also excels in
other common downstream tasks, including Visual Question Answering (VQA) and
report generation. Ablation studies empirically show that the integration of
visual grounding ability leads to improved performance on these tasks. Our code
is publicly available at https://github.com/function2-llx/MMMM.

摘要：最近在视觉语言模型 (VLM) 方面的进步已展示出在生成视觉基础响应方面的非凡前景。然而，它们在医学领域的应用受到独特的挑战的阻碍。例如，大多数 VLM 依赖于一种视觉基础方法，而复杂的医学任务需要更多样化的方法。此外，虽然大多数 VLM 只处理二维图像，但大部分医学图像都是三维的。缺乏医学数据进一步加剧了这些障碍。为了应对这些挑战，我们提出了 VividMed，这是一种具有多功能医学视觉基础的视觉语言模型。我们的模型支持生成语义分割掩模和实例级边界框，并适用于各种成像方式，包括二维和三维数据。我们设计了一个三阶段训练程序和一个基于开放数据集和模型的自动数据合成管道。除了视觉基础任务之外，VividMed 在其他常见的下游任务中也表现出色，包括视觉问答 (VQA) 和报告生成。消融研究凭经验证明，视觉基础能力的整合导致了这些任务的性能提升。我们的代码在 https://github.com/function2-llx/MMMM 上公开提供。

##### **Building Better: Avoiding Pitfalls in Developing Language Resources when Data is Scarce**
2410.12691v1 by Nedjma Ousidhoum, Meriem Beloucif, Saif M. Mohammad

Language is a symbolic capital that affects people's lives in many ways
(Bourdieu, 1977, 1991). It is a powerful tool that accounts for identities,
cultures, traditions, and societies in general. Hence, data in a given language
should be viewed as more than a collection of tokens. Good data collection and
labeling practices are key to building more human-centered and socially aware
technologies. While there has been a rising interest in mid- to low-resource
languages within the NLP community, work in this space has to overcome unique
challenges such as data scarcity and access to suitable annotators. In this
paper, we collect feedback from those directly involved in and impacted by NLP
artefacts for mid- to low-resource languages. We conduct a quantitative and
qualitative analysis of the responses and highlight the main issues related to
(1) data quality such as linguistic and cultural data suitability; and (2) the
ethics of common annotation practices such as the misuse of online community
services. Based on these findings, we make several recommendations for the
creation of high-quality language artefacts that reflect the cultural milieu of
its speakers, while simultaneously respecting the dignity and labor of data
workers.

摘要：語言是一種象徵資本，以許多方式影響人們的生活（Bourdieu，1977、1991）。它是一種強大的工具，說明了身分、文化、傳統和整體社會。因此，特定語言中的資料應視為不只是代幣集合。良好的資料收集和標記實務是建構以人為中心且具有社會意識的技術的關鍵。雖然 NLP 社群對中等至低資源語言有越來越高的興趣，但這方面的研究必須克服獨特的挑戰，例如資料稀少以及取得適當註解者的管道。在本論文中，我們收集了直接參與並受中低資源語言 NLP 人工製品影響者的回饋。我們對回應進行量化和質性分析，並重點說明與 (1) 資料品質（例如語言和文化資料的適用性）相關的主要問題；以及 (2) 常見註解實務（例如線上社群服務的誤用）的倫理。根據這些發現，我們提出幾項建議，用於建立反映其使用者文化環境的高品質語言人工製品，同時尊重資料工作者的尊嚴和勞動。

##### **Automatic Mapping of Anatomical Landmarks from Free-Text Using Large Language Models: Insights from Llama-2**
2410.12686v1 by Mohamad Abdi, Gerardo Hemosillo Valadez, Halid Ziya Yerebakan

Anatomical landmarks are vital in medical imaging for navigation and anomaly
detection. Modern large language models (LLMs), like Llama-2, offer promise for
automating the mapping of these landmarks in free-text radiology reports to
corresponding positions in image data. Recent studies propose LLMs may develop
coherent representations of generative processes. Motivated by these insights,
we investigated whether LLMs accurately represent the spatial positions of
anatomical landmarks. Through experiments with Llama-2 models, we found that
they can linearly represent anatomical landmarks in space with considerable
robustness to different prompts. These results underscore the potential of LLMs
to enhance the efficiency and accuracy of medical imaging workflows.

摘要：解剖標誌在醫學影像中對於導航和異常偵測至關重要。像 Llama-2 等現代大型語言模型 (LLM) 有望自動化將這些標誌對應到影像資料中相應位置的自由文字放射線學報告的對應。最近的研究提出，LLM 可能會發展出生成式過程的連貫表徵。受到這些見解的啟發，我們調查了 LLM 是否能準確表示解剖標誌的空間位置。透過 Llama-2 模型的實驗，我們發現它們可以用線性方式表示空間中的解剖標誌，並對不同的提示具有相當的穩健性。這些結果強調了 LLM 提高醫學影像工作流程效率和準確性的潛力。

##### **Context Matters: Leveraging Contextual Features for Time Series Forecasting**
2410.12672v2 by Sameep Chattopadhyay, Pulkit Paliwal, Sai Shankar Narasimhan, Shubhankar Agarwal, Sandeep P. Chinchali

Time series forecasts are often influenced by exogenous contextual features
in addition to their corresponding history. For example, in financial settings,
it is hard to accurately predict a stock price without considering public
sentiments and policy decisions in the form of news articles, tweets, etc.
Though this is common knowledge, the current state-of-the-art (SOTA)
forecasting models fail to incorporate such contextual information, owing to
its heterogeneity and multimodal nature. To address this, we introduce
ContextFormer, a novel plug-and-play method to surgically integrate multimodal
contextual information into existing pre-trained forecasting models.
ContextFormer effectively distills forecast-specific information from rich
multimodal contexts, including categorical, continuous, time-varying, and even
textual information, to significantly enhance the performance of existing base
forecasters. ContextFormer outperforms SOTA forecasting models by up to 30% on
a range of real-world datasets spanning energy, traffic, environmental, and
financial domains.

摘要：時間序列預測通常會受到外生脈絡特徵的影響，除了其對應的歷史記錄。例如，在金融環境中，很難在不考慮新聞文章、推文等形式的公眾情緒和政策決策的情況下準確預測股票價格。儘管這是常識，但目前最先進 (SOTA) 的預測模型無法納入此類脈絡資訊，因為其異質性和多模態性質。為了解決這個問題，我們引入了 ContextFormer，這是一種新穎的即插即用方法，可以將多模態脈絡資訊外科手術式地整合到現有的預訓練預測模型中。ContextFormer 有效地從豐富的多模態脈絡中提取特定於預測的資訊，包括分類、連續、時變，甚至文字資訊，以顯著增強現有基本預測器的效能。ContextFormer 在涵蓋能源、交通、環境和金融領域的一系列真實世界資料集上，比 SOTA 預測模型的效能高出 30%。

##### **Hamiltonian bridge: A physics-driven generative framework for targeted pattern control**
2410.12665v1 by Vishaal Krishnan, Sumit Sinha, L. Mahadevan

Patterns arise spontaneously in a range of systems spanning the sciences, and
their study typically focuses on mechanisms to understand their evolution in
space-time. Increasingly, there has been a transition towards controlling these
patterns in various functional settings, with implications for engineering.
Here, we combine our knowledge of a general class of dynamical laws for pattern
formation in non-equilibrium systems, and the power of stochastic optimal
control approaches to present a framework that allows us to control patterns at
multiple scales, which we dub the "Hamiltonian bridge". We use a mapping
between stochastic many-body Lagrangian physics and deterministic Eulerian
pattern forming PDEs to leverage our recent approach utilizing the
Feynman-Kac-based adjoint path integral formulation for the control of
interacting particles and generalize this to the active control of patterning
fields. We demonstrate the applicability of our computational framework via
numerical experiments on the control of phase separation with and without a
conserved order parameter, self-assembly of fluid droplets, coupled
reaction-diffusion equations and finally a phenomenological model for
spatio-temporal tissue differentiation. We interpret our numerical experiments
in terms of a theoretical understanding of how the underlying physics shapes
the geometry of the pattern manifold, altering the transport paths of patterns
and the nature of pattern interpolation. We finally conclude by showing how
optimal control can be utilized to generate complex patterns via an iterative
control protocol over pattern forming pdes which can be casted as gradient
flows. All together, our study shows how we can systematically build in
physical priors into a generative framework for pattern control in
non-equilibrium systems across multiple length and time scales.

摘要：<paragraph>在跨越科學領域的一系列系統中，模式會自發產生，而它們的研究通常集中在機制上，以了解它們在時空中的演化。越來越多的趨勢是朝向在各種功能設定中控制這些模式，並對工程產生影響。在這裡，我們結合我們對非平衡系統中模式形成的一般類別動力定律的知識，以及隨機最優控制方法的力量，提出了一個框架，允許我們控制多個尺度的模式，我們稱之為「哈密頓橋」。我們使用隨機多體拉格朗日物理和確定性歐拉模式形成偏微分方程之間的映射，以利用我們最近的方法，利用基於費曼-卡茨的伴隨路徑積分公式來控制相互作用的粒子，並將其推廣到模式場的主動控制。我們通過對相分離控制的數值實驗（有和沒有守恆序參數）、流體液滴的自組裝、耦合反應擴散方程，以及最後一個時空組織分化的現象學模型，來證明我們的計算框架的適用性。我們根據對基礎物理如何塑造模式流形的幾何形狀、改變模式的傳輸路徑和模式插值的性質的理論理解，來解釋我們的數值實驗。最後，我們通過展示如何利用最優控制通過模式形成偏微分方程的迭代控制協議來生成複雜模式（可以轉換為梯度流）來總結。總之，我們的研究表明，我們如何系統地將物理先驗構建到非平衡系統中跨多個長度和時間尺度的模式控制的生成框架中。</paragraph>

##### **Cross-Modal Safety Mechanism Transfer in Large Vision-Language Models**
2410.12662v1 by Shicheng Xu, Liang Pang, Yunchang Zhu, Huawei Shen, Xueqi Cheng

Vision-language alignment in Large Vision-Language Models (LVLMs)
successfully enables LLMs to understand visual input. However, we find that
existing vision-language alignment methods fail to transfer the existing safety
mechanism for text in LLMs to vision, which leads to vulnerabilities in toxic
image. To explore the cause of this problem, we give the insightful explanation
of where and how the safety mechanism of LVLMs operates and conduct comparative
analysis between text and vision. We find that the hidden states at the
specific transformer layers play a crucial role in the successful activation of
safety mechanism, while the vision-language alignment at hidden states level in
current methods is insufficient. This results in a semantic shift for input
images compared to text in hidden states, therefore misleads the safety
mechanism. To address this, we propose a novel Text-Guided vision-language
Alignment method (TGA) for LVLMs. TGA retrieves the texts related to input
vision and uses them to guide the projection of vision into the hidden states
space in LLMs. Experiments show that TGA not only successfully transfers the
safety mechanism for text in basic LLMs to vision in vision-language alignment
for LVLMs without any safety fine-tuning on the visual modality but also
maintains the general performance on various vision tasks (Safe and Good).

摘要：大型视觉语言模型（LVLMs）中的视觉语言对齐成功使 LLM 能够理解视觉输入。然而，我们发现现有的视觉语言对齐方法无法将 LLM 中文本的现有安全机制转移到视觉中，这导致了有毒图像中的漏洞。为了探索这个问题的原因，我们对 LVLMs 的安全机制在何处以及如何操作给出了深刻的解释，并在文本和视觉之间进行了比较分析。我们发现，特定 transformer 层的隐藏状态在安全机制的成功激活中起着至关重要的作用，而当前方法在隐藏状态级别的视觉语言对齐还不够。这导致隐藏状态中输入图像与文本的语义发生了变化，因此误导了安全机制。为了解决这个问题，我们为 LVLMs 提出了一种新颖的文本指导视觉语言对齐方法 (TGA)。TGA 检索与输入视觉相关的文本，并使用它们来指导视觉在 LLM 中投影到隐藏状态空间。实验表明，TGA 不仅成功地将基本 LLM 中文本的安全机制转移到 LVLMs 的视觉语言对齐中的视觉中，而无需对视觉方式进行任何安全微调，而且还保持了各种视觉任务（安全且良好）的总体性能。

##### **Evaluating Morphological Compositional Generalization in Large Language Models**
2410.12656v1 by Mete Ismayilzada, Defne Circi, Jonne Sälevä, Hale Sirin, Abdullatif Köksal, Bhuwan Dhingra, Antoine Bosselut, Lonneke van der Plas, Duygu Ataman

Large language models (LLMs) have demonstrated significant progress in
various natural language generation and understanding tasks. However, their
linguistic generalization capabilities remain questionable, raising doubts
about whether these models learn language similarly to humans. While humans
exhibit compositional generalization and linguistic creativity in language use,
the extent to which LLMs replicate these abilities, particularly in morphology,
is under-explored. In this work, we systematically investigate the
morphological generalization abilities of LLMs through the lens of
compositionality. We define morphemes as compositional primitives and design a
novel suite of generative and discriminative tasks to assess morphological
productivity and systematicity. Focusing on agglutinative languages such as
Turkish and Finnish, we evaluate several state-of-the-art instruction-finetuned
multilingual models, including GPT-4 and Gemini. Our analysis shows that LLMs
struggle with morphological compositional generalization particularly when
applied to novel word roots, with performance declining sharply as
morphological complexity increases. While models can identify individual
morphological combinations better than chance, their performance lacks
systematicity, leading to significant accuracy gaps compared to humans.

摘要：大型語言模型（LLM）在各種自然語言生成和理解任務中展現出顯著進展。然而，它們的語言概化能力仍存在疑問，引發了這些模型是否像人類一樣學習語言的疑慮。人類在語言使用中展現出組合概化和語言創造力，而 LLM 在何種程度上複製這些能力，特別是在形態學方面，仍未得到充分探討。在這項工作中，我們透過組合性的觀點系統性地探討 LLM 的形態概化能力。我們將形態定義為組合原語，並設計了一系列新的生成和區分任務來評估形態生產力和系統性。我們專注於像土耳其語和芬蘭語等黏著語，評估了多個最先進的指令微調多語言模型，包括 GPT-4 和 Gemini。我們的分析顯示，LLM 在形態組合概化方面遇到困難，特別是在應用於新的字根時，隨著形態複雜性的增加，效能急劇下降。雖然模型可以比隨機情況更好地識別個別形態組合，但它們的效能缺乏系統性，導致與人類相比出現顯著的準確性差距。

##### **Constrained Posterior Sampling: Time Series Generation with Hard Constraints**
2410.12652v1 by Sai Shankar Narasimhan, Shubhankar Agarwal, Litu Rout, Sanjay Shakkottai, Sandeep P. Chinchali

Generating realistic time series samples is crucial for stress-testing models
and protecting user privacy by using synthetic data. In engineering and
safety-critical applications, these samples must meet certain hard constraints
that are domain-specific or naturally imposed by physics or nature. Consider,
for example, generating electricity demand patterns with constraints on peak
demand times. This can be used to stress-test the functioning of power grids
during adverse weather conditions. Existing approaches for generating
constrained time series are either not scalable or degrade sample quality. To
address these challenges, we introduce Constrained Posterior Sampling (CPS), a
diffusion-based sampling algorithm that aims to project the posterior mean
estimate into the constraint set after each denoising update. Notably, CPS
scales to a large number of constraints (~100) without requiring additional
training. We provide theoretical justifications highlighting the impact of our
projection step on sampling. Empirically, CPS outperforms state-of-the-art
methods in sample quality and similarity to real time series by around 10% and
42%, respectively, on real-world stocks, traffic, and air quality datasets.

摘要：生成逼真的時間序列範例對於壓力測試模型和使用合成資料保護使用者隱私至關重要。在工程和安全關鍵應用中，這些範例必須符合某些特定於領域或自然而然由物理或自然界強加的硬約束。例如，考慮在尖峰需求時間的約束下產生用電需求模式。這可用於在惡劣天氣條件下對電網的功能進行壓力測試。現有的用於產生受約束時間序列的方法不是無法擴展，就是會降低範例品質。為了應對這些挑戰，我們引入了受約束後驗抽樣 (CPS)，這是一種基於擴散的抽樣演算法，其目標是在每次去噪更新後將後驗平均估計值投影到約束集中。值得注意的是，CPS 可以擴展到大量的約束（約 100 個），而不需要額外的訓練。我們提供了理論依據，強調了我們的投影步驟對抽樣的影響。根據經驗，CPS 在範例品質和與實際時間序列的相似性方面優於最先進的方法，分別在實際股票、交通和空氣品質資料集上提高了約 10% 和 42%。

##### **Explainable Moral Values: a neuro-symbolic approach to value classification**
2410.12631v1 by Nicolas Lazzari, Stefano De Giorgis, Aldo Gangemi, Valentina Presutti

This work explores the integration of ontology-based reasoning and Machine
Learning techniques for explainable value classification. By relying on an
ontological formalization of moral values as in the Moral Foundations Theory,
relying on the DnS Ontology Design Pattern, the \textit{sandra} neuro-symbolic
reasoner is used to infer values (fomalized as descriptions) that are
\emph{satisfied by} a certain sentence. Sentences, alongside their structured
representation, are automatically generated using an open-source Large Language
Model. The inferred descriptions are used to automatically detect the value
associated with a sentence. We show that only relying on the reasoner's
inference results in explainable classification comparable to other more
complex approaches. We show that combining the reasoner's inferences with
distributional semantics methods largely outperforms all the baselines,
including complex models based on neural network architectures. Finally, we
build a visualization tool to explore the potential of theory-based values
classification, which is publicly available at http://xmv.geomeaning.com/.

摘要：這項工作探討了基於本体論推理和機器學習技術整合用於可解釋價值分類。透過依賴於道德基礎理論中道德價值的本体形式化，依賴於 DnS 本体設計模式，\textit{sandra} 神經符號推理器用於推論由特定句子「滿足」的值 (形式化為描述)。句子與其結構化表示一起使用開源大型語言模型自動生成。推論出的描述用於自動偵測與句子相關的值。我們展示僅依賴於推理器的推論結果，就能產生可解釋的分類，與其他較複雜的方法相當。我們展示將推理器的推論與分配語義方法結合，大幅優於所有基線，包括基於神經網路架構的複雜模型。最後，我們建立一個視覺化工具來探討基於理論的價值分類的潛力，該工具可公開取得，網址為 http://xmv.geomeaning.com/。

##### **From Measurement Instruments to Data: Leveraging Theory-Driven Synthetic Training Data for Classifying Social Constructs**
2410.12622v2 by Lukas Birkenmaier, Matthias Roth, Indira Sen

Computational text classification is a challenging task, especially for
multi-dimensional social constructs. Recently, there has been increasing
discussion that synthetic training data could enhance classification by
offering examples of how these constructs are represented in texts. In this
paper, we systematically examine the potential of theory-driven synthetic
training data for improving the measurement of social constructs. In
particular, we explore how researchers can transfer established knowledge from
measurement instruments in the social sciences, such as survey scales or
annotation codebooks, into theory-driven generation of synthetic data. Using
two studies on measuring sexism and political topics, we assess the added value
of synthetic training data for fine-tuning text classification models. Although
the results of the sexism study were less promising, our findings demonstrate
that synthetic data can be highly effective in reducing the need for labeled
data in political topic classification. With only a minimal drop in
performance, synthetic data allows for substituting large amounts of labeled
data. Furthermore, theory-driven synthetic data performed markedly better than
data generated without conceptual information in mind.

摘要：計算文本分類是一項具有挑戰性的任務，特別是對於多維度的社會結構。最近，越來越多的討論認為，合成訓練數據可以通過提供這些結構在文本中表示方式的示例來增強分類。在本文中，我們系統地探討了理論驅動合成訓練數據在改進社會結構測量方面的潛力。具體來說，我們探討了研究人員如何將社會科學中測量工具（例如調查量表或註釋手冊）中已確立的知識轉移到合成數據的理論驅動生成中。通過兩項關於衡量性別歧視和政治話題的研究，我們評估了合成訓練數據在微調文本分類模型方面的附加價值。儘管性別歧視研究的結果不太令人滿意，但我們的研究結果表明，合成數據在減少政治話題分類中對標籤數據的需求方面可以非常有效。合成數據僅會導致性能略有下降，就可以替代大量的標籤數據。此外，理論驅動的合成數據的表現明顯優於在構建時沒有考慮概念信息的數據。

##### **Weak-to-Strong Generalization beyond Accuracy: a Pilot Study in Safety, Toxicity, and Legal Reasoning**
2410.12621v1 by Ruimeng Ye, Yang Xiao, Bo Hui

As large language models (LLMs) continue to advance, ensuring their alignment
with human values becomes increasingly critical. Traditional alignment methods
heavily rely on human feedback to fine-tune models. With the emergence of
superhuman models whose outputs may surpass human understanding, evaluating and
aligning these models using human judgments poses significant challenges. To
address the challenges, recent works use weak supervisors to elicit knowledge
from much stronger models. However, there are important disanalogies between
the empirical setup in the existing works and the genuine goal of alignment. We
remark that existing works investigate the phenomenon of weak-to-strong
generation in analogous setup (i.e., binary classification), rather than
practical alignment-relevant tasks (e.g., safety). In this paper, we bridge
this gap by extending weak-to-strong generation to the context of practical
alignment. We empirically demonstrate the widespread phenomenon of
weak-to-strong generation in three complicated alignment tasks: safety,
toxicity, and legal reasoning}. Furthermore, we explore efficient strategies
for improving alignment performance to enhance the quality of model outcomes.
Lastly, we summarize and analyze the challenges and potential solutions in
regard to specific alignment tasks, which we hope to catalyze the research
progress on the topic of weak-to-strong generalization. Our code is released at
https://github.com/yeruimeng/WTS.git.

摘要：隨著大型語言模型 (LLM) 的持續進展，確保它們與人類價值觀保持一致變得越來越重要。傳統對齊方法嚴重依賴人類回饋來微調模型。隨著超越人類理解能力的超人類模型的出現，使用人類判斷來評估和對齊這些模型構成了重大挑戰。為了應對這些挑戰，最近的工作使用弱監督者從更強大的模型中引出知識。然而，現有工作中的經驗設置與對齊的真正目標之間存在重要的差異。我們注意到，現有工作研究了類比設置（即二元分類）中的弱到強生成現象，而不是實際與對齊相關的任務（例如安全性）。在本文中，我們通過將弱到強生成擴展到實際對齊的背景來彌合這一差距。我們通過三個複雜的對齊任務（安全性、毒性和法律推理）經驗性地展示了弱到強生成的廣泛現象。此外，我們探討了提高對齊性能以增強模型結果品質的有效策略。最後，我們總結和分析了與具體對齊任務相關的挑戰和潛在解決方案，我們希望催化弱到強泛化的主題研究進展。我們的代碼發布在 https://github.com/yeruimeng/WTS.git。

##### **Exploring Model Kinship for Merging Large Language Models**
2410.12613v1 by Yedi Hu, Yunzhi Yao, Ningyu Zhang, Shumin Deng, Huajun Chen

Model merging has become one of the key technologies for enhancing the
capabilities and efficiency of Large Language Models (LLMs). However, our
understanding of the expected performance gains and principles when merging any
two models remains limited. In this work, we introduce model kinship, the
degree of similarity or relatedness between LLMs, analogous to biological
evolution. With comprehensive empirical analysis, we find that there is a
certain relationship between model kinship and the performance gains after
model merging, which can help guide our selection of candidate models. Inspired
by this, we propose a new model merging strategy: Top-k Greedy Merging with
Model Kinship, which can yield better performance on benchmark datasets.
Specifically, we discover that using model kinship as a criterion can assist us
in continuously performing model merging, alleviating the degradation (local
optima) in model evolution, whereas model kinship can serve as a guide to
escape these traps. Code is available at
https://github.com/zjunlp/ModelKinship.

摘要：模型合并已成为提升大型语言模型 (LLM) 能力和效率的关键技术之一。然而，对于合并任何两个模型时预期的性能提升和原理，我们的理解仍然有限。在这项工作中，我们引入了模型亲缘关系，即 LLM 之间的相似性或相关性程度，类似于生物进化。通过全面的实证分析，我们发现模型亲缘关系与模型合并后的性能提升之间存在一定的关系，这可以帮助我们指导候选模型的选择。受此启发，我们提出了一种新的模型合并策略：基于模型亲缘关系的 Top-k 贪婪合并，它可以在基准数据集上产生更好的性能。具体来说，我们发现使用模型亲缘关系作为标准可以帮助我们持续执行模型合并，缓解模型演化中的退化（局部最优），而模型亲缘关系可以作为逃离这些陷阱的指南。代码可在 https://github.com/zjunlp/ModelKinship 获得。

##### **Towards Graph Foundation Models: The Perspective of Zero-shot Reasoning on Knowledge Graphs**
2410.12609v1 by Kai Wang, Siqiang Luo

Inspired by the success of artificial general intelligence, there is a trend
towards developing Graph Foundation Models that excel in generalization across
various graph tasks and domains. However, current models often require
extensive training or fine-tuning to capture structural and semantic insights
on new graphs, which limits their versatility. In this work, we explore graph
foundation models from the perspective of zero-shot reasoning on Knowledge
Graphs (KGs). Our focus is on utilizing KGs as a unified topological structure
to tackle diverse tasks, while addressing semantic isolation challenges in KG
reasoning to effectively integrate diverse semantic and structural features.
This brings us new methodological insights into KG reasoning, as well as high
generalizability towards foundation models in practice. Methodologically, we
introduce SCORE, a unified graph reasoning framework that effectively
generalizes diverse graph tasks using zero-shot learning. At the core of SCORE
is semantic conditional message passing, a technique designed to capture both
structural and semantic invariances in graphs, with theoretical backing for its
expressive power. Practically, we evaluate the zero-shot reasoning capability
of SCORE using 38 diverse graph datasets, covering node-level, link-level, and
graph-level tasks across multiple domains. Our experiments reveal a substantial
performance improvement over prior foundation models and supervised baselines,
highlighting the efficacy and adaptability of our approach.

摘要：受到人工通用智能的成功啟發，現正流行開發圖形基礎模型，這些模型擅長於在各種圖形任務和領域中進行概括。然而，當前的模型通常需要大量的訓練或微調，才能擷取新圖形中的結構和語義見解，這限制了它們的多功能性。在這項工作中，我們從知識圖譜 (KG) 的零次推理角度探討圖形基礎模型。我們的重點是利用 KG 作為統一的拓撲結構來處理各種任務，同時解決 KG 推理中的語義孤立挑戰，以有效整合各種語義和結構特徵。這為我們帶來了 KG 推理的新方法論見解，以及在實務中對基礎模型的高泛化能力。在方法論上，我們引入了 SCORE，一個統一的圖形推理框架，它使用零次學習有效地概括了各種圖形任務。SCORE 的核心是語義條件訊息傳遞，這是一種旨在擷取圖形中結構和語義不變性的技術，並有理論支持其表現能力。在實務上，我們使用 38 個不同的圖形資料集評估 SCORE 的零次推理能力，涵蓋跨多個領域的節點層級、連結層級和圖形層級任務。我們的實驗顯示，與先前的基礎模型和監督基準相比，我們的效能有顯著的提升，突顯了我們方法的有效性和適應性。

##### **Not All Votes Count! Programs as Verifiers Improve Self-Consistency of Language Models for Math Reasoning**
2410.12608v1 by Vernon Y. H. Toh, Deepanway Ghosal, Soujanya Poria

Large language models (LLMs) have shown increasing proficiency in solving
mathematical reasoning problems. However, many current open-source LLMs often
still make calculation and semantic understanding errors in their intermediate
reasoning steps. In this work, we propose PROVE, a simple yet effective
framework that uses program-based verification as a heuristic to filter out
potentially incorrect reasoning paths before aggregating the final answers.
Instead of relying on vanilla majority voting, our approach rejects solutions
whose corresponding program outputs are inconsistent with the generated
solution, aggregating only those validated by Python programs. We conducted
extensive experiments on 13 open-source LLMs from various model families and
sizes, ranging from 0.5B to 13B parameters, across seven math benchmarks. We
demonstrate that PROVE consistently outperforms vanilla majority voting as a
heuristic for solving mathematical reasoning tasks across all datasets and
model sizes. Notably, PROVE increases accuracy on the GSM8K benchmark from
48.85% to 53.83% for Qwen2-0.5B-Instruct, from 65.66% to 73.01% for
Llama-3.2-1B-Instruct, from 73.39% to 79.61% for Gemma-2-2b-it, and from 41.32%
to 59.51% for Llama-2-7B-chat. Our codes are available at
https://github.com/declare-lab/prove.

摘要：大型語言模型 (LLM) 在解決數學推理問題方面已展現出越來越高的能力。然而，許多當前開放原始碼的 LLM 仍經常在其中間推理步驟中產生計算和語義理解錯誤。在此研究中，我們提出 PROVE，一個簡單但有效的架構，它使用基於程式的驗證作為一種啟發式方法，在匯總最終答案之前過濾掉潛在不正確的推理路徑。我們的做法並非依賴於香草多數決，而是拒絕其對應程式輸出與產生解不相符的解，僅匯總由 Python 程式驗證的解。我們對來自各種模型系列和規模的 13 個開放原始碼 LLM 進行了廣泛的實驗，模型參數範圍從 0.5B 到 13B，涵蓋七個數學基準。我們證明 PROVE 在所有資料集和模型規模中始終優於香草多數決，作為解決數學推理任務的啟發式方法。值得注意的是，PROVE 將 Qwen2-0.5B-Instruct 的 GSM8K 基準準確率從 48.85% 提升至 53.83%，將 Llama-3.2-1B-Instruct 的準確率從 65.66% 提升至 73.01%，將 Gemma-2-2b-it 的準確率從 73.39% 提升至 79.61%，將 Llama-2-7B-chat 的準確率從 41.32% 提升至 59.51%。我們的程式碼可在 https://github.com/declare-lab/prove 中取得。

##### **Low-Rank Adversarial PGD Attack**
2410.12607v1 by Dayana Savostianova, Emanuele Zangrando, Francesco Tudisco

Adversarial attacks on deep neural network models have seen rapid development
and are extensively used to study the stability of these networks. Among
various adversarial strategies, Projected Gradient Descent (PGD) is a widely
adopted method in computer vision due to its effectiveness and quick
implementation, making it suitable for adversarial training. In this work, we
observe that in many cases, the perturbations computed using PGD predominantly
affect only a portion of the singular value spectrum of the original image,
suggesting that these perturbations are approximately low-rank. Motivated by
this observation, we propose a variation of PGD that efficiently computes a
low-rank attack. We extensively validate our method on a range of standard
models as well as robust models that have undergone adversarial training. Our
analysis indicates that the proposed low-rank PGD can be effectively used in
adversarial training due to its straightforward and fast implementation coupled
with competitive performance. Notably, we find that low-rank PGD often performs
comparably to, and sometimes even outperforms, the traditional full-rank PGD
attack, while using significantly less memory.

摘要：對深度神經網路模型的對抗攻擊已經快速發展，並廣泛用於研究這些網路的穩定性。在各種對抗策略中，投影梯度下降 (PGD) 是一種在電腦視覺中廣泛採用的方法，因為它的有效性和快速實作，使其適合於對抗訓練。在這項工作中，我們觀察到在許多情況下，使用 PGD 計算的擾動主要只影響原始影像的奇異值頻譜的一部分，這表示這些擾動大約是低秩的。受到這個觀察的啟發，我們提出 PGD 的一種變體，可以有效地計算低秩攻擊。我們廣泛驗證了我們的方法，包括一系列標準模型以及經過對抗訓練的強健模型。我們的分析表明，所提出的低秩 PGD 可以有效地用於對抗訓練，因為它的實作簡單快速，並且效能具有競爭力。值得注意的是，我們發現低秩 PGD 通常表現得與傳統全秩 PGD 攻擊相當，甚至有時表現得更好，同時使用的記憶體卻少得多。

##### **CCSBench: Evaluating Compositional Controllability in LLMs for Scientific Document Summarization**
2410.12601v1 by Yixi Ding, Jiaying Wu, Tongyao Zhu, Yanxia Qin, Qian Liu, Min-Yen Kan

To broaden the dissemination of scientific knowledge to diverse audiences,
scientific document summarization must simultaneously control multiple
attributes such as length and empirical focus. However, existing research
typically focuses on controlling single attributes, leaving the compositional
control of multiple attributes underexplored. To address this gap, we introduce
CCSBench, a benchmark for compositional controllable summarization in the
scientific domain. Our benchmark enables fine-grained control over both
explicit attributes (e.g., length), which are objective and straightforward,
and implicit attributes (e.g., empirical focus), which are more subjective and
conceptual. We conduct extensive experiments on GPT-4, LLaMA2, and other
popular LLMs under various settings. Our findings reveal significant
limitations in large language models' ability to balance trade-offs between
control attributes, especially implicit ones that require deeper understanding
and abstract reasoning.

摘要：為擴大科學知識在不同受眾間的傳播，科學文獻摘要必須同時控制多重屬性，例如長度和實證重點。然而，現有研究通常專注於控制單一屬性，而忽略了多重屬性的組成控制。為了解決這個差距，我們引入了 CCSBench，一個在科學領域中用於組成可控摘要的基準。我們的基準能對顯式屬性（例如長度）和隱式屬性（例如實證重點）進行精細的控制，前者是客觀且直接的，而後者則是更主觀且抽象的。我們對 GPT-4、LLaMA2 和其他流行的 LLM 在各種設定下進行了廣泛的實驗。我們的研究結果揭露了大型語言模型在平衡控制屬性之間的權衡時有顯著的限制，尤其是需要更深入理解和抽象推理的隱式屬性。

##### **On the Risk of Evidence Pollution for Malicious Social Text Detection in the Era of LLMs**
2410.12600v1 by Herun Wan, Minnan Luo, Zhixiong Su, Guang Dai, Xiang Zhao

Evidence-enhanced detectors present remarkable abilities in identifying
malicious social text with related evidence. However, the rise of large
language models (LLMs) brings potential risks of evidence pollution to confuse
detectors. This paper explores how to manipulate evidence, simulating potential
misuse scenarios including basic pollution, and rephrasing or generating
evidence by LLMs. To mitigate its negative impact, we propose three defense
strategies from both the data and model sides, including machine-generated text
detection, a mixture of experts, and parameter updating. Extensive experiments
on four malicious social text detection tasks with ten datasets present that
evidence pollution, especially the generate strategy, significantly compromises
existing detectors. On the other hand, the defense strategies could mitigate
evidence pollution, but they faced limitations for practical employment, such
as the need for annotated data and huge inference costs. Further analysis
illustrates that polluted evidence is of high quality, would compromise the
model calibration, and could ensemble to amplify the negative impact.

摘要：證據增強式偵測器在識別具有相關證據的惡意社群文字方面展現出卓越的能力。然而，大型語言模型 (LLM) 的興起帶來了證據污染的潛在風險，可能會混淆偵測器。本文探討如何操縱證據，模擬潛在的誤用情境，包括基本的污染，以及透過 LLM 改寫或產生證據。為了減輕其負面影響，我們從資料和模型兩方面提出三種防禦策略，包括機器產生的文字偵測、專家組合，以及參數更新。在四個惡意社群文字偵測任務上進行的廣泛實驗，使用十個資料集，顯示證據污染，特別是產生策略，顯著地損害了現有的偵測器。另一方面，防禦策略可以減輕證據污染，但它們在實際應用上會遇到限制，例如需要有註解的資料和龐大的推論成本。進一步的分析說明，受到污染的證據品質很高，會損害模型校準，並且可以透過整合來擴大負面影響。

##### **Expand and Compress: Exploring Tuning Principles for Continual Spatio-Temporal Graph Forecasting**
2410.12593v1 by Wei Chen, Yuxuan Liang

The widespread deployment of sensing devices leads to a surge in data for
spatio-temporal forecasting applications such as traffic flow, air quality, and
wind energy. Although spatio-temporal graph neural networks have achieved
success in modeling various static spatio-temporal forecasting scenarios,
real-world spatio-temporal data are typically received in a streaming manner,
and the network continuously expands with the installation of new sensors.
Thus, spatio-temporal forecasting in streaming scenarios faces dual challenges:
the inefficiency of retraining models over newly arrived data and the
detrimental effects of catastrophic forgetting over long-term history. To
address these challenges, we propose a novel prompt tuning-based continuous
forecasting method, following two fundamental tuning principles guided by
empirical and theoretical analysis: expand and compress, which effectively
resolve the aforementioned problems with lightweight tuning parameters.
Specifically, we integrate the base spatio-temporal graph neural network with a
continuous prompt pool, utilizing stored prompts (i.e., few learnable
parameters) in memory, and jointly optimize them with the base spatio-temporal
graph neural network. This method ensures that the model sequentially learns
from the spatio-temporal data stream to accomplish tasks for corresponding
periods. Extensive experimental results on multiple real-world datasets
demonstrate the multi-faceted superiority of our method over the
state-of-the-art baselines, including effectiveness, efficiency, universality,
etc.

摘要：感測裝置的廣泛部署導致時空預測應用程式的資料激增，例如交通流量、空氣品質和風能。儘管時空圖形神經網路已成功建模各種靜態時空預測情境，但現實世界的時空資料通常是以串流方式接收，而且網路會隨著新感測器的安裝而持續擴展。因此，串流情境中的時空預測面臨兩項挑戰：對新抵達資料重新訓練模型的效率低下，以及長期歷史中災難性遺忘的有害影響。為了解決這些挑戰，我們提出了一種基於提示調整的連續預測新方法，遵循經驗和理論分析指導的兩個基本調整原則：擴展和壓縮，有效解決上述問題，且調整參數較輕量。具體來說，我們將基礎時空圖形神經網路與連續提示池整合，利用儲存在記憶體中的儲存提示（即少數可學習參數），並與基礎時空圖形神經網路共同最佳化。此方法確保模型從時空資料串流中循序學習，以完成對應期間的任務。在多個真實世界資料集上進行的廣泛實驗結果證明了我們的方法在有效性、效率、通用性等方面優於現有技術的基準。

##### **Rethinking Visual Counterfactual Explanations Through Region Constraint**
2410.12591v1 by Bartlomiej Sobieski, Jakub Grzywaczewski, Bartlomiej Sadlej, Matthew Tivnan, Przemyslaw Biecek

Visual counterfactual explanations (VCEs) have recently gained immense
popularity as a tool for clarifying the decision-making process of image
classifiers. This trend is largely motivated by what these explanations promise
to deliver -- indicate semantically meaningful factors that change the
classifier's decision. However, we argue that current state-of-the-art
approaches lack a crucial component -- the region constraint -- whose absence
prevents from drawing explicit conclusions, and may even lead to faulty
reasoning due to phenomenons like confirmation bias. To address the issue of
previous methods, which modify images in a very entangled and widely dispersed
manner, we propose region-constrained VCEs (RVCEs), which assume that only a
predefined image region can be modified to influence the model's prediction. To
effectively sample from this subclass of VCEs, we propose Region-Constrained
Counterfactual Schr\"odinger Bridges (RCSB), an adaptation of a tractable
subclass of Schr\"odinger Bridges to the problem of conditional inpainting,
where the conditioning signal originates from the classifier of interest. In
addition to setting a new state-of-the-art by a large margin, we extend RCSB to
allow for exact counterfactual reasoning, where the predefined region contains
only the factor of interest, and incorporating the user to actively interact
with the RVCE by predefining the regions manually.

摘要：視覺反事實解釋（VCE）最近作為一種用於釐清圖像分類器決策過程的工具而廣受歡迎。這種趨勢在很大程度上是由這些解釋所承諾提供的內容所推動的，即指出改變分類器決策的語義有意義的因素。然而，我們認為當前的最先進方法缺乏一個關鍵組成部分——區域約束——其缺失會妨礙得出明確的結論，甚至可能由於確認偏誤等現象而導致錯誤的推理。為了解決先前方法的問題，這些方法以非常糾纏和廣泛分散的方式修改圖像，我們提出了區域約束 VCE（RVCE），它假設只能修改預定義的圖像區域來影響模型的預測。為了有效地從此 VCE 子類中進行採樣，我們提出了區域約束反事實薛丁格橋（RCSB），這是薛丁格橋的一個易處理子類的適應，用於條件性內繪的難題，其中條件信號來自感興趣的分類器。除了大幅設定新的最先進標準外，我們還擴展了 RCSB 以允許進行精確的反事實推理，其中預定義區域僅包含感興趣的因素，並通過手動預定義區域讓使用者主動與 RVCE 互動。

##### **Can We Reverse In-Context Knowledge Edits?**
2410.12586v1 by Paul Youssef, Zhixue Zhao, Jörg Schlötterer, Christin Seifert

In-context knowledge editing (IKE) enables efficient modification of large
language model (LLM) outputs without parameter changes and at zero-cost.
However, it can be misused to manipulate responses opaquely, e.g., insert
misinformation or offensive content. Such malicious interventions could be
incorporated into high-level wrapped APIs where the final input prompt is not
shown to end-users. To address this issue, we investigate the detection and
reversal of IKE-edits. First, we demonstrate that IKE-edits can be detected
with high accuracy (F1 > 80\%) using only the top-10 output probabilities of
the next token, even in a black-box setting, e.g. proprietary LLMs with limited
output information. Further, we introduce the novel task of reversing IKE-edits
using specially tuned reversal tokens. We explore using both continuous and
discrete reversal tokens, achieving over 80\% accuracy in recovering original,
unedited outputs across multiple LLMs. Our continuous reversal tokens prove
particularly effective, with minimal impact on unedited prompts. Through
analysis of output distributions, attention patterns, and token rankings, we
provide insights into IKE's effects on LLMs and how reversal tokens mitigate
them. This work represents a significant step towards enhancing LLM resilience
against potential misuse of in-context editing, improving their transparency
and trustworthiness.

摘要：在語境中知識編輯 (IKE) 能夠有效修改大型語言模型 (LLM) 的輸出，無需參數變更且成本為零。
然而，它可能會被誤用來不透明地操縱回應，例如插入錯誤資訊或攻擊性內容。這種惡意的干預可能會被整合到高階包裝 API 中，其中最終輸入提示不會顯示給最終使用者。為了解決這個問題，我們研究了 IKE 編輯的偵測和還原。首先，我們展示了 IKE 編輯可以使用下一個代碼的僅前 10 個輸出機率來偵測，準確率很高 (F1 > 80%)，即使在黑盒設定中，例如具有有限輸出資訊的專有 LLM。此外，我們引入了使用特別調整的反轉代碼來還原 IKE 編輯的新穎任務。我們探討使用連續和離散的反轉代碼，在多個 LLM 中恢復原始未編輯輸出的準確率達 80% 以上。我們的連續反轉代碼被證明特別有效，對未編輯提示的影響最小。透過分析輸出分佈、注意力模式和代碼排名，我們提供了對 IKE 對 LLM 的影響以及反轉代碼如何減輕這些影響的見解。這項工作代表了在增強 LLM 對語境編輯潛在誤用的復原力、改善其透明度和可信度方面邁出的重要一步。

##### **STRUX: An LLM for Decision-Making with Structured Explanations**
2410.12583v1 by Yiming Lu, Yebowen Hu, Hassan Foroosh, Wei Jin, Fei Liu

Countless decisions shape our daily lives, and it is paramount to understand
the how and why behind these choices. In this paper, we introduce a new LLM
decision-making framework called STRUX, which enhances LLM decision-making by
providing structured explanations. These include favorable and adverse facts
related to the decision, along with their respective strengths. STRUX begins by
distilling lengthy information into a concise table of key facts. It then
employs a series of self-reflection steps to determine which of these facts are
pivotal, categorizing them as either favorable or adverse in relation to a
specific decision. Lastly, we fine-tune an LLM to identify and prioritize these
key facts to optimize decision-making. STRUX has been evaluated on the
challenging task of forecasting stock investment decisions based on earnings
call transcripts and demonstrated superior performance against strong
baselines. It enhances decision transparency by allowing users to understand
the impact of different factors, representing a meaningful step towards
practical decision-making with LLMs.

摘要：無數的決定形塑著我們的日常生活，而理解這些選擇背後的原因和方式至關重要。在本文中，我們介紹了一個名為 STRUX 的 LLM 決策制定框架，它透過提供結構化的說明來增強 LLM 決策制定。這些說明包括與決策相關的有利和不利事實，以及它們各自的優缺點。STRUX 首先將冗長的資訊提煉成一個簡潔的關鍵事實表格。然後，它採用一系列自我反省步驟來確定哪些事實至關重要，並將它們分類為有利或不利於特定決策。最後，我們微調 LLM 以識別和優先考慮這些關鍵事實，以優化決策制定。STRUX 已針對根據收益電話記錄預測股票投資決策的挑戰性任務進行評估，並證明其相對於強大的基準具有優異的表現。它透過讓使用者了解不同因素的影響來增強決策透明度，代表著朝著使用 LLM 進行實際決策邁出了一大步。

##### **On the Utility of Domain Modeling Assistance with Large Language Models**
2410.12577v1 by Meriem Ben Chaaben, Lola Burgueño, Istvan David, Houari Sahraoui

Model-driven engineering (MDE) simplifies software development through
abstraction, yet challenges such as time constraints, incomplete domain
understanding, and adherence to syntactic constraints hinder the design
process. This paper presents a study to evaluate the usefulness of a novel
approach utilizing large language models (LLMs) and few-shot prompt learning to
assist in domain modeling. The aim of this approach is to overcome the need for
extensive training of AI-based completion models on scarce domain-specific
datasets and to offer versatile support for various modeling activities,
providing valuable recommendations to software modelers. To support this
approach, we developed MAGDA, a user-friendly tool, through which we conduct a
user study and assess the real-world applicability of our approach in the
context of domain modeling, offering valuable insights into its usability and
effectiveness.

摘要：模型驅動工程 (MDE) 透過抽象簡化軟體開發，但時間限制、不完整的領域理解和對語法約束的堅持等挑戰阻礙了設計流程。本文提出了一項研究，以評估一種新方法的實用性，該方法利用大型語言模型 (LLM) 和少次提示學習來協助領域建模。此方法的目標是克服在稀缺的特定領域資料集上對基於 AI 的完成模型進行廣泛訓練的需求，並為各種建模活動提供多功能支援，為軟體建模人員提供有價值的建議。為了支援此方法，我們開發了一個使用者友善的工具 MAGDA，透過該工具，我們進行使用者研究並評估我們的方法在領域建模中的實際適用性，提供對其可用性和有效性的寶貴見解。

##### **Robust RL with LLM-Driven Data Synthesis and Policy Adaptation for Autonomous Driving**
2410.12568v1 by Sihao Wu, Jiaxu Liu, Xiangyu Yin, Guangliang Cheng, Meng Fang, Xingyu Zhao, Xinping Yi, Xiaowei Huang

The integration of Large Language Models (LLMs) into autonomous driving
systems demonstrates strong common sense and reasoning abilities, effectively
addressing the pitfalls of purely data-driven methods. Current LLM-based agents
require lengthy inference times and face challenges in interacting with
real-time autonomous driving environments. A key open question is whether we
can effectively leverage the knowledge from LLMs to train an efficient and
robust Reinforcement Learning (RL) agent. This paper introduces RAPID, a novel
\underline{\textbf{R}}obust \underline{\textbf{A}}daptive
\underline{\textbf{P}}olicy \underline{\textbf{I}}nfusion and
\underline{\textbf{D}}istillation framework, which trains specialized
mix-of-policy RL agents using data synthesized by an LLM-based driving agent
and online adaptation. RAPID features three key designs: 1) utilization of
offline data collected from an LLM agent to distil expert knowledge into RL
policies for faster real-time inference; 2) introduction of robust distillation
in RL to inherit both performance and robustness from LLM-based teacher; and 3)
employment of a mix-of-policy approach for joint decision decoding with a
policy adapter. Through fine-tuning via online environment interaction, RAPID
reduces the forgetting of LLM knowledge while maintaining adaptability to
different tasks. Extensive experiments demonstrate RAPID's capability to
effectively integrate LLM knowledge into scaled-down RL policies in an
efficient, adaptable, and robust way. Code and checkpoints will be made
publicly available upon acceptance.

摘要：大型語言模型 (LLM) 整合到自動駕駛系統中，展現出強大的常識和推理能力，有效解決純數據驅動方法的缺陷。當前基於 LLM 的代理需要冗長的推論時間，並在與實時自動駕駛環境互動時面臨挑戰。一個關鍵的開放性問題是，我們是否能有效利用 LLM 的知識來訓練一個有效率且強健的強化學習 (RL) 代理。本文介紹 RAPID，一個新穎的\underline{\textbf{R}}obust \underline{\textbf{A}}daptive \underline{\textbf{P}}olicy \underline{\textbf{I}}nfusion and \underline{\textbf{D}}istillation 框架，它使用由基於 LLM 的駕駛代理和線上適應合成的數據，來訓練專門的混合策略 RL 代理。RAPID 具有三個關鍵設計：1) 利用從 LLM 代理收集的離線數據，將專家知識提煉到 RL 政策中，以加快實時推論；2) 在 RL 中引入強健的提煉，以繼承基於 LLM 的教師的效能和強健性；3) 採用混合策略方法，使用策略適配器進行聯合決策解碼。透過線上環境互動進行微調，RAPID 減少了 LLM 知識的遺忘，同時保持對不同任務的適應性。廣泛的實驗證明了 RAPID 有能力以有效率、適應性和強健的方式，將 LLM 知識有效整合到縮小的 RL 政策中。程式碼和檢查點將在接受後公開。

##### **Development of Image Collection Method Using YOLO and Siamese Network**
2410.12561v1 by Chan Young Shin, Ah Hyun Lee, Jun Young Lee, Ji Min Lee, Soo Jin Park

As we enter the era of big data, collecting high-quality data is very
important. However, collecting data by humans is not only very time-consuming
but also expensive. Therefore, many scientists have devised various methods to
collect data using computers. Among them, there is a method called web
crawling, but the authors found that the crawling method has a problem in that
unintended data is collected along with the user. The authors found that this
can be filtered using the object recognition model YOLOv10. However, there are
cases where data that is not properly filtered remains. Here, image
reclassification was performed by additionally utilizing the distance output
from the Siamese network, and higher performance was recorded than other
classification models. (average \_f1 score YOLO+MobileNet
0.678->YOLO+SiameseNet 0.772)) The user can specify a distance threshold to
adjust the balance between data deficiency and noise-robustness. The authors
also found that the Siamese network can achieve higher performance with fewer
resources because the cropped images are used for object recognition when
processing images in the Siamese network. (Class 20 mean-based f1 score,
non-crop+Siamese(MobileNetV3-Small) 80.94 -> crop
preprocessing+Siamese(MobileNetV3-Small) 82.31) In this way, the image
retrieval system that utilizes two consecutive models to reduce errors can save
users' time and effort, and build better quality data faster and with fewer
resources than before.

摘要：隨著我們進入大數據時代，收集高品質的數據非常重要。然而，由人類收集數據不僅非常耗時，而且成本高昂。因此，許多科學家已經設計出各種使用電腦收集數據的方法。其中，有一種方法稱為網路爬蟲，但作者發現爬蟲方法存在一個問題，即會在收集使用者的同時收集到意外的數據。作者發現這可以使用物件辨識模型 YOLOv10 來過濾。然而，有時候會有一些數據無法適當過濾。在此，透過額外使用 Siamese 網路的距離輸出執行影像重新分類，並且記錄到的效能比其他分類模型高。（平均 _f1 分數 YOLO+MobileNet 0.678->YOLO+SiameseNet 0.772）使用者可以指定距離閾值來調整數據不足和抗雜訊的平衡。作者還發現，由於在 Siamese 網路中處理影像時，會使用裁切的影像進行物件辨識，因此 Siamese 網路可以使用較少的資源來達成較高的效能。（類別 20 的平均 f1 分數，未裁切+Siamese（MobileNetV3-Small）80.94 -> 裁切預處理+Siamese（MobileNetV3-Small）82.31）透過這種方式，使用兩個連續的模型來減少錯誤的影像檢索系統可以節省使用者的時間和精力，並比以前更快、使用更少的資源來建立品質更好的數據。

##### **A Claim Decomposition Benchmark for Long-form Answer Verification**
2410.12558v1 by Zhihao Zhang, Yixing Fan, Ruqing Zhang, Jiafeng Guo

The advancement of LLMs has significantly boosted the performance of complex
long-form question answering tasks. However, one prominent issue of LLMs is the
generated "hallucination" responses that are not factual. Consequently,
attribution for each claim in responses becomes a common solution to improve
the factuality and verifiability. Existing researches mainly focus on how to
provide accurate citations for the response, which largely overlook the
importance of identifying the claims or statements for each response. To bridge
this gap, we introduce a new claim decomposition benchmark, which requires
building system that can identify atomic and checkworthy claims for LLM
responses. Specifically, we present the Chinese Atomic Claim Decomposition
Dataset (CACDD), which builds on the WebCPM dataset with additional expert
annotations to ensure high data quality. The CACDD encompasses a collection of
500 human-annotated question-answer pairs, including a total of 4956 atomic
claims. We further propose a new pipeline for human annotation and describe the
challenges of this task. In addition, we provide experiment results on
zero-shot, few-shot and fine-tuned LLMs as baselines. The results show that the
claim decomposition is highly challenging and requires further explorations.
All code and data are publicly available at
\url{https://github.com/FBzzh/CACDD}.

摘要：大型語言模型的進步顯著提升了複雜長篇問答任務的性能。然而，大型語言模型的一個顯著問題是產生的「幻覺」回應並非事實。因此，回應中每個說法的歸因成為改善事實性和可驗證性的常見解決方案。現有的研究主要集中在如何為回應提供準確的引用，這在很大程度上忽視了識別每個回應的說法或陳述的重要性。為了彌補這一差距，我們引入了一個新的說法分解基準，它需要建立一個系統，該系統可以識別大型語言模型回應的原子和可驗證的說法。具體來說，我們提出了中文原子說法分解數據集 (CACDD)，它建立在 WebCPM 數據集之上，並增加了專家註釋以確保高數據質量。CACDD 包含一系列 500 個人工註釋的問題答案對，總共包括 4956 個原子說法。我們進一步提出了人工註釋的新管道，並描述了此任務的挑戰。此外，我們提供了零次學習、少次學習和微調大型語言模型的實驗結果作為基準。結果表明，說法分解極具挑戰性，需要進一步探索。所有代碼和數據都可以在 \url{https://github.com/FBzzh/CACDD} 公開獲得。

##### **LLM-based Translation Inference with Iterative Bilingual Understanding**
2410.12543v2 by Andong Chen, Kehai Chen, Yang Xiang, Xuefeng Bai, Muyun Yang, Tiejun Zhao, Min zhang

The remarkable understanding and generation capabilities of large language
models (LLMs) have greatly improved translation performance. However, incorrect
understanding of the sentence to be translated can degrade translation quality.
To address this issue, we proposed a novel Iterative Bilingual Understanding
Translation (IBUT) method based on the cross-lingual capabilities of LLMs and
the dual characteristics of translation tasks. The cross-lingual capability of
LLMs enables the generation of contextual understanding for both the source and
target languages separately. Furthermore, the dual characteristics allow IBUT
to generate effective cross-lingual feedback, iteratively refining contextual
understanding, thereby reducing errors and improving translation performance.
Experimental results showed that the proposed IBUT outperforms several strong
comparison methods, especially being generalized to multiple domains (e.g.,
news, commonsense, and cultural translation benchmarks).

摘要：大型語言模型 (LLM) 傑出的理解和生成能力大幅提升了翻譯效能。然而，對待翻譯句子的理解不正確會降低翻譯品質。為了解決這個問題，我們提出了一種創新的反覆雙語理解翻譯 (IBUT) 方法，它基於 LLM 的跨語言能力和翻譯任務的雙重特徵。LLM 的跨語言能力可以分別為來源語言和目標語言產生脈絡理解。此外，雙重特徵讓 IBUT 能夠產生有效的跨語言回饋，反覆精進脈絡理解，從而減少錯誤並提升翻譯效能。實驗結果顯示，提出的 IBUT 優於多種強大的對比方法，特別是廣泛運用於多個領域（例如新聞、常識和文化翻譯基準）。

##### **Counterfactual Effect Decomposition in Multi-Agent Sequential Decision Making**
2410.12539v1 by Stelios Triantafyllou, Aleksa Sukovic, Yasaman Zolfimoselo, Goran Radanovic

We address the challenge of explaining counterfactual outcomes in multi-agent
Markov decision processes. In particular, we aim to explain the total
counterfactual effect of an agent's action on the outcome of a realized
scenario through its influence on the environment dynamics and the agents'
behavior. To achieve this, we introduce a novel causal explanation formula that
decomposes the counterfactual effect by attributing to each agent and state
variable a score reflecting their respective contributions to the effect.
First, we show that the total counterfactual effect of an agent's action can be
decomposed into two components: one measuring the effect that propagates
through all subsequent agents' actions and another related to the effect that
propagates through the state transitions. Building on recent advancements in
causal contribution analysis, we further decompose these two effects as
follows. For the former, we consider agent-specific effects -- a causal concept
that quantifies the counterfactual effect of an agent's action that propagates
through a subset of agents. Based on this notion, we use Shapley value to
attribute the effect to individual agents. For the latter, we consider the
concept of structure-preserving interventions and attribute the effect to state
variables based on their "intrinsic" contributions. Through extensive
experimentation, we demonstrate the interpretability of our decomposition
approach in a Gridworld environment with LLM-assisted agents and a sepsis
management simulator.

摘要：我們探討了解釋多智能體馬可夫決策過程中反事實結果的挑戰。特別是，我們旨在透過影響環境動態和智能體的行為，解釋智能體的動作對已實現情境的結果的總體反事實影響。為此，我們引進了一個新穎的因果解釋公式，透過將反事實影響分解，將其歸因於每個智能體和狀態變數，並給予一個反映其對影響的各自貢獻的分數。首先，我們展示了智能體動作的總體反事實影響可以分解成兩個組成部分：一個測量透過所有後續智能體動作傳播的影響，另一個則與透過狀態轉換傳播的影響有關。建立在因果貢獻分析的最新進展上，我們進一步將這兩個影響分解如下。對於前者，我們考慮特定於智能體的影響——一個量化了智能體動作的反事實影響並透過智能體子集傳播的因果概念。基於這個概念，我們使用 Shapley 值將影響歸因於個別智能體。對於後者，我們考慮結構保留介入的概念，並根據其「內在」貢獻將影響歸因於狀態變數。透過廣泛的實驗，我們證明了我們的分解方法在有 LLM 協助的智能體的網格世界環境和敗血症管理模擬器中的可解釋性。

##### **Characterizing Behavioral Differences and Adaptations of Automated Vehicles and Human Drivers at Unsignalized Intersections: Insights from Waymo and Lyft Open Datasets**
2410.12538v1 by Saeed Rahmani, Zhenlin, Xu, Simeon C. Calvert, Bart van Arem

The integration of autonomous vehicles (AVs) into transportation systems
presents an unprecedented opportunity to enhance road safety and efficiency.
However, understanding the interactions between AVs and human-driven vehicles
(HVs) at intersections remains an open research question. This study aims to
bridge this gap by examining behavioral differences and adaptations of AVs and
HVs at unsignalized intersections by utilizing two comprehensive AV datasets
from Waymo and Lyft. Using a systematic methodology, the research identifies
and analyzes merging and crossing conflicts by calculating key safety and
efficiency metrics, including time to collision (TTC), post-encroachment time
(PET), maximum required deceleration (MRD), time advantage (TA), and speed and
acceleration profiles. The findings reveal a paradox in mixed traffic flow:
while AVs maintain larger safety margins, their conservative behavior can lead
to unexpected situations for human drivers, potentially causing unsafe
conditions. From a performance point of view, human drivers exhibit more
consistent behavior when interacting with AVs versus other HVs, suggesting AVs
may contribute to harmonizing traffic flow patterns. Moreover, notable
differences were observed between Waymo and Lyft vehicles, which highlights the
importance of considering manufacturer-specific AV behaviors in traffic
modeling and management strategies for the safe integration of AVs. The
processed dataset utilized in this study is openly published to foster the
research on AV-HV interactions.

摘要：自動駕駛車輛 (AV) 整合到交通系統中，提供了一個前所未有的機會來提升道路安全和效率。然而，了解自動駕駛車輛和人類駕駛車輛 (HV) 在交叉路口的互動，仍然是一個開放的研究問題。本研究旨在透過利用來自 Waymo 和 Lyft 的兩個全面的自動駕駛車輛數據集，探討自動駕駛車輛和人類駕駛車輛在沒有信號燈的交叉路口中的行為差異和適應性，以彌補這個差距。本研究使用系統化的方法，透過計算關鍵的安全和效率指標（包括碰撞時間 (TTC)、侵佔後時間 (PET)、最大所需減速度 (MRD)、時間優勢 (TA) 以及速度和加速度曲線），來識別和分析匯入和交叉衝突。研究結果揭示了混合交通流中的矛盾現象：雖然自動駕駛車輛維持較大的安全裕度，但其保守的行為可能會導致人類駕駛發生意外狀況，進而造成不安全的狀況。從性能的角度來看，人類駕駛在與自動駕駛車輛互動時，表現出比與其他人類駕駛車輛互動時更一致的行為，這表示自動駕駛車輛可能有助於協調交通流模式。此外，在 Waymo 和 Lyft 車輛之間觀察到顯著的差異，這突顯了在交通建模和管理策略中考量特定製造商的自動駕駛車輛行為的重要性，以安全整合自動駕駛車輛。本研究中使用的已處理數據集公開發布，以促進對自動駕駛車輛與人類駕駛車輛互動的研究。

##### **Is Complex Query Answering Really Complex?**
2410.12537v1 by Cosimo Gregucci, Bo Xiong, Daniel Hernandez, Lorenzo Loconte, Pasquale Minervini, Steffen Staab, Antonio Vergari

Complex query answering (CQA) on knowledge graphs (KGs) is gaining momentum
as a challenging reasoning task. In this paper, we show that the current
benchmarks for CQA are not really complex, and the way they are built distorts
our perception of progress in this field. For example, we find that in these
benchmarks, most queries (up to 98% for some query types) can be reduced to
simpler problems, e.g., link prediction, where only one link needs to be
predicted. The performance of state-of-the-art CQA models drops significantly
when such models are evaluated on queries that cannot be reduced to easier
types. Thus, we propose a set of more challenging benchmarks, composed of
queries that require models to reason over multiple hops and better reflect the
construction of real-world KGs. In a systematic empirical investigation, the
new benchmarks show that current methods leave much to be desired from current
CQA methods.

摘要：複雜查詢回答（CQA）在知識圖譜（KG）上正逐漸成為一項具有挑戰性的推理任務。在本文中，我們將表明 CQA 的當前基準並非真正複雜，且其建構方式扭曲了我們對此領域進展的認知。例如，我們發現，在這些基準中，大多數查詢（對於某些查詢類型而言高達 98%）都可以簡化為更簡單的問題，例如連結預測，其中只需要預測一個連結。當此類模型在無法簡化為更簡單類型的查詢上進行評估時，最先進的 CQA 模型的效能會大幅下降。因此，我們提出了一組更具挑戰性的基準，其中包含需要模型透過多個跳躍進行推理並能更好地反映真實世界 KG 建構的查詢。在系統性的實證調查中，新的基準表明，目前的 CQA 方法與理想狀態仍有很大的差距。

##### **MedAide: Towards an Omni Medical Aide via Specialized LLM-based Multi-Agent Collaboration**
2410.12532v2 by Jinjie Wei, Dingkang Yang, Yanshu Li, Qingyao Xu, Zhaoyu Chen, Mingcheng Li, Yue Jiang, Xiaolu Hou, Lihua Zhang

Large Language Model (LLM)-driven interactive systems currently show
potential promise in healthcare domains. Despite their remarkable capabilities,
LLMs typically lack personalized recommendations and diagnosis analysis in
sophisticated medical applications, causing hallucinations and performance
bottlenecks. To address these challenges, this paper proposes MedAide, an
LLM-based omni medical multi-agent collaboration framework for specialized
healthcare services. Specifically, MedAide first performs query rewriting
through retrieval-augmented generation to accomplish accurate medical intent
understanding. Immediately, we devise a contextual encoder to obtain intent
prototype embeddings, which are used to recognize fine-grained intents by
similarity matching. According to the intent relevance, the activated agents
collaborate effectively to provide integrated decision analysis. Extensive
experiments are conducted on four medical benchmarks with composite intents.
Experimental results from automated metrics and expert doctor evaluations show
that MedAide outperforms current LLMs and improves their medical proficiency
and strategic reasoning.

摘要：大型語言模型 (LLM) 驅動的互動系統目前在醫療領域展現潛在的希望。儘管有其非凡的能力，LLM 在複雜的醫療應用中通常缺乏個人化建議和診斷分析，導致出現幻覺和效能瓶頸。為了應對這些挑戰，本文提出了 MedAide，一個基於 LLM 的全方位醫療多代理協作架構，用於專業醫療服務。具體來說，MedAide 首先透過檢索增強生成來執行查詢改寫，以達成準確的醫療意圖理解。接著，我們設計一個脈絡編碼器來取得意圖原型嵌入，用於透過相似性比對來辨識細緻的意圖。根據意圖相關性，已啟動的代理有效地協作以提供整合的決策分析。在具有複合意圖的四個醫療基準上進行了廣泛的實驗。自動化指標和專家醫師評估的實驗結果顯示，MedAide 優於目前的 LLM，並提升其醫療專業知識和策略推理。

##### **Spectrum Sharing using Deep Reinforcement Learning in Vehicular Networks**
2410.12521v1 by Riya Dinesh Deshpande, Faheem A. Khan, Qasim Zeeshan Ahmed

As the number of devices getting connected to the vehicular network grows
exponentially, addressing the numerous challenges of effectively allocating
spectrum in dynamic vehicular environment becomes increasingly difficult.
Traditional methods may not suffice to tackle this issue. In vehicular networks
safety critical messages are involved and it is important to implement an
efficient spectrum allocation paradigm for hassle free communication as well as
manage the congestion in the network. To tackle this, a Deep Q Network (DQN)
model is proposed as a solution, leveraging its ability to learn optimal
strategies over time and make decisions. The paper presents a few results and
analyses, demonstrating the efficacy of the DQN model in enhancing spectrum
sharing efficiency. Deep Reinforcement Learning methods for sharing spectrum in
vehicular networks have shown promising outcomes, demonstrating the system's
ability to adjust to dynamic communication environments. Both SARL and MARL
models have exhibited successful rates of V2V communication, with the
cumulative reward of the RL model reaching its maximum as training progresses.

摘要：隨著連接到車輛網路的裝置數量呈指數成長，在動態的車輛環境中有效分配頻譜的眾多挑戰變得越來越困難。傳統方法可能不足以解決此問題。在車輛網路中涉及安全關鍵訊息，並且實施有效的頻譜分配範例對於無障礙通訊以及管理網路中的壅塞非常重要。為了解決此問題，提出了深度 Q 網路 (DQN) 模型作為解決方案，利用其隨著時間推移學習最佳策略和做出決策的能力。本文提出了一些結果和分析，證明了 DQN 模型在提高頻譜共享效率方面的效能。車輛網路中用於共享頻譜的深度強化學習方法已顯示出有希望的結果，證明了系統適應動態通訊環境的能力。SARL 和 MARL 模型都展現了成功的 V2V 通訊速率，RL 模型的累積回報隨著訓練的進行而達到最大值。

##### **FiRST: Finetuning Router-Selective Transformers for Input-Adaptive Latency Reduction**
2410.12513v1 by Akriti Jain, Saransh Sharma, Koyel Mukherjee, Soumyabrata Pal

Auto-regressive Large Language Models (LLMs) demonstrate remarkable
performance across domanins such as vision and language processing. However,
due to sequential processing through a stack of transformer layers,
autoregressive decoding faces significant computation/latency challenges,
particularly in resource constrained environments like mobile and edge devices.
Existing approaches in literature that aim to improve latency via skipping
layers have two distinct flavors - 1) Early exit 2) Input-agnostic heuristics
where tokens exit at pre-determined layers irrespective of input sequence. Both
the above strategies have limitations - the former cannot be applied to handle
KV Caching necessary for speed-ups in modern framework and the latter does not
capture the variation in layer importance across tasks or more generally,
across input sequences. To address both limitations, we propose FIRST, an
algorithm that reduces inference latency by using layer-specific routers to
select a subset of transformer layers adaptively for each input sequence - the
prompt (during prefill stage) decides which layers will be skipped during
decoding. FIRST preserves compatibility with KV caching enabling faster
inference while being quality-aware. FIRST is model-agnostic and can be easily
enabled on any pre-trained LLM. We further improve performance by incorporating
LoRA adapters for fine-tuning on external datasets, enhancing task-specific
accuracy while maintaining latency benefits. Our approach reveals that input
adaptivity is critical - indeed, different task-specific middle layers play a
crucial role in evolving hidden representations depending on task. Extensive
experiments show that FIRST significantly reduces latency while retaining
competitive performance (as compared to baselines), making our approach an
efficient solution for LLM deployment in low-resource environments.

摘要：自動回歸大型語言模型 (LLM) 在視覺和語言處理等領域表現出色。然而，由於通過堆疊轉換器層進行順序處理，自動回歸解碼面臨著顯著的計算/延遲挑戰，特別是在移動和邊緣設備等資源受限的環境中。現有文獻中旨在通過跳過層來改善延遲的方法有兩種不同的風格 - 1) 早期退出 2) 與輸入無關的啟發式方法，其中令牌在預先確定的層退出，而與輸入序列無關。上述兩種策略都有局限性 - 前者不能用於處理現代框架中加速所需的 KV 快取，而後者沒有捕捉到跨任務或更一般地跨輸入序列的層重要性的變化。為了解決這兩個限制，我們提出了 FIRST，這是一種通過使用特定於層的路由器自適應地為每個輸入序列選擇轉換器層子集來減少推論延遲的演算法 - 提示 (在預填充階段) 決定在解碼過程中將跳過哪些層。FIRST 保持與 KV 快取的相容性，從而在保證品質的同時實現更快的推論。FIRST 與模型無關，並且可以輕鬆地在任何預先訓練的 LLM 上啟用。我們進一步通過整合 LoRA 適配器來改進在外部資料集上的微調效能，在保持延遲優勢的同時提高特定任務的準確度。我們的做法表明，輸入自適應性至關重要 - 事實上，不同的特定任務中間層在根據任務演化隱藏表示方面發揮著至關重要的作用。大量的實驗表明，FIRST 在保持競爭效能的同時顯著降低了延遲 (與基線相比)，使我們的做法成為在低資源環境中部署 LLM 的有效解決方案。

##### **Advancing Fairness in Natural Language Processing: From Traditional Methods to Explainability**
2410.12511v1 by Fanny Jourdan

The burgeoning field of Natural Language Processing (NLP) stands at a
critical juncture where the integration of fairness within its frameworks has
become an imperative. This PhD thesis addresses the need for equity and
transparency in NLP systems, recognizing that fairness in NLP is not merely a
technical challenge but a moral and ethical necessity, requiring a rigorous
examination of how these technologies interact with and impact diverse human
populations. Through this lens, this thesis undertakes a thorough investigation
into the development of equitable NLP methodologies and the evaluation of
biases that prevail in current systems.
  First, it introduces an innovative algorithm to mitigate biases in
multi-class classifiers, tailored for high-risk NLP applications, surpassing
traditional methods in both bias mitigation and prediction accuracy. Then, an
analysis of the Bios dataset reveals the impact of dataset size on
discriminatory biases and the limitations of standard fairness metrics. This
awareness has led to explorations in the field of explainable AI, aiming for a
more complete understanding of biases where traditional metrics are limited.
Consequently, the thesis presents COCKATIEL, a model-agnostic explainability
method that identifies and ranks concepts in Transformer models, outperforming
previous approaches in sentiment analysis tasks. Finally, the thesis
contributes to bridging the gap between fairness and explainability by
introducing TaCo, a novel method to neutralize bias in Transformer model
embeddings.
  In conclusion, this thesis constitutes a significant interdisciplinary
endeavor that intertwines explicability and fairness to challenge and reshape
current NLP paradigms. The methodologies and critiques presented contribute to
the ongoing discourse on fairness in machine learning, offering actionable
solutions for more equitable and responsible AI systems.

摘要：<paragraph>自然語言處理 (NLP) 蓬勃發展的領域正處於一個關鍵時刻，在其中，公平性的整合已成為其架構中的一項要務。本博士論文探討了 NLP 系統中公平性和透明性的需求，並認識到 NLP 中的公平性不僅僅是一項技術挑戰，更是一項道德和倫理必要性，需要嚴格審查這些技術如何與不同的人群互動並對其產生影響。透過此觀點，本論文對公平 NLP 方法的開發以及當前系統中普遍存在的偏差進行了徹底調查。
首先，它引入了一種創新的演算法來減輕多類別分類器中的偏差，專門針對高風險 NLP 應用，在偏差減輕和預測準確性方面都優於傳統方法。然後，對 Bios 資料集的分析揭示了資料集大小對歧視性偏差的影響以及標準公平性指標的限制。這種認知已導致在可解釋 AI 領域的探索，旨在更全面地了解傳統指標受限的偏差。因此，本論文提出了 COCKATIEL，這是一種與模型無關的可解釋性方法，它可以識別和排列 Transformer 模型中的概念，在情緒分析任務中優於先前的做法。最後，本論文透過引入 TaCo，一種在 Transformer 模型嵌入中消除偏差的新方法，為彌合公平性和可解釋性之間的差距做出了貢獻。
總之，本論文構成了一項重要的跨學科努力，它將可解釋性和公平性交織在一起，以挑戰和重塑當前的 NLP 典範。提出的方法和批評有助於關於機器學習中公平性的持續討論，為更公平且負責任的 AI 系統提供了可行的解決方案。</paragraph>

##### **Benchmarking Defeasible Reasoning with Large Language Models -- Initial Experiments and Future Directions**
2410.12509v1 by Ilias Tachmazidis, Sotiris Batsakis, Grigoris Antoniou

Large Language Models (LLMs) have gained prominence in the AI landscape due
to their exceptional performance. Thus, it is essential to gain a better
understanding of their capabilities and limitations, among others in terms of
nonmonotonic reasoning. This paper proposes a benchmark that corresponds to
various defeasible rule-based reasoning patterns. We modified an existing
benchmark for defeasible logic reasoners by translating defeasible rules into
text suitable for LLMs. We conducted preliminary experiments on nonmonotonic
rule-based reasoning using ChatGPT and compared it with reasoning patterns
defined by defeasible logic.

摘要：大型語言模型 (LLM) 在人工智慧領域中獲得顯著地位，因為它們具有傑出的表現。因此，有必要對它們的能力和限制有更深入的了解，其中包括非單調推理。本文提出了對應於各種可推翻規則推理模式的基準。我們修改了一個現有的可推翻邏輯推理基準，將可推翻規則轉換為適合 LLM 的文字。我們對使用 ChatGPT 的非單調規則推理進行了初步實驗，並將其與可推翻邏輯定義的推理模式進行了比較。

##### **DH-VTON: Deep Text-Driven Virtual Try-On via Hybrid Attention Learning**
2410.12501v1 by Jiabao Wei, Zhiyuan Ma

Virtual Try-ON (VTON) aims to synthesis specific person images dressed in
given garments, which recently receives numerous attention in online shopping
scenarios. Currently, the core challenges of the VTON task mainly lie in the
fine-grained semantic extraction (i.e.,deep semantics) of the given reference
garments during depth estimation and effective texture preservation when the
garments are synthesized and warped onto human body. To cope with these issues,
we propose DH-VTON, a deep text-driven virtual try-on model featuring a special
hybrid attention learning strategy and deep garment semantic preservation
module. By standing on the shoulder of a well-built pre-trained
paint-by-example (abbr. PBE) approach, we present our DH-VTON pipeline in this
work. Specifically, to extract the deep semantics of the garments, we first
introduce InternViT-6B as fine-grained feature learner, which can be trained to
align with the large-scale intrinsic knowledge with deep text semantics
(e.g.,"neckline" or "girdle") to make up for the deficiency of the commonly
adopted CLIP encoder. Based on this, to enhance the customized dressing
abilities, we further introduce Garment-Feature ControlNet Plus (abbr. GFC+)
module and propose to leverage a fresh hybrid attention strategy for training,
which can adaptively integrate fine-grained characteristics of the garments
into the different layers of the VTON model, so as to achieve multi-scale
features preservation effects. Extensive experiments on several representative
datasets demonstrate that our method outperforms previous diffusion-based and
GAN-based approaches, showing competitive performance in preserving garment
details and generating authentic human images.

摘要：虛擬試穿（VTON）旨在合成特定人物穿著指定服裝的影像，最近在線上購物情境中受到廣泛關注。目前，VTON 任務的核心挑戰主要在於深度估計期間指定參考服裝的細緻語義萃取（即深度語義），以及在服裝合成並變形到人體上時有效保留紋理。為了應對這些問題，我們提出 DH-VTON，一種以特殊混合注意力學習策略和深度服裝語義保留模組為特色的深度文字驅動虛擬試穿模型。在這項工作中，我們建立在一個建構良好的預訓練範例繪製（簡稱 PBE）方法的基礎上，提出我們的 DH-VTON 處理程序。具體來說，為了萃取服裝的深度語義，我們首先引入 InternViT-6B 作為細緻特徵學習器，它可以訓練與具有深度文字語義（例如，「領口」或「腰帶」）的大規模內在知識保持一致，以彌補常採用的 CLIP 編碼器的不足。基於此，為了增強客製化穿著能力，我們進一步引入服裝特徵控制網路 Plus（簡稱 GFC+）模組，並提出利用新的混合注意力策略進行訓練，它可以自適應地將服裝的細緻特徵整合到 VTON 模型的不同層中，以實現多尺度特徵保留效果。在幾個具有代表性的資料集上進行的廣泛實驗表明，我們的模型優於先前的基於擴散和基於 GAN 的方法，在保留服裝細節和生成真實的人體影像方面展現出競爭力的效能。

##### **With a Grain of SALT: Are LLMs Fair Across Social Dimensions?**
2410.12499v1 by Samee Arif, Zohaib Khan, Agha Ali Raza, Awais Athar

This paper presents an analysis of biases in open-source Large Language
Models (LLMs) across various genders, religions, and races. We introduce a
methodology for generating a bias detection dataset using seven bias triggers:
General Debate, Positioned Debate, Career Advice, Story Generation,
Problem-Solving, Cover-Letter Writing, and CV Generation. We use GPT-4o to
generate a diverse set of prompts for each trigger across various genders,
religious and racial groups. We evaluate models from Llama and Gemma family on
the generated dataset. We anonymise the LLM-generated text associated with each
group using GPT-4o-mini and do a pairwise comparison using GPT-4o-as-a-Judge.
To quantify bias in the LLM-generated text we use the number of wins and losses
in the pairwise comparison. Our analysis spans three languages, English,
German, and Arabic to explore how language influences bias manifestation. Our
findings reveal that LLMs exhibit strong polarization toward certain groups
across each category, with a notable consistency observed across models.
However, when switching languages, variations and anomalies emerge, often
attributable to cultural cues and contextual differences.

摘要：這篇論文分析了開放原始碼大型語言模型 (LLM) 中各種性別、宗教和種族偏見。我們引入了一種生成偏見檢測資料集的方法，使用七個偏見觸發器：一般性辯論、立場辯論、職業建議、故事生成、問題解決、求職信撰寫和履歷生成。我們使用 GPT-4o 為各種性別、宗教和種族群體的每個觸發器生成一組多樣的提示。我們根據生成的資料集評估了 Llama 和 Gemma 家族的模型。我們使用 GPT-4o-mini 對與每個群組相關的 LLM 生成的文字進行匿名化，並使用 GPT-4o-as-a-Judge 進行成對比較。為了量化 LLM 生成的文字中的偏見，我們使用成對比較中的勝利和失敗次數。我們的分析涵蓋了英語、德語和阿拉伯語三種語言，以探討語言如何影響偏見表現。我們的研究結果表明，LLM 對每個類別中的某些群體表現出強烈的兩極分化，並且在各個模型中觀察到顯著的一致性。然而，在切換語言時，會出現變異和異常，通常歸因於文化線索和背景差異。

##### **End-to-end Planner Training for Language Modeling**
2410.12492v1 by Nathan Cornille, Florian Mai, Jingyuan Sun, Marie-Francine Moens

Through end-to-end training to predict the next token, LLMs have become
valuable tools for various tasks. Enhancing their core training in language
modeling can improve numerous downstream applications. A successful approach to
enhance language modeling uses a separate planning module to predict abstract
labels of future sentences and conditions the LM on these predictions. However,
this method is non-differentiable, preventing joint end-to-end tuning of the
planner with the LM. We propose an effective method to improve this approach by
enabling joint fine-tuning of the planner and the LM. We show that a naive way
of approximating the gradient of selecting a label via the straight-through
estimator is not effective. Instead, we propose to use the predicted label
probabilities as mixing weights to condition the LM on a weighted average of
label embeddings in a differentiable manner. This not only enables joint
fine-tuning of the planner and the LM, but also allows the LM to draw on the
full label distribution predicted by the planner, retaining more information.
Our experimental results show consistent improvements in perplexity.

摘要：透過端對端訓練來預測下一個符號，LLM 已成為各種任務的寶貴工具。增強其在語言模型中的核心訓練可以改善許多下游應用程式。增強語言模型的一個成功方法是使用一個獨立的規劃模組來預測未來句子的抽象標籤，並根據這些預測對 LM 進行條件化。然而，這種方法是不可微分的，阻止了規劃器與 LM 的聯合端對端調整。我們提出了一種有效的方法來改善這種方法，方法是讓規劃器和 LM 能夠進行聯合微調。我們表明，通過直通估計器來近似選擇標籤的梯度是一種天真的方式，這種方式是無效的。相反，我們建議使用預測的標籤機率作為混合權重，以可微分的方式對 LM 進行條件化，使其根據標籤嵌入的加權平均值進行條件化。這不僅能讓規劃器和 LM 進行聯合微調，還能讓 LM 利用規劃器預測的完整標籤分佈，從而保留更多資訊。我們的實驗結果顯示困惑度持續改善。

##### **Insights from the Inverse: Reconstructing LLM Training Goals Through Inverse RL**
2410.12491v1 by Jared Joselowitz, Arjun Jagota, Satyapriya Krishna, Sonali Parbhoo

Large language models (LLMs) trained with Reinforcement Learning from Human
Feedback (RLHF) have demonstrated remarkable capabilities, but their underlying
reward functions and decision-making processes remain opaque. This paper
introduces a novel approach to interpreting LLMs by applying inverse
reinforcement learning (IRL) to recover their implicit reward functions. We
conduct experiments on toxicity-aligned LLMs of varying sizes, extracting
reward models that achieve up to 80.40% accuracy in predicting human
preferences. Our analysis reveals key insights into the non-identifiability of
reward functions, the relationship between model size and interpretability, and
potential pitfalls in the RLHF process. We demonstrate that IRL-derived reward
models can be used to fine-tune new LLMs, resulting in comparable or improved
performance on toxicity benchmarks. This work provides a new lens for
understanding and improving LLM alignment, with implications for the
responsible development and deployment of these powerful systems.

摘要：大型语言模型（LLM）经过人类反馈强化学习（RLHF）训练，展示了非凡的能力，但其底层奖励函数和决策过程仍然不透明。本文介绍了一种通过应用逆向强化学习（IRL）来解释 LLM 的新方法，以恢复其隐式奖励函数。我们对不同规模的毒性对齐 LLM 进行了实验，提取了奖励模型，其在预测人类偏好方面实现了高达 80.40% 的准确度。我们的分析揭示了奖励函数不可识别的关键见解、模型大小与可解释性之间的关系以及 RLHF 过程中的潜在缺陷。我们证明了 IRL 衍生的奖励模型可用于微调新的 LLM，从而在毒性基准上产生可比或改进的性能。这项工作为理解和改进 LLM 对齐提供了一个新的视角，对这些强大系统的负责任开发和部署具有影响。

##### **Stabilize the Latent Space for Image Autoregressive Modeling: A Unified Perspective**
2410.12490v1 by Yongxin Zhu, Bocheng Li, Hang Zhang, Xin Li, Linli Xu, Lidong Bing

Latent-based image generative models, such as Latent Diffusion Models (LDMs)
and Mask Image Models (MIMs), have achieved notable success in image generation
tasks. These models typically leverage reconstructive autoencoders like VQGAN
or VAE to encode pixels into a more compact latent space and learn the data
distribution in the latent space instead of directly from pixels. However, this
practice raises a pertinent question: Is it truly the optimal choice? In
response, we begin with an intriguing observation: despite sharing the same
latent space, autoregressive models significantly lag behind LDMs and MIMs in
image generation. This finding contrasts sharply with the field of NLP, where
the autoregressive model GPT has established a commanding presence. To address
this discrepancy, we introduce a unified perspective on the relationship
between latent space and generative models, emphasizing the stability of latent
space in image generative modeling. Furthermore, we propose a simple but
effective discrete image tokenizer to stabilize the latent space for image
generative modeling. Experimental results show that image autoregressive
modeling with our tokenizer (DiGIT) benefits both image understanding and image
generation with the next token prediction principle, which is inherently
straightforward for GPT models but challenging for other generative models.
Remarkably, for the first time, a GPT-style autoregressive model for images
outperforms LDMs, which also exhibits substantial improvement akin to GPT when
scaling up model size. Our findings underscore the potential of an optimized
latent space and the integration of discrete tokenization in advancing the
capabilities of image generative models. The code is available at
\url{https://github.com/DAMO-NLP-SG/DiGIT}.

摘要：<paragraph>潛在圖像生成模型，例如潛在擴散模型 (LDM) 和遮罩圖像模型 (MIM)，在圖像生成任務中取得了顯著的成功。這些模型通常利用重建自動編碼器，例如 VQGAN 或 VAE，將像素編碼成更緊湊的潛在空間，並在潛在空間中學習資料分佈，而不是直接從像素中學習。但是，這種做法引發了一個相關的問題：這真的是最佳選擇嗎？作為回應，我們從一個有趣的觀察開始：儘管共享相同的潛在空間，但自迴歸模型在圖像生成中顯著落後於 LDM 和 MIM。這一發現與 NLP 領域形成鮮明對比，在 NLP 領域，自迴歸模型 GPT 已確立了主導地位。為了解決這種差異，我們對潛在空間和生成模型之間的關係引入了一個統一的觀點，強調了潛在空間在圖像生成建模中的穩定性。此外，我們提出了一個簡單但有效的離散圖像分詞器，以穩定圖像生成建模的潛在空間。實驗結果表明，使用我們的分詞器 (DiGIT) 的圖像自迴歸建模既有利於圖像理解，也有利於圖像生成，其下一個符號預測原理本質上對 GPT 模型來說很簡單，但對其他生成模型來說卻很有挑戰性。值得注意的是，對於圖像，GPT 風格自迴歸模型首次優於 LDM，這也表現出類似於 GPT 在擴大模型規模時的顯著改進。我們的發現強調了優化潛在空間和整合離散分詞在提升圖像生成模型能力方面的潛力。程式碼可在 \url{https://github.com/DAMO-NLP-SG/DiGIT} 獲得。</paragraph>

##### **SAC-GLAM: Improving Online RL for LLM agents with Soft Actor-Critic and Hindsight Relabeling**
2410.12481v1 by Loris Gaven, Clement Romac, Thomas Carta, Sylvain Lamprier, Olivier Sigaud, Pierre-Yves Oudeyer

The past years have seen Large Language Models (LLMs) strive not only as
generative models but also as agents solving textual sequential decision-making
tasks. When facing complex environments where their zero-shot abilities are
insufficient, recent work showed online Reinforcement Learning (RL) could be
used for the LLM agent to discover and learn efficient strategies
interactively. However, most prior work sticks to on-policy algorithms, which
greatly reduces the scope of methods such agents could use for both exploration
and exploitation, such as experience replay and hindsight relabeling. Yet, such
methods may be key for LLM learning agents, and in particular when designing
autonomous intrinsically motivated agents sampling and pursuing their own goals
(i.e. autotelic agents). This paper presents and studies an adaptation of Soft
Actor-Critic and hindsight relabeling to LLM agents. Our method not only paves
the path towards autotelic LLM agents that learn online but can also outperform
on-policy methods in more classic multi-goal RL environments.

摘要：近年來，大型語言模型 (LLM) 不僅作為生成模型，也作為解決文本順序決策任務的代理而努力。在面對其零次學習能力不足的複雜環境時，最近的研究表明，線上強化學習 (RL) 可用於 LLM 代理互動式地發現和學習有效策略。然而，大多數先前的研究都堅持使用策略梯度演算法，這大大減少了此類代理在探索和開發中可使用的方法的範圍，例如經驗重播和回顧式重新標記。然而，此類方法可能是 LLM 學習代理的關鍵，特別是在設計自主的內在動機代理，對自己的目標進行取樣和追求時 (即自動目標代理)。本文提出並研究了 Soft Actor-Critic 和回顧式重新標記對 LLM 代理的改編。我們的模型不僅為學習線上自動目標 LLM 代理鋪平了道路，還可以勝過更經典的多目標 RL 環境中的策略梯度演算法。

##### **KcMF: A Knowledge-compliant Framework for Schema and Entity Matching with Fine-tuning-free LLMs**
2410.12480v1 by Yongqin Xu, Huan Li, Ke Chen, Lidan Shou

Schema and entity matching tasks are crucial for data integration and
management. While large language models (LLMs) have shown promising results in
these tasks, they suffer from hallucinations and confusion about task
instructions. In this paper, we present the Knowledge-Compliant Matching
Framework (KcMF), an LLM-based approach that addresses these issues without the
need for domain-specific fine-tuning. KcMF employs a pseudo-code-based task
decomposition strategy to adopt task-specific natural language statements that
guide LLM reasoning and reduce confusion. We also propose two mechanisms,
Dataset as Knowledge (DaK) and Example as Knowledge (EaK), to build domain
knowledge sets when unstructured domain knowledge is lacking. Additionally, we
introduce a result-ensembling strategy to leverage multiple knowledge sources
and suppress poorly formatted outputs. Comprehensive evaluations on schema and
entity matching tasks demonstrate that KcMF outperforms previous non-LLM
state-of-the-art (SOTA) methods by an average F1 score of 22.9% and competes
effectively with SOTA fine-tuned LLMs. Moreover, KcMF generalizes well across
different LLMs.

摘要：架構和實體比對任務對於資料整合和管理至關重要。儘管大型語言模型 (LLM) 已在這些任務中展現出令人滿意的結果，但它們卻會出現幻覺，且對任務指示感到困惑。在本文中，我們提出知識相容比對架構 (KcMF)，這是一種基於 LLM 的方法，可解決這些問題，而無需特定領域的微調。KcMF 採用基於偽程式碼的任務分解策略，以採用特定任務的自然語言陳述，引導 LLM 推理並減少困惑。我們還提出兩種機制，資料集作為知識 (DaK) 和範例作為知識 (EaK)，在缺乏非結構化領域知識時建立領域知識集。此外，我們引入結果整合策略，以利用多個知識來源並抑制格式不佳的輸出。架構和實體比對任務的綜合評估表明，KcMF 在平均 F1 分數方面優於先前的非 LLM 最先進 (SOTA) 方法 22.9%，並與 SOTA 微調 LLM 有效競爭。此外，KcMF 在不同的 LLM 中具有良好的泛化性。

##### **MlingConf: A Comprehensive Study of Multilingual Confidence Estimation on Large Language Models**
2410.12478v1 by Boyang Xue, Hongru Wang, Rui Wang, Sheng Wang, Zezhong Wang, Yiming Du, Bin Liang, Kam-Fai Wong

The tendency of Large Language Models (LLMs) to generate hallucinations
raises concerns regarding their reliability. Therefore, confidence estimations
indicating the extent of trustworthiness of the generations become essential.
However, current LLM confidence estimations in languages other than English
remain underexplored. This paper addresses this gap by introducing a
comprehensive investigation of Multilingual Confidence estimation (MlingConf)
on LLMs, focusing on both language-agnostic (LA) and language-specific (LS)
tasks to explore the performance and language dominance effects of multilingual
confidence estimations on different tasks. The benchmark comprises four
meticulously checked and human-evaluate high-quality multilingual datasets for
LA tasks and one for the LS task tailored to specific social, cultural, and
geographical contexts of a language. Our experiments reveal that on LA tasks
English exhibits notable linguistic dominance in confidence estimations than
other languages, while on LS tasks, using question-related language to prompt
LLMs demonstrates better linguistic dominance in multilingual confidence
estimations. The phenomena inspire a simple yet effective native-tone prompting
strategy by employing language-specific prompts for LS tasks, effectively
improving LLMs' reliability and accuracy on LS tasks.

摘要：大型語言模型 (LLM) 產生幻覺的傾向引發了人們對其可靠性的擔憂。因此，指示世代可信度程度的信心估計變得至關重要。然而，目前 LLM 對英語以外語言的信心估計仍未得到充分探討。本文通過對多語言信心估計 (MlingConf) 進行全面的調查來解決這一差距，重點關注語言不可知 (LA) 和特定語言 (LS) 任務，以探索多語言信心估計在不同任務上的效能和語言優勢效應。基準包含四個經過仔細檢查和人工評估的高品質多語言資料集，用於 LA 任務，以及一個針對特定語言的社會、文化和地理背景量身打造的 LS 任務。我們的實驗表明，在 LA 任務中，英語在信心估計中表現出比其他語言顯著的語言優勢，而在 LS 任務中，使用與問題相關的語言提示 LLM 在多語言信心估計中表現出更好的語言優勢。這些現象激發了一種簡單但有效的原生語調提示策略，通過為 LS 任務採用特定語言的提示，有效提高了 LLM 在 LS 任務上的可靠性和準確性。

##### **Retrieval-Reasoning Large Language Model-based Synthetic Clinical Trial Generation**
2410.12476v1 by Zerui Xu, Fang Wu, Tianfan Fu, Yue Zhao

Machine learning (ML) exhibits promise in the clinical domain. However, it is
constrained by data scarcity and ethical considerations, as the generation of
clinical trials presents significant challenges due to stringent privacy
regulations, high costs, and the extended duration required for conducting
studies with human participants. Despite the advancements of large language
models (LLMs) in general generation tasks, their potential in facilitating the
generation of synthetic clinical trials is under-explored. To address this gap,
we introduce a novel Retrieval-Reasoning few-shot framework that leverages LLMs
to generate artificial yet realistic and diverse clinical trials with binary
success/failure labels. Experiments conducted on real clinical trials from the
\url{ClinicalTrials.gov} database demonstrate that our synthetic data can
effectively augment real datasets. Furthermore, by fine-tuning a pre-trained
model as a binary classifier on synthetic clinical trial datasets, we
demonstrate that this augmentation enhances model training for downstream tasks
such as trial outcome prediction. Our findings suggest that LLMs for synthetic
clinical trial generation hold promise for accelerating clinical research and
upholding ethical standards for patient privacy. The code is publicly available
at
https://anonymous.4open.science/r/Retrieval_Reasoning_Clinical_Trial_Generation-3EC4.

摘要：機器學習 (ML) 在臨床領域展現出前景。然而，它受到資料稀少性和倫理考量的限制，因為臨床試驗的產生會帶來嚴峻的挑戰，原因在於嚴格的隱私法規、高昂的成本，以及進行有人類參與者研究所需的時間很長。儘管大型語言模型 (LLM) 在一般生成任務中進展神速，它們在促進合成臨床試驗生成方面的潛力尚未被充分探討。為了解決這個差距，我們引進一個創新的檢索推理少樣本框架，它利用 LLM 來產生人工但逼真且多樣的臨床試驗，並具有二元成功/失敗標籤。在來自 \url{ClinicalTrials.gov} 資料庫的實際臨床試驗中進行的實驗證明，我們的合成資料可以有效地擴充實際資料集。此外，透過將預先訓練的模型微調為合成臨床試驗資料集上的二元分類器，我們證明了這種擴充增強了模型訓練，以進行下游任務，例如試驗結果預測。我們的研究結果表明，用於合成臨床試驗生成的 LLM 有望加速臨床研究，並維護患者隱私的倫理標準。程式碼已公開在 https://anonymous.4open.science/r/Retrieval_Reasoning_Clinical_Trial_Generation-3EC4。

##### **Unifying Economic and Language Models for Enhanced Sentiment Analysis of the Oil Market**
2410.12473v1 by Himmet Kaplan, Ralf-Peter Mundani, Heiko Rölke, Albert Weichselbraun, Martin Tschudy

Crude oil, a critical component of the global economy, has its prices
influenced by various factors such as economic trends, political events, and
natural disasters. Traditional prediction methods based on historical data have
their limits in forecasting, but recent advancements in natural language
processing bring new possibilities for event-based analysis. In particular,
Language Models (LM) and their advancement, the Generative Pre-trained
Transformer (GPT), have shown potential in classifying vast amounts of natural
language. However, these LMs often have difficulty with domain-specific
terminology, limiting their effectiveness in the crude oil sector. Addressing
this gap, we introduce CrudeBERT, a fine-tuned LM specifically for the crude
oil market. The results indicate that CrudeBERT's sentiment scores align more
closely with the WTI Futures curve and significantly enhance price predictions,
underscoring the crucial role of integrating economic principles into LMs.

摘要：原油是全球經濟的重要組成部分，其價格受經濟趨勢、政治事件和自然災害等各種因素影響。基於歷史數據的傳統預測方法在預測方面存在局限性，但自然語言處理的最新進展為基於事件的分析帶來了新的可能性。特別是，語言模型 (LM) 及其進步，生成式預訓練Transformer (GPT)，已顯示出對大量自然語言進行分類的潛力。然而，這些 LM 通常難以處理特定領域的術語，這限制了它們在原油領域的有效性。為了解決這一差距，我們引入了 CrudeBERT，這是一個專門針對原油市場進行微調的 LM。結果表明，CrudeBERT 的情緒分數與 WTI 期貨曲線更為一致，並顯著提高了價格預測，這強調了將經濟原理整合到 LM 中至關重要的作用。

##### **Learning to Predict Usage Options of Product Reviews with LLM-Generated Labels**
2410.12470v1 by Leo Kohlenberg, Leonard Horns, Frederic Sadrieh, Nils Kiele, Matthis Clausen, Konstantin Ketterer, Avetis Navasardyan, Tamara Czinczoll, Gerard de Melo, Ralf Herbrich

Annotating large datasets can be challenging. However, crowd-sourcing is
often expensive and can lack quality, especially for non-trivial tasks. We
propose a method of using LLMs as few-shot learners for annotating data in a
complex natural language task where we learn a standalone model to predict
usage options for products from customer reviews. We also propose a new
evaluation metric for this scenario, HAMS4, that can be used to compare a set
of strings with multiple reference sets. Learning a custom model offers
individual control over energy efficiency and privacy measures compared to
using the LLM directly for the sequence-to-sequence task. We compare this data
annotation approach with other traditional methods and demonstrate how LLMs can
enable considerable cost savings. We find that the quality of the resulting
data exceeds the level attained by third-party vendor services and that
GPT-4-generated labels even reach the level of domain experts. We make the code
and generated labels publicly available.

摘要：標註大型資料集可能具有挑戰性。然而，群眾外包通常很昂貴，而且可能缺乏品質，尤其是對於非平凡的任務。我們提出一種將 LLM 用作少次學習器的方法，用於在複雜的自然語言任務中標註資料，其中我們學習一個獨立的模型來預測客戶評論中產品的使用選項。我們還為此情境提出一個新的評估指標 HAMS4，可用於比較一組字串與多個參考組。與直接將 LLM 用於序列到序列任務相比，學習自訂模型提供對能源效率和隱私措施的個別控制。我們將此資料標註方法與其他傳統方法進行比較，並展示 LLM 如何節省可觀的成本。我們發現，產生的資料品質超過第三方供應商服務達到的水準，而 GPT-4 生成的標籤甚至達到領域專家的水準。我們公開程式碼和產生的標籤。

##### **Evaluating Software Development Agents: Patch Patterns, Code Quality, and Issue Complexity in Real-World GitHub Scenarios**
2410.12468v1 by Zhi Chen, Lingxiao Jiang

In recent years, AI-based software engineering has progressed from
pre-trained models to advanced agentic workflows, with Software Development
Agents representing the next major leap. These agents, capable of reasoning,
planning, and interacting with external environments, offer promising solutions
to complex software engineering tasks. However, while much research has
evaluated code generated by large language models (LLMs), comprehensive studies
on agent-generated patches, particularly in real-world settings, are lacking.
This study addresses that gap by evaluating 4,892 patches from 10 top-ranked
agents on 500 real-world GitHub issues from SWE-Bench Verified, focusing on
their impact on code quality. Our analysis shows no single agent dominated,
with 170 issues unresolved, indicating room for improvement. Even for patches
that passed unit tests and resolved issues, agents made different file and
function modifications compared to the gold patches from repository developers,
revealing limitations in the benchmark's test case coverage. Most agents
maintained code reliability and security, avoiding new bugs or vulnerabilities;
while some agents increased code complexity, many reduced code duplication and
minimized code smells. Finally, agents performed better on simpler codebases,
suggesting that breaking complex tasks into smaller sub-tasks could improve
effectiveness. This study provides the first comprehensive evaluation of
agent-generated patches on real-world GitHub issues, offering insights to
advance AI-driven software development.

摘要：在最近几年，基于 AI 的软件工程已从预先训练的模型发展到先进的代理工作流程，其中软件开发代理代表了下一个重大飞跃。这些代理能够推理、规划和与外部环境互动，为复杂的软件工程任务提供了有希望的解决方案。然而，虽然许多研究已经评估了大型语言模型（LLM）生成的代码，但对代理生成的补丁的全面研究，特别是在实际环境中，仍然缺乏。本研究通过评估来自 SWE-Bench Verified 的 500 个实际 GitHub 问题上的 10 个顶级代理的 4,892 个补丁来解决这一差距，重点关注它们对代码质量的影响。我们的分析表明没有一个代理占主导地位，有 170 个问题未解决，表明有改进的空间。即使对于通过单元测试并解决问题的补丁，代理也对文件和函数进行了与存储库开发人员的黄金补丁不同的修改，揭示了基准测试用例覆盖范围的局限性。大多数代理维护了代码的可靠性和安全性，避免了新的错误或漏洞；而一些代理增加了代码复杂性，许多代理减少了代码重复并最大程度地减少了代码异味。最后，代理在更简单的代码库上表现得更好，这表明将复杂的任务分解成更小的子任务可以提高效率。本研究提供了对实际 GitHub 问题上代理生成的补丁的首次全面评估，为推进 AI 驱动的软件开发提供了见解。

##### **Bridging the Language Gaps in Large Language Models with Inference-Time Cross-Lingual Intervention**
2410.12462v1 by Weixuan Wang, Minghao Wu, Barry Haddow, Alexandra Birch

Large Language Models (LLMs) have shown remarkable capabilities in natural
language processing but exhibit significant performance gaps among different
languages. Most existing approaches to address these disparities rely on
pretraining or fine-tuning, which are resource-intensive. To overcome these
limitations without incurring significant costs, we propose Inference-Time
Cross-Lingual Intervention (INCLINE), a novel framework that enhances LLM
performance on low-performing (source) languages by aligning their internal
representations with those of high-performing (target) languages during
inference. INCLINE initially learns alignment matrices using parallel sentences
from source and target languages through a Least-Squares optimization, and then
applies these matrices during inference to transform the low-performing
language representations toward the high-performing language space. Extensive
experiments on nine benchmarks with five LLMs demonstrate that INCLINE
significantly improves performance across diverse tasks and languages, compared
to recent strong baselines. Our analysis demonstrates that INCLINE is highly
cost-effective and applicable to a wide range of applications. In addition, we
release the code to foster research along this line:
https://github.com/weixuan-wang123/INCLINE.

摘要：大型語言模型 (LLM) 在自然語言處理方面表現出非凡的能力，但在不同語言之間的效能差距顯著。現有方法解決這些差異大多依賴於預訓練或微調，而這些方法需要大量資源。為了克服這些限制而又不產生顯著成本，我們提出了推理時間跨語言介入 (INCLINE)，這是一個創新的架構，透過在推理過程中將 LLM 的內部表徵與效能較高的（目標）語言對齊，來增強 LLM 在效能較低的（來源）語言上的效能。INCLINE 最初使用來自來源語言和目標語言的平行句子，透過最小平方最佳化來學習對齊矩陣，然後在推理過程中應用這些矩陣，將效能較低的語言表徵轉換為效能較高的語言空間。在使用五個 LLM 的九個基準上進行的廣泛實驗證明，與最近的強大基準線相比，INCLINE 大幅提升了各種任務和語言的效能。我們的分析證明 INCLINE 非常具有成本效益，且適用於各種應用。此外，我們釋出程式碼，以促進這方面的研究：
https://github.com/weixuan-wang123/INCLINE。

##### **The Best of Both Worlds: Bridging Quality and Diversity in Data Selection with Bipartite Graph**
2410.12458v1 by Minghao Wu, Thuy-Trang Vu, Lizhen Qu, Gholamreza Haffari

The performance of large language models (LLMs) in natural language
processing (NLP) tasks is significantly influenced by the quality and diversity
of data used for supervised fine-tuning (SFT). Current data selection methods
often focus solely on quality or diversity, leading to underperforming models
due to suboptimal training data. In this paper, we introduce GraphFilter, a
novel method that represents the dataset as a bipartite graph, linking
sentences to their constituent n-grams. This representation effectively
captures the relationships between sentences and linguistic patterns,
facilitating the selection of sentences that enhance n-gram diversity. To
balance quality and diversity during selection, we propose a priority function
that combines the quality metric with the diversity metric in a multiplicative
manner. GraphFilter iteratively selects high-priority sentences, updates the
bipartite graph by removing covered n-grams, and re-calculates priorities to
reflect the evolving data landscape. We conduct extensive experiments using
three model backbones across six widely used benchmarks. The results
demonstrate that GraphFilter outperforms all nine baseline approaches,
achieving superior model performance and computational efficiency. Our analyses
validate the effectiveness of our design choices, examine the subsets selected
by GraphFilter and other methods, highlight the importance of instruction
diversity, and explore the role of quality and diversity in relation to subset
sizes. GraphFilter establishes a new foundation for effective data selection
strategies, encouraging further research in data selection for LLMs.

摘要：大型語言模型 (LLM) 在自然語言處理 (NLP) 任務中的表現，受到用於監督微調 (SFT) 的資料品質和多樣性顯著影響。目前的資料選取方法通常只關注品質或多樣性，導致訓練資料次佳，進而造成模型表現不佳。在本文中，我們介紹 GraphFilter，一種新穎的方法，它將資料集表示為二部圖，將句子連結到其組成 n-gram。這種表示方式有效捕捉句子和語言模式之間的關係，有助於選擇能提升 n-gram 多樣性的句子。為了在選取過程中平衡品質和多樣性，我們提出優先函數，以乘法方式結合品質指標和多樣性指標。GraphFilter 迭代選取高優先級句子，透過移除已涵蓋 n-gram 來更新二部圖，並重新計算優先級以反映不斷變化的資料樣貌。我們使用三個模型主幹在六個廣泛使用的基準上進行廣泛的實驗。結果顯示，GraphFilter 優於所有九種基線方法，達到卓越的模型效能和運算效率。我們的分析驗證了我們設計選擇的有效性，檢驗 GraphFilter 和其他方法選取的子集，強調指令多樣性的重要性，並探討品質和多樣性與子集大小的關係。GraphFilter 為有效的資料選取策略奠定新的基礎，鼓勵進一步研究 LLM 的資料選取。

##### **Sharpness-Aware Black-Box Optimization**
2410.12457v1 by Feiyang Ye, Yueming Lyu, Xuehao Wang, Masashi Sugiyama, Yu Zhang, Ivor Tsang

Black-box optimization algorithms have been widely used in various machine
learning problems, including reinforcement learning and prompt fine-tuning.
However, directly optimizing the training loss value, as commonly done in
existing black-box optimization methods, could lead to suboptimal model quality
and generalization performance. To address those problems in black-box
optimization, we propose a novel Sharpness-Aware Black-box Optimization (SABO)
algorithm, which applies a sharpness-aware minimization strategy to improve the
model generalization. Specifically, the proposed SABO method first
reparameterizes the objective function by its expectation over a Gaussian
distribution. Then it iteratively updates the parameterized distribution by
approximated stochastic gradients of the maximum objective value within a small
neighborhood around the current solution in the Gaussian distribution space.
Theoretically, we prove the convergence rate and generalization bound of the
proposed SABO algorithm. Empirically, extensive experiments on the black-box
prompt fine-tuning tasks demonstrate the effectiveness of the proposed SABO
method in improving model generalization performance.

摘要：黑盒優化演算法已被廣泛用於各種機器學習問題中，包括強化學習和提示微調。
然而，直接優化訓練損失值，就像現有黑盒優化方法中常見的那樣，可能會導致次優模型品質和泛化效能。為了解決黑盒優化中的那些問題，我們提出了一種新穎的敏銳度感知黑盒優化 (SABO) 演算法，它應用一種敏銳度感知最小化策略來改善模型泛化。具體來說，所提出的 SABO 方法首先透過其在高斯分佈上的期望值對目標函數進行重新參數化。然後，它透過高斯分佈空間中目前解附近一個小鄰域內最大目標值的近似隨機梯度，反覆更新參數化分佈。理論上，我們證明了所提出的 SABO 演算法的收斂速度和泛化界限。根據經驗，在黑盒提示微調任務上進行的廣泛實驗證明了所提出的 SABO 方法在改善模型泛化效能方面的有效性。

##### **Open Ko-LLM Leaderboard2: Bridging Foundational and Practical Evaluation for Korean LLMs**
2410.12445v1 by Hyeonwoo Kim, Dahyun Kim, Jihoo Kim, Sukyung Lee, Yungi Kim, Chanjun Park

The Open Ko-LLM Leaderboard has been instrumental in benchmarking Korean
Large Language Models (LLMs), yet it has certain limitations. Notably, the
disconnect between quantitative improvements on the overly academic leaderboard
benchmarks and the qualitative impact of the models should be addressed.
Furthermore, the benchmark suite is largely composed of translated versions of
their English counterparts, which may not fully capture the intricacies of the
Korean language. To address these issues, we propose Open Ko-LLM Leaderboard2,
an improved version of the earlier Open Ko-LLM Leaderboard. The original
benchmarks are entirely replaced with new tasks that are more closely aligned
with real-world capabilities. Additionally, four new native Korean benchmarks
are introduced to better reflect the distinct characteristics of the Korean
language. Through these refinements, Open Ko-LLM Leaderboard2 seeks to provide
a more meaningful evaluation for advancing Korean LLMs.

摘要：開放式 Ko-LLM 排行榜對於基準測試韓文大型語言模型 (LLM) 發揮了重要作用，但仍有某些限制。特別是，過於學術的排行榜基準測試在量化改進與模型的質化影響之間的脫節應該得到解決。此外，基準測試套件主要由其英文對應版本的翻譯組成，可能無法完全捕捉韓語的複雜性。為了解決這些問題，我們提出了開放式 Ko-LLM 排行榜 2，這是早期開放式 Ko-LLM 排行榜的改良版本。原始基準測試完全替換為與實際能力更緊密結合的新任務。此外，還引入了四個新的原生韓語基準測試，以更好地反映韓語的獨特特徵。透過這些改進，開放式 Ko-LLM 排行榜 2 旨在為提升韓語 LLM 提供更有意義的評估。

##### **Expanding Chatbot Knowledge in Customer Service: Context-Aware Similar Question Generation Using Large Language Models**
2410.12444v1 by Mengze Hong, Yuanfeng Song, Di Jiang, Lu Wang, Zichang Guo, Chen Jason Zhang

Reliable responses of service chatbots are often achieved by employing
retrieval-based methods that restrict answers to a knowledge base comprising
predefined question-answer pairs (QA pairs). To accommodate potential
variations in how a customer's query may be expressed, it emerges as the
favored solution to augment these QA pairs with similar questions that are
possibly diverse while remaining semantic consistency. This augmentation task
is known as Similar Question Generation (SQG). Traditional methods that heavily
rely on human efforts or rule-based techniques suffer from limited diversity or
significant semantic deviation from the source question, only capable of
producing a finite number of useful questions.
  To address these limitations, we propose an SQG approach based on Large
Language Models (LLMs), capable of producing a substantial number of diverse
questions while maintaining semantic consistency to the source QA pair. This is
achieved by leveraging LLMs' natural language understanding capability through
fine-tuning with specially designed prompts. The experiments conducted on a
real customer-service dataset demonstrate that our method surpasses baseline
methods by a significant margin in terms of semantic diversity. Human
evaluation further confirms that integrating the answer that reflects the
customer's intention is crucial for increasing the number of generated
questions that meet business requirements.

摘要：服務聊天機器人的可靠回應通常透過採用檢索式方法來達成，此方法將答案限制在包含預先定義的問題解答對（問答對）的知識庫中。為了適應客戶查詢可能表達的方式的潛在變異，擴充這些問答對以納入在語意一致性的前提下可能不同的類似問題，逐漸成為受到青睞的解決方案。此擴充任務稱為類似問題產生（SQG）。傳統方法過度依賴人力或基於規則的技術，會造成多樣性受限或與原始問題產生顯著的語意偏差，僅能產生有限數量的有用問題。
為了解決這些限制，我們提出一個基於大型語言模型（LLM）的 SQG 方法，此方法能夠產生大量多樣化的問題，同時維持與原始問答對的語意一致性。這透過利用 LLM 的自然語言理解能力，並透過特別設計的提示進行微調來達成。在實際的客戶服務資料集上進行的實驗顯示，我們的模型在語意多樣性方面大幅超越基線模型。人工評估進一步證實，整合反映客戶意圖的答案對於增加符合業務需求的產生問題數量至關重要。

##### **Reconstruction of Differentially Private Text Sanitization via Large Language Models**
2410.12443v1 by Shuchao Pang, Zhigang Lu, Haichen Wang, Peng Fu, Yongbin Zhou, Minhui Xue, Bo Li

Differential privacy (DP) is the de facto privacy standard against privacy
leakage attacks, including many recently discovered ones against large language
models (LLMs). However, we discovered that LLMs could reconstruct the
altered/removed privacy from given DP-sanitized prompts. We propose two attacks
(black-box and white-box) based on the accessibility to LLMs and show that LLMs
could connect the pair of DP-sanitized text and the corresponding private
training data of LLMs by giving sample text pairs as instructions (in the
black-box attacks) or fine-tuning data (in the white-box attacks). To
illustrate our findings, we conduct comprehensive experiments on modern LLMs
(e.g., LLaMA-2, LLaMA-3, ChatGPT-3.5, ChatGPT-4, ChatGPT-4o, Claude-3,
Claude-3.5, OPT, GPT-Neo, GPT-J, Gemma-2, and Pythia) using commonly used
datasets (such as WikiMIA, Pile-CC, and Pile-Wiki) against both word-level and
sentence-level DP. The experimental results show promising recovery rates,
e.g., the black-box attacks against the word-level DP over WikiMIA dataset gave
72.18% on LLaMA-2 (70B), 82.39% on LLaMA-3 (70B), 75.35% on Gemma-2, 91.2% on
ChatGPT-4o, and 94.01% on Claude-3.5 (Sonnet). More urgently, this study
indicates that these well-known LLMs have emerged as a new security risk for
existing DP text sanitization approaches in the current environment.

摘要：差分隱私 (DP) 是針對隱私外洩攻擊的事實隱私標準，包括最近針對大型語言模型 (LLM) 發現的許多攻擊。然而，我們發現 LLM 可以從給定的 DP 清理提示中重建已變更/移除的隱私。我們提出了兩種攻擊（黑盒和白盒），基於對 LLM 的可訪問性，並展示 LLM 可以通過提供範例文字對作為指令（在黑盒攻擊中）或微調資料（在白盒攻擊中）來連接 DP 清理文字和對應的 LLM 私人訓練資料。為了說明我們的發現，我們對現代 LLM（例如 LLaMA-2、LLaMA-3、ChatGPT-3.5、ChatGPT-4、ChatGPT-4o、Claude-3、Claude-3.5、OPT、GPT-Neo、GPT-J、Gemma-2 和 Pythia）進行了全面的實驗，使用常用的資料集（例如 WikiMIA、Pile-CC 和 Pile-Wiki）針對字元級和句子級 DP。實驗結果顯示出有希望的恢復率，例如，針對 WikiMIA 資料集的字元級 DP 的黑盒攻擊在 LLaMA-2 (70B) 上獲得 72.18%，在 LLaMA-3 (70B) 上獲得 82.39%，在 Gemma-2 上獲得 75.35%，在 ChatGPT-4o 上獲得 91.2%，在 Claude-3.5 (Sonnet) 上獲得 94.01%。更緊急的是，這項研究表明，這些眾所周知的 LLM 已成為當前環境中現有 DP 文字清理方法的新安全風險。

##### **Conformity in Large Language Models**
2410.12428v1 by Xiaochen Zhu, Caiqi Zhang, Tom Stafford, Nigel Collier, Andreas Vlachos

The conformity effect describes the tendency of individuals to align their
responses with the majority. Studying this bias in large language models (LLMs)
is crucial, as LLMs are increasingly used in various information-seeking and
decision-making tasks as conversation partners to improve productivity. Thus,
conformity to incorrect responses can compromise their effectiveness. In this
paper, we adapt psychological experiments to examine the extent of conformity
in state-of-the-art LLMs. Our findings reveal that all models tested exhibit
varying levels of conformity toward the majority, regardless of their initial
choice or correctness, across different knowledge domains. Notably, we are the
first to show that LLMs are more likely to conform when they are more uncertain
in their own prediction. We further explore factors that influence conformity,
such as training paradigms and input characteristics, finding that
instruction-tuned models are less susceptible to conformity, while increasing
the naturalness of majority tones amplifies conformity. Finally, we propose two
interventions--Devil's Advocate and Question Distillation--to mitigate
conformity, providing insights into building more robust language models.

摘要：從眾效應描述了個人將自己的反應與多數人保持一致的傾向。在大型語言模型（LLM）中研究這種偏見至關重要，因為 LLM 正逐漸用於各種資訊搜尋和決策制定任務中，作為對話夥伴以提高生產力。因此，對不正確反應的從眾效應會損害它們的有效性。在本文中，我們調整了心理實驗以檢查最先進的 LLM 中從眾效應的程度。我們的研究結果顯示，所有測試的模型都表現出不同程度的從眾效應，無論它們的初始選擇或正確性如何，以及在不同的知識領域中。值得注意的是，我們首次表明，當 LLM 對自己的預測不確定時，它們更有可能從眾。我們進一步探討了影響從眾效應的因素，例如訓練範例和輸入特徵，發現經過指令調整的模型不易受到從眾效應的影響，而增加多數語氣的自然性會放大從眾效應。最後，我們提出了兩種干預措施——魔鬼辯護人和問題提煉——以減輕從眾效應，並提供深入見解以建構更強大的語言模型。

##### **Theoretical Analysis of Hierarchical Language Recognition and Generation by Transformers without Positional Encoding**
2410.12413v1 by Daichi Hayakawa, Issei Sato

In this study, we provide constructive proof that Transformers can recognize
and generate hierarchical language efficiently with respect to model size, even
without the need for a specific positional encoding. Specifically, we show that
causal masking and a starting token enable Transformers to compute positional
information and depth within hierarchical structures. We demonstrate that
Transformers without positional encoding can generate hierarchical languages.
Furthermore, we suggest that explicit positional encoding might have a
detrimental effect on generalization with respect to sequence length.

摘要：在這項研究中，我們提供了建構性的證明，證明 Transformer 可以有效地識別和產生階層語言，即使不需要特定位置編碼。具體來說，我們展示了因果遮罩和起始標記使 Transformer 能夠計算階層結構中的位置資訊和深度。我們證明了沒有位置編碼的 Transformer 可以產生階層語言。此外，我們建議明確的位置編碼可能會對序列長度的一般化產生不利影響。

##### **Revealing the Barriers of Language Agents in Planning**
2410.12409v1 by Jian Xie, Kexun Zhang, Jiangjie Chen, Siyu Yuan, Kai Zhang, Yikai Zhang, Lei Li, Yanghua Xiao

Autonomous planning has been an ongoing pursuit since the inception of
artificial intelligence. Based on curated problem solvers, early planning
agents could deliver precise solutions for specific tasks but lacked
generalization. The emergence of large language models (LLMs) and their
powerful reasoning capabilities has reignited interest in autonomous planning
by automatically generating reasonable solutions for given tasks. However,
prior research and our experiments show that current language agents still lack
human-level planning abilities. Even the state-of-the-art reasoning model,
OpenAI o1, achieves only 15.6% on one of the complex real-world planning
benchmarks. This highlights a critical question: What hinders language agents
from achieving human-level planning? Although existing studies have highlighted
weak performance in agent planning, the deeper underlying issues and the
mechanisms and limitations of the strategies proposed to address them remain
insufficiently understood. In this work, we apply the feature attribution study
and identify two key factors that hinder agent planning: the limited role of
constraints and the diminishing influence of questions. We also find that
although current strategies help mitigate these challenges, they do not fully
resolve them, indicating that agents still have a long way to go before
reaching human-level intelligence.

摘要：自主規劃自人工智慧創立以來一直是持續追求的目標。基於精選的問題解決者，早期的規劃代理可以提供特定任務的精確解決方案，但缺乏概括性。大型語言模型 (LLM) 和其強大的推理能力的出現，重新點燃了對自主規劃的興趣，透過自動為給定的任務產生合理的解決方案。然而，先前的研究和我們的實驗顯示，當前的語言代理仍然缺乏人類層級的規劃能力。即使是目前最先進的推理模型 OpenAI o1，在一個複雜的真實世界規劃基準中也只達到 15.6%。這突顯了一個關鍵問題：是什麼阻礙語言代理達到人類層級的規劃？儘管現有研究強調了代理規劃中的弱項，但更深層的根本問題以及為了解決這些問題而提出的策略機制和限制，仍然了解不足。在這項工作中，我們應用特徵歸因研究，並找出阻礙代理規劃的兩個關鍵因素：約束的有限作用和問題的影響遞減。我們也發現，儘管當前的策略有助於緩解這些挑戰，但並未完全解決它們，這表示代理在達到人類層級的智慧之前，仍有很長一段路要走。

##### **Beyond Coarse-Grained Matching in Video-Text Retrieval**
2410.12407v1 by Aozhu Chen, Hazel Doughty, Xirong Li, Cees G. M. Snoek

Video-text retrieval has seen significant advancements, yet the ability of
models to discern subtle differences in captions still requires verification.
In this paper, we introduce a new approach for fine-grained evaluation. Our
approach can be applied to existing datasets by automatically generating hard
negative test captions with subtle single-word variations across nouns, verbs,
adjectives, adverbs, and prepositions. We perform comprehensive experiments
using four state-of-the-art models across two standard benchmarks (MSR-VTT and
VATEX) and two specially curated datasets enriched with detailed descriptions
(VLN-UVO and VLN-OOPS), resulting in a number of novel insights: 1) our
analyses show that the current evaluation benchmarks fall short in detecting a
model's ability to perceive subtle single-word differences, 2) our fine-grained
evaluation highlights the difficulty models face in distinguishing such subtle
variations. To enhance fine-grained understanding, we propose a new baseline
that can be easily combined with current methods. Experiments on our
fine-grained evaluations demonstrate that this approach enhances a model's
ability to understand fine-grained differences.

摘要：影片文字擷取已取得顯著進展，然而，模型辨別字幕中細微差異的能力仍需要驗證。在本文中，我們介紹一種新的細粒度評估方法。我們的做法可應用於現有資料集，透過自動產生具有名詞、動詞、形容詞、副詞和介系詞等單字細微變化的困難負面測試字幕。我們使用四種最先進的模型對兩個標準基準（MSR-VTT 和 VATEX）和兩個特別策展且豐富詳細說明的資料集（VLN-UVO 和 VLN-OOPS）進行全面實驗，產生許多新見解：1）我們的分析顯示，目前的評估基準無法偵測模型感知單字細微差異的能力，2）我們的細粒度評估強調模型在區分此類細微變化的困難。為了增強細粒度理解，我們提出一個新的基準，可以輕鬆地與目前的方法結合。針對我們細粒度評估的實驗證明，這種方法增強了模型理解細粒度差異的能力。

##### **ProSA: Assessing and Understanding the Prompt Sensitivity of LLMs**
2410.12405v1 by Jingming Zhuo, Songyang Zhang, Xinyu Fang, Haodong Duan, Dahua Lin, Kai Chen

Large language models (LLMs) have demonstrated impressive capabilities across
various tasks, but their performance is highly sensitive to the prompts
utilized. This variability poses challenges for accurate assessment and user
satisfaction. Current research frequently overlooks instance-level prompt
variations and their implications on subjective evaluations. To address these
shortcomings, we introduce ProSA, a framework designed to evaluate and
comprehend prompt sensitivity in LLMs. ProSA incorporates a novel sensitivity
metric, PromptSensiScore, and leverages decoding confidence to elucidate
underlying mechanisms. Our extensive study, spanning multiple tasks, uncovers
that prompt sensitivity fluctuates across datasets and models, with larger
models exhibiting enhanced robustness. We observe that few-shot examples can
alleviate this sensitivity issue, and subjective evaluations are also
susceptible to prompt sensitivities, particularly in complex,
reasoning-oriented tasks. Furthermore, our findings indicate that higher model
confidence correlates with increased prompt robustness. We believe this work
will serve as a helpful tool in studying prompt sensitivity of LLMs. The
project is released at: https://github.com/open-compass/ProSA .

摘要：大型語言模型 (LLM) 已在各種任務中展現出令人印象深刻的能力，但其效能對所使用的提示非常敏感。這種變異性對準確評估和使用者滿意度構成挑戰。目前的研究所常忽略個別提示變異及其對主觀評估的影響。為了解決這些缺點，我們引入了 ProSA，一個旨在評估和理解 LLM 中提示敏感度的架構。ProSA 結合了一種新穎的敏感度量度 PromptSensiScore，並利用解碼信心來闡明底層機制。我們廣泛的研究涵蓋多項任務，發現提示敏感度在資料集和模型之間有所波動，而較大的模型表現出增強的穩健性。我們觀察到少數範例可以緩解這種敏感度問題，而主觀評估也容易受到提示敏感度的影響，特別是在複雜的、以推理為導向的任務中。此外，我們的研究結果表明，較高的模型信心與增加的提示穩健性相關。我們相信這項工作將成為研究 LLM 提示敏感度的有用工具。該專案已發布於：https://github.com/open-compass/ProSA。

##### **Tracking Universal Features Through Fine-Tuning and Model Merging**
2410.12391v1 by Niels Horn, Desmond Elliott

We study how features emerge, disappear, and persist across models fine-tuned
on different domains of text. More specifically, we start from a base one-layer
Transformer language model that is trained on a combination of the BabyLM
corpus, and a collection of Python code from The Stack. This base model is
adapted to two new domains of text: TinyStories, and the Lua programming
language, respectively; and then these two models are merged using these two
models using spherical linear interpolation. Our exploration aims to provide
deeper insights into the stability and transformation of features across
typical transfer-learning scenarios using small-scale models and sparse
auto-encoders.

摘要：我們研究特徵如何出現在不同文本領域上進行微調的模型中、消失和持續存在。更具體地說，我們從一個基本的一層 Transformer 語言模型開始，該模型在 BabyLM 語料庫的組合和 The Stack 中的 Python 程式碼集合上進行訓練。這個基本模型適應了兩個新的文本領域：TinyStories 和 Lua 程式語言；然後使用球面線性插值將這兩個模型合併。我們的探索旨在提供更深入的見解，了解在使用小規模模型和稀疏自動編碼器進行典型的遷移學習場景時，特徵的穩定性和轉換。

##### **A Fast Convoluted Story: Scaling Probabilistic Inference for Integer Arithmetic**
2410.12389v1 by Lennert De Smet, Pedro Zuidberg Dos Martires

As illustrated by the success of integer linear programming, linear integer
arithmetic is a powerful tool for modelling combinatorial problems.
Furthermore, the probabilistic extension of linear programming has been used to
formulate problems in neurosymbolic AI. However, two key problems persist that
prevent the adoption of neurosymbolic techniques beyond toy problems. First,
probabilistic inference is inherently hard, #P-hard to be precise. Second, the
discrete nature of integers renders the construction of meaningful gradients
challenging, which is problematic for learning. In order to mitigate these
issues, we formulate linear arithmetic over integer-valued random variables as
tensor manipulations that can be implemented in a straightforward fashion using
modern deep learning libraries. At the core of our formulation lies the
observation that the addition of two integer-valued random variables can be
performed by adapting the fast Fourier transform to probabilities in the
log-domain. By relying on tensor operations we obtain a differentiable data
structure, which unlocks, virtually for free, gradient-based learning. In our
experimental validation we show that tensorising probabilistic linear integer
arithmetic and leveraging the fast Fourier transform allows us to push the
state of the art by several orders of magnitude in terms of inference and
learning times.

摘要：正如整数线性规划的成功所展示的那样，线性整数算术是建模组合问题的强大工具。此外，线性规划的概率扩展已被用于制定神经符号 AI 中的问题。然而，仍然存在两个关键问题，阻止了神经符号技术在玩具问题之外的应用。首先，概率推理本质上是困难的，准确地说，#P-hard。其次，整数的离散性质使得有意义的梯度的构建具有挑战性，这对学习来说是有问题的。为了缓解这些问题，我们将基于整数随机变量的线性算术公式化为张量操作，可以使用现代深度学习库以直接的方式实现。我们公式化的核心在于观察到，两个整数随机变量的加法可以通过将快速傅里叶变换调整为对数域中的概率来执行。通过依赖张量运算，我们获得了可微的数据结构，它几乎免费地解锁了基于梯度的学习。在我们的实验验证中，我们表明张量化概率线性整数算术并利用快速傅里叶变换使我们能够在推理和学习时间方面将最先进的技术提升几个数量级。

##### **Prompt Compression for Large Language Models: A Survey**
2410.12388v2 by Zongqian Li, Yinhong Liu, Yixuan Su, Nigel Collier

Leveraging large language models (LLMs) for complex natural language tasks
typically requires long-form prompts to convey detailed requirements and
information, which results in increased memory usage and inference costs. To
mitigate these challenges, multiple efficient methods have been proposed, with
prompt compression gaining significant research interest. This survey provides
an overview of prompt compression techniques, categorized into hard prompt
methods and soft prompt methods. First, the technical approaches of these
methods are compared, followed by an exploration of various ways to understand
their mechanisms, including the perspectives of attention optimization,
Parameter-Efficient Fine-Tuning (PEFT), modality integration, and new synthetic
language. We also examine the downstream adaptations of various prompt
compression techniques. Finally, the limitations of current prompt compression
methods are analyzed, and several future directions are outlined, such as
optimizing the compression encoder, combining hard and soft prompts methods,
and leveraging insights from multimodality.

摘要：利用大型語言模型 (LLM) 執行複雜的自然語言任務通常需要長篇提示才能傳達詳細的要求和資訊，這會導致記憶體使用量和推論成本增加。為了減輕這些挑戰，已經提出了多種有效的方法，其中提示壓縮獲得了顯著的研究興趣。這項調查提供了提示壓縮技術的概述，分為硬提示方法和軟提示方法。首先，比較這些方法的技術方法，然後探討了解其機制的各種方式，包括注意最佳化、參數有效微調 (PEFT)、模態整合和新的合成語言。我們還檢查了各種提示壓縮技術的下游適應。最後，分析了當前提示壓縮方法的限制，並概述了幾個未來的方向，例如最佳化壓縮編碼器、結合硬提示和軟提示方法，以及利用多模態的見解。

##### **HumanEval-V: Evaluating Visual Understanding and Reasoning Abilities of Large Multimodal Models Through Coding Tasks**
2410.12381v1 by Fengji Zhang, Linquan Wu, Huiyu Bai, Guancheng Lin, Xiao Li, Xiao Yu, Yue Wang, Bei Chen, Jacky Keung

Coding tasks have been valuable for evaluating Large Language Models (LLMs),
as they demand the comprehension of high-level instructions, complex reasoning,
and the implementation of functional programs -- core capabilities for
advancing Artificial General Intelligence. Despite the progress in Large
Multimodal Models (LMMs), which extend LLMs with visual perception and
understanding capabilities, there remains a notable lack of coding benchmarks
that rigorously assess these models, particularly in tasks that emphasize
visual reasoning. To address this gap, we introduce HumanEval-V, a novel and
lightweight benchmark specifically designed to evaluate LMMs' visual
understanding and reasoning capabilities through code generation. HumanEval-V
includes 108 carefully crafted, entry-level Python coding tasks derived from
platforms like CodeForces and Stack Overflow. Each task is adapted by modifying
the context and algorithmic patterns of the original problems, with visual
elements redrawn to ensure distinction from the source, preventing potential
data leakage. LMMs are required to complete the code solution based on the
provided visual context and a predefined Python function signature outlining
the task requirements. Every task is equipped with meticulously handcrafted
test cases to ensure a thorough and reliable evaluation of model-generated
solutions. We evaluate 19 state-of-the-art LMMs using HumanEval-V, uncovering
significant challenges. Proprietary models like GPT-4o achieve only 13% pass@1
and 36.4% pass@10, while open-weight models with 70B parameters score below 4%
pass@1. Ablation studies further reveal the limitations of current LMMs in
vision reasoning and coding capabilities. These results underscore key areas
for future research to enhance LMMs' capabilities. We have open-sourced our
code and benchmark at https://github.com/HumanEval-V/HumanEval-V-Benchmark.

摘要：<paragraph>編碼任務對於評估大型語言模型 (LLM) 很有價值，
因為它們需要理解高層級指令、複雜推理，
以及實作函式程式 -- 人工通用智慧進步的核心能力。儘管大型多模態模型 (LMM) 有進展，它擴充了 LLM 的視覺感知和理解能力，但仍然顯著缺乏編碼基準，嚴格評估這些模型，特別是在強調視覺推理的任務中。為了填補這個缺口，我們引入了 HumanEval-V，一個新穎且輕量化的基準，專門設計用於透過程式碼產生來評估 LMM 的視覺理解和推理能力。HumanEval-V 包含 108 個精心製作的入門級 Python 編碼任務，衍生自 CodeForces 和 Stack Overflow 等平台。每個任務透過修改原始問題的背景和演算法模式來改編，並重新繪製視覺元素以確保與來源區分，防止潛在資料外洩。LMM 需要根據提供的視覺背景和預先定義的 Python 函式簽章來完成程式碼解決方案，概述任務需求。每個任務都配備了精心製作的測試案例，以確保對模型產生的解決方案進行徹底且可靠的評估。我們使用 HumanEval-V 評估了 19 個最先進的 LMM，發現了重大挑戰。GPT-4o 等專有模型僅達到 13% 的 pass@1 和 36.4% 的 pass@10，而具有 70B 參數的開放權重模型得分低於 4% 的 pass@1。消融研究進一步揭示了當前 LMM 在視覺推理和編碼能力方面的限制。這些結果強調了未來研究以增強 LMM 能力的主要領域。我們已在 https://github.com/HumanEval-V/HumanEval-V-Benchmark 開放我們的程式碼和基準。</paragraph>

##### **Evaluation of Attribution Bias in Retrieval-Augmented Large Language Models**
2410.12380v1 by Amin Abolghasemi, Leif Azzopardi, Seyyed Hadi Hashemi, Maarten de Rijke, Suzan Verberne

Attributing answers to source documents is an approach used to enhance the
verifiability of a model's output in retrieval augmented generation (RAG).
Prior work has mainly focused on improving and evaluating the attribution
quality of large language models (LLMs) in RAG, but this may come at the
expense of inducing biases in the attribution of answers. We define and examine
two aspects in the evaluation of LLMs in RAG pipelines, namely attribution
sensitivity and bias with respect to authorship information. We explicitly
inform an LLM about the authors of source documents, instruct it to attribute
its answers, and analyze (i) how sensitive the LLM's output is to the author of
source documents, and (ii) whether the LLM exhibits a bias towards
human-written or AI-generated source documents. We design an experimental setup
in which we use counterfactual evaluation to study three LLMs in terms of their
attribution sensitivity and bias in RAG pipelines. Our results show that adding
authorship information to source documents can significantly change the
attribution quality of LLMs by 3% to 18%. Moreover, we show that LLMs can have
an attribution bias towards explicit human authorship, which can serve as a
competing hypothesis for findings of prior work that shows that LLM-generated
content may be preferred over human-written contents. Our findings indicate
that metadata of source documents can influence LLMs' trust, and how they
attribute their answers. Furthermore, our research highlights attribution bias
and sensitivity as a novel aspect of brittleness in LLMs.

摘要：<paragraph>在檢索擴充生成（RAG）中，將答案歸因於來源文件是一種用於增強模型輸出可驗證性的方法。
先前的工作主要集中於改進和評估 RAG 中大型語言模型（LLM）的歸因品質，但這可能會導致在答案的歸因中引發偏差。我們在 RAG 管線中定義並檢視了 LLM 評估的兩個面向，即歸因敏感度和關於作者資訊的偏差。我們明確地告知 LLM 來源文件的作者，指示它歸因其答案，並分析 (i) LLM 的輸出對來源文件的作者有多敏感，以及 (ii) LLM 是否對人類撰寫或 AI 生成的來源文件表現出偏差。我們設計了一個實驗設定，在其中我們使用反事實評估來研究三個 LLM 在 RAG 管線中的歸因敏感度和偏差。我們的結果顯示，將作者資訊新增到來源文件可以顯著改變 LLM 的歸因品質，介於 3% 到 18%。此外，我們顯示 LLM 可能對明確的人類作者身份有歸因偏差，這可以用作先前工作發現的競爭假設，該發現顯示 LLM 生成的內容可能比人類撰寫的內容更受青睞。我們的發現表明，來源文件的元資料會影響 LLM 的信任，以及它們如何歸因其答案。此外，我們的研究強調歸因偏差和敏感度是 LLM 中脆性的新面向。</paragraph>

##### **HerO at AVeriTeC: The Herd of Open Large Language Models for Verifying Real-World Claims**
2410.12377v1 by Yejun Yoon, Jaeyoon Jung, Seunghyun Yoon, Kunwoo Park

To tackle the AVeriTeC shared task hosted by the FEVER-24, we introduce a
system that only employs publicly available large language models (LLMs) for
each step of automated fact-checking, dubbed the Herd of Open LLMs for
verifying real-world claims (HerO). HerO employs multiple LLMs for each step of
automated fact-checking. For evidence retrieval, a language model is used to
enhance a query by generating hypothetical fact-checking documents. We prompt
pretrained and fine-tuned LLMs for question generation and veracity prediction
by crafting prompts with retrieved in-context samples. HerO achieved 2nd place
on the leaderboard with the AVeriTeC score of 0.57, suggesting the potential of
open LLMs for verifying real-world claims. For future research, we make our
code publicly available at https://github.com/ssu-humane/HerO.

摘要：為了應對由 FEVER-24 主辦的 AVeriTeC 共享任務，我們引入了一個系統，它只在自動查證的每一步中採用公開可用的大型語言模型 (LLM)，並將其稱為用於驗證真實世界聲明的開放 LLM 群集 (HerO)。HerO 在自動查證的每一步中採用多個 LLM。對於證據檢索，語言模型用於通過生成假設性的查證文件來增強查詢。我們通過使用檢索到的上下文範本製作提示，提示預訓練和微調的 LLM 進行問題生成和真實性預測。HerO 在排行榜上獲得第 2 名，AVeriTeC 得分為 0.57，這表明開放式 LLM 在驗證真實世界聲明方面具有潛力。對於未來的研究，我們在 https://github.com/ssu-humane/HerO 上公開了我們的代碼。

##### **ShapefileGPT: A Multi-Agent Large Language Model Framework for Automated Shapefile Processing**
2410.12376v1 by Qingming Lin, Rui Hu, Huaxia Li, Sensen Wu, Yadong Li, Kai Fang, Hailin Feng, Zhenhong Du, Liuchang Xu

Vector data is one of the two core data structures in geographic information
science (GIS), essential for accurately storing and representing geospatial
information. Shapefile, the most widely used vector data format, has become the
industry standard supported by all major geographic information systems.
However, processing this data typically requires specialized GIS knowledge and
skills, creating a barrier for researchers from other fields and impeding
interdisciplinary research in spatial data analysis. Moreover, while large
language models (LLMs) have made significant advancements in natural language
processing and task automation, they still face challenges in handling the
complex spatial and topological relationships inherent in GIS vector data. To
address these challenges, we propose ShapefileGPT, an innovative framework
powered by LLMs, specifically designed to automate Shapefile tasks.
ShapefileGPT utilizes a multi-agent architecture, in which the planner agent is
responsible for task decomposition and supervision, while the worker agent
executes the tasks. We developed a specialized function library for handling
Shapefiles and provided comprehensive API documentation, enabling the worker
agent to operate Shapefiles efficiently through function calling. For
evaluation, we developed a benchmark dataset based on authoritative textbooks,
encompassing tasks in categories such as geometric operations and spatial
queries. ShapefileGPT achieved a task success rate of 95.24%, outperforming the
GPT series models. In comparison to traditional LLMs, ShapefileGPT effectively
handles complex vector data analysis tasks, overcoming the limitations of
traditional LLMs in spatial analysis. This breakthrough opens new pathways for
advancing automation and intelligence in the GIS field, with significant
potential in interdisciplinary data analysis and application contexts.

摘要：向量資料是地理資訊科學 (GIS) 中的兩個核心資料結構之一，對於準確儲存和表示地理空間資訊至關重要。Shapefile 是使用最廣泛的向量資料格式，已成為所有主要地理資訊系統支援的產業標準。然而，處理這些資料通常需要專業的 GIS 知識和技能，為來自其他領域的研究人員製造障礙，並阻礙空間資料分析的跨領域研究。此外，儘管大型語言模型 (LLM) 在自然語言處理和任務自動化方面取得重大進展，但在處理 GIS 向量資料中固有的複雜空間和拓撲關係時仍面臨挑戰。為了應對這些挑戰，我們提出了 ShapefileGPT，這是一個由 LLM 驅動的創新框架，專門設計用於自動化 Shapefile 任務。ShapefileGPT 使用多代理架構，其中規劃代理負責任務分解和監督，而工作代理則執行任務。我們開發了一個專門的功能函式庫來處理 Shapefile，並提供了全面的 API 文件，使工作代理能夠透過函式呼叫有效地操作 Shapefile。為了進行評估，我們根據權威教科書開發了一個基準資料集，涵蓋幾何運算和空間查詢等類別中的任務。ShapefileGPT 的任務成功率達到 95.24%，優於 GPT 系列模型。與傳統 LLM 相比，ShapefileGPT 能有效處理複雜的向量資料分析任務，克服了傳統 LLM 在空間分析中的限制。這項突破為推動 GIS 領域的自動化和智慧化開闢了新途徑，在跨領域資料分析和應用情境中具有顯著的潛力。

##### **PRefLexOR: Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking**
2410.12375v1 by Markus J. Buehler

PRefLexOR (Preference-based Recursive Language Modeling for Exploratory
Optimization of Reasoning) combines preference optimization with concepts from
Reinforcement Learning to enable models to self-teach through iterative
reasoning improvements. We propose a recursive learning approach that engages
the model in multi-step reasoning, revisiting, and refining intermediate steps
before producing a final output in training and inference phases. Through
multiple training stages, the model first learns to align its reasoning with
accurate decision paths by optimizing the log odds between preferred and
non-preferred responses. During this process, PRefLexOR builds a dynamic
knowledge graph by generating questions from random text chunks and
retrieval-augmentation to contextualize relevant details from the entire
training corpus. In the second stage, preference optimization enhances model
performance by using rejection sampling to fine-tune reasoning quality by
continually producing in-situ training data while masking the reasoning steps.
Recursive optimization within a thinking token framework introduces iterative
feedback loops, where the model refines reasoning, achieving deeper coherence,
consistency, and adaptability. Implemented in small language models with only 3
billion parameters, we should that even tiny models can iteratively teach
themselves to reason with greater depth and reflectivity. Our implementation is
straightforward and can be incorporated into any existing pretrained LLM. We
focus our examples on applications in biological materials science and
demonstrate the method in a variety of case studies that range from in-domain
to cross-domain applications. Using reasoning strategies that include thinking
and reflection modalities we build a multi-agent recursive self-improving
inference approach to successively improve responses via repeated sampling in
inference time.

摘要：PRefLexOR（用於探索性推理優化的基於偏好的遞迴語言建模）將偏好優化與強化學習中的概念相結合，使模型能夠通過反覆推理改進來自我教學。我們提出了一種遞迴學習方法，讓模型參與多步驟推理、重新審視和改進中間步驟，然後在訓練和推理階段產生最終輸出。通過多個訓練階段，模型首先學習通過優化首選和非首選響應之間的對數幾率，使其推理與準確的決策路徑保持一致。在此過程中，PRefLexOR 通過從隨機文本塊生成問題和檢索增強來構建一個動態知識圖，從整個訓練語料庫中提取相關細節以進行語境化。在第二階段，偏好優化通過使用拒絕採樣來微調推理質量，從而增強模型性能，同時連續產生原位訓練數據，同時掩蓋推理步驟。在思考令牌框架內進行遞迴優化會引入迭代反饋迴路，其中模型會改進推理，從而實現更深入的連貫性、一致性和適應性。在只有 30 億個參數的小語言模型中實現，我們應該讓即使是很小的模型也能通過迭代的方式教會自己以更大的深度和反思能力進行推理。我們的實現非常直接，可以整合到任何現有的預訓練 LLM 中。我們將我們的示例重點放在生物材料科學應用上，並在從域內到跨域應用等各種案例研究中演示了該方法。使用包括思考和反思模式在內的推理策略，我們構建了一個多代理遞迴自我改進推理方法，以通過在推理時間重複採樣來連續改進響應。

##### **Proactive Agent: Shifting LLM Agents from Reactive Responses to Active Assistance**
2410.12361v1 by Yaxi Lu, Shenzhi Yang, Cheng Qian, Guirong Chen, Qinyu Luo, Yesai Wu, Huadong Wang, Xin Cong, Zhong Zhang, Yankai Lin, Weiwen Liu, Yasheng Wang, Zhiyuan Liu, Fangming Liu, Maosong Sun

Agents powered by large language models have shown remarkable abilities in
solving complex tasks. However, most agent systems remain reactive, limiting
their effectiveness in scenarios requiring foresight and autonomous
decision-making. In this paper, we tackle the challenge of developing proactive
agents capable of anticipating and initiating tasks without explicit human
instructions. We propose a novel data-driven approach for this problem.
Firstly, we collect real-world human activities to generate proactive task
predictions. These predictions are then labeled by human annotators as either
accepted or rejected. The labeled data is used to train a reward model that
simulates human judgment and serves as an automatic evaluator of the
proactiveness of LLM agents. Building on this, we develop a comprehensive data
generation pipeline to create a diverse dataset, ProactiveBench, containing
6,790 events. Finally, we demonstrate that fine-tuning models with the proposed
ProactiveBench can significantly elicit the proactiveness of LLM agents.
Experimental results show that our fine-tuned model achieves an F1-Score of
66.47% in proactively offering assistance, outperforming all open-source and
close-source models. These results highlight the potential of our method in
creating more proactive and effective agent systems, paving the way for future
advancements in human-agent collaboration.

摘要：<paragraph>由大型語言模型驅動的代理已在解決複雜任務方面展現出非凡的能力。然而，大多數代理系統仍然被動，這限制了它們在需要預見性和自主決策制定場景中的效能。在本文中，我們將應對開發主動代理的挑戰，這些代理能夠預期並啟動任務，而無需明確的人類指令。我們針對此問題提出了一種新穎的數據驅動方法。首先，我們收集真實世界的人類活動以生成主動任務預測。然後，這些預測由人類註解者標記為接受或拒絕。標記的數據用於訓練一個獎勵模型，該模型模擬人類判斷，並作為 LLM 代理主動性的自動評估器。在此基礎上，我們開發了一個全面的數據生成管道，以創建一個多樣化的數據集 ProactiveBench，其中包含 6,790 個事件。最後，我們證明使用所提出的 ProactiveBench 微調模型可以顯著引發 LLM 代理的積極性。實驗結果表明，我們微調後的模型在主動提供協助方面達到了 66.47% 的 F1 分數，優於所有開源和閉源模型。這些結果突出了我們的方法在創造更主動和有效的代理系統方面的潛力，為未來人機協作的進步鋪平了道路。</paragraph>

##### **Towards Neural Scaling Laws for Time Series Foundation Models**
2410.12360v1 by Qingren Yao, Chao-Han Huck Yang, Renhe Jiang, Yuxuan Liang, Ming Jin, Shirui Pan

Scaling laws offer valuable insights into the design of time series
foundation models (TSFMs). However, previous research has largely focused on
the scaling laws of TSFMs for in-distribution (ID) data, leaving their
out-of-distribution (OOD) scaling behavior and the influence of model
architectures less explored. In this work, we examine two common TSFM
architectures, encoder-only and decoder-only Transformers, and investigate
their scaling behavior on both ID and OOD data. These models are trained and
evaluated across varying parameter counts, compute budgets, and dataset sizes.
Our experiments reveal that the log-likelihood loss of TSFMs exhibits similar
scaling behavior in both OOD and ID settings. We further compare the scaling
properties across different architectures, incorporating two state-of-the-art
TSFMs as case studies, showing that model architecture plays a significant role
in scaling. The encoder-only Transformers demonstrate better scalability than
the decoder-only Transformers, while the architectural enhancements in the two
advanced TSFMs primarily improve ID performance but reduce OOD scalability.
While scaling up TSFMs is expected to drive performance breakthroughs, the lack
of a comprehensive understanding of TSFM scaling laws has hindered the
development of a robust framework to guide model scaling. We fill this gap in
this work by synthesizing our findings and providing practical guidelines for
designing and scaling larger TSFMs with enhanced model capabilities.

摘要：<paragraph>規模定律為時序基礎模型 (TSFM) 的設計提供了有價值的見解。然而，先前的研究主要集中在 TSFM 的分佈內 (ID) 資料的規模定律，較少探討它們的分佈外 (OOD) 規模行為和模型架構的影響。在這項工作中，我們檢驗了兩種常見的 TSFM 架構，僅編碼器和僅解碼器 Transformer，並研究它們在 ID 和 OOD 資料上的規模行為。這些模型經過訓練並在不同的參數數量、運算預算和資料集大小中進行評估。我們的實驗表明，TSFM 的對數似然損失在 OOD 和 ID 設定中都表現出類似的規模行為。我們進一步比較了不同架構的規模屬性，將兩個最先進的 TSFM 作為案例研究，表明模型架構在規模中扮演著重要的角色。僅編碼器 Transformer 比僅解碼器 Transformer 具有更好的可擴充性，而兩個進階 TSFM 中的架構增強主要改善了 ID 效能，但降低了 OOD 可擴充性。儘管擴充 TSFM 預計將推動效能突破，但缺乏對 TSFM 規模定律的全面了解阻礙了制定一個健全的架構來指導模型規模。我們透過綜合我們的發現並提供實用的指南，來填補這項工作中的空白，以設計和擴充具有增強模型功能的更大 TSFM。</paragraph>

##### **GECTurk WEB: An Explainable Online Platform for Turkish Grammatical Error Detection and Correction**
2410.12350v1 by Ali Gebeşçe, Gözde Gül Şahin

Sophisticated grammatical error detection/correction tools are available for
a small set of languages such as English and Chinese. However, it is not
straightforward -- if not impossible -- to adapt them to morphologically rich
languages with complex writing rules like Turkish which has more than 80
million speakers. Even though several tools exist for Turkish, they primarily
focus on spelling errors rather than grammatical errors and lack features such
as web interfaces, error explanations and feedback mechanisms. To fill this
gap, we introduce GECTurk WEB, a light, open-source, and flexible web-based
system that can detect and correct the most common forms of Turkish writing
errors, such as the misuse of diacritics, compound and foreign words, pronouns,
light verbs along with spelling mistakes. Our system provides native speakers
and second language learners an easily accessible tool to detect/correct such
mistakes and also to learn from their mistakes by showing the explanation for
the violated rule(s). The proposed system achieves 88,3 system usability score,
and is shown to help learn/remember a grammatical rule (confirmed by 80% of the
participants). The GECTurk WEB is available both as an offline tool at
https://github.com/GGLAB-KU/gecturkweb or online at www.gecturk.net.

摘要：對於少數語言（例如英文和中文），有提供精密的文法錯誤偵測/修正工具。然而，要將這些工具套用在形態豐富且書寫規則複雜的語言（例如有超過 8000 萬名使用者土耳其語）並不容易，甚至是不可能的。儘管有幾種工具可供土耳其語使用，但它們主要著重於拼寫錯誤，而非文法錯誤，而且缺乏網路介面、錯誤說明和回饋機制等功能。為了填補這個缺口，我們推出了 GECTurk WEB，這是一個輕量、開放原始碼且彈性的網路系統，可以偵測並修正最常見的土耳其語寫作錯誤，例如變音符號、複合字、外來語、代名詞、輕動詞的誤用，以及拼寫錯誤。我們的系統為母語人士和第二語言學習者提供了一個容易取得的工具，可以偵測/修正這些錯誤，並透過顯示違規規則的說明，從他們的錯誤中學習。建議的系統達到了 88.3 的系統可用性評分，並顯示有助於學習/記住文法規則（80% 的參與者證實）。GECTurk WEB 可作為離線工具在 https://github.com/GGLAB-KU/gecturkweb 取得，或在 www.gecturk.net 線上取得。

##### **TAS: Distilling Arbitrary Teacher and Student via a Hybrid Assistant**
2410.12342v1 by Guopeng Li, Qiang Wang, Ke Yan, Shouhong Ding, Yuan Gao, Gui-Song Xia

Most knowledge distillation (KD) methodologies predominantly focus on
teacher-student pairs with similar architectures, such as both being
convolutional neural networks (CNNs). However, the potential and flexibility of
KD can be greatly improved by expanding it to novel Cross-Architecture KD
(CAKD), where the knowledge of homogeneous and heterogeneous teachers can be
transferred flexibly to a given student. The primary challenge in CAKD lies in
the substantial feature gaps between heterogeneous models, originating from the
distinction of their inherent inductive biases and module functions. To this
end, we introduce an assistant model as a bridge to facilitate smooth feature
knowledge transfer between heterogeneous teachers and students. More
importantly, within our proposed design principle, the assistant model combines
the advantages of cross-architecture inductive biases and module functions by
merging convolution and attention modules derived from both student and teacher
module functions. Furthermore, we observe that heterogeneous features exhibit
diverse spatial distributions in CAKD, hindering the effectiveness of
conventional pixel-wise mean squared error (MSE) loss. Therefore, we leverage a
spatial-agnostic InfoNCE loss to align features after spatial smoothing,
thereby improving the feature alignments in CAKD. Our proposed method is
evaluated across some homogeneous model pairs and arbitrary heterogeneous
combinations of CNNs, ViTs, and MLPs, achieving state-of-the-art performance
for distilled models with a maximum gain of 11.47% on CIFAR-100 and 3.67% on
ImageNet-1K. Our code and models will be released.

摘要：<paragraph>大多数知识蒸馏 (KD) 方法论主要关注具有相似架构的师生对，例如都是卷积神经网络 (CNN)。然而，KD 的潜力和灵活性可以通过将其扩展到新颖的跨架构 KD (CAKD) 来极大提高，其中同质和异质教师的知识可以灵活地转移到给定的学生。CAKD 中的主要挑战在于异构模型之间存在实质性的特征差距，这源于其固有的归纳偏差和模块功能的差异。为此，我们引入了一个辅助模型作为桥梁，以促进异构教师和学生之间平滑的特征知识转移。更重要的是，在我们提出的设计原则中，辅助模型通过合并源自学生和教师模块功能的卷积和注意力模块，结合了跨架构归纳偏差和模块功能的优势。此外，我们观察到异构特征在 CAKD 中表现出不同的空间分布，阻碍了传统的逐像素均方误差 (MSE) 损失的有效性。因此，我们利用空间无关的 InfoNCE 损失在空间平滑后对齐特征，从而改善 CAKD 中的特征对齐。我们提出的方法在一些同构模型对和 CNN、ViT 和 MLP 的任意异构组合中进行评估，在 CIFAR-100 上以 11.47% 的最大增益和 ImageNet-1K 上以 3.67% 的最大增益实现了蒸馏模型的最新性能。我们的代码和模型将被发布。</paragraph>

##### **A linguistic analysis of undesirable outcomes in the era of generative AI**
2410.12341v1 by Daniele Gambetta, Gizem Gezici, Fosca Giannotti, Dino Pedreschi, Alistair Knott, Luca Pappalardo

Recent research has focused on the medium and long-term impacts of generative
AI, posing scientific and societal challenges mainly due to the detection and
reliability of machine-generated information, which is projected to form the
major content on the Web soon. Prior studies show that LLMs exhibit a lower
performance in generation tasks (model collapse) as they undergo a fine-tuning
process across multiple generations on their own generated content
(self-consuming loop). In this paper, we present a comprehensive simulation
framework built upon the chat version of LLama2, focusing particularly on the
linguistic aspects of the generated content, which has not been fully examined
in existing studies. Our results show that the model produces less lexical rich
content across generations, reducing diversity. The lexical richness has been
measured using the linguistic measures of entropy and TTR as well as
calculating the POSTags frequency. The generated content has also been examined
with an $n$-gram analysis, which takes into account the word order, and
semantic networks, which consider the relation between different words. These
findings suggest that the model collapse occurs not only by decreasing the
content diversity but also by distorting the underlying linguistic patterns of
the generated text, which both highlight the critical importance of carefully
choosing and curating the initial input text, which can alleviate the model
collapse problem. Furthermore, we conduct a qualitative analysis of the
fine-tuned models of the pipeline to compare their performances on generic NLP
tasks to the original model. We find that autophagy transforms the initial
model into a more creative, doubtful and confused one, which might provide
inaccurate answers and include conspiracy theories in the model responses,
spreading false and biased information on the Web.

摘要：<paragraph>最近的研究专注于生成式 AI 的中期和长期影响，主要由于机器生成信息的检测和可靠性，预计这将很快形成网络上的主要内容，从而带来科学和社会挑战。先前的研究表明，LLM 在生成任务（模型崩溃）中表现出较低的性能，因为它们在自己的生成内容上跨多个世代进行微调过程（自耗循环）。在本文中，我们提出了一个基于 LLama2 聊天版本的综合模拟框架，特别关注生成内容的语言方面，这在现有研究中尚未得到充分检验。我们的结果表明，该模型在各个世代中产生的词汇丰富度较低，从而降低了多样性。词汇丰富度已使用熵和 TTR 的语言度量以及计算 POSTags 频率来衡量。还使用考虑单词顺序的 n-gram 分析和考虑不同单词之间关系的语义网络检查了生成的内容。这些发现表明，模型崩溃不仅通过降低内容多样性发生，还通过扭曲生成文本的底层语言模式发生，这两者都突出了仔细选择和策划初始输入文本的关键重要性，这可以缓解模型崩溃问题。此外，我们对流水线的微调模型进行定性分析，以将其在通用 NLP 任务上的性能与原始模型进行比较。我们发现自噬将初始模型转化为更具创造力、怀疑和困惑的模型，这可能会提供不准确的答案，并在模型响应中包含阴谋论，在网络上散布虚假和有偏差的信息。</paragraph>

##### **Understanding the Role of LLMs in Multimodal Evaluation Benchmarks**
2410.12329v1 by Botian Jiang, Lei Li, Xiaonan Li, Zhaowei Li, Xiachong Feng, Lingpeng Kong, Qi Liu, Xipeng Qiu

The rapid advancement of Multimodal Large Language Models (MLLMs) has been
accompanied by the development of various benchmarks to evaluate their
capabilities. However, the true nature of these evaluations and the extent to
which they assess multimodal reasoning versus merely leveraging the underlying
Large Language Model (LLM) backbone remain unclear. This paper presents a
comprehensive investigation into the role of LLM backbones in MLLM evaluation,
focusing on two critical aspects: the degree to which current benchmarks truly
assess multimodal reasoning and the influence of LLM prior knowledge on
performance. Specifically, we introduce a modified evaluation protocol to
disentangle the contributions of the LLM backbone from multimodal integration,
and an automatic knowledge identification technique for diagnosing whether LLMs
equip the necessary knowledge for corresponding multimodal questions. Our study
encompasses four diverse MLLM benchmarks and eight state-of-the-art MLLMs. Key
findings reveal that some benchmarks allow high performance even without visual
inputs and up to 50\% of error rates can be attributed to insufficient world
knowledge in the LLM backbone, indicating a heavy reliance on language
capabilities. To address knowledge deficiencies, we propose a knowledge
augmentation pipeline that achieves significant performance gains, with
improvements of up to 60\% on certain datasets, resulting in a approximately 4x
increase in performance. Our work provides crucial insights into the role of
the LLM backbone in MLLMs, and highlights the need for more nuanced
benchmarking approaches.

摘要：隨著多模態大型語言模型 (MLLM) 的快速進展，各種基準測試也隨之發展，用於評估其能力。然而，這些評估的真正性質以及它們評估多模態推理的程度，相對於僅利用基礎大型語言模型 (LLM) 主幹仍不清楚。本文對 LLM 主幹在 MLLM 評估中的作用進行了全面調查，重點關注兩個關鍵方面：當前基準測試真正評估多模態推理的程度，以及 LLM 先驗知識對效能的影響。具體來說，我們引入了一個修改後的評估協議，以區分 LLM 主幹對多模態整合的貢獻，以及一種自動知識識別技術，用於診斷 LLM 是否具備對應多模態問題的必要知識。我們的研究涵蓋了四個不同的 MLLM 基準測試和八個最先進的 MLLM。關鍵發現表明，即使沒有視覺輸入，一些基準測試也能允許高性能，並且高達 50% 的錯誤率可歸因於 LLM 主幹中世界知識不足，這表明對語言能力的嚴重依賴。為了解決知識缺陷，我們提出了一個知識擴充管道，可實現顯著的性能提升，在某些數據集上提升高達 60%，導致性能提升約 4 倍。我們的研究對 LLM 主幹在 MLLM 中的作用提供了至關重要的見解，並強調了對更細緻的基準測試方法的需求。

##### **Neuron-based Personality Trait Induction in Large Language Models**
2410.12327v1 by Jia Deng, Tianyi Tang, Yanbin Yin, Wenhao Yang, Wayne Xin Zhao, Ji-Rong Wen

Large language models (LLMs) have become increasingly proficient at
simulating various personality traits, an important capability for supporting
related applications (e.g., role-playing). To further improve this capacity, in
this paper, we present a neuron-based approach for personality trait induction
in LLMs, with three major technical contributions. First, we construct
PersonalityBench, a large-scale dataset for identifying and evaluating
personality traits in LLMs. This dataset is grounded in the Big Five
personality traits from psychology and is designed to assess the generative
capabilities of LLMs towards specific personality traits. Second, by leveraging
PersonalityBench, we propose an efficient method for identifying
personality-related neurons within LLMs by examining the opposite aspects of a
given trait. Third, we develop a simple yet effective induction method that
manipulates the values of these identified personality-related neurons. This
method enables fine-grained control over the traits exhibited by LLMs without
training and modifying model parameters. Extensive experiments validate the
efficacy of our neuron identification and trait induction methods. Notably, our
approach achieves comparable performance as fine-tuned models, offering a more
efficient and flexible solution for personality trait induction in LLMs. We
provide access to all the mentioned resources at
https://github.com/RUCAIBox/NPTI.

摘要：大型語言模型 (LLM) 在模擬各種人格特質方面變得越來越熟練，這對於支援相關應用程式（例如角色扮演）來說是一項重要的能力。為了進一步提升這種能力，我們在本文中提出了一種基於神經元的 LLM 人格特質誘導方法，並有三大技術貢獻。首先，我們構建了 PersonalityBench，這是一個用於識別和評估 LLM 中人格特質的大規模資料集。此資料集以心理學中的五大性格特質為基礎，旨在評估 LLM 對特定人格特質的生成能力。其次，透過利用 PersonalityBench，我們提出了一種有效的方法，透過檢視特定特質的相反面向來識別 LLM 中與人格相關的神經元。第三，我們開發了一種簡單但有效的方法，用於調整這些已識別與人格相關的神經元的值。這種方法可以在不訓練和修改模型參數的情況下，精細地控制 LLM 所表現出的特質。廣泛的實驗驗證了我們的神經元識別和特質誘導方法的效能。值得注意的是，我們的做法達到了與微調模型相當的效能，為 LLM 中的人格特質誘導提供了更有效率且更靈活的解決方案。我們在 https://github.com/RUCAIBox/NPTI 提供所有上述資源的存取權。

##### **Optimizing Low-Resource Language Model Training: Comprehensive Analysis of Multi-Epoch, Multi-Lingual, and Two-Stage Approaches**
2410.12325v1 by Kosuke Akimoto, Masafumi Oyamada

In this paper, we address the challenge of optimizing training setups for
Large Language Models (LLMs) of low-resource language with a limited amount of
corpus. Existing works adopt multi-epoch, multi-lingual, and two-stage training
to utilize the limited target language corpus efficiently. However, there is
still a lack of understanding about the optimal hyperparameter setups for
combining these three approaches to train LLMs. We exhaustively explore
training setups for low-resource language LLM, combining these three
approaches, and found the following insights for efficiently reducing the cost
of hyperparameter search: (1) As the amount of target language corpus
decreases, the optimal training approach shifts from monolingual single-stage
training to multi-lingual two-stage training at a compute budget dependent
threshold. (2) The optimal model scale remains stable regardless of the amount
of target language corpus, allowing the use of the compute-optimal scale of
monolingual training. (3) The optimal number of epochs can be extrapolated from
smaller-scale experiments to larger scale using our proposed model. Also, we
provide evidence that, in single-stage training, the target language validation
loss follows a power law with respect to the target language ratio, with an
exponent independent of the amount of data, model scale, and language pair.

摘要：<paragraph>在本文中，我們探討了使用有限語料庫，針對低資源語言的大型語言模型 (LLM) 最佳化訓練設定的挑戰。現有作品採用多個世代、多語言和兩階段訓練，以有效利用有限的目標語言語料庫。然而，對於結合這三種方法來訓練 LLM 的最佳超參數設定，目前仍缺乏了解。我們針對低資源語言 LLM 的訓練設定進行了詳盡的探討，結合了這三種方法，並發現了以下見解，可有效減少超參數搜尋的成本：(1) 隨著目標語言語料庫的數量減少，最佳訓練方法會從單語單階段訓練轉移到多語言兩階段訓練，具體取決於運算預算。 (2) 最佳模型規模會保持穩定，與目標語言語料庫的數量無關，這讓我們可以使用單語訓練的運算最佳規模。 (3) 最佳世代數可以使用我們提出的模型，從小規模實驗外推到更大規模。此外，我們提供了證據，在單階段訓練中，目標語言驗證損失會遵循目標語言比率的冪律，且指數與資料量、模型規模和語言配對無關。</paragraph>

##### **Reversal of Thought: Enhancing Large Language Models with Preference-Guided Reverse Reasoning Warm-up**
2410.12323v1 by Jiahao Yuan, Dehui Du, Hao Zhang, Zixiang Di, Usman Naseem

Large language models (LLMs) have shown remarkable performance in reasoning
tasks but face limitations in mathematical and complex logical reasoning.
Existing methods to improve LLMs' logical capabilities either involve traceable
or verifiable logical sequences that generate more reliable responses by
constructing logical structures yet increase computational costs, or introduces
rigid logic template rules, reducing flexibility. In this paper, we propose
Reversal of Thought (RoT), a novel framework aimed at enhancing the logical
reasoning abilities of LLMs. RoT utilizes a Preference-Guided Reverse Reasoning
warm-up strategy, which integrates logical symbols for pseudocode planning
through meta-cognitive mechanisms and pairwise preference self-evaluation to
generate task-specific prompts solely through demonstrations, aligning with
LLMs' cognitive preferences shaped by Reinforcement Learning with Human
Feedback (RLHF). Through reverse reasoning, we ultilize a Cognitive Preference
Manager to assess knowledge boundaries and further expand LLMs' reasoning
capabilities by aggregating solution logic for known tasks and stylistic
templates for unknown tasks. Experiments across various tasks demonstrate that
RoT surpasses existing baselines in both reasoning accuracy and efficiency.

摘要：大型語言模型 (LLM) 在推理任務中展現出卓越的表現，但在數學和複雜邏輯推理方面卻面臨限制。現有的改進 LLM 邏輯能力的方法，要不就是涉及可追溯或可驗證的邏輯序列，藉由建構邏輯結構來產生更可靠的回應，但會增加運算成本；要不就是引入僵化的邏輯範本規則，降低靈活性。在本文中，我們提出逆向思考 (RoT)，這是一個新穎的架構，旨在增強 LLM 的邏輯推理能力。RoT 利用偏好引導的反向推理熱身策略，透過元認知機制和成對偏好自我評估，將邏輯符號整合到偽代碼規劃中，以產生僅透過示範就能產生的特定任務提示，並與 LLM 的認知偏好（由人類回饋增強學習 (RLHF) 所形塑）保持一致。透過逆向推理，我們利用認知偏好管理員來評估知識界線，並透過彙總已知任務的解決方案邏輯和未知任務的文體範本，進一步擴展 LLM 的推理能力。在各種任務中的實驗證明，RoT 在推理準確度和效率方面都超越了現有的基準。

##### **UTF:Undertrained Tokens as Fingerprints A Novel Approach to LLM Identification**
2410.12318v1 by Jiacheng Cai, Jiahao Yu, Yangguang Shao, Yuhang Wu, Xinyu Xing

Fingerprinting large language models (LLMs) is essential for verifying model
ownership, ensuring authenticity, and preventing misuse. Traditional
fingerprinting methods often require significant computational overhead or
white-box verification access. In this paper, we introduce UTF, a novel and
efficient approach to fingerprinting LLMs by leveraging under-trained tokens.
Under-trained tokens are tokens that the model has not fully learned during its
training phase. By utilizing these tokens, we perform supervised fine-tuning to
embed specific input-output pairs into the model. This process allows the LLM
to produce predetermined outputs when presented with certain inputs,
effectively embedding a unique fingerprint. Our method has minimal overhead and
impact on model's performance, and does not require white-box access to target
model's ownership identification. Compared to existing fingerprinting methods,
UTF is also more effective and robust to fine-tuning and random guess.

摘要：大型語言模型 (LLM) 指紋辨識對於驗證模型所有權、確保真實性及防止濫用至關重要。傳統指紋辨識方法通常需要大量的運算負擔或白盒驗證存取權。在本文中，我們介紹 UTF，一種新穎且有效率的方法，透過利用未充分訓練的符號來辨識 LLM 指紋。未充分訓練的符號是模型在其訓練階段中尚未完全學會的符號。透過利用這些符號，我們執行監督微調，將特定輸入輸出對嵌入到模型中。此程序允許 LLM 在呈現特定輸入時產生預先決定的輸出，有效地嵌入唯一的指紋。我們的技術對模型效能的負擔和影響很小，且不需要白盒存取權就能辨識目標模型的所有權。與現有的指紋辨識方法相比，UTF 對微調和隨機猜測也更有效且更強健。

##### **FaceChain-FACT: Face Adapter with Decoupled Training for Identity-preserved Personalization**
2410.12312v1 by Cheng Yu, Haoyu Xie, Lei Shang, Yang Liu, Jun Dan, Baigui Sun, Liefeng Bo

In the field of human-centric personalized image generation, the
adapter-based method obtains the ability to customize and generate portraits by
text-to-image training on facial data. This allows for identity-preserved
personalization without additional fine-tuning in inference. Although there are
improvements in efficiency and fidelity, there is often a significant
performance decrease in test following ability, controllability, and diversity
of generated faces compared to the base model. In this paper, we analyze that
the performance degradation is attributed to the failure to decouple identity
features from other attributes during extraction, as well as the failure to
decouple the portrait generation training from the overall generation task. To
address these issues, we propose the Face Adapter with deCoupled Training
(FACT) framework, focusing on both model architecture and training strategy. To
decouple identity features from others, we leverage a transformer-based
face-export encoder and harness fine-grained identity features. To decouple the
portrait generation training, we propose Face Adapting Increment
Regularization~(FAIR), which effectively constrains the effect of face adapters
on the facial region, preserving the generative ability of the base model.
Additionally, we incorporate a face condition drop and shuffle mechanism,
combined with curriculum learning, to enhance facial controllability and
diversity. As a result, FACT solely learns identity preservation from training
data, thereby minimizing the impact on the original text-to-image capabilities
of the base model. Extensive experiments show that FACT has both
controllability and fidelity in both text-to-image generation and inpainting
solutions for portrait generation.

摘要：在以人为本的个性化图像生成领域，基于适配器的方法通过面部数据上的文本到图像训练获得了定制和生成人像的能力。这允许在推理中进行身份保留的个性化，而无需额外的微调。虽然效率和保真度有所提高，但与基础模型相比，生成的面的测试跟随能力、可控性和多样性通常会显着下降。在本文中，我们分析了性能下降归因于在提取过程中未能将身份特征与其他属性分离，以及未能将人像生成训练与整体生成任务分离。为了解决这些问题，我们提出了具有解耦训练 (FACT) 框架的面部适配器，重点关注模型架构和训练策略。为了将身份特征与其他特征分离，我们利用基于 transformer 的面部导出编码器并利用细粒度的身份特征。为了分离人像生成训练，我们提出了面部自适应增量正则化~(FAIR)，它有效地限制了面部适配器对人脸区域的影响，保留了基础模型的生成能力。此外，我们结合课程学习，加入了面部条件丢弃和洗牌机制，以增强面部可控性和多样性。因此，FACT 仅从训练数据中学习身份保留，从而最大程度地减少对基础模型的原始文本到图像功能的影响。大量的实验表明，FACT 在文本到图像生成和人像生成修复解决方案中都具有可控性和保真度。

##### **Open Domain Question Answering with Conflicting Contexts**
2410.12311v1 by Siyi Liu, Qiang Ning, Kishaloy Halder, Wei Xiao, Zheng Qi, Phu Mon Htut, Yi Zhang, Neha Anna John, Bonan Min, Yassine Benajiba, Dan Roth

Open domain question answering systems frequently rely on information
retrieved from large collections of text (such as the Web) to answer questions.
However, such collections of text often contain conflicting information, and
indiscriminately depending on this information may result in untruthful and
inaccurate answers. To understand the gravity of this problem, we collect a
human-annotated dataset, Question Answering with Conflicting Contexts (QACC),
and find that as much as 25% of unambiguous, open domain questions can lead to
conflicting contexts when retrieved using Google Search. We evaluate and
benchmark three powerful Large Language Models (LLMs) with our dataset QACC and
demonstrate their limitations in effectively addressing questions with
conflicting information. To explore how humans reason through conflicting
contexts, we request our annotators to provide explanations for their
selections of correct answers. We demonstrate that by finetuning LLMs to
explain their answers, we can introduce richer information into their training
that guide them through the process of reasoning with conflicting contexts.

摘要：開放領域問題解答系統經常依賴從大量文本集合（例如網路）中擷取的資訊來回答問題。然而，此類文本集合經常包含相互矛盾的資訊，而無差別地依賴這些資訊可能會導致不真實且不準確的答案。為了了解此問題的嚴重性，我們收集了一個人工標註的資料集，即帶有衝突脈絡的問題解答 (QACC)，並發現多達 25% 的明確開放領域問題在使用 Google 搜尋擷取時可能會導致衝突脈絡。我們使用我們的資料集 QACC 評估和比較了三個強大的大型語言模型 (LLM)，並展示了它們在有效處理具有衝突資訊的問題上的局限性。為了探討人類如何透過衝突脈絡進行推理，我們要求我們的標註者為他們選擇的正確答案提供解釋。我們證明，透過微調 LLM 以解釋其答案，我們可以將更豐富的資訊引入其訓練中，以引導它們完成處理衝突脈絡的過程。

##### **Semantics-Adaptive Activation Intervention for LLMs via Dynamic Steering Vectors**
2410.12299v1 by Weixuan Wang, Jingyuan Yang, Wei Peng

Large language models (LLMs) have achieved remarkable performance across many
tasks, yet aligning them with desired behaviors remains challenging. Activation
intervention has emerged as an effective and economical method to modify the
behavior of LLMs. Despite considerable interest in this area, current
intervention methods exclusively employ a fixed steering vector to modify model
activations, lacking adaptability to diverse input semantics. To address this
limitation, we propose Semantics-Adaptive Dynamic Intervention (SADI), a novel
method that constructs a dynamic steering vector to intervene model activations
at inference time. More specifically, SADI utilizes activation differences in
contrastive pairs to precisely identify critical elements of an LLM (i.e.,
attention heads, hidden states, and neurons) for targeted intervention. During
inference, SADI dynamically steers model behavior by scaling element-wise
activations based on the directions of input semantics. Experimental results
show that SADI outperforms established baselines by substantial margins,
improving task performance without training. SADI's cost-effectiveness and
generalizability across various LLM backbones and tasks highlight its potential
as a versatile alignment technique. In addition, we release the code to foster
research along this line:https://github.com/weixuan-wang123/SADI.

摘要：大型語言模型 (LLM) 已在許多任務中取得顯著的表現，但要讓它們與所需的行為保持一致仍然具有挑戰性。啟動介入已成為一種有效且經濟的方法，可以修改 LLM 的行為。儘管對這個領域有相當大的興趣，但目前的介入方法僅使用固定的導向向量來修改模型啟動，缺乏適應不同輸入語義的能力。為了解決這個限制，我們提出語義自適應動態介入 (SADI)，這是一種創新的方法，用於建立動態導向向量，以便在推理時介入模型啟動。更具體地說，SADI 利用對比對中的啟動差異，精確地識別 LLM 的關鍵元素（即注意力頭、隱藏狀態和神經元），以進行有針對性的介入。在推理期間，SADI 根據輸入語義的方向，通過調整元素級啟動，動態地引導模型行為。實驗結果表明，SADI 以大幅的幅度優於已建立的基準，在沒有訓練的情況下提高了任務性能。SADI 在各種 LLM 主幹和任務中的成本效益和通用性突出了它作為一種多功能對齊技術的潛力。此外，我們發布代碼以促進沿此線的研究：https://github.com/weixuan-wang123/SADI。

