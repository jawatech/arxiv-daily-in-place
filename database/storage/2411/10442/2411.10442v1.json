{"2411.10442": {"publish_time": "2024-11-15", "title": "Enhancing the Reasoning Ability of Multimodal Large Language Models via Mixed Preference Optimization", "paper_summary": "Existing open-source multimodal large language models (MLLMs) generally\nfollow a training process involving pre-training and supervised fine-tuning.\nHowever, these models suffer from distribution shifts, which limit their\nmultimodal reasoning, particularly in the Chain-of-Thought (CoT) performance.\nTo address this, we introduce a preference optimization (PO) process to enhance\nthe multimodal reasoning capabilities of MLLMs. Specifically, (1) on the data\nside, we design an automated preference data construction pipeline to create\nMMPR, a high-quality, large-scale multimodal reasoning preference dataset. and\n(2) on the model side, we explore integrating PO with MLLMs, developing a\nsimple yet effective method, termed Mixed Preference Optimization (MPO), which\nboosts multimodal CoT performance. Our approach demonstrates improved\nperformance across multiple benchmarks, particularly in multimodal reasoning\ntasks. Notably, our model, InternVL2-8B-MPO, achieves an accuracy of 67.0 on\nMathVista, outperforming InternVL2-8B by 8.7 points and achieving performance\ncomparable to the 10x larger InternVL2-76B. We hope this study could inspire\nfurther advancements in MLLMs. Code, data, and model shall be publicly\nreleased.", "paper_summary_zh": "\u73fe\u6709\u7684\u958b\u6e90\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MMLM) \u901a\u5e38\u9075\u5faa\u4e00\u500b\u5305\u542b\u9810\u8a13\u7df4\u548c\u76e3\u7763\u5fae\u8abf\u7684\u8a13\u7df4\u6d41\u7a0b\u3002\u7136\u800c\uff0c\u9019\u4e9b\u6a21\u578b\u6703\u53d7\u5230\u5206\u4f48\u8f49\u79fb\u7684\u5f71\u97ff\uff0c\u9019\u6703\u9650\u5236\u5b83\u5011\u7684\u591a\u6a21\u614b\u63a8\u7406\uff0c\u7279\u5225\u662f\u5728\u601d\u8003\u93c8 (CoT) \u6548\u80fd\u65b9\u9762\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u504f\u597d\u6700\u4f73\u5316 (PO) \u6d41\u7a0b\u4f86\u589e\u5f37 MMLM \u7684\u591a\u6a21\u614b\u63a8\u7406\u80fd\u529b\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c(1) \u5728\u8cc7\u6599\u65b9\u9762\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u81ea\u52d5\u5316\u504f\u597d\u8cc7\u6599\u5efa\u69cb\u7ba1\u7dda\u4f86\u5efa\u7acb MMPR\uff0c\u4e00\u500b\u9ad8\u54c1\u8cea\u3001\u5927\u898f\u6a21\u7684\u591a\u6a21\u614b\u63a8\u7406\u504f\u597d\u8cc7\u6599\u96c6\u3002\u4ee5\u53ca (2) \u5728\u6a21\u578b\u65b9\u9762\uff0c\u6211\u5011\u63a2\u7d22\u5c07 PO \u8207 MLLM \u6574\u5408\uff0c\u958b\u767c\u4e00\u7a2e\u7c21\u55ae\u4f46\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u7a31\u70ba\u6df7\u5408\u504f\u597d\u6700\u4f73\u5316 (MPO)\uff0c\u5b83\u53ef\u4ee5\u63d0\u5347\u591a\u6a21\u614b CoT \u6548\u80fd\u3002\u6211\u5011\u7684\u505a\u6cd5\u8b49\u660e\u4e86\u5728\u591a\u500b\u57fa\u6e96\u6e2c\u8a66\u4e2d\u90fd\u6709\u6539\u9032\u7684\u6548\u80fd\uff0c\u7279\u5225\u662f\u5728\u591a\u6a21\u614b\u63a8\u7406\u4efb\u52d9\u4e2d\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u6211\u5011\u7684\u6a21\u578b InternVL2-8B-MPO \u5728 MathVista \u4e0a\u9054\u5230\u4e86 67.0 \u7684\u6e96\u78ba\u5ea6\uff0c\u6bd4 InternVL2-8B \u9ad8\u51fa 8.7 \u500b\u767e\u5206\u9ede\uff0c\u4e26\u9054\u5230\u4e86\u8207\u5927 10 \u500d\u7684 InternVL2-76B \u76f8\u7576\u7684\u6548\u80fd\u3002\u6211\u5011\u5e0c\u671b\u9019\u9805\u7814\u7a76\u80fd\u6fc0\u52f5 MLLM \u7684\u9032\u4e00\u6b65\u767c\u5c55\u3002\u7a0b\u5f0f\u78bc\u3001\u8cc7\u6599\u548c\u6a21\u578b\u5c07\u516c\u958b\u767c\u5e03\u3002", "author": "Weiyun Wang et.al.", "authors": "Weiyun Wang, Zhe Chen, Wenhai Wang, Yue Cao, Yangzhou Liu, Zhangwei Gao, Jinguo Zhu, Xizhou Zhu, Lewei Lu, Yu Qiao, Jifeng Dai", "id": "2411.10442v1", "paper_url": "http://arxiv.org/abs/2411.10442v1", "repo": "null"}}