{"2502.13965": {"publish_time": "2025-02-19", "title": "Autellix: An Efficient Serving Engine for LLM Agents as General Programs", "paper_summary": "Large language model (LLM) applications are evolving beyond simple chatbots\ninto dynamic, general-purpose agentic programs, which scale LLM calls and\noutput tokens to help AI agents reason, explore, and solve complex tasks.\nHowever, existing LLM serving systems ignore dependencies between programs and\ncalls, missing significant opportunities for optimization. Our analysis reveals\nthat programs submitted to LLM serving engines experience long cumulative wait\ntimes, primarily due to head-of-line blocking at both the individual LLM\nrequest and the program. To address this, we introduce Autellix, an LLM serving\nsystem that treats programs as first-class citizens to minimize their\nend-to-end latencies. Autellix intercepts LLM calls submitted by programs,\nenriching schedulers with program-level context. We propose two scheduling\nalgorithms-for single-threaded and distributed programs-that preempt and\nprioritize LLM calls based on their programs' previously completed calls. Our\nevaluation demonstrates that across diverse LLMs and agentic workloads,\nAutellix improves throughput of programs by 4-15x at the same latency compared\nto state-of-the-art systems, such as vLLM.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u61c9\u7528\u6b63\u5f9e\u7c21\u55ae\u7684\u804a\u5929\u6a5f\u5668\u4eba\u6f14\u8b8a\u6210\u52d5\u614b\u3001\u901a\u7528\u7684\u4ee3\u7406\u7a0b\u5f0f\uff0c\u5b83\u64f4\u5c55\u4e86 LLM \u7684\u547c\u53eb\uff0c\u4e26\u8f38\u51fa\u4ee3\u78bc\uff0c\u4ee5\u5e6b\u52a9 AI \u4ee3\u7406\u63a8\u7406\u3001\u63a2\u7d22\u548c\u89e3\u6c7a\u8907\u96dc\u4efb\u52d9\u3002\n\u7136\u800c\uff0c\u73fe\u6709\u7684 LLM \u670d\u52d9\u7cfb\u7d71\u5ffd\u8996\u4e86\u7a0b\u5f0f\u548c\u547c\u53eb\u4e4b\u9593\u7684\u4f9d\u8cf4\u95dc\u4fc2\uff0c\u932f\u5931\u4e86\u6700\u4f73\u5316\u7684\u91cd\u8981\u6a5f\u6703\u3002\u6211\u5011\u7684\u5206\u6790\u986f\u793a\uff0c\u63d0\u4ea4\u7d66 LLM \u670d\u52d9\u5f15\u64ce\u7684\u7a0b\u5f0f\u6703\u9047\u5230\u9577\u6642\u9593\u7684\u7d2f\u7a4d\u7b49\u5f85\u6642\u9593\uff0c\u9019\u4e3b\u8981\u662f\u56e0\u70ba\u5728\u500b\u5225 LLM \u8acb\u6c42\u548c\u7a0b\u5f0f\u4e2d\u90fd\u6703\u767c\u751f\u968a\u5217\u982d\u7aef\u5c01\u9396\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86 Autellix\uff0c\u9019\u662f\u4e00\u500b LLM \u670d\u52d9\u7cfb\u7d71\uff0c\u5b83\u5c07\u7a0b\u5f0f\u8996\u70ba\u4e00\u7d1a\u516c\u6c11\uff0c\u4ee5\u6700\u5c0f\u5316\u5176\u7aef\u5230\u7aef\u5ef6\u9072\u3002Autellix \u6703\u6514\u622a\u7a0b\u5f0f\u63d0\u4ea4\u7684 LLM \u547c\u53eb\uff0c\u4e26\u4f7f\u7528\u7a0b\u5f0f\u5c64\u7d1a\u7684\u5167\u5bb9\u8c50\u5bcc\u6392\u7a0b\u5668\u3002\u6211\u5011\u63d0\u51fa\u4e86\u5169\u7a2e\u6392\u7a0b\u6f14\u7b97\u6cd5\uff0c\u5206\u5225\u9069\u7528\u65bc\u55ae\u57f7\u884c\u7dd2\u548c\u5206\u6563\u5f0f\u7a0b\u5f0f\uff0c\u9019\u4e9b\u6f14\u7b97\u6cd5\u6703\u6839\u64da\u7a0b\u5f0f\u5148\u524d\u5b8c\u6210\u7684\u547c\u53eb\uff0c\u512a\u5148\u8655\u7406\u548c\u9810\u5148\u8655\u7406 LLM \u547c\u53eb\u3002\u6211\u5011\u7684\u8a55\u4f30\u8b49\u660e\uff0c\u8207 vLLM \u7b49\u6700\u5148\u9032\u7684\u7cfb\u7d71\u76f8\u6bd4\uff0c\u5728\u76f8\u540c\u7684\u5ef6\u9072\u4e0b\uff0cAutellix \u53ef\u5c07\u7a0b\u5f0f\u7684\u8655\u7406\u91cf\u63d0\u5347 4-15 \u500d\uff0c\u4e14\u9069\u7528\u65bc\u5404\u7a2e LLM \u548c\u4ee3\u7406\u5de5\u4f5c\u8ca0\u8f09\u3002", "author": "Michael Luo et.al.", "authors": "Michael Luo, Xiaoxiang Shi, Colin Cai, Tianjun Zhang, Justin Wong, Yichuan Wang, Chi Wang, Yanping Huang, Zhifeng Chen, Joseph E. Gonzalez, Ion Stoica", "id": "2502.13965v1", "paper_url": "http://arxiv.org/abs/2502.13965v1", "repo": "null"}}