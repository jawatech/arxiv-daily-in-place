{"2406.19255": {"publish_time": "2024-06-27", "title": "Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment", "paper_summary": "While pre-training large-scale video-language models (VLMs) has shown\nremarkable potential for various downstream video-language tasks, existing VLMs\ncan still suffer from certain commonly seen limitations, e.g., coarse-grained\ncross-modal aligning , under-modeling of temporal dynamics, detached\nvideo-language view. In this work, we target enhancing VLMs with a fine-grained\nstructural spatio-temporal alignment learning method (namely Finsta). First of\nall, we represent the input texts and videos with fine-grained scene graph (SG)\nstructures, both of which are further unified into a holistic SG (HSG) for\nbridging two modalities. Then, an SG-based framework is built, where the\ntextual SG (TSG) is encoded with a graph Transformer, while the video dynamic\nSG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for\nspatial and temporal feature propagation. A spatial-temporal Gaussian\ndifferential graph Transformer is further devised to strengthen the sense of\nthe changes in objects across spatial and temporal dimensions. Next, based on\nthe fine-grained structural features of TSG and DSG, we perform object-centered\nspatial alignment and predicate-centered temporal alignment respectively,\nenhancing the video-language grounding in both the spatiality and temporality.\nWe design our method as a plug&play system, which can be integrated into\nexisting well-trained VLMs for further representation augmentation, without\ntraining from scratch or relying on SG annotations in downstream applications.\nOn 6 representative VL modeling tasks over 12 datasets in both standard and\nlong-form video scenarios, Finsta consistently improves the existing 13\nstrong-performing VLMs persistently, and refreshes the current state-of-the-art\nend task performance significantly in both the fine-tuning and zero-shot\nsettings.", "paper_summary_zh": "<paragraph>\u96d6\u7136\u9810\u8a13\u7df4\u5927\u578b\u8996\u8a0a\u8a9e\u8a00\u6a21\u578b (VLM) \u5df2\u5c55\u73fe\u51fa\u5c0d\u5404\u7a2e\u4e0b\u6e38\u8996\u8a0a\u8a9e\u8a00\u4efb\u52d9\u7684\u986f\u8457\u6f5b\u529b\uff0c\u4f46\u73fe\u6709\u7684 VLM \u4ecd\u53ef\u80fd\u53d7\u5230\u67d0\u4e9b\u5e38\u898b\u9650\u5236\u7684\u5f71\u97ff\uff0c\u4f8b\u5982\u7c97\u7c92\u5ea6\u7684\u8de8\u6a21\u614b\u5c0d\u9f4a\u3001\u5c0d\u6642\u9593\u52d5\u614b\u7684\u5efa\u6a21\u4e0d\u8db3\u3001\u5206\u96e2\u7684\u8996\u8a0a\u8a9e\u8a00\u6aa2\u8996\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u4ee5\u5177\u5099\u7d30\u7c92\u5ea6\u7d50\u69cb\u5316\u6642\u7a7a\u5c0d\u9f4a\u5b78\u7fd2\u65b9\u6cd5 (\u5373 Finsta) \u7684\u589e\u5f37 VLM \u70ba\u76ee\u6a19\u3002\u9996\u5148\uff0c\u6211\u5011\u4ee5\u7d30\u7c92\u5ea6\u7684\u5834\u666f\u5716 (SG) \u7d50\u69cb\u8868\u793a\u8f38\u5165\u6587\u5b57\u548c\u8996\u8a0a\uff0c\u5169\u8005\u9032\u4e00\u6b65\u7d71\u4e00\u5230\u4e00\u500b\u6574\u9ad4 SG (HSG) \u4e2d\uff0c\u4ee5\u6a4b\u63a5\u5169\u500b\u6a21\u614b\u3002\u7136\u5f8c\uff0c\u5efa\u7acb\u4e00\u500b\u57fa\u65bc SG \u7684\u6846\u67b6\uff0c\u5176\u4e2d\u6587\u5b57 SG (TSG) \u4f7f\u7528\u5716\u5f62 Transformer \u7de8\u78bc\uff0c\u800c\u8996\u8a0a\u52d5\u614b SG (DSG) \u548c HSG \u5247\u4f7f\u7528\u65b0\u7a4e\u7684\u905e\u8ff4\u5716\u5f62 Transformer \u5efa\u6a21\uff0c\u4ee5\u9032\u884c\u7a7a\u9593\u548c\u6642\u9593\u7279\u5fb5\u50b3\u64ad\u3002\u9032\u4e00\u6b65\u8a2d\u8a08\u4e86\u4e00\u500b\u6642\u7a7a\u9ad8\u65af\u5dee\u5206\u5716\u5f62 Transformer\uff0c\u4ee5\u589e\u5f37\u7269\u9ad4\u5728\u6642\u7a7a\u7dad\u5ea6\u4e2d\u8b8a\u5316\u7684\u611f\u89ba\u3002\u63a5\u4e0b\u4f86\uff0c\u6839\u64da TSG \u548c DSG \u7684\u7d30\u7c92\u5ea6\u7d50\u69cb\u7279\u5fb5\uff0c\u6211\u5011\u5206\u5225\u57f7\u884c\u4ee5\u7269\u4ef6\u70ba\u4e2d\u5fc3\u7684\u7a7a\u9593\u5c0d\u9f4a\u548c\u4ee5\u8b02\u8a5e\u70ba\u4e2d\u5fc3\u7684\u6642\u5e8f\u5c0d\u9f4a\uff0c\u589e\u5f37\u8996\u8a0a\u8a9e\u8a00\u5728\u7a7a\u9593\u548c\u6642\u9593\u4e0a\u7684\u57fa\u790e\u3002\u6211\u5011\u5c07\u65b9\u6cd5\u8a2d\u8a08\u70ba\u4e00\u500b\u5373\u63d2\u5373\u7528\u7684\u7cfb\u7d71\uff0c\u53ef\u4ee5\u6574\u5408\u5230\u73fe\u6709\u7684\u8a13\u7df4\u826f\u597d\u7684 VLM \u4e2d\uff0c\u4ee5\u9032\u4e00\u6b65\u64f4\u5145\u8868\u793a\uff0c\u800c\u7121\u9700\u5f9e\u982d\u958b\u59cb\u8a13\u7df4\u6216\u4f9d\u8cf4\u4e0b\u6e38\u61c9\u7528\u7a0b\u5f0f\u4e2d\u7684 SG \u6a19\u8a3b\u3002\u5728 12 \u500b\u8cc7\u6599\u96c6\u4e0a\u7684 6 \u500b\u4ee3\u8868\u6027 VL \u5efa\u6a21\u4efb\u52d9\u4e2d\uff0c\u7121\u8ad6\u662f\u5728\u6a19\u6e96\u8996\u8a0a\u5834\u666f\u9084\u662f\u9577\u683c\u5f0f\u8996\u8a0a\u5834\u666f\u4e2d\uff0cFinsta \u90fd\u6301\u7e8c\u6539\u5584\u73fe\u6709\u7684 13 \u500b\u6548\u80fd\u5f37\u5927\u7684 VLM\uff0c\u4e26\u5728\u5fae\u8abf\u548c\u96f6\u6b21\u5b78\u7fd2\u8a2d\u5b9a\u4e2d\u986f\u8457\u66f4\u65b0\u76ee\u524d\u7684\u6700\u65b0\u6280\u8853\u6700\u7d42\u4efb\u52d9\u6548\u80fd\u3002</paragraph>", "author": "Hao Fei et.al.", "authors": "Hao Fei, Shengqiong Wu, Meishan Zhang, Min Zhang, Tat-Seng Chua, Shuicheng Yan", "id": "2406.19255v1", "paper_url": "http://arxiv.org/abs/2406.19255v1", "repo": "null"}}