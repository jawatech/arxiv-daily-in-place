{"2410.13191": {"publish_time": "2024-10-17", "title": "MCQG-SRefine: Multiple Choice Question Generation and Evaluation with Iterative Self-Critique, Correction, and Comparison Feedback", "paper_summary": "Automatic question generation (QG) is essential for AI and NLP, particularly\nin intelligent tutoring, dialogue systems, and fact verification. Generating\nmultiple-choice questions (MCQG) for professional exams, like the United States\nMedical Licensing Examination (USMLE), is particularly challenging, requiring\ndomain expertise and complex multi-hop reasoning for high-quality questions.\nHowever, current large language models (LLMs) like GPT-4 struggle with\nprofessional MCQG due to outdated knowledge, hallucination issues, and prompt\nsensitivity, resulting in unsatisfactory quality and difficulty. To address\nthese challenges, we propose MCQG-SRefine, an LLM self-refine-based (Critique\nand Correction) framework for converting medical cases into high-quality\nUSMLE-style questions. By integrating expert-driven prompt engineering with\niterative self-critique and self-correction feedback, MCQG-SRefine\nsignificantly enhances human expert satisfaction regarding both the quality and\ndifficulty of the questions. Furthermore, we introduce an LLM-as-Judge-based\nautomatic metric to replace the complex and costly expert evaluation process,\nensuring reliable and expert-aligned assessments.", "paper_summary_zh": "\u81ea\u52d5\u5316\u554f\u984c\u751f\u6210 (QG) \u5c0d\u65bc AI \u548c NLP \u81f3\u95dc\u91cd\u8981\uff0c\u7279\u5225\u662f\u5728\u667a\u6167\u6559\u5b78\u3001\u5c0d\u8a71\u7cfb\u7d71\u548c\u4e8b\u5be6\u9a57\u8b49\u4e2d\u3002\u70ba\u5c08\u696d\u8003\u8a66\uff08\u4f8b\u5982\u7f8e\u570b\u91ab\u5e2b\u57f7\u7167\u8003\u8a66 (USMLE)\uff09\u751f\u6210\u591a\u9078\u984c (MCQG) \u7279\u5225\u5177\u6709\u6311\u6230\u6027\uff0c\u9700\u8981\u5c08\u696d\u77e5\u8b58\u548c\u8907\u96dc\u7684\u591a\u8df3\u63a8\u7406\u624d\u80fd\u7522\u751f\u9ad8\u54c1\u8cea\u7684\u554f\u984c\u3002\u7136\u800c\uff0c\u76ee\u524d\u7684 GPT-4 \u7b49\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7531\u65bc\u77e5\u8b58\u904e\u6642\u3001\u5e7b\u89ba\u554f\u984c\u548c\u63d0\u793a\u654f\u611f\u6027\uff0c\u800c\u96e3\u4ee5\u8655\u7406\u5c08\u696d MCQG\uff0c\u5c0e\u81f4\u54c1\u8cea\u548c\u96e3\u5ea6\u4e0d\u76e1\u4eba\u610f\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa\u4e86 MCQG-SRefine\uff0c\u4e00\u7a2e\u57fa\u65bc LLM \u81ea\u6211\u7cbe\u9032\uff08\u6279\u8a55\u548c\u4fee\u6b63\uff09\u67b6\u69cb\uff0c\u7528\u65bc\u5c07\u91ab\u7642\u6848\u4f8b\u8f49\u63db\u70ba\u9ad8\u54c1\u8cea\u7684 USMLE \u98a8\u683c\u554f\u984c\u3002\u900f\u904e\u6574\u5408\u5c08\u5bb6\u9a45\u52d5\u7684\u63d0\u793a\u5de5\u7a0b\u8207\u53cd\u8986\u81ea\u6211\u6279\u8a55\u548c\u81ea\u6211\u4fee\u6b63\u7684\u56de\u994b\uff0cMCQG-SRefine \u5927\u5e45\u63d0\u5347\u4e86\u4eba\u985e\u5c08\u5bb6\u5c0d\u65bc\u554f\u984c\u54c1\u8cea\u548c\u96e3\u5ea6\u7684\u6eff\u610f\u5ea6\u3002\u6b64\u5916\uff0c\u6211\u5011\u5f15\u9032\u4e00\u500b\u57fa\u65bc LLM \u4f5c\u70ba\u8a55\u5be9\u7684\u81ea\u52d5\u5316\u6307\u6a19\uff0c\u4ee5\u53d6\u4ee3\u8907\u96dc\u4e14\u6602\u8cb4\u7684\u5c08\u5bb6\u8a55\u4f30\u7a0b\u5e8f\uff0c\u78ba\u4fdd\u53ef\u9760\u4e14\u8207\u5c08\u5bb6\u4e00\u81f4\u7684\u8a55\u91cf\u3002", "author": "Zonghai Yao et.al.", "authors": "Zonghai Yao, Aditya Parashar, Huixue Zhou, Won Seok Jang, Feiyun Ouyang, Zhichao Yang, Hong Yu", "id": "2410.13191v1", "paper_url": "http://arxiv.org/abs/2410.13191v1", "repo": "null"}}