{"2304.01543": {"publish_time": "2023-04-04", "title": "A Brief Review of Explainable Artificial Intelligence in Healthcare", "paper_summary": "XAI refers to the techniques and methods for building AI applications which\nassist end users to interpret output and predictions of AI models. Black box AI\napplications in high-stakes decision-making situations, such as medical domain\nhave increased the demand for transparency and explainability since wrong\npredictions may have severe consequences. Model explainability and\ninterpretability are vital successful deployment of AI models in healthcare\npractices. AI applications' underlying reasoning needs to be transparent to\nclinicians in order to gain their trust. This paper presents a systematic\nreview of XAI aspects and challenges in the healthcare domain. The primary\ngoals of this study are to review various XAI methods, their challenges, and\nrelated machine learning models in healthcare. The methods are discussed under\nsix categories: Features-oriented methods, global methods, concept models,\nsurrogate models, local pixel-based methods, and human-centric methods. Most\nimportantly, the paper explores XAI role in healthcare problems to clarify its\nnecessity in safety-critical applications. The paper intends to establish a\ncomprehensive understanding of XAI-related applications in the healthcare field\nby reviewing the related experimental results. To facilitate future research\nfor filling research gaps, the importance of XAI models from different\nviewpoints and their limitations are investigated.", "paper_summary_zh": "", "author": "Zahra Sadeghi et.al.", "authors": "Zahra Sadeghi,Roohallah Alizadehsani,Mehmet Akif Cifci,Samina Kausar,Rizwan Rehman,Priyakshi Mahanta,Pranjal Kumar Bora,Ammar Almasri,Rami S. Alkhawaldeh,Sadiq Hussain,Bilal Alatas,Afshin Shoeibi,Hossein Moosaei,Milan Hladik,Saeid Nahavandi,Panos M. Pardalos", "id": "2304.01543v1", "paper_url": "http://arxiv.org/abs/2304.01543v1", "repo": "null"}}