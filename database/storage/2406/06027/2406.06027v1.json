{"2406.06027": {"publish_time": "2024-06-10", "title": "HOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs", "paper_summary": "Given unstructured text, Large Language Models (LLMs) are adept at answering\nsimple (single-hop) questions. However, as the complexity of the questions\nincrease, the performance of LLMs degrade. We believe this is due to the\noverhead associated with understanding the complex question followed by\nfiltering and aggregating unstructured information in the raw text. Recent\nmethods try to reduce this burden by integrating structured knowledge triples\ninto the raw text, aiming to provide a structured overview that simplifies\ninformation processing. However, this simplistic approach is query-agnostic and\nthe extracted facts are ambiguous as they lack context. To address these\ndrawbacks and to enable LLMs to answer complex (multi-hop) questions with ease,\nwe propose to use a knowledge graph (KG) that is context-aware and is distilled\nto contain query-relevant information. The use of our compressed distilled KG\nas input to the LLM results in our method utilizing up to $67\\%$ fewer tokens\nto represent the query relevant information present in the supporting\ndocuments, compared to the state-of-the-art (SoTA) method. Our experiments show\nconsistent improvements over the SoTA across several metrics (EM, F1,\nBERTScore, and Human Eval) on two popular benchmark datasets (HotpotQA and\nMuSiQue).", "paper_summary_zh": "\u7d66\u5b9a\u975e\u7d50\u69cb\u5316\u6587\u672c\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u64c5\u9577\u56de\u7b54\u7c21\u55ae\uff08\u55ae\u8df3\uff09\u554f\u984c\u3002\u7136\u800c\uff0c\u96a8\u8457\u554f\u984c\u7684\u8907\u96dc\u6027\u589e\u52a0\uff0cLLM \u7684\u6548\u80fd\u6703\u4e0b\u964d\u3002\u6211\u5011\u76f8\u4fe1\u9019\u662f\u56e0\u70ba\u7406\u89e3\u8907\u96dc\u554f\u984c\u6240\u4f34\u96a8\u7684\u958b\u92b7\uff0c\u63a5\u8457\u5728\u539f\u59cb\u6587\u672c\u4e2d\u904e\u6ffe\u548c\u5f59\u7e3d\u975e\u7d50\u69cb\u5316\u8cc7\u8a0a\u3002\u6700\u8fd1\u7684\u65b9\u6cd5\u5617\u8a66\u900f\u904e\u5c07\u7d50\u69cb\u5316\u77e5\u8b58\u4e09\u5143\u7d44\u6574\u5408\u5230\u539f\u59cb\u6587\u672c\u4e2d\u4f86\u6e1b\u8f15\u9019\u500b\u8ca0\u64d4\uff0c\u76ee\u7684\u662f\u63d0\u4f9b\u4e00\u500b\u7c21\u5316\u8cc7\u8a0a\u8655\u7406\u7684\u7d50\u69cb\u5316\u6982\u89c0\u3002\u7136\u800c\uff0c\u9019\u7a2e\u7c21\u5316\u7684\u65b9\u5f0f\u8207\u67e5\u8a62\u7121\u95dc\uff0c\u800c\u4e14\u63d0\u53d6\u7684\u4e8b\u5be6\u6a21\u7a1c\u5169\u53ef\uff0c\u56e0\u70ba\u5b83\u5011\u7f3a\u4e4f\u80cc\u666f\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u7f3a\u9ede\uff0c\u4e26\u4f7f LLM \u80fd\u5920\u8f15\u9b06\u56de\u7b54\u8907\u96dc\uff08\u591a\u8df3\uff09\u554f\u984c\uff0c\u6211\u5011\u5efa\u8b70\u4f7f\u7528\u4e00\u500b\u8207\u80cc\u666f\u76f8\u95dc\u4e14\u7d93\u904e\u63d0\u7149\u4ee5\u5305\u542b\u8207\u67e5\u8a62\u76f8\u95dc\u8cc7\u8a0a\u7684\u77e5\u8b58\u5716\u8b5c (KG)\u3002\u5c07\u6211\u5011\u58d3\u7e2e\u63d0\u7149\u7684 KG \u7528\u4f5c LLM \u7684\u8f38\u5165\uff0c\u4f7f\u5f97\u6211\u5011\u7684\u6a21\u578b\u4f7f\u7528\u6bd4\u6700\u5148\u9032 (SoTA) \u65b9\u6cd5\u6e1b\u5c11\u591a\u9054 $67\\%$ \u7684\u6a19\u8a18\u4f86\u8868\u793a\u652f\u63f4\u6587\u4ef6\u4e2d\u7684\u8207\u67e5\u8a62\u76f8\u95dc\u7684\u8cc7\u8a0a\u3002\u6211\u5011\u7684\u5be6\u9a57\u986f\u793a\uff0c\u5728\u5169\u500b\u6d41\u884c\u7684\u57fa\u6e96\u8cc7\u6599\u96c6\uff08HotpotQA \u548c MuSiQue\uff09\u4e0a\uff0c\u6211\u5011\u7684\u6a21\u578b\u5728\u591a\u9805\u6307\u6a19\uff08EM\u3001F1\u3001BERTScore \u548c\u4eba\u5de5\u8a55\u4f30\uff09\u4e2d\u90fd\u6bd4 SoTA \u6709\u986f\u8457\u7684\u6539\u5584\u3002", "author": "Pranoy Panda et.al.", "authors": "Pranoy Panda, Ankush Agarwal, Chaitanya Devaguptapu, Manohar Kaul, Prathosh A P", "id": "2406.06027v1", "paper_url": "http://arxiv.org/abs/2406.06027v1", "repo": "null"}}