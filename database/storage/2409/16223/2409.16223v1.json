{"2409.16223": {"publish_time": "2024-09-24", "title": "Fine-Tuning is Fine, if Calibrated", "paper_summary": "Fine-tuning is arguably the most straightforward way to tailor a pre-trained\nmodel (e.g., a foundation model) to downstream applications, but it also comes\nwith the risk of losing valuable knowledge the model had learned in\npre-training. For example, fine-tuning a pre-trained classifier capable of\nrecognizing a large number of classes to master a subset of classes at hand is\nshown to drastically degrade the model's accuracy in the other classes it had\npreviously learned. As such, it is hard to further use the fine-tuned model\nwhen it encounters classes beyond the fine-tuning data. In this paper, we\nsystematically dissect the issue, aiming to answer the fundamental question,\n''What has been damaged in the fine-tuned model?'' To our surprise, we find\nthat the fine-tuned model neither forgets the relationship among the other\nclasses nor degrades the features to recognize these classes. Instead, the\nfine-tuned model often produces more discriminative features for these other\nclasses, even if they were missing during fine-tuning! {What really hurts the\naccuracy is the discrepant logit scales between the fine-tuning classes and the\nother classes}, implying that a simple post-processing calibration would bring\nback the pre-trained model's capability and at the same time unveil the feature\nimprovement over all classes. We conduct an extensive empirical study to\ndemonstrate the robustness of our findings and provide preliminary explanations\nunderlying them, suggesting new directions for future theoretical analysis. Our\ncode is available at\nhttps://github.com/OSU-MLB/Fine-Tuning-Is-Fine-If-Calibrated.", "paper_summary_zh": "\u5fae\u8abf\u7121\u7591\u662f\u91dd\u5c0d\u9810\u5148\u8a13\u7df4\u6a21\u578b\uff08\u4f8b\u5982\u57fa\u790e\u6a21\u578b\uff09\u4ee5\u9069\u61c9\u4e0b\u6e38\u61c9\u7528\u6700\u76f4\u63a5\u7684\u65b9\u6cd5\uff0c\u4f46\u5b83\u4e5f\u4f34\u96a8\u8457\u5931\u53bb\u6a21\u578b\u5728\u9810\u5148\u8a13\u7df4\u4e2d\u5b78\u5230\u7684\u5bf6\u8cb4\u77e5\u8b58\u7684\u98a8\u96aa\u3002\u4f8b\u5982\uff0c\u5fae\u8abf\u4e00\u500b\u9810\u5148\u8a13\u7df4\u7684\u5206\u985e\u5668\uff0c\u5b83\u80fd\u5920\u8b58\u5225\u5927\u91cf\u7684\u985e\u5225\uff0c\u4ee5\u638c\u63e1\u624b\u908a\u7684\u985e\u5225\u5b50\u96c6\uff0c\u9019\u5df2\u88ab\u8b49\u660e\u6703\u5927\u5e45\u964d\u4f4e\u6a21\u578b\u5728\u5148\u524d\u5b78\u5230\u7684\u5176\u4ed6\u985e\u5225\u4e2d\u7684\u6e96\u78ba\u5ea6\u3002\u56e0\u6b64\uff0c\u7576\u5fae\u8abf\u6a21\u578b\u9047\u5230\u5fae\u8abf\u6578\u64da\u4e4b\u5916\u7684\u985e\u5225\u6642\uff0c\u5f88\u96e3\u9032\u4e00\u6b65\u4f7f\u7528\u5b83\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u7cfb\u7d71\u6027\u5730\u5256\u6790\u4e86\u9019\u500b\u554f\u984c\uff0c\u65e8\u5728\u56de\u7b54\u9019\u500b\u57fa\u672c\u554f\u984c\uff1a\u300c\u5fae\u8abf\u6a21\u578b\u4e2d\u640d\u58de\u4e86\u4ec0\u9ebc\uff1f\u300d\u4ee4\u6211\u5011\u9a5a\u8a1d\u7684\u662f\uff0c\u6211\u5011\u767c\u73fe\u5fae\u8abf\u6a21\u578b\u65e2\u4e0d\u6703\u5fd8\u8a18\u5176\u4ed6\u985e\u5225\u4e4b\u9593\u7684\u95dc\u4fc2\uff0c\u4e5f\u4e0d\u6703\u964d\u4f4e\u8b58\u5225\u9019\u4e9b\u985e\u5225\u7684\u7279\u5fb5\u3002\u76f8\u53cd\uff0c\u5fae\u8abf\u6a21\u578b\u901a\u5e38\u6703\u70ba\u9019\u4e9b\u5176\u4ed6\u985e\u5225\u7522\u751f\u66f4\u591a\u5177\u5340\u5225\u6027\u7684\u7279\u5fb5\uff0c\u5373\u4f7f\u5b83\u5011\u5728\u5fae\u8abf\u904e\u7a0b\u4e2d\u7f3a\u5931\uff01{\u771f\u6b63\u640d\u5bb3\u6e96\u78ba\u5ea6\u7684\u662f\u5fae\u8abf\u985e\u5225\u548c\u5176\u5b83\u985e\u5225\u4e4b\u9593\u4e0d\u540c\u7684 logit \u5c3a\u5ea6}\uff0c\u9019\u610f\u5473\u8457\u4e00\u500b\u7c21\u55ae\u7684\u5f8c\u8655\u7406\u6821\u6e96\u5c07\u6703\u5e36\u56de\u9810\u5148\u8a13\u7df4\u6a21\u578b\u7684\u80fd\u529b\uff0c\u540c\u6642\u63ed\u793a\u6240\u6709\u985e\u5225\u7684\u7279\u5fb5\u6539\u9032\u3002\u6211\u5011\u9032\u884c\u4e86\u4e00\u9805\u5ee3\u6cdb\u7684\u5be6\u8b49\u7814\u7a76\uff0c\u4ee5\u8b49\u660e\u6211\u5011\u767c\u73fe\u7684\u7a69\u5065\u6027\uff0c\u4e26\u63d0\u4f9b\u4e86\u5b83\u5011\u80cc\u5f8c\u7684\u521d\u6b65\u89e3\u91cb\uff0c\u70ba\u672a\u4f86\u7684\u7406\u8ad6\u5206\u6790\u63d0\u51fa\u4e86\u65b0\u7684\u65b9\u5411\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u53ef\u4ee5\u5728 https://github.com/OSU-MLB/Fine-Tuning-Is-Fine-If-Calibrated \u53d6\u5f97\u3002", "author": "Zheda Mai et.al.", "authors": "Zheda Mai, Arpita Chowdhury, Ping Zhang, Cheng-Hao Tu, Hong-You Chen, Vardaan Pahuja, Tanya Berger-Wolf, Song Gao, Charles Stewart, Yu Su, Wei-Lun Chao", "id": "2409.16223v1", "paper_url": "http://arxiv.org/abs/2409.16223v1", "repo": "null"}}