
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-14**|**On the Surprising Effectiveness of Attention Transfer for Vision Transformers**|Alexander C. Li et.al.|[2411.09702v1](http://arxiv.org/abs/2411.09702v1)|null|
|**2024-11-14**|**A Bayesian Optimization Approach to Machine Translation Reranking**|Julius Cheng et.al.|[2411.09694v1](http://arxiv.org/abs/2411.09694v1)|null|
|**2024-11-14**|**LLM Hallucination Reasoning with Zero-shot Knowledge Test**|Seongmin Lee et.al.|[2411.09689v1](http://arxiv.org/abs/2411.09689v1)|null|
|**2024-11-14**|**Squeezed Attention: Accelerating Long Context Length LLM Inference**|Coleman Hooper et.al.|[2411.09688v1](http://arxiv.org/abs/2411.09688v1)|null|
|**2024-11-14**|**Towards a Classification of Open-Source ML Models and Datasets for Software Engineering**|Alexandra González et.al.|[2411.09683v1](http://arxiv.org/abs/2411.09683v1)|null|
|**2024-11-14**|**NeuralDEM -- Real-time Simulation of Industrial Particulate Flows**|Benedikt Alkin et.al.|[2411.09678v1](http://arxiv.org/abs/2411.09678v1)|null|
|**2024-11-14**|**Adaptive Decoding via Latent Preference Optimization**|Shehzaad Dhuliawala et.al.|[2411.09661v1](http://arxiv.org/abs/2411.09661v1)|null|
|**2024-11-14**|**Med-Bot: An AI-Powered Assistant to Provide Accurate and Reliable Medical Information**|Ahan Bhatt et.al.|[2411.09648v1](http://arxiv.org/abs/2411.09648v1)|null|
|**2024-11-14**|**On the Limits of Language Generation: Trade-Offs Between Hallucination and Mode Collapse**|Alkis Kalavasis et.al.|[2411.09642v1](http://arxiv.org/abs/2411.09642v1)|null|
|**2024-11-14**|**PTR: Precision-Driven Tool Recommendation for Large Language Models**|Hang Gao et.al.|[2411.09613v1](http://arxiv.org/abs/2411.09613v1)|null|
|**2024-11-14**|**The Moral Foundations Weibo Corpus**|Renjie Cao et.al.|[2411.09612v1](http://arxiv.org/abs/2411.09612v1)|null|
|**2024-11-14**|**Initial Nugget Evaluation Results for the TREC 2024 RAG Track with the AutoNuggetizer Framework**|Ronak Pradeep et.al.|[2411.09607v1](http://arxiv.org/abs/2411.09607v1)|null|
|**2024-11-14**|**Local-Global Attention: An Adaptive Mechanism for Multi-Scale Feature Integration**|Yifan Shao et.al.|[2411.09604v1](http://arxiv.org/abs/2411.09604v1)|[link](https://github.com/ziyueqingwan/localglobalattention)|
|**2024-11-14**|**Accelerating Knowledge Graph and Ontology Engineering with Large Language Models**|Cogan Shimizu et.al.|[2411.09601v1](http://arxiv.org/abs/2411.09601v1)|null|
|**2024-11-14**|**LLaMA-Mesh: Unifying 3D Mesh Generation with Language Models**|Zhengyi Wang et.al.|[2411.09595v1](http://arxiv.org/abs/2411.09595v1)|null|
|**2024-11-14**|**Adopting RAG for LLM-Aided Future Vehicle Design**|Vahid Zolfaghari et.al.|[2411.09590v1](http://arxiv.org/abs/2411.09590v1)|null|
|**2024-11-14**|**BabyLM Challenge: Exploring the Effect of Variation Sets on Language Model Training Efficiency**|Akari Haga et.al.|[2411.09587v1](http://arxiv.org/abs/2411.09587v1)|null|
|**2024-11-14**|**Software Performance Engineering for Foundation Model-Powered Software (FMware)**|Haoxiang Zhang et.al.|[2411.09580v1](http://arxiv.org/abs/2411.09580v1)|null|
|**2024-11-14**|**Automating Reformulation of Essence Specifications via Graph Rewriting**|Ian Miguel et.al.|[2411.09576v1](http://arxiv.org/abs/2411.09576v1)|null|
|**2024-11-14**|**Piecing It All Together: Verifying Multi-Hop Multimodal Claims**|Haoran Wang et.al.|[2411.09547v1](http://arxiv.org/abs/2411.09547v1)|null|
|**2024-11-14**|**Prompting the Unseen: Detecting Hidden Backdoors in Black-Box Models**|Zi-Xuan Huang et.al.|[2411.09540v1](http://arxiv.org/abs/2411.09540v1)|null|
|**2024-11-14**|**A Practical Guide to Fine-tuning Language Models with Limited Data**|Márton Szép et.al.|[2411.09539v1](http://arxiv.org/abs/2411.09539v1)|null|
|**2024-11-14**|**Navigating the Risks: A Survey of Security, Privacy, and Ethics Threats in LLM-Based Agents**|Yuyou Gan et.al.|[2411.09523v1](http://arxiv.org/abs/2411.09523v1)|null|
|**2024-11-14**|**Communication Compression for Tensor Parallel LLM Inference**|Jan Hansen-Palmus et.al.|[2411.09510v1](http://arxiv.org/abs/2411.09510v1)|null|
|**2024-11-14**|**Toward a Cohesive AI and Simulation Software Ecosystem for Scientific Innovation**|Michael A. Heroux et.al.|[2411.09507v1](http://arxiv.org/abs/2411.09507v1)|null|
|**2024-11-14**|**MM-Eval: A Hierarchical Benchmark for Modern Mongolian Evaluation in LLMs**|Mengyuan Zhang et.al.|[2411.09492v1](http://arxiv.org/abs/2411.09492v1)|null|
|**2024-11-14**|**ResidualDroppath: Enhancing Feature Reuse over Residual Connections**|Sejik Park et.al.|[2411.09475v1](http://arxiv.org/abs/2411.09475v1)|null|
|**2024-11-14**|**An Explainable Attention Model for Cervical Precancer Risk Classification using Colposcopic Images**|Smith K. Khare et.al.|[2411.09469v1](http://arxiv.org/abs/2411.09469v1)|null|
|**2024-11-14**|**DiffRoad: Realistic and Diverse Road Scenario Generation for Autonomous Vehicle Testing**|Junjie Zhou et.al.|[2411.09451v1](http://arxiv.org/abs/2411.09451v1)|null|
|**2024-11-14**|**Robot Tasks with Fuzzy Time Requirements from Natural Language Instructions**|Sascha Sucker et.al.|[2411.09436v1](http://arxiv.org/abs/2411.09436v1)|null|
|**2024-11-14**|**Everyone deserves their voice to be heard: Analyzing Predictive Gender Bias in ASR Models Applied to Dutch Speech Data**|Rik Raes et.al.|[2411.09431v1](http://arxiv.org/abs/2411.09431v1)|null|
|**2024-11-14**|**AI-driven inverse design of materials: Past, present and future**|Xiao-Qi Han et.al.|[2411.09429v1](http://arxiv.org/abs/2411.09429v1)|null|
|**2024-11-14**|**SAG-ViT: A Scale-Aware, High-Fidelity Patching Approach with Graph Attention for Vision Transformers**|Shravan Venkatraman et.al.|[2411.09420v1](http://arxiv.org/abs/2411.09420v1)|null|
|**2024-11-14**|**Script-centric behavior understanding for assisted autism spectrum disorder diagnosis**|Wenxing Liu et.al.|[2411.09413v1](http://arxiv.org/abs/2411.09413v1)|null|
|**2024-11-14**|**Imagined Speech and Visual Imagery as Intuitive Paradigms for Brain-Computer Interfaces**|Seo-Hyun Lee et.al.|[2411.09400v1](http://arxiv.org/abs/2411.09400v1)|null|
|**2024-11-14**|**Less is More: Unseen Domain Fake News Detection via Causal Propagation Substructures**|Shuzhi Gong et.al.|[2411.09389v1](http://arxiv.org/abs/2411.09389v1)|null|
|**2024-11-14**|**LTLf+ and PPLTL+: Extending LTLf and PPLTL to Infinite Traces**|Benjamin Aminof et.al.|[2411.09366v1](http://arxiv.org/abs/2411.09366v1)|null|
|**2024-11-14**|**Multi-scale Generative Modeling for Fast Sampling**|Xiongye Xiao et.al.|[2411.09356v1](http://arxiv.org/abs/2411.09356v1)|null|
|**2024-11-14**|**Re-Parameterization of Lightweight Transformer for On-Device Speech Emotion Recognition**|Zixing Zhang et.al.|[2411.09339v1](http://arxiv.org/abs/2411.09339v1)|null|
|**2024-11-14**|**DriveThru: a Document Extraction Platform and Benchmark Datasets for Indonesian Local Language Archives**|MohammadRifqi Farhansyah et.al.|[2411.09318v1](http://arxiv.org/abs/2411.09318v1)|[link](https://github.com/ragambahasa/OCR-Correction)|
|**2024-11-14**|**EEG-Based Speech Decoding: A Novel Approach Using Multi-Kernel Ensemble Diffusion Models**|Soowon Kim et.al.|[2411.09302v1](http://arxiv.org/abs/2411.09302v1)|null|
|**2024-11-14**|**DTELS: Towards Dynamic Granularity of Timeline Summarization**|Chenlong Zhang et.al.|[2411.09297v1](http://arxiv.org/abs/2411.09297v1)|[link](https://github.com/chenlong-clock/DTELS-Bench)|
|**2024-11-14**|**StreamAdapter: Efficient Test Time Adaptation from Contextual Streams**|Dilxat Muhtar et.al.|[2411.09289v1](http://arxiv.org/abs/2411.09289v1)|null|
|**2024-11-14**|**Cross-Modal Consistency in Multimodal Large Language Models**|Xiang Zhang et.al.|[2411.09273v1](http://arxiv.org/abs/2411.09273v1)|null|
|**2024-11-14**|**Harnessing multiple LLMs for Information Retrieval: A case study on Deep Learning methodologies in Biodiversity publications**|Vamsi Krishna Kommineni et.al.|[2411.09269v1](http://arxiv.org/abs/2411.09269v1)|null|
|**2024-11-14**|**How Good is ChatGPT at Audiovisual Deepfake Detection: A Comparative Study of ChatGPT, AI Models and Human Perception**|Sahibzada Adil Shahzad et.al.|[2411.09266v1](http://arxiv.org/abs/2411.09266v1)|null|
|**2024-11-14**|**Automating Autograding: Large Language Models as Test Suite Generators for Introductory Programming**|Umar Alkafaween et.al.|[2411.09261v1](http://arxiv.org/abs/2411.09261v1)|null|
|**2024-11-14**|**Jailbreak Attacks and Defenses against Multimodal Generative Models: A Survey**|Xuannan Liu et.al.|[2411.09259v1](http://arxiv.org/abs/2411.09259v1)|null|
|**2024-11-14**|**DAHL: Domain-specific Automated Hallucination Evaluation of Long-Form Text through a Benchmark Dataset in Biomedicine**|Jean Seo et.al.|[2411.09255v1](http://arxiv.org/abs/2411.09255v1)|[link](https://github.com/seemdog/DAHL)|
|**2024-11-14**|**Cross Space and Time: A Spatio-Temporal Unitized Model for Traffic Flow Forecasting**|Weilin Ruan et.al.|[2411.09251v1](http://arxiv.org/abs/2411.09251v1)|null|
|**2024-11-14**|**Enhancing Financial Domain Adaptation of Language Models via Model Augmentation**|Kota Tanabe et.al.|[2411.09249v1](http://arxiv.org/abs/2411.09249v1)|null|
|**2024-11-14**|**Towards Unified Neural Decoding of Perceived, Spoken and Imagined Speech from EEG Signals**|Jung-Sun Lee et.al.|[2411.09243v1](http://arxiv.org/abs/2411.09243v1)|null|
|**2024-11-14**|**Programming with AI: Evaluating ChatGPT, Gemini, AlphaCode, and GitHub Copilot for Programmers**|Md Kamrul Siam et.al.|[2411.09224v1](http://arxiv.org/abs/2411.09224v1)|null|
|**2024-11-14**|**Transferable Adversarial Attacks against ASR**|Xiaoxue Gao et.al.|[2411.09220v1](http://arxiv.org/abs/2411.09220v1)|null|
|**2024-11-14**|**HateGPT: Unleashing GPT-3.5 Turbo to Combat Hate Speech on X**|Aniket Deroy et.al.|[2411.09214v1](http://arxiv.org/abs/2411.09214v1)|null|
|**2024-11-14**|**Comprehensive and Practical Evaluation of Retrieval-Augmented Generation Systems for Medical Question Answering**|Nghia Trung Ngo et.al.|[2411.09213v1](http://arxiv.org/abs/2411.09213v1)|null|
|**2024-11-14**|**Improvement and Implementation of a Speech Emotion Recognition Model Based on Dual-Layer LSTM**|Xiaoran Yang et.al.|[2411.09189v1](http://arxiv.org/abs/2411.09189v1)|null|
|**2024-11-14**|**Dynamic technology impact analysis: A multi-task learning approach to patent citation prediction**|Youngjin Seol et.al.|[2411.09184v1](http://arxiv.org/abs/2411.09184v1)|null|
|**2024-11-14**|**DeBaTeR: Denoising Bipartite Temporal Graph for Recommendation**|Xinyu He et.al.|[2411.09181v1](http://arxiv.org/abs/2411.09181v1)|null|
|**2024-11-14**|**LEAP:D -- A Novel Prompt-based Approach for Domain-Generalized Aerial Object Detection**|Chanyeong Park et.al.|[2411.09180v1](http://arxiv.org/abs/2411.09180v1)|null|
|**2024-11-14**|**Gazing at Rewards: Eye Movements as a Lens into Human and AI Decision-Making in Hybrid Visual Foraging**|Bo Wang et.al.|[2411.09176v1](http://arxiv.org/abs/2411.09176v1)|null|
|**2024-11-14**|**Advancing Diffusion Models: Alias-Free Resampling and Enhanced Rotational Equivariance**|Md Fahim Anjum et.al.|[2411.09174v1](http://arxiv.org/abs/2411.09174v1)|null|
|**2024-11-14**|**Towards Scalable Handwriting Communication via EEG Decoding and Latent Embedding Integration**|Jun-Young Kim et.al.|[2411.09170v1](http://arxiv.org/abs/2411.09170v1)|null|
|**2024-11-14**|**Artificial Theory of Mind and Self-Guided Social Organisation**|Michael S. Harré et.al.|[2411.09169v1](http://arxiv.org/abs/2411.09169v1)|null|
|**2024-11-14**|**Unstructured Text Enhanced Open-domain Dialogue System: A Systematic Survey**|Longxuan Ma et.al.|[2411.09166v1](http://arxiv.org/abs/2411.09166v1)|null|
|**2024-11-14**|**Rationality based Innate-Values-driven Reinforcement Learning**|Qin Yang et.al.|[2411.09160v1](http://arxiv.org/abs/2411.09160v1)|null|
|**2024-11-14**|**DROJ: A Prompt-Driven Attack against Large Language Models**|Leyang Hu et.al.|[2411.09125v1](http://arxiv.org/abs/2411.09125v1)|[link](https://github.com/leon-leyang/llm-safeguard)|
|**2024-11-14**|**P-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of LLMs**|Yidan Zhang et.al.|[2411.09116v1](http://arxiv.org/abs/2411.09116v1)|null|
|**2024-11-14**|**Personalized Help for Optimizing Low-Skilled Users' Strategy**|Feng Gu et.al.|[2411.09109v1](http://arxiv.org/abs/2411.09109v1)|null|
|**2024-11-14**|**VCBench: A Controllable Benchmark for Symbolic and Abstract Challenges in Video Cognition**|Chenglin Li et.al.|[2411.09105v1](http://arxiv.org/abs/2411.09105v1)|null|
|**2024-11-14**|**Provocation: Who benefits from "inclusion" in Generative AI?**|Nari Johnson et.al.|[2411.09102v1](http://arxiv.org/abs/2411.09102v1)|null|
|**2024-11-14**|**Heuristical Comparison of Vision Transformers Against Convolutional Neural Networks for Semantic Segmentation on Remote Sensing Imagery**|Ashim Dahal et.al.|[2411.09101v1](http://arxiv.org/abs/2411.09101v1)|[link](https://github.com/ashimdahal/vit-vs-cnn-image-segmentation)|
|**2024-11-13**|**Drone Detection using Deep Neural Networks Trained on Pure Synthetic Data**|Mariusz Wisniewski et.al.|[2411.09077v1](http://arxiv.org/abs/2411.09077v1)|[link](https://github.com/mazqtpopx/cranfield-synthetic-drone-detection)|
|**2024-11-13**|**Code-mixed LLM: Improve Large Language Models' Capability to Handle Code-Mixing through Reinforcement Learning from AI Feedback**|Wenbo Zhang et.al.|[2411.09073v1](http://arxiv.org/abs/2411.09073v1)|null|
|**2024-11-13**|**Liner Shipping Network Design with Reinforcement Learning**|Utsav Dutta et.al.|[2411.09068v1](http://arxiv.org/abs/2411.09068v1)|null|
|**2024-11-13**|**Language-Model Prior Overcomes Cold-Start Items**|Shiyu Wang et.al.|[2411.09065v1](http://arxiv.org/abs/2411.09065v1)|[link](https://github.com/awslabs/language-model-prior-4-item-cold-start)|
|**2024-11-13**|**Multimodal Object Detection using Depth and Image Data for Manufacturing Parts**|Nazanin Mahjourian et.al.|[2411.09062v1](http://arxiv.org/abs/2411.09062v1)|null|
|**2024-11-13**|**SAFELOC: Overcoming Data Poisoning Attacks in Heterogeneous Federated Machine Learning for Indoor Localization**|Akhil Singampalli et.al.|[2411.09055v1](http://arxiv.org/abs/2411.09055v1)|null|
|**2024-11-13**|**The Systems Engineering Approach in Times of Large Language Models**|Christian Cabrera et.al.|[2411.09050v1](http://arxiv.org/abs/2411.09050v1)|[link](https://github.com/cabrerac/semi-automatic-literature-survey)|
|**2024-11-13**|**Bridging the Visual Gap: Fine-Tuning Multimodal Models with Knowledge-Adapted Captions**|Moran Yanuka et.al.|[2411.09018v1](http://arxiv.org/abs/2411.09018v1)|null|
|**2024-11-13**|**Cut Your Losses in Large-Vocabulary Language Models**|Erik Wijmans et.al.|[2411.09009v1](http://arxiv.org/abs/2411.09009v1)|[link](https://github.com/apple/ml-cross-entropy)|
|**2024-11-13**|**Refusal in LLMs is an Affine Function**|Thomas Marshall et.al.|[2411.09003v1](http://arxiv.org/abs/2411.09003v1)|[link](https://github.com/eleutherai/steering-llama3)|
|**2024-11-13**|**IDCIA: Immunocytochemistry Dataset for Cellular Image Analysis**|Abdurahman Ali Mohammed et.al.|[2411.08992v1](http://arxiv.org/abs/2411.08992v1)|[link](https://github.com/isu-nrt-d4/cell-analysis)|
|**2024-11-13**|**CoCoP: Enhancing Text Classification with LLM through Code Completion Prompt**|Mohammad Mahdi Mohajeri et.al.|[2411.08979v1](http://arxiv.org/abs/2411.08979v1)|null|
|**2024-11-13**|**Robustness and Confounders in the Demographic Alignment of LLMs with Human Perceptions of Offensiveness**|Shayan Alipour et.al.|[2411.08977v1](http://arxiv.org/abs/2411.08977v1)|null|
|**2024-11-13**|**Sparse Upcycling: Inference Inefficient Finetuning**|Sasha Doubov et.al.|[2411.08968v1](http://arxiv.org/abs/2411.08968v1)|null|
|**2024-11-13**|**Inconsistencies In Consistency Models: Better ODE Solving Does Not Imply Better Samples**|Noël Vouitsis et.al.|[2411.08954v1](http://arxiv.org/abs/2411.08954v1)|[link](https://github.com/layer6ai-labs/direct-cms)|
|**2024-11-13**|**4D Gaussian Splatting in the Wild with Uncertainty-Aware Regularization**|Mijeong Kim et.al.|[2411.08879v1](http://arxiv.org/abs/2411.08879v1)|null|
|**2024-11-13**|**The Limited Impact of Medical Adaptation of Large Language and Vision-Language Models**|Daniel P. Jeong et.al.|[2411.08870v1](http://arxiv.org/abs/2411.08870v1)|null|
|**2024-11-13**|**CamemBERT 2.0: A Smarter French Language Model Aged to Perfection**|Wissam Antoun et.al.|[2411.08868v1](http://arxiv.org/abs/2411.08868v1)|null|
|**2024-11-13**|**Data-driven Surface Solar Irradiance Estimation using Neural Operators at Global Scale**|Alberto Carpentieri et.al.|[2411.08843v1](http://arxiv.org/abs/2411.08843v1)|null|
|**2024-11-13**|**AstroM$^3$: A self-supervised multimodal model for astronomy**|Mariia Rizhko et.al.|[2411.08842v1](http://arxiv.org/abs/2411.08842v1)|null|
|**2024-11-13**|**Offline Adaptation of Quadruped Locomotion using Diffusion Models**|Reece O'Mahoney et.al.|[2411.08832v1](http://arxiv.org/abs/2411.08832v1)|null|
|**2024-11-13**|**Process-aware Human Activity Recognition**|Jiawei Zheng et.al.|[2411.08814v1](http://arxiv.org/abs/2411.08814v1)|null|
|**2024-11-13**|**Rethinking CyberSecEval: An LLM-Aided Approach to Evaluation Critique**|Suhas Hariharan et.al.|[2411.08813v1](http://arxiv.org/abs/2411.08813v1)|null|
|**2024-11-13**|**Evaluating World Models with LLM for Decision Making**|Chang Yang et.al.|[2411.08794v1](http://arxiv.org/abs/2411.08794v1)|null|
|**2024-11-13**|**Can sparse autoencoders be used to decompose and interpret steering vectors?**|Harry Mayne et.al.|[2411.08790v1](http://arxiv.org/abs/2411.08790v1)|[link](https://github.com/harrymayne/sv_interpretability)|
|**2024-11-13**|**Zero-shot Cross-lingual Transfer Learning with Multiple Source and Target Languages for Information Extraction: Language Selection and Adversarial Training**|Nghia Trung Ngo et.al.|[2411.08785v1](http://arxiv.org/abs/2411.08785v1)|null|
|**2024-11-13**|**Sharingan: Extract User Action Sequence from Desktop Recordings**|Yanting Chen et.al.|[2411.08768v1](http://arxiv.org/abs/2411.08768v1)|null|
|**2024-11-13**|**SANDWICH: Towards an Offline, Differentiable, Fully-Trainable Wireless Neural Ray-Tracing Surrogate**|Yifei Jin et.al.|[2411.08767v1](http://arxiv.org/abs/2411.08767v1)|null|

#### Abstracts
##### **On the Surprising Effectiveness of Attention Transfer for Vision Transformers**
2411.09702v1 by Alexander C. Li, Yuandong Tian, Beidi Chen, Deepak Pathak, Xinlei Chen

Conventional wisdom suggests that pre-training Vision Transformers (ViT)
improves downstream performance by learning useful representations. Is this
actually true? We investigate this question and find that the features and
representations learned during pre-training are not essential. Surprisingly,
using only the attention patterns from pre-training (i.e., guiding how
information flows between tokens) is sufficient for models to learn high
quality features from scratch and achieve comparable downstream performance. We
show this by introducing a simple method called attention transfer, where only
the attention patterns from a pre-trained teacher ViT are transferred to a
student, either by copying or distilling the attention maps. Since attention
transfer lets the student learn its own features, ensembling it with a
fine-tuned teacher also further improves accuracy on ImageNet. We
systematically study various aspects of our findings on the sufficiency of
attention maps, including distribution shift settings where they underperform
fine-tuning. We hope our exploration provides a better understanding of what
pre-training accomplishes and leads to a useful alternative to the standard
practice of fine-tuning

摘要：傳統觀念認為預訓練視覺Transformer（ViT）
透過學習有用的表徵來提升下游效能。這
是否屬實？我們探討這個問題，發現預訓練期間學習到的特徵和
表徵並非必要的。令人驚訝的是，僅使用預訓練的注意力模式（也
就是引導資訊如何在符號之間流動）就足以讓模型從頭學習高
品質的特徵，並達成相近的下游效能。我們透過引入一種稱為注
意力轉移的簡單方法來證明這一點，其中僅將預訓練教師 ViT 的
注意力模式轉移給學生，方法是複製或萃取注意力圖。由於注
意力轉移讓學生學習自己的特徵，因此將其與微調教師結合也
進一步提升了 ImageNet 的準確度。我們系統性地研究了我們在
注意力圖的充分性方面的發現的各個面向，包括它們表現不如微
調的分配轉移設定。我們希望我們的探索能提供對預訓練達成
什麼目標的更深入理解，並提供一種有用的替代方案來取代微調
的標準做法

##### **A Bayesian Optimization Approach to Machine Translation Reranking**
2411.09694v1 by Julius Cheng, Maike Züfle, Vilém Zouhar, Andreas Vlachos

Reranking a list of candidates from a machine translation system with an
external scoring model and returning the highest-scoring candidate remains a
simple and effective method for improving the overall output quality.
Translation scoring models continue to grow in size, with the best models being
comparable to generation models. Thus, reranking can add substantial
computational cost to the translation pipeline. In this work, we pose reranking
as a Bayesian optimization (BayesOpt) problem. By strategically selecting
candidates to score based on a balance of exploration and exploitation, we show
that it is possible to find top-scoring candidates when scoring only a fraction
of the candidate list. For instance, our method achieves the same CometKiwi
score using only 70 scoring evaluations compared a baseline system using 180.
We present a multi-fidelity setting for BayesOpt, where the candidates are
first scored with a cheaper but noisier proxy scoring model, which further
improves the cost-performance tradeoff when using smaller but well-trained
distilled proxy scorers.

摘要：利用外部評分模型重新排列機器翻譯系統的候選清單，並回傳評分最高的候選，這仍然是改善整體輸出品質的簡單且有效的方法。
翻譯評分模型持續擴增，其中最佳的模型與生成模型相當。因此，重新排列會為翻譯流程增加大量的運算成本。在這項工作中，我們將重新排列視為貝氏最佳化 (BayesOpt) 問題。透過策略性地選擇候選，在探索與開發取得平衡的基礎上進行評分，我們證明了在僅評分候選清單的一部分時，有可能找到評分最高的候選。例如，我們的模型僅使用 70 次評分評估就達到相同的 CometKiwi 分數，而基線系統則使用 180 次。我們提出適用於 BayesOpt 的多重保真度設定，其中候選首先使用較便宜但較多雜訊的代理評分模型進行評分，這進一步改善了使用較小但訓練良好的蒸餾代理評分器的成本效益權衡。

##### **LLM Hallucination Reasoning with Zero-shot Knowledge Test**
2411.09689v1 by Seongmin Lee, Hsiang Hsu, Chun-Fu Chen

LLM hallucination, where LLMs occasionally generate unfaithful text, poses
significant challenges for their practical applications. Most existing
detection methods rely on external knowledge, LLM fine-tuning, or
hallucination-labeled datasets, and they do not distinguish between different
types of hallucinations, which are crucial for improving detection performance.
We introduce a new task, Hallucination Reasoning, which classifies
LLM-generated text into one of three categories: aligned, misaligned, and
fabricated. Our novel zero-shot method assesses whether LLM has enough
knowledge about a given prompt and text. Our experiments conducted on new
datasets demonstrate the effectiveness of our method in hallucination reasoning
and underscore its importance for enhancing detection performance.

摘要：大型语言模型 (LLM) 的幻觉，也就是 LLM 偶尔会生成不忠实文本的情况，对其实际应用构成了重大挑战。大多数现有的检测方法依赖于外部知识、LLM 微调或幻觉标记数据集，而且它们不区分不同类型的幻觉，而这对于提高检测性能至关重要。我们引入了一项新任务，即幻觉推理，它将 LLM 生成的文本归类为以下三类之一：对齐、错位和虚构。我们新颖的零样本方法评估了 LLM 是否对给定的提示和文本有足够的了解。我们对新数据集进行的实验证明了我们的方法在幻觉推理中的有效性，并强调了其对提高检测性能的重要性。

##### **Squeezed Attention: Accelerating Long Context Length LLM Inference**
2411.09688v1 by Coleman Hooper, Sehoon Kim, Hiva Mohammadzadeh, Monishwaran Maheswaran, June Paik, Michael W. Mahoney, Kurt Keutzer, Amir Gholami

Emerging Large Language Model (LLM) applications require long input prompts
to perform complex downstream tasks like document analysis and code generation.
For these long context length applications, the length of the input prompt
poses a significant challenge in terms of inference efficiency since the
inference costs increase linearly with sequence length. However, for many of
these applications, much of the context in the prompt is fixed across different
user inputs, thereby providing the opportunity to perform offline optimizations
to process user inputs quickly, as they are received. In this work, we propose
Squeezed Attention as a mechanism to accelerate LLM applications where a large
portion of the input prompt is fixed. We first leverage K-means clustering
offline to group the keys for the fixed context based on semantic similarity
and represent each cluster with a single centroid value. During inference, we
compare query tokens from the user input with the centroids to predict which of
the keys from the fixed context are semantically relevant and need to be loaded
during inference. We then compute exact attention using only these important
keys from the fixed context, thereby reducing bandwidth and computational
costs. We also extend our method to use a hierarchical centroid lookup to
identify important keys, which can reduce the complexity of attention from
linear to logarithmic with respect to the context length. We implement
optimized Triton kernels for centroid comparison and sparse FlashAttention with
important keys, achieving more than 4x speedups during both the prefill and
generation phases for long-context inference. Furthermore, we have extensively
evaluated our method on various long-context benchmarks including LongBench,
where it achieves a 3x reduction in KV cache budget without accuracy loss and
up to an 8x reduction with <0.5 point accuracy gap for various models.

摘要：新興的大語言模型 (LLM) 應用程式需要長的輸入提示，才能執行複雜的下游任務，例如文件分析和程式碼產生。對於這些長脈絡長度的應用程式來說，輸入提示的長度在推論效率方面構成重大挑戰，因為推論成本會隨著序列長度線性增加。然而，對於這些應用程式中的許多應用程式，提示中的大部分脈絡在不同的使用者輸入中都是固定的，因此提供了執行離線最佳化以快速處理使用者輸入的機會，因為它們已被接收。在這項工作中，我們建議使用 Squeezed Attention 作為一種機制，以加速 LLM 應用程式，其中輸入提示的大部分是固定的。我們首先利用 K 平均群集在離線模式下根據語義相似性對固定脈絡的鍵進行分組，並使用單一質心值表示每個群集。在推論期間，我們將使用者輸入中的查詢代幣與質心進行比較，以預測固定脈絡中的哪些鍵在語義上相關，並且需要在推論期間載入。然後，我們僅使用固定脈絡中的這些重要鍵計算確切的注意力，從而減少頻寬和運算成本。我們還將方法擴充套件為使用階層質心查詢來識別重要鍵，這可以將注意力的複雜度從線性降低到對數，相對於脈絡長度而言。我們實作最佳化的 Triton 核心，用於質心比較和具有重要鍵的稀疏 FlashAttention，在長脈絡推論的預填和產生階段實現超過 4 倍的加速。此外，我們已針對各種長脈絡基準廣泛評估我們的模型，包括 LongBench，其中在不損失準確性的情況下實現了 KV 快取預算減少 3 倍，並且對於各種模型，減少了多達 8 倍，準確度差距小於 0.5 點。

##### **Towards a Classification of Open-Source ML Models and Datasets for Software Engineering**
2411.09683v1 by Alexandra González, Xavier Franch, David Lo, Silverio Martínez-Fernández

Background: Open-Source Pre-Trained Models (PTMs) and datasets provide
extensive resources for various Machine Learning (ML) tasks, yet these
resources lack a classification tailored to Software Engineering (SE) needs.
Aims: We apply an SE-oriented classification to PTMs and datasets on a popular
open-source ML repository, Hugging Face (HF), and analyze the evolution of PTMs
over time. Method: We conducted a repository mining study. We started with a
systematically gathered database of PTMs and datasets from the HF API. Our
selection was refined by analyzing model and dataset cards and metadata, such
as tags, and confirming SE relevance using Gemini 1.5 Pro. All analyses are
replicable, with a publicly accessible replication package. Results: The most
common SE task among PTMs and datasets is code generation, with a primary focus
on software development and limited attention to software management. Popular
PTMs and datasets mainly target software development. Among ML tasks, text
generation is the most common in SE PTMs and datasets. There has been a marked
increase in PTMs for SE since 2023 Q2. Conclusions: This study underscores the
need for broader task coverage to enhance the integration of ML within SE
practices.

摘要：背景：開放原始碼預訓練模型 (PTM) 和資料集為各種機器學習 (ML) 任務提供廣泛的資源，但這些資源缺乏針對軟體工程 (SE) 需求量身打造的分類。
目標：我們將以 SE 為導向的分類應用於熱門開放原始碼 ML 儲存庫 Hugging Face (HF) 上的 PTM 和資料集，並分析 PTM 隨著時間的演變。方法：我們進行了儲存庫挖掘研究。我們從 HF API 系統性收集的 PTM 和資料集資料庫開始。我們透過分析模型和資料集卡片和元資料（例如標籤）並使用 Gemini 1.5 Pro 確認 SE 相關性來改善我們的選擇。所有分析都是可複製的，並提供公開可存取的複製套件。結果：PTM 和資料集中最常見的 SE 任務是程式碼產生，主要專注於軟體開發，而較少關注軟體管理。熱門的 PTM 和資料集主要針對軟體開發。在 ML 任務中，文字產生在 SE PTM 和資料集中最常見。自 2023 年第 2 季以來，SE 的 PTM 大幅增加。結論：本研究強調需要更廣泛的任務涵蓋範圍，以增強 ML 在 SE 實務中的整合。

##### **NeuralDEM -- Real-time Simulation of Industrial Particulate Flows**
2411.09678v1 by Benedikt Alkin, Tobias Kronlachner, Samuele Papa, Stefan Pirker, Thomas Lichtenegger, Johannes Brandstetter

Advancements in computing power have made it possible to numerically simulate
large-scale fluid-mechanical and/or particulate systems, many of which are
integral to core industrial processes. Among the different numerical methods
available, the discrete element method (DEM) provides one of the most accurate
representations of a wide range of physical systems involving granular and
discontinuous materials. Consequently, DEM has become a widely accepted
approach for tackling engineering problems connected to granular flows and
powder mechanics. Additionally, DEM can be integrated with grid-based
computational fluid dynamics (CFD) methods, enabling the simulation of chemical
processes taking place, e.g., in fluidized beds. However, DEM is
computationally intensive because of the intrinsic multiscale nature of
particulate systems, restricting simulation duration or number of particles.
Towards this end, NeuralDEM presents an end-to-end approach to replace slow
numerical DEM routines with fast, adaptable deep learning surrogates. NeuralDEM
is capable of picturing long-term transport processes across different regimes
using macroscopic observables without any reference to microscopic model
parameters. First, NeuralDEM treats the Lagrangian discretization of DEM as an
underlying continuous field, while simultaneously modeling macroscopic behavior
directly as additional auxiliary fields. Second, NeuralDEM introduces
multi-branch neural operators scalable to real-time modeling of
industrially-sized scenarios - from slow and pseudo-steady to fast and
transient. Such scenarios have previously posed insurmountable challenges for
deep learning models. Notably, NeuralDEM faithfully models coupled CFD-DEM
fluidized bed reactors of 160k CFD cells and 500k DEM particles for
trajectories of 28s. NeuralDEM will open many new doors to advanced engineering
and much faster process cycles.

摘要：<paragraph>運算能力的進步使得以數字方式模擬大規模流體力學和/或顆粒系統成為可能，其中許多系統都是核心工業流程中不可或缺的一部分。在各種可用的數值方法中，離散元素法 (DEM) 提供了涉及顆粒和不連續材料的各種物理系統最準確的表示之一。因此，DEM 已成為解決與顆粒流和粉末力學相關的工程問題的廣泛接受方法。此外，DEM 可以與基於網格的計算流體力學 (CFD) 方法整合，從而能夠模擬發生的化學過程，例如在流化床中。然而，由於顆粒系統固有的多尺度性質，DEM 在計算上很密集，限制了模擬持續時間或粒子數量。為此，NeuralDEM 提出了一種端到端方法，用快速、適應性強的深度學習代理取代緩慢的數值 DEM 常式。NeuralDEM 能夠在不參考微觀模型參數的情況下，使用宏觀可觀察量描繪跨不同機制的長期傳輸過程。首先，NeuralDEM 將 DEM 的拉格朗日離散化視為一個底層連續場，同時將宏觀行為直接建模為額外的輔助場。其次，NeuralDEM 引入了可擴展到工業規模場景的實時建模的多分支神經運算子 - 從緩慢和擬穩態到快速和瞬態。此類場景以前對深度學習模型構成了無法克服的挑戰。值得注意的是，NeuralDEM 忠實地模擬了 160k CFD 單元和 500k DEM 粒子的耦合 CFD-DEM 流化床反應器，持續時間為 28 秒。NeuralDEM 將為先進工程和更快的流程週期開啟許多新的大門。</paragraph>

##### **Adaptive Decoding via Latent Preference Optimization**
2411.09661v1 by Shehzaad Dhuliawala, Ilia Kulikov, Ping Yu, Asli Celikyilmaz, Jason Weston, Sainbayar Sukhbaatar, Jack Lanchantin

During language model decoding, it is known that using higher temperature
sampling gives more creative responses, while lower temperatures are more
factually accurate. However, such models are commonly applied to general
instruction following, which involves both creative and fact seeking tasks,
using a single fixed temperature across all examples and tokens. In this work,
we introduce Adaptive Decoding, a layer added to the model to select the
sampling temperature dynamically at inference time, at either the token or
example level, in order to optimize performance. To learn its parameters we
introduce Latent Preference Optimization (LPO) a general approach to train
discrete latent variables such as choices of temperature. Our method
outperforms all fixed decoding temperatures across a range of tasks that
require different temperatures, including UltraFeedback, Creative Story
Writing, and GSM8K.

摘要：在語言模型解碼過程中，已知使用較高的溫度採樣會產生較有創意的回應，而較低的溫度則在事實上較為準確。然而，此類模型通常用於遵循一般指示，這涉及有創意和尋求事實的任務，在所有範例和代碼中使用單一固定溫度。在這項工作中，我們引入了自適應解碼，這是新增到模型中的一個層，用於在推論時間動態選擇採樣溫度，無論是在代碼或範例層級，以最佳化效能。為了學習其參數，我們引入了潛在偏好最佳化 (LPO)，這是一種訓練離散潛在變數（例如溫度選擇）的通用方法。我們的模型在需要不同溫度的一系列任務中優於所有固定解碼溫度，包括 UltraFeedback、創意故事寫作和 GSM8K。

##### **Med-Bot: An AI-Powered Assistant to Provide Accurate and Reliable Medical Information**
2411.09648v1 by Ahan Bhatt, Nandan Vaghela

This paper introduces Med-Bot, an AI-powered chatbot designed to provide
users with accurate and reliable medical information. Utilizing advanced
libraries and frameworks such as PyTorch, Chromadb, Langchain and Autogptq,
Med-Bot is built to handle the complexities of natural language understanding
in a healthcare context. The integration of llamaassisted data processing and
AutoGPT-Q provides enhanced performance in processing and responding to queries
based on PDFs of medical literature, ensuring that users receive precise and
trustworthy information. This research details the methodologies employed in
developing Med-Bot and evaluates its effectiveness in disseminating healthcare
information.

摘要：本文介紹 Med-Bot，一個由人工智慧驅動的聊天機器人，旨在為使用者提供準確且可靠的醫療資訊。Med-Bot 利用進階函式庫和框架，例如 PyTorch、Chromadb、Langchain 和 Autogptq，建構來處理醫療保健環境中自然語言理解的複雜性。整合了 Llama 輔助資料處理和 AutoGPT-Q，在處理和回應基於醫學文獻 PDF 的查詢時提供了增強的效能，確保使用者收到精確且可信賴的資訊。本研究詳細說明了開發 Med-Bot 所採用的方法，並評估其在傳播醫療保健資訊方面的有效性。

##### **On the Limits of Language Generation: Trade-Offs Between Hallucination and Mode Collapse**
2411.09642v1 by Alkis Kalavasis, Anay Mehrotra, Grigoris Velegkas

Specifying all desirable properties of a language model is challenging, but
certain requirements seem essential. Given samples from an unknown language,
the trained model should produce valid strings not seen in training and be
expressive enough to capture the language's full richness. Otherwise,
outputting invalid strings constitutes "hallucination," and failing to capture
the full range leads to "mode collapse." We ask if a language model can meet
both requirements.
  We investigate this within a statistical language generation setting building
on Gold and Angluin. Here, the model receives random samples from a
distribution over an unknown language K, which belongs to a possibly infinite
collection of languages. The goal is to generate unseen strings from K. We say
the model generates from K with consistency and breadth if, as training size
increases, its output converges to all unseen strings in K.
  Kleinberg and Mullainathan [KM24] asked if consistency and breadth in
language generation are possible. We answer this negatively: for a large class
of language models, including next-token prediction models, this is impossible
for most collections of candidate languages. This contrasts with [KM24]'s
result, showing consistent generation without breadth is possible for any
countable collection of languages. Our finding highlights that generation with
breadth fundamentally differs from generation without breadth.
  As a byproduct, we establish near-tight bounds on the number of samples
needed for generation with or without breadth.
  Finally, our results offer hope: consistent generation with breadth is
achievable for any countable collection of languages when negative examples
(strings outside K) are available alongside positive ones. This suggests that
post-training feedback, which encodes negative examples, can be crucial in
reducing hallucinations while limiting mode collapse.

摘要：<paragraph>指定語言模型的所有理想屬性具有挑戰性，但某些需求似乎是必要的。給定來自未知語言的範例，訓練過的模型應產生訓練中未見的有效字串，並且足夠具有表現力以捕捉語言的豐富性。否則，輸出無效字串構成「幻覺」，而無法捕捉完整範圍則導致「模式崩潰」。我們詢問語言模型是否可以滿足這兩個需求。
我們在建立在 Gold 和 Angluin 的統計語言生成設定中研究這一點。在此，模型從未知語言 K 的分布中接收隨機範例，它屬於可能無限的語言集合。目標是從 K 生成未見的字串。我們說模型從 K 生成具有一致性和廣度，如果隨著訓練大小的增加，其輸出收斂到 K 中所有未見的字串。
Kleinberg 和 Mullainathan [KM24] 詢問語言生成中的一致性和廣度是否可能。我們回答是否定的：對於包含下一個符號預測模型在內的大類語言模型，對於大多數候選語言集合來說，這是不可能的。這與 [KM24] 的結果形成對比，後者表明對於任何可數的語言集合，一致生成而沒有廣度是可能的。我們的發現強調，具有廣度的生成在根本上與沒有廣度的生成不同。
作為副產品，我們建立了具有或沒有廣度生成所需的範例數量的近似緊密界限。
最後，我們的結果提供了希望：當負面範例（K 之外的字串）與正面範例一起可用時，對於任何可數的語言集合，具有一致性和廣度的生成是可以實現的。這表明編碼負面範例的訓練後回饋在減少幻覺的同時限制模式崩潰方面至關重要。</paragraph>

##### **PTR: Precision-Driven Tool Recommendation for Large Language Models**
2411.09613v1 by Hang Gao, Yongfeng Zhang

By augmenting Large Language Models (LLMs) with external tools, their
capacity to solve complex problems has been significantly enhanced. However,
despite ongoing advancements in the parsing capabilities of LLMs, incorporating
all available tools simultaneously in the prompt remains impractical due to the
vast number of external tools. Consequently, it is essential to provide LLMs
with a precise set of tools tailored to the specific task, considering both
quantity and quality. Current tool retrieval methods primarily focus on
refining the ranking list of tools and directly packaging a fixed number of
top-ranked tools as the tool set. However, these approaches often fail to equip
LLMs with the optimal set of tools prior to execution, since the optimal number
of tools for different tasks could be different, resulting in inefficiencies
such as redundant or unsuitable tools, which impede immediate access to the
most relevant tools. This paper addresses the challenge of recommending precise
toolsets for LLMs. We introduce the problem of tool recommendation, define its
scope, and propose a novel Precision-driven Tool Recommendation (PTR) approach.
PTR captures an initial, concise set of tools by leveraging historical tool
bundle usage and dynamically adjusts the tool set by performing tool matching,
culminating in a multi-view-based tool addition. Additionally, we present a new
dataset, RecTools, and a metric, TRACC, designed to evaluate the effectiveness
of tool recommendation for LLMs. We further validate our design choices through
comprehensive experiments, demonstrating promising accuracy across two open
benchmarks and our RecTools dataset.

摘要：<paragraph>透過擴充大型語言模型 (LLM) 的外部工具，其解決複雜問題的能力已大幅提升。然而，儘管 LLM 的解析能力持續進步，但由於外部工具數量龐大，因此在提示中同時納入所有可用工具仍不切實際。因此，必須為 LLM 提供一組針對特定任務量身打造的精確工具，同時考量數量和品質。目前的工具檢索方法主要專注於精進工具的排名清單，並直接封裝固定數量的排名最高工具作為工具組。然而，這些方法通常無法在執行前為 LLM 提供最佳工具組，因為不同任務的最佳工具數量可能不同，這會導致重複或不適用的工具等低效率，進而阻礙立即存取最相關的工具。本文探討了為 LLM 推薦精確工具組的挑戰。我們引入了工具推薦問題，定義其範圍，並提出了一種創新的精準驅動工具推薦 (PTR) 方法。PTR 透過利用歷史工具組合使用率擷取一組初始的簡潔工具，並透過執行工具比對動態調整工具組，最終形成基於多視角的工具新增。此外，我們提出了新的資料集 RecTools 和指標 TRACC，旨在評估 LLM 工具推薦的有效性。我們進一步透過全面的實驗驗證我們的設計選擇，證明了在兩個開放基准和我們的 RecTools 資料集中的準確性。</paragraph>

##### **The Moral Foundations Weibo Corpus**
2411.09612v1 by Renjie Cao, Miaoyan Hu, Jiahan Wei, Baha Ihnaini

Moral sentiments expressed in natural language significantly influence both
online and offline environments, shaping behavioral styles and interaction
patterns, including social media selfpresentation, cyberbullying, adherence to
social norms, and ethical decision-making. To effectively measure moral
sentiments in natural language processing texts, it is crucial to utilize
large, annotated datasets that provide nuanced understanding for accurate
analysis and modeltraining. However, existing corpora, while valuable, often
face linguistic limitations. To address this gap in the Chinese language
domain,we introduce the Moral Foundation Weibo Corpus. This corpus consists of
25,671 Chinese comments on Weibo, encompassing six diverse topic areas. Each
comment is manually annotated by at least three systematically trained
annotators based on ten moral categories derived from a grounded theory of
morality. To assess annotator reliability, we present the kappa testresults, a
gold standard for measuring consistency. Additionally, we apply several the
latest large language models to supplement the manual annotations, conducting
analytical experiments to compare their performance and report baseline results
for moral sentiment classification.

摘要：自然語言中表達的道德情緒顯著影響線上和線下環境，形塑行為風格和互動模式，包括社群媒體自我呈現、網路霸凌、遵守社會規範和道德決策制定。為有效衡量自然語言處理文字中的道德情緒，利用大型標註資料集對於提供細緻的理解以進行精確的分析和模型訓練至關重要。然而，現有的語料庫雖然有價值，但經常面臨語言限制。為了解決中文領域的這個差距，我們引入了道德基礎微博語料庫。此語料庫包含 25,671 則微博中文留言，涵蓋六個不同的主題領域。每則留言都由至少三位經過系統訓練的標註者根據源自道德基礎理論的十個道德類別進行手動標註。為了評估標註者可靠性，我們呈現 kappa 檢定結果，這是衡量一致性的黃金標準。此外，我們應用幾個最新的大型語言模型來補充手動標註，進行分析實驗以比較它們的效能，並報告道德情緒分類的基準結果。

##### **Initial Nugget Evaluation Results for the TREC 2024 RAG Track with the AutoNuggetizer Framework**
2411.09607v1 by Ronak Pradeep, Nandan Thakur, Shivani Upadhyay, Daniel Campos, Nick Craswell, Jimmy Lin

This report provides an initial look at partial results from the TREC 2024
Retrieval-Augmented Generation (RAG) Track. We have identified RAG evaluation
as a barrier to continued progress in information access (and more broadly,
natural language processing and artificial intelligence), and it is our hope
that we can contribute to tackling the many challenges in this space. The
central hypothesis we explore in this work is that the nugget evaluation
methodology, originally developed for the TREC Question Answering Track in
2003, provides a solid foundation for evaluating RAG systems. As such, our
efforts have focused on "refactoring" this methodology, specifically applying
large language models to both automatically create nuggets and to automatically
assign nuggets to system answers. We call this the AutoNuggetizer framework.
Within the TREC setup, we are able to calibrate our fully automatic process
against a manual process whereby nuggets are created by human assessors
semi-manually and then assigned manually to system answers. Based on initial
results across 21 topics from 45 runs, we observe a strong correlation between
scores derived from a fully automatic nugget evaluation and a (mostly) manual
nugget evaluation by human assessors. This suggests that our fully automatic
evaluation process can be used to guide future iterations of RAG systems.

摘要：這份報告提供了 TREC 2024 檢索增強生成 (RAG) 軌道的部分初始結果。我們已將 RAG 評估確定為資訊存取（更廣泛地說，自然語言處理和人工智慧）持續進展的障礙，我們希望我們能為解決這個領域的許多挑戰做出貢獻。我們在這項工作中探討的核心假設是，最初為 2003 年 TREC 問題解答軌道開發的核塊評估方法，可作為評估 RAG 系統的堅實基礎。因此，我們的努力專注於「重構」此方法，特別是將大型語言模型應用於自動建立核塊和自動將核塊指定給系統答案。我們稱之為 AutoNuggetizer 架構。在 TREC 設定中，我們能夠根據人工評估員半自動建立核塊，然後手動指定給系統答案的手動流程，校準我們的全自動流程。根據 45 次執行中 21 個主題的初始結果，我們觀察到從全自動核塊評估衍生的分數與人工評估員的（大多數）手動核塊評估之間存在強烈的相關性。這表明我們全自動評估流程可用於指導 RAG 系統的未來迭代。

##### **Local-Global Attention: An Adaptive Mechanism for Multi-Scale Feature Integration**
2411.09604v1 by Yifan Shao

In recent years, attention mechanisms have significantly enhanced the
performance of object detection by focusing on key feature information.
However, prevalent methods still encounter difficulties in effectively
balancing local and global features. This imbalance hampers their ability to
capture both fine-grained details and broader contextual information-two
critical elements for achieving accurate object detection.To address these
challenges, we propose a novel attention mechanism, termed Local-Global
Attention, which is designed to better integrate both local and global
contextual features. Specifically, our approach combines multi-scale
convolutions with positional encoding, enabling the model to focus on local
details while concurrently considering the broader global context.
Additionally, we introduce a learnable parameters, which allow the model to
dynamically adjust the relative importance of local and global attention,
depending on the specific requirements of the task, thereby optimizing feature
representations across multiple scales.We have thoroughly evaluated the
Local-Global Attention mechanism on several widely used object detection and
classification datasets. Our experimental results demonstrate that this
approach significantly enhances the detection of objects at various scales,
with particularly strong performance on multi-class and small object detection
tasks. In comparison to existing attention mechanisms, Local-Global Attention
consistently outperforms them across several key metrics, all while maintaining
computational efficiency.

摘要：近年来，注意力机制通过关注关键特征信息显著提升了目标检测的性能。然而，流行的方法在有效平衡局部和全局特征方面仍然遇到困难。这种不平衡阻碍了它们同时捕捉细粒度细节和更广泛的上下文信息的能力，而这两者是实现准确目标检测的关键要素。为了应对这些挑战，我们提出了一种新颖的注意力机制，称为局部-全局注意力，旨在更好地整合局部和全局上下文特征。具体而言，我们的方法将多分辨率卷积与位置编码相结合，使模型能够专注于局部细节，同时考虑更广泛的全局上下文。此外，我们引入了一个可学习的参数，允许模型根据任务的具体要求动态调整局部和全局注意力的相对重要性，从而优化跨多个尺度的特征表示。我们在几个广泛使用目标检测和分类数据集上彻底评估了局部-全局注意力机制。我们的实验结果表明，这种方法显著增强了对不同尺度目标的检测，在多类和小目标检测任务上的表现尤其出色。与现有的注意力机制相比，局部-全局注意力在几个关键指标上始终优于它们，同时保持了计算效率。

##### **Accelerating Knowledge Graph and Ontology Engineering with Large Language Models**
2411.09601v1 by Cogan Shimizu, Pascal Hitzler

Large Language Models bear the promise of significant acceleration of key
Knowledge Graph and Ontology Engineering tasks, including ontology modeling,
extension, modification, population, alignment, as well as entity
disambiguation. We lay out LLM-based Knowledge Graph and Ontology Engineering
as a new and coming area of research, and argue that modular approaches to
ontologies will be of central importance.

摘要：大型語言模型承諾大幅加速關鍵知識圖譜和本体工程任務，包括本体建模、擴充、修改、填充、比對以及實體消歧。我們將 LLM 為基礎的知識圖譜和本体工程規劃為一個新興的研究領域，並主張模組化本体方法將至關重要。

##### **LLaMA-Mesh: Unifying 3D Mesh Generation with Language Models**
2411.09595v1 by Zhengyi Wang, Jonathan Lorraine, Yikai Wang, Hang Su, Jun Zhu, Sanja Fidler, Xiaohui Zeng

This work explores expanding the capabilities of large language models (LLMs)
pretrained on text to generate 3D meshes within a unified model. This offers
key advantages of (1) leveraging spatial knowledge already embedded in LLMs,
derived from textual sources like 3D tutorials, and (2) enabling conversational
3D generation and mesh understanding. A primary challenge is effectively
tokenizing 3D mesh data into discrete tokens that LLMs can process seamlessly.
To address this, we introduce LLaMA-Mesh, a novel approach that represents the
vertex coordinates and face definitions of 3D meshes as plain text, allowing
direct integration with LLMs without expanding the vocabulary. We construct a
supervised fine-tuning (SFT) dataset enabling pretrained LLMs to (1) generate
3D meshes from text prompts, (2) produce interleaved text and 3D mesh outputs
as required, and (3) understand and interpret 3D meshes. Our work is the first
to demonstrate that LLMs can be fine-tuned to acquire complex spatial knowledge
for 3D mesh generation in a text-based format, effectively unifying the 3D and
text modalities. LLaMA-Mesh achieves mesh generation quality on par with models
trained from scratch while maintaining strong text generation performance.

摘要：本研究探索了擴展大型語言模型 (LLM) 的能力，這些模型經過文字預訓練，可以在統一模型中生成 3D 網格。這提供了下列主要優點：(1) 充分利用 LLM 中已嵌入的空間知識，這些知識來自 3D 教學等文字來源，以及 (2) 支援對話式 3D 生成和網格理解。一個主要的挑戰是有效地將 3D 網格資料代幣化為 LLM 可以無縫處理的離散代幣。為了解決這個問題，我們引入了 LLaMA-Mesh，這是一種新方法，它將 3D 網格的頂點座標和面部定義表示為純文字，允許直接與 LLM 整合，而無需擴充詞彙。我們建構了一個監督微調 (SFT) 資料集，讓預訓練的 LLM 能夠 (1) 從文字提示中生成 3D 網格，(2) 根據需要產生交錯的文字和 3D 網格輸出，以及 (3) 理解和解釋 3D 網格。我們的研究首次證明，LLM 可以微調以獲取複雜的空間知識，用於以文字為基礎的格式進行 3D 網格生成，有效地統一了 3D 和文字模式。LLaMA-Mesh 達到了與從頭開始訓練的模型同等的網格生成品質，同時保持強大的文字生成效能。

##### **Adopting RAG for LLM-Aided Future Vehicle Design**
2411.09590v1 by Vahid Zolfaghari, Nenad Petrovic, Fengjunjie Pan, Krzysztof Lebioda, Alois Knoll

In this paper, we explore the integration of Large Language Models (LLMs)
with Retrieval-Augmented Generation (RAG) to enhance automated design and
software development in the automotive industry. We present two case studies: a
standardization compliance chatbot and a design copilot, both utilizing RAG to
provide accurate, context-aware responses. We evaluate four LLMs-GPT-4o,
LLAMA3, Mistral, and Mixtral -- comparing their answering accuracy and
execution time. Our results demonstrate that while GPT-4 offers superior
performance, LLAMA3 and Mistral also show promising capabilities for local
deployment, addressing data privacy concerns in automotive applications. This
study highlights the potential of RAG-augmented LLMs in improving design
workflows and compliance in automotive engineering.

摘要：在本文中，我們探討將大型語言模型 (LLM) 與檢索增強生成 (RAG) 整合，以增強汽車產業中的自動化設計和軟體開發。我們提出兩個案例研究：一個標準化合規聊天機器人和一個設計副駕駛，兩者都利用 RAG 來提供準確且符合脈絡的回應。我們評估了四個 LLM-GPT-4o、LLAMA3、Mistral 和 Mixtral，比較它們的回答準確度和執行時間。我們的結果表明，儘管 GPT-4 提供了卓越的效能，但 LLAMA3 和 Mistral 也顯示出有望用於本地部署的能力，解決了汽車應用中的資料隱私問題。這項研究強調了 RAG 增強的 LLM 在改善汽車工程中的設計工作流程和合規性的潛力。

##### **BabyLM Challenge: Exploring the Effect of Variation Sets on Language Model Training Efficiency**
2411.09587v1 by Akari Haga, Akiyo Fukatsu, Miyu Oba, Arianna Bisazza, Yohei Oseki

While current large language models have achieved a remarkable success, their
data efficiency remains a challenge to overcome. Recently it has been suggested
that child-directed speech (CDS) can improve training data efficiency of modern
language models based on Transformer neural networks. However, it is not yet
understood which specific properties of CDS are effective for training these
models. In the context of the BabyLM Challenge, we focus on Variation Sets
(VSs), sets of consecutive utterances expressing a similar intent with slightly
different words and structures, which are ubiquitous in CDS. To assess the
impact of VSs on training data efficiency, we augment CDS data with different
proportions of artificial VSs and use these datasets to train an
auto-regressive model, GPT-2. We find that the best proportion of VSs depends
on the evaluation benchmark: BLiMP and GLUE scores benefit from the presence of
VSs, but EWOK scores do not. Additionally, the results vary depending on
multiple factors such as the number of epochs and the order of utterance
presentation. Taken together, these findings suggest that VSs can have a
beneficial influence on language models, while leaving room for further
investigation.

摘要：儘管目前的大語言模型已取得顯著的成功，但其資料效率仍是一項待克服的挑戰。最近有人提出，以兒童為對象的語言（CDS）可以提升基於 Transformer 神經網路的現代語言模型的訓練資料效率。然而，目前尚未了解 CDS 的哪些特定屬性有助於訓練這些模型。在 BabyLM 挑戰的背景下，我們專注於變異集 (VS)，即表達類似意圖的一組連續話語，其字詞和結構略有不同，這在 CDS 中無所不在。為了評估 VS 對訓練資料效率的影響，我們使用不同比例的人工 VS 擴充 CDS 資料，並使用這些資料集訓練自迴歸模型 GPT-2。我們發現 VS 的最佳比例取決於評估基準：BLiMP 和 GLUE 分數受益於 VS 的存在，但 EWOK 分數則不然。此外，結果會因多重因素而異，例如時代數和話語呈現順序。綜合而言，這些發現表明 VS 可能對語言模型產生有益的影響，同時也為進一步的研究留下了空間。

##### **Software Performance Engineering for Foundation Model-Powered Software (FMware)**
2411.09580v1 by Haoxiang Zhang, Shi Chang, Arthur Leung, Kishanthan Thangarajah, Boyuan Chen, Hanan Lutfiyya, Ahmed E. Hassan

The rise of Foundation Models (FMs) like Large Language Models (LLMs) is
revolutionizing software development. Despite the impressive prototypes,
transforming FMware into production-ready products demands complex engineering
across various domains. A critical but overlooked aspect is performance
engineering, which aims at ensuring FMware meets performance goals such as
throughput and latency to avoid user dissatisfaction and financial loss. Often,
performance considerations are an afterthought, leading to costly optimization
efforts post-deployment. FMware's high computational resource demands highlight
the need for efficient hardware use. Continuous performance engineering is
essential to prevent degradation. This paper highlights the significance of
Software Performance Engineering (SPE) in FMware, identifying four key
challenges: cognitive architecture design, communication protocols, tuning and
optimization, and deployment. These challenges are based on literature surveys
and experiences from developing an in-house FMware system. We discuss problems,
current practices, and innovative paths for the software engineering community.

摘要：大型語言模型 (LLM) 等基礎模型 (FM) 的興起正在革新軟體開發。儘管有令人印象深刻的原型，但要將 FMware 轉變為可供生產的產品，需要跨越不同領域的複雜工程。一個關鍵但被忽視的面向是效能工程，其目標在於確保 FMware 符合效能目標，例如吞吐量和延遲，以避免使用者不滿意和財務損失。效能考量通常是事後才想到，導致部署後進行代價高昂的最佳化工作。FMware 對高運算資源的需求凸顯了對高效硬體使用的需求。持續的效能工程對於防止效能下降至關重要。本文強調了軟體效能工程 (SPE) 在 FMware 中的重要性，並找出四項主要挑戰：認知架構設計、通訊協定、調整和最佳化，以及部署。這些挑戰基於文獻調查和開發內部 FMware 系統的經驗。我們討論了軟體工程社群的問題、現行做法和創新途徑。

##### **Automating Reformulation of Essence Specifications via Graph Rewriting**
2411.09576v1 by Ian Miguel, András Z. Salamon, Christopher Stone

Formulating an effective constraint model of a parameterised problem class is
crucial to the efficiency with which instances of the class can subsequently be
solved. It is difficult to know beforehand which of a set of candidate models
will perform best in practice. This paper presents a system that employs graph
rewriting to reformulate an input model for improved performance automatically.
By situating our work in the Essence abstract constraint specification
language, we can use the structure in its high level variable types to trigger
rewrites directly. We implement our system via rewrite rules expressed in the
Graph Programs 2 language, applied to the abstract syntax tree of an input
specification. We show how to automatically translate the solution of the
reformulated problem into a solution of the original problem for verification
and presentation. We demonstrate the efficacy of our system with a detailed
case study.

摘要：制定一個參數化問題類別的有效約束模型對於隨後求解該類別的實例的效率至關重要。事先很難知道一組候選模型中哪一個在實務上表現最佳。本文提出一個系統，採用圖形重寫來自動重新制定輸入模型以改善效能。透過將我們的工作置於 Essence 抽象約束規範語言中，我們可以使用其高層級變數類型中的結構來直接觸發重寫。我們透過以 Graph Programs 2 語言表示的重寫規則來實作我們的系統，應用於輸入規範的抽象語法樹。我們展示如何自動將重新制定問題的解法轉換為原始問題的解法，以進行驗證和呈現。我們透過詳細的個案研究來展示我們系統的效能。

##### **Piecing It All Together: Verifying Multi-Hop Multimodal Claims**
2411.09547v1 by Haoran Wang, Aman Rangapur, Xiongxiao Xu, Yueqing Liang, Haroon Gharwi, Carl Yang, Kai Shu

Existing claim verification datasets often do not require systems to perform
complex reasoning or effectively interpret multimodal evidence. To address
this, we introduce a new task: multi-hop multimodal claim verification. This
task challenges models to reason over multiple pieces of evidence from diverse
sources, including text, images, and tables, and determine whether the combined
multimodal evidence supports or refutes a given claim. To study this task, we
construct MMCV, a large-scale dataset comprising 16k multi-hop claims paired
with multimodal evidence, generated and refined using large language models,
with additional input from human feedback. We show that MMCV is challenging
even for the latest state-of-the-art multimodal large language models,
especially as the number of reasoning hops increases. Additionally, we
establish a human performance benchmark on a subset of MMCV. We hope this
dataset and its evaluation task will encourage future research in multimodal
multi-hop claim verification.

摘要：現有的聲明驗證資料集通常不需要系統執行複雜的推理或有效地詮釋多模態證據。為了解決此問題，我們引入一個新任務：多跳多模態聲明驗證。此任務挑戰模型對來自不同來源（包括文字、圖像和表格）的多個證據進行推理，並確定組合的多模態證據是否支持或反駁給定的聲明。為了研究此任務，我們建構了 MMCV，一個包含 16k 個多跳聲明的大規模資料集，與多模態證據配對，使用大型語言模型生成和優化，並加入了人類回饋的額外輸入。我們證明 MMCV 即使對於最新的最先進多模態大型語言模型來說也很具有挑戰性，特別是隨著推理跳數的增加。此外，我們在 MMCV 的子集上建立了人類效能基準。我們希望此資料集及其評估任務將鼓勵未來在多模態多跳聲明驗證方面的研究。

##### **Prompting the Unseen: Detecting Hidden Backdoors in Black-Box Models**
2411.09540v1 by Zi-Xuan Huang, Jia-Wei Chen, Zhi-Peng Zhang, Chia-Mu Yu

Visual prompting (VP) is a new technique that adapts well-trained frozen
models for source domain tasks to target domain tasks. This study examines VP's
benefits for black-box model-level backdoor detection. The visual prompt in VP
maps class subspaces between source and target domains. We identify a
misalignment, termed class subspace inconsistency, between clean and poisoned
datasets. Based on this, we introduce \textsc{BProm}, a black-box model-level
detection method to identify backdoors in suspicious models, if any.
\textsc{BProm} leverages the low classification accuracy of prompted models
when backdoors are present. Extensive experiments confirm \textsc{BProm}'s
effectiveness.

摘要：視覺提示 (VP) 是一種新技術，可以將訓練有素的凍結模型從來源域任務適應到目標域任務。本研究探討了 VP 對黑盒模型級後門檢測的優點。VP 中的視覺提示會對來源和目標域之間的類子空間進行對應。我們發現了一個錯位，稱為類子空間不一致，存在於乾淨和中毒的資料集之間。基於此，我們引入了 \textsc{BProm}，這是一種黑盒模型級檢測方法，用於識別可疑模型中的後門（如果有）。\textsc{BProm} 利用了當後門存在時提示模型的低分類準確度。大量的實驗驗證了 \textsc{BProm} 的有效性。

##### **A Practical Guide to Fine-tuning Language Models with Limited Data**
2411.09539v1 by Márton Szép, Daniel Rueckert, Rüdiger von Eisenhart-Rothe, Florian Hinterwimmer

Employing pre-trained Large Language Models (LLMs) has become the de facto
standard in Natural Language Processing (NLP) despite their extensive data
requirements. Motivated by the recent surge in research focused on training
LLMs with limited data, particularly in low-resource domains and languages,
this paper surveys recent transfer learning approaches to optimize model
performance in downstream tasks where data is scarce. We first address initial
and continued pre-training strategies to better leverage prior knowledge in
unseen domains and languages. We then examine how to maximize the utility of
limited data during fine-tuning and few-shot learning. The final section takes
a task-specific perspective, reviewing models and methods suited for different
levels of data scarcity. Our goal is to provide practitioners with practical
guidelines for overcoming the challenges posed by constrained data while also
highlighting promising directions for future research.

摘要：採用預先訓練的大語言模型 (LLM) 已成為自然語言處理 (NLP) 的實際標準，儘管其資料需求廣泛。在專注於以有限資料訓練 LLM 的研究最近激增的推動下，特別是在低資源領域和語言中，本文調查了最近的遷移學習方法，以最佳化資料稀少的下游任務中的模型效能。我們首先探討最初和持續的預訓練策略，以在未見領域和語言中更好地運用先前的知識。然後我們探討如何在微調和少次學習期間最大化有限資料的效用。最後一節採用特定任務觀點，檢視適合不同資料稀少程度的模型和方法。我們的目標是為實務工作者提供克服受限資料所帶來的挑戰的實用指南，同時也強調未來研究的有希望的方向。

##### **Navigating the Risks: A Survey of Security, Privacy, and Ethics Threats in LLM-Based Agents**
2411.09523v1 by Yuyou Gan, Yong Yang, Zhe Ma, Ping He, Rui Zeng, Yiming Wang, Qingming Li, Chunyi Zhou, Songze Li, Ting Wang, Yunjun Gao, Yingcai Wu, Shouling Ji

With the continuous development of large language models (LLMs),
transformer-based models have made groundbreaking advances in numerous natural
language processing (NLP) tasks, leading to the emergence of a series of agents
that use LLMs as their control hub. While LLMs have achieved success in various
tasks, they face numerous security and privacy threats, which become even more
severe in the agent scenarios. To enhance the reliability of LLM-based
applications, a range of research has emerged to assess and mitigate these
risks from different perspectives.
  To help researchers gain a comprehensive understanding of various risks, this
survey collects and analyzes the different threats faced by these agents. To
address the challenges posed by previous taxonomies in handling cross-module
and cross-stage threats, we propose a novel taxonomy framework based on the
sources and impacts. Additionally, we identify six key features of LLM-based
agents, based on which we summarize the current research progress and analyze
their limitations. Subsequently, we select four representative agents as case
studies to analyze the risks they may face in practical use. Finally, based on
the aforementioned analyses, we propose future research directions from the
perspectives of data, methodology, and policy, respectively.

摘要：隨著大型語言模型 (LLM) 的持續發展，
基於 Transformer 的模型在眾多自然語言處理 (NLP) 任務中取得了突破性的進展，導致了一系列使用 LLM 作為其控制中心的主體出現。儘管 LLM 在各種任務中取得了成功，但它們面臨著眾多的安全和隱私威脅，在主體場景中變得更加嚴重。為了增強基於 LLM 的應用程式的可靠性，出現了一系列研究來評估和減輕這些風險，從不同的角度來看。
為了幫助研究人員全面了解各種風險，本調查收集並分析了這些主體面臨的不同威脅。為了應對先前分類法在處理跨模組和跨階段威脅時所帶來的挑戰，我們基於來源和影響提出了新的分類法框架。此外，我們根據 LLM 基於主體的六個關鍵特徵，總結了當前的研究進展並分析了其局限性。隨後，我們選擇了四個有代表性的主體作為案例研究，以分析它們在實際使用中可能面臨的風險。最後，基於上述分析，我們分別從資料、方法和政策的角度提出了未來的研究方向。

##### **Communication Compression for Tensor Parallel LLM Inference**
2411.09510v1 by Jan Hansen-Palmus, Michael Truong-Le, Oliver Hausdörfer, Alok Verma

Large Language Models (LLMs) have pushed the frontier of artificial
intelligence but are comprised of hundreds of billions of parameters and
operations. For faster inference latency, LLMs are deployed on multiple
hardware accelerators through various Model Parallelism strategies. Our paper
looks into the details on one such strategy - Tensor Parallel - and proposes to
reduce latency by compressing inter-accelerator communication. We leverage fine
grained quantization techniques to compress selected activations by 3.5 - 4.5x.
Our proposed method leads up to 2x reduction of time-to-first-token (TTFT) with
negligible model performance degradation.

摘要：大型語言模型 (LLM) 已推進了人工智慧的疆界，但由數百億個參數和運算組成。為了更快的推論延遲，LLM 透過各種模型平行策略部署在多個硬體加速器上。我們的論文探討了其中一種策略 - 張量平行 - 的詳細資訊，並提出透過壓縮加速器間的通訊來降低延遲。我們利用細緻的量化技術將所選的激活壓縮 3.5 - 4.5 倍。我們提出的方法可將首次標記時間 (TTFT) 減少多達 2 倍，且模型效能幾乎沒有下降。

##### **Toward a Cohesive AI and Simulation Software Ecosystem for Scientific Innovation**
2411.09507v1 by Michael A. Heroux, Sameer Shende, Lois Curfman McInnes, Todd Gamblin, James M. Willenbring

In this paper, we discuss the need for an integrated software stack that
unites artificial intelligence (AI) and modeling and simulation (ModSim) tools
to advance scientific discovery. The authors advocate for a unified AI/ModSim
software ecosystem that ensures compatibility across a wide range of software
on diverse high-performance computing systems, promoting ease of deployment,
version management, and binary distribution. Key challenges highlighted include
balancing the distinct needs of AI and ModSim, especially in terms of software
build practices, dependency management, and compatibility. The document
underscores the importance of continuous integration, community-driven
stewardship, and collaboration with the Department of Energy (DOE) to develop a
portable and cohesive scientific software ecosystem. Recommendations focus on
supporting standardized environments through initiatives like the Extreme-scale
Scientific Software Stack (E4S) and Spack to foster interdisciplinary
innovation and facilitate new scientific advancements.

摘要：在本文中，我們討論了整合軟體堆疊的需求，它結合了人工智慧 (AI) 和建模與模擬 (ModSim) 工具，以推進科學發現。作者提倡統一的 AI/ModSim 軟體生態系統，以確保在各種軟體中相容性，涵蓋多樣化的高效能運算系統，促進部署、版本管理和二進位制發行。重點挑戰包括平衡 AI 和 ModSim 的不同需求，特別是在軟體建置實務、依賴管理和相容性方面。本文強調持續整合、社群驅動管理和與能源部 (DOE) 合作，以開發可攜式且有凝聚力的科學軟體生態系統。建議重點在於透過極端規模科學軟體堆疊 (E4S) 和 Spack 等計畫支援標準化環境，以促進跨領域創新並促進新的科學進展。

##### **MM-Eval: A Hierarchical Benchmark for Modern Mongolian Evaluation in LLMs**
2411.09492v1 by Mengyuan Zhang, Ruihui Wang, Bo Xia, Yuan Sun, Xiaobing Zhao

Large language models (LLMs) excel in high-resource languages but face
notable challenges in low-resource languages like Mongolian. This paper
addresses these challenges by categorizing capabilities into language abilities
(syntax and semantics) and cognitive abilities (knowledge and reasoning). To
systematically evaluate these areas, we developed MM-Eval, a specialized
dataset based on Modern Mongolian Language Textbook I and enriched with WebQSP
and MGSM datasets.
  Preliminary experiments on models including Qwen2-7B-Instruct, GLM4-9b-chat,
Llama3.1-8B-Instruct, GPT-4, and DeepseekV2.5 revealed that: 1) all models
performed better on syntactic tasks than semantic tasks, highlighting a gap in
deeper language understanding; and 2) knowledge tasks showed a moderate
decline, suggesting that models can transfer general knowledge from
high-resource to low-resource contexts.
  The release of MM-Eval, comprising 569 syntax, 677 semantics, 344 knowledge,
and 250 reasoning tasks, offers valuable insights for advancing NLP and LLMs in
low-resource languages like Mongolian. The dataset is available at
https://github.com/joenahm/MM-Eval.

摘要：大型語言模型 (LLM) 在資源豐富的語言中表現出色，但在蒙古語等資源貧乏的語言中卻面臨顯著的挑戰。本文透過將能力分類為語言能力（語法和語意）和認知能力（知識和推理），來解決這些挑戰。為了系統性地評估這些領域，我們開發了 MM-Eval，這是一個基於現代蒙古語教科書 I 編制的專業數據集，並透過 WebQSP 和 MGSM 數據集進行擴充。
針對包括 Qwen2-7B-Instruct、GLM4-9b-chat、Llama3.1-8B-Instruct、GPT-4 和 DeepseekV2.5 在內的模型進行的初步實驗顯示：1) 所有模型在語法任務上的表現都優於語意任務，突顯了在更深入的語言理解方面的差距；以及 2) 知識任務表現出適度的下降，表明模型可以將一般知識從資源豐富的環境轉移到資源貧乏的環境。
MM-Eval 的發布包含 569 個語法、677 個語意、344 個知識和 250 個推理任務，為在蒙古語等資源貧乏的語言中推進 NLP 和 LLM 提供了寶貴的見解。該數據集可在 https://github.com/joenahm/MM-Eval 取得。

##### **ResidualDroppath: Enhancing Feature Reuse over Residual Connections**
2411.09475v1 by Sejik Park

Residual connections are one of the most important components in neural
network architectures for mitigating the vanishing gradient problem and
facilitating the training of much deeper networks. One possible explanation for
how residual connections aid deeper network training is by promoting feature
reuse. However, we identify and analyze the limitations of feature reuse with
vanilla residual connections. To address these limitations, we propose
modifications in training methods. Specifically, we provide an additional
opportunity for the model to learn feature reuse with residual connections
through two types of iterations during training. The first type of iteration
involves using droppath, which enforces feature reuse by randomly dropping a
subset of layers. The second type of iteration focuses on training the dropped
parts of the model while freezing the undropped parts. As a result, the dropped
parts learn in a way that encourages feature reuse, as the model relies on the
undropped parts with feature reuse in mind. Overall, we demonstrated
performance improvements in models with residual connections for image
classification in certain cases.

摘要：殘差連接是神經網路架構中最重要的組成部分之一，用於減輕消失梯度問題，並促進更深層網路的訓練。一個可能的解釋是殘差連接如何幫助更深層網路訓練，即透過促進特徵重用。然而，我們找出並分析了香草殘差連接的特徵重用限制。為了解決這些限制，我們提出訓練方法的修改。具體來說，我們為模型提供了一個額外的機會，讓模型透過訓練期間的兩種反覆運算，使用殘差連接學習特徵重用。第一種類型的反覆運算涉及使用 droppath，它透過隨機捨棄一組層來強制執行特徵重用。第二種類型的反覆運算著重於訓練模型的捨棄部分，同時凍結未捨棄的部分。因此，捨棄的部分會以鼓勵特徵重用的方式學習，因為模型依賴於具有特徵重用概念的未捨棄部分。總的來說，我們證明了在某些情況下，具有殘差連接的模型在影像分類方面的效能有提升。

##### **An Explainable Attention Model for Cervical Precancer Risk Classification using Colposcopic Images**
2411.09469v1 by Smith K. Khare, Berit Bargum Booth, Victoria Blanes-Vidal, Lone Kjeld Petersen, Esmaeil S. Nadimi

Cervical cancer remains a major worldwide health issue, with early
identification and risk assessment playing critical roles in effective
preventive interventions. This paper presents the Cervix-AID-Net model for
cervical precancer risk classification. The study designs and evaluates the
proposed Cervix-AID-Net model based on patients colposcopy images. The model
comprises a Convolutional Block Attention Module (CBAM) and convolutional
layers that extract interpretable and representative features of colposcopic
images to distinguish high-risk and low-risk cervical precancer. In addition,
the proposed Cervix-AID-Net model integrates four explainable techniques,
namely gradient class activation maps, Local Interpretable Model-agnostic
Explanations, CartoonX, and pixel rate distortion explanation based on output
feature maps and input features. The evaluation using holdout and ten-fold
cross-validation techniques yielded a classification accuracy of 99.33\% and
99.81\%. The analysis revealed that CartoonX provides meticulous explanations
for the decision of the Cervix-AID-Net model due to its ability to provide the
relevant piece-wise smooth part of the image. The effect of Gaussian noise and
blur on the input shows that the performance remains unchanged up to Gaussian
noise of 3\% and blur of 10\%, while the performance reduces thereafter. A
comparison study of the proposed model's performance compared to other deep
learning approaches highlights the Cervix-AID-Net model's potential as a
supplemental tool for increasing the effectiveness of cervical precancer risk
assessment. The proposed method, which incorporates the CBAM and explainable
artificial integration, has the potential to influence cervical cancer
prevention and early detection, improving patient outcomes and lowering the
worldwide burden of this preventable disease.

摘要：子宮頸癌仍然是全球主要的健康議題，早期辨識和風險評估在有效的預防性干預措施中扮演著關鍵性的角色。本文提出子宮頸輔助網路模型，用於子宮頸癌前病變風險分類。本研究基於病患的陰道鏡影像設計並評估所提出的子宮頸輔助網路模型。該模型包含卷積區塊注意力模組 (CBAM) 和卷積層，用於萃取可解釋且具代表性的陰道鏡影像特徵，以區分高風險和低風險的子宮頸癌前病變。此外，所提出的子宮頸輔助網路模型整合了四種可解釋的技術，分別為梯度類別激活圖、局部可解釋模型不可知解釋、CartoonX 和基於輸出特徵圖和輸入特徵的像素率失真解釋。使用留存法和十倍交叉驗證技術進行評估，得到 99.33% 和 99.81% 的分類準確率。分析顯示，CartoonX 能夠提供影像中相關的分段平滑部分，因此能為子宮頸輔助網路模型的決策提供細緻的解釋。高斯噪聲和模糊對輸入的影響顯示，在高斯噪聲低於 3% 和模糊低於 10% 的情況下，效能保持不變，但之後效能便會下降。所提出的模型效能與其他深度學習方法的比較研究，突顯了子宮頸輔助網路模型作為補充工具的潛力，用於提高子宮頸癌前病變風險評估的有效性。所提出的方法結合了 CBAM 和可解釋的人工整合，有潛力影響子宮頸癌的預防和早期偵測，改善病患的預後並降低這種可預防疾病在全球的負擔。

##### **DiffRoad: Realistic and Diverse Road Scenario Generation for Autonomous Vehicle Testing**
2411.09451v1 by Junjie Zhou, Lin Wang, Qiang Meng, Xiaofan Wang

Generating realistic and diverse road scenarios is essential for autonomous
vehicle testing and validation. Nevertheless, owing to the complexity and
variability of real-world road environments, creating authentic and varied
scenarios for intelligent driving testing is challenging. In this paper, we
propose DiffRoad, a novel diffusion model designed to produce controllable and
high-fidelity 3D road scenarios. DiffRoad leverages the generative capabilities
of diffusion models to synthesize road layouts from white noise through an
inverse denoising process, preserving real-world spatial features. To enhance
the quality of generated scenarios, we design the Road-UNet architecture,
optimizing the balance between backbone and skip connections for high-realism
scenario generation. Furthermore, we introduce a road scenario evaluation
module that screens adequate and reasonable scenarios for intelligent driving
testing using two critical metrics: road continuity and road reasonableness.
Experimental results on multiple real-world datasets demonstrate DiffRoad's
ability to generate realistic and smooth road structures while maintaining the
original distribution. Additionally, the generated scenarios can be fully
automated into the OpenDRIVE format, facilitating generalized autonomous
vehicle simulation testing. DiffRoad provides a rich and diverse scenario
library for large-scale autonomous vehicle testing and offers valuable insights
for future infrastructure designs that are better suited for autonomous
vehicles.

摘要：<paragraph>產生逼真且多元的道路場景對於自動駕駛測試和驗證至關重要。然而，由於真實世界道路環境的複雜性和多變性，為智慧駕駛測試創造真實且多變的場景是一項挑戰。在本文中，我們提出 DiffRoad，一種新穎的擴散模型，旨在產生可控且高保真的 3D 道路場景。DiffRoad 利用擴散模型的生成能力，透過反向去噪過程從白噪音中合成道路佈局，保留真實世界的空間特徵。為了提高生成場景的品質，我們設計了 Road-UNet 架構，優化主幹和跳躍連接之間的平衡，以產生高度逼真的場景。此外，我們引入了一個道路場景評估模組，使用兩個關鍵指標：道路連續性和道路合理性，篩選出適用且合理的場景，以進行智慧駕駛測試。在多個真實世界資料集上的實驗結果證明了 DiffRoad 產生逼真且平滑道路結構的能力，同時維持原始分佈。此外，產生的場景可以完全自動化到 OpenDRIVE 格式，促進廣泛的自動駕駛模擬測試。DiffRoad 為大規模自動駕駛測試提供了豐富且多樣化的場景庫，並為更適合自動駕駛的未來基礎設施設計提供了寶貴的見解。</paragraph>

##### **Robot Tasks with Fuzzy Time Requirements from Natural Language Instructions**
2411.09436v1 by Sascha Sucker, Michael Neubauer, Dominik Henrich

Natural language allows robot programming to be accessible to everyone.
However, the inherent fuzziness in natural language poses challenges for
inflexible, traditional robot systems. We focus on instructions with fuzzy time
requirements (e.g., "start in a few minutes"). Building on previous robotics
research, we introduce fuzzy skills. These define an execution by the robot
with so-called satisfaction functions representing vague execution time
requirements. Such functions express a user's satisfaction over potential
starting times for skill execution. When the robot handles multiple fuzzy
skills, the satisfaction function provides a temporal tolerance window for
execution, thus, enabling optimal scheduling based on satisfaction. We
generalized such functions based on individual user expectations with a user
study. The participants rated their satisfaction with an instruction's
execution at various times. Our investigations reveal that trapezoidal
functions best approximate the users' satisfaction. Additionally, the results
suggest that users are more lenient if the execution is specified further into
the future.

摘要：自然語言讓機器人程式設計變得人人可及。
然而，自然語言中固有的模糊性對
僵化的傳統機器人系統構成挑戰。我們專注於具有模糊時間
需求的指令（例如，「幾分鐘後開始」）。建立在先前的機器人
研究上，我們引入了模糊技能。這些技能定義了機器人執行，
並使用稱為滿意度函數的東西來表示模糊的執行時間需求。
此類函數表達使用者對技能執行潛在開始時間的滿意度。
當機器人處理多個模糊技能時，滿意度函數會提供執行的時間
容忍範圍，因此，能夠根據滿意度進行最佳排程。我們
根據個人使用者的期望值，透過使用者研究概括了這些函數。
參與者對指令執行在不同時間的滿意度進行評分。我們的
調查顯示，梯形函數最能近似使用者的滿意度。此外，結果
顯示使用者對於較晚指定的執行較為寬容。

##### **Everyone deserves their voice to be heard: Analyzing Predictive Gender Bias in ASR Models Applied to Dutch Speech Data**
2411.09431v1 by Rik Raes, Saskia Lensink, Mykola Pechenizkiy

Recent research has shown that state-of-the-art (SotA) Automatic Speech
Recognition (ASR) systems, such as Whisper, often exhibit predictive biases
that disproportionately affect various demographic groups. This study focuses
on identifying the performance disparities of Whisper models on Dutch speech
data from the Common Voice dataset and the Dutch National Public Broadcasting
organisation. We analyzed the word error rate, character error rate and a
BERT-based semantic similarity across gender groups. We used the moral
framework of Weerts et al. (2022) to assess quality of service harms and
fairness, and to provide a nuanced discussion on the implications of these
biases, particularly for automatic subtitling. Our findings reveal substantial
disparities in word error rate (WER) among gender groups across all model
sizes, with bias identified through statistical testing.

摘要：最近的研究表明，最先进 (SotA) 的自动语音识别 (ASR) 系统（例如 Whisper）通常表现出预测偏差，对不同的人口群体造成不成比例的影响。本研究重点关注 Whisper 模型在来自 Common Voice 数据集和荷兰国家公共广播组织的荷兰语语音数据上的性能差异。我们分析了性别组之间的词错误率、字符错误率和基于 BERT 的语义相似性。我们使用了 Weerts 等人的道德框架。(2022) 评估服务质量损害和公平性，并对这些偏差的影响（特别是对自动字幕）进行细致的讨论。我们的研究结果揭示了所有模型规模中性别组之间的词错误率 (WER) 存在显着差异，偏差通过统计测试识别。

##### **AI-driven inverse design of materials: Past, present and future**
2411.09429v1 by Xiao-Qi Han, Xin-De Wang, Meng-Yuan Xu, Zhen Feng, Bo-Wen Yao, Peng-Jie Guo, Ze-Feng Gao, Zhong-Yi Lu

The discovery of advanced materials is the cornerstone of human technological
development and progress. The structures of materials and their corresponding
properties are essentially the result of a complex interplay of multiple
degrees of freedom such as lattice, charge, spin, symmetry, and topology. This
poses significant challenges for the inverse design methods of materials.
Humans have long explored new materials through a large number of experiments
and proposed corresponding theoretical systems to predict new material
properties and structures. With the improvement of computational power,
researchers have gradually developed various electronic structure calculation
methods, particularly such as the one based density functional theory, as well
as high-throughput computational methods. Recently, the rapid development of
artificial intelligence technology in the field of computer science has enabled
the effective characterization of the implicit association between material
properties and structures, thus opening up an efficient paradigm for the
inverse design of functional materials. A significant progress has been made in
inverse design of materials based on generative and discriminative models,
attracting widespread attention from researchers. Considering this rapid
technological progress, in this survey, we look back on the latest advancements
in AI-driven inverse design of materials by introducing the background, key
findings, and mainstream technological development routes. In addition, we
summarize the remaining issues for future directions. This survey provides the
latest overview of AI-driven inverse design of materials, which can serve as a
useful resource for researchers.

摘要：先進材料的發現是人類科技發展進步的基石，材料的結構及其對應的性質，本質上是多個自由度，如晶格、電荷、自旋、對稱性、拓撲性複雜交互作用的結果，這對材料的反向設計方法提出了嚴峻的挑戰。人類長期以來通過大量的實驗探索新材料，並提出相應的理論體系來預測新材料的性質和結構。隨著計算能力的提升，研究人員逐漸發展出各種電子結構計算方法，特別是基於密度泛函理論的方法，以及高通量計算方法。近年來，計算機科學領域人工智能技術的飛速發展，使得材料性質和結構之間的隱含關聯得以有效表徵，從而為功能材料的反向設計打開了一條高效的範式。基於生成和判別模型的材料反向設計取得了顯著進展，引起了研究人員的廣泛關注。鑑於技術的飛速進步，本綜述回顧了人工智能驅動的材料反向設計的最新進展，介紹了背景、關鍵發現和主流技術發展路線。此外，我們總結了未來發展方向尚存的問題。本綜述提供了人工智能驅動的材料反向設計的最新概況，可作為研究人員有益的參考。

##### **SAG-ViT: A Scale-Aware, High-Fidelity Patching Approach with Graph Attention for Vision Transformers**
2411.09420v1 by Shravan Venkatraman, Jaskaran Singh Walia, Joe Dhanith P R

Image classification is a computer vision task where a model analyzes an
image to categorize it into a specific label. Vision Transformers (ViT) improve
this task by leveraging self-attention to capture complex patterns and long
range relationships between image patches. However, a key challenge for ViTs is
efficiently incorporating multiscale feature representations, which is inherent
in CNNs through their hierarchical structure. In this paper, we introduce the
Scale-Aware Graph Attention Vision Transformer (SAG-ViT), a novel framework
that addresses this challenge by integrating multi-scale features. Using
EfficientNet as a backbone, the model extracts multi-scale feature maps, which
are divided into patches to preserve semantic information. These patches are
organized into a graph based on spatial and feature similarities, with a Graph
Attention Network (GAT) refining the node embeddings. Finally, a Transformer
encoder captures long-range dependencies and complex interactions. The SAG-ViT
is evaluated on benchmark datasets, demonstrating its effectiveness in
enhancing image classification performance.

摘要：影像分類是一種電腦視覺任務，其中模型會分析影像並將其分類為特定標籤。視覺Transformer (ViT) 透過利用自我注意力來捕捉複雜模式和影像區塊之間的長距離關係，進而改善此任務。然而，ViT 的一項主要挑戰是有效地結合多尺度特徵表示，而這在 CNN 中透過其階層結構是與生俱來的。在本文中，我們介紹了尺度感知圖注意力視覺Transformer (SAG-ViT)，這是一個新穎的架構，透過整合多尺度特徵來解決此挑戰。模型以 EfficientNet 為基礎，提取多尺度特徵圖，並將其分割為區塊以保留語義資訊。這些區塊根據空間和特徵相似性組織成一個圖形，並透過圖形注意力網路 (GAT) 來改善節點嵌入。最後，Transformer編碼器會捕捉長距離依賴關係和複雜互動。SAG-ViT 在基準資料集上進行評估，證明其在增強影像分類效能方面的有效性。

##### **Script-centric behavior understanding for assisted autism spectrum disorder diagnosis**
2411.09413v1 by Wenxing Liu, Yueran Pan, Ming Li

Observing and analyzing children's social behaviors is crucial for the early
diagnosis of Autism Spectrum Disorders (ASD). This work focuses on
automatically detecting ASD using computer vision techniques and large language
models (LLMs). Existing methods typically rely on supervised learning. However,
the scarcity of ASD diagnostic datasets and the lack of interpretability in
diagnostic results significantly limits its clinical application. To address
these challenges, we introduce a novel unsupervised approach based on
script-centric behavior understanding. Our pipeline converts video content into
scripts that describe the behavior of characters, leveraging the
generalizability of large language models to detect ASD in a zero-shot or
few-shot manner. Specifically, we propose a scripts transcription module for
multimodal behavior data textualization and a domain prompts module to bridge
LLMs. Our method achieves an accuracy of 92.00\% in diagnosing ASD in children
with an average age of 24 months, surpassing the performance of supervised
learning methods by 3.58\% absolutely. Extensive experiments confirm the
effectiveness of our approach and suggest its potential for advancing ASD
research through LLMs.

摘要：觀察和分析兒童的社交行為對於自閉症譜系障礙 (ASD) 的早期診斷至關重要。這項工作著重於使用電腦視覺技術和大語言模型 (LLM) 自動偵測 ASD。現有方法通常依賴於監督式學習。然而，ASD 診斷資料集的稀少性和診斷結果缺乏可解釋性，顯著地限制了其臨床應用。為了應對這些挑戰，我們引入了一種基於以腳本為中心的行為理解的新型非監督式方法。我們的管道將影片內容轉換成描述角色行為的腳本，利用大語言模型的泛化性以零次或少次學習的方式偵測 ASD。具體來說，我們提出了一個腳本轉錄模組用於多模態行為資料文字化，以及一個網域提示模組來橋接 LLM。我們的模型在診斷平均年齡為 24 個月的兒童 ASD 時，達到了 92.00% 的準確率，絕對優於監督式學習方法 3.58%。大量的實驗證實了我們方法的有效性，並表明其通過 LLM 推動 ASD 研究的潛力。

##### **Imagined Speech and Visual Imagery as Intuitive Paradigms for Brain-Computer Interfaces**
2411.09400v1 by Seo-Hyun Lee, Ji-Ha Park, Deok-Seon Kim

Recent advancements in brain-computer interface (BCI) technology have
emphasized the promise of imagined speech and visual imagery as effective
paradigms for intuitive communication. This study investigates the
classification performance and brain connectivity patterns associated with
these paradigms, focusing on decoding accuracy across selected word classes.
Sixteen participants engaged in tasks involving thirteen imagined speech and
visual imagery classes, revealing above-chance classification accuracy for both
paradigms. Variability in classification accuracy across individual classes
highlights the influence of sensory and motor associations in imagined speech
and vivid visual associations in visual imagery. Connectivity analysis further
demonstrated increased functional connectivity in language-related and sensory
regions for imagined speech, whereas visual imagery activated spatial and
visual processing networks. These findings suggest the potential of imagined
speech and visual imagery as an intuitive and scalable paradigm for BCI
communication when selecting optimal word classes. Further exploration of the
decoding outcomes for these two paradigms could provide insights for practical
BCI communication.

摘要：腦機介面 (BCI) 技術的最新進展
強調了想像語言和視覺意象作為直覺溝通的有效典範。本研究探討了與這些典範相關的分類效能和腦部連結模式，專注於解碼特定字詞類別的準確度。十六位參與者參與了包含十三種想像語言和視覺意象類別的任務，揭露了兩種典範皆高於隨機的分類準確度。不同類別的分類準確度變異性突顯了感覺和運動關聯對想像語言的影響，以及視覺意象中生動的視覺關聯。連接性分析進一步證明了想像語言的語言相關和感覺區域功能連接性增加，而視覺意象則活化了空間和視覺處理網路。這些發現表明想像語言和視覺意象具有潛力，可用於選擇最佳字詞類別時，作為 BCI 溝通的直覺且可擴充的典範。進一步探討這兩種典範的解碼結果，可以為實務上的 BCI 溝通提供見解。

##### **Less is More: Unseen Domain Fake News Detection via Causal Propagation Substructures**
2411.09389v1 by Shuzhi Gong, Richard O. Sinnott, Jianzhong Qi, Cecile Paris

The spread of fake news on social media poses significant threats to
individuals and society. Text-based and graph-based models have been employed
for fake news detection by analysing news content and propagation networks,
showing promising results in specific scenarios. However, these data-driven
models heavily rely on pre-existing in-distribution data for training, limiting
their performance when confronted with fake news from emerging or previously
unseen domains, known as out-of-distribution (OOD) data. Tackling OOD fake news
is a challenging yet critical task. In this paper, we introduce the Causal
Subgraph-oriented Domain Adaptive Fake News Detection (CSDA) model, designed to
enhance zero-shot fake news detection by extracting causal substructures from
propagation graphs using in-distribution data and generalising this approach to
OOD data. The model employs a graph neural network based mask generation
process to identify dominant nodes and edges within the propagation graph,
using these substructures for fake news detection. Additionally, the
performance of CSDA is further improved through contrastive learning in
few-shot scenarios, where a limited amount of OOD data is available for
training. Extensive experiments on public social media datasets demonstrate
that CSDA effectively handles OOD fake news detection, achieving a 7 to 16
percents accuracy improvement over other state-of-the-art models.

摘要：社群媒體上假新聞的散布對個人和社會構成重大威脅。基於文字和圖形的模型已被用於假新聞偵測，方法是分析新聞內容和傳播網路，在特定場景中展現令人滿意的結果。然而，這些資料驅動的模型在訓練時極度仰賴現有的分佈內資料，當面對來自新興或先前未見領域（稱為分佈外 (OOD) 資料）的假新聞時，效能會受到限制。處理 OOD 假新聞是一項艱難但重要的任務。在本文中，我們介紹因果子圖導向的領域適應式假新聞偵測 (CSDA) 模型，旨在透過使用分佈內資料從傳播圖中萃取因果子結構，並將此方法推廣到 OOD 資料，來提升零次學習假新聞偵測。該模型採用基於圖形神經網路的遮罩產生程序，來識別傳播圖中主要的節點和邊緣，並使用這些子結構進行假新聞偵測。此外，CSDA 的效能透過在小樣本學習中進行對比學習進一步提升，在這種情況下，只有有限數量的 OOD 資料可用於訓練。在公開社群媒體資料集上的廣泛實驗證明，CSDA 能有效處理 OOD 假新聞偵測，比其他最先進的模型提高了 7% 到 16% 的準確率。

##### **LTLf+ and PPLTL+: Extending LTLf and PPLTL to Infinite Traces**
2411.09366v1 by Benjamin Aminof, Giuseppe De Giacomo, Sasha Rubin, Moshe Y. Vardi

We introduce LTLf+ and PPLTL+, two logics to express properties of infinite
traces, that are based on the linear-time temporal logics LTLf and PPLTL on
finite traces. LTLf+/PPLTL+ use levels of Manna and Pnueli's LTL
safety-progress hierarchy, and thus have the same expressive power as LTL.
However, they also retain a crucial characteristic of the reactive synthesis
problem for the base logics: the game arena for strategy extraction can be
derived from deterministic finite automata (DFA). Consequently, these logics
circumvent the notorious difficulties associated with determinizing infinite
trace automata, typical of LTL reactive synthesis. We present DFA-based
synthesis techniques for LTLf+/PPLTL+, and show that synthesis is
2EXPTIME-complete for LTLf+ (matching LTLf) and EXPTIME-complete for PPLTL+
(matching PPLTL). Notably, while PPLTL+ retains the full expressive power of
LTL, reactive synthesis is EXPTIME-complete instead of 2EXPTIME-complete. The
techniques are also adapted to optimally solve satisfiability, validity, and
model-checking, to get EXPSPACE-complete for LTLf+ (extending a recent result
for the guarantee level using LTLf), and PSPACE-complete for PPLTL+.

摘要：<paragraph>我們引入了 LTLf+ 和 PPLTL+，這兩個邏輯用於表達無限軌跡的屬性，它們基於有限軌跡上的線性時間時序邏輯 LTLf 和 PPLTL。LTLf+/PPLTL+ 使用 Manna 和 Pnueli 的 LTL 安全進度階層的層級，因此具有與 LTL 相同的表達能力。然而，它們也保留了基本邏輯的反應式合成問題的一個關鍵特徵：可以從確定性有限自動機 (DFA) 中推導出策略提取的遊戲場景。因此，這些邏輯規避了與確定無限軌跡自動機相關的臭名昭著的困難，這對於 LTL 反應式合成來說是典型的。我們提出了基於 DFA 的 LTLf+/PPLTL+ 合成技術，並證明了 LTLf+ 的合成是 2EXPTIME 完備的（匹配 LTLf），而 PPLTL+ 的合成是 EXPTIME 完備的（匹配 PPLTL）。值得注意的是，雖然 PPLTL+ 保留了 LTL 的全部表達能力，但反應式合成是 EXPTIME 完備的，而不是 2EXPTIME 完備的。這些技術也適用於最佳地解決可滿足性、有效性和模型檢查，以獲得 LTLf+ 的 EXPSPACE 完備（擴展了使用 LTLf 的保證層級的最新結果），以及 PPLTL+ 的 PSPACE 完備。</paragraph>

##### **Multi-scale Generative Modeling for Fast Sampling**
2411.09356v1 by Xiongye Xiao, Shixuan Li, Luzhe Huang, Gengshuo Liu, Trung-Kien Nguyen, Yi Huang, Di Chang, Mykel J. Kochenderfer, Paul Bogdan

While working within the spatial domain can pose problems associated with
ill-conditioned scores caused by power-law decay, recent advances in
diffusion-based generative models have shown that transitioning to the wavelet
domain offers a promising alternative. However, within the wavelet domain, we
encounter unique challenges, especially the sparse representation of
high-frequency coefficients, which deviates significantly from the Gaussian
assumptions in the diffusion process. To this end, we propose a multi-scale
generative modeling in the wavelet domain that employs distinct strategies for
handling low and high-frequency bands. In the wavelet domain, we apply
score-based generative modeling with well-conditioned scores for low-frequency
bands, while utilizing a multi-scale generative adversarial learning for
high-frequency bands. As supported by the theoretical analysis and experimental
results, our model significantly improve performance and reduce the number of
trainable parameters, sampling steps, and time.

摘要：在空间域内工作时，可能会遇到由幂律衰减引起的病态评分相关的问题，但基于扩散的生成模型的最新进展表明，过渡到小波域提供了一个有希望的替代方案。然而，在小波域内，我们遇到了独特的挑战，特别是高频系数的稀疏表示，它与扩散过程中的高斯假设有很大偏差。为此，我们提出了一种多尺度小波域生成模型，该模型采用不同的策略来处理低频和高频带。在小波域中，我们对低频带应用基于评分的生成模型，该模型具有良好的条件评分，同时对高频带利用多尺度生成对抗学习。正如理论分析和实验结果所支持的，我们的模型显著提高了性能，并减少了可训练参数、采样步骤和时间。

##### **Re-Parameterization of Lightweight Transformer for On-Device Speech Emotion Recognition**
2411.09339v1 by Zixing Zhang, Zhongren Dong, Weixiang Xu, Jing Han

With the increasing implementation of machine learning models on edge or
Internet-of-Things (IoT) devices, deploying advanced models on
resource-constrained IoT devices remains challenging. Transformer models, a
currently dominant neural architecture, have achieved great success in broad
domains but their complexity hinders its deployment on IoT devices with limited
computation capability and storage size. Although many model compression
approaches have been explored, they often suffer from notorious performance
degradation. To address this issue, we introduce a new method, namely
Transformer Re-parameterization, to boost the performance of lightweight
Transformer models. It consists of two processes: the High-Rank Factorization
(HRF) process in the training stage and the deHigh-Rank Factorization (deHRF)
process in the inference stage. In the former process, we insert an additional
linear layer before the Feed-Forward Network (FFN) of the lightweight
Transformer. It is supposed that the inserted HRF layers can enhance the model
learning capability. In the later process, the auxiliary HRF layer will be
merged together with the following FFN layer into one linear layer and thus
recover the original structure of the lightweight model. To examine the
effectiveness of the proposed method, we evaluate it on three widely used
Transformer variants, i.e., ConvTransformer, Conformer, and SpeechFormer
networks, in the application of speech emotion recognition on the IEMOCAP, M3ED
and DAIC-WOZ datasets. Experimental results show that our proposed method
consistently improves the performance of lightweight Transformers, even making
them comparable to large models. The proposed re-parameterization approach
enables advanced Transformer models to be deployed on resource-constrained IoT
devices.

摘要：隨著機器學習模型在邊緣或物聯網 (IoT) 裝置上實作的增加，在資源受限的 IoT 裝置上部署進階模型仍然是一項挑戰。Transformer模型是一種目前主流的神經網路架構，已在廣泛的領域中取得巨大的成功，但其複雜性阻礙了其在運算能力和儲存空間有限的 IoT 裝置上的部署。儘管已探討了許多模型壓縮方法，但它們通常會面臨效能顯著下降的問題。為了解決此問題，我們提出了一種名為Transformer重新參數化的全新方法，以提升輕量級Transformer模型的效能。它包含兩個程序：訓練階段的高階分解 (HRF) 程序和推理階段的去高階分解 (deHRF) 程序。在前一個程序中，我們在輕量級Transformer的饋前網路 (FFN) 之前插入一個額外的線性層。假設插入的 HRF 層可以增強模型的學習能力。在後續程序中，輔助 HRF 層將與後續的 FFN 層合併為一個線性層，從而恢復輕量級模型的原始結構。為了檢驗所提出方法的有效性，我們在三個廣泛使用的Transformer變體（即 ConvTransformer、Conformer 和 SpeechFormer 網路）上對其進行評估，在 IEMOCAP、M3ED 和 DAIC-WOZ 資料集上應用語音情緒辨識。實驗結果顯示，我們提出的方法持續提升輕量級Transformer的效能，甚至讓它們與大型模型相媲美。所提出的重新參數化方法使進階Transformer模型能夠部署在資源受限的 IoT 裝置上。

##### **DriveThru: a Document Extraction Platform and Benchmark Datasets for Indonesian Local Language Archives**
2411.09318v1 by MohammadRifqi Farhansyah, Muhammad Zuhdi Fikri Johari, Afinzaki Amiral, Ayu Purwarianti, Kumara Ari Yuana, Derry Tanti Wijaya

Indonesia is one of the most diverse countries linguistically. However,
despite this linguistic diversity, Indonesian languages remain underrepresented
in Natural Language Processing (NLP) research and technologies. In the past two
years, several efforts have been conducted to construct NLP resources for
Indonesian languages. However, most of these efforts have been focused on
creating manual resources thus difficult to scale to more languages. Although
many Indonesian languages do not have a web presence, locally there are
resources that document these languages well in printed forms such as books,
magazines, and newspapers. Digitizing these existing resources will enable
scaling of Indonesian language resource construction to many more languages. In
this paper, we propose an alternative method of creating datasets by digitizing
documents, which have not previously been used to build digital language
resources in Indonesia. DriveThru is a platform for extracting document content
utilizing Optical Character Recognition (OCR) techniques in its system to
provide language resource building with less manual effort and cost. This paper
also studies the utility of current state-of-the-art LLM for post-OCR
correction to show the capability of increasing the character accuracy rate
(CAR) and word accuracy rate (WAR) compared to off-the-shelf OCR.

摘要：印尼在語言學上是最多元化的國家之一。然而，儘管有這種語言的多樣性，印尼語在自然語言處理 (NLP) 研究和技術中仍然代表性不足。在過去兩年，已經進行了數項工作來構建印尼語的 NLP 資源。然而，這些工作大多集中在創建手動資源上，因此難以擴展到更多語言。儘管許多印尼語沒有網路存在，但在當地有資源以印刷形式（例如書籍、雜誌和報紙）很好地記錄了這些語言。將這些現有資源數位化將使印尼語資源構建擴展到更多語言。在本文中，我們提出了一種通過數位化文件來創建資料集的替代方法，該方法以前未用於在印尼建立數位語言資源。DriveThru 是利用其系統中的光學字元辨識 (OCR) 技術來擷取文件內容的平台，可提供語言資源建置，且人工成本較低。本文還研究了當前最先進的 LLM 在 OCR 後校正中的效用，以展示與現成的 OCR 相比，提高字元準確率 (CAR) 和字詞準確率 (WAR) 的能力。

##### **EEG-Based Speech Decoding: A Novel Approach Using Multi-Kernel Ensemble Diffusion Models**
2411.09302v1 by Soowon Kim, Ha-Na Jo, Eunyeong Ko

In this study, we propose an ensemble learning framework for
electroencephalogram-based overt speech classification, leveraging denoising
diffusion probabilistic models with varying convolutional kernel sizes. The
ensemble comprises three models with kernel sizes of 51, 101, and 201,
effectively capturing multi-scale temporal features inherent in signals. This
approach improves the robustness and accuracy of speech decoding by
accommodating the rich temporal complexity of neural signals. The ensemble
models work in conjunction with conditional autoencoders that refine the
reconstructed signals and maximize the useful information for downstream
classification tasks. The results indicate that the proposed ensemble-based
approach significantly outperforms individual models and existing
state-of-the-art techniques. These findings demonstrate the potential of
ensemble methods in advancing brain signal decoding, offering new possibilities
for non-verbal communication applications, particularly in brain-computer
interface systems aimed at aiding individuals with speech impairments.

摘要：在這個研究中，我們提出了一個集合學習架構，用於基於腦電圖的明顯言語分類，利用具有不同卷積核大小的去噪擴散機率模型。此集合包含三個模型，其核大小分別為 51、101 和 201，有效擷取訊號中固有的多尺度時間特徵。此方法透過容納神經訊號豐富的時間複雜性，來改善言語解碼的穩健性和準確性。集合模型與條件式自動編碼器一起使用，可以改善重建訊號並最大化對下游分類任務有用的資訊。結果表明，所提出的基於集合的方法顯著優於個別模型和現有的最先進技術。這些發現展示了集合方法在推進腦訊號解碼方面的潛力，為非語言溝通應用程式提供了新的可能性，特別是在旨在幫助言語障礙人士的腦電腦介面系統中。

##### **DTELS: Towards Dynamic Granularity of Timeline Summarization**
2411.09297v1 by Chenlong Zhang, Tong Zhou, Pengfei Cao, Zhuoran Jin, Yubo Chen, Kang Liu, Jun Zhao

The rapid proliferation of online news has posed significant challenges in
tracking the continuous development of news topics. Traditional timeline
summarization constructs a chronological summary of the events but often lacks
the flexibility to meet the diverse granularity needs. To overcome this
limitation, we introduce a new paradigm, Dynamic-granularity TimELine
Summarization, (DTELS), which aims to construct adaptive timelines based on
user instructions or requirements. This paper establishes a comprehensive
benchmark for DTLES that includes: (1) an evaluation framework grounded in
journalistic standards to assess the timeline quality across four dimensions:
Informativeness, Granular Consistency, Factuality, and Coherence; (2) a
large-scale, multi-source dataset with multiple granularity timeline
annotations based on a consensus process to facilitate authority; (3) extensive
experiments and analysis with two proposed solutions based on Large Language
Models (LLMs) and existing state-of-the-art TLS methods. The experimental
results demonstrate the effectiveness of LLM-based solutions. However, even the
most advanced LLMs struggle to consistently generate timelines that are both
informative and granularly consistent, highlighting the challenges of the DTELS
task.

摘要：網路新聞的快速擴散對追蹤新聞議題的持續發展提出了重大挑戰。傳統的時間軸摘要建構事件的時序摘要，但往往缺乏滿足不同粒度需求的彈性。為了克服這個限制，我們引入了一個新的模式，動態粒度時間軸摘要 (DTELS)，其目標是根據使用者的指示或需求建構自適應時間軸。本文建立了一個 DTLES 的綜合基準，其中包括：(1) 一個基於新聞標準的評估架構，用於評估時間軸品質，涵蓋四個面向：資訊性、粒度一致性、事實性和連貫性；(2) 一個大型、多來源的資料集，其中包含基於共識程序的各種粒度時間軸註解，以促進權威性；(3) 針對兩種建議的解決方案進行廣泛的實驗和分析，這些解決方案基於大型語言模型 (LLM) 和現有的最先進 TLS 方法。實驗結果證明了基於 LLM 的解決方案的有效性。然而，即使是最先進的 LLM 也難以持續產生既具資訊性又粒度一致的時間軸，這突顯了 DTELS 任務的挑戰。

##### **StreamAdapter: Efficient Test Time Adaptation from Contextual Streams**
2411.09289v1 by Dilxat Muhtar, Yelong Shen, Yaming Yang, Xiaodong Liu, Yadong Lu, Jianfeng Liu, Yuefeng Zhan, Hao Sun, Weiwei Deng, Feng Sun, Xueliang Zhang, Jianfeng Gao, Weizhu Chen, Qi Zhang

In-context learning (ICL) allows large language models (LLMs) to adapt to new
tasks directly from the given demonstrations without requiring gradient
updates. While recent advances have expanded context windows to accommodate
more demonstrations, this approach increases inference costs without
necessarily improving performance. To mitigate these issues, We propose
StreamAdapter, a novel approach that directly updates model parameters from
context at test time, eliminating the need for explicit in-context
demonstrations. StreamAdapter employs context mapping and weight absorption
mechanisms to dynamically transform ICL demonstrations into parameter updates
with minimal additional parameters. By reducing reliance on numerous in-context
examples, StreamAdapter significantly reduce inference costs and allows for
efficient inference with constant time complexity, regardless of demonstration
count. Extensive experiments across diverse tasks and model architectures
demonstrate that StreamAdapter achieves comparable or superior adaptation
capability to ICL while requiring significantly fewer demonstrations. The
superior task adaptation and context encoding capabilities of StreamAdapter on
both language understanding and generation tasks provides a new perspective for
adapting LLMs at test time using context, allowing for more efficient
adaptation across scenarios and more cost-effective inference

摘要：語境學習 (ICL) 讓大型語言模型 (LLM) 能直接從給定的示範中適應新任務，而不需要梯度更新。雖然最近的進展已擴展語境窗口以容納更多示範，但此方法會增加推論成本，卻不一定能改善效能。為了減輕這些問題，我們提出 StreamAdapter，這是一種新穎的方法，它在測試時直接從語境更新模型參數，消除了對明確語境示範的需求。StreamAdapter 採用語境對應和權重吸收機制，將 ICL 示範動態轉換為參數更新，同時將額外參數減至最少。透過減少對大量語境範例的依賴，StreamAdapter 大幅降低推論成本，並允許以恆定的時間複雜度進行有效率的推論，與示範數量無關。跨不同任務和模型架構的廣泛實驗證明，StreamAdapter 達到與 ICL 相當或更優異的適應能力，同時所需的示範數量卻少得多。StreamAdapter 在語言理解和生成任務上都具有優異的任務適應和語境編碼能力，為在測試時使用語境來適應 LLM 提供了新的觀點，允許跨場景進行更有效率的適應和更具成本效益的推論。

##### **Cross-Modal Consistency in Multimodal Large Language Models**
2411.09273v1 by Xiang Zhang, Senyu Li, Ning Shi, Bradley Hauer, Zijun Wu, Grzegorz Kondrak, Muhammad Abdul-Mageed, Laks V. S. Lakshmanan

Recent developments in multimodal methodologies have marked the beginning of
an exciting era for models adept at processing diverse data types, encompassing
text, audio, and visual content. Models like GPT-4V, which merge computer
vision with advanced language processing, exhibit extraordinary proficiency in
handling intricate tasks that require a simultaneous understanding of both
textual and visual information. Prior research efforts have meticulously
evaluated the efficacy of these Vision Large Language Models (VLLMs) in various
domains, including object detection, image captioning, and other related
fields. However, existing analyses have often suffered from limitations,
primarily centering on the isolated evaluation of each modality's performance
while neglecting to explore their intricate cross-modal interactions.
Specifically, the question of whether these models achieve the same level of
accuracy when confronted with identical task instances across different
modalities remains unanswered. In this study, we take the initiative to delve
into the interaction and comparison among these modalities of interest by
introducing a novel concept termed cross-modal consistency. Furthermore, we
propose a quantitative evaluation framework founded on this concept. Our
experimental findings, drawn from a curated collection of parallel
vision-language datasets developed by us, unveil a pronounced inconsistency
between the vision and language modalities within GPT-4V, despite its portrayal
as a unified multimodal model. Our research yields insights into the
appropriate utilization of such models and hints at potential avenues for
enhancing their design.

摘要：<paragraph>多模态方法的最新发展标志着一个令人兴奋的新时代，在这个时代，模型擅长处理各种数据类型，包括文本、音频和视觉内容。像 GPT-4V 这样的模型将计算机视觉与高级语言处理相结合，在处理需要同时理解文本和视觉信息的任务时表现出非凡的熟练度。先前的研究工作已仔细评估了这些视觉大语言模型 (VLLM) 在各个领域的功效，包括对象检测、图像字幕和其他相关领域。然而，现有的分析通常存在局限性，主要集中在孤立评估每个模态的性能，而忽略了探索它们复杂的跨模态交互。具体来说，这些模型在面对不同模态的相同任务实例时是否达到相同级别的准确性，这个问题仍然没有答案。在这项研究中，我们主动深入研究这些感兴趣的模态之间的交互和比较，引入了称为跨模态一致性的新概念。此外，我们提出了一个基于这一概念的定量评估框架。我们的实验结果来自我们开发的经过整理的并行视觉语言数据集，揭示了 GPT-4V 中视觉和语言模态之间明显的差异，尽管它被描述为一个统一的多模态模型。我们的研究得出了对这些模型的适当利用的见解，并暗示了增强其设计的潜在途径。</paragraph>

##### **Harnessing multiple LLMs for Information Retrieval: A case study on Deep Learning methodologies in Biodiversity publications**
2411.09269v1 by Vamsi Krishna Kommineni, Birgitta König-Ries, Sheeba Samuel

Deep Learning (DL) techniques are increasingly applied in scientific studies
across various domains to address complex research questions. However, the
methodological details of these DL models are often hidden in the unstructured
text. As a result, critical information about how these models are designed,
trained, and evaluated is challenging to access and comprehend. To address this
issue, in this work, we use five different open-source Large Language Models
(LLMs): Llama-3 70B, Llama-3.1 70B, Mixtral-8x22B-Instruct-v0.1, Mixtral 8x7B,
and Gemma 2 9B in combination with Retrieval-Augmented Generation (RAG)
approach to extract and process DL methodological details from scientific
publications automatically. We built a voting classifier from the outputs of
five LLMs to accurately report DL methodological information. We tested our
approach using biodiversity publications, building upon our previous research.
To validate our pipeline, we employed two datasets of DL-related biodiversity
publications: a curated set of 100 publications from our prior work and a set
of 364 publications from the Ecological Informatics journal. Our results
demonstrate that the multi-LLM, RAG-assisted pipeline enhances the retrieval of
DL methodological information, achieving an accuracy of 69.5% (417 out of 600
comparisons) based solely on textual content from publications. This
performance was assessed against human annotators who had access to code,
figures, tables, and other supplementary information. Although demonstrated in
biodiversity, our methodology is not limited to this field; it can be applied
across other scientific domains where detailed methodological reporting is
essential for advancing knowledge and ensuring reproducibility. This study
presents a scalable and reliable approach for automating information
extraction, facilitating better reproducibility and knowledge transfer across
studies.

摘要：深度學習 (DL) 技術正越來越廣泛地應用於各個領域的科學研究中，以解決複雜的研究問題。然而，這些 DL 模型的方法論細節通常隱藏在非結構化的文本中。因此，關於這些模型如何設計、訓練和評估的重要資訊難以取得和理解。為了解決這個問題，我們在這項工作中使用了五種不同的開源大型語言模型 (LLM)：Llama-3 70B、Llama-3.1 70B、Mixtral-8x22B-Instruct-v0.1、Mixtral 8x7B 和 Gemma 2 9B，並結合檢索增強生成 (RAG) 方法，自動從科學出版物中提取和處理 DL 方法論細節。我們根據五個 LLM 的輸出建立了一個投票分類器，以準確報告 DL 方法論資訊。我們使用生物多樣性出版物測試了我們的做法，並建立在我們先前的研究基礎上。為了驗證我們的管道，我們使用了兩個與 DL 相關的生物多樣性出版物資料集：一組我們先前工作中精選的 100 篇出版物，以及一組來自 Ecological Informatics 期刊的 364 篇出版物。我們的結果表明，多 LLM、RAG 輔助管道增強了 DL 方法論資訊的檢索，僅根據出版物的文字內容就達到了 69.5%（600 次比較中的 417 次）的準確度。此效能是針對可以取得程式碼、圖表、表格和其他補充資訊的人類註解者進行評估。儘管在生物多樣性中得到證實，但我們的做法並不限於此領域；它可以應用於其他科學領域，在這些領域中，詳細的方法論報告對於推進知識和確保可重複性至關重要。本研究提出了一種可擴充且可靠的方法，用於自動化資訊提取，促進更好的可重複性和跨研究的知識傳遞。

##### **How Good is ChatGPT at Audiovisual Deepfake Detection: A Comparative Study of ChatGPT, AI Models and Human Perception**
2411.09266v1 by Sahibzada Adil Shahzad, Ammarah Hashmi, Yan-Tsung Peng, Yu Tsao, Hsin-Min Wang

Multimodal deepfakes involving audiovisual manipulations are a growing threat
because they are difficult to detect with the naked eye or using unimodal deep
learningbased forgery detection methods. Audiovisual forensic models, while
more capable than unimodal models, require large training datasets and are
computationally expensive for training and inference. Furthermore, these models
lack interpretability and often do not generalize well to unseen manipulations.
In this study, we examine the detection capabilities of a large language model
(LLM) (i.e., ChatGPT) to identify and account for any possible visual and
auditory artifacts and manipulations in audiovisual deepfake content. Extensive
experiments are conducted on videos from a benchmark multimodal deepfake
dataset to evaluate the detection performance of ChatGPT and compare it with
the detection capabilities of state-of-the-art multimodal forensic models and
humans. Experimental results demonstrate the importance of domain knowledge and
prompt engineering for video forgery detection tasks using LLMs. Unlike
approaches based on end-to-end learning, ChatGPT can account for spatial and
spatiotemporal artifacts and inconsistencies that may exist within or across
modalities. Additionally, we discuss the limitations of ChatGPT for multimedia
forensic tasks.

摘要：多模態深度偽造涉及視聽操縱，是一個日益嚴重的威脅，因為用肉眼或使用單模態深度學習偽造偵測方法很難偵測到。視聽鑑識模型雖然比單模態模型功能更強大，但需要大量的訓練資料集，而且訓練和推論的計算成本很高。此外，這些模型缺乏可解釋性，而且通常無法很好地概括到未見過的操縱。在本研究中，我們檢驗大型語言模型 (LLM)（即 ChatGPT）的偵測能力，以識別和說明視聽深度偽造內容中的任何可能的視覺和聽覺人工製品和操縱。在一個基準多模態深度偽造資料集的影片上進行廣泛的實驗，以評估 ChatGPT 的偵測效能，並將其與最先進的多模態鑑識模型和人類的偵測能力進行比較。實驗結果證明了領域知識和提示工程對於使用 LLM 進行影片偽造偵測任務的重要性。與基於端到端學習的方法不同，ChatGPT 可以說明可能存在於模態內或跨模態的空間和時空人工製品和不一致性。此外，我們討論了 ChatGPT 在多媒體鑑識任務中的限制。

##### **Automating Autograding: Large Language Models as Test Suite Generators for Introductory Programming**
2411.09261v1 by Umar Alkafaween, Ibrahim Albluwi, Paul Denny

Automatically graded programming assignments provide instant feedback to
students and significantly reduce manual grading time for instructors. However,
creating comprehensive suites of test cases for programming problems within
automatic graders can be time-consuming and complex. The effort needed to
define test suites may deter some instructors from creating additional problems
or lead to inadequate test coverage, potentially resulting in misleading
feedback on student solutions. Such limitations may reduce student access to
the well-documented benefits of timely feedback when learning programming.
  In this work, we evaluate the effectiveness of using Large Language Models
(LLMs), as part of a larger workflow, to automatically generate test suites for
CS1-level programming problems. Each problem's statement and reference solution
are provided to GPT-4 to produce a test suite that can be used by an
autograder. We evaluate our proposed approach using a sample of 26 problems,
and more than 25,000 attempted solutions to those problems, submitted by
students in an introductory programming course. We compare the performance of
the LLM-generated test suites against the instructor-created test suites for
each problem. Our findings reveal that LLM-generated test suites can correctly
identify most valid solutions, and for most problems are at least as
comprehensive as the instructor test suites. Additionally, the LLM-generated
test suites exposed ambiguities in some problem statements, underscoring their
potential to improve both autograding and instructional design.

摘要：自動評分的程式作業提供即時的回饋給學生，並大幅減少教師的手動評分時間。然而，在自動評分器中為程式問題建立全面的測試案例套件可能會很耗時且複雜。定義測試套件所需的精力可能會阻止一些教師建立其他問題或導致測試範圍不足，進而可能導致對學生解答產生誤導性的回饋。此類限制可能會減少學生在學習程式設計時獲得及時回饋的充分文件記錄好處的機會。在這項工作中，我們評估使用大型語言模型 (LLM) 作為較大工作流程的一部分，自動為 CS1 等級的程式設計問題產生測試套件的有效性。每個問題的陳述和參考解答都提供給 GPT-4，以產生自動評分器可以使用的測試套件。我們使用 26 個問題的範例來評估我們提出的方法，以及學生在入門程式設計課程中提交的超過 25,000 個嘗試解答。我們比較 LLM 生成的測試套件與每個問題的教師建立的測試套件的表現。我們的發現顯示，LLM 生成的測試套件可以正確識別大多數有效的解答，而且對於大多數問題，它們至少與教師測試套件一樣全面。此外，LLM 生成的測試套件揭露了一些問題陳述中的歧義，強調它們改善自動評分和教學設計的潛力。

##### **Jailbreak Attacks and Defenses against Multimodal Generative Models: A Survey**
2411.09259v1 by Xuannan Liu, Xing Cui, Peipei Li, Zekun Li, Huaibo Huang, Shuhan Xia, Miaoxuan Zhang, Yueying Zou, Ran He

The rapid evolution of multimodal foundation models has led to significant
advancements in cross-modal understanding and generation across diverse
modalities, including text, images, audio, and video. However, these models
remain susceptible to jailbreak attacks, which can bypass built-in safety
mechanisms and induce the production of potentially harmful content.
Consequently, understanding the methods of jailbreak attacks and existing
defense mechanisms is essential to ensure the safe deployment of multimodal
generative models in real-world scenarios, particularly in security-sensitive
applications. To provide comprehensive insight into this topic, this survey
reviews jailbreak and defense in multimodal generative models. First, given the
generalized lifecycle of multimodal jailbreak, we systematically explore
attacks and corresponding defense strategies across four levels: input,
encoder, generator, and output. Based on this analysis, we present a detailed
taxonomy of attack methods, defense mechanisms, and evaluation frameworks
specific to multimodal generative models. Additionally, we cover a wide range
of input-output configurations, including modalities such as Any-to-Text,
Any-to-Vision, and Any-to-Any within generative systems. Finally, we highlight
current research challenges and propose potential directions for future
research.The open-source repository corresponding to this work can be found at
https://github.com/liuxuannan/Awesome-Multimodal-Jailbreak.

摘要：<paragraph>多模態基礎模型的快速演進引發了跨模態理解和生成方面的重大進展，涵蓋了文字、影像、音訊和影片等多種模態。然而，這些模型仍然容易受到越獄攻擊，這可能會繞過內建的安全機制，並引發潛在有害內容的產生。因此，瞭解越獄攻擊的方法和現有的防禦機制對於確保在現實世界場景中安全部署多模態生成模型至關重要，特別是在注重安全的應用程式中。為了提供對此主題的全面見解，本調查回顧了多模態生成模型中的越獄和防禦。首先，鑑於多模態越獄的概括生命週期，我們系統性地探索了四個層級的攻擊和相應的防禦策略：輸入、編碼器、生成器和輸出。基於此分析，我們提出了針對多模態生成模型的攻擊方法、防禦機制和評估架構的詳細分類。此外，我們涵蓋了廣泛的輸入輸出組態，包括生成系統中的 Any-to-Text、Any-to-Vision 和 Any-to-Any 等模態。最後，我們重點介紹了當前的研究挑戰，並提出了未來研究的潛在方向。本著作對應的開放原始碼存放庫可以在 https://github.com/liuxuannan/Awesome-Multimodal-Jailbreak 找到。</paragraph>

##### **DAHL: Domain-specific Automated Hallucination Evaluation of Long-Form Text through a Benchmark Dataset in Biomedicine**
2411.09255v1 by Jean Seo, Jongwon Lim, Dongjun Jang, Hyopil Shin

We introduce DAHL, a benchmark dataset and automated evaluation system
designed to assess hallucination in long-form text generation, specifically
within the biomedical domain. Our benchmark dataset, meticulously curated from
biomedical research papers, consists of 8,573 questions across 29 categories.
DAHL evaluates fact-conflicting hallucinations in Large Language Models (LLMs)
by deconstructing responses into atomic units, each representing a single piece
of information. The accuracy of these responses is averaged to produce the DAHL
Score, offering a more in-depth evaluation of hallucinations compared to
previous methods that rely on multiple-choice tasks. We conduct experiments
with 8 different models, finding that larger models tend to hallucinate less;
however, beyond a model size of 7 to 8 billion parameters, further scaling does
not significantly improve factual accuracy. The DAHL Score holds potential as
an efficient alternative to human-annotated preference labels, being able to be
expanded to other specialized domains. We release the dataset and code in
public.

摘要：我們推出 DAHL，這是一個基準資料集和自動化評估系統，旨在評估長篇文字生成中的幻覺，特別是在生物醫學領域。我們從生物醫學研究論文中精心策劃的基準資料集包含 29 個類別中的 8,573 個問題。DAHL 透過將回應解構為原子單位（每個單位代表單一資訊）來評估大型語言模型 (LLM) 中與事實相衝突的幻覺。這些回應的準確度會取平均值以產生 DAHL 分數，與依賴多選題任務的先前方法相比，提供了更深入的幻覺評估。我們對 8 種不同的模型進行實驗，發現較大的模型往往較少產生幻覺；然而，在模型大小超過 70 到 80 億個參數後，進一步擴充並不會顯著提高事實準確度。DAHL 分數具有成為人工標註偏好標籤的有效替代方案的潛力，能夠擴展到其他專業領域。我們公開發布資料集和程式碼。

##### **Cross Space and Time: A Spatio-Temporal Unitized Model for Traffic Flow Forecasting**
2411.09251v1 by Weilin Ruan, Wenzhuo Wang, Siru Zhong, Wei Chen, Li Liu, Yuxuan Liang

Predicting spatio-temporal traffic flow presents significant challenges due
to complex interactions between spatial and temporal factors. Existing
approaches often address these dimensions in isolation, neglecting their
critical interdependencies. In this paper, we introduce the Spatio-Temporal
Unitized Model (STUM), a unified framework designed to capture both spatial and
temporal dependencies while addressing spatio-temporal heterogeneity through
techniques such as distribution alignment and feature fusion. It also ensures
both predictive accuracy and computational efficiency. Central to STUM is the
Adaptive Spatio-temporal Unitized Cell (ASTUC), which utilizes low-rank
matrices to seamlessly store, update, and interact with space, time, as well as
their correlations. Our framework is also modular, allowing it to integrate
with various spatio-temporal graph neural networks through components such as
backbone models, feature extractors, residual fusion blocks, and predictive
modules to collectively enhance forecasting outcomes. Experimental results
across multiple real-world datasets demonstrate that STUM consistently improves
prediction performance with minimal computational cost. These findings are
further supported by hyperparameter optimization, pre-training analysis, and
result visualization. We provide our source code for reproducibility at
https://anonymous.4open.science/r/STUM-E4F0.

摘要：預測時空流量會因為時空因素之間的複雜交互作用而產生重大的挑戰。現有的方法通常孤立地處理這些面向，忽略它們之間的關鍵相互依賴性。在本文中，我們引入了時空單元模型 (STUM)，這是一個統一的架構，旨在捕捉時空依賴性，同時透過分配比對和特徵融合等技術來處理時空異質性。它也確保了預測準確性和運算效率。STUM 的核心是自適應時空單元格 (ASTUC)，它利用低秩矩陣來無縫地儲存、更新，並與空間、時間及其相關性進行互動。我們的架構也是模組化的，允許它透過主幹模型、特徵擷取器、殘差融合區塊和預測模組等組件，與各種時空圖形神經網路整合，以共同增強預測結果。跨多個真實世界資料集的實驗結果證明，STUM 以最小的運算成本持續改善預測效能。這些發現進一步獲得了超參數最佳化、預訓練分析和結果視覺化的支持。我們在 https://anonymous.4open.science/r/STUM-E4F0 提供我們的原始碼以供重現。

##### **Enhancing Financial Domain Adaptation of Language Models via Model Augmentation**
2411.09249v1 by Kota Tanabe, Masanori Hirano, Kazuki Matoya, Kentaro Imajo, Hiroki Sakaji, Itsuki Noda

The domain adaptation of language models, including large language models
(LLMs), has become increasingly important as the use of such models continues
to expand. This study demonstrates the effectiveness of Composition to Augment
Language Models (CALM) in adapting to the financial domain. CALM is a model to
extend the capabilities of existing models by introducing cross-attention
between two LLMs with different functions. In our experiments, we developed a
CALM to enhance the financial performance of an LLM with strong response
capabilities by leveraging a financial-specialized LLM. Notably, the CALM was
trained using a financial dataset different from the one used to train the
financial-specialized LLM, confirming CALM's ability to adapt to various
datasets. The models were evaluated through quantitative Japanese financial
benchmarks and qualitative response comparisons, demonstrating that CALM
enables superior responses with higher scores than the original models and
baselines. Additionally, comparative experiments on connection points revealed
that connecting the middle layers of the models is most effective in
facilitating adaptation to the financial domain. These findings confirm that
CALM is a practical approach for adapting LLMs to the financial domain.

摘要：語言模型的領域適應，包括大型語言模型 (LLM)，隨著這些模型的使用持續擴展而變得越來越重要。本研究展示了 Composition to Augment Language Models (CALM) 在適應金融領域方面的有效性。CALM 是一個模型，透過在具有不同功能的兩個 LLM 之間引入交叉注意力來擴展現有模型的能力。在我們的實驗中，我們開發了一個 CALM，透過利用一個財務專業的 LLM 來增強具有強大回應能力的 LLM 的財務表現。值得注意的是，CALM 是使用與訓練財務專業 LLM 不同的財務資料集進行訓練的，這證實了 CALM 適應各種資料集的能力。透過定量的日文財務基準和定性的回應比較來評估模型，證明 CALM 能夠產生比原始模型和基線更高的分數的優異回應。此外，對連接點的比較實驗顯示，連接模型的中間層在促進適應金融領域方面最有效。這些發現證實 CALM 是將 LLM 適應到金融領域的實用方法。

##### **Towards Unified Neural Decoding of Perceived, Spoken and Imagined Speech from EEG Signals**
2411.09243v1 by Jung-Sun Lee, Ha-Na Jo, Seo-Hyun Lee

Brain signals accompany various information relevant to human actions and
mental imagery, making them crucial to interpreting and understanding human
intentions. Brain-computer interface technology leverages this brain activity
to generate external commands for controlling the environment, offering
critical advantages to individuals with paralysis or locked-in syndrome. Within
the brain-computer interface domain, brain-to-speech research has gained
attention, focusing on the direct synthesis of audible speech from brain
signals. Most current studies decode speech from brain activity using invasive
techniques and emphasize spoken speech data. However, humans express various
speech states, and distinguishing these states through non-invasive approaches
remains a significant yet challenging task. This research investigated the
effectiveness of deep learning models for non-invasive-based neural signal
decoding, with an emphasis on distinguishing between different speech
paradigms, including perceived, overt, whispered, and imagined speech, across
multiple frequency bands. The model utilizing the spatial conventional neural
network module demonstrated superior performance compared to other models,
especially in the gamma band. Additionally, imagined speech in the theta
frequency band, where deep learning also showed strong effects, exhibited
statistically significant differences compared to the other speech paradigms.

摘要：腦信號伴隨著與人類動作和心智意象相關的各種資訊，使其對於詮釋和理解人類意圖至關重要。腦電腦介面技術利用此腦部活動來產生控制環境的外部指令，為癱瘓或閉鎖症候群的個人提供關鍵優勢。在腦電腦介面領域中，腦語音研究備受關注，重點在於從腦信號直接合成可聽的語音。大多數現行研究使用侵入式技術從腦部活動中解碼語音，並強調口說語音資料。然而，人類會表達各種語音狀態，而透過非侵入式方法區分這些狀態仍是一項重要且具有挑戰性的任務。本研究探討了深度學習模型對於非侵入式神經信號解碼的有效性，重點在於區分不同的語音範例，包括感知、顯性、耳語和想像的語音，橫跨多個頻率頻段。利用空間傳統神經網路模組的模型展現出優於其他模型的效能，特別是在伽馬頻段。此外，在深度學習也展現出強大效果的西塔頻段中，想像的語音與其他語音範例相比，呈現出具有統計顯著性的差異。

##### **Programming with AI: Evaluating ChatGPT, Gemini, AlphaCode, and GitHub Copilot for Programmers**
2411.09224v1 by Md Kamrul Siam, Huanying Gu, Jerry Q. Cheng

Our everyday lives now heavily rely on artificial intelligence (AI) powered
large language models (LLMs). Like regular users, programmers are also
benefiting from the newest large language models. In response to the critical
role that AI models play in modern software development, this study presents a
thorough evaluation of leading programming assistants, including ChatGPT,
Gemini(Bard AI), AlphaCode, and GitHub Copilot. The evaluation is based on
tasks like natural language processing and code generation accuracy in
different programming languages like Java, Python and C++. Based on the
results, it has emphasized their strengths and weaknesses and the importance of
further modifications to increase the reliability and accuracy of the latest
popular models. Although these AI assistants illustrate a high level of
progress in language understanding and code generation, along with ethical
considerations and responsible usage, they provoke a necessity for discussion.
With time, developing more refined AI technology is essential for achieving
advanced solutions in various fields, especially with the knowledge of the
feature intricacies of these models and their implications. This study offers a
comparison of different LLMs and provides essential feedback on the rapidly
changing area of AI models. It also emphasizes the need for ethical
developmental practices to actualize AI models' full potential.

摘要：我們現在的日常生活嚴重依賴由人工智慧 (AI) 驅動的大型語言模型 (LLM)。與一般使用者一樣，程式設計師也受益於最新的大型語言模型。針對 AI 模型在現代軟體開發中扮演的重要角色，本研究對領先的程式設計助理進行了徹底評估，包括 ChatGPT、Gemini(Bard AI)、AlphaCode 和 GitHub Copilot。評估的依據包括自然語言處理和不同程式語言（例如 Java、Python 和 C++）的程式碼生成準確性。根據結果，研究強調了它們的優缺點，以及進一步修改以提高最新熱門模型的可靠性和準確性的重要性。儘管這些 AI 助理在語言理解和程式碼生成方面表現出高水準的進展，但它們與道德考量和負責任的使用一起，引發了討論的必要性。隨著時間推移，開發更精緻的 AI 技術對於在各個領域實現先進的解決方案至關重要，特別是了解這些模型的功能複雜性和它們的影響。本研究比較了不同的 LLM，並對 AI 模型快速變化的領域提供了重要的回饋。它還強調了道德開發實務對於實現 AI 模型全部潛力的必要性。

##### **Transferable Adversarial Attacks against ASR**
2411.09220v1 by Xiaoxue Gao, Zexin Li, Yiming Chen, Cong Liu, Haizhou Li

Given the extensive research and real-world applications of automatic speech
recognition (ASR), ensuring the robustness of ASR models against minor input
perturbations becomes a crucial consideration for maintaining their
effectiveness in real-time scenarios. Previous explorations into ASR model
robustness have predominantly revolved around evaluating accuracy on white-box
settings with full access to ASR models. Nevertheless, full ASR model details
are often not available in real-world applications. Therefore, evaluating the
robustness of black-box ASR models is essential for a comprehensive
understanding of ASR model resilience. In this regard, we thoroughly study the
vulnerability of practical black-box attacks in cutting-edge ASR models and
propose to employ two advanced time-domain-based transferable attacks alongside
our differentiable feature extractor. We also propose a speech-aware gradient
optimization approach (SAGO) for ASR, which forces mistranscription with
minimal impact on human imperceptibility through voice activity detection rule
and a speech-aware gradient-oriented optimizer. Our comprehensive experimental
results reveal performance enhancements compared to baseline approaches across
five models on two databases.

摘要：由於自動語音辨識 (ASR) 的廣泛研究和實際應用，確保 ASR 模型對輕微輸入擾動的穩健性成為在實際情況中維持其有效性的關鍵考量。先前對 ASR 模型穩健性的探討主要圍繞著評估白盒設置中對 ASR 模型有完全存取權的準確度。然而，在實際應用中通常無法取得完整的 ASR 模型詳細資料。因此，評估黑盒 ASR 模型的穩健性對於全面了解 ASR 模型的復原力至關重要。在這方面，我們徹底研究了尖端 ASR 模型中實際黑盒攻擊的漏洞，並提議採用兩個進階的基於時域的可轉移攻擊以及我們可微分的特徵萃取器。我們還提出了一個適用於 ASR 的語音感知梯度最佳化方法 (SAGO)，它透過語音活動偵測規則和一個語音感知梯度導向最佳化器，在對人類感知影響最小的情況下強制錯誤轉錄。我們全面的實驗結果顯示，與五個模型在兩個資料庫上的基準方法相比，我們的表現有所提升。

##### **HateGPT: Unleashing GPT-3.5 Turbo to Combat Hate Speech on X**
2411.09214v1 by Aniket Deroy, Subhankar Maity

The widespread use of social media platforms like Twitter and Facebook has
enabled people of all ages to share their thoughts and experiences, leading to
an immense accumulation of user-generated content. However, alongside the
benefits, these platforms also face the challenge of managing hate speech and
offensive content, which can undermine rational discourse and threaten
democratic values. As a result, there is a growing need for automated methods
to detect and mitigate such content, especially given the complexity of
conversations that may require contextual analysis across multiple languages,
including code-mixed languages like Hinglish, German-English, and Bangla. We
participated in the English task where we have to classify English tweets into
two categories namely Hate and Offensive and Non Hate-Offensive. In this work,
we experiment with state-of-the-art large language models like GPT-3.5 Turbo
via prompting to classify tweets into Hate and Offensive or Non Hate-Offensive.
In this study, we evaluate the performance of a classification model using
Macro-F1 scores across three distinct runs. The Macro-F1 score, which balances
precision and recall across all classes, is used as the primary metric for
model evaluation. The scores obtained are 0.756 for run 1, 0.751 for run 2, and
0.754 for run 3, indicating a high level of performance with minimal variance
among the runs. The results suggest that the model consistently performs well
in terms of precision and recall, with run 1 showing the highest performance.
These findings highlight the robustness and reliability of the model across
different runs.

摘要：社群媒體平台（例如 Twitter 和 Facebook）的廣泛使用已使各年齡層的人們都能分享他們的想法和經驗，導致使用者產生的內容大量累積。然而，除了這些好處之外，這些平台也面臨著管理仇恨言論和冒犯性內容的挑戰，這些內容可能會破壞理性討論並威脅民主價值觀。因此，對於自動化方法的需求日益增加，以偵測和緩解此類內容，特別是考量到對話的複雜性，可能需要跨多種語言進行情境分析，包括混雜語言，例如 Hinglish、德語-英語和孟加拉語。我們參與了英語任務，在該任務中，我們必須將英語推文分類為兩個類別，即仇恨和冒犯性以及非仇恨-非冒犯性。在這項工作中，我們透過提示實驗了最先進的大語言模型，例如 GPT-3.5 Turbo，以將推文分類為仇恨和冒犯性或非仇恨-非冒犯性。在這項研究中，我們使用三個不同的執行結果的巨集 F1 分數來評估分類模型的效能。巨集 F1 分數可在所有類別中平衡準確度和召回率，並用作模型評估的主要指標。獲得的分數分別為執行結果 1 的 0.756、執行結果 2 的 0.751 和執行結果 3 的 0.754，表示效能水準高，且執行結果之間的差異很小。結果表明，該模型在準確度和召回率方面始終表現良好，其中執行結果 1 表現最佳。這些發現突顯了該模型在不同執行結果中的穩健性和可靠性。

##### **Comprehensive and Practical Evaluation of Retrieval-Augmented Generation Systems for Medical Question Answering**
2411.09213v1 by Nghia Trung Ngo, Chien Van Nguyen, Franck Dernoncourt, Thien Huu Nguyen

Retrieval-augmented generation (RAG) has emerged as a promising approach to
enhance the performance of large language models (LLMs) in knowledge-intensive
tasks such as those from medical domain. However, the sensitive nature of the
medical domain necessitates a completely accurate and trustworthy system. While
existing RAG benchmarks primarily focus on the standard retrieve-answer
setting, they overlook many practical scenarios that measure crucial aspects of
a reliable medical system. This paper addresses this gap by providing a
comprehensive evaluation framework for medical question-answering (QA) systems
in a RAG setting for these situations, including sufficiency, integration, and
robustness. We introduce Medical Retrieval-Augmented Generation Benchmark
(MedRGB) that provides various supplementary elements to four medical QA
datasets for testing LLMs' ability to handle these specific scenarios.
Utilizing MedRGB, we conduct extensive evaluations of both state-of-the-art
commercial LLMs and open-source models across multiple retrieval conditions.
Our experimental results reveals current models' limited ability to handle
noise and misinformation in the retrieved documents. We further analyze the
LLMs' reasoning processes to provides valuable insights and future directions
for developing RAG systems in this critical medical domain.

摘要：檢索增強生成（RAG）已成為一種有前途的方法，可增強大型語言模型（LLM）在知識密集型任務中的效能，例如醫療領域的任務。然而，醫療領域的敏感性質需要一個完全準確且值得信賴的系統。雖然現有的 RAG 評量基準主要著重於標準檢索回答設定，但它們忽略了許多衡量可靠醫療系統關鍵面向的實際情境。本文透過提供一個全面的評量架構來解決這個差距，這個架構適用於這些情境的 RAG 設定中的醫療問答（QA）系統，包括充足性、整合性與穩健性。我們引入了醫療檢索增強生成評量基準（MedRGB），它為四個醫療 QA 資料集提供了各種補充元素，以測試 LLM 處理這些特定情境的的能力。利用 MedRGB，我們對多種檢索條件下的最新商業 LLM 和開源模型進行了廣泛的評量。我們的實驗結果顯示，目前模型處理檢索文件中的雜訊和錯誤資訊的能力有限。我們進一步分析了 LLM 的推理程序，為在這個關鍵的醫療領域開發 RAG 系統提供了寶貴的見解和未來的方向。

##### **Improvement and Implementation of a Speech Emotion Recognition Model Based on Dual-Layer LSTM**
2411.09189v1 by Xiaoran Yang, Shuhan Yu, Wenxi Xu

This paper builds upon an existing speech emotion recognition model by adding
an additional LSTM layer to improve the accuracy and processing efficiency of
emotion recognition from audio data. By capturing the long-term dependencies
within audio sequences through a dual-layer LSTM network, the model can
recognize and classify complex emotional patterns more accurately. Experiments
conducted on the RAVDESS dataset validated this approach, showing that the
modified dual layer LSTM model improves accuracy by 2% compared to the
single-layer LSTM while significantly reducing recognition latency, thereby
enhancing real-time performance. These results indicate that the dual-layer
LSTM architecture is highly suitable for handling emotional features with
long-term dependencies, providing a viable optimization for speech emotion
recognition systems. This research provides a reference for practical
applications in fields like intelligent customer service, sentiment analysis
and human-computer interaction.

摘要：本論文建立在現有的語音情緒辨識模型上，加入額外的 LSTM 層，以提升從音訊資料中辨識情緒的準確度及處理效率。透過雙層 LSTM 網路擷取音訊序列中的長期依存關係，模型能更準確地辨識和分類複雜的情緒模式。在 RAVDESS 資料集上進行的實驗驗證了此方法，顯示修改後的雙層 LSTM 模型比單層 LSTM 提升了 2% 的準確度，同時大幅降低辨識延遲，進而提升即時效能。這些結果表明，雙層 LSTM 架構非常適合處理具有長期依存關係的情緒特徵，為語音情緒辨識系統提供了可行的最佳化方式。本研究為智慧客服、情緒分析和人機互動等領域的實際應用提供了參考。

##### **Dynamic technology impact analysis: A multi-task learning approach to patent citation prediction**
2411.09184v1 by Youngjin Seol, Jaewoong Choi, Seunghyun Lee, Janghyeok Yoon

Machine learning (ML) models are valuable tools for analyzing the impact of
technology using patent citation information. However, existing ML-based
methods often struggle to account for the dynamic nature of the technology
impact over time and the interdependencies of these impacts across different
periods. This study proposes a multi-task learning (MTL) approach to enhance
the prediction of technology impact across various time frames by leveraging
knowledge sharing and simultaneously monitoring the evolution of technology
impact. First, we quantify the technology impacts and identify patterns through
citation analysis over distinct time periods. Next, we develop MTL models to
predict citation counts using multiple patent indicators over time. Finally, we
examine the changes in key input indicators and their patterns over different
periods using the SHapley Additive exPlanation method. We also offer guidelines
for validating and interpreting the results by employing statistical methods
and natural language processing techniques. A case study on battery
technologies demonstrates that our approach not only deepens the understanding
of technology impact, but also improves prediction accuracy, yielding valuable
insights for both academia and industry.

摘要：機器學習 (ML) 模型是使用專利引文資訊分析技術影響力的有價值工具。然而，現有的基於 ML 的方法通常難以考量技術影響力隨著時間推移的動態性質，以及這些影響力在不同時期的相互依賴性。本研究提出一個多任務學習 (MTL) 方法，透過利用知識共享和同時監控技術影響力的演變，來增強對各種時間範圍內技術影響力的預測。首先，我們透過不同時間區段的引文分析，量化技術影響力和找出模式。接下來，我們開發 MTL 模型，以使用多個專利指標預測隨著時間推移的引文計數。最後，我們使用 SHapley 加法解釋方法，檢查關鍵輸入指標的變化及其在不同時期的模式。我們還提供透過採用統計方法和自然語言處理技術，來驗證和詮釋結果的指南。電池技術的案例研究證明，我們的做法不僅加深了對技術影響力的理解，也提高了預測準確度，為學術界和產業提供了有價值的見解。

##### **DeBaTeR: Denoising Bipartite Temporal Graph for Recommendation**
2411.09181v1 by Xinyu He, Jose Sepulveda, Mostafa Rahmani, Alyssa Woo, Fei Wang, Hanghang Tong

Due to the difficulty of acquiring large-scale explicit user feedback,
implicit feedback (e.g., clicks or other interactions) is widely applied as an
alternative source of data, where user-item interactions can be modeled as a
bipartite graph. Due to the noisy and biased nature of implicit real-world
user-item interactions, identifying and rectifying noisy interactions are vital
to enhance model performance and robustness. Previous works on purifying
user-item interactions in collaborative filtering mainly focus on mining the
correlation between user/item embeddings and noisy interactions, neglecting the
benefit of temporal patterns in determining noisy interactions. Time
information, while enhancing the model utility, also bears its natural
advantage in helping to determine noisy edges, e.g., if someone usually watches
horror movies at night and talk shows in the morning, a record of watching a
horror movie in the morning is more likely to be noisy interaction. Armed with
this observation, we introduce a simple yet effective mechanism for generating
time-aware user/item embeddings and propose two strategies for denoising
bipartite temporal graph in recommender systems (DeBaTeR): the first is through
reweighting the adjacency matrix (DeBaTeR-A), where a reliability score is
defined to reweight the edges through both soft assignment and hard assignment;
the second is through reweighting the loss function (DeBaTeR-L), where weights
are generated to reweight user-item samples in the losses. Extensive
experiments have been conducted to demonstrate the efficacy of our methods and
illustrate how time information indeed helps identifying noisy edges.

摘要：由於難以取得大規模的明確使用者回饋，隱含回饋（例如，點擊或其他互動）廣泛用作資料的替代來源，其中使用者與項目互動可以建模為二部圖。由於隱含的真實世界使用者與項目互動的雜訊和偏差性質，識別和修正雜訊互動對於增強模型效能和穩健性至關重要。先前在協同過濾中淨化使用者與項目互動的研究，主要集中在探勘使用者／項目嵌入與雜訊互動之間的關聯性，忽略了時間模式在決定雜訊互動中的好處。時間資訊在增強模型效用的同時，在幫助確定雜訊邊緣方面也具有其自然優勢，例如，如果某人通常在晚上看恐怖片，在早上看談話性節目，那麼在早上觀看恐怖片的記錄更有可能是雜訊互動。根據此觀察，我們引入了一種簡單但有效的機制來產生時間感知使用者／項目嵌入，並提出了兩種策略，用於在推薦系統中對二部時間圖進行去雜訊（DeBaTeR）：第一個是透過重新加權鄰接矩陣（DeBaTeR-A），其中定義了一個可靠性分數，透過軟指派和硬指派重新加權邊緣；第二個是透過重新加權損失函數（DeBaTeR-L），其中產生權重以重新加權損失中的使用者與項目樣本。已進行廣泛的實驗，以證明我們方法的有效性，並說明時間資訊確實有助於識別雜訊邊緣。

##### **LEAP:D -- A Novel Prompt-based Approach for Domain-Generalized Aerial Object Detection**
2411.09180v1 by Chanyeong Park, Heegwang Kim, Joonki Paik

Drone-captured images present significant challenges in object detection due
to varying shooting conditions, which can alter object appearance and shape.
Factors such as drone altitude, angle, and weather cause these variations,
influencing the performance of object detection algorithms. To tackle these
challenges, we introduce an innovative vision-language approach using learnable
prompts. This shift from conventional manual prompts aims to reduce
domain-specific knowledge interference, ultimately improving object detection
capabilities. Furthermore, we streamline the training process with a one-step
approach, updating the learnable prompt concurrently with model training,
enhancing efficiency without compromising performance. Our study contributes to
domain-generalized object detection by leveraging learnable prompts and
optimizing training processes. This enhances model robustness and adaptability
across diverse environments, leading to more effective aerial object detection.

摘要：無人機拍攝的影像在物體偵測方面面臨重大挑戰，原因在於拍攝條件多變，可能會改變物體的外觀和形狀。無人機高度、角度和天氣等因素會造成這些變化，影響物體偵測演算法的效能。為了應對這些挑戰，我們引進一種創新的視覺語言方法，使用可學習提示。這種從傳統手動提示的轉變旨在減少特定領域知識的干擾，最終提升物體偵測能力。此外，我們透過單步驟方法簡化訓練流程，在模型訓練的同時更新可學習提示，在不影響效能的情況下提升效率。我們的研究透過利用可學習提示和最佳化訓練流程，有助於領域概括的物體偵測。這增強了模型的穩健性和適應性，適用於各種環境，進而提升空中物體偵測的效能。

##### **Gazing at Rewards: Eye Movements as a Lens into Human and AI Decision-Making in Hybrid Visual Foraging**
2411.09176v1 by Bo Wang, Dingwei Tan, Yen-Ling Kuo, Zhaowei Sun, Jeremy M. Wolfe, Tat-Jen Cham, Mengmi Zhang

Imagine searching a collection of coins for quarters ($0.25$), dimes
($0.10$), nickels ($0.05$), and pennies ($0.01$)-a hybrid foraging task where
observers look for multiple instances of multiple target types. In such tasks,
how do target values and their prevalence influence foraging and eye movement
behaviors (e.g., should you prioritize rare quarters or common nickels)? To
explore this, we conducted human psychophysics experiments, revealing that
humans are proficient reward foragers. Their eye fixations are drawn to regions
with higher average rewards, fixation durations are longer on more valuable
targets, and their cumulative rewards exceed chance, approaching the upper
bound of optimal foragers. To probe these decision-making processes of humans,
we developed a transformer-based Visual Forager (VF) model trained via
reinforcement learning. Our VF model takes a series of targets, their
corresponding values, and the search image as inputs, processes the images
using foveated vision, and produces a sequence of eye movements along with
decisions on whether to collect each fixated item. Our model outperforms all
baselines, achieves cumulative rewards comparable to those of humans, and
approximates human foraging behavior in eye movements and foraging biases
within time-limited environments. Furthermore, stress tests on
out-of-distribution tasks with novel targets, unseen values, and varying set
sizes demonstrate the VF model's effective generalization. Our work offers
valuable insights into the relationship between eye movements and
decision-making, with our model serving as a powerful tool for further
exploration of this connection. All data, code, and models will be made
publicly available.

摘要：<paragraph>想像一下在硬幣集合中搜尋 25 美分（0.25 美元）、10 美分（0.10 美元）、5 美分（0.05 美元）和 1 美分（0.01 美元）的硬幣，這是一個混合覓食任務，觀察者尋找多個目標類型的多個實例。在這樣的任務中，目標價值及其普遍性如何影響覓食和眼睛運動行為（例如，你應該優先考慮稀有的 25 美分還是常見的 5 美分）？為了探討這一點，我們進行了人類心理物理學實驗，結果顯示人類是熟練的獎勵覓食者。他們的眼睛注視會被平均獎勵較高的區域吸引，注視時間在更有價值的目標上較長，而且他們的累積獎勵超過機會，接近最佳覓食者的上限。為了探討人類的這些決策制定過程，我們開發了一個基於Transformer的視覺覓食者 (VF) 模型，透過強化學習進行訓練。我們的 VF 模型採用一系列目標、其對應值和搜尋圖像作為輸入，使用注視視覺處理圖像，並產生一系列眼睛運動以及是否收集每個注視項目的決策。我們的模型優於所有基線，獲得與人類相當的累積獎勵，並在眼睛運動和時間限制環境中的覓食偏好中近似人類的覓食行為。此外，在具有新目標、未見值和不同設定大小的非分佈任務中進行的壓力測試證明了 VF 模型的有效概化。我們的研究提供了關於眼睛運動和決策制定之間關係的寶貴見解，我們的模型作為進一步探索這種聯繫的有力工具。所有資料、程式碼和模型都將公開提供。</paragraph>

##### **Advancing Diffusion Models: Alias-Free Resampling and Enhanced Rotational Equivariance**
2411.09174v1 by Md Fahim Anjum

Recent advances in image generation, particularly via diffusion models, have
led to impressive improvements in image synthesis quality. Despite this,
diffusion models are still challenged by model-induced artifacts and limited
stability in image fidelity. In this work, we hypothesize that the primary
cause of this issue is the improper resampling operation that introduces
aliasing in the diffusion model and a careful alias-free resampling dictated by
image processing theory can improve the model's performance in image synthesis.
We propose the integration of alias-free resampling layers into the UNet
architecture of diffusion models without adding extra trainable parameters,
thereby maintaining computational efficiency. We then assess whether these
theory-driven modifications enhance image quality and rotational equivariance.
Our experimental results on benchmark datasets, including CIFAR-10, MNIST, and
MNIST-M, reveal consistent gains in image quality, particularly in terms of FID
and KID scores. Furthermore, we propose a modified diffusion process that
enables user-controlled rotation of generated images without requiring
additional training. Our findings highlight the potential of theory-driven
enhancements such as alias-free resampling in generative models to improve
image quality while maintaining model efficiency and pioneer future research
directions to incorporate them into video-generating diffusion models, enabling
deeper exploration of the applications of alias-free resampling in generative
modeling.

摘要：影像生成技術的最新進展，特別是透過擴散模型，已大幅提升影像合成品質。儘管如此，擴散模型仍受限於模型引發的人工製品，且影像保真度穩定性有限。在這項工作中，我們假設此問題的主要原因是不適當的重新取樣運算，這會在擴散模型中引入混疊，而由影像處理理論指導的仔細無混疊重新取樣可以提升模型在影像合成的效能。我們建議將無混疊重新取樣層整合到擴散模型的 UNet 架構中，而無須增加額外的可訓練參數，進而維持運算效率。接著我們評估這些理論驅動的修改是否能提升影像品質和旋轉等變性。我們在基準資料集（包括 CIFAR-10、MNIST 和 MNIST-M）上的實驗結果顯示，影像品質獲得一致的提升，特別是在 FID 和 KID 分數方面。此外，我們提出一個修改過的擴散程序，它能讓使用者控制生成影像的旋轉，而無需額外訓練。我們的發現突顯了理論驅動的強化（例如無混疊重新取樣）在生成模型中的潛力，它能在維持模型效率的同時提升影像品質，並為未來研究開拓方向，將其納入生成影片的擴散模型中，進一步探索無混疊重新取樣在生成模型中的應用。

##### **Towards Scalable Handwriting Communication via EEG Decoding and Latent Embedding Integration**
2411.09170v1 by Jun-Young Kim, Deok-Seon Kim, Seo-Hyun Lee

In recent years, brain-computer interfaces have made advances in decoding
various motor-related tasks, including gesture recognition and movement
classification, utilizing electroencephalogram (EEG) data. These developments
are fundamental in exploring how neural signals can be interpreted to recognize
specific physical actions. This study centers on a written alphabet
classification task, where we aim to decode EEG signals associated with
handwriting. To achieve this, we incorporate hand kinematics to guide the
extraction of the consistent embeddings from high-dimensional neural recordings
using auxiliary variables (CEBRA). These CEBRA embeddings, along with the EEG,
are processed by a parallel convolutional neural network model that extracts
features from both data sources simultaneously. The model classifies nine
different handwritten characters, including symbols such as exclamation marks
and commas, within the alphabet. We evaluate the model using a quantitative
five-fold cross-validation approach and explore the structure of the embedding
space through visualizations. Our approach achieves a classification accuracy
of 91 % for the nine-class task, demonstrating the feasibility of fine-grained
handwriting decoding from EEG.

摘要：近年來，腦機介面在解碼各種與運動相關的任務方面取得進展，包括手勢辨識和動作分類，利用腦電圖 (EEG) 資料。這些發展在探索如何解釋神經訊號以辨識特定肢體動作方面具有根本性的意義。本研究重點在於書寫字母分類任務，我們旨在解碼與手寫相關的 EEG 訊號。為達成此目的，我們結合手部運動學來引導從高維神經記錄中萃取一致的嵌入，使用輔助變數 (CEBRA)。這些 CEBRA 嵌入與 EEG，由並行卷積神經網路模型處理，同時從兩個資料來源萃取特徵。此模型對九個不同的手寫字元進行分類，包括感嘆號和逗號等符號，在字母表中。我們使用定量的五重交叉驗證方法評估模型，並透過視覺化探索嵌入空間的結構。我們的做法對九類任務達到了 91% 的分類準確度，證明了從 EEG 中進行細緻手寫解碼的可行性。

##### **Artificial Theory of Mind and Self-Guided Social Organisation**
2411.09169v1 by Michael S. Harré, Jaime Ruiz-Serra, Catherine Drysdale

One of the challenges artificial intelligence (AI) faces is how a collection
of agents coordinate their behaviour to achieve goals that are not reachable by
any single agent. In a recent article by Ozmen et al this was framed as one of
six grand challenges: That AI needs to respect human cognitive processes at the
human-AI interaction frontier. We suggest that this extends to the AI-AI
frontier and that it should also reflect human psychology, as it is the only
successful framework we have from which to build out. In this extended abstract
we first make the case for collective intelligence in a general setting,
drawing on recent work from single neuron complexity in neural networks and ant
network adaptability in ant colonies. From there we introduce how species
relate to one another in an ecological network via niche selection, niche
choice, and niche conformity with the aim of forming an analogy with human
social network development as new agents join together and coordinate. From
there we show how our social structures are influenced by our neuro-physiology,
our psychology, and our language. This emphasises how individual people within
a social network influence the structure and performance of that network in
complex tasks, and that cognitive faculties such as Theory of Mind play a
central role. We finish by discussing the current state of the art in AI and
where there is potential for further development of a socially embodied
collective artificial intelligence that is capable of guiding its own social
structures.

摘要：人工智能 (AI) 所面临的挑戰之一，在於一組智能體如何協調其行為以達成單一智能體無法達成的目標。在 Ozmen 等人的一篇近期文章中，這被視為六大挑戰之一：AI 需要在人機互動前沿尊重人類的認知過程。我們認為這延伸到了 AI-AI 前沿，並且也應反映人類心理，因為這是我們用來建構的唯一成功架構。在此擴展摘要中，我們首先在一般設定中提出集體智慧的論點，並引用神經網路中單一神經元複雜性和螞蟻群落中螞蟻網路適應性的最新研究。從那裡，我們介紹物種如何透過利基選擇、利基選擇和利基適應在生態網路中相互關聯，目的是形成人類社交網路發展的類比，因為新的智能體會加入並協調。從那裡，我們展示我們的社會結構如何受到我們的生理、心理和語言的影響。這強調了社交網路中的個人如何影響網路在複雜任務中的結構和效能，以及心智理論等認知能力扮演著核心角色。最後，我們討論 AI 的現狀，以及社會化集體人工智能進一步發展的潛力，這種人工智能有能力引導其自身的社會結構。

##### **Unstructured Text Enhanced Open-domain Dialogue System: A Systematic Survey**
2411.09166v1 by Longxuan Ma, Mingda Li, Weinan Zhang, Jiapeng Li, Ting Liu

Incorporating external knowledge into dialogue generation has been proven to
benefit the performance of an open-domain Dialogue System (DS), such as
generating informative or stylized responses, controlling conversation topics.
In this article, we study the open-domain DS that uses unstructured text as
external knowledge sources (\textbf{U}nstructured \textbf{T}ext
\textbf{E}nhanced \textbf{D}ialogue \textbf{S}ystem, \textbf{UTEDS}). The
existence of unstructured text entails distinctions between UTEDS and
traditional data-driven DS and we aim to analyze these differences. We first
give the definition of the UTEDS related concepts, then summarize the recently
released datasets and models. We categorize UTEDS into Retrieval and Generative
models and introduce them from the perspective of model components. The
retrieval models consist of Fusion, Matching, and Ranking modules, while the
generative models comprise Dialogue and Knowledge Encoding, Knowledge
Selection, and Response Generation modules. We further summarize the evaluation
methods utilized in UTEDS and analyze the current models' performance. At last,
we discuss the future development trends of UTEDS, hoping to inspire new
research in this field.

摘要：將外部知識納入對話生成已被證明可以提升開放領域對話系統 (DS) 的效能，例如產生資訊豐富或有風格的回應、控制對話主題。在本文中，我們研究使用非結構化文字作為外部知識來源的開放領域 DS（非結構化文字增強對話系統，UTEDS）。非結構化文字的存在使得 UTEDS 與傳統的資料驅動 DS 有所區別，我們旨在分析這些差異。我們首先定義 UTEDS 相關概念，然後總結最近釋出的資料集和模型。我們將 UTEDS 分類為檢索和生成模型，並從模型組成的角度介紹它們。檢索模型包含融合、比對和排名模組，而生成模型包含對話和知識編碼、知識選擇和回應生成模組。我們進一步總結 UTEDS 中使用的評估方法，並分析當前模型的效能。最後，我們討論 UTEDS 未來的發展趨勢，希望能激勵此領域的新研究。

##### **Rationality based Innate-Values-driven Reinforcement Learning**
2411.09160v1 by Qin Yang

Innate values describe agents' intrinsic motivations, which reflect their
inherent interests and preferences to pursue goals and drive them to develop
diverse skills satisfying their various needs. The essence of reinforcement
learning (RL) is learning from interaction based on reward-driven behaviors,
much like natural agents. It is an excellent model to describe the
innate-values-driven (IV) behaviors of AI agents. Especially developing the
awareness of the AI agent through balancing internal and external utilities
based on its needs in different tasks is a crucial problem for individuals
learning to support AI agents integrating human society with safety and harmony
in the long term. This paper proposes a hierarchical compound intrinsic value
reinforcement learning model -- innate-values-driven reinforcement learning
termed IVRL to describe the complex behaviors of AI agents' interaction. We
formulated the IVRL model and proposed two IVRL models: DQN and A2C. By
comparing them with benchmark algorithms such as DQN, DDQN, A2C, and PPO in the
Role-Playing Game (RPG) reinforcement learning test platform VIZDoom, we
demonstrated that rationally organizing various individual needs can
effectively achieve better performance.

摘要：內在價值描述了代理人的內在動機，反映了他們追求目標和驅使他們發展滿足其各種需求的多樣技能的內在興趣和偏好。強化學習 (RL) 的本質是從基於獎勵驅動行為的互動中學習，很像自然代理人。這是一個描述 AI 代理人的內在價值驅動 (IV) 行為的優秀模型。特別是通過根據其在不同任務中的需求平衡內部和外部效用來發展 AI 代理人的認識，對於個人來說，長期學習支持 AI 代理人以安全和諧的方式融入人類社會至關重要。本文提出了一個分層複合內在價值強化學習模型——內在價值驅動強化學習，稱為 IVRL，用於描述 AI 代理人互動的複雜行為。我們制定了 IVRL 模型，並提出了兩個 IVRL 模型：DQN 和 A2C。通過在角色扮演遊戲 (RPG) 強化學習測試平台 VIZDoom 中將它們與 DQN、DDQN、A2C 和 PPO 等基準演算法進行比較，我們證明了合理組織各種個別需求可以有效地實現更好的效能。

##### **DROJ: A Prompt-Driven Attack against Large Language Models**
2411.09125v1 by Leyang Hu, Boran Wang

Large Language Models (LLMs) have demonstrated exceptional capabilities
across various natural language processing tasks. Due to their training on
internet-sourced datasets, LLMs can sometimes generate objectionable content,
necessitating extensive alignment with human feedback to avoid such outputs.
Despite massive alignment efforts, LLMs remain susceptible to adversarial
jailbreak attacks, which usually are manipulated prompts designed to circumvent
safety mechanisms and elicit harmful responses. Here, we introduce a novel
approach, Directed Rrepresentation Optimization Jailbreak (DROJ), which
optimizes jailbreak prompts at the embedding level to shift the hidden
representations of harmful queries towards directions that are more likely to
elicit affirmative responses from the model. Our evaluations on LLaMA-2-7b-chat
model show that DROJ achieves a 100\% keyword-based Attack Success Rate (ASR),
effectively preventing direct refusals. However, the model occasionally
produces repetitive and non-informative responses. To mitigate this, we
introduce a helpfulness system prompt that enhances the utility of the model's
responses. Our code is available at
https://github.com/Leon-Leyang/LLM-Safeguard.

摘要：大型語言模型 (LLM) 已在各種自然語言處理任務中展現出非凡的能力。由於在網際網路來源的資料集上進行訓練，LLM 有時會產生令人反感的內容，因此需要大量比對人類回饋，以避免此類輸出。儘管進行了大量比對工作，LLM 仍然容易受到對抗性越獄攻擊，這通常是為了規避安全機制和引發有害回應而設計的操縱提示。在此，我們介紹一種新方法，即定向表示最佳化越獄 (DROJ)，它在嵌入層最佳化越獄提示，以將有害查詢的隱藏表示轉移到更可能從模型引發肯定回應的方向。我們對 LLaMA-2-7b-chat 模型的評估顯示，DROJ 達到了 100% 基於關鍵字的攻擊成功率 (ASR)，有效防止直接拒絕。然而，該模型偶爾會產生重複且無意義的回應。為了減輕這個問題，我們引入了有助益的系統提示，以增強模型回應的效用。我們的程式碼可在 https://github.com/Leon-Leyang/LLM-Safeguard 取得。

##### **P-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of LLMs**
2411.09116v1 by Yidan Zhang, Boyi Deng, Yu Wan, Baosong Yang, Haoran Wei, Fei Huang, Bowen Yu, Junyang Lin, Fei Huang, Jingren Zhou

Recent advancements in large language models (LLMs) showcase varied
multilingual capabilities across tasks like translation, code generation, and
reasoning. Previous assessments often limited their scope to fundamental
natural language processing (NLP) or isolated capability-specific tasks. To
alleviate this drawback, we aim to present a comprehensive multilingual
multitask benchmark. First, we present a pipeline for selecting available and
reasonable benchmarks from massive ones, addressing the oversight in previous
work regarding the utility of these benchmarks, i.e., their ability to
differentiate between models being evaluated. Leveraging this pipeline, we
introduce P-MMEval, a large-scale benchmark covering effective fundamental and
capability-specialized datasets. Furthermore, P-MMEval delivers consistent
language coverage across various datasets and provides parallel samples.
Finally, we conduct extensive experiments on representative multilingual model
series to compare performances across models, analyze dataset effectiveness,
examine prompt impacts on model performances, and explore the relationship
between multilingual performances and factors such as tasks, model sizes, and
languages. These insights offer valuable guidance for future research. The
dataset is available at https://huggingface.co/datasets/Qwen/P-MMEval.

摘要：大型語言模型 (LLM) 的最新進展展示了在翻譯、程式碼產生和推理等任務上的多種多語能力。先前的評估通常將其範圍限制在基本的自然語言處理 (NLP) 或孤立的能力特定任務。為了減輕這個缺點，我們旨在提出一個全面的多語言多任務基準。首先，我們提出了一個管道，用於從大量的基準中選擇可用且合理的基準，解決先前工作中關於這些基準的效用（即它們區分正在評估的模型的能力）的疏忽。利用這個管道，我們引入了 P-MMEval，一個涵蓋有效的基本和能力專用資料集的大規模基準。此外，P-MMEval 在各種資料集上提供了一致的語言覆蓋範圍，並提供並行範例。最後，我們對具代表性的多語言模型系列進行了廣泛的實驗，以比較模型之間的效能、分析資料集的有效性、檢查提示對模型效能的影響，並探討多語言效能與任務、模型大小和語言等因素之間的關係。這些見解為未來的研究提供了有價值的指導。資料集可在 https://huggingface.co/datasets/Qwen/P-MMEval 取得。

##### **Personalized Help for Optimizing Low-Skilled Users' Strategy**
2411.09109v1 by Feng Gu, Wichayaporn Wongkamjan, Jordan Lee Boyd-Graber, Jonathan K. Kummerfeld, Denis Peskoff, Jonathan May

AIs can beat humans in game environments; however, how helpful those agents
are to human remains understudied. We augment CICERO, a natural language agent
that demonstrates superhuman performance in Diplomacy, to generate both move
and message advice based on player intentions. A dozen Diplomacy games with
novice and experienced players, with varying advice settings, show that some of
the generated advice is beneficial. It helps novices compete with experienced
players and in some instances even surpass them. The mere presence of advice
can be advantageous, even if players do not follow it.

摘要：人工智能可以在遊戲環境中擊敗人類；然而，這些代理對人類的幫助程度尚未得到充分研究。我們擴充了 CICERO，一個在外交事務中展現出超人類表現的自然語言代理，以根據玩家意圖產生移動和訊息建議。十幾場外交事務遊戲，包括新手和經驗豐富的玩家，並採用不同的建議設定，顯示出一些產生的建議是有益的。它幫助新手與經驗豐富的玩家競爭，在某些情況下甚至超越他們。即使玩家不遵循建議，僅僅有建議的存在也會是有利的。

##### **VCBench: A Controllable Benchmark for Symbolic and Abstract Challenges in Video Cognition**
2411.09105v1 by Chenglin Li, Qianglong Chen, Zhi Li, Feng Tao, Yin Zhang

Recent advancements in Large Video-Language Models (LVLMs) have driven the
development of benchmarks designed to assess cognitive abilities in video-based
tasks. However, most existing benchmarks heavily rely on web-collected videos
paired with human annotations or model-generated questions, which limit control
over the video content and fall short in evaluating advanced cognitive
abilities involving symbolic elements and abstract concepts. To address these
limitations, we introduce VCBench, a controllable benchmark to assess LVLMs'
cognitive abilities, involving symbolic and abstract concepts at varying
difficulty levels. By generating video data with the Python-based engine,
VCBench allows for precise control over the video content, creating dynamic,
task-oriented videos that feature complex scenes and abstract concepts. Each
task pairs with tailored question templates that target specific cognitive
challenges, providing a rigorous evaluation test. Our evaluation reveals that
even state-of-the-art (SOTA) models, such as Qwen2-VL-72B, struggle with simple
video cognition tasks involving abstract concepts, with performance sharply
dropping by 19% as video complexity rises. These findings reveal the current
limitations of LVLMs in advanced cognitive tasks and highlight the critical
role of VCBench in driving research toward more robust LVLMs for complex video
cognition challenges.

摘要：大型视频语言模型 (LVLMs) 的最新进展推动了基准测试的发展，旨在评估基于视频的任务中的认知能力。然而，大多数现有的基准测试严重依赖于与人工注释或模型生成的问题配对的网络收集的视频，这限制了对视频内容的控制，并且无法评估涉及符号元素和抽象概念的高级认知能力。为了解决这些限制，我们引入了 VCBench，这是一个可控基准测试，用于评估 LVLMs 的认知能力，涉及不同难度级别的符号和抽象概念。通过使用基于 Python 的引擎生成视频数据，VCBench 可以精确控制视频内容，创建动态、面向任务的视频，这些视频具有复杂场景和抽象概念。每个任务都与针对特定认知挑战的定制问题模板配对，提供严格的评估测试。我们的评估表明，即使是 Qwen2-VL-72B 等最先进 (SOTA) 模型，在涉及抽象概念的简单视频认知任务中也存在困难，随着视频复杂性的增加，性能急剧下降 19%。这些发现揭示了 LVLMs 在高级认知任务中的当前局限性，并强调了 VCBench 在推动研究朝着更强大的 LVLMs 以应对复杂视频认知挑战方面发挥的关键作用。

##### **Provocation: Who benefits from "inclusion" in Generative AI?**
2411.09102v1 by Nari Johnson, Siobhan Mackenzie Hall, Samantha Dalal

The demands for accurate and representative generative AI systems means there
is an increased demand on participatory evaluation structures. While these
participatory structures are paramount to to ensure non-dominant values,
knowledge and material culture are also reflected in AI models and the media
they generate, we argue that dominant structures of community participation in
AI development and evaluation are not explicit enough about the benefits and
harms that members of socially marginalized groups may experience as a result
of their participation. Without explicit interrogation of these benefits by AI
developers, as a community we may remain blind to the immensity of systemic
change that is needed as well. To support this provocation, we present a
speculative case study, developed from our own collective experiences as AI
researchers. We use this speculative context to itemize the barriers that need
to be overcome in order for the proposed benefits to marginalized communities
to be realized, and harms mitigated.

摘要：準確且具有代表性的生成式 AI 系統的需求，表示對於參與式評估結構的需求也隨之增加。雖然這些參與式結構對於確保非主流價值觀、知識和物質文化也能反映在 AI 模型和它們所生成的媒體中至關重要，但我們認為，AI 開發和評估中社群參與的主流結構並未明確說明社會邊緣化群體的成員可能會因參與而獲得的利益和損害。如果 AI 開發者未明確審視這些利益，我們這個社群可能會對系統性變革的廣大需求視而不見。為了支持這種挑釁，我們提出一個推測性的案例研究，這個研究是根據我們作為 AI 研究人員的集體經驗所發展出來的。我們使用這個推測性的脈絡來細目列出必須克服的障礙，才能讓邊緣化社群獲得建議的利益，並減輕損害。

##### **Heuristical Comparison of Vision Transformers Against Convolutional Neural Networks for Semantic Segmentation on Remote Sensing Imagery**
2411.09101v1 by Ashim Dahal, Saydul Akbar Murad, Nick Rahimi

Vision Transformers (ViT) have recently brought a new wave of research in the
field of computer vision. These models have done particularly well in the field
of image classification and segmentation. Research on semantic and instance
segmentation has emerged to accelerate with the inception of the new
architecture, with over 80\% of the top 20 benchmarks for the iSAID dataset
being either based on the ViT architecture or the attention mechanism behind
its success. This paper focuses on the heuristic comparison of three key
factors of using (or not using) ViT for semantic segmentation of remote sensing
aerial images on the iSAID. The experimental results observed during the course
of the research were under the scrutinization of the following objectives: 1.
Use of weighted fused loss function for the maximum mean Intersection over
Union (mIoU) score, Dice score, and minimization or conservation of entropy or
class representation, 2. Comparison of transfer learning on Meta's MaskFormer,
a ViT-based semantic segmentation model, against generic UNet Convolutional
Neural Networks (CNNs) judged over mIoU, Dice scores, training efficiency, and
inference time, and 3. What do we lose for what we gain? i.e., the comparison
of the two models against current state-of-art segmentation models. We show the
use of the novel combined weighted loss function significantly boosts the CNN
model's performance capacities as compared to transfer learning the ViT. The
code for this implementation can be found on
\url{https://github.com/ashimdahal/ViT-vs-CNN-ImageSegmentation}.

摘要：視覺Transformer (ViT) 近期為電腦視覺領域帶來了新一波研究熱潮。這些模型在影像分類和分割領域表現特別出色。語意和實例分割的研究在這個新架構出現後加速發展，在 iSAID 資料集的 20 個頂尖基準中，有超過 80% 是基於 ViT 架構或其成功背後的注意力機制。本文重點比較三個關鍵因素，探討在 iSAID 上使用 (或不使用) ViT 進行遙測航照影像語意分割的啟發式方法。研究過程中觀察到的實驗結果經過以下目標的仔細檢視：1. 使用加權融合損失函數，以取得最大的平均交集並聯 (mIoU) 分數、Dice 分數，以及最小化或保存熵或類別表示；2. 比較在 Meta 的 MaskFormer（一個基於 ViT 的語意分割模型）上進行遷移學習，以及在通用 UNet 捲積神經網路 (CNN) 上進行遷移學習，並根據 mIoU、Dice 分數、訓練效率和推論時間進行評斷；以及 3. 我們為了獲得什麼而失去了什麼？也就是說，比較這兩個模型與目前最先進的分割模型。我們展示了使用新穎的結合加權損失函數，大幅提升了 CNN 模型的效能，相較於遷移學習 ViT。這個實作的程式碼可以在 \url{https://github.com/ashimdahal/ViT-vs-CNN-ImageSegmentation} 找到。

##### **Drone Detection using Deep Neural Networks Trained on Pure Synthetic Data**
2411.09077v1 by Mariusz Wisniewski, Zeeshan A. Rana, Ivan Petrunin, Alan Holt, Stephen Harman

Drone detection has benefited from improvements in deep neural networks, but
like many other applications, suffers from the availability of accurate data
for training. Synthetic data provides a potential for low-cost data generation
and has been shown to improve data availability and quality. However, models
trained on synthetic datasets need to prove their ability to perform on
real-world data, known as the problem of sim-to-real transferability. Here, we
present a drone detection Faster-RCNN model trained on a purely synthetic
dataset that transfers to real-world data. We found that it achieves an AP_50
of 97.0% when evaluated on the MAV-Vid - a real dataset of flying drones -
compared with 97.8% for an equivalent model trained on real-world data. Our
results show that using synthetic data for drone detection has the potential to
reduce data collection costs and improve labelling quality. These findings
could be a starting point for more elaborate synthetic drone datasets. For
example, realistic recreations of specific scenarios could de-risk the dataset
generation of safety-critical applications such as the detection of drones at
airports. Further, synthetic data may enable reliable drone detection systems,
which could benefit other areas, such as unmanned traffic management systems.
The code is available
https://github.com/mazqtpopx/cranfield-synthetic-drone-detection alongside the
datasets
https://huggingface.co/datasets/mazqtpopx/cranfield-synthetic-drone-detection.

摘要：無人機偵測受益於深度神經網路的進步，但與許多其他應用程式一樣，會受到準確訓練資料取得的影響。合成資料提供了低成本資料生成的可能性，並已證明可提升資料的取得和品質。然而，在合成資料集上訓練的模型需要證明其在真實世界資料上執行任務的能力，這便是類比到真實轉移性的問題。在此，我們提出一個純粹在合成資料集上訓練的無人機偵測 Faster-RCNN 模型，並轉移至真實世界資料。我們發現，在 MAV-Vid（一個真實的飛行無人機資料集）上評估時，它達到了 97.0% 的 AP_50，而使用真實世界資料訓練的等效模型則為 97.8%。我們的結果顯示，將合成資料用於無人機偵測有潛力降低資料收集成本並提升標籤品質。這些發現可以作為更精緻的合成無人機資料集的起點。例如，特定場景的逼真重建可以降低資料集生成的安全關鍵應用程式的風險，例如機場的無人機偵測。此外，合成資料可以建構可靠的無人機偵測系統，這可以讓其他領域受惠，例如無人交通管理系統。程式碼可於 https://github.com/mazqtpopx/cranfield-synthetic-drone-detection 取得，資料集則可於 https://huggingface.co/datasets/mazqtpopx/cranfield-synthetic-drone-detection 取得。

##### **Code-mixed LLM: Improve Large Language Models' Capability to Handle Code-Mixing through Reinforcement Learning from AI Feedback**
2411.09073v1 by Wenbo Zhang, Aditya Majumdar, Amulya Yadav

Code-mixing(CM) or code-switching(CSW) refers to the juxtaposition of
linguistic units from two or more languages during the conversation or
sometimes even a single utterance. Code-mixing introduces unique challenges in
daily life, such as syntactic mismatches and semantic blending, that are rarely
encountered in monolingual settings. Large language models (LLMs) have
revolutionized the field of natural language processing (NLP) by offering
unprecedented capabilities in understanding human languages. However, the
effectiveness of current state-of-the-art multilingual LLMs has not yet been
fully explored in the CM scenario. To fill this gap, we first benchmark the
performance of multilingual LLMs on various code-mixing NLP tasks. Then we
propose to improve the multilingual LLMs' ability to understand code-mixing
through reinforcement learning from human feedback (RLHF) and code-mixed
machine translation tasks. Given the high-cost and time-consuming preference
labeling procedure, we improve this by utilizing LLMs as annotators to perform
the reinforcement learning from AI feedback (RLAIF). The experiments show the
effectiveness of the proposed method.

摘要：代碼混合（CM）或代碼轉換（CSW）是指在對話中或有時甚至單一語句中並置來自兩種或更多語言的語言單位。代碼混合在日常生活中引入了獨特的挑戰，例如語法不匹配和語義混合，這在單語環境中很少遇到。大型語言模型 (LLM) 通過提供理解人類語言的空前能力，徹底改變了自然語言處理 (NLP) 領域。然而，當前最先進的多語種 LLM 的有效性尚未在 CM 場景中得到充分探索。為了填補這一空白，我們首先對多語種 LLM 在各種代碼混合 NLP 任務上的性能進行基準測試。然後，我們建議通過人類反饋（RLHF）和代碼混合機器翻譯任務的強化學習來提高多語種 LLM 理解代碼混合的能力。鑑於高成本和耗時的偏好標籤程序，我們通過利用 LLM 作為註釋者來執行 AI 反饋（RLAIF）的強化學習來改進這一點。實驗表明了所提出方法的有效性。

##### **Liner Shipping Network Design with Reinforcement Learning**
2411.09068v1 by Utsav Dutta, Yifan Lin, Zhaoyang Larry Jin

This paper proposes a novel reinforcement learning framework to address the
Liner Shipping Network Design Problem (LSNDP), a challenging combinatorial
optimization problem focused on designing cost-efficient maritime shipping
routes. Traditional methods for solving the LSNDP typically involve decomposing
the problem into sub-problems, such as network design and multi-commodity flow,
which are then tackled using approximate heuristics or large neighborhood
search (LNS) techniques. In contrast, our approach employs a model-free
reinforcement learning algorithm on the network design, integrated with a
heuristic-based multi-commodity flow solver, to produce competitive results on
the publicly available LINERLIB benchmark. Additionally, our method also
demonstrates generalization capabilities by producing competitive solutions on
the benchmark instances after training on perturbed instances.

摘要：本文提出了一個新穎的強化學習框架來解決班輪網路設計問題 (LSNDP)，這是一個專注於設計具有成本效益的海運航線的具有挑戰性的組合優化問題。解決 LSNDP 的傳統方法通常涉及將問題分解為子問題，例如網路設計和多商品流，然後使用近似啟發式或大鄰域搜尋 (LNS) 技術來解決。相比之下，我們的做法在網路設計上採用了無模型強化學習演算法，並與基於啟發式的多商品流求解器整合，在公開的 LINERLIB 基準上產生了具有競爭力的結果。此外，我們的演算法還展示了泛化能力，在經過擾動實例訓練後，在基準實例上產生了具有競爭力的解。

##### **Language-Model Prior Overcomes Cold-Start Items**
2411.09065v1 by Shiyu Wang, Hao Ding, Yupeng Gu, Sergul Aydore, Kousha Kalantari, Branislav Kveton

The growth of recommender systems (RecSys) is driven by digitization and the
need for personalized content in areas such as e-commerce and video streaming.
The content in these systems often changes rapidly and therefore they
constantly face the ongoing cold-start problem, where new items lack
interaction data and are hard to value. Existing solutions for the cold-start
problem, such as content-based recommenders and hybrid methods, leverage item
metadata to determine item similarities. The main challenge with these methods
is their reliance on structured and informative metadata to capture detailed
item similarities, which may not always be available. This paper introduces a
novel approach for cold-start item recommendation that utilizes the language
model (LM) to estimate item similarities, which are further integrated as a
Bayesian prior with classic recommender systems. This approach is generic and
able to boost the performance of various recommenders. Specifically, our
experiments integrate it with both sequential and collaborative filtering-based
recommender and evaluate it on two real-world datasets, demonstrating the
enhanced performance of the proposed approach.

摘要：推薦系統 (RecSys) 的成長是由數位化和電子商務與串流影音等領域對個人化內容的需求所推動。這些系統中的內容經常快速變動，因此持續面臨持續的冷啟動問題，其中新項目缺乏互動資料，難以評估價值。現有的冷啟動問題解決方案，例如基於內容的推薦系統和混合方法，利用項目元資料來判斷項目相似性。這些方法的主要挑戰在於依賴結構化且有資訊性的元資料來擷取詳細的項目相似性，而這些相似性可能無法隨時取得。本文介紹一種冷啟動項目推薦的新穎方法，利用語言模型 (LM) 來估計項目相似性，進一步將其整合為貝氏先驗與傳統推薦系統。這種方法是通用的，能夠提升各種推薦系統的效能。具體來說，我們的實驗將其整合到基於順序和協同過濾的推薦系統中，並在兩個真實世界的資料集上評估它，證明了所提出的方法的效能提升。

##### **Multimodal Object Detection using Depth and Image Data for Manufacturing Parts**
2411.09062v1 by Nazanin Mahjourian, Vinh Nguyen

Manufacturing requires reliable object detection methods for precise picking
and handling of diverse types of manufacturing parts and components.
Traditional object detection methods utilize either only 2D images from cameras
or 3D data from lidars or similar 3D sensors. However, each of these sensors
have weaknesses and limitations. Cameras do not have depth perception and 3D
sensors typically do not carry color information. These weaknesses can
undermine the reliability and robustness of industrial manufacturing systems.
To address these challenges, this work proposes a multi-sensor system combining
an red-green-blue (RGB) camera and a 3D point cloud sensor. The two sensors are
calibrated for precise alignment of the multimodal data captured from the two
hardware devices. A novel multimodal object detection method is developed to
process both RGB and depth data. This object detector is based on the Faster
R-CNN baseline that was originally designed to process only camera images. The
results show that the multimodal model significantly outperforms the depth-only
and RGB-only baselines on established object detection metrics. More
specifically, the multimodal model improves mAP by 13% and raises Mean
Precision by 11.8% in comparison to the RGB-only baseline. Compared to the
depth-only baseline, it improves mAP by 78% and raises Mean Precision by 57%.
Hence, this method facilitates more reliable and robust object detection in
service to smart manufacturing applications.

摘要：製造業需要可靠的物件偵測方法，以精準地挑選和處理種類繁多的製造零件和組件。
傳統的物件偵測方法僅使用相機的 2D 影像或雷達或類似 3D 感測器的 3D 資料。然而，這些感測器各自都有缺點和限制。相機沒有深度感知，而 3D 感測器通常不具備色彩資訊。這些缺點會損害工業製造系統的可靠性和穩健性。
為了解決這些挑戰，本研究提出了一個多感測器系統，結合紅綠藍 (RGB) 相機和 3D 點雲感測器。這兩個感測器經過校正，以精準對齊從這兩個硬體裝置擷取的多模式資料。開發了一種新穎的多模式物件偵測方法，以處理 RGB 和深度資料。這個物件偵測器基於 Faster R-CNN 基線，而 Faster R-CNN 基線最初是設計來僅處理相機影像。
結果顯示，多模式模型在既定的物件偵測指標上明顯優於僅深度和僅 RGB 的基線。更具體來說，與僅 RGB 的基線相比，多模式模型將 mAP 提升了 13%，並將平均準確度提高了 11.8%。與僅深度基線相比，它將 mAP 提升了 78%，並將平均準確度提高了 57%。
因此，此方法有助於在智慧製造應用中實現更可靠和穩健的物件偵測。

##### **SAFELOC: Overcoming Data Poisoning Attacks in Heterogeneous Federated Machine Learning for Indoor Localization**
2411.09055v1 by Akhil Singampalli, Danish Gufran, Sudeep Pasricha

Machine learning (ML) based indoor localization solutions are critical for
many emerging applications, yet their efficacy is often compromised by
hardware/software variations across mobile devices (i.e., device heterogeneity)
and the threat of ML data poisoning attacks. Conventional methods aimed at
countering these challenges show limited resilience to the uncertainties
created by these phenomena. In response, in this paper, we introduce SAFELOC, a
novel framework that not only minimizes localization errors under these
challenging conditions but also ensures model compactness for efficient mobile
device deployment. Our framework targets a distributed and co-operative
learning environment that uses federated learning (FL) to preserve user data
privacy and assumes heterogeneous mobile devices carried by users (just like in
most real-world scenarios). Within this heterogeneous FL context, SAFELOC
introduces a novel fused neural network architecture that performs data
poisoning detection and localization, with a low model footprint. Additionally,
a dynamic saliency map-based aggregation strategy is designed to adapt based on
the severity of the detected data poisoning scenario. Experimental evaluations
demonstrate that SAFELOC achieves improvements of up to 5.9x in mean
localization error, 7.8x in worst-case localization error, and a 2.1x reduction
in model inference latency compared to state-of-the-art indoor localization
frameworks, across diverse building floorplans, mobile devices, and ML data
poisoning attack scenarios.

摘要：基於機器學習 (ML) 的室內定位解決方案對於許多新興應用至關重要，但其效能常常受到行動裝置間的硬體/軟體差異（即裝置異質性）和 ML 資料中毒攻擊的威脅而受損。針對這些挑戰的傳統方法顯示出對這些現象所造成的變數具有有限的韌性。為了解決這個問題，我們在本文中介紹 SAFELOC，這是一個新穎的架構，它不僅在這些具有挑戰性的條件下將定位誤差降至最低，而且還確保模型緊湊性以進行有效的行動裝置部署。我們的架構目標是一個分散且合作的學習環境，它使用聯合學習 (FL) 來保護使用者資料隱私，並假設使用者攜帶異質行動裝置（就像在大多數真實世界場景中一樣）。在這個異質的 FL 背景下，SAFELOC 引入了一種新穎的融合神經網路架構，它執行資料中毒偵測和定位，並具有低模型佔用空間。此外，動態顯著性圖聚合策略旨在根據偵測到的資料中毒情境的嚴重性進行調整。實驗評估證明，與最先進的室內定位架構相比，SAFELOC 在平均定位誤差方面提高了 5.9 倍，在最差情況定位誤差方面提高了 7.8 倍，並且模型推論延遲減少了 2.1 倍，涵蓋了不同的建築平面圖、行動裝置和 ML 資料中毒攻擊情境。

##### **The Systems Engineering Approach in Times of Large Language Models**
2411.09050v1 by Christian Cabrera, Viviana Bastidas, Jennifer Schooling, Neil D. Lawrence

Using Large Language Models (LLMs) to address critical societal problems
requires adopting this novel technology into socio-technical systems. However,
the complexity of such systems and the nature of LLMs challenge such a vision.
It is unlikely that the solution to such challenges will come from the
Artificial Intelligence (AI) community itself. Instead, the Systems Engineering
approach is better equipped to facilitate the adoption of LLMs by prioritising
the problems and their context before any other aspects. This paper introduces
the challenges LLMs generate and surveys systems research efforts for
engineering AI-based systems. We reveal how the systems engineering principles
have supported addressing similar issues to the ones LLMs pose and discuss our
findings to provide future directions for adopting LLMs.

摘要：使用大型語言模型 (LLM) 來解決重大的社會問題
需要將這項新技術納入社會技術系統中。然而，
此類系統的複雜性和 LLM 的性質對此願景構成挑戰。
不太可能由
人工智慧 (AI) 社群本身提出解決此類挑戰的方案。相反地，系統工程
方法更能促進 LLM 的採用，方法是在優先考量問題及其脈絡之前，先考量其他面向。本文介紹
LLM 產生的挑戰，並調查了工程人工智慧系統的系統研究工作。我們揭示了系統工程原則
如何協助解決與 LLM 相似的問題，並討論我們的發現，以提供未來採用 LLM 的方向。

##### **Bridging the Visual Gap: Fine-Tuning Multimodal Models with Knowledge-Adapted Captions**
2411.09018v1 by Moran Yanuka, Assaf Ben Kish, Yonatan Bitton, Idan Szpektor, Raja Giryes

Recent research increasingly focuses on training vision-language models
(VLMs) with long, detailed image captions. However, small-scale VLMs often
struggle to balance the richness of these captions with the risk of
hallucinating content during fine-tuning. In this paper, we explore how well
VLMs adapt to such captions. To quantify caption quality, we propose Decomposed
NLI (DNLI), an evaluation framework that breaks down generated captions into
individual propositions, assessing each in isolation. This fine-grained
analysis reveals a critical balance between capturing descriptive details and
preventing hallucinations. Our findings show that simply reducing caption
complexity or employing standard data curation techniques does not effectively
resolve this issue. To tackle this challenge, we introduce Knowledge Adapted
(KnowAda) fine-tuning, a data-centric approach that automatically adapts
training data with the model's existing knowledge and visual understanding.
KnowAda minimizes hallucinations while preserving high descriptiveness. We
validate this approach across several small-scale VLMs (up to 7B parameters)
and dense caption datasets, demonstrating that KnowAda effectively balances
hallucination reduction and descriptiveness. Our results show that KnowAda
outperforms various baselines in both automatic metrics and human evaluations.
We will release our code and models.

摘要：近期研究越来越专注于使用长而详细的图像标题来训练视觉语言模型 (VLM)。然而，小规模 VLM 经常在微调期间平衡这些标题的丰富性与出现幻觉内容的风险时遇到困难。在本文中，我们探讨 VLM 如何适应此类标题。为了量化标题质量，我们提出了分解自然语言推理 (DNLI)，这是一种评估框架，它将生成的标题分解为各个命题，并分别评估每个命题。这种细粒度分析揭示了捕捉描述性细节和防止出现幻觉之间的关键平衡。我们的研究结果表明，仅仅降低标题复杂性或采用标准的数据整理技术并不能有效解决此问题。为了应对这一挑战，我们引入了知识自适应 (KnowAda) 微调，这是一种以数据为中心的方法，它使用模型的现有知识和视觉理解来自动调整训练数据。KnowAda 最大程度地减少了幻觉，同时保留了高度描述性。我们通过几个小规模 VLM（最多 7B 个参数）和密集标题数据集验证了这种方法，证明 KnowAda 有效地平衡了幻觉减少和描述性。我们的结果表明，KnowAda 在自动指标和人工评估中都优于各种基线。我们将发布我们的代码和模型。

##### **Cut Your Losses in Large-Vocabulary Language Models**
2411.09009v1 by Erik Wijmans, Brody Huval, Alexander Hertzberg, Vladlen Koltun, Philipp Krähenbühl

As language models grow ever larger, so do their vocabularies. This has
shifted the memory footprint of LLMs during training disproportionately to one
single layer: the cross-entropy in the loss computation. Cross-entropy builds
up a logit matrix with entries for each pair of input tokens and vocabulary
items and, for small models, consumes an order of magnitude more memory than
the rest of the LLM combined. We propose Cut Cross-Entropy (CCE), a method that
computes the cross-entropy loss without materializing the logits for all tokens
into global memory. Rather, CCE only computes the logit for the correct token
and evaluates the log-sum-exp over all logits on the fly. We implement a custom
kernel that performs the matrix multiplications and the log-sum-exp reduction
over the vocabulary in flash memory, making global memory consumption for the
cross-entropy computation negligible. This has a dramatic effect. Taking the
Gemma 2 (2B) model as an example, CCE reduces the memory footprint of the loss
computation from 24 GB to 1 MB, and the total training-time memory consumption
of the classifier head from 28 GB to 1 GB. To improve the throughput of CCE, we
leverage the inherent sparsity of softmax and propose to skip elements of the
gradient computation that have a negligible (i.e., below numerical precision)
contribution to the gradient. Experiments demonstrate that the dramatic
reduction in memory consumption is accomplished without sacrificing training
speed or convergence.

摘要：隨著語言模型越來越龐大，其詞彙量也隨之增加。這使得大型語言模型在訓練期間的記憶體使用量不成比例地轉移到單一層：損失計算中的交叉熵。交叉熵建立一個對數機率矩陣，其中包含輸入 token 和詞彙項目每對的條目，對於小型模型，其消耗的記憶體數量級高於大型語言模型其他部分的總和。我們提出切斷交叉熵 (CCE)，這是一種在不將所有 token 的對數機率實體化到全域記憶體中情況下計算交叉熵損失的方法。相反，CCE 僅計算正確 token 的對數機率，並即時評估所有對數機率的對數和指數。我們實作一個自訂核，在快閃記憶體中執行矩陣乘法和對數和指數約簡，使交叉熵計算的全域記憶體消耗可以忽略不計。這有顯著的效果。以 Gemma 2 (2B) 模型為例，CCE 將損失計算的記憶體使用量從 24 GB 減少到 1 MB，並將分類器頭的總訓練時間記憶體消耗從 28 GB 減少到 1 GB。為了提高 CCE 的處理量，我們利用 softmax 的內在稀疏性，並建議跳過對梯度貢獻可以忽略不計（即低於數值精度）的梯度計算元素。實驗證明，在不犧牲訓練速度或收斂性的情況下，可以大幅減少記憶體消耗。

##### **Refusal in LLMs is an Affine Function**
2411.09003v1 by Thomas Marshall, Adam Scherlis, Nora Belrose

We propose affine concept editing (ACE) as an approach for steering language
models' behavior by intervening directly in activations. We begin with an
affine decomposition of model activation vectors and show that prior methods
for steering model behavior correspond to subsets of terms of this
decomposition. We then provide a derivation of ACE and test it on refusal using
Llama 3 8B and Hermes Eagle RWKV v5. ACE ultimately combines affine subspace
projection and activation addition to reliably control the model's refusal
responses across prompt types. We evaluate the results using LLM-based scoring
on a collection of harmful and harmless prompts. Our experiments demonstrate
that ACE consistently achieves more precise control over model behavior and
generalizes to models where directional ablation via affine subspace projection
alone produces incoherent outputs. Code for reproducing our results is
available at https://github.com/EleutherAI/steering-llama3 .

摘要：我們提出仿射概念編輯 (ACE)，作為一種透過直接介入激勵來引導語言模型行為的方法。我們從模型激勵向量的仿射分解開始，並顯示出引導模型行為的先前方法對應於此分解的子集。然後，我們提供 ACE 的推導，並使用 Llama 3 8B 和 Hermes Eagle RWKV v5 對拒絕進行測試。ACE 最終結合仿射子空間投影和激勵加法，以可靠地控制模型在提示類型中的拒絕回應。我們使用基於 LLM 的評分對有害和無害提示的集合進行評估。我們的實驗表明，ACE 持續對模型行為實現更精確的控制，並推廣到僅透過仿射子空間投影進行方向性消融會產生不連貫輸出的模型。可用於重現我們結果的程式碼位於 https://github.com/EleutherAI/steering-llama3。

##### **IDCIA: Immunocytochemistry Dataset for Cellular Image Analysis**
2411.08992v1 by Abdurahman Ali Mohammed, Catherine Fonder, Donald S. Sakaguchi, Wallapak Tavanapong, Surya K. Mallapragada, Azeez Idris

We present a new annotated microscopic cellular image dataset to improve the
effectiveness of machine learning methods for cellular image analysis. Cell
counting is an important step in cell analysis. Typically, domain experts
manually count cells in a microscopic image. Automated cell counting can
potentially eliminate this tedious, time-consuming process. However, a good,
labeled dataset is required for training an accurate machine learning model.
Our dataset includes microscopic images of cells, and for each image, the cell
count and the location of individual cells. The data were collected as part of
an ongoing study investigating the potential of electrical stimulation to
modulate stem cell differentiation and possible applications for neural repair.
Compared to existing publicly available datasets, our dataset has more images
of cells stained with more variety of antibodies (protein components of immune
responses against invaders) typically used for cell analysis. The experimental
results on this dataset indicate that none of the five existing models under
this study are able to achieve sufficiently accurate count to replace the
manual methods. The dataset is available at
https://figshare.com/articles/dataset/Dataset/21970604.

摘要：<paragraph>我們提供一個新的註解式微觀細胞影像資料集，以提高機器學習方法在細胞影像分析方面的效能。細胞計數是細胞分析中的一項重要步驟。通常，領域專家會手動計算顯微鏡影像中的細胞。自動化細胞計數有可能消除這個繁瑣且耗時的程序。然而，訓練一個準確的機器學習模型需要一個良好且標註的資料集。我們的資料集包含細胞的顯微鏡影像，並且對於每個影像，會標註細胞計數和個別細胞的位置。這些資料是作為一項正在進行的研究的一部分收集的，該研究調查了電刺激調節幹細胞分化和神經修復的潛在應用。與現有公開可用的資料集相比，我們的資料集有更多使用各種抗體（針對入侵者的免疫反應的蛋白質成分）染色細胞的影像，這些抗體通常用於細胞分析。此資料集的實驗結果表明，本研究中的五個現有模型均無法達到足夠準確的計數來取代手動方法。該資料集可在 https://figshare.com/articles/dataset/Dataset/21970604 取得。</paragraph>

##### **CoCoP: Enhancing Text Classification with LLM through Code Completion Prompt**
2411.08979v1 by Mohammad Mahdi Mohajeri, Mohammad Javad Dousti, Majid Nili Ahmadabadi

Text classification is a fundamental task in natural language processing
(NLP), and large language models (LLMs) have demonstrated their capability to
perform this task across various domains. However, the performance of LLMs
heavily depends on the quality of their input prompts. Recent studies have also
shown that LLMs exhibit remarkable results in code-related tasks. To leverage
the capabilities of LLMs in text classification, we propose the Code Completion
Prompt (CoCoP) method, which transforms the text classification problem into a
code completion task. CoCoP significantly improves text classification
performance across diverse datasets by utilizing LLMs' code-completion
capability. For instance, CoCoP enhances the accuracy of the SST2 dataset by
more than 20%. Moreover, when CoCoP integrated with LLMs specifically designed
for code-related tasks (code models), such as CodeLLaMA, this method
demonstrates better or comparable performance to few-shot learning techniques
while using only one-tenth of the model size. The source code of our proposed
method will be available to the public upon the acceptance of the paper.

摘要：文本分類是自然語言處理 (NLP) 中的一項基本任務，而大型語言模型 (LLM) 已展現其在各種領域執行此任務的能力。然而，LLM 的效能高度依賴於其輸入提示的品質。最近的研究也顯示，LLM 在與程式碼相關的任務中展現出顯著的結果。為了在文本分類中利用 LLM 的能力，我們提出程式碼完成提示 (CoCoP) 方法，它將文本分類問題轉換為程式碼完成任務。CoCoP 透過利用 LLM 的程式碼完成能力，大幅提升各種資料集的文本分類效能。例如，CoCoP 將 SST2 資料集的準確度提升了 20% 以上。此外，當 CoCoP 與專為程式碼相關任務（程式碼模型）設計的 LLM（例如 CodeLLaMA）整合時，此方法展現出比少量學習技術更佳或相當的效能，同時僅使用十分之一的模型大小。我們提出的方法的原始碼將在論文被接受後提供給大眾。

##### **Robustness and Confounders in the Demographic Alignment of LLMs with Human Perceptions of Offensiveness**
2411.08977v1 by Shayan Alipour, Indira Sen, Mattia Samory, Tanushree Mitra

Large language models (LLMs) are known to exhibit demographic biases, yet few
studies systematically evaluate these biases across multiple datasets or
account for confounding factors. In this work, we examine LLM alignment with
human annotations in five offensive language datasets, comprising approximately
220K annotations. Our findings reveal that while demographic traits,
particularly race, influence alignment, these effects are inconsistent across
datasets and often entangled with other factors. Confounders -- such as
document difficulty, annotator sensitivity, and within-group agreement --
account for more variation in alignment patterns than demographic traits alone.
Specifically, alignment increases with higher annotator sensitivity and group
agreement, while greater document difficulty corresponds to reduced alignment.
Our results underscore the importance of multi-dataset analyses and
confounder-aware methodologies in developing robust measures of demographic
bias in LLMs.

摘要：大型語言模型 (LLM) 已知會表現出人口統計偏誤，但很少有研究系統性地評估這些偏誤，並考量多個資料集或混淆因素。在這項研究中，我們檢視 LLM 與五個攻擊性語言資料集中的真人標註的一致性，這些資料集包含約 220K 個標註。我們的研究結果顯示，雖然人口統計特徵，尤其是種族，會影響一致性，但這些影響在資料集之間並不一致，而且常常與其他因素糾纏在一起。混淆因素（例如文件難度、標註者敏感度和組內共識）比單獨的人口統計特徵更能說明一致性模式的變化。具體來說，一致性會隨著標註者敏感度和群體共識的提高而增加，而文件難度越高，一致性就越低。我們的結果強調了多資料集分析和考量混淆因素的方法在開發 LLM 中人口統計偏誤的穩健衡量標準中的重要性。

##### **Sparse Upcycling: Inference Inefficient Finetuning**
2411.08968v1 by Sasha Doubov, Nikhil Sardana, Vitaliy Chiley

Small, highly trained, open-source large language models are widely used due
to their inference efficiency, but further improving their quality remains a
challenge. Sparse upcycling is a promising approach that transforms a
pretrained dense model into a Mixture-of-Experts (MoE) architecture, increasing
the model's parameter count and quality. In this work, we compare the
effectiveness of sparse upcycling against continued pretraining (CPT) across
different model sizes, compute budgets, and pretraining durations. Our
experiments show that sparse upcycling can achieve better quality, with
improvements of over 20% relative to CPT in certain scenarios. However, this
comes with a significant inference cost, leading to 40% slowdowns in
high-demand inference settings for larger models. Our findings highlight the
trade-off between model quality and inference efficiency, offering insights for
practitioners seeking to balance model quality and deployment constraints.

摘要：小型的、经过高度训练的、开源的大语言模型因其推理效率而被广泛使用，但进一步提高其质量仍然是一个挑战。稀疏升级是一种很有前途的方法，它将预先训练的稠密模型转换为专家混合 (MoE) 架构，从而增加了模型的参数数量和质量。在这项工作中，我们比较了稀疏升级与持续预训练 (CPT) 在不同模型大小、计算预算和预训练持续时间方面的有效性。我们的实验表明，稀疏升级可以实现更好的质量，在某些情况下相对于 CPT 提高了 20% 以上。然而，这会带来显着的推理成本，导致在大型模型的高需求推理设置中速度降低 40%。我们的研究结果突出了模型质量和推理效率之间的权衡，为寻求平衡模型质量和部署约束的从业者提供了见解。

##### **Inconsistencies In Consistency Models: Better ODE Solving Does Not Imply Better Samples**
2411.08954v1 by Noël Vouitsis, Rasa Hosseinzadeh, Brendan Leigh Ross, Valentin Villecroze, Satya Krishna Gorti, Jesse C. Cresswell, Gabriel Loaiza-Ganem

Although diffusion models can generate remarkably high-quality samples, they
are intrinsically bottlenecked by their expensive iterative sampling procedure.
Consistency models (CMs) have recently emerged as a promising diffusion model
distillation method, reducing the cost of sampling by generating high-fidelity
samples in just a few iterations. Consistency model distillation aims to solve
the probability flow ordinary differential equation (ODE) defined by an
existing diffusion model. CMs are not directly trained to minimize error
against an ODE solver, rather they use a more computationally tractable
objective. As a way to study how effectively CMs solve the probability flow
ODE, and the effect that any induced error has on the quality of generated
samples, we introduce Direct CMs, which \textit{directly} minimize this error.
Intriguingly, we find that Direct CMs reduce the ODE solving error compared to
CMs but also result in significantly worse sample quality, calling into
question why exactly CMs work well in the first place. Full code is available
at: https://github.com/layer6ai-labs/direct-cms.

摘要：儘管擴散模型可以產生品質極高的樣本，但它們本質上會受到其昂貴的迭代採樣程序的瓶頸。一致性模型 (CM) 最近已成為一種有前途的擴散模型蒸餾方法，它透過在僅幾次迭代中產生高保真樣本來降低採樣的成本。一致性模型蒸餾旨在解決由現有擴散模型定義的機率流常微分方程式 (ODE)。CM 並非直接訓練來最小化相對於 ODE 求解器的誤差，而是使用計算上更易於處理的目標。為了研究 CM 有效解決機率流 ODE 的方式，以及任何誘發誤差對所產生樣本品質的影響，我們引入了直接 CM，它\textit{直接}最小化此誤差。有趣的是，我們發現與 CM 相比，直接 CM 減少了 ODE 求解誤差，但也導致樣本品質顯著惡化，這會讓人質疑 CM 究竟為何一開始就能運作良好。完整程式碼可於下列網址取得：https://github.com/layer6ai-labs/direct-cms。

##### **4D Gaussian Splatting in the Wild with Uncertainty-Aware Regularization**
2411.08879v1 by Mijeong Kim, Jongwoo Lim, Bohyung Han

Novel view synthesis of dynamic scenes is becoming important in various
applications, including augmented and virtual reality. We propose a novel 4D
Gaussian Splatting (4DGS) algorithm for dynamic scenes from casually recorded
monocular videos. To overcome the overfitting problem of existing work for
these real-world videos, we introduce an uncertainty-aware regularization that
identifies uncertain regions with few observations and selectively imposes
additional priors based on diffusion models and depth smoothness on such
regions. This approach improves both the performance of novel view synthesis
and the quality of training image reconstruction. We also identify the
initialization problem of 4DGS in fast-moving dynamic regions, where the
Structure from Motion (SfM) algorithm fails to provide reliable 3D landmarks.
To initialize Gaussian primitives in such regions, we present a dynamic region
densification method using the estimated depth maps and scene flow. Our
experiments show that the proposed method improves the performance of 4DGS
reconstruction from a video captured by a handheld monocular camera and also
exhibits promising results in few-shot static scene reconstruction.

摘要：動態場景的新穎視圖合成在各種應用中變得重要，包括擴增實境和虛擬實境。我們提出一個用於動態場景的新穎 4D 高斯點繪 (4DGS) 演算法，從隨意記錄的單眼影片中取得。為了克服現有工作對這些真實世界影片的過度擬合問題，我們引入了不確定性感知正則化，它會識別觀察次數較少的不明確區域，並根據擴散模型和深度平滑有選擇性地對此類區域施加額外的先驗。這種方法同時改善了新穎視圖合成的效能和訓練影像重建的品質。我們也識別出 4DGS 在快速移動動態區域中的初始化問題，在這些區域中，運動結構 (SfM) 演算法無法提供可靠的 3D 地標。為了在這些區域中初始化高斯基元，我們提出一個動態區域增密方法，使用估計的深度圖和場景流。我們的實驗顯示，所提出的方法改善了從手持單眼相機拍攝的影片中重建 4DGS 的效能，而且在少量靜態場景重建中也展現出有希望的結果。

##### **The Limited Impact of Medical Adaptation of Large Language and Vision-Language Models**
2411.08870v1 by Daniel P. Jeong, Pranav Mani, Saurabh Garg, Zachary C. Lipton, Michael Oberst

Several recent works seek to develop foundation models specifically for
medical applications, adapting general-purpose large language models (LLMs) and
vision-language models (VLMs) via continued pretraining on publicly available
biomedical corpora. These works typically claim that such domain-adaptive
pretraining (DAPT) improves performance on downstream medical tasks, such as
answering medical licensing exam questions. In this paper, we compare ten
public "medical" LLMs and two VLMs against their corresponding base models,
arriving at a different conclusion: all medical VLMs and nearly all medical
LLMs fail to consistently improve over their base models in the zero-/few-shot
prompting and supervised fine-tuning regimes for medical question-answering
(QA). For instance, across all tasks and model pairs we consider in the 3-shot
setting, medical LLMs only outperform their base models in 22.7% of cases,
reach a (statistical) tie in 36.8% of cases, and are significantly worse than
their base models in the remaining 40.5% of cases. Our conclusions are based on
(i) comparing each medical model head-to-head, directly against the
corresponding base model; (ii) optimizing the prompts for each model separately
in zero-/few-shot prompting; and (iii) accounting for statistical uncertainty
in comparisons. While these basic practices are not consistently adopted in the
literature, our ablations show that they substantially impact conclusions.
Meanwhile, we find that after fine-tuning on specific QA tasks, medical LLMs
can show performance improvements, but the benefits do not carry over to tasks
based on clinical notes. Our findings suggest that state-of-the-art
general-domain models may already exhibit strong medical knowledge and
reasoning capabilities, and offer recommendations to strengthen the conclusions
of future studies.

摘要：<paragraph>最近有許多研究專門開發醫療應用基礎模型，透過持續預訓練公開的生物醫學語料庫，改編通用大型語言模型 (LLM) 和視覺語言模型 (VLM)。這些研究通常聲稱此類領域自適應預訓練 (DAPT) 能提升下游醫療任務的效能，例如回答醫療執照考試題目。在本文中，我們比較了十個公開的「醫療」LLM 和兩個 VLM，並將其與對應的基本模型進行比較，得出了不同的結論：所有醫療 VLM 和幾乎所有醫療 LLM 都無法在醫療問題解答 (QA) 的零次/小樣本提示和監督微調機制中持續優於其基本模型。例如，在我們在 3 次取樣設定中考量的所有任務和模型配對中，醫療 LLM 僅在 22.7% 的案例中優於其基本模型，在 36.8% 的案例中達到（統計）平手，而在其餘 40.5% 的案例中則顯著低於其基本模型。我們的結論基於 (i) 將每個醫療模型與對應的基本模型進行一對一比較；(ii) 在零次/小樣本提示中分別針對每個模型最佳化提示；以及 (iii) 在比較中考量統計不確定性。儘管這些基本做法並未在文獻中一致採用，但我們的消融研究顯示，它們對結論有重大影響。同時，我們發現，在針對特定 QA 任務進行微調後，醫療 LLM 可以展現效能提升，但這些好處並未延續到基於臨床筆記的任務。我們的研究結果表明，最先進的通用領域模型可能已經展現出強大的醫療知識和推理能力，並提供建議以強化未來研究的結論。</paragraph>

##### **CamemBERT 2.0: A Smarter French Language Model Aged to Perfection**
2411.08868v1 by Wissam Antoun, Francis Kulumba, Rian Touchent, Éric de la Clergerie, Benoît Sagot, Djamé Seddah

French language models, such as CamemBERT, have been widely adopted across
industries for natural language processing (NLP) tasks, with models like
CamemBERT seeing over 4 million downloads per month. However, these models face
challenges due to temporal concept drift, where outdated training data leads to
a decline in performance, especially when encountering new topics and
terminology. This issue emphasizes the need for updated models that reflect
current linguistic trends. In this paper, we introduce two new versions of the
CamemBERT base model-CamemBERTav2 and CamemBERTv2-designed to address these
challenges. CamemBERTav2 is based on the DeBERTaV3 architecture and makes use
of the Replaced Token Detection (RTD) objective for better contextual
understanding, while CamemBERTv2 is built on RoBERTa, which uses the Masked
Language Modeling (MLM) objective. Both models are trained on a significantly
larger and more recent dataset with longer context length and an updated
tokenizer that enhances tokenization performance for French. We evaluate the
performance of these models on both general-domain NLP tasks and
domain-specific applications, such as medical field tasks, demonstrating their
versatility and effectiveness across a range of use cases. Our results show
that these updated models vastly outperform their predecessors, making them
valuable tools for modern NLP systems. All our new models, as well as
intermediate checkpoints, are made openly available on Huggingface.

摘要：法語語言模型，例如 CamemBERT，已在各產業廣泛採用於自然語言處理 (NLP) 任務，而 CamemBERT 等模型每月下載量超過 400 萬次。然而，這些模型會因時間概念漂移而面臨挑戰，過時的訓練資料會導致效能下降，特別是在遇到新主題和術語時。此問題強調了需要更新的模型來反映當前的語言趨勢。在本文中，我們介紹了 CamemBERT 基礎模型的兩個新版本，CamemBERTav2 和 CamemBERTv2，旨在解決這些挑戰。CamemBERTav2 基於 DeBERTaV3 架構，並利用替換代幣偵測 (RTD) 目標，以獲得更好的脈絡理解，而 CamemBERTv2 則建構在 RoBERTa 上，使用遮蔽語言模型 (MLM) 目標。這兩個模型都訓練於一個顯著更大且更新的資料集，具有較長的脈絡長度和一個更新的 tokenizer，可增強法語的 tokenization 效能。我們評估了這些模型在一般領域 NLP 任務和特定領域應用程式（例如醫學領域任務）上的效能，展示了它們在各種使用案例中的多功能性和有效性。我們的結果顯示，這些更新的模型大幅優於它們的前身，使其成為現代 NLP 系統的寶貴工具。我們所有的新模型，以及中間檢查點，都公開在 Huggingface 上。

##### **Data-driven Surface Solar Irradiance Estimation using Neural Operators at Global Scale**
2411.08843v1 by Alberto Carpentieri, Jussi Leinonen, Jeff Adie, Boris Bonev, Doris Folini, Farah Hariri

Accurate surface solar irradiance (SSI) forecasting is essential for
optimizing renewable energy systems, particularly in the context of long-term
energy planning on a global scale. This paper presents a pioneering approach to
solar radiation forecasting that leverages recent advancements in numerical
weather prediction (NWP) and data-driven machine learning weather models. These
advances facilitate long, stable rollouts and enable large ensemble forecasts,
enhancing the reliability of predictions. Our flexible model utilizes variables
forecast by these NWP and AI weather models to estimate 6-hourly SSI at global
scale. Developed using NVIDIA Modulus, our model represents the first adaptive
global framework capable of providing long-term SSI forecasts. Furthermore, it
can be fine-tuned using satellite data, which significantly enhances its
performance in the fine-tuned regions, while maintaining accuracy elsewhere.
The improved accuracy of these forecasts has substantial implications for the
integration of solar energy into power grids, enabling more efficient energy
management and contributing to the global transition to renewable energy
sources.

摘要：精準的太陽表面輻照度 (SSI) 預測對於最佳化再生能源系統至關重要，特別是在全球規模的長期能源規劃中。本文提出了一種創新的太陽輻射預測方法，它利用了數值天氣預報 (NWP) 和資料驅動機器學習天氣模型的最新進展。這些進展促成了長期、穩定的推出，並實現了大型集合預測，進而提高了預測的可靠性。我們的彈性模型利用這些 NWP 和 AI 天氣模型預測的變數來估計全球範圍內的 6 小時 SSI。我們的模型使用 NVIDIA Modulus 開發，代表了第一個能夠提供長期 SSI 預測的適應性全球架構。此外，它可以使用衛星資料進行微調，這顯著增強了它在微調區域的效能，同時在其他地方保持準確性。這些預測精度的提高對太陽能整合到電網中具有重大影響，實現了更有效的能源管理，並有助於全球轉向再生能源。

##### **AstroM$^3$: A self-supervised multimodal model for astronomy**
2411.08842v1 by Mariia Rizhko, Joshua S. Bloom

While machine-learned models are now routinely employed to facilitate
astronomical inquiry, model inputs tend to be limited to a primary data source
(namely images or time series) and, in the more advanced approaches, some
metadata. Yet with the growing use of wide-field, multiplexed observational
resources, individual sources of interest often have a broad range of
observational modes available. Here we construct an astronomical multimodal
dataset and propose AstroM$^3$, a self-supervised pre-training approach that
enables a model to learn from multiple modalities simultaneously. Specifically,
we extend the CLIP (Contrastive Language-Image Pretraining) model to a trimodal
setting, allowing the integration of time-series photometry data, spectra, and
astrophysical metadata. In a fine-tuning supervised setting, our results
demonstrate that CLIP pre-training improves classification performance for
time-series photometry, where accuracy increases from 84.6% to 91.5%.
Furthermore, CLIP boosts classification accuracy by up to 12.6% when the
availability of labeled data is limited, showing the effectiveness of
leveraging larger corpora of unlabeled data. In addition to fine-tuned
classification, we can use the trained model in other downstream tasks that are
not explicitly contemplated during the construction of the self-supervised
model. In particular we show the efficacy of using the learned embeddings for
misclassifications identification, similarity search, and anomaly detection.
One surprising highlight is the "rediscovery" of Mira subtypes and two
Rotational variable subclasses using manifold learning and dimension reduction
algorithm. To our knowledge this is the first construction of an $n>2$ mode
model in astronomy. Extensions to $n>3$ modes is naturally anticipated with
this approach.

摘要：<paragraph>雖然機器學習模型現在例行用於促進天文學探究，但模型輸入往往僅限於主要的資料來源（即影像或時間序列），而在更進階的方法中，則為一些元資料。但隨著廣視場、多工觀測資源的使用增加，個別感興趣的來源通常有廣泛的觀測模式可用。在此，我們建構一個天文學多模態資料集，並提出 AstroM$^3$，一種自我監督預訓練方法，使模型能夠同時從多種模態中學習。具體來說，我們將 CLIP（對比式語言影像預訓練）模型擴充到三模態設定，允許整合時間序列光度測量資料、光譜和天體物理元資料。在微調監督設定中，我們的結果證明 CLIP 預訓練改善了時間序列光度測量的分類效能，其中準確度從 84.6% 提升至 91.5%。此外，當標記資料的可用性受限時，CLIP 可將分類準確度提高多達 12.6%，顯示出利用較大規模的未標記資料的有效性。除了微調分類外，我們可以在其他下游任務中使用訓練好的模型，這些任務並未在自我監督模型的建構過程中明確考慮。特別是，我們展示了使用已學習嵌入進行錯誤分類識別、相似性搜尋和異常偵測的效能。一個令人驚訝的亮點是使用流形學習和降維演算法「重新發現」米拉子類型和兩個旋轉變數子類別。據我們所知，這是天文學中第一個建構 $n>2$ 模式模型。使用這種方法自然會預期擴充至 $n>3$ 模式。</paragraph>

##### **Offline Adaptation of Quadruped Locomotion using Diffusion Models**
2411.08832v1 by Reece O'Mahoney, Alexander L. Mitchell, Wanming Yu, Ingmar Posner, Ioannis Havoutis

We present a diffusion-based approach to quadrupedal locomotion that
simultaneously addresses the limitations of learning and interpolating between
multiple skills and of (modes) offline adapting to new locomotion behaviours
after training. This is the first framework to apply classifier-free guided
diffusion to quadruped locomotion and demonstrate its efficacy by extracting
goal-conditioned behaviour from an originally unlabelled dataset. We show that
these capabilities are compatible with a multi-skill policy and can be applied
with little modification and minimal compute overhead, i.e., running entirely
on the robots onboard CPU. We verify the validity of our approach with hardware
experiments on the ANYmal quadruped platform.

摘要：我們提出了一種基於擴散的四足步態方法，它同時解決了在多種技能之間學習和內插的限制，以及在訓練後離線適應新的運動行為的限制（模式）。這是第一個將無分類器引導擴散應用於四足運動的框架，並通過從最初未標記的數據集中提取目標條件行為來證明其功效。我們展示了這些能力與多技能策略相容，並且可以應用於很少的修改和最小的計算開銷，即完全在機器人板載 CPU 上運行。我們在 ANYmal 四足平台上進行的硬體實驗驗證了我們方法的有效性。

##### **Process-aware Human Activity Recognition**
2411.08814v1 by Jiawei Zheng, Petros Papapanagiotou, Jacques D. Fleuriot, Jane Hillston

Humans naturally follow distinct patterns when conducting their daily
activities, which are driven by established practices and processes, such as
production workflows, social norms and daily routines. Human activity
recognition (HAR) algorithms usually use neural networks or machine learning
techniques to analyse inherent relationships within the data. However, these
approaches often overlook the contextual information in which the data are
generated, potentially limiting their effectiveness. We propose a novel
approach that incorporates process information from context to enhance the HAR
performance. Specifically, we align probabilistic events generated by machine
learning models with process models derived from contextual information. This
alignment adaptively weighs these two sources of information to optimise HAR
accuracy. Our experiments demonstrate that our approach achieves better
accuracy and Macro F1-score compared to baseline models.

摘要：人類在進行日常活動時自然會遵循不同的模式，這些模式是由既定的實務和流程所驅動，例如生產工作流程、社會規範和日常例行公事。人類活動辨識 (HAR) 演算法通常使用神經網路或機器學習技術來分析資料中的內在關係。然而，這些方法經常忽略資料產生的脈絡資訊，這可能會限制其效能。我們提出了一種創新的方法，它將來自脈絡的流程資訊納入其中，以增強 HAR 的效能。具體來說，我們將機器學習模型產生的機率事件與從脈絡資訊衍生的流程模型對齊。這種對齊會根據這兩個資訊來源調整權重，以最佳化 HAR 的準確度。我們的實驗證明，與基線模型相比，我們的做法達到了更好的準確度和巨觀 F1 分數。

##### **Rethinking CyberSecEval: An LLM-Aided Approach to Evaluation Critique**
2411.08813v1 by Suhas Hariharan, Zainab Ali Majid, Jaime Raldua Veuthey, Jacob Haimes

A key development in the cybersecurity evaluations space is the work carried
out by Meta, through their CyberSecEval approach. While this work is
undoubtedly a useful contribution to a nascent field, there are notable
features that limit its utility. Key drawbacks focus on the insecure code
detection part of Meta's methodology. We explore these limitations, and use our
exploration as a test case for LLM-assisted benchmark analysis.

摘要：網路安全評估領域的一項關鍵發展是 Meta 透過其 CyberSecEval 方法所進行的工作。儘管這項工作無疑對新興領域有所貢獻，但仍有一些顯著特點限制了其效用。主要缺點集中在 Meta 方法論的不安全程式碼偵測部分。我們探討這些限制，並將我們的探討用作 LLM 輔助基準分析的測試案例。

##### **Evaluating World Models with LLM for Decision Making**
2411.08794v1 by Chang Yang, Xinrun Wang, Junzhe Jiang, Qinggang Zhang, Xiao Huang

World model emerges as a key module in decision making, where MuZero and
Dreamer achieve remarkable successes in complex tasks. Recent work leverages
Large Language Models (LLMs) as general world simulators to simulate the
dynamics of the world due to their generalizability. LLMs also serve as the
world model for deliberative reasoning in Reasoning via Planning (RAP) and Tree
of Thought (ToT). However, the world models are either evaluated as a general
world simulator, or as a functional module of the agent, i.e., predicting the
transitions to assist the planning. In this work, we propose a comprehensive
evaluation of the world models with LLMs from the decision making perspective.
Specifically, we leverage the 31 diverse environments from (Wang et al.,
2023;2024) and curate the rule-based policy of each environment for the diverse
evaluation. Then, we design three main tasks, i.e., policy verification, action
proposal, and policy planning, where the world models can be used for decision
making solely. Finally, we conduct the comprehensive evaluation of the advanced
LLMs, i.e., GPT-4o and GPT-4o-mini, on the environments for the three main
tasks under various settings. The key observations include: i) GPT-4o
significantly outperforms GPT-4o-mini on the three main tasks, especially for
the tasks which require the domain knowledge, ii) the performance of the world
model with LLM will be decreased for long-term decision-making tasks, and iii)
the combination of different functionalities of the world model will brings
additional unstabilities of the performance.

摘要：世界模型成為決策中的一個關鍵模組，其中 MuZero 和 Dreamer 在複雜任務中取得顯著成功。最近的研究利用大型語言模型 (LLM) 作為通用的世界模擬器，模擬世界的動態，因為它們具有普遍性。LLM 也可用作規劃推理 (RAP) 和思考樹 (ToT) 中審議推理的世界模型。然而，世界模型要么被評估為一個通用的世界模擬器，要么作為代理的一個功能模組，即預測過渡以協助規劃。在這項工作中，我們提出了從決策制定角度對使用 LLM 的世界模型進行全面評估。具體來說，我們利用了來自 (Wang et al., 2023;2024) 的 31 個不同的環境，並為不同的評估整理了每個環境的基於規則的策略。然後，我們設計了三個主要任務，即策略驗證、動作建議和策略規劃，世界模型可以僅用於決策制定。最後，我們對先進的 LLM（即 GPT-4o 和 GPT-4o-mini）在不同環境下進行了三個主要任務的綜合評估。關鍵觀察結果包括：i) GPT-4o 在三個主要任務上明顯優於 GPT-4o-mini，特別是對於需要領域知識的任務，ii) 使用 LLM 的世界模型的性能會因長期決策制定任務而降低，以及 iii) 世界模型的不同功能的結合會帶來額外的性能不穩定性。

##### **Can sparse autoencoders be used to decompose and interpret steering vectors?**
2411.08790v1 by Harry Mayne, Yushi Yang, Adam Mahdi

Steering vectors are a promising approach to control the behaviour of large
language models. However, their underlying mechanisms remain poorly understood.
While sparse autoencoders (SAEs) may offer a potential method to interpret
steering vectors, recent findings show that SAE-reconstructed vectors often
lack the steering properties of the original vectors. This paper investigates
why directly applying SAEs to steering vectors yields misleading
decompositions, identifying two reasons: (1) steering vectors fall outside the
input distribution for which SAEs are designed, and (2) steering vectors can
have meaningful negative projections in feature directions, which SAEs are not
designed to accommodate. These limitations hinder the direct use of SAEs for
interpreting steering vectors.

摘要：引導向量是一種控制大型語言模型行為的有前途方法。然而，它們的底層機制仍然知之甚少。儘管稀疏自動編碼器 (SAE) 可能提供一種解釋引導向量的潛在方法，但最近的研究結果表明，SAE 重建的向量通常缺乏原始向量的引導屬性。本文探討了為什麼直接將 SAE 應用於引導向量會產生誤導性的分解，並找出兩個原因：(1) 引導向量超出 SAE 設計的輸入分佈，以及 (2) 引導向量在特徵方向上可能具有有意義的負投影，而 SAE 並未設計為適應這種情況。這些限制阻礙了直接使用 SAE 來解釋引導向量。

##### **Zero-shot Cross-lingual Transfer Learning with Multiple Source and Target Languages for Information Extraction: Language Selection and Adversarial Training**
2411.08785v1 by Nghia Trung Ngo, Thien Huu Nguyen

The majority of previous researches addressing multi-lingual IE are limited
to zero-shot cross-lingual single-transfer (one-to-one) setting, with
high-resource languages predominantly as source training data. As a result,
these works provide little understanding and benefit for the realistic goal of
developing a multi-lingual IE system that can generalize to as many languages
as possible. Our study aims to fill this gap by providing a detailed analysis
on Cross-Lingual Multi-Transferability (many-to-many transfer learning), for
the recent IE corpora that cover a diverse set of languages. Specifically, we
first determine the correlation between single-transfer performance and a wide
range of linguistic-based distances. From the obtained insights, a combined
language distance metric can be developed that is not only highly correlated
but also robust across different tasks and model scales. Next, we investigate
the more general zero-shot multi-lingual transfer settings where multiple
languages are involved in the training and evaluation processes. Language
clustering based on the newly defined distance can provide directions for
achieving the optimal cost-performance trade-off in data (languages) selection
problem. Finally, a relational-transfer setting is proposed to further
incorporate multi-lingual unlabeled data based on adversarial training using
the relation induced from the above linguistic distance.

摘要：過去針對多語言資訊萃取（IE）的研究多半侷限於零次學習跨語言單一轉移（一對一）的設定，且以資源豐富的語言作為來源訓練資料。因此，這些研究對於開發一個能盡可能推廣至多種語言的多語言 IE 系統這個實際目標，幾乎沒有提供理解或幫助。我們的研究旨在透過提供對跨語言多重可轉移性（多對多轉移學習）的詳細分析，來填補這個缺口，以涵蓋各種語言的近期 IE 語料庫。具體來說，我們首先確定單一轉移效能與各種基於語言的距離之間的關聯性。從獲得的見解中，可以開發出一種綜合語言距離指標，不僅高度相關，而且在不同的任務和模型規模中也很穩健。接下來，我們研究更通用的零次學習多語言轉移設定，其中多種語言參與訓練和評估過程。根據新定義的距離進行語言群集，可以提供在資料（語言）選擇問題中達成最佳成本效益權衡的方向。最後，提出了一個關係轉移設定，以進一步根據對抗式訓練中從上述語言距離中推導出的關係，來納入多語言未標記資料。

##### **Sharingan: Extract User Action Sequence from Desktop Recordings**
2411.08768v1 by Yanting Chen, Yi Ren, Xiaoting Qin, Jue Zhang, Kehong Yuan, Lu Han, Qingwei Lin, Dongmei Zhang, Saravan Rajmohan, Qi Zhang

Video recordings of user activities, particularly desktop recordings, offer a
rich source of data for understanding user behaviors and automating processes.
However, despite advancements in Vision-Language Models (VLMs) and their
increasing use in video analysis, extracting user actions from desktop
recordings remains an underexplored area. This paper addresses this gap by
proposing two novel VLM-based methods for user action extraction: the Direct
Frame-Based Approach (DF), which inputs sampled frames directly into VLMs, and
the Differential Frame-Based Approach (DiffF), which incorporates explicit
frame differences detected via computer vision techniques. We evaluate these
methods using a basic self-curated dataset and an advanced benchmark adapted
from prior work. Our results show that the DF approach achieves an accuracy of
70% to 80% in identifying user actions, with the extracted action sequences
being re-playable though Robotic Process Automation. We find that while VLMs
show potential, incorporating explicit UI changes can degrade performance,
making the DF approach more reliable. This work represents the first
application of VLMs for extracting user action sequences from desktop
recordings, contributing new methods, benchmarks, and insights for future
research.

摘要：使用者活動的影片錄製，特別是桌面錄製，提供了豐富的資料來源，可用於了解使用者行為並自動化流程。然而，儘管視覺語言模型 (VLM) 有所進步，且在影片分析中使用越來越廣泛，從桌面錄製中擷取使用者動作仍然是一個尚未充分探討的領域。本文透過提出兩種基於 VLM 的使用者動作擷取新穎方法來解決這個問題：直接基於畫面的方法 (DF)，它將取樣的畫面直接輸入 VLM，以及差異化基於畫面的方法 (DiffF)，它結合了透過電腦視覺技術偵測到的明確畫面差異。我們使用一個基本的自訂資料集和一個從先前工作中改編的高階基準來評估這些方法。我們的結果顯示，DF 方法在識別使用者動作時達到了 70% 到 80% 的準確度，而擷取的動作序列可透過機器人流程自動化重新播放。我們發現，儘管 VLM 具有潛力，但結合明確的 UI 變更可能會降低效能，使 DF 方法更可靠。這項工作代表了首次應用 VLM 從桌面錄製中擷取使用者動作序列，為未來的研究提供了新的方法、基準和見解。

##### **SANDWICH: Towards an Offline, Differentiable, Fully-Trainable Wireless Neural Ray-Tracing Surrogate**
2411.08767v1 by Yifei Jin, Ali Maatouk, Sarunas Girdzijauskas, Shugong Xu, Leandros Tassiulas, Rex Ying

Wireless ray-tracing (RT) is emerging as a key tool for three-dimensional
(3D) wireless channel modeling, driven by advances in graphical rendering.
Current approaches struggle to accurately model beyond 5G (B5G) network
signaling, which often operates at higher frequencies and is more susceptible
to environmental conditions and changes. Existing online learning solutions
require real-time environmental supervision during training, which is both
costly and incompatible with GPU-based processing. In response, we propose a
novel approach that redefines ray trajectory generation as a sequential
decision-making problem, leveraging generative models to jointly learn the
optical, physical, and signal properties within each designated environment.
Our work introduces the Scene-Aware Neural Decision Wireless Channel Raytracing
Hierarchy (SANDWICH), an innovative offline, fully differentiable approach that
can be trained entirely on GPUs. SANDWICH offers superior performance compared
to existing online learning methods, outperforms the baseline by 4e^-2 radian
in RT accuracy, and only fades 0.5 dB away from toplined channel gain
estimation.

摘要：無線射線追蹤 (RT) 在圖形渲染的進步帶動下，正成為三維 (3D) 無線通道建模的一項關鍵工具。
目前的方法難以準確建模 5G (B5G) 網路訊號之外的訊號，而這些訊號通常以更高的頻率運作，且更容易受到環境條件和變化的影響。現有的線上學習解決方案需要在訓練期間進行即時的環境監控，這既昂貴又不相容於基於 GPU 的處理。為了解決這個問題，我們提出了一種新穎的方法，將射線軌跡生成重新定義為一個順序決策問題，利用生成模型來共同學習每個指定環境中的光學、物理和訊號特性。我們的研究引入了場景感知神經決策無線通道射線追蹤階層 (SANDWICH)，這是一種創新的離線、完全可微分的做法，可以在 GPU 上完全訓練。與現有的線上學習方法相比，SANDWICH 提供了卓越的效能，在 RT 精確度上優於基準 4e^-2 弧度，且僅在頂線通道增益估計中衰減 0.5 dB。

