{"2412.17726": {"publish_time": "2024-12-23", "title": "VidTwin: Video VAE with Decoupled Structure and Dynamics", "paper_summary": "Recent advancements in video autoencoders (Video AEs) have significantly\nimproved the quality and efficiency of video generation. In this paper, we\npropose a novel and compact video autoencoder, VidTwin, that decouples video\ninto two distinct latent spaces: Structure latent vectors, which capture\noverall content and global movement, and Dynamics latent vectors, which\nrepresent fine-grained details and rapid movements. Specifically, our approach\nleverages an Encoder-Decoder backbone, augmented with two submodules for\nextracting these latent spaces, respectively. The first submodule employs a\nQ-Former to extract low-frequency motion trends, followed by downsampling\nblocks to remove redundant content details. The second averages the latent\nvectors along the spatial dimension to capture rapid motion. Extensive\nexperiments show that VidTwin achieves a high compression rate of 0.20% with\nhigh reconstruction quality (PSNR of 28.14 on the MCL-JCV dataset), and\nperforms efficiently and effectively in downstream generative tasks. Moreover,\nour model demonstrates explainability and scalability, paving the way for\nfuture research in video latent representation and generation. Our code has\nbeen released at https://github.com/microsoft/VidTok/tree/main/vidtwin.", "paper_summary_zh": "\u6700\u8fd1\u5f71\u7247\u81ea\u52d5\u7de8\u78bc\u5668 (\u5f71\u7247 AE) \u7684\u9032\u6b65\u5927\u5e45\u63d0\u5347\u4e86\u5f71\u7247\u751f\u6210\u7684\u54c1\u8cea\u548c\u6548\u7387\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u65b0\u7a4e\u4e14\u7cbe\u7c21\u7684\u5f71\u7247\u81ea\u52d5\u7de8\u78bc\u5668 VidTwin\uff0c\u5b83\u5c07\u5f71\u7247\u89e3\u8026\u6210\u5169\u500b\u4e0d\u540c\u7684\u6f5b\u5728\u7a7a\u9593\uff1a\u7d50\u69cb\u6f5b\u5728\u5411\u91cf\uff0c\u7528\u65bc\u64f7\u53d6\u6574\u9ad4\u5167\u5bb9\u548c\u5168\u5c40\u52d5\u4f5c\uff1b\u4ee5\u53ca\u52d5\u614b\u6f5b\u5728\u5411\u91cf\uff0c\u7528\u65bc\u8868\u793a\u7d30\u5fae\u7684\u7d30\u7bc0\u548c\u5feb\u901f\u52d5\u4f5c\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u7684\u505a\u6cd5\u5229\u7528\u4e00\u500b\u7de8\u78bc\u5668-\u89e3\u78bc\u5668\u4e3b\u5e79\uff0c\u4e26\u64f4\u5145\u5169\u500b\u5b50\u6a21\u7d44\u4f86\u5206\u5225\u8403\u53d6\u9019\u4e9b\u6f5b\u5728\u7a7a\u9593\u3002\u7b2c\u4e00\u500b\u5b50\u6a21\u7d44\u63a1\u7528 Q-Former \u4f86\u8403\u53d6\u4f4e\u983b\u7387\u52d5\u4f5c\u8da8\u52e2\uff0c\u63a5\u8457\u662f\u964d\u63a1\u6a23\u5340\u584a\u4ee5\u79fb\u9664\u591a\u9918\u7684\u5167\u5bb9\u7d30\u7bc0\u3002\u7b2c\u4e8c\u500b\u5b50\u6a21\u7d44\u6cbf\u8457\u7a7a\u9593\u7dad\u5ea6\u5e73\u5747\u6f5b\u5728\u5411\u91cf\u4ee5\u64f7\u53d6\u5feb\u901f\u52d5\u4f5c\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u986f\u793a\uff0cVidTwin \u9054\u5230 0.20% \u7684\u9ad8\u58d3\u7e2e\u7387\uff0c\u4e14\u91cd\u5efa\u54c1\u8cea\u5f88\u9ad8\uff08\u5728 MCL-JCV \u8cc7\u6599\u96c6\u4e0a PSNR \u70ba 28.14\uff09\uff0c\u800c\u4e14\u5728\u4e0b\u6e38\u751f\u6210\u4efb\u52d9\u4e2d\u8868\u73fe\u5f97\u6709\u6548\u7387\u4e14\u6709\u6548\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684\u6a21\u578b\u5c55\u73fe\u4e86\u89e3\u91cb\u6027\u548c\u53ef\u64f4\u5145\u6027\uff0c\u70ba\u672a\u4f86\u7684\u5f71\u7247\u6f5b\u5728\u8868\u793a\u548c\u751f\u6210\u7814\u7a76\u92ea\u8def\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u5df2\u5728 https://github.com/microsoft/VidTok/tree/main/vidtwin \u767c\u5e03\u3002", "author": "Yuchi Wang et.al.", "authors": "Yuchi Wang, Junliang Guo, Xinyi Xie, Tianyu He, Xu Sun, Jiang Bian", "id": "2412.17726v1", "paper_url": "http://arxiv.org/abs/2412.17726v1", "repo": "https://github.com/microsoft/vidtok"}}