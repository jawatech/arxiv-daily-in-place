{"2411.08375": {"publish_time": "2024-11-13", "title": "Developing an Effective Training Dataset to Enhance the Performance of AI-based Speaker Separation Systems", "paper_summary": "This paper addresses the challenge of speaker separation, which remains an\nactive research topic despite the promising results achieved in recent years.\nThese results, however, often degrade in real recording conditions due to the\npresence of noise, echo, and other interferences. This is because neural models\nare typically trained on synthetic datasets consisting of mixed audio signals\nand their corresponding ground truths, which are generated using computer\nsoftware and do not fully represent the complexities of real-world recording\nscenarios. The lack of realistic training sets for speaker separation remains a\nmajor hurdle, as obtaining individual sounds from mixed audio signals is a\nnontrivial task. To address this issue, we propose a novel method for\nconstructing a realistic training set that includes mixture signals and\ncorresponding ground truths for each speaker. We evaluate this dataset on a\ndeep learning model and compare it to a synthetic dataset. We got a 1.65 dB\nimprovement in Scale Invariant Signal to Distortion Ratio (SI-SDR) for speaker\nseparation accuracy in realistic mixing. Our findings highlight the potential\nof realistic training sets for enhancing the performance of speaker separation\nmodels in real-world scenarios.", "paper_summary_zh": "\u672c\u6587\u63a2\u8ba8\u4e86\u8bf4\u8bdd\u8005\u5206\u79bb\u7684\u6311\u6218\uff0c\u5118\u7ba1\u8fd1\u5e74\u53d6\u5f97\u4e86\u6709\u5e0c\u671b\u7684\u7ed3\u679c\uff0c\u5b83\u4ecd\u7136\u662f\u4e00\u4e2a\u6d3b\u8dc3\u7684\u7814\u7a76\u8bfe\u9898\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u7ed3\u679c\u5728\u5b9e\u9645\u5f55\u97f3\u6761\u4ef6\u4e0b\u5e38\u5e38\u4f1a\u56e0\u566a\u97f3\u3001\u56de\u97f3\u548c\u5176\u4ed6\u5e72\u6270\u800c\u964d\u4f4e\u3002\u8fd9\u662f\u56e0\u4e3a\u795e\u7ecf\u6a21\u578b\u901a\u5e38\u5728\u7531\u6df7\u5408\u97f3\u9891\u4fe1\u53f7\u53ca\u5176\u5bf9\u5e94\u5730\u9762\u5b9e\u51b5\u7ec4\u6210\u7684\u5408\u6210\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u8fd9\u4e9b\u4fe1\u53f7\u548c\u5730\u9762\u5b9e\u51b5\u662f\u4f7f\u7528\u8ba1\u7b97\u673a\u8f6f\u4ef6\u751f\u6210\u7684\uff0c\u5e76\u4e14\u4e0d\u80fd\u5b8c\u5168\u4ee3\u8868\u73b0\u5b9e\u4e16\u754c\u5f55\u97f3\u573a\u666f\u7684\u590d\u6742\u6027\u3002\u7f3a\u4e4f\u7528\u4e8e\u8bf4\u8bdd\u8005\u5206\u79bb\u7684\u771f\u5b9e\u8bad\u7ec3\u96c6\u4ecd\u7136\u662f\u4e00\u4e2a\u4e3b\u8981\u969c\u788d\uff0c\u56e0\u4e3a\u4ece\u6df7\u5408\u97f3\u9891\u4fe1\u53f7\u4e2d\u83b7\u53d6\u5404\u4e2a\u58f0\u97f3\u662f\u4e00\u9879\u975e\u5e73\u51e1\u7684\u4efb\u52a1\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\u6765\u6784\u5efa\u4e00\u4e2a\u771f\u5b9e\u7684\u8bad\u7ec3\u96c6\uff0c\u5176\u4e2d\u5305\u62ec\u6df7\u5408\u4fe1\u53f7\u548c\u6bcf\u4e2a\u8bf4\u8bdd\u8005\u7684\u5bf9\u5e94\u5730\u9762\u5b9e\u51b5\u3002\u6211\u4eec\u5728\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e0a\u8bc4\u4f30\u4e86\u8fd9\u4e2a\u6570\u636e\u96c6\uff0c\u5e76\u5c06\u5176\u4e0e\u5408\u6210\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u5728\u771f\u5b9e\u7684\u6df7\u5408\u4e2d\uff0c\u6211\u4eec\u5728\u8bf4\u8bdd\u8005\u5206\u79bb\u51c6\u786e\u6027\u7684\u5c3a\u5ea6\u4e0d\u53d8\u4fe1\u53f7\u5931\u771f\u6bd4\uff08SI-SDR\uff09\u4e2d\u83b7\u5f97\u4e86 1.65 dB \u7684\u6539\u8fdb\u3002\u6211\u4eec\u7684\u7814\u7a76\u7ed3\u679c\u7a81\u51fa\u4e86\u771f\u5b9e\u8bad\u7ec3\u96c6\u5728\u589e\u5f3a\u8bf4\u8bdd\u8005\u5206\u79bb\u6a21\u578b\u5728\u73b0\u5b9e\u4e16\u754c\u573a\u666f\u4e2d\u7684\u6027\u80fd\u65b9\u9762\u7684\u6f5c\u529b\u3002", "author": "Rawad Melhem et.al.", "authors": "Rawad Melhem, Assef Jafar, Oumayma Al Dakkak", "id": "2411.08375v1", "paper_url": "http://arxiv.org/abs/2411.08375v1", "repo": "null"}}