{"2410.05218": {"publish_time": "2024-10-07", "title": "Density estimation with LLMs: a geometric investigation of in-context learning trajectories", "paper_summary": "Large language models (LLMs) demonstrate remarkable emergent abilities to\nperform in-context learning across various tasks, including time series\nforecasting. This work investigates LLMs' ability to estimate probability\ndensity functions (PDFs) from data observed in-context; such density estimation\n(DE) is a fundamental task underlying many probabilistic modeling problems. We\nleverage the Intensive Principal Component Analysis (InPCA) to visualize and\nanalyze the in-context learning dynamics of LLaMA-2 models. Our main finding is\nthat these LLMs all follow similar learning trajectories in a low-dimensional\nInPCA space, which are distinct from those of traditional density estimation\nmethods like histograms and Gaussian kernel density estimation (KDE). We\ninterpret the LLaMA in-context DE process as a KDE with an adaptive kernel\nwidth and shape. This custom kernel model captures a significant portion of\nLLaMA's behavior despite having only two parameters. We further speculate on\nwhy LLaMA's kernel width and shape differs from classical algorithms, providing\ninsights into the mechanism of in-context probabilistic reasoning in LLMs.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5c55\u793a\u4e86\u975e\u51e1\u7684\u65b0\u8208\u80fd\u529b\uff0c\u53ef\u4ee5\u5728\u5404\u7a2e\u4efb\u52d9\u4e2d\u57f7\u884c\u60c5\u5883\u5b78\u7fd2\uff0c\u5305\u62ec\u6642\u9593\u5e8f\u5217\u9810\u6e2c\u3002\u9019\u9805\u5de5\u4f5c\u63a2\u8a0e\u4e86 LLM \u5f9e\u60c5\u5883\u4e2d\u89c0\u5bdf\u5230\u7684\u8cc7\u6599\u4f30\u8a08\u6a5f\u7387\u5bc6\u5ea6\u51fd\u6578 (PDF) \u7684\u80fd\u529b\uff1b\u9019\u7a2e\u5bc6\u5ea6\u4f30\u8a08 (DE) \u662f\u8a31\u591a\u6a5f\u7387\u6a21\u578b\u554f\u984c\u7684\u57fa\u790e\u4efb\u52d9\u3002\u6211\u5011\u5229\u7528\u5bc6\u96c6\u4e3b\u6210\u5206\u5206\u6790 (InPCA) \u4f86\u8996\u89ba\u5316\u548c\u5206\u6790 LLaMA-2 \u6a21\u578b\u7684\u60c5\u5883\u5b78\u7fd2\u52d5\u614b\u3002\u6211\u5011\u7684\u767c\u73fe\u662f\uff0c\u9019\u4e9b LLM \u5728\u4f4e\u7dad\u5ea6 InPCA \u7a7a\u9593\u4e2d\u90fd\u9075\u5faa\u985e\u4f3c\u7684\u5b78\u7fd2\u8ecc\u8de1\uff0c\u9019\u8207\u76f4\u65b9\u5716\u548c\u9ad8\u65af\u6838\u5bc6\u5ea6\u4f30\u8a08 (KDE) \u7b49\u50b3\u7d71\u5bc6\u5ea6\u4f30\u8a08\u65b9\u6cd5\u4e0d\u540c\u3002\u6211\u5011\u5c07 LLaMA \u60c5\u5883 DE \u904e\u7a0b\u89e3\u91cb\u70ba\u5177\u6709\u81ea\u9069\u61c9\u6838\u5bec\u5ea6\u548c\u5f62\u72c0\u7684 KDE\u3002\u5118\u7ba1\u53ea\u6709\u5169\u500b\u53c3\u6578\uff0c\u4f46\u6b64\u81ea\u8a02\u6838\u6a21\u578b\u4ecd\u6355\u6349\u5230 LLaMA \u884c\u70ba\u7684\u91cd\u8981\u90e8\u5206\u3002\u6211\u5011\u9032\u4e00\u6b65\u63a8\u6e2c LLaMA \u7684\u6838\u5bec\u5ea6\u548c\u5f62\u72c0\u8207\u7d93\u5178\u6f14\u7b97\u6cd5\u4e0d\u540c\u7684\u539f\u56e0\uff0c\u4e26\u6df1\u5165\u4e86\u89e3 LLM \u4e2d\u60c5\u5883\u6a5f\u7387\u63a8\u7406\u7684\u6a5f\u5236\u3002", "author": "Toni J. B. Liu et.al.", "authors": "Toni J. B. Liu, Nicolas Boull\u00e9, Rapha\u00ebl Sarfati, Christopher J. Earls", "id": "2410.05218v1", "paper_url": "http://arxiv.org/abs/2410.05218v1", "repo": "null"}}