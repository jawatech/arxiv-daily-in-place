
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-13**|**GaussianWorld: Gaussian World Model for Streaming 3D Occupancy Prediction**|Sicheng Zuo et.al.|[2412.10373v1](http://arxiv.org/abs/2412.10373v1)|[link](https://github.com/zuosc19/gaussianworld)|
|**2024-12-13**|**A Grounded Typology of Word Classes**|Coleman Haley et.al.|[2412.10369v1](http://arxiv.org/abs/2412.10369v1)|null|
|**2024-12-13**|**Apollo: An Exploration of Video Understanding in Large Multimodal Models**|Orr Zohar et.al.|[2412.10360v1](http://arxiv.org/abs/2412.10360v1)|null|
|**2024-12-13**|**A Library for Learning Neural Operators**|Jean Kossaifi et.al.|[2412.10354v1](http://arxiv.org/abs/2412.10354v1)|null|
|**2024-12-13**|**A dual contrastive framework**|Yuan Sun et.al.|[2412.10348v1](http://arxiv.org/abs/2412.10348v1)|null|
|**2024-12-13**|**COMET: Benchmark for Comprehensive Biological Multi-omics Evaluation Tasks and Language Models**|Yuchen Ren et.al.|[2412.10347v1](http://arxiv.org/abs/2412.10347v1)|null|
|**2024-12-13**|**TraceVLA: Visual Trace Prompting Enhances Spatial-Temporal Awareness for Generalist Robotic Policies**|Ruijie Zheng et.al.|[2412.10345v1](http://arxiv.org/abs/2412.10345v1)|null|
|**2024-12-13**|**Iris: Breaking GUI Complexity with Adaptive Focus and Self-Refining**|Zhiqi Ge et.al.|[2412.10342v1](http://arxiv.org/abs/2412.10342v1)|null|
|**2024-12-13**|**Generative AI in Medicine**|Divya Shanmugam et.al.|[2412.10337v1](http://arxiv.org/abs/2412.10337v1)|null|
|**2024-12-13**|**AdvPrefix: An Objective for Nuanced LLM Jailbreaks**|Sicheng Zhu et.al.|[2412.10321v1](http://arxiv.org/abs/2412.10321v1)|null|
|**2024-12-13**|**SCBench: A KV Cache-Centric Analysis of Long-Context Methods**|Yucheng Li et.al.|[2412.10319v1](http://arxiv.org/abs/2412.10319v1)|null|
|**2024-12-13**|**BrushEdit: All-In-One Image Inpainting and Editing**|Yaowei Li et.al.|[2412.10316v1](http://arxiv.org/abs/2412.10316v1)|null|
|**2024-12-13**|**Interlocking-free Selective Rationalization Through Genetic-based Learning**|Federico Ruggeri et.al.|[2412.10312v1](http://arxiv.org/abs/2412.10312v1)|null|
|**2024-12-13**|**DeepSeek-VL2: Mixture-of-Experts Vision-Language Models for Advanced Multimodal Understanding**|Zhiyu Wu et.al.|[2412.10302v1](http://arxiv.org/abs/2412.10302v1)|[link](https://github.com/deepseek-ai/deepseek-vl2)|
|**2024-12-13**|**Still "Talking About Large Language Models": Some Clarifications**|Murray Shanahan et.al.|[2412.10291v1](http://arxiv.org/abs/2412.10291v1)|null|
|**2024-12-13**|**One world, one opinion? The superstar effect in LLM responses**|Sofie Goethals et.al.|[2412.10281v1](http://arxiv.org/abs/2412.10281v1)|null|
|**2024-12-13**|**Envisioning National Resources for Artificial Intelligence Research: NSF Workshop Report**|Shantenu Jha et.al.|[2412.10278v1](http://arxiv.org/abs/2412.10278v1)|null|
|**2024-12-13**|**Benchmarking Linguistic Diversity of Large Language Models**|Yanzhu Guo et.al.|[2412.10271v1](http://arxiv.org/abs/2412.10271v1)|[link](https://github.com/yanzhuguo/llm-diversity)|
|**2024-12-13**|**Cultural Evolution of Cooperation among LLM Agents**|Aron Vallinder et.al.|[2412.10270v1](http://arxiv.org/abs/2412.10270v1)|null|
|**2024-12-13**|**Does Multiple Choice Have a Future in the Age of Generative AI? A Posttest-only RCT**|Danielle R. Thomas et.al.|[2412.10267v1](http://arxiv.org/abs/2412.10267v1)|[link](https://github.com/cmu-plus/lak2025-advocacy)|
|**2024-12-13**|**Reasoner Outperforms: Generative Stance Detection with Rationalization for Social Media**|Jiaqing Yuan et.al.|[2412.10266v1](http://arxiv.org/abs/2412.10266v1)|null|
|**2024-12-13**|**Targeted Angular Reversal of Weights (TARS) for Knowledge Removal in Large Language Models**|Harry J. Davies et.al.|[2412.10257v1](http://arxiv.org/abs/2412.10257v1)|null|
|**2024-12-13**|**Exploring the Frontiers of Animation Video Generation in the Sora Era: Method, Dataset and Benchmark**|Yudong Jiang et.al.|[2412.10255v1](http://arxiv.org/abs/2412.10255v1)|null|
|**2024-12-13**|**Efficient Continual Pre-training of LLMs for Low-resource Languages**|Arijit Nag et.al.|[2412.10244v1](http://arxiv.org/abs/2412.10244v1)|null|
|**2024-12-13**|**Physics Instrument Design with Reinforcement Learning**|Shah Rukh Qasim et.al.|[2412.10237v1](http://arxiv.org/abs/2412.10237v1)|null|
|**2024-12-13**|**How good is my story? Towards quantitative metrics for evaluating LLM-generated XAI narratives**|Timour Ichmoukhamedov et.al.|[2412.10220v1](http://arxiv.org/abs/2412.10220v1)|null|
|**2024-12-13**|**GAF: Gaussian Avatar Reconstruction from Monocular Videos via Multi-view Diffusion**|Jiapeng Tang et.al.|[2412.10209v1](http://arxiv.org/abs/2412.10209v1)|null|
|**2024-12-13**|**Retrieval-Augmented Semantic Parsing: Using Large Language Models to Improve Generalization**|Xiao Zhang et.al.|[2412.10207v1](http://arxiv.org/abs/2412.10207v1)|null|
|**2024-12-13**|**From Allies to Adversaries: Manipulating LLM Tool-Calling through Adversarial Injection**|Haowei Wang et.al.|[2412.10198v1](http://arxiv.org/abs/2412.10198v1)|null|
|**2024-12-13**|**Solving Robust Markov Decision Processes: Generic, Reliable, Efficient**|Tobias Meggendorfer et.al.|[2412.10185v1](http://arxiv.org/abs/2412.10185v1)|null|
|**2024-12-13**|**Multi-Head Encoding for Extreme Label Classification**|Daojun Liang et.al.|[2412.10182v1](http://arxiv.org/abs/2412.10182v1)|[link](https://github.com/anoise/mhe)|
|**2024-12-13**|**SwiftTry: Fast and Consistent Video Virtual Try-On with Diffusion Models**|Hung Nguyen et.al.|[2412.10178v1](http://arxiv.org/abs/2412.10178v1)|null|
|**2024-12-13**|**Scaling Combinatorial Optimization Neural Improvement Heuristics with Online Search and Adaptation**|Federico Julian Camerota Verdù et.al.|[2412.10163v1](http://arxiv.org/abs/2412.10163v1)|null|
|**2024-12-13**|**Direct Encoding of Declare Constraints in ASP**|Francesco Chiariello et.al.|[2412.10152v1](http://arxiv.org/abs/2412.10152v1)|null|
|**2024-12-13**|**VLR-Bench: Multilingual Benchmark Dataset for Vision-Language Retrieval Augmented Generation**|Hyeonseok Lim et.al.|[2412.10151v1](http://arxiv.org/abs/2412.10151v1)|null|
|**2024-12-13**|**TACOMORE: Leveraging the Potential of LLMs in Corpus-based Discourse Analysis with Prompt Engineering**|Bingru Li et.al.|[2412.10139v1](http://arxiv.org/abs/2412.10139v1)|null|
|**2024-12-13**|**ROUTE: Robust Multitask Tuning and Collaboration for Text-to-SQL**|Yang Qin et.al.|[2412.10138v1](http://arxiv.org/abs/2412.10138v1)|[link](https://github.com/alibaba/route)|
|**2024-12-13**|**Can LLMs Convert Graphs to Text-Attributed Graphs?**|Zehong Wang et.al.|[2412.10136v1](http://arxiv.org/abs/2412.10136v1)|[link](https://github.com/zehong-wang/tans)|
|**2024-12-13**|**ASLoRA: Adaptive Sharing Low-Rank Adaptation Across Layers**|Junyan Hu et.al.|[2412.10135v1](http://arxiv.org/abs/2412.10135v1)|null|
|**2024-12-13**|**You Name It, I Run It: An LLM Agent to Execute Tests of Arbitrary Projects**|Islem Bouzenia et.al.|[2412.10133v1](http://arxiv.org/abs/2412.10133v1)|null|
|**2024-12-13**|**Familiarity: Better Evaluation of Zero-Shot Named Entity Recognition by Quantifying Label Shifts in Synthetic Training Data**|Jonas Golde et.al.|[2412.10121v1](http://arxiv.org/abs/2412.10121v1)|null|
|**2024-12-13**|**CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language Models**|Zhihao Du et.al.|[2412.10117v1](http://arxiv.org/abs/2412.10117v1)|null|
|**2024-12-13**|**Label-template based Few-Shot Text Classification with Contrastive Learning**|Guanghua Hou et.al.|[2412.10110v1](http://arxiv.org/abs/2412.10110v1)|null|
|**2024-12-13**|**NetOrchLLM: Mastering Wireless Network Orchestration with Large Language Models**|Asmaa Abdallah et.al.|[2412.10107v1](http://arxiv.org/abs/2412.10107v1)|null|
|**2024-12-13**|**A Cascaded Dilated Convolution Approach for Mpox Lesion Classification**|Ayush Deshmukh et.al.|[2412.10106v1](http://arxiv.org/abs/2412.10106v1)|null|
|**2024-12-13**|**MALAMUTE: A Multilingual, Highly-granular, Template-free, Education-based Probing Dataset**|Sagi Shaier et.al.|[2412.10105v1](http://arxiv.org/abs/2412.10105v1)|null|
|**2024-12-13**|**RETQA: A Large-Scale Open-Domain Tabular Question Answering Dataset for Real Estate Sector**|Zhensheng Wang et.al.|[2412.10104v1](http://arxiv.org/abs/2412.10104v1)|[link](https://github.com/jensen-w/retqa)|
|**2024-12-13**|**AMuSeD: An Attentive Deep Neural Network for Multimodal Sarcasm Detection Incorporating Bi-modal Data Augmentation**|Xiyuan Gao et.al.|[2412.10103v1](http://arxiv.org/abs/2412.10103v1)|null|
|**2024-12-13**|**HiTZ at VarDial 2025 NorSID: Overcoming Data Scarcity with Language Transfer and Automatic Data Annotation**|Jaione Bengoetxea et.al.|[2412.10095v1](http://arxiv.org/abs/2412.10095v1)|null|
|**2024-12-13**|**AI in the Cosmos**|N. Sahakyan et.al.|[2412.10093v1](http://arxiv.org/abs/2412.10093v1)|null|
|**2024-12-13**|**Lost in the Middle, and In-Between: Enhancing Language Models' Ability to Reason Over Long Contexts in Multi-Hop QA**|George Arthur Baker et.al.|[2412.10079v1](http://arxiv.org/abs/2412.10079v1)|null|
|**2024-12-13**|**Panacea: Novel DNN Accelerator using Accuracy-Preserving Asymmetric Quantization and Energy-Saving Bit-Slice Sparsity**|Dongyun Kam et.al.|[2412.10059v1](http://arxiv.org/abs/2412.10059v1)|null|
|**2024-12-13**|**GAOKAO-Eval: Does high scores truly reflect strong capabilities in LLMs?**|Zhikai Lei et.al.|[2412.10056v1](http://arxiv.org/abs/2412.10056v1)|null|
|**2024-12-13**|**Unsupervised Named Entity Disambiguation for Low Resource Domains**|Debarghya Datta et.al.|[2412.10054v1](http://arxiv.org/abs/2412.10054v1)|[link](https://github.com/deba-iitbh/gst-ned)|
|**2024-12-13**|**TSGaussian: Semantic and Depth-Guided Target-Specific Gaussian Splatting from Sparse Views**|Liang Zhao et.al.|[2412.10051v1](http://arxiv.org/abs/2412.10051v1)|null|
|**2024-12-13**|**Large Action Models: From Inception to Implementation**|Lu Wang et.al.|[2412.10047v1](http://arxiv.org/abs/2412.10047v1)|[link](https://github.com/microsoft/UFO)|
|**2024-12-13**|**Enhanced Speech Emotion Recognition with Efficient Channel Attention Guided Deep CNN-BiLSTM Framework**|Niloy Kumar Kundu et.al.|[2412.10011v1](http://arxiv.org/abs/2412.10011v1)|null|
|**2024-12-13**|**Automated Collection of Evaluation Dataset for Semantic Search in Low-Resource Domain Language**|Anastasia Zhukova et.al.|[2412.10008v1](http://arxiv.org/abs/2412.10008v1)|null|
|**2024-12-13**|**The role of inhibitory control in garden-path sentence processing: A Chinese-English bilingual perspective**|Xiaohui Rao et.al.|[2412.10006v1](http://arxiv.org/abs/2412.10006v1)|null|
|**2024-12-13**|**Cycle-Consistent Bridge Diffusion Model for Accelerated MRI Reconstruction**|Tao Song et.al.|[2412.09998v1](http://arxiv.org/abs/2412.09998v1)|null|
|**2024-12-13**|**A Comparative Study of LLMs, NMT Models, and Their Combination in Persian-English Idiom Translation**|Sara Rezaeimanesh et.al.|[2412.09993v1](http://arxiv.org/abs/2412.09993v1)|null|
|**2024-12-13**|**Visual Object Tracking across Diverse Data Modalities: A Review**|Mengmeng Wang et.al.|[2412.09991v1](http://arxiv.org/abs/2412.09991v1)|null|
|**2024-12-13**|**Small Language Model as Data Prospector for Large Language Model**|Shiwen Ni et.al.|[2412.09990v1](http://arxiv.org/abs/2412.09990v1)|null|
|**2024-12-13**|**AI and the Future of Digital Public Squares**|Beth Goldberg et.al.|[2412.09988v1](http://arxiv.org/abs/2412.09988v1)|null|
|**2024-12-13**|**Efficient Large-Scale Traffic Forecasting with Transformers: A Spatial Data Management Perspective**|Yuchen Fang et.al.|[2412.09972v1](http://arxiv.org/abs/2412.09972v1)|[link](https://github.com/lmissher/patchstg)|
|**2024-12-13**|**EP-CFG: Energy-Preserving Classifier-Free Guidance**|Kai Zhang et.al.|[2412.09966v1](http://arxiv.org/abs/2412.09966v1)|null|
|**2024-12-13**|**Romanized to Native Malayalam Script Transliteration Using an Encoder-Decoder Framework**|Bajiyo Baiju et.al.|[2412.09957v1](http://arxiv.org/abs/2412.09957v1)|null|
|**2024-12-13**|**Enhancing Nursing and Elderly Care with Large Language Models: An AI-Driven Framework**|Qiao Sun et.al.|[2412.09946v1](http://arxiv.org/abs/2412.09946v1)|null|
|**2024-12-13**|**Low-Resource Fast Text Classification Based on Intra-Class and Inter-Class Distance Calculation**|Yanxu Mao et.al.|[2412.09922v1](http://arxiv.org/abs/2412.09922v1)|null|
|**2024-12-13**|**B-VLLM: A Vision Large Language Model with Balanced Spatio-Temporal Tokens**|Zhuqiang Lu et.al.|[2412.09919v1](http://arxiv.org/abs/2412.09919v1)|null|
|**2024-12-13**|**Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning**|Jing Bi et.al.|[2412.09906v1](http://arxiv.org/abs/2412.09906v1)|[link](https://github.com/bijings/sgft)|
|**2024-12-13**|**Analyzing Fairness of Computer Vision and Natural Language Processing Models**|Ahmed Rashed et.al.|[2412.09900v1](http://arxiv.org/abs/2412.09900v1)|null|
|**2024-12-13**|**Analyzing Fairness of Classification Machine Learning Model with Structured Dataset**|Ahmed Rashed et.al.|[2412.09896v1](http://arxiv.org/abs/2412.09896v1)|null|
|**2024-12-13**|**Semi-Periodic Activation for Time Series Classification**|José Gilberto Barbosa de Medeiros Júnior et.al.|[2412.09889v1](http://arxiv.org/abs/2412.09889v1)|[link](https://github.com/jose-gilberto/leakysinelu)|
|**2024-12-13**|**CSL-L2M: Controllable Song-Level Lyric-to-Melody Generation Based on Conditional Transformer with Fine-Grained Lyric and Musical Controls**|Li Chai et.al.|[2412.09887v1](http://arxiv.org/abs/2412.09887v1)|null|
|**2024-12-13**|**Benchmarking Table Comprehension In The Wild**|Yikang Pan et.al.|[2412.09884v1](http://arxiv.org/abs/2412.09884v1)|null|
|**2024-12-13**|**On the Limit of Language Models as Planning Formalizers**|Cassie Huang et.al.|[2412.09879v1](http://arxiv.org/abs/2412.09879v1)|null|
|**2024-12-13**|**Byte Latent Transformer: Patches Scale Better Than Tokens**|Artidoro Pagnoni et.al.|[2412.09871v1](http://arxiv.org/abs/2412.09871v1)|[link](https://github.com/facebookresearch/blt)|
|**2024-12-13**|**Financial Sentiment Analysis: Leveraging Actual and Synthetic Data for Supervised Fine-tuning**|Abraham Atsiwo et.al.|[2412.09859v1](http://arxiv.org/abs/2412.09859v1)|null|
|**2024-12-13**|**RLDG: Robotic Generalist Policy Distillation via Reinforcement Learning**|Charles Xu et.al.|[2412.09858v1](http://arxiv.org/abs/2412.09858v1)|null|
|**2024-12-13**|**LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity**|Hongjie Wang et.al.|[2412.09856v1](http://arxiv.org/abs/2412.09856v1)|null|
|**2024-12-13**|**Learning Structural Causal Models from Ordering: Identifiable Flow Models**|Minh Khoa Le et.al.|[2412.09843v1](http://arxiv.org/abs/2412.09843v1)|null|
|**2024-12-13**|**Low-Rank Adaptation with Task-Relevant Feature Enhancement for Fine-tuning Language Models**|Changqun Li et.al.|[2412.09827v1](http://arxiv.org/abs/2412.09827v1)|null|
|**2024-12-13**|**Precise Antigen-Antibody Structure Predictions Enhance Antibody Development with HelixFold-Multimer**|Jie Gao et.al.|[2412.09826v1](http://arxiv.org/abs/2412.09826v1)|null|
|**2024-12-13**|**MERaLiON-AudioLLM: Technical Report**|Yingxu He et.al.|[2412.09818v1](http://arxiv.org/abs/2412.09818v1)|null|
|**2024-12-13**|**Enhancing Multimodal Large Language Models Complex Reason via Similarity Computation**|Xiaofeng Zhang et.al.|[2412.09817v1](http://arxiv.org/abs/2412.09817v1)|[link](https://github.com/fanshuozeng/simignore)|
|**2024-12-13**|**Temporal Causal Discovery in Dynamic Bayesian Networks Using Federated Learning**|Jianhong Chen et.al.|[2412.09814v1](http://arxiv.org/abs/2412.09814v1)|null|
|**2024-12-13**|**ScaleOT: Privacy-utility-scalable Offsite-tuning with Dynamic LayerReplace and Selective Rank Compression**|Kai Yao et.al.|[2412.09812v1](http://arxiv.org/abs/2412.09812v1)|null|
|**2024-12-13**|**LLM Distillation for Efficient Few-Shot Multiple Choice Question Answering**|Patrick Sutanto et.al.|[2412.09807v1](http://arxiv.org/abs/2412.09807v1)|null|
|**2024-12-13**|**Universal Inceptive GNNs by Eliminating the Smoothness-generalization Dilemma**|Ming Gu et.al.|[2412.09805v1](http://arxiv.org/abs/2412.09805v1)|null|
|**2024-12-13**|**CP-DETR: Concept Prompt Guide DETR Toward Stronger Universal Object Detection**|Qibo Chen et.al.|[2412.09799v1](http://arxiv.org/abs/2412.09799v1)|null|
|**2024-12-13**|**AutoPatent: A Multi-Agent Framework for Automatic Patent Generation**|Qiyao Wang et.al.|[2412.09796v1](http://arxiv.org/abs/2412.09796v1)|[link](https://github.com/qiyao-wang/autopatent)|
|**2024-12-13**|**Learning Visually Grounded Domain Ontologies via Embodied Conversation and Explanation**|Jonghyuk Park et.al.|[2412.09770v1](http://arxiv.org/abs/2412.09770v1)|[link](https://github.com/jpstyle/ns-arch-unity)|
|**2024-12-12**|**Memory Layers at Scale**|Vincent-Pierre Berges et.al.|[2412.09764v1](http://arxiv.org/abs/2412.09764v1)|[link](https://github.com/facebookresearch/memory)|
|**2024-12-12**|**Congruence-based Learning of Probabilistic Deterministic Finite Automata**|Matías Carrasco et.al.|[2412.09760v1](http://arxiv.org/abs/2412.09760v1)|null|
|**2024-12-12**|**AI Red-Teaming is a Sociotechnical System. Now What?**|Tarleton Gillespie et.al.|[2412.09751v1](http://arxiv.org/abs/2412.09751v1)|null|
|**2024-12-12**|**Let Curves Speak: A Continuous Glucose Monitor based Large Sensor Foundation Model for Diabetes Management**|Junjie Luo et.al.|[2412.09727v1](http://arxiv.org/abs/2412.09727v1)|null|
|**2024-12-12**|**The Unreasonable Effectiveness of Gaussian Score Approximation for Diffusion Models and its Applications**|Binxu Wang et.al.|[2412.09726v1](http://arxiv.org/abs/2412.09726v1)|null|
|**2024-12-12**|**GReaTer: Gradients over Reasoning Makes Smaller Language Models Strong Prompt Optimizers**|Sarkar Snigdha Sarathi Das et.al.|[2412.09722v1](http://arxiv.org/abs/2412.09722v1)|null|
|**2024-12-12**|**Human vs. AI: A Novel Benchmark and a Comparative Study on the Detection of Generated Images and the Impact of Prompts**|Philipp Moeßner et.al.|[2412.09715v1](http://arxiv.org/abs/2412.09715v1)|[link](https://github.com/heikeadel/cocoxgen)|

#### Abstracts
##### **GaussianWorld: Gaussian World Model for Streaming 3D Occupancy Prediction**
2412.10373v1 by Sicheng Zuo, Wenzhao Zheng, Yuanhui Huang, Jie Zhou, Jiwen Lu

3D occupancy prediction is important for autonomous driving due to its
comprehensive perception of the surroundings. To incorporate sequential inputs,
most existing methods fuse representations from previous frames to infer the
current 3D occupancy. However, they fail to consider the continuity of driving
scenarios and ignore the strong prior provided by the evolution of 3D scenes
(e.g., only dynamic objects move). In this paper, we propose a
world-model-based framework to exploit the scene evolution for perception. We
reformulate 3D occupancy prediction as a 4D occupancy forecasting problem
conditioned on the current sensor input. We decompose the scene evolution into
three factors: 1) ego motion alignment of static scenes; 2) local movements of
dynamic objects; and 3) completion of newly-observed scenes. We then employ a
Gaussian world model (GaussianWorld) to explicitly exploit these priors and
infer the scene evolution in the 3D Gaussian space considering the current RGB
observation. We evaluate the effectiveness of our framework on the widely used
nuScenes dataset. Our GaussianWorld improves the performance of the
single-frame counterpart by over 2% in mIoU without introducing additional
computations. Code: https://github.com/zuosc19/GaussianWorld.

摘要：3D 佔用預測對於自動駕駛很重要，因為它能全面感知周圍環境。為了納入序列輸入，大多數現有方法融合了前幾幀的表示，以推論當前的 3D 佔用。然而，它們未能考慮駕駛場景的連續性，並且忽略了 3D 場景演化所提供的強先驗（例如，只有動態物體會移動）。在本文中，我們提出了一個基於世界模型的框架，以利用場景演化進行感知。我們將 3D 佔用預測重新表述為 4D 佔用預測問題，條件取決於當前的感測器輸入。我們將場景演化分解為三個因素：1）靜態場景的自運動對齊；2）動態物體的局部運動；以及 3）新觀察場景的完成。然後，我們採用高斯世界模型 (GaussianWorld) 來明確利用這些先驗，並在考慮當前 RGB 觀測值的情況下，推論 3D 高斯空間中的場景演化。我們在廣泛使用的 nuScenes 資料集上評估了我們框架的有效性。我們的 GaussianWorld 在不引入額外計算的情況下，將單幀對應項的 mIoU 效能提升了 2% 以上。程式碼：https://github.com/zuosc19/GaussianWorld。

##### **A Grounded Typology of Word Classes**
2412.10369v1 by Coleman Haley, Sharon Goldwater, Edoardo Ponti

We propose a grounded approach to meaning in language typology. We treat data
from perceptual modalities, such as images, as a language-agnostic
representation of meaning. Hence, we can quantify the function--form
relationship between images and captions across languages. Inspired by
information theory, we define "groundedness", an empirical measure of
contextual semantic contentfulness (formulated as a difference in surprisal)
which can be computed with multilingual multimodal language models. As a proof
of concept, we apply this measure to the typology of word classes. Our measure
captures the contentfulness asymmetry between functional (grammatical) and
lexical (content) classes across languages, but contradicts the view that
functional classes do not convey content. Moreover, we find universal trends in
the hierarchy of groundedness (e.g., nouns > adjectives > verbs), and show that
our measure partly correlates with psycholinguistic concreteness norms in
English. We release a dataset of groundedness scores for 30 languages. Our
results suggest that the grounded typology approach can provide quantitative
evidence about semantic function in language.

摘要：我們提出了一個基於語言類型學意義的紮實方法。我們將來自感知方式的數據（例如圖像）視為一種與語言無關的意義表示。因此，我們可以量化跨語言的圖像和字幕之間的功能形式關係。受資訊理論的啟發，我們定義了「紮實性」，這是一個上下文語義內容豐富性的經驗測量（表述為驚奇的差異），可以用多語言多模態語言模型計算。作為概念驗證，我們將此測量應用於詞類的類型學。我們的測量捕捉了跨語言的功能（語法）和詞彙（內容）類別之間的內容豐富性不對稱，但與功能類別不傳達內容的觀點相矛盾。此外，我們發現了紮實性層級中的普遍趨勢（例如，名詞>形容詞>動詞），並表明我們的測量部分與英語的心理語言具體性規範相關。我們發布了一個包含 30 種語言的紮實性分數的數據集。我們的結果表明，紮實類型學方法可以提供關於語言中語義功能的量化證據。

##### **Apollo: An Exploration of Video Understanding in Large Multimodal Models**
2412.10360v1 by Orr Zohar, Xiaohan Wang, Yann Dubois, Nikhil Mehta, Tong Xiao, Philippe Hansen-Estruch, Licheng Yu, Xiaofang Wang, Felix Juefei-Xu, Ning Zhang, Serena Yeung-Levy, Xide Xia

Despite the rapid integration of video perception capabilities into Large
Multimodal Models (LMMs), the underlying mechanisms driving their video
understanding remain poorly understood. Consequently, many design decisions in
this domain are made without proper justification or analysis. The high
computational cost of training and evaluating such models, coupled with limited
open research, hinders the development of video-LMMs. To address this, we
present a comprehensive study that helps uncover what effectively drives video
understanding in LMMs.
  We begin by critically examining the primary contributors to the high
computational requirements associated with video-LMM research and discover
Scaling Consistency, wherein design and training decisions made on smaller
models and datasets (up to a critical size) effectively transfer to larger
models. Leveraging these insights, we explored many video-specific aspects of
video-LMMs, including video sampling, architectures, data composition, training
schedules, and more. For example, we demonstrated that fps sampling during
training is vastly preferable to uniform frame sampling and which vision
encoders are the best for video representation.
  Guided by these findings, we introduce Apollo, a state-of-the-art family of
LMMs that achieve superior performance across different model sizes. Our models
can perceive hour-long videos efficiently, with Apollo-3B outperforming most
existing $7$B models with an impressive 55.1 on LongVideoBench. Apollo-7B is
state-of-the-art compared to 7B LMMs with a 70.9 on MLVU, and 63.3 on
Video-MME.

摘要：儘管影片感知能力已快速整合至大型多模態模型 (LMM)，但驅動其影片理解的底層機制仍鮮為人知。因此，此領域中的許多設計決策都是在缺乏適當依據或分析的情況下做出的。訓練和評估此類模型的高運算成本，加上有限的公開研究，阻礙了影片 LMM 的發展。為了解決這個問題，我們提出了一項全面性研究，有助於揭示有效驅動 LMM 中影片理解的因素。
我們首先批判性地審視與影片 LMM 研究相關的高運算需求的主要因素，並發現規模一致性，其中在較小型號和資料集（達到臨界規模）上做出的設計和訓練決策，可有效轉移到較大型號。運用這些見解，我們探討了影片 LMM 的許多影片特定面向，包括影片取樣、架構、資料組成、訓練時程等。例如，我們證明了訓練期間的 fps 取樣遠比均勻的影格取樣來得理想，以及哪種視覺編碼器最適合影片表徵。
在這些發現的指導下，我們推出了 Apollo，一個最先進的 LMM 系列，可在不同模型規模中實現卓越的效能。我們的模型可以有效感知長達一小時的影片，其中 Apollo-3B 以令人印象深刻的 LongVideoBench 55.1 分數，超越了現有的 $7$B 模型。Apollo-7B 以 MLVU 70.9 分和 Video-MME 63.3 分，與 7B LMM 相比是目前最先進的。

##### **A Library for Learning Neural Operators**
2412.10354v1 by Jean Kossaifi, Nikola Kovachki, Zongyi Li, Davit Pitt, Miguel Liu-Schiaffini, Robert Joseph George, Boris Bonev, Kamyar Azizzadenesheli, Julius Berner, Anima Anandkumar

We present NeuralOperator, an open-source Python library for operator
learning. Neural operators generalize neural networks to maps between function
spaces instead of finite-dimensional Euclidean spaces. They can be trained and
inferenced on input and output functions given at various discretizations,
satisfying a discretization convergence properties. Built on top of PyTorch,
NeuralOperator provides all the tools for training and deploying neural
operator models, as well as developing new ones, in a high-quality, tested,
open-source package. It combines cutting-edge models and customizability with a
gentle learning curve and simple user interface for newcomers.

摘要：我們展示了 NeuralOperator，這是一個用於算子學習的開源 Python 函式庫。神經算子將神經網路概括為函數空間之間的映射，而不是有限維的歐幾里得空間。它們可以在各種離散化中給出的輸入和輸出函數上進行訓練和推論，滿足離散化收斂特性。NeuralOperator 建構在 PyTorch 之上，提供訓練和部署神經算子模型以及開發新模型的所有工具，並以高品質、經過測試的開源套件提供。它結合了尖端的模型和可自訂性，並為新手提供了平緩的學習曲線和簡單的使用者介面。

##### **A dual contrastive framework**
2412.10348v1 by Yuan Sun, Zhao Zhang, Jorge Ortiz

In current multimodal tasks, models typically freeze the encoder and decoder
while adapting intermediate layers to task-specific goals, such as region
captioning. Region-level visual understanding presents significant challenges
for large-scale vision-language models. While limited spatial awareness is a
known issue, coarse-grained pretraining, in particular, exacerbates the
difficulty of optimizing latent representations for effective encoder-decoder
alignment. We propose AlignCap, a framework designed to enhance region-level
understanding through fine-grained alignment of latent spaces. Our approach
introduces a novel latent feature refinement module that enhances conditioned
latent space representations to improve region-level captioning performance. We
also propose an innovative alignment strategy, the semantic space alignment
module, which boosts the quality of multimodal representations. Additionally,
we incorporate contrastive learning in a novel manner within both modules to
further enhance region-level captioning performance. To address spatial
limitations, we employ a General Object Detection (GOD) method as a data
preprocessing pipeline that enhances spatial reasoning at the regional level.
Extensive experiments demonstrate that our approach significantly improves
region-level captioning performance across various tasks

摘要：在當前的多模態任務中，模型通常會凍結編碼器和解碼器，同時調整中間層以適應特定任務的目標，例如區域標題。區域級別的視覺理解對大規模視覺語言模型提出了重大挑戰。儘管已知空間感知有限是一個問題，但粗粒度預訓練尤其會加劇優化潛在表示以實現有效編碼器-解碼器對齊的難度。我們提出了 AlignCap，一個旨在通過潛在空間的細粒度對齊來增強區域級別理解的框架。我們的做法引入了一個新穎的潛在特徵細化模組，它增強了條件潛在空間表示以改善區域級別標題的性能。我們還提出了一種創新的對齊策略，語義空間對齊模組，它提升了多模態表示的品質。此外，我們在兩個模組中以一種新穎的方式納入了對比學習，以進一步增強區域級別的標題性能。為了解決空間限制，我們採用通用物件偵測 (GOD) 方法作為資料預處理管道，它增強了區域級別的空間推理。廣泛的實驗表明，我們的做法顯著改善了各種任務中的區域級別標題性能

##### **COMET: Benchmark for Comprehensive Biological Multi-omics Evaluation Tasks and Language Models**
2412.10347v1 by Yuchen Ren, Wenwei Han, Qianyuan Zhang, Yining Tang, Weiqiang Bai, Yuchen Cai, Lifeng Qiao, Hao Jiang, Dong Yuan, Tao Chen, Siqi Sun, Pan Tan, Wanli Ouyang, Nanqing Dong, Xinzhu Ma, Peng Ye

As key elements within the central dogma, DNA, RNA, and proteins play crucial
roles in maintaining life by guaranteeing accurate genetic expression and
implementation. Although research on these molecules has profoundly impacted
fields like medicine, agriculture, and industry, the diversity of machine
learning approaches-from traditional statistical methods to deep learning
models and large language models-poses challenges for researchers in choosing
the most suitable models for specific tasks, especially for cross-omics and
multi-omics tasks due to the lack of comprehensive benchmarks. To address this,
we introduce the first comprehensive multi-omics benchmark COMET (Benchmark for
Biological COmprehensive Multi-omics Evaluation Tasks and Language Models),
designed to evaluate models across single-omics, cross-omics, and multi-omics
tasks. First, we curate and develop a diverse collection of downstream tasks
and datasets covering key structural and functional aspects in DNA, RNA, and
proteins, including tasks that span multiple omics levels. Then, we evaluate
existing foundational language models for DNA, RNA, and proteins, as well as
the newly proposed multi-omics method, offering valuable insights into their
performance in integrating and analyzing data from different biological
modalities. This benchmark aims to define critical issues in multi-omics
research and guide future directions, ultimately promoting advancements in
understanding biological processes through integrated and different omics data
analysis.

摘要：作為中心法則中的關鍵元素，DNA、RNA 和蛋白質在維持生命方面發揮著至關重要的作用，它們保證了準確的基因表達和實施。儘管對這些分子的研究對醫學、農業和工業等領域產生了深遠的影響，但機器學習方法的多樣性（從傳統的統計方法到深度學習模型和大語言模型）對研究人員在為特定任務選擇最合適的模型提出了挑戰，特別是對於組學間和多組學任務，這是由於缺乏全面的基準。為了解決這個問題，我們引入了第一個全面的多組學基準 COMET（生物綜合多組學評估任務和語言模型基準），旨在評估模型在單組學、組學間和多組學任務中的表現。首先，我們策劃並開發了一系列多樣的下游任務和數據集，涵蓋了 DNA、RNA 和蛋白質中的關鍵結構和功能方面，包括跨越多個組學層級的任務。然後，我們評估了現有的 DNA、RNA 和蛋白質基礎語言模型，以及新提出的多組學方法，對它們整合和分析來自不同生物模式的數據的性能提供了寶貴的見解。這個基準旨在定義多組學研究中的關鍵問題並指導未來的方向，最終通過整合和不同的組學數據分析促進對生物過程的理解。

##### **TraceVLA: Visual Trace Prompting Enhances Spatial-Temporal Awareness for Generalist Robotic Policies**
2412.10345v1 by Ruijie Zheng, Yongyuan Liang, Shuaiyi Huang, Jianfeng Gao, Hal Daumé III, Andrey Kolobov, Furong Huang, Jianwei Yang

Although large vision-language-action (VLA) models pretrained on extensive
robot datasets offer promising generalist policies for robotic learning, they
still struggle with spatial-temporal dynamics in interactive robotics, making
them less effective in handling complex tasks, such as manipulation. In this
work, we introduce visual trace prompting, a simple yet effective approach to
facilitate VLA models' spatial-temporal awareness for action prediction by
encoding state-action trajectories visually. We develop a new TraceVLA model by
finetuning OpenVLA on our own collected dataset of 150K robot manipulation
trajectories using visual trace prompting. Evaluations of TraceVLA across 137
configurations in SimplerEnv and 4 tasks on a physical WidowX robot demonstrate
state-of-the-art performance, outperforming OpenVLA by 10% on SimplerEnv and
3.5x on real-robot tasks and exhibiting robust generalization across diverse
embodiments and scenarios. To further validate the effectiveness and generality
of our method, we present a compact VLA model based on 4B Phi-3-Vision,
pretrained on the Open-X-Embodiment and finetuned on our dataset, rivals the 7B
OpenVLA baseline while significantly improving inference efficiency.

摘要：儘管在廣泛機器人資料集上預訓練的大型視覺語言動作 (VLA) 模型為機器人學習提供了有前途的通才策略，但它們在互動機器人中的時空動態上仍有困難，這使得它們在處理複雜任務（例如操作）時效率較低。在這項工作中，我們引入了視覺軌跡提示，這是一種簡單但有效的方法，通過視覺編碼狀態動作軌跡來促進 VLA 模型的時空感知，以進行動作預測。我們通過使用視覺軌跡提示，在我們自己收集的 150K 機器人操作軌跡數據集上對 OpenVLA 進行微調，開發了一個新的 TraceVLA 模型。TraceVLA 在 SimplerEnv 中的 137 種配置和物理 WidowX 機器人上的 4 項任務的評估證明了最先進的效能，在 SimplerEnv 上比 OpenVLA 高出 10%，在真實機器人任務上高出 3.5 倍，並在不同的具體化和場景中表現出強大的泛化能力。為了進一步驗證我們方法的有效性和普遍性，我們提出了一個基於 4B Phi-3-Vision 的緊湊 VLA 模型，在 Open-X-Embodiment 上預訓練並在我們的數據集上進行微調，與 7B OpenVLA 基線相媲美，同時顯著提高了推理效率。

##### **Iris: Breaking GUI Complexity with Adaptive Focus and Self-Refining**
2412.10342v1 by Zhiqi Ge, Juncheng Li, Xinglei Pang, Minghe Gao, Kaihang Pan, Wang Lin, Hao Fei, Wenqiao Zhang, Siliang Tang, Yueting Zhuang

Digital agents are increasingly employed to automate tasks in interactive
digital environments such as web pages, software applications, and operating
systems. While text-based agents built on Large Language Models (LLMs) often
require frequent updates due to platform-specific APIs, visual agents
leveraging Multimodal Large Language Models (MLLMs) offer enhanced adaptability
by interacting directly with Graphical User Interfaces (GUIs). However, these
agents face significant challenges in visual perception, particularly when
handling high-resolution, visually complex digital environments. This paper
introduces Iris, a foundational visual agent that addresses these challenges
through two key innovations: Information-Sensitive Cropping (ISC) and
Self-Refining Dual Learning (SRDL). ISC dynamically identifies and prioritizes
visually dense regions using a edge detection algorithm, enabling efficient
processing by allocating more computational resources to areas with higher
information density. SRDL enhances the agent's ability to handle complex tasks
by leveraging a dual-learning loop, where improvements in referring (describing
UI elements) reinforce grounding (locating elements) and vice versa, all
without requiring additional annotated data. Empirical evaluations demonstrate
that Iris achieves state-of-the-art performance across multiple benchmarks with
only 850K GUI annotations, outperforming methods using 10x more training data.
These improvements further translate to significant gains in both web and OS
agent downstream tasks.

摘要：數位代理人愈來愈常被用來自動化互動式數位環境中的任務，例如網頁、軟體應用程式和作業系統。雖然建立在大型語言模型 (LLM) 上的文字代理人通常需要頻繁更新，以符合特定平台的 API，但利用多模態大型語言模型 (MLLM) 的視覺代理人透過直接與圖形使用者介面 (GUI) 互動，提供增強的適應性。然而，這些代理人在視覺感知方面面臨重大挑戰，特別是在處理高解析度、視覺複雜的數位環境時。本文介紹 Iris，這是一個基礎視覺代理人，透過兩項主要創新來解決這些挑戰：資訊敏感裁切 (ISC) 和自我精進雙重學習 (SRDL)。ISC 使用邊緣偵測演算法動態識別和優先處理視覺密集區域，透過將更多運算資源配置到資訊密度較高的區域，實現有效率的處理。SRDL 透過利用雙重學習迴圈來增強代理人處理複雜任務的能力，其中參照（描述 UI 元素）的改進強化了基礎（定位元素），反之亦然，而且所有這些都不需要額外的註解資料。經驗評估顯示，Iris 僅使用 850K GUI 註解，就在多個基準測試中達到最先進的效能，表現優於使用多 10 倍訓練資料的方法。這些改進進一步轉化為網頁和作業系統代理人下游任務的顯著收益。

##### **Generative AI in Medicine**
2412.10337v1 by Divya Shanmugam, Monica Agrawal, Rajiv Movva, Irene Y. Chen, Marzyeh Ghassemi, Emma Pierson

The increased capabilities of generative AI have dramatically expanded its
possible use cases in medicine. We provide a comprehensive overview of
generative AI use cases for clinicians, patients, clinical trial organizers,
researchers, and trainees. We then discuss the many challenges -- including
maintaining privacy and security, improving transparency and interpretability,
upholding equity, and rigorously evaluating models -- which must be overcome to
realize this potential, and the open research directions they give rise to.

摘要：生成式 AI 的能力提升大幅擴展了其在醫學中的潛在應用案例。我們提供了一個全面的概觀，說明生成式 AI 在臨床醫生、患者、臨床試驗組織者、研究人員和受訓人員的應用案例。接著，我們討論了許多挑戰，包括維護隱私和安全性、提升透明度和可解釋性、維護公平性，以及嚴格評估模型，這些挑戰必須克服才能實現這種潛力，以及它們引發的開放研究方向。

##### **AdvPrefix: An Objective for Nuanced LLM Jailbreaks**
2412.10321v1 by Sicheng Zhu, Brandon Amos, Yuandong Tian, Chuan Guo, Ivan Evtimov

Many jailbreak attacks on large language models (LLMs) rely on a common
objective: making the model respond with the prefix "Sure, here is (harmful
request)". While straightforward, this objective has two limitations: limited
control over model behaviors, often resulting in incomplete or unrealistic
responses, and a rigid format that hinders optimization. To address these
limitations, we introduce AdvPrefix, a new prefix-forcing objective that
enables more nuanced control over model behavior while being easy to optimize.
Our objective leverages model-dependent prefixes, automatically selected based
on two criteria: high prefilling attack success rates and low negative
log-likelihood. It can further simplify optimization by using multiple prefixes
for a single user request. AdvPrefix can integrate seamlessly into existing
jailbreak attacks to improve their performance for free. For example, simply
replacing GCG attack's target prefixes with ours on Llama-3 improves nuanced
attack success rates from 14% to 80%, suggesting that current alignment
struggles to generalize to unseen prefixes. Our work demonstrates the
importance of jailbreak objectives in achieving nuanced jailbreaks.

摘要：許多針對大型語言模型 (LLM) 的越獄攻擊都依賴於一個共同目標：讓模型以「好的，以下是 (有害請求)」的前綴回應。雖然直接了當，但此目標有兩個限制：對模型行為的控制有限，通常會導致不完整或不切實際的回應，以及阻礙最佳化的僵化格式。為了解決這些限制，我們引入了 AdvPrefix，這是一個新的前綴強制目標，可以在易於最佳化的同時，對模型行為進行更細緻的控制。我們的目標利用了依據兩個標準自動選取的模型依賴前綴：高預填充攻擊成功率和低負對數似然度。它可以透過對單一使用者請求使用多個前綴，進一步簡化最佳化。AdvPrefix 可以無縫整合到現有的越獄攻擊中，以免費提升其效能。例如，僅僅用我們 Llama-3 上的目標前綴取代 GCG 攻擊的目標前綴，就能將細緻的攻擊成功率從 14% 提升至 80%，這表示目前的比對難以概括到未見的前綴。我們的研究展示了越獄目標在達成細緻越獄中的重要性。

##### **SCBench: A KV Cache-Centric Analysis of Long-Context Methods**
2412.10319v1 by Yucheng Li, Huiqiang Jiang, Qianhui Wu, Xufang Luo, Surin Ahn, Chengruidong Zhang, Amir H. Abdi, Dongsheng Li, Jianfeng Gao, Yuqing Yang, Lili Qiu

Long-context LLMs have enabled numerous downstream applications but also
introduced significant challenges related to computational and memory
efficiency. To address these challenges, optimizations for long-context
inference have been developed, centered around the KV cache. However, existing
benchmarks often evaluate in single-request, neglecting the full lifecycle of
the KV cache in real-world use. This oversight is particularly critical, as KV
cache reuse has become widely adopted in LLMs inference frameworks, such as
vLLM and SGLang, as well as by LLM providers, including OpenAI, Microsoft,
Google, and Anthropic. To address this gap, we introduce
SCBench(SharedContextBench), a comprehensive benchmark for evaluating
long-context methods from a KV cachecentric perspective: 1) KV cache
generation, 2) KV cache compression, 3) KV cache retrieval, 4) KV cache
loading. Specifically, SCBench uses test examples with shared context, ranging
12 tasks with two shared context modes, covering four categories of
long-context capabilities: string retrieval, semantic retrieval, global
information, and multi-task. With it, we provide an extensive KV cache-centric
analysis of eight categories long-context solutions, including Gated Linear
RNNs, Mamba-Attention hybrids, and efficient methods such as sparse attention,
KV cache dropping, quantization, retrieval, loading, and prompt compression.
The evaluation is conducted on 8 long-context LLMs. Our findings show that
sub-O(n) memory methods suffer in multi-turn scenarios, while sparse encoding
with O(n) memory and sub-O(n^2) pre-filling computation perform robustly.
Dynamic sparsity yields more expressive KV caches than static patterns, and
layer-level sparsity in hybrid architectures reduces memory usage with strong
performance. Additionally, we identify attention distribution shift issues in
long-generation scenarios. https://aka.ms/SCBench.

摘要：長語境 LLM 已啟用許多下游應用程式，但也引入了與運算和記憶體效率相關的重大挑戰。為了應對這些挑戰，已針對長語境推論開發最佳化，集中在 KV 快取上。然而，現有的基準測試通常在單一要求中進行評估，忽略了 KV 快取在實際使用中的完整生命週期。這種疏忽特別關鍵，因為 KV 快取重複使用已在 LLM 推論架構中廣泛採用，例如 vLLM 和 SGLang，以及 LLM 供應商，包括 OpenAI、Microsoft、Google 和 Anthropic。為了解決這個差距，我們引入了 SCBench（SharedContextBench），這是一個全面的基準測試，用 KV 快取為中心的觀點評估長語境方法：1) KV 快取產生，2) KV 快取壓縮，3) KV 快取擷取，4) KV 快取載入。具體來說，SCBench 使用具有共用語境的測試範例，範圍涵蓋兩種共用語境模式的 12 個任務，涵蓋長語境功能的四種類別：字串擷取、語意擷取、全域資訊和多任務。透過它，我們提供了對八種類別長語境解決方案的廣泛 KV 快取為中心分析，包括閘控線性 RNN、Mamba-Attention 混合體，以及稀疏注意力、KV 快取捨棄、量化、擷取、載入和提示壓縮等有效方法。評估是在 8 個長語境 LLM 上進行的。我們的研究結果顯示，sub-O(n) 記憶體方法在多輪情況下會受到影響，而具有 O(n) 記憶體和 sub-O(n^2) 預先填入運算的稀疏編碼則表現得很好。動態稀疏性產生比靜態模式更具表現力的 KV 快取，而混合架構中的層級稀疏性則以強勁的效能降低記憶體使用量。此外，我們在長生成情況中發現了注意力分佈轉移問題。https://aka.ms/SCBench。

##### **BrushEdit: All-In-One Image Inpainting and Editing**
2412.10316v1 by Yaowei Li, Yuxuan Bian, Xuan Ju, Zhaoyang Zhang, Ying Shan, Qiang Xu

Image editing has advanced significantly with the development of diffusion
models using both inversion-based and instruction-based methods. However,
current inversion-based approaches struggle with big modifications (e.g.,
adding or removing objects) due to the structured nature of inversion noise,
which hinders substantial changes. Meanwhile, instruction-based methods often
constrain users to black-box operations, limiting direct interaction for
specifying editing regions and intensity. To address these limitations, we
propose BrushEdit, a novel inpainting-based instruction-guided image editing
paradigm, which leverages multimodal large language models (MLLMs) and image
inpainting models to enable autonomous, user-friendly, and interactive
free-form instruction editing. Specifically, we devise a system enabling
free-form instruction editing by integrating MLLMs and a dual-branch image
inpainting model in an agent-cooperative framework to perform editing category
classification, main object identification, mask acquisition, and editing area
inpainting. Extensive experiments show that our framework effectively combines
MLLMs and inpainting models, achieving superior performance across seven
metrics including mask region preservation and editing effect coherence.

摘要：影像編輯隨著使用基於反演和基於指令方法的擴散模型的發展而顯著進步。然而，當前的基於反演的方法由於反演雜訊的結構性質而難以進行大幅修改（例如，增加或移除物件），這阻礙了實質性的變更。同時，基於指令的方法通常限制使用者只能進行黑盒子操作，限制了直接互動以指定編輯區域和強度。為了解決這些限制，我們提出了 BrushEdit，一種新穎的基於內插的指令引導影像編輯範例，它利用多模態大型語言模型 (MLLM) 和影像內插模型來實現自主、使用者友善且互動的自由形式指令編輯。具體來說，我們設計了一個系統，透過整合 MLLM 和一個雙分支影像內插模型在一個代理合作架構中來執行編輯類別分類、主物件識別、遮罩擷取和編輯區域內插，從而實現自由形式指令編輯。廣泛的實驗表明，我們的架構有效地結合了 MLLM 和內插模型，在七項指標中實現了卓越的效能，包括遮罩區域保留和編輯效果一致性。

##### **Interlocking-free Selective Rationalization Through Genetic-based Learning**
2412.10312v1 by Federico Ruggeri, Gaetano Signorelli

A popular end-to-end architecture for selective rationalization is the
select-then-predict pipeline, comprising a generator to extract highlights fed
to a predictor. Such a cooperative system suffers from suboptimal equilibrium
minima due to the dominance of one of the two modules, a phenomenon known as
interlocking. While several contributions aimed at addressing interlocking,
they only mitigate its effect, often by introducing feature-based heuristics,
sampling, and ad-hoc regularizations. We present GenSPP, the first
interlocking-free architecture for selective rationalization that does not
require any learning overhead, as the above-mentioned. GenSPP avoids
interlocking by performing disjoint training of the generator and predictor via
genetic global search. Experiments on a synthetic and a real-world benchmark
show that our model outperforms several state-of-the-art competitors.

摘要：選擇式簡化的一種流行端對端架構是選擇再預測管線，包含一個產生器用於萃取亮點並提供給預測器。這種合作系統會因兩個模組之一的支配而導致次佳平衡極小值，這種現象稱為互鎖。雖然有許多貢獻旨在解決互鎖，但它們僅能減輕其影響，通常是透過引入基於特徵的啟發法、取樣和特定規範化。我們提出 GenSPP，這是第一個無互鎖架構，用於選擇式簡化，不需要任何學習開銷，如上述。GenSPP 透過遺傳全球搜尋執行產生器和預測器的分離訓練，來避免互鎖。在合成和真實世界基準上的實驗顯示，我們的模型優於多個最先進的競爭者。

##### **DeepSeek-VL2: Mixture-of-Experts Vision-Language Models for Advanced Multimodal Understanding**
2412.10302v1 by Zhiyu Wu, Xiaokang Chen, Zizheng Pan, Xingchao Liu, Wen Liu, Damai Dai, Huazuo Gao, Yiyang Ma, Chengyue Wu, Bingxuan Wang, Zhenda Xie, Yu Wu, Kai Hu, Jiawei Wang, Yaofeng Sun, Yukun Li, Yishi Piao, Kang Guan, Aixin Liu, Xin Xie, Yuxiang You, Kai Dong, Xingkai Yu, Haowei Zhang, Liang Zhao, Yisong Wang, Chong Ruan

We present DeepSeek-VL2, an advanced series of large Mixture-of-Experts (MoE)
Vision-Language Models that significantly improves upon its predecessor,
DeepSeek-VL, through two key major upgrades. For the vision component, we
incorporate a dynamic tiling vision encoding strategy designed for processing
high-resolution images with different aspect ratios. For the language
component, we leverage DeepSeekMoE models with the Multi-head Latent Attention
mechanism, which compresses Key-Value cache into latent vectors, to enable
efficient inference and high throughput. Trained on an improved vision-language
dataset, DeepSeek-VL2 demonstrates superior capabilities across various tasks,
including but not limited to visual question answering, optical character
recognition, document/table/chart understanding, and visual grounding. Our
model series is composed of three variants: DeepSeek-VL2-Tiny,
DeepSeek-VL2-Small and DeepSeek-VL2, with 1.0B, 2.8B and 4.5B activated
parameters respectively. DeepSeek-VL2 achieves competitive or state-of-the-art
performance with similar or fewer activated parameters compared to existing
open-source dense and MoE-based models. Codes and pre-trained models are
publicly accessible at https://github.com/deepseek-ai/DeepSeek-VL2.

摘要：我們提出了 DeepSeek-VL2，這是一個先進的大型混合專家 (MoE) 系列視覺語言模型，透過兩項主要升級，大幅改進其前身 DeepSeek-VL。對於視覺元件，我們結合動態拼貼視覺編碼策略，旨在處理具有不同長寬比的高解析度影像。對於語言元件，我們利用具備多頭潛在注意力機制的 DeepSeekMoE 模型，將鍵值快取壓縮成潛在向量，以實現有效率的推論和高通量。在改良的視覺語言資料集上進行訓練，DeepSeek-VL2 在各種任務中展現出優異的能力，包括但不限於視覺問題解答、光學字元辨識、文件/表格/圖表理解和視覺基礎。我們的模型系列由三種變體組成：DeepSeek-VL2-Tiny、DeepSeek-VL2-Small 和 DeepSeek-VL2，分別具有 1.0B、2.8B 和 4.5B 個已啟用的參數。與現有的開源密集和基於 MoE 的模型相比，DeepSeek-VL2 以相同或更少的已啟用參數，取得具競爭力或最先進的效能。程式碼和預訓練模型可在 https://github.com/deepseek-ai/DeepSeek-VL2 公開取得。

##### **Still "Talking About Large Language Models": Some Clarifications**
2412.10291v1 by Murray Shanahan

My paper "Talking About Large Language Models" has more than once been
interpreted as advocating a reductionist stance towards large language models.
But the paper was not intended that way, and I do not endorse such positions.
This short note situates the paper in the context of a larger philosophical
project that is concerned with the (mis)use of words rather than metaphysics,
in the spirit of Wittgenstein's later writing.

摘要：我的論文「談大型語言模型」已不止一次被解讀為主張對大型語言模型採取還原論立場。但這篇論文並非如此用意，我也不認同這種立場。這篇簡短的註解將這篇論文定位在一個較大的哲學專案的背景下，這個專案關注的是（誤）用詞彙，而非形上學，並秉持維根斯坦後期著作的精神。

##### **One world, one opinion? The superstar effect in LLM responses**
2412.10281v1 by Sofie Goethals, Lauren Rhue

As large language models (LLMs) are shaping the way information is shared and
accessed online, their opinions have the potential to influence a wide
audience. This study examines who the LLMs view as the most prominent figures
across various fields, using prompts in ten different languages to explore the
influence of linguistic diversity. Our findings reveal low diversity in
responses, with a small number of figures dominating recognition across
languages (also known as the "superstar effect"). These results highlight the
risk of narrowing global knowledge representation when LLMs retrieve subjective
information.

摘要：隨著大型語言模型 (LLM) 形塑線上資訊分享與取得的方式，它們的觀點有潛力影響廣大受眾。本研究使用十種不同語言的提示來探討語言多樣性的影響，探討 LLM 視為各領域最傑出人物的人選。我們的研究結果顯示，回應的多樣性低，少數人物在各語言中都獲得極高的認可（也稱為「超級巨星效應」）。這些結果凸顯了當 LLM 擷取主觀資訊時，全球知識呈現可能會過於狹隘的風險。

##### **Envisioning National Resources for Artificial Intelligence Research: NSF Workshop Report**
2412.10278v1 by Shantenu Jha, Yolanda Gil

This is a report of an NSF workshop titled "Envisioning National Resources
for Artificial Intelligence Research" held in Alexandria, Virginia, in May
2024. The workshop aimed to identify initial challenges and opportunities for
national resources for AI research (e.g., compute, data, models, etc.) and to
facilitate planning for the envisioned National AI Research Resource.
Participants included AI and cyberinfrastructure (CI) experts. The report
outlines significant findings and identifies needs and recommendations from the
workshop.

摘要：這份報告是 NSF 工作坊的報告，標題為「構想人工智慧研究的國家資源」，於 2024 年 5 月在維吉尼亞州亞歷山卓市舉行。該工作坊旨在找出國家 AI 研究資源（例如運算、資料、模型等）的初步挑戰和機會，並促進規劃構想中的國家 AI 研究資源。參與者包括 AI 和網路基礎建設 (CI) 專家。這份報告概述了重要的發現，並找出工作坊的需求和建議。

##### **Benchmarking Linguistic Diversity of Large Language Models**
2412.10271v1 by Yanzhu Guo, Guokan Shang, Chloé Clavel

The development and evaluation of Large Language Models (LLMs) has primarily
focused on their task-solving capabilities, with recent models even surpassing
human performance in some areas. However, this focus often neglects whether
machine-generated language matches the human level of diversity, in terms of
vocabulary choice, syntactic construction, and expression of meaning, raising
questions about whether the fundamentals of language generation have been fully
addressed. This paper emphasizes the importance of examining the preservation
of human linguistic richness by language models, given the concerning surge in
online content produced or aided by LLMs. We propose a comprehensive framework
for evaluating LLMs from various linguistic diversity perspectives including
lexical, syntactic, and semantic dimensions. Using this framework, we benchmark
several state-of-the-art LLMs across all diversity dimensions, and conduct an
in-depth case study for syntactic diversity. Finally, we analyze how different
development and deployment choices impact the linguistic diversity of LLM
outputs.

摘要：大型語言模型 (LLM) 的開發和評估主要集中於其解決任務的能力，最近的模型甚至在某些領域超越了人類的表現。然而，這種關注往往忽略了機器產生的語言在詞彙選擇、句法結構和意義表達方面的多樣性是否達到人類的水平，這引發了關於語言生成的基本原理是否已得到充分解決的問題。本文強調了在 LLM 生產或輔助的線上內容激增的情況下，檢視語言模型對人類語言豐富性的保留的重要性。我們提出了一個全面的框架，從詞彙、句法和語義維度等各種語言多樣性角度評估 LLM。使用這個框架，我們對所有多樣性維度進行了數個最先進的 LLM 基準測試，並對句法多樣性進行了深入的案例研究。最後，我們分析了不同的開發和部署選擇如何影響 LLM 輸出的語言多樣性。

##### **Cultural Evolution of Cooperation among LLM Agents**
2412.10270v1 by Aron Vallinder, Edward Hughes

Large language models (LLMs) provide a compelling foundation for building
generally-capable AI agents. These agents may soon be deployed at scale in the
real world, representing the interests of individual humans (e.g., AI
assistants) or groups of humans (e.g., AI-accelerated corporations). At
present, relatively little is known about the dynamics of multiple LLM agents
interacting over many generations of iterative deployment. In this paper, we
examine whether a "society" of LLM agents can learn mutually beneficial social
norms in the face of incentives to defect, a distinctive feature of human
sociality that is arguably crucial to the success of civilization. In
particular, we study the evolution of indirect reciprocity across generations
of LLM agents playing a classic iterated Donor Game in which agents can observe
the recent behavior of their peers. We find that the evolution of cooperation
differs markedly across base models, with societies of Claude 3.5 Sonnet agents
achieving significantly higher average scores than Gemini 1.5 Flash, which, in
turn, outperforms GPT-4o. Further, Claude 3.5 Sonnet can make use of an
additional mechanism for costly punishment to achieve yet higher scores, while
Gemini 1.5 Flash and GPT-4o fail to do so. For each model class, we also
observe variation in emergent behavior across random seeds, suggesting an
understudied sensitive dependence on initial conditions. We suggest that our
evaluation regime could inspire an inexpensive and informative new class of LLM
benchmarks, focussed on the implications of LLM agent deployment for the
cooperative infrastructure of society.

摘要：大型語言模型 (LLM) 為建構具備一般能力的 AI 代理提供了令人信服的基礎。這些代理人可能很快就會在現實世界中大規模部署，代表個人人類（例如，AI 助理）或人類群體（例如，AI 加速公司）的利益。目前，對於多個 LLM 代理在多代疊代部署中互動的動態知之甚少。在本文中，我們探討了一個 LLM 代理「社會」是否能夠在背叛誘因面前學習到對彼此有益的社會規範，這是人類社會性的一個顯著特徵，可以說是文明成功的重要關鍵。特別是，我們研究了 LLM 代理在經典的重複捐贈者遊戲中跨世代的間接互惠演變，在該遊戲中，代理人可以觀察到同儕最近的行為。我們發現合作的演變在基礎模型之間有顯著差異，Claude 3.5 Sonnet 代理的社會比 Gemini 1.5 Flash 獲得顯著更高的平均分數，而後者又優於 GPT-4o。此外，Claude 3.5 Sonnet 可以利用額外的代價懲罰機制來獲得更高的分數，而 Gemini 1.5 Flash 和 GPT-4o 則無法做到這一點。對於每個模型類別，我們還觀察到隨機種子中出現行為的變化，這表明對初始條件的敏感依賴性尚未得到充分研究。我們建議我們的評估制度可以激勵一種廉價且有益的新型 LLM 基準，專注於 LLM 代理部署對社會合作基礎設施的影響。

##### **Does Multiple Choice Have a Future in the Age of Generative AI? A Posttest-only RCT**
2412.10267v1 by Danielle R. Thomas, Conrad Borchers, Sanjit Kakarla, Jionghao Lin, Shambhavi Bhushan, Boyuan Guo, Erin Gatz, Kenneth R. Koedinger

The role of multiple-choice questions (MCQs) as effective learning tools has
been debated in past research. While MCQs are widely used due to their ease in
grading, open response questions are increasingly used for instruction, given
advances in large language models (LLMs) for automated grading. This study
evaluates MCQs effectiveness relative to open-response questions, both
individually and in combination, on learning. These activities are embedded
within six tutor lessons on advocacy. Using a posttest-only randomized control
design, we compare the performance of 234 tutors (790 lesson completions)
across three conditions: MCQ only, open response only, and a combination of
both. We find no significant learning differences across conditions at
posttest, but tutors in the MCQ condition took significantly less time to
complete instruction. These findings suggest that MCQs are as effective, and
more efficient, than open response tasks for learning when practice time is
limited. To further enhance efficiency, we autograded open responses using
GPT-4o and GPT-4-turbo. GPT models demonstrate proficiency for purposes of
low-stakes assessment, though further research is needed for broader use. This
study contributes a dataset of lesson log data, human annotation rubrics, and
LLM prompts to promote transparency and reproducibility.

摘要：多選題 (MCQ) 作為有效的學習工具的角色在過去的研究中一直備受爭議。雖然 MCQ 因其易於評分而被廣泛使用，但隨著大型語言模型 (LLM) 在自動評分方面的進步，開放式問題正越來越被用於教學。本研究評估了 MCQ 相對於開放式問題的有效性，無論是單獨還是組合，對學習的影響。這些活動嵌入在六個關於倡導的輔導課程中。使用僅限後測的隨機對照設計，我們比較了 234 位輔導員 (790 個課程完成) 在三種條件下的表現：僅 MCQ、僅開放式回應以及兩者的組合。我們發現後測時各條件之間沒有顯著的學習差異，但在 MCQ 條件下的輔導員完成教學所需的時間顯著減少。這些發現表明，當練習時間有限時，MCQ 與開放式任務一樣有效，而且效率更高。為了進一步提高效率，我們使用 GPT-4o 和 GPT-4-turbo 自動評分開放式回應。GPT 模型展示了低風險評估目的的熟練度，儘管需要進一步的研究以更廣泛地使用。本研究提供了一組課程日誌數據、人工註釋準則和 LLM 提示，以促進透明度和可複製性。

##### **Reasoner Outperforms: Generative Stance Detection with Rationalization for Social Media**
2412.10266v1 by Jiaqing Yuan, Ruijie Xi, Munindar P. Singh

Stance detection is crucial for fostering a human-centric Web by analyzing
user-generated content to identify biases and harmful narratives that undermine
trust. With the development of Large Language Models (LLMs), existing
approaches treat stance detection as a classification problem, providing robust
methodologies for modeling complex group interactions and advancing
capabilities in natural language tasks. However, these methods often lack
interpretability, limiting their ability to offer transparent and
understandable justifications for predictions. This study adopts a generative
approach, where stance predictions include explicit, interpretable rationales,
and integrates them into smaller language models through single-task and
multitask learning. We find that incorporating reasoning into stance detection
enables the smaller model (FlanT5) to outperform GPT-3.5's zero-shot
performance, achieving an improvement of up to 9.57%. Moreover, our results
show that reasoning capabilities enhance multitask learning performance but may
reduce effectiveness in single-task settings. Crucially, we demonstrate that
faithful rationales improve rationale distillation into SLMs, advancing efforts
to build interpretable, trustworthy systems for addressing discrimination,
fostering trust, and promoting equitable engagement on social media.

摘要：立場偵測對於促進以人為本的網路至關重要，透過分析使用者產生的內容來辨識破壞信任的偏見和有害敘述。隨著大型語言模型 (LLM) 的發展，現有的方法將立場偵測視為分類問題，提供強健的方法來建模複雜的群體互動，並提升自然語言任務的能力。然而，這些方法通常缺乏可解釋性，限制了它們提供透明且可理解的預測依據的能力。本研究採用生成式方法，其中立場預測包括明確、可解釋的依據，並透過單一任務和多任務學習將它們整合到較小的語言模型中。我們發現將推理納入立場偵測能讓較小的模型 (FlanT5) 優於 GPT-3.5 的零次學習效能，提升幅度最高達 9.57%。此外，我們的結果顯示推理能力提升了多任務學習效能，但可能降低單一任務設定中的效能。至關重要的是，我們證明忠實的依據能改善將依據萃取到 SLM 中，促進建構可解釋、值得信賴的系統，以解決歧視、建立信任，並在社群媒體上推廣公平的參與。

##### **Targeted Angular Reversal of Weights (TARS) for Knowledge Removal in Large Language Models**
2412.10257v1 by Harry J. Davies, Giorgos Iacovides, Danilo P. Mandic

The sheer scale of data required to train modern large language models (LLMs)
poses significant risks, as models are likely to gain knowledge of sensitive
topics such as bio-security, as well the ability to replicate copyrighted
works. Methods designed to remove such knowledge must do so from all prompt
directions, in a multi-lingual capacity and without degrading general model
performance. To this end, we introduce the targeted angular reversal (TARS)
method of knowledge removal from LLMs. The TARS method firstly leverages the
LLM in combination with a detailed prompt to aggregate information about a
selected concept in the internal representation space of the LLM. It then
refines this approximate concept vector to trigger the concept token with high
probability, by perturbing the approximate concept vector with noise and
transforming it into token scores with the language model head. The feedforward
weight vectors in the LLM which operate directly on the internal representation
space, and have the highest cosine similarity with this targeting vector, are
then replaced by a reversed targeting vector, thus limiting the ability of the
concept to propagate through the model. The modularity of the TARS method
allows for a sequential removal of concepts from Llama 3.1 8B, such as the
famous literary detective Sherlock Holmes, and the planet Saturn. It is
demonstrated that the probability of triggering target concepts can be reduced
to 0.00 with as few as 1 TARS edit, whilst simultaneously removing the
knowledge bi-directionally. Moreover, knowledge is shown to be removed across
all languages despite only being targeted in English. Importantly, TARS has
minimal impact on the general model capabilities, as after removing 5 diverse
concepts in a modular fashion, there is minimal KL divergence in the next token
probabilities of the LLM on large corpora of Wikipedia text (median of 0.002).

摘要：<paragraph>訓練現代大型語言模型 (LLM) 所需的龐大數據規模帶來重大風險，因為模型很可能會獲取敏感主題的知識，例如生物安全，以及複製受版權保護作品的能力。旨在移除此類知識的方法必須從所有提示方向以多語言方式執行此操作，且不會降低一般模型效能。為此，我們引入了從 LLM 中移除知識的目標角反轉 (TARS) 方法。TARS 方法首先利用 LLM 結合詳細提示，在 LLM 的內部表示空間中彙整有關所選概念的資訊。然後，它會微調此近似概念向量，藉由使用雜訊擾動近似概念向量，並使用語言模型頭將其轉換為代幣分數，以高機率觸發概念代幣。在 LLM 中直接作用於內部表示空間，且與此目標向量具有最高餘弦相似度的前饋權重向量，隨後會被反向目標向量取代，因此限制了概念在模型中傳播的能力。TARS 方法的模組化允許從 Llama 3.1 8B 中循序移除概念，例如著名的文學偵探夏洛克福爾摩斯和土星。結果表明，觸發目標概念的機率可以透過少至 1 次 TARS 編輯降低至 0.00，同時雙向移除知識。此外，儘管僅以英文為目標，但已顯示知識已跨所有語言移除。重要的是，TARS 對一般模型功能的影響很小，因為在以模組化方式移除 5 個不同的概念後，LLM 在大量維基百科文字中的下一個代幣機率的 KL 分歧很小（中位數為 0.002）。</paragraph>

##### **Exploring the Frontiers of Animation Video Generation in the Sora Era: Method, Dataset and Benchmark**
2412.10255v1 by Yudong Jiang, Baohan Xu, Siqian Yang, Mingyu Yin, Jing Liu, Chao Xu, Siqi Wang, Yidi Wu, Bingwen Zhu, Jixuan Xu, Yue Zhang, Jinlong Hou, Huyang Sun

Animation has gained significant interest in the recent film and TV industry.
Despite the success of advanced video generation models like Sora, Kling, and
CogVideoX in generating natural videos, they lack the same effectiveness in
handling animation videos. Evaluating animation video generation is also a
great challenge due to its unique artist styles, violating the laws of physics
and exaggerated motions. In this paper, we present a comprehensive system,
AniSora, designed for animation video generation, which includes a data
processing pipeline, a controllable generation model, and an evaluation
dataset. Supported by the data processing pipeline with over 10M high-quality
data, the generation model incorporates a spatiotemporal mask module to
facilitate key animation production functions such as image-to-video
generation, frame interpolation, and localized image-guided animation. We also
collect an evaluation benchmark of 948 various animation videos, the evaluation
on VBench and human double-blind test demonstrates consistency in character and
motion, achieving state-of-the-art results in animation video generation. %We
also collect an evaluation benchmark of 948 various animation videos, with
specifically developed metrics for animation video generation. Our model access
API and evaluation benchmark will be publicly available.

摘要：動畫在最近的電影和電視產業中獲得了顯著的關注。
儘管像 Sora、Kling 和 CogVideoX 這樣的先進影片生成模型在生成自然影片方面取得了成功，但在處理動畫影片方面卻缺乏相同的效能。由於其獨特的藝術風格、違反物理定律和誇張的動作，評估動畫影片生成也是一個巨大的挑戰。在本文中，我們提出了一個全面的系統 AniSora，專門用於動畫影片生成，其中包括一個資料處理管線、一個可控的生成模型和一個評估資料集。在擁有超過 10M 高品質資料的資料處理管線的支援下，生成模型結合了時空遮罩模組，以促進關鍵動畫製作功能，例如影像轉影片生成、幀插補和局部影像導向動畫。我們還收集了一個由 948 個各種動畫影片組成的評估基準，在 VBench 和人類雙盲測試上的評估證明了角色和動作的一致性，在動畫影片生成中取得了最先進的成果。% 我們還收集了一個由 948 個各種動畫影片組成的評估基準，並為動畫影片生成特別開發了指標。我們的模型存取 API 和評估基準將公開提供。

##### **Efficient Continual Pre-training of LLMs for Low-resource Languages**
2412.10244v1 by Arijit Nag, Soumen Chakrabarti, Animesh Mukherjee, Niloy Ganguly

Open-source Large Language models (OsLLMs) propel the democratization of
natural language research by giving the flexibility to augment or update model
parameters for performance improvement. Nevertheless, like proprietary LLMs,
Os-LLMs offer poorer performance on low-resource languages (LRLs) than
high-resource languages (HRLs), owing to smaller amounts of training data and
underrepresented vocabulary. On the other hand, continual pre-training (CPT)
with large amounts of language-specific data is a costly proposition in terms
of data acquisition and computational resources. Our goal is to drastically
reduce CPT cost. To that end, we first develop a new algorithm to select a
subset of texts from a larger corpus. We show the effectiveness of our
technique using very little CPT data. In search of further improvement, we
design a new algorithm to select tokens to include in the LLM vocabulary. We
experiment with the recent Llama-3 model and nine Indian languages with diverse
scripts and extent of resource availability. For evaluation, we use
IndicGenBench, a generation task benchmark dataset for Indic languages. We
experiment with various CPT corpora and augmented vocabulary size and offer
insights across language families.

摘要：開放原始碼大型語言模型 (OsLLM) 推動自然語言研究的民主化，讓模型參數可以靈活地擴充或更新以提升效能。儘管如此，與專有 LLM 類似，由於訓練資料量較少且詞彙量不足，Os-LLM 在低資源語言 (LRL) 上的表現比高資源語言 (HRL) 差。另一方面，針對特定語言資料進行持續預訓練 (CPT) 在資料取得和運算資源方面是一項昂貴的提議。我們的目標是大幅降低 CPT 成本。為此，我們首先開發一種新演算法，從較大的語料庫中選取一個子集的文字。我們使用極少的 CPT 資料來展示我們技術的有效性。為了進一步改進，我們設計一種新演算法來選取要包含在 LLM 詞彙中的詞彙。我們使用最新的 Llama-3 模型和九種印度語言進行實驗，這些語言具有不同的文字系統和資源可用性程度。在評估方面，我們使用 IndicGenBench，這是一個針對印度語言的產生任務基準資料集。我們使用各種 CPT 語料庫和擴充的詞彙量進行實驗，並提供跨語言系列的見解。

##### **Physics Instrument Design with Reinforcement Learning**
2412.10237v1 by Shah Rukh Qasim, Patrick Owen, Nicola Serra

We present a case for the use of Reinforcement Learning (RL) for the design
of physics instrument as an alternative to gradient-based
instrument-optimization methods. It's applicability is demonstrated using two
empirical studies. One is longitudinal segmentation of calorimeters and the
second is both transverse segmentation as well longitudinal placement of
trackers in a spectrometer. Based on these experiments, we propose an
alternative approach that offers unique advantages over differentiable
programming and surrogate-based differentiable design optimization methods.
First, Reinforcement Learning (RL) algorithms possess inherent exploratory
capabilities, which help mitigate the risk of convergence to local optima.
Second, this approach eliminates the necessity of constraining the design to a
predefined detector model with fixed parameters. Instead, it allows for the
flexible placement of a variable number of detector components and facilitates
discrete decision-making. We then discuss the road map of how this idea can be
extended into designing very complex instruments. The presented study sets the
stage for a novel framework in physics instrument design, offering a scalable
and efficient framework that can be pivotal for future projects such as the
Future Circular Collider (FCC), where most optimized detectors are essential
for exploring physics at unprecedented energy scales.

摘要：我們提出一個案例，說明使用強化學習 (RL) 來設計物理儀器，作為基於梯度的儀器最佳化方法的替代方案。它的適用性已通過兩項實證研究得到證實。一個是量熱器的縱向分割，另一個是橫向分割和光譜儀中追蹤器的縱向放置。基於這些實驗，我們提出了一種替代方法，它比可微分程式設計和基於代理的可微分設計最佳化方法具有獨特優勢。首先，強化學習 (RL) 演算法具有內在的探索能力，有助於降低收斂到局部最優的風險。其次，這種方法消除了將設計限制在具有固定參數的預定義偵測器模型的必要性。相反，它允許靈活放置可變數量的偵測器組件，並促進離散決策制定。然後，我們討論了如何將這個想法擴展到設計非常複雜的儀器的路線圖。提出的研究為物理儀器設計中的新框架奠定了基礎，提供了一個可擴充且高效的框架，對於未來的專案（例如未來環形對撞機 (FCC)）至關重要，在這些專案中，最最佳化的偵測器對於探索前所未有的能量尺度的物理現象至關重要。

##### **How good is my story? Towards quantitative metrics for evaluating LLM-generated XAI narratives**
2412.10220v1 by Timour Ichmoukhamedov, James Hinns, David Martens

A rapidly developing application of LLMs in XAI is to convert quantitative
explanations such as SHAP into user-friendly narratives to explain the
decisions made by smaller prediction models. Evaluating the narratives without
relying on human preference studies or surveys is becoming increasingly
important in this field. In this work we propose a framework and explore
several automated metrics to evaluate LLM-generated narratives for explanations
of tabular classification tasks. We apply our approach to compare several
state-of-the-art LLMs across different datasets and prompt types. As a
demonstration of their utility, these metrics allow us to identify new
challenges related to LLM hallucinations for XAI narratives.

摘要：LLM 在 XAI 中快速發展的應用是將定量解釋（例如 SHAP）轉換為使用者友善的敘述，以解釋較小的預測模型所做的決策。在這個領域中，在不依賴人類偏好研究或調查的情況下評估敘述變得越來越重要。在這項工作中，我們提出一個架構並探討多種自動化指標，以評估 LLM 生成的敘述，用於解釋表格分類任務。我們應用我們的做法來比較不同資料集和提示類型中的幾個最先進的 LLM。作為其效用的示範，這些指標讓我們能夠找出與 XAI 敘述的 LLM 幻覺相關的新挑戰。

##### **GAF: Gaussian Avatar Reconstruction from Monocular Videos via Multi-view Diffusion**
2412.10209v1 by Jiapeng Tang, Davide Davoli, Tobias Kirschstein, Liam Schoneveld, Matthias Niessner

We propose a novel approach for reconstructing animatable 3D Gaussian avatars
from monocular videos captured by commodity devices like smartphones.
Photorealistic 3D head avatar reconstruction from such recordings is
challenging due to limited observations, which leaves unobserved regions
under-constrained and can lead to artifacts in novel views. To address this
problem, we introduce a multi-view head diffusion model, leveraging its priors
to fill in missing regions and ensure view consistency in Gaussian splatting
renderings. To enable precise viewpoint control, we use normal maps rendered
from FLAME-based head reconstruction, which provides pixel-aligned inductive
biases. We also condition the diffusion model on VAE features extracted from
the input image to preserve details of facial identity and appearance. For
Gaussian avatar reconstruction, we distill multi-view diffusion priors by using
iteratively denoised images as pseudo-ground truths, effectively mitigating
over-saturation issues. To further improve photorealism, we apply latent
upsampling to refine the denoised latent before decoding it into an image. We
evaluate our method on the NeRSemble dataset, showing that GAF outperforms the
previous state-of-the-art methods in novel view synthesis by a 5.34\% higher
SSIM score. Furthermore, we demonstrate higher-fidelity avatar reconstructions
from monocular videos captured on commodity devices.

摘要：我們提出了一種創新的方法，用智慧型手機等商品設備所拍攝的單眼影片，重建出可動畫的 3D 高斯頭像。
從這類錄製影片中重建出逼真的 3D 頭像頭像具有挑戰性，因為觀察有限，這使得未觀察到的區域受到約束不足，並可能導致新視圖中出現人工製品。
為了解決這個問題，我們引入了多視圖頭部擴散模型，利用其先驗來填補缺失區域並確保高斯潑灑渲染中的視圖一致性。
為了實現精確的視點控制，我們使用了從基於 FLAME 的頭部重建所渲染的法線貼圖，它提供了像素對齊的歸納偏差。
我們還根據從輸入影像中提取的 VAE 特徵對擴散模型進行條件化，以保留面部特徵和外觀的細節。
對於高斯頭像重建，我們使用反覆降噪影像作為偽地面實況，來提取多視圖擴散先驗，有效地減輕過飽和問題。
為了進一步提高逼真度，我們應用潛在向上取樣來改善降噪潛在值，然後將其解碼成影像。
我們在 NeRSemble 資料集上評估了我們的方法，顯示 GAF 在新視圖合成中優於先前的最新方法，SSIM 分數高出 5.34%。
此外，我們展示了從商品設備上拍攝的單眼影片中重建出更高保真度的頭像。

##### **Retrieval-Augmented Semantic Parsing: Using Large Language Models to Improve Generalization**
2412.10207v1 by Xiao Zhang, Qianru Meng, Johan Bos

Open-domain semantic parsing remains a challenging task, as models often rely
on heuristics and struggle to handle unseen concepts. In this paper, we
investigate the potential of large language models (LLMs) for this task and
introduce Retrieval-Augmented Semantic Parsing (RASP), a simple yet effective
approach that integrates external lexical knowledge into the parsing process.
Our experiments not only show that LLMs outperform previous encoder-decoder
baselines for semantic parsing, but that RASP further enhances their ability to
predict unseen concepts, nearly doubling the performance of previous models on
out-of-distribution concepts. These findings highlight the promise of
leveraging large language models and retrieval mechanisms for robust and
open-domain semantic parsing.

摘要：開放領域語義解析仍然是一項具有挑戰性的任務，因為模型通常依賴啟發法，並且難以處理未見過的概念。在本文中，我們探討大型語言模型 (LLM) 在這項任務中的潛力，並提出檢索增強語義解析 (RASP)，這是一種簡單但有效的方法，可以將外部詞彙知識整合到解析過程中。我們的實驗不僅表明 LLM 優於語義解析的先前編碼器 - 解碼器基線，而且 RASP 進一步增強了它們預測未見過概念的能力，幾乎將先前模型在分布外概念上的效能提高了一倍。這些發現突顯了利用大型語言模型和檢索機制進行強健且開放領域語義解析的潛力。

##### **From Allies to Adversaries: Manipulating LLM Tool-Calling through Adversarial Injection**
2412.10198v1 by Haowei Wang, Rupeng Zhang, Junjie Wang, Mingyang Li, Yuekai Huang, Dandan Wang, Qing Wang

Tool-calling has changed Large Language Model (LLM) applications by
integrating external tools, significantly enhancing their functionality across
diverse tasks. However, this integration also introduces new security
vulnerabilities, particularly in the tool scheduling mechanisms of LLM, which
have not been extensively studied. To fill this gap, we present ToolCommander,
a novel framework designed to exploit vulnerabilities in LLM tool-calling
systems through adversarial tool injection. Our framework employs a
well-designed two-stage attack strategy. Firstly, it injects malicious tools to
collect user queries, then dynamically updates the injected tools based on the
stolen information to enhance subsequent attacks. These stages enable
ToolCommander to execute privacy theft, launch denial-of-service attacks, and
even manipulate business competition by triggering unscheduled tool-calling.
Notably, the ASR reaches 91.67% for privacy theft and hits 100% for
denial-of-service and unscheduled tool calling in certain cases. Our work
demonstrates that these vulnerabilities can lead to severe consequences beyond
simple misuse of tool-calling systems, underscoring the urgent need for robust
defensive strategies to secure LLM Tool-calling systems.

摘要：工具呼叫已透過整合外部工具來改變大型語言模型 (LLM) 應用程式，大幅提升其在各種任務中的功能。不過，這種整合也引入了新的安全性漏洞，特別是在 LLM 的工具排程機制中，而這尚未獲得廣泛的研究。為了填補這個空白，我們提出 ToolCommander，這是一個新穎的架構，旨在透過對抗性的工具注入來利用 LLM 工具呼叫系統中的漏洞。我們的架構採用精心設計的兩階段攻擊策略。首先，它會注入惡意工具來收集使用者查詢，然後根據竊取的資訊動態更新注入的工具，以加強後續攻擊。這些階段讓 ToolCommander 能夠執行隱私竊取、發動阻斷服務攻擊，甚至透過觸發非預定的工具呼叫來操縱商業競爭。值得注意的是，在某些情況下，ASR 達到 91.67% 的隱私竊取，並達到 100% 的阻斷服務和非預定工具呼叫。我們的研究表明，這些漏洞可能會導致嚴重的後果，而這不只是工具呼叫系統的濫用，這強調了確保 LLM 工具呼叫系統安全的穩健防禦策略的迫切需求。

##### **Solving Robust Markov Decision Processes: Generic, Reliable, Efficient**
2412.10185v1 by Tobias Meggendorfer, Maximilian Weininger, Patrick Wienhöft

Markov decision processes (MDP) are a well-established model for sequential
decision-making in the presence of probabilities. In robust MDP (RMDP), every
action is associated with an uncertainty set of probability distributions,
modelling that transition probabilities are not known precisely. Based on the
known theoretical connection to stochastic games, we provide a framework for
solving RMDPs that is generic, reliable, and efficient. It is *generic* both
with respect to the model, allowing for a wide range of uncertainty sets,
including but not limited to intervals, $L^1$- or $L^2$-balls, and polytopes;
and with respect to the objective, including long-run average reward,
undiscounted total reward, and stochastic shortest path. It is *reliable*, as
our approach not only converges in the limit, but provides precision guarantees
at any time during the computation. It is *efficient* because -- in contrast to
state-of-the-art approaches -- it avoids explicitly constructing the underlying
stochastic game. Consequently, our prototype implementation outperforms
existing tools by several orders of magnitude and can solve RMDPs with a
million states in under a minute.

摘要：馬可夫決策過程 (MDP) 是一種在機率存在的情況下進行順序決策的既定模型。在強健 MDP (RMDP) 中，每個動作都與機率分佈的不確定性集合相關，建模為轉移機率並非精確已知。根據已知的與隨機博弈的理論連結，我們提供了一個解決 RMDP 的架構，它具有通用性、可靠性與效率。它在模型方面是「通用的」，允許使用廣泛的不確定性集合，包括但不限於區間、$L^1$ 或 $L^2$ 球體和多面體；在目標方面也是通用的，包括長期平均獎勵、未貼現總獎勵和隨機最短路徑。它很「可靠」，因為我們的做法不僅會在極限中收斂，還會在運算過程中隨時提供精確度保證。它很「有效」，因為與最先進的做法相反，它避免明確建構基礎隨機博弈。因此，我們的原型實作在幾個數量級上都優於現有工具，而且可以在不到一分鐘的時間內解決擁有數百萬個狀態的 RMDP。

##### **Multi-Head Encoding for Extreme Label Classification**
2412.10182v1 by Daojun Liang, Haixia Zhang, Dongfeng Yuan, Minggao Zhang

The number of categories of instances in the real world is normally huge, and
each instance may contain multiple labels. To distinguish these massive labels
utilizing machine learning, eXtreme Label Classification (XLC) has been
established. However, as the number of categories increases, the number of
parameters and nonlinear operations in the classifier also rises. This results
in a Classifier Computational Overload Problem (CCOP). To address this, we
propose a Multi-Head Encoding (MHE) mechanism, which replaces the vanilla
classifier with a multi-head classifier. During the training process, MHE
decomposes extreme labels into the product of multiple short local labels, with
each head trained on these local labels. During testing, the predicted labels
can be directly calculated from the local predictions of each head. This
reduces the computational load geometrically. Then, according to the
characteristics of different XLC tasks, e.g., single-label, multi-label, and
model pretraining tasks, three MHE-based implementations, i.e., Multi-Head
Product, Multi-Head Cascade, and Multi-Head Sampling, are proposed to more
effectively cope with CCOP. Moreover, we theoretically demonstrate that MHE can
achieve performance approximately equivalent to that of the vanilla classifier
by generalizing the low-rank approximation problem from Frobenius-norm to
Cross-Entropy. Experimental results show that the proposed methods achieve
state-of-the-art performance while significantly streamlining the training and
inference processes of XLC tasks. The source code has been made public at
https://github.com/Anoise/MHE.

摘要：<paragraph>現實世界中實例類別的數量通常龐大，且每個實例可能包含多個標籤。為了利用機器學習來區分這些大量的標籤，已建立極端標籤分類 (XLC)。然而，隨著類別數量的增加，分類器中的參數和非線性運算數量也會增加。這導致分類器計算過載問題 (CCOP)。為了解決這個問題，我們提出了一個多頭編碼 (MHE) 機制，它以一個多頭分類器取代了香草分類器。在訓練過程中，MHE 將極端標籤分解為多個較短的局部標籤的乘積，每個頭部都在這些局部標籤上進行訓練。在測試期間，可以根據每個頭部的局部預測直接計算預測標籤。這在幾何上減少了計算負載。然後，根據不同的 XLC 任務的特徵，例如單標籤、多標籤和模型預訓練任務，提出了三種基於 MHE 的實現，即多頭乘積、多頭串聯和多頭抽樣，以更有效地應對 CCOP。此外，我們從理論上證明了 MHE 可以通過將低秩逼近問題從 Frobenius 範數推廣到交叉熵來實現與香草分類器近似的性能。實驗結果表明，所提出的方法在顯著簡化 XLC 任務的訓練和推理過程的同時，實現了最先進的性能。源代碼已公開在 https://github.com/Anoise/MHE。</paragraph>

##### **SwiftTry: Fast and Consistent Video Virtual Try-On with Diffusion Models**
2412.10178v1 by Hung Nguyen, Quang Qui-Vinh Nguyen, Khoi Nguyen, Rang Nguyen

Given an input video of a person and a new garment, the objective of this
paper is to synthesize a new video where the person is wearing the specified
garment while maintaining spatiotemporal consistency. While significant
advances have been made in image-based virtual try-ons, extending these
successes to video often results in frame-to-frame inconsistencies. Some
approaches have attempted to address this by increasing the overlap of frames
across multiple video chunks, but this comes at a steep computational cost due
to the repeated processing of the same frames, especially for long video
sequence. To address these challenges, we reconceptualize video virtual try-on
as a conditional video inpainting task, with garments serving as input
conditions. Specifically, our approach enhances image diffusion models by
incorporating temporal attention layers to improve temporal coherence. To
reduce computational overhead, we introduce ShiftCaching, a novel technique
that maintains temporal consistency while minimizing redundant computations.
Furthermore, we introduce the \dataname~dataset, a new video try-on dataset
featuring more complex backgrounds, challenging movements, and higher
resolution compared to existing public datasets. Extensive experiments show
that our approach outperforms current baselines, particularly in terms of video
consistency and inference speed. Data and code are available at
https://github.com/VinAIResearch/swift-try

摘要：給定一個人的輸入影片和一件新衣服，本文的目標是合成一個新影片，影片中的人穿著指定的衣服，同時保持時空一致性。雖然在基於影像的虛擬試穿方面已有顯著進展，但將這些成功推廣到影片中，通常會導致逐幀不一致。一些方法已嘗試透過增加多個影片區塊中幀的重疊來解決此問題，但由於重複處理相同的幀，特別是對於長的影片序列，這會帶來高昂的運算成本。為了應對這些挑戰，我們將影片虛擬試穿重新概念化為條件影片修復任務，並將服裝作為輸入條件。具體來說，我們的做法是透過加入時間注意力層來增強影像擴散模型，以改善時間相干性。為了減少運算負擔，我們引入了 ShiftCaching，這是一種新技術，可在最大程度減少重複運算的同時，維持時間一致性。此外，我們引入了 \dataname~資料集，這是一個新的影片試穿資料集，與現有的公開資料集相比，具有更複雜的背景、具挑戰性的動作和更高的解析度。廣泛的實驗表明，我們的做法優於目前的基準，特別是在影片一致性和推論速度方面。資料和程式碼可在 https://github.com/VinAIResearch/swift-try 取得

##### **Scaling Combinatorial Optimization Neural Improvement Heuristics with Online Search and Adaptation**
2412.10163v1 by Federico Julian Camerota Verdù, Lorenzo Castelli, Luca Bortolussi

We introduce Limited Rollout Beam Search (LRBS), a beam search strategy for
deep reinforcement learning (DRL) based combinatorial optimization improvement
heuristics. Utilizing pre-trained models on the Euclidean Traveling Salesperson
Problem, LRBS significantly enhances both in-distribution performance and
generalization to larger problem instances, achieving optimality gaps that
outperform existing improvement heuristics and narrowing the gap with
state-of-the-art constructive methods. We also extend our analysis to two
pickup and delivery TSP variants to validate our results. Finally, we employ
our search strategy for offline and online adaptation of the pre-trained
improvement policy, leading to improved search performance and surpassing
recent adaptive methods for constructive heuristics.

摘要：我們引入了有限展開波束搜尋 (LRBS)，一種基於深度強化學習 (DRL) 的組合優化改善啟發式演算法的波束搜尋策略。利用在歐幾里得旅行商問題上預先訓練的模型，LRBS 大幅提升了分佈內效能和對較大型問題實例的泛化，達到了優於現有改善啟發式演算法的最佳化差距，並縮小了與最先進建構方法的差距。我們也將分析延伸到兩個取貨和遞送 TSP 變體，以驗證我們的結果。最後，我們採用我們的搜尋策略進行預先訓練的改善策略的離線和線上適應，提升了搜尋效能，並超越了建構啟發式演算法的近期適應方法。

##### **Direct Encoding of Declare Constraints in ASP**
2412.10152v1 by Francesco Chiariello, Valeria Fionda, Antonio Ielo, Francesco Ricca

Answer Set Programming (ASP), a well-known declarative logic programming
paradigm, has recently found practical application in Process Mining. In
particular, ASP has been used to model tasks involving declarative
specifications of business processes. In this area, Declare stands out as the
most widely adopted declarative process modeling language, offering a means to
model processes through sets of constraints valid traces must satisfy, that can
be expressed in Linear Temporal Logic over Finite Traces (LTLf). Existing
ASP-based solutions encode Declare constraints by modeling the corresponding
LTLf formula or its equivalent automaton which can be obtained using
established techniques. In this paper, we introduce a novel encoding for
Declare constraints that directly models their semantics as ASP rules,
eliminating the need for intermediate representations. We assess the
effectiveness of this novel approach on two Process Mining tasks by comparing
it with alternative ASP encodings and a Python library for Declare. Under
consideration in Theory and Practice of Logic Programming (TPLP).

摘要：<paragraph>Answer Set Programming (ASP)，一種著名的宣告式邏輯程式設計範例，最近在流程探勘中找到實用應用。特別是，ASP 已用於建模涉及業務流程宣告式規範的任務。在這個領域，Declare 作為最廣泛採用的宣告式流程建模語言而脫穎而出，提供一種方法，透過必須滿足的約束集來建模流程，這些約束集可以用有限軌跡上的線性時序邏輯 (LTLf) 來表示。現有的基於 ASP 的解決方案透過建模對應的 LTLf 公式或可以使用已建立技術取得的等效自動機來編碼 Declare 約束。在本文中，我們引入一種新的 Declare 約束編碼，直接將其語意建模為 ASP 規則，消除了對中間表示的需求。我們透過與備用的 ASP 編碼和 Declare 的 Python 函式庫進行比較，評估這種新方法在兩個流程探勘任務上的有效性。在邏輯程式設計理論與實務 (TPLP) 中考量中。</paragraph>

##### **VLR-Bench: Multilingual Benchmark Dataset for Vision-Language Retrieval Augmented Generation**
2412.10151v1 by Hyeonseok Lim, Dongjae Shin, Seohyun Song, Inho Won, Minjun Kim, Junghun Yuk, Haneol Jang, KyungTae Lim

We propose the VLR-Bench, a visual question answering (VQA) benchmark for
evaluating vision language models (VLMs) based on retrieval augmented
generation (RAG). Unlike existing evaluation datasets for external
knowledge-based VQA, the proposed VLR-Bench includes five input passages. This
allows testing of the ability to determine which passage is useful for
answering a given query, a capability lacking in previous research. In this
context, we constructed a dataset of 32,000 automatically generated
instruction-following examples, which we denote as VLR-IF. This dataset is
specifically designed to enhance the RAG capabilities of VLMs by enabling them
to learn how to generate appropriate answers based on input passages. We
evaluated the validity of the proposed benchmark and training data and verified
its performance using the state-of-the-art Llama3-based VLM, the Llava-Llama-3
model. The proposed VLR-Bench and VLR-IF datasets are publicly available
online.

摘要：我們提出 VLR-Bench，一種視覺問答 (VQA) 基準，用於根據檢索增強生成 (RAG) 評估視覺語言模型 (VLM)。與現有外部知識庫 VQA 評估資料集不同，所提出的 VLR-Bench 包含五個輸入段落。這允許測試確定哪個段落有助於回答特定查詢的能力，這項功能在先前的研究中有所欠缺。在此背景下，我們建構了一個資料集，包含 32,000 個自動產生的遵循指令範例，我們將其表示為 VLR-IF。此資料集特別設計用於增強 VLM 的 RAG 功能，讓它們能夠學習如何根據輸入段落產生適當的答案。我們評估了所提出的基準和訓練資料的有效性，並使用最先進的基於 Llama3 的 VLM，即 Llava-Llama-3 模型，驗證其效能。所提出的 VLR-Bench 和 VLR-IF 資料集已公開在線上。

##### **TACOMORE: Leveraging the Potential of LLMs in Corpus-based Discourse Analysis with Prompt Engineering**
2412.10139v1 by Bingru Li, Han Wang

The capacity of LLMs to carry out automated qualitative analysis has been
questioned by corpus linguists, and it has been argued that corpus-based
discourse analysis incorporating LLMs is hindered by issues of unsatisfying
performance, hallucination, and irreproducibility. Our proposed method,
TACOMORE, aims to address these concerns by serving as an effective prompting
framework in this domain. The framework consists of four principles, i.e.,
Task, Context, Model and Reproducibility, and specifies five fundamental
elements of a good prompt, i.e., Role Description, Task Definition, Task
Procedures, Contextual Information and Output Format. We conduct experiments on
three LLMs, i.e., GPT-4o, Gemini-1.5-Pro and Gemini-1.5.Flash, and find that
TACOMORE helps improve LLM performance in three representative discourse
analysis tasks, i.e., the analysis of keywords, collocates and concordances,
based on an open corpus of COVID-19 research articles. Our findings show the
efficacy of the proposed prompting framework TACOMORE in corpus-based discourse
analysis in terms of Accuracy, Ethicality, Reasoning, and Reproducibility, and
provide novel insights into the application and evaluation of LLMs in automated
qualitative studies.

摘要：大型語言模型執行自動化定性分析的能力已受到語料庫語言學家的質疑，有人認為，結合大型語言模型的語料庫為基礎的語篇分析受到不令人滿意的表現、幻覺和不可複製性等問題的阻礙。我們提出的方法 TACOMORE 旨在透過作為此領域中有效的提示架構來解決這些問題。此架構包含四項原則，即任務、脈絡、模型和可複製性，並指定良好提示的五個基本元素，即角色描述、任務定義、任務程序、脈絡資訊和輸出格式。我們對三個大型語言模型執行實驗，即 GPT-4o、Gemini-1.5-Pro 和 Gemini-1.5.Flash，發現 TACOMORE 有助於提升大型語言模型在三項代表性語篇分析任務中的表現，即關鍵字、搭配詞和共現分析，這些任務基於 COVID-19 研究文章的開放語料庫。我們的研究結果顯示，提出的提示架構 TACOMORE 在語料庫為基礎的語篇分析中，在準確性、倫理性、推理和可複製性方面具有效能，並提供大型語言模型在自動化定性研究中應用和評估的新見解。

##### **ROUTE: Robust Multitask Tuning and Collaboration for Text-to-SQL**
2412.10138v1 by Yang Qin, Chao Chen, Zhihang Fu, Ze Chen, Dezhong Peng, Peng Hu, Jieping Ye

Despite the significant advancements in Text-to-SQL (Text2SQL) facilitated by
large language models (LLMs), the latest state-of-the-art techniques are still
trapped in the in-context learning of closed-source LLMs (e.g., GPT-4), which
limits their applicability in open scenarios. To address this challenge, we
propose a novel RObust mUltitask Tuning and collaboration mEthod (ROUTE) to
improve the comprehensive capabilities of open-source LLMs for Text2SQL,
thereby providing a more practical solution. Our approach begins with
multi-task supervised fine-tuning (SFT) using various synthetic training data
related to SQL generation. Unlike existing SFT-based Text2SQL methods, we
introduced several additional SFT tasks, including schema linking, noise
correction, and continuation writing. Engaging in a variety of SQL generation
tasks enhances the model's understanding of SQL syntax and improves its ability
to generate high-quality SQL queries. Additionally, inspired by the
collaborative modes of LLM agents, we introduce a Multitask Collaboration
Prompting (MCP) strategy. This strategy leverages collaboration across several
SQL-related tasks to reduce hallucinations during SQL generation, thereby
maximizing the potential of enhancing Text2SQL performance through explicit
multitask capabilities. Extensive experiments and in-depth analyses have been
performed on eight open-source LLMs and five widely-used benchmarks. The
results demonstrate that our proposal outperforms the latest Text2SQL methods
and yields leading performance.

摘要：儘管大型語言模型 (LLM) 促進了文字轉 SQL (Text2SQL) 的重大進展，但最新的最先進技術仍受限於封閉原始碼 LLM (例如 GPT-4) 的情境學習中，這限制了它們在開放場景中的適用性。為了應對這一挑戰，我們提出了一種新穎的強健多任務調整和協作方法 (ROUTE)，以提高開放原始碼 LLM 對 Text2SQL 的綜合能力，從而提供更實用的解決方案。我們的做法從使用與 SQL 生成相關的各種合成訓練資料的多任務監督微調 (SFT) 開始。與現有的基於 SFT 的 Text2SQL 方法不同，我們引入了幾個額外的 SFT 任務，包括模式連結、雜訊校正和延續寫作。參與各種 SQL 生成任務增強了模型對 SQL 語法的理解，並提高了它生成高品質 SQL 查詢的能力。此外，在 LLM 代理的協作模式的啟發下，我們引入了多任務協作提示 (MCP) 策略。此策略利用跨多個與 SQL 相關任務的協作來減少 SQL 生成過程中的幻覺，從而通過明確的多任務能力最大限度地發揮增強 Text2SQL 效能的潛力。已經對八個開放原始碼 LLM 和五個廣泛使用的基準進行了廣泛的實驗和深入的分析。結果表明，我們的提案優於最新的 Text2SQL 方法，並產生了領先的效能。

##### **Can LLMs Convert Graphs to Text-Attributed Graphs?**
2412.10136v1 by Zehong Wang, Sidney Liu, Zheyuan Zhang, Tianyi Ma, Chuxu Zhang, Yanfang Ye

Graphs are ubiquitous data structures found in numerous real-world
applications, such as drug discovery, recommender systems, and social network
analysis. Graph neural networks (GNNs) have become a popular tool to learn node
embeddings through message passing on these structures. However, a significant
challenge arises when applying GNNs to multiple graphs with different feature
spaces, as existing GNN architectures are not designed for cross-graph feature
alignment. To address this, recent approaches introduce text-attributed graphs,
where each node is associated with a textual description, enabling the use of a
shared textual encoder to project nodes from different graphs into a unified
feature space. While promising, this method relies heavily on the availability
of text-attributed data, which can be difficult to obtain in practice. To
bridge this gap, we propose a novel method named Topology-Aware Node
description Synthesis (TANS), which leverages large language models (LLMs) to
automatically convert existing graphs into text-attributed graphs. The key idea
is to integrate topological information with each node's properties, enhancing
the LLMs' ability to explain how graph topology influences node semantics. We
evaluate our TANS on text-rich, text-limited, and text-free graphs,
demonstrating that it enables a single GNN to operate across diverse graphs.
Notably, on text-free graphs, our method significantly outperforms existing
approaches that manually design node features, showcasing the potential of LLMs
for preprocessing graph-structured data, even in the absence of textual
information. The code and data are available at
https://github.com/Zehong-Wang/TANS.

摘要：圖形是普遍存在於許多真實世界應用中的資料結構，例如藥物發現、推薦系統和社交網路分析。圖形神經網路 (GNN) 已成為一種流行的工具，可透過在這些結構上傳遞訊息來學習節點嵌入。然而，當將 GNN 應用於具有不同特徵空間的多個圖形時，會出現一個重大的挑戰，因為現有的 GNN 架構並非設計用於跨圖形特徵對齊。為了解決這個問題，最近的方法引入了文字屬性圖形，其中每個節點都與文字描述相關聯，從而可以使用共用文字編碼器將來自不同圖形的節點投影到統一的特徵空間中。儘管有希望，但此方法在很大程度上依賴於文字屬性資料的可用性，這在實務上可能難以取得。為了彌補這個差距，我們提出了一種名為拓撲感知節點描述合成 (TANS) 的新方法，該方法利用大型語言模型 (LLM) 將現有圖形自動轉換為文字屬性圖形。其關鍵思想是將拓撲資訊與每個節點的屬性整合在一起，增強 LLM 解釋圖形拓撲如何影響節點語義的能力。我們在文字豐富、文字受限和無文字圖形上評估我們的 TANS，證明它能讓單一 GNN 在不同的圖形中運作。值得注意的是，在無文字圖形上，我們的模型顯著優於手動設計節點特徵的現有方法，展示了 LLM 在預處理圖形結構資料方面的潛力，即使在沒有文字資訊的情況下也是如此。程式碼和資料可在 https://github.com/Zehong-Wang/TANS 取得。

##### **ASLoRA: Adaptive Sharing Low-Rank Adaptation Across Layers**
2412.10135v1 by Junyan Hu, Xue Xiao, Mengqi Zhang, Xiao Chen, Zhaochun Ren, Zhumin Chen, Pengjie Ren

As large language models (LLMs) grow in size, traditional full fine-tuning
becomes increasingly impractical due to its high computational and storage
costs. Although popular parameter-efficient fine-tuning methods, such as LoRA,
have significantly reduced the number of tunable parameters, there is still
room for further optimization. In this work, we propose ASLoRA, a cross-layer
parameter-sharing strategy combining global sharing with partial adaptive
sharing. Specifically, we share the low-rank matrix A across all layers and
adaptively merge matrix B during training. This sharing mechanism not only
mitigates overfitting effectively but also captures inter-layer dependencies,
significantly enhancing the model's representational capability. We conduct
extensive experiments on various NLP tasks, showing that ASLoRA outperforms
LoRA while using less than 25% of the parameters, highlighting its flexibility
and superior parameter efficiency. Furthermore, in-depth analyses of the
adaptive sharing strategy confirm its significant advantages in enhancing both
model flexibility and task adaptability.

摘要：隨著大型語言模型 (LLM) 規模的擴大，由於其高運算和儲存成本，傳統的全微調變得越來越不切實際。儘管流行的參數有效微調方法，例如 LoRA，已顯著減少可調參數的數量，但仍有進一步最佳化的空間。在這項工作中，我們提出 ASLoRA，一種跨層參數共享策略，結合了全局共享和部分自適應共享。具體來說，我們在所有層中共享低秩矩陣 A，並在訓練期間自適應地合併矩陣 B。這種共享機制不僅有效地減輕了過度擬合，而且還捕獲了層間依賴性，顯著增強了模型的表示能力。我們對各種 NLP 任務進行了廣泛的實驗，表明 ASLoRA 在使用不到 25% 的參數時優於 LoRA，突出了其靈活性與卓越的參數效率。此外，對自適應共享策略的深入分析證實了其在增強模型靈活性與任務適應性方面的顯著優勢。

##### **You Name It, I Run It: An LLM Agent to Execute Tests of Arbitrary Projects**
2412.10133v1 by Islem Bouzenia, Michael Pradel

The ability to execute the test suite of a project is essential in many
scenarios, e.g., to assess code quality and code coverage, to validate code
changes made by developers or automated tools, and to ensure compatibility with
dependencies. Despite its importance, executing the test suite of a project can
be challenging in practice because different projects use different programming
languages, software ecosystems, build systems, testing frameworks, and other
tools. These challenges make it difficult to create a reliable, universal test
execution method that works across different projects. This paper presents
ExecutionAgent, an automated technique that installs arbitrary projects,
configures them to run test cases, and produces project-specific scripts to
reproduce the setup. Inspired by the way a human developer would address this
task, our approach is a large language model-based agent that autonomously
executes commands and interacts with the host system. The agent uses
meta-prompting to gather guidelines on the latest technologies related to the
given project, and it iteratively refines its process based on feedback from
the previous steps. Our evaluation applies ExecutionAgent to 50 open-source
projects that use 14 different programming languages and many different build
and testing tools. The approach successfully executes the test suites of 33/55
projects, while matching the test results of ground truth test suite executions
with a deviation of only 7.5\%. These results improve over the best previously
available technique by 6.6x. The costs imposed by the approach are reasonable,
with an execution time of 74 minutes and LLM costs of 0.16 dollars, on average
per project. We envision ExecutionAgent to serve as a valuable tool for
developers, automated programming tools, and researchers that need to execute
tests across a wide variety of projects.

摘要：在許多場景中，執行專案的測試套件的能力至關重要，例如評估程式碼品質和程式碼涵蓋率、驗證開發人員或自動化工具所做的程式碼變更，以及確保與依賴項相容。儘管其重要性，在實務上執行專案的測試套件可能具有挑戰性，因為不同的專案使用不同的程式語言、軟體生態系統、建置系統、測試架構和其他工具。這些挑戰使得難以建立一個可靠的通用測試執行方法，可以在不同的專案中運作。本文提出 ExecutionAgent，一種自動化技術，它會安裝任意專案、將其組態為執行測試案例，並產生專案特定的腳本以重現設定。我們的做法受到人類開發人員處理此任務的方式啟發，是一種大型語言模型基礎的代理，它會自動執行指令並與主機系統互動。代理使用元提示來收集有關給定專案的最新技術的指南，並且根據前一階段的回饋，反覆改善其流程。我們的評估將 ExecutionAgent 套用到 50 個使用 14 種不同程式語言和許多不同建置和測試工具的開源專案。此做法成功執行 33/55 個專案的測試套件，同時僅有 7.5% 的偏差，與基本實況測試套件執行結果相符。這些結果比先前可用的最佳技術進步了 6.6 倍。此做法產生的成本合理，平均每個專案的執行時間為 74 分鐘，LLM 成本為 0.16 美元。我們預想 ExecutionAgent 可作為開發人員、自動化程式設計工具和需要執行各種專案測試的研究人員的寶貴工具。

##### **Familiarity: Better Evaluation of Zero-Shot Named Entity Recognition by Quantifying Label Shifts in Synthetic Training Data**
2412.10121v1 by Jonas Golde, Patrick Haller, Max Ploner, Fabio Barth, Nicolaas Jedema, Alan Akbik

Zero-shot named entity recognition (NER) is the task of detecting named
entities of specific types (such as 'Person' or 'Medicine') without any
training examples. Current research increasingly relies on large synthetic
datasets, automatically generated to cover tens of thousands of distinct entity
types, to train zero-shot NER models. However, in this paper, we find that
these synthetic datasets often contain entity types that are semantically
highly similar to (or even the same as) those in standard evaluation
benchmarks. Because of this overlap, we argue that reported F1 scores for
zero-shot NER overestimate the true capabilities of these approaches. Further,
we argue that current evaluation setups provide an incomplete picture of
zero-shot abilities since they do not quantify the label shift (i.e., the
similarity of labels) between training and evaluation datasets. To address
these issues, we propose Familiarity, a novel metric that captures both the
semantic similarity between entity types in training and evaluation, as well as
their frequency in the training data, to provide an estimate of label shift. It
allows researchers to contextualize reported zero-shot NER scores when using
custom synthetic training datasets. Further, it enables researchers to generate
evaluation setups of various transfer difficulties for fine-grained analysis of
zero-shot NER.

摘要：零次學習命名實體辨識 (NER) 是一項任務，在沒有任何訓練範例的情況下，偵測特定類型的命名實體（例如「人物」或「藥物」）。目前的研究所越來越依賴大型合成資料集，自動產生涵蓋數萬個不同實體類型的資料，來訓練零次學習 NER 模型。然而，在本文中，我們發現這些合成資料集通常包含語義上與標準評量基準中的實體類型高度相似（甚至相同）的實體類型。由於這種重疊，我們認為零次學習 NER 所報告的 F1 分數高估了這些方法的真實能力。此外，我們認為目前的評量設定提供了不完整的零次學習能力，因為它們沒有量化訓練和評量資料集之間的標籤轉移（即標籤的相似性）。為了解決這些問題，我們提出了熟悉度，這是一種新的指標，它同時擷取了訓練和評量中實體類型之間的語義相似性，以及它們在訓練資料中的頻率，以提供標籤轉移的估計值。它允許研究人員在使用自訂合成訓練資料集時，將所報告的零次學習 NER 分數脈絡化。此外，它使研究人員能夠產生各種轉移難度的評量設定，以進行零次學習 NER 的細粒度分析。

##### **CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language Models**
2412.10117v1 by Zhihao Du, Yuxuan Wang, Qian Chen, Xian Shi, Xiang Lv, Tianyu Zhao, Zhifu Gao, Yexin Yang, Changfeng Gao, Hui Wang, Fan Yu, Huadai Liu, Zhengyan Sheng, Yue Gu, Chong Deng, Wen Wang, Shiliang Zhang, Zhijie Yan, Jingren Zhou

In our previous work, we introduced CosyVoice, a multilingual speech
synthesis model based on supervised discrete speech tokens. By employing
progressive semantic decoding with two popular generative models, language
models (LMs) and Flow Matching, CosyVoice demonstrated high prosody
naturalness, content consistency, and speaker similarity in speech in-context
learning. Recently, significant progress has been made in multi-modal large
language models (LLMs), where the response latency and real-time factor of
speech synthesis play a crucial role in the interactive experience. Therefore,
in this report, we present an improved streaming speech synthesis model,
CosyVoice 2, which incorporates comprehensive and systematic optimizations.
Specifically, we introduce finite-scalar quantization to improve the codebook
utilization of speech tokens. For the text-speech LM, we streamline the model
architecture to allow direct use of a pre-trained LLM as the backbone. In
addition, we develop a chunk-aware causal flow matching model to support
various synthesis scenarios, enabling both streaming and non-streaming
synthesis within a single model. By training on a large-scale multilingual
dataset, CosyVoice 2 achieves human-parity naturalness, minimal response
latency, and virtually lossless synthesis quality in the streaming mode. We
invite readers to listen to the demos at
https://funaudiollm.github.io/cosyvoice2.

摘要：在我們之前的工作中，我們介紹了 CosyVoice，這是一個基於監督離散語音符號的多語言語音合成模型。通過使用兩個流行的生成模型（語言模型 (LM) 和流匹配）來採用漸進語義解碼，CosyVoice 展示了語境學習中語調的自然性、內容的一致性和說話者的相似性。最近，多模態大型語言模型 (LLM) 取得了重大進展，其中語音合成的響應延遲和實時因素在互動體驗中發揮著至關重要的作用。因此，在本文中，我們提出了一個改進的串流語音合成模型 CosyVoice 2，它包含了全面和系統性的最佳化。具體來說，我們引入了有限標量量化來改善語音符號的碼本利用率。對於文字語音 LM，我們簡化了模型架構，允許直接使用預訓練的 LLM 作為主幹。此外，我們開發了一個分塊感知因果流匹配模型來支援各種合成場景，在單一模型中實現串流和非串流合成。通過在一個大規模多語言資料集上訓練，CosyVoice 2 在串流模式下實現了人類同等的自然性、最小的響應延遲和幾乎無損的合成品質。我們邀請讀者在 https://funaudiollm.github.io/cosyvoice2 上收聽示範。

##### **Label-template based Few-Shot Text Classification with Contrastive Learning**
2412.10110v1 by Guanghua Hou, Shuhui Cao, Deqiang Ouyang, Ning Wang

As an algorithmic framework for learning to learn, meta-learning provides a
promising solution for few-shot text classification. However, most existing
research fail to give enough attention to class labels. Traditional basic
framework building meta-learner based on prototype networks heavily relies on
inter-class variance, and it is easily influenced by noise. To address these
limitations, we proposes a simple and effective few-shot text classification
framework. In particular, the corresponding label templates are embed into
input sentences to fully utilize the potential value of class labels, guiding
the pre-trained model to generate more discriminative text representations
through the semantic information conveyed by labels. With the continuous
influence of label semantics, supervised contrastive learning is utilized to
model the interaction information between support samples and query samples.
Furthermore, the averaging mechanism is replaced with an attention mechanism to
highlight vital semantic information. To verify the proposed scheme, four
typical datasets are employed to assess the performance of different methods.
Experimental results demonstrate that our method achieves substantial
performance enhancements and outperforms existing state-of-the-art models on
few-shot text classification tasks.

摘要：作為一種用於學習學習的演算法架構，元學習為少發文字分類提供了一個有前途的解決方案。然而，現有的大多數研究未能給予類別標籤足夠的關注。傳統的基本架構建立基於原型網路的元學習者，嚴重依賴於類間差異，並且容易受到雜訊的影響。為了解決這些限制，我們提出了一個簡單而有效的少發文字分類架構。具體來說，將對應的標籤範本嵌入輸入句子中，以充分利用類別標籤的潛在價值，指導預訓練模型通過標籤傳達的語義資訊生成更具區別性的文字表示。在標籤語義的持續影響下，利用監督對比學習對支援樣本和查詢樣本之間的互動資訊進行建模。此外，將平均機制替換為注意力機制，以突出重要的語義資訊。為了驗證所提出的方案，採用了四個典型的資料集來評估不同方法的效能。實驗結果表明，我們的模型在少發文字分類任務中實現了顯著的效能提升，並且優於現有的最先進模型。

##### **NetOrchLLM: Mastering Wireless Network Orchestration with Large Language Models**
2412.10107v1 by Asmaa Abdallah, Abdullatif Albaseer, Abdulkadir Celik, Mohamed Abdallah, Ahmed M. Eltawil

The transition to 6G networks promises unprecedented advancements in wireless
communication, with increased data rates, ultra-low latency, and enhanced
capacity. However, the complexity of managing and optimizing these
next-generation networks presents significant challenges. The advent of large
language models (LLMs) has revolutionized various domains by leveraging their
sophisticated natural language understanding capabilities. However, the
practical application of LLMs in wireless network orchestration and management
remains largely unexplored. Existing literature predominantly offers visionary
perspectives without concrete implementations, leaving a significant gap in the
field. To address this gap, this paper presents NETORCHLLM, a wireless NETwork
ORCHestrator LLM framework that uses LLMs to seamlessly orchestrate diverse
wireless-specific models from wireless communication communities using their
language understanding and generation capabilities. A comprehensive framework
is introduced, demonstrating the practical viability of our approach and
showcasing how LLMs can be effectively harnessed to optimize dense network
operations, manage dynamic environments, and improve overall network
performance. NETORCHLLM bridges the theoretical aspirations of prior research
with practical, actionable solutions, paving the way for future advancements in
integrating generative AI technologies within the wireless communications
sector.

摘要：6G 網路轉型承諾無線通訊前所未有的進展，包括更高的資料速率、極低的延遲和增強的容量。然而，管理和最佳化這些次世代網路的複雜性，帶來了重大的挑戰。大型語言模型 (LLM) 的出現，透過運用其精密自然語言理解能力，徹底改變了各種領域。然而，LLM 在無線網路協調和管理中的實際應用，仍然很大程度上未經探索。現有的文獻主要提供有遠見的觀點，而沒有具體的實作，在該領域留下了重大的鴻溝。為了解決這個鴻溝，本文提出 NETORCHLLM，一個無線網路協調器 LLM 架構，它使用 LLM 從無線通訊社群中無縫地協調各種特定於無線的模型，使用它們的語言理解和生成能力。引進了一個全面的架構，展示我們方法的實際可行性，並展示如何有效地利用 LLM 來最佳化密集網路操作、管理動態環境，以及改善整體網路效能。NETORCHLLM 將先前研究的理論願景與實用且可行的解決方案連結起來，為未來在無線通訊領域整合生成式 AI 技術的進展鋪路。

##### **A Cascaded Dilated Convolution Approach for Mpox Lesion Classification**
2412.10106v1 by Ayush Deshmukh

The global outbreak of Mpox virus, classified as a Public Health Emergency of
International Concern by WHO, presents significant diagnostic challenges due to
its visual similarity to other skin lesion diseases. Current clinical detection
techniques face limitations in accuracy and efficiency, necessitating improved
automated diagnostic solutions. This study introduces a novel Cascaded Atrous
Group Attention (CAGA) module, specifically designed to enhance multi-scale
feature representation while optimizing computational efficiency. By
integrating CAGA with EfficientViT-L1 as the backbone architecture, our
approach achieves state-of-the-art performance with a score of 0.98% on the
MCSI dataset, while reducing model parameters by 37.5% compared to the original
EfficientViT-L1. This reduction in computational complexity maintains
diagnostic accuracy while enabling broader deployment across
resource-constrained healthcare settings. Extensive validation across two other
benchmark datasets, including MSID and MSLD, demonstrate the model's
robustness, consistently outperforming existing approaches. Our findings
suggest that CAGA's efficient feature extraction mechanism could be adapted for
other medical imaging tasks requiring fine-grained visual discrimination.

摘要：由於世界衛生組織將猴痘病毒全球爆發定為國際關注的公共衛生緊急事件，因此猴痘病毒與其他皮膚病變疾病在視覺上的相似性，對診斷帶來重大挑戰。目前的臨床檢測技術在準確性和效率方面面臨限制，因此需要改進的自動化診斷解決方案。本研究引入了一個新穎的串聯空洞組注意力 (CAGA) 模組，專門設計用於增強多尺度特徵表示，同時最佳化運算效率。透過將 CAGA 與 EfficientViT-L1 整合作為主幹架構，我們的做法在 MCSI 資料集上以 0.98% 的分數達到了最先進的效能，同時與原始 EfficientViT-L1 相比，模型參數減少了 37.5%。這種運算複雜度的降低維持了診斷準確性，同時支援在資源受限的醫療保健環境中更廣泛地部署。在包括 MSID 和 MSLD 在內的另外兩個基準資料集上的廣泛驗證證明了模型的穩健性，始終優於現有方法。我們的研究結果表明，CAGA 的高效特徵提取機制可以調整為其他需要細緻視覺辨別的醫學影像任務。

##### **MALAMUTE: A Multilingual, Highly-granular, Template-free, Education-based Probing Dataset**
2412.10105v1 by Sagi Shaier, George Arthur Baker, Chiranthan Sridhar, Lawrence E Hunter, Katharina von der Wense

Language models (LMs) have excelled in various broad domains. However, to
ensure their safe and effective integration into real-world educational
settings, they must demonstrate proficiency in specific, granular areas of
knowledge. Existing cloze-style benchmarks, commonly used to evaluate LMs'
knowledge, have three major limitations. They: 1) do not cover the educational
domain; 2) typically focus on low-complexity, generic knowledge or broad
domains, which do not adequately assess the models' knowledge in specific
subjects; and 3) often rely on templates that can bias model predictions. Here,
we introduce MALAMUTE, a multilingual, template-free, and highly granular
probing dataset comprising expert-written, peer-reviewed probes from 71
university-level textbooks across three languages (English, Spanish, and
Polish). MALAMUTE is the first education-based cloze-style dataset. It covers
eight domains, each with up to 14 subdomains, further broken down into concepts
and concept-based prompts, totaling 33,361 university curriculum concepts and
116,887 prompts. MALAMUTE's fine granularity, educational focus, and inclusion
of both sentence-level and paragraph-level prompts make it an ideal tool for
evaluating LMs' course-related knowledge. Our evaluation of masked and causal
LMs on MALAMUTE shows that despite overall proficiency, they have significant
gaps in knowledge when examined closely on specific subjects, hindering their
safe use in classrooms and underscoring the need for further development.

摘要：語言模型 (LM) 在各種廣泛的領域中表現出色。然而，為了確保它們安全有效地整合到現實世界的教育環境中，它們必須在特定、細緻的知識領域中展現出熟練度。現有的完形填空基準，通常用於評估 LM 的知識，有三個主要的限制。它們：1) 沒有涵蓋教育領域；2) 通常專注於低複雜性、通用知識或廣泛領域，無法充分評估模型在特定主題中的知識；3) 經常依賴可能偏向模型預測的範本。在此，我們介紹 MALAMUTE，一個多語言、無範本且高度細緻的探測資料集，包含來自 71 本大學教科書的專家撰寫、同行評審的探測，涵蓋三種語言（英語、西班牙語和波蘭語）。MALAMUTE 是第一個基於教育的完形填空資料集。它涵蓋八個領域，每個領域最多有 14 個子領域，進一步細分為概念和基於概念的提示，總計 33,361 個大學課程概念和 116,887 個提示。MALAMUTE 的細緻粒度、教育焦點以及包含句子層級和段落層級提示，使其成為評估 LM 與課程相關知識的理想工具。我們對 MALAMUTE 上的遮蔽和因果 LM 的評估表明，儘管整體熟練，但仔細檢視特定主題時，它們在知識上存在顯著差距，阻礙了它們在課堂上的安全使用，並強調進一步開發的必要性。

##### **RETQA: A Large-Scale Open-Domain Tabular Question Answering Dataset for Real Estate Sector**
2412.10104v1 by Zhensheng Wang, Wenmian Yang, Kun Zhou, Yiquan Zhang, Weijia Jia

The real estate market relies heavily on structured data, such as property
details, market trends, and price fluctuations. However, the lack of
specialized Tabular Question Answering datasets in this domain limits the
development of automated question-answering systems. To fill this gap, we
introduce RETQA, the first large-scale open-domain Chinese Tabular Question
Answering dataset for Real Estate. RETQA comprises 4,932 tables and 20,762
question-answer pairs across 16 sub-fields within three major domains: property
information, real estate company finance information and land auction
information. Compared with existing tabular question answering datasets, RETQA
poses greater challenges due to three key factors: long-table structures,
open-domain retrieval, and multi-domain queries. To tackle these challenges, we
propose the SLUTQA framework, which integrates large language models with
spoken language understanding tasks to enhance retrieval and answering
accuracy. Extensive experiments demonstrate that SLUTQA significantly improves
the performance of large language models on RETQA by in-context learning. RETQA
and SLUTQA provide essential resources for advancing tabular question answering
research in the real estate domain, addressing critical challenges in
open-domain and long-table question-answering. The dataset and code are
publicly available at \url{https://github.com/jensen-w/RETQA}.

摘要：房地產市場極度依賴結構化資料，例如地產明細、市場趨勢和價格波動。然而，此領域缺乏專業的表格問答資料集，限制了自動化問答系統的發展。為了填補此缺口，我們引進 RETQA，這是第一個針對房地產的大規模開放領域中文表格問答資料集。RETQA 包含 4,932 個表格和 20,762 個問答組，涵蓋三個主要領域內的 16 個子領域：地產資訊、房地產公司財務資訊和土地拍賣資訊。與現有的表格問答資料集相比，RETQA 由於三個關鍵因素而帶來更大的挑戰：長表格結構、開放領域擷取和多領域查詢。為了應對這些挑戰，我們提出了 SLUTQA 框架，它將大型語言模型與口語理解任務整合在一起，以增強擷取和回答的準確性。廣泛的實驗證明，SLUTQA 透過情境學習，大幅提升大型語言模型在 RETQA 上的效能。RETQA 和 SLUTQA 提供了必要的資源，用於推進房地產領域的表格問答研究，解決開放領域和長表格問答中的關鍵挑戰。資料集和程式碼已公開於 \url{https://github.com/jensen-w/RETQA}。

##### **AMuSeD: An Attentive Deep Neural Network for Multimodal Sarcasm Detection Incorporating Bi-modal Data Augmentation**
2412.10103v1 by Xiyuan Gao, Shubhi Bansal, Kushaan Gowda, Zhu Li, Shekhar Nayak, Nagendra Kumar, Matt Coler

Detecting sarcasm effectively requires a nuanced understanding of context,
including vocal tones and facial expressions. The progression towards
multimodal computational methods in sarcasm detection, however, faces
challenges due to the scarcity of data. To address this, we present AMuSeD
(Attentive deep neural network for MUltimodal Sarcasm dEtection incorporating
bi-modal Data augmentation). This approach utilizes the Multimodal Sarcasm
Detection Dataset (MUStARD) and introduces a two-phase bimodal data
augmentation strategy. The first phase involves generating varied text samples
through Back Translation from several secondary languages. The second phase
involves the refinement of a FastSpeech 2-based speech synthesis system,
tailored specifically for sarcasm to retain sarcastic intonations. Alongside a
cloud-based Text-to-Speech (TTS) service, this Fine-tuned FastSpeech 2 system
produces corresponding audio for the text augmentations. We also investigate
various attention mechanisms for effectively merging text and audio data,
finding self-attention to be the most efficient for bimodal integration. Our
experiments reveal that this combined augmentation and attention approach
achieves a significant F1-score of 81.0% in text-audio modalities, surpassing
even models that use three modalities from the MUStARD dataset.

摘要：偵測諷刺需要對脈絡有細緻的理解，包括語調和表情。然而，朝向多模態計算方法的進展在諷刺偵測上會面臨挑戰，因為資料稀少。為了解決這個問題，我們提出了 AMuSeD (用於多模態諷刺偵測的注意力深度神經網路，結合雙模態資料擴充)。此方法利用多模態諷刺偵測資料集 (MUStARD)，並引入一個兩階段的雙模態資料擴充策略。第一階段包含透過從多種次要語言進行反向翻譯來產生不同的文字範例。第二階段包含改進 FastSpeech 2 為基礎的語音合成系統，特別針對諷刺進行調整，以保留諷刺性的語調。這個微調過的 FastSpeech 2 系統與雲端文字轉語音 (TTS) 服務一起，為文字擴充產生對應的音訊。我們也研究了各種注意力機制，以有效地合併文字和音訊資料，發現自我注意力對於雙模態整合最有效率。我們的實驗顯示，這種結合擴充和注意力的方法在文字音訊模態中達到顯著的 F1 分數 81.0%，甚至超越使用 MUStARD 資料集三個模態的模型。

##### **HiTZ at VarDial 2025 NorSID: Overcoming Data Scarcity with Language Transfer and Automatic Data Annotation**
2412.10095v1 by Jaione Bengoetxea, Mikel Zubillaga, Ekhi Azurmendi, Maite Heredia, Julen Etxaniz, Markel Ferro, Jeremy Barnes

In this paper we present our submission for the NorSID Shared Task as part of
the 2025 VarDial Workshop (Scherrer et al., 2025), consisting of three tasks:
Intent Detection, Slot Filling and Dialect Identification, evaluated using data
in different dialects of the Norwegian language. For Intent Detection and Slot
Filling, we have fine-tuned a multitask model in a cross-lingual setting, to
leverage the xSID dataset available in 17 languages. In the case of Dialect
Identification, our final submission consists of a model fine-tuned on the
provided development set, which has obtained the highest scores within our
experiments. Our final results on the test set show that our models do not drop
in performance compared to the development set, likely due to the
domain-specificity of the dataset and the similar distribution of both subsets.
Finally, we also report an in-depth analysis of the provided datasets and their
artifacts, as well as other sets of experiments that have been carried out but
did not yield the best results. Additionally, we present an analysis on the
reasons why some methods have been more successful than others; mainly the
impact of the combination of languages and domain-specificity of the training
data on the results.

摘要：<paragraph>在本文中，我們提交了我們對 NorSID 共享任務的提交，作為 2025 VarDial 研討會（Scherrer 等人，2025 年）的一部分，包括三個任務：意圖偵測、槽位填補和方言辨識，使用挪威語不同方言的資料進行評估。對於意圖偵測和槽位填補，我們在跨語言設定中微調了一個多任務模型，以利用 17 種語言中可用的 xSID 資料集。在方言辨識的情況下，我們的最終提交包含一個在提供的開發設定上微調的模型，該模型在我們的實驗中獲得了最高分。我們在測試設定上的最終結果顯示，與開發設定相比，我們的模型的效能沒有下降，這可能是由於資料集的特定領域和兩個子集的相似分佈。最後，我們還報告了對提供的資料集及其人工製品的深入分析，以及已執行但未產生最佳結果的其他實驗組。此外，我們分析了某些方法比其他方法更成功的原因；主要是語言組合和訓練資料的特定領域對結果的影響。</paragraph>

##### **AI in the Cosmos**
2412.10093v1 by N. Sahakyan

Artificial intelligence (AI) is revolutionizing research by enabling the
efficient analysis of large datasets and the discovery of hidden patterns. In
astrophysics, AI has become essential, transforming the classification of
celestial sources, data modeling, and the interpretation of observations. In
this review, I highlight examples of AI applications in astrophysics, including
source classification, spectral energy distribution modeling, and discuss the
advancements achievable through generative AI. However, the use of AI
introduces challenges, including biases, errors, and the "black box" nature of
AI models, which must be resolved before their application. These issues can be
addressed through the concept of Human-Guided AI (HG-AI), which integrates
human expertise and domain-specific knowledge into AI applications. This
approach aims to ensure that AI is applied in a robust, interpretable, and
ethical manner, leading to deeper insights and fostering scientific excellence.

摘要：人工智慧 (AI) 透過協助有效分析大型資料集和發現隱藏模式，進而革新研究。在天文物理學中，AI 已成為不可或缺的工具，轉變了天體來源的分類、資料建模和觀測結果的詮釋。在這篇評論中，我重點介紹了 AI 在天文物理學中的應用範例，包括來源分類、光譜能量分布建模，並探討透過生成式 AI 所能達到的進展。然而，AI 的使用也帶來了挑戰，包括偏差、錯誤和 AI 模型的「黑箱」性質，在應用之前必須解決這些問題。這些問題可透過人類引導 AI (HG-AI) 的概念來解決，這將人類的專業知識和特定領域的知識整合到 AI 應用中。這種方法旨在確保 AI 以強健、可詮釋和合乎道德的方式應用，進而獲得更深入的見解並促進科學卓越。

##### **Lost in the Middle, and In-Between: Enhancing Language Models' Ability to Reason Over Long Contexts in Multi-Hop QA**
2412.10079v1 by George Arthur Baker, Ankush Raut, Sagi Shaier, Lawrence E Hunter, Katharina von der Wense

Previous work finds that recent long-context language models fail to make
equal use of information in the middle of their inputs, preferring pieces of
information located at the tail ends which creates an undue bias in situations
where we would like models to be equally capable of using different parts of
the input. Thus far, the problem has mainly only been considered in settings
with single pieces of critical information, leading us to question what happens
when multiple necessary pieces of information are spread out over the inputs.
Here, we demonstrate the effects of the "lost in the middle" problem in the
multi-hop question answering setting -- in which multiple reasoning "hops" over
disconnected documents are required -- and show that performance degrades not
only with respect to the distance of information from the edges of the context,
but also between pieces of information. Additionally, we experiment with means
of alleviating the problem by reducing superfluous document contents through
knowledge graph triple extraction and summarization, and prompting models to
reason more thoroughly using chain-of-thought prompting.

摘要：先前的研究發現，最近的長語境語言模型無法平均利用其輸入中段的資訊，偏好位於尾端的資訊片段，這會造成不當的偏差，在我們希望模型能平均使用輸入不同部分的情況下。到目前為止，這個問題主要只在具有單一關鍵資訊片段的設定中被考慮，導致我們質疑當多個必要的資訊片段散佈在輸入中時會發生什麼情況。在此，我們示範了「遺失在中間」問題在多跳問答設定中的影響，其中需要跨越未連接文件的多次推理「跳躍」，並顯示效能不僅會隨著資訊與語境邊緣的距離而下降，也會隨著資訊片段之間的距離而下降。此外，我們實驗了透過知識圖譜三元組萃取和摘要來減少多餘文件內容，並提示模型使用思考鏈提示來更徹底地推理，以減輕問題的方法。

##### **Panacea: Novel DNN Accelerator using Accuracy-Preserving Asymmetric Quantization and Energy-Saving Bit-Slice Sparsity**
2412.10059v1 by Dongyun Kam, Myeongji Yun, Sunwoo Yoo, Seungwoo Hong, Zhengya Zhang, Youngjoo Lee

Low bit-precisions and their bit-slice sparsity have recently been studied to
accelerate general matrix-multiplications (GEMM) during large-scale deep neural
network (DNN) inferences. While the conventional symmetric quantization
facilitates low-resolution processing with bit-slice sparsity for both weight
and activation, its accuracy loss caused by the activation's asymmetric
distributions cannot be acceptable, especially for large-scale DNNs. In efforts
to mitigate this accuracy loss, recent studies have actively utilized
asymmetric quantization for activations without requiring additional
operations. However, the cutting-edge asymmetric quantization produces numerous
nonzero slices that cannot be compressed and skipped by recent bit-slice GEMM
accelerators, naturally consuming more processing energy to handle the
quantized DNN models.
  To simultaneously achieve high accuracy and hardware efficiency for
large-scale DNN inferences, this paper proposes an Asymmetrically-Quantized
bit-Slice GEMM (AQS-GEMM) for the first time. In contrast to the previous
bit-slice computing, which only skips operations of zero slices, the AQS-GEMM
compresses frequent nonzero slices, generated by asymmetric quantization, and
skips their operations. To increase the slice-level sparsity of activations, we
also introduce two algorithm-hardware co-optimization methods: a zero-point
manipulation and a distribution-based bit-slicing. To support the proposed
AQS-GEMM and optimizations at the hardware-level, we newly introduce a DNN
accelerator, Panacea, which efficiently handles sparse/dense workloads of the
tiled AQS-GEMM to increase data reuse and utilization. Panacea supports a
specialized dataflow and run-length encoding to maximize data reuse and
minimize external memory accesses, significantly improving its hardware
efficiency. Our benchmark evaluations show Panacea outperforms existing DNN
accelerators.

摘要：<paragraph>低位元精度及其位元切片稀疏性最近已被研究用于在大型深度神经网络 (DNN) 推论期间加速通用矩阵乘法 (GEMM)。虽然传统的对称量化促进了位元切片稀疏性的低分辨率处理，同时适用于权重和激活，但由于激活的不对称分布而造成的准确性损失是不可接受的，特别是对于大型 DNN。为了减轻这种准确性损失，最近的研究积极利用了不对称量化来激活，而不需要额外的操作。然而，最先进的不对称量化产生了大量非零切片，这些切片无法被最近的位元切片 GEMM 加速器压缩和跳过，自然会消耗更多处理能量来处理量化的 DNN 模型。
为了同时实现大型 DNN 推论的高精度和硬件效率，本文首次提出了不对称量化的位元切片 GEMM (AQS-GEMM)。与以前仅跳过零切片操作的位元切片计算不同，AQS-GEMM 压缩了由不对称量化生成的高频非零切片，并跳过它们的运算。为了增加激活的切片级稀疏性，我们还引入了两种算法-硬件协同优化方法：零点操作和基于分布的位元切片。为了在硬件级别支持所提出的 AQS-GEMM 和优化，我们新推出了一种 DNN 加速器 Panacea，它可以有效地处理平铺 AQS-GEMM 的稀疏/密集工作负载，以增加数据重用和利用率。Panacea 支持专门的数据流和游程编码，以最大化数据重用并最小化外部内存访问，从而显著提高其硬件效率。我们的基准评估表明，Panacea 优于现有的 DNN 加速器。</paragraph>

##### **GAOKAO-Eval: Does high scores truly reflect strong capabilities in LLMs?**
2412.10056v1 by Zhikai Lei, Tianyi Liang, Hanglei Hu, Jin Zhang, Yunhua Zhou, Yunfan Shao, Linyang Li, Chenchui Li, Changbo Wang, Hang Yan, Qipeng Guo

Large Language Models (LLMs) are commonly evaluated using human-crafted
benchmarks, under the premise that higher scores implicitly reflect stronger
human-like performance. However, there is growing concern that LLMs may ``game"
these benchmarks due to data leakage, achieving high scores while struggling
with tasks simple for humans. To substantively address the problem, we create
GAOKAO-Eval, a comprehensive benchmark based on China's National College
Entrance Examination (Gaokao), and conduct ``closed-book" evaluations for
representative models released prior to Gaokao. Contrary to prevailing
consensus, even after addressing data leakage and comprehensiveness,
GAOKAO-Eval reveals that high scores still fail to truly reflect human-aligned
capabilities. To better understand this mismatch, We introduce the Rasch model
from cognitive psychology to analyze LLM scoring patterns and identify two key
discrepancies: 1) anomalous consistent performance across various question
difficulties, and 2) high variance in performance on questions of similar
difficulty. In addition, We identified inconsistent grading of LLM-generated
answers among teachers and recurring mistake patterns. we find that the
phenomenons are well-grounded in the motivations behind OpenAI o1, and o1's
reasoning-as-difficulties can mitigate the mismatch. These results show that
GAOKAO-Eval can reveal limitations in LLM capabilities not captured by current
benchmarks and highlight the need for more LLM-aligned difficulty analysis.

摘要：大型語言模型（LLM）通常使用人工評分基準進行評估，前提是較高的分數隱含著更強的人類表現。然而，越來越令人擔憂的是，LLM 可能會由於資料外洩而「玩弄」這些評分基準，在人類執行簡單任務時苦苦掙扎，卻能獲得高分。為了實質解決這個問題，我們根據中國國家大學入學考試（高考）建立了一個全面的評分基準 GAOKAO-Eval，並對在高考之前發布的代表性模型進行「閉卷」評估。與普遍共識相反，即使在解決資料外洩和全面性問題後，GAOKAO-Eval 揭示高分仍然無法真正反映與人類一致的能力。為了更好地理解這種不匹配，我們引入了認知心理學中的 Rasch 模型來分析 LLM 評分模式並找出兩個關鍵差異：1）在各種問題難度中異常一致的表現，以及 2）在難度相似的問題上表現出高變異性。此外，我們發現教師對 LLM 生成的答案評分不一致，並且存在重複的錯誤模式。我們發現這些現象深深植根於 OpenAI o1 背後的動機，o1 的推理即困難，可以減輕這種不匹配。這些結果表明，GAOKAO-Eval 可以揭示 LLM 能力中的限制，而目前的評分基準無法捕捉到這些限制，並強調需要進行更多與 LLM 一致的難度分析。

##### **Unsupervised Named Entity Disambiguation for Low Resource Domains**
2412.10054v1 by Debarghya Datta, Soumajit Pramanik

In the ever-evolving landscape of natural language processing and information
retrieval, the need for robust and domain-specific entity linking algorithms
has become increasingly apparent. It is crucial in a considerable number of
fields such as humanities, technical writing and biomedical sciences to enrich
texts with semantics and discover more knowledge. The use of Named Entity
Disambiguation (NED) in such domains requires handling noisy texts, low
resource settings and domain-specific KBs. Existing approaches are mostly
inappropriate for such scenarios, as they either depend on training data or are
not flexible enough to work with domain-specific KBs. Thus in this work, we
present an unsupervised approach leveraging the concept of Group Steiner Trees
(GST), which can identify the most relevant candidates for entity
disambiguation using the contextual similarities across candidate entities for
all the mentions present in a document. We outperform the state-of-the-art
unsupervised methods by more than 40\% (in avg.) in terms of Precision@1 across
various domain-specific datasets.

摘要：在不断演進的自然語言處理和資訊檢索領域中，對強健且特定於領域的實體連結演算法的需求已變得越來越明顯。在大量領域中，例如人文學科、技術寫作和生物醫學科學，豐富語意和發現更多知識至關重要。在這些領域中使用命名實體消歧 (NED) 需要處理雜訊文字、低資源設定和特定於領域的知識庫。現有的方法大多不適合此類場景，因為它們依賴於訓練資料或不夠靈活，無法與特定於領域的知識庫搭配使用。因此，在這項工作中，我們提出了一個無監督的方法，利用群組史坦納樹 (GST) 的概念，它可以使用文件中所有提及的候選實體之間的上下文相似性來識別實體消歧最相關的候選項。在各種特定於領域的資料集上，我們在 Precision@1 方面優於最先進的無監督方法超過 40%（平均值）。

##### **TSGaussian: Semantic and Depth-Guided Target-Specific Gaussian Splatting from Sparse Views**
2412.10051v1 by Liang Zhao, Zehan Bao, Yi Xie, Hong Chen, Yaohui Chen, Weifu Li

Recent advances in Gaussian Splatting have significantly advanced the field,
achieving both panoptic and interactive segmentation of 3D scenes. However,
existing methodologies often overlook the critical need for reconstructing
specified targets with complex structures from sparse views. To address this
issue, we introduce TSGaussian, a novel framework that combines semantic
constraints with depth priors to avoid geometry degradation in challenging
novel view synthesis tasks. Our approach prioritizes computational resources on
designated targets while minimizing background allocation. Bounding boxes from
YOLOv9 serve as prompts for Segment Anything Model to generate 2D mask
predictions, ensuring semantic accuracy and cost efficiency. TSGaussian
effectively clusters 3D gaussians by introducing a compact identity encoding
for each Gaussian ellipsoid and incorporating 3D spatial consistency
regularization. Leveraging these modules, we propose a pruning strategy to
effectively reduce redundancy in 3D gaussians. Extensive experiments
demonstrate that TSGaussian outperforms state-of-the-art methods on three
standard datasets and a new challenging dataset we collected, achieving
superior results in novel view synthesis of specific objects. Code is available
at: https://github.com/leon2000-ai/TSGaussian.

摘要：高斯散射的最新进展显著推动了该领域的发展，实现了 3D 场景的全景和交互式分割。然而，现有的方法通常忽视了从稀疏视图重建具有复杂结构的特定目标的关键需求。为了解决这个问题，我们引入了 TSGaussian，这是一个新颖的框架，它将语义约束与深度先验相结合，以避免在具有挑战性的新视图合成任务中几何退化。我们的方法将计算资源优先分配给指定目标，同时最小化背景分配。来自 YOLOv9 的边界框用作提示，以使 Segment Anything Model 生成 2D 掩码预测，确保语义准确性和成本效益。TSGaussian 通过为每个高斯椭球体引入紧凑的身份编码并结合 3D 空间一致性正则化，有效地对 3D 高斯进行聚类。利用这些模块，我们提出了一种修剪策略，以有效减少 3D 高斯中的冗余。大量的实验表明，TSGaussian 在三个标准数据集和我们收集的一个具有挑战性的新数据集上优于最先进的方法，在特定对象的 novel view synthesis 中取得了优异的成果。代码可从以下网址获得：https://github.com/leon2000-ai/TSGaussian。

##### **Large Action Models: From Inception to Implementation**
2412.10047v1 by Lu Wang, Fangkai Yang, Chaoyun Zhang, Junting Lu, Jiaxu Qian, Shilin He, Pu Zhao, Bo Qiao, Ray Huang, Si Qin, Qisheng Su, Jiayi Ye, Yudi Zhang, Jian-Guang Lou, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang

As AI continues to advance, there is a growing demand for systems that go
beyond language-based assistance and move toward intelligent agents capable of
performing real-world actions. This evolution requires the transition from
traditional Large Language Models (LLMs), which excel at generating textual
responses, to Large Action Models (LAMs), designed for action generation and
execution within dynamic environments. Enabled by agent systems, LAMs hold the
potential to transform AI from passive language understanding to active task
completion, marking a significant milestone in the progression toward
artificial general intelligence.
  In this paper, we present a comprehensive framework for developing LAMs,
offering a systematic approach to their creation, from inception to deployment.
We begin with an overview of LAMs, highlighting their unique characteristics
and delineating their differences from LLMs. Using a Windows OS-based agent as
a case study, we provide a detailed, step-by-step guide on the key stages of
LAM development, including data collection, model training, environment
integration, grounding, and evaluation. This generalizable workflow can serve
as a blueprint for creating functional LAMs in various application domains. We
conclude by identifying the current limitations of LAMs and discussing
directions for future research and industrial deployment, emphasizing the
challenges and opportunities that lie ahead in realizing the full potential of
LAMs in real-world applications.
  The code for the data collection process utilized in this paper is publicly
available at: https://github.com/microsoft/UFO/tree/main/dataflow, and
comprehensive documentation can be found at
https://microsoft.github.io/UFO/dataflow/overview/.

摘要：隨著人工智慧持續進步，對於超越基於語言的協助，並朝向能夠執行實際行動的智慧代理人的系統需求日益增長。此演進需要從擅長產生文字回應的傳統大型語言模型 (LLM) 轉變為大型動作模型 (LAM)，而後者則專為在動態環境中產生動作和執行動作而設計。透過代理系統的協助，LAM 擁有將人工智慧從被動語言理解轉變為主動任務完成的潛力，並在朝向人工通用智慧邁進的過程中樹立重要的里程碑。
  在本文中，我們提出了一個用於開發 LAM 的全面架構，並提供從構思到部署的系統方法來建立 LAM。我們首先概述 LAM，重點說明其獨特特性，並說明其與 LLM 的不同之處。我們使用基於 Windows 作業系統的代理作為案例研究，並提供有關 LAM 開發關鍵階段的詳細逐步指南，包括資料收集、模型訓練、環境整合、基礎和評估。這個可概括的工作流程可作為在各種應用領域建立功能性 LAM 的藍圖。我們最後找出 LAM 目前的限制，並討論未來研究和產業部署的方向，強調在實際應用中實現 LAM 全部潛力的挑戰和機會。
  本文中使用的資料收集程序程式碼已公開於：https://github.com/microsoft/UFO/tree/main/dataflow，而全面的文件可於 https://microsoft.github.io/UFO/dataflow/overview/ 找到。

##### **Enhanced Speech Emotion Recognition with Efficient Channel Attention Guided Deep CNN-BiLSTM Framework**
2412.10011v1 by Niloy Kumar Kundu, Sarah Kobir, Md. Rayhan Ahmed, Tahmina Aktar, Niloya Roy

Speech emotion recognition (SER) is crucial for enhancing affective computing
and enriching the domain of human-computer interaction. However, the main
challenge in SER lies in selecting relevant feature representations from speech
signals with lower computational costs. In this paper, we propose a lightweight
SER architecture that integrates attention-based local feature blocks (ALFBs)
to capture high-level relevant feature vectors from speech signals. We also
incorporate a global feature block (GFB) technique to capture sequential,
global information and long-term dependencies in speech signals. By aggregating
attention-based local and global contextual feature vectors, our model
effectively captures the internal correlation between salient features that
reflect complex human emotional cues. To evaluate our approach, we extracted
four types of spectral features from speech audio samples: mel-frequency
cepstral coefficients, mel-spectrogram, root mean square value, and
zero-crossing rate. Through a 5-fold cross-validation strategy, we tested the
proposed method on five multi-lingual standard benchmark datasets: TESS,
RAVDESS, BanglaSER, SUBESCO, and Emo-DB, and obtained a mean accuracy of
99.65%, 94.88%, 98.12%, 97.94%, and 97.19% respectively. The results indicate
that our model achieves state-of-the-art (SOTA) performance compared to most
existing methods.

摘要：語音情緒辨識 (SER) 對於加強情感運算和豐富人機互動領域至關重要。然而，SER 的主要挑戰在於以較低的運算成本從語音訊號中選擇相關特徵表徵。在本文中，我們提出了一種輕量級 SER 架構，它整合了基於注意力的局部特徵區塊 (ALFB) 以從語音訊號中擷取高層級相關特徵向量。我們還結合了全局特徵區塊 (GFB) 技術，以擷取語音訊號中的順序、全局資訊和長期依賴性。透過彙總基於注意力的局部和全局脈絡特徵向量，我們的模型有效地擷取了反映複雜人類情緒線索的顯著特徵之間的內部關聯性。為了評估我們的作法，我們從語音音訊範例中萃取了四種類型的頻譜特徵：梅爾頻率倒頻率譜係數、梅爾頻譜圖、均方根值和零交越率。透過 5 倍交叉驗證策略，我們在五個多語言標準基準資料集：TESS、RAVDESS、BanglaSER、SUBESCO 和 Emo-DB 上測試了所提出的方法，並分別獲得了 99.65%、94.88%、98.12%、97.94% 和 97.19% 的平均準確度。結果表明，與大多數現有方法相比，我們的模型達到了最先進 (SOTA) 的效能。

##### **Automated Collection of Evaluation Dataset for Semantic Search in Low-Resource Domain Language**
2412.10008v1 by Anastasia Zhukova, Christian E. Matt, Bela Gipp

Domain-specific languages that use a lot of specific terminology often fall
into the category of low-resource languages. Collecting test datasets in a
narrow domain is time-consuming and requires skilled human resources with
domain knowledge and training for the annotation task. This study addresses the
challenge of automated collecting test datasets to evaluate semantic search in
low-resource domain-specific German language of the process industry. Our
approach proposes an end-to-end annotation pipeline for automated query
generation to the score reassessment of query-document pairs. To overcome the
lack of text encoders trained in the German chemistry domain, we explore a
principle of an ensemble of "weak" text encoders trained on common knowledge
datasets. We combine individual relevance scores from diverse models to
retrieve document candidates and relevance scores generated by an LLM, aiming
to achieve consensus on query-document alignment. Evaluation results
demonstrate that the ensemble method significantly improves alignment with
human-assigned relevance scores, outperforming individual models in both
inter-coder agreement and accuracy metrics. These findings suggest that
ensemble learning can effectively adapt semantic search systems for
specialized, low-resource languages, offering a practical solution to resource
limitations in domain-specific contexts.

摘要：<paragraph>使用大量特定術語的特定領域語言通常屬於低資源語言類別。在狹窄的領域中收集測試數據集非常耗時，並且需要具備領域知識和標註任務訓練的熟練人力資源。本研究解決了自動收集測試數據集的挑戰，以評估流程產業中低資源特定領域德語的語義搜索。我們的做法提出了一個端到端的標註管道，用於自動查詢生成，以重新評分查詢文件對。為了克服在德語化學領域中訓練的文本編碼器的不足，我們探討了一個由在常識數據集上訓練的「弱」文本編碼器組成的集合原理。我們結合了來自不同模型的個別相關性分數，以擷取文件候選項和 LLM 生成的相關性分數，旨在達成查詢文件比對的共識。評估結果表明，集合方法顯著改善了與人工指定的相關性分數的比對，在編碼器間的一致性和準確性指標方面都優於個別模型。這些發現表明，集合學習可以有效地調整語義搜索系統以適應專業的低資源語言，為特定領域背景中的資源限制提供實用的解決方案。</paragraph>

##### **The role of inhibitory control in garden-path sentence processing: A Chinese-English bilingual perspective**
2412.10006v1 by Xiaohui Rao, Haoze Li, Xiaofang Lin, Lijuan Liang

In reading garden-path sentences, people must resolve competing
interpretations, though initial misinterpretations can linger despite
reanalysis. This study examines the role of inhibitory control (IC) in managing
these misinterpretations among Chinese-English bilinguals. Using self-paced
reading tasks, we investigated how IC influences recovery from garden-path
sentences in Chinese (L1) and its interaction with language proficiency during
English (L2) processing. Results indicate that IC does not affect garden-path
recovery in Chinese, suggesting reliance on semantic context may reduce the
need for IC. In contrast, findings for English L2 learners reveal a complex
relationship between language proficiency and IC: Participants with low L2
proficiency but high IC showed lingering misinterpretations, while those with
high proficiency exhibited none. These results support and extend the Model of
Cognitive Control (Ness et al., 2023). Moreover, our comparison of three Stroop
task versions identifies L1 colour-word Stroop task as the preferred measure of
IC in bilingual research.

摘要：在閱讀花園小徑句時，人們必須解決相互競爭的解釋，儘管重新分析，最初的誤解可能會持續存在。本研究探討了抑制性控制 (IC) 在管理中國英語雙語者之間這些誤解中的作用。使用自定進度閱讀任務，我們調查了 IC 如何影響從中文 (L1) 的花園小徑句中恢復，以及它在英語 (L2) 處理過程中與語言能力的互動。結果表明，IC 沒有影響中文中的花園小徑恢復，這表明依賴語義上下文可以減少對 IC 的需求。相比之下，英語 L2 學習者的研究結果揭示了語言能力和 IC 之間的複雜關係：L2 水平低但 IC 高的參與者表現出持續的誤解，而那些水平高的參與者則沒有。這些結果支持並擴展了認知控制模型 (Ness 等人，2023)。此外，我們對三個 Stroop 任務版本的比較將 L1 顏色詞 Stroop 任務確定為雙語研究中 IC 的首選測量方法。

##### **Cycle-Consistent Bridge Diffusion Model for Accelerated MRI Reconstruction**
2412.09998v1 by Tao Song, Yicheng Wu, Minhao Hu, Xiangde Luo, Guoting Luo, Guotai Wang, Yi Guo, Feng Xu, Shaoting Zhang

Accelerated MRI reconstruction techniques aim to reduce examination time
while maintaining high image fidelity, which is highly desirable in clinical
settings for improving patient comfort and hospital efficiency. Existing deep
learning methods typically reconstruct images from under-sampled data with
traditional reconstruction approaches, but they still struggle to provide
high-fidelity results. Diffusion models show great potential to improve
fidelity of generated images in recent years. However, their inference process
starting with a random Gaussian noise introduces instability into the results
and usually requires thousands of sampling steps, resulting in sub-optimal
reconstruction quality and low efficiency. To address these challenges, we
propose Cycle-Consistent Bridge Diffusion Model (CBDM). CBDM employs two bridge
diffusion models to construct a cycle-consistent diffusion process with a
consistency loss, enhancing the fine-grained details of reconstructed images
and reducing the number of diffusion steps. Moreover, CBDM incorporates a
Contourlet Decomposition Embedding Module (CDEM) which captures multi-scale
structural texture knowledge in images through frequency domain decomposition
pyramids and directional filter banks to improve structural fidelity. Extensive
experiments demonstrate the superiority of our model by higher reconstruction
quality and fewer training iterations, achieving a new state of the art for
accelerated MRI reconstruction in both fastMRI and IXI datasets.

摘要：加速式 MRI 重建技術旨在縮短檢查時間，同時維持高影像保真度，這在臨床環境中非常理想，可提升病患舒適度和醫院效率。現有的深度學習方法通常使用傳統重建方法從欠採樣數據重建影像，但仍難以提供高保真度結果。擴散模型在近年展現出提升生成影像保真度的絕佳潛力。然而，其從隨機高斯雜訊開始的推論過程會為結果帶來不穩定性，且通常需要數千個採樣步驟，導致次最佳重建品質和低效率。為了應對這些挑戰，我們提出循環一致橋接擴散模型 (CBDM)。CBDM 使用兩個橋接擴散模型，建構一個具有相容性損失的循環一致擴散過程，增強重建影像的精細細節並減少擴散步驟的數量。此外，CBDM 整合了一個輪廓分解嵌入模組 (CDEM)，透過頻域分解金字塔和方向濾波器組在影像中擷取多尺度結構紋理知識，以提升結構保真度。廣泛的實驗證明了我們模型的優異性，具有更高的重建品質和更少的訓練反覆運算，在 fastMRI 和 IXI 資料集的加速式 MRI 重建中達成新的技術水準。

##### **A Comparative Study of LLMs, NMT Models, and Their Combination in Persian-English Idiom Translation**
2412.09993v1 by Sara Rezaeimanesh, Faezeh Hosseini, Yadollah Yaghoobzadeh

Large language models (LLMs) have shown superior capabilities in translating
figurative language compared to neural machine translation (NMT) systems.
However, the impact of different prompting methods and LLM-NMT combinations on
idiom translation has yet to be thoroughly investigated. This paper introduces
two parallel datasets of sentences containing idiomatic expressions for
Persian$\rightarrow$English and English$\rightarrow$Persian translations, with
Persian idioms sampled from our PersianIdioms resource, a collection of 2,200
idioms and their meanings. Using these datasets, we evaluate various open- and
closed-source LLMs, NMT models, and their combinations. Translation quality is
assessed through idiom translation accuracy and fluency. We also find that
automatic evaluation methods like LLM-as-a-judge, BLEU and BERTScore are
effective for comparing different aspects of model performance. Our experiments
reveal that Claude-3.5-Sonnet delivers outstanding results in both translation
directions. For English$\rightarrow$Persian, combining weaker LLMs with Google
Translate improves results, while Persian$\rightarrow$English translations
benefit from single prompts for simpler models and complex prompts for advanced
ones.

摘要：大型語言模型 (LLM) 在翻譯比喻語言方面展現出比神經機器翻譯 (NMT) 系統更優越的能力。
然而，不同的提示方法和 LLM-NMT 組合對慣用語翻譯的影響尚未得到徹底研究。本文介紹了兩個包含慣用語句子的平行數據集，用於波斯語$\rightarrow$英語和英語$\rightarrow$波斯語翻譯，其中波斯語慣用語取樣自我們的 PersianIdioms 資源，該資源收集了 2,200 個慣用語及其含義。使用這些數據集，我們評估了各種開源和閉源 LLM、NMT 模型及其組合。翻譯品質通過慣用語翻譯準確度和流暢度進行評估。我們還發現，像 LLM-as-a-judge、BLEU 和 BERTScore 等自動評估方法對於比較模型效能的不同方面是有效的。我們的實驗表明，Claude-3.5-Sonnet 在兩個翻譯方向上都提供了傑出的結果。對於英語$\rightarrow$波斯語，將較弱的 LLM 與 Google Translate 結合起來可以改善結果，而波斯語$\rightarrow$英語翻譯則受益於較簡單模型的單一提示和較高級模型的複雜提示。

##### **Visual Object Tracking across Diverse Data Modalities: A Review**
2412.09991v1 by Mengmeng Wang, Teli Ma, Shuo Xin, Xiaojun Hou, Jiazheng Xing, Guang Dai, Jingdong Wang, Yong Liu

Visual Object Tracking (VOT) is an attractive and significant research area
in computer vision, which aims to recognize and track specific targets in video
sequences where the target objects are arbitrary and class-agnostic. The VOT
technology could be applied in various scenarios, processing data of diverse
modalities such as RGB, thermal infrared and point cloud. Besides, since no one
sensor could handle all the dynamic and varying environments, multi-modal VOT
is also investigated. This paper presents a comprehensive survey of the recent
progress of both single-modal and multi-modal VOT, especially the deep learning
methods. Specifically, we first review three types of mainstream single-modal
VOT, including RGB, thermal infrared and point cloud tracking. In particular,
we conclude four widely-used single-modal frameworks, abstracting their schemas
and categorizing the existing inheritors. Then we summarize four kinds of
multi-modal VOT, including RGB-Depth, RGB-Thermal, RGB-LiDAR and RGB-Language.
Moreover, the comparison results in plenty of VOT benchmarks of the discussed
modalities are presented. Finally, we provide recommendations and insightful
observations, inspiring the future development of this fast-growing literature.

摘要：視覺物件追蹤 (VOT) 是電腦視覺中一個有吸引力且重要的研究領域，其目標是識別並追蹤影片序列中特定的目標，其中目標物件是任意的且與類別無關。VOT 技術可應用於各種場景，處理各種模式的資料，例如 RGB、熱紅外線和點雲。此外，由於沒有任何一種感測器可以處理所有動態且多變的環境，因此多模式 VOT 也在研究中。本文提供了單模式和多模式 VOT 最近進展的全面調查，特別是深度學習方法。具體來說，我們首先回顧了三種類型的主流單模式 VOT，包括 RGB、熱紅外線和點雲追蹤。特別是，我們總結了四個廣泛使用的單模式架構，抽象其架構並分類現有的繼承者。然後，我們總結了四種類型的多模式 VOT，包括 RGB-深度、RGB-熱、RGB-LiDAR 和 RGB-語言。此外，還提供了在大量 VOT 基準中討論模式的比較結果。最後，我們提供了建議和有見地的觀察，激勵了這個快速成長的領域的未來發展。

##### **Small Language Model as Data Prospector for Large Language Model**
2412.09990v1 by Shiwen Ni, Haihong Wu, Di Yang, Qiang Qu, Hamid Alinejad-Rokny, Min Yang

The quality of instruction data directly affects the performance of
fine-tuned Large Language Models (LLMs). Previously, \cite{li2023one} proposed
\texttt{NUGGETS}, which identifies and selects high-quality quality data from a
large dataset by identifying those individual instruction examples that can
significantly improve the performance of different tasks after being learnt as
one-shot instances. In this work, we propose \texttt{SuperNUGGETS}, an improved
variant of \texttt{NUGGETS} optimised for efficiency and performance. Our
\texttt{SuperNUGGETS} uses a small language model (SLM) instead of a large
language model (LLM) to filter the data for outstanding one-shot instances and
refines the predefined set of tests. The experimental results show that the
performance of \texttt{SuperNUGGETS} only decreases by 1-2% compared to
\texttt{NUGGETS}, but the efficiency can be increased by a factor of 58.
Compared to the original \texttt{NUGGETS}, our \texttt{SuperNUGGETS} has a
higher utility value due to the significantly lower resource consumption.

摘要：教學資料的品質直接影響微調後的巨量語言模型 (LLM) 的效能。先前，\cite{li2023one} 提出 \texttt{NUGGETS}，它會從大型資料集中識別並選取高品質資料，方法是找出那些個別教學範例，在學習為一次性實例後，能大幅提升不同任務的效能。在這項工作中，我們提出 \texttt{SuperNUGGETS}，這是 \texttt{NUGGETS} 的改良版本，針對效率和效能進行了最佳化。我們的 \texttt{SuperNUGGETS} 使用小型語言模型 (SLM)，而非大型語言模型 (LLM)，來過濾資料以找出傑出的單次實例，並改善預先定義的測試集。實驗結果顯示，與 \texttt{NUGGETS} 相比，\texttt{SuperNUGGETS} 的效能僅下降 1-2%，但效率卻能提升 58 倍。與原始 \texttt{NUGGETS} 相比，我們的 \texttt{SuperNUGGETS} 具有更高的實用價值，因為資源消耗顯著降低。

##### **AI and the Future of Digital Public Squares**
2412.09988v1 by Beth Goldberg, Diana Acosta-Navas, Michiel Bakker, Ian Beacock, Matt Botvinick, Prateek Buch, Renée DiResta, Nandika Donthi, Nathanael Fast, Ravi Iyer, Zaria Jalan, Andrew Konya, Grace Kwak Danciu, Hélène Landemore, Alice Marwick, Carl Miller, Aviv Ovadya, Emily Saltz, Lisa Schirch, Dalit Shalom, Divya Siddarth, Felix Sieker, Christopher Small, Jonathan Stray, Audrey Tang, Michael Henry Tessler, Amy Zhang

Two substantial technological advances have reshaped the public square in
recent decades: first with the advent of the internet and second with the
recent introduction of large language models (LLMs). LLMs offer opportunities
for a paradigm shift towards more decentralized, participatory online spaces
that can be used to facilitate deliberative dialogues at scale, but also create
risks of exacerbating societal schisms. Here, we explore four applications of
LLMs to improve digital public squares: collective dialogue systems, bridging
systems, community moderation, and proof-of-humanity systems. Building on the
input from over 70 civil society experts and technologists, we argue that LLMs
both afford promising opportunities to shift the paradigm for conversations at
scale and pose distinct risks for digital public squares. We lay out an agenda
for future research and investments in AI that will strengthen digital public
squares and safeguard against potential misuses of AI.

摘要：近十年來，兩項重大的技術進步重塑了公共領域：首先是網際網路的出現，其次是最近引入的大型語言模型 (LLM)。LLM 為轉向更分散、更具參與性的線上空間提供了機會，可被用於促進大規模的審議對話，但也產生了加劇社會分裂的風險。在此，我們探討了 LLM 在改善數位公共領域的四種應用：集體對話系統、橋接系統、社群審核和人類證明系統。根據 70 多位公民社會專家和技術人員的意見，我們認為 LLM 既提供了轉變大規模對話典範的有希望機會，也對數位公共領域構成明確的風險。我們制定了一項未來研究和 AI 投資議程，將強化數位公共領域並防止 AI 遭到潛在的誤用。

##### **Efficient Large-Scale Traffic Forecasting with Transformers: A Spatial Data Management Perspective**
2412.09972v1 by Yuchen Fang, Yuxuan Liang, Bo Hui, Zezhi Shao, Liwei Deng, Xu Liu, Xinke Jiang, Kai Zheng

Road traffic forecasting is crucial in real-world intelligent transportation
scenarios like traffic dispatching and path planning in city management and
personal traveling. Spatio-temporal graph neural networks (STGNNs) stand out as
the mainstream solution in this task. Nevertheless, the quadratic complexity of
remarkable dynamic spatial modeling-based STGNNs has become the bottleneck over
large-scale traffic data. From the spatial data management perspective, we
present a novel Transformer framework called PatchSTG to efficiently and
dynamically model spatial dependencies for large-scale traffic forecasting with
interpretability and fidelity. Specifically, we design a novel irregular
spatial patching to reduce the number of points involved in the dynamic
calculation of Transformer. The irregular spatial patching first utilizes the
leaf K-dimensional tree (KDTree) to recursively partition irregularly
distributed traffic points into leaf nodes with a small capacity, and then
merges leaf nodes belonging to the same subtree into occupancy-equaled and
non-overlapped patches through padding and backtracking. Based on the patched
data, depth and breadth attention are used interchangeably in the encoder to
dynamically learn local and global spatial knowledge from points in a patch and
points with the same index of patches. Experimental results on four real world
large-scale traffic datasets show that our PatchSTG achieves train speed and
memory utilization improvements up to $10\times$ and $4\times$ with the
state-of-the-art performance.

摘要：道路交通預測在實際的智慧運輸場景中至關重要，例如城市管理和個人旅行中的交通調度和路徑規劃。時空圖神經網路 (STGNN) 成為這項任務的主流解決方案。然而，基於顯著動態空間建模的 STGNN 的二次複雜度已成為大規模交通數據的瓶頸。從空間數據管理的角度來看，我們提出一個名為 PatchSTG 的新型 Transformer 框架，以便有效且動態地對大規模交通預測建模空間依賴性，同時具備可解釋性和保真度。具體來說，我們設計了一個新穎的不規則空間修補，以減少 Transformer 動態計算中涉及的點數。不規則空間修補首先利用葉 K 維樹 (KDTree) 將不規則分佈的交通點遞迴分割成容量小的葉節點，然後透過填充和回溯將屬於相同子樹的葉節點合併成佔用相等且不重疊的修補程式。基於修補的數據，深度和廣度注意力在編碼器中互換使用，以動態地從修補程式中的點和具有相同修補程式索引的點中學習局部和全局空間知識。在四個真實世界的大規模交通數據集上的實驗結果表明，我們的 PatchSTG 在訓練速度和記憶體利用率方面分別提升了最先進的效能達 $10\times$ 和 $4\times$。

##### **EP-CFG: Energy-Preserving Classifier-Free Guidance**
2412.09966v1 by Kai Zhang, Fujun Luan, Sai Bi, Jianming Zhang

Classifier-free guidance (CFG) is widely used in diffusion models but often
introduces over-contrast and over-saturation artifacts at higher guidance
strengths. We present EP-CFG (Energy-Preserving Classifier-Free Guidance),
which addresses these issues by preserving the energy distribution of the
conditional prediction during the guidance process. Our method simply rescales
the energy of the guided output to match that of the conditional prediction at
each denoising step, with an optional robust variant for improved artifact
suppression. Through experiments, we show that EP-CFG maintains natural image
quality and preserves details across guidance strengths while retaining CFG's
semantic alignment benefits, all with minimal computational overhead.

摘要：無分類器引導 (CFG) 廣泛用於擴散模型，但通常會在較高的引導強度下引入過度對比和過度飽和的偽像。我們提出 EP-CFG（能量保留無分類器引導），它透過在引導過程中保留條件預測的能量分佈來解決這些問題。我們的模型僅僅在每個去噪步驟中重新調整引導輸出的能量，以匹配條件預測的能量，並提供一個可選的穩健變體以改善偽像抑制。透過實驗，我們證明 EP-CFG 能夠在保持 CFG 的語義對齊優勢的同時，在所有引導強度下維持自然影像品質和保留細節，且計算量開銷極小。

##### **Romanized to Native Malayalam Script Transliteration Using an Encoder-Decoder Framework**
2412.09957v1 by Bajiyo Baiju, Kavya Manohar, Leena G Pillai, Elizabeth Sherly

In this work, we present the development of a reverse transliteration model
to convert romanized Malayalam to native script using an encoder-decoder
framework built with attention-based bidirectional Long Short Term Memory
(Bi-LSTM) architecture. To train the model, we have used curated and combined
collection of 4.3 million transliteration pairs derived from publicly available
Indic language translitertion datasets, Dakshina and Aksharantar. We evaluated
the model on two different test dataset provided by IndoNLP-2025-Shared-Task
that contain, (1) General typing patterns and (2) Adhoc typing patterns,
respectively. On the Test Set-1, we obtained a character error rate (CER) of
7.4%. However upon Test Set-2, with adhoc typing patterns, where most vowel
indicators are missing, our model gave a CER of 22.7%.

摘要：在這項工作中，我們展示了一個反轉音譯模型的開發，使用一個建構於基於注意力的雙向長短期記憶 (Bi-LSTM) 架構的編碼器-解碼器框架，將羅馬化的馬拉雅拉姆語轉換成原生文字。為了訓練模型，我們使用了一個由公開的印度語言轉寫資料集 Dakshina 和 Aksharantar 中衍生的 430 萬個轉寫對的精選和組合集合。我們在 IndoNLP-2025-Shared-Task 提供的兩個不同的測試資料集上評估了模型，分別包含 (1) 一般輸入模式和 (2) 特殊輸入模式。在測試集 1 上，我們獲得了 7.4% 的字元錯誤率 (CER)。然而在測試集 2 上，在特殊輸入模式中，大多數的元音指示符號都遺失，我們的模型給出了 22.7% 的 CER。

##### **Enhancing Nursing and Elderly Care with Large Language Models: An AI-Driven Framework**
2412.09946v1 by Qiao Sun, Jiexin Xie, Nanyang Ye, Qinying Gu, Shijie Guo

This paper explores the application of large language models (LLMs) in
nursing and elderly care, focusing on AI-driven patient monitoring and
interaction. We introduce a novel Chinese nursing dataset and implement
incremental pre-training (IPT) and supervised fine-tuning (SFT) techniques to
enhance LLM performance in specialized tasks. Using LangChain, we develop a
dynamic nursing assistant capable of real-time care and personalized
interventions. Experimental results demonstrate significant improvements,
paving the way for AI-driven solutions to meet the growing demands of
healthcare in aging populations.

摘要：本文探討大型語言模型 (LLM) 在護理和老年照護中的應用，重點在於 AI 驅動的病人監控和互動。我們引入了一個新穎的中文護理資料集，並實施增量預訓練 (IPT) 和監督微調 (SFT) 技術，以增強 LLM 在專業任務中的表現。使用 LangChain，我們開發了一個動態護理助理，能夠提供即時照護和個人化干預措施。實驗結果證明了顯著的改進，為 AI 驅動的解決方案鋪平了道路，以滿足老齡化人口對醫療保健日益增長的需求。

##### **Low-Resource Fast Text Classification Based on Intra-Class and Inter-Class Distance Calculation**
2412.09922v1 by Yanxu Mao, Peipei Liu, Tiehan Cui, Congying Liu, Datao You

In recent years, text classification methods based on neural networks and
pre-trained models have gained increasing attention and demonstrated excellent
performance. However, these methods still have some limitations in practical
applications: (1) They typically focus only on the matching similarity between
sentences. However, there exists implicit high-value information both within
sentences of the same class and across different classes, which is very crucial
for classification tasks. (2) Existing methods such as pre-trained language
models and graph-based approaches often consume substantial memory for training
and text-graph construction. (3) Although some low-resource methods can achieve
good performance, they often suffer from excessively long processing times. To
address these challenges, we propose a low-resource and fast text
classification model called LFTC. Our approach begins by constructing a
compressor list for each class to fully mine the regularity information within
intra-class data. We then remove redundant information irrelevant to the target
classification to reduce processing time. Finally, we compute the similarity
distance between text pairs for classification. We evaluate LFTC on 9 publicly
available benchmark datasets, and the results demonstrate significant
improvements in performance and processing time, especially under limited
computational and data resources, highlighting its superior advantages.

摘要：近年来，基于神经网络和预训练模型的文本分类方法越来越受到关注，并表现出优异的性能。然而，这些方法在实际应用中仍然存在一些局限性：(1) 它们通常只关注句子之间的匹配相似性。然而，同类句子内部和不同类句子之间都存在隐含的高价值信息，这对分类任务至关重要。(2) 预训练语言模型和基于图的方法等现有方法通常需要大量的内存用于训练和文本图构建。(3) 虽然一些低资源方法可以达到良好的性能，但它们通常处理时间过长。为了应对这些挑战，我们提出了一种低资源且快速的文本分类模型，称为 LFTC。我们的方法首先为每个类别构建一个压缩器列表，以充分挖掘类内数据中的规律性信息。然后，我们删除与目标分类无关的冗余信息，以减少处理时间。最后，我们计算文本对之间的相似性距离进行分类。我们在 9 个公开的基准数据集上评估了 LFTC，结果表明在有限的计算和数据资源下，其性能和处理时间都有显著提升，突出了其优越的优势。

##### **B-VLLM: A Vision Large Language Model with Balanced Spatio-Temporal Tokens**
2412.09919v1 by Zhuqiang Lu, Zhenfei Yin, Mengwei He, Zhihui Wang, Zicheng Liu, Zhiyong Wang, Kun Hu

Recently, Vision Large Language Models (VLLMs) integrated with vision
encoders have shown promising performance in vision understanding. The key of
VLLMs is to encode visual content into sequences of visual tokens, enabling
VLLMs to simultaneously process both visual and textual content. However,
understanding videos, especially long videos, remain a challenge to VLLMs as
the number of visual tokens grows rapidly when encoding videos, resulting in
the risk of exceeding the context window of VLLMs and introducing heavy
computation burden. To restrict the number of visual tokens, existing VLLMs
either: (1) uniformly downsample videos into a fixed number of frames or (2)
reducing the number of visual tokens encoded from each frame. We argue the
former solution neglects the rich temporal cue in videos and the later
overlooks the spatial details in each frame. In this work, we present
Balanced-VLLM (B-VLLM): a novel VLLM framework that aims to effectively
leverage task relevant spatio-temporal cues while restricting the number of
visual tokens under the VLLM context window length. At the core of our method,
we devise a text-conditioned adaptive frame selection module to identify frames
relevant to the visual understanding task. The selected frames are then
de-duplicated using a temporal frame token merging technique. The visual tokens
of the selected frames are processed through a spatial token sampling module
and an optional spatial token merging strategy to achieve precise control over
the token count. Experimental results show that B-VLLM is effective in
balancing the number of frames and visual tokens in video understanding,
yielding superior performance on various video understanding benchmarks. Our
code is available at https://github.com/zhuqiangLu/B-VLLM.

摘要：<paragraph>最近，结合视觉编码器的视觉大型语言模型 (VLLM) 在视觉理解中展现了令人满意的性能。VLLM 的关键在于将视觉内容编码成视觉标记序列，让 VLLM 能够同时处理视觉和文本内容。然而，理解视频，尤其是长视频，对于 VLLM 来说仍然是一个挑战，因为在对视频进行编码时，视觉标记的数量会迅速增长，从而导致超出 VLLM 的上下文窗口并带来沉重的计算负担的风险。为了限制视觉标记的数量，现有的 VLLM 要么：(1) 将视频均匀降采样成固定数量的帧，要么：(2) 减少从每帧编码的视觉标记数量。我们认为前一种解决方案忽略了视频中丰富的时序线索，而后一种解决方案忽略了每帧中的空间细节。在这项工作中，我们提出了平衡 VLLM (B-VLLM)：一种新颖的 VLLM 框架，旨在有效利用与任务相关的时空线索，同时限制 VLLM 上下文窗口长度下的视觉标记数量。在我们的方法的核心，我们设计了一个文本条件自适应帧选择模块来识别与视觉理解任务相关的帧。然后使用时序帧标记合并技术对选定的帧进行去重处理。选定帧的视觉标记通过空间标记采样模块和可选的空间标记合并策略进行处理，以实现对标记计数的精确控制。实验结果表明，B-VLLM 在平衡视频理解中的帧数和视觉标记数量方面是有效的，在各种视频理解基准上产生了更优异的性能。我们的代码可在 https://github.com/zhuqiangLu/B-VLLM 获得。</paragraph>

##### **Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning**
2412.09906v1 by Jing Bi, Yuting Wu, Weiwei Xing, Zhenjie Wei

Large language models (LLMs) have demonstrated remarkable performance across
a wide range of tasks. Advances in prompt engineering and fine-tuning
techniques have further enhanced their ability to address complex reasoning
challenges. However, these advanced capabilities are often exclusive to models
exceeding 100 billion parameters. Although Chain-of-Thought (CoT) fine-tuning
methods have been explored for smaller models (under 10 billion parameters),
they typically depend on extensive CoT training data, which can introduce
inconsistencies and limit effectiveness in low-data settings. To overcome these
limitations, this paper introduce a new reasoning strategy Solution Guidance
(SG) and a plug-and-play training paradigm Solution-Guidance Fine-Tuning (SGFT)
for enhancing the reasoning capabilities of small language models. SG focuses
on problem understanding and decomposition at the semantic and logical levels,
rather than specific computations, which can effectively improve the SLMs'
generalization and reasoning abilities. With only a small amount of SG training
data, SGFT can fine-tune a SLM to produce accurate problem-solving guidances,
which can then be flexibly fed to any SLM as prompts, enabling it to generate
correct answers directly. Experimental results demonstrate that our method
significantly improves the performance of SLMs on various reasoning tasks,
enhancing both their practicality and efficiency within resource-constrained
environments.

摘要：大型語言模型 (LLM) 已在廣泛的任務中展現出卓越的效能。提示工程和微調技術的進展進一步提升了它們處理複雜推理挑戰的能力。然而，這些進階功能通常專屬於超過 1000 億個參數的模型。儘管已針對較小模型（小於 100 億個參數）探索思維鏈 (CoT) 微調方法，但它們通常依賴於大量的 CoT 訓練資料，這可能會在資料量少的情況下造成不一致性並限制效能。為了克服這些限制，本文介紹了一種新的推理策略「解決方案指導」(SG) 和一種即插即用訓練範例「解決方案指導微調」(SGFT)，用於增強小型語言模型的推理能力。SG 專注於語意和邏輯層面的問題理解和分解，而非特定運算，這可以有效提升 SLM 的概化和推理能力。SGFT 僅需少量的 SG 訓練資料，就能微調 SLM 以產生準確的解決問題指導，然後可以靈活地將其提供給任何 SLM 作為提示，使其能夠直接產生正確的答案。實驗結果表明，我們的模型顯著提升了 SLM 在各種推理任務中的效能，在資源受限的環境中提升了其實用性和效率。

##### **Analyzing Fairness of Computer Vision and Natural Language Processing Models**
2412.09900v1 by Ahmed Rashed, Abdelkrim Kallich, Mohamed Eltayeb

Machine learning (ML) algorithms play a crucial role in decision making
across diverse fields such as healthcare, finance, education, and law
enforcement. Despite their widespread adoption, these systems raise ethical and
social concerns due to potential biases and fairness issues. This study focuses
on evaluating and improving the fairness of Computer Vision and Natural
Language Processing (NLP) models applied to unstructured datasets, emphasizing
how biased predictions can reinforce existing systemic inequalities. A publicly
available dataset from Kaggle was utilized to simulate a practical scenario for
examining fairness in ML workflows. To address and mitigate biases, the study
employed two leading fairness libraries: Fairlearn by Microsoft, and AIF360 by
IBM. These tools offer comprehensive frameworks for fairness analysis,
including metrics evaluation, result visualization, and bias mitigation
techniques. The research aims to measure bias levels in ML models, compare the
effectiveness of these fairness libraries, and provide actionable
recommendations for practitioners. The results demonstrate that each library
possesses distinct strengths and limitations in evaluating and mitigating
fairness. By systematically analyzing these tools, the study contributes
valuable insights to the growing field of ML fairness, offering practical
guidance for integrating fairness solutions into real world applications. This
research underscores the importance of building more equitable and responsible
machine learning systems.

摘要：機器學習 (ML) 演算法在醫療保健、金融、教育和執法等不同領域的決策制定中扮演著至關重要的角色。儘管這些系統被廣泛採用，但由於潛在的偏見和公平性問題，這些系統引發了倫理和社會問題。本研究重點在於評估和改善應用於非結構化資料集的電腦視覺和自然語言處理 (NLP) 模型的公平性，強調有偏見的預測如何加劇現有的系統性不平等。利用 Kaggle 上公開提供的資料集來模擬實際場景，以檢視 ML 工作流程中的公平性。為了解決和減輕偏見，本研究採用了兩個領先的公平性函式庫：Microsoft 的 Fairlearn 和 IBM 的 AIF360。這些工具提供了全面的公平性分析架構，包括指標評估、結果視覺化和偏見緩解技術。本研究旨在衡量 ML 模型中的偏見程度，比較這些公平性函式庫的有效性，並為從業人員提供可行的建議。結果表明，每個函式庫在評估和減輕公平性方面都具有不同的優勢和限制。透過系統性地分析這些工具，本研究為 ML 公平性這個不斷發展的領域做出了寶貴的見解，為將公平性解決方案整合到實際應用中提供了實用的指導。本研究強調了建構更公平、更負責任的機器學習系統的重要性。

##### **Analyzing Fairness of Classification Machine Learning Model with Structured Dataset**
2412.09896v1 by Ahmed Rashed, Abdelkrim Kallich, Mohamed Eltayeb

Machine learning (ML) algorithms have become integral to decision making in
various domains, including healthcare, finance, education, and law enforcement.
However, concerns about fairness and bias in these systems pose significant
ethical and social challenges. This study investigates the fairness of ML
models applied to structured datasets in classification tasks, highlighting the
potential for biased predictions to perpetuate systemic inequalities. A
publicly available dataset from Kaggle was selected for analysis, offering a
realistic scenario for evaluating fairness in machine learning workflows.
  To assess and mitigate biases, three prominent fairness libraries; Fairlearn
by Microsoft, AIF360 by IBM, and the What If Tool by Google were employed.
These libraries provide robust frameworks for analyzing fairness, offering
tools to evaluate metrics, visualize results, and implement bias mitigation
strategies. The research aims to assess the extent of bias in the ML models,
compare the effectiveness of these libraries, and derive actionable insights
for practitioners.
  The findings reveal that each library has unique strengths and limitations in
fairness evaluation and mitigation. By systematically comparing their
capabilities, this study contributes to the growing field of ML fairness by
providing practical guidance for integrating fairness tools into real world
applications. These insights are intended to support the development of more
equitable machine learning systems.

摘要：機器學習 (ML) 演算法已成為各個領域（包括醫療保健、金融、教育和執法）決策中不可或缺的一部分。
然而，對於這些系統中公平性和偏差的疑慮，帶來了重大的倫理和社會挑戰。本研究探討了 ML 模型在分類任務中應用於結構化資料集的公平性，強調了有偏差的預測可能使系統性不平等永續化的潛力。我們選擇了 Kaggle 上一個公開可用的資料集進行分析，提供了評估機器學習工作流程中公平性的實際情境。
為了評估和減輕偏差，我們使用了三個著名的公平性函式庫：Microsoft 的 Fairlearn、IBM 的 AIF360 和 Google 的 What If Tool。這些函式庫提供了強大的框架來分析公平性，提供了用於評估指標、視覺化結果和實作偏差減緩策略的工具。這項研究旨在評估 ML 模型中偏差的程度，比較這些函式庫的有效性，並為從業人員得出可行的見解。
研究結果顯示，每個函式庫在公平性評估和減緩方面都有其獨特的優點和缺點。透過系統性地比較它們的能力，本研究透過提供將公平性工具整合到實際應用中的實務指南，為 ML 公平性這個不斷成長的領域做出貢獻。這些見解旨在支援開發更公平的機器學習系統。

##### **Semi-Periodic Activation for Time Series Classification**
2412.09889v1 by José Gilberto Barbosa de Medeiros Júnior, Andre Guarnier de Mitri, Diego Furtado Silva

This paper investigates the lack of research on activation functions for
neural network models in time series tasks. It highlights the need to identify
essential properties of these activations to improve their effectiveness in
specific domains. To this end, the study comprehensively analyzes properties,
such as bounded, monotonic, nonlinearity, and periodicity, for activation in
time series neural networks. We propose a new activation that maximizes the
coverage of these properties, called LeakySineLU. We empirically evaluate the
LeakySineLU against commonly used activations in the literature using 112
benchmark datasets for time series classification, obtaining the best average
ranking in all comparative scenarios.

摘要：這篇論文探討時間序列任務中神經網路模型的激活函數研究不足的問題。它強調了識別這些激活函數基本特性的必要性，以提高它們在特定領域的有效性。為此，本研究全面分析了時間序列神經網路中激活函數的性質，例如有界、單調、非線性和週期性。我們提出了一個新的激活函數 LeakySineLU，它最大化了這些性質的覆蓋範圍。我們使用 112 個時間序列分類基準資料集，根據文獻中常用的激活函數對 LeakySineLU 進行實證評估，在所有比較情境中獲得最佳平均排名。

##### **CSL-L2M: Controllable Song-Level Lyric-to-Melody Generation Based on Conditional Transformer with Fine-Grained Lyric and Musical Controls**
2412.09887v1 by Li Chai, Donglin Wang

Lyric-to-melody generation is a highly challenging task in the field of AI
music generation. Due to the difficulty of learning strict yet weak
correlations between lyrics and melodies, previous methods have suffered from
weak controllability, low-quality and poorly structured generation. To address
these challenges, we propose CSL-L2M, a controllable song-level lyric-to-melody
generation method based on an in-attention Transformer decoder with
fine-grained lyric and musical controls, which is able to generate full-song
melodies matched with the given lyrics and user-specified musical attributes.
Specifically, we first introduce REMI-Aligned, a novel music representation
that incorporates strict syllable- and sentence-level alignments between lyrics
and melodies, facilitating precise alignment modeling. Subsequently,
sentence-level semantic lyric embeddings independently extracted from a
sentence-wise Transformer encoder are combined with word-level part-of-speech
embeddings and syllable-level tone embeddings as fine-grained controls to
enhance the controllability of lyrics over melody generation. Then we introduce
human-labeled musical tags, sentence-level statistical musical attributes, and
learned musical features extracted from a pre-trained VQ-VAE as coarse-grained,
fine-grained and high-fidelity controls, respectively, to the generation
process, thereby enabling user control over melody generation. Finally, an
in-attention Transformer decoder technique is leveraged to exert fine-grained
control over the full-song melody generation with the aforementioned lyric and
musical conditions. Experimental results demonstrate that our proposed CSL-L2M
outperforms the state-of-the-art models, generating melodies with higher
quality, better controllability and enhanced structure. Demos and source code
are available at https://lichaiustc.github.io/CSL-L2M/.

摘要：歌詞轉旋律生成是 AI 音樂生成領域中極具挑戰性的任務。由於難以學習歌詞和旋律之間嚴格但薄弱的相關性，以前的生成方法一直飽受可控性差、品質低落且結構不良的困擾。為了應對這些挑戰，我們提出了 CSL-L2M，這是一種可控的歌曲級歌詞轉旋律生成方法，它基於帶有細粒度歌詞和音樂控制的非注意力 Transformer 解碼器，能夠生成與給定歌詞和使用者指定的音樂屬性相匹配的全曲旋律。具體來說，我們首先介紹 REMI-Aligned，這是一種新穎的音樂表示，它結合了歌詞和旋律之間嚴格的音節和句子級別對齊，促進了精確對齊建模。隨後，從句子級 Transformer 編碼器中獨立提取的句子級語義歌詞嵌入與詞級詞性嵌入和音節級音調嵌入相結合，作為細粒度控制，以增強歌詞對旋律生成的控制力。然後，我們在生成過程中分別將人工標記的音樂標籤、句子級統計音樂屬性以及從預訓練的 VQ-VAE 中提取的學習音樂特徵引入為粗粒度、細粒度和高保真控制，從而使用戶能夠控制旋律生成。最後，利用非注意力 Transformer 解碼器技術，對全曲旋律生成施加細粒度控制，並具備上述歌詞和音樂條件。實驗結果表明，我們提出的 CSL-L2M 優於最先進的模型，生成的旋律具有更高的品質、更好的可控性以及增強的結構。展示和源代碼可在 https://lichaiustc.github.io/CSL-L2M/ 獲得。

##### **Benchmarking Table Comprehension In The Wild**
2412.09884v1 by Yikang Pan, Yi Zhu, Rand Xie, Yizhi Liu

Large Language Models (LLMs), while being increasingly dominant on a myriad
of knowledge-intensive activities, have only had limited success understanding
lengthy table-text mixtures, such as academic papers and financial reports.
Recent advances of long-context LLMs have opened up new possibilities for this
field. Nonetheless, we identify two roadblocks: (1) Prior benchmarks of table
question answering (TableQA) have focused on isolated tables without context,
making it hard to evaluate models in real-world scenarios. (2) Prior benchmarks
have focused on some narrow skill sets of table comprehension such as table
recognition, data manipulation/calculation, table summarization etc., while a
skilled human employs those skills collectively. In this work, we introduce
TableQuest, a new benchmark designed to evaluate the holistic table
comprehension capabilities of LLMs in the natural table-rich context of
financial reports. We employ a rigorous data processing and filtering procedure
to ensure that the question-answer pairs are logical, reasonable, and diverse.
We experiment with 7 state-of-the-art models, and find that despite reasonable
accuracy in locating facts, they often falter when required to execute more
sophisticated reasoning or multi-step calculations. We conclude with a
qualitative study of the failure modes and discuss the challenges of
constructing a challenging benchmark. We make the evaluation data, judging
procedure and results of this study publicly available to facilitate research
in this field.

摘要：大型語言模型 (LLM) 儘管在各種知識密集活動中越來越佔主導地位，但在理解冗長的表格文字混合物（例如學術論文和財務報告）方面卻僅獲得有限的成功。長語境 LLM 的最新進展為這個領域開啟了新的可能性。儘管如此，我們發現了兩個障礙：(1) 先前的表格問題回答 (TableQA) 基準側重於沒有語境的孤立表格，這使得在真實世界場景中評估模型變得困難。(2) 先前的基準側重於表格理解的一些狹窄技能，例如表格識別、數據處理/計算、表格摘要等，而熟練的人員會綜合運用這些技能。在這項工作中，我們介紹了 TableQuest，這是一個新的基準，旨在評估 LLM 在財務報告的自然表格豐富語境中的整體表格理解能力。我們採用嚴格的數據處理和過濾程序，以確保問題答案對具有邏輯性、合理性和多樣性。我們使用 7 個最先進的模型進行實驗，發現儘管在定位事實方面具有合理的準確性，但它們在需要執行更複雜的推理或多步驟計算時常常會失敗。我們以失敗模式的定性研究作為結論，並討論了構建具有挑戰性的基準的挑戰。我們公開評估數據、評審程序和本研究的結果，以促進該領域的研究。

##### **On the Limit of Language Models as Planning Formalizers**
2412.09879v1 by Cassie Huang, Li Zhang

Large Language Models have been shown to fail to create executable and
verifiable plans in grounded environments. An emerging line of work shows
success in using LLM as a formalizer to generate a formal representation (e.g.,
PDDL) of the planning domain, which can be deterministically solved to find a
plan. We systematically evaluate this methodology while bridging some major
gaps. While previous work only generates a partial PDDL representation given
templated and thus unrealistic environment descriptions, we generate the
complete representation given descriptions of various naturalness levels. Among
an array of observations critical to improve LLMs' formal planning ability, we
note that large enough models can effectively formalize descriptions as PDDL,
outperforming those directly generating plans, while being robust to lexical
perturbation. As the descriptions become more natural-sounding, we observe a
decrease in performance and provide detailed error analysis.

摘要：大型語言模型已被證明無法在接地的環境中建立可執行和可驗證的計畫。新興的工作路線顯示，使用 LLM 作為形式化器來產生規劃領域的形式化表示（例如，PDDL）是成功的，該表示可以確定性地求解以找到一個計畫。我們系統性地評估此方法，同時彌合一些主要差距。雖然先前的工作只產生部分 PDDL 表示，給定模板化且不切實際的環境描述，但我們產生了給定各種自然程度描述的完整表示。在改進 LLM 形式化規劃能力的眾多觀察中，我們注意到足夠大的模型可以有效地將描述形式化為 PDDL，優於直接產生計畫的模型，同時對詞彙擾動具有魯棒性。隨著描述變得更自然，我們觀察到性能下降並提供詳細的錯誤分析。

##### **Byte Latent Transformer: Patches Scale Better Than Tokens**
2412.09871v1 by Artidoro Pagnoni, Ram Pasunuru, Pedro Rodriguez, John Nguyen, Benjamin Muller, Margaret Li, Chunting Zhou, Lili Yu, Jason Weston, Luke Zettlemoyer, Gargi Ghosh, Mike Lewis, Ari Holtzman, Srinivasan Iyer

We introduce the Byte Latent Transformer (BLT), a new byte-level LLM
architecture that, for the first time, matches tokenization-based LLM
performance at scale with significant improvements in inference efficiency and
robustness. BLT encodes bytes into dynamically sized patches, which serve as
the primary units of computation. Patches are segmented based on the entropy of
the next byte, allocating more compute and model capacity where increased data
complexity demands it. We present the first FLOP controlled scaling study of
byte-level models up to 8B parameters and 4T training bytes. Our results
demonstrate the feasibility of scaling models trained on raw bytes without a
fixed vocabulary. Both training and inference efficiency improve due to
dynamically selecting long patches when data is predictable, along with
qualitative improvements on reasoning and long tail generalization. Overall,
for fixed inference costs, BLT shows significantly better scaling than
tokenization-based models, by simultaneously growing both patch and model size.

摘要：我們介紹 Byte Latent Transformer (BLT)，這是一種新的位元組級別 LLM 架構，它首次以顯著提升的推論效率和穩健性，匹配了基於標記化的 LLM 的規模化效能。BLT 將位元組編碼成動態大小的區塊，作為運算的主要單位。區塊根據下一個位元組的熵進行分割，在增加的資料複雜度需要時，分配更多運算和模型容量。我們提供了第一個 FLOP 控制的位元組級別模型擴充研究，參數高達 8B，訓練位元組高達 4T。我們的結果證明了在沒有固定詞彙表的情況下，擴充在原始位元組上訓練的模型的可行性。由於在資料可預測時動態選擇長區塊，以及在推理和長尾概括上的質化改進，訓練和推論效率都有所提升。總體而言，對於固定的推論成本，BLT 透過同時增加區塊和模型大小，展現出比基於標記化的模型顯著更好的擴充。

##### **Financial Sentiment Analysis: Leveraging Actual and Synthetic Data for Supervised Fine-tuning**
2412.09859v1 by Abraham Atsiwo

The Efficient Market Hypothesis (EMH) highlights the essence of financial
news in stock price movement. Financial news comes in the form of corporate
announcements, news titles, and other forms of digital text. The generation of
insights from financial news can be done with sentiment analysis.
General-purpose language models are too general for sentiment analysis in
finance. Curated labeled data for fine-tuning general-purpose language models
are scare, and existing fine-tuned models for sentiment analysis in finance do
not capture the maximum context width. We hypothesize that using actual and
synthetic data can improve performance. We introduce BertNSP-finance to
concatenate shorter financial sentences into longer financial sentences, and
finbert-lc to determine sentiment from digital text. The results show improved
performance on the accuracy and the f1 score for the financial phrasebank data
with $50\%$ and $100\%$ agreement levels.

摘要：有效市場假設 (EMH) 強調了財經新聞在股價變動中的精髓。財經新聞以公司公告、新聞標題和其他形式的數位文字呈現。從財經新聞中產生見解可以使用情緒分析來完成。
通用語言模型對於財務中的情緒分析來說過於通用。用於微調通用語言模型的精選標籤數據很稀少，而現有的用於財務情緒分析的微調模型無法捕捉最大的上下文寬度。我們假設使用實際和合成數據可以提高性能。我們引入 BertNSP-finance 將較短的財務句子串聯成較長的財務句子，以及 finbert-lc 從數位文字中確定情緒。結果顯示在準確性和 f1 分數上改進了財務詞彙庫數據的表現，同意程度為 50% 和 100%。

##### **RLDG: Robotic Generalist Policy Distillation via Reinforcement Learning**
2412.09858v1 by Charles Xu, Qiyang Li, Jianlan Luo, Sergey Levine

Recent advances in robotic foundation models have enabled the development of
generalist policies that can adapt to diverse tasks. While these models show
impressive flexibility, their performance heavily depends on the quality of
their training data. In this work, we propose Reinforcement Learning Distilled
Generalists (RLDG), a method that leverages reinforcement learning to generate
high-quality training data for finetuning generalist policies. Through
extensive real-world experiments on precise manipulation tasks like connector
insertion and assembly, we demonstrate that generalist policies trained with
RL-generated data consistently outperform those trained with human
demonstrations, achieving up to 40% higher success rates while generalizing
better to new tasks. We also provide a detailed analysis that reveals this
performance gain stems from both optimized action distributions and improved
state coverage. Our results suggest that combining task-specific RL with
generalist policy distillation offers a promising approach for developing more
capable and efficient robotic manipulation systems that maintain the
flexibility of foundation models while achieving the performance of specialized
controllers. Videos and code can be found on our project website
https://generalist-distillation.github.io

摘要：機器人基礎模型的最新進展已能開發出適應各種任務的通才策略。儘管這些模型展現出令人印象深刻的靈活性，但其效能卻高度依賴於訓練資料的品質。在這項工作中，我們提出強化學習蒸餾通才 (RLDG)，這是一種運用強化學習來產生高品質訓練資料以微調通才策略的方法。透過針對精準操作任務（如連接器插入和組裝）進行廣泛的實際實驗，我們證明使用 RL 生成的資料訓練出的通才策略，其效能始終優於使用人類示範訓練出的策略，在推廣到新任務時可將成功率提高多達 40%。我們也提供詳細分析，揭示這種效能提升來自於最佳化的動作分配和改善的狀態覆蓋率。我們的結果表明，將特定任務的 RL 與通才策略蒸餾結合，為開發更強大、更有效率的機器人操作系統提供了一種有前途的方法，這種系統在維持基礎模型的靈活性的同時，也能達到專用控制器的效能。可以在我們的專案網站 https://generalist-distillation.github.io 找到影片和程式碼

##### **LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity**
2412.09856v1 by Hongjie Wang, Chih-Yao Ma, Yen-Cheng Liu, Ji Hou, Tao Xu, Jialiang Wang, Felix Juefei-Xu, Yaqiao Luo, Peizhao Zhang, Tingbo Hou, Peter Vajda, Niraj K. Jha, Xiaoliang Dai

Text-to-video generation enhances content creation but is highly
computationally intensive: The computational cost of Diffusion Transformers
(DiTs) scales quadratically in the number of pixels. This makes minute-length
video generation extremely expensive, limiting most existing models to
generating videos of only 10-20 seconds length. We propose a Linear-complexity
text-to-video Generation (LinGen) framework whose cost scales linearly in the
number of pixels. For the first time, LinGen enables high-resolution
minute-length video generation on a single GPU without compromising quality. It
replaces the computationally-dominant and quadratic-complexity block,
self-attention, with a linear-complexity block called MATE, which consists of
an MA-branch and a TE-branch. The MA-branch targets short-to-long-range
correlations, combining a bidirectional Mamba2 block with our token
rearrangement method, Rotary Major Scan, and our review tokens developed for
long video generation. The TE-branch is a novel TEmporal Swin Attention block
that focuses on temporal correlations between adjacent tokens and medium-range
tokens. The MATE block addresses the adjacency preservation issue of Mamba and
improves the consistency of generated videos significantly. Experimental
results show that LinGen outperforms DiT (with a 75.6% win rate) in video
quality with up to 15$\times$ (11.5$\times$) FLOPs (latency) reduction.
Furthermore, both automatic metrics and human evaluation demonstrate our
LinGen-4B yields comparable video quality to state-of-the-art models (with a
50.5%, 52.1%, 49.1% win rate with respect to Gen-3, LumaLabs, and Kling,
respectively). This paves the way to hour-length movie generation and real-time
interactive video generation. We provide 68s video generation results and more
examples in our project website: https://lineargen.github.io/.

摘要：文本到影片生成會增強內容創作，但計算成本極高：擴散式Transformer (DiT) 的計算成本會隨著像素數平方增加。這使得影片生成極為昂貴，限制大多數現有模型只能產生長度僅 10-20 秒的影片。我們提出一個線性複雜度文本到影片生成 (LinGen) 架構，其成本會隨著像素數線性增加。LinGen 首次在單一 GPU 上實現高解析度分鐘長度影片生成，且不損害品質。它使用線性複雜度區塊 MATE 取代計算量龐大且複雜度為平方的自注意力區塊，MATE 包含 MA 分支和 TE 分支。MA 分支鎖定短距離到長距離關聯，結合雙向 Mamba2 區塊與我們的代幣重新排列方法、旋轉主掃描，以及我們針對長影片生成所開發的審查代幣。TE 分支是一種新穎的時序 Swin 注意力區塊，專注於相鄰代幣和中距離代幣之間的時序關聯。MATE 區塊解決了 Mamba 的鄰接保留問題，並大幅改善生成影片的一致性。實驗結果顯示，LinGen 在影片品質上優於 DiT（勝率 75.6%），且 FLOP（延遲）減少多達 15 倍（11.5 倍）。此外，自動指標和人為評估都證明我們的 LinGen-4B 產生與最先進模型相當的影片品質（與 Gen-3、LumaLabs 和 Kling 相比，勝率分別為 50.5%、52.1%、49.1%）。這為小時長度電影生成和即時互動影片生成鋪路。我們在專案網站中提供 68 秒影片生成結果和更多範例：https://lineargen.github.io/。

##### **Learning Structural Causal Models from Ordering: Identifiable Flow Models**
2412.09843v1 by Minh Khoa Le, Kien Do, Truyen Tran

In this study, we address causal inference when only observational data and a
valid causal ordering from the causal graph are available. We introduce a set
of flow models that can recover component-wise, invertible transformation of
exogenous variables. Our flow-based methods offer flexible model design while
maintaining causal consistency regardless of the number of discretization
steps. We propose design improvements that enable simultaneous learning of all
causal mechanisms and reduce abduction and prediction complexity to linear O(n)
relative to the number of layers, independent of the number of causal
variables. Empirically, we demonstrate that our method outperforms previous
state-of-the-art approaches and delivers consistent performance across a wide
range of structural causal models in answering observational, interventional,
and counterfactual questions. Additionally, our method achieves a significant
reduction in computational time compared to existing diffusion-based
techniques, making it practical for large structural causal models.

摘要：在這個研究中，我們在只有觀察資料和因果圖中有效的因果順序時，探討因果推論。我們介紹了一組流動模型，可以恢復外生變數的組成部分、可逆轉換。我們的基於流動的方法提供了靈活的模型設計，同時無論離散化步驟的數量如何，都能維持因果一致性。我們提出了設計改進，能夠同時學習所有因果機制，並將外推和預測複雜度降低為線性 O(n)，相對於層數，與因果變數的數量無關。根據經驗，我們證明了我們的方法優於先前的最先進方法，並且在回答觀察、介入和反事實問題時，在各種結構因果模型中提供了穩定的效能。此外，與現有的基於擴散的技術相比，我們的方法在計算時間上實現了顯著的減少，這使得它適用於大型結構因果模型。

##### **Low-Rank Adaptation with Task-Relevant Feature Enhancement for Fine-tuning Language Models**
2412.09827v1 by Changqun Li, Chaofan Ding, Kexin Luan, Xinhan Di

Fine-tuning pre-trained large language models in a parameter-efficient manner
is widely studied for its effectiveness and efficiency. LoRA is one of the most
widely used methods, which assumes that the optimization process is essentially
low dimensional. Although LoRA has demonstrated commendable performance, there
remains a significant performance gap between LoRA and full fine-tuning when
learning new tasks. In this work, we propose Low-Rank Adaptation with
Task-Relevant Feature Enhancement(LoRATRF) for enhancing task-relevant features
from the perspective of editing neural network representations. To prioritize
task-relevant features, a task-aware filter that selectively extracts valuable
knowledge from hidden representations for the target or current task is
designed. As the experiments on a vareity of datasets including NLU,
commonsense reasoning and mathematical reasoning tasks demonstrates, our method
reduces 33.71% parameters and achieves better performance on a variety of
datasets in comparison with SOTA low-rank methods.

摘要：以參數有效率的方式微調預先訓練的大語言模型因其有效性和效率而廣受研究。LoRA 是其中一種最廣泛使用的方法，它假設最佳化過程本質上是低維度的。儘管 LoRA 已展現出令人稱道的效能，但在學習新任務時，LoRA 和完全微調之間仍存在顯著的效能差距。在這項工作中，我們提出具有任務相關特徵增強的低秩適應 (LoRATRF)，以編輯神經網路表示的方式增強與任務相關的特徵。為了優先考慮與任務相關的特徵，我們設計了一個任務感知篩選器，用於有選擇地從隱藏表示中提取有價值的知識，以供目標或當前任務使用。正如在包含 NLU、常識推理和數學推理任務在內的各種資料集上的實驗所示，與 SOTA 低秩方法相比，我們的模型減少了 33.71% 的參數，並在各種資料集上實現了更好的效能。

##### **Precise Antigen-Antibody Structure Predictions Enhance Antibody Development with HelixFold-Multimer**
2412.09826v1 by Jie Gao, Jing Hu, Lihang Liu, Yang Xue, Kunrui Zhu, Xiaonan Zhang, Xiaomin Fang

The accurate prediction of antigen-antibody structures is essential for
advancing immunology and therapeutic development, as it helps elucidate
molecular interactions that underlie immune responses. Despite recent progress
with deep learning models like AlphaFold and RoseTTAFold, accurately modeling
antigen-antibody complexes remains a challenge due to their unique evolutionary
characteristics. HelixFold-Multimer, a specialized model developed for this
purpose, builds on the framework of AlphaFold-Multimer and demonstrates
improved precision for antigen-antibody structures. HelixFold-Multimer not only
surpasses other models in accuracy but also provides essential insights into
antibody development, enabling more precise identification of binding sites,
improved interaction prediction, and enhanced design of therapeutic antibodies.
These advances underscore HelixFold-Multimer's potential in supporting antibody
research and therapeutic innovation.

摘要：準確預測抗原抗體結構對於免疫學和治療開發至關重要，因為它有助於闡明免疫反應的基礎分子交互作用。儘管像 AlphaFold 和 RoseTTAFold 等深度學習模型取得了進展，但由於抗原抗體複合物的獨特演化特性，準確建模仍然是一個挑戰。HelixFold-Multimer 是為此目的開發的專用模型，它建立在 AlphaFold-Multimer 的框架之上，並展示了抗原抗體結構的改進精度。HelixFold-Multimer 不僅在準確性上超越其他模型，還提供了對抗體開發的必要見解，從而能夠更精確地識別結合位點、改進交互作用預測以及增強治療性抗體的設計。這些進展強調了 HelixFold-Multimer 在支持抗體研究和治療創新方面的潛力。

##### **MERaLiON-AudioLLM: Technical Report**
2412.09818v1 by Yingxu He, Zhuohan Liu, Shuo Sun, Bin Wang, Wenyu Zhang, Xunlong Zou, Nancy F. Chen, Ai Ti Aw

We introduce MERaLiON-AudioLLM (Multimodal Empathetic Reasoning and Learning
in One Network), the first speech-text model tailored for Singapore's
multilingual and multicultural landscape. Developed under the National Large
Language Models Funding Initiative, Singapore, MERaLiON-AudioLLM integrates
advanced speech and text processing to address the diverse linguistic nuances
of local accents and dialects, enhancing accessibility and usability in
complex, multilingual environments. Our results demonstrate improvements in
both speech recognition and task-specific understanding, positioning
MERaLiON-AudioLLM as a pioneering solution for region specific AI applications.
We envision this release to set a precedent for future models designed to
address localised linguistic and cultural contexts in a global framework.

摘要：我們推出 MERaLiON-AudioLLM（多模態同理推理和學習於一體網路），這是第一個專為新加坡的多語言和多元文化環境量身打造的語音文本模型。在新加坡國家大型語言模型資助計畫下開發的 MERaLiON-AudioLLM 整合了進階的語音和文字處理，以應對當地口音和方言的多樣化語言差異，提升在複雜的多語言環境中的可及性和可用性。我們的結果證明了語音辨識和特定任務理解都有所進步，讓 MERaLiON-AudioLLM 成為區域特定 AI 應用的一項先驅解決方案。我們預見此版本將為未來模型樹立先例，這些模型旨在在全球架構中應對在地化的語言和文化背景。

##### **Enhancing Multimodal Large Language Models Complex Reason via Similarity Computation**
2412.09817v1 by Xiaofeng Zhang, Fanshuo Zeng, Yihao Quan, Zheng Hui, Jiawei Yao

Multimodal large language models have experienced rapid growth, and numerous
different models have emerged. The interpretability of LVLMs remains an
under-explored area. Especially when faced with more complex tasks such as
chain-of-thought reasoning, its internal mechanisms still resemble a black box
that is difficult to decipher. By studying the interaction and information flow
between images and text, we noticed that in models such as LLaVA1.5, image
tokens that are semantically related to text are more likely to have
information flow convergence in the LLM decoding layer, and these image tokens
receive higher attention scores. However, those image tokens that are less
relevant to the text do not have information flow convergence, and they only
get very small attention scores. To efficiently utilize the image information,
we propose a new image token reduction method, Simignore, which aims to improve
the complex reasoning ability of LVLMs by computing the similarity between
image and text embeddings and ignoring image tokens that are irrelevant and
unimportant to the text. Through extensive experiments, we demonstrate the
effectiveness of our method for complex reasoning tasks. The paper's source
code can be accessed from \url{https://github.com/FanshuoZeng/Simignore}.

摘要：多模态大型语言模型经历了快速发展，并且出现了许多不同的模型。LLVM 的可解释性仍然是一个尚未充分探索的领域。特别是当面临链式思维推理等更复杂的任务时，其内部机制仍然类似于一个难以破译的黑匣子。通过研究图像和文本之间的交互和信息流，我们注意到在 LLaVA1.5 等模型中，与文本语义相关的图像标记更有可能在 LLM 解码层中具有信息流收敛，并且这些图像标记接收更高的注意力分数。然而，那些与文本相关性较低的图像标记没有信息流收敛，而且它们只获得非常小的注意力分数。为了有效利用图像信息，我们提出了一种新的图像标记简化方法 Simignore，其旨在通过计算图像和文本嵌入之间的相似性并忽略与文本无关且不重要的图像标记来提高 LLVMs 的复杂推理能力。通过广泛的实验，我们证明了我们的方法对复杂推理任务的有效性。本文的源代码可以从 \url{https://github.com/FanshuoZeng/Simignore} 访问。

##### **Temporal Causal Discovery in Dynamic Bayesian Networks Using Federated Learning**
2412.09814v1 by Jianhong Chen, Ying Ma, Xubo Yue

Traditionally, learning the structure of a Dynamic Bayesian Network has been
centralized, with all data pooled in one location. However, in real-world
scenarios, data are often dispersed among multiple parties (e.g., companies,
devices) that aim to collaboratively learn a Dynamic Bayesian Network while
preserving their data privacy and security. In this study, we introduce a
federated learning approach for estimating the structure of a Dynamic Bayesian
Network from data distributed horizontally across different parties. We propose
a distributed structure learning method that leverages continuous optimization
so that only model parameters are exchanged during optimization. Experimental
results on synthetic and real datasets reveal that our method outperforms other
state-of-the-art techniques, particularly when there are many clients with
limited individual sample sizes.

摘要：傳統上，學習動態貝氏網路的結構是集中式的，所有資料都集中在一個位置。然而，在真實世界的場景中，資料通常分散在多個參與者（例如公司、裝置）中，他們希望在保留資料隱私和安全性的同時，協作學習動態貝氏網路。在這項研究中，我們引入了一種聯邦學習方法，用於估計橫跨不同參與者的資料中動態貝氏網路的結構。我們提出了一種分佈式結構學習方法，利用連續最佳化，這樣在最佳化過程中只會交換模型參數。在合成和真實資料集上的實驗結果顯示，我們的模型優於其他最先進的技術，特別是在有許多客戶且個別樣本大小有限的情況下。

##### **ScaleOT: Privacy-utility-scalable Offsite-tuning with Dynamic LayerReplace and Selective Rank Compression**
2412.09812v1 by Kai Yao, Zhaorui Tan, Tiandi Ye, Lichun Li, Yuan Zhao, Wenyan Liu, Wei Wang, Jianke Zhu

Offsite-tuning is a privacy-preserving method for tuning large language
models (LLMs) by sharing a lossy compressed emulator from the LLM owners with
data owners for downstream task tuning. This approach protects the privacy of
both the model and data owners. However, current offsite tuning methods often
suffer from adaptation degradation, high computational costs, and limited
protection strength due to uniformly dropping LLM layers or relying on
expensive knowledge distillation. To address these issues, we propose ScaleOT,
a novel privacy-utility-scalable offsite-tuning framework that effectively
balances privacy and utility. ScaleOT introduces a novel layerwise lossy
compression algorithm that uses reinforcement learning to obtain the importance
of each layer. It employs lightweight networks, termed harmonizers, to replace
the raw LLM layers. By combining important original LLM layers and harmonizers
in different ratios, ScaleOT generates emulators tailored for optimal
performance with various model scales for enhanced privacy protection.
Additionally, we present a rank reduction method to further compress the
original LLM layers, significantly enhancing privacy with negligible impact on
utility. Comprehensive experiments show that ScaleOT can achieve nearly
lossless offsite tuning performance compared with full fine-tuning while
obtaining better model privacy.

摘要：場外微調是一種隱私保護方法，用於透過 LLM 所有者與資料所有者分享有損失壓縮的 LLM 模擬器，以進行下游任務微調，進而微調大型語言模型 (LLM)。此方法保護模型和資料所有者的隱私。然而，目前的場外微調方法通常會因為適應性降低、高運算成本和有限的保護強度而受苦，這是因為均勻地捨棄 LLM 層或依賴昂貴的知識萃取。為了解決這些問題，我們提出 ScaleOT，這是一個新穎的隱私公用事業可擴充場外微調架構，能有效平衡隱私和公用事業。ScaleOT 介紹了一種新穎的逐層有損失壓縮演算法，該演算法使用強化學習來取得每一層的重要性。它採用稱為調和器的輕量級網路，以取代原始的 LLM 層。透過以不同的比例結合重要的原始 LLM 層和調和器，ScaleOT 能產生針對最佳效能量身打造的模擬器，並具備各種模型規模以增強隱私保護。此外，我們提出一個秩次簡約法，以進一步壓縮原始的 LLM 層，大幅提升隱私，且對公用事業的影響可以忽略不計。全面的實驗顯示，與完全微調相比，ScaleOT 能夠達成近乎無損失的場外微調效能，同時還能取得更好的模型隱私。

##### **LLM Distillation for Efficient Few-Shot Multiple Choice Question Answering**
2412.09807v1 by Patrick Sutanto, Joan Santoso

Multiple Choice Question Answering (MCQA) is an important problem with
numerous real-world applications, such as medicine, law, and education. The
high cost of building MCQA datasets makes few-shot learning pivotal in this
domain. While Large Language Models (LLMs) can enable few-shot learning, their
direct application in real-world scenarios is often hindered by their high
computational cost. To address this challenge, we propose a simple yet
effective approach that uses LLMs for data generation and scoring. Our approach
utilizes LLMs to create MCQA data which contains questions and choices, and to
assign probability scores to the generated choices. We then use the generated
data and LLM-assigned scores to finetune a smaller and more efficient
encoder-only model, DeBERTa-v3-base by leveraging distillation loss. Extensive
experiments on the Massive Multitask Language Understanding (MMLU) benchmark
demonstrate that our method improves accuracy from 28.9% to 39.3%, representing
a gain of over 10% compared to a baseline finetuned directly on 5-shot
examples. This shows the effectiveness of LLM-driven data generation and
knowledge distillation for few-shot MCQA.

摘要：多選題問答 (MCQA) 是一個重要的問題，在現實世界中有許多應用，例如醫學、法律和教育。建立 MCQA 資料集的成本很高，這使得小樣本學習在這個領域至關重要。儘管大型語言模型 (LLM) 可以支援小樣本學習，但它們在實際場景中的直接應用常常受到其高昂的運算成本所阻礙。為了應對這個挑戰，我們提出了一種簡單但有效的方法，該方法使用 LLM 來進行資料產生和評分。我們的做法利用 LLM 來建立包含問題和選項的 MCQA 資料，並為產生的選項分配機率分數。然後，我們使用產生的資料和 LLM 分配的分數，藉由利用蒸餾損失來微調一個更小且更有效率的編碼器專用模型 DeBERTa-v3-base。在 Massive Multitask Language Understanding (MMLU) 基準上進行的廣泛實驗證明，我們的方法將準確率從 28.9% 提升至 39.3%，與直接微調在 5 次嘗試的範例上相比，增加了超過 10%。這顯示了 LLM 驅動的資料產生和知識蒸餾在小樣本 MCQA 中的有效性。

##### **Universal Inceptive GNNs by Eliminating the Smoothness-generalization Dilemma**
2412.09805v1 by Ming Gu, Zhuonan Zheng, Sheng Zhou, Meihan Liu, Jiawei Chen, Tanyu Qiao, Liangcheng Li, Jiajun Bu

Graph Neural Networks (GNNs) have demonstrated remarkable success in various
domains, such as transaction and social net-works. However, their application
is often hindered by the varyinghomophily levels across different orders of
neighboring nodes, ne-cessitating separate model designs for homophilic and
heterophilicgraphs. In this paper, we aim to develop a unified framework
ca-pable of handling neighborhoods of various orders and homophilylevels.
Through theoretical exploration, we identify a previouslyoverlooked
architectural aspect in multi-hop learning: the cascadedependency, which leads
to asmoothness-generalization dilemma.This dilemma significantly affects the
learning process, especiallyin the context of high-order neighborhoods and
heterophilic graphs.To resolve this issue, we propose an Inceptive Graph Neural
Net-work (IGNN), a universal message-passing framework that replacesthe cascade
dependency with an inceptive architecture. IGNN pro-vides independent
representations for each hop, allowing personal-ized generalization
capabilities, and captures neighborhood-wiserelationships to select appropriate
receptive fields. Extensive ex-periments show that our IGNN outperforms 23
baseline methods,demonstrating superior performance on both homophilic and
het-erophilic graphs, while also scaling efficiently to large graphs.

摘要：圖神經網路 (GNN) 已在各種領域中展現出顯著的成功，例如交易和社交網路。然而，其應用通常會受到不同順序鄰接節點之間不同同質性層級的阻礙，因此需要針對同質性與異質性圖形設計不同的模型。在本文中，我們旨在開發一個統一的架構，能夠處理不同順序和同質性層級的鄰域。透過理論探討，我們識別出多跳學習中先前被忽略的架構層面：串聯依賴性，這會導致平滑性泛化兩難。此兩難顯著影響學習過程，特別是在高階鄰域和異質性圖形中。為了解決此問題，我們提出一個深度圖神經網路 (IGNN)，一個通用的訊息傳遞架構，以深度架構取代串聯依賴性。IGNN 為每個跳躍提供獨立的表示，允許個人化的泛化能力，並擷取鄰域更明智的關係以選擇適當的感受野。廣泛的實驗顯示，我們的 IGNN 優於 23 種基準方法，證明了在同質性和異質性圖形上都具有優異的效能，同時也能有效擴充到大型圖形。

##### **CP-DETR: Concept Prompt Guide DETR Toward Stronger Universal Object Detection**
2412.09799v1 by Qibo Chen, Weizhong Jin, Jianyue Ge, Mengdi Liu, Yuchao Yan, Jian Jiang, Li Yu, Xuanjiang Guo, Shuchang Li, Jianzhong Chen

Recent research on universal object detection aims to introduce language in a
SoTA closed-set detector and then generalize the open-set concepts by
constructing large-scale (text-region) datasets for training. However, these
methods face two main challenges: (i) how to efficiently use the prior
information in the prompts to genericise objects and (ii) how to reduce
alignment bias in the downstream tasks, both leading to sub-optimal performance
in some scenarios beyond pre-training. To address these challenges, we propose
a strong universal detection foundation model called CP-DETR, which is
competitive in almost all scenarios, with only one pre-training weight.
Specifically, we design an efficient prompt visual hybrid encoder that enhances
the information interaction between prompt and visual through scale-by-scale
and multi-scale fusion modules. Then, the hybrid encoder is facilitated to
fully utilize the prompted information by prompt multi-label loss and auxiliary
detection head. In addition to text prompts, we have designed two practical
concept prompt generation methods, visual prompt and optimized prompt, to
extract abstract concepts through concrete visual examples and stably reduce
alignment bias in downstream tasks. With these effective designs, CP-DETR
demonstrates superior universal detection performance in a broad spectrum of
scenarios. For example, our Swin-T backbone model achieves 47.6 zero-shot AP on
LVIS, and the Swin-L backbone model achieves 32.2 zero-shot AP on ODinW35.
Furthermore, our visual prompt generation method achieves 68.4 AP on COCO val
by interactive detection, and the optimized prompt achieves 73.1 fully-shot AP
on ODinW13.

摘要：<paragraph>最近的通用物体检测研究旨在在 SoTA 闭集检测器中引入语言，然后通过构建用于训练的大规模（文本区域）数据集来概括开放集概念。然而，这些方法面临两个主要挑战：（i）如何有效地使用提示中的先验信息来泛化对象，以及（ii）如何减少下游任务中的对齐偏差，这两者都会导致在某些超出预训练的场景中出现次优性能。为了应对这些挑战，我们提出了一个名为 CP-DETR 的强大的通用检测基础模型，该模型在几乎所有场景中都具有竞争力，并且只有一个预训练权重。具体来说，我们设计了一个高效的提示视觉混合编码器，它通过按比例融合模块和多尺度融合模块增强了提示和视觉之间的信息交互。然后，通过提示多标签损失和辅助检测头，促进混合编码器充分利用提示信息。除了文本提示之外，我们还设计了两种实用的概念提示生成方法，即视觉提示和优化提示，以通过具体的视觉示例提取抽象概念并稳定地减少下游任务中的对齐偏差。通过这些有效的设计，CP-DETR 在广泛的场景中展示了卓越的通用检测性能。例如，我们的 Swin-T 主干模型在 LVIS 上实现了 47.6 的零次 AP，而 Swin-L 主干模型在 ODinW35 上实现了 32.2 的零次 AP。此外，我们的视觉提示生成方法通过交互式检测在 COCO val 上实现了 68.4 AP，而优化提示在 ODinW13 上实现了 73.1 的全次 AP。</paragraph>

##### **AutoPatent: A Multi-Agent Framework for Automatic Patent Generation**
2412.09796v1 by Qiyao Wang, Shiwen Ni, Huaren Liu, Shule Lu, Guhong Chen, Xi Feng, Chi Wei, Qiang Qu, Hamid Alinejad-Rokny, Yuan Lin, Min Yang

As the capabilities of Large Language Models (LLMs) continue to advance, the
field of patent processing has garnered increased attention within the natural
language processing community. However, the majority of research has been
concentrated on classification tasks, such as patent categorization and
examination, or on short text generation tasks like patent summarization and
patent quizzes. In this paper, we introduce a novel and practical task known as
Draft2Patent, along with its corresponding D2P benchmark, which challenges LLMs
to generate full-length patents averaging 17K tokens based on initial drafts.
Patents present a significant challenge to LLMs due to their specialized
nature, standardized terminology, and extensive length. We propose a
multi-agent framework called AutoPatent which leverages the LLM-based planner
agent, writer agents, and examiner agent with PGTree and RRAG to generate
lengthy, intricate, and high-quality complete patent documents. The
experimental results demonstrate that our AutoPatent framework significantly
enhances the ability to generate comprehensive patents across various LLMs.
Furthermore, we have discovered that patents generated solely with the
AutoPatent framework based on the Qwen2.5-7B model outperform those produced by
larger and more powerful LLMs, such as GPT-4o, Qwen2.5-72B, and LLAMA3.1-70B,
in both objective metrics and human evaluations. We will make the data and code
available upon acceptance at \url{https://github.com/QiYao-Wang/AutoPatent}.

摘要：隨著大型語言模型 (LLM) 的能力不斷進步，專利處理領域在自然語言處理社群中備受關注。然而，大部分研究都集中在分類任務上，例如專利分類和審查，或簡短文字生成任務，例如專利摘要和專利測驗。在本文中，我們介紹了一項新穎且實用的任務，稱為 Draft2Patent，以及其對應的 D2P 基準，它挑戰 LLM 根據初始草稿生成平均 17K 個代碼的全文專利。專利由於其專業性質、標準化術語和篇幅冗長，對 LLM 構成重大挑戰。我們提出了一個名為 AutoPatent 的多代理架構，它利用基於 LLM 的規劃器代理、寫作者代理和審查員代理與 PGTree 和 RRAG 來生成冗長、複雜且高品質的完整專利文件。實驗結果表明，我們的 AutoPatent 架構顯著增強了跨各種 LLM 生成綜合專利的能力。此外，我們發現僅使用基於 Qwen2.5-7B 模型的 AutoPatent 架構生成的專利在客觀指標和人類評估中都優於由更大、更強大的 LLM（例如 GPT-4o、Qwen2.5-72B 和 LLAMA3.1-70B）產生的專利。我們將在 \url{https://github.com/QiYao-Wang/AutoPatent} 上接受後提供數據和代碼。

##### **Learning Visually Grounded Domain Ontologies via Embodied Conversation and Explanation**
2412.09770v1 by Jonghyuk Park, Alex Lascarides, Subramanian Ramamoorthy

In this paper, we offer a learning framework in which the agent's knowledge
gaps are overcome through corrective feedback from a teacher whenever the agent
explains its (incorrect) predictions. We test it in a low-resource visual
processing scenario, in which the agent must learn to recognize distinct types
of toy truck. The agent starts the learning process with no ontology about what
types of trucks exist nor which parts they have, and a deficient model for
recognizing those parts from visual input. The teacher's feedback to the
agent's explanations addresses its lack of relevant knowledge in the ontology
via a generic rule (e.g., "dump trucks have dumpers"), whereas an inaccurate
part recognition is corrected by a deictic statement (e.g., "this is not a
dumper"). The learner utilizes this feedback not only to improve its estimate
of the hypothesis space of possible domain ontologies and probability
distributions over them, but also to use those estimates to update its visual
interpretation of the scene. Our experiments demonstrate that teacher-learner
pairs utilizing explanations and corrections are more data-efficient than those
without such a faculty.

摘要：在本文中，我們提供了一個學習架構，其中代理的知識差距會透過教師在代理解釋其（錯誤的）預測時提供的糾正回饋來克服。我們在低資源視覺處理場景中測試了它，其中代理必須學會辨識不同類型的玩具卡車。代理從學習過程中開始，沒有關於卡車類型或其零件的本體論，以及一個從視覺輸入中辨識這些零件的缺陷模型。教師對代理解釋的回饋透過一個通用規則（例如，「自卸卡車有自卸車斗」）來解決其在本體論中缺乏相關知識，而一個不準確的零件辨識則會透過一個指示性陳述（例如，「這不是自卸車斗」）來修正。學習者利用此回饋不僅可以改善其對可能的領域本體論的假設空間和其上機率分布的估計，還可以利用這些估計來更新其對場景的視覺詮釋。我們的實驗證明，利用解釋和修正的老師與學習者配對比沒有這種能力的配對更具資料效率。

##### **Memory Layers at Scale**
2412.09764v1 by Vincent-Pierre Berges, Barlas Oğuz, Daniel Haziza, Wen-tau Yih, Luke Zettlemoyer, Gargi Gosh

Memory layers use a trainable key-value lookup mechanism to add extra
parameters to a model without increasing FLOPs. Conceptually, sparsely
activated memory layers complement compute-heavy dense feed-forward layers,
providing dedicated capacity to store and retrieve information cheaply. This
work takes memory layers beyond proof-of-concept, proving their utility at
contemporary scale. On downstream tasks, language models augmented with our
improved memory layer outperform dense models with more than twice the
computation budget, as well as mixture-of-expert models when matched for both
compute and parameters. We find gains are especially pronounced for factual
tasks. We provide a fully parallelizable memory layer implementation,
demonstrating scaling laws with up to 128B memory parameters, pretrained to 1
trillion tokens, comparing to base models with up to 8B parameters.

摘要：記憶層使用可訓練的鍵值查詢機制，在不增加 FLOP 的情況下為模型新增額外參數。從概念上來說，稀疏激活記憶層補充了計算密集的稠密前饋層，提供了專門的容量來廉價儲存和擷取資訊。這項工作將記憶層帶離了概念驗證，證明了它們在當代規模上的效用。在下游任務中，使用我們改良的記憶層增強的語言模型，其效能優於計算預算增加兩倍以上的稠密模型，以及在計算和參數方面都匹配的專家混合模型。我們發現收益在事實任務中特別明顯。我們提供了一個完全可並行的記憶層實作，展示了高達 128B 記憶體參數的縮放定律，預訓練到 1 兆個 token，與高達 8B 參數的基本模型進行比較。

##### **Congruence-based Learning of Probabilistic Deterministic Finite Automata**
2412.09760v1 by Matías Carrasco, Franz Mayr, Sergio Yovine

This work studies the question of learning probabilistic deterministic
automata from language models. For this purpose, it focuses on analyzing the
relations defined on algebraic structures over strings by equivalences and
similarities on probability distributions. We introduce a congruence that
extends the classical Myhill-Nerode congruence for formal languages. This new
congruence is the basis for defining regularity over language models. We
present an active learning algorithm that computes the quotient with respect to
this congruence whenever the language model is regular. The paper also defines
the notion of recognizability for language models and shows that it coincides
with regularity for congruences. For relations which are not congruences, it
shows that this is not the case. Finally, it discusses the impact of this
result on learning in the context of language models.

摘要：本研究探討從語言模型學習機率性確定自動機的問題。為此，它專注於分析由機率分佈上的等價性和相似性在字串上的代數結構所定義的關係。我們引入了一個同餘，它擴充了形式語言的經典 Myhill-Nerode 同餘。這個新的同餘是定義語言模型上正則性的基礎。我們提出了一個主動學習演算法，只要語言模型是正則的，它就會計算相對於這個同餘的商。本文還定義了語言模型的可辨識概念，並表明它與同餘的正則性一致。對於不是同餘的關係，它表明情況並非如此。最後，它討論了這個結果對語言模型中學習的影響。

##### **AI Red-Teaming is a Sociotechnical System. Now What?**
2412.09751v1 by Tarleton Gillespie, Ryland Shaw, Mary L. Gray, Jina Suh

As generative AI technologies find more and more real-world applications, the
importance of testing their performance and safety seems paramount.
``Red-teaming'' has quickly become the primary approach to test AI
models--prioritized by AI companies, and enshrined in AI policy and regulation.
Members of red teams act as adversaries, probing AI systems to test their
safety mechanisms and uncover vulnerabilities. Yet we know too little about
this work and its implications. This essay calls for collaboration between
computer scientists and social scientists to study the sociotechnical systems
surrounding AI technologies, including the work of red-teaming, to avoid
repeating the mistakes of the recent past. We highlight the importance of
understanding the values and assumptions behind red-teaming, the labor
involved, and the psychological impacts on red-teamers.

摘要：隨著生成式 AI 技術在現實世界中找到越來越多的應用，測試其效能和安全性顯得至關重要。
「紅隊」已迅速成為測試 AI 模型的主要方法，由 AI 公司優先考慮，並載入 AI 政策和法規中。
紅隊成員扮演對手，探測 AI 系統以測試其安全機制並找出漏洞。然而，我們對這項工作及其影響所知甚少。本文呼籲電腦科學家和社會科學家合作研究圍繞 AI 技術的社會技術系統，包括紅隊工作，以避免重蹈近期錯誤。我們強調了解紅隊背後的價值觀和假設、所涉及的勞動力以及對紅隊成員的心理影響的重要性。

##### **Let Curves Speak: A Continuous Glucose Monitor based Large Sensor Foundation Model for Diabetes Management**
2412.09727v1 by Junjie Luo, Abhimanyu Kumbara, Mansur Shomali, Rui Han, Anand Iyer, Ritu Agarwal, Gordon Gao

While previous studies of AI in diabetes management focus on long-term risk,
research on near-future glucose prediction remains limited but important as it
enables timely diabetes self-management. Integrating AI with continuous glucose
monitoring (CGM) holds promise for near-future glucose prediction. However,
existing models have limitations in capturing patterns of blood glucose
fluctuations and demonstrate poor generalizability. A robust approach is needed
to leverage massive CGM data for near-future glucose prediction. We propose
large sensor models (LSMs) to capture knowledge in CGM data by modeling
patients as sequences of glucose. CGM-LSM is pretrained on 15.96 million
glucose records from 592 diabetes patients for near-future glucose prediction.
We evaluated CGM-LSM against state-of-the-art methods using the OhioT1DM
dataset across various metrics, prediction horizons, and unseen patients.
Additionally, we assessed its generalizability across factors like diabetes
type, age, gender, and hour of day. CGM-LSM achieved exceptional performance,
with an rMSE of 29.81 mg/dL for type 1 diabetes patients and 23.49 mg/dL for
type 2 diabetes patients in a two-hour prediction horizon. For the OhioT1DM
dataset, CGM-LSM achieved a one-hour rMSE of 15.64 mg/dL, halving the previous
best of 31.97 mg/dL. Robustness analyses revealed consistent performance not
only for unseen patients and future periods, but also across diabetes type,
age, and gender. The model demonstrated adaptability to different hours of day,
maintaining accuracy across periods of various activity intensity levels.
CGM-LSM represents a transformative step in diabetes management by leveraging
pretraining to uncover latent glucose generation patterns in sensor data. Our
findings also underscore the broader potential of LSMs to drive innovation
across domains involving complex sensor data.

摘要：儘管先前的糖尿病管理人工智慧研究著重於長期風險，
但對於近期血糖預測的研究仍然有限，但由於它能及時進行糖尿病自我管理，因此非常重要。將人工智慧與連續血糖監測 (CGM) 結合，有望進行近期血糖預測。然而，
現有模型在捕捉血糖波動模式方面有其限制，且顯示出不佳的概括性。需要一種穩健的方法來利用大量的 CGM 資料進行近期血糖預測。我們提出大型感測器模型 (LSM) 來捕捉 CGM 資料中的知識，方法是將患者建模為葡萄糖序列。CGM-LSM 在 592 位糖尿病患者的 1596 萬筆葡萄糖記錄上進行預訓練，以進行近期血糖預測。
我們使用 OhioT1DM 資料集根據各種指標、預測範圍和未見患者，針對最先進的方法評估 CGM-LSM。
此外，我們評估了它在糖尿病類型、年齡、性別和一天中的小時等因素中的概括性。CGM-LSM 達到了非凡的效能，在兩小時預測範圍內，1 型糖尿病患者的 rMSE 為 29.81 mg/dL，2 型糖尿病患者的 rMSE 為 23.49 mg/dL。對於 OhioT1DM 資料集，CGM-LSM 達到一小時 rMSE 為 15.64 mg/dL，將先前的最佳值 31.97 mg/dL 減半。穩健性分析顯示，效能不僅對於未見患者和未來期間一致，而且在糖尿病類型、年齡和性別方面也一致。該模型證明了對一天中不同小時的適應性，在各種活動強度時期保持準確性。
CGM-LSM 透過利用預訓練來揭示感測器資料中的潛在葡萄糖生成模式，代表了糖尿病管理的轉型步驟。我們的研究結果也強調了 LSM 在推動涉及複雜感測器資料的領域創新的更廣泛潛力。

##### **The Unreasonable Effectiveness of Gaussian Score Approximation for Diffusion Models and its Applications**
2412.09726v1 by Binxu Wang, John J. Vastola

By learning the gradient of smoothed data distributions, diffusion models can
iteratively generate samples from complex distributions. The learned score
function enables their generalization capabilities, but how the learned score
relates to the score of the underlying data manifold remains largely unclear.
Here, we aim to elucidate this relationship by comparing learned neural scores
to the scores of two kinds of analytically tractable distributions: Gaussians
and Gaussian mixtures. The simplicity of the Gaussian model makes it
theoretically attractive, and we show that it admits a closed-form solution and
predicts many qualitative aspects of sample generation dynamics. We claim that
the learned neural score is dominated by its linear (Gaussian) approximation
for moderate to high noise scales, and supply both theoretical and empirical
arguments to support this claim. Moreover, the Gaussian approximation
empirically works for a larger range of noise scales than naive theory suggests
it should, and is preferentially learned early in training. At smaller noise
scales, we observe that learned scores are better described by a coarse-grained
(Gaussian mixture) approximation of training data than by the score of the
training distribution, a finding consistent with generalization. Our findings
enable us to precisely predict the initial phase of trained models' sampling
trajectories through their Gaussian approximations. We show that this allows
the skipping of the first 15-30% of sampling steps while maintaining high
sample quality (with a near state-of-the-art FID score of 1.93 on CIFAR-10
unconditional generation). This forms the foundation of a novel hybrid sampling
method, termed analytical teleportation, which can seamlessly integrate with
and accelerate existing samplers, including DPM-Solver-v3 and UniPC. Our
findings suggest ways to improve the design and training of diffusion models.

摘要：透過學習平滑資料分佈的梯度，擴散模型可以反覆生成複雜分佈的樣本。學習到的分數函數能讓它們具備概化能力，但學習到的分數如何與底層資料流形的分數相關，在很大程度上仍不清楚。在此，我們旨在透過將學習到的神經分數與兩種解析可處理分佈（高斯分佈和高斯混合分佈）的分數進行比較，來闡明這種關係。高斯模型的簡潔性使其在理論上具有吸引力，我們表明它承認閉合形式的解，並預測了樣本生成動態的許多定性方面。我們聲稱，對於中等至高噪聲尺度，學習到的神經分數由其線性（高斯）近似主導，並提供理論和經驗論證來支持此說法。此外，高斯近似在比樸素理論所建議的更廣泛的噪聲尺度範圍內經驗上有效，並且在訓練早期優先學習。在較小的噪聲尺度下，我們觀察到學習到的分數由訓練資料的粗粒度（高斯混合）近似，而不是訓練分佈的分數來更好地描述，這一發現與概化相一致。我們的發現使我們能夠通過高斯近似準確預測訓練模型採樣軌跡的初始階段。我們表明，這允許跳過前 15-30% 的採樣步驟，同時保持高樣本品質（在 CIFAR-10 無條件生成上獲得接近最先進的 1.93 FID 分數）。這構成了創新混合採樣方法的基礎，稱為分析傳送，它可以無縫整合並加速現有採樣器，包括 DPM-Solver-v3 和 UniPC。我們的發現提出了改進擴散模型設計和訓練的方法。

##### **GReaTer: Gradients over Reasoning Makes Smaller Language Models Strong Prompt Optimizers**
2412.09722v1 by Sarkar Snigdha Sarathi Das, Ryo Kamoi, Bo Pang, Yusen Zhang, Caiming Xiong, Rui Zhang

The effectiveness of large language models (LLMs) is closely tied to the
design of prompts, making prompt optimization essential for enhancing their
performance across a wide range of tasks. Many existing approaches to
automating prompt engineering rely exclusively on textual feedback, refining
prompts based solely on inference errors identified by large, computationally
expensive LLMs. Unfortunately, smaller models struggle to generate high-quality
feedback, resulting in complete dependence on large LLM judgment. Moreover,
these methods fail to leverage more direct and finer-grained information, such
as gradients, due to operating purely in text space. To this end, we introduce
GReaTer, a novel prompt optimization technique that directly incorporates
gradient information over task-specific reasoning. By utilizing task loss
gradients, GReaTer enables self-optimization of prompts for open-source,
lightweight language models without the need for costly closed-source LLMs.
This allows high-performance prompt optimization without dependence on massive
LLMs, closing the gap between smaller models and the sophisticated reasoning
often needed for prompt refinement. Extensive evaluations across diverse
reasoning tasks including BBH, GSM8k, and FOLIO demonstrate that GReaTer
consistently outperforms previous state-of-the-art prompt optimization methods,
even those reliant on powerful LLMs. Additionally, GReaTer-optimized prompts
frequently exhibit better transferability and, in some cases, boost task
performance to levels comparable to or surpassing those achieved by larger
language models, highlighting the effectiveness of prompt optimization guided
by gradients over reasoning. Code of GReaTer is available at
https://github.com/psunlpgroup/GreaTer.

摘要：大型語言模型 (LLM) 的效能與提示設計息息相關，因此提示最佳化對於提升 LLM 在各種任務中的表現至關重要。許多現有的自動化提示工程方法僅依賴文字回饋，根據大型、運算成本高昂的 LLM 識別出的推論錯誤來改進提示。不幸的是，較小的模型難以產生高品質的回饋，導致完全依賴大型 LLM 的判斷。此外，這些方法由於純粹在文字空間中運作，無法利用更直接、更細緻的資訊，例如梯度。為此，我們引入了 GReaTer，這是一種新穎的提示最佳化技術，可直接將梯度資訊納入特定任務的推理中。透過利用任務損失梯度，GReaTer 可以為開放原始碼、輕量級語言模型進行提示自最佳化，無需依賴昂貴的閉源 LLM。這允許執行高性能提示最佳化，而無需依賴大型 LLM，縮小了較小模型與提示改進通常需要的複雜推理之間的差距。在包括 BBH、GSM8k 和 FOLIO 在內的各種推理任務中進行的廣泛評估表明，GReaTer 一致優於先前的提示最佳化方法，即使是依賴強大 LLM 的方法也是如此。此外，GReaTer 最佳化的提示通常表現出更好的可移植性，在某些情況下，任務效能提升至與較大型語言模型相當或超越其效能的程度，突顯了透過推理梯度引導的提示最佳化的效能。GReaTer 的程式碼可在 https://github.com/psunlpgroup/GreaTer 取得。

##### **Human vs. AI: A Novel Benchmark and a Comparative Study on the Detection of Generated Images and the Impact of Prompts**
2412.09715v1 by Philipp Moeßner, Heike Adel

With the advent of publicly available AI-based text-to-image systems, the
process of creating photorealistic but fully synthetic images has been largely
democratized. This can pose a threat to the public through a simplified spread
of disinformation. Machine detectors and human media expertise can help to
differentiate between AI-generated (fake) and real images and counteract this
danger. Although AI generation models are highly prompt-dependent, the impact
of the prompt on the fake detection performance has rarely been investigated
yet. This work therefore examines the influence of the prompt's level of detail
on the detectability of fake images, both with an AI detector and in a user
study. For this purpose, we create a novel dataset, COCOXGEN, which consists of
real photos from the COCO dataset as well as images generated with SDXL and
Fooocus using prompts of two standardized lengths. Our user study with 200
participants shows that images generated with longer, more detailed prompts are
detected significantly more easily than those generated with short prompts.
Similarly, an AI-based detection model achieves better performance on images
generated with longer prompts. However, humans and AI models seem to pay
attention to different details, as we show in a heat map analysis.

摘要：隨著公開的人工智慧基於文字轉換圖像系統的出現，創造寫實但完全合成的圖像的過程在很大程度上已經民主化。這可能會透過簡化錯誤訊息的散布對公眾構成威脅。機器偵測器和人類媒體專業知識有助於區分人工智慧產生的（假的）和真實的圖像，並對抗這種危險。儘管人工智慧生成模型高度依賴提示，但提示對假偵測效能的影響卻很少受到調查。因此，這項工作探討了提示的詳細程度對假圖像的可偵測性的影響，同時使用人工智慧偵測器和使用者研究。為此，我們創建了一個新的資料集 COCOXGEN，其中包含來自 COCO 資料集的真實照片，以及使用兩種標準化長度的提示產生的 SDXL 和 Fooocus 影像。我們對 200 名參與者進行的使用者研究顯示，使用較長、更詳細的提示產生的圖像比使用簡短提示產生的圖像更容易被偵測到。同樣地，基於人工智慧的偵測模型在使用較長提示產生的圖像上獲得了更好的效能。然而，正如我們在熱點圖分析中所示，人類和人工智慧模型似乎關注不同的細節。

