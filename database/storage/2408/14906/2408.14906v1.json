{"2408.14906": {"publish_time": "2024-08-27", "title": "Writing in the Margins: Better Inference Pattern for Long Context Retrieval", "paper_summary": "In this paper, we introduce Writing in the Margins (WiM), a new inference\npattern for Large Language Models designed to optimize the handling of long\ninput sequences in retrieval-oriented tasks. This approach leverages the\nchunked prefill of the key-value cache to perform segment-wise inference, which\nenables efficient processing of extensive contexts along with the generation\nand classification of intermediate information (\"margins\") that guide the model\ntowards specific tasks. This method increases computational overhead marginally\nwhile significantly enhancing the performance of off-the-shelf models without\nthe need for fine-tuning. Specifically, we observe that WiM provides an average\nenhancement of 7.5% in accuracy for reasoning skills (HotpotQA, MultiHop-RAG)\nand more than a 30.0% increase in the F1-score for aggregation tasks (CWE).\nAdditionally, we show how the proposed pattern fits into an interactive\nretrieval design that provides end-users with ongoing updates about the\nprogress of context processing, and pinpoints the integration of relevant\ninformation into the final response. We release our implementation of WiM using\nHugging Face Transformers library at\nhttps://github.com/writer/writing-in-the-margins.", "paper_summary_zh": "\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86\u908a\u7de3\u5beb\u5165 (WiM)\uff0c\u9019\u662f\u4e00\u7a2e\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u65b0\u63a8\u8ad6\u6a21\u5f0f\uff0c\u65e8\u5728\u512a\u5316\u5728\u6aa2\u7d22\u5c0e\u5411\u4efb\u52d9\u4e2d\u8655\u7406\u9577\u8f38\u5165\u5e8f\u5217\u3002\u6b64\u65b9\u6cd5\u5229\u7528\u95dc\u9375\u503c\u5feb\u53d6\u7684\u5206\u584a\u9810\u586b\u5145\u4f86\u57f7\u884c\u5206\u6bb5\u63a8\u8ad6\uff0c\u9019\u4f7f\u5f97\u80fd\u5920\u6709\u6548\u7387\u5730\u8655\u7406\u5ee3\u6cdb\u7684\u4e0a\u4e0b\u6587\uff0c\u4e26\u751f\u6210\u548c\u5206\u985e\u4e2d\u9593\u8cc7\u8a0a\uff08\u300c\u908a\u7de3\u300d\uff09\uff0c\u4ee5\u5f15\u5c0e\u6a21\u578b\u57f7\u884c\u7279\u5b9a\u4efb\u52d9\u3002\u6b64\u65b9\u6cd5\u6703\u7a0d\u5fae\u589e\u52a0\u904b\u7b97\u8ca0\u64d4\uff0c\u540c\u6642\u5927\u5e45\u63d0\u5347\u73fe\u6210\u6a21\u578b\u7684\u6548\u80fd\uff0c\u800c\u7121\u9700\u5fae\u8abf\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u89c0\u5bdf\u5230 WiM \u70ba\u63a8\u7406\u6280\u80fd\uff08HotpotQA\u3001MultiHop-RAG\uff09\u63d0\u4f9b\u4e86\u5e73\u5747 7.5% \u7684\u6e96\u78ba\u5ea6\u63d0\u5347\uff0c\u4e26\u4e14\u805a\u5408\u4efb\u52d9\uff08CWE\uff09\u7684 F1 \u5206\u6578\u63d0\u5347\u4e86 30.0% \u4ee5\u4e0a\u3002\u6b64\u5916\uff0c\u6211\u5011\u5c55\u793a\u4e86\u6240\u63d0\u51fa\u7684\u6a21\u5f0f\u5982\u4f55\u878d\u5165\u4e92\u52d5\u5f0f\u6aa2\u7d22\u8a2d\u8a08\u4e2d\uff0c\u8a72\u8a2d\u8a08\u53ef\u70ba\u6700\u7d42\u4f7f\u7528\u8005\u63d0\u4f9b\u6709\u95dc\u8655\u7406\u9032\u5ea6\u7684\u6301\u7e8c\u66f4\u65b0\uff0c\u4e26\u7cbe\u78ba\u6307\u51fa\u5c07\u76f8\u95dc\u8cc7\u8a0a\u6574\u5408\u5230\u6700\u7d42\u56de\u61c9\u4e2d\u3002\u6211\u5011\u5728 https://github.com/writer/writing-in-the-margins \u4e2d\u4f7f\u7528 Hugging Face Transformers \u51fd\u5f0f\u5eab\u767c\u5e03\u4e86\u6211\u5011\u7684 WiM \u5be6\u4f5c\u3002", "author": "Melisa Russak et.al.", "authors": "Melisa Russak, Umar Jamil, Christopher Bryant, Kiran Kamble, Axel Magnuson, Mateusz Russak, Waseem AlShikh", "id": "2408.14906v1", "paper_url": "http://arxiv.org/abs/2408.14906v1", "repo": "https://github.com/writer/writing-in-the-margins"}}