{"2502.14628": {"publish_time": "2025-02-20", "title": "PEARL: Towards Permutation-Resilient LLMs", "paper_summary": "The in-context learning (ICL) capability of large language models (LLMs)\nenables them to perform challenging tasks using provided demonstrations.\nHowever, ICL is highly sensitive to the ordering of demonstrations, leading to\ninstability in predictions. This paper shows that this vulnerability can be\nexploited to design a natural attack - difficult for model providers to detect\n- that achieves nearly 80% success rate on LLaMA-3 by simply permuting the\ndemonstrations. Existing mitigation methods primarily rely on post-processing\nand fail to enhance the model's inherent robustness to input permutations,\nraising concerns about safety and reliability of LLMs. To address this issue,\nwe propose Permutation-resilient learning (PEARL), a novel framework based on\ndistributionally robust optimization (DRO), which optimizes model performance\nagainst the worst-case input permutation. Specifically, PEARL consists of a\npermutation-proposal network (P-Net) and the LLM. The P-Net generates the most\nchallenging permutations by treating it as an optimal transport problem, which\nis solved using an entropy-constrained Sinkhorn algorithm. Through minimax\noptimization, the P-Net and the LLM iteratively optimize against each other,\nprogressively improving the LLM's robustness. Experiments on synthetic\npre-training and real-world instruction tuning tasks demonstrate that PEARL\neffectively mitigates permutation attacks and enhances performance. Notably,\ndespite being trained on fewer shots and shorter contexts, PEARL achieves\nperformance gains of up to 40% when scaled to many-shot and long-context\nscenarios, highlighting its efficiency and generalization capabilities.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u8a9e\u5883\u5b78\u7fd2 (ICL) \u80fd\u529b\u4f7f\u5176\u80fd\u5920\u900f\u904e\u63d0\u4f9b\u7684\u793a\u7bc4\u4f86\u57f7\u884c\u5177\u6709\u6311\u6230\u6027\u7684\u4efb\u52d9\u3002\u7136\u800c\uff0cICL \u5c0d\u793a\u7bc4\u7684\u6392\u5e8f\u975e\u5e38\u654f\u611f\uff0c\u5c0e\u81f4\u9810\u6e2c\u4e0d\u7a69\u5b9a\u3002\u672c\u6587\u986f\u793a\uff0c\u53ef\u4ee5\u5229\u7528\u6b64\u6f0f\u6d1e\u4f86\u8a2d\u8a08\u4e00\u7a2e\u81ea\u7136\u653b\u64ca\uff0c\u8b93\u6a21\u578b\u63d0\u4f9b\u8005\u96e3\u4ee5\u5075\u6e2c\uff0c\u900f\u904e\u7c21\u55ae\u5730\u6392\u5217\u793a\u7bc4\uff0c\u5728 LLaMA-3 \u4e0a\u9054\u5230\u8fd1 80% \u7684\u6210\u529f\u7387\u3002\u73fe\u6709\u7684\u7de9\u89e3\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8cf4\u5f8c\u8655\u7406\uff0c\u4e14\u7121\u6cd5\u589e\u5f37\u6a21\u578b\u5c0d\u8f38\u5165\u6392\u5217\u7684\u56fa\u6709\u7a69\u5065\u6027\uff0c\u5f15\u767c\u4e86\u5c0d LLM \u7684\u5b89\u5168\u6027\u8207\u53ef\u9760\u6027\u7684\u7591\u616e\u3002\u70ba\u4e86\u89e3\u6c7a\u6b64\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u57fa\u65bc\u5206\u914d\u7a69\u5065\u6700\u4f73\u5316 (DRO) \u7684\u65b0\u578b\u67b6\u69cb\uff0c\u7a31\u70ba\u6392\u5217\u5f48\u6027\u5b78\u7fd2 (PEARL)\uff0c\u5b83\u91dd\u5c0d\u6700\u5dee\u60c5\u6cc1\u7684\u8f38\u5165\u6392\u5217\u4f86\u6700\u4f73\u5316\u6a21\u578b\u6548\u80fd\u3002\u5177\u9ad4\u4f86\u8aaa\uff0cPEARL \u5305\u542b\u6392\u5217\u5efa\u8b70\u7db2\u8def (P-Net) \u548c LLM\u3002P-Net \u5c07\u5176\u8996\u70ba\u6700\u512a\u50b3\u8f38\u554f\u984c\u4f86\u7522\u751f\u6700\u5177\u6311\u6230\u6027\u7684\u6392\u5217\uff0c\u4e26\u4f7f\u7528\u71b5\u7d04\u675f Sinkhorn \u6f14\u7b97\u6cd5\u4f86\u89e3\u6c7a\u3002\u900f\u904e\u6975\u5c0f\u6975\u5927\u6700\u4f73\u5316\uff0cP-Net \u548c LLM \u8fed\u4ee3\u5730\u76f8\u4e92\u6700\u4f73\u5316\uff0c\u9010\u6b65\u6539\u5584 LLM \u7684\u7a69\u5065\u6027\u3002\u5728\u5408\u6210\u9810\u8a13\u7df4\u548c\u771f\u5be6\u4e16\u754c\u6307\u4ee4\u8abf\u6574\u4efb\u52d9\u4e0a\u7684\u5be6\u9a57\u8b49\u660e\uff0cPEARL \u6709\u6548\u5730\u6e1b\u8f15\u4e86\u6392\u5217\u653b\u64ca\u4e26\u589e\u5f37\u4e86\u6548\u80fd\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5118\u7ba1\u5728\u8f03\u5c11\u7684\u6b21\u6578\u548c\u8f03\u77ed\u7684\u8a9e\u5883\u4e2d\u9032\u884c\u8a13\u7df4\uff0c\u4f46 PEARL \u5728\u64f4\u5c55\u5230\u591a\u91cd\u6b21\u6578\u548c\u9577\u8a9e\u5883\u5834\u666f\u6642\u4ecd\u53ef\u7372\u5f97\u9ad8\u9054 40% \u7684\u6548\u80fd\u63d0\u5347\uff0c\u7a81\u986f\u4e86\u5176\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u3002", "author": "Liang Chen et.al.", "authors": "Liang Chen, Li Shen, Yang Deng, Xiaoyan Zhao, Bin Liang, Kam-Fai Wong", "id": "2502.14628v1", "paper_url": "http://arxiv.org/abs/2502.14628v1", "repo": "null"}}