{"2408.05911": {"publish_time": "2024-08-12", "title": "A New Pipeline For Generating Instruction Dataset via RAG and Self Fine-Tuning", "paper_summary": "With the rapid development of large language models in recent years, there\nhas been an increasing demand for domain-specific Agents that can cater to the\nunique needs of enterprises and organizations. Unlike general models, which\nstrive for broad coverage, these specialized Agents rely on focused datasets\ntailored to their intended applications. This research proposes a pipeline that\nleverages the power of LLMs and the Retrieval-Augmented Generation related\nframework to construct high-quality instruction datasets for fine-tuning on\nspecific domains using custom document collections. By ingesting\ndomain-specific documents, the pipeline generates relevant and contextually\nappropriate instructions, thus effectively creating a comprehensive dataset for\nfine-tuning LLMs on the target domain. This approach overcomes the limitations\nof traditional dataset creation methods, which often rely on manual curation or\nweb-scraping techniques that may introduce noise and irrelevant data. Notably,\nour pipeline offers a dynamic solution that can quickly adapt to updates or\nmodifications in the domain-specific document collection, eliminating the need\nfor complete retraining. Additionally, it addresses the challenge of data\nscarcity by enabling the generation of instruction datasets from a limited set\nof initial documents, rendering it suitable for unpopular or specialized\ndomains where comprehensive datasets are scarce. As a case study, we apply this\napproach to the domain of psychiatry, a field requiring specialized knowledge\nand sensitive handling of patient information. The resulting fine-tuned LLM\ndemonstrates showcases the viability of the proposed approach and underscores\nits potential for widespread adoption across various industries and domains\nwhere tailored, accurate, and contextually relevant language models are\nindispensable.", "paper_summary_zh": "<paragraph>\u96a8\u8457\u8fd1\u5e7e\u5e74\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u5feb\u901f\u767c\u5c55\uff0c\u5c0d\u80fd\u5920\u6eff\u8db3\u4f01\u696d\u548c\u7d44\u7e54\u7368\u7279\u9700\u6c42\u7684\u7279\u5b9a\u9818\u57df\u4ee3\u7406\u7684\u9700\u6c42\u8207\u65e5\u4ff1\u589e\u3002\u9019\u4e9b\u5c08\u7528\u4ee3\u7406\u8207\u8ffd\u6c42\u5ee3\u6cdb\u6db5\u84cb\u7bc4\u570d\u7684\u901a\u7528\u6a21\u578b\u4e0d\u540c\uff0c\u5b83\u5011\u4f9d\u8cf4\u65bc\u91dd\u5c0d\u5176\u9810\u671f\u61c9\u7528\u7a0b\u5f0f\u91cf\u8eab\u6253\u9020\u7684\u805a\u7126\u5f0f\u8cc7\u6599\u96c6\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u500b\u7ba1\u9053\uff0c\u5b83\u5229\u7528 LLM \u7684\u5f37\u5927\u529f\u80fd\u548c\u6aa2\u7d22\u589e\u5f37\u751f\u6210\u76f8\u95dc\u6846\u67b6\uff0c\u4f7f\u7528\u81ea\u8a02\u6587\u4ef6\u96c6\u5408\u70ba\u7279\u5b9a\u9818\u57df\u7684\u5fae\u8abf\u69cb\u5efa\u9ad8\u54c1\u8cea\u7684\u6307\u4ee4\u8cc7\u6599\u96c6\u3002\u900f\u904e\u64f7\u53d6\u7279\u5b9a\u9818\u57df\u7684\u6587\u4ef6\uff0c\u7ba1\u9053\u6703\u7522\u751f\u76f8\u95dc\u4e14\u5728\u8108\u7d61\u4e0a\u9069\u7576\u7684\u6307\u4ee4\uff0c\u5f9e\u800c\u6709\u6548\u5730\u70ba\u76ee\u6a19\u9818\u57df\u4e0a\u7684 LLM \u5fae\u8abf\u5efa\u7acb\u4e00\u500b\u5168\u9762\u7684\u8cc7\u6599\u96c6\u3002\u9019\u7a2e\u65b9\u6cd5\u514b\u670d\u4e86\u50b3\u7d71\u8cc7\u6599\u96c6\u5efa\u7acb\u65b9\u6cd5\u7684\u9650\u5236\uff0c\u9019\u4e9b\u65b9\u6cd5\u901a\u5e38\u4f9d\u8cf4\u65bc\u4eba\u5de5\u6574\u7406\u6216\u7db2\u8def\u64f7\u53d6\u6280\u8853\uff0c\u800c\u9019\u4e9b\u6280\u8853\u53ef\u80fd\u6703\u5f15\u5165\u96dc\u8a0a\u548c\u4e0d\u76f8\u95dc\u7684\u8cc7\u6599\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u6211\u5011\u7684\u7ba1\u9053\u63d0\u4f9b\u4e86\u4e00\u500b\u52d5\u614b\u7684\u89e3\u6c7a\u65b9\u6848\uff0c\u53ef\u4ee5\u5feb\u901f\u9069\u61c9\u7279\u5b9a\u9818\u57df\u6587\u4ef6\u96c6\u5408\u4e2d\u7684\u66f4\u65b0\u6216\u4fee\u6539\uff0c\u5f9e\u800c\u7121\u9700\u9032\u884c\u5b8c\u6574\u7684\u91cd\u65b0\u8a13\u7df4\u3002\u6b64\u5916\uff0c\u5b83\u900f\u904e\u5f9e\u4e00\u7d44\u6709\u9650\u7684\u521d\u59cb\u6587\u4ef6\u7522\u751f\u6307\u4ee4\u8cc7\u6599\u96c6\u4f86\u89e3\u6c7a\u8cc7\u6599\u7a00\u7f3a\u7684\u6311\u6230\uff0c\u4f7f\u5176\u9069\u7528\u65bc\u5168\u9762\u7684\u8cc7\u6599\u96c6\u7a00\u7f3a\u7684\u975e\u71b1\u9580\u6216\u5c08\u696d\u9818\u57df\u3002\u4f5c\u70ba\u4e00\u500b\u6848\u4f8b\u7814\u7a76\uff0c\u6211\u5011\u5c07\u6b64\u65b9\u6cd5\u61c9\u7528\u65bc\u7cbe\u795e\u75c5\u5b78\u9818\u57df\uff0c\u9019\u662f\u4e00\u500b\u9700\u8981\u5c08\u696d\u77e5\u8b58\u548c\u654f\u611f\u8655\u7406\u60a3\u8005\u8cc7\u8a0a\u7684\u9818\u57df\u3002\u5fae\u8abf\u5f8c\u7684 LLM \u8b49\u660e\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u53ef\u884c\u6027\uff0c\u4e26\u5f37\u8abf\u4e86\u5176\u5728\u5404\u7a2e\u7522\u696d\u548c\u9818\u57df\u4e2d\u5ee3\u6cdb\u63a1\u7528\u7684\u6f5b\u529b\uff0c\u5728\u9019\u4e9b\u9818\u57df\u4e2d\uff0c\u91cf\u8eab\u6253\u9020\u3001\u6e96\u78ba\u4e14\u8207\u8108\u7d61\u76f8\u95dc\u7684\u8a9e\u8a00\u6a21\u578b\u662f\u4e0d\u53ef\u6216\u7f3a\u7684\u3002</paragraph>", "author": "Chih-Wei Song et.al.", "authors": "Chih-Wei Song, Yu-Kai Lee, Yin-Te Tsai", "id": "2408.05911v1", "paper_url": "http://arxiv.org/abs/2408.05911v1", "repo": "null"}}