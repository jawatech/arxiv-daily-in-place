{"2412.17727": {"publish_time": "2024-12-23", "title": "Knowledge Editing through Chain-of-Thought", "paper_summary": "Large Language Models (LLMs) have demonstrated exceptional capabilities\nacross a wide range of natural language processing (NLP) tasks. However,\nkeeping these models up-to-date with evolving world knowledge remains a\nsignificant challenge due to the high costs of frequent retraining. To address\nthis challenge, knowledge editing techniques have emerged to update LLMs with\nnew information without rebuilding the model from scratch. Among these, the\nin-context editing paradigm stands out for its effectiveness in integrating new\nknowledge while preserving the model's original capabilities. Despite its\npotential, existing in-context knowledge editing methods are often\ntask-specific, focusing primarily on multi-hop QA tasks using structured\nknowledge triples. Moreover, their reliance on few-shot prompting for task\ndecomposition makes them unstable and less effective in generalizing across\ndiverse tasks.\n  In response to these limitations, we propose EditCoT, a novel knowledge\nediting framework that flexibly and efficiently updates LLMs across various\ntasks without retraining. EditCoT works by generating a chain-of-thought (CoT)\nfor a given input and then iteratively refining this CoT process using a CoT\neditor based on updated knowledge. We evaluate EditCoT across a diverse range\nof benchmarks, covering multiple languages and tasks. The results demonstrate\nthat our approach achieves state-of-the-art performance while offering superior\ngeneralization, effectiveness, and stability compared to existing methods,\nmarking a significant advancement in the field of knowledge updating. Code and\ndata are available at: https://github.com/bebr2/EditCoT.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5728\u5ee3\u6cdb\u7684\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u975e\u51e1\u7684\u80fd\u529b\u3002\u7136\u800c\uff0c\u7531\u65bc\u983b\u7e41\u91cd\u65b0\u8a13\u7df4\u7684\u6210\u672c\u9ad8\u6602\uff0c\u8b93\u9019\u4e9b\u6a21\u578b\u8207\u4e0d\u65b7\u6f14\u9032\u7684\u4e16\u754c\u77e5\u8b58\u4fdd\u6301\u540c\u6b65\u4ecd\u662f\u4e00\u9805\u91cd\u5927\u6311\u6230\u3002\u70ba\u4e86\u61c9\u5c0d\u6b64\u6311\u6230\uff0c\u77e5\u8b58\u7de8\u8f2f\u6280\u8853\u61c9\u904b\u800c\u751f\uff0c\u53ef\u4ee5\u5728\u4e0d\u5f9e\u982d\u91cd\u5efa\u6a21\u578b\u7684\u60c5\u6cc1\u4e0b\uff0c\u4f7f\u7528\u65b0\u8cc7\u8a0a\u66f4\u65b0 LLM\u3002\u5176\u4e2d\uff0c\u60c5\u5883\u7de8\u8f2f\u7bc4\u4f8b\u56e0\u5176\u5728\u6574\u5408\u65b0\u77e5\u8b58\u7684\u540c\u6642\uff0c\u9084\u80fd\u4fdd\u7559\u6a21\u578b\u7684\u539f\u59cb\u80fd\u529b\u800c\u812b\u7a4e\u800c\u51fa\u3002\u5118\u7ba1\u6709\u5176\u6f5b\u529b\uff0c\u73fe\u6709\u7684\u60c5\u5883\u77e5\u8b58\u7de8\u8f2f\u65b9\u6cd5\u901a\u5e38\u662f\u7279\u5b9a\u65bc\u4efb\u52d9\u7684\uff0c\u4e3b\u8981\u5c08\u6ce8\u65bc\u4f7f\u7528\u7d50\u69cb\u5316\u77e5\u8b58\u4e09\u5143\u7d44\u7684\u591a\u8df3\u554f\u7b54\u4efb\u52d9\u3002\u6b64\u5916\uff0c\u5b83\u5011\u4f9d\u8cf4\u65bc\u5c11\u6b21\u63d0\u793a\u4f86\u9032\u884c\u4efb\u52d9\u5206\u89e3\uff0c\u9019\u4f7f\u5f97\u5b83\u5011\u4e0d\u7a69\u5b9a\uff0c\u4e14\u5728\u8de8\u4e0d\u540c\u4efb\u52d9\u9032\u884c\u6982\u62ec\u6642\u6548\u679c\u8f03\u5dee\u3002\n\u70ba\u4e86\u56de\u61c9\u9019\u4e9b\u9650\u5236\uff0c\u6211\u5011\u63d0\u51fa\u4e86 EditCoT\uff0c\u9019\u662f\u4e00\u500b\u65b0\u7a4e\u7684\u77e5\u8b58\u7de8\u8f2f\u67b6\u69cb\uff0c\u53ef\u4ee5\u5728\u4e0d\u91cd\u65b0\u8a13\u7df4\u7684\u60c5\u6cc1\u4e0b\uff0c\u9748\u6d3b\u4e14\u6709\u6548\u5730\u8de8\u5404\u7a2e\u4efb\u52d9\u66f4\u65b0 LLM\u3002EditCoT \u7684\u904b\u4f5c\u65b9\u5f0f\u662f\u70ba\u7d66\u5b9a\u7684\u8f38\u5165\u7522\u751f\u4e00\u500b\u601d\u8003\u93c8 (CoT)\uff0c\u7136\u5f8c\u4f7f\u7528\u57fa\u65bc\u66f4\u65b0\u77e5\u8b58\u7684 CoT \u7de8\u8f2f\u5668\uff0c\u53cd\u8986\u512a\u5316\u9019\u500b CoT \u7a0b\u5e8f\u3002\u6211\u5011\u5728\u6db5\u84cb\u591a\u7a2e\u8a9e\u8a00\u548c\u4efb\u52d9\u7684\u591a\u5143\u57fa\u6e96\u4e0a\u8a55\u4f30 EditCoT\u3002\u7d50\u679c\u8868\u660e\uff0c\u8207\u73fe\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6211\u5011\u7684\u505a\u6cd5\u9054\u5230\u4e86\u6700\u5148\u9032\u7684\u6548\u80fd\uff0c\u540c\u6642\u63d0\u4f9b\u4e86\u512a\u7570\u7684\u6982\u62ec\u6027\u3001\u6709\u6548\u6027\u548c\u7a69\u5b9a\u6027\uff0c\u6a19\u8a8c\u8457\u77e5\u8b58\u66f4\u65b0\u9818\u57df\u7684\u91cd\u5927\u9032\u5c55\u3002\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\u53ef\u65bc\u4ee5\u4e0b\u7db2\u5740\u53d6\u5f97\uff1ahttps://github.com/bebr2/EditCoT\u3002", "author": "Changyue Wang et.al.", "authors": "Changyue Wang, Weihang Su, Qingyao Ai, Yiqun Liu", "id": "2412.17727v1", "paper_url": "http://arxiv.org/abs/2412.17727v1", "repo": "https://github.com/bebr2/editcot"}}