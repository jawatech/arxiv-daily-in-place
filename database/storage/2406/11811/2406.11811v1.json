{"2406.11811": {"publish_time": "2024-06-17", "title": "RepLiQA: A Question-Answering Dataset for Benchmarking LLMs on Unseen Reference Content", "paper_summary": "Large Language Models (LLMs) are trained on vast amounts of data, most of\nwhich is automatically scraped from the internet. This data includes\nencyclopedic documents that harbor a vast amount of general knowledge (e.g.,\nWikipedia) but also potentially overlap with benchmark datasets used for\nevaluating LLMs. Consequently, evaluating models on test splits that might have\nleaked into the training set is prone to misleading conclusions. To foster\nsound evaluation of language models, we introduce a new test dataset named\nRepLiQA, suited for question-answering and topic retrieval tasks. RepLiQA is a\ncollection of five splits of test sets, four of which have not been released to\nthe internet or exposed to LLM APIs prior to this publication. Each sample in\nRepLiQA comprises (1) a reference document crafted by a human annotator and\ndepicting an imaginary scenario (e.g., a news article) absent from the\ninternet; (2) a question about the document's topic; (3) a ground-truth answer\nderived directly from the information in the document; and (4) the paragraph\nextracted from the reference document containing the answer. As such, accurate\nanswers can only be generated if a model can find relevant content within the\nprovided document. We run a large-scale benchmark comprising several\nstate-of-the-art LLMs to uncover differences in performance across models of\nvarious types and sizes in a context-conditional language modeling setting.\nReleased splits of RepLiQA can be found here:\nhttps://huggingface.co/datasets/ServiceNow/repliqa.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u662f\u5728\u5927\u91cf\u7684\u8cc7\u6599\u4e0a\u8a13\u7df4\u7684\uff0c\u5176\u4e2d\u5927\u90e8\u5206\u662f\u5f9e\u7db2\u8def\u4e0a\u81ea\u52d5\u6293\u53d6\u7684\u3002\u9019\u4e9b\u8cc7\u6599\u5305\u62ec\u5305\u542b\u5927\u91cf\u4e00\u822c\u77e5\u8b58\u7684\u767e\u79d1\u5168\u66f8\u6587\u4ef6\uff08\u4f8b\u5982\u7dad\u57fa\u767e\u79d1\uff09\uff0c\u4f46\u4e5f\u53ef\u80fd\u8207\u7528\u65bc\u8a55\u4f30 LLM \u7684\u57fa\u6e96\u8cc7\u6599\u96c6\u91cd\u758a\u3002\u56e0\u6b64\uff0c\u5728\u53ef\u80fd\u5df2\u6d29\u6f0f\u5230\u8a13\u7df4\u96c6\u4e2d\u7684\u6e2c\u8a66\u5206\u5272\u4e0a\u8a55\u4f30\u6a21\u578b\u5bb9\u6613\u5c0e\u81f4\u8aa4\u5c0e\u6027\u7684\u7d50\u8ad6\u3002\u70ba\u4e86\u4fc3\u9032\u8a9e\u8a00\u6a21\u578b\u7684\u5065\u5168\u8a55\u4f30\uff0c\u6211\u5011\u5f15\u5165\u4e86\u540d\u70ba RepLiQA \u7684\u65b0\u6e2c\u8a66\u8cc7\u6599\u96c6\uff0c\u9069\u7528\u65bc\u554f\u7b54\u548c\u4e3b\u984c\u6aa2\u7d22\u4efb\u52d9\u3002RepLiQA \u662f\u7531\u4e94\u500b\u6e2c\u8a66\u96c6\u5206\u5272\u7d44\u6210\u7684\u96c6\u5408\uff0c\u5176\u4e2d\u56db\u500b\u5728\u672c\u6b21\u767c\u5e03\u4e4b\u524d\u5c1a\u672a\u767c\u5e03\u5230\u7db2\u8def\u4e0a\u6216\u516c\u958b\u7d66 LLM API\u3002RepLiQA \u4e2d\u7684\u6bcf\u500b\u7bc4\u4f8b\u5305\u542b (1) \u7531\u4eba\u985e\u8a3b\u89e3\u8005\u7de8\u5beb\u7684\u53c3\u8003\u6587\u4ef6\uff0c\u63cf\u8ff0\u4e00\u500b\u4e0d\u5b58\u5728\u65bc\u7db2\u8def\u4e0a\u3001\u865b\u69cb\u7684\u60c5\u5883\uff08\u4f8b\u5982\u65b0\u805e\u6587\u7ae0\uff09\uff1b(2) \u95dc\u65bc\u6587\u4ef6\u4e3b\u984c\u7684\u554f\u984c\uff1b(3) \u76f4\u63a5\u5f9e\u6587\u4ef6\u4e2d\u7684\u8cc7\u8a0a\u884d\u751f\u7684\u57fa\u672c\u4e8b\u5be6\u7b54\u6848\uff1b\u4ee5\u53ca (4) \u5f9e\u5305\u542b\u7b54\u6848\u7684\u53c3\u8003\u6587\u4ef6\u4e2d\u6458\u9304\u7684\u6bb5\u843d\u3002\u56e0\u6b64\uff0c\u53ea\u6709\u7576\u6a21\u578b\u53ef\u4ee5\u5728\u63d0\u4f9b\u7684\u6587\u4ef6\u4e2d\u627e\u5230\u76f8\u95dc\u5167\u5bb9\u6642\uff0c\u624d\u80fd\u7522\u751f\u6e96\u78ba\u7684\u7b54\u6848\u3002\u6211\u5011\u57f7\u884c\u4e86\u4e00\u9805\u5927\u898f\u6a21\u57fa\u6e96\u6e2c\u8a66\uff0c\u5176\u4e2d\u5305\u542b\u591a\u500b\u6700\u5148\u9032\u7684 LLM\uff0c\u4ee5\u5728\u60c5\u5883\u689d\u4ef6\u8a9e\u8a00\u5efa\u6a21\u8a2d\u5b9a\u4e2d\u63ed\u793a\u5404\u7a2e\u985e\u578b\u548c\u898f\u6a21\u7684\u6a21\u578b\u4e4b\u9593\u7684\u6548\u80fd\u5dee\u7570\u3002RepLiQA \u7684\u5df2\u767c\u5e03\u5206\u5272\u53ef\u4ee5\u5728\u6b64\u8655\u627e\u5230\uff1ahttps://huggingface.co/datasets/ServiceNow/repliqa\u3002", "author": "Joao Monteiro et.al.", "authors": "Joao Monteiro, Pierre-Andre Noel, Etienne Marcotte, Sai Rajeswar, Valentina Zantedeschi, David Vazquez, Nicolas Chapados, Christopher Pal, Perouz Taslakian", "id": "2406.11811v1", "paper_url": "http://arxiv.org/abs/2406.11811v1", "repo": "null"}}