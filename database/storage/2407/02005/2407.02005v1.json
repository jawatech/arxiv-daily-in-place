{"2407.02005": {"publish_time": "2024-07-02", "title": "An End-to-End Speech Summarization Using Large Language Model", "paper_summary": "Abstractive Speech Summarization (SSum) aims to generate human-like text\nsummaries from spoken content. It encounters difficulties in handling long\nspeech input and capturing the intricate cross-modal mapping between long\nspeech inputs and short text summaries. Research on large language models\n(LLMs) and multimodal information fusion has provided new insights for\naddressing these challenges. In this paper, we propose an end-to-end SSum model\nthat utilizes Q-Former as a connector for the audio-text modality and employs\nLLMs to generate text summaries directly from speech features. We adopt a\nmulti-stage training approach that includes LLM based ASR and Text\nSummarization (TSum) tasks as auxiliary tasks. ASR tasks are used to align\nfeature spaces and enhance the LLM's ability to handle longer speech. Then, we\nutilize a curriculum learning strategy to facilitate the model's transition\nfrom TSum to SSum. Finally, our model achieves competitive performance on the\nHow-2 dataset.", "paper_summary_zh": "\u6458\u8981\u5f0f\u8a9e\u97f3\u6458\u8981 (SSum) \u7684\u76ee\u6a19\u662f\u5f9e\u53e3\u8aaa\u5167\u5bb9\u7522\u751f\u985e\u4f3c\u4eba\u985e\u7684\u6587\u5b57\u6458\u8981\u3002\u5b83\u5728\u8655\u7406\u9577\u8a9e\u97f3\u8f38\u5165\u548c\u64f7\u53d6\u9577\u8a9e\u97f3\u8f38\u5165\u8207\u77ed\u6587\u5b57\u6458\u8981\u4e4b\u9593\u8907\u96dc\u7684\u8de8\u6a21\u614b\u5c0d\u61c9\u6642\u6703\u9047\u5230\u56f0\u96e3\u3002\u95dc\u65bc\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u548c\u591a\u6a21\u614b\u8cc7\u8a0a\u878d\u5408\u7684\u7814\u7a76\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u6311\u6230\u63d0\u4f9b\u4e86\u65b0\u7684\u898b\u89e3\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u7aef\u5230\u7aef\u7684 SSum \u6a21\u578b\uff0c\u5b83\u5229\u7528 Q-Former \u4f5c\u70ba\u97f3\u8a0a\u6587\u5b57\u6a21\u614b\u7684\u9023\u63a5\u5668\uff0c\u4e26\u4f7f\u7528 LLM \u76f4\u63a5\u5f9e\u8a9e\u97f3\u7279\u5fb5\u7522\u751f\u6587\u5b57\u6458\u8981\u3002\u6211\u5011\u63a1\u7528\u591a\u968e\u6bb5\u8a13\u7df4\u65b9\u6cd5\uff0c\u5176\u4e2d\u5305\u62ec\u57fa\u65bc LLM \u7684 ASR \u548c\u6587\u5b57\u6458\u8981 (TSum) \u4efb\u52d9\u4f5c\u70ba\u8f14\u52a9\u4efb\u52d9\u3002ASR \u4efb\u52d9\u7528\u65bc\u5c0d\u9f4a\u7279\u5fb5\u7a7a\u9593\u4e26\u589e\u5f37 LLM \u8655\u7406\u8f03\u9577\u8a9e\u97f3\u7684\u80fd\u529b\u3002\u7136\u5f8c\uff0c\u6211\u5011\u5229\u7528\u8ab2\u7a0b\u5b78\u7fd2\u7b56\u7565\u4f86\u4fc3\u9032\u6a21\u578b\u5f9e TSum \u904e\u6e21\u5230 SSum\u3002\u6700\u5f8c\uff0c\u6211\u5011\u7684\u6a21\u578b\u5728 How-2 \u8cc7\u6599\u96c6\u4e0a\u53d6\u5f97\u4e86\u6709\u7af6\u722d\u529b\u7684\u8868\u73fe\u3002", "author": "Hengchao Shang et.al.", "authors": "Hengchao Shang, Zongyao Li, Jiaxin Guo, Shaojun Li, Zhiqiang Rao, Yuanchang Luo, Daimeng Wei, Hao Yang", "id": "2407.02005v1", "paper_url": "http://arxiv.org/abs/2407.02005v1", "repo": "null"}}