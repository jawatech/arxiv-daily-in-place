{"2411.02599": {"publish_time": "2024-11-04", "title": "Vocal Sandbox: Continual Learning and Adaptation for Situated Human-Robot Collaboration", "paper_summary": "We introduce Vocal Sandbox, a framework for enabling seamless human-robot\ncollaboration in situated environments. Systems in our framework are\ncharacterized by their ability to adapt and continually learn at multiple\nlevels of abstraction from diverse teaching modalities such as spoken dialogue,\nobject keypoints, and kinesthetic demonstrations. To enable such adaptation, we\ndesign lightweight and interpretable learning algorithms that allow users to\nbuild an understanding and co-adapt to a robot's capabilities in real-time, as\nthey teach new behaviors. For example, after demonstrating a new low-level\nskill for \"tracking around\" an object, users are provided with trajectory\nvisualizations of the robot's intended motion when asked to track a new object.\nSimilarly, users teach high-level planning behaviors through spoken dialogue,\nusing pretrained language models to synthesize behaviors such as \"packing an\nobject away\" as compositions of low-level skills $-$ concepts that can be\nreused and built upon. We evaluate Vocal Sandbox in two settings: collaborative\ngift bag assembly and LEGO stop-motion animation. In the first setting, we run\nsystematic ablations and user studies with 8 non-expert participants,\nhighlighting the impact of multi-level teaching. Across 23 hours of total robot\ninteraction time, users teach 17 new high-level behaviors with an average of 16\nnovel low-level skills, requiring 22.1% less active supervision compared to\nbaselines and yielding more complex autonomous performance (+19.7%) with fewer\nfailures (-67.1%). Qualitatively, users strongly prefer Vocal Sandbox systems\ndue to their ease of use (+20.6%) and overall performance (+13.9%). Finally, we\npair an experienced system-user with a robot to film a stop-motion animation;\nover two hours of continuous collaboration, the user teaches progressively more\ncomplex motion skills to shoot a 52 second (232 frame) movie.", "paper_summary_zh": "<paragraph>\u6211\u5011\u4ecb\u7d39 Vocal Sandbox\uff0c\u4e00\u500b\u5728\u7279\u5b9a\u74b0\u5883\u4e2d\u5be6\u73fe\u7121\u7e2b\u4eba\u6a5f\u5354\u4f5c\u7684\u6846\u67b6\u3002\u6211\u5011\u6846\u67b6\u4e2d\u7684\u7cfb\u7d71\u7279\u9ede\u5728\u65bc\u5b83\u5011\u80fd\u5920\u9069\u61c9\u4e26\u6301\u7e8c\u5f9e\u591a\u7a2e\u6559\u5b78\u6a21\u5f0f\u4e2d\u5b78\u7fd2\u591a\u500b\u62bd\u8c61\u5c64\u7d1a\uff0c\u4f8b\u5982\u53e3\u8a9e\u5c0d\u8a71\u3001\u7269\u4ef6\u95dc\u9375\u9ede\u548c\u52d5\u89ba\u793a\u7bc4\u3002\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u9069\u61c9\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u8f15\u91cf\u4e14\u53ef\u89e3\u91cb\u7684\u5b78\u7fd2\u6f14\u7b97\u6cd5\uff0c\u8b93\u4f7f\u7528\u8005\u80fd\u5920\u5efa\u7acb\u7406\u89e3\uff0c\u4e26\u5728\u6559\u6388\u65b0\u884c\u70ba\u6642\u5373\u6642\u5171\u540c\u9069\u61c9\u6a5f\u5668\u4eba\u7684\u80fd\u529b\u3002\u4f8b\u5982\uff0c\u5728\u793a\u7bc4\u4e86\u300c\u7e5e\u8457\u300d\u7269\u4ef6\u8ffd\u8e64\u7684\u65b0\u4f4e\u968e\u6280\u80fd\u5f8c\uff0c\u7576\u8981\u6c42\u8ffd\u8e64\u65b0\u7269\u4ef6\u6642\uff0c\u7cfb\u7d71\u6703\u63d0\u4f9b\u6a5f\u5668\u4eba\u9810\u671f\u52d5\u4f5c\u7684\u8ecc\u8de1\u8996\u89ba\u5316\u3002\u540c\u6a23\u5730\uff0c\u4f7f\u7528\u8005\u900f\u904e\u53e3\u8a9e\u5c0d\u8a71\u4f86\u6559\u6388\u9ad8\u968e\u898f\u5283\u884c\u70ba\uff0c\u4f7f\u7528\u9810\u5148\u8a13\u7df4\u7684\u8a9e\u8a00\u6a21\u578b\u4f86\u5408\u6210\u300c\u5c07\u7269\u4ef6\u6253\u5305\u300d\u7b49\u884c\u70ba\uff0c\u4f5c\u70ba\u4f4e\u968e\u6280\u80fd\u7684\u7d44\u5408\uff0c\u9019\u4e9b\u6982\u5ff5\u53ef\u4ee5\u91cd\u8907\u4f7f\u7528\u4e26\u52a0\u4ee5\u5efa\u69cb\u3002\u6211\u5011\u5728\u5169\u7a2e\u8a2d\u5b9a\u4e2d\u8a55\u4f30 Vocal Sandbox\uff1a\u5354\u4f5c\u79ae\u54c1\u888b\u7d44\u88dd\u548c\u6a02\u9ad8\u5b9a\u683c\u52d5\u756b\u3002\u5728\u7b2c\u4e00\u500b\u8a2d\u5b9a\u4e2d\uff0c\u6211\u5011\u91dd\u5c0d 8 \u4f4d\u975e\u5c08\u5bb6\u53c3\u8207\u8005\u57f7\u884c\u7cfb\u7d71\u6027\u6d88\u878d\u548c\u4f7f\u7528\u8005\u7814\u7a76\uff0c\u5f37\u8abf\u591a\u5c64\u7d1a\u6559\u5b78\u7684\u5f71\u97ff\u3002\u5728\u6a5f\u5668\u4eba\u4e92\u52d5\u6642\u9593\u7e3d\u8a08 23 \u5c0f\u6642\u4e2d\uff0c\u4f7f\u7528\u8005\u6559\u6388\u4e86 17 \u7a2e\u65b0\u7684\u9ad8\u968e\u884c\u70ba\uff0c\u5e73\u5747\u6709 16 \u7a2e\u65b0\u7a4e\u7684\u4f4e\u968e\u6280\u80fd\uff0c\u8207\u57fa\u6e96\u76f8\u6bd4\uff0c\u6240\u9700\u7684\u4e3b\u52d5\u76e3\u7763\u6e1b\u5c11\u4e86 22.1%\uff0c\u4e26\u4ee5\u8f03\u5c11\u7684\u5931\u6557\uff08-67.1%\uff09\u7522\u751f\u66f4\u8907\u96dc\u7684\u81ea\u4e3b\u6548\u80fd\uff08+19.7%\uff09\u3002\u5f9e\u8cea\u5316\u7684\u89d2\u5ea6\u4f86\u770b\uff0c\u4f7f\u7528\u8005\u5f37\u70c8\u504f\u597d Vocal Sandbox \u7cfb\u7d71\uff0c\u56e0\u70ba\u5b83\u5011\u6613\u65bc\u4f7f\u7528\uff08+20.6%\uff09\u4e14\u6574\u9ad4\u6548\u80fd\u8f03\u4f73\uff08+13.9%\uff09\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5c07\u4e00\u4f4d\u7d93\u9a57\u8c50\u5bcc\u7684\u7cfb\u7d71\u4f7f\u7528\u8005\u8207\u6a5f\u5668\u4eba\u914d\u5c0d\uff0c\u62cd\u651d\u5b9a\u683c\u52d5\u756b\uff1b\u5728\u6301\u7e8c\u5408\u4f5c\u7684\u5169\u500b\u5c0f\u6642\u4e2d\uff0c\u4f7f\u7528\u8005\u6559\u6388\u8d8a\u4f86\u8d8a\u8907\u96dc\u7684\u52d5\u4f5c\u6280\u80fd\uff0c\u62cd\u651d\u4e86\u4e00\u90e8 52 \u79d2\uff08232 \u5e40\uff09\u7684\u5f71\u7247\u3002</paragraph>", "author": "Jennifer Grannen et.al.", "authors": "Jennifer Grannen, Siddharth Karamcheti, Suvir Mirchandani, Percy Liang, Dorsa Sadigh", "id": "2411.02599v1", "paper_url": "http://arxiv.org/abs/2411.02599v1", "repo": "null"}}