
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-15**|**VeriGraph: Scene Graphs for Execution Verifiable Robot Planning**|Daniel Ekpo et.al.|[2411.10446v1](http://arxiv.org/abs/2411.10446v1)|null|
|**2024-11-15**|**Enhancing the Reasoning Ability of Multimodal Large Language Models via Mixed Preference Optimization**|Weiyun Wang et.al.|[2411.10442v1](http://arxiv.org/abs/2411.10442v1)|null|
|**2024-11-15**|**Mitigating Hallucination in Multimodal Large Language Model via Hallucination-targeted Direct Preference Optimization**|Yuhan Fu et.al.|[2411.10436v1](http://arxiv.org/abs/2411.10436v1)|null|
|**2024-11-15**|**Mitigating Parameter Degeneracy using Joint Conditional Diffusion Model for WECC Composite Load Model in Power Systems**|Feiqin Zhu et.al.|[2411.10431v1](http://arxiv.org/abs/2411.10431v1)|null|
|**2024-11-15**|**Evaluating Creativity and Deception in Large Language Models: A Simulation Framework for Multi-Agent Balderdash**|Parsa Hejabi et.al.|[2411.10422v1](http://arxiv.org/abs/2411.10422v1)|[link](https://github.com/parsahejabi/simulation-framework-for-multi-agent-balderdash)|
|**2024-11-15**|**Llama Guard 3 Vision: Safeguarding Human-AI Image Understanding Conversations**|Jianfeng Chi et.al.|[2411.10414v1](http://arxiv.org/abs/2411.10414v1)|null|
|**2024-11-15**|**Repurposing Stable Diffusion Attention for Training-Free Unsupervised Interactive Segmentation**|Markus Karmann et.al.|[2411.10411v1](http://arxiv.org/abs/2411.10411v1)|null|
|**2024-11-15**|**Features that Make a Difference: Leveraging Gradients for Improved Dictionary Learning**|Jeffrey Olmo et.al.|[2411.10397v1](http://arxiv.org/abs/2411.10397v1)|null|
|**2024-11-15**|**Deep Learning for Micro-Scale Crack Detection on Imbalanced Datasets Using Key Point Localization**|Fatahlla Moreh et.al.|[2411.10389v1](http://arxiv.org/abs/2411.10389v1)|null|
|**2024-11-15**|**Low-Latency Task-Oriented Communications with Multi-Round, Multi-Task Deep Learning**|Yalin E. Sagduyu et.al.|[2411.10385v1](http://arxiv.org/abs/2411.10385v1)|null|
|**2024-11-15**|**A Survey of Event Causality Identification: Principles, Taxonomy, Challenges, and Assessment**|Zefan Zeng et.al.|[2411.10371v1](http://arxiv.org/abs/2411.10371v1)|null|
|**2024-11-15**|**Towards High-Fidelity 3D Portrait Generation with Rich Details by Cross-View Prior-Aware Diffusion**|Haoran Wei et.al.|[2411.10369v1](http://arxiv.org/abs/2411.10369v1)|null|
|**2024-11-15**|**Mechanisms of Generative Image-to-Image Translation Networks**|Guangzong Chen et.al.|[2411.10368v1](http://arxiv.org/abs/2411.10368v1)|null|
|**2024-11-15**|**Domain Adaptation-based Edge Computing for Cross-Conditions Fault Diagnosis**|Yanzhi Wang et.al.|[2411.10340v1](http://arxiv.org/abs/2411.10340v1)|null|
|**2024-11-15**|**Safe Text-to-Image Generation: Simply Sanitize the Prompt Embedding**|Huming Qiu et.al.|[2411.10329v1](http://arxiv.org/abs/2411.10329v1)|null|
|**2024-11-15**|**Emotion Detection in Reddit: Comparative Study of Machine Learning and Deep Learning Techniques**|Maliheh Alaeddini et.al.|[2411.10328v1](http://arxiv.org/abs/2411.10328v1)|null|
|**2024-11-15**|**The Dawn of GUI Agent: A Preliminary Case Study with Claude 3.5 Computer Use**|Siyuan Hu et.al.|[2411.10323v1](http://arxiv.org/abs/2411.10323v1)|[link](https://github.com/showlab/computer_use_ootb)|
|**2024-11-15**|**Unveiling Topological Structures in Text: A Comprehensive Survey of Topological Data Analysis Applications in NLP**|Adaku Uchendu et.al.|[2411.10298v1](http://arxiv.org/abs/2411.10298v1)|null|
|**2024-11-15**|**Scaling Law for Post-training after Model Pruning**|Xiaodong Chen et.al.|[2411.10272v1](http://arxiv.org/abs/2411.10272v1)|null|
|**2024-11-15**|**The Unreasonable Effectiveness of Guidance for Diffusion Models**|Tim Kaiser et.al.|[2411.10257v1](http://arxiv.org/abs/2411.10257v1)|null|
|**2024-11-15**|**Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**|Mohammed Yaseen Jabarulla et.al.|[2411.10255v1](http://arxiv.org/abs/2411.10255v1)|null|
|**2024-11-15**|**Scaling up the Evaluation of Collaborative Problem Solving: Promises and Challenges of Coding Chat Data with ChatGPT**|Jiangang Hao et.al.|[2411.10246v1](http://arxiv.org/abs/2411.10246v1)|null|
|**2024-11-15**|**Measuring Non-Adversarial Reproduction of Training Data in Large Language Models**|Michael Aerni et.al.|[2411.10242v1](http://arxiv.org/abs/2411.10242v1)|null|
|**2024-11-15**|**Generative AI in Multimodal User Interfaces: Trends, Challenges, and Cross-Platform Adaptability**|J. Bieniek et.al.|[2411.10234v1](http://arxiv.org/abs/2411.10234v1)|null|
|**2024-11-15**|**ColorEdit: Training-free Image-Guided Color editing with diffusion model**|Xingxi Yin et.al.|[2411.10232v1](http://arxiv.org/abs/2411.10232v1)|null|
|**2024-11-15**|**A Low-Resolution Image is Worth 1x1 Words: Enabling Fine Image Super-Resolution with Transformers and TaylorShift**|Sanath Budakegowdanadoddi Nagaraju et.al.|[2411.10231v1](http://arxiv.org/abs/2411.10231v1)|null|
|**2024-11-15**|**Entropy and type-token ratio in gigaword corpora**|Pablo Rosillo-Rodes et.al.|[2411.10227v1](http://arxiv.org/abs/2411.10227v1)|null|
|**2024-11-15**|**An Empirical Study on LLM-based Agents for Automated Bug Fixing**|Xiangxin Meng et.al.|[2411.10213v1](http://arxiv.org/abs/2411.10213v1)|null|
|**2024-11-15**|**FengWu-W2S: A deep learning model for seamless weather-to-subseasonal forecast of global atmosphere**|Fenghua Ling et.al.|[2411.10191v1](http://arxiv.org/abs/2411.10191v1)|null|
|**2024-11-15**|**Agentic LLMs in the Supply Chain: Towards Autonomous Multi-Agent Consensus-Seeking**|Valeria Jannelli et.al.|[2411.10184v1](http://arxiv.org/abs/2411.10184v1)|null|
|**2024-11-15**|**The Surprising Ineffectiveness of Pre-Trained Visual Representations for Model-Based Reinforcement Learning**|Moritz Schneider et.al.|[2411.10175v1](http://arxiv.org/abs/2411.10175v1)|null|
|**2024-11-15**|**A Hard-Label Cryptanalytic Extraction of Non-Fully Connected Deep Neural Networks using Side-Channel Attacks**|Benoit Coqueret et.al.|[2411.10174v1](http://arxiv.org/abs/2411.10174v1)|null|
|**2024-11-15**|**Increasing the Accessibility of Causal Domain Knowledge via Causal Information Extraction Methods: A Case Study in the Semiconductor Manufacturing Industry**|Houssam Razouk et.al.|[2411.10172v1](http://arxiv.org/abs/2411.10172v1)|null|
|**2024-11-15**|**Imagine-2-Drive: High-Fidelity World Modeling in CARLA for Autonomous Vehicles**|Anant Garg et.al.|[2411.10171v1](http://arxiv.org/abs/2411.10171v1)|null|
|**2024-11-15**|**Evaluating the role of `Constitutions' for learning from AI feedback**|Saskia Redgate et.al.|[2411.10168v1](http://arxiv.org/abs/2411.10168v1)|null|
|**2024-11-15**|**Compound-QA: A Benchmark for Evaluating LLMs on Compound Questions**|Yutao Hou et.al.|[2411.10163v1](http://arxiv.org/abs/2411.10163v1)|null|
|**2024-11-15**|**Mitigating Sycophancy in Decoder-Only Transformer Architectures: Synthetic Data Intervention**|Libo Wang et.al.|[2411.10156v1](http://arxiv.org/abs/2411.10156v1)|[link](https://github.com/brucewang123456789/GeniusTrail)|
|**2024-11-15**|**Causal Time-Series Synchronization for Multi-Dimensional Forecasting**|Michael Mayr et.al.|[2411.10152v1](http://arxiv.org/abs/2411.10152v1)|null|
|**2024-11-15**|**An Effective Framework to Help Large Language Models Handle Numeric-involved Long-context Tasks**|Yijiong Yu et.al.|[2411.10145v1](http://arxiv.org/abs/2411.10145v1)|null|
|**2024-11-15**|**Legal Evalutions and Challenges of Large Language Models**|Jiaqi Wang et.al.|[2411.10137v1](http://arxiv.org/abs/2411.10137v1)|null|
|**2024-11-15**|**Prompting and Fine-tuning Large Language Models for Automated Code Review Comment Generation**|Md. Asif Haider et.al.|[2411.10129v1](http://arxiv.org/abs/2411.10129v1)|null|
|**2024-11-15**|**Memorization in Attention-only Transformers**|Léo Dana et.al.|[2411.10115v1](http://arxiv.org/abs/2411.10115v1)|null|
|**2024-11-15**|**Generative Agent Simulations of 1,000 People**|Joon Sung Park et.al.|[2411.10109v1](http://arxiv.org/abs/2411.10109v1)|null|
|**2024-11-15**|**Identifying Key Drivers of Heatwaves: A Novel Spatio-Temporal Framework for Extreme Event Detection**|J. Pérez-Aracil et.al.|[2411.10108v1](http://arxiv.org/abs/2411.10108v1)|null|
|**2024-11-15**|**Multi-Task Adversarial Variational Autoencoder for Estimating Biological Brain Age with Multimodal Neuroimaging**|Muhammad Usman et.al.|[2411.10100v1](http://arxiv.org/abs/2411.10100v1)|null|
|**2024-11-15**|**PFML: Self-Supervised Learning of Time-Series Data Without Representation Collapse**|Einari Vaaras et.al.|[2411.10087v1](http://arxiv.org/abs/2411.10087v1)|null|
|**2024-11-15**|**Adapting the Biological SSVEP Response to Artificial Neural Networks**|Emirhan Böge et.al.|[2411.10084v1](http://arxiv.org/abs/2411.10084v1)|null|
|**2024-11-15**|**Xmodel-1.5: An 1B-scale Multilingual LLM**|Wang Qun et.al.|[2411.10083v1](http://arxiv.org/abs/2411.10083v1)|[link](https://github.com/xiaoduoailab/xmodellm)|
|**2024-11-15**|**Understanding The Effect Of Temperature On Alignment With Human Opinions**|Maja Pavlovic et.al.|[2411.10080v1](http://arxiv.org/abs/2411.10080v1)|null|
|**2024-11-15**|**Real-Time AI-Driven People Tracking and Counting Using Overhead Cameras**|Ishrath Ahamed et.al.|[2411.10072v1](http://arxiv.org/abs/2411.10072v1)|null|
|**2024-11-15**|**Evidential Federated Learning for Skin Lesion Image Classification**|Rutger Hendrix et.al.|[2411.10071v1](http://arxiv.org/abs/2411.10071v1)|null|
|**2024-11-15**|**Layer Importance and Hallucination Analysis in Large Language Models via Enhanced Activation Variance-Sparsity**|Zichen Song et.al.|[2411.10069v1](http://arxiv.org/abs/2411.10069v1)|null|
|**2024-11-15**|**Federated Domain Generalization via Prompt Learning and Aggregation**|Shuai Gong et.al.|[2411.10063v1](http://arxiv.org/abs/2411.10063v1)|[link](https://github.com/GongShuai8210/PLAN)|
|**2024-11-15**|**CMATH: Cross-Modality Augmented Transformer with Hierarchical Variational Distillation for Multimodal Emotion Recognition in Conversation**|Xiaofei Zhu et.al.|[2411.10060v1](http://arxiv.org/abs/2411.10060v1)|null|
|**2024-11-15**|**KuaiFormer: Transformer-Based Retrieval at Kuaishou**|Chi Liu et.al.|[2411.10057v1](http://arxiv.org/abs/2411.10057v1)|null|
|**2024-11-15**|**Towards unearthing neglected climate innovations from scientific literature using Large Language Models**|César Quilodrán-Casas et.al.|[2411.10055v1](http://arxiv.org/abs/2411.10055v1)|null|
|**2024-11-15**|**Jal Anveshak: Prediction of fishing zones using fine-tuned LlaMa 2**|Arnav Mejari et.al.|[2411.10050v1](http://arxiv.org/abs/2411.10050v1)|null|
|**2024-11-15**|**VMID: A Multimodal Fusion LLM Framework for Detecting and Identifying Misinformation of Short Videos**|Weihao Zhong et.al.|[2411.10032v1](http://arxiv.org/abs/2411.10032v1)|null|
|**2024-11-15**|**MOT\_FCG++: Enhanced Representation of Motion and Appearance Features**|Yanzhao Fang et.al.|[2411.10028v1](http://arxiv.org/abs/2411.10028v1)|null|
|**2024-11-15**|**Information Extraction from Clinical Notes: Are We Ready to Switch to Large Language Models?**|Yan Hu et.al.|[2411.10020v1](http://arxiv.org/abs/2411.10020v1)|null|
|**2024-11-15**|**Once More, With Feeling: Measuring Emotion of Acting Performances in Contemporary American Film**|Naitian Zhou et.al.|[2411.10018v1](http://arxiv.org/abs/2411.10018v1)|null|
|**2024-11-15**|**MicroCrackAttentionNeXt: Advancing Microcrack Detection in Wave Field Analysis Using Deep Neural Networks through Feature Visualization**|Fatahlla Moreh et.al.|[2411.10015v1](http://arxiv.org/abs/2411.10015v1)|null|
|**2024-11-15**|**DeepMedcast: A Deep Learning Method for Generating Intermediate Weather Forecasts among Multiple NWP Models**|Atsushi Kudo et.al.|[2411.10010v1](http://arxiv.org/abs/2411.10010v1)|null|
|**2024-11-15**|**Graph-based Complexity for Causal Effect by Empirical Plug-in**|Rina Dechter et.al.|[2411.10008v1](http://arxiv.org/abs/2411.10008v1)|null|
|**2024-11-15**|**Orca: Enhancing Role-Playing Abilities of Large Language Models by Integrating Personality Traits**|Yuxuan Huang et.al.|[2411.10006v1](http://arxiv.org/abs/2411.10006v1)|null|
|**2024-11-15**|**EyeDiff: text-to-image diffusion model improves rare eye disease diagnosis**|Ruoyu Chen et.al.|[2411.10004v1](http://arxiv.org/abs/2411.10004v1)|null|
|**2024-11-15**|**DuSEGO: Dual Second-order Equivariant Graph Ordinary Differential Equation**|Yingxu Wang et.al.|[2411.10000v1](http://arxiv.org/abs/2411.10000v1)|null|
|**2024-11-15**|**Building 6G Radio Foundation Models with Transformer Architectures**|Ahmed Aboulfotouh et.al.|[2411.09996v1](http://arxiv.org/abs/2411.09996v1)|null|
|**2024-11-15**|**Unlocking Transfer Learning for Open-World Few-Shot Recognition**|Byeonggeun Kim et.al.|[2411.09986v1](http://arxiv.org/abs/2411.09986v1)|null|
|**2024-11-15**|**HistoLens: An LLM-Powered Framework for Multi-Layered Analysis of Historical Texts -- A Case Application of Yantie Lun**|Yifan Zeng et.al.|[2411.09978v1](http://arxiv.org/abs/2411.09978v1)|null|
|**2024-11-15**|**Large Language Models as User-Agents for Evaluating Task-Oriented-Dialogue Systems**|Taaha Kazi et.al.|[2411.09972v1](http://arxiv.org/abs/2411.09972v1)|null|
|**2024-11-15**|**Steering AI-Driven Personalization of Scientific Text for General Audiences**|Taewook Kim et.al.|[2411.09969v1](http://arxiv.org/abs/2411.09969v1)|null|
|**2024-11-15**|**Seeing Clearly by Layer Two: Enhancing Attention Heads to Alleviate Hallucination in LVLMs**|Xiaofeng Zhang et.al.|[2411.09968v1](http://arxiv.org/abs/2411.09968v1)|null|
|**2024-11-15**|**Instruction-Guided Editing Controls for Images and Multimedia: A Survey in LLM era**|Thanh Tam Nguyen et.al.|[2411.09955v1](http://arxiv.org/abs/2411.09955v1)|null|
|**2024-11-15**|**GGAvatar: Reconstructing Garment-Separated 3D Gaussian Splatting Avatars from Monocular Video**|Jingxuan Chen et.al.|[2411.09952v1](http://arxiv.org/abs/2411.09952v1)|[link](https://github.com/j-x-chen/ggavatar)|
|**2024-11-15**|**LoRA-LiteE: A Computationally Efficient Framework for Chatbot Preference-Tuning**|Yahe Yang et.al.|[2411.09947v1](http://arxiv.org/abs/2411.09947v1)|null|
|**2024-11-15**|**TEESlice: Protecting Sensitive Neural Network Models in Trusted Execution Environments When Attackers have Pre-Trained Models**|Ding Li et.al.|[2411.09945v1](http://arxiv.org/abs/2411.09945v1)|null|
|**2024-11-15**|**SlimLM: An Efficient Small Language Model for On-Device Document Assistance**|Thang M. Pham et.al.|[2411.09944v1](http://arxiv.org/abs/2411.09944v1)|null|
|**2024-11-15**|**Refined and Segmented Price Sentiment Indices from Survey Comments**|Masahiro Suzuki et.al.|[2411.09937v1](http://arxiv.org/abs/2411.09937v1)|null|
|**2024-11-15**|**JRadiEvo: A Japanese Radiology Report Generation Model Enhanced by Evolutionary Optimization of Model Merging**|Kaito Baba et.al.|[2411.09933v1](http://arxiv.org/abs/2411.09933v1)|null|
|**2024-11-15**|**Motion-Grounded Video Reasoning: Understanding and Perceiving Motion at Pixel Level**|Andong Deng et.al.|[2411.09921v1](http://arxiv.org/abs/2411.09921v1)|null|
|**2024-11-15**|**AMXFP4: Taming Activation Outliers with Asymmetric Microscaling Floating-Point for 4-bit LLM Inference**|Janghwan Lee et.al.|[2411.09909v1](http://arxiv.org/abs/2411.09909v1)|null|
|**2024-11-15**|**Statistical Analysis of Policy Space Compression Problem**|Majid Molaei et.al.|[2411.09900v1](http://arxiv.org/abs/2411.09900v1)|null|
|**2024-11-15**|**Research on Domain-Specific Chinese Spelling Correction Method Based on Plugin Extension Modules**|Xiaowu Zhang et.al.|[2411.09884v1](http://arxiv.org/abs/2411.09884v1)|null|
|**2024-11-15**|**A Hybrid Artificial Intelligence System for Automated EEG Background Analysis and Report Generation**|Chin-Sung Tung et.al.|[2411.09874v1](http://arxiv.org/abs/2411.09874v1)|[link](https://github.com/tcs211/ai_eeeg_report)|
|**2024-11-15**|**Enhancing Diffusion Posterior Sampling for Inverse Problems by Integrating Crafted Measurements**|Shijie Zhou et.al.|[2411.09850v1](http://arxiv.org/abs/2411.09850v1)|null|
|**2024-11-14**|**Self-Supervised Radio Pre-training: Toward Foundational Models for Spectrogram Learning**|Ahmed Aboulfotouh et.al.|[2411.09849v1](http://arxiv.org/abs/2411.09849v1)|null|
|**2024-11-14**|**Deep Autoencoders for Unsupervised Anomaly Detection in Wildfire Prediction**|İrem Üstek et.al.|[2411.09844v1](http://arxiv.org/abs/2411.09844v1)|null|
|**2024-11-14**|**Real-time Adapting Routing (RAR): Improving Efficiency Through Continuous Learning in Software Powered by Layered Foundation Models**|Kirill Vasilevski et.al.|[2411.09837v1](http://arxiv.org/abs/2411.09837v1)|null|
|**2024-11-14**|**A Benchmark for Long-Form Medical Question Answering**|Pedram Hosseini et.al.|[2411.09834v1](http://arxiv.org/abs/2411.09834v1)|[link](https://github.com/lavita-ai/medical-eval-sphere)|
|**2024-11-14**|**Evaluating Gender Bias in Large Language Models**|Michael Döll et.al.|[2411.09826v1](http://arxiv.org/abs/2411.09826v1)|null|
|**2024-11-14**|**A Self-Supervised Model for Multi-modal Stroke Risk Prediction**|Camille Delgrange et.al.|[2411.09822v1](http://arxiv.org/abs/2411.09822v1)|null|
|**2024-11-14**|**WelQrate: Defining the Gold Standard in Small Molecule Drug Discovery Benchmarking**|Yunchao et.al.|[2411.09820v1](http://arxiv.org/abs/2411.09820v1)|null|
|**2024-11-14**|**Evaluating Loss Landscapes from a Topology Perspective**|Tiankai Xie et.al.|[2411.09807v1](http://arxiv.org/abs/2411.09807v1)|null|
|**2024-11-14**|**Deep Learning for Fetal Inflammatory Response Diagnosis in the Umbilical Cord**|Marina A. Ayad et.al.|[2411.09767v1](http://arxiv.org/abs/2411.09767v1)|null|
|**2024-11-14**|**Evaluating the Predictive Capacity of ChatGPT for Academic Peer Review Outcomes Across Multiple Platforms**|Mike Thelwall et.al.|[2411.09763v1](http://arxiv.org/abs/2411.09763v1)|null|
|**2024-11-14**|**On the Surprising Effectiveness of Attention Transfer for Vision Transformers**|Alexander C. Li et.al.|[2411.09702v1](http://arxiv.org/abs/2411.09702v1)|null|
|**2024-11-14**|**A Bayesian Optimization Approach to Machine Translation Reranking**|Julius Cheng et.al.|[2411.09694v1](http://arxiv.org/abs/2411.09694v1)|null|
|**2024-11-14**|**LLM Hallucination Reasoning with Zero-shot Knowledge Test**|Seongmin Lee et.al.|[2411.09689v1](http://arxiv.org/abs/2411.09689v1)|null|
|**2024-11-14**|**Squeezed Attention: Accelerating Long Context Length LLM Inference**|Coleman Hooper et.al.|[2411.09688v1](http://arxiv.org/abs/2411.09688v1)|null|

#### Abstracts
##### **VeriGraph: Scene Graphs for Execution Verifiable Robot Planning**
2411.10446v1 by Daniel Ekpo, Mara Levy, Saksham Suri, Chuong Huynh, Abhinav Shrivastava

Recent advancements in vision-language models (VLMs) offer potential for
robot task planning, but challenges remain due to VLMs' tendency to generate
incorrect action sequences. To address these limitations, we propose VeriGraph,
a novel framework that integrates VLMs for robotic planning while verifying
action feasibility. VeriGraph employs scene graphs as an intermediate
representation, capturing key objects and spatial relationships to improve plan
verification and refinement. The system generates a scene graph from input
images and uses it to iteratively check and correct action sequences generated
by an LLM-based task planner, ensuring constraints are respected and actions
are executable. Our approach significantly enhances task completion rates
across diverse manipulation scenarios, outperforming baseline methods by 58%
for language-based tasks and 30% for image-based tasks.

摘要：最近在視覺語言模型 (VLM) 的進步為機器人任務規劃提供了可能性，但由於 VLM 容易產生不正確的動作序列，因此挑戰仍然存在。為了解決這些限制，我們提出了 VeriGraph，一個將 VLM 整合到機器人規劃中的創新架構，同時驗證動作的可行性。VeriGraph 使用場景圖作為中間表示，捕捉關鍵物件和空間關係以改善計畫驗證和精煉。該系統從輸入影像產生場景圖，並使用它來反覆檢查和修正 LLM 基於任務規劃器產生的動作序列，確保符合約束條件且動作可執行。我們的做法大幅提升了各種操作場景中的任務完成率，在基於語言的任務中比基線方法高出 58%，在基於影像的任務中高出 30%。

##### **Enhancing the Reasoning Ability of Multimodal Large Language Models via Mixed Preference Optimization**
2411.10442v1 by Weiyun Wang, Zhe Chen, Wenhai Wang, Yue Cao, Yangzhou Liu, Zhangwei Gao, Jinguo Zhu, Xizhou Zhu, Lewei Lu, Yu Qiao, Jifeng Dai

Existing open-source multimodal large language models (MLLMs) generally
follow a training process involving pre-training and supervised fine-tuning.
However, these models suffer from distribution shifts, which limit their
multimodal reasoning, particularly in the Chain-of-Thought (CoT) performance.
To address this, we introduce a preference optimization (PO) process to enhance
the multimodal reasoning capabilities of MLLMs. Specifically, (1) on the data
side, we design an automated preference data construction pipeline to create
MMPR, a high-quality, large-scale multimodal reasoning preference dataset. and
(2) on the model side, we explore integrating PO with MLLMs, developing a
simple yet effective method, termed Mixed Preference Optimization (MPO), which
boosts multimodal CoT performance. Our approach demonstrates improved
performance across multiple benchmarks, particularly in multimodal reasoning
tasks. Notably, our model, InternVL2-8B-MPO, achieves an accuracy of 67.0 on
MathVista, outperforming InternVL2-8B by 8.7 points and achieving performance
comparable to the 10x larger InternVL2-76B. We hope this study could inspire
further advancements in MLLMs. Code, data, and model shall be publicly
released.

摘要：現有的開源多模態大型語言模型 (MMLM) 通常遵循一個包含預訓練和監督微調的訓練流程。然而，這些模型會受到分佈轉移的影響，這會限制它們的多模態推理，特別是在思考鏈 (CoT) 效能方面。為了解決這個問題，我們引入了一個偏好最佳化 (PO) 流程來增強 MMLM 的多模態推理能力。具體來說，(1) 在資料方面，我們設計了一個自動化偏好資料建構管線來建立 MMPR，一個高品質、大規模的多模態推理偏好資料集。以及 (2) 在模型方面，我們探索將 PO 與 MLLM 整合，開發一種簡單但有效的方法，稱為混合偏好最佳化 (MPO)，它可以提升多模態 CoT 效能。我們的做法證明了在多個基準測試中都有改進的效能，特別是在多模態推理任務中。值得注意的是，我們的模型 InternVL2-8B-MPO 在 MathVista 上達到了 67.0 的準確度，比 InternVL2-8B 高出 8.7 個百分點，並達到了與大 10 倍的 InternVL2-76B 相當的效能。我們希望這項研究能激勵 MLLM 的進一步發展。程式碼、資料和模型將公開發布。

##### **Mitigating Hallucination in Multimodal Large Language Model via Hallucination-targeted Direct Preference Optimization**
2411.10436v1 by Yuhan Fu, Ruobing Xie, Xingwu Sun, Zhanhui Kang, Xirong Li

Multimodal Large Language Models (MLLMs) are known to hallucinate, which
limits their practical applications. Recent works have attempted to apply
Direct Preference Optimization (DPO) to enhance the performance of MLLMs, but
have shown inconsistent improvements in mitigating hallucinations. To address
this issue more effectively, we introduce Hallucination-targeted Direct
Preference Optimization (HDPO) to reduce hallucinations in MLLMs. Unlike
previous approaches, our method tackles hallucinations from their diverse forms
and causes. Specifically, we develop three types of preference pair data
targeting the following causes of MLLM hallucinations: (1) insufficient visual
capabilities, (2) long context generation, and (3) multimodal conflicts.
Experimental results demonstrate that our method achieves superior performance
across multiple hallucination evaluation datasets, surpassing most
state-of-the-art (SOTA) methods and highlighting the potential of our approach.
Ablation studies and in-depth analyses further confirm the effectiveness of our
method and suggest the potential for further improvements through scaling up.

摘要：多模态大型语言模型 (MLLM) 会出现幻觉，这限制了它们的实际应用。最近的研究尝试应用直接偏好优化 (DPO) 来增强 MLLM 的性能，但在减轻幻觉方面表现并不一致。为了更有效地解决这个问题，我们引入了幻觉目标直接偏好优化 (HDPO) 来减少 MLLM 中的幻觉。与以前的方法不同，我们的方法从其不同的形式和原因来解决幻觉。具体来说，我们针对以下 MLLM 幻觉原因开发了三种类型的偏好对数据：(1) 视觉能力不足，(2) 长上下文生成，以及 (3) 多模态冲突。实验结果表明，我们的方法在多个幻觉评估数据集上实现了卓越的性能，超越了大多数最先进 (SOTA) 方法，并突出了我们方法的潜力。消融研究和深入分析进一步证实了我们方法的有效性，并表明通过扩展可以进一步改进。

##### **Mitigating Parameter Degeneracy using Joint Conditional Diffusion Model for WECC Composite Load Model in Power Systems**
2411.10431v1 by Feiqin Zhu, Dmitrii Torbunov, Yihui Ren, Zhongjing Jiang, Tianqiao Zhao, Amirthagunaraj Yogarathnam, Meng Yue

Data-driven modeling for dynamic systems has gained widespread attention in
recent years. Its inverse formulation, parameter estimation, aims to infer the
inherent model parameters from observations. However, parameter degeneracy,
where different combinations of parameters yield the same observable output,
poses a critical barrier to accurately and uniquely identifying model
parameters. In the context of WECC composite load model (CLM) in power systems,
utility practitioners have observed that CLM parameters carefully selected for
one fault event may not perform satisfactorily in another fault. Here, we
innovate a joint conditional diffusion model-based inverse problem solver
(JCDI), that incorporates a joint conditioning architecture with simultaneous
inputs of multi-event observations to improve parameter generalizability.
Simulation studies on the WECC CLM show that the proposed JCDI effectively
reduces uncertainties of degenerate parameters, thus the parameter estimation
error is decreased by 42.1% compared to a single-event learning scheme. This
enables the model to achieve high accuracy in predicting power trajectories
under different fault events, including electronic load tripping and motor
stalling, outperforming standard deep reinforcement learning and supervised
learning approaches. We anticipate this work will contribute to mitigating
parameter degeneracy in system dynamics, providing a general parameter
estimation framework across various scientific domains.

摘要：<paragraph>近年来，数据驱动建模在动态系统中获得了广泛的关注。其逆向公式，参数估计，旨在从观测中推断出固有的模型参数。然而，参数退化，其中不同组合的参数产生相同的可观察输出，对准确和唯一地识别模型参数构成了一个关键障碍。在电力系统中 WECC 复合负载模型 (CLM) 的背景下，电力从业者观察到，为一个故障事件精心选择的 CLM 参数可能无法在另一个故障中令人满意地执行。在这里，我们创新了一种联合条件扩散模型的逆问题求解器 (JCDI)，它结合了联合条件架构，同时输入多事件观测，以提高参数的可概括性。对 WECC CLM 的模拟研究表明，所提出的 JCDI 有效地减少了退化参数的不确定性，因此与单事件学习方案相比，参数估计误差降低了 42.1%。这使得该模型能够在预测不同故障事件下的功率轨迹方面实现高精度，包括电子负载跳闸和电机失速，优于标准深度强化学习和监督学习方法。我们预计这项工作将有助于减轻系统动力学中的参数退化，为各个科学领域提供一个通用的参数估计框架。</paragraph>

##### **Evaluating Creativity and Deception in Large Language Models: A Simulation Framework for Multi-Agent Balderdash**
2411.10422v1 by Parsa Hejabi, Elnaz Rahmati, Alireza S. Ziabari, Preni Golazizian, Jesse Thomason, Morteza Dehghani

Large Language Models (LLMs) have shown impressive capabilities in complex
tasks and interactive environments, yet their creativity remains underexplored.
This paper introduces a simulation framework utilizing the game Balderdash to
evaluate both the creativity and logical reasoning of LLMs. In Balderdash,
players generate fictitious definitions for obscure terms to deceive others
while identifying correct definitions. Our framework enables multiple LLM
agents to participate in this game, assessing their ability to produce
plausible definitions and strategize based on game rules and history. We
implemented a centralized game engine featuring various LLMs as participants
and a judge LLM to evaluate semantic equivalence. Through a series of
experiments, we analyzed the performance of different LLMs, examining metrics
such as True Definition Ratio, Deception Ratio, and Correct Guess Ratio. The
results provide insights into the creative and deceptive capabilities of LLMs,
highlighting their strengths and areas for improvement. Specifically, the study
reveals that infrequent vocabulary in LLMs' input leads to poor reasoning on
game rules and historical context
(https://github.com/ParsaHejabi/Simulation-Framework-for-Multi-Agent-Balderdash).

摘要：大型語言模型（LLM）在複雜任務和互動環境中展現令人印象深刻的能力，但其創造力仍未被充分探討。本文介紹了一個模擬框架，利用遊戲「胡說八道」來評估 LLM 的創造力和邏輯推理能力。在「胡說八道」中，玩家為晦澀的詞彙產生虛構的定義以欺騙他人，同時找出正確的定義。我們的框架讓多個 LLM 代理參與這個遊戲，評估它們產生合理定義和根據遊戲規則和歷史制定策略的能力。我們實作了一個集中式的遊戲引擎，其中包含各種 LLM 作為參與者，以及一個評估語義等價性的評審 LLM。透過一系列實驗，我們分析了不同 LLM 的表現，檢視了真實定義比率、欺騙比率和正確猜測比率等指標。結果提供了對 LLM 創造力和欺騙能力的見解，突顯了它們的優點和改進領域。具體來說，研究顯示 LLM 輸入中的不常用詞彙會導致對遊戲規則和歷史背景的推理不佳（https://github.com/ParsaHejabi/Simulation-Framework-for-Multi-Agent-Balderdash）。

##### **Llama Guard 3 Vision: Safeguarding Human-AI Image Understanding Conversations**
2411.10414v1 by Jianfeng Chi, Ujjwal Karn, Hongyuan Zhan, Eric Smith, Javier Rando, Yiming Zhang, Kate Plawiak, Zacharie Delpierre Coudert, Kartikeya Upasani, Mahesh Pasupuleti

We introduce Llama Guard 3 Vision, a multimodal LLM-based safeguard for
human-AI conversations that involves image understanding: it can be used to
safeguard content for both multimodal LLM inputs (prompt classification) and
outputs (response classification). Unlike the previous text-only Llama Guard
versions (Inan et al., 2023; Llama Team, 2024b,a), it is specifically designed
to support image reasoning use cases and is optimized to detect harmful
multimodal (text and image) prompts and text responses to these prompts. Llama
Guard 3 Vision is fine-tuned on Llama 3.2-Vision and demonstrates strong
performance on the internal benchmarks using the MLCommons taxonomy. We also
test its robustness against adversarial attacks. We believe that Llama Guard 3
Vision serves as a good starting point to build more capable and robust content
moderation tools for human-AI conversation with multimodal capabilities.

摘要：我們介紹 Llama Guard 3 Vision，這是一種基於多模態 LLM 的多模態防護措施，用於涉及影像理解的人工智慧對話：它可用於保護多模態 LLM 輸入（提示分類）和輸出（回應分類）的內容。與之前的純文字 Llama Guard 版本（Inan et al., 2023; Llama Team, 2024b,a）不同，它特別設計用於支援影像推理用例，並針對偵測有害的多模態（文字和影像）提示和對這些提示的文字回應進行最佳化。Llama Guard 3 Vision 在 Llama 3.2-Vision 上進行微調，並使用 MLCommons 分類法在內部基準測試中展現強勁效能。我們也測試它對抗攻擊的穩健性。我們相信 Llama Guard 3 Vision 可以作為一個良好的起點，為具備多模態功能的人工智慧對話建置更強大且穩健的內容審核工具。

##### **Repurposing Stable Diffusion Attention for Training-Free Unsupervised Interactive Segmentation**
2411.10411v1 by Markus Karmann, Onay Urfalioglu

Recent progress in interactive point prompt based Image Segmentation allows
to significantly reduce the manual effort to obtain high quality semantic
labels. State-of-the-art unsupervised methods use self-supervised pre-trained
models to obtain pseudo-labels which are used in training a prompt-based
segmentation model. In this paper, we propose a novel unsupervised and
training-free approach based solely on the self-attention of Stable Diffusion.
We interpret the self-attention tensor as a Markov transition operator, which
enables us to iteratively construct a Markov chain. Pixel-wise counting of the
required number of iterations along the Markov-chain to reach a relative
probability threshold yields a Markov-iteration-map, which we simply call a
Markov-map. Compared to the raw attention maps, we show that our proposed
Markov-map has less noise, sharper semantic boundaries and more uniform values
within semantically similar regions. We integrate the Markov-map in a simple
yet effective truncated nearest neighbor framework to obtain interactive point
prompt based segmentation. Despite being training-free, we experimentally show
that our approach yields excellent results in terms of Number of Clicks (NoC),
even outperforming state-of-the-art training based unsupervised methods in most
of the datasets.

摘要：最近在基于交互式点提示的影像分割方面取得的进展，可大幅降低取得高品质语义标签的手动工作。最先进的无监督方法使用自我监督预训练模型来取得伪标签，这些标签用于训练基于提示的分割模型。在这篇论文中，我们提出一种仅基于 Stable Diffusion 自注意力的新颖无监督且无需训练的方法。我们将自注意力张量解释为马可夫转换算子，这使我们能够迭代构建马可夫链。沿着马可夫链计算达到相对概率阈值所需的迭代次数，可产生马可夫迭代图，我们简单地称之为马可夫图。与原始注意力图相比，我们展示了我们提出的马可夫图具有更少的噪声、更清晰的语义边界以及语义相似区域内的更均匀的值。我们将马可夫图整合到一个简单而有效的截断最近邻框架中，以获取交互式点提示分割。尽管无需训练，但我们通过实验表明，我们的方法在点击次数 (NoC) 方面产生了极佳的结果，甚至在大多数数据集上优于最先进的基于训练的无监督方法。

##### **Features that Make a Difference: Leveraging Gradients for Improved Dictionary Learning**
2411.10397v1 by Jeffrey Olmo, Jared Wilson, Max Forsey, Bryce Hepner, Thomas Vin Howe, David Wingate

Sparse Autoencoders (SAEs) are a promising approach for extracting neural
network representations by learning a sparse and overcomplete decomposition of
the network's internal activations. However, SAEs are traditionally trained
considering only activation values and not the effect those activations have on
downstream computations. This limits the information available to learn
features, and biases the autoencoder towards neglecting features which are
represented with small activation values but strongly influence model outputs.
To address this, we introduce Gradient SAEs (g-SAEs), which modify the
$k$-sparse autoencoder architecture by augmenting the TopK activation function
to rely on the gradients of the input activation when selecting the $k$
elements. For a given sparsity level, g-SAEs produce reconstructions that are
more faithful to original network performance when propagated through the
network. Additionally, we find evidence that g-SAEs learn latents that are on
average more effective at steering models in arbitrary contexts. By considering
the downstream effects of activations, our approach leverages the dual nature
of neural network features as both $\textit{representations}$, retrospectively,
and $\textit{actions}$, prospectively. While previous methods have approached
the problem of feature discovery primarily focused on the former aspect, g-SAEs
represent a step towards accounting for the latter as well.

摘要：稀疏自編碼器 (SAE) 是一種有前途的方法，可藉由學習網路內部活化的稀疏且過度完備分解，來萃取神經網路表示。然而，SAE 傳統上只考慮活化值進行訓練，而未考慮這些活化對下游運算的影響。這會限制可用於學習特徵的資訊，並使自動編碼器偏向忽略以小活化值表示但會強烈影響模型輸出的特徵。為了解決這個問題，我們引入了梯度 SAE (g-SAE)，它透過擴充 TopK 活化函數來修改 $k$-稀疏自動編碼器架構，在選擇 $k$ 個元素時依賴輸入活化的梯度。對於給定的稀疏度等級，g-SAE 會產生在透過網路傳播時更忠於原始網路效能的重建。此外，我們發現證據顯示，g-SAE 會學習到平均而言更有效於在任意情境中引導模型的潛在變數。透過考慮活化的下游效應，我們的做法利用了神經網路特徵作為 $\textit{表示}$（回顧性）和 $\textit{動作}$（前瞻性）的雙重性質。雖然先前的做法主要專注於特徵發現問題的前者面向，但 g-SAE 代表了朝後者邁進一步的作法。

##### **Deep Learning for Micro-Scale Crack Detection on Imbalanced Datasets Using Key Point Localization**
2411.10389v1 by Fatahlla Moreh, Yusuf Hasan, Bilal Zahid Hussain, Mohammad Ammar, Sven Tomforde

Internal crack detection has been a subject of focus in structural health
monitoring. By focusing on crack detection in structural datasets, it is
demonstrated that deep learning (DL) methods can effectively analyze seismic
wave fields interacting with micro-scale cracks, which are beyond the
resolution of conventional visual inspection. This work explores a novel
application of DL-based key point detection technique, where cracks are
localized by predicting the coordinates of four key points that define a
bounding region of the crack. The study not only opens new research directions
for non-visual applications but also effectively mitigates the impact of
imbalanced data which poses a challenge for previous DL models, as it can be
biased toward predicting the majority class (non-crack regions). Popular DL
techniques, such as the Inception blocks, are used and investigated. The model
shows an overall reduction in loss when applied to micro-scale crack detection
and is reflected in the lower average deviation between the location of actual
and predicted cracks, with an average Intersection over Union (IoU) being 0.511
for all micro cracks (greater than 0.00 micrometers) and 0.631 for larger micro
cracks (greater than 4 micrometers).

摘要：內部裂縫偵測一直是結構健康監測的重點。透過專注於結構資料集中的裂縫偵測，證明深度學習 (DL) 方法可以有效分析與微尺度裂縫交互作用的地震波場，這超出了傳統目視檢查的解析度。這項工作探索了基於 DL 的關鍵點偵測技術的一項新應用，其中透過預測定義裂縫邊界區域的四個關鍵點的座標來定位裂縫。這項研究不僅為非視覺應用開啟了新的研究方向，還能有效減輕不平衡資料的影響，而這對先前的 DL 模型構成挑戰，因為它可能偏向於預測多數類別（非裂縫區域）。使用並研究了流行的 DL 技術，例如 Inception 區塊。該模型在應用於微尺度裂縫偵測時顯示出整體損失減少，並且反映在實際裂縫和預測裂縫的位置之間的較低平均偏差中，所有微裂縫（大於 0.00 微米）的平均交集比聯合（IoU）為 0.511，而較大的微裂縫（大於 4 微米）則為 0.631。

##### **Low-Latency Task-Oriented Communications with Multi-Round, Multi-Task Deep Learning**
2411.10385v1 by Yalin E. Sagduyu, Tugba Erpek, Aylin Yener, Sennur Ulukus

In this paper, we address task-oriented (or goal-oriented) communications
where an encoder at the transmitter learns compressed latent representations of
data, which are then transmitted over a wireless channel. At the receiver, a
decoder performs a machine learning task, specifically for classifying the
received signals. The deep neural networks corresponding to the encoder-decoder
pair are jointly trained, taking both channel and data characteristics into
account. Our objective is to achieve high accuracy in completing the underlying
task while minimizing the number of channel uses determined by the encoder's
output size. To this end, we propose a multi-round, multi-task learning (MRMTL)
approach for the dynamic update of channel uses in multi-round transmissions.
The transmitter incrementally sends an increasing number of encoded samples
over the channel based on the feedback from the receiver, and the receiver
utilizes the signals from a previous round to enhance the task performance,
rather than only considering the latest transmission. This approach employs
multi-task learning to jointly optimize accuracy across varying number of
channel uses, treating each configuration as a distinct task. By evaluating the
confidence of the receiver in task decisions, MRMTL decides on whether to
allocate additional channel uses in multiple rounds. We characterize both the
accuracy and the delay (total number of channel uses) of MRMTL, demonstrating
that it achieves the accuracy close to that of conventional methods requiring
large numbers of channel uses, but with reduced delay by incorporating signals
from a prior round. We consider the CIFAR-10 dataset, convolutional neural
network architectures, and AWGN and Rayleigh channel models for performance
evaluation. We show that MRMTL significantly improves the efficiency of
task-oriented communications, balancing accuracy and latency effectively.

摘要：<paragraph>在本文中，我们讨论了面向任务（或面向目标）的通信，其中，发送端的编码器学习数据的压缩隐式表示，然后通过无线信道传输这些表示。在接收端，解码器执行机器学习任务，特别是对接收到的信号进行分类。与编码器-解码器对相对应的深度神经网络经过联合训练，同时考虑信道和数据特征。我们的目标是在完成基础任务时实现高精度，同时最大程度地减少编码器输出大小确定的信道使用次数。为此，我们针对多轮传输中的信道使用动态更新提出了一种多轮多任务学习 (MRMTL) 方法。发送器根据接收器的反馈通过信道逐步发送越来越多的编码样本，而接收器利用上一轮的信号来增强任务性能，而不是仅考虑最新的传输。此方法采用多任务学习来联合优化不同信道使用次数的准确性，将每种配置视为一个不同的任务。通过评估接收器在任务决策中的信心，MRMTL 决定是否在多轮中分配额外的信道使用。我们描述了 MRMTL 的准确性和延迟（信道使用总数），证明它实现了接近于需要大量信道使用的传统方法的准确性，但通过合并上一轮的信号来减少了延迟。我们考虑了 CIFAR-10 数据集、卷积神经网络架构以及 AWGN 和瑞利信道模型以进行性能评估。我们表明，MRMTL 显著提高了面向任务通信的效率，有效地平衡了准确性和延迟。</paragraph>

##### **A Survey of Event Causality Identification: Principles, Taxonomy, Challenges, and Assessment**
2411.10371v1 by Zefan Zeng, Qing Cheng, Xingchen Hu, Yuehang Si, Zhong Liu

Event Causality Identification (ECI) has become a crucial task in Natural
Language Processing (NLP), aimed at automatically extracting causalities from
textual data. In this survey, we systematically address the foundational
principles, technical frameworks, and challenges of ECI, offering a
comprehensive taxonomy to categorize and clarify current research
methodologies, as well as a quantitative assessment of existing models. We
first establish a conceptual framework for ECI, outlining key definitions,
problem formulations, and evaluation standards. Our taxonomy classifies ECI
methods according to the two primary tasks of sentence-level (SECI) and
document-level (DECI) event causality identification. For SECI, we examine
feature pattern-based matching, deep semantic encoding, causal knowledge
pre-training and prompt-based fine-tuning, and external knowledge enhancement
methods. For DECI, we highlight approaches focused on event graph reasoning and
prompt-based techniques to address the complexity of cross-sentence causal
inference. Additionally, we analyze the strengths, limitations, and open
challenges of each approach. We further conduct an extensive quantitative
evaluation of various ECI methods on two benchmark datasets. Finally, we
explore future research directions, highlighting promising pathways to overcome
current limitations and broaden ECI applications.

摘要：事件因果關係識別（ECI）已成為自然語言處理（NLP）中的一項關鍵任務，旨在從文本資料中自動提取因果關係。在本次調查中，我們系統性地探討 ECI 的基礎原理、技術框架和挑戰，提供一個全面的分類法來分類和釐清當前研究方法，以及對現有模型進行定量評估。我們首先為 ECI 建立一個概念框架，概述關鍵定義、問題表述和評估標準。我們的分類法根據句子層級（SECI）和文件層級（DECI）事件因果關係識別這兩個主要任務對 ECI 方法進行分類。對於 SECI，我們探討基於特徵模式的匹配、深度語義編碼、因果知識預訓練和基於提示的微調，以及外部知識增強方法。對於 DECI，我們重點介紹專注於事件圖形推理和基於提示的技術，以解決跨句子因果推論的複雜性。此外，我們分析了每種方法的優點、限制和開放性挑戰。我們進一步對兩種基準資料集上的各種 ECI 方法進行廣泛的定量評估。最後，我們探討未來的研究方向，重點介紹克服當前限制和擴展 ECI 應用程式的有希望的途徑。

##### **Towards High-Fidelity 3D Portrait Generation with Rich Details by Cross-View Prior-Aware Diffusion**
2411.10369v1 by Haoran Wei, Wencheng Han, Xingping Dong, Jianbing Shen

Recent diffusion-based Single-image 3D portrait generation methods typically
employ 2D diffusion models to provide multi-view knowledge, which is then
distilled into 3D representations. However, these methods usually struggle to
produce high-fidelity 3D models, frequently yielding excessively blurred
textures. We attribute this issue to the insufficient consideration of
cross-view consistency during the diffusion process, resulting in significant
disparities between different views and ultimately leading to blurred 3D
representations. In this paper, we address this issue by comprehensively
exploiting multi-view priors in both the conditioning and diffusion procedures
to produce consistent, detail-rich portraits. From the conditioning standpoint,
we propose a Hybrid Priors Diffsion model, which explicitly and implicitly
incorporates multi-view priors as conditions to enhance the status consistency
of the generated multi-view portraits. From the diffusion perspective,
considering the significant impact of the diffusion noise distribution on
detailed texture generation, we propose a Multi-View Noise Resamplig Strategy
integrated within the optimization process leveraging cross-view priors to
enhance representation consistency. Extensive experiments demonstrate that our
method can produce 3D portraits with accurate geometry and rich details from a
single image. The project page is at
\url{https://haoran-wei.github.io/Portrait-Diffusion}.

摘要：<paragraph>近期的基于扩散的单图像 3D 肖像生成方法通常采用 2D 扩散模型来提供多视图知识，然后将其提炼成 3D 表征。然而，这些方法通常难以生成高保真 3D 模型，经常产生过度模糊的纹理。我们将此问题归因于在扩散过程中对跨视图一致性的考虑不足，导致不同视图之间存在显着差异，最终导致模糊的 3D 表征。在本文中，我们通过在调适和扩散程序中全面利用多视图先验来解决此问题，以生成一致且细节丰富的肖像。从调适的观点来看，我们提出了混合先验扩散模型，该模型显式和隐式地将多视图先验作为条件纳入其中，以增强所生成的多视图肖像的状态一致性。从扩散的角度来看，考虑到扩散噪声分布对详细纹理生成的影响，我们提出了一种在优化过程中集成的多视图噪声重采样策略，利用跨视图先验来增强表征一致性。大量的实验表明，我们的方法可以从单一图像中生成具有准确几何形状和丰富细节的 3D 肖像。项目页面位于
\url{https://haoran-wei.github.io/Portrait-Diffusion}。</paragraph>

##### **Mechanisms of Generative Image-to-Image Translation Networks**
2411.10368v1 by Guangzong Chen, Mingui Sun, Zhi-Hong Mao, Kangni Liu, Wenyan Jia

Generative Adversarial Networks (GANs) are a class of neural networks that
have been widely used in the field of image-to-image translation. In this
paper, we propose a streamlined image-to-image translation network with a
simpler architecture compared to existing models. We investigate the
relationship between GANs and autoencoders and provide an explanation for the
efficacy of employing only the GAN component for tasks involving image
translation. We show that adversarial for GAN models yields results comparable
to those of existing methods without additional complex loss penalties.
Subsequently, we elucidate the rationale behind this phenomenon. We also
incorporate experimental results to demonstrate the validity of our findings.

摘要：生成對抗網路 (GAN) 是一類神經網路，廣泛用於影像轉換領域。在本論文中，我們提出一個簡化版的影像轉換網路，其架構比現有模型更為簡潔。我們探討 GAN 與自動編碼器之間的關係，並說明僅使用 GAN 組件來執行影像轉換任務的效能。我們證明 GAN 模型的對抗性可產生與現有方法相當的結果，而無需額外的複雜損失懲罰。隨後，我們闡明了此現象背後的原理。我們也納入實驗結果來證明我們發現的有效性。

##### **Domain Adaptation-based Edge Computing for Cross-Conditions Fault Diagnosis**
2411.10340v1 by Yanzhi Wang, Chu Wang, Jinhong Wu, Ziyang Yu, Qi Zhou

Fault diagnosis technology supports the healthy operation of mechanical
equipment. However, the variations conditions during the operation of
mechanical equipment lead to significant disparities in data distribution,
posing challenges to fault diagnosis. Furthermore, when deploying applications,
traditional methods often encounter issues such as latency and data security.
Therefore, conducting fault diagnosis and deploying application methods under
cross-operating conditions holds significant value. This paper proposes a
domain adaptation-based lightweight fault diagnosis framework for edge
computing scenarios. Incorporating the local maximum mean discrepancy into
knowledge transfer aligns the feature distributions of different domains in a
high-dimensional feature space, to discover a common feature space across
domains. The acquired fault diagnosis expertise from the cloud-model is
transferred to the lightweight edge-model using adaptation knowledge transfer
methods. While ensuring real-time diagnostic capabilities, accurate fault
diagnosis is achieved across working conditions. We conducted validation
experiments on the NVIDIA Jetson Xavier NX kit. In terms of diagnostic
performance, the proposed method significantly improved diagnostic accuracy,
with average increases of 34.44% and 17.33% compared to the comparison method,
respectively. Regarding lightweight effectiveness, proposed method achieved an
average inference speed increase of 80.47%. Additionally, compared to the
cloud-model, the parameter count of the edge-model decreased by 96.37%, while
the Flops decreased by 83.08%.

摘要：故障診斷技術支援機械設備的健康運作。然而，機械設備在運作期間的變異條件導致資料分佈有顯著差異，對故障診斷構成挑戰。此外，在部署應用程式時，傳統方法經常會遇到延遲和資料安全等問題。因此，在跨操作條件下進行故障診斷和部署應用程式方法具有重要的價值。本文提出了一個基於領域適應的輕量級故障診斷框架，用於邊緣運算場景。將局部最大平均差異納入知識轉移，在高維特徵空間中對齊不同領域的特徵分佈，以發現跨領域的共同特徵空間。從雲模型中獲取的故障診斷專業知識，使用適應知識轉移方法轉移到輕量級邊緣模型中。在確保即時診斷能力的同時，在工作條件下實現了準確的故障診斷。我們在 NVIDIA Jetson Xavier NX 套件上進行了驗證實驗。在診斷效能方面，所提出的方法顯著提高了診斷準確度，與比較方法相比，平均分別提高了 34.44% 和 17.33%。關於輕量級有效性，所提出的方法實現了平均推論速度提高 80.47%。此外，與雲模型相比，邊緣模型的參數數量減少了 96.37%，而 Flops 減少了 83.08%。

##### **Safe Text-to-Image Generation: Simply Sanitize the Prompt Embedding**
2411.10329v1 by Huming Qiu, Guanxu Chen, Mi Zhang, Min Yang

In recent years, text-to-image (T2I) generation models have made significant
progress in generating high-quality images that align with text descriptions.
However, these models also face the risk of unsafe generation, potentially
producing harmful content that violates usage policies, such as explicit
material. Existing safe generation methods typically focus on suppressing
inappropriate content by erasing undesired concepts from visual
representations, while neglecting to sanitize the textual representation.
Although these methods help mitigate the risk of misuse to certain extent,
their robustness remains insufficient when dealing with adversarial attacks.
  Given that semantic consistency between input text and output image is a
fundamental requirement for T2I models, we identify that textual
representations (i.e., prompt embeddings) are likely the primary source of
unsafe generation. To this end, we propose a vision-agnostic safe generation
framework, Embedding Sanitizer (ES), which focuses on erasing inappropriate
concepts from prompt embeddings and uses the sanitized embeddings to guide the
model for safe generation. ES is applied to the output of the text encoder as a
plug-and-play module, enabling seamless integration with different T2I models
as well as other safeguards. In addition, ES's unique scoring mechanism assigns
a score to each token in the prompt to indicate its potential harmfulness, and
dynamically adjusts the sanitization intensity to balance defensive performance
and generation quality. Through extensive evaluation on five prompt benchmarks,
our approach achieves state-of-the-art robustness by sanitizing the source
(prompt embedding) of unsafe generation compared to nine baseline methods. It
significantly outperforms existing safeguards in terms of interpretability and
controllability while maintaining generation quality.

摘要：<paragraph>近年来，文本到图像 (T2I) 生成模型在生成与文本描述相符的高质量图像方面取得了重大进展。然而，这些模型也面临着不安全的生成风险，可能会产生违反使用政策的有害内容，例如露骨的材料。现有的安全生成方法通常侧重于通过从视觉表现中抹去不需要的概念来抑制不当内容，而忽略了对文本表现进行清理。尽管这些方法在一定程度上帮助减轻了滥用的风险，但它们在应对对抗性攻击时的鲁棒性仍然不足。鉴于输入文本和输出图像之间的语义一致性是 T2I 模型的基本要求，我们发现文本表现（即提示嵌入）可能是不安全生成的根源。为此，我们提出了一种与视觉无关的安全生成框架，嵌入清理器 (ES)，其重点是从提示嵌入中抹去不当概念，并使用经过清理的嵌入来指导模型进行安全生成。ES 被应用于文本编码器的输出，作为一个即插即用模块，能够与不同的 T2I 模型以及其他保障措施无缝集成。此外，ES 独特的评分机制为提示中的每个标记分配一个分数，以表示其潜在危害性，并动态调整清理强度以平衡防御性能和生成质量。通过对五个提示基准的广泛评估，我们的方法通过清理不安全生成的源（提示嵌入）而实现了最先进的鲁棒性，与九种基线方法相比。它在可解释性和可控性方面明显优于现有的保障措施，同时保持了生成质量。</paragraph>

##### **Emotion Detection in Reddit: Comparative Study of Machine Learning and Deep Learning Techniques**
2411.10328v1 by Maliheh Alaeddini

Emotion detection is pivotal in human communication, as it significantly
influences behavior, relationships, and decision-making processes. This study
concentrates on text-based emotion detection by leveraging the GoEmotions
dataset, which annotates Reddit comments with 27 distinct emotions. These
emotions are subsequently mapped to Ekman's six basic categories: joy, anger,
fear, sadness, disgust, and surprise. We employed a range of models for this
task, including six machine learning models, three ensemble models, and a Long
Short-Term Memory (LSTM) model to determine the optimal model for emotion
detection. Results indicate that the Stacking classifier outperforms other
models in accuracy and performance. We also benchmark our models against
EmoBERTa, a pre-trained emotion detection model, with our Stacking classifier
proving more effective. Finally, the Stacking classifier is deployed via a
Streamlit web application, underscoring its potential for real-world
applications in text-based emotion analysis.

摘要：情緒偵測在人類溝通中至關重要，因為它顯著影響行為、人際關係和決策制定過程。本研究集中於基於文字的情緒偵測，利用 GoEmotions 資料集，其中註解了 Reddit 評論，並標示了 27 種不同的情緒。這些情緒隨後對應到 Ekman 的六種基本類別：快樂、憤怒、恐懼、悲傷、厭惡和驚訝。我們採用了一系列模型來執行這項任務，包括六個機器學習模型、三個集成模型和一個長短期記憶 (LSTM) 模型，以確定最佳的情緒偵測模型。結果表明，堆疊分類器在準確性和效能方面優於其他模型。我們也根據預先訓練好的情緒偵測模型 EmoBERTa 來評量我們的模型，而我們的堆疊分類器證明了更有效。最後，堆疊分類器透過 Streamlit 網路應用程式進行部署，突顯了它在基於文字的情緒分析中對真實世界應用程式的潛力。

##### **The Dawn of GUI Agent: A Preliminary Case Study with Claude 3.5 Computer Use**
2411.10323v1 by Siyuan Hu, Mingyu Ouyang, Difei Gao, Mike Zheng Shou

The recently released model, Claude 3.5 Computer Use, stands out as the first
frontier AI model to offer computer use in public beta as a graphical user
interface (GUI) agent. As an early beta, its capability in the real-world
complex environment remains unknown. In this case study to explore Claude 3.5
Computer Use, we curate and organize a collection of carefully designed tasks
spanning a variety of domains and software. Observations from these cases
demonstrate Claude 3.5 Computer Use's unprecedented ability in end-to-end
language to desktop actions. Along with this study, we provide an
out-of-the-box agent framework for deploying API-based GUI automation models
with easy implementation. Our case studies aim to showcase a groundwork of
capabilities and limitations of Claude 3.5 Computer Use with detailed analyses
and bring to the fore questions about planning, action, and critic, which must
be considered for future improvement. We hope this preliminary exploration will
inspire future research into the GUI agent community. All the test cases in the
paper can be tried through the project:
https://github.com/showlab/computer_use_ootb.

摘要：最近發布的模型，Claude 3.5 電腦使用，作為第一個提供電腦使用於公開測試版，作為圖形使用者介面 (GUI) 代理的邊疆 AI 模型而脫穎而出。作為一個早期測試版，它在真實世界複雜環境中的能力仍然未知。在這個案例研究中，我們策劃並組織了一系列精心設計的任務，涵蓋各種領域和軟體，以探索 Claude 3.5 電腦使用。這些案例的觀察結果證明了 Claude 3.5 電腦使用在端對端語言到桌面動作中前所未有的能力。隨著這項研究，我們提供了一個開箱即用的代理架構，用於部署基於 API 的 GUI 自動化模型，並易於實作。我們的案例研究旨在展示 Claude 3.5 電腦使用能力和限制的基礎，並進行詳細分析，並提出關於規劃、行動和批評的問題，這些問題必須考慮在未來的改進中。我們希望這個初步探索能激勵未來對 GUI 代理社群的研究。本文中的所有測試案例都可以透過專案嘗試：
https://github.com/showlab/computer_use_ootb。

##### **Unveiling Topological Structures in Text: A Comprehensive Survey of Topological Data Analysis Applications in NLP**
2411.10298v1 by Adaku Uchendu, Thai Le

The surge of data available on the internet has led to the adoption of
various computational methods to analyze and extract valuable insights from
this wealth of information. Among these, the field of Machine Learning (ML) has
thrived by leveraging data to extract meaningful insights. However, ML
techniques face notable challenges when dealing with real-world data, often due
to issues of imbalance, noise, insufficient labeling, and high dimensionality.
To address these limitations, some researchers advocate for the adoption of
Topological Data Analysis (TDA), a statistical approach that discerningly
captures the intrinsic shape of data despite noise. Despite its potential, TDA
has not gained as much traction within the Natural Language Processing (NLP)
domain compared to structurally distinct areas like computer vision.
Nevertheless, a dedicated community of researchers has been exploring the
application of TDA in NLP, yielding 85 papers we comprehensively survey in this
paper. Our findings categorize these efforts into theoretical and
nontheoretical approaches. Theoretical approaches aim to explain linguistic
phenomena from a topological viewpoint, while non-theoretical approaches merge
TDA with ML features, utilizing diverse numerical representation techniques. We
conclude by exploring the challenges and unresolved questions that persist in
this niche field. Resources and a list of papers on this topic can be found at:
https://github.com/AdaUchendu/AwesomeTDA4NLP.

摘要：網路上資料激增，導致採用各種運算方法來分析和從這些豐富資訊中萃取有價值的見解。其中，機器學習 (ML) 領域透過利用資料來萃取有意義的見解而蓬勃發展。然而，ML 技術在處理真實世界資料時會面臨顯著的挑戰，通常是因為不平衡、雜訊、標籤不足和高維度等問題。為了解決這些限制，一些研究人員提倡採用拓撲資料分析 (TDA)，這是一種統計方法，可以明辨地擷取資料的內在形狀，即使有雜訊。儘管有其潛力，與電腦視覺等結構上不同的領域相比，TDA 在自然語言處理 (NLP) 領域並未獲得太多關注。儘管如此，一群專門的研究人員一直在探索 TDA 在 NLP 中的應用，並在本文中全面調查了 85 篇論文。我們的研究結果將這些努力分類為理論和非理論方法。理論方法旨在從拓撲觀點解釋語言現象，而非理論方法則將 TDA 與 ML 特徵合併，並利用多樣化的數值表示技術。我們最後探討此利基領域中持續存在的挑戰與未解決問題。可以在以下位置找到此主題的資源和論文清單：https://github.com/AdaUchendu/AwesomeTDA4NLP。

##### **Scaling Law for Post-training after Model Pruning**
2411.10272v1 by Xiaodong Chen, Yuxuan Hu, Jing Zhang, Xiaokang Zhang, Cuiping Li, Hong Chen

Large language models (LLMs) based on the Transformer architecture are widely
employed across various domains and tasks. However, their increasing size
imposes significant hardware demands, limiting practical deployment. To
mitigate this, model pruning techniques have been developed to create more
efficient models while maintaining high performance. Despite this,
post-training after pruning is crucial for performance recovery and can be
resource-intensive. This paper investigates the post-training requirements of
pruned LLMs and introduces a scaling law to determine the optimal amount of
post-training data. Post-training experiments with the Llama-3 and Qwen-2.5
series models, pruned using depth pruning, width pruning, and 2:4
semi-structured pruning, show that higher pruning ratios necessitate more
post-training data for performance recovery, whereas larger LLMs require less.
The proposed scaling law predicts a model's loss based on its parameter counts
before and after pruning, as well as the post-training token counts.
Furthermore, we find that the scaling law established from smaller LLMs can be
reliably extrapolated to larger LLMs. This work provides valuable insights into
the post-training of pruned LLMs and offers a practical scaling law for
optimizing post-training data usage.

摘要：<paragraph>基於 Transformer 架構的大型語言模型 (LLM) 廣泛用於各種領域和任務中。然而，它們日益增加的大小會帶來顯著的硬體需求，限制了實際部署。為了減輕這個問題，已經開發出模型剪枝技術，以在維持高性能的同時建立更有效率的模型。儘管如此，剪枝後的後續訓練對於性能恢復至關重要，而且可能會消耗大量資源。本文探討了剪枝後的 LLM 的後續訓練需求，並引入了一個縮放定律來確定最佳的後續訓練資料量。使用深度剪枝、寬度剪枝和 2:4 半結構化剪枝進行剪枝的 Llama-3 和 Qwen-2.5 系列模型的後續訓練實驗表明，較高的剪枝率需要更多後續訓練資料才能恢復性能，而較大的 LLM 則需要較少。所提出的縮放定律根據模型在剪枝前後的參數數量以及後續訓練的 token 數量預測模型的損失。此外，我們發現從較小的 LLM 建立的縮放定律可以可靠地外推到較大的 LLM。這項工作提供了對剪枝後 LLM 的後續訓練的寶貴見解，並為最佳化後續訓練資料使用提供了實用的縮放定律。</paragraph>

##### **The Unreasonable Effectiveness of Guidance for Diffusion Models**
2411.10257v1 by Tim Kaiser, Nikolas Adaloglou, Markus Kollmann

Guidance is an error-correcting technique used to improve the perceptual
quality of images generated by diffusion models. Typically, the correction is
achieved by linear extrapolation, using an auxiliary diffusion model that has
lower performance than the primary model. Using a 2D toy example, we show that
it is highly beneficial when the auxiliary model exhibits similar errors as the
primary one but stronger. We verify this finding in higher dimensions, where we
show that competitive generative performance to state-of-the-art guidance
methods can be achieved when the auxiliary model differs from the primary one
only by having stronger weight regularization. As an independent contribution,
we investigate whether upweighting long-range spatial dependencies improves
visual fidelity. The result is a novel guidance method, which we call sliding
window guidance (SWG), that guides the primary model with itself by
constraining its receptive field. Intriguingly, SWG aligns better with human
preferences than state-of-the-art guidance methods while requiring neither
training, architectural modifications, nor class conditioning. The code will be
released.

摘要：指導是一種錯誤修正技術，用於改善擴散模型生成的影像之感知品質。通常，修正會透過線性外推來達成，使用一個輔助擴散模型，其效能低於主要模型。使用一個 2D 玩具範例，我們展示當輔助模型展現與主要模型相似的錯誤，但更強時，會有高度的好處。我們在較高維度中驗證此發現，其中我們展示當輔助模型僅在具有較強的權重正規化時與主要模型不同時，可以達成與現有技術指導方法相競爭的生成效能。作為一個獨立的貢獻，我們探討是否上調長程空間依賴性會改善視覺保真度。結果是一種新穎的指導方法，我們稱之為滑動視窗指導 (SWG)，它透過限制其感受野來使用自身指導主要模型。有趣的是，SWG 比現有技術指導方法更符合人類偏好，同時不需要訓練、架構修改或類別調整。程式碼將會釋出。

##### **Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**
2411.10255v1 by Mohammed Yaseen Jabarulla, Theodor Uden, Thomas Jack, Philipp Beerbaum, Steffen Oeltze-Jafra

Pediatric heart diseases present a broad spectrum of congenital and acquired
diseases. More complex congenital malformations require a differentiated and
multimodal decision-making process, usually including echocardiography as a
central imaging method. Artificial intelligence (AI) offers considerable
promise for clinicians by facilitating automated interpretation of pediatric
echocardiography data. However, adapting AI technologies for pediatric
echocardiography analysis has challenges such as limited public data
availability, data privacy, and AI model transparency. Recently, researchers
have focused on disruptive technologies, such as federated learning (FL) and
explainable AI (XAI), to improve automatic diagnostic and decision support
workflows. This study offers a comprehensive overview of the limitations and
opportunities of AI in pediatric echocardiography, emphasizing the synergistic
workflow and role of XAI and FL, identifying research gaps, and exploring
potential future developments. Additionally, three relevant clinical use cases
demonstrate the functionality of XAI and FL with a focus on (i) view
recognition, (ii) disease classification, (iii) segmentation of cardiac
structures, and (iv) quantitative assessment of cardiac function.

摘要：小兒心臟疾病呈現先天性與後天性疾病的廣泛光譜。較複雜的先天性畸形需要一個差異化且多模式的決策過程，通常包括超音波檢查作為主要的影像方法。人工智慧 (AI) 為臨床醫生提供了相當大的希望，因為它可以促進小兒超音波檢查資料的自動化解讀。然而，將人工智慧技術應用於小兒超音波檢查分析有許多挑戰，例如有限的公開資料可用性、資料隱私和人工智慧模型透明度。最近，研究人員專注於破壞性技術，例如聯合學習 (FL) 和可解釋人工智慧 (XAI)，以改善自動診斷和決策支援工作流程。本研究提供了人工智慧在小兒超音波檢查中的限制和機會的全面概述，強調了 XAI 和 FL 的協同工作流程和角色，找出研究差距並探討潛在的未來發展。此外，三個相關的臨床使用案例展示了 XAI 和 FL 的功能，重點在於 (i) 檢視辨識、(ii) 疾病分類、(iii) 心臟結構分割和 (iv) 心臟功能的量化評估。

##### **Scaling up the Evaluation of Collaborative Problem Solving: Promises and Challenges of Coding Chat Data with ChatGPT**
2411.10246v1 by Jiangang Hao, Wenju Cui, Patrick Kyllonen, Emily Kerzabi, Lei Liu, Michael Flor

Collaborative problem solving (CPS) is widely recognized as a critical 21st
century skill. Efficiently coding communication data is a big challenge in
scaling up research on assessing CPS. This paper reports the findings on using
ChatGPT to directly code CPS chat data by benchmarking performance across
multiple datasets and coding frameworks. We found that ChatGPT-based coding
outperformed human coding in tasks where the discussions were characterized by
colloquial languages but fell short in tasks where the discussions dealt with
specialized scientific terminology and contexts. The findings offer practical
guidelines for researchers to develop strategies for efficient and scalable
analysis of communication data from CPS tasks.

摘要：協作問題解決 (CPS) 廣泛被認為是 21 世紀的一項關鍵技能。有效編碼溝通資料是擴大 CPS 評估研究的一項重大挑戰。本文報告了使用 ChatGPT 直接編碼 CPS 聊天資料的發現，並透過對多個資料集和編碼框架進行效能基準測試。我們發現，在討論以口語為特徵的任務中，基於 ChatGPT 的編碼優於人工編碼，但在討論涉及專業科學術語和背景的任務中則表現不佳。這些發現為研究人員提供了實用的指南，以便制定策略，以有效且可擴充的方式分析來自 CPS 任務的溝通資料。

##### **Measuring Non-Adversarial Reproduction of Training Data in Large Language Models**
2411.10242v1 by Michael Aerni, Javier Rando, Edoardo Debenedetti, Nicholas Carlini, Daphne Ippolito, Florian Tramèr

Large language models memorize parts of their training data. Memorizing short
snippets and facts is required to answer questions about the world and to be
fluent in any language. But models have also been shown to reproduce long
verbatim sequences of memorized text when prompted by a motivated adversary. In
this work, we investigate an intermediate regime of memorization that we call
non-adversarial reproduction, where we quantify the overlap between model
responses and pretraining data when responding to natural and benign prompts.
For a variety of innocuous prompt categories (e.g., writing a letter or a
tutorial), we show that up to 15% of the text output by popular conversational
language models overlaps with snippets from the Internet. In worst cases, we
find generations where 100% of the content can be found exactly online. For the
same tasks, we find that human-written text has far less overlap with Internet
data. We further study whether prompting strategies can close this reproduction
gap between models and humans. While appropriate prompting can reduce
non-adversarial reproduction on average, we find that mitigating worst-case
reproduction of training data requires stronger defenses -- even for benign
interactions.

摘要：大型語言模型會記憶訓練資料的一部分。記憶簡短的片段和事實對於回答有關世界問題以及流利使用任何語言都是必要的。但是，當受到有動機的對手提示時，模型也已被證明會複製記憶文字的長串逐字序列。在這項工作中，我們研究了一種稱為非對抗性複製的記憶中間機制，其中我們量化了模型回應與在回應自然且良性的提示時預訓練資料之間的重疊。對於各種無害的提示類別（例如，寫一封信或一個教學），我們展示了熱門對話語言模型輸出的文本中，多達 15% 與來自網際網路的片段重疊。在最壞的情況下，我們發現 100% 的內容可以在網路上找到。對於相同的任務，我們發現人類寫的文字與網際網路資料的重疊程度遠低於此。我們進一步研究提示策略是否可以縮小模型和人類之間的這種複製差距。雖然適當的提示可以平均減少非對抗性複製，但我們發現，減輕訓練資料的最壞情況複製需要更強的防禦措施，即使對於良性的互動也是如此。

##### **Generative AI in Multimodal User Interfaces: Trends, Challenges, and Cross-Platform Adaptability**
2411.10234v1 by J. Bieniek, M. Rahouti, D. C. Verma

As the boundaries of human computer interaction expand, Generative AI emerges
as a key driver in reshaping user interfaces, introducing new possibilities for
personalized, multimodal and cross-platform interactions. This integration
reflects a growing demand for more adaptive and intuitive user interfaces that
can accommodate diverse input types such as text, voice and video, and deliver
seamless experiences across devices. This paper explores the integration of
generative AI in modern user interfaces, examining historical developments and
focusing on multimodal interaction, cross-platform adaptability and dynamic
personalization. A central theme is the interface dilemma, which addresses the
challenge of designing effective interactions for multimodal large language
models, assessing the trade-offs between graphical, voice-based and immersive
interfaces. The paper further evaluates lightweight frameworks tailored for
mobile platforms, spotlighting the role of mobile hardware in enabling scalable
multimodal AI. Technical and ethical challenges, including context retention,
privacy concerns and balancing cloud and on-device processing are thoroughly
examined. Finally, the paper outlines future directions such as emotionally
adaptive interfaces, predictive AI driven user interfaces and real-time
collaborative systems, underscoring generative AI's potential to redefine
adaptive user-centric interfaces across platforms.

摘要：隨著人機互動的界線不斷擴展，生成式 AI 成為重新塑造使用者介面的關鍵驅動力，為個人化、多模態和跨平台互動引入了新的可能性。這種整合反映出對更具適應性和直覺性的使用者介面的需求日益增加，這種介面可以容納多種輸入類型，例如文字、語音和視訊，並在各種裝置上提供無縫的體驗。本文探討了生成式 AI 在現代使用者介面中的整合，探討了歷史發展，並專注於多模態互動、跨平台適應性和動態個人化。一個核心主題是介面困境，它解決了為多模態大型語言模型設計有效互動的挑戰，評估了圖形、語音和沉浸式介面之間的取捨。本文進一步評估了專為行動平台量身打造的輕量化框架，強調了行動硬體在實現可擴充多模態 AI 中所扮演的角色。技術和倫理挑戰，包括內容保留、隱私問題以及平衡雲端和裝置處理，都經過徹底檢視。最後，本文概述了未來方向，例如情緒適應性介面、預測性 AI 驅動的使用者介面和即時協作系統，強調了生成式 AI 在跨平台重新定義適應性以使用者為中心的介面的潛力。

##### **ColorEdit: Training-free Image-Guided Color editing with diffusion model**
2411.10232v1 by Xingxi Yin, Zhi Li, Jingfeng Zhang, Chenglin Li, Yin Zhang

Text-to-image (T2I) diffusion models, with their impressive generative
capabilities, have been adopted for image editing tasks, demonstrating
remarkable efficacy. However, due to attention leakage and collision between
the cross-attention map of the object and the new color attribute from the text
prompt, text-guided image editing methods may fail to change the color of an
object, resulting in a misalignment between the resulting image and the text
prompt. In this paper, we conduct an in-depth analysis on the process of
text-guided image synthesizing and what semantic information different
cross-attention blocks have learned. We observe that the visual representation
of an object is determined in the up-block of the diffusion model in the early
stage of the denoising process, and color adjustment can be achieved through
value matrices alignment in the cross-attention layer. Based on our findings,
we propose a straightforward, yet stable, and effective image-guided method to
modify the color of an object without requiring any additional fine-tuning or
training. Lastly, we present a benchmark dataset called COLORBENCH, the first
benchmark to evaluate the performance of color change methods. Extensive
experiments validate the effectiveness of our method in object-level color
editing and surpass the performance of popular text-guided image editing
approaches in both synthesized and real images.

摘要：文本到图像 (T2I) 扩散模型及其令人印象深刻的生成能力已用于图像编辑任务，展现出卓越的功效。然而，由于注意力泄漏和来自文本提示的对象交叉注意力图与新颜色属性之间的冲突，文本引导的图像编辑方法可能无法改变对象的顏色，导致生成图像与文本提示之间出现错位。在本文中，我们对文本引导图像合成过程以及不同交叉注意力模块学习到的语义信息进行了深入分析。我们观察到，对象的视觉表征是在扩散模型的上行模块中在去噪过程的早期阶段确定的，并且可以通过交叉注意力层中的值矩阵对齐来实现颜色调整。根据我们的发现，我们提出了一种直接、稳定且有效的面向图像的方法来修改对象的顏色，而无需任何额外的微调或训练。最后，我们提出了一个名为 COLORBENCH 的基准数据集，这是第一个评估颜色改变方法性能的基准。大量的实验验证了我们的方法在对象级颜色编辑中的有效性，并且在合成图像和真实图像中都超越了流行的文本引导图像编辑方法的性能。

##### **A Low-Resolution Image is Worth 1x1 Words: Enabling Fine Image Super-Resolution with Transformers and TaylorShift**
2411.10231v1 by Sanath Budakegowdanadoddi Nagaraju, Brian Bernhard Moser, Tobias Christian Nauen, Stanislav Frolov, Federico Raue, Andreas Dengel

Transformer-based Super-Resolution (SR) models have recently advanced image
reconstruction quality, yet challenges remain due to computational complexity
and an over-reliance on large patch sizes, which constrain fine-grained detail
enhancement. In this work, we propose TaylorIR to address these limitations by
utilizing a patch size of 1x1, enabling pixel-level processing in any
transformer-based SR model. To address the significant computational demands
under the traditional self-attention mechanism, we employ the TaylorShift
attention mechanism, a memory-efficient alternative based on Taylor series
expansion, achieving full token-to-token interactions with linear complexity.
Experimental results demonstrate that our approach achieves new
state-of-the-art SR performance while reducing memory consumption by up to 60%
compared to traditional self-attention-based transformers.

摘要：基於 Transformer 的超解析度 (SR) 模型最近提升了影像重建品質，但仍因運算複雜度和過度依賴大型區塊大小而面臨挑戰，這會限制細緻細節的增強。在此研究中，我們提出 TaylorIR 來解決這些限制，方法是利用 1x1 的區塊大小，讓任何基於 Transformer 的 SR 模型都能進行像素層級處理。為了滿足傳統自我注意機制下的重大運算需求，我們採用 TaylorShift 注意力機制，這是一種基於 Taylor 級數展開的省記憶體替代方案，能以線性複雜度實現完整的 token-to-token 互動。實驗結果顯示，我們的做法可達成新的超解析度技術水準，同時與傳統基於自我注意力的 Transformer 相比，記憶體消耗量最多可減少 60%。

##### **Entropy and type-token ratio in gigaword corpora**
2411.10227v1 by Pablo Rosillo-Rodes, Maxi San Miguel, David Sanchez

Lexical diversity measures the vocabulary variation in texts. While its
utility is evident for analyses in language change and applied linguistics, it
is not yet clear how to operationalize this concept in a unique way. We here
investigate entropy and text-token ratio, two widely employed metrics for
lexical diversities, in six massive linguistic datasets in English, Spanish,
and Turkish, consisting of books, news articles, and tweets. These gigaword
corpora correspond to languages with distinct morphological features and differ
in registers and genres, thus constituting a diverse testbed for a quantitative
approach to lexical diversity. Strikingly, we find a functional relation
between entropy and text-token ratio that holds across the corpora under
consideration. Further, in the limit of large vocabularies we find an
analytical expression that sheds light on the origin of this relation and its
connection with both Zipf and Heaps laws. Our results then contribute to the
theoretical understanding of text structure and offer practical implications
for fields like natural language processing.

摘要：詞彙多樣性測量文本中的詞彙變化。雖然它的效用在語言變遷和應用語言學的分析中很明顯，但如何以獨特的方式將這個概念具體化還不是很清楚。我們在此探討熵和文本符號比，這是英語、西班牙語和土耳其語中六個廣泛使用的詞彙多樣性指標，包括書籍、新聞文章和推文。這些吉加字語料庫對應於具有不同形態特徵的語言，並且在註冊和類型上有所不同，因此構成了對詞彙多樣性進行定量方法的不同的測試平台。令人驚訝的是，我們發現熵和文本符號比之間存在一種函數關係，這種關係存在於所考慮的語料庫中。此外，在大量詞彙的限制中，我們發現了一個分析表達式，它闡明了這種關係的起源及其與齊夫定律和希普定律的聯繫。我們的結果有助於對文本結構的理論理解，並為自然語言處理等領域提供了實用的意義。

##### **An Empirical Study on LLM-based Agents for Automated Bug Fixing**
2411.10213v1 by Xiangxin Meng, Zexiong Ma, Pengfei Gao, Chao Peng

Large language models (LLMs) and LLM-based Agents have been applied to fix
bugs automatically, demonstrating the capability in addressing software defects
by engaging in development environment interaction, iterative validation and
code modification. However, systematic analysis of these agent and non-agent
systems remain limited, particularly regarding performance variations among
top-performing ones. In this paper, we examine seven proprietary and
open-source systems on the SWE-bench Lite benchmark for automated bug fixing.
We first assess each system's overall performance, noting instances solvable by
all or none of these sytems, and explore why some instances are uniquely solved
by specific system types. We also compare fault localization accuracy at file
and line levels and evaluate bug reproduction capabilities, identifying
instances solvable only through dynamic reproduction. Through analysis, we
concluded that further optimization is needed in both the LLM itself and the
design of Agentic flow to improve the effectiveness of the Agent in bug fixing.

摘要：大型語言模型 (LLM) 和基於 LLM 的代理已應用於自動修復錯誤，展示了通過參與開發環境互動、反覆驗證和程式碼修改來解決軟體缺陷的能力。然而，對這些代理和非代理系統的系統分析仍然有限，特別是關於頂尖系統之間的效能差異。在本文中，我們在 SWE-bench Lite 基準上檢查了七個專有和開源系統，用於自動修復錯誤。我們首先評估每個系統的整體效能，記錄所有或沒有這些系統可以解決的實例，並探討為什麼某些實例是由特定系統類型獨特解決的。我們還比較了檔案和程式碼行的故障定位準確度，並評估錯誤重現能力，識別僅通過動態重現才能解決的實例。透過分析，我們得出結論，需要進一步最佳化 LLM 本身和代理流程的設計，以提高代理在錯誤修復中的有效性。

##### **FengWu-W2S: A deep learning model for seamless weather-to-subseasonal forecast of global atmosphere**
2411.10191v1 by Fenghua Ling, Kang Chen, Jiye Wu, Tao Han, Jing-Jia Luo, Wanli Ouyang, Lei Bai

Seamless forecasting that produces warning information at continuum
timescales based on only one system is a long-standing pursuit for
weather-climate service. While the rapid advancement of deep learning has
induced revolutionary changes in classical forecasting field, current efforts
are still focused on building separate AI models for weather and climate
forecasts. To explore the seamless forecasting ability based on one AI model,
we propose FengWu-Weather to Subseasonal (FengWu-W2S), which builds on the
FengWu global weather forecast model and incorporates an ocean-atmosphere-land
coupling structure along with a diverse perturbation strategy. FengWu-W2S can
generate 6-hourly atmosphere forecasts extending up to 42 days through an
autoregressive and seamless manner. Our hindcast results demonstrate that
FengWu-W2S reliably predicts atmospheric conditions out to 3-6 weeks ahead,
enhancing predictive capabilities for global surface air temperature,
precipitation, geopotential height and intraseasonal signals such as the
Madden-Julian Oscillation (MJO) and North Atlantic Oscillation (NAO). Moreover,
our ablation experiments on forecast error growth from daily to seasonal
timescales reveal potential pathways for developing AI-based integrated system
for seamless weather-climate forecasting in the future.

摘要：無縫預測在連續時間尺度上僅根據一個系統產生警告資訊是天氣氣候服務的長期追求。儘管深度學習的快速進展已對經典預測領域產生革命性的變化，但目前的努力仍集中於為天氣和氣候預測建立單獨的 AI 模型。為了探索基於一個 AI 模型的無縫預測能力，我們提出 FengWu-Weather to Subseasonal（FengWu-W2S），它建立在 FengWu 全球天氣預測模型之上，並結合了海洋-大氣-陸地耦合結構以及多樣化的擾動策略。FengWu-W2S 可以通過自迴歸和無縫的方式產生長達 42 天的 6 小時大氣預測。我們的後驗預測結果表明，FengWu-W2S 可靠地預測出 3-6 週後的大氣條件，增強了對全球地表氣溫、降水、地勢高度和季節內信號（如 Madden-Julian 振盪 (MJO) 和北大西洋振盪 (NAO)）的預測能力。此外，我們從每日到季節時間尺度的預測誤差增長中進行的消融實驗揭示了未來開發基於 AI 的無縫天氣氣候預測整合系統的潛在途徑。

##### **Agentic LLMs in the Supply Chain: Towards Autonomous Multi-Agent Consensus-Seeking**
2411.10184v1 by Valeria Jannelli, Stefan Schoepf, Matthias Bickel, Torbjørn Netland, Alexandra Brintrup

This paper explores how Large Language Models (LLMs) can automate
consensus-seeking in supply chain management (SCM), where frequent decisions on
problems such as inventory levels and delivery times require coordination among
companies. Traditional SCM relies on human consensus in decision-making to
avoid emergent problems like the bullwhip effect. Some routine consensus
processes, especially those that are time-intensive and costly, can be
automated. Existing solutions for automated coordination have faced challenges
due to high entry barriers locking out SMEs, limited capabilities, and limited
adaptability in complex scenarios. However, recent advances in Generative AI,
particularly LLMs, show promise in overcoming these barriers. LLMs, trained on
vast datasets can negotiate, reason, and plan, facilitating near-human-level
consensus at scale with minimal entry barriers. In this work, we identify key
limitations in existing approaches and propose autonomous LLM agents to address
these gaps. We introduce a series of novel, supply chain-specific
consensus-seeking frameworks tailored for LLM agents and validate the
effectiveness of our approach through a case study in inventory management. To
accelerate progress within the SCM community, we open-source our code,
providing a foundation for further advancements in LLM-powered autonomous
supply chain solutions.

摘要：本文探討大型語言模型 (LLM) 如何自動化供應鏈管理 (SCM) 中的共識尋求，其中有關庫存水準和交貨時間等問題的頻繁決策需要各公司之間的協調。傳統的 SCM 依賴於決策制定中的人為共識，以避免牛鞭效應等突發問題。某些例行共識流程，尤其是那些耗時且成本高昂的流程，可以自動化。現有的自動化協調解決方案因高進入門檻將中小型企業拒之門外、功能受限以及在複雜場景中適應性不足等挑戰而面臨困境。然而，生成式 AI 的最新進展，尤其是 LLM，顯示出克服這些障礙的希望。在龐大資料集上訓練的 LLM 可以協商、推理和規劃，從而以最小的進入門檻促進接近人類水準的大規模共識。在這項工作中，我們找出現有方法中的主要限制，並提出自主 LLM 代理來解決這些差距。我們引入一系列針對 LLM 代理量身打造的新穎供應鏈特定共識尋求框架，並透過庫存管理中的個案研究驗證我們方法的有效性。為了加速 SCM 社群內的進展，我們開放原始碼，為 LLM 驅動的自主供應鏈解決方案的進一步進展奠定基礎。

##### **The Surprising Ineffectiveness of Pre-Trained Visual Representations for Model-Based Reinforcement Learning**
2411.10175v1 by Moritz Schneider, Robert Krug, Narunas Vaskevicius, Luigi Palmieri, Joschka Boedecker

Visual Reinforcement Learning (RL) methods often require extensive amounts of
data. As opposed to model-free RL, model-based RL (MBRL) offers a potential
solution with efficient data utilization through planning. Additionally, RL
lacks generalization capabilities for real-world tasks. Prior work has shown
that incorporating pre-trained visual representations (PVRs) enhances sample
efficiency and generalization. While PVRs have been extensively studied in the
context of model-free RL, their potential in MBRL remains largely unexplored.
In this paper, we benchmark a set of PVRs on challenging control tasks in a
model-based RL setting. We investigate the data efficiency, generalization
capabilities, and the impact of different properties of PVRs on the performance
of model-based agents. Our results, perhaps surprisingly, reveal that for MBRL
current PVRs are not more sample efficient than learning representations from
scratch, and that they do not generalize better to out-of-distribution (OOD)
settings. To explain this, we analyze the quality of the trained dynamics
model. Furthermore, we show that data diversity and network architecture are
the most important contributors to OOD generalization performance.

摘要：視覺強化學習 (RL) 方法通常需要大量資料。與無模型 RL 相比，基於模型的 RL (MBRL) 提供了一種潛在的解決方案，可透過規劃有效利用資料。此外，RL 缺乏針對真實世界任務的泛化能力。先前的研究表明，加入預先訓練的視覺表徵 (PVR) 可提高取樣效率和泛化能力。雖然 PVR 已在無模型 RL 的背景下廣泛研究，但它們在 MBRL 中的潛力仍未被充分探索。在本文中，我們在基於模型的 RL 設定中對具有挑戰性的控制任務進行一組 PVR 的基準測試。我們探討資料效率、泛化能力，以及 PVR 的不同屬性對基於模型代理程式效能的影響。我們的結果也許令人驚訝地揭示，對於 MBRL，目前的 PVR 並不比從頭開始學習表徵更能有效利用取樣，而且它們在不符合分佈 (OOD) 設定下的泛化能力並未更好。為了解釋這一點，我們分析了訓練動態模型的品質。此外，我們證明資料多樣性和網路架構是 OOD 泛化效能最重要的貢獻者。

##### **A Hard-Label Cryptanalytic Extraction of Non-Fully Connected Deep Neural Networks using Side-Channel Attacks**
2411.10174v1 by Benoit Coqueret, Mathieu Carbone, Olivier Sentieys, Gabriel Zaid

During the past decade, Deep Neural Networks (DNNs) proved their value on a
large variety of subjects. However despite their high value and public
accessibility, the protection of the intellectual property of DNNs is still an
issue and an emerging research field. Recent works have successfully extracted
fully-connected DNNs using cryptanalytic methods in hard-label settings,
proving that it was possible to copy a DNN with high fidelity, i.e., high
similitude in the output predictions. However, the current cryptanalytic
attacks cannot target complex, i.e., not fully connected, DNNs and are limited
to special cases of neurons present in deep networks.
  In this work, we introduce a new end-to-end attack framework designed for
model extraction of embedded DNNs with high fidelity. We describe a new
black-box side-channel attack which splits the DNN in several linear parts for
which we can perform cryptanalytic extraction and retrieve the weights in
hard-label settings. With this method, we are able to adapt cryptanalytic
extraction, for the first time, to non-fully connected DNNs, while maintaining
a high fidelity. We validate our contributions by targeting several
architectures implemented on a microcontroller unit, including a Multi-Layer
Perceptron (MLP) of 1.7 million parameters and a shortened MobileNetv1. Our
framework successfully extracts all of these DNNs with high fidelity (88.4% for
the MobileNetv1 and 93.2% for the MLP). Furthermore, we use the stolen model to
generate adversarial examples and achieve close to white-box performance on the
victim's model (95.8% and 96.7% transfer rate).

摘要：<paragraph>在過去的十年中，深度神經網路 (DNN) 已證明其在各種主題上的價值。然而，儘管它們價值很高且公開可取得，但 DNN 的智慧財產權保護仍然是一個問題和一個新興的研究領域。最近的研究已成功使用密碼分析方法在硬標籤設定中提取完全連接的 DNN，證明可以高保真複製 DNN，即輸出預測中的高相似度。然而，目前的密碼分析攻擊無法針對複雜的（即非完全連接的）DNN，並且僅限於深度網路中存在的神經元特殊情況。
在這項工作中，我們引入了一個新的端到端攻擊框架，專門用於高保真提取嵌入式 DNN 的模型。我們描述了一種新的黑盒側信道攻擊，它將 DNN 分割成幾個線性部分，我們可以對其執行密碼分析提取並在硬標籤設定中檢索權重。使用此方法，我們首次能夠將密碼分析提取適應到非完全連接的 DNN，同時保持高保真度。我們通過針對在微控制器單元上實作的幾個架構來驗證我們的貢獻，包括一個具有 170 萬個參數的多層感知器 (MLP) 和一個縮短的 MobileNetv1。我們的框架成功地以高保真度提取了所有這些 DNN（MobileNetv1 為 88.4%，MLP 為 93.2%）。此外，我們使用被竊取的模型來產生對抗性範例，並在受害者的模型上實現接近白盒效能（傳輸率為 95.8% 和 96.7%）。</paragraph>

##### **Increasing the Accessibility of Causal Domain Knowledge via Causal Information Extraction Methods: A Case Study in the Semiconductor Manufacturing Industry**
2411.10172v1 by Houssam Razouk, Leonie Benischke, Daniel Garber, Roman Kern

The extraction of causal information from textual data is crucial in the
industry for identifying and mitigating potential failures, enhancing process
efficiency, prompting quality improvements, and addressing various operational
challenges. This paper presents a study on the development of automated methods
for causal information extraction from actual industrial documents in the
semiconductor manufacturing industry. The study proposes two types of causal
information extraction methods, single-stage sequence tagging (SST) and
multi-stage sequence tagging (MST), and evaluates their performance using
existing documents from a semiconductor manufacturing company, including
presentation slides and FMEA (Failure Mode and Effects Analysis) documents. The
study also investigates the effect of representation learning on downstream
tasks. The presented case study showcases that the proposed MST methods for
extracting causal information from industrial documents are suitable for
practical applications, especially for semi structured documents such as FMEAs,
with a 93\% F1 score. Additionally, MST achieves a 73\% F1 score on texts
extracted from presentation slides. Finally, the study highlights the
importance of choosing a language model that is more aligned with the domain
and in-domain fine-tuning.

摘要：從文本資料中萃取因果資訊對於產業來說至關重要，可以找出並減輕潛在故障、提升流程效率、促使品質改善，並解決各種營運挑戰。本篇論文探討自動化方法在半導體製造產業中從實際產業文件萃取因果資訊的發展。本研究提出兩種因果資訊萃取方法，單階段序列標註 (SST) 和多階段序列標註 (MST)，並使用半導體製造公司的既有文件評估其效能，包括簡報投影片和 FMEA（故障模式與影響分析）文件。本研究也探討表徵學習對下游任務的影響。提出的個案研究展示，提出的 MST 方法用於從產業文件中萃取因果資訊，適合實際應用，特別是對於半結構化文件（例如 FMEA），F1 分數為 93%。此外，MST 在從簡報投影片中萃取的文字上達到 73% 的 F1 分數。最後，本研究強調選擇與領域更一致的語言模型，以及領域內微調的重要性。

##### **Imagine-2-Drive: High-Fidelity World Modeling in CARLA for Autonomous Vehicles**
2411.10171v1 by Anant Garg, K Madhava Krishna

In autonomous driving with image based state space, accurate prediction of
future events and modeling diverse behavioral modes are essential for safety
and effective decision-making. World model-based Reinforcement Learning (WMRL)
approaches offers a promising solution by simulating future states from current
state and actions. However, utility of world models is often limited by typical
RL policies being limited to deterministic or single gaussian distribution. By
failing to capture the full spectrum of possible actions, reduces their
adaptability in complex, dynamic environments. In this work, we introduce
Imagine-2-Drive, a framework that consists of two components, VISTAPlan, a
high-fidelity world model for accurate future prediction and Diffusion Policy
Actor (DPA), a diffusion based policy to model multi-modal behaviors for
trajectory prediction. We use VISTAPlan to simulate and evaluate trajectories
from DPA and use Denoising Diffusion Policy Optimization (DDPO) to train DPA to
maximize the cumulative sum of rewards over the trajectories. We analyze the
benefits of each component and the framework as a whole in CARLA with standard
driving metrics. As a consequence of our twin novelties- VISTAPlan and DPA, we
significantly outperform the state of the art (SOTA) world models on standard
driving metrics by 15% and 20% on Route Completion and Success Rate
respectively.

摘要：在以影像為基礎的狀態空間中進行自動駕駛時，準確預測未來事件和建模多樣化的行為模式對於安全和有效的決策制定至關重要。基於世界模型的強化學習 (WMRL) 方法通過從當前狀態和動作模擬未來狀態，提供了一個有前途的解決方案。然而，世界模型的效用通常受到典型 RL 策略僅限於確定性或單一高斯分布的限制。由於未能捕捉到所有可能的動作，降低了它們在複雜、動態環境中的適應性。在這項工作中，我們引入了 Imagine-2-Drive，一個由兩個組成部分組成的框架，VISTAPlan，一個用於準確未來預測的高保真世界模型和擴散策略執行器 (DPA)，一個基於擴散的策略，用於對多模態行為進行建模以進行軌跡預測。我們使用 VISTAPlan 從 DPA 模擬和評估軌跡，並使用去噪擴散策略優化 (DDPO) 訓練 DPA 以最大化軌跡上獎勵的累計和。我們分析了每個組成部分和整個框架在 CARLA 中的優點，並使用標準的駕駛指標。作為我們 VISTAPlan 和 DPA 這兩個新穎之處的結果，我們在標準駕駛指標上顯著優於最先進 (SOTA) 的世界模型，在路線完成和成功率上分別提高了 15% 和 20%。

##### **Evaluating the role of `Constitutions' for learning from AI feedback**
2411.10168v1 by Saskia Redgate, Andrew M. Bean, Adam Mahdi

The growing capabilities of large language models (LLMs) have led to their
use as substitutes for human feedback for training and assessing other LLMs.
These methods often rely on `constitutions', written guidelines which a critic
model uses to provide feedback and improve generations. We investigate how the
choice of constitution affects feedback quality by using four different
constitutions to improve patient-centered communication in medical interviews.
In pairwise comparisons conducted by 215 human raters, we found that detailed
constitutions led to better results regarding emotive qualities. However, none
of the constitutions outperformed the baseline in learning more
practically-oriented skills related to information gathering and provision. Our
findings indicate that while detailed constitutions should be prioritised,
there are possible limitations to the effectiveness of AI feedback as a reward
signal in certain areas.

摘要：大型語言模型（LLM）功能不斷增強，促使它們被用作人類回饋的替代品，以訓練和評估其他 LLM。這些方法通常依賴於「憲法」，也就是評論模型用來提供回饋和改進生成的書面準則。我們探討憲法選擇如何影響回饋品質，方法是使用四種不同的憲法來改善醫療訪談中的以患者為中心的溝通。在 215 位人類評分員進行的成對比較中，我們發現詳細的憲法在情緒品質方面帶來更好的結果。然而，沒有任何憲法在學習與資訊收集和提供相關的更實用技能方面優於基準。我們的研究結果表明，雖然應優先考慮詳細的憲法，但 AI 回饋作為特定領域的獎勵訊號的有效性可能有限。

##### **Compound-QA: A Benchmark for Evaluating LLMs on Compound Questions**
2411.10163v1 by Yutao Hou, Yajing Luo, Zhiwen Ruan, Hongru Wang, Weifeng Ge, Yun Chen, Guanhua Chen

Large language models (LLMs) demonstrate remarkable performance across
various tasks, prompting researchers to develop diverse evaluation benchmarks.
However, existing benchmarks typically measure the ability of LLMs to respond
to individual questions, neglecting the complex interactions in real-world
applications. In this paper, we introduce Compound Question Synthesis (CQ-Syn)
to create the Compound-QA benchmark, focusing on compound questions with
multiple sub-questions. This benchmark is derived from existing QA datasets,
annotated with proprietary LLMs and verified by humans for accuracy. It
encompasses five categories: Factual-Statement, Cause-and-Effect,
Hypothetical-Analysis, Comparison-and-Selection, and Evaluation-and-Suggestion.
It evaluates the LLM capability in terms of three dimensions including
understanding, reasoning, and knowledge. Our assessment of eight open-source
LLMs using Compound-QA reveals distinct patterns in their responses to compound
questions, which are significantly poorer than those to non-compound questions.
Additionally, we investigate various methods to enhance LLMs performance on
compound questions. The results indicate that these approaches significantly
improve the models' comprehension and reasoning abilities on compound
questions.

摘要：大型語言模型 (LLM) 在各種任務中展現出顯著的效能，促使研究人員開發多元的評量基準。不過，現有的基準通常測量 LLM 回應個別問題的能力，忽略了真實世界應用中的複雜互動。在本文中，我們介紹複合問題合成 (CQ-Syn) 來建立複合式問答基準，重點在於具有多個子問題的複合式問題。此基準來自現有的問答資料集，由專有的 LLM 加上註解，並由人類驗證其準確性。它包含五個類別：事實陳述、因果關係、假設分析、比較與選擇，以及評估與建議。它在理解、推理和知識等三個面向評估 LLM 的能力。我們使用複合式問答評估八個開源 LLM，揭露它們在回應複合式問題時的不同模式，顯著低於非複合式問題的模式。此外，我們探討各種方法來增強 LLM 在複合式問題上的效能。結果顯示，這些方法顯著改善模型在複合式問題上的理解和推理能力。

##### **Mitigating Sycophancy in Decoder-Only Transformer Architectures: Synthetic Data Intervention**
2411.10156v1 by Libo Wang

To address the sycophancy problem caused by reinforcement learning from human
feedback in large language models, this research applies synthetic data
intervention technology to the decoder-only transformer architecture. Based on
the research gaps in the existing literature, the researcher designed an
experimental process to reduce the tendency of models to cater by generating
diversified data, and used GPT4o as an experimental tool for verification. The
experiment used 100 true and false questions, and compared the performance of
the model trained with synthetic data intervention and the original untrained
model on multiple indicators. The results show that the SDI training model
supports the technology in terms of accuracy rate and sycophancy rate and has
significant effectiveness in reducing sycophancy phenomena. Notably, the data
set, experimental process, code and data results have been uploaded to Github,
the link is https://github.com/brucewang123456789/GeniusTrail.git.

摘要：為了解決大型語言模型中因人類反饋的強化學習所造成的阿諛奉承問題，本研究將合成資料介入技術應用於僅解碼器Transformer架構中。研究者基於現有文獻中的研究缺口，設計了一個實驗流程，透過生成多元資料來減少模型迎合的傾向，並以 GPT4o 作為驗證的實驗工具。實驗中採用 100 題是非題，並比較了使用合成資料介入訓練的模型與原未訓練模型在多項指標上的表現。結果顯示，SDI 訓練模型在準確率與阿諛奉承率上，皆支持了技術對於減少阿諛奉承現象的顯著成效。特別的是，資料集、實驗流程、程式碼與資料結果已上傳至 Github，連結為 https://github.com/brucewang123456789/GeniusTrail.git。

##### **Causal Time-Series Synchronization for Multi-Dimensional Forecasting**
2411.10152v1 by Michael Mayr, Georgios C. Chasparis, Josef Küng

The process industry's high expectations for Digital Twins require modeling
approaches that can generalize across tasks and diverse domains with
potentially different data dimensions and distributional shifts i.e.,
Foundational Models. Despite success in natural language processing and
computer vision, transfer learning with (self-) supervised signals for
pre-training general-purpose models is largely unexplored in the context of
Digital Twins in the process industry due to challenges posed by
multi-dimensional time-series data, lagged cause-effect dependencies, complex
causal structures, and varying number of (exogenous) variables. We propose a
novel channel-dependent pre-training strategy that leverages synchronized
cause-effect pairs to overcome these challenges by breaking down the
multi-dimensional time-series data into pairs of cause-effect variables. Our
approach focuses on: (i) identifying highly lagged causal relationships using
data-driven methods, (ii) synchronizing cause-effect pairs to generate training
samples for channel-dependent pre-training, and (iii) evaluating the
effectiveness of this approach in channel-dependent forecasting. Our
experimental results demonstrate significant improvements in forecasting
accuracy and generalization capability compared to traditional training
methods.

摘要：製程產業對數位分身的高期望需要建模方法，這些方法能夠在任務和不同的領域中概化，並具有潛在不同的資料維度和分佈轉移，也就是基礎模型。儘管在自然語言處理和電腦視覺方面獲得成功，但針對製程產業中的數位分身，利用（自我）監督訊號進行轉移學習以預先訓練通用模型在很大程度上仍未探索，原因在於多維時間序列資料、滯後因果依賴性、複雜因果結構和變數（外生）數量多變所帶來的挑戰。我們提出了一種新穎的通道依賴預訓練策略，該策略利用同步的因果對來克服這些挑戰，方法是將多維時間序列資料分解成因果變數對。我們的做法著重於：(i) 使用資料驅動方法識別高度滯後的因果關係，(ii) 同步因果對以產生通道依賴預訓練的訓練樣本，以及 (iii) 評估此方法在通道依賴預測中的有效性。我們的實驗結果顯示，與傳統訓練方法相比，預測準確度和概化能力有顯著的提升。

##### **An Effective Framework to Help Large Language Models Handle Numeric-involved Long-context Tasks**
2411.10145v1 by Yijiong Yu

Large Language Models (LLMs) have demonstrated remarkable capabilities in
handling long texts and have almost perfect performance in traditional
retrieval tasks. However, their performance significantly degrades when it
comes to numerical calculations in the long-context. Numeric-involved
long-context tasks typically cannot be addressed by current LLMs in normal
settings due to their inherent limitations in simultaneously handling complex
and massive information. Some CoT like prompting methods can improve accuracy
but demands massive output tokens, which is costly and slow. To address this
issue, we propose a workflow, which decompose a numeric-involved long-context
task into 4 low-level subtasks: judging, extracting and processing with code
and conclusion. The former 2 subtasks is relatively simple, which allows us to
use smaller models for efficiently processing long context. When numerical
calculations are required, we use code generated by LLMs to avoid the
disadvantage of LLM not being good at calculations. The results in 2
numeric-involved long-context benchmarks demonstrate our workflow can not only
improve accuracy, but also significantly reduce the cost of API calls.

摘要：大型語言模型 (LLM) 在處理長篇文字方面展現出驚人的能力，在傳統的檢索任務中表現近乎完美。然而，在處理長語境中的數值計算時，它們的表現卻大幅下降。由於 LLM 本身在同時處理複雜且大量的資訊時有其限制，因此涉及數值的長語境任務通常無法在正常設定下由目前的 LLM 處理。一些 CoT（例如提示方法）可以提高準確性，但需要大量的輸出 token，這既昂貴又緩慢。為了解決這個問題，我們提出了一個工作流程，將涉及數值的長語境任務分解為 4 個低階子任務：判斷、萃取和處理程式碼以及結論。前 2 個子任務相對簡單，這讓我們得以使用較小的模型來有效處理長語境。當需要數值計算時，我們會使用 LLM 生成的程式碼來避免 LLM 不擅長計算的缺點。在 2 個涉及數值的長語境基準測試中的結果顯示，我們的這個工作流程不僅可以提高準確性，還能大幅降低 API 呼叫的成本。

##### **Legal Evalutions and Challenges of Large Language Models**
2411.10137v1 by Jiaqi Wang, Huan Zhao, Zhenyuan Yang, Peng Shu, Junhao Chen, Haobo Sun, Ruixi Liang, Shixin Li, Pengcheng Shi, Longjun Ma, Zongjia Liu, Zhengliang Liu, Tianyang Zhong, Yutong Zhang, Chong Ma, Xin Zhang, Tuo Zhang, Tianli Ding, Yudan Ren, Tianming Liu, Xi Jiang, Shu Zhang

In this paper, we review legal testing methods based on Large Language Models
(LLMs), using the OPENAI o1 model as a case study to evaluate the performance
of large models in applying legal provisions. We compare current
state-of-the-art LLMs, including open-source, closed-source, and legal-specific
models trained specifically for the legal domain. Systematic tests are
conducted on English and Chinese legal cases, and the results are analyzed in
depth. Through systematic testing of legal cases from common law systems and
China, this paper explores the strengths and weaknesses of LLMs in
understanding and applying legal texts, reasoning through legal issues, and
predicting judgments. The experimental results highlight both the potential and
limitations of LLMs in legal applications, particularly in terms of challenges
related to the interpretation of legal language and the accuracy of legal
reasoning. Finally, the paper provides a comprehensive analysis of the
advantages and disadvantages of various types of models, offering valuable
insights and references for the future application of AI in the legal field.

摘要：<paragraph>在本文中，我們回顧基於大型語言模型 (LLM) 的法律測試方法，使用 OPENAI o1 模型作為案例研究來評估大型模型在應用法律條款方面的性能。我們比較了當前最先進的 LLM，包括專門針對法律領域訓練的開源、閉源和法律特定模型。對英語和中文法律案例進行了系統測試，並對結果進行了深入分析。通過對普通法系和中國法律案例的系統測試，本文探討了 LLM 在理解和應用法律文本、推理法律問題和預測判決方面的優缺點。實驗結果突出了 LLM 在法律應用中的潛力和局限性，特別是在與法律語言解釋和法律推理準確性相關的挑戰方面。最後，本文對各種類型模型的優缺點進行了全面分析，為人工智能在法律領域的未來應用提供了寶貴的見解和參考。</paragraph>

##### **Prompting and Fine-tuning Large Language Models for Automated Code Review Comment Generation**
2411.10129v1 by Md. Asif Haider, Ayesha Binte Mostofa, Sk. Sabit Bin Mosaddek, Anindya Iqbal, Toufique Ahmed

Generating accurate code review comments remains a significant challenge due
to the inherently diverse and non-unique nature of the task output. Large
language models pretrained on both programming and natural language data tend
to perform well in code-oriented tasks. However, large-scale pretraining is not
always feasible due to its environmental impact and project-specific
generalizability issues. In this work, first we fine-tune open-source Large
language models (LLM) in parameter-efficient, quantized low-rank (QLoRA)
fashion on consumer-grade hardware to improve review comment generation. Recent
studies demonstrate the efficacy of augmenting semantic metadata information
into prompts to boost performance in other code-related tasks. To explore this
in code review activities, we also prompt proprietary, closed-source LLMs
augmenting the input code patch with function call graphs and code summaries.
Both of our strategies improve the review comment generation performance, with
function call graph augmented few-shot prompting on the GPT-3.5 model
surpassing the pretrained baseline by around 90% BLEU-4 score on the
CodeReviewer dataset. Moreover, few-shot prompted Gemini-1.0 Pro, QLoRA
fine-tuned Code Llama and Llama 3.1 models achieve competitive results (ranging
from 25% to 83% performance improvement) on this task. An additional human
evaluation study further validates our experimental findings, reflecting
real-world developers' perceptions of LLM-generated code review comments based
on relevant qualitative metrics.

摘要：<paragraph>產生準確的程式碼審查評論仍然是一個重大挑戰，因為任務輸出的本質上是多樣且非獨特的。在程式設計和自然語言資料上進行預訓練的大型語言模型往往在以程式碼為導向的任務中表現良好。然而，由於其對環境的影響和專案特定的一般化問題，大規模預訓練並非總是可行的。在這項工作中，我們首先在參數有效、量化的低秩 (QLoRA) 方式中微調開源大型語言模型 (LLM)，在消費級硬體上改善審查評論的產生。最近的研究證明了在提示中增加語義元資料資訊以提升其他與程式碼相關任務中效能的功效。為了在程式碼審查活動中探索這一點，我們也提示專有的、閉源 LLM，使用函數呼叫圖和程式碼摘要來增加輸入程式碼修補程式。我們的兩種策略都改善了審查評論產生的效能，在 GPT-3.5 模型上使用函數呼叫圖增加的少量提示，在 CodeReviewer 資料集上超越了預訓練基準，BLEU-4 分數提高了約 90%。此外，少量提示的 Gemini-1.0 Pro、QLoRA 微調的 Code Llama 和 Llama 3.1 模型在此任務上達到了有競爭力的結果（效能提升範圍為 25% 至 83%）。額外的使用者評估研究進一步驗證了我們的實驗結果，反映了實際開發人員對 LLM 產生的程式碼審查評論的看法，這些看法基於相關的定性指標。</paragraph>

##### **Memorization in Attention-only Transformers**
2411.10115v1 by Léo Dana, Muni Sreenivas Pydi, Yann Chevaleyre

Recent research has explored the memorization capacity of multi-head
attention, but these findings are constrained by unrealistic limitations on the
context size. We present a novel proof for language-based Transformers that
extends the current hypothesis to any context size. Our approach improves upon
the state-of-the-art by achieving more effective exact memorization with an
attention layer, while also introducing the concept of approximate memorization
of distributions. Through experimental validation, we demonstrate that our
proposed bounds more accurately reflect the true memorization capacity of
language models, and provide a precise comparison with prior work.

摘要：最近的研究探討了多頭注意力的記憶容量，但這些發現受到上下文大小的不切實際限制。我們提出了一個基於語言的 Transformer 的新證明，將當前假設延伸到任何上下文大小。我們的做法透過使用注意力層實現更有效的精確記憶，同時也引入了近似記憶分佈的概念，從而改進了現有技術。透過實驗驗證，我們證明了我們提出的界線更準確地反映了語言模型的真正記憶容量，並提供了與先前工作的精確比較。

##### **Generative Agent Simulations of 1,000 People**
2411.10109v1 by Joon Sung Park, Carolyn Q. Zou, Aaron Shaw, Benjamin Mako Hill, Carrie Cai, Meredith Ringel Morris, Robb Willer, Percy Liang, Michael S. Bernstein

The promise of human behavioral simulation--general-purpose computational
agents that replicate human behavior across domains--could enable broad
applications in policymaking and social science. We present a novel agent
architecture that simulates the attitudes and behaviors of 1,052 real
individuals--applying large language models to qualitative interviews about
their lives, then measuring how well these agents replicate the attitudes and
behaviors of the individuals that they represent. The generative agents
replicate participants' responses on the General Social Survey 85% as
accurately as participants replicate their own answers two weeks later, and
perform comparably in predicting personality traits and outcomes in
experimental replications. Our architecture reduces accuracy biases across
racial and ideological groups compared to agents given demographic
descriptions. This work provides a foundation for new tools that can help
investigate individual and collective behavior.

摘要：人類行為模擬的承諾——通用計算代理，可複製人類跨領域的行為——可以在政策制定和社會科學中實現廣泛的應用。我們提出了一種新穎的代理架構，模擬了 1,052 位真實個體的態度和行為——將大型語言模型應用於對他們生活進行的質性訪談，然後衡量這些代理人複製他們所代表的個體的態度和行為的程度。生成式代理在一般社會調查中複製參與者的回答準確度為 85%，與參與者兩週後複製自己的答案一樣準確，並且在實驗複製中預測人格特質和結果方面表現相當。與提供人口統計描述的代理相比，我們的架構減少了跨種族和意識形態群體的準確性偏差。這項工作為新工具奠定了基礎，這些工具可以幫助調查個人和集體行為。

##### **Identifying Key Drivers of Heatwaves: A Novel Spatio-Temporal Framework for Extreme Event Detection**
2411.10108v1 by J. Pérez-Aracil, C. Peláez-Rodríguez, Ronan McAdam, Antonello Squintu, Cosmin M. Marina, Eugenio Lorente-Ramos, Niklas Luther, Veronica Torralba, Enrico Scoccimarro, Leone Cavicchia, Matteo Giuliani, Eduardo Zorita, Felicitas Hansen, David Barriopedro, Ricardo Garcia-Herrera, Pedro A. Gutiérrez, Jürg Luterbacher, Elena Xoplaki, Andrea Castelletti, S. Salcedo-Sanz

Heatwaves (HWs) are extreme atmospheric events that produce significant
societal and environmental impacts. Predicting these extreme events remains
challenging, as their complex interactions with large-scale atmospheric and
climatic variables are difficult to capture with traditional statistical and
dynamical models. This work presents a general method for driver identification
in extreme climate events. A novel framework (STCO-FS) is proposed to identify
key immediate (short-term) HW drivers by combining clustering algorithms with
an ensemble evolutionary algorithm. The framework analyzes spatio-temporal
data, reduces dimensionality by grouping similar geographical nodes for each
variable, and develops driver selection in spatial and temporal domains,
identifying the best time lags between predictive variables and HW occurrences.
The proposed method has been applied to analyze HWs in the Adda river basin in
Italy. The approach effectively identifies significant variables influencing
HWs in this region. This research can potentially enhance our understanding of
HW drivers and predictability.

摘要：熱浪 (HWs) 是極端的氣象事件，會產生重大的社會和環境影響。預測這些極端事件仍然具有挑戰性，因為它們與大規模大氣和氣候變數的複雜交互作用難以透過傳統的統計和動力模型捕捉。這項工作提出了一種用於極端氣候事件中驅動因素識別的通用方法。提出一個新穎的框架 (STCO-FS) 來識別關鍵的立即 (短期) HW 驅動因素，方法是將聚類演算法與整體演化演算法結合。該框架分析時空資料，透過為每個變數分組類似的地理節點來降低維度，並在空間和時間域中開發驅動因素選擇，找出預測變數和 HW 發生之間最佳的時間差。所提出的方法已應用於分析義大利阿達河流域中的 HWs。這種方法有效地識別出影響該地區 HWs 的重要變數。這項研究有可能增強我們對 HW 驅動因素和可預測性的理解。

##### **Multi-Task Adversarial Variational Autoencoder for Estimating Biological Brain Age with Multimodal Neuroimaging**
2411.10100v1 by Muhammad Usman, Azka Rehman, Abdullah Shahid, Abd Ur Rehman, Sung-Min Gho, Aleum Lee, Tariq M. Khan, Imran Razzak

Despite advances in deep learning for estimating brain age from structural
MRI data, incorporating functional MRI data is challenging due to its complex
structure and the noisy nature of functional connectivity measurements. To
address this, we present the Multitask Adversarial Variational Autoencoder, a
custom deep learning framework designed to improve brain age predictions
through multimodal MRI data integration. This model separates latent variables
into generic and unique codes, isolating shared and modality-specific features.
By integrating multitask learning with sex classification as an additional
task, the model captures sex-specific aging patterns. Evaluated on the OpenBHB
dataset, a large multisite brain MRI collection, the model achieves a mean
absolute error of 2.77 years, outperforming traditional methods. This success
positions M-AVAE as a powerful tool for metaverse-based healthcare applications
in brain age estimation.

摘要：儘管深度學習在根據結構性 MRI 資料估計大腦年齡方面有進展，但由於其複雜的結構和功能性連結測量的雜訊性質，整合功能性 MRI 資料仍然具有挑戰性。為了解決這個問題，我們提出了多任務對抗變異自動編碼器，這是一個客製化的深度學習架構，旨在透過多模式 MRI 資料整合來改善大腦年齡預測。此模型將潛在變數分為一般和獨特代碼，隔離共享和特定於模式的功能。透過將多任務學習與性別分類整合為額外任務，此模型擷取了特定於性別的老化模式。在大型多場域大腦 MRI 蒐集的 OpenBHB 資料集上進行評估，此模型達到了 2.77 年的平均絕對誤差，優於傳統方法。這項成功讓 M-AVAE 成為大腦年齡估計中基於元宇宙的醫療保健應用中強大的工具。

##### **PFML: Self-Supervised Learning of Time-Series Data Without Representation Collapse**
2411.10087v1 by Einari Vaaras, Manu Airaksinen, Okko Räsänen

Self-supervised learning (SSL) is a data-driven learning approach that
utilizes the innate structure of the data to guide the learning process. In
contrast to supervised learning, which depends on external labels, SSL utilizes
the inherent characteristics of the data to produce its own supervisory signal.
However, one frequent issue with SSL methods is representation collapse, where
the model outputs a constant input-invariant feature representation. This issue
hinders the potential application of SSL methods to new data modalities, as
trying to avoid representation collapse wastes researchers' time and effort.
This paper introduces a novel SSL algorithm for time-series data called
Prediction of Functionals from Masked Latents (PFML). Instead of predicting
masked input signals or their latent representations directly, PFML operates by
predicting statistical functionals of the input signal corresponding to masked
embeddings, given a sequence of unmasked embeddings. The algorithm is designed
to avoid representation collapse, rendering it straightforwardly applicable to
different time-series data domains, such as novel sensor modalities in clinical
data. We demonstrate the effectiveness of PFML through complex, real-life
classification tasks across three different data modalities: infant posture and
movement classification from multi-sensor inertial measurement unit data,
emotion recognition from speech data, and sleep stage classification from EEG
data. The results show that PFML is superior to a conceptually similar
pre-existing SSL method and competitive against the current state-of-the-art
SSL method, while also being conceptually simpler and without suffering from
representation collapse.

摘要：自监督学习 (SSL) 是一种数据驱动的学习方法，它利用数据的内在结构来指导学习过程。与依赖外部标签的监督学习相反，SSL 利用数据本身的固有特征来产生自己的监督信号。然而，SSL 方法的一个常见问题是表示坍塌，其中模型输出一个常数输入不变特征表示。这个问题阻碍了 SSL 方法在新的数据模式中的潜在应用，因为试图避免表示坍塌会浪费研究人员的时间和精力。本文介绍了一种针对时间序列数据的新型 SSL 算法，称为掩码潜在变量的功能预测 (PFML)。PFML 不是直接预测掩码输入信号或其潜在表示，而是通过预测输入信号的统计函数（对应于掩码嵌入）来操作，给定一系列未掩码嵌入。该算法旨在避免表示坍塌，使其可以直接应用于不同的时间序列数据域，例如临床数据中的新型传感器模式。我们通过三个不同数据模式的复杂现实生活分类任务展示了 PFML 的有效性：多传感器惯性测量单元数据的婴儿姿势和运动分类、语音数据的语音识别以及脑电图数据的睡眠阶段分类。结果表明，PFML 优于概念上相似的现有 SSL 方法，并且与当前最先进的 SSL 方法具有竞争力，同时在概念上更简单，并且不会出现表示坍塌。

##### **Adapting the Biological SSVEP Response to Artificial Neural Networks**
2411.10084v1 by Emirhan Böge, Yasemin Gunindi, Erchan Aptoula, Nihan Alp, Huseyin Ozkan

Neuron importance assessment is crucial for understanding the inner workings
of artificial neural networks (ANNs) and improving their interpretability and
efficiency. This paper introduces a novel approach to neuron significance
assessment inspired by frequency tagging, a technique from neuroscience. By
applying sinusoidal contrast modulation to image inputs and analyzing resulting
neuron activations, this method enables fine-grained analysis of a network's
decision-making processes. Experiments conducted with a convolutional neural
network for image classification reveal notable harmonics and intermodulations
in neuron-specific responses under part-based frequency tagging. These findings
suggest that ANNs exhibit behavior akin to biological brains in tuning to
flickering frequencies, thereby opening avenues for neuron/filter importance
assessment through frequency tagging. The proposed method holds promise for
applications in network pruning, and model interpretability, contributing to
the advancement of explainable artificial intelligence and addressing the lack
of transparency in neural networks. Future research directions include
developing novel loss functions to encourage biologically plausible behavior in
ANNs.

摘要：神經元重要性評估對於理解人工神經網路 (ANN) 的內部運作，以及提升其可解釋性和效率至關重要。本文介紹一種受頻率標記啟發的神經元重要性評估新方法，頻率標記是一種來自神經科學的技術。透過將正弦對比調變應用於影像輸入，並分析產生的神經元活化，此方法能對網路的決策制定過程進行細緻的分析。使用卷積神經網路進行影像分類所執行的實驗，揭示了在基於部分的頻率標記下，神經元特定反應中顯著的諧波和互調。這些發現表明，ANN 在調整閃爍頻率時表現出類似於生物大腦的行為，從而為透過頻率標記進行神經元/濾波器重要性評估開啟了途徑。所提出的方法有望應用於網路剪枝和模型可解釋性，有助於可解釋人工智慧的進步，並解決神經網路中缺乏透明度。未來的研究方向包括開發新的損失函數，以鼓勵 ANN 中具有生物學上合理行為。

##### **Xmodel-1.5: An 1B-scale Multilingual LLM**
2411.10083v1 by Wang Qun, Liu Yang, Lin Qingquan, Jiang Ling

We introduce Xmodel-1.5, a novel 1-billion-parameter multilingual large model
pretrained on approximately 2 trillion tokens. The model demonstrates strong
performance across several languages, with particularly notable results in
Thai, Arabic, and French, alongside its effectiveness in Chinese and English.
In addition, we contribute to the research community by releasing a Thai
evaluation dataset, which includes hundreds of questions annotated by students
from Chulalongkorn University's School of Integrated Innovation. While the
results are promising, we acknowledge that there is still room for improvement.
We hope this work advances ongoing efforts in multilingual AI research and
promotes better cross-linguistic understanding in various natural language
processing tasks. Our models and code are publicly available on GitHub at
https://github.com/XiaoduoAILab/XmodelLM.

摘要：我們推出 Xmodel-1.5，一個新穎的 10 億參數多語言大型模型，預訓練約 2 兆個符號。該模型在多種語言中展現強勁的效能，在泰語、阿拉伯語和法語中有特別顯著的結果，同時在中文和英文方面也十分有效。此外，我們透過釋出泰語評估資料集來為研究社群做出貢獻，其中包含數百個由朱拉隆功大學綜合創新學院學生註解的問題。儘管結果令人振奮，我們承認仍有進步空間。我們希望這項工作能促進多語言 AI 研究的持續努力，並在各種自然語言處理任務中促進更好的跨語言理解。我們的模型和程式碼已公開發布在 GitHub 上，網址為 https://github.com/XiaoduoAILab/XmodelLM。

##### **Understanding The Effect Of Temperature On Alignment With Human Opinions**
2411.10080v1 by Maja Pavlovic, Massimo Poesio

With the increasing capabilities of LLMs, recent studies focus on
understanding whose opinions are represented by them and how to effectively
extract aligned opinion distributions. We conducted an empirical analysis of
three straightforward methods for obtaining distributions and evaluated the
results across a variety of metrics. Our findings suggest that sampling and
log-probability approaches with simple parameter adjustments can return better
aligned outputs in subjective tasks compared to direct prompting. Yet, assuming
models reflect human opinions may be limiting, highlighting the need for
further research on how human subjectivity affects model uncertainty.

摘要：隨著 LLM 能力的提升，近期研究著重於了解 LLM 所代表的意見來自何人，以及如何有效提取對齊的意見分佈。我們對三種用於取得分佈的直接方法進行實證分析，並根據各種指標評估結果。我們的研究結果顯示，與直接提示相比，取樣和對數機率方法搭配簡單的參數調整，可以在主觀任務中回傳更對齊的輸出。然而，假設模型反映人類意見可能有所限制，這凸顯了進一步研究人類主觀性如何影響模型不確定性的必要性。

##### **Real-Time AI-Driven People Tracking and Counting Using Overhead Cameras**
2411.10072v1 by Ishrath Ahamed, Chamith Dilshan Ranathunga, Dinuka Sandun Udayantha, Benny Kai Kiat Ng, Chau Yuen

Accurate people counting in smart buildings and intelligent transportation
systems is crucial for energy management, safety protocols, and resource
allocation. This is especially critical during emergencies, where precise
occupant counts are vital for safe evacuation. Existing methods struggle with
large crowds, often losing accuracy with even a few additional people. To
address this limitation, this study proposes a novel approach combining a new
object tracking algorithm, a novel counting algorithm, and a fine-tuned object
detection model. This method achieves 97% accuracy in real-time people counting
with a frame rate of 20-27 FPS on a low-power edge computer.

摘要：在智慧型建築和智慧交通系統中準確計算人數對於能源管理、安全協定和資源分配至關重要。這在緊急情況下尤其重要，因為精確的居住者人數對於安全疏散至關重要。現有方法難以應付大量人群，即使增加少數人也會降低準確度。為了解決這個限制，本研究提出了一個創新的方法，結合一種新的物件追蹤演算法、一種新的計數演算法和一個微調的物件偵測模型。此方法在低功耗邊緣電腦上以 20-27 FPS 的幀率進行即時人數計算，準確率達到 97%。

##### **Evidential Federated Learning for Skin Lesion Image Classification**
2411.10071v1 by Rutger Hendrix, Federica Proietto Salanitri, Concetto Spampinato, Simone Palazzo, Ulas Bagci

We introduce FedEvPrompt, a federated learning approach that integrates
principles of evidential deep learning, prompt tuning, and knowledge
distillation for distributed skin lesion classification. FedEvPrompt leverages
two sets of prompts: b-prompts (for low-level basic visual knowledge) and
t-prompts (for task-specific knowledge) prepended to frozen pre-trained Vision
Transformer (ViT) models trained in an evidential learning framework to
maximize class evidences. Crucially, knowledge sharing across federation
clients is achieved only through knowledge distillation on attention maps
generated by the local ViT models, ensuring enhanced privacy preservation
compared to traditional parameter or synthetic image sharing methodologies.
FedEvPrompt is optimized within a round-based learning paradigm, where each
round involves training local models followed by attention maps sharing with
all federation clients. Experimental validation conducted in a real distributed
setting, on the ISIC2019 dataset, demonstrates the superior performance of
FedEvPrompt against baseline federated learning algorithms and knowledge
distillation methods, without sharing model parameters. In conclusion,
FedEvPrompt offers a promising approach for federated learning, effectively
addressing challenges such as data heterogeneity, imbalance, privacy
preservation, and knowledge sharing.

摘要：<paragraph>我們介紹 FedEvPrompt，這是一種聯邦學習方法，整合了
證據深度學習、提示調整和知識提煉的原理，用於分佈式皮膚病灶分類。FedEvPrompt 利用
兩組提示：b-提示（用於低階基本視覺知識）和
t-提示（用於特定任務的知識）加到凍結的預訓練 Vision
Transformer (ViT) 模型之前，這些模型在證據學習架構中進行訓練，以
最大化類別證據。至關重要的是，聯邦客戶之間的知識共享僅通過對本地 ViT 模型生成的注意力圖進行知識提煉來實現，與傳統參數或合成影像共享方法相比，確保了增強的隱私保護。
FedEvPrompt 在基於輪次的學習範例中進行優化，其中每個
輪次都涉及訓練本地模型，然後與所有聯邦客戶共享注意力圖。在真實的分布式
設置中進行的實驗驗證，在 ISIC2019 資料集上，展示了 FedEvPrompt 優於基準聯邦學習演算法和知識
提煉方法的優異效能，而無需共享模型參數。總之，
FedEvPrompt 為聯邦學習提供了一種有前途的方法，有效地解決了資料異質性、不平衡、隱私保護和知識共享等挑戰。</paragraph>

##### **Layer Importance and Hallucination Analysis in Large Language Models via Enhanced Activation Variance-Sparsity**
2411.10069v1 by Zichen Song, Sitan Huang, Yuxin Wu, Zhongfeng Kang

Evaluating the importance of different layers in large language models (LLMs)
is crucial for optimizing model performance and interpretability. This paper
first explores layer importance using the Activation Variance-Sparsity Score
(AVSS), which combines normalized activation variance and sparsity to quantify
each layer's contribution to overall model performance. By ranking layers based
on AVSS and pruning the least impactful 25\%, our experiments on tasks such as
question answering, language modeling, and sentiment classification show that
over 90\% of the original performance is retained, highlighting potential
redundancies in LLM architectures. Building on AVSS, we propose an enhanced
version tailored to assess hallucination propensity across layers (EAVSS). This
improved approach introduces Hallucination-Specific Activation Variance (HSAV)
and Hallucination-Specific Sparsity (HSS) metrics, allowing precise
identification of hallucination-prone layers. By incorporating contrastive
learning on these layers, we effectively mitigate hallucination generation,
contributing to more robust and efficient LLMs(The maximum performance
improvement is 12\%). Our results on the NQ, SciQ, TriviaQA, TruthfulQA, and
WikiQA datasets demonstrate the efficacy of this method, offering a
comprehensive framework for both layer importance evaluation and hallucination
mitigation in LLMs.

摘要：評估大型語言模型 (LLM) 中不同層級的重要性對於最佳化模型效能和可解釋性至關重要。本文首先使用啟動方差稀疏度評分 (AVSS) 來探討層級的重要性，它結合了標準化啟動方差和稀疏度，以量化每一層對整體模型效能的貢獻。透過根據 AVSS 對層級進行排序，並修剪影響最小的 25%，我們在問答、語言建模和情緒分類等任務上的實驗顯示，保留了超過 90% 的原始效能，突顯了 LLM 架構中潛在的冗餘。建立在 AVSS 的基礎上，我們提出一個增強版本，專門用於評估跨層級的幻覺傾向 (EAVSS)。這種改良的方法引入了幻覺特定啟動方差 (HSAV) 和幻覺特定稀疏度 (HSS) 指標，可以精準辨識容易產生幻覺的層級。透過在這些層級中納入對比學習，我們有效減輕了幻覺的產生，有助於建立更強大且更有效的 LLM（效能最大的提升幅度為 12%）。我們在 NQ、SciQ、TriviaQA、TruthfulQA 和 WikiQA 資料集上的結果證明了此方法的效用，為 LLM 中的層級重要性評估和幻覺減輕提供了一個全面的架構。

##### **Federated Domain Generalization via Prompt Learning and Aggregation**
2411.10063v1 by Shuai Gong, Chaoran Cui, Chunyun Zhang, Wenna Wang, Xiushan Nie, Lei Zhu

Federated domain generalization (FedDG) aims to improve the global model
generalization in unseen domains by addressing data heterogeneity under
privacy-preserving constraints. A common strategy in existing FedDG studies
involves sharing domain-specific knowledge among clients, such as spectrum
information, class prototypes, and data styles. However, this knowledge is
extracted directly from local client samples, and sharing such sensitive
information poses a potential risk of data leakage, which might not fully meet
the requirements of FedDG. In this paper, we introduce prompt learning to adapt
pre-trained vision-language models (VLMs) in the FedDG scenario, and leverage
locally learned prompts as a more secure bridge to facilitate knowledge
transfer among clients. Specifically, we propose a novel FedDG framework
through Prompt Learning and AggregatioN (PLAN), which comprises two training
stages to collaboratively generate local prompts and global prompts at each
federated round. First, each client performs both text and visual prompt
learning using their own data, with local prompts indirectly synchronized by
regarding the global prompts as a common reference. Second, all domain-specific
local prompts are exchanged among clients and selectively aggregated into the
global prompts using lightweight attention-based aggregators. The global
prompts are finally applied to adapt VLMs to unseen target domains. As our PLAN
framework requires training only a limited number of prompts and lightweight
aggregators, it offers notable advantages in computational and communication
efficiency for FedDG. Extensive experiments demonstrate the superior
generalization ability of PLAN across four benchmark datasets.

摘要：聯邦領域泛化 (FedDG) 旨在透過在保密約束下解決資料異質性，來改善在未見領域中的整體模型泛化。現有 FedDG 研究中常見的策略，涉及在客戶端之間分享領域特定知識，例如頻譜資訊、類原型和資料樣式。然而，這項知識直接從當地客戶端範例中擷取，而分享此類敏感資訊會造成資料外洩的潛在風險，可能無法完全滿足 FedDG 的需求。在本文中，我們引入提示學習，以在 FedDG 情境中調整預先訓練的視覺語言模型 (VLM)，並利用當地學習的提示作為更安全的橋樑，以促進客戶端之間的知識轉移。具體來說，我們透過提示學習和聚合 (PLAN) 提出一個新穎的 FedDG 架構，它包含兩個訓練階段，以在每個聯邦回合中共同產生本地提示和全域提示。首先，每個客戶端使用自己的資料執行文字和視覺提示學習，並透過將全域提示視為共通參考，間接同步本地提示。其次，所有領域特定的本地提示會在客戶端之間交換，並使用輕量級基於注意力的聚合器有選擇地聚合到全域提示中。全域提示最後應用於調整 VLM 以適應未見的目標領域。由於我們的 PLAN 架構僅需要訓練有限數量的提示和輕量級聚合器，因此在 FedDG 的運算和通訊效率方面提供了顯著的優勢。廣泛的實驗證明了 PLAN 在四個基準資料集中的卓越泛化能力。

##### **CMATH: Cross-Modality Augmented Transformer with Hierarchical Variational Distillation for Multimodal Emotion Recognition in Conversation**
2411.10060v1 by Xiaofei Zhu, Jiawei Cheng, Zhou Yang, Zhuo Chen, Qingyang Wang, Jianfeng Yao

Multimodal emotion recognition in conversation (MER) aims to accurately
identify emotions in conversational utterances by integrating multimodal
information. Previous methods usually treat multimodal information as equal
quality and employ symmetric architectures to conduct multimodal fusion.
However, in reality, the quality of different modalities usually varies
considerably, and utilizing a symmetric architecture is difficult to accurately
recognize conversational emotions when dealing with uneven modal information.
Furthermore, fusing multi-modality information in a single granularity may fail
to adequately integrate modal information, exacerbating the inaccuracy in
emotion recognition. In this paper, we propose a novel Cross-Modality Augmented
Transformer with Hierarchical Variational Distillation, called CMATH, which
consists of two major components, i.e., Multimodal Interaction Fusion and
Hierarchical Variational Distillation. The former is comprised of two
submodules, including Modality Reconstruction and Cross-Modality Augmented
Transformer (CMA-Transformer), where Modality Reconstruction focuses on
obtaining high-quality compressed representation of each modality, and
CMA-Transformer adopts an asymmetric fusion strategy which treats one modality
as the central modality and takes others as auxiliary modalities. The latter
first designs a variational fusion network to fuse the fine-grained
representations learned by CMA- Transformer into a coarse-grained
representations. Then, it introduces a hierarchical distillation framework to
maintain the consistency between modality representations with different
granularities. Experiments on the IEMOCAP and MELD datasets demonstrate that
our proposed model outperforms previous state-of-the-art baselines.
Implementation codes can be available at https://github.com/ cjw-MER/CMATH.

摘要：<paragraph>多模态对话情绪识别（MER）旨在通过整合多模态信息准确识别对话中的情绪。以往的方法通常将多模态信息视为同等质量，并采用对称架构进行多模态融合。然而，在现实中，不同模态的质量通常差异很大，并且在处理不均匀的模态信息时，利用对称架构难以准确识别对话情绪。此外，以单一粒度融合多模态信息可能无法充分整合模态信息，从而加剧情绪识别中的不准确性。在本文中，我们提出了一种具有分层变分蒸馏的跨模态增强 Transformer，称为 CMATH，它由两个主要组成部分组成，即多模态交互融合和分层变分蒸馏。前者由两个子模块组成，包括模态重建和跨模态增强 Transformer（CMA-Transformer），其中模态重建专注于获取每个模态的高质量压缩表示，而 CMA-Transformer 采用不对称融合策略，将一种模态视为中心模态，并将其他模态视为辅助模态。后者首先设计了一个变分融合网络，将 CMA-Transformer 学习到的细粒度表示融合成粗粒度表示。然后，它引入了一个分层蒸馏框架，以保持具有不同粒度的模态表示之间的一致性。在 IEMOCAP 和 MELD 数据集上的实验表明，我们提出的模型优于以往最先进的基准。实现代码可以在 https://github.com/ cjw-MER/CMATH 获得。</paragraph>

##### **KuaiFormer: Transformer-Based Retrieval at Kuaishou**
2411.10057v1 by Chi Liu, Jiangxia Cao, Rui Huang, Kai Zheng, Qiang Luo, Kun Gai, Guorui Zhou

In large-scale content recommendation systems, retrieval serves as the
initial stage in the pipeline, responsible for selecting thousands of candidate
items from billions of options to pass on to ranking modules. Traditionally,
the dominant retrieval method has been Embedding-Based Retrieval (EBR) using a
Deep Neural Network (DNN) dual-tower structure. However, applying transformer
in retrieval tasks has been the focus of recent research, though real-world
industrial deployment still presents significant challenges. In this paper, we
introduce KuaiFormer, a novel transformer-based retrieval framework deployed in
a large-scale content recommendation system. KuaiFormer fundamentally redefines
the retrieval process by shifting from conventional score estimation tasks
(such as click-through rate estimate) to a transformer-driven Next Action
Prediction paradigm. This shift enables more effective real-time interest
acquisition and multi-interest extraction, significantly enhancing retrieval
performance. KuaiFormer has been successfully integrated into Kuaishou App's
short-video recommendation system since May 2024, serving over 400 million
daily active users and resulting in a marked increase in average daily usage
time of Kuaishou users. We provide insights into both the technical and
business aspects of deploying transformer in large-scale recommendation
systems, addressing practical challenges encountered during industrial
implementation. Our findings offer valuable guidance for engineers and
researchers aiming to leverage transformer models to optimize large-scale
content recommendation systems.

摘要：在大型內容推薦系統中，檢索作為管道中的初始階段，負責從數十億個選項中選擇數千個候選項目傳遞給排名模組。傳統上，主要的檢索方法一直是使用深度神經網路（DNN）雙塔結構的基於嵌入的檢索（EBR）。然而，將Transformer應用於檢索任務一直是近期研究的重點，儘管現實世界的產業部署仍面臨重大挑戰。在本文中，我們介紹了 KuaiFormer，這是一個部署在大型內容推薦系統中的基於Transformer的檢索框架。KuaiFormer 從根本上重新定義了檢索流程，從傳統的分數估計任務（例如點擊率估計）轉移到由Transformer驅動的下一個動作預測範例。這種轉變使得更有效的實時興趣獲取和多興趣提取成為可能，顯著增強了檢索效能。自 2024 年 5 月以來，KuaiFormer 已成功整合到快手 App 的短影片推薦系統中，服務於超過 4 億的每日活躍用戶，並導致快手用戶的平均每日使用時間顯著增加。我們提供了在大型推薦系統中部署Transformer的技術和業務方面的見解，解決了產業實施過程中遇到的實際挑戰。我們的發現為工程師和研究人員提供了有價值的指導，他們旨在利用Transformer模型來優化大型內容推薦系統。

##### **Towards unearthing neglected climate innovations from scientific literature using Large Language Models**
2411.10055v1 by César Quilodrán-Casas, Christopher Waite, Nicole Alhadeff, Diyona Dsouza, Cathal Hughes, Larissa Kunstel-Tabet, Alyssa Gilbert

Climate change poses an urgent global threat, needing the rapid
identification and deployment of innovative solutions. We hypothesise that many
of these solutions already exist within scientific literature but remain
underutilised. To address this gap, this study employs a curated dataset
sourced from OpenAlex, a comprehensive repository of scientific papers.
Utilising Large Language Models (LLMs), such as GPT4-o from OpenAI, we evaluate
title-abstract pairs from scientific papers on seven dimensions, covering
climate change mitigation potential, stage of technological development, and
readiness for deployment. The outputs of the language models are then compared
with human evaluations to assess their effectiveness in identifying promising
yet overlooked climate innovations. Our findings suggest that these LLM-based
models can effectively augment human expertise, uncovering climate solutions
that are potentially impactful but with far greater speed, throughput and
consistency. Here, we focused on UK-based solutions, but the workflow is
region-agnostic. This work contributes to the discovery of neglected
innovations in scientific literature and demonstrates the potential of AI in
enhancing climate action strategies.

摘要：氣候變遷構成一項迫切的全球威脅，需要快速找出並部署創新解決方案。我們假設，這些解決方案中的許多方案已存在於科學文獻中，但仍未得到充分利用。為了解決這個差距，本研究採用從 OpenAlex（一個全面的科學論文儲存庫）取得的精選資料集。利用大型語言模型 (LLM)，例如 OpenAI 的 GPT4-o，我們從七個面向評估科學論文的標題摘要配對，包括氣候變遷減緩潛力、技術發展階段和部署準備情況。然後將語言模型的輸出與人類評估進行比較，以評估其在找出有希望但被忽視的氣候創新方面的有效性。我們的研究結果表明，這些基於 LLM 的模型可以有效地擴充人類專長，找出可能產生影響但速度、產量和一致性遠高於人類的氣候解決方案。在此，我們專注於英國的解決方案，但工作流程與地區無關。這項工作有助於找出科學文獻中被忽視的創新，並展示了 AI 在加強氣候行動策略方面的潛力。

##### **Jal Anveshak: Prediction of fishing zones using fine-tuned LlaMa 2**
2411.10050v1 by Arnav Mejari, Maitreya Vaghulade, Paarshva Chitaliya, Arya Telang, Lynette D'mello

In recent years, the global and Indian government efforts in monitoring and
collecting data related to the fisheries industry have witnessed significant
advancements. Despite this wealth of data, there exists an untapped potential
for leveraging artificial intelligence based technological systems to benefit
Indian fishermen in coastal areas. To fill this void in the Indian technology
ecosystem, the authors introduce Jal Anveshak. This is an application framework
written in Dart and Flutter that uses a Llama 2 based Large Language Model
fine-tuned on pre-processed and augmented government data related to fishing
yield and availability. Its main purpose is to help Indian fishermen safely get
the maximum yield of fish from coastal areas and to resolve their fishing
related queries in multilingual and multimodal ways.

摘要：近年來，全球和印度政府在監控和收集與漁業產業相關數據的努力已見證顯著進展。儘管有這麼豐富的數據，但仍有未開發的潛力，可以利用基於人工智慧的技術系統，讓印度沿海地區的漁民受益。為了填補印度科技生態系統中的這個空白，作者引入了 Jal Anveshak。這是一個使用 Dart 和 Flutter 編寫的應用程式框架，它使用基於 Llama 2 的大型語言模型，針對與捕魚產量和可用性相關的預處理和擴充政府數據進行微調。其主要目的是幫助印度漁民安全地從沿海地區獲得最大魚獲量，並以多語言和多模式的方式解決他們與捕魚相關的疑問。

##### **VMID: A Multimodal Fusion LLM Framework for Detecting and Identifying Misinformation of Short Videos**
2411.10032v1 by Weihao Zhong, Yinhao Xiao, Minghui Xu, Xiuzhen Cheng

Short video platforms have become important channels for news dissemination,
offering a highly engaging and immediate way for users to access current events
and share information. However, these platforms have also emerged as
significant conduits for the rapid spread of misinformation, as fake news and
rumors can leverage the visual appeal and wide reach of short videos to
circulate extensively among audiences. Existing fake news detection methods
mainly rely on single-modal information, such as text or images, or apply only
basic fusion techniques, limiting their ability to handle the complex,
multi-layered information inherent in short videos. To address these
limitations, this paper presents a novel fake news detection method based on
multimodal information, designed to identify misinformation through a
multi-level analysis of video content. This approach effectively utilizes
different modal representations to generate a unified textual description,
which is then fed into a large language model for comprehensive evaluation. The
proposed framework successfully integrates multimodal features within videos,
significantly enhancing the accuracy and reliability of fake news detection.
Experimental results demonstrate that the proposed approach outperforms
existing models in terms of accuracy, robustness, and utilization of multimodal
information, achieving an accuracy of 90.93%, which is significantly higher
than the best baseline model (SV-FEND) at 81.05%. Furthermore, case studies
provide additional evidence of the effectiveness of the approach in accurately
distinguishing between fake news, debunking content, and real incidents,
highlighting its reliability and robustness in real-world applications.

摘要：短影音平台已成為傳播新聞的重要管道，為使用者提供極具吸引力且即時的方式來存取時事並分享資訊。然而，這些平台也成為錯誤資訊迅速散布的重要管道，因為假新聞和謠言可以利用短影音的視覺吸引力和廣泛觸及率在受眾之間廣泛流傳。現有的假新聞偵測方法主要依賴單一模式資訊，例如文字或影像，或僅應用基本的融合技術，限制了其處理短影音中複雜、多層次資訊的能力。為了解決這些限制，本文提出了一種基於多模式資訊的新穎假新聞偵測方法，旨在透過對影音內容進行多層次分析來識別錯誤資訊。此方法有效利用不同的模式表示來產生統一的文字描述，然後將其輸入大型語言模型進行全面評估。所提出的架構成功整合了影片中的多模式特徵，大幅提升假新聞偵測的準確性和可靠性。實驗結果證明，所提出的方法在準確性、穩健性和多模式資訊利用方面優於現有模型，達到 90.93% 的準確度，顯著高於最佳基線模型 (SV-FEND) 的 81.05%。此外，案例研究提供了額外的證據，證明該方法在準確區分假新聞、揭穿內容和真實事件方面具有成效，突顯其在真實世界應用中的可靠性和穩健性。

##### **MOT\_FCG++: Enhanced Representation of Motion and Appearance Features**
2411.10028v1 by Yanzhao Fang

The goal of multi-object tracking (MOT) is to detect and track all objects in
a scene across frames, while maintaining a unique identity for each object.
Most existing methods rely on the spatial motion features and appearance
embedding features of the detected objects in consecutive frames. Effectively
and robustly representing the spatial and appearance features of long
trajectories has become a critical factor affecting the performance of MOT. We
propose a novel approach for appearance and spatial feature representation,
improving upon the clustering association method MOT\_FCG. For spatial motion
features, we propose Diagonal Modulated GIoU, which more accurately represents
the relationship between the position and shape of the objects. For appearance
features, we utilize a dynamic appearance representation that incorporates
confidence information, enabling the trajectory appearance features to be more
robust and global. Based on the baseline model MOT\_FCG, we achieved 76.1 HOTA,
80.4 MOTA and 81.3 IDF1 on the MOT17 validation set, and also achieved
competitive performance on the MOT20 and DanceTrack validation sets.

摘要：多目標追蹤 (MOT) 的目標是偵測和追蹤場景中所有物體在各個畫格中的位置，同時為每個物體維持一個獨特的識別碼。
大多數現有的方法依賴於連續畫格中偵測到物體的空間運動特徵和外觀嵌入特徵。有效且穩健地表示長軌跡的空間和外觀特徵已成為影響 MOT 效能的關鍵因素。我們提出了一種外觀和空間特徵表示的新方法，改進了群集關聯方法 MOT\_FCG。對於空間運動特徵，我們提出了對角調製 GIoU，它更準確地表示物體位置和形狀之間的關係。對於外觀特徵，我們利用了結合信心資訊的動態外觀表示，使軌跡外觀特徵更加穩健且全面。根據基準模型 MOT\_FCG，我們在 MOT17 驗證集上達到了 76.1 HOTA、80.4 MOTA 和 81.3 IDF1，並且在 MOT20 和 DanceTrack 驗證集上也取得了具有競爭力的效能。

##### **Information Extraction from Clinical Notes: Are We Ready to Switch to Large Language Models?**
2411.10020v1 by Yan Hu, Xu Zuo, Yujia Zhou, Xueqing Peng, Jimin Huang, Vipina K. Keloth, Vincent J. Zhang, Ruey-Ling Weng, Qingyu Chen, Xiaoqian Jiang, Kirk E. Roberts, Hua Xu

Backgrounds: Information extraction (IE) is critical in clinical natural
language processing (NLP). While large language models (LLMs) excel on
generative tasks, their performance on extractive tasks remains debated.
Methods: We investigated Named Entity Recognition (NER) and Relation Extraction
(RE) using 1,588 clinical notes from four sources (UT Physicians, MTSamples,
MIMIC-III, and i2b2). We developed an annotated corpus covering 4 clinical
entities and 16 modifiers, and compared instruction-tuned LLaMA-2 and LLaMA-3
against BiomedBERT in terms of performance, generalizability, computational
resources, and throughput to BiomedBERT. Results: LLaMA models outperformed
BiomedBERT across datasets. With sufficient training data, LLaMA showed modest
improvements (1% on NER, 1.5-3.7% on RE); improvements were larger with limited
training data. On unseen i2b2 data, LLaMA-3-70B outperformed BiomedBERT by 7%
(F1) on NER and 4% on RE. However, LLaMA models required more computing
resources and ran up to 28 times slower. We implemented "Kiwi," a clinical IE
package featuring both models, available at https://kiwi.clinicalnlp.org/.
Conclusion: This study is among the first to develop and evaluate a
comprehensive clinical IE system using open-source LLMs. Results indicate that
LLaMA models outperform BiomedBERT for clinical NER and RE but with higher
computational costs and lower throughputs. These findings highlight that
choosing between LLMs and traditional deep learning methods for clinical IE
applications should remain task-specific, taking into account both performance
metrics and practical considerations such as available computing resources and
the intended use case scenarios.

摘要：背景：資訊萃取 (IE) 在臨床自然語言處理 (NLP) 中至關重要。儘管大型語言模型 (LLM) 在生成式任務中表現出色，但它們在萃取式任務中的表現仍有爭議。方法：我們使用來自四個來源（UT Physicians、MTSamples、MIMIC-III 和 i2b2）的 1,588 個臨床筆記，研究了命名實體辨識 (NER) 和關係萃取 (RE)。我們開發了一個註解語料庫，涵蓋 4 個臨床實體和 16 個修飾詞，並在效能、泛化性、運算資源和處理量方面，將經過指令微調的 LLaMA-2 和 LLaMA-3 與 BiomedBERT 進行比較。結果：LLaMA 模型在所有資料集的表現都優於 BiomedBERT。在有足夠的訓練資料下，LLaMA 表現出適度的進步（NER 提升 1%，RE 提升 1.5-3.7%）；在訓練資料有限的情況下，進步幅度更大。在未見過的 i2b2 資料上，LLaMA-3-70B 在 NER 上的表現優於 BiomedBERT 7%（F1），在 RE 上優於 4%。然而，LLaMA 模型需要更多的運算資源，執行速度慢了 28 倍。我們實作了「Kiwi」，一個同時具備這兩個模型的臨床 IE 套件，可在 https://kiwi.clinicalnlp.org/ 取得。結論：本研究是第一個使用開源 LLM 開發和評估全面臨床 IE 系統的研究。結果顯示，LLaMA 模型在臨床 NER 和 RE 方面優於 BiomedBERT，但運算成本較高，處理量較低。這些發現強調，在臨床 IE 應用中，選擇 LLM 和傳統深度學習方法應取決於特定任務，同時考量效能指標和實際考量因素，例如可用的運算資源和預期的使用案例情境。

##### **Once More, With Feeling: Measuring Emotion of Acting Performances in Contemporary American Film**
2411.10018v1 by Naitian Zhou, David Bamman

Narrative film is a composition of writing, cinematography, editing, and
performance. While much computational work has focused on the writing or visual
style in film, we conduct in this paper a computational exploration of acting
performance. Applying speech emotion recognition models and a variationist
sociolinguistic analytical framework to a corpus of popular, contemporary
American film, we find narrative structure, diachronic shifts, and genre- and
dialogue-based constraints located in spoken performances.

摘要：敘事電影是寫作、攝影、剪輯和表演的組合。雖然許多計算工作都專注於電影中的寫作或視覺風格，但我們在這篇論文中進行了表演的計算探索。應用語音情緒識別模型和變異社會語言學分析框架到流行的當代美國電影語料庫中，我們發現敘事結構、歷時性轉變以及體裁和對話基礎的限制存在於口語表演中。

##### **MicroCrackAttentionNeXt: Advancing Microcrack Detection in Wave Field Analysis Using Deep Neural Networks through Feature Visualization**
2411.10015v1 by Fatahlla Moreh, Yusuf Hasan, Bilal Zahid Hussain, Mohammad Ammar, Sven Tomforde

Micro Crack detection using deep neural networks (DNNs) through an automated
pipeline using wave fields interacting with the damaged areas is highly sought
after. These high-dimensional spatio-temporal crack data are limited, and these
datasets have large dimensions in the temporal domain. The dataset presents a
substantial class imbalance, with crack pixels constituting an average of only
5% of the total pixels per sample. This extreme class imbalance poses a
challenge for deep learning models with the different micro-scale cracks, as
the network can be biased toward predicting the majority class, generally
leading to poor detection accuracy. This study builds upon the previous
benchmark SpAsE-Net, an asymmetric encoder-decoder network for micro-crack
detection. The impact of various activation and loss functions were examined
through feature space visualization using the manifold discovery and analysis
(MDA) algorithm. The optimized architecture and training methodology achieved
an accuracy of 86.85%.

摘要：利用波場與受損區域交互作用的自動化管道，使用深度神經網路 (DNN) 進行微裂紋檢測備受重視。這些高維時空裂紋資料有限，且這些資料集在時域中具有大維度。該資料集呈現出顯著的類別不平衡，其中裂紋像素平均僅構成每個樣本總像素的 5%。這種極端的類別不平衡對具有不同微尺度裂紋的深度學習模型構成挑戰，因為網路可能偏向於預測多數類別，通常導致檢測準確度不佳。本研究建立在先前的基準 SpAsE-Net，一種用於微裂紋檢測的不對稱編碼器-解碼器網路。透過使用流形發現和分析 (MDA) 演算法進行特徵空間視覺化，檢驗了各種激活和損失函數的影響。最佳化的架構和訓練方法達到 86.85% 的準確度。

##### **DeepMedcast: A Deep Learning Method for Generating Intermediate Weather Forecasts among Multiple NWP Models**
2411.10010v1 by Atsushi Kudo

Numerical weather prediction (NWP) centers around the world operate a variety
of NWP models, and recent advances in AI-driven NWP models have increased the
availability of diverse NWP outputs. While this expansion holds the potential
to improve forecast accuracy, it also raises a critical challenge of
identifying the most reliable predictions for specific forecast scenarios.
Traditional approaches, such as ensemble or weighted averaging, combine
multiple NWP outputs but often generate unrealistic atmospheric fields,
complicating the production of reliable and consistent forecasts in operational
settings. In this study, we introduce DeepMedcast, a deep learning method that
generates intermediate forecast, or "medcast", between two or more NWP outputs.
Unlike ensemble averaging, DeepMedcast can provide consistent and explainable
medcast without distorting meteorological fields. This paper details the
methodology and case studies of DeepMedcast, discussing its advantages and
potential contributions to operational forecasting.

摘要：全球數值天氣預測 (NWP) 中心營運各種 NWP 模型，而 AI 驅動 NWP 模型的最新進展已提升各種 NWP 產出的可取得性。雖然此擴充具備提升預測精準度的潛力，但也引發一項重大挑戰，即找出特定預測情境中最可靠的預測。傳統方法（例如集合或加權平均）會結合多個 NWP 產出，但通常會產生不切實際的大氣場，使得在營運設定中產生可靠且一致的預測變得複雜。在此研究中，我們介紹 DeepMedcast，這是一種深度學習方法，可以在兩個或多個 NWP 產出之間產生中間預測或「medcast」。與集合平均不同的是，DeepMedcast 可以提供一致且可解釋的 medcast，而不會扭曲氣象場。本文詳述 DeepMedcast 的方法論和案例研究，討論其優點和對營運預測的潛在貢獻。

##### **Graph-based Complexity for Causal Effect by Empirical Plug-in**
2411.10008v1 by Rina Dechter, Annie Raichev, Alexander Ihler, Jin Tian

This paper focuses on the computational complexity of computing empirical
plug-in estimates for causal effect queries. Given a causal graph and
observational data, any identifiable causal query can be estimated from an
expression over the observed variables, called the estimand. The estimand can
then be evaluated by plugging in probabilities computed empirically from data.
In contrast to conventional wisdom, which assumes that high dimensional
probabilistic functions will lead to exponential evaluation time of the
estimand. We show that computation can be done efficiently, potentially in time
linear in the data size, depending on the estimand's hypergraph.
  In particular, we show that both the treewidth and hypertree width of the
estimand's structure bound the evaluation complexity of the plug-in estimands,
analogous to their role in the complexity of probabilistic inference in
graphical models. Often, the hypertree width provides a more effective bound,
since the empirical distributions are sparse.

摘要：本文重點探討計算因果效應查詢的經驗插補估計值之計算複雜度。假設給定一個因果圖和觀察資料，任何可識別的因果查詢都可以從一個觀察變數的表達式中估計，稱為估計量。接著，估計量可以透過將從資料中經驗計算出的機率代入來評估。與假設高維機率函數將導致估計量的指數評估時間的傳統觀念相反，我們顯示計算可以有效率地完成，潛在資料大小線性時間，視估計量的超圖而定。
特別地，我們顯示估計量結構的樹寬和超樹寬都界定了插補估計量的評估複雜度，類似於機率圖形模型中機率推論複雜度中的角色。由於經驗分佈是稀疏的，因此超樹寬通常提供更有效的界限。

##### **Orca: Enhancing Role-Playing Abilities of Large Language Models by Integrating Personality Traits**
2411.10006v1 by Yuxuan Huang

Large language models has catalyzed the development of personalized dialogue
systems, numerous role-playing conversational agents have emerged. While
previous research predominantly focused on enhancing the model's capability to
follow instructions by designing character profiles, neglecting the
psychological factors that drive human conversations. In this paper, we propose
Orca, a framework for data processing and training LLMs of custom characters by
integrating personality traits. Orca comprises four stages: (1) Personality
traits inferring, leverage LLMs to infer user's BigFive personality trait
reports and scores. (2) Data Augment, simulate user's profile, background
story, and psychological activities. (3) Dataset construction,
personality-conditioned instruction prompting (PCIP) to stimulate LLMs. (4)
Modeling and Training, personality-conditioned instruction tuning (PTIT and
PSIT), using the generated data to enhance existing open-source LLMs. We
introduce OrcaBench, the first benchmark for evaluating the quality of content
generated by LLMs on social platforms across multiple scales. Our experiments
demonstrate that our proposed model achieves superior performance on this
benchmark, demonstrating its excellence and effectiveness in perceiving
personality traits that significantly improve role-playing abilities. Our Code
is available at https://github.com/Aipura/Orca.

摘要：大型语言模型催化了个人化对话系统的开发，涌现出众多角色扮演对话代理。虽然之前的研究主要集中于通过设计角色档案来增强模型遵循指令的能力，但忽略了推动人类对话的心理因素。在本文中，我们提出了 Orca，一个通过整合人格特质来进行数据处理和训练自定义角色的 LLM 框架。Orca 包含四个阶段：(1) 人格特质推断，利用 LLM 推断用户的五大人格特质报告和分数。(2) 数据增强，模拟用户的个人资料、背景故事和心理活动。(3) 数据集构建，人格条件指令提示 (PCIP) 来刺激 LLM。(4) 建模和训练，人格条件指令调整 (PTIT 和 PSIT)，使用生成的数据来增强现有的开源 LLM。我们引入了 OrcaBench，这是第一个用于评估 LLM 在社交平台上跨多个尺度生成的内容质量的基准。我们的实验表明，我们提出的模型在这个基准上取得了优异的性能，展示了它在感知人格特质方面的卓越性和有效性，显着提高了角色扮演能力。我们的代码可在 https://github.com/Aipura/Orca 获得。

##### **EyeDiff: text-to-image diffusion model improves rare eye disease diagnosis**
2411.10004v1 by Ruoyu Chen, Weiyi Zhang, Bowen Liu, Xiaolan Chen, Pusheng Xu, Shunming Liu, Mingguang He, Danli Shi

The rising prevalence of vision-threatening retinal diseases poses a
significant burden on the global healthcare systems. Deep learning (DL) offers
a promising solution for automatic disease screening but demands substantial
data. Collecting and labeling large volumes of ophthalmic images across various
modalities encounters several real-world challenges, especially for rare
diseases. Here, we introduce EyeDiff, a text-to-image model designed to
generate multimodal ophthalmic images from natural language prompts and
evaluate its applicability in diagnosing common and rare diseases. EyeDiff is
trained on eight large-scale datasets using the advanced latent diffusion
model, covering 14 ophthalmic image modalities and over 80 ocular diseases, and
is adapted to ten multi-country external datasets. The generated images
accurately capture essential lesional characteristics, achieving high alignment
with text prompts as evaluated by objective metrics and human experts.
Furthermore, integrating generated images significantly enhances the accuracy
of detecting minority classes and rare eye diseases, surpassing traditional
oversampling methods in addressing data imbalance. EyeDiff effectively tackles
the issue of data imbalance and insufficiency typically encountered in rare
diseases and addresses the challenges of collecting large-scale annotated
images, offering a transformative solution to enhance the development of
expert-level diseases diagnosis models in ophthalmic field.

摘要：隨著威脅視力的視網膜疾病盛行率上升，對全球醫療保健系統造成重大負擔。深度學習 (DL) 為自動疾病篩檢提供了一個有希望的解決方案，但需要大量資料。收集和標記各種模式的大量眼科影像會遇到若干實際挑戰，尤其是罕見疾病。在此，我們介紹 EyeDiff，這是一個文字轉影像模型，旨在從自然語言提示中生成多模式眼科影像，並評估其在診斷常見和罕見疾病中的適用性。EyeDiff 使用先進的潛在擴散模型在八個大型資料集上進行訓練，涵蓋 14 種眼科影像模式和超過 80 種眼部疾病，並適應十個多國外部資料集。生成的影像精準捕捉必要的病灶特徵，與由客觀指標和人類專家評估的文字提示高度一致。此外，整合生成的影像顯著增強了偵測少數類別和罕見眼疾的準確性，在解決資料不平衡方面超越了傳統的過度抽樣方法。EyeDiff 有效解決了罕見疾病中通常遇到的資料不平衡和不足問題，並解決了收集大量標註影像的挑戰，提供了一個變革性的解決方案，以增強眼科領域專家級疾病診斷模型的開發。

##### **DuSEGO: Dual Second-order Equivariant Graph Ordinary Differential Equation**
2411.10000v1 by Yingxu Wang, Nan Yin, Mingyan Xiao, Xinhao Yi, Siwei Liu, Shangsong Liang

Graph Neural Networks (GNNs) with equivariant properties have achieved
significant success in modeling complex dynamic systems and molecular
properties. However, their expressiveness ability is limited by: (1) Existing
methods often overlook the over-smoothing issue caused by traditional GNN
models, as well as the gradient explosion or vanishing problems in deep GNNs.
(2) Most models operate on first-order information, neglecting that the real
world often consists of second-order systems, which further limits the model's
representation capabilities. To address these issues, we propose the
\textbf{Du}al \textbf{S}econd-order \textbf{E}quivariant \textbf{G}raph
\textbf{O}rdinary Differential Equation (\method{}) for equivariant
representation. Specifically, \method{} apply the dual second-order equivariant
graph ordinary differential equations (Graph ODEs) on graph embeddings and node
coordinates, simultaneously. Theoretically, we first prove that \method{}
maintains the equivariant property. Furthermore, we provide theoretical
insights showing that \method{} effectively alleviates the over-smoothing
problem in both feature representation and coordinate update. Additionally, we
demonstrate that the proposed \method{} mitigates the exploding and vanishing
gradients problem, facilitating the training of deep multi-layer GNNs.
Extensive experiments on benchmark datasets validate the superiority of the
proposed \method{} compared to baselines.

摘要：<paragraph>具有等變性質的圖神經網路 (GNN) 已在建模複雜動態系統和分子性質方面取得顯著成功。然而，它們的表現能力受到以下因素限制：(1) 現有方法經常忽略傳統 GNN 模型造成的過度平滑問題，以及深度 GNN 中的梯度爆炸或消失問題。(2) 大多數模型運作於一階資訊，忽略了現實世界通常由二階系統組成，這進一步限制了模型的表示能力。為了解決這些問題，我們提出了等變表示的**雙**二階**S**econd-order **E**quivariant **G**raph **O**rdinary Differential Equation (\method{})。具體來說，\method{} 同時在圖嵌入和節點坐標上應用二階等變圖常微分方程式 (Graph ODE)。理論上，我們首先證明 \method{} 保持等變性質。此外，我們提供了理論見解，表明 \method{} 有效地緩解了特徵表示和座標更新中的過度平滑問題。此外，我們證明了所提出的 \method{} 減輕了爆炸和消失梯度問題，促进了多層深度 GNN 的訓練。在基準資料集上的大量實驗驗證了所提出的 \method{} 與基準相比的優越性。</paragraph>

##### **Building 6G Radio Foundation Models with Transformer Architectures**
2411.09996v1 by Ahmed Aboulfotouh, Ashkan Eshaghbeigi, Hatem Abou-Zeid

Foundation deep learning (DL) models are general models, designed to learn
general, robust and adaptable representations of their target modality,
enabling finetuning across a range of downstream tasks. These models are
pretrained on large, unlabeled datasets using self-supervised learning (SSL).
Foundation models have demonstrated better generalization than traditional
supervised approaches, a critical requirement for wireless communications where
the dynamic environment demands model adaptability. In this work, we propose
and demonstrate the effectiveness of a Vision Transformer (ViT) as a radio
foundation model for spectrogram learning. We introduce a Masked Spectrogram
Modeling (MSM) approach to pretrain the ViT in a self-supervised fashion. We
evaluate the ViT-based foundation model on two downstream tasks: Channel State
Information (CSI)-based Human Activity sensing and Spectrogram Segmentation.
Experimental results demonstrate competitive performance to supervised training
while generalizing across diverse domains. Notably, the pretrained ViT model
outperforms a four-times larger model that is trained from scratch on the
spectrogram segmentation task, while requiring significantly less training
time, and achieves competitive performance on the CSI-based human activity
sensing task. This work demonstrates the effectiveness of ViT with MSM for
pretraining as a promising technique for scalable foundation model development
in future 6G networks.

摘要：基礎深度學習 (DL) 模型是通用模型，旨在學習其目標模態的一般、穩健且適應性強的表徵，從而針對一系列下游任務進行微調。這些模型使用自監督學習 (SSL) 在大型、未標籤的資料集上進行預訓練。基礎模型已展示出比傳統監督方法更好的泛化能力，這是無線通訊中的一項關鍵要求，其中動態環境需要模型適應性。在這項工作中，我們提出了視覺轉換器 (ViT) 作為光譜圖學習的無線基礎模型，並證明了其有效性。我們引入了一個遮罩光譜圖建模 (MSM) 方法，以自監督的方式預訓練 ViT。我們在兩個下游任務上評估了基於 ViT 的基礎模型：基於頻道狀態資訊 (CSI) 的人類活動感測和光譜圖分割。實驗結果證明了與監督訓練相比具有競爭力的效能，同時在不同領域中進行泛化。值得注意的是，預訓練的 ViT 模型優於在光譜圖分割任務上從頭開始訓練的四倍大小的模型，同時需要顯著減少的訓練時間，並在基於 CSI 的人類活動感測任務上實現了競爭力的效能。這項工作證明了具有 MSM 的 ViT 在預訓練方面的有效性，這是一種有前途的技術，可用於未來 6G 網路中的可擴展基礎模型開發。

##### **Unlocking Transfer Learning for Open-World Few-Shot Recognition**
2411.09986v1 by Byeonggeun Kim, Juntae Lee, Kyuhong Shim, Simyung Chang

Few-Shot Open-Set Recognition (FSOSR) targets a critical real-world
challenge, aiming to categorize inputs into known categories, termed closed-set
classes, while identifying open-set inputs that fall outside these classes.
Although transfer learning where a model is tuned to a given few-shot task has
become a prominent paradigm in closed-world, we observe that it fails to expand
to open-world. To unlock this challenge, we propose a two-stage method which
consists of open-set aware meta-learning with open-set free transfer learning.
In the open-set aware meta-learning stage, a model is trained to establish a
metric space that serves as a beneficial starting point for the subsequent
stage. During the open-set free transfer learning stage, the model is further
adapted to a specific target task through transfer learning. Additionally, we
introduce a strategy to simulate open-set examples by modifying the training
dataset or generating pseudo open-set examples. The proposed method achieves
state-of-the-art performance on two widely recognized benchmarks, miniImageNet
and tieredImageNet, with only a 1.5\% increase in training effort. Our work
demonstrates the effectiveness of transfer learning in FSOSR.

摘要：少样本开放集识别 (FSOSR) 针对关键的真实世界挑战，旨在将输入分类到已知类别（称为闭集类），同时识别属于这些类之外的开放集输入。尽管迁移学习（其中模型针对给定的少样本任务进行调整）已成为封闭世界中的一个突出范例，但我们观察到它无法扩展到开放世界。为了应对这一挑战，我们提出了一种两阶段方法，该方法包括具有开放集自由迁移学习的开放集感知元学习。在开放集感知元学习阶段，训练模型以建立度量空间，作为后续阶段的有益起点。在开放集自由迁移学习阶段，模型通过迁移学习进一步适应特定目标任务。此外，我们引入了一种策略，通过修改训练数据集或生成伪开放集示例来模拟开放集示例。所提出的方法在两个广泛认可的基准（miniImageNet 和 tieredImageNet）上实现了最先进的性能，训练工作量仅增加了 1.5%。我们的工作证明了迁移学习在 FSOSR 中的有效性。

##### **HistoLens: An LLM-Powered Framework for Multi-Layered Analysis of Historical Texts -- A Case Application of Yantie Lun**
2411.09978v1 by Yifan Zeng

This paper proposes HistoLens, a multi-layered analysis framework for
historical texts based on Large Language Models (LLMs). Using the important
Western Han dynasty text "Yantie Lun" as a case study, we demonstrate the
framework's potential applications in historical research and education.
HistoLens integrates NLP technology (especially LLMs), including named entity
recognition, knowledge graph construction, and geographic information
visualization. The paper showcases how HistoLens explores Western Han culture
in "Yantie Lun" through multi-dimensional, visual, and quantitative methods,
focusing particularly on the influence of Confucian and Legalist thoughts on
political, economic, military, and ethnic. We also demonstrate how HistoLens
constructs a machine teaching scenario using LLMs for explainable analysis,
based on a dataset of Confucian and Legalist ideas extracted with LLM
assistance. This approach offers novel and diverse perspectives for studying
historical texts like "Yantie Lun" and provides new auxiliary tools for history
education. The framework aims to equip historians and learners with
LLM-assisted tools to facilitate in-depth, multi-layered analysis of historical
texts and foster innovation in historical education.

摘要：本文提出 HistoLens，一個基於大型語言模型 (LLM) 的多層分析架構，用於歷史文本。使用重要的西漢王朝文本「鹽鐵論」作為個案研究，我們展示了該架構在歷史研究和教育中的潛在應用。HistoLens 整合了 NLP 技術（尤其是 LLM），包括命名實體識別、知識圖譜建構和地理資訊視覺化。本文展示了 HistoLens 如何透過多維度、視覺化和量化方法探索「鹽鐵論」中的西漢文化，特別關注儒家和法家思想對政治、經濟、軍事和種族的影響。我們還展示了 HistoLens 如何建構一個使用 LLM 的機器教學場景，以進行可解釋分析，這是基於 LLM 協助提取的儒家和法家思想資料集。這種方法為研究「鹽鐵論」等歷史文本提供了新穎且多樣化的觀點，並為歷史教育提供了新的輔助工具。該架構旨在為歷史學家和學習者提供 LLM 協助的工具，以利於深入、多層次地分析歷史文本，並促進歷史教育的創新。

##### **Large Language Models as User-Agents for Evaluating Task-Oriented-Dialogue Systems**
2411.09972v1 by Taaha Kazi, Ruiliang Lyu, Sizhe Zhou, Dilek Hakkani-Tur, Gokhan Tur

Traditionally, offline datasets have been used to evaluate task-oriented
dialogue (TOD) models. These datasets lack context awareness, making them
suboptimal benchmarks for conversational systems. In contrast, user-agents,
which are context-aware, can simulate the variability and unpredictability of
human conversations, making them better alternatives as evaluators. Prior
research has utilized large language models (LLMs) to develop user-agents. Our
work builds upon this by using LLMs to create user-agents for the evaluation of
TOD systems. This involves prompting an LLM, using in-context examples as
guidance, and tracking the user-goal state. Our evaluation of diversity and
task completion metrics for the user-agents shows improved performance with the
use of better prompts. Additionally, we propose methodologies for the automatic
evaluation of TOD models within this dynamic framework.

摘要：傳統上，離線資料集已被用於評估任務導向對話 (TOD) 模型。這些資料集缺乏情境意識，使其成為對話系統次佳的基準。相比之下，具備情境意識的使用者代理可以模擬人類對話的多變性和不可預測性，使其成為更好的評估者替代方案。先前的研究已利用大型語言模型 (LLM) 來開發使用者代理。我們的研究建立在這個基礎上，使用 LLM 為 TOD 系統的評估建立使用者代理。這涉及提示 LLM，使用情境中的範例作為指導，並追蹤使用者目標狀態。我們對使用者代理的多樣性和任務完成指標的評估顯示，使用更好的提示可以改善效能。此外，我們提出在這個動態架構中自動評估 TOD 模型的方法。

##### **Steering AI-Driven Personalization of Scientific Text for General Audiences**
2411.09969v1 by Taewook Kim, Dhruv Agarwal, Jordan Ackerman, Manaswi Saha

Digital media platforms (e.g., social media, science blogs) offer
opportunities to communicate scientific content to general audiences at scale.
However, these audiences vary in their scientific expertise, literacy levels,
and personal backgrounds, making effective science communication challenging.
To address this challenge, we designed TranSlider, an AI-powered tool that
generates personalized translations of scientific text based on individual user
profiles (e.g., hobbies, location, and education). Our tool features an
interactive slider that allows users to steer the degree of personalization
from 0 (weakly relatable) to 100 (strongly relatable), leveraging LLMs to
generate the translations with given degrees. Through an exploratory study with
15 participants, we investigated both the utility of these AI-personalized
translations and how interactive reading features influenced users'
understanding and reading experiences. We found that participants who preferred
higher degrees of personalization appreciated the relatable and contextual
translations, while those who preferred lower degrees valued concise
translations with subtle contextualization. Furthermore, participants reported
the compounding effect of multiple translations on their understanding of
scientific content. Given these findings, we discuss several implications of
AI-personalized translation tools in facilitating communication in
collaborative contexts.

摘要：數位媒體平台（例如社群媒體、科學部落格）提供機會，可以大規模地向一般大眾傳達科學內容。然而，這些受眾的科學專業知識、識字程度和個人背景各不相同，這使得有效的科學傳播具有挑戰性。為了應對這項挑戰，我們設計了 TranSlider，這是一款由 AI 驅動的工具，它根據個別使用者的個人資料（例如嗜好、位置和教育程度）產生科學文字的個人化翻譯。我們的工具具有一個互動式滑桿，使用戶可以從 0（關聯性低）到 100（關聯性高）調整個人化的程度，並利用大型語言模型 (LLM) 產生具有特定程度的翻譯。透過一項包含 15 位參與者的探索性研究，我們探討了這些 AI 個人化翻譯的效用，以及互動式閱讀功能如何影響使用者的理解和閱讀體驗。我們發現，較偏好高個人化程度的參與者欣賞相關且有脈絡的翻譯，而較偏好低個人化程度的參與者則重視簡潔且脈絡化不那麼明顯的翻譯。此外，參與者回報了多重翻譯對他們理解科學內容的累加效應。根據這些發現，我們討論了 AI 個人化翻譯工具在促進協作環境中溝通的幾個影響。

##### **Seeing Clearly by Layer Two: Enhancing Attention Heads to Alleviate Hallucination in LVLMs**
2411.09968v1 by Xiaofeng Zhang, Yihao Quan, Chaochen Gu, Chen Shen, Xiaosong Yuan, Shaotian Yan, Hao Cheng, Kaijie Wu, Jieping Ye

The hallucination problem in multimodal large language models (MLLMs) remains
a common issue. Although image tokens occupy a majority of the input sequence
of MLLMs, there is limited research to explore the relationship between image
tokens and hallucinations. In this paper, we analyze the distribution of
attention scores for image tokens across each layer and head of the model,
revealing an intriguing and common phenomenon: most hallucinations are closely
linked to the pattern of attention sinks in the self-attention matrix of image
tokens, where shallow layers exhibit dense attention sinks and deeper layers
show sparse attention sinks. We further analyze the attention heads of
different layers and find that heads with high-density attention sink in the
image part play a positive role in alleviating hallucinations. In this paper,
we propose a training-free method named \textcolor{red}{\textbf{E}}nhancing
\textcolor{red}{\textbf{A}}ttention \textcolor{red}{\textbf{H}}eads (EAH), an
approach designed to enhance the convergence of image tokens attention sinks in
the shallow layers. EAH identifies the attention head that shows the vision
sink in a shallow layer and extracts its attention matrix. This attention map
is then broadcast to other heads in the layer, thereby strengthening the layer
to pay more attention to the image itself. With extensive experiments, EAH
shows significant hallucination-mitigating performance on different MLLMs and
metrics, proving its effectiveness and generality.

摘要：多模态大型语言模型 (MLLM) 中的幻觉问题仍然是一个常见问题。尽管图像标记占据了 MLLM 输入序列的大部分，但探索图像标记和幻觉之间关系的研究却很有限。在本文中，我们分析了跨模型的每一层和头的图像标记的注意力分数分布，揭示了一个有趣且普遍的现象：大多数幻觉与图像标记的自注意力矩阵中的注意力汇聚模式密切相关，其中浅层表现出密集的注意力汇聚，而深层表现出稀疏的注意力汇聚。我们进一步分析了不同层的注意力头，发现图像部分中具有高密度注意力汇聚的注意力头在减轻幻觉中起到了积极作用。在本文中，我们提出了一种名为\textcolor{red}{\textbf{E}}nhancing \textcolor{red}{\textbf{A}}ttention \textcolor{red}{\textbf{H}}eads (EAH) 的免训练方法，这是一种旨在增强浅层中图像标记注意力汇聚收敛性的方法。EAH 识别出在浅层中显示视觉汇聚的注意力头并提取其注意力矩阵。然后将此注意力图广播到层中的其他头，从而增强该层对图像本身的关注。通过广泛的实验，EAH 在不同的 MLLM 和指标上显示出显着的缓解幻觉的性能，证明了其有效性和普遍性。

##### **Instruction-Guided Editing Controls for Images and Multimedia: A Survey in LLM era**
2411.09955v1 by Thanh Tam Nguyen, Zhao Ren, Trinh Pham, Phi Le Nguyen, Hongzhi Yin, Quoc Viet Hung Nguyen

The rapid advancement of large language models (LLMs) and multimodal learning
has transformed digital content creation and manipulation. Traditional visual
editing tools require significant expertise, limiting accessibility. Recent
strides in instruction-based editing have enabled intuitive interaction with
visual content, using natural language as a bridge between user intent and
complex editing operations. This survey provides an overview of these
techniques, focusing on how LLMs and multimodal models empower users to achieve
precise visual modifications without deep technical knowledge. By synthesizing
over 100 publications, we explore methods from generative adversarial networks
to diffusion models, examining multimodal integration for fine-grained content
control. We discuss practical applications across domains such as fashion, 3D
scene manipulation, and video synthesis, highlighting increased accessibility
and alignment with human intuition. Our survey compares existing literature,
emphasizing LLM-empowered editing, and identifies key challenges to stimulate
further research. We aim to democratize powerful visual editing across various
industries, from entertainment to education. Interested readers are encouraged
to access our repository at
https://github.com/tamlhp/awesome-instruction-editing.

摘要：大型語言模型 (LLM) 和多模態學習的快速進展已經轉變了數位內容的建立和操作。傳統的視覺編輯工具需要大量的專業知識，限制了可及性。最近在基於指令的編輯上取得的進展，使用自然語言作為使用者意圖和複雜編輯操作之間的橋梁，實現了與視覺內容的直覺互動。這項調查提供了這些技術的概述，重點在於 LLM 和多模態模型如何讓使用者在沒有深入技術知識的情況下，實現精確的視覺修改。透過綜合超過 100 篇出版品，我們探討了從生成對抗網路到擴散模型的方法，檢視多模態整合以進行細緻的內容控制。我們討論了在時尚、3D 場景操作和影片合成等領域的實際應用，強調了可及性的提升和與人類直覺的一致性。我們的調查比較了現有的文獻，強調了 LLM 賦能的編輯，並找出關鍵挑戰以激勵進一步的研究。我們的目標是讓強大的視覺編輯在各種產業中民主化，從娛樂到教育。我們鼓勵有興趣的讀者存取我們的資源庫：
https://github.com/tamlhp/awesome-instruction-editing。

##### **GGAvatar: Reconstructing Garment-Separated 3D Gaussian Splatting Avatars from Monocular Video**
2411.09952v1 by Jingxuan Chen

Avatar modelling has broad applications in human animation and virtual
try-ons. Recent advancements in this field have focused on high-quality and
comprehensive human reconstruction but often overlook the separation of
clothing from the body. To bridge this gap, this paper introduces GGAvatar
(Garment-separated 3D Gaussian Splatting Avatar), which relies on monocular
videos. Through advanced parameterized templates and unique phased training,
this model effectively achieves decoupled, editable, and realistic
reconstruction of clothed humans. Comparative evaluations with other costly
models confirm GGAvatar's superior quality and efficiency in modelling both
clothed humans and separable garments. The paper also showcases applications in
clothing editing, as illustrated in Figure 1, highlighting the model's benefits
and the advantages of effective disentanglement. The code is available at
https://github.com/J-X-Chen/GGAvatar/.

摘要：化身建模在人類動畫和虛擬試穿中具有廣泛的應用。最近在這個領域的進展專注於高品質和全面的重建，但常常忽略了將衣物與身體分開。為了彌補這個差距，本文介紹了 GGAvatar（分離衣物的 3D 高斯潑濺化身），它依賴於單眼影片。透過先進的參數化範本和獨特的階段訓練，這個模型有效地達到了分離、可編輯和逼真的穿著人類重建。與其他昂貴模型的比較評估證實了 GGAvatar 在建模穿著人類和可分離衣物方面的優異品質和效率。本文還展示了服裝編輯的應用，如圖 1 所示，突出了該模型的優點和有效解開糾纏的優勢。程式碼可在 https://github.com/J-X-Chen/GGAvatar/ 取得。

##### **LoRA-LiteE: A Computationally Efficient Framework for Chatbot Preference-Tuning**
2411.09947v1 by Yahe Yang, Chunliang Tao, Xiaojing Fan

Effective preference tuning is pivotal in aligning chatbot responses with
human expectations, enhancing user satisfaction and engagement. Traditional
approaches, notably Reinforcement Learning from Human Feedback (RLHF) as
employed in advanced models like GPT-4, have demonstrated considerable success
in this domain. However, RLHF methods are often computationally intensive and
resource-demanding, limiting their scalability and accessibility for broader
applications. To address these challenges, this study introduces LoRA-Lite
Ensemble (LoRA-LiteE), an innovative framework that combines Supervised
Fine-tuning (SFT) with Low-Rank Adaptation (LoRA) and Ensemble Learning
techniques to effectively aggregate predictions of lightweight models, which
aim to achieve a balance between the performance and computational cost.
Utilizing the Chatbot Arena benchmark dataset, we conduct a comprehensive
comparative analysis among our LoRA-LiteE model, corresponding base models at
different scales, and GPT-4 trained with RLHF. Our empirical results
demonstrate that the proposed LoRA-LiteE model achieves comparable performance
to un-finetuned GPT-4 and outperforms the single larger-scale models under
limited resource constraints. These findings highlight that our LoRA-LiteE
provides a feasible and efficient methodology for human preference prediction
in chatbot systems, enhancing scalability and accessibility, and thereby
broadening the applicability of preference-tuned chatbots in
resource-constrained environments.

摘要：<paragraph>有效的偏好調整對於將聊天機器人回應與人類期望保持一致至關重要，從而增強用戶滿意度和參與度。傳統方法，尤其是像 GPT-4 等先進模型中採用的基於人類反饋的強化學習 (RLHF)，已證明在這個領域取得了顯著成功。然而，RLHF 方法通常計算量大且需要大量資源，這限制了它們在更廣泛應用中的可擴展性和可訪問性。為了應對這些挑戰，本研究引入了 LoRA-Lite Ensemble (LoRA-LiteE)，這是一個創新的框架，它將監督微調 (SFT) 與低秩適應 (LoRA) 和集成學習技術相結合，以有效地匯總輕量級模型的預測，旨在性能與計算成本之間取得平衡。利用 Chatbot Arena 基準數據集，我們對我們的 LoRA-LiteE 模型、不同規模的對應基礎模型以及使用 RLHF 訓練的 GPT-4 進行了全面的比較分析。我們的實證結果表明，所提出的 LoRA-LiteE 模型實現了與未微調的 GPT-4 相當的性能，並且在有限的資源約束下優於單個更大規模的模型。這些發現強調了我們的 LoRA-LiteE 為聊天機器人系統中的人類偏好預測提供了一種可行且高效的方法，增強了可擴展性和可訪問性，從而擴大了偏好調整聊天機器人在資源受限環境中的適用性。</paragraph>

##### **TEESlice: Protecting Sensitive Neural Network Models in Trusted Execution Environments When Attackers have Pre-Trained Models**
2411.09945v1 by Ding Li, Ziqi Zhang, Mengyu Yao, Yifeng Cai, Yao Guo, Xiangqun Chen

Trusted Execution Environments (TEE) are used to safeguard on-device models.
However, directly employing TEEs to secure the entire DNN model is challenging
due to the limited computational speed. Utilizing GPU can accelerate DNN's
computation speed but commercial widely-available GPUs usually lack security
protection. To this end, scholars introduce TSDP, a method that protects
privacy-sensitive weights within TEEs and offloads insensitive weights to GPUs.
Nevertheless, current methods do not consider the presence of a knowledgeable
adversary who can access abundant publicly available pre-trained models and
datasets. This paper investigates the security of existing methods against such
a knowledgeable adversary and reveals their inability to fulfill their security
promises. Consequently, we introduce a novel partition before training
strategy, which effectively separates privacy-sensitive weights from other
components of the model. Our evaluation demonstrates that our approach can
offer full model protection with a computational cost reduced by a factor of
10. In addition to traditional CNN models, we also demonstrate the scalability
to large language models. Our approach can compress the private functionalities
of the large language model to lightweight slices and achieve the same level of
protection as the shielding-whole-model baseline.

摘要：受信任執行環境 (TEE) 用於保護裝置上的模型。
然而，由於運算速度有限，直接使用 TEE 保護整個 DNN 模型具有挑戰性。利用 GPU 可以加速 DNN 的運算速度，但市面上普遍可用的 GPU 通常缺乏安全性保護。為此，學者們引入了 TSDP，一種在 TEE 內保護隱私敏感權重並將不敏感權重卸載到 GPU 的方法。
儘管如此，目前的方法並未考慮知識淵博的對手，他們可以存取大量公開可用的預訓練模型和資料集。本文探討了現有方法針對此類知識淵博對手的安全性，並揭示了他們無法履行安全承諾。因此，我們在訓練策略之前引入了創新的分割，有效地將隱私敏感權重與模型的其他組成部分分開。我們的評估表明，我們的做法可以提供完整的模型保護，同時將運算成本降低了 10 倍。除了傳統的 CNN 模型外，我們還展示了可擴充性至大型語言模型。我們的做法可以將大型語言模型的私有功能壓縮成輕量級切片，並實現與保護整個模型的基準線相同的保護級別。

##### **SlimLM: An Efficient Small Language Model for On-Device Document Assistance**
2411.09944v1 by Thang M. Pham, Phat T. Nguyen, Seunghyun Yoon, Viet Dac Lai, Franck Dernoncourt, Trung Bui

While small language models (SLMs) show promises for mobile deployment, their
real-world performance and applications on smartphones remains underexplored.
We present SlimLM, a series of SLMs optimized for document assistance tasks on
mobile devices. Through extensive experiments on a Samsung Galaxy S24, we
identify the optimal trade-offs between model size (ranging from 125M to 7B
parameters), context length, and inference time for efficient on-device
processing. SlimLM is pre-trained on SlimPajama-627B and fine-tuned on
DocAssist, our constructed dataset for summarization, question answering and
suggestion tasks. Our smallest model demonstrates efficient performance on S24,
while larger variants offer enhanced capabilities within mobile constraints. We
evaluate SlimLM against existing SLMs, showing comparable or superior
performance and offering a benchmark for future research in on-device language
models. We also provide an Android application, offering practical insights
into SLM deployment. Our findings provide valuable insights and illuminate the
capabilities of running advanced language models on high-end smartphones,
potentially reducing server costs and enhancing privacy through on-device
processing.

摘要：儘管小型語言模型 (SLM) 對於行動裝置部署而言極具前景，但其在智慧型手機上的實際效能和應用仍有待深入探討。我們提出 SlimLM，這是一系列針對行動裝置上的文件輔助任務而最佳化的 SLM。透過在 Samsung Galaxy S24 上進行廣泛的實驗，我們找出模型大小（範圍從 125M 到 7B 參數）、內容長度和推論時間之間的最佳取捨，以利於高效的裝置內處理。SlimLM 預先在 SlimPajama-627B 上進行訓練，並在 DocAssist（我們建構的摘要、問答和建議任務資料集）上進行微調。我們最小的模型在 S24 上展現出高效能，而較大的變體則在行動裝置限制內提供增強的功能。我們針對現有的 SLM 評估 SlimLM，展現出相近或更優異的效能，並為未來的裝置內語言模型研究提供一個基準。我們也提供一個 Android 應用程式，提供 SLM 部署的實用見解。我們的研究結果提供有價值的見解，並闡明在高階智慧型手機上執行進階語言模型的能力，這有可能透過裝置內處理來降低伺服器成本並增強隱私權。

##### **Refined and Segmented Price Sentiment Indices from Survey Comments**
2411.09937v1 by Masahiro Suzuki, Hiroki Sakaji

We aim to enhance a price sentiment index and to more precisely understand
price trends from the perspective of not only consumers but also businesses. We
extract comments related to prices from the Economy Watchers Survey conducted
by the Cabinet Office of Japan and classify price trends using a large language
model (LLM). We classify whether the survey sample reflects the perspective of
consumers or businesses, and whether the comments pertain to goods or services
by utilizing information on the fields of comments and the industries of
respondents included in the Economy Watchers Survey. From these classified
price-related comments, we construct price sentiment indices not only for a
general purpose but also for more specific objectives by combining perspectives
on consumers and prices, as well as goods and services. It becomes possible to
achieve a more accurate classification of price directions by employing a LLM
for classification. Furthermore, integrating the outputs of multiple LLMs
suggests the potential for the better performance of the classification. The
use of more accurately classified comments allows for the construction of an
index with a higher correlation to existing indices than previous studies. We
demonstrate that the correlation of the price index for consumers, which has a
larger sample size, is further enhanced by selecting comments for aggregation
based on the industry of the survey respondents.

摘要：我们旨在提升价格情绪指数，并从消费者和企业的角度更准确地了解价格趋势。我们从日本内阁府进行的经济观察者调查中提取与价格相关的评论，并使用大型语言模型 (LLM) 对价格趋势进行分类。我们通过利用经济观察者调查中包含的评论领域和受访者行业的信息，对调查样本是反映消费者还是企业的观点以及评论是否涉及商品或服务进行分类。从这些分类的价格相关评论中，我们不仅针对一般目的，还针对更具体的目标构建价格情绪指数，方法是结合消费者和价格以及商品和服务的观点。通过使用 LLM 进行分类，可以更准确地对价格方向进行分类。此外，整合多个 LLM 的输出表明分类性能更好的可能性。使用更准确分类的评论可以构建一个与现有指数相关性高于以前研究的指数。我们证明了样本量较大的消费者价格指数的相关性通过根据调查受访者的行业选择用于聚合的评论而进一步提高。

##### **JRadiEvo: A Japanese Radiology Report Generation Model Enhanced by Evolutionary Optimization of Model Merging**
2411.09933v1 by Kaito Baba, Ryota Yagi, Junichiro Takahashi, Risa Kishikawa, Satoshi Kodera

With the rapid advancement of large language models (LLMs), foundational
models (FMs) have seen significant advancements. Healthcare is one of the most
crucial application areas for these FMs, given the significant time and effort
required for physicians to analyze large volumes of patient data. Recent
efforts have focused on adapting multimodal FMs to the medical domain through
techniques like instruction-tuning, leading to the development of medical
foundation models (MFMs). However, these approaches typically require large
amounts of training data to effectively adapt models to the medical field.
Moreover, most existing models are trained on English datasets, limiting their
practicality in non-English-speaking regions where healthcare professionals and
patients are not always fluent in English. The need for translation introduces
additional costs and inefficiencies. To address these challenges, we propose a
\textbf{J}apanese \textbf{Radi}ology report generation model enhanced by
\textbf{Evo}lutionary optimization of model merging (JRadiEvo). This is the
first attempt to extend a non-medical vision-language foundation model to the
medical domain through evolutionary optimization of model merging. We
successfully created a model that generates accurate Japanese reports from
X-ray images using only 50 translated samples from publicly available data.
This model, developed with highly efficient use of limited data, outperformed
leading models from recent research trained on much larger datasets.
Additionally, with only 8 billion parameters, this relatively compact
foundation model can be deployed locally within hospitals, making it a
practical solution for environments where APIs and other external services
cannot be used due to strict privacy and security requirements.

摘要：<paragraph>隨著大型語言模型 (LLM) 的快速進展，基礎模型 (FM) 已經獲得顯著的進步。醫療保健是這些 FM 最重要的應用領域之一，因為醫生需要花費大量時間和精力來分析大量的患者資料。最近的研究重點在於透過指令微調等技術將多模態 FM 適應到醫療領域，從而開發出醫療基礎模型 (MFM)。然而，這些方法通常需要大量的訓練資料才能有效地將模型適應到醫療領域。此外，大多數現有模型都是針對英語資料集進行訓練，這限制了它們在非英語地區的實用性，那裡的醫療專業人員和患者並不總是精通英語。翻譯的需求引入了額外的成本和低效率。為了應對這些挑戰，我們提出了一個由模型合併的進化優化增強的**J**apanese **Radi**ology 報告生成模型 (JRadiEvo)。這是首次嘗試透過模型合併的進化優化將非醫療視覺語言基礎模型擴展到醫療領域。我們成功地建立了一個模型，僅使用來自公開資料的 50 個翻譯範例，就能從 X 光影像中產生準確的日文報告。這個模型使用有限資料進行高效率的開發，其效能優於最近研究中在更大資料集上訓練出來的領先模型。此外，這個相對精簡的基礎模型只有 80 億個參數，可以在醫院內部進行本地部署，使其成為在嚴格的隱私和安全要求下無法使用 API 和其他外部服務的環境中的實用解決方案。</paragraph>

##### **Motion-Grounded Video Reasoning: Understanding and Perceiving Motion at Pixel Level**
2411.09921v1 by Andong Deng, Tongjia Chen, Shoubin Yu, Taojiannan Yang, Lincoln Spencer, Yapeng Tian, Ajmal Saeed Mian, Mohit Bansal, Chen Chen

In this paper, we introduce Motion-Grounded Video Reasoning, a new motion
understanding task that requires generating visual answers (video segmentation
masks) according to the input question, and hence needs implicit spatiotemporal
reasoning and grounding. This task extends existing spatiotemporal grounding
work focusing on explicit action/motion grounding, to a more general format by
enabling implicit reasoning via questions. To facilitate the development of the
new task, we collect a large-scale dataset called GROUNDMORE, which comprises
1,715 video clips, 249K object masks that are deliberately designed with 4
question types (Causal, Sequential, Counterfactual, and Descriptive) for
benchmarking deep and comprehensive motion reasoning abilities. GROUNDMORE
uniquely requires models to generate visual answers, providing a more concrete
and visually interpretable response than plain texts. It evaluates models on
both spatiotemporal grounding and reasoning, fostering to address complex
challenges in motion-related video reasoning, temporal perception, and
pixel-level understanding. Furthermore, we introduce a novel baseline model
named Motion-Grounded Video Reasoning Assistant (MORA). MORA incorporates the
multimodal reasoning ability from the Multimodal LLM, the pixel-level
perception capability from the grounding model (SAM), and the temporal
perception ability from a lightweight localization head. MORA achieves
respectable performance on GROUNDMORE outperforming the best existing visual
grounding baseline model by an average of 21.5% relatively. We hope this novel
and challenging task will pave the way for future advancements in robust and
general motion understanding via video reasoning segmentation

摘要：<paragraph>本文中，我們介紹了運動基礎影片推理，這是一種新的運動理解任務，需要根據輸入問題生成視覺答案（影片分割遮罩），因此需要隱含的時空推理和基礎。此任務擴展了現有的時空基礎工作，專注於明確的動作/運動基礎，通過問題啟用隱含推理，轉變為更通用的格式。為了促進新任務的發展，我們收集了一個名為 GROUNDMORE 的大型資料集，其中包含 1,715 個影片剪輯、249K 個物件遮罩，這些遮罩經過精心設計，有 4 種類型的問題（因果、順序、反事實和描述性），用於評量深入且全面的運動推理能力。GROUNDMORE 獨特地要求模型生成視覺答案，提供比純文字更具體且視覺上可解釋的回應。它在時空基礎和推理上評估模型，促進了解與運動相關的影片推理、時間感知和像素層級理解中的複雜挑戰。此外，我們介紹了一個名為運動基礎影片推理助理（MORA）的新穎基線模型。MORA 結合了多模態 LLM 的多模態推理能力、基礎模型（SAM）的像素層級感知能力，以及輕量級定位頭的時間感知能力。MORA 在 GROUNDMORE 上取得了令人尊敬的效能，平均優於現有最佳視覺基礎基線模型 21.5%。我們希望這個新穎且具有挑戰性的任務將為透過影片推理分割，在穩健且通用的運動理解方面未來進展鋪路。</paragraph>

##### **AMXFP4: Taming Activation Outliers with Asymmetric Microscaling Floating-Point for 4-bit LLM Inference**
2411.09909v1 by Janghwan Lee, Jiwoong Park, Jinseok Kim, Yongjik Kim, Jungju Oh, Jinwook Oh, Jungwook Choi

Scaling Large Language Models (LLMs) with extended context lengths has
increased the need for efficient low-bit quantization to manage their
substantial computational demands. However, reducing precision to 4 bits
frequently degrades performance due to activation outliers. To address this, we
propose Asymmetric Microscaling 4-bit Floating-Point (AMXFP4) for efficient LLM
inference. This novel data format leverages asymmetric shared scales to
mitigate outliers while naturally capturing the asymmetry introduced by
group-wise quantization. Unlike conventional 4-bit quantization methods that
rely on data rotation and costly calibration, AMXFP4 uses asymmetric shared
scales for direct 4-bit casting, achieving near-ideal quantization accuracy
across various LLM tasks, including multi-turn conversations, long-context
reasoning, and visual question answering. Our AMXFP4 format significantly
outperforms MXFP4 and other leading quantization techniques, enabling robust,
calibration-free 4-bit inference.

摘要：擴展上下文長度的大語言模型 (LLM) 的擴展，增加了對有效低位元量化管理其大量運算需求的需求。然而，將精度降低到 4 位元經常會因為啟動值異常值而降低效能。為了解決這個問題，我們提出非對稱微縮 4 位元浮點數 (AMXFP4) 以進行有效的 LLM 推論。這種新穎的資料格式利用非對稱共享比例來減輕異常值，同時自然捕捉群組量化引入的非對稱性。與依賴資料旋轉和昂貴校準的傳統 4 位元量化方法不同，AMXFP4 使用非對稱共享比例進行直接 4 位元轉換，在各種 LLM 任務中實現接近理想的量化精度，包括多輪對話、長脈絡推理和視覺問答。我們的 AMXFP4 格式明顯優於 MXFP4 和其他領先的量化技術，實現強健、無需校準的 4 位元推論。

##### **Statistical Analysis of Policy Space Compression Problem**
2411.09900v1 by Majid Molaei, Marcello Restelli, Alberto Maria Metelli, Matteo Papini

Policy search methods are crucial in reinforcement learning, offering a
framework to address continuous state-action and partially observable problems.
However, the complexity of exploring vast policy spaces can lead to significant
inefficiencies. Reducing the policy space through policy compression emerges as
a powerful, reward-free approach to accelerate the learning process. This
technique condenses the policy space into a smaller, representative set while
maintaining most of the original effectiveness. Our research focuses on
determining the necessary sample size to learn this compressed set accurately.
We employ R\'enyi divergence to measure the similarity between true and
estimated policy distributions, establishing error bounds for good
approximations. To simplify the analysis, we employ the $l_1$ norm, determining
sample size requirements for both model-based and model-free settings. Finally,
we correlate the error bounds from the $l_1$ norm with those from R\'enyi
divergence, distinguishing between policies near the vertices and those in the
middle of the policy space, to determine the lower and upper bounds for the
required sample sizes.

摘要：策略搜索方法在强化学习中至关重要，它提供了一个解决连续状态动作和部分可观察问题的框架。然而，探索广阔策略空间的复杂性可能导致严重的低效率。通过策略压缩来减少策略空间成为一种强大的、无奖励的方法，可以加速学习过程。这种技术将策略空间压缩到一个更小、更具代表性的集合中，同时保持大部分的原始有效性。我们的研究重点是确定学习这个压缩集合所需的样本量。我们采用 R\'enyi 散度来衡量真实策略分布和估计策略分布之间的相似性，为良好的近似值建立误差界限。为了简化分析，我们采用 $l_1$ 范数，确定基于模型和无模型设置的样本量需求。最后，我们将 $l_1$ 范数的误差界限与 R\'enyi 散度的误差界限相关联，区分接近顶点的策略和策略空间中间的策略，以确定所需样本量的下限和上限。

##### **Research on Domain-Specific Chinese Spelling Correction Method Based on Plugin Extension Modules**
2411.09884v1 by Xiaowu Zhang, Hongfei Zhao, Xuan Chang

This paper proposes a Chinese spelling correction method based on plugin
extension modules, aimed at addressing the limitations of existing models in
handling domain-specific texts. Traditional Chinese spelling correction models
are typically trained on general-domain datasets, resulting in poor performance
when encountering specialized terminology in domain-specific texts. To address
this issue, we design an extension module that learns the features of
domain-specific terminology, thereby enhancing the model's correction
capabilities within specific domains. This extension module can provide domain
knowledge to the model without compromising its general spelling correction
performance, thus improving its accuracy in specialized fields. Experimental
results demonstrate that after integrating extension modules for medical,
legal, and official document domains, the model's correction performance is
significantly improved compared to the baseline model without any extension
modules.

摘要：本文提出一個基於外掛程式擴充模組的中文拼寫修正方法，旨在解決現有模型在處理特定領域文本時的限制。傳統的中文拼寫修正模型通常在一般領域的資料集上訓練，在遇到特定領域文本中的專業術語時，效能不佳。為了解決這個問題，我們設計了一個擴充模組，學習特定領域術語的特徵，從而增強模型在特定領域內的修正能力。此擴充模組可以向模型提供領域知識，而不會影響其一般拼寫修正效能，從而提高其在專業領域的準確性。實驗結果表明，在整合了醫療、法律和官方文件領域的擴充模組後，模型的修正效能與沒有任何擴充模組的基準模型相比，顯著提升。

##### **A Hybrid Artificial Intelligence System for Automated EEG Background Analysis and Report Generation**
2411.09874v1 by Chin-Sung Tung, Sheng-Fu Liang, Shu-Feng Chang, Chung-Ping Young

Electroencephalography (EEG) plays a crucial role in the diagnosis of various
neurological disorders. However, small hospitals and clinics often lack
advanced EEG signal analysis systems and are prone to misinterpretation in
manual EEG reading. This study proposes an innovative hybrid artificial
intelligence (AI) system for automatic interpretation of EEG background
activity and report generation. The system combines deep learning models for
posterior dominant rhythm (PDR) prediction, unsupervised artifact removal, and
expert-designed algorithms for abnormality detection. For PDR prediction, 1530
labeled EEGs were used, and the best ensemble model achieved a mean absolute
error (MAE) of 0.237, a root mean square error (RMSE) of 0.359, an accuracy of
91.8% within a 0.6Hz error, and an accuracy of 99% within a 1.2Hz error. The AI
system significantly outperformed neurologists in detecting generalized
background slowing (p = 0.02; F1: AI 0.93, neurologists 0.82) and demonstrated
improved focal abnormality detection, although not statistically significant (p
= 0.79; F1: AI 0.71, neurologists 0.55). Validation on both an internal dataset
and the Temple University Abnormal EEG Corpus showed consistent performance
(F1: 0.884 and 0.835, respectively; p = 0.66), demonstrating generalizability.
The use of large language models (LLMs) for report generation demonstrated 100%
accuracy, verified by three other independent LLMs. This hybrid AI system
provides an easily scalable and accurate solution for EEG interpretation in
resource-limited settings, assisting neurologists in improving diagnostic
accuracy and reducing misdiagnosis rates.

摘要：腦電圖（EEG）在診斷各種神經疾病中扮演至關重要的角色。然而，小型醫院和診所通常缺乏進階的 EEG 訊號分析系統，且容易在手動判讀 EEG 時產生誤解。本研究提出一個創新的混合人工智慧（AI）系統，用於自動判讀 EEG 背景活動並產生報告。此系統結合深度學習模型，用於預測後優勢律動（PDR）、非監督人工製品移除，以及專家設計的異常偵測演算法。在 PDR 預測中，使用了 1530 個標記 EEG，最佳的整體模型達到了 0.237 的平均絕對誤差（MAE）、0.359 的均方根誤差（RMSE）、91.8% 的 0.6Hz 誤差準確度，以及 99% 的 1.2Hz 誤差準確度。AI 系統在偵測廣泛背景減慢方面明顯優於神經學家（p = 0.02；F1：AI 0.93，神經學家 0.82），並展現出改善的局部異常偵測，儘管沒有統計意義（p = 0.79；F1：AI 0.71，神經學家 0.55）。在內部資料集和 Temple University 異常 EEG 語料庫上的驗證顯示了一致的效能（F1：分別為 0.884 和 0.835；p = 0.66），證明了其普遍性。使用大型語言模型（LLM）來產生報告證明了 100% 的準確度，並由其他三個獨立的 LLM 驗證。此混合 AI 系統提供了一個易於擴充且準確的解決方案，用於在資源有限的環境中進行 EEG 判讀，協助神經學家提高診斷準確度並降低誤診率。

##### **Enhancing Diffusion Posterior Sampling for Inverse Problems by Integrating Crafted Measurements**
2411.09850v1 by Shijie Zhou, Huaisheng Zhu, Rohan Sharma, Ruiyi Zhang, Kaiyi Ji, Changyou Chen

Diffusion models have emerged as a powerful foundation model for visual
generation. With an appropriate sampling process, it can effectively serve as a
generative prior to solve general inverse problems. Current posterior sampling
based methods take the measurement (i.e., degraded image sample) into the
posterior sampling to infer the distribution of the target data (i.e., clean
image sample). However, in this manner, we show that high-frequency information
can be prematurely introduced during the early stages, which could induce
larger posterior estimate errors during the restoration sampling. To address
this issue, we first reveal that forming the log posterior gradient with the
noisy measurement ( i.e., samples from a diffusion forward process) instead of
the clean one can benefit the reverse process. Consequently, we propose a novel
diffusion posterior sampling method DPS-CM, which incorporates a Crafted
Measurement (i.e., samples generated by a reverse denoising process, compared
to random sampling with noise in standard methods) to form the posterior
estimate. This integration aims to mitigate the misalignment with the diffusion
prior caused by cumulative posterior estimate errors. Experimental results
demonstrate that our approach significantly improves the overall capacity to
solve general and noisy inverse problems, such as Gaussian deblurring,
super-resolution, inpainting, nonlinear deblurring, and tasks with Poisson
noise, relative to existing approaches.

摘要：擴散模型已成為視覺生成的有力基礎模型。透過適當的取樣程序，它可以有效地作為生成先驗來解決一般的逆問題。當前的後驗取樣方法將測量（即退化的影像樣本）納入後驗取樣，以推斷目標資料（即乾淨的影像樣本）的分布。然而，我們在此顯示，高頻率資訊可能會在早期階段過早地被引入，這可能會在還原取樣期間導致較大的後驗估計誤差。為了解決此問題，我們首先揭示，使用有雜訊的測量（即從擴散前向過程中取樣的樣本）而不是乾淨的測量來形成對數後驗梯度，有助於反向過程。因此，我們提出了一種新的擴散後驗取樣方法 DPS-CM，它結合了精心製作的測量（即由反向去雜訊過程生成的樣本，與標準方法中的雜訊隨機取樣相比）來形成後驗估計。這種整合旨在減輕由累積後驗估計誤差引起的與擴散先驗的不一致。實驗結果表明，與現有方法相比，我們的做法顯著改善了解決一般和有雜訊的逆問題的整體能力，例如高斯去模糊、超解析度、內插、非線性去模糊，以及具有泊松雜訊的任務。

##### **Self-Supervised Radio Pre-training: Toward Foundational Models for Spectrogram Learning**
2411.09849v1 by Ahmed Aboulfotouh, Ashkan Eshaghbeigi, Dimitrios Karslidis, Hatem Abou-Zeid

Foundational deep learning (DL) models are general models, trained on large,
diverse, and unlabelled datasets, typically using self-supervised learning
techniques have led to significant advancements especially in natural language
processing. These pretrained models can be fine-tuned for related downstream
tasks, offering faster development and reduced training costs, while often
achieving improved performance. In this work, we introduce Masked Spectrogram
Modeling, a novel self-supervised learning approach for pretraining
foundational DL models on radio signals. Adopting a Convolutional LSTM
architecture for efficient spatio-temporal processing, we pretrain the model
with an unlabelled radio dataset collected from over-the-air measurements.
Subsequently, the pretrained model is fine-tuned for two downstream tasks:
spectrum forecasting and segmentation. Experimental results demonstrate that
our methodology achieves competitive performance in both forecasting accuracy
and segmentation, validating its effectiveness for developing foundational
radio models.

摘要：基礎深度學習 (DL) 模型為一般模型，訓練於大型、多樣且未標記的資料集上，通常使用自我監督學習技術，已導致顯著的進展，特別是在自然語言處理中。這些預訓練模型可微調以進行相關的下游任務，提供更快的開發速度和降低的訓練成本，同時通常能提升效能。在此研究中，我們介紹遮罩語譜模型，一種用於在無線電訊號上預訓練基礎 DL 模型的新穎自我監督學習方法。採用卷積 LSTM 架構以進行有效率的時空處理，我們使用從無線量測中收集的未標記無線電資料集預訓練模型。隨後，預訓練模型會微調以進行兩個下游任務：頻譜預測和分割。實驗結果證明，我們的技術在預測準確度和分割方面都達到了競爭力，驗證了其在開發基礎無線電模型方面的有效性。

##### **Deep Autoencoders for Unsupervised Anomaly Detection in Wildfire Prediction**
2411.09844v1 by İrem Üstek, Miguel Arana-Catania, Alexander Farr, Ivan Petrunin

Wildfires pose a significantly increasing hazard to global ecosystems due to
the climate crisis. Due to its complex nature, there is an urgent need for
innovative approaches to wildfire prediction, such as machine learning. This
research took a unique approach, differentiating from classical supervised
learning, and addressed the gap in unsupervised wildfire prediction using
autoencoders and clustering techniques for anomaly detection. Historical
weather and normalised difference vegetation index datasets of Australia for
2005 - 2021 were utilised. Two main unsupervised approaches were analysed. The
first used a deep autoencoder to obtain latent features, which were then fed
into clustering models, isolation forest, local outlier factor and one-class
SVM for anomaly detection. The second approach used a deep autoencoder to
reconstruct the input data and use reconstruction errors to identify anomalies.
Long Short-Term Memory (LSTM) autoencoders and fully connected (FC)
autoencoders were employed in this part, both in an unsupervised way learning
only from nominal data. The FC autoencoder outperformed its counterparts,
achieving an accuracy of 0.71, an F1-score of 0.74, and an MCC of 0.42. These
findings highlight the practicality of this method, as it effectively predicts
wildfires in the absence of ground truth, utilising an unsupervised learning
technique.

摘要：野火因气候危机对全球生态系统构成日益严重的危害。由于其复杂性，迫切需要采用创新方法来预测野火，例如机器学习。本研究采取了一种独特的方法，区别于经典的监督学习，并使用自动编码器和聚类技术解决了无监督野火预测中的差距，用于异常检测。利用了 2005 年至 2021 年澳大利亚的历史天气和归一化差异植被指数数据集。分析了两种主要的无监督方法。第一个使用深度自动编码器来获取潜在特征，然后将其输入聚类模型、隔离森林、局部异常因子和一类 SVM 以进行异常检测。第二种方法使用深度自动编码器来重建输入数据并使用重建误差来识别异常。长短期记忆 (LSTM) 自动编码器和全连接 (FC) 自动编码器用于这部分，两者都以无监督的方式仅从标称数据中学习。FC 自动编码器优于其对应项，准确率达到 0.71，F1 分数为 0.74，MCC 为 0.42。这些发现突出了该方法的实用性，因为它在没有地面真实值的情况下有效地预测野火，利用无监督学习技术。

##### **Real-time Adapting Routing (RAR): Improving Efficiency Through Continuous Learning in Software Powered by Layered Foundation Models**
2411.09837v1 by Kirill Vasilevski, Dayi Lin, Ahmed Hassan

To balance the quality and inference cost of a Foundation Model (FM, such as
large language models (LLMs)) powered software, people often opt to train a
routing model that routes requests to FMs with different sizes and
capabilities. Existing routing models rely on learning the optimal routing
decision from carefully curated data, require complex computations to be
updated, and do not consider the potential evolution of weaker FMs. In this
paper, we propose Real-time Adaptive Routing (RAR), an approach to continuously
adapt FM routing decisions while using guided in-context learning to enhance
the capabilities of weaker FM. The goal is to reduce reliance on stronger, more
expensive FMs. We evaluate our approach on different subsets of the popular
MMLU benchmark. Over time, our approach routes 50.2% fewer requests to
computationally expensive models while maintaining around 90.5% of the general
response quality. In addition, the guides generated from stronger models have
shown intra-domain generalization and led to a better quality of responses
compared to an equivalent approach with a standalone weaker FM.

摘要：為了平衡由基礎模型 (FM，例如大型語言模型 (LLM)) 驅動的軟體品質和推論成本，人們通常選擇訓練一個路由模型，將請求路由到具有不同大小和功能的 FM。現有的路由模型依賴於從仔細策劃的資料中學習最佳路由決策，需要複雜的運算才能更新，而且不會考慮較弱 FM 的潛在演化。在本文中，我們提出實時適應性路由 (RAR)，一種方法可以持續調整 FM 路由決策，同時使用引導式情境學習來增強較弱 FM 的功能。目標是減少對更強大、更昂貴的 FM 的依賴。我們在流行的 MMLU 基準的不同子集上評估我們的做法。隨著時間推移，我們的做法將請求路由到計算成本昂貴的模型的數量減少了 50.2%，同時維持約 90.5% 的一般回應品質。此外，從較強大的模型產生的指南已顯示出領域內概化，並且與具有獨立較弱 FM 的等效做法相比，產生了較好的回應品質。

##### **A Benchmark for Long-Form Medical Question Answering**
2411.09834v1 by Pedram Hosseini, Jessica M. Sin, Bing Ren, Bryceton G. Thomas, Elnaz Nouri, Ali Farahanchi, Saeed Hassanpour

There is a lack of benchmarks for evaluating large language models (LLMs) in
long-form medical question answering (QA). Most existing medical QA evaluation
benchmarks focus on automatic metrics and multiple-choice questions. While
valuable, these benchmarks fail to fully capture or assess the complexities of
real-world clinical applications where LLMs are being deployed. Furthermore,
existing studies on evaluating long-form answer generation in medical QA are
primarily closed-source, lacking access to human medical expert annotations,
which makes it difficult to reproduce results and enhance existing baselines.
In this work, we introduce a new publicly available benchmark featuring
real-world consumer medical questions with long-form answer evaluations
annotated by medical doctors. We performed pairwise comparisons of responses
from various open and closed-source medical and general-purpose LLMs based on
criteria such as correctness, helpfulness, harmfulness, and bias. Additionally,
we performed a comprehensive LLM-as-a-judge analysis to study the alignment
between human judgments and LLMs. Our preliminary results highlight the strong
potential of open LLMs in medical QA compared to leading closed models. Code &
Data: https://github.com/lavita-ai/medical-eval-sphere

摘要：缺乏評估大型語言模型 (LLM) 在長篇醫療問題解答 (QA) 中表現的基準。現有的醫療 QA 評估基準大多著重於自動化指標和多選題。儘管有價值，但這些基準並未完全掌握或評估 LLM 部署於其中的真實世界臨床應用之複雜性。此外，現有評估醫療 QA 中長篇答案產生的研究主要為閉源，無法取得人類醫療專家註解，這使得難以重現結果並強化現有基準。在這項工作中，我們引進一個新的公開基準，其特點是真實世界的消費者醫療問題，並附有由醫療醫生註解的長篇答案評估。我們根據正確性、有益性、有害性和偏見等準則，對來自各種開放和閉源醫療和通用 LLM 的回應進行成對比較。此外，我們執行了一項全面的 LLM 作為評判的分析，以研究人類判斷和 LLM 之間的一致性。我們的初步結果突出了開放 LLM 在醫療 QA 中的強大潛力，優於領先的閉源模型。程式碼和資料：https://github.com/lavita-ai/medical-eval-sphere

##### **Evaluating Gender Bias in Large Language Models**
2411.09826v1 by Michael Döll, Markus Döhring, Andreas Müller

Gender bias in artificial intelligence has become an important issue,
particularly in the context of language models used in communication-oriented
applications. This study examines the extent to which Large Language Models
(LLMs) exhibit gender bias in pronoun selection in occupational contexts. The
analysis evaluates the models GPT-4, GPT-4o, PaLM 2 Text Bison and Gemini 1.0
Pro using a self-generated dataset. The jobs considered include a range of
occupations, from those with a significant male presence to those with a
notable female concentration, as well as jobs with a relatively equal gender
distribution. Three different sentence processing methods were used to assess
potential gender bias: masked tokens, unmasked sentences, and sentence
completion. In addition, the LLMs suggested names of individuals in specific
occupations, which were then examined for gender distribution. The results show
a positive correlation between the models' pronoun choices and the gender
distribution present in U.S. labor force data. Female pronouns were more often
associated with female-dominated occupations, while male pronouns were more
often associated with male-dominated occupations. Sentence completion showed
the strongest correlation with actual gender distribution, while name
generation resulted in a more balanced 'politically correct' gender
distribution, albeit with notable variations in predominantly male or female
occupations. Overall, the prompting method had a greater impact on gender
distribution than the model selection itself, highlighting the complexity of
addressing gender bias in LLMs. The findings highlight the importance of
prompting in gender mapping.

摘要：<paragraph>人工智能中的性別偏見已成為一個重要議題，
特別是在用於以溝通為導向的應用程式的語言模型的背景下。本研究探討了大型語言模型 (LLM) 在職業背景中代名詞選擇中表現出的性別偏見程度。
分析評估了模型 GPT-4、GPT-4o、PaLM 2 Text Bison 和 Gemini 1.0 Pro，使用自產的資料集。所考慮的工作包括一系列職業，從男性大量存在的工作到女性顯著集中的工作，以及性別分配相對平等的工作。使用了三種不同的句子處理方法來評估潛在的性別偏見：遮蔽符號、未遮蔽句子和句子完成。此外，LLM 建議了特定職業的個人姓名，然後檢查這些姓名的性別分佈。結果顯示，模型的代名詞選擇與美國勞動力數據中存在的性別分佈之間存在正相關。女性代名詞通常與女性主導的職業相關，而男性代名詞通常與男性主導的職業相關。句子完成顯示與實際性別分佈相關性最強，而名稱產生則產生了更平衡的「政治正確」性別分佈，儘管在男性或女性主導的職業中存在顯著差異。整體而言，提示方法對性別分佈的影響大於模型選擇本身，突顯了解決 LLM 中性別偏見的複雜性。研究結果強調了提示在性別對應中的重要性。</paragraph>

##### **A Self-Supervised Model for Multi-modal Stroke Risk Prediction**
2411.09822v1 by Camille Delgrange, Olga Demler, Samia Mora, Bjoern Menze, Ezequiel de la Rosa, Neda Davoudi

Predicting stroke risk is a complex challenge that can be enhanced by
integrating diverse clinically available data modalities. This study introduces
a self-supervised multimodal framework that combines 3D brain imaging, clinical
data, and image-derived features to improve stroke risk prediction prior to
onset. By leveraging large unannotated clinical datasets, the framework
captures complementary and synergistic information across image and tabular
data modalities. Our approach is based on a contrastive learning framework that
couples contrastive language-image pretraining with an image-tabular matching
module, to better align multimodal data representations in a shared latent
space. The model is trained on the UK Biobank, which includes structural brain
MRI and clinical data. We benchmark its performance against state-of-the-art
unimodal and multimodal methods using tabular, image, and image-tabular
combinations under diverse frozen and trainable model settings. The proposed
model outperformed self-supervised tabular (image) methods by 2.6% (2.6%) in
ROC-AUC and by 3.3% (5.6%) in balanced accuracy. Additionally, it showed a 7.6%
increase in balanced accuracy compared to the best multimodal supervised model.
Through interpretable tools, our approach demonstrated better integration of
tabular and image data, providing richer and more aligned embeddings.
Gradient-weighted Class Activation Mapping heatmaps further revealed activated
brain regions commonly associated in the literature with brain aging, stroke
risk, and clinical outcomes. This robust self-supervised multimodal framework
surpasses state-of-the-art methods for stroke risk prediction and offers a
strong foundation for future studies integrating diverse data modalities to
advance clinical predictive modelling.

摘要：<paragraph>預測中風風險是一項複雜的挑戰，可以透過整合多樣化的臨床可用數據模式來加強。本研究介紹了一個自監督多模式架構，結合 3D 大腦影像、臨床數據和影像衍生特徵，以在發作前改善中風風險預測。透過利用大量的未標記臨床數據集，該架構擷取了影像和表格數據模式之間的互補和協同資訊。我們的做法基於對比學習架構，將對比語言影像預訓練與影像表格匹配模組結合，以在共享潛在空間中更好地對齊多模式數據表示。該模型是在英國生物銀行中訓練的，其中包括結構性腦部 MRI 和臨床數據。我們使用表格、影像和影像表格組合，在不同的凍結和可訓練模型設定下，根據最先進的單模式和多模式方法對其效能進行基準測試。所提出的模型在 ROC-AUC 中比自監督表格（影像）方法高出 2.6%（2.6%），在平衡準確度中高出 3.3%（5.6%）。此外，與最佳多模式監督模型相比，它的平衡準確度提高了 7.6%。透過可解釋的工具，我們的做法證明了表格和影像數據的整合性更好，提供了更豐富且更一致的嵌入。梯度加權類別啟用對應熱圖進一步揭示了文獻中通常與腦部老化、中風風險和臨床結果相關的活化腦區。這個強健的自監督多模式架構超越了中風風險預測的最新方法，並為整合不同數據模式以推進臨床預測建模的未來研究提供了堅實的基礎。</paragraph>

##### **WelQrate: Defining the Gold Standard in Small Molecule Drug Discovery Benchmarking**
2411.09820v1 by Yunchao, Liu, Ha Dong, Xin Wang, Rocco Moretti, Yu Wang, Zhaoqian Su, Jiawei Gu, Bobby Bodenheimer, Charles David Weaver, Jens Meiler, Tyler Derr

While deep learning has revolutionized computer-aided drug discovery, the AI
community has predominantly focused on model innovation and placed less
emphasis on establishing best benchmarking practices. We posit that without a
sound model evaluation framework, the AI community's efforts cannot reach their
full potential, thereby slowing the progress and transfer of innovation into
real-world drug discovery. Thus, in this paper, we seek to establish a new gold
standard for small molecule drug discovery benchmarking, WelQrate.
Specifically, our contributions are threefold: WelQrate Dataset Collection - we
introduce a meticulously curated collection of 9 datasets spanning 5
therapeutic target classes. Our hierarchical curation pipelines, designed by
drug discovery experts, go beyond the primary high-throughput screen by
leveraging additional confirmatory and counter screens along with rigorous
domain-driven preprocessing, such as Pan-Assay Interference Compounds (PAINS)
filtering, to ensure the high-quality data in the datasets; WelQrate Evaluation
Framework - we propose a standardized model evaluation framework considering
high-quality datasets, featurization, 3D conformation generation, evaluation
metrics, and data splits, which provides a reliable benchmarking for drug
discovery experts conducting real-world virtual screening; Benchmarking - we
evaluate model performance through various research questions using the
WelQrate dataset collection, exploring the effects of different models, dataset
quality, featurization methods, and data splitting strategies on the results.
In summary, we recommend adopting our proposed WelQrate as the gold standard in
small molecule drug discovery benchmarking. The WelQrate dataset collection,
along with the curation codes, and experimental scripts are all publicly
available at WelQrate.org.

摘要：<paragraph>深度學習雖然徹底改變了電腦輔助藥物發現，但 AI 社群主要專注於模型創新，較少重視建立最佳基準測試實務。我們假設，若沒有健全的模型評估架構，AI 社群的努力將無法發揮其全部潛力，進而減緩創新進程，並將創新轉移到現實世界的藥物發現中。因此，我們在本文中尋求為小分子藥物發現基準測試建立新的金標準 WelQrate。具體來說，我們的貢獻有三方面：WelQrate 資料集收集 - 我們引進一個精心策劃的 9 個資料集集合，涵蓋 5 個治療目標類別。我們的階層式策劃管道由藥物發現專家設計，透過利用其他確認和反向篩選以及嚴格的領域驅動預處理（例如 Pan-Assay Interference Compounds (PAINS) 過濾）超越主要的高通量篩選，以確保資料集中的資料品質；WelQrate 評估架構 - 我們提出一個標準化的模型評估架構，考量高品質資料集、特徵化、3D 構象產生、評估指標和資料分割，這為進行真實世界虛擬篩選的藥物發現專家提供可靠的基準測試；基準測試 - 我們透過使用 WelQrate 資料集收集來評估模型效能，探討不同模型、資料集品質、特徵化方法和資料分割策略對結果的影響。總之，我們建議採用我們提出的 WelQrate 作為小分子藥物發現基準測試的金標準。WelQrate 資料集收集，連同策劃程式碼和實驗腳本，都公開於 WelQrate.org。</paragraph>

##### **Evaluating Loss Landscapes from a Topology Perspective**
2411.09807v1 by Tiankai Xie, Caleb Geniesse, Jiaqing Chen, Yaoqing Yang, Dmitriy Morozov, Michael W. Mahoney, Ross Maciejewski, Gunther H. Weber

Characterizing the loss of a neural network with respect to model parameters,
i.e., the loss landscape, can provide valuable insights into properties of that
model. Various methods for visualizing loss landscapes have been proposed, but
less emphasis has been placed on quantifying and extracting actionable and
reproducible insights from these complex representations. Inspired by powerful
tools from topological data analysis (TDA) for summarizing the structure of
high-dimensional data, here we characterize the underlying shape (or topology)
of loss landscapes, quantifying the topology to reveal new insights about
neural networks. To relate our findings to the machine learning (ML)
literature, we compute simple performance metrics (e.g., accuracy, error), and
we characterize the local structure of loss landscapes using Hessian-based
metrics (e.g., largest eigenvalue, trace, eigenvalue spectral density).
Following this approach, we study established models from image pattern
recognition (e.g., ResNets) and scientific ML (e.g., physics-informed neural
networks), and we show how quantifying the shape of loss landscapes can provide
new insights into model performance and learning dynamics.

摘要：通过模型参数来表征神经网络的损失，即损失景观，可以为该模型的属性提供有价值的见解。已经提出了可视化损失景观的各种方法，但较少强调从这些复杂表示中量化和提取可操作且可重复的见解。受拓扑数据分析 (TDA) 中用于总结高维数据结构的强大工具的启发，我们在此表征损失景观的底层形状（或拓扑），量化拓扑以揭示有关神经网络的新见解。为了将我们的发现与机器学习 (ML) 文献联系起来，我们计算简单的性能指标（例如，准确度、错误），并使用基于 Hessian 的指标（例如，最大特征值、迹、特征值谱密度）来表征损失景观的局部结构。遵循这种方法，我们研究了图像模式识别（例如，ResNets）和科学 ML（例如，物理信息神经网络）中的已建立模型，并展示了量化损失景观的形状如何可以为模型性能和学习动态提供新的见解。

##### **Deep Learning for Fetal Inflammatory Response Diagnosis in the Umbilical Cord**
2411.09767v1 by Marina A. Ayad, Ramin Nateghi, Abhishek Sharma, Lawrence Chillrud, Tilly Seesillapachai, Lee A. D. Cooper, Jeffery A. Goldstein

Inflammation of the umbilical cord can be seen as a result of ascending
intrauterine infection or other inflammatory stimuli. Acute fetal inflammatory
response (FIR) is characterized by infiltration of the umbilical cord by fetal
neutrophils, and can be associated with neonatal sepsis or fetal inflammatory
response syndrome. Recent advances in deep learning in digital pathology have
demonstrated favorable performance across a wide range of clinical tasks, such
as diagnosis and prognosis. In this study we classified FIR from whole slide
images (WSI). We digitized 4100 histological slides of umbilical cord stained
with hematoxylin and eosin(H&E) and extracted placental diagnoses from the
electronic health record. We build models using attention-based whole slide
learning models. We compared strategies between features extracted by a model
(ConvNeXtXLarge) pretrained on non-medical images (ImageNet), and one
pretrained using histopathology images (UNI). We trained multiple iterations of
each model and combined them into an ensemble. The predictions from the
ensemble of models trained using UNI achieved an overall balanced accuracy of
0.836 on the test dataset. In comparison, the ensembled predictions using
ConvNeXtXLarge had a lower balanced accuracy of 0.7209. Heatmaps generated from
top accuracy model appropriately highlighted arteritis in cases of FIR 2. In
FIR 1, the highest performing model assigned high attention to areas of
activated-appearing stroma in Wharton's Jelly. However, other high-performing
models assigned attention to umbilical vessels. We developed models for
diagnosis of FIR from placental histology images, helping reduce interobserver
variability among pathologists. Future work may examine the utility of these
models for identifying infants at risk of systemic inflammatory response or
early onset neonatal sepsis.

摘要：臍帶發炎可視為上行性子宮內感染或其他發炎刺激所致。急性胎兒發炎反應 (FIR) 的特徵是胎兒中性球浸潤臍帶，可能與新生兒敗血症或胎兒發炎反應症候群有關。數位病理學中深度學習的最新進展已證明在廣泛的臨床任務中表現良好，例如診斷和預後。在這項研究中，我們從全切片影像 (WSI) 中分類 FIR。我們將 4100 張用蘇木精和曙紅 (H&E) 染色的臍帶組織切片數位化，並從電子病歷中提取胎盤診斷。我們使用基於注意力的全切片學習模型建立模型。我們比較了非醫療影像 (ImageNet) 預訓練模型 (ConvNeXtXLarge) 和使用組織病理學影像 (UNI) 預訓練模型提取的特徵之間的策略。我們訓練了每個模型的多次迭代，並將它們組合成一個整體。使用 UNI 訓練的模型整體的預測在測試資料集上達到 0.836 的整體平衡準確度。相比之下，使用 ConvNeXtXLarge 的整體預測的平衡準確度較低，為 0.7209。從準確度最高的模型產生的熱圖適當地突出了 FIR 2 病例中的動脈炎。在 FIR 1 中，表現最好的模型將高度關注分配給沃頓氏膠中的活化外觀基質區域。然而，其他表現良好的模型將注意力分配給臍帶血管。我們開發了從胎盤組織學影像診斷 FIR 的模型，有助於減少病理學家之間的觀察者間變異性。未來的研究可能會探討這些模型在識別有全身性發炎反應風險或早期發作新生兒敗血症的嬰兒方面的效用。

##### **Evaluating the Predictive Capacity of ChatGPT for Academic Peer Review Outcomes Across Multiple Platforms**
2411.09763v1 by Mike Thelwall, Abdullah Yaghi

While previous studies have demonstrated that Large Language Models (LLMs)
can predict peer review outcomes to some extent, this paper builds on that by
introducing two new contexts and employing a more robust method - averaging
multiple ChatGPT scores. The findings that averaging 30 ChatGPT predictions,
based on reviewer guidelines and using only the submitted titles and abstracts,
failed to predict peer review outcomes for F1000Research (Spearman's rho=0.00).
However, it produced mostly weak positive correlations with the quality
dimensions of SciPost Physics (rho=0.25 for validity, rho=0.25 for originality,
rho=0.20 for significance, and rho = 0.08 for clarity) and a moderate positive
correlation for papers from the International Conference on Learning
Representations (ICLR) (rho=0.38). Including the full text of articles
significantly increased the correlation for ICLR (rho=0.46) and slightly
improved it for F1000Research (rho=0.09), while it had variable effects on the
four quality dimension correlations for SciPost LaTeX files. The use of
chain-of-thought system prompts slightly increased the correlation for
F1000Research (rho=0.10), marginally reduced it for ICLR (rho=0.37), and
further decreased it for SciPost Physics (rho=0.16 for validity, rho=0.18 for
originality, rho=0.18 for significance, and rho=0.05 for clarity). Overall, the
results suggest that in some contexts, ChatGPT can produce weak pre-publication
quality assessments. However, the effectiveness of these assessments and the
optimal strategies for employing them vary considerably across different
platforms, journals, and conferences. Additionally, the most suitable inputs
for ChatGPT appear to differ depending on the platform.

摘要：<paragraph>儘管先前的研究已證實大型語言模型 (LLM)
在某種程度上可以預測同行評審結果，但本文建立在該基礎上，
引入了兩個新的脈絡，並採用更強健的方法 - 平均
多個 ChatGPT 分數。研究結果顯示，平均 30 個 ChatGPT 預測，
根據審查員指南，僅使用提交的標題和摘要，
無法預測 F1000Research 的同行評審結果（Spearman's rho=0.00）。
然而，它產生了與 SciPost Physics 的品質向度呈弱正相關（rho=0.25 表示有效性，rho=0.25 表示獨創性，
rho=0.20 表示重要性，rho = 0.08 表示清晰度）以及與國際學習表徵會議（ICLR）論文的中等正相關
（rho=0.38）。包含文章的全文顯著增加了 ICLR 的相關性（rho=0.46），並略微
改善了 F1000Research（rho=0.09），而它對 SciPost LaTeX 檔案的四個品質向度相關性有不同的影響。使用
思考鏈系統提示略微增加了 F1000Research 的相關性（rho=0.10），略微降低了 ICLR 的相關性（rho=0.37），並
進一步降低了 SciPost Physics 的相關性（rho=0.16 表示有效性，rho=0.18 表示獨創性，rho=0.18 表示重要性，rho=0.05 表示清晰度）。總的來說，
結果表明，在某些情況下，ChatGPT 可以產生弱的出版前品質評估。然而，這些評估的有效性以及採用它們的最佳策略在不同的
平台、期刊和會議之間有很大差異。此外，ChatGPT 最合適的輸入似乎會根據平台而有所不同。</paragraph>

##### **On the Surprising Effectiveness of Attention Transfer for Vision Transformers**
2411.09702v1 by Alexander C. Li, Yuandong Tian, Beidi Chen, Deepak Pathak, Xinlei Chen

Conventional wisdom suggests that pre-training Vision Transformers (ViT)
improves downstream performance by learning useful representations. Is this
actually true? We investigate this question and find that the features and
representations learned during pre-training are not essential. Surprisingly,
using only the attention patterns from pre-training (i.e., guiding how
information flows between tokens) is sufficient for models to learn high
quality features from scratch and achieve comparable downstream performance. We
show this by introducing a simple method called attention transfer, where only
the attention patterns from a pre-trained teacher ViT are transferred to a
student, either by copying or distilling the attention maps. Since attention
transfer lets the student learn its own features, ensembling it with a
fine-tuned teacher also further improves accuracy on ImageNet. We
systematically study various aspects of our findings on the sufficiency of
attention maps, including distribution shift settings where they underperform
fine-tuning. We hope our exploration provides a better understanding of what
pre-training accomplishes and leads to a useful alternative to the standard
practice of fine-tuning

摘要：傳統觀念認為預訓練視覺Transformer（ViT）
透過學習有用的表徵來提升下游效能。這
是否屬實？我們探討這個問題，發現預訓練期間學習到的特徵和
表徵並非必要的。令人驚訝的是，僅使用預訓練的注意力模式（也
就是引導資訊如何在符號之間流動）就足以讓模型從頭學習高
品質的特徵，並達成相近的下游效能。我們透過引入一種稱為注
意力轉移的簡單方法來證明這一點，其中僅將預訓練教師 ViT 的
注意力模式轉移給學生，方法是複製或萃取注意力圖。由於注
意力轉移讓學生學習自己的特徵，因此將其與微調教師結合也
進一步提升了 ImageNet 的準確度。我們系統性地研究了我們在
注意力圖的充分性方面的發現的各個面向，包括它們表現不如微
調的分配轉移設定。我們希望我們的探索能提供對預訓練達成
什麼目標的更深入理解，並提供一種有用的替代方案來取代微調
的標準做法

##### **A Bayesian Optimization Approach to Machine Translation Reranking**
2411.09694v1 by Julius Cheng, Maike Züfle, Vilém Zouhar, Andreas Vlachos

Reranking a list of candidates from a machine translation system with an
external scoring model and returning the highest-scoring candidate remains a
simple and effective method for improving the overall output quality.
Translation scoring models continue to grow in size, with the best models being
comparable to generation models. Thus, reranking can add substantial
computational cost to the translation pipeline. In this work, we pose reranking
as a Bayesian optimization (BayesOpt) problem. By strategically selecting
candidates to score based on a balance of exploration and exploitation, we show
that it is possible to find top-scoring candidates when scoring only a fraction
of the candidate list. For instance, our method achieves the same CometKiwi
score using only 70 scoring evaluations compared a baseline system using 180.
We present a multi-fidelity setting for BayesOpt, where the candidates are
first scored with a cheaper but noisier proxy scoring model, which further
improves the cost-performance tradeoff when using smaller but well-trained
distilled proxy scorers.

摘要：利用外部評分模型重新排列機器翻譯系統的候選清單，並回傳評分最高的候選，這仍然是改善整體輸出品質的簡單且有效的方法。
翻譯評分模型持續擴增，其中最佳的模型與生成模型相當。因此，重新排列會為翻譯流程增加大量的運算成本。在這項工作中，我們將重新排列視為貝氏最佳化 (BayesOpt) 問題。透過策略性地選擇候選，在探索與開發取得平衡的基礎上進行評分，我們證明了在僅評分候選清單的一部分時，有可能找到評分最高的候選。例如，我們的模型僅使用 70 次評分評估就達到相同的 CometKiwi 分數，而基線系統則使用 180 次。我們提出適用於 BayesOpt 的多重保真度設定，其中候選首先使用較便宜但較多雜訊的代理評分模型進行評分，這進一步改善了使用較小但訓練良好的蒸餾代理評分器的成本效益權衡。

##### **LLM Hallucination Reasoning with Zero-shot Knowledge Test**
2411.09689v1 by Seongmin Lee, Hsiang Hsu, Chun-Fu Chen

LLM hallucination, where LLMs occasionally generate unfaithful text, poses
significant challenges for their practical applications. Most existing
detection methods rely on external knowledge, LLM fine-tuning, or
hallucination-labeled datasets, and they do not distinguish between different
types of hallucinations, which are crucial for improving detection performance.
We introduce a new task, Hallucination Reasoning, which classifies
LLM-generated text into one of three categories: aligned, misaligned, and
fabricated. Our novel zero-shot method assesses whether LLM has enough
knowledge about a given prompt and text. Our experiments conducted on new
datasets demonstrate the effectiveness of our method in hallucination reasoning
and underscore its importance for enhancing detection performance.

摘要：大型语言模型 (LLM) 的幻觉，也就是 LLM 偶尔会生成不忠实文本的情况，对其实际应用构成了重大挑战。大多数现有的检测方法依赖于外部知识、LLM 微调或幻觉标记数据集，而且它们不区分不同类型的幻觉，而这对于提高检测性能至关重要。我们引入了一项新任务，即幻觉推理，它将 LLM 生成的文本归类为以下三类之一：对齐、错位和虚构。我们新颖的零样本方法评估了 LLM 是否对给定的提示和文本有足够的了解。我们对新数据集进行的实验证明了我们的方法在幻觉推理中的有效性，并强调了其对提高检测性能的重要性。

##### **Squeezed Attention: Accelerating Long Context Length LLM Inference**
2411.09688v1 by Coleman Hooper, Sehoon Kim, Hiva Mohammadzadeh, Monishwaran Maheswaran, June Paik, Michael W. Mahoney, Kurt Keutzer, Amir Gholami

Emerging Large Language Model (LLM) applications require long input prompts
to perform complex downstream tasks like document analysis and code generation.
For these long context length applications, the length of the input prompt
poses a significant challenge in terms of inference efficiency since the
inference costs increase linearly with sequence length. However, for many of
these applications, much of the context in the prompt is fixed across different
user inputs, thereby providing the opportunity to perform offline optimizations
to process user inputs quickly, as they are received. In this work, we propose
Squeezed Attention as a mechanism to accelerate LLM applications where a large
portion of the input prompt is fixed. We first leverage K-means clustering
offline to group the keys for the fixed context based on semantic similarity
and represent each cluster with a single centroid value. During inference, we
compare query tokens from the user input with the centroids to predict which of
the keys from the fixed context are semantically relevant and need to be loaded
during inference. We then compute exact attention using only these important
keys from the fixed context, thereby reducing bandwidth and computational
costs. We also extend our method to use a hierarchical centroid lookup to
identify important keys, which can reduce the complexity of attention from
linear to logarithmic with respect to the context length. We implement
optimized Triton kernels for centroid comparison and sparse FlashAttention with
important keys, achieving more than 4x speedups during both the prefill and
generation phases for long-context inference. Furthermore, we have extensively
evaluated our method on various long-context benchmarks including LongBench,
where it achieves a 3x reduction in KV cache budget without accuracy loss and
up to an 8x reduction with <0.5 point accuracy gap for various models.

摘要：新興的大語言模型 (LLM) 應用程式需要長的輸入提示，才能執行複雜的下游任務，例如文件分析和程式碼產生。對於這些長脈絡長度的應用程式來說，輸入提示的長度在推論效率方面構成重大挑戰，因為推論成本會隨著序列長度線性增加。然而，對於這些應用程式中的許多應用程式，提示中的大部分脈絡在不同的使用者輸入中都是固定的，因此提供了執行離線最佳化以快速處理使用者輸入的機會，因為它們已被接收。在這項工作中，我們建議使用 Squeezed Attention 作為一種機制，以加速 LLM 應用程式，其中輸入提示的大部分是固定的。我們首先利用 K 平均群集在離線模式下根據語義相似性對固定脈絡的鍵進行分組，並使用單一質心值表示每個群集。在推論期間，我們將使用者輸入中的查詢代幣與質心進行比較，以預測固定脈絡中的哪些鍵在語義上相關，並且需要在推論期間載入。然後，我們僅使用固定脈絡中的這些重要鍵計算確切的注意力，從而減少頻寬和運算成本。我們還將方法擴充套件為使用階層質心查詢來識別重要鍵，這可以將注意力的複雜度從線性降低到對數，相對於脈絡長度而言。我們實作最佳化的 Triton 核心，用於質心比較和具有重要鍵的稀疏 FlashAttention，在長脈絡推論的預填和產生階段實現超過 4 倍的加速。此外，我們已針對各種長脈絡基準廣泛評估我們的模型，包括 LongBench，其中在不損失準確性的情況下實現了 KV 快取預算減少 3 倍，並且對於各種模型，減少了多達 8 倍，準確度差距小於 0.5 點。

