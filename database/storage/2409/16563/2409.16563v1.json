{"2409.16563": {"publish_time": "2024-09-25", "title": "Enhancing disease detection in radiology reports through fine-tuning lightweight LLM on weak labels", "paper_summary": "Despite significant progress in applying large language models (LLMs) to the\nmedical domain, several limitations still prevent them from practical\napplications. Among these are the constraints on model size and the lack of\ncohort-specific labeled datasets. In this work, we investigated the potential\nof improving a lightweight LLM, such as Llama 3.1-8B, through fine-tuning with\ndatasets using synthetic labels. Two tasks are jointly trained by combining\ntheir respective instruction datasets. When the quality of the task-specific\nsynthetic labels is relatively high (e.g., generated by GPT4- o), Llama 3.1-8B\nachieves satisfactory performance on the open-ended disease detection task,\nwith a micro F1 score of 0.91. Conversely, when the quality of the\ntask-relevant synthetic labels is relatively low (e.g., from the MIMIC-CXR\ndataset), fine-tuned Llama 3.1-8B is able to surpass its noisy teacher labels\n(micro F1 score of 0.67 v.s. 0.63) when calibrated against curated labels,\nindicating the strong inherent underlying capability of the model. These\nfindings demonstrate the potential of fine-tuning LLMs with synthetic labels,\noffering a promising direction for future research on LLM specialization in the\nmedical domain.", "paper_summary_zh": "\u5118\u7ba1\u5c07\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u61c9\u7528\u65bc\u91ab\u7642\u9818\u57df\u5df2\u53d6\u5f97\u986f\u8457\u9032\u5c55\uff0c\u4f46\u4ecd\u6709\u82e5\u5e72\u9650\u5236\u963b\u7919\u5b83\u5011\u5be6\u969b\u61c9\u7528\u3002\u5176\u4e2d\u5305\u62ec\u6a21\u578b\u5927\u5c0f\u7684\u9650\u5236\u548c\u7f3a\u4e4f\u7279\u5b9a\u65bc\u7fa4\u9ad4\u7684\u6a19\u7c64\u8cc7\u6599\u96c6\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u900f\u904e\u4f7f\u7528\u5408\u6210\u6a19\u7c64\u5fae\u8abf\u8cc7\u6599\u96c6\u4f86\u6539\u5584\u8f15\u91cf\u7d1a LLM\uff08\u4f8b\u5982 Llama 3.1-8B\uff09\u7684\u6f5b\u529b\u3002\u900f\u904e\u7d50\u5408\u5404\u81ea\u7684\u6307\u4ee4\u8cc7\u6599\u96c6\uff0c\u5171\u540c\u8a13\u7df4\u5169\u500b\u4efb\u52d9\u3002\u7576\u7279\u5b9a\u65bc\u4efb\u52d9\u7684\u5408\u6210\u6a19\u7c64\u54c1\u8cea\u76f8\u5c0d\u8f03\u9ad8\u6642\uff08\u4f8b\u5982\uff0c\u7531 GPT4-o \u7522\u751f\uff09\uff0cLlama 3.1-8B \u5728\u958b\u653e\u5f0f\u75be\u75c5\u5075\u6e2c\u4efb\u52d9\u4e2d\u53d6\u5f97\u4ee4\u4eba\u6eff\u610f\u7684\u8868\u73fe\uff0c\u5fae\u89c0 F1 \u5206\u6578\u70ba 0.91\u3002\u76f8\u53cd\u5730\uff0c\u7576\u8207\u4efb\u52d9\u76f8\u95dc\u7684\u5408\u6210\u6a19\u7c64\u54c1\u8cea\u76f8\u5c0d\u8f03\u4f4e\u6642\uff08\u4f8b\u5982\uff0c\u4f86\u81ea MIMIC-CXR \u8cc7\u6599\u96c6\uff09\uff0c\u5fae\u8abf\u5f8c\u7684 Llama 3.1-8B \u80fd\u5920\u8d85\u8d8a\u5176\u6709\u96dc\u8a0a\u7684\u6559\u5e2b\u6a19\u7c64\uff08\u5fae\u89c0 F1 \u5206\u6578\u70ba 0.67\uff0c\u76f8\u8f03\u65bc 0.63\uff09\uff0c\u4e26\u6839\u64da\u7d93\u904e\u6574\u7406\u7684\u6a19\u7c64\u9032\u884c\u6821\u6e96\uff0c\u9019\u8868\u793a\u8a72\u6a21\u578b\u5177\u6709\u5f37\u5927\u7684\u5167\u5728\u6f5b\u5728\u80fd\u529b\u3002\u9019\u4e9b\u767c\u73fe\u8b49\u660e\u4e86\u4f7f\u7528\u5408\u6210\u6a19\u7c64\u5fae\u8abf LLM \u7684\u6f5b\u529b\uff0c\u70ba\u672a\u4f86\u91dd\u5c0d LLM \u5728\u91ab\u7642\u9818\u57df\u7684\u5c08\u9580\u5316\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002", "author": "Yishu Wei et.al.", "authors": "Yishu Wei, Xindi Wang, Hanley Ong, Yiliang Zhou, Adam Flanders, George Shih, Yifan Peng", "id": "2409.16563v1", "paper_url": "http://arxiv.org/abs/2409.16563v1", "repo": "null"}}