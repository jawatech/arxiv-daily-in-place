{"2412.20962": {"publish_time": "2024-12-30", "title": "Conservation-informed Graph Learning for Spatiotemporal Dynamics Prediction", "paper_summary": "Data-centric methods have shown great potential in understanding and\npredicting spatiotemporal dynamics, enabling better design and control of the\nobject system. However, pure deep learning models often lack interpretability,\nfail to obey intrinsic physics, and struggle to cope with the various domains.\nWhile geometry-based methods, e.g., graph neural networks (GNNs), have been\nproposed to further tackle these challenges, they still need to find the\nimplicit physical laws from large datasets and rely excessively on rich labeled\ndata. In this paper, we herein introduce the conservation-informed GNN (CiGNN),\nan end-to-end explainable learning framework, to learn spatiotemporal dynamics\nbased on limited training data. The network is designed to conform to the\ngeneral conservation law via symmetry, where conservative and non-conservative\ninformation passes over a multiscale space enhanced by a latent temporal\nmarching strategy. The efficacy of our model has been verified in various\nspatiotemporal systems based on synthetic and real-world datasets, showing\nsuperiority over baseline models. Results demonstrate that CiGNN exhibits\nremarkable accuracy and generalization ability, and is readily applicable to\nlearning for prediction of various spatiotemporal dynamics in a spatial domain\nwith complex geometry.", "paper_summary_zh": "<paragraph>\u8cc7\u6599\u70ba\u4e2d\u5fc3\u7684\u5404\u7a2e\u65b9\u6cd5\u5728\u7406\u89e3\u548c\u9810\u6e2c\u6642\u7a7a\u52d5\u529b\u5b78\u65b9\u9762\u5c55\u73fe\u6975\u4f73\u7684\u6f5b\u529b\uff0c\u80fd\u66f4\u6709\u6548\u5730\u8a2d\u8a08\u8207\u63a7\u5236\u7269\u4ef6\u7cfb\u7d71\u3002\u7136\u800c\uff0c\u7d14\u7cb9\u7684\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\u5f80\u5f80\u7f3a\u4e4f\u53ef\u89e3\u91cb\u6027\uff0c\u7121\u6cd5\u9075\u5faa\u5167\u5728\u7269\u7406\u5b9a\u5f8b\uff0c\u4e14\u96e3\u4ee5\u61c9\u5c0d\u5404\u7a2e\u9818\u57df\u3002\u96d6\u7136\u5e7e\u4f55\u57fa\u790e\u65b9\u6cd5\uff08\u4f8b\u5982\u5716\u5f62\u795e\u7d93\u7db2\u8def (GNN)\uff09\u5df2\u88ab\u63d0\u51fa\u9032\u4e00\u6b65\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u4f46\u5b83\u5011\u4ecd\u9700\u8981\u5f9e\u5927\u578b\u8cc7\u6599\u96c6\u4e2d\u627e\u51fa\u96b1\u542b\u7684\u7269\u7406\u5b9a\u5f8b\uff0c\u4e26\u904e\u5ea6\u4f9d\u8cf4\u8c50\u5bcc\u7684\u6a19\u7c64\u8cc7\u6599\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5728\u6b64\u4ecb\u7d39\u4e86\u53d7\u5b88\u6046\u5b9a\u5f8b\u555f\u767c\u7684 GNN (CiGNN)\uff0c\u9019\u662f\u4e00\u500b\u7aef\u5230\u7aef\u7684\u53ef\u89e3\u91cb\u5b78\u7fd2\u67b6\u69cb\uff0c\u7528\u65bc\u6839\u64da\u6709\u9650\u7684\u8a13\u7df4\u8cc7\u6599\u5b78\u7fd2\u6642\u7a7a\u52d5\u529b\u5b78\u3002\u8a72\u7db2\u8def\u88ab\u8a2d\u8a08\u70ba\u900f\u904e\u5c0d\u7a31\u6027\u7b26\u5408\u4e00\u822c\u5b88\u6046\u5b9a\u5f8b\uff0c\u5176\u4e2d\u4fdd\u5b88\u548c\u975e\u4fdd\u5b88\u8cc7\u8a0a\u6703\u900f\u904e\u4e00\u500b\u7531\u6f5b\u5728\u6642\u9593\u884c\u9032\u7b56\u7565\u589e\u5f37\u7684\u591a\u5c3a\u5ea6\u7a7a\u9593\u50b3\u905e\u3002\u6211\u5011\u6a21\u578b\u7684\u6548\u529b\u5df2\u5728\u5404\u7a2e\u57fa\u65bc\u5408\u6210\u548c\u771f\u5be6\u4e16\u754c\u8cc7\u6599\u96c6\u7684\u6642\u7a7a\u7cfb\u7d71\u4e2d\u5f97\u5230\u9a57\u8b49\uff0c\u986f\u793a\u51fa\u512a\u65bc\u57fa\u7dda\u6a21\u578b\u7684\u512a\u8d8a\u6027\u3002\u7d50\u679c\u8b49\u660e\uff0cCiGNN \u5c55\u73fe\u51fa\u5353\u8d8a\u7684\u6e96\u78ba\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4e14\u6613\u65bc\u61c9\u7528\u65bc\u5b78\u7fd2\uff0c\u4ee5\u9810\u6e2c\u5177\u6709\u8907\u96dc\u5e7e\u4f55\u5f62\u72c0\u7684\u7a7a\u9593\u57df\u4e2d\u7684\u5404\u7a2e\u6642\u7a7a\u52d5\u529b\u5b78\u3002</paragraph>", "author": "Yuan Mi et.al.", "authors": "Yuan Mi, Pu Ren, Hongteng Xu, Hongsheng Liu, Zidong Wang, Yike Guo, Ji-Rong Wen, Hao Sun, Yang Liu", "id": "2412.20962v1", "paper_url": "http://arxiv.org/abs/2412.20962v1", "repo": "null"}}