{"2407.13218": {"publish_time": "2024-07-18", "title": "LiNR: Model Based Neural Retrieval on GPUs at LinkedIn", "paper_summary": "This paper introduces LiNR, LinkedIn's large-scale, GPU-based retrieval\nsystem. LiNR supports a billion-sized index on GPU models. We discuss our\nexperiences and challenges in creating scalable, differentiable search indexes\nusing TensorFlow and PyTorch at production scale. In LiNR, both items and model\nweights are integrated into the model binary. Viewing index construction as a\nform of model training, we describe scaling our system for large indexes,\nincorporating full scans and efficient filtering. A key focus is on enabling\nattribute-based pre-filtering for exhaustive GPU searches, addressing the\ncommon challenge of post-filtering in KNN searches that often reduces system\nquality. We further provide multi-embedding retrieval algorithms and strategies\nfor tackling cold start issues in retrieval. Our advancements in supporting\nlarger indexes through quantization are also discussed. We believe LiNR\nrepresents one of the industry's first Live-updated model-based retrieval\nindexes. Applied to out-of-network post recommendations on LinkedIn Feed, LiNR\nhas contributed to a 3% relative increase in professional daily active users.\nWe envisage LiNR as a step towards integrating retrieval and ranking into a\nsingle GPU model, simplifying complex infrastructures and enabling end-to-end\noptimization of the entire differentiable infrastructure through gradient\ndescent.", "paper_summary_zh": "\u672c\u6587\u4ecb\u7ecd\u4e86 LinkedIn \u7684\u5927\u89c4\u6a21\u57fa\u4e8e GPU \u7684\u68c0\u7d22\u7cfb\u7edf LiNR\u3002LiNR \u5728 GPU \u6a21\u578b\u4e0a\u652f\u6301\u5341\u4ebf\u7ea7\u7d22\u5f15\u3002\u6211\u4eec\u8ba8\u8bba\u4e86\u4f7f\u7528 TensorFlow \u548c PyTorch \u5728\u751f\u4ea7\u89c4\u6a21\u4e0a\u521b\u5efa\u53ef\u6269\u5c55\u3001\u53ef\u5fae\u5206\u641c\u7d22\u7d22\u5f15\u7684\u7ecf\u9a8c\u548c\u6311\u6218\u3002\u5728 LiNR \u4e2d\uff0c\u9879\u76ee\u548c\u6a21\u578b\u6743\u91cd\u90fd\u96c6\u6210\u5230\u4e86\u6a21\u578b\u4e8c\u8fdb\u5236\u6587\u4ef6\u4e2d\u3002\u5c06\u7d22\u5f15\u6784\u5efa\u89c6\u4e3a\u4e00\u79cd\u6a21\u578b\u8bad\u7ec3\u5f62\u5f0f\uff0c\u6211\u4eec\u63cf\u8ff0\u4e86\u9488\u5bf9\u5927\u578b\u7d22\u5f15\u6269\u5c55\u6211\u4eec\u7684\u7cfb\u7edf\uff0c\u7ed3\u5408\u4e86\u5168\u626b\u63cf\u548c\u9ad8\u6548\u8fc7\u6ee4\u3002\u4e00\u4e2a\u91cd\u70b9\u662f\u9488\u5bf9\u7a77\u4e3e GPU \u641c\u7d22\u542f\u7528\u57fa\u4e8e\u5c5e\u6027\u7684\u9884\u8fc7\u6ee4\uff0c\u89e3\u51b3\u4e86 KNN \u641c\u7d22\u4e2d\u5e38\u89c1\u7684\u540e\u8fc7\u6ee4\u6311\u6218\uff0c\u800c\u540e\u8fc7\u6ee4\u901a\u5e38\u4f1a\u964d\u4f4e\u7cfb\u7edf\u8d28\u91cf\u3002\u6211\u4eec\u8fdb\u4e00\u6b65\u63d0\u4f9b\u4e86\u591a\u5d4c\u5165\u68c0\u7d22\u7b97\u6cd5\u548c\u7b56\u7565\uff0c\u4ee5\u89e3\u51b3\u68c0\u7d22\u4e2d\u7684\u51b7\u542f\u52a8\u95ee\u9898\u3002\u6211\u4eec\u8fd8\u8ba8\u8bba\u4e86\u901a\u8fc7\u91cf\u5316\u652f\u6301\u66f4\u5927\u7d22\u5f15\u7684\u8fdb\u5c55\u3002\u6211\u4eec\u76f8\u4fe1 LiNR \u4ee3\u8868\u4e86\u4e1a\u754c\u9996\u6279\u57fa\u4e8e\u5b9e\u65f6\u66f4\u65b0\u6a21\u578b\u7684\u68c0\u7d22\u7d22\u5f15\u4e4b\u4e00\u3002\u5e94\u7528\u4e8e LinkedIn Feed \u4e0a\u7684\u7f51\u7edc\u5916\u5e16\u5b50\u63a8\u8350\uff0cLiNR \u5df2\u4e3a\u4e13\u4e1a\u65e5\u6d3b\u8dc3\u7528\u6237\u589e\u52a0\u4e86 3% \u7684\u76f8\u5bf9\u589e\u957f\u3002\u6211\u4eec\u8bbe\u60f3 LiNR \u662f\u5c06\u68c0\u7d22\u548c\u6392\u540d\u96c6\u6210\u5230\u5355\u4e00 GPU \u6a21\u578b\u4e2d\u7684\u4e00\u6b65\uff0c\u7b80\u5316\u590d\u6742\u7684\u67b6\u6784\u5e76\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u5b9e\u73b0\u6574\u4e2a\u53ef\u5fae\u5206\u67b6\u6784\u7684\u7aef\u5230\u7aef\u4f18\u5316\u3002", "author": "Fedor Borisyuk et.al.", "authors": "Fedor Borisyuk, Qingquan Song, Mingzhou Zhou, Ganesh Parameswaran, Madhu Arun, Siva Popuri, Tugrul Bingol, Zhuotao Pei, Kuang-Hsuan Lee, Lu Zheng, Qizhan Shao, Ali Naqvi, Sen Zhou, Aman Gupta", "id": "2407.13218v1", "paper_url": "http://arxiv.org/abs/2407.13218v1", "repo": "null"}}