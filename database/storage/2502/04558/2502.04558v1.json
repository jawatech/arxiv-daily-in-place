{"2502.04558": {"publish_time": "2025-02-06", "title": "Probing a Vision-Language-Action Model for Symbolic States and Integration into a Cognitive Architecture", "paper_summary": "Vision-language-action (VLA) models hold promise as generalist robotics\nsolutions by translating visual and linguistic inputs into robot actions, yet\nthey lack reliability due to their black-box nature and sensitivity to\nenvironmental changes. In contrast, cognitive architectures (CA) excel in\nsymbolic reasoning and state monitoring but are constrained by rigid predefined\nexecution. This work bridges these approaches by probing OpenVLA's hidden\nlayers to uncover symbolic representations of object properties, relations, and\naction states, enabling integration with a CA for enhanced interpretability and\nrobustness. Through experiments on LIBERO-spatial pick-and-place tasks, we\nanalyze the encoding of symbolic states across different layers of OpenVLA's\nLlama backbone. Our probing results show consistently high accuracies (> 0.90)\nfor both object and action states across most layers, though contrary to our\nhypotheses, we did not observe the expected pattern of object states being\nencoded earlier than action states. We demonstrate an integrated DIARC-OpenVLA\nsystem that leverages these symbolic representations for real-time state\nmonitoring, laying the foundation for more interpretable and reliable robotic\nmanipulation.", "paper_summary_zh": "\u8996\u89ba\u8a9e\u8a00\u52d5\u4f5c (VLA) \u6a21\u578b\u627f\u8afe\u6210\u70ba\u901a\u7528\u6a5f\u5668\u4eba\u89e3\u6c7a\u65b9\u6848\uff0c\u900f\u904e\u5c07\u8996\u89ba\u548c\u8a9e\u8a00\u8f38\u5165\u8f49\u63db\u70ba\u6a5f\u5668\u4eba\u52d5\u4f5c\uff0c\u4f46\u7531\u65bc\u5176\u9ed1\u76d2\u6027\u8cea\u548c\u5c0d\u74b0\u5883\u8b8a\u5316\u7684\u654f\u611f\u6027\uff0c\u5b83\u5011\u7f3a\u4e4f\u53ef\u9760\u6027\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u8a8d\u77e5\u67b6\u69cb (CA) \u5728\u7b26\u865f\u63a8\u7406\u548c\u72c0\u614b\u76e3\u63a7\u65b9\u9762\u8868\u73fe\u51fa\u8272\uff0c\u4f46\u53d7\u5230\u56b4\u683c\u9810\u5b9a\u7fa9\u57f7\u884c\u7684\u7d04\u675f\u3002\u9019\u9805\u5de5\u4f5c\u900f\u904e\u63a2\u6e2c OpenVLA \u7684\u96b1\u85cf\u5c64\u4f86\u6a4b\u63a5\u9019\u4e9b\u65b9\u6cd5\uff0c\u4ee5\u63ed\u793a\u7269\u4ef6\u5c6c\u6027\u3001\u95dc\u4fc2\u548c\u52d5\u4f5c\u72c0\u614b\u7684\u7b26\u865f\u8868\u793a\uff0c\u5f9e\u800c\u80fd\u5920\u8207 CA \u6574\u5408\uff0c\u4ee5\u589e\u5f37\u53ef\u89e3\u91cb\u6027\u548c\u7a69\u5065\u6027\u3002\u900f\u904e\u5728 LIBERO \u7a7a\u9593\u62fe\u653e\u4efb\u52d9\u4e2d\u9032\u884c\u5be6\u9a57\uff0c\u6211\u5011\u5206\u6790\u4e86 OpenVLA \u7684 Llama \u4e3b\u5e79\u4e0d\u540c\u5c64\u4e2d\u7684\u7b26\u865f\u72c0\u614b\u7de8\u78bc\u3002\u6211\u5011\u7684\u63a2\u6e2c\u7d50\u679c\u986f\u793a\uff0c\u5c0d\u65bc\u5927\u591a\u6578\u5c64\u4e2d\u7684\u7269\u4ef6\u548c\u52d5\u4f5c\u72c0\u614b\uff0c\u6e96\u78ba\u7387\u6301\u7e8c\u5f88\u9ad8 (> 0.90)\uff0c\u5118\u7ba1\u8207\u6211\u5011\u7684\u5047\u8a2d\u76f8\u53cd\uff0c\u6211\u5011\u6c92\u6709\u89c0\u5bdf\u5230\u9810\u671f\u7684\u7269\u4ef6\u72c0\u614b\u6bd4\u52d5\u4f5c\u72c0\u614b\u66f4\u65e9\u7de8\u78bc\u7684\u6a21\u5f0f\u3002\u6211\u5011\u5c55\u793a\u4e86\u4e00\u500b\u6574\u5408\u7684 DIARC-OpenVLA \u7cfb\u7d71\uff0c\u8a72\u7cfb\u7d71\u5229\u7528\u9019\u4e9b\u7b26\u865f\u8868\u793a\u9032\u884c\u5373\u6642\u72c0\u614b\u76e3\u63a7\uff0c\u70ba\u66f4\u5177\u53ef\u89e3\u91cb\u6027\u548c\u53ef\u9760\u6027\u7684\u6a5f\u5668\u4eba\u64cd\u4f5c\u5960\u5b9a\u57fa\u790e\u3002", "author": "Hong Lu et.al.", "authors": "Hong Lu, Hengxu Li, Prithviraj Singh Shahani, Stephanie Herbers, Matthias Scheutz", "id": "2502.04558v1", "paper_url": "http://arxiv.org/abs/2502.04558v1", "repo": "null"}}