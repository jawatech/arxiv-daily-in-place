{"2406.19931": {"publish_time": "2024-06-28", "title": "Decoupling General and Personalized Knowledge in Federated Learning via Additive and Low-Rank Decomposition", "paper_summary": "To address data heterogeneity, the key strategy of Personalized Federated\nLearning (PFL) is to decouple general knowledge (shared among clients) and\nclient-specific knowledge, as the latter can have a negative impact on\ncollaboration if not removed. Existing PFL methods primarily adopt a parameter\npartitioning approach, where the parameters of a model are designated as one of\ntwo types: parameters shared with other clients to extract general knowledge\nand parameters retained locally to learn client-specific knowledge. However, as\nthese two types of parameters are put together like a jigsaw puzzle into a\nsingle model during the training process, each parameter may simultaneously\nabsorb both general and client-specific knowledge, thus struggling to separate\nthe two types of knowledge effectively. In this paper, we introduce FedDecomp,\na simple but effective PFL paradigm that employs parameter additive\ndecomposition to address this issue. Instead of assigning each parameter of a\nmodel as either a shared or personalized one, FedDecomp decomposes each\nparameter into the sum of two parameters: a shared one and a personalized one,\nthus achieving a more thorough decoupling of shared and personalized knowledge\ncompared to the parameter partitioning method. In addition, as we find that\nretaining local knowledge of specific clients requires much lower model\ncapacity compared with general knowledge across all clients, we let the matrix\ncontaining personalized parameters be low rank during the training process.\nMoreover, a new alternating training strategy is proposed to further improve\nthe performance. Experimental results across multiple datasets and varying\ndegrees of data heterogeneity demonstrate that FedDecomp outperforms\nstate-of-the-art methods up to 4.9\\%.", "paper_summary_zh": "<paragraph>\u70ba\u4e86\u8655\u7406\u8cc7\u6599\u7570\u8cea\u6027\uff0c\u500b\u4eba\u5316\u806f\u90a6\u5b78\u7fd2 (PFL) \u7684\u95dc\u9375\u7b56\u7565\u662f\u5c07\u4e00\u822c\u77e5\u8b58 (\u5728\u5ba2\u6236\u7aef\u4e4b\u9593\u5171\u4eab) \u548c\u5ba2\u6236\u7aef\u7279\u5b9a\u7684\u77e5\u8b58\u5206\u958b\uff0c\u56e0\u70ba\u5f8c\u8005\u5982\u679c\u6c92\u6709\u79fb\u9664\uff0c\u53ef\u80fd\u6703\u5c0d\u5354\u4f5c\u7522\u751f\u8ca0\u9762\u5f71\u97ff\u3002\u73fe\u6709\u7684 PFL \u65b9\u6cd5\u4e3b\u8981\u63a1\u7528\u53c3\u6578\u5206\u5272\u65b9\u6cd5\uff0c\u5176\u4e2d\u6a21\u578b\u7684\u53c3\u6578\u88ab\u6307\u5b9a\u70ba\u5169\u7a2e\u985e\u578b\u4e4b\u4e00\uff1a\u8207\u5176\u4ed6\u5ba2\u6236\u7aef\u5171\u4eab\u4ee5\u63d0\u53d6\u4e00\u822c\u77e5\u8b58\u7684\u53c3\u6578\u548c\u4fdd\u7559\u5728\u672c\u5730\u4ee5\u5b78\u7fd2\u5ba2\u6236\u7aef\u7279\u5b9a\u77e5\u8b58\u7684\u53c3\u6578\u3002\u7136\u800c\uff0c\u7531\u65bc\u9019\u5169\u7a2e\u985e\u578b\u7684\u53c3\u6578\u5728\u8a13\u7df4\u904e\u7a0b\u4e2d\u6703\u50cf\u62fc\u5716\u4e00\u6a23\u7d44\u5408\u6210\u55ae\u4e00\u6a21\u578b\uff0c\u56e0\u6b64\u6bcf\u500b\u53c3\u6578\u53ef\u80fd\u6703\u540c\u6642\u5438\u6536\u4e00\u822c\u548c\u5ba2\u6236\u7aef\u7279\u5b9a\u7684\u77e5\u8b58\uff0c\u5f9e\u800c\u96e3\u4ee5\u6709\u6548\u5730\u5c07\u9019\u5169\u7a2e\u77e5\u8b58\u985e\u578b\u5206\u958b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 FedDecomp\uff0c\u9019\u662f\u4e00\u500b\u7c21\u55ae\u4f46\u6709\u6548\u7684 PFL \u5178\u7bc4\uff0c\u63a1\u7528\u53c3\u6578\u52a0\u6cd5\u5206\u89e3\u4f86\u89e3\u6c7a\u6b64\u554f\u984c\u3002FedDecomp \u6c92\u6709\u5c07\u6a21\u578b\u7684\u6bcf\u500b\u53c3\u6578\u6307\u5b9a\u70ba\u5171\u4eab\u53c3\u6578\u6216\u500b\u4eba\u5316\u53c3\u6578\uff0c\u800c\u662f\u5c07\u6bcf\u500b\u53c3\u6578\u5206\u89e3\u70ba\u5169\u500b\u53c3\u6578\u7684\u7e3d\u548c\uff1a\u5171\u4eab\u53c3\u6578\u548c\u500b\u4eba\u5316\u53c3\u6578\uff0c\u5f9e\u800c\u5be6\u73fe\u4e86\u8207\u53c3\u6578\u5206\u5272\u65b9\u6cd5\u76f8\u6bd4\u66f4\u5fb9\u5e95\u7684\u5171\u4eab\u548c\u500b\u4eba\u5316\u77e5\u8b58\u89e3\u8026\u3002\u6b64\u5916\uff0c\u7531\u65bc\u6211\u5011\u767c\u73fe\u4fdd\u7559\u7279\u5b9a\u5ba2\u6236\u7aef\u7684\u672c\u5730\u77e5\u8b58\u6240\u9700\u7684\u6a21\u578b\u5bb9\u91cf\u9060\u4f4e\u65bc\u6240\u6709\u5ba2\u6236\u7aef\u7684\u4e00\u822c\u77e5\u8b58\uff0c\u56e0\u6b64\u6211\u5011\u8b93\u5305\u542b\u500b\u4eba\u5316\u53c3\u6578\u7684\u77e9\u9663\u5728\u8a13\u7df4\u904e\u7a0b\u4e2d\u4fdd\u6301\u4f4e\u79e9\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7684\u4ea4\u66ff\u8a13\u7df4\u7b56\u7565\uff0c\u4ee5\u9032\u4e00\u6b65\u63d0\u9ad8\u6027\u80fd\u3002\u8de8\u591a\u500b\u8cc7\u6599\u96c6\u548c\u4e0d\u540c\u7a0b\u5ea6\u8cc7\u6599\u7570\u8cea\u6027\u7684\u5be6\u9a57\u7d50\u679c\u8b49\u660e\uff0cFedDecomp \u7684\u6548\u80fd\u512a\u65bc\u6700\u5148\u9032\u7684\u65b9\u6cd5\uff0c\u6700\u9ad8\u53ef\u9054 4.9%\u3002</paragraph>", "author": "Xinghao Wu et.al.", "authors": "Xinghao Wu, Xuefeng Liu, Jianwei Niu, Haolin Wang, Shaojie Tang, Guogang Zhu, Hao Su", "id": "2406.19931v1", "paper_url": "http://arxiv.org/abs/2406.19931v1", "repo": "null"}}