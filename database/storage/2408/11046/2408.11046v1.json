{"2408.11046": {"publish_time": "2024-08-20", "title": "Inside the Black Box: Detecting Data Leakage in Pre-trained Language Encoders", "paper_summary": "Despite being prevalent in the general field of Natural Language Processing\n(NLP), pre-trained language models inherently carry privacy and copyright\nconcerns due to their nature of training on large-scale web-scraped data. In\nthis paper, we pioneer a systematic exploration of such risks associated with\npre-trained language encoders, specifically focusing on the membership leakage\nof pre-training data exposed through downstream models adapted from pre-trained\nlanguage encoders-an aspect largely overlooked in existing literature. Our\nstudy encompasses comprehensive experiments across four types of pre-trained\nencoder architectures, three representative downstream tasks, and five\nbenchmark datasets. Intriguingly, our evaluations reveal, for the first time,\nthe existence of membership leakage even when only the black-box output of the\ndownstream model is exposed, highlighting a privacy risk far greater than\npreviously assumed. Alongside, we present in-depth analysis and insights toward\nguiding future researchers and practitioners in addressing the privacy\nconsiderations in developing pre-trained language models.", "paper_summary_zh": "\u5118\u7ba1\u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u7684\u4e00\u822c\u9818\u57df\u4e2d\u5f88\u666e\u904d\uff0c\u4f46\u9810\u5148\u8a13\u7df4\u7684\u8a9e\u8a00\u6a21\u578b\u7531\u65bc\u5176\u5728\u5927\u91cf\u7db2\u8def\u64f7\u53d6\u8cc7\u6599\u4e0a\u8a13\u7df4\u7684\u7279\u6027\uff0c\u672c\u8cea\u4e0a\u6703\u5e36\u4f86\u96b1\u79c1\u548c\u7248\u6b0a\u554f\u984c\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u7387\u5148\u7cfb\u7d71\u6027\u5730\u63a2\u8a0e\u8207\u9810\u5148\u8a13\u7df4\u8a9e\u8a00\u7de8\u78bc\u5668\u76f8\u95dc\u7684\u6b64\u985e\u98a8\u96aa\uff0c\u7279\u5225\u95dc\u6ce8\u900f\u904e\u6539\u7de8\u81ea\u9810\u5148\u8a13\u7df4\u8a9e\u8a00\u7de8\u78bc\u5668\u7684\u4e0b\u6e38\u6a21\u578b\u6240\u63ed\u9732\u7684\u9810\u5148\u8a13\u7df4\u8cc7\u6599\u7684\u6210\u54e1\u8eab\u5206\u5916\u6d29\uff0c\u800c\u9019\u65b9\u9762\u5728\u73fe\u6709\u6587\u737b\u4e2d\u5927\u591a\u88ab\u5ffd\u7565\u3002\u6211\u5011\u7684\u7814\u7a76\u6db5\u84cb\u4e86\u56db\u7a2e\u985e\u578b\u7684\u9810\u5148\u8a13\u7df4\u7de8\u78bc\u5668\u67b6\u69cb\u3001\u4e09\u500b\u5177\u4ee3\u8868\u6027\u7684\u4e0b\u6e38\u4efb\u52d9\u4ee5\u53ca\u4e94\u500b\u57fa\u6e96\u8cc7\u6599\u96c6\u7684\u7d9c\u5408\u5be6\u9a57\u3002\u6709\u8da3\u7684\u662f\uff0c\u6211\u5011\u7684\u8a55\u4f30\u9996\u6b21\u63ed\u793a\u4e86\u5373\u4f7f\u50c5\u516c\u958b\u4e0b\u6e38\u6a21\u578b\u7684\u9ed1\u76d2\u8f38\u51fa\uff0c\u4e5f\u6703\u5b58\u5728\u6210\u54e1\u8eab\u5206\u5916\u6d29\u7684\u60c5\u6cc1\uff0c\u7a81\u986f\u4e86\u9060\u5927\u65bc\u5148\u524d\u5047\u8a2d\u7684\u96b1\u79c1\u98a8\u96aa\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u6df1\u5165\u7684\u5206\u6790\u548c\u898b\u89e3\uff0c\u4ee5\u6307\u5c0e\u672a\u4f86\u7684\u7814\u7a76\u4eba\u54e1\u548c\u5f9e\u696d\u4eba\u54e1\u5728\u958b\u767c\u9810\u5148\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b\u6642\u89e3\u6c7a\u96b1\u79c1\u8003\u91cf\u3002", "author": "Yuan Xin et.al.", "authors": "Yuan Xin, Zheng Li, Ning Yu, Dingfan Chen, Mario Fritz, Michael Backes, Yang Zhang", "id": "2408.11046v1", "paper_url": "http://arxiv.org/abs/2408.11046v1", "repo": "null"}}