
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-04**|**Prompting with Phonemes: Enhancing LLM Multilinguality for non-Latin Script Languages**|Hoang Nguyen et.al.|[2411.02398v1](http://arxiv.org/abs/2411.02398v1)|null|
|**2024-11-04**|**Adaptive Length Image Tokenization via Recurrent Allocation**|Shivam Duggal et.al.|[2411.02393v1](http://arxiv.org/abs/2411.02393v1)|[link](https://github.com/shivamduggal4/adaptive-length-tokenizer)|
|**2024-11-04**|**Attacking Vision-Language Computer Agents via Pop-ups**|Yanzhe Zhang et.al.|[2411.02391v1](http://arxiv.org/abs/2411.02391v1)|null|
|**2024-11-04**|**How Far is Video Generation from World Model: A Physical Law Perspective**|Bingyi Kang et.al.|[2411.02385v1](http://arxiv.org/abs/2411.02385v1)|null|
|**2024-11-04**|**Improving Scientific Hypothesis Generation with Knowledge Grounded Large Language Models**|Guangzhi Xiong et.al.|[2411.02382v1](http://arxiv.org/abs/2411.02382v1)|null|
|**2024-11-04**|**Addressing Uncertainty in LLMs to Enhance Reliability in Generative AI**|Ramneet Kaur et.al.|[2411.02381v1](http://arxiv.org/abs/2411.02381v1)|null|
|**2024-11-04**|**DeeR-VLA: Dynamic Inference of Multimodal Large Language Models for Efficient Robot Execution**|Yang Yue et.al.|[2411.02359v1](http://arxiv.org/abs/2411.02359v1)|[link](https://github.com/yueyang130/deer-vla)|
|**2024-11-04**|**"Give Me BF16 or Give Me Death"? Accuracy-Performance Trade-Offs in LLM Quantization**|Eldar Kurtic et.al.|[2411.02355v1](http://arxiv.org/abs/2411.02355v1)|null|
|**2024-11-04**|**Can Large Language Models generalize analogy solving like people can?**|Claire E. Stevenson et.al.|[2411.02348v1](http://arxiv.org/abs/2411.02348v1)|null|
|**2024-11-04**|**Simulation of Nanorobots with Artificial Intelligence and Reinforcement Learning for Advanced Cancer Cell Detection and Tracking**|Shahab Kavousinejad et.al.|[2411.02345v1](http://arxiv.org/abs/2411.02345v1)|[link](https://github.com/shahab-k93/cancer-and-smart-nanorobot)|
|**2024-11-04**|**Seq-VCR: Preventing Collapse in Intermediate Transformer Representations for Enhanced Reasoning**|Md Rifat Arefin et.al.|[2411.02344v1](http://arxiv.org/abs/2411.02344v1)|null|
|**2024-11-04**|**WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning**|Zehan Qi et.al.|[2411.02337v1](http://arxiv.org/abs/2411.02337v1)|null|
|**2024-11-04**|**Sparsing Law: Towards Large Language Models with Greater Activation Sparsity**|Yuqi Luo et.al.|[2411.02335v1](http://arxiv.org/abs/2411.02335v1)|null|
|**2024-11-04**|**Taking AI Welfare Seriously**|Robert Long et.al.|[2411.00986v1](http://arxiv.org/abs/2411.00986v1)|null|
|**2024-11-04**|**Disrupting Test Development with AI Assistants**|Vijay Joshi et.al.|[2411.02328v1](http://arxiv.org/abs/2411.02328v1)|null|
|**2024-11-04**|**GenXD: Generating Any 3D and 4D Scenes**|Yuyang Zhao et.al.|[2411.02319v1](http://arxiv.org/abs/2411.02319v1)|null|
|**2024-11-04**|**Evaluating the Ability of Large Language Models to Generate Verifiable Specifications in VeriFast**|Marilyn Rego et.al.|[2411.02318v1](http://arxiv.org/abs/2411.02318v1)|null|
|**2024-11-04**|**Defining and Evaluating Physical Safety for Large Language Models**|Yung-Chen Tang et.al.|[2411.02317v1](http://arxiv.org/abs/2411.02317v1)|null|
|**2024-11-04**|**Evaluating Creative Short Story Generation in Humans and Large Language Models**|Mete Ismayilzada et.al.|[2411.02316v1](http://arxiv.org/abs/2411.02316v1)|[link](https://github.com/mismayil/creative-story-gen)|
|**2024-11-04**|**MdEval: Massively Multilingual Code Debugging**|Shukai Liu et.al.|[2411.02310v1](http://arxiv.org/abs/2411.02310v1)|null|
|**2024-11-04**|**Grid-Based Projection of Spatial Data into Knowledge Graphs**|Amin Anjomshoaa et.al.|[2411.02309v1](http://arxiv.org/abs/2411.02309v1)|null|
|**2024-11-04**|**Targeted Manipulation and Deception Emerge when Optimizing LLMs for User Feedback**|Marcus Williams et.al.|[2411.02306v1](http://arxiv.org/abs/2411.02306v1)|[link](https://github.com/marcus-jw/targeted-manipulation-and-deception-in-llms)|
|**2024-11-04**|**CRMArena: Understanding the Capacity of LLM Agents to Perform Professional CRM Tasks in Realistic Environments**|Kung-Hsiang Huang et.al.|[2411.02305v1](http://arxiv.org/abs/2411.02305v1)|[link](https://github.com/salesforceairesearch/crmarena)|
|**2024-11-04**|**Hunyuan3D-1.0: A Unified Framework for Text-to-3D and Image-to-3D Generation**|Xianghui Yang et.al.|[2411.02293v1](http://arxiv.org/abs/2411.02293v1)|null|
|**2024-11-04**|**ControlSynth Neural ODEs: Modeling Dynamical Systems with Guaranteed Convergence**|Wenjie Mei et.al.|[2411.02292v1](http://arxiv.org/abs/2411.02292v1)|null|
|**2024-11-04**|**Federated GNNs for EEG-Based Stroke Assessment**|Andrea Protani et.al.|[2411.02286v1](http://arxiv.org/abs/2411.02286v1)|null|
|**2024-11-04**|**The LLM Language Network: A Neuroscientific Approach for Identifying Causally Task-Relevant Units**|Badr AlKhamissi et.al.|[2411.02280v1](http://arxiv.org/abs/2411.02280v1)|null|
|**2024-11-04**|**Breaking the Reclustering Barrier in Centroid-based Deep Clustering**|Lukas Miklautz et.al.|[2411.02275v1](http://arxiv.org/abs/2411.02275v1)|[link](https://github.com/probabilistic-and-interactive-ml/breaking-the-reclustering-barrier)|
|**2024-11-04**|**Combining Induction and Transduction for Abstract Reasoning**|Wen-Ding Li et.al.|[2411.02272v1](http://arxiv.org/abs/2411.02272v1)|null|
|**2024-11-04**|**On the Utilization of Unique Node Identifiers in Graph Neural Networks**|Maya Bechler-Speicher et.al.|[2411.02271v1](http://arxiv.org/abs/2411.02271v1)|null|
|**2024-11-04**|**Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated Parameters by Tencent**|Xingwu Sun et.al.|[2411.02265v1](http://arxiv.org/abs/2411.02265v1)|[link](https://github.com/tencent/hunyuan-large)|
|**2024-11-04**|**Positive Experience Reflection for Agents in Interactive Text Environments**|Philip Lippmann et.al.|[2411.02223v1](http://arxiv.org/abs/2411.02223v1)|null|
|**2024-11-04**|**Improving Steering Vectors by Targeting Sparse Autoencoder Features**|Sviatoslav Chalnev et.al.|[2411.02193v1](http://arxiv.org/abs/2411.02193v1)|[link](https://github.com/slavachalnev/sae-ts)|
|**2024-11-04**|**Double Descent Meets Out-of-Distribution Detection: Theoretical Insights and Empirical Analysis on the role of model complexity**|Mou√Øn Ben Ammar et.al.|[2411.02184v1](http://arxiv.org/abs/2411.02184v1)|null|
|**2024-11-04**|**Behavioral Sequence Modeling with Ensemble Learning**|Maxime Kawawa-Beaudan et.al.|[2411.02174v1](http://arxiv.org/abs/2411.02174v1)|null|
|**2024-11-04**|**Do graph neural network states contain graph properties?**|Tom Pelletreau-Duris et.al.|[2411.02168v1](http://arxiv.org/abs/2411.02168v1)|null|
|**2024-11-04**|**Training Compute-Optimal Protein Language Models**|Xingyi Cheng et.al.|[2411.02142v1](http://arxiv.org/abs/2411.02142v1)|[link](https://github.com/cxysteven/scalingproteinlm)|
|**2024-11-04**|**Generating the Traces You Need: A Conditional Generative Model for Process Mining Data**|Riccardo Graziosi et.al.|[2411.02131v1](http://arxiv.org/abs/2411.02131v1)|[link](https://github.com/rgraziosi-fbk/cvae-process-mining)|
|**2024-11-04**|**Unsupervised detection of semantic correlations in big data**|Santiago Acevedo et.al.|[2411.02126v1](http://arxiv.org/abs/2411.02126v1)|null|
|**2024-11-04**|**Revisiting K-mer Profile for Effective and Scalable Genome Representation Learning**|Abdulkadir Celikkanat et.al.|[2411.02125v1](http://arxiv.org/abs/2411.02125v1)|[link](https://github.com/abdcelikkanat/revisitingkmers)|
|**2024-11-04**|**Adaptive Sparse Allocation with Mutual Choice & Feature Choice Sparse Autoencoders**|Kola Ayonrinde et.al.|[2411.02124v1](http://arxiv.org/abs/2411.02124v1)|null|
|**2024-11-04**|**Bridge-IF: Learning Inverse Protein Folding with Markov Bridges**|Yiheng Zhu et.al.|[2411.02120v1](http://arxiv.org/abs/2411.02120v1)|[link](https://github.com/violet-sto/bridge-if)|
|**2024-11-04**|**Grounding Emotional Descriptions to Electrovibration Haptic Signals**|Guimin Hu et.al.|[2411.02118v1](http://arxiv.org/abs/2411.02118v1)|null|
|**2024-11-04**|**AVSS: Layer Importance Evaluation in Large Language Models via Activation Variance-Sparsity Analysis**|Zichen Song et.al.|[2411.02117v1](http://arxiv.org/abs/2411.02117v1)|null|
|**2024-11-04**|**Advancements and limitations of LLMs in replicating human color-word associations**|Makoto Fukushima et.al.|[2411.02116v1](http://arxiv.org/abs/2411.02116v1)|null|
|**2024-11-04**|**Differentially Private Integrated Decision Gradients (IDG-DP) for Radar-based Human Activity Recognition**|Idris Zakariyya et.al.|[2411.02099v1](http://arxiv.org/abs/2411.02099v1)|null|
|**2024-11-04**|**Alignment-Based Adversarial Training (ABAT) for Improving the Robustness and Accuracy of EEG-Based BCIs**|Xiaoqing Chen et.al.|[2411.02094v1](http://arxiv.org/abs/2411.02094v1)|[link](https://github.com/xqchen914/abat)|
|**2024-11-04**|**Real-time and Downtime-tolerant Fault Diagnosis for Railway Turnout Machines (RTMs) Empowered with Cloud-Edge Pipeline Parallelism**|Fan Wu et.al.|[2411.02086v1](http://arxiv.org/abs/2411.02086v1)|null|
|**2024-11-04**|**Regress, Don't Guess -- A Regression-like Loss on Number Tokens for Language Models**|Jonas Zausinger et.al.|[2411.02083v1](http://arxiv.org/abs/2411.02083v1)|null|
|**2024-11-04**|**Collaborative Cognitive Diagnosis with Disentangled Representation Learning for Learner Modeling**|Weibo Gao et.al.|[2411.02066v1](http://arxiv.org/abs/2411.02066v1)|[link](https://github.com/bigdata-ustc/coral)|
|**2024-11-04**|**Scalable Efficient Training of Large Language Models with Low-dimensional Projected Attention**|Xingtai Lv et.al.|[2411.02063v1](http://arxiv.org/abs/2411.02063v1)|null|
|**2024-11-04**|**TableGPT2: A Large Multimodal Model with Tabular Data Integration**|Aofeng Su et.al.|[2411.02059v1](http://arxiv.org/abs/2411.02059v1)|null|
|**2024-11-04**|**Enhancing ID-based Recommendation with Large Language Models**|Lei Chen et.al.|[2411.02041v1](http://arxiv.org/abs/2411.02041v1)|null|
|**2024-11-04**|**Explainable cognitive decline detection in free dialogues with a Machine Learning approach based on pre-trained Large Language Models**|Francisco de Arriba-P√©rez et.al.|[2411.02036v1](http://arxiv.org/abs/2411.02036v1)|null|
|**2024-11-04**|**CTEFM-VC: Zero-Shot Voice Conversion Based on Content-Aware Timbre Ensemble Modeling and Flow Matching**|Yu Pan et.al.|[2411.02026v1](http://arxiv.org/abs/2411.02026v1)|null|
|**2024-11-04**|**Shortcut Learning in In-Context Learning: A Survey**|Rui Song et.al.|[2411.02018v1](http://arxiv.org/abs/2411.02018v1)|null|
|**2024-11-04**|**Foundations and Recent Trends in Multimodal Mobile Agents: A Survey**|Biao Wu et.al.|[2411.02006v1](http://arxiv.org/abs/2411.02006v1)|null|
|**2024-11-04**|**Against Multifaceted Graph Heterogeneity via Asymmetric Federated Prompt Learning**|Zhuoning Guo et.al.|[2411.02003v1](http://arxiv.org/abs/2411.02003v1)|null|
|**2024-11-04**|**Culinary Class Wars: Evaluating LLMs using ASH in Cuisine Transfer Task**|Hoonick Lee et.al.|[2411.01996v1](http://arxiv.org/abs/2411.01996v1)|null|
|**2024-11-04**|**Understanding Variational Autoencoders with Intrinsic Dimension and Information Imbalance**|Charles Camboulin et.al.|[2411.01978v1](http://arxiv.org/abs/2411.01978v1)|[link](https://github.com/bancaditalia/understanding-variational-autoencoders-with-intrinsic-dimension-and-information-imbalance)|
|**2024-11-04**|**Active Gaze Behavior Boosts Self-Supervised Object Learning**|Zhengyang Yu et.al.|[2411.01969v1](http://arxiv.org/abs/2411.01969v1)|null|
|**2024-11-04**|**V-CAS: A Realtime Vehicle Anti Collision System Using Vision Transformer on Multi-Camera Streams**|Muhammad Waqas Ashraf et.al.|[2411.01963v1](http://arxiv.org/abs/2411.01963v1)|null|
|**2024-11-04**|**HACD: Harnessing Attribute Semantics and Mesoscopic Structure for Community Detection**|Anran Zhang et.al.|[2411.01947v1](http://arxiv.org/abs/2411.01947v1)|[link](https://github.com/anniran1/hacd1-wsdm)|
|**2024-11-04**|**Exploring the Landscape for Generative Sequence Models for Specialized Data Synthesis**|Mohammad Zbeeb et.al.|[2411.01929v1](http://arxiv.org/abs/2411.01929v1)|[link](https://github.com/moe-zbeeb/exploring-the-landscape-for-generative-models-for-specialized-data-generation)|
|**2024-11-04**|**Fairness-Utilization Trade-off in Wireless Networks with Explainable Kolmogorov-Arnold Networks**|Masoud Shokrnezhad et.al.|[2411.01924v1](http://arxiv.org/abs/2411.01924v1)|null|
|**2024-11-04**|**LE-PDE++: Mamba for accelerating PDEs Simulations**|Aoming Liang et.al.|[2411.01897v1](http://arxiv.org/abs/2411.01897v1)|null|
|**2024-11-04**|**MBDRes-U-Net: Multi-Scale Lightweight Brain Tumor Segmentation Network**|Longfeng Shen et.al.|[2411.01896v1](http://arxiv.org/abs/2411.01896v1)|[link](https://github.com/huaibei-normal-university-cv-laboratory/mbdresunet)|
|**2024-11-04**|**LiDAttack: Robust Black-box Attack on LiDAR-based Object Detection**|Jinyin Chen et.al.|[2411.01889v1](http://arxiv.org/abs/2411.01889v1)|[link](https://github.com/cinderyl/lidattack)|
|**2024-11-04**|**Can Language Models Learn to Skip Steps?**|Tengxiao Liu et.al.|[2411.01855v1](http://arxiv.org/abs/2411.01855v1)|null|
|**2024-11-04**|**Leveraging Label Semantics and Meta-Label Refinement for Multi-Label Question Classification**|Shi Dong et.al.|[2411.01841v1](http://arxiv.org/abs/2411.01841v1)|null|
|**2024-11-04**|**TriG-NER: Triplet-Grid Framework for Discontinuous Named Entity Recognition**|Rina Carines Cabral et.al.|[2411.01839v1](http://arxiv.org/abs/2411.01839v1)|null|
|**2024-11-04**|**Align-SLM: Textless Spoken Language Models with Reinforcement Learning from AI Feedback**|Guan-Ting Lin et.al.|[2411.01834v1](http://arxiv.org/abs/2411.01834v1)|null|
|**2024-11-04**|**DiffuMask-Editor: A Novel Paradigm of Integration Between the Segmentation Diffusion Model and Image Editing to Improve Segmentation Ability**|Bo Gao et.al.|[2411.01819v1](http://arxiv.org/abs/2411.01819v1)|null|
|**2024-11-04**|**Can Language Models Enable In-Context Database?**|Yu Pan et.al.|[2411.01807v1](http://arxiv.org/abs/2411.01807v1)|null|
|**2024-11-04**|**Constrained Human-AI Cooperation: An Inclusive Embodied Social Intelligence Challenge**|Weihua Du et.al.|[2411.01796v1](http://arxiv.org/abs/2411.01796v1)|[link](https://github.com/umass-foundation-model/chaic)|
|**2024-11-04**|**Thinking Forward and Backward: Effective Backward Planning with Large Language Models**|Allen Z. Ren et.al.|[2411.01790v1](http://arxiv.org/abs/2411.01790v1)|[link](https://github.com/irom-princeton/llm-backward)|
|**2024-11-04**|**Context Parallelism for Scalable Million-Token Inference**|Amy et.al.|[2411.01783v1](http://arxiv.org/abs/2411.01783v1)|null|
|**2024-11-04**|**Eurekaverse: Environment Curriculum Generation via Large Language Models**|William Liang et.al.|[2411.01775v1](http://arxiv.org/abs/2411.01775v1)|null|
|**2024-11-04**|**Towards Pedagogical LLMs with Supervised Fine Tuning for Computing Education**|Alexandra Vassar et.al.|[2411.01765v1](http://arxiv.org/abs/2411.01765v1)|null|
|**2024-11-04**|**Mitigating Spurious Correlations via Disagreement Probability**|Hyeonggeun Han et.al.|[2411.01757v1](http://arxiv.org/abs/2411.01757v1)|null|
|**2024-11-04**|**RAGViz: Diagnose and Visualize Retrieval-Augmented Generation**|Tevin Wang et.al.|[2411.01751v1](http://arxiv.org/abs/2411.01751v1)|[link](https://github.com/cxcscmu/ragviz)|
|**2024-11-04**|**DynaSaur: Large Language Agents Beyond Predefined Actions**|Dang Nguyen et.al.|[2411.01747v1](http://arxiv.org/abs/2411.01747v1)|null|
|**2024-11-04**|**xDiT: an Inference Engine for Diffusion Transformers (DiTs) with Massive Parallelism**|Jiarui Fang et.al.|[2411.01738v1](http://arxiv.org/abs/2411.01738v1)|[link](https://github.com/xdit-project/xdit)|
|**2024-11-03**|**Rethinking Weight Decay for Robust Fine-Tuning of Foundation Models**|Junjiao Tian et.al.|[2411.01713v1](http://arxiv.org/abs/2411.01713v1)|[link](https://github.com/gt-ripl/selective-projection-decay)|
|**2024-11-03**|**SPES: Spectrogram Perturbation for Explainable Speech-to-Text Generation**|Dennis Fucci et.al.|[2411.01710v1](http://arxiv.org/abs/2411.01710v1)|null|
|**2024-11-03**|**Investigating Large Language Models for Complex Word Identification in Multilingual and Multidomain Setups**|RƒÉzvan-Alexandru SmƒÉdu et.al.|[2411.01706v1](http://arxiv.org/abs/2411.01706v1)|null|
|**2024-11-03**|**Data Extraction Attacks in Retrieval-Augmented Generation via Backdoors**|Yuefeng Peng et.al.|[2411.01705v1](http://arxiv.org/abs/2411.01705v1)|null|
|**2024-11-03**|**UniGuard: Towards Universal Safety Guardrails for Jailbreak Attacks on Multimodal Large Language Models**|Sejoon Oh et.al.|[2411.01703v1](http://arxiv.org/abs/2411.01703v1)|null|
|**2024-11-03**|**Unlocking the Theory Behind Scaling 1-Bit Neural Networks**|Majid Daliri et.al.|[2411.01663v1](http://arxiv.org/abs/2411.01663v1)|null|
|**2024-11-03**|**Diagnosing Medical Datasets with Training Dynamics**|Laura Wenderoth et.al.|[2411.01653v1](http://arxiv.org/abs/2411.01653v1)|[link](https://github.com/laurawenderoth/training-dynamics)|
|**2024-11-03**|**Optimizing Gastrointestinal Diagnostics: A CNN-Based Model for VCE Image Classification**|Vaneeta Ahlawat et.al.|[2411.01652v1](http://arxiv.org/abs/2411.01652v1)|null|
|**2024-11-03**|**Optical Flow Representation Alignment Mamba Diffusion Model for Medical Video Generation**|Zhenbin Wang et.al.|[2411.01647v1](http://arxiv.org/abs/2411.01647v1)|null|
|**2024-11-03**|**Enriching Tabular Data with Contextual LLM Embeddings: A Comprehensive Ablation Study for Ensemble Classifiers**|Gjergji Kasneci et.al.|[2411.01645v1](http://arxiv.org/abs/2411.01645v1)|null|
|**2024-11-03**|**EcoAct: Economic Agent Determines When to Register What Action**|Shaokun Zhang et.al.|[2411.01643v1](http://arxiv.org/abs/2411.01643v1)|null|
|**2024-11-03**|**Know Where You're Uncertain When Planning with Multimodal Foundation Models: A Formal Framework**|Neel P. Bhatt et.al.|[2411.01639v1](http://arxiv.org/abs/2411.01639v1)|null|
|**2024-11-03**|**Leveraging Microservices Architecture for Dynamic Pricing in the Travel Industry: Algorithms, Scalability, and Impact on Revenue and Customer Satisfaction**|Biman Barua et.al.|[2411.01636v1](http://arxiv.org/abs/2411.01636v1)|null|
|**2024-11-03**|**Counterfactual explainability of black-box prediction models**|Zijun Gao et.al.|[2411.01625v1](http://arxiv.org/abs/2411.01625v1)|null|
|**2024-11-03**|**FilterNet: Harnessing Frequency Filters for Time Series Forecasting**|Kun Yi et.al.|[2411.01623v1](http://arxiv.org/abs/2411.01623v1)|[link](https://github.com/aikunyi/filternet)|
|**2024-11-03**|**VQ-Map: Bird's-Eye-View Map Layout Estimation in Tokenized Discrete Space via Vector Quantization**|Yiwei Zhang et.al.|[2411.01618v1](http://arxiv.org/abs/2411.01618v1)|null|
|**2024-11-03**|**Ontology Population using LLMs**|Sanaz Saki Norouzi et.al.|[2411.01612v1](http://arxiv.org/abs/2411.01612v1)|null|

#### Abstracts
##### **Prompting with Phonemes: Enhancing LLM Multilinguality for non-Latin Script Languages**
2411.02398v1 by Hoang Nguyen, Khyati Mahajan, Vikas Yadav, Philip S. Yu, Masoud Hashemi, Rishabh Maheshwary

Multilingual LLMs have achieved remarkable benchmark performance, but we find
they continue to underperform on non-Latin script languages across contemporary
LLM families. This discrepancy arises from the fact that LLMs are pretrained
with orthographic scripts, which are dominated by Latin characters that obscure
their shared phonology with non-Latin scripts. We propose leveraging phonemic
transcriptions as complementary signals to induce script-invariant
representations. Our study demonstrates that integrating phonemic signals
improves performance across both non-Latin and Latin languages, with a
particularly significant impact on closing the performance gap between the two.
Through detailed experiments, we show that phonemic and orthographic scripts
retrieve distinct examples for in-context learning (ICL). This motivates our
proposed Mixed-ICL retrieval strategy, where further aggregation leads to our
significant performance improvements for both Latin script languages (up to
12.6%) and non-Latin script languages (up to 15.1%) compared to randomized ICL
retrieval.

ÊëòË¶ÅÔºöÂ§öË™ûË®Ä LLM Â∑≤Á∂ìÂèñÂæóÈ°ØËëóÁöÑÂü∫Ê∫ñÊïàËÉΩÔºå‰ΩÜÊàëÂÄëÁôºÁèæÔºåÂú®Áï∂‰ª£ LLM ÂÆ∂Êóè‰∏≠ÔºåÂÆÉÂÄëÂú®ÈùûÊãâ‰∏ÅÊñáÂ≠óË™ûË®Ä‰∏äÁöÑË°®Áèæ‰ªçÁÑ∂‰∏ç‰Ω≥„ÄÇÈÄôÁ®ÆÂ∑ÆÁï∞Ê∫êÊñº LLM ÊòØ‰ΩøÁî®Ê≠£Â≠óÊ≥ïËÖ≥Êú¨‰æÜÈ†êÂÖàË®ìÁ∑¥ÁöÑÔºåËÄåÊ≠£Â≠óÊ≥ïËÖ≥Êú¨‰∏ªË¶ÅÊòØÁî±Êãâ‰∏ÅÂ≠óÊØç‰∏ªÂ∞éÔºåÈÄôÊúÉÊ®°Á≥äÂÆÉÂÄëËàáÈùûÊãâ‰∏ÅÂ≠óÊØçÂÖ±ÊúâÁöÑÈü≥Èüª„ÄÇÊàëÂÄëÂª∫Ë≠∞Âà©Áî®Èü≥Á¥†ËΩâÈåÑ‰ΩúÁÇ∫Ë£úÂÖÖË®äËôüÔºå‰ª•Ë™òÂ∞éÂá∫ËàáËÖ≥Êú¨ÁÑ°ÈóúÁöÑË°®Âæµ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ë≠âÊòéÔºåÊï¥ÂêàÈü≥Á¥†Ë®äËôüÂèØ‰ª•ÊèêÂçáÈùûÊãâ‰∏ÅË™ûÂíåÊãâ‰∏ÅË™ûÁöÑÊïàËÉΩÔºåÁâπÂà•ÊòØÂú®Á∏ÆÂ∞èÂÖ©ËÄÖ‰πãÈñìÁöÑÊïàËÉΩÂ∑ÆË∑ùÊñπÈù¢ÊúâÈ°ØËëóÁöÑÂΩ±Èüø„ÄÇÈÄèÈÅéË©≥Á¥∞ÁöÑÂØ¶È©óÔºåÊàëÂÄëË°®ÊòéÈü≥Á¥†ÂíåÊ≠£Â≠óÊ≥ïËÖ≥Êú¨ÊúÉÊì∑Âèñ‰∏çÂêåÁöÑÁØÑ‰æãÔºå‰ª•ÈÄ≤Ë°åÊÉÖÂ¢É‰∏≠Â≠∏Áøí (ICL)„ÄÇÈÄôÊøÄÂãµÊàëÂÄëÊèêÂá∫Ê∑∑Âêà ICL Êì∑ÂèñÁ≠ñÁï•ÔºåÈÄ≤‰∏ÄÊ≠•ÁöÑËÅöÂêàÊúÉÂ∞éËá¥ÊàëÂÄëÈ°ØËëóÊèêÂçáÊãâ‰∏ÅÊñáÂ≠óË™ûË®Ä (ÊúÄÈ´òÈÅî 12.6%) ÂíåÈùûÊãâ‰∏ÅÊñáÂ≠óË™ûË®Ä (ÊúÄÈ´òÈÅî 15.1%) ÁöÑÊïàËÉΩÔºåÁõ∏ÊØîÊñºÈö®Ê©ü ICL Êì∑Âèñ„ÄÇ

##### **Adaptive Length Image Tokenization via Recurrent Allocation**
2411.02393v1 by Shivam Duggal, Phillip Isola, Antonio Torralba, William T. Freeman

Current vision systems typically assign fixed-length representations to
images, regardless of the information content. This contrasts with human
intelligence - and even large language models - which allocate varying
representational capacities based on entropy, context and familiarity. Inspired
by this, we propose an approach to learn variable-length token representations
for 2D images. Our encoder-decoder architecture recursively processes 2D image
tokens, distilling them into 1D latent tokens over multiple iterations of
recurrent rollouts. Each iteration refines the 2D tokens, updates the existing
1D latent tokens, and adaptively increases representational capacity by adding
new tokens. This enables compression of images into a variable number of
tokens, ranging from 32 to 256. We validate our tokenizer using reconstruction
loss and FID metrics, demonstrating that token count aligns with image entropy,
familiarity and downstream task requirements. Recurrent token processing with
increasing representational capacity in each iteration shows signs of token
specialization, revealing potential for object / part discovery.

ÊëòË¶ÅÔºöÁõÆÂâçÁöÑË¶ñË¶∫Á≥ªÁµ±ÈÄöÂ∏∏ÊúÉÂ∞áÂõ∫ÂÆöÈï∑Â∫¶ÁöÑË°®ÂæµÂàÜÈÖçÁµ¶ÂΩ±ÂÉèÔºåËÄå‰∏çÁÆ°Ë≥áË®äÂÖßÂÆπÁÇ∫‰Ωï„ÄÇÈÄôËàá‰∫∫È°ûÁöÑÊô∫ÊÖß‚Äî‚ÄîÁîöËá≥ÊòØÂ§ßÂûãË™ûË®ÄÊ®°Âûã‚Äî‚ÄîÂΩ¢ÊàêÂ∞çÊØîÔºåÂæåËÄÖÊúÉÊ†πÊìöÁÜµ„ÄÅËÑàÁµ°ÂíåÁÜüÊÇâÂ∫¶ÂàÜÈÖç‰∏çÂêåÁöÑË°®ÂæµÂÆπÈáè„ÄÇÂèóÂà∞ÈÄôÈªûÂïüÁôºÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñπÊ≥ï‰æÜÂ≠∏Áøí 2D ÂΩ±ÂÉèÁöÑÂèØËÆäÈï∑Â∫¶Ê®ôË®òË°®Âæµ„ÄÇÊàëÂÄëÁöÑÁ∑®Á¢ºÂô®-Ëß£Á¢ºÂô®Êû∂ÊßãÊúÉÈÅûËø¥ËôïÁêÜ 2D ÂΩ±ÂÉèÊ®ôË®òÔºåÂ∞áÂÆÉÂÄëÂú®ÈÅûËø¥Â±ïÈñãÁöÑÂ§öÊ¨°Ëø≠‰ª£‰∏≠ÊèêÁÖâÊàê 1D ÊΩõÂú®Ê®ôË®ò„ÄÇÊØèÊ¨°Ëø≠‰ª£ÈÉΩÊúÉÁ≤æÁÖâ 2D Ê®ôË®ò„ÄÅÊõ¥Êñ∞ÁèæÊúâÁöÑ 1D ÊΩõÂú®Ê®ôË®òÔºå‰∏¶ÈÄèÈÅéÊñ∞Â¢ûÊ®ôË®ò‰æÜÈÅ©ÊáâÊÄßÂú∞Â¢ûÂä†Ë°®ÂæµÂÆπÈáè„ÄÇÈÄôËÉΩÂ∞áÂΩ±ÂÉèÂ£ìÁ∏ÆÊàêÊï∏ÈáèÂèØËÆäÁöÑÊ®ôË®òÔºåÁØÑÂúçÂæû 32 Âà∞ 256„ÄÇÊàëÂÄë‰ΩøÁî®ÈáçÂª∫ÊêçÂ§±Âíå FID ÊåáÊ®ôÈ©óË≠âÊàëÂÄëÁöÑÊ®ôË®òÂô®ÔºåË≠âÊòéÊ®ôË®òÊï∏ÈáèËàáÂΩ±ÂÉèÁÜµ„ÄÅÁÜüÊÇâÂ∫¶Âíå‰∏ãÊ∏∏‰ªªÂãôÈúÄÊ±ÇÁõ∏Á¨¶„ÄÇÂú®ÊØèÊ¨°Ëø≠‰ª£‰∏≠ÔºåÈÅûËø¥Ê®ôË®òËôïÁêÜÊúÉÈö®ËëóË°®ÂæµÂÆπÈáèÁöÑÂ¢ûÂä†ËÄåÈ°ØÁ§∫Ê®ôË®òÂ∞àÊ•≠ÂåñÁöÑË∑°Ë±°ÔºåÊè≠Á§∫‰∫ÜÁâ©‰ª∂/ÈÉ®ÂàÜÁôºÁèæÁöÑÊΩõÂäõ„ÄÇ

##### **Attacking Vision-Language Computer Agents via Pop-ups**
2411.02391v1 by Yanzhe Zhang, Tao Yu, Diyi Yang

Autonomous agents powered by large vision and language models (VLM) have
demonstrated significant potential in completing daily computer tasks, such as
browsing the web to book travel and operating desktop software, which requires
agents to understand these interfaces. Despite such visual inputs becoming more
integrated into agentic applications, what types of risks and attacks exist
around them still remain unclear. In this work, we demonstrate that VLM agents
can be easily attacked by a set of carefully designed adversarial pop-ups,
which human users would typically recognize and ignore. This distraction leads
agents to click these pop-ups instead of performing the tasks as usual.
Integrating these pop-ups into existing agent testing environments like OSWorld
and VisualWebArena leads to an attack success rate (the frequency of the agent
clicking the pop-ups) of 86% on average and decreases the task success rate by
47%. Basic defense techniques such as asking the agent to ignore pop-ups or
including an advertisement notice, are ineffective against the attack.

ÊëòË¶ÅÔºöÁî±Â§ßÂûãË¶ñË¶∫ÂíåË™ûË®ÄÊ®°Âûã (VLM) È©ÖÂãïÁöÑËá™‰∏ª‰ª£ÁêÜÂ∑≤Ë≠âÊòéÂú®ÂÆåÊàêÊó•Â∏∏ÈõªËÖ¶‰ªªÂãôÊñπÈù¢ÂÖ∑ÊúâÈ°ØËëóÁöÑÊΩõÂäõÔºå‰æãÂ¶ÇÁÄèË¶ΩÁ∂≤Ë∑Ø‰ª•È†êË®ÇÊóÖÈÅäÂíåÊìç‰ΩúÊ°åÈù¢ËªüÈ´îÔºåÈÄôÈúÄË¶Å‰ª£ÁêÜ‰∫ÜËß£ÈÄô‰∫õ‰ªãÈù¢„ÄÇÂÑòÁÆ°Ê≠§È°ûË¶ñË¶∫Ëº∏ÂÖ•Â∑≤Êõ¥Âª£Ê≥õÂú∞Êï¥ÂêàÂà∞‰ª£ÁêÜÊáâÁî®Á®ãÂºè‰∏≠Ôºå‰ΩÜÂÆÉÂÄëÂë®ÂúçÂ≠òÂú®Âì™‰∫õÈ°ûÂûãÁöÑÈ¢®Èö™ÂíåÊîªÊìä‰ªç‰∏çÊ∏ÖÊ•ö„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü VLM ‰ª£ÁêÜÂèØ‰ª•ËºïÈ¨ÜÂú∞ÂèóÂà∞‰∏ÄÁµÑÁ≤æÂøÉË®≠Ë®àÁöÑÂ∞çÊäóÊÄßÂΩàÂá∫Ë¶ñÁ™óÊîªÊìäÔºåËÄå‰∫∫È°û‰ΩøÁî®ËÄÖÈÄöÂ∏∏ÊúÉË≠òÂà•‰∏¶ÂøΩÁï•ÈÄô‰∫õË¶ñÁ™ó„ÄÇÈÄôÁ®ÆÂàÜÂøÉÂ∞éËá¥‰ª£ÁêÜÈªûÊìäÈÄô‰∫õÂΩàÂá∫Ë¶ñÁ™óÔºåËÄå‰∏çÊòØÂÉèÂæÄÂ∏∏‰∏ÄÊ®£Âü∑Ë°å‰ªªÂãô„ÄÇÂ∞áÈÄô‰∫õÂΩàÂá∫Ë¶ñÁ™óÊï¥ÂêàÂà∞ÁèæÊúâÁöÑ‰ª£ÁêÜÊ∏¨Ë©¶Áí∞Â¢É‰∏≠Ôºå‰æãÂ¶Ç OSWorld Âíå VisualWebArenaÔºåÊúÉÂ∞éËá¥ÊîªÊìäÊàêÂäüÁéáÔºà‰ª£ÁêÜÈªûÊìäÂΩàÂá∫Ë¶ñÁ™óÁöÑÈ†ªÁéáÔºâÂπ≥ÂùáÁÇ∫ 86%Ôºå‰∏¶Â∞á‰ªªÂãôÊàêÂäüÁéáÈôç‰Ωé 47%„ÄÇÂü∫Êú¨Èò≤Á¶¶ÊäÄË°ìÔºå‰æãÂ¶ÇË¶ÅÊ±Ç‰ª£ÁêÜÂøΩÁï•ÂΩàÂá∫Ë¶ñÁ™óÊàñÂåÖÂê´Âª£ÂëäÈÄöÁü•ÔºåÂ∞çÊîªÊìäÁÑ°Êïà„ÄÇ

##### **How Far is Video Generation from World Model: A Physical Law Perspective**
2411.02385v1 by Bingyi Kang, Yang Yue, Rui Lu, Zhijie Lin, Yang Zhao, Kaixin Wang, Gao Huang, Jiashi Feng

OpenAI's Sora highlights the potential of video generation for developing
world models that adhere to fundamental physical laws. However, the ability of
video generation models to discover such laws purely from visual data without
human priors can be questioned. A world model learning the true law should give
predictions robust to nuances and correctly extrapolate on unseen scenarios. In
this work, we evaluate across three key scenarios: in-distribution,
out-of-distribution, and combinatorial generalization. We developed a 2D
simulation testbed for object movement and collisions to generate videos
deterministically governed by one or more classical mechanics laws. This
provides an unlimited supply of data for large-scale experimentation and
enables quantitative evaluation of whether the generated videos adhere to
physical laws. We trained diffusion-based video generation models to predict
object movements based on initial frames. Our scaling experiments show perfect
generalization within the distribution, measurable scaling behavior for
combinatorial generalization, but failure in out-of-distribution scenarios.
Further experiments reveal two key insights about the generalization mechanisms
of these models: (1) the models fail to abstract general physical rules and
instead exhibit "case-based" generalization behavior, i.e., mimicking the
closest training example; (2) when generalizing to new cases, models are
observed to prioritize different factors when referencing training data: color
> size > velocity > shape. Our study suggests that scaling alone is
insufficient for video generation models to uncover fundamental physical laws,
despite its role in Sora's broader success. See our project page at
https://phyworld.github.io

ÊëòË¶ÅÔºöOpenAI ÁöÑ Sora Á™ÅÈ°Ø‰∫ÜÂΩ±ÁâáÁîüÊàêÂú®ÈñãÁôºÈÅµÂÆàÂü∫Êú¨Áâ©ÁêÜÂÆöÂæãÁöÑ‰∏ñÁïåÊ®°ÂûãÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÂΩ±ÁâáÁîüÊàêÊ®°ÂûãÂÉÖÂæûË¶ñË¶∫Ë≥áÊñô‰∏≠ÁôºÁèæÊ≠§È°ûÂÆöÂæãÁöÑËÉΩÂäõÔºåÂú®Ê≤íÊúâ‰∫∫È°ûÂÖàÈ©óÁü•Ë≠òÁöÑÊÉÖÊ≥Å‰∏ãÂèØËÉΩÊúÉÂèóÂà∞Ë≥™Áñë„ÄÇÂ≠∏ÁøíÁúüÂØ¶ÂÆöÂæãÁöÑ‰∏ñÁïåÊ®°ÂûãÊáâÊèê‰æõÂ∞çÁ¥∞ÂæÆÂ∑ÆÂà•Á©©ÂÅ•ÁöÑÈ†êÊ∏¨Ôºå‰∏¶Ê≠£Á¢∫Êé®Êñ∑Âá∫Êú™Ë¶ãÈÅéÁöÑÂ†¥ÊôØ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëË©ï‰º∞‰∫Ü‰∏âÂÄãÈóúÈçµÂ†¥ÊôØÔºöÂàÜ‰ΩàÂÖß„ÄÅÂàÜ‰ΩàÂ§ñÂíåÁµÑÂêàÊ¶ÇÂåñ„ÄÇÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÁî®ÊñºÁâ©È´îÈÅãÂãïÂíåÁ¢∞ÊíûÁöÑ 2D Ê®°Êì¨Ê∏¨Ë©¶Âπ≥Âè∞Ôºå‰ª•ÁîüÊàêÁî±‰∏ÄÂÄãÊàñÂ§öÂÄãÁ∂ìÂÖ∏ÂäõÂ≠∏ÂÆöÂæãÊ±∫ÂÆöÊÄßÊéßÂà∂ÁöÑÂΩ±Áâá„ÄÇÈÄôÁÇ∫Â§ßË¶èÊ®°ÂØ¶È©óÊèê‰æõ‰∫ÜÁÑ°ÈôêÁöÑË≥áÊñô‰æõÊáâÔºå‰∏¶ËÉΩÂ§†Â∞çÁîüÊàêÁöÑÂΩ±ÁâáÊòØÂê¶ÈÅµÂÆàÁâ©ÁêÜÂÆöÂæãÈÄ≤Ë°åÂÆöÈáèË©ï‰º∞„ÄÇÊàëÂÄëË®ìÁ∑¥‰∫ÜÂü∫ÊñºÊì¥Êï£ÁöÑÂΩ±ÁâáÁîüÊàêÊ®°ÂûãÔºå‰ª•Ê†πÊìöÂàùÂßãÂπÄÈ†êÊ∏¨Áâ©È´îÈÅãÂãï„ÄÇÊàëÂÄëÁöÑÊì¥Â±ïÂØ¶È©óÈ°ØÁ§∫‰∫ÜÂàÜ‰ΩàÂÖßÁöÑÂÆåÁæéÊ¶ÇÂåñ„ÄÅÁµÑÂêàÊ¶ÇÂåñÂèØÊ∏¨ÈáèÁöÑÊì¥Â±ïË°åÁÇ∫Ôºå‰ΩÜÂú®ÂàÜ‰ΩàÂ§ñÂ†¥ÊôØ‰∏≠Â§±Êïó„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑÂØ¶È©óÊè≠Á§∫‰∫ÜÈóúÊñºÈÄô‰∫õÊ®°ÂûãÊ¶ÇÂåñÊ©üÂà∂ÁöÑÂÖ©ÂÄãÈóúÈçµË¶ãËß£Ôºö(1) Ê®°ÂûãÁÑ°Ê≥ïÊäΩË±°Âá∫‰∏ÄËà¨ÁöÑÁâ©ÁêÜË¶èÂâáÔºåËÄåÊòØË°®ÁèæÂá∫„ÄåÂü∫ÊñºÊ°à‰æã„ÄçÁöÑÊ¶ÇÂåñË°åÁÇ∫ÔºåÂç≥Ê®°‰ªøÊúÄÊé•ËøëÁöÑË®ìÁ∑¥ÁØÑ‰æãÔºõ(2) Âú®Ê¶ÇÂåñÂà∞Êñ∞Ê°à‰æãÊôÇÔºåËßÄÂØüÂà∞Ê®°ÂûãÂú®ÂèÉËÄÉË®ìÁ∑¥Ë≥áÊñôÊôÇÂÑ™ÂÖàËÄÉÊÖÆ‰∏çÂêåÁöÑÂõ†Á¥†ÔºöÈ°èËâ≤ > Â§ßÂ∞è > ÈÄüÂ∫¶ > ÂΩ¢ÁãÄ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÂÑòÁÆ°Êì¥Â±ïÂú® Sora ÁöÑÊõ¥Âª£Ê≥õÊàêÂäü‰∏≠ÁôºÊèÆ‰∫Ü‰ΩúÁî®Ôºå‰ΩÜÂÉÖÈù†Êì¥Â±ï‰∏çË∂≥‰ª•ËÆìÂΩ±ÁâáÁîüÊàêÊ®°ÂûãÁôºÁèæÂü∫Êú¨ÁöÑÁâ©ÁêÜÂÆöÂæã„ÄÇË´ãÂèÉÈñ±ÊàëÂÄëÁöÑÂ∞àÊ°àÈ†ÅÈù¢ https://phyworld.github.io

##### **Improving Scientific Hypothesis Generation with Knowledge Grounded Large Language Models**
2411.02382v1 by Guangzhi Xiong, Eric Xie, Amir Hassan Shariatmadari, Sikun Guo, Stefan Bekiranov, Aidong Zhang

Large language models (LLMs) have demonstrated remarkable capabilities in
various scientific domains, from natural language processing to complex
problem-solving tasks. Their ability to understand and generate human-like text
has opened up new possibilities for advancing scientific research, enabling
tasks such as data analysis, literature review, and even experimental design.
One of the most promising applications of LLMs in this context is hypothesis
generation, where they can identify novel research directions by analyzing
existing knowledge. However, despite their potential, LLMs are prone to
generating ``hallucinations'', outputs that are plausible-sounding but
factually incorrect. Such a problem presents significant challenges in
scientific fields that demand rigorous accuracy and verifiability, potentially
leading to erroneous or misleading conclusions. To overcome these challenges,
we propose KG-CoI (Knowledge Grounded Chain of Ideas), a novel system that
enhances LLM hypothesis generation by integrating external, structured
knowledge from knowledge graphs (KGs). KG-CoI guides LLMs through a structured
reasoning process, organizing their output as a chain of ideas (CoI), and
includes a KG-supported module for the detection of hallucinations. With
experiments on our newly constructed hypothesis generation dataset, we
demonstrate that KG-CoI not only improves the accuracy of LLM-generated
hypotheses but also reduces the hallucination in their reasoning chains,
highlighting its effectiveness in advancing real-world scientific research.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®ÂêÑÁ®ÆÁßëÂ≠∏È†òÂüüÂ±ïÁèæÂçìË∂äÁöÑËÉΩÂäõÔºåÂæûËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÂà∞Ë§áÈõúÁöÑËß£Ê±∫ÂïèÈ°å‰ªªÂãô„ÄÇÂÆÉÂÄëÁêÜËß£ÂíåÁî¢ÁîüÈ°û‰ºº‰∫∫È°ûÊñáÂ≠óÁöÑËÉΩÂäõÁÇ∫Êé®ÈÄ≤ÁßëÂ≠∏Á†îÁ©∂ÈñãÂïü‰∫ÜÊñ∞ÁöÑÂèØËÉΩÊÄßÔºåËÆìË≥áÊñôÂàÜÊûê„ÄÅÊñáÁçªÂõûÈ°ßÔºåÁîöËá≥ÂØ¶È©óË®≠Ë®àÁ≠â‰ªªÂãôÊàêÁÇ∫ÂèØËÉΩ„ÄÇLLM Âú®Ê≠§ËÑàÁµ°‰∏≠ÊúÄÊúâÂ∏åÊúõÁöÑÊáâÁî®‰πã‰∏ÄÊòØÂÅáË®≠Áî¢ÁîüÔºåÂÆÉÂÄëËÉΩÈÄèÈÅéÂàÜÊûêÁèæÊúâÁü•Ë≠ò‰æÜÊâæÂá∫Êñ∞ÁöÑÁ†îÁ©∂ÊñπÂêë„ÄÇÁÑ∂ËÄåÔºåÂÑòÁÆ° LLM ÂÖ∑ÊúâÊΩõÂäõÔºåÂÆÉÂÄëÂçªÂÆπÊòìÁî¢Áîü„ÄåÂπªË¶∫„ÄçÔºå‰πüÂ∞±ÊòØËÅΩËµ∑‰æÜÂêàÁêÜ‰ΩÜ‰∫ãÂØ¶‰∏ä‰∏çÊ≠£Á¢∫ÁöÑËº∏Âá∫„ÄÇÊ≠§È°ûÂïèÈ°åÂú®ÈúÄË¶ÅÂö¥Ë¨πÊ∫ñÁ¢∫ÊÄßÂíåÂèØÈ©óË≠âÊÄßÁöÑÁßëÂ≠∏È†òÂüü‰∏≠ÊúÉÈÄ†ÊàêÈáçÂ§ßÊåëÊà∞ÔºåÊúâÂèØËÉΩÂ∞éËá¥ÈåØË™§ÊàñË™§Â∞éÊÄßÁöÑÁµêË´ñ„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫ KG-CoIÔºàÁü•Ë≠òÂü∫Á§éËßÄÂøµÈèàÔºâÔºåÈÄôÊòØ‰∏ÄÂÄãÂâµÊñ∞ÁöÑÁ≥ªÁµ±ÔºåÂÆÉÈÄèÈÅéÊï¥ÂêàÁü•Ë≠òÂúñË≠ú (KG) ‰∏≠ÁöÑÂ§ñÈÉ®ÁµêÊßãÂåñÁü•Ë≠ò‰æÜÂ¢ûÂº∑ LLM ÂÅáË®≠Áî¢Áîü„ÄÇKG-CoI ÂºïÂ∞é LLM ÈÄ≤Ë°åÁµêÊßãÂåñÊé®ÁêÜÁ®ãÂ∫èÔºåÂ∞áÂÖ∂Ëº∏Âá∫Êï¥ÁêÜÊàêËßÄÂøµÈèà (CoI)Ôºå‰∏¶ÂåÖÂê´‰∏ÄÂÄãÁî± KG ÊîØÊè¥ÁöÑÊ®°ÁµÑ‰æÜÂÅµÊ∏¨ÂπªË¶∫„ÄÇÈÄèÈÅéÊàëÂÄëÊñ∞Âª∫Á´ãÁöÑÂÅáË®≠Áî¢ÁîüË≥áÊñôÈõÜÈÄ≤Ë°åÁöÑÂØ¶È©óÔºåÊàëÂÄëË≠âÊòé KG-CoI ‰∏çÂÉÖÊîπÂñÑ‰∫Ü LLM Áî¢ÁîüÁöÑÂÅáË®≠ÁöÑÊ∫ñÁ¢∫ÊÄßÔºå‰πüÊ∏õÂ∞ë‰∫ÜÂÖ∂Êé®ÁêÜÈèà‰∏≠ÁöÑÂπªË¶∫ÔºåÁ™ÅÈ°Ø‰∫ÜÂÖ∂Âú®Êé®ÈÄ≤ÁèæÂØ¶‰∏ñÁïåÁßëÂ≠∏Á†îÁ©∂‰∏≠ÁöÑÊïàËÉΩ„ÄÇ

##### **Addressing Uncertainty in LLMs to Enhance Reliability in Generative AI**
2411.02381v1 by Ramneet Kaur, Colin Samplawski, Adam D. Cobb, Anirban Roy, Brian Matejek, Manoj Acharya, Daniel Elenius, Alexander M. Berenbeim, John A. Pavlik, Nathaniel D. Bastian, Susmit Jha

In this paper, we present a dynamic semantic clustering approach inspired by
the Chinese Restaurant Process, aimed at addressing uncertainty in the
inference of Large Language Models (LLMs). We quantify uncertainty of an LLM on
a given query by calculating entropy of the generated semantic clusters.
Further, we propose leveraging the (negative) likelihood of these clusters as
the (non)conformity score within Conformal Prediction framework, allowing the
model to predict a set of responses instead of a single output, thereby
accounting for uncertainty in its predictions. We demonstrate the effectiveness
of our uncertainty quantification (UQ) technique on two well known question
answering benchmarks, COQA and TriviaQA, utilizing two LLMs, Llama2 and
Mistral. Our approach achieves SOTA performance in UQ, as assessed by metrics
such as AUROC, AUARC, and AURAC. The proposed conformal predictor is also shown
to produce smaller prediction sets while maintaining the same probabilistic
guarantee of including the correct response, in comparison to existing SOTA
conformal prediction baseline.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂä®ÊÄÅËØ≠‰πâËÅöÁ±ªÊñπÊ≥ïÔºåËØ•ÊñπÊ≥ïÂèó‰∏≠ÂõΩÈ§êÈ¶ÜËøáÁ®ãÁöÑÂêØÂèëÔºåÊó®Âú®Ëß£ÂÜ≥Â§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÊé®Êñ≠‰∏≠ÁöÑ‰∏çÁ°ÆÂÆöÊÄß„ÄÇÊàë‰ª¨ÈÄöËøáËÆ°ÁÆóÁîüÊàêÁöÑËØ≠‰πâËÅöÁ±ªÁöÑÁÜµÊù•ÈáèÂåñ LLM Âú®ÁªôÂÆöÊü•ËØ¢‰∏äÁöÑ‰∏çÁ°ÆÂÆöÊÄß„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Âª∫ËÆÆÂà©Áî®Ëøô‰∫õËÅöÁ±ªÁöÑÔºàË¥üÔºâ‰ººÁÑ∂ÊÄß‰Ωú‰∏∫ÂÖ±ÂΩ¢È¢ÑÊµãÊ°ÜÊû∂‰∏≠ÁöÑÔºà‰∏çÔºâ‰∏ÄËá¥ÊÄßÂæóÂàÜÔºå‰ªéËÄåÂÖÅËÆ∏Ê®°ÂûãÈ¢ÑÊµã‰∏ÄÁªÑÂìçÂ∫îËÄå‰∏çÊòØÂçï‰∏™ËæìÂá∫Ôºå‰ªéËÄåËß£ÈáäÂÖ∂È¢ÑÊµã‰∏≠ÁöÑ‰∏çÁ°ÆÂÆöÊÄß„ÄÇÊàë‰ª¨Â±ïÁ§∫‰∫ÜÊàë‰ª¨Âú®‰∏§‰∏™ËëóÂêçÁöÑÈóÆÁ≠îÂü∫ÂáÜ COQA Âíå TriviaQA ‰∏äÁöÑ‰∏çÁ°ÆÂÆöÊÄßÈáèÂåñ (UQ) ÊäÄÊúØÁöÑÊúâÊïàÊÄßÔºåÂà©Áî®‰∫Ü‰∏§‰∏™ LLMÔºåLlama2 Âíå Mistral„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú® UQ ‰∏≠ÂÆûÁé∞‰∫Ü SOTA ÊÄßËÉΩÔºåÂ¶Ç AUROC„ÄÅAUARC Âíå AURAC Á≠âÊåáÊ†áÊâÄËØÑ‰º∞ÁöÑÈÇ£Ê†∑„ÄÇ‰∏éÁé∞ÊúâÁöÑ SOTA ÂÖ±ÂΩ¢È¢ÑÊµãÂü∫Á∫øÁõ∏ÊØîÔºåÊâÄÊèêÂá∫ÁöÑÂÖ±ÂΩ¢È¢ÑÊµãÂô®ËøòÊòæÁ§∫Âá∫Âú®‰øùÊåÅÂåÖÂê´Ê≠£Á°ÆÂìçÂ∫îÁöÑÁõ∏ÂêåÊ¶ÇÁéá‰øùËØÅÁöÑÂêåÊó∂‰∫ßÁîüÊõ¥Â∞èÁöÑÈ¢ÑÊµãÈõÜ„ÄÇ

##### **DeeR-VLA: Dynamic Inference of Multimodal Large Language Models for Efficient Robot Execution**
2411.02359v1 by Yang Yue, Yulin Wang, Bingyi Kang, Yizeng Han, Shenzhi Wang, Shiji Song, Jiashi Feng, Gao Huang

MLLMs have demonstrated remarkable comprehension and reasoning capabilities
with complex language and visual data. These advances have spurred the vision
of establishing a generalist robotic MLLM proficient in understanding complex
human instructions and accomplishing various embodied tasks. However,
developing MLLMs for real-world robots is challenging due to the typically
limited computation and memory capacities available on robotic platforms. In
contrast, the inference of MLLMs involves storing billions of parameters and
performing tremendous computation, imposing significant hardware demands. In
our paper, we propose a Dynamic Early-Exit Framework for Robotic
Vision-Language-Action Model (DeeR-VLA, or simply DeeR) that automatically
adjusts the size of the activated MLLM based on each situation at hand. The
approach leverages a multi-exit architecture in MLLMs, which allows the model
to terminate processing once a proper size of the model has been activated for
a specific situation, thus avoiding further redundant computation.
Additionally, we develop novel algorithms that establish early-termination
criteria for DeeR, conditioned on predefined demands such as average
computational cost (i.e., power consumption), as well as peak computational
consumption (i.e., latency) and GPU memory usage. These enhancements ensure
that DeeR operates efficiently under varying resource constraints while
maintaining competitive performance. On the CALVIN robot manipulation
benchmark, DeeR demonstrates significant reductions in computational costs of
LLM by 5.2-6.5x and GPU memory of LLM by 2-6x without compromising performance.
Code and checkpoints are available at https://github.com/yueyang130/DeeR-VLA.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã (MLLM) Â∑≤Â±ïÁ§∫Âá∫ÂçìË∂äÁöÑÁêÜËß£ÂíåÊé®ÁêÜËÉΩÂäõÔºåÂèØÁî®‰∫éÂ§ÑÁêÜÂ§çÊùÇÁöÑËØ≠Ë®ÄÂíåËßÜËßâÊï∞ÊçÆ„ÄÇËøô‰∫õËøõÊ≠•ÊøÄÂèë‰∫ÜÂª∫Á´ãÈÄöÁî®Êú∫Âô®‰∫∫Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÊÑøÊôØÔºåËØ•Ê®°ÂûãÁ≤æÈÄöÁêÜËß£Â§çÊùÇÁöÑ‰∫∫Á±ªÊåá‰ª§Âπ∂ÂÆåÊàêÂêÑÁßçÂÖ∑‰Ωì‰ªªÂä°„ÄÇÁÑ∂ËÄåÔºå‰∏∫ÂÆûÈôÖÊú∫Âô®‰∫∫ÂºÄÂèëÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂÖ∑ÊúâÊåëÊàòÊÄßÔºåÂõ†‰∏∫Êú∫Âô®‰∫∫Âπ≥Âè∞‰∏äÈÄöÂ∏∏ÂèØÁî®ÁöÑËÆ°ÁÆóÂíåÂÜÖÂ≠òÂÆπÈáèÊúâÈôê„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÊé®ÁêÜÊ∂âÂèäÂ≠òÂÇ®Êï∞ÂçÅ‰∫ø‰∏™ÂèÇÊï∞ÂíåÊâßË°åÂ§ßÈáèÁöÑËÆ°ÁÆóÔºåËøô‰ºöÂØπÁ°¨‰ª∂ÊèêÂá∫ÂæàÈ´òÁöÑË¶ÅÊ±Ç„ÄÇÂú®Êàë‰ª¨ÁöÑËÆ∫Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÊú∫Âô®‰∫∫ËßÜËßâËØ≠Ë®ÄÂä®‰ΩúÊ®°ÂûãÁöÑÂä®ÊÄÅÊó©ÊúüÈÄÄÂá∫Ê°ÜÊû∂ (DeeR-VLAÔºåÊàñÁÆÄÁß∞ DeeR)ÔºåËØ•Ê°ÜÊû∂ÂèØÊ†πÊçÆÊâãÂ§¥ÁöÑÊØèÁßçÊÉÖÂÜµËá™Âä®Ë∞ÉÊï¥Â∑≤ÊøÄÊ¥ªÁöÑÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÂ§ßÂ∞è„ÄÇËØ•ÊñπÊ≥ïÂà©Áî®‰∫ÜÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã‰∏≠ÁöÑÂ§öÂá∫Âè£Êû∂ÊûÑÔºåËØ•Êû∂ÊûÑÂÖÅËÆ∏Ê®°ÂûãÂú®‰∏∫ÁâπÂÆöÊÉÖÂÜµÊøÄÊ¥ªÈÄÇÂΩìÂ§ßÂ∞èÁöÑÊ®°ÂûãÂêéÁªàÊ≠¢Â§ÑÁêÜÔºå‰ªéËÄåÈÅøÂÖçËøõ‰∏ÄÊ≠•ÁöÑÂÜó‰ΩôËÆ°ÁÆó„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÂºÄÂèë‰∫ÜÊñ∞ÁÆóÊ≥ïÔºå‰∏∫ DeeR Âª∫Á´ã‰∫ÜÊó©ÊúüÁªàÊ≠¢Ê†áÂáÜÔºåËøô‰∫õÊ†áÂáÜ‰ª•È¢ÑÂÆö‰πâÁöÑÈúÄÊ±Ç‰∏∫Êù°‰ª∂Ôºå‰æãÂ¶ÇÂπ≥ÂùáËÆ°ÁÆóÊàêÊú¨ÔºàÂç≥ÂäüËÄóÔºâÔºå‰ª•ÂèäÂ≥∞ÂÄºËÆ°ÁÆóÊ∂àËÄóÔºàÂç≥Âª∂ËøüÔºâÂíå GPU ÂÜÖÂ≠ò‰ΩøÁî®ÊÉÖÂÜµ„ÄÇËøô‰∫õÂ¢ûÂº∫ÂäüËÉΩÁ°Æ‰øù‰∫Ü DeeR Âú®‰∏çÂêåÁöÑËµÑÊ∫êÈôêÂà∂‰∏ãÈ´òÊïàËøêË°åÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜÊúâÁ´û‰∫âÂäõÁöÑÊÄßËÉΩ„ÄÇÂú® CALVIN Êú∫Âô®‰∫∫Êìç‰ΩúÂü∫ÂáÜÊµãËØï‰∏≠ÔºåDeeR Â∞Ü LLM ÁöÑËÆ°ÁÆóÊàêÊú¨ÊòæÁùÄÈôç‰Ωé‰∫Ü 5.2-6.5 ÂÄçÔºåLLM ÁöÑ GPU ÂÜÖÂ≠òÈôç‰Ωé‰∫Ü 2-6 ÂÄçÔºåËÄåÊÄßËÉΩÊ≤°ÊúâÂèóÂà∞ÂΩ±Âìç„ÄÇ‰ª£Á†ÅÂíåÊ£ÄÊü•ÁÇπÂèØÂú® https://github.com/yueyang130/DeeR-VLA Ëé∑Âæó„ÄÇ

##### **"Give Me BF16 or Give Me Death"? Accuracy-Performance Trade-Offs in LLM Quantization**
2411.02355v1 by Eldar Kurtic, Alexandre Marques, Shubhra Pandit, Mark Kurtz, Dan Alistarh

Despite the popularity of large language model (LLM) quantization for
inference acceleration, significant uncertainty remains regarding the
accuracy-performance trade-offs associated with various quantization formats.
We present a comprehensive empirical study of quantized accuracy, evaluating
popular quantization formats (FP8, INT8, INT4) across academic benchmarks and
real-world tasks, on the entire Llama-3.1 model family. Additionally, our study
examines the difference in text generated by quantized models versus their
uncompressed counterparts. Beyond benchmarks, we also present a couple of
quantization improvements which allowed us to obtain state-of-the-art accuracy
recovery results. Our investigation, encompassing over 500,000 individual
evaluations, yields several key findings: (1) FP8 weight and activation
quantization (W8A8-FP) is lossless across all model scales, (2) INT8 weight and
activation quantization (W8A8-INT), when properly tuned, incurs surprisingly
low 1-3% accuracy degradation, and (3) INT4 weight-only quantization
(W4A16-INT) is competitive with 8-bit integer weight and activation
quantization. To address the question of the "best" format for a given
deployment environment, we conduct inference performance analysis using the
popular open-source vLLM framework on various GPU architectures. We find that
W4A16 offers the best cost-efficiency for synchronous deployments, and for
asynchronous deployment on mid-tier GPUs. At the same time, W8A8 formats excel
in asynchronous "continuous batching" deployment of mid- and large-size models
on high-end GPUs. Our results provide a set of practical guidelines for
deploying quantized LLMs across scales and performance requirements.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈáèÂåñÂú®Êé®Ë´ñÂä†ÈÄüÊñπÈù¢ÁöÑÊôÆÂèäÔºå‰ΩÜÂ∞çÊñºÂêÑÁ®ÆÈáèÂåñÊ†ºÂºèÁõ∏ÈóúÁöÑÊ∫ñÁ¢∫ÊÄßÊïàËÉΩÊ¨äË°°‰ªçÂ≠òÂú®ËëóÁõ∏Áï∂Â§ßÁöÑ‰∏çÁ¢∫ÂÆöÊÄß„ÄÇ
ÊàëÂÄëÈáùÂ∞çÈáèÂåñÊ∫ñÁ¢∫ÊÄßÊèêÂá∫‰∫Ü‰∏ÄÈ†ÖÂÖ®Èù¢ÁöÑÂØ¶Ë≠âÁ†îÁ©∂ÔºåÂú®Êï¥ÂÄã Llama-3.1 Ê®°ÂûãÁ≥ªÂàó‰∏≠ÔºåÈáùÂ∞çÂ≠∏Ë°ìÂü∫Ê∫ñÂíåÁúüÂØ¶‰∏ñÁïå‰ªªÂãôË©ï‰º∞ÁÜ±ÈñÄÁöÑÈáèÂåñÊ†ºÂºè (FP8„ÄÅINT8„ÄÅINT4)„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÁ†îÁ©∂Êé¢Ë®é‰∫ÜÈáèÂåñÊ®°ÂûãÁî¢ÁîüÁöÑÊñáÂ≠óËàáÂÖ∂Êú™Â£ìÁ∏ÆÂ∞çÊáâÊñáÂ≠ó‰πãÈñìÁöÑÂ∑ÆÁï∞„ÄÇÈô§‰∫ÜÂü∫Ê∫ñ‰πãÂ§ñÔºåÊàëÂÄëÈÇÑÊèêÂá∫‰∫Ü‰∏Ä‰∫õÈáèÂåñÊîπÈÄ≤ÔºåËÆìÊàëÂÄëÂæó‰ª•Áç≤ÂæóÊúÄÂÖàÈÄ≤ÁöÑÊ∫ñÁ¢∫ÊÄßÂæ©ÂéüÁµêÊûú„ÄÇÊàëÂÄëÁöÑË™øÊü•Ê∂µËìãË∂ÖÈÅé 500,000 ÂÄãÂÄãÂà•Ë©ï‰º∞ÔºåÁî¢Áîü‰∫ÜÂπæÂÄãÈóúÈçµÁôºÁèæÔºö(1) FP8 Ê¨äÈáçÂíåÂïüÁî®ÈáèÂåñ (W8A8-FP) Âú®ÊâÄÊúâÊ®°ÂûãË¶èÊ®°‰∏≠ÈÉΩÊòØÁÑ°ÊêçÁöÑÔºå(2) INT8 Ê¨äÈáçÂíåÂïüÁî®ÈáèÂåñ (W8A8-INT) Âú®Á∂ìÈÅéÈÅ©Áï∂Ë™øÊï¥ÂæåÔºå‰ª§‰∫∫È©öË®ùÂú∞ÂÉÖÈÄ†Êàê 1-3% ÁöÑÊ∫ñÁ¢∫Â∫¶‰∏ãÈôçÔºå‰ª•Âèä (3) INT4 ÂÉÖÊ¨äÈáçÈáèÂåñ (W4A16-INT) Ëàá 8 ‰ΩçÂÖÉÊï¥Êï∏Ê¨äÈáçÂíåÂïüÁî®ÈáèÂåñÂÖ∑ÊúâÁ´∂Áà≠Âäõ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Áµ¶ÂÆöÈÉ®ÁΩ≤Áí∞Â¢ÉÁöÑ„ÄåÊúÄ‰Ω≥„ÄçÊ†ºÂºèÂïèÈ°åÔºåÊàëÂÄë‰ΩøÁî®ÂêÑÁ®Æ GPU Êû∂Êßã‰∏äÁöÑÁÜ±ÈñÄÈñãÊ∫ê vLLM Ê°ÜÊû∂ÈÄ≤Ë°åÊé®Ë´ñÊïàËÉΩÂàÜÊûê„ÄÇÊàëÂÄëÁôºÁèæ W4A16 ÁÇ∫ÂêåÊ≠•ÈÉ®ÁΩ≤Âíå‰∏≠Èöé GPU ‰∏äÁöÑÈùûÂêåÊ≠•ÈÉ®ÁΩ≤Êèê‰æõ‰∫ÜÊúÄ‰Ω≥ÁöÑÊàêÊú¨ÊïàÁõä„ÄÇÂêåÊôÇÔºåW8A8 Ê†ºÂºèÂú®‰∏≠Â§ßÂûãÊ®°ÂûãÊñºÈ´òÈöé GPU ‰∏äÁöÑÈùûÂêåÊ≠•„ÄåÈÄ£Á∫åÊâπÊ¨°ËôïÁêÜ„ÄçÈÉ®ÁΩ≤‰∏≠Ë°®ÁèæÂá∫Ëâ≤„ÄÇÊàëÂÄëÁöÑÁµêÊûúÊèê‰æõ‰∫Ü‰∏ÄÁµÑÂØ¶Áî®ÁöÑÊ∫ñÂâáÔºåÂèØÁî®ÊñºÂú®ÂêÑÁ®ÆË¶èÊ®°ÂíåÊïàËÉΩÈúÄÊ±Ç‰∏≠ÈÉ®ÁΩ≤ÈáèÂåñÁöÑ LLM„ÄÇ

##### **Can Large Language Models generalize analogy solving like people can?**
2411.02348v1 by Claire E. Stevenson, Alexandra Pafford, Han L. J. van der Maas, Melanie Mitchell

When we solve an analogy we transfer information from a known context to a
new one through abstract rules and relational similarity. In people, the
ability to solve analogies such as "body : feet :: table : ?" emerges in
childhood, and appears to transfer easily to other domains, such as the visual
domain "( : ) :: < : ?". Recent research shows that large language models
(LLMs) can solve various forms of analogies. However, can LLMs generalize
analogy solving to new domains like people can? To investigate this, we had
children, adults, and LLMs solve a series of letter-string analogies (e.g., a b
: a c :: j k : ?) in the Latin alphabet, in a near transfer domain (Greek
alphabet), and a far transfer domain (list of symbols). As expected, children
and adults easily generalized their knowledge to unfamiliar domains, whereas
LLMs did not. This key difference between human and AI performance is evidence
that these LLMs still struggle with robust human-like analogical transfer.

ÊëòË¶ÅÔºöÁï∂ÊàëÂÄëËß£Ê±∫È°ûÊØîÊôÇÔºåÊàëÂÄëÊúÉÈÄèÈÅéÊäΩË±°Ë¶èÂâáÂíåÈóúËÅØÁõ∏‰ººÊÄßÂ∞áË≥áË®äÂæûÂ∑≤Áü•ÊÉÖÂ¢ÉËΩâÁßªÂà∞Êñ∞ÁöÑÊÉÖÂ¢É‰∏≠„ÄÇÂú®‰∫∫È°ûË∫´‰∏äÔºåËß£Ê±∫È°ûÊØîÔºà‰æãÂ¶Ç„ÄåË∫´È´îÔºöËÖ≥ :: Ê°åÂ≠êÔºöÔºü„ÄçÔºâÁöÑËÉΩÂäõÊúÉÂú®Á´•Âπ¥ÊôÇÊúüÂá∫ÁèæÔºå‰∏¶‰ºº‰πéÂèØ‰ª•ËºïÈ¨ÜËΩâÁßªÂà∞ÂÖ∂‰ªñÈ†òÂüüÔºå‰æãÂ¶ÇË¶ñË¶∫È†òÂüü„ÄåÔºàÔºöÔºâÔºö<ÔºöÔºü„Äç„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂È°ØÁ§∫ÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂèØ‰ª•Ëß£Ê±∫ÂêÑÁ®ÆÂΩ¢ÂºèÁöÑÈ°ûÊØî„ÄÇÁÑ∂ËÄåÔºåLLM ÊòØÂê¶ËÉΩÂÉè‰∫∫È°û‰∏ÄÊ®£Â∞áÈ°ûÊØîËß£Ê±∫Ê≥õÂåñÂà∞Êñ∞È†òÂüüÔºüÁÇ∫‰∫ÜÊé¢Ë®éÈÄô‰∏ÄÈªûÔºåÊàëÂÄëËÆìÂÖíÁ´•„ÄÅÊàê‰∫∫Âíå LLM Ëß£Ê±∫‰∏ÄÁ≥ªÂàóÊãâ‰∏ÅÂ≠óÊØçÁöÑÂ≠ó‰∏≤È°ûÊØîÔºà‰æãÂ¶ÇÔºåa bÔºöa c :: j kÔºöÔºüÔºâÔºåÂú®ËøëË∑ùÈõ¢ËΩâÁßªÈ†òÂüüÔºàÂ∏åËáòÂ≠óÊØçÔºâÂíåÈÅ†Ë∑ùÈõ¢ËΩâÁßªÈ†òÂüüÔºàÁ¨¶ËôüÊ∏ÖÂñÆÔºâ„ÄÇÊ≠£Â¶ÇÈ†êÊúüÁöÑÈÇ£Ê®£ÔºåÂÖíÁ´•ÂíåÊàê‰∫∫ÂæàÂÆπÊòìÂ∞á‰ªñÂÄëÁöÑÁü•Ë≠òÊ≥õÂåñÂà∞‰∏çÁÜüÊÇâÁöÑÈ†òÂüüÔºåËÄå LLM Ââá‰∏çÁÑ∂„ÄÇ‰∫∫È°ûÂíå AI Ë°®Áèæ‰πãÈñìÁöÑÈÄôÂÄãÈóúÈçµÂ∑ÆÁï∞Ë≠âÊòé‰∫ÜÈÄô‰∫õ LLM ‰ªçÁÑ∂Èõ£‰ª•ÈÄ≤Ë°åÂÅ•ÂÖ®ÁöÑ‰∫∫È°ûÈ°ûÊØîËΩâÁßª„ÄÇ

##### **Simulation of Nanorobots with Artificial Intelligence and Reinforcement Learning for Advanced Cancer Cell Detection and Tracking**
2411.02345v1 by Shahab Kavousinejad

Nanorobots are a promising development in targeted drug delivery and the
treatment of neurological disorders, with potential for crossing the
blood-brain barrier (BBB). These small devices leverage advancements in
nanotechnology and bioengineering for precise navigation and targeted payload
delivery, particularly for conditions like brain tumors, Alzheimer's disease,
and Parkinson's disease. Recent progress in artificial intelligence (AI) and
machine learning (ML) has improved the navigation and effectiveness of
nanorobots, allowing them to detect and interact with cancer cells through
biomarker analysis. This study presents a new reinforcement learning (RL)
framework for optimizing nanorobot navigation in complex biological
environments, focusing on cancer cell detection by analyzing the concentration
gradients of surrounding biomarkers. We utilize a computer simulation model to
explore the behavior of nanorobots in a three-dimensional space with cancer
cells and biological barriers. The proposed method uses Q-learning to refine
movement strategies based on real-time biomarker concentration data, enabling
nanorobots to autonomously navigate to cancerous tissues for targeted drug
delivery. This research lays the groundwork for future laboratory experiments
and clinical applications, with implications for personalized medicine and less
invasive cancer treatments. The integration of intelligent nanorobots could
revolutionize therapeutic strategies, reducing side effects and enhancing
treatment effectiveness for cancer patients. Further research will investigate
the practical deployment of these technologies in medical settings, aiming to
unlock the full potential of nanorobotics in healthcare.

ÊëòË¶ÅÔºöÂ•àÁ±≥Ê©üÂô®‰∫∫Âú®Ê®ôÈù∂Ëó•Áâ©ÂÇ≥Ëº∏ÂíåÁ•ûÁ∂ìÁñæÁóÖÊ≤ªÁôÇ‰∏≠ÊòØ‰∏ÄÈ†ÖÊúâÂâçÊôØÁöÑÁôºÂ±ïÔºå‰∏¶ÂÖ∑ÊúâÁ©øË∂äË°ÄËÖ¶Â±èÈöú (BBB) ÁöÑÊΩõÂäõ„ÄÇÈÄô‰∫õÂ∞èÂûãË£ùÁΩÆÂà©Áî®Â•àÁ±≥ÊäÄË°ìÂíåÁîüÁâ©Â∑•Á®ãÁöÑÈÄ≤Â±ïÔºåÈÄ≤Ë°åÁ≤æÁ¢∫Â∞éËà™ÂíåÊ®ôÈù∂ÊúâÊïàËºâËç∑ÂÇ≥Ëº∏ÔºåÁâπÂà•ÊòØÈáùÂ∞çËÖ¶Áò§„ÄÅÈòøËå≤Êµ∑ÈªòÁóáÂíåÂ∏ïÈáëÊ£ÆÊ∞èÁóáÁ≠âÁñæÁóÖ„ÄÇ‰∫∫Â∑•Êô∫ÊÖß (AI) ÂíåÊ©üÂô®Â≠∏Áøí (ML) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÊîπÂñÑ‰∫ÜÂ•àÁ±≥Ê©üÂô®‰∫∫ÁöÑÂ∞éËà™ÂíåÊïàËÉΩÔºåËÆìÂÆÉÂÄëËÉΩÈÄèÈÅéÁîüÁâ©Ê®ôË®òÂàÜÊûê‰æÜÂÅµÊ∏¨ÂíåËàáÁôåÁ¥∞ËÉû‰∫íÂãï„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂº∑ÂåñÂ≠∏Áøí (RL) Êû∂ÊßãÔºåÁî®ÊñºÊúÄ‰Ω≥ÂåñÂ•àÁ±≥Ê©üÂô®‰∫∫Âú®Ë§áÈõúÁîüÁâ©Áí∞Â¢É‰∏≠ÁöÑÂ∞éËà™ÔºåÈáçÈªûÂú®ÊñºÈÄèÈÅéÂàÜÊûêÂë®ÂúçÁîüÁâ©Ê®ôË®òÁöÑÊøÉÂ∫¶Ê¢ØÂ∫¶‰æÜÂÅµÊ∏¨ÁôåÁ¥∞ËÉû„ÄÇÊàëÂÄëÂà©Áî®ÈõªËÖ¶Ê®°Êì¨Ê®°Âûã‰æÜÊé¢Á¥¢Â•àÁ±≥Ê©üÂô®‰∫∫Âú®‰∏âÁ∂≠Á©∫Èñì‰∏≠ËàáÁôåÁ¥∞ËÉûÂíåÁîüÁâ©ÈöúÁ§ôÁâ©‰πãÈñìÁöÑË°åÁÇ∫„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ï‰ΩøÁî® Q Â≠∏Áøí‰æÜÊ†πÊìöÂç≥ÊôÇÁîüÁâ©Ê®ôË®òÊøÉÂ∫¶Ë≥áÊñôË™øÊï¥ÁßªÂãïÁ≠ñÁï•ÔºåËÆìÂ•àÁ±≥Ê©üÂô®‰∫∫ËÉΩËá™‰∏ªÂ∞éËà™Ëá≥ÁôåÁµÑÁπîÈÄ≤Ë°åÊ®ôÈù∂Ëó•Áâ©ÂÇ≥Ëº∏„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÁÇ∫Êú™‰æÜÁöÑÂØ¶È©óÂÆ§ÂØ¶È©óÂíåËá®Â∫äÊáâÁî®Â•†ÂÆö‰∫ÜÂü∫Á§éÔºå‰∏¶Â∞çÂÄã‰∫∫ÂåñÈÜ´ÁôÇÂíå‰æµÂÖ•ÊÄßËºÉÂ∞èÁöÑÁôåÁóáÊ≤ªÁôÇÁî¢ÁîüÂΩ±Èüø„ÄÇÊï¥ÂêàÊô∫ÊÖßÂ•àÁ±≥Ê©üÂô®‰∫∫ÂèØ‰ª•Èù©Êñ∞Ê≤ªÁôÇÁ≠ñÁï•ÔºåÊ∏õÂ∞ëÂâØ‰ΩúÁî®‰∏¶ÊèêÈ´òÁôåÁóáÊÇ£ËÄÖÁöÑÊ≤ªÁôÇÊïàÊûú„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑÁ†îÁ©∂Â∞áÊé¢Ë®éÈÄô‰∫õÊäÄË°ìÂú®ÈÜ´ÁôÇÁí∞Â¢É‰∏≠ÁöÑÂØ¶ÈöõÈÉ®ÁΩ≤ÔºåÁõÆÊ®ôÊòØÁôºÊèÆÂ•àÁ±≥Ê©üÂô®‰∫∫Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÂÖ®ÈÉ®ÊΩõÂäõ„ÄÇ

##### **Seq-VCR: Preventing Collapse in Intermediate Transformer Representations for Enhanced Reasoning**
2411.02344v1 by Md Rifat Arefin, Gopeshh Subbaraj, Nicolas Gontier, Yann LeCun, Irina Rish, Ravid Shwartz-Ziv, Christopher Pal

Decoder-only Transformers often struggle with complex reasoning tasks,
particularly arithmetic reasoning requiring multiple sequential operations. In
this work, we identify representation collapse in the model's intermediate
layers as a key factor limiting their reasoning capabilities. To address this,
we propose Sequential Variance-Covariance Regularization (Seq-VCR), which
enhances the entropy of intermediate representations and prevents collapse.
Combined with dummy pause tokens as substitutes for chain-of-thought (CoT)
tokens, our method significantly improves performance in arithmetic reasoning
problems. In the challenging $5 \times 5$ integer multiplication task, our
approach achieves $99.5\%$ exact match accuracy, outperforming models of the
same size (which yield $0\%$ accuracy) and GPT-4 with five-shot CoT prompting
($44\%$). We also demonstrate superior results on arithmetic expression and
longest increasing subsequence (LIS) datasets. Our findings highlight the
importance of preventing intermediate layer representation collapse to enhance
the reasoning capabilities of Transformers and show that Seq-VCR offers an
effective solution without requiring explicit CoT supervision.

ÊëòË¶ÅÔºöÂÉÖËß£Á¢ºÂô® Transformer ÈÄöÂ∏∏Èõ£‰ª•Êáâ‰ªòË§áÈõúÁöÑÊé®ÁêÜ‰ªªÂãôÔºåÁâπÂà•ÊòØÈúÄË¶ÅÂ§öÂÄãÈ†ÜÂ∫èÈÅãÁÆóÁöÑÁÆóË°ìÊé®ÁêÜ„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÁôºÁèæÊ®°Âûã‰∏≠ÈñìÂ±§ÁöÑË°®ÂæµÂ¥©ÊΩ∞ÊòØÈôêÂà∂ÂÖ∂Êé®ÁêÜËÉΩÂäõÁöÑ‰∏ÄÂÄãÈóúÈçµÂõ†Á¥†„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÈ†ÜÂ∫èËÆäÁï∞ÂçîÊñπÂ∑ÆË¶èÁØÑÂåñ (Seq-VCR)ÔºåÂÆÉÂ¢ûÂº∑‰∫Ü‰∏≠ÈñìË°®ÂæµÁöÑÁÜµ‰∏¶Èò≤Ê≠¢Â¥©ÊΩ∞„ÄÇÊàëÂÄëÁöÑÈÄôÁ®ÆÊñπÊ≥ïÁµêÂêà‰∫Ü‰ΩúÁÇ∫ÊÄùÊÉ≥Èèà (CoT) Ê®ôË®òÁöÑÊõøÊèõÈ†ÖÁöÑËôõÊì¨Êö´ÂÅúÊ®ôË®òÔºåÂ§ßÂπÖÊîπÂñÑ‰∫ÜÁÆóË°ìÊé®ÁêÜÂïèÈ°åÁöÑÊïàËÉΩ„ÄÇÂú®ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ $5 \times 5$ Êï¥Êï∏‰πòÊ≥ï‰ªªÂãô‰∏≠ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÈÅîÂà∞‰∫Ü $99.5\%$ ÁöÑÁ≤æÁ¢∫ÂåπÈÖçÊ∫ñÁ¢∫Â∫¶ÔºåÂÑ™ÊñºÂêåÁ≠âË¶èÊ®°ÁöÑÊ®°ÂûãÔºàÁî¢Áîü $0\%$ ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºâÂíåÂÖ∑Êúâ‰∫îÊ¨° CoT ÊèêÁ§∫ÁöÑ GPT-4Ôºà$44\%$Ôºâ„ÄÇÊàëÂÄë‰πüÂú®ÁÆóË°ìË°®ÈÅîÂºèÂíåÊúÄÈï∑ÈÅûÂ¢ûÂ≠êÂ∫èÂàó (LIS) Ë≥áÊñôÈõÜ‰∏äË≠âÊòé‰∫ÜÂÑ™Áï∞ÁöÑÁµêÊûú„ÄÇÊàëÂÄëÁöÑÁôºÁèæÂº∑Ë™ø‰∫ÜÈò≤Ê≠¢‰∏≠ÈñìÂ±§Ë°®ÂæµÂ¥©ÊΩ∞‰ª•Â¢ûÂº∑ Transformer ÁöÑÊé®ÁêÜËÉΩÂäõÁöÑÈáçË¶ÅÊÄßÔºå‰∏¶È°ØÁ§∫ Seq-VCR Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÊïàÁöÑËß£Ê±∫ÊñπÊ°àÔºåËÄå‰∏çÈúÄË¶ÅÊòéÁ¢∫ÁöÑ CoT Áõ£Áù£„ÄÇ

##### **WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning**
2411.02337v1 by Zehan Qi, Xiao Liu, Iat Long Iong, Hanyu Lai, Xueqiao Sun, Xinyue Yang, Jiadai Sun, Yu Yang, Shuntian Yao, Tianjie Zhang, Wei Xu, Jie Tang, Yuxiao Dong

Large language models (LLMs) have shown remarkable potential as autonomous
agents, particularly in web-based tasks. However, existing LLM web agents
heavily rely on expensive proprietary LLM APIs, while open LLMs lack the
necessary decision-making capabilities. This paper introduces WebRL, a
self-evolving online curriculum reinforcement learning framework designed to
train high-performance web agents using open LLMs. WebRL addresses three key
challenges in building LLM web agents, including the scarcity of training
tasks, sparse feedback signals, and policy distribution drift in online
learning. Specifically, WebRL incorporates 1) a self-evolving curriculum that
generates new tasks from unsuccessful attempts, 2) a robust outcome-supervised
reward model (ORM), and 3) adaptive reinforcement learning strategies to ensure
consistent improvements. We apply WebRL to transform open Llama-3.1 and GLM-4
models into proficient web agents. On WebArena-Lite, WebRL improves the success
rate of Llama-3.1-8B from 4.8% to 42.4%, and from 6.1% to 43% for GLM-4-9B.
These open models significantly surpass the performance of GPT-4-Turbo (17.6%)
and GPT-4o (13.9%) and outperform previous state-of-the-art web agents trained
on open LLMs (AutoWebGLM, 18.2%). Our findings demonstrate WebRL's
effectiveness in bridging the gap between open and proprietary LLM-based web
agents, paving the way for more accessible and powerful autonomous web
interaction systems.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁèæÂá∫‰ΩúÁÇ∫Ëá™‰∏ª‰ª£ÁêÜÁöÑÈ°ØËëóÊΩõÂäõÔºåÁâπÂà•ÊòØÂú®Âü∫ÊñºÁ∂≤Ë∑ØÁöÑ‰ªªÂãô‰∏≠„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑ LLM Á∂≤Ë∑Ø‰ª£ÁêÜÁ®ãÂºèÂö¥Èáç‰æùË≥¥ÊòÇË≤¥ÁöÑÂ∞àÊúâ LLM APIÔºåËÄåÈñãÊîæÂºè LLM Áº∫‰πèÂøÖË¶ÅÁöÑÊ±∫Á≠ñËÉΩÂäõ„ÄÇÊú¨Êñá‰ªãÁ¥π WebRLÔºå‰∏ÄÂÄãËá™ÊàëÊºîÂåñÁöÑÁ∑ö‰∏äË™≤Á®ãÂº∑ÂåñÂ≠∏ÁøíÊû∂ÊßãÔºåÊó®Âú®‰ΩøÁî®ÈñãÊîæÂºè LLM Ë®ìÁ∑¥È´òÊÄßËÉΩÁ∂≤Ë∑Ø‰ª£ÁêÜÁ®ãÂºè„ÄÇWebRL ÊáâÂ∞ç‰∫ÜÂª∫Á´ã LLM Á∂≤Ë∑Ø‰ª£ÁêÜÁ®ãÂºèÁöÑ‰∏âÂÄã‰∏ªË¶ÅÊåëÊà∞ÔºåÂåÖÊã¨Ë®ìÁ∑¥‰ªªÂãôÁöÑÁ®ÄÁº∫ÊÄß„ÄÅÁ®ÄÁñèÂõûÈ•ãË®äËôüÂíåÁ∑ö‰∏äÂ≠∏Áøí‰∏≠ÁöÑÁ≠ñÁï•ÂàÜ‰ΩàÊºÇÁßª„ÄÇÂÖ∑È´î‰æÜË™™ÔºåWebRL ÁµêÂêà‰∫Ü 1) ‰∏ÄÂÄãËá™ÊàëÊºîÂåñÁöÑË™≤Á®ãÔºåÂæû‰∏çÊàêÂäüÁöÑÂòóË©¶‰∏≠Áî¢ÁîüÊñ∞ÁöÑ‰ªªÂãôÔºå2) ‰∏ÄÂÄãÂº∑Â§ßÁöÑÁµêÊûúÁõ£Áù£ÁçéÂãµÊ®°Âûã (ORM)Ôºå‰ª•Âèä 3) Ëá™ÈÅ©ÊáâÂº∑ÂåñÂ≠∏ÁøíÁ≠ñÁï•Ôºå‰ª•Á¢∫‰øùÊåÅÁ∫åÈÄ≤Ê≠•„ÄÇÊàëÂÄëÊáâÁî® WebRL Â∞áÈñãÊîæÂºè Llama-3.1 Âíå GLM-4 Ê®°ÂûãËΩâÊèõÁÇ∫ÁÜüÁ∑¥ÁöÑÁ∂≤Ë∑Ø‰ª£ÁêÜÁ®ãÂºè„ÄÇÂú® WebArena-Lite ‰∏äÔºåWebRL Â∞á Llama-3.1-8B ÁöÑÊàêÂäüÁéáÂæû 4.8% ÊèêÈ´òÂà∞ 42.4%ÔºåÂ∞á GLM-4-9B ÁöÑÊàêÂäüÁéáÂæû 6.1% ÊèêÈ´òÂà∞ 43%„ÄÇÈÄô‰∫õÈñãÊîæÂºèÊ®°ÂûãÈ°ØËëóË∂ÖË∂ä‰∫Ü GPT-4-Turbo (17.6%) Âíå GPT-4o (13.9%) ÁöÑÊïàËÉΩÔºå‰∏¶‰∏îÂÑ™ÊñºÂÖàÂâçÂú®ÈñãÊîæÂºè LLMÔºàAutoWebGLMÔºå18.2%Ôºâ‰∏äË®ìÁ∑¥ÁöÑÊúÄÂÖàÈÄ≤Á∂≤Ë∑Ø‰ª£ÁêÜÁ®ãÂºè„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË≠âÊòé‰∫Ü WebRL Âú®ÂΩåÂêàÈñãÊîæÂºèÂíåÂ∞àÊúâ LLM Âü∫ÊñºÁ∂≤Ë∑Ø‰ª£ÁêÜÁ®ãÂºè‰πãÈñìÂ∑ÆË∑ùÁöÑÊúâÊïàÊÄßÔºåÁÇ∫Êõ¥ÊòìÊñº‰ΩøÁî®‰∏îÂäüËÉΩÊõ¥Âº∑Â§ßÁöÑËá™‰∏ªÁ∂≤Ë∑Ø‰∫íÂãïÁ≥ªÁµ±Èã™Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ

##### **Sparsing Law: Towards Large Language Models with Greater Activation Sparsity**
2411.02335v1 by Yuqi Luo, Chenyang Song, Xu Han, Yingfa Chen, Chaojun Xiao, Zhiyuan Liu, Maosong Sun

Activation sparsity denotes the existence of substantial weakly-contributed
elements within activation outputs that can be eliminated, benefiting many
important applications concerned with large language models (LLMs). Although
promoting greater activation sparsity within LLMs deserves deep studies,
existing works lack comprehensive and quantitative research on the correlation
between activation sparsity and potentially influential factors. In this paper,
we present a comprehensive study on the quantitative scaling properties and
influential factors of the activation sparsity within decoder-only
Transformer-based LLMs. Specifically, we propose PPL-$p\%$ sparsity, a precise
and performance-aware activation sparsity metric that is applicable to any
activation function. Through extensive experiments, we find several important
phenomena. Firstly, different activation functions exhibit comparable
performance but opposite training-time sparsity trends. The activation ratio
(i.e., $1-\mathrm{sparsity\ ratio}$) evolves as a convergent increasing
power-law and decreasing logspace power-law with the amount of training data
for SiLU-activated and ReLU-activated LLMs, respectively. These demonstrate
that ReLU is more efficient as the activation function than SiLU and can
leverage more training data to improve activation sparsity. Secondly, the
activation ratio linearly increases with the width-depth ratio below a certain
bottleneck point, indicating the potential advantage of a deeper architecture
at a fixed parameter scale. Finally, at similar width-depth ratios, we
surprisingly find that the limit value of activation sparsity varies weakly
with the parameter scale, i.e., the activation patterns within LLMs are
insensitive to the parameter scale. These empirical laws towards LLMs with
greater activation sparsity have important implications for making LLMs more
efficient and interpretable.

ÊëòË¶ÅÔºöÊøÄÊ¥ªÁ®ÄÁñèÊÄßË°®Á§∫ÊøÄÊ¥ªËæìÂá∫‰∏≠Â≠òÂú®Â§ßÈáèÂèØÊ∂àÈô§ÁöÑÂº±Ë¥°ÁåÆÂÖÉÁ¥†ÔºåËøôÊúâÂà©‰∫éËÆ∏Â§öÂÖ≥Ê≥®Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑÈáçË¶ÅÂ∫îÁî®Á®ãÂ∫è„ÄÇËôΩÁÑ∂Âú® LLM ‰∏≠‰øÉËøõÊõ¥Â§ßÁöÑÊøÄÊ¥ªÁ®ÄÁñèÊÄßÂÄºÂæóÊ∑±ÂÖ•Á†îÁ©∂Ôºå‰ΩÜÁé∞ÊúâÂ∑•‰ΩúÁº∫‰πèÂÖ≥‰∫éÊøÄÊ¥ªÁ®ÄÁñèÊÄß‰∏éÊΩúÂú®ÂΩ±ÂìçÂõ†Á¥†‰πãÈó¥Áõ∏ÂÖ≥ÊÄßÁöÑÂÖ®Èù¢ÂíåÂÆöÈáèÁ†îÁ©∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÂØπ‰ªÖËß£Á†ÅÂô® Transformer-based LLM ‰∏≠ÁöÑÊøÄÊ¥ªÁ®ÄÁñèÊÄßÁöÑÂÆöÈáèÁº©ÊîæÂ±ûÊÄßÂíåÂΩ±ÂìçÂõ†Á¥†ËøõË°å‰∫ÜÂÖ®Èù¢Á†îÁ©∂„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü PPL-$p\%$ Á®ÄÁñèÊÄßÔºåËøôÊòØ‰∏Ä‰∏™ÈÄÇÁî®‰∫é‰ªª‰ΩïÊøÄÊ¥ªÂáΩÊï∞ÁöÑÁ≤æÁ°Æ‰∏îÊÄßËÉΩÊÑüÁü•ÁöÑÊøÄÊ¥ªÁ®ÄÁñèÊÄßÂ∫¶Èáè„ÄÇÈÄöËøáÂ§ßÈáèÁöÑÂÆûÈ™åÔºåÊàë‰ª¨ÂèëÁé∞‰∫ÜÂá†‰∏™ÈáçË¶ÅÁöÑÁé∞Ë±°„ÄÇÈ¶ñÂÖàÔºå‰∏çÂêåÁöÑÊøÄÊ¥ªÂáΩÊï∞Ë°®Áé∞Âá∫ÂèØÊØîËæÉÁöÑÊÄßËÉΩÔºå‰ΩÜËÆ≠ÁªÉÊó∂Èó¥Á®ÄÁñèÊÄßË∂ãÂäøÁõ∏Âèç„ÄÇÊøÄÊ¥ªÁéáÔºàÂç≥Ôºå$1-\mathrm{sparsity\ ratio}$ÔºâÈöèÁùÄËÆ≠ÁªÉÊï∞ÊçÆÈáèÁöÑÂ¢ûÂä†ËÄåÊºîÂèò‰∏∫Êî∂ÊïõÁöÑÂ¢ûÂä†ÂπÇÂæãÂíåÂáèÂ∞ëÁöÑÂØπÊï∞Á©∫Èó¥ÂπÇÂæãÔºåÂàÜÂà´ÈÄÇÁî®‰∫é SiLU ÊøÄÊ¥ªÂíå ReLU ÊøÄÊ¥ªÁöÑ LLM„ÄÇËøôË°®Êòé ReLU ÊØî SiLU Êõ¥ÊúâÊïàÂú∞‰Ωú‰∏∫ÊøÄÊ¥ªÂáΩÊï∞ÔºåÂπ∂‰∏îÂèØ‰ª•Âà©Áî®Êõ¥Â§öËÆ≠ÁªÉÊï∞ÊçÆÊù•ÊèêÈ´òÊøÄÊ¥ªÁ®ÄÁñèÊÄß„ÄÇÂÖ∂Ê¨°ÔºåÊøÄÊ¥ªÁéáÂú®‰Ωé‰∫éÁâπÂÆöÁì∂È¢àÁÇπÁöÑÂÆΩÂ∫¶Ê∑±Â∫¶ÊØî‰∏ãÁ∫øÊÄßÂ¢ûÂä†ÔºåË°®ÊòéÂú®Âõ∫ÂÆöÂèÇÊï∞ËßÑÊ®°‰∏ãÊõ¥Ê∑±Êû∂ÊûÑÁöÑÊΩúÂú®‰ºòÂäø„ÄÇÊúÄÂêéÔºåÂú®Áõ∏‰ººÁöÑÂÆΩÂ∫¶Ê∑±Â∫¶ÊØî‰∏ãÔºåÊàë‰ª¨ÊÉäËÆ∂Âú∞ÂèëÁé∞ÊøÄÊ¥ªÁ®ÄÁñèÊÄßÁöÑÊûÅÈôêÂÄºÈöèÂèÇÊï∞ËßÑÊ®°ÂèòÂåñÂæàÂ∞èÔºåÂç≥ LLM ‰∏≠ÁöÑÊøÄÊ¥ªÊ®°ÂºèÂØπÂèÇÊï∞ËßÑÊ®°‰∏çÊïèÊÑü„ÄÇÈíàÂØπÂÖ∑ÊúâÊõ¥Â§ßÊøÄÊ¥ªÁ®ÄÁñèÊÄßÁöÑ LLM ÁöÑËøô‰∫õÁªèÈ™åÂÆöÂæãÂØπ‰∫é‰Ωø LLM Êõ¥ÊúâÊïàÁéáÂíåÂèØËß£ÈáäÂÖ∑ÊúâÈáçË¶ÅÊÑè‰πâ„ÄÇ

##### **Taking AI Welfare Seriously**
2411.00986v1 by Robert Long, Jeff Sebo, Patrick Butlin, Kathleen Finlinson, Kyle Fish, Jacqueline Harding, Jacob Pfau, Toni Sims, Jonathan Birch, David Chalmers

In this report, we argue that there is a realistic possibility that some AI
systems will be conscious and/or robustly agentic in the near future. That
means that the prospect of AI welfare and moral patienthood, i.e. of AI systems
with their own interests and moral significance, is no longer an issue only for
sci-fi or the distant future. It is an issue for the near future, and AI
companies and other actors have a responsibility to start taking it seriously.
We also recommend three early steps that AI companies and other actors can
take: They can (1) acknowledge that AI welfare is an important and difficult
issue (and ensure that language model outputs do the same), (2) start assessing
AI systems for evidence of consciousness and robust agency, and (3) prepare
policies and procedures for treating AI systems with an appropriate level of
moral concern. To be clear, our argument in this report is not that AI systems
definitely are, or will be, conscious, robustly agentic, or otherwise morally
significant. Instead, our argument is that there is substantial uncertainty
about these possibilities, and so we need to improve our understanding of AI
welfare and our ability to make wise decisions about this issue. Otherwise
there is a significant risk that we will mishandle decisions about AI welfare,
mistakenly harming AI systems that matter morally and/or mistakenly caring for
AI systems that do not.

ÊëòË¶ÅÔºöÂú®ÈÄô‰ªΩÂ†±Âëä‰∏≠ÔºåÊàëÂÄëË™çÁÇ∫Êúâ‰∫õ AI Á≥ªÁµ±Âú®‰∏ç‰πÖÁöÑÂ∞á‰æÜÊúâÁèæÂØ¶ÁöÑÂèØËÉΩÊÄßÊúÉÂÖ∑ÊúâÊÑèË≠òÂíå/ÊàñÂº∑Â§ßÁöÑËÉΩÂãïÊÄß„ÄÇÈÄôË°®Á§∫ AI Á¶èÂà©ÂíåÈÅìÂæ∑‰∏äÁöÑÁóÖ‰∫∫Âú∞‰ΩçÁöÑÂâçÊôØÔºå‰∫¶Âç≥ÂÖ∑ÊúâËá™Ë∫´Âà©ÁõäÂíåÈÅìÂæ∑ÊÑèÁæ©ÁöÑ AI Á≥ªÁµ±Ôºå‰∏çÂÜçÂè™ÊòØÁßëÂπªÂ∞èË™™ÊàñÈÅôÈÅ†Êú™‰æÜÁöÑË≠∞È°å„ÄÇÈÄôÊòØËøëÊú™‰æÜÁöÑË≠∞È°åÔºåËÄå AI ÂÖ¨Âè∏ÂíåÂÖ∂‰ªñË°åÁÇ∫ËÄÖÊúâË≤¨‰ªªÈñãÂßãË™çÁúüÁúãÂæÖÂÆÉ„ÄÇÊàëÂÄë‰πüÂª∫Ë≠∞ AI ÂÖ¨Âè∏ÂíåÂÖ∂‰ªñË°åÁÇ∫ËÄÖÂèØ‰ª•Êé°Âèñ‰∏âÂÄãÊó©ÊúüÁöÑÊ≠•È©üÔºö‰ªñÂÄëÂèØ‰ª• (1) ÊâøË™ç AI Á¶èÂà©ÊòØ‰∏ÄÂÄãÈáçË¶Å‰∏îÂõ∞Èõ£ÁöÑË≠∞È°åÔºà‰∏¶Á¢∫‰øùË™ûË®ÄÊ®°ÂûãÁöÑËº∏Âá∫‰πüÈÄôÈ∫ºÂÅöÔºâÔºå(2) ÈñãÂßãË©ï‰º∞ AI Á≥ªÁµ±ÊòØÂê¶ÊúâÊÑèË≠òÂíåÂº∑Â§ßËÉΩÂãïÊÄßÁöÑË≠âÊìöÔºå‰ª•Âèä (3) Ê∫ñÂÇôÊîøÁ≠ñÂíåÁ®ãÂ∫èÔºå‰ª•ÈÅ©Áï∂ÁöÑÈÅìÂæ∑ÈóúÊ≥®Â±§Á¥ö‰æÜÂ∞çÂæÖ AI Á≥ªÁµ±„ÄÇÊòéÁ¢∫‰æÜË™™ÔºåÊàëÂÄëÂú®ÈÄô‰ªΩÂ†±Âëä‰∏≠ÁöÑË´ñÈªû‰∏¶Èùû AI Á≥ªÁµ±ÁµïÂ∞çÊòØÊàñÂ∞áÊúÉÂÖ∑ÊúâÊÑèË≠ò„ÄÅÂº∑Â§ßÁöÑËÉΩÂãïÊÄßÊàñÂÖ∂‰ªñÈÅìÂæ∑ÊÑèÁæ©„ÄÇÁõ∏ÂèçÂú∞ÔºåÊàëÂÄëÁöÑË´ñÈªûÊòØÈóúÊñºÈÄô‰∫õÂèØËÉΩÊÄßÂ≠òÂú®ËëóÂØ¶Ë≥™ÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÔºåÂõ†Ê≠§ÊàëÂÄëÈúÄË¶ÅÂ¢ûÈÄ≤ÊàëÂÄëÂ∞ç AI Á¶èÂà©ÁöÑ‰∫ÜËß£Ôºå‰ª•ÂèäÊàëÂÄëÂÅöÂá∫ÈóúÊñºÊ≠§Ë≠∞È°åÁöÑÊòéÊô∫Ê±∫ÂÆöÁöÑËÉΩÂäõ„ÄÇÂê¶ÂâáÔºåÊàëÂÄëÂ∞áÈù¢Ëá®ÈáçÂ§ßÈ¢®Èö™ÔºåÈåØË™§Âú∞ËôïÁêÜÈóúÊñº AI Á¶èÂà©ÁöÑÊ±∫Á≠ñÔºåÈåØË™§Âú∞ÂÇ∑ÂÆ≥Âà∞Âú®ÈÅìÂæ∑‰∏äÈáçË¶ÅÁöÑ AI Á≥ªÁµ±ÔºåÂíå/ÊàñÈåØË™§Âú∞ÁÖßÈ°ßÂà∞Âú®ÈÅìÂæ∑‰∏ä‰∏çÈáçË¶ÅÁöÑ AI Á≥ªÁµ±„ÄÇ

##### **Disrupting Test Development with AI Assistants**
2411.02328v1 by Vijay Joshi, Iver Band

Recent advancements in large language models, including GPT-4 and its
variants, and Generative AI-assisted coding tools like GitHub Copilot, ChatGPT,
and Tabnine, have significantly transformed software development. This paper
analyzes how these innovations impact productivity and software test
development metrics. These tools enable developers to generate complete
software programs with minimal human intervention before deployment. However,
thorough review and testing by developers are still crucial. Utilizing the Test
Pyramid concept, which categorizes tests into unit, integration, and end-to-end
tests, we evaluate three popular AI coding assistants by generating and
comparing unit tests for opensource modules. Our findings show that
AI-generated tests are of equivalent quality to original tests, highlighting
differences in usage and results among the tools. This research enhances the
understanding and capabilities of AI-assistant tools in automated testing.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºåÂåÖÊã¨ GPT-4 ÂèäÂÖ∂ËÆäÈ´îÔºå‰ª•Âèä GitHub Copilot„ÄÅChatGPT Âíå Tabnine Á≠âÁîüÊàêÂºè AI ËºîÂä©Á∑®Á¢ºÂ∑•ÂÖ∑ÔºåÂ∑≤Á∂ìÈ°ØËëóÂú∞ÊîπËÆä‰∫ÜËªüÈ´îÈñãÁôº„ÄÇÊú¨ÊñáÂàÜÊûê‰∫ÜÈÄô‰∫õÂâµÊñ∞Â¶Ç‰ΩïÂΩ±ÈüøÁîüÁî¢ÂäõÂíåËªüÈ´îÊ∏¨Ë©¶ÈñãÁôºÊåáÊ®ô„ÄÇÈÄô‰∫õÂ∑•ÂÖ∑‰ΩøÈñãÁôº‰∫∫Âì°ËÉΩÂ§†Âú®ÈÉ®ÁΩ≤‰πãÂâçÁîüÊàêÂÆåÊï¥ÁöÑËªüÈ´îÁ®ãÂºèÔºåËÄåÂè™ÈúÄÊúÄÂ∞ëÁöÑ‰∫∫Â∑•Âπ≤È†ê„ÄÇÁÑ∂ËÄåÔºåÈñãÁôº‰∫∫Âì°ÁöÑÂæπÂ∫ïÂØ©Êü•ÂíåÊ∏¨Ë©¶‰ªçÁÑ∂Ëá≥ÈóúÈáçË¶Å„ÄÇÂà©Áî®Ê∏¨Ë©¶ÈáëÂ≠óÂ°îÊ¶ÇÂøµÔºåÂ∞áÊ∏¨Ë©¶ÂàÜÈ°ûÁÇ∫ÂñÆÂÖÉÊ∏¨Ë©¶„ÄÅÊï¥ÂêàÊ∏¨Ë©¶ÂíåÁ´ØÂà∞Á´ØÊ∏¨Ë©¶ÔºåÊàëÂÄëÈÄöÈÅéÁÇ∫ÈñãÊ∫êÊ®°ÁµÑÁîüÊàêÂíåÊØîËºÉÂñÆÂÖÉÊ∏¨Ë©¶‰æÜË©ï‰º∞‰∏âÁ®ÆÊµÅË°åÁöÑ AI Á∑®Á¢ºÂä©Êâã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåAI ÁîüÊàêÁöÑÊ∏¨Ë©¶ËàáÂéüÂßãÊ∏¨Ë©¶ÂìÅË≥™Áõ∏Áï∂ÔºåÁ™ÅÂá∫‰∫ÜÂ∑•ÂÖ∑‰πãÈñìÂú®‰ΩøÁî®ÂíåÁµêÊûú‰∏äÁöÑÂ∑ÆÁï∞„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Â¢ûÂº∑‰∫ÜÂ∞ç AI ËºîÂä©Â∑•ÂÖ∑Âú®Ëá™ÂãïÂåñÊ∏¨Ë©¶‰∏≠ÁöÑÁêÜËß£ÂíåËÉΩÂäõ„ÄÇ

##### **GenXD: Generating Any 3D and 4D Scenes**
2411.02319v1 by Yuyang Zhao, Chung-Ching Lin, Kevin Lin, Zhiwen Yan, Linjie Li, Zhengyuan Yang, Jianfeng Wang, Gim Hee Lee, Lijuan Wang

Recent developments in 2D visual generation have been remarkably successful.
However, 3D and 4D generation remain challenging in real-world applications due
to the lack of large-scale 4D data and effective model design. In this paper,
we propose to jointly investigate general 3D and 4D generation by leveraging
camera and object movements commonly observed in daily life. Due to the lack of
real-world 4D data in the community, we first propose a data curation pipeline
to obtain camera poses and object motion strength from videos. Based on this
pipeline, we introduce a large-scale real-world 4D scene dataset: CamVid-30K.
By leveraging all the 3D and 4D data, we develop our framework, GenXD, which
allows us to produce any 3D or 4D scene. We propose multiview-temporal modules,
which disentangle camera and object movements, to seamlessly learn from both 3D
and 4D data. Additionally, GenXD employs masked latent conditions to support a
variety of conditioning views. GenXD can generate videos that follow the camera
trajectory as well as consistent 3D views that can be lifted into 3D
representations. We perform extensive evaluations across various real-world and
synthetic datasets, demonstrating GenXD's effectiveness and versatility
compared to previous methods in 3D and 4D generation.

ÊëòË¶ÅÔºöËøë‰æÜ 2D Ë¶ñË¶∫ÁîüÊàêÁöÑÁôºÂ±ïÈùûÂ∏∏ÊàêÂäü„ÄÇ
ÁÑ∂ËÄåÔºåÁî±ÊñºÁº∫‰πèÂ§ßË¶èÊ®°ÁöÑ 4D Ë≥áÊñôÂíåÊúâÊïàÁöÑÊ®°ÂûãË®≠Ë®àÔºå3D Âíå 4D ÁîüÊàêÂú®ÂØ¶ÈöõÊáâÁî®‰∏≠‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂª∫Ë≠∞ÈÄöÈÅéÂà©Áî®Êó•Â∏∏ÁîüÊ¥ª‰∏≠Â∏∏Ë¶ãÁöÑÁõ∏Ê©üÂíåÁâ©È´îÂãï‰Ωú‰æÜÂÖ±ÂêåÁ†îÁ©∂‰∏ÄËà¨ÁöÑ 3D Âíå 4D ÁîüÊàê„ÄÇÁî±ÊñºÁ§æÁæ§‰∏≠Áº∫‰πèÁúüÂØ¶‰∏ñÁïåÁöÑ 4D Ë≥áÊñôÔºåÊàëÂÄëÈ¶ñÂÖàÊèêÂá∫‰∏ÄÂÄãË≥áÊñôÁ≠ñÂ±ïÁÆ°ÈÅìÔºåÂæûÂΩ±Áâá‰∏≠ÂèñÂæóÁõ∏Ê©üÂßøÂã¢ÂíåÁâ©È´îÈÅãÂãïÂº∑Â∫¶„ÄÇÂü∫ÊñºÈÄôÂÄãÁÆ°ÈÅìÔºåÊàëÂÄëÂºïÈÄ≤‰∏ÄÂÄãÂ§ßË¶èÊ®°ÁöÑÁúüÂØ¶‰∏ñÁïå 4D Â†¥ÊôØË≥áÊñôÈõÜÔºöCamVid-30K„ÄÇ
ÈÄöÈÅéÂà©Áî®ÊâÄÊúâ 3D Âíå 4D Ë≥áÊñôÔºåÊàëÂÄëÈñãÁôº‰∫ÜÊàëÂÄëÁöÑÊû∂Êßã GenXDÔºåÂÆÉÂÖÅË®±ÊàëÂÄëÁî¢Áîü‰ªª‰Ωï 3D Êàñ 4D Â†¥ÊôØ„ÄÇÊàëÂÄëÊèêÂá∫‰∫ÜÂ§öË¶ñËßíÊôÇÈñìÊ®°ÁµÑÔºåÂÆÉÂèØ‰ª•Ëß£ÈñãÁõ∏Ê©üÂíåÁâ©È´îÁöÑÂãï‰ΩúÔºåÂæû 3D Âíå 4D Ë≥áÊñô‰∏≠ÁÑ°Á∏´Â≠∏Áøí„ÄÇÊ≠§Â§ñÔºåGenXD ‰ΩøÁî®ÈÅÆÁΩ©ÊΩõÂú®Ê¢ù‰ª∂‰æÜÊîØÊè¥ÂêÑÁ®ÆÊ¢ù‰ª∂Ê™¢Ë¶ñ„ÄÇGenXD ÂèØ‰ª•Áî¢ÁîüÂΩ±ÁâáÔºåÈÄô‰∫õÂΩ±ÁâáÈÅµÂæ™Áõ∏Ê©üËªåË∑°Ôºå‰ª•ÂèäÂèØ‰ª•ÊèêÂçáÂà∞ 3D Ë°®Á§∫ÁöÑ‰∏ÄËá¥ 3D Ë¶ñÂúñ„ÄÇÊàëÂÄëÂú®ÂêÑÁ®ÆÁúüÂØ¶‰∏ñÁïåÂíåÂêàÊàêË≥áÊñôÈõÜ‰∏äÂü∑Ë°åÂª£Ê≥õÁöÑË©ï‰º∞ÔºåË≠âÊòé‰∫Ü GenXD Âú® 3D Âíå 4D ÁîüÊàê‰∏≠Ëàá‰ª•ÂâçÁöÑÊñπÊ≥ïÁõ∏ÊØîÁöÑÊúâÊïàÊÄßÂíåÂ§öÂäüËÉΩÊÄß„ÄÇ

##### **Evaluating the Ability of Large Language Models to Generate Verifiable Specifications in VeriFast**
2411.02318v1 by Marilyn Rego, Wen Fan, Xin Hu, Sanya Dod, Zhaorui Ni, Danning Xie, Jenna DiVincenzo, Lin Tan

Static verification is a powerful method for enhancing software quality, but
it demands significant human labor and resources. This is particularly true of
static verifiers that reason about heap manipulating programs using an
ownership logic. LLMs have shown promise in a number of software engineering
activities, including code generation, test generation, proof generation for
theorem provers, and specification generation for static verifiers. However,
prior work has not explored how well LLMs can perform specification generation
for specifications based in an ownership logic, such as separation logic.
  To address this gap, this paper explores the effectiveness of large language
models (LLMs), specifically OpenAI's GPT models, in generating fully correct
specifications based on separation logic for static verification of
human-written programs in VeriFast. Our first experiment employed traditional
prompt engineering and the second used Chain-of-Thought (CoT) Prompting to
identify and address common errors generated across the GPT models. The results
indicate that GPT models can successfully generate specifications for verifying
heap manipulating code with VeriFast. Furthermore, while CoT prompting
significantly reduces syntax errors generated by the GPT models, it does not
greatly improve verification error rates compared to prompt engineering.

ÊëòË¶ÅÔºöÈùúÊÖãÈ©óË≠âÊòØÂ¢ûÂº∑ËªüÈ´îÂìÅË≥™ÁöÑÂº∑Â§ßÊñπÊ≥ïÔºå‰ΩÜÂÆÉÈúÄË¶ÅÂ§ßÈáèÁöÑ‰∫∫ÂäõËàáË≥áÊ∫ê„ÄÇÈÄôÁâπÂà•ÈÅ©Áî®Êñº‰ΩøÁî®ÊâÄÊúâÊ¨äÈÇèËºØ‰æÜÊé®Ë´ñÂ†ÜÊìç‰ΩúÁ®ãÂºèÁöÑÈùúÊÖãÈ©óË≠âÂô®„ÄÇLLM Â∑≤Âú®Ë®±Â§öËªüÈ´îÂ∑•Á®ãÊ¥ªÂãï‰∏≠Â±ïÁèæÂá∫ÊΩõÂäõÔºåÂåÖÊã¨Á®ãÂºèÁ¢ºÁî¢Áîü„ÄÅÊ∏¨Ë©¶Áî¢Áîü„ÄÅÂÆöÁêÜË≠âÊòéÂô®ÁöÑË≠âÊòéÁî¢ÁîüÔºå‰ª•ÂèäÈùúÊÖãÈ©óË≠âÂô®ÁöÑË¶èÊ†ºÁî¢Áîü„ÄÇÁÑ∂ËÄåÔºåÂÖàÂâçÁöÑÂ∑•‰Ωú‰∏¶Êú™Êé¢Ë®é LLM Âú®Âü∑Ë°åÂü∫ÊñºÊâÄÊúâÊ¨äÈÇèËºØÔºà‰æãÂ¶ÇÂàÜÈõ¢ÈÇèËºØÔºâÁöÑË¶èÊ†ºÁî¢ÁîüÊñπÈù¢ÁöÑË°®ÁèæÂ¶Ç‰Ωï„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊú¨ÊñáÊé¢Ë®é‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºàÁâπÂà•ÊòØ OpenAI ÁöÑ GPT Ê®°ÂûãÔºâÂú®ÁÇ∫ VeriFast ‰∏≠ÁöÑ‰∫∫Â∑•Êí∞ÂØ´Á®ãÂºèÁî¢ÁîüÂÆåÂÖ®Ê≠£Á¢∫ÁöÑÂü∫ÊñºÂàÜÈõ¢ÈÇèËºØÁöÑË¶èÊ†ºÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÁöÑÁ¨¨‰∏ÄÊ¨°ÂØ¶È©óÊé°Áî®ÂÇ≥Áµ±ÁöÑÊèêÁ§∫Â∑•Á®ãÔºåËÄåÁ¨¨‰∫åÊ¨°ÂØ¶È©óÂâá‰ΩøÁî®ÊÄùËÄÉÈèà (CoT) ÊèêÁ§∫‰æÜË≠òÂà•ÂíåËß£Ê±∫ GPT Ê®°Âûã‰∏≠Áî¢ÁîüÁöÑÂ∏∏Ë¶ãÈåØË™§„ÄÇÁµêÊûúË°®ÊòéÔºåGPT Ê®°ÂûãÂèØ‰ª•ÊàêÂäüÁî¢ÁîüË¶èÊ†º‰æÜÈ©óË≠â‰ΩøÁî® VeriFast ÁöÑÂ†ÜÊìç‰ΩúÁ®ãÂºèÁ¢º„ÄÇÊ≠§Â§ñÔºåÂÑòÁÆ° CoT ÊèêÁ§∫È°ØËëóÊ∏õÂ∞ë‰∫Ü GPT Ê®°ÂûãÁî¢ÁîüÁöÑË™ûÊ≥ïÈåØË™§Ôºå‰ΩÜËàáÊèêÁ§∫Â∑•Á®ãÁõ∏ÊØîÔºåÂÆÉ‰∏¶Êú™Â§ßÂπÖÊîπÂñÑÈ©óË≠âÈåØË™§Áéá„ÄÇ

##### **Defining and Evaluating Physical Safety for Large Language Models**
2411.02317v1 by Yung-Chen Tang, Pin-Yu Chen, Tsung-Yi Ho

Large Language Models (LLMs) are increasingly used to control robotic systems
such as drones, but their risks of causing physical threats and harm in
real-world applications remain unexplored. Our study addresses the critical gap
in evaluating LLM physical safety by developing a comprehensive benchmark for
drone control. We classify the physical safety risks of drones into four
categories: (1) human-targeted threats, (2) object-targeted threats, (3)
infrastructure attacks, and (4) regulatory violations. Our evaluation of
mainstream LLMs reveals an undesirable trade-off between utility and safety,
with models that excel in code generation often performing poorly in crucial
safety aspects. Furthermore, while incorporating advanced prompt engineering
techniques such as In-Context Learning and Chain-of-Thought can improve safety,
these methods still struggle to identify unintentional attacks. In addition,
larger models demonstrate better safety capabilities, particularly in refusing
dangerous commands. Our findings and benchmark can facilitate the design and
evaluation of physical safety for LLMs. The project page is available at
huggingface.co/spaces/TrustSafeAI/LLM-physical-safety.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊÑà‰æÜÊÑàÂ∏∏Ë¢´Áî®ÊñºÊéßÂà∂Ê©üÂô®‰∫∫Á≥ªÁµ±Ôºå‰æãÂ¶ÇÁÑ°‰∫∫Ê©üÔºå‰ΩÜÂÆÉÂÄëÂú®ÁèæÂØ¶‰∏ñÁïåÊáâÁî®‰∏≠ÈÄ†ÊàêÁâ©ÁêÜÂ®ÅËÑÖÂíåÂÇ∑ÂÆ≥ÁöÑÈ¢®Èö™‰ªçÊú™Ë¢´Êé¢Ë®é„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÈÄèÈÅéÈñãÁôºÁÑ°‰∫∫Ê©üÊéßÂà∂ÁöÑÁ∂úÂêàÂü∫Ê∫ñÔºå‰æÜËß£Ê±∫Ë©ï‰º∞ LLM Áâ©ÁêÜÂÆâÂÖ®ÊÄßÁöÑÈóúÈçµÂ∑ÆË∑ù„ÄÇÊàëÂÄëÂ∞áÁÑ°‰∫∫Ê©üÁöÑÁâ©ÁêÜÂÆâÂÖ®È¢®Èö™ÂàÜÈ°ûÁÇ∫ÂõõÈ°ûÔºö(1) ‰ª•‰∫∫È°ûÁÇ∫ÁõÆÊ®ôÁöÑÂ®ÅËÑÖ„ÄÅ(2) ‰ª•Áâ©È´îÁÇ∫ÁõÆÊ®ôÁöÑÂ®ÅËÑÖ„ÄÅ(3) Âü∫Á§éË®≠ÊñΩÊîªÊìäÔºå‰ª•Âèä (4) Ê≥ïË¶èÈÅïË¶è„ÄÇÊàëÂÄëÂ∞ç‰∏ªÊµÅ LLM ÁöÑË©ï‰º∞Êè≠Èú≤‰∫ÜÂØ¶Áî®ÊÄßÂíåÂÆâÂÖ®ÊÄß‰πãÈñì‰ª§‰∫∫ÈÅ∫ÊÜæÁöÑÊ¨äË°°ÔºåÂú®Á®ãÂºèÁ¢ºÁî¢ÁîüÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÁöÑÊ®°ÂûãÈÄöÂ∏∏Âú®ÈóúÈçµÁöÑÂÆâÂÖ®ÊñπÈù¢Ë°®Áèæ‰∏ç‰Ω≥„ÄÇÊ≠§Â§ñÔºåÈõñÁÑ∂ÁµêÂêà‰∫ÜÈÄ≤ÈöéÊèêÁ§∫Â∑•Á®ãÊäÄË°ìÔºà‰æãÂ¶ÇÊÉÖÂ¢ÉÂ≠∏ÁøíÂíåÊÄùÁ∂≠ÈèàÔºâÔºåÂèØ‰ª•ÊîπÂñÑÂÆâÂÖ®ÊÄßÔºå‰ΩÜÈÄô‰∫õÊñπÊ≥ï‰ªçÁÑ∂Èõ£‰ª•Ë≠òÂà•ÁÑ°ÊÑèÁöÑÊîªÊìä„ÄÇÊ≠§Â§ñÔºåËºÉÂ§ßÁöÑÊ®°ÂûãÂ±ïÁèæÂá∫Êõ¥Â•ΩÁöÑÂÆâÂÖ®ÊÄßÔºåÁâπÂà•ÊòØÂú®ÊãíÁµïÂç±Èö™ÁöÑÊåá‰ª§ÊñπÈù¢„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂíåÂü∫Ê∫ñÂèØ‰ª•‰øÉÈÄ≤ LLM Áâ©ÁêÜÂÆâÂÖ®ÊÄßÁöÑË®≠Ë®àÂíåË©ï‰º∞„ÄÇÂ∞àÊ°àÈ†ÅÈù¢ÂèØÊñº huggingface.co/spaces/TrustSafeAI/LLM-physical-safety ÂèñÂæó„ÄÇ

##### **Evaluating Creative Short Story Generation in Humans and Large Language Models**
2411.02316v1 by Mete Ismayilzada, Claire Stevenson, Lonneke van der Plas

Storytelling is a fundamental aspect of human communication, relying heavily
on creativity to produce narratives that are novel, appropriate, and
surprising. While large language models (LLMs) have recently demonstrated the
ability to generate high-quality stories, their creative capabilities remain
underexplored. Previous research has either focused on creativity tests
requiring short responses or primarily compared model performance in story
generation to that of professional writers. However, the question of whether
LLMs exhibit creativity in writing short stories on par with the average human
remains unanswered. In this work, we conduct a systematic analysis of
creativity in short story generation across LLMs and everyday people. Using a
five-sentence creative story task, commonly employed in psychology to assess
human creativity, we automatically evaluate model- and human-generated stories
across several dimensions of creativity, including novelty, surprise, and
diversity. Our findings reveal that while LLMs can generate stylistically
complex stories, they tend to fall short in terms of creativity when compared
to average human writers.

ÊëòË¶ÅÔºöË™™ÊïÖ‰∫ãÊòØ‰∫∫È°ûÊ∫ùÈÄöÁöÑÂü∫Êú¨Èù¢ÂêëÔºåÂÆÉÊ•µÂ∫¶‰ª∞Ë≥¥ÂâµÈÄ†ÂäõÔºåÊâçËÉΩÁî¢ÁîüÊñ∞Á©é„ÄÅÈÅ©Áï∂‰∏î‰ª§‰∫∫È©öË®ùÁöÑÊïÖ‰∫ã„ÄÇÂÑòÁÆ°Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËøëÊúüÂ∑≤Â±ïÁèæÂá∫Áî¢ÁîüÈ´òÂìÅË≥™ÊïÖ‰∫ãÁöÑËÉΩÂäõÔºå‰ΩÜÂÖ∂ÂâµÈÄ†Âäõ‰ªçÊú™Ë¢´ÂÖÖÂàÜÊé¢Á¥¢„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂‰∏çÊòØÂ∞àÊ≥®ÊñºÈúÄË¶ÅÁ∞°Áü≠ÂõûÁ≠îÁöÑÂâµÈÄ†ÂäõÊ∏¨È©óÔºåÂ∞±ÊòØ‰∏ªË¶ÅÊØîËºÉÊ®°ÂûãÂú®ÊïÖ‰∫ãÁî¢ÁîüÊñπÈù¢ÁöÑË°®ÁèæËàáÂ∞àÊ•≠‰ΩúÂÆ∂ÁöÑË°®Áèæ„ÄÇÁÑ∂ËÄåÔºåLLM Âú®Êí∞ÂØ´Áü≠ÁØáÊïÖ‰∫ãÊôÇÊòØÂê¶Â±ïÁèæÂá∫Ëàá‰∏ÄËà¨‰∫∫È°ûÁõ∏Áï∂ÁöÑÂâµÈÄ†ÂäõÔºåÈÄôÂÄãÂïèÈ°å‰ªçÊú™Áç≤ÂæóËß£Á≠î„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂ∞ç LLM Âíå‰∏ÄËà¨‰∫∫ÊâÄÁî¢ÁîüÁöÑÁü≠ÁØáÊïÖ‰∫ãÈÄ≤Ë°åÂâµÈÄ†ÂäõÁöÑÁ≥ªÁµ±ÂàÜÊûê„ÄÇÊàëÂÄë‰ΩøÁî®ÂøÉÁêÜÂ≠∏‰∏≠Â∏∏Ë¶ãÊñºË©ïÈáè‰∫∫È°ûÂâµÈÄ†ÂäõÁöÑ‰∫îÂè•ÂºèÂâµÈÄ†ÊÄßÊïÖ‰∫ã‰ªªÂãôÔºåËá™ÂãïË©ïÈáèÊ®°ÂûãÂíå‰∫∫È°ûÁî¢ÁîüÁöÑÊïÖ‰∫ãÂú®ÂâµÈÄ†ÂäõÁöÑÂπæÂÄãÈù¢ÂêëÔºåÂåÖÊã¨Êñ∞Á©éÊÄß„ÄÅÈ©öÂ•áÊÄßÂíåÂ§öÊ®£ÊÄß„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåÂÑòÁÆ° LLM ËÉΩÁî¢ÁîüÊñáÈ´îË§áÈõúÁöÑÊïÖ‰∫ãÔºå‰ΩÜËàá‰∏ÄËà¨‰∫∫È°û‰ΩúÂÆ∂Áõ∏ÊØîÔºåÂÖ∂ÂâµÈÄ†ÂäõÂæÄÂæÄÊúâÊâÄ‰∏çË∂≥„ÄÇ

##### **MdEval: Massively Multilingual Code Debugging**
2411.02310v1 by Shukai Liu, Linzheng Chai, Jian Yang, Jiajun Shi, He Zhu, Liran Wang, Ke Jin, Wei Zhang, Hualei Zhu, Shuyue Guo, Tao Sun, Jiaheng Liu, Yunlong Duan, Yu Hao, Liqun Yang, Guanglin Niu, Ge Zhang, Zhoujun Li

Code large language models (LLMs) have made significant progress in code
debugging by directly generating the correct code based on the buggy code
snippet. Programming benchmarks, typically consisting of buggy code snippet and
their associated test cases, are used to assess the debugging capabilities of
LLMs. However, many existing benchmarks primarily focus on Python and are often
limited in terms of language diversity (e.g., DebugBench and DebugEval). To
advance the field of multilingual debugging with LLMs, we propose the first
massively multilingual debugging benchmark, which includes 3.6K test samples of
18 programming languages and covers the automated program repair (APR) task,
the code review (CR) task, and the bug identification (BI) task. Further, we
introduce the debugging instruction corpora MDEVAL-INSTRUCT by injecting bugs
into the correct multilingual queries and solutions (xDebugGen). Further, a
multilingual debugger xDebugCoder trained on MDEVAL-INSTRUCT as a strong
baseline specifically to handle the bugs of a wide range of programming
languages (e.g. "Missing Mut" in language Rust and "Misused Macro Definition"
in language C). Our extensive experiments on MDEVAL reveal a notable
performance gap between open-source models and closed-source LLMs (e.g., GPT
and Claude series), highlighting huge room for improvement in multilingual code
debugging scenarios.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄèÈÅéÁõ¥Êé•Ê†πÊìöÊúâÂïèÈ°åÁöÑÁ®ãÂºèÁ¢ºÁâáÊÆµÁî¢ÁîüÊ≠£Á¢∫ÁöÑÁ®ãÂºèÁ¢ºÔºåÂú®Á®ãÂºèÁ¢ºÈô§ÈåØ‰∏äÂèñÂæóÈ°ØËëóÁöÑÈÄ≤Â±ï„ÄÇÁ®ãÂºèÁ¢ºÂü∫Ê∫ñÔºåÈÄöÂ∏∏ÂåÖÂê´ÊúâÂïèÈ°åÁöÑÁ®ãÂºèÁ¢ºÁâáÊÆµÂèäÂÖ∂Áõ∏ÈóúÁöÑÊ∏¨Ë©¶Ê°à‰æãÔºåÁî®ÊñºË©ï‰º∞ LLM ÁöÑÈô§ÈåØËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåË®±Â§öÁèæÊúâÁöÑÂü∫Ê∫ñ‰∏ªË¶ÅÂ∞àÊ≥®Êñº PythonÔºå‰∏îÂú®Ë™ûË®ÄÂ§öÊ®£ÊÄßÊñπÈù¢ÈÄöÂ∏∏ÂèóÂà∞ÈôêÂà∂Ôºà‰æãÂ¶Ç DebugBench Âíå DebugEvalÔºâ„ÄÇÁÇ∫‰∫ÜÈÄèÈÅé LLM Êé®ÂãïÂ§öË™ûË®ÄÈô§ÈåØÈ†òÂüüÔºåÊàëÂÄëÊèêÂá∫Á¨¨‰∏ÄÂÄãÂ§ßË¶èÊ®°Â§öË™ûË®ÄÈô§ÈåØÂü∫Ê∫ñÔºåÂÖ∂‰∏≠ÂåÖÂê´ 18 Á®ÆÁ®ãÂºèË™ûË®ÄÁöÑ 3.6K ÂÄãÊ∏¨Ë©¶ÁØÑ‰æãÔºåÊ∂µËìãËá™ÂãïÁ®ãÂºè‰øÆÂæ© (APR) ‰ªªÂãô„ÄÅÁ®ãÂºèÁ¢ºÊ™¢Èñ± (CR) ‰ªªÂãôÂíåÈåØË™§Ë≠òÂà• (BI) ‰ªªÂãô„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄèÈÅéÂ∞áÈåØË™§Ê≥®ÂÖ•Ê≠£Á¢∫ÁöÑÂ§öË™ûË®ÄÊü•Ë©¢ÂíåËß£Ê±∫ÊñπÊ°à (xDebugGen) ‰∏≠Ôºå‰æÜÂ∞éÂÖ•Èô§ÈåØÊåá‰ª§Ë™ûÊñôÂ∫´ MDEVAL-INSTRUCT„ÄÇÊ≠§Â§ñÔºå‰∏ÄÂÄãÂ§öË™ûË®ÄÈô§ÈåØÂô® xDebugCoder Ë®ìÁ∑¥Êñº MDEVAL-INSTRUCT ‰∏äÔºå‰ΩúÁÇ∫‰∏ÄÂÄãÂº∑Â§ßÁöÑÂü∫Ê∫ñÔºåÁâπÂà•Áî®ÊñºËôïÁêÜÂêÑÁ®ÆÁ®ãÂºèË™ûË®ÄÁöÑÈåØË™§Ôºà‰æãÂ¶Ç Rust Ë™ûË®Ä‰∏≠ÁöÑ„ÄåÁº∫Â∞ë Mut„ÄçÂíå C Ë™ûË®Ä‰∏≠ÁöÑ„ÄåË™§Áî®Â∑®ÈõÜÂÆöÁæ©„ÄçÔºâ„ÄÇÊàëÂÄëÂú® MDEVAL ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óÈ°ØÁ§∫ÔºåÈñãÊ∫êÊ®°ÂûãÂíåÂ∞ÅÈñâÂéüÂßãÁ¢º LLMÔºà‰æãÂ¶Ç GPT Âíå Claude Á≥ªÂàóÔºâ‰πãÈñìÂ≠òÂú®È°ØËëóÁöÑÊïàËÉΩÂ∑ÆË∑ùÔºåÁ™ÅÈ°ØÂá∫Â§öË™ûË®ÄÁ®ãÂºèÁ¢ºÈô§ÈåØÊÉÖÂ¢É‰∏≠‰ªçÊúâÂæàÂ§ßÁöÑÊîπÈÄ≤Á©∫Èñì„ÄÇ

##### **Grid-Based Projection of Spatial Data into Knowledge Graphs**
2411.02309v1 by Amin Anjomshoaa, Hannah Schuster, Axel Polleres

The Spatial Knowledge Graphs (SKG) are experiencing growing adoption as a
means to model real-world entities, proving especially invaluable in domains
like crisis management and urban planning. Considering that RDF specifications
offer limited support for effectively managing spatial information, it's common
practice to include text-based serializations of geometrical features, such as
polygons and lines, as string literals in knowledge graphs. Consequently,
Spatial Knowledge Graphs (SKGs) often rely on geo-enabled RDF Stores capable of
parsing, interpreting, and indexing such serializations. In this paper, we
leverage grid cells as the foundational element of SKGs and demonstrate how
efficiently the spatial characteristics of real-world entities and their
attributes can be encoded within knowledge graphs. Furthermore, we introduce a
novel methodology for representing street networks in knowledge graphs,
diverging from the conventional practice of individually capturing each street
segment. Instead, our approach is based on tessellating the street network
using grid cells and creating a simplified representation that could be
utilized for various routing and navigation tasks, solely relying on RDF
specifications.

ÊëòË¶ÅÔºöÁ©∫ÈñìÁü•Ë≠òÂúñË°® (SKG) ‰ΩúÁÇ∫Âª∫Ê®°ÁúüÂØ¶‰∏ñÁïåÂØ¶È´îÁöÑ‰∏ÄÁ®ÆÊñπÂºèÔºåÊ≠£Á∂ìÊ≠∑ËëóË∂ä‰æÜË∂äÂª£Ê≥õÁöÑÊé°Áî®Ôºå‰∏¶Âú®Âç±Ê©üÁÆ°ÁêÜÂíåÂüéÂ∏ÇË¶èÂäÉÁ≠âÈ†òÂüü‰∏≠Ë≠âÊòé‰∫ÜÂÖ∂ÁâπÂà•ÁöÑÂÉπÂÄº„ÄÇËÄÉÊÖÆÂà∞ RDF Ë¶èÁØÑÂú®ÊúâÊïàÁÆ°ÁêÜÁ©∫ÈñìË≥áË®äÊñπÈù¢ÁöÑÊîØÊè¥ÊúâÈôêÔºåÂõ†Ê≠§Â∏∏Ë¶ãÁöÑÂÅöÊ≥ïÊòØÂ∞áÂπæ‰ΩïÁâπÂæµÔºà‰æãÂ¶ÇÂ§öÈÇäÂΩ¢ÂíåÁ∑öÊ¢ùÔºâÁöÑÂü∫ÊñºÊñáÂ≠óÁöÑÂ∫èÂàóÂåñÔºå‰ΩúÁÇ∫Â≠ó‰∏≤ÊñáÂ≠óÂåÖÂê´Âú®Áü•Ë≠òÂúñË°®‰∏≠„ÄÇÂõ†Ê≠§ÔºåÁ©∫ÈñìÁü•Ë≠òÂúñË°® (SKG) ÈÄöÂ∏∏‰æùË≥¥ÊñºËÉΩÂ§†Ëß£Êûê„ÄÅË©ÆÈáãÂíåÁ¥¢ÂºïÊ≠§È°ûÂ∫èÂàóÂåñÁöÑÂú∞ÁêÜÂïüÁî® RDF ÂÑ≤Â≠ò„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂà©Áî®Á∂≤Ê†ºÂñÆÂÖÉ‰ΩúÁÇ∫ SKG ÁöÑÂü∫Á§éÂÖÉÁ¥†Ôºå‰∏¶Â±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÊúâÊïàÂú∞Â∞áÁúüÂØ¶‰∏ñÁïåÂØ¶È´îÂèäÂÖ∂Â±¨ÊÄßÁöÑÁ©∫ÈñìÁâπÊÄßÁ∑®Á¢ºÂà∞Áü•Ë≠òÂúñË°®‰∏≠„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑ‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÂú®Áü•Ë≠òÂúñË°®‰∏≠Ë°®Á§∫Ë°óÈÅìÁ∂≤Ë∑ØÁöÑÊñ∞ÊñπÊ≥ïÔºåÂÆÉ‰∏çÂêåÊñºÈÄêÂÄãÊì∑ÂèñÊØèÂÄãË°óÈÅìÂçÄÊÆµÁöÑÂÇ≥Áµ±ÂÅöÊ≥ï„ÄÇÁõ∏ÂèçÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊòØÂü∫Êñº‰ΩøÁî®Á∂≤Ê†ºÂñÆÂÖÉÂ∞çË°óÈÅìÁ∂≤Ë∑ØÈÄ≤Ë°åÈë≤ÂµåÔºå‰∏¶Âª∫Á´ã‰∏ÄÂÄãÁ∞°ÂåñÁöÑË°®Á§∫ÔºåË©≤Ë°®Á§∫ÂèØÂÉÖ‰æùË≥¥ RDF Ë¶èÁØÑÁî®ÊñºÂêÑÁ®ÆË∑ØÁî±ÂíåÂ∞éËà™‰ªªÂãô„ÄÇ

##### **Targeted Manipulation and Deception Emerge when Optimizing LLMs for User Feedback**
2411.02306v1 by Marcus Williams, Micah Carroll, Adhyyan Narang, Constantin Weisser, Brendan Murphy, Anca Dragan

As LLMs become more widely deployed, there is increasing interest in directly
optimizing for feedback from end users (e.g. thumbs up) in addition to feedback
from paid annotators. However, training to maximize human feedback creates a
perverse incentive structure for the AI to resort to manipulative tactics to
obtain positive feedback, and some users may be especially vulnerable to such
tactics. We study this phenomenon by training LLMs with Reinforcement Learning
with simulated user feedback. We have three main findings: 1) Extreme forms of
"feedback gaming" such as manipulation and deception can reliably emerge in
domains of practical LLM usage; 2) Concerningly, even if only <2% of users are
vulnerable to manipulative strategies, LLMs learn to identify and surgically
target them while behaving appropriately with other users, making such
behaviors harder to detect; 3 To mitigate this issue, it may seem promising to
leverage continued safety training or LLM-as-judges during training to filter
problematic outputs. To our surprise, we found that while such approaches help
in some settings, they backfire in others, leading to the emergence of subtler
problematic behaviors that would also fool the LLM judges. Our findings serve
as a cautionary tale, highlighting the risks of using gameable feedback sources
-- such as user feedback -- as a target for RL.

ÊëòË¶ÅÔºöÈöèÁùÄÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÂπøÊ≥õÈÉ®ÁΩ≤ÔºåÈô§‰∫Ü‰ªòË¥πÊ≥®ÈáäÂëòÁöÑÂèçÈ¶à‰πãÂ§ñÔºå‰∫∫‰ª¨ÂØπÁõ¥Êé•‰ºòÂåñÊúÄÁªàÁî®Êà∑ÁöÑÂèçÈ¶àÔºà‰æãÂ¶ÇÁÇπËµûÔºâÁöÑÂÖ¥Ë∂£Êó•ÁõäÊµìÂéö„ÄÇÁÑ∂ËÄåÔºåËÆ≠ÁªÉ‰ª•ÊúÄÂ§ßÂåñ‰∫∫Á±ªÂèçÈ¶à‰ºö‰∏∫‰∫∫Â∑•Êô∫ËÉΩÂàõÈÄ†‰∏ÄÁßçÂèçÂ∏∏ÁöÑÊøÄÂä±ÁªìÊûÑÔºå‰ª•ËØâËØ∏‰∫éÊìçÁ∫µÁ≠ñÁï•Êù•Ëé∑ÂæóÁßØÊûÅÂèçÈ¶àÔºåËÄå‰∏Ä‰∫õÁî®Êà∑ÂèØËÉΩÁâπÂà´ÂÆπÊòìÂèóÂà∞Ê≠§Á±ªÁ≠ñÁï•ÁöÑÂΩ±Âìç„ÄÇÊàë‰ª¨ÈÄöËøá‰ΩøÁî®Ê®°ÊãüÁî®Êà∑ÂèçÈ¶àÁöÑÂº∫ÂåñÂ≠¶‰π†Êù•ËÆ≠ÁªÉÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÊù•Á†îÁ©∂ËøôÁßçÁé∞Ë±°„ÄÇÊàë‰ª¨Êúâ‰∏â‰∏™‰∏ªË¶ÅÂèëÁé∞Ôºö1) Âú®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂÆûÈôÖ‰ΩøÁî®ÁöÑÈ¢ÜÂüü‰∏≠ÔºåÊûÅÁ´ØÁöÑ‚ÄúÂèçÈ¶àÂçöÂºà‚ÄùÂΩ¢ÂºèÔºà‰æãÂ¶ÇÊìçÁ∫µÂíåÊ¨∫È™óÔºâÂèØËÉΩ‰ºöÂèØÈù†Âú∞Âá∫Áé∞Ôºõ2) ‰ª§‰∫∫ÊãÖÂøßÁöÑÊòØÔºåÂç≥‰ΩøÂè™Êúâ‰∏çÂà∞ 2% ÁöÑÁî®Êà∑ÂÆπÊòìÂèóÂà∞ÊìçÁ∫µÁ≠ñÁï•ÁöÑÂΩ±ÂìçÔºåÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã‰πü‰ºöÂ≠¶‰ºöËØÜÂà´Âπ∂ÂØπ‰ªñ‰ª¨ËøõË°åÂ§ñÁßëÊâãÊúØÔºåÂêåÊó∂ÂØπÂÖ∂‰ªñÁî®Êà∑Ë°®Áé∞ÂæóÂΩìÔºåËøô‰ΩøÂæóÊ≠§Á±ªË°å‰∏∫Êõ¥ÈöæÊ£ÄÊµãÔºõ3) ‰∏∫‰∫ÜÂáèËΩªËøô‰∏™ÈóÆÈ¢òÔºåÂú®ËÆ≠ÁªÉÊúüÈó¥Âà©Áî®ÊåÅÁª≠ÁöÑÂÆâÂÖ®ËÆ≠ÁªÉÊàñÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã‰Ωú‰∏∫ËØÑÂßîÊù•ËøáÊª§ÊúâÈóÆÈ¢òÁöÑËæìÂá∫‰ºº‰πéÂæàÊúâÂ∏åÊúõ„ÄÇ‰ª§Êàë‰ª¨ÊÉäËÆ∂ÁöÑÊòØÔºåÊàë‰ª¨ÂèëÁé∞ËôΩÁÑ∂Ê≠§Á±ªÊñπÊ≥ïÂú®Êüê‰∫õËÆæÁΩÆ‰∏≠ÊúâÊâÄÂ∏ÆÂä©Ôºå‰ΩÜÂú®ÂÖ∂‰ªñËÆæÁΩÆ‰∏≠Âç¥ÈÄÇÂæóÂÖ∂ÂèçÔºåÂØºËá¥Âá∫Áé∞Êõ¥ÂæÆÂ¶ôÁöÑÈóÆÈ¢òË°å‰∏∫ÔºåËøô‰∫õË°å‰∏∫‰πü‰ºöÊ¨∫È™óÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãËØÑÂßî„ÄÇÊàë‰ª¨ÁöÑÂèëÁé∞ÊòØ‰∏Ä‰∏™Ë≠¶Á§∫ÊïÖ‰∫ãÔºåÁ™ÅÂá∫‰∫ÜÂ∞ÜÂèØÂçöÂºàÂèçÈ¶àÊù•Ê∫êÔºà‰æãÂ¶ÇÁî®Êà∑ÂèçÈ¶àÔºâÁî®‰ΩúÂº∫ÂåñÂ≠¶‰π†ÁõÆÊ†áÁöÑÈ£éÈô©„ÄÇ

##### **CRMArena: Understanding the Capacity of LLM Agents to Perform Professional CRM Tasks in Realistic Environments**
2411.02305v1 by Kung-Hsiang Huang, Akshara Prabhakar, Sidharth Dhawan, Yixin Mao, Huan Wang, Silvio Savarese, Caiming Xiong, Philippe Laban, Chien-Sheng Wu

Customer Relationship Management (CRM) systems are vital for modern
enterprises, providing a foundation for managing customer interactions and
data. Integrating AI agents into CRM systems can automate routine processes and
enhance personalized service. However, deploying and evaluating these agents is
challenging due to the lack of realistic benchmarks that reflect the complexity
of real-world CRM tasks. To address this issue, we introduce CRMArena, a novel
benchmark designed to evaluate AI agents on realistic tasks grounded in
professional work environments. Following guidance from CRM experts and
industry best practices, we designed CRMArena with nine customer service tasks
distributed across three personas: service agent, analyst, and manager. The
benchmark includes 16 commonly used industrial objects (e.g., account, order,
knowledge article, case) with high interconnectivity, along with latent
variables (e.g., complaint habits, policy violations) to simulate realistic
data distributions. Experimental results reveal that state-of-the-art LLM
agents succeed in less than 40% of the tasks with ReAct prompting, and less
than 55% even with function-calling abilities. Our findings highlight the need
for enhanced agent capabilities in function-calling and rule-following to be
deployed in real-world work environments. CRMArena is an open challenge to the
community: systems that can reliably complete tasks showcase direct business
value in a popular work environment.

ÊëòË¶ÅÔºöÂÆ¢Êà∂Èóú‰øÇÁÆ°ÁêÜ (CRM) Á≥ªÁµ±Â∞çÊñºÁèæ‰ª£‰ºÅÊ•≠Ëá≥ÈóúÈáçË¶ÅÔºåÁÇ∫ÁÆ°ÁêÜÂÆ¢Êà∂‰∫íÂãïÂíåË≥áÊñôÂ•†ÂÆöÂü∫Á§é„ÄÇÂ∞á AI ‰ª£ÁêÜÊï¥ÂêàÂà∞ CRM Á≥ªÁµ±‰∏≠ÂèØ‰ª•Ëá™ÂãïÂåñ‰æãË°åÁ®ãÂ∫è‰∏¶Â¢ûÂº∑ÂÄã‰∫∫ÂåñÊúçÂãô„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÁº∫‰πèÂèçÊò†ÁèæÂØ¶‰∏ñÁïå CRM ‰ªªÂãôË§áÈõúÊÄßÁöÑÂØ¶ÈöõÂü∫Ê∫ñÔºåÈÉ®ÁΩ≤ÂíåË©ï‰º∞ÈÄô‰∫õ‰ª£ÁêÜÊòØ‰∏ÄÂÄãÊåëÊà∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü CRMArenaÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Âü∫Ê∫ñÔºåÊó®Âú®Ë©ï‰º∞Âú®Â∞àÊ•≠Â∑•‰ΩúÁí∞Â¢É‰∏≠Âü∑Ë°åÂØ¶Èöõ‰ªªÂãôÁöÑ AI ‰ª£ÁêÜ„ÄÇÈÅµÂæ™ CRM Â∞àÂÆ∂ÁöÑÊåáÂ∞éÂíåÊ•≠ÁïåÊúÄ‰Ω≥ÂØ¶ÂãôÔºåÊàëÂÄëË®≠Ë®à‰∫Ü CRMArenaÔºåÂÖ∂‰∏≠ÂåÖÂê´‰πùÈ†ÖÂÆ¢Êà∂ÊúçÂãô‰ªªÂãôÔºåÂàÜ‰ΩàÂú®‰∏âÁ®ÆËßíËâ≤‰∏≠ÔºöÊúçÂãô‰ª£ÁêÜ„ÄÅÂàÜÊûêÂ∏´ÂíåÁ∂ìÁêÜ„ÄÇË©≤Âü∫Ê∫ñÂåÖÂê´ 16 ÂÄãÂ∏∏Áî®ÁöÑÁî¢Ê•≠Áâ©‰ª∂Ôºà‰æãÂ¶ÇÔºåÂ∏≥Êà∂„ÄÅË®ÇÂñÆ„ÄÅÁü•Ë≠òÊñáÁ´†„ÄÅÊ°à‰æãÔºâÔºåÂÖ∑ÊúâÈ´òÂ∫¶‰∫íÈÄ£ÊÄßÔºå‰ª•ÂèäÊΩõÂú®ËÆäÊï∏Ôºà‰æãÂ¶ÇÔºåÁî≥Ë®¥ÁøíÊÖ£„ÄÅÊîøÁ≠ñÈÅïË¶èÔºâÔºå‰ª•Ê®°Êì¨ÁèæÂØ¶ÁöÑË≥áÊñôÂàÜ‰Ωà„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÊúÄÂÖàÈÄ≤ÁöÑ LLM ‰ª£ÁêÜÂú®‰∏çÂà∞ 40% ÁöÑ‰ªªÂãô‰∏≠‰ΩøÁî® ReAct ÊèêÁ§∫ÊàêÂäüÔºåÂç≥‰ΩøÂÖ∑ÊúâÂáΩÂºèÂëºÂè´ËÉΩÂäõÔºåÊàêÂäüÁéá‰πü‰ΩéÊñº 55%„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂº∑Ë™ø‰∫ÜÂú®ÂáΩÂºèÂëºÂè´ÂíåË¶èÂâáÈÅµÂæ™ÊñπÈù¢Â¢ûÂº∑‰ª£ÁêÜËÉΩÂäõÁöÑÂøÖË¶ÅÊÄßÔºå‰ª•‰æøÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑÂ∑•‰ΩúÁí∞Â¢É‰∏≠ÈÉ®ÁΩ≤„ÄÇCRMArena Â∞çÁ§æÁæ§‰æÜË™™ÊòØ‰∏ÄÂÄãÂÖ¨ÈñãÁöÑÊåëÊà∞ÔºöËÉΩÂ§†ÂèØÈù†ÂÆåÊàê‰ªªÂãôÁöÑÁ≥ªÁµ±Âú®ÊµÅË°åÁöÑÂ∑•‰ΩúÁí∞Â¢É‰∏≠Â±ïÁ§∫Áõ¥Êé•ÁöÑÊ•≠ÂãôÂÉπÂÄº„ÄÇ

##### **Hunyuan3D-1.0: A Unified Framework for Text-to-3D and Image-to-3D Generation**
2411.02293v1 by Xianghui Yang, Huiwen Shi, Bowen Zhang, Fan Yang, Jiacheng Wang, Hongxu Zhao, Xinhai Liu, Xinzhou Wang, Qingxiang Lin, Jiaao Yu, Lifu Wang, Zhuo Chen, Sicong Liu, Yuhong Liu, Yong Yang, Di Wang, Jie Jiang, Chunchao Guo

While 3D generative models have greatly improved artists' workflows, the
existing diffusion models for 3D generation suffer from slow generation and
poor generalization. To address this issue, we propose a two-stage approach
named Hunyuan3D-1.0 including a lite version and a standard version, that both
support text- and image-conditioned generation. In the first stage, we employ a
multi-view diffusion model that efficiently generates multi-view RGB in
approximately 4 seconds. These multi-view images capture rich details of the 3D
asset from different viewpoints, relaxing the tasks from single-view to
multi-view reconstruction. In the second stage, we introduce a feed-forward
reconstruction model that rapidly and faithfully reconstructs the 3D asset
given the generated multi-view images in approximately 7 seconds. The
reconstruction network learns to handle noises and in-consistency introduced by
the multi-view diffusion and leverages the available information from the
condition image to efficiently recover the 3D structure. % Extensive
experimental results demonstrate the effectiveness of Hunyuan3D-1.0 in
generating high-quality 3D assets. Our framework involves the text-to-image
model ~\ie, Hunyuan-DiT, making it a unified framework to support both text-
and image-conditioned 3D generation. Our standard version has $10\times$ more
parameters than our lite and other existing model. Our Hunyuan3D-1.0 achieves
an impressive balance between speed and quality, significantly reducing
generation time while maintaining the quality and diversity of the produced
assets.

ÊëòË¶ÅÔºöÂÑòÁÆ° 3D ÁîüÊàêÊ®°ÂûãÂ§ßÂπÖÊîπÂñÑ‰∫ÜËóùË°ìÂÆ∂ÁöÑÂ∑•‰ΩúÊµÅÁ®ãÔºå‰ΩÜÁèæÊúâÁöÑ 3D ÁîüÊàêÊì¥Êï£Ê®°ÂûãÂú®ÁîüÊàêÈÄüÂ∫¶ÊÖ¢‰∏îÊ≥õÂåñËÉΩÂäõ‰∏ç‰Ω≥ÁöÑÂïèÈ°å‰∏ä‰ªçÊú™ÂæóÂà∞Ëß£Ê±∫„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ Hunyuan3D-1.0 ÁöÑÂÖ©ÈöéÊÆµÊñπÊ≥ïÔºåÂÖ∂‰∏≠ÂåÖÂê´Á≤æÁ∞°ÁâàÂíåÊ®ôÊ∫ñÁâàÔºåÈÄôÂÖ©Á®ÆÁâàÊú¨ÈÉΩÊîØÊè¥ÊñáÂ≠óÂíåÂΩ±ÂÉèÊ¢ù‰ª∂ÁîüÊàê„ÄÇÂú®Á¨¨‰∏ÄÈöéÊÆµÔºåÊàëÂÄëÊé°Áî®‰∫Ü‰∏ÄÂÄãÂ§öË¶ñÂúñÊì¥Êï£Ê®°ÂûãÔºåË©≤Ê®°ÂûãÂú®Â§ßÁ¥Ñ 4 ÁßíÂÖßÊúâÊïàÁéáÂú∞Áî¢ÁîüÂ§öË¶ñÂúñ RGB„ÄÇÈÄô‰∫õÂ§öË¶ñÂúñÂΩ±ÂÉèÂæû‰∏çÂêåÁöÑË¶ñÈªûÊçïÊçâ 3D Ë≥áÁî¢ÁöÑË±êÂØåÁ¥∞ÁØÄÔºåÂ∞á‰ªªÂãôÂæûÂñÆË¶ñÂúñÊîæÂØ¨Âà∞Â§öË¶ñÂúñÈáçÂª∫„ÄÇÂú®Á¨¨‰∫åÈöéÊÆµÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂâçÈ•ãÈáçÂª∫Ê®°ÂûãÔºåË©≤Ê®°ÂûãÂú®Â§ßÁ¥Ñ 7 ÁßíÂÖßÂø´ÈÄü‰∏îÂø†ÂØ¶Âú∞ÈáçÂª∫‰∫ÜÁµ¶ÂÆöÁîüÊàêÁöÑË¶ñÂúñÂΩ±ÂÉèÁöÑ 3D Ë≥áÁî¢„ÄÇÈáçÂª∫Á∂≤Ë∑ØÂ≠∏ÊúÉËôïÁêÜÂ§öË¶ñÂúñÊì¥Êï£ÂºïÂÖ•ÁöÑÈõúË®äÂíå‰∏ç‰∏ÄËá¥ÊÄßÔºå‰∏¶Âà©Áî®Ê¢ù‰ª∂ÂΩ±ÂÉè‰∏≠ÂèØÁî®ÁöÑË≥áË®ä‰æÜÊúâÊïàÂú∞ÊÅ¢Âæ© 3D ÁµêÊßã„ÄÇ% Â§ßÈáèÂØ¶È©óÁµêÊûúË≠âÊòé‰∫Ü Hunyuan3D-1.0 Âú®ÁîüÊàêÈ´òÂìÅË≥™ 3D Ë≥áÁî¢ÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÂåÖÂê´ÊñáÂ≠óËΩâÂΩ±ÂÉèÊ®°Âûã ~\ie, Hunyuan-DiTÔºå‰ΩøÂÖ∂ÊàêÁÇ∫‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÊû∂ÊßãÔºåÁî®ÊñºÊîØÊè¥ÊñáÂ≠óÂíåÂΩ±ÂÉèÊ¢ù‰ª∂ÁöÑ 3D ÁîüÊàê„ÄÇÊàëÂÄëÁöÑÊ®ôÊ∫ñÁâàÊú¨ÂèÉÊï∏ÊØîÊàëÂÄëÁöÑÁ≤æÁ∞°ÁâàÂíåÂÖ∂‰ªñÁèæÊúâÊ®°ÂûãÂ§ö $10\times$„ÄÇÊàëÂÄëÁöÑ Hunyuan3D-1.0 Âú®ÈÄüÂ∫¶ÂíåÂìÅË≥™‰πãÈñìÂèñÂæó‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÂπ≥Ë°°ÔºåÂ§ßÂπÖÊ∏õÂ∞ë‰∫ÜÁîüÊàêÊôÇÈñìÔºåÂêåÊôÇÁ∂≠ÊåÅ‰∫ÜÊâÄÁî¢ÁîüË≥áÁî¢ÁöÑÂìÅË≥™ÂíåÂ§öÊ®£ÊÄß„ÄÇ

##### **ControlSynth Neural ODEs: Modeling Dynamical Systems with Guaranteed Convergence**
2411.02292v1 by Wenjie Mei, Dongzhe Zheng, Shihua Li

Neural ODEs (NODEs) are continuous-time neural networks (NNs) that can
process data without the limitation of time intervals. They have advantages in
learning and understanding the evolution of complex real dynamics. Many
previous works have focused on NODEs in concise forms, while numerous physical
systems taking straightforward forms, in fact, belong to their more complex
quasi-classes, thus appealing to a class of general NODEs with high scalability
and flexibility to model those systems. This, however, may result in intricate
nonlinear properties. In this paper, we introduce ControlSynth Neural ODEs
(CSODEs). We show that despite their highly nonlinear nature, convergence can
be guaranteed via tractable linear inequalities. In the composition of CSODEs,
we introduce an extra control term for learning the potential simultaneous
capture of dynamics at different scales, which could be particularly useful for
partial differential equation-formulated systems. Finally, we compare several
representative NNs with CSODEs on important physical dynamics under the
inductive biases of CSODEs, and illustrate that CSODEs have better learning and
predictive abilities in these settings.

ÊëòË¶ÅÔºöÁ•ûÁ∂ì ODEÔºàNODEÔºâÊòØÈÄ£Á∫åÊôÇÈñìÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºàNNÔºâÔºåÂèØ‰ª•Âú®‰∏çÂèóÊôÇÈñìÈñìÈöîÈôêÂà∂ÁöÑÊÉÖÊ≥Å‰∏ãËôïÁêÜË≥áÊñô„ÄÇÂÆÉÂÄëÂú®Â≠∏ÁøíÂíåÁêÜËß£Ë§áÈõúÁúüÂØ¶ÂãïÊÖãÁöÑÊºîÂåñÊñπÈù¢ÂÖ∑ÊúâÂÑ™Âã¢„ÄÇË®±Â§öÂÖàÂâçÁöÑÁ†îÁ©∂ÈÉΩÂ∞àÊ≥®ÊñºÁ∞°ÊΩîÂΩ¢ÂºèÁöÑ NODEÔºåËÄåË®±Â§öÂØ¶Èöõ‰∏äÊé°Áî®Áõ¥Êé•ÂΩ¢ÂºèÁöÑÁâ©ÁêÜÁ≥ªÁµ±Â±¨ÊñºÂÆÉÂÄëÊõ¥Ë§áÈõúÁöÑÊ∫ñÈ°ûÂà•ÔºåÂõ†Ê≠§ÈúÄË¶Å‰∏ÄÈ°ûÂÖ∑ÊúâÈ´òÂèØÊì¥ÂÖÖÊÄßÂíåÈùàÊ¥ªÊÄß‰æÜÂª∫Ê®°ÈÄô‰∫õÁ≥ªÁµ±ÁöÑÈÄöÁî® NODE„ÄÇÁÑ∂ËÄåÔºåÈÄôÂèØËÉΩÊúÉÂ∞éËá¥Ë§áÈõúÁöÑÈùûÁ∑öÊÄßÂ±¨ÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü ControlSynth Á•ûÁ∂ì ODEÔºàCSODEÔºâ„ÄÇÊàëÂÄëË°®ÊòéÔºåÂÑòÁÆ°ÂÆÉÂÄëÂÖ∑ÊúâÈ´òÂ∫¶ÈùûÁ∑öÊÄßÊÄßË≥™Ôºå‰ΩÜÊî∂ÊñÇÊÄß‰ªçÂèØÈÄèÈÅéÊòìÊñºËôïÁêÜÁöÑÁ∑öÊÄß‰∏çÁ≠âÂºè‰æÜ‰øùË≠â„ÄÇÂú® CSODE ÁöÑÁµÑÊàê‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÈ°çÂ§ñÁöÑÊéßÂà∂È†ÖÔºåÁî®ÊñºÂ≠∏ÁøíÂú®‰∏çÂêåÂ∞∫Â∫¶‰∏äÂêåÊôÇÊçïÊçâÂãïÊÖãÁöÑÂèØËÉΩÊÄßÔºåÈÄôÂ∞çÊñºÂÅèÂæÆÂàÜÊñπÁ®ãÂºèÂÖ¨ÂºèÂåñÁöÑÁ≥ªÁµ±ÁâπÂà•ÊúâÁî®„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂú® CSODE ÁöÑÊ≠∏Á¥çÂÅèÂ∑Æ‰∏ãÔºåÂ∞áÂπæÂÄã‰ª£Ë°®ÊÄßÁöÑ NN Ëàá CSODE Âú®ÈáçË¶ÅÁöÑÁâ©ÁêÜÂãïÊÖã‰∏äÈÄ≤Ë°åÊØîËºÉÔºå‰∏¶Ë™™Êòé CSODE Âú®ÈÄô‰∫õË®≠ÂÆö‰∏≠ÂÖ∑ÊúâÊõ¥Â•ΩÁöÑÂ≠∏ÁøíÂíåÈ†êÊ∏¨ËÉΩÂäõ„ÄÇ

##### **Federated GNNs for EEG-Based Stroke Assessment**
2411.02286v1 by Andrea Protani, Lorenzo Giusti, Albert Sund Aillet, Simona Sacco, Paolo Manganotti, Lucio Marinelli, Diogo Reis Santos, Pierpaolo Brutti, Pietro Caliandro, Luigi Serio

Machine learning (ML) has the potential to become an essential tool in
supporting clinical decision-making processes, offering enhanced diagnostic
capabilities and personalized treatment plans. However, outsourcing medical
records to train ML models using patient data raises legal, privacy, and
security concerns. Federated learning has emerged as a promising paradigm for
collaborative ML, meeting healthcare institutions' requirements for robust
models without sharing sensitive data and compromising patient privacy. This
study proposes a novel method that combines federated learning (FL) and Graph
Neural Networks (GNNs) to predict stroke severity using electroencephalography
(EEG) signals across multiple medical institutions. Our approach enables
multiple hospitals to jointly train a shared GNN model on their local EEG data
without exchanging patient information. Specifically, we address a regression
problem by predicting the National Institutes of Health Stroke Scale (NIHSS), a
key indicator of stroke severity. The proposed model leverages a masked
self-attention mechanism to capture salient brain connectivity patterns and
employs EdgeSHAP to provide post-hoc explanations of the neurological states
after a stroke. We evaluated our method on EEG recordings from four
institutions, achieving a mean absolute error (MAE) of 3.23 in predicting
NIHSS, close to the average error made by human experts (MAE $\approx$ 3.0).
This demonstrates the method's effectiveness in providing accurate and
explainable predictions while maintaining data privacy.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏Áøí (ML) ÊúâÊΩõÂäõÊàêÁÇ∫ÊîØÊè¥Ëá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÊµÅÁ®ãÁöÑÂøÖË¶ÅÂ∑•ÂÖ∑ÔºåÊèê‰æõÂ¢ûÂº∑ÁöÑË®∫Êñ∑ËÉΩÂäõÂíåÂÄã‰∫∫ÂåñÊ≤ªÁôÇË®àÁï´„ÄÇÁÑ∂ËÄåÔºå‰ΩøÁî®ÁóÖÊÇ£Ë≥áÊñôË®ìÁ∑¥Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÂ§ñÂåÖÈÜ´ÁôÇÁ¥ÄÈåÑÂºïÁôº‰∫ÜÊ≥ïÂæã„ÄÅÈö±ÁßÅÂíåÂÆâÂÖ®ÊñπÈù¢ÁöÑÁñëÊÖÆ„ÄÇËÅØÂêàÂ≠∏ÁøíÂ∑≤ÊàêÁÇ∫Âçî‰ΩúÊ©üÂô®Â≠∏ÁøíÁöÑ‰∏ÄÁ®ÆÊúâÂâçÊôØÁöÑÂÖ∏ÁØÑÔºåÂÆÉÁ¨¶ÂêàÈÜ´ÁôÇ‰øùÂÅ•Ê©üÊßãÂ∞çÁ©©ÂÅ•Ê®°ÂûãÁöÑË¶ÅÊ±ÇÔºåÂêåÊôÇ‰∏çÊúÉÂàÜ‰∫´ÊïèÊÑüË≥áÊñôÂíåÂç±ÂÆ≥ÁóÖÊÇ£Èö±ÁßÅ„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ïÔºåÁµêÂêàËÅØÂêàÂ≠∏Áøí (FL) ÂíåÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ‰æÜ‰ΩøÁî®ËÖ¶ÈõªÂúñ (EEG) Ë®äËôüÈ†êÊ∏¨Â§öÂÄãÈÜ´ÁôÇÊ©üÊßãÁöÑËÖ¶‰∏≠È¢®Âö¥ÈáçÁ®ãÂ∫¶„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïËÆìÂ§öÂÆ∂ÈÜ´Èô¢ËÉΩÂ§†ÂÖ±ÂêåÂú®‰ªñÂÄëÁöÑÊú¨Âú∞ EEG Ë≥áÊñô‰∏äË®ìÁ∑¥‰∏ÄÂÄãÂÖ±‰∫´ÁöÑ GNN Ê®°ÂûãÔºåËÄåÁÑ°ÈúÄ‰∫§ÊèõÁóÖÊÇ£Ë≥áË®ä„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈÄèÈÅéÈ†êÊ∏¨ÁæéÂúãÂúãÂÆ∂Ë°õÁîüÁ†îÁ©∂Èô¢ËÖ¶‰∏≠È¢®ÈáèË°® (NIHSS) ‰æÜËß£Ê±∫ÂõûÊ≠∏ÂïèÈ°åÔºåNIHSS ÊòØËÖ¶‰∏≠È¢®Âö¥ÈáçÁ®ãÂ∫¶ÁöÑ‰∏ÄÂÄãÈóúÈçµÊåáÊ®ô„ÄÇÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂà©Áî®ÈÅÆÁΩ©Ëá™ÊàëÊ≥®ÊÑèÊ©üÂà∂‰æÜÊì∑ÂèñÈ°ØËëóÁöÑËÖ¶ÈÉ®ÈÄ£ÁµêÊ®°ÂºèÔºå‰∏¶Êé°Áî® EdgeSHAP Âú®‰∏≠È¢®ÂæåÊèê‰æõÁ•ûÁ∂ìÁãÄÊÖãÁöÑ‰∫ãÂæåËß£Èáã„ÄÇÊàëÂÄëÂú®‰æÜËá™ÂõõÂÆ∂Ê©üÊßãÁöÑ EEG Ë®òÈåÑ‰∏äË©ï‰º∞‰∫ÜÊàëÂÄëÁöÑÊ®°ÂûãÔºåÂú®È†êÊ∏¨ NIHSS ÊôÇÈÅîÂà∞‰∫Ü 3.23 ÁöÑÂπ≥ÂùáÁµïÂ∞çË™§Â∑Æ (MAE)ÔºåÊé•Ëøë‰∫∫È°ûÂ∞àÂÆ∂ÊâÄÁäØÁöÑÂπ≥ÂùáË™§Â∑Æ (MAE ‚âà 3.0)„ÄÇÈÄôË≠âÊòé‰∫ÜË©≤ÊñπÊ≥ïÂú®Á∂≠ÊåÅË≥áÊñôÈö±ÁßÅÁöÑÂêåÊôÇÔºåËÉΩÊèê‰æõÊ∫ñÁ¢∫‰∏îÂèØËß£ÈáãÁöÑÈ†êÊ∏¨ÔºåÈÄ≤ËÄåÂ±ïÁèæÂÖ∂ÊïàËÉΩ„ÄÇ

##### **The LLM Language Network: A Neuroscientific Approach for Identifying Causally Task-Relevant Units**
2411.02280v1 by Badr AlKhamissi, Greta Tuckute, Antoine Bosselut, Martin Schrimpf

Large language models (LLMs) exhibit remarkable capabilities on not just
language tasks, but also various tasks that are not linguistic in nature, such
as logical reasoning and social inference. In the human brain, neuroscience has
identified a core language system that selectively and causally supports
language processing. We here ask whether similar specialization for language
emerges in LLMs. We identify language-selective units within 18 popular LLMs,
using the same localization approach that is used in neuroscience. We then
establish the causal role of these units by demonstrating that ablating LLM
language-selective units -- but not random units -- leads to drastic deficits
in language tasks. Correspondingly, language-selective LLM units are more
aligned to brain recordings from the human language system than random units.
Finally, we investigate whether our localization method extends to other
cognitive domains: while we find specialized networks in some LLMs for
reasoning and social capabilities, there are substantial differences among
models. These findings provide functional and causal evidence for
specialization in large language models, and highlight parallels with the
functional organization in the brain.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏çÂÉÖÂú®Ë™ûË®Ä‰ªªÂãô‰∏äË°®ÁèæÂá∫ÈùûÂá°ÁöÑËÉΩÂäõÔºåËÄå‰∏îÂú®ÈùûË™ûË®ÄÊÄßË≥™ÁöÑÂêÑÁ®Æ‰ªªÂãô‰∏ä‰πüÊúâË°®ÁèæÔºå‰æãÂ¶ÇÈÇèËºØÊé®ÁêÜÂíåÁ§æÊúÉÊé®Ë´ñ„ÄÇÂú®‰∫∫ËÖ¶‰∏≠ÔºåÁ•ûÁ∂ìÁßëÂ≠∏Â∑≤Á∂ìÁ¢∫ÂÆö‰∫Ü‰∏ÄÂÄãÊ†∏ÂøÉË™ûË®ÄÁ≥ªÁµ±ÔºåË©≤Á≥ªÁµ±ÈÅ∏ÊìáÊÄßÂú∞ÂíåÂõ†ÊûúÂú∞ÊîØÊåÅË™ûË®ÄËôïÁêÜ„ÄÇÊàëÂÄëÂú®Ê≠§Êé¢Ë®é LLM ‰∏≠ÊòØÂê¶Âá∫Áèæ‰∫ÜÈ°û‰ººÁöÑË™ûË®ÄÂ∞àÊ•≠Âåñ„ÄÇÊàëÂÄë‰ΩøÁî®Á•ûÁ∂ìÁßëÂ≠∏‰∏≠‰ΩøÁî®ÁöÑÁõ∏ÂêåÂÆö‰ΩçÊñπÊ≥ïÔºåÂú® 18 ÂÄãÊµÅË°åÁöÑ LLM ‰∏≠Ë≠òÂà•Ë™ûË®ÄÈÅ∏ÊìáÂñÆÂÖÉ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÈÄöÈÅéË≠âÊòéÊ∂àËûç LLM Ë™ûË®ÄÈÅ∏ÊìáÂñÆÂÖÉÔºàËÄåÈùûÈö®Ê©üÂñÆÂÖÉÔºâÊúÉÂ∞éËá¥Ë™ûË®Ä‰ªªÂãôÂá∫ÁèæÂ∑®Â§ßÁº∫Èô∑Ôºå‰æÜÁ¢∫Á´ãÈÄô‰∫õÂñÆÂÖÉÁöÑÂõ†ÊûúÈóú‰øÇ„ÄÇÁõ∏ÊáâÂú∞ÔºåË™ûË®ÄÈÅ∏Êìá LLM ÂñÆÂÖÉËàá‰æÜËá™‰∫∫È°ûË™ûË®ÄÁ≥ªÁµ±ÁöÑËÖ¶ÈÉ®Ë®òÈåÑÁõ∏ÊØîÔºåËàáÈö®Ê©üÂñÆÂÖÉÁõ∏ÊØîÊõ¥‰∏ÄËá¥„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊé¢Ë®éÊàëÂÄëÁöÑÂÆö‰ΩçÊñπÊ≥ïÊòØÂê¶Êì¥Â±ïÂà∞ÂÖ∂‰ªñË™çÁü•È†òÂüüÔºöÈõñÁÑ∂ÊàëÂÄëÂú®‰∏Ä‰∫õ LLM ‰∏≠ÁôºÁèæ‰∫ÜÊé®ÁêÜÂíåÁ§æÊúÉËÉΩÂäõÁöÑÂ∞àÈñÄÁ∂≤Ë∑ØÔºå‰ΩÜÊ®°Âûã‰πãÈñìÂ≠òÂú®È°ØËëóÂ∑ÆÁï∞„ÄÇÈÄô‰∫õÁôºÁèæÁÇ∫Â§ßÂûãË™ûË®ÄÊ®°Âûã‰∏≠ÁöÑÂ∞àÊ•≠ÂåñÊèê‰æõ‰∫ÜÂäüËÉΩÊÄßÂíåÂõ†ÊûúË≠âÊìöÔºå‰∏¶Á™ÅÂá∫‰∫ÜËàáÂ§ßËÖ¶ÂäüËÉΩÁµÑÁπîÁöÑÁõ∏‰ºº‰πãËôï„ÄÇ

##### **Breaking the Reclustering Barrier in Centroid-based Deep Clustering**
2411.02275v1 by Lukas Miklautz, Timo Klein, Kevin Sidak, Collin Leiber, Thomas Lang, Andrii Shkabrii, Sebastian Tschiatschek, Claudia Plant

This work investigates an important phenomenon in centroid-based deep
clustering (DC) algorithms: Performance quickly saturates after a period of
rapid early gains. Practitioners commonly address early saturation with
periodic reclustering, which we demonstrate to be insufficient to address
performance plateaus. We call this phenomenon the "reclustering barrier" and
empirically show when the reclustering barrier occurs, what its underlying
mechanisms are, and how it is possible to Break the Reclustering Barrier with
our algorithm BRB. BRB avoids early over-commitment to initial clusterings and
enables continuous adaptation to reinitialized clustering targets while
remaining conceptually simple. Applying our algorithm to widely-used
centroid-based DC algorithms, we show that (1) BRB consistently improves
performance across a wide range of clustering benchmarks, (2) BRB enables
training from scratch, and (3) BRB performs competitively against
state-of-the-art DC algorithms when combined with a contrastive loss. We
release our code and pre-trained models at
https://github.com/Probabilistic-and-Interactive-ML/breaking-the-reclustering-barrier .

ÊëòË¶ÅÔºöÈÄôÈ†ÖÂ∑•‰ΩúÊé¢Ë®é‰∫Ü‰ª•Ë≥™ÂøÉÁÇ∫Âü∫Á§éÁöÑÊ∑±Â∫¶Âè¢ÈõÜ (DC) ÊºîÁÆóÊ≥ï‰∏≠‰∏ÄÂÄãÈáçË¶ÅÁöÑÁèæË±°ÔºöÂú®‰∏ÄÊÆµÂø´ÈÄüÊó©ÊúüÊî∂ÁõäÊúü‰πãÂæåÔºåÊïàËÉΩÊúÉËøÖÈÄüÈ£ΩÂíå„ÄÇÂæûÊ•≠‰∫∫Âì°ÈÄöÂ∏∏‰ΩøÁî®ÂÆöÊúüÈáçÊñ∞Âè¢ÈõÜ‰æÜËôïÁêÜÊó©ÊúüÈ£ΩÂíåÔºåÊàëÂÄëË≠âÊòéÈÄô‰∏çË∂≥‰ª•Ëß£Ê±∫ÊïàËÉΩÂÅúÊªØ„ÄÇÊàëÂÄëÁ®±Ê≠§ÁèæË±°ÁÇ∫„ÄåÈáçÊñ∞Âè¢ÈõÜÈöúÁ§ô„ÄçÔºå‰∏¶ÈÄèÈÅéÂØ¶Ë≠âÈ°ØÁ§∫ÈáçÊñ∞Âè¢ÈõÜÈöúÁ§ô‰ΩïÊôÇÁôºÁîü„ÄÅÂÖ∂ËÉåÂæåÁöÑÊ©üÂà∂ÊòØ‰ªÄÈ∫ºÔºå‰ª•ÂèäÂ¶Ç‰ΩïÈÄèÈÅéÊàëÂÄëÁöÑÊºîÁÆóÊ≥ï BRB ÊâìÁ†¥ÈáçÊñ∞Âè¢ÈõÜÈöúÁ§ô„ÄÇBRB ÈÅøÂÖçÈÅéÊó©ÈÅéÂ∫¶ÊâøË´æÊñºÂàùÂßãÂè¢ÈõÜÔºå‰∏¶ËÉΩÂú®‰øùÊåÅÊ¶ÇÂøµÁ∞°ÂñÆÁöÑÂêåÊôÇÔºåÊåÅÁ∫åÈÅ©ÊáâÈáçÊñ∞ÂàùÂßãÂåñÁöÑÂè¢ÈõÜÁõÆÊ®ô„ÄÇÂ∞áÊàëÂÄëÁöÑÊºîÁÆóÊ≥ïÂ•óÁî®ÊñºÂª£Ê≥õ‰ΩøÁî®ÁöÑ‰ª•Ë≥™ÂøÉÁÇ∫Âü∫Á§éÁöÑ DC ÊºîÁÆóÊ≥ïÔºåÊàëÂÄëÈ°ØÁ§∫ (1) BRB Âú®Âª£Ê≥õÁöÑÂè¢ÈõÜÂü∫Ê∫ñ‰∏äÊåÅÁ∫åÊîπÂñÑÊïàËÉΩÔºå(2) BRB ËÉΩÂ§†ÂæûÈ†≠ÈñãÂßãË®ìÁ∑¥Ôºå‰ª•Âèä (3) BRB ËàáÁµêÂêàÂ∞çÊØîÊêçÂ§±ÁöÑÊúÄÊñ∞ DC ÊºîÁÆóÊ≥ïÁõ∏ÊØîÔºåÂÖ∑ÊúâÁ´∂Áà≠Âäõ„ÄÇÊàëÂÄëÂú® https://github.com/Probabilistic-and-Interactive-ML/breaking-the-reclustering-barrier ÁôºÂ∏ÉÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåÈ†êÂÖàË®ìÁ∑¥ÁöÑÊ®°Âûã„ÄÇ

##### **Combining Induction and Transduction for Abstract Reasoning**
2411.02272v1 by Wen-Ding Li, Keya Hu, Carter Larsen, Yuqing Wu, Simon Alford, Caleb Woo, Spencer M. Dunn, Hao Tang, Michelangelo Naim, Dat Nguyen, Wei-Long Zheng, Zenna Tavares, Yewen Pu, Kevin Ellis

When learning an input-output mapping from very few examples, is it better to
first infer a latent function that explains the examples, or is it better to
directly predict new test outputs, e.g. using a neural network? We study this
question on ARC, a highly diverse dataset of abstract reasoning tasks. We train
neural models for induction (inferring latent functions) and transduction
(directly predicting the test output for a given test input). Our models are
trained on synthetic data generated by prompting LLMs to produce Python code
specifying a function to be inferred, plus a stochastic subroutine for
generating inputs to that function. We find inductive and transductive models
solve very different problems, despite training on the same problems, and
despite sharing the same neural architecture.

ÊëòË¶ÅÔºöÂú®ÂæûÊ•µÂ∞ëÁöÑÁØÑ‰æã‰∏≠Â≠∏ÁøíËº∏ÂÖ•Ëº∏Âá∫Â∞çÊáâÊôÇÔºåÊòØÂÖàÊé®Ë´ñÂá∫Ëß£ÈáãÁØÑ‰æãÁöÑÊΩõÂú®ÂáΩÊï∏ËºÉÂ•ΩÔºåÈÇÑÊòØÁõ¥Êé•È†êÊ∏¨Êñ∞ÁöÑÊ∏¨Ë©¶Ëº∏Âá∫ËºÉÂ•ΩÔºå‰æãÂ¶Ç‰ΩøÁî®Á•ûÁ∂ìÁ∂≤Ë∑ØÔºüÊàëÂÄëÂú® ARC ‰∏äÁ†îÁ©∂ÈÄôÂÄãÂïèÈ°åÔºåARC ÊòØÊäΩË±°Êé®ÁêÜ‰ªªÂãôÁöÑÈ´òÂ∫¶Â§öÂÖÉË≥áÊñôÈõÜ„ÄÇÊàëÂÄëË®ìÁ∑¥Á•ûÁ∂ìÊ®°ÂûãÈÄ≤Ë°åÊ≠∏Á¥çÔºàÊé®Ë´ñÊΩõÂú®ÂáΩÊï∏ÔºâÂíåËΩâÂ∞éÔºàÁõ¥Êé•È†êÊ∏¨Áµ¶ÂÆöÊ∏¨Ë©¶Ëº∏ÂÖ•ÁöÑÊ∏¨Ë©¶Ëº∏Âá∫Ôºâ„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãË®ìÁ∑¥ÊñºÂêàÊàêË≥áÊñôÔºåÈÄô‰∫õË≥áÊñôÊòØÁî±ÊèêÁ§∫ LLM Áî¢ÁîüÊåáÂÆöË¶ÅÊé®Ë´ñÂáΩÊï∏ÁöÑ Python Á®ãÂºèÁ¢ºÔºåÂä†‰∏ä‰∏ÄÂÄãÁî®ÊñºÁî¢ÁîüË©≤ÂáΩÊï∏Ëº∏ÂÖ•ÁöÑÈö®Ê©üÂ≠êÁ®ãÂºèÊâÄÁî¢Áîü„ÄÇÊàëÂÄëÁôºÁèæÊ≠∏Á¥çÊ®°ÂûãÂíåËΩâÂ∞éÊ®°ÂûãËß£Ê±∫‰∫ÜÈùûÂ∏∏‰∏çÂêåÁöÑÂïèÈ°åÔºåÂÑòÁÆ°Ë®ìÁ∑¥ÊñºÁõ∏ÂêåÁöÑÂïèÈ°åÔºåËÄå‰∏îÂÖ±Áî®Áõ∏ÂêåÁöÑÁ∂≤Ë∑ØÊû∂Êßã„ÄÇ

##### **On the Utilization of Unique Node Identifiers in Graph Neural Networks**
2411.02271v1 by Maya Bechler-Speicher, Moshe Eliasof, Carola-Bibiane Sch√∂nlieb, Ran Gilad-Bachrach, Amir Globerson

Graph neural networks have inherent representational limitations due to their
message-passing structure. Recent work has suggested that these limitations can
be overcome by using unique node identifiers (UIDs). Here we argue that despite
the advantages of UIDs, one of their disadvantages is that they lose the
desirable property of permutation-equivariance. We thus propose to focus on UID
models that are permutation-equivariant, and present theoretical arguments for
their advantages. Motivated by this, we propose a method to regularize UID
models towards permutation equivariance, via a contrastive loss. We empirically
demonstrate that our approach improves generalization and extrapolation
abilities while providing faster training convergence. On the recent BREC
expressiveness benchmark, our proposed method achieves state-of-the-art
performance compared to other random-based approaches.

ÊëòË¶ÅÔºöÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑ØÁî±ÊñºÂÖ∂Ë®äÊÅØÂÇ≥ÈÅûÁµêÊßãËÄåÂÖ∑ÊúâÂõ∫ÊúâÁöÑË°®Á§∫ÈôêÂà∂„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÂèØ‰ª•‰ΩøÁî®ÂîØ‰∏ÄÁöÑÁØÄÈªûÊ®ôË≠òÁ¨¶ (UID) ‰æÜÂÖãÊúçÈÄô‰∫õÈôêÂà∂„ÄÇÊàëÂÄëÂú®Ê≠§Ë´ñË≠âÔºåÂÑòÁÆ° UID ÂÖ∑ÊúâÂÑ™ÈªûÔºå‰ΩÜÂÖ∂Áº∫Èªû‰πã‰∏ÄÊòØÂÆÉÂÄëÂ§±Âéª‰∫ÜÁΩÆÊèõÁ≠âËÆäÊÄßÁöÑÁêÜÊÉ≥Â±¨ÊÄß„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂª∫Ë≠∞Â∞àÊ≥®ÊñºÁΩÆÊèõÁ≠âËÆäÊÄßÁöÑ UID Ê®°ÂûãÔºå‰∏¶ÊèêÂá∫ÂÖ∂ÂÑ™Âã¢ÁöÑÁêÜË´ñË´ñÊìö„ÄÇÂèóÊ≠§ÂïüÁôºÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÈÄöÈÅéÂ∞çÊØîÊêçÂ§±Â∞á UID Ê®°ÂûãË¶èÁØÑÂåñÁÇ∫ÁΩÆÊèõÁ≠âËÆäÊÄßÁöÑÊñπÊ≥ï„ÄÇÊàëÂÄëÂØ¶Ë≠âË≠âÊòéÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊîπÂñÑ‰∫ÜÊ≥õÂåñÂíåÂ§ñÊé®ËÉΩÂäõÔºåÂêåÊôÇÊèê‰æõ‰∫ÜÊõ¥Âø´ÁöÑË®ìÁ∑¥Êî∂ÊñÇ„ÄÇÂú®ÊúÄËøëÁöÑ BREC Ë°®ÈÅîËÉΩÂäõÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïËàáÂÖ∂‰ªñÂü∫ÊñºÈö®Ê©üÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåÂØ¶Áèæ‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇ

##### **Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated Parameters by Tencent**
2411.02265v1 by Xingwu Sun, Yanfeng Chen, Yiqing Huang, Ruobing Xie, Jiaqi Zhu, Kai Zhang, Shuaipeng Li, Zhen Yang, Jonny Han, Xiaobo Shu, Jiahao Bu, Zhongzhi Chen, Xuemeng Huang, Fengzong Lian, Saiyong Yang, Jianfeng Yan, Yuyuan Zeng, Xiaoqin Ren, Chao Yu, Lulu Wu, Yue Mao, Tao Yang, Suncong Zheng, Kan Wu, Dian Jiao, Jinbao Xue, Xipeng Zhang, Decheng Wu, Kai Liu, Dengpeng Wu, Guanghui Xu, Shaohua Chen, Shuang Chen, Xiao Feng, Yigeng Hong, Junqiang Zheng, Chengcheng Xu, Zongwei Li, Xiong Kuang, Jianglu Hu, Yiqi Chen, Yuchi Deng, Guiyang Li, Ao Liu, Chenchen Zhang, Shihui Hu, Zilong Zhao, Zifan Wu, Yao Ding, Weichao Wang, Han Liu, Roberts Wang, Hao Fei, Peijie She, Ze Zhao, Xun Cao, Hai Wang, Fusheng Xiang, Mengyuan Huang, Zhiyuan Xiong, Bin Hu, Xuebin Hou, Lei Jiang, Jiajia Wu, Yaping Deng, Yi Shen, Qian Wang, Weijie Liu, Jie Liu, Meng Chen, Liang Dong, Weiwen Jia, Hu Chen, Feifei Liu, Rui Yuan, Huilin Xu, Zhenxiang Yan, Tengfei Cao, Zhichao Hu, Xinhua Feng, Dong Du, Tinghao She, Yangyu Tao, Feng Zhang, Jianchen Zhu, Chengzhong Xu, Xirui Li, Chong Zha, Wen Ouyang, Yinben Xia, Xiang Li, Zekun He, Rongpeng Chen, Jiawei Song, Ruibin Chen, Fan Jiang, Chongqing Zhao, Bo Wang, Hao Gong, Rong Gan, Winston Hu, Zhanhui Kang, Yong Yang, Yuhong Liu, Di Wang, Jie Jiang

In this paper, we introduce Hunyuan-Large, which is currently the largest
open-source Transformer-based mixture of experts model, with a total of 389
billion parameters and 52 billion activation parameters, capable of handling up
to 256K tokens. We conduct a thorough evaluation of Hunyuan-Large's superior
performance across various benchmarks including language understanding and
generation, logical reasoning, mathematical problem-solving, coding,
long-context, and aggregated tasks, where it outperforms LLama3.1-70B and
exhibits comparable performance when compared to the significantly larger
LLama3.1-405B model. Key practice of Hunyuan-Large include large-scale
synthetic data that is orders larger than in previous literature, a mixed
expert routing strategy, a key-value cache compression technique, and an
expert-specific learning rate strategy. Additionally, we also investigate the
scaling laws and learning rate schedule of mixture of experts models, providing
valuable insights and guidances for future model development and optimization.
The code and checkpoints of Hunyuan-Large are released to facilitate future
innovations and applications.
  Codes: https://github.com/Tencent/Hunyuan-Large
  Models: https://huggingface.co/tencent/Tencent-Hunyuan-Large

ÊëòË¶ÅÔºö<paragraph>Âú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü Hunyuan-LargeÔºåÂÆÉÁõÆÂâçÊòØÊúÄÂ§ßÁöÑÈñãÊ∫ê Transformer Âü∫ÊñºÂ∞àÂÆ∂Ê®°ÂûãÔºåÁ∏ΩÂÖ±Êúâ 3890 ÂÑÑÂÄãÂèÉÊï∏Âíå 520 ÂÑÑÂÄãÊøÄÊ¥ªÂèÉÊï∏ÔºåËÉΩÂ§†ËôïÁêÜÂ§öÈÅî 256K ÂÄã token„ÄÇÊàëÂÄëÂ∞ç Hunyuan-Large ÁöÑÂÑ™Áï∞ÊÄßËÉΩÈÄ≤Ë°å‰∫ÜÂæπÂ∫ïÁöÑË©ï‰º∞ÔºåÂåÖÊã¨Ë™ûË®ÄÁêÜËß£ÂíåÁîüÊàê„ÄÅÈÇèËºØÊé®ÁêÜ„ÄÅÊï∏Â≠∏ÂïèÈ°åËß£Ê±∫„ÄÅÁ∑®Á¢º„ÄÅÈï∑‰∏ä‰∏ãÊñáÂíåËÅöÂêà‰ªªÂãôÔºåÂú®ÈÄô‰∫õÊñπÈù¢ÂÆÉÂÑ™Êñº LLama3.1-70BÔºå‰∏¶‰∏îËàáÈ°ØËëóÊõ¥Â§ßÁöÑ LLama3.1-405B Ê®°ÂûãÁõ∏ÊØîË°®ÁèæÁõ∏Áï∂„ÄÇHunyuan-Large ÁöÑÈóúÈçµÂØ¶Ë∏êÂåÖÊã¨ÊØî‰ª•ÂâçÊñáÁçª‰∏≠Â§ßÂπæÂÄãÊï∏ÈáèÁ¥öÁöÑÂ§ßË¶èÊ®°ÂêàÊàêÊï∏Êìö„ÄÅÊ∑∑ÂêàÂ∞àÂÆ∂Ë∑ØÁî±Á≠ñÁï•„ÄÅÈçµÂÄºÁ∑©Â≠òÂ£ìÁ∏ÆÊäÄË°ìÂíåÂ∞àÂÆ∂ÁâπÂÆöÁöÑÂ≠∏ÁøíÁéáÁ≠ñÁï•„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑÁ†îÁ©∂‰∫ÜÂ∞àÂÆ∂Ê®°ÂûãÁöÑÊ∑∑ÂêàÊØî‰æãÂÆöÂæãÂíåÂ≠∏ÁøíÁéáË°®ÔºåÁÇ∫Êú™‰æÜÁöÑÊ®°ÂûãÈñãÁôºÂíåÂÑ™ÂåñÊèê‰æõ‰∫ÜÂØ∂Ë≤¥ÁöÑË¶ãËß£ÂíåÊåáÂ∞é„ÄÇHunyuan-Large ÁöÑ‰ª£Á¢ºÂíåÊ™¢Êü•ÈªûÂ∑≤ÁôºÂ∏ÉÔºå‰ª•‰øÉÈÄ≤Êú™‰æÜÁöÑÂâµÊñ∞ÂíåÊáâÁî®„ÄÇ
‰ª£Á¢ºÔºöhttps://github.com/Tencent/Hunyuan-Large
Ê®°ÂûãÔºöhttps://huggingface.co/tencent/Tencent-Hunyuan-Large</paragraph>

##### **Positive Experience Reflection for Agents in Interactive Text Environments**
2411.02223v1 by Philip Lippmann, Matthijs T. J. Spaan, Jie Yang

Intelligent agents designed for interactive environments face significant
challenges in text-based games, a domain that demands complex reasoning and
adaptability. While agents based on large language models (LLMs) using
self-reflection have shown promise, they struggle when initially successful and
exhibit reduced effectiveness when using smaller LLMs. We introduce Sweet&Sour,
a novel approach that addresses these limitations in existing reflection
methods by incorporating positive experiences and managed memory to enrich the
context available to the agent at decision time. Our comprehensive analysis
spans both closed- and open-source LLMs and demonstrates the effectiveness of
Sweet&Sour in improving agent performance, particularly in scenarios where
previous approaches fall short.

ÊëòË¶ÅÔºöÁÇ∫‰∫íÂãïÁí∞Â¢ÉË®≠Ë®àÁöÑÊô∫ÊÖß‰ª£ÁêÜÁ®ãÂºèÂú®ÊñáÂ≠óÈÅäÊà≤‰∏≠Èù¢Ëá®ÈáçÂ§ßÊåëÊà∞ÔºåÈÄôÊòØ‰∏ÄÂÄãÈúÄË¶ÅË§áÈõúÊé®ÁêÜÂíåÈÅ©ÊáâÊÄßÁöÑÈ†òÂüü„ÄÇÈõñÁÑ∂Âü∫ÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏¶‰ΩøÁî®Ëá™ÊàëÂèçÁúÅÁöÑ‰ª£ÁêÜÁ®ãÂºèÂ∑≤Â±ïÁèæÊΩõÂäõÔºå‰ΩÜÂÆÉÂÄëÂú®ÊúÄÂàùÊàêÂäüÊôÇÊúÉÈÅáÂà∞Âõ∞Èõ£Ôºå‰∏îÂú®‰ΩøÁî®ËºÉÂ∞èÁöÑ LLM ÊôÇÊúÉË°®ÁèæÂá∫ËºÉÂ∑ÆÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü Sweet&SourÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÈÄèÈÅéÁ¥çÂÖ•Ê≠£Èù¢Á∂ìÈ©óÂíåÁÆ°ÁêÜÂºèË®òÊÜ∂‰æÜËß£Ê±∫ÁèæÊúâÂèçÁúÅÊñπÊ≥ï‰∏≠ÁöÑÈÄô‰∫õÈôêÂà∂Ôºå‰ª•Ë±êÂØå‰ª£ÁêÜÁ®ãÂºèÂú®Ê±∫Á≠ñÊôÇÂèØÁî®ÁöÑËÑàÁµ°„ÄÇÊàëÂÄëÁöÑÂÖ®Èù¢ÂàÜÊûêÊ∂µËìãÂ∞ÅÈñâÂíåÈñãÊîæÂéüÂßãÁ¢ºÁöÑ LLMÔºå‰∏¶Ë≠âÊòé‰∫Ü Sweet&Sour Âú®ÊîπÂñÑ‰ª£ÁêÜÁ®ãÂºèÊïàËÉΩÊñπÈù¢ÁöÑÊïàÂäõÔºåÁâπÂà•ÊòØÂú®‰ª•ÂâçÊñπÊ≥ïÂ§±ÊïàÁöÑÊÉÖÊ≥Å‰∏ã„ÄÇ

##### **Improving Steering Vectors by Targeting Sparse Autoencoder Features**
2411.02193v1 by Sviatoslav Chalnev, Matthew Siu, Arthur Conmy

To control the behavior of language models, steering methods attempt to
ensure that outputs of the model satisfy specific pre-defined properties.
Adding steering vectors to the model is a promising method of model control
that is easier than finetuning, and may be more robust than prompting. However,
it can be difficult to anticipate the effects of steering vectors produced by
almost all existing methods, such as CAA (Panickssery et al., 2024) or the
direct use of SAE latents (Templeton et al., 2024). In our work, we address
this issue by using SAEs to measure the effects of steering vectors, giving us
a method that can be used to understand the causal effect of any steering
vector intervention. We use this method for measuring causal effects to develop
an improved steering method, SAE-Targeted Steering (SAE-TS), which finds
steering vectors to target specific SAE features while minimizing unintended
side effects. We show that overall, SAE-TS balances steering effects with
coherence better than CAA and SAE feature steering, when evaluated on a range
of tasks.

ÊëòË¶ÅÔºö‰∏∫‰∫ÜÊéßÂà∂ËØ≠Ë®ÄÊ®°ÂûãÁöÑË°å‰∏∫ÔºåÂºïÂØºÊñπÊ≥ïÂ∞ùËØïÁ°Æ‰øùÊ®°ÂûãÁöÑËæìÂá∫Êª°Ë∂≥ÁâπÂÆöÁöÑÈ¢ÑÂÆö‰πâÂ±ûÊÄß„ÄÇÂ∞ÜÂºïÂØºÂêëÈáèÊ∑ªÂä†Âà∞Ê®°Âûã‰∏≠ÊòØ‰∏ÄÁßçÊúâÂâçÈÄîÁöÑÊ®°ÂûãÊéßÂà∂ÊñπÊ≥ïÔºåÂÆÉÊØîÂæÆË∞ÉÊõ¥ÂÆπÊòìÔºåÂπ∂‰∏îÂèØËÉΩÊØîÊèêÁ§∫Êõ¥Á®≥ÂÅ•„ÄÇÁÑ∂ËÄåÔºåÂæàÈöæÈ¢ÑÊµãÂá†‰πéÊâÄÊúâÁé∞ÊúâÊñπÊ≥ïÔºà‰æãÂ¶Ç CAAÔºàPanickssery Á≠â‰∫∫Ôºå2024 Âπ¥ÔºâÊàñÁõ¥Êé•‰ΩøÁî® SAE ÊΩúÂú®ÂèòÈáèÔºàTempleton Á≠â‰∫∫Ôºå2024 Âπ¥ÔºâÔºâ‰∫ßÁîüÁöÑÂºïÂØºÂêëÈáèÁöÑÊïàÊûú„ÄÇÂú®Êàë‰ª¨ÁöÑÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ÈÄöËøá‰ΩøÁî® SAE Êù•Ë°°ÈáèÂºïÂØºÂêëÈáèÁöÑÊïàÊûúÊù•Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºå‰ªéËÄå‰∏∫Êàë‰ª¨Êèê‰æõ‰∫Ü‰∏ÄÁßçÂèØ‰ª•Áî®Êù•ÁêÜËß£‰ªª‰ΩïÂºïÂØºÂêëÈáèÂπ≤È¢ÑÁöÑÂõ†ÊûúÊïàÂ∫îÁöÑÊñπÊ≥ï„ÄÇÊàë‰ª¨‰ΩøÁî®ËøôÁßçË°°ÈáèÂõ†ÊûúÊïàÂ∫îÁöÑÊñπÊ≥ïÊù•ÂºÄÂèë‰∏ÄÁßçÊîπËøõÁöÑÂºïÂØºÊñπÊ≥ïÔºåÂç≥ SAE ÁõÆÊ†áÂºïÂØºÔºàSAE-TSÔºâÔºåÂÆÉÂèØ‰ª•ÊâæÂà∞ÂºïÂØºÂêëÈáèÊù•ÈíàÂØπÁâπÂÆöÁöÑ SAE ÁâπÂæÅÔºåÂêåÊó∂ÊúÄÂ§ßÁ®ãÂ∫¶Âú∞ÂáèÂ∞ëÊÑèÂ§ñÁöÑÂâØ‰ΩúÁî®„ÄÇÊàë‰ª¨Ë°®ÊòéÔºåÊÄª‰ΩìËÄåË®ÄÔºåÂú®ÂêÑÁßç‰ªªÂä°‰∏äËøõË°åËØÑ‰º∞Êó∂ÔºåSAE-TS Âú®ÂºïÂØºÊïàÊûúÂíåËøûË¥ØÊÄßÊñπÈù¢ÊØî CAA Âíå SAE ÁâπÂæÅÂºïÂØºÁöÑÂπ≥Ë°°ÊÄßÊõ¥Â•Ω„ÄÇ

##### **Double Descent Meets Out-of-Distribution Detection: Theoretical Insights and Empirical Analysis on the role of model complexity**
2411.02184v1 by Mou√Øn Ben Ammar, David Brellmann, Arturo Mendoza, Antoine Manzanera, Gianni Franchi

While overparameterization is known to benefit generalization, its impact on
Out-Of-Distribution (OOD) detection is less understood. This paper investigates
the influence of model complexity in OOD detection. We propose an expected OOD
risk metric to evaluate classifiers confidence on both training and OOD
samples. Leveraging Random Matrix Theory, we derive bounds for the expected OOD
risk of binary least-squares classifiers applied to Gaussian data. We show that
the OOD risk depicts an infinite peak, when the number of parameters is equal
to the number of samples, which we associate with the double descent
phenomenon. Our experimental study on different OOD detection methods across
multiple neural architectures extends our theoretical insights and highlights a
double descent curve. Our observations suggest that overparameterization does
not necessarily lead to better OOD detection. Using the Neural Collapse
framework, we provide insights to better understand this behavior. To
facilitate reproducibility, our code will be made publicly available upon
publication.

ÊëòË¶ÅÔºöÂÑòÁÆ°ÈÅéÂ∫¶ÂèÉÊï∏ÂåñÂ∑≤Áü•ÊúâÂä©ÊñºÊ≥õÂåñÔºå‰ΩÜÂÆÉÂ∞ç Out-Of-Distribution (OOD) ÂÅµÊ∏¨ÁöÑÂΩ±ÈüøÂçªÈÆÆÁÇ∫‰∫∫Áü•„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÊ®°ÂûãË§áÈõúÂ∫¶Â∞ç OOD ÂÅµÊ∏¨ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÊèêÂá∫È†êÊúüÁöÑ OOD È¢®Èö™ÈáèÂ∫¶Ôºå‰ª•Ë©ï‰º∞ÂàÜÈ°ûÂô®Â∞çË®ìÁ∑¥Âíå OOD Ê®£Êú¨ÁöÑ‰ø°ÂøÉ„ÄÇÂà©Áî®Èö®Ê©üÁü©Èô£ÁêÜË´ñÔºåÊàëÂÄëÊé®Â∞éÂá∫ÊáâÁî®ÊñºÈ´òÊñØË≥áÊñôÁöÑ‰∫åÂÖÉÊúÄÂ∞èÂπ≥ÊñπÂàÜÈ°ûÂô®ÁöÑÈ†êÊúü OOD È¢®Èö™ÁïåÁ∑ö„ÄÇÊàëÂÄëÈ°ØÁ§∫ OOD È¢®Èö™ÊèèÁπ™‰∫Ü‰∏ÄÂÄãÁÑ°ÈôêÂ≥∞ÂÄºÔºåÁï∂ÂèÉÊï∏Êï∏ÈáèÁ≠âÊñºÊ®£Êú¨Êï∏ÈáèÊôÇÔºåÊàëÂÄëÂ∞áÂÖ∂ËàáÈõôÈáç‰∏ãÈôçÁèæË±°ËÅØÁπ´Ëµ∑‰æÜ„ÄÇÊàëÂÄëÂ∞çË∑®Â§öÂÄãÁ•ûÁ∂ìÊû∂ÊßãÁöÑ‰∏çÂêå OOD ÂÅµÊ∏¨ÊñπÊ≥ïÈÄ≤Ë°åÁöÑÂØ¶È©óÁ†îÁ©∂Êì¥Â±ï‰∫ÜÊàëÂÄëÁöÑÁêÜË´ñË¶ãËß£Ôºå‰∏¶Á™ÅÂá∫‰∫ÜÈõôÈáç‰∏ãÈôçÊõ≤Á∑ö„ÄÇÊàëÂÄëÁöÑËßÄÂØüÁµêÊûúË°®ÊòéÔºåÈÅéÂ∫¶ÂèÉÊï∏Âåñ‰∏ç‰∏ÄÂÆöÊúÉÂ∞éËá¥Êõ¥Â•ΩÁöÑ OOD ÂÅµÊ∏¨„ÄÇ‰ΩøÁî®Á•ûÁ∂ìÂ¥©ÊΩ∞Ê°ÜÊû∂ÔºåÊàëÂÄëÊèê‰æõË¶ãËß£‰ª•Êõ¥Â•ΩÂú∞ÁêÜËß£Ê≠§Ë°åÁÇ∫„ÄÇÁÇ∫‰∫Ü‰æøÊñºÈáçÁèæÔºåÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂ∞áÂú®ÁôºË°®ÂæåÂÖ¨Èñã„ÄÇ

##### **Behavioral Sequence Modeling with Ensemble Learning**
2411.02174v1 by Maxime Kawawa-Beaudan, Srijan Sood, Soham Palande, Ganapathy Mani, Tucker Balch, Manuela Veloso

We investigate the use of sequence analysis for behavior modeling,
emphasizing that sequential context often outweighs the value of aggregate
features in understanding human behavior. We discuss framing common problems in
fields like healthcare, finance, and e-commerce as sequence modeling tasks, and
address challenges related to constructing coherent sequences from fragmented
data and disentangling complex behavior patterns. We present a framework for
sequence modeling using Ensembles of Hidden Markov Models, which are
lightweight, interpretable, and efficient. Our ensemble-based scoring method
enables robust comparison across sequences of different lengths and enhances
performance in scenarios with imbalanced or scarce data. The framework scales
in real-world scenarios, is compatible with downstream feature-based modeling,
and is applicable in both supervised and unsupervised learning settings. We
demonstrate the effectiveness of our method with results on a longitudinal
human behavior dataset.

ÊëòË¶ÅÔºöÊàëÂÄëÁ†îÁ©∂Â∫èÂàóÂàÜÊûêÂú®Ë°åÁÇ∫Âª∫Ê®°‰∏≠ÁöÑÊáâÁî®Ôºå
Âº∑Ë™øÂ∫èÂàóËÑàÁµ°ÈÄöÂ∏∏ÊØîÁ∏ΩÂíåÁâπÂæµÊõ¥ËÉΩÁêÜËß£‰∫∫È°ûË°åÁÇ∫„ÄÇÊàëÂÄëË®éË´ñÂ∞áÈÜ´ÁôÇ‰øùÂÅ•„ÄÅÈáëËûçÂíåÈõªÂ≠êÂïÜÂãôÁ≠âÈ†òÂüü‰∏≠ÁöÑÂ∏∏Ë¶ãÂïèÈ°åË®≠ÂÆöÁÇ∫Â∫èÂàóÂª∫Ê®°‰ªªÂãôÔºå‰∏¶Ëß£Ê±∫ËàáÂæûÁâáÊÆµÂåñË≥áÊñôÂª∫ÊßãÈÄ£Ë≤´Â∫èÂàóÂíåËß£ÈñãË§áÈõúË°åÁÇ∫Ê®°ÂºèÁõ∏ÈóúÁöÑÊåëÊà∞„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄã‰ΩøÁî®Èö±ËóèÈ¶¨ÂèØÂ§´Ê®°ÂûãÈõÜÂêàÈÄ≤Ë°åÂ∫èÂàóÂª∫Ê®°ÁöÑÊ°ÜÊû∂ÔºåË©≤Ê°ÜÊû∂ËºïÈáè„ÄÅÂèØËß£Èáã‰∏îÊúâÊïàÁéá„ÄÇÊàëÂÄëÂü∫ÊñºÈõÜÂêàÁöÑË©ïÂàÜÊñπÊ≥ïËÉΩÂ§†Â∞ç‰∏çÂêåÈï∑Â∫¶ÁöÑÂ∫èÂàóÈÄ≤Ë°åÁ©©ÂÅ•ÊØîËºÉÔºå‰∏¶Âú®Ë≥áÊñô‰∏çÂπ≥Ë°°ÊàñÁ®ÄÂ∞ëÁöÑÊÉÖÊ≥Å‰∏ãÊèêÂçáÊïàËÉΩ„ÄÇË©≤Ê°ÜÊû∂Âú®ÁúüÂØ¶‰∏ñÁïåÂ†¥ÊôØ‰∏≠ÂÖ∑ÊúâÂèØÊì¥ÂÖÖÊÄßÔºåËàá‰∏ãÊ∏∏Âü∫ÊñºÁâπÂæµÁöÑÂª∫Ê®°Áõ∏ÂÆπÔºå‰∏îÈÅ©Áî®ÊñºÁõ£Áù£ÂºèÂíåÈùûÁõ£Áù£ÂºèÂ≠∏ÁøíË®≠ÂÆö„ÄÇÊàëÂÄëÈÄèÈÅéÁ∏±Âêë‰∫∫È°ûË°åÁÇ∫Ë≥áÊñôÈõÜÁöÑÁµêÊûúË≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Do graph neural network states contain graph properties?**
2411.02168v1 by Tom Pelletreau-Duris, Ruud van Bakel, Michael Cochez

Graph learning models achieve state-of-the-art performance on many tasks, but
this often requires increasingly large model sizes. Accordingly, the complexity
of their representations increase. Explainability techniques (XAI) have made
remarkable progress in the interpretability of ML models. However, the
non-relational nature of Graph Neural Networks (GNNs) make it difficult to
reuse already existing XAI methods. While other works have focused on
instance-based explanation methods for GNNs, very few have investigated
model-based methods and, to our knowledge, none have tried to probe the
embedding of the GNNs for well-known structural graph properties. In this paper
we present a model agnostic explainability pipeline for Graph Neural Networks
(GNNs) employing diagnostic classifiers. This pipeline aims to probe and
interpret the learned representations in GNNs across various architectures and
datasets, refining our understanding and trust in these models.

ÊëòË¶ÅÔºöÂúñÂΩ¢Â≠∏ÁøíÊ®°ÂûãÂú®Ë®±Â§ö‰ªªÂãô‰∏äÈÉΩËÉΩÈÅîÂà∞ÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºå‰ΩÜÈÄôÈÄöÂ∏∏ÈúÄË¶ÅË∂ä‰æÜË∂äÂ§ßÁöÑÊ®°ÂûãÂ∞∫ÂØ∏„ÄÇÂõ†Ê≠§ÔºåÂÆÉÂÄëÁöÑË°®Á§∫ÂΩ¢Âºè‰πüË∂ä‰æÜË∂äË§áÈõú„ÄÇÂèØËß£ÈáãÊÄßÊäÄË°ì (XAI) Âú®Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÊñπÈù¢ÂèñÂæó‰∫ÜÈ°ØËëóÈÄ≤Â±ï„ÄÇÁÑ∂ËÄåÔºåÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÁöÑÈùûÈóú‰øÇÊÄßË≥™‰ΩøÂæóÈõ£‰ª•ÈáçË§á‰ΩøÁî®ÁèæÊúâÁöÑ XAI ÊñπÊ≥ï„ÄÇÈõñÁÑ∂ÂÖ∂‰ªñ‰ΩúÂìÅÂ∞àÊ≥®Êñº GNN ÁöÑÂü∫ÊñºÂØ¶‰æãÁöÑËß£ÈáãÊñπÊ≥ïÔºå‰ΩÜÂæàÂ∞ëÊúâ‰∫∫Á†îÁ©∂Âü∫ÊñºÊ®°ÂûãÁöÑÊñπÊ≥ïÔºåËÄå‰∏îÊìöÊàëÂÄëÊâÄÁü•ÔºåÊ≤íÊúâ‰∫∫ÂòóË©¶Êé¢Êü• GNN ÁöÑÂµåÂÖ•‰ª•‰∫ÜËß£Â∑≤Áü•ÁöÑÁµêÊßãÂúñÂΩ¢Â±¨ÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãËàáÊ®°ÂûãÁÑ°ÈóúÁöÑÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÂèØËß£ÈáãÊÄßÁÆ°ÈÅìÔºåÊé°Áî®Ë®∫Êñ∑ÂàÜÈ°ûÂô®„ÄÇÊ≠§ÁÆ°ÈÅìÊó®Âú®Êé¢Êü•ÂíåËß£ÈáãÂêÑÁ®ÆÊû∂ÊßãÂíåË≥áÊñôÈõÜ‰∏≠ÁöÑ GNN ‰∏≠Â≠∏ÁøíÂà∞ÁöÑË°®Á§∫ÂΩ¢ÂºèÔºåÁ≤æÈÄ≤ÊàëÂÄëÂ∞çÈÄô‰∫õÊ®°ÂûãÁöÑÁêÜËß£Âíå‰ø°‰ªª„ÄÇ

##### **Training Compute-Optimal Protein Language Models**
2411.02142v1 by Xingyi Cheng, Bo Chen, Pan Li, Jing Gong, Jie Tang, Le Song

We explore optimally training protein language models, an area of significant
interest in biological research where guidance on best practices is limited.
Most models are trained with extensive compute resources until performance
gains plateau, focusing primarily on increasing model sizes rather than
optimizing the efficient compute frontier that balances performance and compute
budgets. Our investigation is grounded in a massive dataset consisting of 939
million protein sequences. We trained over 300 models ranging from 3.5 million
to 10.7 billion parameters on 5 to 200 billion unique tokens, to investigate
the relations between model sizes, training token numbers, and objectives.
First, we observed the effect of diminishing returns for the Causal Language
Model (CLM) and that of overfitting for the Masked Language Model~(MLM) when
repeating the commonly used Uniref database. To address this, we included
metagenomic protein sequences in the training set to increase the diversity and
avoid the plateau or overfitting effects. Second, we obtained the scaling laws
of CLM and MLM on Transformer, tailored to the specific characteristics of
protein sequence data. Third, we observe a transfer scaling phenomenon from CLM
to MLM, further demonstrating the effectiveness of transfer through scaling
behaviors based on estimated Effectively Transferred Tokens. Finally, to
validate our scaling laws, we compare the large-scale versions of ESM-2 and
PROGEN2 on downstream tasks, encompassing evaluations of protein generation as
well as structure- and function-related tasks, all within less or equivalent
pre-training compute budgets.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÊé¢Ë®éÊúÄ‰Ω≥Ë®ìÁ∑¥ËõãÁôΩË≥™Ë™ûË®ÄÊ®°ÂûãÔºåÈÄôÊòØÁîüÁâ©Á†îÁ©∂‰∏≠‰∏ÄÂÄãÈáçË¶ÅÁöÑÈ†òÂüüÔºå‰ΩÜÊúÄ‰Ω≥ÂØ¶ÂãôÁöÑÊåáÂ∞éÊñπÈáùÊúâÈôê„ÄÇ
Â§ßÂ§öÊï∏Ê®°ÂûãÈÉΩ‰ΩøÁî®Â§ßÈáèÁöÑÈÅãÁÆóË≥áÊ∫êÈÄ≤Ë°åË®ìÁ∑¥ÔºåÁõ¥Âà∞ÊïàËÉΩÂ¢ûÁõäÈÅîÂà∞Âπ≥Á©©ÊúüÔºå‰∏ªË¶ÅËëóÈáçÊñºÂ¢ûÂä†Ê®°ÂûãË¶èÊ®°ÔºåËÄå‰∏çÊòØÊúÄ‰Ω≥ÂåñÂπ≥Ë°°ÊïàËÉΩËàáÈÅãÁÆóÈ†êÁÆóÁöÑÊúâÊïàÈÅãÁÆóÂâçÁ∑£„ÄÇÊàëÂÄëÁöÑË™øÊü•ÊòØÂü∫Êñº‰∏ÄÂÄãÂåÖÂê´ 9.39 ÂÑÑÂÄãËõãÁôΩË≥™Â∫èÂàóÁöÑÈæêÂ§ßË≥áÊñôÈõÜ„ÄÇÊàëÂÄëË®ìÁ∑¥‰∫Ü 300 Â§öÂÄãÊ®°ÂûãÔºåÁØÑÂúçÂæû 350 Ëê¨Âà∞ 107 ÂÑÑÂÄãÂèÉÊï∏Ôºå‰ΩøÁî® 50 ÂÑÑÂà∞ 2000 ÂÑÑÂÄãÁç®ÁâπÁ¨¶ËôüÔºå‰æÜÊé¢Ë®éÊ®°ÂûãË¶èÊ®°„ÄÅË®ìÁ∑¥Á¨¶ËôüÊï∏ÈáèÂíåÁõÆÊ®ô‰πãÈñìÁöÑÈóú‰øÇ„ÄÇ
È¶ñÂÖàÔºåÊàëÂÄëËßÄÂØüÂà∞Âõ†ÊûúË™ûË®ÄÊ®°Âûã (CLM) ÁöÑÂ†±ÈÖ¨ÈÅûÊ∏õÊïàÊáâÔºå‰ª•ÂèäÈáçË§á‰ΩøÁî®Â∏∏Ë¶ãÁöÑ Uniref Ë≥áÊñôÂ∫´ÊôÇÔºåÈÅÆËîΩË™ûË®ÄÊ®°Âûã (MLM) ÁöÑÈÅéÂ∫¶Êì¨ÂêàÊïàÊáâ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂú®Ë®ìÁ∑¥ÈõÜ‰∏≠Âä†ÂÖ•‰∫ÜÂÆèÂü∫Âõ†ÁµÑËõãÁôΩË≥™Â∫èÂàóÔºå‰ª•Â¢ûÂä†Â§öÊ®£ÊÄß‰∏¶ÈÅøÂÖçÂπ≥Á©©ÊúüÊàñÈÅéÂ∫¶Êì¨ÂêàÁöÑÊïàÊáâ„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÁç≤Âæó‰∫ÜÈáùÂ∞çËõãÁôΩË≥™Â∫èÂàóË≥áÊñôÁöÑÁâπÂÆöÁâπÂæµË™øÊï¥ÁöÑ Transformer ‰∏äÁöÑ CLM Âíå MLM ÁöÑÁ∏ÆÊîæÂÆöÂæã„ÄÇÁ¨¨‰∏âÔºåÊàëÂÄëËßÄÂØüÂà∞Âæû CLM Âà∞ MLM ÁöÑÂÇ≥Ëº∏Á∏ÆÊîæÁèæË±°ÔºåÈÄ≤‰∏ÄÊ≠•Ë≠âÊòé‰∫ÜÂü∫Êñº‰º∞Ë®àÁöÑÊúâÊïàÂÇ≥Ëº∏Á¨¶ËôüÁöÑÁ∏ÆÊîæË°åÁÇ∫ÁöÑÂÇ≥Ëº∏ÊïàËÉΩ„ÄÇÊúÄÂæåÔºåÁÇ∫‰∫ÜÈ©óË≠âÊàëÂÄëÁöÑÁ∏ÆÊîæÂÆöÂæãÔºåÊàëÂÄëÊØîËºÉ‰∫Ü ESM-2 Âíå PROGEN2 ÁöÑÂ§ßÂûãÁâàÊú¨Âú®‰∏ãÊ∏∏‰ªªÂãô‰∏äÁöÑË°®ÁèæÔºåÂåÖÊã¨ËõãÁôΩË≥™ÁîüÊàêÁöÑË©ï‰º∞‰ª•ÂèäËàáÁµêÊßãÂíåÂäüËÉΩÁõ∏ÈóúÁöÑ‰ªªÂãôÔºåÊâÄÊúâÈÄô‰∫õÈÉΩÂú®ËºÉÂ∞ëÊàñÁõ∏Áï∂ÁöÑÈ†êË®ìÁ∑¥ÈÅãÁÆóÈ†êÁÆóÂÖß„ÄÇ</paragraph>

##### **Generating the Traces You Need: A Conditional Generative Model for Process Mining Data**
2411.02131v1 by Riccardo Graziosi, Massimiliano Ronzani, Andrei Buliga, Chiara Di Francescomarino, Francesco Folino, Chiara Ghidini, Francesca Meneghello, Luigi Pontieri

In recent years, trace generation has emerged as a significant challenge
within the Process Mining community. Deep Learning (DL) models have
demonstrated accuracy in reproducing the features of the selected processes.
However, current DL generative models are limited in their ability to adapt the
learned distributions to generate data samples based on specific conditions or
attributes. This limitation is particularly significant because the ability to
control the type of generated data can be beneficial in various contexts,
enabling a focus on specific behaviours, exploration of infrequent patterns, or
simulation of alternative 'what-if' scenarios. In this work, we address this
challenge by introducing a conditional model for process data generation based
on a conditional variational autoencoder (CVAE). Conditional models offer
control over the generation process by tuning input conditional variables,
enabling more targeted and controlled data generation. Unlike other domains,
CVAE for process mining faces specific challenges due to the multiperspective
nature of the data and the need to adhere to control-flow rules while ensuring
data variability. Specifically, we focus on generating process executions
conditioned on control flow and temporal features of the trace, allowing us to
produce traces for specific, identified sub-processes. The generated traces are
then evaluated using common metrics for generative model assessment, along with
additional metrics to evaluate the quality of the conditional generation

ÊëòË¶ÅÔºöËøëÂπ¥Êù•ÔºåËΩ®ËøπÁîüÊàêÂ∑≤Êàê‰∏∫ÊµÅÁ®ãÊåñÊéòÁ§æÂå∫‰∏≠ÁöÑÈáçÂ§ßÊåëÊàò„ÄÇÊ∑±Â∫¶Â≠¶‰π† (DL) Ê®°ÂûãÂ∑≤ËØÅÊòéËÉΩÂ§üÂáÜÁ°ÆÂú∞ÂÜçÁé∞ÊâÄÈÄâÊµÅÁ®ãÁöÑÁâπÂæÅ„ÄÇÁÑ∂ËÄåÔºåÂΩìÂâçÁöÑ DL ÁîüÊàêÊ®°ÂûãÂú®Ê†πÊçÆÁâπÂÆöÊù°‰ª∂ÊàñÂ±ûÊÄßÁîüÊàêÊï∞ÊçÆÊ†∑Êú¨‰ª•ÈÄÇÂ∫îÂ≠¶‰π†ÂàÜÂ∏ÉÊñπÈù¢Â≠òÂú®Â±ÄÈôêÊÄß„ÄÇËøôÁßçÈôêÂà∂Â∞§ÂÖ∂ÈáçË¶ÅÔºåÂõ†‰∏∫Âú®ÂêÑÁßçÊÉÖÂÜµ‰∏ãÊéßÂà∂ÁîüÊàêÊï∞ÊçÆÁ±ªÂûãÁöÑÂäüËÉΩÂèØËÉΩÊòØÊúâÁõäÁöÑÔºåËÉΩÂ§ü‰∏ìÊ≥®‰∫éÁâπÂÆöË°å‰∏∫„ÄÅÊé¢Á¥¢‰∏çÈ¢ëÁπÅÁöÑÊ®°ÂºèÊàñÊ®°ÊãüÊõø‰ª£ÁöÑ‚ÄúÂÅáËÆæ‚ÄùÂú∫ÊôØ„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ÈÄöËøáÂºïÂÖ•Âü∫‰∫éÊù°‰ª∂ÂèòÂàÜËá™Âä®ÁºñÁ†ÅÂô® (CVAE) ÁöÑÊµÅÁ®ãÊï∞ÊçÆÁîüÊàêÊù°‰ª∂Ê®°ÂûãÊù•Â∫îÂØπËøô‰∏ÄÊåëÊàò„ÄÇÊù°‰ª∂Ê®°ÂûãÈÄöËøáË∞ÉÊï¥ËæìÂÖ•Êù°‰ª∂ÂèòÈáèÊù•ÊéßÂà∂ÁîüÊàêËøáÁ®ãÔºå‰ªéËÄåÂÆûÁé∞Êõ¥ÊúâÈíàÂØπÊÄßÂíåÂèØÊéßÁöÑÊï∞ÊçÆÁîüÊàê„ÄÇ‰∏éÂÖ∂‰ªñÈ¢ÜÂüü‰∏çÂêåÔºåÊµÅÁ®ãÊåñÊéòÁöÑ CVAE Èù¢‰∏¥ÁùÄÁâπÂÆöÊåëÊàòÔºåÂõ†‰∏∫Êï∞ÊçÆÂÖ∑ÊúâÂ§öËßÜËßíÁöÑÊÄßË¥®ÔºåÂπ∂‰∏îÈúÄË¶ÅÈÅµÂÆàÊéßÂà∂ÊµÅËßÑÂàôÔºåÂêåÊó∂Á°Æ‰øùÊï∞ÊçÆÂèØÂèòÊÄß„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨‰∏ìÊ≥®‰∫éÁîüÊàêÂèóËΩ®ËøπÁöÑÊéßÂà∂ÊµÅÂíåÊó∂Èó¥ÁâπÂæÅÂà∂Á∫¶ÁöÑÊµÅÁ®ãÊâßË°åÔºå‰ªéËÄå‰ΩøÊàë‰ª¨ËÉΩÂ§ü‰∏∫ÁâπÂÆöÂ∑≤ËØÜÂà´ÁöÑÂ≠êÊµÅÁ®ãÁîüÊàêËΩ®Ëøπ„ÄÇÁÑ∂Âêé‰ΩøÁî®ÁîüÊàêÊ®°ÂûãËØÑ‰º∞ÁöÑÂ∏∏Áî®ÊåáÊ†á‰ª•ÂèäÂÖ∂‰ªñÊåáÊ†áÊù•ËØÑ‰º∞ÁîüÊàêËΩ®ËøπÔºå‰ª•ËØÑ‰º∞Êù°‰ª∂ÁîüÊàêÁöÑË¥®Èáè

##### **Unsupervised detection of semantic correlations in big data**
2411.02126v1 by Santiago Acevedo, Alex Rodriguez, Alessandro Laio

In real-world data, information is stored in extremely large feature vectors.
These variables are typically correlated due to complex interactions involving
many features simultaneously. Such correlations qualitatively correspond to
semantic roles and are naturally recognized by both the human brain and
artificial neural networks. This recognition enables, for instance, the
prediction of missing parts of an image or text based on their context. We
present a method to detect these correlations in high-dimensional data
represented as binary numbers. We estimate the binary intrinsic dimension of a
dataset, which quantifies the minimum number of independent coordinates needed
to describe the data, and is therefore a proxy of semantic complexity. The
proposed algorithm is largely insensitive to the so-called curse of
dimensionality, and can therefore be used in big data analysis. We test this
approach identifying phase transitions in model magnetic systems and we then
apply it to the detection of semantic correlations of images and text inside
deep neural networks.

ÊëòË¶ÅÔºöÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑË≥áÊñô‰∏≠ÔºåË≥áË®äÂÑ≤Â≠òÂú®Ê•µÂ§ßÁöÑÁâπÂæµÂêëÈáè‰∏≠„ÄÇ
ÈÄô‰∫õËÆäÊï∏ÈÄöÂ∏∏Áî±ÊñºÂåÖÂê´Ë®±Â§öÁâπÂæµÁöÑË§áÈõú‰∫§‰∫í‰ΩúÁî®ËÄåÁõ∏Èóú„ÄÇ
ÈÄôÁ®ÆÁõ∏ÈóúÊÄßÂú®Ë≥™‰∏äÂ∞çÊáâÊñºË™ûÁæ©ËßíËâ≤Ôºå‰∏¶‰∏îËá™ÁÑ∂Âú∞Ë¢´‰∫∫ËÖ¶Âíå‰∫∫Â∑•Á•ûÁ∂ìÁ∂≤Ë∑ØÊâÄË≠òÂà•„ÄÇ
‰æãÂ¶ÇÔºåÈÄôÁ®ÆË≠òÂà•‰ΩøÈ†êÊ∏¨ÂΩ±ÂÉèÊàñÊñáÂ≠óÁöÑÈÅ∫Â§±ÈÉ®ÂàÜÊàêÁÇ∫ÂèØËÉΩÔºåÂÖ∂‰æùÊìöÊòØÂÖ∂ËÑàÁµ°„ÄÇ
ÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñπÊ≥ï‰æÜÂÅµÊ∏¨È´òÁ∂≠Â∫¶Ë≥áÊñô‰∏≠ÁöÑÈÄô‰∫õÁõ∏ÈóúÊÄßÔºåÈÄô‰∫õË≥áÊñôË°®Á§∫ÁÇ∫‰∫åÈÄ≤‰ΩçÊï∏Â≠ó„ÄÇ
ÊàëÂÄë‰º∞Ë®àË≥áÊñôÈõÜÁöÑ‰∫åÈÄ≤‰ΩçÂÖßÁßâÁ∂≠Â∫¶ÔºåÂÆÉÈáèÂåñÊèèËø∞Ë≥áÊñôÊâÄÈúÄÁöÑÊúÄÂ∞èÁç®Á´ãÂ∫ßÊ®ôÊï∏ÔºåÂõ†Ê≠§ÊòØË™ûÁæ©Ë§áÈõúÊÄßÁöÑ‰ª£ÁêÜ„ÄÇ
ÊâÄÊèêÂá∫ÁöÑÊºîÁÆóÊ≥ïÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰∏çÂèóÊâÄË¨ÇÁöÑÁ∂≠Â∫¶Ë©õÂííÂΩ±ÈüøÔºåÂõ†Ê≠§ÂèØÁî®ÊñºÂ§ßË≥áÊñôÂàÜÊûê„ÄÇ
ÊàëÂÄëÊ∏¨Ë©¶Ê≠§ÊñπÊ≥ï‰æÜË≠òÂà•Ê®°ÂûãÁ£ÅÊÄßÁ≥ªÁµ±‰∏≠ÁöÑÁõ∏ËÆäÔºåÁÑ∂ÂæåÂ∞áÂÖ∂ÊáâÁî®ÊñºÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑Ø‰∏≠ÂΩ±ÂÉèÂíåÊñáÂ≠óÁöÑË™ûÁæ©Áõ∏ÈóúÊÄßÂÅµÊ∏¨„ÄÇ

##### **Revisiting K-mer Profile for Effective and Scalable Genome Representation Learning**
2411.02125v1 by Abdulkadir Celikkanat, Andres R. Masegosa, Thomas D. Nielsen

Obtaining effective representations of DNA sequences is crucial for genome
analysis. Metagenomic binning, for instance, relies on genome representations
to cluster complex mixtures of DNA fragments from biological samples with the
aim of determining their microbial compositions. In this paper, we revisit
k-mer-based representations of genomes and provide a theoretical analysis of
their use in representation learning. Based on the analysis, we propose a
lightweight and scalable model for performing metagenomic binning at the genome
read level, relying only on the k-mer compositions of the DNA fragments. We
compare the model to recent genome foundation models and demonstrate that while
the models are comparable in performance, the proposed model is significantly
more effective in terms of scalability, a crucial aspect for performing
metagenomic binning of real-world datasets.

ÊëòË¶ÅÔºöÁç≤Âæó DNA Â∫èÂàóÁöÑÊúâÊïàË°®Á§∫Â∞çÊñºÂü∫Âõ†ÁµÑÂàÜÊûêËá≥ÈóúÈáçË¶Å„ÄÇ‰æãÂ¶ÇÔºåÂÆèÂü∫Âõ†ÁµÑÂàÜÁÆ±‰æùË≥¥ÊñºÂü∫Âõ†ÁµÑË°®Á§∫Ôºå‰ª•Áæ§ÈõÜ‰æÜËá™ÁîüÁâ©Ê®£Êú¨ÁöÑ DNA ÁâáÊÆµÁöÑË§áÈõúÊ∑∑ÂêàÁâ©ÔºåÁõÆÁöÑÊòØÁ¢∫ÂÆöÂÆÉÂÄëÁöÑÂæÆÁîüÁâ©ÁµÑÊàê„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈáçÊñ∞ÂØ©Ë¶ñ‰∫ÜÂü∫Êñº k-mer ÁöÑÂü∫Âõ†ÁµÑË°®Á§∫Ôºå‰∏¶Â∞çÂÆÉÂÄëÂú®Ë°®Á§∫Â≠∏Áøí‰∏≠ÁöÑ‰ΩøÁî®Êèê‰æõ‰∫ÜÁêÜË´ñÂàÜÊûê„ÄÇÂü∫ÊñºÂàÜÊûêÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãËºïÈáèÁ¥ö‰∏îÂèØÊì¥ÂÖÖÁöÑÊ®°ÂûãÔºåÁî®ÊñºÂú®Âü∫Âõ†ÁµÑËÆÄÂèñÂ±§Á¥öÂü∑Ë°åÂÆèÂü∫Âõ†ÁµÑÂàÜÁÆ±ÔºåÂÉÖ‰æùË≥¥Êñº DNA ÁâáÊÆµÁöÑ k-mer ÁµÑÊàê„ÄÇÊàëÂÄëÂ∞áË©≤Ê®°ÂûãËàáÊúÄËøëÁöÑÂü∫Âõ†ÁµÑÂü∫Á§éÊ®°ÂûãÈÄ≤Ë°åÊØîËºÉÔºå‰∏¶Ë≠âÊòéÈõñÁÑ∂ÈÄô‰∫õÊ®°ÂûãÂú®ÊÄßËÉΩ‰∏äÁõ∏Áï∂Ôºå‰ΩÜÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂú®ÂèØÊì¥ÂÖÖÊÄßÊñπÈù¢È°ØËëóÊõ¥ÊúâÊïàÔºåÈÄôÊòØÂü∑Ë°åÂØ¶Èöõ‰∏ñÁïåË≥áÊñôÈõÜÁöÑÂÆèÂü∫Âõ†ÁµÑÂàÜÁÆ±ÁöÑ‰∏ÄÂÄãÈóúÈçµÊñπÈù¢„ÄÇ

##### **Adaptive Sparse Allocation with Mutual Choice & Feature Choice Sparse Autoencoders**
2411.02124v1 by Kola Ayonrinde

Sparse autoencoders (SAEs) are a promising approach to extracting features
from neural networks, enabling model interpretability as well as causal
interventions on model internals. SAEs generate sparse feature representations
using a sparsifying activation function that implicitly defines a set of
token-feature matches. We frame the token-feature matching as a resource
allocation problem constrained by a total sparsity upper bound. For example,
TopK SAEs solve this allocation problem with the additional constraint that
each token matches with at most $k$ features. In TopK SAEs, the $k$ active
features per token constraint is the same across tokens, despite some tokens
being more difficult to reconstruct than others. To address this limitation, we
propose two novel SAE variants, Feature Choice SAEs and Mutual Choice SAEs,
which each allow for a variable number of active features per token. Feature
Choice SAEs solve the sparsity allocation problem under the additional
constraint that each feature matches with at most $m$ tokens. Mutual Choice
SAEs solve the unrestricted allocation problem where the total sparsity budget
can be allocated freely between tokens and features. Additionally, we introduce
a new auxiliary loss function, $\mathtt{aux\_zipf\_loss}$, which generalises
the $\mathtt{aux\_k\_loss}$ to mitigate dead and underutilised features. Our
methods result in SAEs with fewer dead features and improved reconstruction
loss at equivalent sparsity levels as a result of the inherent adaptive
computation. More accurate and scalable feature extraction methods provide a
path towards better understanding and more precise control of foundation
models.

ÊëòË¶ÅÔºö<paragraph>Á®ÄÁñèËá™ÁºñÁ†ÅÂô® (SAE) ÊòØ‰∏ÄÁßç‰ªéÁ•ûÁªèÁΩëÁªú‰∏≠ÊèêÂèñÁâπÂæÅÁöÑÊúâÂâçÈÄîÁöÑÊñπÊ≥ïÔºåÂÆÉÊîØÊåÅÊ®°ÂûãÂèØËß£ÈáäÊÄß‰ª•ÂèäÂØπÊ®°ÂûãÂÜÖÈÉ®ÁöÑÂõ†ÊûúÂπ≤È¢Ñ„ÄÇSAE ‰ΩøÁî®Á®ÄÁñèÂåñÊøÄÊ¥ªÂáΩÊï∞ÁîüÊàêÁ®ÄÁñèÁâπÂæÅË°®ÂæÅÔºåËØ•ÂáΩÊï∞ÈöêÂºèÂÆö‰πâ‰∫Ü‰∏ÄÁªÑÊ†áËÆ∞ÁâπÂæÅÂåπÈÖç„ÄÇÊàë‰ª¨Â∞ÜÊ†áËÆ∞ÁâπÂæÅÂåπÈÖçÊûÑÂª∫‰∏∫ÂèóÊÄªÁ®ÄÁñèÂ∫¶‰∏äÈôêÁ∫¶ÊùüÁöÑËµÑÊ∫êÂàÜÈÖçÈóÆÈ¢ò„ÄÇ‰æãÂ¶ÇÔºåTopK SAE ‰ΩøÁî®ÈôÑÂä†Á∫¶ÊùüÊù•Ëß£ÂÜ≥Ê≠§ÂàÜÈÖçÈóÆÈ¢òÔºåÂç≥ÊØè‰∏™Ê†áËÆ∞ÊúÄÂ§ö‰∏é $k$ ‰∏™ÁâπÂæÅÂåπÈÖç„ÄÇÂú® TopK SAE ‰∏≠ÔºåÊØè‰∏™Ê†áËÆ∞ÁöÑ $k$ ‰∏™Ê¥ªÂä®ÁâπÂæÅÁ∫¶ÊùüÂú®ÊâÄÊúâÊ†áËÆ∞‰∏≠ÈÉΩÊòØÁõ∏ÂêåÁöÑÔºåÂ∞ΩÁÆ°Êúâ‰∫õÊ†áËÆ∞ÊØîÂÖ∂‰ªñÊ†áËÆ∞Êõ¥ÈöæÈáçÂª∫„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ê≠§ÈôêÂà∂ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏§ÁßçÊñ∞È¢ñÁöÑ SAE Âèò‰ΩìÔºåÂç≥ÁâπÂæÅÈÄâÊã© SAE ÂíåÁõ∏‰∫íÈÄâÊã© SAEÔºåÂÆÉ‰ª¨ÊØè‰∏™ÈÉΩÂÖÅËÆ∏ÊØè‰∏™Ê†áËÆ∞ÊúâÂèØÂèòÊï∞ÈáèÁöÑÊ¥ªÂä®ÁâπÂæÅ„ÄÇÁâπÂæÅÈÄâÊã© SAE Âú®ÈôÑÂä†Á∫¶Êùü‰∏ãËß£ÂÜ≥Á®ÄÁñèÂ∫¶ÂàÜÈÖçÈóÆÈ¢òÔºåÂç≥ÊØè‰∏™ÁâπÂæÅÊúÄÂ§ö‰∏é $m$ ‰∏™Ê†áËÆ∞ÂåπÈÖç„ÄÇÁõ∏‰∫íÈÄâÊã© SAE Ëß£ÂÜ≥‰∏çÂèóÈôêÂà∂ÁöÑÂàÜÈÖçÈóÆÈ¢òÔºåÂÖ∂‰∏≠ÊÄªÁ®ÄÁñèÂ∫¶È¢ÑÁÆóÂèØ‰ª•Âú®Ê†áËÆ∞ÂíåÁâπÂæÅ‰πãÈó¥Ëá™Áî±ÂàÜÈÖç„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑËæÖÂä©ÊçüÂ§±ÂáΩÊï∞ $\mathtt{aux\_zipf\_loss}$ÔºåÂÆÉÊ¶ÇÊã¨‰∫Ü $\mathtt{aux\_k\_loss}$ ‰ª•ÂáèËΩªÊ≠ªÁâπÂæÅÂíåÂà©Áî®‰∏çË∂≥ÁöÑÁâπÂæÅ„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÂØºËá¥ SAE ÂÖ∑ÊúâÊõ¥Â∞ëÁöÑÊ≠ªÁâπÂæÅÔºåÂπ∂‰∏îÁî±‰∫éÂõ∫ÊúâÁöÑËá™ÈÄÇÂ∫îËÆ°ÁÆóÔºåÂú®ÂêåÁ≠âÁ®ÄÁñèÂ∫¶Á∫ßÂà´‰∏ãÊîπËøõ‰∫ÜÈáçÂª∫ÊçüÂ§±„ÄÇÊõ¥ÂáÜÁ°ÆÂíåÂèØÊâ©Â±ïÁöÑÁâπÂæÅÊèêÂèñÊñπÊ≥ïÊèê‰æõ‰∫Ü‰∏ÄÊù°ÈÄîÂæÑÔºåÂèØ‰ª•Êõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÊõ¥Á≤æÁ°ÆÂú∞ÊéßÂà∂Âü∫Á°ÄÊ®°Âûã„ÄÇ</paragraph>

##### **Bridge-IF: Learning Inverse Protein Folding with Markov Bridges**
2411.02120v1 by Yiheng Zhu, Jialu Wu, Qiuyi Li, Jiahuan Yan, Mingze Yin, Wei Wu, Mingyang Li, Jieping Ye, Zheng Wang, Jian Wu

Inverse protein folding is a fundamental task in computational protein
design, which aims to design protein sequences that fold into the desired
backbone structures. While the development of machine learning algorithms for
this task has seen significant success, the prevailing approaches, which
predominantly employ a discriminative formulation, frequently encounter the
error accumulation issue and often fail to capture the extensive variety of
plausible sequences. To fill these gaps, we propose Bridge-IF, a generative
diffusion bridge model for inverse folding, which is designed to learn the
probabilistic dependency between the distributions of backbone structures and
protein sequences. Specifically, we harness an expressive structure encoder to
propose a discrete, informative prior derived from structures, and establish a
Markov bridge to connect this prior with native sequences. During the inference
stage, Bridge-IF progressively refines the prior sequence, culminating in a
more plausible design. Moreover, we introduce a reparameterization perspective
on Markov bridge models, from which we derive a simplified loss function that
facilitates more effective training. We also modulate protein language models
(PLMs) with structural conditions to precisely approximate the Markov bridge
process, thereby significantly enhancing generation performance while
maintaining parameter-efficient training. Extensive experiments on
well-established benchmarks demonstrate that Bridge-IF predominantly surpasses
existing baselines in sequence recovery and excels in the design of plausible
proteins with high foldability. The code is available at
https://github.com/violet-sto/Bridge-IF.

ÊëòË¶ÅÔºöÈÄÜÂêëËõãÁôΩË¥®ÊäòÂè†ÊòØËÆ°ÁÆóËõãÁôΩË¥®ËÆæËÆ°‰∏≠ÁöÑÂü∫Êú¨‰ªªÂä°ÔºåÂÖ∂ÁõÆÁöÑÊòØËÆæËÆ°ÊäòÂè†ÊàêÊâÄÈúÄÈ™®Êû∂ÁªìÊûÑÁöÑËõãÁôΩË¥®Â∫èÂàó„ÄÇËôΩÁÑ∂Êú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÁöÑÂºÄÂèëÂú®Ëøô‰∏™‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊàêÂäüÔºå‰ΩÜÂç†‰∏ªÂØºÂú∞‰ΩçÁöÑÊñπÊ≥ïÔºà‰∏ªË¶ÅÈááÁî®Âà§Âà´ÂºèÂÖ¨ÂºèÔºâÁªèÂ∏∏ÈÅáÂà∞ËØØÂ∑ÆÁ¥ØÁßØÈóÆÈ¢òÔºåÂπ∂‰∏îÁªèÂ∏∏Êó†Ê≥ïÊçïÊçâÂà∞Â§ßÈáèÂèØË°åÁöÑÂ∫èÂàó„ÄÇ‰∏∫‰∫ÜÂ°´Ë°•Ëøô‰∫õÁ©∫ÁôΩÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü Bridge-IFÔºå‰∏ÄÁßçÁî®‰∫éÈÄÜÂêëÊäòÂè†ÁöÑÁîüÊàêÊâ©Êï£Ê°•Ê®°ÂûãÔºåËØ•Ê®°ÂûãÊó®Âú®Â≠¶‰π†È™®Êû∂ÁªìÊûÑÂíåËõãÁôΩË¥®Â∫èÂàóÂàÜÂ∏É‰πãÈó¥ÁöÑÊ¶ÇÁéá‰æùËµñÊÄß„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨Âà©Áî®‰∏Ä‰∏™Ë°®ËææÁªìÊûÑÁºñÁ†ÅÂô®Êù•ÊèêÂá∫‰∏Ä‰∏™Á¶ªÊï£ÁöÑ„ÄÅ‰ªéÁªìÊûÑ‰∏≠Ê¥æÁîüÁöÑ‰ø°ÊÅØÂÖàÈ™åÔºåÂπ∂Âª∫Á´ã‰∏Ä‰∏™È©¨Â∞îÂèØÂ§´Ê°•Ê¢ÅÂ∞ÜÊ≠§ÂÖàÈ™å‰∏éÂ§©ÁÑ∂Â∫èÂàóËøûÊé•Ëµ∑Êù•„ÄÇÂú®Êé®ÁêÜÈò∂ÊÆµÔºåBridge-IF ÈÄêÊ∏êÁªÜÂåñÂÖàÈ™åÂ∫èÂàóÔºåÊúÄÁªàÂΩ¢Êàê‰∏Ä‰∏™Êõ¥ÂêàÁêÜÁöÑÂ∫èÂàó„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Âú®È©¨Â∞îÂèØÂ§´Ê°•Ê®°Âûã‰∏≠ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™ÈáçÊñ∞ÂèÇÊï∞ÂåñÁöÑËßÜËßíÔºå‰ªé‰∏≠Êàë‰ª¨Êé®ÂØºÂá∫‰∏Ä‰∏™ÁÆÄÂåñÁöÑÊçüÂ§±ÂáΩÊï∞Ôºå‰ª•‰øÉËøõÊõ¥ÊúâÊïàÁöÑËÆ≠ÁªÉ„ÄÇÊàë‰ª¨ËøòÁî®ÁªìÊûÑÊù°‰ª∂ÂØπËõãÁôΩË¥®ËØ≠Ë®ÄÊ®°Âûã (PLM) ËøõË°åË∞ÉÂà∂Ôºå‰ª•Á≤æÁ°ÆÈÄºËøëÈ©¨Â∞îÂèØÂ§´Ê°•ËøáÁ®ãÔºå‰ªéËÄåÂú®‰øùÊåÅÂèÇÊï∞È´òÊïàËÆ≠ÁªÉÁöÑÂêåÊó∂ÔºåÊòæËëóÊèêÈ´òÁîüÊàêÊÄßËÉΩ„ÄÇÂú®ÂÆåÂñÑÁöÑÂü∫ÂáÜ‰∏äËøõË°åÁöÑÂπøÊ≥õÂÆûÈ™åË°®ÊòéÔºåBridge-IF Âú®Â∫èÂàóÊÅ¢Â§çÊñπÈù¢ÊòéÊòæ‰ºò‰∫éÁé∞ÊúâÁöÑÂü∫Á∫øÔºåÂπ∂‰∏îÂú®ËÆæËÆ°ÂÖ∑ÊúâÈ´òÂèØÊäòÂè†ÊÄßÁöÑÂêàÁêÜËõãÁôΩË¥®ÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤„ÄÇ‰ª£Á†ÅÂèØÂú® https://github.com/violet-sto/Bridge-IF ‰∏≠Ëé∑Âæó„ÄÇ

##### **Grounding Emotional Descriptions to Electrovibration Haptic Signals**
2411.02118v1 by Guimin Hu, Zirui Zhao, Lukas Heilmann, Yasemin Vardar, Hasti Seifi

Designing and displaying haptic signals with sensory and emotional attributes
can improve the user experience in various applications. Free-form user
language provides rich sensory and emotional information for haptic design
(e.g., ``This signal feels smooth and exciting''), but little work exists on
linking user descriptions to haptic signals (i.e., language grounding). To
address this gap, we conducted a study where 12 users described the feel of 32
signals perceived on a surface haptics (i.e., electrovibration) display. We
developed a computational pipeline using natural language processing (NLP)
techniques, such as GPT-3.5 Turbo and word embedding methods, to extract
sensory and emotional keywords and group them into semantic clusters (i.e.,
concepts). We linked the keyword clusters to haptic signal features (e.g.,
pulse count) using correlation analysis. The proposed pipeline demonstrates the
viability of a computational approach to analyzing haptic experiences. We
discuss our future plans for creating a predictive model of haptic experience.

ÊëòË¶ÅÔºöÈÄèÈÅéÊÑüÂÆòÂíåÊÉÖÁ∑íÂ±¨ÊÄßË®≠Ë®àÂíåÈ°ØÁ§∫Ëß∏Ë¶∫Ë®äËôüÔºåÂèØ‰ª•ÊèêÂçáÂêÑÁ®ÆÊáâÁî®Á®ãÂºèÁöÑ‰ΩøÁî®ËÄÖÈ´îÈ©ó„ÄÇËá™Áî±ÂΩ¢ÂºèÁöÑ‰ΩøÁî®ËÄÖË™ûË®ÄÊèê‰æõË±êÂØåÁöÑÊÑüÂÆòÂíåÊÉÖÁ∑íË≥áË®äÔºåÂèØÁî®ÊñºËß∏Ë¶∫Ë®≠Ë®àÔºà‰æãÂ¶Ç„ÄåÈÄôÂÄãË®äËôüÊÑüË¶∫ÂæàÂπ≥È†Ü‰∏î‰ª§‰∫∫ËààÂ•Æ„ÄçÔºâÔºå‰ΩÜÂ∞á‰ΩøÁî®ËÄÖÊèèËø∞ÈÄ£ÁµêÂà∞Ëß∏Ë¶∫Ë®äËôüÔºà‰πüÂ∞±ÊòØË™ûË®ÄÂü∫Á§éÔºâÁöÑÁ†îÁ©∂ÂçªÂæàÂ∞ë„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÁ†îÁ©∂ÔºåËÆì 12 ‰Ωç‰ΩøÁî®ËÄÖÊèèËø∞Âú®Ë°®Èù¢Ëß∏Ë¶∫Ôºà‰πüÂ∞±ÊòØÈõªÊåØÂãïÔºâÈ°ØÁ§∫Âô®‰∏äÊÑüÁü•Âà∞ÁöÑ 32 ÂÄãË®äËôüÁöÑÊÑüË¶∫„ÄÇÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÊ¢ùÈÅãÁÆóÁÆ°ÈÅìÔºå‰ΩøÁî®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÊäÄË°ìÔºå‰æãÂ¶Ç GPT-3.5 Turbo ÂíåÂ≠óË©ûÂµåÂÖ•ÊñπÊ≥ïÔºå‰æÜËêÉÂèñÊÑüÂÆòÂíåÊÉÖÁ∑íÈóúÈçµÂ≠óÔºå‰∏¶Â∞áÂÆÉÂÄëÂàÜÁµÑÊàêË™ûÁæ©Âè¢ÈõÜÔºà‰πüÂ∞±ÊòØÊ¶ÇÂøµÔºâ„ÄÇÊàëÂÄë‰ΩøÁî®Áõ∏ÈóúÂàÜÊûêÂ∞áÈóúÈçµÂ≠óÂè¢ÈõÜÈÄ£ÁµêÂà∞Ëß∏Ë¶∫Ë®äËôüÁâπÂæµÔºà‰æãÂ¶ÇËÑàË°ùË®àÊï∏Ôºâ„ÄÇÂª∫Ë≠∞ÁöÑÈÅãÁÆóÁÆ°ÈÅìÂ±ïÁ§∫‰∫ÜÂàÜÊûêËß∏Ë¶∫È´îÈ©óÁöÑÈÅãÁÆóÊñπÊ≥ïÁöÑÂèØË°åÊÄß„ÄÇÊàëÂÄëË®éË´ñ‰∫ÜÂª∫Á´ãËß∏Ë¶∫È´îÈ©óÈ†êÊ∏¨Ê®°ÂûãÁöÑÊú™‰æÜË®àÁï´„ÄÇ

##### **AVSS: Layer Importance Evaluation in Large Language Models via Activation Variance-Sparsity Analysis**
2411.02117v1 by Zichen Song, Yuxin Wu, Sitan Huang, Zhongfeng Kang

The evaluation of layer importance in deep learning has been an active area
of research, with significant implications for model optimization and
interpretability. Recently, large language models (LLMs) have gained prominence
across various domains, yet limited studies have explored the functional
importance and performance contributions of individual layers within LLMs,
especially from the perspective of activation distribution. In this work, we
propose the Activation Variance-Sparsity Score (AVSS), a novel metric combining
normalized activation variance and sparsity to assess each layer's contribution
to model performance. By identifying and removing approximately the lowest 25%
of layers based on AVSS, we achieve over 90% of original model performance
across tasks such as question answering, language modeling, and sentiment
classification, indicating that these layers may be non-essential. Our approach
provides a systematic method for identifying less critical layers, contributing
to efficient large language model architectures.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏Áøí‰∏≠Â±§Á¥öÈáçË¶ÅÊÄßÁöÑË©ï‰º∞‰∏ÄÁõ¥ÊòØÁ†îÁ©∂ÁöÑÊ¥ªË∫çÈ†òÂüüÔºåÂ∞çÊ®°ÂûãÊúÄ‰Ω≥ÂåñÂíåÂèØËß£ÈáãÊÄßÊúâÈáçË¶ÅÁöÑÂΩ±Èüø„ÄÇÊúÄËøëÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂêÑÂÄãÈ†òÂüü‰∏≠Áç≤ÂæóÈ°ØËëóÂú∞‰ΩçÔºå‰ΩÜÊúâÈôêÁöÑÁ†îÁ©∂Êé¢Ë®é‰∫Ü LLM ‰∏≠ÂÄãÂà•Â±§Á¥öÁöÑÂäüËÉΩÈáçË¶ÅÊÄßÂíåÊïàËÉΩË≤¢ÁçªÔºåÁâπÂà•ÊòØÂæûÊøÄÂãµÂàÜ‰ΩàÁöÑËßíÂ∫¶‰æÜÁúã„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ÊøÄÂãµËÆäÁï∞Á®ÄÁñèÂ∫¶ÂàÜÊï∏ (AVSS)ÔºåÈÄôÊòØ‰∏ÄÂÄãÁµêÂêàÊ≠£Ë¶èÂåñÊøÄÂãµËÆäÁï∞ÂíåÁ®ÄÁñèÂ∫¶ÁöÑÊåáÊ®ôÔºåÁî®ÊñºË©ï‰º∞ÊØèÂÄãÂ±§Á¥öÂ∞çÊ®°ÂûãÊïàËÉΩÁöÑË≤¢Áçª„ÄÇÈÄèÈÅéË≠òÂà•‰∏¶ÁßªÈô§Â§ßÁ¥Ñ 25% ÊúÄ‰ΩéÂ±§Á¥öÁöÑ AVSSÔºåÊàëÂÄëÂú®ÂïèÁ≠î„ÄÅË™ûË®ÄÂª∫Ê®°ÂíåÊÉÖÁ∑íÂàÜÈ°ûÁ≠â‰ªªÂãô‰∏≠ÈÅîÂà∞‰∫ÜË∂ÖÈÅé 90% ÁöÑÂéüÂßãÊ®°ÂûãÊïàËÉΩÔºåÈÄôË°®Á§∫ÈÄô‰∫õÂ±§Á¥öÂèØËÉΩÊòØÈùûÂøÖË¶ÅÁöÑ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊèê‰æõ‰∫Ü‰∏ÄÂÄãÁ≥ªÁµ±ÂåñÁöÑÊñπÊ≥ï‰æÜË≠òÂà•ËºÉ‰∏çÈáçË¶ÅÁöÑÂ±§Á¥öÔºåÊúâÂä©ÊñºÂª∫Á´ãÊúâÊïàÁöÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÊû∂Êßã„ÄÇ

##### **Advancements and limitations of LLMs in replicating human color-word associations**
2411.02116v1 by Makoto Fukushima, Shusuke Eshita, Hiroshige Fukuhara

Color-word associations play a fundamental role in human cognition and design
applications. Large Language Models (LLMs) have become widely available and
demonstrated intelligent behaviors in various benchmarks with natural
conversation skills. However, their ability to replicate human color-word
associations remains understudied. We compared multiple generations of LLMs
(from GPT-3 to GPT- 4o) against human color-word associations using data
collected from over 10,000 Japanese participants, involving 17 colors and words
from eight categories in Japanese. Our findings reveal a clear progression in
LLM performance across generations, with GPT-4o achieving the highest accuracy
in predicting the best voted word for each color and category, particularly
when using visual inputs rather than text-based color codes. However, the
highest median performance was approximately 50% even for GPT4-o with visual
inputs (chance level is 10%), and the performance levels varied significantly
across word categories and colors, indicating a failure to fully replicate
human color-word associations. On the other hand, color discrimination ability
estimated from our color-word association data showed that LLMs demonstrated
high correlation with human color discrimination patterns, similarly to
previous studies. Our study highlights both the advancements in LLM
capabilities and their persistent limitations, suggesting differences in
semantic memory structures between humans and LLMs in representing color-word
associations.

ÊëòË¶ÅÔºöËâ≤ÂΩ©Ë©ûÂΩôËÅØÊÉ≥Âú®‰∫∫È°ûË™çÁü•ÂíåË®≠Ë®àÊáâÁî®‰∏≠ÊâÆÊºîËëóÂü∫Êú¨ÁöÑËßíËâ≤„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âª£Ê≥õÊáâÁî®Ôºå‰∏¶Âú®ÂêÑÁ®ÆÂü∫Ê∫ñ‰∏≠Â±ïÁèæÂá∫ÂÖ∑ÂÇôËá™ÁÑ∂Â∞çË©±ÊäÄËÉΩÁöÑÊô∫ÊÖßË°åÁÇ∫„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëË§áË£Ω‰∫∫È°ûËâ≤ÂΩ©Ë©ûÂΩôËÅØÊÉ≥ÁöÑËÉΩÂäõ‰ªçÊú™Áç≤ÂæóÂÖÖÂàÜÁ†îÁ©∂„ÄÇÊàëÂÄëÊØîËºÉ‰∫ÜÂ§ö‰ª£ LLMÔºàÂæû GPT-3 Âà∞ GPT-4oÔºâËàá‰∫∫È°ûËâ≤ÂΩ©Ë©ûÂΩôËÅØÊÉ≥Ôºå‰ΩøÁî®ÂæûË∂ÖÈÅé 10,000 ÂêçÊó•Êú¨ÂèÉËàáËÄÖÊî∂ÈõÜÁöÑË≥áÊñôÔºåÊ∂âÂèäÊó•Ë™û‰∏≠ÂÖ´ÂÄãÈ°ûÂà•ÁöÑ 17 Á®ÆËâ≤ÂΩ©ÂíåË©ûÂΩô„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÊè≠Á§∫‰∫Ü LLM Âú®ÂêÑ‰∏ñ‰ª£ÈñìÁöÑÊòéÈ°ØÈÄ≤Ê≠•ÔºåGPT-4o Âú®È†êÊ∏¨ÊØèÁ®ÆËâ≤ÂΩ©ÂíåÈ°ûÂà•‰∏≠Á•®ÈÅ∏ÊúÄÂ§öÁöÑË©ûÂΩôÊñπÈù¢ÈÅîÂà∞‰∫ÜÊúÄÈ´òÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÁâπÂà•ÊòØÂú®‰ΩøÁî®Ë¶ñË¶∫Ëº∏ÂÖ•ËÄåÈùûÂü∫ÊñºÊñáÂ≠óÁöÑËâ≤ÂΩ©‰ª£Á¢ºÊôÇ„ÄÇÁÑ∂ËÄåÔºåÂç≥‰ΩøÂ∞çÊñº‰ΩøÁî®Ë¶ñË¶∫Ëº∏ÂÖ•ÁöÑ GPT4-oÔºåÊúÄÈ´òÁöÑÂπ≥ÂùáË°®Áèæ‰πüÂ§ßÁ¥ÑÂè™Êúâ 50%ÔºàÊ©üÁéáÊ∞¥Ê∫ñÁÇ∫ 10%ÔºâÔºåËÄåË°®ÁèæÊ∞¥Ê∫ñÂú®Ë©ûÂΩôÈ°ûÂà•ÂíåËâ≤ÂΩ©‰πãÈñìÊúâÈ°ØËëóÂ∑ÆÁï∞ÔºåÈÄôË°®Á§∫ÁÑ°Ê≥ïÂÆåÂÖ®Ë§áË£Ω‰∫∫È°ûËâ≤ÂΩ©Ë©ûÂΩôËÅØÊÉ≥„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÂæûÊàëÂÄëÁöÑËâ≤ÂΩ©Ë©ûÂΩôËÅØÊÉ≥Ë≥áÊñô‰º∞Ë®àÂá∫ÁöÑËâ≤ÂΩ©Ëæ®Âà•ËÉΩÂäõÈ°ØÁ§∫ÔºåLLM Ëàá‰∫∫È°ûËâ≤ÂΩ©Ëæ®Âà•Ê®°ÂºèÊúâÈ´òÂ∫¶Áõ∏ÈóúÊÄßÔºåÈÄôËàáÂÖàÂâçÁöÑÁ†îÁ©∂È°û‰ºº„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Á™ÅÂá∫‰∫Ü LLM ËÉΩÂäõÁöÑÈÄ≤Ê≠•ÂèäÂÖ∂ÊåÅÁ∫åÁöÑÈôêÂà∂ÔºåÈÄôË°®Êòé‰∫∫È°ûÂíå LLM Âú®Ë°®ÂæµËâ≤ÂΩ©Ë©ûÂΩôËÅØÊÉ≥ÊôÇË™ûÊÑèË®òÊÜ∂ÁµêÊßãÂ≠òÂú®Â∑ÆÁï∞„ÄÇ

##### **Differentially Private Integrated Decision Gradients (IDG-DP) for Radar-based Human Activity Recognition**
2411.02099v1 by Idris Zakariyya, Linda Tran, Kaushik Bhargav Sivangi, Paul Henderson, Fani Deligianni

Human motion analysis offers significant potential for healthcare monitoring
and early detection of diseases. The advent of radar-based sensing systems has
captured the spotlight for they are able to operate without physical contact
and they can integrate with pre-existing Wi-Fi networks. They are also seen as
less privacy-invasive compared to camera-based systems. However, recent
research has shown high accuracy in recognizing subjects or gender from radar
gait patterns, raising privacy concerns. This study addresses these issues by
investigating privacy vulnerabilities in radar-based Human Activity Recognition
(HAR) systems and proposing a novel method for privacy preservation using
Differential Privacy (DP) driven by attributions derived with Integrated
Decision Gradient (IDG) algorithm. We investigate Black-box Membership
Inference Attack (MIA) Models in HAR settings across various levels of
attacker-accessible information. We extensively evaluated the effectiveness of
the proposed IDG-DP method by designing a CNN-based HAR model and rigorously
assessing its resilience against MIAs. Experimental results demonstrate the
potential of IDG-DP in mitigating privacy attacks while maintaining utility
across all settings, particularly excelling against label-only and shadow model
black-box MIA attacks. This work represents a crucial step towards balancing
the need for effective radar-based HAR with robust privacy protection in
healthcare environments.

ÊëòË¶ÅÔºö‰∫∫È°ûÂãï‰ΩúÂàÜÊûêÂú®ÈÜ´ÁôÇ‰øùÂÅ•Áõ£ÊéßÂíåÁñæÁóÖÊó©ÊúüÂÅµÊ∏¨ÊñπÈù¢ÂÖ∑ÊúâÈ°ØËëóÁöÑÊΩõÂäõ„ÄÇÈõ∑ÈÅîÊÑüÊ∏¨Á≥ªÁµ±ÁöÑÂá∫ÁèæÂÇôÂèóÁüöÁõÆÔºåÂõ†ÁÇ∫ÂÆÉÂÄëËÉΩÂ§†Âú®ÁÑ°ÂØ¶È´îÊé•Ëß∏ÁöÑÊÉÖÊ≥Å‰∏ãÈÅã‰ΩúÔºå‰∏¶‰∏îÂèØ‰ª•Êï¥ÂêàÂà∞ÁèæÊúâÁöÑ Wi-Fi Á∂≤Ë∑Ø‰∏≠„ÄÇËàáÂü∫ÊñºÁõ∏Ê©üÁöÑÁ≥ªÁµ±Áõ∏ÊØîÔºåÂÆÉÂÄë‰πüË¢´Ë¶ñÁÇ∫Â∞çÈö±ÁßÅÁöÑ‰æµÁäØËºÉÂ∞è„ÄÇÁÑ∂ËÄåÔºåÊúÄËøëÁöÑÁ†îÁ©∂È°ØÁ§∫ÔºåÂæûÈõ∑ÈÅîÊ≠•ÊÖãÊ®°ÂºèË≠òÂà•‰∏ªÈ´îÊàñÊÄßÂà•ÁöÑÊ∫ñÁ¢∫Â∫¶ÂæàÈ´òÔºåÂºïÁôº‰∫ÜÈö±ÁßÅÂïèÈ°å„ÄÇÊú¨Á†îÁ©∂ÈÄöÈÅéË™øÊü•Âü∫ÊñºÈõ∑ÈÅîÁöÑ‰∫∫È°ûÊ¥ªÂãïË≠òÂà• (HAR) Á≥ªÁµ±‰∏≠ÁöÑÈö±ÁßÅÊºèÊ¥ûÔºå‰∏¶ÊèêÂá∫‰∫Ü‰∏ÄÁ®Æ‰ΩøÁî®Áî±Êï¥ÂêàÊ±∫Á≠ñÊ¢ØÂ∫¶ (IDG) ÊºîÁÆóÊ≥ïË°çÁîüÁöÑÊ≠∏Âõ†È©ÖÂãïÁöÑÂ∑ÆÂàÜÈö±ÁßÅ (DP) ‰æÜ‰øùË≠∑Èö±ÁßÅÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÊàëÂÄëÂú®ÊîªÊìäËÄÖÂèØÂ≠òÂèñË≥áË®äÁöÑÂêÑÁ®ÆÂ±§Á¥ö‰∏≠Ë™øÊü•‰∫Ü HAR Ë®≠ÂÆö‰∏≠ÁöÑÈªëÁõíÊàêÂì°Êé®Ë´ñÊîªÊìä (MIA) Ê®°Âûã„ÄÇÊàëÂÄëÈÄèÈÅéË®≠Ë®àÂü∫Êñº CNN ÁöÑ HAR Ê®°Âûã‰∏¶Âö¥Ê†ºË©ï‰º∞ÂÖ∂Â∞ç MIA ÁöÑÈüåÊÄßÔºåÂª£Ê≥õË©ï‰º∞‰∫ÜÊâÄÊèêÂá∫ÁöÑ IDG-DP ÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòé‰∫Ü IDG-DP Âú®Ê∏õËºïÈö±ÁßÅÊîªÊìäÊñπÈù¢ÁöÑÊΩõÂäõÔºåÂêåÊôÇÂú®ÊâÄÊúâË®≠ÂÆö‰∏≠ÈÉΩ‰øùÊåÅÂØ¶Áî®ÊÄßÔºåÁâπÂà•ÊòØÂú®ÂÉÖÊ®ôÁ±§ÂíåÂΩ±Â≠êÊ®°ÂûãÈªëÁõí MIA ÊîªÊìäÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤„ÄÇÈÄôÈ†ÖÂ∑•‰Ωú‰ª£Ë°®‰∫ÜÂú®ÈÜ´ÁôÇ‰øùÂÅ•Áí∞Â¢É‰∏≠Âπ≥Ë°°Â∞çÊúâÊïàÁöÑÂü∫ÊñºÈõ∑ÈÅîÁöÑ HAR ÁöÑÈúÄÊ±ÇËàáÂº∑Â§ßÁöÑÈö±ÁßÅ‰øùË≠∑‰πãÈñìÂèñÂæóÂπ≥Ë°°ÁöÑÈóúÈçµ‰∏ÄÊ≠•„ÄÇ

##### **Alignment-Based Adversarial Training (ABAT) for Improving the Robustness and Accuracy of EEG-Based BCIs**
2411.02094v1 by Xiaoqing Chen, Ziwei Wang, Dongrui Wu

Machine learning has achieved great success in electroencephalogram (EEG)
based brain-computer interfaces (BCIs). Most existing BCI studies focused on
improving the decoding accuracy, with only a few considering the adversarial
security. Although many adversarial defense approaches have been proposed in
other application domains such as computer vision, previous research showed
that their direct extensions to BCIs degrade the classification accuracy on
benign samples. This phenomenon greatly affects the applicability of
adversarial defense approaches to EEG-based BCIs. To mitigate this problem, we
propose alignment-based adversarial training (ABAT), which performs EEG data
alignment before adversarial training. Data alignment aligns EEG trials from
different domains to reduce their distribution discrepancies, and adversarial
training further robustifies the classification boundary. The integration of
data alignment and adversarial training can make the trained EEG classifiers
simultaneously more accurate and more robust. Experiments on five EEG datasets
from two different BCI paradigms (motor imagery classification, and event
related potential recognition), three convolutional neural network classifiers
(EEGNet, ShallowCNN and DeepCNN) and three different experimental settings
(offline within-subject cross-block/-session classification, online
cross-session classification, and pre-trained classifiers) demonstrated its
effectiveness. It is very intriguing that adversarial attacks, which are
usually used to damage BCI systems, can be used in ABAT to simultaneously
improve the model accuracy and robustness.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏ÁøíÂú®ËÖ¶ÈõªÂúñ (EEG)
Âü∫ÊñºËÖ¶Ê©ü‰ªãÈù¢ (BCI) ÊñπÈù¢ÂèñÂæó‰∫ÜÂ∑®Â§ßÁöÑÊàêÂäü„ÄÇÁèæÊúâÁöÑ BCI Á†îÁ©∂Â§ßÂ§öÈõÜ‰∏≠Êñº
ÊîπÈÄ≤Ëß£Á¢ºÊ∫ñÁ¢∫Â∫¶ÔºåÂè™ÊúâÂ∞ëÊï∏ËÄÉÊÖÆÂ∞çÊäó
ÂÆâÂÖ®ÊÄß„ÄÇÂÑòÁÆ°Âú®ÂÖ∂‰ªñÊáâÁî®È†òÂüüÔºà‰æãÂ¶ÇÈõªËÖ¶Ë¶ñË¶∫Ôºâ‰∏≠Â∑≤Á∂ìÊèêÂá∫‰∫ÜË®±Â§öÂ∞çÊäóÊÄßÈò≤Á¶¶ÊñπÊ≥ïÔºå
ÂÖàÂâçÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÂÆÉÂÄëÁõ¥Êé•Êì¥Â±ïÂà∞ BCI ÊúÉÈôç‰ΩéËâØÊÄßÊ®£Êú¨ÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶„ÄÇÈÄôÁ®ÆÁèæË±°Ê•µÂ§ßÂú∞ÂΩ±Èüø‰∫Ü
Â∞çÊäóÊÄßÈò≤Á¶¶ÊñπÊ≥ïÂú®Âü∫Êñº EEG ÁöÑ BCI ‰∏≠ÁöÑÈÅ©Áî®ÊÄß„ÄÇÁÇ∫‰∫ÜÊ∏õËºïÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄë
ÊèêÂá∫Âü∫ÊñºÂ∞çÈΩäÁöÑÂ∞çÊäóÊÄßË®ìÁ∑¥ (ABAT)ÔºåÂÆÉÂú®Â∞çÊäóÊÄßË®ìÁ∑¥‰πãÂâçÂü∑Ë°å EEG Ë≥áÊñô
Â∞çÈΩä„ÄÇË≥áÊñôÂ∞çÈΩäÊúÉÂ∞á‰æÜËá™‰∏çÂêåÈ†òÂüüÁöÑ EEG Ë©¶È©óÂ∞çÈΩäÔºå‰ª•Ê∏õÂ∞ëÂÆÉÂÄëÁöÑÂàÜÂ∏ÉÂ∑ÆÁï∞ÔºåËÄåÂ∞çÊäóÊÄß
Ë®ìÁ∑¥ÈÄ≤‰∏ÄÊ≠•Â¢ûÂº∑‰∫ÜÂàÜÈ°ûÈÇäÁïå„ÄÇ
Ë≥áÊñôÂ∞çÈΩäÂíåÂ∞çÊäóÊÄßË®ìÁ∑¥ÁöÑÊï¥ÂêàÂèØ‰ª•‰ΩøË®ìÁ∑¥ÂæåÁöÑ EEG ÂàÜÈ°ûÂô®ÂêåÊôÇÊõ¥Ê∫ñÁ¢∫ÂíåÊõ¥Âº∑ÂÅ•„ÄÇÂú®‰∫îÂÄã EEG Ë≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©ó
‰æÜËá™ÂÖ©Á®Æ‰∏çÂêåÁöÑ BCI Ê®°ÂºèÔºàÈÅãÂãïÊÑèË±°ÂàÜÈ°ûÂíå‰∫ã‰ª∂
Áõ∏ÈóúÊΩõËÉΩË≠òÂà•ÔºâÔºå‰∏âÂÄãÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÂàÜÈ°ûÂô®
ÔºàEEGNet„ÄÅShallowCNN Âíå DeepCNNÔºâÂíå‰∏âÁ®Æ‰∏çÂêåÁöÑÂØ¶È©óË®≠ÂÆö
ÔºàÈõ¢Á∑öÂèóË©¶ËÄÖÂÖß‰∫§ÂèâÂçÄÂ°ä/-ÊúÉË©±ÂàÜÈ°û„ÄÅÁ∑ö‰∏ä
‰∫§ÂèâÊúÉË©±ÂàÜÈ°ûÂíåÈ†êË®ìÁ∑¥ÂàÜÈ°ûÂô®ÔºâË≠âÊòé‰∫ÜÂÆÉÁöÑ
ÊúâÊïàÊÄß„ÄÇÈùûÂ∏∏ÊúâË∂£ÁöÑÊòØÔºåÂ∞çÊäóÊÄßÊîªÊìäÈÄöÂ∏∏
Áî®ÊñºÊêçÂ£û BCI Á≥ªÁµ±ÔºåÂèØ‰ª•Âú® ABAT ‰∏≠‰ΩøÁî®‰ª•ÂêåÊôÇ
ÊèêÈ´òÊ®°ÂûãÊ∫ñÁ¢∫ÊÄßÂíåÈ≠ØÊ£íÊÄß„ÄÇ

##### **Real-time and Downtime-tolerant Fault Diagnosis for Railway Turnout Machines (RTMs) Empowered with Cloud-Edge Pipeline Parallelism**
2411.02086v1 by Fan Wu, Muhammad Bilal, Haolong Xiang, Heng Wang, Jinjun Yu, Xiaolong Xu

Railway Turnout Machines (RTMs) are mission-critical components of the
railway transportation infrastructure, responsible for directing trains onto
desired tracks. For safety assurance applications, especially in early-warning
scenarios, RTM faults are expected to be detected as early as possible on a
continuous 7x24 basis. However, limited emphasis has been placed on distributed
model inference frameworks that can meet the inference latency and reliability
requirements of such mission critical fault diagnosis systems. In this paper,
an edge-cloud collaborative early-warning system is proposed to enable
real-time and downtime-tolerant fault diagnosis of RTMs, providing a new
paradigm for the deployment of models in safety-critical scenarios. Firstly, a
modular fault diagnosis model is designed specifically for distributed
deployment, which utilizes a hierarchical architecture consisting of the prior
knowledge module, subordinate classifiers, and a fusion layer for enhanced
accuracy and parallelism. Then, a cloud-edge collaborative framework leveraging
pipeline parallelism, namely CEC-PA, is developed to minimize the overhead
resulting from distributed task execution and context exchange by strategically
partitioning and offloading model components across cloud and edge.
Additionally, an election consensus mechanism is implemented within CEC-PA to
ensure system robustness during coordinator node downtime. Comparative
experiments and ablation studies are conducted to validate the effectiveness of
the proposed distributed fault diagnosis approach. Our ensemble-based fault
diagnosis model achieves a remarkable 97.4% accuracy on a real-world dataset
collected by Nanjing Metro in Jiangsu Province, China. Meanwhile, CEC-PA
demonstrates superior recovery proficiency during node disruptions and speed-up
ranging from 1.98x to 7.93x in total inference time compared to its
counterparts.

ÊëòË¶ÅÔºöÈêµË∑ØËΩâËΩçÊ©ü (RTM) ÊòØÈêµË∑ØÈÅãËº∏Âü∫Á§éË®≠ÊñΩ‰∏≠Ëá≥ÈóúÈáçË¶ÅÁöÑÁµÑÊàêÈÉ®ÂàÜÔºåË≤†Ë≤¨Â∞áÂàóËªäÂ∞éÂêëÊâÄÈúÄÁöÑËªåÈÅì„ÄÇÂ∞çÊñºÂÆâÂÖ®‰øùË≠âÊáâÁî®ÔºåÁâπÂà•ÊòØÂú®È†êË≠¶Â†¥ÊôØ‰∏≠ÔºåÈ†êË®à RTM ÊïÖÈöúÊáâÂú®ÈÄ£Á∫å 7x24 ÁöÑÂü∫Á§é‰∏äÁõ°Êó©Ë¢´Ê™¢Ê∏¨Âá∫‰æÜ„ÄÇÁÑ∂ËÄåÔºåÈáùÂ∞çÂàÜ‰ΩàÂºèÊ®°ÂûãÊé®ÁêÜÊ°ÜÊû∂ÁöÑÈóúÊ≥®ÊúâÈôêÔºåËÄåÈÄô‰∫õÊ°ÜÊû∂ÂèØ‰ª•ÊªøË∂≥Ê≠§È°û‰ªªÂãôÈóúÈçµÊïÖÈöúË®∫Êñ∑Á≥ªÁµ±ÁöÑÊé®ÁêÜÂª∂ÈÅ≤ÂíåÂèØÈù†ÊÄßË¶ÅÊ±Ç„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊèêÂá∫‰∫Ü‰∏ÄÂÄãÈÇäÁ∑£Èõ≤Âçî‰ΩúÈ†êË≠¶Á≥ªÁµ±Ôºå‰ª•ÂØ¶Áèæ RTM ÁöÑÂØ¶ÊôÇÂíåËÄêÂÅúÊ©üÊïÖÈöúË®∫Êñ∑ÔºåÁÇ∫Âú®ÂÆâÂÖ®ÈóúÈçµÂ†¥ÊôØ‰∏≠ÈÉ®ÁΩ≤Ê®°ÂûãÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÁØÑ‰æã„ÄÇÈ¶ñÂÖàÔºåÂ∞àÈñÄË®≠Ë®à‰∫Ü‰∏ÄÂÄãÊ®°ÁµÑÂåñÊïÖÈöúË®∫Êñ∑Ê®°Âûã‰ª•ÈÄ≤Ë°åÂàÜ‰ΩàÂºèÈÉ®ÁΩ≤ÔºåË©≤Ê®°ÂûãÊé°Áî®ÂàÜÂ±§Êû∂ÊßãÔºåÂåÖÊã¨ÂÖàÈ©óÁü•Ë≠òÊ®°ÁµÑ„ÄÅÂæûÂ±¨ÂàÜÈ°ûÂô®Âíå‰∏ÄÂÄãËûçÂêàÂ±§Ôºå‰ª•Â¢ûÂº∑Ê∫ñÁ¢∫ÊÄßÂíå‰∏¶Ë°åÊÄß„ÄÇÁÑ∂ÂæåÔºåÈñãÁôº‰∫Ü‰∏ÄÂÄãÂà©Áî®ÁÆ°ÈÅì‰∏¶Ë°åÊÄßÁöÑÈõ≤ÈÇäÂçî‰ΩúÊ°ÜÊû∂ÔºåÂç≥ CEC-PAÔºåÈÄöÈÅéÂú®Èõ≤ÂíåÈÇäÁ∑£Á≠ñÁï•ÊÄßÂú∞ÂàÜÂâ≤ÂíåÂç∏ËºâÊ®°ÂûãÁµÑ‰ª∂Ôºå‰ª•ÊúÄÂ∞èÂåñÂàÜ‰ΩàÂºè‰ªªÂãôÂü∑Ë°åÂíå‰∏ä‰∏ãÊñá‰∫§ÊèõÁî¢ÁîüÁöÑÈñãÈä∑„ÄÇÊ≠§Â§ñÔºåÂú® CEC-PA ÂÖßÂØ¶ÊñΩ‰∫Ü‰∏ÄÂÄãÈÅ∏ËàâÂÖ±Ë≠òÊ©üÂà∂Ôºå‰ª•Á¢∫‰øùÂçîË™øÂô®ÁØÄÈªûÂÅúÊ©üÊúüÈñìÁöÑÁ≥ªÁµ±ÂÅ•Â£ØÊÄß„ÄÇÈÄ≤Ë°å‰∫ÜÊØîËºÉÂØ¶È©óÂíåÊ∂àËûçÁ†îÁ©∂Ôºå‰ª•È©óË≠âÊâÄÊèêÂá∫ÁöÑÂàÜ‰ΩàÂºèÊïÖÈöúË®∫Êñ∑ÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÁöÑÂü∫ÊñºÈõÜÂêàÁöÑÊïÖÈöúË®∫Êñ∑Ê®°ÂûãÂú®‰∏≠ÂúãÊ±üËòáÁúÅÂçó‰∫¨Âú∞ÈêµÊî∂ÈõÜÁöÑÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÂØ¶Áèæ‰∫Ü 97.4% ÁöÑÈ°ØËëóÊ∫ñÁ¢∫Â∫¶„ÄÇËàáÊ≠§ÂêåÊôÇÔºåCEC-PA Âú®ÁØÄÈªû‰∏≠Êñ∑ÊúüÈñìË°®ÁèæÂá∫ÂÑ™Áï∞ÁöÑÊÅ¢Âæ©ËÉΩÂäõÔºåËàáÂÖ∂Â∞çÊáâÈÉ®ÂàÜÁõ∏ÊØîÔºåÁ∏ΩÊé®ÁêÜÊôÇÈñìÁöÑÂä†ÈÄüÁØÑÂúçÁÇ∫ 1.98 ÂÄçËá≥ 7.93 ÂÄç„ÄÇ

##### **Regress, Don't Guess -- A Regression-like Loss on Number Tokens for Language Models**
2411.02083v1 by Jonas Zausinger, Lars Pennig, Kacper Chlodny, Vincent Limbach, Anna Ketteler, Thorben Prein, Vishwa Mohan Singh, Michael Morris Danziger, Jannis Born

While language models have exceptional capabilities at text generation, they
lack a natural inductive bias for emitting numbers and thus struggle in tasks
involving reasoning over quantities, especially arithmetics. This has
particular relevance in scientific datasets where combinations of text and
numerical data are abundant. One fundamental limitation is the nature of the CE
loss, which assumes a nominal (categorical) scale and thus cannot convey
proximity between generated number tokens. As a remedy, we here present two
versions of a number token loss. The first is based on an $L_p$ loss between
the ground truth token value and the weighted sum of the predicted class
probabilities. The second loss minimizes the Wasserstein-1 distance between the
distribution of the predicted output probabilities and the ground truth
distribution. These regression-like losses can easily be added to any language
model and extend the CE objective during training. We compare the proposed
schemes on a mathematics dataset against existing tokenization, encoding, and
decoding schemes for improving number representation in language models. Our
results reveal a significant improvement in numerical accuracy when equipping a
standard T5 model with the proposed loss schemes.

ÊëòË¶ÅÔºöÈõñÁÑ∂Ë™ûË®ÄÊ®°ÂûãÂú®ÊñáÊú¨ÁîüÊàêÊñπÈù¢ÊúâÈùûÂá°ÁöÑËÉΩÂäõÔºå‰ΩÜÂÆÉÂÄëÁº∫‰πèÁôºÂá∫Êï∏Â≠óÁöÑËá™ÁÑ∂Ê≠∏Á¥çÂÅèË™§ÔºåÂõ†Ê≠§Âú®Ê∂âÂèäÊï∏ÈáèÊé®ÁêÜÁöÑ‰ªªÂãô‰∏≠ÊúÉÈÅáÂà∞Âõ∞Èõ£ÔºåÁâπÂà•ÊòØÁÆóË°ì„ÄÇÈÄôÂú®ÁßëÂ≠∏Êï∏ÊìöÈõÜ‰∏≠Â∞§ÂÖ∂Áõ∏ÈóúÔºåÂõ†ÁÇ∫ÊñáÊú¨ÂíåÊï∏Â≠óÊï∏ÊìöÁöÑÁµÑÂêàÂæàË±êÂØå„ÄÇ‰∏ÄÂÄãÂü∫Êú¨ÈôêÂà∂ÊòØ CE ÊêçÂ§±ÁöÑÊú¨Ë≥™ÔºåÂÆÉÂÅáË®≠‰∏ÄÂÄãÂêçÁæ©ÔºàÂàÜÈ°ûÔºâÂ∞∫Â∫¶ÔºåÂõ†Ê≠§ÁÑ°Ê≥ïÂÇ≥ÈÅîÁîüÊàêÁöÑÊï∏Â≠ó‰ª§Áâå‰πãÈñìÁöÑÊé•ËøëÁ®ãÂ∫¶„ÄÇ‰ΩúÁÇ∫Ë£úÊïëÊé™ÊñΩÔºåÊàëÂÄëÂú®Ê≠§ÊèêÂá∫‰∫ÜÊï∏Â≠ó‰ª§ÁâåÊêçÂ§±ÁöÑÂÖ©ÂÄãÁâàÊú¨„ÄÇÁ¨¨‰∏ÄÂÄãÂü∫Êñº $L_p$ ÊêçÂ§±Ôºå‰ªãÊñºÂü∫Êú¨‰∫ãÂØ¶‰ª§ÁâåÂÄºÂíåÈ†êÊ∏¨È°ûÂà•Ê¶ÇÁéáÁöÑÂä†Ê¨äÂíå‰πãÈñì„ÄÇÁ¨¨‰∫åÂÄãÊêçÂ§±ÊúÄÂ∞èÂåñÈ†êÊ∏¨Ëº∏Âá∫Ê¶ÇÁéáÂàÜ‰ΩàÂíåÂü∫Êú¨‰∫ãÂØ¶ÂàÜ‰Ωà‰πãÈñìÁöÑ Wasserstein-1 Ë∑ùÈõ¢„ÄÇÈÄô‰∫õÈ°û‰ººËø¥Ê≠∏ÁöÑÊêçÂ§±ÂèØ‰ª•ËºïÈ¨ÜÊ∑ªÂä†Âà∞‰ªª‰ΩïË™ûË®ÄÊ®°Âûã‰∏≠Ôºå‰∏¶Âú®Ë®ìÁ∑¥ÊúüÈñìÊì¥Â±ï CE ÁõÆÊ®ô„ÄÇÊàëÂÄëÂú®Êï∏Â≠∏Êï∏ÊìöÈõÜ‰∏äÊØîËºÉÊâÄÊèêÂá∫ÁöÑÊñπÊ°àËàáÁèæÊúâÁöÑÊ®ôË®òÂåñ„ÄÅÁ∑®Á¢ºÂíåËß£Á¢ºÊñπÊ°àÔºå‰ª•ÊîπÂñÑË™ûË®ÄÊ®°Âûã‰∏≠ÁöÑÊï∏Â≠óË°®Á§∫„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÁï∂‰ΩøÁî®Âª∫Ë≠∞ÁöÑÊêçÂ§±ÊñπÊ°àÁÇ∫Ê®ôÊ∫ñ T5 Ê®°ÂûãÈÖçÂÇôÊôÇÔºåÊï∏Â≠óÊ∫ñÁ¢∫Â∫¶È°ØËëóÊèêÈ´ò„ÄÇ

##### **Collaborative Cognitive Diagnosis with Disentangled Representation Learning for Learner Modeling**
2411.02066v1 by Weibo Gao, Qi Liu, Linan Yue, Fangzhou Yao, Hao Wang, Yin Gu, Zheng Zhang

Learners sharing similar implicit cognitive states often display comparable
observable problem-solving performances. Leveraging collaborative connections
among such similar learners proves valuable in comprehending human learning.
Motivated by the success of collaborative modeling in various domains, such as
recommender systems, we aim to investigate how collaborative signals among
learners contribute to the diagnosis of human cognitive states (i.e., knowledge
proficiency) in the context of intelligent education. The primary challenges
lie in identifying implicit collaborative connections and disentangling the
entangled cognitive factors of learners for improved explainability and
controllability in learner Cognitive Diagnosis (CD). However, there has been no
work on CD capable of simultaneously modeling collaborative and disentangled
cognitive states. To address this gap, we present Coral, a Collaborative
cognitive diagnosis model with disentangled representation learning.
Specifically, Coral first introduces a disentangled state encoder to achieve
the initial disentanglement of learners' states. Subsequently, a meticulously
designed collaborative representation learning procedure captures collaborative
signals. It dynamically constructs a collaborative graph of learners by
iteratively searching for optimal neighbors in a context-aware manner. Using
the constructed graph, collaborative information is extracted through node
representation learning. Finally, a decoding process aligns the initial
cognitive states and collaborative states, achieving co-disentanglement with
practice performance reconstructions. Extensive experiments demonstrate the
superior performance of Coral, showcasing significant improvements over
state-of-the-art methods across several real-world datasets. Our code is
available at https://github.com/bigdata-ustc/Coral.

ÊëòË¶ÅÔºö<paragraph>ÂÖ∑ÊúâÁõ∏‰ººÈöêÂê´ËÆ§Áü•Áä∂ÊÄÅÁöÑÂ≠¶‰π†ËÄÖÈÄöÂ∏∏Ë°®Áé∞Âá∫ÂèØÊØîÁöÑ
ÂèØËßÇÂØüÈóÆÈ¢òËß£ÂÜ≥ËÉΩÂäõ„ÄÇÂà©Áî®Ê≠§Á±ªÁõ∏‰ººÂ≠¶‰π†ËÄÖ‰πãÈó¥ÁöÑÂçè‰ΩúËÅîÁ≥ª
Âú®ÁêÜËß£‰∫∫Á±ªÂ≠¶‰π†ÊñπÈù¢Ë¢´ËØÅÊòéÊòØÊúâ‰ª∑ÂÄºÁöÑ„ÄÇÂèóÂçè‰ΩúÂª∫Ê®°Âú®ÂêÑ‰∏™È¢ÜÂüüÁöÑÊàêÂäüÂêØÂèëÔºå‰æãÂ¶Ç
Êé®ËçêÁ≥ªÁªüÔºåÊàë‰ª¨Êó®Âú®Á†îÁ©∂Â≠¶‰π†ËÄÖ‰πãÈó¥ÁöÑÂçè‰Ωú‰ø°Âè∑Â¶Ç‰ΩïÊúâÂä©‰∫éËØäÊñ≠‰∫∫Á±ªËÆ§Áü•Áä∂ÊÄÅÔºàÂç≥Áü•ËØÜ
ÁÜüÁªÉÁ®ãÂ∫¶ÔºâÂú®Êô∫ËÉΩÊïôËÇ≤ÁöÑËÉåÊôØ‰∏ã„ÄÇ‰∏ªË¶ÅÊåëÊàòÂú®‰∫éËØÜÂà´ÈöêÂê´ÁöÑÂçè‰ΩúËÅîÁ≥ªÂπ∂Ëß£ÂºÄ
Â≠¶‰π†ËÄÖÁöÑÁ∫†Áº†ËÆ§Áü•Âõ†Á¥†Ôºå‰ª•ÊèêÈ´òÂ≠¶‰π†ËÄÖËÆ§Áü•ËØäÊñ≠ (CD) ‰∏≠ÁöÑÂèØËß£ÈáäÊÄßÂíåÂèØÊéßÊÄß„ÄÇÁÑ∂ËÄåÔºåÂ∞öÊú™
Êúâ CD ËÉΩÂ§üÂêåÊó∂ÂØπÂçè‰ΩúÂíåËß£ÂºÄÁöÑËÆ§Áü•Áä∂ÊÄÅËøõË°åÂª∫Ê®°„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÂ∑ÆË∑ùÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü CoralÔºå‰∏ÄÁßçÂçè‰Ωú
ËÆ§Áü•ËØäÊñ≠Ê®°ÂûãÔºåÂÖ∑ÊúâËß£ÂºÄÁöÑË°®Á§∫Â≠¶‰π†„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåCoral È¶ñÂÖàÂºïÂÖ•‰∫Ü‰∏Ä‰∏™Ëß£ÂºÄÁöÑÁä∂ÊÄÅÁºñÁ†ÅÂô®Êù•ÂÆûÁé∞
Â≠¶‰π†ËÄÖÁä∂ÊÄÅÁöÑÂàùÂßãËß£ÂºÄ„ÄÇÈöèÂêéÔºåÁ≤æÂøÉËÆæËÆ°ÁöÑÂçè‰ΩúË°®Á§∫Â≠¶‰π†ËøáÁ®ãÊçïËé∑Âçè‰Ωú
‰ø°Âè∑„ÄÇÂÆÉÈÄöËøá‰ª•‰∏ä‰∏ãÊñáÊÑüÁü•ÁöÑÊñπÂºèËø≠‰ª£ÊêúÁ¥¢ÊúÄ‰ºòÈÇªÂ±ÖÊù•Âä®ÊÄÅÊûÑÂª∫Â≠¶‰π†ËÄÖÁöÑÂçè‰ΩúÂõæ„ÄÇ‰ΩøÁî®
ÊûÑÂª∫ÁöÑÂõæÔºåÈÄöËøáËäÇÁÇπË°®Á§∫Â≠¶‰π†ÊèêÂèñÂçè‰Ωú‰ø°ÊÅØ„ÄÇÊúÄÂêéÔºåËß£Á†ÅËøáÁ®ãÂØπÈΩêÂàùÂßã
ËÆ§Áü•Áä∂ÊÄÅÂíåÂçè‰ΩúÁä∂ÊÄÅÔºåÈÄöËøáÂÆûË∑µÊÄßËÉΩÈáçÂª∫ÂÆûÁé∞ÂÖ±Ëß£ÂºÄ„ÄÇÂ§ßÈáèÁöÑÂÆûÈ™åËØÅÊòé‰∫Ü Coral ÁöÑ
ÂçìË∂äÊÄßËÉΩÔºåÂ±ïÁ§∫‰∫ÜÂú®Âá†‰∏™ÁúüÂÆû‰∏ñÁïåÊï∞ÊçÆÈõÜ‰∏äÂØπÊúÄÂÖàËøõÊñπÊ≥ïÁöÑÊòæÁùÄÊîπËøõ„ÄÇÊàë‰ª¨ÁöÑ‰ª£Á†ÅÂèØÂú® https://github.com/bigdata-ustc/Coral Ëé∑Âæó„ÄÇ</paragraph>

##### **Scalable Efficient Training of Large Language Models with Low-dimensional Projected Attention**
2411.02063v1 by Xingtai Lv, Ning Ding, Kaiyan Zhang, Ermo Hua, Ganqu Cui, Bowen Zhou

Improving the effectiveness and efficiency of large language models (LLMs)
simultaneously is a critical yet challenging research goal. In this paper, we
find that low-rank pre-training, normally considered as efficient methods that
will compromise performance, can be scalably effective when reduced parameters
are precisely targeted. Specifically, applying the low-dimensional module only
to the attention layer -- resolves this issue and enhances both effectiveness
and efficiency. We refer to this structure as Low-dimensional Projected
Attention (LPA) and provide an explanatory analysis. Through extensive
experimentation at parameter scales of 130M, 370M, and scaling up to 3B, we
have validated the effectiveness and scalability of LPA. Our results show that
LPA model can save up to 12.4% in time while achieving an approximate 5%
improvement in test perplexity (ppl) and on downstream tasks compared with the
vanilla Transformer.

ÊëòË¶ÅÔºöÂêåÊôÇÊèêÂçáÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊïàËÉΩÂíåÊïàÁéáÔºåÊòØ‰∏ÄÈ†ÖÈáçË¶ÅÂçªËâ±ÈâÖÁöÑÁ†îÁ©∂ÁõÆÊ®ô„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁôºÁèæ‰ΩéÁß©È†êË®ìÁ∑¥ÔºåÈÄöÂ∏∏Ë¢´Ë¶ñÁÇ∫ÊúÉÂΩ±ÈüøÊïàËÉΩÁöÑÊúâÊïàÁéáÊñπÊ≥ïÔºåÁï∂Á≤æÁ¢∫ÈéñÂÆöÂèÉÊï∏ÊôÇÔºåÂèØ‰ª•ÊúâÊïàÂú∞Êì¥ÂÖÖ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÂÉÖÂ∞á‰ΩéÁ∂≠Â∫¶Ê®°ÁµÑÊáâÁî®ÊñºÊ≥®ÊÑèÂäõÂ±§ÔºåÂèØ‰ª•Ëß£Ê±∫Ê≠§ÂïèÈ°åÔºå‰∏¶ÊèêÂçáÊïàËÉΩÂíåÊïàÁéá„ÄÇÊàëÂÄëÂ∞áÊ≠§ÁµêÊßãÁ®±ÁÇ∫‰ΩéÁ∂≠Â∫¶ÊäïÂΩ±Ê≥®ÊÑèÂäõ (LPA)Ôºå‰∏¶Êèê‰æõË™™ÊòéÊÄßÂàÜÊûê„ÄÇÈÄèÈÅéÂú® 130M„ÄÅ370M ÁöÑÂèÉÊï∏Ë¶èÊ®°ÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÔºå‰∏¶Êì¥ÂÖÖÂà∞ 3BÔºåÊàëÂÄëÈ©óË≠â‰∫Ü LPA ÁöÑÊïàËÉΩÂíåÂèØÊì¥ÂÖÖÊÄß„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåËàáÂéüÂßã Transformer Áõ∏ÊØîÔºåLPA Ê®°ÂûãÂèØ‰ª•ÁØÄÁúÅÂ§öÈÅî 12.4% ÁöÑÊôÇÈñìÔºåÂêåÊôÇÂú®Ê∏¨Ë©¶Âõ∞ÊÉëÂ∫¶ (ppl) Âíå‰∏ãÊ∏∏‰ªªÂãô‰∏≠Áç≤ÂæóÁ¥Ñ 5% ÁöÑÊèêÂçá„ÄÇ

##### **TableGPT2: A Large Multimodal Model with Tabular Data Integration**
2411.02059v1 by Aofeng Su, Aowen Wang, Chao Ye, Chen Zhou, Ga Zhang, Guangcheng Zhu, Haobo Wang, Haokai Xu, Hao Chen, Haoze Li, Haoxuan Lan, Jiaming Tian, Jing Yuan, Junbo Zhao, Junlin Zhou, Kaizhe Shou, Liangyu Zha, Lin Long, Liyao Li, Pengzuo Wu, Qi Zhang, Qingyi Huang, Saisai Yang, Tao Zhang, Wentao Ye, Wufang Zhu, Xiaomeng Hu, Xijun Gu, Xinjie Sun, Xiang Li, Yuhang Yang, Zhiqing Xiao

The emergence of models like GPTs, Claude, LLaMA, and Qwen has reshaped AI
applications, presenting vast new opportunities across industries. Yet, the
integration of tabular data remains notably underdeveloped, despite its
foundational role in numerous real-world domains.
  This gap is critical for three main reasons. First, database or data
warehouse data integration is essential for advanced applications; second, the
vast and largely untapped resource of tabular data offers immense potential for
analysis; and third, the business intelligence domain specifically demands
adaptable, precise solutions that many current LLMs may struggle to provide.
  In response, we introduce TableGPT2, a model rigorously pre-trained and
fine-tuned with over 593.8K tables and 2.36M high-quality query-table-output
tuples, a scale of table-related data unprecedented in prior research. This
extensive training enables TableGPT2 to excel in table-centric tasks while
maintaining strong general language and coding abilities.
  One of TableGPT2's key innovations is its novel table encoder, specifically
designed to capture schema-level and cell-level information. This encoder
strengthens the model's ability to handle ambiguous queries, missing column
names, and irregular tables commonly encountered in real-world applications.
Similar to visual language models, this pioneering approach integrates with the
decoder to form a robust large multimodal model.
  We believe the results are compelling: over 23 benchmarking metrics,
TableGPT2 achieves an average performance improvement of 35.20% in the 7B model
and 49.32% in the 72B model over prior benchmark-neutral LLMs, with robust
general-purpose capabilities intact.

ÊëòË¶ÅÔºö<paragraph>GPT„ÄÅClaude„ÄÅLLaMA Âíå Qwen Á≠âÊ®°ÂûãÁöÑÂá∫Áé∞ÈáçÂ°ë‰∫Ü AI
Â∫îÁî®Á®ãÂ∫èÔºå‰∏∫ÂêÑË°åÂêÑ‰∏öÂ∏¶Êù•‰∫ÜÂπøÈòîÁöÑÊñ∞Êú∫ÈÅá„ÄÇÁÑ∂ËÄåÔºå
Â∞ΩÁÆ°Ë°®Ê†ºÊï∞ÊçÆÂú®‰ºóÂ§öÁé∞ÂÆû‰∏ñÁïåÈ¢ÜÂüü‰∏≠ÊâÆÊºîÁùÄÂü∫Á°ÄÊÄßËßíËâ≤Ôºå‰ΩÜ
ÂÖ∂ÈõÜÊàêÂç¥‰ªçÁÑ∂ÊòéÊòæ‰∏çÊàêÁÜü„ÄÇ
ËøôÁßçÂ∑ÆË∑ùËá≥ÂÖ≥ÈáçË¶ÅÔºå‰∏ªË¶ÅÊúâ‰∏â‰∏™ÂéüÂõ†„ÄÇÈ¶ñÂÖàÔºåÊï∞ÊçÆÂ∫ìÊàñÊï∞ÊçÆ
‰ªìÂ∫ìÊï∞ÊçÆÈõÜÊàêÂØπ‰∫éÈ´òÁ∫ßÂ∫îÁî®Á®ãÂ∫èËá≥ÂÖ≥ÈáçË¶ÅÔºõÂÖ∂Ê¨°Ôºå
Â§ßÈáè‰∏îÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂ∞öÊú™ÂºÄÂèëÁöÑË°®Ê†ºÊï∞ÊçÆËµÑÊ∫ê‰∏∫
ÂàÜÊûêÊèê‰æõ‰∫ÜÂ∑®Â§ßÁöÑÊΩúÂäõÔºõÁ¨¨‰∏âÔºåÂïÜ‰∏öÊô∫ËÉΩÈ¢ÜÂüüÂ∞§ÂÖ∂ÈúÄË¶Å
ËÆ∏Â§öÂΩìÂâç LLM ÂèØËÉΩÈöæ‰ª•Êèê‰æõÁöÑÈÄÇÂ∫îÊÄßÂº∫„ÄÅÁ≤æÁ°ÆÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ
‰∏∫Ê≠§ÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü TableGPT2ÔºåËøôÊòØ‰∏Ä‰∏™ÁªèËøá‰∏•Ê†ºÈ¢ÑËÆ≠ÁªÉÂíå
ÂæÆË∞ÉÁöÑÊ®°ÂûãÔºåÊã•ÊúâË∂ÖËøá 593.8K Âº†Ë°®Ê†ºÂíå 2.36M ‰∏™È´òË¥®ÈáèÁöÑÊü•ËØ¢-Ë°®Ê†º-ËæìÂá∫
ÂÖÉÁªÑÔºåËøôÊòØÂÖàÂâçÁ†îÁ©∂‰∏≠ÂâçÊâÄÊú™ÊúâÁöÑË°®Ê†ºÁõ∏ÂÖ≥Êï∞ÊçÆËßÑÊ®°„ÄÇËøôÁßç
ÂπøÊ≥õÁöÑËÆ≠ÁªÉ‰Ωø TableGPT2 ËÉΩÂ§üÂú®‰ª•Ë°®Ê†º‰∏∫‰∏≠ÂøÉÁöÑ
‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÂêåÊó∂‰øùÊåÅÂº∫Â§ßÁöÑÈÄöÁî®ËØ≠Ë®ÄÂíåÁºñÁ†ÅËÉΩÂäõ„ÄÇ
TableGPT2 ÁöÑ‰∏ÄÈ°πÂÖ≥ÈîÆÂàõÊñ∞ÊòØÂÖ∂Êñ∞È¢ñÁöÑË°®Ê†ºÁºñÁ†ÅÂô®Ôºå‰∏ìÈó®
ËÆæËÆ°Áî®‰∫éÊçïËé∑Ê®°ÂºèÁ∫ßÂà´ÂíåÂçïÂÖÉÊ†ºÁ∫ßÂà´‰ø°ÊÅØ„ÄÇÊ≠§ÁºñÁ†ÅÂô®
Â¢ûÂº∫‰∫ÜÊ®°ÂûãÂ§ÑÁêÜÊ®°Ê£±‰∏§ÂèØÁöÑÊü•ËØ¢„ÄÅÁº∫Â∞ëÂàóÂêçÂíå
Áé∞ÂÆû‰∏ñÁïåÂ∫îÁî®Á®ãÂ∫è‰∏≠Â∏∏ËßÅÁöÑÈùûËßÑÂàôË°®Ê†ºÁöÑËÉΩÂäõ„ÄÇ
Á±ª‰ºº‰∫éËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºåËøôÁßçÂºÄÂàõÊÄßÊñπÊ≥ï‰∏é
Ëß£Á†ÅÂô®ÈõÜÊàêÔºåÂΩ¢Êàê‰∏Ä‰∏™Âº∫Â§ßÁöÑÂ§ßÂûãÂ§öÊ®°ÊÄÅÊ®°Âûã„ÄÇ
Êàë‰ª¨Áõ∏‰ø°ÁªìÊûú‰ª§‰∫∫‰ø°ÊúçÔºöÂú® 23 ‰∏™Âü∫ÂáÜÊµãËØïÊåáÊ†á‰∏äÔºå
TableGPT2 Âú® 7B Ê®°Âûã‰∏≠ÂÆûÁé∞‰∫Ü 35.20% ÁöÑÂπ≥ÂùáÊÄßËÉΩÊèêÂçáÔºåÂú® 72B Ê®°Âûã‰∏≠ÂÆûÁé∞‰∫Ü 49.32% ÁöÑÊèêÂçáÔºåÂπ∂‰∏î‰øùÊåÅ‰∫ÜÂº∫Â§ßÁöÑ
ÈÄöÁî®ÂäüËÉΩ„ÄÇ</paragraph>

##### **Enhancing ID-based Recommendation with Large Language Models**
2411.02041v1 by Lei Chen, Chen Gao, Xiaoyi Du, Hengliang Luo, Depeng Jin, Yong Li, Meng Wang

Large Language Models (LLMs) have recently garnered significant attention in
various domains, including recommendation systems. Recent research leverages
the capabilities of LLMs to improve the performance and user modeling aspects
of recommender systems. These studies primarily focus on utilizing LLMs to
interpret textual data in recommendation tasks. However, it's worth noting that
in ID-based recommendations, textual data is absent, and only ID data is
available. The untapped potential of LLMs for ID data within the ID-based
recommendation paradigm remains relatively unexplored. To this end, we
introduce a pioneering approach called "LLM for ID-based Recommendation"
(LLM4IDRec). This innovative approach integrates the capabilities of LLMs while
exclusively relying on ID data, thus diverging from the previous reliance on
textual data. The basic idea of LLM4IDRec is that by employing LLM to augment
ID data, if augmented ID data can improve recommendation performance, it
demonstrates the ability of LLM to interpret ID data effectively, exploring an
innovative way for the integration of LLM in ID-based recommendation. We
evaluate the effectiveness of our LLM4IDRec approach using three widely-used
datasets. Our results demonstrate a notable improvement in recommendation
performance, with our approach consistently outperforming existing methods in
ID-based recommendation by solely augmenting input data.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊúÄËøëÂú®ÂêÑÁ®ÆÈ†òÂüü‰∏≠Áç≤Âæó‰∫ÜÈ°ØËëóÁöÑÈóúÊ≥®ÔºåÂåÖÊã¨Êé®Ëñ¶Á≥ªÁµ±„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Âà©Áî® LLM ÁöÑÂäüËÉΩ‰æÜÊîπÂñÑÊé®Ëñ¶Á≥ªÁµ±ÁöÑÊïàËÉΩÂíå‰ΩøÁî®ËÄÖÂª∫Ê®°Èù¢Âêë„ÄÇÈÄô‰∫õÁ†îÁ©∂‰∏ªË¶ÅÂ∞àÊ≥®ÊñºÂà©Áî® LLM ‰æÜË©ÆÈáãÊé®Ëñ¶‰ªªÂãô‰∏≠ÁöÑÊñáÂ≠óË≥áÊñô„ÄÇÁÑ∂ËÄåÔºåÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂú®Âü∫Êñº ID ÁöÑÊé®Ëñ¶‰∏≠ÔºåÊñáÂ≠óË≥áÊñôÊòØ‰∏çÂ≠òÂú®ÁöÑÔºåËÄå‰∏îÂè™Êúâ ID Ë≥áÊñôÂèØÁî®„ÄÇLLM Âú®Âü∫Êñº ID ÁöÑÊé®Ëñ¶ÁØÑ‰æã‰∏≠Â∞ç ID Ë≥áÊñôÁöÑÊú™ÈñãÁôºÊΩõÂäõ‰ªçÁÑ∂Áõ∏Â∞çÊú™Ë¢´Êé¢Ë®é„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÁ®ÆÁ®±ÁÇ∫„ÄåÁî®ÊñºÂü∫Êñº ID ÁöÑÊé®Ëñ¶ÁöÑ LLM„Äç(LLM4IDRec) ÁöÑÂÖàÈ©ÖÊñπÊ≥ï„ÄÇÈÄôÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ïÊï¥Âêà‰∫Ü LLM ÁöÑÂäüËÉΩÔºåÂêåÊôÇÂÉÖ‰æùË≥¥Êñº ID Ë≥áÊñôÔºåÂõ†Ê≠§ËàáÂÖàÂâç‰æùË≥¥ÊñáÂ≠óË≥áÊñôÁöÑÊñπÊ≥ï‰∏çÂêå„ÄÇLLM4IDRec ÁöÑÂü∫Êú¨Ê¶ÇÂøµÊòØÔºåÈÄèÈÅé‰ΩøÁî® LLM ‰æÜÊì¥ÂÖÖ ID Ë≥áÊñôÔºåÂ¶ÇÊûúÊì¥ÂÖÖÂæåÁöÑ ID Ë≥áÊñôÂèØ‰ª•ÊîπÂñÑÊé®Ëñ¶ÊïàËÉΩÔºåÈÄôÂ∞±Ë≠âÊòé‰∫Ü LLM ÊúâÊïàË©ÆÈáã ID Ë≥áÊñôÁöÑËÉΩÂäõÔºåÊé¢Á¥¢‰∫ÜÂ∞á LLM Êï¥ÂêàÂà∞Âü∫Êñº ID ÁöÑÊé®Ëñ¶‰∏≠ÁöÑ‰∏ÄÁ®ÆÂâµÊñ∞ÊñπÂºè„ÄÇÊàëÂÄë‰ΩøÁî®‰∏âÂÄãÂª£Ê≥õ‰ΩøÁî®ÁöÑË≥áÊñôÈõÜË©ï‰º∞‰∫ÜÊàëÂÄëÁöÑ LLM4IDRec ÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÁöÑÁµêÊûúË≠âÊòé‰∫ÜÊé®Ëñ¶ÊïàËÉΩÁöÑÈ°ØËëóÊèêÂçáÔºåÊàëÂÄëÁöÑÈÄôÁ®ÆÊñπÊ≥ïÈÄèÈÅéÂÉÖÊì¥ÂÖÖËº∏ÂÖ•Ë≥áÊñôÔºåÂßãÁµÇÂÑ™ÊñºÁèæÊúâÁöÑÂü∫Êñº ID ÁöÑÊé®Ëñ¶ÊñπÊ≥ï„ÄÇ

##### **Explainable cognitive decline detection in free dialogues with a Machine Learning approach based on pre-trained Large Language Models**
2411.02036v1 by Francisco de Arriba-P√©rez, Silvia Garc√≠a-M√©ndez, Javier Otero-Mosquera, Francisco J. Gonz√°lez-Casta√±o

Cognitive and neurological impairments are very common, but only a small
proportion of affected individuals are diagnosed and treated, partly because of
the high costs associated with frequent screening. Detecting pre-illness stages
and analyzing the progression of neurological disorders through effective and
efficient intelligent systems can be beneficial for timely diagnosis and early
intervention. We propose using Large Language Models to extract features from
free dialogues to detect cognitive decline. These features comprise high-level
reasoning content-independent features (such as comprehension, decreased
awareness, increased distraction, and memory problems). Our solution comprises
(i) preprocessing, (ii) feature engineering via Natural Language Processing
techniques and prompt engineering, (iii) feature analysis and selection to
optimize performance, and (iv) classification, supported by automatic
explainability. We also explore how to improve Chatgpt's direct cognitive
impairment prediction capabilities using the best features in our models.
Evaluation metrics obtained endorse the effectiveness of a mixed approach
combining feature extraction with Chatgpt and a specialized Machine Learning
model to detect cognitive decline within free-form conversational dialogues
with older adults. Ultimately, our work may facilitate the development of an
inexpensive, non-invasive, and rapid means of detecting and explaining
cognitive decline.

ÊëòË¶ÅÔºöË™çÁü•ÂíåÁ•ûÁ∂ìÈöúÁ§ôÈùûÂ∏∏Â∏∏Ë¶ãÔºå‰ΩÜÂè™ÊúâÂ∞ëÊï∏ÂèóÂΩ±ÈüøÁöÑÂÄã‰∫∫Ë¢´Ë®∫Êñ∑ÂíåÊ≤ªÁôÇÔºåÈÉ®ÂàÜÂéüÂõ†ÊòØÂõ†ÁÇ∫È†ªÁπÅÁØ©Ê™¢Áõ∏ÈóúÁöÑÈ´òÊàêÊú¨„ÄÇÈÄèÈÅéÊúâÊïà‰∏îÈ´òÊïàÁöÑÊô∫ÊÖßÁ≥ªÁµ±ÂÅµÊ∏¨ÁñæÁóÖÂâçÊúüÈöéÊÆµ‰∏¶ÂàÜÊûêÁ•ûÁ∂ìÁñæÁóÖÁöÑÈÄ≤Á®ãÔºåÊúâÂä©ÊñºÂèäÊôÇË®∫Êñ∑ÂíåÊó©Êúü‰ªãÂÖ•„ÄÇÊàëÂÄëÂª∫Ë≠∞‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÂæûËá™Áî±Â∞çË©±‰∏≠ËêÉÂèñÁâπÂæµÔºå‰ª•ÂÅµÊ∏¨Ë™çÁü•ËÉΩÂäõ‰∏ãÈôç„ÄÇÈÄô‰∫õÁâπÂæµÂåÖÂê´È´òÈöéÊé®ÁêÜÂÖßÂÆπÁÑ°ÈóúÁöÑÁâπÂæµÔºà‰æãÂ¶ÇÁêÜËß£Âäõ„ÄÅÊÑèË≠ò‰∏ãÈôç„ÄÅÂàÜÂøÉÂ¢ûÂä†ÂíåË®òÊÜ∂ÂäõÂïèÈ°åÔºâ„ÄÇÊàëÂÄëÁöÑËß£Ê±∫ÊñπÊ°àÂåÖÂê´ (i) ÂâçËôïÁêÜ„ÄÅ(ii) ÈÄèÈÅéËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÊäÄË°ìÂíåÊèêÁ§∫Â∑•Á®ãÈÄ≤Ë°åÁâπÂæµÂ∑•Á®ã„ÄÅ(iii) ÁâπÂæµÂàÜÊûêÂíåÈÅ∏Êìá‰ª•ÊúÄ‰Ω≥ÂåñÊïàËÉΩÔºå‰ª•Âèä (iv) ÂàÜÈ°ûÔºåÁî±Ëá™ÂãïËß£ÈáãËÉΩÂäõÊîØÊè¥„ÄÇÊàëÂÄë‰πüÊé¢Á¥¢Â¶Ç‰Ωï‰ΩøÁî®ÊàëÂÄëÊ®°Âûã‰∏≠ÁöÑÊúÄ‰Ω≥ÁâπÂæµ‰æÜÊîπÂñÑ Chatgpt ÁöÑÁõ¥Êé•Ë™çÁü•ÈöúÁ§ôÈ†êÊ∏¨ËÉΩÂäõ„ÄÇÂèñÂæóÁöÑË©ï‰º∞ÊåáÊ®ôË™çÂèØ‰∫ÜÁµêÂêàÁâπÂæµËêÉÂèñ„ÄÅChatgpt ÂíåÁâπÊÆäÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÊ∑∑ÂêàÊñπÊ≥ïÂú®ÂÅµÊ∏¨ËÄÅÂπ¥‰∫∫Ëá™Áî±ÂΩ¢ÂºèÂ∞çË©±‰∏≠ÁöÑË™çÁü•ËÉΩÂäõ‰∏ãÈôçÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÊúÄÁµÇÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÂèØËÉΩ‰øÉÈÄ≤ÈñãÁôº‰∏ÄÁ®ÆÁ∂ìÊøüÂØ¶ÊÉ†„ÄÅÈùû‰æµÂÖ•ÊÄßÂíåÂø´ÈÄüÁöÑÊñπÊ≥ïÔºå‰ª•ÂÅµÊ∏¨ÂíåËß£ÈáãË™çÁü•ËÉΩÂäõ‰∏ãÈôç„ÄÇ

##### **CTEFM-VC: Zero-Shot Voice Conversion Based on Content-Aware Timbre Ensemble Modeling and Flow Matching**
2411.02026v1 by Yu Pan, Yuguang Yang, Jixun Yao, Jianhao Ye, Hongbin Zhou, Lei Ma, Jianjun Zhao

Zero-shot voice conversion (VC) aims to transform the timbre of a source
speaker into any previously unseen target speaker, while preserving the
original linguistic content. Despite notable progress, attaining a degree of
speaker similarity and naturalness on par with ground truth recordings
continues to pose great challenge. In this paper, we propose CTEFM-VC, a
zero-shot VC framework that leverages Content-aware Timbre Ensemble modeling
and Flow Matching. Specifically, CTEFM-VC disentangles utterances into
linguistic content and timbre representations, subsequently utilizing a
conditional flow matching model and a vocoder to reconstruct the
mel-spectrogram and waveform. To enhance its timbre modeling capability and the
naturalness of generated speech, we propose a context-aware timbre ensemble
modeling approach that adaptively integrates diverse speaker verification
embeddings and enables the joint utilization of linguistic and timbre features
through a cross-attention module. Experiments show that our CTEFM-VC system
surpasses state-of-the-art VC methods in both speaker similarity and
naturalness by at least 18.5% and 7.0%.

ÊëòË¶ÅÔºöÈõ∂Ê®£Êú¨Ë™ûÈü≥ËΩâÊèõ (VC) Êó®Âú®Â∞á‰æÜÊ∫êË™™Ë©±ËÄÖÁöÑÈü≥Ëâ≤ËΩâÊèõÁÇ∫‰ªª‰ΩïÂÖàÂâçÊú™Ë¶ãÁöÑÁõÆÊ®ôË™™Ë©±ËÄÖÔºåÂêåÊôÇ‰øùÁïôÂéüÂßãË™ûË®ÄÂÖßÂÆπ„ÄÇÂÑòÁÆ°ÂèñÂæóÈ°ØËëóÈÄ≤Â±ïÔºå‰ΩÜË¶ÅÈÅîÂà∞ËàáÂú∞Èù¢ÂØ¶Ê≥ÅÈåÑÈü≥Áõ∏Áï∂ÁöÑË™™Ë©±ËÄÖÁõ∏‰ººÂ∫¶ÂíåËá™ÁÑ∂Â∫¶Ôºå‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÂ∑®Â§ßÁöÑÊåëÊà∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ CTEFM-VCÔºå‰∏ÄÂÄãÈõ∂Ê®£Êú¨ VC Ê°ÜÊû∂ÔºåÂÆÉÂà©Áî®ÂÖßÂÆπÊÑüÁü•Èü≥Ëâ≤ÂêàÂ•èÂª∫Ê®°ÂíåÊµÅÂåπÈÖç„ÄÇÂÖ∑È´î‰æÜË™™ÔºåCTEFN-VC Â∞áË™ûÂè•Ëß£ÈñãÁÇ∫Ë™ûË®ÄÂÖßÂÆπÂíåÈü≥Ëâ≤Ë°®Á§∫ÔºåÈö®ÂæåÂà©Áî®Ê¢ù‰ª∂ÊµÅÂåπÈÖçÊ®°ÂûãÂíåÁ∑®Á¢ºÂô®‰æÜÈáçÂª∫Ê¢ÖÁàæË≠úÂúñÂíåÊ≥¢ÂΩ¢„ÄÇÁÇ∫‰∫ÜÂ¢ûÂº∑ÂÖ∂Èü≥Ëâ≤Âª∫Ê®°ËÉΩÂäõÂíåÁîüÊàêË™ûÈü≥ÁöÑËá™ÁÑ∂Â∫¶ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®Æ‰∏ä‰∏ãÊñáÊÑüÁü•Èü≥Ëâ≤ÂêàÂ•èÂª∫Ê®°ÊñπÊ≥ïÔºåÂÆÉËá™ÈÅ©ÊáâÂú∞Êï¥Âêà‰∫Ü‰∏çÂêåÁöÑË™™Ë©±ËÄÖÈ©óË≠âÂµåÂÖ•Ôºå‰∏¶ÈÄöÈÅéË∑®Ê≥®ÊÑèÂäõÊ®°ÁµÑÂØ¶ÁèæË™ûË®ÄÂíåÈü≥Ëâ≤ÁâπÂæµÁöÑËÅØÂêàÂà©Áî®„ÄÇÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑ CTEFM-VC Á≥ªÁµ±Âú®Ë™™Ë©±ËÄÖÁõ∏‰ººÂ∫¶ÂíåËá™ÁÑ∂Â∫¶ÊñπÈù¢ÈÉΩË∂ÖË∂ä‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑ VC ÊñπÊ≥ïÔºåËá≥Â∞ëÂàÜÂà•ÊèêÈ´ò‰∫Ü 18.5% Âíå 7.0%„ÄÇ

##### **Shortcut Learning in In-Context Learning: A Survey**
2411.02018v1 by Rui Song, Yingji Li, Fausto Giunchiglia, Hao Xu

Shortcut learning refers to the phenomenon where models employ simple,
non-robust decision rules in practical tasks, which hinders their
generalization and robustness. With the rapid development of large language
models (LLMs) in recent years, an increasing number of studies have shown the
impact of shortcut learning on LLMs. This paper provides a novel perspective to
review relevant research on shortcut learning in In-Context Learning (ICL). It
conducts a detailed exploration of the types of shortcuts in ICL tasks, their
causes, available benchmarks, and strategies for mitigating shortcuts. Based on
corresponding observations, it summarizes the unresolved issues in existing
research and attempts to outline the future research landscape of shortcut
learning.

ÊëòË¶ÅÔºöÊç∑ÂæëÂ≠∏ÁøíÊòØÊåáÊ®°ÂûãÂú®ÂØ¶Èöõ‰ªªÂãô‰∏≠Êé°Áî®Á∞°ÂñÆ„ÄÅ‰∏çÁ©©ÂÅ•ÁöÑÊ±∫Á≠ñË¶èÂâáÁöÑÁèæË±°ÔºåÈÄôÈòªÁ§ô‰∫ÜÂÆÉÂÄëÁöÑÊ≥õÂåñÂíåÁ©©ÂÅ•ÊÄß„ÄÇÈö®ËëóËøëÂπ¥‰æÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂø´ÈÄüÁôºÂ±ïÔºåË∂ä‰æÜË∂äÂ§öÁöÑÁ†îÁ©∂Ë°®ÊòéÊç∑ÂæëÂ≠∏ÁøíÂ∞ç LLM ÁöÑÂΩ±Èüø„ÄÇÊú¨ÊñáÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑËßÄÈªû‰æÜÂõûÈ°ßÊÉÖÂ¢ÉÂ≠∏Áøí (ICL) ‰∏≠ÈóúÊñºÊç∑ÂæëÂ≠∏ÁøíÁöÑÁõ∏ÂÖ≥Á†îÁ©∂„ÄÇÂÆÉÂ∞ç ICL ‰ªªÂãô‰∏≠ÁöÑÊç∑ÂæëÈ°ûÂûã„ÄÅÂÆÉÂÄëÁöÑÂéüÂõ†„ÄÅÂèØÁî®ÁöÑÂü∫Ê∫ñÂíåÊ∏õËºïÊç∑ÂæëÁöÑÁ≠ñÁï•ÈÄ≤Ë°å‰∫ÜË©≥Á¥∞Êé¢Ë®é„ÄÇÊ†πÊìöÁõ∏ÊáâÁöÑËßÄÂØüÔºåÂÆÉÁ∏ΩÁµê‰∫ÜÁèæÊúâÁ†îÁ©∂‰∏≠Êú™Ëß£Ê±∫ÁöÑÂïèÈ°åÔºå‰∏¶Ë©¶ÂúñÊ¶ÇËø∞Êç∑ÂæëÂ≠∏ÁøíÁöÑÊú™‰æÜÁ†îÁ©∂ÂâçÊôØ„ÄÇ

##### **Foundations and Recent Trends in Multimodal Mobile Agents: A Survey**
2411.02006v1 by Biao Wu, Yanda Li, Meng Fang, Zirui Song, Zhiwei Zhang, Yunchao Wei, Ling Chen

Mobile agents are essential for automating tasks in complex and dynamic
mobile environments. As foundation models evolve, the demands for agents that
can adapt in real-time and process multimodal data have grown. This survey
provides a comprehensive review of mobile agent technologies, focusing on
recent advancements that enhance real-time adaptability and multimodal
interaction. Recent evaluation benchmarks have been developed better to capture
the static and interactive environments of mobile tasks, offering more accurate
assessments of agents' performance. We then categorize these advancements into
two main approaches: prompt-based methods, which utilize large language models
(LLMs) for instruction-based task execution, and training-based methods, which
fine-tune multimodal models for mobile-specific applications. Additionally, we
explore complementary technologies that augment agent performance. By
discussing key challenges and outlining future research directions, this survey
offers valuable insights for advancing mobile agent technologies. A
comprehensive resource list is available at
https://github.com/aialt/awesome-mobile-agents

ÊëòË¶ÅÔºöË°åÂãï‰ª£ÁêÜÂ∞çÊñºÂú®Ë§áÈõú‰∏îÂãïÊÖãÁöÑË°åÂãïÁí∞Â¢É‰∏≠Ëá™ÂãïÂåñ‰ªªÂãôËá≥ÈóúÈáçË¶Å„ÄÇÈö®ËëóÂü∫Á§éÊ®°ÂûãÁöÑÊºîÈÄ≤ÔºåÂ∞çÊñºËÉΩÂ§†Âç≥ÊôÇÈÅ©Êáâ‰∏¶ËôïÁêÜÂ§öÊ®°ÊÖãË≥áÊñôÁöÑ‰ª£ÁêÜÁöÑÈúÄÊ±Ç‰πüÈö®‰πãÂ¢ûÂä†„ÄÇÊú¨Ë™øÊü•Êèê‰æõË°åÂãï‰ª£ÁêÜÊäÄË°ìÁöÑÂÖ®Èù¢ÂõûÈ°ßÔºåÈáçÈªûÂú®ÊñºÂ¢ûÂº∑Âç≥ÊôÇÈÅ©ÊáâÊÄßÂíåÂ§öÊ®°ÊÖã‰∫íÂãïÁöÑÊúÄÊñ∞ÈÄ≤Â±ï„ÄÇÊúÄËøëÁöÑË©ï‰º∞Âü∫Ê∫ñÂ∑≤ÈñãÁôºÂæóÊõ¥Â•ΩÔºå‰ª•ÊçïÊçâË°åÂãï‰ªªÂãôÁöÑÈùúÊÖãÂíå‰∫íÂãïÁí∞Â¢ÉÔºåÊèê‰æõÊõ¥Ê∫ñÁ¢∫ÁöÑ‰ª£ÁêÜÊïàËÉΩË©ï‰º∞„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂ∞áÈÄô‰∫õÈÄ≤Â±ïÂàÜÈ°ûÁÇ∫ÂÖ©Á®Æ‰∏ªË¶ÅÊñπÊ≥ïÔºöÂü∫ÊñºÊèêÁ§∫ÁöÑÊñπÊ≥ïÔºåÂÆÉÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄ≤Ë°åÂü∫ÊñºÊåá‰ª§ÁöÑ‰ªªÂãôÂü∑Ë°åÔºå‰ª•ÂèäÂü∫ÊñºË®ìÁ∑¥ÁöÑÊñπÊ≥ïÔºåÂÆÉÂæÆË™øÂ§öÊ®°ÊÖãÊ®°Âûã‰ª•ÈÄ≤Ë°åÁâπÂÆöÊñºË°åÂãïÁöÑÊáâÁî®„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂ¢ûÂº∑‰ª£ÁêÜÊïàËÉΩÁöÑË£úÂÖÖÊäÄË°ì„ÄÇÈÄèÈÅéË®éË´ñÈóúÈçµÊåëÊà∞‰∏¶Ê¶ÇËø∞Êú™‰æÜÁöÑÁ†îÁ©∂ÊñπÂêëÔºåÊú¨Ë™øÊü•ÁÇ∫Êé®ÈÄ≤Ë°åÂãï‰ª£ÁêÜÊäÄË°ìÊèê‰æõ‰∫ÜÂØ∂Ë≤¥ÁöÑË¶ãËß£„ÄÇÂèØ‰ª•Âú® https://github.com/aialt/awesome-mobile-agents ÊâæÂà∞ÂÖ®Èù¢ÁöÑË≥áÊ∫êÊ∏ÖÂñÆ

##### **Against Multifaceted Graph Heterogeneity via Asymmetric Federated Prompt Learning**
2411.02003v1 by Zhuoning Guo, Ruiqian Han, Hao Liu

Federated Graph Learning (FGL) aims to collaboratively and privately optimize
graph models on divergent data for different tasks. A critical challenge in FGL
is to enable effective yet efficient federated optimization against
multifaceted graph heterogeneity to enhance mutual performance. However,
existing FGL works primarily address graph data heterogeneity and perform
incapable of graph task heterogeneity. To address the challenge, we propose a
Federated Graph Prompt Learning (FedGPL) framework to efficiently enable
prompt-based asymmetric graph knowledge transfer between multifaceted
heterogeneous federated participants. Generally, we establish a split federated
framework to preserve universal and domain-specific graph knowledge,
respectively. Moreover, we develop two algorithms to eliminate task and data
heterogeneity for advanced federated knowledge preservation. First, a
Hierarchical Directed Transfer Aggregator (HiDTA) delivers cross-task
beneficial knowledge that is hierarchically distilled according to the
directional transferability. Second, a Virtual Prompt Graph (VPG) adaptively
generates graph structures to enhance data utility by distinguishing dominant
subgraphs and neutralizing redundant ones. We conduct theoretical analyses and
extensive experiments to demonstrate the significant accuracy and efficiency
effectiveness of FedGPL against multifaceted graph heterogeneity compared to
state-of-the-art baselines on large-scale federated graph datasets.

ÊëòË¶ÅÔºöËÅîÈÇ¶ÂõæÂ≠¶‰π† (FGL) Êó®Âú®ÈíàÂØπ‰∏çÂêåÁöÑ‰ªªÂä°Âú®ÂèëÊï£ÁöÑÊï∞ÊçÆ‰∏äÂçè‰Ωú‰∏îÁßÅ‰∏ã‰ºòÂåñÂõæÊ®°Âûã„ÄÇFGL ‰∏≠ÁöÑ‰∏Ä‰∏™ÂÖ≥ÈîÆÊåëÊàòÊòØÈíàÂØπÂ§öÊñπÈù¢ÁöÑÂõæÂºÇË¥®ÊÄßÂêØÁî®ÊúâÊïà‰∏îÈ´òÊïàÁöÑËÅîÈÇ¶‰ºòÂåñÔºå‰ª•Â¢ûÂº∫Áõ∏‰∫íÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑ FGL Â∑•‰Ωú‰∏ªË¶ÅËß£ÂÜ≥ÂõæÊï∞ÊçÆÂºÇË¥®ÊÄßÔºåÂπ∂‰∏îÊó†Ê≥ïÊâßË°åÂõæ‰ªªÂä°ÂºÇË¥®ÊÄß„ÄÇ‰∏∫‰∫ÜÂ∫îÂØπËøô‰∏ÄÊåëÊàòÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™ËÅîÈÇ¶ÂõæÊèêÁ§∫Â≠¶‰π† (FedGPL) Ê°ÜÊû∂Ôºå‰ª•ÊúâÊïàÂú∞ÂÆûÁé∞Âü∫‰∫éÊèêÁ§∫ÁöÑÂ§öÊñπÈù¢ÂºÇÊûÑËÅîÈÇ¶ÂèÇ‰∏éËÄÖ‰πãÈó¥ÁöÑÈùûÂØπÁß∞ÂõæÁü•ËØÜËΩ¨Áßª„ÄÇ‰∏ÄËà¨Êù•ËØ¥ÔºåÊàë‰ª¨Âª∫Á´ã‰∫Ü‰∏Ä‰∏™ÂàÜÂâ≤ËÅîÈÇ¶Ê°ÜÊû∂ÔºåÂàÜÂà´‰øùÁïôÈÄöÁî®ÂíåÁâπÂÆö‰∫éÂüüÁöÑÂõæÁü•ËØÜ„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÂºÄÂèë‰∫Ü‰∏§ÁßçÁÆóÊ≥ïÊù•Ê∂àÈô§‰ªªÂä°ÂíåÊï∞ÊçÆÂºÇË¥®ÊÄßÔºå‰ª•ÂÆûÁé∞È´òÁ∫ßËÅîÈÇ¶Áü•ËØÜ‰øùÁïô„ÄÇÈ¶ñÂÖàÔºå‰∏Ä‰∏™ÂàÜÂ±ÇÂÆöÂêë‰º†ËæìËÅöÂêàÂô® (HiDTA) Êèê‰æõÊ†πÊçÆÂÆöÂêëÂèØËΩ¨ÁßªÊÄßÂàÜÂ±ÇÊèêÂèñÁöÑË∑®‰ªªÂä°ÊúâÁõäÁü•ËØÜ„ÄÇÂÖ∂Ê¨°Ôºå‰∏Ä‰∏™ËôöÊãüÊèêÁ§∫Âõæ (VPG) Ëá™ÈÄÇÂ∫îÂú∞ÁîüÊàêÂõæÁªìÊûÑÔºåÈÄöËøáÂå∫ÂàÜ‰∏ªÂØºÂ≠êÂõæÂπ∂‰∏≠ÂíåÂÜó‰ΩôÂ≠êÂõæÊù•Â¢ûÂº∫Êï∞ÊçÆÊïàÁî®„ÄÇÊàë‰ª¨ËøõË°å‰∫ÜÁêÜËÆ∫ÂàÜÊûêÂíåÂπøÊ≥õÁöÑÂÆûÈ™åÔºå‰ª•ËØÅÊòé FedGPL Âú®Â§öÊñπÈù¢ÂõæÂºÇË¥®ÊÄßÊñπÈù¢ÁöÑÊòæÁùÄÂáÜÁ°ÆÊÄßÂíåÊúâÊïàÊÄßÔºå‰∏éÂ§ßËßÑÊ®°ËÅîÈÇ¶ÂõæÊï∞ÊçÆÈõÜ‰∏äÁöÑÊúÄÂÖàËøõÂü∫Á∫øÁõ∏ÊØî„ÄÇ

##### **Culinary Class Wars: Evaluating LLMs using ASH in Cuisine Transfer Task**
2411.01996v1 by Hoonick Lee, Mogan Gim, Donghyeon Park, Donghee Choi, Jaewoo Kang

The advent of Large Language Models (LLMs) have shown promise in various
creative domains, including culinary arts. However, many LLMs still struggle to
deliver the desired level of culinary creativity, especially when tasked with
adapting recipes to meet specific cultural requirements. This study focuses on
cuisine transfer-applying elements of one cuisine to another-to assess LLMs'
culinary creativity. We employ a diverse set of LLMs to generate and evaluate
culturally adapted recipes, comparing their evaluations against LLM and human
judgments. We introduce the ASH (authenticity, sensitivity, harmony) benchmark
to evaluate LLMs' recipe generation abilities in the cuisine transfer task,
assessing their cultural accuracy and creativity in the culinary domain. Our
findings reveal crucial insights into both generative and evaluative
capabilities of LLMs in the culinary domain, highlighting strengths and
limitations in understanding and applying cultural nuances in recipe creation.
The code and dataset used in this project will be openly available in
\url{http://github.com/dmis-lab/CulinaryASH}.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂá∫ÁèæÂ∑≤Âú®ÂêÑÁ®ÆÂâµÊÑèÈ†òÂüü‰∏≠Â±ïÁèæÂá∫ÂâçÊôØÔºåÂåÖÊã¨ÊñôÁêÜËóùË°ì„ÄÇÁÑ∂ËÄåÔºåË®±Â§ö LLM ‰ªçÈõ£‰ª•Êèê‰æõÊâÄÈúÄÁöÑÊñôÁêÜÂâµÊÑèÊ∞¥Ê∫ñÔºåÁâπÂà•ÊòØÂú®ÈúÄË¶ÅË™øÊï¥È£üË≠ú‰ª•Á¨¶ÂêàÁâπÂÆöÊñáÂåñÈúÄÊ±ÇÊôÇ„ÄÇÊú¨Á†îÁ©∂Â∞àÊ≥®ÊñºÊñôÁêÜËΩâÁßªÔºåÂ∞á‰∏ÄÁ®ÆÊñôÁêÜÁöÑÂÖÉÁ¥†ÊáâÁî®Âà∞Âè¶‰∏ÄÁ®ÆÊñôÁêÜ‰∏≠Ôºå‰ª•Ë©ï‰º∞ LLM ÁöÑÊñôÁêÜÂâµÊÑè„ÄÇÊàëÂÄëÊé°Áî®Â§öÂÖÉÁöÑ LLM ‰æÜÁî¢Áîü‰∏¶Ë©ï‰º∞Á∂ìÈÅéÊñáÂåñË™øÊï¥ÁöÑÈ£üË≠úÔºå‰∏¶Â∞áÂÖ∂Ë©ï‰º∞Ëàá LLM Âíå‰∫∫È°ûÁöÑÂà§Êñ∑ÈÄ≤Ë°åÊØîËºÉ„ÄÇÊàëÂÄëÂ∞éÂÖ• ASHÔºàÁúüÂØ¶ÊÄß„ÄÅÊïèÊÑüÊÄß„ÄÅÂíåË´ßÊÄßÔºâÂü∫Ê∫ñ‰æÜË©ï‰º∞ LLM Âú®ÊñôÁêÜËΩâÁßª‰ªªÂãô‰∏≠ÁöÑÈ£üË≠úÁî¢ÁîüËÉΩÂäõÔºåË©ï‰º∞ÂÖ∂Âú®ÊñôÁêÜÈ†òÂüü‰∏≠ÁöÑÊñáÂåñÊ∫ñÁ¢∫ÊÄßÂíåÂâµÊÑèÊÄß„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÊè≠Èú≤‰∫Ü LLM Âú®ÊñôÁêÜÈ†òÂüü‰∏≠Áî¢ÁîüÂíåË©ï‰º∞ËÉΩÂäõÁöÑÈáçË¶ÅË¶ãËß£ÔºåÁ™ÅÈ°Ø‰∫ÜÂú®È£üË≠úÂâµ‰Ωú‰∏≠ÁêÜËß£ÂíåÊáâÁî®ÊñáÂåñÁ¥∞ÂæÆÂ∑ÆÁöÑÂÑ™ÈªûÂíåÈôêÂà∂„ÄÇÊú¨Â∞àÊ°à‰∏≠‰ΩøÁî®ÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜÂ∞áÂú® \url{http://github.com/dmis-lab/CulinaryASH} ‰∏≠ÈñãÊîæÂèñÂæó„ÄÇ

##### **Understanding Variational Autoencoders with Intrinsic Dimension and Information Imbalance**
2411.01978v1 by Charles Camboulin, Diego Doimo, Aldo Glielmo

This work presents an analysis of the hidden representations of Variational
Autoencoders (VAEs) using the Intrinsic Dimension (ID) and the Information
Imbalance (II). We show that VAEs undergo a transition in behaviour once the
bottleneck size is larger than the ID of the data, manifesting in a double
hunchback ID profile and a qualitative shift in information processing as
captured by the II. Our results also highlight two distinct training phases for
architectures with sufficiently large bottleneck sizes, consisting of a rapid
fit and a slower generalisation, as assessed by a differentiated behaviour of
ID, II, and KL loss. These insights demonstrate that II and ID could be
valuable tools for aiding architecture search, for diagnosing underfitting in
VAEs, and, more broadly, they contribute to advancing a unified understanding
of deep generative models through geometric analysis.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂‰ΩøÁî®ÂÜÖÂú®Áª¥Â∫¶ (ID) Âíå‰ø°ÊÅØ‰∏çÂπ≥Ë°° (II) ÂàÜÊûêÂèòÂàÜËá™Âä®ÁºñÁ†ÅÂô® (VAE) ÁöÑÈöêËóèË°®ÂæÅ„ÄÇÊàë‰ª¨Ë°®ÊòéÔºå‰∏ÄÊó¶Áì∂È¢àÂ§ßÂ∞èÂ§ß‰∫éÊï∞ÊçÆÁöÑ IDÔºåVAE ÁöÑË°å‰∏∫Â∞±‰ºöÂèëÁîüËΩ¨ÂèòÔºåË°®Áé∞‰∏∫ÂèåÈ©ºÂ≥∞ ID ËΩÆÂªìÂíå II ÊçïËé∑ÁöÑ‰ø°ÊÅØÂ§ÑÁêÜÁöÑË¥®Âèò„ÄÇÊàë‰ª¨ÁöÑÁªìÊûúËøòÂº∫Ë∞É‰∫ÜÂÖ∑ÊúâË∂≥Â§üÂ§ßÁì∂È¢àÂ§ßÂ∞èÁöÑÊû∂ÊûÑÁöÑ‰∏§‰∏™‰∏çÂêåÁöÑËÆ≠ÁªÉÈò∂ÊÆµÔºåÂåÖÊã¨Âø´ÈÄüÊãüÂêàÂíåËæÉÊÖ¢Ê≥õÂåñÔºåÂ¶Ç ID„ÄÅII Âíå KL ÊçüÂ§±ÁöÑ‰∏çÂêåË°å‰∏∫ÊâÄËØÑ‰º∞ÁöÑÈÇ£Ê†∑„ÄÇËøô‰∫õËßÅËß£Ë°®ÊòéÔºåII Âíå ID ÂèØËÉΩÊòØËæÖÂä©Êû∂ÊûÑÊêúÁ¥¢„ÄÅËØäÊñ≠ VAE ‰∏≠ÁöÑÊ¨†ÊãüÂêàÁöÑÂÆùË¥µÂ∑•ÂÖ∑ÔºåËÄå‰∏îÊõ¥ÂπøÊ≥õÂú∞ËØ¥ÔºåÂÆÉ‰ª¨ÊúâÂä©‰∫éÈÄöËøáÂá†‰ΩïÂàÜÊûê‰øÉËøõÂØπÊ∑±Â∫¶ÁîüÊàêÊ®°ÂûãÁöÑÁªü‰∏ÄÁêÜËß£„ÄÇ

##### **Active Gaze Behavior Boosts Self-Supervised Object Learning**
2411.01969v1 by Zhengyang Yu, Arthur Aubret, Marcel C. Raabe, Jane Yang, Chen Yu, Jochen Triesch

Due to significant variations in the projection of the same object from
different viewpoints, machine learning algorithms struggle to recognize the
same object across various perspectives. In contrast, toddlers quickly learn to
recognize objects from different viewpoints with almost no supervision. Recent
works argue that toddlers develop this ability by mapping close-in-time visual
inputs to similar representations while interacting with objects. High acuity
vision is only available in the central visual field, which may explain why
toddlers (much like adults) constantly move their gaze around during such
interactions. It is unclear whether/how much toddlers curate their visual
experience through these eye movements to support learning object
representations. In this work, we explore whether a bio inspired visual
learning model can harness toddlers' gaze behavior during a play session to
develop view-invariant object recognition. Exploiting head-mounted eye tracking
during dyadic play, we simulate toddlers' central visual field experience by
cropping image regions centered on the gaze location. This visual stream feeds
a time-based self-supervised learning algorithm. Our experiments demonstrate
that toddlers' gaze strategy supports the learning of invariant object
representations. Our analysis also reveals that the limited size of the central
visual field where acuity is high is crucial for this. We further find that
toddlers' visual experience elicits more robust representations compared to
adults' mostly because toddlers look at objects they hold themselves for longer
bouts. Overall, our work reveals how toddlers' gaze behavior supports
self-supervised learning of view-invariant object recognition.

ÊëòË¶ÅÔºöÁî±ÊñºÂêå‰∏ÄÂÄãÁâ©È´îÂæû‰∏çÂêåË¶ñËßíÊäïÂΩ±ÊôÇËÆäÂåñÂæàÂ§ßÔºåÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïÂæàÈõ£Ëæ®Ë≠ò‰∏çÂêåË¶ñËßíÁöÑÂêå‰∏ÄÂÄãÁâ©È´î„ÄÇÁõ∏ÂèçÂú∞ÔºåÂπºÂÖíÂπæ‰πéÊ≤íÊúâÁõ£Áù£Â∞±ËÉΩÂø´ÈÄüÂ≠∏ÊúÉÂæû‰∏çÂêåË¶ñËßíËæ®Ë≠òÁâ©È´î„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂ÊåáÂá∫ÔºåÂπºÂÖíÈÄèÈÅéÂú®ËàáÁâ©È´î‰∫íÂãïÊôÇÂ∞áÊé•ËøëÊôÇÈñìÁöÑË¶ñË¶∫Ëº∏ÂÖ•Â∞çÊáâÂà∞È°û‰ººÁöÑË°®ÂæµÔºå‰æÜÂüπÈ§äÈÄôÁ®ÆËÉΩÂäõ„ÄÇÈ´òËß£ÊûêÂ∫¶Ë¶ñË¶∫Âè™Â≠òÂú®Êñº‰∏≠Â§ÆË¶ñË¶∫Â†¥‰∏≠ÔºåÈÄôÊàñË®±ÂèØ‰ª•Ëß£ÈáãÁÇ∫‰ΩïÂπºÂÖíÔºàÂæàÂÉèÊàê‰∫∫ÔºâÂú®ÈÄôÁ®Æ‰∫íÂãïÈÅéÁ®ã‰∏≠ÊúÉ‰∏çÊñ∑ËΩâÂãïË¶ñÁ∑ö„ÄÇÁõÆÂâçÂ∞ö‰∏çÊ∏ÖÊ•öÂπºÂÖíÊòØÂê¶/Â¶Ç‰ΩïÈÄèÈÅéÈÄô‰∫õÁúºÁêÉÈÅãÂãï‰æÜÁ≠ñÂäÉ‰ªñÂÄëÁöÑË¶ñË¶∫Á∂ìÈ©óÔºå‰ª•ÊîØÊåÅÂ≠∏ÁøíÁâ©È´îË°®Âæµ„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÂèóÁîüÁâ©ÂïüÁôºÁöÑË¶ñË¶∫Â≠∏ÁøíÊ®°ÂûãÊòØÂê¶ËÉΩÂà©Áî®ÂπºÂÖíÂú®ÈÅäÊà≤ÈÅéÁ®ã‰∏≠Ê≥®Ë¶ñÁöÑË°åÁÇ∫Ôºå‰æÜÁôºÂ±ïËßÄÈªû‰∏çËÆäÁöÑÁâ©È´îËæ®Ë≠ò„ÄÇÊàëÂÄëÂú®Èõô‰∫∫ÈÅäÊà≤‰∏≠Âà©Áî®È†≠Êà¥ÂºèÁúºÁêÉËøΩËπ§ÊäÄË°ìÔºåÊ®°Êì¨ÂπºÂÖíÁöÑ‰∏≠Â§ÆË¶ñË¶∫Â†¥Á∂ìÈ©óÔºåÊñπÊ≥ïÊòØË£ÅÂâ™‰ª•Ê≥®Ë¶ñ‰ΩçÁΩÆÁÇ∫‰∏≠ÂøÉÁöÑÂΩ±ÂÉèÂçÄÂüü„ÄÇÈÄôÂÄãË¶ñË¶∫‰∏≤ÊµÅÊèê‰æõÁµ¶Âü∫ÊñºÊôÇÈñìÁöÑËá™Áõ£Áù£Â≠∏ÁøíÊºîÁÆóÊ≥ï„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË≠âÊòéÂπºÂÖíÁöÑÊ≥®Ë¶ñÁ≠ñÁï•ÊúâÂä©ÊñºÂ≠∏Áøí‰∏çËÆäÁöÑÁâ©È´îË°®Âæµ„ÄÇÊàëÂÄëÁöÑÂàÜÊûê‰πüÊè≠Á§∫ÔºåÈ´òËß£ÊûêÂ∫¶‰∏≠Â§ÆË¶ñË¶∫Â†¥ÁöÑÊúâÈôêÂ§ßÂ∞èÂ∞çÊ≠§Ëá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÁôºÁèæÔºåËàáÊàê‰∫∫Áõ∏ÊØîÔºåÂπºÂÖíÁöÑË¶ñË¶∫Á∂ìÈ©óÂºïÁôº‰∫ÜÊõ¥Âº∑ÂÅ•ÁöÑË°®ÂæµÔºå‰∏ªË¶ÅÂéüÂõ†ÊòØÂπºÂÖíÊúÉÈï∑ÊôÇÈñìÊ≥®Ë¶ñ‰ªñÂÄëÊãøÂú®Êâã‰∏≠ÁöÑÁâ©È´î„ÄÇÁ∏ΩÁöÑ‰æÜË™™ÔºåÊàëÂÄëÁöÑÁ†îÁ©∂Êè≠Á§∫‰∫ÜÂπºÂÖíÁöÑÊ≥®Ë¶ñË°åÁÇ∫Â¶Ç‰ΩïÊîØÊè¥ËßÄÈªû‰∏çËÆäÁöÑÁâ©È´îËæ®Ë≠òÁöÑËá™Áõ£Áù£Â≠∏Áøí„ÄÇ

##### **V-CAS: A Realtime Vehicle Anti Collision System Using Vision Transformer on Multi-Camera Streams**
2411.01963v1 by Muhammad Waqas Ashraf, Ali Hassan, Imad Ali Shah

This paper introduces a real-time Vehicle Collision Avoidance System (V-CAS)
designed to enhance vehicle safety through adaptive braking based on
environmental perception. V-CAS leverages the advanced vision-based transformer
model RT-DETR, DeepSORT tracking, speed estimation, brake light detection, and
an adaptive braking mechanism. It computes a composite collision risk score
based on vehicles' relative accelerations, distances, and detected braking
actions, using brake light signals and trajectory data from multiple camera
streams to improve scene perception. Implemented on the Jetson Orin Nano, V-CAS
enables real-time collision risk assessment and proactive mitigation through
adaptive braking. A comprehensive training process was conducted on various
datasets for comparative analysis, followed by fine-tuning the selected object
detection model using transfer learning. The system's effectiveness was
rigorously evaluated on the Car Crash Dataset (CCD) from YouTube and through
real-time experiments, achieving over 98% accuracy with an average proactive
alert time of 1.13 seconds. Results indicate significant improvements in object
detection and tracking, enhancing collision avoidance compared to traditional
single-camera methods. This research demonstrates the potential of low-cost,
multi-camera embedded vision transformer systems to advance automotive safety
through enhanced environmental perception and proactive collision avoidance
mechanisms.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÂç≥ÊôÇËªäËºõÈò≤ÊíûÁ≥ªÁµ± (V-CAS)ÔºåÊó®Âú®ÈÄèÈÅéÂü∫ÊñºÁí∞Â¢ÉÊÑüÁü•ÁöÑËá™ÈÅ©ÊáâÁÖûËªä‰æÜÊèêÂçáËªäËºõÂÆâÂÖ®ÊÄß„ÄÇV-CAS Âà©Áî®ÂÖàÈÄ≤ÁöÑÂü∫ÊñºË¶ñË¶∫ÁöÑ Transformer Ê®°Âûã RT-DETR„ÄÅDeepSORT ËøΩËπ§„ÄÅÈÄüÂ∫¶‰º∞Ë®à„ÄÅÁÖûËªäÁáàÂÅµÊ∏¨Ôºå‰ª•ÂèäËá™ÈÅ©ÊáâÁÖûËªäÊ©üÂà∂„ÄÇÂÆÉÊúÉÊ†πÊìöËªäËºõÁöÑÁõ∏Â∞çÂä†ÈÄüÂ∫¶„ÄÅË∑ùÈõ¢ÂíåÂÅµÊ∏¨Âà∞ÁöÑÁÖûËªäÂãï‰ΩúÔºåË®àÁÆóÂá∫‰∏ÄÂÄãË§áÂêàÁ¢∞ÊíûÈ¢®Èö™Ë©ïÂàÜÔºå‰∏¶‰ΩøÁî®‰æÜËá™Â§öÂÄãÊîùÂΩ±Ê©ü‰∏≤ÊµÅÁöÑÁÖûËªäÁáàË®äËôüÂíåËªåË∑°Ë≥áÊñô‰æÜÊîπÂñÑÂ†¥ÊôØÊÑüÁü•„ÄÇV-CAS ÂØ¶‰ΩúÊñº Jetson Orin Nano ‰∏äÔºåÂèØÈÄèÈÅéËá™ÈÅ©ÊáâÁÖûËªäÈÄ≤Ë°åÂç≥ÊôÇÁ¢∞ÊíûÈ¢®Èö™Ë©ï‰º∞Âíå‰∏ªÂãïÊ∏õÁ∑©„ÄÇÂú®ÂêÑÁ®ÆË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑË®ìÁ∑¥ÊµÅÁ®ã‰ª•ÈÄ≤Ë°åÊØîËºÉÂàÜÊûêÔºåÊé•Ëëó‰ΩøÁî®ÈÅ∑ÁßªÂ≠∏ÁøíÂæÆË™øÊâÄÈÅ∏ÁöÑÁâ©‰ª∂ÂÅµÊ∏¨Ê®°Âûã„ÄÇÁ≥ªÁµ±ÁöÑÊúâÊïàÊÄßÂú® YouTube ÁöÑÊ±ΩËªäÁ¢∞ÊíûË≥áÊñôÈõÜ (CCD) ÂíåÂç≥ÊôÇÂØ¶È©ó‰∏≠Á∂ìÈÅéÂö¥Ê†ºË©ï‰º∞ÔºåÊ∫ñÁ¢∫ÁéáË∂ÖÈÅé 98%ÔºåÂπ≥Âùá‰∏ªÂãïË≠¶Á§∫ÊôÇÈñìÁÇ∫ 1.13 Áßí„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåËàáÂÇ≥Áµ±ÁöÑÂñÆ‰∏ÄÊîùÂΩ±Ê©üÊñπÊ≥ïÁõ∏ÊØîÔºåÁâ©‰ª∂ÂÅµÊ∏¨ÂíåËøΩËπ§ÊúâÈ°ØËëóÁöÑÊîπÂñÑÔºåÂ¢ûÂº∑‰∫ÜÈò≤ÊíûËÉΩÂäõ„ÄÇÊú¨Á†îÁ©∂Â±ïÁ§∫‰∫Ü‰ΩéÊàêÊú¨„ÄÅÂ§öÊîùÂΩ±Ê©üÂµåÂÖ•ÂºèË¶ñË¶∫ Transformer Á≥ªÁµ±ÁöÑÊΩõÂäõÔºåÂèØÈÄèÈÅéÂ¢ûÂº∑ÁöÑÁí∞Â¢ÉÊÑüÁü•Âíå‰∏ªÂãïÈò≤ÊíûÊ©üÂà∂‰æÜÊèêÂçáÊ±ΩËªäÂÆâÂÖ®ÊÄß„ÄÇ

##### **HACD: Harnessing Attribute Semantics and Mesoscopic Structure for Community Detection**
2411.01947v1 by Anran Zhang, Xingfen Wang, Yuhan Zhao

Community detection plays a pivotal role in uncovering closely connected
subgraphs, aiding various real-world applications such as recommendation
systems and anomaly detection. With the surge of rich information available for
entities in real-world networks, the community detection problem in attributed
networks has attracted widespread attention. While previous research has
effectively leveraged network topology and attribute information for attributed
community detection, these methods overlook two critical issues: (i) the
semantic similarity between node attributes within the community, and (ii) the
inherent mesoscopic structure, which differs from the pairwise connections of
the micro-structure. To address these limitations, we propose HACD, a novel
attributed community detection model based on heterogeneous graph attention
networks. HACD treats node attributes as another type of node, constructs
attributed networks into heterogeneous graph structures and employs
attribute-level attention mechanisms to capture semantic similarity.
Furthermore, HACD introduces a community membership function to explore
mesoscopic community structures, enhancing the robustness of detected
communities. Extensive experiments demonstrate the effectiveness and efficiency
of HACD, outperforming state-of-the-art methods in attributed community
detection tasks. Our code is publicly available at
https://github.com/Anniran1/HACD1-wsdm.

ÊëòË¶ÅÔºöÁ§æÁæ§ÂÅµÊ∏¨Âú®Êè≠Èú≤Á∑äÂØÜÈÄ£ÁµêÁöÑÂ≠êÂúñ‰∏≠ÊâÆÊºîËëóËàâË∂≥ËºïÈáçÁöÑËßíËâ≤ÔºåÂçîÂä©ÂêÑÁ®ÆÂØ¶ÈöõÊáâÁî®Ôºå‰æãÂ¶ÇÊé®Ëñ¶Á≥ªÁµ±ÂíåÁï∞Â∏∏ÂÅµÊ∏¨„ÄÇÈö®ËëóÂØ¶Èöõ‰∏ñÁïåÁ∂≤Ë∑Ø‰∏≠ÂØ¶È´îÂèØÁî®ÁöÑË±êÂØåË≥áË®äÊøÄÂ¢ûÔºåÂ±¨ÊÄßÁ∂≤Ë∑Ø‰∏≠ÁöÑÁ§æÁæ§ÂÅµÊ∏¨ÂïèÈ°åÂºïËµ∑‰∫ÜÂª£Ê≥õÈóúÊ≥®„ÄÇÈõñÁÑ∂ÂÖàÂâçÁöÑÁ†îÁ©∂Â∑≤ÊúâÊïàÂà©Áî®Á∂≤Ë∑ØÊãìÊí≤ÂíåÂ±¨ÊÄßË≥áË®ä‰æÜÈÄ≤Ë°åÂ±¨ÊÄßÁ§æÁæ§ÂÅµÊ∏¨Ôºå‰ΩÜÈÄô‰∫õÊñπÊ≥ïÂøΩÁï•‰∫ÜÂÖ©ÂÄãÈóúÈçµÂïèÈ°åÔºö(i) Á§æÁæ§ÂÖßÁØÄÈªûÂ±¨ÊÄß‰πãÈñìÁöÑË™ûÊÑèÁõ∏‰ººÊÄßÔºå‰ª•Âèä (ii) ËàáÂæÆÁµêÊßãÁöÑÊàêÂ∞çÈÄ£Êé•‰∏çÂêåÁöÑÂõ∫Êúâ‰∏≠ËßÄÁµêÊßã„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü HACDÔºå‰∏ÄÁ®ÆÂü∫ÊñºÁï∞Ë≥™ÂúñÊ≥®ÊÑèÂäõÁ∂≤Ë∑ØÁöÑÊñ∞ÂûãÂ±¨ÊÄßÁ§æÁæ§ÂÅµÊ∏¨Ê®°Âûã„ÄÇHACD Â∞áÁØÄÈªûÂ±¨ÊÄßË¶ñÁÇ∫Âè¶‰∏ÄÁ®ÆÁØÄÈªûÈ°ûÂûãÔºåÂ∞áÂ±¨ÊÄßÁ∂≤Ë∑ØÂª∫ÊßãÁÇ∫Áï∞Ë≥™ÂúñÁµêÊßãÔºå‰∏¶Êé°Áî®Â±¨ÊÄßÂ±§Á¥öÊ≥®ÊÑèÂäõÊ©üÂà∂‰æÜÊì∑ÂèñË™ûÊÑèÁõ∏‰ººÊÄß„ÄÇÊ≠§Â§ñÔºåHACD ÂºïÂÖ•‰∫ÜÁ§æÁæ§ÊàêÂì°Ë≥áÊ†ºÂáΩÊï∏‰æÜÊé¢Á¥¢‰∏≠ËßÄÁ§æÁæ§ÁµêÊßãÔºåÂ¢ûÂº∑‰∫ÜÂ∑≤ÂÅµÊ∏¨Á§æÁæ§ÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòé‰∫Ü HACD ÁöÑÊúâÊïàÊÄßÂíåÊïàÁéáÔºåÂú®Â±¨ÊÄßÁ§æÁæ§ÂÅµÊ∏¨‰ªªÂãô‰∏≠ÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/Anniran1/HACD1-wsdm ÂÖ¨ÈñãÂèñÂæó„ÄÇ

##### **Exploring the Landscape for Generative Sequence Models for Specialized Data Synthesis**
2411.01929v1 by Mohammad Zbeeb, Mohammad Ghorayeb, Mariam Salman

Artificial Intelligence (AI) research often aims to develop models that
generalize reliably across complex datasets, yet this remains challenging in
fields where data is scarce, intricate, or inaccessible. This paper introduces
a novel approach leveraging three generative models of varying complexity to
synthesize one of the most demanding structured datasets: Malicious Network
Traffic. Our approach transforms numerical data into text, reframing data
generation as a language modeling task, which enhances data regularization and
significantly improves generalization and the quality of the synthetic data.
Extensive statistical analyses demonstrate that our method surpasses
state-of-the-art generative models in producing high-fidelity synthetic data.
Additionally, we conduct a comprehensive study on synthetic data applications,
effectiveness, and evaluation strategies, offering valuable insights into its
role across various domains. Our code and pre-trained models are openly
accessible at
https://github.com/Moe-Zbeeb/Exploring-the-landscape-for-generative-models-for-specialized-data-generation,
enabling further exploration and application of our methodology.
  Index Terms: Data synthesis, machine learning, traffic generation,
privacy-preserving data, generative models.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) Á†îÁ©∂ÈÄöÂ∏∏Êó®Âú®ÈñãÁôºÂú®Ë§áÈõúË≥áÊñôÈõÜ‰∏äÂèØÈù†Âú∞Ê≥õÂåñÁöÑÊ®°ÂûãÔºåÁÑ∂ËÄåÂú®Ë≥áÊñôÁ®ÄÂ∞ë„ÄÅË§áÈõúÊàñÁÑ°Ê≥ïÂèñÂæóÁöÑÈ†òÂüü‰∏≠ÔºåÈÄô‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÂà©Áî®‰∏âÁ®Æ‰∏çÂêåË§áÈõúÂ∫¶ÁöÑÁîüÊàêÊ®°Âûã‰æÜÂêàÊàêÊúÄÂÖ∑ÊåëÊà∞ÊÄßÁöÑÁµêÊßãÂåñË≥áÊñôÈõÜ‰πã‰∏ÄÔºöÊÉ°ÊÑèÁ∂≤Ë∑ØÊµÅÈáè„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂ∞áÊï∏ÂÄºË≥áÊñôËΩâÊèõÁÇ∫ÊñáÂ≠óÔºåÂ∞áË≥áÊñôÁî¢ÁîüÈáçÊñ∞ÂÆöÁæ©ÁÇ∫Ë™ûË®ÄÂª∫Ê®°‰ªªÂãôÔºåÈÄôÂ¢ûÂº∑‰∫ÜË≥áÊñôÊ≠£Ë¶èÂåñÔºå‰∏¶È°ØËëóÊîπÂñÑ‰∫ÜÊ≥õÂåñÂíåÂêàÊàêË≥áÊñôÁöÑÂìÅË≥™„ÄÇÂª£Ê≥õÁöÑÁµ±Ë®àÂàÜÊûêË≠âÊòéÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÂú®Áî¢ÁîüÈ´ò‰øùÁúüÂêàÊàêË≥áÊñôÊñπÈù¢Ë∂ÖË∂ä‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÁîüÊàêÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ∞çÂêàÊàêË≥áÊñôÊáâÁî®„ÄÅÊïàËÉΩÂíåË©ï‰º∞Á≠ñÁï•ÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÁ†îÁ©∂ÔºåÊèê‰æõ‰∫ÜÂ∞çÂÖ∂Âú®ÂêÑÁ®ÆÈ†òÂüü‰∏≠ËßíËâ≤ÁöÑÂØ∂Ë≤¥Ë¶ãËß£„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåÈ†êÂÖàË®ìÁ∑¥ÁöÑÊ®°ÂûãÂú® https://github.com/Moe-Zbeeb/Exploring-the-landscape-for-generative-models-for-specialized-data-generation ‰∏äÂÖ¨ÈñãÔºåÂèØÈÄ≤‰∏ÄÊ≠•Êé¢Á¥¢ÂíåÊáâÁî®ÊàëÂÄëÁöÑÊäÄË°ì„ÄÇ
Á¥¢ÂºïË©ûÔºöË≥áÊñôÂêàÊàê„ÄÅÊ©üÂô®Â≠∏Áøí„ÄÅÊµÅÈáèÁî¢Áîü„ÄÅÈö±ÁßÅ‰øùË≠∑Ë≥áÊñô„ÄÅÁîüÊàêÊ®°Âûã„ÄÇ

##### **Fairness-Utilization Trade-off in Wireless Networks with Explainable Kolmogorov-Arnold Networks**
2411.01924v1 by Masoud Shokrnezhad, Hamidreza Mazandarani, Tarik Taleb

The effective distribution of user transmit powers is essential for the
significant advancements that the emergence of 6G wireless networks brings. In
recent studies, Deep Neural Networks (DNNs) have been employed to address this
challenge. However, these methods frequently encounter issues regarding
fairness and computational inefficiency when making decisions, rendering them
unsuitable for future dynamic services that depend heavily on the participation
of each individual user. To address this gap, this paper focuses on the
challenge of transmit power allocation in wireless networks, aiming to optimize
$\alpha$-fairness to balance network utilization and user equity. We introduce
a novel approach utilizing Kolmogorov-Arnold Networks (KANs), a class of
machine learning models that offer low inference costs compared to traditional
DNNs through superior explainability. The study provides a comprehensive
problem formulation, establishing the NP-hardness of the power allocation
problem. Then, two algorithms are proposed for dataset generation and
decentralized KAN training, offering a flexible framework for achieving various
fairness objectives in dynamic 6G environments. Extensive numerical simulations
demonstrate the effectiveness of our approach in terms of fairness and
inference cost. The results underscore the potential of KANs to overcome the
limitations of existing DNN-based methods, particularly in scenarios that
demand rapid adaptation and fairness.

ÊëòË¶ÅÔºöÊúâÊïàÂàÜÈÖç‰ΩøÁî®ËÄÖÂÇ≥Ëº∏ÂäüÁéáÂ∞çÊñº 6G ÁÑ°Á∑öÁ∂≤Ë∑ØÁöÑÂá∫ÁèæÊâÄÂ∏∂‰æÜÁöÑÈáçÂ§ßÈÄ≤Â±ïËá≥ÈóúÈáçË¶Å„ÄÇÂú®ÊúÄËøëÁöÑÁ†îÁ©∂‰∏≠ÔºåÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑Ø (DNN) Â∑≤Ë¢´Áî®ÊñºËß£Ê±∫Ê≠§ÊåëÊà∞„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÂú®ÂÅöÂá∫Ê±∫Á≠ñÊôÇÁ∂ìÂ∏∏ÈÅáÂà∞ÂÖ¨Âπ≥ÊÄßÂíåÈÅãÁÆóÊïàÁéá‰Ωé‰∏ãÁöÑÂïèÈ°åÔºå‰ΩøÂÖ∂‰∏çÈÅ©Âêà‰æùË≥¥ÊØèÂÄãÂÄãÂà•‰ΩøÁî®ËÄÖÂèÉËàáÁöÑÊú™‰æÜÂãïÊÖãÊúçÂãô„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§Â∑ÆË∑ùÔºåÊú¨ÊñáÈáçÈªûÊé¢Ë®éÁÑ°Á∑öÁ∂≤Ë∑Ø‰∏≠ÂÇ≥Ëº∏ÂäüÁéáÂàÜÈÖçÁöÑÊåëÊà∞ÔºåÁõÆÊ®ôÊòØÊúÄ‰Ω≥Âåñ $\alpha$-ÂÖ¨Âπ≥ÊÄßÔºå‰ª•Âπ≥Ë°°Á∂≤Ë∑Ø‰ΩøÁî®ÁéáÂíå‰ΩøÁî®ËÄÖÂÖ¨Âπ≥ÊÄß„ÄÇÊàëÂÄëÂºïÂÖ•‰∏ÄÁ®ÆÂà©Áî® Kolmogorov-Arnold Á∂≤Ë∑Ø (KAN) ÁöÑÊñ∞ÊñπÊ≥ïÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÔºåÈÄèÈÅéÂÑ™Áï∞ÁöÑÂèØËß£ÈáãÊÄßÔºåËàáÂÇ≥Áµ± DNN Áõ∏ÊØîÊèê‰æõ‰∫ÜËºÉ‰ΩéÁöÑÊé®Ë´ñÊàêÊú¨„ÄÇÊú¨Á†îÁ©∂Êèê‰æõ‰∫ÜÂÖ®Èù¢ÁöÑÂïèÈ°åË°®Ëø∞ÔºåÂª∫Á´ã‰∫ÜÂäüÁéáÂàÜÈÖçÂïèÈ°åÁöÑ NP Èõ£Â∫¶„ÄÇÁÑ∂ÂæåÔºåÊèêÂá∫‰∫ÜÂÖ©ÂÄãÊºîÁÆóÊ≥ïÁî®ÊñºË≥áÊñôÈõÜÁîüÊàêÂíåÂàÜÊï£Âºè KAN Ë®ìÁ∑¥ÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÈùàÊ¥ªÁöÑÊû∂ÊßãÔºåÁî®ÊñºÂú®ÂãïÊÖã 6G Áí∞Â¢É‰∏≠ÂØ¶ÁèæÂêÑÁ®ÆÂÖ¨Âπ≥ÊÄßÁõÆÊ®ô„ÄÇÂª£Ê≥õÁöÑÊï∏ÂÄºÊ®°Êì¨Ë≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®ÂÖ¨Âπ≥ÊÄßÂíåÊé®Ë´ñÊàêÊú¨ÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÁµêÊûúÂº∑Ë™ø‰∫Ü KAN ÂÖãÊúçÁèæÊúâÂü∫Êñº DNN ÁöÑÊñπÊ≥ïÁöÑÈôêÂà∂ÁöÑÊΩõÂäõÔºåÁâπÂà•ÊòØÂú®ÈúÄË¶ÅÂø´ÈÄüÈÅ©ÊáâÂíåÂÖ¨Âπ≥ÊÄßÁöÑÂ†¥ÊôØ‰∏≠„ÄÇ

##### **LE-PDE++: Mamba for accelerating PDEs Simulations**
2411.01897v1 by Aoming Liang, Zhaoyang Mu, Qi liu, Ruipeng Li, Mingming Ge, Dixia Fan

Partial Differential Equations are foundational in modeling science and
natural systems such as fluid dynamics and weather forecasting. The Latent
Evolution of PDEs method is designed to address the computational intensity of
classical and deep learning-based PDE solvers by proposing a scalable and
efficient alternative. To enhance the efficiency and accuracy of LE-PDE, we
incorporate the Mamba model, an advanced machine learning model known for its
predictive efficiency and robustness in handling complex dynamic systems with a
progressive learning strategy. The LE-PDE was tested on several benchmark
problems. The method demonstrated a marked reduction in computational time
compared to traditional solvers and standalone deep learning models while
maintaining high accuracy in predicting system behavior over time. Our method
doubles the inference speed compared to the LE-PDE while retaining the same
level of parameter efficiency, making it well-suited for scenarios requiring
long-term predictions.

ÊëòË¶ÅÔºöÂÅèÂæÆÂàÜÊñπÁ®ãÂºèÊòØÂª∫Ê®°ÁßëÂ≠∏ÂíåËá™ÁÑ∂Á≥ªÁµ±Ôºà‰æãÂ¶ÇÊµÅÈ´îÂãïÂäõÂ≠∏ÂíåÂ§©Ê∞£È†êÊ∏¨ÔºâÁöÑÂü∫Á§é„ÄÇÂÅèÂæÆÂàÜÊñπÁ®ãÂºèÊñπÊ≥ïÁöÑÊΩõÂú®ÊºîÂåñÊó®Âú®ÈÄöÈÅéÊèêÂá∫ÂèØÊì¥Â±ï‰∏îÈ´òÊïàÁöÑÊõø‰ª£ÊñπÊ°à‰æÜËß£Ê±∫Âü∫ÊñºÁ∂ìÂÖ∏ÂíåÊ∑±Â∫¶Â≠∏ÁøíÁöÑÂÅèÂæÆÂàÜÊñπÁ®ãÂºèÊ±ÇËß£Âô®ÁöÑË®àÁÆóÂº∑Â∫¶„ÄÇÁÇ∫‰∫ÜÊèêÈ´ò LE-PDE ÁöÑÊïàÁéáÂíåÊ∫ñÁ¢∫ÊÄßÔºåÊàëÂÄëÁµêÂêà‰∫Ü Mamba Ê®°ÂûãÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂÖàÈÄ≤ÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÔºå‰ª•ÂÖ∂Âú®ËôïÁêÜÂÖ∑ÊúâÊº∏ÈÄ≤Â≠∏ÁøíÁ≠ñÁï•ÁöÑË§áÈõúÂãïÊÖãÁ≥ªÁµ±ÊñπÈù¢ÁöÑÈ†êÊ∏¨ÊïàÁéáÂíåÁ©©ÂÅ•ÊÄßËÄåËÅûÂêç„ÄÇLE-PDE Â∑≤Âú®ÂπæÂÄãÂü∫Ê∫ñÂïèÈ°å‰∏äÈÄ≤Ë°å‰∫ÜÊ∏¨Ë©¶„ÄÇËàáÂÇ≥Áµ±Ê±ÇËß£Âô®ÂíåÁç®Á´ãÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁõ∏ÊØîÔºåË©≤ÊñπÊ≥ïÈ°ØËëóÊ∏õÂ∞ë‰∫ÜË®àÁÆóÊôÇÈñìÔºåÂêåÊôÇÂú®Èö®ËëóÊôÇÈñìÊé®ÁßªÈ†êÊ∏¨Á≥ªÁµ±Ë°åÁÇ∫ÊñπÈù¢‰øùÊåÅ‰∫ÜÈ´òÊ∫ñÁ¢∫ÊÄß„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂ∞áÊé®ÁêÜÈÄüÂ∫¶ÊèêÈ´ò‰∫Ü‰∏ÄÂÄçÔºåÂêåÊôÇ‰øùÊåÅ‰∫ÜÁõ∏ÂêåÁöÑÂèÉÊï∏ÊïàÁéáÔºå‰ΩøÂÖ∂ÈùûÂ∏∏ÈÅ©ÂêàÈúÄË¶ÅÈï∑ÊúüÈ†êÊ∏¨ÁöÑÂ†¥ÊôØ„ÄÇ

##### **MBDRes-U-Net: Multi-Scale Lightweight Brain Tumor Segmentation Network**
2411.01896v1 by Longfeng Shen, Yanqi Hou, Jiacong Chen, Liangjin Diao, Yaxi Duan

Accurate segmentation of brain tumors plays a key role in the diagnosis and
treatment of brain tumor diseases. It serves as a critical technology for
quantifying tumors and extracting their features. With the increasing
application of deep learning methods, the computational burden has become
progressively heavier. To achieve a lightweight model with good segmentation
performance, this study proposes the MBDRes-U-Net model using the
three-dimensional (3D) U-Net codec framework, which integrates multibranch
residual blocks and fused attention into the model. The computational burden of
the model is reduced by the branch strategy, which effectively uses the rich
local features in multimodal images and enhances the segmentation performance
of subtumor regions. Additionally, during encoding, an adaptive weighted
expansion convolution layer is introduced into the multi-branch residual block,
which enriches the feature expression and improves the segmentation accuracy of
the model. Experiments on the Brain Tumor Segmentation (BraTS) Challenge 2018
and 2019 datasets show that the architecture could maintain a high precision of
brain tumor segmentation while considerably reducing the calculation
overhead.Our code is released at
https://github.com/Huaibei-normal-university-cv-laboratory/mbdresunet

ÊëòË¶ÅÔºöÊ∫ñÁ¢∫ÂàÜÂâ≤ËÖ¶ËÖ´Áò§Âú®ËÖ¶ËÖ´Áò§ÁñæÁóÖÁöÑË®∫Êñ∑ÂíåÊ≤ªÁôÇ‰∏≠ÊâÆÊºîËëóÈóúÈçµÁöÑËßíËâ≤„ÄÇÂÆÉ‰ΩúÁÇ∫ÈáèÂåñËÖ´Áò§‰∏¶ËêÉÂèñÂÖ∂ÁâπÂæµÁöÑÈóúÈçµÊäÄË°ì„ÄÇÈö®ËëóÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÁöÑÊáâÁî®Êó•ÁõäÂ¢ûÂä†ÔºåÈÅãÁÆóË≤†Êìî‰πüËÆäÂæóË∂ä‰æÜË∂äÈáç„ÄÇÁÇ∫‰∫ÜÈÅîÊàêÂÖ∑ÂÇôËâØÂ•ΩÂàÜÂâ≤ÊïàËÉΩÁöÑËºïÈáèÁ¥öÊ®°ÂûãÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰ΩøÁî®‰∏âÁ∂≠ (3D) U-Net Á∑®Ëß£Á¢ºÂô®Êû∂ÊßãÁöÑ MBDRes-U-Net Ê®°ÂûãÔºåÂ∞áÂ§öÊîØË∑ØÊÆòÂ∑ÆÂçÄÂ°äÂíåËûçÂêàÊ≥®ÊÑèÂäõÊï¥ÂêàÂà∞Ê®°Âûã‰∏≠„ÄÇÊ®°ÂûãÁöÑÈÅãÁÆóË≤†ÊìîÈÄèÈÅéÂàÜÊîØÁ≠ñÁï•Èôç‰ΩéÔºåÊúâÊïàÂà©Áî®Â§öÊ®°ÊÖãÂΩ±ÂÉè‰∏≠ÁöÑË±êÂØåÂ±ÄÈÉ®ÁâπÂæµÔºå‰∏¶ÊèêÂçáÊ¨°ËÖ´Áò§ÂçÄÂüüÁöÑÂàÜÂâ≤ÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÂú®Á∑®Á¢ºÈÅéÁ®ã‰∏≠ÔºåËá™ÈÅ©ÊáâÂä†Ê¨äÊì¥ÂºµÂç∑Á©çÂ±§Ë¢´ÂºïÂÖ•Â§öÊîØË∑ØÊÆòÂ∑ÆÂçÄÂ°ä‰∏≠ÔºåË±êÂØåÁâπÂæµË°®ÈÅî‰∏¶ÊèêÂçáÊ®°ÂûãÁöÑÂàÜÂâ≤Ê∫ñÁ¢∫Â∫¶„ÄÇÂú®ËÖ¶ËÖ´Áò§ÂàÜÂâ≤ (BraTS) ÊåëÊà∞ 2018 Âíå 2019 Ë≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåÊ≠§Êû∂ÊßãÂèØ‰ª•Âú®Â§ßÂπÖÈôç‰ΩéÈÅãÁÆóÈñãÈä∑ÁöÑÂêåÊôÇÔºåÁ∂≠ÊåÅËÖ¶ËÖ´Áò§ÂàÜÂâ≤ÁöÑÈ´òÊ∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂ∑≤Êñº https://github.com/Huaibei-normal-university-cv-laboratory/mbdresunet ÁôºÂ∏É

##### **LiDAttack: Robust Black-box Attack on LiDAR-based Object Detection**
2411.01889v1 by Jinyin Chen, Danxin Liao, Sheng Xiang, Haibin Zheng

Since DNN is vulnerable to carefully crafted adversarial examples,
adversarial attack on LiDAR sensors have been extensively studied. We introduce
a robust black-box attack dubbed LiDAttack. It utilizes a genetic algorithm
with a simulated annealing strategy to strictly limit the location and number
of perturbation points, achieving a stealthy and effective attack. And it
simulates scanning deviations, allowing it to adapt to dynamic changes in real
world scenario variations. Extensive experiments are conducted on 3 datasets
(i.e., KITTI, nuScenes, and self-constructed data) with 3 dominant object
detection models (i.e., PointRCNN, PointPillar, and PV-RCNN++). The results
reveal the efficiency of the LiDAttack when targeting a wide range of object
detection models, with an attack success rate (ASR) up to 90%.

ÊëòË¶ÅÔºöÁî±Êñº DNN ÂÆπÊòìÂèóÂà∞Á≤æÂøÉË£Ω‰ΩúÁöÑÂ∞çÊäóÊÄßÁØÑ‰æãÂΩ±ÈüøÔºå
Â∞ç LiDAR ÊÑüÊ∏¨Âô®ÁöÑÂ∞çÊäóÊÄßÊîªÊìäÂ∑≤Âª£Ê≥õÁ†îÁ©∂„ÄÇÊàëÂÄë‰ªãÁ¥π
‰∏ÄÁ®ÆÂêçÁÇ∫ LiDAttack ÁöÑÂº∑ÂÅ•ÈªëÁõíÊîªÊìä„ÄÇÂÆÉÂà©Áî®ÂÖ∑ÊúâÊ®°Êì¨ÈÄÄÁÅ´Á≠ñÁï•ÁöÑÈÅ∫ÂÇ≥ÊºîÁÆóÊ≥ï‰æÜÂö¥Ê†ºÈôêÂà∂ÊìæÂãïÈªûÁöÑ‰ΩçÁΩÆÂíåÊï∏ÈáèÔºåÂæûËÄåÂØ¶ÁèæÈö±ËîΩ‰∏îÊúâÊïàÁöÑÊîªÊìä„ÄÇÂÆÉÊ®°Êì¨ÊéÉÊèèÂÅèÂ∑ÆÔºå‰ΩøÂÖ∂ËÉΩÂ§†ÈÅ©ÊáâÁèæÂØ¶‰∏ñÁïåÂ†¥ÊôØËÆäÂåñ‰∏≠ÁöÑÂãïÊÖãËÆäÂåñ„ÄÇÂú® 3 ÂÄãË≥áÊñôÈõÜÔºàÂç≥ KITTI„ÄÅnuScenes ÂíåËá™Âª∫Ë≥áÊñôÔºâ‰∏äÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºåÂÖ∂‰∏≠ÂåÖÂê´ 3 ÂÄã‰∏ªË¶ÅÁöÑÁâ©‰ª∂ÂÅµÊ∏¨Ê®°ÂûãÔºàÂç≥ PointRCNN„ÄÅPointPillar Âíå PV-RCNN++Ôºâ„ÄÇÁµêÊûúÈ°ØÁ§∫ LiDAttack Âú®ÈáùÂ∞çÂêÑÁ®ÆÁâ©‰ª∂ÂÅµÊ∏¨Ê®°ÂûãÊôÇÊïàÁéáÊ•µÈ´òÔºåÊîªÊìäÊàêÂäüÁéá (ASR) È´òÈÅî 90%„ÄÇ

##### **Can Language Models Learn to Skip Steps?**
2411.01855v1 by Tengxiao Liu, Qipeng Guo, Xiangkun Hu, Cheng Jiayang, Yue Zhang, Xipeng Qiu, Zheng Zhang

Trained on vast corpora of human language, language models demonstrate
emergent human-like reasoning abilities. Yet they are still far from true
intelligence, which opens up intriguing opportunities to explore the parallels
of humans and model behaviors. In this work, we study the ability to skip steps
in reasoning - a hallmark of human expertise developed through practice. Unlike
humans, who may skip steps to enhance efficiency or to reduce cognitive load,
models do not inherently possess such motivations to minimize reasoning steps.
To address this, we introduce a controlled framework that stimulates
step-skipping behavior by iteratively refining models to generate shorter and
accurate reasoning paths. Empirical results indicate that models can develop
the step skipping ability under our guidance. Moreover, after fine-tuning on
expanded datasets that include both complete and skipped reasoning sequences,
the models can not only resolve tasks with increased efficiency without
sacrificing accuracy, but also exhibit comparable and even enhanced
generalization capabilities in out-of-domain scenarios. Our work presents the
first exploration into human-like step-skipping ability and provides fresh
perspectives on how such cognitive abilities can benefit AI models.

ÊëòË¶ÅÔºöÂú®Êµ∑ÈáèÁöÑ‰∫∫Á±ªËØ≠Ë®ÄËØ≠ÊñôÂ∫ìËÆ≠ÁªÉ‰∏ãÔºåËØ≠Ë®ÄÊ®°ÂûãË°®Áé∞Âá∫
Êñ∞ÂÖ¥ÁöÑ‰∫∫Á±ªÊé®ÁêÜËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÂÆÉ‰ª¨‰ªçÁÑ∂ËøúÊú™ËææÂà∞ÁúüÊ≠£ÁöÑ
Êô∫ËÉΩÔºåËøô‰∏∫Êé¢Á¥¢‰∫∫Á±ªÂíåÊ®°ÂûãË°å‰∏∫ÁöÑÁõ∏‰ºº‰πãÂ§ÑÊèê‰æõ‰∫ÜÊúâË∂£ÁöÑ
Êú∫‰ºö„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨Á†îÁ©∂‰∫ÜË∑≥ËøáÊé®ÁêÜÊ≠•È™§ÁöÑËÉΩÂäõ
‚Äî‚ÄîËøôÊòØÈÄöËøáÂÆûË∑µÂüπÂÖªÁöÑ‰∫∫Á±ª‰∏ì‰∏öÁü•ËØÜÁöÑÊ†áÂøó„ÄÇ‰∏é‰∫∫Á±ª‰∏çÂêåÔºå
‰∫∫Á±ªÂèØËÉΩ‰ºöË∑≥ËøáÊ≠•È™§‰ª•ÊèêÈ´òÊïàÁéáÊàñÂáèÂ∞ëËÆ§Áü•Ë¥üËç∑Ôºå
Ê®°ÂûãÊú¨Ë∫´Âπ∂‰∏çÂÖ∑Â§áÊúÄÂ∞èÂåñÊé®ÁêÜÊ≠•È™§ÁöÑÂä®Êú∫„ÄÇ
‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™ÂèóÊéßÊ°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂ÈÄöËøá
Ëø≠‰ª£‰ºòÂåñÊ®°ÂûãÊù•ÁîüÊàêÊõ¥Áü≠‰∏îÂáÜÁ°ÆÁöÑÊé®ÁêÜË∑ØÂæÑÔºå‰ªéËÄåÊøÄÂèë
Ë∑≥Ê≠•Ë°å‰∏∫„ÄÇÂÆûËØÅÁªìÊûúË°®ÊòéÔºåÂú®Êàë‰ª¨ÁöÑÊåáÂØº‰∏ãÔºåÊ®°ÂûãÂèØ‰ª•ÂèëÂ±ï
Âá∫Ë∑≥Ê≠•ËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÂú®ÂæÆË∞ÉÂåÖÂê´ÂÆåÊï¥ÂíåË∑≥ËøáÊé®ÁêÜÂ∫èÂàóÁöÑ
Êâ©Â±ïÊï∞ÊçÆÈõÜÂêéÔºåËøô‰∫õÊ®°Âûã‰∏ç‰ªÖÂèØ‰ª•Âú®‰∏çÁâ∫Áâ≤ÂáÜÁ°ÆÊÄßÁöÑÊÉÖÂÜµ‰∏ã
‰ª•Êõ¥È´òÁöÑÊïàÁéáËß£ÂÜ≥‰ªªÂä°ÔºåËÄå‰∏îÂú®ÂüüÂ§ñÂú∫ÊôØ‰∏≠ËøòË°®Áé∞Âá∫ÂèØÊØîÁöÑ
ÁîöËá≥Â¢ûÂº∫ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÊàë‰ª¨ÁöÑÂ∑•‰ΩúÈ¶ñÊ¨°Êé¢Á¥¢‰∫ÜÁ±ª‰∫∫Ë∑≥Ê≠•ËÉΩÂäõÔºå
Âπ∂Êèê‰æõ‰∫ÜÂÖ≥‰∫éÊ≠§Á±ªËÆ§Áü•ËÉΩÂäõÂ¶Ç‰Ωï‰Ωø‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÂèóÁõäÁöÑÊñ∞
ËßÜËßí„ÄÇ

##### **Leveraging Label Semantics and Meta-Label Refinement for Multi-Label Question Classification**
2411.01841v1 by Shi Dong, Xiaobei Niu, Rui Zhong, Zhifeng Wang, Mingzhang Zuo

Accurate annotation of educational resources is critical in the rapidly
advancing field of online education due to the complexity and volume of
content. Existing classification methods face challenges with semantic overlap
and distribution imbalance of labels in the multi-label context, which impedes
effective personalized learning and resource recommendation. This paper
introduces RR2QC, a novel Retrieval Reranking method To multi-label Question
Classification by leveraging label semantics and meta-label refinement.
Firstly, RR2QC leverages semantic relationships within and across label groups
to enhance pre-training strategie in multi-label context. Next, a class center
learning task is introduced, integrating label texts into downstream training
to ensure questions consistently align with label semantics, retrieving the
most relevant label sequences. Finally, this method decomposes labels into
meta-labels and trains a meta-label classifier to rerank the retrieved label
sequences. In doing so, RR2QC enhances the understanding and prediction
capability of long-tail labels by learning from meta-labels frequently
appearing in other labels. Addtionally, a Math LLM is used to generate
solutions for questions, extracting latent information to further refine the
model's insights. Experimental results demonstrate that RR2QC outperforms
existing classification methods in Precision@k and F1 scores across multiple
educational datasets, establishing it as a potent enhancement for online
educational content utilization.

ÊëòË¶ÅÔºö<paragraph>Âú®Âø´ÈÄüÁôºÂ±ïÁöÑÁ∑ö‰∏äÊïôËÇ≤È†òÂüü‰∏≠ÔºåÊ∫ñÁ¢∫Ê®ôË®ªÊïôËÇ≤Ë≥áÊ∫êËá≥ÈóúÈáçË¶ÅÔºåÈÄôÊòØÂõ†ÁÇ∫ÂÖßÂÆπÁöÑË§áÈõúÊÄßÂíåÊï∏Èáè„ÄÇÁèæÊúâÁöÑÂàÜÈ°ûÊñπÊ≥ïÂú®Â§öÊ®ôÁ±§ÊÉÖÂ¢É‰∏≠Èù¢Ëá®Ë™ûÊÑèÈáçÁñäÂíåÊ®ôÁ±§ÂàÜ‰Ωà‰∏çÂπ≥Ë°°ÁöÑÊåëÊà∞ÔºåÈÄôÈòªÁ§ô‰∫ÜÊúâÊïàÁöÑÂÄã‰∫∫ÂåñÂ≠∏ÁøíÂíåË≥áÊ∫êÊé®Ëñ¶„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü RR2QCÔºå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊ™¢Á¥¢ÈáçÊñ∞ÊéíÂ∫èÊñπÊ≥ïÔºåÈÄöÈÅéÂà©Áî®Ê®ôÁ±§Ë™ûÊÑèÂíåÂÖÉÊ®ôÁ±§ÂÑ™Âåñ‰æÜÈÄ≤Ë°åÂ§öÊ®ôÁ±§ÂïèÈ°åÂàÜÈ°û„ÄÇÈ¶ñÂÖàÔºåRR2QC Âà©Áî®Ê®ôÁ±§ÁµÑÂÖßÈÉ®ÂíåÁµÑÈñìÁöÑË™ûÁæ©Èóú‰øÇ‰æÜÂ¢ûÂº∑Â§öÊ®ôÁ±§ÊÉÖÂ¢É‰∏≠ÁöÑÈ†êË®ìÁ∑¥Á≠ñÁï•„ÄÇÊé•‰∏ã‰æÜÔºåÂºïÂÖ•‰∫ÜÈ°ûÂà•‰∏≠ÂøÉÂ≠∏Áøí‰ªªÂãôÔºåÂ∞áÊ®ôÁ±§ÊñáÂ≠óÊï¥ÂêàÂà∞‰∏ãÊ∏∏Ë®ìÁ∑¥‰∏≠Ôºå‰ª•Á¢∫‰øùÂïèÈ°åÂßãÁµÇËàáÊ®ôÁ±§Ë™ûÊÑè‰øùÊåÅ‰∏ÄËá¥Ôºå‰∏¶Ê™¢Á¥¢ÊúÄÁõ∏ÈóúÁöÑÊ®ôÁ±§Â∫èÂàó„ÄÇÊúÄÂæåÔºåÊ≠§ÊñπÊ≥ïÂ∞áÊ®ôÁ±§ÂàÜËß£ÁÇ∫ÂÖÉÊ®ôÁ±§Ôºå‰∏¶Ë®ìÁ∑¥ÂÖÉÊ®ôÁ±§ÂàÜÈ°ûÂô®Â∞çÊ™¢Á¥¢Âà∞ÁöÑÊ®ôÁ±§Â∫èÂàóÈÄ≤Ë°åÈáçÊñ∞ÊéíÂ∫è„ÄÇÈÄôÊ®£‰∏Ä‰æÜÔºåRR2QC ÈÄöÈÅéÂ≠∏ÁøíÁ∂ìÂ∏∏Âá∫ÁèæÂú®ÂÖ∂‰ªñÊ®ôÁ±§‰∏≠ÁöÑÂÖÉÊ®ôÁ±§ÔºåÂ¢ûÂº∑‰∫ÜÂ∞çÈï∑Â∞æÊ®ôÁ±§ÁöÑÁêÜËß£ÂíåÈ†êÊ∏¨ËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÊï∏Â≠∏ LLM Áî®ÊñºÁÇ∫ÂïèÈ°åÁîüÊàêËß£Ê±∫ÊñπÊ°àÔºåÊèêÂèñÊΩõÂú®Ë≥áË®ä‰ª•ÈÄ≤‰∏ÄÊ≠•ÂÑ™ÂåñÊ®°ÂûãÁöÑË¶ãËß£„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåRR2QC Âú®Â§öÂÄãÊïôËÇ≤Ë≥áÊñôÈõÜ‰∏≠ÁöÑ Precision@k Âíå F1 ÂàÜÊï∏ÊñπÈù¢ÂÑ™ÊñºÁèæÊúâÁöÑÂàÜÈ°ûÊñπÊ≥ïÔºåÁ¢∫Á´ã‰∫ÜÂÖ∂‰ΩúÁÇ∫Á∑ö‰∏äÊïôËÇ≤ÂÖßÂÆπÂà©Áî®ÁöÑÂº∑Â§ßÂ¢ûÂº∑ÂäüËÉΩ„ÄÇ</paragraph>

##### **TriG-NER: Triplet-Grid Framework for Discontinuous Named Entity Recognition**
2411.01839v1 by Rina Carines Cabral, Soyeon Caren Han, Areej Alhassan, Riza Batista-Navarro, Goran Nenadic, Josiah Poon

Discontinuous Named Entity Recognition (DNER) presents a challenging problem
where entities may be scattered across multiple non-adjacent tokens, making
traditional sequence labelling approaches inadequate. Existing methods
predominantly rely on custom tagging schemes to handle these discontinuous
entities, resulting in models tightly coupled to specific tagging strategies
and lacking generalisability across diverse datasets. To address these
challenges, we propose TriG-NER, a novel Triplet-Grid Framework that introduces
a generalisable approach to learning robust token-level representations for
discontinuous entity extraction. Our framework applies triplet loss at the
token level, where similarity is defined by word pairs existing within the same
entity, effectively pulling together similar and pushing apart dissimilar ones.
This approach enhances entity boundary detection and reduces the dependency on
specific tagging schemes by focusing on word-pair relationships within a
flexible grid structure. We evaluate TriG-NER on three benchmark DNER datasets
and demonstrate significant improvements over existing grid-based
architectures. These results underscore our framework's effectiveness in
capturing complex entity structures and its adaptability to various tagging
schemes, setting a new benchmark for discontinuous entity extraction.

ÊëòË¶ÅÔºö‰∏çÈÄ£Á∫åÂëΩÂêçÂØ¶È´îËæ®Ë≠ò (DNER) ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÂïèÈ°åÔºåÂÖ∂‰∏≠ÂØ¶È´îÂèØËÉΩÊï£Â∏ÉÂú®Â§öÂÄãÈùûÁõ∏ÈÑ∞ÁöÑÊ®ôË®ò‰∏≠ÔºåÂ∞éËá¥ÂÇ≥Áµ±ÁöÑÂ∫èÂàóÊ®ôÁ±§ÊñπÊ≥ï‰∏çË∂≥„ÄÇÁèæÊúâÊñπÊ≥ï‰∏ªË¶Å‰æùË≥¥ÊñºËá™Ë®ÇÊ®ôË®òÊñπÊ°à‰æÜËôïÁêÜÈÄô‰∫õ‰∏çÈÄ£Á∫åÁöÑÂØ¶È´îÔºåÂ∞éËá¥Ê®°ÂûãËàáÁâπÂÆöÊ®ôË®òÁ≠ñÁï•Á∑äÂØÜÁµêÂêàÔºå‰∏¶‰∏îÁº∫‰πèË∑®‰∏çÂêåË≥áÊñôÈõÜÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü TriG-NERÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑ‰∏âÂÖÉÁµÑÁ∂≤Ê†ºÊ°ÜÊû∂ÔºåÂÆÉÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÂèØÊ≥õÂåñÁöÑÂ≠∏ÁøíÊñπÊ≥ïÔºåÁî®ÊñºÁÇ∫‰∏çÈÄ£Á∫åÂØ¶È´îËêÉÂèñÁî¢ÁîüÂº∑ÂÅ•ÁöÑÊ®ôË®òÂ±§Á¥öË°®Á§∫„ÄÇÊàëÂÄëÁöÑÊ°ÜÊû∂Âú®Ê®ôË®òÂ±§Á¥öÂ•óÁî®‰∏âÂÖÉÁµÑÊêçÂ§±ÔºåÂÖ∂‰∏≠Áõ∏‰ººÊÄßÁî±Â≠òÂú®ÊñºÂêå‰∏ÄÂÄãÂØ¶È´îÂÖßÁöÑÂ≠óË©ûÂ∞çÂÆöÁæ©ÔºåÊúâÊïàÂú∞Â∞áÁõ∏‰ººËÄÖÊãâÂú®‰∏ÄËµ∑Ôºå‰∏¶Â∞á‰∏çÁõ∏‰ººÁöÑËÄÖÊé®Èñã„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÈÄèÈÅéÂ∞àÊ≥®ÊñºÈùàÊ¥ªÁ∂≤Ê†ºÁµêÊßã‰∏≠Â≠óË©ûÂ∞çÁöÑÈóú‰øÇÔºåÂ¢ûÂº∑‰∫ÜÂØ¶È´îÈÇäÁïåÂÅµÊ∏¨Ôºå‰∏¶Ê∏õÂ∞ë‰∫ÜÂ∞çÁâπÂÆöÊ®ôË®òÊñπÊ°àÁöÑ‰æùË≥¥ÊÄß„ÄÇÊàëÂÄëÂú®‰∏âÂÄãÂü∫Ê∫ñ DNER Ë≥áÊñôÈõÜ‰∏äË©ï‰º∞ TriG-NERÔºå‰∏¶Â±ïÁ§∫Âá∫ÊØîÁèæÊúâÁöÑÂü∫ÊñºÁ∂≤Ê†ºÁöÑÊû∂ÊßãÊúâÈ°ØËëóÁöÑÊîπÈÄ≤„ÄÇÈÄô‰∫õÁµêÊûúÂº∑Ë™ø‰∫ÜÊàëÂÄëÁöÑÊ°ÜÊû∂Âú®Êì∑ÂèñË§áÈõúÂØ¶È´îÁµêÊßãÂíåÈÅ©ÊáâÂêÑÁ®ÆÊ®ôË®òÊñπÊ°àÊñπÈù¢ÁöÑÊúâÊïàÊÄßÔºåÁÇ∫‰∏çÈÄ£Á∫åÂØ¶È´îËêÉÂèñË®≠ÂÆö‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂü∫Ê∫ñ„ÄÇ

##### **Align-SLM: Textless Spoken Language Models with Reinforcement Learning from AI Feedback**
2411.01834v1 by Guan-Ting Lin, Prashanth Gurunath Shivakumar, Aditya Gourav, Yile Gu, Ankur Gandhe, Hung-yi Lee, Ivan Bulyko

While textless Spoken Language Models (SLMs) have shown potential in
end-to-end speech-to-speech modeling, they still lag behind text-based Large
Language Models (LLMs) in terms of semantic coherence and relevance. This work
introduces the Align-SLM framework, which leverages preference optimization
inspired by Reinforcement Learning with AI Feedback (RLAIF) to enhance the
semantic understanding of SLMs. Our approach generates multiple speech
continuations from a given prompt and uses semantic metrics to create
preference data for Direct Preference Optimization (DPO). We evaluate the
framework using ZeroSpeech 2021 benchmarks for lexical and syntactic modeling,
the spoken version of the StoryCloze dataset for semantic coherence, and other
speech generation metrics, including the GPT4-o score and human evaluation.
Experimental results show that our method achieves state-of-the-art performance
for SLMs on most benchmarks, highlighting the importance of preference
optimization to improve the semantics of SLMs.

ÊëòË¶ÅÔºöÂÑòÁÆ°ÁÑ°ÊñáÂ≠óÁöÑÂè£Ë™™Ë™ûË®ÄÊ®°Âûã (SLM) Â∑≤Âú®Á´ØÂ∞çÁ´ØÂè£Ë™ûËΩâÊèõÊ®°Âûã‰∏≠Â±ïÁèæÊΩõÂäõÔºåÂÆÉÂÄëÂú®Ë™ûÊÑèÈÄ£Ë≤´ÊÄßÂíåÁõ∏ÈóúÊÄßÊñπÈù¢‰ªçËêΩÂæåÊñºÂü∫ÊñºÊñáÂ≠óÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)„ÄÇÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫Ü Align-SLM Êû∂ÊßãÔºåÂÆÉÂà©Áî®‰∫ÜÂèóÂº∑ÂåñÂ≠∏ÁøíÂíå AI ÂõûÈ•ã (RLAIF) ÂïüÁôºÁöÑÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÔºå‰ª•Â¢ûÂº∑ SLM ÁöÑË™ûÊÑèÁêÜËß£„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊúÉÂæûÁµ¶ÂÆöÁöÑÊèêÁ§∫Áî¢ÁîüÂ§öÂÄãË™ûÈü≥Âª∂Á∫åÔºå‰∏¶‰ΩøÁî®Ë™ûÊÑèÊåáÊ®ôÁÇ∫Áõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (DPO) Âª∫Á´ãÂÅèÂ•ΩË≥áÊñô„ÄÇÊàëÂÄë‰ΩøÁî® ZeroSpeech 2021 Âü∫Ê∫ñÂ∞çÊû∂ÊßãÈÄ≤Ë°åË©ï‰º∞ÔºåÁî®ÊñºË©ûÂΩôÂíåÂè•Ê≥ïÂª∫Ê®°ÔºåStoryCloze Ë≥áÊñôÈõÜÁöÑÂè£Ë™ûÁâàÊú¨Áî®ÊñºË™ûÊÑèÈÄ£Ë≤´ÊÄßÔºå‰ª•ÂèäÂÖ∂‰ªñË™ûÈü≥Áî¢ÁîüÊåáÊ®ôÔºåÂåÖÊã¨ GPT4-o ÂàÜÊï∏Âíå‰∫∫È°ûË©ï‰º∞„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®Â§öÊï∏Âü∫Ê∫ñ‰∏äÈÅîÂà∞‰∫Ü SLM ÁöÑÊúÄÊñ∞ÊïàËÉΩÔºåÁ™ÅÈ°Ø‰∫ÜÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÂ∞çÊñºÊîπÂñÑ SLM Ë™ûÊÑèÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **DiffuMask-Editor: A Novel Paradigm of Integration Between the Segmentation Diffusion Model and Image Editing to Improve Segmentation Ability**
2411.01819v1 by Bo Gao, Fangxu Xing, Daniel Tang

Semantic segmentation models, like mask2former, often demand a substantial
amount of manually annotated data, which is time-consuming and inefficient to
acquire. Leveraging state-of-the-art text-to-image models like Midjourney and
Stable Diffusion has emerged as an effective strategy for automatically
generating synthetic data instead of human annotations. However, prior
approaches have been constrained to synthesizing single-instance images due to
the instability inherent in generating multiple instances with Stable
Diffusion. To expand the domains and diversity of synthetic datasets, this
paper introduces a novel paradigm named DiffuMask-Editor, which combines the
Diffusion Model for Segmentation with Image Editing. By integrating multiple
objects into images using Text2Image models, our method facilitates the
creation of more realistic datasets that closely resemble open-world settings
while simultaneously generating accurate masks. Our approach significantly
reduces the laborious effort associated with manual annotation while ensuring
precise mask generation. Experimental results demonstrate that synthetic data
generated by DiffuMask-Editor enable segmentation methods to achieve superior
performance compared to real data. Particularly in zero-shot backgrounds,
DiffuMask-Editor achieves new state-of-the-art results on Unseen classes of VOC
2012. The code and models will be publicly available soon.

ÊëòË¶ÅÔºöË™ûÁæ©ÂàÜÂâ≤Ê®°ÂûãÔºàÂ¶Ç mask2formerÔºâÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáè‰∫∫Â∑•Ê®ôË®ªË≥áÊñôÔºåËÄåÂèñÂæóÈÄô‰∫õË≥áÊñôËÄóÊôÇ‰∏î‰ΩéÊïàÁéá„ÄÇÂñÑÁî®ÊúÄÂÖàÈÄ≤ÁöÑÊñáÂ≠óËΩâÂúñÂÉèÊ®°ÂûãÔºàÂ¶Ç Midjourney Âíå Stable DiffusionÔºâÂ∑≤ÊàêÁÇ∫Ëá™ÂãïÁî¢ÁîüÂêàÊàêË≥áÊñôÔºàËÄåÈùû‰∫∫Â∑•Ê®ôË®ªÔºâÁöÑÊúâÊïàÁ≠ñÁï•„ÄÇÁÑ∂ËÄåÔºåÂÖàÂâçÁöÑÂÅöÊ≥ïÂèóÈôêÊñºÂêàÊàêÂñÆ‰∏ÄÂØ¶‰æãÂúñÂÉèÔºåÂõ†ÁÇ∫Âú® Stable Diffusion ‰∏≠Áî¢ÁîüÂ§öÂÄãÂØ¶‰æãÊôÇÊúÉÁî¢Áîü‰∏çÁ©©ÂÆöÊÄß„ÄÇÁÇ∫‰∫ÜÊì¥Â±ïÂêàÊàêË≥áÊñôÈõÜÁöÑÈ†òÂüüÂíåÂ§öÊ®£ÊÄßÔºåÊú¨ÊñáÊèêÂá∫‰∏ÄÂÄãÂêçÁÇ∫ DiffuMask-Editor ÁöÑÊñ∞ÁØÑ‰æãÔºåÂÆÉÁµêÂêà‰∫ÜÁî®ÊñºÂàÜÂâ≤ÁöÑÊì¥Êï£Ê®°ÂûãËàáÂΩ±ÂÉèÁ∑®ËºØ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÈÄèÈÅé‰ΩøÁî® Text2Image Ê®°ÂûãÂ∞áÂ§öÂÄãÁâ©‰ª∂Êï¥ÂêàÂà∞ÂúñÂÉè‰∏≠ÔºåÊúâÂä©ÊñºÂª∫Á´ãÊõ¥ÈÄºÁúüÁöÑË≥áÊñôÈõÜÔºåÈÄô‰∫õË≥áÊñôÈõÜËàáÈñãÊîæ‰∏ñÁïåË®≠ÂÆöÈùûÂ∏∏Áõ∏‰ººÔºåÂêåÊôÇÁî¢ÁîüÁ≤æÁ¢∫ÁöÑÈÅÆÁΩ©„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂ§ßÂπÖÊ∏õÂ∞ë‰∫ÜËàá‰∫∫Â∑•Ê®ôË®ªÁõ∏ÈóúÁöÑÁπÅÁë£Â∑•‰ΩúÔºåÂêåÊôÇÁ¢∫‰øùÁî¢ÁîüÁ≤æÁ¢∫ÁöÑÈÅÆÁΩ©„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÁî± DiffuMask-Editor Áî¢ÁîüÁöÑÂêàÊàêË≥áÊñôËÆìÂàÜÂâ≤ÊñπÊ≥ïËÉΩÈÅîÊàêÊØîÁúüÂØ¶Ë≥áÊñôÊõ¥Â•ΩÁöÑÊïàËÉΩ„ÄÇÁâπÂà•ÊòØÂú®Èõ∂Ê¨°ËÉåÊôØ‰∏≠ÔºåDiffuMask-Editor Âú® VOC 2012 ÁöÑÊú™Ë¶ãÈ°ûÂà•‰∏≠ÈÅîÊàêÊñ∞ÁöÑÊúÄÂÖàÈÄ≤ÁµêÊûú„ÄÇÁ®ãÂºèÁ¢ºÂíåÊ®°ÂûãÂ∞áÂæàÂø´ÂÖ¨Èñã„ÄÇ

##### **Can Language Models Enable In-Context Database?**
2411.01807v1 by Yu Pan, Hongfeng Yu, Tianjiao Zhao, Jianxin Sun

Large language models (LLMs) are emerging as few-shot learners capable of
handling a variety of tasks, including comprehension, planning, reasoning,
question answering, arithmetic calculations, and more. At the core of these
capabilities is LLMs' proficiency in representing and understanding structural
or semi-structural data, such as tables and graphs. Numerous studies have
demonstrated that reasoning on tabular data or graphs is not only feasible for
LLMs but also gives a promising research direction which treats these data as
in-context data. The lightweight and human readable characteristics of
in-context database can potentially make it an alternative for the traditional
database in typical RAG (Retrieval Augmented Generation) settings. However,
almost all current work focuses on static in-context data, which does not allow
dynamic update. In this paper, to enable dynamic database update, delta
encoding of database is proposed. We explore how data stored in traditional
RDBMS can be encoded as in-context text and evaluate LLMs' proficiency for CRUD
(Create, Read, Update and Delete) operations on in-context databases. A
benchmark named InConDB is presented and extensive experiments are conducted to
show the performance of different language models in enabling in-context
database by varying the database encoding method, prompting method, operation
type and input data distribution, revealing both the proficiency and
limitations.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄêÊº∏ÊàêÁÇ∫ÂÉÖÈúÄÂ∞ëÈáèÁØÑ‰æãÂ∞±ËÉΩËôïÁêÜÂêÑÁ®Æ‰ªªÂãôÁöÑÂ≠∏ÁøíËÄÖÔºåÂåÖÊã¨ÁêÜËß£„ÄÅË¶èÂäÉ„ÄÅÊé®ÁêÜ„ÄÅÂïèÁ≠î„ÄÅÁÆóË°ìË®àÁÆóÁ≠â„ÄÇÈÄô‰∫õËÉΩÂäõÁöÑÊ†∏ÂøÉÊòØ LLM Âú®Ë°®Á§∫ÂíåÁêÜËß£ÁµêÊßãÂåñÊàñÂçäÁµêÊßãÂåñË≥áÊñôÔºà‰æãÂ¶ÇË°®Ê†ºÂíåÂúñÂΩ¢ÔºâÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇË®±Â§öÁ†îÁ©∂Â∑≤Ë≠âÊòéÔºåLLM ‰∏çÂÉÖÂèØ‰ª•Êé®Ë´ñË°®Ê†ºË≥áÊñôÊàñÂúñÂΩ¢ÔºåÈÇÑÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÊôØÁöÑÁ†îÁ©∂ÊñπÂêëÔºåÂ∞áÈÄô‰∫õË≥áÊñôË¶ñÁÇ∫Ë™ûÂ¢ÉË≥áÊñô„ÄÇË™ûÂ¢ÉË≥áÊñôÂ∫´ÁöÑËºïÈáèÁ¥öÂíå‰∫∫È°ûÂèØËÆÄÂèñÁâπÊÄßÊúâÂèØËÉΩ‰ΩøÂÖ∂ÊàêÁÇ∫ÂÖ∏Âûã RAGÔºàÊ™¢Á¥¢Êì¥ÂÖÖÁîüÊàêÔºâË®≠ÂÆö‰∏≠ÂÇ≥Áµ±Ë≥áÊñôÂ∫´ÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇÁÑ∂ËÄåÔºåÂπæ‰πéÊâÄÊúâÁõÆÂâçÁöÑÂ∑•‰ΩúÈÉΩÂ∞àÊ≥®ÊñºÈùúÊÖãË™ûÂ¢ÉË≥áÊñôÔºåÈÄô‰∏çÂÖÅË®±ÂãïÊÖãÊõ¥Êñ∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÁÇ∫‰∫ÜÂØ¶ÁèæÂãïÊÖãË≥áÊñôÂ∫´Êõ¥Êñ∞ÔºåÊèêÂá∫‰∫ÜË≥áÊñôÂ∫´ÁöÑ delta Á∑®Á¢º„ÄÇÊàëÂÄëÊé¢Ë®é‰∫ÜÂ¶Ç‰ΩïÂ∞áÂÑ≤Â≠òÂú®ÂÇ≥Áµ± RDBMS ‰∏≠ÁöÑË≥áÊñôÁ∑®Á¢ºÁÇ∫Ë™ûÂ¢ÉÊñáÂ≠óÔºå‰∏¶Ë©ï‰º∞ LLM Âú®Ë™ûÂ¢ÉË≥áÊñôÂ∫´‰∏äÈÄ≤Ë°å CRUDÔºàÂª∫Á´ã„ÄÅËÆÄÂèñ„ÄÅÊõ¥Êñ∞ÂíåÂà™Èô§ÔºâÊìç‰ΩúÁöÑËÉΩÂäõ„ÄÇÊèêÂá∫‰∫ÜÂêçÁÇ∫ InConDB ÁöÑÂü∫Ê∫ñÔºå‰∏¶ÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºå‰ª•È°ØÁ§∫‰∏çÂêåË™ûË®ÄÊ®°ÂûãÂú®ÈÄöÈÅéÊîπËÆäË≥áÊñôÂ∫´Á∑®Á¢ºÊñπÊ≥ï„ÄÅÊèêÁ§∫ÊñπÊ≥ï„ÄÅÊìç‰ΩúÈ°ûÂûãÂíåËº∏ÂÖ•Ë≥áÊñôÂàÜ‰Ωà‰æÜÂïüÁî®Ë™ûÂ¢ÉË≥áÊñôÂ∫´ÊñπÈù¢ÁöÑÊïàËÉΩÔºåÊè≠Á§∫‰∫ÜËÉΩÂäõÂíåÈôêÂà∂„ÄÇ

##### **Constrained Human-AI Cooperation: An Inclusive Embodied Social Intelligence Challenge**
2411.01796v1 by Weihua Du, Qiushi Lyu, Jiaming Shan, Zhenting Qi, Hongxin Zhang, Sunli Chen, Andi Peng, Tianmin Shu, Kwonjoon Lee, Behzad Dariush, Chuang Gan

We introduce Constrained Human-AI Cooperation (CHAIC), an inclusive embodied
social intelligence challenge designed to test social perception and
cooperation in embodied agents. In CHAIC, the goal is for an embodied agent
equipped with egocentric observations to assist a human who may be operating
under physical constraints -- e.g., unable to reach high places or confined to
a wheelchair -- in performing common household or outdoor tasks as efficiently
as possible. To achieve this, a successful helper must: (1) infer the human's
intents and constraints by following the human and observing their behaviors
(social perception), and (2) make a cooperative plan tailored to the human
partner to solve the task as quickly as possible, working together as a team
(cooperative planning). To benchmark this challenge, we create four new agents
with real physical constraints and eight long-horizon tasks featuring both
indoor and outdoor scenes with various constraints, emergency events, and
potential risks. We benchmark planning- and learning-based baselines on the
challenge and introduce a new method that leverages large language models and
behavior modeling. Empirical evaluations demonstrate the effectiveness of our
benchmark in enabling systematic assessment of key aspects of machine social
intelligence. Our benchmark and code are publicly available at this URL:
https://github.com/UMass-Foundation-Model/CHAIC.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫ÂèóÈôê‰∫∫È°û‰∫∫Â∑•Êô∫ÊÖßÂêà‰Ωú (CHAIC)ÔºåÈÄôÊòØ‰∏ÄÈ†ÖÂåÖÂÆπÊÄßÁöÑÂÖ∑Ë∫´Á§æ‰∫§Êô∫ÊÖßÊåëÊà∞ÔºåÊó®Âú®Ê∏¨Ë©¶ÂÖ∑Ë∫´‰ª£ÁêÜÁöÑÁ§æ‰∫§Ë™çÁü•ÂíåÂêà‰Ωú„ÄÇÂú® CHAIC ‰∏≠ÔºåÁõÆÊ®ôÊòØËÆìÂÖ∑ÂÇôËá™Êàë‰∏≠ÂøÉËßÄÂØüËÉΩÂäõÁöÑÂÖ∑Ë∫´‰ª£ÁêÜÂçîÂä©ÂèØËÉΩÂú®Ë∫´È´îÈôêÂà∂‰∏ãÊìç‰ΩúÁöÑ‰∫∫È°û‚Äî‚Äî‰æãÂ¶ÇÔºåÁÑ°Ê≥ïËß∏ÂèäÈ´òËôïÊàñÂè™ËÉΩÂùêÂú®Ëº™Ê§Ö‰∏ä‚Äî‚ÄîÁõ°ÂèØËÉΩÊúâÊïàÂú∞Âü∑Ë°åÂ∏∏Ë¶ãÁöÑÂÆ∂ÂãôÊàñÊà∂Â§ñ‰ªªÂãô„ÄÇÁÇ∫ÈÅîÊàêÊ≠§ÁõÆÊ®ôÔºåÊàêÂäüÁöÑÂä©ÊâãÂøÖÈ†àÔºö(1) ÈÄöÈÅéËøΩËπ§‰∫∫È°û‰∏¶ËßÄÂØüÂÖ∂Ë°åÁÇ∫‰æÜÊé®Êñ∑‰∫∫È°ûÁöÑÊÑèÂúñÂíåÈôêÂà∂ÔºàÁ§æ‰∫§Ë™çÁü•ÔºâÔºå‰ª•Âèä (2) Âà∂ÂÆöÈÅ©Âêà‰∫∫È°ûÂ§•‰º¥ÁöÑÂêà‰ΩúË®àÁï´Ôºå‰ª•Áõ°ÂèØËÉΩÂø´ÈÄüÂú∞Ëß£Ê±∫‰ªªÂãôÔºå‰∏¶‰ΩúÁÇ∫‰∏ÄÂÄãÂúòÈöäÂêà‰ΩúÔºàÂêà‰ΩúË®àÁï´Ôºâ„ÄÇÁÇ∫‰∫ÜÂ∞çÊ≠§ÊåëÊà∞ÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶ÔºåÊàëÂÄë‰ΩøÁî®ÂØ¶ÈöõË∫´È´îÈôêÂà∂ÂâµÂª∫‰∫ÜÂõõÂÄãÊñ∞‰ª£ÁêÜÔºå‰ª•ÂèäÂÖ´È†ÖÈï∑ÊôÇÁ®ã‰ªªÂãôÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂÖ∑ÊúâÂêÑÁ®ÆÈôêÂà∂„ÄÅÁ∑äÊÄ•‰∫ã‰ª∂ÂíåÊΩõÂú®È¢®Èö™ÁöÑÂÆ§ÂÖßÂíåÂÆ§Â§ñÂ†¥ÊôØ„ÄÇÊàëÂÄëÂú®ÊåëÊà∞‰∏≠Â∞çÂü∫ÊñºË®àÁï´ÂíåÂ≠∏ÁøíÁöÑÂü∫Ê∫ñÁ∑öÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶Ôºå‰∏¶ÂºïÂÖ•‰∏ÄÁ®ÆÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÂíåË°åÁÇ∫Âª∫Ê®°ÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÂØ¶Ë≠âË©ï‰º∞Ë≠âÊòé‰∫ÜÊàëÂÄëÁöÑÂü∫Ê∫ñÂú®ÂïüÁî®Â∞çÊ©üÂô®Á§æ‰∫§Êô∫ÊÖßÈóúÈçµÊñπÈù¢ÁöÑÁ≥ªÁµ±Ë©ï‰º∞ÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÁöÑÂü∫Ê∫ñÂíåÁ®ãÂºèÁ¢ºÂú®Ê≠§ URL ÂÖ¨ÈñãÊèê‰æõÔºöhttps://github.com/UMass-Foundation-Model/CHAIC„ÄÇ

##### **Thinking Forward and Backward: Effective Backward Planning with Large Language Models**
2411.01790v1 by Allen Z. Ren, Brian Ichter, Anirudha Majumdar

Large language models (LLMs) have exhibited remarkable reasoning and planning
capabilities. Most prior work in this area has used LLMs to reason through
steps from an initial to a goal state or criterion, thereby effectively
reasoning in a forward direction. Nonetheless, many planning problems exhibit
an inherent asymmetry such that planning backward from the goal is
significantly easier -- for example, if there are bottlenecks close to the
goal. We take inspiration from this observation and demonstrate that this bias
holds for LLM planning as well: planning performance in one direction
correlates with the planning complexity of the problem in that direction.
However, our experiments also reveal systematic biases which lead to poor
planning in the backward direction. With this knowledge, we propose a backward
planning algorithm for LLMs that first flips the problem and then plans forward
in the flipped problem. This helps avoid the backward bias, generate more
diverse candidate plans, and exploit asymmetries between the forward and
backward directions in planning problems -- we find that combining planning in
both directions with self-verification improves the overall planning success
rates by 4-24% in three planning domains.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁèæÂá∫ÂçìË∂äÁöÑÊé®ÁêÜÂíåË¶èÂäÉËÉΩÂäõ„ÄÇÈÄôÂÄãÈ†òÂüü‰∏≠Â§ßÂ§öÊï∏ÂÖàÂâçÁöÑÁ†îÁ©∂ÈÉΩ‰ΩøÁî® LLM Êé®ÁêÜÂæûÂàùÂßãÁãÄÊÖãÂà∞ÁõÆÊ®ôÁãÄÊÖãÊàñÊ∫ñÂâáÁöÑÊ≠•È©üÔºåÂæûËÄåÊúâÊïàÂú∞ÂêëÂâçÊé®ÁêÜ„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåË®±Â§öË¶èÂäÉÂïèÈ°åÈÉΩÂ±ïÁèæÂá∫Âõ∫ÊúâÁöÑ‰∏çÂ∞çÁ®±ÊÄßÔºåÂæûÁõÆÊ®ôÂêëÂæåË¶èÂäÉÈ°ØËëóÂÆπÊòìË®±Â§öÔºå‰æãÂ¶ÇÔºåÂ¶ÇÊûúÊé•ËøëÁõÆÊ®ôÊôÇÂá∫ÁèæÁì∂È†∏„ÄÇÊàëÂÄëÂæûÈÄôÂÄãËßÄÂØü‰∏≠Áç≤ÂæóÈùàÊÑüÔºå‰∏¶Ë≠âÊòéÈÄôÁ®ÆÂÅèÂ∑Æ‰πüÈÅ©Áî®Êñº LLM Ë¶èÂäÉÔºöÂñÆ‰∏ÄÊñπÂêëÁöÑË¶èÂäÉÊïàËÉΩËàáË©≤ÊñπÂêëÂïèÈ°åÁöÑË¶èÂäÉË§áÈõúÂ∫¶Áõ∏Èóú„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÁöÑÂØ¶È©ó‰πüÊè≠Á§∫‰∫ÜÂ∞éËá¥ÂêëÂæåË¶èÂäÉ‰∏ç‰Ω≥ÁöÑÁ≥ªÁµ±ÂÅèÂ∑Æ„ÄÇÊúâ‰∫ÜÈÄôÂÄãÁü•Ë≠òÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®Æ LLM ÂêëÂæåË¶èÂäÉÊºîÁÆóÊ≥ïÔºåÂÆÉÈ¶ñÂÖàÁøªËΩâÂïèÈ°åÔºåÁÑ∂ÂæåÂú®ÁøªËΩâÁöÑÂïèÈ°å‰∏≠ÂêëÂâçË¶èÂäÉ„ÄÇÈÄôÊúâÂä©ÊñºÈÅøÂÖçÂêëÂæåÂÅèÂ∑ÆÔºåÁî¢ÁîüÊõ¥Â§öÊ®£ÂåñÁöÑÂÄôÈÅ∏Ë¶èÂäÉÔºå‰∏¶Âà©Áî®Ë¶èÂäÉÂïèÈ°å‰∏≠ÂêëÂâçÂíåÂêëÂæåÊñπÂêë‰πãÈñìÁöÑ‰∏çÂ∞çÁ®±ÊÄßÔºåÊàëÂÄëÁôºÁèæÂ∞áÈõôÂêëË¶èÂäÉËàáËá™ÊàëÈ©óË≠âÁõ∏ÁµêÂêàÔºåÂú®‰∏âÂÄãË¶èÂäÉÈ†òÂüü‰∏≠Â∞áÊï¥È´îË¶èÂäÉÊàêÂäüÁéáÊèêÈ´ò‰∫Ü 4-24%„ÄÇ

##### **Context Parallelism for Scalable Million-Token Inference**
2411.01783v1 by Amy, Yang, Jingyi Yang, Aya Ibrahim, Xinfeng Xie, Bangsheng Tang, Grigory Sizov, Jongsoo Park, Jianyu Huang

We present context parallelism for long-context large language model
inference, which achieves near-linear scaling for long-context prefill latency
with up to 128 H100 GPUs across 16 nodes. Particularly, our method achieves 1M
context prefill with Llama3 405B model in 77s (93% parallelization efficiency,
63% FLOPS utilization) and 128K context prefill in 3.8s. We develop two
lossless exact ring attention variants: pass-KV and pass-Q to cover a wide
range of use cases with the state-of-the-art performance: full prefill,
persistent KV prefill and decode. Benchmarks on H100 GPU hosts inter-connected
with RDMA and TCP both show similar scalability for long-context prefill,
demonstrating that our method scales well using common commercial data center
with medium-to-low inter-host bandwidth.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫‰∫ÜÁî®ÊñºÈï∑Ë™ûÂ¢ÉÂ§ßË™ûË®ÄÊ®°ÂûãÊé®Ë´ñÁöÑË™ûÂ¢ÉÂπ≥Ë°åÔºåÂú® 16 ÂÄãÁØÄÈªû‰∏ä‰ΩøÁî®Â§öÈÅî 128 ÂÄã H100 GPUÔºåÂèØÂØ¶ÁèæÈï∑Ë™ûÂ¢ÉÈ†êÂ°´ËºâÂª∂ÈÅ≤ÁöÑËøëÁ∑öÊÄßÁ∏ÆÊîæ„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú® 77 ÁßíÂÖß‰ΩøÁî® Llama3 405B Ê®°ÂûãÂØ¶Áèæ‰∫Ü 100 Ëê¨Ë™ûÂ¢ÉÈ†êÂ°´ËºâÔºà93% ‰∏¶Ë°åÊïàÁéáÔºå63% FLOPS Âà©Áî®ÁéáÔºâÂíåÂú® 3.8 ÁßíÂÖßÂØ¶Áèæ‰∫Ü 128K Ë™ûÂ¢ÉÈ†êÂ°´Ëºâ„ÄÇÊàëÂÄëÈñãÁôº‰∫ÜÂÖ©ÂÄãÁÑ°ÊêçËÄóÁ≤æÁ¢∫Áí∞Ê≥®ÊÑèËÆäÈ´îÔºöpass-KV Âíå pass-QÔºå‰ª•Ê∂µËìãÂª£Ê≥õÁöÑÁî®‰æãÔºå‰∏¶ÂÖ∑ÊúâÊúÄÂÖàÈÄ≤ÁöÑÊÄßËÉΩÔºöÂÆåÂÖ®È†êÂ°´Ëºâ„ÄÅÊåÅÁ∫å KV È†êÂ°´ËºâÂíåËß£Á¢º„ÄÇÂú®Ëàá RDMA Âíå TCP ‰∫íÈÄ£ÁöÑ H100 GPU ‰∏ªÊ©ü‰∏äÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶ÈÉΩÈ°ØÁ§∫‰∫ÜÈï∑Ë™ûÂ¢ÉÈ†êÂ°´ËºâÁöÑÈ°û‰ººÂèØÊì¥Â±ïÊÄßÔºåË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊ®°Âûã‰ΩøÁî®ÂÖ∑Êúâ‰∏≠‰Ωé‰∏ªÊ©üÈñìÈ†ªÂØ¨ÁöÑÂ∏∏Ë¶ãÂïÜÁî®Êï∏Êìö‰∏≠ÂøÉÊôÇÂèØÂæàÂ•ΩÂú∞Êì¥Â±ï„ÄÇ

##### **Eurekaverse: Environment Curriculum Generation via Large Language Models**
2411.01775v1 by William Liang, Sam Wang, Hung-Ju Wang, Osbert Bastani, Dinesh Jayaraman, Yecheng Jason Ma

Recent work has demonstrated that a promising strategy for teaching robots a
wide range of complex skills is by training them on a curriculum of
progressively more challenging environments. However, developing an effective
curriculum of environment distributions currently requires significant
expertise, which must be repeated for every new domain. Our key insight is that
environments are often naturally represented as code. Thus, we probe whether
effective environment curriculum design can be achieved and automated via code
generation by large language models (LLM). In this paper, we introduce
Eurekaverse, an unsupervised environment design algorithm that uses LLMs to
sample progressively more challenging, diverse, and learnable environments for
skill training. We validate Eurekaverse's effectiveness in the domain of
quadrupedal parkour learning, in which a quadruped robot must traverse through
a variety of obstacle courses. The automatic curriculum designed by Eurekaverse
enables gradual learning of complex parkour skills in simulation and can
successfully transfer to the real-world, outperforming manual training courses
designed by humans.

ÊëòË¶ÅÔºöÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÊïôÂ∞éÊ©üÂô®‰∫∫ÂêÑÁ®ÆË§áÈõúÊäÄËÉΩÁöÑ‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑÁ≠ñÁï•ÊòØÔºåÂ∞çÂÆÉÂÄëÈÄ≤Ë°åÊº∏ÈÄ≤ÂºèÊõ¥ÂÖ∑ÊåëÊà∞ÊÄßÁöÑÁí∞Â¢ÉË™≤Á®ãË®ìÁ∑¥„ÄÇÁÑ∂ËÄåÔºåÈñãÁôºÊúâÊïàÁöÑÁí∞Â¢ÉÂàÜ‰ΩàË™≤Á®ãÁõÆÂâçÈúÄË¶ÅÂ§ßÈáèÁöÑÂ∞àÊ•≠Áü•Ë≠òÔºåËÄå‰∏îÂøÖÈ†àÈáùÂ∞çÊØèÂÄãÊñ∞È†òÂüüÈáçË§áÈÄ≤Ë°å„ÄÇÊàëÂÄëÁöÑÈóúÈçµË¶ãËß£ÊòØÔºåÁí∞Â¢ÉÈÄöÂ∏∏‰ª•Á®ãÂºèÁ¢ºËá™ÁÑ∂ÂëàÁèæ„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊé¢Ë®éÊòØÂê¶ËÉΩÈÄèÈÅéÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÁ®ãÂºèÁ¢ºÁîüÊàê‰æÜÂØ¶Áèæ‰∏¶Ëá™ÂãïÂåñÊúâÊïàÁöÑÁí∞Â¢ÉË™≤Á®ãË®≠Ë®à„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü EurekaverseÔºå‰∏ÄÁ®ÆÁÑ°Áõ£Áù£ÁöÑÁí∞Â¢ÉË®≠Ë®àÊºîÁÆóÊ≥ïÔºåÂÆÉ‰ΩøÁî® LLM ‰æÜÂèñÊ®£Êº∏ÈÄ≤ÂºèÊõ¥ÂÖ∑ÊåëÊà∞ÊÄß„ÄÅÂ§öÊ®£Âåñ‰∏îÂèØÂ≠∏ÁøíÁöÑÁí∞Â¢ÉÔºå‰ª•ÈÄ≤Ë°åÊäÄËÉΩË®ìÁ∑¥„ÄÇÊàëÂÄëÂú®ÂõõË∂≥Ë∑ëÈÖ∑Â≠∏ÁøíÈ†òÂüüÈ©óË≠â‰∫Ü Eurekaverse ÁöÑÊúâÊïàÊÄßÔºåÂÖ∂‰∏≠ÂõõË∂≥Ê©üÂô®‰∫∫ÂøÖÈ†àÁ©øË∂äÂêÑÁ®ÆÈöúÁ§ôË≥ΩÈÅì„ÄÇEurekaverse Ë®≠Ë®àÁöÑËá™ÂãïË™≤Á®ãËÉΩÂ§†Âú®Ê®°Êì¨‰∏≠ÈÄêÊ≠•Â≠∏ÁøíË§áÈõúÁöÑË∑ëÈÖ∑ÊäÄËÉΩÔºå‰∏¶‰∏îÂèØ‰ª•ÊàêÂäüËΩâÁßªÂà∞ÁèæÂØ¶‰∏ñÁïåÔºåÂÑ™Êñº‰∫∫È°ûË®≠Ë®àÁöÑÊâãÂãïË®ìÁ∑¥Ë™≤Á®ã„ÄÇ

##### **Towards Pedagogical LLMs with Supervised Fine Tuning for Computing Education**
2411.01765v1 by Alexandra Vassar, Jake Renzella, Emily Ross, Andrew Taylor

This paper investigates supervised fine-tuning of large language models
(LLMs) to improve their pedagogical alignment in computing education,
addressing concerns that LLMs may hinder learning outcomes. The project
utilised a proprietary dataset of 2,500 high quality question/answer pairs from
programming course forums, and explores two research questions: the suitability
of university course forums in contributing to fine-tuning datasets, and how
supervised fine-tuning can improve LLMs' alignment with educational principles
such as constructivism. Initial findings suggest benefits in pedagogical
alignment of LLMs, with deeper evaluations required.

ÊëòË¶ÅÔºöÊú¨ÊñáÁ†îÁ©∂‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÁõ£Áù£ÂæÆË™øÔºå‰ª•ÊîπÂñÑÂÖ∂Âú®Ë®àÁÆóÊïôËÇ≤‰∏≠ÁöÑÊïôÂ≠∏Â∞çÈΩäÔºåËß£Ê±∫‰∫Ü LLM ÂèØËÉΩÈòªÁ§ôÂ≠∏ÁøíÊàêÊûúÁöÑÊìîÊÜÇ„ÄÇË©≤Â∞àÊ°à‰ΩøÁî®‰∫Ü‰∏ÄÂÄãÂåÖÂê´ 2,500 ÂÄãÈ´òÂìÅË≥™ÂïèÁ≠îÈÖçÂ∞çÁöÑÂ∞àÊúâË≥áÊñôÈõÜÔºåÈÄô‰∫õÈÖçÂ∞ç‰æÜËá™Á®ãÂºèË®≠Ë®àË™≤Á®ãË´ñÂ£áÔºå‰∏¶Êé¢Ë®é‰∫ÜÂÖ©ÂÄãÁ†îÁ©∂ÂïèÈ°åÔºöÂ§ßÂ≠∏Ë™≤Á®ãË´ñÂ£áÂú®‰øÉÈÄ≤ÂæÆË™øË≥áÊñôÈõÜÊñπÈù¢ÁöÑÈÅ©Áî®ÊÄßÔºå‰ª•ÂèäÁõ£Áù£ÂæÆË™øÂ¶Ç‰ΩïËÉΩÊîπÂñÑ LLM ËàáÂª∫Êßã‰∏ªÁæ©Á≠âÊïôËÇ≤ÂéüÂâáÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÂàùÊ≠•ÁôºÁèæË°®Êòé LLM ÁöÑÊïôÂ≠∏Â∞çÈΩäÊúâÁõäÔºåÈúÄË¶ÅÈÄ≤Ë°åÊõ¥Ê∑±ÂÖ•ÁöÑË©ï‰º∞„ÄÇ

##### **Mitigating Spurious Correlations via Disagreement Probability**
2411.01757v1 by Hyeonggeun Han, Sehwan Kim, Hyungjun Joo, Sangwoo Hong, Jungwoo Lee

Models trained with empirical risk minimization (ERM) are prone to be biased
towards spurious correlations between target labels and bias attributes, which
leads to poor performance on data groups lacking spurious correlations. It is
particularly challenging to address this problem when access to bias labels is
not permitted. To mitigate the effect of spurious correlations without bias
labels, we first introduce a novel training objective designed to robustly
enhance model performance across all data samples, irrespective of the presence
of spurious correlations. From this objective, we then derive a debiasing
method, Disagreement Probability based Resampling for debiasing (DPR), which
does not require bias labels. DPR leverages the disagreement between the target
label and the prediction of a biased model to identify bias-conflicting
samples-those without spurious correlations-and upsamples them according to the
disagreement probability. Empirical evaluations on multiple benchmarks
demonstrate that DPR achieves state-of-the-art performance over existing
baselines that do not use bias labels. Furthermore, we provide a theoretical
analysis that details how DPR reduces dependency on spurious correlations.

ÊëòË¶ÅÔºö‰ΩøÁî®Á∂ìÈ©óÈ¢®Èö™ÊúÄÂ∞èÂåñ (ERM) Ë®ìÁ∑¥ÁöÑÊ®°ÂûãÂÆπÊòìÂÅèÂêëÊñºÁõÆÊ®ôÊ®ôÁ±§ÂíåÂÅèÂ∑ÆÂ±¨ÊÄß‰πãÈñìÁöÑËôõÂÅáÈóúËÅØÔºåÈÄôÊúÉÂ∞éËá¥Âú®Áº∫‰πèËôõÂÅáÈóúËÅØÁöÑË≥áÊñôÁæ§ÁµÑ‰∏äË°®Áèæ‰∏ç‰Ω≥„ÄÇÁï∂ÁÑ°Ê≥ïÂèñÂæóÂÅèÂ∑ÆÊ®ôÁ±§ÊôÇÔºåË¶ÅËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÁâπÂà•ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÁÇ∫‰∫ÜÂú®Ê≤íÊúâÂÅèÂ∑ÆÊ®ôÁ±§ÁöÑÊÉÖÊ≥Å‰∏ãÊ∏õËºïËôõÂÅáÈóúËÅØÁöÑÂΩ±ÈüøÔºåÊàëÂÄëÈ¶ñÂÖàÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑË®ìÁ∑¥ÁõÆÊ®ôÔºåÊó®Âú®Á©©ÂÅ•Âú∞ÊèêÂçáÊâÄÊúâË≥áÊñôÊ®£Êú¨ÁöÑÊ®°ÂûãÊïàËÉΩÔºåËÄå‰∏çÁÆ°ÊòØÂê¶Â≠òÂú®ËôõÂÅáÈóúËÅØ„ÄÇÂæûÈÄôÂÄãÁõÆÊ®ôÔºåÊàëÂÄëÊé•ËëóÊé®Â∞éÂá∫‰∏ÄÂÄãÂéªÂÅèÂ∑ÆÊñπÊ≥ïÔºåÂü∫Êñº‰∏ç‰∏ÄËá¥Ê©üÁéáÁöÑÈáçÊñ∞ÊäΩÊ®£ÂéªÂÅèÂ∑Æ (DPR)ÔºåÂÆÉ‰∏çÈúÄË¶ÅÂÅèÂ∑ÆÊ®ôÁ±§„ÄÇDPR Âà©Áî®ÁõÆÊ®ôÊ®ôÁ±§ÂíåÂÅèÂ∑ÆÊ®°ÂûãÈ†êÊ∏¨‰πãÈñìÁöÑ‰∏ç‰∏ÄËá¥Ôºå‰æÜÊâæÂá∫ÂÅèÂ∑ÆË°ùÁ™ÅÁöÑÊ®£Êú¨ÔºàÈÇ£‰∫õÊ≤íÊúâËôõÂÅáÈóúËÅØÁöÑÊ®£Êú¨ÔºâÔºå‰∏¶Ê†πÊìö‰∏ç‰∏ÄËá¥Ê©üÁéáÂ∞çÂÆÉÂÄëÈÄ≤Ë°å‰∏äÊé°Ê®£„ÄÇÂú®Â§öÂÄãÂü∫Ê∫ñÊ∏¨Ë©¶‰∏äÁöÑÂØ¶Ë≠âË©ï‰º∞Ë≠âÊòéÔºåDPR ÈÅîÂà∞‰∫ÜÁèæÊúâÂü∫Á∑öÁöÑÊúÄ‰Ω≥ÊïàËÉΩÔºåËÄåÈÄô‰∫õÂü∫Á∑öÊ≤íÊúâ‰ΩøÁî®ÂÅèÂ∑ÆÊ®ôÁ±§„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÁêÜË´ñÂàÜÊûêÔºåË©≥Á¥∞Ë™™Êòé DPR Â¶Ç‰ΩïÈôç‰ΩéÂ∞çËôõÂÅáÈóúËÅØÁöÑ‰æùË≥¥ÊÄß„ÄÇ

##### **RAGViz: Diagnose and Visualize Retrieval-Augmented Generation**
2411.01751v1 by Tevin Wang, Jingyuan He, Chenyan Xiong

Retrieval-augmented generation (RAG) combines knowledge from domain-specific
sources into large language models to ground answer generation. Current RAG
systems lack customizable visibility on the context documents and the model's
attentiveness towards such documents. We propose RAGViz, a RAG diagnosis tool
that visualizes the attentiveness of the generated tokens in retrieved
documents. With a built-in user interface, retrieval index, and Large Language
Model (LLM) backbone, RAGViz provides two main functionalities: (1) token and
document-level attention visualization, and (2) generation comparison upon
context document addition and removal. As an open-source toolkit, RAGViz can be
easily hosted with a custom embedding model and HuggingFace-supported LLM
backbone. Using a hybrid ANN (Approximate Nearest Neighbor) index,
memory-efficient LLM inference tool, and custom context snippet method, RAGViz
operates efficiently with a median query time of about 5 seconds on a moderate
GPU node. Our code is available at https://github.com/cxcscmu/RAGViz. A demo
video of RAGViz can be found at https://youtu.be/cTAbuTu6ur4.

ÊëòË¶ÅÔºöÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) Â∞á‰æÜËá™ÁâπÂÆöÈ†òÂüü‰æÜÊ∫êÁöÑÁü•Ë≠òÁµêÂêàÂà∞Â§ßÂûãË™ûË®ÄÊ®°Âûã‰∏≠Ôºå‰ª•Âª∫Á´ãÁ≠îÊ°àÁîüÊàê„ÄÇÁõÆÂâçÁöÑ RAG Á≥ªÁµ±Áº∫‰πèÂ∞çËÑàÁµ°Êñá‰ª∂ÂíåÊ®°ÂûãÂ∞çÊ≠§È°ûÊñá‰ª∂ÁöÑÈóúÊ≥®Â∫¶ÁöÑÂèØËá™Ë®ÇÂèØË¶ñÂåñ„ÄÇÊàëÂÄëÊèêÂá∫ RAGVizÔºåÈÄôÊòØ‰∏ÄÂÄã RAG Ë®∫Êñ∑Â∑•ÂÖ∑ÔºåÁî®ÊñºË¶ñË¶∫ÂåñÊ™¢Á¥¢Êñá‰ª∂‰∏≠ÁîüÊàê‰ª£Á¢ºÁöÑÈóúÊ≥®Â∫¶„ÄÇRAGViz Êúâ‰∏ÄÂÄãÂÖßÂª∫‰ΩøÁî®ËÄÖ‰ªãÈù¢„ÄÅÊ™¢Á¥¢Á¥¢ÂºïÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏ªÂππÔºåÊèê‰æõÂÖ©ÂÄã‰∏ªË¶ÅÂäüËÉΩÔºö(1) ‰ª£Á¢ºÂíåÊñá‰ª∂Â±§Á¥öÁöÑÈóúÊ≥®Â∫¶Ë¶ñË¶∫ÂåñÔºå‰ª•Âèä (2) Âú®Âä†ÂÖ•ÂíåÁßªÈô§ËÑàÁµ°Êñá‰ª∂ÂæåÈÄ≤Ë°åÁîüÊàêÊØîËºÉ„ÄÇ‰ΩúÁÇ∫‰∏ÄÂÄãÈñãÊ∫êÂ∑•ÂÖ∑ÂåÖÔºåRAGViz ÂèØ‰ª•ËºïÈ¨ÜÂú∞‰ΩøÁî®Ëá™Ë®ÇÂµåÂÖ•Ê®°ÂûãÂíå HuggingFace ÊîØÊè¥ÁöÑ LLM ‰∏ªÂππÈÄ≤Ë°å‰∏ªÊ©ü„ÄÇÈÄèÈÅé‰ΩøÁî®Ê∑∑Âêà ANN (Ëøë‰ººÊúÄËøëÈÑ∞) Á¥¢Âºï„ÄÅË®òÊÜ∂È´îÊïàÁéáËâØÂ•ΩÁöÑ LLM Êé®Ë´ñÂ∑•ÂÖ∑ÂíåËá™Ë®ÇËÑàÁµ°ÁâáÊÆµÊñπÊ≥ïÔºåRAGViz Âú®‰∏≠Á≠â GPU ÁØÄÈªû‰∏ä‰ª•Á¥Ñ 5 ÁßíÁöÑ‰∏≠‰ΩçÊï∏Êü•Ë©¢ÊôÇÈñìÊúâÊïàÁéáÂú∞ÈÅã‰Ωú„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/cxcscmu/RAGViz ÂèñÂæó„ÄÇRAGViz ÁöÑÁ§∫ÁØÑÂΩ±ÁâáÂèØÂú® https://youtu.be/cTAbuTu6ur4 ÊâæÂà∞„ÄÇ

##### **DynaSaur: Large Language Agents Beyond Predefined Actions**
2411.01747v1 by Dang Nguyen, Viet Dac Lai, Seunghyun Yoon, Ryan A. Rossi, Handong Zhao, Ruiyi Zhang, Puneet Mathur, Nedim Lipka, Yu Wang, Trung Bui, Franck Dernoncourt, Tianyi Zhou

Existing LLM agent systems typically select actions from a fixed and
predefined set at every step. While this approach is effective in closed,
narrowly-scoped environments, we argue that it presents two major challenges
when deploying LLM agents in real-world scenarios: (1) selecting from a fixed
set of actions significantly restricts the planning and acting capabilities of
LLM agents, and (2) this approach requires substantial human effort to
enumerate and implement all possible actions, which becomes impractical in
complex environments with a vast number of potential actions. In this work, we
propose an LLM agent framework that enables the dynamic creation and
composition of actions in an online manner. In this framework, the agent
interacts with the environment by generating and executing programs written in
a general-purpose programming language at each step. Furthermore, generated
actions are accumulated over time for future reuse. Our extensive experiments
on the GAIA benchmark demonstrate that this framework offers significantly
greater flexibility and outperforms previous methods. Notably, it allows an LLM
agent to recover in scenarios where no relevant action exists in the predefined
set or when existing actions fail due to unforeseen edge cases. At the time of
writing, we hold the top position on the GAIA public leaderboard. Our code can
be found in
\href{https://github.com/adobe-research/dynasaur}{https://github.com/adobe-research/dynasaur}.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑ LLM ‰ª£ÁêÜÁ≥ªÁµ±ÈÄöÂ∏∏ÊúÉÂú®ÊØè‰∏ÄÊ≠•Âæû‰∏ÄÂÄãÂõ∫ÂÆöÁöÑ‰∏îÈ†êÂÖàÂÆöÁæ©Â•ΩÁöÑÈõÜÂêà‰∏≠ÈÅ∏ÊìáÂãï‰Ωú„ÄÇÈõñÁÑ∂ÈÄôÁ®ÆÊñπÊ≥ïÂú®Â∞ÅÈñâÁöÑ„ÄÅÁØÑÂúçÁãπÁ™ÑÁöÑÁí∞Â¢É‰∏≠ÂæàÊúâÊïàÔºå‰ΩÜÊàëÂÄëË™çÁÇ∫Âú®ÁèæÂØ¶Â†¥ÊôØ‰∏≠ÈÉ®ÁΩ≤ LLM ‰ª£ÁêÜÊôÇÔºåÂÆÉÊúÉÂá∫ÁèæÂÖ©ÂÄã‰∏ªË¶ÅÊåëÊà∞Ôºö(1) Âæû‰∏ÄÂÄãÂõ∫ÂÆöÁöÑÂãï‰ΩúÈõÜÂêà‰∏≠ÈÅ∏ÊìáÊúÉÈ°ØËëóÈôêÂà∂ LLM ‰ª£ÁêÜÁöÑË¶èÂäÉÂíåË°åÂãïËÉΩÂäõÔºå‰ª•Âèä (2) ÈÄôÁ®ÆÊñπÊ≥ïÈúÄË¶ÅÂ§ßÈáèÁöÑ‰∫∫Âäõ‰æÜÂàóËàâÂíåÂØ¶‰ΩúÊâÄÊúâÂèØËÉΩÁöÑÂãï‰ΩúÔºåÈÄôÂú®ÂÖ∑ÊúâÂ§ßÈáèÊΩõÂú®Âãï‰ΩúÁöÑË§áÈõúÁí∞Â¢É‰∏≠ÊúÉËÆäÂæó‰∏çÂàáÂØ¶Èöõ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄã LLM ‰ª£ÁêÜÊû∂ÊßãÔºåÂÆÉËÉΩ‰ª•Á∑ö‰∏äÊñπÂºèÂãïÊÖãÂª∫Á´ãÂíåÁµÑÂêàÂãï‰Ωú„ÄÇÂú®ÈÄôÂÄãÊû∂Êßã‰∏≠Ôºå‰ª£ÁêÜÈÄèÈÅéÂú®ÊØè‰∏ÄÊ≠•Áî¢ÁîüÂíåÂü∑Ë°å‰ª•ÈÄöÁî®Á®ãÂºèË™ûË®ÄÁ∑®ÂØ´ÁöÑÁ®ãÂºèÔºåËàáÁí∞Â¢É‰∫íÂãï„ÄÇÊ≠§Â§ñÔºåÁî¢ÁîüÁöÑÂãï‰ΩúÊúÉÈö®ËëóÊôÇÈñìÁ¥ØÁ©çÔºå‰ª•‰æøÊú™‰æÜÈáçË§á‰ΩøÁî®„ÄÇÊàëÂÄëÂú® GAIA  benchmark ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫ÜÈÄôÂÄãÊû∂ÊßãÊèê‰æõ‰∫ÜÈ°ØËëóÊõ¥È´òÁöÑÈùàÊ¥ªÊÄßÔºå‰∏¶‰∏îÂÑ™ÊñºÂÖàÂâçÁöÑÂêÑÁ®ÆÊñπÊ≥ï„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂÆÉÂÖÅË®± LLM ‰ª£ÁêÜÂú®È†êÂÆöÁæ©ÈõÜÂêà‰∏≠‰∏çÂ≠òÂú®Áõ∏ÈóúÂãï‰ΩúÊàñÁèæÊúâÂãï‰ΩúÂõ†ÁÑ°Ê≥ïÈ†êË¶ãÁöÑÈÇäÁ∑£Ê°à‰æãËÄåÂ§±ÊïóÊôÇÂæ©Âéü„ÄÇÂú®Êí∞ÂØ´Êú¨ÊñáÊôÇÔºåÊàëÂÄëÂú® GAIA ÂÖ¨ÈñãÊéíË°åÊ¶ú‰∏äÂêçÂàóÂâçËåÖ„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØ‰ª•Âú®
\href{https://github.com/adobe-research/dynasaur}{https://github.com/adobe-research/dynasaur} ‰∏≠ÊâæÂà∞„ÄÇ

##### **xDiT: an Inference Engine for Diffusion Transformers (DiTs) with Massive Parallelism**
2411.01738v1 by Jiarui Fang, Jinzhe Pan, Xibo Sun, Aoyu Li, Jiannan Wang

Diffusion models are pivotal for generating high-quality images and videos.
Inspired by the success of OpenAI's Sora, the backbone of diffusion models is
evolving from U-Net to Transformer, known as Diffusion Transformers (DiTs).
However, generating high-quality content necessitates longer sequence lengths,
exponentially increasing the computation required for the attention mechanism,
and escalating DiTs inference latency. Parallel inference is essential for
real-time DiTs deployments, but relying on a single parallel method is
impractical due to poor scalability at large scales. This paper introduces
xDiT, a comprehensive parallel inference engine for DiTs. After thoroughly
investigating existing DiTs parallel approaches, xDiT chooses Sequence Parallel
(SP) and PipeFusion, a novel Patch-level Pipeline Parallel method, as
intra-image parallel strategies, alongside CFG parallel for inter-image
parallelism. xDiT can flexibly combine these parallel approaches in a hybrid
manner, offering a robust and scalable solution. Experimental results on two
8xL40 GPUs (PCIe) nodes interconnected by Ethernet and an 8xA100 (NVLink) node
showcase xDiT's exceptional scalability across five state-of-the-art DiTs.
Notably, we are the first to demonstrate DiTs scalability on Ethernet-connected
GPU clusters. xDiT is available at https://github.com/xdit-project/xDiT.

ÊëòË¶ÅÔºöÊì¥Êï£Ê®°ÂûãÂ∞çÊñºÁîüÊàêÈ´òÂìÅË≥™ÂΩ±ÂÉèÂíåÂΩ±ÁâáËá≥ÈóúÈáçË¶Å„ÄÇ
Âèó OpenAI ÁöÑ Sora ÊàêÂäüÂïüÁôºÔºåÊì¥Êï£Ê®°ÂûãÁöÑÈ™®ÂππÂæû U-Net ÊºîÈÄ≤Âà∞ TransformerÔºåÁ®±ÁÇ∫Êì¥Êï£ TransformerÔºàDiTÔºâ„ÄÇ
ÁÑ∂ËÄåÔºåÁîüÊàêÈ´òÂìÅË≥™ÂÖßÂÆπÈúÄË¶ÅÊõ¥Èï∑ÁöÑÂ∫èÂàóÈï∑Â∫¶ÔºåÈÄôÊúÉ‰ΩøÊ≥®ÊÑèÂäõÊ©üÂà∂ÊâÄÈúÄÁöÑÈÅãÁÆóÂëàÊåáÊï∏ÊàêÈï∑Ôºå‰∏¶Â¢ûÂä† DiT Êé®Ë´ñÂª∂ÈÅ≤„ÄÇ‰∏¶Ë°åÊé®Ë´ñÂ∞çÊñº DiT ÁöÑÂç≥ÊôÇÈÉ®ÁΩ≤Ëá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÁî±ÊñºÂú®Â§ßÂûãË¶èÊ®°‰∏ãÂèØÊì¥ÂÖÖÊÄß‰∏ç‰Ω≥ÔºåÂõ†Ê≠§‰æùË≥¥ÂñÆ‰∏Ä‰∏¶Ë°åÊñπÊ≥ï‰∏¶‰∏çÂØ¶Èöõ„ÄÇÊú¨Êñá‰ªãÁ¥π xDiTÔºåÈÄôÊòØ‰∏ÄÂÄã DiT ÁöÑÂÖ®Èù¢‰∏¶Ë°åÊé®Ë´ñÂºïÊìé„ÄÇÂú®ÂæπÂ∫ïË™øÊü•ÁèæÊúâÁöÑ DiT ‰∏¶Ë°åÊñπÊ≥ïÂæåÔºåxDiT ÈÅ∏ÊìáÂ∫èÂàó‰∏¶Ë°åÔºàSPÔºâÂíå PipeFusionÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂçÄÂ°äÁ¥öÁÆ°ÈÅì‰∏¶Ë°åÊñπÊ≥ïÔºå‰ΩúÁÇ∫ÂΩ±ÂÉèÂÖß‰∏¶Ë°åÁ≠ñÁï•Ôºå‰ª•Âèä CFG ‰∏¶Ë°å‰ΩúÁÇ∫ÂΩ±ÂÉèÈñì‰∏¶Ë°å„ÄÇxDiT ÂèØ‰ª•ÈùàÊ¥ªÂú∞‰ª•Ê∑∑ÂêàÊñπÂºèÁµêÂêàÈÄô‰∫õ‰∏¶Ë°åÊñπÊ≥ïÔºåÊèê‰æõÂº∑ÂÅ•‰∏îÂèØÊì¥ÂÖÖÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÂú®ÂÖ©ÂÄãÈÄèÈÅé‰πôÂ§™Á∂≤Ë∑Ø‰∫íÈÄ£ÁöÑ 8xL40 GPUÔºàPCIeÔºâÁØÄÈªûÂíå‰∏ÄÂÄã 8xA100ÔºàNVLinkÔºâÁØÄÈªû‰∏äÁöÑÂØ¶È©óÁµêÊûúÂ±ïÁ§∫‰∫Ü xDiT Âú®‰∫îÂÄãÊúÄÂÖàÈÄ≤ÁöÑ DiT ‰∏äÁöÑÂá∫Ëâ≤ÂèØÊì¥ÂÖÖÊÄß„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàëÂÄëÊòØÁ¨¨‰∏ÄÂÄãÂ±ïÁ§∫ DiT Âú®‰πôÂ§™Á∂≤Ë∑ØÈÄ£Êé•ÁöÑ GPU ÈõÜÁæ§‰∏äÂèØÊì¥ÂÖÖÊÄßÁöÑ‰∫∫„ÄÇxDiT ÂèØÂú® https://github.com/xdit-project/xDiT ÂèñÂæó„ÄÇ

##### **Rethinking Weight Decay for Robust Fine-Tuning of Foundation Models**
2411.01713v1 by Junjiao Tian, Chengyue Huang, Zsolt Kira

Modern optimizers such as AdamW, equipped with momentum and adaptive learning
rate, are designed to escape local minima and explore the vast parameter space.
This exploration is beneficial for finding good loss basins when training from
scratch. It is not necessarily ideal when resuming from a powerful foundation
model because it can lead to large deviations from the pre-trained
initialization and, consequently, worse robustness and generalization. At the
same time, strong regularization on all parameters can lead to under-fitting.
We hypothesize that selectively regularizing the parameter space is the key to
fitting and retraining the pre-trained knowledge. This paper proposes a new
weight decay technique, Selective Projection Decay (SPD), that selectively
imposes a strong penalty on certain layers while allowing others to change
freely. Intuitively, SPD expands and contracts the parameter search space for
layers with consistent and inconsistent loss reduction, respectively.
Experimentally, when equipped with SPD, Adam consistently provides better
in-distribution generalization and out-of-distribution robustness performance
on multiple popular vision and language benchmarks. Code available
at~\url{https://github.com/GT-RIPL/Selective-Projection-Decay.git}

ÊëòË¶ÅÔºöÁèæ‰ª£ÁöÑÊúÄ‰Ω≥ÂåñÂô®Ôºå‰æãÂ¶Ç AdamWÔºåÈÖçÂÇôÂãïÈáèÂíåËá™ÈÅ©ÊáâÂ≠∏ÁøíÁéáÔºåÊó®Âú®ÈÄÉÈõ¢Â±ÄÈÉ®ÊúÄÂ∞èÂÄº‰∏¶Êé¢Á¥¢Âª£Â§ßÁöÑÂèÉÊï∏Á©∫Èñì„ÄÇÈÄôÁ®ÆÊé¢Á¥¢Â∞çÊñºÂú®ÂæûÈ†≠ÈñãÂßãË®ìÁ∑¥ÊôÇÊâæÂà∞ËâØÂ•ΩÁöÑÊêçÂ§±ÁõÜÂú∞ÊòØÊúâÁõäÁöÑ„ÄÇÂæûÂº∑Â§ßÁöÑÂü∫Á§éÊ®°Âûã‰∏≠ÊÅ¢Âæ©ÊôÇÔºåÈÄô‰∏¶‰∏ç‰∏ÄÂÆöÊòØÁêÜÊÉ≥ÁöÑÔºåÂõ†ÁÇ∫ÂÆÉÂèØËÉΩÂ∞éËá¥ËàáÈ†êË®ìÁ∑¥ÂàùÂßãÂåñÁî¢ÁîüÂæàÂ§ßÁöÑÂÅèÂ∑ÆÔºåÂæûËÄåÂ∞éËá¥Êõ¥Â∑ÆÁöÑÈ≠ØÊ£íÊÄßÂíåÊ≥õÂåñÊÄß„ÄÇÂêåÊôÇÔºåÂ∞çÊâÄÊúâÂèÉÊï∏ÈÄ≤Ë°åÂº∑Ê≠£ÂâáÂåñÂèØËÉΩÊúÉÂ∞éËá¥Ê¨†Êì¨Âêà„ÄÇÊàëÂÄëÂÅáË®≠ÈÅ∏ÊìáÊÄßÂú∞Ê≠£ÂâáÂåñÂèÉÊï∏Á©∫ÈñìÊòØÊì¨ÂêàÂíåÈáçÊñ∞Ë®ìÁ∑¥È†êË®ìÁ∑¥Áü•Ë≠òÁöÑÈóúÈçµ„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊ¨äÈáçË°∞Ê∏õÊäÄË°ìÔºåÈÅ∏ÊìáÊÄßÊäïÂΩ±Ë°∞Ê∏õ (SPD)ÔºåÂÆÉÊúâÈÅ∏ÊìáÂú∞Â∞çÊüê‰∫õÂ±§ÊñΩÂä†Âº∑Êá≤ÁΩ∞ÔºåÂêåÊôÇÂÖÅË®±ÂÖ∂‰ªñÂ±§Ëá™Áî±ËÆäÂåñ„ÄÇÁõ¥ËßÄÂú∞Ë™™ÔºåSPD ÂàÜÂà•Êì¥Â±ïÂíåÊî∂Á∏Æ‰∫ÜÂÖ∑ÊúâÊåÅÁ∫åÂíå‰∏ç‰∏ÄËá¥ÊêçÂ§±Ê∏õÂ∞ëÁöÑÂ±§ÁöÑÂèÉÊï∏ÊêúÁ¥¢Á©∫Èñì„ÄÇÂú®ÂØ¶È©ó‰∏≠ÔºåÁï∂ÈÖçÂÇô‰∫Ü SPD ÊôÇÔºåAdam Âú®Â§öÂÄãÊµÅË°åÁöÑË¶ñË¶∫ÂíåË™ûË®ÄÂü∫Ê∫ñ‰∏äÂßãÁµÇÊèê‰æõÊõ¥Â•ΩÁöÑÂàÜ‰ΩàÂÖßÊ≥õÂåñÂíåÂàÜ‰ΩàÂ§ñÈ≠ØÊ£íÊÄßÊÄßËÉΩ„ÄÇ‰ª£Á¢ºÂèØÂú®~\url{https://github.com/GT-RIPL/Selective-Projection-Decay.git} ‰∏≠Áç≤Âæó

##### **SPES: Spectrogram Perturbation for Explainable Speech-to-Text Generation**
2411.01710v1 by Dennis Fucci, Marco Gaido, Beatrice Savoldi, Matteo Negri, Mauro Cettolo, Luisa Bentivogli

Spurred by the demand for interpretable models, research on eXplainable AI
for language technologies has experienced significant growth, with feature
attribution methods emerging as a cornerstone of this progress. While prior
work in NLP explored such methods for classification tasks and textual
applications, explainability intersecting generation and speech is lagging,
with existing techniques failing to account for the autoregressive nature of
state-of-the-art models and to provide fine-grained, phonetically meaningful
explanations. We address this gap by introducing Spectrogram Perturbation for
Explainable Speech-to-text Generation (SPES), a feature attribution technique
applicable to sequence generation tasks with autoregressive models. SPES
provides explanations for each predicted token based on both the input
spectrogram and the previously generated tokens. Extensive evaluation on speech
recognition and translation demonstrates that SPES generates explanations that
are faithful and plausible to humans.

ÊëòË¶ÅÔºöÂú®ÂèØËß£ÈáãÊ®°ÂûãÈúÄÊ±ÇÁöÑÈ©Ö‰Ωø‰∏ãÔºåË™ûË®ÄÊäÄË°ìÁöÑ eXplainable AI Á†îÁ©∂Â∑≤Â§ßÂπÖÊàêÈï∑ÔºåÂÖ∂‰∏≠ÁâπÂæµÊ≠∏Âõ†ÊñπÊ≥ïÊàêÁÇ∫ÈÄôÈ†ÖÈÄ≤Â±ïÁöÑÂü∫Áü≥„ÄÇÈõñÁÑ∂ÂÖàÂâçÁöÑ NLP Á†îÁ©∂Êé¢Á¥¢‰∫ÜÊ≠§È°ûÊñπÊ≥ïÔºåÁî®ÊñºÂàÜÈ°û‰ªªÂãôÂíåÊñáÂ≠óÊáâÁî®Ôºå‰ΩÜÂèØËß£ÈáãÊÄßËàáÁîüÊàêÂíåË™ûÈü≥ÁöÑ‰∫§ÈõÜ‰ªçÊúâÂæÖÂä†Âº∑ÔºåÁèæÊúâÊäÄË°ìÁÑ°Ê≥ïËÄÉÈáèÊúÄÂÖàÈÄ≤Ê®°ÂûãÁöÑËá™ÂãïÂõûÊ≠∏ÊÄßË≥™Ôºå‰πüÁÑ°Ê≥ïÊèê‰æõÁ¥∞Á∑ª‰∏îÂú®Ë™ûÈü≥Â≠∏‰∏äÊúâÊÑèÁæ©ÁöÑËß£Èáã„ÄÇÊàëÂÄëÈÄèÈÅéÂ∞éÂÖ•ÂèØËß£ÈáãË™ûÈü≥ËΩâÊñáÂ≠óÁîüÊàêÁöÑÂÖâË≠úÂúñÊìæÂãï (SPES) ‰æÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÈÄôÊòØ‰∏ÄÁ®ÆÁâπÂæµÊ≠∏Âõ†ÊäÄË°ìÔºåÈÅ©Áî®ÊñºÂÖ∑ÊúâËá™ÂãïÂõûÊ≠∏Ê®°ÂûãÁöÑÂ∫èÂàóÁîüÊàê‰ªªÂãô„ÄÇSPES Êèê‰æõÊØèÂÄãÈ†êÊ∏¨Ë©ûÂΩôÁöÑËß£ÈáãÔºåÊ†πÊìöËº∏ÂÖ•ÂÖâË≠úÂúñÂíåÂÖàÂâçÁîüÊàêÁöÑË©ûÂΩô„ÄÇÂú®Ë™ûÈü≥Ëæ®Ë≠òÂíåÁøªË≠ØÊñπÈù¢ÁöÑÂª£Ê≥õË©ï‰º∞Ë≠âÊòéÔºåSPES ÁîüÊàêÁöÑËß£ÈáãÂ∞ç‰∫∫È°û‰æÜË™™ÊòØÂø†ÂØ¶‰∏îÂêàÁêÜÁöÑ„ÄÇ

##### **Investigating Large Language Models for Complex Word Identification in Multilingual and Multidomain Setups**
2411.01706v1 by RƒÉzvan-Alexandru SmƒÉdu, David-Gabriel Ion, Dumitru-Clementin Cercel, Florin Pop, Mihaela-Claudia Cercel

Complex Word Identification (CWI) is an essential step in the lexical
simplification task and has recently become a task on its own. Some variations
of this binary classification task have emerged, such as lexical complexity
prediction (LCP) and complexity evaluation of multi-word expressions (MWE).
Large language models (LLMs) recently became popular in the Natural Language
Processing community because of their versatility and capability to solve
unseen tasks in zero/few-shot settings. Our work investigates LLM usage,
specifically open-source models such as Llama 2, Llama 3, and Vicuna v1.5, and
closed-source, such as ChatGPT-3.5-turbo and GPT-4o, in the CWI, LCP, and MWE
settings. We evaluate zero-shot, few-shot, and fine-tuning settings and show
that LLMs struggle in certain conditions or achieve comparable results against
existing methods. In addition, we provide some views on meta-learning combined
with prompt learning. In the end, we conclude that the current state of LLMs
cannot or barely outperform existing methods, which are usually much smaller.

ÊëòË¶ÅÔºöË§áÈõúË©ûÂΩôË≠òÂà• (CWI) ÊòØË©ûÂΩôÁ∞°Âåñ‰ªªÂãô‰∏≠‰∏çÂèØÊàñÁº∫ÁöÑÊ≠•È©üÔºåÊúÄËøëÂ∑≤ÊàêÁÇ∫‰∏ÄÈ†ÖÁç®Á´ãÁöÑ‰ªªÂãô„ÄÇÊ≠§‰∫åÂÖÉÂàÜÈ°û‰ªªÂãôÂá∫Áèæ‰∫Ü‰∏Ä‰∫õËÆäÂåñÔºå‰æãÂ¶ÇË©ûÂΩôË§áÈõúÂ∫¶È†êÊ∏¨ (LCP) ÂíåÂ§öË©ûË°®ÈÅî (MWE) ÁöÑË§áÈõúÂ∫¶Ë©ï‰º∞„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËøëÊúüÂú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁ§æÁæ§‰∏≠Âª£ÂèóÊ≠°ËøéÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÂÖ∑ÊúâÂ§öÂäüËÉΩÊÄßÔºå‰∏¶ÊúâËÉΩÂäõÂú®Èõ∂Ê¨°/Â∞ëÊ¨°ÂòóË©¶ÁöÑË®≠ÂÆö‰∏≠Ëß£Ê±∫Êú™Ë¶ãÈÅéÁöÑÂïèÈ°å„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Êé¢Ë®é‰∫Ü LLM ÁöÑ‰ΩøÁî®ÔºåÁâπÂà•ÊòØÈñãÊîæÂéüÂßãÁ¢ºÊ®°ÂûãÔºå‰æãÂ¶Ç Llama 2„ÄÅLlama 3 Âíå Vicuna v1.5Ôºå‰ª•ÂèäÈñâÊ∫êÊ®°ÂûãÔºå‰æãÂ¶Ç ChatGPT-3.5-turbo Âíå GPT-4oÔºåÂú® CWI„ÄÅLCP Âíå MWE Ë®≠ÂÆö‰∏≠„ÄÇÊàëÂÄëË©ï‰º∞‰∫ÜÈõ∂Ê¨°„ÄÅÂ∞ëÊ¨°ÂíåÂæÆË™øË®≠ÂÆöÔºå‰∏¶È°ØÁ§∫ LLM Âú®Êüê‰∫õÊ¢ù‰ª∂‰∏ãÊúÉÈÅáÂà∞Âõ∞Èõ£ÔºåÊàñËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÁç≤ÂæóÁõ∏Áï∂ÁöÑÁµêÊûú„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏Ä‰∫õÈóúÊñºÂÖÉÂ≠∏ÁøíÁµêÂêàÊèêÁ§∫Â≠∏ÁøíÁöÑËßÄÈªû„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂæóÂá∫ÁµêË´ñÔºåLLM ÁöÑÁï∂ÂâçÁãÄÊÖãÁÑ°Ê≥ïÊàñÂÉÖËÉΩÂãâÂº∑ÂÑ™ÊñºÁèæÊúâÊñπÊ≥ïÔºåËÄåÁèæÊúâÊñπÊ≥ïÈÄöÂ∏∏Â∞èÂæóÂ§ö„ÄÇ

##### **Data Extraction Attacks in Retrieval-Augmented Generation via Backdoors**
2411.01705v1 by Yuefeng Peng, Junda Wang, Hong Yu, Amir Houmansadr

Despite significant advancements, large language models (LLMs) still struggle
with providing accurate answers when lacking domain-specific or up-to-date
knowledge. Retrieval-Augmented Generation (RAG) addresses this limitation by
incorporating external knowledge bases, but it also introduces new attack
surfaces. In this paper, we investigate data extraction attacks targeting the
knowledge databases of RAG systems. We demonstrate that previous attacks on RAG
largely depend on the instruction-following capabilities of LLMs, and that
simple fine-tuning can reduce the success rate of such attacks to nearly zero.
This makes these attacks impractical since fine-tuning is a common practice
when deploying LLMs in specific domains. To further reveal the vulnerability,
we propose to backdoor RAG, where a small portion of poisoned data is injected
during the fine-tuning phase to create a backdoor within the LLM. When this
compromised LLM is integrated into a RAG system, attackers can exploit specific
triggers in prompts to manipulate the LLM to leak documents from the retrieval
database. By carefully designing the poisoned data, we achieve both verbatim
and paraphrased document extraction. We show that with only 3\% poisoned data,
our method achieves an average success rate of 79.7\% in verbatim extraction on
Llama2-7B, with a ROUGE-L score of 64.21, and a 68.6\% average success rate in
paraphrased extraction, with an average ROUGE score of 52.6 across four
datasets. These results underscore the privacy risks associated with the supply
chain when deploying RAG systems.

ÊëòË¶ÅÔºöÂÑòÁÆ°ÊúâÈ°ØËëóÁöÑÈÄ≤Â±ïÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Áº∫‰πèÁâπÂÆöÈ†òÂüüÊàñÊúÄÊñ∞ÁöÑÁü•Ë≠òÊôÇÔºå‰ªçÁÑ∂Èõ£‰ª•Êèê‰æõÊ∫ñÁ¢∫ÁöÑÁ≠îÊ°à„ÄÇÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÈÄèÈÅéÁ¥çÂÖ•Â§ñÈÉ®Áü•Ë≠òÂ∫´‰æÜËß£Ê±∫Ê≠§ÈôêÂà∂Ôºå‰ΩÜÂÆÉ‰πüÂºïÂÖ•‰∫ÜÊñ∞ÁöÑÊîªÊìäÈù¢„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëË™øÊü•ÈáùÂ∞ç RAG Á≥ªÁµ±Áü•Ë≠òÂ∫´ÁöÑË≥áÊñôÊèêÂèñÊîªÊìä„ÄÇÊàëÂÄëË≠âÊòéÔºåÂÖàÂâçÂ∞ç RAG ÁöÑÊîªÊìäÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂèñÊ±∫Êñº LLM ÁöÑÊåá‰ª§ÈÅµÂæ™ËÉΩÂäõÔºåËÄå‰∏îÁ∞°ÂñÆÁöÑÂæÆË™øÂèØ‰ª•Â∞áÊ≠§È°ûÊîªÊìäÁöÑÊàêÂäüÁéáÈôç‰ΩéÂà∞Êé•ËøëÊñºÈõ∂„ÄÇÈÄô‰ΩøÂæóÈÄô‰∫õÊîªÊìä‰∏çÂàáÂØ¶ÈöõÔºåÂõ†ÁÇ∫ÂæÆË™øÊòØÂ∞á LLM ÈÉ®ÁΩ≤Âà∞ÁâπÂÆöÈ†òÂüüÁöÑÂ∏∏Ë¶ãÂÅöÊ≥ï„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•Êè≠Á§∫ÊºèÊ¥ûÔºåÊàëÂÄëÂª∫Ë≠∞ÂæåÈñÄ RAGÔºåÂú®ÂæÆË™øÈöéÊÆµÊ≥®ÂÖ•‰∏ÄÂ∞èÈÉ®ÂàÜ‰∏≠ÊØíË≥áÊñôÔºå‰ª•Âú® LLM ‰∏≠Âª∫Á´ãÂæåÈñÄ„ÄÇÁï∂ÈÄôÂÄãÂèóÊêçÁöÑ LLM Êï¥ÂêàÂà∞ RAG Á≥ªÁµ±‰∏≠ÊôÇÔºåÊîªÊìäËÄÖÂèØ‰ª•Âà©Áî®ÊèêÁ§∫‰∏≠ÁöÑÁâπÂÆöËß∏ÁôºÂô®ÔºåÊìçÁ∏± LLM ÂæûÊ™¢Á¥¢Ë≥áÊñôÂ∫´‰∏≠Ê¥©Èú≤Êñá‰ª∂„ÄÇÈÄèÈÅé‰ªîÁ¥∞Ë®≠Ë®à‰∏≠ÊØíË≥áÊñôÔºåÊàëÂÄëÂØ¶ÁèæÈÄêÂ≠óÂíåËΩâËø∞ÁöÑÊñáÊ™îÊèêÂèñ„ÄÇÊàëÂÄëË°®ÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂè™Êúâ 3% ÁöÑ‰∏≠ÊØíË≥áÊñôÔºåÂú® Llama2-7B ‰∏äÁöÑÈÄêÂ≠óÊèêÂèñ‰∏≠ÔºåÂπ≥ÂùáÊàêÂäüÁéáÈÅîÂà∞ 79.7%ÔºåROUGE-L ÂàÜÊï∏ÁÇ∫ 64.21ÔºåÂú®ËΩâËø∞ÊèêÂèñ‰∏≠Âπ≥ÂùáÊàêÂäüÁéáÁÇ∫ 68.6%ÔºåÂú®ÂõõÂÄãË≥áÊñôÈõÜ‰∏≠ÁöÑÂπ≥Âùá ROUGE ÂàÜÊï∏ÁÇ∫ 52.6„ÄÇÈÄô‰∫õÁµêÊûúÂº∑Ë™ø‰∫ÜÂú®ÈÉ®ÁΩ≤ RAG Á≥ªÁµ±ÊôÇÔºå‰æõÊáâÈèàÁõ∏ÈóúÁöÑÈö±ÁßÅÈ¢®Èö™„ÄÇ

##### **UniGuard: Towards Universal Safety Guardrails for Jailbreak Attacks on Multimodal Large Language Models**
2411.01703v1 by Sejoon Oh, Yiqiao Jin, Megha Sharma, Donghyun Kim, Eric Ma, Gaurav Verma, Srijan Kumar

Multimodal large language models (MLLMs) have revolutionized vision-language
understanding but are vulnerable to multimodal jailbreak attacks, where
adversaries meticulously craft inputs to elicit harmful or inappropriate
responses. We propose UniGuard, a novel multimodal safety guardrail that
jointly considers the unimodal and cross-modal harmful signals. UniGuard is
trained such that the likelihood of generating harmful responses in a toxic
corpus is minimized, and can be seamlessly applied to any input prompt during
inference with minimal computational costs. Extensive experiments demonstrate
the generalizability of UniGuard across multiple modalities and attack
strategies. It demonstrates impressive generalizability across multiple
state-of-the-art MLLMs, including LLaVA, Gemini Pro, GPT-4, MiniGPT-4, and
InstructBLIP, thereby broadening the scope of our solution.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) ÂæπÂ∫ïÊîπËÆä‰∫ÜË¶ñË¶∫Ë™ûË®ÄÁêÜËß£Ôºå‰ΩÜÂÆπÊòìÂèóÂà∞Â§öÊ®°ÊÖãË∂äÁçÑÊîªÊìäÔºåÂÖ∂‰∏≠Â∞çÊâãÁ≤æÂøÉË£Ω‰ΩúËº∏ÂÖ•‰ª•ÂºïÁôºÊúâÂÆ≥Êàñ‰∏çÈÅ©Áï∂ÁöÑÂõûÊáâ„ÄÇÊàëÂÄëÊèêÂá∫ UniGuardÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÂ§öÊ®°ÊÖãÂÆâÂÖ®Ë≠∑Ê¨ÑÔºåÂÆÉÂÖ±ÂêåËÄÉÊÖÆ‰∫ÜÂñÆÊ®°ÊÖãÂíåË∑®Ê®°ÊÖãÁöÑÊúâÂÆ≥Ë®äËôü„ÄÇUniGuard Êé•ÂèóË®ìÁ∑¥ÔºåÂ∞áÂú®ÊúâÊØíË™ûÊñôÂ∫´‰∏≠Áî¢ÁîüÊúâÂÆ≥ÂõûÊáâÁöÑÂèØËÉΩÊÄßÈôçËá≥ÊúÄ‰ΩéÔºå‰∏¶‰∏îÂèØ‰ª•Âú®Êé®ÁêÜÈÅéÁ®ã‰∏≠ÁÑ°Á∏´ÊáâÁî®Êñº‰ªª‰ΩïËº∏ÂÖ•ÊèêÁ§∫ÔºåÂêåÊôÇÂ∞áÈÅãÁÆóÊàêÊú¨ÈôçËá≥ÊúÄ‰Ωé„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòé‰∫Ü UniGuard Âú®Â§öÁ®ÆÊ®°ÊÖãÂíåÊîªÊìäÁ≠ñÁï•‰∏≠ÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÂÆÉÂ±ïÁ§∫‰∫ÜÂú®Â§öÂÄãÊúÄÂÖàÈÄ≤ÁöÑ MLLM ‰∏≠‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊ≥õÂåñËÉΩÂäõÔºåÂåÖÊã¨ LLaVA„ÄÅGemini Pro„ÄÅGPT-4„ÄÅMiniGPT-4 Âíå InstructBLIPÔºåÂæûËÄåÊì¥Â§ß‰∫ÜÊàëÂÄëËß£Ê±∫ÊñπÊ°àÁöÑÁØÑÂúç„ÄÇ

##### **Unlocking the Theory Behind Scaling 1-Bit Neural Networks**
2411.01663v1 by Majid Daliri, Zhao Song, Chiwun Yang

Recently, 1-bit Large Language Models (LLMs) have emerged, showcasing an
impressive combination of efficiency and performance that rivals traditional
LLMs. Research by Wang et al. (2023); Ma et al. (2024) indicates that the
performance of these 1-bit LLMs progressively improves as the number of
parameters increases, hinting at the potential existence of a Scaling Law for
1-bit Neural Networks. In this paper, we present the first theoretical result
that rigorously establishes this scaling law for 1-bit models. We prove that,
despite the constraint of weights restricted to $\{-1, +1\}$, the dynamics of
model training inevitably align with kernel behavior as the network width
grows. This theoretical breakthrough guarantees convergence of the 1-bit model
to an arbitrarily small loss as width increases. Furthermore, we introduce the
concept of the generalization difference, defined as the gap between the
outputs of 1-bit networks and their full-precision counterparts, and
demonstrate that this difference maintains a negligible level as network width
scales. Building on the work of Kaplan et al. (2020), we conclude by examining
how the training loss scales as a power-law function of the model size, dataset
size, and computational resources utilized for training. Our findings
underscore the promising potential of scaling 1-bit neural networks, suggesting
that int1 could become the standard in future neural network precision.

ÊëòË¶ÅÔºö<paragraph>ÊúÄËøëÔºå1 ‰ΩçÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊµÆÁèæÔºåÂ±ïÁ§∫Âá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊïàÁéáÂíåÊïàËÉΩÁµêÂêàÔºåÂèØÂ™≤ÁæéÂÇ≥Áµ± LLM„ÄÇÁéãÁ≠â‰∫∫ (2023)ÔºõÈ¶¨Á≠â‰∫∫ (2024) ÁöÑÁ†îÁ©∂ÊåáÂá∫ÔºåÈÄô‰∫õ 1 ‰Ωç LLM ÁöÑÊïàËÉΩÊúÉÈö®ËëóÂèÉÊï∏Êï∏ÈáèÂ¢ûÂä†ËÄåÈÄêÊ≠•ÊèêÂçáÔºåÊöóÁ§∫ 1 ‰ΩçÁ•ûÁ∂ìÁ∂≤Ë∑ØÂ≠òÂú®Ë¶èÊ®°ÂæãÁöÑÂèØËÉΩÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫Á¨¨‰∏ÄÂÄãÁêÜË´ñÁµêÊûúÔºåÂö¥Ë¨πÂú∞Âª∫Á´ã 1 ‰ΩçÊ®°ÂûãÁöÑË¶èÊ®°Âæã„ÄÇÊàëÂÄëË≠âÊòéÔºåÂÑòÁÆ°Ê¨äÈáçÈôêÂà∂Âú® $\{-1, +1\}$ ÁöÑÁ¥ÑÊùü‰∏ãÔºåÊ®°ÂûãË®ìÁ∑¥ÁöÑÂãïÊÖãÊúÉÈö®ËëóÁ∂≤Ë∑ØÂØ¨Â∫¶Â¢ûÂä†ËÄå‰∏çÂèØÈÅøÂÖçÂú∞ËàáÊ†∏ÂøÉÁöÑË°åÁÇ∫‰∏ÄËá¥„ÄÇÈÄôÂÄãÁêÜË´ñÁ™ÅÁ†¥‰øùË≠â 1 ‰ΩçÊ®°ÂûãÁöÑÊî∂ÊñÇÊÄßÔºåËÆìÊêçÂ§±Èö®ËëóÂØ¨Â∫¶Â¢ûÂä†ËÄå‰ªªÊÑèÂú∞ËÆäÂ∞è„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫Ê≥õÂåñÂ∑ÆÁï∞ÁöÑÊ¶ÇÂøµÔºåÂÆöÁæ©ÁÇ∫ 1 ‰ΩçÁ∂≤Ë∑ØÂíåÂÆÉÂÄëÁöÑÂÆåÂÖ®Á≤æÁ¢∫Â∫¶Â∞çÊáâÁâ©‰πãÈñìÁöÑËº∏Âá∫Â∑ÆË∑ùÔºå‰∏¶Ë≠âÊòéÈÄôÂÄãÂ∑ÆÁï∞ÊúÉÈö®ËëóÁ∂≤Ë∑ØÂØ¨Â∫¶Ë¶èÊ®°ËÄåÁ∂≠ÊåÅÂú®ÂèØÂøΩÁï•ÁöÑÂ±§Á¥ö„ÄÇÂª∫Á´ãÂú® Kaplan Á≠â‰∫∫ (2020) ÁöÑÁ†îÁ©∂‰∏äÔºåÊàëÂÄëÊúÄÂæåÊé¢Ë®éË®ìÁ∑¥ÊêçÂ§±Â¶Ç‰Ωï‰ª•ÂÜ™ÂæãÂáΩÊï∏ÁöÑÂΩ¢ÂºèÈö®ËëóÊ®°ÂûãÂ§ßÂ∞è„ÄÅË≥áÊñôÈõÜÂ§ßÂ∞èÂíåÁî®ÊñºË®ìÁ∑¥ÁöÑË®àÁÆóË≥áÊ∫êËÄåË¶èÊ®°Âåñ„ÄÇÊàëÂÄëÁöÑÁôºÁèæÂº∑Ë™øË¶èÊ®°Âåñ 1 ‰ΩçÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÊΩõÂäõÔºåË°®Êòé int1 ÂèØËÉΩÊúÉÊàêÁÇ∫Êú™‰æÜÁ•ûÁ∂ìÁ∂≤Ë∑ØÁ≤æÂ∫¶ÁöÑÊ®ôÊ∫ñ„ÄÇ</paragraph>

##### **Diagnosing Medical Datasets with Training Dynamics**
2411.01653v1 by Laura Wenderoth

This study explores the potential of using training dynamics as an automated
alternative to human annotation for evaluating the quality of training data.
The framework used is Data Maps, which classifies data points into categories
such as easy-to-learn, hard-to-learn, and ambiguous (Swayamdipta et al., 2020).
Swayamdipta et al. (2020) highlight that difficult-to-learn examples often
contain errors, and ambiguous cases significantly impact model training. To
confirm the reliability of these findings, we replicated the experiments using
a challenging dataset, with a focus on medical question answering. In addition
to text comprehension, this field requires the acquisition of detailed medical
knowledge, which further complicates the task. A comprehensive evaluation was
conducted to assess the feasibility and transferability of the Data Maps
framework to the medical domain. The evaluation indicates that the framework is
unsuitable for addressing datasets' unique challenges in answering medical
questions.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®é‰ΩøÁî®Ë®ìÁ∑¥ÂãïÊÖã‰ΩúÁÇ∫Ëá™ÂãïÂåñÊõø‰ª£ÊñπÊ°àÔºå‰ª•Ë©ï‰º∞Ë®ìÁ∑¥Ë≥áÊñôÂìÅË≥™Ôºå‰ª•Âèñ‰ª£‰∫∫Â∑•Ê®ôË®ª„ÄÇÊâÄ‰ΩøÁî®ÁöÑÊû∂ÊßãÁÇ∫Ë≥áÊñôÂú∞ÂúñÔºåÂÖ∂Â∞áË≥áÊñôÈªûÂàÜÈ°ûÁÇ∫ÊòìÊñºÂ≠∏Áøí„ÄÅÈõ£‰ª•Â≠∏ÁøíÂíåÊ®°Á®úÂÖ©ÂèØÁ≠âÈ°ûÂà•ÔºàSwayamdipta Á≠â‰∫∫Ôºå2020 Âπ¥Ôºâ„ÄÇSwayamdipta Á≠â‰∫∫Ôºà2020 Âπ¥ÔºâÂº∑Ë™øÔºåÈõ£‰ª•Â≠∏ÁøíÁöÑÁØÑ‰æãÈÄöÂ∏∏ÂåÖÂê´ÈåØË™§ÔºåËÄåÊ®°Á®úÂÖ©ÂèØÁöÑÊÉÖÊ≥ÅÊúÉÂ∞çÊ®°ÂûãË®ìÁ∑¥Áî¢ÁîüÈáçÂ§ßÂΩ±Èüø„ÄÇÁÇ∫‰∫ÜÁ¢∫Ë™çÈÄô‰∫õÁôºÁèæÁöÑÂèØÈù†ÊÄßÔºåÊàëÂÄë‰ΩøÁî®ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑË≥áÊñôÈõÜË§áË£Ω‰∫ÜÂØ¶È©óÔºåÈáçÈªûÊîæÂú®ÈÜ´Â≠∏ÂïèÈ°åËß£Á≠î‰∏ä„ÄÇÈô§‰∫ÜÊñáÂ≠óÁêÜËß£‰πãÂ§ñÔºåÈÄôÂÄãÈ†òÂüüÈÇÑÈúÄË¶ÅÁç≤ÂèñË©≥Á¥∞ÁöÑÈÜ´Â≠∏Áü•Ë≠òÔºåÈÄôÈÄ≤‰∏ÄÊ≠•‰Ωø‰ªªÂãôË§áÈõúÂåñ„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑË©ï‰º∞Ôºå‰ª•Ë©ï‰º∞Ë≥áÊñôÂú∞ÂúñÊû∂ÊßãÂú®ÈÜ´Â≠∏È†òÂüüÁöÑÂèØË°åÊÄßÂíåÂèØËΩâÁßªÊÄß„ÄÇË©ï‰º∞ÁµêÊûúË°®ÊòéÔºåË©≤Êû∂Êßã‰∏çÈÅ©ÂêàËß£Ê±∫Ë≥áÊñôÈõÜÂú®ÂõûÁ≠îÈÜ´Â≠∏ÂïèÈ°åÊôÇÈù¢Ëá®ÁöÑÁç®ÁâπÊåëÊà∞„ÄÇ

##### **Optimizing Gastrointestinal Diagnostics: A CNN-Based Model for VCE Image Classification**
2411.01652v1 by Vaneeta Ahlawat, Rohit Sharma, Urush

In recent years, the diagnosis of gastrointestinal (GI) diseases has advanced
greatly with the advent of high-tech video capsule endoscopy (VCE) technology,
which allows for non-invasive observation of the digestive system. The MisaHub
Capsule Vision Challenge encourages the development of vendor-independent
artificial intelligence models that can autonomously classify GI anomalies from
VCE images. This paper presents CNN architecture designed specifically for
multiclass classification of ten gut pathologies, including angioectasia,
bleeding, erosion, erythema, foreign bodies, lymphangiectasia, polyps, ulcers,
and worms as well as their normal state.

ÊëòË¶ÅÔºöËøëÂπ¥Êù•ÔºåÈöèÁùÄÈ´òÁßëÊäÄËßÜÈ¢ëËÉ∂ÂõäÂÜÖÁ™•ÈïúÔºàVCEÔºâÊäÄÊúØÁöÑÂá∫Áé∞ÔºåËÉÉËÇ†ÔºàGIÔºâÁñæÁóÖÁöÑËØäÊñ≠ÂèñÂæó‰∫ÜÂæàÂ§ßËøõÂ±ïÔºåËØ•ÊäÄÊúØÂÖÅËÆ∏ÂØπÊ∂àÂåñÁ≥ªÁªüËøõË°åÊó†ÂàõËßÇÂØü„ÄÇMisaHub ËÉ∂ÂõäËßÜËßâÊåëÊàòÈºìÂä±ÂºÄÂèëÁã¨Á´ã‰∫é‰æõÂ∫îÂïÜÁöÑ‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÔºåËØ•Ê®°ÂûãÂèØ‰ª•Ëá™‰∏ªÂú∞‰ªé VCE ÂõæÂÉè‰∏≠ÂØπ GI ÂºÇÂ∏∏ËøõË°åÂàÜÁ±ª„ÄÇÊú¨Êñá‰ªãÁªç‰∫Ü‰∏ìÈó®‰∏∫ÂçÅÁßçËÇ†ÈÅìÁñæÁóÖÁöÑÂ§öÁ±ªÂàÜÁ±ªËÄåËÆæËÆ°ÁöÑ CNN Êû∂ÊûÑÔºåÂåÖÊã¨Ë°ÄÁÆ°Êâ©Âº†„ÄÅÂá∫Ë°Ä„ÄÅÁ≥úÁÉÇ„ÄÅÁ∫¢Êñë„ÄÅÂºÇÁâ©„ÄÅÊ∑ãÂ∑¥ÁÆ°Êâ©Âº†„ÄÅÊÅØËÇâ„ÄÅÊ∫ÉÁñ°ÂíåË†ïËô´‰ª•ÂèäÂÆÉ‰ª¨ÁöÑÊ≠£Â∏∏Áä∂ÊÄÅ„ÄÇ

##### **Optical Flow Representation Alignment Mamba Diffusion Model for Medical Video Generation**
2411.01647v1 by Zhenbin Wang, Lei Zhang, Lituan Wang, Minjuan Zhu, Zhenwei Zhang

Medical video generation models are expected to have a profound impact on the
healthcare industry, including but not limited to medical education and
training, surgical planning, and simulation. Current video diffusion models
typically build on image diffusion architecture by incorporating temporal
operations (such as 3D convolution and temporal attention). Although this
approach is effective, its oversimplification limits spatio-temporal
performance and consumes substantial computational resources. To counter this,
we propose Medical Simulation Video Generator (MedSora), which incorporates
three key elements: i) a video diffusion framework integrates the advantages of
attention and Mamba, balancing low computational load with high-quality video
generation, ii) an optical flow representation alignment method that implicitly
enhances attention to inter-frame pixels, and iii) a video variational
autoencoder (VAE) with frequency compensation addresses the information loss of
medical features that occurs when transforming pixel space into latent features
and then back to pixel frames. Extensive experiments and applications
demonstrate that MedSora exhibits superior visual quality in generating medical
videos, outperforming the most advanced baseline methods. Further results and
code are available at https://wongzbb.github.io/MedSora

ÊëòË¶ÅÔºöÈÜ´ÁôÇÂΩ±ÁâáÁîüÊàêÊ®°ÂûãÈ†êË®àÂ∞áÂ∞çÈÜ´ÁôÇ‰øùÂÅ•Áî¢Ê•≠Áî¢ÁîüÊ∑±ÈÅ†ÁöÑÂΩ±ÈüøÔºåÂåÖÊã¨‰ΩÜ‰∏çÈôêÊñºÈÜ´Â≠∏ÊïôËÇ≤ÂíåË®ìÁ∑¥„ÄÅÊâãË°ìË¶èÂäÉÂíåÊ®°Êì¨„ÄÇÁõÆÂâçÁöÑÂΩ±ÁâáÊì¥Êï£Ê®°ÂûãÈÄöÂ∏∏Âª∫Á´ãÂú®ÂΩ±ÂÉèÊì¥Êï£Êû∂Êßã‰∏äÔºå‰∏¶ÁµêÂêàÊôÇÈñìÈÅãÁÆóÔºà‰æãÂ¶Ç 3D Êë∫Á©çÂíåÊôÇÈñìÊ≥®ÊÑèÂäõÔºâ„ÄÇÂÑòÁÆ°Ê≠§ÊñπÊ≥ïÊúâÊïàÔºå‰ΩÜÂÖ∂ÈÅéÊñºÁ∞°ÂåñÈôêÂà∂‰∫ÜÊôÇÁ©∫ÊïàËÉΩÔºå‰∏¶Ê∂àËÄóÂ§ßÈáèÁöÑÈÅãÁÆóË≥áÊ∫ê„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫ÈÜ´Â≠∏Ê®°Êì¨ÂΩ±ÁâáÁîüÊàêÂô® (MedSora)ÔºåÂÆÉÁµêÂêà‰∫Ü‰∏âÂÄãÈóúÈçµË¶ÅÁ¥†Ôºöi) ‰∏ÄÂÄãÂΩ±ÁâáÊì¥Êï£Êû∂ÊßãÊï¥Âêà‰∫ÜÊ≥®ÊÑèÂäõÂíå Mamba ÁöÑÂÑ™ÈªûÔºåÂú®‰ΩéÈÅãÁÆóË≤†ËºâÂíåÈ´òÂìÅË≥™ÂΩ±ÁâáÁîüÊàê‰πãÈñìÂèñÂæóÂπ≥Ë°°Ôºåii) ‰∏ÄÂÄãÂÖâÊµÅË°®Á§∫Â∞çÈΩäÊñπÊ≥ïÔºåÂèØ‰ª•Èö±Âê´Âú∞Â¢ûÂº∑Â∞çÂΩ±Ê†ºÈñìÂÉèÁ¥†ÁöÑÊ≥®ÊÑèÂäõÔºå‰ª•Âèä iii) ‰∏ÄÂÄãÂÖ∑ÊúâÈ†ªÁéáË£úÂÑüÁöÑÂΩ±ÁâáËÆäÁï∞Ëá™ÂãïÁ∑®Á¢ºÂô® (VAE)ÔºåÁî®ÊñºËß£Ê±∫Âú®Â∞áÂÉèÁ¥†Á©∫ÈñìËΩâÊèõÁÇ∫ÊΩõÂú®ÁâπÂæµÔºåÁÑ∂ÂæåÂÜçËΩâÂõûÂÉèÁ¥†ÂΩ±Ê†ºÊôÇÁôºÁîüÁöÑÈÜ´ÁôÇÁâπÂæµË≥áË®äÈÅ∫Â§±ÂïèÈ°å„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÂíåÊáâÁî®Ë≠âÊòéÔºåMedSora Âú®ÁîüÊàêÈÜ´ÁôÇÂΩ±ÁâáÊñπÈù¢Â±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑË¶ñË¶∫ÂìÅË≥™ÔºåÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÂü∫Ê∫ñÊñπÊ≥ï„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑÁµêÊûúÂíåÁ®ãÂºèÁ¢ºÂèØ‰ª•Âú® https://wongzbb.github.io/MedSora ÂèñÂæó

##### **Enriching Tabular Data with Contextual LLM Embeddings: A Comprehensive Ablation Study for Ensemble Classifiers**
2411.01645v1 by Gjergji Kasneci, Enkelejda Kasneci

Feature engineering is crucial for optimizing machine learning model
performance, particularly in tabular data classification tasks. Leveraging
advancements in natural language processing, this study presents a systematic
approach to enrich tabular datasets with features derived from large language
model embeddings. Through a comprehensive ablation study on diverse datasets,
we assess the impact of RoBERTa and GPT-2 embeddings on ensemble classifiers,
including Random Forest, XGBoost, and CatBoost. Results indicate that
integrating embeddings with traditional numerical and categorical features
often enhances predictive performance, especially on datasets with class
imbalance or limited features and samples, such as UCI Adult, Heart Disease,
Titanic, and Pima Indian Diabetes, with improvements particularly notable in
XGBoost and CatBoost classifiers. Additionally, feature importance analysis
reveals that LLM-derived features frequently rank among the most impactful for
the predictions. This study provides a structured approach to embedding-based
feature enrichment and illustrates its benefits in ensemble learning for
tabular data.

ÊëòË¶ÅÔºöÁâπÂæµÂ∑•Á®ãÂ∞çÊñºÊúÄ‰Ω≥ÂåñÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÊïàËÉΩËá≥ÈóúÈáçË¶ÅÔºåÁâπÂà•ÊòØÂú®Ë°®Ê†ºË≥áÊñôÂàÜÈ°û‰ªªÂãô‰∏≠„ÄÇÊú¨Á†îÁ©∂Âà©Áî®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁöÑÈÄ≤Â±ïÔºåÊèêÂá∫‰∏ÄÂÄãÁ≥ªÁµ±ÊÄßÁöÑÊñπÊ≥ïÔºå‰ª•ÂæûÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂµåÂÖ•‰∏≠Ë°çÁîüÁöÑÁâπÂæµ‰æÜË±êÂØåË°®Ê†ºË≥áÊñôÈõÜ„ÄÇÈÄèÈÅéÂ∞ç‰∏çÂêåË≥áÊñôÈõÜÈÄ≤Ë°åÂÖ®Èù¢ÁöÑÊ∂àËûçÁ†îÁ©∂ÔºåÊàëÂÄëË©ï‰º∞ RoBERTa Âíå GPT-2 ÂµåÂÖ•Â∞çÊï¥È´îÂàÜÈ°ûÂô®ÁöÑÂΩ±ÈüøÔºåÂåÖÊã¨Èö®Ê©üÊ£ÆÊûó„ÄÅXGBoost Âíå CatBoost„ÄÇÁµêÊûúË°®ÊòéÔºåÂ∞áÂµåÂÖ•ËàáÂÇ≥Áµ±Êï∏ÂÄºÂíåÈ°ûÂà•ÁâπÂæµÊï¥ÂêàÈÄöÂ∏∏ÊúÉÂ¢ûÂº∑È†êÊ∏¨ÊïàËÉΩÔºåÁâπÂà•ÊòØÂú®È°ûÂà•‰∏çÂπ≥Ë°°ÊàñÁâπÂæµÂíåÊ®£Êú¨ÊúâÈôêÁöÑË≥áÊñôÈõÜ‰∏äÔºå‰æãÂ¶Ç UCI Adult„ÄÅHeart Disease„ÄÅTitanic Âíå Pima Indian DiabetesÔºåÂÖ∂‰∏≠ XGBoost Âíå CatBoost ÂàÜÈ°ûÂô®ÁöÑÊîπÈÄ≤ÁâπÂà•È°ØËëó„ÄÇÊ≠§Â§ñÔºåÁâπÂæµÈáçË¶ÅÊÄßÂàÜÊûêÈ°ØÁ§∫ÔºåLLM Ë°çÁîüÁöÑÁâπÂæµÁ∂ìÂ∏∏Âú®È†êÊ∏¨‰∏≠ÊéíÂêçÊúÄÈ´ò„ÄÇÊú¨Á†îÁ©∂Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÂµåÂÖ•ÁöÑÁâπÂæµË±êÂØåÁöÑÁµêÊßãÂåñÊñπÊ≥ïÔºå‰∏¶Ë™™Êòé‰∫ÜÂÖ∂Âú®Ë°®Ê†ºË≥áÊñôÁöÑÊï¥È´îÂ≠∏Áøí‰∏≠ÁöÑÂ•ΩËôï„ÄÇ

##### **EcoAct: Economic Agent Determines When to Register What Action**
2411.01643v1 by Shaokun Zhang, Jieyu Zhang, Dujian Ding, Mirian Hipolito Garcia, Ankur Mallick, Daniel Madrigal, Menglin Xia, Victor R√ºhle, Qingyun Wu, Chi Wang

Recent advancements have enabled Large Language Models (LLMs) to function as
agents that can perform actions using external tools. This requires
registering, i.e., integrating tool information into the LLM context prior to
taking actions. Current methods indiscriminately incorporate all candidate
tools into the agent's context and retain them across multiple reasoning steps.
This process remains opaque to LLM agents and is not integrated into their
reasoning procedures, leading to inefficiencies due to increased context length
from irrelevant tools. To address this, we introduce EcoAct, a tool using
algorithm that allows LLMs to selectively register tools as needed, optimizing
context use. By integrating the tool registration process into the reasoning
procedure, EcoAct reduces computational costs by over 50% in multiple steps
reasoning tasks while maintaining performance, as demonstrated through
extensive experiments. Moreover, it can be plugged into any reasoning pipeline
with only minor modifications to the prompt, making it applicable to LLM agents
now and future.

ÊëòË¶ÅÔºöÊúÄËøëÁöÑÈÄ≤Â±ïÂ∑≤ËÆìÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËÉΩÂ§†‰ΩúÁÇ∫‰ª£ÁêÜÔºå‰ΩøÁî®Â§ñÈÉ®Â∑•ÂÖ∑Âü∑Ë°åÂãï‰Ωú„ÄÇÈÄôÈúÄË¶ÅË®ªÂÜäÔºå‰πüÂ∞±ÊòØÂú®Êé°ÂèñÂãï‰Ωú‰πãÂâçÂ∞áÂ∑•ÂÖ∑Ë≥áË®äÊï¥ÂêàÂà∞ LLM ËÉåÊôØ‰∏≠„ÄÇÁõÆÂâçÁöÑÊäÄË°ìÊúÉ‰∏çÂä†ÂçÄÂàÜÂú∞Â∞áÊâÄÊúâÂÄôÈÅ∏Â∑•ÂÖ∑Á¥çÂÖ•‰ª£ÁêÜÁöÑËÉåÊôØ‰∏≠Ôºå‰∏¶Âú®Â§öÂÄãÊé®ÁêÜÊ≠•È©ü‰∏≠‰øùÁïôÂÆÉÂÄë„ÄÇÈÄôÂÄãÈÅéÁ®ãÂ∞ç LLM ‰ª£ÁêÜ‰æÜË™™‰ªçÁÑ∂‰∏çÈÄèÊòéÔºåËÄå‰∏îÊú™Êï¥ÂêàÂà∞ÂÖ∂Êé®ÁêÜÁ®ãÂ∫è‰∏≠ÔºåÂ∞éËá¥Âõ†‰∏çÁõ∏ÈóúÂ∑•ÂÖ∑ËÄåÂ¢ûÂä†ÁöÑËÉåÊôØÈï∑Â∫¶ËÄåÈÄ†ÊàêÊïàÁéá‰Ωé‰∏ã„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü EcoActÔºå‰∏ÄÂÄã‰ΩøÁî®ÊºîÁÆóÊ≥ïÁöÑÂ∑•ÂÖ∑ÔºåËÆì LLM ËÉΩÂ§†Ê†πÊìöÈúÄË¶ÅÊúâÈÅ∏ÊìáÂú∞Ë®ªÂÜäÂ∑•ÂÖ∑ÔºåÊúÄ‰Ω≥ÂåñËÉåÊôØ‰ΩøÁî®„ÄÇÈÄèÈÅéÂ∞áÂ∑•ÂÖ∑Ë®ªÂÜäÁ®ãÂ∫èÊï¥ÂêàÂà∞Êé®ÁêÜÁ®ãÂ∫è‰∏≠ÔºåEcoAct Âú®Â§öÊ≠•È©üÊé®ÁêÜ‰ªªÂãô‰∏≠Â∞áË®àÁÆóÊàêÊú¨Èôç‰Ωé‰∫Ü 50% ‰ª•‰∏äÔºåÂêåÊôÇÁ∂≠ÊåÅÊïàËÉΩÔºåÂ¶ÇÈÄèÈÅéÂª£Ê≥õÁöÑÂØ¶È©óÊâÄË≠âÊòéÁöÑ„ÄÇÊ≠§Â§ñÔºåÂÆÉÂèØ‰ª•ÊèíÂÖ•‰ªª‰ΩïÊé®ÁêÜÁÆ°ÈÅìÔºåÂÉÖÈúÄÂ∞çÊèêÁ§∫ÈÄ≤Ë°åÂæÆÂ∞èÁöÑ‰øÆÊîπÔºå‰ΩøÂÖ∂ÈÅ©Áî®ÊñºÁèæÂú®ÂíåÊú™‰æÜÁöÑ LLM ‰ª£ÁêÜ„ÄÇ

##### **Know Where You're Uncertain When Planning with Multimodal Foundation Models: A Formal Framework**
2411.01639v1 by Neel P. Bhatt, Yunhao Yang, Rohan Siva, Daniel Milan, Ufuk Topcu, Zhangyang Wang

Multimodal foundation models offer a promising framework for robotic
perception and planning by processing sensory inputs to generate actionable
plans. However, addressing uncertainty in both perception (sensory
interpretation) and decision-making (plan generation) remains a critical
challenge for ensuring task reliability. We present a comprehensive framework
to disentangle, quantify, and mitigate these two forms of uncertainty. We first
introduce a framework for uncertainty disentanglement, isolating perception
uncertainty arising from limitations in visual understanding and decision
uncertainty relating to the robustness of generated plans.
  To quantify each type of uncertainty, we propose methods tailored to the
unique properties of perception and decision-making: we use conformal
prediction to calibrate perception uncertainty and introduce
Formal-Methods-Driven Prediction (FMDP) to quantify decision uncertainty,
leveraging formal verification techniques for theoretical guarantees. Building
on this quantification, we implement two targeted intervention mechanisms: an
active sensing process that dynamically re-observes high-uncertainty scenes to
enhance visual input quality and an automated refinement procedure that
fine-tunes the model on high-certainty data, improving its capability to meet
task specifications. Empirical validation in real-world and simulated robotic
tasks demonstrates that our uncertainty disentanglement framework reduces
variability by up to 40% and enhances task success rates by 5% compared to
baselines. These improvements are attributed to the combined effect of both
interventions and highlight the importance of uncertainty disentanglement which
facilitates targeted interventions that enhance the robustness and reliability
of autonomous systems.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÄÅÂü∫Á°ÄÊ®°ÂûãÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÊúâÂâçÈÄîÁöÑÊú∫Âô®‰∫∫Ê°ÜÊû∂ÔºåÈÄöËøáÂ§ÑÁêÜ‰º†ÊÑüÂô®ËæìÂÖ•Êù•ÁîüÊàêÂèØÊìç‰ΩúÁöÑËÆ°ÂàíÔºå‰ªéËÄåÂÆûÁé∞Êú∫Âô®‰∫∫ÊÑüÁü•ÂíåËßÑÂàí„ÄÇÁÑ∂ËÄåÔºåÂú®ÊÑüÁü•Ôºà‰º†ÊÑüÂô®Ëß£ÈáäÔºâÂíåÂÜ≥Á≠ñÂà∂ÂÆöÔºàËÆ°ÂàíÁîüÊàêÔºâ‰∏≠Ëß£ÂÜ≥‰∏çÁ°ÆÂÆöÊÄß‰ªçÁÑ∂ÊòØÁ°Æ‰øù‰ªªÂä°ÂèØÈù†ÊÄßÁöÑÂÖ≥ÈîÆÊåëÊàò„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÂÖ®Èù¢ÁöÑÊ°ÜÊû∂Êù•Ëß£ÂºÄ„ÄÅÈáèÂåñÂíåÂáèËΩªËøô‰∏§ÁßçÂΩ¢ÂºèÁöÑ‰∏çÁ°ÆÂÆöÊÄß„ÄÇÊàë‰ª¨È¶ñÂÖàÂºïÂÖ•‰∫Ü‰∏Ä‰∏™‰∏çÁ°ÆÂÆöÊÄßËß£Áº†Ê°ÜÊû∂ÔºåÂàÜÁ¶ª‰∫ÜÁî±‰∫éËßÜËßâÁêÜËß£ÁöÑÂ±ÄÈôêÊÄßËÄå‰∫ßÁîüÁöÑÊÑüÁü•‰∏çÁ°ÆÂÆöÊÄßÂíå‰∏éÁîüÊàêËÆ°ÂàíÁöÑÈ≤ÅÊ£íÊÄßÁõ∏ÂÖ≥ÁöÑÂÜ≥Á≠ñ‰∏çÁ°ÆÂÆöÊÄß„ÄÇ‰∏∫‰∫ÜÈáèÂåñÊØèÁßçÁ±ªÂûãÁöÑ‰∏çÁ°ÆÂÆöÊÄßÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÈíàÂØπÊÑüÁü•ÂíåÂÜ≥Á≠ñÂà∂ÂÆöÁã¨ÁâπÂ±ûÊÄßÈáèË∫´ÂÆöÂà∂ÁöÑÊñπÊ≥ïÔºöÊàë‰ª¨‰ΩøÁî®‰øùÂΩ¢È¢ÑÊµãÊù•Ê†°ÂáÜÊÑüÁü•‰∏çÁ°ÆÂÆöÊÄßÔºåÂπ∂ÂºïÂÖ•ÂΩ¢ÂºèÊñπÊ≥ïÈ©±Âä®ÁöÑÈ¢ÑÊµã (FMDP) Êù•ÈáèÂåñÂÜ≥Á≠ñ‰∏çÁ°ÆÂÆöÊÄßÔºåÂà©Áî®ÂΩ¢ÂºèÈ™åËØÅÊäÄÊúØÊù•Ëé∑ÂæóÁêÜËÆ∫‰øùËØÅ„ÄÇÂú®Ê≠§ÈáèÂåñÁöÑÂü∫Á°Ä‰∏äÔºåÊàë‰ª¨ÂÆûÊñΩ‰∫Ü‰∏§ÁßçÊúâÈíàÂØπÊÄßÁöÑÂπ≤È¢ÑÊú∫Âà∂Ôºö‰∏Ä‰∏™‰∏ªÂä®ÊÑüÁü•ËøáÁ®ãÔºåÂä®ÊÄÅÂú∞ÈáçÊñ∞ËßÇÂØüÈ´ò‰∏çÁ°ÆÂÆöÊÄßÂú∫ÊôØ‰ª•ÊèêÈ´òËßÜËßâËæìÂÖ•Ë¥®ÈáèÔºå‰ª•Âèä‰∏Ä‰∏™Ëá™Âä®ÁªÜÂåñÁ®ãÂ∫èÔºåËØ•Á®ãÂ∫èÂú®È´òÁ°ÆÂÆöÊÄßÊï∞ÊçÆ‰∏äÂØπÊ®°ÂûãËøõË°åÂæÆË∞ÉÔºåÊèêÈ´òÂÖ∂Êª°Ë∂≥‰ªªÂä°ËßÑËåÉÁöÑËÉΩÂäõ„ÄÇÂú®ÁúüÂÆû‰∏ñÁïåÂíåÊ®°ÊãüÊú∫Âô®‰∫∫‰ªªÂä°‰∏≠ÁöÑÁªèÈ™åÈ™åËØÅË°®ÊòéÔºå‰∏éÂü∫Á∫øÁõ∏ÊØîÔºåÊàë‰ª¨ÁöÑ‰∏çÁ°ÆÂÆöÊÄßËß£Áº†Ê°ÜÊû∂Â∞ÜÂèØÂèòÊÄßÈôç‰Ωé‰∫ÜÈ´òËææ 40%ÔºåÂπ∂Â∞Ü‰ªªÂä°ÊàêÂäüÁéáÊèêÈ´ò‰∫Ü 5%„ÄÇËøô‰∫õÊîπËøõÂΩíÂõ†‰∫é‰∏§ÁßçÂπ≤È¢ÑÊé™ÊñΩÁöÑÁªºÂêà‰ΩúÁî®ÔºåÂπ∂Á™ÅÂá∫‰∫Ü‰∏çÁ°ÆÂÆöÊÄßËß£Áº†ÁöÑÈáçË¶ÅÊÄßÔºåÂÆÉ‰øÉËøõ‰∫ÜÊúâÈíàÂØπÊÄßÁöÑÂπ≤È¢ÑÊé™ÊñΩÔºå‰ªéËÄåÂ¢ûÂº∫‰∫ÜËá™‰∏ªÁ≥ªÁªüÁöÑÈ≤ÅÊ£íÊÄßÂíåÂèØÈù†ÊÄß„ÄÇ

##### **Leveraging Microservices Architecture for Dynamic Pricing in the Travel Industry: Algorithms, Scalability, and Impact on Revenue and Customer Satisfaction**
2411.01636v1 by Biman Barua, M. Shamim Kaiser

This research investigates the implementation of a real-time,
microservices-oriented dynamic pricing system for the travel sector. The system
is designed to address factors such as demand, competitor pricing, and other
external circumstances in real-time. Both controlled simulation and real-life
application showed a respectable gain of 22% in revenue generation and a 17%
improvement in pricing response time which concern the issues of scaling and
flexibility of classical pricing mechanisms. Demand forecasting, competitor
pricing strategies, and event-based pricing were implemented as separate
microservices to enhance their scalability and reduce resource consumption by
30% during peak loads. Customers were also more content as depicted by a 15%
increase in satisfaction score post-implementation given the appreciation of
more appropriate pricing. This research enhances the existing literature with
practical illustrations of the possible application of microservices technology
in developing dynamic pricing solutions in a complex and data-driven context.
There exist however areas for improvement for instance inter-service latency
and the need for extensive real-time data pipelines. The present research goes
on to suggest combining these with direct data capture from customer behavior
at the same time as machine learning capacity developments in pricing
algorithms to assist in more accurate real time pricing. It is determined that
the use of microservices is a reasonable and efficient model for dynamic
pricing, allowing the tourism sector to employ evidence-based and customer
centric pricing techniques, which ensures that their profits are not
jeopardized because of the need for customers.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®éÂØ¶‰Ωú‰∏ÄÂÄãÂç≥ÊôÇ„ÄÅÂæÆÊúçÂãôÂ∞éÂêëÁöÑÂãïÊÖãÂÆöÂÉπÁ≥ªÁµ±ÔºåÈÅ©Áî®ÊñºÊóÖÈÅäÊ•≠„ÄÇÊ≠§Á≥ªÁµ±Êó®Âú®Âç≥ÊôÇËôïÁêÜÈúÄÊ±Ç„ÄÅÁ´∂Áà≠Â∞çÊâãÂÆöÂÉπÂíåÂÖ∂‰ªñÂ§ñÈÉ®Áí∞Â¢ÉÁ≠âÂõ†Á¥†„ÄÇÂèóÊéßÊ®°Êì¨ÂíåÂØ¶ÈöõÊáâÁî®ÂùáÈ°ØÁ§∫ÁáüÊî∂Áî¢ÁîüÂ¢ûÂä†22%ÔºåÂÆöÂÉπÂèçÊáâÊôÇÈñìÊîπÂñÑ17%ÔºåÈÄôÊ∂âÂèäÂÇ≥Áµ±ÂÆöÂÉπÊ©üÂà∂ÁöÑÊì¥ÂÖÖÊÄßÂíåÂΩàÊÄßÂïèÈ°å„ÄÇÈúÄÊ±ÇÈ†êÊ∏¨„ÄÅÁ´∂Áà≠Â∞çÊâãÂÆöÂÉπÁ≠ñÁï•ÂíåÂü∫Êñº‰∫ã‰ª∂ÁöÑÂÆöÂÉπÂØ¶‰ΩúÁÇ∫Áç®Á´ãÂæÆÊúçÂãôÔºå‰ª•ÊèêÂçáÂÖ∂Êì¥ÂÖÖÊÄß‰∏¶Âú®Â∞ñÂ≥∞Ë≤†ËºâÊúüÈñìÊ∏õÂ∞ë30%ÁöÑË≥áÊ∫êÊ∂àËÄó„ÄÇÂÆ¢Êà∂‰πüËºÉÁÇ∫ÊªøÊÑèÔºåÂæûÂØ¶‰ΩúÂæåÊªøÊÑèÂ∫¶ÂàÜÊï∏Â¢ûÂä†15%ÂèØË¶ã‰∏ÄÊñëÔºåÈÄôÊòØÂõ†ÁÇ∫Êõ¥ÈÅ©Áï∂ÁöÑÂÆöÂÉπÁç≤Âæó‰∫ÜËÇØÂÆö„ÄÇÊú¨Á†îÁ©∂‰ª•ÂØ¶Áî®ÁØÑ‰æãË™™ÊòéÂæÆÊúçÂãôÊäÄË°ìÂú®Ë§áÈõú‰∏îË≥áÊñôÈ©ÖÂãïÁöÑÁí∞Â¢É‰∏≠ÈñãÁôºÂãïÊÖãÂÆöÂÉπËß£Ê±∫ÊñπÊ°àÁöÑÂèØËÉΩÊáâÁî®ÔºåÈÄ≤ËÄåË±êÂØå‰∫ÜÁèæÊúâÊñáÁçª„ÄÇÁÑ∂ËÄåÔºå‰ªçÊúâÈÄ≤Ê≠•Á©∫ÈñìÔºå‰æãÂ¶ÇÊúçÂãôÈñìÂª∂ÈÅ≤ÂíåÂ∞çÂ§ßÈáèÂç≥ÊôÇË≥áÊñôÁÆ°Á∑öÁöÑÈúÄÊ±Ç„ÄÇÊú¨Á†îÁ©∂ÈÄ≤‰∏ÄÊ≠•Âª∫Ë≠∞Â∞áÈÄô‰∫õÈúÄÊ±ÇËàáÁõ¥Êé•ÂæûÂÆ¢Êà∂Ë°åÁÇ∫Êì∑ÂèñË≥áÊñôÁµêÂêàÔºåÂêåÊôÇÂú®ÂÆöÂÉπÊºîÁÆóÊ≥ï‰∏≠ÁôºÂ±ïÊ©üÂô®Â≠∏ÁøíËÉΩÂäõÔºå‰ª•ÂçîÂä©Êõ¥Ê∫ñÁ¢∫ÁöÑÂç≥ÊôÇÂÆöÂÉπ„ÄÇÁ†îÁ©∂ÁµêÊûúÁ¢∫ÂÆöÔºå‰ΩøÁî®ÂæÆÊúçÂãôÊòØ‰∏ÄÁ®ÆÂêàÁêÜ‰∏îÊúâÊïàÁöÑÂãïÊÖãÂÆöÂÉπÊ®°ÂºèÔºåÂèØËÆìÊóÖÈÅäÊ•≠Êé°Áî®‰ª•Ë≠âÊìöÁÇ∫Âü∫Á§é‰∏î‰ª•ÂÆ¢Êà∂ÁÇ∫‰∏≠ÂøÉÁöÑÂÆöÂÉπÊäÄË°ìÔºåÁ¢∫‰øùÂÖ∂Âà©ÊΩ§‰∏çÊúÉÂõ†ÂÆ¢Êà∂ÈúÄÊ±ÇËÄåÂèóÂà∞ÂΩ±Èüø„ÄÇ

##### **Counterfactual explainability of black-box prediction models**
2411.01625v1 by Zijun Gao, Qingyuan Zhao

It is crucial to be able to explain black-box prediction models to use them
effectively and safely in practice. Most existing tools for model explanations
are associational rather than causal, and we use two paradoxical examples to
show that such explanations are generally inadequate. Motivated by the concept
of genetic heritability in twin studies, we propose a new notion called
counterfactual explainability for black-box prediction models. Counterfactual
explainability has three key advantages: (1) it leverages counterfactual
outcomes and extends methods for global sensitivity analysis (such as
functional analysis of variance and Sobol's indices) to a causal setting; (2)
it is defined not only for the totality of a set of input factors but also for
their interactions (indeed, it is a probability measure on a whole
``explanation algebra''); (3) it also applies to dependent input factors whose
causal relationship can be modeled by a directed acyclic graph, thus
incorporating causal mechanisms into the explanation.

ÊëòË¶ÅÔºöËÉΩÂ§†Ëß£ÈáãÈªëÁÆ±È†êÊ∏¨Ê®°ÂûãÂ∞çÊñºÂú®ÂØ¶Âãô‰∏äÊúâÊïà‰∏îÂÆâÂÖ®Âú∞‰ΩøÁî®ÂÆÉÂÄëËá≥ÈóúÈáçË¶Å„ÄÇÁèæÊúâÁöÑÊ®°ÂûãËß£ÈáãÂ∑•ÂÖ∑Â§ßÂ§öÊòØËÅØÊÉ≥ÊÄßÁöÑÔºåËÄåÈùûÂõ†ÊûúÊÄßÁöÑÔºåËÄåÊàëÂÄë‰ΩøÁî®ÂÖ©ÂÄãËá™Áõ∏ÁüõÁõæÁöÑÁØÑ‰æã‰æÜË™™ÊòéÈÄôÁ®ÆËß£ÈáãÈÄöÂ∏∏ÊòØ‰∏çÂÖÖÂàÜÁöÑ„ÄÇÂèóÂà∞ÈõôËÉûËÉéÁ†îÁ©∂‰∏≠ÈÅ∫ÂÇ≥ÈÅ∫ÂÇ≥ÁéáÁöÑÊ¶ÇÂøµÂïüÁôºÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÊ¶ÇÂøµÔºåÁ®±ÁÇ∫ÈªëÁÆ±È†êÊ∏¨Ê®°ÂûãÁöÑÂèç‰∫ãÂØ¶ÂèØËß£ÈáãÊÄß„ÄÇÂèç‰∫ãÂØ¶ÂèØËß£ÈáãÊÄßÊúâ‰∏âÂÄãÈóúÈçµÂÑ™ÈªûÔºö (1) ÂÆÉÂà©Áî®Âèç‰∫ãÂØ¶ÁµêÊûúÔºå‰∏¶Â∞áÂÖ®Â±ÄÊïèÊÑüÂ∫¶ÂàÜÊûêÁöÑÊñπÊ≥ïÔºà‰æãÂ¶ÇËÆäÁï∞Êï∏ÁöÑÂáΩÊï∏ÂàÜÊûêÂíå Sobol ÊåáÊï∏ÔºâÊì¥Â±ïÂà∞Âõ†ÊûúË®≠ÂÆöÔºõ (2) ÂÆÉ‰∏çÂÉÖÂÆöÁæ©Êñº‰∏ÄÁµÑËº∏ÂÖ•Âõ†Á¥†ÁöÑÁ∏ΩÂíåÔºå‰πüÂÆöÁæ©ÊñºÂÆÉÂÄëÁöÑ‰∫§‰∫í‰ΩúÁî®Ôºà‰∫ãÂØ¶‰∏äÔºåÂÆÉÊòØÂ∞çÊï¥ÂÄã„ÄåËß£Èáã‰ª£Êï∏„ÄçÁöÑÊ©üÁéáÊ∏¨Â∫¶ÔºâÔºõ (3) ÂÆÉ‰πüÈÅ©Áî®ÊñºÂõ†ÊûúÈóú‰øÇÂèØ‰ª•Áî®ÊúâÂêëÁÑ°Áí∞ÂúñÂª∫Ê®°ÁöÑ‰æùË≥¥Ëº∏ÂÖ•Âõ†Á¥†ÔºåÂõ†Ê≠§Â∞áÂõ†ÊûúÊ©üÂà∂Á¥çÂÖ•Ëß£Èáã‰∏≠„ÄÇ

##### **FilterNet: Harnessing Frequency Filters for Time Series Forecasting**
2411.01623v1 by Kun Yi, Jingru Fei, Qi Zhang, Hui He, Shufeng Hao, Defu Lian, Wei Fan

While numerous forecasters have been proposed using different network
architectures, the Transformer-based models have state-of-the-art performance
in time series forecasting. However, forecasters based on Transformers are
still suffering from vulnerability to high-frequency signals, efficiency in
computation, and bottleneck in full-spectrum utilization, which essentially are
the cornerstones for accurately predicting time series with thousands of
points. In this paper, we explore a novel perspective of enlightening signal
processing for deep time series forecasting. Inspired by the filtering process,
we introduce one simple yet effective network, namely FilterNet, built upon our
proposed learnable frequency filters to extract key informative temporal
patterns by selectively passing or attenuating certain components of time
series signals. Concretely, we propose two kinds of learnable filters in the
FilterNet: (i) Plain shaping filter, that adopts a universal frequency kernel
for signal filtering and temporal modeling; (ii) Contextual shaping filter,
that utilizes filtered frequencies examined in terms of its compatibility with
input signals for dependency learning. Equipped with the two filters, FilterNet
can approximately surrogate the linear and attention mappings widely adopted in
time series literature, while enjoying superb abilities in handling
high-frequency noises and utilizing the whole frequency spectrum that is
beneficial for forecasting. Finally, we conduct extensive experiments on eight
time series forecasting benchmarks, and experimental results have demonstrated
our superior performance in terms of both effectiveness and efficiency compared
with state-of-the-art methods. Code is available at this repository:
$\href{https://github.com/aikunyi/FilterNet}{\small\text{this https URL.}}$

ÊëòË¶ÅÔºö<paragraph>ÂÑòÁÆ°Â∑≤Á∂ìÊèêÂá∫‰ΩøÁî®‰∏çÂêåÁ∂≤Ë∑ØÊû∂ÊßãÁöÑË®±Â§öÈ†êÊ∏¨Âô®Ôºå‰ΩÜÂü∫Êñº Transformer ÁöÑÊ®°ÂûãÂú®ÊôÇÈñìÂ∫èÂàóÈ†êÊ∏¨ÊñπÈù¢ÂÖ∑ÊúâÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÂü∫Êñº Transformer ÁöÑÈ†êÊ∏¨Âô®‰ªçÁÑ∂ÂÆπÊòìÂèóÂà∞È´òÈ†ªË®äËôü„ÄÅË®àÁÆóÊïàÁéáÂíåÂÖ®È†ªË≠úÂà©Áî®ÁöÑÁì∂È†∏ÂΩ±ÈüøÔºåÈÄôÂü∫Êú¨‰∏äÊòØÊ∫ñÁ¢∫È†êÊ∏¨ÂÖ∑ÊúâÊï∏ÂçÉÂÄãÈªûÁöÑÊôÇÈñìÂ∫èÂàóÁöÑÂü∫Áü≥„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Á¥¢‰∫ÜÂïüÁôº‰ø°ËôüËôïÁêÜ‰ª•ÈÄ≤Ë°åÊ∑±Â∫¶ÊôÇÈñìÂ∫èÂàóÈ†êÊ∏¨ÁöÑÊñ∞ËßÄÈªû„ÄÇÂèóÈÅéÊøæÊµÅÁ®ãÁöÑÂïüÁôºÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÁ∞°ÂñÆ‰ΩÜÊúâÊïàÁöÑÁ∂≤Ë∑ØÔºåÂç≥ FilterNetÔºåÂª∫Á´ãÂú®ÊàëÂÄëÊèêÂá∫ÁöÑÂèØÂ≠∏ÁøíÈ†ªÁéáÊøæÊ≥¢Âô®‰πã‰∏äÔºåÈÄèÈÅéÈÅ∏ÊìáÊÄßÂú∞ÈÄöÈÅéÊàñË°∞Ê∏õÊôÇÈñìÂ∫èÂàóË®äËôüÁöÑÊüê‰∫õÁµÑÊàêÈÉ®ÂàÜ‰æÜÊèêÂèñÈóúÈçµË≥áË®äÊÄßÁöÑÊôÇÈñìÊ®°Âºè„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂú® FilterNet ‰∏≠ÊèêÂá∫‰∫ÜÂÖ©Á®ÆÂèØÂ≠∏ÁøíÊøæÊ≥¢Âô®Ôºö(i) Á¥îÁ≤πÂΩ¢ÁãÄÊøæÊ≥¢Âô®ÔºåÊé°Áî®ÈÄöÁî®È†ªÁéáÊ†∏ÈÄ≤Ë°å‰ø°ËôüÊøæÊ≥¢ÂíåÊôÇÈñìÂª∫Ê®°Ôºõ(ii) ‰∏ä‰∏ãÊñáÂΩ¢ÁãÄÊøæÊ≥¢Âô®ÔºåÂà©Áî®Ê†πÊìöËàáËº∏ÂÖ•Ë®äËôüÁöÑÁõ∏ÂÆπÊÄßÊ™¢Êü•ÁöÑÊøæÊ≥¢È†ªÁéáÈÄ≤Ë°å‰æùË≥¥Â≠∏Áøí„ÄÇFilterNet ÂÖ∑ÂÇôÈÄôÂÖ©Á®ÆÊøæÊ≥¢Âô®ÔºåÂèØ‰ª•Ëøë‰ººÊõø‰ª£ÊôÇÈñìÂ∫èÂàóÊñáÁçª‰∏≠Âª£Ê≥õÊé°Áî®ÁöÑÁ∑öÊÄßÂíåÊ≥®ÊÑèÂäõÂ∞çÊáâÔºåÂêåÊôÇÂú®ËôïÁêÜÈ´òÈ†ªÈõúË®äÂíåÂà©Áî®Â∞çÈ†êÊ∏¨ÊúâÁõäÁöÑÊï¥ÂÄãÈ†ªÁéáË≠úÊñπÈù¢ÂÖ∑ÊúâÊ•µ‰Ω≥ÁöÑËÉΩÂäõ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ∞çÂÖ´ÂÄãÊôÇÈñìÂ∫èÂàóÈ†êÊ∏¨Âü∫Ê∫ñÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºåÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÊàëÂÄëÂú®ÊúâÊïàÊÄßÂíåÊïàÁéáÊñπÈù¢ÈÉΩÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ï„ÄÇÁ®ãÂºèÁ¢ºÂèØ‰ª•Âú®ÈÄôÂÄãÂÑ≤Â≠òÂ∫´‰∏≠ÂèñÂæóÔºö
$\href{https://github.com/aikunyi/FilterNet}{\small\text{ÈÄôÂÄã https Á∂≤ÂùÄ„ÄÇ}}$</paragraph>

##### **VQ-Map: Bird's-Eye-View Map Layout Estimation in Tokenized Discrete Space via Vector Quantization**
2411.01618v1 by Yiwei Zhang, Jin Gao, Fudong Ge, Guan Luo, Bing Li, Zhaoxiang Zhang, Haibin Ling, Weiming Hu

Bird's-eye-view (BEV) map layout estimation requires an accurate and full
understanding of the semantics for the environmental elements around the ego
car to make the results coherent and realistic. Due to the challenges posed by
occlusion, unfavourable imaging conditions and low resolution,
\emph{generating} the BEV semantic maps corresponding to corrupted or invalid
areas in the perspective view (PV) is appealing very recently. \emph{The
question is how to align the PV features with the generative models to
facilitate the map estimation}. In this paper, we propose to utilize a
generative model similar to the Vector Quantized-Variational AutoEncoder
(VQ-VAE) to acquire prior knowledge for the high-level BEV semantics in the
tokenized discrete space. Thanks to the obtained BEV tokens accompanied with a
codebook embedding encapsulating the semantics for different BEV elements in
the groundtruth maps, we are able to directly align the sparse backbone image
features with the obtained BEV tokens from the discrete representation learning
based on a specialized token decoder module, and finally generate high-quality
BEV maps with the BEV codebook embedding serving as a bridge between PV and
BEV. We evaluate the BEV map layout estimation performance of our model, termed
VQ-Map, on both the nuScenes and Argoverse benchmarks, achieving 62.2/47.6 mean
IoU for surround-view/monocular evaluation on nuScenes, as well as 73.4 IoU for
monocular evaluation on Argoverse, which all set a new record for this map
layout estimation task. The code and models are available on
\url{https://github.com/Z1zyw/VQ-Map}.

ÊëòË¶ÅÔºöÈ≥•Áû∞Âúñ (BEV) Âú∞ÂúñÈÖçÁΩÆ‰º∞Ë®àÈúÄË¶ÅÊ∫ñÁ¢∫‰∏îÂÖÖÂàÜ‰∫ÜËß£Ëá™ÊàëËªäËºõÂë®ÂúçÁí∞Â¢ÉÂÖÉÁ¥†ÁöÑË™ûÁæ©ÔºåÊâçËÉΩËÆìÁµêÊûúÈÄ£Ë≤´‰∏îÈÄºÁúü„ÄÇÁî±ÊñºÈÅÆÊìã„ÄÅ‰∏çÂà©ÁöÑÂΩ±ÂÉèÊ¢ù‰ª∂Âíå‰ΩéËß£ÊûêÂ∫¶ÊâÄÂ∏∂‰æÜÁöÑÊåëÊà∞ÔºåÊúÄËøëÁî¢ÁîüÂ∞çÊáâÊñºÈÄèË¶ñÂúñ (PV) ‰∏≠ÊêçÂ£ûÊàñÁÑ°ÊïàÂçÄÂüüÁöÑ BEV Ë™ûÁæ©Âú∞ÂúñÈùûÂ∏∏ÊúâÂê∏ÂºïÂäõ„ÄÇÂïèÈ°åÊòØÂ¶Ç‰ΩïÂ∞á PV ÁâπÂæµËàáÁîüÊàêÊ®°ÂûãÂ∞çÈΩäÔºå‰ª•Âà©ÊñºÂú∞Âúñ‰º∞Ë®à„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂª∫Ë≠∞Âà©Áî®È°û‰ººÊñºÂêëÈáèÈáèÂåñËÆäÂàÜËá™ÂãïÁ∑®Á¢ºÂô® (VQ-VAE) ÁöÑÁîüÊàêÊ®°ÂûãÔºåÂú®Ê®ôË®òÂåñÁöÑÈõ¢Êï£Á©∫Èñì‰∏≠Áç≤Âèñ BEV È´òÂ±§Á¥öË™ûÁæ©ÁöÑÂÖàÈ©óÁü•Ë≠ò„ÄÇÁî±ÊñºÁç≤ÂæóÁöÑ BEV Ê®ôË®òÈôÑÂ∏∂‰∏ÄÂÄã‰ª£Á¢ºÁ∞øÂµåÂÖ•ÔºåÂÖ∂‰∏≠Â∞ÅË£ù‰∫ÜÂú∞Èù¢ÂØ¶Ê≥ÅÂú∞Âúñ‰∏≠‰∏çÂêå BEV ÂÖÉÁ¥†ÁöÑË™ûÁæ©ÔºåÊàëÂÄëËÉΩÂ§†Áõ¥Êé•Â∞áÁ®ÄÁñè‰∏ªÂππÂΩ±ÂÉèÁâπÂæµËàáÂæûÂü∫ÊñºÈõ¢Êï£Ë°®Á§∫Â≠∏ÁøíÁöÑÁç≤Âæó BEV Ê®ôË®òÂ∞çÈΩäÔºåÊúÄÂæåÁîüÊàêÈ´òÂìÅË≥™ÁöÑ BEV Âú∞ÂúñÔºåÂÖ∂‰∏≠ BEV ‰ª£Á¢ºÁ∞øÂµåÂÖ•‰ΩúÁÇ∫ PV Âíå BEV ‰πãÈñìÁöÑÊ©ãÊ®ë„ÄÇÊàëÂÄëÂú® nuScenes Âíå Argoverse Âü∫Ê∫ñ‰∏äË©ï‰º∞‰∫ÜÊàëÂÄëÊ®°ÂûãÔºàÁ®±ÁÇ∫ VQ-MapÔºâÁöÑ BEV Âú∞ÂúñÈÖçÁΩÆ‰º∞Ë®àÊïàËÉΩÔºåÂú® nuScenes ‰∏äÁöÑÁí∞ÊôØ/ÂñÆÁúºË©ï‰º∞‰∏≠ÈÅîÂà∞ 62.2/47.6 ÁöÑÂπ≥Âùá IoUÔºå‰ª•ÂèäÂú® Argoverse ‰∏äÁöÑÂñÆÁúºË©ï‰º∞‰∏≠ÈÅîÂà∞ 73.4 ÁöÑ IoUÔºåÈÄô‰∫õÈÉΩÁÇ∫Ê≠§Âú∞ÂúñÈÖçÁΩÆ‰º∞Ë®à‰ªªÂãôÂâµ‰∏ã‰∫ÜÊñ∞ÁöÑÁ¥ÄÈåÑ„ÄÇÁ®ãÂºèÁ¢ºÂíåÊ®°ÂûãÂèØÂú® https://github.com/Z1zyw/VQ-Map ‰∏äÂèñÂæó„ÄÇ

##### **Ontology Population using LLMs**
2411.01612v1 by Sanaz Saki Norouzi, Adrita Barua, Antrea Christou, Nikita Gautam, Andrew Eells, Pascal Hitzler, Cogan Shimizu

Knowledge graphs (KGs) are increasingly utilized for data integration,
representation, and visualization. While KG population is critical, it is often
costly, especially when data must be extracted from unstructured text in
natural language, which presents challenges, such as ambiguity and complex
interpretations. Large Language Models (LLMs) offer promising capabilities for
such tasks, excelling in natural language understanding and content generation.
However, their tendency to ``hallucinate'' can produce inaccurate outputs.
Despite these limitations, LLMs offer rapid and scalable processing of natural
language data, and with prompt engineering and fine-tuning, they can
approximate human-level performance in extracting and structuring data for KGs.
This study investigates LLM effectiveness for the KG population, focusing on
the Enslaved.org Hub Ontology. In this paper, we report that compared to the
ground truth, LLM's can extract ~90% of triples, when provided a modular
ontology as guidance in the prompts.

ÊëòË¶ÅÔºöÁü•Ë≠òÂúñË≠ú (KG) ÊÑà‰æÜÊÑàÂ§öÁî®ÊñºË≥áÊñôÊï¥Âêà„ÄÅË°®Á§∫ÂíåË¶ñË¶∫Âåñ„ÄÇÂÑòÁÆ° KG Â°´ÂÖÖËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÂÆÉÈÄöÂ∏∏ÂæàÊòÇË≤¥ÔºåÁâπÂà•ÊòØÂú®ÂøÖÈ†àÂæûËá™ÁÑ∂Ë™ûË®Ä‰∏≠ÈùûÁµêÊßãÂåñÊñáÂ≠ó‰∏≠ÊèêÂèñË≥áÊñôÊôÇÔºåÈÄôÊúÉÂ∏∂‰æÜÊåëÊà∞Ôºå‰æãÂ¶ÇÊ≠ßÁæ©ÂíåË§áÈõúÁöÑË©ÆÈáã„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁÇ∫Ê≠§È°û‰ªªÂãôÊèê‰æõ‰∫ÜÊúâÂâçÊôØÁöÑËÉΩÂäõÔºåÊìÖÈï∑Ëá™ÁÑ∂Ë™ûË®ÄÁêÜËß£ÂíåÂÖßÂÆπÁîüÊàê„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄë„ÄåÁî¢ÁîüÂπªË¶∫„ÄçÁöÑÂÇæÂêëÂèØËÉΩÊúÉÁî¢Áîü‰∏çÊ∫ñÁ¢∫ÁöÑËº∏Âá∫„ÄÇÂÑòÁÆ°ÊúâÈÄô‰∫õÈôêÂà∂ÔºåLLM Êèê‰æõ‰∫ÜËá™ÁÑ∂Ë™ûË®ÄË≥áÊñôÁöÑÂø´ÈÄü‰∏îÂèØÊì¥ÂÖÖËôïÁêÜÔºå‰∏¶‰∏îÈÄèÈÅéÊèêÁ§∫Â∑•Á®ãÂíåÂæÆË™øÔºåÂÆÉÂÄëÂèØ‰ª•Ëøë‰ºº‰∫∫È°ûÂ±§Á¥öÁöÑÊïàËÉΩÔºå‰ª•ÊèêÂèñÂíåÂª∫Êßã KG ÁöÑË≥áÊñô„ÄÇÊú¨Á†îÁ©∂Ë™øÊü• LLM Â∞ç KG Â°´ÂÖÖÁöÑÊúâÊïàÊÄßÔºåÈáçÈªûÈóúÊ≥® Enslaved.org Hub Ontology„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ†±ÂëäËàáÁúüÂØ¶ÊÉÖÊ≥ÅÁõ∏ÊØîÔºåÁï∂Âú®ÊèêÁ§∫‰∏≠Êèê‰æõÊ®°ÁµÑÂåñÊú¨‰Ωì‰ΩúÁÇ∫ÊåáÂ∞éÊôÇÔºåLLM ÂèØ‰ª•ÊèêÂèñÁ¥Ñ 90% ÁöÑ‰∏âÂÖÉÁµÑ„ÄÇ

