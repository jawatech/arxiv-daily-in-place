
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-02-14**|**MM-RLHF: The Next Step Forward in Multimodal LLM Alignment**|Yi-Fan Zhang et.al.|[2502.10391v1](http://arxiv.org/abs/2502.10391v1)|null|
|**2025-02-14**|**Region-Adaptive Sampling for Diffusion Transformers**|Ziming Liu et.al.|[2502.10389v1](http://arxiv.org/abs/2502.10389v1)|null|
|**2025-02-14**|**Aspect-Oriented Summarization for Psychiatric Short-Term Readmission Prediction**|WonJin Yoon et.al.|[2502.10388v1](http://arxiv.org/abs/2502.10388v1)|null|
|**2025-02-14**|**Simplifying DINO via Coding Rate Regularization**|Ziyang Wu et.al.|[2502.10385v1](http://arxiv.org/abs/2502.10385v1)|null|
|**2025-02-14**|**Unknown Word Detection for English as a Second Language (ESL) Learners Using Gaze and Pre-trained Language Models**|Jiexin Ding et.al.|[2502.10378v1](http://arxiv.org/abs/2502.10378v1)|null|
|**2025-02-14**|**OWLS: Scaling Laws for Multilingual Speech Recognition and Translation Models**|William Chen et.al.|[2502.10373v1](http://arxiv.org/abs/2502.10373v1)|null|
|**2025-02-14**|**Enhancing Multilingual LLM Pretraining with Model-Based Data Selection**|Bettina Messmer et.al.|[2502.10361v1](http://arxiv.org/abs/2502.10361v1)|null|
|**2025-02-14**|**Agentic Verification for Ambiguous Query Disambiguation**|Youngwon Lee et.al.|[2502.10352v1](http://arxiv.org/abs/2502.10352v1)|null|
|**2025-02-14**|**Organize the Web: Constructing Domains Enhances Pre-Training Data Curation**|Alexander Wettig et.al.|[2502.10341v1](http://arxiv.org/abs/2502.10341v1)|null|
|**2025-02-14**|**STAR: Spectral Truncation and Rescale for Model Merging**|Yu-Ang Lee et.al.|[2502.10339v1](http://arxiv.org/abs/2502.10339v1)|null|
|**2025-02-14**|**Evaluating the Meta- and Object-Level Reasoning of Large Language Models for Question Answering**|Nick Ferguson et.al.|[2502.10338v1](http://arxiv.org/abs/2502.10338v1)|null|
|**2025-02-14**|**Process Reward Models for LLM Agents: Practical Framework and Directions**|Sanjiban Choudhury et.al.|[2502.10325v1](http://arxiv.org/abs/2502.10325v1)|null|
|**2025-02-14**|**ExplainReduce: Summarising local explanations via proxies**|Lauri Seppäläinen et.al.|[2502.10311v1](http://arxiv.org/abs/2502.10311v1)|null|
|**2025-02-14**|**LLM-Powered Preference Elicitation in Combinatorial Assignment**|Ermis Soumalias et.al.|[2502.10308v1](http://arxiv.org/abs/2502.10308v1)|null|
|**2025-02-14**|**Reinforcement Learning in Strategy-Based and Atari Games: A Review of Google DeepMinds Innovations**|Abdelrhman Shaheen et.al.|[2502.10303v1](http://arxiv.org/abs/2502.10303v1)|null|
|**2025-02-14**|**DeltaProduct: Increasing the Expressivity of DeltaNet Through Products of Householders**|Julien Siems et.al.|[2502.10297v1](http://arxiv.org/abs/2502.10297v1)|null|
|**2025-02-14**|**A Hybrid Cross-Stage Coordination Pre-ranking Model for Online Recommendation Systems**|Binglei Zhao et.al.|[2502.10284v1](http://arxiv.org/abs/2502.10284v1)|null|
|**2025-02-14**|**Probing Perceptual Constancy in Large Vision Language Models**|Haoran Sun et.al.|[2502.10273v1](http://arxiv.org/abs/2502.10273v1)|null|
|**2025-02-14**|**Are Large Language Models the future crowd workers of Linguistics?**|Iris Ferrazzo et.al.|[2502.10266v1](http://arxiv.org/abs/2502.10266v1)|null|
|**2025-02-14**|**Large Language Models and Synthetic Data for Monitoring Dataset Mentions in Research Papers**|Aivin V. Solatorio et.al.|[2502.10263v1](http://arxiv.org/abs/2502.10263v1)|null|
|**2025-02-14**|**VisCon-100K: Leveraging Contextual Web Data for Fine-tuning Vision Language Models**|Gokul Karthik Kumar et.al.|[2502.10250v1](http://arxiv.org/abs/2502.10250v1)|null|
|**2025-02-14**|**Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model**|Guoqing Ma et.al.|[2502.10248v1](http://arxiv.org/abs/2502.10248v1)|null|
|**2025-02-14**|**Efficient Zero-Order Federated Finetuning of Language Models for Resource-Constrained Devices**|Mohamed Aboelenien Ahmed et.al.|[2502.10239v1](http://arxiv.org/abs/2502.10239v1)|null|
|**2025-02-14**|**Shaping Inductive Bias in Diffusion Models through Frequency-Based Noise Control**|Thomas Jiralerspong et.al.|[2502.10236v1](http://arxiv.org/abs/2502.10236v1)|null|
|**2025-02-14**|**Forget the Data and Fine-Tuning! Just Fold the Network to Compress**|Dong Wang et.al.|[2502.10216v1](http://arxiv.org/abs/2502.10216v1)|null|
|**2025-02-14**|**Do Large Language Models Reason Causally Like Us? Even Better?**|Hanna M. Dettki et.al.|[2502.10215v1](http://arxiv.org/abs/2502.10215v1)|null|
|**2025-02-14**|**Can Post-Training Quantization Benefit from an Additional QLoRA Integration?**|Xiliang Zhu et.al.|[2502.10202v1](http://arxiv.org/abs/2502.10202v1)|null|
|**2025-02-14**|**Prediction hubs are context-informed frequent tokens in LLMs**|Beatrix M. G. Nielsen et.al.|[2502.10201v1](http://arxiv.org/abs/2502.10201v1)|null|
|**2025-02-14**|**MathConstruct: Challenging LLM Reasoning with Constructive Proofs**|Mislav Balunović et.al.|[2502.10197v1](http://arxiv.org/abs/2502.10197v1)|null|
|**2025-02-14**|**Exploring the Camera Bias of Person Re-identification**|Myungseo Song et.al.|[2502.10195v1](http://arxiv.org/abs/2502.10195v1)|null|
|**2025-02-14**|**From Markov to Laplace: How Mamba In-Context Learns Markov Chains**|Marco Bondaschi et.al.|[2502.10178v1](http://arxiv.org/abs/2502.10178v1)|null|
|**2025-02-14**|**STMA: A Spatio-Temporal Memory Agent for Long-Horizon Embodied Task Planning**|Mingcong Lei et.al.|[2502.10177v1](http://arxiv.org/abs/2502.10177v1)|null|
|**2025-02-14**|**SessionRec: Next Session Prediction Paradigm For Generative Sequential Recommendation**|Lei Huang et.al.|[2502.10157v1](http://arxiv.org/abs/2502.10157v1)|null|
|**2025-02-14**|**Video Soundtrack Generation by Aligning Emotions and Temporal Boundaries**|Serkan Sulun et.al.|[2502.10154v1](http://arxiv.org/abs/2502.10154v1)|null|
|**2025-02-14**|**Cooperative Multi-Agent Planning with Adaptive Skill Synthesis**|Zhiyuan Li et.al.|[2502.10148v1](http://arxiv.org/abs/2502.10148v1)|null|
|**2025-02-14**|**Small Models, Big Impact: Efficient Corpus and Graph-Based Adaptation of Small Multilingual Language Models for Low-Resource Languages**|Daniil Gurgurov et.al.|[2502.10140v1](http://arxiv.org/abs/2502.10140v1)|null|
|**2025-02-14**|**Image Embedding Sampling Method for Diverse Captioning**|Sania Waheed et.al.|[2502.10118v1](http://arxiv.org/abs/2502.10118v1)|null|
|**2025-02-14**|**Causal Information Prioritization for Efficient Reinforcement Learning**|Hongye Cao et.al.|[2502.10097v1](http://arxiv.org/abs/2502.10097v1)|null|
|**2025-02-14**|**A novel approach to data generation in generative model**|JaeHong Kim et.al.|[2502.10092v1](http://arxiv.org/abs/2502.10092v1)|null|
|**2025-02-14**|**Manual2Skill: Learning to Read Manuals and Acquire Robotic Skills for Furniture Assembly Using Vision-Language Models**|Chenrui Tie et.al.|[2502.10090v1](http://arxiv.org/abs/2502.10090v1)|null|
|**2025-02-14**|**A Hybrid Edge Classifier: Combining TinyML-Optimised CNN with RRAM-CMOS ACAM for Energy-Efficient Inference**|Kieran Woodward et.al.|[2502.10089v1](http://arxiv.org/abs/2502.10089v1)|null|
|**2025-02-14**|**Towards Empowerment Gain through Causal Structure Learning in Model-Based RL**|Hongye Cao et.al.|[2502.10077v1](http://arxiv.org/abs/2502.10077v1)|null|
|**2025-02-14**|**Adaptive Bi-Level Multi-Robot Task Allocation and Learning under Uncertainty with Temporal Logic Constraints**|Xiaoshan Lin et.al.|[2502.10062v1](http://arxiv.org/abs/2502.10062v1)|null|
|**2025-02-14**|**Annotating Compositionality Scores for Irish Noun Compounds is Hard Work**|Abigail Walsh et.al.|[2502.10061v1](http://arxiv.org/abs/2502.10061v1)|null|
|**2025-02-14**|**MTLM: an Innovative Language Model Training Paradigm for ASR**|Qingliang Meng et.al.|[2502.10058v1](http://arxiv.org/abs/2502.10058v1)|null|
|**2025-02-14**|**ORI: O Routing Intelligence**|Ahmad Shadid et.al.|[2502.10051v1](http://arxiv.org/abs/2502.10051v1)|null|
|**2025-02-14**|**A Survey on LLM-powered Agents for Recommender Systems**|Qiyao Peng et.al.|[2502.10050v1](http://arxiv.org/abs/2502.10050v1)|null|
|**2025-02-14**|**Janus: Collaborative Vision Transformer Under Dynamic Network Environment**|Linyi Jiang et.al.|[2502.10047v1](http://arxiv.org/abs/2502.10047v1)|null|
|**2025-02-14**|**Unsupervised Entity Alignment Based on Personalized Discriminative Rooted Tree**|Yaming Yang et.al.|[2502.10044v1](http://arxiv.org/abs/2502.10044v1)|null|
|**2025-02-14**|**POI-Enhancer: An LLM-based Semantic Enhancement Framework for POI Representation Learning**|Jiawei Cheng et.al.|[2502.10038v1](http://arxiv.org/abs/2502.10038v1)|null|
|**2025-02-14**|**Probabilistic Lexical Manifold Construction in Large Language Models via Hierarchical Vector Field Interpolation**|Clive Pendleton et.al.|[2502.10013v1](http://arxiv.org/abs/2502.10013v1)|null|
|**2025-02-14**|**Dream to Drive: Model-Based Vehicle Control Using Analytic World Models**|Asen Nachkov et.al.|[2502.10012v1](http://arxiv.org/abs/2502.10012v1)|null|
|**2025-02-14**|**SciClaimHunt: A Large Dataset for Evidence-based Scientific Claim Verification**|Sujit Kumar et.al.|[2502.10003v1](http://arxiv.org/abs/2502.10003v1)|null|
|**2025-02-14**|**EmbBERT-Q: Breaking Memory Barriers in Embedded NLP**|Riccardo Bravin et.al.|[2502.10001v1](http://arxiv.org/abs/2502.10001v1)|null|
|**2025-02-14**|**Decision Information Meets Large Language Models: The Future of Explainable Operations Research**|Yansen Zhang et.al.|[2502.09994v1](http://arxiv.org/abs/2502.09994v1)|null|
|**2025-02-14**|**Large Language Diffusion Models**|Shen Nie et.al.|[2502.09992v1](http://arxiv.org/abs/2502.09992v1)|null|
|**2025-02-14**|**X-Boundary: Establishing Exact Safety Boundary to Shield LLMs from Multi-Turn Jailbreaks without Compromising Usability**|Xiaoya Lu et.al.|[2502.09990v1](http://arxiv.org/abs/2502.09990v1)|null|
|**2025-02-14**|**LaRA: Benchmarking Retrieval-Augmented Generation and Long-Context LLMs - No Silver Bullet for LC or RAG Routing**|Kuan Li et.al.|[2502.09977v1](http://arxiv.org/abs/2502.09977v1)|null|
|**2025-02-14**|**Has My System Prompt Been Used? Large Language Model Prompt Membership Inference**|Roman Levin et.al.|[2502.09974v1](http://arxiv.org/abs/2502.09974v1)|null|
|**2025-02-14**|**Conditional Latent Coding with Learnable Synthesized Reference for Deep Image Compression**|Siqi Wu et.al.|[2502.09971v1](http://arxiv.org/abs/2502.09971v1)|null|
|**2025-02-14**|**Data Valuation using Neural Networks for Efficient Instruction Fine-Tuning**|Ishika Agarwal et.al.|[2502.09969v1](http://arxiv.org/abs/2502.09969v1)|[link](https://github.com/agarwalishika/NN-CIFT)|
|**2025-02-14**|**KGGen: Extracting Knowledge Graphs from Plain Text with Language Models**|Belinda Mo et.al.|[2502.09956v1](http://arxiv.org/abs/2502.09956v1)|null|
|**2025-02-14**|**Diverse Inference and Verification for Advanced Reasoning**|Iddo Drori et.al.|[2502.09955v1](http://arxiv.org/abs/2502.09955v1)|null|
|**2025-02-14**|**Using MRNet to Predict Lunar Rock Categories Detected by Chang'e 5 Probe**|Jin Cui et.al.|[2502.09952v1](http://arxiv.org/abs/2502.09952v1)|null|
|**2025-02-14**|**Analyzing Patient Daily Movement Behavior Dynamics Using Two-Stage Encoding Model**|Jin Cui et.al.|[2502.09947v1](http://arxiv.org/abs/2502.09947v1)|null|
|**2025-02-14**|**Self-Supervised Learning for Neural Topic Models with Variance-Invariance-Covariance Regularization**|Weiran Xu et.al.|[2502.09944v1](http://arxiv.org/abs/2502.09944v1)|null|
|**2025-02-14**|**A Preliminary Exploration with GPT-4o Voice Mode**|Yu-Xiang Lin et.al.|[2502.09940v1](http://arxiv.org/abs/2502.09940v1)|null|
|**2025-02-14**|**MIR-Bench: Benchmarking LLM's Long-Context Intelligence via Many-Shot In-Context Inductive Reasoning**|Kai Yan et.al.|[2502.09933v1](http://arxiv.org/abs/2502.09933v1)|null|
|**2025-02-14**|**TransGUNet: Transformer Meets Graph-based Skip Connection for Medical Image Segmentation**|Ju-Hyeon Nam et.al.|[2502.09931v1](http://arxiv.org/abs/2502.09931v1)|null|
|**2025-02-14**|**Deep Tree Tensor Networks for Image Recognition**|Chang Nie et.al.|[2502.09928v1](http://arxiv.org/abs/2502.09928v1)|null|
|**2025-02-14**|**Granite Vision: a lightweight, open-source multimodal model for enterprise Intelligence**|Granite Vision Team et.al.|[2502.09927v1](http://arxiv.org/abs/2502.09927v1)|null|
|**2025-02-14**|**TaskGalaxy: Scaling Multi-modal Instruction Fine-tuning with Tens of Thousands Vision Task Types**|Jiankang Chen et.al.|[2502.09925v1](http://arxiv.org/abs/2502.09925v1)|null|
|**2025-02-14**|**Machine Learning for Phase Estimation in Satellite-to-Earth Quantum Communication**|Nathan K Long et.al.|[2502.09920v1](http://arxiv.org/abs/2502.09920v1)|null|
|**2025-02-14**|**AttenGluco: Multimodal Transformer-Based Blood Glucose Forecasting on AI-READI Dataset**|Ebrahim Farahmand et.al.|[2502.09919v1](http://arxiv.org/abs/2502.09919v1)|null|
|**2025-02-14**|**AutoS$^2$earch: Unlocking the Reasoning Potential of Large Models for Web-based Source Search**|Zhengqiu Zhu et.al.|[2502.09913v1](http://arxiv.org/abs/2502.09913v1)|null|
|**2025-02-14**|**The Ann Arbor Architecture for Agent-Oriented Programming**|Wei Dong et.al.|[2502.09903v1](http://arxiv.org/abs/2502.09903v1)|null|
|**2025-02-14**|**Artificial Intelligence in Spectroscopy: Advancing Chemistry from Prediction to Generation and Beyond**|Kehan Guo et.al.|[2502.09897v1](http://arxiv.org/abs/2502.09897v1)|null|
|**2025-02-14**|**ArchRAG: Attributed Community-based Hierarchical Retrieval-Augmented Generation**|Shu Wang et.al.|[2502.09891v1](http://arxiv.org/abs/2502.09891v1)|null|
|**2025-02-14**|**Video2Policy: Scaling up Manipulation Tasks in Simulation through Internet Videos**|Weirui Ye et.al.|[2502.09886v1](http://arxiv.org/abs/2502.09886v1)|null|
|**2025-02-14**|**Comprehensive Review of Neural Differential Equations for Time Series Analysis**|YongKyung Oh et.al.|[2502.09885v1](http://arxiv.org/abs/2502.09885v1)|null|
|**2025-02-14**|**FrGNet: A fourier-guided weakly-supervised framework for nuclear instance segmentation**|Peng Ling et.al.|[2502.09874v1](http://arxiv.org/abs/2502.09874v1)|null|
|**2025-02-14**|**A Taxonomy of Linguistic Expressions That Contribute To Anthropomorphism of Language Technologies**|Alicia DeVrio et.al.|[2502.09870v1](http://arxiv.org/abs/2502.09870v1)|null|
|**2025-02-14**|**Solvable Dynamics of Self-Supervised Word Embeddings and the Emergence of Analogical Reasoning**|Dhruva Karkada et.al.|[2502.09863v1](http://arxiv.org/abs/2502.09863v1)|null|
|**2025-02-14**|**Automated Hypothesis Validation with Agentic Sequential Falsifications**|Kexin Huang et.al.|[2502.09858v1](http://arxiv.org/abs/2502.09858v1)|null|
|**2025-02-14**|**Efficient Multitask Learning in Small Language Models Through Upside-Down Reinforcement Learning**|Yu-Chen Lin et.al.|[2502.09854v1](http://arxiv.org/abs/2502.09854v1)|null|
|**2025-02-14**|**HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation via Heterogeneous Knowledge Adaptation**|Tianwei Lin et.al.|[2502.09838v1](http://arxiv.org/abs/2502.09838v1)|null|
|**2025-02-14**|**Efficient Evaluation of Multi-Task Robot Policies With Active Experiment Selection**|Abrar Anwar et.al.|[2502.09829v1](http://arxiv.org/abs/2502.09829v1)|null|
|**2025-02-13**|**A Solver-Aided Hierarchical Language for LLM-Driven CAD Design**|Benjamin T. Jones et.al.|[2502.09819v1](http://arxiv.org/abs/2502.09819v1)|null|
|**2025-02-13**|**Statistical Coherence Alignment for Large Language Model Representation Learning Through Tensor Field Convergence**|Jonathan Gale et.al.|[2502.09815v1](http://arxiv.org/abs/2502.09815v1)|null|
|**2025-02-13**|**INJONGO: A Multicultural Intent Detection and Slot-filling Dataset for 16 African Languages**|Hao Yu et.al.|[2502.09814v1](http://arxiv.org/abs/2502.09814v1)|null|
|**2025-02-13**|**AgentGuard: Repurposing Agentic Orchestrator for Safety Evaluation of Tool Orchestration**|Jizhou Chen et.al.|[2502.09809v1](http://arxiv.org/abs/2502.09809v1)|null|
|**2025-02-13**|**Acute Lymphoblastic Leukemia Diagnosis Employing YOLOv11, YOLOv8, ResNet50, and Inception-ResNet-v2 Deep Learning Models**|Alaa Awad et.al.|[2502.09804v1](http://arxiv.org/abs/2502.09804v1)|null|
|**2025-02-13**|**Co-designing Large Language Model Tools for Project-Based Learning with K12 Educators**|Prerna Ravi et.al.|[2502.09799v1](http://arxiv.org/abs/2502.09799v1)|null|
|**2025-02-13**|**A Survey on LLM-based News Recommender Systems**|Rongyao Wang et.al.|[2502.09797v1](http://arxiv.org/abs/2502.09797v1)|null|
|**2025-02-13**|**TableTalk: Scaffolding Spreadsheet Development with a Language Agent**|Jenny T. Liang et.al.|[2502.09787v1](http://arxiv.org/abs/2502.09787v1)|null|
|**2025-02-13**|**Improving Acoustic Side-Channel Attacks on Keyboards Using Transformers and Large Language Models**|Jin Hyun Park et.al.|[2502.09782v1](http://arxiv.org/abs/2502.09782v1)|null|
|**2025-02-13**|**Incentivize without Bonus: Provably Efficient Model-based Online Multi-agent RL for Markov Games**|Tong Yang et.al.|[2502.09780v1](http://arxiv.org/abs/2502.09780v1)|null|
|**2025-02-13**|**Prompt and circumstance: A word-by-word LLM prompting approach to interlinear glossing for low-resource languages**|Micha Elsner et.al.|[2502.09778v1](http://arxiv.org/abs/2502.09778v1)|null|
|**2025-02-13**|**Non-Markovian Discrete Diffusion with Causal Language Models**|Yangtian Zhang et.al.|[2502.09767v1](http://arxiv.org/abs/2502.09767v1)|null|
|**2025-02-13**|**Differential Adjusted Parity for Learning Fair Representations**|Bucher Sahyouni et.al.|[2502.09765v1](http://arxiv.org/abs/2502.09765v1)|null|

#### Abstracts
##### **MM-RLHF: The Next Step Forward in Multimodal LLM Alignment**
2502.10391v1 by Yi-Fan Zhang, Tao Yu, Haochen Tian, Chaoyou Fu, Peiyan Li, Jianshu Zeng, Wulin Xie, Yang Shi, Huanyu Zhang, Junkang Wu, Xue Wang, Yibo Hu, Bin Wen, Fan Yang, Zhang Zhang, Tingting Gao, Di Zhang, Liang Wang, Rong Jin, Tieniu Tan

Despite notable advancements in Multimodal Large Language Models (MLLMs),
most state-of-the-art models have not undergone thorough alignment with human
preferences. This gap exists because current alignment research has primarily
achieved progress in specific areas (e.g., hallucination reduction), while the
broader question of whether aligning models with human preferences can
systematically enhance MLLM capability remains largely unexplored. To this end,
we introduce MM-RLHF, a dataset containing $\mathbf{120k}$ fine-grained,
human-annotated preference comparison pairs. This dataset represents a
substantial advancement over existing resources, offering superior size,
diversity, annotation granularity, and quality. Leveraging this dataset, we
propose several key innovations to improve both the quality of reward models
and the efficiency of alignment algorithms. Notably, we introduce a
Critique-Based Reward Model, which generates critiques of model outputs before
assigning scores, offering enhanced interpretability and more informative
feedback compared to traditional scalar reward mechanisms. Additionally, we
propose Dynamic Reward Scaling, a method that adjusts the loss weight of each
sample according to the reward signal, thereby optimizing the use of
high-quality comparison pairs. Our approach is rigorously evaluated across
$\mathbf{10}$ distinct dimensions and $\mathbf{27}$ benchmarks, with results
demonstrating significant and consistent improvements in model performance.
Specifically, fine-tuning LLaVA-ov-7B with MM-RLHF and our alignment algorithm
leads to a $\mathbf{19.5}$% increase in conversational abilities and a
$\mathbf{60}$% improvement in safety.
  We have open-sourced the preference dataset, reward model, training and
evaluation code, as well as reward modeling and safety benchmarks. For more
details, please visit our project page: https://mm-rlhf.github.io.

摘要：<paragraph>儘管多模態大型語言模型 (MMLM) 有顯著的進展，
大多數最先進的模型尚未與人類
偏好進行徹底比對。這個差距存在是因為目前的比對研究主要
在特定領域（例如，減少幻覺）取得進展，而
是否將模型與人類偏好比對可以
系統性地增強 MLLM 能力的更廣泛問題仍然很大程度上未被探索。為此，
我們引入了 MM-RLHF，一個包含 $\mathbf{120k}$ 個細緻的，
人類標註的偏好比較對的資料集。此資料集代表了
比現有資源的重大進展，提供了優越的大小、
多樣性、標註粒度和品質。利用此資料集，我們
提出了一些關鍵創新，以提高獎勵模型的品質和
比對演算法的效率。值得注意的是，我們引入了
基於批評的獎勵模型，它會在
在指定分數之前產生模型輸出的批評，與傳統的
標量獎勵機制相比，提供了增強的可解釋性和更具資訊性的
回饋。此外，我們提出了動態獎勵調整，一種根據
獎勵信號調整每個範例的損失權重的，從而最佳化
高品質比較對的使用。我們的做法在
$\mathbf{10}$ 個不同的維度和 $\mathbf{27}$ 個基準上進行了嚴格評估，結果
證明模型效能有顯著且一致的改善。
具體來說，使用 MM-RLHF 和我們的比對演算法微調 LLaVA-ov-7B
導致對話能力提升 $\mathbf{19.5}$%，並且
安全性改善了 $\mathbf{60}$%。
我們已經開源了偏好資料集、獎勵模型、訓練和
評估程式碼，以及獎勵建模和安全性基準。有關更多
詳細資訊，請訪問我們的專案頁面：https://mm-rlhf.github.io。</paragraph>

##### **Region-Adaptive Sampling for Diffusion Transformers**
2502.10389v1 by Ziming Liu, Yifan Yang, Chengruidong Zhang, Yiqi Zhang, Lili Qiu, Yang You, Yuqing Yang

Diffusion models (DMs) have become the leading choice for generative tasks
across diverse domains. However, their reliance on multiple sequential forward
passes significantly limits real-time performance. Previous acceleration
methods have primarily focused on reducing the number of sampling steps or
reusing intermediate results, failing to leverage variations across spatial
regions within the image due to the constraints of convolutional U-Net
structures. By harnessing the flexibility of Diffusion Transformers (DiTs) in
handling variable number of tokens, we introduce RAS, a novel, training-free
sampling strategy that dynamically assigns different sampling ratios to regions
within an image based on the focus of the DiT model. Our key observation is
that during each sampling step, the model concentrates on semantically
meaningful regions, and these areas of focus exhibit strong continuity across
consecutive steps. Leveraging this insight, RAS updates only the regions
currently in focus, while other regions are updated using cached noise from the
previous step. The model's focus is determined based on the output from the
preceding step, capitalizing on the temporal consistency we observed. We
evaluate RAS on Stable Diffusion 3 and Lumina-Next-T2I, achieving speedups up
to 2.36x and 2.51x, respectively, with minimal degradation in generation
quality. Additionally, a user study reveals that RAS delivers comparable
qualities under human evaluation while achieving a 1.6x speedup. Our approach
makes a significant step towards more efficient diffusion transformers,
enhancing their potential for real-time applications.

摘要：擴散模型 (DM) 已成為跨領域生成任務的首選。然而，它們依賴於多個順序的前向傳遞，這顯著限制了實時效能。先前的加速方法主要集中於減少採樣步驟的數量或重複使用中間結果，由於卷積 U-Net 結構的限制，無法利用影像中各空間區域的變化。透過利用擴散Transformer (DiT) 在處理可變數量權杖時的靈活性，我們引入了 RAS，這是一種新穎的、無需訓練的採樣策略，可根據 DiT 模型的焦點，動態地將不同的採樣比率分配給影像中的區域。我們的關鍵觀察是，在每個採樣步驟中，模型都集中在語義上有意義的區域，而這些焦點區域在連續的步驟中展現出強烈的連續性。利用這個見解，RAS 僅更新目前焦點所在的區域，而其他區域則使用來自前一步驟的快取雜訊進行更新。該模型的焦點取決於前一步驟的輸出，並利用我們觀察到的時間一致性。我們在 Stable Diffusion 3 和 Lumina-Next-T2I 上評估 RAS，分別達到 2.36 倍和 2.51 倍的加速，而生成品質的降低幅度很小。此外，一項使用者研究顯示，RAS 在人類評估下提供了可比較的品質，同時實現了 1.6 倍的加速。我們的做法朝著更有效率的擴散Transformer邁出了一大步，提升了它們在實時應用中的潛力。

##### **Aspect-Oriented Summarization for Psychiatric Short-Term Readmission Prediction**
2502.10388v1 by WonJin Yoon, Boyu Ren, Spencer Thomas, Chanwhi Kim, Guergana Savova, Mei-Hua Hall, Timothy Miller

Recent progress in large language models (LLMs) has enabled the automated
processing of lengthy documents even without supervised training on a
task-specific dataset. Yet, their zero-shot performance in complex tasks as
opposed to straightforward information extraction tasks remains suboptimal. One
feasible approach for tasks with lengthy, complex input is to first summarize
the document and then apply supervised fine-tuning to the summary. However, the
summarization process inevitably results in some loss of information. In this
study we present a method for processing the summaries of long documents aimed
to capture different important aspects of the original document. We hypothesize
that LLM summaries generated with different aspect-oriented prompts contain
different \textit{information signals}, and we propose methods to measure these
differences. We introduce approaches to effectively integrate signals from
these different summaries for supervised training of transformer models. We
validate our hypotheses on a high-impact task -- 30-day readmission prediction
from a psychiatric discharge -- using real-world data from four hospitals, and
show that our proposed method increases the prediction performance for the
complex task of predicting patient outcome.

摘要：大型語言模型 (LLM) 的最新進展使得即使沒有針對特定任務資料集進行監督式訓練，也能自動處理冗長的文檔。然而，它們在複雜任務中的零次學習表現，與直接的資訊萃取任務相比，仍然不是最佳的。對於有冗長、複雜輸入的任務，一種可行的做法是先摘要文件，然後對摘要進行監督式微調。然而，摘要過程不可避免會導致一些資訊遺失。在本研究中，我們提出了一種處理長文摘要的方法，旨在擷取原始文件中的不同重要面向。我們假設使用不同面向提示產生的 LLM 摘要包含不同的「資訊訊號」，並且我們提出方法來衡量這些差異。我們引入了有效整合來自這些不同摘要的訊號，以進行Transformer模型的監督式訓練的方法。我們在一個高影響力的任務上驗證了我們的假設——從精神科出院預測 30 天再入院——使用來自四家醫院的真實世界資料，並證明我們提出的方法增加了預測複雜的患者預後任務的預測效能。

##### **Simplifying DINO via Coding Rate Regularization**
2502.10385v1 by Ziyang Wu, Jingyuan Zhang, Druv Pai, XuDong Wang, Chandan Singh, Jianwei Yang, Jianfeng Gao, Yi Ma

DINO and DINOv2 are two model families being widely used to learn
representations from unlabeled imagery data at large scales. Their learned
representations often enable state-of-the-art performance for downstream tasks,
such as image classification and segmentation. However, they employ many
empirically motivated design choices and their training pipelines are highly
complex and unstable -- many hyperparameters need to be carefully tuned to
ensure that the representations do not collapse -- which poses considerable
difficulty to improving them or adapting them to new domains. In this work, we
posit that we can remove most such-motivated idiosyncrasies in the pre-training
pipelines, and only need to add an explicit coding rate term in the loss
function to avoid collapse of the representations. As a result, we obtain
highly simplified variants of the DINO and DINOv2 which we call SimDINO and
SimDINOv2, respectively. Remarkably, these simplified models are more robust to
different design choices, such as network architecture and hyperparameters, and
they learn even higher-quality representations, measured by performance on
downstream tasks, offering a Pareto improvement over the corresponding DINO and
DINOv2 models. This work highlights the potential of using simplifying design
principles to improve the empirical practice of deep learning.

摘要：DINO 和 DINOv2 是兩個模型系列，它們被廣泛用於從大型未標記影像資料中學習表徵。它們學習到的表徵通常能讓下游任務（例如影像分類和分割）達到最先進的效能。然而，它們採用許多以經驗為依據的設計選擇，而且它們的訓練管道非常複雜且不穩定，需要仔細調整許多超參數，以確保表徵不會崩潰，這對改善它們或將它們適應到新領域造成了相當大的困難。在這項工作中，我們假設我們可以在預訓練管道中移除大多數此類動機特質，而且只需要在損失函數中加入明確的編碼率項，就能避免表徵崩潰。因此，我們獲得了 DINO 和 DINOv2 的高度簡化變體，我們分別稱之為 SimDINO 和 SimDINOv2。值得注意的是，這些簡化的模型對不同的設計選擇（例如網路架構和超參數）更為穩健，而且它們學習到品質更高的表徵，這以在下游任務中的效能來衡量，對應應的 DINO 和 DINOv2 模型提供了帕雷托改善。這項工作突顯了使用簡化設計原則來改善深度學習的實務潛力。

##### **Unknown Word Detection for English as a Second Language (ESL) Learners Using Gaze and Pre-trained Language Models**
2502.10378v1 by Jiexin Ding, Bowen Zhao, Yuntao Wang, Xinyun Liu, Rui Hao, Ishan Chatterjee, Yuanchun Shi

English as a Second Language (ESL) learners often encounter unknown words
that hinder their text comprehension. Automatically detecting these words as
users read can enable computing systems to provide just-in-time definitions,
synonyms, or contextual explanations, thereby helping users learn vocabulary in
a natural and seamless manner. This paper presents EyeLingo, a
transformer-based machine learning method that predicts the probability of
unknown words based on text content and eye gaze trajectory in real time with
high accuracy. A 20-participant user study revealed that our method can achieve
an accuracy of 97.6%, and an F1-score of 71.1%. We implemented a real-time
reading assistance prototype to show the effectiveness of EyeLingo. The user
study shows improvement in willingness to use and usefulness compared to
baseline methods.

摘要：身為第二語言（ESL）學習者，常會遇到阻礙文本理解的生字。系統能自動偵測使用者閱讀時遇到的生字，提供即時定義、同義字或上下文解釋，幫助使用者自然且無縫地學習字彙。本文提出 EyeLingo，一種基於 Transformer 的機器學習方法，可根據文字內容和眼球注視軌跡即時預測生字的機率，且準確度極高。一項針對 20 位參與者的使用者研究顯示，我們的模型能達到 97.6% 的準確度和 71.1% 的 F1 值。我們實作了一個即時閱讀輔助原型來展示 EyeLingo 的效能。與基線方法相比，使用者研究顯示出更高的使用意願和實用性。

##### **OWLS: Scaling Laws for Multilingual Speech Recognition and Translation Models**
2502.10373v1 by William Chen, Jinchuan Tian, Yifan Peng, Brian Yan, Chao-Han Huck Yang, Shinji Watanabe

Neural scaling laws offer valuable insights for designing robust sequence
processing architectures. While these laws have been extensively characterized
in other modalities, their behavior in speech remains comparatively
underexplored. In this work, we introduce OWLS, an open-access, reproducible
suite of multilingual speech recognition and translation models spanning 0.25B
to 18B parameters, with the 18B version being the largest speech model, to the
best of our knowledge. OWLS leverages up to 360K hours of public speech data
across 150 languages, enabling a systematic investigation into how data, model,
and compute scaling each influence performance in multilingual speech tasks. We
use OWLS to derive neural scaling laws, showing how final performance can be
reliably predicted when scaling. One of our key findings is that scaling
enhances performance on low-resource languages/dialects, helping to mitigate
bias and improve the accessibility of speech technologies. Finally, we show how
OWLS can be used to power new research directions by discovering emergent
abilities in large-scale speech models. Model checkpoints will be released on
https://huggingface.co/collections/espnet/owls-scaling-laws-for-speech-recognition-and-translation-67ab7f991c194065f057ce8d
for future studies.

摘要：神經縮放定律提供有價值的見解，用於設計強健的序列處理架構。雖然這些定律已在其他模式中廣泛描述，但它們在語音中的行為仍然相對未被探討。在這項工作中，我們引入了 OWLS，這是一個開放獲取、可複製的多語言語音辨識和翻譯模型套件，涵蓋 0.25B 到 18B 個參數，其中 18B 版本是最大的語音模型，就我們所知。OWLS 充分利用了 150 種語言中長達 360K 小時的公開語音數據，從而能夠系統性地探討數據、模型和運算縮放如何影響多語言語音任務中的效能。我們使用 OWLS 推導神經縮放定律，顯示在縮放時如何可靠地預測最終效能。我們的其中一項主要發現是縮放增強了低資源語言/方言的效能，有助於減輕偏差並改善語音技術的可及性。最後，我們展示了如何使用 OWLS 推動新的研究方向，方法是在大型語音模型中發現新興的能力。模型檢查點將在 https://huggingface.co/collections/espnet/owls-scaling-laws-for-speech-recognition-and-translation-67ab7f991c194065f057ce8d 上發布，以供將來的研究使用。

##### **Enhancing Multilingual LLM Pretraining with Model-Based Data Selection**
2502.10361v1 by Bettina Messmer, Vinko Sabolčec, Martin Jaggi

Dataset curation has become a basis for strong large language model (LLM)
performance. While various rule-based filtering heuristics exist for English
and multilingual datasets, model-based filtering techniques have primarily
focused on English. To address the disparity stemming from limited research on
non-English languages, we propose a model-based filtering framework for
multilingual datasets that aims to identify a diverse set of structured and
knowledge-rich samples. Our approach emphasizes transparency, simplicity, and
efficiency, leveraging Transformer- and FastText-based classifiers to ensure
the broad accessibility of our technique and data. We conduct comprehensive
ablation studies on the FineWeb-2 web crawl dataset across diverse language
families, scripts, and resource availability to demonstrate the effectiveness
of our method. Training a 1B-parameter Llama model for 70B and 119B tokens, our
approach can match the baseline MMLU score with as little as 15% of the
training tokens, while also improving across other benchmarks. These findings
provide strong evidence for the generalizability of our approach to other
languages. As a result, we extend our framework to 20 languages for which we
release the refined pretraining datasets.

摘要：資料集策展已成為強大的大型語言模型 (LLM) 效能的基礎。雖然針對英文和多語言資料集存在各種基於規則的過濾啟發法，但基於模型的過濾技術主要集中在英文上。為了解決源自對非英文語言研究有限的不平等，我們提出了一個針對多語言資料集的基於模型的過濾架構，旨在識別一組結構化且富含知識的樣本。我們的做法強調透明度、簡潔性和效率，利用 Transformer 和 FastText 為基礎的分類器來確保我們技術和資料的廣泛可及性。我們對 FineWeb-2 網路爬取資料集進行了全面的消融研究，涵蓋不同的語言系列、腳本和資源可用性，以證明我們方法的有效性。訓練一個 1B 參數的 Llama 模型，分別使用 70B 和 119B 個詞彙，我們的做法可以匹配基準 MMLU 分數，而訓練詞彙量僅為 15%，同時也能在其他基準中獲得改進。這些發現為我們的方法對其他語言的普遍性提供了強有力的證據。因此，我們將我們的架構擴展到 20 種語言，並為其發布精煉的預訓練資料集。

##### **Agentic Verification for Ambiguous Query Disambiguation**
2502.10352v1 by Youngwon Lee, Seung-won Hwang, Ruofan Wu, Feng Yan, Danmei Xu, Moutasem Akkad, Zhewei Yao, Yuxiong He

In this work, we tackle the challenge of disambiguating queries in
retrieval-augmented generation (RAG) to diverse yet answerable interpretations.
State-of-the-arts follow a Diversify-then-Verify (DtV) pipeline, where diverse
interpretations are generated by an LLM, later used as search queries to
retrieve supporting passages. Such a process may introduce noise in either
interpretations or retrieval, particularly in enterprise settings, where LLMs
-- trained on static data -- may struggle with domain-specific disambiguations.
Thus, a post-hoc verification phase is introduced to prune noises. Our
distinction is to unify diversification with verification by incorporating
feedback from retriever and generator early on. This joint approach improves
both efficiency and robustness by reducing reliance on multiple retrieval and
inference steps, which are susceptible to cascading errors. We validate the
efficiency and effectiveness of our method, Verified-Diversification with
Consolidation (VERDICT), on the widely adopted ASQA benchmark to achieve
diverse yet verifiable interpretations. Empirical results show that VERDICT
improves grounding-aware F1 score by an average of 23% over the strongest
baseline across different backbone LLMs.

摘要：在這項工作中，我們應對了在檢索增強生成 (RAG) 中消除查詢歧義的挑戰，以獲得多元且可回答的詮釋。最先進的技術遵循多元化後驗證 (DtV) 管線，其中不同的詮釋是由 LLM 生成的，稍後用作檢索查詢以檢索支援段落。這樣的過程可能會在詮釋或檢索中引入雜訊，特別是在企業環境中，在靜態資料上訓練的 LLM 可能難以進行特定領域的消除歧義。因此，引入了事後驗證階段以消除雜訊。我們的區別在於透過及早納入檢索器和生成器的回饋，將多元化與驗證統一起來。這種聯合方法透過減少對多重檢索和推論步驟的依賴，來改善效率和穩健性，而這些步驟容易發生連鎖錯誤。我們在廣泛採用的 ASQA 基準上驗證了我們的方法，即合併驗證的多元化 (VERDICT) 的效率和有效性，以達成多元且可驗證的詮釋。經驗結果顯示，VERDICT 將以接地為基礎的 F1 分數平均提高 23%，優於不同主幹 LLM 的最強基線。

##### **Organize the Web: Constructing Domains Enhances Pre-Training Data Curation**
2502.10341v1 by Alexander Wettig, Kyle Lo, Sewon Min, Hannaneh Hajishirzi, Danqi Chen, Luca Soldaini

Modern language models are trained on large, unstructured datasets consisting
of trillions of tokens and obtained by crawling the web. The unstructured
nature makes it difficult to reason about their contents and develop systematic
approaches to data curation. In this paper, we unpack monolithic web corpora by
developing taxonomies of their contents and organizing them into domains. We
introduce WebOrganizer, a framework for organizing web pages in terms of both
their topic and format. Using these two complementary notions of domains, we
automatically annotate pre-training data by distilling annotations from a large
language model into efficient classifiers. This allows us to study how data
from different domains should be mixed to improve models on downstream tasks,
and we show that we can combine insights about effective topics and formats to
further boost performance. We demonstrate that our domain mixing also improves
existing methods that select data based on quality. Furthermore, we study and
compare how quality-based methods will implicitly change the domain mixture.
Overall, our work demonstrates that constructing and mixing domains provides a
valuable complement to quality-based data curation methods, opening new avenues
for effective and insightful pre-training data curation.

摘要：現代語言模型在龐大且非結構化的資料集上進行訓練，這些資料集包含數兆個符號，並透過網路爬蟲取得。非結構化的本質使得難以推論其內容並開發系統性的資料整理方法。在本文中，我們透過開發其內容的分類法並將它們組織成網域，來解構單一網路語料庫。我們介紹 WebOrganizer，一個用於組織網頁的架構，同時考量它們的主題和格式。使用這兩個網域互補概念，我們透過從大型語言模型中萃取註解到高效分類器中，自動註解預訓練資料。這讓我們得以研究如何混合來自不同網域的資料，以改善下游任務的模型，並且我們展示我們可以結合關於有效主題和格式的見解，以進一步提升效能。我們證明我們的網域混合也改善了基於品質選擇資料的現有方法。此外，我們研究並比較基於品質的方法將如何隱含地改變網域混合。整體而言，我們的研究證明建構和混合網域，為基於品質的資料整理方法提供了有價值的補充，為有效且有見地的預訓練資料整理開啟了新途徑。

##### **STAR: Spectral Truncation and Rescale for Model Merging**
2502.10339v1 by Yu-Ang Lee, Ching-Yun Ko, Tejaswini Pedapati, I-Hsin Chung, Mi-Yen Yeh, Pin-Yu Chen

Model merging is an efficient way of obtaining a multi-task model from
several pretrained models without further fine-tuning, and it has gained
attention in various domains, including natural language processing (NLP).
Despite the efficiency, a key challenge in model merging is the seemingly
inevitable decrease in task performance as the number of models increases. In
this paper, we propose $\mathbf{S}$pectral $\mathbf{T}$runcation $\mathbf{A}$nd
$\mathbf{R}$escale (STAR) that aims at mitigating ``merging conflicts'' by
truncating small components in the respective spectral spaces, which is
followed by an automatic parameter rescaling scheme to retain the nuclear norm
of the original matrix. STAR requires no additional inference on original
training data and is robust to hyperparamater choice. We demonstrate the
effectiveness of STAR through extensive model merging cases on diverse NLP
tasks. Specifically, STAR works robustly across varying model sizes, and can
outperform baselines by 4.2$\%$ when merging 12 models on Flan-T5. Our code is
publicly available at https://github.com/IBM/STAR.

摘要：模型合併是一種從多個預訓練模型中取得多任務模型的有效方式，無需進一步微調，且在各種領域中受到關注，包括自然語言處理 (NLP)。儘管效率高，模型合併中的主要挑戰在於隨著模型數量增加，任務執行效能似乎不可避免地下降。在本文中，我們提出 $\mathbf{S}$pectral $\mathbf{T}$runcation $\mathbf{A}$nd $\mathbf{R}$escale (STAR)，其目標在於透過截斷各個特徵空間中的小組成，來減輕「合併衝突」，接著使用自動參數縮放機制來保留原始矩陣的核範數。STAR 不需要對原始訓練資料進行額外的推論，且對於超參數選擇具有穩健性。我們透過在各種 NLP 任務中進行廣泛的模型合併案例，來證明 STAR 的有效性。具體而言，STAR 在各種模型大小中都能穩健地運作，並且在 Flan-T5 上合併 12 個模型時，可以比基準高出 4.2%。我們的程式碼已公開於 https://github.com/IBM/STAR。

##### **Evaluating the Meta- and Object-Level Reasoning of Large Language Models for Question Answering**
2502.10338v1 by Nick Ferguson, Liane Guillou, Alan Bundy, Kwabena Nuamah

Large Language Models (LLMs) excel in natural language tasks but still face
challenges in Question Answering (QA) tasks requiring complex, multi-step
reasoning. We outline the types of reasoning required in some of these tasks,
and reframe them in terms of meta-level reasoning (akin to high-level strategic
reasoning or planning) and object-level reasoning (embodied in lower-level
tasks such as mathematical reasoning). Franklin, a novel dataset with
requirements of meta- and object-level reasoning, is introduced and used along
with three other datasets to evaluate four LLMs at question answering tasks
requiring multiple steps of reasoning. Results from human annotation studies
suggest LLMs demonstrate meta-level reasoning with high frequency, but struggle
with object-level reasoning tasks in some of the datasets used. Additionally,
evidence suggests that LLMs find the object-level reasoning required for the
questions in the Franklin dataset challenging, yet they do exhibit strong
performance with respect to the meta-level reasoning requirements.

摘要：大型語言模型 (LLM) 在自然語言任務中表現出色，但在需要複雜的多步驟推理的問答 (QA) 任務中仍面臨挑戰。我們概述了這些任務中需要的一些推理類型，並根據元級推理（類似於高級策略推理或規劃）和物件級推理（體現在數學推理等較低層級任務中）重新定義它們。Franklin 是個新穎的資料集，需要元級和物件級推理，並與其他三個資料集一起使用，以評估四個 LLM 在需要多個推理步驟的問答任務中的表現。人類註釋研究的結果表明，LLM 以高頻率展示元級推理，但在某些所用資料集中難以應付物件級推理任務。此外，證據表明，LLM 發現 Franklin 資料集中問題所需的物件級推理具有挑戰性，但它們確實在元級推理需求方面表現出強勁的表現。

##### **Process Reward Models for LLM Agents: Practical Framework and Directions**
2502.10325v1 by Sanjiban Choudhury

We introduce Agent Process Reward Models (AgentPRM), a simple and scalable
framework for training LLM agents to continually improve through interactions.
AgentPRM follows a lightweight actor-critic paradigm, using Monte Carlo
rollouts to compute reward targets and optimize policies. It requires minimal
modifications to existing RLHF pipelines, making it easy to integrate at scale.
Beyond AgentPRM, we propose InversePRM, which learns process rewards directly
from demonstrations without explicit outcome supervision. We also explore key
challenges and opportunities, including exploration, process reward shaping,
and model-predictive reasoning. We evaluate on ALFWorld benchmark, show that
small 3B models trained with AgentPRM and InversePRM outperform strong GPT-4o
baselines, and analyze test-time scaling, reward hacking, and more. Our code is
available at: https://github.com/sanjibanc/agent_prm.

摘要：我們介紹了代理程序獎勵模型 (AgentPRM)，這是一個簡單且可擴充的框架，用於訓練 LLM 代理程序透過互動持續改進。AgentPRM 遵循輕量級的 Actor-Critic 範例，使用蒙地卡羅滾動計算獎勵目標並最佳化策略。它只需要對現有的 RLHF 管線進行最小的修改，使其易於大規模整合。除了 AgentPRM，我們提出了 InversePRM，它直接從示範中學習過程獎勵，而無需明確的結果監督。我們還探討了關鍵挑戰和機會，包括探索、過程獎勵塑造和模型預測推理。我們在 ALFWorld 基準上進行評估，表明使用 AgentPRM 和 InversePRM 訓練的小型 3B 模型優於強大的 GPT-4o 基準，並分析測試時間縮放、獎勵破解等。我們的程式碼可於此處取得：https://github.com/sanjibanc/agent_prm。

##### **ExplainReduce: Summarising local explanations via proxies**
2502.10311v1 by Lauri Seppäläinen, Mudong Guo, Kai Puolamäki

Most commonly used non-linear machine learning methods are closed-box models,
uninterpretable to humans. The field of explainable artificial intelligence
(XAI) aims to develop tools to examine the inner workings of these closed
boxes. An often-used model-agnostic approach to XAI involves using simple
models as local approximations to produce so-called local explanations;
examples of this approach include LIME, SHAP, and SLISEMAP. This paper shows
how a large set of local explanations can be reduced to a small "proxy set" of
simple models, which can act as a generative global explanation. This reduction
procedure, ExplainReduce, can be formulated as an optimisation problem and
approximated efficiently using greedy heuristics.

摘要：最常用的非線性機器學習方法是黑箱模型，人類無法理解。可解釋人工智慧 (XAI) 領域旨在開發工具來檢查這些黑箱的內部運作。一種常用的與模型無關的 XAI 方法涉及使用簡單模型作為局部近似值來產生所謂的局部解釋；這種方法的範例包括 LIME、SHAP 和 SLISEMAP。本文展示了如何將一大組局部解釋簡化為一組簡單模型的「代理組」，它可以用作生成式全局解釋。這個簡化程序 ExplainReduce 可以表述為一個最佳化問題，並使用貪婪啟發法有效地進行近似。

##### **LLM-Powered Preference Elicitation in Combinatorial Assignment**
2502.10308v1 by Ermis Soumalias, Yanchen Jiang, Kehang Zhu, Michael Curry, Sven Seuken, David C. Parkes

We study the potential of large language models (LLMs) as proxies for humans
to simplify preference elicitation (PE) in combinatorial assignment. While
traditional PE methods rely on iterative queries to capture preferences, LLMs
offer a one-shot alternative with reduced human effort. We propose a framework
for LLM proxies that can work in tandem with SOTA ML-powered preference
elicitation schemes. Our framework handles the novel challenges introduced by
LLMs, such as response variability and increased computational costs. We
experimentally evaluate the efficiency of LLM proxies against human queries in
the well-studied course allocation domain, and we investigate the model
capabilities required for success. We find that our approach improves
allocative efficiency by up to 20%, and these results are robust across
different LLMs and to differences in quality and accuracy of reporting.

摘要：我們研究大型語言模型 (LLM) 作為人類代理人的潛力，以簡化組合式分配中的偏好引導 (PE)。雖然傳統的 PE 方法依賴於反覆查詢以捕捉偏好，但 LLM 提供了一種一次性的替代方案，可減少人類的努力。我們提出了一個 LLM 代理框架，該框架可以與 SOTA ML 驅動的偏好引導方案協同工作。我們的框架處理了 LLM 引入的新挑戰，例如響應變異性和增加的計算成本。我們在研究充分的課程分配領域中，透過實驗評估 LLM 代理相對於人類查詢的效率，並調查成功所需的模型功能。我們發現，我們的做法將配置效率提高了 20%，而這些結果對於不同的 LLM 以及報告品質和準確性的差異都具有穩健性。

##### **Reinforcement Learning in Strategy-Based and Atari Games: A Review of Google DeepMinds Innovations**
2502.10303v1 by Abdelrhman Shaheen, Anas Badr, Ali Abohendy, Hatem Alsaadawy, Nadine Alsayad

Reinforcement Learning (RL) has been widely used in many applications,
particularly in gaming, which serves as an excellent training ground for AI
models. Google DeepMind has pioneered innovations in this field, employing
reinforcement learning algorithms, including model-based, model-free, and deep
Q-network approaches, to create advanced AI models such as AlphaGo, AlphaGo
Zero, and MuZero. AlphaGo, the initial model, integrates supervised learning
and reinforcement learning to master the game of Go, surpassing professional
human players. AlphaGo Zero refines this approach by eliminating reliance on
human gameplay data, instead utilizing self-play for enhanced learning
efficiency. MuZero further extends these advancements by learning the
underlying dynamics of game environments without explicit knowledge of the
rules, achieving adaptability across various games, including complex Atari
games. This paper reviews the significance of reinforcement learning
applications in Atari and strategy-based games, analyzing these three models,
their key innovations, training processes, challenges encountered, and
improvements made. Additionally, we discuss advancements in the field of
gaming, including MiniZero and multi-agent models, highlighting future
directions and emerging AI models from Google DeepMind.

摘要：強化學習 (RL) 已廣泛應用於許多應用中，特別是在遊戲中，這是一個訓練 AI 模型的絕佳訓練場。Google DeepMind 在此領域率先創新，採用強化學習演算法，包括基於模型、無模型和深度 Q 網路方法，建立了先進的 AI 模型，例如 AlphaGo、AlphaGo Zero 和 MuZero。AlphaGo 是最初的模型，它整合了監督式學習和強化學習來掌握圍棋遊戲，超越了職業人類玩家。AlphaGo Zero 改進了這種方法，消除了對人類遊戲數據的依賴，而是利用自玩來提高學習效率。MuZero 進一步擴展了這些進展，學習遊戲環境的底層動態，而無需明確了解規則，並實現了跨越各種遊戲的適應性，包括複雜的 Atari 遊戲。本文回顧了強化學習應用在 Atari 和策略遊戲中的重要性，分析了這三種模型、它們的主要創新、訓練過程、遇到的挑戰和所做的改進。此外，我們還討論了遊戲領域的進步，包括 MiniZero 和多智能體模型，重點介紹了 Google DeepMind 未來的方向和新興 AI 模型。

##### **DeltaProduct: Increasing the Expressivity of DeltaNet Through Products of Householders**
2502.10297v1 by Julien Siems, Timur Carstensen, Arber Zela, Frank Hutter, Massimiliano Pontil, Riccardo Grazzi

Linear Recurrent Neural Networks (linear RNNs) have emerged as competitive
alternatives to Transformers for sequence modeling, offering efficient training
and linear-time inference. However, existing architectures face a fundamental
trade-off between expressivity and efficiency, dictated by the structure of
their state-transition matrices. While diagonal matrices used in architectures
like Mamba, GLA, or mLSTM yield fast runtime, they suffer from severely limited
expressivity. To address this, recent architectures such as (Gated) DeltaNet
and RWKVv7 adopted a diagonal plus rank-1 structure, allowing simultaneous
token-channel mixing, which overcomes some expressivity limitations with only a
slight decrease in training efficiency. Building on the interpretation of
DeltaNet's recurrence as performing one step of online gradient descent per
token on an associative recall loss, we introduce DeltaProduct, which instead
takes multiple ($n_h$) steps per token. This naturally leads to diagonal plus
rank-$n_h$ state-transition matrices, formed as products of $n_h$ generalized
Householder transformations, providing a tunable mechanism to balance
expressivity and efficiency and a stable recurrence. Through extensive
experiments, we demonstrate that DeltaProduct achieves superior state-tracking
and language modeling capabilities while exhibiting significantly improved
length extrapolation compared to DeltaNet. Additionally, we also strengthen the
theoretical foundation of DeltaNet's expressivity by proving that it can solve
dihedral group word problems in just two layers.

摘要：線性遞迴神經網路 (線性 RNN) 已成為 Transformer 的競爭替代方案，用於序列建模，提供高效訓練和線性時間推論。然而，現有架構面臨著表達力和效率之間的根本權衡，這取決於其狀態轉換矩陣的結構。雖然 Mamba、GLA 或 mLSTM 等架構中使用的對角矩陣產生快速的執行時間，但它們的表達力受到嚴重限制。為了解決這個問題，最近的架構，例如 (Gated) DeltaNet 和 RWKVv7 採用了對角線加秩 1 結構，允許同時進行令牌通道混合，這克服了某些表達力限制，而訓練效率僅略有下降。建立在將 DeltaNet 的遞迴解釋為對關聯召回損失對每個令牌執行一步線上梯度下降的基礎上，我們引入了 DeltaProduct，它對每個令牌採取多個 ($n_h$) 步驟。這自然會導致對角線加秩-$n_h$ 狀態轉換矩陣，形成為 $n_h$ 個廣義 Householder 轉換的乘積，提供了一個可調整的機制來平衡表達力和效率以及穩定的遞迴。通過廣泛的實驗，我們證明 DeltaProduct 在與 DeltaNet 相比時，實現了卓越的狀態追蹤和語言建模能力，同時展現出顯著改善的長度外推。此外，我們還通過證明它只需兩層就能解決二面體群字問題，來加強 DeltaNet 表達力的理論基礎。

##### **A Hybrid Cross-Stage Coordination Pre-ranking Model for Online Recommendation Systems**
2502.10284v1 by Binglei Zhao, Houying Qi, Guang Xu, Mian Ma, Xiwei Zhao, Feng Mei, Sulong Xu, Jinghe Hu

Large-scale recommendation systems often adopt cascading architecture
consisting of retrieval, pre-ranking, ranking, and re-ranking stages. With
strict latency requirements, pre-ranking utilizes lightweight models to perform
a preliminary selection from massive retrieved candidates. However, recent
works focus solely on improving consistency with ranking, relying exclusively
on downstream stages. Since downstream input is derived from the pre-ranking
output, they will exacerbate the sample selection bias (SSB) issue and Matthew
effect, leading to sub-optimal results. To address the limitation, we propose a
novel Hybrid Cross-Stage Coordination Pre-ranking model (HCCP) to integrate
information from upstream (retrieval) and downstream (ranking, re-ranking)
stages. Specifically, cross-stage coordination refers to the pre-ranking's
adaptability to the entire stream and the role of serving as a more effective
bridge between upstream and downstream. HCCP consists of Hybrid Sample
Construction and Hybrid Objective Optimization. Hybrid sample construction
captures multi-level unexposed data from the entire stream and rearranges them
to become the optimal guiding "ground truth" for pre-ranking learning. Hybrid
objective optimization contains the joint optimization of consistency and
long-tail precision through our proposed Margin InfoNCE loss. It is
specifically designed to learn from such hybrid unexposed samples, improving
the overall performance and mitigating the SSB issue. The appendix describes a
proof of the efficacy of the proposed loss in selecting potential positives.
Extensive offline and online experiments indicate that HCCP outperforms SOTA
methods by improving cross-stage coordination. It contributes up to 14.9% UCVR
and 1.3% UCTR in the JD E-commerce recommendation system. Concerning code
privacy, we provide a pseudocode for reference.

摘要：<paragraph>大型推薦系統通常採用由檢索、預排序、排序和重新排序階段組成的串聯架構。由於嚴格的延遲要求，預排序使用輕量級模型從大量檢索候選中執行初步選擇。然而，最近的工作僅專注於改善與排名的相容性，完全依賴於下游階段。由於下游輸入來自預排序輸出，它們會加劇樣本選擇偏差 (SSB) 問題和馬太效應，從而導致次優結果。為了解決這個限制，我們提出了一個新穎的混合跨階段協調預排序模型 (HCCP) 來整合來自上游（檢索）和下游（排名、重新排名）階段的信息。具體來說，跨階段協調是指預排序對整個流的可適應性以及作為上游和下游之間更有效橋樑的作用。HCCP 包含混合樣本構建和混合目標優化。混合樣本構建從整個流中捕獲多級未公開數據，並將它們重新排列，以成為預排序學習的最佳指導「基本事實」。混合目標優化包含通過我們提出的 Margin InfoNCE 損失對一致性和長尾精度的聯合優化。它專門設計用於從這些混合未公開樣本中學習，從而提高整體性能並減輕 SSB 問題。附錄描述了所提出的損失在選擇潛在正例中的功效證明。廣泛的離線和線上實驗表明，HCCP 通過改進跨階段協調而優於 SOTA 方法。它在 JD 電子商務推薦系統中貢獻了高達 14.9% 的 UCVR 和 1.3% 的 UCTR。關於代碼隱私，我們提供了偽代碼供參考。</paragraph>

##### **Probing Perceptual Constancy in Large Vision Language Models**
2502.10273v1 by Haoran Sun, Suyang Yu, Yijiang Li, Qingying Gao, Haiyun Lyu, Hokin Deng, Dezhi Luo

Perceptual constancy is the ability to maintain stable perceptions of objects
despite changes in sensory input, such as variations in distance, angle, or
lighting. This ability is crucial for recognizing visual information in a
dynamic world, making it essential for Vision-Language Models (VLMs). However,
whether VLMs are currently and theoretically capable of mastering this ability
remains underexplored. In this study, we evaluated 33 VLMs using 253
experiments across three domains: color, size, and shape constancy. The
experiments included single-image and video adaptations of classic cognitive
tasks, along with novel tasks in in-the-wild conditions, to evaluate the
models' recognition of object properties under varying conditions. We found
significant variability in VLM performance, with models performance in shape
constancy clearly dissociated from that of color and size constancy.

摘要：知覺恆常性是指在感官輸入發生變化（例如距離、角度或光線變化）時，維持對物體的穩定知覺的能力。這種能力對於在動態世界中識別視覺資訊至關重要，因此對視覺語言模型 (VLM) 至關重要。然而，VLM 目前和理論上是否有能力掌握這種能力仍未得到充分探討。在這項研究中，我們使用 253 項實驗評估了 33 個 VLM，涵蓋三個領域：顏色、大小和形狀恆常性。這些實驗包括經典認知任務的單一影像和影片改編，以及在野外條件下的新任務，以評估模型在不同條件下對物體屬性的識別能力。我們發現 VLM 效能有顯著差異，模型在形狀恆常性中的效能明顯不同於顏色和大小恆常性。

##### **Are Large Language Models the future crowd workers of Linguistics?**
2502.10266v1 by Iris Ferrazzo

Data elicitation from human participants is one of the core data collection
strategies used in empirical linguistic research. The amount of participants in
such studies may vary considerably, ranging from a handful to crowdsourcing
dimensions. Even if they provide resourceful extensive data, both of these
settings come alongside many disadvantages, such as low control of
participants' attention during task completion, precarious working conditions
in crowdsourcing environments, and time-consuming experimental designs. For
these reasons, this research aims to answer the question of whether Large
Language Models (LLMs) may overcome those obstacles if included in empirical
linguistic pipelines. Two reproduction case studies are conducted to gain
clarity into this matter: Cruz (2023) and Lombard et al. (2021). The two forced
elicitation tasks, originally designed for human participants, are reproduced
in the proposed framework with the help of OpenAI's GPT-4o-mini model. Its
performance with our zero-shot prompting baseline shows the effectiveness and
high versatility of LLMs, that tend to outperform human informants in
linguistic tasks. The findings of the second replication further highlight the
need to explore additional prompting techniques, such as Chain-of-Thought (CoT)
prompting, which, in a second follow-up experiment, demonstrates higher
alignment to human performance on both critical and filler items. Given the
limited scale of this study, it is worthwhile to further explore the
performance of LLMs in empirical Linguistics and in other future applications
in the humanities.

摘要：<paragraph>從人類參與者引出資料是實證語言研究中使用的核心資料收集策略之一。此類研究的參與者數量可能差異很大，從少數人到群眾外包的規模都有。即使他們提供了豐富且廣泛的資料，這兩種設定都伴隨著許多缺點，例如在完成任務期間對參與者注意力控制不佳、群眾外包環境中的工作條件不穩定，以及耗時的實驗設計。基於這些原因，本研究旨在回答一個問題，即如果將大型語言模型 (LLM) 納入實證語言管道，它們是否可以克服這些障礙。進行了兩個複製案例研究以釐清此事：Cruz (2023) 和 Lombard 等人 (2021)。最初為人類參與者設計的兩個強制引出任務，在建議的架構中使用 OpenAI 的 GPT-4o-mini 模型複製。它與我們的零次提示基準的效能展現了 LLM 的有效性和高度通用性，這往往在語言任務中優於人類線人。第二次複製的結果進一步強調了探索其他提示技術的必要性，例如思考鏈 (CoT) 提示，在第二次追蹤實驗中，它證明在關鍵項目和填空項目上與人類表現的一致性更高。鑑於本研究的規模有限，進一步探討 LLM 在實證語言學中的表現以及在人文學科中其他未來的應用是值得的。</paragraph>

##### **Large Language Models and Synthetic Data for Monitoring Dataset Mentions in Research Papers**
2502.10263v1 by Aivin V. Solatorio, Rafael Macalaba, James Liounis

Tracking how data is mentioned and used in research papers provides critical
insights for improving data discoverability, quality, and production. However,
manually identifying and classifying dataset mentions across vast academic
literature is resource-intensive and not scalable. This paper presents a
machine learning framework that automates dataset mention detection across
research domains by leveraging large language models (LLMs), synthetic data,
and a two-stage fine-tuning process. We employ zero-shot extraction from
research papers, an LLM-as-a-Judge for quality assessment, and a reasoning
agent for refinement to generate a weakly supervised synthetic dataset. The
Phi-3.5-mini instruct model is pre-fine-tuned on this dataset, followed by
fine-tuning on a manually annotated subset. At inference, a ModernBERT-based
classifier efficiently filters dataset mentions, reducing computational
overhead while maintaining high recall. Evaluated on a held-out manually
annotated sample, our fine-tuned model outperforms NuExtract-v1.5 and
GLiNER-large-v2.1 in dataset extraction accuracy. Our results highlight how
LLM-generated synthetic data can effectively address training data scarcity,
improving generalization in low-resource settings. This framework offers a
pathway toward scalable monitoring of dataset usage, enhancing transparency,
and supporting researchers, funders, and policymakers in identifying data gaps
and strengthening data accessibility for informed decision-making.

摘要：<paragraph>追蹤研究論文中如何提及和使用資料，可提供關鍵見解，用於改善資料的可發現性、品質和產出。然而，手動識別和分類跨越廣泛學術文獻的資料集提及是耗費資源且無法擴展的。本文提出一個機器學習架構，透過利用大型語言模型 (LLM)、合成資料和兩階段微調過程，自動化跨研究領域的資料集提及偵測。我們採用從研究論文中進行零次學習萃取、作為品質評估的 LLM 和用於改善的推理代理，以產生弱監督合成資料集。Phi-3.5-mini 指導模型在此資料集上進行預微調，然後在手動標註的子集上進行微調。在推理時，基於 ModernBERT 的分類器有效濾除資料集提及，同時在維持高召回率的情況下降低運算負擔。在手動標註的留出樣本上進行評估，我們微調的模型在資料集萃取準確度上優於 NuExtract-v1.5 和 GLiNER-large-v2.1。我們的結果突顯了 LLM 生成的合成資料如何有效解決訓練資料的稀少性，並改善低資源環境中的概化能力。此架構提供了一條途徑，可擴展監控資料集使用情況、增強透明度，並協助研究人員、資助者和政策制定者識別資料差距，並加強資料的可及性，以進行明智的決策制定。</paragraph>

##### **VisCon-100K: Leveraging Contextual Web Data for Fine-tuning Vision Language Models**
2502.10250v1 by Gokul Karthik Kumar, Iheb Chaabane, Kebin Wu

Vision-language models (VLMs) excel in various visual benchmarks but are
often constrained by the lack of high-quality visual fine-tuning data. To
address this challenge, we introduce VisCon-100K, a novel dataset derived from
interleaved image-text web documents. Our approach transforms 45K web documents
from the OBELICS dataset into 100K image conversation samples. We utilize
GPT-4V to generate image-contextual captions and OpenChat 3.5 model to convert
these captions into diverse free-form and multiple-choice question-answer
pairs. Integrating this dataset for fine-tuning considerably enhances VLM
performance across multiple benchmarks. Unlike methods that focus solely on
fine-grained visual content, our approach leverages accompanying web context,
yielding superior results. We also discover that a `leaky modality mix,' where
conversation samples contain questions answerable from both the image and its
contextual caption, outperforms non-leaky combinations of captions and Q\&A
pairs. VisCon-100k dataset shows strong performance with two popular VLM
approaches: text-only large language model (LLM) aligned with a vision encoder
using image captions data (ShareGPT4V-7b) and multimodally pretrained LLM
(IDEFICS2-8b) using interleaved image-text data. In addition to releasing the
VisCon-100K dataset, we provide a contextual captioner trained on this dataset,
facilitating scalable fine-tuning data generation for future research and
open-source applications. Using the same pipeline, but substituting our trained
contextual captioner for GPT-4V, we also release the larger VisCon-1M dataset.

摘要：視覺語言模型 (VLM) 在各種視覺基準測試中表現出色，但往往受到缺乏高品質視覺微調資料的限制。為了應對這個挑戰，我們引進 VisCon-100K，這是一個從交錯圖像文字網路文件中衍生的新資料集。我們的做法將 OBELICS 資料集中的 45K 網路文件轉換成 100K 的圖像對話範例。我們利用 GPT-4V 產生圖像情境標題，並使用 OpenChat 3.5 模型將這些標題轉換成多樣化的自由形式和多選題問答配對。整合這個資料集進行微調，大幅提升了 VLM 在多個基準測試中的表現。與僅專注於細微視覺內容的方法不同，我們的做法利用了隨附的網路情境，產生了更優異的結果。我們還發現「外洩的模式組合」，其中對話範例包含可從圖像及其情境標題回答的問題，其表現優於標題和問答配對的非外洩組合。VisCon-100k 資料集在兩種流行的 VLM 方法中表現出色：與使用圖像標題資料 (ShareGPT4V-7b) 的視覺編碼器對齊的純文字大型語言模型 (LLM)，以及使用交錯圖像文字資料的多模態預訓練 LLM (IDEFICS2-8b)。除了釋出 VisCon-100K 資料集，我們還提供了一個在這個資料集上訓練的情境標題產生器，促進了可擴充微調資料的產生，以利未來的研究和開源應用。使用相同的管道，但將我們訓練的情境標題產生器替換為 GPT-4V，我們也釋出了較大的 VisCon-1M 資料集。

##### **Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model**
2502.10248v1 by Guoqing Ma, Haoyang Huang, Kun Yan, Liangyu Chen, Nan Duan, Shengming Yin, Changyi Wan, Ranchen Ming, Xiaoniu Song, Xing Chen, Yu Zhou, Deshan Sun, Deyu Zhou, Jian Zhou, Kaijun Tan, Kang An, Mei Chen, Wei Ji, Qiling Wu, Wen Sun, Xin Han, Yanan Wei, Zheng Ge, Aojie Li, Bin Wang, Bizhu Huang, Bo Wang, Brian Li, Changxing Miao, Chen Xu, Chenfei Wu, Chenguang Yu, Dapeng Shi, Dingyuan Hu, Enle Liu, Gang Yu, Ge Yang, Guanzhe Huang, Gulin Yan, Haiyang Feng, Hao Nie, Haonan Jia, Hanpeng Hu, Hanqi Chen, Haolong Yan, Heng Wang, Hongcheng Guo, Huilin Xiong, Huixin Xiong, Jiahao Gong, Jianchang Wu, Jiaoren Wu, Jie Wu, Jie Yang, Jiashuai Liu, Jiashuo Li, Jingyang Zhang, Junjing Guo, Junzhe Lin, Kaixiang Li, Lei Liu, Lei Xia, Liang Zhao, Liguo Tan, Liwen Huang, Liying Shi, Ming Li, Mingliang Li, Muhua Cheng, Na Wang, Qiaohui Chen, Qinglin He, Qiuyan Liang, Quan Sun, Ran Sun, Rui Wang, Shaoliang Pang, Shiliang Yang, Sitong Liu, Siqi Liu, Shuli Gao, Tiancheng Cao, Tianyu Wang, Weipeng Ming, Wenqing He, Xu Zhao, Xuelin Zhang, Xianfang Zeng, Xiaojia Liu, Xuan Yang, Yaqi Dai, Yanbo Yu, Yang Li, Yineng Deng, Yingming Wang, Yilei Wang, Yuanwei Lu, Yu Chen, Yu Luo, Yuchu Luo, Yuhe Yin, Yuheng Feng, Yuxiang Yang, Zecheng Tang, Zekai Zhang, Zidong Yang, Binxing Jiao, Jiansheng Chen, Jing Li, Shuchang Zhou, Xiangyu Zhang, Xinhao Zhang, Yibo Zhu, Heung-Yeung Shum, Daxin Jiang

We present Step-Video-T2V, a state-of-the-art text-to-video pre-trained model
with 30B parameters and the ability to generate videos up to 204 frames in
length. A deep compression Variational Autoencoder, Video-VAE, is designed for
video generation tasks, achieving 16x16 spatial and 8x temporal compression
ratios, while maintaining exceptional video reconstruction quality. User
prompts are encoded using two bilingual text encoders to handle both English
and Chinese. A DiT with 3D full attention is trained using Flow Matching and is
employed to denoise input noise into latent frames. A video-based DPO approach,
Video-DPO, is applied to reduce artifacts and improve the visual quality of the
generated videos. We also detail our training strategies and share key
observations and insights. Step-Video-T2V's performance is evaluated on a novel
video generation benchmark, Step-Video-T2V-Eval, demonstrating its
state-of-the-art text-to-video quality when compared with both open-source and
commercial engines. Additionally, we discuss the limitations of current
diffusion-based model paradigm and outline future directions for video
foundation models. We make both Step-Video-T2V and Step-Video-T2V-Eval
available at https://github.com/stepfun-ai/Step-Video-T2V. The online version
can be accessed from https://yuewen.cn/videos as well. Our goal is to
accelerate the innovation of video foundation models and empower video content
creators.

摘要：<paragraph>我們提出 Step-Video-T2V，一個最先進的文字轉影片預訓練模型，具有 30B 參數，並能夠產生長達 204 幀的影片。一個深度壓縮變異自動編碼器 Video-VAE，專為影片產生任務而設計，可實現 16x16 空間和 8x 時間壓縮比，同時維持出色的影片重建品質。使用兩個雙語文字編碼器對使用者提示進行編碼，以處理英文和中文。使用流匹配訓練具有 3D 全注意力的 DiT，並用於將輸入雜訊去噪成潛在幀。應用基於影片的 DPO 方法 Video-DPO，以減少人工製品並提升產生影片的視覺品質。我們也詳細說明我們的訓練策略，並分享關鍵觀察和見解。Step-Video-T2V 的效能是在一個新穎的影片產生基準 Step-Video-T2V-Eval 上評估，與開源和商業引擎相比，展示其最先進的文字轉影片品質。此外，我們討論了當前基於擴散模型範例的限制，並概述影片基礎模型的未來方向。我們在 https://github.com/stepfun-ai/Step-Video-T2V 上提供 Step-Video-T2V 和 Step-Video-T2V-Eval。也可以從 https://yuewen.cn/videos 訪問線上版本。我們的目標是加速影片基礎模型的創新，並賦能影片內容創作者。</paragraph>

##### **Efficient Zero-Order Federated Finetuning of Language Models for Resource-Constrained Devices**
2502.10239v1 by Mohamed Aboelenien Ahmed, Kilian Pfeiffer, Ramin Khalili, Heba Khdr, Jörg Henkel

Federated fine-tuning offers a promising approach for tuning Large Language
Models (LLMs) on edge devices while preserving data privacy. However,
fine-tuning these models on edge devices remains challenging due to high
memory, communication, and computational demands. Zero-order optimization with
task alignment provides a potential solution, enabling fine-tuning with
inference-level memory requirements but requires a longer convergence time. In
this paper, we propose Federated Split-Perturbation Zero-order Optimization
(FedSPZO) that divides the network into two blocks, applying a different number
of perturbations per block in a computationally effective way, achieving faster
convergence. Our evaluation shows a $2.5 - 7\times $ reduction in computation
overhead compared to zero-order state of the art techniques in federated
learning.

摘要：聯邦微調提供了一種有前途的方法，可以在邊緣設備上對大型語言模型 (LLM) 進行微調，同時保護數據隱私。然而，由於對內存、通信和計算要求很高，在邊緣設備上微調這些模型仍然具有挑戰性。帶任務對齊的零階優化提供了一個潛在的解決方案，它可以在推論級別的內存需求下進行微調，但需要更長的收斂時間。在本文中，我們提出了聯邦分裂擾動零階優化 (FedSPZO)，它將網路分成兩個區塊，以計算有效的方式在每個區塊中應用不同數量的擾動，從而實現更快的收斂。我們的評估表明，與聯邦學習中零階最先進技術相比，計算開銷減少了 2.5 - 7 倍。

##### **Shaping Inductive Bias in Diffusion Models through Frequency-Based Noise Control**
2502.10236v1 by Thomas Jiralerspong, Berton Earnshaw, Jason Hartford, Yoshua Bengio, Luca Scimeca

Diffusion Probabilistic Models (DPMs) are powerful generative models that
have achieved unparalleled success in a number of generative tasks. In this
work, we aim to build inductive biases into the training and sampling of
diffusion models to better accommodate the target distribution of the data to
model. For topologically structured data, we devise a frequency-based noising
operator to purposefully manipulate, and set, these inductive biases. We first
show that appropriate manipulations of the noising forward process can lead
DPMs to focus on particular aspects of the distribution to learn. We show that
different datasets necessitate different inductive biases, and that appropriate
frequency-based noise control induces increased generative performance compared
to standard diffusion. Finally, we demonstrate the possibility of ignoring
information at particular frequencies while learning. We show this in an image
corruption and recovery task, where we train a DPM to recover the original
target distribution after severe noise corruption.

摘要：擴散機率模型 (DPM) 是強大的生成模型，在許多生成任務中取得無與倫比的成功。在這項工作中，我們旨在將歸納偏誤建構到擴散模型的訓練和抽樣中，以更好地適應要建模的資料目標分佈。對於拓撲結構資料，我們設計了一個基於頻率的雜訊運算子，以有目的地操作和設定這些歸納偏誤。我們首先表明，對雜訊前向處理的適當操作可以讓 DPM 專注於分佈的特定方面以進行學習。我們表明，不同的資料集需要不同的歸納偏誤，並且適當的基於頻率的雜訊控制會比標準擴散產生更高的生成效能。最後，我們展示了在學習時忽略特定頻率資訊的可能性。我們在影像損壞和復原任務中展示這一點，在該任務中，我們訓練 DPM 在嚴重的雜訊損壞後復原原始目標分佈。

##### **Forget the Data and Fine-Tuning! Just Fold the Network to Compress**
2502.10216v1 by Dong Wang, Haris Šikić, Lothar Thiele, Olga Saukh

We introduce model folding, a novel data-free model compression technique
that merges structurally similar neurons across layers, significantly reducing
the model size without the need for fine-tuning or access to training data.
Unlike existing methods, model folding preserves data statistics during
compression by leveraging k-means clustering, and using novel data-free
techniques to prevent variance collapse or explosion. Our theoretical framework
and experiments across standard benchmarks, including ResNet18 and LLaMA-7B,
demonstrate that model folding achieves comparable performance to data-driven
compression techniques and outperforms recently proposed data-free methods,
especially at high sparsity levels. This approach is particularly effective for
compressing large-scale models, making it suitable for deployment in
resource-constrained environments.

摘要：我們引入了模型摺疊，一種新穎的無資料模型壓縮技術，它會合併層中結構相似的神經元，大幅減少模型大小，無需微調或取得訓練資料。與現有方法不同，模型摺疊會在壓縮期間透過利用 k 平均值聚類來保留資料統計資料，並使用新穎的無資料技術來防止變異收斂或爆炸。我們在標準基準（包括 ResNet18 和 LLaMA-7B）上的理論架構和實驗證明，模型摺疊可達成與資料驅動壓縮技術相當的效能，而且在高稀疏層級上優於最近提出的無資料方法。此方法特別適用於壓縮大型模型，使其適合部署在資源受限的環境中。

##### **Do Large Language Models Reason Causally Like Us? Even Better?**
2502.10215v1 by Hanna M. Dettki, Brenden M. Lake, Charley M. Wu, Bob Rehder

Causal reasoning is a core component of intelligence. Large language models
(LLMs) have shown impressive capabilities in generating human-like text,
raising questions about whether their responses reflect true understanding or
statistical patterns. We compared causal reasoning in humans and four LLMs
using tasks based on collider graphs, rating the likelihood of a query variable
occurring given evidence from other variables. We find that LLMs reason
causally along a spectrum from human-like to normative inference, with
alignment shifting based on model, context, and task. Overall, GPT-4o and
Claude showed the most normative behavior, including "explaining away", whereas
Gemini-Pro and GPT-3.5 did not. Although all agents deviated from the expected
independence of causes - Claude the least - they exhibited strong associative
reasoning and predictive inference when assessing the likelihood of the effect
given its causes. These findings underscore the need to assess AI biases as
they increasingly assist human decision-making.

摘要：因果推理是智能的核心組成部分。大型語言模型 (LLM) 在生成類人文本方面展現了令人印象深刻的能力，引發了關於它們的回應是否反映真實理解或統計模式的疑問。我們使用基於碰撞圖的任務比較了人類和四個 LLM 中的因果推理，根據其他變數的證據評估查詢變數發生的可能性。我們發現 LLM 沿著從類人到規範推論的光譜進行因果推理，對齊會根據模型、上下文和任務而改變。總體而言，GPT-4o 和 Claude 表現出最規範的行為，包括「解釋」，而 Gemini-Pro 和 GPT-3.5 則沒有。儘管所有代理都偏離了預期的原因獨立性 - Claude 最不偏離 - 但它們在評估給定原因的效果可能性時表現出強烈的關聯推理和預測推論。這些發現強調了評估 AI 偏差的必要性，因為它們越來越協助人類決策。

##### **Can Post-Training Quantization Benefit from an Additional QLoRA Integration?**
2502.10202v1 by Xiliang Zhu, Elena Khasanova, Cheng Chen

Large language models (LLMs) have transformed natural language processing but
pose significant challenges for real-world deployment. These models necessitate
considerable computing resources, which can be costly and frequently
unavailable. Model compression techniques such as quantization are often
leveraged to alleviate resource demand, but they may have a negative impact on
the generation quality. In this study, we explore the integration of 4-bit
Post-training Quantization (PTQ) with QLoRA to address these issues. We
demonstrate through extensive experiments that this integration outperforms
standard PTQ, and in some cases even 16-bit full-parameter fine-tuning on LLMs,
validated across proprietary and public datasets with different quantization
algorithms. The results demonstrate the efficacy of PTQ-QLoRA integration,
offering a viable solution for deploying powerful LLMs in resource-constrained
environments without compromising on performance.

摘要：大型語言模型 (LLM) 已經轉變了自然語言處理，但對真實世界的部署提出了重大的挑戰。這些模型需要大量的運算資源，這可能會很昂貴且經常不可用。模型壓縮技術（例如量化）通常用於減輕資源需求，但它們可能會對生成品質產生負面影響。在本研究中，我們探討了將 4 位元訓練後量化 (PTQ) 與 QLoRA 整合以解決這些問題。我們透過廣泛的實驗證明，這種整合優於標準 PTQ，在某些情況下甚至優於 LLM 上的 16 位元全參數微調，並在使用不同量化演算法的專有和公開資料集上進行驗證。結果證明了 PTQ-QLoRA 整合的效能，為在資源受限的環境中部署強大的 LLM 提供了一個可行的解決方案，同時不影響效能。

##### **Prediction hubs are context-informed frequent tokens in LLMs**
2502.10201v1 by Beatrix M. G. Nielsen, Iuri Macocco, Marco Baroni

Hubness, the tendency for few points to be among the nearest neighbours of a
disproportionate number of other points, commonly arises when applying standard
distance measures to high-dimensional data, often negatively impacting
distance-based analysis. As autoregressive large language models (LLMs) operate
on high-dimensional representations, we ask whether they are also affected by
hubness. We first show, theoretically, that the only representation comparison
operation performed by LLMs, namely that between context and unembedding
vectors to determine continuation probabilities, is not characterized by the
concentration of distances phenomenon that typically causes the appeareance of
nuisance hubness. We then empirically show that this comparison still leads to
a high degree of hubness, but the hubs in this case do not constitute a
disturbance. They are rather the result of context-modulated frequent tokens
often appearing in the pool of likely candidates for next token prediction. On
the other hand, when other distance computations involving LLM representations
are performed, we do not have the same theoretical guarantees, and, indeed, we
see nuisance hubs appear. In summary, our work highlights, on the one hand, how
hubness, while omnipresent in high-dimensional spaces, is not always a negative
property that needs to be mitigated, and, on the other hand, it shows that
various widely-used LLMs have developed a guessing strategy that consists in
constantly assigning a high probability to frequent tokens.

摘要：集線性，即少數點成為大量其他點最近鄰居的趨勢，通常在將標準距離測量應用於高維度資料時產生，常對基於距離的分析造成負面影響。由於自迴歸大型語言模型 (LLM) 運作於高維度表示，我們探討它們是否也受集線性影響。我們首先在理論上證明，LLM 執行的唯一表示比較運算，即在脈絡和非嵌入向量之間比較以決定延續機率，並非以通常導致惱人集線性出現的距離集中現象為特徵。我們接著以經驗方式證明，此比較仍然導致高度集線性，但這種情況下的集線器並非干擾。它們反而是脈絡調整的頻繁代幣，常出現在下一個代幣預測的可能候選池中。另一方面，在執行涉及 LLM 表示的其他距離運算時，我們沒有相同的理論保證，而且確實會看到惱人的集線器出現。總之，我們的研究一方面強調，集線性雖然普遍存在於高維度空間中，但並非總是需要減輕的負面屬性；另一方面，它顯示出各種廣泛使用的 LLM 已發展出一種猜測策略，其包含持續對頻繁代幣賦予高機率。

##### **MathConstruct: Challenging LLM Reasoning with Constructive Proofs**
2502.10197v1 by Mislav Balunović, Jasper Dekoninck, Nikola Jovanović, Ivo Petrov, Martin Vechev

While Large Language Models (LLMs) demonstrate impressive performance in
mathematics, existing math benchmarks come with significant limitations. Many
focus on problems with fixed ground-truth answers, and are often saturated due
to problem simplicity or the viability of guessing or memorization. Crucially,
they capture only a narrow subset of relevant math problems. To address this
research gap, we introduce \mc, a new benchmark of 126 challenging problems
sourced from various math competitions, which targets constructive proofs, a
widely encountered problem type requiring the construction of mathematical
objects with specific properties. These proofs are particularly suitable for
LLM evaluation, as solution correctness can be easily verified. Our automated
verifiers also enable MathConstruct to generate problem variations, used to
evaluate robustness. State-of-the-art LLMs solve only 54% of MathConstruct
problems, highlighting its complexity and importance for LLM evaluation.

摘要：儘管大型語言模型 (LLM) 在數學方面表現出色，但現有的數學基準存在重大限制。許多基準著重於具有固定正解的問題，而且由於問題過於簡單或可透過猜測或記憶來解決，因此經常會出現飽和狀態。最重要的是，它們僅涵蓋了相關數學問題的狹窄子集。為了解決這個研究差距，我們引入了 \mc，一個新的基準，包含了 126 個來自各種數學競賽的具挑戰性問題，目標是建構性證明，一種廣泛遇到的問題類型，需要建構具有特定性質的數學物件。這些證明特別適合 LLM 評估，因為可以輕鬆驗證解的正確性。我們的自動化驗證器也讓 MathConstruct 能產生問題變體，用於評估穩健性。最先進的 LLM 只解決了 54% 的 MathConstruct 問題，突顯了它的複雜性和對 LLM 評估的重要性。

##### **Exploring the Camera Bias of Person Re-identification**
2502.10195v1 by Myungseo Song, Jin-Woo Park, Jong-Seok Lee

We empirically investigate the camera bias of person re-identification (ReID)
models. Previously, camera-aware methods have been proposed to address this
issue, but they are largely confined to training domains of the models. We
measure the camera bias of ReID models on unseen domains and reveal that camera
bias becomes more pronounced under data distribution shifts. As a debiasing
method for unseen domain data, we revisit feature normalization on embedding
vectors. While the normalization has been used as a straightforward solution,
its underlying causes and broader applicability remain unexplored. We analyze
why this simple method is effective at reducing bias and show that it can be
applied to detailed bias factors such as low-level image properties and body
angle. Furthermore, we validate its generalizability across various models and
benchmarks, highlighting its potential as a simple yet effective test-time
postprocessing method for ReID. In addition, we explore the inherent risk of
camera bias in unsupervised learning of ReID models. The unsupervised models
remain highly biased towards camera labels even for seen domain data,
indicating substantial room for improvement. Based on observations of the
negative impact of camera-biased pseudo labels on training, we suggest simple
training strategies to mitigate the bias. By applying these strategies to
existing unsupervised learning algorithms, we show that significant performance
improvements can be achieved with minor modifications.

摘要：我們實證調查了人體再辨識 (ReID) 模型的相機偏誤。先前，已提出相機感知方法來解決這個問題，但它們在很大程度上僅限於模型的訓練領域。我們測量了 ReID 模型在未見領域的相機偏誤，並揭示相機偏誤在資料分佈轉移下變得更加明顯。作為未見領域資料的去偏誤方法，我們重新審視嵌入向量的特徵正規化。雖然正規化已被用作一種直接的解決方案，但其根本原因和更廣泛的適用性仍未被探討。我們分析了為什麼這種簡單的方法可以有效減少偏誤，並表明它可以應用於詳細的偏誤因素，例如低階影像屬性和身體角度。此外，我們驗證了它在各種模型和基準測試中的通用性，強調了它作為一種簡單但有效的 ReID 測試時後處理方法的潛力。此外，我們探討了 ReID 模型無監督學習中相機偏誤的固有風險。即使對於已見領域的資料，無監督模型仍然高度偏向相機標籤，這表示有很大的改進空間。基於觀察到相機偏誤偽標籤對訓練的負面影響，我們建議簡單的訓練策略來減輕偏誤。通過將這些策略應用於現有的無監督學習演算法，我們表明可以透過微小的修改來實現顯著的效能提升。

##### **From Markov to Laplace: How Mamba In-Context Learns Markov Chains**
2502.10178v1 by Marco Bondaschi, Nived Rajaraman, Xiuying Wei, Kannan Ramchandran, Razvan Pascanu, Caglar Gulcehre, Michael Gastpar, Ashok Vardhan Makkuva

While transformer-based language models have driven the AI revolution thus
far, their computational complexity has spurred growing interest in viable
alternatives, such as structured state space sequence models (SSMs) and
Selective SSMs. Among these, Mamba (S6) and its variant Mamba-2 have shown
remarkable inference speed ups over transformers while achieving comparable or
superior performance on complex language modeling tasks. However, despite these
architectural innovations and empirical successes, the fundamental learning
capabilities of Mamba remain poorly understood. In this paper, we address this
gap by studying in-context learning (ICL) on Markov chains and uncovering a
surprising phenomenon: unlike transformers, even a single-layer Mamba
efficiently learns the in-context Laplacian smoothing estimator, which is both
Bayes and minimax optimal, for all Markovian orders. To explain this, we
theoretically characterize the representation capacity of Mamba and reveal the
fundamental role of convolution in enabling it to represent the optimal
Laplacian smoothing. These theoretical insights align strongly with empirical
results and, to the best of our knowledge, represent the first formal
connection between Mamba and optimal statistical estimators. Finally, we
outline promising research directions inspired by these findings.

摘要：儘管基於Transformer的語言模型迄今為止推動了 AI 革命，但其計算複雜度卻激發了人們對可行替代方案（例如結構化狀態空間序列模型 (SSM) 和選擇性 SSM）的興趣。在這些模型中，Mamba (S6) 及其變體 Mamba-2 在複雜語言建模任務上實現了可與Transformer媲美或更佳的效能，同時展現出顯著的推論速度提升。然而，儘管有這些架構創新和實證上的成功，Mamba 的基本學習能力仍鮮為人知。在本文中，我們透過研究馬可夫鏈上的情境內學習 (ICL)，並揭露一個驚人的現象來解決這個差距：與Transformer不同，即使是單層 Mamba 也能有效學習情境內拉普拉斯平滑估計器，這對於所有馬可夫階數來說都是貝氏和極小極大最優的。為了解釋這一點，我們從理論上描述了 Mamba 的表示能力，並揭示了卷積在使其能夠表示最佳拉普拉斯平滑中所扮演的基本角色。這些理論見解與實證結果密切吻合，並且據我們所知，它們代表了 Mamba 和最佳統計估計器之間的第一個形式聯繫。最後，我們概述了受這些發現啟發的有希望的研究方向。

##### **STMA: A Spatio-Temporal Memory Agent for Long-Horizon Embodied Task Planning**
2502.10177v1 by Mingcong Lei, Yiming Zhao, Ge Wang, Zhixin Mai, Shuguang Cui, Yatong Han, Jinke Ren

A key objective of embodied intelligence is enabling agents to perform
long-horizon tasks in dynamic environments while maintaining robust
decision-making and adaptability. To achieve this goal, we propose the
Spatio-Temporal Memory Agent (STMA), a novel framework designed to enhance task
planning and execution by integrating spatio-temporal memory. STMA is built
upon three critical components: (1) a spatio-temporal memory module that
captures historical and environmental changes in real time, (2) a dynamic
knowledge graph that facilitates adaptive spatial reasoning, and (3) a
planner-critic mechanism that iteratively refines task strategies. We evaluate
STMA in the TextWorld environment on 32 tasks, involving multi-step planning
and exploration under varying levels of complexity. Experimental results
demonstrate that STMA achieves a 31.25% improvement in success rate and a 24.7%
increase in average score compared to the state-of-the-art model. The results
highlight the effectiveness of spatio-temporal memory in advancing the memory
capabilities of embodied agents.

摘要：具身智能的主要目標是讓代理在動態環境中執行長遠任務，同時維持穩健的決策制定和適應力。為達成此目標，我們提出時空記憶代理 (STMA)，這是一個新穎的架構，旨在透過整合時空記憶來強化任務規劃和執行。STMA 建立在三個關鍵組成部分之上：(1) 捕捉歷史和環境即時變化的時空記憶模組，(2) 促進適應性空間推理的動態知識圖譜，以及 (3) 迭代精進任務策略的規劃者-評論家機制。我們在 TextWorld 環境中針對 32 項任務評估 STMA，這些任務涉及在不同複雜度等級下的多步驟規劃和探索。實驗結果表明，與最先進的模型相比，STMA 的成功率提升了 31.25%，平均分數增加了 24.7%。這些結果突顯了時空記憶在提升具身代理記憶能力方面的有效性。

##### **SessionRec: Next Session Prediction Paradigm For Generative Sequential Recommendation**
2502.10157v1 by Lei Huang, Hao Guo, Linzhi Peng, Long Zhang, Xiaoteng Wang, Daoyuan Wang, Shichao Wang, Jinpeng Wang, Lei Wang, Sheng Chen

We introduce SessionRec, a novel next-session prediction paradigm (NSPP) for
generative sequential recommendation, addressing the fundamental misalignment
between conventional next-item prediction paradigm (NIPP) and real-world
recommendation scenarios. Unlike NIPP's item-level autoregressive generation
that contradicts actual session-based user interactions, our framework
introduces a session-aware representation learning through hierarchical
sequence aggregation (intra/inter-session), reducing attention computation
complexity while enabling implicit modeling of massive negative interactions,
and a session-based prediction objective that better captures users' diverse
interests through multi-item recommendation in next sessions. Moreover, we
found that incorporating a rank loss for items within the session under the
next session prediction paradigm can significantly improve the ranking
effectiveness of generative sequence recommendation models. We also verified
that SessionRec exhibits clear power-law scaling laws similar to those observed
in LLMs. Extensive experiments conducted on public datasets and online A/B test
in Meituan App demonstrate the effectiveness of SessionRec. The proposed
paradigm establishes new foundations for developing industrial-scale generative
recommendation systems through its model-agnostic architecture and
computational efficiency.

摘要：<paragraph>我們介紹 SessionRec，一種新的下一個會話預測範例 (NSPP)，用於生成式序列推薦，解決傳統的下一個項目預測範例 (NIPP) 與真實世界推薦情境之間的基本不一致。與 NIPP 的項目級自迴歸生成不同，這與實際基於會話的使用者互動相矛盾，我們的架構通過分層序列聚合（會話內/會話間）引入了會話感知表示學習，同時降低了注意力計算複雜度，並啟用了大量負面互動的隱式建模，以及一個基於會話的預測目標，通過在下一個會話中進行多項目推薦，更好地捕捉使用者的多元化興趣。此外，我們發現，在下一會話預測範例中為會話中的項目納入排名損失，可以顯著提高生成式序列推薦模型的排名效果。我們還驗證了 SessionRec 表現出明顯的冪律縮放定律，類似於在 LLM 中觀察到的定律。在公共數據集和美團 App 中進行的廣泛實驗證明了 SessionRec 的有效性。所提出的範例通過其與模型無關的架構和計算效率，為開發產業規模的生成式推薦系統建立了新的基礎。</paragraph>

##### **Video Soundtrack Generation by Aligning Emotions and Temporal Boundaries**
2502.10154v1 by Serkan Sulun, Paula Viana, Matthew E. P. Davies

We introduce EMSYNC, a video-based symbolic music generation model that
aligns music with a video's emotional content and temporal boundaries. It
follows a two-stage framework, where a pretrained video emotion classifier
extracts emotional features, and a conditional music generator produces MIDI
sequences guided by both emotional and temporal cues. We introduce boundary
offsets, a novel temporal conditioning mechanism that enables the model to
anticipate and align musical chords with scene cuts. Unlike existing models,
our approach retains event-based encoding, ensuring fine-grained timing control
and expressive musical nuances. We also propose a mapping scheme to bridge the
video emotion classifier, which produces discrete emotion categories, with the
emotion-conditioned MIDI generator, which operates on continuous-valued
valence-arousal inputs. In subjective listening tests, EMSYNC outperforms
state-of-the-art models across all subjective metrics, for music theory-aware
participants as well as the general listeners.

摘要：我們介紹 EMSYNC，這是一個基於影片的符號音樂生成模型，它會將音樂與影片的情緒內容和時間界線對齊。它遵循一個兩階段架構，其中一個預先訓練好的影片情緒分類器會萃取情緒特徵，而一個條件式音樂產生器會根據情緒和時間提示產生 MIDI 序列。我們介紹邊界偏移，這是一種新穎的時間條件機制，使模型能夠預測並將音樂和弦與場景切換對齊。與現有模型不同，我們的做法保留了基於事件的編碼，確保了細緻的時序控制和表現力的音樂細微差別。我們還提出了對應機制，以將產生離散情緒類別的影片情緒分類器，與以連續值效價喚醒輸入運作的情緒條件 MIDI 產生器聯繫起來。在主觀聆聽測試中，EMSYNC 在所有主觀指標上都優於最先進的模型，無論是對音樂理論有認知的參與者，還是普通聽眾。

##### **Cooperative Multi-Agent Planning with Adaptive Skill Synthesis**
2502.10148v1 by Zhiyuan Li, Wenshuai Zhao, Joni Pajarinen

Despite much progress in training distributed artificial intelligence (AI),
building cooperative multi-agent systems with multi-agent reinforcement
learning (MARL) faces challenges in sample efficiency, interpretability, and
transferability. Unlike traditional learning-based methods that require
extensive interaction with the environment, large language models (LLMs)
demonstrate remarkable capabilities in zero-shot planning and complex
reasoning. However, existing LLM-based approaches heavily rely on text-based
observations and struggle with the non-Markovian nature of multi-agent
interactions under partial observability. We present COMPASS, a novel
multi-agent architecture that integrates vision-language models (VLMs) with a
dynamic skill library and structured communication for decentralized
closed-loop decision-making. The skill library, bootstrapped from
demonstrations, evolves via planner-guided tasks to enable adaptive strategies.
COMPASS propagates entity information through multi-hop communication under
partial observability. Evaluations on the improved StarCraft Multi-Agent
Challenge (SMACv2) demonstrate COMPASS achieves up to 30\% higher win rates
than state-of-the-art MARL algorithms in symmetric scenarios.

摘要：儘管在訓練分散式人工智慧 (AI) 上取得許多進展，但建構結合多重代理強化學習 (MARL) 的合作式多重代理系統在取樣效率、可解釋性和可轉移性方面仍面臨挑戰。與需要與環境廣泛互動的傳統基於學習的方法不同，大型語言模型 (LLM) 在零次規劃和複雜推理方面展現出非凡的能力。然而，現有的基於 LLM 的方法過度依賴基於文字的觀察，且難以應付部分可觀察性下多重代理互動的非馬可夫性質。我們提出 COMPASS，這是一種新穎的多重代理架構，它將視覺語言模型 (VLM) 與動態技能庫和結構化溝通整合起來，以進行分散式的閉環決策制定。技能庫從示範中啟動，透過規劃器引導的任務演化，以實現適應性策略。COMPASS 在部分可觀察性下透過多重跳躍溝通傳播實體資訊。在改進的星海爭霸多重代理挑戰 (SMACv2) 上的評估顯示，在對稱情境中，COMPASS 的獲勝率比最先進的 MARL 演算法高出 30%。

##### **Small Models, Big Impact: Efficient Corpus and Graph-Based Adaptation of Small Multilingual Language Models for Low-Resource Languages**
2502.10140v1 by Daniil Gurgurov, Ivan Vykopal, Josef van Genabith, Simon Ostermann

Low-resource languages (LRLs) face significant challenges in natural language
processing (NLP) due to limited data. While current state-of-the-art large
language models (LLMs) still struggle with LRLs, smaller multilingual models
(mLMs) such as mBERT and XLM-R offer greater promise due to a better fit of
their capacity to low training data sizes. This study systematically
investigates parameter-efficient adapter-based methods for adapting mLMs to
LRLs, evaluating three architectures: Sequential Bottleneck, Invertible
Bottleneck, and Low-Rank Adaptation. Using unstructured text from GlotCC and
structured knowledge from ConceptNet, we show that small adaptation datasets
(e.g., up to 1 GB of free-text or a few MB of knowledge graph data) yield gains
in intrinsic (masked language modeling) and extrinsic tasks (topic
classification, sentiment analysis, and named entity recognition). We find that
Sequential Bottleneck adapters excel in language modeling, while Invertible
Bottleneck adapters slightly outperform other methods on downstream tasks due
to better embedding alignment and larger parameter counts. Adapter-based
methods match or outperform full fine-tuning while using far fewer parameters,
and smaller mLMs prove more effective for LRLs than massive LLMs like LLaMA-3,
GPT-4, and DeepSeek-R1-based distilled models. While adaptation improves
performance, pre-training data size remains the dominant factor, especially for
languages with extensive pre-training coverage.

摘要：低資源語言 (LRL) 由於資料有限，在自然語言處理 (NLP) 中面臨重大挑戰。雖然當前最先進的大型語言模型 (LLM) 仍難以處理 LRL，但較小的多語言模型 (mLMS)，例如 mBERT 和 XLM-R，由於其容量更適合低訓練資料大小，因此提供了更大的希望。本研究系統性地探討了基於參數效率適配器的適配方法，以將 mLMS 適配到 LRL，評估了三種架構：順序瓶頸、可逆瓶頸和低秩適配。使用來自 GlotCC 的非結構化文本和來自 ConceptNet 的結構化知識，我們表明小型適配資料集（例如，高達 1 GB 的自由文本或幾 MB 的知識圖譜資料）在內在（遮蔽語言模型）和外在任務（主題分類、情緒分析和命名實體識別）中產生增益。我們發現順序瓶頸適配器在語言模型中表現出色，而可逆瓶頸適配器由於更好的嵌入對齊和更大的參數數量，在下游任務上略勝於其他方法。基於適配器的方法在使用更少參數的同時，可以匹配或優於完全微調，而較小的 mLM 被證明比 LLaMA-3、GPT-4 和基於 DeepSeek-R1 的蒸餾模型等大型 LLM 更適合 LRL。雖然適配可以提高效能，但預訓練資料大小仍然是主要因素，特別是對於預訓練覆蓋範圍廣泛的語言。

##### **Image Embedding Sampling Method for Diverse Captioning**
2502.10118v1 by Sania Waheed, Na Min An

Image Captioning for state-of-the-art VLMs has significantly improved over
time; however, this comes at the cost of increased computational complexity,
making them less accessible for resource-constrained applications such as
mobile devices and assistive technologies. Alternatively, smaller VLMs
prioritize high-level scene descriptions, overlooking finer details that
contribute to a richer understanding of an image. In this paper, we introduce a
training-free framework that enhances caption diversity and informativeness by
explicitly attending to distinct image regions using a comparably small VLM,
BLIP, as the backbone. Our approach leverages structured segmentation to
produce hierarchical representations that capture both global and localized
semantics. Without requiring additional model training, we demonstrate that our
method allows smaller VLMs to achieve performance comparable to larger models
in terms of image-caption alignment, semantic integrity, and diversity. We
evaluate our framework on MSCOCO, Flickr30k, and Nocaps test datasets,
achieving a Div-2 score of 0.735, 0.750, and 0.748 for each dataset
respectively, while maintaining strong image-caption relevancy and semantic
integrity with the human-annotated captions.

摘要：<paragraph>最先進的 VLM 的影像標題在一段時間以來已大幅改善；然而，這是以增加運算複雜度為代價，這使得它們對於資源受限的應用程式（例如行動裝置和輔助技術）較難使用。或者，較小的 VLM 優先考量高階場景描述，忽略有助於更豐富地了解影像的較精細細節。在本文中，我們介紹一個無需訓練的架構，透過明確關注不同的影像區域，使用較小的 VLM，BLIP，作為主幹，來提升標題的多樣性和資訊性。我們的做法利用結構化分割產生階層式表示，捕捉全局和局部語意。在不需要額外模型訓練的情況下，我們證明我們的做法讓較小的 VLM 能夠在影像標題對齊、語意完整性和多樣性方面，達到與較大模型相當的效能。我們在 MSCOCO、Flickr30k 和 Nocaps 測試資料集上評估我們的架構，分別為每個資料集達到 0.735、0.750 和 0.748 的 Div-2 分數，同時維持與人工標註的標題之間強大的影像標題相關性和語意完整性。</paragraph>

##### **Causal Information Prioritization for Efficient Reinforcement Learning**
2502.10097v1 by Hongye Cao, Fan Feng, Tianpei Yang, Jing Huo, Yang Gao

Current Reinforcement Learning (RL) methods often suffer from
sample-inefficiency, resulting from blind exploration strategies that neglect
causal relationships among states, actions, and rewards. Although recent causal
approaches aim to address this problem, they lack grounded modeling of
reward-guided causal understanding of states and actions for goal-orientation,
thus impairing learning efficiency. To tackle this issue, we propose a novel
method named Causal Information Prioritization (CIP) that improves sample
efficiency by leveraging factored MDPs to infer causal relationships between
different dimensions of states and actions with respect to rewards, enabling
the prioritization of causal information. Specifically, CIP identifies and
leverages causal relationships between states and rewards to execute
counterfactual data augmentation to prioritize high-impact state features under
the causal understanding of the environments. Moreover, CIP integrates a
causality-aware empowerment learning objective, which significantly enhances
the agent's execution of reward-guided actions for more efficient exploration
in complex environments. To fully assess the effectiveness of CIP, we conduct
extensive experiments across 39 tasks in 5 diverse continuous control
environments, encompassing both locomotion and manipulation skills learning
with pixel-based and sparse reward settings. Experimental results demonstrate
that CIP consistently outperforms existing RL methods across a wide range of
scenarios.

摘要：目前的強化學習 (RL) 方法常常會因為盲目探索策略而導致樣本效率低下，這些策略忽略了狀態、動作和獎勵之間的因果關係。雖然最近的因果方法旨在解決這個問題，但它們缺乏對狀態和動作的獎勵引導因果理解的紮實建模，以實現目標導向，從而損害學習效率。為了解決這個問題，我們提出了一種名為因果資訊優先化 (CIP) 的新方法，它利用分解的 MDP 來推論狀態和動作的不同維度之間相對於獎勵的因果關係，從而提高樣本效率，並使因果資訊優先化。具體來說，CIP 識別並利用狀態和獎勵之間的因果關係，執行反事實數據擴充，以在環境的因果理解下優先考慮高影響狀態特徵。此外，CIP 整合了一個因果感知賦權學習目標，這顯著增強了代理執行獎勵引導動作的能力，以便在複雜的環境中更有效地探索。為了充分評估 CIP 的有效性，我們在 5 個不同的連續控制環境中的 39 項任務中進行了廣泛的實驗，包括基於像素和稀疏獎勵設置的運動和操作技能學習。實驗結果表明，CIP 在各種場景中始終優於現有的 RL 方法。

##### **A novel approach to data generation in generative model**
2502.10092v1 by JaeHong Kim, Jaewon Shim

Variational Autoencoders (VAEs) and other generative models are widely
employed in artificial intelligence to synthesize new data. However, current
approaches rely on Euclidean geometric assumptions and statistical
approximations that fail to capture the structured and emergent nature of data
generation. This paper introduces the Convergent Fusion Paradigm (CFP) theory,
a novel geometric framework that redefines data generation by integrating
dimensional expansion accompanied by qualitative transformation. By modifying
the latent space geometry to interact with emergent high-dimensional
structures, CFP theory addresses key challenges such as identifiability issues
and unintended artifacts like hallucinations in Large Language Models (LLMs).
CFP theory is based on two key conceptual hypotheses that redefine how
generative models structure relationships between data and algorithms. Through
the lens of CFP theory, we critically examine existing metric-learning
approaches. CFP theory advances this perspective by introducing time-reversed
metric embeddings and structural convergence mechanisms, leading to a novel
geometric approach that better accounts for data generation as a structured
epistemic process. Beyond its computational implications, CFP theory provides
philosophical insights into the ontological underpinnings of data generation.
By offering a systematic framework for high-dimensional learning dynamics, CFP
theory contributes to establishing a theoretical foundation for understanding
the data-relationship structures in AI. Finally, future research in CFP theory
will be led to its implications for fully realizing qualitative
transformations, introducing the potential of Hilbert space in generative
modeling.

摘要：變異自動編碼器 (VAE) 和其他生成模型廣泛用於人工智慧中，以合成新資料。然而，目前的做法依賴於歐幾何假設和統計近似，無法捕捉資料生成的結構化和新興本質。本文介紹了收斂融合範例 (CFP) 理論，這是一個新穎的幾何框架，透過整合伴隨著質變的維度擴充，重新定義資料生成。透過修改潛在空間幾何，以與新興的高維結構互動，CFP 理論解決了關鍵挑戰，例如大型語言模型 (LLM) 中的可識別性問題和意外人工製品（例如幻覺）。CFP 理論基於兩個關鍵的概念假設，重新定義了生成模型如何建構資料和演算法之間的關係。透過 CFP 理論的觀點，我們批判性地檢視現有的度量學習方法。CFP 理論透過引入時間反轉的度量嵌入和結構收斂機制，推動了這個觀點，進而導致一種新穎的幾何方法，能更好地將資料生成視為一個結構化的認識論過程。除了其計算上的含意之外，CFP 理論還提供了關於資料生成本體論基礎的哲學見解。透過提供一個系統化的高維學習動態框架，CFP 理論有助於建立一個理解 AI 中資料關係結構的理論基礎。最後，CFP 理論的未來研究將導向其對充分實現質變的影響，在生成模型中引入希爾伯特空間的可能性。

##### **Manual2Skill: Learning to Read Manuals and Acquire Robotic Skills for Furniture Assembly Using Vision-Language Models**
2502.10090v1 by Chenrui Tie, Shengxiang Sun, Jinxuan Zhu, Yiwei Liu, Jingxiang Guo, Yue Hu, Haonan Chen, Junting Chen, Ruihai Wu, Lin Shao

Humans possess an extraordinary ability to understand and execute complex
manipulation tasks by interpreting abstract instruction manuals. For robots,
however, this capability remains a substantial challenge, as they cannot
interpret abstract instructions and translate them into executable actions. In
this paper, we present Manual2Skill, a novel framework that enables robots to
perform complex assembly tasks guided by high-level manual instructions. Our
approach leverages a Vision-Language Model (VLM) to extract structured
information from instructional images and then uses this information to
construct hierarchical assembly graphs. These graphs represent parts,
subassemblies, and the relationships between them. To facilitate task
execution, a pose estimation model predicts the relative 6D poses of components
at each assembly step. At the same time, a motion planning module generates
actionable sequences for real-world robotic implementation. We demonstrate the
effectiveness of Manual2Skill by successfully assembling several real-world
IKEA furniture items. This application highlights its ability to manage
long-horizon manipulation tasks with both efficiency and precision,
significantly enhancing the practicality of robot learning from instruction
manuals. This work marks a step forward in advancing robotic systems capable of
understanding and executing complex manipulation tasks in a manner akin to
human capabilities.

摘要：人類擁有理解並執行複雜操作任務的非凡能力，方法是詮釋抽象的說明手冊。然而，對機器人來說，這項能力仍然是一項重大的挑戰，因為它們無法詮釋抽象的指令並將其轉換為可執行的動作。在本文中，我們提出了 Manual2Skill，這是一個新穎的框架，使機器人能夠在高階手冊說明的指導下執行複雜的組裝任務。我們的做法利用視覺語言模型 (VLM) 從教學圖片中提取結構化資訊，然後使用此資訊來建構階層式組裝圖。這些圖表示零件、子組件以及它們之間的關係。為了促進任務執行，姿勢估計模型會預測每個組裝步驟中組件的相對 6D 姿勢。同時，動作規劃模組會產生適用於實際機器人實作的可操作順序。我們透過成功組裝幾個真實世界的 IKEA 家具來展示 Manual2Skill 的有效性。此應用程式突顯了它以高效率和高精準度管理長時程操作任務的能力，大幅提升機器人從說明手冊中學習的實用性。這項工作標誌著機器人系統在理解和執行複雜操作任務方面向前邁進了一步，其方式類似於人類的能力。

##### **A Hybrid Edge Classifier: Combining TinyML-Optimised CNN with RRAM-CMOS ACAM for Energy-Efficient Inference**
2502.10089v1 by Kieran Woodward, Eiman Kanjo, Georgios Papandroulidakis, Shady Agwa, Themis Prodromakis

In recent years, the development of smart edge computing systems to process
information locally is on the rise. Many near-sensor machine learning (ML)
approaches have been implemented to introduce accurate and energy efficient
template matching operations in resource-constrained edge sensing systems, such
as wearables. To introduce novel solutions that can be viable for extreme edge
cases, hybrid solutions combining conventional and emerging technologies have
started to be proposed. Deep Neural Networks (DNN) optimised for edge
application alongside new approaches of computing (both device and architecture
-wise) could be a strong candidate in implementing edge ML solutions that aim
at competitive accuracy classification while using a fraction of the power of
conventional ML solutions. In this work, we are proposing a hybrid
software-hardware edge classifier aimed at the extreme edge near-sensor
systems. The classifier consists of two parts: (i) an optimised digital tinyML
network, working as a front-end feature extractor, and (ii) a back-end
RRAM-CMOS analogue content addressable memory (ACAM), working as a final stage
template matching system. The combined hybrid system exhibits a competitive
trade-off in accuracy versus energy metric with $E_{front-end}$ = $96.23 nJ$
and $E_{back-end}$ = $1.45 nJ$ for each classification operation compared with
78.06$\mu$J for the original teacher model, representing a 792-fold reduction,
making it a viable solution for extreme edge applications.

摘要：<paragraph>近年來，發展智慧邊緣運算系統以在本地處理資訊的技術正蓬勃發展。許多近感測器機器學習 (ML) 方法已被實作，以在受資源限制的邊緣感測系統中導入精準且節能的範本比對運算，例如穿戴式裝置。為了導入可行於極端邊緣案例的新穎解決方案，已開始提出結合傳統與新興技術的混合解決方案。針對邊緣應用最佳化的深度神經網路 (DNN) 連同新的運算方法（裝置和架構方面），可能是實作邊緣 ML 解決方案的有力候選，目標是在使用傳統 ML 解決方案一小部分功率的同時，實作具競爭力精準度的分類。在這項工作中，我們提出一個混合軟體硬體邊緣分類器，目標在於極端邊緣近感測器系統。此分類器包含兩部分：(i) 一個最佳化的數位 tinyML 網路，作為前端特徵萃取器，以及 (ii) 一個後端 RRAM-CMOS 類比內容可尋址記憶體 (ACAM)，作為最終階段的範本比對系統。結合的混合系統展現出精準度與能耗指標的競爭性權衡，每個分類運算的 $E_{front-end}$ = $96.23 nJ$ 和 $E_{back-end}$ = $1.45 nJ$，相比於原始教師模型的 78.06$\mu$J，減少了 792 倍，使其成為極端邊緣應用可行的解決方案。</paragraph>

##### **Towards Empowerment Gain through Causal Structure Learning in Model-Based RL**
2502.10077v1 by Hongye Cao, Fan Feng, Meng Fang, Shaokang Dong, Tianpei Yang, Jing Huo, Yang Gao

In Model-Based Reinforcement Learning (MBRL), incorporating causal structures
into dynamics models provides agents with a structured understanding of the
environments, enabling efficient decision. Empowerment as an intrinsic
motivation enhances the ability of agents to actively control their
environments by maximizing the mutual information between future states and
actions. We posit that empowerment coupled with causal understanding can
improve controllability, while enhanced empowerment gain can further facilitate
causal reasoning in MBRL. To improve learning efficiency and controllability,
we propose a novel framework, Empowerment through Causal Learning (ECL), where
an agent with the awareness of causal dynamics models achieves
empowerment-driven exploration and optimizes its causal structure for task
learning. Specifically, ECL operates by first training a causal dynamics model
of the environment based on collected data. We then maximize empowerment under
the causal structure for exploration, simultaneously using data gathered
through exploration to update causal dynamics model to be more controllable
than dense dynamics model without causal structure. In downstream task
learning, an intrinsic curiosity reward is included to balance the causality,
mitigating overfitting. Importantly, ECL is method-agnostic and is capable of
integrating various causal discovery methods. We evaluate ECL combined with 3
causal discovery methods across 6 environments including pixel-based tasks,
demonstrating its superior performance compared to other causal MBRL methods,
in terms of causal discovery, sample efficiency, and asymptotic performance.

摘要：<paragraph>在基於模型的強化學習 (MBRL) 中，將因果結構納入動態模型為代理提供對環境的結構化理解，從而實現高效決策。作為內在動機的賦權通過最大化未來狀態和動作之間的互信息來增強代理主動控制其環境的能力。我們假設賦權與因果理解相結合可以提高可控性，而增強的賦權增益可以進一步促進 MBRL 中的因果推理。為了提高學習效率和可控性，我們提出了一個新的框架，即通過因果學習（ECL）實現賦權，其中具有因果動態模型意識的代理實現了賦權驅動的探索並優化了其因果結構以進行任務學習。具體來說，ECL 通過首先基於收集的數據訓練環境的因果動態模型來運作。然後，我們在因果結構下最大化賦權以進行探索，同時使用通過探索收集的數據來更新因果動態模型，使其比沒有因果結構的密集動態模型更具可控性。在下游任務學習中，包含內在的好奇心獎勵以平衡因果關係，減輕過度擬合。重要的是，ECL 與方法無關，並且能夠整合各種因果發現方法。我們評估了 ECL 與 3 種因果發現方法在 6 個環境（包括基於像素的任務）中的結合，證明了其在因果發現、樣本效率和漸近性能方面優於其他因果 MBRL 方法的卓越性能。</paragraph>

##### **Adaptive Bi-Level Multi-Robot Task Allocation and Learning under Uncertainty with Temporal Logic Constraints**
2502.10062v1 by Xiaoshan Lin, Roberto Tron

This work addresses the problem of multi-robot coordination under unknown
robot transition models, ensuring that tasks specified by Time Window Temporal
Logic are satisfied with user-defined probability thresholds. We present a
bi-level framework that integrates (i) high-level task allocation, where tasks
are assigned based on the robots' estimated task completion probabilities and
expected rewards, and (ii) low-level distributed policy learning and execution,
where robots independently optimize auxiliary rewards while fulfilling their
assigned tasks. To handle uncertainty in robot dynamics, our approach leverages
real-time task execution data to iteratively refine expected task completion
probabilities and rewards, enabling adaptive task allocation without explicit
robot transition models. We theoretically validate the proposed algorithm,
demonstrating that the task assignments meet the desired probability thresholds
with high confidence. Finally, we demonstrate the effectiveness of our
framework through comprehensive simulations.

摘要：本研究解決了在未知機器人轉換模型下多機器人協調的問題，確保由時間窗口時序邏輯規定的任務滿足使用者定義的機率閥值。我們提出一個雙層架構，整合 (i) 高層級任務分配，其中任務根據機器人的估計任務完成機率和預期獎勵分配，以及 (ii) 低層級分散策略學習和執行，其中機器人在執行分配的任務時獨立最佳化輔助獎勵。為了處理機器人動態中的不確定性，我們的做法利用即時任務執行資料來反覆調整預期的任務完成機率和獎勵，在沒有明確機器人轉換模型的情況下實現自適應任務分配。我們在理論上驗證了所提出的演算法，證明任務分配以高信心滿足所需的機率閥值。最後，我們透過全面的模擬證明了我們架構的有效性。

##### **Annotating Compositionality Scores for Irish Noun Compounds is Hard Work**
2502.10061v1 by Abigail Walsh, Teresa Clifford, Emma Daly, Jane Dunne, Brian Davis, Gearóid Ó Cleircín

Noun compounds constitute a challenging construction for NLP applications,
given their variability in idiomaticity and interpretation. In this paper, we
present an analysis of compound nouns identified in Irish text of varied
domains by expert annotators, focusing on compositionality as a key feature,
but also domain specificity, as well as familiarity and confidence of the
annotator giving the ratings. Our findings and the discussion that ensued
contributes towards a greater understanding of how these constructions appear
in Irish language, and how they might be treated separately from English noun
compounds.

摘要：名詞複合詞對自然語言處理應用程式構成挑戰，
因為它們在慣用語法和解釋上的可變性。在本文中，我們
分析了由專家註解員在不同領域的愛爾蘭文本中識別出的複合名詞，重點關注組合性作為一個關鍵特徵，
但也關注領域特異性，以及註解員給出評級時的熟悉度和信心。我們的研究結果和隨之而來的討論
有助於更深入地了解這些結構如何出現在愛爾蘭語中，以及如何將它們與英語名詞複合詞分開處理。

##### **MTLM: an Innovative Language Model Training Paradigm for ASR**
2502.10058v1 by Qingliang Meng, Pengju Ren, Tian Li, Changsong Dai

Pre-training Transformer-based language models (LMs) on a large amount of
text has proven crucial for improving automatic speech recognition (ASR)
performance. Generally, traditional LMs are unidirectional and unable to access
the context on the right. This paper proposes a method for training LMs that
enable traditional unidirectional LMs to fully utilize left and right contexts.
Compared with the unidirectional LMs, our LM facilitates ASR to transcribe
hypotheses more consistently and in a more semantically unambiguous way, as it
incorporates richer contextual representations. Finally, our experimental
results on the LibriSpeech corpus demonstrate that our model outperforms
traditional unidirectional LMs, whether n-best rescoring or shallow fusion is
used as the decoding algorithm.

摘要：在大量文本上預訓練基於 Transformer 的語言模型 (LM) 已被證明對於提升自動語音辨識 (ASR) 效能至關重要。一般來說，傳統的 LM 是單向的，無法存取右側的內容。本文提出了一種訓練 LM 的方法，使傳統的單向 LM 能夠充分利用左右兩側的內容。與單向 LM 相比，我們的 LM 能夠讓 ASR 更一致且以更明確的語意方式轉錄假設，因為它納入了更豐富的脈絡表示。最後，我們在 LibriSpeech 語料庫上的實驗結果證明，無論是使用 n-best 重新評分或淺層融合作為解碼演算法，我們的模型都優於傳統的單向 LM。

##### **ORI: O Routing Intelligence**
2502.10051v1 by Ahmad Shadid, Rahul Kumar, Mohit Mayank

Single large language models (LLMs) often fall short when faced with the
ever-growing range of tasks, making a single-model approach insufficient. We
address this challenge by proposing ORI (O Routing Intelligence), a dynamic
framework that leverages a set of LLMs. By intelligently routing incoming
queries to the most suitable model, ORI not only improves task-specific
accuracy, but also maintains efficiency. Comprehensive evaluations across
diverse benchmarks demonstrate consistent accuracy gains while controlling
computational overhead. By intelligently routing queries, ORI outperforms the
strongest individual models by up to 2.7 points on MMLU and 1.8 points on MuSR,
ties the top performance on ARC, and on BBH. These results underscore the
benefits of a multi-model strategy and demonstrate how ORI's adaptive
architecture can more effectively handle diverse tasks, offering a scalable,
high-performance solution for a system of multiple large language models.

摘要：大型單一語言模型 (LLM) 在面對不斷增加的任務範圍時，通常會表現不佳，使得單一模型方法不足以應付。我們透過提出 ORI (O 路由情報) 來解決這個挑戰，ORI 是一個利用一組 LLM 的動態架構。透過將傳入的查詢智能路由到最合適的模型，ORI 不僅提升了任務特定的準確度，還維持了效率。跨不同基準的全面評估顯示，在控制運算負擔的同時，持續提升準確度。透過智能路由查詢，ORI 在 MMLU 上比最強的個別模型高出 2.7 個百分點，在 MuSR 上高出 1.8 個百分點，在 ARC 和 BBH 上則與最高效能並列。這些結果強調了多模型策略的優點，並展示了 ORI 的自適應架構如何更有效地處理各種任務，為多個大型語言模型的系統提供可擴充、高性能的解決方案。

##### **A Survey on LLM-powered Agents for Recommender Systems**
2502.10050v1 by Qiyao Peng, Hongtao Liu, Hua Huang, Qing Yang, Minglai Shao

Recommender systems are essential components of many online platforms, yet
traditional approaches still struggle with understanding complex user
preferences and providing explainable recommendations. The emergence of Large
Language Model (LLM)-powered agents offers a promising approach by enabling
natural language interactions and interpretable reasoning, potentially
transforming research in recommender systems. This survey provides a systematic
review of the emerging applications of LLM-powered agents in recommender
systems. We identify and analyze three key paradigms in current research: (1)
Recommender-oriented approaches, which leverage intelligent agents to enhance
the fundamental recommendation mechanisms; (2) Interaction-oriented approaches,
which facilitate dynamic user engagement through natural dialogue and
interpretable suggestions; and (3) Simulation-oriented approaches, which employ
multi-agent frameworks to model complex user-item interactions and system
dynamics. Beyond paradigm categorization, we analyze the architectural
foundations of LLM-powered recommendation agents, examining their essential
components: profile construction, memory management, strategic planning, and
action execution. Our investigation extends to a comprehensive analysis of
benchmark datasets and evaluation frameworks in this domain. This systematic
examination not only illuminates the current state of LLM-powered agent
recommender systems but also charts critical challenges and promising research
directions in this transformative field.

摘要：推薦系統是許多線上平台的必要組成部分，但傳統方法仍難以理解複雜的使用者偏好並提供可解釋的推薦。大型語言模型 (LLM) 驅動代理的出現提供了一個有前途的方法，它能實現自然語言互動和可解釋的推理，有可能轉變推薦系統的研究。這項調查對 LLM 驅動代理在推薦系統中新興的應用提供了系統性的回顧。我們找出並分析了當前研究中的三個關鍵範例：(1) 推薦導向方法，它利用智慧代理來增強基本的推薦機制；(2) 互動導向方法，它透過自然對話和可解釋的建議促進動態使用者參與；以及 (3) 模擬導向方法，它採用多代理架構來模擬複雜的使用者-項目互動和系統動態。除了範例分類之外，我們分析了 LLM 驅動推薦代理的架構基礎，檢查其基本組成部分：輪廓建構、記憶體管理、策略規劃和動作執行。我們的調查延伸到對此領域中的基準資料集和評估架構進行全面分析。這項系統性檢查不僅闡明了 LLM 驅動代理推薦系統的現狀，還勾勒出此轉型領域中關鍵的挑戰和有前途的研究方向。

##### **Janus: Collaborative Vision Transformer Under Dynamic Network Environment**
2502.10047v1 by Linyi Jiang, Silvery D. Fu, Yifei Zhu, Bo Li

Vision Transformers (ViTs) have outperformed traditional Convolutional Neural
Network architectures and achieved state-of-the-art results in various computer
vision tasks. Since ViTs are computationally expensive, the models either have
to be pruned to run on resource-limited edge devices only or have to be
executed on remote cloud servers after receiving the raw data transmitted over
fluctuating networks. The resulting degraded performance or high latency all
hinder their widespread applications. In this paper, we present Janus, the
first framework for low-latency cloud-device collaborative Vision Transformer
inference over dynamic networks. Janus overcomes the intrinsic model
limitations of ViTs and realizes collaboratively executing ViT models on both
cloud and edge devices, achieving low latency, high accuracy, and low
communication overhead. Specifically, Janus judiciously combines token pruning
techniques with a carefully designed fine-to-coarse model splitting policy and
non-static mixed pruning policy. It attains a balance between accuracy and
latency by dynamically selecting the optimal pruning level and split point.
Experimental results across various tasks demonstrate that Janus enhances
throughput by up to 5.15 times and reduces latency violation ratios by up to
98.7% when compared with baseline approaches under various network
environments.

摘要：視覺Transformer (ViT) 已超越傳統的卷積神經網路架構，並在各種電腦視覺任務中取得了最先進的成果。由於 ViT 在計算上很昂貴，因此模型必須經過修剪才能在資源受限的邊緣裝置上執行，或是在接收透過波動網路傳輸的原始資料後，在遠端的雲端伺服器上執行。由此產生的效能降低或高延遲，都會阻礙其廣泛的應用。在本文中，我們提出 Janus，這是第一個用於在動態網路中進行低延遲雲端裝置協作視覺Transformer推論的架構。Janus 克服了 ViT 內在的模型限制，並實現了在雲端和邊緣裝置上協作執行 ViT 模型，達到了低延遲、高準確度和低通訊負擔。具體來說，Janus 明智地結合了令牌修剪技術，以及精心設計的精細到粗略的模型分割策略和非靜態混合修剪策略。它透過動態選擇最佳修剪層級和分割點，在準確度和延遲之間取得平衡。各種任務的實驗結果表明，與各種網路環境下的基準方法相比，Janus 將吞吐量提升了 5.15 倍，並將延遲違規率降低了 98.7%。

##### **Unsupervised Entity Alignment Based on Personalized Discriminative Rooted Tree**
2502.10044v1 by Yaming Yang, Zhe Wang, Ziyu Guan, Wei Zhao, Xinyan Huang, Xiaofei He

Entity Alignment (EA) is to link potential equivalent entities across
different knowledge graphs (KGs). Most existing EA methods are supervised as
they require the supervision of seed alignments, i.e., manually specified
aligned entity pairs. Very recently, several EA studies have made some attempts
to get rid of seed alignments. Despite achieving preliminary progress, they
still suffer two limitations: (1) The entity embeddings produced by their
GNN-like encoders lack personalization since some of the aggregation subpaths
are shared between different entities. (2) They cannot fully alleviate the
distribution distortion issue between candidate KGs due to the absence of the
supervised signal. In this work, we propose a novel unsupervised entity
alignment approach called UNEA to address the above two issues. First, we
parametrically sample a tree neighborhood rooted at each entity, and
accordingly develop a tree attention aggregation mechanism to extract a
personalized embedding for each entity. Second, we introduce an auxiliary task
of maximizing the mutual information between the input and the output of the KG
encoder, to regularize the model and prevent the distribution distortion.
Extensive experiments show that our UNEA achieves a new state-of-the-art for
the unsupervised EA task, and can even outperform many existing supervised EA
baselines.

摘要：實體對齊 (EA) 是將不同知識圖譜 (KG) 中的潛在等效實體連結起來。大多數現有的 EA 方法都是監督式的，因為它們需要種子對齊的監督，也就是手動指定的對齊實體配對。最近，幾項 EA 研究已嘗試擺脫種子對齊。儘管取得初步進展，它們仍有兩個限制：(1) 它們的 GNN 類編碼器產生的實體嵌入缺乏個人化，因為某些聚合子路徑在不同實體之間共享。(2) 由於缺乏監督訊號，它們無法完全緩解候選 KG 之間的分配失真問題。在這項工作中，我們提出一個名為 UNEA 的新無監督實體對齊方法來解決上述兩個問題。首先，我們參數化地對根植於每個實體的樹狀鄰域進行抽樣，並據此開發一個樹狀注意力聚合機制，為每個實體提取個人化嵌入。其次，我們引入一個輔助任務，將 KG 編碼器的輸入和輸出之間的互信息最大化，以規範模型並防止分配失真。大量的實驗表明，我們的 UNEA 為無監督 EA 任務實現了新的技術水準，甚至可以優於許多現有的監督式 EA 基準。

##### **POI-Enhancer: An LLM-based Semantic Enhancement Framework for POI Representation Learning**
2502.10038v1 by Jiawei Cheng, Jingyuan Wang, Yichuan Zhang, Jiahao Ji, Yuanshao Zhu, Zhibo Zhang, Xiangyu Zhao

POI representation learning plays a crucial role in handling tasks related to
user mobility data. Recent studies have shown that enriching POI
representations with multimodal information can significantly enhance their
task performance. Previously, the textual information incorporated into POI
representations typically involved only POI categories or check-in content,
leading to relatively weak textual features in existing methods. In contrast,
large language models (LLMs) trained on extensive text data have been found to
possess rich textual knowledge. However leveraging such knowledge to enhance
POI representation learning presents two key challenges: first, how to extract
POI-related knowledge from LLMs effectively, and second, how to integrate the
extracted information to enhance POI representations. To address these
challenges, we propose POI-Enhancer, a portable framework that leverages LLMs
to improve POI representations produced by classic POI learning models. We
first design three specialized prompts to extract semantic information from
LLMs efficiently. Then, the Dual Feature Alignment module enhances the quality
of the extracted information, while the Semantic Feature Fusion module
preserves its integrity. The Cross Attention Fusion module then fully
adaptively integrates such high-quality information into POI representations
and Multi-View Contrastive Learning further injects human-understandable
semantic information into these representations. Extensive experiments on three
real-world datasets demonstrate the effectiveness of our framework, showing
significant improvements across all baseline representations.

摘要：POI 表示學習在處理與使用者行動資料相關的任務中扮演著至關重要的角色。最近的研究顯示，使用多模態資訊豐富 POI 表示可以大幅提升其任務效能。先前納入 POI 表示的文字資訊通常只包含 POI 類別或報到內容，導致現有方法中的文字特徵相對薄弱。相比之下，在大量文字資料上訓練的大型語言模型 (LLM) 被發現擁有豐富的文字知識。然而，要利用此類知識來加強 POI 表示學習，會面臨兩個主要挑戰：首先，如何有效從 LLM 中萃取與 POI 相關的知識；其次，如何整合萃取的資訊來加強 POI 表示。為了應對這些挑戰，我們提出 POI-Enhancer，這是一個可攜式架構，利用 LLM 來改善傳統 POI 學習模型產生的 POI 表示。我們首先設計三個專門提示，以有效率的方式從 LLM 中萃取語義資訊。接著，雙重特徵比對模組提升萃取資訊的品質，而語義特徵融合模組則保留其完整性。然後，交叉注意力融合模組將此類高品質資訊完全自適應地整合到 POI 表示中，而多視圖對比學習進一步將人類可理解的語義資訊注入這些表示中。在三個真實世界資料集上進行的廣泛實驗證明了我們架構的有效性，顯示在所有基準表示上都有顯著的進步。

##### **Probabilistic Lexical Manifold Construction in Large Language Models via Hierarchical Vector Field Interpolation**
2502.10013v1 by Clive Pendleton, Ewan Harrington, Giles Fairbrother, Jasper Arkwright, Nigel Fenwick, Richard Katrix

Hierarchical vector field interpolation introduces a structured probabilistic
framework for lexical representation, ensuring that word embeddings transition
smoothly across a continuous manifold rather than being constrained to discrete
token mappings. The proposed methodology constructs a probabilistic function
space where word representations adhere to topological consistency, mitigating
representational discontinuities commonly observed in transformer-based
embeddings. Empirical evaluations reveal that probabilistic constraints enhance
lexical coherence by refining contextual relationships, leading to improvements
in semantic stability across multiple linguistic distributions. The application
of divergence minimization techniques ensures that interpolated embeddings
maintain probabilistic consistency while preserving computational feasibility
for large-scale implementations. Experimental findings demonstrate that
interpolated lexical manifolds improve representation density alignment,
reducing anisotropic distortions in contextual embedding distributions.
Comparative analyses with standard transformer-based models highlight that
structured interpolation yields more stable representations, particularly in
tasks requiring fine-grained semantic differentiation. The statistical
evaluation of embedding divergence confirms that probabilistic lexical
manifolds reduce representational inconsistencies while maintaining coherence
across varying scales of contextual abstraction. An assessment of computational
efficiency reveals that while interpolation introduces minor processing
overhead, the structured representation learning approach remains scalable for
practical deployment.

摘要：分层向量场插值法为词汇表征引入了一个结构化的概率框架，确保词嵌入在连续流形上平滑过渡，而不是受限于离散标记映射。所提出的方法构建了一个概率函数空间，其中单词表征遵循拓扑一致性，减轻了基于 Transformer 的嵌入中常见的表征不连续性。实证评估表明，概率约束通过细化上下文关系来增强词汇连贯性，从而提高跨多个语言分布的语义稳定性。散度最小化技术的应用确保了插值嵌入保持概率一致性，同时为大规模实现保留了计算可行性。实验结果表明，插值词汇流形改进了表征密度对齐，减少了上下文嵌入分布中的各向异性失真。与基于 Transformer 的标准模型的比较分析强调，结构化插值产生了更稳定的表征，特别是在需要细粒度语义差异化的任务中。嵌入散度的统计评估证实，概率词汇流形减少了表征不一致性，同时保持了在不同规模的上下文抽象中的连贯性。对计算效率的评估表明，虽然插值引入了较小的处理开销，但结构化表征学习方法对于实际部署仍然具有可扩展性。

##### **Dream to Drive: Model-Based Vehicle Control Using Analytic World Models**
2502.10012v1 by Asen Nachkov, Danda Pani Paudel, Jan-Nico Zaech, Davide Scaramuzza, Luc Van Gool

Differentiable simulators have recently shown great promise for training
autonomous vehicle controllers. Being able to backpropagate through them, they
can be placed into an end-to-end training loop where their known dynamics turn
into useful priors for the policy to learn, removing the typical black box
assumption of the environment. So far, these systems have only been used to
train policies. However, this is not the end of the story in terms of what they
can offer. Here, for the first time, we use them to train world models.
Specifically, we present three new task setups that allow us to learn next
state predictors, optimal planners, and optimal inverse states. Unlike analytic
policy gradients (APG), which requires the gradient of the next simulator state
with respect to the current actions, our proposed setups rely on the gradient
of the next state with respect to the current state. We call this approach
Analytic World Models (AWMs) and showcase its applications, including how to
use it for planning in the Waymax simulator. Apart from pushing the limits of
what is possible with such simulators, we offer an improved training recipe
that increases performance on the large-scale Waymo Open Motion dataset by up
to 12% compared to baselines at essentially no additional cost.

摘要：可微分模拟器最近在训练自动驾驶汽车控制器方面显示出了很大的前景。由于能够反向传播，它们可以被置于端到端训练循环中，其中它们已知的动态变成了策略学习的有用先验，消除了环境的典型黑盒假设。到目前为止，这些系统仅用于训练策略。然而，这并不是它们所能提供的内容的终点。在这里，我们首次使用它们来训练世界模型。具体来说，我们提出了三种新的任务设置，使我们能够学习下一个状态预测器、最优规划器和最优逆状态。与需要下一个模拟器状态相对于当前动作的梯度的解析策略梯度 (APG) 不同，我们提出的设置依赖于下一个状态相对于当前状态的梯度。我们称这种方法为解析世界模型 (AWM)，并展示了它的应用，包括如何在 Waymax 模拟器中使用它进行规划。除了推动此类模拟器可能的极限之外，我们还提供了一种改进的训练方法，与基线相比，它将大规模 Waymo Open Motion 数据集上的性能提高了 12%，而几乎没有额外的成本。

##### **SciClaimHunt: A Large Dataset for Evidence-based Scientific Claim Verification**
2502.10003v1 by Sujit Kumar, Anshul Sharma, Siddharth Hemant Khincha, Gargi Shroff, Sanasam Ranbir Singh, Rahul Mishra

Verifying scientific claims presents a significantly greater challenge than
verifying political or news-related claims. Unlike the relatively broad
audience for political claims, the users of scientific claim verification
systems can vary widely, ranging from researchers testing specific hypotheses
to everyday users seeking information on a medication. Additionally, the
evidence for scientific claims is often highly complex, involving technical
terminology and intricate domain-specific concepts that require specialized
models for accurate verification. Despite considerable interest from the
research community, there is a noticeable lack of large-scale scientific claim
verification datasets to benchmark and train effective models. To bridge this
gap, we introduce two large-scale datasets, SciClaimHunt and SciClaimHunt_Num,
derived from scientific research papers. We propose several baseline models
tailored for scientific claim verification to assess the effectiveness of these
datasets. Additionally, we evaluate models trained on SciClaimHunt and
SciClaimHunt_Num against existing scientific claim verification datasets to
gauge their quality and reliability. Furthermore, we conduct human evaluations
of the claims in proposed datasets and perform error analysis to assess the
effectiveness of the proposed baseline models. Our findings indicate that
SciClaimHunt and SciClaimHunt_Num serve as highly reliable resources for
training models in scientific claim verification.

摘要：驗證科學主張比驗證政治或新聞相關主張困難得多。與政治主張相對廣泛的受眾不同，科學主張驗證系統的使用者差異很大，從測試特定假設的研究人員到尋求藥物資訊的日常使用者。此外，科學主張的證據通常非常複雜，涉及技術術語和需要專業模型才能準確驗證的複雜領域特定概念。儘管研究社群有相當大的興趣，但顯著缺乏用於基準測試和訓練有效模型的大規模科學主張驗證資料集。為了彌補這個差距，我們從科學研究論文中引入了兩個大規模資料集，SciClaimHunt 和 SciClaimHunt_Num。我們提出了幾個針對科學主張驗證量身打造的基準模型，以評估這些資料集的有效性。此外，我們評估在 SciClaimHunt 和 SciClaimHunt_Num 上訓練的模型，並針對現有的科學主張驗證資料集，以評估它們的品質和可靠性。此外，我們對所提出的資料集中的主張進行人工評估，並執行錯誤分析以評估所提出的基準模型的有效性。我們的研究結果表明，SciClaimHunt 和 SciClaimHunt_Num 可作為訓練科學主張驗證模型的高度可靠資源。

##### **EmbBERT-Q: Breaking Memory Barriers in Embedded NLP**
2502.10001v1 by Riccardo Bravin, Massimo Pavan, Hazem Hesham Yousef Shalby, Fabrizio Pittorino, Manuel Roveri

Large Language Models (LLMs) have revolutionized natural language processing,
setting new standards across a wide range of applications. However, their
relevant memory and computational demands make them impractical for deployment
on technologically-constrained tiny devices such as wearable devices and
Internet-of-Things units. To address this limitation, we introduce EmbBERT-Q, a
novel tiny language model specifically designed for tiny devices with stringent
memory constraints. EmbBERT-Q achieves state-of-the-art (SotA) accuracy in
Natural Language Processing tasks in this scenario, with a total memory
footprint (weights and activations) of just 781 kB, representing a 25x
reduction in size with respect to SotA models. By combining architectural
innovations with hardware-compatible 8-bit quantization, EmbBERT-Q consistently
outperforms several baseline models scaled down to a 2 MB memory budget (i.e.,
the maximum memory typically available in tiny devices), including heavily
compressed versions of BERT and MAMBA. Extensive experimental evaluations on
both a selected benchmark dataset, TinyNLP, specifically curated to evaluate
Tiny Language Models in NLP tasks and real-world scenarios, and the GLUE
benchmark, demonstrate EmbBERT-Q ability to deliver competitive accuracy with
respect to existing approaches, achieving an unmatched balance between memory
and performance. To ensure the complete and immediate reproducibility of all
our results, we release all code, scripts, and model checkpoints at
https://github.com/RiccardoBravin/tiny-LLM.

摘要：大型語言模型 (LLM) 徹底改變了自然語言處理，在廣泛的應用中樹立了新的標準。然而，它們相關的記憶體和運算需求使得它們不切實際地部署在技術受限的小型設備上，例如穿戴式設備和物聯網單元。為了解決這個限制，我們引入了 EmbBERT-Q，這是一個專為具有嚴格記憶體限制的小型設備設計的新型小型語言模型。EmbBERT-Q 在這種情況下達到了自然語言處理任務的最新技術 (SotA) 準確度，總記憶體使用量（權重和激活）僅為 781 kB，與 SotA 模型相比，尺寸縮小了 25 倍。通過將架構創新與硬體相容的 8 位量化相結合，EmbBERT-Q 持續優於縮小到 2 MB 記憶體預算的幾個基準模型（即，小型設備中通常可用的最大記憶體），包括 BERT 和 MAMBA 的高度壓縮版本。在精選基準資料集 TinyNLP（專門用於評估 NLP 任務中的小型語言模型和實際場景）和 GLUE 基準上進行的廣泛實驗評估，證明了 EmbBERT-Q 在現有方法方面提供競爭準確度的能力，在記憶體和效能之間取得了無與倫比的平衡。為了確保所有結果的完整且立即重現性，我們在 https://github.com/RiccardoBravin/tiny-LLM 上釋出所有程式碼、指令碼和模型檢查點。

##### **Decision Information Meets Large Language Models: The Future of Explainable Operations Research**
2502.09994v1 by Yansen Zhang, Qingcan Kang, Wing Yin Yu, Hailei Gong, Xiaojin Fu, Xiongwei Han, Tao Zhong, Chen Ma

Operations Research (OR) is vital for decision-making in many industries.
While recent OR methods have seen significant improvements in automation and
efficiency through integrating Large Language Models (LLMs), they still
struggle to produce meaningful explanations. This lack of clarity raises
concerns about transparency and trustworthiness in OR applications. To address
these challenges, we propose a comprehensive framework, Explainable Operations
Research (EOR), emphasizing actionable and understandable explanations
accompanying optimization. The core of EOR is the concept of Decision
Information, which emerges from what-if analysis and focuses on evaluating the
impact of complex constraints (or parameters) changes on decision-making.
Specifically, we utilize bipartite graphs to quantify the changes in the OR
model and adopt LLMs to improve the explanation capabilities. Additionally, we
introduce the first industrial benchmark to rigorously evaluate the
effectiveness of explanations and analyses in OR, establishing a new standard
for transparency and clarity in the field.

摘要：作業研究 (OR) 對許多產業的決策制定至關重要。雖然近期的 OR 方法已透過整合大型語言模型 (LLM) 在自動化和效率方面取得顯著的進步，但它們在產生有意義的解釋方面仍面臨挑戰。這種缺乏明確性的情況會對 OR 應用中的透明度和可信度造成疑慮。為了應對這些挑戰，我們提出一個全面的架構，即可解釋作業研究 (EOR)，強調在最佳化過程中提供可操作且易於理解的解釋。EOR 的核心是決策資訊的概念，它源自假設分析，並專注於評估複雜約束條件 (或參數) 變更對決策制定的影響。具體來說，我們利用二部圖量化 OR 模型的變化，並採用 LLM 來改善解釋能力。此外，我們引入了第一個產業基準，以嚴格評估 OR 中解釋和分析的有效性，為該領域的透明度和清晰度建立新的標準。

##### **Large Language Diffusion Models**
2502.09992v1 by Shen Nie, Fengqi Zhu, Zebin You, Xiaolu Zhang, Jingyang Ou, Jun Hu, Jun Zhou, Yankai Lin, Ji-Rong Wen, Chongxuan Li

Autoregressive models (ARMs) are widely regarded as the cornerstone of large
language models (LLMs). We challenge this notion by introducing LLaDA, a
diffusion model trained from scratch under the pre-training and supervised
fine-tuning (SFT) paradigm. LLaDA models distributions through a forward data
masking process and a reverse process, parameterized by a vanilla Transformer
to predict masked tokens. By optimizing a likelihood bound, it provides a
principled generative approach for probabilistic inference. Across extensive
benchmarks, LLaDA demonstrates strong scalability, outperforming our
self-constructed ARM baselines. Remarkably, LLaDA 8B is competitive with strong
LLMs like LLaMA3 8B in in-context learning and, after SFT, exhibits impressive
instruction-following abilities in case studies such as multi-turn dialogue.
Moreover, LLaDA addresses the reversal curse, surpassing GPT-4o in a reversal
poem completion task. Our findings establish diffusion models as a viable and
promising alternative to ARMs, challenging the assumption that key LLM
capabilities discussed above are inherently tied to ARMs.

摘要：自回归模型 (ARM) 被广泛认为是大型语言模型 (LLM) 的基石。我们通过引入 LLaDA 来挑战这一概念，LLaDA 是一种在预训练和监督微调 (SFT) 范例下从头开始训练的扩散模型。LLaDA 通过正向数据掩蔽过程和反向过程对分布建模，由一个香草 Transformer 参数化以预测被掩蔽的标记。通过优化似然界，它为概率推理提供了一种原则性的生成方法。在广泛的基准测试中，LLaDA 表现出很强的可扩展性，优于我们自己构建的 ARM 基线。值得注意的是，LLaDA 8B 在上下文学习中与 LLaMA3 8B 等强大的 LLM 具有竞争力，并且在 SFT 之后，在多轮对话等案例研究中表现出令人印象深刻的指令遵循能力。此外，LLaDA 解决了解析诅咒，在反向诗歌完成任务中超越了 GPT-4o。我们的发现将扩散模型确立为 ARM 的可行且有前途的替代方案，挑战了上述关键 LLM 能力本质上与 ARM 相关联的假设。

##### **X-Boundary: Establishing Exact Safety Boundary to Shield LLMs from Multi-Turn Jailbreaks without Compromising Usability**
2502.09990v1 by Xiaoya Lu, Dongrui Liu, Yi Yu, Luxin Xu, Jing Shao

Despite the rapid development of safety alignment techniques for LLMs,
defending against multi-turn jailbreaks is still a challenging task. In this
paper, we conduct a comprehensive comparison, revealing that some existing
defense methods can improve the robustness of LLMs against multi-turn
jailbreaks but compromise usability, i.e., reducing general capabilities or
causing the over-refusal problem. From the perspective of mechanism
interpretability of LLMs, we discover that these methods fail to establish a
boundary that exactly distinguishes safe and harmful feature representations.
Therefore, boundary-safe representations close to harmful representations are
inevitably disrupted, leading to a decline in usability. To address this issue,
we propose X-Boundary to push harmful representations away from boundary-safe
representations and obtain an exact distinction boundary. In this way, harmful
representations can be precisely erased without disrupting safe ones.
Experimental results show that X-Boundary achieves state-of-the-art defense
performance against multi-turn jailbreaks, while reducing the over-refusal rate
by about 20% and maintaining nearly complete general capability. Furthermore,
we theoretically prove and empirically verify that X-Boundary can accelerate
the convergence process during training. Please see our code at:
https://github.com/AI45Lab/X-Boundary.

摘要：儘管 LLM 的安全校準技術發展迅速，但防禦多輪越獄仍然是一項具有挑戰性的任務。在本文中，我們進行了一項全面的比較，揭示了一些現有的防禦方法可以提高 LLM 對多輪越獄的穩健性，但會損害可用性，例如，降低一般能力或導致過度拒絕問題。從 LLM 機制可解釋性的角度來看，我們發現這些方法未能建立一個準確區分安全和有害特徵表示的邊界。因此，接近有害表示的邊界安全表示不可避免地會受到破壞，導致可用性下降。為了解決這個問題，我們提出 X-Boundary，將有害表示從邊界安全表示中移除，並獲得一個精確的區分邊界。這樣，有害表示可以被精確地刪除，而不會破壞安全的表示。實驗結果表明，X-Boundary 在對抗多輪越獄方面取得了最先進的防禦性能，同時將過度拒絕率降低了約 20%，並保持了幾乎完整的通用能力。此外，我們在理論上證明並通過經驗驗證，X-Boundary 可以加速訓練過程中的收斂過程。請參閱我們的代碼：
https://github.com/AI45Lab/X-Boundary。

##### **LaRA: Benchmarking Retrieval-Augmented Generation and Long-Context LLMs - No Silver Bullet for LC or RAG Routing**
2502.09977v1 by Kuan Li, Liwen Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Shuai Wang, Minhao Cheng

Effectively incorporating external knowledge into Large Language Models
(LLMs) is crucial for enhancing their capabilities and addressing real-world
needs. Retrieval-Augmented Generation (RAG) offers an effective method for
achieving this by retrieving the most relevant fragments into LLMs. However,
the advancements in context window size for LLMs offer an alternative approach,
raising the question of whether RAG remains necessary for effectively handling
external knowledge. Several existing studies provide inconclusive comparisons
between RAG and long-context (LC) LLMs, largely due to limitations in the
benchmark designs. In this paper, we present LaRA, a novel benchmark
specifically designed to rigorously compare RAG and LC LLMs. LaRA encompasses
2,326 test cases across four practical QA task categories and three types of
naturally occurring long texts. Through systematic evaluation of seven
open-source and four proprietary LLMs, we find that the optimal choice between
RAG and LC depends on a complex interplay of factors, including the model's
parameter size, long-text capabilities, context length, task type, and the
characteristics of the retrieved chunks. Our findings provide actionable
guidelines for practitioners to effectively leverage both RAG and LC approaches
in developing and deploying LLM applications. Our code and dataset is provided
at:
\href{https://github.com/likuanppd/LaRA}{\textbf{https://github.com/likuanppd/LaRA}}.

摘要：有效地將外部知識整合至大型語言模型 (LLM) 對於提升其能力和滿足實際需求至關重要。檢索增強生成 (RAG) 提供一種有效的方法來達成此目的，方法是將最相關的片段檢索到 LLM 中。然而，LLM 的內容視窗大小的進展提供了另一種方法，引發了 RAG 是否仍然是有效處理外部知識的必要條件的問題。由於基準設計的限制，現有研究在 RAG 和長內容 (LC) LLM 之間提供了不確定的比較。在本文中，我們提出了 LaRA，一個專門設計用於嚴格比較 RAG 和 LC LLM 的新基準。LaRA 涵蓋四個實用 QA 任務類別和三種類型的自然發生的長文本中的 2,326 個測試案例。通過對七個開源和四個專有 LLM 的系統評估，我們發現 RAG 和 LC 之間的最佳選擇取決於多種因素的複雜交互作用，包括模型的參數大小、長文本能力、內容長度、任務類型和檢索片段的特性。我們的研究結果為實務人員提供了可行的指導方針，以便在開發和部署 LLM 應用程式時有效地利用 RAG 和 LC 方法。我們的程式碼和資料集可在以下位置取得：
\href{https://github.com/likuanppd/LaRA}{\textbf{https://github.com/likuanppd/LaRA}}。

##### **Has My System Prompt Been Used? Large Language Model Prompt Membership Inference**
2502.09974v1 by Roman Levin, Valeriia Cherepanova, Abhimanyu Hans, Avi Schwarzschild, Tom Goldstein

Prompt engineering has emerged as a powerful technique for optimizing large
language models (LLMs) for specific applications, enabling faster prototyping
and improved performance, and giving rise to the interest of the community in
protecting proprietary system prompts. In this work, we explore a novel
perspective on prompt privacy through the lens of membership inference. We
develop Prompt Detective, a statistical method to reliably determine whether a
given system prompt was used by a third-party language model. Our approach
relies on a statistical test comparing the distributions of two groups of model
outputs corresponding to different system prompts. Through extensive
experiments with a variety of language models, we demonstrate the effectiveness
of Prompt Detective for prompt membership inference. Our work reveals that even
minor changes in system prompts manifest in distinct response distributions,
enabling us to verify prompt usage with statistical significance.

摘要：提示工程已成為針對特定應用最佳化大型語言模型 (LLM) 的強大技術，可實現更快速的原型製作和更佳的效能，並引起社群對保護專有系統提示的興趣。在這項工作中，我們透過成員推論的觀點探討提示隱私的新觀點。我們開發了提示偵探，這是一種統計方法，可可靠地判斷第三方語言模型是否使用了給定的系統提示。我們的做法依賴於統計檢定，比較對應於不同系統提示的兩組模型輸出的分布。透過對各種語言模型進行廣泛的實驗，我們展示了提示偵探在提示成員推論方面的有效性。我們的研究顯示，即使系統提示有微小的變更，也會在不同的回應分布中顯現，讓我們能夠以統計顯著性驗證提示使用。

##### **Conditional Latent Coding with Learnable Synthesized Reference for Deep Image Compression**
2502.09971v1 by Siqi Wu, Yinda Chen, Dong Liu, Zhihai He

In this paper, we study how to synthesize a dynamic reference from an
external dictionary to perform conditional coding of the input image in the
latent domain and how to learn the conditional latent synthesis and coding
modules in an end-to-end manner. Our approach begins by constructing a
universal image feature dictionary using a multi-stage approach involving
modified spatial pyramid pooling, dimension reduction, and multi-scale feature
clustering. For each input image, we learn to synthesize a conditioning latent
by selecting and synthesizing relevant features from the dictionary, which
significantly enhances the model's capability in capturing and exploring image
source correlation. This conditional latent synthesis involves a
correlation-based feature matching and alignment strategy, comprising a
Conditional Latent Matching (CLM) module and a Conditional Latent Synthesis
(CLS) module. The synthesized latent is then used to guide the encoding
process, allowing for more efficient compression by exploiting the correlation
between the input image and the reference dictionary. According to our
theoretical analysis, the proposed conditional latent coding (CLC) method is
robust to perturbations in the external dictionary samples and the selected
conditioning latent, with an error bound that scales logarithmically with the
dictionary size, ensuring stability even with large and diverse dictionaries.
Experimental results on benchmark datasets show that our new method improves
the coding performance by a large margin (up to 1.2 dB) with a very small
overhead of approximately 0.5\% bits per pixel. Our code is publicly available
at https://github.com/ydchen0806/CLC.

摘要：<paragraph>在本文中，我们研究如何从外部字典中合成动态参考，以在潜在域中对输入图像进行条件编码，以及如何以端到端的方式学习条件潜在合成和编码模块。我们的方法首先使用多阶段方法构建通用图像特征字典，该方法涉及修改后的空间金字塔池化、降维和多尺度特征聚类。对于每个输入图像，我们学习通过从字典中选择和合成相关特征来合成条件潜在，这极大地增强了模型捕获和探索图像源相关性的能力。这种条件潜在合成涉及基于相关性的特征匹配和对齐策略，包括条件潜在匹配 (CLM) 模块和条件潜在合成 (CLS) 模块。然后使用合成的潜在来指导编码过程，通过利用输入图像与参考字典之间的相关性，实现更有效的压缩。根据我们的理论分析，所提出的条件潜在编码 (CLC) 方法对外部字典样本和所选条件潜在中的扰动具有鲁棒性，其误差范围与字典大小成对数比例，即使对于大而多样的字典也能确保稳定性。基准数据集上的实验结果表明，我们的新方法将编码性能提高了很大幅度（高达 1.2 dB），而每像素的开销非常小，约为 0.5%。我们的代码已公开发布，网址为 https://github.com/ydchen0806/CLC。</paragraph>

##### **Data Valuation using Neural Networks for Efficient Instruction Fine-Tuning**
2502.09969v1 by Ishika Agarwal, Dilek Hakkani-Tur

Influence functions provide crucial insights into model training, but
existing methods suffer from large computational costs and limited
generalization. Particularly, recent works have proposed various metrics and
algorithms to calculate the influence of data using language models, which do
not scale well with large models and datasets. This is because of the expensive
forward and backward passes required for computation, substantial memory
requirements to store large models, and poor generalization of influence
estimates to new data. In this paper, we explore the use of small neural
networks -- which we refer to as the InfluenceNetwork -- to estimate influence
values, achieving up to 99% cost reduction. Our evaluation demonstrates that
influence values can be estimated with models just 0.0027% the size of full
language models (we use 7B and 8B versions). We apply our algorithm of
estimating influence values (called NN-CIFT: Neural Networks for effiCient
Instruction Fine-Tuning) to the downstream task of subset selection for general
instruction fine-tuning. In our study, we include four state-of-the-art
influence functions and show no compromise in performance, despite large
speedups, between NN-CIFT and the original influence functions. We provide an
in-depth hyperparameter analyses of NN-CIFT. The code for our method can be
found here: https://github.com/agarwalishika/NN-CIFT.

摘要：影響函數提供模型訓練的重要見解，但現有方法存在運算成本高和泛化性有限的問題。特別是，最近的研究提出了各種指標和演算法，使用語言模型計算資料的影響，這些模型和資料集的規模並不理想。這是因為計算所需的昂貴前向和後向傳遞、儲存大型模型的大量記憶體需求，以及影響估計對新資料的泛化性不佳。在本文中，我們探討使用小型神經網路（我們稱之為 InfluenceNetwork）來估計影響值，達到高達 99% 的成本降低。我們的評估表明，影響值可以用僅為完整語言模型大小 0.0027% 的模型估計（我們使用 7B 和 8B 版本）。我們將估計影響值的演算法（稱為 NN-CIFT：用於高效指令微調的神經網路）應用於一般指令微調的子集選擇下游任務。在我們的研究中，我們納入了四種最先進的影響函數，並顯示在 NN-CIFT 和原始影響函數之間，儘管速度大幅提升，但效能沒有妥協。我們提供了 NN-CIFT 的深入超參數分析。我們的方法程式碼可以在這裡找到：https://github.com/agarwalishika/NN-CIFT。

##### **KGGen: Extracting Knowledge Graphs from Plain Text with Language Models**
2502.09956v1 by Belinda Mo, Kyssen Yu, Joshua Kazdan, Proud Mpala, Lisa Yu, Chris Cundy, Charilaos Kanatsoulis, Sanmi Koyejo

Recent interest in building foundation models for KGs has highlighted a
fundamental challenge: knowledge-graph data is relatively scarce. The
best-known KGs are primarily human-labeled, created by pattern-matching, or
extracted using early NLP techniques. While human-generated KGs are in short
supply, automatically extracted KGs are of questionable quality. We present a
solution to this data scarcity problem in the form of a text-to-KG generator
(KGGen), a package that uses language models to create high-quality graphs from
plaintext. Unlike other KG extractors, KGGen clusters related entities to
reduce sparsity in extracted KGs. KGGen is available as a Python library
(\texttt{pip install kg-gen}), making it accessible to everyone. Along with
KGGen, we release the first benchmark, Measure of of Information in Nodes and
Edges (MINE), that tests an extractor's ability to produce a useful KG from
plain text. We benchmark our new tool against existing extractors and
demonstrate far superior performance.

摘要：最近对于构建知识图谱基础模型的兴趣凸显了一个基本挑战：知识图谱数据相对稀缺。最知名的知识图谱主要为人标注，由模式匹配创建，或使用早期自然语言处理技术提取。虽然人生成的知识图谱供不应求，但自动提取的知识图谱质量堪忧。我们以文本到知识图谱生成器 (KGGen) 的形式为这一数据稀缺问题提供了一个解决方案，这是一个使用语言模型从纯文本创建高质量图表的包。与其他知识图谱提取器不同，KGGen 对相关实体进行聚类以减少提取的知识图谱中的稀疏性。KGGen 可用作 Python 库（\texttt{pip install kg-gen}），使其所有人都能访问。除了 KGGen，我们还发布了第一个基准测试，即节点和边信息度量 (MINE)，它测试了提取器从纯文本生成有用知识图谱的能力。我们针对现有提取器对我们的新工具进行基准测试，并展示了远超其性能。

##### **Diverse Inference and Verification for Advanced Reasoning**
2502.09955v1 by Iddo Drori, Gaston Longhitano, Mao Mao, Seunghwan Hyun, Yuke Zhang, Sungjun Park, Zachary Meeks, Xin-Yu Zhang, Ben Segev, Howard Yong, Nakul Verma, Avi Shporer, Alon Amit, Madeleine Udell

Reasoning LLMs such as OpenAI o1, o3 and DeepSeek R1 have made significant
progress in mathematics and coding, yet find challenging advanced tasks such as
International Mathematical Olympiad (IMO) combinatorics problems, Abstraction
and Reasoning Corpus (ARC) puzzles, and Humanity's Last Exam (HLE) questions.
We use a diverse inference approach that combines multiple models and methods
at test time. We find that verifying mathematics and code problems, and
rejection sampling on other problems is simple and effective. We automatically
verify correctness of solutions to IMO problems by Lean, and ARC puzzles by
code, and find that best-of-N effectively answers HLE questions. Our approach
increases answer accuracy on IMO combinatorics problems from 33.3% to 77.8%,
accuracy on HLE questions from 8% to 37%, and solves 80% of ARC puzzles that
948 humans could not and 26.5% of ARC puzzles that o3 high compute does not.
Test-time simulations, reinforcement learning, and meta-learning with inference
feedback improve generalization by adapting agent graph representations and
varying prompts, code, and datasets. Our approach is reliable, robust, and
scalable, and in the spirit of reproducible research, we will make it publicly
available upon publication.

摘要：推理 LLM，例如 OpenAI o1、o3 和 DeepSeek R1，已在数学和编码方面取得了重大进展，但发现诸如国际数学奥林匹克竞赛 (IMO) 组合问题、抽象和推理语料库 (ARC) 谜题和人类最后考试 (HLE) 问题等高级任务具有挑战性。我们在测试时使用了一种结合了多种模型和方法的多样化推理方法。我们发现验证数学和代码问题以及对其他问题进行拒绝采样既简单又有效。我们通过 Lean 自动验证 IMO 问题的解决方案的正确性，并通过代码验证 ARC 谜题，并发现 N 中最优有效地回答了 HLE 问题。我们的方法将 IMO 组合问题的答案准确性从 33.3% 提高到 77.8%，将 HLE 问题的准确性从 8% 提高到 37%，并且解决了 948 人无法解决的 80% 的 ARC 谜题和 o3 高计算无法解决的 26.5% 的 ARC 谜题。测试时间模拟、强化学习和具有推理反馈的元学习通过调整代理图表示并改变提示、代码和数据集来提高泛化能力。我们的方法可靠、稳健且可扩展，并且本着可重复研究的精神，我们将在发表后公开提供。

##### **Using MRNet to Predict Lunar Rock Categories Detected by Chang'e 5 Probe**
2502.09952v1 by Jin Cui, Yifei Zou, Siyuan Zhang

China's Chang'e 5 mission has been a remarkable success, with the chang'e 5
lander traveling on the Oceanus Procellarum to collect images of the lunar
surface. Over the past half century, people have brought back some lunar rock
samples, but its quantity does not meet the need for research. Under current
circumstances, people still mainly rely on the analysis of rocks on the lunar
surface through the detection of lunar rover. The Oceanus Procellarum, chosen
by Chang'e 5 mission, contains various kind of rock species. Therefore, we
first applied to the National Astronomical Observatories of the China under the
Chinese Academy of Sciences for the Navigation and Terrain Camera (NaTeCam) of
the lunar surface image, and established a lunar surface rock image data set
CE5ROCK. The data set contains 100 images, which randomly divided into
training, validation and test set. Experimental results show that the
identification accuracy testing on convolutional neural network (CNN) models
like AlexNet or MobileNet is about to 40.0%. In order to make full use of the
global information in Moon images, this paper proposes the MRNet (MoonRockNet)
network architecture. The encoding structure of the network uses VGG16 for
feature extraction, and the decoding part adds dilated convolution and commonly
used U-Net structure on the original VGG16 decoding structure, which is more
conducive to identify more refined but more sparsely distributed types of lunar
rocks. We have conducted extensive experiments on the established CE5ROCK data
set, and the experimental results show that MRNet can achieve more accurate
rock type identification, and outperform other existing mainstream algorithms
in the identification performance.

摘要：中國的嫦娥五號任務獲得了非凡的成功，嫦娥五號著陸器在月海中穿梭，收集月球表面的影像。在過去的半個世紀裡，人類帶回了一些月岩樣本，但其數量仍無法滿足研究需求。在目前的情況下，人們仍主要依賴於通過月球車探測月球表面岩石的分析。嫦娥五號任務所選定的月海，包含各種類型的岩石種類。因此，我們首先向中國科學院國家天文台申請月球表面影像的導航地形相機（NaTeCam），並建立了月球表面岩石影像數據集 CE5ROCK。該數據集包含 100 張影像，隨機分為訓練、驗證和測試集。實驗結果表明，在 AlexNet 或 MobileNet 等卷積神經網路（CNN）模型上進行的識別準確度測試約為 40.0%。為了充分利用月球影像中的全局資訊，本文提出了 MRNet（MoonRockNet）網路架構。該網路的編碼結構使用 VGG16 進行特徵提取，而解碼部分則在原始 VGG16 解碼結構上添加了膨脹卷積和常用的 U-Net 結構，這更有利於識別更精細但分布更稀疏的月岩類型。我們對已建立的 CE5ROCK 數據集進行了廣泛的實驗，實驗結果表明，MRNet 可以實現更準確的岩石類型識別，並在識別性能上優於其他現有的主流演算法。

##### **Analyzing Patient Daily Movement Behavior Dynamics Using Two-Stage Encoding Model**
2502.09947v1 by Jin Cui, Alexander Capstick, Payam Barnaghi, Gregory Scott

In the analysis of remote healthcare monitoring data, time series
representation learning offers substantial value in uncovering deeper patterns
of patient behavior, especially given the fine temporal granularity of the
data. In this study, we focus on a dataset of home activity records from people
living with Dementia. We propose a two-stage self-supervised learning approach.
The first stage involves converting time-series activities into text strings,
which are then encoded by a fine-tuned language model. In the second stage,
these time-series vectors are bi-dimensionalized for applying PageRank method,
to analyze latent state transitions to quantitatively assess participants
behavioral patterns and identify activity biases. These insights, combined with
diagnostic data, aim to support personalized care interventions.

摘要：在遠程醫療監控數據分析中，時序表示學習在揭示患者行為的更深層模式方面提供了實質性的價值，特別是考慮到數據的精細時間粒度。在本研究中，我們專注於痴呆症患者居家活動記錄的數據集。我們提出了一種兩階段的自我監督學習方法。第一階段涉及將時序活動轉換為文本串，然後由微調語言模型編碼。在第二階段，這些時序向量被雙維化以應用 PageRank 方法，分析潛在狀態轉換以定量評估參與者的行為模式並識別活動偏差。這些見解與診斷數據相結合，旨在支持個性化護理干預。

##### **Self-Supervised Learning for Neural Topic Models with Variance-Invariance-Covariance Regularization**
2502.09944v1 by Weiran Xu, Kengo Hirami, Koji Eguchi

In our study, we propose a self-supervised neural topic model (NTM) that
combines the power of NTMs and regularized self-supervised learning methods to
improve performance. NTMs use neural networks to learn latent topics hidden
behind the words in documents, enabling greater flexibility and the ability to
estimate more coherent topics compared to traditional topic models. On the
other hand, some self-supervised learning methods use a joint embedding
architecture with two identical networks that produce similar representations
for two augmented versions of the same input. Regularizations are applied to
these representations to prevent collapse, which would otherwise result in the
networks outputting constant or redundant representations for all inputs. Our
model enhances topic quality by explicitly regularizing latent topic
representations of anchor and positive samples. We also introduced an
adversarial data augmentation method to replace the heuristic sampling method.
We further developed several variation models including those on the basis of
an NTM that incorporates contrastive learning with both positive and negative
samples. Experimental results on three datasets showed that our models
outperformed baselines and state-of-the-art models both quantitatively and
qualitatively.

摘要：在我們的研究中，我們提出了一個自我監督的神經主題模型 (NTM)，它結合了 NTM 的功能和正規化的自我監督學習方法來提升效能。NTM 使用神經網路來學習隱藏在文件字詞背後的潛在主題，與傳統主題模型相比，它能提供更大的彈性和估計出更一致的主題。另一方面，一些自我監督學習方法使用一個聯合嵌入架構，其中兩個相同的網路為同一個輸入的兩個擴充版本產生類似的表示。正規化會套用在這些表示上，以防止崩潰，否則會導致網路為所有輸入輸出恆定的或重複的表示。我們的模型透過明確正規化錨定樣本和正樣本的潛在主題表示來提升主題品質。我們也引進了一個對抗式資料擴充方法來取代啟發式抽樣方法。我們進一步開發了幾個變異模型，包括在 NTM 基礎上結合對比學習與正負樣本的模型。在三個資料集上的實驗結果顯示，我們的模型在質和量上都優於基準和最先進的模型。

##### **A Preliminary Exploration with GPT-4o Voice Mode**
2502.09940v1 by Yu-Xiang Lin, Chih-Kai Yang, Wei-Chih Chen, Chen-An Li, Chien-yu Huang, Xuanjun Chen, Hung-yi Lee

With the rise of multimodal large language models, GPT-4o stands out as a
pioneering model, driving us to evaluate its capabilities. This report assesses
GPT-4o across various tasks to analyze its audio processing and reasoning
abilities. We find that GPT-4o exhibits strong knowledge in audio, speech, and
music understanding, performing well in tasks like intent classification,
spoken command classification, semantic and grammatical reasoning.,
multilingual speech recognition, and singing analysis. It also shows greater
robustness against hallucinations than other large audio-language models
(LALMs). However, it struggles with tasks such as audio duration prediction and
instrument classification. Additionally, GPT-4o's safety mechanisms cause it to
decline tasks like speaker identification, age classification, MOS prediction,
and audio deepfake detection. Notably, the model exhibits a significantly
different refusal rate when responding to speaker verification tasks on
different datasets. This is likely due to variations in the accompanying
instructions or the quality of the input audio, suggesting the sensitivity of
its built-in safeguards. Finally, we acknowledge that model performance varies
with evaluation protocols. This report only serves as a preliminary exploration
of the current state of LALMs.

摘要：隨著多模態大型語言模型的興起，GPT-4o 作為開創性的模型脫穎而出，驅使我們評估其能力。本報告評估了 GPT-4o 在各種任務中的表現，以分析其音訊處理和推理能力。我們發現 GPT-4o 在音訊、語音和音樂理解方面展現了強大的知識，在諸如意圖分類、口語指令分類、語義和語法推理、多語言語音識別和歌唱分析等任務中表現良好。它還比其他大型音訊語言模型 (LALM) 具有更強的抗幻覺能力。然而，它在音訊持續時間預測和樂器分類等任務中表現不佳。此外，GPT-4o 的安全機制導致其拒絕執行諸如說話者識別、年齡分類、MOS 預測和音訊深度偽造檢測等任務。值得注意的是，該模型在不同資料集上對說話者驗證任務做出回應時，拒絕率有顯著差異。這可能是由於附帶說明或輸入音訊品質的差異所致，表明其內建防護措施的敏感性。最後，我們承認模型效能會隨著評估協定而有所不同。本報告僅作為對 LALM 目前狀態的初步探討。

##### **MIR-Bench: Benchmarking LLM's Long-Context Intelligence via Many-Shot In-Context Inductive Reasoning**
2502.09933v1 by Kai Yan, Zhan Ling, Kang Liu, Yifan Yang, Ting-Han Fan, Lingfeng Shen, Zhengyin Du, Jiecao Chen

Inductive Reasoning (IR), the ability to summarize rules from examples and
apply on new ones, has long been viewed as a primal ability for general
intelligence and widely studied by cognitive science and AI researchers. Many
benchmarks have been proposed to measure such ability for Large Language Models
(LLMs); however, they focus on few-shot (usually $<$10) setting and lack
evaluation for aggregating many pieces of information from long contexts. On
the other hand, the ever-growing context length of LLMs have brought forth the
novel paradigm of many-shot In-Context Learning (ICL), which addresses new
tasks with hundreds to thousands of examples without expensive and inefficient
fine-tuning. However, many-shot evaluations are mostly focused on
classification (a very limited aspect of IR), and popular long-context LLM
tasks such as Needle-In-A-Haystack (NIAH) seldom require complicated
intelligence for integrating many pieces of information. To fix the issues from
both worlds, we propose MIR-Bench, the first many-shot in-context inductive
reasoning benchmark that asks LLM to induce output via input-output examples
from underlying functions with diverse data format. Based on MIR-Bench, we
study many novel problems for inductive reasoning and many-shot ICL, including
robustness against erroneous shots and the effect of Chain-of-Thought (CoT),
and acquired insightful findings.

摘要：歸納推理 (IR) 是一種從範例中總結規則並應用到新範例的能力，長久以來被視為一般智能的原始能力，並受到認知科學和人工智慧研究人員廣泛的研究。許多基準測試已被提出用於衡量大型語言模型 (LLM) 的這種能力；然而，它們專注於少次嘗試 (通常 <$10) 的設定，並且缺乏從長語境中彙總許多資訊片段的評估。另一方面，LLM 不斷增長的語境長度帶來了許多次嘗試的語境學習 (ICL) 的新範例，它以數百到數千個範例來處理新任務，而無需昂貴且低效率的微調。然而，許多次嘗試的評估主要集中於分類 (IR 的一個非常有限的方面)，而流行的長語境 LLM 任務（例如針頭在乾草堆中 (NIAH)）很少需要複雜的智能來整合許多資訊片段。為了解決兩全其美的問題，我們提出了 MIR-Bench，這是第一個許多次嘗試的語境歸納推理基準測試，它要求 LLM 透過具有不同資料格式的底層函數的輸入輸出範例來推導輸出。根據 MIR-Bench，我們研究了歸納推理和許多次嘗試 ICL 的許多新問題，包括對錯誤嘗試的穩健性和思維鏈 (CoT) 的影響，並獲得了有見地的發現。

##### **TransGUNet: Transformer Meets Graph-based Skip Connection for Medical Image Segmentation**
2502.09931v1 by Ju-Hyeon Nam, Nur Suriza Syazwany, Sang-Chul Lee

Skip connection engineering is primarily employed to address the semantic gap
between the encoder and decoder, while also integrating global dependencies to
understand the relationships among complex anatomical structures in medical
image segmentation. Although several models have proposed transformer-based
approaches to incorporate global dependencies within skip connections, they
often face limitations in capturing detailed local features with high
computational complexity. In contrast, graph neural networks (GNNs) exploit
graph structures to effectively capture local and global features. Leveraging
these properties, we introduce an attentional cross-scale graph neural network
(ACS-GNN), which enhances the skip connection framework by converting
cross-scale feature maps into a graph structure and capturing complex
anatomical structures through node attention. Additionally, we observed that
deep learning models often produce uninformative feature maps, which degrades
the quality of spatial attention maps. To address this problem, we integrated
entropy-driven feature selection (EFS) with spatial attention, calculating an
entropy score for each channel and filtering out high-entropy feature maps. Our
innovative framework, TransGUNet, comprises ACS-GNN and EFS-based spatial
attentio} to effectively enhance domain generalizability across various
modalities by leveraging GNNs alongside a reliable spatial attention map,
ensuring more robust features within the skip connection. Through comprehensive
experiments and analysis, TransGUNet achieved superior segmentation performance
on six seen and eight unseen datasets, demonstrating significantly higher
efficiency compared to previous methods.

摘要：跳躍連接工程主要用於解決編碼器和解碼器之間的語義鴻溝，同時還整合全局依賴關係以了解醫學影像分割中複雜解剖結構之間的關係。儘管有幾個模型提出了基於Transformer的架構來整合跳躍連接中的全局依賴關係，但它們在以高計算複雜度擷取詳細的局部特徵時常常面臨限制。相比之下，圖神經網路 (GNN) 利用圖結構有效擷取局部和全局特徵。利用這些屬性，我們引入了注意力跨尺度圖神經網路 (ACS-GNN)，它通過將跨尺度特徵圖轉換為圖結構並通過節點注意力擷取複雜的解剖結構來增強跳躍連接框架。此外，我們觀察到深度學習模型通常會產生無意義的特徵圖，這會降低空間注意力圖的品質。為了解決這個問題，我們將熵驅動特徵選擇 (EFS) 與空間注意力整合在一起，為每個通道計算熵分數並濾出高熵特徵圖。我們創新的框架 TransGUNet 包含 ACS-GNN 和基於 EFS 的空間注意力，通過利用 GNN 以及可靠的空間注意力圖有效增強跨各種模態的域泛化能力，確保跳躍連接中更強大的特徵。透過全面的實驗和分析，TransGUNet 在六個已見和八個未見的資料集上實現了優異的分割效能，證明與先前的方法相比，效率顯著提高。

##### **Deep Tree Tensor Networks for Image Recognition**
2502.09928v1 by Chang Nie, Junfang Chen, Yajie Chen

Originating in quantum physics, tensor networks (TNs) have been widely
adopted as exponential machines and parameter decomposers for recognition
tasks. Typical TN models, such as Matrix Product States (MPS), have not yet
achieved successful application in natural image processing. When employed,
they primarily serve to compress parameters within off-the-shelf networks, thus
losing their distinctive capability to enhance exponential-order feature
interactions. This paper introduces a novel architecture named
\textit{\textbf{D}eep \textbf{T}ree \textbf{T}ensor \textbf{N}etwork} (DTTN),
which captures $2^L$-order multiplicative interactions across features through
multilinear operations, while essentially unfolding into a \emph{tree}-like TN
topology with the parameter-sharing property. DTTN is stacked with multiple
antisymmetric interacting modules (AIMs), and this design facilitates efficient
implementation. Moreover, we theoretically reveal the equivalency among
quantum-inspired TN models and polynomial and multilinear networks under
certain conditions, and we believe that DTTN can inspire more interpretable
studies in this field. We evaluate the proposed model against a series of
benchmarks and achieve excellent performance compared to its peers and
cutting-edge architectures. Our code will soon be publicly available.

摘要：源自量子物理学的张量网络 (TN) 已被广泛用作指数机器和参数分解器，用于识别任务。典型的 TN 模型（例如矩阵乘积态 (MPS)）尚未在自然图像处理中实现成功应用。在使用时，它们主要用于压缩现成网络中的参数，因此失去了增强指数级特征交互的独特能力。本文介绍了一种名为\textit{\textbf{D}eep \textbf{T}ree \textbf{T}ensor \textbf{N}etwork} (DTTN) 的新架构，它通过多线性运算捕获了跨特征的 $2^L$ 级乘法交互，同时本质上展开为具有参数共享属性的类似\emph{树}的 TN 拓扑。DTTN 与多个反对称交互模块 (AIM) 堆叠在一起，这种设计促进了高效实施。此外，我们在特定条件下从理论上揭示了量子启发 TN 模型与多项式和多线性网络之间的等效性，我们相信 DTTN 可以激发该领域更多可解释的研究。我们针对一系列基准评估了所提出的模型，与同类模型和前沿架构相比，取得了优异的性能。我们的代码很快就会公开。

##### **Granite Vision: a lightweight, open-source multimodal model for enterprise Intelligence**
2502.09927v1 by Granite Vision Team, Leonid Karlinsky, Assaf Arbelle, Abraham Daniels, Ahmed Nassar, Amit Alfassi, Bo Wu, Eli Schwartz, Dhiraj Joshi, Jovana Kondic, Nimrod Shabtay, Pengyuan Li, Roei Herzig, Shafiq Abedin, Shaked Perek, Sivan Harary, Udi Barzelay, Adi Raz Goldfarb, Aude Oliva, Ben Wieles, Bishwaranjan Bhattacharjee, Brandon Huang, Christoph Auer, Dan Gutfreund, David Beymer, David Wood, Hilde Kuehne, Jacob Hansen, Joseph Shtok, Ken Wong, Luis Angel Bathen, Mayank Mishra, Maksym Lysak, Michele Dolfi, Mikhail Yurochkin, Nikolaos Livathinos, Nimrod Harel, Ophir Azulai, Oshri Naparstek, Rafael Teixeira de Lima, Rameswar Panda, Sivan Doveh, Shubham Gupta, Subhro Das, Syed Zawad, Yusik Kim, Zexue He, Alexander Brooks, Gabe Goodhart, Anita Govindjee, Derek Leist, Ibrahim Ibrahim, Aya Soffer, David Cox, Kate Soule, Luis Lastras, Nirmit Desai, Shila Ofek-koifman, Sriram Raghavan, Tanveer Syeda-Mahmood, Peter Staar, Tal Drory, Rogerio Feris

We introduce Granite Vision, a lightweight large language model with vision
capabilities, specifically designed to excel in enterprise use cases,
particularly in visual document understanding. Our model is trained on a
comprehensive instruction-following dataset, including document-related tasks,
such as content extraction from tables, charts, diagrams, sketches, and
infographics, as well as general image tasks. The architecture of Granite
Vision is centered around visual modality alignment with a decoder-only, 2
billion parameter Granite large language model. Additionally, we introduce a
dedicated safety classification approach in test-time that leverages a sparse
set of attention vectors to identify potential harmful inputs. Despite its
lightweight architecture, Granite Vision achieves strong results in standard
benchmarks related to visual document understanding, as well as on the LiveXiv
benchmark, which is designed to avoid test set contamination by using a
constantly updated corpus of recently published Arxiv papers. We are releasing
the model under the Apache-2 license, allowing for both research and commercial
use, while offering complete visibility into the training data and other
relevant details. See https://huggingface.co/ibm-granite/ for model weights.

摘要：我們推出 Granite Vision，這是一個輕量級的大型語言模型，具備視覺能力，專門設計用於企業用例，特別是在視覺文件理解方面。我們的模型是根據一個全面的指令遵循資料集進行訓練，包括與文件相關的任務，例如從表格、圖表、圖解、草圖和資訊圖表中提取內容，以及一般的影像任務。Granite Vision 的架構圍繞著視覺模式對齊，只有一個解碼器，20 億個參數的 Granite 大型語言模型。此外，我們在測試時引入了一個專用的安全分類方法，它利用一組稀疏的注意力向量來識別潛在的惡意輸入。儘管其架構輕量級，但 Granite Vision 在與視覺文件理解相關的標準基準測試中取得了強勁的結果，以及在 LiveXiv 基準測試中，該基準測試旨在避免測試集污染，方法是使用不斷更新的近期發布的 Arxiv 論文語料庫。我們在 Apache-2  license 下發布該模型，允許研究和商業用途，同時提供對訓練資料和其他相關詳細資訊的完整可見性。請參閱 https://huggingface.co/ibm-granite/ 以取得模型權重。

##### **TaskGalaxy: Scaling Multi-modal Instruction Fine-tuning with Tens of Thousands Vision Task Types**
2502.09925v1 by Jiankang Chen, Tianke Zhang, Changyi Liu, Haojie Ding, Yaya Shi, Feng Cheng, Huihui Xiao, Bin Wen, Fan Yang, Tingting Gao, Di Zhang

Multimodal visual language models are gaining prominence in open-world
applications, driven by advancements in model architectures, training
techniques, and high-quality data. However, their performance is often limited
by insufficient task-specific data, leading to poor generalization and biased
outputs. Existing efforts to increase task diversity in fine-tuning datasets
are hindered by the labor-intensive process of manual task labeling, which
typically produces only a few hundred task types. To address this, we propose
TaskGalaxy, a large-scale multimodal instruction fine-tuning dataset comprising
19,227 hierarchical task types and 413,648 samples. TaskGalaxy utilizes GPT-4o
to enrich task diversity by expanding from a small set of manually defined
tasks, with CLIP and GPT-4o filtering those that best match open-source images,
and generating relevant question-answer pairs. Multiple models are employed to
ensure sample quality. This automated process enhances both task diversity and
data quality, reducing manual intervention. Incorporating TaskGalaxy into
LLaVA-v1.5 and InternVL-Chat-v1.0 models shows substantial performance
improvements across 16 benchmarks, demonstrating the critical importance of
task diversity. TaskGalaxy is publicly released at
https://github.com/Kwai-YuanQi/TaskGalaxy.

摘要：多模态视觉语言模型在开放世界应用中正变得越来越突出，这得益于模型架构、训练技术和高质量数据的进步。然而，它们的性能常常受到特定任务数据不足的限制，从而导致泛化能力差和输出有偏差。现有的努力是通过微调数据集来增加任务多样性，但受到人工任务标记劳动密集型过程的阻碍，通常只能产生几百种任务类型。为了解决这个问题，我们提出了 TaskGalaxy，这是一个包含 19,227 个分层任务类型和 413,648 个样本的大规模多模态指令微调数据集。TaskGalaxy 利用 GPT-4o 通过从一小部分手动定义的任务扩展来丰富任务多样性，并使用 CLIP 和 GPT-4o 筛选出与开源图像最匹配的任务，并生成相关的问答对。采用多个模型来确保样本质量。这个自动化过程既提高了任务多样性，又提高了数据质量，减少了人工干预。将 TaskGalaxy 纳入 LLaVA-v1.5 和 InternVL-Chat-v1.0 模型显示出跨越 16 个基准的实质性性能改进，证明了任务多样性的关键重要性。TaskGalaxy 已在 https://github.com/Kwai-YuanQi/TaskGalaxy 公开发布。

##### **Machine Learning for Phase Estimation in Satellite-to-Earth Quantum Communication**
2502.09920v1 by Nathan K Long, Robert Malaney, Kenneth J Grant

A global continuous-variable quantum key distribution (CV-QKD) network can be
established using a series of satellite-to-Earth channels. Increased
performance in such a network is provided by performing coherent measurement of
the optical quantum signals using a real local oscillator, calibrated locally
by encoding known information on transmitted reference pulses and using signal
phase error estimation algorithms. The speed and accuracy of the signal phase
error estimation algorithm are vital to practical CV-QKD implementation. Our
work provides a framework to analyze long short-term memory neural network (NN)
architecture parameterization, with respect to the quantum Cram\'er-Rao
uncertainty bound of the signal phase error estimation, with a focus on
reducing the model complexity. More specifically, we demonstrate that signal
phase error estimation can be achieved using a low-complexity NN architecture,
without significantly sacrificing accuracy. Our results significantly improve
the real-time performance of practical CV-QKD systems deployed over
satellite-to-Earth channels, thereby contributing to the ongoing development of
the Quantum Internet.

摘要：透過一系列衛星對地通道，可以建立全球連續變數量子密鑰分配 (CV-QKD) 網路。透過使用真實局部振盪器對光量子訊號進行相干測量，並透過編碼已知資訊於傳輸參考脈衝上，並使用訊號相位誤差估計演算法，在本地校正，可提升此類網路的效能。訊號相位誤差估計演算法的速度和準確度對於實際的 CV-QKD 實作至關重要。我們的研究提供了一個架構，用於分析長短期記憶神經網路 (NN) 架構參數化，相對於訊號相位誤差估計的量子 Cram\'er-Rao 不確定性界限，重點在於降低模型複雜度。更具體地說，我們證明了訊號相位誤差估計可以使用低複雜度 NN 架構來達成，而不會顯著犧牲準確度。我們的結果顯著改善了實際 CV-QKD 系統在衛星對地通道上部署的即時效能，從而有助於量子網際網路的持續發展。

##### **AttenGluco: Multimodal Transformer-Based Blood Glucose Forecasting on AI-READI Dataset**
2502.09919v1 by Ebrahim Farahmand, Reza Rahimi Azghan, Nooshin Taheri Chatrudi, Eric Kim, Gautham Krishna Gudur, Edison Thomaz, Giulia Pedrielli, Pavan Turaga, Hassan Ghasemzadeh

Diabetes is a chronic metabolic disorder characterized by persistently high
blood glucose levels (BGLs), leading to severe complications such as
cardiovascular disease, neuropathy, and retinopathy. Predicting BGLs enables
patients to maintain glucose levels within a safe range and allows caregivers
to take proactive measures through lifestyle modifications. Continuous Glucose
Monitoring (CGM) systems provide real-time tracking, offering a valuable tool
for monitoring BGLs. However, accurately forecasting BGLs remains challenging
due to fluctuations due to physical activity, diet, and other factors. Recent
deep learning models show promise in improving BGL prediction. Nonetheless,
forecasting BGLs accurately from multimodal, irregularly sampled data over long
prediction horizons remains a challenging research problem. In this paper, we
propose AttenGluco, a multimodal Transformer-based framework for long-term
blood glucose prediction. AttenGluco employs cross-attention to effectively
integrate CGM and activity data, addressing challenges in fusing data with
different sampling rates. Moreover, it employs multi-scale attention to capture
long-term dependencies in temporal data, enhancing forecasting accuracy. To
evaluate the performance of AttenGluco, we conduct forecasting experiments on
the recently released AIREADI dataset, analyzing its predictive accuracy across
different subject cohorts including healthy individuals, people with
prediabetes, and those with type 2 diabetes. Furthermore, we investigate its
performance improvements and forgetting behavior as new cohorts are introduced.
Our evaluations show that AttenGluco improves all error metrics, such as root
mean square error (RMSE), mean absolute error (MAE), and correlation, compared
to the multimodal LSTM model. AttenGluco outperforms this baseline model by
about 10% and 15% in terms of RMSE and MAE, respectively.

摘要：糖尿病是一种慢性代谢疾病，其特征是持续高血糖水平 (BGL)，导致严重并发症，如心血管疾病、神经病变和视网膜病变。预测 BGL 使患者能够将葡萄糖水平保持在安全范围内，并允许护理人员通过改变生活方式采取积极措施。持续葡萄糖监测 (CGM) 系统提供实时跟踪，为监测 BGL 提供了一个有价值的工具。然而，由于身体活动、饮食和其他因素导致的波动，准确预测 BGL 仍然具有挑战性。最近的深度学习模型显示出改善 BGL 预测的希望。尽管如此，从多模式、不规则采样的数据中准确预测长期预测范围内的 BGL 仍然是一个具有挑战性的研究问题。在本文中，我们提出了 AttenGluco，一个基于多模式 Transformer 的长期血糖预测框架。AttenGluco 采用交叉注意力来有效地整合 CGM 和活动数据，解决了以不同采样率融合数据中的挑战。此外，它采用多尺度注意力来捕获时间数据中的长期依赖关系，提高预测准确性。为了评估 AttenGluco 的性能，我们在最近发布的 AIREADI 数据集上进行预测实验，分析了其在不同受试者队列中的预测准确性，包括健康个体、患有糖尿病前期的人和患有 2 型糖尿病的人。此外，我们研究了随着新队列的引入，其性能的提升和遗忘行为。我们的评估表明，与多模式 LSTM 模型相比，AttenGluco 改进了所有误差指标，例如均方根误差 (RMSE)、平均绝对误差 (MAE) 和相关性。AttenGluco 在 RMSE 和 MAE 方面分别比这个基准模型高出约 10% 和 15%。

##### **AutoS$^2$earch: Unlocking the Reasoning Potential of Large Models for Web-based Source Search**
2502.09913v1 by Zhengqiu Zhu, Yatai Ji, Jiaheng Huang, Yong Zhao, Sihang Qiu, Rusheng Ju

Web-based management systems have been widely used in risk control and
industrial safety. However, effectively integrating source search capabilities
into these systems, to enable decision-makers to locate and address the hazard
(e.g., gas leak detection) remains a challenge. While prior efforts have
explored using web crowdsourcing and AI algorithms for source search decision
support, these approaches suffer from overheads in recruiting human
participants and slow response times in time-sensitive situations. To address
this, we introduce AutoS$^2$earch, a novel framework leveraging large models
for zero-shot source search in web applications. AutoS$^2$earch operates on a
simplified visual environment projected through a web-based display, utilizing
a chain-of-thought prompt designed to emulate human reasoning. The multi-modal
large language model (MLLMs) dynamically converts visual observations into
language descriptions, enabling the LLM to perform linguistic reasoning on four
directional choices. Extensive experiments demonstrate that AutoS$^2$earch
achieves performance nearly equivalent to human-AI collaborative source search
while eliminating dependency on crowdsourced labor. Our work offers valuable
insights in using web engineering to design such autonomous systems in other
industrial applications.

摘要：基於網路的管理系統已廣泛用於風險控管和工業安全。然而，有效地將來源搜尋功能整合到這些系統中，以使決策者能夠定位和處理危害（例如，氣體洩漏偵測）仍然是一項挑戰。雖然先前的努力已探討使用網路群眾外包和 AI 演算法來進行來源搜尋決策支援，但這些方法在招募人類參與者時會產生額外的負擔，且在時間敏感的情況下反應時間較慢。為了解決這個問題，我們引入了 AutoS$^2$earch，一個利用大型模型進行網路應用程式中零次學習來源搜尋的新架構。AutoS$^2$earch 運作在透過網路顯示器投影出的簡化視覺環境中，利用旨在模擬人類推理的思考鏈提示。多模態大型語言模型 (MLLM) 會動態地將視覺觀察轉換為語言描述，使 LLM 能對四個方向選擇執行語言推理。廣泛的實驗證明，AutoS$^2$earch 達到了幾乎等同於人類與 AI 協作來源搜尋的效能，同時消除了對群眾外包勞動的依賴。我們的研究提供了寶貴的見解，說明如何使用網路工程在其他工業應用中設計此類自主系統。

##### **The Ann Arbor Architecture for Agent-Oriented Programming**
2502.09903v1 by Wei Dong

In this paper, we reexamine prompt engineering for large language models
through the lens of automata theory. We argue that language models function as
automata and, like all automata, should be programmed in the languages they
accept, a unified collection of all natural and formal languages. Therefore,
traditional software engineering practices--conditioned on the clear separation
of programming languages and natural languages--must be rethought. We introduce
the Ann Arbor Architecture, a conceptual framework for agent-oriented
programming of language models, as a higher-level abstraction over raw token
generation, and provide a new perspective on in-context learning. Based on this
framework, we present the design of our agent platform Postline, and report on
our initial experiments in agent training.

摘要：在本文中，我们通过自动机理论重新审视大型语言模型的提示工程。我们认为语言模型作为自动机发挥作用，并且像所有自动机一样，应该用它们接受的语言进行编程，这是所有自然语言和形式语言的统一集合。因此，传统的软件工程实践（以编程语言和自然语言的明确分离为条件）必须重新考虑。我们介绍了安娜堡架构，这是一个面向代理的语言模型编程的概念框架，作为对原始标记生成的高级抽象，并提供了对上下文学习的新视角。基于此框架，我们展示了我们的代理平台 Postline 的设计，并报告了我们在代理训练中的初步实验。

##### **Artificial Intelligence in Spectroscopy: Advancing Chemistry from Prediction to Generation and Beyond**
2502.09897v1 by Kehan Guo, Yili Shen, Gisela Abigail Gonzalez-Montiel, Yue Huang, Yujun Zhou, Mihir Surve, Zhichun Guo, Prayel Das, Nitesh V Chawla, Olaf Wiest, Xiangliang Zhang

The rapid advent of machine learning (ML) and artificial intelligence (AI)
has catalyzed major transformations in chemistry, yet the application of these
methods to spectroscopic and spectrometric data, referred to as Spectroscopy
Machine Learning (SpectraML), remains relatively underexplored. Modern
spectroscopic techniques (MS, NMR, IR, Raman, UV-Vis) generate an ever-growing
volume of high-dimensional data, creating a pressing need for automated and
intelligent analysis beyond traditional expert-based workflows. In this survey,
we provide a unified review of SpectraML, systematically examining
state-of-the-art approaches for both forward tasks (molecule-to-spectrum
prediction) and inverse tasks (spectrum-to-molecule inference). We trace the
historical evolution of ML in spectroscopy, from early pattern recognition to
the latest foundation models capable of advanced reasoning, and offer a
taxonomy of representative neural architectures, including graph-based and
transformer-based methods. Addressing key challenges such as data quality,
multimodal integration, and computational scalability, we highlight emerging
directions such as synthetic data generation, large-scale pretraining, and few-
or zero-shot learning. To foster reproducible research, we also release an
open-source repository containing recent papers and their corresponding curated
datasets (https://github.com/MINE-Lab-ND/SpectrumML_Survey_Papers). Our survey
serves as a roadmap for researchers, guiding progress at the intersection of
spectroscopy and AI.

摘要：機器學習 (ML) 和人工智慧 (AI) 的快速發展
催化了化學領域的重大轉變，然而將這些
方法應用於光譜和光譜儀數據，稱為光譜
機器學習 (SpectraML)，仍然相對未被充分探索。現代
光譜技術 (MS、NMR、IR、拉曼、UV-Vis) 產生了不斷增長的
高維數據量，對傳統基於專家的工作流程之外的自動化和
智能分析產生了迫切需求。在此調查中，
我們提供了 SpectraML 的統一回顧，系統地檢查
最先進的方法，包括正向任務（分子到光譜
預測）和逆向任務（光譜到分子推論）。我們追溯了
光譜學中機器學習的歷史演變，從早期的模式識別到
具有先進推理能力的最新基礎模型，並提供了一個
代表性神經架構的分類，包括基於圖形和
基於Transformer的的方法。針對數據質量、
多模態整合和計算可擴展性等關鍵挑戰，我們重點介紹了新興
方向，例如合成數據生成、大規模預訓練和少
或零次學習。為了促進可重現的研究，我們還發布了一個
開源倉庫，其中包含最近的論文及其對應的策展
數據集 (https://github.com/MINE-Lab-ND/SpectrumML_Survey_Papers)。我們的調查
作為研究人員的路線圖，指導光譜學和人工智能交叉領域的進展。

##### **ArchRAG: Attributed Community-based Hierarchical Retrieval-Augmented Generation**
2502.09891v1 by Shu Wang, Yixiang Fang, Yingli Zhou, Xilin Liu, Yuchi Ma

Retrieval-Augmented Generation (RAG) has proven effective in integrating
external knowledge into large language models (LLMs) for question-answer (QA)
tasks. The state-of-the-art RAG approaches often use the graph data as the
external data since they capture the rich semantic information and link
relationships between entities. However, existing graph-based RAG approaches
cannot accurately identify the relevant information from the graph and also
consume large numbers of tokens in the online retrieval process. To address
these issues, we introduce a novel graph-based RAG approach, called Attributed
Community-based Hierarchical RAG (ArchRAG), by augmenting the question using
attributed communities, and also introducing a novel LLM-based hierarchical
clustering method. To retrieve the most relevant information from the graph for
the question, we build a novel hierarchical index structure for the attributed
communities and develop an effective online retrieval method. Experimental
results demonstrate that ArchRAG outperforms existing methods in terms of both
accuracy and token cost.

摘要：檢索增強生成 (RAG) 已證明可將外部知識整合到大型語言模型 (LLM)，用於問答 (QA) 任務。最先進的 RAG 方法通常使用圖形資料作為外部資料，因為它們擷取了豐富的語意資訊和實體之間的連結關係。然而，現有的基於圖形的 RAG 方法無法準確識別圖形中的相關資訊，而且在線上檢索過程中也會消耗大量的符號。為了解決這些問題，我們提出了一種新穎的基於圖形的 RAG 方法，稱為基於屬性社群的分層 RAG (ArchRAG)，透過使用屬性社群來擴充問題，並引入一種新穎的基於 LLM 的分層聚類方法。為了從圖形中檢索與問題最相關的資訊，我們為屬性社群建立了一個新穎的分層索引結構，並開發了一種有效的線上檢索方法。實驗結果證明，ArchRAG 在準確性和符號成本方面都優於現有方法。

##### **Video2Policy: Scaling up Manipulation Tasks in Simulation through Internet Videos**
2502.09886v1 by Weirui Ye, Fangchen Liu, Zheng Ding, Yang Gao, Oleh Rybkin, Pieter Abbeel

Simulation offers a promising approach for cheaply scaling training data for
generalist policies. To scalably generate data from diverse and realistic
tasks, existing algorithms either rely on large language models (LLMs) that may
hallucinate tasks not interesting for robotics; or digital twins, which require
careful real-to-sim alignment and are hard to scale. To address these
challenges, we introduce Video2Policy, a novel framework that leverages
internet RGB videos to reconstruct tasks based on everyday human behavior. Our
approach comprises two phases: (1) task generation in simulation from videos;
and (2) reinforcement learning utilizing in-context LLM-generated reward
functions iteratively. We demonstrate the efficacy of Video2Policy by
reconstructing over 100 videos from the Something-Something-v2 (SSv2) dataset,
which depicts diverse and complex human behaviors on 9 different tasks. Our
method can successfully train RL policies on such tasks, including complex and
challenging tasks such as throwing. Finally, we show that the generated
simulation data can be scaled up for training a general policy, and it can be
transferred back to the real robot in a Real2Sim2Real way.

摘要：模擬提供了一種有前途的方法，可以用於擴展訓練資料，以制定通才政策。為了從多樣化且逼真的任務中可擴充地產生資料，現有演算法仰賴大型語言模型 (LLM)，這些模型可能會產生對機器人技術不感興趣的任務；或者仰賴數位雙胞胎，這需要仔細地將真實環境與模擬環境對齊，而且很難擴充。為了應對這些挑戰，我們引入了 Video2Policy，這是一個新穎的架構，它利用網路上的 RGB 影片，根據日常人類行為來重建任務。我們的做法包含兩個階段：(1) 從影片中在模擬環境中產生任務；以及 (2) 利用在情境中由 LLM 產生的獎勵函數，反覆進行強化學習。我們透過重建 Something-Something-v2 (SSv2) 資料集中的 100 多個影片來展示 Video2Policy 的效能，這些影片描繪了 9 項不同任務中多樣化且複雜的人類行為。我們的做法可以在這些任務上成功訓練 RL 政策，包括複雜且具挑戰性的任務，例如投擲。最後，我們展示了產生的模擬資料可以擴充到訓練一般政策，而且可以透過 Real2Sim2Real 的方式轉移回真實機器人。

##### **Comprehensive Review of Neural Differential Equations for Time Series Analysis**
2502.09885v1 by YongKyung Oh, Seungsu Kam, Jonghun Lee, Dong-Young Lim, Sungil Kim, Alex Bui

Time series modeling and analysis has become critical in various domains.
Conventional methods such as RNNs and Transformers, while effective for
discrete-time and regularly sampled data, face significant challenges in
capturing the continuous dynamics and irregular sampling patterns inherent in
real-world scenarios. Neural Differential Equations (NDEs) represent a paradigm
shift by combining the flexibility of neural networks with the mathematical
rigor of differential equations. This paper presents a comprehensive review of
NDE-based methods for time series analysis, including neural ordinary
differential equations, neural controlled differential equations, and neural
stochastic differential equations. We provide a detailed discussion of their
mathematical formulations, numerical methods, and applications, highlighting
their ability to model continuous-time dynamics. Furthermore, we address key
challenges and future research directions. This survey serves as a foundation
for researchers and practitioners seeking to leverage NDEs for advanced time
series analysis.

摘要：時間序列建模和分析已在各個領域中變得至關重要。
RNN 和 Transformer 等傳統方法雖然對離散時間和定期採樣資料有效，但在捕捉現實世界場景中固有的連續動態和不規則採樣模式方面面臨重大挑戰。神經微分方程式 (NDE) 代表了一種典範轉變，它結合了神經網路的靈活性與微分方程式的數學嚴謹性。本文全面回顧了基於 NDE 的時間序列分析方法，包括神經常微分方程式、神經控制微分方程式和神經隨機微分方程式。我們詳細討論了它們的數學公式、數值方法和應用，強調它們對連續時間動態建模的能力。此外，我們還解決了關鍵挑戰和未來的研究方向。這項調查為尋求利用 NDE 進行高級時間序列分析的研究人員和從業者奠定了基礎。

##### **FrGNet: A fourier-guided weakly-supervised framework for nuclear instance segmentation**
2502.09874v1 by Peng Ling

Nuclear instance segmentation has played a critical role in pathology image
analysis. The main challenges arise from the difficulty in accurately
segmenting instances and the high cost of precise mask-level annotations for
fully-supervised training.In this work, we propose a fourier guidance framework
for solving the weakly-supervised nuclear instance segmentation problem. In
this framework, we construct a fourier guidance module to fuse the priori
information into the training process of the model, which facilitates the model
to capture the relevant features of the nuclear.Meanwhile, in order to further
improve the model's ability to represent the features of nuclear, we propose
the guide-based instance level contrastive module. This module makes full use
of the framework's own properties and guide information to effectively enhance
the representation features of nuclear. We show on two public datasets that our
model can outperform current SOTA methods under fully-supervised design, and in
weakly-supervised experiments, with only a small amount of labeling our model
still maintains close to the performance under full supervision.In addition, we
also perform generalization experiments on a private dataset, and without any
labeling, our model is able to segment nuclear images that have not been seen
during training quite effectively. As open science, all codes and pre-trained
models are available at https://github.com/LQY404/FrGNet.

摘要：核实例分割在病理图像分析中发挥了至关重要的作用。主要挑战在于准确分割实例的难度以及用于完全监督训练的精确掩模级注释的高成本。在这项工作中，我们提出了一种傅里叶指导框架来解决弱监督核实例分割问题。在这个框架中，我们构建了一个傅里叶指导模块，将先验信息融合到模型的训练过程中，这有助于模型捕捉核的相关特征。同时，为了进一步提高模型表示核特征的能力，我们提出了基于指导的实例级对比模块。该模块充分利用了框架自身的属性和指导信息，有效地增强了核的表示特征。我们在两个公共数据集上展示了我们的模型在完全监督设计下可以优于当前的 SOTA 方法，并且在弱监督实验中，即使只有少量标记，我们的模型仍保持接近完全监督下的性能。此外，我们还在私有数据集上进行了泛化实验，并且在没有任何标记的情况下，我们的模型能够非常有效地分割在训练期间没有见过的核图像。作为开放科学，所有代码和预训练模型均可在 https://github.com/LQY404/FrGNet 获得。

##### **A Taxonomy of Linguistic Expressions That Contribute To Anthropomorphism of Language Technologies**
2502.09870v1 by Alicia DeVrio, Myra Cheng, Lisa Egede, Alexandra Olteanu, Su Lin Blodgett

Recent attention to anthropomorphism -- the attribution of human-like
qualities to non-human objects or entities -- of language technologies like
LLMs has sparked renewed discussions about potential negative impacts of
anthropomorphism. To productively discuss the impacts of this anthropomorphism
and in what contexts it is appropriate, we need a shared vocabulary for the
vast variety of ways that language can be anthropomorphic. In this work, we
draw on existing literature and analyze empirical cases of user interactions
with language technologies to develop a taxonomy of textual expressions that
can contribute to anthropomorphism. We highlight challenges and tensions
involved in understanding linguistic anthropomorphism, such as how all language
is fundamentally human and how efforts to characterize and shift perceptions of
humanness in machines can also dehumanize certain humans. We discuss ways that
our taxonomy supports more precise and effective discussions of and decisions
about anthropomorphism of language technologies.

摘要：最近對擬人化的關注——將類人的品質歸因於非人類的物體或實體——例如 LLM 等語言技術，已引發了關於擬人化潛在負面影響的重新討論。為了富有成效地討論這種擬人化的影響以及在哪些情況下它是適當的，我們需要一個共享的詞彙，用於語言可以擬人化的各種方式。在這項工作中，我們借鑒現有文獻並分析使用者與語言技術互動的經驗案例，以開發一個文本表達分類法，有助於擬人化。我們強調了理解語言擬人化所涉及的挑戰和緊張關係，例如所有語言從根本上來說都是人類的，以及如何表徵和改變機器中人類感知的努力也可能使某些人類非人化。我們討論了我們的分類法如何支持對語言技術的擬人化進行更準確和有效的討論和決策。

##### **Solvable Dynamics of Self-Supervised Word Embeddings and the Emergence of Analogical Reasoning**
2502.09863v1 by Dhruva Karkada, James B. Simon, Yasaman Bahri, Michael R. DeWeese

The remarkable success of large language models relies on their ability to
implicitly learn structured latent representations from the pretraining corpus.
As a simpler surrogate for representation learning in language modeling, we
study a class of solvable contrastive self-supervised algorithms which we term
quadratic word embedding models. These models resemble the word2vec algorithm
and perform similarly on downstream tasks. Our main contributions are
analytical solutions for both the training dynamics (under certain
hyperparameter choices) and the final word embeddings, given in terms of only
the corpus statistics. Our solutions reveal that these models learn orthogonal
linear subspaces one at a time, each one incrementing the effective rank of the
embeddings until model capacity is saturated. Training on WikiText, we find
that the top subspaces represent interpretable concepts. Finally, we use our
dynamical theory to predict how and when models acquire the ability to complete
analogies.

摘要：大型語言模型的顯著成功，在於它們從預訓練語料庫中隱含地學習結構化潛在表徵的能力。作為語言模型中表徵學習的較簡單替代方案，我們研究了一類可解的對比自我監督演算法，我們稱之為二次詞嵌入模型。這些模型類似於 word2vec 演算法，且在下游任務上的表現類似。我們的貢獻在於，僅根據語料庫統計資料，就訓練動態（在特定超參數選擇下）和最終詞嵌入提供了分析解。我們的解法揭示了這些模型一次學習一個正交線性子空間，每個子空間都會增加嵌入的有效秩，直到模型容量飽和。在 WikiText 上進行訓練，我們發現頂級子空間代表可解釋的概念。最後，我們使用我們的動態理論來預測模型如何以及何時獲得完成類比的能力。

##### **Automated Hypothesis Validation with Agentic Sequential Falsifications**
2502.09858v1 by Kexin Huang, Ying Jin, Ryan Li, Michael Y. Li, Emmanuel Candès, Jure Leskovec

Hypotheses are central to information acquisition, decision-making, and
discovery. However, many real-world hypotheses are abstract, high-level
statements that are difficult to validate directly. This challenge is further
intensified by the rise of hypothesis generation from Large Language Models
(LLMs), which are prone to hallucination and produce hypotheses in volumes that
make manual validation impractical. Here we propose Popper, an agentic
framework for rigorous automated validation of free-form hypotheses. Guided by
Karl Popper's principle of falsification, Popper validates a hypothesis using
LLM agents that design and execute falsification experiments targeting its
measurable implications. A novel sequential testing framework ensures strict
Type-I error control while actively gathering evidence from diverse
observations, whether drawn from existing data or newly conducted procedures.
We demonstrate Popper on six domains including biology, economics, and
sociology. Popper delivers robust error control, high power, and scalability.
Furthermore, compared to human scientists, Popper achieved comparable
performance in validating complex biological hypotheses while reducing time by
10 folds, providing a scalable, rigorous solution for hypothesis validation.

摘要：假設是資訊獲取、決策制定和發現的中心。然而，許多真實世界的假設是抽象、高層次的陳述，難以直接驗證。這個挑戰進一步加劇了大型語言模型 (LLM) 產生的假設，這些模型容易產生幻覺，並產生大量假設，使得手動驗證不切實際。在此，我們提出 Popper，一個用於嚴格自動驗證自由形式假設的代理框架。在卡爾·波普爾的證偽原則指導下，Popper 使用 LLM 代理驗證假設，這些代理設計並執行針對其可測量含義的證偽實驗。一個新穎的順序測試框架確保嚴格的 I 型錯誤控制，同時積極從不同的觀察中收集證據，無論是從現有數據中提取還是新進行的程序中提取。我們在包括生物學、經濟學和社會學在內的六個領域展示了 Popper。Popper 提供了穩健的錯誤控制、高功率和可擴展性。此外，與人類科學家相比，Popper 在驗證複雜的生物假設方面取得了相當的表現，同時將時間縮短了 10 倍，為假設驗證提供了一個可擴展、嚴格的解決方案。

##### **Efficient Multitask Learning in Small Language Models Through Upside-Down Reinforcement Learning**
2502.09854v1 by Yu-Chen Lin, Sanat Sharma, Hari Manikandan, Jayant Kumar, Tracy Holloway King, Jing Zheng

In this work, we demonstrate that small language models (SLMs), specifically
a 100M parameter GPT-2 model, can achieve competitive performance in multitask
prompt generation tasks while requiring only a fraction of the computational
resources needed by large language models (LLMs). Through a novel combination
of upside-down reinforcement learning and synthetic data distillation from a
powerful LLM, Llama-3, we train an SLM that achieves relevance scores within 5%
of state-of-the-art models, including Llama-3, Qwen2, and Mistral, despite
being up to 80 times smaller, making it highly suitable for
resource-constrained and real-time applications. This study highlights the
potential of SLMs as efficient multitask learners in multimodal settings,
providing a promising alternative to LLMs for scalable, low-latency
deployments.

摘要：在這項工作中，我們證明了小語言模型（SLM），特別是 100M 參數的 GPT-2 模型，可以在多任務提示生成任務中實現具有競爭力的效能，同時只需要大型語言模型（LLM）所需計算資源的一小部分。透過新穎的顛倒式強化學習和來自強大 LLM Llama-3 的合成資料萃取的組合，我們訓練了一個 SLM，其相關性分數在 5% 以內，包括 Llama-3、Qwen2 和 Mistral，儘管它小了 80 倍，使其非常適合資源受限和即時應用程式。這項研究突出了 SLM 作為多模態設定中高效的多任務學習者的潛力，為可擴充、低延遲部署提供了有希望的 LLM 替代方案。

##### **HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation via Heterogeneous Knowledge Adaptation**
2502.09838v1 by Tianwei Lin, Wenqiao Zhang, Sijing Li, Yuqian Yuan, Binhe Yu, Haoyuan Li, Wanggui He, Hao Jiang, Mengze Li, Xiaohui Song, Siliang Tang, Jun Xiao, Hui Lin, Yueting Zhuang, Beng Chin Ooi

We present HealthGPT, a powerful Medical Large Vision-Language Model
(Med-LVLM) that integrates medical visual comprehension and generation
capabilities within a unified autoregressive paradigm. Our bootstrapping
philosophy is to progressively adapt heterogeneous comprehension and generation
knowledge to pre-trained large language models (LLMs). This is achieved through
a novel heterogeneous low-rank adaptation (H-LoRA) technique, which is
complemented by a tailored hierarchical visual perception approach and a
three-stage learning strategy. To effectively learn the HealthGPT, we devise a
comprehensive medical domain-specific comprehension and generation dataset
called VL-Health. Experimental results demonstrate exceptional performance and
scalability of HealthGPT in medical visual unified tasks. Our project can be
accessed at https://github.com/DCDmllm/HealthGPT.

摘要：我們提出 HealthGPT，一個強大的醫學大視覺語言模型 (Med-LVLM)，它在統一的自迴歸範例中整合了醫學視覺理解和生成能力。我們的引導哲學是逐步將異質理解和生成知識適應到預訓練的大語言模型 (LLM)。這是通過一種新穎的異質低秩適應 (H-LoRA) 技術實現的，該技術由量身定制的分層視覺感知方法和三階段學習策略補充。為了有效學習 HealthGPT，我們設計了一個全面的醫學領域特定理解和生成數據集，稱為 VL-Health。實驗結果證明了 HealthGPT 在醫學視覺統一任務中的卓越性能和可擴展性。我們的項目可在 https://github.com/DCDmllm/HealthGPT 中訪問。

##### **Efficient Evaluation of Multi-Task Robot Policies With Active Experiment Selection**
2502.09829v1 by Abrar Anwar, Rohan Gupta, Zain Merchant, Sayan Ghosh, Willie Neiswanger, Jesse Thomason

Evaluating learned robot control policies to determine their physical
task-level capabilities costs experimenter time and effort. The growing number
of policies and tasks exacerbates this issue. It is impractical to test every
policy on every task multiple times; each trial requires a manual environment
reset, and each task change involves re-arranging objects or even changing
robots. Naively selecting a random subset of tasks and policies to evaluate is
a high-cost solution with unreliable, incomplete results. In this work, we
formulate robot evaluation as an active testing problem. We propose to model
the distribution of robot performance across all tasks and policies as we
sequentially execute experiments. Tasks often share similarities that can
reveal potential relationships in policy behavior, and we show that natural
language is a useful prior in modeling these relationships between tasks. We
then leverage this formulation to reduce the experimenter effort by using a
cost-aware expected information gain heuristic to efficiently select
informative trials. Our framework accommodates both continuous and discrete
performance outcomes. We conduct experiments on existing evaluation data from
real robots and simulations. By prioritizing informative trials, our framework
reduces the cost of calculating evaluation metrics for robot policies across
many tasks.

摘要：評估已學習的機器人控制策略以確定其物理任務層級的能力需要實驗人員的時間和精力。策略和任務數量的增加加劇了這個問題。在每個任務上多次測試每個策略是不切實際的；每次試驗都需要手動環境重置，每次任務變更都涉及重新排列物件甚至更換機器人。天真地選擇隨機子集的任務和策略來評估是一種成本高昂的解決方案，其結果不可靠且不完整。在這項工作中，我們將機器人評估制定為一個主動測試問題。我們提議對機器人效能的分布進行建模，因為我們在所有任務和策略中依序執行實驗。任務通常具有相似性，可以揭示策略行為中的潛在關係，我們表明自然語言是建模任務之間這些關係的有用先驗。然後，我們利用這個公式，透過使用成本感知預期資訊增益啟發法來有效選擇有資訊的試驗，以減少實驗人員的努力。我們的架構涵蓋連續和離散的效能結果。我們對來自真實機器人和模擬的現有評估資料進行實驗。透過優先考慮有資訊的試驗，我們的架構降低了計算許多任務中機器人策略的評估指標的成本。

##### **A Solver-Aided Hierarchical Language for LLM-Driven CAD Design**
2502.09819v1 by Benjamin T. Jones, Felix Hähnlein, Zihan Zhang, Maaz Ahmad, Vladimir Kim, Adriana Schulz

Large language models (LLMs) have been enormously successful in solving a
wide variety of structured and unstructured generative tasks, but they struggle
to generate procedural geometry in Computer Aided Design (CAD). These
difficulties arise from an inability to do spatial reasoning and the necessity
to guide a model through complex, long range planning to generate complex
geometry. We enable generative CAD Design with LLMs through the introduction of
a solver-aided, hierarchical domain specific language (DSL) called AIDL, which
offloads the spatial reasoning requirements to a geometric constraint solver.
Additionally, we show that in the few-shot regime, AIDL outperforms even a
language with in-training data (OpenSCAD), both in terms of generating visual
results closer to the prompt and creating objects that are easier to
post-process and reason about.

摘要：大型語言模型 (LLM) 在解決各種結構化和非結構化生成任務方面取得了巨大成功，但它們在電腦輔助設計 (CAD) 中生成程序幾何圖形時卻舉步維艱。這些困難源於無法進行空間推理，以及必須引導模型進行複雜的長期規劃才能生成複雜的幾何圖形。我們透過導入稱為 AIDL 的求解器輔助分層領域特定語言 (DSL) 來啟用 LLM 的生成式 CAD 設計，它將空間推理需求卸載到幾何約束求解器。此外，我們表明在少量樣本的訓練模式中，AIDL 的表現優於在訓練資料（OpenSCAD）中包含語言的模型，無論是在生成更接近提示的視覺結果，還是創建更容易進行後處理和推理的物件方面。

##### **Statistical Coherence Alignment for Large Language Model Representation Learning Through Tensor Field Convergence**
2502.09815v1 by Jonathan Gale, Godfrey Aldington, Harriet Thistlewood, Thomas Tattershall, Basil Wentworth, Vincent Enoasmo

Representation learning plays a central role in structuring internal
embeddings to capture the statistical properties of language, influencing the
coherence and contextual consistency of generated text. Statistical Coherence
Alignment is introduced as a method to enforce structured token representations
through tensor field convergence, guiding embeddings to reflect statistical
dependencies inherent in linguistic data. A mathematical framework is
established to quantify coherence alignment, integrating a loss function that
optimizes representational consistency across training iterations. Empirical
evaluations demonstrate that applying coherence constraints improves
perplexity, enhances classification accuracy, and refines rare word embeddings,
contributing to a more stable representation space. Comparative analyses with
baseline models reveal that the proposed method fosters a more interpretable
internal structure, ensuring that embeddings retain contextual dependencies
while mitigating representation collapse. The impact on coherence score
distributions suggests that the alignment mechanism strengthens semantic
integrity across diverse linguistic constructs, leading to a more balanced
organization of learned embeddings. Computational assessments indicate that
while the method introduces additional memory and training costs, the
structured optimization process justifies the trade-offs in applications
requiring heightened contextual fidelity. Experimental results validate the
effectiveness of coherence alignment in optimizing token representations,
providing insights into how statistical dependencies can be leveraged to
improve language model training.

摘要：表示學習在建構內部嵌入以擷取語言的統計特性中扮演著核心角色，影響所產生文本的連貫性和脈絡一致性。統計連貫性對齊被引入為一種方法，透過張量場收斂來強制結構化標記表示，引導嵌入反映語言資料中固有的統計依賴性。建立了一個數學框架來量化連貫性對齊，整合一個損失函數，在訓練反覆運算中最佳化表示一致性。經驗評估顯示，應用連貫性約束改善了困惑度、增強了分類準確度，並改進了罕見詞嵌入，有助於建立更穩定的表示空間。與基線模型的比較分析顯示，所提出的方法促進了更具可解釋性的內部結構，確保嵌入保留脈絡依賴性，同時減輕表示崩潰。對連貫性分數分佈的影響表明，對齊機制增強了各種語言結構的語義完整性，導致學習嵌入的組織更為平衡。計算評估表明，雖然該方法引入了額外的記憶體和訓練成本，但結構化最佳化過程證明了在需要提高脈絡保真度的應用中進行權衡是合理的。實驗結果驗證了連貫性對齊在最佳化標記表示中的有效性，提供了關於如何利用統計依賴性來改善語言模型訓練的見解。

##### **INJONGO: A Multicultural Intent Detection and Slot-filling Dataset for 16 African Languages**
2502.09814v1 by Hao Yu, Jesujoba O. Alabi, Andiswa Bukula, Jian Yun Zhuang, En-Shiun Annie Lee, Tadesse Kebede Guge, Israel Abebe Azime, Happy Buzaaba, Blessing Kudzaishe Sibanda, Godson K. Kalipe, Jonathan Mukiibi, Salomon Kabongo Kabenamualu, Mmasibidi Setaka, Lolwethu Ndolela, Nkiruka Odu, Rooweither Mabuya, Shamsuddeen Hassan Muhammad, Salomey Osei, Sokhar Samb, Juliet W. Murage, Dietrich Klakow, David Ifeoluwa Adelani

Slot-filling and intent detection are well-established tasks in
Conversational AI. However, current large-scale benchmarks for these tasks
often exclude evaluations of low-resource languages and rely on translations
from English benchmarks, thereby predominantly reflecting Western-centric
concepts. In this paper, we introduce Injongo -- a multicultural, open-source
benchmark dataset for 16 African languages with utterances generated by native
speakers across diverse domains, including banking, travel, home, and dining.
Through extensive experiments, we benchmark the fine-tuning multilingual
transformer models and the prompting large language models (LLMs), and show the
advantage of leveraging African-cultural utterances over Western-centric
utterances for improving cross-lingual transfer from the English language.
Experimental results reveal that current LLMs struggle with the slot-filling
task, with GPT-4o achieving an average performance of 26 F1-score. In contrast,
intent detection performance is notably better, with an average accuracy of
70.6%, though it still falls behind the fine-tuning baselines. Compared to the
English language, GPT-4o and fine-tuning baselines perform similarly on intent
detection, achieving an accuracy of approximately 81%. Our findings suggest
that the performance of LLMs is still behind for many low-resource African
languages, and more work is needed to further improve their downstream
performance.

摘要：插槽填補和意圖偵測是對話式 AI 中的既定任務。然而，這些任務的現行大型基準測試通常會排除低資源語言的評估，並依賴於從英文基準測試的翻譯，因此主要反映以西方為中心的觀念。在本文中，我們介紹 Injongo - 一個多文化、開放原始碼基準測試資料集，包含 16 種非洲語言，由母語人士在不同領域（包括銀行、旅遊、家庭和用餐）中產生的語句。透過廣泛的實驗，我們對微調多語言變形金剛模型和提示大型語言模型 (LLM) 進行基準測試，並展示了利用非洲文化語句優於以西方為中心的語句來改善從英文進行跨語言轉移的優勢。實驗結果顯示，目前的 LLM 難以應付插槽填補任務，GPT-4o 的平均表現為 26 F1 分數。相比之下，意圖偵測表現顯著較佳，平均準確度為 70.6%，儘管仍落後於微調基準。與英文相比，GPT-4o 和微調基準在意圖偵測方面表現類似，準確度約為 81%。我們的發現表明，LLM 的表現對於許多低資源的非洲語言來說仍然落後，需要更多的工作來進一步改善它們的下游表現。

##### **AgentGuard: Repurposing Agentic Orchestrator for Safety Evaluation of Tool Orchestration**
2502.09809v1 by Jizhou Chen, Samuel Lee Cong

The integration of tool use into large language models (LLMs) enables agentic
systems with real-world impact. In the meantime, unlike standalone LLMs,
compromised agents can execute malicious workflows with more consequential
impact, signified by their tool-use capability. We propose AgentGuard, a
framework to autonomously discover and validate unsafe tool-use workflows,
followed by generating safety constraints to confine the behaviors of agents,
achieving the baseline of safety guarantee at deployment. AgentGuard leverages
the LLM orchestrator's innate capabilities - knowledge of tool functionalities,
scalable and realistic workflow generation, and tool execution privileges - to
act as its own safety evaluator. The framework operates through four phases:
identifying unsafe workflows, validating them in real-world execution,
generating safety constraints, and validating constraint efficacy. The output,
an evaluation report with unsafe workflows, test cases, and validated
constraints, enables multiple security applications. We empirically demonstrate
AgentGuard's feasibility with experiments. With this exploratory work, we hope
to inspire the establishment of standardized testing and hardening procedures
for LLM agents to enhance their trustworthiness in real-world applications.

摘要：將工具使用整合到大型語言模型 (LLM) 中，可啟用具有實際影響力的代理系統。與此同時，與獨立的 LLM 不同，受損代理可以執行惡意工作流程，並產生更嚴重的後果，這表示其具有工具使用能力。我們提出 AgentGuard，一個框架用於自動發現和驗證不安全的工具使用工作流程，然後產生安全約束來限制代理的行為，在部署時達成安全保證的基準。AgentGuard 利用 LLM 編排器的內在能力 - 工具功能的知識、可擴充且實際的工作流程產生，以及工具執行權限 - 作為其自己的安全評估器。該框架透過四個階段運作：識別不安全的工作流程、在實際執行中驗證它們、產生安全約束，以及驗證約束效力。輸出，包含不安全工作流程、測試案例和驗證約束的評估報告，可啟用多重安全應用。我們透過實驗經驗性地展示 AgentGuard 的可行性。透過這項探索性工作，我們希望激勵建立標準化測試和強化程序，以提升 LLM 代理在實際應用中的可信度。

##### **Acute Lymphoblastic Leukemia Diagnosis Employing YOLOv11, YOLOv8, ResNet50, and Inception-ResNet-v2 Deep Learning Models**
2502.09804v1 by Alaa Awad, Salah A. Aly

Thousands of individuals succumb annually to leukemia alone. As artificial
intelligence-driven technologies continue to evolve and advance, the question
of their applicability and reliability remains unresolved. This study aims to
utilize image processing and deep learning methodologies to achieve
state-of-the-art results for the detection of Acute Lymphoblastic Leukemia
(ALL) using data that best represents real-world scenarios. ALL is one of
several types of blood cancer, and it is an aggressive form of leukemia. In
this investigation, we examine the most recent advancements in ALL detection,
as well as the latest iteration of the YOLO series and its performance. We
address the question of whether white blood cells are malignant or benign.
Additionally, the proposed models can identify different ALL stages, including
early stages. Furthermore, these models can detect hematogones despite their
frequent misclassification as ALL. By utilizing advanced deep learning models,
namely, YOLOv8, YOLOv11, ResNet50 and Inception-ResNet-v2, the study achieves
accuracy rates as high as 99.7%, demonstrating the effectiveness of these
algorithms across multiple datasets and various real-world situations.

摘要：每年有數千人僅死於白血病。隨著人工智慧驅動技術持續演進和進步，其適用性和可靠性問題仍未解決。本研究旨在利用影像處理和深度學習方法，使用最能代表真實世界場景的資料，達成急性淋巴性白血病 (ALL) 檢測的最新結果。ALL 是數種血癌類型之一，也是一種侵襲性白血病。在此研究中，我們探討了 ALL 檢測的最新進展，以及 YOLO 系列的最新版本及其效能。我們探討白血球是惡性還是良性的問題。此外，所提出的模型可以識別不同的 ALL 階段，包括早期階段。更進一步的是，這些模型可以檢測到血球母細胞，儘管它們經常被錯誤分類為 ALL。本研究利用進階深度學習模型，即 YOLOv8、YOLOv11、ResNet50 和 Inception-ResNet-v2，達到了高達 99.7% 的準確率，證明了這些演算法在多個資料集和各種真實世界情況下的有效性。

##### **Co-designing Large Language Model Tools for Project-Based Learning with K12 Educators**
2502.09799v1 by Prerna Ravi, John Masla, Gisella Kakoti, Grace Lin, Emma Anderson, Matt Taylor, Anastasia Ostrowski, Cynthia Breazeal, Eric Klopfer, Hal Abelson

The emergence of generative AI, particularly large language models (LLMs),
has opened the door for student-centered and active learning methods like
project-based learning (PBL). However, PBL poses practical implementation
challenges for educators around project design and management, assessment, and
balancing student guidance with student autonomy. The following research
documents a co-design process with interdisciplinary K-12 teachers to explore
and address the current PBL challenges they face. Through teacher-driven
interviews, collaborative workshops, and iterative design of wireframes, we
gathered evidence for ways LLMs can support teachers in implementing
high-quality PBL pedagogy by automating routine tasks and enhancing
personalized learning. Teachers in the study advocated for supporting their
professional growth and augmenting their current roles without replacing them.
They also identified affordances and challenges around classroom integration,
including resource requirements and constraints, ethical concerns, and
potential immediate and long-term impacts. Drawing on these, we propose design
guidelines for future deployment of LLM tools in PBL.

摘要：生成式 AI 的出現，尤其是大型語言模型 (LLM)，
為以學生為中心和主動學習的方法開啟了大門，例如
專題式學習 (PBL)。然而，PBL 對教育工作者提出了實際的實施
挑戰，包括專題設計和管理、評量，以及平衡學生指導與學生自主性。以下研究
記錄了一個與跨領域 K-12 教師共同設計的過程，以探索
並解決他們目前面臨的 PBL 挑戰。透過教師主導的
訪談、協作工作坊和線框圖的迭代設計，我們
收集了 LLM 可以透過自動化例行工作和增強
個人化學習來支援教師實施高品質 PBL 教學法的證據。研究中的教師主張支援他們的
專業成長並擴充他們目前的角色，而不是取代他們。
他們也指出了教室整合的優點和挑戰，
包括資源需求和限制、倫理考量，以及
潛在的立即和長期影響。根據這些，我們提出設計
未來在 PBL 中部署 LLM 工具的準則。

##### **A Survey on LLM-based News Recommender Systems**
2502.09797v1 by Rongyao Wang, Veronica Liesaputra, Zhiyi Huang

News recommender systems play a critical role in mitigating the information
overload problem. In recent years, due to the successful applications of large
language model technologies, researchers have utilized Discriminative Large
Language Models (DLLMs) or Generative Large Language Models (GLLMs) to improve
the performance of news recommender systems. Although several recent surveys
review significant challenges for deep learning-based news recommender systems,
such as fairness, privacy-preserving, and responsibility, there is a lack of a
systematic survey on Large Language Model (LLM)-based news recommender systems.
In order to review different core methodologies and explore potential issues
systematically, we categorize DLLM-based and GLLM-based news recommender
systems under the umbrella of LLM-based news recommender systems. In this
survey, we first overview the development of deep learning-based news
recommender systems. Then, we review LLM-based news recommender systems based
on three aspects: news-oriented modeling, user-oriented modeling, and
prediction-oriented modeling. Next, we examine the challenges from various
perspectives, including datasets, benchmarking tools, and methodologies.
Furthermore, we conduct extensive experiments to analyze how large language
model technologies affect the performance of different news recommender
systems. Finally, we comprehensively explore the future directions for
LLM-based news recommendations in the era of LLMs.

摘要：新聞推薦系統在減輕資訊超載問題中扮演著關鍵角色。近年來，由於大型語言模型技術的成功應用，研究人員利用判別式大型語言模型（DLLM）或生成式大型語言模型（GLLM）來改善新聞推薦系統的效能。儘管最近有幾項調查回顧了基於深度學習的新聞推薦系統所面臨的重大挑戰，例如公平性、隱私保護和責任，但缺乏針對基於大型語言模型（LLM）的新聞推薦系統進行系統性調查。為了系統性地回顧不同的核心方法並探討潛在問題，我們將基於 DLLM 和基於 GLLM 的新聞推薦系統歸類為基於 LLM 的新聞推薦系統。在這項調查中，我們首先概述基於深度學習的新聞推薦系統的發展。接著，我們基於三個面向回顧基於 LLM 的新聞推薦系統：以新聞為導向的建模、以使用者為導向的建模，以及以預測為導向的建模。接下來，我們從各種觀點檢視挑戰，包括資料集、基準測試工具和方法。此外，我們進行廣泛的實驗，分析大型語言模型技術如何影響不同新聞推薦系統的效能。最後，我們全面探討 LLM 時代基於 LLM 的新聞推薦的未來方向。

##### **TableTalk: Scaffolding Spreadsheet Development with a Language Agent**
2502.09787v1 by Jenny T. Liang, Aayush Kumar, Yasharth Bajpai, Sumit Gulwani, Vu Le, Chris Parnin, Arjun Radhakrishna, Ashish Tiwari, Emerson Murphy-Hill, Guastavo Soares

Despite its ubiquity in the workforce, spreadsheet programming remains
challenging as programmers need both spreadsheet-specific knowledge (e.g., APIs
to write formulas) and problem-solving skills to create complex spreadsheets.
Large language models (LLMs) can help automate aspects of this process, and
recent advances in planning and reasoning have enabled language agents, which
dynamically plan, use tools, and take iterative actions to complete complex
tasks. These agents observe, plan, and act, making them well-suited to scaffold
spreadsheet programming by following expert processes.
  We present TableTalk, a language agent that helps programmers build
spreadsheets conversationally. Its design reifies three design principles --
scaffolding, flexibility, and incrementality -- which we derived from two
studies of seven programmers and 62 Excel templates. TableTalk structures
spreadsheet development by generating step-by-step plans and suggesting three
next steps users can choose from. It also integrates tools that enable
incremental spreadsheet construction. A user study with 20 programmers shows
that TableTalk produces spreadsheets 2.3 times more likely to be preferred over
a baseline agent, while reducing cognitive load and time spent reasoning about
spreadsheet actions by 12.6%. TableTalk's approach has implications for
human-agent collaboration. This includes providing persistent direct
manipulation interfaces for stopping or undoing agent actions, while ensuring
that such interfaces for accepting actions can be deactivated.

摘要：儘管電子試算表程式在職場中無所不在，但電子試算表程式設計仍具有挑戰性，因為程式設計師需要電子試算表特定知識（例如，撰寫公式的 API）和解決問題的技能才能建立複雜的電子試算表。大型語言模型 (LLM) 可協助自動化此程序的各個面向，而規劃和推理的最新進展已讓語言代理得以動態規劃、使用工具和採取反覆動作來完成複雜的任務。這些代理會觀察、規劃和執行，因此非常適合透過遵循專家流程來建構電子試算表程式。
我們提出 TableTalk，這是一種語言代理，可協助程式設計師以對話方式建立電子試算表。其設計實踐了三項設計原則：建構鷹架、靈活性，以及漸進性，這些原則是我們從針對七位程式設計師和 62 個 Excel 範本進行的兩項研究中衍生而來的。TableTalk 透過產生逐步計畫並建議使用者從三個後續步驟中進行選擇，來建構電子試算表開發。它也整合了可讓電子試算表漸進式建構的工具。一項針對 20 位程式設計師進行的使用者研究顯示，TableTalk 產生的電子試算表比基本代理更可能獲得偏好，機率高出 2.3 倍，同時降低認知負擔，並將思考電子試算表動作所花費的時間減少 12.6%。TableTalk 的方法對於人機協作具有影響。這包括提供持續直接操作介面來停止或復原代理動作，同時確保接受動作的此類介面可以停用。

##### **Improving Acoustic Side-Channel Attacks on Keyboards Using Transformers and Large Language Models**
2502.09782v1 by Jin Hyun Park, Seyyed Ali Ayati, Yichen Cai

The increasing prevalence of microphones in everyday devices and the growing
reliance on online services have amplified the risk of acoustic side-channel
attacks (ASCAs) targeting keyboards. This study explores deep learning
techniques, specifically vision transformers (VTs) and large language models
(LLMs), to enhance the effectiveness and applicability of such attacks. We
present substantial improvements over prior research, with the CoAtNet model
achieving state-of-the-art performance. Our CoAtNet shows a 5.0% improvement
for keystrokes recorded via smartphone (Phone) and 5.9% for those recorded via
Zoom compared to previous benchmarks. We also evaluate transformer
architectures and language models, with the best VT model matching CoAtNet's
performance. A key advancement is the introduction of a noise mitigation method
for real-world scenarios. By using LLMs for contextual understanding, we detect
and correct erroneous keystrokes in noisy environments, enhancing ASCA
performance. Additionally, fine-tuned lightweight language models with Low-Rank
Adaptation (LoRA) deliver comparable performance to heavyweight models with 67X
more parameters. This integration of VTs and LLMs improves the practical
applicability of ASCA mitigation, marking the first use of these technologies
to address ASCAs and error correction in real-world scenarios.

摘要：隨著日常裝置中麥克風的普及率越來越高，以及對線上服務的依賴性日益增加，針對鍵盤的聲學側信道攻擊 (ASCA) 風險也隨之擴大。本研究探討深度學習技術，特別是視覺Transformer (VT) 和大型語言模型 (LLM)，以增強此類攻擊的有效性和適用性。我們提出對先前研究的重大改進，其中 CoAtNet 模型達到最先進的效能。與先前的基準相比，我們的 CoAtNet 對於透過智慧型手機 (Phone) 記錄的按鍵顯示有 5.0% 的改進，而透過 Zoom 記錄的按鍵則有 5.9% 的改進。我們也評估了Transformer架構和語言模型，其中最佳 VT 模型符合 CoAtNet 的效能。一項關鍵進展是引入了適用於真實世界場景的雜訊緩解方法。透過使用 LLM 進行脈絡理解，我們可以偵測並修正有雜訊環境中的錯誤按鍵，進而增強 ASCA 效能。此外，經過微調的輕量級語言模型搭配低階適應 (LoRA) 可提供與具備多 67 倍參數的重量級模型相當的效能。VT 和 LLM 的整合改進了 ASCA 緩解的實用適用性，標誌著首次使用這些技術來解決真實世界場景中的 ASCA 和錯誤修正。

##### **Incentivize without Bonus: Provably Efficient Model-based Online Multi-agent RL for Markov Games**
2502.09780v1 by Tong Yang, Bo Dai, Lin Xiao, Yuejie Chi

Multi-agent reinforcement learning (MARL) lies at the heart of a plethora of
applications involving the interaction of a group of agents in a shared unknown
environment. A prominent framework for studying MARL is Markov games, with the
goal of finding various notions of equilibria in a sample-efficient manner,
such as the Nash equilibrium (NE) and the coarse correlated equilibrium (CCE).
However, existing sample-efficient approaches either require tailored
uncertainty estimation under function approximation, or careful coordination of
the players. In this paper, we propose a novel model-based algorithm, called
VMG, that incentivizes exploration via biasing the empirical estimate of the
model parameters towards those with a higher collective best-response values of
all the players when fixing the other players' policies, thus encouraging the
policy to deviate from its current equilibrium for more exploration. VMG is
oblivious to different forms of function approximation, and permits
simultaneous and uncoupled policy updates of all players. Theoretically, we
also establish that VMG achieves a near-optimal regret for finding both the NEs
of two-player zero-sum Markov games and CCEs of multi-player general-sum Markov
games under linear function approximation in an online environment, which
nearly match their counterparts with sophisticated uncertainty quantification.

摘要：多智能體強化學習 (MARL) 是一系列應用程式的心臟，這些應用程式涉及一群智能體在一個共用未知環境中的互動。研究 MARL 的一個著名框架是馬可夫博弈，其目標是用樣本有效率的方式找出各種均衡概念，例如納許均衡 (NE) 和粗相關均衡 (CCE)。然而，現有的樣本有效率方法需要在函數逼近下進行量身打造的不確定性估計，或謹慎協調參與者。在本文中，我們提出了一種新的基於模型的演算法，稱為 VMG，它透過將模型參數的經驗估計值偏向於在固定其他參與者政策時所有參與者的集體最佳反應值，從而激勵探索，進而鼓勵政策偏離其當前均衡以進行更多探索。VMG 不會忽略函數逼近的不同形式，並允許所有參與者同時進行非耦合的政策更新。在理論上，我們也建立了 VMG 在線上環境中使用線性函數逼近來尋找雙人零和馬可夫博弈的 NE 和多人一般和馬可夫博弈的 CCE 時，會獲得接近最佳的後悔，這幾乎與其在不確定性量化方面更為複雜的對應物相匹配。

##### **Prompt and circumstance: A word-by-word LLM prompting approach to interlinear glossing for low-resource languages**
2502.09778v1 by Micha Elsner, David Liu

Partly automated creation of interlinear glossed text (IGT) has the potential
to assist in linguistic documentation. We argue that LLMs can make this process
more accessible to linguists because of their capacity to follow
natural-language instructions. We investigate the effectiveness of a
retrieval-based LLM prompting approach to glossing, applied to the seven
languages from the SIGMORPHON 2023 shared task. Our system beats the BERT-based
shared task baseline for every language in the morpheme-level score category,
and we show that a simple 3-best oracle has higher word-level scores than the
challenge winner (a tuned sequence model) in five languages. In a case study on
Tsez, we ask the LLM to automatically create and follow linguistic
instructions, reducing errors on a confusing grammatical feature. Our results
thus demonstrate the potential contributions which LLMs can make in interactive
systems for glossing, both in making suggestions to human annotators and
following directions.

摘要：部分自動化建立語間線性對譯文 (IGT) 有潛力協助語言文件編製。我們認為，由於 LLM 能夠遵循自然語言指令，因此可以讓語言學家更輕鬆地進行這個程序。我們研究了基於檢索的 LLM 提示方法對詞彙註釋的有效性，並將其應用於 SIGMORPHON 2023 共享任務中的七種語言。我們的系統在形態層級評分類別中擊敗了基於 BERT 的共享任務基準，我們發現一個簡單的 3 最佳神諭在五種語言中的詞彙層級評分高於挑戰獲獎者（一個調整過的序列模型）。在關於 Tsez 的案例研究中，我們要求 LLM 自動建立並遵循語言學指令，減少了一個令人困惑的語法特徵的錯誤。因此，我們的結果證明了 LLM 在詞彙註釋的互動系統中可以做出潛在的貢獻，包括向人工標註者提出建議和遵循指示。

##### **Non-Markovian Discrete Diffusion with Causal Language Models**
2502.09767v1 by Yangtian Zhang, Sizhuang He, Daniel Levine, Lawrence Zhao, David Zhang, Syed A Rizvi, Emanuele Zappala, Rex Ying, David van Dijk

Discrete diffusion models have emerged as a flexible and controllable
paradigm for structured sequence modeling, yet they still lag behind causal
language models in expressiveness. To bridge the gap between two paradigms, we
introduce CaDDi, a causal discrete diffusion model that unifies sequential and
temporal modeling within a non-Markovian diffusion framework. Unlike
conventional diffusion models that operate step by step with no access to prior
states, CaDDi integrates the temporal trajectory, enabling more expressive and
controllable generation. Our approach also treats causal language models as a
special case, allowing seamless adoption of pretrained large language models
(LLMs) for discrete diffusion without the need for architectural modifications.
Empirically, we demonstrate that CaDDi outperforms state-of-the-art discrete
diffusion models on both natural language and biological sequence tasks,
narrowing the gap between diffusion-based methods and large-scale
autoregressive transformers.

摘要：離散擴散模型已成為結構化序列建模中一種靈活且可控的範例，但它們在表現力方面仍落後於因果語言模型。為了彌合這兩種範例之間的差距，我們引入了 CaDDi，這是一個因果離散擴散模型，它在非馬可夫擴散框架內統一了序列和時間建模。與逐步驟運作且無法存取先前狀態的傳統擴散模型不同，CaDDi 整合了時間軌跡，從而實現更具表現力和可控性的生成。我們的做法還將因果語言模型視為一個特例，允許無縫採用預訓練的大語言模型 (LLM) 進行離散擴散，而無需進行架構修改。根據經驗，我們證明 CaDDi 在自然語言和生物序列任務上都優於最先進的離散擴散模型，縮小了基於擴散的方法與大規模自迴歸Transformer之間的差距。

##### **Differential Adjusted Parity for Learning Fair Representations**
2502.09765v1 by Bucher Sahyouni, Matthew Vowels, Liqun Chen, Simon Hadfield

The development of fair and unbiased machine learning models remains an
ongoing objective for researchers in the field of artificial intelligence. We
introduce the Differential Adjusted Parity (DAP) loss to produce unbiased
informative representations. It utilises a differentiable variant of the
adjusted parity metric to create a unified objective function. By combining
downstream task classification accuracy and its inconsistency across sensitive
feature domains, it provides a single tool to increase performance and mitigate
bias. A key element in this approach is the use of soft balanced accuracies. In
contrast to previous non-adversarial approaches, DAP does not suffer a
degeneracy where the metric is satisfied by performing equally poorly across
all sensitive domains. It outperforms several adversarial models on downstream
task accuracy and fairness in our analysis. Specifically, it improves the
demographic parity, equalized odds and sensitive feature accuracy by as much as
22.5\%, 44.1\% and 40.1\%, respectively, when compared to the best performing
adversarial approaches on these metrics. Overall, the DAP loss and its
associated metric can play a significant role in creating more fair machine
learning models.

摘要：公平且無偏見機器學習模型的開發仍然是人工智慧領域研究人員持續進行的目標。我們引進差異調整奇偶 (DAP) 損失，以產生無偏見的資訊性表示。它利用調整奇偶指標的可微分變體來建立統一的目標函數。透過結合下游任務分類準確度及其在敏感特徵域中的不一致性，它提供了一個單一的工具來提升效能並減輕偏見。此方法中的關鍵元素是使用軟平衡準確度。與先前的非對抗方法相比，DAP 沒有遇到退化問題，其中透過在所有敏感域中表現同樣差勁來滿足指標。在我們的分析中，它在下游任務準確度和公平性方面優於多個對抗模型。具體來說，與這些指標上表現最佳的對抗方法相比，它分別將人口統計奇偶、等化機率和敏感特徵準確度提升了多達 22.5%、44.1% 和 40.1%。總體而言，DAP 損失及其相關指標在建立更公平的機器學習模型中可以發揮重要作用。

