{"2410.06846": {"publish_time": "2024-10-09", "title": "Joint Fine-tuning and Conversion of Pretrained Speech and Language Models towards Linear Complexity", "paper_summary": "Architectures such as Linformer and Mamba have recently emerged as\ncompetitive linear time replacements for transformers. However, corresponding\nlarge pretrained models are often unavailable, especially in non-text domains.\nTo remedy this, we present a Cross-Architecture Layerwise Distillation (CALD)\napproach that jointly converts a transformer model to a linear time substitute\nand fine-tunes it to a target task. We also compare several means to guide the\nfine-tuning to optimally retain the desired inference capability from the\noriginal model. The methods differ in their use of the target model and the\ntrajectory of the parameters. In a series of empirical studies on language\nprocessing, language modeling, and speech processing, we show that CALD can\neffectively recover the result of the original model, and that the guiding\nstrategy contributes to the result. Some reasons for the variation are\nsuggested.", "paper_summary_zh": "\u6700\u8fd1\uff0cLinformer \u548c Mamba \u7b49\u67b6\u69cb\u5df2\u6210\u70ba transformer \u7684\u7af6\u722d\u7dda\u6027\u6642\u9593\u66ff\u63db\u3002\u7136\u800c\uff0c\u5c0d\u61c9\u7684\u5927\u578b\u9810\u8a13\u7df4\u6a21\u578b\u901a\u5e38\u4e0d\u53ef\u7528\uff0c\u7279\u5225\u662f\u5728\u975e\u6587\u5b57\u9818\u57df\u3002\u70ba\u4e86\u88dc\u6551\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u8de8\u67b6\u69cb\u9010\u5c64\u84b8\u993e (CALD) \u65b9\u6cd5\uff0c\u8a72\u65b9\u6cd5\u806f\u5408\u5c07 transformer \u6a21\u578b\u8f49\u63db\u70ba\u7dda\u6027\u6642\u9593\u66ff\u4ee3\u4e26\u5c0d\u5176\u9032\u884c\u5fae\u8abf\u4ee5\u9069\u61c9\u76ee\u6a19\u4efb\u52d9\u3002\u6211\u5011\u9084\u6bd4\u8f03\u4e86\u5e7e\u7a2e\u65b9\u6cd5\u4f86\u6307\u5c0e\u5fae\u8abf\uff0c\u4ee5\u6700\u4f73\u5730\u4fdd\u7559\u539f\u59cb\u6a21\u578b\u6240\u9700\u7684\u63a8\u8ad6\u80fd\u529b\u3002\u9019\u4e9b\u65b9\u6cd5\u5728\u4f7f\u7528\u76ee\u6a19\u6a21\u578b\u548c\u53c3\u6578\u8ecc\u8de1\u65b9\u9762\u6709\u6240\u4e0d\u540c\u3002\u5728\u8a9e\u8a00\u8655\u7406\u3001\u8a9e\u8a00\u5efa\u6a21\u548c\u8a9e\u97f3\u8655\u7406\u7684\u4e00\u7cfb\u5217\u5be6\u8b49\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u8868\u660e CALD \u53ef\u4ee5\u6709\u6548\u5730\u6062\u5fa9\u539f\u59cb\u6a21\u578b\u7684\u7d50\u679c\uff0c\u4e26\u4e14\u6307\u5c0e\u7b56\u7565\u6709\u52a9\u65bc\u5be6\u73fe\u9019\u4e00\u7d50\u679c\u3002\u63d0\u51fa\u4e86\u4e00\u4e9b\u8b8a\u5316\u7684\u539f\u56e0\u3002", "author": "Mutian He et.al.", "authors": "Mutian He, Philip N. Garner", "id": "2410.06846v1", "paper_url": "http://arxiv.org/abs/2410.06846v1", "repo": "null"}}