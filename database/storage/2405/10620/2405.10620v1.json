{"2405.10620": {"publish_time": "2024-05-17", "title": "MC-GPT: Empowering Vision-and-Language Navigation with Memory Map and Reasoning Chains", "paper_summary": "In the Vision-and-Language Navigation (VLN) task, the agent is required to\nnavigate to a destination following a natural language instruction. While\nlearning-based approaches have been a major solution to the task, they suffer\nfrom high training costs and lack of interpretability. Recently, Large Language\nModels (LLMs) have emerged as a promising tool for VLN due to their strong\ngeneralization capabilities. However, existing LLM-based methods face\nlimitations in memory construction and diversity of navigation strategies. To\naddress these challenges, we propose a suite of techniques. Firstly, we\nintroduce a method to maintain a topological map that stores navigation\nhistory, retaining information about viewpoints, objects, and their spatial\nrelationships. This map also serves as a global action space. Additionally, we\npresent a Navigation Chain of Thoughts module, leveraging human navigation\nexamples to enrich navigation strategy diversity. Finally, we establish a\npipeline that integrates navigational memory and strategies with perception and\naction prediction modules. Experimental results on the REVERIE and R2R datasets\nshow that our method effectively enhances the navigation ability of the LLM and\nimproves the interpretability of navigation reasoning.", "paper_summary_zh": "\u5728\u8996\u89ba\u8207\u8a9e\u8a00\u5c0e\u822a (VLN) \u4efb\u52d9\u4e2d\uff0c\u4ee3\u7406\u5fc5\u9808\u9075\u5faa\u81ea\u7136\u8a9e\u8a00\u6307\u4ee4\u5c0e\u822a\u81f3\u76ee\u7684\u5730\u3002\u96d6\u7136\u57fa\u65bc\u5b78\u7fd2\u7684\u65b9\u6cd5\u4e00\u76f4\u662f\u6b64\u4efb\u52d9\u7684\u4e3b\u8981\u89e3\u6c7a\u65b9\u6848\uff0c\u4f46\u5b83\u5011\u5b58\u5728\u8a13\u7df4\u6210\u672c\u9ad8\u548c\u7f3a\u4e4f\u53ef\u89e3\u91cb\u6027\u7684\u554f\u984c\u3002\u6700\u8fd1\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7531\u65bc\u5176\u5f37\u5927\u7684\u6cdb\u5316\u80fd\u529b\u800c\u6210\u70ba VLN \u7684\u4e00\u500b\u6709\u524d\u9014\u7684\u5de5\u5177\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684\u57fa\u65bc LLM \u7684\u65b9\u6cd5\u5728\u8a18\u61b6\u9ad4\u5efa\u69cb\u548c\u5c0e\u822a\u7b56\u7565\u7684\u591a\u6a23\u6027\u65b9\u9762\u9762\u81e8\u9650\u5236\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u6280\u8853\u3002\u9996\u5148\uff0c\u6211\u5011\u4ecb\u7d39\u4e86\u4e00\u7a2e\u7dad\u8b77\u62d3\u64b2\u5730\u5716\u7684\u65b9\u6cd5\uff0c\u8a72\u5730\u5716\u5132\u5b58\u5c0e\u822a\u6b77\u53f2\uff0c\u4fdd\u7559\u6709\u95dc\u8996\u9ede\u3001\u7269\u4ef6\u53ca\u5176\u7a7a\u9593\u95dc\u4fc2\u7684\u8cc7\u8a0a\u3002\u6b64\u5730\u5716\u9084\u53ef\u7528\u4f5c\u5168\u5c40\u52d5\u4f5c\u7a7a\u9593\u3002\u6b64\u5916\uff0c\u6211\u5011\u5c55\u793a\u4e86\u4e00\u500b\u5c0e\u822a\u601d\u7dad\u93c8\u6a21\u7d44\uff0c\u5229\u7528\u4eba\u985e\u5c0e\u822a\u7bc4\u4f8b\u4f86\u8c50\u5bcc\u5c0e\u822a\u7b56\u7565\u7684\u591a\u6a23\u6027\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5efa\u7acb\u4e86\u4e00\u500b\u5c07\u5c0e\u822a\u8a18\u61b6\u9ad4\u548c\u7b56\u7565\u8207\u611f\u77e5\u548c\u52d5\u4f5c\u9810\u6e2c\u6a21\u7d44\u6574\u5408\u7684\u7ba1\u9053\u3002\u5728 REVERIE \u548c R2R \u8cc7\u6599\u96c6\u4e0a\u7684\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u6211\u5011\u7684\u6a21\u578b\u6709\u6548\u5730\u589e\u5f37\u4e86 LLM \u7684\u5c0e\u822a\u80fd\u529b\uff0c\u4e26\u63d0\u9ad8\u4e86\u5c0e\u822a\u63a8\u7406\u7684\u53ef\u89e3\u91cb\u6027\u3002", "author": "Zhaohuan Zhan et.al.", "authors": "Zhaohuan Zhan, Lisha Yu, Sijie Yu, Guang Tan", "id": "2405.10620v1", "paper_url": "http://arxiv.org/abs/2405.10620v1", "repo": "null"}}