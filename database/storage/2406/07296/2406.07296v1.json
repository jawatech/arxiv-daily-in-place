{"2406.07296": {"publish_time": "2024-06-11", "title": "Instruct Large Language Models to Drive like Humans", "paper_summary": "Motion planning in complex scenarios is the core challenge in autonomous\ndriving. Conventional methods apply predefined rules or learn from driving data\nto plan the future trajectory. Recent methods seek the knowledge preserved in\nlarge language models (LLMs) and apply them in the driving scenarios. Despite\nthe promising results, it is still unclear whether the LLM learns the\nunderlying human logic to drive. In this paper, we propose an InstructDriver\nmethod to transform LLM into a motion planner with explicit instruction tuning\nto align its behavior with humans. We derive driving instruction data based on\nhuman logic (e.g., do not cause collisions) and traffic rules (e.g., proceed\nonly when green lights). We then employ an interpretable InstructChain module\nto further reason the final planning reflecting the instructions. Our\nInstructDriver allows the injection of human rules and learning from driving\ndata, enabling both interpretability and data scalability. Different from\nexisting methods that experimented on closed-loop or simulated settings, we\nadopt the real-world closed-loop motion planning nuPlan benchmark for better\nevaluation. InstructDriver demonstrates the effectiveness of the LLM planner in\na real-world closed-loop setting. Our code is publicly available at\nhttps://github.com/bonbon-rj/InstructDriver.", "paper_summary_zh": "\u8907\u96dc\u60c5\u5883\u4e0b\u7684\u904b\u52d5\u898f\u5283\u662f\u81ea\u52d5\u99d5\u99db\u7684\u6838\u5fc3\u6311\u6230\u3002\u50b3\u7d71\u65b9\u6cd5\u61c9\u7528\u9810\u5148\u5b9a\u7fa9\u7684\u898f\u5247\u6216\u5f9e\u99d5\u99db\u6578\u64da\u4e2d\u5b78\u7fd2\u4f86\u898f\u5283\u672a\u4f86\u8ecc\u8de1\u3002\u6700\u8fd1\u7684\u65b9\u6cd5\u5c0b\u6c42\u4fdd\u7559\u5728\u5927\u8a9e\u8a00\u6a21\u578b (LLM) \u4e2d\u7684\u77e5\u8b58\u4e26\u5c07\u5176\u61c9\u7528\u65bc\u99d5\u99db\u60c5\u5883\u3002\u5118\u7ba1\u6709\u4ee4\u4eba\u6eff\u610f\u7684\u7d50\u679c\uff0c\u4f46 LLM \u662f\u5426\u5b78\u7fd2\u4e86\u4eba\u985e\u7684\u57fa\u672c\u99d5\u99db\u908f\u8f2f\u4ecd\u4e0d\u6e05\u695a\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b InstructDriver \u65b9\u6cd5\uff0c\u5c07 LLM \u8f49\u63db\u70ba\u904b\u52d5\u898f\u5283\u5668\uff0c\u4e26\u9032\u884c\u660e\u78ba\u7684\u6307\u4ee4\u8abf\u6574\uff0c\u4f7f\u5176\u884c\u70ba\u8207\u4eba\u985e\u4fdd\u6301\u4e00\u81f4\u3002\u6211\u5011\u6839\u64da\u4eba\u985e\u908f\u8f2f\uff08\u4f8b\u5982\uff0c\u4e0d\u8981\u9020\u6210\u78b0\u649e\uff09\u548c\u4ea4\u901a\u898f\u5247\uff08\u4f8b\u5982\uff0c\u53ea\u6709\u5728\u7da0\u71c8\u6642\u624d\u9032\u884c\uff09\u63a8\u5c0e\u99d5\u99db\u6307\u4ee4\u6578\u64da\u3002\u7136\u5f8c\uff0c\u6211\u5011\u63a1\u7528\u4e00\u500b\u53ef\u89e3\u91cb\u7684 InstructChain \u6a21\u7d44\uff0c\u9032\u4e00\u6b65\u63a8\u8ad6\u53cd\u6620\u6307\u4ee4\u7684\u6700\u7d42\u898f\u5283\u3002\u6211\u5011\u7684 InstructDriver \u5141\u8a31\u6ce8\u5165\u4eba\u985e\u898f\u5247\u548c\u5f9e\u99d5\u99db\u6578\u64da\u4e2d\u5b78\u7fd2\uff0c\u5f9e\u800c\u5be6\u73fe\u53ef\u89e3\u91cb\u6027\u548c\u6578\u64da\u53ef\u64f4\u5145\u6027\u3002\u4e0d\u540c\u65bc\u5728\u9589\u74b0\u6216\u6a21\u64ec\u8a2d\u7f6e\u4e2d\u9032\u884c\u5be6\u9a57\u7684\u73fe\u6709\u65b9\u6cd5\uff0c\u6211\u5011\u63a1\u7528\u4e86\u771f\u5be6\u4e16\u754c\u7684\u9589\u74b0\u904b\u52d5\u898f\u5283 nuPlan \u57fa\u6e96\u4ee5\u9032\u884c\u66f4\u597d\u7684\u8a55\u4f30\u3002InstructDriver \u5728\u771f\u5be6\u4e16\u754c\u7684\u9589\u74b0\u8a2d\u7f6e\u4e2d\u5c55\u793a\u4e86 LLM \u898f\u5283\u5668\u7684\u6709\u6548\u6027\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/bonbon-rj/InstructDriver \u516c\u958b\u53d6\u5f97\u3002", "author": "Ruijun Zhang et.al.", "authors": "Ruijun Zhang, Xianda Guo, Wenzhao Zheng, Chenming Zhang, Kurt Keutzer, Long Chen", "id": "2406.07296v1", "paper_url": "http://arxiv.org/abs/2406.07296v1", "repo": "https://github.com/bonbon-rj/instructdriver"}}