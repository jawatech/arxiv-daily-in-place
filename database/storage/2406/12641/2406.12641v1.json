{"2406.12641": {"publish_time": "2024-06-18", "title": "DetectBench: Can Large Language Model Detect and Piece Together Implicit Evidence?", "paper_summary": "Detecting evidence within the context is a key step in the process of\nreasoning task. Evaluating and enhancing the capabilities of LLMs in evidence\ndetection will strengthen context-based reasoning performance. This paper\nproposes a benchmark called DetectBench for verifying the ability to detect and\npiece together implicit evidence within a long context. DetectBench contains\n3,928 multiple-choice questions, with an average of 994 tokens per question.\nEach question contains an average of 4.55 pieces of implicit evidence, and\nsolving the problem typically requires 7.62 logical jumps to find the correct\nanswer. To enhance the performance of LLMs in evidence detection, this paper\nproposes Detective Reasoning Prompt and Finetune. Experiments demonstrate that\nthe existing LLMs' abilities to detect evidence in long contexts are far\ninferior to humans. However, the Detective Reasoning Prompt effectively\nenhances the capability of powerful LLMs in evidence detection, while the\nFinetuning method shows significant effects in enhancing the performance of\nweaker LLMs. Moreover, when the abilities of LLMs in evidence detection are\nimproved, their final reasoning performance is also enhanced accordingly.", "paper_summary_zh": "\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\uff0c\u5728\u8bed\u5883\u4e2d\u68c0\u6d4b\u8bc1\u636e\u662f\u5173\u952e\u7684\u4e00\u6b65\u3002\u8bc4\u4f30\u548c\u589e\u5f3a LLM \u5728\u8bc1\u636e\u68c0\u6d4b\u4e2d\u7684\u80fd\u529b\u5c06\u5f3a\u5316\u57fa\u4e8e\u8bed\u5883\u7684\u63a8\u7406\u6027\u80fd\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3a DetectBench \u7684\u57fa\u51c6\uff0c\u7528\u4e8e\u9a8c\u8bc1\u5728\u957f\u8bed\u5883\u4e2d\u68c0\u6d4b\u548c\u62fc\u51d1\u9690\u5f0f\u8bc1\u636e\u7684\u80fd\u529b\u3002DetectBench \u5305\u542b 3,928 \u4e2a\u591a\u9879\u9009\u62e9\u9898\uff0c\u6bcf\u4e2a\u95ee\u9898\u5e73\u5747\u6709 994 \u4e2a\u6807\u8bb0\u3002\u6bcf\u4e2a\u95ee\u9898\u5e73\u5747\u5305\u542b 4.55 \u4e2a\u9690\u5f0f\u8bc1\u636e\uff0c\u89e3\u51b3\u95ee\u9898\u901a\u5e38\u9700\u8981 7.62 \u4e2a\u903b\u8f91\u8df3\u8dc3\u624d\u80fd\u627e\u5230\u6b63\u786e\u7b54\u6848\u3002\u4e3a\u4e86\u589e\u5f3a LLM \u5728\u8bc1\u636e\u68c0\u6d4b\u4e2d\u7684\u6027\u80fd\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4fa6\u63a2\u63a8\u7406\u63d0\u793a\u548c\u5fae\u8c03\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u73b0\u6709 LLM \u5728\u957f\u8bed\u5883\u4e2d\u68c0\u6d4b\u8bc1\u636e\u7684\u80fd\u529b\u8fdc\u900a\u4e8e\u4eba\u7c7b\u3002\u7136\u800c\uff0c\u4fa6\u63a2\u63a8\u7406\u63d0\u793a\u6709\u6548\u5730\u589e\u5f3a\u4e86\u5f3a\u5927\u7684 LLM \u5728\u8bc1\u636e\u68c0\u6d4b\u4e2d\u7684\u80fd\u529b\uff0c\u800c\u5fae\u8c03\u65b9\u6cd5\u5728\u589e\u5f3a\u8f83\u5f31 LLM \u7684\u6027\u80fd\u65b9\u9762\u663e\u793a\u51fa\u663e\u7740\u6548\u679c\u3002\u6b64\u5916\uff0c\u5f53 LLM \u5728\u8bc1\u636e\u68c0\u6d4b\u4e2d\u7684\u80fd\u529b\u5f97\u5230\u63d0\u9ad8\u65f6\uff0c\u5176\u6700\u7ec8\u63a8\u7406\u6027\u80fd\u4e5f\u4f1a\u76f8\u5e94\u63d0\u9ad8\u3002", "author": "Zhouhong Gu et.al.", "authors": "Zhouhong Gu, Lin Zhang, Xiaoxuan Zhu, Jiangjie Chen, Wenhao Huang, Yikai Zhang, Shusen Wang, Zheyu Ye, Yan Gao, Hongwei Feng, Yanghua Xiao", "id": "2406.12641v1", "paper_url": "http://arxiv.org/abs/2406.12641v1", "repo": "null"}}