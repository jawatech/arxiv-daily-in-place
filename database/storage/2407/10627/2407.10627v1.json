{"2407.10627": {"publish_time": "2024-07-15", "title": "Arena Learning: Build Data Flywheel for LLMs Post-training via Simulated Chatbot Arena", "paper_summary": "Assessing the effectiveness of large language models (LLMs) presents\nsubstantial challenges. The method of conducting human-annotated battles in an\nonline Chatbot Arena is a highly effective evaluative technique. However, this\napproach is limited by the costs and time required for human annotation. In\nthis paper, we introduce Arena Learning, an innovative offline strategy\ndesigned to simulate these arena battles using AI-driven annotations to\nevaluate battle outcomes, thus facilitating the continuous improvement of the\ntarget model through both supervised fine-tuning and reinforcement learning.\nArena Learning comprises two key elements. First, it ensures precise\nevaluations and maintains consistency between offline simulations and online\ncompetitions via WizardArena, a pipeline developed to accurately predict the\nElo rankings of various models using a meticulously designed offline test set.\nOur results demonstrate that WizardArena's predictions closely align with those\nfrom the online Arena. Second, it involves the continuous improvement of\ntraining data based on the battle results and the refined model. We establish a\ndata flywheel to iteratively update the training data by highlighting the\nweaknesses of the target model based on its battle results, enabling it to\nlearn from the strengths of multiple different models. We apply Arena Learning\nto train our target model, WizardLM-$\\beta$, and demonstrate significant\nperformance enhancements across various metrics. This fully automated training\nand evaluation pipeline sets the stage for continuous advancements in various\nLLMs via post-training. Notably, Arena Learning plays a pivotal role in the\nsuccess of WizardLM-2, and this paper serves both as an exploration of its\nefficacy and a foundational study for future discussions related to WizardLM-2\nand its derivatives.", "paper_summary_zh": "\u8a55\u4f30\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6548\u80fd\u6703\u5e36\u4f86\u91cd\u5927\u7684\u6311\u6230\u3002\u5728\u7dda\u4e0a\u804a\u5929\u6a5f\u5668\u4eba\u7af6\u6280\u5834\u4e2d\u9032\u884c\u4eba\u5de5\u6a19\u8a3b\u5c0d\u6230\u7684\u65b9\u6cd5\u662f\u4e00\u7a2e\u9ad8\u5ea6\u6709\u6548\u7684\u8a55\u4f30\u6280\u8853\u3002\u7136\u800c\uff0c\u9019\u7a2e\u65b9\u6cd5\u53d7\u5230\u4eba\u5de5\u6a19\u8a3b\u6240\u9700\u7684\u6210\u672c\u548c\u6642\u9593\u6240\u9650\u5236\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u7af6\u6280\u5834\u5b78\u7fd2\uff0c\u9019\u662f\u4e00\u7a2e\u5275\u65b0\u7684\u96e2\u7dda\u7b56\u7565\uff0c\u65e8\u5728\u4f7f\u7528 AI \u9a45\u52d5\u7684\u6a19\u8a3b\u4f86\u6a21\u64ec\u9019\u4e9b\u7af6\u6280\u5834\u5c0d\u6230\uff0c\u4ee5\u8a55\u4f30\u5c0d\u6230\u7d50\u679c\uff0c\u5f9e\u800c\u4fc3\u9032\u76ee\u6a19\u6a21\u578b\u900f\u904e\u76e3\u7763\u5fae\u8abf\u548c\u5f37\u5316\u5b78\u7fd2\u6301\u7e8c\u6539\u9032\u3002\u7af6\u6280\u5834\u5b78\u7fd2\u5305\u542b\u5169\u500b\u95dc\u9375\u5143\u7d20\u3002\u9996\u5148\uff0c\u5b83\u900f\u904e WizardArena \u78ba\u4fdd\u7cbe\u78ba\u7684\u8a55\u4f30\u4e26\u7dad\u6301\u96e2\u7dda\u6a21\u64ec\u8207\u7dda\u4e0a\u7af6\u8cfd\u4e4b\u9593\u7684\u4e00\u81f4\u6027\uff0cWizardArena \u662f\u4e00\u500b\u7ba1\u9053\uff0c\u7528\u65bc\u4f7f\u7528\u7cbe\u5fc3\u8a2d\u8a08\u7684\u96e2\u7dda\u6e2c\u8a66\u96c6\u6e96\u78ba\u9810\u6e2c\u5404\u7a2e\u6a21\u578b\u7684 Elo \u6392\u540d\u3002\u6211\u5011\u7684\u7d50\u679c\u8b49\u660e\uff0cWizardArena \u7684\u9810\u6e2c\u8207\u7dda\u4e0a\u7af6\u6280\u5834\u7684\u9810\u6e2c\u975e\u5e38\u543b\u5408\u3002\u5176\u6b21\uff0c\u5b83\u6d89\u53ca\u6839\u64da\u5c0d\u6230\u7d50\u679c\u548c\u7cbe\u7149\u6a21\u578b\u6301\u7e8c\u6539\u9032\u8a13\u7df4\u8cc7\u6599\u3002\u6211\u5011\u5efa\u7acb\u4e00\u500b\u8cc7\u6599\u98db\u8f2a\uff0c\u900f\u904e\u6839\u64da\u76ee\u6a19\u6a21\u578b\u7684\u5c0d\u6230\u7d50\u679c\u7a81\u986f\u5176\u5f31\u9ede\uff0c\u53cd\u8986\u66f4\u65b0\u8a13\u7df4\u8cc7\u6599\uff0c\u4f7f\u5176\u80fd\u5920\u5f9e\u591a\u500b\u4e0d\u540c\u6a21\u578b\u7684\u512a\u9ede\u4e2d\u5b78\u7fd2\u3002\u6211\u5011\u5c07\u7af6\u6280\u5834\u5b78\u7fd2\u61c9\u7528\u65bc\u8a13\u7df4\u6211\u5011\u7684\u76ee\u6a19\u6a21\u578b WizardLM-$\\beta$\uff0c\u4e26\u5c55\u793a\u4e86\u5404\u7a2e\u6307\u6a19\u7684\u986f\u8457\u6548\u80fd\u63d0\u5347\u3002\u9019\u7a2e\u5168\u81ea\u52d5\u5316\u8a13\u7df4\u548c\u8a55\u4f30\u7ba1\u9053\u70ba\u900f\u904e\u8a13\u7df4\u5f8c\u6301\u7e8c\u63a8\u9032\u5404\u7a2e LLM \u5960\u5b9a\u4e86\u57fa\u790e\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u7af6\u6280\u5834\u5b78\u7fd2\u5728 WizardLM-2 \u7684\u6210\u529f\u4e2d\u626e\u6f14\u4e86\u95dc\u9375\u89d2\u8272\uff0c\u800c\u672c\u6587\u65e2\u63a2\u7d22\u4e86\u5176\u6548\u80fd\uff0c\u4e5f\u70ba\u672a\u4f86\u8207 WizardLM-2 \u53ca\u5176\u884d\u751f\u7522\u54c1\u76f8\u95dc\u7684\u8a0e\u8ad6\u5960\u5b9a\u4e86\u57fa\u790e\u7814\u7a76\u3002", "author": "Haipeng Luo et.al.", "authors": "Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Qingwei Lin, Jianguang Lou, Shifeng Chen, Yansong Tang, Weizhu Chen", "id": "2407.10627v1", "paper_url": "http://arxiv.org/abs/2407.10627v1", "repo": "null"}}