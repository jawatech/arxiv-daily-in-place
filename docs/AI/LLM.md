
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-05**|**Self-Taught Evaluators**|Tianlu Wang et.al.|[2408.02666v1](http://arxiv.org/abs/2408.02666v1)|null|
|**2024-08-05**|**Can Reinforcement Learning Unlock the Hidden Dangers in Aligned Large Language Models?**|Mohammad Bahrami Karkevandi et.al.|[2408.02651v1](http://arxiv.org/abs/2408.02651v1)|null|
|**2024-08-05**|**SEAS: Self-Evolving Adversarial Safety Optimization for Large Language Models**|Muxi Diao et.al.|[2408.02632v1](http://arxiv.org/abs/2408.02632v1)|null|
|**2024-08-05**|**Language Model Can Listen While Speaking**|Ziyang Ma et.al.|[2408.02622v1](http://arxiv.org/abs/2408.02622v1)|null|
|**2024-08-05**|**BioMamba: A Pre-trained Biomedical Language Representation Model Leveraging Mamba**|Ling Yue et.al.|[2408.02600v1](http://arxiv.org/abs/2408.02600v1)|null|
|**2024-08-05**|**Progressively Selective Label Enhancement for Language Model Alignment**|Biao Liu et.al.|[2408.02599v1](http://arxiv.org/abs/2408.02599v1)|null|
|**2024-08-05**|**Modelling Visual Semantics via Image Captioning to extract Enhanced Multi-Level Cross-Modal Semantic Incongruity Representation with Attention for Multimodal Sarcasm Detection**|Sajal Aggarwal et.al.|[2408.02595v1](http://arxiv.org/abs/2408.02595v1)|null|
|**2024-08-05**|**Leveraging the Power of LLMs: A Fine-Tuning Approach for High-Quality Aspect-Based Summarization**|Ankan Mullick et.al.|[2408.02584v1](http://arxiv.org/abs/2408.02584v1)|null|
|**2024-08-05**|**Clustering and Mining Accented Speech for Inclusive and Fair Speech Recognition**|Jaeyoung Kim et.al.|[2408.02582v1](http://arxiv.org/abs/2408.02582v1)|null|
|**2024-08-05**|**Contrastive Learning-based Multi Modal Architecture for Emoticon Prediction by Employing Image-Text Pairs**|Ananya Pandey et.al.|[2408.02571v1](http://arxiv.org/abs/2408.02571v1)|null|
|**2024-08-05**|**Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information**|Yauwai Yim et.al.|[2408.02559v1](http://arxiv.org/abs/2408.02559v1)|null|
|**2024-08-05**|**MeshAnything V2: Artist-Created Mesh Generation With Adjacent Mesh Tokenization**|Yiwen Chen et.al.|[2408.02555v1](http://arxiv.org/abs/2408.02555v1)|null|
|**2024-08-05**|**The Role of Functional Muscle Networks in Improving Hand Gesture Perception for Human-Machine Interfaces**|Costanza Armanini et.al.|[2408.02547v1](http://arxiv.org/abs/2408.02547v1)|null|
|**2024-08-05**|**RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation**|Daniel Fleischer et.al.|[2408.02545v1](http://arxiv.org/abs/2408.02545v1)|null|
|**2024-08-05**|**Caution for the Environment: Multimodal Agents are Susceptible to Environmental Distractions**|Xinbei Ma et.al.|[2408.02544v1](http://arxiv.org/abs/2408.02544v1)|null|
|**2024-08-05**|**OneLove beyond the field -- A few-shot pipeline for topic and sentiment analysis during the FIFA World Cup in Qatar**|Christoph Rauchegger et.al.|[2408.02520v1](http://arxiv.org/abs/2408.02520v1)|null|
|**2024-08-05**|**UnifiedMLLM: Enabling Unified Representation for Multi-modal Multi-tasks With Large Language Model**|Zhaowei Li et.al.|[2408.02503v1](http://arxiv.org/abs/2408.02503v1)|null|
|**2024-08-05**|**A First Look at License Compliance Capability of LLMs in Code Generation**|Weiwei Xu et.al.|[2408.02487v1](http://arxiv.org/abs/2408.02487v1)|null|
|**2024-08-05**|**From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future**|Haolin Jin et.al.|[2408.02479v1](http://arxiv.org/abs/2408.02479v1)|null|
|**2024-08-05**|**An investigation into the causes of race bias in AI-based cine CMR segmentation**|Tiarna Lee et.al.|[2408.02462v1](http://arxiv.org/abs/2408.02462v1)|null|
|**2024-08-05**|**Enhancing Heterogeneous Knowledge Graph Completion with a Novel GAT-based Approach**|Wanxu Wei et.al.|[2408.02456v1](http://arxiv.org/abs/2408.02456v1)|null|
|**2024-08-05**|**Let Me Speak Freely? A Study on the Impact of Format Restrictions on Performance of Large Language Models**|Zhi Rui Tam et.al.|[2408.02442v1](http://arxiv.org/abs/2408.02442v1)|null|
|**2024-08-05**|**Long Input Benchmark for Russian Analysis**|Igor Churin et.al.|[2408.02439v1](http://arxiv.org/abs/2408.02439v1)|null|
|**2024-08-05**|**Infusing Emotions into Task-oriented Dialogue Systems: Understanding, Management, and Generation**|Shutong Feng et.al.|[2408.02417v1](http://arxiv.org/abs/2408.02417v1)|null|
|**2024-08-05**|**Why Are My Prompts Leaked? Unraveling Prompt Extraction Threats in Customized Large Language Models**|Zi Liang et.al.|[2408.02416v1](http://arxiv.org/abs/2408.02416v1)|null|
|**2024-08-05**|**Multi-weather Cross-view Geo-localization Using Denoising Diffusion Models**|Tongtong Feng et.al.|[2408.02408v1](http://arxiv.org/abs/2408.02408v1)|null|
|**2024-08-05**|**Enhancing AI-based Generation of Software Exploits with Contextual Information**|Pietro Liguori et.al.|[2408.02402v1](http://arxiv.org/abs/2408.02402v1)|null|
|**2024-08-05**|**A Few-Shot Approach for Relation Extraction Domain Adaptation using Large Language Models**|Vanni Zavarella et.al.|[2408.02377v1](http://arxiv.org/abs/2408.02377v1)|null|
|**2024-08-05**|**Operationalizing Contextual Integrity in Privacy-Conscious Assistants**|Sahra Ghalebikesabi et.al.|[2408.02373v1](http://arxiv.org/abs/2408.02373v1)|null|
|**2024-08-05**|**Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought Decoding**|Renato Vukovic et.al.|[2408.02361v1](http://arxiv.org/abs/2408.02361v1)|null|
|**2024-08-05**|**Active Sensing of Knee Osteoarthritis Progression with Reinforcement Learning**|Khanh Nguyen et.al.|[2408.02349v1](http://arxiv.org/abs/2408.02349v1)|null|
|**2024-08-05**|**An approach to optimize inference of the DIART speaker diarization pipeline**|Roman Aperdannier et.al.|[2408.02341v1](http://arxiv.org/abs/2408.02341v1)|null|
|**2024-08-05**|**Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction**|Albert Sawczyn et.al.|[2408.02337v1](http://arxiv.org/abs/2408.02337v1)|null|
|**2024-08-05**|**SNFinLLM: Systematic and Nuanced Financial Domain Adaptation of Chinese Large Language Models**|Shujuan Zhao et.al.|[2408.02302v1](http://arxiv.org/abs/2408.02302v1)|null|
|**2024-08-05**|**Generalized Gaussian Temporal Difference Error For Uncertainty-aware Reinforcement Learning**|Seyeon Kim et.al.|[2408.02295v1](http://arxiv.org/abs/2408.02295v1)|null|
|**2024-08-05**|**Decoupled Vocabulary Learning Enables Zero-Shot Translation from Unseen Languages**|Carlos Mullov et.al.|[2408.02290v1](http://arxiv.org/abs/2408.02290v1)|null|
|**2024-08-05**|**Spin glass model of in-context learning**|Yuhao Li et.al.|[2408.02288v1](http://arxiv.org/abs/2408.02288v1)|null|
|**2024-08-05**|**Hardware Aware Ensemble Selection for Balancing Predictive Accuracy and Cost**|Jannis Maier et.al.|[2408.02280v1](http://arxiv.org/abs/2408.02280v1)|null|
|**2024-08-05**|**DRFormer: Multi-Scale Transformer Utilizing Diverse Receptive Fields for Long Time-Series Forecasting**|Ruixin Ding et.al.|[2408.02279v1](http://arxiv.org/abs/2408.02279v1)|null|
|**2024-08-05**|**Geometric Algebra Meets Large Language Models: Instruction-Based Transformations of Separate Meshes in 3D, Interactive and Controllable Scenes**|Dimitris Angelis et.al.|[2408.02275v1](http://arxiv.org/abs/2408.02275v1)|null|
|**2024-08-05**|**COM Kitchens: An Unedited Overhead-view Video Dataset as a Vision-Language Benchmark**|Koki Maeda et.al.|[2408.02272v1](http://arxiv.org/abs/2408.02272v1)|null|
|**2024-08-05**|**StyEmp: Stylizing Empathetic Response Generation via Multi-Grained Prefix Encoder and Personality Reinforcement**|Yahui Fu et.al.|[2408.02271v1](http://arxiv.org/abs/2408.02271v1)|null|
|**2024-08-05**|**Advancing Post-OCR Correction: A Comparative Study of Synthetic Data**|Shuhao Guan et.al.|[2408.02253v1](http://arxiv.org/abs/2408.02253v1)|null|
|**2024-08-05**|**ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems**|Andrew Zhu et.al.|[2408.02248v1](http://arxiv.org/abs/2408.02248v1)|null|
|**2024-08-05**|**Evaluating Vision-Language Models for Zero-Shot Detection, Classification, and Association of Motorcycles, Passengers, and Helmets**|Lucas Choi et.al.|[2408.02244v1](http://arxiv.org/abs/2408.02244v1)|null|
|**2024-08-05**|**BOTS-LM: Training Large Language Models for Setswana**|Nathan Brown et.al.|[2408.02239v1](http://arxiv.org/abs/2408.02239v1)|null|
|**2024-08-05**|**Do Large Language Models Speak All Languages Equally? A Comparative Study in Low-Resource Settings**|Md. Arid Hasan et.al.|[2408.02237v1](http://arxiv.org/abs/2408.02237v1)|null|
|**2024-08-05**|**A Multi-Source Heterogeneous Knowledge Injected Prompt Learning Method for Legal Charge Prediction**|Jingyun Sun et.al.|[2408.02233v1](http://arxiv.org/abs/2408.02233v1)|null|
|**2024-08-05**|**SpecRover: Code Intent Extraction via LLMs**|Haifeng Ruan et.al.|[2408.02232v1](http://arxiv.org/abs/2408.02232v1)|null|
|**2024-08-05**|**Is Large Language Model Good at Database Knob Tuning? A Comprehensive Experimental Evaluation**|Yiyan Li et.al.|[2408.02213v1](http://arxiv.org/abs/2408.02213v1)|null|
|**2024-08-05**|**MARCO: A Memory-Augmented Reinforcement Framework for Combinatorial Optimization**|Andoni I. Garmendia et.al.|[2408.02207v1](http://arxiv.org/abs/2408.02207v1)|null|
|**2024-08-05**|**Towards AI-Safety-by-Design: A Taxonomy of Runtime Guardrails in Foundation Model based Systems**|Md Shamsujjoha et.al.|[2408.02205v1](http://arxiv.org/abs/2408.02205v1)|null|
|**2024-08-05**|**Evaluating the Performance of Large Language Models for SDG Mapping (Technical Report)**|Hui Yin et.al.|[2408.02201v1](http://arxiv.org/abs/2408.02201v1)|null|
|**2024-08-05**|**CodeACT: Code Adaptive Compute-efficient Tuning Framework for Code LLMs**|Weijie Lv et.al.|[2408.02193v1](http://arxiv.org/abs/2408.02193v1)|null|
|**2024-08-04**|**Calibration-Disentangled Learning and Relevance-Prioritized Reranking for Calibrated Sequential Recommendation**|Hyunsik Jeon et.al.|[2408.02156v1](http://arxiv.org/abs/2408.02156v1)|null|
|**2024-08-04**|**ARVO: Atlas of Reproducible Vulnerabilities for Open Source Software**|Xiang Mei et.al.|[2408.02153v1](http://arxiv.org/abs/2408.02153v1)|null|
|**2024-08-04**|**Generative Retrieval with Few-shot Indexing**|Arian Askari et.al.|[2408.02152v1](http://arxiv.org/abs/2408.02152v1)|null|
|**2024-08-04**|**Environment Complexity and Nash Equilibria in a Sequential Social Dilemma**|Mustafa Yasir et.al.|[2408.02148v1](http://arxiv.org/abs/2408.02148v1)|null|
|**2024-08-04**|**Analyzing Cultural Representations of Emotions in LLMs through Mixed Emotion Survey**|Shiran Dudy et.al.|[2408.02143v1](http://arxiv.org/abs/2408.02143v1)|null|
|**2024-08-04**|**VidModEx: Interpretable and Efficient Black Box Model Extraction for High-Dimensional Spaces**|Somnath Sendhil Kumar et.al.|[2408.02140v1](http://arxiv.org/abs/2408.02140v1)|null|
|**2024-08-04**|**Table Transformers for Imputing Textual Attributes**|Ting-Ruen Wei et.al.|[2408.02128v1](http://arxiv.org/abs/2408.02128v1)|null|
|**2024-08-04**|**Recent Advances in Multi-Choice Machine Reading Comprehension: A Survey on Methods and Datasets**|Shima Foolad et.al.|[2408.02114v1](http://arxiv.org/abs/2408.02114v1)|null|
|**2024-08-04**|**Understanding Deep Learning via Notions of Rank**|Noam Razin et.al.|[2408.02111v1](http://arxiv.org/abs/2408.02111v1)|null|
|**2024-08-04**|**Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process**|Peng Wang et.al.|[2408.02103v1](http://arxiv.org/abs/2408.02103v1)|null|
|**2024-08-04**|**KAN-RCBEVDepth: A multi-modal fusion algorithm in object detection for autonomous driving**|Zhihao Lai et.al.|[2408.02088v1](http://arxiv.org/abs/2408.02088v1)|null|
|**2024-08-04**|**Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data Assessment and Selection for Instruction Tuning of Language Models**|Yulei Qin et.al.|[2408.02085v1](http://arxiv.org/abs/2408.02085v1)|null|
|**2024-08-04**|**MedSyn: LLM-based Synthetic Medical Text Generation Framework**|Gleb Kumichev et.al.|[2408.02056v1](http://arxiv.org/abs/2408.02056v1)|null|
|**2024-08-04**|**Fine-tuning multilingual language models in Twitter/X sentiment analysis: a study on Eastern-European V4 languages**|Tomáš Filip et.al.|[2408.02044v1](http://arxiv.org/abs/2408.02044v1)|null|
|**2024-08-04**|**Self-Introspective Decoding: Alleviating Hallucinations for Large Vision-Language Models**|Fushuo Huo et.al.|[2408.02032v1](http://arxiv.org/abs/2408.02032v1)|null|
|**2024-08-04**|**Contrastive Learning-based Chaining-Cluster for Multilingual Voice-Face Association**|Wuyang Chen et.al.|[2408.02025v1](http://arxiv.org/abs/2408.02025v1)|null|
|**2024-08-04**|**Individualized multi-horizon MRI trajectory prediction for Alzheimer's Disease**|Rosemary He et.al.|[2408.02018v1](http://arxiv.org/abs/2408.02018v1)|null|
|**2024-08-04**|**Joint Learning of Emotions in Music and Generalized Sounds**|Simonetta Federico et.al.|[2408.02009v1](http://arxiv.org/abs/2408.02009v1)|null|
|**2024-08-04**|**LLaSA: Large Language and E-Commerce Shopping Assistant**|Shuo Zhang et.al.|[2408.02006v1](http://arxiv.org/abs/2408.02006v1)|null|
|**2024-08-04**|**Reinforcement Learning for an Efficient and Effective Malware Investigation during Cyber Incident Response**|Dipo Dunsin et.al.|[2408.01999v1](http://arxiv.org/abs/2408.01999v1)|null|
|**2024-08-04**|**MetaWearS: A Shortcut in Wearable Systems Lifecycle with Only a Few Shots**|Alireza Amirshahi et.al.|[2408.01988v1](http://arxiv.org/abs/2408.01988v1)|null|
|**2024-08-04**|**DeMansia: Mamba Never Forgets Any Tokens**|Ricky Fang et.al.|[2408.01986v1](http://arxiv.org/abs/2408.01986v1)|null|
|**2024-08-04**|**SR-CIS: Self-Reflective Incremental System with Decoupled Memory and Reasoning**|Biqing Qi et.al.|[2408.01970v1](http://arxiv.org/abs/2408.01970v1)|null|
|**2024-08-04**|**Optimal and efficient text counterfactuals using Graph Neural Networks**|Dimitris Lymperopoulos et.al.|[2408.01969v1](http://arxiv.org/abs/2408.01969v1)|null|
|**2024-08-04**|**ML-EAT: A Multilevel Embedding Association Test for Interpretable and Transparent Social Science**|Robert Wolfe et.al.|[2408.01966v1](http://arxiv.org/abs/2408.01966v1)|null|
|**2024-08-04**|**Top K Enhanced Reinforcement Learning Attacks on Heterogeneous Graph Node Classification**|Honglin Gao et.al.|[2408.01964v1](http://arxiv.org/abs/2408.01964v1)|null|
|**2024-08-04**|**A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios**|Samuel Ackerman et.al.|[2408.01963v1](http://arxiv.org/abs/2408.01963v1)|null|
|**2024-08-04**|**The Implications of Open Generative Models in Human-Centered Data Science Work: A Case Study with Fact-Checking Organizations**|Robert Wolfe et.al.|[2408.01962v1](http://arxiv.org/abs/2408.01962v1)|null|
|**2024-08-04**|**Representation Bias of Adolescents in AI: A Bilingual, Bicultural Study**|Robert Wolfe et.al.|[2408.01961v1](http://arxiv.org/abs/2408.01961v1)|null|
|**2024-08-04**|**AnomalySD: Few-Shot Multi-Class Anomaly Detection with Stable Diffusion Model**|Zhenyu Yan et.al.|[2408.01960v1](http://arxiv.org/abs/2408.01960v1)|null|
|**2024-08-04**|**Dataset Scale and Societal Consistency Mediate Facial Impression Bias in Vision-Language AI**|Robert Wolfe et.al.|[2408.01959v1](http://arxiv.org/abs/2408.01959v1)|null|
|**2024-08-04**|**Why Perturbing Symbolic Music is Necessary: Fitting the Distribution of Never-used Notes through a Joint Probabilistic Diffusion Model**|Shipei Liu et.al.|[2408.01950v1](http://arxiv.org/abs/2408.01950v1)|null|
|**2024-08-04**|**Visual Grounding for Object-Level Generalization in Reinforcement Learning**|Haobin Jiang et.al.|[2408.01942v1](http://arxiv.org/abs/2408.01942v1)|null|
|**2024-08-04**|**Defining and Evaluating Decision and Composite Risk in Language Models Applied to Natural Language Inference**|Ke Shen et.al.|[2408.01935v1](http://arxiv.org/abs/2408.01935v1)|null|
|**2024-08-04**|**DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models**|Bowen Wang et.al.|[2408.01933v1](http://arxiv.org/abs/2408.01933v1)|null|
|**2024-08-04**|**A Semi-supervised Multi-channel Graph Convolutional Network for Query Classification in E-commerce**|Chunyuan Yuan et.al.|[2408.01928v1](http://arxiv.org/abs/2408.01928v1)|null|
|**2024-08-04**|**MAO: A Framework for Process Model Generation with Multi-Agent Orchestration**|Leilei Lin et.al.|[2408.01916v1](http://arxiv.org/abs/2408.01916v1)|null|
|**2024-08-04**|**Re-ENACT: Reinforcement Learning for Emotional Speech Generation using Actor-Critic Strategy**|Ravi Shankar et.al.|[2408.01892v1](http://arxiv.org/abs/2408.01892v1)|null|
|**2024-08-04**|**Cross-layer Attention Sharing for Large Language Models**|Yongyu Mu et.al.|[2408.01890v1](http://arxiv.org/abs/2408.01890v1)|null|
|**2024-08-03**|**Walk Wisely on Graph: Knowledge Graph Reasoning with Dual Agents via Efficient Guidance-Exploration**|Zijian Wang et.al.|[2408.01880v1](http://arxiv.org/abs/2408.01880v1)|null|
|**2024-08-03**|**Re-Invoke: Tool Invocation Rewriting for Zero-Shot Tool Retrieval**|Yanfei Chen et.al.|[2408.01875v1](http://arxiv.org/abs/2408.01875v1)|null|
|**2024-08-03**|**MALADE: Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance**|Jihye Choi et.al.|[2408.01869v1](http://arxiv.org/abs/2408.01869v1)|null|
|**2024-08-03**|**Efficient Solutions For An Intriguing Failure of LLMs: Long Context Window Does Not Mean LLMs Can Analyze Long Sequences Flawlessly**|Peyman Hosseini et.al.|[2408.01866v1](http://arxiv.org/abs/2408.01866v1)|null|
|**2024-08-03**|**Sólo Escúchame: Spanish Emotional Accompaniment Chatbot**|Bruno Gil Ramírez et.al.|[2408.01852v1](http://arxiv.org/abs/2408.01852v1)|null|
|**2024-08-03**|**ST-SACLF: Style Transfer Informed Self-Attention Classifier for Bias-Aware Painting Classification**|Mridula Vijendran et.al.|[2408.01827v1](http://arxiv.org/abs/2408.01827v1)|null|
|**2024-08-03**|**ALIF: Low-Cost Adversarial Audio Attacks on Black-Box Speech Platforms using Linguistic Features**|Peng Cheng et.al.|[2408.01808v1](http://arxiv.org/abs/2408.01808v1)|null|

#### Abstracts
##### **Self-Taught Evaluators**
2408.02666v1 by Tianlu Wang, Ilia Kulikov, Olga Golovneva, Ping Yu, Weizhe Yuan, Jane Dwivedi-Yu, Richard Yuanzhe Pang, Maryam Fazel-Zarandi, Jason Weston, Xian Li

Model-based evaluation is at the heart of successful model development -- as
a reward model for training, and as a replacement for human evaluation. To
train such evaluators, the standard approach is to collect a large amount of
human preference judgments over model responses, which is costly and the data
becomes stale as models improve. In this work, we present an approach that aims
to im-prove evaluators without human annotations, using synthetic training data
only. Starting from unlabeled instructions, our iterative self-improvement
scheme generates contrasting model outputs and trains an LLM-as-a-Judge to
produce reasoning traces and final judgments, repeating this training at each
new iteration using the improved predictions. Without any labeled preference
data, our Self-Taught Evaluator can improve a strong LLM (Llama3-70B-Instruct)
from 75.4 to 88.3 (88.7 with majority vote) on RewardBench. This outperforms
commonly used LLM judges such as GPT-4 and matches the performance of the
top-performing reward models trained with labeled examples.

摘要：基於模型的評估是成功模型開發的核心，作為訓練的獎勵模型，以及作為人工評估的替代方案。為了訓練此類評估器，標準方法是收集大量人類偏好判斷，以對模型反應進行評估，這既昂貴，而且隨著模型的改進，數據也會變得陳舊。在這項工作中，我們提出了一種旨在在沒有人工註解的情況下改進評估器的方法，僅使用合成訓練數據。從未標記的說明開始，我們的迭代式自我改進方案會產生對比的模型輸出，並訓練 LLM-as-a-Judge 以產生推理追蹤和最終判斷，在每次新的迭代中使用改進的預測重複此訓練。在沒有任何標記的偏好數據的情況下，我們的自學評估器可以將強大的 LLM（Llama3-70B-Instruct）從 RewardBench 上的 75.4 提升到 88.3（多數投票為 88.7）。這優於常用的 LLM 評審，例如 GPT-4，並且與使用標記範例訓練的效能最佳的獎勵模型的效能相匹配。

##### **Can Reinforcement Learning Unlock the Hidden Dangers in Aligned Large Language Models?**
2408.02651v1 by Mohammad Bahrami Karkevandi, Nishant Vishwamitra, Peyman Najafirad

Large Language Models (LLMs) have demonstrated impressive capabilities in
natural language tasks, but their safety and morality remain contentious due to
their training on internet text corpora. To address these concerns, alignment
techniques have been developed to improve the public usability and safety of
LLMs. Yet, the potential for generating harmful content through these models
seems to persist. This paper explores the concept of jailbreaking
LLMs-reversing their alignment through adversarial triggers. Previous methods,
such as soft embedding prompts, manually crafted prompts, and gradient-based
automatic prompts, have had limited success on black-box models due to their
requirements for model access and for producing a low variety of manually
crafted prompts, making them susceptible to being blocked. This paper
introduces a novel approach using reinforcement learning to optimize
adversarial triggers, requiring only inference API access to the target model
and a small surrogate model. Our method, which leverages a BERTScore-based
reward function, enhances the transferability and effectiveness of adversarial
triggers on new black-box models. We demonstrate that this approach improves
the performance of adversarial triggers on a previously untested language
model.

摘要：大型語言模型 (LLM) 在自然語言任務中展現出令人印象深刻的能力，但由於它們在網際網路文字語料庫上訓練，安全性與道德性仍有爭議。為了解決這些問題，已開發出校準技術來改善 LLM 的公開可用性和安全性。然而，透過這些模型產生有害內容的可能性似乎仍然存在。本文探討了越獄 LLM 的概念，透過對抗性觸發器來逆轉它們的校準。先前的技術，例如軟嵌入提示、手動製作提示和基於梯度的自動提示，由於需要存取模型和產生少量手動製作提示，導致在黑箱模型上成功有限，使其容易受到封鎖。本文介紹了一種使用強化學習來最佳化對抗性觸發器的新方法，只需要推論 API 存取目標模型和一個小型代理模型。我們的技術利用基於 BERTScore 的獎勵函數，增強了對抗性觸發器在新黑箱模型上的可傳遞性和有效性。我們證明了這種方法改善了對抗性觸發器在先前未測試過的語言模型上的效能。

##### **SEAS: Self-Evolving Adversarial Safety Optimization for Large Language Models**
2408.02632v1 by Muxi Diao, Rumei Li, Shiyang Liu, Guogang Liao, Jingang Wang, Xunliang Cai, Weiran Xu

As large language models (LLMs) continue to advance in capability and
influence, ensuring their security and preventing harmful outputs has become
crucial. A promising approach to address these concerns involves training
models to automatically generate adversarial prompts for red teaming. However,
the evolving subtlety of vulnerabilities in LLMs challenges the effectiveness
of current adversarial methods, which struggle to specifically target and
explore the weaknesses of these models. To tackle these challenges, we
introduce the $\mathbf{S}\text{elf-}\mathbf{E}\text{volving
}\mathbf{A}\text{dversarial }\mathbf{S}\text{afety }\mathbf{(SEAS)}$
optimization framework, which enhances security by leveraging data generated by
the model itself. SEAS operates through three iterative stages: Initialization,
Attack, and Adversarial Optimization, refining both the Red Team and Target
models to improve robustness and safety. This framework reduces reliance on
manual testing and significantly enhances the security capabilities of LLMs.
Our contributions include a novel adversarial framework, a comprehensive safety
dataset, and after three iterations, the Target model achieves a security level
comparable to GPT-4, while the Red Team model shows a marked increase in attack
success rate (ASR) against advanced models.

摘要：隨著大型語言模型 (LLM) 在能力和影響力方面持續進步，確保其安全性並防止有害輸出已變得至關重要。解決這些問題的一個有前途的方法涉及訓練模型以自動生成對抗性提示以進行紅隊演練。然而，LLM 中漏洞的微妙性不斷演變，挑戰了當前對抗方法的有效性，這些方法難以針對這些模型的弱點並加以探索。為了應對這些挑戰，我們引入了 $\mathbf{S}\text{elf-}\mathbf{E}\text{volving
}\mathbf{A}\text{dversarial }\mathbf{S}\text{afety }\mathbf{(SEAS)}$ 最佳化架構，它通過利用模型本身產生的數據來增強安全性。SEAS 通過三個反覆運算階段運作：初始化、攻擊和對抗性最佳化，優化紅隊和目標模型以提高穩健性和安全性。此架構減少了對手動測試的依賴，並顯著增強了 LLM 的安全功能。我們的貢獻包括一個新穎的對抗性架構、一個全面的安全性資料集，並且經過三次反覆運算後，目標模型達到了與 GPT-4 相當的安全性等級，而紅隊模型顯示出對抗高級模型的攻擊成功率 (ASR) 明顯增加。

##### **Language Model Can Listen While Speaking**
2408.02622v1 by Ziyang Ma, Yakun Song, Chenpeng Du, Jian Cong, Zhuo Chen, Yuping Wang, Yuxuan Wang, Xie Chen

Dialogue serves as the most natural manner of human-computer interaction
(HCI). Recent advancements in speech language models (SLM) have significantly
enhanced speech-based conversational AI. However, these models are limited to
turn-based conversation, lacking the ability to interact with humans in
real-time spoken scenarios, for example, being interrupted when the generated
content is not satisfactory. To address these limitations, we explore full
duplex modeling (FDM) in interactive speech language models (iSLM), focusing on
enhancing real-time interaction and, more explicitly, exploring the
quintessential ability of interruption. We introduce a novel model design,
namely listening-while-speaking language model (LSLM), an end-to-end system
equipped with both listening and speaking channels. Our LSLM employs a
token-based decoder-only TTS for speech generation and a streaming
self-supervised learning (SSL) encoder for real-time audio input. LSLM fuses
both channels for autoregressive generation and detects turn-taking in real
time. Three fusion strategies -- early fusion, middle fusion, and late fusion
-- are explored, with middle fusion achieving an optimal balance between speech
generation and real-time interaction. Two experimental settings, command-based
FDM and voice-based FDM, demonstrate LSLM's robustness to noise and sensitivity
to diverse instructions. Our results highlight LSLM's capability to achieve
duplex communication with minimal impact on existing systems. This study aims
to advance the development of interactive speech dialogue systems, enhancing
their applicability in real-world contexts.

摘要：對話是人機互動 (HCI) 最自然的方式。語音語言模型 (SLM) 的最新進展已大幅提升基於語音的對話式 AI。然而，這些模型僅限於回合制對話，無法與人類進行即時口語互動，例如在產生的內容不令人滿意時被打斷。為了解決這些限制，我們在互動式語音語言模型 (iSLM) 中探索全雙工建模 (FDM)，重點在於增強即時互動，更明確地說，探索中斷的精髓能力。我們引入了一種新穎的模型設計，即聆聽時說話語言模型 (LSLM)，這是一個具備聆聽和說話通道的端對端系統。我們的 LSLM 使用基於代碼的僅解碼器 TTS 進行語音產生，並使用串流自監督學習 (SSL) 編碼器進行即時音訊輸入。LSLM 融合了兩個通道進行自迴歸產生，並即時偵測輪流發言。探索了三個融合策略——早期融合、中期融合和後期融合——其中中期融合在語音產生和即時互動之間取得了最佳平衡。兩種實驗設定，基於指令的 FDM 和基於語音的 FDM，展示了 LSLM 對雜訊的穩健性和對不同指令的敏感性。我們的結果突顯了 LSLM 在對現有系統影響最小的情況下實現雙工通訊的能力。本研究旨在推動互動式語音對話系統的發展，增強其在現實世界中的應用性。

##### **BioMamba: A Pre-trained Biomedical Language Representation Model Leveraging Mamba**
2408.02600v1 by Ling Yue, Sixue Xing, Yingzhou Lu, Tianfan Fu

The advancement of natural language processing (NLP) in biology hinges on
models' ability to interpret intricate biomedical literature. Traditional
models often struggle with the complex and domain-specific language in this
field. In this paper, we present BioMamba, a pre-trained model specifically
designed for biomedical text mining. BioMamba builds upon the Mamba
architecture and is pre-trained on an extensive corpus of biomedical
literature. Our empirical studies demonstrate that BioMamba significantly
outperforms models like BioBERT and general-domain Mamba across various
biomedical tasks. For instance, BioMamba achieves a 100 times reduction in
perplexity and a 4 times reduction in cross-entropy loss on the BioASQ test
set. We provide an overview of the model architecture, pre-training process,
and fine-tuning techniques. Additionally, we release the code and trained model
to facilitate further research.

摘要：自然語言處理 (NLP) 在生物學中的進展取決於
模型詮釋複雜生物醫學文獻的能力。傳統
模型經常難以應付這個領域中複雜且領域特定的語言。在本文中，我們提出 BioMamba，一種專門
設計用於生物醫學文本探勘的預訓練模型。BioMamba 建立在 Mamba
架構之上，並在大量的生物醫學預訓練
文獻上進行預訓練。我們的實證研究證明，BioMamba 在各種
生物醫學任務上都明顯優於 BioBERT 和一般領域的 Mamba。例如，BioMamba 在 BioASQ 測試
集中將困惑度降低了 100 倍，並將交叉熵損失降低了 4 倍。我們提供了模型架構、預訓練流程的概述，
以及微調技術。此外，我們釋出程式碼和訓練好的模型
以促進進一步的研究。

##### **Progressively Selective Label Enhancement for Language Model Alignment**
2408.02599v1 by Biao Liu, Ning Xu, Xin Geng

Large Language Models have demonstrated impressive capabilities in various
language tasks but may produce content that misaligns with human expectations,
raising ethical and legal concerns. Therefore, it is important to explore the
limitations and implement restrictions on the models to ensure safety and
compliance, with Reinforcement Learning from Human Feedback (RLHF) being the
primary method. Due to challenges in stability and scalability with the RLHF
stages, researchers are exploring alternative methods to achieve effects
comparable to those of RLHF. However, these methods often depend on large
high-quality datasets and inefficiently utilize generated data. To deal with
this problem, we propose PSLE, i.e., Progressively Selective Label Enhancement
for Language Model Alignment, a framework that fully utilizes all generated
data by guiding the model with principles to align outputs with human
expectations. Using a dynamically updated threshold, our approach ensures
efficient data utilization by incorporating all generated responses and
weighting them based on their corresponding reward scores. Experimental results
on multiple datasets demonstrate the effectiveness of PSLE compared to existing
language model alignment methods.

摘要：大型語言模型已在各種語言任務中展現出令人印象深刻的能力，但可能會產生與人類期望不符的內容，引發道德和法律方面的疑慮。因此，探索模型的限制並實施限制以確保安全性和合規性非常重要，而透過人類回饋的強化學習 (RLHF) 是主要方法。由於 RLHF 階段在穩定性和可擴充性方面存在挑戰，研究人員正在探索替代方法以實現與 RLHF 相當的效果。然而，這些方法通常依賴於大型高品質的資料集，且無法有效利用產生的資料。為了解決這個問題，我們提出 PSLE，即語言模型比對的漸進式選擇標籤增強，這是一個透過指導模型使用原則來比對輸出與人類期望，進而充分利用所有產生資料的框架。我們的做法使用動態更新的閾值，透過納入所有產生的回應並根據其對應的獎勵分數加權，確保有效利用資料。在多個資料集上的實驗結果證明了 PSLE 與現有的語言模型比對方法相比的有效性。

##### **Modelling Visual Semantics via Image Captioning to extract Enhanced Multi-Level Cross-Modal Semantic Incongruity Representation with Attention for Multimodal Sarcasm Detection**
2408.02595v1 by Sajal Aggarwal, Ananya Pandey, Dinesh Kumar Vishwakarma

Sarcasm is a type of irony, characterized by an inherent mismatch between the
literal interpretation and the intended connotation. Though sarcasm detection
in text has been extensively studied, there are situations in which textual
input alone might be insufficient to perceive sarcasm. The inclusion of
additional contextual cues, such as images, is essential to recognize sarcasm
in social media data effectively. This study presents a novel framework for
multimodal sarcasm detection that can process input triplets. Two components of
these triplets comprise the input text and its associated image, as provided in
the datasets. Additionally, a supplementary modality is introduced in the form
of descriptive image captions. The motivation behind incorporating this visual
semantic representation is to more accurately capture the discrepancies between
the textual and visual content, which are fundamental to the sarcasm detection
task. The primary contributions of this study are: (1) a robust textual feature
extraction branch that utilizes a cross-lingual language model; (2) a visual
feature extraction branch that incorporates a self-regulated residual ConvNet
integrated with a lightweight spatially aware attention module; (3) an
additional modality in the form of image captions generated using an
encoder-decoder architecture capable of reading text embedded in images; (4)
distinct attention modules to effectively identify the incongruities between
the text and two levels of image representations; (5) multi-level cross-domain
semantic incongruity representation achieved through feature fusion. Compared
with cutting-edge baselines, the proposed model achieves the best accuracy of
92.89% and 64.48%, respectively, on the Twitter multimodal sarcasm and
MultiBully datasets.

摘要：<paragraph>諷刺是一種反諷，其特點是字面意思與預期的含義之間存在固有的不匹配。雖然文本中的諷刺偵測已被廣泛研究，但在某些情況下，單獨的文本輸入可能不足以感知諷刺。加入額外的上下文線索，例如圖片，對於有效識別社群媒體資料中的諷刺至關重要。本研究提出了一個多模態諷刺偵測的新框架，可以處理輸入三元組。這些三元組的兩個組成部分包括輸入文本及其關聯圖片，如資料集中所提供的。此外，以描述性圖片標題的形式引入了一個補充模態。加入這種視覺語義表示的動機是更準確地捕捉文本和視覺內容之間的差異，這對於諷刺偵測任務至關重要。本研究的主要貢獻包括：(1) 一個強健的文本特徵提取分支，它利用了一個跨語言語言模型；(2) 一個視覺特徵提取分支，它結合了一個自調節殘差 ConvNet，並集成了輕量級空間感知注意力模組；(3) 一個額外的模態，以圖片標題的形式，使用一個能夠讀取圖片中嵌入文本的編碼器-解碼器架構產生；(4) 不同的注意力模組，以有效識別文本和兩個層級的圖片表示之間的不一致；(5) 通過特徵融合實現的多層級跨領域語義不一致表示。與尖端的基準相比，所提出的模型分別在 Twitter 多模態諷刺和 MultiBully 資料集上達到了 92.89% 和 64.48% 的最佳準確度。</paragraph>

##### **Leveraging the Power of LLMs: A Fine-Tuning Approach for High-Quality Aspect-Based Summarization**
2408.02584v1 by Ankan Mullick, Sombit Bose, Rounak Saha, Ayan Kumar Bhowmick, Aditya Vempaty, Pawan Goyal, Niloy Ganguly, Prasenjit Dey, Ravi Kokku

The ever-increasing volume of digital information necessitates efficient
methods for users to extract key insights from lengthy documents. Aspect-based
summarization offers a targeted approach, generating summaries focused on
specific aspects within a document. Despite advancements in aspect-based
summarization research, there is a continuous quest for improved model
performance. Given that large language models (LLMs) have demonstrated the
potential to revolutionize diverse tasks within natural language processing,
particularly in the problem of summarization, this paper explores the potential
of fine-tuning LLMs for the aspect-based summarization task. We evaluate the
impact of fine-tuning open-source foundation LLMs, including Llama2, Mistral,
Gemma and Aya, on a publicly available domain-specific aspect based summary
dataset. We hypothesize that this approach will enable these models to
effectively identify and extract aspect-related information, leading to
superior quality aspect-based summaries compared to the state-of-the-art. We
establish a comprehensive evaluation framework to compare the performance of
fine-tuned LLMs against competing aspect-based summarization methods and
vanilla counterparts of the fine-tuned LLMs. Our work contributes to the field
of aspect-based summarization by demonstrating the efficacy of fine-tuning LLMs
for generating high-quality aspect-based summaries. Furthermore, it opens doors
for further exploration of using LLMs for targeted information extraction tasks
across various NLP domains.

摘要：隨著數位資訊量不斷增加，使用者需要有效率的方法從冗長的文件中萃取出重點洞察。基於面向面向的摘要提供了一個目標導向的方法，產生摘要，專注於文件中的特定面向。儘管在基於面向的摘要研究中有進展，但仍持續追求改善模型效能。考量到大型語言模型 (LLM) 已展現出革新自然語言處理中各種任務的潛力，特別是在摘要問題中，本文探討了微調 LLM 以用於基於面向的摘要任務的潛力。我們評估微調開放原始碼基礎 LLM（包括 Llama2、Mistral、Gemma 和 Aya）對公開可用的特定領域面向摘要資料集的影響。我們假設這種方法將使這些模型能夠有效地識別和萃取出與面向相關的資訊，產生與現有技術相比品質更優異的基於面向的摘要。我們建立了一個全面的評估架構，以比較微調 LLM 與競爭的基於面向的摘要方法以及微調 LLM 的原始版本之間的效能。我們的研究透過展示微調 LLM 以產生高品質的基於面向的摘要的效能，為基於面向的摘要領域做出貢獻。此外，它也開啟了進一步探索使用 LLM 進行跨各種 NLP 領域的目標資訊萃取任務的大門。

##### **Clustering and Mining Accented Speech for Inclusive and Fair Speech Recognition**
2408.02582v1 by Jaeyoung Kim, Han Lu, Soheil Khorram, Anshuman Tripathi, Qian Zhang, Hasim Sak

Modern automatic speech recognition (ASR) systems are typically trained on
more than tens of thousands hours of speech data, which is one of the main
factors for their great success. However, the distribution of such data is
typically biased towards common accents or typical speech patterns. As a
result, those systems often poorly perform on atypical accented speech. In this
paper, we present accent clustering and mining schemes for fair speech
recognition systems which can perform equally well on under-represented
accented speech. For accent recognition, we applied three schemes to overcome
limited size of supervised accent data: supervised or unsupervised
pre-training, distributionally robust optimization (DRO) and unsupervised
clustering. Three schemes can significantly improve the accent recognition
model especially for unbalanced and small accented speech. Fine-tuning ASR on
the mined Indian accent speech using the proposed supervised or unsupervised
clustering schemes showed 10.0% and 5.3% relative improvements compared to
fine-tuning on the randomly sampled speech, respectively.

摘要：現代自動語音辨識 (ASR) 系統通常會在超過數萬小時的語音資料上進行訓練，這是它們成功的主要因素之一。然而，此類資料的分配通常會偏向於常見的口音或典型的語音模式。因此，這些系統在非典型口音的語音上往往表現不佳。在本文中，我們提出公平語音辨識系統的口音分群和挖掘方案，這些方案可以在代表性不足的口音語音上表現得一樣好。對於口音辨識，我們應用三種方案來克服監督式口音資料的規模限制：監督式或非監督式預訓練、分佈穩健最佳化 (DRO) 和非監督式分群。三種方案可以顯著改善口音辨識模型，特別是對於不平衡且規模小的口音語音。使用建議的監督式或非監督式分群方案對挖掘的印度口音語音進行 ASR 微調，與對隨機取樣的語音進行微調相比，分別顯示出 10.0% 和 5.3% 的相對改善。

##### **Contrastive Learning-based Multi Modal Architecture for Emoticon Prediction by Employing Image-Text Pairs**
2408.02571v1 by Ananya Pandey, Dinesh Kumar Vishwakarma

The emoticons are symbolic representations that generally accompany the
textual content to visually enhance or summarize the true intention of a
written message. Although widely utilized in the realm of social media, the
core semantics of these emoticons have not been extensively explored based on
multiple modalities. Incorporating textual and visual information within a
single message develops an advanced way of conveying information. Hence, this
research aims to analyze the relationship among sentences, visuals, and
emoticons. For an orderly exposition, this paper initially provides a detailed
examination of the various techniques for extracting multimodal features,
emphasizing the pros and cons of each method. Through conducting a
comprehensive examination of several multimodal algorithms, with specific
emphasis on the fusion approaches, we have proposed a novel contrastive
learning based multimodal architecture. The proposed model employs the joint
training of dual-branch encoder along with the contrastive learning to
accurately map text and images into a common latent space. Our key finding is
that by integrating the principle of contrastive learning with that of the
other two branches yields superior results. The experimental results
demonstrate that our suggested methodology surpasses existing multimodal
approaches in terms of accuracy and robustness. The proposed model attained an
accuracy of 91% and an MCC-score of 90% while assessing emoticons using the
Multimodal-Twitter Emoticon dataset acquired from Twitter. We provide evidence
that deep features acquired by contrastive learning are more efficient,
suggesting that the proposed fusion technique also possesses strong
generalisation capabilities for recognising emoticons across several modes.

摘要：表情符號是象徵性的表示，通常伴隨著文字內容，以視覺方式增強或總結書面訊息的真實意圖。雖然在社群媒體領域廣泛使用，但這些表情符號的核心語義尚未根據多種模式廣泛探討。在單一訊息中納入文字和視覺資訊，發展出傳達資訊的先進方式。因此，本研究旨在分析句子、視覺和表情符號之間的關係。為了有條理地說明，本文最初詳細探討了各種萃取多模態特徵的技術，並強調了每種方法的優缺點。透過對多種多模態演算法進行全面探討，特別強調融合方法，我們提出了一種基於對比學習的新穎多模態架構。所提出的模型採用雙分支編碼器的聯合訓練，以及對比學習，以準確地將文字和影像對應到一個共同的潛在空間。我們的關鍵發現是，將對比學習的原則與其他兩個分支的原則整合起來，會產生更好的結果。實驗結果表明，我們建議的方法在準確性和穩健性方面優於現有的多模態方法。所提出的模型在使用從 Twitter 取得的多模態 Twitter 表情符號資料集評估表情符號時，達到了 91% 的準確度和 90% 的 MCC 分數。我們提供了證據，證明透過對比學習獲得的深度特徵更有效率，這表示所提出的融合技術也具備跨多種模式辨識表情符號的強大泛化能力。

##### **Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information**
2408.02559v1 by Yauwai Yim, Chunkit Chan, Tianyu Shi, Zheye Deng, Wei Fan, Tianshi Zheng, Yangqiu Song

Large language models (LLMs) have shown success in handling simple games with
imperfect information and enabling multi-agent coordination, but their ability
to facilitate practical collaboration against other agents in complex,
imperfect information environments, especially in a non-English environment,
still needs to be explored. This study investigates the applicability of
knowledge acquired by open-source and API-based LLMs to sophisticated
text-based games requiring agent collaboration under imperfect information,
comparing their performance to established baselines using other types of
agents. We propose a Theory of Mind (ToM) planning technique that allows LLM
agents to adapt their strategy against various adversaries using only game
rules, current state, and historical context as input. An external tool was
incorporated to mitigate the challenge of dynamic and extensive action spaces
in this card game. Our results show that although a performance gap exists
between current LLMs and state-of-the-art reinforcement learning (RL) models,
LLMs demonstrate ToM capabilities in this game setting. It consistently
improves their performance against opposing agents, suggesting their ability to
understand the actions of allies and adversaries and establish collaboration
with allies. To encourage further research and understanding, we have made our
codebase openly accessible.

摘要：大型語言模型 (LLM) 已展現出在處理具有不完美資訊的簡單遊戲以及啟用多重代理協調方面的成功，但其促進在複雜、不完美資訊環境中與其他代理進行實際協作的能力，特別是在非英語環境中，仍有待探討。本研究探討了開放原始碼和基於 API 的 LLM 所獲得的知識，在需要代理在不完美資訊下協作的精緻文字遊戲中的適用性，並將其效能與使用其他類型代理的已建立基準進行比較。我們提出了一種心智理論 (ToM) 規劃技術，允許 LLM 代理僅使用遊戲規則、目前狀態和歷史背景作為輸入，來調整其對抗各種對手的策略。在這個紙牌遊戲中，整合了一個外部工具來減輕動態且廣泛動作空間的挑戰。我們的結果顯示，儘管目前的 LLM 和最先進的強化學習 (RL) 模型之間存在效能差距，但 LLM 在此遊戲設定中展現了 ToM 能力。它持續提升其對抗敵對代理的效能，表明其了解盟友和敵人的行動，並與盟友建立合作的能力。為了鼓勵進一步的研究和理解，我們已公開我們的程式碼庫。

##### **MeshAnything V2: Artist-Created Mesh Generation With Adjacent Mesh Tokenization**
2408.02555v1 by Yiwen Chen, Yikai Wang, Yihao Luo, Zhengyi Wang, Zilong Chen, Jun Zhu, Chi Zhang, Guosheng Lin

We introduce MeshAnything V2, an autoregressive transformer that generates
Artist-Created Meshes (AM) aligned to given shapes. It can be integrated with
various 3D asset production pipelines to achieve high-quality, highly
controllable AM generation. MeshAnything V2 surpasses previous methods in both
efficiency and performance using models of the same size. These improvements
are due to our newly proposed mesh tokenization method: Adjacent Mesh
Tokenization (AMT). Different from previous methods that represent each face
with three vertices, AMT uses a single vertex whenever possible. Compared to
previous methods, AMT requires about half the token sequence length to
represent the same mesh in average. Furthermore, the token sequences from AMT
are more compact and well-structured, fundamentally benefiting AM generation.
Our extensive experiments show that AMT significantly improves the efficiency
and performance of AM generation. Project Page:
https://buaacyw.github.io/meshanything-v2/

摘要：我們介紹了 MeshAnything V2，這是一種自迴歸轉換器，可生成與給定形狀對齊的藝術家創建網格 (AM)。它可以與各種 3D 資產製作管道整合，以實現高品質、高度可控的 AM 生成。MeshAnything V2 在效率和效能方面都超越了之前的模型，使用相同大小的模型。這些改進歸功於我們新提出的網格標記化方法：相鄰網格標記化 (AMT)。與之前用三個頂點表示每個面的方法不同，AMT 盡可能使用單個頂點。與之前的模型相比，AMT 平均需要大約一半的標記序列長度來表示相同的網格。此外，來自 AMT 的標記序列更緊湊且結構良好，從根本上有利於 AM 生成。我們廣泛的實驗表明，AMT 大幅提高了 AM 生成效率和效能。專案頁面：
https://buaacyw.github.io/meshanything-v2/

##### **The Role of Functional Muscle Networks in Improving Hand Gesture Perception for Human-Machine Interfaces**
2408.02547v1 by Costanza Armanini, Tuka Alhanai, Farah E. Shamout, S. Farokh Atashzar

Developing accurate hand gesture perception models is critical for various
robotic applications, enabling effective communication between humans and
machines and directly impacting neurorobotics and interactive robots. Recently,
surface electromyography (sEMG) has been explored for its rich informational
context and accessibility when combined with advanced machine learning
approaches and wearable systems. The literature presents numerous approaches to
boost performance while ensuring robustness for neurorobots using sEMG, often
resulting in models requiring high processing power, large datasets, and less
scalable solutions. This paper addresses this challenge by proposing the
decoding of muscle synchronization rather than individual muscle activation. We
study coherence-based functional muscle networks as the core of our perception
model, proposing that functional synchronization between muscles and the
graph-based network of muscle connectivity encode contextual information about
intended hand gestures. This can be decoded using shallow machine learning
approaches without the need for deep temporal networks. Our technique could
impact myoelectric control of neurorobots by reducing computational burdens and
enhancing efficiency. The approach is benchmarked on the Ninapro database,
which contains 12 EMG signals from 40 subjects performing 17 hand gestures. It
achieves an accuracy of 85.1%, demonstrating improved performance compared to
existing methods while requiring much less computational power. The results
support the hypothesis that a coherence-based functional muscle network encodes
critical information related to gesture execution, significantly enhancing hand
gesture perception with potential applications for neurorobotic systems and
interactive machines.

摘要：開發準確的手部手勢感知模型對於各種機器人應用至關重要，能讓人類與機器之間有效溝通，並直接影響神經機器人和互動式機器人。最近，表面肌電圖 (sEMG) 已被探索其豐富的資訊脈絡和可及性，並與先進的機器學習方法和可穿戴系統結合使用。文獻提出了許多方法來提升效能，同時確保使用 sEMG 的神經機器人的穩健性，通常會產生需要高處理能力、大型資料集和較不具擴充性的解決方案。本文透過提出解碼肌肉同步化，而非個別肌肉活化，來解決此挑戰。我們研究基於相干性的功能性肌肉網路，作為我們感知模型的核心，提出肌肉之間的功能性同步化和基於圖形的肌肉連接網路編碼有關預期手部手勢的背景資訊。這可以使用淺層機器學習方法解碼，而不需要深度時間網路。我們的技術可以透過減少運算負擔和提高效率，影響神經機器人的肌電控制。此方法以 Ninapro 資料庫為基準，其中包含來自 40 位受試者執行 17 種手部手勢的 12 個 EMG 訊號。它達到了 85.1% 的準確度，與現有方法相比，表現有所提升，同時需要的運算能力也少了很多。結果支持了基於相干性的功能性肌肉網路編碼與手勢執行相關的重要資訊的假設，顯著增強了手部手勢感知，並具有神經機器人系統和互動式機器人的潛在應用。

##### **RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation**
2408.02545v1 by Daniel Fleischer, Moshe Berchansky, Moshe Wasserblat, Peter Izsak

Implementing Retrieval-Augmented Generation (RAG) systems is inherently
complex, requiring deep understanding of data, use cases, and intricate design
decisions. Additionally, evaluating these systems presents significant
challenges, necessitating assessment of both retrieval accuracy and generative
quality through a multi-faceted approach. We introduce RAG Foundry, an
open-source framework for augmenting large language models for RAG use cases.
RAG Foundry integrates data creation, training, inference and evaluation into a
single workflow, facilitating the creation of data-augmented datasets for
training and evaluating large language models in RAG settings. This integration
enables rapid prototyping and experimentation with various RAG techniques,
allowing users to easily generate datasets and train RAG models using internal
or specialized knowledge sources. We demonstrate the framework effectiveness by
augmenting and fine-tuning Llama-3 and Phi-3 models with diverse RAG
configurations, showcasing consistent improvements across three
knowledge-intensive datasets. Code is released as open-source in
https://github.com/IntelLabs/RAGFoundry.

摘要：實作檢索增強生成（RAG）系統本質上很複雜，需要深入了解資料、使用案例和複雜的設計決策。此外，評估這些系統會帶來顯著的挑戰，需要透過多面向的方法評估檢索準確度和生成品質。我們介紹 RAG Foundry，一個用於擴充大型語言模型以進行 RAG 使用案例的開源架構。RAG Foundry 將資料建立、訓練、推論和評估整合到單一工作流程中，簡化了資料增強資料集的建立，以便在 RAG 設定中訓練和評估大型語言模型。這種整合能快速製作原型和使用各種 RAG 技術進行實驗，讓使用者能輕鬆使用內部或專業知識來源來產生資料集並訓練 RAG 模型。我們透過使用多樣化的 RAG 組態來擴充和微調 Llama-3 和 Phi-3 模型來展示架構的有效性，展示了在三個知識密集型資料集中的持續改進。程式碼已在 https://github.com/IntelLabs/RAGFoundry 中以開源方式釋出。

##### **Caution for the Environment: Multimodal Agents are Susceptible to Environmental Distractions**
2408.02544v1 by Xinbei Ma, Yiting Wang, Yao Yao, Tongxin Yuan, Aston Zhang, Zhuosheng Zhang, Hai Zhao

This paper investigates the faithfulness of multimodal large language model
(MLLM) agents in the graphical user interface (GUI) environment, aiming to
address the research question of whether multimodal GUI agents can be
distracted by environmental context. A general setting is proposed where both
the user and the agent are benign, and the environment, while not malicious,
contains unrelated content. A wide range of MLLMs are evaluated as GUI agents
using our simulated dataset, following three working patterns with different
levels of perception. Experimental results reveal that even the most powerful
models, whether generalist agents or specialist GUI agents, are susceptible to
distractions. While recent studies predominantly focus on the helpfulness
(i.e., action accuracy) of multimodal agents, our findings indicate that these
agents are prone to environmental distractions, resulting in unfaithful
behaviors. Furthermore, we switch to the adversarial perspective and implement
environment injection, demonstrating that such unfaithfulness can be exploited,
leading to unexpected risks.

摘要：本文探討了圖形使用者介面 (GUI) 環境中多模態大型語言模型 (MLLM) 代理的忠實度，旨在解決多模態 GUI 代理是否會受到環境背景影響的研究問題。本文提出了一般設定，其中使用者和代理都是良性的，而環境雖然沒有惡意，但包含不相關的內容。我們使用模擬資料集評估了廣泛的 MLLM 作為 GUI 代理，遵循具有不同感知層級的三種工作模式。實驗結果顯示，即使是最強大的模型（無論是通才代理還是專家 GUI 代理）都容易受到干擾。儘管最近的研究主要關注多模態代理的有用性（即動作準確性），但我們的研究結果表明，這些代理容易受到環境干擾，導致不忠實的行為。此外，我們轉向對抗觀點並實作環境注入，證明這種不忠實可以被利用，導致意外的風險。

##### **OneLove beyond the field -- A few-shot pipeline for topic and sentiment analysis during the FIFA World Cup in Qatar**
2408.02520v1 by Christoph Rauchegger, Sonja Mei Wang, Pieter Delobelle

The FIFA World Cup in Qatar was discussed extensively in the news and on
social media. Due to news reports with allegations of human rights violations,
there were calls to boycott it. Wearing a OneLove armband was part of a planned
protest activity. Controversy around the armband arose when FIFA threatened to
sanction captains who wear it. To understand what topics Twitter users Tweeted
about and what the opinion of German Twitter users was towards the OneLove
armband, we performed an analysis of German Tweets published during the World
Cup using in-context learning with LLMs. We validated the labels on human
annotations. We found that Twitter users initially discussed the armband's
impact, LGBT rights, and politics; after the ban, the conversation shifted
towards politics in sports in general, accompanied by a subtle shift in
sentiment towards neutrality. Our evaluation serves as a framework for future
research to explore the impact of sports activism and evolving public
sentiment. This is especially useful in settings where labeling datasets for
specific opinions is unfeasible, such as when events are unfolding.

摘要：卡達的 FIFA 世界盃在新聞和社群媒體上被廣泛討論。由於新聞報導中有人指控有侵犯人權的行為，因此有人呼籲抵制。佩戴 OneLove 臂章是計畫抗議活動的一部分。當 FIFA 威脅要制裁佩戴臂章的隊長時，圍繞臂章的爭議隨之而起。為了了解 Twitter 用戶推文的主題以及德國 Twitter 用戶對 OneLove 臂章的看法，我們使用 LLM 的語境學習對世界盃期間發布的德文推文進行了分析。我們驗證了人工標註的標籤。我們發現，Twitter 用戶最初討論的是臂章的影響、LGBT 權利和政治；在禁令之後，對話轉向體育中的政治，同時情緒微妙地轉向中立。我們的評估作為未來研究探索運動激進主義和公眾情緒演變的影響的框架。這在為特定意見標記資料集不可行的情況下特別有用，例如在事件正在展開時。

##### **UnifiedMLLM: Enabling Unified Representation for Multi-modal Multi-tasks With Large Language Model**
2408.02503v1 by Zhaowei Li, Wei Wang, YiQing Cai, Xu Qi, Pengyu Wang, Dong Zhang, Hang Song, Botian Jiang, Zhida Huang, Tao Wang

Significant advancements has recently been achieved in the field of
multi-modal large language models (MLLMs), demonstrating their remarkable
capabilities in understanding and reasoning across diverse tasks. However,
these models are often trained for specific tasks and rely on task-specific
input-output formats, limiting their applicability to a broader range of tasks.
This raises a fundamental question: Can we develop a unified approach to
represent and handle different multi-modal tasks to maximize the
generalizability of MLLMs? In this paper, we propose UnifiedMLLM, a
comprehensive model designed to represent various tasks using a unified
representation. Our model exhibits strong capabilities in comprehending the
implicit intent of user instructions and preforming reasoning. In addition to
generating textual responses, our model also outputs task tokens and grounding
tokens, serving as indicators of task types and task granularity. These outputs
are subsequently routed through the task router and directed to specific expert
models for task completion. To train our model, we construct a task-specific
dataset and an 100k multi-task dataset encompassing complex scenarios.
Employing a three-stage training strategy, we equip our model with robust
reasoning and task processing capabilities while preserving its generalization
capacity and knowledge reservoir. Extensive experiments showcase the impressive
performance of our unified representation approach across various tasks,
surpassing existing methodologies. Furthermore, our approach exhibits
exceptional scalability and generality. Our code, model, and dataset will be
available at \url{https://github.com/lzw-lzw/UnifiedMLLM}.

摘要：<paragraph>最近，多模态大型语言模型 (MLLM) 领域取得了重大进展，展示了它们在理解和推理各种任务方面的卓越能力。然而，这些模型通常针对特定任务进行训练，并依赖于特定任务的输入输出格式，这限制了它们在更广泛的任务范围内的适用性。这引发了一个基本问题：我们能否开发一种统一的方法来表示和处理不同的多模态任务，以最大化 MLLM 的泛化能力？在本文中，我们提出了 UnifiedMLLM，这是一个综合模型，旨在使用统一表示来表示各种任务。我们的模型在理解用户指令的隐含意图和进行推理方面表现出强大的能力。除了生成文本响应之外，我们的模型还输出任务标记和基础标记，作为任务类型和任务粒度的指标。这些输出随后通过任务路由器路由，并定向到特定专家模型以完成任务。为了训练我们的模型，我们构建了一个特定于任务的数据集和一个包含复杂场景的 100k 多任务数据集。采用三阶段训练策略，我们为我们的模型配备了强大的推理和任务处理能力，同时保留了它的泛化能力和知识储备。广泛的实验展示了我们的统一表示方法在各种任务中的出色表现，超越了现有方法。此外，我们的方法表现出卓越的可扩展性和通用性。我们的代码、模型和数据集将在 \url{https://github.com/lzw-lzw/UnifiedMLLM} 上提供。</paragraph>

##### **A First Look at License Compliance Capability of LLMs in Code Generation**
2408.02487v1 by Weiwei Xu, Kai Gao, Hao He, Minghui Zhou

Recent advances in Large Language Models (LLMs) have revolutionized code
generation, leading to widespread adoption of AI coding tools by developers.
However, LLMs can generate license-protected code without providing the
necessary license information, leading to potential intellectual property
violations during software production. This paper addresses the critical, yet
underexplored, issue of license compliance in LLM-generated code by
establishing a benchmark to evaluate the ability of LLMs to provide accurate
license information for their generated code. To establish this benchmark, we
conduct an empirical study to identify a reasonable standard for "striking
similarity" that excludes the possibility of independent creation, indicating a
copy relationship between the LLM output and certain open-source code. Based on
this standard, we propose an evaluation benchmark LiCoEval, to evaluate the
license compliance capabilities of LLMs. Using LiCoEval, we evaluate 14 popular
LLMs, finding that even top-performing LLMs produce a non-negligible proportion
(0.88% to 2.01%) of code strikingly similar to existing open-source
implementations. Notably, most LLMs fail to provide accurate license
information, particularly for code under copyleft licenses. These findings
underscore the urgent need to enhance LLM compliance capabilities in code
generation tasks. Our study provides a foundation for future research and
development to improve license compliance in AI-assisted software development,
contributing to both the protection of open-source software copyrights and the
mitigation of legal risks for LLM users.

摘要：<paragraph>大型語言模型 (LLM) 的近期進展徹底改變了程式碼生成，導致開發人員廣泛採用 AI 編碼工具。然而，LLM 可以生成受許可證保護的程式碼，而沒有提供必要的許可證資訊，這會在軟體製作過程中導致潛在的智慧財產權侵權。本文探討 LLM 生成的程式碼中許可證合規性的關鍵議題（但尚未充分探討），方法是建立基準來評估 LLM 為其生成的程式碼提供準確許可證資訊的能力。為了建立這個基準，我們進行實證研究，以找出「極度相似」的合理標準，排除獨立創作的可能性，表示 LLM 輸出與特定開源程式碼之間的複製關係。基於這個標準，我們提出評估基準 LiCoEval，以評估 LLM 的許可證合規能力。使用 LiCoEval，我們評估了 14 個流行的 LLM，發現即使效能最好的 LLM 仍會產生與現有開源實作極度相似的程式碼，比例不可忽略（0.88% 至 2.01%）。值得注意的是，大多數 LLM 無法提供準確的許可證資訊，特別是受 copyleft 許可證保護的程式碼。這些發現強調了在程式碼生成任務中增強 LLM 合規能力的迫切需求。我們的研究為未來的研究和開發奠定了基礎，以改善 AI 輔助軟體開發中的許可證合規性，有助於保護開源軟體的著作權，並減輕 LLM 使用者的法律風險。</paragraph>

##### **From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future**
2408.02479v1 by Haolin Jin, Linghan Huang, Haipeng Cai, Jun Yan, Bo Li, Huaming Chen

With the rise of large language models (LLMs), researchers are increasingly
exploring their applications in var ious vertical domains, such as software
engineering. LLMs have achieved remarkable success in areas including code
generation and vulnerability detection. However, they also exhibit numerous
limitations and shortcomings. LLM-based agents, a novel tech nology with the
potential for Artificial General Intelligence (AGI), combine LLMs as the core
for decision-making and action-taking, addressing some of the inherent
limitations of LLMs such as lack of autonomy and self-improvement. Despite
numerous studies and surveys exploring the possibility of using LLMs in
software engineering, it lacks a clear distinction between LLMs and LLM based
agents. It is still in its early stage for a unified standard and benchmarking
to qualify an LLM solution as an LLM-based agent in its domain. In this survey,
we broadly investigate the current practice and solutions for LLMs and
LLM-based agents for software engineering. In particular we summarise six key
topics: requirement engineering, code generation, autonomous decision-making,
software design, test generation, and software maintenance. We review and
differentiate the work of LLMs and LLM-based agents from these six topics,
examining their differences and similarities in tasks, benchmarks, and
evaluation metrics. Finally, we discuss the models and benchmarks used,
providing a comprehensive analysis of their applications and effectiveness in
software engineering. We anticipate this work will shed some lights on pushing
the boundaries of LLM-based agents in software engineering for future research.

摘要：<paragraph>隨著大型語言模型 (LLM) 的興起，研究人員正越來越探索它們在各種垂直領域的應用，例如軟體工程。LLM 在包括程式碼生成和漏洞偵測等領域取得了顯著的成功。然而，它們也表現出許多限制和缺點。基於 LLM 的代理是一種新穎的技術，具有具備人工通用智慧 (AGI) 的潛力，結合 LLM 作為決策制定和採取行動的核心，解決了 LLM 的一些固有限制，例如缺乏自主性和自我完善。儘管有許多研究和調查探索在軟體工程中使用 LLM 的可能性，但它缺乏 LLM 和基於 LLM 的代理之間的明確區別。對於統一標準和基準以使其域中的 LLM 解决方案有資格成為基於 LLM 的代理，它仍處於早期階段。在本次調查中，我們廣泛調查了 LLM 和基於 LLM 的軟體工程代理的當前實務和解決方案。特別是，我們總結了六個關鍵主題：需求工程、程式碼生成、自主決策制定、軟體設計、測試生成和軟體維護。我們回顧並區分了 LLM 和基於 LLM 的代理在這六個主題中的工作，檢視它們在任務、基準和評估指標上的差異和相似性。最後，我們討論了所使用的模型和基準，全面分析了它們在軟體工程中的應用和有效性。我們預期這項工作將為推動基於 LLM 的代理在軟體工程中的界限提供一些啟示，以利未來的研究。</paragraph>

##### **An investigation into the causes of race bias in AI-based cine CMR segmentation**
2408.02462v1 by Tiarna Lee, Esther Puyol-Anton, Bram Ruijsink, Sebastien Roujol, Theodore Barfoot, Shaheim Ogbomo-Harmitt, Miaojing Shi, Andrew P. King

Artificial intelligence (AI) methods are being used increasingly for the
automated segmentation of cine cardiac magnetic resonance (CMR) imaging.
However, these methods have been shown to be subject to race bias, i.e. they
exhibit different levels of performance for different races depending on the
(im)balance of the data used to train the AI model. In this paper we
investigate the source of this bias, seeking to understand its root cause(s) so
that it can be effectively mitigated. We perform a series of classification and
segmentation experiments on short-axis cine CMR images acquired from Black and
White subjects from the UK Biobank and apply AI interpretability methods to
understand the results. In the classification experiments, we found that race
can be predicted with high accuracy from the images alone, but less accurately
from ground truth segmentations, suggesting that the distributional shift
between races, which is often the cause of AI bias, is mostly image-based
rather than segmentation-based. The interpretability methods showed that most
attention in the classification models was focused on non-heart regions, such
as subcutaneous fat. Cropping the images tightly around the heart reduced
classification accuracy to around chance level. Similarly, race can be
predicted from the latent representations of a biased segmentation model,
suggesting that race information is encoded in the model. Cropping images
tightly around the heart reduced but did not eliminate segmentation bias. We
also investigate the influence of possible confounders on the bias observed.

摘要：人工智慧 (AI) 方法正日益用於自動分割心臟電影式磁振造影 (CMR) 影像。
然而，這些方法已被證明會受到種族偏見的影響，即根據用於訓練 AI 模型的資料的 (不) 平衡，它們對不同種族展現出不同層級的效能。在本文中，我們調查此偏見的來源，試圖了解其根本原因，以便能有效減輕它。我們對來自英國生物銀行的黑人和白人受試者所取得的短軸心臟電影式 CMR 影像執行一系列分類和分割實驗，並套用 AI 可解釋性方法來了解結果。在分類實驗中，我們發現僅從影像就能以高準確度預測種族，但從真實分割的準確度較低，這表示種族之間的分配轉移（通常是 AI 偏見的原因）主要是基於影像，而非基於分割。可解釋性方法顯示，分類模型中的大部分注意力都集中在非心臟區域，例如皮下脂肪。緊密裁剪影像以圍繞心臟會將分類準確度降低至接近隨機層級。同樣地，種族可以從有偏見的分割模型的潛在表示中預測，這表示種族資訊已編碼在模型中。緊密裁剪影像以圍繞心臟會降低分割偏見，但無法消除它。我們也調查可能混淆因子對所觀察到的偏見的影響。

##### **Enhancing Heterogeneous Knowledge Graph Completion with a Novel GAT-based Approach**
2408.02456v1 by Wanxu Wei, Yitong Song, Bin Yao

Knowledge graphs (KGs) play a vital role in enhancing search results and
recommendation systems. With the rapid increase in the size of the KGs, they
are becoming inaccuracy and incomplete. This problem can be solved by the
knowledge graph completion methods, of which graph attention network
(GAT)-based methods stand out since their superior performance. However,
existing GAT-based knowledge graph completion methods often suffer from
overfitting issues when dealing with heterogeneous knowledge graphs, primarily
due to the unbalanced number of samples. Additionally, these methods
demonstrate poor performance in predicting the tail (head) entity that shares
the same relation and head (tail) entity with others. To solve these problems,
we propose GATH, a novel GAT-based method designed for Heterogeneous KGs. GATH
incorporates two separate attention network modules that work synergistically
to predict the missing entities. We also introduce novel encoding and feature
transformation approaches, enabling the robust performance of GATH in scenarios
with imbalanced samples. Comprehensive experiments are conducted to evaluate
the GATH's performance. Compared with the existing SOTA GAT-based model on
Hits@10 and MRR metrics, our model improves performance by 5.2% and 5.2% on the
FB15K-237 dataset, and by 4.5% and 14.6% on the WN18RR dataset, respectively.

摘要：知識圖譜 (KG) 在提升搜尋結果和推薦系統中扮演著至關重要的角色。隨著 KG 規模的快速增長，它們正變得不準確且不完整。這個問題可以透過知識圖譜完成方法來解決，其中基於圖注意力網路 (GAT) 的方法因其卓越的效能而脫穎而出。然而，現有的基於 GAT 的知識圖譜完成方法在處理異質知識圖譜時，通常會遇到過度擬合的問題，這主要是由於樣本數不平衡所致。此外，這些方法在預測與他人共享相同關係和頭部 (尾部) 實體的尾部 (頭部) 實體時，表現不佳。為了解決這些問題，我們提出了 GATH，這是一種專為異質 KG 設計的創新 GAT 基礎方法。GATH 結合了兩個獨立的注意力網路模組，它們協同工作以預測缺失的實體。我們還引入了創新的編碼和特徵轉換方法，讓 GATH 在樣本不平衡的場景中能有穩健的表現。我們進行了全面的實驗來評估 GATH 的效能。與現有的 SOTA GAT 基礎模型在 Hits@10 和 MRR 指標上相比，我們的模型在 FB15K-237 資料集上分別提升了 5.2% 和 5.2% 的效能，在 WN18RR 資料集上分別提升了 4.5% 和 14.6%。

##### **Let Me Speak Freely? A Study on the Impact of Format Restrictions on Performance of Large Language Models**
2408.02442v1 by Zhi Rui Tam, Cheng-Kuang Wu, Yi-Lin Tsai, Chieh-Yen Lin, Hung-yi Lee, Yun-Nung Chen

Structured generation, the process of producing content in standardized
formats like JSON and XML, is widely utilized in real-world applications to
extract key output information from large language models (LLMs). This study
investigates whether such constraints on generation space impact LLMs'
abilities, including reasoning and domain knowledge comprehension.
Specifically, we evaluate LLMs' performance when restricted to adhere to
structured formats versus generating free-form responses across various common
tasks. Surprisingly, we observe a significant decline in LLMs' reasoning
abilities under format restrictions. Furthermore, we find that stricter format
constraints generally lead to greater performance degradation in reasoning
tasks.

摘要：結構化生成，即以 JSON 和 XML 等標準化格式製作內容的過程，廣泛用於實際應用中，從大型語言模型 (LLM) 中提取關鍵輸出資訊。本研究探討此類生成空間限制是否會影響 LLM 的能力，包括推理和領域知識理解。具體來說，我們評估 LLM 在受限於遵循結構化格式與在各種常見任務中產生自由形式回應時的表現。令人驚訝的是，我們觀察到 LLM 在格式限制下的推理能力顯著下降。此外，我們發現更嚴格的格式限制通常會導致推理任務的效能更差。

##### **Long Input Benchmark for Russian Analysis**
2408.02439v1 by Igor Churin, Murat Apishev, Maria Tikhonova, Denis Shevelev, Aydar Bulatov, Yuri Kuratov, Sergej Averkiev, Alena Fenogenova

Recent advancements in Natural Language Processing (NLP) have fostered the
development of Large Language Models (LLMs) that can solve an immense variety
of tasks. One of the key aspects of their application is their ability to work
with long text documents and to process long sequences of tokens. This has
created a demand for proper evaluation of long-context understanding. To
address this need for the Russian language, we propose LIBRA (Long Input
Benchmark for Russian Analysis), which comprises 21 adapted datasets to study
the LLM's abilities to understand long texts thoroughly. The tests are divided
into four complexity groups and allow the evaluation of models across various
context lengths ranging from 4k up to 128k tokens. We provide the open-source
datasets, codebase, and public leaderboard for LIBRA to guide forthcoming
research.

摘要：自然語言處理 (NLP) 的最新進展促進了大型語言模型 (LLM) 的發展，它能解決各種各樣的任務。其應用的一個關鍵方面是它們處理長文本文件和處理長序列代幣的能力。這對長語境理解的適當評估產生了需求。為了滿足俄語的需求，我們提出了 LIBRA（俄語分析長輸入基準），它包含 21 個適用的數據集，用於研究 LLM 全面理解長文本的能力。測試分為四個複雜度組，並允許評估模型在從 4k 到 128k 代幣的各種語境長度。我們提供 LIBRA 的開源數據集、代碼庫和公開排行榜，以指導後續研究。

##### **Infusing Emotions into Task-oriented Dialogue Systems: Understanding, Management, and Generation**
2408.02417v1 by Shutong Feng, Hsien-chin Lin, Christian Geishauser, Nurul Lubis, Carel van Niekerk, Michael Heck, Benjamin Ruppik, Renato Vukovic, Milica Gašić

Emotions are indispensable in human communication, but are often overlooked
in task-oriented dialogue (ToD) modelling, where the task success is the
primary focus. While existing works have explored user emotions or similar
concepts in some ToD tasks, none has so far included emotion modelling into a
fully-fledged ToD system nor conducted interaction with human or simulated
users. In this work, we incorporate emotion into the complete ToD processing
loop, involving understanding, management, and generation. To this end, we
extend the EmoWOZ dataset (Feng et al., 2022) with system affective behaviour
labels. Through interactive experimentation involving both simulated and human
users, we demonstrate that our proposed framework significantly enhances the
user's emotional experience as well as the task success.

摘要：情緒在人類溝通中不可或缺，但在以任務為導向的對話 (ToD) 建模中卻經常被忽略，而任務成功是主要焦點。雖然現有研究已探討使用者情緒或類似概念在某些 ToD 任務中，但目前尚未將情緒建模納入一個成熟的 ToD 系統，也未與人類或模擬使用者進行互動。在這項研究中，我們將情緒納入完整的 ToD 處理迴圈，包括理解、管理和產生。為此，我們透過系統情感行為標籤延伸 EmoWOZ 資料集 (Feng 等人，2022)。透過涉及模擬和人類使用者的互動式實驗，我們證明我們提出的架構大幅提升使用者的情緒體驗以及任務成功。

##### **Why Are My Prompts Leaked? Unraveling Prompt Extraction Threats in Customized Large Language Models**
2408.02416v1 by Zi Liang, Haibo Hu, Qingqing Ye, Yaxin Xiao, Haoyang Li

The drastic increase of large language models' (LLMs) parameters has led to a
new research direction of fine-tuning-free downstream customization by prompts,
i.e., task descriptions. While these prompt-based services (e.g. OpenAI's GPTs)
play an important role in many businesses, there has emerged growing concerns
about the prompt leakage, which undermines the intellectual properties of these
services and causes downstream attacks. In this paper, we analyze the
underlying mechanism of prompt leakage, which we refer to as prompt
memorization, and develop corresponding defending strategies. By exploring the
scaling laws in prompt extraction, we analyze key attributes that influence
prompt extraction, including model sizes, prompt lengths, as well as the types
of prompts. Then we propose two hypotheses that explain how LLMs expose their
prompts. The first is attributed to the perplexity, i.e. the familiarity of
LLMs to texts, whereas the second is based on the straightforward token
translation path in attention matrices. To defend against such threats, we
investigate whether alignments can undermine the extraction of prompts. We find
that current LLMs, even those with safety alignments like GPT-4, are highly
vulnerable to prompt extraction attacks, even under the most straightforward
user attacks. Therefore, we put forward several defense strategies with the
inspiration of our findings, which achieve 83.8\% and 71.0\% drop in the prompt
extraction rate for Llama2-7B and GPT-3.5, respectively. Source code is
avaliable at \url{https://github.com/liangzid/PromptExtractionEval}.

摘要：<paragraph>大型語言模型 (LLM) 參數的急劇增加，導致了提示符進行微調自由下游自訂的新研究方向，即任務描述。雖然這些基於提示符的服務（例如 OpenAI 的 GPT）在許多企業中扮演著重要的角色，但對於提示符洩漏的擔憂與日俱增，這會破壞這些服務的智慧財產權並導致下游攻擊。在本文中，我們分析了提示符洩漏的底層機制，我們稱之為提示符記憶，並制定了相應的防禦策略。通過探索提示符提取中的規模定律，我們分析了影響提示符提取的關鍵屬性，包括模型大小、提示符長度以及提示符類型。然後，我們提出了兩個假設來解釋 LLM 如何公開其提示符。第一個歸因於困惑，即 LLM 對文本的熟悉度，而第二個則基於注意力矩陣中的直接代幣轉換路徑。為了防禦此類威脅，我們研究了對齊是否會破壞提示符的提取。我們發現當前的 LLM，即使是那些具有安全對齊功能（例如 GPT-4）的 LLM，也極易受到提示符提取攻擊，即使是在最直接的使用者攻擊下也是如此。因此，我們根據我們的發現提出了幾種防禦策略，這些策略分別為 Llama2-7B 和 GPT-3.5 的提示符提取率降低了 83.8% 和 71.0%。原始碼可於\url{https://github.com/liangzid/PromptExtractionEval}取得。</paragraph>

##### **Multi-weather Cross-view Geo-localization Using Denoising Diffusion Models**
2408.02408v1 by Tongtong Feng, Qing Li, Xin Wang, Mingzi Wang, Guangyao Li, Wenwu Zhu

Cross-view geo-localization in GNSS-denied environments aims to determine an
unknown location by matching drone-view images with the correct geo-tagged
satellite-view images from a large gallery. Recent research shows that learning
discriminative image representations under specific weather conditions can
significantly enhance performance. However, the frequent occurrence of unseen
extreme weather conditions hinders progress. This paper introduces MCGF, a
Multi-weather Cross-view Geo-localization Framework designed to dynamically
adapt to unseen weather conditions. MCGF establishes a joint optimization
between image restoration and geo-localization using denoising diffusion
models. For image restoration, MCGF incorporates a shared encoder and a
lightweight restoration module to help the backbone eliminate weather-specific
information. For geo-localization, MCGF uses EVA-02 as a backbone for feature
extraction, with cross-entropy loss for training and cosine distance for
testing. Extensive experiments on University160k-WX demonstrate that MCGF
achieves competitive results for geo-localization in varying weather
conditions.

摘要：在 GNSS 拒絕的環境中進行跨視圖地理定位旨在通過將無人機視圖影像與來自大型圖庫的正確地理標記衛星視圖影像進行匹配來確定未知位置。最近的研究表明，在特定天氣條件下學習判別影像表徵可以顯著提高性能。然而，極端天氣條件的頻繁出現阻礙了進展。本文介紹了 MCGF，一個多天氣跨視圖地理定位框架，旨在動態適應未知天氣條件。MCGF 在影像修復和地理定位之間建立了聯合優化，使用去噪擴散模型。對於影像修復，MCGF 結合了一個共享編碼器和一個輕量級修復模組，以幫助主幹消除特定天氣資訊。對於地理定位，MCGF 使用 EVA-02 作為特徵提取的主幹，使用交叉熵損失進行訓練，使用餘弦距離進行測試。在 University160k-WX 上進行的大量實驗表明，MCGF 在不同的天氣條件下實現了地理定位的競爭結果。

##### **Enhancing AI-based Generation of Software Exploits with Contextual Information**
2408.02402v1 by Pietro Liguori, Cristina Improta, Roberto Natella, Bojan Cukic, Domenico Cotroneo

This practical experience report explores Neural Machine Translation (NMT)
models' capability to generate offensive security code from natural language
(NL) descriptions, highlighting the significance of contextual understanding
and its impact on model performance. Our study employs a dataset comprising
real shellcodes to evaluate the models across various scenarios, including
missing information, necessary context, and unnecessary context. The
experiments are designed to assess the models' resilience against incomplete
descriptions, their proficiency in leveraging context for enhanced accuracy,
and their ability to discern irrelevant information. The findings reveal that
the introduction of contextual data significantly improves performance.
However, the benefits of additional context diminish beyond a certain point,
indicating an optimal level of contextual information for model training.
Moreover, the models demonstrate an ability to filter out unnecessary context,
maintaining high levels of accuracy in the generation of offensive security
code. This study paves the way for future research on optimizing context use in
AI-driven code generation, particularly for applications requiring a high
degree of technical precision such as the generation of offensive code.

摘要：這份實務經驗報告探討神經機器翻譯 (NMT)
模型從自然語言 (NL) 說明產生攻擊性安全程式碼的能力，並強調脈絡理解的重要性
及其對模型效能的影響。我們的研究採用包含
實際 shellcode 的資料集來評估各種情境中的模型，包括
遺失資訊、必要的脈絡和不必要的脈絡。
這些實驗旨在評估模型對不完整
說明的韌性、利用脈絡以提高準確度的熟練程度，以及辨別不相關資訊的能力。研究結果顯示
脈絡資料的引入顯著改善效能。
然而，額外脈絡的好處在某個點之後會遞減，
表示模型訓練有脈絡資訊的最佳層級。
此外，這些模型展現出過濾不必要脈絡的能力，
在產生攻擊性安全
程式碼時維持高準確度。這項研究為未來在 AI 驅動程式碼產生中最佳化脈絡使用鋪路，
特別是對於需要高度技術精準度的應用，例如產生攻擊性程式碼。

##### **A Few-Shot Approach for Relation Extraction Domain Adaptation using Large Language Models**
2408.02377v1 by Vanni Zavarella, Juan Carlos Gamero-Salinas, Sergio Consoli

Knowledge graphs (KGs) have been successfully applied to the analysis of
complex scientific and technological domains, with automatic KG generation
methods typically building upon relation extraction models capturing
fine-grained relations between domain entities in text. While these relations
are fully applicable across scientific areas, existing models are trained on
few domain-specific datasets such as SciERC and do not perform well on new
target domains. In this paper, we experiment with leveraging in-context
learning capabilities of Large Language Models to perform schema-constrained
data annotation, collecting in-domain training instances for a
Transformer-based relation extraction model deployed on titles and abstracts of
research papers in the Architecture, Construction, Engineering and Operations
(AECO) domain. By assessing the performance gain with respect to a baseline
Deep Learning architecture trained on off-domain data, we show that by using a
few-shot learning strategy with structured prompts and only minimal expert
annotation the presented approach can potentially support domain adaptation of
a science KG generation model.

摘要：知識圖譜 (KG) 已成功應用於分析複雜的科學技術領域，自動 KG 生成方法通常建構於關係萃取模型上，捕捉文本中領域實體之間的細粒度關係。雖然這些關係完全適用於各科學領域，但現有模型是用 SciERC 等少數特定領域的資料集訓練，而且在新目標領域的表現不佳。在本論文中，我們嘗試利用大型語言模型的脈絡學習能力，執行受架構約束的資料標註，收集領域內訓練實例，用於部署在建築、營造、工程和營運 (AECO) 領域研究論文標題和摘要的基於 Transformer 的關係萃取模型。透過評估相對於在領域外資料上訓練的基準深度學習架構的效能提升，我們展示透過使用帶有結構化提示的少量學習策略，以及僅最少的專家標註，所提出的方法有可能支援科學 KG 生成模型的領域適應。

##### **Operationalizing Contextual Integrity in Privacy-Conscious Assistants**
2408.02373v1 by Sahra Ghalebikesabi, Eugene Bagdasaryan, Ren Yi, Itay Yona, Ilia Shumailov, Aneesh Pappu, Chongyang Shi, Laura Weidinger, Robert Stanforth, Leonard Berrada, Pushmeet Kohli, Po-Sen Huang, Borja Balle

Advanced AI assistants combine frontier LLMs and tool access to autonomously
perform complex tasks on behalf of users. While the helpfulness of such
assistants can increase dramatically with access to user information including
emails and documents, this raises privacy concerns about assistants sharing
inappropriate information with third parties without user supervision. To steer
information-sharing assistants to behave in accordance with privacy
expectations, we propose to operationalize $\textit{contextual integrity}$
(CI), a framework that equates privacy with the appropriate flow of information
in a given context. In particular, we design and evaluate a number of
strategies to steer assistants' information-sharing actions to be CI compliant.
Our evaluation is based on a novel form filling benchmark composed of synthetic
data and human annotations, and it reveals that prompting frontier LLMs to
perform CI-based reasoning yields strong results.

摘要：進階人工智慧助理結合前沿 LLM 與工具存取，以自動化執行複雜任務，代表使用者執行。雖然此類助理的便利性會隨著存取使用者資訊（包括電子郵件和文件）而大幅提升，但這也引發了隱私疑慮，擔心助理會在未經使用者監督的情況下，與第三方分享不適當的資訊。為了引導資訊共享助理，使其行為符合隱私期望，我們提議將「脈絡完整性」（CI）操作化，此架構將隱私與特定脈絡中適當的資訊流畫上等號。特別是，我們設計並評估多種策略，以引導助理的資訊共享行為，符合 CI 規範。我們的評估是基於由合成資料和人為註解組成的新穎表單填寫基準，結果顯示提示前沿 LLM 執行基於 CI 的推理，可產生強而有力的成果。

##### **Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought Decoding**
2408.02361v1 by Renato Vukovic, David Arps, Carel van Niekerk, Benjamin Matthias Ruppik, Hsien-Chin Lin, Michael Heck, Milica Gašić

State-of-the-art task-oriented dialogue systems typically rely on
task-specific ontologies for fulfilling user queries. The majority of
task-oriented dialogue data, such as customer service recordings, comes without
ontology and annotation. Such ontologies are normally built manually, limiting
the application of specialised systems. Dialogue ontology construction is an
approach for automating that process and typically consists of two steps: term
extraction and relation extraction. In this work, we focus on relation
extraction in a transfer learning set-up. To improve the generalisation, we
propose an extension to the decoding mechanism of large language models. We
adapt Chain-of-Thought (CoT) decoding, recently developed for reasoning
problems, to generative relation extraction. Here, we generate multiple
branches in the decoding space and select the relations based on a confidence
threshold. By constraining the decoding to ontology terms and relations, we aim
to decrease the risk of hallucination. We conduct extensive experimentation on
two widely used datasets and find improvements in performance on target
ontology for source fine-tuned and one-shot prompted large language models.

摘要：最先进的任务导向对话系统通常依赖于特定任务的本体来满足用户查询。大多数面向任务的对话数据（例如客服录音）都没有本体和注释。此类本体通常是手动构建的，限制了专门系统的应用。对话本体构建是一种自动化该过程的方法，通常包括两个步骤：术语提取和关系提取。在这项工作中，我们专注于转移学习设置中的关系提取。为了提高泛化性，我们提出了对大语言模型解码机制的扩展。我们改编了最近为推理问题开发的思想链 (CoT) 解码，用于生成关系提取。在这里，我们在解码空间中生成多个分支，并根据置信度阈值选择关系。通过将解码限制在本体术语和关系上，我们旨在降低出现幻觉的风险。我们在两个广泛使用的数据集上进行了广泛的实验，发现针对源微调和单次提示的大语言模型，目标本体的性能有所提高。

##### **Active Sensing of Knee Osteoarthritis Progression with Reinforcement Learning**
2408.02349v1 by Khanh Nguyen, Huy Hoang Nguyen, Egor Panfilov, Aleksei Tiulpin

Osteoarthritis (OA) is the most common musculoskeletal disease, which has no
cure. Knee OA (KOA) is one of the highest causes of disability worldwide, and
it costs billions of United States dollars to the global community. Prediction
of KOA progression has been of high interest to the community for years, as it
can advance treatment development through more efficient clinical trials and
improve patient outcomes through more efficient healthcare utilization.
Existing approaches for predicting KOA, however, are predominantly static, i.e.
consider data from a single time point to predict progression many years into
the future, and knee level, i.e. consider progression in a single joint only.
Due to these and related reasons, these methods fail to deliver the level of
predictive performance, which is sufficient to result in cost savings and
better patient outcomes. Collecting extensive data from all patients on a
regular basis could address the issue, but it is limited by the high cost at a
population level. In this work, we propose to go beyond static prediction
models in OA, and bring a novel Active Sensing (AS) approach, designed to
dynamically follow up patients with the objective of maximizing the number of
informative data acquisitions, while minimizing their total cost over a period
of time. Our approach is based on Reinforcement Learning (RL), and it leverages
a novel reward function designed specifically for AS of disease progression in
more than one part of a human body. Our method is end-to-end, relies on
multi-modal Deep Learning, and requires no human input at inference time.
Throughout an exhaustive experimental evaluation, we show that using RL can
provide a higher monetary benefit when compared to state-of-the-art baselines.

摘要：骨關節炎 (OA) 是一種最常見的肌肉骨骼疾病，目前尚無藥可醫。膝關節骨關節炎 (KOA) 是全球殘疾的首要原因之一，並使全球社會損失數十億美元。多年來，預測 KOA 的進展一直是社會關注的重點，因為它可以透過更有效的臨床試驗推進治療的發展，並透過更有效率的醫療保健利用來改善患者的預後。然而，現有的 KOA 預測方法主要都是靜態的，也就是說，僅考慮單一時間點的數據來預測未來多年的進展，而且是膝蓋層面的，也就是說，僅考慮單一關節的進展。由於這些原因和其他相關原因，這些方法無法提供足夠的預測效能，以致於無法節省成本並改善患者的預後。定期從所有患者身上收集廣泛的數據可以解決這個問題，但這會受到人口層級的高成本所限制。在這項工作中，我們建議超越 OA 中的靜態預測模型，並提出一個創新的主動感測 (AS) 方法，旨在動態追蹤患者，目標是最大化具有資訊性的數據擷取次數，同時在一段時間內將其總成本降至最低。我們的做法是基於強化學習 (RL)，並利用專門為人類身體多個部位的疾病進展的 AS 所設計的新型回饋函數。我們的做法是端到端的，依賴於多模態深度學習，並且在推論時間不需要人工輸入。在詳盡的實驗評估中，我們表明與最先進的基準相比，使用 RL 可以提供更高的金錢效益。

##### **An approach to optimize inference of the DIART speaker diarization pipeline**
2408.02341v1 by Roman Aperdannier, Sigurd Schacht, Alexander Piazza

Speaker diarization answers the question "who spoke when" for an audio file.
In some diarization scenarios, low latency is required for transcription.
Speaker diarization with low latency is referred to as online speaker
diarization. The DIART pipeline is an online speaker diarization system. It
consists of a segmentation and an embedding model. The embedding model has the
largest share of the overall latency. The aim of this paper is to optimize the
inference latency of the DIART pipeline. Different inference optimization
methods such as knowledge distilation, pruning, quantization and layer fusion
are applied to the embedding model of the pipeline. It turns out that knowledge
distillation optimizes the latency, but has a negative effect on the accuracy.
Quantization and layer fusion also have a positive influence on the latency
without worsening the accuracy. Pruning, on the other hand, does not improve
latency.

摘要：說話者日記化回答音訊檔案的「誰在何時說話」問題。
在某些日記化情境中，轉錄需要低延遲。
低延遲的說話者日記化稱為線上說話者日記化。DIART 管線是一個線上說話者日記化系統。它
包含一個分段和一個嵌入模型。嵌入模型在整體延遲中佔有最大的份額。本文的目的是最佳化
DIART 管線的推論延遲。不同的推論最佳化方法，例如知識蒸餾、剪枝、量化和層融合
應用於管線的嵌入模型。結果發現知識蒸餾最佳化延遲，但對準確度有負面影響。
量化和層融合也對延遲有正向影響，且不會惡化準確度。另一方面，剪枝並未改善
延遲。

##### **Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction**
2408.02337v1 by Albert Sawczyn, Katsiaryna Viarenich, Konrad Wojtasik, Aleksandra Domogała, Marcin Oleksy, Maciej Piasecki, Tomasz Kajdanowicz

Advancements in AI and natural language processing have revolutionized
machine-human language interactions, with question answering (QA) systems
playing a pivotal role. The knowledge base question answering (KBQA) task,
utilizing structured knowledge graphs (KG), allows for handling extensive
knowledge-intensive questions. However, a significant gap exists in KBQA
datasets, especially for low-resource languages. Many existing construction
pipelines for these datasets are outdated and inefficient in human labor, and
modern assisting tools like Large Language Models (LLM) are not utilized to
reduce the workload. To address this, we have designed and implemented a
modern, semi-automated approach for creating datasets, encompassing tasks such
as KBQA, Machine Reading Comprehension (MRC), and Information Retrieval (IR),
tailored explicitly for low-resource environments. We executed this pipeline
and introduced the PUGG dataset, the first Polish KBQA dataset, and novel
datasets for MRC and IR. Additionally, we provide a comprehensive
implementation, insightful findings, detailed statistics, and evaluation of
baseline models.

摘要：人工智能和自然語言處理的進展徹底改變了機器與人類的語言互動，其中問答 (QA) 系統扮演了關鍵角色。知識庫問答 (KBQA) 任務利用結構化的知識圖譜 (KG)，可以處理大量的知識密集型問題。然而，KBQA 資料集存在著顯著的差距，特別是對於低資源語言。許多現有的這些資料集建構管道已經過時且在人力上效率低下，而像大型語言模型 (LLM) 這樣的現代輔助工具並未被用於減少工作負載。為了解決這個問題，我們設計並實作了一種現代的半自動化方法來建立資料集，涵蓋了專門針對低資源環境量身打造的任務，例如 KBQA、機器閱讀理解 (MRC) 和資訊檢索 (IR)。我們執行了這個管道並引入了 PUGG 資料集，這是第一個波蘭 KBQA 資料集，以及 MRC 和 IR 的新穎資料集。此外，我們提供了全面的實作、有見地的發現、詳細的統計資料和基準模型的評估。

##### **SNFinLLM: Systematic and Nuanced Financial Domain Adaptation of Chinese Large Language Models**
2408.02302v1 by Shujuan Zhao, Lingfeng Qiao, Kangyang Luo, Qian-Wen Zhang, Junru Lu, Di Yin

Large language models (LLMs) have become powerful tools for advancing natural
language processing applications in the financial industry. However, existing
financial LLMs often face challenges such as hallucinations or superficial
parameter training, resulting in suboptimal performance, particularly in
financial computing and machine reading comprehension (MRC). To address these
issues, we propose a novel large language model specifically designed for the
Chinese financial domain, named SNFinLLM. SNFinLLM excels in domain-specific
tasks such as answering questions, summarizing financial research reports,
analyzing sentiment, and executing financial calculations. We then perform the
supervised fine-tuning (SFT) to enhance the model's proficiency across various
financial domains. Specifically, we gather extensive financial data and create
a high-quality instruction dataset composed of news articles, professional
papers, and research reports of finance domain. Utilizing both domain-specific
and general datasets, we proceed with continuous pre-training on an established
open-source base model, resulting in SNFinLLM-base. Following this, we engage
in supervised fine-tuning (SFT) to bolster the model's capability across
multiple financial tasks. Crucially, we employ a straightforward Direct
Preference Optimization (DPO) method to better align the model with human
preferences. Extensive experiments conducted on finance benchmarks and our
evaluation dataset demonstrate that SNFinLLM markedly outperforms other
state-of-the-art financial language models. For more details, check out our
demo video here: https://www.youtube.com/watch?v=GYT-65HZwus.

摘要：大型語言模型 (LLM) 已成為推動金融業自然語言處理應用程式的強大工具。然而，現有的金融 LLM 經常面臨幻覺或表面參數訓練等挑戰，導致次佳效能，特別是在金融運算和機器閱讀理解 (MRC) 中。為了解決這些問題，我們提出了一個專門為中文金融領域設計的新型大型語言模型，稱為 SNFinLLM。SNFinLLM 在特定領域的任務中表現出色，例如回答問題、總結財務研究報告、分析情緒和執行財務計算。然後，我們執行監督微調 (SFT) 以增強模型在各種金融領域的熟練度。具體來說，我們收集廣泛的財務數據，並建立一個由新聞文章、專業論文和金融領域研究報告組成的高品質指令數據集。利用特定領域和一般數據集，我們繼續在已建立的開源基礎模型上進行持續預訓練，產生 SNFinLLM-base。在此之後，我們進行監督微調 (SFT) 以加強模型在多項財務任務中的能力。至關重要的是，我們採用直接偏好最佳化 (DPO) 方法，以更好地將模型與人類偏好保持一致。在金融基準和我們的評估數據集上進行的廣泛實驗表明，SNFinLLM 明顯優於其他最先進的金融語言模型。有關更多詳細資訊，請在此處查看我們的示範影片：https://www.youtube.com/watch?v=GYT-65HZwus。

##### **Generalized Gaussian Temporal Difference Error For Uncertainty-aware Reinforcement Learning**
2408.02295v1 by Seyeon Kim, Joonhun Lee, Namhoon Cho, Sungjun Han, Seungeon Baek

Conventional uncertainty-aware temporal difference (TD) learning methods
often rely on simplistic assumptions, typically including a zero-mean Gaussian
distribution for TD errors. Such oversimplification can lead to inaccurate
error representations and compromised uncertainty estimation. In this paper, we
introduce a novel framework for generalized Gaussian error modeling in deep
reinforcement learning, applicable to both discrete and continuous control
settings. Our framework enhances the flexibility of error distribution modeling
by incorporating higher-order moments, particularly kurtosis, thereby improving
the estimation and mitigation of data-dependent noise, i.e., aleatoric
uncertainty. We examine the influence of the shape parameter of the generalized
Gaussian distribution (GGD) on aleatoric uncertainty and provide a closed-form
expression that demonstrates an inverse relationship between uncertainty and
the shape parameter. Additionally, we propose a theoretically grounded
weighting scheme to fully leverage the GGD. To address epistemic uncertainty,
we enhance the batch inverse variance weighting by incorporating bias reduction
and kurtosis considerations, resulting in improved robustness. Extensive
experimental evaluations using policy gradient algorithms demonstrate the
consistent efficacy of our method, showcasing significant performance
improvements.

摘要：傳統的考量不確定性的時間差分 (TD) 學習方法
通常依賴於簡化的假設，通常包括 TD 誤差的零均值高斯分布。這種過度簡化可能導致不準確的
誤差表示和不佳的不確定性估計。在本文中，我們介紹了一個用於深度強化學習中廣義高斯誤差建模的新框架，適用於離散和連續控制設置。我們的框架通過納入高階矩（特別是峰度）來增強誤差分佈建模的靈活性，從而改進對數據依賴性噪聲（即隨機不確定性）的估計和緩解。我們探討了廣義高斯分佈 (GGD) 的形狀參數對隨機不確定性的影響，並提供了一個閉合形式的表達式，證明了不確定性和形狀參數之間的反比關係。此外，我們提出了一個理論依據的加權方案，以充分利用 GGD。為了應對認識論不確定性，我們通過納入偏差減少和峰度考量來增強批次逆變異加權，從而提高魯棒性。使用策略梯度演算法進行的廣泛實驗評估證明了我們方法的一致有效性，展示了顯著的性能改進。

##### **Decoupled Vocabulary Learning Enables Zero-Shot Translation from Unseen Languages**
2408.02290v1 by Carlos Mullov, Ngoc-Quan Pham, Alexander Waibel

Multilingual neural machine translation systems learn to map sentences of
different languages into a common representation space. Intuitively, with a
growing number of seen languages the encoder sentence representation grows more
flexible and easily adaptable to new languages. In this work, we test this
hypothesis by zero-shot translating from unseen languages. To deal with unknown
vocabularies from unknown languages we propose a setup where we decouple
learning of vocabulary and syntax, i.e. for each language we learn word
representations in a separate step (using cross-lingual word embeddings), and
then train to translate while keeping those word representations frozen. We
demonstrate that this setup enables zero-shot translation from entirely unseen
languages. Zero-shot translating with a model trained on Germanic and Romance
languages we achieve scores of 42.6 BLEU for Portuguese-English and 20.7 BLEU
for Russian-English on TED domain. We explore how this zero-shot translation
capability develops with varying number of languages seen by the encoder.
Lastly, we explore the effectiveness of our decoupled learning strategy for
unsupervised machine translation. By exploiting our model's zero-shot
translation capability for iterative back-translation we attain near parity
with a supervised setting.

摘要：多語言神經機器翻譯系統會學習將不同語言的句子對應到一個共同的表示空間中。直覺上，隨著所見語言數量的增加，編碼器句子表示會變得更靈活，且更容易適應新的語言。在這項研究中，我們透過從未見過的語言進行零次學習翻譯來測試這個假設。為了處理來自未知語言的未知詞彙，我們提出一個設定，其中我們將詞彙和語法的學習分開，也就是說，對於每種語言，我們在一個獨立的步驟中學習詞彙表示（使用跨語言詞彙嵌入），然後在保持這些詞彙表示凍結的狀態下進行翻譯訓練。我們展示這個設定能從完全未見過的語言進行零次學習翻譯。使用在日耳曼語和羅曼語上訓練的模型進行零次學習翻譯，我們在 TED 領域上獲得了葡萄牙語到英語的 42.6 BLEU 分數，以及俄語到英語的 20.7 BLEU 分數。我們探討了這個零次學習翻譯能力如何隨著編碼器所見語言數量的變化而發展。最後，我們探討了我們解耦學習策略對於無監督機器翻譯的有效性。透過利用我們模型的零次學習翻譯能力進行反覆回譯，我們在監督式設定中獲得了接近相等的效果。

##### **Spin glass model of in-context learning**
2408.02288v1 by Yuhao Li, Ruoran Bai, Haiping Huang

Large language models show a surprising in-context learning ability -- being
able to use a prompt to form a prediction for a query, yet without additional
training, in stark contrast to old-fashioned supervised learning. Providing a
mechanistic interpretation and linking the empirical phenomenon to physics are
thus challenging and remain unsolved. We study a simple yet expressive
transformer with linear attention, and map this structure to a spin glass model
with real-valued spins, where the couplings and fields explain the intrinsic
disorder in data. The spin glass model explains how the weight parameters
interact with each other during pre-training, and most importantly why an
unseen function can be predicted by providing only a prompt yet without
training. Our theory reveals that for single instance learning, increasing the
task diversity leads to the emergence of the in-context learning, by allowing
the Boltzmann distribution to converge to a unique correct solution of weight
parameters. Therefore the pre-trained transformer displays a prediction power
in a novel prompt setting. The proposed spin glass model thus establishes a
foundation to understand the empirical success of large language models.

摘要：大型語言模型展現出令人驚訝的脈絡學習能力——能夠使用提示為查詢形成預測，但無需額外訓練，這與傳統的監督式學習形成鮮明對比。因此，提供機械論解釋並將經驗現象與物理聯繫起來具有挑戰性，且仍未解決。我們研究了一個簡單但富有表現力的線性注意力Transformer，並將此結構映射到一個具有實值自旋的自旋玻璃模型，其中耦合和場解釋了數據中的內在無序。自旋玻璃模型解釋了權重參數在預訓練期間如何相互作用，最重要的是為什麼僅通過提供提示而無需訓練就可以預測一個未見函數。我們的理論揭示，對於單例學習，增加任務多樣性會導致脈絡學習的出現，通過允許玻爾茲曼分佈收斂於權重參數的唯一正確解。因此，預訓練的Transformer在新的提示設置中顯示出預測能力。因此，所提出的自旋玻璃模型為理解大型語言模型的經驗成功奠定了基礎。

##### **Hardware Aware Ensemble Selection for Balancing Predictive Accuracy and Cost**
2408.02280v1 by Jannis Maier, Felix Möller, Lennart Purucker

Automated Machine Learning (AutoML) significantly simplifies the deployment
of machine learning models by automating tasks from data preprocessing to model
selection to ensembling. AutoML systems for tabular data often employ post hoc
ensembling, where multiple models are combined to improve predictive accuracy.
This typically results in longer inference times, a major limitation in
practical deployments. Addressing this, we introduce a hardware-aware ensemble
selection approach that integrates inference time into post hoc ensembling. By
leveraging an existing framework for ensemble selection with quality diversity
optimization, our method evaluates ensemble candidates for their predictive
accuracy and hardware efficiency. This dual focus allows for a balanced
consideration of accuracy and operational efficiency. Thus, our approach
enables practitioners to choose from a Pareto front of accurate and efficient
ensembles. Our evaluation using 83 classification datasets shows that our
approach sustains competitive accuracy and can significantly improve ensembles'
operational efficiency. The results of this study provide a foundation for
extending these principles to additional hardware constraints, setting the
stage for the development of more resource-efficient AutoML systems.

摘要：自動機器學習 (AutoML) 透過自動化從資料前處理到模型選擇再到集成等任務，大幅簡化機器學習模型的部署。用於表格資料的 AutoML 系統通常採用事後集成，其中結合多個模型以提升預測準確度。這通常會導致較長的推論時間，這是實務部署的一大限制。為了解決這個問題，我們引入一個硬體感知集成選擇方法，將推論時間整合到事後集成中。透過利用現有的集成選擇架構，並結合品質多樣性最佳化，我們的模型會評估集成候選者的預測準確度和硬體效率。這種雙重關注允許平衡考量準確度和運作效率。因此，我們的模型讓實務人員能夠從準確且有效率的集成中選擇帕雷托前緣。我們使用 83 個分類資料集進行評估，結果顯示我們的模型能維持競爭力的準確度，並能顯著提升集成運作效率。這項研究的結果提供了基礎，可以用來將這些原則延伸到其他硬體限制，為開發更具資源效率的 AutoML 系統奠定基礎。

##### **DRFormer: Multi-Scale Transformer Utilizing Diverse Receptive Fields for Long Time-Series Forecasting**
2408.02279v1 by Ruixin Ding, Yuqi Chen, Yu-Ting Lan, Wei Zhang

Long-term time series forecasting (LTSF) has been widely applied in finance,
traffic prediction, and other domains. Recently, patch-based transformers have
emerged as a promising approach, segmenting data into sub-level patches that
serve as input tokens. However, existing methods mostly rely on predetermined
patch lengths, necessitating expert knowledge and posing challenges in
capturing diverse characteristics across various scales. Moreover, time series
data exhibit diverse variations and fluctuations across different temporal
scales, which traditional approaches struggle to model effectively. In this
paper, we propose a dynamic tokenizer with a dynamic sparse learning algorithm
to capture diverse receptive fields and sparse patterns of time series data. In
order to build hierarchical receptive fields, we develop a multi-scale
Transformer model, coupled with multi-scale sequence extraction, capable of
capturing multi-resolution features. Additionally, we introduce a group-aware
rotary position encoding technique to enhance intra- and inter-group position
awareness among representations across different temporal scales. Our proposed
model, named DRFormer, is evaluated on various real-world datasets, and
experimental results demonstrate its superiority compared to existing methods.
Our code is available at: https://github.com/ruixindingECNU/DRFormer.

摘要：長期時間序列預測 (LTSF) 已廣泛應用於金融、交通預測和其他領域。最近，基於 patch 的 Transformer 已成為一種有前景的方法，將資料分割成子層級 patch，作為輸入 token。然而，現有方法大多依賴於預先確定的 patch 長度，需要專家知識，並在擷取各種規模的不同特徵時構成挑戰。此外，時間序列資料在不同的時間尺度上表現出不同的變化和波動，傳統方法難以有效建模。在本文中，我們提出一個具有動態稀疏學習演算法的動態 token，以擷取時間序列資料的不同感受野和稀疏模式。為了建立分層感受野，我們開發了一個多尺度 Transformer 模型，結合多尺度序列提取，能夠擷取多解析度特徵。此外，我們引入了一個群組感知旋轉位置編碼技術，以增強不同時間尺度上表示之間的組內和組間位置感知。我們提出的模型，稱為 DRFormer，在各種真實世界資料集上進行評估，實驗結果證明了它優於現有方法。我們的程式碼可在 https://github.com/ruixindingECNU/DRFormer 獲得。

##### **Geometric Algebra Meets Large Language Models: Instruction-Based Transformations of Separate Meshes in 3D, Interactive and Controllable Scenes**
2408.02275v1 by Dimitris Angelis, Prodromos Kolyvakis, Manos Kamarianakis, George Papagiannakis

This paper introduces a novel integration of Large Language Models (LLMs)
with Conformal Geometric Algebra (CGA) to revolutionize controllable 3D scene
editing, particularly for object repositioning tasks, which traditionally
requires intricate manual processes and specialized expertise. These
conventional methods typically suffer from reliance on large training datasets
or lack a formalized language for precise edits. Utilizing CGA as a robust
formal language, our system, shenlong, precisely models spatial transformations
necessary for accurate object repositioning. Leveraging the zero-shot learning
capabilities of pre-trained LLMs, shenlong translates natural language
instructions into CGA operations which are then applied to the scene,
facilitating exact spatial transformations within 3D scenes without the need
for specialized pre-training. Implemented in a realistic simulation
environment, shenlong ensures compatibility with existing graphics pipelines.
To accurately assess the impact of CGA, we benchmark against robust Euclidean
Space baselines, evaluating both latency and accuracy. Comparative performance
evaluations indicate that shenlong significantly reduces LLM response times by
16% and boosts success rates by 9.6% on average compared to the traditional
methods. Notably, shenlong achieves a 100% perfect success rate in common
practical queries, a benchmark where other systems fall short. These
advancements underscore shenlong's potential to democratize 3D scene editing,
enhancing accessibility and fostering innovation across sectors such as
education, digital entertainment, and virtual reality.

摘要：本文介紹大語言模型 (LLM) 與共形幾何代數 (CGA) 的創新整合，以革新可控 3D 場景編輯，特別是物件重新定位任務，這種任務傳統上需要複雜的手動處理和專業知識。這些傳統方法通常仰賴大型訓練資料集，或缺乏精確編輯的正式語言。我們的系統 Shenlong 利用 CGA 作為強健的正式語言，精確建模物件重新定位所需的空間轉換。Shenlong 透過利用預先訓練 LLM 的零次學習能力，將自然語言指令轉換為 CGA 運算，然後將這些運算套用到場景中，在 3D 場景中促成精確的空間轉換，而無需專門的預先訓練。Shenlong 在逼真的模擬環境中實作，確保與現有圖形管線相容。為了準確評估 CGA 的影響，我們針對強健的歐幾里得空間基準進行基準測試，評估延遲和準確度。比較效能評估顯示，與傳統方法相比，Shenlong 將 LLM 回應時間顯著降低 16%，並將成功率平均提升 9.6%。值得注意的是，Shenlong 在常見的實用查詢中達到 100% 的完美成功率，這是其他系統無法達到的基準。這些進展突顯了 Shenlong 在民主化 3D 場景編輯方面的潛力，增強了可及性，並促進了教育、數位娛樂和虛擬實境等領域的創新。

##### **COM Kitchens: An Unedited Overhead-view Video Dataset as a Vision-Language Benchmark**
2408.02272v1 by Koki Maeda, Tosho Hirasawa, Atsushi Hashimoto, Jun Harashima, Leszek Rybicki, Yusuke Fukasawa, Yoshitaka Ushiku

Procedural video understanding is gaining attention in the vision and
language community. Deep learning-based video analysis requires extensive data.
Consequently, existing works often use web videos as training resources, making
it challenging to query instructional contents from raw video observations. To
address this issue, we propose a new dataset, COM Kitchens. The dataset
consists of unedited overhead-view videos captured by smartphones, in which
participants performed food preparation based on given recipes. Fixed-viewpoint
video datasets often lack environmental diversity due to high camera setup
costs. We used modern wide-angle smartphone lenses to cover cooking counters
from sink to cooktop in an overhead view, capturing activity without in-person
assistance. With this setup, we collected a diverse dataset by distributing
smartphones to participants. With this dataset, we propose the novel
video-to-text retrieval task Online Recipe Retrieval (OnRR) and new video
captioning domain Dense Video Captioning on unedited Overhead-View videos
(DVC-OV). Our experiments verified the capabilities and limitations of current
web-video-based SOTA methods in handling these tasks.

摘要：程序视频理解在视觉和语言社区中备受关注。基于深度学习的视频分析需要大量数据。因此，现有工作通常使用网络视频作为训练资源，这使得从原始视频观察中查询教学内容具有挑战性。为了解决这个问题，我们提出了一个新的数据集，COM Kitchens。该数据集由智能手机拍摄的未经编辑的俯视图视频组成，其中参与者根据给定的食谱进行食物准备。固定视点视频数据集由于摄像机设置成本高，通常缺乏环境多样性。我们使用现代广角智能手机镜头从水槽到炉灶以俯视图覆盖烹饪台，在没有人员协助的情况下捕捉活动。通过这种设置，我们通过向参与者分发智能手机收集了一个多样化的数据集。使用此数据集，我们提出了新颖的视频到文本检索任务在线食谱检索（OnRR）和新的视频字幕域未编辑俯视图视频上的密集视频字幕（DVC-OV）。我们的实验验证了当前基于网络视频的 SOTA 方法在处理这些任务时的能力和局限性。

##### **StyEmp: Stylizing Empathetic Response Generation via Multi-Grained Prefix Encoder and Personality Reinforcement**
2408.02271v1 by Yahui Fu, Chenhui Chu, Tatsuya Kawahara

Recent approaches for empathetic response generation mainly focus on
emotional resonance and user understanding, without considering the system's
personality. Consistent personality is evident in real human expression and is
important for creating trustworthy systems. To address this problem, we propose
StyEmp, which aims to stylize the empathetic response generation with a
consistent personality. Specifically, it incorporates a multi-grained prefix
mechanism designed to capture the intricate relationship between a system's
personality and its empathetic expressions. Furthermore, we introduce a
personality reinforcement module that leverages contrastive learning to
calibrate the generation model, ensuring that responses are both empathetic and
reflective of a distinct personality. Automatic and human evaluations on the
EMPATHETICDIALOGUES benchmark show that StyEmp outperforms competitive
baselines in terms of both empathy and personality expressions.

摘要：近期的同理心回應生成方法主要著重於情緒共鳴和使用者理解，而不考慮系統的人格特質。一致的人格特質在真實的人類表達中很明顯，而且對於建立值得信賴的系統來說很重要。為了解決這個問題，我們提出 StyEmp，其目標是透過一致的人格特質來調整同理心回應的生成。具體來說，它結合了一個多層級的前置機制，旨在捕捉系統人格特質與其同理心表達之間的複雜關係。此外，我們還導入了一個人格強化模組，利用對比學習來校準生成模型，確保回應既具有同理心，又能反映出鮮明的人格特質。在 EMPATHETICDIALOGUES 基準上的自動和人工評估顯示，StyEmp 在同理心和人格表達方面都優於競爭基準。

##### **Advancing Post-OCR Correction: A Comparative Study of Synthetic Data**
2408.02253v1 by Shuhao Guan, Derek Greene

This paper explores the application of synthetic data in the post-OCR domain
on multiple fronts by conducting experiments to assess the impact of data
volume, augmentation, and synthetic data generation methods on model
performance. Furthermore, we introduce a novel algorithm that leverages
computer vision feature detection algorithms to calculate glyph similarity for
constructing post-OCR synthetic data. Through experiments conducted across a
variety of languages, including several low-resource ones, we demonstrate that
models like ByT5 can significantly reduce Character Error Rates (CER) without
the need for manually annotated data, and our proposed synthetic data
generation method shows advantages over traditional methods, particularly in
low-resource languages.

摘要：本文探討合成資料在後 OCR 領域的應用，並透過實驗評估資料量、擴充和合成資料生成方法對模型效能的影響。此外，我們提出了一種新演算法，利用電腦視覺特徵偵測演算法計算字形相似度，以建構後 OCR 合成資料。透過在多種語言（包括數種低資源語言）進行的實驗，我們證明像 ByT5 這類模型可以大幅降低字元錯誤率 (CER)，而無需人工標註資料，而我們提出的合成資料生成方法顯示出優於傳統方法的優勢，特別是在低資源語言中。

##### **ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems**
2408.02248v1 by Andrew Zhu, Liam Dugan, Chris Callison-Burch

Recently, there has been increasing interest in using Large Language Models
(LLMs) to construct complex multi-agent systems to perform tasks such as
compiling literature reviews, drafting consumer reports, and planning
vacations. Many tools and libraries exist for helping create such systems,
however none support recursive multi-agent systems -- where the models
themselves flexibly decide when to delegate tasks and how to organize their
delegation structure. In this work, we introduce ReDel: a toolkit for recursive
multi-agent systems that supports custom tool-use, delegation schemes,
event-based logging, and interactive replay in an easy-to-use web interface. We
show that, using ReDel, we are able to achieve significant performance gains on
agentic benchmarks and easily identify potential areas of improvements through
the visualization and debugging tools. Our code, documentation, and PyPI
package are open-source and free to use under the MIT license.

摘要：最近，人们越来越热衷于使用大型语言模型 (LLM) 来构建复杂的多主体系统，以执行诸如编译文献综述、起草消费者报告和规划假期等任务。许多工具和库可用于帮助创建此类系统，但没有一个支持递归多主体系统——模型本身灵活地决定何时委派任务以及如何组织其委派结构。在这项工作中，我们介绍了 ReDel：一个用于递归多主体系统的工具包，它支持自定义工具使用、委派方案、基于事件的日志记录和易于使用的 Web 界面中的交互式重放。我们表明，使用 ReDel，我们能够在代理基准上实现显着的性能提升，并通过可视化和调试工具轻松识别潜在的改进领域。我们的代码、文档和 PyPI 包是开源的，可以在 MIT 许可下免费使用。

##### **Evaluating Vision-Language Models for Zero-Shot Detection, Classification, and Association of Motorcycles, Passengers, and Helmets**
2408.02244v1 by Lucas Choi, Ross Greer

Motorcycle accidents pose significant risks, particularly when riders and
passengers do not wear helmets. This study evaluates the efficacy of an
advanced vision-language foundation model, OWLv2, in detecting and classifying
various helmet-wearing statuses of motorcycle occupants using video data. We
extend the dataset provided by the CVPR AI City Challenge and employ a cascaded
model approach for detection and classification tasks, integrating OWLv2 and
CNN models. The results highlight the potential of zero-shot learning to
address challenges arising from incomplete and biased training datasets,
demonstrating the usage of such models in detecting motorcycles, helmet usage,
and occupant positions under varied conditions. We have achieved an average
precision of 0.5324 for helmet detection and provided precision-recall curves
detailing the detection and classification performance. Despite limitations
such as low-resolution data and poor visibility, our research shows promising
advancements in automated vehicle safety and traffic safety enforcement
systems.

摘要：機車事故會造成重大風險，特別是當騎士和乘客沒有戴安全帽時。本研究評估先進的視覺語言基礎模型 OWLv2 在使用視訊資料偵測和分類機車駕駛人各種配戴安全帽的狀態的效能。我們擴充由 CVPR AI City Challenge 提供的資料集，並採用串聯模型方法進行偵測和分類任務，整合 OWLv2 和 CNN 模型。結果突顯了零次學習的潛力，以解決不完整和有偏差的訓練資料集所造成的挑戰，展示使用此類模型在各種條件下偵測機車、安全帽使用情況和駕駛人位置。我們在安全帽偵測方面達到了 0.5324 的平均精準度，並提供了詳細說明偵測和分類效能的精準度召回率曲線。儘管有低解析度資料和能見度不佳等限制，我們的研究顯示了自動化車輛安全和交通安全執法系統的進步潛力。

##### **BOTS-LM: Training Large Language Models for Setswana**
2408.02239v1 by Nathan Brown, Vukosi Marivate

In this work we present BOTS-LM, a series of bilingual language models
proficient in both Setswana and English. Leveraging recent advancements in data
availability and efficient fine-tuning, BOTS-LM achieves performance similar to
models significantly larger than itself while maintaining computational
efficiency. Our initial release features an 8 billion parameter generative
large language model, with upcoming 0.5 billion and 1 billion parameter large
language models and a 278 million parameter encoder-only model soon to be
released. We find the 8 billion parameter model significantly outperforms
Llama-3-70B and Aya 23 on English-Setswana translation tasks, approaching the
performance of dedicated machine translation models, while approaching 70B
parameter performance on Setswana reasoning as measured by a machine translated
subset of the MMLU benchmark. To accompany the BOTS-LM series of language
models, we release the largest Setswana web dataset, SetsText, totalling over
267 million tokens. In addition, we release the largest machine translated
Setswana dataset, the first and largest synthetic Setswana dataset, training
and evaluation code, training logs, and MMLU-tsn, a machine translated subset
of MMLU.

摘要：在這項工作中，我們展示了 BOTS-LM，這是一系列精通塞茨瓦納語和英語的雙語語言模型。利用數據可用性和高效微調的最新進展，BOTS-LM 達到了與自身大得多的模型相似的性能，同時保持了計算效率。我們的初始版本具有 80 億個參數的生成式大型語言模型，即將推出的 0.5 億和 10 億個參數大型語言模型，以及一個 2.78 億個參數的僅編碼器模型。我們發現，80 億個參數的模型在英語-塞茨瓦納語翻譯任務中顯著優於 Llama-3-70B 和 Aya 23，接近專用機器翻譯模型的性能，同時在通過機器翻譯的 MMLU 基準子集測量的塞茨瓦納語推理方面接近 70B 參數性能。為了配合 BOTS-LM 系列語言模型，我們發布了最大的塞茨瓦納語網路數據集 SetsText，總計超過 2.67 億個令牌。此外，我們發布了最大的機器翻譯塞茨瓦納語數據集、第一個也是最大的合成塞茨瓦納語數據集、訓練和評估代碼、訓練日誌和 MMLU-tsn，這是 MMLU 的機器翻譯子集。

##### **Do Large Language Models Speak All Languages Equally? A Comparative Study in Low-Resource Settings**
2408.02237v1 by Md. Arid Hasan, Prerona Tarannum, Krishno Dey, Imran Razzak, Usman Naseem

Large language models (LLMs) have garnered significant interest in natural
language processing (NLP), particularly their remarkable performance in various
downstream tasks in resource-rich languages. Recent studies have highlighted
the limitations of LLMs in low-resource languages, primarily focusing on binary
classification tasks and giving minimal attention to South Asian languages.
These limitations are primarily attributed to constraints such as dataset
scarcity, computational costs, and research gaps specific to low-resource
languages. To address this gap, we present datasets for sentiment and hate
speech tasks by translating from English to Bangla, Hindi, and Urdu,
facilitating research in low-resource language processing. Further, we
comprehensively examine zero-shot learning using multiple LLMs in English and
widely spoken South Asian languages. Our findings indicate that GPT-4
consistently outperforms Llama 2 and Gemini, with English consistently
demonstrating superior performance across diverse tasks compared to
low-resource languages. Furthermore, our analysis reveals that natural language
inference (NLI) exhibits the highest performance among the evaluated tasks,
with GPT-4 demonstrating superior capabilities.

摘要：大型語言模型 (LLM) 在自然語言處理 (NLP) 中引起了極大的興趣，特別是它們在資源豐富的語言中執行各種下游任務的出色表現。最近的研究強調了 LLM 在低資源語言中的局限性，主要關注二元分類任務，並對南亞語言的關注最少。這些限制主要歸因於諸如數據集稀缺、計算成本和特定於低資源語言的研究差距等約束。為了解決這個差距，我們通過將英語翻譯成孟加拉語、印地語和烏爾都語來提供情緒和仇恨言論任務的數據集，促進低資源語言處理的研究。此外，我們全面檢查了使用多個 LLM 在英語和廣泛使用的南亞語言中進行零次學習。我們的研究結果表明，GPT-4 持續優於 Llama 2 和 Gemini，與低資源語言相比，英語在各種任務中持續表現出優異的表現。此外，我們的分析表明，自然語言推理 (NLI) 在評估任務中表現最佳，而 GPT-4 則表現出卓越的能力。

##### **A Multi-Source Heterogeneous Knowledge Injected Prompt Learning Method for Legal Charge Prediction**
2408.02233v1 by Jingyun Sun, Chi Wei, Yang Li

Legal charge prediction, an essential task in legal AI, seeks to assign
accurate charge labels to case descriptions, attracting significant recent
interest. Existing methods primarily employ diverse neural network structures
for modeling case descriptions directly, failing to effectively leverage
multi-source external knowledge. We propose a prompt learning framework-based
method that simultaneously leverages multi-source heterogeneous external
knowledge from a legal knowledge base, a conversational LLM, and related legal
articles. Specifically, we match knowledge snippets in case descriptions via
the legal knowledge base and encapsulate them into the input through a hard
prompt template. Additionally, we retrieve legal articles related to a given
case description through contrastive learning, and then obtain factual elements
within the case description through a conversational LLM. We fuse the embedding
vectors of soft prompt tokens with the encoding vector of factual elements to
achieve knowledge-enhanced model forward inference. Experimental results show
that our method achieved state-of-the-art results on CAIL-2018, the largest
legal charge prediction dataset, and our method has lower data dependency. Case
studies also demonstrate our method's strong interpretability.

摘要：<paragraph>法律指控預測是法律 AI 中一項必要的任務，旨在為案件描述分配準確的指控標籤，最近引起了極大的興趣。現有方法主要採用不同的神經網路結構來直接對案件描述進行建模，未能有效利用多來源外部知識。我們提出了一個基於提示學習框架的方法，該方法同時利用來自法律知識庫、對話式 LLM 和相關法律條文的來源多樣且異質的外部知識。具體來說，我們通過法律知識庫比對案件描述中的知識片段，並通過硬提示範本將它們封裝到輸入中。此外，我們通過對比學習檢索與給定案件描述相關的法律條文，然後通過對話式 LLM 獲取案件描述中的事實要素。我們將軟提示符號的嵌入向量與事實要素的編碼向量融合，以實現知識增強模型的前向推理。實驗結果表明，我們的模型在最大的法律指控預測數據集 CAIL-2018 上取得了最先進的結果，並且我們的模型具有較低的数据依賴性。案例研究也證明了我們模型的強可解釋性。</paragraph>

##### **SpecRover: Code Intent Extraction via LLMs**
2408.02232v1 by Haifeng Ruan, Yuntong Zhang, Abhik Roychoudhury

Autonomous program improvement typically involves automatically producing bug
fixes and feature additions. Such program improvement can be accomplished by a
combination of large language model (LLM) and program analysis capabilities, in
the form of an LLM agent. Since program repair or program improvement typically
requires a specification of intended behavior - specification inference can be
useful for producing high quality program patches. In this work, we examine
efficient and low-cost workflows for iterative specification inference within
an LLM agent. Given a GitHub issue to be resolved in a software project, our
goal is to conduct iterative code search accompanied by specification inference
- thereby inferring intent from both the project structure and behavior. The
intent thus captured is examined by a reviewer agent with the goal of vetting
the patches as well as providing a measure of confidence in the vetted patches.
Our approach SpecRover (AutoCodeRover-v2) is built on the open-source LLM agent
AutoCodeRover. In an evaluation on the full SWE-Bench consisting of 2294 GitHub
issues, it shows more than 50% improvement in efficacy over AutoCodeRover.
Compared to the open-source agents available, our work shows modest cost ($0.65
per issue) in resolving an average GitHub issue in SWE-Bench lite. The
production of explanation by SpecRover allows for a better "signal" to be given
to the developer, on when the suggested patches can be accepted with
confidence. SpecRover also seeks to demonstrate the continued importance of
specification inference in automated program repair, even as program repair
technologies enter the LLM era.

摘要：自動程式改善通常涉及自動產生錯誤修正和功能新增。這種程式改善可以透過大型語言模型 (LLM) 和程式分析功能的結合來完成，以 LLM 代理的形式。由於程式修復或程式改善通常需要指定預期行為 - 規格推論對於產生高品質程式修補程式很有用。在這項工作中，我們研究了 LLM 代理中迭代規格推論的有效且低成本工作流程。假設有一個 GitHub 問題需要在軟體專案中解決，我們的目標是進行迭代程式碼搜尋，並伴隨著規格推論 - 從而從專案結構和行為中推論意圖。由此擷取的意圖由審查員代理檢查，目標是審查修補程式並提供對已審查修補程式的信心測量。我們的方法 SpecRover (AutoCodeRover-v2) 建立在開源 LLM 代理 AutoCodeRover 上。在包含 2294 個 GitHub 問題的完整 SWE-Bench 上的評估中，它顯示出比 AutoCodeRover 高出 50% 以上的效能改善。與現有的開源代理相比，我們的作品顯示出在解決 SWE-Bench Lite 中的平均 GitHub 問題時成本適中（每個問題 0.65 美元）。SpecRover 產生的說明允許向開發人員提供更好的「訊號」，說明何時可以自信地接受建議的修補程式。SpecRover 也試圖證明規格推論在自動程式修復中的持續重要性，即使程式修復技術已進入 LLM 時代。

##### **Is Large Language Model Good at Database Knob Tuning? A Comprehensive Experimental Evaluation**
2408.02213v1 by Yiyan Li, Haoyang Li, Zhao Pu, Jing Zhang, Xinyi Zhang, Tao Ji, Luming Sun, Cuiping Li, Hong Chen

Knob tuning plays a crucial role in optimizing databases by adjusting knobs
to enhance database performance. However, traditional tuning methods often
follow a Try-Collect-Adjust approach, proving inefficient and
database-specific. Moreover, these methods are often opaque, making it
challenging for DBAs to grasp the underlying decision-making process.
  The emergence of large language models (LLMs) like GPT-4 and Claude-3 has
excelled in complex natural language tasks, yet their potential in database
knob tuning remains largely unexplored. This study harnesses LLMs as
experienced DBAs for knob-tuning tasks with carefully designed prompts. We
identify three key subtasks in the tuning system: knob pruning, model
initialization, and knob recommendation, proposing LLM-driven solutions to
replace conventional methods for each subtask.
  We conduct extensive experiments to compare LLM-driven approaches against
traditional methods across the subtasks to evaluate LLMs' efficacy in the knob
tuning domain. Furthermore, we explore the adaptability of LLM-based solutions
in diverse evaluation settings, encompassing new benchmarks, database engines,
and hardware environments. Our findings reveal that LLMs not only match or
surpass traditional methods but also exhibit notable interpretability by
generating responses in a coherent ``chain-of-thought'' manner. We further
observe that LLMs exhibit remarkable generalizability through simple
adjustments in prompts, eliminating the necessity for additional training or
extensive code modifications.
  Drawing insights from our experimental findings, we identify several
opportunities for future research aimed at advancing the utilization of LLMs in
the realm of database management.

摘要：<paragraph>旋鈕調整透過調整旋鈕來最佳化資料庫，在提升資料庫效能方面扮演至關重要的角色。然而，傳統的調整方法通常遵循嘗試-收集-調整的方法，證明效率低下且資料庫專屬。此外，這些方法通常是不透明的，這使得資料庫管理員難以掌握其背後的決策過程。
大型語言模型 (LLM) 如 GPT-4 和 Claude-3 的出現，在複雜的自然語言任務中表現出色，但它們在資料庫旋鈕調整中的潛力仍未被廣泛探索。本研究利用 LLM 作為經驗豐富的資料庫管理員，使用精心設計的提示進行旋鈕調整任務。我們在調整系統中識別出三個關鍵子任務：旋鈕修剪、模型初始化和旋鈕推薦，並提出以 LLM 為驅動的解決方案來取代每個子任務的傳統方法。
我們進行廣泛的實驗，將 LLM 驅動的方法與各個子任務中的傳統方法進行比較，以評估 LLM 在旋鈕調整領域的效能。此外，我們探討了基於 LLM 的解決方案在不同評估設定中的適應性，包括新的基準、資料庫引擎和硬體環境。我們的研究結果表明，LLM 不僅能與傳統方法相匹配或超越傳統方法，而且還通過以連貫的「思維鏈」方式產生回應，展現出顯著的可解釋性。我們進一步觀察到，LLM 通過提示中的簡單調整展現出顯著的泛化能力，消除了額外訓練或廣泛代碼修改的必要性。
從我們的實驗結果中汲取見解，我們找出幾個未來研究的機會，旨在推進 LLM 在資料庫管理領域的應用。</paragraph>

##### **MARCO: A Memory-Augmented Reinforcement Framework for Combinatorial Optimization**
2408.02207v1 by Andoni I. Garmendia, Quentin Cappart, Josu Ceberio, Alexander Mendiburu

Neural Combinatorial Optimization (NCO) is an emerging domain where deep
learning techniques are employed to address combinatorial optimization problems
as a standalone solver. Despite their potential, existing NCO methods often
suffer from inefficient search space exploration, frequently leading to local
optima entrapment or redundant exploration of previously visited states. This
paper introduces a versatile framework, referred to as Memory-Augmented
Reinforcement for Combinatorial Optimization (MARCO), that can be used to
enhance both constructive and improvement methods in NCO through an innovative
memory module. MARCO stores data collected throughout the optimization
trajectory and retrieves contextually relevant information at each state. This
way, the search is guided by two competing criteria: making the best decision
in terms of the quality of the solution and avoiding revisiting already
explored solutions. This approach promotes a more efficient use of the
available optimization budget. Moreover, thanks to the parallel nature of NCO
models, several search threads can run simultaneously, all sharing the same
memory module, enabling an efficient collaborative exploration. Empirical
evaluations, carried out on the maximum cut, maximum independent set and
travelling salesman problems, reveal that the memory module effectively
increases the exploration, enabling the model to discover diverse,
higher-quality solutions. MARCO achieves good performance in a low
computational cost, establishing a promising new direction in the field of NCO.

摘要：神經組合最佳化（NCO）是一個新興領域，其中深度學習技術被用於解決組合最佳化問題，作為一個獨立的求解器。儘管它們具有潛力，現有的 NCO 方法通常會遇到搜索空間探索效率低下的問題，經常導致局部最優陷入或重複探索先前訪問過的狀態。本文介紹了一個通用的框架，稱為組合最佳化的記憶增強強化（MARCO），可通過創新的記憶模組用於增強 NCO 中的建構和改進方法。MARCO 儲存整個最佳化軌跡中收集的資料，並在每個狀態檢索與上下文相關的資訊。這樣，搜尋會受到兩個競爭標準的指導：根據解決方案的品質做出最佳決策，並避免重新檢視已探索的解決方案。這種方法促进了更有效地使用可用的最佳化預算。此外，由於 NCO 模型的並行性質，多個搜尋執行緒可以同時執行，所有執行緒共用同一個記憶模組，實現高效的協作探索。在最大割、最大獨立集和旅行商問題上進行的實證評估表明，記憶模組有效地增加了探索，使模型能夠發現多樣化、更高品質的解決方案。MARCO 在低計算成本下實現了良好的效能，為 NCO 領域建立了一個有希望的新方向。

##### **Towards AI-Safety-by-Design: A Taxonomy of Runtime Guardrails in Foundation Model based Systems**
2408.02205v1 by Md Shamsujjoha, Qinghua Lu, Dehai Zhao, Liming Zhu

The rapid advancement and widespread deployment of foundation model (FM)
based systems have revolutionized numerous applications across various domains.
However, the fast-growing capabilities and autonomy have also raised
significant concerns about responsible AI and AI safety. Recently, there have
been increasing attention toward implementing guardrails to ensure the runtime
behavior of FM-based systems is safe and responsible. Given the early stage of
FMs and their applications (such as agents), the design of guardrails have not
yet been systematically studied. It remains underexplored which software
qualities should be considered when designing guardrails and how these
qualities can be ensured from a software architecture perspective. Therefore,
in this paper, we present a taxonomy for guardrails to classify and compare the
characteristics and design options of guardrails. Our taxonomy is organized
into three main categories: the motivation behind adopting runtime guardrails,
the quality attributes to consider, and the design options available. This
taxonomy provides structured and concrete guidance for making architectural
design decisions when designing guardrails and highlights trade-offs arising
from the design decisions.

摘要：基礎模型 (FM)
系統的快速進展和廣泛部署已經徹底改變了各個領域的眾多應用。
然而，快速增長的機能和自主性也引發了對負責任的 AI 和 AI 安全性的重大疑慮。最近，對於實施防護措施以確保 FM 系統的執行期間行為安全且負責任，越來越受到重視。鑑於 FM 及其應用（例如代理）的早期階段，防護措施的設計尚未經過系統性研究。在設計防護措施時應該考慮哪些軟體品質，以及如何從軟體架構的角度確保這些品質，這些問題仍然未被充分探討。因此，在本文中，我們提出了防護措施的分類法，以分類和比較防護措施的特性和設計選項。我們的分類法分為三大類：採用執行期間防護措施的動機、應考慮的品質屬性，以及可用的設計選項。此分類法提供了結構化且具體的指導，供在設計防護措施時做出架構設計決策，並強調設計決策所產生的權衡取捨。

##### **Evaluating the Performance of Large Language Models for SDG Mapping (Technical Report)**
2408.02201v1 by Hui Yin, Amir Aryani, Nakul Nambiar

The use of large language models (LLMs) is expanding rapidly, and open-source
versions are becoming available, offering users safer and more adaptable
options. These models enable users to protect data privacy by eliminating the
need to provide data to third parties and can be customized for specific tasks.
In this study, we compare the performance of various language models on the
Sustainable Development Goal (SDG) mapping task, using the output of GPT-4o as
the baseline. The selected open-source models for comparison include Mixtral,
LLaMA 2, LLaMA 3, Gemma, and Qwen2. Additionally, GPT-4o-mini, a more
specialized version of GPT-4o, was included to extend the comparison. Given the
multi-label nature of the SDG mapping task, we employed metrics such as F1
score, precision, and recall with micro-averaging to evaluate different aspects
of the models' performance. These metrics are derived from the confusion matrix
to ensure a comprehensive evaluation. We provide a clear observation and
analysis of each model's performance by plotting curves based on F1 score,
precision, and recall at different thresholds. According to the results of this
experiment, LLaMA 2 and Gemma still have significant room for improvement. The
other four models do not exhibit particularly large differences in performance.
The outputs from all seven models are available on Zenodo:
https://doi.org/10.5281/zenodo.12789375.

摘要：大型語言模型（LLM）的使用正在迅速擴展，且開放原始碼版本也正變得可得，為使用者提供更安全且更具適應性的選項。這些模型讓使用者能透過消除提供資料給第三方的需求來保護資料隱私，且能針對特定任務進行客製化。在此研究中，我們比較了各種語言模型在永續發展目標（SDG）對應任務上的表現，並使用 GPT-4o 的輸出作為基準。所選用於比較之開放原始碼模型包括 Mixtral、LLaMA 2、LLaMA 3、Gemma 和 Qwen2。此外，還加入了 GPT-4o 的更專業版本 GPT-4o-mini 以擴充比較。考量到 SDG 對應任務的多標籤性質，我們採用了 F1 分數、精確度和召回率等指標，並使用微平均來評估模型表現的不同面向。這些指標皆衍生自混淆矩陣，以確保評估的全面性。我們透過繪製基於不同閾值的 F1 分數、精確度和召回率的曲線，提供每個模型表現的明確觀察和分析。根據此實驗的結果，LLaMA 2 和 Gemma 仍有顯著的進步空間。其他四個模型在表現上沒有特別大的差異。所有七個模型的輸出皆可在 Zenodo 上取得：https://doi.org/10.5281/zenodo.12789375。

##### **CodeACT: Code Adaptive Compute-efficient Tuning Framework for Code LLMs**
2408.02193v1 by Weijie Lv, Xuan Xia, Sheng-Jun Huang

Large language models (LLMs) have shown great potential in code-related
tasks, yet open-source models lag behind their closed-source counterparts. To
bridge this performance gap, existing methods generate vast amounts of
synthetic data for fine-tuning, leading to inefficiencies in training.
Motivated by the need for more effective and efficient training, we propose the
Code Adaptive Compute-efficient Tuning (CodeACT) framework. CodeACT introduces
the Complexity and Diversity Aware Sampling (CDAS) method to select
high-quality training data based on complexity and diversity, and the Dynamic
Pack padding strategy to reduce computational resource usage by minimizing
padding tokens during training. Experimental results demonstrate that
CodeACT-DeepSeek-Coder-6.7B, fine-tuned on only 40% of the EVOL-Instruct data,
achieves an 8.6% performance increase on HumanEval, reduces training time by
78%, and decreases peak GPU memory usage by 27%. These findings underscore
CodeACT's ability to enhance the performance and efficiency of open-source
models. By optimizing both the data selection and training processes, CodeACT
offers a comprehensive approach to improving the capabilities of open-source
LLMs while significantly reducing computational requirements, addressing the
dual challenges of data quality and training efficiency, and paving the way for
more resource-efficient and performant models.

摘要：大型語言模型 (LLM) 在與程式碼相關的任務中展現了極大的潛力，然而開放原始碼模型卻落後於閉源模型。為了彌補這種效能差距，現有的方法會產生大量的合成資料進行微調，導致訓練效率不彰。由於需要更有效率的訓練，我們提出了 Code Adaptive Compute-efficient Tuning (CodeACT) 架構。CodeACT 引入了「複雜度和多樣性感知取樣」(CDAS) 方法，根據複雜度和多樣性來挑選高品質的訓練資料，以及「動態封包填充」策略，透過在訓練期間將填充符號減到最少，以降低運算資源使用量。實驗結果顯示，在僅使用 40% 的 EVOL-Instruct 資料進行微調後，CodeACT-DeepSeek-Coder-6.7B 在 HumanEval 上的效能提升了 8.6%，訓練時間減少了 78%，而且 GPU 記憶體使用量減少了 27%。這些發現凸顯了 CodeACT 提升開放原始碼模型效能和效率的能力。透過最佳化資料選擇和訓練流程，CodeACT 提供了一種全面性的方法來提升開放原始碼 LLM 的功能，同時大幅降低運算需求，解決資料品質和訓練效率的雙重挑戰，並為更省資源且效能更高的模型鋪路。

##### **Calibration-Disentangled Learning and Relevance-Prioritized Reranking for Calibrated Sequential Recommendation**
2408.02156v1 by Hyunsik Jeon, Se-eun Yoon, Julian McAuley

Calibrated recommendation, which aims to maintain personalized proportions of
categories within recommendations, is crucial in practical scenarios since it
enhances user satisfaction by reflecting diverse interests. However, achieving
calibration in a sequential setting (i.e., calibrated sequential
recommendation) is challenging due to the need to adapt to users' evolving
preferences. Previous methods typically leverage reranking algorithms to
calibrate recommendations after training a model without considering the effect
of calibration and do not effectively tackle the conflict between relevance and
calibration during the reranking process. In this work, we propose LeapRec
(Calibration-Disentangled Learning and Relevance-Prioritized Reranking), a
novel approach for the calibrated sequential recommendation that addresses
these challenges. LeapRec consists of two phases, model training phase and
reranking phase. In the training phase, a backbone model is trained using our
proposed calibration-disentangled learning-to-rank loss, which optimizes
personalized rankings while integrating calibration considerations. In the
reranking phase, relevant items are prioritized at the top of the list, with
items needed for calibration following later to address potential conflicts
between relevance and calibration. Through extensive experiments on four
real-world datasets, we show that LeapRec consistently outperforms previous
methods in the calibrated sequential recommendation. Our code is available at
https://github.com/jeon185/LeapRec.

摘要：校準推薦，旨在維持推薦中類別的個人化比例，在實際場景中至關重要，因為它通過反映不同的興趣來增強用戶滿意度。然而，在順序設定中實現校準（即校準順序推薦）具有挑戰性，因為需要適應用戶不斷變化的偏好。先前的辦法通常利用重新排序演算法，在訓練模型後校準推薦，而不考慮校準的效果，並且在重新排序過程中無法有效解決相關性和校準之間的衝突。在這項工作中，我們提出 LeapRec（校準分離學習和相關性優先重新排序），一種解決這些挑戰的校準順序推薦新方法。LeapRec 包含兩個階段，模型訓練階段和重新排序階段。在訓練階段，使用我們提出的校準分離學習到排序損失訓練主幹模型，在整合校準考量時最佳化個人化排序。在重新排序階段，相關項目優先排列在清單頂端，而需要校準的項目隨後排列，以解決相關性和校準之間的潛在衝突。透過在四個真實世界資料集上進行廣泛的實驗，我們展示 LeapRec 在校準順序推薦中始終優於先前的辦法。我們的程式碼可在 https://github.com/jeon185/LeapRec 取得。

##### **ARVO: Atlas of Reproducible Vulnerabilities for Open Source Software**
2408.02153v1 by Xiang Mei, Pulkit Singh Singaria, Jordi Del Castillo, Haoran Xi, Abdelouahab, Benchikh, Tiffany Bao, Ruoyu Wang, Yan Shoshitaishvili, Adam Doupé, Hammond Pearce, Brendan Dolan-Gavitt

High-quality datasets of real-world vulnerabilities are enormously valuable
for downstream research in software security, but existing datasets are
typically small, require extensive manual effort to update, and are missing
crucial features that such research needs. In this paper, we introduce ARVO: an
Atlas of Reproducible Vulnerabilities in Open-source software. By sourcing
vulnerabilities from C/C++ projects that Google's OSS-Fuzz discovered and
implementing a reliable re-compilation system, we successfully reproduce more
than 5,000 memory vulnerabilities across over 250 projects, each with a
triggering input, the canonical developer-written patch for fixing the
vulnerability, and the ability to automatically rebuild the project from source
and run it at its vulnerable and patched revisions. Moreover, our dataset can
be automatically updated as OSS-Fuzz finds new vulnerabilities, allowing it to
grow over time. We provide a thorough characterization of the ARVO dataset,
show that it can locate fixes more accurately than Google's own OSV
reproduction effort, and demonstrate its value for future research through two
case studies: firstly evaluating real-world LLM-based vulnerability repair, and
secondly identifying over 300 falsely patched (still-active) zero-day
vulnerabilities from projects improperly labeled by OSS-Fuzz.

摘要：<paragraph>高品質的真實世界漏洞資料集對於軟體安全的下游研究非常有價值，但現有的資料集通常很小，需要大量的修改手動工作，而且缺少此類研究所需的關鍵功能。在本文中，我們介紹了 ARVO：開源軟體中可複製漏洞的 Atlas。通過從 Google 的 OSS-Fuzz 發現的 C/C++ 專案中獲取漏洞並實作可靠的重新編譯系統，我們成功複製了超過 250 個專案中超過 5,000 個記憶體漏洞，每個漏洞都有一個觸發輸入、一個用於修正漏洞的正規開發人員編寫的修補程式，以及從原始碼自動重新建置專案並在易受攻擊和修補的版本中執行它的能力。此外，我們的資料集可以在 OSS-Fuzz 發現新漏洞時自動更新，允許它隨著時間推移而增長。我們提供了 ARVO 資料集的徹底特徵描述，表明它比 Google 自己 OSV 的複製工作更準確地找到修正程式，並透過兩個案例研究展示了其對未來研究的價值：首先評估真實世界的 LLM 基於漏洞修復，其次從 OSS-Fuzz 標籤不當的專案中找出超過 300 個錯誤修補的（仍然活躍的）零時差漏洞。</paragraph>

##### **Generative Retrieval with Few-shot Indexing**
2408.02152v1 by Arian Askari, Chuan Meng, Mohammad Aliannejadi, Zhaochun Ren, Evangelos Kanoulas, Suzan Verberne

Existing generative retrieval (GR) approaches rely on training-based
indexing, i.e., fine-tuning a model to memorise the associations between a
query and the document identifier (docid) of a relevant document.
Training-based indexing has three limitations: high training overhead,
under-utilization of the pre-trained knowledge of large language models (LLMs),
and challenges in adapting to a dynamic document corpus. To address the above
issues, we propose a novel few-shot indexing-based GR framework (Few-Shot GR).
It has a novel few-shot indexing process, where we prompt an LLM to generate
docids for all documents in a corpus, ultimately creating a docid bank for the
entire corpus. During retrieval, we feed a query to the same LLM and constrain
it to generate a docid within the docid bank created during indexing, and then
map the generated docid back to its corresponding document. Few-Shot GR relies
solely on prompting an LLM without requiring any training, making it more
efficient. Moreover, we devise few-shot indexing with one-to-many mapping to
further enhance Few-Shot GR. Experiments show that Few-Shot GR achieves
superior performance to state-of-the-art GR methods that require heavy
training.

摘要：現有的生成式檢索 (GR) 方法依賴於基於訓練的索引，即微調模型以記憶查詢與相關文件的文件識別碼 (docid) 之間的關聯。基於訓練的索引有三個限制：高訓練開銷、大型語言模型 (LLM) 的預訓練知識利用不足，以及適應動態文件語料庫時的挑戰。為了解決上述問題，我們提出了一個新穎的基於少量索引的 GR 框架 (Few-Shot GR)。它有一個新穎的少量索引過程，我們在其中提示 LLM 為語料庫中的所有文件生成 docid，最終為整個語料庫創建一個 docid 庫。在檢索過程中，我們將查詢饋送到同一個 LLM 並限制它在索引過程中創建的 docid 庫中生成 docid，然後將生成的 docid 映射回其對應的文件。Few-Shot GR 僅依賴於提示 LLM，而不需要任何訓練，這使其更有效率。此外，我們設計了一對多的映射的少量索引，以進一步增強 Few-Shot GR。實驗表明，Few-Shot GR 達到了優於需要大量訓練的最新 GR 方法的性能。

##### **Environment Complexity and Nash Equilibria in a Sequential Social Dilemma**
2408.02148v1 by Mustafa Yasir, Andrew Howes, Vasilios Mavroudis, Chris Hicks

Multi-agent reinforcement learning (MARL) methods, while effective in
zero-sum or positive-sum games, often yield suboptimal outcomes in general-sum
games where cooperation is essential for achieving globally optimal outcomes.
Matrix game social dilemmas, which abstract key aspects of general-sum
interactions, such as cooperation, risk, and trust, fail to model the temporal
and spatial dynamics characteristic of real-world scenarios. In response, our
study extends matrix game social dilemmas into more complex, higher-dimensional
MARL environments. We adapt a gridworld implementation of the Stag Hunt dilemma
to more closely match the decision-space of a one-shot matrix game while also
introducing variable environment complexity. Our findings indicate that as
complexity increases, MARL agents trained in these environments converge to
suboptimal strategies, consistent with the risk-dominant Nash equilibria
strategies found in matrix games. Our work highlights the impact of environment
complexity on achieving optimal outcomes in higher-dimensional game-theoretic
MARL environments.

摘要：多智能體強化學習 (MARL) 方法在零和或正和遊戲中雖然有效，但在合作對達成全球最佳結果至關重要的總和遊戲中，往往會產生次佳結果。矩陣遊戲中的社會困境，抽象化了總和互動中的關鍵面向，例如合作、風險和信任，但無法模擬真實世界情境中特有的時間和空間動態。為了解決這個問題，我們的研究將矩陣遊戲中的社會困境擴展到更複雜、更高維度的 MARL 環境中。我們調整了 Stag Hunt 困境的網格世界實作，讓它更接近一次性矩陣遊戲的決策空間，同時也引入了可變環境複雜度。我們的研究結果顯示，隨著複雜度的增加，在這些環境中訓練的 MARL 智能體會收斂到次佳策略，這與矩陣遊戲中發現的風險主導納許均衡策略一致。我們的研究突顯了環境複雜度對在更高維度博弈論 MARL 環境中達成最佳結果的影響。

##### **Analyzing Cultural Representations of Emotions in LLMs through Mixed Emotion Survey**
2408.02143v1 by Shiran Dudy, Ibrahim Said Ahmad, Ryoko Kitajima, Agata Lapedriza

Large Language Models (LLMs) have gained widespread global adoption,
showcasing advanced linguistic capabilities across multiple of languages. There
is a growing interest in academia to use these models to simulate and study
human behaviors. However, it is crucial to acknowledge that an LLM's
proficiency in a specific language might not fully encapsulate the norms and
values associated with its culture. Concerns have emerged regarding potential
biases towards Anglo-centric cultures and values due to the predominance of
Western and US-based training data. This study focuses on analyzing the
cultural representations of emotions in LLMs, in the specific case of
mixed-emotion situations. Our methodology is based on the studies of Miyamoto
et al. (2010), which identified distinctive emotional indicators in Japanese
and American human responses. We first administer their mixed emotion survey to
five different LLMs and analyze their outputs. Second, we experiment with
contextual variables to explore variations in responses considering both
language and speaker origin. Thirdly, we expand our investigation to encompass
additional East Asian and Western European origin languages to gauge their
alignment with their respective cultures, anticipating a closer fit. We find
that (1) models have limited alignment with the evidence in the literature; (2)
written language has greater effect on LLMs' response than information on
participants origin; and (3) LLMs responses were found more similar for East
Asian languages than Western European languages.

摘要：大型語言模型（LLM）已獲得全球廣泛採用，展示了跨多種語言的高階語言能力。學術界對使用這些模型來模擬和研究人類行為越來越感興趣。然而，必須承認，LLM 在特定語言中的熟練程度可能無法完全概括與其文化相關的規範和價值觀。由於西方和美國訓練資料佔主導地位，因此出現了對英格蘭中心文化和價值觀潛在偏見的擔憂。本研究重點分析 LLM 中情緒的文化表徵，特別是混合情緒的情況。我們的研究方法基於 Miyamoto 等人的研究。（2010 年），該研究確定了日本和美國人類反應中獨特的情緒指標。我們首先對五種不同的 LLM 進行他們的混合情緒調查，並分析其輸出。其次，我們實驗上下文變數，以探討考慮語言和說話者來源的回應變化。第三，我們擴大調查範圍，涵蓋更多東亞和西歐起源語言，以評估它們與各自文化的契合度，並預期更密切的契合。我們發現 (1) 模型與文獻中的證據對齊有限；(2) 書面語言對 LLM 的回應比參與者來源的資訊有更大的影響；(3) 發現 LLM 對東亞語言的回應比對西歐語言的回應更相似。

##### **VidModEx: Interpretable and Efficient Black Box Model Extraction for High-Dimensional Spaces**
2408.02140v1 by Somnath Sendhil Kumar, Yuvaraj Govindarajulu, Pavan Kulkarni, Manojkumar Parmar

In the domain of black-box model extraction, conventional methods reliant on
soft labels or surrogate datasets struggle with scaling to high-dimensional
input spaces and managing the complexity of an extensive array of interrelated
classes. In this work, we present a novel approach that utilizes SHAP (SHapley
Additive exPlanations) to enhance synthetic data generation. SHAP quantifies
the individual contributions of each input feature towards the victim model's
output, facilitating the optimization of an energy-based GAN towards a
desirable output. This method significantly boosts performance, achieving a
16.45% increase in the accuracy of image classification models and extending to
video classification models with an average improvement of 26.11% and a maximum
of 33.36% on challenging datasets such as UCF11, UCF101, Kinetics 400, Kinetics
600, and Something-Something V2. We further demonstrate the effectiveness and
practical utility of our method under various scenarios, including the
availability of top-k prediction probabilities, top-k prediction labels, and
top-1 labels.

摘要：在黑盒模型提取领域，依赖软标签或替代数据集的传统方法难以扩展到高维输入空间，并且难以管理大量相互关联的类别的复杂性。在这项工作中，我们提出了一种新颖的方法，该方法利用 SHAP（SHapley Additive exPlanations）来增强合成数据生成。SHAP 量化了每个输入特征对受害者模型输出的个别贡献，从而促进了基于能量的 GAN 朝着理想输出进行优化。这种方法显著提升了性能，使图像分类模型的准确性提高了 16.45%，并且扩展到视频分类模型，在 UCF11、UCF101、Kinetics 400、Kinetics 600 和 Something-Something V2 等具有挑战性的数据集上平均提高了 26.11%，最高提高了 33.36%。我们进一步展示了我们的方法在各种场景下的有效性和实用性，包括 top-k 预测概率、top-k 预测标签和 top-1 标签的可用性。

##### **Table Transformers for Imputing Textual Attributes**
2408.02128v1 by Ting-Ruen Wei, Yuan Wang, Yoshitaka Inoue, Hsin-Tai Wu, Yi Fang

Missing data in tabular dataset is a common issue as the performance of
downstream tasks usually depends on the completeness of the training dataset.
Previous missing data imputation methods focus on numeric and categorical
columns, but we propose a novel end-to-end approach called Table Transformers
for Imputing Textual Attributes (TTITA) based on the transformer to impute
unstructured textual columns using other columns in the table. We conduct
extensive experiments on two Amazon Reviews datasets, and our approach shows
competitive performance outperforming baseline models such as recurrent neural
networks and Llama2. The performance improvement is more significant when the
target sequence has a longer length. Additionally, we incorporated multi-task
learning to simultaneously impute for heterogeneous columns, boosting the
performance for text imputation. We also qualitatively compare with ChatGPT for
realistic applications.

摘要：表格資料集中遺失的資料是一個常見的問題，因為下游任務的效能通常取決於訓練資料集的完整性。先前的遺失資料填補方法專注於數字和類別欄位，但我們提出了一種稱為表格Transformer用於填補文字屬性（TTITA）的新穎端到端方法，該方法基於Transformer，使用表格中的其他欄位來填補非結構化的文字欄位。我們對兩個 Amazon 評論資料集進行了廣泛的實驗，我們的做法展現了優異的效能，優於基線模型，例如遞迴神經網路和 Llama2。當目標序列較長時，效能提升更為顯著。此外，我們結合了多任務學習來同時填補異質欄位，提升文字填補的效能。我們也從質性的角度與 ChatGPT 進行比較，以進行實際應用。

##### **Recent Advances in Multi-Choice Machine Reading Comprehension: A Survey on Methods and Datasets**
2408.02114v1 by Shima Foolad, Kourosh Kiani, Razieh Rastgoo

This paper provides a thorough examination of recent developments in the
field of multi-choice Machine Reading Comprehension (MRC). Focused on benchmark
datasets, methodologies, challenges, and future trajectories, our goal is to
offer researchers a comprehensive overview of the current landscape in
multi-choice MRC. The analysis delves into 30 existing cloze-style and
multiple-choice MRC benchmark datasets, employing a refined classification
method based on attributes such as corpus style, domain, complexity, context
style, question style, and answer style. This classification system enhances
our understanding of each dataset's diverse attributes and categorizes them
based on their complexity. Furthermore, the paper categorizes recent
methodologies into Fine-tuned and Prompt-tuned methods. Fine-tuned methods
involve adapting pre-trained language models (PLMs) to a specific task through
retraining on domain-specific datasets, while prompt-tuned methods use prompts
to guide PLM response generation, presenting potential applications in
zero-shot or few-shot learning scenarios. By contributing to ongoing
discussions, inspiring future research directions, and fostering innovations,
this paper aims to propel multi-choice MRC towards new frontiers of
achievement.

摘要：本文全面檢視多選項機器閱讀理解（MRC）領域的最新發展。我們專注於基準資料集、方法論、挑戰和未來軌跡，目標是為研究人員提供多選項 MRC 當前概況的全面概述。分析深入探討了 30 個現有的完形填空式和多選項 MRC 基準資料集，採用基於屬性的精煉分類方法，例如語料庫樣式、領域、複雜度、上下文樣式、問題樣式和答案樣式。此分類系統增強了我們對每個資料集不同屬性的理解，並根據其複雜度對它們進行分類。此外，本文將近期方法論分類為微調方法和提示調整方法。微調方法涉及通過在特定領域的資料集上重新訓練來調整預訓練語言模型 (PLM) 以適應特定任務，而提示調整方法使用提示來引導 PLM 回應生成，在零次學習或少次學習場景中呈現潛在應用。透過為持續的討論做出貢獻、激勵未來的研究方向並促進創新，本文旨在推進多選項 MRC 朝向新的成就前沿。

##### **Understanding Deep Learning via Notions of Rank**
2408.02111v1 by Noam Razin

Despite the extreme popularity of deep learning in science and industry, its
formal understanding is limited. This thesis puts forth notions of rank as key
for developing a theory of deep learning, focusing on the fundamental aspects
of generalization and expressiveness. In particular, we establish that
gradient-based training can induce an implicit regularization towards low rank
for several neural network architectures, and demonstrate empirically that this
phenomenon may facilitate an explanation of generalization over natural data
(e.g., audio, images, and text). Then, we characterize the ability of graph
neural networks to model interactions via a notion of rank, which is commonly
used for quantifying entanglement in quantum physics. A central tool underlying
these results is a connection between neural networks and tensor
factorizations. Practical implications of our theory for designing explicit
regularization schemes and data preprocessing algorithms are presented.

摘要：儘管深度學習在科學和產業中廣受歡迎，但其正式理解仍受限。本論文提出秩的概念，作為發展深度學習理論的關鍵，專注於泛化和表現力的基本面向。特別是，我們確立基於梯度的訓練可以對多個神經網路結構誘導出低秩的隱式正則化，並透過實證證明此現象有助於解釋自然資料（例如音訊、影像和文字）的泛化。接著，我們透過秩的概念描述圖形神經網路建模互動的能力，這通常用於量化量子物理中的糾纏。這些結果背後的一個核心工具是神經網路和張量分解之間的關聯。本理論在設計明確的正則化架構和資料前處理演算法上的實務意涵已獲得說明。

##### **Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process**
2408.02103v1 by Peng Wang, Xiaobin Wang, Chao Lou, Shengyu Mao, Pengjun Xie, Yong Jiang

In-context learning (ICL) is a few-shot learning paradigm that involves
learning mappings through input-output pairs and appropriately applying them to
new instances. Despite the remarkable ICL capabilities demonstrated by Large
Language Models (LLMs), existing works are highly dependent on large-scale
labeled support sets, not always feasible in practical scenarios. To refine
this approach, we focus primarily on an innovative selective annotation
mechanism, which precedes the standard demonstration retrieval. We introduce
the Language Model-based Determinant Point Process (LM-DPP) that simultaneously
considers the uncertainty and diversity of unlabeled instances for optimal
selection. Consequently, this yields a subset for annotation that strikes a
trade-off between the two factors. We apply LM-DPP to various language models,
including GPT-J, LlaMA, and GPT-3. Experimental results on 9 NLU and 2
Generation datasets demonstrate that LM-DPP can effectively select canonical
examples. Further analysis reveals that LLMs benefit most significantly from
subsets that are both low uncertainty and high diversity.

摘要：情境學習 (ICL) 是一種小樣本學習範例，涉及透過輸入輸出配對學習對應，並適當地將其應用於新個體。儘管大型語言模型 (LLM) 展示了非凡的 ICL 能力，但現有工作高度依賴於大規模標籤支援集，這在實際場景中並非總是可行。為了優化此方法，我們主要關注創新的選擇性標註機制，它先於標準示範檢索。我們引入了基於語言模型的確定點過程 (LM-DPP)，它同時考慮了未標籤個體的不確定性和多樣性，以進行最佳選擇。因此，這會產生一個標註子集，在兩個因素之間取得折衷。我們將 LM-DPP 應用於各種語言模型，包括 GPT-J、LlaMA 和 GPT-3。在 9 個 NLU 和 2 個生成資料集上的實驗結果表明，LM-DPP 可以有效地選擇典型範例。進一步的分析表明，LLM 最受益於不確定性低且多樣性高的子集。

##### **KAN-RCBEVDepth: A multi-modal fusion algorithm in object detection for autonomous driving**
2408.02088v1 by Zhihao Lai, Chuanhao Liu, Shihui Sheng, Zhiqiang Zhang

Accurate 3D object detection in autonomous driving is critical yet
challenging due to occlusions, varying object scales, and complex urban
environments. This paper introduces the RCBEV-KAN algorithm, a pioneering
method designed to enhance 3D object detection by fusing multimodal sensor data
from cameras, LiDAR, and millimeter-wave radar. Our innovative Bird's Eye View
(BEV)-based approach, utilizing a Transformer architecture, significantly
boosts detection precision and efficiency by seamlessly integrating diverse
data sources, improving spatial relationship handling, and optimizing
computational processes. Experimental results show that the RCBEV-KAN model
demonstrates superior performance across most detection categories, achieving
higher Mean Distance AP (0.389 vs. 0.316, a 23% improvement), better ND Score
(0.484 vs. 0.415, a 17% improvement), and faster Evaluation Time (71.28s, 8%
faster). These results indicate that RCBEV-KAN is more accurate, reliable, and
efficient, making it ideal for dynamic and challenging autonomous driving
environments.

摘要：在自動駕駛中，準確的 3D 物體偵測至關重要，但由於遮擋、物體比例變化和複雜的城市環境，這項任務也極具挑戰性。本文介紹了 RCBEV-KAN 演算法，這是一種先驅方法，旨在透過融合來自相機、LiDAR 和毫米波雷達的多模態感測器資料來增強 3D 物體偵測。我們創新的基於鳥瞰圖 (BEV) 的方法利用 Transformer 架構，透過無縫整合不同的資料來源、改善空間關係處理和最佳化運算流程，大幅提升偵測精準度和效率。實驗結果顯示，RCBEV-KAN 模型在大部分偵測類別中展現出優異的效能，達到了更高的平均距離 AP（0.389 對比 0.316，提升了 23%）、更好的 ND 分數（0.484 對比 0.415，提升了 17%）和更快的評估時間（71.28 秒，快了 8%）。這些結果表明，RCBEV-KAN 更準確、更可靠且更有效率，使其成為動態且具挑戰性的自動駕駛環境的理想選擇。

##### **Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data Assessment and Selection for Instruction Tuning of Language Models**
2408.02085v1 by Yulei Qin, Yuncheng Yang, Pengcheng Guo, Gang Li, Hang Shao, Yuchen Shi, Zihan Xu, Yun Gu, Ke Li, Xing Sun

Instruction tuning plays a critical role in aligning large language models
(LLMs) with human preference. Despite the vast amount of open instruction
datasets, naively training a LLM on all existing instructions may not be
optimal and practical. To pinpoint the most beneficial datapoints, data
assessment and selection methods have been proposed in the fields of natural
language processing (NLP) and deep learning. However, under the context of
instruction tuning, there still exists a gap in knowledge on what kind of data
evaluation metrics can be employed and how they can be integrated into the
selection mechanism. To bridge this gap, we present a comprehensive review on
existing literature of data assessment and selection especially for instruction
tuning of LLMs. We systematically categorize all applicable methods into
quality-based, diversity-based, and importance-based ones where a unified,
fine-grained taxonomy is structured. For each category, representative methods
are elaborated to describe the landscape of relevant research. In addition,
comparison between latest methods is conducted on their officially reported
results to provide in-depth discussions on their limitations. Finally, we
summarize the open challenges and propose the promosing avenues for future
studies. All related contents are available at
https://github.com/yuleiqin/fantastic-data-engineering.

摘要：指令微调在将大型语言模型（LLM）与人类偏好保持一致方面发挥着至关重要的作用。尽管有大量的开放式指令数据集，但天真地训练 LLM 来处理所有现有指令可能既不理想也不切实际。为了找出最有益的数据点，自然语言处理 (NLP) 和深度学习领域提出了数据评估和选择方法。然而，在指令微调的背景下，对于可以使用哪种数据评估指标以及如何将它们集成到选择机制中，仍然存在知识空白。为了弥补这一空白，我们对现有数据评估和选择文献进行了全面回顾，特别是针对 LLM 的指令微调。我们将所有适用的方法系统地分类为基于质量、基于多样性和基于重要性的方法，其中构建了一个统一的、细粒度的分类法。对于每个类别，我们详细阐述了代表性方法，以描述相关研究的概况。此外，我们根据其官方报告的结果对最新方法进行了比较，以深入讨论其局限性。最后，我们总结了开放性挑战，并提出了未来研究的有希望的途径。所有相关内容均可在 https://github.com/yuleiqin/fantastic-data-engineering 获得。

##### **MedSyn: LLM-based Synthetic Medical Text Generation Framework**
2408.02056v1 by Gleb Kumichev, Pavel Blinov, Yulia Kuzkina, Vasily Goncharov, Galina Zubkova, Nikolai Zenovkin, Aleksei Goncharov, Andrey Savchenko

Generating synthetic text addresses the challenge of data availability in
privacy-sensitive domains such as healthcare. This study explores the
applicability of synthetic data in real-world medical settings. We introduce
MedSyn, a novel medical text generation framework that integrates large
language models with a Medical Knowledge Graph (MKG). We use MKG to sample
prior medical information for the prompt and generate synthetic clinical notes
with GPT-4 and fine-tuned LLaMA models. We assess the benefit of synthetic data
through application in the ICD code prediction task. Our research indicates
that synthetic data can increase the classification accuracy of vital and
challenging codes by up to 17.8% compared to settings without synthetic data.
Furthermore, to provide new data for further research in the healthcare domain,
we present the largest open-source synthetic dataset of clinical notes for the
Russian language, comprising over 41k samples covering 219 ICD-10 codes.

摘要：合成文本的生成解决了隐私敏感领域（如医疗保健）中数据可用性的挑战。本研究探讨了合成数据在实际医疗环境中的适用性。我们引入了 MedSyn，这是一个新颖的医学文本生成框架，它将大型语言模型与医学知识图谱 (MKG) 相结合。我们使用 MKG 为提示采样先验医学信息，并使用 GPT-4 和微调的 LLaMA 模型生成合成临床注释。我们通过在 ICD 代码预测任务中的应用评估了合成数据的优势。我们的研究表明，与没有合成数据的设置相比，合成数据可以将重要且具有挑战性的代码的分类准确性提高多达 17.8%。此外，为了为医疗保健领域的进一步研究提供新数据，我们展示了最大的开放源代码合成数据集，其中包含超过 41k 个涵盖 219 个 ICD-10 代码的临床注释。

##### **Fine-tuning multilingual language models in Twitter/X sentiment analysis: a study on Eastern-European V4 languages**
2408.02044v1 by Tomáš Filip, Martin Pavlíček, Petr Sosík

The aspect-based sentiment analysis (ABSA) is a standard NLP task with
numerous approaches and benchmarks, where large language models (LLM) represent
the current state-of-the-art. We focus on ABSA subtasks based on Twitter/X data
in underrepresented languages. On such narrow tasks, small tuned language
models can often outperform universal large ones, providing available and cheap
solutions.
  We fine-tune several LLMs (BERT, BERTweet, Llama2, Llama3, Mistral) for
classification of sentiment towards Russia and Ukraine in the context of the
ongoing military conflict. The training/testing dataset was obtained from the
academic API from Twitter/X during 2023, narrowed to the languages of the V4
countries (Czech Republic, Slovakia, Poland, Hungary). Then we measure their
performance under a variety of settings including translations, sentiment
targets, in-context learning and more, using GPT4 as a reference model. We
document several interesting phenomena demonstrating, among others, that some
models are much better fine-tunable on multilingual Twitter tasks than others,
and that they can reach the SOTA level with a very small training set. Finally
we identify combinations of settings providing the best results.

摘要：基於面向方面的觀點分析 (ABSA) 是一項標準的 NLP 任務，有
許多方法和基準，其中大型語言模型 (LLM) 代表了當前技術水準。我們專注於基於 Twitter/X 資料的 ABSA 子任務，使用代表性不足的語言。在這些狹窄的任務中，經過微調的小語言模型通常可以優於通用的大型語言模型，提供可用且便宜的解決方案。
我們微調了多個 LLM（BERT、BERTweet、Llama2、Llama3、Mistral），以便在持續的軍事衝突背景下對俄羅斯和烏克蘭的情感進行分類。訓練/測試資料集是從 Twitter/X 的學術 API 在 2023 年獲得的，並縮小到 V4 國家的語言（捷克共和國、斯洛伐克、波蘭、匈牙利）。然後，我們使用 GPT4 作為參考模型，在各種設定（包括翻譯、情感目標、情境學習等）下衡量它們的效能。我們記錄了幾個有趣的現象，其中包括一些模型比其他模型更適合在多語言的 Twitter 任務上進行微調，而且它們可以使用非常小的訓練集達到 SOTA 水準。最後，我們找出提供最佳結果的設定組合。

##### **Self-Introspective Decoding: Alleviating Hallucinations for Large Vision-Language Models**
2408.02032v1 by Fushuo Huo, Wenchao Xu, Zhong Zhang, Haozhao Wang, Zhicheng Chen, Peilin Zhao

While Large Vision-Language Models (LVLMs) have rapidly advanced in recent
years, the prevalent issue known as the `hallucination' problem has emerged as
a significant bottleneck, hindering their real-world deployments. Existing
methods mitigate this issue mainly from two perspectives: One approach
leverages extra knowledge like robust instruction tuning LVLMs with curated
datasets or employing auxiliary analysis networks, which inevitable incur
additional costs. Another approach, known as contrastive decoding, induces
hallucinations by manually disturbing the vision or instruction raw inputs and
mitigates them by contrasting the outputs of the disturbed and original LVLMs.
However, these approaches rely on empirical holistic input disturbances and
double the inference cost. To avoid these issues, we propose a simple yet
effective method named Self-Introspective Decoding (SID). Our empirical
investigation reveals that pretrained LVLMs can introspectively assess the
importance of vision tokens based on preceding vision and text (both
instruction and generated) tokens. We develop the Context and Text-aware Token
Selection (CT2S) strategy, which preserves only unimportant vision tokens after
early layers of LVLMs to adaptively amplify text-informed hallucination during
the auto-regressive decoding. This approach ensures that multimodal knowledge
absorbed in the early layers induces multimodal contextual rather than aimless
hallucinations. Subsequently, the original token logits subtract the amplified
vision-and-text association hallucinations, guiding LVLMs decoding faithfully.
Extensive experiments illustrate SID generates less-hallucination and
higher-quality texts across various metrics, without extra knowledge and much
additional computation burdens.

摘要：<paragraph>儘管大型視覺語言模型 (LVLMs) 近年來迅速進步，但眾所周知的「幻覺」問題已成為一個重大的瓶頸，阻礙了它們在現實世界中的部署。現有的方法主要從兩個角度來緩解這個問題：一種方法利用額外的知識，例如使用經過整理的資料集對 LVLMs 進行穩健的指令調整，或採用輔助分析網路，這不可避免地會產生額外的成本。另一種稱為對比解碼的方法，則透過手動擾動視覺或指令原始輸入來誘發幻覺，並透過對比擾動和原始 LVLMs 的輸出結果來緩解幻覺。然而，這些方法依賴於經驗性的整體輸入擾動，並將推論成本增加一倍。為了避免這些問題，我們提出了一種簡單但有效的方法，稱為自省式解碼 (SID)。我們的經驗調查顯示，預訓練的 LVLMs 可以根據先前的視覺和文字（指令和產生的文字）代碼，內省地評估視覺代碼的重要性。我們開發了情境和文字感知代碼選擇 (CT2S) 策略，它僅在 LVLMs 的早期層之後保留不重要的視覺代碼，以在自迴歸解碼過程中適應性地放大文字引發的幻覺。這種方法確保了在早期層中吸收的多模態知識會引發多模態的上下文，而不是無目標的幻覺。隨後，原始代碼對數機率會減去放大的視覺和文字關聯幻覺，指導 LVLMs 忠實地解碼。廣泛的實驗表明，SID 在各種指標下產生的幻覺更少且文字品質更高，且沒有額外的知識和大量的額外運算負擔。</paragraph>

##### **Contrastive Learning-based Chaining-Cluster for Multilingual Voice-Face Association**
2408.02025v1 by Wuyang Chen, Yanjie Sun, Kele Xu, Yong Dou

The innate correlation between a person's face and voice has recently emerged
as a compelling area of study, especially within the context of multilingual
environments. This paper introduces our novel solution to the Face-Voice
Association in Multilingual Environments (FAME) 2024 challenge, focusing on a
contrastive learning-based chaining-cluster method to enhance face-voice
association. This task involves the challenges of building biometric relations
between auditory and visual modality cues and modelling the prosody
interdependence between different languages while addressing both intrinsic and
extrinsic variability present in the data. To handle these non-trivial
challenges, our method employs supervised cross-contrastive (SCC) learning to
establish robust associations between voices and faces in multi-language
scenarios. Following this, we have specifically designed a
chaining-cluster-based post-processing step to mitigate the impact of outliers
often found in unconstrained in the wild data. We conducted extensive
experiments to investigate the impact of language on face-voice association.
The overall results were evaluated on the FAME public evaluation platform,
where we achieved 2nd place. The results demonstrate the superior performance
of our method, and we validate the robustness and effectiveness of our proposed
approach. Code is available at https://github.com/colaudiolab/FAME24_solution.

摘要：人臉與聲音之間的內在關聯性最近浮現為一項引人入勝的研究領域，特別是在多語言環境的脈絡中。本文介紹我們在 2024 年多語言環境中的人臉與聲音關聯 (FAME) 挑戰中提出的創新解決方案，重點在於使用對比學習為基礎的鏈結群集方法來加強人臉與聲音的關聯性。此任務涉及建立聽覺和視覺模式提示之間的生物特徵關係，以及在處理資料中存在的內在和外在變異性的同時，模擬不同語言之間的韻律相互依賴性的挑戰。為了應對這些非同小可的挑戰，我們的模型採用監督式交叉對比 (SCC) 學習，以在多語言場景中建立聲音和人臉之間穩健的關聯性。在此之後，我們特別設計了一個基於鏈結群集的後處理步驟，以減輕在不受約束的野生資料中常見的異常值所造成的影響。我們進行了廣泛的實驗，以探討語言對人臉與聲音關聯性的影響。整體結果在 FAME 公開評估平台上進行評估，我們取得了第二名的成績。結果證明了我們方法的卓越效能，我們驗證了我們所提出的方法的穩健性和有效性。程式碼可於 https://github.com/colaudiolab/FAME24_solution 取得。

##### **Individualized multi-horizon MRI trajectory prediction for Alzheimer's Disease**
2408.02018v1 by Rosemary He, Gabriella Ang, Daniel Tward

Neurodegeneration as measured through magnetic resonance imaging (MRI) is
recognized as a potential biomarker for diagnosing Alzheimer's disease (AD),
but is generally considered less specific than amyloid or tau based biomarkers.
Due to a large amount of variability in brain anatomy between different
individuals, we hypothesize that leveraging MRI time series can help improve
specificity, by treating each patient as their own baseline. Here we turn to
conditional variational autoencoders to generate individualized MRI predictions
given the subject's age, disease status and one previous scan. Using serial
imaging data from the Alzheimer's Disease Neuroimaging Initiative, we train a
novel architecture to build a latent space distribution which can be sampled
from to generate future predictions of changing anatomy. This enables us to
extrapolate beyond the dataset and predict MRIs up to 10 years. We evaluated
the model on a held-out set from ADNI and an independent dataset (from Open
Access Series of Imaging Studies). By comparing to several alternatives, we
show that our model produces more individualized images with higher resolution.
Further, if an individual already has a follow-up MRI, we demonstrate a usage
of our model to compute a likelihood ratio classifier for disease status. In
practice, the model may be able to assist in early diagnosis of AD and provide
a counterfactual baseline trajectory for treatment effect estimation.
Furthermore, it generates a synthetic dataset that can potentially be used for
downstream tasks such as anomaly detection and classification.

摘要：透過磁振造影 (MRI) 測量的神經退化症被視為診斷阿茲海默症 (AD) 的潛在生物標記，但通常被認為比類澱粉或 tau 蛋白生物標記的特異性低。由於不同個體之間的腦部解剖結構有很大的變異性，我們假設利用 MRI 時間序列可以透過將每位患者視為其自己的基準線來幫助提高特異性。在此，我們求助於條件變異自動編碼器來生成個體化的 MRI 預測，給定受試者的年齡、疾病狀態和一次先前的掃描。使用阿茲海默症神經影像計劃的序列影像資料，我們訓練一個新穎的架構來建立一個潛在空間分佈，可以從中取樣以生成未來對解剖結構改變的預測。這使我們能夠外推資料集並預測長達 10 年的 MRI。我們在 ADNI 的保留組和一個獨立的資料集（來自影像研究的開放存取系列）上評估了該模型。透過與幾個替代方案進行比較，我們表明我們的模型產生了具有更高解析度、更個性化的影像。此外，如果個人已經有後續 MRI，我們展示了使用我們的模型來計算疾病狀態的似然比分類器。在實務中，該模型可能有助於 AD 的早期診斷，並提供一個反事實的基準軌跡以進行治療效果估計。此外，它會生成一個合成資料集，該資料集潛在地可用於下游任務，例如異常偵測和分類。

##### **Joint Learning of Emotions in Music and Generalized Sounds**
2408.02009v1 by Simonetta Federico, Certo Francesca, Ntalampiras Stavros

In this study, we aim to determine if generalized sounds and music can share
a common emotional space, improving predictions of emotion in terms of arousal
and valence. We propose the use of multiple datasets as a multi-domain learning
technique. Our approach involves creating a common space encompassing features
that characterize both generalized sounds and music, as they can evoke emotions
in a similar manner. To achieve this, we utilized two publicly available
datasets, namely IADS-E and PMEmo, following a standardized experimental
protocol. We employed a wide variety of features that capture diverse aspects
of the audio structure including key parameters of spectrum, energy, and
voicing. Subsequently, we performed joint learning on the common feature space,
leveraging heterogeneous model architectures. Interestingly, this synergistic
scheme outperforms the state-of-the-art in both sound and music emotion
prediction. The code enabling full replication of the presented experimental
pipeline is available at https://github.com/LIMUNIMI/MusicSoundEmotions.

摘要：在這項研究中，我們旨在確定廣泛的聲音和音樂是否可以共享一個共同的情緒空間，進而改善情緒預測，特別是喚醒和效價。我們提出使用多個資料集作為多領域學習技術。我們的做法包括建立一個共同的空間，包含特徵，以描述廣泛的聲音和音樂，因為它們可以用類似的方式喚起情緒。為了實現這個目標，我們利用了兩個公開可用的資料集，即 IADS-E 和 PMEmo，並遵循標準化的實驗協議。我們採用了各種特徵，以捕捉音訊結構的不同面向，包括頻譜、能量和發聲的主要參數。隨後，我們在共同的特徵空間上執行聯合學習，利用異質模型架構。有趣的是，這種協同方案優於聲音和音樂情緒預測的現有技術。啟用完整複製所呈現實驗管線的程式碼可以在 https://github.com/LIMUNIMI/MusicSoundEmotions 取得。

##### **LLaSA: Large Language and E-Commerce Shopping Assistant**
2408.02006v1 by Shuo Zhang, Boci Peng, Xinping Zhao, Boren Hu, Yun Zhu, Yanjia Zeng, Xuming Hu

The e-commerce platform has evolved rapidly due to its widespread popularity
and convenience. Developing an e-commerce shopping assistant for customers is
crucial to aiding them in quickly finding desired products and recommending
precisely what they need. However, most previous shopping assistants face two
main problems: (1) task-specificity, which necessitates the development of
different models for various tasks, thereby increasing development costs and
limiting effectiveness; and (2) poor generalization, where the trained model
performs inadequately on up-to-date products. To resolve these issues, we
employ Large Language Models (LLMs) to construct an omnipotent assistant,
leveraging their adeptness at handling multiple tasks and their superior
generalization capability. Nonetheless, LLMs lack inherent knowledge of
e-commerce concepts. To address this, we create an instruction dataset
comprising 65,000 samples and diverse tasks, termed as EshopInstruct. Through
instruction tuning on our dataset, the assistant, named LLaSA, demonstrates the
potential to function as an omnipotent assistant. Additionally, we propose
various inference optimization strategies to enhance performance with limited
inference resources. In the Amazon KDD Cup 2024 Challenge, our proposed method,
LLaSA, achieved an overall ranking of 3rd place on ShopBench, including 57
tasks and approximately 20,000 questions, and we secured top-5 rankings in each
track, especially in track4, where we achieved the best performance result
among all student teams. Our extensive practices fully demonstrate that LLMs
possess the great potential to be competent e-commerce shopping assistants.

摘要：<paragraph>由於電子商務平台的廣泛普及和便利性，它已迅速發展。為客戶開發電子商務購物助理對於協助他們快速找到所需的產品並準確推薦他們需要什麼至關重要。然而，大多數以前的購物助理面臨兩個主要問題：(1) 任務專一性，這需要為各種任務開發不同的模型，從而增加開發成本並限制效能；(2) 概化能力差，訓練好的模型在最新產品上的表現不佳。為了解決這些問題，我們採用大型語言模型 (LLM) 來建構一個全能的助理，利用它們擅長處理多項任務和卓越的概化能力。儘管如此，LLM 缺乏電子商務概念的內在知識。為了解決這個問題，我們建立了一個包含 65,000 個範例和各種任務的教學資料集，稱為 EshopInstruct。透過對我們的資料集進行教學調整，名為 LLaSA 的助理證明了作為全能助理運作的潛力。此外，我們提出各種推論最佳化策略，以增強效能並限制推論資源。在 Amazon KDD Cup 2024 挑戰賽中，我們提出的方法 LLaSA 在 ShopBench 上獲得了第 3 名的總排名，其中包括 57 項任務和約 20,000 個問題，而且我們在每個軌道上都獲得了前 5 名的排名，特別是在軌道 4 中，我們在所有學生團隊中取得了最佳表現。我們的廣泛實務充分證明 LLM 具有成為稱職的電子商務購物助理的巨大潛力。</paragraph>

##### **Reinforcement Learning for an Efficient and Effective Malware Investigation during Cyber Incident Response**
2408.01999v1 by Dipo Dunsin, Mohamed Chahine Ghanem, Karim Ouazzane, Vassil Vassilev

This research focused on enhancing post-incident malware forensic
investigation using reinforcement learning RL. We proposed an advanced MDP post
incident malware forensics investigation model and framework to expedite post
incident forensics. We then implement our RL Malware Investigation Model based
on structured MDP within the proposed framework. To identify malware artefacts,
the RL agent acquires and examines forensics evidence files, iteratively
improving its capabilities using Q Table and temporal difference learning. The
Q learning algorithm significantly improved the agent ability to identify
malware. An epsilon greedy exploration strategy and Q learning updates enabled
efficient learning and decision making. Our experimental testing revealed that
optimal learning rates depend on the MDP environment complexity, with simpler
environments benefiting from higher rates for quicker convergence and complex
ones requiring lower rates for stability. Our model performance in identifying
and classifying malware reduced malware analysis time compared to human
experts, demonstrating robustness and adaptability. The study highlighted the
significance of hyper parameter tuning and suggested adaptive strategies for
complex environments. Our RL based approach produced promising results and is
validated as an alternative to traditional methods notably by offering
continuous learning and adaptation to new and evolving malware threats which
ultimately enhance the post incident forensics investigations.

摘要：本研究專注於使用強化學習 RL 來增強事件後惡意軟體鑑識調查。我們提出了一個先進的事件後 MDP 惡意軟體鑑識調查模型和架構，以加速事件後的鑑識。接著，我們在建議的架構內，根據結構化的 MDP 實作我們的 RL 惡意軟體調查模型。為了識別惡意軟體人工製品，RL 代理取得並檢查鑑識證據檔案，使用 Q 表和時間差分學習反覆改善其功能。Q 學習演算法大幅提升了代理識別惡意軟體的能力。epsilon 貪婪探索策略和 Q 學習更新啟用了有效的學習和決策制定。我們的實驗測試顯示，最佳學習率取決於 MDP 環境的複雜性，較簡單的環境受益於較高的比率，以實現更快的收斂，而複雜的環境則需要較低的比率以維持穩定性。我們的模型在識別和分類惡意軟體方面的效能，與人類專家相比，減少了惡意軟體分析時間，展示了穩健性和適應性。這項研究強調了超參數調整的重要性，並建議了複雜環境的適應性策略。我們基於 RL 的方法產出了有希望的結果，並驗證為傳統方法的替代方案，特別是透過提供持續學習和適應新的和不斷演化的惡意軟體威脅，最終增強事件後的鑑識調查。

##### **MetaWearS: A Shortcut in Wearable Systems Lifecycle with Only a Few Shots**
2408.01988v1 by Alireza Amirshahi, Maedeh H. Toosi, Siamak Mohammadi, Stefano Albini, Pasquale Davide Schiavone, Giovanni Ansaloni, Amir Aminifar, David Atienza

Wearable systems provide continuous health monitoring and can lead to early
detection of potential health issues. However, the lifecycle of wearable
systems faces several challenges. First, effective model training for new
wearable devices requires substantial labeled data from various subjects
collected directly by the wearable. Second, subsequent model updates require
further extensive labeled data for retraining. Finally, frequent model updating
on the wearable device can decrease the battery life in long-term data
monitoring. Addressing these challenges, in this paper, we propose MetaWearS, a
meta-learning method to reduce the amount of initial data collection required.
Moreover, our approach incorporates a prototypical updating mechanism,
simplifying the update process by modifying the class prototype rather than
retraining the entire model. We explore the performance of MetaWearS in two
case studies, namely, the detection of epileptic seizures and the detection of
atrial fibrillation. We show that by fine-tuning with just a few samples, we
achieve 70% and 82% AUC for the detection of epileptic seizures and the
detection of atrial fibrillation, respectively. Compared to a conventional
approach, our proposed method performs better with up to 45% AUC. Furthermore,
updating the model with only 16 minutes of additional labeled data increases
the AUC by up to 5.3%. Finally, MetaWearS reduces the energy consumption for
model updates by 456x and 418x for epileptic seizure and AF detection,
respectively.

摘要：<paragraph>穿戴式系統提供持續的健康監測，並可及早偵測潛在的健康問題。然而，穿戴式系統的生命週期面臨幾個挑戰。首先，新穿戴式裝置的有效模型訓練需要從各種受試者收集的大量標籤資料，且資料必須直接由穿戴式裝置收集。其次，後續的模型更新需要進一步的大量標籤資料才能重新訓練。最後，穿戴式裝置上頻繁的模型更新會縮短長期資料監測的電池續航力。為了應對這些挑戰，我們在本文中提出 MetaWearS，這是一種元學習方法，可減少所需的初始資料收集量。此外，我們的方法結合了一個原型更新機制，透過修改類別原型而非重新訓練整個模型來簡化更新過程。我們在兩個案例研究中探討 MetaWearS 的效能，分別是癲癇發作偵測和心房顫動偵測。我們展示了透過微調僅少數樣本，我們分別在癲癇發作偵測和心房顫動偵測中達到 70% 和 82% 的 AUC。與傳統方法相比，我們提出的方法表現更好，AUC 最高可達 45%。此外，僅使用 16 分鐘的額外標籤資料更新模型，即可將 AUC 提高多達 5.3%。最後，MetaWearS 分別將癲癇發作和心房顫動偵測的模型更新能耗降低了 456 倍和 418 倍。</paragraph>

##### **DeMansia: Mamba Never Forgets Any Tokens**
2408.01986v1 by Ricky Fang

This paper examines the mathematical foundations of transformer
architectures, highlighting their limitations particularly in handling long
sequences. We explore prerequisite models such as Mamba, Vision Mamba (ViM),
and LV-ViT that pave the way for our proposed architecture, DeMansia. DeMansia
integrates state space models with token labeling techniques to enhance
performance in image classification tasks, efficiently addressing the
computational challenges posed by traditional transformers. The architecture,
benchmark, and comparisons with contemporary models demonstrate DeMansia's
effectiveness. The implementation of this paper is available on GitHub at
https://github.com/catalpaaa/DeMansia

摘要：本文探討了 Transformer 架構的數學基礎，特別強調了它們在處理長序列時的限制。我們探討了 Mamba、Vision Mamba (ViM) 和 LV-ViT 等先決條件模型，為我們提出的架構 DeMansia 鋪平了道路。DeMansia 將狀態空間模型與標記技術整合，以增強圖像分類任務的效能，有效地解決傳統 Transformer 所帶來的計算挑戰。此架構、基準和與當代模型的比較證明了 DeMansia 的效能。本文的實作可在 GitHub 上取得，網址為 https://github.com/catalpaaa/DeMansia

##### **SR-CIS: Self-Reflective Incremental System with Decoupled Memory and Reasoning**
2408.01970v1 by Biqing Qi, Junqi Gao, Xinquan Chen, Dong Li, Weinan Zhang, Bowen Zhou

The ability of humans to rapidly learn new knowledge while retaining old
memories poses a significant challenge for current deep learning models. To
handle this challenge, we draw inspiration from human memory and learning
mechanisms and propose the Self-Reflective Complementary Incremental System
(SR-CIS). Comprising the deconstructed Complementary Inference Module (CIM) and
Complementary Memory Module (CMM), SR-CIS features a small model for fast
inference and a large model for slow deliberation in CIM, enabled by the
Confidence-Aware Online Anomaly Detection (CA-OAD) mechanism for efficient
collaboration. CMM consists of task-specific Short-Term Memory (STM) region and
a universal Long-Term Memory (LTM) region. By setting task-specific Low-Rank
Adaptive (LoRA) and corresponding prototype weights and biases, it instantiates
external storage for parameter and representation memory, thus deconstructing
the memory module from the inference module. By storing textual descriptions of
images during training and combining them with the Scenario Replay Module (SRM)
post-training for memory combination, along with periodic short-to-long-term
memory restructuring, SR-CIS achieves stable incremental memory with limited
storage requirements. Balancing model plasticity and memory stability under
constraints of limited storage and low data resources, SR-CIS surpasses
existing competitive baselines on multiple standard and few-shot incremental
learning benchmarks.

摘要：人類快速學習新知識的同時，還能保留舊記憶的能力，對目前的深度學習模型來說是一項重大的挑戰。為了應對這項挑戰，我們從人類的記憶和學習機制中汲取靈感，並提出自我反省的互補增量系統 (SR-CIS)。SR-CIS 由解構的互補推論模組 (CIM) 和互補記憶模組 (CMM) 組成，其特點是在 CIM 中有一個用於快速推論的小模型和一個用於緩慢思考的大模型，並由信心感知線上異常偵測 (CA-OAD) 機制實現高效協作。CMM 由特定任務的短期記憶 (STM) 區域和一個通用的長期記憶 (LTM) 區域組成。通過設定特定任務的低秩自適應 (LoRA) 和對應的原型權重和偏差，它實例化了參數和表示記憶的外部儲存，從而將記憶模組從推論模組中解構。通過在訓練期間儲存影像的文字描述，並將它們與訓練後的場景重播模組 (SRM) 結合起來進行記憶組合，以及定期的短期到長期記憶重組，SR-CIS 在有限的儲存需求下實現穩定的增量記憶。在有限的儲存和低資料資源的約束下，平衡模型可塑性和記憶穩定性，SR-CIS 在多個標準和少次增量學習基準上超越了現有的競爭基準。

##### **Optimal and efficient text counterfactuals using Graph Neural Networks**
2408.01969v1 by Dimitris Lymperopoulos, Maria Lymperaiou, Giorgos Filandrianos, Giorgos Stamou

As NLP models become increasingly integral to decision-making processes, the
need for explainability and interpretability has become paramount. In this
work, we propose a framework that achieves the aforementioned by generating
semantically edited inputs, known as counterfactual interventions, which change
the model prediction, thus providing a form of counterfactual explanations for
the model. We test our framework on two NLP tasks - binary sentiment
classification and topic classification - and show that the generated edits are
contrastive, fluent and minimal, while the whole process remains significantly
faster that other state-of-the-art counterfactual editors.

摘要：隨著 NLP 模型在決策過程中扮演的角色日益吃重，對於可解釋性和可詮釋性的需求也變得至關重要。在這項工作中，我們提出一個架構，透過產生語義編輯的輸入（稱為反事實介入）來達成上述目標，這些輸入會改變模型預測，進而提供模型的反事實解釋形式。我們在兩個 NLP 任務上測試我們的架構，分別是二元情緒分類和主題分類，並顯示產生的編輯具有對比性、流暢性和最小性，同時整個過程仍然比其他最先進的反事實編輯器快得多。

##### **ML-EAT: A Multilevel Embedding Association Test for Interpretable and Transparent Social Science**
2408.01966v1 by Robert Wolfe, Alexis Hiniker, Bill Howe

This research introduces the Multilevel Embedding Association Test (ML-EAT),
a method designed for interpretable and transparent measurement of intrinsic
bias in language technologies. The ML-EAT addresses issues of ambiguity and
difficulty in interpreting the traditional EAT measurement by quantifying bias
at three levels of increasing granularity: the differential association between
two target concepts with two attribute concepts; the individual effect size of
each target concept with two attribute concepts; and the association between
each individual target concept and each individual attribute concept. Using the
ML-EAT, this research defines a taxonomy of EAT patterns describing the nine
possible outcomes of an embedding association test, each of which is associated
with a unique EAT-Map, a novel four-quadrant visualization for interpreting the
ML-EAT. Empirical analysis of static and diachronic word embeddings, GPT-2
language models, and a CLIP language-and-image model shows that EAT patterns
add otherwise unobservable information about the component biases that make up
an EAT; reveal the effects of prompting in zero-shot models; and can also
identify situations when cosine similarity is an ineffective metric, rendering
an EAT unreliable. Our work contributes a method for rendering bias more
observable and interpretable, improving the transparency of computational
investigations into human minds and societies.

摘要：這項研究引入了多層嵌入關聯檢定 (ML-EAT)，一種方法，設計用於對語言技術中的內在偏見進行可解釋且透明的測量。ML-EAT 透過量化三個層級日益細緻的偏見，來解決傳統 EAT 測量中含糊不清和難於解釋的問題：兩個目標概念與兩個屬性概念之間的差異關聯；每個目標概念與兩個屬性概念的個別效應量；以及每個個別目標概念與每個個別屬性概念之間的關聯。透過使用 ML-EAT，這項研究定義了一套 EAT 模式分類法，描述嵌入關聯檢定的九種可能結果，每種結果都與一個獨特的 EAT-Map 關聯，這是一種新穎的四象限視覺化，用於解釋 ML-EAT。對靜態和歷時詞嵌入、GPT-2 語言模型以及 CLIP 語言和圖像模型的實證分析顯示，EAT 模式增加了關於組成 EAT 的組成偏見的原本無法觀察到的資訊；揭示了在零次學習模型中提示的效果；並且還能識別出當餘弦相似度是一個無效指標時的情況，使 EAT 變得不可靠。我們的研究貢獻了一種方法，用於使偏見更具可觀察性和可解釋性，進而改善對人類心智和社會的運算調查的透明度。

##### **Top K Enhanced Reinforcement Learning Attacks on Heterogeneous Graph Node Classification**
2408.01964v1 by Honglin Gao, Gaoxi Xiao

Graph Neural Networks (GNNs) have attracted substantial interest due to their
exceptional performance on graph-based data. However, their robustness,
especially on heterogeneous graphs, remains underexplored, particularly against
adversarial attacks. This paper proposes HeteroKRLAttack, a targeted evasion
black-box attack method for heterogeneous graphs. By integrating reinforcement
learning with a Top-K algorithm to reduce the action space, our method
efficiently identifies effective attack strategies to disrupt node
classification tasks. We validate the effectiveness of HeteroKRLAttack through
experiments on multiple heterogeneous graph datasets, showing significant
reductions in classification accuracy compared to baseline methods. An ablation
study underscores the critical role of the Top-K algorithm in enhancing attack
performance. Our findings highlight potential vulnerabilities in current models
and provide guidance for future defense strategies against adversarial attacks
on heterogeneous graphs.

摘要：圖形神經網路 (GNN) 因其在基於圖形的數據上的卓越表現而備受關注。然而，它們的穩健性，特別是在異質圖形上，仍未得到充分探討，特別是針對對抗性攻擊。本文提出 HeteroKRLAttack，一種針對異質圖形的目標性規避黑盒攻擊方法。通過將強化學習與 Top-K 演算法整合以減少動作空間，我們的模型有效地識別出破壞節點分類任務的有效攻擊策略。我們透過在多個異質圖形資料集上進行實驗，驗證了 HeteroKRLAttack 的有效性，與基準方法相比，分類準確度顯著降低。消融研究強調了 Top-K 演算法在增強攻擊效能中的關鍵作用。我們的發現突顯了當前模型中潛在的漏洞，並為針對異質圖形上對抗性攻擊的未來防禦策略提供指導。

##### **A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios**
2408.01963v1 by Samuel Ackerman, Ella Rabinovich, Eitan Farchi, Ateret Anaby-Tavor

We evaluate the robustness of several large language models on multiple
datasets. Robustness here refers to the relative insensitivity of the model's
answers to meaning-preserving variants of their input. Benchmark datasets are
constructed by introducing naturally-occurring, non-malicious perturbations, or
by generating semantically equivalent paraphrases of input questions or
statements. We further propose a novel metric for assessing a model robustness,
and demonstrate its benefits in the non-adversarial scenario by empirical
evaluation of several models on the created datasets.

摘要：我們評估多個大型語言模型在多個資料集上的健壯性。此處的健壯性是指模型的答案對其輸入的保留意義變體的相對不敏感性。基準資料集是透過引入自然發生的、非惡意的擾動，或透過產生語義等效的輸入問題或陳述的同義詞而建構的。我們進一步提出一個新的指標來評估模型的健壯性，並透過在建立的資料集上對多個模型進行經驗評估，證明其在非對抗情境中的優點。

##### **The Implications of Open Generative Models in Human-Centered Data Science Work: A Case Study with Fact-Checking Organizations**
2408.01962v1 by Robert Wolfe, Tanushree Mitra

Calls to use open generative language models in academic research have
highlighted the need for reproducibility and transparency in scientific
research. However, the impact of generative AI extends well beyond academia, as
corporations and public interest organizations have begun integrating these
models into their data science pipelines. We expand this lens to include the
impact of open models on organizations, focusing specifically on fact-checking
organizations, which use AI to observe and analyze large volumes of circulating
misinformation, yet must also ensure the reproducibility and impartiality of
their work. We wanted to understand where fact-checking organizations use open
models in their data science pipelines; what motivates their use of open models
or proprietary models; and how their use of open or proprietary models can
inform research on the societal impact of generative AI. To answer these
questions, we conducted an interview study with N=24 professionals at 20
fact-checking organizations on six continents. Based on these interviews, we
offer a five-component conceptual model of where fact-checking organizations
employ generative AI to support or automate parts of their data science
pipeline, including Data Ingestion, Data Analysis, Data Retrieval, Data
Delivery, and Data Sharing. We then provide taxonomies of fact-checking
organizations' motivations for using open models and the limitations that
prevent them for further adopting open models, finding that they prefer open
models for Organizational Autonomy, Data Privacy and Ownership, Application
Specificity, and Capability Transparency. However, they nonetheless use
proprietary models due to perceived advantages in Performance, Usability, and
Safety, as well as Opportunity Costs related to participation in emerging
generative AI ecosystems. Our work provides novel perspective on open models in
data-driven organizations.

摘要：<paragraph>在學術研究中使用開放式生成語言模型的呼聲強調了科學研究中可複製性和透明度的必要性。然而，生成式 AI 的影響遠遠超出了學術界，因為企業和公共利益組織已開始將這些模型整合到其資料科學管道中。我們擴展此觀點，將開放模型對組織的影響納入考量，特別關注事實查核組織，這些組織使用 AI 來觀察和分析大量流傳的錯誤資訊，但同時也必須確保其工作的可複製性和公正性。我們想要了解事實查核組織在其資料科學管道中使用開放模型的位置；是什麼動機促使他們使用開放模型或專有模型；以及他們如何使用開放模型或專有模型，可以為生成式 AI 對社會的影響提供研究資訊。為了回答這些問題，我們對六大洲 20 個事實查核組織的 24 位專業人員進行了訪談研究。根據這些訪談，我們提供了事實查核組織使用生成式 AI 來支援或自動化其資料科學管道部分的五個組成概念模型，包括資料擷取、資料分析、資料檢索、資料傳輸和資料共享。然後，我們提供了事實查核組織使用開放模型的動機分類法，以及阻礙他們進一步採用開放模型的限制，發現他們偏好開放模型，原因在於組織自主性、資料隱私和所有權、應用程式特殊性以及功能透明度。然而，他們仍然使用專有模型，因為他們認為專有模型在效能、可用性和安全性方面具有優勢，以及與參與新興生成式 AI 生態系統相關的機會成本。我們的研究為資料驅動組織中的開放模型提供了新穎的觀點。</paragraph>

##### **Representation Bias of Adolescents in AI: A Bilingual, Bicultural Study**
2408.01961v1 by Robert Wolfe, Aayushi Dangol, Bill Howe, Alexis Hiniker

Popular and news media often portray teenagers with sensationalism, as both a
risk to society and at risk from society. As AI begins to absorb some of the
epistemic functions of traditional media, we study how teenagers in two
countries speaking two languages: 1) are depicted by AI, and 2) how they would
prefer to be depicted. Specifically, we study the biases about teenagers
learned by static word embeddings (SWEs) and generative language models (GLMs),
comparing these with the perspectives of adolescents living in the U.S. and
Nepal. We find English-language SWEs associate teenagers with societal
problems, and more than 50% of the 1,000 words most associated with teenagers
in the pretrained GloVe SWE reflect such problems. Given prompts about
teenagers, 30% of outputs from GPT2-XL and 29% from LLaMA-2-7B GLMs discuss
societal problems, most commonly violence, but also drug use, mental illness,
and sexual taboo. Nepali models, while not free of such associations, are less
dominated by social problems. Data from workshops with N=13 U.S. adolescents
and N=18 Nepalese adolescents show that AI presentations are disconnected from
teenage life, which revolves around activities like school and friendship.
Participant ratings of how well 20 trait words describe teens are decorrelated
from SWE associations, with Pearson's r=.02, n.s. in English FastText and
r=.06, n.s. in GloVe; and r=.06, n.s. in Nepali FastText and r=-.23, n.s. in
GloVe. U.S. participants suggested AI could fairly present teens by
highlighting diversity, while Nepalese participants centered positivity.
Participants were optimistic that, if it learned from adolescents, rather than
media sources, AI could help mitigate stereotypes. Our work offers an
understanding of the ways SWEs and GLMs misrepresent a developmentally
vulnerable group and provides a template for less sensationalized
characterization.

摘要：<paragraph>流行和新聞媒體經常以聳動的方式描繪青少年，既是對社會的風險，也是社會的風險。隨著 AI 開始吸收傳統媒體的一些認識論功能，我們研究了兩個國家講兩種語言的青少年：1) 如何被 AI 描繪，以及 2) 他們希望如何被描繪。具體來說，我們研究了靜態詞嵌入 (SWE) 和生成語言模型 (GLM) 學習到的關於青少年的偏見，並將這些偏見與居住在美國和尼泊爾的青少年的觀點進行比較。我們發現英語 SWE 將青少年與社會問題聯繫起來，在預訓練的 GloVe SWE 中與青少年最相關的 1,000 個單詞中，有 50% 以上反映了這些問題。對於關於青少年的提示，GPT2-XL 的 30% 的輸出和 LLaMA-2-7B GLM 的 29% 討論了社會問題，最常見的是暴力，還有吸毒、精神疾病和性禁忌。尼泊爾模型雖然沒有擺脫這些聯想，但不太受社會問題的支配。來自與 N=13 名美國青少年和 N=18 名尼泊爾青少年舉辦的工作坊的數據表明，AI 展示與青少年生活脫節，而青少年生活圍繞著學校和友誼等活動。參與者對 20 個特質詞描述青少年程度的評分與 SWE 聯想無關，皮爾森相關係數在英語 FastText 中為 r=.02，n.s.，在 GloVe 中為 r=.06，n.s.；在尼泊爾 FastText 中為 r=.06，n.s.，在 GloVe 中為 r=-.23，n.s。美國參與者建議 AI 可以通過強調多樣性來公正地展示青少年，而尼泊爾參與者則以積極性為中心。參與者樂觀地認為，如果 AI 從青少年而不是媒體來源學習，它可以幫助減輕刻板印象。我們的研究有助於了解 SWE 和 GLM 錯誤描述發育脆弱群體的方式，並為不那麼聳人聽聞的刻畫提供了一個模板。</paragraph>

##### **AnomalySD: Few-Shot Multi-Class Anomaly Detection with Stable Diffusion Model**
2408.01960v1 by Zhenyu Yan, Qingqing Fang, Wenxi Lv, Qinliang Su

Anomaly detection is a critical task in industrial manufacturing, aiming to
identify defective parts of products. Most industrial anomaly detection methods
assume the availability of sufficient normal data for training. This assumption
may not hold true due to the cost of labeling or data privacy policies.
Additionally, mainstream methods require training bespoke models for different
objects, which incurs heavy costs and lacks flexibility in practice. To address
these issues, we seek help from Stable Diffusion (SD) model due to its
capability of zero/few-shot inpainting, which can be leveraged to inpaint
anomalous regions as normal. In this paper, a few-shot multi-class anomaly
detection framework that adopts Stable Diffusion model is proposed, named
AnomalySD. To adapt SD to anomaly detection task, we design different
hierarchical text descriptions and the foreground mask mechanism for
fine-tuning SD. In the inference stage, to accurately mask anomalous regions
for inpainting, we propose multi-scale mask strategy and prototype-guided mask
strategy to handle diverse anomalous regions. Hierarchical text prompts are
also utilized to guide the process of inpainting in the inference stage. The
anomaly score is estimated based on inpainting result of all masks. Extensive
experiments on the MVTec-AD and VisA datasets demonstrate the superiority of
our approach. We achieved anomaly classification and segmentation results of
93.6%/94.8% AUROC on the MVTec-AD dataset and 86.1%/96.5% AUROC on the VisA
dataset under multi-class and one-shot settings.

摘要：異常偵測是工業製造中的一項重要任務，旨在識別產品的瑕疵部分。大多數工業異常偵測方法假設有足夠的正常資料可用於訓練。由於標記或資料隱私政策的成本，此假設可能不成立。此外，主流方法需要為不同的物件訓練客製化模型，這會產生高昂的成本，且在實務上缺乏彈性。為了解決這些問題，我們尋求 Stable Diffusion（SD）模型的協助，因為它具有零/少次數 inpainting 的能力，可用於將異常區域 inpaint 為正常。在本文中，提出了一個採用 Stable Diffusion 模型的少次數多類別異常偵測架構，命名為 AnomalySD。為了將 SD 調整為異常偵測任務，我們設計了不同的階層式文字描述和前景遮罩機制，用於微調 SD。在推論階段，為了準確遮罩異常區域以進行 inpainting，我們提出了多尺度遮罩策略和原型引導遮罩策略來處理不同的異常區域。階層式文字提示也用於引導推論階段的 inpainting 程序。異常分數是根據所有遮罩的 inpainting 結果估計的。在 MVTec-AD 和 VisA 資料集上的廣泛實驗證明了我們方法的優越性。在多類別和一次性設定下，我們在 MVTec-AD 資料集上達到了 93.6%/94.8% AUROC 的異常分類和分割結果，在 VisA 資料集上達到了 86.1%/96.5% AUROC。

##### **Dataset Scale and Societal Consistency Mediate Facial Impression Bias in Vision-Language AI**
2408.01959v1 by Robert Wolfe, Aayushi Dangol, Alexis Hiniker, Bill Howe

Multimodal AI models capable of associating images and text hold promise for
numerous domains, ranging from automated image captioning to accessibility
applications for blind and low-vision users. However, uncertainty about bias
has in some cases limited their adoption and availability. In the present work,
we study 43 CLIP vision-language models to determine whether they learn
human-like facial impression biases, and we find evidence that such biases are
reflected across three distinct CLIP model families. We show for the first time
that the the degree to which a bias is shared across a society predicts the
degree to which it is reflected in a CLIP model. Human-like impressions of
visually unobservable attributes, like trustworthiness and sexuality, emerge
only in models trained on the largest dataset, indicating that a better fit to
uncurated cultural data results in the reproduction of increasingly subtle
social biases. Moreover, we use a hierarchical clustering approach to show that
dataset size predicts the extent to which the underlying structure of facial
impression bias resembles that of facial impression bias in humans. Finally, we
show that Stable Diffusion models employing CLIP as a text encoder learn facial
impression biases, and that these biases intersect with racial biases in Stable
Diffusion XL-Turbo. While pretrained CLIP models may prove useful for
scientific studies of bias, they will also require significant dataset curation
when intended for use as general-purpose models in a zero-shot setting.

摘要：多模態 AI 模型能夠將圖像和文字聯想起來，對許多領域來說都很有前景，從自動化圖片標題到為失明和視力低下的使用者提供的輔助應用程式。然而，在某些情況下，對於偏差的不確定性限制了它們的採用和可用性。在目前的工作中，我們研究了 43 個 CLIP 視覺語言模型，以確定它們是否會學習類似人類的臉部印象偏差，並且我們發現證據表明此類偏差反映在三個不同的 CLIP 模型系列中。我們首次展示了一個社會中偏差被共享的程度預測了它在 CLIP 模型中被反映的程度。對視覺上不可觀察屬性的類人印象，例如可信度和性，僅出現在在最大的資料集上訓練的模型中，這表明與未整理的文化資料更好的擬合導致越來越微妙的社會偏差的再現。此外，我們使用階層式聚類方法來表明資料集大小預測了臉部印象偏差的底層結構與人類臉部印象偏差的底層結構相似的程度。最後，我們展示了採用 CLIP 作為文字編碼器的 Stable Diffusion 模型學習了臉部印象偏差，並且這些偏差與 Stable Diffusion XL-Turbo 中的種族偏差相交。雖然預訓練的 CLIP 模型可能被證明對偏差的科學研究很有用，但當它們打算在零次學習設定中用作通用模型時，它們也需要大量的資料集整理。

##### **Why Perturbing Symbolic Music is Necessary: Fitting the Distribution of Never-used Notes through a Joint Probabilistic Diffusion Model**
2408.01950v1 by Shipei Liu, Xiaoya Fan, Guowei Wu

Existing music generation models are mostly language-based, neglecting the
frequency continuity property of notes, resulting in inadequate fitting of rare
or never-used notes and thus reducing the diversity of generated samples. We
argue that the distribution of notes can be modeled by translational invariance
and periodicity, especially using diffusion models to generalize notes by
injecting frequency-domain Gaussian noise. However, due to the low-density
nature of music symbols, estimating the distribution of notes latent in the
high-density solution space poses significant challenges. To address this
problem, we introduce the Music-Diff architecture, which fits a joint
distribution of notes and accompanying semantic information to generate
symbolic music conditionally. We first enhance the fragmentation module for
extracting semantics by using event-based notations and the structural
similarity index, thereby preventing boundary blurring. As a prerequisite for
multivariate perturbation, we introduce a joint pre-training method to
construct the progressions between notes and musical semantics while avoiding
direct modeling of low-density notes. Finally, we recover the perturbed notes
by a multi-branch denoiser that fits multiple noise objectives via Pareto
optimization. Our experiments suggest that in contrast to language models,
joint probability diffusion models perturbing at both note and semantic levels
can provide more sample diversity and compositional regularity. The case study
highlights the rhythmic advantages of our model over language- and DDPMs-based
models by analyzing the hierarchical structure expressed in the self-similarity
metrics.

摘要：現有的音樂生成模型大多基於語言，忽略了音符的頻率連續性，導致罕見或從未使用的音符不適配，從而降低了生成樣本的多樣性。我們認為音符的分布可以用平移不變性和週期性來建模，特別是使用擴散模型通過注入頻域高斯噪聲來概括音符。然而，由於音樂符號的低密度特性，估計隱藏在高密度解空間中的音符分佈提出了重大挑戰。為了解決這個問題，我們引入了 Music-Diff 架構，它擬合音符和伴隨語義信息的聯合分佈，以有條件地生成符號音樂。我們首先通過使用基於事件的符號和結構相似性指數來增強提取語義的分割模組，從而防止邊界模糊。作為多元微擾的先決條件，我們引入了一種聯合預訓練方法，用於構建音符和音樂語義之間的進程，同時避免直接對低密度音符進行建模。最後，我們通過一個多分支去噪器恢復受擾音符，該去噪器通過帕累托優化擬合多個噪聲目標。我們的實驗表明，與語言模型相比，在音符和語義層面同時進行微擾的聯合概率擴散模型可以提供更多的樣本多樣性和組合規律性。案例研究通過分析自相似度指標中表達的分層結構，突出了我們的模型相對於基於語言和 DDPM 的模型的節奏優勢。

##### **Visual Grounding for Object-Level Generalization in Reinforcement Learning**
2408.01942v1 by Haobin Jiang, Zongqing Lu

Generalization is a pivotal challenge for agents following natural language
instructions. To approach this goal, we leverage a vision-language model (VLM)
for visual grounding and transfer its vision-language knowledge into
reinforcement learning (RL) for object-centric tasks, which makes the agent
capable of zero-shot generalization to unseen objects and instructions. By
visual grounding, we obtain an object-grounded confidence map for the target
object indicated in the instruction. Based on this map, we introduce two routes
to transfer VLM knowledge into RL. Firstly, we propose an object-grounded
intrinsic reward function derived from the confidence map to more effectively
guide the agent towards the target object. Secondly, the confidence map offers
a more unified, accessible task representation for the agent's policy, compared
to language embeddings. This enables the agent to process unseen objects and
instructions through comprehensible visual confidence maps, facilitating
zero-shot object-level generalization. Single-task experiments prove that our
intrinsic reward significantly improves performance on challenging skill
learning. In multi-task experiments, through testing on tasks beyond the
training set, we show that the agent, when provided with the confidence map as
the task representation, possesses better generalization capabilities than
language-based conditioning. The code is available at
https://github.com/PKU-RL/COPL.

摘要：泛化對於遵循自然語言指令的代理人而言是一項關鍵挑戰。為了達成此目標，我們利用視覺語言模型 (VLM) 來進行視覺基礎，並將其視覺語言知識轉移到強化學習 (RL) 中，以進行以對象為中心的任務，這使得代理人能夠對未見過的對象和指令進行零次學習泛化。透過視覺基礎，我們為指令中指示的目標對象取得一個以對象為基礎的信心圖。根據此圖，我們引進兩條路徑將 VLM 知識轉移到 RL 中。首先，我們提議一個源自信心圖的以對象為基礎的內在獎勵函數，以更有效地引導代理人朝向目標對象。其次，與語言嵌入相比，信心圖為代理人的政策提供了一個更統一、更易於存取的任務表示。這使代理人能夠透過可理解的視覺信心圖處理未見過的對象和指令，從而促進零次學習的對象層級泛化。單一任務實驗證明，我們的內在獎勵顯著改善了具有挑戰性的技能學習的表現。在多任務實驗中，透過在訓練集之外的任務上進行測試，我們表明，當提供信心圖作為任務表示時，代理人比基於語言的制約條件擁有更好的泛化能力。程式碼可在 https://github.com/PKU-RL/COPL 取得。

##### **Defining and Evaluating Decision and Composite Risk in Language Models Applied to Natural Language Inference**
2408.01935v1 by Ke Shen, Mayank Kejriwal

Despite their impressive performance, large language models (LLMs) such as
ChatGPT are known to pose important risks. One such set of risks arises from
misplaced confidence, whether over-confidence or under-confidence, that the
models have in their inference. While the former is well studied, the latter is
not, leading to an asymmetry in understanding the comprehensive risk of the
model based on misplaced confidence. In this paper, we address this asymmetry
by defining two types of risk (decision and composite risk), and proposing an
experimental framework consisting of a two-level inference architecture and
appropriate metrics for measuring such risks in both discriminative and
generative LLMs. The first level relies on a decision rule that determines
whether the underlying language model should abstain from inference. The second
level (which applies if the model does not abstain) is the model's inference.
Detailed experiments on four natural language commonsense reasoning datasets
using both an open-source ensemble-based RoBERTa model and ChatGPT, demonstrate
the practical utility of the evaluation framework. For example, our results
show that our framework can get an LLM to confidently respond to an extra 20.1%
of low-risk inference tasks that other methods might misclassify as high-risk,
and skip 19.8% of high-risk tasks, which would have been answered incorrectly.

摘要：儘管大型語言模型 (LLM) 例如 ChatGPT 擁有令人印象深刻的表現，但已知會造成重要的風險。其中一組風險源自於模型在推論中出現的錯誤信心，無論是過度自信或過度不自信。前者已被廣泛研究，後者則否，導致在了解模型基於錯誤信心的全面風險時出現不對稱。在本文中，我們透過定義兩種風險（決策風險和複合風險）來解決這個不對稱，並提出一個實驗架構，包括一個二層推論架構和適當的指標，用於衡量判別式和生成式 LLM 中的這兩種風險。第一層依賴於一個決策規則，用於決定底層語言模型是否應棄權推論。第二層（如果模型不棄權則適用）是模型的推論。使用開源的基於集合的 RoBERTa 模型和 ChatGPT，在四個自然語言常識推理資料集上進行的詳細實驗，證明了評估架構的實用性。例如，我們的結果顯示，我們的架構可以讓 LLM 自信地回應額外的 20.1% 的低風險推論任務，而其他方法可能會將其錯誤分類為高風險，並略過 19.8% 的高風險任務，而這些任務可能會被回答錯誤。

##### **DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models**
2408.01933v1 by Bowen Wang, Jiuyang Chang, Yiming Qian, Guoxin Chen, Junhao Chen, Zhouqiang Jiang, Jiahao Zhang, Yuta Nakashima, Hajime Nagahara

Large language models (LLMs) have recently showcased remarkable capabilities,
spanning a wide range of tasks and applications, including those in the medical
domain. Models like GPT-4 excel in medical question answering but may face
challenges in the lack of interpretability when handling complex tasks in real
clinical settings. We thus introduce the diagnostic reasoning dataset for
clinical notes (DiReCT), aiming at evaluating the reasoning ability and
interpretability of LLMs compared to human doctors. It contains 521 clinical
notes, each meticulously annotated by physicians, detailing the diagnostic
reasoning process from observations in a clinical note to the final diagnosis.
Additionally, a diagnostic knowledge graph is provided to offer essential
knowledge for reasoning, which may not be covered in the training data of
existing LLMs. Evaluations of leading LLMs on DiReCT bring out a significant
gap between their reasoning ability and that of human doctors, highlighting the
critical need for models that can reason effectively in real-world clinical
scenarios.

摘要：大型語言模型 (LLM) 近期展示出非凡的能力，涵蓋廣泛的任務和應用，包括醫療領域。GPT-4 等模型在醫療問題解答方面表現出色，但在處理實際臨床場景中的複雜任務時可能會面臨缺乏可解釋性的挑戰。因此，我們引入了臨床筆記的診斷推理數據集 (DiReCT)，旨在評估 LLM 與人類醫生相比的推理能力和可解釋性。它包含 521 個臨床筆記，每個筆記都經過醫師仔細註解，詳細說明了從臨床筆記中的觀察到最終診斷的診斷推理過程。此外，還提供了診斷知識圖譜，以提供推理所需的必要知識，這些知識可能未涵蓋在現有 LLM 的訓練數據中。在 DiReCT 上對領先的 LLM 進行評估，發現它們的推理能力與人類醫生之間存在顯著差距，強調了在現實世界的臨床場景中能夠有效推理的模型的關鍵需求。

##### **A Semi-supervised Multi-channel Graph Convolutional Network for Query Classification in E-commerce**
2408.01928v1 by Chunyuan Yuan, Ming Pang, Zheng Fang, Xue Jiang, Changping Peng, Zhangang Lin

Query intent classification is an essential module for customers to find
desired products on the e-commerce application quickly. Most existing query
intent classification methods rely on the users' click behavior as a supervised
signal to construct training samples. However, these methods based entirely on
posterior labels may lead to serious category imbalance problems because of the
Matthew effect in click samples. Compared with popular categories, it is
difficult for products under long-tail categories to obtain traffic and user
clicks, which makes the models unable to detect users' intent for products
under long-tail categories. This in turn aggravates the problem that long-tail
categories cannot obtain traffic, forming a vicious circle. In addition, due to
the randomness of the user's click, the posterior label is unstable for the
query with similar semantics, which makes the model very sensitive to the
input, leading to an unstable and incomplete recall of categories.
  In this paper, we propose a novel Semi-supervised Multi-channel Graph
Convolutional Network (SMGCN) to address the above problems from the
perspective of label association and semi-supervised learning. SMGCN extends
category information and enhances the posterior label by utilizing the
similarity score between the query and categories. Furthermore, it leverages
the co-occurrence and semantic similarity graph of categories to strengthen the
relations among labels and weaken the influence of posterior label instability.
We conduct extensive offline and online A/B experiments, and the experimental
results show that SMGCN significantly outperforms the strong baselines, which
shows its effectiveness and practicality.

摘要：查詢意圖分類是客戶在電子商務應用程式上快速找到所需商品的重要模組。現有的大部分查詢意圖分類方法都依賴使用者的點擊行為作為監督訊號來建構訓練樣本。然而，這些完全基於後驗標籤的方法可能會導致嚴重的類別不平衡問題，因為點擊樣本中存在馬太效應。與熱門類別相比，長尾類別下的商品很難獲得流量和使用者點擊，這使得模型無法偵測使用者對長尾類別下商品的意圖。這反過來又加劇了長尾類別無法獲得流量的問題，形成惡性循環。此外，由於使用者的點擊具有隨機性，因此後驗標籤對於語意相似的查詢是不穩定的，這使得模型對輸入非常敏感，導致類別的召回不穩定且不完整。
在本文中，我們提出了一個新穎的半監督多通道圖形卷積網路 (SMGCN)，從標籤關聯和半監督學習的角度來解決上述問題。SMGCN 透過使用查詢和類別之間的相似度分數來擴充類別資訊並增強後驗標籤。此外，它利用類別的共現和語意相似度圖形來加強標籤之間的關係並減弱後驗標籤不穩定的影響。我們進行了廣泛的離線和線上 A/B 實驗，實驗結果表明 SMGCN 明顯優於強大的基線，這證明了它的有效性和實用性。

##### **MAO: A Framework for Process Model Generation with Multi-Agent Orchestration**
2408.01916v1 by Leilei Lin, Yumeng Jin, Yingming Zhou, Wenlong Chen, Chen Qian

Process models are frequently used in software engineering to describe
business requirements, guide software testing and control system improvement.
However, traditional process modeling methods often require the participation
of numerous experts, which is expensive and time-consuming. Therefore, the
exploration of a more efficient and cost-effective automated modeling method
has emerged as a focal point in current research. This article explores a
framework for automatically generating process models with multi-agent
orchestration (MAO), aiming to enhance the efficiency of process modeling and
offer valuable insights for domain experts. Our framework MAO leverages large
language models as the cornerstone for multi-agent, employing an innovative
prompt strategy to ensure efficient collaboration among multi-agent.
Specifically, 1) generation. The first phase of MAO is to generate a slightly
rough process model from the text description; 2) refinement. The agents would
continuously refine the initial process model through multiple rounds of
dialogue; 3) reviewing. Large language models are prone to hallucination
phenomena among multi-turn dialogues, so the agents need to review and repair
semantic hallucinations in process models; 4) testing. The representation of
process models is diverse. Consequently, the agents utilize external tools to
test whether the generated process model contains format errors, namely format
hallucinations, and then adjust the process model to conform to the output
paradigm. The experiments demonstrate that the process models generated by our
framework outperform existing methods and surpass manual modeling by 89%, 61%,
52%, and 75% on four different datasets, respectively.

摘要：流程模型在軟體工程中經常被用來描述商業需求、引導軟體測試和控制系統改進。然而，傳統的流程建模方法通常需要許多專家的參與，這既昂貴又耗時。因此，探討更有效率且更具成本效益的自動化建模方法已成為當前研究的重點。本文探討了一個使用多主體協調 (MAO) 自動生成流程模型的框架，旨在提高流程建模的效率並為領域專家提供有價值的見解。我們的框架 MAO 以大型語言模型作為多主體的基石，採用創新的提示策略來確保多主體之間的有效協作。具體來說，1) 生成。MAO 的第一階段是從文字描述中生成一個稍微粗略的流程模型；2) 精煉。主體會透過多輪對話持續精煉初始流程模型；3) 檢閱。大型語言模型在多輪對話中容易出現幻覺現象，因此主體需要檢閱並修復流程模型中的語義幻覺；4) 測試。流程模型的表示方式多樣化。因此，主體利用外部工具來測試生成的流程模型是否包含格式錯誤，即格式幻覺，然後調整流程模型以符合輸出範例。實驗表明，我們的框架所生成的流程模型優於現有方法，並在四個不同的資料集上分別比手動建模高出 89%、61%、52% 和 75%。

##### **Re-ENACT: Reinforcement Learning for Emotional Speech Generation using Actor-Critic Strategy**
2408.01892v1 by Ravi Shankar, Archana Venkataraman

In this paper, we propose the first method to modify the prosodic features of
a given speech signal using actor-critic reinforcement learning strategy. Our
approach uses a Bayesian framework to identify contiguous segments of
importance that links segments of the given utterances to perception of
emotions in humans. We train a neural network to produce the variational
posterior of a collection of Bernoulli random variables; our model applies a
Markov prior on it to ensure continuity. A sample from this distribution is
used for downstream emotion prediction. Further, we train the neural network to
predict a soft assignment over emotion categories as the target variable. In
the next step, we modify the prosodic features (pitch, intensity, and rhythm)
of the masked segment to increase the score of target emotion. We employ an
actor-critic reinforcement learning to train the prosody modifier by
discretizing the space of modifications. Further, it provides a simple solution
to the problem of gradient computation through WSOLA operation for rhythm
manipulation. Our experiments demonstrate that this framework changes the
perceived emotion of a given speech utterance to the target. Further, we show
that our unified technique is on par with state-of-the-art emotion conversion
models from supervised and unsupervised domains that require pairwise training.

摘要：在本文中，我们提出了第一种方法，使用演员-评论强化学习策略来修改给定语音信号的韵律特征。我们的方法使用贝叶斯框架来识别重要性的连续片段，将给定话语的片段与人类对情绪的感知联系起来。我们训练神经网络来生成伯努利随机变量集合的变分后验；我们的模型对其应用马尔可夫先验以确保连续性。此分布的样本用于下游情绪预测。此外，我们训练神经网络预测情绪类别上的软分配作为目标变量。在下一步中，我们修改掩码片段的韵律特征（音高、强度和节奏）以增加目标情绪的分数。我们采用演员-评论强化学习来训练韵律修改器，通过离散化修改空间。此外，它为通过 WSOLA 操作进行节奏操作的梯度计算问题提供了一个简单的解决方案。我们的实验表明，该框架将给定语音话语的感知情绪改变为目标情绪。此外，我们表明我们的统一技术与来自需要成对训练的监督和无监督域的最新情绪转换模型不相上下。

##### **Cross-layer Attention Sharing for Large Language Models**
2408.01890v1 by Yongyu Mu, Yuzhang Wu, Yuchun Fan, Chenglong Wang, Hengyu Li, Qiaozhi He, Murun Yang, Tong Xiao, Jingbo Zhu

As large language models (LLMs) evolve, the increase in model depth and
parameter number leads to substantial redundancy. To enhance the efficiency of
the attention mechanism, previous works primarily compress the KV cache or
group attention heads, while largely overlooking redundancy between layers. Our
comprehensive analyses across various LLMs show that highly similar attention
patterns persist within most layers. It's intuitive to save the computation by
sharing attention weights across layers. However, further analysis reveals two
challenges: (1) Directly sharing the weight matrix without carefully
rearranging the attention heads proves to be ineffective; (2) Shallow layers
are vulnerable to small deviations in attention weights. Driven by these
insights, we introduce LiSA, a lightweight substitute for self-attention in
well-trained LLMs. LiSA employs tiny feed-forward networks to align attention
heads between adjacent layers and low-rank matrices to approximate differences
in layer-wise attention weights. Evaluations encompassing 13 typical benchmarks
demonstrate that LiSA maintains high response quality in terms of accuracy and
perplexity while reducing redundant attention calculations within 53-84% of the
total layers. Our implementations of LiSA achieve a 6X compression of Q and K,
with maximum throughput improvements of 19.5% for LLaMA3-8B and 32.3% for
LLaMA2-7B.

摘要：随着大型语言模型（LLM）的演进，模型深度和参数数量的增加导致了大量的冗余。为了提高注意力机制的效率，以前的工作主要压缩 KV 缓存或分组注意力头，而很大程度上忽略了层之间的冗余。我们对各种 LLM 的综合分析表明，在大多数层中，注意力模式高度相似。通过跨层共享注意力权重来节省计算是直观的。然而，进一步的分析揭示了两个挑战： (1) 直接共享权重矩阵而不仔细重新排列注意力头被证明是无效的；(2) 浅层容易受到注意力权重的小偏差的影响。受这些见解的启发，我们引入了 LiSA，一种经过良好训练的 LLM 中自注意力的轻量级替代品。LiSA 采用微小的前馈网络来对齐相邻层之间的注意力头，并采用低秩矩阵来逼近层级注意力权重中的差异。涵盖 13 个典型基准的评估表明，LiSA 在准确性和困惑度方面保持了较高的响应质量，同时将 53-84% 的总层中的冗余注意力计算减少了。我们对 LiSA 的实现实现了 Q 和 K 的 6 倍压缩，LLaMA3-8B 的最大吞吐量提高了 19.5%，LLaMA2-7B 的最大吞吐量提高了 32.3%。

##### **Walk Wisely on Graph: Knowledge Graph Reasoning with Dual Agents via Efficient Guidance-Exploration**
2408.01880v1 by Zijian Wang, Bin Wang, Haifeng Jing, Huayu Li, Hongbo Dou

Recent years, multi-hop reasoning has been widely studied for knowledge graph
(KG) reasoning due to its efficacy and interpretability. However, previous
multi-hop reasoning approaches are subject to two primary shortcomings. First,
agents struggle to learn effective and robust policies at the early phase due
to sparse rewards. Second, these approaches often falter on specific datasets
like sparse knowledge graphs, where agents are required to traverse lengthy
reasoning paths. To address these problems, we propose a multi-hop reasoning
model with dual agents based on hierarchical reinforcement learning (HRL),
which is named FULORA. FULORA tackles the above reasoning challenges by
eFficient GUidance-ExpLORAtion between dual agents. The high-level agent walks
on the simplified knowledge graph to provide stage-wise hints for the low-level
agent walking on the original knowledge graph. In this framework, the low-level
agent optimizes a value function that balances two objectives: (1) maximizing
return, and (2) integrating efficient guidance from the high-level agent.
Experiments conducted on three real-word knowledge graph datasets demonstrate
that FULORA outperforms RL-based baselines, especially in the case of
long-distance reasoning.

摘要：近年來，由於多跳推理的功效和可解釋性，它已被廣泛地研究用於知識圖譜 (KG) 推理。然而，先前的多跳推理方法會受到兩個主要的缺點影響。首先，由於獎勵稀疏，代理在早期階段難以學習有效且穩健的策略。其次，這些方法經常在特定資料集上失敗，例如稀疏知識圖譜，其中需要代理遍歷冗長的推理路徑。為了解決這些問題，我們提出了一個基於階層式強化學習 (HRL) 的雙代理多跳推理模型，它被命名為 FULORA。FULORA 透過雙代理之間的 eFficient GUidance-ExpLORAtion 來解決上述推理挑戰。高階代理在簡化的知識圖譜上執行，為在原始知識圖譜上執行的低階代理提供階段性的提示。在此架構中，低階代理最佳化一個值函數，該函數平衡兩個目標：(1) 最大化回報，以及 (2) 整合來自高階代理的有效指導。在三個真實世界的知識圖譜資料集上進行的實驗證明，FULORA 優於基於 RL 的基線，特別是在長距離推理的情況下。

##### **Re-Invoke: Tool Invocation Rewriting for Zero-Shot Tool Retrieval**
2408.01875v1 by Yanfei Chen, Jinsung Yoon, Devendra Singh Sachan, Qingze Wang, Vincent Cohen-Addad, Mohammadhossein Bateni, Chen-Yu Lee, Tomas Pfister

Recent advances in large language models (LLMs) have enabled autonomous
agents with complex reasoning and task-fulfillment capabilities using a wide
range of tools. However, effectively identifying the most relevant tools for a
given task becomes a key bottleneck as the toolset size grows, hindering
reliable tool utilization. To address this, we introduce Re-Invoke, an
unsupervised tool retrieval method designed to scale effectively to large
toolsets without training. Specifically, we first generate a diverse set of
synthetic queries that comprehensively cover different aspects of the query
space associated with each tool document during the tool indexing phase.
Second, we leverage LLM's query understanding capabilities to extract key
tool-related context and underlying intents from user queries during the
inference phase. Finally, we employ a novel multi-view similarity ranking
strategy based on intents to pinpoint the most relevant tools for each query.
Our evaluation demonstrates that Re-Invoke significantly outperforms
state-of-the-art alternatives in both single-tool and multi-tool scenarios, all
within a fully unsupervised setting. Notably, on the ToolE datasets, we achieve
a 20% relative improvement in nDCG@5 for single-tool retrieval and a 39%
improvement for multi-tool retrieval.

摘要：大型語言模型 (LLM) 的最新進展讓自主代理人能夠使用各種工具進行複雜的推理和任務履行。然而，隨著工具組規模的擴大，有效地找出與特定任務最相關的工具已成為一項關鍵瓶頸，阻礙了可靠的工具利用率。為了解決這個問題，我們引入了 Re-Invoke，這是一種無監督的工具檢索方法，旨在有效地擴展到大型工具組，而無需訓練。具體來說，我們首先產生一組多樣化的合成查詢，在工具索引階段全面涵蓋與每個工具文件相關的查詢空間的不同方面。其次，我們利用 LLM 的查詢理解能力在推理階段從使用者查詢中提取關鍵工具相關的背景和基本意圖。最後，我們採用基於意圖的新穎多視角相似性排序策略，為每個查詢找出最相關的工具。我們的評估表明，Re-Invoke 在單工具和多工具場景中都明顯優於最先進的替代方案，所有這些都在完全無監督的設置中進行。值得注意的是，在 ToolE 資料集上，我們在單工具檢索方面實現了 nDCG@5 的 20% 相對改進，在多工具檢索方面實現了 39% 的改進。

##### **MALADE: Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance**
2408.01869v1 by Jihye Choi, Nils Palumbo, Prasad Chalasani, Matthew M. Engelhard, Somesh Jha, Anivarya Kumar, David Page

In the era of Large Language Models (LLMs), given their remarkable text
understanding and generation abilities, there is an unprecedented opportunity
to develop new, LLM-based methods for trustworthy medical knowledge synthesis,
extraction and summarization. This paper focuses on the problem of
Pharmacovigilance (PhV), where the significance and challenges lie in
identifying Adverse Drug Events (ADEs) from diverse text sources, such as
medical literature, clinical notes, and drug labels. Unfortunately, this task
is hindered by factors including variations in the terminologies of drugs and
outcomes, and ADE descriptions often being buried in large amounts of narrative
text. We present MALADE, the first effective collaborative multi-agent system
powered by LLM with Retrieval Augmented Generation for ADE extraction from drug
label data. This technique involves augmenting a query to an LLM with relevant
information extracted from text resources, and instructing the LLM to compose a
response consistent with the augmented data. MALADE is a general LLM-agnostic
architecture, and its unique capabilities are: (1) leveraging a variety of
external sources, such as medical literature, drug labels, and FDA tools (e.g.,
OpenFDA drug information API), (2) extracting drug-outcome association in a
structured format along with the strength of the association, and (3) providing
explanations for established associations. Instantiated with GPT-4 Turbo or
GPT-4o, and FDA drug label data, MALADE demonstrates its efficacy with an Area
Under ROC Curve of 0.90 against the OMOP Ground Truth table of ADEs. Our
implementation leverages the Langroid multi-agent LLM framework and can be
found at https://github.com/jihyechoi77/malade.

摘要：在大语言模型 (LLM) 时代，鉴于其卓越的文本理解和生成能力，出现了一个前所未有的机会，可以开发基于 LLM 的新方法，用于可信的医学知识综合、提取和摘要。本文重点关注药物警戒 (PhV) 的问题，其重要性和挑战在于从各种文本来源（如医学文献、临床笔记和药物标签）中识别不良药物事件 (ADE)。不幸的是，这项任务受到多种因素的阻碍，包括药物和结果术语的变化，以及 ADE 描述通常埋没在大量叙述性文本中。我们展示了 MALADE，这是第一个有效的协作多智能体系统，由 LLM 提供支持，并使用检索增强生成来从药物标签数据中提取 ADE。此技术涉及使用从文本资源中提取的相关信息来扩充对 LLM 的查询，并指示 LLM 编写与扩充数据一致的响应。MALADE 是一种通用的 LLM 不可知架构，其独特功能包括：(1) 利用各种外部来源，例如医学文献、药物标签和 FDA 工具（例如 OpenFDA 药物信息 API），(2) 以结构化格式提取药物-结果关联以及关联强度，以及 (3) 为已建立的关联提供解释。MALADE 使用 GPT-4 Turbo 或 GPT-4o 以及 FDA 药物标签数据实例化，并通过针对 ADE 的 OMOP 基本事实表，以 0.90 的 ROC 曲线下面积证明了其有效性。我们的实现利用了 Langroid 多智能体 LLM 框架，可以在 https://github.com/jihyechoi77/malade 中找到。

##### **Efficient Solutions For An Intriguing Failure of LLMs: Long Context Window Does Not Mean LLMs Can Analyze Long Sequences Flawlessly**
2408.01866v1 by Peyman Hosseini, Ignacio Castro, Iacopo Ghinassi, Matthew Purver

Large Language Models (LLMs) have demonstrated remarkable capabilities in
comprehending and analyzing lengthy sequential inputs, owing to their extensive
context windows that allow processing millions of tokens in a single forward
pass. However, this paper uncovers a surprising limitation: LLMs fall short
when handling long input sequences. We investigate this issue using three
datasets and two tasks (sentiment analysis and news categorization) across
various LLMs, including Claude 3, Gemini Pro, GPT 3.5 Turbo, Llama 3 Instruct,
and Mistral Instruct models. To address this limitation, we propose and
evaluate ad-hoc solutions that substantially enhance LLMs' performance on long
input sequences by up to 50%, while reducing API cost and latency by up to 93%
and 50%, respectively.

摘要：大型語言模型 (LLM) 在理解和分析冗長的順序輸入方面表現出非凡的能力，這要歸功於它們廣泛的上下文視窗，允許在單次前向傳遞中處理數百萬個符號。然而，本文揭示了一個令人驚訝的限制：LLM 在處理長輸入序列時表現不佳。我們使用三個資料集和兩個任務（情緒分析和新聞分類）調查了這個問題，涉及各種 LLM，包括 Claude 3、Gemini Pro、GPT 3.5 Turbo、Llama 3 Instruct 和 Mistral Instruct 模型。為了解決這個限制，我們提出並評估了臨時解決方案，這些解決方案大幅提升了 LLM 在長輸入序列上的效能，最高達 50%，同時將 API 成本和延遲分別降低了 93% 和 50%。

##### **Sólo Escúchame: Spanish Emotional Accompaniment Chatbot**
2408.01852v1 by Bruno Gil Ramírez, Jessica López Espejel, María del Carmen Santiago Díaz, Gustavo Trinidad Rubín Linares

According to the World Health Organization (WHO), suicide was the fourth
leading cause of death in the world for individuals aged 15 to 29 in 2019.
Given the rapid increase in mental health issues, providing psychological
support is both crucial and urgent. In this paper: (1) we propose S\'olo
Esc\'uchame, the first open-source Spanish emotional assistance chatbot, based
on LLaMA-2-7b-Chat. (2) We introduced the HEAR (Hispanic Emotional
Accompaniment Responses) dataset, compiled from multiple English sources
translated into Spanish, as well as generic data generated using
ChatGPT-3.5-Turbo. Finally, (3) we propose an evaluation metric based on two
semi-automatic assessment methods. Our system outperforms a range of
state-of-the-art models in providing psychological assistance in Spanish. Our
models and datasets are publicly available to facilitate reproducibility.

摘要：根據世界衛生組織（WHO）的統計，2019 年自殺是全球 15 至 29 歲人士的第四大死因。
鑑於心理健康問題快速增加，提供心理支持既重要又迫切。在本文中：(1) 我們提出 S\'olo Esc\'uchame，這是第一個基於 LLaMA-2-7b-Chat 的開源式西班牙語情緒協助聊天機器人。(2) 我們引入了 HEAR（西班牙裔情緒陪伴回應）資料集，該資料集由多個翻譯成西班牙語的英文來源編譯而成，以及使用 ChatGPT-3.5-Turbo 生成的通用資料。最後，(3) 我們提出一個基於兩種半自動評估方法的評估指標。我們的系統在提供西班牙語心理協助方面優於一系列最先進的模型。我們的模型和資料集公開提供，以利於重現性。

##### **ST-SACLF: Style Transfer Informed Self-Attention Classifier for Bias-Aware Painting Classification**
2408.01827v1 by Mridula Vijendran, Frederick W. B. Li, Jingjing Deng, Hubert P. H. Shum

Painting classification plays a vital role in organizing, finding, and
suggesting artwork for digital and classic art galleries. Existing methods
struggle with adapting knowledge from the real world to artistic images during
training, leading to poor performance when dealing with different datasets. Our
innovation lies in addressing these challenges through a two-step process.
First, we generate more data using Style Transfer with Adaptive Instance
Normalization (AdaIN), bridging the gap between diverse styles. Then, our
classifier gains a boost with feature-map adaptive spatial attention modules,
improving its understanding of artistic details. Moreover, we tackle the
problem of imbalanced class representation by dynamically adjusting augmented
samples. Through a dual-stage process involving careful hyperparameter search
and model fine-tuning, we achieve an impressive 87.24\% accuracy using the
ResNet-50 backbone over 40 training epochs. Our study explores quantitative
analyses that compare different pretrained backbones, investigates model
optimization through ablation studies, and examines how varying augmentation
levels affect model performance. Complementing this, our qualitative
experiments offer valuable insights into the model's decision-making process
using spatial attention and its ability to differentiate between easy and
challenging samples based on confidence ranking.

摘要：繪畫分類在組織、尋找和建議數位和經典藝廊的藝術品中扮演重要的角色。現有的方法在訓練時難以將現實世界的知識適應到藝術圖像中，導致在處理不同資料集時效能不佳。我們的創新在於透過兩步驟的程序來解決這些挑戰。首先，我們使用具有自適應實例正規化 (AdaIN) 的風格轉移來產生更多資料，彌合了不同風格之間的差距。接著，我們的分類器透過具備特徵圖自適應空間注意力模組而獲得提升，進而改善其對藝術細節的理解。此外，我們透過動態調整擴充樣本來解決類別表示不平衡的問題。透過一個涉及仔細的超參數搜尋和模型微調的雙階段程序，我們使用 ResNet-50 主幹在超過 40 個訓練時期達到了令人印象深刻的 87.24% 準確度。我們的研究探討了比較不同預訓練主幹的定量分析，透過消融研究來探討模型最佳化，並檢視不同的擴充層級如何影響模型效能。作為補充，我們的定性實驗透過空間注意力提供了有價值的見解，了解模型的決策制定程序，以及它根據信心排名來區分容易和困難樣本的能力。

##### **ALIF: Low-Cost Adversarial Audio Attacks on Black-Box Speech Platforms using Linguistic Features**
2408.01808v1 by Peng Cheng, Yuwei Wang, Peng Huang, Zhongjie Ba, Xiaodong Lin, Feng Lin, Li Lu, Kui Ren

Extensive research has revealed that adversarial examples (AE) pose a
significant threat to voice-controllable smart devices. Recent studies have
proposed black-box adversarial attacks that require only the final
transcription from an automatic speech recognition (ASR) system. However, these
attacks typically involve many queries to the ASR, resulting in substantial
costs. Moreover, AE-based adversarial audio samples are susceptible to ASR
updates. In this paper, we identify the root cause of these limitations, namely
the inability to construct AE attack samples directly around the decision
boundary of deep learning (DL) models. Building on this observation, we propose
ALIF, the first black-box adversarial linguistic feature-based attack pipeline.
We leverage the reciprocal process of text-to-speech (TTS) and ASR models to
generate perturbations in the linguistic embedding space where the decision
boundary resides. Based on the ALIF pipeline, we present the ALIF-OTL and
ALIF-OTA schemes for launching attacks in both the digital domain and the
physical playback environment on four commercial ASRs and voice assistants.
Extensive evaluations demonstrate that ALIF-OTL and -OTA significantly improve
query efficiency by 97.7% and 73.3%, respectively, while achieving competitive
performance compared to existing methods. Notably, ALIF-OTL can generate an
attack sample with only one query. Furthermore, our test-of-time experiment
validates the robustness of our approach against ASR updates.

摘要：廣泛的研究顯示，對抗範例 (AE) 對語音控制智慧裝置構成重大威脅。最近的研究提出了黑盒對抗攻擊，僅需要自動語音辨識 (ASR) 系統的最終轉錄。然而，這些攻擊通常涉及對 ASR 的大量查詢，導致成本高昂。此外，基於 AE 的對抗性音訊範例容易受到 ASR 更新的影響。在本文中，我們找出這些限制的根本原因，即無法直接在深度學習 (DL) 模型的決策邊界周圍建構 AE 攻擊範例。根據此觀察，我們提出 ALIF，這是第一個基於黑盒對抗語言特徵的攻擊管道。我們利用文字轉語音 (TTS) 和 ASR 模型的互惠程序，在決策邊界所在的語言嵌入空間中產生擾動。根據 ALIF 管道，我們提出 ALIF-OTL 和 ALIF-OTA 計畫，在數位領域和實體播放環境中對四個商用 ASR 和語音助理發動攻擊。廣泛的評估顯示，與現有方法相比，ALIF-OTL 和 -OTA 分別顯著提高了 97.7% 和 73.3% 的查詢效率，同時達到了競爭力的效能。值得注意的是，ALIF-OTL 僅能透過一次查詢產生一個攻擊範例。此外，我們的時間測試實驗驗證了我們的方法對抗 ASR 更新的穩健性。

