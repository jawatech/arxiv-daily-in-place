{"2410.12329": {"publish_time": "2024-10-16", "title": "Understanding the Role of LLMs in Multimodal Evaluation Benchmarks", "paper_summary": "The rapid advancement of Multimodal Large Language Models (MLLMs) has been\naccompanied by the development of various benchmarks to evaluate their\ncapabilities. However, the true nature of these evaluations and the extent to\nwhich they assess multimodal reasoning versus merely leveraging the underlying\nLarge Language Model (LLM) backbone remain unclear. This paper presents a\ncomprehensive investigation into the role of LLM backbones in MLLM evaluation,\nfocusing on two critical aspects: the degree to which current benchmarks truly\nassess multimodal reasoning and the influence of LLM prior knowledge on\nperformance. Specifically, we introduce a modified evaluation protocol to\ndisentangle the contributions of the LLM backbone from multimodal integration,\nand an automatic knowledge identification technique for diagnosing whether LLMs\nequip the necessary knowledge for corresponding multimodal questions. Our study\nencompasses four diverse MLLM benchmarks and eight state-of-the-art MLLMs. Key\nfindings reveal that some benchmarks allow high performance even without visual\ninputs and up to 50\\% of error rates can be attributed to insufficient world\nknowledge in the LLM backbone, indicating a heavy reliance on language\ncapabilities. To address knowledge deficiencies, we propose a knowledge\naugmentation pipeline that achieves significant performance gains, with\nimprovements of up to 60\\% on certain datasets, resulting in a approximately 4x\nincrease in performance. Our work provides crucial insights into the role of\nthe LLM backbone in MLLMs, and highlights the need for more nuanced\nbenchmarking approaches.", "paper_summary_zh": "\u96a8\u8457\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM) \u7684\u5feb\u901f\u9032\u5c55\uff0c\u5404\u7a2e\u57fa\u6e96\u6e2c\u8a66\u4e5f\u96a8\u4e4b\u767c\u5c55\uff0c\u7528\u65bc\u8a55\u4f30\u5176\u80fd\u529b\u3002\u7136\u800c\uff0c\u9019\u4e9b\u8a55\u4f30\u7684\u771f\u6b63\u6027\u8cea\u4ee5\u53ca\u5b83\u5011\u8a55\u4f30\u591a\u6a21\u614b\u63a8\u7406\u7684\u7a0b\u5ea6\uff0c\u76f8\u5c0d\u65bc\u50c5\u5229\u7528\u57fa\u790e\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4e3b\u5e79\u4ecd\u4e0d\u6e05\u695a\u3002\u672c\u6587\u5c0d LLM \u4e3b\u5e79\u5728 MLLM \u8a55\u4f30\u4e2d\u7684\u4f5c\u7528\u9032\u884c\u4e86\u5168\u9762\u8abf\u67e5\uff0c\u91cd\u9ede\u95dc\u6ce8\u5169\u500b\u95dc\u9375\u65b9\u9762\uff1a\u7576\u524d\u57fa\u6e96\u6e2c\u8a66\u771f\u6b63\u8a55\u4f30\u591a\u6a21\u614b\u63a8\u7406\u7684\u7a0b\u5ea6\uff0c\u4ee5\u53ca LLM \u5148\u9a57\u77e5\u8b58\u5c0d\u6548\u80fd\u7684\u5f71\u97ff\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u4fee\u6539\u5f8c\u7684\u8a55\u4f30\u5354\u8b70\uff0c\u4ee5\u5340\u5206 LLM \u4e3b\u5e79\u5c0d\u591a\u6a21\u614b\u6574\u5408\u7684\u8ca2\u737b\uff0c\u4ee5\u53ca\u4e00\u7a2e\u81ea\u52d5\u77e5\u8b58\u8b58\u5225\u6280\u8853\uff0c\u7528\u65bc\u8a3a\u65b7 LLM \u662f\u5426\u5177\u5099\u5c0d\u61c9\u591a\u6a21\u614b\u554f\u984c\u7684\u5fc5\u8981\u77e5\u8b58\u3002\u6211\u5011\u7684\u7814\u7a76\u6db5\u84cb\u4e86\u56db\u500b\u4e0d\u540c\u7684 MLLM \u57fa\u6e96\u6e2c\u8a66\u548c\u516b\u500b\u6700\u5148\u9032\u7684 MLLM\u3002\u95dc\u9375\u767c\u73fe\u8868\u660e\uff0c\u5373\u4f7f\u6c92\u6709\u8996\u89ba\u8f38\u5165\uff0c\u4e00\u4e9b\u57fa\u6e96\u6e2c\u8a66\u4e5f\u80fd\u5141\u8a31\u9ad8\u6027\u80fd\uff0c\u4e26\u4e14\u9ad8\u9054 50% \u7684\u932f\u8aa4\u7387\u53ef\u6b78\u56e0\u65bc LLM \u4e3b\u5e79\u4e2d\u4e16\u754c\u77e5\u8b58\u4e0d\u8db3\uff0c\u9019\u8868\u660e\u5c0d\u8a9e\u8a00\u80fd\u529b\u7684\u56b4\u91cd\u4f9d\u8cf4\u3002\u70ba\u4e86\u89e3\u6c7a\u77e5\u8b58\u7f3a\u9677\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u77e5\u8b58\u64f4\u5145\u7ba1\u9053\uff0c\u53ef\u5be6\u73fe\u986f\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5728\u67d0\u4e9b\u6578\u64da\u96c6\u4e0a\u63d0\u5347\u9ad8\u9054 60%\uff0c\u5c0e\u81f4\u6027\u80fd\u63d0\u5347\u7d04 4 \u500d\u3002\u6211\u5011\u7684\u7814\u7a76\u5c0d LLM \u4e3b\u5e79\u5728 MLLM \u4e2d\u7684\u4f5c\u7528\u63d0\u4f9b\u4e86\u81f3\u95dc\u91cd\u8981\u7684\u898b\u89e3\uff0c\u4e26\u5f37\u8abf\u4e86\u5c0d\u66f4\u7d30\u7dfb\u7684\u57fa\u6e96\u6e2c\u8a66\u65b9\u6cd5\u7684\u9700\u6c42\u3002", "author": "Botian Jiang et.al.", "authors": "Botian Jiang, Lei Li, Xiaonan Li, Zhaowei Li, Xiachong Feng, Lingpeng Kong, Qi Liu, Xipeng Qiu", "id": "2410.12329v1", "paper_url": "http://arxiv.org/abs/2410.12329v1", "repo": "null"}}