{"2406.10492": {"publish_time": "2024-06-15", "title": "Large Language Models as Event Forecasters", "paper_summary": "Key elements of human events are extracted as quadruples that consist of\nsubject, relation, object, and timestamp. This representation can be extended\nto a quintuple by adding a fifth element: a textual summary that briefly\ndescribes the event. These quadruples or quintuples, when organized within a\nspecific domain, form a temporal knowledge graph (TKG). Current learning\nframeworks focus on a few TKG-related tasks, such as predicting an object given\na subject and a relation or forecasting the occurrences of multiple types of\nevents (i.e., relation) in the next time window. They typically rely on complex\nstructural and sequential models like graph neural networks (GNNs) and\nrecurrent neural networks (RNNs) to update intermediate embeddings. However,\nthese methods often neglect the contextual information inherent in each\nquintuple, which can be effectively captured through concise textual\ndescriptions. In this paper, we investigate how large language models (LLMs)\ncan streamline the design of TKG learning frameworks while maintaining\ncompetitive accuracy in prediction and forecasting tasks. We develop multiple\nprompt templates to frame the object prediction (OP) task as a standard\nquestion-answering (QA) task, suitable for instruction fine-tuning with an\nencoder-decoder generative LLM. For multi-event forecasting (MEF), we design\nsimple yet effective prompt templates for each TKG quintuple. This novel\napproach removes the need for GNNs and RNNs, instead utilizing an encoder-only\nLLM to generate fixed intermediate embeddings, which are subsequently processed\nby a prediction head with a self-attention mechanism to forecast potential\nfuture relations. Extensive experiments on multiple real-world datasets using\nvarious evaluation metrics validate the effectiveness and robustness of our\napproach.", "paper_summary_zh": "<paragraph>\u4eba\u985e\u4e8b\u4ef6\u7684\u4e3b\u8981\u5143\u7d20\u88ab\u8403\u53d6\u70ba\u7531\u4e3b\u8a5e\u3001\u95dc\u4fc2\u3001\u53d7\u8a5e\u548c\u6642\u9593\u6233\u7d44\u6210\u7684\u56db\u5143\u7d44\u3002\u6b64\u8868\u793a\u6cd5\u53ef\u900f\u904e\u65b0\u589e\u7b2c\u4e94\u500b\u5143\u7d20\u4f86\u5ef6\u4f38\u70ba\u4e94\u5143\u7d44\uff1a\u7c21\u8981\u63cf\u8ff0\u4e8b\u4ef6\u7684\u6587\u5b57\u6458\u8981\u3002\u9019\u4e9b\u56db\u5143\u7d44\u6216\u4e94\u5143\u7d44\u5728\u7279\u5b9a\u9818\u57df\u4e2d\u7d44\u7e54\u6642\uff0c\u6703\u5f62\u6210\u6642\u5e8f\u77e5\u8b58\u5716\u8b5c (TKG)\u3002\u76ee\u524d\u7684\u5b78\u7fd2\u67b6\u69cb\u5c08\u6ce8\u65bc\u4e00\u4e9b\u8207 TKG \u76f8\u95dc\u7684\u4efb\u52d9\uff0c\u4f8b\u5982\u5728\u7d66\u5b9a\u4e3b\u8a5e\u548c\u95dc\u4fc2\u7684\u60c5\u6cc1\u4e0b\u9810\u6e2c\u53d7\u8a5e\uff0c\u6216\u9810\u6e2c\u4e0b\u4e00\u500b\u6642\u9593\u8996\u7a97\u4e2d\u591a\u7a2e\u985e\u578b\u4e8b\u4ef6\uff08\u5373\u95dc\u4fc2\uff09\u7684\u767c\u751f\u3002\u5b83\u5011\u901a\u5e38\u4f9d\u8cf4\u65bc\u8907\u96dc\u7684\u7d50\u69cb\u548c\u5e8f\u5217\u6a21\u578b\uff0c\u4f8b\u5982\u5716\u5f62\u795e\u7d93\u7db2\u8def (GNN) \u548c\u905e\u8ff4\u795e\u7d93\u7db2\u8def (RNN)\uff0c\u4f86\u66f4\u65b0\u4e2d\u9593\u5d4c\u5165\u3002\u7136\u800c\uff0c\u9019\u4e9b\u65b9\u6cd5\u7d93\u5e38\u5ffd\u7565\u6bcf\u500b\u4e94\u5143\u7d44\u4e2d\u56fa\u6709\u7684\u8108\u7d61\u8cc7\u8a0a\uff0c\u800c\u9019\u4e9b\u8cc7\u8a0a\u53ef\u900f\u904e\u7c21\u6f54\u7684\u6587\u5b57\u63cf\u8ff0\u6709\u6548\u64f7\u53d6\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5982\u4f55\u7c21\u5316 TKG \u5b78\u7fd2\u67b6\u69cb\u7684\u8a2d\u8a08\uff0c\u540c\u6642\u5728\u9810\u6e2c\u548c\u9810\u6e2c\u4efb\u52d9\u4e2d\u7dad\u6301\u5177\u7af6\u722d\u529b\u7684\u6e96\u78ba\u5ea6\u3002\u6211\u5011\u958b\u767c\u591a\u500b\u63d0\u793a\u7bc4\u672c\uff0c\u5c07\u7269\u4ef6\u9810\u6e2c (OP) \u4efb\u52d9\u8a2d\u5b9a\u70ba\u6a19\u6e96\u554f\u7b54 (QA) \u4efb\u52d9\uff0c\u9069\u7528\u65bc\u4f7f\u7528\u7de8\u78bc\u5668-\u89e3\u78bc\u5668\u751f\u6210\u5f0f LLM \u9032\u884c\u6307\u4ee4\u5fae\u8abf\u3002\u5c0d\u65bc\u591a\u4e8b\u4ef6\u9810\u6e2c (MEF)\uff0c\u6211\u5011\u70ba\u6bcf\u500b TKG \u4e94\u5143\u7d44\u8a2d\u8a08\u7c21\u55ae\u4f46\u6709\u6548\u7684\u63d0\u793a\u7bc4\u672c\u3002\u9019\u7a2e\u65b0\u7a4e\u7684\u65b9\u6cd5\u6d88\u9664\u4e86\u5c0d GNN \u548c RNN \u7684\u9700\u6c42\uff0c\u800c\u662f\u5229\u7528\u50c5\u7de8\u78bc\u5668 LLM \u4f86\u7522\u751f\u56fa\u5b9a\u7684\u4e2d\u9593\u5d4c\u5165\uff0c\u7136\u5f8c\u7531\u5177\u6709\u81ea\u6ce8\u610f\u529b\u6a5f\u5236\u7684\u9810\u6e2c\u982d\u8655\u7406\u9019\u4e9b\u5d4c\u5165\uff0c\u4ee5\u9810\u6e2c\u6f5b\u5728\u7684\u672a\u4f86\u95dc\u4fc2\u3002\u4f7f\u7528\u5404\u7a2e\u8a55\u4f30\u6307\u6a19\u5c0d\u591a\u500b\u771f\u5be6\u4e16\u754c\u8cc7\u6599\u96c6\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u9a57\u8b49\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u7a69\u5065\u6027\u3002</paragraph>", "author": "Libo Zhang et.al.", "authors": "Libo Zhang, Yue Ning", "id": "2406.10492v1", "paper_url": "http://arxiv.org/abs/2406.10492v1", "repo": "null"}}