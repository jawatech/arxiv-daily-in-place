{"2407.13989": {"publish_time": "2024-07-19", "title": "Enhancing Data-Limited Graph Neural Networks by Actively Distilling Knowledge from Large Language Models", "paper_summary": "Graphs have emerged as critical data structures for content analysis in\nvarious domains, such as social network analysis, bioinformatics, and\nrecommendation systems. Node classification, a fundamental task in this\ncontext, is typically tackled using graph neural networks (GNNs).\nUnfortunately, conventional GNNs still face challenges in scenarios with few\nlabeled nodes, despite the prevalence of few-shot node classification tasks in\nreal-world applications. To address this challenge, various approaches have\nbeen proposed, including graph meta-learning, transfer learning, and methods\nbased on Large Language Models (LLMs). However, traditional meta-learning and\ntransfer learning methods often require prior knowledge from base classes or\nfail to exploit the potential advantages of unlabeled nodes. Meanwhile,\nLLM-based methods may overlook the zero-shot capabilities of LLMs and rely\nheavily on the quality of generated contexts. In this paper, we propose a novel\napproach that integrates LLMs and GNNs, leveraging the zero-shot inference and\nreasoning capabilities of LLMs and employing a Graph-LLM-based active learning\nparadigm to enhance GNNs' performance. Extensive experiments demonstrate the\neffectiveness of our model in improving node classification accuracy with\nconsiderably limited labeled data, surpassing state-of-the-art baselines by\nsignificant margins.", "paper_summary_zh": "\u5716\u8868\u5df2\u6210\u70ba\u5404\u7a2e\u9818\u57df\u4e2d\u5167\u5bb9\u5206\u6790\u7684\u95dc\u9375\u6578\u64da\u7d50\u69cb\uff0c\u4f8b\u5982\u793e\u4ea4\u7db2\u8def\u5206\u6790\u3001\u751f\u7269\u8cc7\u8a0a\u5b78\u548c\u63a8\u85a6\u7cfb\u7d71\u3002\u7bc0\u9ede\u5206\u985e\u662f\u6b64\u8108\u7d61\u4e2d\u7684\u57fa\u672c\u4efb\u52d9\uff0c\u901a\u5e38\u4f7f\u7528\u5716\u5f62\u795e\u7d93\u7db2\u8def (GNN) \u4f86\u8655\u7406\u3002\u4e0d\u5e78\u7684\u662f\uff0c\u5118\u7ba1\u73fe\u5be6\u4e16\u754c\u61c9\u7528\u4e2d\u666e\u904d\u5b58\u5728\u5c11\u6a23\u672c\u7bc0\u9ede\u5206\u985e\u4efb\u52d9\uff0c\u4f46\u50b3\u7d71\u7684 GNN \u5728\u6a19\u8a18\u7bc0\u9ede\u5f88\u5c11\u7684\u60c5\u6cc1\u4e0b\u4ecd\u9762\u81e8\u6311\u6230\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e00\u6311\u6230\uff0c\u5df2\u63d0\u51fa\u5404\u7a2e\u65b9\u6cd5\uff0c\u5305\u62ec\u5716\u5f62\u5143\u5b78\u7fd2\u3001\u9077\u79fb\u5b78\u7fd2\u548c\u57fa\u65bc\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u50b3\u7d71\u7684\u5143\u5b78\u7fd2\u548c\u9077\u79fb\u5b78\u7fd2\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u4f86\u81ea\u57fa\u790e\u985e\u5225\u7684\u5148\u9a57\u77e5\u8b58\uff0c\u6216\u8005\u7121\u6cd5\u5229\u7528\u672a\u6a19\u8a18\u7bc0\u9ede\u7684\u6f5b\u5728\u512a\u52e2\u3002\u540c\u6642\uff0c\u57fa\u65bc LLM \u7684\u65b9\u6cd5\u53ef\u80fd\u6703\u5ffd\u8996 LLM \u7684\u96f6\u6a23\u672c\u80fd\u529b\uff0c\u4e26\u4e14\u904e\u5ea6\u4f9d\u8cf4\u751f\u6210\u8a9e\u5883\u7684\u54c1\u8cea\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7684\u65b9\u6cd5\uff0c\u5b83\u6574\u5408\u4e86 LLM \u548c GNN\uff0c\u5229\u7528 LLM \u7684\u96f6\u6a23\u672c\u63a8\u8ad6\u548c\u63a8\u7406\u80fd\u529b\uff0c\u4e26\u63a1\u7528\u57fa\u65bc Graph-LLM \u7684\u4e3b\u52d5\u5b78\u7fd2\u7bc4\u4f8b\u4f86\u589e\u5f37 GNN \u7684\u6548\u80fd\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u8b49\u660e\u4e86\u6211\u5011\u7684\u6a21\u578b\u5728\u6539\u9032\u7bc0\u9ede\u5206\u985e\u6e96\u78ba\u5ea6\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u6a19\u8a18\u6578\u64da\u76f8\u7576\u6709\u9650\uff0c\u986f\u8457\u8d85\u8d8a\u4e86\u6700\u5148\u9032\u7684\u57fa\u6e96\u3002", "author": "Quan Li et.al.", "authors": "Quan Li, Tianxiang Zhao, Lingwei Chen, Junjie Xu, Suhang Wang", "id": "2407.13989v1", "paper_url": "http://arxiv.org/abs/2407.13989v1", "repo": "null"}}