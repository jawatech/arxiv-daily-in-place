{"2410.18749": {"publish_time": "2024-10-24", "title": "Does Differential Privacy Impact Bias in Pretrained NLP Models?", "paper_summary": "Differential privacy (DP) is applied when fine-tuning pre-trained large\nlanguage models (LLMs) to limit leakage of training examples. While most DP\nresearch has focused on improving a model's privacy-utility tradeoff, some find\nthat DP can be unfair to or biased against underrepresented groups. In this\nwork, we show the impact of DP on bias in LLMs through empirical analysis.\nDifferentially private training can increase the model bias against protected\ngroups w.r.t AUC-based bias metrics. DP makes it more difficult for the model\nto differentiate between the positive and negative examples from the protected\ngroups and other groups in the rest of the population. Our results also show\nthat the impact of DP on bias is not only affected by the privacy protection\nlevel but also the underlying distribution of the dataset.", "paper_summary_zh": "\u5dee\u5206\u96b1\u79c1 (DP) \u7528\u65bc\u5fae\u8abf\u9810\u8a13\u7df4\u7684\u5927\u8a9e\u8a00\u6a21\u578b (LLM)\uff0c\u4ee5\u9650\u5236\u8a13\u7df4\u7bc4\u4f8b\u7684\u6d29\u6f0f\u3002\u96d6\u7136\u5927\u591a\u6578 DP \u7814\u7a76\u90fd\u96c6\u4e2d\u5728\u6539\u5584\u6a21\u578b\u7684\u96b1\u79c1\u6548\u7528\u6b0a\u8861\uff0c\u4f46\u6709\u4e9b\u4eba\u767c\u73fe DP \u53ef\u80fd\u5c0d\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u7fa4\u9ad4\u4e0d\u516c\u5e73\u6216\u6709\u504f\u898b\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u900f\u904e\u5be6\u8b49\u5206\u6790\u5c55\u793a DP \u5c0d LLM \u4e2d\u504f\u898b\u7684\u5f71\u97ff\u3002\u5dee\u7570\u5316\u96b1\u79c1\u8a13\u7df4\u53ef\u4ee5\u589e\u52a0\u6a21\u578b\u5c0d\u53d7\u4fdd\u8b77\u7fa4\u9ad4\u7684\u504f\u898b\uff0c\u76f8\u5c0d\u65bc\u57fa\u65bc AUC \u7684\u504f\u898b\u6307\u6a19\u3002DP \u4f7f\u6a21\u578b\u66f4\u96e3\u5340\u5206\u53d7\u4fdd\u8b77\u7fa4\u9ad4\u548c\u5176\u4ed6\u7fa4\u9ad4\u5728\u5176\u4ed6\u65cf\u7fa4\u4e2d\u7684\u6b63\u9762\u548c\u8ca0\u9762\u7bc4\u4f8b\u3002\u6211\u5011\u7684\u7d50\u679c\u4e5f\u986f\u793a\uff0cDP \u5c0d\u504f\u898b\u7684\u5f71\u97ff\u4e0d\u50c5\u53d7\u96b1\u79c1\u4fdd\u8b77\u5c64\u7d1a\u5f71\u97ff\uff0c\u4e5f\u53d7\u8cc7\u6599\u96c6\u7684\u57fa\u790e\u5206\u4f48\u5f71\u97ff\u3002", "author": "Md. Khairul Islam et.al.", "authors": "Md. Khairul Islam, Andrew Wang, Tianhao Wang, Yangfeng Ji, Judy Fox, Jieyu Zhao", "id": "2410.18749v1", "paper_url": "http://arxiv.org/abs/2410.18749v1", "repo": "https://github.com/khairulislam/dp-on-nlp-bias"}}