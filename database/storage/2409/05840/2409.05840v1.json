{"2409.05840": {"publish_time": "2024-09-09", "title": "MMEvol: Empowering Multimodal Large Language Models with Evol-Instruct", "paper_summary": "The development of Multimodal Large Language Models (MLLMs) has seen\nsignificant advancements. However, the quantity and quality of multimodal\ninstruction data have emerged as significant bottlenecks in their progress.\nManually creating multimodal instruction data is both time-consuming and\ninefficient, posing challenges in producing instructions of high complexity.\nMoreover, distilling instruction data from black-box commercial models (e.g.,\nGPT-4o, GPT-4V) often results in simplistic instruction data, which constrains\nperformance to that of these models. The challenge of curating diverse and\ncomplex instruction data remains substantial. We propose MMEvol, a novel\nmultimodal instruction data evolution framework that combines fine-grained\nperception evolution, cognitive reasoning evolution, and interaction evolution.\nThis iterative approach breaks through data quality bottlenecks to generate a\ncomplex and diverse image-text instruction dataset, thereby empowering MLLMs\nwith enhanced capabilities. Beginning with an initial set of instructions,\nSEED-163K, we utilize MMEvol to systematically broadens the diversity of\ninstruction types, integrates reasoning steps to enhance cognitive\ncapabilities, and extracts detailed information from images to improve visual\nunderstanding and robustness. To comprehensively evaluate the effectiveness of\nour data, we train LLaVA-NeXT using the evolved data and conduct experiments\nacross 13 vision-language tasks. Compared to the baseline trained with seed\ndata, our approach achieves an average accuracy improvement of 3.1 points and\nreaches state-of-the-art (SOTA) performance on 9 of these tasks.", "paper_summary_zh": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u7684\u53d1\u5c55\u5df2\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\u3002\u7136\u800c\uff0c\u591a\u6a21\u6001\u6307\u4ee4\u6570\u636e\u7684\u6570\u91cf\u548c\u8d28\u91cf\u5df2\u6210\u4e3a\u5176\u8fdb\u6b65\u4e2d\u7684\u91cd\u5927\u74f6\u9888\u3002\u624b\u52a8\u521b\u5efa\u591a\u6a21\u6001\u6307\u4ee4\u6570\u636e\u65e2\u8d39\u65f6\u53c8\u4f4e\u6548\uff0c\u5728\u751f\u6210\u9ad8\u590d\u6742\u5ea6\u6307\u4ee4\u65f6\u4f1a\u9020\u6210\u6311\u6218\u3002\u6b64\u5916\uff0c\u4ece\u9ed1\u7bb1\u5546\u4e1a\u6a21\u578b\uff08\u4f8b\u5982 GPT-4o\u3001GPT-4V\uff09\u4e2d\u63d0\u53d6\u6307\u4ee4\u6570\u636e\u901a\u5e38\u4f1a\u5bfc\u81f4\u6307\u4ee4\u6570\u636e\u8fc7\u4e8e\u7b80\u5355\uff0c\u8fd9\u4f1a\u5c06\u6027\u80fd\u9650\u5236\u5728\u8fd9\u4e9b\u6a21\u578b\u7684\u6027\u80fd\u8303\u56f4\u5185\u3002\u5bf9\u591a\u6837\u4e14\u590d\u6742\u6307\u4ee4\u6570\u636e\u8fdb\u884c\u6574\u7406\u7684\u6311\u6218\u4ecd\u7136\u5f88\u5927\u3002\u6211\u4eec\u63d0\u51fa\u4e86 MMEvol\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u9896\u7684\u591a\u6a21\u6001\u6307\u4ee4\u6570\u636e\u6f14\u5316\u6846\u67b6\uff0c\u5b83\u7ed3\u5408\u4e86\u7ec6\u7c92\u5ea6\u7684\u611f\u77e5\u6f14\u5316\u3001\u8ba4\u77e5\u63a8\u7406\u6f14\u5316\u548c\u4ea4\u4e92\u6f14\u5316\u3002\u8fd9\u79cd\u8fed\u4ee3\u65b9\u6cd5\u7a81\u7834\u4e86\u6570\u636e\u8d28\u91cf\u74f6\u9888\uff0c\u751f\u6210\u590d\u6742\u4e14\u591a\u6837\u7684\u56fe\u50cf\u6587\u672c\u6307\u4ee4\u6570\u636e\u96c6\uff0c\u4ece\u800c\u589e\u5f3a\u4e86 MLLM \u7684\u80fd\u529b\u3002\u4ece\u4e00\u7ec4\u521d\u59cb\u6307\u4ee4 SEED-163K \u5f00\u59cb\uff0c\u6211\u4eec\u5229\u7528 MMEvol \u7cfb\u7edf\u5730\u62d3\u5bbd\u6307\u4ee4\u7c7b\u578b\u7684\u591a\u6837\u6027\uff0c\u6574\u5408\u63a8\u7406\u6b65\u9aa4\u4ee5\u589e\u5f3a\u8ba4\u77e5\u80fd\u529b\uff0c\u5e76\u4ece\u56fe\u50cf\u4e2d\u63d0\u53d6\u8be6\u7ec6\u4fe1\u606f\u4ee5\u63d0\u9ad8\u89c6\u89c9\u7406\u89e3\u548c\u9c81\u68d2\u6027\u3002\u4e3a\u4e86\u5168\u9762\u8bc4\u4f30\u6211\u4eec\u6570\u636e\u7684\u6709\u6548\u6027\uff0c\u6211\u4eec\u4f7f\u7528\u6f14\u5316\u6570\u636e\u8bad\u7ec3 LLaVA-NeXT\uff0c\u5e76\u5728 13 \u9879\u89c6\u89c9\u8bed\u8a00\u4efb\u52a1\u4e2d\u8fdb\u884c\u5b9e\u9a8c\u3002\u4e0e\u4f7f\u7528\u79cd\u5b50\u6570\u636e\u8bad\u7ec3\u7684\u57fa\u7ebf\u76f8\u6bd4\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5c06\u5e73\u5747\u51c6\u786e\u5ea6\u63d0\u9ad8\u4e86 3.1 \u4e2a\u767e\u5206\u70b9\uff0c\u5e76\u5728\u5176\u4e2d 9 \u9879\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb (SOTA) \u7684\u6027\u80fd\u3002", "author": "Run Luo et.al.", "authors": "Run Luo, Haonan Zhang, Longze Chen, Ting-En Lin, Xiong Liu, Yuchuan Wu, Min Yang, Minzheng Wang, Pengpeng Zeng, Lianli Gao, Heng Tao Shen, Yunshui Li, Xiaobo Xia, Fei Huang, Jingkuan Song, Yongbin Li", "id": "2409.05840v1", "paper_url": "http://arxiv.org/abs/2409.05840v1", "repo": "null"}}