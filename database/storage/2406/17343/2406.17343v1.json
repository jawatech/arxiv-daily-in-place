{"2406.17343": {"publish_time": "2024-06-25", "title": "Q-DiT: Accurate Post-Training Quantization for Diffusion Transformers", "paper_summary": "Recent advancements in diffusion models, particularly the trend of\narchitectural transformation from UNet-based Diffusion to Diffusion Transformer\n(DiT), have significantly improved the quality and scalability of image\nsynthesis. Despite the incredible generative quality, the large computational\nrequirements of these large-scale models significantly hinder the deployments\nin real-world scenarios. Post-training Quantization (PTQ) offers a promising\nsolution by compressing model sizes and speeding up inference for the\npretrained models while eliminating model retraining. However, we have observed\nthe existing PTQ frameworks exclusively designed for both ViT and conventional\nDiffusion models fall into biased quantization and result in remarkable\nperformance degradation. In this paper, we find that the DiTs typically exhibit\nconsiderable variance in terms of both weight and activation, which easily runs\nout of the limited numerical representations. To address this issue, we devise\nQ-DiT, which seamlessly integrates three techniques: fine-grained quantization\nto manage substantial variance across input channels of weights and\nactivations, an automatic search strategy to optimize the quantization\ngranularity and mitigate redundancies, and dynamic activation quantization to\ncapture the activation changes across timesteps. Extensive experiments on the\nImageNet dataset demonstrate the effectiveness of the proposed Q-DiT.\nSpecifically, when quantizing DiT-XL/2 to W8A8 on ImageNet 256x256, Q-DiT\nachieves a remarkable reduction in FID by 1.26 compared to the baseline. Under\na W4A8 setting, it maintains high fidelity in image generation, showcasing only\na marginal increase in FID and setting a new benchmark for efficient,\nhigh-quality quantization in diffusion transformers. Code is available at\n\\href{https://github.com/Juanerx/Q-DiT}{https://github.com/Juanerx/Q-DiT}.", "paper_summary_zh": "<paragraph>\u64f4\u6563\u6a21\u578b\u7684\u6700\u65b0\u9032\u5c55\uff0c\u7279\u5225\u662f\u5f9e\u57fa\u65bc UNet \u7684\u64f4\u6563\u5230\u64f4\u6563\u8b8a\u63db\u5668 (DiT) \u7684\u67b6\u69cb\u8f49\u63db\u8da8\u52e2\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u5f71\u50cf\u5408\u6210\u7684\u54c1\u8cea\u548c\u53ef\u64f4\u5145\u6027\u3002\u5118\u7ba1\u751f\u6210\u54c1\u8cea\u4ee4\u4eba\u9a5a\u5606\uff0c\u4f46\u9019\u4e9b\u5927\u578b\u6a21\u578b\u9f90\u5927\u7684\u904b\u7b97\u9700\u6c42\uff0c\u5927\u5e45\u963b\u7919\u4e86\u5728\u5be6\u969b\u5834\u666f\u4e2d\u7684\u90e8\u7f72\u3002\u8a13\u7df4\u5f8c\u91cf\u5316 (PTQ) \u63d0\u4f9b\u4e86\u4e00\u500b\u6709\u524d\u666f\u7684\u89e3\u6c7a\u65b9\u6848\uff0c\u900f\u904e\u58d3\u7e2e\u6a21\u578b\u5927\u5c0f\u4e26\u52a0\u901f\u9810\u8a13\u7df4\u6a21\u578b\u7684\u63a8\u8ad6\uff0c\u540c\u6642\u6d88\u9664\u6a21\u578b\u91cd\u65b0\u8a13\u7df4\u3002\u7136\u800c\uff0c\u6211\u5011\u89c0\u5bdf\u5230\u73fe\u6709\u7684 PTQ \u6846\u67b6\u5c08\u9580\u8a2d\u8a08\u7d66 ViT \u548c\u50b3\u7d71\u64f4\u6563\u6a21\u578b\uff0c\u6703\u9677\u5165\u6709\u504f\u5dee\u7684\u91cf\u5316\uff0c\u4e26\u5c0e\u81f4\u986f\u8457\u7684\u6548\u80fd\u4e0b\u964d\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u767c\u73fe DiT \u901a\u5e38\u5728\u6b0a\u91cd\u548c\u6fc0\u6d3b\u65b9\u9762\u8868\u73fe\u51fa\u76f8\u7576\u5927\u7684\u5dee\u7570\uff0c\u9019\u5f88\u5bb9\u6613\u8d85\u51fa\u6709\u9650\u7684\u6578\u503c\u8868\u793a\u7bc4\u570d\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u8a2d\u8a08\u4e86 Q-DiT\uff0c\u5b83\u7121\u7e2b\u6574\u5408\u4e86\u4e09\u7a2e\u6280\u8853\uff1a\u7d30\u7c92\u5ea6\u91cf\u5316\u4ee5\u7ba1\u7406\u6b0a\u91cd\u548c\u6fc0\u6d3b\u8f38\u5165\u901a\u9053\u4e4b\u9593\u7684\u5be6\u8cea\u5dee\u7570\u3001\u81ea\u52d5\u641c\u5c0b\u7b56\u7565\u4ee5\u6700\u4f73\u5316\u91cf\u5316\u7c92\u5ea6\u4e26\u6e1b\u8f15\u5197\u9918\uff0c\u4ee5\u53ca\u52d5\u614b\u6fc0\u6d3b\u91cf\u5316\u4ee5\u6355\u6349\u6642\u9593\u6b65\u9577\u4e4b\u9593\u7684\u6fc0\u6d3b\u8b8a\u5316\u3002\u5728 ImageNet \u8cc7\u6599\u96c6\u4e0a\u7684\u5ee3\u6cdb\u5be6\u9a57\u8b49\u660e\u4e86\u6240\u63d0\u51fa\u7684 Q-DiT \u7684\u6709\u6548\u6027\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u7576\u5c07 DiT-XL/2 \u91cf\u5316\u70ba ImageNet 256x256 \u4e0a\u7684 W8A8 \u6642\uff0c\u8207\u57fa\u7dda\u76f8\u6bd4\uff0cQ-DiT \u5728 FID \u4e0a\u5be6\u73fe\u4e86\u986f\u8457\u7684 1.26 \u6e1b\u5c11\u3002\u5728 W4A8 \u8a2d\u5b9a\u4e0b\uff0c\u5b83\u5728\u5f71\u50cf\u751f\u6210\u4e2d\u7dad\u6301\u9ad8\u4fdd\u771f\u5ea6\uff0c\u50c5\u5c55\u793a FID \u7684\u908a\u969b\u589e\u52a0\uff0c\u4e26\u70ba\u64f4\u6563\u8b8a\u63db\u5668\u4e2d\u7684\u9ad8\u6548\u3001\u9ad8\u54c1\u8cea\u91cf\u5316\u8a2d\u5b9a\u4e86\u65b0\u7684\u57fa\u6e96\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728\\href{https://github.com/Juanerx/Q-DiT}{https://github.com/Juanerx/Q-DiT}\u53d6\u5f97\u3002</paragraph>", "author": "Lei Chen et.al.", "authors": "Lei Chen, Yuan Meng, Chen Tang, Xinzhu Ma, Jingyan Jiang, Xin Wang, Zhi Wang, Wenwu Zhu", "id": "2406.17343v1", "paper_url": "http://arxiv.org/abs/2406.17343v1", "repo": "null"}}