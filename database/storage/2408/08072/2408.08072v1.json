{"2408.08072": {"publish_time": "2024-08-15", "title": "I-SHEEP: Self-Alignment of LLM from Scratch through an Iterative Self-Enhancement Paradigm", "paper_summary": "Large Language Models (LLMs) have achieved significant advancements, however,\nthe common learning paradigm treats LLMs as passive information repositories,\nneglecting their potential for active learning and alignment. Some approaches\ntrain LLMs using their own generated synthetic data, exploring the possibility\nof active alignment. However, there is still a huge gap between these one-time\nalignment methods and the continuous automatic alignment of humans. In this\npaper, we introduce \\textbf{I-SHEEP}, an \\textbf{I}terative\n\\textbf{S}elf-En\\textbf{H}anc\\textbf{E}m\\textbf{E}nt \\textbf{P}aradigm.This\nhuman-like paradigm enables LLMs to \\textbf{continuously self-align from\nscratch with nothing}. Compared to the one-time alignment method Dromedary\n\\cite{sun2023principledriven}, which refers to the first iteration in this\npaper, I-SHEEP can significantly enhance capacities on both Qwen and Llama\nmodels. I-SHEEP achieves a maximum relative improvement of 78.2\\% in the Alpaca\nEval, 24.0\\% in the MT Bench, and an absolute increase of 8.88\\% in the IFEval\naccuracy over subsequent iterations in Qwen-1.5 72B model. Additionally,\nI-SHEEP surpasses the base model in various standard benchmark generation\ntasks, achieving an average improvement of 24.77\\% in code generation tasks,\n12.04\\% in TrivialQA, and 20.29\\% in SQuAD. We also provide new insights based\non the experiment results. Our codes, datasets, and models are available at\n\\textbf{https://anonymous.4open.science/r/I-SHEEP}.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u53d6\u5f97\u91cd\u5927\u9032\u5c55\uff0c\u7136\u800c\uff0c\n\u901a\u7528\u7684\u5b78\u7fd2\u7bc4\u4f8b\u5c07 LLM \u8996\u70ba\u88ab\u52d5\u5f0f\u8cc7\u8a0a\u5132\u5b58\u5eab\uff0c\n\u5ffd\u7565\u5b83\u5011\u4e3b\u52d5\u5b78\u7fd2\u548c\u5c0d\u9f4a\u7684\u6f5b\u529b\u3002\u4e00\u4e9b\u65b9\u6cd5\n\u4f7f\u7528 LLM \u81ea\u884c\u7522\u751f\u7684\u5408\u6210\u8cc7\u6599\u8a13\u7df4 LLM\uff0c\u63a2\u7d22\u4e3b\u52d5\u5c0d\u9f4a\u7684\u53ef\u80fd\u6027\u3002\n\u7136\u800c\uff0c\u9019\u4e9b\u4e00\u6b21\u6027\u7684\u5c0d\u9f4a\u65b9\u6cd5\u8207\u4eba\u985e\u7684\u6301\u7e8c\u81ea\u52d5\u5c0d\u9f4a\u4e4b\u9593\u4ecd\u6709\u5f88\u5927\u5dee\u8ddd\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86\\textbf{I-SHEEP}\uff0c\u4e00\u500b\\textbf{I}terative\\textbf{S}elf-En\\textbf{H}anc\\textbf{E}m\\textbf{E}nt \\textbf{P}aradigm\u3002\u9019\u500b\n\u985e\u4f3c\u4eba\u985e\u7684\u7bc4\u4f8b\u4f7f LLM \u80fd\u5920\\textbf{\u5f9e\u982d\u958b\u59cb\u6301\u7e8c\u81ea\u6211\u5c0d\u9f4a\uff0c\u800c\u7121\u9700\u4efb\u4f55\u6771\u897f}\u3002\u8207\u4e00\u6b21\u6027\u5c0d\u9f4a\u65b9\u6cd5 Dromedary \u76f8\u6bd4\n\\cite{sun2023principledriven}\uff0c\u9019\u662f\u672c\u6587\u4e2d\u7684\u7b2c\u4e00\u6b21\u8fed\u4ee3\uff0cI-SHEEP \u53ef\u4ee5\u986f\u8457\u63d0\u5347 Qwen \u548c Llama \u6a21\u578b\u7684\u5bb9\u91cf\u3002I-SHEEP \u5728 Alpaca Eval \u4e2d\u5be6\u73fe\u4e86 78.2% \u7684\u6700\u5927\u76f8\u5c0d\u6539\u9032\uff0c\u5728 MT Bench \u4e2d\u5be6\u73fe\u4e86 24.0% \u7684\u6700\u5927\u76f8\u5c0d\u6539\u9032\uff0c\u4e26\u4e14\u5728 Qwen-1.5 72B \u6a21\u578b\u7684\u5f8c\u7e8c\u8fed\u4ee3\u4e2d\uff0cIFEval \u7684\u6e96\u78ba\u5ea6\u7d55\u5c0d\u63d0\u9ad8\u4e86 8.88%\u3002\u6b64\u5916\uff0c\nI-SHEEP \u5728\u5404\u7a2e\u6a19\u6e96\u57fa\u6e96\u751f\u6210\u4efb\u52d9\u4e2d\u8d85\u8d8a\u4e86\u57fa\u790e\u6a21\u578b\uff0c\u5728\u7a0b\u5f0f\u78bc\u751f\u6210\u4efb\u52d9\u4e2d\u5be6\u73fe\u4e86 24.77% \u7684\u5e73\u5747\u6539\u9032\uff0c\u5728 TrivialQA \u4e2d\u5be6\u73fe\u4e86 12.04% \u7684\u5e73\u5747\u6539\u9032\uff0c\u5728 SQuAD \u4e2d\u5be6\u73fe\u4e86 20.29% \u7684\u5e73\u5747\u6539\u9032\u3002\u6211\u5011\u4e5f\u6839\u64da\u5be6\u9a57\u7d50\u679c\u63d0\u4f9b\u4e86\u65b0\u7684\u898b\u89e3\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u3001\u8cc7\u6599\u96c6\u548c\u6a21\u578b\u53ef\u4ee5\u5728\u4ee5\u4e0b\u4f4d\u7f6e\u53d6\u5f97\uff1a\n\\textbf{https://anonymous.4open.science/r/I-SHEEP}\u3002", "author": "Yiming Liang et.al.", "authors": "Yiming Liang, Ge Zhang, Xingwei Qu, Tianyu Zheng, Jiawei Guo, Xinrun Du, Zhenzhu Yang, Jiaheng Liu, Chenghua Lin, Lei Ma, Wenhao Huang, Jiajun Zhang", "id": "2408.08072v1", "paper_url": "http://arxiv.org/abs/2408.08072v1", "repo": "null"}}