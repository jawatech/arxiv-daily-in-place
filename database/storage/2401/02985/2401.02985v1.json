{"2401.02985": {"publish_time": "2024-01-02", "title": "Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education", "paper_summary": "The rapid evolution of artificial intelligence (AI), especially in the domain\nof Large Language Models (LLMs) and generative AI, has opened new avenues for\napplication across various fields, yet its role in business education remains\nunderexplored. This study introduces the first benchmark to assess the\nperformance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and\nGPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models\n(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission\nprocess for graduate business programs. Our analysis shows that most LLMs\noutperform human candidates, with GPT-4 Turbo not only outperforming the other\nmodels but also surpassing the average scores of graduate students at top\nbusiness schools. Through a case study, this research examines GPT-4 Turbo's\nability to explain answers, evaluate responses, identify errors, tailor\ninstructions, and generate alternative scenarios. The latest LLM versions,\nGPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in\nreasoning tasks compared to their predecessors, underscoring their potential\nfor complex problem-solving. While AI's promise in education, assessment, and\ntutoring is clear, challenges remain. Our study not only sheds light on LLMs'\nacademic potential but also emphasizes the need for careful development and\napplication of AI in education. As AI technology advances, it is imperative to\nestablish frameworks and protocols for AI interaction, verify the accuracy of\nAI-generated content, ensure worldwide access for diverse learners, and create\nan educational environment where AI supports human expertise. This research\nsets the stage for further exploration into the responsible use of AI to enrich\neducational experiences and improve exam preparation and assessment methods.", "paper_summary_zh": "\u4eba\u5de5\u667a\u6167 (AI) \u7684\u5feb\u901f\u6f14\u9032\uff0c\u5c24\u5176\u662f\u5728\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u548c\u751f\u6210\u5f0f AI \u7684\u9818\u57df\uff0c\u70ba\u5404\u500b\u9818\u57df\u7684\u61c9\u7528\u958b\u555f\u4e86\u65b0\u9014\u5f91\uff0c\u4f46\u5176\u5728\u5546\u696d\u6559\u80b2\u4e2d\u7684\u89d2\u8272\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u8a0e\u3002\u672c\u7814\u7a76\u9996\u6b21\u5f15\u5165\u4e86\u57fa\u6e96\uff0c\u7528\u4ee5\u8a55\u4f30\u4e03\u500b\u4e3b\u8981 LLM \u7684\u6548\u80fd\uff0c\u5305\u62ec OpenAI \u7684\u6a21\u578b (GPT-3.5 Turbo\u3001GPT-4 \u548c GPT-4 Turbo)\u3001Google \u7684\u6a21\u578b (PaLM 2\u3001Gemini 1.0 Pro) \u548c Anthropic \u7684\u6a21\u578b (Claude 2 \u548c Claude 2.1)\uff0c\u9019\u4e9b\u6a21\u578b\u5c07\u7528\u65bc\u7814\u7a76\u751f\u5546\u696d\u8ab2\u7a0b\u5165\u5b78\u7a0b\u5e8f\u4e2d\u7684\u95dc\u9375\u8003\u8a66 GMAT\u3002\u6211\u5011\u7684\u5206\u6790\u986f\u793a\uff0c\u5927\u591a\u6578 LLM \u7684\u8868\u73fe\u90fd\u512a\u65bc\u4eba\u985e\u8003\u751f\uff0c\u5176\u4e2d GPT-4 Turbo \u4e0d\u50c5\u512a\u65bc\u5176\u4ed6\u6a21\u578b\uff0c\u66f4\u8d85\u8d8a\u4e86\u9802\u5c16\u5546\u5b78\u9662\u7684\u7814\u7a76\u751f\u5e73\u5747\u5206\u6578\u3002\u900f\u904e\u6848\u4f8b\u7814\u7a76\uff0c\u672c\u7814\u7a76\u63a2\u8a0e\u4e86 GPT-4 Turbo \u5728\u89e3\u91cb\u7b54\u6848\u3001\u8a55\u4f30\u56de\u61c9\u3001\u8fa8\u8b58\u932f\u8aa4\u3001\u8abf\u6574\u8aaa\u660e\u548c\u7522\u751f\u66ff\u4ee3\u60c5\u5883\u65b9\u9762\u7684\u80fd\u529b\u3002\u8207\u524d\u4e00\u4ee3\u7248\u672c\u76f8\u6bd4\uff0c\u6700\u65b0\u7684 LLM \u7248\u672c GPT-4 Turbo\u3001Claude 2.1 \u548c Gemini 1.0 Pro \u5728\u63a8\u7406\u4efb\u52d9\u65b9\u9762\u6709\u986f\u8457\u7684\u9032\u6b65\uff0c\u51f8\u986f\u4e86\u5176\u5728\u89e3\u6c7a\u8907\u96dc\u554f\u984c\u65b9\u9762\u7684\u6f5b\u529b\u3002\u5118\u7ba1 AI \u5728\u6559\u80b2\u3001\u8a55\u91cf\u548c\u8f14\u5c0e\u65b9\u9762\u7684\u627f\u8afe\u5f88\u660e\u78ba\uff0c\u4f46\u4ecd\u6709\u6311\u6230\u5b58\u5728\u3002\u6211\u5011\u7684\u7814\u7a76\u4e0d\u50c5\u95e1\u660e\u4e86 LLM \u7684\u5b78\u8853\u6f5b\u529b\uff0c\u4e5f\u5f37\u8abf\u4e86\u5728\u6559\u80b2\u4e2d\u5be9\u614e\u958b\u767c\u548c\u61c9\u7528 AI \u7684\u5fc5\u8981\u6027\u3002\u96a8\u8457 AI \u6280\u8853\u7684\u9032\u6b65\uff0c\u5efa\u7acb AI \u4e92\u52d5\u7684\u67b6\u69cb\u548c\u5354\u5b9a\u3001\u9a57\u8b49 AI \u751f\u6210\u7684\u5167\u5bb9\u7684\u6e96\u78ba\u6027\u3001\u78ba\u4fdd\u5168\u7403\u5404\u5730\u591a\u5143\u5b78\u7fd2\u8005\u7684\u5b58\u53d6\u6b0a\uff0c\u4ee5\u53ca\u5275\u9020\u4e00\u500b AI \u652f\u6301\u4eba\u985e\u5c08\u696d\u77e5\u8b58\u7684\u6559\u80b2\u74b0\u5883\u81f3\u95dc\u91cd\u8981\u3002\u672c\u7814\u7a76\u70ba\u9032\u4e00\u6b65\u63a2\u7d22\u8ca0\u8cac\u4efb\u5730\u4f7f\u7528 AI \u4f86\u8c50\u5bcc\u6559\u80b2\u9ad4\u9a57\u4e26\u6539\u5584\u8003\u8a66\u6e96\u5099\u548c\u8a55\u91cf\u65b9\u6cd5\u5960\u5b9a\u4e86\u57fa\u790e\u3002", "author": "Vahid Ashrafimoghari et.al.", "authors": "Vahid Ashrafimoghari, Necdet G\u00fcrkan, Jordan W. Suchow", "id": "2401.02985v1", "paper_url": "http://arxiv.org/abs/2401.02985v1", "repo": "null"}}