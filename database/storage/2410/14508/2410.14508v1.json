{"2410.14508": {"publish_time": "2024-10-18", "title": "LEAD: Latent Realignment for Human Motion Diffusion", "paper_summary": "Our goal is to generate realistic human motion from natural language. Modern\nmethods often face a trade-off between model expressiveness and text-to-motion\nalignment. Some align text and motion latent spaces but sacrifice\nexpressiveness; others rely on diffusion models producing impressive motions,\nbut lacking semantic meaning in their latent space. This may compromise\nrealism, diversity, and applicability. Here, we address this by combining\nlatent diffusion with a realignment mechanism, producing a novel, semantically\nstructured space that encodes the semantics of language. Leveraging this\ncapability, we introduce the task of textual motion inversion to capture novel\nmotion concepts from a few examples. For motion synthesis, we evaluate LEAD on\nHumanML3D and KIT-ML and show comparable performance to the state-of-the-art in\nterms of realism, diversity, and text-motion consistency. Our qualitative\nanalysis and user study reveal that our synthesized motions are sharper, more\nhuman-like and comply better with the text compared to modern methods. For\nmotion textual inversion, our method demonstrates improved capacity in\ncapturing out-of-distribution characteristics in comparison to traditional\nVAEs.", "paper_summary_zh": "\u6211\u4eec\u7684\u76ee\u6807\u662f\u6839\u636e\u81ea\u7136\u8bed\u8a00\u751f\u6210\u903c\u771f\u7684\u771f\u4eba\u52a8\u4f5c\u3002\u73b0\u4ee3\u65b9\u6cd5\u901a\u5e38\u4f1a\u5728\u6a21\u578b\u8868\u73b0\u529b\u4e0e\u6587\u672c\u5230\u52a8\u4f5c\u7684\u6bd4\u5bf9\u4e4b\u95f4\u9762\u4e34\u6743\u8861\u3002\u4e00\u4e9b\u65b9\u6cd5\u6bd4\u5bf9\u4e86\u6587\u672c\u548c\u52a8\u4f5c\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u4f46\u727a\u7272\u4e86\u8868\u73b0\u529b\uff1b\u5176\u4ed6\u65b9\u6cd5\u4f9d\u9760\u6269\u6563\u6a21\u578b\u6765\u5236\u4f5c\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u52a8\u4f5c\uff0c\u4f46\u5176\u6f5c\u5728\u7a7a\u95f4\u7f3a\u4e4f\u8bed\u4e49\u542b\u4e49\u3002\u8fd9\u53ef\u80fd\u4f1a\u635f\u5bb3\u771f\u5b9e\u6027\u3001\u591a\u6837\u6027\u548c\u9002\u7528\u6027\u3002\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u901a\u8fc7\u5c06\u6f5c\u5728\u6269\u6563\u4e0e\u91cd\u65b0\u6bd4\u5bf9\u673a\u5236\u76f8\u7ed3\u5408\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4ece\u800c\u751f\u6210\u4e00\u4e2a\u65b0\u9896\u7684\u3001\u8bed\u4e49\u7ed3\u6784\u5316\u7684\u7a7a\u95f4\uff0c\u5bf9\u8bed\u8a00\u7684\u8bed\u4e49\u8fdb\u884c\u7f16\u7801\u3002\u5229\u7528\u8fd9\u79cd\u80fd\u529b\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u6587\u672c\u52a8\u4f5c\u53cd\u6f14\u4efb\u52a1\uff0c\u4ee5\u4ece\u51e0\u4e2a\u793a\u4f8b\u4e2d\u6355\u6349\u65b0\u9896\u7684\u52a8\u4f5c\u6982\u5ff5\u3002\u5bf9\u4e8e\u52a8\u4f5c\u5408\u6210\uff0c\u6211\u4eec\u5728 HumanML3D \u548c KIT-ML \u4e0a\u8bc4\u4f30\u4e86 LEAD\uff0c\u5e76\u5c55\u793a\u4e86\u4e0e\u6700\u5148\u8fdb\u6280\u672f\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u5305\u62ec\u771f\u5b9e\u6027\u3001\u591a\u6837\u6027\u548c\u6587\u672c\u52a8\u4f5c\u4e00\u81f4\u6027\u3002\u6211\u4eec\u7684\u5b9a\u6027\u5206\u6790\u548c\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u4e0e\u73b0\u4ee3\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6211\u4eec\u5408\u6210\u7684\u52a8\u4f5c\u66f4\u6e05\u6670\u3001\u66f4\u50cf\u771f\u4eba\uff0c\u5e76\u4e14\u4e0e\u6587\u672c\u7684\u543b\u5408\u5ea6\u66f4\u9ad8\u3002\u5bf9\u4e8e\u52a8\u4f5c\u6587\u672c\u53cd\u6f14\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u6355\u6349\u5206\u5e03\u5916\u7279\u5f81\u65b9\u9762\u5c55\u793a\u4e86\u6bd4\u4f20\u7edf VAE \u66f4\u5f3a\u7684\u80fd\u529b\u3002", "author": "Nefeli Andreou et.al.", "authors": "Nefeli Andreou, Xi Wang, Victoria Fern\u00e1ndez Abrevaya, Marie-Paule Cani, Yiorgos Chrysanthou, Vicky Kalogeiton", "id": "2410.14508v1", "paper_url": "http://arxiv.org/abs/2410.14508v1", "repo": "null"}}