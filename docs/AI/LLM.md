
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-20**|**SpecTool: A Benchmark for Characterizing Errors in Tool-Use LLMs**|Shirley Kokane et.al.|[2411.13547v1](http://arxiv.org/abs/2411.13547v1)|null|
|**2024-11-20**|**BALROG: Benchmarking Agentic LLM and VLM Reasoning On Games**|Davide Paglieri et.al.|[2411.13543v1](http://arxiv.org/abs/2411.13543v1)|null|
|**2024-11-20**|**Metacognition for Unknown Situations and Environments (MUSE)**|Rodolfo Valiente et.al.|[2411.13537v1](http://arxiv.org/abs/2411.13537v1)|null|
|**2024-11-20**|**Identity Preserving 3D Head Stylization with Multiview Score Distillation**|Bahri Batuhan Bilecen et.al.|[2411.13536v1](http://arxiv.org/abs/2411.13536v1)|null|
|**2024-11-20**|**Predictive Insights into LGBTQ+ Minority Stress: A Transductive Exploration of Social Media Discourse**|S. Chapagain et.al.|[2411.13534v1](http://arxiv.org/abs/2411.13534v1)|null|
|**2024-11-20**|**Advancing Complex Medical Communication in Arabic with Sporo AraSum: Surpassing Existing Large Language Models**|Chanseo Lee et.al.|[2411.13518v1](http://arxiv.org/abs/2411.13518v1)|null|
|**2024-11-20**|**Disentangling Memory and Reasoning Ability in Large Language Models**|Mingyu Jin et.al.|[2411.13504v1](http://arxiv.org/abs/2411.13504v1)|[link](https://github.com/mingyuj666/disentangling-memory-and-reasoning)|
|**2024-11-20**|**Utilizing Large Language Models to Synthesize Product Desirability Datasets**|John D. Hastings et.al.|[2411.13485v1](http://arxiv.org/abs/2411.13485v1)|null|
|**2024-11-20**|**PatentEdits: Framing Patent Novelty as Textual Entailment**|Ryan Lee et.al.|[2411.13477v1](http://arxiv.org/abs/2411.13477v1)|null|
|**2024-11-20**|**When Precision Meets Position: BFloat16 Breaks Down RoPE in Long-Context Training**|Haonan Wang et.al.|[2411.13476v1](http://arxiv.org/abs/2411.13476v1)|[link](https://github.com/haonan3/anchorcontext)|
|**2024-11-20**|**SoK: A Systems Perspective on Compound AI Threats and Countermeasures**|Sarbartha Banerjee et.al.|[2411.13459v1](http://arxiv.org/abs/2411.13459v1)|null|
|**2024-11-20**|**LIMBA: An Open-Source Framework for the Preservation and Valorization of Low-Resource Languages using Generative Models**|Salvatore Mario Carta et.al.|[2411.13453v1](http://arxiv.org/abs/2411.13453v1)|null|
|**2024-11-20**|**AdaptAgent: Adapting Multimodal Web Agents with Few-Shot Learning from Human Demonstrations**|Gaurav Verma et.al.|[2411.13451v1](http://arxiv.org/abs/2411.13451v1)|null|
|**2024-11-20**|**Robust Monocular Visual Odometry using Curriculum Learning**|Assaf Lahiany et.al.|[2411.13438v1](http://arxiv.org/abs/2411.13438v1)|null|
|**2024-11-20**|**SynEHRgy: Synthesizing Mixed-Type Structured Electronic Health Records using Decoder-Only Transformers**|Hojjat Karami et.al.|[2411.13428v1](http://arxiv.org/abs/2411.13428v1)|null|
|**2024-11-20**|**WaterPark: A Robustness Assessment of Language Model Watermarking**|Jiacheng Liang et.al.|[2411.13425v1](http://arxiv.org/abs/2411.13425v1)|null|
|**2024-11-20**|**CAFE A Novel Code switching Dataset for Algerian Dialect French and English**|Houssam Eddine-Othman Lachemat et.al.|[2411.13424v1](http://arxiv.org/abs/2411.13424v1)|null|
|**2024-11-20**|**Heuristically Adaptive Diffusion-Model Evolutionary Strategy**|Benedikt Hartl et.al.|[2411.13420v1](http://arxiv.org/abs/2411.13420v1)|null|
|**2024-11-20**|**Unification of Balti and trans-border sister dialects in the essence of LLMs and AI Technology**|Muhammad Sharif et.al.|[2411.13409v1](http://arxiv.org/abs/2411.13409v1)|null|
|**2024-11-20**|**Transformer-Based Contextualized Language Models Joint with Neural Networks for Natural Language Inference in Vietnamese**|Dat Van-Thanh Nguyen et.al.|[2411.13407v1](http://arxiv.org/abs/2411.13407v1)|null|
|**2024-11-20**|**On the Way to LLM Personalization: Learning to Remember User Conversations**|Lucie Charlotte Magister et.al.|[2411.13405v1](http://arxiv.org/abs/2411.13405v1)|null|
|**2024-11-20**|**Executable QR codes with Machine Learning for Industrial Applications**|Stefano Scanzio et.al.|[2411.13400v1](http://arxiv.org/abs/2411.13400v1)|null|
|**2024-11-20**|**Explainable Finite-Memory Policies for Partially Observable Markov Decision Processes**|Muqsit Azeem et.al.|[2411.13365v1](http://arxiv.org/abs/2411.13365v1)|null|
|**2024-11-20**|**Fact-Level Confidence Calibration and Self-Correction**|Yige Yuan et.al.|[2411.13343v1](http://arxiv.org/abs/2411.13343v1)|null|
|**2024-11-20**|**Verifying Machine Unlearning with Explainable AI**|Àlex Pujol Vidal et.al.|[2411.13332v1](http://arxiv.org/abs/2411.13332v1)|null|
|**2024-11-20**|**An Evolutional Neural Network Framework for Classification of Microarray Data**|Maryam Eshraghi Evari et.al.|[2411.13326v1](http://arxiv.org/abs/2411.13326v1)|null|
|**2024-11-20**|**Are Large Language Models Memorizing Bug Benchmarks?**|Daniel Ramos et.al.|[2411.13323v1](http://arxiv.org/abs/2411.13323v1)|null|
|**2024-11-20**|**Scaling Laws for Online Advertisement Retrieval**|Yunli Wang et.al.|[2411.13322v1](http://arxiv.org/abs/2411.13322v1)|null|
|**2024-11-20**|**Combining Autoregressive and Autoencoder Language Models for Text Classification**|João Gonçalves et.al.|[2411.13282v1](http://arxiv.org/abs/2411.13282v1)|null|
|**2024-11-20**|**VideoAutoArena: An Automated Arena for Evaluating Large Multimodal Models in Video Analysis through User Simulation**|Ziyang Luo et.al.|[2411.13281v1](http://arxiv.org/abs/2411.13281v1)|null|
|**2024-11-20**|**Unlocking the Power of Gradient Guidance for Structure-Based Molecule Optimization**|Keyue Qiu et.al.|[2411.13280v1](http://arxiv.org/abs/2411.13280v1)|null|
|**2024-11-20**|**Towards Specification-Driven LLM-Based Generation of Embedded Automotive Software**|Minal Suresh Patil et.al.|[2411.13269v1](http://arxiv.org/abs/2411.13269v1)|null|
|**2024-11-20**|**FASTNav: Fine-tuned Adaptive Small-language-models Trained for Multi-point Robot Navigation**|Yuxuan Chen et.al.|[2411.13262v1](http://arxiv.org/abs/2411.13262v1)|null|
|**2024-11-20**|**BelHouse3D: A Benchmark Dataset for Assessing Occlusion Robustness in 3D Point Cloud Semantic Segmentation**|Umamaheswaran Raman Kumar et.al.|[2411.13251v1](http://arxiv.org/abs/2411.13251v1)|null|
|**2024-11-20**|**Leveraging Prior Experience: An Expandable Auxiliary Knowledge Base for Text-to-SQL**|Zhibo Chu et.al.|[2411.13244v1](http://arxiv.org/abs/2411.13244v1)|null|
|**2024-11-20**|**XMask3D: Cross-modal Mask Reasoning for Open Vocabulary 3D Semantic Segmentation**|Ziyi Wang et.al.|[2411.13243v1](http://arxiv.org/abs/2411.13243v1)|[link](https://github.com/wangzy22/xmask3d)|
|**2024-11-20**|**Transforming the Hybrid Cloud for Emerging AI Workloads**|Deming Chen et.al.|[2411.13239v1](http://arxiv.org/abs/2411.13239v1)|null|
|**2024-11-20**|**BIPro: Zero-shot Chinese Poem Generation via Block Inverse Prompting Constrained Generation Framework**|Xu Zou et.al.|[2411.13237v1](http://arxiv.org/abs/2411.13237v1)|null|
|**2024-11-20**|**AIDBench: A benchmark for evaluating the authorship identification capability of large language models**|Zichen Wen et.al.|[2411.13226v1](http://arxiv.org/abs/2411.13226v1)|null|
|**2024-11-20**|**Quantum Kernel-Based Long Short-term Memory**|Yu-Chao Hsu et.al.|[2411.13225v1](http://arxiv.org/abs/2411.13225v1)|null|
|**2024-11-20**|**Existential Conversations with Large Language Models: Content, Community, and Culture**|Murray Shanahan et.al.|[2411.13223v1](http://arxiv.org/abs/2411.13223v1)|null|
|**2024-11-20**|**Comparative Analysis of Audio Feature Extraction for Real-Time Talking Portrait Synthesis**|Pegah Salehi et.al.|[2411.13209v1](http://arxiv.org/abs/2411.13209v1)|[link](https://github.com/pegahs1993/whisper-afe-talkingheadsgen)|
|**2024-11-20**|**The Information Security Awareness of Large Language Models**|Ofir Cohen et.al.|[2411.13207v1](http://arxiv.org/abs/2411.13207v1)|null|
|**2024-11-20**|**Engagement-Driven Content Generation with Large Language Models**|Erica Coppolillo et.al.|[2411.13187v1](http://arxiv.org/abs/2411.13187v1)|null|
|**2024-11-20**|**Cross-Camera Distracted Driver Classification through Feature Disentanglement and Contrastive Learning**|Simone Bianco et.al.|[2411.13181v1](http://arxiv.org/abs/2411.13181v1)|null|
|**2024-11-20**|**Writing Style Matters: An Examination of Bias and Fairness in Information Retrieval Systems**|Hongliu Cao et.al.|[2411.13173v1](http://arxiv.org/abs/2411.13173v1)|null|
|**2024-11-20**|**Hard-Synth: Synthesizing Diverse Hard Samples for ASR using Zero-Shot TTS and LLM**|Jiawei Yu et.al.|[2411.13159v1](http://arxiv.org/abs/2411.13159v1)|null|
|**2024-11-20**|**Closer Look at Efficient Inference Methods: A Survey of Speculative Decoding**|Hyun Ryu et.al.|[2411.13157v1](http://arxiv.org/abs/2411.13157v1)|null|
|**2024-11-20**|**DMQR-RAG: Diverse Multi-Query Rewriting for RAG**|Zhicong Li et.al.|[2411.13154v1](http://arxiv.org/abs/2411.13154v1)|null|
|**2024-11-20**|**AGLP: A Graph Learning Perspective for Semi-supervised Domain Adaptation**|Houcheng Su et.al.|[2411.13152v1](http://arxiv.org/abs/2411.13152v1)|null|
|**2024-11-20**|**GraphCL: Graph-based Clustering for Semi-Supervised Medical Image Segmentation**|Mengzhu Wang et.al.|[2411.13147v1](http://arxiv.org/abs/2411.13147v1)|null|
|**2024-11-20**|**CopyrightMeter: Revisiting Copyright Protection in Text-to-image Models**|Naen Xu et.al.|[2411.13144v1](http://arxiv.org/abs/2411.13144v1)|null|
|**2024-11-20**|**Video-RAG: Visually-aligned Retrieval-Augmented Long Video Comprehension**|Yongdong Luo et.al.|[2411.13093v1](http://arxiv.org/abs/2411.13093v1)|[link](https://github.com/leon1207/video-rag-master)|
|**2024-11-20**|**Patience Is The Key to Large Language Model Reasoning**|Yijiong Yu et.al.|[2411.13082v1](http://arxiv.org/abs/2411.13082v1)|null|
|**2024-11-20**|**Neural Internal Model Control: Learning a Robust Control Policy via Predictive Error Feedback**|Feng Gao et.al.|[2411.13079v1](http://arxiv.org/abs/2411.13079v1)|[link](https://github.com/thu-uav/neuralimc)|
|**2024-11-20**|**Branches, Assemble! Multi-Branch Cooperation Network for Large-Scale Click-Through Rate Prediction at Taobao**|Xu Chen et.al.|[2411.13057v1](http://arxiv.org/abs/2411.13057v1)|null|
|**2024-11-20**|**MEGL: Multimodal Explanation-Guided Learning**|Yifei Zhang et.al.|[2411.13053v1](http://arxiv.org/abs/2411.13053v1)|null|
|**2024-11-20**|**Explainable LLM-driven Multi-dimensional Distillation for E-Commerce Relevance Learning**|Gang Zhao et.al.|[2411.13045v1](http://arxiv.org/abs/2411.13045v1)|null|
|**2024-11-20**|**"It was 80% me, 20% AI": Seeking Authenticity in Co-Writing with Large Language Models**|Angel Hsing-Chi Hwang et.al.|[2411.13032v1](http://arxiv.org/abs/2411.13032v1)|null|
|**2024-11-20**|**LLMSteer: Improving Long-Context LLM Inference by Steering Attention on Reused Contexts**|Zhuohan Gu et.al.|[2411.13009v1](http://arxiv.org/abs/2411.13009v1)|null|
|**2024-11-20**|**Evaluating LLMs Capabilities Towards Understanding Social Dynamics**|Anique Tahir et.al.|[2411.13008v1](http://arxiv.org/abs/2411.13008v1)|null|
|**2024-11-20**|**Automating Sonologists USG Commands with AI and Voice Interface**|Emad Mohamed et.al.|[2411.13006v1](http://arxiv.org/abs/2411.13006v1)|null|
|**2024-11-20**|**MemoryFormer: Minimize Transformer Computation by Removing Fully-Connected Layers**|Ning Ding et.al.|[2411.12992v1](http://arxiv.org/abs/2411.12992v1)|null|
|**2024-11-20**|**BetterBench: Assessing AI Benchmarks, Uncovering Issues, and Establishing Best Practices**|Anka Reuel et.al.|[2411.12990v1](http://arxiv.org/abs/2411.12990v1)|null|
|**2024-11-20**|**Training Bilingual LMs with Data Constraints in the Targeted Language**|Skyler Seto et.al.|[2411.12986v1](http://arxiv.org/abs/2411.12986v1)|null|
|**2024-11-20**|**LaVida Drive: Vision-Text Interaction VLM for Autonomous Driving with Token Selection, Recovery and Enhancement**|Siwen Jiao et.al.|[2411.12980v1](http://arxiv.org/abs/2411.12980v1)|null|
|**2024-11-20**|**MindForge: Empowering Embodied Agents with Theory of Mind for Lifelong Collaborative Learning**|Mircea Lică et.al.|[2411.12977v1](http://arxiv.org/abs/2411.12977v1)|null|
|**2024-11-20**|**Shrinking POMCP: A Framework for Real-Time UAV Search and Rescue**|Yunuo Zhang et.al.|[2411.12967v1](http://arxiv.org/abs/2411.12967v1)|null|
|**2024-11-20**|**Real-Time Energy-Optimal Path Planning for Electric Vehicles**|Saman Ahmadi et.al.|[2411.12964v1](http://arxiv.org/abs/2411.12964v1)|null|
|**2024-11-20**|**KAAE: Numerical Reasoning for Knowledge Graphs via Knowledge-aware Attributes Learning**|Ming Yin et.al.|[2411.12950v1](http://arxiv.org/abs/2411.12950v1)|null|
|**2024-11-20**|**A Flexible Large Language Models Guardrail Development Methodology Applied to Off-Topic Prompt Detection**|Gabriel Chua et.al.|[2411.12946v1](http://arxiv.org/abs/2411.12946v1)|null|
|**2024-11-19**|**Loss-to-Loss Prediction: Scaling Laws for All Datasets**|David Brandfonbrener et.al.|[2411.12925v1](http://arxiv.org/abs/2411.12925v1)|[link](https://github.com/kempnerinstitute/loss-to-loss-olmo)|
|**2024-11-19**|**Human-In-the-Loop Software Development Agents**|Wannita Takerngsaksiri et.al.|[2411.12924v1](http://arxiv.org/abs/2411.12924v1)|null|
|**2024-11-19**|**A Comparative Study of Text Retrieval Models on DaReCzech**|Jakub Stetina et.al.|[2411.12921v1](http://arxiv.org/abs/2411.12921v1)|null|
|**2024-11-19**|**Enhancing Deep Learning-Driven Multi-Coil MRI Reconstruction via Self-Supervised Denoising**|Asad Aali et.al.|[2411.12919v1](http://arxiv.org/abs/2411.12919v1)|[link](https://github.com/utcsilab/gsure-diffusion-mri)|
|**2024-11-19**|**MLDGG: Meta-Learning for Domain Generalization on Graphs**|Qin Tian et.al.|[2411.12913v1](http://arxiv.org/abs/2411.12913v1)|null|
|**2024-11-19**|**Signformer is all you need: Towards Edge AI for Sign Language**|Eta Yang et.al.|[2411.12901v1](http://arxiv.org/abs/2411.12901v1)|[link](https://github.com/EtaEnding/Signformer)|
|**2024-11-19**|**Selective Attention: Enhancing Transformer through Principled Context Control**|Xuechen Zhang et.al.|[2411.12892v1](http://arxiv.org/abs/2411.12892v1)|null|
|**2024-11-19**|**ProSec: Fortifying Code LLMs with Proactive Security Alignment**|Xiangzhe Xu et.al.|[2411.12882v1](http://arxiv.org/abs/2411.12882v1)|null|
|**2024-11-19**|**Advancing Large Language Models for Spatiotemporal and Semantic Association Mining of Similar Environmental Events**|Yuanyuan Tian et.al.|[2411.12880v1](http://arxiv.org/abs/2411.12880v1)|null|
|**2024-11-19**|**The Illusion of Empathy: How AI Chatbots Shape Conversation Perception**|Tingting Liu et.al.|[2411.12877v1](http://arxiv.org/abs/2411.12877v1)|null|
|**2024-11-19**|**Puppet-CNN: Input-Adaptive Convolutional Neural Networks with Model Compression using Ordinary Differential Equation**|Yucheng Xing et.al.|[2411.12876v1](http://arxiv.org/abs/2411.12876v1)|null|
|**2024-11-19**|**From Text to Pose to Image: Improving Diffusion Model Control and Quality**|Clément Bonnett et.al.|[2411.12872v1](http://arxiv.org/abs/2411.12872v1)|[link](https://github.com/clement-bonnet/text-to-pose)|
|**2024-11-19**|**AzSLD: Azerbaijani Sign Language Dataset for Fingerspelling, Word, and Sentence Translation with Baseline Software**|Nigar Alishzade et.al.|[2411.12865v1](http://arxiv.org/abs/2411.12865v1)|null|
|**2024-11-19**|**Reward Modeling with Ordinal Feedback: Wisdom of the Crowd**|Shang Liu et.al.|[2411.12843v1](http://arxiv.org/abs/2411.12843v1)|null|
|**2024-11-19**|**Efficient Medicinal Image Transmission and Resolution Enhancement via GAN**|Rishabh Kumar Sharma et.al.|[2411.12833v1](http://arxiv.org/abs/2411.12833v1)|null|
|**2024-11-19**|**Human-Robot Dialogue Annotation for Multi-Modal Common Ground**|Claire Bonial et.al.|[2411.12829v1](http://arxiv.org/abs/2411.12829v1)|null|
|**2024-11-19**|**Probing the Capacity of Language Model Agents to Operationalize Disparate Experiential Context Despite Distraction**|Sonny George et.al.|[2411.12828v1](http://arxiv.org/abs/2411.12828v1)|[link](https://github.com/sonnygeorge/oedd)|
|**2024-11-19**|**Declare and Justify: Explicit assumptions in AI evaluations are necessary for effective regulation**|Peter Barnett et.al.|[2411.12820v1](http://arxiv.org/abs/2411.12820v1)|null|
|**2024-11-19**|**Conversational Medical AI: Ready for Practice**|Antoine Lizée et.al.|[2411.12808v1](http://arxiv.org/abs/2411.12808v1)|null|
|**2024-11-19**|**ACING: Actor-Critic for Instruction Learning in Black-Box Large Language Models**|Salma Kharrat et.al.|[2411.12736v1](http://arxiv.org/abs/2411.12736v1)|[link](https://github.com/salmakh1/ACING)|
|**2024-11-19**|**Benchmarking Positional Encodings for GNNs and Graph Transformers**|Florian Grötschla et.al.|[2411.12732v1](http://arxiv.org/abs/2411.12732v1)|[link](https://github.com/ETH-DISCO/Benchmarking-PEs)|
|**2024-11-19**|**Information Theory of Meaningful Communication**|Doron Sivan et.al.|[2411.12728v1](http://arxiv.org/abs/2411.12728v1)|null|
|**2024-11-19**|**Scaling laws for nonlinear dynamical models of speech**|Sam Kirkham et.al.|[2411.12720v1](http://arxiv.org/abs/2411.12720v1)|null|
|**2024-11-19**|**Rethinking MUSHRA: Addressing Modern Challenges in Text-to-Speech Evaluation**|Praveen Srinivasa Varadhan et.al.|[2411.12719v1](http://arxiv.org/abs/2411.12719v1)|null|
|**2024-11-19**|**CATCH: Complementary Adaptive Token-level Contrastive Decoding to Mitigate Hallucinations in LVLMs**|Zhehan Kan et.al.|[2411.12713v1](http://arxiv.org/abs/2411.12713v1)|null|
|**2024-11-19**|**Enhancing Multi-Class Disease Classification: Neoplasms, Cardiovascular, Nervous System, and Digestive Disorders Using Advanced LLMs**|Ahmed Akib Jawad Karim et.al.|[2411.12712v1](http://arxiv.org/abs/2411.12712v1)|null|
|**2024-11-19**|**Strengthening Fake News Detection: Leveraging SVM and Sophisticated Text Vectorization Techniques. Defying BERT?**|Ahmed Akib Jawad Karim et.al.|[2411.12703v1](http://arxiv.org/abs/2411.12703v1)|null|
|**2024-11-19**|**When Backdoors Speak: Understanding LLM Backdoor Attacks Through Model-Generated Explanations**|Huaizhi Ge et.al.|[2411.12701v1](http://arxiv.org/abs/2411.12701v1)|null|
|**2024-11-19**|**Attribute Inference Attacks for Federated Regression Tasks**|Francesco Diana et.al.|[2411.12697v1](http://arxiv.org/abs/2411.12697v1)|null|

#### Abstracts
##### **SpecTool: A Benchmark for Characterizing Errors in Tool-Use LLMs**
2411.13547v1 by Shirley Kokane, Ming Zhu, Tulika Awalgaonkar, Jianguo Zhang, Thai Hoang, Akshara Prabhakar, Zuxin Liu, Tian Lan, Liangwei Yang, Juntao Tan, Rithesh Murthy, Weiran Yao, Zhiwei Liu, Juan Carlos Niebles, Huan Wang, Shelby Heinecke, Caiming Xiong, Silivo Savarese

Evaluating the output of Large Language Models (LLMs) is one of the most
critical aspects of building a performant compound AI system. Since the output
from LLMs propagate to downstream steps, identifying LLM errors is crucial to
system performance. A common task for LLMs in AI systems is tool use. While
there are several benchmark environments for evaluating LLMs on this task, they
typically only give a success rate without any explanation of the failure
cases. To solve this problem, we introduce SpecTool, a new benchmark to
identify error patterns in LLM output on tool-use tasks. Our benchmark data set
comprises of queries from diverse environments that can be used to test for the
presence of seven newly characterized error patterns. Using SPECTOOL , we show
that even the most prominent LLMs exhibit these error patterns in their
outputs. Researchers can use the analysis and insights from SPECTOOL to guide
their error mitigation strategies.

摘要：評估大型語言模型 (LLM) 的輸出是建構高效能複合式 AI 系統最重要的面向之一。由於 LLM 的輸出會傳播到下游步驟，因此找出 LLM 錯誤對於系統效能至關重要。在 AI 系統中，LLM 的一項常見任務是使用工具。雖然有幾個用於評估 LLM 執行此項任務的基準環境，但它們通常只提供成功率，而沒有說明失敗案例。為了解決這個問題，我們引進 SpecTool，一個用於找出 LLM 在工具使用任務中輸出錯誤模式的新基準。我們的基準資料集包含來自不同環境的查詢，可據以測試七種新特徵化錯誤模式的存在。使用 SPECTOOL，我們顯示出即使是最傑出的 LLM 也會在其輸出中展現這些錯誤模式。研究人員可以使用 SPECTOOL 的分析和見解來引導他們的錯誤緩解策略。

##### **BALROG: Benchmarking Agentic LLM and VLM Reasoning On Games**
2411.13543v1 by Davide Paglieri, Bartłomiej Cupiał, Samuel Coward, Ulyana Piterbarg, Maciej Wolczyk, Akbir Khan, Eduardo Pignatelli, Łukasz Kuciński, Lerrel Pinto, Rob Fergus, Jakob Nicolaus Foerster, Jack Parker-Holder, Tim Rocktäschel

Large Language Models (LLMs) and Vision Language Models (VLMs) possess
extensive knowledge and exhibit promising reasoning abilities; however, they
still struggle to perform well in complex, dynamic environments. Real-world
tasks require handling intricate interactions, advanced spatial reasoning,
long-term planning, and continuous exploration of new strategies-areas in which
we lack effective methodologies for comprehensively evaluating these
capabilities. To address this gap, we introduce BALROG, a novel benchmark
designed to assess the agentic capabilities of LLMs and VLMs through a diverse
set of challenging games. Our benchmark incorporates a range of existing
reinforcement learning environments with varying levels of difficulty,
including tasks that are solvable by non-expert humans in seconds to extremely
challenging ones that may take years to master (e.g., the NetHack Learning
Environment). We devise fine-grained metrics to measure performance and conduct
an extensive evaluation of several popular open-source and closed-source LLMs
and VLMs. Our findings indicate that while current models achieve partial
success in the easier games, they struggle significantly with more challenging
tasks. Notably, we observe severe deficiencies in vision-based decision-making,
as models perform worse when visual representations of the environments are
provided. We release BALROG as an open and user-friendly benchmark to
facilitate future research and development in the agentic community.

摘要：大型語言模型 (LLM) 和視覺語言模型 (VLM) 擁有
廣泛的知識並展現出有前途的推理能力；然而，它們
在複雜、動態的環境中仍然難以表現良好。現實世界的
任務需要處理複雜的互動、先進的空間推理、
長期規劃和持續探索新的策略，我們缺乏有效的
方法來全面評估這些能力。為了解決這個差距，我們引入了 BALROG，一個新基準
旨在通過一系列具有挑戰性的遊戲來評估 LLM 和 VLM 的代理能力。我們的基準納入了範圍廣泛的現有
強化學習環境，難度各不相同，
包括非專家人類可以在幾秒鐘內解決的任務到可能需要數年才能掌握的極具挑戰性的任務（例如 NetHack 學習
環境）。我們設計了細緻的指標來衡量性能並進行
對幾個流行的開源和閉源 LLM
和 VLM 進行廣泛的評估。我們的研究結果表明，雖然當前模型在較簡單的遊戲中取得了部分成功，但它們在更具挑戰性的
任務中顯著掙扎。值得注意的是，我們觀察到基於視覺的決策制定存在嚴重缺陷，
因為當提供環境的視覺表示時，模型的表現會更差。我們將 BALROG 發布為一個開放且用戶友好的基準，以
促進代理社區未來的研究和開發。

##### **Metacognition for Unknown Situations and Environments (MUSE)**
2411.13537v1 by Rodolfo Valiente, Praveen K. Pilly

Metacognition--the awareness and regulation of one's cognitive processes--is
central to human adaptability in unknown situations. In contrast, current
autonomous agents often struggle in novel environments due to their limited
capacity for adaptation. We hypothesize that metacognition is a critical
missing ingredient in adaptive autonomous systems, equipping them with the
cognitive flexibility needed to tackle unfamiliar challenges. Given the broad
scope of metacognitive abilities, we focus on two key aspects: competence
awareness and strategy selection for novel tasks. To this end, we propose the
Metacognition for Unknown Situations and Environments (MUSE) framework, which
integrates metacognitive processes--specifically self-awareness and
self-regulation--into autonomous agents. We present two initial implementations
of MUSE: one based on world modeling and another leveraging large language
models (LLMs), both instantiating the metacognitive cycle. Our system
continuously learns to assess its competence on a given task and uses this
self-awareness to guide iterative cycles of strategy selection. MUSE agents
show significant improvements in self-awareness and self-regulation, enabling
them to solve novel, out-of-distribution tasks more effectively compared to
Dreamer-v3-based reinforcement learning and purely prompt-based LLM agent
approaches. This work highlights the promise of approaches inspired by
cognitive and neural systems in enabling autonomous systems to adapt to new
environments, overcoming the limitations of current methods that rely heavily
on extensive training data.

摘要：元認知——對自身認知過程的覺察與調節——是人類在未知情境中適應能力的中心。相比之下，當前的自主代理經常在新的環境中掙扎，因為它們的適應能力有限。我們假設元認知是適應性自主系統中一個重要的遺失成分，它為它們提供了應對不熟悉挑戰所需的認知靈活性。鑑於元認知能力的廣泛範圍，我們專注於兩個關鍵方面：能力意識和新任務的策略選擇。為此，我們提出了未知情境和環境的元認知 (MUSE) 框架，它將元認知過程——特別是自我意識和自我調節——整合到自主代理中。我們提出了 MUSE 的兩個初始實現：一個基於世界建模，另一個利用大型語言模型 (LLM)，兩者都實例化了元認知迴圈。我們的系統持續學習評估其在給定任務上的能力，並利用這種自我意識來指導策略選擇的迭代迴圈。與基於 Dreamer-v3 的強化學習和純粹基於提示的 LLM 代理方法相比，MUSE 代理在自我意識和自我調節方面表現出顯著的改進，使它們能夠更有效地解決新穎的、分布外的任務。這項工作突出了受認知和神經系統啟發的方法在使自主系統適應新環境方面的前景，克服了當前方法的局限性，而當前方法過於依賴於大量的訓練資料。

##### **Identity Preserving 3D Head Stylization with Multiview Score Distillation**
2411.13536v1 by Bahri Batuhan Bilecen, Ahmet Berke Gokmen, Furkan Guzelant, Aysegul Dundar

3D head stylization transforms realistic facial features into artistic
representations, enhancing user engagement across gaming and virtual reality
applications. While 3D-aware generators have made significant advancements,
many 3D stylization methods primarily provide near-frontal views and struggle
to preserve the unique identities of original subjects, often resulting in
outputs that lack diversity and individuality. This paper addresses these
challenges by leveraging the PanoHead model, synthesizing images from a
comprehensive 360-degree perspective. We propose a novel framework that employs
negative log-likelihood distillation (LD) to enhance identity preservation and
improve stylization quality. By integrating multi-view grid score and mirror
gradients within the 3D GAN architecture and introducing a score rank weighing
technique, our approach achieves substantial qualitative and quantitative
improvements. Our findings not only advance the state of 3D head stylization
but also provide valuable insights into effective distillation processes
between diffusion models and GANs, focusing on the critical issue of identity
preservation. Please visit the https://three-bee.github.io/head_stylization for
more visuals.

摘要：3D 頭部風格化將逼真的臉部特徵轉換成藝術表現，提升遊戲和虛擬實境應用中的使用者參與度。雖然 3D 感知生成器已取得顯著進展，但許多 3D 風格化方法主要提供近乎正面的視角，且難以保留原始主體的獨特身分，通常導致產出缺乏多樣性和個性。本文透過利用 PanoHead 模型，從全面的 360 度視角合成影像，來解決這些挑戰。我們提出一個新的架構，採用負對數似然蒸餾 (LD) 來增強身分保留並提升風格化品質。透過整合多視角網格評分和鏡像梯度於 3D GAN 架構中，並引入評分等級加權技術，我們的做法在質量和數量上皆取得顯著的進步。我們的發現不僅推進了 3D 頭部風格化的現況，也提供了關於擴散模型和 GAN 之間有效蒸餾程序的寶貴見解，重點關注身分保留的關鍵問題。請造訪 https://three-bee.github.io/head_stylization 以取得更多視覺效果。

##### **Predictive Insights into LGBTQ+ Minority Stress: A Transductive Exploration of Social Media Discourse**
2411.13534v1 by S. Chapagain, Y. Zhao, T. K. Rohleen, S. M. Hamdi, S. F. Boubrahimi, R. E. Flinn, E. M. Lund, D. Klooster, J. R. Scheer, C. J. Cascalheira

Individuals who identify as sexual and gender minorities, including lesbian,
gay, bisexual, transgender, queer, and others (LGBTQ+) are more likely to
experience poorer health than their heterosexual and cisgender counterparts.
One primary source that drives these health disparities is minority stress
(i.e., chronic and social stressors unique to LGBTQ+ communities' experiences
adapting to the dominant culture). This stress is frequently expressed in
LGBTQ+ users' posts on social media platforms. However, these expressions are
not just straightforward manifestations of minority stress. They involve
linguistic complexity (e.g., idiom or lexical diversity), rendering them
challenging for many traditional natural language processing methods to detect.
In this work, we designed a hybrid model using Graph Neural Networks (GNN) and
Bidirectional Encoder Representations from Transformers (BERT), a pre-trained
deep language model to improve the classification performance of minority
stress detection. We experimented with our model on a benchmark social media
dataset for minority stress detection (LGBTQ+ MiSSoM+). The dataset is
comprised of 5,789 human-annotated Reddit posts from LGBTQ+ subreddits. Our
approach enables the extraction of hidden linguistic nuances through
pretraining on a vast amount of raw data, while also engaging in transductive
learning to jointly develop representations for both labeled training data and
unlabeled test data. The RoBERTa-GCN model achieved an accuracy of 0.86 and an
F1 score of 0.86, surpassing the performance of other baseline models in
predicting LGBTQ+ minority stress. Improved prediction of minority stress
expressions on social media could lead to digital health interventions to
improve the wellbeing of LGBTQ+ people-a community with high rates of
stress-sensitive health problems.

摘要：<paragraph>認同自己是性與性別少數族群的人，包括女同性戀、男同性戀、雙性戀、跨性別、酷兒和其他 LGBTQ+ 族群，比異性戀和順性別者更容易有較差的健康狀況。造成這些健康差異的主要來源之一是少數族群壓力（即 LGBTQ+ 社群在適應主流文化時獨有的慢性與社會壓力）。這種壓力經常在 LGBTQ+ 使用者於社群媒體平台上的貼文中表達出來。然而，這些表達並不僅僅是少數族群壓力的直接表現。它們包含了語言複雜性（例如慣用語或詞彙多樣性），讓許多傳統的自然語言處理方法難以辨識。在這項研究中，我們設計了一個混合模型，使用圖神經網路 (GNN) 和來自 Transformer 的雙向編碼器表徵 (BERT)，這是一個經過預先訓練的深度語言模型，以提升少數族群壓力辨識的分類效能。我們在一個用於少數族群壓力辨識的基準社群媒體資料集 (LGBTQ+ MiSSoM+) 上對我們的模型進行實驗。該資料集包含了 5,789 篇由人類註解的 Reddit 貼文，來自於 LGBTQ+ 的 subreddit。我們的做法能夠透過在大量的原始資料上進行預訓練來萃取隱藏的語言差異，同時也參與轉導式學習，以共同開發標籤訓練資料和未標籤測試資料的表徵。RoBERTa-GCN 模型達到了 0.86 的準確率和 0.86 的 F1 分數，在預測 LGBTQ+ 少數族群壓力方面超越了其他基線模型的效能。在社群媒體上對少數族群壓力表達的預測改善，可以導致數位健康介入措施，以改善 LGBTQ+ 族群的福祉，而這個族群有很高的壓力敏感性健康問題發生率。</paragraph>

##### **Advancing Complex Medical Communication in Arabic with Sporo AraSum: Surpassing Existing Large Language Models**
2411.13518v1 by Chanseo Lee, Sonu Kumar, Kimon A. Vogt, Sam Meraj, Antonia Vogt

The increasing demand for multilingual capabilities in healthcare underscores
the need for AI models adept at processing diverse languages, particularly in
clinical documentation and decision-making. Arabic, with its complex
morphology, syntax, and diglossia, poses unique challenges for natural language
processing (NLP) in medical contexts. This case study evaluates Sporo AraSum, a
language model tailored for Arabic clinical documentation, against JAIS, the
leading Arabic NLP model. Using synthetic datasets and modified PDQI-9 metrics
modified ourselves for the purposes of assessing model performances in a
different language. The study assessed the models' performance in summarizing
patient-physician interactions, focusing on accuracy, comprehensiveness,
clinical utility, and linguistic-cultural competence.
  Results indicate that Sporo AraSum significantly outperforms JAIS in
AI-centric quantitative metrics and all qualitative attributes measured in our
modified version of the PDQI-9. AraSum's architecture enables precise and
culturally sensitive documentation, addressing the linguistic nuances of Arabic
while mitigating risks of AI hallucinations. These findings suggest that Sporo
AraSum is better suited to meet the demands of Arabic-speaking healthcare
environments, offering a transformative solution for multilingual clinical
workflows. Future research should incorporate real-world data to further
validate these findings and explore broader integration into healthcare
systems.

摘要：醫療保健領域對多語言能力的需求日益增加，這凸顯了對善於處理各種語言的 AI 模型的需求，特別是在臨床文件和決策制定中。阿拉伯語具有複雜的形態、語法和雙語現象，這對醫療環境中的自然語言處理 (NLP) 構成了獨特的挑戰。本案例研究評估了 Sporo AraSum（一種專為阿拉伯語臨床文件量身打造的語言模型）和阿拉伯語 NLP 模型的領導者 JAIS。我們使用合成資料集和修改後的 PDQI-9 指標（我們自行修改，以評估模型在不同語言中的表現）。本研究評估了模型在總結患者與醫師互動時的表現，重點在於準確性、全面性、臨床效用和語言文化能力。
結果表明，在以 AI 為中心的定量指標和我們修改後的 PDQI-9 版本中測量的所有定性屬性中，Sporo AraSum 明顯優於 JAIS。AraSum 的架構能產生精確且具有文化敏感度的文件，它能處理阿拉伯語的語言差異，同時降低 AI 產生幻覺的風險。這些發現表明，Sporo AraSum 更適合滿足講阿拉伯語的醫療保健環境的需求，為多語言臨床工作流程提供了一個變革性的解決方案。未來的研究應納入真實世界的資料，以進一步驗證這些發現，並探索更廣泛地整合到醫療保健系統中。

##### **Disentangling Memory and Reasoning Ability in Large Language Models**
2411.13504v1 by Mingyu Jin, Weidi Luo, Sitao Cheng, Xinyi Wang, Wenyue Hua, Ruixiang Tang, William Yang Wang, Yongfeng Zhang

Large Language Models (LLMs) have demonstrated strong performance in handling
complex tasks requiring both extensive knowledge and reasoning abilities.
However, the existing LLM inference pipeline operates as an opaque process
without explicit separation between knowledge retrieval and reasoning steps,
making the model's decision-making process unclear and disorganized. This
ambiguity can lead to issues such as hallucinations and knowledge forgetting,
which significantly impact the reliability of LLMs in high-stakes domains. In
this paper, we propose a new inference paradigm that decomposes the complex
inference process into two distinct and clear actions: (1) memory recall: which
retrieves relevant knowledge, and (2) reasoning: which performs logical steps
based on the recalled knowledge. To facilitate this decomposition, we introduce
two special tokens memory and reason, guiding the model to distinguish between
steps that require knowledge retrieval and those that involve reasoning. Our
experiment results show that this decomposition not only improves model
performance but also enhances the interpretability of the inference process,
enabling users to identify sources of error and refine model responses
effectively. The code is available at
https://github.com/MingyuJ666/Disentangling-Memory-and-Reasoning.

摘要：大型語言模型 (LLM) 已證明在處理需要廣泛知識和推理能力的複雜任務方面具有強勁的效能。然而，現有的 LLM 推論管道以不透明的程序運作，知識擷取和推理步驟之間沒有明確的區分，使得模型的決策過程不明確且混亂。這種模糊性可能導致幻覺和知識遺忘等問題，這會嚴重影響 LLM 在高風險領域的可靠性。在本文中，我們提出了一種新的推論範例，將複雜的推論過程分解為兩個不同且明確的動作：(1) 記憶回想：擷取相關知識，以及 (2) 推理：根據回想的知識執行邏輯步驟。為了促進這種分解，我們引入了兩個特殊符號記憶和推理，引導模型區分需要知識擷取的步驟和涉及推理的步驟。我們的實驗結果表明，這種分解不僅改善了模型效能，還增強了推論過程的可解釋性，使用戶能夠識別錯誤來源並有效地改善模型回應。程式碼可在 https://github.com/MingyuJ666/Disentangling-Memory-and-Reasoning 取得。

##### **Utilizing Large Language Models to Synthesize Product Desirability Datasets**
2411.13485v1 by John D. Hastings, Sherri Weitl-Harms, Joseph Doty, Zachary L. Myers, Warren Thompson

This research explores the application of large language models (LLMs) to
generate synthetic datasets for Product Desirability Toolkit (PDT) testing, a
key component in evaluating user sentiment and product experience. Utilizing
gpt-4o-mini, a cost-effective alternative to larger commercial LLMs, three
methods, Word+Review, Review+Word, and Supply-Word, were each used to
synthesize 1000 product reviews. The generated datasets were assessed for
sentiment alignment, textual diversity, and data generation cost. Results
demonstrated high sentiment alignment across all methods, with Pearson
correlations ranging from 0.93 to 0.97. Supply-Word exhibited the highest
diversity and coverage of PDT terms, although with increased generation costs.
Despite minor biases toward positive sentiments, in situations with limited
test data, LLM-generated synthetic data offers significant advantages,
including scalability, cost savings, and flexibility in dataset production.

摘要：本研究探討將大型語言模型 (LLM) 應用於產生產品可欲性工具組 (PDT) 測試的合成資料集，這是評估使用者情緒和產品體驗的關鍵組成部分。利用 gpt-4o-mini，這是一種具備成本效益且可替代大型商業 LLM 的方法，三種方法（Word+Review、Review+Word 和 Supply-Word）各用於合成 1000 個產品評論。對產生的資料集進行情緒對齊、文字多樣性和資料產生成本的評估。結果顯示所有方法的情緒對齊度都很高，皮爾森相關係數介於 0.93 到 0.97 之間。Supply-Word 展現出最高的 PDT 術語多樣性和涵蓋範圍，儘管產生成本也隨之增加。儘管對正面情緒有輕微的偏見，但在測試資料有限的情況下，LLM 產生的合成資料提供了顯著的優勢，包括可擴充性、成本節省和資料集製作的靈活性。

##### **PatentEdits: Framing Patent Novelty as Textual Entailment**
2411.13477v1 by Ryan Lee, Alexander Spangher, Xuezhe Ma

A patent must be deemed novel and non-obvious in order to be granted by the
US Patent Office (USPTO). If it is not, a US patent examiner will cite the
prior work, or prior art, that invalidates the novelty and issue a non-final
rejection. Predicting what claims of the invention should change given the
prior art is an essential and crucial step in securing invention rights, yet
has not been studied before as a learnable task. In this work we introduce the
PatentEdits dataset, which contains 105K examples of successful revisions that
overcome objections to novelty. We design algorithms to label edits sentence by
sentence, then establish how well these edits can be predicted with large
language models (LLMs). We demonstrate that evaluating textual entailment
between cited references and draft sentences is especially effective in
predicting which inventive claims remained unchanged or are novel in relation
to prior art.

摘要：要獲得美國專利商標局 (USPTO) 授予專利，該專利必須被視為新穎且非顯而易見的。如果不是這樣，美國專利審查員將引用先前作品或先前技術，使新穎性失效並發出非最終駁回。預測在先技術下應更改哪些發明權利要求是確保發明權利的必要且關鍵步驟，但尚未作為可學習的任務進行研究。在這項工作中，我們引入了 PatentEdits 資料集，其中包含 105K 個成功修改範例，克服了對新穎性的反對意見。我們設計演算法來逐句標記編輯，然後確定使用大型語言模型 (LLM) 可以預測這些編輯的程度。我們證明評估引用的參考文獻和草稿句子之間的文本蘊涵對於預測哪些發明權利要求保持不變或相對於先前技術而言是新穎的特別有效。

##### **When Precision Meets Position: BFloat16 Breaks Down RoPE in Long-Context Training**
2411.13476v1 by Haonan Wang, Qian Liu, Chao Du, Tongyao Zhu, Cunxiao Du, Kenji Kawaguchi, Tianyu Pang

Extending context window sizes allows large language models (LLMs) to process
longer sequences and handle more complex tasks. Rotary Positional Embedding
(RoPE) has become the de facto standard due to its relative positional encoding
properties that benefit long-context training. However, we observe that using
RoPE with BFloat16 format results in numerical issues, causing it to deviate
from its intended relative positional encoding, especially in long-context
scenarios. This issue arises from BFloat16's limited precision and accumulates
as context length increases, with the first token contributing significantly to
this problem. To address this, we develop AnchorAttention, a plug-and-play
attention method that alleviates numerical issues caused by BFloat16, improves
long-context capabilities, and speeds up training. AnchorAttention reduces
unnecessary attention computations, maintains semantic coherence, and boosts
computational efficiency by treating the first token as a shared anchor with a
consistent position ID, making it visible to all documents within the training
context. Experiments on three types of LLMs demonstrate that AnchorAttention
significantly improves long-context performance and reduces training time by
over 50\% compared to standard full attention mechanisms, while preserving the
original LLM's capabilities on general tasks. Our code is available at
https://github.com/haonan3/AnchorContext.

摘要：擴展上下文視窗大小允許大型語言模型 (LLM) 處理更長的序列並處理更複雜的任務。旋轉位置嵌入 (RoPE) 已成為事實上的標準，因為它具有相對位置編碼特性，有利於長文脈訓練。然而，我們觀察到使用 BFloat16 格式的 RoPE 會導致數值問題，導致它偏離其預期的相對位置編碼，特別是在長文脈場景中。此問題源自 BFloat16 的有限精度，並隨著文脈長度的增加而累積，其中第一個標記對此問題有顯著的影響。為了解決這個問題，我們開發了 AnchorAttention，這是一種即插即用的注意力方法，可以減輕由 BFloat16 引起的數值問題，改善長文脈能力，並加快訓練速度。AnchorAttention 減少了不必要的注意力計算，維持語義一致性，並通過將第一個標記視為具有固定位置 ID 的共享錨點來提升運算效率，使其在訓練文脈中的所有文件都可見。在三種類型的 LLM 上進行的實驗表明，與標準全注意力機制相比，AnchorAttention 大幅提升了長文脈效能，並將訓練時間縮短了 50% 以上，同時保留了 LLM 在一般任務上的原始能力。我們的程式碼可在 https://github.com/haonan3/AnchorContext 取得。

##### **SoK: A Systems Perspective on Compound AI Threats and Countermeasures**
2411.13459v1 by Sarbartha Banerjee, Prateek Sahu, Mulong Luo, Anjo Vahldiek-Oberwagner, Neeraja J. Yadwadkar, Mohit Tiwari

Large language models (LLMs) used across enterprises often use proprietary
models and operate on sensitive inputs and data. The wide range of attack
vectors identified in prior research - targeting various software and hardware
components used in training and inference - makes it extremely challenging to
enforce confidentiality and integrity policies.
  As we advance towards constructing compound AI inference pipelines that
integrate multiple large language models (LLMs), the attack surfaces expand
significantly. Attackers now focus on the AI algorithms as well as the software
and hardware components associated with these systems. While current research
often examines these elements in isolation, we find that combining cross-layer
attack observations can enable powerful end-to-end attacks with minimal
assumptions about the threat model. Given, the sheer number of existing attacks
at each layer, we need a holistic and systemized understanding of different
attack vectors at each layer.
  This SoK discusses different software and hardware attacks applicable to
compound AI systems and demonstrates how combining multiple attack mechanisms
can reduce the threat model assumptions required for an isolated attack. Next,
we systematize the ML attacks in lines with the Mitre Att&ck framework to
better position each attack based on the threat model. Finally, we outline the
existing countermeasures for both software and hardware layers and discuss the
necessity of a comprehensive defense strategy to enable the secure and
high-performance deployment of compound AI systems.

摘要：大型語言模型 (LLM) 在企業中廣泛使用，通常使用專有模型並對敏感輸入和數據進行操作。先前研究中發現的各種攻擊媒介 - 針對訓練和推理中使用的各種軟體和硬體元件 - 使得執行機密性和完整性政策極具挑戰性。
當我們朝著構建整合多個大型語言模型 (LLM) 的複合式 AI 推理管線邁進時，攻擊面會顯著擴大。攻擊者現在專注於 AI 演算法以及與這些系統相關的軟體和硬體元件。雖然目前的研究所調查通常孤立地檢查這些元素，但我們發現結合跨層攻擊觀察可以實現強大的端對端攻擊，對威脅模型的假設最少。由於每一層現有攻擊的數量龐大，我們需要對每一層的不同攻擊媒介有全面且系統化的了解。
本 SoK 討論了適用於複合式 AI 系統的不同軟體和硬體攻擊，並展示了結合多種攻擊機制如何降低孤立攻擊所需的威脅模型假設。接下來，我們系統化 ML 攻擊，並與 Mitre Att&ck 架構保持一致，以便根據威脅模型更好地定位每個攻擊。最後，我們概述了軟體和硬體層的現有對策，並討論了全面防禦策略的必要性，以實現複合式 AI 系統的安全和高性能部署。

##### **LIMBA: An Open-Source Framework for the Preservation and Valorization of Low-Resource Languages using Generative Models**
2411.13453v1 by Salvatore Mario Carta, Stefano Chessa, Giulia Contu, Andrea Corriga, Andrea Deidda, Gianni Fenu, Luca Frigau, Alessandro Giuliani, Luca Grassi, Marco Manolo Manca, Mirko Marras, Francesco Mola, Bastianino Mossa, Piergiorgio Mura, Marco Ortu, Leonardo Piano, Simone Pisano, Alessia Pisu, Alessandro Sebastian Podda, Livio Pompianu, Simone Seu, Sandro Gabriele Tiddia

Minority languages are vital to preserving cultural heritage, yet they face
growing risks of extinction due to limited digital resources and the dominance
of artificial intelligence models trained on high-resource languages. This
white paper proposes a framework to generate linguistic tools for low-resource
languages, focusing on data creation to support the development of language
models that can aid in preservation efforts. Sardinian, an endangered language,
serves as the case study to demonstrate the framework's effectiveness. By
addressing the data scarcity that hinders intelligent applications for such
languages, we contribute to promoting linguistic diversity and support ongoing
efforts in language standardization and revitalization through modern
technologies.

摘要：少數語言對於保存文化遺產至關重要，但由於數位資源有限以及以高資源語言訓練的人工智慧模型的普及，這些語言面臨越來越高的滅絕風險。本白皮書提出了一個框架，用於產生低資源語言的語言工具，重點在於建立資料，以支援語言模型的開發，進而協助保存工作。薩丁尼亞語是一種瀕臨滅絕的語言，作為案例研究來證明此框架的有效性。透過解決阻礙此類語言的智慧型應用程式的資料短缺問題，我們可以協助推廣語言多樣性，並透過現代科技支援語言標準化和復興的持續努力。

##### **AdaptAgent: Adapting Multimodal Web Agents with Few-Shot Learning from Human Demonstrations**
2411.13451v1 by Gaurav Verma, Rachneet Kaur, Nishan Srishankar, Zhen Zeng, Tucker Balch, Manuela Veloso

State-of-the-art multimodal web agents, powered by Multimodal Large Language
Models (MLLMs), can autonomously execute many web tasks by processing user
instructions and interacting with graphical user interfaces (GUIs). Current
strategies for building web agents rely on (i) the generalizability of
underlying MLLMs and their steerability via prompting, and (ii) large-scale
fine-tuning of MLLMs on web-related tasks. However, web agents still struggle
to automate tasks on unseen websites and domains, limiting their applicability
to enterprise-specific and proprietary platforms. Beyond generalization from
large-scale pre-training and fine-tuning, we propose building agents for
few-shot adaptability using human demonstrations. We introduce the AdaptAgent
framework that enables both proprietary and open-weights multimodal web agents
to adapt to new websites and domains using few human demonstrations (up to 2).
Our experiments on two popular benchmarks -- Mind2Web & VisualWebArena -- show
that using in-context demonstrations (for proprietary models) or
meta-adaptation demonstrations (for meta-learned open-weights models) boosts
task success rate by 3.36% to 7.21% over non-adapted state-of-the-art models,
corresponding to a relative increase of 21.03% to 65.75%. Furthermore, our
additional analyses (a) show the effectiveness of multimodal demonstrations
over text-only ones, (b) shed light on the influence of different data
selection strategies during meta-learning on the generalization of the agent,
and (c) demonstrate the effect of number of few-shot examples on the web
agent's success rate. Overall, our results unlock a complementary axis for
developing widely applicable multimodal web agents beyond large-scale
pre-training and fine-tuning, emphasizing few-shot adaptability.

摘要：<paragraph>由多模态大型语言模型 (MLLM) 驱动的最先进多模态网络代理可以通过处理用户指令并与图形用户界面 (GUI) 交互来自主执行许多网络任务。当前构建网络代理的策略依赖于 (i) 基础 MLLM 的泛化性和通过提示进行的可操纵性，以及 (ii) 在与网络相关的任务上对 MLLM 进行大规模微调。然而，网络代理仍然难以在看不见的网站和域上自动执行任务，从而限制了它们对特定于企业和专有平台的适用性。除了从大规模预训练和微调中进行泛化之外，我们建议使用人类演示构建具有少量适应性的代理。我们引入了 AdaptAgent 框架，该框架使专有和开放权重的多模态网络代理能够使用少量人类演示（最多 2 个）适应新的网站和域。我们在两个流行基准 Mind2Web 和 VisualWebArena 上的实验表明，使用情境中演示（针对专有模型）或元适应演示（针对元学习开放权重模型）将任务成功率提高了 3.36% 至 7.21%，高于未适应的最先进模型，相当于相对增加了 21.03% 至 65.75%。此外，我们的附加分析 (a) 显示了多模态演示优于仅文本演示的有效性，(b) 阐明了元学习期间不同数据选择策略对代理泛化的影响，以及 (c) 证明了少量示例数量对网络代理成功率的影响。总体而言，我们的结果为开发广泛适用的多模态网络代理解锁了一个补充轴，超出了大规模预训练和微调，强调了少量适应性。</paragraph>

##### **Robust Monocular Visual Odometry using Curriculum Learning**
2411.13438v1 by Assaf Lahiany, Oren Gal

Curriculum Learning (CL), drawing inspiration from natural learning patterns
observed in humans and animals, employs a systematic approach of gradually
introducing increasingly complex training data during model development. Our
work applies innovative CL methodologies to address the challenging geometric
problem of monocular Visual Odometry (VO) estimation, which is essential for
robot navigation in constrained environments. The primary objective of our
research is to push the boundaries of current state-of-the-art (SOTA)
benchmarks in monocular VO by investigating various curriculum learning
strategies. We enhance the end-to-end Deep-Patch-Visual Odometry (DPVO)
framework through the integration of novel CL approaches, with the goal of
developing more resilient models capable of maintaining high performance across
challenging environments and complex motion scenarios. Our research encompasses
several distinctive CL strategies. We develop methods to evaluate sample
difficulty based on trajectory motion characteristics, implement sophisticated
adaptive scheduling through self-paced weighted loss mechanisms, and utilize
reinforcement learning agents for dynamic adjustment of training emphasis.
Through comprehensive evaluation on the real-world TartanAir dataset, our
Curriculum Learning-based Deep-Patch-Visual Odometry (CL-DPVO) demonstrates
superior performance compared to existing SOTA methods, including both
feature-based and learning-based VO approaches. The results validate the
effectiveness of integrating curriculum learning principles into visual
odometry systems.

摘要：課程學習 (CL) 從人類和動物中觀察到的自然學習模式中汲取靈感，採用一種系統化方法，在模型開發過程中逐漸引入越來越複雜的訓練資料。我們的作品應用創新的 CL 方法來解決單眼視覺里程計 (VO) 估計的具有挑戰性的幾何問題，這對於機器人在受限環境中的導航至關重要。我們研究的主要目的是通過研究各種課程學習策略，來突破單眼 VO 中當前最先進 (SOTA) 基準的界限。我們通過整合新的 CL 方法來增強端到端深度補丁視覺里程計 (DPVO) 框架，目標是開發更具彈性的模型，能夠在具有挑戰性的環境和複雜的運動場景中保持高性能。我們的研究包含幾個獨特的 CL 策略。我們開發了基於軌跡運動特徵評估樣本難度的的方法，通過自適應加權損失機制實現複雜的自適應調度，並利用強化學習代理動態調整訓練重點。通過對真實世界的 TartanAir 資料集進行綜合評估，我們的基於課程學習的深度補丁視覺里程計 (CL-DPVO) 與現有的 SOTA 方法（包括基於特徵和基於學習的 VO 方法）相比，展示了卓越的性能。結果驗證了將課程學習原理整合到視覺里程計系統中的有效性。

##### **SynEHRgy: Synthesizing Mixed-Type Structured Electronic Health Records using Decoder-Only Transformers**
2411.13428v1 by Hojjat Karami, David Atienza, Anisoara Ionescu

Generating synthetic Electronic Health Records (EHRs) offers significant
potential for data augmentation, privacy-preserving data sharing, and improving
machine learning model training. We propose a novel tokenization strategy
tailored for structured EHR data, which encompasses diverse data types such as
covariates, ICD codes, and irregularly sampled time series. Using a GPT-like
decoder-only transformer model, we demonstrate the generation of high-quality
synthetic EHRs. Our approach is evaluated using the MIMIC-III dataset, and we
benchmark the fidelity, utility, and privacy of the generated data against
state-of-the-art models.

摘要：生成合成電子病歷 (EHR) 提供了顯著的數據擴充、隱私保護數據共享以及改進機器學習模型訓練的潛力。我們提出了一種針對結構化電子病歷數據量身打造的新型標記化策略，它包含了各種數據類型，例如協變量、ICD 代碼和不規則採樣的時序。使用類似 GPT 的僅解碼器Transformer模型，我們展示了高品質合成電子病歷的生成。我們的做法使用 MIMIC-III 數據集進行評估，我們根據最先進的模型對生成數據的保真度、實用性和隱私性進行基準測試。

##### **WaterPark: A Robustness Assessment of Language Model Watermarking**
2411.13425v1 by Jiacheng Liang, Zian Wang, Lauren Hong, Shouling Ji, Ting Wang

To mitigate the misuse of large language models (LLMs), such as
disinformation, automated phishing, and academic cheating, there is a pressing
need for the capability of identifying LLM-generated texts. Watermarking
emerges as one promising solution: it plants statistical signals into LLMs'
generative processes and subsequently verifies whether LLMs produce given
texts. Various watermarking methods (``watermarkers'') have been proposed; yet,
due to the lack of unified evaluation platforms, many critical questions remain
under-explored: i) What are the strengths/limitations of various watermarkers,
especially their attack robustness? ii) How do various design choices impact
their robustness? iii) How to optimally operate watermarkers in adversarial
environments?
  To fill this gap, we systematize existing LLM watermarkers and watermark
removal attacks, mapping out their design spaces. We then develop WaterPark, a
unified platform that integrates 10 state-of-the-art watermarkers and 12
representative attacks. More importantly, leveraging WaterPark, we conduct a
comprehensive assessment of existing watermarkers, unveiling the impact of
various design choices on their attack robustness. For instance, a
watermarker's resilience to increasingly intensive attacks hinges on its
context dependency. We further explore the best practices to operate
watermarkers in adversarial environments. For instance, using a generic
detector alongside a watermark-specific detector improves the security of
vulnerable watermarkers. We believe our study sheds light on current LLM
watermarking techniques while WaterPark serves as a valuable testbed to
facilitate future research.

摘要：<paragraph>為了減輕大型語言模型（LLM）的濫用，例如錯誤資訊、自動網路釣魚和學術作弊，迫切需要識別 LLM 生成的文字的能力。浮水印作為一種有前景的解決方案浮出水面：它將統計訊號植入 LLM 的生成過程中，並隨後驗證 LLM 是否產生給定的文字。已經提出了各種浮水印方法（「浮水印」）；然而，由於缺乏統一的評估平台，許多關鍵問題仍未得到充分探討：i) 各種浮水印的優缺點是什麼，特別是它們的攻擊魯棒性？ii) 各種設計選擇如何影響它們的魯棒性？iii) 如何在對抗性環境中最佳操作浮水印？
為了填補這一空白，我們系統化現有的 LLM 浮水印和浮水印移除攻擊，並繪製出它們的設計空間。然後，我們開發了 WaterPark，一個統一的平台，它整合了 10 個最先進的浮水印和 12 個代表性攻擊。更重要的是，利用 WaterPark，我們對現有的浮水印進行了全面的評估，揭示了各種設計選擇對其攻擊魯棒性的影響。例如，浮水印對越來越密集的攻擊的彈性取決於它的上下文依賴性。我們進一步探討了在對抗性環境中操作浮水印的最佳實務。例如，在特定於浮水印的偵測器旁邊使用通用偵測器可以提高容易受攻擊的浮水印的安全性。我們相信我們的研究揭示了當前 LLM 浮水印技術，而 WaterPark 則作為一個有價值的測試平台，以促進未來的研究。</paragraph>

##### **CAFE A Novel Code switching Dataset for Algerian Dialect French and English**
2411.13424v1 by Houssam Eddine-Othman Lachemat, Akli Abbas, Nourredine Oukas, Yassine El Kheir, Samia Haboussi, Absar Showdhury Shammur

The paper introduces and publicly releases (Data download link available
after acceptance) CAFE -- the first Code-switching dataset between Algerian
dialect, French, and english languages. The CAFE speech data is unique for (a)
its spontaneous speaking style in vivo human-human conversation capturing
phenomena like code-switching and overlapping speech, (b) addresses distinct
linguistic challenges in North African Arabic dialect; (c) the CAFE captures
dialectal variations from various parts of Algeria within different
sociolinguistic contexts. CAFE data contains approximately 37 hours of speech,
with a subset, CAFE-small, of 2 hours and 36 minutes released with manual human
annotation including speech segmentation, transcription, explicit annotation of
code-switching points, overlapping speech, and other events such as noises, and
laughter among others. The rest approximately 34.58 hours contain pseudo label
transcriptions. In addition to the data release, the paper also highlighted the
challenges of using state-of-the-art Automatic Speech Recognition (ASR) models
such as Whisper large-v2,3 and PromptingWhisper to handle such content.
Following, we benchmark CAFE data with the aforementioned Whisper models and
show how well-designed data processing pipelines and advanced decoding
techniques can improve the ASR performance in terms of Mixed Error Rate (MER)
of 0.310, Character Error Rate (CER) of 0.329 and Word Error Rate (WER) of
0.538.

摘要：本文介紹並公開發布 (資料下載連結在接受後提供) CAFE -- 第一個阿爾及利亞方言、法語和英語語言之間的代碼轉換資料集。CAFE 語音資料的獨特之處在於：(a) 在人與人之間的對話中自發的說話風格，捕捉了代碼轉換和重疊語音等現象，(b) 解決北非阿拉伯方言中不同的語言挑戰；(c) CAFE 捕捉了阿爾及利亞不同地區在不同社會語言背景下的方言變異。CAFE 資料包含約 37 小時的語音，其中一小部分 CAFE-small，有 2 小時 36 分鐘，並附有人工標註，包括語音分段、轉錄、代碼轉換點的明確標註、重疊語音，以及其他事件，例如噪音和笑聲等。其餘約 34.58 小時包含偽標籤轉錄。除了資料發布之外，本文還強調了使用 Whisper large-v2,3 和 PromptingWhisper 等最先進的自動語音辨識 (ASR) 模型來處理此類內容的挑戰。接下來，我們使用上述 Whisper 模型對 CAFE 資料進行基準測試，並展示設計良好的資料處理管道和先進的解碼技術如何能改善 ASR 的效能，以混合錯誤率 (MER) 0.310、字元錯誤率 (CER) 0.329 和字詞錯誤率 (WER) 0.538 來衡量。

##### **Heuristically Adaptive Diffusion-Model Evolutionary Strategy**
2411.13420v1 by Benedikt Hartl, Yanbo Zhang, Hananel Hazan, Michael Levin

Diffusion Models represent a significant advancement in generative modeling,
employing a dual-phase process that first degrades domain-specific information
via Gaussian noise and restores it through a trainable model. This framework
enables pure noise-to-data generation and modular reconstruction of, images or
videos. Concurrently, evolutionary algorithms employ optimization methods
inspired by biological principles to refine sets of numerical parameters
encoding potential solutions to rugged objective functions. Our research
reveals a fundamental connection between diffusion models and evolutionary
algorithms through their shared underlying generative mechanisms: both methods
generate high-quality samples via iterative refinement on random initial
distributions. By employing deep learning-based diffusion models as generative
models across diverse evolutionary tasks and iteratively refining diffusion
models with heuristically acquired databases, we can iteratively sample
potentially better-adapted offspring parameters, integrating them into
successive generations of the diffusion model. This approach achieves efficient
convergence toward high-fitness parameters while maintaining explorative
diversity. Diffusion models introduce enhanced memory capabilities into
evolutionary algorithms, retaining historical information across generations
and leveraging subtle data correlations to generate refined samples. We elevate
evolutionary algorithms from procedures with shallow heuristics to frameworks
with deep memory. By deploying classifier-free guidance for conditional
sampling at the parameter level, we achieve precise control over evolutionary
search dynamics to further specific genotypical, phenotypical, or
population-wide traits. Our framework marks a major heuristic and algorithmic
transition, offering increased flexibility, precision, and control in
evolutionary optimization processes.

摘要：擴散模型代表生成模型的重大進步，採用雙階段處理，首先透過高斯噪聲降低特定領域的資訊，並透過可訓練模型還原該資訊。此架構支援純粹的雜訊轉資料生成和模組化重建，例如影像或影片。同時，演化演算法採用受生物原理啟發的最佳化方法，以優化編碼對崎嶇目標函數的潛在解的數值參數集合。我們的研究揭示了擴散模型與演化演算法之間透過其共用基礎生成機制而產生的根本關聯：兩種方法都透過對隨機初始分布進行反覆優化來產生高品質樣本。透過在各種演化任務中採用基於深度學習的擴散模型作為生成模型，並使用啟發式獲取的資料庫反覆優化擴散模型，我們可以反覆取樣潛在適應性更佳的後代參數，將它們整合到擴散模型的後續世代中。此方法可有效收斂到高適應度參數，同時維持探索性的多樣性。擴散模型為演化演算法引入增強的記憶能力，保留世代間的歷史資訊，並利用細微的資料關聯性來產生優化的樣本。我們將演化演算法從具有淺層啟發法的程序提升到具有深度記憶的架構。透過在參數層級部署無分類器引導進行條件取樣，我們可以精確控制演化搜尋動態，以進一步實現特定的基因型、表型或全族群特徵。我們的架構標誌著重大的啟發法和演算法轉變，在演化最佳化過程中提供更高的彈性、精確度和控制力。

##### **Unification of Balti and trans-border sister dialects in the essence of LLMs and AI Technology**
2411.13409v1 by Muhammad Sharif, Jiangyan Yi, Muhammad Shoaib

The language called Balti belongs to the Sino-Tibetan, specifically the
Tibeto-Burman language family. It is understood with variations, across
populations in India, China, Pakistan, Nepal, Tibet, Burma, and Bhutan,
influenced by local cultures and producing various dialects. Considering the
diverse cultural, socio-political, religious, and geographical impacts, it is
important to step forward unifying the dialects, the basis of common root,
lexica, and phonological perspectives, is vital. In the era of globalization
and the increasingly frequent developments in AI technology, understanding the
diversity and the efforts of dialect unification is important to understanding
commonalities and shortening the gaps impacted by unavoidable circumstances.
This article analyzes and examines how artificial intelligence AI in the
essence of Large Language Models LLMs, can assist in analyzing, documenting,
and standardizing the endangered Balti Language, based on the efforts made in
different dialects so far.

摘要：巴爾提語屬於漢藏語系，特別是藏緬語族。在印度、中國、巴基斯坦、尼泊爾、西藏、緬甸和不丹的人口中，巴爾提語有不同的變體，受到當地文化的影響，產生了不同的方言。考慮到多樣化的文化、社會政治、宗教和地理影響，重要的是要進一步統一方言，共同的詞根、詞彙和音系觀點的基礎至關重要。在全球化時代和人工智能技術日益頻繁的發展中，了解方言的多樣性和統一方言的努力對於理解共性並縮小不可避免的環境造成的差距非常重要。本文分析和探討了人工智能 AI，本質上是大語言模型 LLM，如何協助分析、記錄和標準化瀕危的巴爾提語，基於迄今為止在不同方言中做出的努力。

##### **Transformer-Based Contextualized Language Models Joint with Neural Networks for Natural Language Inference in Vietnamese**
2411.13407v1 by Dat Van-Thanh Nguyen, Tin Van Huynh, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen

Natural Language Inference (NLI) is a task within Natural Language Processing
(NLP) that holds value for various AI applications. However, there have been
limited studies on Natural Language Inference in Vietnamese that explore the
concept of joint models. Therefore, we conducted experiments using various
combinations of contextualized language models (CLM) and neural networks. We
use CLM to create contextualized work presentations and use Neural Networks for
classification. Furthermore, we have evaluated the strengths and weaknesses of
each joint model and identified the model failure points in the Vietnamese
context. The highest F1 score in this experiment, up to 82.78\% in the
benchmark dataset (ViNLI). By conducting experiments with various models, the
most considerable size of the CLM is XLM-R (355M). That combination has
consistently demonstrated superior performance compared to fine-tuning strong
pre-trained language models like PhoBERT (+6.58\%), mBERT (+19.08\%), and XLM-R
(+0.94\%) in terms of F1-score. This article aims to introduce a novel approach
or model that attains improved performance for Vietnamese NLI. Overall, we find
that the joint approach of CLM and neural networks is simple yet capable of
achieving high-quality performance, which makes it suitable for applications
that require efficient resource utilization.

摘要：自然語言推理 (NLI) 是自然語言處理 (NLP) 中的一項任務，對各種 AI 應用具有價值。然而，關於越南語自然語言推理的研究有限，探索了聯合模型的概念。因此，我們使用各種背景化語言模型 (CLM) 和神經網路的組合進行了實驗。我們使用 CLM 來建立背景化的工作簡報，並使用神經網路進行分類。此外，我們評估了每個聯合模型的優缺點，並找出越南語環境中的模型失敗點。在這個實驗中，基准資料集 (ViNLI) 中最高 F1 分數達 82.78%。通過對各種模型進行實驗，CLM 中最顯著的大小是 XLM-R (355M)。與微調強大的預訓練語言模型（例如 PhoBERT (+6.58%)、mBERT (+19.08%) 和 XLM-R (+0.94%) 相比，這種組合在 F1 分數方面始終表現出優異的效能。本文旨在介紹一種新穎的方法或模型，以提升越南語 NLI 的效能。總體而言，我們發現 CLM 和神經網路的聯合方法既簡單又能夠達到高品質的效能，這使其適用於需要有效利用資源的應用程式。

##### **On the Way to LLM Personalization: Learning to Remember User Conversations**
2411.13405v1 by Lucie Charlotte Magister, Katherine Metcalf, Yizhe Zhang, Maartje ter Hoeve

Large Language Models (LLMs) have quickly become an invaluable assistant for
a variety of tasks. However, their effectiveness is constrained by their
ability to tailor responses to human preferences and behaviors via
personalization. Prior work in LLM personalization has largely focused on style
transfer or incorporating small factoids about the user, as knowledge injection
remains an open challenge. In this paper, we explore injecting knowledge of
prior conversations into LLMs to enable future work on less redundant,
personalized conversations. We identify two real-world constraints: (1)
conversations are sequential in time and must be treated as such during
training, and (2) per-user personalization is only viable in
parameter-efficient settings. To this aim, we propose PLUM, a pipeline
performing data augmentation for up-sampling conversations as question-answer
pairs, that are then used to finetune a low-rank adaptation adapter with a
weighted cross entropy loss. Even in this first exploration of the problem, we
perform competitively with baselines such as RAG, attaining an accuracy of
81.5% across 100 conversations.

摘要：大型語言模型 (LLM) 已迅速成為各種任務中不可或缺的助手。然而，它們的有效性受到它們通過個人化調整回應以符合人類偏好和行為的能力的限制。LLM 個人化的先前工作主要集中在樣式轉移或納入有關使用者的少量事實，因為知識注入仍然是一個未解決的挑戰。在本文中，我們探討將先前對話的知識注入 LLM，以支持未來在冗餘較少、個性化的對話方面的工作。我們確定了兩個現實世界的限制：(1) 對話在時間上是連續的，並且在訓練期間必須這樣處理，以及 (2) 每用戶個人化僅在參數有效率的設定中可行。為此，我們提出了 PLUM，這是一個管道，執行資料擴充以對話作為問答對進行上採樣，然後用於微調低秩適應適配器，並使用加權交叉熵損失。即使在對問題的首次探討中，我們的表現也能與 RAG 等基準競爭，在 100 次對話中達到 81.5% 的準確度。

##### **Executable QR codes with Machine Learning for Industrial Applications**
2411.13400v1 by Stefano Scanzio, Francesco Velluto, Matteo Rosani, Lukasz Wisniewski, Gianluca Cena

Executable QR codes, also known as eQR codes or just sQRy, are a special kind
of QR codes that embed programs conceived to run on mobile devices like
smartphones. Since the program is directly encoded in binary form within the QR
code, it can be executed even when the reading device is not provided with
Internet access. The applications of this technology are manifold, and range
from smart user guides to advisory systems. The first programming language made
available for eQR is QRtree, which enables the implementation of decision trees
aimed, for example, at guiding the user in operating/maintaining a complex
machinery or for reaching a specific location.
  In this work, an additional language is proposed, we term QRind, which was
specifically devised for Industry. It permits to integrate distinct
computational blocks into the QR code, e.g., machine learning models to enable
predictive maintenance and algorithms to ease machinery usage. QRind permits
the Industry 4.0/5.0 paradigms to be implemented, in part, also in those cases
where Internet is unavailable.

摘要：可執行 QR 碼，又稱為 eQR 碼或 sQRy，是一種特殊類型的 QR 碼，其中嵌入程式，供行動裝置（如智慧型手機）執行。由於程式直接以二進位形式編碼在 QR 碼中，因此即使讀取裝置未連上網路，也可以執行程式。此技術的應用範圍廣泛，從智慧使用者指南到諮詢系統。第一個可供 eQR 使用的程式語言是 QRtree，它能實作決策樹，例如引導使用者操作/維護複雜的機械或到達特定地點。
在這項工作中，我們提出了一種額外的語言，我們稱之為 QRind，它專門為產業設計。它允許將不同的運算區塊整合到 QR 碼中，例如機器學習模型，以實現預測性維護，以及演算法，以簡化機械使用。QRind 允許實作工業 4.0/5.0 典範，部分情況下，即使在無法使用網路時也可以實作。

##### **Explainable Finite-Memory Policies for Partially Observable Markov Decision Processes**
2411.13365v1 by Muqsit Azeem, Debraj Chakraborty, Sudeep Kanav, Jan Kretinsky

Partially Observable Markov Decision Processes (POMDPs) are a fundamental
framework for decision-making under uncertainty and partial observability.
Since in general optimal policies may require infinite memory, they are hard to
implement and often render most problems undecidable. Consequently,
finite-memory policies are mostly considered instead. However, the algorithms
for computing them are typically very complex, and so are the resulting
policies. Facing the need for their explainability, we provide a representation
of such policies, both (i) in an interpretable formalism and (ii) typically of
smaller size, together yielding higher explainability. To that end, we combine
models of Mealy machines and decision trees; the latter describing simple,
stationary parts of the policies and the former describing how to switch among
them. We design a translation for policies of the finite-state-controller (FSC)
form from standard literature and show how our method smoothly generalizes to
other variants of finite-memory policies. Further, we identify specific
properties of recently used "attractor-based" policies, which allow us to
construct yet simpler and smaller representations. Finally, we illustrate the
higher explainability in a few case studies.

摘要：部分可觀察馬可夫決策過程 (POMDP) 是在不確定性和部分可觀察性下的決策制定基礎架構。由於一般最佳策略可能需要無限記憶，因此它們難以實作，而且通常會讓大多數問題無法判定。因此，大多數情況下會考慮有限記憶策略。然而，用於計算它們的演算法通常非常複雜，所產生的策略也是如此。面對需要解釋它們的情況，我們提供此類策略的表示，（i）以可解釋的形式和（ii）通常較小的規模，共同產生更高的可解釋性。為此，我們結合了 Mealy 機器和決策樹模型；後者描述策略的簡單、穩定的部分，前者描述如何在其中進行切換。我們設計了一種從標準文獻中轉換有限狀態控制器 (FSC) 形式策略的方法，並展示了我們的這種方法如何順利推廣到其他版本的有限記憶策略。此外，我們找出最近使用的「基於吸引子」策略的特定屬性，這些屬性讓我們能夠建構更簡單、更小的表示。最後，我們在幾個案例研究中說明了更高的可解釋性。

##### **Fact-Level Confidence Calibration and Self-Correction**
2411.13343v1 by Yige Yuan, Bingbing Xu, Hexiang Tan, Fei Sun, Teng Xiao, Wei Li, Huawei Shen, Xueqi Cheng

Confidence calibration in LLMs, i.e., aligning their self-assessed confidence
with the actual accuracy of their responses, enabling them to self-evaluate the
correctness of their outputs. However, current calibration methods for LLMs
typically estimate two scalars to represent overall response confidence and
correctness, which is inadequate for long-form generation where the response
includes multiple atomic facts and may be partially confident and correct.
These methods also overlook the relevance of each fact to the query. To address
these challenges, we propose a Fact-Level Calibration framework that operates
at a finer granularity, calibrating confidence to relevance-weighted
correctness at the fact level. Furthermore, comprehensive analysis under the
framework inspired the development of Confidence-Guided Fact-level
Self-Correction ($\textbf{ConFix}$), which uses high-confidence facts within a
response as additional knowledge to improve low-confidence ones. Extensive
experiments across four datasets and six models demonstrate that ConFix
effectively mitigates hallucinations without requiring external knowledge
sources such as retrieval systems.

摘要：大型语言模型的信心校准，即对其自评的信心与响应的实际准确性保持一致，使其能够自我评估输出的正确性。然而，当前针对大型语言模型的校准方法通常估计两个标量来表示整体响应信心和正确性，这对于长篇生成来说是不够的，因为响应包含多个原子事实，并且可能部分正确且有信心。这些方法还忽略了每个事实与查询的相关性。为了应对这些挑战，我们提出了一个事实级别校准框架，该框架以更精细的粒度运行，将信心校准为事实级别的相关性加权正确性。此外，在该框架下的全面分析启发了信心引导事实级别自我纠正（$\textbf{ConFix}$）的开发，它使用响应中高信心的事实作为附加知识来改进低信心的事实。跨四个数据集和六个模型的广泛实验表明，ConFix 有效地减轻了幻觉，而不需要检索系统等外部知识源。

##### **Verifying Machine Unlearning with Explainable AI**
2411.13332v1 by Àlex Pujol Vidal, Anders S. Johansen, Mohammad N. S. Jahromi, Sergio Escalera, Kamal Nasrollahi, Thomas B. Moeslund

We investigate the effectiveness of Explainable AI (XAI) in verifying Machine
Unlearning (MU) within the context of harbor front monitoring, focusing on data
privacy and regulatory compliance. With the increasing need to adhere to
privacy legislation such as the General Data Protection Regulation (GDPR),
traditional methods of retraining ML models for data deletions prove
impractical due to their complexity and resource demands. MU offers a solution
by enabling models to selectively forget specific learned patterns without full
retraining. We explore various removal techniques, including data relabeling,
and model perturbation. Then, we leverage attribution-based XAI to discuss the
effects of unlearning on model performance. Our proof-of-concept introduces
feature importance as an innovative verification step for MU, expanding beyond
traditional metrics and demonstrating techniques' ability to reduce reliance on
undesired patterns. Additionally, we propose two novel XAI-based metrics,
Heatmap Coverage (HC) and Attention Shift (AS), to evaluate the effectiveness
of these methods. This approach not only highlights how XAI can complement MU
by providing effective verification, but also sets the stage for future
research to enhance their joint integration.

摘要：我們探討可解釋人工智慧 (XAI) 在驗證機器遺忘 (MU) 中的有效性，在港口前監控的背景下，重點關注資料隱私和法規遵循。隨著越來越需要遵守隱私法規，例如一般資料保護規範 (GDPR)，傳統的機器學習模型重新訓練方法對於資料刪除來說證明不切實際，因為它們很複雜且需要大量資源。MU 提供了一個解決方案，讓模型能夠選擇性地遺忘特定的學習模式，而無需完全重新訓練。我們探索各種移除技術，包括資料重新標記和模型擾動。然後，我們利用基於歸因的 XAI 來討論遺忘對模型效能的影響。我們的概念驗證將特徵重要性作為 MU 的創新驗證步驟，擴展到傳統指標之外，並展示技術減少對不需要模式依賴的能力。此外，我們提出了兩個新穎的基於 XAI 的指標，熱圖覆蓋率 (HC) 和注意力轉移 (AS)，以評估這些方法的有效性。這種方法不僅強調 XAI 如何透過提供有效的驗證來補充 MU，而且還為未來的研究奠定了基礎，以增強它們的聯合整合。

##### **An Evolutional Neural Network Framework for Classification of Microarray Data**
2411.13326v1 by Maryam Eshraghi Evari, Md Nasir Sulaiman, Amir Rajabi Behjat

DNA microarray gene-expression data has been widely used to identify
cancerous gene signatures. Microarray can increase the accuracy of cancer
diagnosis and prognosis. However, analyzing the large amount of gene expression
data from microarray chips pose a challenge for current machine learning
researches. One of the challenges lie within classification of healthy and
cancerous tissues is high dimensionality of gene expressions. High
dimensionality decreases the accuracy of the classification. This research aims
to apply a hybrid model of Genetic Algorithm and Neural Network to overcome the
problem during subset selection of informative genes. Whereby, a Genetic
Algorithm (GA) reduced dimensionality during feature selection and then a
Multi-Layer perceptron Neural Network (MLP) is applied to classify selected
genes. The performance evaluated by considering to the accuracy and the number
of selected genes. Experimental results show the proposed method suggested high
accuracy and minimum number of selected genes in comparison with other machine
learning algorithms.

摘要：DNA 微陣列基因表現資料已被廣泛用於識別癌症基因特徵。微陣列可提升癌症診斷和預後的準確度。然而，分析微陣列晶片中大量的基因表現資料對目前的機器學習研究構成挑戰。其中一項挑戰在於健康和癌組織的分類是基因表現的高維度。高維度會降低分類的準確度。本研究旨在應用遺傳演算法和神經網路的混合模型，以克服在資訊基因子集選擇期間的問題。其中，遺傳演算法 (GA) 在特徵選擇期間降低維度，然後應用多層感知器神經網路 (MLP) 來分類所選基因。評估效能時會考慮準確度和所選基因的數量。實驗結果顯示，與其他機器學習演算法相比，所提出的方法建議了高準確度和最少數量的所選基因。

##### **Are Large Language Models Memorizing Bug Benchmarks?**
2411.13323v1 by Daniel Ramos, Claudia Mamede, Kush Jain, Paulo Canelas, Catarina Gamboa, Claire Le Goues

Large Language Models (LLMs) have become integral to various software
engineering tasks, including code generation, bug detection, and repair. To
evaluate model performance in these domains, numerous bug benchmarks containing
real-world bugs from software projects have been developed. However, a growing
concern within the software engineering community is that these benchmarks may
not reliably reflect true LLM performance due to the risk of data leakage.
Despite this concern, limited research has been conducted to quantify the
impact of potential leakage.
  In this paper, we systematically evaluate popular LLMs to assess their
susceptibility to data leakage from widely used bug benchmarks. To identify
potential leakage, we use multiple metrics, including a study of benchmark
membership within commonly used training datasets, as well as analyses of
negative log-likelihood and n-gram accuracy. Our findings show that certain
models, in particular codegen-multi, exhibit significant evidence of
memorization in widely used benchmarks like Defects4J, while newer models
trained on larger datasets like LLaMa 3.1 exhibit limited signs of leakage.
These results highlight the need for careful benchmark selection and the
adoption of robust metrics to adequately assess models capabilities.

摘要：大型語言模型 (LLM) 已成為各種軟體工程任務中不可或缺的一部分，包括程式碼產生、錯誤偵測和修復。為了評估這些領域中的模型效能，已開發出許多包含軟體專案中真實錯誤的錯誤基準測試。然而，軟體工程社群中日益關注的是，由於資料外洩的風險，這些基準測試可能無法可靠地反映真正的 LLM 效能。儘管有此疑慮，但針對量化潛在外洩影響的研究卻十分有限。
在本文中，我們系統性地評估熱門 LLM，以評估它們對廣泛使用的錯誤基準測試中資料外洩的敏感性。為了識別潛在的外洩，我們使用多種指標，包括研究基準測試成員資格在常用的訓練資料集中的情況，以及對負對數似然和 n-gram 精確度的分析。我們的研究結果顯示，某些模型，特別是 codegen-multi，在 Defects4J 等廣泛使用的基準測試中展現出顯著的記憶證據，而訓練於較大型資料集（例如 LLaMa 3.1）的較新模型則展現出有限的外洩跡象。這些結果突顯了仔細選擇基準測試和採用穩健指標以充分評估模型功能的必要性。

##### **Scaling Laws for Online Advertisement Retrieval**
2411.13322v1 by Yunli Wang, Zixuan Yang, Zhen Zhang, Zhiqiang Wang, Jian Yang, Shiyang Wen, Peng Jiang, Kun Gai

The scaling law is a notable property of neural network models and has
significantly propelled the development of large language models. Scaling laws
hold great promise in guiding model design and resource allocation. Recent
research increasingly shows that scaling laws are not limited to NLP tasks or
Transformer architectures; they also apply to domains such as recommendation.
However, there is still a lack of literature on scaling law research in online
advertisement retrieval systems. This may be because 1) identifying the scaling
law for resource cost and online revenue is often expensive in both time and
training resources for large-scale industrial applications, and 2) varying
settings for different systems prevent the scaling law from being applied
across various scenarios. To address these issues, we propose a lightweight
paradigm to identify the scaling law of online revenue and machine cost for a
certain online advertisement retrieval scenario with a low experimental cost.
Specifically, we focus on a sole factor (FLOPs) and propose an offline metric
named R/R* that exhibits a high linear correlation with online revenue for
retrieval models. We estimate the machine cost offline via a simulation
algorithm. Thus, we can transform most online experiments into low-cost offline
experiments. We conduct comprehensive experiments to verify the effectiveness
of our proposed metric R/R* and to identify the scaling law in the online
advertisement retrieval system of Kuaishou. With the scaling law, we
demonstrate practical applications for ROI-constrained model designing and
multi-scenario resource allocation in Kuaishou advertising system. To the best
of our knowledge, this is the first work to study the scaling laws for online
advertisement retrieval of real-world systems, showing great potential for
scaling law in advertising system optimization.

摘要：<paragraph>規模定律是神經網路模型的顯著特性，並已顯著推動大型語言模型的發展。規模定律在指導模型設計和資源分配方面具有很大的前景。最近的研究越來越表明，規模定律不僅限於 NLP 任務或 Transformer 架構；它們也適用於推薦等領域。然而，在線上廣告檢索系統中，關於規模定律研究的文獻仍然缺乏。這可能是因為 1) 針對大規模產業應用，找出資源成本和線上收益的規模定律通常在時間和訓練資源上很昂貴，以及 2) 不同系統的設定不同，會妨礙規模定律應用於各種場景。為了解決這些問題，我們提出了一個輕量的範例，以低實驗成本找出線上收益和機器成本的規模定律，適用於特定的線上廣告檢索場景。具體來說，我們專注於單一因素 (FLOP)，並提出一個名為 R/R* 的離線指標，它與檢索模型的線上收益呈現高度線性相關性。我們透過模擬演算法估計離線機器成本。因此，我們可以將大多數線上實驗轉換為低成本離線實驗。我們進行了全面的實驗，以驗證我們提出的指標 R/R* 的有效性，並找出快手線上廣告檢索系統中的規模定律。有了規模定律，我們展示了 ROI 受限模型設計和快手廣告系統中多場景資源分配的實際應用。據我們所知，這是第一個研究真實世界系統的線上廣告檢索規模定律的研究，顯示了規模定律在廣告系統最佳化方面的巨大潛力。</paragraph>

##### **Combining Autoregressive and Autoencoder Language Models for Text Classification**
2411.13282v1 by João Gonçalves

This paper presents CAALM-TC (Combining Autoregressive and Autoencoder
Language Models for Text Classification), a novel method that enhances text
classification by integrating autoregressive and autoencoder language models.
Autoregressive large language models such as Open AI's GPT, Meta's Llama or
Microsoft's Phi offer promising prospects for content analysis practitioners,
but they generally underperform supervised BERT based models for text
classification. CAALM leverages autoregressive models to generate contextual
information based on input texts, which is then combined with the original text
and fed into an autoencoder model for classification. This hybrid approach
capitalizes on the extensive contextual knowledge of autoregressive models and
the efficient classification capabilities of autoencoders. Experimental results
on four benchmark datasets demonstrate that CAALM consistently outperforms
existing methods, particularly in tasks with smaller datasets and more abstract
classification objectives. The findings indicate that CAALM offers a scalable
and effective solution for automated content analysis in social science
research that minimizes sample size requirements.

摘要：本文提出了 CAALM-TC（結合自迴歸和自動編碼器語言模型進行文本分類），這是一種通過整合自迴歸和自動編碼器語言模型來增強文本分類的新方法。Open AI 的 GPT、Meta 的 Llama 或 Microsoft 的 Phi 等自迴歸大型語言模型為內容分析從業者提供了有希望的前景，但它們在基於文本分類的監督式 BERT 模型中表現普遍不佳。CAALM 利用自迴歸模型根據輸入文本生成上下文信息，然後將其與原始文本結合並輸入自動編碼器模型進行分類。這種混合方法利用了自迴歸模型廣泛的上下文知識和自動編碼器的有效分類能力。在四個基準數據集上的實驗結果表明，CAALM 始終優於現有方法，特別是在數據集較小且分類目標更抽象的任務中。研究結果表明，CAALM 為社會科學研究中的自動化內容分析提供了一個可擴展且有效的解決方案，最大程度地減少了樣本量要求。

##### **VideoAutoArena: An Automated Arena for Evaluating Large Multimodal Models in Video Analysis through User Simulation**
2411.13281v1 by Ziyang Luo, Haoning Wu, Dongxu Li, Jing Ma, Mohan Kankanhalli, Junnan Li

Large multimodal models (LMMs) with advanced video analysis capabilities have
recently garnered significant attention. However, most evaluations rely on
traditional methods like multiple-choice questions in benchmarks such as
VideoMME and LongVideoBench, which are prone to lack the depth needed to
capture the complex demands of real-world users. To address this limitation-and
due to the prohibitive cost and slow pace of human annotation for video
tasks-we introduce VideoAutoArena, an arena-style benchmark inspired by LMSYS
Chatbot Arena's framework, designed to automatically assess LMMs' video
analysis abilities. VideoAutoArena utilizes user simulation to generate
open-ended, adaptive questions that rigorously assess model performance in
video understanding. The benchmark features an automated, scalable evaluation
framework, incorporating a modified ELO Rating System for fair and continuous
comparisons across multiple LMMs. To validate our automated judging system, we
construct a 'gold standard' using a carefully curated subset of human
annotations, demonstrating that our arena strongly aligns with human judgment
while maintaining scalability. Additionally, we introduce a fault-driven
evolution strategy, progressively increasing question complexity to push models
toward handling more challenging video analysis scenarios. Experimental results
demonstrate that VideoAutoArena effectively differentiates among
state-of-the-art LMMs, providing insights into model strengths and areas for
improvement. To further streamline our evaluation, we introduce VideoAutoBench
as an auxiliary benchmark, where human annotators label winners in a subset of
VideoAutoArena battles. We use GPT-4o as a judge to compare responses against
these human-validated answers. Together, VideoAutoArena and VideoAutoBench
offer a cost-effective, and scalable framework for evaluating LMMs in
user-centric video analysis.

摘要：<paragraph>具有先进视频分析功能的大型多模态模型 (LMM) 近期引起了极大的关注。然而，大多数评估都依赖于传统方法，例如 VideoMME 和 LongVideoBench 等基准测试中的多项选择题，这些方法容易缺乏满足现实世界用户复杂需求所需的深度。为了解决这一限制，并且由于视频任务的人工标注成本高昂且速度缓慢，我们引入了 VideoAutoArena，这是一个受 LMSYS Chatbot Arena 框架启发的竞技场式基准测试，旨在自动评估 LMM 的视频分析能力。VideoAutoArena 利用用户模拟来生成开放式自适应问题，严格评估模型在视频理解方面的性能。该基准测试采用自动化可扩展评估框架，结合了经过修改的 ELO 评级系统，以便对多个 LMM 进行公平且持续的比较。为了验证我们的自动化评判系统，我们使用精心挑选的人工标注子集构建了一个“黄金标准”，表明我们的竞技场与人工判断高度一致，同时保持可扩展性。此外，我们引入了一种故障驱动的进化策略，逐步增加问题复杂性，以推动模型处理更具挑战性的视频分析场景。实验结果表明，VideoAutoArena 有效地区分了最先进的 LMM，提供了对模型优势和改进领域的见解。为了进一步简化我们的评估，我们引入了 VideoAutoBench 作为辅助基准测试，其中人工标注员在 VideoAutoArena 战斗的子集中标记获胜者。我们使用 GPT-4o 作为评委，将响应与这些经过人工验证的答案进行比较。VideoAutoArena 和 VideoAutoBench 共同提供了一个经济高效且可扩展的框架，用于评估以用户为中心的视频分析中的 LMM。</paragraph>

##### **Unlocking the Power of Gradient Guidance for Structure-Based Molecule Optimization**
2411.13280v1 by Keyue Qiu, Yuxuan Song, Jie Yu, Hongbo Ma, Ziyao Cao, Zhilong Zhang, Yushuai Wu, Mingyue Zheng, Hao Zhou, Wei-Ying Ma

Structure-based molecule optimization (SBMO) aims to optimize molecules with
both continuous coordinates and discrete types against protein targets. A
promising direction is to exert gradient guidance on generative models given
its remarkable success in images, but it is challenging to guide discrete data
and risks inconsistencies between modalities. To this end, we leverage a
continuous and differentiable space derived through Bayesian inference,
presenting Molecule Joint Optimization (MolJO), the first gradient-based SBMO
framework that facilitates joint guidance signals across different modalities
while preserving SE(3)-equivariance. We introduce a novel backward correction
strategy that optimizes within a sliding window of the past histories, allowing
for a seamless trade-off between explore-and-exploit during optimization. Our
proposed MolJO achieves state-of-the-art performance on CrossDocked2020
benchmark (Success Rate 51.3% , Vina Dock -9.05 and SA 0.78), more than 4x
improvement in Success Rate compared to the gradient-based counterpart, and 2x
"Me-Better" Ratio as much as 3D baselines. Furthermore, we extend MolJO to a
wide range of optimization settings, including multi-objective optimization and
challenging tasks in drug design such as R-group optimization and scaffold
hopping, further underscoring its versatility and potential.

摘要：結構式分子最佳化（SBMO）旨在最佳化分子，其中包含針對蛋白質目標的連續座標和離散類型。一個有前途的方向是對生成模型施加梯度引導，因為它在影像方面獲得了顯著的成功，但指導離散資料具有挑戰性，並且存在模式之間不一致的風險。為此，我們利用透過貝氏推論衍生的連續且可微分的空間，提出分子聯合最佳化（MolJO），這是第一個基於梯度的 SBMO 架構，可在不同模式之間促進聯合引導訊號，同時保留 SE(3) 等變性。我們引入了一種新穎的後向修正策略，在過去歷史的滑動視窗中最佳化，允許在最佳化過程中探索和利用之間進行無縫的權衡。我們提出的 MolJO 在 CrossDocked2020 基準測試中取得了最先進的效能（成功率 51.3%、Vina Dock -9.05 和 SA 0.78），與基於梯度的對應項目相比，成功率提高了 4 倍以上，而「自我改善」比率則提高了 3D 基線的 2 倍。此外，我們將 MolJO 擴展到廣泛的最佳化設定，包括多目標最佳化和藥物設計中的挑戰性任務，例如 R 基團最佳化和支架跳躍，進一步強調了其多功能性和潛力。

##### **Towards Specification-Driven LLM-Based Generation of Embedded Automotive Software**
2411.13269v1 by Minal Suresh Patil, Gustav Ung, Mattias Nyberg

The paper studies how code generation by LLMs can be combined with formal
verification to produce critical embedded software. The first contribution is a
general framework, spec2code, in which LLMs are combined with different types
of critics that produce feedback for iterative backprompting and fine-tuning.
The second contribution presents a first feasibility study, where a
minimalistic instantiation of spec2code, without iterative backprompting and
fine-tuning, is empirically evaluated using three industrial case studies from
the heavy vehicle manufacturer Scania. The goal is to automatically generate
industrial-quality code from specifications only. Different combinations of
formal ACSL specifications and natural language specifications are explored.
The results indicate that formally correct code can be generated even without
the application of iterative backprompting and fine-tuning.

摘要：這篇論文探討如何將 LLM 的程式碼生成與形式化驗證結合，以產生關鍵的嵌入式軟體。第一個貢獻是一個通用架構 spec2code，其中 LLM 與不同類型的批評者結合，這些批評者會產生回饋，用於反覆提示和微調。第二個貢獻提出了一項初步可行性研究，其中對 spec2code 的極簡實例進行經驗評估，不使用反覆提示和微調，並使用重型車輛製造商 Scania 的三個產業案例研究。目標是僅從規格自動產生產業品質的程式碼。探索了形式 ACSL 規格和自然語言規格的不同組合。結果表明，即使不應用反覆提示和微調，也可以產生形式上正確的程式碼。

##### **FASTNav: Fine-tuned Adaptive Small-language-models Trained for Multi-point Robot Navigation**
2411.13262v1 by Yuxuan Chen, Yixin Han, Xiao Li

With the rapid development of large language models (LLM), robots are
starting to enjoy the benefits of new interaction methods that large language
models bring. Because edge computing fulfills the needs for rapid response,
privacy, and network autonomy, we believe it facilitates the extensive
deployment of large models for robot navigation across various industries. To
enable local deployment of language models on edge devices, we adopt some model
boosting methods. In this paper, we propose FASTNav - a method for boosting
lightweight LLMs, also known as small language models (SLMs), for robot
navigation. The proposed method contains three modules: fine-tuning,
teacher-student iteration, and language-based multi-point robot navigation. We
train and evaluate models with FASTNav in both simulation and real robots,
proving that we can deploy them with low cost, high accuracy and low response
time. Compared to other model compression methods, FASTNav shows potential in
the local deployment of language models and tends to be a promising solution
for language-guided robot navigation on edge devices.

摘要：隨著大型語言模型（LLM）的快速發展，機器人開始享受大型語言模型帶來的新互動方式的優勢。由於邊緣運算滿足了快速響應、隱私和網路自主性的需求，我們相信它有助於在各個產業中廣泛部署大型模型以進行機器人導航。為了在邊緣裝置上實現語言模型的本地部署，我們採用了一些模型提升方法。在本文中，我們提出 FASTNav - 一種提升輕量級 LLM（也稱為小型語言模型，SLM）的方法，用於機器人導航。所提出的方法包含三個模組：微調、教師-學生反覆運算，以及基於語言的多點機器人導航。我們在模擬和真實機器人中使用 FASTNav 訓練和評估模型，證明我們可以低成本、高準確度和低回應時間部署它們。與其他模型壓縮方法相比，FASTNav 在語言模型的本地部署中顯示出潛力，並且趨勢成為邊緣裝置上語言導引機器人導航的有前途的解決方案。

##### **BelHouse3D: A Benchmark Dataset for Assessing Occlusion Robustness in 3D Point Cloud Semantic Segmentation**
2411.13251v1 by Umamaheswaran Raman Kumar, Abdur Razzaq Fayjie, Jurgen Hannaert, Patrick Vandewalle

Large-scale 2D datasets have been instrumental in advancing machine learning;
however, progress in 3D vision tasks has been relatively slow. This disparity
is largely due to the limited availability of 3D benchmarking datasets. In
particular, creating real-world point cloud datasets for indoor scene semantic
segmentation presents considerable challenges, including data collection within
confined spaces and the costly, often inaccurate process of per-point labeling
to generate ground truths. While synthetic datasets address some of these
challenges, they often fail to replicate real-world conditions, particularly
the occlusions that occur in point clouds collected from real environments.
Existing 3D benchmarking datasets typically evaluate deep learning models under
the assumption that training and test data are independently and identically
distributed (IID), which affects the models' usability for real-world point
cloud segmentation. To address these challenges, we introduce the BelHouse3D
dataset, a new synthetic point cloud dataset designed for 3D indoor scene
semantic segmentation. This dataset is constructed using real-world references
from 32 houses in Belgium, ensuring that the synthetic data closely aligns with
real-world conditions. Additionally, we include a test set with data occlusion
to simulate out-of-distribution (OOD) scenarios, reflecting the occlusions
commonly encountered in real-world point clouds. We evaluate popular
point-based semantic segmentation methods using our OOD setting and present a
benchmark. We believe that BelHouse3D and its OOD setting will advance research
in 3D point cloud semantic segmentation for indoor scenes, providing valuable
insights for the development of more generalizable models.

摘要：<paragraph>大型 2D 資料集對於推進機器學習發揮了重要作用；
然而，3D 視覺任務的進展相對緩慢。這種差異
主要是由於 3D 基準資料集的可取得性有限。特別是，
建立室內場景語義分割的真實世界點雲資料集會出現相當大的挑戰，包括在密閉空間內收集資料，以及代價高昂、通常不準確的逐點標籤處理程序，以產生基本事實。儘管合成資料集解決了其中一些
挑戰，但它們通常無法複製真實世界的條件，特別是從真實環境收集的點雲中發生的遮擋。
現有的 3D 基準資料集通常在訓練資料和測試資料獨立且同質分佈 (IID) 的假設下評估深度學習模型，這會影響模型在真實世界點雲分割中的可用性。為了應對這些挑戰，我們引入了 BelHouse3D 資料集，這是一個新的合成點雲資料集，專為 3D 室內場景語義分割而設計。這個資料集是使用比利時 32 間房屋的真實世界參考建立的，確保合成資料與真實世界條件緊密對齊。此外，我們還包括一個測試集，其中包含資料遮擋，以模擬分佈外 (OOD) 場景，反映真實世界點雲中常見的遮擋。我們使用我們的 OOD 設定評估了流行的基於點的語義分割方法，並提出了基準。我們相信 BelHouse3D 及其 OOD 設定將推進室內場景的 3D 點雲語義分割研究，為開發更具概括性的模型提供有價值的見解。</paragraph>

##### **Leveraging Prior Experience: An Expandable Auxiliary Knowledge Base for Text-to-SQL**
2411.13244v1 by Zhibo Chu, Zichong Wang, Qitao Qin

Large Language Models (LLMs) exhibit impressive problem-solving skills across
many tasks, but they still underperform compared to humans in various
downstream applications, such as text-to-SQL. On the BIRD benchmark
leaderboard, human performance achieves an accuracy of 92.96\%, whereas the
top-performing method reaches only 72.39\%. Notably, these state-of-the-art
(SoTA) methods predominantly rely on in-context learning to simulate human-like
reasoning. However, they overlook a critical human skill: continual learning.
Inspired by the educational practice of maintaining mistake notebooks during
our formative years, we propose LPE-SQL (Leveraging Prior Experience: An
Expandable Auxiliary Knowledge Base for Text-to-SQL), a novel framework
designed to augment LLMs by enabling continual learning without requiring
parameter fine-tuning. LPE-SQL consists of four modules that \textbf{i)}
retrieve relevant entries, \textbf{ii)} efficient sql generation, \textbf{iii)}
generate the final result through a cross-consistency mechanism and
\textbf{iv)} log successful and failed tasks along with their reasoning
processes or reflection-generated tips. Importantly, the core module of LPE-SQL
is the fourth one, while the other modules employ foundational methods,
allowing LPE-SQL to be easily integrated with SoTA technologies to further
enhance performance. Our experimental results demonstrate that this continual
learning approach yields substantial performance gains, with the smaller
Llama-3.1-70B model with surpassing the performance of the larger
Llama-3.1-405B model using SoTA methods.

摘要：大型語言模型 (LLM) 在許多任務中展現出令人印象深刻的解決問題技能，但與人類相比，它們在各種下游應用（例如文字轉 SQL）中的表現仍然較差。在 BIRD 基準排行榜上，人類的表現達到 92.96% 的準確度，而表現最佳的方法僅達到 72.39%。值得注意的是，這些最先進 (SoTA) 方法主要依賴於情境學習來模擬類人推理。然而，他們忽視了一項關鍵的人類技能：持續學習。受我們在成長過程中保持錯誤筆記本的教育實務啟發，我們提出了 LPE-SQL（利用先驗經驗：文字轉 SQL 可擴充輔助知識庫），這是一個新穎的架構，旨在通過啟用持續學習來擴充 LLM，而無需進行參數微調。LPE-SQL 包含四個模組，它們\textbf{i)} 檢索相關條目，\textbf{ii)} 有效的 SQL 生成，\textbf{iii)} 通過交叉一致性機制生成最終結果，以及\textbf{iv)} 記錄成功的和失敗的任務以及它們的推理過程或反思產生的提示。重要的是，LPE-SQL 的核心模組是第四個模組，而其他模組採用基礎方法，允許 LPE-SQL 輕鬆與 SoTA 技術整合以進一步提高效能。我們的實驗結果表明，這種持續學習方法產生了顯著的效能提升，使用 SoTA 方法的較小 Llama-3.1-70B 模型超越了較大 Llama-3.1-405B 模型的效能。

##### **XMask3D: Cross-modal Mask Reasoning for Open Vocabulary 3D Semantic Segmentation**
2411.13243v1 by Ziyi Wang, Yanbo Wang, Xumin Yu, Jie Zhou, Jiwen Lu

Existing methodologies in open vocabulary 3D semantic segmentation primarily
concentrate on establishing a unified feature space encompassing 3D, 2D, and
textual modalities. Nevertheless, traditional techniques such as global feature
alignment or vision-language model distillation tend to impose only approximate
correspondence, struggling notably with delineating fine-grained segmentation
boundaries. To address this gap, we propose a more meticulous mask-level
alignment between 3D features and the 2D-text embedding space through a
cross-modal mask reasoning framework, XMask3D. In our approach, we developed a
mask generator based on the denoising UNet from a pre-trained diffusion model,
leveraging its capability for precise textual control over dense pixel
representations and enhancing the open-world adaptability of the generated
masks. We further integrate 3D global features as implicit conditions into the
pre-trained 2D denoising UNet, enabling the generation of segmentation masks
with additional 3D geometry awareness. Subsequently, the generated 2D masks are
employed to align mask-level 3D representations with the vision-language
feature space, thereby augmenting the open vocabulary capability of 3D geometry
embeddings. Finally, we fuse complementary 2D and 3D mask features, resulting
in competitive performance across multiple benchmarks for 3D open vocabulary
semantic segmentation. Code is available at
https://github.com/wangzy22/XMask3D.

摘要：現有的開放式詞彙 3D 語意分割方法論主要集中於建立一個統一的特徵空間，涵蓋 3D、2D 和文本模式。儘管如此，傳統技術（例如全局特徵對齊或視覺語言模型蒸餾）傾向於僅施加近似對應，在描繪細粒度分割邊界時顯著受挫。為了解決這個差距，我們提出一個更細緻的 3D 特徵與 2D-text 嵌入空間之間的遮罩級別對齊，透過跨模態遮罩推理框架 XMask3D。在我們的做法中，我們開發了一個基於預訓練擴散模型的去噪 UNet 的遮罩生成器，利用其對密集像素表示的精確文本控制能力，並增強生成遮罩的開放世界適應性。我們進一步將 3D 全局特徵整合為預訓練 2D 去噪 UNet 中的隱式條件，使能夠生成具有額外 3D 幾何感知的分割遮罩。隨後，生成的 2D 遮罩用於將遮罩級別 3D 表示與視覺語言特徵空間對齊，從而擴增 3D 幾何嵌入的開放式詞彙能力。最後，我們融合互補的 2D 和 3D 遮罩特徵，在 3D 開放式詞彙語意分割的多次基準測試中產生競爭力的效能。程式碼可在 https://github.com/wangzy22/XMask3D 取得。

##### **Transforming the Hybrid Cloud for Emerging AI Workloads**
2411.13239v1 by Deming Chen, Alaa Youssef, Ruchi Pendse, André Schleife, Bryan K. Clark, Hendrik Hamann, Jingrui He, Teodoro Laino, Lav Varshney, Yuxiong Wang, Avirup Sil, Reyhaneh Jabbarvand, Tianyin Xu, Volodymyr Kindratenko, Carlos Costa, Sarita Adve, Charith Mendis, Minjia Zhang, Santiago Núñez-Corrales, Raghu Ganti, Mudhakar Srivatsa, Nam Sung Kim, Josep Torrellas, Jian Huang, Seetharami Seelam, Klara Nahrstedt, Tarek Abdelzaher, Tamar Eilam, Huimin Zhao, Matteo Manica, Ravishankar Iyer, Martin Hirzel, Vikram Adve, Darko Marinov, Hubertus Franke, Hanghang Tong, Elizabeth Ainsworth, Han Zhao, Deepak Vasisht, Minh Do, Fabio Oliveira, Giovanni Pacifici, Ruchir Puri, Priya Nagpurkar

This white paper, developed through close collaboration between IBM Research
and UIUC researchers within the IIDAI Institute, envisions transforming hybrid
cloud systems to meet the growing complexity of AI workloads through
innovative, full-stack co-design approaches, emphasizing usability,
manageability, affordability, adaptability, efficiency, and scalability. By
integrating cutting-edge technologies such as generative and agentic AI,
cross-layer automation and optimization, unified control plane, and composable
and adaptive system architecture, the proposed framework addresses critical
challenges in energy efficiency, performance, and cost-effectiveness.
Incorporating quantum computing as it matures will enable quantum-accelerated
simulations for materials science, climate modeling, and other high-impact
domains. Collaborative efforts between academia and industry are central to
this vision, driving advancements in foundation models for material design and
climate solutions, scalable multimodal data processing, and enhanced
physics-based AI emulators for applications like weather forecasting and carbon
sequestration. Research priorities include advancing AI agentic systems, LLM as
an Abstraction (LLMaaA), AI model optimization and unified abstractions across
heterogeneous infrastructure, end-to-end edge-cloud transformation, efficient
programming model, middleware and platform, secure infrastructure,
application-adaptive cloud systems, and new quantum-classical collaborative
workflows. These ideas and solutions encompass both theoretical and practical
research questions, requiring coordinated input and support from the research
community. This joint initiative aims to establish hybrid clouds as secure,
efficient, and sustainable platforms, fostering breakthroughs in AI-driven
applications and scientific discovery across academia, industry, and society.

摘要：這份白皮書由 IBM 研究中心與 IIDAI 研究所內的 UIUC 研究人員密切合作開發，預想透過創新的全端共同設計方法，轉換混合雲端系統，以滿足 AI 工作負載日益增長的複雜性，並強調可用性、可管理性、負擔能力、適應性、效率和可擴充性。透過整合生成式和代理式 AI、跨層自動化和最佳化、統一控制平面，以及可組成和自適應系統架構等尖端技術，所提出的架構解決了能源效率、效能和成本效益等重大挑戰。隨著量子運算技術日漸成熟，將能進行材料科學、氣候建模和其它高影響領域的量子加速模擬。產學合作對於此願景至關重要，推動材料設計和氣候解決方案、可擴充多模態資料處理，以及用於天氣預測和碳封存等應用程式的增強型物理基礎 AI 模擬器的進展。研究重點包括推進 AI 代理系統、LLM 作為抽象化 (LLMaaA)、異質基礎設施中的 AI 模型最佳化和統一抽象化、端到端邊緣雲端轉型、高效能程式設計模型、中介軟體和平台、安全基礎設施、應用程式自適應雲端系統，以及新的量子經典協作工作流程。這些想法和解決方案涵蓋了理論和實務研究問題，需要研究社群協調投入和支援。此聯合計畫旨在將混合雲端建立為安全、高效和永續的平台，促進學術界、產業和社會中 AI 驅動應用程式和科學發現的突破。

##### **BIPro: Zero-shot Chinese Poem Generation via Block Inverse Prompting Constrained Generation Framework**
2411.13237v1 by Xu Zou

Recently, generative pre-trained models have made significant strides,
particularly highlighted by the release of ChatGPT and GPT-4, which exhibit
superior cross-domain capabilities. However, these models still face challenges
on constrained writing tasks like poem generation under open-domain titles. In
response to this challenge, we introduce Block Inverse Prompting (BIPro)
constrained generation framework. BIPro leverages two block inverse prompting
methods, revise and rewrite, that mimic the process of human text writing using
block generative models. It significantly improves the zero-shot generation
quality on the formidable constrained generation task of open-domain
traditional-form Chinese poem generation. Based on a less powerful block
generative model GLM-10B-Chinese, poems composed via BIPro without priming or
additional training outperform both most advanced direct generative systems
like GPT-4 or GLM-4 and best domain-specific systems such as Yusheng,
Shisanbai, or Baidu Poetry Helper in human evaluation by proficient poets.
Finally, BIPro considerably narrows the gap between AI-generated works and
short-listed human literary arts in another human evaluation, unveiling the
promising potential of block generative models in improving the quality of
constrained generation.

摘要：近来，生成式预训练模型取得了重大进展，特别是 ChatGPT 和 GPT-4 的发布，表现出优异的跨领域能力。然而，这些模型在开放领域标题下的受限写作任务（如诗歌生成）中仍然面临挑战。为了应对这一挑战，我们引入了块逆提示（BIPro）受限生成框架。BIPro 借助两种块逆提示方法（修改和重写）来模拟使用块生成模型进行人类文本写作的过程。它显著提高了开放领域传统形式中文诗歌生成这一艰巨的受限生成任务的零样本生成质量。基于功能较弱的块生成模型 GLM-10B-Chinese，通过 BIPro 创作的诗歌在没有预处理或额外训练的情况下，在熟练诗人的人类评估中优于最先进的直接生成系统（如 GPT-4 或 GLM-4）和最佳领域特定系统（如御胜、十三白或百度诗词助手）。最后，BIPro 在另一项人类评估中显著缩小了 AI 生成的作品与入围人类文学艺术之间的差距，揭示了块生成模型在提高受限生成质量方面的巨大潜力。

##### **AIDBench: A benchmark for evaluating the authorship identification capability of large language models**
2411.13226v1 by Zichen Wen, Dadi Guo, Huishuai Zhang

As large language models (LLMs) rapidly advance and integrate into daily
life, the privacy risks they pose are attracting increasing attention. We focus
on a specific privacy risk where LLMs may help identify the authorship of
anonymous texts, which challenges the effectiveness of anonymity in real-world
systems such as anonymous peer review systems. To investigate these risks, we
present AIDBench, a new benchmark that incorporates several author
identification datasets, including emails, blogs, reviews, articles, and
research papers. AIDBench utilizes two evaluation methods: one-to-one
authorship identification, which determines whether two texts are from the same
author; and one-to-many authorship identification, which, given a query text
and a list of candidate texts, identifies the candidate most likely written by
the same author as the query text. We also introduce a Retrieval-Augmented
Generation (RAG)-based method to enhance the large-scale authorship
identification capabilities of LLMs, particularly when input lengths exceed the
models' context windows, thereby establishing a new baseline for authorship
identification using LLMs. Our experiments with AIDBench demonstrate that LLMs
can correctly guess authorship at rates well above random chance, revealing new
privacy risks posed by these powerful models. The source code and data will be
made publicly available after acceptance.

摘要：隨著大型語言模型 (LLM) 快速進步並整合到日常生活中，它們帶來的隱私風險也引起越來越多的關注。我們專注於一個特定的隱私風險，其中 LLM 可能有助於識別匿名文本的作者，這挑戰了匿名性在現實世界系統中的有效性，例如匿名同行評審系統。為了調查這些風險，我們提出了 AIDBench，這是一個新的基準，它包含了幾個作者識別數據集，包括電子郵件、部落格、評論、文章和研究論文。AIDBench 利用兩種評估方法：一對一的作者識別，它確定兩個文本是否來自同一個作者；以及一對多的作者識別，它在給定一個查詢文本和一個候選文本列表的情況下，識別出最可能由與查詢文本同一個作者編寫的候選文本。我們還引入了一個基於檢索增強生成 (RAG) 的方法來增強 LLM 的大規模作者識別能力，特別是在輸入長度超過模型上下文視窗時，從而為使用 LLM 進行作者識別建立了一個新的基準。我們使用 AIDBench 進行的實驗表明，LLM 可以以遠高於隨機機會的比率正確猜測作者，揭示了這些強大模型帶來的新的隱私風險。原始程式碼和資料將在接受後公開。

##### **Quantum Kernel-Based Long Short-term Memory**
2411.13225v1 by Yu-Chao Hsu, Tai-Yu Li, Kuan-Cheng Chen

The integration of quantum computing into classical machine learning
architectures has emerged as a promising approach to enhance model efficiency
and computational capacity. In this work, we introduce the Quantum Kernel-Based
Long Short-Term Memory (QK-LSTM) network, which utilizes quantum kernel
functions within the classical LSTM framework to capture complex, non-linear
patterns in sequential data. By embedding input data into a high-dimensional
quantum feature space, the QK-LSTM model reduces the reliance on large
parameter sets, achieving effective compression while maintaining accuracy in
sequence modeling tasks. This quantum-enhanced architecture demonstrates
efficient convergence, robust loss minimization, and model compactness, making
it suitable for deployment in edge computing environments and resource-limited
quantum devices (especially in the NISQ era). Benchmark comparisons reveal that
QK-LSTM achieves performance on par with classical LSTM models, yet with fewer
parameters, underscoring its potential to advance quantum machine learning
applications in natural language processing and other domains requiring
efficient temporal data processing.

摘要：量子運算整合到傳統機器學習架構中，已成為一種提升模型效率和運算能力的潛力方法。在這項工作中，我們引入了量子核基於長短期記憶 (QK-LSTM) 網路，它在傳統 LSTM 架構中利用量子核函數，以擷取序列資料中的複雜非線性模式。透過將輸入資料嵌入到高維量子特徵空間中，QK-LSTM 模型減少對大型參數集的依賴，在序列建模任務中實現有效壓縮，同時維持準確度。這種量子增強架構展現出有效收斂、穩健損失最小化和模型緊湊性，使其適用於邊緣運算環境和資源受限的量子裝置（特別是在 NISQ 時代）中部署。基準比較顯示，QK-LSTM 達到與傳統 LSTM 模型同等的效能，但參數較少，突顯其在自然語言處理和其他需要有效時間資料處理領域中推進量子機器學習應用的潛力。

##### **Existential Conversations with Large Language Models: Content, Community, and Culture**
2411.13223v1 by Murray Shanahan, Beth Singler

Contemporary conversational AI systems based on large language models (LLMs)
can engage users on a wide variety of topics, including philosophy,
spirituality, and religion. Suitably prompted, LLMs can be coaxed into
discussing such existentially significant matters as their own putative
consciousness and the role of artificial intelligence in the fate of the
Cosmos. Here we examine two lengthy conversations of this type. We trace likely
sources, both ancient and modern, for the extensive repertoire of images,
myths, metaphors, and conceptual esoterica that the language model draws on
during these conversations, and foreground the contemporary communities and
cultural movements that deploy related motifs, especially in their online
activity. Finally, we consider the larger societal impacts of such engagements
with LLMs.

摘要：當代會話式 AI 系統建構於大型語言模型 (LLM)，
能與使用者在各種主題上互動，包括哲學、
靈性與宗教。在適當的提示下，LLM 可被誘導
討論存在意義重大的議題，像是它們假定的
意識與人工智慧在宇宙命運中的角色。在此我們檢視兩場此類的冗長對話。我們追溯語言模型在這些對話中所引用的豐富意象、
神話、隱喻與概念性深奧知識的可能來源，無論是古代或現代，並凸顯當代社群與文化運動，特別是在他們的線上活動中，部署相關母題。最後，我們考量與 LLM 互動的更廣泛社會影響。

##### **Comparative Analysis of Audio Feature Extraction for Real-Time Talking Portrait Synthesis**
2411.13209v1 by Pegah Salehi, Sajad Amouei Sheshkal, Vajira Thambawita, Sushant Gautam, Saeed S. Sabet, Dag Johansen, Michael A. Riegler, Pål Halvorsen

This paper examines the integration of real-time talking-head generation for
interviewer training, focusing on overcoming challenges in Audio Feature
Extraction (AFE), which often introduces latency and limits responsiveness in
real-time applications. To address these issues, we propose and implement a
fully integrated system that replaces conventional AFE models with Open AI's
Whisper, leveraging its encoder to optimize processing and improve overall
system efficiency. Our evaluation of two open-source real-time models across
three different datasets shows that Whisper not only accelerates processing but
also improves specific aspects of rendering quality, resulting in more
realistic and responsive talking-head interactions. These advancements make the
system a more effective tool for immersive, interactive training applications,
expanding the potential of AI-driven avatars in interviewer training.

摘要：本文探討了整合即時對話頭部生成技術於面試人員訓練中的應用，重點在於克服音訊特徵萃取 (AFE) 中的挑戰，而這些挑戰通常會導致延遲並限制即時應用程式的回應能力。為了解決這些問題，我們提出並實作了一個完全整合的系統，以 Open AI 的 Whisper 取代傳統的 AFE 模型，並利用其編碼器來最佳化處理程序並提升整體系統效率。我們對三個不同資料集中的兩個開源即時模型進行評估，結果顯示 Whisper 不僅加速處理速度，也改善了渲染品質的特定面向，進而產生更逼真且回應更快速的對話頭部互動。這些進展讓此系統成為更有效的工具，可運用於沈浸式互動訓練應用程式中，並擴展了 AI 驅動頭像在面試人員訓練中的潛力。

##### **The Information Security Awareness of Large Language Models**
2411.13207v1 by Ofir Cohen, Gil Ari Agmon, Asaf Shabtai, Rami Puzis

The popularity of large language models (LLMs) continues to increase, and
LLM-based assistants have become ubiquitous, assisting people of diverse
backgrounds in many aspects of life. Significant resources have been invested
in the safety of LLMs and their alignment with social norms. However, research
examining their behavior from the information security awareness (ISA)
perspective is lacking. Chatbots and LLM-based assistants may put unwitting
users in harm's way by facilitating unsafe behavior. We observe that the ISA
inherent in some of today's most popular LLMs varies significantly, with most
models requiring user prompts with a clear security context to utilize their
security knowledge and provide safe responses to users. Based on this
observation, we created a comprehensive set of 30 scenarios to assess the ISA
of LLMs. These scenarios benchmark the evaluated models with respect to all
focus areas defined in a mobile ISA taxonomy. Among our findings is that ISA is
mildly affected by changing the model's temperature, whereas adjusting the
system prompt can substantially impact it. This underscores the necessity of
setting the right system prompt to mitigate ISA weaknesses. Our findings also
highlight the importance of ISA assessment for the development of future
LLM-based assistants.

摘要：大型語言模型（LLM）的普及持續增加，而基於 LLM 的助理已無處不在，協助來自不同背景的人們處理生活的許多面向。已投入大量資源於 LLM 的安全性及其與社會規範的一致性。然而，從資訊安全意識（ISA）的角度審查其行為的研究卻付之闕如。聊天機器人和基於 LLM 的助理可能會讓不知情的使用者身處險境，因為它們會助長不安全的行為。我們觀察到，當今一些最受歡迎的 LLM 中固有的 ISA 差異很大，大多數模型需要具有明確安全性脈絡的使用者提示，才能運用其安全知識並對使用者提供安全的回應。基於此觀察，我們建立了一套包含 30 個範例的綜合清單，以評估 LLM 的 ISA。這些範例針對行動 ISA 分類法中定義的所有焦點領域，對評估的模型進行基準測試。我們的研究結果之一是，ISA 受到改變模型溫度影響不大，而調整系統提示則會對其產生重大影響。這強調了設定正確的系統提示以減輕 ISA 弱點的必要性。我們的研究結果也凸顯了 ISA 評估對於開發未來基於 LLM 的助理的重要性。

##### **Engagement-Driven Content Generation with Large Language Models**
2411.13187v1 by Erica Coppolillo, Marco Minici, Federico Cinus, Francesco Bonchi, Giuseppe Manco

Large Language Models (LLMs) exhibit significant persuasion capabilities in
one-on-one interactions, but their influence within social networks remains
underexplored. This study investigates the potential social impact of LLMs in
these environments, where interconnected users and complex opinion dynamics
pose unique challenges. In particular, we address the following research
question: can LLMs learn to generate meaningful content that maximizes user
engagement on social networks?
  To answer this question, we define a pipeline to guide the LLM-based content
generation which employs reinforcement learning with simulated feedback. In our
framework, the reward is based on an engagement model borrowed from the
literature on opinion dynamics and information propagation. Moreover, we force
the text generated by the LLM to be aligned with a given topic and to satisfy a
minimum fluency requirement.
  Using our framework, we analyze the capabilities and limitations of LLMs in
tackling the given task, specifically considering the relative positions of the
LLM as an agent within the social network and the distribution of opinions in
the network on the given topic. Our findings show the full potential of LLMs in
creating social engagement. Notable properties of our approach are that the
learning procedure is adaptive to the opinion distribution of the underlying
network and agnostic to the specifics of the engagement model, which is
embedded as a plug-and-play component. In this regard, our approach can be
easily refined for more complex engagement tasks and interventions in
computational social science.
  The code used for the experiments is publicly available at
https://anonymous.4open.science/r/EDCG/.

摘要：<paragraph>大型語言模型 (LLM) 在一對一的互動中展現出顯著的說服能力，但它們在社交網路中的影響力仍未得到充分探討。本研究探討了 LLM 在這些環境中的潛在社會影響，在這些環境中，相互聯繫的使用者和複雜的意見動態帶來了獨特的挑戰。特別是，我們探討了以下研究問題：LLM 能否學會產生有意義的內容，以最大化社交網路上的使用者參與度？
為了回答這個問題，我們定義了一個管道來指導基於 LLM 的內容生成，該管道採用了帶有模擬反饋的強化學習。在我們的框架中，獎勵基於借用自意見動態和資訊傳播文獻的參與模型。此外，我們強制 LLM 生成的文字與給定的主題保持一致，並滿足最低流暢度要求。
使用我們的框架，我們分析了 LLM 在處理給定任務中的能力和限制，特別考慮了 LLM 作為社交網路中代理人的相對位置以及網路中關於給定主題的意見分佈。我們的研究結果顯示了 LLM 在創造社會參與方面的全部潛力。我們方法的顯著特性在於學習程序適應於底層網路的意見分佈，並且不依賴於參與模型的具體情況，而參與模型被嵌入為一個即插即用的組成部分。在這方面，我們的做法可以很容易地針對更複雜的參與任務和計算社會科學中的干預措施進行改進。
用於實驗的程式碼已公開發布於
https://anonymous.4open.science/r/EDCG/。</paragraph>

##### **Cross-Camera Distracted Driver Classification through Feature Disentanglement and Contrastive Learning**
2411.13181v1 by Simone Bianco, Luigi Celona, Paolo Napoletano

The classification of distracted drivers is pivotal for ensuring safe
driving. Previous studies demonstrated the effectiveness of neural networks in
automatically predicting driver distraction, fatigue, and potential hazards.
However, recent research has uncovered a significant loss of accuracy in these
models when applied to samples acquired under conditions that differ from the
training data. In this paper, we introduce a robust model designed to withstand
changes in camera position within the vehicle. Our Driver Behavior Monitoring
Network (DBMNet) relies on a lightweight backbone and integrates a
disentanglement module to discard camera view information from features,
coupled with contrastive learning to enhance the encoding of various driver
actions. Experiments conducted on the daytime and nighttime subsets of the
100-Driver dataset validate the effectiveness of our approach with an increment
on average of 9\% in Top-1 accuracy in comparison with the state of the art. In
addition, cross-dataset and cross-camera experiments conducted on three
benchmark datasets, namely AUCDD-V1, EZZ2021 and SFD, demonstrate the superior
generalization capability of the proposed method.

摘要：分心駕駛的分類對於確保安全駕駛至關重要。先前的研究證明了神經網路在自動預測駕駛分心、疲勞和潛在危險方面的有效性。然而，最近的研究發現，當這些模型應用於在與訓練資料不同的條件下獲取的樣本時，其準確性會大幅下降。在本文中，我們引入了一個強健的模型，旨在承受車輛內攝像機位置的變化。我們的駕駛行為監控網路 (DBMNet) 依賴於輕量級主幹，並整合了一個解糾纏模組，以從特徵中丟棄攝像機視圖資訊，並結合對比學習來增強對各種駕駛動作的編碼。在 100-Driver 資料集的日間和夜間子集上進行的實驗驗證了我們方法的有效性，與現有技術相比，Top-1 準確度平均增加了 9%。此外，在三個基準資料集上進行的跨資料集和跨攝像機實驗，即 AUCDD-V1、EZZ2021 和 SFD，證明了所提出方法的優越泛化能力。

##### **Writing Style Matters: An Examination of Bias and Fairness in Information Retrieval Systems**
2411.13173v1 by Hongliu Cao

The rapid advancement of Language Model technologies has opened new
opportunities, but also introduced new challenges related to bias and fairness.
This paper explores the uncharted territory of potential biases in
state-of-the-art universal text embedding models towards specific document and
query writing styles within Information Retrieval (IR) systems. Our
investigation reveals that different embedding models exhibit different
preferences of document writing style, while more informal and emotive styles
are less favored by most embedding models. In terms of query writing styles,
many embedding models tend to match the style of the query with the style of
the retrieved documents, but some show a consistent preference for specific
styles. Text embedding models fine-tuned on synthetic data generated by LLMs
display a consistent preference for certain style of generated data. These
biases in text embedding based IR systems can inadvertently silence or
marginalize certain communication styles, thereby posing a significant threat
to fairness in information retrieval. Finally, we also compare the answer
styles of Retrieval Augmented Generation (RAG) systems based on different LLMs
and find out that most text embedding models are biased towards LLM's answer
styles when used as evaluation metrics for answer correctness. This study sheds
light on the critical issue of writing style based bias in IR systems, offering
valuable insights for the development of more fair and robust models.

摘要：語言模型技術的快速進步開創了新的機會，但也帶來了與偏見和公平性相關的新挑戰。本文探討了最先進的通用文字嵌入模型中潛在偏見的未知領域，這些偏見針對信息檢索 (IR) 系統中的特定文件和查詢撰寫風格。我們的調查顯示，不同的嵌入模型展現出不同的文件撰寫風格偏好，而大多數嵌入模型較不偏好較非正式和較感性的風格。在查詢撰寫風格方面，許多嵌入模型傾向於將查詢的風格與擷取文件的風格相匹配，但有些模型持續偏好特定風格。針對 LLM 生成的合成資料進行微調的文字嵌入模型持續偏好特定風格的生成資料。基於文字嵌入的 IR 系統中的這些偏見可能會無意間讓某些溝通風格變得沉默或邊緣化，從而對信息檢索中的公平性構成重大威脅。最後，我們還比較了基於不同 LLM 的檢索增強生成 (RAG) 系統的答案風格，並發現大多數文字嵌入模型在用作答案正確性的評估指標時會偏向 LLM 的答案風格。這項研究闡明了 IR 系統中基於寫作風格的偏見這個關鍵問題，為開發更公平、更強健的模型提供了寶貴的見解。

##### **Hard-Synth: Synthesizing Diverse Hard Samples for ASR using Zero-Shot TTS and LLM**
2411.13159v1 by Jiawei Yu, Yuang Li, Xiaosong Qiao, Huan Zhao, Xiaofeng Zhao, Wei Tang, Min Zhang, Hao Yang, Jinsong Su

Text-to-speech (TTS) models have been widely adopted to enhance automatic
speech recognition (ASR) systems using text-only corpora, thereby reducing the
cost of labeling real speech data. Existing research primarily utilizes
additional text data and predefined speech styles supported by TTS models. In
this paper, we propose Hard-Synth, a novel ASR data augmentation method that
leverages large language models (LLMs) and advanced zero-shot TTS. Our approach
employs LLMs to generate diverse in-domain text through rewriting, without
relying on additional text data. Rather than using predefined speech styles, we
introduce a hard prompt selection method with zero-shot TTS to clone speech
styles that the ASR model finds challenging to recognize. Experiments
demonstrate that Hard-Synth significantly enhances the Conformer model,
achieving relative word error rate (WER) reductions of 6.5\%/4.4\% on
LibriSpeech dev/test-other subsets. Additionally, we show that Hard-Synth is
data-efficient and capable of reducing bias in ASR.

摘要：文本轉語音 (TTS) 模型已被廣泛採用，以利用純文字語料庫增強自動語音辨識 (ASR) 系統，從而降低標記真實語音資料的成本。現有研究主要利用 TTS 模型支援的額外文字資料和預先定義的語音風格。在本文中，我們提出 Hard-Synth，這是一種新穎的 ASR 資料擴充方法，它利用大型語言模型 (LLM) 和進階的零次學習 TTS。我們的方法利用 LLM 透過改寫來產生多樣化的領域內文字，而不依賴額外的文字資料。我們沒有使用預先定義的語音風格，而是引進一種搭配零次學習 TTS 的硬提示選取方法，以複製 ASR 模型難以辨識的語音風格。實驗證明 Hard-Synth 大幅增強 Conformer 模型，在 LibriSpeech dev/test-other 子集中達成 6.5%/4.4% 的相對詞彙錯誤率 (WER) 降低。此外，我們證明 Hard-Synth 具有資料效率，並且能夠降低 ASR 中的偏差。

##### **Closer Look at Efficient Inference Methods: A Survey of Speculative Decoding**
2411.13157v1 by Hyun Ryu, Eric Kim

Efficient inference in large language models (LLMs) has become a critical
focus as their scale and complexity grow. Traditional autoregressive decoding,
while effective, suffers from computational inefficiencies due to its
sequential token generation process. Speculative decoding addresses this
bottleneck by introducing a two-stage framework: drafting and verification. A
smaller, efficient model generates a preliminary draft, which is then refined
by a larger, more sophisticated model. This paper provides a comprehensive
survey of speculative decoding methods, categorizing them into draft-centric
and model-centric approaches. We discuss key ideas associated with each method,
highlighting their potential for scaling LLM inference. This survey aims to
guide future research in optimizing speculative decoding and its integration
into real-world LLM applications.

摘要：大型語言模型 (LLM) 中的有效推論已成為一項重要的重點，因為其規模和複雜性不斷增長。傳統自迴歸解碼雖然有效，但由於其序列標記產生過程而導致計算效率低下。推測解碼通過引入兩階段架構（起草和驗證）來解決這個瓶頸。一個較小、高效的模型產生初步草稿，然後由一個較大、更複雜的模型進行優化。本文對推測解碼方法進行了全面的調查，將其分類為以草稿為中心和以模型為中心的方法。我們討論了與每種方法相關的關鍵思想，強調了它們在擴展 LLM 推論方面的潛力。本調查旨在指導未來在最佳化推測解碼及其整合到實際 LLM 應用中的研究。

##### **DMQR-RAG: Diverse Multi-Query Rewriting for RAG**
2411.13154v1 by Zhicong Li, Jiahao Wang, Zhishu Jiang, Hangyu Mao, Zhongxia Chen, Jiazhen Du, Yuanxing Zhang, Fuzheng Zhang, Di Zhang, Yong Liu

Large language models often encounter challenges with static knowledge and
hallucinations, which undermine their reliability. Retrieval-augmented
generation (RAG) mitigates these issues by incorporating external information.
However, user queries frequently contain noise and intent deviations,
necessitating query rewriting to improve the relevance of retrieved documents.
In this paper, we introduce DMQR-RAG, a Diverse Multi-Query Rewriting framework
designed to improve the performance of both document retrieval and final
responses in RAG. Specifically, we investigate how queries with varying
information quantities can retrieve a diverse array of documents, presenting
four rewriting strategies that operate at different levels of information to
enhance the performance of baseline approaches. Additionally, we propose an
adaptive strategy selection method that minimizes the number of rewrites while
optimizing overall performance. Our methods have been rigorously validated
through extensive experiments conducted in both academic and industry settings.

摘要：大型语言模型经常遇到静态知识和幻觉的挑战，这会破坏其可靠性。检索增强生成 (RAG) 通过纳入外部信息来缓解这些问题。然而，用户查询经常包含噪音和意图偏差，这需要查询重写来提高检索到的文档的相关性。在本文中，我们介绍了 DMQR-RAG，这是一个多元化多查询重写框架，旨在提高 RAG 中文档检索和最终响应的性能。具体来说，我们研究了具有不同信息量的查询如何检索各种文档，提出了四种在不同信息级别操作的重写策略，以增强基线方法的性能。此外，我们提出了一种自适应策略选择方法，该方法在优化整体性能的同时最大程度地减少了重写次数。我们的方法已经通过在学术和工业环境中进行的广泛实验得到了严格验证。

##### **AGLP: A Graph Learning Perspective for Semi-supervised Domain Adaptation**
2411.13152v1 by Houcheng Su, Mengzhu Wang, Jiao Li, Nan Yin, Li Shen

In semi-supervised domain adaptation (SSDA), the model aims to leverage
partially labeled target domain data along with a large amount of labeled
source domain data to enhance its generalization capability for the target
domain. A key advantage of SSDA is its ability to significantly reduce reliance
on labeled data, thereby lowering the costs and time associated with data
preparation. Most existing SSDA methods utilize information from domain labels
and class labels but overlook the structural information of the data. To
address this issue, this paper proposes a graph learning perspective (AGLP) for
semi-supervised domain adaptation. We apply the graph convolutional network to
the instance graph which allows structural information to propagate along the
weighted graph edges. The proposed AGLP model has several advantages. First, to
the best of our knowledge, this is the first work to model structural
information in SSDA. Second, the proposed model can effectively learn
domain-invariant and semantic representations, reducing domain discrepancies in
SSDA. Extensive experimental results on multiple standard benchmarks
demonstrate that the proposed AGLP algorithm outperforms state-of-the-art
semi-supervised domain adaptation methods.

摘要：在半监督域适应 (SSDA) 中，该模型旨在利用部分标记的目标域数据以及大量的标记源域数据来增强其对目标域的泛化能力。SSDA 的一个关键优势在于它能够显著减少对标记数据的依赖，从而降低与数据准备相关联的成本和时间。大多数现有的 SSDA 方法利用来自域标签和类标签的信息，但忽略了数据的结构信息。为了解决这个问题，本文提出了一个用于半监督域适应的图学习视角 (AGLP)。我们将图卷积网络应用于实例图，该图允许结构信息沿着加权图边传播。提出的 AGLP 模型有几个优点。首先，据我们所知，这是第一个在 SSDA 中对结构信息进行建模的工作。其次，所提出的模型可以有效地学习域不变和语义表示，从而减少 SSDA 中的域差异。在多个标准基准上的广泛实验结果表明，所提出的 AGLP 算法优于最先进的半监督域适应方法。

##### **GraphCL: Graph-based Clustering for Semi-Supervised Medical Image Segmentation**
2411.13147v1 by Mengzhu Wang, Jiao Li, Houcheng Su, Nan Yin, Shen Li

Semi-supervised learning (SSL) has made notable advancements in medical image
segmentation (MIS), particularly in scenarios with limited labeled data and
significantly enhancing data utilization efficiency. Previous methods primarily
focus on complex training strategies to utilize unlabeled data but neglect the
importance of graph structural information. Different from existing methods, we
propose a graph-based clustering for semi-supervised medical image segmentation
(GraphCL) by jointly modeling graph data structure in a unified deep model. The
proposed GraphCL model enjoys several advantages. Firstly, to the best of our
knowledge, this is the first work to model the data structure information for
semi-supervised medical image segmentation (SSMIS). Secondly, to get the
clustered features across different graphs, we integrate both pairwise
affinities between local image features and raw features as inputs. Extensive
experimental results on three standard benchmarks show that the proposed
GraphCL algorithm outperforms state-of-the-art semi-supervised medical image
segmentation methods.

摘要：半监督学习（SSL）在医学影像分割（MIS）中取得了显着进展，特别是在标注数据有限且显著提高数据利用效率的场景中。以前的方法主要集中在复杂的训练策略上以利用未标注的数据，但忽略了图结构信息的重要性。与现有方法不同，我们提出了一种基于图的聚类方法用于半监督医学影像分割（GraphCL），通过在统一的深度模型中联合建模图数据结构。所提出的 GraphCL 模型具有以下几个优点。首先，据我们所知，这是第一个为半监督医学影像分割（SSMIS）建模数据结构信息的模型。其次，为了获得不同图中聚类的特征，我们将局部图像特征和原始特征之间的成对相似性作为输入进行整合。在三个标准基准上的大量实验结果表明，所提出的 GraphCL 算法优于最先进的半监督医学影像分割方法。

##### **CopyrightMeter: Revisiting Copyright Protection in Text-to-image Models**
2411.13144v1 by Naen Xu, Changjiang Li, Tianyu Du, Minxi Li, Wenjie Luo, Jiacheng Liang, Yuyuan Li, Xuhong Zhang, Meng Han, Jianwei Yin, Ting Wang

Text-to-image diffusion models have emerged as powerful tools for generating
high-quality images from textual descriptions. However, their increasing
popularity has raised significant copyright concerns, as these models can be
misused to reproduce copyrighted content without authorization. In response,
recent studies have proposed various copyright protection methods, including
adversarial perturbation, concept erasure, and watermarking techniques.
However, their effectiveness and robustness against advanced attacks remain
largely unexplored. Moreover, the lack of unified evaluation frameworks has
hindered systematic comparison and fair assessment of different approaches. To
bridge this gap, we systematize existing copyright protection methods and
attacks, providing a unified taxonomy of their design spaces. We then develop
CopyrightMeter, a unified evaluation framework that incorporates 17
state-of-the-art protections and 16 representative attacks. Leveraging
CopyrightMeter, we comprehensively evaluate protection methods across multiple
dimensions, thereby uncovering how different design choices impact fidelity,
efficacy, and resilience under attacks. Our analysis reveals several key
findings: (i) most protections (16/17) are not resilient against attacks; (ii)
the "best" protection varies depending on the target priority; (iii) more
advanced attacks significantly promote the upgrading of protections. These
insights provide concrete guidance for developing more robust protection
methods, while its unified evaluation protocol establishes a standard benchmark
for future copyright protection research in text-to-image generation.

摘要：文字轉圖像擴散模型已成為從文字描述中生成高品質圖像的有力工具。然而，它們日益普及引發了重大的版權問題，因為這些模型可能會被濫用來未經授權地複製受版權保護的內容。為了解決這個問題，最近的研究提出了各種版權保護方法，包括對抗性擾動、概念擦除和浮水印技術。然而，它們對進階攻擊的有效性和穩健性在很大程度上仍未得到探討。此外，缺乏統一的評估框架阻礙了對不同方法的系統比較和公平評估。為了彌補這一差距，我們系統化了現有的版權保護方法和攻擊，並提供了它們的設計空間的統一分類法。然後，我們開發了 CopyrightMeter，這是一個統一的評估框架，它包含了 17 種最先進的保護措施和 16 種代表性攻擊。利用 CopyrightMeter，我們全面評估了多個維度的保護方法，從而揭示了不同的設計選擇如何影響攻擊下的保真度、效能和韌性。我們的分析揭示了幾個關鍵發現：(i) 大多數保護措施 (16/17) 對攻擊沒有韌性；(ii) 「最佳」保護措施會根據目標優先順序而有所不同；(iii) 更進階的攻擊顯著促進了保護措施的升級。這些見解為開發更強大的保護方法提供了具體指導，而其統一的評估協議為文字轉圖像生成中的未來版權保護研究建立了一個標準基准。

##### **Video-RAG: Visually-aligned Retrieval-Augmented Long Video Comprehension**
2411.13093v1 by Yongdong Luo, Xiawu Zheng, Xiao Yang, Guilin Li, Haojia Lin, Jinfa Huang, Jiayi Ji, Fei Chao, Jiebo Luo, Rongrong Ji

Existing large video-language models (LVLMs) struggle to comprehend long
videos correctly due to limited context. To address this problem, fine-tuning
long-context LVLMs and employing GPT-based agents have emerged as promising
solutions. However, fine-tuning LVLMs would require extensive high-quality data
and substantial GPU resources, while GPT-based agents would rely on proprietary
models (e.g., GPT-4o). In this paper, we propose Video Retrieval-Augmented
Generation (Video-RAG), a training-free and cost-effective pipeline that
employs visually-aligned auxiliary texts to help facilitate cross-modality
alignment while providing additional information beyond the visual content.
Specifically, we leverage open-source external tools to extract
visually-aligned information from pure video data (e.g., audio, optical
character, and object detection), and incorporate the extracted information
into an existing LVLM as auxiliary texts, alongside video frames and queries,
in a plug-and-play manner. Our Video-RAG offers several key advantages: (i)
lightweight with low computing overhead due to single-turn retrieval; (ii) easy
implementation and compatibility with any LVLM; and (iii) significant,
consistent performance gains across long video understanding benchmarks,
including Video-MME, MLVU, and LongVideoBench. Notably, our model demonstrates
superior performance over proprietary models like Gemini-1.5-Pro and GPT-4o
when utilized with a 72B model.

摘要：現有的大型視訊語言模型 (LVLMs) 由於受限於情境，難以正確理解長篇視訊。為了解決這個問題，微調長情境 LVLMs 和使用基於 GPT 的代理已成為有前景的解決方案。然而，微調 LVLMs 需要大量高品質資料和大量的 GPU 資源，而基於 GPT 的代理則依賴專有模型（例如，GPT-4o）。在本文中，我們提出視訊檢索增強生成 (Video-RAG)，這是一個免訓練且成本效益的管道，它使用視覺對齊的輔助文字來協助促進跨模態對齊，同時提供視覺內容以外的額外資訊。具體來說，我們利用開源外部工具從純視訊資料（例如，音訊、光學字元和物件偵測）中萃取視覺對齊的資訊，並將萃取的資訊作為輔助文字納入現有的 LVLM 中，連同視訊畫格和查詢，採用即插即用的方式。我們的 Video-RAG 提供了幾個關鍵優勢：(i) 由於單次檢索而重量輕且運算負擔低；(ii) 容易實作且與任何 LVLM 相容；以及 (iii) 在長視訊理解基準中獲得顯著且一致的效能提升，包括 Video-MME、MLVU 和 LongVideoBench。值得注意的是，當與 72B 模型一起使用時，我們的模型表現出優於專有模型（例如 Gemini-1.5-Pro 和 GPT-4o）的效能。

##### **Patience Is The Key to Large Language Model Reasoning**
2411.13082v1 by Yijiong Yu

Recent advancements in the field of large language models, particularly
through the Chain of Thought (CoT) approach, have demonstrated significant
improvements in solving complex problems. However, existing models either tend
to sacrifice detailed reasoning for brevity due to user preferences, or require
extensive and expensive training data to learn complicated reasoning ability,
limiting their potential in solving complex tasks. To bridge this gap,
following the concept of scaling test-time, we propose a simple method by
encouraging models to adopt a more patient reasoning style without the need of
introducing new knowledge or skills. To employ a preference optimization
approach, we generate detailed reasoning processes as positive examples and
simple answers as negative examples, thereby training the model to favor
thoroughness in its responses. Our results demonstrate a performance increase
of up to 6.7% on GSM8k with training just on a lightweight dataset.

摘要：近期在大型语言模型领域取得的进步，特别是通过思维链 (CoT) 方法，已证明在解决复杂问题方面有显著的改进。然而，现有模型要么倾向于牺牲详细推理以换取简洁性，以迎合用户偏好，要么需要广泛且昂贵的训练数据来学习复杂的推理能力，从而限制了它们在解决复杂任务中的潜力。为了弥合这一差距，遵循测试时间扩展的概念，我们提出了一种简单的方法，通过鼓励模型采用更耐心的推理风格，而无需引入新的知识或技能。为了采用偏好优化方法，我们生成详细的推理过程作为正例，生成简单的答案作为反例，从而训练模型偏好其响应中的全面性。我们的结果表明，仅在轻量级数据集上进行训练，GSM8k 的性能提升了 6.7%。

##### **Neural Internal Model Control: Learning a Robust Control Policy via Predictive Error Feedback**
2411.13079v1 by Feng Gao, Chao Yu, Yu Wang, Yi Wu

Accurate motion control in the face of disturbances within complex
environments remains a major challenge in robotics. Classical model-based
approaches often struggle with nonlinearities and unstructured disturbances,
while RL-based methods can be fragile when encountering unseen scenarios. In
this paper, we propose a novel framework, Neural Internal Model Control, which
integrates model-based control with RL-based control to enhance robustness. Our
framework streamlines the predictive model by applying Newton-Euler equations
for rigid-body dynamics, eliminating the need to capture complex
high-dimensional nonlinearities. This internal model combines model-free RL
algorithms with predictive error feedback. Such a design enables a closed-loop
control structure to enhance the robustness and generalizability of the control
system. We demonstrate the effectiveness of our framework on both quadrotors
and quadrupedal robots, achieving superior performance compared to
state-of-the-art methods. Furthermore, real-world deployment on a quadrotor
with rope-suspended payloads highlights the framework's robustness in
sim-to-real transfer. Our code is released at
https://github.com/thu-uav/NeuralIMC.

摘要：在複雜環境中，精準的運動控制面對干擾，仍是機器人技術的一大挑戰。基於古典模型的方法，經常難以應付非線性和非結構化干擾，而基於 RL 的方法，在遇到未見過的場景時，可能會很脆弱。在本文中，我們提出了一個新穎的框架，稱為神經內部模型控制，它整合了基於模型的控制和基於 RL 的控制，以增強穩健性。我們的框架通過應用牛頓-歐拉方程式來簡化預測模型，以獲得剛體動力學，消除了捕捉複雜高維非線性的需要。這個內部模型結合了無模型 RL 演算法和預測誤差回饋。這樣的設計，使閉迴路控制結構能夠增強控制系統的穩健性和泛化能力。我們在四旋翼和四足機器人上證明了我們框架的有效性，與最先進的方法相比，達到了更好的效能。此外，在帶有繩索懸掛載荷的四旋翼上進行的真實世界部署，突出了該框架在模擬到真實轉移中的穩健性。我們的程式碼已發佈在 https://github.com/thu-uav/NeuralIMC。

##### **Branches, Assemble! Multi-Branch Cooperation Network for Large-Scale Click-Through Rate Prediction at Taobao**
2411.13057v1 by Xu Chen, Zida Cheng, Yuangang Pan, Shuai Xiao, Xiaoming Liu, Jinsong Lan, Qingwen Liu, Ivor W. Tsang

Existing click-through rate (CTR) prediction works have studied the role of
feature interaction through a variety of techniques. Each interaction technique
exhibits its own strength, and solely using one type could constrain the
model's capability to capture the complex feature relationships, especially for
industrial large-scale data with enormous users and items. Recent research
shows that effective CTR models often combine an MLP network with a dedicated
feature interaction network in a two-parallel structure. However, the interplay
and cooperative dynamics between different streams or branches remain
under-researched. In this work, we introduce a novel Multi-Branch Cooperation
Network (MBCnet) which enables multiple branch networks to collaborate with
each other for better complex feature interaction modeling. Specifically,
MBCnet consists of three branches: the Expert-based Feature Grouping and
Crossing (EFGC) branch that promotes the model's memorization ability of
specific feature fields, the low rank Cross Net branch and Deep branch to
enhance both explicit and implicit feature crossing for improved
generalization. Among branches, a novel cooperation scheme is proposed based on
two principles: branch co-teaching and moderate differentiation. Branch
co-teaching encourages well-learned branches to support poorly-learned ones on
specific training samples. Moderate differentiation advocates branches to
maintain a reasonable level of difference in their feature representations. The
cooperation strategy improves learning through mutual knowledge sharing via
co-teaching and boosts the discovery of diverse feature interactions across
branches. Extensive experiments on large-scale industrial datasets and online
A/B test demonstrate MBCnet's superior performance, delivering a 0.09 point
increase in CTR, 1.49% growth in deals, and 1.62% rise in GMV. Core codes will
be released soon.

摘要：現有的點擊率 (CTR) 預測研究已透過各種技術探討特徵互動的角色。每個互動技術展現其獨特優勢，僅使用一種類型可能會限制模型擷取複雜特徵關係的能力，特別是對於擁有大量使用者和項目的產業級大規模資料。最近的研究顯示，有效的 CTR 模型經常在雙平行結構中結合 MLP 網路與專用的特徵互動網路。然而，不同串流或分支之間的交互作用和協作動態仍未得到充分的研究。在這項研究中，我們引入了一種新穎的多分支協作網路 (MBCnet)，它讓多個分支網路相互協作，以改善複雜特徵互動建模。具體來說，MBCnet 包含三個分支：專家級特徵分組和交叉 (EFGC) 分支，可提升模型對特定特徵欄位的記憶能力；低階交叉網路分支和深度分支，可增強顯式和隱式特徵交叉，以改善泛化。在分支之間，基於兩個原則提出了新穎的協作架構：分支共同教學和適度區分。分支共同教學鼓勵學習良好的分支在特定訓練樣本上支援學習不良的分支。適度區分主張分支在特徵表示中維持合理的差異程度。協作策略透過共同教學改善透過相互知識共享的學習，並促進跨分支發現多樣化的特徵互動。在大型產業資料集和線上 A/B 測試上的廣泛實驗證明了 MBCnet 的優異效能，在 CTR 上提升了 0.09 個百分點、在交易上成長了 1.49%、在 GMV 上提升了 1.62%。核心程式碼將於近期釋出。

##### **MEGL: Multimodal Explanation-Guided Learning**
2411.13053v1 by Yifei Zhang, Tianxu Jiang, Bo Pan, Jingyu Wang, Guangji Bai, Liang Zhao

Explaining the decision-making processes of Artificial Intelligence (AI)
models is crucial for addressing their "black box" nature, particularly in
tasks like image classification. Traditional eXplainable AI (XAI) methods
typically rely on unimodal explanations, either visual or textual, each with
inherent limitations. Visual explanations highlight key regions but often lack
rationale, while textual explanations provide context without spatial
grounding. Further, both explanation types can be inconsistent or incomplete,
limiting their reliability. To address these challenges, we propose a novel
Multimodal Explanation-Guided Learning (MEGL) framework that leverages both
visual and textual explanations to enhance model interpretability and improve
classification performance. Our Saliency-Driven Textual Grounding (SDTG)
approach integrates spatial information from visual explanations into textual
rationales, providing spatially grounded and contextually rich explanations.
Additionally, we introduce Textual Supervision on Visual Explanations to align
visual explanations with textual rationales, even in cases where ground truth
visual annotations are missing. A Visual Explanation Distribution Consistency
loss further reinforces visual coherence by aligning the generated visual
explanations with dataset-level patterns, enabling the model to effectively
learn from incomplete multimodal supervision. We validate MEGL on two new
datasets, Object-ME and Action-ME, for image classification with multimodal
explanations. Experimental results demonstrate that MEGL outperforms previous
approaches in prediction accuracy and explanation quality across both visual
and textual domains. Our code will be made available upon the acceptance of the
paper.

摘要：<paragraph>解釋人工智慧（AI）模型的決策過程對於解決其「黑盒子」性質至關重要，特別是在影像分類等任務中。傳統的可解釋 AI（XAI）方法通常依賴於單模態解釋，無論是視覺或文字，每種解釋都有其固有的限制。視覺解釋重點強調關鍵區域，但通常缺乏依據，而文字解釋則提供背景，卻沒有空間依據。此外，這兩種解釋類型都可能不一致或不完整，限制了其可靠性。為了應對這些挑戰，我們提出了一個創新的多模態解釋引導學習（MEGL）架構，它利用視覺和文字解釋來增強模型的可解釋性，並提高分類效能。我們的顯著性驅動文字基礎（SDTG）方法將來自視覺解釋的空間資訊整合到文字依據中，提供具有空間依據且內容豐富的解釋。此外，我們在視覺解釋中引入了文字監督，即使在缺少地面真實視覺註解的情況下，也能將視覺解釋與文字依據對齊。視覺解釋分佈一致性損失進一步加強了視覺一致性，方法是將產生的視覺解釋與資料集層級模式對齊，使模型能夠有效地從不完整的多模態監督中學習。我們在兩個新資料集 Object-ME 和 Action-ME 上驗證了 MEGL，用於具有多模態解釋的影像分類。實驗結果表明，在視覺和文字領域中，MEGL 在預測準確性和解釋品質方面都優於先前的做法。我們的程式碼將在論文被接受後提供。</paragraph>

##### **Explainable LLM-driven Multi-dimensional Distillation for E-Commerce Relevance Learning**
2411.13045v1 by Gang Zhao, Ximing Zhang, Chenji Lu, Hui Zhao, Tianshu Wu, Pengjie Wang, Jian Xu, Bo Zheng

Effective query-item relevance modeling is pivotal for enhancing user
experience and safeguarding user satisfaction in e-commerce search systems.
Recently, benefiting from the vast inherent knowledge, Large Language Model
(LLM) approach demonstrates strong performance and long-tail generalization
ability compared with previous neural-based specialized relevance learning
methods. Though promising, current LLM-based methods encounter the following
inadequacies in practice: First, the massive parameters and computational
demands make it difficult to be deployed online. Second, distilling LLM models
to online models is a feasible direction, but the LLM relevance modeling is a
black box, and its rich intrinsic knowledge is difficult to extract and apply
online. To improve the interpretability of LLM and boost the performance of
online relevance models via LLM, we propose an Explainable LLM-driven
Multi-dimensional Distillation framework for e-commerce relevance learning,
which comprises two core components: (1) An Explainable LLM for relevance
modeling (ELLM-rele), which decomposes the relevance learning into intermediate
steps and models relevance learning as a Chain-of-Thought (CoT) reasoning,
thereby enhancing both interpretability and performance of LLM. (2) A
Multi-dimensional Knowledge Distillation (MKD) architecture that transfers the
knowledge of ELLM-rele to current deployable interaction-based and
representation-based student models from both the relevance score distribution
and CoT reasoning aspects. Through distilling the probabilistic and CoT
reasoning knowledge, MKD improves both the semantic interaction and long-tail
generalization abilities of student models. Extensive offline evaluations and
online experiments on Taobao search ad scene demonstrate that our proposed
framework significantly enhances e-commerce relevance learning performance and
user experience.

摘要：<paragraph>有效的查詢項目相關性建模對於提升使用者體驗和保障電子商務搜尋系統中的使用者滿意度至關重要。最近，受益於廣泛的內在知識，大型語言模型 (LLM) 方法展現了強大的效能和長尾概化能力，與先前的基於神經網路的專業相關性學習方法相比。儘管有前景，目前的基於 LLM 的方法在實務上仍遇到以下不足：首先，龐大的參數和運算需求使得線上部署困難。其次，將 LLM 模型精簡為線上模型是一個可行的方向，但 LLM 相關性建模是一個黑盒子，其豐富的內在知識難以提取並線上應用。為了提升 LLM 的可解釋性，並透過 LLM 提升線上相關性模型的效能，我們提出了一個可解釋 LLM 驅動的多維度知識萃取架構，用於電子商務相關性學習，其中包含兩個核心組成部分：(1) 一個用於相關性建模的可解釋 LLM (ELLM-rele)，它將相關性學習分解成中間步驟，並將相關性學習建模為一個思考鏈 (CoT) 推理，從而提升 LLM 的可解釋性和效能。(2) 一個多維度知識萃取 (MKD) 架構，它將 ELLM-rele 的知識轉移到目前可部署的基於互動和基於表示的學生模型，從相關性分數分佈和 CoT 推理面向進行轉移。透過萃取機率和 CoT 推理知識，MKD 提升了學生模型的語意互動和長尾概化能力。在淘寶搜尋廣告場景中進行的大量離線評估和線上實驗顯示，我們提出的架構顯著提升了電子商務相關性學習效能和使用者體驗。</paragraph>

##### **"It was 80% me, 20% AI": Seeking Authenticity in Co-Writing with Large Language Models**
2411.13032v1 by Angel Hsing-Chi Hwang, Q. Vera Liao, Su Lin Blodgett, Alexandra Olteanu, Adam Trischler

Given the rising proliferation and diversity of AI writing assistance tools,
especially those powered by large language models (LLMs), both writers and
readers may have concerns about the impact of these tools on the authenticity
of writing work. We examine whether and how writers want to preserve their
authentic voice when co-writing with AI tools and whether personalization of AI
writing support could help achieve this goal. We conducted semi-structured
interviews with 19 professional writers, during which they co-wrote with both
personalized and non-personalized AI writing-support tools. We supplemented
writers' perspectives with opinions from 30 avid readers about the written work
co-produced with AI collected through an online survey. Our findings illuminate
conceptions of authenticity in human-AI co-creation, which focus more on the
process and experience of constructing creators' authentic selves. While
writers reacted positively to personalized AI writing tools, they believed the
form of personalization needs to target writers' growth and go beyond the phase
of text production. Overall, readers' responses showed less concern about
human-AI co-writing. Readers could not distinguish AI-assisted work,
personalized or not, from writers' solo-written work and showed positive
attitudes toward writers experimenting with new technology for creative
writing.

摘要：隨著 AI 寫作輔助工具的普及和多樣化，特別是那些由大型語言模型 (LLM) 驅動的工具，寫作者和讀者可能都擔心這些工具對寫作作品真實性的影響。我們探討了在與 AI 工具共同寫作時，寫作者是否以及如何想要保留他們的真實聲音，以及 AI 寫作支援的個人化是否可以幫助實現這一目標。我們對 19 位專業寫作者進行了半結構化訪談，在訪談中，他們與個性化和非個性化的 AI 寫作支援工具共同寫作。我們通過一項線上調查，用 30 位熱心讀者對與 AI 共同創作的書面作品的意見，補充了寫作者的觀點。我們的研究結果闡明了人機共同創作中真實性的概念，其更側重於構建創作者真實自我的過程和體驗。雖然寫作者對個性化的 AI 寫作工具反應積極，但他們認為個性化的形式需要針對寫作者的成長，並超越文本產生的階段。總體而言，讀者的回應對人機共同寫作的關注較少。讀者無法區分 AI 協助的作品（無論是否個性化）和寫作者單獨寫作的作品，並對寫作者嘗試使用新技術進行創意寫作表現出積極的態度。

##### **LLMSteer: Improving Long-Context LLM Inference by Steering Attention on Reused Contexts**
2411.13009v1 by Zhuohan Gu, Jiayi Yao, Kuntai Du, Junchen Jiang

As large language models (LLMs) show impressive performance on complex tasks,
they still struggle with longer contextual understanding and high computational
costs. To balance efficiency and quality, we introduce LLMSteer, a
fine-tuning-free framework that enhances LLMs through query-independent
attention steering. Tested on popular LLMs and datasets, LLMSteer narrows the
performance gap with baselines by 65.9% and reduces the runtime delay by up to
4.8x compared to recent attention steering methods.

摘要：隨著大型語言模型 (LLM) 在複雜任務中展現出令人印象深刻的效能，
它們在較長的脈絡理解和高運算成本方面仍面臨挑戰。為了平衡效率與品質，我們引入了 LLMSteer，一個無需微調的架構，透過與查詢無關的注意力引導來增強 LLM。在熱門的 LLM 和資料集上進行測試，LLMSteer 將效能差距與基準縮小了 65.9%，並將執行時間延遲減少了 4.8 倍，與最近的注意力引導方法相比。

##### **Evaluating LLMs Capabilities Towards Understanding Social Dynamics**
2411.13008v1 by Anique Tahir, Lu Cheng, Manuel Sandoval, Yasin N. Silva, Deborah L. Hall, Huan Liu

Social media discourse involves people from different backgrounds, beliefs,
and motives. Thus, often such discourse can devolve into toxic interactions.
Generative Models, such as Llama and ChatGPT, have recently exploded in
popularity due to their capabilities in zero-shot question-answering. Because
these models are increasingly being used to ask questions of social
significance, a crucial research question is whether they can understand social
media dynamics. This work provides a critical analysis regarding generative
LLM's ability to understand language and dynamics in social contexts,
particularly considering cyberbullying and anti-cyberbullying (posts aimed at
reducing cyberbullying) interactions. Specifically, we compare and contrast the
capabilities of different large language models (LLMs) to understand three key
aspects of social dynamics: language, directionality, and the occurrence of
bullying/anti-bullying messages. We found that while fine-tuned LLMs exhibit
promising results in some social media understanding tasks (understanding
directionality), they presented mixed results in others (proper paraphrasing
and bullying/anti-bullying detection). We also found that fine-tuning and
prompt engineering mechanisms can have positive effects in some tasks. We
believe that a understanding of LLM's capabilities is crucial to design future
models that can be effectively used in social applications.

摘要：社群媒體論述涉及來自不同背景、信仰和動機的人。因此，這種論述通常會演變成有毒的互動。生成式模型，例如 Llama 和 ChatGPT，最近由於其在零次發問回答中的能力而爆紅。由於這些模型正越來越常被用來詢問具有社會意義的問題，一個重要的研究問題是它們是否能理解社群媒體動態。這項工作提供了關於生成式 LLM 理解語言和社群脈絡中的動態的能力的批判性分析，特別是考慮到網路霸凌和反網路霸凌（旨在減少網路霸凌）互動。具體來說，我們比較和對比了不同大型語言模型 (LLM) 理解社群動態的三个關鍵面向的能力：語言、方向性和霸凌/反霸凌訊息發生的情況。我們發現，雖然微調的 LLM 在某些社群媒體理解任務（理解方向性）中展現出有希望的結果，但它們在其他任務（適當的改寫和霸凌/反霸凌偵測）中呈現出好壞參半的結果。我們也發現微調和提示工程機制可以在某些任務中產生正面的效果。我們相信了解 LLM 的能力對於設計未來可以在社群應用程式中有效使用的模型至關重要。

##### **Automating Sonologists USG Commands with AI and Voice Interface**
2411.13006v1 by Emad Mohamed, Shruti Tiwari, Sheena Christabel Pravin

This research presents an advanced AI-powered ultrasound imaging system that
incorporates real-time image processing, organ tracking, and voice commands to
enhance the efficiency and accuracy of diagnoses in clinical practice.
Traditional ultrasound diagnostics often require significant time and introduce
a degree of subjectivity due to user interaction. The goal of this innovative
solution is to provide Sonologists with a more predictable and productive
imaging procedure utilizing artificial intelligence, computer vision, and voice
technology. The functionality of the system employs computer vision and deep
learning algorithms, specifically adopting the Mask R-CNN model from Detectron2
for semantic segmentation of organs and key landmarks. This automation improves
diagnostic accuracy by enabling the extraction of valuable information with
minimal human input. Additionally, it includes a voice recognition feature that
allows for hands-free operation, enabling users to control the system with
commands such as freeze or liver, all while maintaining their focus on the
patient. The architecture comprises video processing and real-time segmentation
modules that prepare the system to perform essential imaging functions, such as
freezing and zooming in on frames. The liver histopathology module, optimized
for detecting fibrosis, achieved an impressive accuracy of 98.6%. Furthermore,
the organ segmentation module produces output confidence levels between 50% and
95%, demonstrating its efficacy in organ detection.

摘要：本研究提出了一個進階的人工智慧超音波影像系統，它結合了即時影像處理、器官追蹤和語音指令，以增強臨床實務中診斷的效率和準確性。傳統的超音波診斷通常需要大量的時間，並由於使用者的互動而引入了一定的主觀性。這個創新解決方案的目標是為超音波檢查醫師提供一個更可預測且更具生產力的影像程序，利用人工智慧、電腦視覺和語音技術。該系統的功能採用電腦視覺和深度學習演算法，特別是採用 Detectron2 中的 Mask R-CNN 模型來進行器官和關鍵地標的語意分割。此自動化透過以最少的人工輸入提取有價值的資訊來提高診斷準確性。此外，它還包括一個語音辨識功能，允許免持操作，使用戶能夠使用凍結或肝臟等指令來控制系統，同時將注意力集中在患者身上。架構包含視訊處理和即時分割模組，準備系統執行必要的影像功能，例如凍結和縮放畫面。針對纖維化偵測而最佳化的肝臟組織病理學模組，達到了令人印象深刻的 98.6% 準確度。此外，器官分割模組產生的輸出信心水準在 50% 到 95% 之間，證明了其在器官偵測中的效能。

##### **MemoryFormer: Minimize Transformer Computation by Removing Fully-Connected Layers**
2411.12992v1 by Ning Ding, Yehui Tang, Haochen Qin, Zhenli Zhou, Chao Xu, Lin Li, Kai Han, Heng Liao, Yunhe Wang

In order to reduce the computational complexity of large language models,
great efforts have been made to to improve the efficiency of transformer models
such as linear attention and flash-attention. However, the model size and
corresponding computational complexity are constantly scaled up in pursuit of
higher performance. In this work, we present MemoryFormer, a novel transformer
architecture which significantly reduces the computational complexity (FLOPs)
from a new perspective. We eliminate nearly all the computations of the
transformer model except for the necessary computation required by the
multi-head attention operation. This is made possible by utilizing an
alternative method for feature transformation to replace the linear projection
of fully-connected layers. Specifically, we first construct a group of
in-memory lookup tables that store a large amount of discrete vectors to
replace the weight matrix used in linear projection. We then use a hash
algorithm to retrieve a correlated subset of vectors dynamically based on the
input embedding. The retrieved vectors combined together will form the output
embedding, which provides an estimation of the result of matrix multiplication
operation in a fully-connected layer. Compared to conducting matrix
multiplication, retrieving data blocks from memory is a much cheaper operation
which requires little computations. We train MemoryFormer from scratch and
conduct extensive experiments on various benchmarks to demonstrate the
effectiveness of the proposed model.

摘要：为了降低大型语言模型的计算复杂度，
在提高 Transformer 模型的效率方面，例如线性注意力和闪存注意力，已经做出了巨大的努力。然而，为了追求更高的性能，模型大小和相应的计算复杂度不断扩大。在这项工作中，我们提出了 MemoryFormer，这是一种新的 Transformer 架构，它从一个新的角度显著降低了计算复杂度 (FLOP)。我们消除了 Transformer 模型几乎所有计算，除了多头注意力操作所需的必要计算。这是通过利用一种替代的特征转换方法来替换全连接层的线性投影而实现的。具体来说，我们首先构建一组内存中查找表，存储大量的离散向量来替换线性投影中使用的权重矩阵。然后，我们使用哈希算法根据输入嵌入动态地检索一个相关的向量子集。检索到的向量组合在一起将形成输出嵌入，它提供了全连接层中矩阵乘法运算结果的估计。与执行矩阵乘法相比，从内存中检索数据块是一个开销小得多的操作，几乎不需要计算。我们从头开始训练 MemoryFormer，并在各种基准上进行了广泛的实验，以证明所提出模型的有效性。

##### **BetterBench: Assessing AI Benchmarks, Uncovering Issues, and Establishing Best Practices**
2411.12990v1 by Anka Reuel, Amelia Hardy, Chandler Smith, Max Lamparth, Malcolm Hardy, Mykel J. Kochenderfer

AI models are increasingly prevalent in high-stakes environments,
necessitating thorough assessment of their capabilities and risks. Benchmarks
are popular for measuring these attributes and for comparing model performance,
tracking progress, and identifying weaknesses in foundation and non-foundation
models. They can inform model selection for downstream tasks and influence
policy initiatives. However, not all benchmarks are the same: their quality
depends on their design and usability. In this paper, we develop an assessment
framework considering 46 best practices across an AI benchmark's lifecycle and
evaluate 24 AI benchmarks against it. We find that there exist large quality
differences and that commonly used benchmarks suffer from significant issues.
We further find that most benchmarks do not report statistical significance of
their results nor allow for their results to be easily replicated. To support
benchmark developers in aligning with best practices, we provide a checklist
for minimum quality assurance based on our assessment. We also develop a living
repository of benchmark assessments to support benchmark comparability,
accessible at betterbench.stanford.edu.

摘要：AI 模型在高風險環境中越來越普遍，
需要徹底評估其能力和風險。基准
廣泛用於衡量這些屬性，並用於比較模型效能，
追蹤進度，並找出基礎和非基礎
模型中的弱點。它們可以告知下游任務的模型選擇並影響
政策倡議。然而，並非所有基準都相同：其品質
取決於其設計和可用性。在本文中，我們開發了一個評估
架構，考量了 AI 基準生命週期中的 46 項最佳實務，並
針對它評估了 24 個 AI 基準。我們發現存在很大的品質
差異，且常見的基準存在重大問題。
我們進一步發現，大多數基準未報告其結果的統計顯著性，也未讓其結果易於複製。為了支持
基準開發人員遵循最佳實務，我們根據我們的評估提供了一個最低品質保證的檢查表。我們也開發了一個基准評估的動態
儲存庫，以支援基準的可比較性，可在 betterbench.stanford.edu 取得。

##### **Training Bilingual LMs with Data Constraints in the Targeted Language**
2411.12986v1 by Skyler Seto, Maartje ter Hoeve, He Bai, Natalie Schluter, David Grangier

Large language models are trained on massive scrapes of the web, as required
by current scaling laws. Most progress is made for English, given its abundance
of high-quality pretraining data. For most other languages, however, such high
quality pretraining data is unavailable. In this work, we study how to boost
pretrained model performance in a data constrained target language by enlisting
data from an auxiliary language for which high quality data is available. We
study this by quantifying the performance gap between training with data in a
data-rich auxiliary language compared with training in the target language,
exploring the benefits of translation systems, studying the limitations of
model scaling for data constrained languages, and proposing new methods for
upsampling data from the auxiliary language. Our results show that stronger
auxiliary datasets result in performance gains without modification to the
model or training objective for close languages, and, in particular, that
performance gains due to the development of more information-rich English
pretraining datasets can extend to targeted language settings with limited
data.

摘要：大型語言模型根據當前規模定律的要求，在網路的大規模擷取上進行訓練。由於有大量高品質的預訓練資料，因此英語方面進展最大。然而，對於大多數其他語言而言，這類高品質的預訓練資料並不可用。在這項工作中，我們研究如何透過徵用資料品質良好的輔助語言資料，來提升資料受限目標語言的預訓練模型效能。我們透過量化使用資料豐富的輔助語言訓練與在目標語言中訓練的效能差距、探討翻譯系統的優點、研究資料受限語言的模型擴充限制，以及提出從輔助語言中對資料進行上採樣的全新方法來研究這一點。我們的結果顯示，對於相近語言，更強大的輔助資料集會帶來效能提升，且無需修改模型或訓練目標；特別是，由於開發出更多資訊豐富的英語預訓練資料集，效能提升可以延伸至資料有限的目標語言設定。

##### **LaVida Drive: Vision-Text Interaction VLM for Autonomous Driving with Token Selection, Recovery and Enhancement**
2411.12980v1 by Siwen Jiao, Yangyi Fang

Recent advancements in Visual Language Models (VLMs) have made them crucial
for visual question answering (VQA) in autonomous driving, enabling natural
human-vehicle interactions. However, existing methods often struggle in dynamic
driving environments, as they usually focus on static images or videos and rely
on downsampling to manage computational costs. This results in the loss of
critical details and the difficulty in effectively integrating spatial and
temporal information, undermining fine-grained perception and temporal
coherence essential for effective decision-making. To tackle these challenges,
we introduce LaVida Drive, a novel and efficient VQA framework for autonomous
driving. LaVida Drive seamlessly integrates temporal data while maintaining
high-resolution inputs for detailed visual perception. It optimizes spatial
processing by retaining high-resolution data for intricate details and using
lower-resolution inputs for temporal analysis to focus on motion-related
features, thereby boosting computational efficiency. The core of LaVida Drive
consists of two modules: the \textit{Query-aware Token Selection} module and
the \textit{Spatial-Temporal Token Recovery and Enhancement} module. The former
dynamically selects the most relevant visual tokens based on semantic alignment
with the input query, reducing the token count from high-resolution spatial
input. The latter ensures smooth and coherent interactions between spatial and
temporal information, preserving contextual continuity across frames. Extensive
experiments on various autonomous driving question-answering benchmarks show
that LaVida Drive significantly reduces visual tokens, enhances efficiency, and
improves overall performance.

摘要：<paragraph>視覺語言模型 (VLM) 近期的進展使其成為自動駕駛中視覺問題解答 (VQA) 的關鍵，實現了自然的人車互動。然而，現有方法在動態駕駛環境中常常難以應對，因為它們通常專注於靜態影像或影片，並依賴於降採樣來管理運算成本。這導致關鍵細節的遺失，以及難以有效整合空間和時間資訊，進而損害了對有效決策制定至關重要的細緻感知和時間連貫性。為了應對這些挑戰，我們引入了 LaVida Drive，一個用於自動駕駛的新穎且高效的 VQA 框架。LaVida Drive 無縫整合時間資料，同時維持高解析度輸入以進行詳細的視覺感知。它透過保留高解析度資料以獲取複雜細節，並使用低解析度輸入進行時間分析以專注於與動作相關的特徵，從而最佳化空間處理，進而提升運算效率。LaVida Drive 的核心包含兩個模組：\textit{查詢感知代幣選擇} 模組和 \textit{時空代幣復原及強化} 模組。前者根據與輸入查詢的語義對齊動態選擇最相關的視覺代幣，從高解析度空間輸入中減少代幣數量。後者確保時空資訊之間的互動順暢且連貫，在各個影格中保留上下文連續性。在各種自動駕駛問題解答基準上的廣泛實驗顯示，LaVida Drive 大幅減少了視覺代幣，提升了效率，並改善了整體效能。</paragraph>

##### **MindForge: Empowering Embodied Agents with Theory of Mind for Lifelong Collaborative Learning**
2411.12977v1 by Mircea Lică, Ojas Shirekar, Baptiste Colle, Chirag Raman

Contemporary embodied agents, such as Voyager in Minecraft, have demonstrated
promising capabilities in open-ended individual learning. However, when powered
with open large language models (LLMs), these agents often struggle with
rudimentary tasks, even when fine-tuned on domain-specific knowledge. Inspired
by human cultural learning, we present \collabvoyager, a novel framework that
enhances Voyager with lifelong collaborative learning through explicit
perspective-taking. \collabvoyager introduces three key innovations: (1) theory
of mind representations linking percepts, beliefs, desires, and actions; (2)
natural language communication between agents; and (3) semantic memory of task
and environment knowledge and episodic memory of collaboration episodes. These
advancements enable agents to reason about their and others' mental states,
empirically addressing two prevalent failure modes: false beliefs and faulty
task executions. In mixed-expertise Minecraft experiments, \collabvoyager
agents outperform Voyager counterparts, significantly improving task completion
rate by $66.6\% (+39.4\%)$ for collecting one block of dirt and $70.8\%
(+20.8\%)$ for collecting one wood block. They exhibit emergent behaviors like
knowledge transfer from expert to novice agents and collaborative code
correction. \collabvoyager agents also demonstrate the ability to adapt to
out-of-distribution tasks by using their previous experiences and beliefs
obtained through collaboration. In this open-ended social learning paradigm,
\collabvoyager paves the way for the democratic development of embodied AI,
where agents learn in deployment from both peer and environmental feedback.

摘要：<paragraph>例如 Minecraft 中的 Voyager 等當代具身代理已在開放式個別學習中展示出有希望的能力。然而，當使用開放式大型語言模型 (LLM) 時，這些代理經常難以應付基本任務，即使在特定領域知識上進行微調也是如此。受人類文化學習的啟發，我們提出了 \collabvoyager，這是一個新穎的框架，它通過明確的觀點採取增強了 Voyager 的終身協作學習。\collabvoyager 引入了三項關鍵創新：(1) 將知覺、信念、慾望和行動聯繫起來的心智表徵理論；(2) 代理之間的自然語言溝通；以及 (3) 任務和環境知識的語義記憶和協作事件的偶發記憶。這些進步使代理能夠推理他們自己和他人的心智狀態，從經驗上解決兩種普遍的失敗模式：錯誤的信念和有缺陷的任務執行。在混合專業知識的 Minecraft 實驗中，\collabvoyager 代理優於 Voyager 對應代理，顯著提高了任務完成率，收集一塊泥土提高了 66.6%（+39.4%），收集一塊木頭提高了 70.8%（+20.8%）。他們表現出新興行為，例如從專家代理向新手代理傳遞知識和協作代碼更正。\collabvoyager 代理還展示了通過協作獲得的先前經驗和信念適應分佈外任務的能力。在這種開放式的社會學習範式中，\collabvoyager 為具身 AI 的民主發展鋪平了道路，代理從同行和環境反饋中學習部署。</paragraph>

##### **Shrinking POMCP: A Framework for Real-Time UAV Search and Rescue**
2411.12967v1 by Yunuo Zhang, Baiting Luo, Ayan Mukhopadhyay, Daniel Stojcsics, Daniel Elenius, Anirban Roy, Susmit Jha, Miklos Maroti, Xenofon Koutsoukos, Gabor Karsai, Abhishek Dubey

Efficient path optimization for drones in search and rescue operations faces
challenges, including limited visibility, time constraints, and complex
information gathering in urban environments. We present a comprehensive
approach to optimize UAV-based search and rescue operations in neighborhood
areas, utilizing both a 3D AirSim-ROS2 simulator and a 2D simulator. The path
planning problem is formulated as a partially observable Markov decision
process (POMDP), and we propose a novel ``Shrinking POMCP'' approach to address
time constraints. In the AirSim environment, we integrate our approach with a
probabilistic world model for belief maintenance and a neurosymbolic navigator
for obstacle avoidance. The 2D simulator employs surrogate ROS2 nodes with
equivalent functionality. We compare trajectories generated by different
approaches in the 2D simulator and evaluate performance across various belief
types in the 3D AirSim-ROS simulator. Experimental results from both simulators
demonstrate that our proposed shrinking POMCP solution achieves significant
improvements in search times compared to alternative methods, showcasing its
potential for enhancing the efficiency of UAV-assisted search and rescue
operations.

摘要：在搜救行动中，无人机的路径优化面临着许多挑战，包括能见度有限、时间限制，以及在城市环境中收集复杂的信息。我们提出了一种综合方法来优化基于无人机的搜救行动，利用 3D AirSim-ROS2 模拟器和 2D 模拟器。路径规划问题被表述为部分可观测马尔可夫决策过程 (POMDP)，我们提出了一种新颖的 ``Shrinking POMCP'' 方法来解决时间限制问题。在 AirSim 环境中，我们将我们的方法与概率世界模型相结合，用于信念维护，并将神经符号导航器用于避障。2D 模拟器采用具有同等功能的替代 ROS2 节点。我们在 2D 模拟器中比较了不同方法生成的轨迹，并在 3D AirSim-ROS 模拟器中评估了不同信念类型的性能。来自两个模拟器的实验结果表明，与其他方法相比，我们提出的 Shrinking POMCP 解决方案在搜索时间方面取得了显著的改进，展示了其提高无人机辅助搜救行动效率的潜力。

##### **Real-Time Energy-Optimal Path Planning for Electric Vehicles**
2411.12964v1 by Saman Ahmadi, Guido Tack, Daniel Harabor, Philip Kilby, Mahdi Jalili

The rapid adoption of electric vehicles (EVs) in modern transport systems has
made energy-aware routing a critical task in their successful integration,
especially within large-scale networks. In cases where an EV's remaining energy
is limited and charging locations are not easily accessible, some destinations
may only be reachable through an energy-optimal path: a route that consumes
less energy than all other alternatives. The feasibility of such
energy-efficient paths depends heavily on the accuracy of the energy model used
for planning, and thus failing to account for vehicle dynamics can lead to
inaccurate energy estimates, rendering some planned routes infeasible in
reality. This paper explores the impact of vehicle dynamics on energy-optimal
path planning for EVs. We develop an accurate energy model that incorporates
key vehicle dynamics parameters into energy calculations, thereby reducing the
risk of planning infeasible paths under battery constraints. The paper also
introduces two novel online reweighting functions that allow for a faster,
pre-processing free, pathfinding in the presence of negative energy costs
resulting from regenerative braking, making them ideal for real-time
applications. Through extensive experimentation on real-world transport
networks, we demonstrate that our approach considerably enhances energy-optimal
pathfinding for EVs in both computational efficiency and energy estimation
accuracy.

摘要：電動車 (EV) 在現代交通系統中快速普及，使得能源感知路由成為其成功整合中的一項關鍵任務，特別是在大規模網路中。在電動車剩餘能量有限且充電地點不易取得的情況下，有些目的地可能只能透過能源最佳化路徑到達：一條消耗能量低於所有其他替代方案的路線。此類節能路徑的可行性高度依賴於規劃中所使用的能源模型的準確性，因此未能考量車輛動態可能會導致不準確的能源估計，使一些規劃好的路線在現實中不可行。本文探討車輛動態對電動車能源最佳化路徑規劃的影響。我們開發了一個準確的能源模型，將關鍵車輛動態參數納入能源計算中，從而降低在電池限制下規劃不可行路徑的風險。本文還介紹了兩個新穎的線上重新加權函數，允許在再生制動產生的負能量成本下進行更快速的、無需預處理的路徑尋找，使其成為實時應用中的理想選擇。透過在真實世界交通網路中進行廣泛的實驗，我們證明了我們的策略在計算效率和能源估計準確性方面都大幅提升了電動車的能源最佳化路徑尋找。

##### **KAAE: Numerical Reasoning for Knowledge Graphs via Knowledge-aware Attributes Learning**
2411.12950v1 by Ming Yin, Qiang Zhou, Zongsheng Cao, Mei Li

Numerical reasoning is pivotal in various artificial intelligence
applications, such as natural language processing and recommender systems,
where it involves using entities, relations, and attribute values (e.g.,
weight, length) to infer new factual relations (e.g., the Nile is longer than
the Amazon). However, existing approaches encounter two critical challenges in
modeling: (1) semantic relevance-the challenge of insufficiently capturing the
necessary contextual interactions among entities, relations, and numerical
attributes, often resulting in suboptimal inference; and (2) semantic
ambiguity-the difficulty in accurately distinguishing ordinal relationships
during numerical reasoning, which compromises the generation of high-quality
samples and limits the effectiveness of contrastive learning. To address these
challenges, we propose the novel Knowledge-Aware Attributes Embedding model
(KAAE) for knowledge graph embeddings in numerical reasoning. Specifically, to
overcome the challenge of semantic relevance, we introduce a
Mixture-of-Experts-Knowledge-Aware (MoEKA) Encoder, designed to integrate the
semantics of entities, relations, and numerical attributes into a joint
semantic space. To tackle semantic ambiguity, we implement a new ordinal
knowledge contrastive learning (OKCL) strategy that generates high-quality
ordinal samples from the original data with the aid of ordinal relations,
capturing fine-grained semantic nuances essential for accurate numerical
reasoning. Experiments on three public benchmark datasets demonstrate the
superior performance of KAAE across various attribute value distributions.

摘要：數字推理在各種人工智慧應用中至關重要，例如自然語言處理和推薦系統，其中涉及使用實體、關係和屬性值（例如，重量、長度）來推斷新的事實關係（例如，尼羅河比亞馬遜河長）。然而，現有方法在建模中遇到兩個關鍵挑戰：(1) 語義相關性 - 無法充分捕捉實體、關係和數值屬性之間必要的上下文交互的挑戰，通常導致次優推論；(2) 語義模糊 - 在數字推理過程中準確區分序數關係的難度，這會損害高品質樣本的生成並限制對比學習的有效性。為了應對這些挑戰，我們提出了用於數字推理中知識圖嵌入的知識感知屬性嵌入模型 (KAAE)。具體來說，為了克服語義相關性的挑戰，我們引入了一個混合專家知識感知 (MoEKA) 編碼器，旨在將實體、關係和數值屬性的語義整合到一個聯合語義空間中。為了應對語義模糊，我們實施了一種新的序數知識對比學習 (OKCL) 策略，該策略利用序數關係從原始數據中生成高品質序數樣本，捕捉對準確數字推理至關重要的細粒度語義細微差別。在三個公共基準數據集上的實驗證明了 KAAE 在各種屬性值分佈中的卓越性能。

##### **A Flexible Large Language Models Guardrail Development Methodology Applied to Off-Topic Prompt Detection**
2411.12946v1 by Gabriel Chua, Shing Yee Chan, Shaun Khoo

Large Language Models are prone to off-topic misuse, where users may prompt
these models to perform tasks beyond their intended scope. Current guardrails,
which often rely on curated examples or custom classifiers, suffer from high
false-positive rates, limited adaptability, and the impracticality of requiring
real-world data that is not available in pre-production. In this paper, we
introduce a flexible, data-free guardrail development methodology that
addresses these challenges. By thoroughly defining the problem space
qualitatively and passing this to an LLM to generate diverse prompts, we
construct a synthetic dataset to benchmark and train off-topic guardrails that
outperform heuristic approaches. Additionally, by framing the task as
classifying whether the user prompt is relevant with respect to the system
prompt, our guardrails effectively generalize to other misuse categories,
including jailbreak and harmful prompts. Lastly, we further contribute to the
field by open-sourcing both the synthetic dataset and the off-topic guardrail
models, providing valuable resources for developing guardrails in
pre-production environments and supporting future research and development in
LLM safety.

摘要：大型語言模型容易被濫用於非主題相關的用途，使用者可能會提示這些模型執行超出其預期範圍的工作。目前的防護措施通常依賴於策展範例或自訂分類器，但存在高偽陽性率、適應性有限，以及需要實際資料的非實用性等問題，而這些資料在生產前並不可用。在本文中，我們介紹了一種靈活、無資料的防護措施開發方法，可解決這些挑戰。透過徹底定義問題空間並將其傳遞給 LLM 以產生多樣化的提示，我們建構了一個合成資料集，用於評量和訓練非主題相關防護措施，其效能優於啟發式方法。此外，透過將任務設定為分類使用者提示是否與系統提示相關，我們的防護措施可有效地概括到其他濫用類別，包括越獄和有害提示。最後，我們進一步透過開放原始碼合成資料集和非主題相關防護措施模型來為此領域做出貢獻，為在生產前環境中開發防護措施以及支援 LLM 安全性的未來研究和開發提供有價值的資源。

##### **Loss-to-Loss Prediction: Scaling Laws for All Datasets**
2411.12925v1 by David Brandfonbrener, Nikhil Anand, Nikhil Vyas, Eran Malach, Sham Kakade

While scaling laws provide a reliable methodology for predicting train loss
across compute scales for a single data distribution, less is known about how
these predictions should change as we change the distribution. In this paper,
we derive a strategy for predicting one loss from another and apply it to
predict across different pre-training datasets and from pre-training data to
downstream task data. Our predictions extrapolate well even at 20x the largest
FLOP budget used to fit the curves. More precisely, we find that there are
simple shifted power law relationships between (1) the train losses of two
models trained on two separate datasets when the models are paired by training
compute (train-to-train), (2) the train loss and the test loss on any
downstream distribution for a single model (train-to-test), and (3) the test
losses of two models trained on two separate train datasets (test-to-test). The
results hold up for pre-training datasets that differ substantially (some are
entirely code and others have no code at all) and across a variety of
downstream tasks. Finally, we find that in some settings these shifted power
law relationships can yield more accurate predictions than extrapolating
single-dataset scaling laws.

摘要：雖然規模定律提供了一個可靠的方法來預測單一資料分佈中，跨運算規模的訓練損失，但對於這些預測在我們改變分佈時應如何改變，我們所知甚少。在本文中，我們推導出從一個損失預測另一個損失的策略，並將其應用於預測不同的預訓練資料集，以及從預訓練資料到下游任務資料。即使在用於擬合曲線的最大 FLOP 預算的 20 倍下，我們的預測也能很好地外推。更精確地說，我們發現（1）在兩個模型在訓練運算（訓練到訓練）中配對時，在兩個單獨資料集上訓練的兩個模型的訓練損失之間存在簡單的移位冪律關係，（2）單一模型在任何下游分佈上的訓練損失和測試損失（訓練到測試），以及（3）在兩個單獨訓練資料集上訓練的兩個模型的測試損失（測試到測試）。結果適用於差異很大的預訓練資料集（有些完全是程式碼，而有些根本沒有程式碼），以及各種下游任務。最後，我們發現，在某些設定中，這些移位冪律關係可以產生比外推單一資料集規模定律更準確的預測。

##### **Human-In-the-Loop Software Development Agents**
2411.12924v1 by Wannita Takerngsaksiri, Jirat Pasuksmit, Patanamon Thongtanunam, Chakkrit Tantithamthavorn, Ruixiong Zhang, Fan Jiang, Jing Li, Evan Cook, Kun Chen, Ming Wu

Recently, Large Language Models (LLMs)-based multi-agent paradigms for
software engineering are introduced to automatically resolve software
development tasks (e.g., from a given issue to source code). However, existing
work is evaluated based on historical benchmark datasets, does not consider
human feedback at each stage of the automated software development process, and
has not been deployed in practice. In this paper, we introduce a
Human-in-the-loop LLM-based Agents framework (HULA) for software development
that allows software engineers to refine and guide LLMs when generating coding
plans and source code for a given task. We design, implement, and deploy the
HULA framework into Atlassian JIRA for internal uses. Through a multi-stage
evaluation of the HULA framework, Atlassian software engineers perceive that
HULA can minimize the overall development time and effort, especially in
initiating a coding plan and writing code for straightforward tasks. On the
other hand, challenges around code quality are raised to be solved in some
cases. We draw lessons learned and discuss opportunities for future work, which
will pave the way for the advancement of LLM-based agents in software
development.

摘要：最近，引入了基于大语言模型 (LLM) 的软件工程多主体范例，以自动解决软件开发任务（例如，从给定的问题到源代码）。然而，现有工作是根据历史基准数据集进行评估的，没有考虑在自动化软件开发过程的每个阶段的人工反馈，并且尚未在实践中部署。在本文中，我们介绍了一个基于 LLM 的人类参与循环代理框架 (HULA)，用于软件开发，该框架允许软件工程师在为给定任务生成编码计划和源代码时优化和指导 LLM。我们设计、实现并将 HULA 框架部署到 Atlassian JIRA 以供内部使用。通过对 HULA 框架的多阶段评估，Atlassian 软件工程师认为 HULA 可以最大程度地减少整体开发时间和精力，尤其是在启动编码计划和为直接任务编写代码时。另一方面，在某些情况下提出了需要解决的有关代码质量的挑战。我们汲取经验教训并讨论未来工作的机遇，这将为基于 LLM 的代理在软件开发中的进步铺平道路。

##### **A Comparative Study of Text Retrieval Models on DaReCzech**
2411.12921v1 by Jakub Stetina, Martin Fajcik, Michal Stefanik, Michal Hradis

This article presents a comprehensive evaluation of 7 off-the-shelf document
retrieval models: Splade, Plaid, Plaid-X, SimCSE, Contriever, OpenAI ADA and
Gemma2 chosen to determine their performance on the Czech retrieval dataset
DaReCzech. The primary objective of our experiments is to estimate the quality
of modern retrieval approaches in the Czech language. Our analyses include
retrieval quality, speed, and memory footprint. Secondly, we analyze whether it
is better to use the model directly in Czech text, or to use machine
translation into English, followed by retrieval in English. Our experiments
identify the most effective option for Czech information retrieval. The
findings revealed notable performance differences among the models, with
Gemma22 achieving the highest precision and recall, while Contriever performing
poorly. Conclusively, SPLADE and PLAID models offered a balance of efficiency
and performance.

摘要：本文全面評估了 7 種現成的文件檢索模型：Splade、Plaid、Plaid-X、SimCSE、Contriever、OpenAI ADA 和 Gemma2，以確定它們在捷克檢索資料集 DaReCzech 上的效能。我們實驗的主要目標是評估捷克語中現代檢索方法的品質。我們的分析包括檢索品質、速度和記憶體使用量。其次，我們分析是直接在捷克語文中使用模型，還是先將其機器翻譯成英語，然後再用英語檢索會比較好。我們的實驗找出了捷克資訊檢索最有效的方法。結果顯示，各個模型之間的效能差異顯著，其中 Gemma22 達到了最高的精確度和召回率，而 Contriever 的表現則不佳。總之，SPADE 和 PLAID 模型在效率和效能之間取得了平衡。

##### **Enhancing Deep Learning-Driven Multi-Coil MRI Reconstruction via Self-Supervised Denoising**
2411.12919v1 by Asad Aali, Marius Arvinte, Sidharth Kumar, Yamin I. Arefeen, Jonathan I. Tamir

We examine the effect of incorporating self-supervised denoising as a
pre-processing step for training deep learning (DL) based reconstruction
methods on data corrupted by Gaussian noise. K-space data employed for training
are typically multi-coil and inherently noisy. Although DL-based reconstruction
methods trained on fully sampled data can enable high reconstruction quality,
obtaining large, noise-free datasets is impractical. We leverage Generalized
Stein's Unbiased Risk Estimate (GSURE) for denoising. We evaluate two DL-based
reconstruction methods: Diffusion Probabilistic Models (DPMs) and Model-Based
Deep Learning (MoDL). We evaluate the impact of denoising on the performance of
these DL-based methods in solving accelerated multi-coil magnetic resonance
imaging (MRI) reconstruction. The experiments were carried out on T2-weighted
brain and fat-suppressed proton-density knee scans. We observed that
self-supervised denoising enhances the quality and efficiency of MRI
reconstructions across various scenarios. Specifically, employing denoised
images rather than noisy counterparts when training DL networks results in
lower normalized root mean squared error (NRMSE), higher structural similarity
index measure (SSIM) and peak signal-to-noise ratio (PSNR) across different SNR
levels, including 32dB, 22dB, and 12dB for T2-weighted brain data, and 24dB,
14dB, and 4dB for fat-suppressed knee data. Overall, we showed that denoising
is an essential pre-processing technique capable of improving the efficacy of
DL-based MRI reconstruction methods under diverse conditions. By refining the
quality of input data, denoising can enable the training of more effective DL
networks, potentially bypassing the need for noise-free reference MRI scans.

摘要：<paragraph>我們探討了將自監督去噪作為預處理步驟，用於訓練基於深度學習 (DL) 的重建方法，以針對受高斯雜訊損壞的資料進行重建。用於訓練的 k 空間資料通常是多線圈且本質上具有雜訊。儘管在完整採樣資料上訓練的基於 DL 的重建方法可以實現高重建品質，但取得大型無雜訊的資料集是不切實際的。我們利用廣義 Stein 無偏風險估計 (GSURE) 進行去噪。我們評估了兩種基於 DL 的重建方法：擴散機率模型 (DPM) 和基於模型的深度學習 (MoDL)。我們評估去噪對這些基於 DL 的方法在解決加速多線圈磁振造影 (MRI) 重建中的效能影響。這些實驗是在 T2 加權腦部和脂肪抑制質子密度膝部掃描上進行的。我們觀察到自監督去噪增強了 MRI 重建在各種場景中的品質和效率。具體來說，在訓練 DL 網路時採用去噪影像，而非雜訊對應影像，會導致較低的標準化均方根誤差 (NRMSE)、較高的結構相似性指標 (SSIM) 和峰值信號雜訊比 (PSNR)，涵蓋不同的 SNR 等級，包括 T2 加權腦部資料的 32dB、22dB 和 12dB，以及脂肪抑制膝部資料的 24dB、14dB 和 4dB。總體而言，我們展示了去噪是一種必要的預處理技術，能夠在各種條件下改善基於 DL 的 MRI 重建方法的效能。透過改善輸入資料的品質，去噪可以訓練出更有效的 DL 網路，潛在地繞過對無雜訊參考 MRI 掃描的需求。</paragraph>

##### **MLDGG: Meta-Learning for Domain Generalization on Graphs**
2411.12913v1 by Qin Tian, Chen Zhao, Minglai Shao, Wenjun Wang, Yujie Lin, Dong Li

Domain generalization on graphs aims to develop models with robust
generalization capabilities, ensuring effective performance on the testing set
despite disparities between testing and training distributions. However,
existing methods often rely on static encoders directly applied to the target
domain, constraining its flexible adaptability. In contrast to conventional
methodologies, which concentrate on developing specific generalized models, our
framework, MLDGG, endeavors to achieve adaptable generalization across diverse
domains by integrating cross-multi-domain meta-learning with structure learning
and semantic identification. Initially, it introduces a generalized structure
learner to mitigate the adverse effects of task-unrelated edges, enhancing the
comprehensiveness of representations learned by Graph Neural Networks (GNNs)
while capturing shared structural information across domains. Subsequently, a
representation learner is designed to disentangle domain-invariant semantic and
domain-specific variation information in node embedding by leveraging causal
reasoning for semantic identification, further enhancing generalization. In the
context of meta-learning, meta-parameters for both learners are optimized to
facilitate knowledge transfer and enable effective adaptation to graphs through
fine-tuning within the target domains, where target graphs are inaccessible
during training. Our empirical results demonstrate that MLDGG surpasses
baseline methods, showcasing its effectiveness in three different distribution
shift settings.

摘要：圖形上的網域泛化旨在開發具有穩健泛化能力的模型，確保在測試集上具有有效效能，儘管測試和訓練分佈之間存在差異。然而，現有方法通常依賴於直接應用於目標網域的靜態編碼器，限制了其靈活的適應性。與專注於開發特定泛化模型的傳統方法相反，我們的框架 MLDGG 致力於透過將跨多網域元學習與結構學習和語義識別整合，在不同的網域中實現適應性泛化。最初，它引入了一個廣義結構學習器來減輕與任務無關的邊緣的不利影響，增強圖神經網路 (GNN) 學習到的表示的全面性，同時擷取跨網域的共用結構資訊。隨後，設計了一個表示學習器，透過利用因果推理進行語義識別，在節點嵌入中解開與網域無關的語義和與網域相關的變異資訊，進一步增強泛化。在元學習的背景下，優化兩個學習器的元參數，以促進知識轉移，並透過在目標網域內進行微調，讓圖形能夠有效適應，其中目標圖形在訓練期間無法取得。我們的實證結果證明，MLDGG 優於基準方法，展示了其在三種不同的分佈轉移設定中的有效性。

##### **Signformer is all you need: Towards Edge AI for Sign Language**
2411.12901v1 by Eta Yang

Sign language translation, especially in gloss-free paradigm, is confronting
a dilemma of impracticality and unsustainability due to growing
resource-intensive methodologies. Contemporary state-of-the-arts (SOTAs) have
significantly hinged on pretrained sophiscated backbones such as Large Language
Models (LLMs), embedding sources, or extensive datasets, inducing considerable
parametric and computational inefficiency for sustainable use in real-world
scenario. Despite their success, following this research direction undermines
the overarching mission of this domain to create substantial value to bridge
hard-hearing and common populations. Committing to the prevailing trend of LLM
and Natural Language Processing (NLP) studies, we pursue a profound essential
change in architecture to achieve ground-up improvements without external aid
from pretrained models, prior knowledge transfer, or any NLP strategies
considered not-from-scratch.
  Introducing Signformer, a from-scratch Feather-Giant transforming the area
towards Edge AI that redefines extremities of performance and efficiency with
LLM-competence and edgy-deployable compactness. In this paper, we present
nature analysis of sign languages to inform our algorithmic design and deliver
a scalable transformer pipeline with convolution and attention novelty. We
achieve new 2nd place on leaderboard with a parametric reduction of 467-1807x
against the finests as of 2024 and outcompete almost every other methods in a
lighter configuration of 0.57 million parameters.

摘要：手語翻譯，特別是在無光澤範例中，由於資源密集型方法不斷增加，面臨著不切實際和不可持續的困境。當代最先進的技術（SOTA）在很大程度上依賴於預訓練的複雜主幹，例如大型語言模型（LLM）、嵌入式來源或廣泛的數據集，從而導致在現實世界場景中可持續使用時，參數和計算效率顯著降低。儘管取得了成功，但遵循這個研究方向會破壞這個領域的總體使命，即創造實質性的價值來橋接聽力障礙者和普通人群。致力於 LLM 和自然語言處理 (NLP) 研究的盛行趨勢，我們追求架構的深刻本質變化，以在沒有預訓練模型、先驗知識轉移或任何非從頭開始的 NLP 策略的外部幫助下實現從頭開始的改進。推出 Signformer，一個從頭開始的 Feather-Giant，將該領域轉變為 Edge AI，重新定義了性能和效率的極端性，具有 LLM 能力和前沿可部署的緊湊性。在本文中，我們展示了手語的自然分析，以告知我們的演算法設計，並提供具有卷積和注意力新穎性的可擴充Transformer管道。我們在排行榜上獲得了新的第二名，與 2024 年的最佳相比，參數減少了 467-1807 倍，並且在 0.57 萬個參數的較輕配置中勝過幾乎所有其他方法。

##### **Selective Attention: Enhancing Transformer through Principled Context Control**
2411.12892v1 by Xuechen Zhang, Xiangyu Chang, Mingchen Li, Amit Roy-Chowdhury, Jiasi Chen, Samet Oymak

The attention mechanism within the transformer architecture enables the model
to weigh and combine tokens based on their relevance to the query. While
self-attention has enjoyed major success, it notably treats all queries $q$ in
the same way by applying the mapping $V^\top\text{softmax}(Kq)$, where $V,K$
are the value and key embeddings respectively. In this work, we argue that this
uniform treatment hinders the ability to control contextual sparsity and
relevance. As a solution, we introduce the $\textit{Selective Self-Attention}$
(SSA) layer that augments the softmax nonlinearity with a principled
temperature scaling strategy. By controlling temperature, SSA adapts the
contextual sparsity of the attention map to the query embedding and its
position in the context window. Through theory and experiments, we demonstrate
that this alleviates attention dilution, aids the optimization process, and
enhances the model's ability to control softmax spikiness of individual
queries. We also incorporate temperature scaling for value embeddings and show
that it boosts the model's ability to suppress irrelevant/noisy tokens.
Notably, SSA is a lightweight method which introduces less than 0.5% new
parameters through a weight-sharing strategy and can be fine-tuned on existing
LLMs. Extensive empirical evaluations demonstrate that SSA-equipped models
achieve a noticeable and consistent accuracy improvement on language modeling
benchmarks.

摘要：Transformer架構中的注意力機制使模型能夠根據代幣與查詢的相關性來加權並組合代幣。雖然自我注意力已經取得了重大的成功，但它明顯地對所有查詢 $q$ 採用相同的方式，通過應用映射 $V^\top\text{softmax}(Kq)$，其中 $V,K$ 分別是值嵌入和鍵嵌入。在這項工作中，我們認為這種統一的處理阻礙了控制上下文稀疏性和相關性的能力。作為解決方案，我們引入了 $\textit{選擇性自我注意力}$ (SSA) 層，該層用一個基於原則的溫度縮放策略來擴充 softmax 非線性。通過控制溫度，SSA 將注意力圖的上下文稀疏性適應查詢嵌入及其在上下文窗口中的位置。通過理論和實驗，我們證明了這減輕了注意力的稀釋，幫助了優化過程，並增強了模型控制單個查詢的 softmax 尖峰的能力。我們還將溫度縮放整合到值嵌入中，並表明它提升了模型抑制無關/噪聲代幣的能力。值得注意的是，SSA 是一種輕量級的方法，通過權重共享策略引入了不到 0.5% 的新參數，並且可以在現有的 LLM 上進行微調。廣泛的實證評估表明，配備了 SSA 的模型在語言建模基準上取得了顯著且一致的準確性提升。

##### **ProSec: Fortifying Code LLMs with Proactive Security Alignment**
2411.12882v1 by Xiangzhe Xu, Zian Su, Jinyao Guo, Kaiyuan Zhang, Zhenting Wang, Xiangyu Zhang

Recent advances in code-specific large language models (LLMs) have greatly
enhanced code generation and refinement capabilities. However, the safety of
code LLMs remains under-explored, posing potential risks as insecure code
generated by these models may introduce vulnerabilities into real-world
systems. Previous work proposes to collect security-focused instruction-tuning
dataset from real-world vulnerabilities. It is constrained by the data sparsity
of vulnerable code, and has limited applicability in the iterative
post-training workflows of modern LLMs. In this paper, we propose ProSec, a
novel proactive security alignment approach designed to align code LLMs with
secure coding practices. ProSec systematically exposes the vulnerabilities in a
code LLM by synthesizing error-inducing coding scenarios from Common Weakness
Enumerations (CWEs), and generates fixes to vulnerable code snippets, allowing
the model to learn secure practices through advanced preference learning
objectives. The scenarios synthesized by ProSec triggers 25 times more
vulnerable code than a normal instruction-tuning dataset, resulting in a
security-focused alignment dataset 7 times larger than the previous work.
Experiments show that models trained with ProSec is 29.2% to 35.5% more secure
compared to previous work, with a marginal negative effect of less than 2
percentage points on model's utility.

摘要：<paragraph>最近在特定代码大型语言模型 (LLM) 方面的进展极大地增强了代码生成和优化能力。然而，代码 LLM 的安全性仍未得到充分探索，因为这些模型生成的非安全代码可能会给现实世界的系统引入漏洞，从而带来潜在风险。以前的工作建议从现实世界的漏洞中收集以安全性为重点的指令微调数据集。它受到易受攻击代码数据稀疏性的限制，并且在现代 LLM 的迭代后训练工作流中的适用性有限。在本文中，我们提出了 ProSec，这是一种新颖的主动安全对齐方法，旨在将代码 LLM 与安全编码实践相一致。ProSec 通过从通用弱点枚举 (CWE) 中合成诱发错误的编码场景，系统地揭示了代码 LLM 中的漏洞，并生成易受攻击的代码片段的修复程序，从而使模型能够通过高级偏好学习目标来学习安全实践。ProSec 合成的场景触发比普通指令微调数据集多 25 倍的易受攻击代码，从而生成的安全重点对齐数据集比以前的工作大 7 倍。实验表明，与以前的工作相比，使用 ProSec 训练的模型的安全性提高了 29.2% 至 35.5%，对模型效用的负面影响不到 2 个百分点。</paragraph>

##### **Advancing Large Language Models for Spatiotemporal and Semantic Association Mining of Similar Environmental Events**
2411.12880v1 by Yuanyuan Tian, Wenwen Li, Lei Hu, Xiao Chen, Michael Brook, Michael Brubaker, Fan Zhang, Anna K. Liljedahl

Retrieval and recommendation are two essential tasks in modern search tools.
This paper introduces a novel retrieval-reranking framework leveraging Large
Language Models (LLMs) to enhance the spatiotemporal and semantic associated
mining and recommendation of relevant unusual climate and environmental events
described in news articles and web posts. This framework uses advanced natural
language processing techniques to address the limitations of traditional manual
curation methods in terms of high labor cost and lack of scalability.
Specifically, we explore an optimized solution to employ cutting-edge embedding
models for semantically analyzing spatiotemporal events (news) and propose a
Geo-Time Re-ranking (GT-R) strategy that integrates multi-faceted criteria
including spatial proximity, temporal association, semantic similarity, and
category-instructed similarity to rank and identify similar spatiotemporal
events. We apply the proposed framework to a dataset of four thousand Local
Environmental Observer (LEO) Network events, achieving top performance in
recommending similar events among multiple cutting-edge dense retrieval models.
The search and recommendation pipeline can be applied to a wide range of
similar data search tasks dealing with geospatial and temporal data. We hope
that by linking relevant events, we can better aid the general public to gain
an enhanced understanding of climate change and its impact on different
communities.

摘要：檢索和推薦是現代搜尋工具中的兩項基本任務。
本文介紹了一個新穎的檢索重新排序架構，利用大型語言模型 (LLM) 來增強時空語義關聯的探勘，以及新聞文章和網路文章中所描述的相關異常氣候和環境事件的推薦。此架構使用進階自然語言處理技術，以解決傳統人工整理方法在高人工成本和缺乏可擴充性方面的限制。
具體來說，我們探索了一種最佳化的解決方案，採用先進的嵌入模型來語義分析時空事件 (新聞)，並提出一個地理時間重新排序 (GT-R) 策略，整合多方面的標準，包括空間接近度、時間關聯性、語義相似性，以及類別引導的相似性，以對類似的時空事件進行排序和識別。我們將所提出的架構應用於四千個地方環境觀察者 (LEO) 網路事件的資料集，在推薦類似事件方面達到了多個先進密集檢索模型中的最佳效能。搜尋和推薦管道可應用於處理時空資料的各種類似資料搜尋任務。我們希望透過連結相關事件，能更好地協助一般民眾增進對氣候變遷及其對不同社群影響的了解。

##### **The Illusion of Empathy: How AI Chatbots Shape Conversation Perception**
2411.12877v1 by Tingting Liu, Salvatore Giorgi, Ankit Aich, Allison Lahnala, Brenda Curtis, Lyle Ungar, João Sedoc

As AI chatbots become more human-like by incorporating empathy, understanding
user-centered perceptions of chatbot empathy and its impact on conversation
quality remains essential yet under-explored. This study examines how chatbot
identity and perceived empathy influence users' overall conversation
experience. Analyzing 155 conversations from two datasets, we found that while
GPT-based chatbots were rated significantly higher in conversational quality,
they were consistently perceived as less empathetic than human conversational
partners. Empathy ratings from GPT-4o annotations aligned with users' ratings,
reinforcing the perception of lower empathy in chatbots. In contrast, 3 out of
5 empathy models trained on human-human conversations detected no significant
differences in empathy language between chatbots and humans. Our findings
underscore the critical role of perceived empathy in shaping conversation
quality, revealing that achieving high-quality human-AI interactions requires
more than simply embedding empathetic language; it necessitates addressing the
nuanced ways users interpret and experience empathy in conversations with
chatbots.

摘要：隨著 AI 聊天機器人透過融入同理心變得越來越像人類，理解以使用者為中心對聊天機器人同理心的認知，以及其對對話品質的影響仍然是重要的，卻鮮少被探討。本研究探討聊天機器人身分和感知同理心如何影響使用者的整體對話體驗。我們分析來自兩個資料集的 155 場對話，發現儘管基於 GPT 的聊天機器人對話品質評分顯著較高，但他們始終被認為比人類對話夥伴同理心較低。GPT-4o 標註的同理心評分與使用者的評分一致，強化了聊天機器人同理心較低的認知。相比之下，5 個在人際對話中訓練的同理心模型中有 3 個並未偵測到聊天機器人和人類之間同理心語言的顯著差異。我們的發現強調了感知同理心在塑造對話品質中扮演關鍵角色，揭示出實現高品質的人工智慧互動不只是植入同理心語言而已；它需要解決使用者在與聊天機器人的對話中詮釋和體驗同理心的細微方式。

##### **Puppet-CNN: Input-Adaptive Convolutional Neural Networks with Model Compression using Ordinary Differential Equation**
2411.12876v1 by Yucheng Xing, Xin Wang

Convolutional Neural Network (CNN) has been applied to more and more
scenarios due to its excellent performance in many machine learning tasks,
especially with deep and complex structures. However, as the network goes
deeper, more parameters need to be stored and optimized. Besides, almost all
common CNN models adopt "train-and-use" strategy where the structure is
pre-defined and the kernel parameters are fixed after the training with the
same structure and set of parameters used for all data without considering the
content complexity. In this paper, we propose a new CNN framework, named as
$\textit{Puppet-CNN}$, which contains two modules: a $\textit{puppet module}$
and a $\textit{puppeteer module}$. The puppet module is a CNN model used to
actually process the input data just like other works, but its depth and
kernels are generated by the puppeteer module (realized with Ordinary
Differential Equation (ODE)) based on the input complexity each time. By
recurrently generating kernel parameters in the puppet module, we can take
advantage of the dependence among kernels of different convolutional layers to
significantly reduce the size of CNN model by only storing and training the
parameters of the much smaller puppeteer ODE module. Through experiments on
several datasets, our method has proven to be superior than the traditional
CNNs on both performance and efficiency. The model size can be reduced more
than 10 times.

摘要：卷积神经网络 (CNN) 由于其在许多机器学习任务中表现优异，尤其是在深度和复杂结构中，已被应用于越来越多的场景。然而，随着网络的加深，需要存储和优化更多的参数。此外，几乎所有常见的 CNN 模型都采用“训练和使用”策略，其中结构是预定义的，并且在使用相同结构和参数集对所有数据进行训练后，内核参数是固定的，而没有考虑内容复杂性。在本文中，我们提出了一种新的 CNN 框架，名为$\textit{Puppet-CNN}$，它包含两个模块：$\textit{puppet 模块}$和$\textit{puppeteer 模块}$。puppet 模块是一个 CNN 模型，用于像其他工作一样实际处理输入数据，但它的深度和内核是由 puppeteer 模块（用常微分方程 (ODE) 实现）根据每次输入的复杂性生成的。通过在 puppet 模块中循环生成内核参数，我们可以利用不同卷积层的内核之间的依赖性，仅通过存储和训练更小的 puppeteer ODE 模块的参数来显着减小 CNN 模型的大小。通过在几个数据集上进行实验，我们的方法已被证明在性能和效率上都优于传统的 CNN。模型大小可以减少 10 倍以上。

##### **From Text to Pose to Image: Improving Diffusion Model Control and Quality**
2411.12872v1 by Clément Bonnett, Ariel N. Lee, Franck Wertel, Antoine Tamano, Tanguy Cizain, Pablo Ducru

In the last two years, text-to-image diffusion models have become extremely
popular. As their quality and usage increase, a major concern has been the need
for better output control. In addition to prompt engineering, one effective
method to improve the controllability of diffusion models has been to condition
them on additional modalities such as image style, depth map, or keypoints.
This forms the basis of ControlNets or Adapters. When attempting to apply these
methods to control human poses in outputs of text-to-image diffusion models,
two main challenges have arisen. The first challenge is generating poses
following a wide range of semantic text descriptions, for which previous
methods involved searching for a pose within a dataset of (caption, pose)
pairs. The second challenge is conditioning image generation on a specified
pose while keeping both high aesthetic and high pose fidelity. In this article,
we fix these two main issues by introducing a text-to-pose (T2P) generative
model alongside a new sampling algorithm, and a new pose adapter that
incorporates more pose keypoints for higher pose fidelity. Together, these two
new state-of-the-art models enable, for the first time, a generative
text-to-pose-to-image framework for higher pose control in diffusion models. We
release all models and the code used for the experiments at
https://github.com/clement-bonnet/text-to-pose.

摘要：在過去兩年，文字轉圖像擴散模型變得極為
流行。隨著其品質和使用率的提升，一個主要的問題在於需要
更好的輸出控制。除了提示工程，一個有效的方法來改善擴散模型
的可控性，是將其建立在額外的模態上，例如影像風格、深度圖或
關鍵點。這形成 ControlNets 或 Adapters 的基礎。當嘗試將這些
方法應用於控制文字轉圖像擴散模型輸出的姿勢時，出現了兩個
主要的挑戰。第一個挑戰是產生符合各種語義文字描述的姿勢，
以前的作法是從（標題、姿勢）配對的資料集中搜尋姿勢。第二個
挑戰是在保持高美感和高姿勢保真度的同時，對指定的姿勢進行影像
生成的條件化。在本文中，我們透過引入文字轉姿勢 (T2P) 生成
模型，以及新的取樣演算法，和新的姿勢適配器（結合更多姿勢關鍵
點以獲得更高的姿勢保真度）來解決這兩個主要問題。這兩個新的
最先進模型共同實現了生成文字轉姿勢轉圖像架構，以在擴散模型中
獲得更高的姿勢控制。我們在 https://github.com/clement-bonnet/text-to-pose
釋出所有模型和用於實驗的程式碼。

##### **AzSLD: Azerbaijani Sign Language Dataset for Fingerspelling, Word, and Sentence Translation with Baseline Software**
2411.12865v1 by Nigar Alishzade, Jamaladdin Hasanov

Sign language processing technology development relies on extensive and
reliable datasets, instructions, and ethical guidelines. We present a
comprehensive Azerbaijani Sign Language Dataset (AzSLD) collected from diverse
sign language users and linguistic parameters to facilitate advancements in
sign recognition and translation systems and support the local sign language
community. The dataset was created within the framework of a vision-based AzSL
translation project. This study introduces the dataset as a summary of the
fingerspelling alphabet and sentence- and word-level sign language datasets.
The dataset was collected from signers of different ages, genders, and signing
styles, with videos recorded from two camera angles to capture each sign in
full detail. This approach ensures robust training and evaluation of gesture
recognition models. AzSLD contains 30,000 videos, each carefully annotated with
accurate sign labels and corresponding linguistic translations. The dataset is
accompanied by technical documentation and source code to facilitate its use in
training and testing. This dataset offers a valuable resource of labeled data
for researchers and developers working on sign language recognition,
translation, or synthesis. Ethical guidelines were strictly followed throughout
the project, with all participants providing informed consent for collecting,
publishing, and using the data.

摘要：手語處理技術開發依賴於廣泛且可靠的資料集、指令和道德準則。我們提出了一個全面的阿塞拜疆手語資料集 (AzSLD)，該資料集收集自不同的手語使用者和語言參數，以促進手勢識別和翻譯系統的進步，並支援當地的手語社群。該資料集是在基於視覺的 AzSL 翻譯專案架構中建立的。本研究將該資料集作為指法字母表和句子和單字級手語資料集的摘要進行介紹。該資料集收集自不同年齡、性別和手語風格的手語者，並從兩個攝影機角度錄製影片，以完整地捕捉每個手勢。這種方法確保了手勢識別模型的強健訓練和評估。AzSLD 包含 30,000 部影片，每部影片都仔細註解了準確的手勢標籤和對應的語言翻譯。該資料集附有技術文件和原始碼，以利於在訓練和測試中使用。該資料集為從事手語識別、翻譯或合成工作的研究人員和開發人員提供了有價值的標記資料資源。在整個專案中嚴格遵守道德準則，所有參與者都提供了收集、發布和使用資料的知情同意。

##### **Reward Modeling with Ordinal Feedback: Wisdom of the Crowd**
2411.12843v1 by Shang Liu, Yu Pan, Guanting Chen, Xiaocheng Li

Learning a reward model (RM) from human preferences has been an important
component in aligning large language models (LLMs). The canonical setup of
learning RMs from pairwise preference data is rooted in the classic
Bradley-Terry (BT) model that accepts binary feedback, i.e., the label being
either Response 1 is better than Response 2, or the opposite. Such a setup
inevitably discards potentially useful samples (such as "tied" between the two
responses) and loses more fine-grained information (such as "slightly better").
In this paper, we propose a framework for learning RMs under ordinal feedback
which generalizes the case of binary preference feedback to any arbitrary
granularity. Specifically, we first identify a marginal unbiasedness condition,
which generalizes the assumption of the BT model in the existing binary
feedback setting. The condition validates itself via the sociological concept
of the wisdom of the crowd. Under the condition, we develop a natural
probability model for pairwise preference data under ordinal feedback and
analyze its properties. We prove the statistical benefits of ordinal feedback
in terms of reducing the Rademacher complexity compared to the case of binary
feedback. The proposed learning objective and the theory also extend to hinge
loss and direct policy optimization (DPO). In particular, the theoretical
analysis may be of independent interest when applying to a seemingly unrelated
problem of knowledge distillation to interpret the bias-variance trade-off
therein. The framework also sheds light on writing guidance for human
annotators. Our numerical experiments validate that fine-grained feedback leads
to better reward learning for both in-distribution and out-of-distribution
settings. Further experiments show that incorporating a certain proportion of
samples with tied preference boosts RM learning.

摘要：<paragraph>從人類偏好中學習獎勵模型 (RM) 一直是調整大型語言模型 (LLM) 的重要組成部分。從成對偏好數據學習 RM 的典型設置植根於經典的 Bradley-Terry (BT) 模型，該模型接受二進制回饋，即標籤為回應 1 優於回應 2，或相反。這樣的設置不可避免地會丟棄潛在有用的樣本（例如兩個回應之間的「平手」）並失去更細緻的信息（例如「略好」）。在本文中，我們提出了一個在序數回饋下學習 RM 的框架，它將二進制偏好回饋的情況概括為任意粒度。具體來說，我們首先確定了一個邊際無偏條件，它概括了現有二進制回饋設置中 BT 模型的假設。該條件通過群體智慧的社會學概念驗證了自身。在這個條件下，我們為序數回饋下的成對偏好數據開發了一個自然的概率模型並分析其屬性。我們證明了序數回饋在降低 Rademacher 複雜性方面的統計優勢，與二進制回饋的情況相比。所提出的學習目標和理論也延伸到鉸鏈損失和直接策略優化 (DPO)。特別是，理論分析在應用於知識蒸餾的看似無關的問題時可能是獨立感興趣的，以解釋其中的偏差 - 方差權衡。該框架也為人類註解者的寫作指導提供了啟示。我們的數字實驗驗證了細粒度回饋導致了分佈內和分佈外設置的更好的獎勵學習。進一步的實驗表明，加入一定比例的具有平手偏好的樣本會提升 RM 學習。</paragraph>

##### **Efficient Medicinal Image Transmission and Resolution Enhancement via GAN**
2411.12833v1 by Rishabh Kumar Sharma, Mukund Sharma, Pushkar Sharma, Jeetashree Aparjeeta

While X-ray imaging is indispensable in medical diagnostics, it inherently
carries with it those noises and limitations on resolution that mask the
details necessary for diagnosis. B/W X-ray images require a careful balance
between noise suppression and high-detail preservation to ensure clarity in
soft-tissue structures and bone edges. While traditional methods, such as CNNs
and early super-resolution models like ESRGAN, have enhanced image resolution,
they often perform poorly regarding high-frequency detail preservation and
noise control for B/W imaging. We are going to present one efficient approach
that improves the quality of an image with the optimization of network
transmission in the following paper. The pre-processing of X-ray images into
low-resolution files by Real-ESRGAN, a version of ESRGAN elucidated and
improved, helps reduce the server load and transmission bandwidth.
Lower-resolution images are upscaled at the receiving end using Real-ESRGAN,
fine-tuned for real-world image degradation. The model integrates
Residual-in-Residual Dense Blocks with perceptual and adversarial loss
functions for high-quality upscaled images with low noise. We further fine-tune
Real-ESRGAN by adapting it to the specific B/W noise and contrast
characteristics. This suppresses noise artifacts without compromising detail.
The comparative evaluation conducted shows that our approach achieves superior
noise reduction and detail clarity compared to state-of-the-art CNN-based and
ESRGAN models, apart from reducing network bandwidth requirements. These
benefits are confirmed both by quantitative metrics, including Peak
Signal-to-Noise Ratio and Structural Similarity Index, and by qualitative
assessments, which indicate the potential of Real-ESRGAN for diagnostic-quality
X-ray imaging and for efficient medical data transmission.

摘要：儘管 X 光影像在醫療診斷中不可或缺，但它本身就帶有那些會遮蔽診斷所需細節的雜訊和解析度限制。黑白 X 光影像需要在雜訊抑制和高細節保留之間取得仔細的平衡，以確保軟組織結構和骨骼邊緣的清晰度。儘管 CNN 和 ESRGAN 等傳統方法和早期超解析度模型已增強影像解析度，但它們在高頻率細節保留和黑白影像的雜訊控制方面通常表現不佳。我們將在以下論文中提出一種有效的方法，該方法透過最佳化網路傳輸來提升影像品質。將 X 光影像預處理成低解析度檔案，透過經過闡明和改良的 ESRGAN 版本 Real-ESRGAN，有助於降低伺服器負載和傳輸頻寬。低解析度影像在接收端使用針對真實世界影像劣化進行微調的 Real-ESRGAN 升級。該模型整合了殘差中殘差密集區塊與感知和對抗損失函數，以產生雜訊低的高品質升級影像。我們進一步微調 Real-ESRGAN，使其適應特定黑白雜訊和對比特徵。這抑制了雜訊偽影，同時不影響細節。進行的比較評估顯示，除了降低網路頻寬需求外，我們的做法在雜訊降低和細節清晰度方面都優於最先進的基於 CNN 和 ESRGAN 的模型。這些優點已透過定量指標（包括峰值信噪比和結構相似性指標）和定性評估得到證實，這表明 Real-ESRGAN 具有診斷品質 X 光影像和有效醫療資料傳輸的潛力。

##### **Human-Robot Dialogue Annotation for Multi-Modal Common Ground**
2411.12829v1 by Claire Bonial, Stephanie M. Lukin, Mitchell Abrams, Anthony Baker, Lucia Donatelli, Ashley Foots, Cory J. Hayes, Cassidy Henry, Taylor Hudson, Matthew Marge, Kimberly A. Pollard, Ron Artstein, David Traum, Clare R. Voss

In this paper, we describe the development of symbolic representations
annotated on human-robot dialogue data to make dimensions of meaning accessible
to autonomous systems participating in collaborative, natural language
dialogue, and to enable common ground with human partners. A particular
challenge for establishing common ground arises in remote dialogue (occurring
in disaster relief or search-and-rescue tasks), where a human and robot are
engaged in a joint navigation and exploration task of an unfamiliar
environment, but where the robot cannot immediately share high quality visual
information due to limited communication constraints. Engaging in a dialogue
provides an effective way to communicate, while on-demand or lower-quality
visual information can be supplemented for establishing common ground. Within
this paradigm, we capture propositional semantics and the illocutionary force
of a single utterance within the dialogue through our Dialogue-AMR annotation,
an augmentation of Abstract Meaning Representation. We then capture patterns in
how different utterances within and across speaker floors relate to one another
in our development of a multi-floor Dialogue Structure annotation schema.
Finally, we begin to annotate and analyze the ways in which the visual
modalities provide contextual information to the dialogue for overcoming
disparities in the collaborators' understanding of the environment. We conclude
by discussing the use-cases, architectures, and systems we have implemented
from our annotations that enable physical robots to autonomously engage with
humans in bi-directional dialogue and navigation.

摘要：<paragraph>在本文中，我們描述了在人機對話資料上註解的符號表徵的開發，以使自主系統參與協作、自然語言對話中可存取的意義向度，並與人類夥伴建立共同基礎。在建立共同基礎時，一個特別的挑戰出現在遠端對話（發生在救災或搜救任務中），在這種情況下，人類和機器人參與了一個不熟悉的環境的聯合導航和探索任務，但由於有限的通信約束，機器人無法立即共享高品質的視覺資訊。參與對話提供了一種有效的溝通方式，而按需或低品質的視覺資訊可以補充以建立共同基礎。在此範例中，我們透過我們的對話 AMR 註解（抽象意義表徵的擴充）擷取命題語義和對話中單一話語的言行力量。然後，我們在我們的多層對話結構註解模式開發中，擷取不同話語在發言者層級內部和之間如何相互關聯的模式。最後，我們開始註解和分析視覺模式為對話提供背景資訊的方式，以克服合作者對環境理解的差異。我們最後討論了我們從註解中實作的使用案例、架構和系統，這些註解使物理機器人能夠與人類進行雙向對話和導航。</paragraph>

##### **Probing the Capacity of Language Model Agents to Operationalize Disparate Experiential Context Despite Distraction**
2411.12828v1 by Sonny George, Chris Sypherd, Dylan Cashman

Large language model (LLM) agents show promise in an increasing number of
domains. In many proposed applications, it is expected that the agent reasons
over accumulated experience presented in an input prompt. We propose the OEDD
(Operationalize Experience Despite Distraction) corpus, a
human-annotator-validated body of scenarios with pre-scripted agent histories
where the agent must make a decision based on disparate experiential
information in the presence of a distractor. We evaluate three state-of-the-art
LLMs (GPT-3.5 Turbo, GPT-4o, and Gemini 1.5 Pro) using a minimal
chain-of-thought prompting strategy and observe that when (1) the input context
contains over 1,615 tokens of historical interactions, (2) a crucially
decision-informing premise is the rightful conclusion over two disparate
environment premises, and (3) a trivial, but distracting red herring fact
follows, all LLMs perform worse than random choice at selecting the better of
two actions. Our code and test corpus are publicly available at:
https://github.com/sonnygeorge/OEDD .

摘要：大型語言模型 (LLM) 代理在越來越多的領域中展現出潛力。在許多提議的應用中，預計代理會根據輸入提示中呈現的累積經驗進行推理。我們提出 OEDD（儘管有干擾也能操作經驗）語料庫，這是一個由人工註解員驗證的場景主體，其中包含預先編寫的代理歷史記錄，代理必須根據分散的體驗資訊在干擾因素存在的情況下做出決策。我們使用最小的思考鏈提示策略評估了三個最先進的 LLM（GPT-3.5 Turbo、GPT-4o 和 Gemini 1.5 Pro），並觀察到當（1）輸入內容包含超過 1,615 個歷次互動的符號，（2）一個至關重要的決策依據前提是對兩個不同的環境前提的正確結論，以及（3）一個微不足道但令人分心的錯誤線索事實緊隨其後，所有 LLM 在選擇兩個動作中較好的動作時表現都比隨機選擇差。我們的程式碼和測試語料庫可於以下網址公開取得：https://github.com/sonnygeorge/OEDD。

##### **Declare and Justify: Explicit assumptions in AI evaluations are necessary for effective regulation**
2411.12820v1 by Peter Barnett, Lisa Thiergart

As AI systems advance, AI evaluations are becoming an important pillar of
regulations for ensuring safety. We argue that such regulation should require
developers to explicitly identify and justify key underlying assumptions about
evaluations as part of their case for safety. We identify core assumptions in
AI evaluations (both for evaluating existing models and forecasting future
models), such as comprehensive threat modeling, proxy task validity, and
adequate capability elicitation. Many of these assumptions cannot currently be
well justified. If regulation is to be based on evaluations, it should require
that AI development be halted if evaluations demonstrate unacceptable danger or
if these assumptions are inadequately justified. Our presented approach aims to
enhance transparency in AI development, offering a practical path towards more
effective governance of advanced AI systems.

摘要：隨著 AI 系統的進步，AI 評估正成為確保安全的法規的重要支柱。我們主張，此類法規應要求開發人員明確說明並證明評估背後的關鍵基本假設，作為其安全論證的一部分。我們找出 AI 評估中的核心假設（用於評估現有模型和預測未來模型），例如全面的威脅建模、代理任務有效性，以及足夠的能力引導。其中許多假設目前無法得到很好的證實。如果法規要以評估為基礎，就應要求在評估證明有不可接受的危險或這些假設無法得到充分證實時，停止 AI 開發。我們提出的方法旨在提高 AI 開發的透明度，為更有效地治理先進 AI 系統提供一條實用的途徑。

##### **Conversational Medical AI: Ready for Practice**
2411.12808v1 by Antoine Lizée, Pierre-Auguste Beaucoté, James Whitbeck, Marion Doumeingts, Anaël Beaugnon, Isabelle Feldhaus

The shortage of doctors is creating a critical squeeze in access to medical
expertise. While conversational Artificial Intelligence (AI) holds promise in
addressing this problem, its safe deployment in patient-facing roles remains
largely unexplored in real-world medical settings. We present the first
large-scale evaluation of a physician-supervised LLM-based conversational agent
in a real-world medical setting.
  Our agent, Mo, was integrated into an existing medical advice chat service.
Over a three-week period, we conducted a randomized controlled experiment with
926 cases to evaluate patient experience and satisfaction. Among these, Mo
handled 298 complete patient interactions, for which we report
physician-assessed measures of safety and medical accuracy.
  Patients reported higher clarity of information (3.73 vs 3.62 out of 4, p <
0.05) and overall satisfaction (4.58 vs 4.42 out of 5, p < 0.05) with
AI-assisted conversations compared to standard care, while showing equivalent
levels of trust and perceived empathy. The high opt-in rate (81% among
respondents) exceeded previous benchmarks for AI acceptance in healthcare.
Physician oversight ensured safety, with 95% of conversations rated as "good"
or "excellent" by general practitioners experienced in operating a medical
advice chat service.
  Our findings demonstrate that carefully implemented AI medical assistants can
enhance patient experience while maintaining safety standards through physician
supervision. This work provides empirical evidence for the feasibility of AI
deployment in healthcare communication and insights into the requirements for
successful integration into existing healthcare services.

摘要：<paragraph>醫生短缺正在造成取得醫療專業知識的嚴重擠壓。儘管對話式人工智慧 (AI) 有望解決此問題，但在現實世界的醫療環境中，其在面對患者的角色中的安全部署仍未得到充分探討。我們提出在現實世界的醫療環境中，對基於 LLM 的醫師監督對話代理進行首次大規模評估。
我們的代理 Mo 已整合到現有的醫療諮詢聊天服務中。在三週的時間裡，我們進行了一項隨機對照實驗，包含 926 個案例，以評估患者體驗和滿意度。其中，Mo 處理了 298 次完整的患者互動，我們報告了醫師評估的安全性和醫療準確性指標。
與標準照護相比，患者報告了更高的資訊清晰度（4 分中的 3.73 對 3.62，p < 0.05）和整體滿意度（5 分中的 4.58 對 4.42，p < 0.05），同時顯示出同等的信任度和同理心。高選擇參與率（受訪者中為 81%）超過了醫療保健中 AI 接受度的先前基準。醫師監督確保了安全性，95% 的對話被經驗豐富的醫療諮詢聊天服務操作員評為「良好」或「極佳」。
我們的研究結果表明，仔細實施的 AI 醫療助理可以在維持醫師監督下的安全標準的同時，提升患者體驗。這項工作為 AI 部署在醫療保健溝通中的可行性提供了實證，並深入了解了成功整合到現有醫療保健服務中的要求。</paragraph>

##### **ACING: Actor-Critic for Instruction Learning in Black-Box Large Language Models**
2411.12736v1 by Salma Kharrat, Fares Fourati, Marco Canini

The effectiveness of Large Language Models (LLMs) in solving tasks vastly
depends on the quality of the instructions, which often require fine-tuning
through extensive human effort. This highlights the need for automated
instruction optimization; however, this optimization is particularly
challenging when dealing with black-box LLMs, where model parameters and
gradients remain inaccessible. We propose ACING, a task-specific prompt
optimization approach framed as a stateless continuous-action Reinforcement
Learning (RL) problem, known as the continuum bandit setting. ACING leverages
an actor-critic-based method to optimize prompts, learning from
non-differentiable reward signals. We validate ACING by optimizing prompts for
ChatGPT on 30 instruction-based tasks. ACING consistently outperforms baseline
methods, achieving a median score improvement of 10 percentage points.
Furthermore, ACING not only recovers but also surpasses human-crafted expert
instructions, achieving up to a 39 percentage point improvement against human
benchmarks.

摘要：大型語言模型 (LLM) 在解決任務方面的有效性在很大程度上取決於說明的品質，這通常需要透過大量的人力進行微調。這突顯了自動化說明最佳化的需求；然而，在處理黑箱 LLM 時，這種最佳化特別具有挑戰性，因為模型參數和梯度無法取得。我們提出 ACING，一種以無狀態連續動作強化學習 (RL) 問題（稱為連續多臂賭博機設定）為架構的任務特定提示最佳化方法。ACING 利用基於動作-評論家的方法來最佳化提示，從不可微分的獎勵訊號中學習。我們透過在 30 個基於說明的任務中最佳化 ChatGPT 的提示來驗證 ACING。ACING 持續優於基線方法，達成中位數分數提升 10 個百分點。此外，ACING 不僅恢復，還超越了人類製作的專家說明，在人類基準上取得高達 39 個百分點的提升。

##### **Benchmarking Positional Encodings for GNNs and Graph Transformers**
2411.12732v1 by Florian Grötschla, Jiaqing Xie, Roger Wattenhofer

Recent advances in Graph Neural Networks (GNNs) and Graph Transformers (GTs)
have been driven by innovations in architectures and Positional Encodings
(PEs), which are critical for augmenting node features and capturing graph
topology. PEs are essential for GTs, where topological information would
otherwise be lost without message-passing. However, PEs are often tested
alongside novel architectures, making it difficult to isolate their effect on
established models. To address this, we present a comprehensive benchmark of
PEs in a unified framework that includes both message-passing GNNs and GTs. We
also establish theoretical connections between MPNNs and GTs and introduce a
sparsified GRIT attention mechanism to examine the influence of global
connectivity. Our findings demonstrate that previously untested combinations of
GNN architectures and PEs can outperform existing methods and offer a more
comprehensive picture of the state-of-the-art. To support future research and
experimentation in our framework, we make the code publicly available.

摘要：圖形神經網路 (GNN) 和圖形Transformer (GT) 的最新進展是由架構和位置編碼 (PE) 的創新所推動，這對於擴充節點特徵和擷取圖形拓撲至關重要。PE 對 GT 至關重要，因為在沒有訊息傳遞的情況下，拓撲資訊將會遺失。然而，PE 經常與新穎的架構一起測試，這使得難以分離它們對已建立模型的影響。為了解決這個問題，我們在一個統一的框架中展示了 PE 的全面基準測試，其中包括訊息傳遞 GNN 和 GT。我們還建立了 MPNN 和 GT 之間的理論關聯，並引入了一個稀疏化 GRIT 注意力機制來檢驗全局連接性的影響。我們的研究結果表明，先前未測試的 GNN 架構和 PE 組合可以優於現有方法，並提供更全面的最先進技術概況。為了支援我們框架中的未來研究和實驗，我們公開了程式碼。

##### **Information Theory of Meaningful Communication**
2411.12728v1 by Doron Sivan, Misha Tsodyks

In Shannon's seminal paper, entropy of printed English, treated as a
stationary stochastic process, was estimated to be roughly 1 bit per character.
However, considered as a means of communication, language differs considerably
from its printed form: (i) the units of information are not characters or even
words but clauses, i.e. shortest meaningful parts of speech; and (ii) what is
transmitted is principally the meaning of what is being said or written, while
the precise phrasing that was used to communicate the meaning is typically
ignored. In this study, we show that one can leverage recently developed large
language models to quantify information communicated in meaningful narratives
in terms of bits of meaning per clause.

摘要：在香農的開創性論文中，將印刷英語視為一個平穩隨機過程，其熵估計約為每字元 1 位元。
然而，語言作為一種溝通方式，與其印刷形式有很大的不同：(i) 資訊的單位不是字元，甚至不是單字，而是子句，也就是語句中最短的有意義的部分；(ii) 傳遞的主要是所說或所寫內容的意義，而用來傳達意義的精確措辭通常被忽略。在這項研究中，我們證明了可以利用最近開發的大型語言模型，以每子句意義位元為單位，量化在有意義的敘述中傳達的資訊。

##### **Scaling laws for nonlinear dynamical models of speech**
2411.12720v1 by Sam Kirkham

The addition of a nonlinear restoring force to dynamical models of the speech
gesture significantly improves the empirical accuracy of model predictions, but
nonlinearity introduces challenges in selecting appropriate parameters and
numerical stability, especially when modelling variation in empirical data. We
address this issue by introducing simple numerical methods for parameterization
of nonlinear task dynamic models. We first illustrate the problem and then
outline solutions in the form of power laws that scale nonlinear stiffness
terms. We apply the scaling laws to a cubic model and show how they facilitate
interpretable simulations of the nonlinear gestural dynamics underpinning
speech production.

摘要：在語音手勢的動態模型中加入非線性恢復力，可以顯著提升模型預測的經驗準確度，但非線性會在選擇適當參數和數值穩定性方面帶來挑戰，特別是在對經驗數據中的變化進行建模時。我們透過引入非線性任務動態模型參數化的簡單數值方法來解決這個問題。我們首先說明問題，然後概述以冪律形式縮放非線性剛度項的解決方案。我們將縮放律應用於三次模型，並展示它們如何促進對支撐語音產生的非線性手勢動態的可解釋模擬。

##### **Rethinking MUSHRA: Addressing Modern Challenges in Text-to-Speech Evaluation**
2411.12719v1 by Praveen Srinivasa Varadhan, Amogh Gulati, Ashwin Sankar, Srija Anand, Anirudh Gupta, Anirudh Mukherjee, Shiva Kumar Marepally, Ankur Bhatia, Saloni Jaju, Suvrat Bhooshan, Mitesh M. Khapra

Despite rapid advancements in TTS models, a consistent and robust human
evaluation framework is still lacking. For example, MOS tests fail to
differentiate between similar models, and CMOS's pairwise comparisons are
time-intensive. The MUSHRA test is a promising alternative for evaluating
multiple TTS systems simultaneously, but in this work we show that its reliance
on matching human reference speech unduly penalises the scores of modern TTS
systems that can exceed human speech quality. More specifically, we conduct a
comprehensive assessment of the MUSHRA test, focusing on its sensitivity to
factors such as rater variability, listener fatigue, and reference bias. Based
on our extensive evaluation involving 471 human listeners across Hindi and
Tamil we identify two primary shortcomings: (i) reference-matching bias, where
raters are unduly influenced by the human reference, and (ii) judgement
ambiguity, arising from a lack of clear fine-grained guidelines. To address
these issues, we propose two refined variants of the MUSHRA test. The first
variant enables fairer ratings for synthesized samples that surpass human
reference quality. The second variant reduces ambiguity, as indicated by the
relatively lower variance across raters. By combining these approaches, we
achieve both more reliable and more fine-grained assessments. We also release
MANGO, a massive dataset of 47,100 human ratings, the first-of-its-kind
collection for Indian languages, aiding in analyzing human preferences and
developing automatic metrics for evaluating TTS systems.

摘要：儘管 TTS 模型快速進步，但仍然缺乏一致且穩健的人類評估架構。例如，MOS 測試無法區分類似的模型，而 CMOS 的成對比較非常耗時。MUSHRA 測試是一種很有前途的替代方案，可以同時評估多個 TTS 系統，但我們在這項工作中表明，它依賴於匹配人類參考語音，過度懲罰了可以超越人類語音品質的現代 TTS 系統的分數。更具體地說，我們對 MUSHRA 測試進行了全面的評估，重點關注其對評分者變異性、聽眾疲勞和參考偏差等因素的敏感性。根據我們對 471 位印地語和泰米爾語人類聽眾進行的廣泛評估，我們發現了兩個主要的缺點：(i) 參考匹配偏差，評分者過度受到人類參考的影響，以及 (ii) 判斷模糊性，源於缺乏明確的細粒度準則。為了解決這些問題，我們提出了 MUSHRA 測試的兩個改進版本。第一個變體可以對超越人類參考品質的合成樣本進行更公平的評分。第二個變體減少了模糊性，如評分者之間相對較低的差異所表明的那樣。通過結合這些方法，我們實現了更可靠且更細粒度的評估。我們還發布了 MANGO，這是一個包含 47,100 個人類評分的龐大數據集，這是印度語言中首創的此類集合，有助於分析人類偏好並開發用於評估 TTS 系統的自動化指標。

##### **CATCH: Complementary Adaptive Token-level Contrastive Decoding to Mitigate Hallucinations in LVLMs**
2411.12713v1 by Zhehan Kan, Ce Zhang, Zihan Liao, Yapeng Tian, Wenming Yang, Junyuan Xiao, Xu Li, Dongmei Jiang, Yaowei Wang, Qingmin Liao

Large Vision-Language Model (LVLM) systems have demonstrated impressive
vision-language reasoning capabilities but suffer from pervasive and severe
hallucination issues, posing significant risks in critical domains such as
healthcare and autonomous systems. Despite previous efforts to mitigate
hallucinations, a persistent issue remains: visual defect from vision-language
misalignment, creating a bottleneck in visual processing capacity. To address
this challenge, we develop Complementary Adaptive Token-level Contrastive
Decoding to Mitigate Hallucinations in LVLMs (CATCH), based on the Information
Bottleneck theory. CATCH introduces Complementary Visual Decoupling (CVD) for
visual information separation, Non-Visual Screening (NVS) for hallucination
detection, and Adaptive Token-level Contrastive Decoding (ATCD) for
hallucination mitigation. CATCH addresses issues related to visual defects that
cause diminished fine-grained feature perception and cumulative hallucinations
in open-ended scenarios. It is applicable to various visual question-answering
tasks without requiring any specific data or prior knowledge, and generalizes
robustly to new tasks without additional training, opening new possibilities
for advancing LVLM in various challenging applications.

摘要：大型視覺語言模型 (LVLM) 系統已展現出令人印象深刻的視覺語言推理能力，但會遭受普遍且嚴重的幻覺問題，對醫療保健和自主系統等關鍵領域構成重大風險。儘管之前已做出減輕幻覺的努力，但仍存在一個持續的問題：視覺語言錯位造成的視覺缺陷，這會造成視覺處理能力的瓶頸。為了應對這項挑戰，我們根據資訊瓶頸理論，開發了用於減輕 LVLM 中幻覺的互補適應式代幣層級對比解碼 (CATCH)。CATCH 引入了互補視覺解耦 (CVD) 以進行視覺資訊分離、非視覺篩選 (NVS) 以進行幻覺偵測，以及適應式代幣層級對比解碼 (ATCD) 以進行幻覺減輕。CATCH 針對視覺缺陷的問題，這些問題會導致精細特徵感知力下降以及在開放式情境中累積幻覺。它適用於各種視覺問答任務，無需任何特定資料或先備知識，而且在沒有額外訓練的情況下，能穩健地概化到新任務，為在各種具挑戰性的應用中推進 LVLM 開啟新的可能性。

##### **Enhancing Multi-Class Disease Classification: Neoplasms, Cardiovascular, Nervous System, and Digestive Disorders Using Advanced LLMs**
2411.12712v1 by Ahmed Akib Jawad Karim, Muhammad Zawad Mahmud, Samiha Islam, Aznur Azam

In this research, we explored the improvement in terms of multi-class disease
classification via pre-trained language models over Medical-Abstracts-TC-Corpus
that spans five medical conditions. We excluded non-cancer conditions and
examined four specific diseases. We assessed four LLMs, BioBERT, XLNet, and
BERT, as well as a novel base model (Last-BERT). BioBERT, which was pre-trained
on medical data, demonstrated superior performance in medical text
classification (97% accuracy). Surprisingly, XLNet followed closely (96%
accuracy), demonstrating its generalizability across domains even though it was
not pre-trained on medical data. LastBERT, a custom model based on the lighter
version of BERT, also proved competitive with 87.10% accuracy (just under
BERT's 89.33%). Our findings confirm the importance of specialized models such
as BioBERT and also support impressions around more general solutions like
XLNet and well-tuned transformer architectures with fewer parameters (in this
case, LastBERT) in medical domain tasks.

摘要：在這項研究中，我們探討了透過預先訓練的語言模型在跨越五種醫療疾病的 Medical-Abstracts-TC-Corpus 上，多類疾病分類的改進。我們排除了非癌症疾病，並檢查了四種特定疾病。我們評估了四個 LLM，BioBERT、XLNet 和 BERT，以及一個新的基礎模型 (Last-BERT)。在醫學文本分類中，經過醫學資料預先訓練的 BioBERT 表現出優異的效能（97% 準確度）。令人驚訝的是，XLNet 緊隨其後（96% 準確度），展示了它在不同領域的概括能力，即使它不是在醫學資料上預先訓練的。LastBERT 是一個基於較輕版本的 BERT 的自訂模型，也證明了競爭力，準確度為 87.10%（僅低於 BERT 的 89.33%）。我們的發現證實了 BioBERT 等專用模型的重要性，也支持了對更通用的解決方案的印象，例如 XLNet 和在醫學領域任務中具有較少參數的微調Transformer架構（在本例中為 LastBERT）。

##### **Strengthening Fake News Detection: Leveraging SVM and Sophisticated Text Vectorization Techniques. Defying BERT?**
2411.12703v1 by Ahmed Akib Jawad Karim, Kazi Hafiz Md Asad, Aznur Azam

The rapid spread of misinformation, particularly through online platforms,
underscores the urgent need for reliable detection systems. This study explores
the utilization of machine learning and natural language processing,
specifically Support Vector Machines (SVM) and BERT, to detect news that are
fake. We employ three distinct text vectorization methods for SVM: Term
Frequency Inverse Document Frequency (TF-IDF), Word2Vec, and Bag of Words (BoW)
evaluating their effectiveness in distinguishing between genuine and fake news.
Additionally, we compare these methods against the transformer large language
model, BERT. Our comprehensive approach includes detailed preprocessing steps,
rigorous model implementation, and thorough evaluation to determine the most
effective techniques. The results demonstrate that while BERT achieves superior
accuracy with 99.98% and an F1-score of 0.9998, the SVM model with a linear
kernel and BoW vectorization also performs exceptionally well, achieving 99.81%
accuracy and an F1-score of 0.9980. These findings highlight that, despite
BERT's superior performance, SVM models with BoW and TF-IDF vectorization
methods come remarkably close, offering highly competitive performance with the
advantage of lower computational requirements.

摘要：隨著錯誤訊息快速散播，特別是透過線上平台，這凸顯了可靠偵測系統的迫切需求。本研究探討利用機器學習和自然語言處理，特別是支援向量機 (SVM) 和 BERT，來偵測假新聞。我們採用三種不同的文字向量化方法，用於 SVM：詞頻逆文件頻率 (TF-IDF)、Word2Vec 和詞袋 (BoW)，評估其在區分真實新聞和假新聞方面的有效性。此外，我們將這些方法與Transformer大型語言模型 BERT 進行比較。我們的綜合方法包括詳細的預處理步驟、嚴謹的模型實作和徹底的評估，以確定最有效的技術。結果表明，儘管 BERT 以 99.98% 的準確率和 0.9998 的 F1 分數取得了優異的準確度，但具有線性核心的 SVM 模型和 BoW 向量化也表現得非常好，準確率達到 99.81%，F1 分數為 0.9980。這些發現強調，儘管 BERT 具有優異的效能，但使用 BoW 和 TF-IDF 向量化方法的 SVM 模型表現得非常接近，在計算需求較低的情況下，提供了極具競爭力的效能。

##### **When Backdoors Speak: Understanding LLM Backdoor Attacks Through Model-Generated Explanations**
2411.12701v1 by Huaizhi Ge, Yiming Li, Qifan Wang, Yongfeng Zhang, Ruixiang Tang

Large Language Models (LLMs) are vulnerable to backdoor attacks, where hidden
triggers can maliciously manipulate model behavior. While several backdoor
attack methods have been proposed, the mechanisms by which backdoor functions
operate in LLMs remain underexplored. In this paper, we move beyond attacking
LLMs and investigate backdoor functionality through the novel lens of natural
language explanations. Specifically, we leverage LLMs' generative capabilities
to produce human-understandable explanations for their decisions, allowing us
to compare explanations for clean and poisoned samples. We explore various
backdoor attacks and embed the backdoor into LLaMA models for multiple tasks.
Our experiments show that backdoored models produce higher-quality explanations
for clean data compared to poisoned data, while generating significantly more
consistent explanations for poisoned data than for clean data. We further
analyze the explanation generation process, revealing that at the token level,
the explanation token of poisoned samples only appears in the final few
transformer layers of the LLM. At the sentence level, attention dynamics
indicate that poisoned inputs shift attention from the input context when
generating the explanation. These findings deepen our understanding of backdoor
attack mechanisms in LLMs and offer a framework for detecting such
vulnerabilities through explainability techniques, contributing to the
development of more secure LLMs.

摘要：大型語言模型 (LLM) 容易受到後門攻擊，其中隱藏的觸發器可以惡意操縱模型行為。雖然已經提出了幾種後門攻擊方法，但後門功能在 LLM 中運作的機制仍未得到充分探討。在本文中，我們超越攻擊 LLM，並通過自然語言解釋的新穎視角來研究後門功能。具體來說，我們利用 LLM 的生成能力為其決策提供人類可以理解的解釋，讓我們能夠比較乾淨和中毒樣本的解釋。我們探索各種後門攻擊，並將後門嵌入到 LLaMA 模型中以執行多項任務。我們的實驗表明，與中毒數據相比，後門模型對乾淨數據產生的解釋品質更高，同時對中毒數據產生的解釋顯著更一致。我們進一步分析了解釋生成過程，發現就權杖層面而言，中毒樣本的解釋權杖只出現在 LLM 的最後幾個轉換層中。在句子層面，注意力動態表明，中毒輸入在生成解釋時會將注意力從輸入內容轉移。這些發現加深了我們對 LLM 中後門攻擊機制的理解，並提供了一個通過可解釋性技術來檢測此類漏洞的框架，有助於開發更安全的 LLM。

##### **Attribute Inference Attacks for Federated Regression Tasks**
2411.12697v1 by Francesco Diana, Othmane Marfoq, Chuan Xu, Giovanni Neglia, Frédéric Giroire, Eoin Thomas

Federated Learning (FL) enables multiple clients, such as mobile phones and
IoT devices, to collaboratively train a global machine learning model while
keeping their data localized. However, recent studies have revealed that the
training phase of FL is vulnerable to reconstruction attacks, such as attribute
inference attacks (AIA), where adversaries exploit exchanged messages and
auxiliary public information to uncover sensitive attributes of targeted
clients. While these attacks have been extensively studied in the context of
classification tasks, their impact on regression tasks remains largely
unexplored. In this paper, we address this gap by proposing novel model-based
AIAs specifically designed for regression tasks in FL environments. Our
approach considers scenarios where adversaries can either eavesdrop on
exchanged messages or directly interfere with the training process. We
benchmark our proposed attacks against state-of-the-art methods using
real-world datasets. The results demonstrate a significant increase in
reconstruction accuracy, particularly in heterogeneous client datasets, a
common scenario in FL. The efficacy of our model-based AIAs makes them better
candidates for empirically quantifying privacy leakage for federated regression
tasks.

摘要：聯邦學習 (FL) 能讓多個用戶端，例如行動電話和 IoT 裝置，在保持其資料在地化的同時，合作訓練一個全球機器學習模型。然而，最近的研究顯示，FL 的訓練階段容易受到重建攻擊，例如屬性推論攻擊 (AIA)，其中對手利用交換的訊息和輔助公開資訊，揭露目標用戶端的敏感屬性。雖然這些攻擊在分類任務的背景下已廣泛研究，但其對迴歸任務的影響仍未廣泛探討。在本文中，我們透過提出專門針對 FL 環境中的迴歸任務設計的新穎基於模型的 AIA，來解決這個差距。我們的做法考慮了對手可以竊聽交換訊息或直接干擾訓練過程的場景。我們使用真實世界的資料集，針對現有方法評量我們提出的攻擊。結果顯示重建精準度大幅提升，特別是在異質用戶端資料集，這是 FL 中常見的場景。我們的基於模型的 AIA 的功效，讓它們成為經驗量化聯邦迴歸任務中隱私外洩的更佳候選者。

