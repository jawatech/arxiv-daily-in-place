{"2502.01591": {"publish_time": "2025-02-03", "title": "Improving Transformer World Models for Data-Efficient RL", "paper_summary": "We present an approach to model-based RL that achieves a new state of the art\nperformance on the challenging Craftax-classic benchmark, an open-world 2D\nsurvival game that requires agents to exhibit a wide range of general abilities\n-- such as strong generalization, deep exploration, and long-term reasoning.\nWith a series of careful design choices aimed at improving sample efficiency,\nour MBRL algorithm achieves a reward of 67.4% after only 1M environment steps,\nsignificantly outperforming DreamerV3, which achieves 53.2%, and, for the first\ntime, exceeds human performance of 65.0%. Our method starts by constructing a\nSOTA model-free baseline, using a novel policy architecture that combines CNNs\nand RNNs. We then add three improvements to the standard MBRL setup: (a) \"Dyna\nwith warmup\", which trains the policy on real and imaginary data, (b) \"nearest\nneighbor tokenizer\" on image patches, which improves the scheme to create the\ntransformer world model (TWM) inputs, and (c) \"block teacher forcing\", which\nallows the TWM to reason jointly about the future tokens of the next timestep.", "paper_summary_zh": "\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u57fa\u65bc\u6a21\u578b\u7684 RL \u65b9\u6cd5\uff0c\u5728\u5177\u6709\u6311\u6230\u6027\u7684 Craftax-classic \u57fa\u6e96\u4e0a\u5be6\u73fe\u4e86\u65b0\u7684\u6280\u8853\u6c34\u6e96\uff0c\u9019\u662f\u4e00\u500b\u958b\u653e\u4e16\u754c\u7684 2D \u751f\u5b58\u904a\u6232\uff0c\u8981\u6c42\u4ee3\u7406\u4eba\u5c55\u73fe\u5ee3\u6cdb\u7684\u4e00\u822c\u80fd\u529b\uff0c\u4f8b\u5982\u5f37\u5927\u7684\u6982\u62ec\u80fd\u529b\u3001\u6df1\u5165\u63a2\u7d22\u548c\u9577\u671f\u63a8\u7406\u3002\u901a\u904e\u4e00\u7cfb\u5217\u65e8\u5728\u63d0\u9ad8\u6a23\u672c\u6548\u7387\u7684\u4ed4\u7d30\u8a2d\u8a08\u9078\u64c7\uff0c\u6211\u5011\u7684 MBRL \u6f14\u7b97\u6cd5\u5728\u50c5 1M \u74b0\u5883\u6b65\u9a5f\u5f8c\u5c31\u5be6\u73fe\u4e86 67.4% \u7684\u734e\u52f5\uff0c\u986f\u8457\u512a\u65bc DreamerV3\uff08\u5be6\u73fe 53.2%\uff09\uff0c\u4e26\u4e14\u9996\u6b21\u8d85\u904e\u4e86\u4eba\u985e\u7684 65.0% \u7684\u8868\u73fe\u3002\u6211\u5011\u7684\u6f14\u7b97\u6cd5\u9996\u5148\u901a\u904e\u4f7f\u7528\u7d50\u5408 CNN \u548c RNN \u7684\u65b0\u7a4e\u7b56\u7565\u67b6\u69cb\u4f86\u5efa\u69cb\u4e00\u500b SOTA \u7121\u6a21\u578b\u57fa\u7dda\u3002\u7136\u5f8c\uff0c\u6211\u5011\u5c0d\u6a19\u6e96 MBRL \u8a2d\u5b9a\u65b0\u589e\u4e86\u4e09\u9805\u6539\u9032\uff1a(a)\u300c\u5e36\u71b1\u8eab\u7684 Dyna\u300d\uff0c\u5b83\u5728\u771f\u5be6\u548c\u5047\u60f3\u8cc7\u6599\u4e0a\u8a13\u7df4\u7b56\u7565\uff0c(b) \u5f71\u50cf\u8cbc\u7247\u7684\u300c\u6700\u8fd1\u9130\u4ee3\u78bc\u5316\u5668\u300d\uff0c\u5b83\u6539\u9032\u4e86\u5efa\u7acb\u8f49\u63db\u5668\u4e16\u754c\u6a21\u578b (TWM) \u8f38\u5165\u7684\u65b9\u6848\uff0c\u4ee5\u53ca (c)\u300c\u5340\u584a\u6559\u5e2b\u5f37\u5236\u300d\uff0c\u5b83\u5141\u8a31 TWM \u5171\u540c\u63a8\u7406\u4e0b\u4e00\u500b\u6642\u9593\u6b65\u9577\u7684\u672a\u4f86\u4ee3\u78bc\u3002", "author": "Antoine Dedieu et.al.", "authors": "Antoine Dedieu, Joseph Ortiz, Xinghua Lou, Carter Wendelken, Wolfgang Lehrach, J Swaroop Guntupalli, Miguel Lazaro-Gredilla, Kevin Patrick Murphy", "id": "2502.01591v1", "paper_url": "http://arxiv.org/abs/2502.01591v1", "repo": "null"}}