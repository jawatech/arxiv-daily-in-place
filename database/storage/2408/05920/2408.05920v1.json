{"2408.05920": {"publish_time": "2024-08-12", "title": "Urban Region Pre-training and Prompting: A Graph-based Approach", "paper_summary": "Urban region representation is crucial for various urban downstream tasks.\nHowever, despite the proliferation of methods and their success, acquiring\ngeneral urban region knowledge and adapting to different tasks remains\nchallenging. Previous work often neglects the spatial structures and functional\nlayouts between entities, limiting their ability to capture transferable\nknowledge across regions. Further, these methods struggle to adapt effectively\nto specific downstream tasks, as they do not adequately address the unique\nfeatures and relationships required for different downstream tasks. In this\npaper, we propose a $\\textbf{G}$raph-based $\\textbf{U}$rban $\\textbf{R}$egion\n$\\textbf{P}$re-training and $\\textbf{P}$rompting framework ($\\textbf{GURPP}$)\nfor region representation learning. Specifically, we first construct an urban\nregion graph that integrates detailed spatial entity data for more effective\nurban region representation. Then, we develop a subgraph-centric urban region\npre-training model to capture the heterogeneous and transferable patterns of\ninteractions among entities. To further enhance the adaptability of these\nembeddings to different tasks, we design two graph-based prompting methods to\nincorporate explicit/hidden task knowledge. Extensive experiments on various\nurban region prediction tasks and different cities demonstrate the superior\nperformance of our GURPP framework. The implementation is available at this\nrepository: https://anonymous.4open.science/r/GURPP.", "paper_summary_zh": "\u57ce\u5e02\u5340\u57df\u8868\u5fb5\u5c0d\u65bc\u5404\u7a2e\u57ce\u5e02\u4e0b\u6e38\u4efb\u52d9\u81f3\u95dc\u91cd\u8981\u3002\n\u7136\u800c\uff0c\u5118\u7ba1\u65b9\u6cd5\u6fc0\u589e\u4e14\u6210\u529f\uff0c\u4f46\u7372\u53d6\u4e00\u822c\u57ce\u5e02\u5340\u57df\u77e5\u8b58\u4e26\u9069\u61c9\u4e0d\u540c\u4efb\u52d9\u4ecd\u7136\u5177\u6709\u6311\u6230\u6027\u3002\u5148\u524d\u7684\u7814\u7a76\u5e38\u5e38\u5ffd\u7565\u5be6\u9ad4\u4e4b\u9593\u7684\u7a7a\u9593\u7d50\u69cb\u548c\u529f\u80fd\u4f48\u5c40\uff0c\u9019\u9650\u5236\u4e86\u5b83\u5011\u8de8\u5340\u57df\u64f7\u53d6\u53ef\u8f49\u79fb\u77e5\u8b58\u7684\u80fd\u529b\u3002\u6b64\u5916\uff0c\u9019\u4e9b\u65b9\u6cd5\u96e3\u4ee5\u6709\u6548\u9069\u61c9\u7279\u5b9a\u7684\u4e0b\u6e38\u4efb\u52d9\uff0c\u56e0\u70ba\u5b83\u5011\u6c92\u6709\u5145\u5206\u8003\u91cf\u4e0d\u540c\u4e0b\u6e38\u4efb\u52d9\u6240\u9700\u7684\u7368\u7279\u7279\u5fb5\u548c\u95dc\u4fc2\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u57fa\u65bc\u5716\u5f62\u7684\u57ce\u5e02\u5340\u57df\u9810\u8a13\u7df4\u548c\u63d0\u793a\u6846\u67b6\uff08GURPP\uff09\uff0c\u7528\u65bc\u5340\u57df\u8868\u5fb5\u5b78\u7fd2\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u9996\u5148\u69cb\u5efa\u4e00\u500b\u57ce\u5e02\u5340\u57df\u5716\u5f62\uff0c\u6574\u5408\u8a73\u7d30\u7684\u7a7a\u9593\u5be6\u9ad4\u8cc7\u6599\uff0c\u4ee5\u7372\u5f97\u66f4\u6709\u6548\u7684\u57ce\u5e02\u5340\u57df\u8868\u5fb5\u3002\u7136\u5f8c\uff0c\u6211\u5011\u958b\u767c\u4e00\u500b\u4ee5\u5b50\u5716\u70ba\u4e2d\u5fc3\u7684\u57ce\u5e02\u5340\u57df\u9810\u8a13\u7df4\u6a21\u578b\uff0c\u4ee5\u64f7\u53d6\u5be6\u9ad4\u4e4b\u9593\u7684\u7570\u8cea\u4e14\u53ef\u8f49\u79fb\u7684\u4e92\u52d5\u6a21\u5f0f\u3002\u70ba\u4e86\u9032\u4e00\u6b65\u589e\u5f37\u9019\u4e9b\u5d4c\u5165\u5c0d\u4e0d\u540c\u4efb\u52d9\u7684\u9069\u61c9\u6027\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u5169\u7a2e\u57fa\u65bc\u5716\u5f62\u7684\u63d0\u793a\u65b9\u6cd5\uff0c\u4ee5\u7d0d\u5165\u660e\u78ba/\u96b1\u85cf\u7684\u4efb\u52d9\u77e5\u8b58\u3002\u5728\u5404\u7a2e\u57ce\u5e02\u5340\u57df\u9810\u6e2c\u4efb\u52d9\u548c\u4e0d\u540c\u57ce\u5e02\u4e0a\u7684\u5ee3\u6cdb\u5be6\u9a57\u8b49\u660e\u4e86\u6211\u5011 GURPP \u6846\u67b6\u7684\u512a\u7570\u6548\u80fd\u3002\u5be6\u4f5c\u53ef\u5728\u6b64\u5132\u5b58\u5eab\u53d6\u5f97\uff1ahttps://anonymous.4open.science/r/GURPP\u3002", "author": "Jiahui Jin et.al.", "authors": "Jiahui Jin, Yifan Song, Dong Kan, Haojia Zhu, Xiangguo Sun, Zhicheng Li, Xigang Sun, Jinghui Zhang", "id": "2408.05920v1", "paper_url": "http://arxiv.org/abs/2408.05920v1", "repo": "null"}}