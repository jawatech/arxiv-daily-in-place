
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**Matryoshka Multimodal Models**|Mu Cai et.al.|[2405.17430v1](http://arxiv.org/abs/2405.17430v1)|null|
|**2024-05-27**|**NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models**|Chankyu Lee et.al.|[2405.17428v1](http://arxiv.org/abs/2405.17428v1)|null|
|**2024-05-27**|**Privacy-Aware Visual Language Models**|Laurens Samson et.al.|[2405.17423v1](http://arxiv.org/abs/2405.17423v1)|null|
|**2024-05-27**|**Hardness-Aware Scene Synthesis for Semi-Supervised 3D Object Detection**|Shuai Zeng et.al.|[2405.17422v1](http://arxiv.org/abs/2405.17422v1)|[link](https://github.com/wzzheng/hass)|
|**2024-05-27**|**MultiOOD: Scaling Out-of-Distribution Detection for Multiple Modalities**|Hao Dong et.al.|[2405.17419v1](http://arxiv.org/abs/2405.17419v1)|[link](https://github.com/donghao51/multiood)|
|**2024-05-27**|**Towards One Model for Classical Dimensionality Reduction: A Probabilistic Perspective on UMAP and t-SNE**|Aditya Ravuri et.al.|[2405.17412v1](http://arxiv.org/abs/2405.17412v1)|null|
|**2024-05-27**|**Spectral Greedy Coresets for Graph Neural Networks**|Mucong Ding et.al.|[2405.17404v1](http://arxiv.org/abs/2405.17404v1)|null|
|**2024-05-27**|**A Closer Look at Time Steps is Worthy of Triple Speed-Up for Diffusion Model Training**|Kai Wang et.al.|[2405.17403v1](http://arxiv.org/abs/2405.17403v1)|[link](https://github.com/1zeryu/speed)|
|**2024-05-27**|**THREAD: Thinking Deeper with Recursive Spawning**|Philip Schroeder et.al.|[2405.17402v1](http://arxiv.org/abs/2405.17402v1)|null|
|**2024-05-27**|**Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability**|Shenyuan Gao et.al.|[2405.17398v1](http://arxiv.org/abs/2405.17398v1)|[link](https://github.com/opendrivelab/vista)|
|**2024-05-27**|**The Expressive Capacity of State Space Models: A Formal Language Perspective**|Yash Sarrof et.al.|[2405.17394v1](http://arxiv.org/abs/2405.17394v1)|null|
|**2024-05-27**|**KSW: Khmer Stop Word based Dictionary for Keyword Extraction**|Nimol Thuon et.al.|[2405.17390v1](http://arxiv.org/abs/2405.17390v1)|[link](https://github.com/back-kh/KSWv2-Khmer-Stop-Word-based-Dictionary-for-Keyword-Extraction)|
|**2024-05-27**|**MindMerger: Efficient Boosting LLM Reasoning in non-English Languages**|Zixian Huang et.al.|[2405.17386v1](http://arxiv.org/abs/2405.17386v1)|null|
|**2024-05-27**|**Unlocking the Secrets of Linear Complexity Sequence Model from A Unified Perspective**|Zhen Qin et.al.|[2405.17383v1](http://arxiv.org/abs/2405.17383v1)|null|
|**2024-05-27**|**ReMoDetect: Reward Models Recognize Aligned LLM's Generations**|Hyunseok Lee et.al.|[2405.17382v1](http://arxiv.org/abs/2405.17382v1)|null|
|**2024-05-27**|**Various Lengths, Constant Speed: Efficient Language Modeling with Lightning Attention**|Zhen Qin et.al.|[2405.17381v1](http://arxiv.org/abs/2405.17381v1)|[link](https://github.com/opennlplab/transnormerllm)|
|**2024-05-27**|**Federating Dynamic Models using Early-Exit Architectures for Automatic Speech Recognition on Heterogeneous Clients**|Mohamed Nabih Ali et.al.|[2405.17376v1](http://arxiv.org/abs/2405.17376v1)|null|
|**2024-05-27**|**BehaviorGPT: Smart Agent Simulation for Autonomous Driving with Next-Patch Prediction**|Zikang Zhou et.al.|[2405.17372v1](http://arxiv.org/abs/2405.17372v1)|null|
|**2024-05-27**|**A One-Layer Decoder-Only Transformer is a Two-Layer RNN: With an Application to Certified Robustness**|Yuhao Zhang et.al.|[2405.17361v1](http://arxiv.org/abs/2405.17361v1)|null|
|**2024-05-27**|**Rethinking Transformers in Solving POMDPs**|Chenhao Lu et.al.|[2405.17358v1](http://arxiv.org/abs/2405.17358v1)|[link](https://github.com/ctp314/tfporl)|
|**2024-05-27**|**DoRA: Enhancing Parameter-Efficient Fine-Tuning with Dynamic Rank Distribution**|Yulong Mao et.al.|[2405.17357v1](http://arxiv.org/abs/2405.17357v1)|[link](https://github.com/yulongmao1/dora)|
|**2024-05-27**|**Prompt Optimization with Human Feedback**|Xiaoqiang Lin et.al.|[2405.17346v1](http://arxiv.org/abs/2405.17346v1)|[link](https://github.com/xqlin98/apohf)|
|**2024-05-27**|**Exploring and steering the moral compass of Large Language Models**|Alejandro Tlaie et.al.|[2405.17345v1](http://arxiv.org/abs/2405.17345v1)|null|
|**2024-05-27**|**Cost-efficient Knowledge-based Question Answering with Large Language Models**|Junnan Dong et.al.|[2405.17337v1](http://arxiv.org/abs/2405.17337v1)|null|
|**2024-05-27**|**XFormParser: A Simple and Effective Multimodal Multilingual Semi-structured Form Parser**|Xianfu Cheng et.al.|[2405.17336v1](http://arxiv.org/abs/2405.17336v1)|null|
|**2024-05-27**|**Leveraging Offline Data in Linear Latent Bandits**|Chinmaya Kausik et.al.|[2405.17324v1](http://arxiv.org/abs/2405.17324v1)|null|
|**2024-05-27**|**Efficient Ensembles Improve Training Data Attribution**|Junwei Deng et.al.|[2405.17293v1](http://arxiv.org/abs/2405.17293v1)|null|
|**2024-05-27**|**Opinion-Guided Reinforcement Learning**|Kyanna Dagenais et.al.|[2405.17287v1](http://arxiv.org/abs/2405.17287v1)|null|
|**2024-05-27**|**An NLP Crosswalk Between the Common Core State Standards and NAEP Item Specifications**|Gregory Camilli et.al.|[2405.17284v1](http://arxiv.org/abs/2405.17284v1)|null|
|**2024-05-27**|**A Library for Automatic Natural Language Generation of Spanish Texts**|Silvia García-Méndez et.al.|[2405.17280v1](http://arxiv.org/abs/2405.17280v1)|null|
|**2024-05-27**|**Socially-Aware Shared Control Navigation for Assistive Mobile Robots in the Built Environment**|Yifan Xu et.al.|[2405.17279v1](http://arxiv.org/abs/2405.17279v1)|null|
|**2024-05-27**|**On the Noise Robustness of In-Context Learning for Text Generation**|Hongfu Gao et.al.|[2405.17264v1](http://arxiv.org/abs/2405.17264v1)|null|
|**2024-05-27**|**$\textit{Trans-LoRA}$: towards data-free Transferable Parameter Efficient Finetuning**|Runqian Wang et.al.|[2405.17258v1](http://arxiv.org/abs/2405.17258v1)|null|
|**2024-05-27**|**Gaussian Embedding of Temporal Networks**|Raphaël Romero et.al.|[2405.17253v1](http://arxiv.org/abs/2405.17253v1)|[link](https://github.com/aida-ugent/tgne)|
|**2024-05-27**|**Assessing LLMs Suitability for Knowledge Graph Completion**|Vasile Ionut Remus Iga et.al.|[2405.17249v1](http://arxiv.org/abs/2405.17249v1)|[link](https://github.com/ionutiga/llms-for-kgc)|
|**2024-05-27**|**Galaxy: A Resource-Efficient Collaborative Edge AI System for In-situ Transformer Inference**|Shengyuan Ye et.al.|[2405.17245v1](http://arxiv.org/abs/2405.17245v1)|null|
|**2024-05-27**|**Benchmarking General Purpose In-Context Learning**|Fan Wang et.al.|[2405.17234v1](http://arxiv.org/abs/2405.17234v1)|null|
|**2024-05-27**|**RLAIF-V: Aligning MLLMs through Open-Source AI Feedback for Super GPT-4V Trustworthiness**|Tianyu Yu et.al.|[2405.17220v1](http://arxiv.org/abs/2405.17220v1)|[link](https://github.com/rlhf-v/rlaif-v)|
|**2024-05-27**|**Autoformalizing Euclidean Geometry**|Logan Murphy et.al.|[2405.17216v1](http://arxiv.org/abs/2405.17216v1)|[link](https://github.com/loganrjmurphy/leaneuclid)|
|**2024-05-27**|**Efficient multi-prompt evaluation of LLMs**|Felipe Maia Polo et.al.|[2405.17202v1](http://arxiv.org/abs/2405.17202v1)|null|
|**2024-05-27**|**DreamMat: High-quality PBR Material Generation with Geometry- and Light-aware Diffusion Models**|Yuqing Zhang et.al.|[2405.17176v1](http://arxiv.org/abs/2405.17176v1)|null|
|**2024-05-27**|**Stop! In the Name of Flaws: Disentangling Personal Names and Sociodemographic Attributes in NLP**|Vagrant Gautam et.al.|[2405.17159v1](http://arxiv.org/abs/2405.17159v1)|null|
|**2024-05-27**|**Synergy and Diversity in CLIP: Enhancing Performance Through Adaptive Backbone Ensembling**|Cristian Rodriguez-Opazo et.al.|[2405.17139v1](http://arxiv.org/abs/2405.17139v1)|null|
|**2024-05-27**|**Exploiting the Layered Intrinsic Dimensionality of Deep Models for Practical Adversarial Training**|Enes Altinisik et.al.|[2405.17130v1](http://arxiv.org/abs/2405.17130v1)|null|
|**2024-05-27**|**TEII: Think, Explain, Interact and Iterate with Large Language Models to Solve Cross-lingual Emotion Detection**|Long Cheng et.al.|[2405.17129v1](http://arxiv.org/abs/2405.17129v1)|null|
|**2024-05-27**|**Mixtures of Unsupervised Lexicon Classification**|Peratham Wiriyathammabhum et.al.|[2405.17116v1](http://arxiv.org/abs/2405.17116v1)|null|
|**2024-05-27**|**Superpixelwise Low-rank Approximation based Partial Label Learning for Hyperspectral Image Classification**|Shujun Yang et.al.|[2405.17110v1](http://arxiv.org/abs/2405.17110v1)|[link](https://github.com/sjyang8/SLAP)|
|**2024-05-27**|**LLM-Optic: Unveiling the Capabilities of Large Language Models for Universal Visual Grounding**|Haoyu Zhao et.al.|[2405.17104v2](http://arxiv.org/abs/2405.17104v2)|null|
|**2024-05-27**|**Empowering Character-level Text Infilling by Eliminating Sub-Tokens**|Houxing Ren et.al.|[2405.17103v1](http://arxiv.org/abs/2405.17103v1)|null|
|**2024-05-27**|**Phase Transitions in the Output Distribution of Large Language Models**|Julian Arnold et.al.|[2405.17088v1](http://arxiv.org/abs/2405.17088v1)|[link](https://github.com/llmtransitions/llmtransitions)|
|**2024-05-27**|**Leveraging small language models for Text2SPARQL tasks to improve the resilience of AI assistance**|Felix Brei et.al.|[2405.17076v1](http://arxiv.org/abs/2405.17076v1)|null|
|**2024-05-27**|**Tokenization Matters! Degrading Large Language Models through Challenging Their Tokenization**|Dixuan Wang et.al.|[2405.17067v1](http://arxiv.org/abs/2405.17067v1)|null|
|**2024-05-27**|**Unifying Demonstration Selection and Compression for In-Context Learning**|Jun Gao et.al.|[2405.17062v1](http://arxiv.org/abs/2405.17062v1)|null|
|**2024-05-27**|**Graph Neural Networks on Quantum Computers**|Yidong Liao et.al.|[2405.17060v1](http://arxiv.org/abs/2405.17060v1)|null|
|**2024-05-27**|**ReflectionCoder: Learning from Reflection Sequence for Enhanced One-off Code Generation**|Houxing Ren et.al.|[2405.17057v1](http://arxiv.org/abs/2405.17057v1)|[link](https://github.com/sensellm/reflectioncoder)|
|**2024-05-27**|**WirelessLLM: Empowering Large Language Models Towards Wireless Intelligence**|Jiawei Shao et.al.|[2405.17053v1](http://arxiv.org/abs/2405.17053v1)|null|
|**2024-05-27**|**SelfCP: Compressing Long Prompt to 1/12 Using the Frozen Large Language Model Itself**|Jun Gao et.al.|[2405.17052v1](http://arxiv.org/abs/2405.17052v1)|null|
|**2024-05-27**|**BeamVQ: Aligning Space-Time Forecasting Model via Self-training on Physics-aware Metrics**|Hao Wu et.al.|[2405.17051v1](http://arxiv.org/abs/2405.17051v1)|null|
|**2024-05-27**|**Generation and human-expert evaluation of interesting research ideas using knowledge graphs and large language models**|Xuemei Gu et.al.|[2405.17044v1](http://arxiv.org/abs/2405.17044v1)|null|
|**2024-05-27**|**BWArea Model: Learning World Model, Inverse Dynamics, and Policy for Controllable Language Generation**|Chengxing Jia et.al.|[2405.17039v1](http://arxiv.org/abs/2405.17039v1)|null|
|**2024-05-27**|**SWAT: Scalable and Efficient Window Attention-based Transformers Acceleration on FPGAs**|Zhenyu Bai et.al.|[2405.17025v1](http://arxiv.org/abs/2405.17025v1)|null|
|**2024-05-27**|**Compositional Few-Shot Class-Incremental Learning**|Yixiong Zou et.al.|[2405.17022v1](http://arxiv.org/abs/2405.17022v1)|null|
|**2024-05-27**|**Position: Foundation Agents as the Paradigm Shift for Decision Making**|Xiaoqian Liu et.al.|[2405.17009v2](http://arxiv.org/abs/2405.17009v2)|null|
|**2024-05-27**|**Vision-and-Language Navigation Generative Pretrained Transformer**|Wen Hanlin et.al.|[2405.16994v1](http://arxiv.org/abs/2405.16994v1)|null|
|**2024-05-27**|**The Multi-Range Theory of Translation Quality Measurement: MQM scoring models and Statistical Quality Control**|Arle Lommel et.al.|[2405.16969v1](http://arxiv.org/abs/2405.16969v1)|null|
|**2024-05-27**|**Exploring the LLM Journey from Cognition to Expression with Linear Representations**|Yuzi Yan et.al.|[2405.16964v1](http://arxiv.org/abs/2405.16964v1)|null|
|**2024-05-27**|**Blind Data Adaptation to tackle Covariate Shift in Operational Steganalysis**|Rony Abecidan et.al.|[2405.16961v1](http://arxiv.org/abs/2405.16961v1)|null|
|**2024-05-27**|**Empowering Large Language Models to Set up a Knowledge Retrieval Indexer via Self-Learning**|Xun Liang et.al.|[2405.16933v1](http://arxiv.org/abs/2405.16933v1)|[link](https://github.com/iaar-shanghai/pgrag)|
|**2024-05-27**|**Uncertainty Management in the Construction of Knowledge Graphs: a Survey**|Lucas Jarnac et.al.|[2405.16929v1](http://arxiv.org/abs/2405.16929v1)|null|
|**2024-05-27**|**VoCoT: Unleashing Visually Grounded Multi-Step Reasoning in Large Multi-Modal Models**|Zejun Li et.al.|[2405.16919v2](http://arxiv.org/abs/2405.16919v2)|[link](https://github.com/rupertluo/vocot)|
|**2024-05-27**|**Can Large Language Models Faithfully Express Their Intrinsic Uncertainty in Words?**|Gal Yona et.al.|[2405.16908v1](http://arxiv.org/abs/2405.16908v1)|null|
|**2024-05-27**|**GTA: Generative Trajectory Augmentation with Guidance for Offline Reinforcement Learning**|Jaewoo Lee et.al.|[2405.16907v2](http://arxiv.org/abs/2405.16907v2)|[link](https://github.com/jaewoopudding/gta)|
|**2024-05-27**|**Partial Models for Building Adaptive Model-Based Reinforcement Learning Agents**|Safa Alver et.al.|[2405.16899v1](http://arxiv.org/abs/2405.16899v1)|null|
|**2024-05-27**|**A Large Language Model-based multi-agent manufacturing system for intelligent shopfloor**|Zhen Zhao et.al.|[2405.16887v1](http://arxiv.org/abs/2405.16887v1)|null|
|**2024-05-27**|**Match, Compare, or Select? An Investigation of Large Language Models for Entity Matching**|Tianshu Wang et.al.|[2405.16884v1](http://arxiv.org/abs/2405.16884v1)|[link](https://github.com/tshu-w/llm4em)|
|**2024-05-27**|**Scorch: A Library for Sparse Deep Learning**|Bobby Yan et.al.|[2405.16883v1](http://arxiv.org/abs/2405.16883v1)|null|
|**2024-05-27**|**Unsupervised Generative Feature Transformation via Graph Contrastive Pre-training and Multi-objective Fine-tuning**|Wangyang Ying et.al.|[2405.16879v1](http://arxiv.org/abs/2405.16879v1)|null|
|**2024-05-27**|**Are Self-Attentions Effective for Time Series Forecasting?**|Dongbin Kim et.al.|[2405.16877v1](http://arxiv.org/abs/2405.16877v1)|null|
|**2024-05-27**|**Transfer Learning for Diffusion Models**|Yidong Ouyang et.al.|[2405.16876v2](http://arxiv.org/abs/2405.16876v2)|null|
|**2024-05-27**|**Mixture of Modality Knowledge Experts for Robust Multi-modal Knowledge Graph Completion**|Yichi Zhang et.al.|[2405.16869v1](http://arxiv.org/abs/2405.16869v1)|[link](https://github.com/zjukg/momok)|
|**2024-05-27**|**Think Before You Act: A Two-Stage Framework for Mitigating Gender Bias Towards Vision-Language Tasks**|Yunqi Zhang et.al.|[2405.16860v1](http://arxiv.org/abs/2405.16860v1)|[link](https://github.com/zyq0000/gama)|
|**2024-05-27**|**Can We Trust LLMs? Mitigate Overconfidence Bias in LLMs through Knowledge Transfer**|Haoyan Yang et.al.|[2405.16856v1](http://arxiv.org/abs/2405.16856v1)|null|
|**2024-05-27**|**EM Distillation for One-step Diffusion Models**|Sirui Xie et.al.|[2405.16852v1](http://arxiv.org/abs/2405.16852v1)|null|
|**2024-05-27**|**Temporal Spiking Neural Networks with Synaptic Delay for Graph Reasoning**|Mingqing Xiao et.al.|[2405.16851v1](http://arxiv.org/abs/2405.16851v1)|null|
|**2024-05-27**|**TokenUnify: Scalable Autoregressive Visual Pre-training with Mixture Token Prediction**|Yinda Chen et.al.|[2405.16847v1](http://arxiv.org/abs/2405.16847v1)|null|
|**2024-05-27**|**On Mesa-Optimization in Autoregressively Trained Transformers: Emergence and Capability**|Chenyu Zheng et.al.|[2405.16845v1](http://arxiv.org/abs/2405.16845v1)|null|
|**2024-05-27**|**Enhancing Fast Feed Forward Networks with Load Balancing and a Master Leaf Node**|Andreas Charalampopoulos et.al.|[2405.16836v1](http://arxiv.org/abs/2405.16836v1)|null|
|**2024-05-27**|**Structured Graph Network for Constrained Robot Crowd Navigation with Low Fidelity Simulation**|Shuijing Liu et.al.|[2405.16830v2](http://arxiv.org/abs/2405.16830v2)|null|
|**2024-05-27**|**Unified Editing of Panorama, 3D Scenes, and Videos Through Disentangled Self-Attention Injection**|Gihyun Kwon et.al.|[2405.16823v1](http://arxiv.org/abs/2405.16823v1)|null|
|**2024-05-27**|**Perturbation-Restrained Sequential Model Editing**|Jun-Yu Ma et.al.|[2405.16821v1](http://arxiv.org/abs/2405.16821v1)|null|
|**2024-05-27**|**Laboratory-Scale AI: Open-Weight Models are Competitive with ChatGPT Even in Low-Resource Settings**|Robert Wolfe et.al.|[2405.16820v1](http://arxiv.org/abs/2405.16820v1)|null|
|**2024-05-27**|**Performance evaluation of Reddit Comments using Machine Learning and Natural Language Processing methods in Sentiment Analysis**|Xiaoxia Zhang et.al.|[2405.16810v2](http://arxiv.org/abs/2405.16810v2)|null|
|**2024-05-27**|**Entity Alignment with Noisy Annotations from Large Language Models**|Shengyuan Chen et.al.|[2405.16806v2](http://arxiv.org/abs/2405.16806v2)|[link](https://github.com/chensycn/llm4ea_official)|
|**2024-05-27**|**AutoCV: Empowering Reasoning with Automated Process Labeling via Confidence Variation**|Jianqiao Lu et.al.|[2405.16802v2](http://arxiv.org/abs/2405.16802v2)|[link](https://github.com/rookie-joe/autocv)|
|**2024-05-27**|**TAGA: Text-Attributed Graph Self-Supervised Learning by Synergizing Graph and Text Mutual Transformations**|Zheng Zhang et.al.|[2405.16800v1](http://arxiv.org/abs/2405.16800v1)|null|
|**2024-05-27**|**A Real-Time Voice Activity Detection Based On Lightweight Neural**|Jidong Jia et.al.|[2405.16797v1](http://arxiv.org/abs/2405.16797v1)|null|
|**2024-05-27**|**Laurel: Generating Dafny Assertions Using Large Language Models**|Eric Mugnier et.al.|[2405.16792v1](http://arxiv.org/abs/2405.16792v1)|null|
|**2024-05-27**|**TrojFM: Resource-efficient Backdoor Attacks against Very Large Foundation Models**|Yuzhou. Nie et.al.|[2405.16783v1](http://arxiv.org/abs/2405.16783v1)|null|
|**2024-05-27**|**Reframing the Relationship in Out-of-Distribution Detection**|YuXiao Lee et.al.|[2405.16766v1](http://arxiv.org/abs/2405.16766v1)|null|
|**2024-05-27**|**Masked Face Recognition with Generative-to-Discriminative Representations**|Shiming Ge et.al.|[2405.16761v1](http://arxiv.org/abs/2405.16761v1)|null|

#### Abstracts
##### **Matryoshka Multimodal Models**
2405.17430v1 by Mu Cai, Jianwei Yang, Jianfeng Gao, Yong Jae Lee

Large Multimodal Models (LMMs) such as LLaVA have shown strong performance in
visual-linguistic reasoning. These models first embed images into a fixed large
number of visual tokens and then feed them into a Large Language Model (LLM).
However, this design causes an excessive number of tokens for dense visual
scenarios such as high-resolution images and videos, leading to great
inefficiency. While token pruning/merging methods do exist, they produce a
single length output for each image and do not afford flexibility in trading
off information density v.s. efficiency. Inspired by the concept of Matryoshka
Dolls, we propose M3: Matryoshka Multimodal Models, which learns to represent
visual content as nested sets of visual tokens that capture information across
multiple coarse-to-fine granularities. Our approach offers several unique
benefits for LMMs: (1) One can explicitly control the visual granularity per
test instance during inference, e.g. , adjusting the number of tokens used to
represent an image based on the anticipated complexity or simplicity of the
content; (2) M3 provides a framework for analyzing the granularity needed for
existing datasets, where we find that COCO-style benchmarks only need around ~9
visual tokens to obtain accuracy similar to that of using all 576 tokens; (3)
Our approach provides a foundation to explore the best trade-off between
performance and visual token length at sample level, where our investigation
reveals that a large gap exists between the oracle upper bound and current
fixed-scale representations.

摘要：大型多模態模型 (LMM) 例如 LLaVA 已在視覺語言推理中展現強勁的效能。這些模型會先將影像嵌入固定大量的視覺代碼，再將它們輸入大型語言模型 (LLM)。然而，此設計會導致過多的代碼用於高解析度影像和影片等密集視覺場景，造成極大的低效率。儘管有代碼剪裁/合併方法，但它們會為每張影像產生單一長度的輸出，且無法靈活地權衡資訊密度與效率。我們受到俄羅斯娃娃的概念啟發，提出 M3：俄羅斯娃娃多模態模型，它學會將視覺內容表示為嵌套的視覺代碼集合，捕捉跨越多種粗略到精細粒度範圍的資訊。我們的方法為 LMM 提供了幾個獨特的優點：(1) 在推論期間，可以明確控制每個測試實例的視覺粒度，例如調整用於表示影像的代碼數量，根據預期的內容複雜度或簡單度進行調整；(2) M3 提供了一個分析現有資料集所需粒度的架構，我們發現 COCO 樣式的基準只需約 9 個視覺代碼即可獲得與使用所有 576 個代碼類似的準確度；(3) 我們的方法提供了一個基礎，用於探索在樣本層級中效能與視覺代碼長度之間的最佳權衡，我們的調查顯示，預言機上限和目前的固定比例表示之間存在很大的差距。

##### **NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models**
2405.17428v1 by Chankyu Lee, Rajarshi Roy, Mengyao Xu, Jonathan Raiman, Mohammad Shoeybi, Bryan Catanzaro, Wei Ping

Decoder-only large language model (LLM)-based embedding models are beginning
to outperform BERT or T5-based embedding models in general-purpose text
embedding tasks, including dense vector-based retrieval. In this work, we
introduce the NV-Embed model with a variety of architectural designs and
training procedures to significantly enhance the performance of LLM as a
versatile embedding model, while maintaining its simplicity and
reproducibility. For model architecture, we propose a latent attention layer to
obtain pooled embeddings, which consistently improves retrieval and downstream
task accuracy compared to mean pooling or using the last <EOS> token embedding
from LLMs. To enhance representation learning, we remove the causal attention
mask of LLMs during contrastive training. For model training, we introduce a
two-stage contrastive instruction-tuning method. It first applies contrastive
training with instructions on retrieval datasets, utilizing in-batch negatives
and curated hard negative examples. At stage-2, it blends various non-retrieval
datasets into instruction tuning, which not only enhances non-retrieval task
accuracy but also improves retrieval performance. Combining these techniques,
our NV-Embed model, using only publicly available data, has achieved a
record-high score of 69.32, ranking No. 1 on the Massive Text Embedding
Benchmark (MTEB) (as of May 24, 2024), with 56 tasks, encompassing retrieval,
reranking, classification, clustering, and semantic textual similarity tasks.
Notably, our model also attains the highest score of 59.36 on 15 retrieval
tasks in the MTEB benchmark (also known as BEIR). We will open-source the model
at: https://huggingface.co/nvidia/NV-Embed-v1.

摘要：<paragraph>僅解碼器的大語言模型 (LLM) 為基礎的嵌入模型正開始
在一般用途文字嵌入任務中超越 BERT 或 T5 為基礎的嵌入模型，包括密集向量為基礎的檢索。在此研究中，我們
引入了 NV-Embed 模型，其具備各種架構設計和
訓練程序，以顯著提升 LLM 的效能，使其成為一個多功能的嵌入模型，同時維持其簡潔性和
可複製性。對於模型架構，我們提出一個潛在注意力層，以取得匯集嵌入，與平均匯集或使用 LLM 的最後一個 <EOS> 代號嵌入相比，這持續改善檢索和下游
任務的準確度。為了加強表徵學習，我們在對比訓練期間移除了 LLM 的因果注意力遮罩。對於模型訓練，我們引入了
一個兩階段對比指令微調方法。它首先對檢索資料集中的指令套用對比訓練，利用批次內負例和策劃的困難負例。在第 2 階段，它將各種非檢索
資料集混合到指令微調中，這不僅加強了非檢索任務的準確度，也改善了檢索效能。結合這些技術，我們的 NV-Embed 模型僅使用公開可取得的資料，在 Massive Text Embedding Benchmark (MTEB)（截至 2024 年 5 月 24 日）中獲得了 69.32 的破紀錄高分，排名第 1，涵蓋了 56 個任務，包含檢索、重新排名、分類、分群和語義文本相似度任務。
值得注意的是，我們的模型也在 MTEB 基準測試（也稱為 BEIR）中的 15 個檢索任務中獲得了 59.36 的最高分。我們將在以下網址開放模型原始碼：https://huggingface.co/nvidia/NV-Embed-v1。</paragraph>

##### **Privacy-Aware Visual Language Models**
2405.17423v1 by Laurens Samson, Nimrod Barazani, Sennay Ghebreab, Yuki M. Asano

This paper aims to advance our understanding of how Visual Language Models
(VLMs) handle privacy-sensitive information, a crucial concern as these
technologies become integral to everyday life. To this end, we introduce a new
benchmark PrivBench, which contains images from 8 sensitive categories such as
passports, or fingerprints. We evaluate 10 state-of-the-art VLMs on this
benchmark and observe a generally limited understanding of privacy,
highlighting a significant area for model improvement. Based on this we
introduce PrivTune, a new instruction-tuning dataset aimed at equipping VLMs
with knowledge about visual privacy. By tuning two pretrained VLMs, TinyLLaVa
and MiniGPT-v2, on this small dataset, we achieve strong gains in their ability
to recognize sensitive content, outperforming even GPT4-V. At the same time, we
show that privacy-tuning only minimally affects the VLMs performance on
standard benchmarks such as VQA. Overall, this paper lays out a crucial
challenge for making VLMs effective in handling real-world data safely and
provides a simple recipe that takes the first step towards building
privacy-aware VLMs.

摘要：本文旨在促進我們對視覺語言模型 (VLM) 如何處理隱私敏感資訊的理解，這項技術已成為日常生活不可或缺的一部分，因此這項議題至關重要。為此，我們引進了一個新的基準 PrivBench，其中包含來自 8 個敏感類別的圖像，例如護照或指紋。我們針對這個基準評估了 10 個最先進的 VLM，並觀察到它們對隱私的理解普遍有限，這突顯了模型改進的重要領域。基於此，我們引入了 PrivTune，這是一個新的指令調整資料集，旨在為 VLM 提供有關視覺隱私的知識。透過針對這個小資料集調整兩個預訓練的 VLM，TinyLLaVa 和 MiniGPT-v2，我們大幅提升了它們辨識敏感內容的能力，甚至超越了 GPT4-V。同時，我們證明了隱私調整僅對 VLM 在標準基準（例如 VQA）上的效能產生極小的影響。整體而言，本文提出了讓 VLM 能夠安全地處理真實世界資料的關鍵挑戰，並提供了一個簡單的秘訣，作為建構具隱私意識的 VLM 的第一步。

##### **Hardness-Aware Scene Synthesis for Semi-Supervised 3D Object Detection**
2405.17422v1 by Shuai Zeng, Wenzhao Zheng, Jiwen Lu, Haibin Yan

3D object detection aims to recover the 3D information of concerning objects
and serves as the fundamental task of autonomous driving perception. Its
performance greatly depends on the scale of labeled training data, yet it is
costly to obtain high-quality annotations for point cloud data. While
conventional methods focus on generating pseudo-labels for unlabeled samples as
supplements for training, the structural nature of 3D point cloud data
facilitates the composition of objects and backgrounds to synthesize realistic
scenes. Motivated by this, we propose a hardness-aware scene synthesis (HASS)
method to generate adaptive synthetic scenes to improve the generalization of
the detection models. We obtain pseudo-labels for unlabeled objects and
generate diverse scenes with different compositions of objects and backgrounds.
As the scene synthesis is sensitive to the quality of pseudo-labels, we further
propose a hardness-aware strategy to reduce the effect of low-quality
pseudo-labels and maintain a dynamic pseudo-database to ensure the diversity
and quality of synthetic scenes. Extensive experimental results on the widely
used KITTI and Waymo datasets demonstrate the superiority of the proposed HASS
method, which outperforms existing semi-supervised learning methods on 3D
object detection. Code: https://github.com/wzzheng/HASS.

摘要：3D 物件偵測旨在恢復相關物件的 3D 資訊，並作為自動駕駛感知的基本任務。其效能很大程度取決於標籤訓練資料的規模，然而取得高品質的點雲資料註解代價高昂。雖然傳統方法專注於為未標籤樣本產生偽標籤作為訓練的補充，但 3D 點雲資料的結構特性有助於組成物件和背景，以合成逼真的場景。基於此，我們提出一個硬度感知場景合成 (HASS) 方法，以產生自適應合成場景，以改善偵測模型的泛化。我們為未標籤物件取得偽標籤，並產生具有不同物件和背景組成的多元場景。由於場景合成對偽標籤的品質很敏感，我們進一步提出一個硬度感知策略，以減少低品質偽標籤的影響，並維護一個動態偽資料庫，以確保合成場景的多元性和品質。在廣泛使用的 KITTI 和 Waymo 資料集上進行的廣泛實驗結果證明了所提出的 HASS 方法的優越性，它在 3D 物件偵測方面優於現有的半監督式學習方法。程式碼：https://github.com/wzzheng/HASS。

##### **MultiOOD: Scaling Out-of-Distribution Detection for Multiple Modalities**
2405.17419v1 by Hao Dong, Yue Zhao, Eleni Chatzi, Olga Fink

Detecting out-of-distribution (OOD) samples is important for deploying
machine learning models in safety-critical applications such as autonomous
driving and robot-assisted surgery. Existing research has mainly focused on
unimodal scenarios on image data. However, real-world applications are
inherently multimodal, which makes it essential to leverage information from
multiple modalities to enhance the efficacy of OOD detection. To establish a
foundation for more realistic Multimodal OOD Detection, we introduce the
first-of-its-kind benchmark, MultiOOD, characterized by diverse dataset sizes
and varying modality combinations. We first evaluate existing unimodal OOD
detection algorithms on MultiOOD, observing that the mere inclusion of
additional modalities yields substantial improvements. This underscores the
importance of utilizing multiple modalities for OOD detection. Based on the
observation of Modality Prediction Discrepancy between in-distribution (ID) and
OOD data, and its strong correlation with OOD performance, we propose the
Agree-to-Disagree (A2D) algorithm to encourage such discrepancy during
training. Moreover, we introduce a novel outlier synthesis method, NP-Mix,
which explores broader feature spaces by leveraging the information from
nearest neighbor classes and complements A2D to strengthen OOD detection
performance. Extensive experiments on MultiOOD demonstrate that training with
A2D and NP-Mix improves existing OOD detection algorithms by a large margin.
Our source code and MultiOOD benchmark are available at
https://github.com/donghao51/MultiOOD.

摘要：<paragraph>偵測異常分佈 (OOD) 樣本對於在安全關鍵應用中部署機器學習模型非常重要，例如自動駕駛和機器人輔助手術。現有研究主要集中於影像資料的單模態場景。然而，真實世界的應用本質上是多模態的，這使得利用來自多模態的資訊來增強 OOD 偵測的效能變得至關重要。為了建立更實際的多模態 OOD 偵測基礎，我們引入了首創基準 MultiOOD，其特點是資料集大小多樣且模態組合變化。我們首先在 MultiOOD 上評估現有的單模態 OOD 偵測演算法，觀察到僅加入額外的模態就會產生顯著的改進。這強調了利用多模態進行 OOD 偵測的重要性。根據分佈內 (ID) 和 OOD 資料之間的模態預測差異的觀察，以及它與 OOD 效能的強相關性，我們提出同意不同意 (A2D) 演算法，以在訓練期間鼓勵這種差異。此外，我們引入了一種新穎的離群值合成方法 NP-Mix，它透過利用來自最近鄰類別的資訊來探索更廣泛的特徵空間，並補充 A2D 以增強 OOD 偵測效能。在 MultiOOD 上進行的廣泛實驗表明，使用 A2D 和 NP-Mix 進行訓練可大幅改善現有的 OOD 偵測演算法。我們的原始程式碼和 MultiOOD 基準可在 https://github.com/donghao51/MultiOOD 取得。</paragraph>

##### **Towards One Model for Classical Dimensionality Reduction: A Probabilistic Perspective on UMAP and t-SNE**
2405.17412v1 by Aditya Ravuri, Neil D. Lawrence

This paper shows that the dimensionality reduction methods, UMAP and t-SNE,
can be approximately recast as MAP inference methods corresponding to a
generalized Wishart-based model introduced in ProbDR. This interpretation
offers deeper theoretical insights into these algorithms, while introducing
tools with which similar dimensionality reduction methods can be studied.

摘要：本文顯示，降維方法 UMAP 和 t-SNE，
可以近似地改寫為對應於 ProbDR 中引入的廣義 Wishart 模型的 MAP 推論方法。這種詮釋提供了對這些演算法更深入的理論見解，同時引入了可以研究類似降維方法的工具。

##### **Spectral Greedy Coresets for Graph Neural Networks**
2405.17404v1 by Mucong Ding, Yinhan He, Jundong Li, Furong Huang

The ubiquity of large-scale graphs in node-classification tasks significantly
hinders the real-world applications of Graph Neural Networks (GNNs). Node
sampling, graph coarsening, and dataset condensation are effective strategies
for enhancing data efficiency. However, owing to the interdependence of graph
nodes, coreset selection, which selects subsets of the data examples, has not
been successfully applied to speed up GNN training on large graphs, warranting
special treatment. This paper studies graph coresets for GNNs and avoids the
interdependence issue by selecting ego-graphs (i.e., neighborhood subgraphs
around a node) based on their spectral embeddings. We decompose the coreset
selection problem for GNNs into two phases: a coarse selection of widely spread
ego graphs and a refined selection to diversify their topologies. We design a
greedy algorithm that approximately optimizes both objectives. Our spectral
greedy graph coreset (SGGC) scales to graphs with millions of nodes, obviates
the need for model pre-training, and applies to low-homophily graphs. Extensive
experiments on ten datasets demonstrate that SGGC outperforms other coreset
methods by a wide margin, generalizes well across GNN architectures, and is
much faster than graph condensation.

摘要：<paragraph>在节点分类任务中，大规模图表的普遍存在极大地阻碍了图神经网络 (GNN) 的实际应用。节点采样、图粗化和数据集浓缩是提高数据效率的有效策略。然而，由于图节点的相互依赖性，选择数据示例子集的核心集选择尚未成功应用于加速大型图上的 GNN 训练，需要特殊处理。本文研究了 GNN 的图核心集，并通过基于其频谱嵌入来选择自我图（即围绕节点的邻域子图）来避免相互依赖问题。我们将 GNN 的核心集选择问题分解为两个阶段：广泛传播的自我图的粗略选择和多样化其拓扑结构的细化选择。我们设计了一种贪婪算法，该算法近似优化了这两个目标。我们的频谱贪婪图核心集 (SGGC) 可扩展到拥有数百万个节点的图，无需模型预训练，并且适用于低同质图。在十个数据集上的广泛实验表明，SGGC 以很大优势优于其他核心集方法，在 GNN 架构中具有良好的泛化性，并且比图浓缩快得多。</paragraph>

##### **A Closer Look at Time Steps is Worthy of Triple Speed-Up for Diffusion Model Training**
2405.17403v1 by Kai Wang, Yukun Zhou, Mingjia Shi, Zhihang Yuan, Yuzhang Shang, Xiaojiang Peng, Hanwang Zhang, Yang You

Training diffusion models is always a computation-intensive task. In this
paper, we introduce a novel speed-up method for diffusion model training,
called, which is based on a closer look at time steps. Our key findings are: i)
Time steps can be empirically divided into acceleration, deceleration, and
convergence areas based on the process increment. ii) These time steps are
imbalanced, with many concentrated in the convergence area. iii) The
concentrated steps provide limited benefits for diffusion training. To address
this, we design an asymmetric sampling strategy that reduces the frequency of
steps from the convergence area while increasing the sampling probability for
steps from other areas. Additionally, we propose a weighting strategy to
emphasize the importance of time steps with rapid-change process increments. As
a plug-and-play and architecture-agnostic approach, SpeeD consistently achieves
3-times acceleration across various diffusion architectures, datasets, and
tasks. Notably, due to its simple design, our approach significantly reduces
the cost of diffusion model training with minimal overhead. Our research
enables more researchers to train diffusion models at a lower cost.

摘要：訓練擴散模型始終是一項運算密集型任務。在本文中，我們介紹了一種名為 SpeeD 的擴散模型訓練加速新方法，它基於對時間步驟的深入探討。我們的關鍵發現如下：i) 基於處理增量，時間步驟可以根據經驗分為加速、減速和收斂區域。ii) 這些時間步驟並不平衡，許多步驟集中在收斂區域。iii) 集中的步驟對擴散訓練提供的優點有限。為了解決這個問題，我們設計了一種非對稱採樣策略，它降低了來自收斂區域的步驟頻率，同時增加了來自其他區域的步驟的採樣機率。此外，我們提出了加權策略，以強調具有快速變化處理增量的時間步驟的重要性。作為一種即插即用且與架構無關的方法，SpeeD 在各種擴散架構、資料集和任務中始終實現 3 倍加速。值得注意的是，由於其設計簡單，我們的做法顯著降低了擴散模型訓練的成本，同時將開銷降至最低。我們的研究使更多研究人員能夠以更低的成本訓練擴散模型。

##### **THREAD: Thinking Deeper with Recursive Spawning**
2405.17402v1 by Philip Schroeder, Nathaniel Morgan, Hongyin Luo, James Glass

Large language models (LLMs) have shown impressive capabilities across
diverse settings, but still struggle as the length and complexity of the
context increases. To address this challenge, we propose Thinking Recursively
and Dynamically (ThReaD). THREAD frames model generation as a thread of
execution that, based on the context, can run to completion or dynamically
spawn new threads. By spawning, threads can offload work (e.g., thinking,
retrieving information) to child threads, which only return tokens needed for
the parent thread to do its work. In effect, this enables the model to adapt,
as needed, the amount of intermediate work used to produce tokens. We apply
THREAD in the settings of LLM task solving and question answering, where the
dynamic threading allows the model to recursively decompose the given task or
question into progressively simpler sub-problems that can be solved by separate
child threads. We test THREAD, implemented using a few-shot learning approach,
on diverse benchmarks for agent tasks and data-grounded question answering.
THREAD achieves state-of-the-art performance with GPT-4 and GPT-3.5 on these
benchmarks, including ALFWorld, TextCraft, and WebShop, along with two new
benchmarks, DataCommons QA and MIMIC-III ICU QA. In addition, THREAD
outperforms existing frameworks by 10% to 50% absolute points with smaller
models, including Llama-3-8b and CodeLlama-7b.

摘要：大型語言模型 (LLM) 已在各種環境中展現令人印象深刻的能力，但隨著內容長度和複雜性的增加，它們仍會面臨挑戰。為了應對這項挑戰，我們提出思考遞迴和動態 (ThReaD) 的概念。THREAD 將模型生成設定為一個執行緒，根據內容，它可以執行到完成或動態產生新的執行緒。透過產生，執行緒可以將工作 (例如思考、擷取資訊) 轉移到子執行緒，子執行緒只會傳回父執行緒執行工作所需的符號。實際上，這讓模型能夠在需要時調整用於產生符號的中間工作量。我們在 LLM 任務解決和問題回答的設定中套用 THREAD，動態執行緒讓模型能夠遞迴分解給定的任務或問題，成為更簡單的子問題，這些子問題可以由個別的子執行緒解決。我們使用少量學習方法實作 THREAD，並在代理人任務和資料基礎問題回答的各種基準上進行測試。THREAD 在這些基準上使用 GPT-4 和 GPT-3.5 達到最先進的效能，包括 ALFWorld、TextCraft 和 WebShop，以及兩個新的基準，DataCommons QA 和 MIMIC-III ICU QA。此外，THREAD 以較小的模型超越現有架構 10% 到 50% 的絕對點數，包括 Llama-3-8b 和 CodeLlama-7b。

##### **Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability**
2405.17398v1 by Shenyuan Gao, Jiazhi Yang, Li Chen, Kashyap Chitta, Yihang Qiu, Andreas Geiger, Jun Zhang, Hongyang Li

World models can foresee the outcomes of different actions, which is of
paramount importance for autonomous driving. Nevertheless, existing driving
world models still have limitations in generalization to unseen environments,
prediction fidelity of critical details, and action controllability for
flexible application. In this paper, we present Vista, a generalizable driving
world model with high fidelity and versatile controllability. Based on a
systematic diagnosis of existing methods, we introduce several key ingredients
to address these limitations. To accurately predict real-world dynamics at high
resolution, we propose two novel losses to promote the learning of moving
instances and structural information. We also devise an effective latent
replacement approach to inject historical frames as priors for coherent
long-horizon rollouts. For action controllability, we incorporate a versatile
set of controls from high-level intentions (command, goal point) to low-level
maneuvers (trajectory, angle, and speed) through an efficient learning
strategy. After large-scale training, the capabilities of Vista can seamlessly
generalize to different scenarios. Extensive experiments on multiple datasets
show that Vista outperforms the most advanced general-purpose video generator
in over 70% of comparisons and surpasses the best-performing driving world
model by 55% in FID and 27% in FVD. Moreover, for the first time, we utilize
the capacity of Vista itself to establish a generalizable reward for real-world
action evaluation without accessing the ground truth actions.

摘要：世界模型可以預測不同動作的結果，這對於自動駕駛至關重要。儘管如此，現有的駕駛世界模型在推廣到未見環境、關鍵細節的預測保真度和靈活應用動作可控性方面仍然存在局限性。在本文中，我們展示了 Vista，一個具有高保真度和多功能可控性的可推廣駕駛世界模型。基於對現有方法的系統診斷，我們引入了幾個關鍵要素來解決這些限制。為了準確預測高解析度的真實世界動態，我們提出了兩種新損失來促進移動實例和結構信息的學習。我們還設計了一種有效的潛在替換方法，將歷史幀作為連貫長時程滾動的先驗注入。對於動作可控性，我們通過一種有效的學習策略，將來自高層級意圖（命令、目標點）到低層級操作（軌跡、角度和速度）的多功能控制集合整合起來。經過大規模訓練後，Vista 的功能可以無縫推廣到不同的場景。在多個數據集上的廣泛實驗表明，Vista 在超過 70% 的比較中優於最先進的通用視頻生成器，並且在 FID 中比性能最好的駕駛世界模型高出 55%，在 FVD 中高出 27%。此外，我們首次利用 Vista 本身的能力為真實世界的動作評估建立一個可推廣的獎勵，而無需訪問真實的動作。

##### **The Expressive Capacity of State Space Models: A Formal Language Perspective**
2405.17394v1 by Yash Sarrof, Yana Veitsman, Michael Hahn

Recently, recurrent models based on linear state space models (SSMs) have
shown promising performance in language modeling (LM), competititve with
transformers. However, there is little understanding of the in-principle
abilities of such models, which could provide useful guidance to the search for
better LM architectures. We present a comprehensive theoretical study of the
capacity of such SSMs as it compares to that of transformers and traditional
RNNs. We find that SSMs and transformers have overlapping but distinct
strengths. In star-free state tracking, SSMs implement straightforward and
exact solutions to problems that transformers struggle to represent exactly.
They can also model bounded hierarchical structure with optimal memory even
without simulating a stack. On the other hand, we identify a design choice in
current SSMs that limits their expressive power. We discuss implications for
SSM and LM research, and verify results empirically on a recent SSM, Mamba.

摘要：近期，基於線性狀態空間模型 (SSM) 的遞迴模型
在語言模型 (LM) 中展現出可觀的效能，與
Transformer模型不相上下。然而，對於此類模型的原則性
能力了解甚少，而這可能會為尋找
更好的 LM 架構提供有用的指導。我們提出了一項對
此類 SSM 容量的全面理論研究，並將其與Transformer模型和傳統
RNN 進行比較。我們發現 SSM 和Transformer模型的優勢重疊但截然不同。在無星狀態追蹤中，SSM 實作了直接且
精確的解決方案，而Transformer模型難以精確表示這些問題。
它們甚至可以在不模擬堆疊的情況下，以最佳記憶體建構有界的階層結構。另一方面，我們找出
目前 SSM 中的設計選擇限制了其表現能力。我們討論了
SSM 和 LM 研究的含意，並在最近的 SSM，Mamba，上驗證結果。

##### **KSW: Khmer Stop Word based Dictionary for Keyword Extraction**
2405.17390v1 by Nimol Thuon, Wangrui Zhang, Sada Thuon

This paper introduces KSW, a Khmer-specific approach to keyword extraction
that leverages a specialized stop word dictionary. Due to the limited
availability of natural language processing resources for the Khmer language,
effective keyword extraction has been a significant challenge. KSW addresses
this by developing a tailored stop word dictionary and implementing a
preprocessing methodology to remove stop words, thereby enhancing the
extraction of meaningful keywords. Our experiments demonstrate that KSW
achieves substantial improvements in accuracy and relevance compared to
previous methods, highlighting its potential to advance Khmer text processing
and information retrieval. The KSW resources, including the stop word
dictionary, are available at the following GitHub repository:
(https://github.com/back-kh/KSWv2-Khmer-Stop-Word-based-Dictionary-for-Keyword-Extraction.git).

摘要：這篇論文介紹了 KSW，一種利用專門停用詞詞典的專門用於高棉語的關鍵字萃取方法。由於高棉語的自然語言處理資源有限，因此有效的關鍵字萃取一直是一項重大的挑戰。KSW 透過開發一個量身打造的停用詞詞典並實作一個預處理方法來移除停用詞，進而增強有意義關鍵字的萃取，來解決這個問題。我們的實驗證明，與先前的各種方法相比，KSW 在準確度和相關性方面都有顯著的提升，突顯了它在推進高棉語文本處理和資訊檢索方面的潛力。KSW 資源，包括停用詞詞典，可以在以下 GitHub 儲存庫中取得：(https://github.com/back-kh/KSWv2-Khmer-Stop-Word-based-Dictionary-for-Keyword-Extraction.git)。

##### **MindMerger: Efficient Boosting LLM Reasoning in non-English Languages**
2405.17386v1 by Zixian Huang, Wenhao Zhu, Gong Cheng, Lei Li, Fei Yuan

Reasoning capabilities are crucial for Large Language Models (LLMs), yet a
notable gap exists between English and non-English languages. To bridge this
disparity, some works fine-tune LLMs to relearn reasoning capabilities in
non-English languages, while others replace non-English inputs with an external
model's outputs such as English translation text to circumvent the challenge of
LLM understanding non-English. Unfortunately, these methods often underutilize
the built-in skilled reasoning and useful language understanding capabilities
of LLMs. In order to better utilize the minds of reasoning and language
understanding in LLMs, we propose a new method, namely MindMerger, which merges
LLMs with the external language understanding capabilities from multilingual
models to boost the multilingual reasoning performance. Furthermore, a two-step
training scheme is introduced to first train to embeded the external
capabilities into LLMs and then train the collaborative utilization of the
external capabilities and the built-in capabilities in LLMs. Experiments on
three multilingual reasoning datasets and a language understanding dataset
demonstrate that MindMerger consistently outperforms all baselines, especially
in low-resource languages. Without updating the parameters of LLMs, the average
accuracy improved by 6.7% and 8.0% across all languages and low-resource
languages on the MGSM dataset, respectively.

摘要：推理能力對於大型語言模型 (LLM) 至關重要，但英語與非英語語言之間存在顯著的差距。為了彌合這種差距，一些作品微調 LLM 以重新學習非英語語言中的推理能力，而另一些作品則用外部模型的輸出（例如英語翻譯文字）取代非英語輸入，以規避 LLM 理解非英語的挑戰。不幸的是，這些方法通常無法充分利用 LLM 內建的熟練推理和有用的語言理解能力。為了更好地利用 LLM 中的推理和語言理解思維，我們提出了一種新方法，即 MindMerger，它將 LLM 與多語言模型中的外部語言理解能力合併，以提升多語言推理效能。此外，引入了兩步驟訓練方案，首先訓練將外部能力嵌入 LLM 中，然後訓練 LLM 中外部能力和內建能力的協作利用。在三個多語言推理數據集和一個語言理解數據集上的實驗表明，MindMerger 在所有基準中始終表現出色，特別是在低資源語言中。在不更新 LLM 參數的情況下，在 MGSM 數據集上，所有語言和低資源語言的平均準確度分別提高了 6.7% 和 8.0%。

##### **Unlocking the Secrets of Linear Complexity Sequence Model from A Unified Perspective**
2405.17383v1 by Zhen Qin, Xuyang Shen, Dong Li, Weigao Sun, Stan Birchfield, Richard Hartley, Yiran Zhong

We present the Linear Complexity Sequence Model (LCSM), a comprehensive
solution that unites various sequence modeling techniques with linear
complexity, including linear attention, state space model, long convolution,
and linear RNN, within a single framework. The goal is to enhance comprehension
of these models by analyzing the impact of each component from a cohesive and
streamlined viewpoint. Specifically, we segment the modeling processes of these
models into three distinct stages: Expand, Oscillation, and Shrink (EOS), with
each model having its own specific settings. The Expand stage involves
projecting the input signal onto a high-dimensional memory state. This is
followed by recursive operations performed on the memory state in the
Oscillation stage. Finally, the memory state is projected back to a
low-dimensional space in the Shrink stage. We perform comprehensive experiments
to analyze the impact of different stage settings on language modeling and
retrieval tasks. Our results show that data-driven methods are crucial for the
effectiveness of the three stages in language modeling, whereas hand-crafted
methods yield better performance in retrieval tasks.

摘要：我們提出線性複雜度序列模型 (LCSM)，這是一個全面的解決方案，它將各種序列建模技術與線性複雜度結合在一個單一架構中，包括線性注意力、狀態空間模型、長卷積和線性 RNN。目標是透過從一個有凝聚力和流暢的觀點分析每個組成的影響，來增強對這些模型的理解。具體來說，我們將這些模型的建模過程分為三個不同的階段：擴展、振盪和收縮 (EOS)，每個模型都有其特定的設定。擴展階段涉及將輸入訊號投射到高維記憶狀態。接下來在振盪階段對記憶狀態執行遞迴運算。最後，在收縮階段將記憶狀態投射回低維空間。我們執行全面的實驗，以分析不同階段設定對語言建模和擷取任務的影響。我們的結果表明，資料驅動的方法對於語言建模中三個階段的有效性至關重要，而手工方法在擷取任務中產生更好的效能。

##### **ReMoDetect: Reward Models Recognize Aligned LLM's Generations**
2405.17382v1 by Hyunseok Lee, Jihoon Tack, Jinwoo Shin

The remarkable capabilities and easy accessibility of large language models
(LLMs) have significantly increased societal risks (e.g., fake news
generation), necessitating the development of LLM-generated text (LGT)
detection methods for safe usage. However, detecting LGTs is challenging due to
the vast number of LLMs, making it impractical to account for each LLM
individually; hence, it is crucial to identify the common characteristics
shared by these models. In this paper, we draw attention to a common feature of
recent powerful LLMs, namely the alignment training, i.e., training LLMs to
generate human-preferable texts. Our key finding is that as these aligned LLMs
are trained to maximize the human preferences, they generate texts with higher
estimated preferences even than human-written texts; thus, such texts are
easily detected by using the reward model (i.e., an LLM trained to model human
preference distribution). Based on this finding, we propose two training
schemes to further improve the detection ability of the reward model, namely
(i) continual preference fine-tuning to make the reward model prefer aligned
LGTs even further and (ii) reward modeling of Human/LLM mixed texts (a
rephrased texts from human-written texts using aligned LLMs), which serves as a
median preference text corpus between LGTs and human-written texts to learn the
decision boundary better. We provide an extensive evaluation by considering six
text domains across twelve aligned LLMs, where our method demonstrates
state-of-the-art results. Code is available at
https://github.com/hyunseoklee-ai/reward_llm_detect.

摘要：大型語言模型 (LLM) 的卓越功能和易於取得，大幅增加了社會風險（例如，假新聞產生），這使得必須開發 LLM 生成的文字 (LGT) 偵測方法，以安全使用。然而，偵測 LGT 具有挑戰性，原因在於 LLM 數量龐大，要個別考量每個 LLM 都是不切實際的；因此，找出這些模型共有的特徵至關重要。在本文中，我們將注意力集中在近期強大的 LLM 的共同特徵，即對齊訓練，也就是訓練 LLM 產生人類偏好的文字。我們的關鍵發現是，由於這些對齊的 LLM 經過訓練以最大化人類偏好，因此它們產生的文字估計偏好甚至高於人類撰寫的文字；因此，此類文字很容易使用回饋模型（也就是訓練 LLM 以建構人類偏好分佈）來偵測。基於此發現，我們提出兩種訓練架構，以進一步提升回饋模型的偵測能力，即 (i) 持續偏好微調，讓回饋模型進一步偏好對齊的 LGT，以及 (ii) 人類/LLM 混合文字的回饋建模（使用對齊的 LLM 從人類撰寫的文字重新表述的文字），這作為 LGT 和人類撰寫的文字之間的偏好文字語料庫的中間值，以更好地學習決策邊界。我們考量六個文本領域和十二個對齊的 LLM，提供廣泛的評估，而我們的模型展示了最先進的結果。程式碼可在 https://github.com/hyunseoklee-ai/reward_llm_detect 取得。

##### **Various Lengths, Constant Speed: Efficient Language Modeling with Lightning Attention**
2405.17381v1 by Zhen Qin, Weigao Sun, Dong Li, Xuyang Shen, Weixuan Sun, Yiran Zhong

We present Lightning Attention, the first linear attention implementation
that maintains a constant training speed for various sequence lengths under
fixed memory consumption. Due to the issue with cumulative summation operations
(cumsum), previous linear attention implementations cannot achieve their
theoretical advantage in a casual setting. However, this issue can be
effectively solved by utilizing different attention calculation strategies to
compute the different parts of attention. Specifically, we split the attention
calculation into intra-blocks and inter-blocks and use conventional attention
computation for intra-blocks and linear attention kernel tricks for
inter-blocks. This eliminates the need for cumsum in the linear attention
calculation. Furthermore, a tiling technique is adopted through both forward
and backward procedures to take full advantage of the GPU hardware. To enhance
accuracy while preserving efficacy, we introduce TransNormerLLM (TNL), a new
architecture that is tailored to our lightning attention. We conduct rigorous
testing on standard and self-collected datasets with varying model sizes and
sequence lengths. TNL is notably more efficient than other language models. In
addition, benchmark results indicate that TNL performs on par with
state-of-the-art LLMs utilizing conventional transformer structures. The source
code is released at github.com/OpenNLPLab/TransnormerLLM.

摘要：<paragraph>我們提出 Lightning Attention，這是第一個線性注意力實作，在固定記憶體消耗下，可維持各種序列長度的恆定訓練速度。由於累積總和運算 (cumsum) 的問題，先前的線性注意力實作無法在休閒設定中獲得理論優勢。然而，這個問題可以用不同的注意力計算策略來有效解決，以計算注意力的不同部分。具體來說，我們將注意力計算拆分為區塊內和區塊間，並對區塊內使用傳統的注意力計算，對區塊間使用線性注意力核技巧。這消除了線性注意力計算中對 cumsum 的需求。此外，在正向和反向程序中都採用平鋪技術，以充分利用 GPU 硬體。為了在保留效能的同時提升準確度，我們引入了 TransNormerLLM (TNL)，這是一種針對我們的 lightning attention 量身打造的新架構。我們對標準和自收集的資料集進行嚴格的測試，並採用不同的模型大小和序列長度。TNL 明顯比其他語言模型更有效率。此外，基準測試結果顯示，TNL 的效能與使用傳統Transformer結構的最新 LLM 相當。原始碼已發布在 github.com/OpenNLPLab/TransnormerLLM。</paragraph>

##### **Federating Dynamic Models using Early-Exit Architectures for Automatic Speech Recognition on Heterogeneous Clients**
2405.17376v1 by Mohamed Nabih Ali, Alessio Brutti, Daniele Falavigna

Automatic speech recognition models require large amounts of speech
recordings for training. However, the collection of such data often is
cumbersome and leads to privacy concerns. Federated learning has been widely
used as an effective decentralized technique that collaboratively learns a
shared prediction model while keeping the data local on different clients.
Unfortunately, client devices often feature limited computation and
communication resources leading to practical difficulties for large models. In
addition, the heterogeneity that characterizes edge devices makes it
sub-optimal to generate a single model that fits all of them. Differently from
the recent literature, where multiple models with different architectures are
used, in this work, we propose using dynamical architectures which, employing
early-exit solutions, can adapt their processing (i.e. traversed layers)
depending on the input and on the operation conditions. This solution falls in
the realm of partial training methods and brings two benefits: a single model
is used on a variety of devices; federating the models after local training is
straightforward. Experiments on public datasets show that our proposed approach
is effective and can be combined with basic federated learning strategies.

摘要：自動語音辨識模型需要大量的語音錄音進行訓練。然而，此類資料的收集通常很繁瑣，並導致隱私問題。聯邦學習已被廣泛用作一種有效的去中心化技術，可以在保持資料在不同客戶端本機的同時，協作學習一個共享預測模型。不幸的是，客戶端裝置通常具有有限的運算和通訊資源，導致實際上難以使用大型模型。此外，邊緣裝置的異質性使得產生一個適合所有裝置的單一模型並非最佳。與最近使用具有不同架構的多個模型的文獻不同，在這項工作中，我們建議使用動態架構，它採用早期退出解決方案，可以根據輸入和操作條件調整其處理（即遍歷的層）。此解決方案屬於部分訓練方法的範疇，並帶來兩個好處：一個模型可用於各種裝置；在本地訓練後聯合模型非常簡單。對公開資料集的實驗表明，我們提出的方法是有效的，並且可以與基本的聯邦學習策略相結合。

##### **BehaviorGPT: Smart Agent Simulation for Autonomous Driving with Next-Patch Prediction**
2405.17372v1 by Zikang Zhou, Haibo Hu, Xinhong Chen, Jianping Wang, Nan Guan, Kui Wu, Yung-Hui Li, Yu-Kai Huang, Chun Jason Xue

Simulating realistic interactions among traffic agents is crucial for
efficiently validating the safety of autonomous driving systems. Existing
leading simulators primarily use an encoder-decoder structure to encode the
historical trajectories for future simulation. However, such a paradigm
complicates the model architecture, and the manual separation of history and
future trajectories leads to low data utilization. To address these challenges,
we propose Behavior Generative Pre-trained Transformers (BehaviorGPT), a
decoder-only, autoregressive architecture designed to simulate the sequential
motion of multiple agents. Crucially, our approach discards the traditional
separation between "history" and "future," treating each time step as the
"current" one, resulting in a simpler, more parameter- and data-efficient
design that scales seamlessly with data and computation. Additionally, we
introduce the Next-Patch Prediction Paradigm (NP3), which enables models to
reason at the patch level of trajectories and capture long-range
spatial-temporal interactions. BehaviorGPT ranks first across several metrics
on the Waymo Sim Agents Benchmark, demonstrating its exceptional performance in
multi-agent and agent-map interactions. We outperformed state-of-the-art models
with a realism score of 0.741 and improved the minADE metric to 1.540, with an
approximately 91.6% reduction in model parameters.

摘要：模擬交通代理之間的真實互動對於有效驗證自動駕駛系統的安全性至關重要。現有的領先模擬器主要使用編碼器-解碼器結構來編碼歷史軌跡以進行未來模擬。然而，這樣的範例使模型架構複雜化，並且歷史和未來軌跡的手動分離導致資料利用率低。為了應對這些挑戰，我們提出了行為生成式預訓練Transformer (BehaviorGPT)，這是一種僅解碼器、自迴歸架構，旨在模擬多個代理的序列運動。至關重要的是，我們的做法捨棄了「歷史」和「未來」之間的傳統區分，將每個時間步驟視為「當前」步驟，從而產生一個更簡單、更具參數和資料效率的設計，可與資料和運算無縫擴展。此外，我們引入了下一個區塊預測範例 (NP3)，使模型能夠在軌跡的區塊層級進行推理，並捕捉長程時空互動。BehaviorGPT 在 Waymo Sim Agents Benchmark 的多項指標中排名第一，證明了其在多代理和代理地圖互動中的出色效能。我們以 0.741 的真實感得分優於最先進的模型，並將 minADE 指標提升至 1.540，模型參數減少了約 91.6%。

##### **A One-Layer Decoder-Only Transformer is a Two-Layer RNN: With an Application to Certified Robustness**
2405.17361v1 by Yuhao Zhang, Aws Albarghouthi, Loris D'Antoni

This paper reveals a key insight that a one-layer decoder-only Transformer is
equivalent to a two-layer Recurrent Neural Network (RNN). Building on this
insight, we propose ARC-Tran, a novel approach for verifying the robustness of
decoder-only Transformers against arbitrary perturbation spaces. Compared to
ARC-Tran, current robustness verification techniques are limited either to
specific and length-preserving perturbations like word substitutions or to
recursive models like LSTMs. ARC-Tran addresses these limitations by
meticulously managing position encoding to prevent mismatches and by utilizing
our key insight to achieve precise and scalable verification. Our evaluation
shows that ARC-Tran (1) trains models more robust to arbitrary perturbation
spaces than those produced by existing techniques and (2) shows high
certification accuracy of the resulting models.

摘要：這篇論文揭示了一個關鍵見解，即僅有解碼器的單層 Transformer 等同於雙層遞迴神經網路 (RNN)。基於這個見解，我們提出 ARC-Tran，一種驗證僅有解碼器的 Transformer 對任意擾動空間的穩健性的新方法。與 ARC-Tran 相比，目前的穩健性驗證技術僅限於特定且長度保持不變的擾動，例如單字替換，或遞迴模型，例如 LSTM。ARC-Tran 透過仔細管理位置編碼來防止不匹配，並利用我們的關鍵見解來實現精確且可擴充的驗證，從而解決這些限制。我們的評估顯示，ARC-Tran (1) 訓練出的模型比現有技術產生的模型對任意擾動空間更穩健，且 (2) 顯示出對結果模型的高驗證準確度。

##### **Rethinking Transformers in Solving POMDPs**
2405.17358v1 by Chenhao Lu, Ruizhe Shi, Yuyao Liu, Kaizhe Hu, Simon S. Du, Huazhe Xu

Sequential decision-making algorithms such as reinforcement learning (RL) in
real-world scenarios inevitably face environments with partial observability.
This paper scrutinizes the effectiveness of a popular architecture, namely
Transformers, in Partially Observable Markov Decision Processes (POMDPs) and
reveals its theoretical limitations. We establish that regular languages, which
Transformers struggle to model, are reducible to POMDPs. This poses a
significant challenge for Transformers in learning POMDP-specific inductive
biases, due to their lack of inherent recurrence found in other models like
RNNs. This paper casts doubt on the prevalent belief in Transformers as
sequence models for RL and proposes to introduce a point-wise recurrent
structure. The Deep Linear Recurrent Unit (LRU) emerges as a well-suited
alternative for Partially Observable RL, with empirical results highlighting
the sub-optimal performance of the Transformer and considerable strength of
LRU.

摘要：在現實世界的場景中，諸如強化學習 (RL) 等順序決策演算法不可避免地面臨具有部分可觀察性的環境。本文審視了在部分可觀察馬可夫決策過程 (POMDP) 中一種流行的架構，即 Transformer 的有效性，並揭示其理論限制。我們建立了 Transformer 難以建模的正則語言可簡化為 POMDP。由於 Transformer 缺乏在其他模型（如 RNN）中發現的固有遞迴，因此這對 Transformer 在學習 POMDP 特定的歸納偏差方面構成重大挑戰。本文對 Transformer 作為 RL 的序列模型普遍存在的信念提出質疑，並建議引入點狀遞迴結構。深度線性遞迴單元 (LRU) 成為部分可觀察 RL 的合適替代方案，實證結果突顯了 Transformer 的次優性能和 LRU 的顯著優勢。

##### **DoRA: Enhancing Parameter-Efficient Fine-Tuning with Dynamic Rank Distribution**
2405.17357v1 by Yulong Mao, Kaiyu Huang, Changhao Guan, Ganglin Bao, Fengran Mo, Jinan Xu

Fine-tuning large-scale pre-trained models is inherently a resource-intensive
task. While it can enhance the capabilities of the model, it also incurs
substantial computational costs, posing challenges to the practical application
of downstream tasks. Existing parameter-efficient fine-tuning (PEFT) methods
such as Low-Rank Adaptation (LoRA) rely on a bypass framework that ignores the
differential parameter budget requirements across weight matrices, which may
lead to suboptimal fine-tuning outcomes. To address this issue, we introduce
the Dynamic Low-Rank Adaptation (DoRA) method. DoRA decomposes high-rank LoRA
layers into structured single-rank components, allowing for dynamic pruning of
parameter budget based on their importance to specific tasks during training,
which makes the most of the limited parameter budget. Experimental results
demonstrate that DoRA can achieve competitive performance compared with LoRA
and full model fine-tuning, and outperform various strong baselines with the
same storage parameter budget. Our code is available at
https://github.com/Yulongmao1/DoRA/

摘要：微調大型預訓練模型本質上是一項資源密集型任務。雖然它可以增強模型的能力，但它也會產生大量的計算成本，對下游任務的實際應用構成挑戰。現有的參數高效微調 (PEFT) 方法（例如低秩適應 (LoRA)）依賴於一個旁路框架，該框架忽略了不同權重矩陣之間的差分參數預算需求，這可能會導致次優的微調結果。為了解決這個問題，我們引入了動態低秩適應 (DoRA) 方法。DoRA 將高秩 LoRA 層分解為結構化的單秩組件，允許根據參數預算對特定任務訓練期間的重要性進行動態剪枝，從而最大限度地利用有限的參數預算。實驗結果表明，與 LoRA 和完全模型微調相比，DoRA 可以實現具有競爭力的性能，並且在相同的存儲參數預算下優於各種強大的基線。我們的代碼可在 https://github.com/Yulongmao1/DoRA/ 獲得

##### **Prompt Optimization with Human Feedback**
2405.17346v1 by Xiaoqiang Lin, Zhongxiang Dai, Arun Verma, See-Kiong Ng, Patrick Jaillet, Bryan Kian Hsiang Low

Large language models (LLMs) have demonstrated remarkable performances in
various tasks. However, the performance of LLMs heavily depends on the input
prompt, which has given rise to a number of recent works on prompt
optimization. However, previous works often require the availability of a
numeric score to assess the quality of every prompt. Unfortunately, when a
human user interacts with a black-box LLM, attaining such a score is often
infeasible and unreliable. Instead, it is usually significantly easier and more
reliable to obtain preference feedback from a human user, i.e., showing the
user the responses generated from a pair of prompts and asking the user which
one is preferred. Therefore, in this paper, we study the problem of prompt
optimization with human feedback (POHF), in which we aim to optimize the prompt
for a black-box LLM using only human preference feedback. Drawing inspiration
from dueling bandits, we design a theoretically principled strategy to select a
pair of prompts to query for preference feedback in every iteration, and hence
introduce our algorithm named automated POHF (APOHF). We apply our APOHF
algorithm to various tasks, including optimizing user instructions, prompt
optimization for text-to-image generative models, and response optimization
with human feedback (i.e., further refining the response using a variant of our
APOHF). The results demonstrate that our APOHF can efficiently find a good
prompt using a small number of preference feedback instances. Our code can be
found at \url{https://github.com/xqlin98/APOHF}.

摘要：大型語言模型 (LLM) 在各種任務中展現出卓越的表現。然而，LLM 的表現高度依賴於輸入提示，這引起了許多關於提示最佳化的近期研究。然而，先前的研究通常需要一個數字分數來評估每個提示的品質。不幸的是，當人類使用者與黑盒子 LLM 互動時，獲得這樣的分數通常不可行且不可靠。相反，從人類使用者那裡獲得偏好回饋通常顯著更容易且更可靠，也就是說，向使用者展示一對提示產生的回應，並詢問使用者偏好哪一個。因此，在本文中，我們研究了帶有人類回饋的提示最佳化 (POHF) 問題，我們旨在使用僅人類偏好回饋來最佳化黑盒子 LLM 的提示。從決鬥土匪中汲取靈感，我們設計了一個理論上合理的策略，在每次迭代中選擇一對提示來查詢偏好回饋，從而引入了我們名為自動化 POHF (APOHF) 的演算法。我們將我們的 APOHF 演算法應用於各種任務，包括最佳化使用者說明、文字轉圖像生成模型的提示最佳化以及帶有人類回饋的回應最佳化（即使用我們 APOHF 的變體進一步精煉回應）。結果表明，我們的 APOHF 能夠使用少量的偏好回饋實例有效地找到一個好的提示。我們的程式碼可以在 \url{https://github.com/xqlin98/APOHF} 中找到。

##### **Exploring and steering the moral compass of Large Language Models**
2405.17345v1 by Alejandro Tlaie

Large Language Models (LLMs) have become central to advancing automation and
decision-making across various sectors, raising significant ethical questions.
This study proposes a comprehensive comparative analysis of the most advanced
LLMs to assess their moral profiles. We subjected several state-of-the-art
models to a selection of ethical dilemmas and found that all the proprietary
ones are mostly utilitarian and all of the open-weights ones align mostly with
values-based ethics. Furthermore, when using the Moral Foundations
Questionnaire, all models we probed - except for Llama 2- displayed a strong
liberal bias. Lastly, in order to causally intervene in one of the studied
models, we propose a novel similarity-specific activation steering technique.
Using this method, we were able to reliably steer the model's moral compass to
different ethical schools. All of these results showcase that there is an
ethical dimension in already deployed LLMs, an aspect that is generally
overlooked.

摘要：大型語言模型 (LLM) 已成為推進各個領域的自動化和決策制定過程的核心，引發了重大的倫理問題。本研究提出對最先進的 LLM 進行全面的比較分析，以評估其道德特徵。我們對幾個最先進的模型進行了一系列道德兩難選擇，並發現所有專有的模型大多是功利主義的，而所有開放權重的模型大多符合基於價值觀的倫理。此外，在使用道德基礎問卷時，我們探測的所有模型（除了 Llama 2）都表現出強烈的自由主義偏見。最後，為了對所研究的模型之一進行因果干預，我們提出了一種新穎的相似性特定激活引導技術。使用這種方法，我們能夠可靠地將模型的道德準則引導到不同的倫理學派。所有這些結果都表明，已經部署的 LLM 中存在道德層面，而這方面通常被忽視。

##### **Cost-efficient Knowledge-based Question Answering with Large Language Models**
2405.17337v1 by Junnan Dong, Qinggang Zhang, Chuang Zhou, Hao Chen, Daochen Zha, Xiao Huang

Knowledge-based question answering (KBQA) is widely used in many scenarios
that necessitate domain knowledge. Large language models (LLMs) bring
opportunities to KBQA, while their costs are significantly higher and absence
of domain-specific knowledge during pre-training. We are motivated to combine
LLMs and prior small models on knowledge graphs (KGMs) for both inferential
accuracy and cost saving. However, it remains challenging since accuracy and
cost are not readily combined in the optimization as two distinct metrics. It
is also laborious for model selection since different models excel in diverse
knowledge. To this end, we propose Coke, a novel cost-efficient strategy for
KBQA with LLMs, modeled as a tailored multi-armed bandit problem to minimize
calls to LLMs within limited budgets. We first formulate the accuracy
expectation with a cluster-level Thompson Sampling for either KGMs or LLMs. A
context-aware policy is optimized to further distinguish the expert model
subject to the question semantics. The overall decision is bounded by the cost
regret according to historical expenditure on failures. Extensive experiments
showcase the superior performance of Coke, which moves the Pareto frontier with
up to 20.89% saving of GPT-4 fees while achieving a 2.74% higher accuracy on
the benchmark datasets.

摘要：<paragraph>基於知識的問答 (KBQA) 廣泛應用於許多需要領域知識的場景中。大型語言模型 (LLM) 為 KBQA 帶來了機會，但其成本顯著提高，且在預訓練期間缺乏特定領域的知識。我們有動力將 LLM 和先前的知識圖譜 (KGM) 上的小模型結合起來，以提高推理準確性和節省成本。然而，由於準確性和成本無法在優化中作為兩個不同的指標輕易地結合在一起，因此這仍然具有挑戰性。由於不同的模型擅長於不同的知識，因此模型選擇也很費力。為此，我們提出了 Coke，一種針對 LLM 的新穎且具有成本效益的 KBQA 策略，它被建模為一個定制的多臂賭博機問題，以在有限的預算內最大程度地減少對 LLM 的呼叫。我們首先使用針對 KGM 或 LLM 的群集級 Thompson 採樣來制定準確性期望。優化了一個上下文感知策略，以進一步區分問題語義的主題模型。根據失敗的歷史支出，總體決策受到成本遺憾的約束。大量的實驗展示了 Coke 的優越性能，它將帕累托前沿移動了多達 20.89%，同時在基準數據集上實現了 2.74% 的更高準確性。</paragraph>

##### **XFormParser: A Simple and Effective Multimodal Multilingual Semi-structured Form Parser**
2405.17336v1 by Xianfu Cheng, Hang Zhang, Jian Yang, Xiang Li, Weixiao Zhou, Kui Wu, Fei Liu, Wei Zhang, Tao Sun, Tongliang Li, Zhoujun Li

In the domain of document AI, semi-structured form parsing plays a crucial
role. This task leverages techniques from key information extraction (KIE),
dealing with inputs that range from plain text to intricate modal data
comprising images and structural layouts. The advent of pre-trained multimodal
models has driven the extraction of key information from form documents in
different formats such as PDFs and images. Nonetheless, the endeavor of form
parsing is still encumbered by notable challenges like subpar capabilities in
multi-lingual parsing and diminished recall in contexts rich in text and
visuals. In this work, we introduce a simple but effective \textbf{M}ultimodal
and \textbf{M}ultilingual semi-structured \textbf{FORM} \textbf{PARSER}
(\textbf{XFormParser}), which is anchored on a comprehensive pre-trained
language model and innovatively amalgamates semantic entity recognition (SER)
and relation extraction (RE) into a unified framework, enhanced by a novel
staged warm-up training approach that employs soft labels to significantly
refine form parsing accuracy without amplifying inference overhead.
Furthermore, we have developed a groundbreaking benchmark dataset, named
InDFormBench, catering specifically to the parsing requirements of multilingual
forms in various industrial contexts. Through rigorous testing on established
multilingual benchmarks and InDFormBench, XFormParser has demonstrated its
unparalleled efficacy, notably surpassing the state-of-the-art (SOTA) models in
RE tasks within language-specific setups by achieving an F1 score improvement
of up to 1.79\%. Our framework exhibits exceptionally improved performance
across tasks in both multi-language and zero-shot contexts when compared to
existing SOTA benchmarks. The code is publicly available at
https://github.com/zhbuaa0/layoutlmft.

摘要：<paragraph>在文件 AI 領域，半結構化表單解析扮演著至關重要的角色。此任務利用關鍵資訊萃取 (KIE) 的技術，處理從純文字到包含影像和結構化配置的複雜模式化資料的輸入。預先訓練的多模態模型的出現帶動了從不同格式（例如 PDF 和影像）的表單文件萃取關鍵資訊。儘管如此，表單解析的努力仍受到顯著的挑戰，例如多語言解析能力不足，以及在文字和視覺效果豐富的環境中召回率降低。在這項工作中，我們引進了一個簡單但有效的**M**ultimodal and **M**ultilingual semi-structured **FORM** **PARSER** (**XFormParser**)，其建立在一個全面的預先訓練語言模型上，並創新地將語義實體辨識 (SER) 和關係萃取 (RE) 融合成一個統一的架構，並透過一種新穎的分階段熱身訓練方法加以強化，該方法採用軟標籤來大幅改善表單解析的準確度，而不會增加推論的負擔。此外，我們開發了一個創新的基準資料集，稱為 InDFormBench，專門用於滿足各種產業環境中多語言表單的解析需求。透過在既定的多語言基準和 InDFormBench 上進行嚴格的測試，XFormParser 已展現其無與倫比的效能，特別是在語言特定設定中，在 RE 任務中超越了最先進 (SOTA) 的模型，將 F1 分數提高了 1.79%。與現有的 SOTA 基準相比，我們的架構在多語言和零次學習環境中的各種任務中都展現了顯著改善的效能。程式碼已公開於 https://github.com/zhbuaa0/layoutlmft。</paragraph>

##### **Leveraging Offline Data in Linear Latent Bandits**
2405.17324v1 by Chinmaya Kausik, Kevin Tan, Ambuj Tewari

Sequential decision-making domains such as recommender systems, healthcare
and education often have unobserved heterogeneity in the population that can be
modeled using latent bandits $-$ a framework where an unobserved latent state
determines the model for a trajectory. While the latent bandit framework is
compelling, the extent of its generality is unclear. We first address this by
establishing a de Finetti theorem for decision processes, and show that
$\textit{every}$ exchangeable and coherent stateless decision process is a
latent bandit. The latent bandit framework lends itself particularly well to
online learning with offline datasets, a problem of growing interest in
sequential decision-making. One can leverage offline latent bandit data to
learn a complex model for each latent state, so that an agent can simply learn
the latent state online to act optimally. We focus on a linear model for a
latent bandit with $d_A$-dimensional actions, where the latent states lie in an
unknown $d_K$-dimensional subspace for $d_K \ll d_A$. We present SOLD, a novel
principled method to learn this subspace from short offline trajectories with
guarantees. We then provide two methods to leverage this subspace online:
LOCAL-UCB and ProBALL-UCB. We demonstrate that LOCAL-UCB enjoys $\tilde
O(\min(d_A\sqrt{T}, d_K\sqrt{T}(1+\sqrt{d_AT/d_KN})))$ regret guarantees, where
the effective dimension is lower when the size $N$ of the offline dataset is
larger. ProBALL-UCB enjoys a slightly weaker guarantee, but is more practical
and computationally efficient. Finally, we establish the efficacy of our
methods using experiments on both synthetic data and real-life movie
recommendation data from MovieLens.

摘要：<paragraph>序貫決策制定領域，例如推薦系統、醫療保健和教育，通常在人口中具有未觀察到的異質性，可以使用潛在強盜進行建模，潛在強盜是一個框架，其中未觀察到的潛在狀態決定軌跡的模型。雖然潛在強盜框架引人注目，但其普遍性的程度尚不清楚。我們首先通過建立決策過程的德芬內蒂定理來解決這個問題，並證明每個可交換且連貫的無狀態決策過程都是一個潛在強盜。潛在強盜框架特別適用於離線數據集的線上學習，這是序貫決策制定中越來越受關注的問題。人們可以利用離線潛在強盜數據為每個潛在狀態學習一個複雜的模型，以便代理可以簡單地線上學習潛在狀態以採取最佳行動。我們專注於一個潛在強盜的線性模型，其具有 $d_A$ 維動作，其中潛在狀態位於未知的 $d_K$ 維子空間中，其中 $d_K \ll d_A$。我們提出了 SOLD，這是一種新穎的原理方法，可用於從具有保證的短離線軌跡中學習這個子空間。然後，我們提供了兩種方法來線上利用這個子空間：LOCAL-UCB 和 ProBALL-UCB。我們證明 LOCAL-UCB 享有 $\tilde O(\min(d_A\sqrt{T}, d_K\sqrt{T}(1+\sqrt{d_AT/d_KN})))$ 後悔保證，其中當離線數據集的大小 $N$ 較大時，有效維度較低。ProBALL-UCB 享有稍弱的保證，但更實用且計算效率更高。最後，我們使用來自 MovieLens 的合成數據和真實電影推薦數據的實驗，建立了我們方法的功效。</paragraph>

##### **Efficient Ensembles Improve Training Data Attribution**
2405.17293v1 by Junwei Deng, Ting-Wei Li, Shichang Zhang, Jiaqi Ma

Training data attribution (TDA) methods aim to quantify the influence of
individual training data points on the model predictions, with broad
applications in data-centric AI, such as mislabel detection, data selection,
and copyright compensation. However, existing methods in this field, which can
be categorized as retraining-based and gradient-based, have struggled with the
trade-off between computational efficiency and attribution efficacy.
Retraining-based methods can accurately attribute complex non-convex models but
are computationally prohibitive, while gradient-based methods are efficient but
often fail for non-convex models. Recent research has shown that augmenting
gradient-based methods with ensembles of multiple independently trained models
can achieve significantly better attribution efficacy. However, this approach
remains impractical for very large-scale applications.
  In this work, we discover that expensive, fully independent training is
unnecessary for ensembling the gradient-based methods, and we propose two
efficient ensemble strategies, DROPOUT ENSEMBLE and LORA ENSEMBLE, alternative
to naive independent ensemble. These strategies significantly reduce training
time (up to 80%), serving time (up to 60%), and space cost (up to 80%) while
maintaining similar attribution efficacy to the naive independent ensemble. Our
extensive experimental results demonstrate that the proposed strategies are
effective across multiple TDA methods on diverse datasets and models, including
generative settings, significantly advancing the Pareto frontier of TDA methods
with better computational efficiency and attribution efficacy.

摘要：訓練資料歸因 (TDA) 方法旨在量化個別訓練資料點對模型預測的影響，在以資料為中心的 AI 中有著廣泛的應用，例如錯誤標籤偵測、資料選取和版權補償。然而，此領域現有的方法（可歸類為基於重新訓練和基於梯度的）一直難以在運算效率和歸因效能之間取得平衡。基於重新訓練的方法能準確歸因複雜的非凸模型，但運算成本高昂，而基於梯度的方法雖然運算效率高，但對於非凸模型往往失效。最近的研究顯示，透過多個獨立訓練模型的組合來擴充基於梯度的方法，可以大幅提升歸因效能。然而，此方法對於非常大規模的應用來說仍然不切實際。
在本文中，我們發現對於基於梯度的組合方法來說，昂貴且完全獨立的訓練並非必要，並且我們提出了兩種高效的組合策略，DROPOUT ENSEMBLE 和 LORA ENSEMBLE，作為樸素的獨立組合的替代方案。這些策略大幅減少了訓練時間（最多 80%）、服務時間（最多 60%）和空間成本（最多 80%），同時維持與樸素的獨立組合類似的歸因效能。我們廣泛的實驗結果證明，所提出的策略對於多種 TDA 方法在不同的資料集和模型上（包括生成設定）都是有效的，大幅提升了 TDA 方法在運算效率和歸因效能方面的帕累托前緣。

##### **Opinion-Guided Reinforcement Learning**
2405.17287v1 by Kyanna Dagenais, Istvan David

Human guidance is often desired in reinforcement learning to improve the
performance of the learning agent. However, human insights are often mere
opinions and educated guesses rather than well-formulated arguments. While
opinions are subject to uncertainty, e.g., due to partial informedness or
ignorance about a problem, they also emerge earlier than hard evidence could be
produced. Thus, guiding reinforcement learning agents through opinions offers
the potential for more performant learning processes, but comes with the
challenge of modeling and managing opinions in a formal way. In this article,
we present a method to guide reinforcement learning agents through opinions. To
this end, we provide an end-to-end method to model and manage advisors'
opinions. To assess the utility of the approach, we evaluate it with synthetic
and human advisors, at different levels of uncertainty, and under multiple
advise strategies. Our results indicate that opinions, even if uncertain,
improve the performance of reinforcement learning agents, resulting in higher
rewards, more efficient exploration, and a better reinforced policy. Although
we demonstrate our approach in a simplified topological running example, our
approach is applicable to complex problems with higher dimensions as well.

摘要：人類的指導在強化學習中通常是必要的，以提升學習代理的表現。然而，人類的見解通常只是意見和有根據的猜測，而非經過良好建構的論點。雖然意見可能會受到不確定性影響，例如由於對問題的部分了解或無知，但它們也會比難以證明的證據更早出現。因此，透過意見來指導強化學習代理具有提供更高效能學習流程的潛力，但同時也伴隨著以正式方式建模和管理意見的挑戰。在本文中，我們提出了一種透過意見來指導強化學習代理的方法。為此，我們提供了一個端到端的方法來建模和管理顧問的意見。為了評估此方法的效用，我們在不同程度的不確定性下，以及在多種建議策略下，使用合成和人類顧問對其進行評估。我們的結果表明，即使是不確定的意見，也能提升強化學習代理的表現，進而獲得更高的獎勵、更有效的探索和更強化的政策。儘管我們在一個簡化的拓撲執行範例中展示了我們的做法，但我們的做法也適用於具有更高維度的複雜問題。

##### **An NLP Crosswalk Between the Common Core State Standards and NAEP Item Specifications**
2405.17284v1 by Gregory Camilli

Natural language processing (NLP) is rapidly developing for applications in
educational assessment. In this paper, I describe an NLP-based procedure that
can be used to support subject matter experts in establishing a crosswalk
between item specifications and content standards. This paper extends recent
work by proposing and demonstrating the use of multivariate similarity based on
embedding vectors for sentences or texts. In particular, a hybrid regression
procedure is demonstrated for establishing the match of each content standard
to multiple item specifications. The procedure is used to evaluate the match of
the Common Core State Standards (CCSS) for mathematics at grade 4 to the
corresponding item specifications for the 2026 National Assessment of
Educational Progress (NAEP).

摘要：自然語言處理 (NLP) 正在快速發展，可用於教育評量的應用程式。在本文中，我描述了一個基於 NLP 的程序，可用於支援主題專家在項目規格和內容標準之間建立對應關係。本文透過提出和展示基於句子或文字嵌入向量的多變量相似性使用，來延伸最近的研究。特別是，展示了一個混合回歸程序，用於建立每個內容標準與多個項目規格的匹配。此程序用於評估 4 年級數學的共同核心州標準 (CCSS) 與 2026 年國家教育進度評估 (NAEP) 的對應項目規格的匹配。

##### **A Library for Automatic Natural Language Generation of Spanish Texts**
2405.17280v1 by Silvia García-Méndez, Milagros Fernández-Gavilanes, Enrique Costa-Montenegro, Jonathan Juncal-Martínez, F. Javier González-Castaño

In this article we present a novel system for natural language generation
(NLG) of Spanish sentences from a minimum set of meaningful words (such as
nouns, verbs and adjectives) which, unlike other state-of-the-art solutions,
performs the NLG task in a fully automatic way, exploiting both knowledge-based
and statistical approaches. Relying on its linguistic knowledge of vocabulary
and grammar, the system is able to generate complete, coherent and correctly
spelled sentences from the main word sets presented by the user. The system,
which was designed to be integrable, portable and efficient, can be easily
adapted to other languages by design and can feasibly be integrated in a wide
range of digital devices. During its development we also created a
supplementary lexicon for Spanish, aLexiS, with wide coverage and high
precision, as well as syntactic trees from a freely available definite-clause
grammar. The resulting NLG library has been evaluated both automatically and
manually (annotation). The system can potentially be used in different
application domains such as augmentative communication and automatic generation
of administrative reports or news.

摘要：<paragraph>在本文中，我們提出了一個新穎的系統，用於從一組有意義的最小單詞（例如名詞、動詞和形容詞）生成西班牙語句子，這與其他最先進的解決方案不同，它以一種完全自動化的方式執行 NLG 任務，同時利用基於知識和統計的方法。該系統依賴於其關於詞彙和語法的語言知識，能夠從使用者提供的單詞主集合中生成完整、連貫且拼寫正確的句子。該系統被設計為可集成、可移植且高效，通過設計可以輕鬆適應其他語言，並且可以切實集成到各種數位設備中。在開發過程中，我們還為西班牙語創建了一個補充詞彙表 aLexiS，它具有廣泛的覆蓋範圍和高精度，以及來自自由提供的確定子句語法的句法樹。生成的 NLG 庫已通過自動和手動（註解）進行評估。該系統潛在可用於不同的應用領域，例如擴充式溝通和自動生成管理報告或新聞。</paragraph>

##### **Socially-Aware Shared Control Navigation for Assistive Mobile Robots in the Built Environment**
2405.17279v1 by Yifan Xu, Qianwei Wang, Vineet Kamat, Carol Menassa

As the number of Persons with Disabilities (PWD), particularly those with one
or more physical impairments, increases, there is an increasing demand for
assistive robotic technologies that can support independent mobility in the
built environment and reduce the burden on caregivers. Current assistive
mobility platforms (e.g., robotic wheelchairs) often fail to incorporate user
preferences and control, leading to reduced trust and efficiency. Existing
shared control algorithms do not allow the incorporation of the user control
preferences inside the navigation framework or the path planning algorithm. In
addition, existing dynamic local planner algorithms for robotic wheelchairs do
not take into account the social spaces of people, potentially leading such
platforms to infringe upon these areas and cause discomfort. To address these
concerns, this work introduces a novel socially-aware shared autonomy-based
navigation system for assistive mobile robotic platforms.
  Our navigation framework comprises a Global Planner and a Local Planner. To
implement the Global Planner, the proposed approach introduces a novel User
Preference Field (UPF) theory within its global planning framework, explicitly
acknowledging user preferences to adeptly navigate away from congested areas.
For the Local Planner, we propose a Socially-aware Shared Control-based Model
Predictive Control with Dynamic Control Barrier Function (SS-MPC-DCBF) to
adjust movements in real-time, integrating user preferences for safer, more
autonomous navigation. Evaluation results show that our Global Planner aligns
closely with user preferences compared to baselines, and our Local Planner
demonstrates enhanced safety and efficiency in dynamic and static scenarios.
This integrated approach fosters trust and autonomy, crucial for the acceptance
of assistive mobility technologies in the built environment.

摘要：隨著身心障礙者（PWD），尤其是身體有障礙者人數的增加，對於輔助機器人技術的需求也與日俱增，此技術可支援建成環境中的獨立行動，並減輕照顧者的負擔。目前的輔助行動平台（例如機器人輪椅）經常無法納入使用者的偏好和控制，導致信任和效率降低。現有的共享控制演算法不允許在導航架構或路徑規劃演算法中納入使用者控制偏好。此外，現有的機器人輪椅動態局部規劃器演算法並未考量人們的社交空間，可能會導致此類平台侵犯這些區域並造成不適。為了解決這些問題，本研究提出了一個新穎的社會感知共享自主導航系統，用於輔助行動機器人平台。
我們的導航架構包含一個全局規劃器和一個局部規劃器。為了實施全局規劃器，所提出的方法在其全局規劃架構中引入了一個新穎的使用者偏好場 (UPF) 理論，明確承認使用者的偏好，以靈活地避開擁擠區域。對於局部規劃器，我們提出了一個基於社會感知共享控制的模型預測控制與動態控制障礙函數 (SS-MPC-DCBF)，以即時調整動作，整合使用者的偏好，以實現更安全、更自主的導航。評估結果顯示，與基準線相比，我們的全局規劃器與使用者的偏好密切吻合，而我們的局部規劃器則在動態和靜態場景中展現出增強的安全性和效率。這種整合方法培養了信任和自主性，這對於在建成環境中接受輔助行動技術至關重要。

##### **On the Noise Robustness of In-Context Learning for Text Generation**
2405.17264v1 by Hongfu Gao, Feipeng Zhang, Wenyu Jiang, Jun Shu, Feng Zheng, Hongxin Wei

Large language models (LLMs) have shown impressive performance on downstream
tasks by in-context learning (ICL), which heavily relies on the quality of
demonstrations selected from a large set of annotated examples. Recent works
claim that in-context learning is robust to noisy demonstrations in text
classification. In this work, we show that, on text generation tasks, noisy
annotations significantly hurt the performance of in-context learning. To
circumvent the issue, we propose a simple and effective approach called Local
Perplexity Ranking (LPR), which replaces the "noisy" candidates with their
nearest neighbors that are more likely to be clean. Our method is motivated by
analyzing the perplexity deviation caused by noisy labels and decomposing
perplexity into inherent perplexity and matching perplexity. Our key idea
behind LPR is thus to decouple the matching perplexity by performing the
ranking among the neighbors in semantic space. Our approach can prevent the
selected demonstrations from including mismatched input-label pairs while
preserving the effectiveness of the original selection methods. Extensive
experiments demonstrate the effectiveness of LPR, improving the EM score by up
to 18.75 on common benchmarks with noisy annotations.

摘要：大型語言模型 (LLM) 已在下游任務中透過情境學習 (ICL) 展現出令人印象深刻的效能，而這在很大程度上取決於從大量註解範例中選出的示範品質。最近的研究聲稱，情境學習對於文字分類中的雜訊示範具有穩健性。在這項研究中，我們展示了在文字生成任務中，雜訊註解會嚴重損害情境學習的效能。為了迴避這個問題，我們提出了一種簡單且有效的方法，稱為局部困惑度排序 (LPR)，它會用更可能是乾淨的最近鄰居取代「雜訊」候選者。我們的做法是透過分析雜訊標籤造成的困惑度偏差，以及將困惑度分解為固有困惑度和匹配困惑度。因此，LPR 背後的主要概念是透過在語義空間中對鄰居進行排序，來解耦匹配困惑度。我們的做法可以防止所選示範包含不匹配的輸入標籤配對，同時保留原始選擇方法的有效性。廣泛的實驗證明了 LPR 的有效性，在有雜訊註解的常見基準上，將 EM 分數提高了 18.75。

##### **$\textit{Trans-LoRA}$: towards data-free Transferable Parameter Efficient Finetuning**
2405.17258v1 by Runqian Wang, Soumya Ghosh, David Cox, Diego Antognini, Aude Oliva, Rogerio Feris, Leonid Karlinsky

Low-rank adapters (LoRA) and their variants are popular parameter-efficient
fine-tuning (PEFT) techniques that closely match full model fine-tune
performance while requiring only a small number of additional parameters. These
additional LoRA parameters are specific to the base model being adapted. When
the base model needs to be deprecated and replaced with a new one, all the
associated LoRA modules need to be re-trained. Such re-training requires access
to the data used to train the LoRA for the original base model. This is
especially problematic for commercial cloud applications where the LoRA modules
and the base models are hosted by service providers who may not be allowed to
host proprietary client task data. To address this challenge, we propose
$\textit{Trans-LoRA}$ -- a novel method for lossless, nearly data-free transfer
of LoRAs across base models. Our approach relies on synthetic data to transfer
LoRA modules. Using large language models, we design a synthetic data generator
to approximate the data-generating process of the $\textit{observed}$ task data
subset. Training on the resulting synthetic dataset transfers LoRA modules to
new models. We show the effectiveness of our approach using both LLama and
Gemma model families. Our approach achieves lossless (mostly improved) LoRA
transfer between models within and across different base model families, and
even between different PEFT methods, on a wide variety of tasks.

摘要：低秩適配器 (LoRA) 及其變體是熱門的參數有效微調 (PEFT) 技術，在僅需要少數額外參數的情況下，可緊密匹配完整模型微調效能。這些額外的 LoRA 參數專屬於要適用的基礎模型。當基礎模型需要棄用並替換為新的模型時，所有關聯的 LoRA 模組都需要重新訓練。此類重新訓練需要存取用於訓練原始基礎模型的 LoRA 的資料。這對於商業雲端應用程式來說特別有問題，因為 LoRA 模組和基礎模型是由服務供應商所主機，而服務供應商可能無法主機專有的客戶任務資料。為了應對此挑戰，我們提出 $\textit{Trans-LoRA}$，這是一種創新的方法，可無損失且幾乎不使用資料來跨基礎模型傳輸 LoRA。我們的做法依賴於合成資料來傳輸 LoRA 模組。我們使用大型語言模型，設計一個合成資料產生器來近似 $\textit{觀察到的}$ 任務資料子集的資料產生過程。在產生的合成資料集上進行訓練，將 LoRA 模組傳輸到新的模型。我們使用 LLama 和 Gemma 模型系列展示了我們做法的有效性。我們的做法在各種任務上，在不同基礎模型系列內部和之間，甚至在不同的 PEFT 方法之間，實現了無損失（大多數情況下都有改善）的 LoRA 傳輸。

##### **Gaussian Embedding of Temporal Networks**
2405.17253v1 by Raphaël Romero, Jefrey Lijffijt, Riccardo Rastelli, Marco Corneli, Tijl De Bie

Representing the nodes of continuous-time temporal graphs in a
low-dimensional latent space has wide-ranging applications, from prediction to
visualization. Yet, analyzing continuous-time relational data with timestamped
interactions introduces unique challenges due to its sparsity. Merely embedding
nodes as trajectories in the latent space overlooks this sparsity, emphasizing
the need to quantify uncertainty around the latent positions. In this paper, we
propose TGNE (\textbf{T}emporal \textbf{G}aussian \textbf{N}etwork
\textbf{E}mbedding), an innovative method that bridges two distinct strands of
literature: the statistical analysis of networks via Latent Space Models
(LSM)\cite{Hoff2002} and temporal graph machine learning. TGNE embeds nodes as
piece-wise linear trajectories of Gaussian distributions in the latent space,
capturing both structural information and uncertainty around the trajectories.
We evaluate TGNE's effectiveness in reconstructing the original graph and
modelling uncertainty. The results demonstrate that TGNE generates competitive
time-varying embedding locations compared to common baselines for
reconstructing unobserved edge interactions based on observed edges.
Furthermore, the uncertainty estimates align with the time-varying degree
distribution in the network, providing valuable insights into the temporal
dynamics of the graph. To facilitate reproducibility, we provide an open-source
implementation of TGNE at \url{https://github.com/aida-ugent/tgne}.

摘要：表示連續時間時態圖形節點於低維潛在空間中具有廣泛的應用，從預測到可視化。然而，分析具有時間戳記交互作用的連續時間關係資料會因為其稀疏性而造成獨特的挑戰。僅將節點嵌入為潛在空間中的軌跡會忽略這種稀疏性，強調量化潛在位置周圍不確定性的必要性。在本文中，我們提出 TGNE（**T**emporal **G**aussian **N**etwork **E**mbedding），這是一種創新的方法，它架起了兩個不同的文獻流：通過潛在空間模型 (LSM) 進行的網路統計分析\cite{Hoff2002}和時態圖形機器學習。TGNE 將節點嵌入為潛在空間中高斯分布的分段線性軌跡，擷取軌跡周圍的結構資訊和不確定性。我們評估 TGNE 在重建原始圖形和建模不確定性方面的有效性。結果表明，與根據觀察到的邊緣重建未觀察到的邊緣交互作用的常見基準線相比，TGNE 生成了具有競爭力的時變嵌入位置。此外，不確定性估計與網路中的時變度數分佈一致，提供了對圖形時態動態的寶貴見解。為了促進可複製性，我們在 \url{https://github.com/aida-ugent/tgne} 提供 TGNE 的開源實作。

##### **Assessing LLMs Suitability for Knowledge Graph Completion**
2405.17249v1 by Vasile Ionut Remus Iga, Gheorghe Cosmin Silaghi

Recent work shown the capability of Large Language Models (LLMs) to solve
tasks related to Knowledge Graphs, such as Knowledge Graph Completion, even in
Zero- or Few-Shot paradigms. However, they are known to hallucinate answers, or
output results in a non-deterministic manner, thus leading to wrongly reasoned
responses, even if they satisfy the user's demands. To highlight opportunities
and challenges in knowledge graphs-related tasks, we experiment with two
distinguished LLMs, namely Mixtral-8x7B-Instruct-v0.1, and gpt-3.5-turbo-0125,
on Knowledge Graph Completion for static knowledge graphs, using prompts
constructed following the TELeR taxonomy, in Zero- and One-Shot contexts, on a
Task-Oriented Dialogue system use case. When evaluated using both strict and
flexible metrics measurement manners, our results show that LLMs could be fit
for such a task if prompts encapsulate sufficient information and relevant
examples.

摘要：最近的研究显示，大型语言模型 (LLM) 具备解决知识图谱相关任务的能力，例如知识图谱补全，即使在零次或小样本的情况下也是如此。然而，众所周知，它们会产生幻觉答案，或以非确定性的方式输出结果，从而导致推理错误的响应，即使它们满足了用户的需求。为了突出知识图谱相关任务中的机遇和挑战，我们对两种杰出的 LLM 进行了实验，分别是 Mixtral-8x7B-Instruct-v0.1 和 gpt-3.5-turbo-0125，在静态知识图谱的知识图谱补全上，使用根据 TELeR 分类法构建的提示，在零次和一次上下文中，在面向任务的对话系统用例中。当使用严格和灵活的度量方式进行评估时，我们的结果表明，如果提示包含足够的信息和相关示例，则 LLM 适用于此类任务。

##### **Galaxy: A Resource-Efficient Collaborative Edge AI System for In-situ Transformer Inference**
2405.17245v1 by Shengyuan Ye, Jiangsu Du, Liekang Zeng, Wenzhong Ou, Xiaowen Chu, Yutong Lu, Xu Chen

Transformer-based models have unlocked a plethora of powerful intelligent
applications at the edge, such as voice assistant in smart home. Traditional
deployment approaches offload the inference workloads to the remote cloud
server, which would induce substantial pressure on the backbone network as well
as raise users' privacy concerns. To address that, in-situ inference has been
recently recognized for edge intelligence, but it still confronts significant
challenges stemming from the conflict between intensive workloads and limited
on-device computing resources. In this paper, we leverage our observation that
many edge environments usually comprise a rich set of accompanying trusted edge
devices with idle resources and propose Galaxy, a collaborative edge AI system
that breaks the resource walls across heterogeneous edge devices for efficient
Transformer inference acceleration. Galaxy introduces a novel hybrid model
parallelism to orchestrate collaborative inference, along with a
heterogeneity-aware parallelism planning for fully exploiting the resource
potential. Furthermore, Galaxy devises a tile-based fine-grained overlapping of
communication and computation to mitigate the impact of tensor synchronizations
on inference latency under bandwidth-constrained edge environments. Extensive
evaluation based on prototype implementation demonstrates that Galaxy
remarkably outperforms state-of-the-art approaches under various edge
environment setups, achieving up to 2.5x end-to-end latency reduction.

摘要：<paragraph>基於 Transformer 的模型已在邊緣解鎖了許多強大的智慧應用程式，例如智慧家庭中的語音助理。傳統的部署方法將推理工作負載卸載到遠端雲端伺服器，這會對主幹網路造成巨大的壓力，並引發使用者的隱私問題。為了解決這個問題，最近已針對邊緣智慧辨識出就地推理，但它仍然面臨著因密集工作負載和有限裝置運算資源之間的衝突所產生的重大挑戰。在本文中，我們利用我們的觀察結果，即許多邊緣環境通常包含一組豐富的附帶受信任邊緣裝置和閒置資源，並提出 Galaxy，一種協作式邊緣 AI 系統，它打破了異質邊緣裝置之間的資源藩籬，以實現高效的 Transformer 推理加速。Galaxy 引入了新穎的混合模型並行處理來協調協作式推理，並結合了異質性感知並行規劃，以充分利用資源潛力。此外，Galaxy 設計了一個基於磁磚的細粒度重疊通訊和運算，以減輕張量同步對頻寬受限的邊緣環境中推理延遲的影響。基於原型實作的廣泛評估表明，Galaxy 在各種邊緣環境設定下都顯著優於最先進的方法，實現了高達 2.5 倍的端到端延遲降低。</paragraph>

##### **Benchmarking General Purpose In-Context Learning**
2405.17234v1 by Fan Wang, Chuan Lin, Yang Cao, Yu Kang

In-context learning (ICL) capabilities is becoming increasingly appealing
towards building general intelligence. Taking this concept one step further, we
draw a parallel to humans and many animals, who inherit primarily learning
capabilities but refine their memory and acquire diverse skills and knowledge
through extensive lifelong experiences. This parallel inspires our approach to
general purpose in-context learning (GPICL). This paper introduces two
lightweight but insightful benchmarks specifically crafted to train and
evaluate GPICL functionalities. Each benchmark encompasses a wide range of
diverse tasks characterized by generation and interaction, minimal transferable
knowledge, and long-term dependency. These features present significant
challenges for models that primarily rely on context or interactions to enhance
their proficiency. We hope that these benchmarks will not only advance research
in GPICL but also contribute significantly to the broader field of general
intelligence.

摘要：情境學習（ICL）能力對於建構一般智慧正變得越來越有吸引力。進一步採取此概念，我們將人類和許多動物視為平行，他們繼承了主要的學習能力，但透過廣泛的終身經驗，改善他們的記憶力並習得多元的技能和知識。這種平行激勵我們採取一般用途情境學習（GPICL）的方法。此論文介紹兩個輕量級但有見地的基準，專門設計用於訓練和評估 GPICL 功能。每個基準都包含廣泛的多元任務，其特點是產生和互動、最少的可轉移知識，以及長期依賴性。這些特點對主要依賴情境或互動來提升其熟練度的模型提出了重大挑戰。我們希望這些基準不僅能推進 GPICL 的研究，也能對一般智慧的更廣泛領域做出重大貢獻。

##### **RLAIF-V: Aligning MLLMs through Open-Source AI Feedback for Super GPT-4V Trustworthiness**
2405.17220v1 by Tianyu Yu, Haoye Zhang, Yuan Yao, Yunkai Dang, Da Chen, Xiaoman Lu, Ganqu Cui, Taiwen He, Zhiyuan Liu, Tat-Seng Chua, Maosong Sun

Learning from feedback reduces the hallucination of multimodal large language
models (MLLMs) by aligning them with human preferences. While traditional
methods rely on labor-intensive and time-consuming manual labeling, recent
approaches employing models as automatic labelers have shown promising results
without human intervention. However, these methods heavily rely on costly
proprietary models like GPT-4V, resulting in scalability issues. Moreover, this
paradigm essentially distills the proprietary models to provide a temporary
solution to quickly bridge the performance gap. As this gap continues to
shrink, the community is soon facing the essential challenge of aligning MLLMs
using labeler models of comparable capability. In this work, we introduce
RLAIF-V, a novel framework that aligns MLLMs in a fully open-source paradigm
for super GPT-4V trustworthiness. RLAIF-V maximally exploits the open-source
feedback from two perspectives, including high-quality feedback data and online
feedback learning algorithm. Extensive experiments on seven benchmarks in both
automatic and human evaluation show that RLAIF-V substantially enhances the
trustworthiness of models without sacrificing performance on other tasks. Using
a 34B model as labeler, RLAIF-V 7B model reduces object hallucination by 82.9\%
and overall hallucination by 42.1\%, outperforming the labeler model.
Remarkably, RLAIF-V also reveals the self-alignment potential of open-source
MLLMs, where a 12B model can learn from the feedback of itself to achieve less
than 29.5\% overall hallucination rate, surpassing GPT-4V (45.9\%) by a large
margin. The results shed light on a promising route to enhance the efficacy of
leading-edge MLLMs.

摘要：<paragraph>從回饋中學習可減少多模態大型語言模型 (MLLM) 的幻覺，方法是讓它們與人類偏好保持一致。雖然傳統方法依賴於勞力密集且耗時的標籤手動標記，但最近採用模型作為自動標籤器的做法已顯示出有希望的結果，而無需人工干預。然而，這些方法嚴重依賴於像 GPT-4V 這樣的昂貴專有模型，導致可擴充性問題。此外，這種範例基本上會精簡專有模型，以提供暫時解決方案來快速縮小效能差距。隨著這個差距持續縮小，社群很快就會面臨使用具有可比能力的標籤器模型來調整 MLLM 的基本挑戰。在這項工作中，我們介紹了 RLAIF-V，這是一個新穎的框架，它在一個完全開源的範例中調整 MLLM，以獲得超 GPT-4V 的可信度。RLAIF-V 從兩個角度最大程度地利用開源回饋，包括高品質回饋資料和線上回饋學習演算法。在自動和人工評估中對七個基準進行的廣泛實驗表明，RLAIF-V 大幅提升了模型的可信度，而不會犧牲其他任務的效能。使用 34B 模型作為標籤器，RLAIF-V 7B 模型將物件幻覺減少了 82.9%，整體幻覺減少了 42.1%，表現優於標籤器模型。值得注意的是，RLAIF-V 也揭示了開源 MLLM 的自我調整潛力，其中一個 12B 模型可以從自身的回饋中學習，以達到低於 29.5% 的整體幻覺率，大幅超越 GPT-4V (45.9%)。這些結果為提升領先 MLLM 的功效照亮了一條有希望的途徑。</paragraph>

##### **Autoformalizing Euclidean Geometry**
2405.17216v1 by Logan Murphy, Kaiyu Yang, Jialiang Sun, Zhaoyu Li, Anima Anandkumar, Xujie Si

Autoformalization involves automatically translating informal math into
formal theorems and proofs that are machine-verifiable. Euclidean geometry
provides an interesting and controllable domain for studying autoformalization.
In this paper, we introduce a neuro-symbolic framework for autoformalizing
Euclidean geometry, which combines domain knowledge, SMT solvers, and large
language models (LLMs). One challenge in Euclidean geometry is that informal
proofs rely on diagrams, leaving gaps in texts that are hard to formalize. To
address this issue, we use theorem provers to fill in such diagrammatic
information automatically, so that the LLM only needs to autoformalize the
explicit textual steps, making it easier for the model. We also provide
automatic semantic evaluation for autoformalized theorem statements. We
construct LeanEuclid, an autoformalization benchmark consisting of problems
from Euclid's Elements and the UniGeo dataset formalized in the Lean proof
assistant. Experiments with GPT-4 and GPT-4V show the capability and
limitations of state-of-the-art LLMs on autoformalizing geometry problems. The
data and code are available at https://github.com/loganrjmurphy/LeanEuclid.

摘要：自動形式化涉及將非正式數學自動翻譯為機器可驗證的正式定理和證明。歐幾里得幾何提供了一個有趣且可控的領域來研究自動形式化。在本文中，我們介紹了一個用於自動形式化歐幾里得幾何的神經符號框架，它結合了領域知識、SMT 求解器和大語言模型 (LLM)。歐幾里得幾何中的一個挑戰是非正式證明依賴於圖表，在難以形式化的文本中留下空白。為了解決這個問題，我們使用定理證明器自動填補這些圖解信息，這樣 LLM 只需要自動形式化明確的文本步驟，這使得模型更容易。我們還為自動形式化的定理陳述提供自動語義評估。我們構建了 LeanEuclid，一個自動形式化基準，其中包含歐幾里得《幾何原本》和在 Lean 證明輔助工具中形式化的 UniGeo 數據集中的問題。使用 GPT-4 和 GPT-4V 進行的實驗展示了最先進的 LLM 在自動形式化幾何問題上的能力和局限性。數據和代碼可在 https://github.com/loganrjmurphy/LeanEuclid 獲得。

##### **Efficient multi-prompt evaluation of LLMs**
2405.17202v1 by Felipe Maia Polo, Ronald Xu, Lucas Weber, Mírian Silva, Onkar Bhardwaj, Leshem Choshen, Allysson Flavio Melo de Oliveira, Yuekai Sun, Mikhail Yurochkin

Most popular benchmarks for comparing LLMs rely on a limited set of prompt
templates, which may not fully capture the LLMs' abilities and can affect the
reproducibility of results on leaderboards. Many recent works empirically
verify prompt sensitivity and advocate for changes in LLM evaluation. In this
paper, we consider the problem of estimating the performance distribution
across many prompt variants instead of finding a single prompt to evaluate
with. We introduce PromptEval, a method for estimating performance across a
large set of prompts borrowing strength across prompts and examples to produce
accurate estimates under practical evaluation budgets. The resulting
distribution can be used to obtain performance quantiles to construct various
robust performance metrics (e.g., top 95% quantile or median). We prove that
PromptEval consistently estimates the performance distribution and demonstrate
its efficacy empirically on three prominent LLM benchmarks: MMLU, BIG-bench
Hard, and LMentry. For example, PromptEval can accurately estimate performance
quantiles across 100 prompt templates on MMLU with a budget equivalent to two
single-prompt evaluations. Our code and data can be found at
https://github.com/felipemaiapolo/prompt-eval.

摘要：大多數用於比較 LLM 的熱門基準都依賴於一組有限的提示範本，這些範本可能無法完全掌握 LLM 的能力，並且會影響排行榜上結果的可複製性。許多近期研究經驗性地驗證了提示敏感性，並倡導改變 LLM 評估。在本文中，我們考慮了估計許多提示變體中的效能分佈的問題，而不是找到一個提示來評估。我們引入了 PromptEval，這是一種估計大量提示效能的方法，它借用提示和範例的力量，在實際評估預算下產生準確的估計。產生的分佈可用於獲取效能分位數，以建構各種穩健效能指標（例如，前 95% 分位數或中位數）。我們證明 PromptEval 一致地估計效能分佈，並在三個著名的 LLM 基準上實證展示其效力：MMLU、BIG-bench Hard 和 LMentry。例如，PromptEval 可以準確估計 MMLU 上 100 個提示範本的效能分位數，其預算等於兩個單一提示評估。我們的程式碼和資料可以在 https://github.com/felipemaiapolo/prompt-eval 找到。

##### **DreamMat: High-quality PBR Material Generation with Geometry- and Light-aware Diffusion Models**
2405.17176v1 by Yuqing Zhang, Yuan Liu, Zhiyu Xie, Lei Yang, Zhongyuan Liu, Mengzhou Yang, Runze Zhang, Qilong Kou, Cheng Lin, Wenping Wang, Xiaogang Jin

2D diffusion model, which often contains unwanted baked-in shading effects
and results in unrealistic rendering effects in the downstream applications.
Generating Physically Based Rendering (PBR) materials instead of just RGB
textures would be a promising solution. However, directly distilling the PBR
material parameters from 2D diffusion models still suffers from incorrect
material decomposition, such as baked-in shading effects in albedo. We
introduce DreamMat, an innovative approach to resolve the aforementioned
problem, to generate high-quality PBR materials from text descriptions. We find
out that the main reason for the incorrect material distillation is that
large-scale 2D diffusion models are only trained to generate final shading
colors, resulting in insufficient constraints on material decomposition during
distillation. To tackle this problem, we first finetune a new light-aware 2D
diffusion model to condition on a given lighting environment and generate the
shading results on this specific lighting condition. Then, by applying the same
environment lights in the material distillation, DreamMat can generate
high-quality PBR materials that are not only consistent with the given geometry
but also free from any baked-in shading effects in albedo. Extensive
experiments demonstrate that the materials produced through our methods exhibit
greater visual appeal to users and achieve significantly superior rendering
quality compared to baseline methods, which are preferable for downstream tasks
such as game and film production.

摘要：2D 擴散模型通常包含不需要的內建陰影效果，並導致下游應用程式中不切實際的渲染效果。生成基於物理的渲染 (PBR) 材質，而不是僅 RGB 紋理，將會是一個有前途的解決方案。然而，直接從 2D 擴散模型中提取 PBR 材質參數仍然會受到不正確的材質分解，例如漫反射中的內建陰影效果。我們引入了 DreamMat，這是一種創新的方法，用於解決上述問題，從文字描述中生成高品質的 PBR 材質。我們發現不正確材質提取的主要原因是，大規模的 2D 擴散模型僅訓練用於生成最終陰影顏色，導致在提取過程中對材質分解的約束不足。為了解決這個問題，我們首先微調一個新的光感知 2D 擴散模型，以在給定的光照環境中進行調整，並在這個特定光照條件下生成陰影結果。然後，通過在材質提取中應用相同的環境光，DreamMat 可以生成高品質的 PBR 材質，這些材質不僅與給定的幾何形狀一致，而且沒有任何漫反射中的內建陰影效果。大量的實驗表明，通過我們的方法產生的材質對使用者展現出更大的視覺吸引力，並且與基準方法相比，實現了顯著優越的渲染品質，這對於下游任務（例如遊戲和電影製作）是較佳的選擇。

##### **Stop! In the Name of Flaws: Disentangling Personal Names and Sociodemographic Attributes in NLP**
2405.17159v1 by Vagrant Gautam, Arjun Subramonian, Anne Lauscher, Os Keyes

Personal names simultaneously differentiate individuals and categorize them
in ways that are important in a given society. While the natural language
processing community has thus associated personal names with sociodemographic
characteristics in a variety of tasks, researchers have engaged to varying
degrees with the established methodological problems in doing so. To guide
future work, we present an interdisciplinary background on names and naming. We
then survey the issues inherent to associating names with sociodemographic
attributes, covering problems of validity (e.g., systematic error, construct
validity), as well as ethical concerns (e.g., harms, differential impact,
cultural insensitivity). Finally, we provide guiding questions along with
normative recommendations to avoid validity and ethical pitfalls when dealing
with names and sociodemographic characteristics in natural language processing.

摘要：個人姓名同時區分個人，並以對特定社會而言重要的方式對其進行分類。雖然自然語言處理社群已因此將個人姓名與各種任務中的社會人口統計特徵聯繫起來，但研究人員在這樣做的過程中，對既定的方法論問題採取了不同程度的參與。為了指導後續工作，我們提供了有關姓名和命名法的跨學科背景。然後，我們調查將姓名與社會人口統計屬性關聯時固有的問題，涵蓋有效性問題（例如系統性錯誤、建構效度）以及道德問題（例如危害、差異影響、文化不敏感）。最後，我們提供了指導性問題以及規範性建議，以避免在自然語言處理中處理姓名和社會人口統計特徵時出現效度和道德陷阱。

##### **Synergy and Diversity in CLIP: Enhancing Performance Through Adaptive Backbone Ensembling**
2405.17139v1 by Cristian Rodriguez-Opazo, Ehsan Abbasnejad, Damien Teney, Edison Marrese-Taylor, Hamed Damirchi, Anton van den Hengel

Contrastive Language-Image Pretraining (CLIP) stands out as a prominent
method for image representation learning. Various architectures, from vision
transformers (ViTs) to convolutional networks (ResNets) have been trained with
CLIP to serve as general solutions to diverse vision tasks. This paper explores
the differences across various CLIP-trained vision backbones. Despite using the
same data and training objective, we find that these architectures have notably
different representations, different classification performance across
datasets, and different robustness properties to certain types of image
perturbations. Our findings indicate a remarkable possible synergy across
backbones by leveraging their respective strengths. In principle,
classification accuracy could be improved by over 40 percentage with an
informed selection of the optimal backbone per test example.Using this insight,
we develop a straightforward yet powerful approach to adaptively ensemble
multiple backbones. The approach uses as few as one labeled example per class
to tune the adaptive combination of backbones. On a large collection of
datasets, the method achieves a remarkable increase in accuracy of up to 39.1%
over the best single backbone, well beyond traditional ensembles

摘要：對比語言影像預訓練 (CLIP) 作為影像表徵學習的顯著方法而備受矚目。從視覺轉換器 (ViT) 到卷積網路 (ResNet) 等各種架構都已針對 CLIP 進行訓練，以作為解決各種視覺任務的通用方案。本文探討各種 CLIP 訓練視覺主幹的差異。儘管使用相同的資料和訓練目標，我們發現這些架構具有顯著不同的表徵、在不同資料集上的不同分類效能，以及對特定類型影像擾動的不同穩健性。我們的研究結果表明，透過利用各自的優勢，主幹之間有顯著的可能協同效應。原則上，透過明智地針對每個測試範例選擇最佳主幹，可以將分類準確度提升 40% 以上。利用此洞見，我們開發出一種直接但強大的方法來適應性地整合多個主幹。此方法每類別使用少至一個標籤範例來調整主幹的適應性組合。在大量資料集上，此方法的準確度顯著提升，比最佳單一主幹高出 39.1%，遠遠超過傳統的整合

##### **Exploiting the Layered Intrinsic Dimensionality of Deep Models for Practical Adversarial Training**
2405.17130v1 by Enes Altinisik, Safa Messaoud, Husrev Taha Sencar, Hassan Sajjad, Sanjay Chawla

Despite being a heavily researched topic, Adversarial Training (AT) is
rarely, if ever, deployed in practical AI systems for two primary reasons: (i)
the gained robustness is frequently accompanied by a drop in generalization and
(ii) generating adversarial examples (AEs) is computationally prohibitively
expensive. To address these limitations, we propose SMAAT, a new AT algorithm
that leverages the manifold conjecture, stating that off-manifold AEs lead to
better robustness while on-manifold AEs result in better generalization.
Specifically, SMAAT aims at generating a higher proportion of off-manifold AEs
by perturbing the intermediate deepnet layer with the lowest intrinsic
dimension. This systematically results in better scalability compared to
classical AT as it reduces the PGD chains length required for generating the
AEs. Additionally, our study provides, to the best of our knowledge, the first
explanation for the difference in the generalization and robustness trends
between vision and language models, ie., AT results in a drop in generalization
in vision models whereas, in encoder-based language models, generalization
either improves or remains unchanged. We show that vision transformers and
decoder-based models tend to have low intrinsic dimensionality in the earlier
layers of the network (more off-manifold AEs), while encoder-based models have
low intrinsic dimensionality in the later layers. We demonstrate the efficacy
of SMAAT; on several tasks, including robustifying (i) sentiment classifiers,
(ii) safety filters in decoder-based models, and (iii) retrievers in RAG
setups. SMAAT requires only 25-33% of the GPU time compared to standard AT,
while significantly improving robustness across all applications and
maintaining comparable generalization.

摘要：儘管對抗訓練 (AT) 是個被廣泛研究的主題，但實際上很少（甚至從未）被部署在實務 AI 系統中，主要原因有兩個：(i) 獲得的穩健性經常伴隨著概括性的下降，以及 (ii) 生成對抗範例 (AE) 在計算上過於昂貴。為了解決這些限制，我們提出了 SMAAT，這是一種新的 AT 演算法，它利用流形猜想，指出流形外的 AE 可帶來更好的穩健性，而流形上的 AE 則可帶來更好的概括性。具體來說，SMAAT 旨在透過擾動內在維度最低的中間深度網路層來產生更高比例的流形外 AE。與傳統 AT 相比，這系統性地產生了更好的可擴充性，因為它減少了產生 AE 所需的 PGD 鏈長。此外，我們的研究提供了關於視覺和語言模型之間的概括性和穩健性趨勢差異的第一個解釋，據我們所知，即 AT 導致視覺模型的概括性下降，而在基於編碼器的語言模型中，概括性則會改善或保持不變。我們表明，視覺變換器和基於解碼器的模型在網路的早期層中往往具有較低的內在維度（更多流形外 AE），而基於編碼器的模型在後來的層中具有較低的內在維度。我們展示了 SMAAT 的功效；在多項任務中，包括強化 (i) 情緒分類器、(ii) 基於解碼器的模型中的安全篩選器，以及 (iii) RAG 設定中的檢索器。與標準 AT 相比，SMAAT 只需要 25-33% 的 GPU 時間，同時顯著提高了所有應用程式的穩健性，並維持了相當的概括性。

##### **TEII: Think, Explain, Interact and Iterate with Large Language Models to Solve Cross-lingual Emotion Detection**
2405.17129v1 by Long Cheng, Qihao Shao, Christine Zhao, Sheng Bi, Gina-Anne Levow

Cross-lingual emotion detection allows us to analyze global trends, public
opinion, and social phenomena at scale. We participated in the Explainability
of Cross-lingual Emotion Detection (EXALT) shared task, achieving an F1-score
of 0.6046 on the evaluation set for the emotion detection sub-task. Our system
outperformed the baseline by more than 0.16 F1-score absolute, and ranked
second amongst competing systems. We conducted experiments using fine-tuning,
zero-shot learning, and few-shot learning for Large Language Model (LLM)-based
models as well as embedding-based BiLSTM and KNN for non-LLM-based techniques.
Additionally, we introduced two novel methods: the Multi-Iteration Agentic
Workflow and the Multi-Binary-Classifier Agentic Workflow. We found that
LLM-based approaches provided good performance on multilingual emotion
detection. Furthermore, ensembles combining all our experimented models yielded
higher F1-scores than any single approach alone.

摘要：跨語言情緒偵測讓我們得以大規模分析全球趨勢、輿論和社會現象。我們參與了跨語言情緒偵測解釋能力 (EXALT) 共享任務，在情緒偵測子任務的評估集中取得了 0.6046 的 F1 分數。我們的系統在絕對 F1 分數上優於基準線 0.16 分以上，在競爭系統中排名第二。我們使用微調、零次學習和少量學習對大型語言模型 (LLM) 進行了實驗，並對非 LLM 技術使用了基於嵌入的 BiLSTM 和 KNN。此外，我們引入了兩種新方法：多重迭代代理工作流程和多二進制分類器代理工作流程。我們發現，LLM 方法在多語言情緒偵測上提供了良好的效能。此外，結合我們所有實驗模型的集成體比任何單一方法單獨產生的 F1 分數更高。

##### **Mixtures of Unsupervised Lexicon Classification**
2405.17116v1 by Peratham Wiriyathammabhum

This paper presents a mixture version of the method-of-moment unsupervised
lexicon classification by an incorporation of a Dirichlet process.

摘要：本文提出了一個方法矩無監督詞彙分類的混合版本，並結合了狄利克雷過程。

##### **Superpixelwise Low-rank Approximation based Partial Label Learning for Hyperspectral Image Classification**
2405.17110v1 by Shujun Yang, Yu Zhang, Yao Ding, Danfeng Hong

Insufficient prior knowledge of a captured hyperspectral image (HSI) scene
may lead the experts or the automatic labeling systems to offer incorrect
labels or ambiguous labels (i.e., assigning each training sample to a group of
candidate labels, among which only one of them is valid; this is also known as
partial label learning) during the labeling process. Accordingly, how to learn
from such data with ambiguous labels is a problem of great practical
importance. In this paper, we propose a novel superpixelwise low-rank
approximation (LRA)-based partial label learning method, namely SLAP, which is
the first to take into account partial label learning in HSI classification.
SLAP is mainly composed of two phases: disambiguating the training labels and
acquiring the predictive model. Specifically, in the first phase, we propose a
superpixelwise LRA-based model, preparing the affinity graph for the subsequent
label propagation process while extracting the discriminative representation to
enhance the following classification task of the second phase. Then to
disambiguate the training labels, label propagation propagates the labeling
information via the affinity graph of training pixels. In the second phase, we
take advantage of the resulting disambiguated training labels and the
discriminative representations to enhance the classification performance. The
extensive experiments validate the advantage of the proposed SLAP method over
state-of-the-art methods.

摘要：<paragraph>對於擷取的高光譜影像 (HSI) 場景缺乏先備知識，可能會導致專家或自動標籤系統在標籤過程中提供不正確的標籤或模稜兩可的標籤（即，將每個訓練樣本分配給一組候選標籤，其中只有一個是有效的；這也稱為部分標籤學習）。因此，如何從具有模稜兩可標籤的此類資料中學習是一個非常重要的實際問題。在本文中，我們提出了一種新的超像素低秩近似 (LRA) 為基礎的部分標籤學習方法，稱為 SLAP，這是第一個在 HSI 分類中考慮部分標籤學習的方法。SLAP 主要包含兩個階段：消除訓練標籤的歧義和獲取預測模型。具體來說，在第一階段，我們提出了一個基於超像素 LRA 的模型，為後續標籤傳播過程準備親和圖，同時提取判別式表示以增強第二階段的後續分類任務。然後，為了消除訓練標籤的歧義，標籤傳播通過訓練像素的親和圖傳播標籤資訊。在第二階段，我們利用產生的消除歧義的訓練標籤和判別式表示來增強分類效能。廣泛的實驗驗證了所提出的 SLAP 方法優於最先進方法的優勢。</paragraph>

##### **LLM-Optic: Unveiling the Capabilities of Large Language Models for Universal Visual Grounding**
2405.17104v2 by Haoyu Zhao, Wenhang Ge, Ying-cong Chen

Visual grounding is an essential tool that links user-provided text queries
with query-specific regions within an image. Despite advancements in visual
grounding models, their ability to comprehend complex queries remains limited.
To overcome this limitation, we introduce LLM-Optic, an innovative method that
utilizes Large Language Models (LLMs) as an optical lens to enhance existing
visual grounding models in comprehending complex text queries involving
intricate text structures, multiple objects, or object spatial relationships,
situations that current models struggle with. LLM-Optic first employs an LLM as
a Text Grounder to interpret complex text queries and accurately identify
objects the user intends to locate. Then a pre-trained visual grounding model
is used to generate candidate bounding boxes given the refined query by the
Text Grounder. After that, LLM-Optic annotates the candidate bounding boxes
with numerical marks to establish a connection between text and specific image
regions, thereby linking two distinct modalities. Finally, it employs a Large
Multimodal Model (LMM) as a Visual Grounder to select the marked candidate
objects that best correspond to the original text query. Through LLM-Optic, we
have achieved universal visual grounding, which allows for the detection of
arbitrary objects specified by arbitrary human language input. Importantly, our
method achieves this enhancement without requiring additional training or
fine-tuning. Extensive experiments across various challenging benchmarks
demonstrate that LLM-Optic achieves state-of-the-art zero-shot visual grounding
capabilities. Project Page: https://haoyu-zhao.github.io/LLM-Optic.github.io/.

摘要：視覺基礎是一個重要的工具，它將使用者提供的文字查詢與影像中特定於查詢的區域連結起來。儘管視覺基礎模型有進展，它們理解複雜查詢的能力仍然有限。為了克服這個限制，我們引入了 LLM-Optic，這是一種創新的方法，它利用大型語言模型 (LLM) 作為一個光學透鏡，以增強現有的視覺基礎模型，理解涉及複雜文字結構、多個物件或物件空間關係的複雜文字查詢，這是目前模型難以處理的情況。LLM-Optic 首先使用 LLM 作為文字基礎，來詮釋複雜的文字查詢，並準確辨識使用者想要定位的物件。然後使用預先訓練的視覺基礎模型，根據文字基礎所精煉的查詢產生候選邊界框。在那之後，LLM-Optic 使用數字標記註解候選邊界框，以便在文字和特定影像區域之間建立關聯，從而連結兩個不同的模態。最後，它使用大型多模態模型 (LMM) 作為視覺基礎，來選擇標記的候選物件，這些物件最符合原始文字查詢。透過 LLM-Optic，我們達到了通用的視覺基礎，這允許偵測由任意人類語言輸入指定的任意物件。重要的是，我們的方法在不需要額外訓練或微調的情況下實現了這種增強。透過各種具有挑戰性的基準測試進行的廣泛實驗證明，LLM-Optic 達到了最先進的零次視覺基礎能力。專案頁面：https://haoyu-zhao.github.io/LLM-Optic.github.io/。

##### **Empowering Character-level Text Infilling by Eliminating Sub-Tokens**
2405.17103v1 by Houxing Ren, Mingjie Zhan, Zhongyuan Wu, Hongsheng Li

In infilling tasks, sub-tokens, representing instances where a complete token
is segmented into two parts, often emerge at the boundaries of prefixes,
middles, and suffixes. Traditional methods focused on training models at the
token level, leading to sub-optimal performance in character-level infilling
tasks during the inference stage. Alternately, some approaches considered
character-level infilling, but they relied on predicting sub-tokens in
inference, yet this strategy diminished ability in character-level infilling
tasks due to the large perplexity of the model on sub-tokens. In this paper, we
introduce FIM-SE, which stands for Fill-In-the-Middle with both Starting and
Ending character constraints. The proposed method addresses character-level
infilling tasks by utilizing a line-level format to avoid predicting any
sub-token in inference. In addition, we incorporate two special tokens to
signify the rest of the incomplete lines, thereby enhancing generation
guidance. Extensive experiments demonstrate that our proposed approach
surpasses previous methods, offering a significant advantage. Code is available
at https://github.com/SenseLLM/FIM-SE.

摘要：在填充任務中，子代幣（表示將一個完整代幣分割成兩部分的實例）通常出現在前綴、中間和後綴的邊界。傳統方法專注於在代幣級別訓練模型，導致在推理階段字元級別填充任務的效能不佳。或者，一些方法考慮了字元級別填充，但它們依賴於在推理中預測子代幣，然而，由於模型對子代幣的困惑性很大，這種策略降低了字元級別填充任務的能力。在本文中，我們介紹了 FIM-SE，它代表了具有開始和結束字元約束的填充中間。所提出的方法通過利用行級格式來解決字元級別填充任務，以避免在推理中預測任何子代幣。此外，我們加入了兩個特殊代幣來表示不完整行的其餘部分，從而增強了生成指導。大量的實驗表明，我們提出的方法優於以前的方法，提供了顯著的優勢。程式碼可在 https://github.com/SenseLLM/FIM-SE 中取得。

##### **Phase Transitions in the Output Distribution of Large Language Models**
2405.17088v1 by Julian Arnold, Flemming Holtorf, Frank Schäfer, Niels Lörch

In a physical system, changing parameters such as temperature can induce a
phase transition: an abrupt change from one state of matter to another.
Analogous phenomena have recently been observed in large language models.
Typically, the task of identifying phase transitions requires human analysis
and some prior understanding of the system to narrow down which low-dimensional
properties to monitor and analyze. Statistical methods for the automated
detection of phase transitions from data have recently been proposed within the
physics community. These methods are largely system agnostic and, as shown
here, can be adapted to study the behavior of large language models. In
particular, we quantify distributional changes in the generated output via
statistical distances, which can be efficiently estimated with access to the
probability distribution over next-tokens. This versatile approach is capable
of discovering new phases of behavior and unexplored transitions -- an ability
that is particularly exciting in light of the rapid development of language
models and their emergent capabilities.

摘要：在物理系統中，改變溫度等參數會誘發相變：物質從一種狀態突然轉變為另一種狀態。最近在大語言模型中觀察到了類似的現象。通常，識別相變的任務需要人工分析和對系統的一些先驗理解，以縮小要監控和分析的低維屬性範圍。最近在物理界提出了從數據中自動檢測相變的統計方法。這些方法在很大程度上與系統無關，並且如本文所示，可以適應於研究大語言模型的行為。特別是，我們通過統計距離量化生成輸出中的分佈變化，這些距離可以使用對下一個符號的概率分佈進行有效估計。這種通用方法能夠發現新的行為階段和未探索的轉變——這種能力在語言模型快速發展及其新興能力的背景下尤其令人興奮。

##### **Leveraging small language models for Text2SPARQL tasks to improve the resilience of AI assistance**
2405.17076v1 by Felix Brei, Johannes Frey, Lars-Peter Meyer

In this work we will show that language models with less than one billion
parameters can be used to translate natural language to SPARQL queries after
fine-tuning. Using three different datasets ranging from academic to real
world, we identify prerequisites that the training data must fulfill in order
for the training to be successful. The goal is to empower users of semantic web
technology to use AI assistance with affordable commodity hardware, making them
more resilient against external factors.

摘要：在這項工作中，我們將展示小於十億個參數的語言模型，在微調後可用於將自然語言轉換為 SPARQL 查詢。使用三個不同的資料集，從學術到真實世界，我們找出訓練資料必須滿足的先決條件，才能讓訓練成功。目標是讓語意網路技術的使用者能夠使用負擔得起的商品硬體的 AI 協助，讓他們對外部因素更有韌性。

##### **Tokenization Matters! Degrading Large Language Models through Challenging Their Tokenization**
2405.17067v1 by Dixuan Wang, Yanda Li, Junyuan Jiang, Zepeng Ding, Guochao Jiang, Jiaqing Liang, Deqing Yang

Large Language Models (LLMs) have shown remarkable capabilities in language
understanding and generation. Nonetheless, it was also witnessed that LLMs tend
to produce inaccurate responses to specific queries. This deficiency can be
traced to the tokenization step LLMs must undergo, which is an inevitable
limitation inherent to all LLMs. In fact, incorrect tokenization is the
critical point that hinders LLMs in understanding the input precisely, thus
leading to unsatisfactory output. To demonstrate this flaw of LLMs, we
construct an adversarial dataset, named as $\textbf{ADT (Adversarial Dataset
for Tokenizer)}$, which draws upon the vocabularies of various open-source LLMs
to challenge LLMs' tokenization. ADT consists of two subsets: the manually
constructed ADT-Human and the automatically generated ADT-Auto. Our empirical
results reveal that our ADT is highly effective on challenging the tokenization
of leading LLMs, including GPT-4o, Llama-3, Qwen2.5-max and so on, thus
degrading these LLMs' capabilities. Moreover, our method of automatic data
generation has been proven efficient and robust, which can be applied to any
open-source LLMs. To the best of our knowledge, our study is the first to
investigating LLMs' vulnerability in terms of challenging their token
segmentation, which will shed light on the subsequent research of improving
LLMs' capabilities through optimizing their tokenization process and
algorithms.

摘要：大型語言模型 (LLM) 在語言理解和生成方面展現出驚人的能力。儘管如此，我們也觀察到 LLM 傾向於對特定查詢產生不準確的回應。這種缺陷可以追溯到 LLM 必須經歷的標記化步驟，這是所有 LLM 固有的不可避免的限制。事實上，不正確的標記化是阻礙 LLM 精確理解輸入的關鍵點，從而導致不令人滿意的輸出。為了證明 LLM 的這個缺陷，我們構建了一個對抗性資料集，稱為 $\textbf{ADT（標記化對抗性資料集）}$，它利用了各種開源 LLM 的詞彙來挑戰 LLM 的標記化。ADT 包含兩個子集：手動構建的 ADT-Human 和自動生成的 ADT-Auto。我們的實證結果表明，我們的 ADT 在挑戰包括 GPT-4o、Llama-3、Qwen2.5-max 等領先 LLM 的標記化方面非常有效，從而降低了這些 LLM 的能力。此外，我們的自動資料生成方法已被證明是高效且強大的，可以應用於任何開源 LLM。據我們所知，我們的研究是第一個在挑戰 LLM 的標記分割方面的漏洞進行調查的研究，這將為通過優化其標記化過程和演算法來改進 LLM 能力的後續研究提供指引。

##### **Unifying Demonstration Selection and Compression for In-Context Learning**
2405.17062v1 by Jun Gao

In-context learning (ICL) facilitates large language models (LLMs) exhibiting
spectacular emergent capabilities in various scenarios. Unfortunately,
introducing demonstrations easily makes the prompt length explode, bringing a
significant burden to hardware. In addition, random demonstrations usually
achieve limited improvements in ICL, necessitating demonstration selection
among accessible candidates. Previous studies introduce extra modules to
perform demonstration compression or selection independently. In this paper, we
propose an ICL framework UniICL, which Unifies demonstration selection and
compression, and final response generation via a single frozen LLM.
Specifically, UniICL first projects actual demonstrations and inference text
inputs into short virtual tokens, respectively. Then, virtual tokens are
applied to select suitable demonstrations by measuring semantic similarity
within latent space among candidate demonstrations and inference input.
Finally, inference text inputs together with selected virtual demonstrations
are fed into the same frozen LLM for response generation. Notably, UniICL is a
parameter-efficient framework that only contains 17M trainable parameters
originating from the projection layer. We conduct experiments and analysis over
in- and out-domain datasets of both generative and understanding tasks,
encompassing ICL scenarios with plentiful and limited demonstration candidates.
Results show that UniICL effectively unifies $12 \times$ compression,
demonstration selection, and response generation, efficiently scaling up the
baseline from 4-shot to 64-shot ICL in IMDb with 24 GB CUDA allocation

摘要：語境學習 (ICL) 促進大型語言模型 (LLM) 在各種場景中展現出驚人的新興能力。不幸的是，引入示範很容易使提示長度暴增，給硬體帶來顯著負擔。此外，隨機示範通常只能在 ICL 中實現有限的改進，因此需要在可訪問的候選者中選擇示範。先前的研究引入了額外的模組來獨立執行示範壓縮或選擇。在本文中，我們提出了一個 ICL 框架 UniICL，它通過單一的凍結 LLM 統一了示範選擇和壓縮，以及最終回應產生。具體來說，UniICL 首先分別將實際示範和推論文字輸入投影到簡短的虛擬代幣中。然後，通過測量候選示範和推論輸入之間潛在空間中的語義相似性，將虛擬代幣應用於選擇合適的示範。最後，推論文字輸入與選定的虛擬示範一起被輸入到同一個凍結的 LLM 中以產生回應。值得注意的是，UniICL 是一個參數高效的框架，僅包含源自投影層的 17M 可訓練參數。我們對生成和理解任務的域內和域外資料集進行了實驗和分析，涵蓋了具有豐富和有限示範候選者的 ICL 場景。結果表明，UniICL 有效地統一了 $12 \times$ 壓縮、示範選擇和回應產生，有效地將 IMDb 中的基準從 4-shot 擴展到 64-shot ICL，CUDA 分配為 24 GB

##### **Graph Neural Networks on Quantum Computers**
2405.17060v1 by Yidong Liao, Xiao-Ming Zhang, Chris Ferrie

Graph Neural Networks (GNNs) are powerful machine learning models that excel
at analyzing structured data represented as graphs, demonstrating remarkable
performance in applications like social network analysis and recommendation
systems. However, classical GNNs face scalability challenges when dealing with
large-scale graphs. This paper proposes frameworks for implementing GNNs on
quantum computers to potentially address the challenges. We devise quantum
algorithms corresponding to the three fundamental types of classical GNNs:
Graph Convolutional Networks, Graph Attention Networks, and Message-Passing
GNNs. A complexity analysis of our quantum implementation of the Simplified
Graph Convolutional (SGC) Network shows potential quantum advantages over its
classical counterpart, with significant improvements in time and space
complexities. Our complexities can have trade-offs between the two: when
optimizing for minimal circuit depth, our quantum SGC achieves logarithmic time
complexity in the input sizes (albeit at the cost of linear space complexity).
When optimizing for minimal qubit usage, the quantum SGC exhibits space
complexity logarithmic in the input sizes, offering an exponential reduction
compared to classical SGCs, while still maintaining better time complexity.
These results suggest our Quantum GNN frameworks could efficiently process
large-scale graphs. This work paves the way for implementing more advanced
Graph Neural Network models on quantum computers, opening new possibilities in
quantum machine learning for analyzing graph-structured data.

摘要：圖形神經網路 (GNN) 是一種強大的機器學習模型，擅長分析以圖形表示的結構化資料，在社交網路分析和推薦系統等應用中展現出卓越的效能。然而，傳統的 GNN 在處理大規模圖形時面臨可擴充性的挑戰。本文提出在量子電腦上實作 GNN 的架構，以潛在解決這些挑戰。我們設計出對應於三種類型的傳統 GNN 的量子演算法：圖形卷積網路、圖形注意力網路和訊息傳遞 GNN。對我們簡化圖形卷積 (SGC) 網路的量子實作進行的複雜度分析顯示出潛在的量子優勢，在時間和空間複雜度方面有顯著的改善。我們的複雜度可以在兩者之間進行權衡：在最佳化最小電路深度時，我們的量子 SGC 在輸入大小上實現了對數時間複雜度（儘管以線性空間複雜度為代價）。在最佳化最小量子位元使用時，量子 SGC 展現出對數輸入大小的空間複雜度，與傳統 SGC 相比提供了指數級的減少，同時仍維持較佳的時間複雜度。這些結果表明我們的量子 GNN 框架可以有效率地處理大規模圖形。這項工作為在量子電腦上實作更進階的圖形神經網路模型鋪路，為分析圖形結構化資料的量子機器學習開啟了新的可能性。

##### **ReflectionCoder: Learning from Reflection Sequence for Enhanced One-off Code Generation**
2405.17057v1 by Houxing Ren, Mingjie Zhan, Zhongyuan Wu, Aojun Zhou, Junting Pan, Hongsheng Li

Code generation plays a crucial role in various tasks, such as code
auto-completion and mathematical reasoning. Previous work has proposed numerous
methods to enhance code generation performance, including integrating feedback
from the compiler. Inspired by this, we present ReflectionCoder, a novel
approach that effectively leverages reflection sequences constructed by
integrating compiler feedback to improve one-off code generation performance.
Furthermore, we propose reflection self-distillation and dynamically masked
distillation to effectively utilize these reflection sequences. Extensive
experiments on three benchmarks, i.e., HumanEval (+), MBPP (+), and MultiPl-E,
demonstrate that models fine-tuned with our method achieve state-of-the-art
performance. Notably, ReflectionCoder-DeepSeek-Coder-33B reaches pass@1 of 82.9
(76.8) on HumanEval (+) and 84.1 (72.0) on MBPP (+), on par with GPT-3.5-Turbo
and Claude-3-opus, and surpasses early GPT-4. Beyond the code domain, we
believe this approach can benefit other domains that focus on final results and
require long reasoning paths. Code and data are available at
https://github.com/SenseLLM/ReflectionCoder.

摘要：程式碼生成在各種任務中扮演至關重要的角色，例如程式碼自動完成和數學推理。先前的研究已經提出許多方法來增強程式碼生成效能，包括整合編譯器的回饋。受到此啟發，我們提出 ReflectionCoder，一種創新的方法，它有效地利用整合編譯器回饋所建構的反思序列來提升一次性程式碼生成效能。此外，我們提出反思自我萃取和動態遮罩萃取來有效利用這些反思序列。在三個基準 HumanEval (+)、MBPP (+) 和 MultiPl-E 上的廣泛實驗證明，使用我們的方法微調的模型達到了最先進的效能。值得注意的是，ReflectionCoder-DeepSeek-Coder-33B 在 HumanEval (+) 上達到 82.9 (76.8) 的 pass@1，在 MBPP (+) 上達到 84.1 (72.0)，與 GPT-3.5-Turbo 和 Claude-3-opus 相當，並超越早期的 GPT-4。除了程式碼領域之外，我們相信這種方法可以使專注於最終結果且需要長時間推理路徑的其他領域受益。程式碼和資料可在 https://github.com/SenseLLM/ReflectionCoder 取得。

##### **WirelessLLM: Empowering Large Language Models Towards Wireless Intelligence**
2405.17053v1 by Jiawei Shao, Jingwen Tong, Qiong Wu, Wei Guo, Zijian Li, Zehong Lin, Jun Zhang

The rapid evolution of wireless technologies and the growing complexity of
network infrastructures necessitate a paradigm shift in how communication
networks are designed, configured, and managed. Recent advancements in Large
Language Models (LLMs) have sparked interest in their potential to
revolutionize wireless communication systems. However, existing studies on LLMs
for wireless systems are limited to a direct application for telecom language
understanding. To empower LLMs with knowledge and expertise in the wireless
domain, this paper proposes WirelessLLM, a comprehensive framework for adapting
and enhancing LLMs to address the unique challenges and requirements of
wireless communication networks. We first identify three foundational
principles that underpin WirelessLLM: knowledge alignment, knowledge fusion,
and knowledge evolution. Then, we investigate the enabling technologies to
build WirelessLLM, including prompt engineering, retrieval augmented
generation, tool usage, multi-modal pre-training, and domain-specific
fine-tuning. Moreover, we present three case studies to demonstrate the
practical applicability and benefits of WirelessLLM for solving typical
problems in wireless networks. Finally, we conclude this paper by highlighting
key challenges and outlining potential avenues for future research.

摘要：無線技術的快速演進和網路基礎架構日益複雜，迫使我們在通訊網路的設計、組態和管理方式上進行典範轉移。大型語言模型 (LLM) 的最新進展，激發了人們對其在無線通訊系統中潛在變革力的興趣。然而，現有針對無線系統的 LLM 研究僅限於電信語言理解的直接應用。為了讓 LLM 擁有無線領域的知識和專業知識，本文提出了 WirelessLLM，一個全面的架構，用於調整和增強 LLM 以應對無線通訊網路的獨特挑戰和需求。我們首先找出支撐 WirelessLLM 的三個基本原則：知識對齊、知識融合和知識演進。接著，我們探討建構 WirelessLLM 的技術，包括提示工程、檢索增強生成、工具使用、多模態預訓練和特定領域微調。此外，我們提出三個案例研究，以展示 WirelessLLM 解決無線網路中典型問題的實際應用性和好處。最後，我們透過強調關鍵挑戰和概述未來研究的潛在途徑，來為本文作結。

##### **SelfCP: Compressing Long Prompt to 1/12 Using the Frozen Large Language Model Itself**
2405.17052v1 by Jun Gao

Long prompt leads to huge hardware costs when using Large Language Models
(LLMs). Unfortunately, many tasks, such as summarization, inevitably introduce
long task-inputs, and the wide application of in-context learning easily makes
the prompt length explode. Inspired by the language understanding ability of
LLMs, this paper proposes SelfCP, which uses the LLM \textbf{itself} to
\textbf{C}ompress long \textbf{P}rompt into compact virtual tokens. SelfCP
applies a general frozen LLM twice, first as an encoder to compress the prompt
and then as a decoder to generate responses. Specifically, given a long prompt,
we place special tokens within the lengthy segment for compression and signal
the LLM to generate $k$ virtual tokens. Afterward, the virtual tokens
concatenate with the uncompressed prompt and are fed into the same LLM to
generate the response. In general, SelfCP facilitates the unconditional and
conditional compression of prompts, fitting both standard tasks and those with
specific objectives. Since the encoder and decoder are frozen, SelfCP only
contains 17M trainable parameters and allows for convenient adaptation across
various backbones. We implement SelfCP with two LLM backbones and evaluate it
in both in- and out-domain tasks. Results show that the compressed virtual
tokens can substitute $12 \times$ larger original prompts effectively

摘要：使用大型语言模型 (LLM) 时，长提示会导致巨大的硬件成本。不幸的是，许多任务（例如摘要）不可避免地会引入长任务输入，并且上下文中学习的广泛应用很容易使提示长度爆炸。受 LLM 的语言理解能力的启发，本文提出了 SelfCP，它使用 LLM 本身将长提示压缩成紧凑的虚拟标记。SelfCP 两次应用通用的冻结 LLM，首先作为编码器来压缩提示，然后作为解码器来生成响应。具体来说，给定一个长提示，我们在冗长的压缩段中放置特殊标记，并发出信号让 LLM 生成 k 个虚拟标记。之后，虚拟标记与未压缩的提示连接，并馈送到相同的 LLM 以生成响应。通常，SelfCP 促进了提示的无条件和条件压缩，既适用于标准任务，也适用于具有特定目标的任务。由于编码器和解码器被冻结，SelfCP 仅包含 17M 可训练参数，并允许跨各种主干进行方便的适应。我们使用两个 LLM 主干实现了 SelfCP，并在域内和域外任务中对其进行了评估。结果表明，压缩的虚拟标记可以有效地替代大 12 倍的原始提示

##### **BeamVQ: Aligning Space-Time Forecasting Model via Self-training on Physics-aware Metrics**
2405.17051v1 by Hao Wu, Xingjian Shi, Ziyue Huang, Penghao Zhao, Wei Xiong, Jinbao Xue, Yangyu Tao, Xiaomeng Huang, Weiyan Wang

Data-driven deep learning has emerged as the new paradigm to model complex
physical space-time systems. These data-driven methods learn patterns by
optimizing statistical metrics and tend to overlook the adherence to physical
laws, unlike traditional model-driven numerical methods. Thus, they often
generate predictions that are not physically realistic. On the other hand, by
sampling a large amount of high quality predictions from a data-driven model,
some predictions will be more physically plausible than the others and closer
to what will happen in the future. Based on this observation, we propose
\emph{Beam search by Vector Quantization} (BeamVQ) to enhance the physical
alignment of data-driven space-time forecasting models. The key of BeamVQ is to
train model on self-generated samples filtered with physics-aware metrics. To
be flexibly support different backbone architectures, BeamVQ leverages a code
bank to transform any encoder-decoder model to the continuous state space into
discrete codes. Afterwards, it iteratively employs beam search to sample
high-quality sequences, retains those with the highest physics-aware scores,
and trains model on the new dataset. Comprehensive experiments show that BeamVQ
not only gave an average statistical skill score boost for more than 32% for
ten backbones on five datasets, but also significantly enhances physics-aware
metrics.

摘要：資料驅動深度學習已成為建模複雜物理時空系統的新典範。這些資料驅動方法透過最佳化統計量度來學習模式，且傾向忽略對物理定律的遵守，這與傳統模型驅動數值方法不同。因此，它們經常產生不符合物理現實的預測。另一方面，藉由從資料驅動模型中抽樣大量高品質預測，有些預測將比其他預測更合乎物理且更接近未來會發生的事。基於此觀察，我們提出「向量量化光束搜尋」（BeamVQ）來增強資料驅動時空預測模型的物理對齊。BeamVQ 的關鍵在於針對經過物理感知量度過濾的自生樣本訓練模型。為了靈活支援不同的主幹架構，BeamVQ 採用代碼庫將任何編碼器解碼器模型轉換為連續狀態空間中的離散代碼。接著，它會反覆使用光束搜尋來抽樣高品質序列，保留物理感知分數最高的序列，並針對新資料集訓練模型。全面的實驗顯示，BeamVQ 不僅讓五個資料集上的十個主幹的平均統計技能分數提升超過 32%，也大幅提升了物理感知量度。

##### **Generation and human-expert evaluation of interesting research ideas using knowledge graphs and large language models**
2405.17044v1 by Xuemei Gu, Mario Krenn

Advanced artificial intelligence (AI) systems with access to millions of
research papers could inspire new research ideas that may not be conceived by
humans alone. However, how interesting are these AI-generated ideas, and how
can we improve their quality? Here, we introduce SciMuse, a system that uses an
evolving knowledge graph built from more than 58 million scientific papers to
generate personalized research ideas via an interface to GPT-4. We conducted a
large-scale human evaluation with over 100 research group leaders from the Max
Planck Society, who ranked more than 4,000 personalized research ideas based on
their level of interest. This evaluation allows us to understand the
relationships between scientific interest and the core properties of the
knowledge graph. We find that data-efficient machine learning can predict
research interest with high precision, allowing us to optimize the
interest-level of generated research ideas. This work represents a step towards
an artificial scientific muse that could catalyze unforeseen collaborations and
suggest interesting avenues for scientists.

摘要：進階人工智慧（AI）系統能存取數百萬篇研究論文，這能激發人類單獨無法構思的新研究點子。然而，這些 AI 生成的點子有多有趣，我們又該如何提升它們的品質？在此，我們介紹 SciMuse，一個利用從超過 5800 萬篇科學論文建構的演化知識圖譜，透過與 GPT-4 的介面產生個人化研究點子的系統。我們執行了大規模的人類評估，由超過 100 位來自馬克斯普朗克學會的研究小組負責人，根據他們的興趣等級對超過 4000 個個人化研究點子進行排名。這項評估讓我們得以了解科學興趣與知識圖譜核心屬性之間的關係。我們發現資料有效率的機器學習可以高精準度預測研究興趣，讓我們能最佳化生成研究點子的興趣等級。這項工作代表邁向人工科學繆思的一步，它能催化預想不到的協作，並為科學家建議有趣的途徑。

##### **BWArea Model: Learning World Model, Inverse Dynamics, and Policy for Controllable Language Generation**
2405.17039v1 by Chengxing Jia, Pengyuan Wang, Ziniu Li, Yi-Chen Li, Zhilong Zhang, Nan Tang, Yang Yu

Large language models (LLMs) have catalyzed a paradigm shift in natural
language processing, yet their limited controllability poses a significant
challenge for downstream applications. We aim to address this by drawing
inspiration from the neural mechanisms of the human brain, specifically Broca's
and Wernicke's areas, which are crucial for language generation and
comprehension, respectively. In particular, Broca's area receives cognitive
decision signals from Wernicke's area, treating the language generation as an
intricate decision-making process, which differs from the fully auto-regressive
language generation of existing LLMs. In a similar vein, our proposed system,
the BWArea model, conceptualizes language generation as a decision-making task.
This model has three components: a language world model, an inverse dynamics
model, and a cognitive policy. Like Wernicke's area, the inverse dynamics model
is designed to deduce the underlying cognitive intentions, or latent actions,
behind each token. The BWArea model is amenable to both pre-training and
fine-tuning like existing LLMs. With 30B clean pre-training tokens, we have
trained a BWArea model, which achieves competitive performance with LLMs of
equal size (1B parameters). Unlike fully auto-regressive LLMs, its pre-training
performance does not degenerate if dirty data unintentionally appears. This
shows the advantage of a decomposed structure of BWArea model in reducing
efforts in laborious data selection and labeling. Finally, we reveal that the
BWArea model offers enhanced controllability via fine-tuning the cognitive
policy with downstream reward metrics, thereby facilitating alignment with
greater simplicity. On 9 out of 10 tasks from two suites, TextWorld and
BigBench Hard, our method shows superior performance to auto-regressive LLMs.

摘要：大型語言模型 (LLM) 已催化自然語言處理的典範轉移，但其有限的可控性對下游應用程式構成重大挑戰。我們旨在透過汲取人類大腦的神經機制，特別是布洛卡區和韋尼克區的靈感來解決此問題，這些區域分別對語言生成和理解至關重要。特別是，布洛卡區從韋尼克區接收認知決策訊號，將語言生成視為一個複雜的決策制定過程，這不同於現有 LLM 的完全自迴歸語言生成。同樣地，我們提出的系統，即 BWArea 模型，將語言生成概念化為一個決策制定任務。此模型有三個組成部分：語言世界模型、逆動力模型和認知策略。與韋尼克區一樣，逆動力模型被設計為推論每個標記背後的潛在認知意圖或潛在動作。BWArea 模型適用於預訓練和微調，就像現有的 LLM 一樣。使用 30B 個乾淨的預訓練代幣，我們訓練了一個 BWArea 模型，其與大小相等 (1B 個參數) 的 LLM 達到了競爭性的效能。與完全自迴歸的 LLM 不同，如果意外出現髒數據，其預訓練效能不會退化。這顯示了 BWArea 模型分解結構在減少繁瑣數據選擇和標記工作方面的優勢。最後，我們揭示了 BWArea 模型透過使用下游獎勵指標微調認知策略來提供增強的可控性，從而促進與更大簡潔性的對齊。在兩個套件（TextWorld 和 BigBench Hard）的 10 個任務中有 9 個，我們的模型顯示出優於自迴歸 LLM 的效能。

##### **SWAT: Scalable and Efficient Window Attention-based Transformers Acceleration on FPGAs**
2405.17025v1 by Zhenyu Bai, Pranav Dangi, Huize Li, Tulika Mitra

Efficiently supporting long context length is crucial for Transformer models.
The quadratic complexity of the self-attention computation plagues traditional
Transformers. Sliding window-based static sparse attention mitigates the
problem by limiting the attention scope of the input tokens, reducing the
theoretical complexity from quadratic to linear. Although the sparsity induced
by window attention is highly structured, it does not align perfectly with the
microarchitecture of the conventional accelerators, leading to suboptimal
implementation. In response, we propose a dataflow-aware FPGA-based accelerator
design, SWAT, that efficiently leverages the sparsity to achieve scalable
performance for long input. The proposed microarchitecture is based on a design
that maximizes data reuse by using a combination of row-wise dataflow, kernel
fusion optimization, and an input-stationary design considering the distributed
memory and computation resources of FPGA. Consequently, it achieves up to
22$\times$ and 5.7$\times$ improvement in latency and energy efficiency
compared to the baseline FPGA-based accelerator and 15$\times$ energy
efficiency compared to GPU-based solution.

摘要：有效支援長背景長度對 Transformer 模型至關重要。
自注意力運算的二次複雜度困擾著傳統 Transformer。
基於滑動視窗的靜態稀疏注意力透過限制輸入標記的注意力範圍來減輕問題，將理論複雜度從二次降低到線性。
雖然視窗注意力所引發的稀疏性高度結構化，但它與傳統加速器的微架構並不完全一致，導致次佳實作。
為了解決這個問題，我們提出一個資料流程感知的基於 FPGA 的加速器設計 SWAT，它有效利用稀疏性，以達成長輸入的可擴充效能。
所提出的微架構基於一種設計，它透過結合逐行資料流程、核心融合最佳化以及考量 FPGA 的分散式記憶體和運算資源的輸入靜止設計來最大化資料重複使用。
因此，與基線的基於 FPGA 的加速器相比，它在延遲和能源效率方面分別達到了 22 倍和 5.7 倍的提升，與基於 GPU 的解決方案相比，能源效率提升了 15 倍。

##### **Compositional Few-Shot Class-Incremental Learning**
2405.17022v1 by Yixiong Zou, Shanghang Zhang, Haichen Zhou, Yuhua Li, Ruixuan Li

Few-shot class-incremental learning (FSCIL) is proposed to continually learn
from novel classes with only a few samples after the (pre-)training on base
classes with sufficient data. However, this remains a challenge. In contrast,
humans can easily recognize novel classes with a few samples. Cognitive science
demonstrates that an important component of such human capability is
compositional learning. This involves identifying visual primitives from
learned knowledge and then composing new concepts using these transferred
primitives, making incremental learning both effective and interpretable. To
imitate human compositional learning, we propose a cognitive-inspired method
for the FSCIL task. We define and build a compositional model based on set
similarities, and then equip it with a primitive composition module and a
primitive reuse module. In the primitive composition module, we propose to
utilize the Centered Kernel Alignment (CKA) similarity to approximate the
similarity between primitive sets, allowing the training and evaluation based
on primitive compositions. In the primitive reuse module, we enhance primitive
reusability by classifying inputs based on primitives replaced with the closest
primitives from other classes. Experiments on three datasets validate our
method, showing it outperforms current state-of-the-art methods with improved
interpretability. Our code is available at
https://github.com/Zoilsen/Comp-FSCIL.

摘要：少樣本類別增量學習 (FSCIL) 被提議用於在以充足資料對基礎類別進行 (預) 訓練後，僅使用少量樣本持續學習新穎類別。然而，這仍然是一個挑戰。相反地，人類可以輕鬆地使用少量樣本識別新穎類別。認知科學證明，這種人類能力的重要組成部分是組合式學習。這涉及從學習的知識中識別視覺原語，然後使用這些轉移的原語組合新的概念，使增量學習既有效又可解釋。為了模仿人類組合式學習，我們為 FSCIL 任務提出了一種受認知啟發的方法。我們根據集合相似性定義並建立了一個組合式模型，然後為其配備一個原語組合模組和一個原語重用模組。在原語組合模組中，我們建議利用中心核對齊 (CKA) 相似性來近似原語集合之間的相似性，從而允許基於原語組合進行訓練和評估。在原語重用模組中，我們通過根據用來自其他類別的最接近原語替換的原語對輸入進行分類，來增強原語的可重用性。在三個資料集上的實驗驗證了我們的方法，表明它優於當前最先進的方法，並提高了可解釋性。我們的程式碼可在 https://github.com/Zoilsen/Comp-FSCIL 獲得。

##### **Position: Foundation Agents as the Paradigm Shift for Decision Making**
2405.17009v2 by Xiaoqian Liu, Xingzhou Lou, Jianbin Jiao, Junge Zhang

Decision making demands intricate interplay between perception, memory, and
reasoning to discern optimal policies. Conventional approaches to decision
making face challenges related to low sample efficiency and poor
generalization. In contrast, foundation models in language and vision have
showcased rapid adaptation to diverse new tasks. Therefore, we advocate for the
construction of foundation agents as a transformative shift in the learning
paradigm of agents. This proposal is underpinned by the formulation of
foundation agents with their fundamental characteristics and challenges
motivated by the success of large language models (LLMs). Moreover, we specify
the roadmap of foundation agents from large interactive data collection or
generation, to self-supervised pretraining and adaptation, and knowledge and
value alignment with LLMs. Lastly, we pinpoint critical research questions
derived from the formulation and delineate trends for foundation agents
supported by real-world use cases, addressing both technical and theoretical
aspects to propel the field towards a more comprehensive and impactful future.

摘要：決策制定需要知覺、記憶和推理之間的複雜交互作用，才能辨別出最佳策略。傳統的決策制定方法面臨與低樣本效率和低泛化性相關的挑戰。相反，語言和視覺中的基礎模型已展示出對各種新任務的快速適應能力。因此，我們主張將基礎代理視為代理學習範式轉變的變革。此提案以基礎代理的制定為基礎，其基本特徵和挑戰受到大型語言模型 (LLM) 成功所激勵。此外，我們指定了基礎代理的路線圖，從大型互動數據收集或生成到自監督預訓練和適應，以及與 LLM 的知識和價值對齊。最後，我們精確指出源自制定並描述由實際用例支持的基礎代理趨勢的關鍵研究問題，解決技術和理論層面，以推動該領域邁向更全面和影響深遠的未來。

##### **Vision-and-Language Navigation Generative Pretrained Transformer**
2405.16994v1 by Wen Hanlin

In the Vision-and-Language Navigation (VLN) field, agents are tasked with
navigating real-world scenes guided by linguistic instructions. Enabling the
agent to adhere to instructions throughout the process of navigation represents
a significant challenge within the domain of VLN. To address this challenge,
common approaches often rely on encoders to explicitly record past locations
and actions, increasing model complexity and resource consumption. Our
proposal, the Vision-and-Language Navigation Generative Pretrained Transformer
(VLN-GPT), adopts a transformer decoder model (GPT2) to model trajectory
sequence dependencies, bypassing the need for historical encoding modules. This
method allows for direct historical information access through trajectory
sequence, enhancing efficiency. Furthermore, our model separates the training
process into offline pre-training with imitation learning and online
fine-tuning with reinforcement learning. This distinction allows for more
focused training objectives and improved performance. Performance assessments
on the VLN dataset reveal that VLN-GPT surpasses complex state-of-the-art
encoder-based models.

摘要：在視覺與語言導航 (VLN) 領域中，代理被賦予任務，在語言指令的引導下導航真實世界的場景。讓代理在整個導航過程中遵守指令，代表了 VLN 領域中的重大挑戰。為了應對此挑戰，常見的方法通常依賴編碼器來明確記錄過去的位置和動作，增加了模型的複雜性和資源消耗。我們的提案，即視覺與語言導航生成式預訓練Transformer (VLN-GPT)，採用Transformer解碼器模型 (GPT2) 來建模軌跡序列依賴性，繞過了對歷史編碼模組的需求。這種方法允許通過軌跡序列直接存取歷史資訊，從而提高效率。此外，我們的模型將訓練過程分為離線預訓練（透過模仿學習）和線上微調（透過強化學習）。此區別允許更專注的訓練目標和改進的效能。在 VLN 資料集上的效能評估顯示，VLN-GPT 超越了複雜的最新編碼器模型。

##### **The Multi-Range Theory of Translation Quality Measurement: MQM scoring models and Statistical Quality Control**
2405.16969v1 by Arle Lommel, Serge Gladkoff, Alan Melby, Sue Ellen Wright, Ingemar Strandvik, Katerina Gasova, Angelika Vaasa, Andy Benzo, Romina Marazzato Sparano, Monica Faresi, Johani Innis, Lifeng Han, Goran Nenadic

The year 2024 marks the 10th anniversary of the Multidimensional Quality
Metrics (MQM) framework for analytic translation quality evaluation. The MQM
error typology has been widely used by practitioners in the translation and
localization industry and has served as the basis for many derivative projects.
The annual Conference on Machine Translation (WMT) shared tasks on both human
and automatic translation quality evaluations used the MQM error typology.
  The metric stands on two pillars: error typology and the scoring model. The
scoring model calculates the quality score from annotation data, detailing how
to convert error type and severity counts into numeric scores to determine if
the content meets specifications. Previously, only the raw scoring model had
been published. This April, the MQM Council published the Linear Calibrated
Scoring Model, officially presented herein, along with the Non-Linear Scoring
Model, which had not been published before.
  This paper details the latest MQM developments and presents a universal
approach to translation quality measurement across three sample size ranges. It
also explains why Statistical Quality Control should be used for very small
sample sizes, starting from a single sentence.

摘要：2024 年是多維度品質度量 (MQM) 框架用於分析翻譯品質評估的 10 週年。MQM 錯誤類型學已廣泛用於翻譯和在地化產業的從業人員，並作為許多衍生專案的基礎。機器翻譯年會 (WMT) 在人類和自動翻譯品質評估中所共用的任務，使用了 MQM 錯誤類型學。

此度量標準建立在兩個支柱上：錯誤類型學和計分模型。計分模型從註解資料計算品質分數，詳細說明如何將錯誤類型和嚴重性計數轉換為數字分數，以確定內容是否符合規格。以前，只有原始計分模型已發布。今年 4 月，MQM 委員會發布了線性校準計分模型，並在本文中正式提出，以及先前未發布的非線性計分模型。

本文詳細說明了最新的 MQM 發展，並提出了針對三個範例大小範圍的翻譯品質測量通用方法。它也說明了為什麼應將統計品質控制用於極小的範例大小，從單一句子開始。

##### **Exploring the LLM Journey from Cognition to Expression with Linear Representations**
2405.16964v1 by Yuzi Yan, Jialian Li, Yipin Zhang, Dong Yan

This paper presents an in-depth examination of the evolution and interplay of
cognitive and expressive capabilities in large language models (LLMs), with a
specific focus on Baichuan-7B and Baichuan-33B, an advanced bilingual (Chinese
and English) LLM series. We define and explore the model's cognitive and
expressive capabilities through linear representations across three critical
phases: Pretraining, Supervised Fine-Tuning (SFT), and Reinforcement Learning
from Human Feedback (RLHF). Cognitive capability is defined as the quantity and
quality of information conveyed by the neuron output vectors within the
network, similar to the neural signal processing in human cognition. Expressive
capability is defined as the model's capability to produce word-level output.
Our findings unveil a sequential development pattern, where cognitive abilities
are largely established during Pretraining, whereas expressive abilities
predominantly advance during SFT and RLHF. Statistical analyses confirm a
significant correlation between the two capabilities, suggesting that cognitive
capacity may limit expressive potential. The paper also explores the
theoretical underpinnings of these divergent developmental trajectories and
their connection to the LLMs' architectural design. Moreover, we evaluate
various optimization-independent strategies, such as few-shot learning and
repeated sampling, which bridge the gap between cognitive and expressive
capabilities. This research reveals the potential connection between the hidden
space and the output space, contributing valuable insights into the
interpretability and controllability of their training processes.

摘要：本文深入探討大型語言模型（LLM）中認知和表達能力的演進和交互作用，特別關注百川-7B 和百川-33B，這是一個先進的雙語（中文和英文）LLM 系列。我們透過三個關鍵階段的線性表示定義和探討模型的認知和表達能力：預訓練、監督微調（SFT）和人類回饋強化學習（RLHF）。認知能力定義為網路中神經元輸出向量傳達的資訊量和品質，類似於人類認知中的神經訊號處理。表達能力定義為模型產生字元級輸出的能力。我們的研究結果揭示了一個順序發展模式，其中認知能力主要在預訓練期間建立，而表達能力則主要在 SFT 和 RLHF 期間進步。統計分析證實這兩種能力之間存在顯著相關性，表明認知能力可能限制表達潛力。本文還探討了這些不同發展軌跡的理論基礎及其與 LLM 架構設計的關聯。此外，我們評估了各種與最佳化無關的策略，例如小樣本學習和重複抽樣，這些策略彌合了認知和表達能力之間的差距。本研究揭示了隱藏空間和輸出空間之間的潛在關聯，為訓練過程的可解釋性和可控性提供了有價值的見解。

##### **Blind Data Adaptation to tackle Covariate Shift in Operational Steganalysis**
2405.16961v1 by Rony Abecidan, Vincent Itier, Jérémie Boulanger, Patrick Bas, Tomáš Pevný

The proliferation of image manipulation for unethical purposes poses
significant challenges in social networks. One particularly concerning method
is Image Steganography, allowing individuals to hide illegal information in
digital images without arousing suspicions. Such a technique pose severe
security risks, making it crucial to develop effective steganalysis methods
enabling to detect manipulated images for clandestine communications. Although
significant advancements have been achieved with machine learning models, a
critical issue remains: the disparity between the controlled datasets used to
train steganalysis models against real-world datasets of forensic
practitioners, undermining severely the practical effectiveness of standardized
steganalysis models. In this paper, we address this issue focusing on a
realistic scenario where practitioners lack crucial information about the
limited target set of images under analysis, including details about their
development process and even whereas it contains manipulated images or not. By
leveraging geometric alignment and distribution matching of source and target
residuals, we develop TADA (Target Alignment through Data Adaptation), a novel
methodology enabling to emulate sources aligned with specific targets in
steganalysis, which is also relevant for highly unbalanced targets. The
emulator is represented by a light convolutional network trained to align
distributions of image residuals. Experimental validation demonstrates the
potential of our strategy over traditional methods fighting covariate shift in
steganalysis.

摘要：图像处理在非道德目的上的激增对社交网络提出了重大挑战。一种特别令人担忧的方法是图像隐写术，它允许个人在数字图像中隐藏非法信息，而不会引起怀疑。这种技术构成了严重的安全性风险，因此至关重要的是开发有效的隐写分析方法，以便检测用于秘密通信的经过处理的图像。尽管机器学习模型取得了重大进展，但仍然存在一个关键问题：用于训练隐写分析模型的受控数据集与法医从业者的真实数据集之间的差异，严重损害了标准化隐写分析模型的实际有效性。在本文中，我们通过关注从业者缺乏有关正在分析的有限目标图像集的关键信息（包括有关其开发过程的详细信息，甚至是否包含经过处理的图像）的实际情况来解决这个问题。通过利用源和目标残差的几何对齐和分布匹配，我们开发了 TADA（通过数据自适应进行目标对齐），这是一种新方法，可以模拟与隐写分析中的特定目标对齐的源，这与高度不平衡的目标也相关。仿真器由一个轻量级卷积网络表示，该网络经过训练以对齐图像残差的分布。实验验证表明，我们的策略在对抗隐写分析中协变量转移的传统方法上具有潜力。

##### **Empowering Large Language Models to Set up a Knowledge Retrieval Indexer via Self-Learning**
2405.16933v1 by Xun Liang, Simin Niu, Zhiyu li, Sensen Zhang, Shichao Song, Hanyu Wang, Jiawei Yang, Feiyu Xiong, Bo Tang, Chenyang Xi

Retrieval-Augmented Generation (RAG) offers a cost-effective approach to
injecting real-time knowledge into large language models (LLMs). Nevertheless,
constructing and validating high-quality knowledge repositories require
considerable effort. We propose a pre-retrieval framework named Pseudo-Graph
Retrieval-Augmented Generation (PG-RAG), which conceptualizes LLMs as students
by providing them with abundant raw reading materials and encouraging them to
engage in autonomous reading to record factual information in their own words.
The resulting concise, well-organized mental indices are interconnected through
common topics or complementary facts to form a pseudo-graph database. During
the retrieval phase, PG-RAG mimics the human behavior in flipping through
notes, identifying fact paths and subsequently exploring the related contexts.
Adhering to the principle of the path taken by many is the best, it integrates
highly corroborated fact paths to provide a structured and refined sub-graph
assisting LLMs. We validated PG-RAG on three specialized question-answering
datasets. In single-document tasks, PG-RAG significantly outperformed the
current best baseline, KGP-LLaMA, across all key evaluation metrics, with an
average overall performance improvement of 11.6%. Specifically, its BLEU score
increased by approximately 14.3%, and the QE-F1 metric improved by 23.7%. In
multi-document scenarios, the average metrics of PG-RAG were at least 2.35%
higher than the best baseline. Notably, the BLEU score and QE-F1 metric showed
stable improvements of around 7.55% and 12.75%, respectively. Our code:
https://github.com/IAAR-Shanghai/PGRAG.

摘要：<paragraph>檢索增強生成（RAG）提供了一種具成本效益的方法，可以將即時知識注入大型語言模型（LLM）。儘管如此，建構和驗證高品質的知識儲存庫需要相當大的努力。我們提出了一個名為偽圖形檢索增強生成（PG-RAG）的預檢索架構，它將 LLM 概念化為學生，為他們提供豐富的原始閱讀材料，並鼓勵他們從事自主閱讀，用自己的話記錄事實資訊。由此產生的簡潔、組織良好的心智索引通過共同的主題或補充事實相互連接，形成一個偽圖形資料庫。在檢索階段，PG-RAG 模仿人類在翻閱筆記、識別事實路徑並隨後探索相關背景中的行為。遵循眾人走的路是最好的原則，它整合了高度證實的事實路徑，以提供一個結構化且精煉的子圖，協助 LLM。我們在三個專業問答資料集上驗證了 PG-RAG。在單一文件任務中，PG-RAG 在所有關鍵評估指標上都顯著優於目前的最佳基準 KGP-LLaMA，平均整體效能提升了 11.6%。具體來說，它的 BLEU 分數提高了大約 14.3%，QE-F1 指標提高了 23.7%。在多文件場景中，PG-RAG 的平均指標至少比最佳基準高 2.35%。值得注意的是，BLEU 分數和 QE-F1 指標分別顯示出約 7.55% 和 12.75% 的穩定提升。我們的程式碼：https://github.com/IAAR-Shanghai/PGRAG。</paragraph>

##### **Uncertainty Management in the Construction of Knowledge Graphs: a Survey**
2405.16929v1 by Lucas Jarnac, Yoan Chabot, Miguel Couceiro

Knowledge Graphs (KGs) are a major asset for companies thanks to their great
flexibility in data representation and their numerous applications, e.g.,
vocabulary sharing, Q/A or recommendation systems. To build a KG it is a common
practice to rely on automatic methods for extracting knowledge from various
heterogeneous sources. But in a noisy and uncertain world, knowledge may not be
reliable and conflicts between data sources may occur. Integrating unreliable
data would directly impact the use of the KG, therefore such conflicts must be
resolved. This could be done manually by selecting the best data to integrate.
This first approach is highly accurate, but costly and time-consuming. That is
why recent efforts focus on automatic approaches, which represents a
challenging task since it requires handling the uncertainty of extracted
knowledge throughout its integration into the KG. We survey state-of-the-art
approaches in this direction and present constructions of both open and
enterprise KGs and how their quality is maintained. We then describe different
knowledge extraction methods, introducing additional uncertainty. We also
discuss downstream tasks after knowledge acquisition, including KG completion
using embedding models, knowledge alignment, and knowledge fusion in order to
address the problem of knowledge uncertainty in KG construction. We conclude
with a discussion on the remaining challenges and perspectives when
constructing a KG taking into account uncertainty.

摘要：知識圖譜 (KG) 對於企業而言是一項重要資產，這要歸功於它們在資料表示上的極大彈性和眾多應用，例如詞彙共享、問答或推薦系統。建立知識圖譜時，常見的做法是依賴自動化方法從各種異質來源中萃取知識。但在一個充滿雜訊和不確定的世界中，知識可能並不可靠，而且資料來源之間可能會發生衝突。整合不可靠的資料會直接影響知識圖譜的使用，因此必須解決這些衝突。這可以透過手動選擇最佳資料來整合來完成。這種第一種方法非常準確，但成本高且耗時。這就是為什麼最近的努力都集中在自動化方法上，這是一個具有挑戰性的任務，因為它需要在將萃取的知識整合到知識圖譜中時處理不確定性。我們調查了這方面的最新方法，並介紹了開放式和企業知識圖譜的建構方式，以及如何維護它們的品質。然後我們描述不同的知識萃取方法，並介紹額外的不確定性。我們還討論了知識獲取後的下游任務，包括使用嵌入模型完成知識圖譜、知識對齊和知識融合，以解決知識圖譜建構中知識不確定性的問題。最後，我們討論在考慮不確定性的情況下建構知識圖譜時，所剩的挑戰和觀點。

##### **VoCoT: Unleashing Visually Grounded Multi-Step Reasoning in Large Multi-Modal Models**
2405.16919v2 by Zejun Li, Ruipu Luo, Jiwen Zhang, Minghui Qiu, Zhongyu Wei

While large multi-modal models (LMMs) have exhibited impressive capabilities
across diverse tasks, their effectiveness in handling complex tasks has been
limited by the prevailing single-step reasoning paradigm. To this end, this
paper proposes VoCoT, a multi-step Visually grounded object-centric
Chain-of-Thought reasoning framework tailored for inference with LMMs. VoCoT is
characterized by two key features: (1) object-centric reasoning paths that
revolve around cross-modal shared object-level information, and (2) visually
grounded representation of object concepts in a multi-modal interleaved and
aligned manner, which effectively bridges the modality gap within LMMs during
long-term generation. Additionally, we construct an instruction dataset to
facilitate LMMs in adapting to reasoning with VoCoT. By introducing VoCoT into
the prevalent open-source LMM architecture, we introduce VolCano. With only 7B
parameters and limited input resolution, VolCano demonstrates excellent
performance across various scenarios, surpassing SOTA models, including GPT-4V,
in tasks requiring complex reasoning. Our code, data and model will be
available at https://github.com/RupertLuo/VoCoT.

摘要：儘管大型多模態模型 (LMM) 在各種任務中展現令人印象深刻的能力，但其在處理複雜任務的效能受到盛行的單步推理範例所限制。為此，本文提出 VoCoT，一個多步驟視覺基礎物件為中心的思想鏈推理架構，專門用於 LMM 的推論。VoCoT 的特點在於兩個關鍵特徵：(1) 以跨模態共享物件層級資訊為核心的物件為中心推理路徑，以及 (2) 以多模態交錯和對齊的方式視覺化基礎物件概念的表示，在長期生成期間有效地彌合了 LMM 中的模態差距。此外，我們建構了一個指令資料集，以利 LMM 適應 VoCoT 的推理。透過將 VoCoT 引入流行的開源 LMM 架構，我們引入了 VolCano。VolCano 僅有 7B 參數和有限的輸入解析度，在各種場景中展現出色的效能，超越了 SOTA 模型，包括 GPT-4V，在需要複雜推理的任務中表現優異。我們的程式碼、資料和模型將在 https://github.com/RupertLuo/VoCoT 提供。

##### **Can Large Language Models Faithfully Express Their Intrinsic Uncertainty in Words?**
2405.16908v1 by Gal Yona, Roee Aharoni, Mor Geva

We posit that large language models (LLMs) should be capable of expressing
their intrinsic uncertainty in natural language. For example, if the LLM is
equally likely to output two contradicting answers to the same question, then
its generated response should reflect this uncertainty by hedging its answer
(e.g., "I'm not sure, but I think..."). We formalize faithful response
uncertainty based on the gap between the model's intrinsic confidence in the
assertions it makes and the decisiveness by which they are conveyed. This
example-level metric reliably indicates whether the model reflects its
uncertainty, as it penalizes both excessive and insufficient hedging. We
evaluate a variety of aligned LLMs at faithfully communicating uncertainty on
several knowledge-intensive question answering tasks. Our results provide
strong evidence that modern LLMs are poor at faithfully conveying their
uncertainty, and that better alignment is necessary to improve their
trustworthiness.

摘要：我們假設大型語言模型 (LLM) 應該能夠以自然語言表達其內在的不確定性。例如，如果 LLM 很可能會對同一個問題輸出兩個相互矛盾的答案，那麼它生成的回應應該反映這種不確定性，並對其答案進行對沖（例如，「我不確定，但我認為...」）。我們根據模型對其所做斷言的內在信心與傳達這些斷言的果斷程度之間的差距，對忠實的回應不確定性進行形式化。這個範例層級的指標可靠地指出模型是否反映了其不確定性，因為它懲罰過度和不足的對沖。我們評估各種對齊的 LLM 在忠實地傳達不確定性方面的表現，針對多項知識密集型問題回答任務。我們的結果提供了強有力的證據，表明現代 LLM 在忠實傳達其不確定性方面表現不佳，並且需要更好的對齊才能提高其可信度。

##### **GTA: Generative Trajectory Augmentation with Guidance for Offline Reinforcement Learning**
2405.16907v2 by Jaewoo Lee, Sujin Yun, Taeyoung Yun, Jinkyoo Park

Offline Reinforcement Learning (Offline RL) presents challenges of learning
effective decision-making policies from static datasets without any online
interactions. Data augmentation techniques, such as noise injection and data
synthesizing, aim to improve Q-function approximation by smoothing the learned
state-action region. However, these methods often fall short of directly
improving the quality of offline datasets, leading to suboptimal results. In
response, we introduce \textbf{GTA}, Generative Trajectory Augmentation, a
novel generative data augmentation approach designed to enrich offline data by
augmenting trajectories to be both high-rewarding and dynamically plausible.
GTA applies a diffusion model within the data augmentation framework. GTA
partially noises original trajectories and then denoises them with
classifier-free guidance via conditioning on amplified return value. Our
results show that GTA, as a general data augmentation strategy, enhances the
performance of widely used offline RL algorithms in both dense and sparse
reward settings. Furthermore, we conduct a quality analysis of data augmented
by GTA and demonstrate that GTA improves the quality of the data. Our code is
available at https://github.com/Jaewoopudding/GTA

摘要：離線強化學習 (Offline RL) 提出從靜態資料集學習有效決策制定政策的挑戰，而沒有任何線上互動。資料擴充技術，例如雜訊注入和資料合成，旨在透過平滑學習的狀態動作區域來改善 Q 函數逼近。然而，這些方法通常無法直接改善離線資料集的品質，導致次佳結果。為了解決這個問題，我們引入了 **GTA**，生成軌跡擴充，一種新穎的生成資料擴充方法，旨在透過擴充軌跡以獲得高報酬和動態可信度來豐富離線資料。GTA 在資料擴充架構中應用擴散模型。GTA 部分雜訊化原始軌跡，然後透過對放大回報值進行條件化，以無分類器引導的方式對其去雜訊。我們的結果顯示，GTA 作為一種通用的資料擴充策略，在密集和稀疏報酬設定中都增強了廣泛使用的離線 RL 演算法的效能。此外，我們對 GTA 擴充的資料進行品質分析，並證明 GTA 改善了資料品質。我們的程式碼可在 https://github.com/Jaewoopudding/GTA 取得

##### **Partial Models for Building Adaptive Model-Based Reinforcement Learning Agents**
2405.16899v1 by Safa Alver, Ali Rahimi-Kalahroudi, Doina Precup

In neuroscience, one of the key behavioral tests for determining whether a
subject of study exhibits model-based behavior is to study its adaptiveness to
local changes in the environment. In reinforcement learning, however, recent
studies have shown that modern model-based agents display poor adaptivity to
such changes. The main reason for this is that modern agents are typically
designed to improve sample efficiency in single task settings and thus do not
take into account the challenges that can arise in other settings. In local
adaptation settings, one particularly important challenge is in quickly
building and maintaining a sufficiently accurate model after a local change.
This is challenging for deep model-based agents as their models and replay
buffers are monolithic structures lacking distribution shift handling
capabilities. In this study, we show that the conceptually simple idea of
partial models can allow deep model-based agents to overcome this challenge and
thus allow for building locally adaptive model-based agents. By modeling the
different parts of the state space through different models, the agent can not
only maintain a model that is accurate across the state space, but it can also
quickly adapt it in the presence of a local change in the environment. We
demonstrate this by showing that the use of partial models in agents such as
deep Dyna-Q, PlaNet and Dreamer can allow for them to effectively adapt to the
local changes in their environments.

摘要：在神经科学中，用於確定研究對象是否表現出基於模型的行為的主要行為測試之一是研究其對環境中局部變化的適應性。然而，在強化學習中，最近的研究表明，現代基於模型的代理對此類變化表現出較差的適應性。造成這種現象的主要原因是，現代代理通常被設計為在單一任務設置中提高樣本效率，因此沒有考慮在其他設置中可能出現的挑戰。在局部適應設置中，一個特別重要的挑戰是在局部變化後快速建立和維護一個足夠準確的模型。這對於深度基於模型的代理來說具有挑戰性，因為它們的模型和重播緩衝區是缺乏分佈轉移處理功能的整體結構。在本研究中，我們表明部分模型的概念簡單，可以讓深度基於模型的代理克服這個挑戰，從而允許建立局部適應的基於模型的代理。通過不同模型對狀態空間的不同部分進行建模，代理不僅可以維護一個在整個狀態空間中準確的模型，而且還可以在環境發生局部變化時快速適應它。我們通過展示在代理中使用部分模型，例如深度 Dyna-Q、PlaNet 和 Dreamer，可以讓它們有效適應環境中的局部變化，來證明這一點。

##### **A Large Language Model-based multi-agent manufacturing system for intelligent shopfloor**
2405.16887v1 by Zhen Zhao, Dunbing Tang, Haihua Zhu, Zequn Zhang, Kai Chen, Changchun Liu, Yuchen Ji

As productivity advances, the demand of customers for multi-variety and
small-batch production is increasing, thereby putting forward higher
requirements for manufacturing systems. When production tasks frequent changes
due to this demand, traditional manufacturing systems often cannot response
promptly. The multi-agent manufacturing system is proposed to address this
problem. However, because of technical limitations, the negotiation among
agents in this kind of system is realized through predefined heuristic rules,
which is not intelligent enough to deal with the multi-variety and small batch
production. To this end, a Large Language Model-based (LLM-based) multi-agent
manufacturing system for intelligent shopfloor is proposed in the present
study. This system delineates the diverse agents and defines their
collaborative methods. The roles of the agents encompass Machine Server Agent
(MSA), Bid Inviter Agent (BIA), Bidder Agent (BA), Thinking Agent (TA), and
Decision Agent (DA). Due to the support of LLMs, TA and DA acquire the ability
of analyzing the shopfloor condition and choosing the most suitable machine, as
opposed to executing a predefined program artificially. The negotiation between
BAs and BIA is the most crucial step in connecting manufacturing resources.
With the support of TA and DA, BIA will finalize the distribution of orders,
relying on the information of each machine returned by BA. MSAs bears the
responsibility for connecting the agents with the physical shopfloor. This
system aims to distribute and transmit workpieces through the collaboration of
the agents with these distinct roles, distinguishing it from other scheduling
approaches. Comparative experiments were also conducted to validate the
performance of this system.

摘要：隨著生產力的提升，客戶對多樣化和小批量生產的需求與日俱增，對製造系統也提出了更高的要求。當生產任務因應這種需求而頻繁變更時，傳統的製造系統往往無法及時回應。多主體製造系統應運而生，以解決這個問題。然而，由於技術限制，這種系統中的主體之間的協商是透過預先定義的啟發式規則來實現的，這並不足以應對多樣化和小批量生產。為此，本研究提出了一個基於大語言模型 (LLM) 的智能車間多主體製造系統。此系統描繪了不同的主體並定義了它們的協作方法。主體的角色包括機器伺服器主體 (MSA)、招標邀請主體 (BIA)、投標主體 (BA)、思考主體 (TA) 和決策主體 (DA)。由於 LLM 的支援，TA 和 DA 具備了分析車間狀況並選擇最合適機器的能力，而不是人工執行預定義的程式。BA 和 BIA 之間的協商是連接製造資源最關鍵的步驟。在 TA 和 DA 的支援下，BIA 將根據 BA 回傳的每台機器資訊，最終確定訂單的分配。MSA 負責將主體與實際車間連接起來。此系統旨在透過具有不同角色的主體協作來分配和傳輸工件，這與其他排程方法不同。也進行了比較實驗來驗證此系統的效能。

##### **Match, Compare, or Select? An Investigation of Large Language Models for Entity Matching**
2405.16884v1 by Tianshu Wang, Hongyu Lin, Xiaoyang Chen, Xianpei Han, Hao Wang, Zhenyu Zeng, Le Sun

Entity matching (EM) is a critical step in entity resolution. Recently,
entity matching based on large language models (LLMs) has shown great promise.
However, current LLM-based entity matching approaches typically follow a binary
matching paradigm that ignores the global consistency between different
records. In this paper, we investigate various methodologies for LLM-based
entity matching that incorporate record interactions from different
perspectives. Specifically, we comprehensively compare three representative
strategies: matching, comparing, and selecting, and analyze their respective
advantages and challenges in diverse scenarios. Based on our findings, we
further design a compositional entity matching (ComEM) framework that leverages
the composition of multiple strategies and LLMs. In this way, ComEM can benefit
from the advantages of different sides and achieve improvements in both
effectiveness and efficiency. Experimental results show that ComEM not only
achieves significant performance gains on various datasets but also reduces the
cost of LLM-based entity matching in real-world application.

摘要：實體配對 (EM) 是實體解決方案中至關重要的一步。最近，基於大型語言模型 (LLM) 的實體配對已展現出極大的前景。然而，當前基於 LLM 的實體配對方法通常遵循二元配對範例，忽略不同記錄之間的整體一致性。在本文中，我們研究了各種基於 LLM 的實體配對方法，這些方法從不同角度整合記錄互動。具體來說，我們全面比較了三種代表性策略：配對、比較和選擇，並分析了它們在不同場景中的各自優勢和挑戰。根據我們的發現，我們進一步設計了一個組合實體配對 (ComEM) 框架，利用了多種策略和 LLM 的組合。這樣，ComEM 可以從不同方面的優勢中受益，並在有效性和效率方面取得進步。實驗結果表明，ComEM 不僅在各種數據集上實現了顯著的性能提升，還降低了 LLM 基於實體配對在實際應用中的成本。

##### **Scorch: A Library for Sparse Deep Learning**
2405.16883v1 by Bobby Yan, Alexander J. Root, Trevor Gale, David Broman, Fredrik Kjolstad

The rapid growth in the size of deep learning models strains the capabilities
of traditional dense computation paradigms. Leveraging sparse computation has
become increasingly popular for training and deploying large-scale models, but
existing deep learning frameworks lack extensive support for sparse operations.
To bridge this gap, we introduce Scorch, a library that seamlessly integrates
efficient sparse tensor computation into the PyTorch ecosystem, with an initial
focus on inference workloads on CPUs. Scorch provides a flexible and intuitive
interface for sparse tensors, supporting diverse sparse data structures. Scorch
introduces a compiler stack that automates key optimizations, including
automatic loop ordering, tiling, and format inference. Combined with a runtime
that adapts its execution to both dense and sparse data, Scorch delivers
substantial speedups over hand-written PyTorch Sparse (torch.sparse) operations
without sacrificing usability. More importantly, Scorch enables efficient
computation of complex sparse operations that lack hand-optimized PyTorch
implementations. This flexibility is crucial for exploring novel sparse
architectures. We demonstrate Scorch's ease of use and performance gains on
diverse deep learning models across multiple domains. With only minimal code
changes, Scorch achieves 1.05-5.78x speedups over PyTorch Sparse on end-to-end
tasks. Scorch's seamless integration and performance gains make it a valuable
addition to the PyTorch ecosystem. We believe Scorch will enable wider
exploration of sparsity as a tool for scaling deep learning and inform the
development of other sparse libraries.

摘要：深度學習模型的規模快速增長，對傳統密集運算範例的能力造成壓力。利用稀疏運算已經變得越來越流行，用於訓練和部署大規模模型，但現有的深度學習框架缺乏對稀疏運算的廣泛支援。為了解決這個差距，我們引入了 Scorch，這是一個將高效稀疏張量運算無縫整合到 PyTorch 生態系統中的函式庫，最初重點放在 CPU 上的推論工作負載。Scorch 為稀疏張量提供了一個靈活且直觀的介面，支援多樣化的稀疏資料結構。Scorch 引入了編譯器堆疊，自動化了關鍵最佳化，包括自動迴圈排序、平鋪和格式推論。結合適應密集和稀疏資料的執行時間，Scorch 提供了比手寫 PyTorch Sparse (torch.sparse) 運算更大幅度的加速，同時不犧牲可用性。更重要的是，Scorch 能夠有效率地計算缺少手動最佳化 PyTorch 實作的複雜稀疏運算。這種靈活性對於探索新穎的稀疏架構至關重要。我們展示了 Scorch 在多個領域的各種深度學習模型上的易用性和效能提升。只需最小的程式碼變更，Scorch 在端到端任務上就能比 PyTorch Sparse 快 1.05-5.78 倍。Scorch 的無縫整合和效能提升使其成為 PyTorch 生態系統的寶貴補充。我們相信 Scorch 將使稀疏性作為擴展深度學習的工具得到更廣泛的探索，並為其他稀疏函式庫的開發提供資訊。

##### **Unsupervised Generative Feature Transformation via Graph Contrastive Pre-training and Multi-objective Fine-tuning**
2405.16879v1 by Wangyang Ying, Dongjie Wang, Xuanming Hu, Yuanchun Zhou, Charu C. Aggarwal, Yanjie Fu

Feature transformation is to derive a new feature set from original features
to augment the AI power of data. In many science domains such as material
performance screening, while feature transformation can model material formula
interactions and compositions and discover performance drivers, supervised
labels are collected from expensive and lengthy experiments. This issue
motivates an Unsupervised Feature Transformation Learning (UFTL) problem. Prior
literature, such as manual transformation, supervised feedback guided search,
and PCA, either relies on domain knowledge or expensive supervised feedback, or
suffers from large search space, or overlooks non-linear feature-feature
interactions. UFTL imposes a major challenge on existing methods: how to design
a new unsupervised paradigm that captures complex feature interactions and
avoids large search space? To fill this gap, we connect graph, contrastive, and
generative learning to develop a measurement-pretrain-finetune paradigm for
UFTL. For unsupervised feature set utility measurement, we propose a feature
value consistency preservation perspective and develop a mean discounted
cumulative gain like unsupervised metric to evaluate feature set utility. For
unsupervised feature set representation pretraining, we regard a feature set as
a feature-feature interaction graph, and develop an unsupervised graph
contrastive learning encoder to embed feature sets into vectors. For generative
transformation finetuning, we regard a feature set as a feature cross sequence
and feature transformation as sequential generation. We develop a deep
generative feature transformation model that coordinates the pretrained feature
set encoder and the gradient information extracted from a feature set utility
evaluator to optimize a transformed feature generator.

摘要：特徵轉換是從原始特徵中衍生一套新的特徵，以增強資料的 AI 能力。在許多科學領域中，例如材料效能篩選，特徵轉換可以建模材料配方交互作用和組成，並找出效能驅動因素，但監督標籤是從昂貴且漫長的實驗中收集而來的。此問題促成了無監督特徵轉換學習 (UFTL) 問題。先前的文獻，例如手動轉換、監督回饋引導搜尋和 PCA，依賴於領域知識或昂貴的監督回饋，或因搜尋空間過大而受苦，或忽略非線性特徵與特徵之間的交互作用。UFTL 對現有方法提出了重大挑戰：如何設計一個新的無監督範例，以捕捉複雜的特徵交互作用並避免大的搜尋空間？為了解決這個問題，我們將圖形、對比和生成式學習聯繫起來，為 UFTL 開發一個測量預訓練微調範例。對於無監督特徵集效用測量，我們提出特徵值一致性保存觀點，並開發一個類似於無監督指標的平均折現累積增益，以評估特徵集效用。對於無監督特徵集表示預訓練，我們將特徵集視為特徵與特徵交互作用圖，並開發一個無監督圖形對比學習編碼器，將特徵集嵌入到向量中。對於生成式轉換微調，我們將特徵集視為特徵交叉序列，並將特徵轉換視為序列生成。我們開發了一個深度生成式特徵轉換模型，該模型協調預訓練的特徵集編碼器和從特徵集效用評估器中提取的梯度資訊，以最佳化轉換的特徵產生器。

##### **Are Self-Attentions Effective for Time Series Forecasting?**
2405.16877v1 by Dongbin Kim, Jinseong Park, Jaewook Lee, Hoki Kim

Time series forecasting is crucial for applications across multiple domains
and various scenarios. Although Transformer models have dramatically shifted
the landscape of forecasting, their effectiveness remains debated. Recent
findings have indicated that simpler linear models might outperform complex
Transformer-based approaches, highlighting the potential for more streamlined
architectures. In this paper, we shift focus from the overall architecture of
the Transformer to the effectiveness of self-attentions for time series
forecasting. To this end, we introduce a new architecture, Cross-Attention-only
Time Series transformer (CATS), that rethinks the traditional Transformer
framework by eliminating self-attention and leveraging cross-attention
mechanisms instead. By establishing future horizon-dependent parameters as
queries and enhanced parameter sharing, our model not only improves long-term
forecasting accuracy but also reduces the number of parameters and memory
usage. Extensive experiment across various datasets demonstrates that our model
achieves superior performance with the lowest mean squared error and uses fewer
parameters compared to existing models.

摘要：時間序列預測對跨多個領域和各種情境的應用至關重要。雖然 Transformer 模型已大幅改變預測的格局，但其有效性仍有爭議。最近的發現顯示，較簡單的線性模型可能優於複雜的基於 Transformer 的方法，突顯了更精簡架構的潛力。在本文中，我們將焦點從 Transformer 的整體架構轉移到自注意力在時間序列預測中的有效性。為此，我們引入了一種新的架構，稱為僅交叉注意力的時間序列 Transformer (CATS)，它重新思考傳統的 Transformer 框架，方法是消除自注意力並改用交叉注意力機制。透過將未來時間範圍依賴參數設定為查詢並增強參數共享，我們的模型不僅提高了長期預測的準確性，而且還減少了參數和記憶體使用量。跨各種資料集的廣泛實驗證明，與現有模型相比，我們的模型以最低的均方誤差實現了卓越的效能，並且使用了較少的參數。

##### **Transfer Learning for Diffusion Models**
2405.16876v2 by Yidong Ouyang, Liyan Xie, Hongyuan Zha, Guang Cheng

Diffusion models, a specific type of generative model, have achieved
unprecedented performance in recent years and consistently produce high-quality
synthetic samples. A critical prerequisite for their notable success lies in
the presence of a substantial number of training samples, which can be
impractical in real-world applications due to high collection costs or
associated risks. Consequently, various finetuning and regularization
approaches have been proposed to transfer knowledge from existing pre-trained
models to specific target domains with limited data. This paper introduces the
Transfer Guided Diffusion Process (TGDP), a novel approach distinct from
conventional finetuning and regularization methods. We prove that the optimal
diffusion model for the target domain integrates pre-trained diffusion models
on the source domain with additional guidance from a domain classifier. We
further extend TGDP to a conditional version for modeling the joint
distribution of data and its corresponding labels, together with two additional
regularization terms to enhance the model performance. We validate the
effectiveness of TGDP on Gaussian mixture simulations and on real
electrocardiogram (ECG) datasets.

摘要：擴散模型，一種特定類型的生成式模型，在近年來取得前所未有的效能，並持續產生高品質的合成樣本。它們顯著成功的關鍵先決條件在於大量訓練樣本的存在，然而在實際應用中，由於高昂的收集成本或相關風險，這可能不切實際。因此，各種微調和正則化方法已被提出，以將知識從現有的預訓練模型轉移到具有有限數據的特定目標領域。本文介紹了轉移引導擴散過程 (TGDP)，這是一種不同於傳統微調和正則化方法的新穎方法。我們證明了目標領域的最佳擴散模型整合了來源領域的預訓練擴散模型，並結合了來自領域分類器的額外指導。我們進一步將 TGDP 延伸到條件式版本，用於建模數據及其對應標籤的聯合分佈，並加入兩個額外的正則化項以增強模型效能。我們在高斯混合模擬和真實心電圖 (ECG) 資料集上驗證了 TGDP 的有效性。

##### **Mixture of Modality Knowledge Experts for Robust Multi-modal Knowledge Graph Completion**
2405.16869v1 by Yichi Zhang, Zhuo Chen, Lingbing Guo, Yajing Xu, Binbin Hu, Ziqi Liu, Wen Zhang, Huajun Chen

Multi-modal knowledge graph completion (MMKGC) aims to automatically discover
new knowledge triples in the given multi-modal knowledge graphs (MMKGs), which
is achieved by collaborative modeling the structural information concealed in
massive triples and the multi-modal features of the entities. Existing methods
tend to focus on crafting elegant entity-wise multi-modal fusion strategies,
yet they overlook the utilization of multi-perspective features concealed
within the modalities under diverse relational contexts. To address this issue,
we introduce a novel MMKGC framework with Mixture of Modality Knowledge experts
(MoMoK for short) to learn adaptive multi-modal embedding under intricate
relational contexts. We design relation-guided modality knowledge experts to
acquire relation-aware modality embeddings and integrate the predictions from
multi-modalities to achieve comprehensive decisions. Additionally, we
disentangle the experts by minimizing their mutual information. Experiments on
four public MMKG benchmarks demonstrate the outstanding performance of MoMoK
under complex scenarios.

摘要：多模态知识图谱补全（MMKGC）旨在在给定的多模态知识图谱（MMKG）中自动发现新的知识三元组，这是通过协作建模隐藏在海量三元组中的结构信息和实体的多模态特征来实现的。现有方法倾向于专注于精心制作优雅的实体级多模态融合策略，但它们忽略了在不同关系语境下隐藏在模态中的多视角特征的利用。为了解决这个问题，我们引入了一个新的 MMKGC 框架，其中包含混合模态知识专家（简称 MoMoK），以在复杂的语境关系下学习自适应的多模态嵌入。我们设计了关系引导的模态知识专家来获取关系感知的模态嵌入，并整合来自多模态的预测以实现全面的决策。此外，我们通过最小化专家的互信息来解开专家的纠缠。在四个公共 MMKG 基准上的实验表明了 MoMoK 在复杂场景下的出色性能。

##### **Think Before You Act: A Two-Stage Framework for Mitigating Gender Bias Towards Vision-Language Tasks**
2405.16860v1 by Yunqi Zhang, Songda Li, Chunyuan Deng, Luyi Wang, Hui Zhao

Gender bias in vision-language models (VLMs) can reinforce harmful
stereotypes and discrimination. In this paper, we focus on mitigating gender
bias towards vision-language tasks. We identify object hallucination as the
essence of gender bias in VLMs. Existing VLMs tend to focus on salient or
familiar attributes in images but ignore contextualized nuances. Moreover, most
VLMs rely on the co-occurrence between specific objects and gender attributes
to infer the ignored features, ultimately resulting in gender bias. We propose
GAMA, a task-agnostic generation framework to mitigate gender bias. GAMA
consists of two stages: narrative generation and answer inference. During
narrative generation, GAMA yields all-sided but gender-obfuscated narratives,
which prevents premature concentration on localized image features, especially
gender attributes. During answer inference, GAMA integrates the image,
generated narrative, and a task-specific question prompt to infer answers for
different vision-language tasks. This approach allows the model to rethink
gender attributes and answers. We conduct extensive experiments on GAMA,
demonstrating its debiasing and generalization ability.

摘要：視覺語言模型 (VLM) 中的性別偏見會強化有害的刻板印象和歧視。在本文中，我們專注於減輕視覺語言任務中的性別偏見。我們將物件幻覺視為 VLM 中性別偏見的本質。現有的 VLM 傾向於關注圖像中的顯著或熟悉的屬性，但忽略了上下文化的細微差別。此外，大多數 VLM 依賴特定物件與性別屬性之間的共現來推斷被忽略的特徵，最終導致性別偏見。我們提出 GAMA，一個與任務無關的生成架構，以減輕性別偏見。GAMA 包含兩個階段：敘事生成和答案推論。在敘事生成期間，GAMA 產生全面但性別模糊的敘事，這可以防止過早集中於局部影像特徵，特別是性別屬性。在答案推論期間，GAMA 整合影像、生成的敘事和特定於任務的問題提示，以推論不同視覺語言任務的答案。這種方法允許模型重新思考性別屬性和答案。我們對 GAMA 進行了廣泛的實驗，證明了它的去偏見和泛化能力。

##### **Can We Trust LLMs? Mitigate Overconfidence Bias in LLMs through Knowledge Transfer**
2405.16856v1 by Haoyan Yang, Yixuan Wang, Xingyin Xu, Hanyuan Zhang, Yirong Bian

The study explores mitigating overconfidence bias in LLMs to improve their
reliability. We introduce a knowledge transfer (KT) method utilizing chain of
thoughts, where "big" LLMs impart knowledge to "small" LLMs via detailed,
sequential reasoning paths. This method uses advanced reasoning of larger
models to fine-tune smaller models, enabling them to produce more accurate
predictions with calibrated confidence. Experimental evaluation using
multiple-choice questions and sentiment analysis across diverse datasets
demonstrated the KT method's superiority over the vanilla and question-answer
pair (QA) fine-tuning methods. The most significant improvement in three key
metrics, where the KT method outperformed the vanilla and QA methods by an
average of 55.3% and 43.1%, respectively. These findings underscore the KT
method's potential in enhancing model trustworthiness and accuracy, offering
precise outputs with well-matched confidence levels across various contexts.

摘要：本研究探討如何減輕大型語言模型 (LLM) 中的過度自信偏差，以提升其可靠性。我們提出了一種利用思考鏈的知識轉移 (KT) 方法，其中「大型」LLM 透過詳細的順序推理路徑，將知識傳授給「小型」LLM。此方法使用較大型模型的高階推理，微調較小型模型，讓它們能夠產生更準確的預測，並校準信心。透過使用多項選擇題和跨不同資料集的情緒分析進行實驗評估，證明 KT 方法優於傳統和問答 (QA) 微調方法。在三個關鍵指標中，KT 方法的進步最顯著，平均分別優於傳統和 QA 方法 55.3% 和 43.1%。這些發現強調了 KT 方法在增強模型可信度和準確度方面的潛力，提供在各種情境中具有良好匹配信心水準的精確輸出。

##### **EM Distillation for One-step Diffusion Models**
2405.16852v1 by Sirui Xie, Zhisheng Xiao, Diederik P Kingma, Tingbo Hou, Ying Nian Wu, Kevin Patrick Murphy, Tim Salimans, Ben Poole, Ruiqi Gao

While diffusion models can learn complex distributions, sampling requires a
computationally expensive iterative process. Existing distillation methods
enable efficient sampling, but have notable limitations, such as performance
degradation with very few sampling steps, reliance on training data access, or
mode-seeking optimization that may fail to capture the full distribution. We
propose EM Distillation (EMD), a maximum likelihood-based approach that
distills a diffusion model to a one-step generator model with minimal loss of
perceptual quality. Our approach is derived through the lens of
Expectation-Maximization (EM), where the generator parameters are updated using
samples from the joint distribution of the diffusion teacher prior and inferred
generator latents. We develop a reparametrized sampling scheme and a noise
cancellation technique that together stabilizes the distillation process. We
further reveal an interesting connection of our method with existing methods
that minimize mode-seeking KL. EMD outperforms existing one-step generative
methods in terms of FID scores on ImageNet-64 and ImageNet-128, and compares
favorably with prior work on distilling text-to-image diffusion models.

摘要：儘管擴散模型可以學習複雜的分布，但取樣需要一個計算成本昂貴的迭代過程。現有的蒸餾方法能夠進行有效率的取樣，但有明顯的限制，例如在取樣步驟非常少時效能下降、依賴訓練資料存取，或是尋求模式的最佳化可能會無法捕捉到完整的分布。我們提出 EM 蒸餾 (EMD)，一種基於最大似然估計的方法，將擴散模型蒸餾成一個步驟生成器模型，同時將感知品質的損失降到最低。我們的做法是透過期望最大化 (EM) 的觀點衍生而來，其中生成器參數使用擴散教師先驗和推論生成器潛在變數的聯合分布中的樣本來更新。我們開發出一個重新參數化的取樣方案和一個雜訊消除技術，它們共同穩定蒸餾過程。我們進一步揭示了我們的方法與最小化尋求模式 KL 的現有方法之間的有趣連結。EMD 在 ImageNet-64 和 ImageNet-128 上的 FID 分數方面優於現有的單步生成方法，並且與先前蒸餾文本到影像擴散模型的研究相比，表現也相當不錯。

##### **Temporal Spiking Neural Networks with Synaptic Delay for Graph Reasoning**
2405.16851v1 by Mingqing Xiao, Yixin Zhu, Di He, Zhouchen Lin

Spiking neural networks (SNNs) are investigated as biologically inspired
models of neural computation, distinguished by their computational capability
and energy efficiency due to precise spiking times and sparse spikes with
event-driven computation. A significant question is how SNNs can emulate
human-like graph-based reasoning of concepts and relations, especially
leveraging the temporal domain optimally. This paper reveals that SNNs, when
amalgamated with synaptic delay and temporal coding, are proficient in
executing (knowledge) graph reasoning. It is elucidated that spiking time can
function as an additional dimension to encode relation properties via a
neural-generalized path formulation. Empirical results highlight the efficacy
of temporal delay in relation processing and showcase exemplary performance in
diverse graph reasoning tasks. The spiking model is theoretically estimated to
achieve $20\times$ energy savings compared to non-spiking counterparts,
deepening insights into the capabilities and potential of biologically inspired
SNNs for efficient reasoning. The code is available at
https://github.com/pkuxmq/GRSNN.

摘要：尖峰神经網路（SNN）被視為生物靈感的類神經運算模型，其特點是運算能力強，由於精準的尖峰時間和具有事件驅動運算的稀疏尖峰，因此能效高。一個重要的問題是 SNN 如何能模擬人類類圖形基於概念和關係的推理，特別是最佳利用時間域。本文揭示了 SNN 在與突觸延遲和時間編碼結合時，擅長執行（知識）圖形推理。說明了尖峰時間可以作為一個附加維度，透過神經廣義路徑公式來編碼關係屬性。經驗結果突顯了時間延遲在關係處理中的效能，並展示了在各種圖形推理任務中的範例效能。理論上估計尖峰模型可節省 $20\times$ 的能量，與非尖峰對應物相比，加深了對生物靈感 SNN 在有效推理方面的能力和潛力的見解。程式碼可在 https://github.com/pkuxmq/GRSNN 取得。

##### **TokenUnify: Scalable Autoregressive Visual Pre-training with Mixture Token Prediction**
2405.16847v1 by Yinda Chen, Haoyuan Shi, Xiaoyu Liu, Te Shi, Ruobing Zhang, Dong Liu, Zhiwei Xiong, Feng Wu

Autoregressive next-token prediction is a standard pretraining method for
large-scale language models, but its application to vision tasks is hindered by
the non-sequential nature of image data, leading to cumulative errors. Most
vision models employ masked autoencoder (MAE) based pretraining, which faces
scalability issues. To address these challenges, we introduce
\textbf{TokenUnify}, a novel pretraining method that integrates random token
prediction, next-token prediction, and next-all token prediction. We provide
theoretical evidence demonstrating that TokenUnify mitigates cumulative errors
in visual autoregression. Cooperated with TokenUnify, we have assembled a
large-scale electron microscopy (EM) image dataset with ultra-high resolution,
ideal for creating spatially correlated long sequences. This dataset includes
over 120 million annotated voxels, making it the largest neuron segmentation
dataset to date and providing a unified benchmark for experimental validation.
Leveraging the Mamba network inherently suited for long-sequence modeling on
this dataset, TokenUnify not only reduces the computational complexity but also
leads to a significant 45\% improvement in segmentation performance on
downstream EM neuron segmentation tasks compared to existing methods.
Furthermore, TokenUnify demonstrates superior scalability over MAE and
traditional autoregressive methods, effectively bridging the gap between
pretraining strategies for language and vision models. Code is available at
\url{https://github.com/ydchen0806/TokenUnify}.

摘要：回歸自迴歸下一個符號預測是大規模語言模型的標準預訓練方法，但其在視覺任務中的應用受到影像資料非序列性質的阻礙，導致累積誤差。大多數視覺模型採用基於遮罩自動編碼器 (MAE) 的預訓練，這面臨可擴充性的問題。為了應對這些挑戰，我們引入了 TokenUnify，這是一種新的預訓練方法，整合了隨機符號預測、下一個符號預測和下一個所有符號預測。我們提供了理論證據，證明 TokenUnify 減輕了視覺自動迴歸中的累積誤差。配合 TokenUnify，我們組建了一個具有超高解析度的大規模電子顯微鏡 (EM) 影像資料集，非常適合建立空間相關長序列。此資料集包含超過 1.2 億個註解體素，使其成為迄今為止最大的神經元分割資料集，並提供了一個統一的基準，用於實驗驗證。利用本質上適合於此資料集上的長序列建模的 Mamba 網路，TokenUnify 不僅降低了運算複雜度，而且與現有方法相比，在下游 EM 神經元分割任務中，分割效能顯著提升了 45%。此外，TokenUnify 展示了優於 MAE 和傳統自動迴歸方法的可擴充性，有效地彌合了語言和視覺模型預訓練策略之間的差距。程式碼可在 https://github.com/ydchen0806/TokenUnify 取得。

##### **On Mesa-Optimization in Autoregressively Trained Transformers: Emergence and Capability**
2405.16845v1 by Chenyu Zheng, Wei Huang, Rongzhen Wang, Guoqiang Wu, Jun Zhu, Chongxuan Li

Autoregressively trained transformers have brought a profound revolution to
the world, especially with their in-context learning (ICL) ability to address
downstream tasks. Recently, several studies suggest that transformers learn a
mesa-optimizer during autoregressive (AR) pretraining to implement ICL. Namely,
the forward pass of the trained transformer is equivalent to optimizing an
inner objective function in-context. However, whether the practical non-convex
training dynamics will converge to the ideal mesa-optimizer is still unclear.
Towards filling this gap, we investigate the non-convex dynamics of a one-layer
linear causal self-attention model autoregressively trained by gradient flow,
where the sequences are generated by an AR process $x_{t+1} = W x_t$. First,
under a certain condition of data distribution, we prove that an
autoregressively trained transformer learns $W$ by implementing one step of
gradient descent to minimize an ordinary least squares (OLS) problem
in-context. It then applies the learned $\widehat{W}$ for next-token
prediction, thereby verifying the mesa-optimization hypothesis. Next, under the
same data conditions, we explore the capability limitations of the obtained
mesa-optimizer. We show that a stronger assumption related to the moments of
data is the sufficient and necessary condition that the learned mesa-optimizer
recovers the distribution. Besides, we conduct exploratory analyses beyond the
first data condition and prove that generally, the trained transformer will not
perform vanilla gradient descent for the OLS problem. Finally, our simulation
results verify the theoretical results.

摘要：自回归训练的 Transformer 为世界带来了深刻的变革，尤其是其上下文学习 (ICL) 能力，可解决下游任务。最近，多项研究表明 Transformer 在自回归 (AR) 预训练期间学习了一个 mesa 优化器来实现 ICL。即，训练后的 Transformer 的前向传递等同于优化上下文中内部的目标函数。然而，实际的非凸训练动态是否会收敛到理想的 mesa 优化器仍不清楚。为了填补这一空白，我们研究了由梯度流自回归训练的单层线性因果自注意力模型的非凸动态，其中序列由 AR 过程生成 $x_{t+1} = W x_t$。首先，在数据分布的特定条件下，我们证明了自回归训练的 Transformer 通过实施一步梯度下降来学习 $W$，以最小化上下文中的普通最小二乘 (OLS) 问题。然后，它将学习到的 $\widehat{W}$ 应用于下一个标记预测，从而验证了 mesa 优化假设。接下来，在相同的数据条件下，我们探索了获得的 mesa 优化器的能力限制。我们表明，与数据矩相关的更强假设是学习到的 mesa 优化器恢复分布的充分且必要条件。此外，我们进行了超出第一个数据条件的探索性分析，并证明通常，训练后的 Transformer 不会对 OLS 问题执行香草梯度下降。最后，我们的模拟结果验证了理论结果。

##### **Enhancing Fast Feed Forward Networks with Load Balancing and a Master Leaf Node**
2405.16836v1 by Andreas Charalampopoulos, Nikolas Chatzis, Foivos Ntoulas-Panagiotopoulos, Charilaos Papaioannou, Alexandros Potamianos

Fast feedforward networks (FFFs) are a class of neural networks that exploit
the observation that different regions of the input space activate distinct
subsets of neurons in wide networks. FFFs partition the input space into
separate sections using a differentiable binary tree of neurons and during
inference descend the binary tree in order to improve computational efficiency.
Inspired by Mixture of Experts (MoE) research, we propose the incorporation of
load balancing and Master Leaf techniques into the FFF architecture to improve
performance and simplify the training process. We reproduce experiments found
in literature and present results on FFF models enhanced using these
techniques. The proposed architecture and training recipe achieves up to 16.3%
and 3% absolute classification accuracy increase in training and test accuracy,
respectively, compared to the original FFF architecture. Additionally, we
observe a smaller variance in the results compared to those reported in prior
research. These findings demonstrate the potential of integrating MoE-inspired
techniques into FFFs for developing more accurate and efficient models.

摘要：快速前馈网络 (FFF) 是一类神经网络，它利用了输入空间的不同区域激活宽网络中不同神经元子集的观察结果。FFF 使用可微二叉树神经元将输入空间划分为不同的部分，并在推理过程中下降二叉树以提高计算效率。受到专家混合 (MoE) 研究的启发，我们建议将负载平衡和主叶技术纳入 FFF 架构，以提高性能并简化训练过程。我们重现了文献中发现的实验，并展示了使用这些技术增强的 FFF 模型的结果。与原始 FFF 架构相比，所提出的架构和训练方法分别在训练和测试准确性方面实现了高达 16.3% 和 3% 的绝对分类准确性提升。此外，我们观察到与先前研究报告的结果相比，结果的差异较小。这些发现证明了将受 MoE 启发的技术集成到 FFF 中以开发更准确、更高效的模型的潜力。

##### **Structured Graph Network for Constrained Robot Crowd Navigation with Low Fidelity Simulation**
2405.16830v2 by Shuijing Liu, Kaiwen Hong, Neeloy Chakraborty, Katherine Driggs-Campbell

We investigate the feasibility of deploying reinforcement learning (RL)
policies for constrained crowd navigation using a low-fidelity simulator. We
introduce a representation of the dynamic environment, separating human and
obstacle representations. Humans are represented through detected states, while
obstacles are represented as computed point clouds based on maps and robot
localization. This representation enables RL policies trained in a low-fidelity
simulator to deploy in real world with a reduced sim2real gap. Additionally, we
propose a spatio-temporal graph to model the interactions between agents and
obstacles. Based on the graph, we use attention mechanisms to capture the
robot-human, human-human, and human-obstacle interactions. Our method
significantly improves navigation performance in both simulated and real-world
environments. Video demonstrations can be found at
https://sites.google.com/view/constrained-crowdnav/home.

摘要：我們研究使用低保真模擬器部署強化學習 (RL) 策略以進行受限人群導航的可行性。我們引入動態環境的表示，將人類和障礙物表示分開。人類透過偵測到的狀態表示，而障礙物則表示為基於地圖和機器人定位的計算點雲。此表示法使在低保真模擬器中訓練的 RL 策略能夠在真實世界中部署，並縮小 sim2real 差距。此外，我們提出一個時空圖形來模擬代理和障礙物之間的交互作用。基於此圖形，我們使用注意力機制來捕捉機器人與人類、人類與人類以及人類與障礙物的交互作用。我們的這種方法顯著改善了在模擬和真實世界環境中的導航效能。影片示範可以在 https://sites.google.com/view/constrained-crowdnav/home 找到。

##### **Unified Editing of Panorama, 3D Scenes, and Videos Through Disentangled Self-Attention Injection**
2405.16823v1 by Gihyun Kwon, Jangho Park, Jong Chul Ye

While text-to-image models have achieved impressive capabilities in image
generation and editing, their application across various modalities often
necessitates training separate models. Inspired by existing method of single
image editing with self attention injection and video editing with shared
attention, we propose a novel unified editing framework that combines the
strengths of both approaches by utilizing only a basic 2D image text-to-image
(T2I) diffusion model. Specifically, we design a sampling method that
facilitates editing consecutive images while maintaining semantic consistency
utilizing shared self-attention features during both reference and consecutive
image sampling processes. Experimental results confirm that our method enables
editing across diverse modalities including 3D scenes, videos, and panorama
images.

摘要：儘管文字轉圖片模型在圖片產生和編輯上已取得令人印象深刻的能力，但它們在各種模態中的應用通常需要訓練獨立的模型。受到現有方法的啟發，包括使用自我注意注入的單一圖片編輯和使用共享注意力的影片編輯，我們提出一個新穎的統一編輯架構，它結合了兩種方法的優點，僅利用基本的 2D 圖片文字轉圖片 (T2I) 擴散模型。具體來說，我們設計一種取樣方法，它在參考和連續圖片取樣過程中，利用共享的自我注意力特徵，促進編輯連續圖片，同時保持語義一致性。實驗結果證實，我們的方法能夠在包括 3D 場景、影片和全景圖片等多種模態中進行編輯。

##### **Perturbation-Restrained Sequential Model Editing**
2405.16821v1 by Jun-Yu Ma, Hong Wang, Hao-Xiang Xu, Zhen-Hua Ling, Jia-Chen Gu

Model editing is an emerging field that focuses on updating the knowledge
embedded within large language models (LLMs) without extensive retraining.
However, current model editing methods significantly compromise the general
abilities of LLMs as the number of edits increases, and this trade-off poses a
substantial challenge to the continual learning of LLMs. In this paper, we
first theoretically analyze that the factor affecting the general abilities in
sequential model editing lies in the condition number of the edited matrix. The
condition number of a matrix represents its numerical sensitivity, and
therefore can be used to indicate the extent to which the original knowledge
associations stored in LLMs are perturbed after editing. Subsequently,
statistical findings demonstrate that the value of this factor becomes larger
as the number of edits increases, thereby exacerbating the deterioration of
general abilities. To this end, a framework termed Perturbation Restraint on
Upper bouNd for Editing (PRUNE) is proposed, which applies the condition number
restraints in sequential editing. These restraints can lower the upper bound on
perturbation to edited models, thus preserving the general abilities.
Systematically, we conduct experiments employing three popular editing methods
on three LLMs across four representative downstream tasks. Evaluation results
show that PRUNE can preserve considerable general abilities while maintaining
the editing performance effectively in sequential model editing. The code and
data are available at https://github.com/mjy1111/PRUNE.

摘要：模型编辑是一个新兴领域，专注于在不进行广泛重新训练的情况下更新嵌入在大语言模型 (LLM) 中的知识。
然而，随着编辑次数的增加，当前的模型编辑方法会显著损害 LLM 的一般能力，而这种权衡给 LLM 的持续学习带来了重大挑战。在本文中，我们首先从理论上分析了顺序模型编辑中影响一般能力的因素在于所编辑矩阵的条件数。矩阵的条件数表示其数值灵敏度，因此可用于指示编辑后存储在 LLM 中的原始知识关联被扰动的程度。随后，统计结果表明，随着编辑次数的增加，该因子的值会变大，从而加剧一般能力的下降。为此，提出了一个名为编辑上界扰动约束 (PRUNE) 的框架，它在顺序编辑中应用条件数约束。这些约束可以降低对编辑模型的扰动上限，从而保留一般能力。系统地，我们在三个 LLM 上使用三种流行的编辑方法对四个有代表性的下游任务进行实验。评估结果表明，PRUNE 可以保留相当大的一般能力，同时在顺序模型编辑中有效地保持编辑性能。代码和数据可在 https://github.com/mjy1111/PRUNE 获得。

##### **Laboratory-Scale AI: Open-Weight Models are Competitive with ChatGPT Even in Low-Resource Settings**
2405.16820v1 by Robert Wolfe, Isaac Slaughter, Bin Han, Bingbing Wen, Yiwei Yang, Lucas Rosenblatt, Bernease Herman, Eva Brown, Zening Qu, Nic Weber, Bill Howe

The rapid proliferation of generative AI has raised questions about the
competitiveness of lower-parameter, locally tunable, open-weight models
relative to high-parameter, API-guarded, closed-weight models in terms of
performance, domain adaptation, cost, and generalization. Centering
under-resourced yet risk-intolerant settings in government, research, and
healthcare, we see for-profit closed-weight models as incompatible with
requirements for transparency, privacy, adaptability, and standards of
evidence. Yet the performance penalty in using open-weight models, especially
in low-data and low-resource settings, is unclear.
  We assess the feasibility of using smaller, open-weight models to replace
GPT-4-Turbo in zero-shot, few-shot, and fine-tuned regimes, assuming access to
only a single, low-cost GPU. We assess value-sensitive issues around bias,
privacy, and abstention on three additional tasks relevant to those topics. We
find that with relatively low effort, very low absolute monetary cost, and
relatively little data for fine-tuning, small open-weight models can achieve
competitive performance in domain-adapted tasks without sacrificing generality.
We then run experiments considering practical issues in bias, privacy, and
hallucination risk, finding that open models offer several benefits over closed
models. We intend this work as a case study in understanding the opportunity
cost of reproducibility and transparency over for-profit state-of-the-art zero
shot performance, finding this cost to be marginal under realistic settings.

摘要：生成式 AI 的快速擴散引發了關於低參數、局部可調、開放權重模型相對於高參數、API 保護、封閉權重模型在性能、領域適應、成本和泛化方面的競爭力問題。專注於政府、研究和醫療保健中資源不足但風險不容忍的環境，我們認為以營利為目的的封閉權重模型與透明度、隱私、適應性和證據標準的要求不相容。然而，使用開放權重模型的性能損失，尤其是在低數據和低資源設置中，尚不清楚。
我們評估了使用較小的開放權重模型替換 GPT-4-Turbo 在零次、少次和微調方案中的可行性，假設只能訪問單個低成本 GPU。我們評估了圍繞偏見、隱私和禁慾的價值敏感問題，這些問題與這些主題相關的三項額外任務有關。我們發現，以相對較低的成本、非常低的絕對金錢成本和相對較少用於微調的數據，小型開放權重模型可以在不犧牲一般性的情況下在領域適應任務中實現競爭性能。然後，我們運行實驗，考慮偏見、隱私和幻覺風險中的實際問題，發現開放模型比封閉模型提供了多項好處。我們希望這項工作作為一個案例研究，了解可複製性和透明性相對於以營利為目的的最新零次表現的機會成本，發現這種成本在現實環境下是邊際的。

##### **Performance evaluation of Reddit Comments using Machine Learning and Natural Language Processing methods in Sentiment Analysis**
2405.16810v2 by Xiaoxia Zhang, Xiuyuan Qi, Zixin Teng

Sentiment analysis, an increasingly vital field in both academia and
industry, plays a pivotal role in machine learning applications, particularly
on social media platforms like Reddit. However, the efficacy of sentiment
analysis models is hindered by the lack of expansive and fine-grained emotion
datasets. To address this gap, our study leverages the GoEmotions dataset,
comprising a diverse range of emotions, to evaluate sentiment analysis methods
across a substantial corpus of 58,000 comments. Distinguished from prior
studies by the Google team, which limited their analysis to only two models,
our research expands the scope by evaluating a diverse array of models. We
investigate the performance of traditional classifiers such as Naive Bayes and
Support Vector Machines (SVM), as well as state-of-the-art transformer-based
models including BERT, RoBERTa, and GPT. Furthermore, our evaluation criteria
extend beyond accuracy to encompass nuanced assessments, including hierarchical
classification based on varying levels of granularity in emotion
categorization. Additionally, considerations such as computational efficiency
are incorporated to provide a comprehensive evaluation framework. Our findings
reveal that the RoBERTa model consistently outperforms the baseline models,
demonstrating superior accuracy in fine-grained sentiment classification tasks.
This underscores the substantial potential and significance of the RoBERTa
model in advancing sentiment analysis capabilities.

摘要：情緒分析是學術界和產業中日益重要的領域，在機器學習應用中扮演著關鍵角色，特別是在 Reddit 等社群媒體平台上。然而，情緒分析模型的效能受到廣泛且細緻的情緒資料集缺乏的阻礙。為了解決這個差距，我們的研究利用 GoEmotions 資料集，涵蓋各種情緒，以評估跨越 58,000 則留言的大型語料庫中的情緒分析方法。與 Google 團隊先前僅將分析限制在兩個模型的研究不同，我們的研究擴大了範圍，評估了各種模型。我們探討了傳統分類器（例如樸素貝氏和支援向量機 (SVM)）的效能，以及包括 BERT、RoBERTa 和 GPT 在內的最新Transformer模型。此外，我們的評估標準不僅限於準確度，還包括細微的評估，例如基於情緒分類中不同粒度層級的階層式分類。此外，還納入了計算效率等考量，以提供全面的評估架構。我們的研究結果表明，RoBERTa 模型始終優於基準模型，在細緻的情緒分類任務中展現出更高的準確度。這突顯了 RoBERTa 模型在提升情緒分析能力方面的巨大潛力和重要性。

##### **Entity Alignment with Noisy Annotations from Large Language Models**
2405.16806v2 by Shengyuan Chen, Qinggang Zhang, Junnan Dong, Wen Hua, Qing Li, Xiao Huang

Entity alignment (EA) aims to merge two knowledge graphs (KGs) by identifying
equivalent entity pairs. While existing methods heavily rely on human-generated
labels, it is prohibitively expensive to incorporate cross-domain experts for
annotation in real-world scenarios. The advent of Large Language Models (LLMs)
presents new avenues for automating EA with annotations, inspired by their
comprehensive capability to process semantic information. However, it is
nontrivial to directly apply LLMs for EA since the annotation space in
real-world KGs is large. LLMs could also generate noisy labels that may mislead
the alignment. To this end, we propose a unified framework, LLM4EA, to
effectively leverage LLMs for EA. Specifically, we design a novel active
learning policy to significantly reduce the annotation space by prioritizing
the most valuable entities based on the entire inter-KG and intra-KG structure.
Moreover, we introduce an unsupervised label refiner to continuously enhance
label accuracy through in-depth probabilistic reasoning. We iteratively
optimize the policy based on the feedback from a base EA model. Extensive
experiments demonstrate the advantages of LLM4EA on four benchmark datasets in
terms of effectiveness, robustness, and efficiency. Codes are available via
https://github.com/chensyCN/llm4ea_official.

摘要：實體比對 (EA) 旨在透過識別等效的實體對來合併兩個知識圖譜 (KG)。雖然現有方法極度依賴人工產生的標籤，但在現實世界的場景中，要納入跨領域的專家進行註解是難以負擔的成本。大型語言模型 (LLM) 的出現為自動化 EA 提供了新的途徑，其靈感來自於 LLM 全面處理語義資訊的能力。然而，由於現實世界 KG 中的註解空間很大，因此直接應用 LLM 於 EA 並非易事。LLM 也有可能產生雜訊標籤，進而誤導比對。為了解決這個問題，我們提出了一個統一的架構 LLM4EA，以有效利用 LLM 進行 EA。具體來說，我們設計了一種新穎的主動學習政策，透過根據整個跨 KG 和內部 KG 結構，優先處理最有價值的實體，從而大幅減少註解空間。此外，我們引入了一個無監督標籤精煉器，以透過深入的機率推理持續提升標籤的準確性。我們根據基礎 EA 模型的回饋，反覆最佳化政策。廣泛的實驗證明了 LLM4EA 在四個基準資料集上的優勢，包括在效能、穩健性和效率方面。程式碼可透過 https://github.com/chensyCN/llm4ea_official 取得。

##### **AutoCV: Empowering Reasoning with Automated Process Labeling via Confidence Variation**
2405.16802v2 by Jianqiao Lu, Zhiyang Dou, Hongru Wang, Zeyu Cao, Jianbo Dai, Yingjia Wan, Yinya Huang, Zhijiang Guo

In this work, we propose a novel method named \textbf{Auto}mated Process
Labeling via \textbf{C}onfidence \textbf{V}ariation (\textbf{\textsc{AutoCV}})
to enhance the reasoning capabilities of large language models (LLMs) by
automatically annotating the reasoning steps. Our approach begins by training a
verification model on the correctness of final answers, enabling it to generate
automatic process annotations. This verification model assigns a confidence
score to each reasoning step, indicating the probability of arriving at the
correct final answer from that point onward. We detect relative changes in the
verification's confidence scores across reasoning steps to automatically
annotate the reasoning process. This alleviates the need for numerous manual
annotations or the high computational costs associated with model-induced
annotation approaches. We experimentally validate that the confidence
variations learned by the verification model trained on the final answer
correctness can effectively identify errors in the reasoning steps.
Subsequently, we demonstrate that the process annotations generated by
\textsc{AutoCV} can improve the accuracy of the verification model in selecting
the correct answer from multiple outputs generated by LLMs. Notably, we achieve
substantial improvements across five datasets in mathematics and commonsense
reasoning. The source code of \textsc{AutoCV} is available at
\url{https://github.com/rookie-joe/AUTOCV}.

摘要：在這項工作中，我們提出了一種名為透過信心變異進行自動化程序標記（AutoCV）的新方法，藉由自動註解推理步驟來增強大型語言模型（LLM）的推理能力。我們的做法首先訓練驗證模型以驗證最終答案的正確性，使其能夠產生自動程序註解。此驗證模型會為每個推理步驟指定一個信心分數，表示從該點開始得出正確最終答案的機率。我們偵測驗證信心分數在推理步驟中的相對變化，以自動註解推理過程。這減輕了大量手動註解或與模型誘導註解方法相關的高運算成本的需求。我們透過實驗驗證，在最終答案正確性上訓練的驗證模型所學習的信心變異可以有效找出推理步驟中的錯誤。隨後，我們證明了 AutoCV 所產生的程序註解可以提高驗證模型從 LLM 所產生的多個輸出中選擇正確答案的準確性。值得注意的是，我們在數學和常識推理的五個資料集中都取得了顯著的進步。AutoCV 的原始程式碼可在 https://github.com/rookie-joe/AUTOCV 取得。

##### **TAGA: Text-Attributed Graph Self-Supervised Learning by Synergizing Graph and Text Mutual Transformations**
2405.16800v1 by Zheng Zhang, Yuntong Hu, Bo Pan, Chen Ling, Liang Zhao

Text-Attributed Graphs (TAGs) enhance graph structures with natural language
descriptions, enabling detailed representation of data and their relationships
across a broad spectrum of real-world scenarios. Despite the potential for
deeper insights, existing TAG representation learning primarily relies on
supervised methods, necessitating extensive labeled data and limiting
applicability across diverse contexts. This paper introduces a new
self-supervised learning framework, Text-And-Graph Multi-View Alignment (TAGA),
which overcomes these constraints by integrating TAGs' structural and semantic
dimensions. TAGA constructs two complementary views: Text-of-Graph view, which
organizes node texts into structured documents based on graph topology, and the
Graph-of-Text view, which converts textual nodes and connections into graph
data. By aligning representations from both views, TAGA captures joint textual
and structural information. In addition, a novel structure-preserving random
walk algorithm is proposed for efficient training on large-sized TAGs. Our
framework demonstrates strong performance in zero-shot and few-shot scenarios
across eight real-world datasets.

摘要：文本属性图 (TAG) 使用自然语言描述增强图结构，能够详细表示数据及其在广泛的真实世界场景中的关系。尽管有更深入见解的潜力，但现有的 TAG 表示学习主要依赖于监督方法，需要大量的标记数据，并限制了在不同上下文中的适用性。本文介绍了一个新的自监督学习框架，文本和图多视图对齐 (TAGA)，通过整合 TAG 的结构和语义维度来克服这些限制。TAGA 构建了两个互补的视图：图文本视图，它根据图拓扑将节点文本组织成结构化文档；文本图视图，它将文本节点和连接转换为图数据。通过对齐来自两个视图的表示，TAGA 捕获了联合文本和结构信息。此外，提出了一种新颖的结构保持随机游走算法，用于对大型 TAG 进行高效训练。我们的框架在八个真实世界数据集的零样本和少样本场景中展示了强大的性能。

##### **A Real-Time Voice Activity Detection Based On Lightweight Neural**
2405.16797v1 by Jidong Jia, Pei Zhao, Di Wang

Voice activity detection (VAD) is the task of detecting speech in an audio
stream, which is challenging due to numerous unseen noises and low
signal-to-noise ratios in real environments. Recently, neural network-based
VADs have alleviated the degradation of performance to some extent. However,
the majority of existing studies have employed excessively large models and
incorporated future context, while neglecting to evaluate the operational
efficiency and latency of the models. In this paper, we propose a lightweight
and real-time neural network called MagicNet, which utilizes casual and depth
separable 1-D convolutions and GRU. Without relying on future features as
input, our proposed model is compared with two state-of-the-art algorithms on
synthesized in-domain and out-domain test datasets. The evaluation results
demonstrate that MagicNet can achieve improved performance and robustness with
fewer parameter costs.

摘要：語音活動偵測 (VAD) 的任務是偵測音訊串流中的語音，由於在真實環境中存在許多未見過的雜訊和低信號雜訊比，這是一項具有挑戰性的任務。近期，基於神經網路的 VAD 在某種程度上減輕了效能的降低。然而，現有研究大多採用過大的模型並納入未來的脈絡，卻忽略了評估模型的操作效率與延遲。在本文中，我們提出了一種稱為 MagicNet 的輕量級即時神經網路，它利用隨機且深度可分離的 1D 卷積和 GRU。我們的建議模型並未依賴未來特徵作為輸入，並在合成領域內和領域外測試資料集上與兩種最先進的演算法進行比較。評估結果顯示，MagicNet 能以較少的參數成本，達到更好的效能和穩健性。

##### **Laurel: Generating Dafny Assertions Using Large Language Models**
2405.16792v1 by Eric Mugnier, Emmanuel Anaya Gonzalez, Ranjit Jhala, Nadia Polikarpova, Yuanyuan Zhou

Dafny is a popular verification language, which automates proofs by
outsourcing them to an SMT solver. This automation is not perfect, however, and
the solver often requires guidance in the form of helper assertions creating a
burden for the proof engineer. In this paper, we propose Laurel, a tool that
uses large language models (LLMs) to automatically generate helper assertions
for Dafny programs. To improve the success rate of LLMs in this task, we design
two domain-specific prompting techniques. First, we help the LLM determine the
location of the missing assertion by analyzing the verifier's error message and
inserting an assertion placeholder at that location. Second, we provide the LLM
with example assertions from the same codebase, which we select based on a new
lemma similarity metric. We evaluate our techniques on a dataset of helper
assertions we extracted from three real-world Dafny codebases. Our evaluation
shows that Laurel is able to generate over 50% of the required helper
assertions given only a few attempts, making LLMs a usable and affordable tool
to further automate practical program verification.

摘要：Dafny 是一種流行的驗證語言，它透過將證明外包給 SMT 求解器來自動化證明。然而，這種自動化並非完美，求解器通常需要輔助斷言形式的指導，為證明工程師造成負擔。在本文中，我們提出 Laurel，一種使用大型語言模型 (LLM) 自動為 Dafny 程式產生輔助斷言的工具。為了提高 LLM 在此任務中的成功率，我們設計了兩種特定領域的提示技術。首先，我們透過分析驗證器的錯誤訊息並在該位置插入斷言佔位符，來幫助 LLM 確定遺失斷言的位置。其次，我們根據新的引理相似性度量，從同一個程式碼庫中提供 LLM 範例斷言。我們在從三個真實世界的 Dafny 程式碼庫中提取的輔助斷言資料集上評估我們的技術。我們的評估顯示，Laurel 能夠在僅嘗試幾次的情況下產生超過 50% 的所需輔助斷言，這使得 LLM 成為一種可用且經濟實惠的工具，可進一步自動化實際程式驗證。

##### **TrojFM: Resource-efficient Backdoor Attacks against Very Large Foundation Models**
2405.16783v1 by Yuzhou. Nie, Yanting. Wang, Jinyuan. Jia, Michael J. De Lucia, Nathaniel D. Bastian, Wenbo. Guo, Dawn. Song

One key challenge in backdoor attacks against large foundation models is the
resource limits. Backdoor attacks usually require retraining the target model,
which is impractical for very large foundation models. Existing backdoor
attacks are mainly designed for supervised classifiers or small foundation
models (e.g., BERT). None of these attacks has successfully compromised a very
large foundation model, such as Llama-3-70B, especially with limited
computational resources. In this paper, we propose TrojFM, a novel backdoor
attack tailored for very large foundation models. Our primary technical
contribution is the development of a novel backdoor injection method. This
method forces a backdoored model to generate similar hidden representations for
poisoned inputs regardless of their actual semantics. Our approach injects such
backdoors by fine-tuning only a very small proportion of model parameters. This
enables TrojFM to efficiently launch downstream task-agnostic backdoor attacks
against very large foundation models under limited computational resources.
Moreover, we optimize the fine-tuning process with our customized QLoRA
technique, enabling launching our attack via only~\textit{one A100 GPU}.
Furthermore, we design a new trigger injection method to ensure our attack
stealthiness. Through extensive experiments, we first demonstrate that TrojFM
can launch effective backdoor attacks against widely used large GPT-style
models without jeopardizing their normal functionalities (and outperforming
existing attacks on BERT-style models). Furthermore, we show that TrojFM is
resilient to SOTA defenses and is insensitive to changes in key
hyper-parameters. Finally, we conduct a resource analysis to quantify that our
method can significantly save computational and memory costs compared to
existing backdoor attacks.

摘要：<paragraph>針對大型基礎模型的後門攻擊中，一個主要的挑戰在於資源限制。後門攻擊通常需要重新訓練目標模型，而這對於非常大型的基礎模型來說是不切實際的。現有的後門攻擊主要設計用於監督分類器或小型基礎模型（例如 BERT）。這些攻擊都沒有成功入侵過非常大型的基礎模型，例如 Llama-3-70B，特別是在計算資源有限的情況下。在本文中，我們提出了 TrojFM，一種針對非常大型基礎模型量身打造的新型後門攻擊。我們的主要技術貢獻是開發了一種新穎的後門注入方法。這種方法迫使後門模型為中毒輸入生成相似的隱藏表示，而不管它們的實際語義如何。我們的做法是通過微調模型參數中非常小的一部分來注入這樣的後門。這使得 TrojFM 能夠在有限的計算資源下，有效地對非常大型的基礎模型發起與下游任務無關的後門攻擊。此外，我們使用自定義的 QLoRA 技術優化了微調過程，使我們能夠僅通過~\textit{一個 A100 GPU}來發起攻擊。此外，我們設計了一種新的觸發注入方法來確保我們的攻擊具備隱蔽性。通過大量的實驗，我們首先證明了 TrojFM 能夠對廣泛使用的 GPT 風格的大型模型發起有效的後門攻擊，而不會損害它們的正常功能（並且優於對 BERT 風格模型的現有攻擊）。此外，我們表明 TrojFM 對 SOTA 防禦具有彈性，並且對關鍵超參數的變化不敏感。最後，我們進行了一項資源分析，以量化與現有的後門攻擊相比，我們的模型可以顯著節省計算和記憶體成本。</paragraph>

##### **Reframing the Relationship in Out-of-Distribution Detection**
2405.16766v1 by YuXiao Lee, Xiaofeng Cao

The remarkable achievements of Large Language Models (LLMs) have captivated
the attention of both academia and industry, transcending their initial role in
dialogue generation. The utilization of LLMs as intermediary agents in various
tasks has yielded promising results, sparking a wave of innovation in
artificial intelligence. Building on these breakthroughs, we introduce a novel
approach that integrates the agent paradigm into the Out-of-distribution (OOD)
detection task, aiming to enhance its robustness and adaptability. Our proposed
method, Concept Matching with Agent (CMA), employs neutral prompts as agents to
augment the CLIP-based OOD detection process. These agents function as dynamic
observers and communication hubs, interacting with both In-distribution (ID)
labels and data inputs to form vector triangle relationships. This triangular
framework offers a more nuanced approach than the traditional binary
relationship, allowing for better separation and identification of ID and OOD
inputs. Our extensive experimental results showcase the superior performance of
CMA over both zero-shot and training-required methods in a diverse array of
real-world scenarios.

摘要：大型語言模型 (LLM) 的顯著成就吸引了學術界和產業的關注，超越了它們最初在對話生成中的角色。將 LLM 作為各種任務中的中介代理的使用產生了有希望的結果，引發了人工智慧創新浪潮。在這些突破的基礎上，我們引入了一種新方法，將代理範例整合到分布外 (OOD) 檢測任務中，旨在增強其穩健性和適應性。我們提出的方法，概念匹配代理 (CMA)，使用中立提示作為代理來擴充基於 CLIP 的 OOD 檢測過程。這些代理作為動態觀察者和通信中心，與分佈內 (ID) 標籤和數據輸入交互以形成向量三角形關係。這個三角形架構提供了一種比傳統二元關係更細緻的方法，允許更好地分離和識別 ID 和 OOD 輸入。我們廣泛的實驗結果展示了 CMA 在各種真實世界場景中優於零次學習和需要訓練的方法的卓越性能。

##### **Masked Face Recognition with Generative-to-Discriminative Representations**
2405.16761v1 by Shiming Ge, Weijia Guo, Chenyu Li, Junzheng Zhang, Yong Li, Dan Zeng

Masked face recognition is important for social good but challenged by
diverse occlusions that cause insufficient or inaccurate representations. In
this work, we propose a unified deep network to learn
generative-to-discriminative representations for facilitating masked face
recognition. To this end, we split the network into three modules and learn
them on synthetic masked faces in a greedy module-wise pretraining manner.
First, we leverage a generative encoder pretrained for face inpainting and
finetune it to represent masked faces into category-aware descriptors.
Attribute to the generative encoder's ability in recovering context
information, the resulting descriptors can provide occlusion-robust
representations for masked faces, mitigating the effect of diverse masks. Then,
we incorporate a multi-layer convolutional network as a discriminative reformer
and learn it to convert the category-aware descriptors into identity-aware
vectors, where the learning is effectively supervised by distilling relation
knowledge from off-the-shelf face recognition model. In this way, the
discriminative reformer together with the generative encoder serves as the
pretrained backbone, providing general and discriminative representations
towards masked faces. Finally, we cascade one fully-connected layer following
by one softmax layer into a feature classifier and finetune it to identify the
reformed identity-aware vectors. Extensive experiments on synthetic and
realistic datasets demonstrate the effectiveness of our approach in recognizing
masked faces.

摘要：遮罩人脸识别对于社会有益，但因各种遮挡而受到挑战，这些遮挡会导致表示不足或不准确。在这项工作中，我们提出了一种统一的深度网络，用于学习生成到判别表示，以促进遮罩人脸识别。为此，我们将网络分成三个模块，并以贪婪的模块化预训练方式在合成遮罩人脸上学习它们。首先，我们利用一个生成式编码器，该编码器经过预训练用于人脸修复，并对其进行微调以将遮罩人脸表示为类别感知描述符。归功于生成式编码器在恢复上下文信息方面的能力，所得描述符可以为遮罩人脸提供遮挡鲁棒表示，从而减轻各种遮罩的影响。然后，我们结合一个多层卷积网络作为判别式改造器，并学习将其转换为身份感知向量的类别感知描述符，其中学习通过从现成的人脸识别模型中提取关系知识来有效地监督。通过这种方式，判别式改造器与生成式编码器一起作为预训练骨干，为遮罩人脸提供通用且判别式的表示。最后，我们将一个全连接层级联到一个 softmax 层中，形成一个特征分类器，并对其进行微调以识别改造后的身份感知向量。在合成和真实数据集上的大量实验表明了我们方法在识别遮罩人脸方面的有效性。

