{"2405.06624": {"publish_time": "2024-05-10", "title": "Towards Guaranteed Safe AI: A Framework for Ensuring Robust and Reliable AI Systems", "paper_summary": "Ensuring that AI systems reliably and robustly avoid harmful or dangerous\nbehaviours is a crucial challenge, especially for AI systems with a high degree\nof autonomy and general intelligence, or systems used in safety-critical\ncontexts. In this paper, we will introduce and define a family of approaches to\nAI safety, which we will refer to as guaranteed safe (GS) AI. The core feature\nof these approaches is that they aim to produce AI systems which are equipped\nwith high-assurance quantitative safety guarantees. This is achieved by the\ninterplay of three core components: a world model (which provides a\nmathematical description of how the AI system affects the outside world), a\nsafety specification (which is a mathematical description of what effects are\nacceptable), and a verifier (which provides an auditable proof certificate that\nthe AI satisfies the safety specification relative to the world model). We\noutline a number of approaches for creating each of these three core\ncomponents, describe the main technical challenges, and suggest a number of\npotential solutions to them. We also argue for the necessity of this approach\nto AI safety, and for the inadequacy of the main alternative approaches.", "paper_summary_zh": "\u78ba\u4fdd AI \u7cfb\u7d71\u53ef\u9760\u4e14\u7a69\u5065\u5730\u907f\u514d\u6709\u5bb3\u6216\u5371\u96aa\u7684\u884c\u70ba\u662f\u4e00\u9805\u81f3\u95dc\u91cd\u8981\u7684\u6311\u6230\uff0c\u7279\u5225\u662f\u5c0d\u65bc\u9ad8\u5ea6\u81ea\u4e3b\u548c\u5177\u5099\u4e00\u822c\u667a\u6167\u7684 AI \u7cfb\u7d71\uff0c\u6216\u7528\u65bc\u5b89\u5168\u95dc\u9375\u60c5\u5883\u4e2d\u7684\u7cfb\u7d71\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5c07\u4ecb\u7d39\u548c\u5b9a\u7fa9\u4e00\u7cfb\u5217 AI \u5b89\u5168\u65b9\u6cd5\uff0c\u6211\u5011\u5c07\u5176\u7a31\u70ba\u4fdd\u8b49\u5b89\u5168 (GS) AI\u3002\u9019\u4e9b\u65b9\u6cd5\u7684\u6838\u5fc3\u7279\u5fb5\u662f\u5b83\u5011\u65e8\u5728\u7522\u751f\u5177\u5099\u9ad8\u4fdd\u8b49\u5b9a\u91cf\u5b89\u5168\u4fdd\u8b49\u7684 AI \u7cfb\u7d71\u3002\u9019\u662f\u900f\u904e\u4e09\u500b\u6838\u5fc3\u7d44\u6210\u7684\u4ea4\u4e92\u4f5c\u7528\u4f86\u5be6\u73fe\u7684\uff1a\u4e16\u754c\u6a21\u578b\uff08\u63d0\u4f9b AI \u7cfb\u7d71\u5982\u4f55\u5f71\u97ff\u5916\u90e8\u4e16\u754c\u7684\u6578\u5b78\u63cf\u8ff0\uff09\u3001\u5b89\u5168\u898f\u7bc4\uff08\u5c0d\u53ef\u63a5\u53d7\u5f71\u97ff\u7684\u6578\u5b78\u63cf\u8ff0\uff09\u548c\u9a57\u8b49\u5668\uff08\u63d0\u4f9b\u53ef\u7a3d\u6838\u7684\u8b49\u660e\u8b49\u660e\uff0c\u8b49\u660e AI \u6eff\u8db3\u76f8\u5c0d\u65bc\u4e16\u754c\u6a21\u578b\u7684\u5b89\u5168\u898f\u7bc4\uff09\u3002\u6211\u5011\u6982\u8ff0\u4e86\u5efa\u7acb\u9019\u4e09\u500b\u6838\u5fc3\u7d44\u6210\u4e2d\u6bcf\u4e00\u500b\u7684\u8a31\u591a\u65b9\u6cd5\uff0c\u63cf\u8ff0\u4e86\u4e3b\u8981\u7684\u6280\u8853\u6311\u6230\uff0c\u4e26\u63d0\u51fa\u4e86\u4e00\u4e9b\u53ef\u80fd\u7684\u89e3\u6c7a\u65b9\u6848\u3002\u6211\u5011\u4e5f\u4e3b\u5f35\u9019\u7a2e\u65b9\u6cd5\u5c0d\u65bc AI \u5b89\u5168\u7684\u5fc5\u8981\u6027\uff0c\u4ee5\u53ca\u4e3b\u8981\u66ff\u4ee3\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "author": "David \"davidad\" Dalrymple et.al.", "authors": "David \"davidad\" Dalrymple, Joar Skalse, Yoshua Bengio, Stuart Russell, Max Tegmark, Sanjit Seshia, Steve Omohundro, Christian Szegedy, Ben Goldhaber, Nora Ammann, Alessandro Abate, Joe Halpern, Clark Barrett, Ding Zhao, Tan Zhi-Xuan, Jeannette Wing, Joshua Tenenbaum", "id": "2405.06624v1", "paper_url": "http://arxiv.org/abs/2405.06624v1", "repo": "null"}}