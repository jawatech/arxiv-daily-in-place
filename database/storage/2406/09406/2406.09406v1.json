{"2406.09406": {"publish_time": "2024-06-13", "title": "4M-21: An Any-to-Any Vision Model for Tens of Tasks and Modalities", "paper_summary": "Current multimodal and multitask foundation models like 4M or UnifiedIO show\npromising results, but in practice their out-of-the-box abilities to accept\ndiverse inputs and perform diverse tasks are limited by the (usually rather\nsmall) number of modalities and tasks they are trained on. In this paper, we\nexpand upon the capabilities of them by training a single model on tens of\nhighly diverse modalities and by performing co-training on large-scale\nmultimodal datasets and text corpora. This includes training on several\nsemantic and geometric modalities, feature maps from recent state of the art\nmodels like DINOv2 and ImageBind, pseudo labels of specialist models like SAM\nand 4DHumans, and a range of new modalities that allow for novel ways to\ninteract with the model and steer the generation, for example image metadata or\ncolor palettes. A crucial step in this process is performing discrete\ntokenization on various modalities, whether they are image-like, neural network\nfeature maps, vectors, structured data like instance segmentation or human\nposes, or data that can be represented as text. Through this, we expand on the\nout-of-the-box capabilities of multimodal models and specifically show the\npossibility of training one model to solve at least 3x more tasks/modalities\nthan existing ones and doing so without a loss in performance. This enables\nmore fine-grained and controllable multimodal generation capabilities and\nallows us to study the distillation of models trained on diverse data and\nobjectives into a unified model. We successfully scale the training to a three\nbillion parameter model using tens of modalities and different datasets. The\nresulting models and training code are open sourced at 4m.epfl.ch.", "paper_summary_zh": "\u7576\u524d\u50cf 4M \u6216 UnifiedIO \u7684\u591a\u6a21\u614b\u548c\u591a\u4efb\u52d9\u57fa\u790e\u6a21\u578b\u5c55\u73fe\u51fa\u6709\u524d\u666f\u7684\u6210\u679c\uff0c\u4f46\u5be6\u969b\u4e0a\u5b83\u5011\u63a5\u53d7\u4e0d\u540c\u8f38\u5165\u548c\u57f7\u884c\u4e0d\u540c\u4efb\u52d9\u7684\u958b\u7bb1\u5373\u7528\u80fd\u529b\u53d7\u5230\u5b83\u5011\u53d7\u8a13\u7684\u6a21\u614b\u548c\u4efb\u52d9\uff08\u901a\u5e38\u76f8\u7576\u5c11\uff09\u6578\u91cf\u9650\u5236\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u900f\u904e\u5728\u6578\u5341\u7a2e\u9ad8\u5ea6\u4e0d\u540c\u7684\u6a21\u614b\u4e0a\u8a13\u7df4\u55ae\u4e00\u6a21\u578b\uff0c\u4e26\u5728\u5927\u898f\u6a21\u591a\u6a21\u614b\u8cc7\u6599\u96c6\u548c\u6587\u5b57\u8a9e\u6599\u5eab\u4e0a\u57f7\u884c\u5171\u540c\u8a13\u7df4\uff0c\u4f86\u64f4\u5c55\u5b83\u5011\u7684\u80fd\u529b\u3002\u9019\u5305\u62ec\u5728\u5e7e\u500b\u8a9e\u610f\u548c\u5e7e\u4f55\u6a21\u614b\u4e0a\u9032\u884c\u8a13\u7df4\uff0c\u4f8b\u5982\u4f86\u81ea\u6700\u8fd1\u7684 DINOv2 \u548c ImageBind \u7b49\u6700\u65b0\u6a21\u578b\u7684\u7279\u5fb5\u5716\uff0c\u4f86\u81ea SAM \u548c 4DHumans \u7b49\u5c08\u696d\u6a21\u578b\u7684\u507d\u6a19\u7c64\uff0c\u4ee5\u53ca\u4e00\u7cfb\u5217\u5141\u8a31\u4ee5\u65b0\u7a4e\u65b9\u5f0f\u8207\u6a21\u578b\u4e92\u52d5\u4e26\u5f15\u5c0e\u751f\u6210\u7684\u6a21\u614b\uff0c\u4f8b\u5982\u5f71\u50cf\u5143\u8cc7\u6599\u6216\u8abf\u8272\u76e4\u3002\u6b64\u904e\u7a0b\u4e2d\u7684\u4e00\u500b\u95dc\u9375\u6b65\u9a5f\u662f\u5728\u5404\u7a2e\u6a21\u614b\u4e0a\u57f7\u884c\u96e2\u6563\u6a19\u8a18\u5316\uff0c\u7121\u8ad6\u5b83\u5011\u662f\u5f71\u50cf\u985e\u3001\u795e\u7d93\u7db2\u8def\u7279\u5fb5\u5716\u3001\u5411\u91cf\u3001\u7d50\u69cb\u5316\u8cc7\u6599\uff08\u4f8b\u5982\u5be6\u4f8b\u5206\u5272\u6216\u4eba\u9ad4\u59ff\u52e2\uff09\uff0c\u9084\u662f\u53ef\u4ee5\u8868\u793a\u70ba\u6587\u5b57\u7684\u8cc7\u6599\u3002\u900f\u904e\u6b64\u65b9\u5f0f\uff0c\u6211\u5011\u64f4\u5c55\u4e86\u591a\u6a21\u614b\u6a21\u578b\u7684\u958b\u7bb1\u5373\u7528\u80fd\u529b\uff0c\u4e26\u7279\u5225\u5c55\u793a\u4e86\u8a13\u7df4\u4e00\u500b\u6a21\u578b\u4ee5\u89e3\u6c7a\u81f3\u5c11\u6bd4\u73fe\u6709\u6a21\u578b\u591a 3 \u500d\u7684\u4efb\u52d9/\u6a21\u614b\u7684\u53ef\u80fd\u6027\uff0c\u800c\u4e14\u5728\u4e0d\u640d\u5931\u6548\u80fd\u7684\u60c5\u6cc1\u4e0b\u505a\u5230\u9019\u4e00\u9ede\u3002\u9019\u80fd\u5be6\u73fe\u66f4\u7d30\u7dfb\u4e14\u53ef\u63a7\u7684\u591a\u6a21\u614b\u751f\u6210\u80fd\u529b\uff0c\u4e26\u5141\u8a31\u6211\u5011\u7814\u7a76\u5c07\u5728\u4e0d\u540c\u8cc7\u6599\u548c\u76ee\u6a19\u4e0a\u8a13\u7df4\u7684\u6a21\u578b\u8403\u53d6\u5230\u7d71\u4e00\u6a21\u578b\u4e2d\u3002\u6211\u5011\u6210\u529f\u5730\u5c07\u8a13\u7df4\u64f4\u5c55\u5230\u4f7f\u7528\u6578\u5341\u7a2e\u6a21\u614b\u548c\u4e0d\u540c\u8cc7\u6599\u96c6\u7684\u4e09\u5341\u5104\u53c3\u6578\u6a21\u578b\u3002\u7522\u751f\u7684\u6a21\u578b\u548c\u8a13\u7df4\u7a0b\u5f0f\u78bc\u5728 4m.epfl.ch \u958b\u6e90\u3002", "author": "Roman Bachmann et.al.", "authors": "Roman Bachmann, O\u011fuzhan Fatih Kar, David Mizrahi, Ali Garjani, Mingfei Gao, David Griffiths, Jiaming Hu, Afshin Dehghan, Amir Zamir", "id": "2406.09406v1", "paper_url": "http://arxiv.org/abs/2406.09406v1", "repo": "null"}}