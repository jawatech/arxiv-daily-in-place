{"2405.10725": {"publish_time": "2024-05-17", "title": "INDUS: Effective and Efficient Language Models for Scientific Applications", "paper_summary": "Large language models (LLMs) trained on general domain corpora showed\nremarkable results on natural language processing (NLP) tasks. However,\nprevious research demonstrated LLMs trained using domain-focused corpora\nperform better on specialized tasks. Inspired by this pivotal insight, we\ndeveloped INDUS, a comprehensive suite of LLMs tailored for the Earth science,\nbiology, physics, heliophysics, planetary sciences and astrophysics domains and\ntrained using curated scientific corpora drawn from diverse data sources. The\nsuite of models include: (1) an encoder model trained using domain-specific\nvocabulary and corpora to address natural language understanding tasks, (2) a\ncontrastive-learning-based general text embedding model trained using a diverse\nset of datasets drawn from multiple sources to address information retrieval\ntasks and (3) smaller versions of these models created using knowledge\ndistillation techniques to address applications which have latency or resource\nconstraints. We also created three new scientific benchmark datasets namely,\nCLIMATE-CHANGE-NER (entity-recognition), NASA-QA (extractive QA) and NASA-IR\n(IR) to accelerate research in these multi-disciplinary fields. Finally, we\nshow that our models outperform both general-purpose encoders (RoBERTa) and\nexisting domain-specific encoders (SciBERT) on these new tasks as well as\nexisting benchmark tasks in the domains of interest.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u4e00\u822c\u9818\u57df\u8a9e\u6599\u5eab\u4e0a\u8a13\u7df4\uff0c\u986f\u793a\u51fa\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u4efb\u52d9\u7684\u986f\u8457\u6210\u679c\u3002\u7136\u800c\uff0c\u5148\u524d\u7684\u7814\u7a76\u8868\u660e\uff0c\u4f7f\u7528\u9818\u57df\u805a\u7126\u8a9e\u6599\u5eab\u8a13\u7df4\u7684 LLM \u5728\u7279\u6b8a\u4efb\u52d9\u4e0a\u7684\u8868\u73fe\u66f4\u597d\u3002\u53d7\u5230\u9019\u9805\u95dc\u9375\u898b\u89e3\u7684\u555f\u767c\uff0c\u6211\u5011\u958b\u767c\u4e86 INDUS\uff0c\u9019\u662f\u4e00\u5957\u91dd\u5c0d\u5730\u7403\u79d1\u5b78\u3001\u751f\u7269\u5b78\u3001\u7269\u7406\u5b78\u3001\u592a\u967d\u7269\u7406\u5b78\u3001\u884c\u661f\u79d1\u5b78\u548c\u5929\u9ad4\u7269\u7406\u5b78\u9818\u57df\u91cf\u8eab\u6253\u9020\u7684 LLM\uff0c\u4e26\u4f7f\u7528\u5f9e\u5404\u7a2e\u6578\u64da\u4f86\u6e90\u4e2d\u63d0\u53d6\u7684\u7cbe\u9078\u79d1\u5b78\u8a9e\u6599\u5eab\u9032\u884c\u8a13\u7df4\u3002\u9019\u5957\u6a21\u578b\u5305\u62ec\uff1a(1) \u4f7f\u7528\u7279\u5b9a\u9818\u57df\u8a5e\u5f59\u548c\u8a9e\u6599\u5eab\u8a13\u7df4\u7684\u7de8\u78bc\u5668\u6a21\u578b\uff0c\u4ee5\u89e3\u6c7a\u81ea\u7136\u8a9e\u8a00\u7406\u89e3\u4efb\u52d9\uff0c(2) \u4f7f\u7528\u5f9e\u591a\u500b\u4f86\u6e90\u4e2d\u63d0\u53d6\u7684\u5404\u7a2e\u8cc7\u6599\u96c6\u8a13\u7df4\u7684\u5c0d\u6bd4\u5b78\u7fd2\u57fa\u790e\u4e00\u822c\u6587\u5b57\u5d4c\u5165\u6a21\u578b\uff0c\u4ee5\u89e3\u6c7a\u8cc7\u8a0a\u6aa2\u7d22\u4efb\u52d9\uff0c\u4ee5\u53ca (3) \u4f7f\u7528\u77e5\u8b58\u84b8\u993e\u6280\u8853\u5efa\u7acb\u7684\u9019\u4e9b\u6a21\u578b\u7684\u8f03\u5c0f\u7248\u672c\uff0c\u4ee5\u89e3\u6c7a\u6709\u5ef6\u9072\u6216\u8cc7\u6e90\u9650\u5236\u7684\u61c9\u7528\u7a0b\u5f0f\u3002\u6211\u5011\u9084\u5efa\u7acb\u4e86\u4e09\u500b\u65b0\u7684\u79d1\u5b78\u57fa\u6e96\u8cc7\u6599\u96c6\uff0c\u5373 CLIMATE-CHANGE-NER (\u5be6\u9ad4\u8b58\u5225)\u3001NASA-QA (\u8403\u53d6\u5f0f\u554f\u7b54) \u548c NASA-IR (IR)\uff0c\u4ee5\u52a0\u901f\u9019\u4e9b\u591a\u5b78\u79d1\u9818\u57df\u7684\u7814\u7a76\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5c55\u793a\u6211\u5011\u7684\u6a21\u578b\u5728\u9019\u4e9b\u65b0\u4efb\u52d9\u4ee5\u53ca\u611f\u8208\u8da3\u9818\u57df\u4e2d\u7684\u73fe\u6709\u57fa\u6e96\u4efb\u52d9\u4e0a\uff0c\u90fd\u512a\u65bc\u901a\u7528\u7de8\u78bc\u5668 (RoBERTa) \u548c\u73fe\u6709\u7684\u7279\u5b9a\u9818\u57df\u7de8\u78bc\u5668 (SciBERT)\u3002", "author": "Bishwaranjan Bhattacharjee et.al.", "authors": "Bishwaranjan Bhattacharjee, Aashka Trivedi, Masayasu Muraoka, Muthukumaran Ramasubramanian, Takuma Udagawa, Iksha Gurung, Rong Zhang, Bharath Dandala, Rahul Ramachandran, Manil Maskey, Kayleen Bugbee, Mike Little, Elizabeth Fancher, Lauren Sanders, Sylvain Costes, Sergi Blanco-Cuaresma, Kelly Lockhart, Thomas Allen, Felix Grazes, Megan Ansdel, Alberto Accomazzi, Yousef El-Kurdi, Davis Wertheimer, Birgit Pfitzmann, Cesar Berrospi Ramis, Michele Dolfi, Rafael Teixeira de Lima, Panos Vegenas, S. Karthik Mukkavilli, Peter Staar, Sanaz Vahidinia, Ryan McGranaghan, Armin Mehrabian, Tsendgar Lee", "id": "2405.10725v1", "paper_url": "http://arxiv.org/abs/2405.10725v1", "repo": "null"}}