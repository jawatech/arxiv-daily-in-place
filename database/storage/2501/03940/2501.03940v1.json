{"2501.03940": {"publish_time": "2025-01-07", "title": "Not all tokens are created equal: Perplexity Attention Weighted Networks for AI generated text detection", "paper_summary": "The rapid advancement in large language models (LLMs) has significantly\nenhanced their ability to generate coherent and contextually relevant text,\nraising concerns about the misuse of AI-generated content and making it\ncritical to detect it. However, the task remains challenging, particularly in\nunseen domains or with unfamiliar LLMs. Leveraging LLM next-token distribution\noutputs offers a theoretically appealing approach for detection, as they\nencapsulate insights from the models' extensive pre-training on diverse\ncorpora. Despite its promise, zero-shot methods that attempt to operationalize\nthese outputs have met with limited success. We hypothesize that one of the\nproblems is that they use the mean to aggregate next-token distribution metrics\nacross tokens, when some tokens are naturally easier or harder to predict and\nshould be weighted differently. Based on this idea, we propose the Perplexity\nAttention Weighted Network (PAWN), which uses the last hidden states of the LLM\nand positions to weight the sum of a series of features based on metrics from\nthe next-token distribution across the sequence length. Although not zero-shot,\nour method allows us to cache the last hidden states and next-token\ndistribution metrics on disk, greatly reducing the training resource\nrequirements. PAWN shows competitive and even better performance\nin-distribution than the strongest baselines (fine-tuned LMs) with a fraction\nof their trainable parameters. Our model also generalizes better to unseen\ndomains and source models, with smaller variability in the decision boundary\nacross distribution shifts. It is also more robust to adversarial attacks, and\nif the backbone has multilingual capabilities, it presents decent\ngeneralization to languages not seen during supervised training, with LLaMA3-1B\nreaching a mean macro-averaged F1 score of 81.46% in cross-validation with nine\nlanguages.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5feb\u901f\u9032\u6b65\u5927\u5e45\u63d0\u5347\u4e86\u5b83\u5011\u751f\u6210\u9023\u8cab\u4e14\u8207\u8a9e\u5883\u76f8\u95dc\u6587\u5b57\u7684\u80fd\u529b\uff0c\u5f15\u767c\u4e86\u5c0d AI \u751f\u6210\u7684\u5167\u5bb9\u88ab\u6feb\u7528\u7684\u64d4\u6182\uff0c\u4e26\u4f7f\u5176\u5075\u6e2c\u8b8a\u5f97\u81f3\u95dc\u91cd\u8981\u3002\u7136\u800c\uff0c\u9019\u9805\u4efb\u52d9\u4ecd\u7136\u5177\u6709\u6311\u6230\u6027\uff0c\u5c24\u5176\u662f\u5728\u672a\u898b\u904e\u7684\u9818\u57df\u6216\u4e0d\u719f\u6089\u7684 LLM \u4e2d\u3002\u5229\u7528 LLM \u4e0b\u4e00\u500b\u4ee3\u5e63\u5206\u4f48\u8f38\u51fa\u63d0\u4f9b\u4e86\u4e00\u500b\u7406\u8ad6\u4e0a\u5c0d\u5075\u6e2c\u6709\u5438\u5f15\u529b\u7684\u65b9\u6cd5\uff0c\u56e0\u70ba\u5b83\u5011\u6982\u62ec\u4e86\u6a21\u578b\u5728\u5404\u7a2e\u8a9e\u6599\u5eab\u4e0a\u9032\u884c\u5ee3\u6cdb\u9810\u8a13\u7df4\u7684\u898b\u89e3\u3002\u5118\u7ba1\u6709\u9019\u6a23\u7684\u627f\u8afe\uff0c\u4f46\u8a66\u5716\u5c07\u9019\u4e9b\u8f38\u51fa\u64cd\u4f5c\u5316\u7684\u96f6\u6b21\u5b78\u7fd2\u65b9\u6cd5\u537b\u53ea\u7372\u5f97\u4e86\u6709\u9650\u7684\u6210\u529f\u3002\u6211\u5011\u5047\u8a2d\u5176\u4e2d\u4e00\u500b\u554f\u984c\u662f\u5b83\u5011\u4f7f\u7528\u5e73\u5747\u503c\u4f86\u5f59\u7e3d\u4ee3\u5e63\u7684\u4e0b\u4e00\u4ee3\u5e63\u5206\u4f48\u6307\u6a19\uff0c\u800c\u6709\u4e9b\u4ee3\u5e63\u5728\u9810\u6e2c\u4e0a\u81ea\u7136\u6bd4\u8f03\u5bb9\u6613\u6216\u56f0\u96e3\uff0c\u4e26\u4e14\u61c9\u8a72\u8ce6\u4e88\u4e0d\u540c\u7684\u6b0a\u91cd\u3002\u57fa\u65bc\u9019\u500b\u60f3\u6cd5\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u56f0\u60d1\u5ea6\u6ce8\u610f\u529b\u52a0\u6b0a\u7db2\u8def (PAWN)\uff0c\u5b83\u4f7f\u7528 LLM \u7684\u6700\u5f8c\u96b1\u85cf\u72c0\u614b\u548c\u4f4d\u7f6e\u4f86\u6839\u64da\u5e8f\u5217\u9577\u5ea6\u4e2d\u4e0b\u4e00\u4ee3\u5e63\u5206\u4f48\u7684\u6307\u6a19\u52a0\u6b0a\u4e00\u7cfb\u5217\u7279\u5fb5\u7684\u7e3d\u548c\u3002\u5118\u7ba1\u4e0d\u662f\u96f6\u6b21\u5b78\u7fd2\uff0c\u4f46\u6211\u5011\u7684\u9019\u7a2e\u65b9\u6cd5\u5141\u8a31\u6211\u5011\u5c07\u6700\u5f8c\u7684\u96b1\u85cf\u72c0\u614b\u548c\u4e0b\u4e00\u4ee3\u5e63\u5206\u4f48\u6307\u6a19\u5feb\u53d6\u5230\u78c1\u789f\u4e2d\uff0c\u5927\u5e45\u6e1b\u5c11\u8a13\u7df4\u8cc7\u6e90\u9700\u6c42\u3002PAWN \u5728\u5206\u4f48\u4e2d\u986f\u793a\u51fa\u6bd4\u6700\u5f37\u7684\u57fa\u6e96\uff08\u5fae\u8abf\u8a9e\u8a00\u6a21\u578b\uff09\u66f4\u5177\u7af6\u722d\u529b\u751a\u81f3\u66f4\u597d\u7684\u6548\u80fd\uff0c\u800c\u5176\u53ef\u8a13\u7df4\u53c3\u6578\u53ea\u4f54\u5b83\u5011\u7684\u4e00\u5c0f\u90e8\u5206\u3002\u6211\u5011\u7684\u6a21\u578b\u5c0d\u65bc\u672a\u898b\u904e\u7684\u9818\u57df\u548c\u539f\u59cb\u6a21\u578b\u4e5f\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u5206\u4f48\u8f49\u79fb\u4e2d\u6c7a\u7b56\u908a\u754c\u7684\u8b8a\u7570\u8f03\u5c0f\u3002\u5b83\u5c0d\u5c0d\u6297\u6027\u653b\u64ca\u4e5f\u66f4\u5f37\u5065\uff0c\u800c\u4e14\u5982\u679c\u4e3b\u5e79\u5177\u6709\u591a\u8a9e\u8a00\u80fd\u529b\uff0c\u5b83\u6703\u5c0d\u5728\u76e3\u7763\u8a13\u7df4\u671f\u9593\u672a\u898b\u904e\u7684\u8a9e\u8a00\u5448\u73fe\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5176\u4e2d LLaMA3-1B \u5728\u8207\u4e5d\u7a2e\u8a9e\u8a00\u7684\u4ea4\u53c9\u9a57\u8b49\u4e2d\u9054\u5230\u5e73\u5747\u5de8\u89c0 F1 \u5206\u6578 81.46%\u3002", "author": "Pablo Miralles-Gonz\u00e1lez et.al.", "authors": "Pablo Miralles-Gonz\u00e1lez, Javier Huertas-Tato, Alejandro Mart\u00edn, David Camacho", "id": "2501.03940v1", "paper_url": "http://arxiv.org/abs/2501.03940v1", "repo": "null"}}