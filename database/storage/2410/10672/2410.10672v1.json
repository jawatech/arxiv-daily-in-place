{"2410.10672": {"publish_time": "2024-10-14", "title": "Large Language Model Evaluation via Matrix Nuclear-Norm", "paper_summary": "As large language models (LLMs) continue to evolve, efficient evaluation\nmetrics are vital for assessing their ability to compress information and\nreduce redundancy. While traditional metrics like Matrix Entropy offer valuable\ninsights, they are computationally intensive for large-scale models due to\ntheir \\( O(n^3) \\) time complexity with Singular Value Decomposition (SVD). To\nmitigate this issue, we introduce the Matrix Nuclear-Norm, which not only\nserves as a metric to quantify the data compression proficiency of LLM but also\nprovides a convex approximation of matrix rank to capture both predictive\ndiscriminability and diversity. By employing the \\( L_{1,2}\\text{-norm} \\) to\nfurther approximate the nuclear norm, we can effectively assess the model's\ninformation compression capabilities. This approach reduces the time complexity\nto \\( O(n^2) \\) and eliminates the need for SVD computation. Consequently, the\nMatrix Nuclear-Norm achieves speeds 8 to 24 times faster than Matrix Entropy\nfor the CEREBRAS-GPT model as sizes increase from 111M to 6.7B. This\nperformance gap becomes more pronounced with larger models, as validated in\ntests with other models like Pythia. Additionally, evaluations on benchmarks\nand model responses confirm that our proposed Matrix Nuclear-Norm is a\nreliable, scalable, and efficient tool for assessing LLMs' performance,\nstriking a balance between accuracy and computational efficiency. The code is\navailable at https://github.com/MLGroupJLU/MatrixNuclearNorm.", "paper_summary_zh": "\u96a8\u8457\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6301\u7e8c\u6f14\u9032\uff0c\u6709\u6548\u7387\u7684\u8a55\u4f30\u6307\u6a19\u5c0d\u65bc\u8a55\u4f30\u5b83\u5011\u58d3\u7e2e\u8cc7\u8a0a\u8207\u964d\u4f4e\u5197\u9918\u7684\u80fd\u529b\u81f3\u95dc\u91cd\u8981\u3002\u96d6\u7136\u50cf\u662f\u77e9\u9663\u71b5\u9019\u985e\u7684\u50b3\u7d71\u6307\u6a19\u63d0\u4f9b\u4e86\u6709\u50f9\u503c\u7684\u898b\u89e3\uff0c\u4f46\u7531\u65bc\u5b83\u5011\u8207\u5947\u7570\u503c\u5206\u89e3 (SVD) \u7684\u6642\u9593\u8907\u96dc\u5ea6\u70ba \\( O(n^3) \\)\uff0c\u5c0d\u65bc\u5927\u578b\u6a21\u578b\u800c\u8a00\u5728\u8a08\u7b97\u4e0a\u76f8\u7576\u5bc6\u96c6\u3002\u70ba\u4e86\u6e1b\u8f15\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86\u77e9\u9663\u6838\u7bc4\u6578\uff0c\u5b83\u4e0d\u50c5\u53ef\u7528\u4f5c\u91cf\u5316 LLM \u8cc7\u6599\u58d3\u7e2e\u80fd\u529b\u7684\u6307\u6a19\uff0c\u4e5f\u63d0\u4f9b\u4e86\u77e9\u9663\u79e9\u7684\u51f8\u8fd1\u4f3c\uff0c\u4ee5\u6355\u6349\u9810\u6e2c\u5224\u5225\u6027\u548c\u591a\u6a23\u6027\u3002\u85c9\u7531\u63a1\u7528 \\( L_{1,2}\\text{-norm} \\) \u4f86\u9032\u4e00\u6b65\u8fd1\u4f3c\u6838\u7bc4\u6578\uff0c\u6211\u5011\u53ef\u4ee5\u6709\u6548\u5730\u8a55\u4f30\u6a21\u578b\u7684\u8cc7\u8a0a\u58d3\u7e2e\u80fd\u529b\u3002\u9019\u7a2e\u65b9\u6cd5\u5c07\u6642\u9593\u8907\u96dc\u5ea6\u964d\u4f4e\u5230 \\( O(n^2) \\)\uff0c\u4e26\u6d88\u9664\u4e86\u5c0d SVD \u8a08\u7b97\u7684\u9700\u6c42\u3002\u56e0\u6b64\uff0c\u96a8\u8457\u6a21\u578b\u5927\u5c0f\u5f9e 111M \u589e\u52a0\u5230 6.7B\uff0c\u77e9\u9663\u6838\u7bc4\u6578\u7684\u901f\u5ea6\u6bd4\u77e9\u9663\u71b5\u5feb\u4e86 8 \u5230 24 \u500d\u3002\u5728\u4f7f\u7528\u5176\u4ed6\u6a21\u578b\uff08\u4f8b\u5982 Pythia\uff09\u9032\u884c\u6e2c\u8a66\u6642\uff0c\u9019\u7a2e\u6548\u80fd\u5dee\u8ddd\u5728\u8f03\u5927\u7684\u6a21\u578b\u4e2d\u8b8a\u5f97\u66f4\u52a0\u660e\u986f\u3002\u6b64\u5916\uff0c\u91dd\u5c0d\u57fa\u6e96\u548c\u6a21\u578b\u56de\u61c9\u7684\u8a55\u4f30\u8b49\u5be6\uff0c\u6211\u5011\u63d0\u51fa\u7684\u77e9\u9663\u6838\u7bc4\u6578\u662f\u4e00\u7a2e\u53ef\u9760\u3001\u53ef\u64f4\u5145\u4e14\u6709\u6548\u7387\u7684\u5de5\u5177\uff0c\u7528\u65bc\u8a55\u4f30 LLM \u7684\u6548\u80fd\uff0c\u5728\u6e96\u78ba\u6027\u548c\u8a08\u7b97\u6548\u7387\u4e4b\u9593\u53d6\u5f97\u5e73\u8861\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/MLGroupJLU/MatrixNuclearNorm \u53d6\u5f97\u3002", "author": "Yahan Li et.al.", "authors": "Yahan Li, Tingyu Xia, Yi Chang, Yuan Wu", "id": "2410.10672v1", "paper_url": "http://arxiv.org/abs/2410.10672v1", "repo": "null"}}