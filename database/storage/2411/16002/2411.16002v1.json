{"2411.16002": {"publish_time": "2024-11-24", "title": "Exploring Performance Contrasts in TableQA: Step-by-Step Reasoning Boosts Bigger Language Models, Limits Smaller Language Models", "paper_summary": "This paper proposes a detailed prompting flow, termed Table-Logic, to\ninvestigate the performance contrasts between bigger and smaller language\nmodels (LMs) utilizing step-by-step reasoning methods in the TableQA task. The\nmethod processes tasks by sequentially identifying critical columns and rows\ngiven question and table with its structure, determining necessary\naggregations, calculations, or comparisons, and finally inferring the results\nto generate a precise prediction. By deploying this method, we observe a 7.8%\naccuracy improvement in bigger LMs like Llama-3-70B compared to the vanilla on\nHybridQA, while smaller LMs like Llama-2-7B shows an 11% performance decline.\nWe empirically investigate the potential causes of performance contrasts by\nexploring the capabilities of bigger and smaller LMs from various dimensions in\nTableQA task. Our findings highlight the limitations of the step-by-step\nreasoning method in small models and provide potential insights for making\nimprovements.", "paper_summary_zh": "\u9019\u7bc7\u8ad6\u6587\u63d0\u51fa\u4e86\u8a73\u76e1\u7684\u63d0\u793a\u6d41\u7a0b\uff0c\u7a31\u70ba Table-Logic\uff0c\u4ee5\u63a2\u8a0e\u5728 TableQA \u4efb\u52d9\u4e2d\u5229\u7528\u9010\u6b65\u63a8\u7406\u65b9\u6cd5\u7684\u5927\u578b\u548c\u5c0f\u578b\u8a9e\u8a00\u6a21\u578b (LM) \u4e4b\u9593\u7684\u6548\u80fd\u5c0d\u6bd4\u3002\u6b64\u65b9\u6cd5\u900f\u904e\u6309\u9806\u5e8f\u8b58\u5225\u95dc\u9375\u6b04\u4f4d\u548c\u5217\uff08\u7d66\u5b9a\u554f\u984c\u548c\u8868\u683c\u53ca\u5176\u7d50\u69cb\uff09\u3001\u6c7a\u5b9a\u5fc5\u8981\u7684\u5f59\u7e3d\u3001\u8a08\u7b97\u6216\u6bd4\u8f03\uff0c\u6700\u5f8c\u63a8\u8ad6\u7d50\u679c\u4ee5\u7522\u751f\u7cbe\u78ba\u9810\u6e2c\uff0c\u4f86\u8655\u7406\u4efb\u52d9\u3002\u900f\u904e\u90e8\u7f72\u6b64\u65b9\u6cd5\uff0c\u6211\u5011\u89c0\u5bdf\u5230 Llama-3-70B \u7b49\u5927\u578b LM \u5728 HybridQA \u4e0a\u7684\u6e96\u78ba\u5ea6\u63d0\u5347\u4e86 7.8%\uff0c\u800c Llama-2-7B \u7b49\u5c0f\u578b LM \u5247\u986f\u793a\u51fa\u6548\u80fd\u4e0b\u964d 11%\u3002\u6211\u5011\u900f\u904e\u63a2\u7d22\u5927\u578b\u548c\u5c0f\u578b LM \u5728 TableQA \u4efb\u52d9\u4e2d\u5404\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5be6\u8b49\u8abf\u67e5\u6548\u80fd\u5c0d\u6bd4\u7684\u6f5b\u5728\u539f\u56e0\u3002\u6211\u5011\u7684\u767c\u73fe\u7a81\u986f\u4e86\u5c0f\u578b\u6a21\u578b\u4e2d\u9010\u6b65\u63a8\u7406\u65b9\u6cd5\u7684\u9650\u5236\uff0c\u4e26\u63d0\u4f9b\u6f5b\u5728\u898b\u89e3\u4ee5\u9032\u884c\u6539\u9032\u3002", "author": "Haoyan Yang et.al.", "authors": "Haoyan Yang, Yixuan Wang, Keyue Tong, Hongjin Zhu, Yuanxin Zhang", "id": "2411.16002v1", "paper_url": "http://arxiv.org/abs/2411.16002v1", "repo": "null"}}