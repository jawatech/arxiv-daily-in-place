{"2410.12492": {"publish_time": "2024-10-16", "title": "End-to-end Planner Training for Language Modeling", "paper_summary": "Through end-to-end training to predict the next token, LLMs have become\nvaluable tools for various tasks. Enhancing their core training in language\nmodeling can improve numerous downstream applications. A successful approach to\nenhance language modeling uses a separate planning module to predict abstract\nlabels of future sentences and conditions the LM on these predictions. However,\nthis method is non-differentiable, preventing joint end-to-end tuning of the\nplanner with the LM. We propose an effective method to improve this approach by\nenabling joint fine-tuning of the planner and the LM. We show that a naive way\nof approximating the gradient of selecting a label via the straight-through\nestimator is not effective. Instead, we propose to use the predicted label\nprobabilities as mixing weights to condition the LM on a weighted average of\nlabel embeddings in a differentiable manner. This not only enables joint\nfine-tuning of the planner and the LM, but also allows the LM to draw on the\nfull label distribution predicted by the planner, retaining more information.\nOur experimental results show consistent improvements in perplexity.", "paper_summary_zh": "\u900f\u904e\u7aef\u5c0d\u7aef\u8a13\u7df4\u4f86\u9810\u6e2c\u4e0b\u4e00\u500b\u7b26\u865f\uff0cLLM \u5df2\u6210\u70ba\u5404\u7a2e\u4efb\u52d9\u7684\u5bf6\u8cb4\u5de5\u5177\u3002\u589e\u5f37\u5176\u5728\u8a9e\u8a00\u6a21\u578b\u4e2d\u7684\u6838\u5fc3\u8a13\u7df4\u53ef\u4ee5\u6539\u5584\u8a31\u591a\u4e0b\u6e38\u61c9\u7528\u7a0b\u5f0f\u3002\u589e\u5f37\u8a9e\u8a00\u6a21\u578b\u7684\u4e00\u500b\u6210\u529f\u65b9\u6cd5\u662f\u4f7f\u7528\u4e00\u500b\u7368\u7acb\u7684\u898f\u5283\u6a21\u7d44\u4f86\u9810\u6e2c\u672a\u4f86\u53e5\u5b50\u7684\u62bd\u8c61\u6a19\u7c64\uff0c\u4e26\u6839\u64da\u9019\u4e9b\u9810\u6e2c\u5c0d LM \u9032\u884c\u689d\u4ef6\u5316\u3002\u7136\u800c\uff0c\u9019\u7a2e\u65b9\u6cd5\u662f\u4e0d\u53ef\u5fae\u5206\u7684\uff0c\u963b\u6b62\u4e86\u898f\u5283\u5668\u8207 LM \u7684\u806f\u5408\u7aef\u5c0d\u7aef\u8abf\u6574\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u6709\u6548\u7684\u65b9\u6cd5\u4f86\u6539\u5584\u9019\u7a2e\u65b9\u6cd5\uff0c\u65b9\u6cd5\u662f\u8b93\u898f\u5283\u5668\u548c LM \u80fd\u5920\u9032\u884c\u806f\u5408\u5fae\u8abf\u3002\u6211\u5011\u8868\u660e\uff0c\u901a\u904e\u76f4\u901a\u4f30\u8a08\u5668\u4f86\u8fd1\u4f3c\u9078\u64c7\u6a19\u7c64\u7684\u68af\u5ea6\u662f\u4e00\u7a2e\u5929\u771f\u7684\u65b9\u5f0f\uff0c\u9019\u7a2e\u65b9\u5f0f\u662f\u7121\u6548\u7684\u3002\u76f8\u53cd\uff0c\u6211\u5011\u5efa\u8b70\u4f7f\u7528\u9810\u6e2c\u7684\u6a19\u7c64\u6a5f\u7387\u4f5c\u70ba\u6df7\u5408\u6b0a\u91cd\uff0c\u4ee5\u53ef\u5fae\u5206\u7684\u65b9\u5f0f\u5c0d LM \u9032\u884c\u689d\u4ef6\u5316\uff0c\u4f7f\u5176\u6839\u64da\u6a19\u7c64\u5d4c\u5165\u7684\u52a0\u6b0a\u5e73\u5747\u503c\u9032\u884c\u689d\u4ef6\u5316\u3002\u9019\u4e0d\u50c5\u80fd\u8b93\u898f\u5283\u5668\u548c LM \u9032\u884c\u806f\u5408\u5fae\u8abf\uff0c\u9084\u80fd\u8b93 LM \u5229\u7528\u898f\u5283\u5668\u9810\u6e2c\u7684\u5b8c\u6574\u6a19\u7c64\u5206\u4f48\uff0c\u5f9e\u800c\u4fdd\u7559\u66f4\u591a\u8cc7\u8a0a\u3002\u6211\u5011\u7684\u5be6\u9a57\u7d50\u679c\u986f\u793a\u56f0\u60d1\u5ea6\u6301\u7e8c\u6539\u5584\u3002", "author": "Nathan Cornille et.al.", "authors": "Nathan Cornille, Florian Mai, Jingyuan Sun, Marie-Francine Moens", "id": "2410.12492v1", "paper_url": "http://arxiv.org/abs/2410.12492v1", "repo": "null"}}