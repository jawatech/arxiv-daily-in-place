{"2407.06172": {"publish_time": "2024-07-08", "title": "On Speeding Up Language Model Evaluation", "paper_summary": "Large language models (LLMs) currently dominate the field of natural language\nprocessing (NLP), representing the state-of-the-art across a diverse array of\ntasks. Developing a model of this nature, from training to inference, requires\nmaking numerous decisions which define a combinatorial search problem. For\nexample, selecting the optimal pre-trained LLM, prompt, or hyperparameters to\nattain the best performance for a task often requires evaluating multiple\ncandidates on an entire test set. This exhaustive evaluation can be\ntime-consuming and costly, as both inference and metric computation with LLMs\nare resource-intensive. In this paper, we address the challenge of identifying\nthe best method within a limited budget for evaluating methods on test\nexamples. By leveraging the well-studied multi-armed bandit framework, which\nsequentially selects the next method-example pair to evaluate, our approach,\ncombining multi-armed bandit algorithms with low-rank factorization,\nsignificantly reduces the required resources. Experiments show that our\nalgorithms can identify the top-performing method using only 5-15\\% of the\ntypically needed resources, resulting in an 85-95\\% reduction in cost.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u76ee\u524d\u4e3b\u5c0e\u8457\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u9818\u57df\uff0c\u4ee3\u8868\u8457\u5404\u7a2e\u4efb\u52d9\u7684\u6700\u65b0\u6280\u8853\u3002\u958b\u767c\u9019\u7a2e\u6027\u8cea\u7684\u6a21\u578b\uff0c\u5f9e\u8a13\u7df4\u5230\u63a8\u7406\uff0c\u90fd\u9700\u8981\u505a\u51fa\u8a31\u591a\u5b9a\u7fa9\u7d44\u5408\u641c\u5c0b\u554f\u984c\u7684\u6c7a\u7b56\u3002\u4f8b\u5982\uff0c\u9078\u64c7\u6700\u4f73\u7684\u9810\u8a13\u7df4 LLM\u3001\u63d0\u793a\u6216\u8d85\u53c3\u6578\u4ee5\u7372\u5f97\u4efb\u52d9\u7684\u6700\u4f73\u6548\u80fd\uff0c\u901a\u5e38\u9700\u8981\u5728\u6574\u500b\u6e2c\u8a66\u96c6\u4e2d\u8a55\u4f30\u591a\u500b\u5019\u9078\u8005\u3002\u9019\u7a2e\u8a73\u76e1\u7684\u8a55\u4f30\u53ef\u80fd\u6703\u8017\u6642\u4e14\u6602\u8cb4\uff0c\u56e0\u70ba\u4f7f\u7528 LLM \u9032\u884c\u63a8\u7406\u548c\u6307\u6a19\u8a08\u7b97\u90fd\u662f\u8cc7\u6e90\u5bc6\u96c6\u578b\u7684\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u5728\u6709\u9650\u9810\u7b97\u5167\u627e\u51fa\u6700\u4f73\u65b9\u6cd5\u4f86\u8a55\u4f30\u6e2c\u8a66\u7bc4\u4f8b\u65b9\u6cd5\u7684\u6311\u6230\u3002\u900f\u904e\u5229\u7528\u7814\u7a76\u5b8c\u5584\u7684\u591a\u91cd\u62c9\u9738\u6a5f\u67b6\u69cb\uff0c\u5b83\u6703\u4f9d\u5e8f\u9078\u64c7\u4e0b\u4e00\u500b\u8981\u8a55\u4f30\u7684\u65b9\u6cd5\u7bc4\u4f8b\u914d\u5c0d\uff0c\u6211\u5011\u7684\u505a\u6cd5\u7d50\u5408\u4e86\u591a\u91cd\u62c9\u9738\u6a5f\u6f14\u7b97\u6cd5\u548c\u4f4e\u968e\u5206\u89e3\uff0c\u5927\u5e45\u6e1b\u5c11\u4e86\u6240\u9700\u7684\u8cc7\u6e90\u3002\u5be6\u9a57\u986f\u793a\uff0c\u6211\u5011\u7684\u6f14\u7b97\u6cd5\u50c5\u4f7f\u7528\u901a\u5e38\u6240\u9700\u8cc7\u6e90\u7684 5-15%\uff0c\u5c31\u80fd\u627e\u51fa\u6548\u80fd\u6700\u4f73\u7684\u65b9\u6cd5\uff0c\u9032\u800c\u964d\u4f4e 85-95% \u7684\u6210\u672c\u3002", "author": "Jin Peng Zhou et.al.", "authors": "Jin Peng Zhou, Christian K. Belardi, Ruihan Wu, Travis Zhang, Carla P. Gomes, Wen Sun, Kilian Q. Weinberger", "id": "2407.06172v1", "paper_url": "http://arxiv.org/abs/2407.06172v1", "repo": "null"}}