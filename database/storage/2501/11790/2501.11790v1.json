{"2501.11790": {"publish_time": "2025-01-20", "title": "Benchmarking Large Language Models via Random Variables", "paper_summary": "With the continuous advancement of large language models (LLMs) in\nmathematical reasoning, evaluating their performance in this domain has become\na prominent research focus. Recent studies have raised concerns about the\nreliability of current mathematical benchmarks, highlighting issues such as\nsimplistic design and potential data leakage. Therefore, creating a reliable\nbenchmark that effectively evaluates the genuine capabilities of LLMs in\nmathematical reasoning remains a significant challenge. To address this, we\npropose RV-Bench, a framework for Benchmarking LLMs via Random Variables in\nmathematical reasoning. Specifically, the background content of a random\nvariable question (RV question) mirrors the original problem in existing\nstandard benchmarks, but the variable combinations are randomized into\ndifferent values. LLMs must fully understand the problem-solving process for\nthe original problem to correctly answer RV questions with various combinations\nof variable values. As a result, the LLM's genuine capability in mathematical\nreasoning is reflected by its accuracy on RV-Bench. Extensive experiments are\nconducted with 29 representative LLMs across 900+ RV questions. A leaderboard\nfor RV-Bench ranks the genuine capability of these LLMs. Further analysis of\naccuracy dropping indicates that current LLMs still struggle with complex\nmathematical reasoning problems.", "paper_summary_zh": "\u96a8\u8457\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u6578\u5b78\u63a8\u7406\u65b9\u9762\u7684\u6301\u7e8c\u9032\u6b65\uff0c\u8a55\u4f30\u5b83\u5011\u5728\u9019\u500b\u9818\u57df\u7684\u8868\u73fe\u5df2\u6210\u70ba\u4e00\u500b\u91cd\u8981\u7684\u7814\u7a76\u91cd\u9ede\u3002\u6700\u8fd1\u7684\u7814\u7a76\u5c0d\u7576\u524d\u6578\u5b78\u57fa\u6e96\u7684\u53ef\u9760\u6027\u63d0\u51fa\u4e86\u7591\u616e\uff0c\u4e26\u5f37\u8abf\u4e86\u8af8\u5982\u8a2d\u8a08\u904e\u65bc\u7c21\u5316\u548c\u6f5b\u5728\u6578\u64da\u6d29\u6f0f\u7b49\u554f\u984c\u3002\u56e0\u6b64\uff0c\u5efa\u7acb\u4e00\u500b\u53ef\u9760\u7684\u57fa\u6e96\uff0c\u4ee5\u6709\u6548\u8a55\u4f30 LLM \u5728\u6578\u5b78\u63a8\u7406\u4e2d\u7684\u771f\u5be6\u80fd\u529b\uff0c\u4ecd\u7136\u662f\u4e00\u9805\u91cd\u5927\u7684\u6311\u6230\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86 RV-Bench\uff0c\u4e00\u500b\u900f\u904e\u96a8\u6a5f\u8b8a\u6578\u5c0d LLM \u9032\u884c\u57fa\u51c6\u6e2c\u8a66\u7684\u6578\u5b78\u63a8\u7406\u6846\u67b6\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u96a8\u6a5f\u8b8a\u6578\u554f\u984c (RV \u554f\u984c) \u7684\u80cc\u666f\u5167\u5bb9\u53cd\u6620\u4e86\u73fe\u6709\u6a19\u6e96\u57fa\u6e96\u4e2d\u7684\u539f\u59cb\u554f\u984c\uff0c\u4f46\u8b8a\u6578\u7d44\u5408\u88ab\u96a8\u6a5f\u5316\u70ba\u4e0d\u540c\u7684\u503c\u3002LLM \u5fc5\u9808\u5145\u5206\u7406\u89e3\u539f\u59cb\u554f\u984c\u7684\u89e3\u984c\u904e\u7a0b\uff0c\u624d\u80fd\u6b63\u78ba\u56de\u7b54\u5177\u6709\u5404\u7a2e\u8b8a\u6578\u503c\u7d44\u5408\u7684 RV \u554f\u984c\u3002\u56e0\u6b64\uff0cLLM \u5728\u6578\u5b78\u63a8\u7406\u4e2d\u7684\u771f\u5be6\u80fd\u529b\u53cd\u6620\u5728\u5176\u5728 RV-Bench \u4e0a\u7684\u6e96\u78ba\u5ea6\u3002\u4f7f\u7528 29 \u500b\u5177\u4ee3\u8868\u6027\u7684 LLM \u5c0d 900 \u591a\u500b RV \u554f\u984c\u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u5be6\u9a57\u3002RV-Bench \u7684\u6392\u884c\u699c\u5c0d\u9019\u4e9b LLM \u7684\u771f\u5be6\u80fd\u529b\u9032\u884c\u4e86\u6392\u540d\u3002\u5c0d\u6e96\u78ba\u5ea6\u4e0b\u964d\u7684\u9032\u4e00\u6b65\u5206\u6790\u8868\u660e\uff0c\u7576\u524d\u7684 LLM \u4ecd\u7136\u96e3\u4ee5\u89e3\u6c7a\u8907\u96dc\u7684\u6578\u5b78\u63a8\u7406\u554f\u984c\u3002", "author": "Zijin Hong et.al.", "authors": "Zijin Hong, Hao Wu, Su Dong, Junnan Dong, Yilin Xiao, Yujing Zhang, Zhu Wang, Feiran Huang, Linyi Li, Hongxia Yang, Xiao Huang", "id": "2501.11790v1", "paper_url": "http://arxiv.org/abs/2501.11790v1", "repo": "null"}}