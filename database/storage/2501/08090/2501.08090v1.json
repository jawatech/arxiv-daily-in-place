{"2501.08090": {"publish_time": "2025-01-14", "title": "Hierarchical Autoscaling for Large Language Model Serving with Chiron", "paper_summary": "Large language model (LLM) serving is becoming an increasingly important\nworkload for cloud providers. Based on performance SLO requirements, LLM\ninference requests can be divided into (a) interactive requests that have tight\nSLOs in the order of seconds, and (b) batch requests that have relaxed SLO in\nthe order of minutes to hours. These SLOs can degrade based on the arrival\nrates, multiplexing, and configuration parameters, thus necessitating the use\nof resource autoscaling on serving instances and their batch sizes. However,\nprevious autoscalers for LLM serving do not consider request SLOs leading to\nunnecessary scaling and resource under-utilization. To address these\nlimitations, we introduce Chiron, an autoscaler that uses the idea of\nhierarchical backpressure estimated using queue size, utilization, and SLOs.\nOur experiments show that Chiron achieves up to 90% higher SLO attainment and\nimproves GPU efficiency by up to 70% compared to existing solutions.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u670d\u52d9\u6b63\u6210\u70ba\u96f2\u7aef\u4f9b\u61c9\u5546\u65e5\u76ca\u91cd\u8981\u7684\u5de5\u4f5c\u8ca0\u8f09\u3002LLM \u63a8\u8ad6\u8981\u6c42\u53ef\u57fa\u65bc\u6548\u80fd SLO \u9700\u6c42\u5206\u70ba\uff1a(a) \u4ea4\u4e92\u5f0f\u8981\u6c42\uff0c\u5176 SLO \u56b4\u683c\uff0c\u7d04\u70ba\u6578\u79d2\uff0c\u4ee5\u53ca (b) \u6279\u6b21\u8981\u6c42\uff0c\u5176 SLO \u8f03\u70ba\u5bec\u9b06\uff0c\u7d04\u70ba\u6578\u5206\u9418\u81f3\u6578\u5c0f\u6642\u3002\u9019\u4e9b SLO \u53ef\u80fd\u6703\u6839\u64da\u5230\u9054\u7387\u3001\u591a\u5de5\u8655\u7406\u548c\u7d44\u614b\u53c3\u6578\u800c\u964d\u4f4e\uff0c\u56e0\u6b64\u9700\u8981\u5728\u63d0\u4f9b\u57f7\u884c\u500b\u9ad4\u53ca\u5176\u6279\u6b21\u5927\u5c0f\u4e0a\u4f7f\u7528\u8cc7\u6e90\u81ea\u52d5\u64f4\u5145\u3002\u7136\u800c\uff0c\u5148\u524d\u7684 LLM \u670d\u52d9\u81ea\u52d5\u64f4\u5145\u5668\u4e26\u672a\u8003\u91cf\u8981\u6c42 SLO\uff0c\u5c0e\u81f4\u4e0d\u5fc5\u8981\u7684\u64f4\u5145\u548c\u8cc7\u6e90\u4f7f\u7528\u4e0d\u8db3\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u9650\u5236\uff0c\u6211\u5011\u5f15\u9032 Chiron\uff0c\u9019\u662f\u4e00\u500b\u81ea\u52d5\u64f4\u5145\u5668\uff0c\u4f7f\u7528\u4f47\u5217\u5927\u5c0f\u3001\u4f7f\u7528\u7387\u548c SLO \u4f30\u8a08\u7684\u968e\u5c64\u5f0f\u53cd\u58d3\u6982\u5ff5\u3002\u6211\u5011\u7684\u5be6\u9a57\u986f\u793a\uff0c\u8207\u73fe\u6709\u89e3\u6c7a\u65b9\u6848\u76f8\u6bd4\uff0cChiron \u53ef\u9054\u6210\u9ad8\u9054 90% \u7684 SLO \u9054\u6210\u7387\uff0c\u4e26\u5c07 GPU \u6548\u7387\u63d0\u5347\u9ad8\u9054 70%\u3002", "author": "Archit Patke et.al.", "authors": "Archit Patke, Dhemath Reddy, Saurabh Jha, Chandra Narayanaswami, Zbigniew Kalbarczyk, Ravishankar Iyer", "id": "2501.08090v1", "paper_url": "http://arxiv.org/abs/2501.08090v1", "repo": "null"}}