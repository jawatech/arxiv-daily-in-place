{"2406.16810": {"publish_time": "2024-06-24", "title": "PISTOL: Dataset Compilation Pipeline for Structural Unlearning of LLMs", "paper_summary": "Recently, machine unlearning, which seeks to erase specific data stored in\nthe pre-trained or fine-tuned models, has emerged as a crucial protective\nmeasure for LLMs. However, unlearning approaches for LLMs that have been\nconsidered thus far have focused on the removal of independent data points and\nhave not taken into account that the stored facts are logically connected to\none another and form an implicit knowledge graph. To facilitate the development\nof structural unlearning methods, which are essential for the practical\napplication of unlearning, we propose PISTOL, a pipeline for compiling\nmulti-scenario datasets for benchmarking structural LLM unlearning.\nAdditionally, leveraging sample datasets synthesized using PISTOL, we conducted\nbenchmarks with four distinct unlearning methods on both Llama2-7B and\nMistral-7B models. This analysis helps to illustrate the prevailing challenges\nin effectively and robustly removing highly inter-connected data, batched data,\nor data skewed towards a specific domain. It also highlights the choice of\npre-trained model can impact unlearning performance. This work not only\nadvances our understandings on the limitation of current LLMs unlearning\nmethods and proposes future research directions, but also provides a replicable\nframework for ongoing exploration and validation in the field.", "paper_summary_zh": "\u6700\u8fd1\uff0c\u673a\u5668\u53bb\u5b66\u4e60\uff08unlearning\uff09\u5df2\u6210\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u7684\u4e00\u9879\u5173\u952e\u4fdd\u62a4\u63aa\u65bd\uff0c\u5b83\u65e8\u5728\u6d88\u9664\u9884\u5148\u8bad\u7ec3\u6216\u5fae\u8c03\u6a21\u578b\u4e2d\u5b58\u50a8\u7684\u7279\u5b9a\u6570\u636e\u3002\u7136\u800c\uff0c\u8fc4\u4eca\u4e3a\u6b62\u8003\u8651\u7684 LLM \u53bb\u5b66\u4e60\u65b9\u6cd5\u90fd\u4e13\u6ce8\u4e8e\u5220\u9664\u72ec\u7acb\u6570\u636e\u70b9\uff0c\u5e76\u672a\u8003\u8651\u5230\u5b58\u50a8\u7684\u4e8b\u5b9e\u5f7c\u6b64\u4e4b\u95f4\u5728\u903b\u8f91\u4e0a\u662f\u76f8\u8fde\u7684\uff0c\u5e76\u5f62\u6210\u4e86\u4e00\u4e2a\u9690\u5f0f\u77e5\u8bc6\u56fe\u3002\u4e3a\u4e86\u4fc3\u8fdb\u7ed3\u6784\u5316\u53bb\u5b66\u4e60\u65b9\u6cd5\u7684\u53d1\u5c55\uff08\u8fd9\u5bf9\u4e8e\u53bb\u5b66\u4e60\u7684\u5b9e\u9645\u5e94\u7528\u81f3\u5173\u91cd\u8981\uff09\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 PISTOL\uff0c\u8fd9\u662f\u4e00\u4e2a\u7528\u4e8e\u7f16\u8bd1\u591a\u573a\u666f\u6570\u636e\u96c6\u4ee5\u5bf9\u7ed3\u6784\u5316 LLM \u53bb\u5b66\u4e60\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u7684\u7ba1\u9053\u3002\u6b64\u5916\uff0c\u5229\u7528\u4f7f\u7528 PISTOL \u5408\u6210\u7684\u6837\u672c\u6570\u636e\u96c6\uff0c\u6211\u4eec\u5bf9 Llama2-7B \u548c Mistral-7B \u6a21\u578b\u8fdb\u884c\u4e86\u56db\u79cd\u4e0d\u540c\u7684\u53bb\u5b66\u4e60\u65b9\u6cd5\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002\u6b64\u5206\u6790\u6709\u52a9\u4e8e\u8bf4\u660e\u5728\u6709\u6548\u4e14\u7a33\u5065\u5730\u5220\u9664\u9ad8\u5ea6\u4e92\u8fde\u7684\u6570\u636e\u3001\u6279\u5904\u7406\u6570\u636e\u6216\u504f\u5411\u7279\u5b9a\u9886\u57df\u7684\u7684\u6570\u636e\u65b9\u9762\u5b58\u5728\u7684\u666e\u904d\u6311\u6218\u3002\u5b83\u8fd8\u5f3a\u8c03\u4e86\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u9009\u62e9\u4f1a\u5f71\u54cd\u53bb\u5b66\u4e60\u6027\u80fd\u3002\u8fd9\u9879\u5de5\u4f5c\u4e0d\u4ec5\u4fc3\u8fdb\u4e86\u6211\u4eec\u5bf9\u5f53\u524d LLM \u53bb\u5b66\u4e60\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u7684\u7406\u89e3\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\uff0c\u8fd8\u4e3a\u8be5\u9886\u57df\u7684\u6301\u7eed\u63a2\u7d22\u548c\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u590d\u5236\u7684\u6846\u67b6\u3002", "author": "Xinchi Qiu et.al.", "authors": "Xinchi Qiu, William F. Shen, Yihong Chen, Nicola Cancedda, Pontus Stenetorp, Nicholas D. Lane", "id": "2406.16810v1", "paper_url": "http://arxiv.org/abs/2406.16810v1", "repo": "null"}}