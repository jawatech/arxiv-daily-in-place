{"2410.06699": {"publish_time": "2024-10-09", "title": "Break the Visual Perception: Adversarial Attacks Targeting Encoded Visual Tokens of Large Vision-Language Models", "paper_summary": "Large vision-language models (LVLMs) integrate visual information into large\nlanguage models, showcasing remarkable multi-modal conversational capabilities.\nHowever, the visual modules introduces new challenges in terms of robustness\nfor LVLMs, as attackers can craft adversarial images that are visually clean\nbut may mislead the model to generate incorrect answers. In general, LVLMs rely\non vision encoders to transform images into visual tokens, which are crucial\nfor the language models to perceive image contents effectively. Therefore, we\nare curious about one question: Can LVLMs still generate correct responses when\nthe encoded visual tokens are attacked and disrupting the visual information?\nTo this end, we propose a non-targeted attack method referred to as VT-Attack\n(Visual Tokens Attack), which constructs adversarial examples from multiple\nperspectives, with the goal of comprehensively disrupting feature\nrepresentations and inherent relationships as well as the semantic properties\nof visual tokens output by image encoders. Using only access to the image\nencoder in the proposed attack, the generated adversarial examples exhibit\ntransferability across diverse LVLMs utilizing the same image encoder and\ngenerality across different tasks. Extensive experiments validate the superior\nattack performance of the VT-Attack over baseline methods, demonstrating its\neffectiveness in attacking LVLMs with image encoders, which in turn can provide\nguidance on the robustness of LVLMs, particularly in terms of the stability of\nthe visual feature space.", "paper_summary_zh": "\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b (LVLMs) \u5c06\u89c6\u89c9\u4fe1\u606f\u6574\u5408\u5230\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u5c55\u793a\u4e86\u975e\u51e1\u7684\u591a\u6a21\u6001\u5bf9\u8bdd\u80fd\u529b\u3002\u7136\u800c\uff0c\u89c6\u89c9\u6a21\u5757\u4e3a LVLMs \u7684\u9c81\u68d2\u6027\u5e26\u6765\u4e86\u65b0\u7684\u6311\u6218\uff0c\u56e0\u4e3a\u653b\u51fb\u8005\u53ef\u4ee5\u5236\u4f5c\u89c6\u89c9\u4e0a\u5e72\u51c0\u4f46\u53ef\u80fd\u8bef\u5bfc\u6a21\u578b\u751f\u6210\u9519\u8bef\u7b54\u6848\u7684\u5bf9\u6297\u6027\u56fe\u50cf\u3002\u4e00\u822c\u6765\u8bf4\uff0cLVLMs \u4f9d\u8d56\u4e8e\u89c6\u89c9\u7f16\u7801\u5668\u5c06\u56fe\u50cf\u8f6c\u6362\u4e3a\u89c6\u89c9\u6807\u8bb0\uff0c\u89c6\u89c9\u6807\u8bb0\u5bf9\u4e8e\u8bed\u8a00\u6a21\u578b\u6709\u6548\u611f\u77e5\u56fe\u50cf\u5185\u5bb9\u81f3\u5173\u91cd\u8981\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u5bf9\u4e00\u4e2a\u95ee\u9898\u611f\u5230\u597d\u5947\uff1a\u5f53\u7f16\u7801\u7684\u89c6\u89c9\u6807\u8bb0\u53d7\u5230\u653b\u51fb\u5e76\u7834\u574f\u89c6\u89c9\u4fe1\u606f\u65f6\uff0cLVLMs \u662f\u5426\u4ecd\u7136\u53ef\u4ee5\u751f\u6210\u6b63\u786e\u7684\u54cd\u5e94\uff1f\u4e3a\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a VT-Attack\uff08\u89c6\u89c9\u6807\u8bb0\u653b\u51fb\uff09\u7684\u975e\u76ee\u6807\u653b\u51fb\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4ece\u591a\u4e2a\u89d2\u5ea6\u6784\u5efa\u5bf9\u6297\u6027\u793a\u4f8b\uff0c\u76ee\u7684\u662f\u5168\u9762\u7834\u574f\u7279\u5f81\u8868\u793a\u548c\u56fa\u6709\u5173\u7cfb\u4ee5\u53ca\u56fe\u50cf\u7f16\u7801\u5668\u8f93\u51fa\u7684\u89c6\u89c9\u6807\u8bb0\u7684\u8bed\u4e49\u5c5e\u6027\u3002\u4ec5\u901a\u8fc7\u8bbf\u95ee\u63d0\u8bae\u653b\u51fb\u4e2d\u7684\u56fe\u50cf\u7f16\u7801\u5668\uff0c\u751f\u6210\u7684\u5bf9\u6297\u6027\u793a\u4f8b\u5c55\u793a\u4e86\u8de8\u5229\u7528\u76f8\u540c\u56fe\u50cf\u7f16\u7801\u5668\u7684\u4e0d\u540c LVLMs \u7684\u53ef\u8f6c\u79fb\u6027\u4ee5\u53ca\u8de8\u4e0d\u540c\u4efb\u52a1\u7684\u901a\u7528\u6027\u3002\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86 VT-Attack \u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u7684\u5353\u8d8a\u653b\u51fb\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u653b\u51fb\u5177\u6709\u56fe\u50cf\u7f16\u7801\u5668\u7684 LVLMs \u4e2d\u7684\u6709\u6548\u6027\uff0c\u8fdb\u800c\u53ef\u4ee5\u4e3a LVLMs \u7684\u9c81\u68d2\u6027\u63d0\u4f9b\u6307\u5bfc\uff0c\u7279\u522b\u662f\u5728\u89c6\u89c9\u7279\u5f81\u7a7a\u95f4\u7684\u7a33\u5b9a\u6027\u65b9\u9762\u3002", "author": "Yubo Wang et.al.", "authors": "Yubo Wang, Chaohu Liu, Yanqiu Qu, Haoyu Cao, Deqiang Jiang, Linli Xu", "id": "2410.06699v1", "paper_url": "http://arxiv.org/abs/2410.06699v1", "repo": "null"}}