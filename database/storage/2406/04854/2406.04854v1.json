{"2406.04854": {"publish_time": "2024-06-07", "title": "Uncertainty Aware Learning for Language Model Alignment", "paper_summary": "As instruction-tuned large language models (LLMs) evolve, aligning pretrained\nfoundation models presents increasing challenges. Existing alignment\nstrategies, which typically leverage diverse and high-quality data sources,\noften overlook the intrinsic uncertainty of tasks, learning all data samples\nequally. This may lead to suboptimal data efficiency and model performance. In\nresponse, we propose uncertainty-aware learning (UAL) to improve the model\nalignment of different task scenarios, by introducing the sample uncertainty\n(elicited from more capable LLMs). We implement UAL in a simple fashion --\nadaptively setting the label smoothing value of training according to the\nuncertainty of individual samples. Analysis shows that our UAL indeed\nfacilitates better token clustering in the feature space, validating our\nhypothesis. Extensive experiments on widely used benchmarks demonstrate that\nour UAL significantly and consistently outperforms standard supervised\nfine-tuning. Notably, LLMs aligned in a mixed scenario have achieved an average\nimprovement of 10.62\\% on high-entropy tasks (i.e., AlpacaEval leaderboard),\nand 1.81\\% on complex low-entropy tasks (i.e., MetaMath and GSM8K).", "paper_summary_zh": "\u96a8\u8457\u6307\u4ee4\u5fae\u8abf\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6f14\u9032\uff0c\u6bd4\u5c0d\u9810\u8a13\u7df4\u57fa\u790e\u6a21\u578b\u9762\u81e8\u7684\u6311\u6230\u8d8a\u4f86\u8d8a\u5927\u3002\u73fe\u6709\u7684\u6bd4\u5c0d\u7b56\u7565\u901a\u5e38\u5229\u7528\u591a\u6a23\u4e14\u9ad8\u54c1\u8cea\u7684\u8cc7\u6599\u4f86\u6e90\uff0c\u537b\u5e38\u5e38\u5ffd\u7565\u4efb\u52d9\u7684\u5167\u5728\u4e0d\u78ba\u5b9a\u6027\uff0c\u4e00\u8996\u540c\u4ec1\u5730\u5b78\u7fd2\u6240\u6709\u8cc7\u6599\u6a23\u672c\u3002\u9019\u53ef\u80fd\u6703\u5c0e\u81f4\u6b21\u4f73\u7684\u8cc7\u6599\u6548\u7387\u548c\u6a21\u578b\u6548\u80fd\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e0d\u78ba\u5b9a\u6027\u611f\u77e5\u5b78\u7fd2 (UAL)\uff0c\u900f\u904e\u5f15\u5165\u6a23\u672c\u4e0d\u78ba\u5b9a\u6027\uff08\u5f9e\u66f4\u5f37\u5927\u7684 LLM \u7372\u5f97\uff09\uff0c\u4f86\u6539\u5584\u4e0d\u540c\u4efb\u52d9\u5834\u666f\u7684\u6a21\u578b\u6bd4\u5c0d\u3002\u6211\u5011\u4ee5\u4e00\u7a2e\u7c21\u55ae\u7684\u65b9\u5f0f\u5be6\u4f5c UAL\uff0c\u6839\u64da\u500b\u5225\u6a23\u672c\u7684\u4e0d\u78ba\u5b9a\u6027\uff0c\u81ea\u9069\u61c9\u5730\u8a2d\u5b9a\u8a13\u7df4\u7684\u6a19\u7c64\u5e73\u6ed1\u503c\u3002\u5206\u6790\u986f\u793a\uff0c\u6211\u5011\u7684 UAL \u78ba\u5be6\u4fc3\u9032\u4e86\u7279\u5fb5\u7a7a\u9593\u4e2d\u66f4\u597d\u7684\u6a19\u8a18\u805a\u985e\uff0c\u9a57\u8b49\u4e86\u6211\u5011\u7684\u5047\u8a2d\u3002\u5728\u5ee3\u6cdb\u4f7f\u7528\u7684\u57fa\u6e96\u4e0a\u9032\u884c\u7684\u5927\u91cf\u5be6\u9a57\u8b49\u660e\uff0c\u6211\u5011\u7684 UAL \u660e\u986f\u4e14\u6301\u7e8c\u5730\u512a\u65bc\u6a19\u6e96\u76e3\u7763\u5fae\u8abf\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5728\u6df7\u5408\u5834\u666f\u4e2d\u6bd4\u5c0d\u7684 LLM \u5728\u9ad8\u71b5\u4efb\u52d9\uff08\u5373 AlpacaEval \u6392\u884c\u699c\uff09\u4e0a\u5e73\u5747\u63d0\u5347\u4e86 10.62%\uff0c\u5728\u8907\u96dc\u4f4e\u71b5\u4efb\u52d9\uff08\u5373 MetaMath \u548c GSM8K\uff09\u4e0a\u63d0\u5347\u4e86 1.81%\u3002", "author": "Yikun Wang et.al.", "authors": "Yikun Wang, Rui Zheng, Liang Ding, Qi Zhang, Dahua Lin, Dacheng Tao", "id": "2406.04854v1", "paper_url": "http://arxiv.org/abs/2406.04854v1", "repo": "null"}}