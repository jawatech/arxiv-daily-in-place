
### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-30**|**Advancing Parkinson's Disease Progression Prediction: Comparing Long Short-Term Memory Networks and Kolmogorov-Arnold Networks**|Abhinav Roy et.al.|[2412.20744v1](http://arxiv.org/abs/2412.20744v1)|null|
|**2024-12-30**|**Latent Drifting in Diffusion Models for Counterfactual Medical Image Synthesis**|Yousef Yeganeh et.al.|[2412.20651v1](http://arxiv.org/abs/2412.20651v1)|null|
|**2024-12-29**|**HALLUCINOGEN: A Benchmark for Evaluating Object Hallucination in Large Visual-Language Models**|Ashish Seth et.al.|[2412.20622v1](http://arxiv.org/abs/2412.20622v1)|[link](https://github.com/AikyamLab/hallucinogen)|
|**2024-12-29**|**Dive into Time-Series Anomaly Detection: A Decade Review**|Paul Boniol et.al.|[2412.20512v1](http://arxiv.org/abs/2412.20512v1)|null|
|**2024-12-29**|**A Deep Subgrouping Framework for Precision Drug Repurposing via Emulating Clinical Trials on Real-world Patient Data**|Seungyeon Lee et.al.|[2412.20373v1](http://arxiv.org/abs/2412.20373v1)|null|
|**2024-12-28**|**On the Compositional Generalization of Multimodal LLMs for Medical Imaging**|Zhenyang Cai et.al.|[2412.20070v1](http://arxiv.org/abs/2412.20070v1)|[link](https://github.com/freedomintelligence/med-mat)|
|**2024-12-28**|**The Emotional Spectrum of LLMs: Leveraging Empathy and Emotion-Based Markers for Mental Health Support**|Alessandro De Grandi et.al.|[2412.20068v1](http://arxiv.org/abs/2412.20068v1)|null|
|**2024-12-28**|**MobileNetV2: A lightweight classification model for home-based sleep apnea screening**|Hui Pan et.al.|[2412.19967v1](http://arxiv.org/abs/2412.19967v1)|[link](https://github.com/mindspore-lab/models/tree/master/research/arxiv_papers/Easy-MobileNetV2)|
|**2024-12-27**|**ErgoChat: a Visual Query System for the Ergonomic Risk Assessment of Construction Workers**|Chao Fan et.al.|[2412.19954v1](http://arxiv.org/abs/2412.19954v1)|null|
|**2024-12-27**|**An Integrated Optimization and Deep Learning Pipeline for Predicting Live Birth Success in IVF Using Feature Optimization and Transformer-Based Models**|Arezoo Borji et.al.|[2412.19696v1](http://arxiv.org/abs/2412.19696v1)|null|
|**2024-12-27**|**A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation**|Jana Zakall et.al.|[2412.19688v1](http://arxiv.org/abs/2412.19688v1)|null|
|**2024-12-27**|**Disparate Model Performance and Stability in Machine Learning Clinical Support for Diabetes and Heart Diseases**|Ioannis Bilionis et.al.|[2412.19495v1](http://arxiv.org/abs/2412.19495v1)|null|
|**2024-12-26**|**Semi-Supervised Learning from Small Annotated Data and Large Unlabeled Data for Fine-grained PICO Entity Recognition**|Fangyi Chen et.al.|[2412.19346v1](http://arxiv.org/abs/2412.19346v1)|null|
|**2024-12-26**|**xSRL: Safety-Aware Explainable Reinforcement Learning -- Safety as a Product of Explainability**|Risal Shahriar Shefin et.al.|[2412.19311v1](http://arxiv.org/abs/2412.19311v1)|[link](https://github.com/risal-shefin/xsrl)|
|**2024-12-26**|**MEDEC: A Benchmark for Medical Error Detection and Correction in Clinical Notes**|Asma Ben Abacha et.al.|[2412.19260v2](http://arxiv.org/abs/2412.19260v2)|[link](https://github.com/abachaa/medec)|
|**2024-12-26**|**Leveraging Self-Training and Variational Autoencoder for Agitation Detection in People with Dementia Using Wearable Sensors**|Abeer Badawi et.al.|[2412.19254v1](http://arxiv.org/abs/2412.19254v1)|null|
|**2024-12-26**|**Evaluating Self-Supervised Learning in Medical Imaging: A Benchmark for Robustness, Generalizability, and Multi-Domain Impact**|Valay Bundele et.al.|[2412.19124v1](http://arxiv.org/abs/2412.19124v1)|null|
|**2024-12-26**|**Modality-Projection Universal Model for Comprehensive Full-Body Medical Imaging Segmentation**|Yixin Chen et.al.|[2412.19026v1](http://arxiv.org/abs/2412.19026v1)|[link](https://github.com/yixinchen-ai/mpum)|
|**2024-12-25**|**MedHallBench: A New Benchmark for Assessing Hallucination in Medical Large Language Models**|Kaiwen Zuo et.al.|[2412.18947v1](http://arxiv.org/abs/2412.18947v1)|null|
|**2024-12-25**|**HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs**|Junying Chen et.al.|[2412.18925v1](http://arxiv.org/abs/2412.18925v1)|[link](https://github.com/freedomintelligence/huatuogpt-o1)|
|**2024-12-25**|**Comprehensive Study on Lumbar Disc Segmentation Techniques Using MRI Data**|Serkan Salturk et.al.|[2412.18894v1](http://arxiv.org/abs/2412.18894v1)|null|
|**2024-12-25**|**Whose Morality Do They Speak? Unraveling Cultural Bias in Multilingual Language Models**|Meltem Aksoy et.al.|[2412.18863v1](http://arxiv.org/abs/2412.18863v1)|null|
|**2024-12-25**|**Unified Local and Global Attention Interaction Modeling for Vision Transformers**|Tan Nguyen et.al.|[2412.18778v1](http://arxiv.org/abs/2412.18778v1)|null|
|**2024-12-25**|**Successes and Limitations of Object-centric Models at Compositional Generalisation**|Milton L. Montero et.al.|[2412.18743v1](http://arxiv.org/abs/2412.18743v1)|null|
|**2024-12-24**|**SurvAttack: Black-Box Attack On Survival Models through Ontology-Informed EHR Perturbation**|Mohsen Nayebi Kerdabadi et.al.|[2412.18706v1](http://arxiv.org/abs/2412.18706v1)|null|
|**2024-12-24**|**A Review of Latent Representation Models in Neuroimaging**|C. Vázquez-García et.al.|[2412.19844v1](http://arxiv.org/abs/2412.19844v1)|null|
|**2024-12-24**|**DiTCtrl: Exploring Attention Control in Multi-Modal Diffusion Transformer for Tuning-Free Multi-Prompt Longer Video Generation**|Minghong Cai et.al.|[2412.18597v1](http://arxiv.org/abs/2412.18597v1)|[link](https://github.com/tencentarc/ditctrl)|
|**2024-12-24**|**Advancing Deformable Medical Image Registration with Multi-axis Cross-covariance Attention**|Mingyuan Meng et.al.|[2412.18545v1](http://arxiv.org/abs/2412.18545v1)|null|
|**2024-12-24**|**Multi-Agent Norm Perception and Induction in Distributed Healthcare**|Chao Li et.al.|[2412.18454v1](http://arxiv.org/abs/2412.18454v1)|null|
|**2024-12-24**|**Research on the Proximity Relationships of Psychosomatic Disease Knowledge Graph Modules Extracted by Large Language Models**|Zihan Zhou et.al.|[2412.18419v1](http://arxiv.org/abs/2412.18419v1)|null|
|**2024-12-24**|**Unveiling the Threat of Fraud Gangs to Graph Neural Networks: Multi-Target Graph Injection Attacks against GNN-Based Fraud Detectors**|Jinhyeok Choi et.al.|[2412.18370v1](http://arxiv.org/abs/2412.18370v1)|[link](https://github.com/bdi-lab/monti)|
|**2024-12-24**|**Real-world Deployment and Evaluation of PErioperative AI CHatbot (PEACH) -- a Large Language Model Chatbot for Perioperative Medicine**|Yu He Ke et.al.|[2412.18096v1](http://arxiv.org/abs/2412.18096v1)|null|
|**2024-12-23**|**Aligning AI Research with the Needs of Clinical Coding Workflows: Eight Recommendations Based on US Data Analysis and Critical Review**|Yidong Gan et.al.|[2412.18043v1](http://arxiv.org/abs/2412.18043v1)|null|
|**2024-12-23**|**A Grounded Observer Framework for Establishing Guardrails for Foundation Models in Socially Sensitive Domains**|Rebecca Ramnauth et.al.|[2412.18639v1](http://arxiv.org/abs/2412.18639v1)|null|
|**2024-12-23**|**Improving Sickle Cell Disease Classification: A Fusion of Conventional Classifiers, Segmented Images, and Convolutional Neural Networks**|Victor Júnio Alcântara Cardoso et.al.|[2412.17975v1](http://arxiv.org/abs/2412.17975v1)|[link](https://github.com/larissafrodrigues/sickle-cell-classification-ENIAC2023)|
|**2024-12-23**|**A Novel Approach to Balance Convenience and Nutrition in Meals With Long-Term Group Recommendations and Reasoning on Multimodal Recipes and its Implementation in BEACON**|Vansh Nagpal et.al.|[2412.17910v1](http://arxiv.org/abs/2412.17910v1)|null|
|**2024-12-23**|**Detecting anxiety and depression in dialogues: a multi-label and explainable approach**|Francisco de Arriba-Pérez et.al.|[2412.17651v1](http://arxiv.org/abs/2412.17651v1)|null|
|**2024-12-23**|**Facial Expression Analysis and Its Potentials in IoT Systems: A Contemporary Survey**|Zixuan Shanggua et.al.|[2412.17616v1](http://arxiv.org/abs/2412.17616v1)|null|
|**2024-12-23**|**V$^2$-SfMLearner: Learning Monocular Depth and Ego-motion for Multimodal Wireless Capsule Endoscopy**|Long Bai et.al.|[2412.17595v1](http://arxiv.org/abs/2412.17595v1)|null|
|**2024-12-23**|**Improved Cotton Leaf Disease Classification Using Parameter-Efficient Deep Learning Framework**|Aswini Kumar Patra et.al.|[2412.17587v1](http://arxiv.org/abs/2412.17587v1)|null|
|**2024-12-23**|**Empathetic Response in Audio-Visual Conversations Using Emotion Preference Optimization and MambaCompressor**|Yeonju Kim et.al.|[2412.17572v1](http://arxiv.org/abs/2412.17572v1)|null|
|**2024-12-23**|**Enhancing Cancer Diagnosis with Explainable & Trustworthy Deep Learning Models**|Badaru I. Olumuyiwa et.al.|[2412.17527v1](http://arxiv.org/abs/2412.17527v1)|null|
|**2024-12-23**|**Applying LLM and Topic Modelling in Psychotherapeutic Contexts**|Alexander Vanin et.al.|[2412.17449v1](http://arxiv.org/abs/2412.17449v1)|null|
|**2024-12-23**|**FFA Sora, video generation as fundus fluorescein angiography simulator**|Xinyuan Wu et.al.|[2412.17346v1](http://arxiv.org/abs/2412.17346v1)|null|
|**2024-12-23**|**QTSeg: A Query Token-Based Architecture for Efficient 2D Medical Image Segmentation**|Phuong-Nam Tran et.al.|[2412.17241v1](http://arxiv.org/abs/2412.17241v1)|[link](https://github.com/tpnam0901/QTSeg)|
|**2024-12-23**|**MatchMiner-AI: An Open-Source Solution for Cancer Clinical Trial Matching**|Ethan Cerami et.al.|[2412.17228v1](http://arxiv.org/abs/2412.17228v1)|null|
|**2024-12-22**|**COVID-19 on YouTube: A Data-Driven Analysis of Sentiment, Toxicity, and Content Recommendations**|Vanessa Su et.al.|[2412.17180v1](http://arxiv.org/abs/2412.17180v1)|null|
|**2024-12-22**|**AI-Based Teat Shape and Skin Condition Prediction for Dairy Management**|Yuexing Hao et.al.|[2412.17142v1](http://arxiv.org/abs/2412.17142v1)|null|
|**2024-12-22**|**An OpenMind for 3D medical vision self-supervised learning**|Tassilo Wald et.al.|[2412.17041v1](http://arxiv.org/abs/2412.17041v1)|null|
|**2024-12-22**|**On Fusing ChatGPT and Ensemble Learning in Discon-tinuous Named Entity Recognition in Health Corpora**|Tzu-Chieh Chen et.al.|[2412.16976v1](http://arxiv.org/abs/2412.16976v1)|null|
|**2024-12-22**|**Quantifying Public Response to COVID-19 Events: Introducing the Community Sentiment and Engagement Index**|Nirmalya Thakur et.al.|[2412.16925v1](http://arxiv.org/abs/2412.16925v1)|null|
|**2024-12-22**|**PsychAdapter: Adapting LLM Transformers to Reflect Traits, Personality and Mental Health**|Huy Vu et.al.|[2412.16882v2](http://arxiv.org/abs/2412.16882v2)|null|
|**2024-12-22**|**KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis**|Kaiwen Zuo et.al.|[2412.16833v1](http://arxiv.org/abs/2412.16833v1)|null|
|**2024-12-21**|**A Comparative Study on Machine Learning Models to Classify Diseases Based on Patient Behaviour and Habits**|Elham Musaaed et.al.|[2412.16768v1](http://arxiv.org/abs/2412.16768v1)|null|
|**2024-12-21**|**From Histopathology Images to Cell Clouds: Learning Slide Representations with Hierarchical Cell Transformer**|Zijiang Yang et.al.|[2412.16715v1](http://arxiv.org/abs/2412.16715v1)|null|
|**2024-12-21**|**Multi-atlas Ensemble Graph Neural Network Model For Major Depressive Disorder Detection Using Functional MRI Data**|Nojod M. Alotaibi et.al.|[2412.19833v1](http://arxiv.org/abs/2412.19833v1)|null|
|**2024-12-21**|**STAMPsy: Towards SpatioTemporal-Aware Mixed-Type Dialogues for Psychological Counseling**|Jieyi Wang et.al.|[2412.16674v1](http://arxiv.org/abs/2412.16674v1)|null|
|**2024-12-21**|**Automated Bleeding Detection and Classification in Wireless Capsule Endoscopy with YOLOv8-X**|Pavan C Shekar et.al.|[2412.16624v1](http://arxiv.org/abs/2412.16624v1)|[link](https://github.com/pavan98765/auto-wcebleedgen)|
|**2024-12-21**|**Patherea: Cell Detection and Classification for the 2020s**|Dejan Štepec et.al.|[2412.16425v1](http://arxiv.org/abs/2412.16425v1)|null|
|**2024-12-21**|**Technical Report: Small Language Model for Japanese Clinical and Medicine**|Shogo Watanabe et.al.|[2412.16423v1](http://arxiv.org/abs/2412.16423v1)|null|
|**2024-12-20**|**Learning Disease Progression Models That Capture Health Disparities**|Erica Chiang et.al.|[2412.16406v1](http://arxiv.org/abs/2412.16406v1)|null|
|**2024-12-20**|**Ethics and Technical Aspects of Generative AI Models in Digital Content Creation**|Atahan Karagoz et.al.|[2412.16389v1](http://arxiv.org/abs/2412.16389v1)|null|
|**2024-12-20**|**VerSe: Integrating Multiple Queries as Prompts for Versatile Cardiac MRI Segmentation**|Bangwei Guo et.al.|[2412.16381v1](http://arxiv.org/abs/2412.16381v1)|[link](https://github.com/bangwayne/verse)|
|**2024-12-20**|**FairREAD: Re-fusing Demographic Attributes after Disentanglement for Fair Medical Image Classification**|Yicheng Gao et.al.|[2412.16373v1](http://arxiv.org/abs/2412.16373v1)|null|
|**2024-12-20**|**Improving Object Detection for Time-Lapse Imagery Using Temporal Features in Wildlife Monitoring**|Marcus Jenkins et.al.|[2412.16329v1](http://arxiv.org/abs/2412.16329v1)|[link](https://github.com/marcusjenkins01/yolov7-temporal)|
|**2024-12-20**|**Benchmarking LLMs and SLMs for patient reported outcomes**|Matteo Marengo et.al.|[2412.16291v1](http://arxiv.org/abs/2412.16291v1)|null|
|**2024-12-20**|**Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG**|Hasan Md Tusfiqur Alam et.al.|[2412.16086v1](http://arxiv.org/abs/2412.16086v1)|[link](https://github.com/tifat58/irr-with-cbm-rag)|
|**2024-12-20**|**Intelligent Approaches to Predictive Analytics in Occupational Health and Safety in India**|Ritwik Raj Saxena et.al.|[2412.16038v3](http://arxiv.org/abs/2412.16038v3)|null|
|**2024-12-20**|**Self-Supervised Radiograph Anatomical Region Classification -- How Clean Is Your Real-World Data?**|Simon Langer et.al.|[2412.15967v1](http://arxiv.org/abs/2412.15967v1)|null|
|**2024-12-20**|**From General to Specific: Tailoring Large Language Models for Personalized Healthcare**|Ruize Shi et.al.|[2412.15957v1](http://arxiv.org/abs/2412.15957v1)|null|
|**2024-12-20**|**Development of a Large-scale Dataset of Chest Computed Tomography Reports in Japanese and a High-performance Finding Classification Model**|Yosuke Yamagishi et.al.|[2412.15907v1](http://arxiv.org/abs/2412.15907v1)|null|
|**2024-12-20**|**Linguistic Features Extracted by GPT-4 Improve Alzheimer's Disease Detection based on Spontaneous Speech**|Jonathan Heitz et.al.|[2412.15772v1](http://arxiv.org/abs/2412.15772v1)|[link](https://github.com/jheitz/coling2025_gpt_paper)|
|**2024-12-20**|**Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models**|Shamus Sim et.al.|[2412.15748v1](http://arxiv.org/abs/2412.15748v1)|null|
|**2024-12-20**|**NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning**|Zheyuan Zhang et.al.|[2412.15547v1](http://arxiv.org/abs/2412.15547v1)|null|
|**2024-12-20**|**The First Multilingual Model For The Detection of Suicide Texts**|Rodolfo Zevallos et.al.|[2412.15498v1](http://arxiv.org/abs/2412.15498v1)|null|
|**2024-12-19**|**AI-Enhanced Sensemaking: Exploring the Design of a Generative AI-Based Assistant to Support Genetic Professionals**|Angela Mastrianni et.al.|[2412.15444v1](http://arxiv.org/abs/2412.15444v1)|null|
|**2024-12-19**|**GIRAFE: Glottal Imaging Dataset for Advanced Segmentation, Analysis, and Facilitative Playbacks Evaluation**|G. Andrade-Miranda et.al.|[2412.15054v1](http://arxiv.org/abs/2412.15054v1)|[link](https://github.com/andrade-miranda/girafe)|
|**2024-12-19**|**RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response**|Junyu Luo et.al.|[2412.14922v1](http://arxiv.org/abs/2412.14922v1)|[link](https://github.com/luo-junyu/robustft)|
|**2024-12-19**|**Advances in Artificial Intelligence forDiabetes Prediction: Insights from a Systematic Literature Review**|Pir Bakhsh Khokhar et.al.|[2412.14736v1](http://arxiv.org/abs/2412.14736v1)|null|
|**2024-12-19**|**Pitfalls of topology-aware image segmentation**|Alexander H. Berger et.al.|[2412.14619v1](http://arxiv.org/abs/2412.14619v1)|[link](https://github.com/alexanderhberger/topo-pitfalls)|
|**2024-12-19**|**CwA-T: A Channelwise AutoEncoder with Transformer for EEG Abnormality Detection**|Youshen Zhao et.al.|[2412.14522v2](http://arxiv.org/abs/2412.14522v2)|[link](https://github.com/yossizhao/cae-t)|
|**2024-12-19**|**GenHMR: Generative Human Mesh Recovery**|Muhammad Usama Saleem et.al.|[2412.14444v1](http://arxiv.org/abs/2412.14444v1)|null|
|**2024-12-19**|**FedPIA -- Permuting and Integrating Adapters leveraging Wasserstein Barycenters for Finetuning Foundation Models in Multi-Modal Federated Learning**|Pramit Saha et.al.|[2412.14424v1](http://arxiv.org/abs/2412.14424v1)|null|
|**2024-12-18**|**Clinical Trials Ontology Engineering with Large Language Models**|Berkan Çakır et.al.|[2412.14387v1](http://arxiv.org/abs/2412.14387v1)|null|
|**2024-12-18**|**Multi-OphthaLingua: A Multilingual Benchmark for Assessing and Debiasing LLM Ophthalmological QA in LMICs**|David Restrepo et.al.|[2412.14304v1](http://arxiv.org/abs/2412.14304v1)|null|
|**2024-12-18**|**Discovering maximally consistent distribution of causal tournaments with Large Language Models**|Federico Baldo et.al.|[2412.14019v1](http://arxiv.org/abs/2412.14019v1)|null|
|**2024-12-18**|**SurgSora: Decoupled RGBD-Flow Diffusion Model for Controllable Surgical Video Generation**|Tong Chen et.al.|[2412.14018v1](http://arxiv.org/abs/2412.14018v1)|null|
|**2024-12-18**|**Cognition Chain for Explainable Psychological Stress Detection on Social Media**|Xin Wang et.al.|[2412.14009v1](http://arxiv.org/abs/2412.14009v1)|null|
|**2024-12-18**|**Federated Learning and RAG Integration: A Scalable Approach for Medical Large Language Models**|Jincheol Jung et.al.|[2412.13720v1](http://arxiv.org/abs/2412.13720v1)|null|
|**2024-12-18**|**Clio: Privacy-Preserving Insights into Real-World AI Use**|Alex Tamkin et.al.|[2412.13678v1](http://arxiv.org/abs/2412.13678v1)|null|
|**2024-12-18**|**Exploring Multi-Modal Integration with Tool-Augmented LLM Agents for Precise Causal Discovery**|ChengAo Shen et.al.|[2412.13667v1](http://arxiv.org/abs/2412.13667v1)|null|
|**2024-12-17**|**BadSAD: Clean-Label Backdoor Attacks against Deep Semi-Supervised Anomaly Detection**|He Cheng et.al.|[2412.13324v1](http://arxiv.org/abs/2412.13324v1)|null|
|**2024-12-17**|**In-context learning for medical image segmentation**|Eichi Takaya et.al.|[2412.13299v1](http://arxiv.org/abs/2412.13299v1)|null|
|**2024-12-17**|**Continuous Patient Monitoring with AI: Real-Time Analysis of Video in Hospital Care Settings**|Paolo Gabriel et.al.|[2412.13152v1](http://arxiv.org/abs/2412.13152v1)|[link](https://github.com/lookdeep/ai-norms-2024)|
|**2024-12-17**|**Boosting Fine-Grained Visual Anomaly Detection with Coarse-Knowledge-Aware Adversarial Learning**|Qingqing Fang et.al.|[2412.12850v1](http://arxiv.org/abs/2412.12850v1)|[link](https://github.com/Faustinaqq/CKAAD)|
|**2024-12-17**|**Rethinking Diffusion-Based Image Generators for Fundus Fluorescein Angiography Synthesis on Limited Data**|Chengzhou Yu et.al.|[2412.12778v1](http://arxiv.org/abs/2412.12778v1)|null|
|**2024-12-17**|**MedMax: Mixed-Modal Instruction Tuning for Training Biomedical Assistants**|Hritik Bansal et.al.|[2412.12661v1](http://arxiv.org/abs/2412.12661v1)|[link](https://github.com/Hritikbansal/medmax)|
|**2024-12-17**|**a2z-1 for Multi-Disease Detection in Abdomen-Pelvis CT: External Validation and Performance Analysis Across 21 Conditions**|Pranav Rajpurkar et.al.|[2412.12629v1](http://arxiv.org/abs/2412.12629v1)|null|
|**2024-12-17**|**A Scalable Approach to Benchmarking the In-Conversation Differential Diagnostic Accuracy of a Health AI**|Deep Bhatt et.al.|[2412.12538v1](http://arxiv.org/abs/2412.12538v1)|null|
|**2024-12-17**|**Addressing Small and Imbalanced Medical Image Datasets Using Generative Models: A Comparative Study of DDPM and PGGANs with Random and Greedy K Sampling**|Iman Khazrak et.al.|[2412.12532v1](http://arxiv.org/abs/2412.12532v1)|[link](https://github.com/imankhazrak/DDPM_X-Ray)|

#### Abstracts
##### **Advancing Parkinson's Disease Progression Prediction: Comparing Long Short-Term Memory Networks and Kolmogorov-Arnold Networks**
2412.20744v1 by Abhinav Roy, Bhavesh Gyanchandani, Aditya Oza, Abhishek Sharma

Parkinson's Disease (PD) is a degenerative neurological disorder that impairs
motor and non-motor functions, significantly reducing quality of life and
increasing mortality risk. Early and accurate detection of PD progression is
vital for effective management and improved patient outcomes. Current
diagnostic methods, however, are often costly, time-consuming, and require
specialized equipment and expertise. This work proposes an innovative approach
to predicting PD progression using regression methods, Long Short-Term Memory
(LSTM) networks, and Kolmogorov Arnold Networks (KAN). KAN, utilizing
spline-parametrized univariate functions, allows for dynamic learning of
activation patterns, unlike traditional linear models.
  The Movement Disorder Society-Sponsored Revision of the Unified Parkinson's
Disease Rating Scale (MDS-UPDRS) is a comprehensive tool for evaluating PD
symptoms and is commonly used to measure disease progression. Additionally,
protein or peptide abnormalities are linked to PD onset and progression.
Identifying these associations can aid in predicting disease progression and
understanding molecular changes.
  Comparing multiple models, including LSTM and KAN, this study aims to
identify the method that delivers the highest metrics. The analysis reveals
that KAN, with its dynamic learning capabilities, outperforms other approaches
in predicting PD progression. This research highlights the potential of AI and
machine learning in healthcare, paving the way for advanced computational
models to enhance clinical predictions and improve patient care and treatment
strategies in PD management.

摘要：帕金森氏症 (PD) 是一種神經退化性疾病，會損害運動和非運動功能，嚴重降低生活品質並增加死亡風險。早期且準確檢測 PD 進程對於有效管理和改善患者預後至關重要。然而，目前的診斷方法通常成本高昂、耗時且需要專業設備和專業知識。這項研究提出了一種創新的方法，使用迴歸方法、長短期記憶 (LSTM) 網路和 Kolmogorov Arnold 網路 (KAN) 來預測 PD 進程。KAN 利用樣條參數化的單變量函數，可以動態學習激活模式，這與傳統線性模型不同。運動障礙協會贊助的統一帕金森氏症評分量表 (MDS-UPDRS) 是評估 PD 症狀的綜合工具，通常用於測量疾病進程。此外，蛋白質或胜肽異常與 PD 發作和進程有關。找出這些關聯可以幫助預測疾病進程並了解分子變化。這項研究比較了包括 LSTM 和 KAN 在內的多種模型，旨在找出提供最高指標的方法。分析顯示，具有動態學習能力的 KAN 在預測 PD 進程方面優於其他方法。這項研究突顯了 AI 和機器學習在醫療保健中的潛力，為先進的計算模型鋪路，以增強臨床預測並改善 PD 管理中的患者照護和治療策略。

##### **Latent Drifting in Diffusion Models for Counterfactual Medical Image Synthesis**
2412.20651v1 by Yousef Yeganeh, Ioannis Charisiadis, Marta Hasny, Martin Hartenberger, Björn Ommer, Nassir Navab, Azade Farshad, Ehsan Adeli

Scaling by training on large datasets has been shown to enhance the quality
and fidelity of image generation and manipulation with diffusion models;
however, such large datasets are not always accessible in medical imaging due
to cost and privacy issues, which contradicts one of the main applications of
such models to produce synthetic samples where real data is scarce. Also,
finetuning on pre-trained general models has been a challenge due to the
distribution shift between the medical domain and the pre-trained models. Here,
we propose Latent Drift (LD) for diffusion models that can be adopted for any
fine-tuning method to mitigate the issues faced by the distribution shift or
employed in inference time as a condition. Latent Drifting enables diffusion
models to be conditioned for medical images fitted for the complex task of
counterfactual image generation, which is crucial to investigate how parameters
such as gender, age, and adding or removing diseases in a patient would alter
the medical images. We evaluate our method on three public longitudinal
benchmark datasets of brain MRI and chest X-rays for counterfactual image
generation. Our results demonstrate significant performance gains in various
scenarios when combined with different fine-tuning schemes. The source code of
this work will be publicly released upon its acceptance.

摘要：<paragraph>透過訓練大型資料集來調整比例，已被證明可以提升擴散模型影像產生與操作的品質和保真度；然而，由於成本和隱私問題，在醫學影像中並不總是能取得這麼大型的資料集，這與這些模型的主要應用之一相矛盾，也就是在真實資料稀少的情況下產生合成樣本。此外，由於醫學領域與預訓練模型之間的分布轉移，對預訓練的通用模型進行微調一直是一項挑戰。在此，我們提出擴散模型的潛在漂移 (LD)，可以採用任何微調方法來減輕分布轉移所面臨的問題，或在推理時間作為條件使用。潛在漂移使擴散模型能夠針對適合於反事實影像產生複雜任務的醫學影像進行調整，這對於探討諸如性別、年齡以及在患者中增加或移除疾病等參數將如何改變醫學影像至關重要。我們在三個大腦 MRI 和胸部 X 光的公開縱向基準資料集上評估了我們的方法，以進行反事實影像產生。我們的結果表明，與不同的微調方案結合使用時，在各種情況下都能顯著提升效能。這項工作的原始碼將在獲得接受後公開發布。</paragraph>

##### **HALLUCINOGEN: A Benchmark for Evaluating Object Hallucination in Large Visual-Language Models**
2412.20622v1 by Ashish Seth, Dinesh Manocha, Chirag Agarwal

Large Vision-Language Models (LVLMs) have demonstrated remarkable performance
in performing complex multimodal tasks. However, they are still plagued by
object hallucination: the misidentification or misclassification of objects
present in images. To this end, we propose HALLUCINOGEN, a novel visual
question answering (VQA) object hallucination attack benchmark that utilizes
diverse contextual reasoning prompts to evaluate object hallucination in
state-of-the-art LVLMs. We design a series of contextual reasoning
hallucination prompts to evaluate LVLMs' ability to accurately identify objects
in a target image while asking them to perform diverse visual-language tasks
such as identifying, locating or performing visual reasoning around specific
objects. Further, we extend our benchmark to high-stakes medical applications
and introduce MED-HALLUCINOGEN, hallucination attacks tailored to the
biomedical domain, and evaluate the hallucination performance of LVLMs on
medical images, a critical area where precision is crucial. Finally, we conduct
extensive evaluations of eight LVLMs and two hallucination mitigation
strategies across multiple datasets to show that current generic and medical
LVLMs remain susceptible to hallucination attacks.

摘要：大型視覺語言模型 (LVLMs) 在執行複雜的多模態任務方面表現出色。然而，它們仍然受到物體幻覺的困擾：錯誤識別或錯誤分類圖像中存在的物體。為此，我們提出了 HALLUCINOGEN，這是一個新穎的視覺問答 (VQA) 物體幻覺攻擊基準，它利用多樣化的上下文推理提示來評估最先進的 LVLMs 中的物體幻覺。我們設計了一系列上下文推理幻覺提示，以評估 LVLMs 在要求它們執行多樣化的視覺語言任務（例如識別、定位或對特定物體進行視覺推理）的同時準確識別目標圖像中物體的能力。此外，我們將基準擴展到高風險的醫學應用，並引入了專門針對生物醫學領域的幻覺攻擊 MED-HALLUCINOGEN，並評估了 LVLMs 在醫學圖像（一個精確至關重要的關鍵領域）上的幻覺表現。最後，我們對八個 LVLMs 和兩個幻覺緩解策略進行了廣泛的評估，跨多個數據集，以表明當前的通用和醫學 LVLMs 仍然容易受到幻覺攻擊。

##### **Dive into Time-Series Anomaly Detection: A Decade Review**
2412.20512v1 by Paul Boniol, Qinghua Liu, Mingyi Huang, Themis Palpanas, John Paparrizos

Recent advances in data collection technology, accompanied by the ever-rising
volume and velocity of streaming data, underscore the vital need for time
series analytics. In this regard, time-series anomaly detection has been an
important activity, entailing various applications in fields such as cyber
security, financial markets, law enforcement, and health care. While
traditional literature on anomaly detection is centered on statistical
measures, the increasing number of machine learning algorithms in recent years
call for a structured, general characterization of the research methods for
time-series anomaly detection. This survey groups and summarizes anomaly
detection existing solutions under a process-centric taxonomy in the time
series context. In addition to giving an original categorization of anomaly
detection methods, we also perform a meta-analysis of the literature and
outline general trends in time-series anomaly detection research.

摘要：隨著資料收集技術的最新進展，以及串流資料的數量和速度持續上升，強調了時間序列分析的迫切需求。在這方面，時間序列異常偵測一直是一項重要的活動，包含網路安全、金融市場、執法和醫療保健等領域中的各種應用。雖然異常偵測的傳統文獻集中於統計測量，但近年來機器學習演算法的數量不斷增加，因此需要對時間序列異常偵測的研究方法進行結構化、通用的描述。這項調查在時間序列脈絡中，依據以流程為中心的分類法，對異常偵測現有解決方案進行分組和摘要。除了對異常偵測方法進行原始分類外，我們也對文獻進行元分析，並概述時間序列異常偵測研究的一般趨勢。

##### **A Deep Subgrouping Framework for Precision Drug Repurposing via Emulating Clinical Trials on Real-world Patient Data**
2412.20373v1 by Seungyeon Lee, Ruoqi Liu, Feixiong Cheng, Ping Zhang

Drug repurposing identifies new therapeutic uses for existing drugs, reducing
the time and costs compared to traditional de novo drug discovery. Most
existing drug repurposing studies using real-world patient data often treat the
entire population as homogeneous, ignoring the heterogeneity of treatment
responses across patient subgroups. This approach may overlook promising drugs
that benefit specific subgroups but lack notable treatment effects across the
entire population, potentially limiting the number of repurposable candidates
identified. To address this, we introduce STEDR, a novel drug repurposing
framework that integrates subgroup analysis with treatment effect estimation.
Our approach first identifies repurposing candidates by emulating multiple
clinical trials on real-world patient data and then characterizes patient
subgroups by learning subgroup-specific treatment effects. We deploy \model to
Alzheimer's Disease (AD), a condition with few approved drugs and known
heterogeneity in treatment responses. We emulate trials for over one thousand
medications on a large-scale real-world database covering over 8 million
patients, identifying 14 drug candidates with beneficial effects to AD in
characterized subgroups. Experiments demonstrate STEDR's superior capability in
identifying repurposing candidates compared to existing approaches.
Additionally, our method can characterize clinically relevant patient subgroups
associated with important AD-related risk factors, paving the way for precision
drug repurposing.

摘要：药物再利用为现有药物找出新的治疗用途，与传统的从头药物发现相比，减少了时间和成本。大多数使用真实世界患者数据的现有药物再利用研究通常将整个人群视为同质的，而忽略了不同患者亚组治疗反应的异质性。这种方法可能会忽视对特定亚组有益但整个群体缺乏显着治疗效果的有希望的药物，从而可能限制已识别的可再利用候选药物的数量。为了解决这个问题，我们引入了 STEDR，这是一个新颖的药物再利用框架，它将亚组分析与治疗效果估计相结合。我们的方法首先通过模拟真实世界患者数据的多个临床试验来识别再利用候选药物，然后通过学习亚组特异性治疗效果来表征患者亚组。我们部署\model到阿尔茨海默病 (AD)，这是一种已获批药物较少且治疗反应已知异质性的疾病。我们在一个覆盖超过 800 万患者的大规模真实世界数据库上模拟了超过一千种药物的试验，确定了 14 种在表征的亚组中对 AD 有益的候选药物。实验表明，与现有方法相比，STEDR 在识别再利用候选药物方面具有更强的能力。此外，我们的方法可以表征与重要的 AD 相关危险因素相关的临床相关患者亚组，为精准药物再利用铺平道路。

##### **On the Compositional Generalization of Multimodal LLMs for Medical Imaging**
2412.20070v1 by Zhenyang Cai, Junying Chen, Rongsheng Wang, Weihong Wang, Yonglin Deng, Dingjie Song, Yize Chen, Zixu Zhang, Benyou Wang

Multimodal large language models (MLLMs) hold significant potential in the
medical field, but their capabilities are often limited by insufficient data in
certain medical domains, highlighting the need for understanding what kinds of
images can be used by MLLMs for generalization. Current research suggests that
multi-task training outperforms single-task as different tasks can benefit each
other, but they often overlook the internal relationships within these tasks,
providing limited guidance on selecting datasets to enhance specific tasks. To
analyze this phenomenon, we attempted to employ compositional generalization
(CG)-the ability of models to understand novel combinations by recombining
learned elements-as a guiding framework. Since medical images can be precisely
defined by Modality, Anatomical area, and Task, naturally providing an
environment for exploring CG. Therefore, we assembled 106 medical datasets to
create Med-MAT for comprehensive experiments. The experiments confirmed that
MLLMs can use CG to understand unseen medical images and identified CG as one
of the main drivers of the generalization observed in multi-task training.
Additionally, further studies demonstrated that CG effectively supports
datasets with limited data and delivers consistent performance across different
backbones, highlighting its versatility and broad applicability. Med-MAT is
publicly available at https://github.com/FreedomIntelligence/Med-MAT.

摘要：多模态大型语言模型 (MLLM) 在医疗领域拥有巨大潜力，但其能力往往受到特定医疗领域数据不足的限制，这突出了理解 MLLM 可用于泛化的图像类型的必要性。当前的研究表明，多任务训练优于单任务训练，因为不同的任务可以相互受益，但它们常常忽略这些任务中的内部关系，在选择数据集以增强特定任务方面提供的指导有限。为了分析这种现象，我们尝试采用组合泛化 (CG)——模型通过重新组合学习的元素来理解新组合的能力——作为指导框架。由于医学图像可以通过方式、解剖区域和任务来精确定义，因此自然地为探索 CG 提供了一个环境。因此，我们组装了 106 个医学数据集来创建 Med-MAT 以进行综合实验。实验证实，MLLM 可以使用 CG 来理解看不见的医学图像，并将 CG 确定为多任务训练中观察到的泛化的主要驱动因素之一。此外，进一步的研究表明，CG 有效地支持了数据有限的数据集，并在不同的主干中提供了持续的性能，突出了其多功能性和广泛的适用性。Med-MAT 在 https://github.com/FreedomIntelligence/Med-MAT 公开可用。

##### **The Emotional Spectrum of LLMs: Leveraging Empathy and Emotion-Based Markers for Mental Health Support**
2412.20068v1 by Alessandro De Grandi, Federico Ravenda, Andrea Raballo, Fabio Crestani

The increasing demand for mental health services has highlighted the need for
innovative solutions, particularly in the realm of psychological conversational
AI, where the availability of sensitive data is scarce. In this work, we
explored the development of a system tailored for mental health support with a
novel approach to psychological assessment based on explainable emotional
profiles in combination with empathetic conversational models, offering a
promising tool for augmenting traditional care, particularly where immediate
expertise is unavailable. Our work can be divided into two main parts,
intrinsecaly connected to each other. First, we present RACLETTE, a
conversational system that demonstrates superior emotional accuracy compared to
state-of-the-art benchmarks in both understanding users' emotional states and
generating empathetic responses during conversations, while progressively
building an emotional profile of the user through their interactions. Second,
we show how the emotional profiles of a user can be used as interpretable
markers for mental health assessment. These profiles can be compared with
characteristic emotional patterns associated with different mental disorders,
providing a novel approach to preliminary screening and support.

摘要：隨著對心理健康服務需求的增加，凸顯了創新解決方案的需求，特別是在心理對話式人工智慧領域，那裡缺乏敏感資料。在這項工作中，我們探索了開發一個針對心理健康支持的系統，採用一種基於可解釋的情緒特徵的新方法進行心理評估，結合同理心對話模式，提供了一個有前途的工具，用於擴充傳統照護，特別是在無法立即獲得專業知識的情況下。我們的工作可以分為兩個主要部分，彼此內在相關。首先，我們展示了 RACLETTE，一個對話系統，與最先進的基準相比，在理解使用者情緒狀態和在對話中產生同理心回應方面表現出優越的情緒準確性，同時透過他們的互動逐漸建立使用者的情緒特徵。其次，我們展示了使用者的情緒特徵如何可用作心理健康評估的可解釋標記。這些特徵可以與與不同心理疾病相關的典型情緒模式進行比較，提供了一種初步篩選和支持的新方法。

##### **MobileNetV2: A lightweight classification model for home-based sleep apnea screening**
2412.19967v1 by Hui Pan, Yanxuan Yu, Jilun Ye, Xu Zhang

This study proposes a novel lightweight neural network model leveraging
features extracted from electrocardiogram (ECG) and respiratory signals for
early OSA screening. ECG signals are used to generate feature spectrograms to
predict sleep stages, while respiratory signals are employed to detect
sleep-related breathing abnormalities. By integrating these predictions, the
method calculates the apnea-hypopnea index (AHI) with enhanced accuracy,
facilitating precise OSA diagnosis.
  The method was validated on three publicly available sleep apnea databases:
the Apnea-ECG database, the UCDDB dataset, and the MIT-BIH Polysomnographic
database. Results showed an overall OSA detection accuracy of 0.978,
highlighting the model's robustness. Respiratory event classification achieved
an accuracy of 0.969 and an area under the receiver operating characteristic
curve (ROC-AUC) of 0.98. For sleep stage classification, in UCDDB dataset, the
ROC-AUC exceeded 0.85 across all stages, with recall for Sleep reaching 0.906
and specificity for REM and Wake states at 0.956 and 0.937, respectively.
  This study underscores the potential of integrating lightweight neural
networks with multi-signal analysis for accurate, portable, and cost-effective
OSA screening, paving the way for broader adoption in home-based and wearable
health monitoring systems.

摘要：本研究提出了一個新穎的輕量級神經網路模型，利用從心電圖 (ECG) 和呼吸訊號中提取的特徵，進行早期 OSA 篩檢。ECG 訊號用於產生特徵頻譜圖，以預測睡眠階段，而呼吸訊號則用於偵測與睡眠相關的呼吸異常。透過整合這些預測，此方法計算出無呼吸低通氣指數 (AHI)，準確度更高，有助於精確診斷 OSA。
此方法已在三個公開的睡眠呼吸中止症資料庫中驗證：Apnea-ECG 資料庫、UCDDB 資料集和 MIT-BIH 多重睡眠生理檢查資料庫。結果顯示 OSA 整體偵測準確度為 0.978，突顯此模型的穩健性。呼吸事件分類的準確度達到 0.969，而受試者工作特性曲線 (ROC-AUC) 下面積為 0.98。對於睡眠階段分類，在 UCDDB 資料集中，ROC-AUC 在所有階段均超過 0.85，睡眠召回率達到 0.906，而 REM 和清醒狀態的特異性分別為 0.956 和 0.937。
本研究強調將輕量級神經網路與多訊號分析整合的潛力，可進行準確、可攜式且具成本效益的 OSA 篩檢，為家庭和穿戴式健康監控系統的廣泛採用鋪路。

##### **ErgoChat: a Visual Query System for the Ergonomic Risk Assessment of Construction Workers**
2412.19954v1 by Chao Fan, Qipei Mei, Xiaonan Wang, Xinming Li

In the construction sector, workers often endure prolonged periods of
high-intensity physical work and prolonged use of tools, resulting in injuries
and illnesses primarily linked to postural ergonomic risks, a longstanding
predominant health concern. To mitigate these risks, researchers have applied
various technological methods to identify the ergonomic risks that construction
workers face. However, traditional ergonomic risk assessment (ERA) techniques
do not offer interactive feedback. The rapidly developing vision-language
models (VLMs), capable of generating textual descriptions or answering
questions about ergonomic risks based on image inputs, have not yet received
widespread attention. This research introduces an interactive visual query
system tailored to assess the postural ergonomic risks of construction workers.
The system's capabilities include visual question answering (VQA), which
responds to visual queries regarding workers' exposure to postural ergonomic
risks, and image captioning (IC), which generates textual descriptions of these
risks from images. Additionally, this study proposes a dataset designed for
training and testing such methodologies. Systematic testing indicates that the
VQA functionality delivers an accuracy of 96.5%. Moreover, evaluations using
nine metrics for IC and assessments from human experts indicate that the
proposed approach surpasses the performance of a method using the same
architecture trained solely on generic datasets. This study sets a new
direction for future developments in interactive ERA using generative
artificial intelligence (AI) technologies.

摘要：在建築業中，工人經常忍受長時間高強度體力勞動和長時間使用工具，導致受傷和疾病，這些問題主要與姿勢人體工學風險有關，這是一個長期的主要健康問題。為了減輕這些風險，研究人員應用各種技術方法來識別建築工人面臨的人體工學風險。然而，傳統的人體工學風險評估 (ERA) 技術並不能提供互動式回饋。快速發展的視覺語言模型 (VLM) 能夠根據影像輸入產生文字描述或回答有關人體工學風險的問題，但尚未受到廣泛關注。本研究介紹了一個互動式視覺查詢系統，專門用於評估建築工人的姿勢人體工學風險。該系統的功能包括視覺問答 (VQA)，它可以回答有關工人接觸姿勢人體工學風險的視覺查詢，以及影像標題 (IC)，它可以根據影像產生這些風險的文字描述。此外，本研究提出了一個專門用於訓練和測試此類方法的資料集。系統性測試表明，VQA 功能的準確度為 96.5%。此外，使用九個 IC 指標進行的評估和來自人類專家的評估表明，所提出的方法超越了使用相同架構僅在通用資料集上訓練的方法的效能。本研究為使用生成式人工智慧 (AI) 技術的互動式 ERA 未來發展設定了一個新方向。

##### **An Integrated Optimization and Deep Learning Pipeline for Predicting Live Birth Success in IVF Using Feature Optimization and Transformer-Based Models**
2412.19696v1 by Arezoo Borji, Hossam Haick, Birgit Pohn, Antonia Graf, Jana Zakall, S M Ragib Shahriar Islam, Gernot Kronreif, Daniel Kovatchki, Heinz Strohmer, Sepideh Hatamikia

In vitro fertilization (IVF) is a widely utilized assisted reproductive
technology, yet predicting its success remains challenging due to the
multifaceted interplay of clinical, demographic, and procedural factors. This
study develops a robust artificial intelligence (AI) pipeline aimed at
predicting live birth outcomes in IVF treatments. The pipeline uses anonymized
data from 2010 to 2018, obtained from the Human Fertilization and Embryology
Authority (HFEA). We evaluated the prediction performance of live birth success
as a binary outcome (success/failure) by integrating different feature
selection methods, such as principal component analysis (PCA) and particle
swarm optimization (PSO), with different traditional machine learning-based
classifiers including random forest (RF) and decision tree, as well as deep
learning-based classifiers including custom transformer-based model and a tab
transformer model with an attention mechanism. Our research demonstrated that
the best performance was achieved by combining PSO for feature selection with
the TabTransformer-based deep learning model, yielding an accuracy of 99.50%
and an AUC of 99.96%, highlighting its significant performance to predict live
births. This study establishes a highly accurate AI pipeline for predicting
live birth outcomes in IVF, demonstrating its potential to enhance personalized
fertility treatments.

摘要：體外受精 (IVF) 是一種廣泛使用的輔助生殖技術，但由於臨床、人口統計和程序因素的多方面交互作用，預測其成功仍然具有挑戰性。本研究開發了一個強大的人工智慧 (AI) 管線，旨在預測 IVF 治療中的活產結果。該管線使用 2010 年至 2018 年的匿名數據，這些數據來自人類受精和胚胎學管理局 (HFEA)。我們通過整合不同的特徵選擇方法（例如主成分分析 (PCA) 和粒子群優化 (PSO)）以及不同的傳統機器學習分類器（包括隨機森林 (RF) 和決策樹），以及深度學習分類器（包括自定義Transformer模型和具有注意力機制的 Tab Transformer模型），來評估活產成功的預測性能，作為二元結果（成功/失敗）。我們的研究表明，通過將 PSO 用於特徵選擇與基於 TabTransformer 的深度學習模型相結合，可以獲得最佳性能，準確率達到 99.50%，AUC 達到 99.96%，突顯了其預測活產的顯著性能。本研究建立了一個高度準確的 AI 管線，用於預測 IVF 中的活產結果，展示了其增強個性化生育治療的潛力。

##### **A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation**
2412.19688v1 by Jana Zakall, Birgit Pohn, Antonia Graf, Daniel Kovatchki, Arezoo Borji, Ragib Shahriar Islam, Hossam Haick, Heinz Strohmer, Sepideh Hatamikia

Artificial intelligence (AI) has emerged as a powerful tool to enhance
decision-making and optimize treatment protocols in in vitro fertilization
(IVF). In particular, AI shows significant promise in supporting
decision-making during the ovarian stimulation phase of the IVF process. This
review evaluates studies focused on the applications of AI combined with
medical imaging in ovarian stimulation, examining methodologies, outcomes, and
current limitations. Our analysis of 13 studies on this topic reveals that,
reveal that while AI algorithms demonstrated notable potential in predicting
optimal hormonal dosages, trigger timing, and oocyte retrieval outcomes, the
medical imaging data utilized predominantly came from two-dimensional (2D)
ultrasound which mainly involved basic quantifications, such as follicle size
and number, with limited use of direct feature extraction or advanced image
analysis techniques. This points to an underexplored opportunity where advanced
image analysis approaches, such as deep learning, and more diverse imaging
modalities, like three-dimensional (3D) ultrasound, could unlock deeper
insights. Additionally, the lack of explainable AI (XAI) in most studies raises
concerns about the transparency and traceability of AI-driven decisions - key
factors for clinical adoption and trust. Furthermore, many studies relied on
single-center designs and small datasets, which limit the generalizability of
their findings. This review highlights the need for integrating advanced
imaging analysis techniques with explainable AI methodologies, as well as the
importance of leveraging multicenter collaborations and larger datasets.
Addressing these gaps has the potential to enhance ovarian stimulation
management, paving the way for efficient, personalized, and data-driven
treatment pathways that improve IVF outcomes.

摘要：人工智慧（AI）已成為增強體外受精（IVF）決策制定和優化治療方案的強大工具。特別是，AI 在支持 IVF 過程中卵巢刺激階段的決策制定方面顯示出顯著的前景。本綜述評估了專注於 AI 結合卵巢刺激中的醫學影像應用、檢驗方法、結果和當前限制的研究。我們對 13 項關於此主題的研究分析顯示，雖然 AI 演算法在預測最佳荷爾蒙劑量、觸發時機和卵子取出結果方面表現出顯著的潛力，但所利用的醫學影像數據主要來自於二次元（2D）超音波，而二次元超音波主要涉及基本量化，例如濾泡大小和數量，且有限使用直接特徵提取或進階影像分析技術。這指向一個尚未探索的機會，例如深度學習等進階影像分析方法，以及更多元的影像模式，例如三維（3D）超音波，可以解鎖更深入的見解。此外，大多數研究缺乏可解釋 AI（XAI），這引起了人們對 AI 驅動決策的透明度和可追溯性的擔憂，而透明度和可追溯性是臨床採用和信任的關鍵因素。此外，許多研究依賴於單中心設計和小型數據集，這限制了其發現的普遍性。本綜述強調了將進階影像分析技術與可解釋 AI 方法整合起來的必要性，以及利用多中心合作和大型數據集的重要性。解決這些差距有可能增強卵巢刺激管理，為有效、個人化和數據驅動的治療途徑鋪平道路，進而改善 IVF 結果。

##### **Disparate Model Performance and Stability in Machine Learning Clinical Support for Diabetes and Heart Diseases**
2412.19495v1 by Ioannis Bilionis, Ricardo C. Berrios, Luis Fernandez-Luque, Carlos Castillo

Machine Learning (ML) algorithms are vital for supporting clinical
decision-making in biomedical informatics. However, their predictive
performance can vary across demographic groups, often due to the
underrepresentation of historically marginalized populations in training
datasets. The investigation reveals widespread sex- and age-related inequities
in chronic disease datasets and their derived ML models. Thus, a novel
analytical framework is introduced, combining systematic arbitrariness with
traditional metrics like accuracy and data complexity. The analysis of data
from over 25,000 individuals with chronic diseases revealed mild sex-related
disparities, favoring predictive accuracy for males, and significant
age-related differences, with better accuracy for younger patients. Notably,
older patients showed inconsistent predictive accuracy across seven datasets,
linked to higher data complexity and lower model performance. This highlights
that representativeness in training data alone does not guarantee equitable
outcomes, and model arbitrariness must be addressed before deploying models in
clinical settings.

摘要：機器學習 (ML) 演算法對於支援生物醫學資訊學中的臨床決策至關重要。然而，其預測效能可能因人口統計群組而異，通常是因為在訓練資料集中歷史上被邊緣化的族群代表性不足。調查顯示，在慢性疾病資料集及其衍生的 ML 模型中，普遍存在與性別和年齡相關的不平等。因此，引進了一個新穎的分析架構，將系統性的任意性與傳統指標（例如準確度和資料複雜度）結合在一起。對來自 25,000 多名慢性病患者的資料進行分析，發現輕微的性別相關差異，有利於男性預測準確度，以及顯著的年齡相關差異，年輕患者的準確度較高。值得注意的是，老年患者在七個資料集中顯示出不一致的預測準確度，這與較高的資料複雜度和較低的模型效能有關。這突顯出訓練資料中的代表性並不能保證公平的結果，在臨床環境中部署模型之前必須解決模型的任意性。

##### **Semi-Supervised Learning from Small Annotated Data and Large Unlabeled Data for Fine-grained PICO Entity Recognition**
2412.19346v1 by Fangyi Chen, Gongbo Zhang, Yilu Fang, Yifan Peng, Chunhua Weng

Objective: Extracting PICO elements -- Participants, Intervention,
Comparison, and Outcomes -- from clinical trial literature is essential for
clinical evidence retrieval, appraisal, and synthesis. Existing approaches do
not distinguish the attributes of PICO entities. This study aims to develop a
named entity recognition (NER) model to extract PICO entities with fine
granularities.
  Materials and Methods: Using a corpus of 2,511 abstracts with PICO mentions
from 4 public datasets, we developed a semi-supervised method to facilitate the
training of a NER model, FinePICO, by combining limited annotated data of PICO
entities and abundant unlabeled data. For evaluation, we divided the entire
dataset into two subsets: a smaller group with annotations and a larger group
without annotations. We then established the theoretical lower and upper
performance bounds based on the performance of supervised learning models
trained solely on the small, annotated subset and on the entire set with
complete annotations, respectively. Finally, we evaluated FinePICO on both the
smaller annotated subset and the larger, initially unannotated subset. We
measured the performance of FinePICO using precision, recall, and F1.
  Results: Our method achieved precision/recall/F1 of 0.567/0.636/0.60,
respectively, using a small set of annotated samples, outperforming the
baseline model (F1: 0.437) by more than 16\%. The model demonstrates
generalizability to a different PICO framework and to another corpus, which
consistently outperforms the benchmark in diverse experimental settings
(p-value \textless0.001).
  Conclusion: This study contributes a generalizable and effective
semi-supervised approach to named entity recognition leveraging large unlabeled
data together with small, annotated data. It also initially supports
fine-grained PICO extraction.

摘要：<paragraph>目標：從臨床試驗文獻中萃取 PICO 元素（參與者、干預措施、比較和結果），對於臨床證據的檢索、評估和綜合至關重要。現有方法無法區分 PICO 實體的屬性。本研究旨在開發一個命名實體辨識 (NER) 模型，以精細粒度萃取 PICO 實體。
材料和方法：使用包含來自 4 個公開資料集的 2,511 篇摘要的語料庫，我們開發了一種半監督式方法，透過結合有限的 PICO 實體標註資料和豐富的未標註資料，來促進 NER 模型 FinePICO 的訓練。為了進行評估，我們將整個資料集分為兩個子集：一個較小的有標註群組和一個較大的無標註群組。然後，我們分別根據僅在小標註子集上訓練的監督式學習模型和在具有完整標註的整個集合上訓練的監督式學習模型的效能，建立理論上的下限和上限效能界線。最後，我們在較小的標註子集和較大的最初未標註子集上評估 FinePICO。我們使用準確度、召回率和 F1 來衡量 FinePICO 的效能。
結果：我們的模型使用一小組標註樣本，分別達到 0.567/0.636/0.60 的準確度/召回率/F1，比基線模型 (F1：0.437) 高出 16% 以上。該模型展示了對不同 PICO 架構和另一個語料庫的泛化性，在不同的實驗設定中始終優於基準 (p 值 \textless0.001)。
結論：本研究貢獻了一種可泛化且有效的半監督式方法，利用大量未標註資料和少量標註資料來進行命名實體辨識。它最初也支援精細粒度的 PICO 萃取。</paragraph>

##### **xSRL: Safety-Aware Explainable Reinforcement Learning -- Safety as a Product of Explainability**
2412.19311v1 by Risal Shahriar Shefin, Md Asifur Rahman, Thai Le, Sarra Alqahtani

Reinforcement learning (RL) has shown great promise in simulated
environments, such as games, where failures have minimal consequences. However,
the deployment of RL agents in real-world systems such as autonomous vehicles,
robotics, UAVs, and medical devices demands a higher level of safety and
transparency, particularly when facing adversarial threats. Safe RL algorithms
have been developed to address these concerns by optimizing both task
performance and safety constraints. However, errors are inevitable, and when
they occur, it is essential that the RL agents can also explain their actions
to human operators. This makes trust in the safety mechanisms of RL systems
crucial for effective deployment. Explainability plays a key role in building
this trust by providing clear, actionable insights into the agent's
decision-making process, ensuring that safety-critical decisions are well
understood. While machine learning (ML) has seen significant advances in
interpretability and visualization, explainability methods for RL remain
limited. Current tools fail to address the dynamic, sequential nature of RL and
its needs to balance task performance with safety constraints over time. The
re-purposing of traditional ML methods, such as saliency maps, is inadequate
for safety-critical RL applications where mistakes can result in severe
consequences. To bridge this gap, we propose xSRL, a framework that integrates
both local and global explanations to provide a comprehensive understanding of
RL agents' behavior. xSRL also enables developers to identify policy
vulnerabilities through adversarial attacks, offering tools to debug and patch
agents without retraining. Our experiments and user studies demonstrate xSRL's
effectiveness in increasing safety in RL systems, making them more reliable and
trustworthy for real-world deployment. Code is available at
https://github.com/risal-shefin/xSRL.

摘要：強化學習 (RL) 在模擬環境中展現出極大的潛力，例如遊戲，在這些環境中，失敗的後果很小。然而，在自動駕駛汽車、機器人、無人機和醫療設備等真實世界系統中部署 RL 代理需要更高的安全性與透明度，特別是在面對對抗性威脅時。安全的 RL 演算法已被開發出來，透過最佳化任務效能和安全限制來解決這些問題。然而，錯誤是不可避免的，當錯誤發生時，RL 代理也必須向人類操作員解釋其行為至關重要。這使得對 RL 系統的安全機制的信任對於有效部署至關重要。可解釋性在建立這種信任中扮演關鍵角色，透過提供對代理決策過程清晰且可行的見解，確保對安全至關重要的決策能被充分理解。雖然機器學習 (ML) 在可解釋性和可視化方面已取得顯著進展，但 RL 的可解釋性方法仍然有限。目前的工具無法解決 RL 的動態、順序性質，以及它需要隨著時間推移平衡任務效能與安全限制。重新利用傳統的 ML 方法，例如顯著性圖，對於安全至關重要的 RL 應用程式來說是不夠的，在這些應用程式中，錯誤可能導致嚴重的後果。為了彌補這一差距，我們提出了 xSRL，一個整合了局部和全局解釋的框架，以提供對 RL 代理行為的全面理解。xSRL 還使開發人員能夠透過對抗性攻擊來識別策略漏洞，提供在不重新訓練的情況下除錯和修補代理的工具。我們的實驗和使用者研究證明了 xSRL 在提高 RL 系統安全性的有效性，使其更可靠且更值得信賴，可部署於真實世界。程式碼可在 https://github.com/risal-shefin/xSRL 中取得。

##### **MEDEC: A Benchmark for Medical Error Detection and Correction in Clinical Notes**
2412.19260v2 by Asma Ben Abacha, Wen-wai Yim, Yujuan Fu, Zhaoyi Sun, Meliha Yetisgen, Fei Xia, Thomas Lin

Several studies showed that Large Language Models (LLMs) can answer medical
questions correctly, even outperforming the average human score in some medical
exams. However, to our knowledge, no study has been conducted to assess the
ability of language models to validate existing or generated medical text for
correctness and consistency. In this paper, we introduce MEDEC
(https://github.com/abachaa/MEDEC), the first publicly available benchmark for
medical error detection and correction in clinical notes, covering five types
of errors (Diagnosis, Management, Treatment, Pharmacotherapy, and Causal
Organism). MEDEC consists of 3,848 clinical texts, including 488 clinical notes
from three US hospital systems that were not previously seen by any LLM. The
dataset has been used for the MEDIQA-CORR shared task to evaluate seventeen
participating systems [Ben Abacha et al., 2024]. In this paper, we describe the
data creation methods and we evaluate recent LLMs (e.g., o1-preview, GPT-4,
Claude 3.5 Sonnet, and Gemini 2.0 Flash) for the tasks of detecting and
correcting medical errors requiring both medical knowledge and reasoning
capabilities. We also conducted a comparative study where two medical doctors
performed the same task on the MEDEC test set. The results showed that MEDEC is
a sufficiently challenging benchmark to assess the ability of models to
validate existing or generated notes and to correct medical errors. We also
found that although recent LLMs have a good performance in error detection and
correction, they are still outperformed by medical doctors in these tasks. We
discuss the potential factors behind this gap, the insights from our
experiments, the limitations of current evaluation metrics, and share potential
pointers for future research.

摘要：多項研究顯示，大型語言模型 (LLM) 能正確回答醫療問題，甚至在某些醫療考試中表現優於人類平均分數。然而，據我們所知，尚未有研究評估語言模型驗證現有或產生的醫療文本正確性和一致性的能力。在本文中，我們介紹 MEDEC (https://github.com/abachaa/MEDEC)，這是第一個公開的臨床筆記醫療錯誤偵測和修正基準，涵蓋五種類型的錯誤（診斷、管理、治療、藥物治療和致病原）。MEDEC 包含 3,848 個臨床文本，包括來自三個美國醫院系統的 488 個臨床筆記，這些筆記以前未曾被任何 LLM 看到。該資料集已用於 MEDIQA-CORR 共享任務，以評估十七個參與系統 [Ben Abacha 等，2024]。在本文中，我們描述了資料建立方法，並評估了近期 LLM（例如 o1-preview、GPT-4、Claude 3.5 Sonnet 和 Gemini 2.0 Flash）在偵測和修正醫療錯誤的任務上，這些任務需要醫療知識和推理能力。我們還進行了一項比較研究，其中兩位醫生在 MEDEC 測試集中執行相同的任務。結果顯示，MEDEC 是足夠具有挑戰性的基準，可以評估模型驗證現有或產生的筆記和修正醫療錯誤的能力。我們還發現，儘管近期 LLM 在錯誤偵測和修正方面表現良好，但在這些任務中仍不如醫生。我們討論了造成此差距的潛在因素、我們實驗的見解、當前評估指標的限制，並分享了未來研究的潛在指標。

##### **Leveraging Self-Training and Variational Autoencoder for Agitation Detection in People with Dementia Using Wearable Sensors**
2412.19254v1 by Abeer Badawi, Somayya Elmoghazy, Samira Choudhury, Khalid Elgazzar, Amer Burhan

Dementia is a neurodegenerative disorder that has been growing among elder
people over the past decades. This growth profoundly impacts the quality of
life for patients and caregivers due to the symptoms arising from it. Agitation
and aggression (AA) are some of the symptoms of people with severe dementia
(PwD) in long-term care or hospitals. AA not only causes discomfort but also
puts the patients or others at potential risk. Existing monitoring solutions
utilizing different wearable sensors integrated with Artificial Intelligence
(AI) offer a way to detect AA early enough for timely and adequate medical
intervention. However, most studies are limited by the availability of
accurately labeled datasets, which significantly affects the efficacy of such
solutions in real-world scenarios. This study presents a novel comprehensive
approach to detect AA in PwD using physiological data from the Empatica E4
wristbands. The research creates a diverse dataset, consisting of three
distinct datasets gathered from 14 participants across multiple hospitals in
Canada. These datasets have not been extensively explored due to their limited
labeling. We propose a novel approach employing self-training and a variational
autoencoder (VAE) to detect AA in PwD effectively. The proposed approach aims
to learn the representation of the features extracted using the VAE and then
uses a semi-supervised block to generate labels, classify events, and detect
AA. We demonstrate that combining Self-Training and Variational Autoencoder
mechanism significantly improves model performance in classifying AA in PwD.
Among the tested techniques, the XGBoost classifier achieved the highest
accuracy of 90.16\%. By effectively addressing the challenge of limited labeled
data, the proposed system not only learns new labels but also proves its
superiority in detecting AA.

摘要：失智症是一種神經退化性疾病，在過去的幾十年中在老年人中不斷增加。這種增長會對患者和照顧者的生活品質產生深遠的影響，因為它會產生症狀。躁動和攻擊性 (AA) 是重度失智症患者 (PwD) 在長期照護或醫院中的症狀之一。AA 不僅會造成不適，還會讓患者或他人面臨潛在風險。現有的監控解決方案利用與人工智慧 (AI) 整合的不同穿戴式感測器，提供一種方法來及早偵測 AA，以便及時且充分地進行醫療介入。然而，大多數研究都受到準確標記資料集可用性的限制，這會顯著影響此類解決方案在實際情況中的效能。本研究提出了一種新穎的綜合方法，使用來自 Empatica E4 腕帶的生理數據來偵測 PwD 中的 AA。該研究建立了一個多元的資料集，由來自加拿大多家醫院的 14 位參與者收集的三個不同資料集組成。由於標記有限，尚未廣泛探討這些資料集。我們提出了一種新穎的方法，採用自我訓練和變異自動編碼器 (VAE) 來有效偵測 PwD 中的 AA。所提出的方法旨在學習使用 VAE 萃取特徵的表示，然後使用半監督區塊來產生標籤、分類事件並偵測 AA。我們證明了將自我訓練和變異自動編碼器機制結合起來，可以顯著提升模型在對 PwD 中的 AA 進行分類時的效能。在測試的技術中，XGBoost 分類器達到了 90.16% 的最高準確度。透過有效地解決標記資料有限的挑戰，所提出的系統不僅學習了新的標籤，還證明了其在偵測 AA 方面的優越性。

##### **Evaluating Self-Supervised Learning in Medical Imaging: A Benchmark for Robustness, Generalizability, and Multi-Domain Impact**
2412.19124v1 by Valay Bundele, Oğuz Ata Çal, Bora Kargi, Karahan Sarıtaş, Kıvanç Tezören, Zohreh Ghaderi, Hendrik Lensch

Self-supervised learning (SSL) has emerged as a promising paradigm in medical
imaging, addressing the chronic challenge of limited labeled data in healthcare
settings. While SSL has shown impressive results, existing studies in the
medical domain are often limited in scope, focusing on specific datasets or
modalities, or evaluating only isolated aspects of model performance. This
fragmented evaluation approach poses a significant challenge, as models
deployed in critical medical settings must not only achieve high accuracy but
also demonstrate robust performance and generalizability across diverse
datasets and varying conditions. To address this gap, we present a
comprehensive evaluation of SSL methods within the medical domain, with a
particular focus on robustness and generalizability. Using the MedMNIST dataset
collection as a standardized benchmark, we evaluate 8 major SSL methods across
11 different medical datasets. Our study provides an in-depth analysis of model
performance in both in-domain scenarios and the detection of
out-of-distribution (OOD) samples, while exploring the effect of various
initialization strategies, model architectures, and multi-domain pre-training.
We further assess the generalizability of SSL methods through cross-dataset
evaluations and the in-domain performance with varying label proportions (1%,
10%, and 100%) to simulate real-world scenarios with limited supervision. We
hope this comprehensive benchmark helps practitioners and researchers make more
informed decisions when applying SSL methods to medical applications.

摘要：自我監督學習 (SSL) 已成為醫學影像中一個有前途的範例，用於解決醫療保健環境中標籤資料有限的長期挑戰。雖然 SSL 已展現令人印象深刻的結果，但醫學領域中的現有研究通常範圍有限，專注於特定資料集或方式，或僅評估模型效能的孤立面向。這種片段化的評估方式構成重大挑戰，因為在關鍵醫療環境中部署的模型不僅必須達到高準確度，還必須展現強健的效能和跨不同資料集和不同條件的一般化能力。為了解決這個差距，我們針對醫學領域中的 SSL 方法提出全面的評估，特別著重於強健性和一般化能力。使用 MedMNIST 資料集集合作為標準基準，我們在 11 個不同的醫學資料集上評估 8 種主要的 SSL 方法。我們的研究深入分析了模型在領域內情境和偵測分佈外 (OOD) 樣本中的效能，同時探索各種初始化策略、模型架構和多領域預訓練的影響。我們進一步透過跨資料集評估和在不同標籤比例 (1%、10% 和 100%) 下的領域內效能評估 SSL 方法的一般化能力，以模擬監督有限的真實世界情境。我們希望這個全面的基準能幫助從業人員和研究人員在將 SSL 方法應用於醫療應用時做出更明智的決策。

##### **Modality-Projection Universal Model for Comprehensive Full-Body Medical Imaging Segmentation**
2412.19026v1 by Yixin Chen, Lin Gao, Yajuan Gao, Rui Wang, Jingge Lian, Xiangxi Meng, Yanhua Duan, Leiying Chai, Hongbin Han, Zhaoping Cheng, Zhaoheng Xie

The integration of deep learning in medical imaging has shown great promise
for enhancing diagnostic, therapeutic, and research outcomes. However, applying
universal models across multiple modalities remains challenging due to the
inherent variability in data characteristics. This study aims to introduce and
evaluate a Modality Projection Universal Model (MPUM). MPUM employs a novel
modality-projection strategy, which allows the model to dynamically adjust its
parameters to optimize performance across different imaging modalities. The
MPUM demonstrated superior accuracy in identifying anatomical structures,
enabling precise quantification for improved clinical decision-making. It also
identifies metabolic associations within the brain-body axis, advancing
research on brain-body physiological correlations. Furthermore, MPUM's unique
controller-based convolution layer enables visualization of saliency maps
across all network layers, significantly enhancing the model's
interpretability.

摘要：深度學習在醫學影像中的整合已展現出極大的前景，用於增強診斷、治療和研究成果。然而，由於資料特性的內在變異性，在多種方式中應用通用模型仍然具有挑戰性。本研究旨在介紹和評估方式投影通用模型 (MPUM)。MPUM 採用一種新穎的方式投影策略，使模型能夠動態調整其參數，以優化不同影像方式的效能。MPUM 在識別解剖結構方面表現出優異的準確性，能夠進行精確量化，以改善臨床決策制定。它還識別出腦體軸內的代謝關聯，推動了對腦體生理相關性的研究。此外，MPUM 獨特的基於控制器的卷積層能夠視覺化所有網路層的顯著性圖，顯著增強了模型的可解釋性。

##### **MedHallBench: A New Benchmark for Assessing Hallucination in Medical Large Language Models**
2412.18947v1 by Kaiwen Zuo, Yirui Jiang

Medical Large Language Models (MLLMs) have demonstrated potential in
healthcare applications, yet their propensity for hallucinations -- generating
medically implausible or inaccurate information -- presents substantial risks
to patient care. This paper introduces MedHallBench, a comprehensive benchmark
framework for evaluating and mitigating hallucinations in MLLMs. Our
methodology integrates expert-validated medical case scenarios with established
medical databases to create a robust evaluation dataset. The framework employs
a sophisticated measurement system that combines automated ACHMI (Automatic
Caption Hallucination Measurement in Medical Imaging) scoring with rigorous
clinical expert evaluations and utilizes reinforcement learning methods to
achieve automatic annotation. Through an optimized reinforcement learning from
human feedback (RLHF) training pipeline specifically designed for medical
applications, MedHallBench enables thorough evaluation of MLLMs across diverse
clinical contexts while maintaining stringent accuracy standards. We conducted
comparative experiments involving various models, utilizing the benchmark to
establish a baseline for widely adopted large language models (LLMs). Our
findings indicate that ACHMI provides a more nuanced understanding of the
effects of hallucinations compared to traditional metrics, thereby highlighting
its advantages in hallucination assessment. This research establishes a
foundational framework for enhancing MLLMs' reliability in healthcare settings
and presents actionable strategies for addressing the critical challenge of AI
hallucinations in medical applications.

摘要：醫療大型語言模型 (MLLM) 已在醫療保健應用中展現其潛力，然而它們容易產生幻覺（產生醫學上不可能或不準確的資訊），對病患照護構成重大風險。本文介紹 MedHallBench，這是一個用於評估和減輕 MLLM 中幻覺的全面基準架構。我們的做法將專家驗證的醫療案例情境與既定的醫療資料庫整合，以建立一個強健的評估資料集。此架構採用一個精密的測量系統，結合自動化 ACHMI（醫學影像中的自動標題幻覺測量）評分與嚴謹的臨床專家評估，並利用強化學習方法來達成自動註解。MedHallBench 透過一個針對醫療應用特別設計的最佳化強化學習來自人類回饋 (RLHF) 訓練管線，在維持嚴格準確度標準的同時，能對 MLLM 進行徹底評估，涵蓋各種臨床情境。我們進行了比較實驗，涉及各種模型，利用基準來為廣泛採用的大型語言模型 (LLM) 建立基準。我們的研究結果顯示，與傳統指標相比，ACHMI 提供了對幻覺影響更細緻的理解，從而突顯其在幻覺評估中的優勢。本研究建立了一個基礎架構，用於提升 MLLM 在醫療保健環境中的可靠性，並提出了可行的策略，以應對醫療應用中 AI 幻覺的重大挑戰。

##### **HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs**
2412.18925v1 by Junying Chen, Zhenyang Cai, Ke Ji, Xidong Wang, Wanlong Liu, Rongsheng Wang, Jianye Hou, Benyou Wang

The breakthrough of OpenAI o1 highlights the potential of enhancing reasoning
to improve LLM. Yet, most research in reasoning has focused on mathematical
tasks, leaving domains like medicine underexplored. The medical domain, though
distinct from mathematics, also demands robust reasoning to provide reliable
answers, given the high standards of healthcare. However, verifying medical
reasoning is challenging, unlike those in mathematics. To address this, we
propose verifiable medical problems with a medical verifier to check the
correctness of model outputs. This verifiable nature enables advancements in
medical reasoning through a two-stage approach: (1) using the verifier to guide
the search for a complex reasoning trajectory for fine-tuning LLMs, (2)
applying reinforcement learning (RL) with verifier-based rewards to enhance
complex reasoning further. Finally, we introduce HuatuoGPT-o1, a medical LLM
capable of complex reasoning, which outperforms general and medical-specific
baselines using only 40K verifiable problems. Experiments show complex
reasoning improves medical problem-solving and benefits more from RL. We hope
our approach inspires advancements in reasoning across medical and other
specialized domains.

摘要：OpenAI o1 的突破突顯了增強推理以改善 LLM 的潛力。然而，推理的大部分研究都集中在數學任務上，而醫學等領域則尚未充分探討。儘管醫學領域與數學不同，但鑑於醫療保健的高標準，它也需要強大的推理能力才能提供可靠的答案。然而，驗證醫學推理具有挑戰性，這與數學中的推理不同。為了解決這個問題，我們提出了可驗證的醫學問題，並使用醫學驗證器來檢查模型輸出的正確性。這種可驗證的性質通過以下兩個階段的方法實現了醫學推理的進步：(1) 使用驗證器來指導尋找複雜推理軌跡以微調 LLM，(2) 應用強化學習 (RL) 和基於驗證器的獎勵來進一步增強複雜推理。最後，我們介紹了 HuatuoGPT-o1，這是一個具備複雜推理能力的醫學 LLM，它僅使用 40K 個可驗證問題就優於一般和特定於醫學的基準。實驗表明，複雜推理改進了醫學問題解決，並從 RL 中受益更多。我們希望我們的做法能激勵醫學和其他專業領域的推理進步。

##### **Comprehensive Study on Lumbar Disc Segmentation Techniques Using MRI Data**
2412.18894v1 by Serkan Salturk, Irem Sayin, Ibrahim Cem Balci, Taha Emre Pamukcu, Zafer Soydan, Huseyin Uvet

Lumbar disk segmentation is essential for diagnosing and curing spinal
disorders by enabling precise detection of disk boundaries in medical imaging.
The advent of deep learning has resulted in the development of many
segmentation methods, offering differing levels of accuracy and effectiveness.
This study assesses the effectiveness of several sophisticated deep learning
architectures, including ResUnext, Ef3 Net, UNet, and TransUNet, for lumbar
disk segmentation, highlighting key metrics like as Pixel Accuracy, Mean
Intersection over Union (Mean IoU), and Dice Coefficient. The findings indicate
that ResUnext achieved the highest segmentation accuracy, with a Pixel Accuracy
of 0.9492 and a Dice Coefficient of 0.8425, with TransUNet following closely
after. Filtering techniques somewhat enhanced the performance of most models,
particularly Dense UNet, improving stability and segmentation quality. The
findings underscore the efficacy of these models in lumbar disk segmentation
and highlight potential areas for improvement.

摘要：腰椎間盤分割對於診斷和治療脊椎疾病至關重要，因為它可以在醫學影像中精確檢測椎間盤的邊界。深度學習的出現導致了許多分割方法的開發，這些方法提供了不同程度的準確性和有效性。本研究評估了幾種複雜的深度學習架構的有效性，包括 ResUnext、Ef3 Net、UNet 和 TransUNet，用於腰椎間盤分割，重點關注關鍵指標，例如像素準確度、平均聯合交集（平均 IoU）和骰子係數。研究結果表明，ResUnext 達到了最高的分割準確度，像素準確度為 0.9492，骰子係數為 0.8425，緊隨其後的是 TransUNet。過濾技術在一定程度上提高了大多數模型的性能，特別是 Dense UNet，提高了穩定性和分割質量。研究結果強調了這些模型在腰椎間盤分割中的功效，並強調了潛在的改進領域。

##### **Whose Morality Do They Speak? Unraveling Cultural Bias in Multilingual Language Models**
2412.18863v1 by Meltem Aksoy

Large language models (LLMs) have become integral tools in diverse domains,
yet their moral reasoning capabilities across cultural and linguistic contexts
remain underexplored. This study investigates whether multilingual LLMs, such
as GPT-3.5-Turbo, GPT-4o-mini, Llama 3.1, and MistralNeMo, reflect culturally
specific moral values or impose dominant moral norms, particularly those rooted
in English. Using the updated Moral Foundations Questionnaire (MFQ-2) in eight
languages, Arabic, Farsi, English, Spanish, Japanese, Chinese, French, and
Russian, the study analyzes the models' adherence to six core moral
foundations: care, equality, proportionality, loyalty, authority, and purity.
The results reveal significant cultural and linguistic variability, challenging
the assumption of universal moral consistency in LLMs. Although some models
demonstrate adaptability to diverse contexts, others exhibit biases influenced
by the composition of the training data. These findings underscore the need for
culturally inclusive model development to improve fairness and trust in
multilingual AI systems.

摘要：大型語言模型 (LLM) 已成為各個領域不可或缺的工具，
但它們在不同文化和語言背景下的道德推理能力
仍未得到充分探討。本研究探討多語言 LLM，例如
GPT-3.5-Turbo、GPT-4o-mini、Llama 3.1 和 MistralNeMo，是否反映了特定文化的
道德價值觀或強加了主流道德規範，尤其是植根於英語的規範。使用更新的道德基礎問卷 (MFQ-2) 八種
語言，阿拉伯語、波斯語、英語、西班牙語、日語、中文、法語和
俄語，該研究分析了模型對六個核心道德的遵守情況
基礎：關懷、平等、相稱性、忠誠、權威和純潔。
結果揭示了顯著的文化和語言變異性，挑戰了 LLM 中普遍道德一致性的假設。儘管一些模型
證明了對不同背景的適應性，而另一些模型則表現出受訓練數據組成影響的偏見。這些發現強調了
文化包容模型開發的必要性，以提高公平性和對
多語言人工智能系統的信任。

##### **Unified Local and Global Attention Interaction Modeling for Vision Transformers**
2412.18778v1 by Tan Nguyen, Coy D. Heldermon, Corey Toler-Franklin

We present a novel method that extends the self-attention mechanism of a
vision transformer (ViT) for more accurate object detection across diverse
datasets. ViTs show strong capability for image understanding tasks such as
object detection, segmentation, and classification. This is due in part to
their ability to leverage global information from interactions among visual
tokens. However, the self-attention mechanism in ViTs are limited because they
do not allow visual tokens to exchange local or global information with
neighboring features before computing global attention. This is problematic
because tokens are treated in isolation when attending (matching) to other
tokens, and valuable spatial relationships are overlooked. This isolation is
further compounded by dot-product similarity operations that make tokens from
different semantic classes appear visually similar. To address these
limitations, we introduce two modifications to the traditional self-attention
framework; a novel aggressive convolution pooling strategy for local feature
mixing, and a new conceptual attention transformation to facilitate interaction
and feature exchange between semantic concepts. Experimental results
demonstrate that local and global information exchange among visual features
before self-attention significantly improves performance on challenging object
detection tasks and generalizes across multiple benchmark datasets and
challenging medical datasets. We publish source code and a novel dataset of
cancerous tumors (chimeric cell clusters).

摘要：<paragraph>我們提出了一種新穎的方法，它擴展了視覺轉換器 (ViT) 的自注意力機制，以在不同的資料集上進行更準確的物件偵測。ViT 顯示出強大的影像理解任務能力，例如物件偵測、分割和分類。這部分歸功於它們能夠利用視覺標記之間互動的全局資訊。然而，ViT 中的自注意力機制受到限制，因為它們不允許視覺標記在計算全局注意力之前與鄰近特徵交換局部或全局資訊。這是個問題，因為在對其他標記進行注意力（比對）時，標記會被孤立處理，而有價值的空間關係則被忽略。這種孤立進一步加劇了點積相似度運算，這使得來自不同語義類別的標記看起來在視覺上相似。為了解決這些限制，我們對傳統的自注意力架構進行了兩項修改；一種新穎的積極卷積池化策略，用於局部特徵混合，以及一種新的概念注意力轉換，以促進語義概念之間的互動和特徵交換。實驗結果表明，在自注意力之前視覺特徵之間的局部和全局資訊交換，顯著改善了具有挑戰性的物件偵測任務的效能，並在多個基準資料集和具有挑戰性的醫療資料集上進行概化。我們發布了癌症腫瘤（嵌合細胞簇）的原始碼和新穎資料集。</paragraph>

##### **Successes and Limitations of Object-centric Models at Compositional Generalisation**
2412.18743v1 by Milton L. Montero, Jeffrey S. Bowers, Gaurav Malhotra

In recent years, it has been shown empirically that standard disentangled
latent variable models do not support robust compositional learning in the
visual domain. Indeed, in spite of being designed with the goal of factorising
datasets into their constituent factors of variations, disentangled models show
extremely limited compositional generalisation capabilities. On the other hand,
object-centric architectures have shown promising compositional skills, albeit
these have 1) not been extensively tested and 2) experiments have been limited
to scene composition -- where models must generalise to novel combinations of
objects in a visual scene instead of novel combinations of object properties.
In this work, we show that these compositional generalisation skills extend to
this later setting. Furthermore, we present evidence pointing to the source of
these skills and how they can be improved through careful training. Finally, we
point to one important limitation that still exists which suggests new
directions of research.

摘要：近年来，经实证表明，标准解纠缠潜在变量模型不支持视觉领域的鲁棒组合学习。事实上，尽管解纠缠模型的设计目标是将数据集分解为其组成变化因子，但其组合泛化能力却极其有限。另一方面，以对象为中心的架构显示出有希望的组合技能，尽管这些技能 1) 尚未经过广泛测试，并且 2) 实验仅限于场景组合——其中模型必须泛化到视觉场景中对象的组合，而不是对象的组合属性。在这项工作中，我们表明这些组合泛化技能扩展到后一种设置。此外，我们提供了指向这些技能来源的证据，以及如何通过仔细训练来改进这些技能。最后，我们指出了仍然存在的一个重要限制，这提示了新的研究方向。

##### **SurvAttack: Black-Box Attack On Survival Models through Ontology-Informed EHR Perturbation**
2412.18706v1 by Mohsen Nayebi Kerdabadi, Arya Hadizadeh Moghaddam, Bin Liu, Mei Liu, Zijun Yao

Survival analysis (SA) models have been widely studied in mining electronic
health records (EHRs), particularly in forecasting the risk of critical
conditions for prioritizing high-risk patients. However, their vulnerability to
adversarial attacks is much less explored in the literature. Developing
black-box perturbation algorithms and evaluating their impact on
state-of-the-art survival models brings two benefits to medical applications.
First, it can effectively evaluate the robustness of models in pre-deployment
testing. Also, exploring how subtle perturbations would result in significantly
different outcomes can provide counterfactual insights into the clinical
interpretation of model prediction. In this work, we introduce SurvAttack, a
novel black-box adversarial attack framework leveraging subtle clinically
compatible, and semantically consistent perturbations on longitudinal EHRs to
degrade survival models' predictive performance. We specifically develop a
greedy algorithm to manipulate medical codes with various adversarial actions
throughout a patient's medical history. Then, these adversarial actions are
prioritized using a composite scoring strategy based on multi-aspect
perturbation quality, including saliency, perturbation stealthiness, and
clinical meaningfulness. The proposed adversarial EHR perturbation algorithm is
then used in an efficient SA-specific strategy to attack a survival model when
estimating the temporal ranking of survival urgency for patients. To
demonstrate the significance of our work, we conduct extensive experiments,
including baseline comparisons, explainability analysis, and case studies. The
experimental results affirm our research's effectiveness in illustrating the
vulnerabilities of patient survival models, model interpretation, and
ultimately contributing to healthcare quality.

摘要：<paragraph>存活分析 (SA) 模型已在電子健康紀錄 (EHR) 的探勘中廣泛研究，特別是在預測危急狀況的風險以優先處理高風險患者。然而，文獻中對於它們對抗攻擊的脆弱性探索較少。開發黑盒擾動演算法並評估它們對最新存活模型的影響，為醫療應用帶來兩項好處。首先，它可以在部署前測試中有效評估模型的穩健性。此外，探索細微的擾動如何導致顯著不同的結果，可以提供反事實的見解，以進行模型預測的臨床解釋。在這項工作中，我們介紹了 SurvAttack，一個新穎的黑盒對抗攻擊架構，利用在縱向 EHR 上細微的臨床相容且語義一致的擾動，來降低存活模型的預測效能。我們特別開發了一個貪婪演算法，以各種對抗動作來操縱病歷中的醫療碼。然後，使用基於多方面擾動品質（包括顯著性、擾動隱蔽性和臨床意義）的複合評分策略，對這些對抗動作進行優先排序。然後將提出的對抗性 EHR 擾動演算法用於特定 SA 的有效策略中，以在估計患者存活緊急性的時間排序時攻擊存活模型。為了證明我們工作的意義，我們進行了廣泛的實驗，包括基線比較、可解釋性分析和案例研究。實驗結果肯定了我們的研究在說明患者存活模型、模型解釋的脆弱性，並最終有助於醫療保健品質方面的有效性。</paragraph>

##### **A Review of Latent Representation Models in Neuroimaging**
2412.19844v1 by C. Vázquez-García, F. J. Martínez-Murcia, F. Segovia Román, Juan M. Górriz

Neuroimaging data, particularly from techniques like MRI or PET, offer rich
but complex information about brain structure and activity. To manage this
complexity, latent representation models - such as Autoencoders, Generative
Adversarial Networks (GANs), and Latent Diffusion Models (LDMs) - are
increasingly applied. These models are designed to reduce high-dimensional
neuroimaging data to lower-dimensional latent spaces, where key patterns and
variations related to brain function can be identified. By modeling these
latent spaces, researchers hope to gain insights into the biology and function
of the brain, including how its structure changes with age or disease, or how
it encodes sensory information, predicts and adapts to new inputs. This review
discusses how these models are used for clinical applications, like disease
diagnosis and progression monitoring, but also for exploring fundamental brain
mechanisms such as active inference and predictive coding. These approaches
provide a powerful tool for both understanding and simulating the brain's
complex computational tasks, potentially advancing our knowledge of cognition,
perception, and neural disorders.

摘要：神經影像資料，特別是來自於 MRI 或 PET 等技術，提供豐富但複雜的大腦結構與活動資訊。為了處理這種複雜性，潛在表徵模型（例如自動編碼器、生成對抗網路 (GAN) 和潛在擴散模型 (LDM)）的應用日益增加。這些模型旨在將高維度神經影像資料降維至低維度潛在空間，在其中可以識別與大腦功能相關的主要模式和變化。透過對這些潛在空間建模，研究人員希望深入了解大腦的生物學和功能，包括其結構如何隨著年齡或疾病而改變，或如何編碼感官資訊、預測和適應新的輸入。本篇評論探討這些模型如何用於臨床應用，例如疾病診斷和進程監控，以及探索主動推論和預測編碼等基本大腦機制。這些方法提供了一個強大的工具，可以用於理解和模擬大腦複雜的運算任務，並有可能增進我們對認知、知覺和神經疾病的認識。

##### **DiTCtrl: Exploring Attention Control in Multi-Modal Diffusion Transformer for Tuning-Free Multi-Prompt Longer Video Generation**
2412.18597v1 by Minghong Cai, Xiaodong Cun, Xiaoyu Li, Wenze Liu, Zhaoyang Zhang, Yong Zhang, Ying Shan, Xiangyu Yue

Sora-like video generation models have achieved remarkable progress with a
Multi-Modal Diffusion Transformer MM-DiT architecture. However, the current
video generation models predominantly focus on single-prompt, struggling to
generate coherent scenes with multiple sequential prompts that better reflect
real-world dynamic scenarios. While some pioneering works have explored
multi-prompt video generation, they face significant challenges including
strict training data requirements, weak prompt following, and unnatural
transitions. To address these problems, we propose DiTCtrl, a training-free
multi-prompt video generation method under MM-DiT architectures for the first
time. Our key idea is to take the multi-prompt video generation task as
temporal video editing with smooth transitions. To achieve this goal, we first
analyze MM-DiT's attention mechanism, finding that the 3D full attention
behaves similarly to that of the cross/self-attention blocks in the UNet-like
diffusion models, enabling mask-guided precise semantic control across
different prompts with attention sharing for multi-prompt video generation.
Based on our careful design, the video generated by DiTCtrl achieves smooth
transitions and consistent object motion given multiple sequential prompts
without additional training. Besides, we also present MPVBench, a new benchmark
specially designed for multi-prompt video generation to evaluate the
performance of multi-prompt generation. Extensive experiments demonstrate that
our method achieves state-of-the-art performance without additional training.

摘要：類 Sora 的影片生成模型在多模態擴散Transformer MM-DiT 架構中取得顯著進展。然而，目前的影片生成模型主要專注於單一提示，難以生成包含多個循序提示的連貫場景，而這些提示更能反映真實世界的動態場景。儘管一些開創性的作品已探索多提示影片生成，但它們面臨嚴峻的挑戰，包括嚴格的訓練資料需求、提示追蹤能力不佳以及不自然的轉換。為了解決這些問題，我們提出 DiTCtrl，這是一種在 MM-DiT 架構下首次使用的免訓練多提示影片生成方法。我們的關鍵想法是將多提示影片生成任務視為具有平滑轉換的時序影片編輯。為了達成此目標，我們首先分析 MM-DiT 的注意力機制，發現 3D 全注意力與 UNet 類擴散模型中的交叉/自我注意力區塊有類似的行為，這使得我們能夠透過注意力共享進行遮罩導引的精確語意控制，以進行多提示影片生成。根據我們的精細設計，DiTCtrl 生成的影片在給定多個循序提示的情況下，可以實現平滑的轉換和一致的物件動作，而不需要額外的訓練。此外，我們還提出了 MPVBench，這是一個專門設計用於多提示影片生成的新基準，用於評估多提示生成的效果。廣泛的實驗證明，我們的方法在沒有額外訓練的情況下，達到了最先進的效能。

##### **Advancing Deformable Medical Image Registration with Multi-axis Cross-covariance Attention**
2412.18545v1 by Mingyuan Meng, Michael Fulham, Lei Bi, Jinman Kim

Deformable image registration is a fundamental requirement for medical image
analysis. Recently, transformers have been widely used in deep learning-based
registration methods for their ability to capture long-range dependency via
self-attention (SA). However, the high computation and memory loads of SA
(growing quadratically with the spatial resolution) hinder transformers from
processing subtle textural information in high-resolution image features, e.g.,
at the full and half image resolutions. This limits deformable registration as
the high-resolution textural information is crucial for finding precise
pixel-wise correspondence between subtle anatomical structures.
Cross-covariance Attention (XCA), as a "transposed" version of SA that operates
across feature channels, has complexity growing linearly with the spatial
resolution, providing the feasibility of capturing long-range dependency among
high-resolution image features. However, existing XCA-based transformers merely
capture coarse global long-range dependency, which are unsuitable for
deformable image registration relying primarily on fine-grained local
correspondence. In this study, we propose to improve existing deep
learning-based registration methods by embedding a new XCA mechanism. To this
end, we design an XCA-based transformer block optimized for deformable medical
image registration, named Multi-Axis XCA (MAXCA). Our MAXCA serves as a general
network block that can be embedded into various registration network
architectures. It can capture both global and local long-range dependency among
high-resolution image features by applying regional and dilated XCA in parallel
via a multi-axis design. Extensive experiments on two well-benchmarked
inter-/intra-patient registration tasks with seven public medical datasets
demonstrate that our MAXCA block enables state-of-the-art registration
performance.

摘要：可變形影像配準是醫學影像分析的基本需求。最近，Transformer已廣泛用於基於深度學習的配準方法，因為它們能透過自我注意 (SA) 擷取長程依賴性。然而，SA 的高運算和記憶體負載（隨著空間解析度呈二次成長）會阻礙Transformer處理高解析度影像特徵中的細微紋理資訊，例如在完整和半影像解析度中。這限制了可變形配準，因為高解析度紋理資訊對於在細微解剖結構之間找到精確的像素對應至關重要。跨協方差注意 (XCA) 作為 SA 的「轉置」版本，其運作跨特徵通道，複雜度隨著空間解析度呈線性成長，提供擷取高解析度影像特徵之間長程依賴性的可行性。然而，現有的基於 XCA 的Transformer僅擷取粗略的全局長程依賴性，這不適合主要依賴細粒度局部對應的可變形影像配準。在本研究中，我們提出透過嵌入新的 XCA 機制來改善現有的基於深度學習的配準方法。為此，我們設計了一個針對可變形醫學影像配準最佳化的基於 XCA 的Transformer區塊，稱為多軸 XCA (MAXCA)。我們的 MAXCA 是一個通用網路區塊，可以嵌入到各種配準網路架構中。它可以透過多軸設計並行應用區域和膨脹的 XCA，來擷取高解析度影像特徵之間的全局和局部長程依賴性。在兩個廣泛基準化的患者間/患者內配準任務中，使用七個公共醫學資料集進行的廣泛實驗證明，我們的 MAXCA 區塊能實現最先進的配準效能。

##### **Multi-Agent Norm Perception and Induction in Distributed Healthcare**
2412.18454v1 by Chao Li, Olga Petruchik, Elizaveta Grishanina, Sergey Kovalchuk

This paper presents a Multi-Agent Norm Perception and Induction Learning
Model aimed at facilitating the integration of autonomous agent systems into
distributed healthcare environments through dynamic interaction processes. The
nature of the medical norm system and its sharing channels necessitates
distinct approaches for Multi-Agent Systems to learn two types of norms.
Building on this foundation, the model enables agents to simultaneously learn
descriptive norms, which capture collective tendencies, and prescriptive norms,
which dictate ideal behaviors. Through parameterized mixed probability density
models and practice-enhanced Markov games, the multi-agent system perceives
descriptive norms in dynamic interactions and captures emergent prescriptive
norms. We conducted experiments using a dataset from a neurological medical
center spanning from 2016 to 2020.

摘要：本文提出了一個多主體規範感知與歸納學習模型，旨在透過動態互動程序促進自主主體系統整合到分散式醫療保健環境中。醫療規範系統的本質及其共享管道需要不同的方法，讓多主體系統學習兩種規範。基於此基礎，該模型讓主體能夠同時學習描述性規範（捕捉集體傾向）和規範性規範（規定理想行為）。透過參數化混合機率密度模型和實務增強馬可夫博弈，多主體系統在動態互動中感知描述性規範，並捕捉新興的規範性規範。我們使用 2016 年至 2020 年期間一個神經醫學醫療中心的数据集進行了實驗。

##### **Research on the Proximity Relationships of Psychosomatic Disease Knowledge Graph Modules Extracted by Large Language Models**
2412.18419v1 by Zihan Zhou, Ziyi Zeng, Wenhao Jiang, Yihui Zhu, Jiaxin Mao, Yonggui Yuan, Min Xia, Shubin Zhao, Mengyu Yao, Yunqian Chen

As social changes accelerate, the incidence of psychosomatic disorders has
significantly increased, becoming a major challenge in global health issues.
This necessitates an innovative knowledge system and analytical methods to aid
in diagnosis and treatment. Here, we establish the ontology model and entity
types, using the BERT model and LoRA-tuned LLM for named entity recognition,
constructing the knowledge graph with 9668 triples. Next, by analyzing the
network distances between disease, symptom, and drug modules, it was found that
closer network distances among diseases can predict greater similarities in
their clinical manifestations, treatment approaches, and psychological
mechanisms, and closer distances between symptoms indicate that they are more
likely to co-occur. Lastly, by comparing the proximity d and proximity z score,
it was shown that symptom-disease pairs in primary diagnostic relationships
have a stronger association and are of higher referential value than those in
diagnostic relationships. The research results revealed the potential
connections between diseases, co-occurring symptoms, and similarities in
treatment strategies, providing new perspectives for the diagnosis and
treatment of psychosomatic disorders and valuable information for future mental
health research and practice.

摘要：隨著社會變遷加速，心身疾病發生率顯著增加，成為全球衛生議題上的重大挑戰。這需要創新的知識體系與分析方法，以協助診斷與治療。在此，我們建立了本体模型與實體類型，利用 BERT 模型與 LoRA 調校過的 LLM 進行命名實體辨識，建構出 9668 個三元組的知識圖譜。接著，透過分析疾病、症狀、藥物模組間的網路距離，發現疾病間較近的網路距離，可預測其臨床表現、治療方式、心理機轉的相似性較高；而症狀間距離較近，則表示較可能共現。最後，透過比較接近度 d 與接近度 z 分數，發現初次診斷關係中的症狀-疾病對，其關聯性較強、參考價值較高，優於診斷關係中的症狀-疾病對。研究成果揭示了疾病、共現症狀、治療策略間的潛在關聯，為心身疾病的診斷與治療提供了新的觀點，也為未來心理健康研究與實務提供了寶貴的資訊。

##### **Unveiling the Threat of Fraud Gangs to Graph Neural Networks: Multi-Target Graph Injection Attacks against GNN-Based Fraud Detectors**
2412.18370v1 by Jinhyeok Choi, Heehyeon Kim, Joyce Jiyoung Whang

Graph neural networks (GNNs) have emerged as an effective tool for fraud
detection, identifying fraudulent users, and uncovering malicious behaviors.
However, attacks against GNN-based fraud detectors and their risks have rarely
been studied, thereby leaving potential threats unaddressed. Recent findings
suggest that frauds are increasingly organized as gangs or groups. In this
work, we design attack scenarios where fraud gangs aim to make their fraud
nodes misclassified as benign by camouflaging their illicit activities in
collusion. Based on these scenarios, we study adversarial attacks against
GNN-based fraud detectors by simulating attacks of fraud gangs in three
real-world fraud cases: spam reviews, fake news, and medical insurance frauds.
We define these attacks as multi-target graph injection attacks and propose
MonTi, a transformer-based Multi-target one-Time graph injection attack model.
MonTi simultaneously generates attributes and edges of all attack nodes with a
transformer encoder, capturing interdependencies between attributes and edges
more effectively than most existing graph injection attack methods that
generate these elements sequentially. Additionally, MonTi adaptively allocates
the degree budget for each attack node to explore diverse injection structures
involving target, candidate, and attack nodes, unlike existing methods that fix
the degree budget across all attack nodes. Experiments show that MonTi
outperforms the state-of-the-art graph injection attack methods on five
real-world graphs.

摘要：圖形神經網路 (GNN) 已成為一種有效的欺詐偵測工具，用於識別欺詐使用者並揭露惡意行為。然而，針對基於 GNN 的欺詐偵測器及其風險的攻擊鮮少受到研究，因此潛在威脅未獲得解決。最近的研究結果顯示，欺詐行為正日益以幫派或團體的方式組織起來。在這項研究中，我們設計了攻擊場景，其中欺詐幫派旨在透過共謀偽裝其非法活動，讓他們的欺詐節點被誤分類為良性。基於這些場景，我們透過模擬三起真實世界的欺詐案件（垃圾評論、假新聞和醫療保險欺詐）中欺詐幫派的攻擊，研究針對基於 GNN 的欺詐偵測器的對抗性攻擊。我們將這些攻擊定義為多目標圖形注入攻擊，並提出 MonTi，一種基於 Transformer 的多目標一次性圖形注入攻擊模型。MonTi 同時利用 Transformer 編碼器生成所有攻擊節點的屬性和邊緣，比大多數現有的圖形注入攻擊方法更有效地捕捉屬性和邊緣之間的相互依賴性，這些方法會依序生成這些元素。此外，與固定所有攻擊節點的度數預算的現有方法不同，MonTi 會自適應地分配每個攻擊節點的度數預算，以探索涉及目標、候選和攻擊節點的多樣化注入結構。實驗顯示，MonTi 在五個真實世界的圖形上優於最先進的圖形注入攻擊方法。

##### **Real-world Deployment and Evaluation of PErioperative AI CHatbot (PEACH) -- a Large Language Model Chatbot for Perioperative Medicine**
2412.18096v1 by Yu He Ke, Liyuan Jin, Kabilan Elangovan, Bryan Wen Xi Ong, Chin Yang Oh, Jacqueline Sim, Kenny Wei-Tsen Loh, Chai Rick Soh, Jonathan Ming Hua Cheng, Aaron Kwang Yang Lee, Daniel Shu Wei Ting, Nan Liu, Hairil Rizal Abdullah

Large Language Models (LLMs) are emerging as powerful tools in healthcare,
particularly for complex, domain-specific tasks. This study describes the
development and evaluation of the PErioperative AI CHatbot (PEACH), a secure
LLM-based system integrated with local perioperative guidelines to support
preoperative clinical decision-making. PEACH was embedded with 35 institutional
perioperative protocols in the secure Claude 3.5 Sonet LLM framework within
Pair Chat (developed by Singapore Government) and tested in a silent deployment
with real-world data. Accuracy, safety, and usability were assessed. Deviations
and hallucinations were categorized based on potential harm, and user feedback
was evaluated using the Technology Acceptance Model (TAM). Updates were made
after the initial silent deployment to amend one protocol.
  In 240 real-world clinical iterations, PEACH achieved a first-generation
accuracy of 97.5% (78/80) and an overall accuracy of 96.7% (232/240) across
three iterations. The updated PEACH demonstrated improved accuracy of 97.9%
(235/240), with a statistically significant difference from the null hypothesis
of 95% accuracy (p = 0.018, 95% CI: 0.952-0.991). Minimal hallucinations and
deviations were observed (both 1/240 and 2/240, respectively). Clinicians
reported that PEACH expedited decisions in 95% of cases, and inter-rater
reliability ranged from kappa 0.772-0.893 within PEACH and 0.610-0.784 among
attendings.
  PEACH is an accurate, adaptable tool that enhances consistency and efficiency
in perioperative decision-making. Future research should explore its
scalability across specialties and its impact on clinical outcomes.

摘要：大型語言模型 (LLM) 正成為醫療保健領域強大的工具，特別適用於複雜的特定領域任務。本研究描述了圍手術期 AI 聊天機器人 (PEACH) 的開發和評估，這是一個安全的 LLM 基礎系統，與本地的圍手術期準則整合，以支援術前臨床決策制定。PEACH 嵌入 35 個機構圍手術期協定，在新加坡政府開發的 Pair Chat 中，採用安全的 Claude 3.5 Sonet LLM 架構，並在靜默部署中使用真實世界資料進行測試。評估了準確性、安全性及可用性。偏差和幻覺依潛在危害進行分類，並使用技術接受模型 (TAM) 評估使用者回饋。在最初的靜默部署後，進行更新以修正一個協定。
  在 240 個真實世界的臨床迭代中，PEACH 在三個迭代中取得 97.5% (78/80) 的第一代準確性，以及 96.7% (232/240) 的整體準確性。更新後的 PEACH 展示出 97.9% (235/240) 的準確性提升，與 95% 準確性的空假設有統計上的顯著差異 (p = 0.018，95% CI：0.952-0.991)。觀察到最小的幻覺和偏差 (分別為 1/240 和 2/240)。臨床醫生回報 PEACH 在 95% 的案例中加速了決策，而評分者間信度在 PEACH 內介於 kappa 0.772-0.893，在主治醫師之間介於 0.610-0.784。
  PEACH 是一個準確且適應性強的工具，可增進圍手術期決策制定的一致性和效率。未來的研究應探索其跨專業的可擴展性，以及其對臨床結果的影響。

##### **Aligning AI Research with the Needs of Clinical Coding Workflows: Eight Recommendations Based on US Data Analysis and Critical Review**
2412.18043v1 by Yidong Gan, Maciej Rybinski, Ben Hachey, Jonathan K. Kummerfeld

Clinical coding is crucial for healthcare billing and data analysis. Manual
clinical coding is labour-intensive and error-prone, which has motivated
research towards full automation of the process. However, our analysis, based
on US English electronic health records and automated coding research using
these records, shows that widely used evaluation methods are not aligned with
real clinical contexts. For example, evaluations that focus on the top 50 most
common codes are an oversimplification, as there are thousands of codes used in
practice. This position paper aims to align AI coding research more closely
with practical challenges of clinical coding. Based on our analysis, we offer
eight specific recommendations, suggesting ways to improve current evaluation
methods. Additionally, we propose new AI-based methods beyond automated coding,
suggesting alternative approaches to assist clinical coders in their workflows.

摘要：臨床編碼對於醫療保健計費和數據分析至關重要。手動臨床編碼勞力密集且容易出錯，這促使研究朝向流程的全面自動化。然而，我們的分析基於美國英文電子健康記錄和使用這些記錄的自動編碼研究，顯示廣泛使用的評估方法與實際臨床背景不符。例如，專注於前 50 個最常見代碼的評估過於簡化，因為實務上使用了數千個代碼。本立場文件旨在讓 AI 編碼研究更貼近臨床編碼的實際挑戰。根據我們的分析，我們提出八項具體建議，提出改善目前評估方法的方法。此外，我們提出超越自動編碼的新 AI 方法，提出協助臨床編碼人員進行工作流程的替代方法。

##### **A Grounded Observer Framework for Establishing Guardrails for Foundation Models in Socially Sensitive Domains**
2412.18639v1 by Rebecca Ramnauth, Dražen Brščić, Brian Scassellati

As foundation models increasingly permeate sensitive domains such as
healthcare, finance, and mental health, ensuring their behavior meets desired
outcomes and social expectations becomes critical. Given the complexities of
these high-dimensional models, traditional techniques for constraining agent
behavior, which typically rely on low-dimensional, discrete state and action
spaces, cannot be directly applied. Drawing inspiration from robotic action
selection techniques, we propose the grounded observer framework for
constraining foundation model behavior that offers both behavioral guarantees
and real-time variability. This method leverages real-time assessment of
low-level behavioral characteristics to dynamically adjust model actions and
provide contextual feedback. To demonstrate this, we develop a system capable
of sustaining contextually appropriate, casual conversations ("small talk"),
which we then apply to a robot for novel, unscripted interactions with humans.
Finally, we discuss potential applications of the framework for other social
contexts and areas for further research.

摘要：隨著基礎模型日益滲透醫療保健、金融和心理健康等敏感領域，確保其行為符合預期的結果和社會期望至關重要。鑑於這些高維度模型的複雜性，傳統的約束代理行為技術（通常依賴於低維度、離散狀態和動作空間）無法直接應用。從機器人動作選擇技術中汲取靈感，我們提出了基礎模型行為約束的基礎觀察者框架，該框架既提供了行為保證，又提供了實時變異性。此方法利用對低層行為特徵的實時評估，來動態調整模型動作並提供情境回饋。為了證明這一點，我們開發了一個系統，能夠維持適當的語境、隨意的對話（「閒聊」），然後我們將其應用於機器人，以進行與人類的新穎、非腳本互動。最後，我們討論了該框架在其他社會環境中的潛在應用，以及進一步研究的領域。

##### **Improving Sickle Cell Disease Classification: A Fusion of Conventional Classifiers, Segmented Images, and Convolutional Neural Networks**
2412.17975v1 by Victor Júnio Alcântara Cardoso, Rodrigo Moreira, João Fernando Mari, Larissa Ferreira Rodrigues Moreira

Sickle cell anemia, which is characterized by abnormal erythrocyte
morphology, can be detected using microscopic images. Computational techniques
in medicine enhance the diagnosis and treatment efficiency. However, many
computational techniques, particularly those based on Convolutional Neural
Networks (CNNs), require high resources and time for training, highlighting the
research opportunities in methods with low computational overhead. In this
paper, we propose a novel approach combining conventional classifiers,
segmented images, and CNNs for the automated classification of sickle cell
disease. We evaluated the impact of segmented images on classification,
providing insight into deep learning integration. Our results demonstrate that
using segmented images and CNN features with an SVM achieves an accuracy of
96.80%. This finding is relevant for computationally efficient scenarios,
paving the way for future research and advancements in medical-image analysis.

摘要：镰状细胞贫血症的特征是红细胞形态异常，可通过显微镜图像检测。医学中的计算技术提高了诊断和治疗效率。然而，许多计算技术，特别是基于卷积神经网络 (CNN) 的技术，需要大量的资源和时间进行训练，这突出了低计算开销方法的研究机会。在本文中，我们提出了一种新颖的方法，结合传统分类器、分割图像和 CNN，用于镰状细胞病的自动化分类。我们评估了分割图像对分类的影响，提供了对深度学习集成的见解。我们的结果表明，使用分割图像和 CNN 特征与 SVM 一起使用可实现 96.80% 的准确率。这一发现与计算效率高的场景相关，为医学图像分析的未来研究和进步铺平了道路。

##### **A Novel Approach to Balance Convenience and Nutrition in Meals With Long-Term Group Recommendations and Reasoning on Multimodal Recipes and its Implementation in BEACON**
2412.17910v1 by Vansh Nagpal, Siva Likitha Valluru, Kausik Lakkaraju, Nitin Gupta, Zach Abdulrahman, Andrew Davison, Biplav Srivastava

"A common decision made by people, whether healthy or with health conditions,
is choosing meals like breakfast, lunch, and dinner, comprising combinations of
foods for appetizer, main course, side dishes, desserts, and beverages. Often,
this decision involves tradeoffs between nutritious choices (e.g., salt and
sugar levels, nutrition content) and convenience (e.g., cost and accessibility,
cuisine type, food source type). We present a data-driven solution for meal
recommendations that considers customizable meal configurations and time
horizons. This solution balances user preferences while accounting for food
constituents and cooking processes. Our contributions include introducing
goodness measures, a recipe conversion method from text to the recently
introduced multimodal rich recipe representation (R3) format, learning methods
using contextual bandits that show promising preliminary results, and the
prototype, usage-inspired, BEACON system."

摘要：「無論是健康或患有健康狀況的人，都會做出的常見決定，
是選擇像早餐、午餐和晚餐等餐點，包括開胃菜、主菜、配菜、甜點和飲料的組合。通常，
這個決定涉及營養選擇（例如鹽和糖的含量、營養成分）和便利性（例如成本和可取得性、菜系類型、食物來源類型）之間的權衡。我們提出一個資料驅動的解決方案，用於餐點推薦，它考量了可自訂的餐點配置和時間範圍。這個解決方案在考量食物成分和烹飪過程的同時，平衡了使用者的喜好。我們的貢獻包括引進優良措施、從文字到最近推出的多模式豐富食譜表示法 (R3) 格式的食譜轉換方法、使用情境強盜的學習方法，這些方法顯示出有希望的初步結果，以及原型、使用靈感的 BEACON 系統。」

##### **Detecting anxiety and depression in dialogues: a multi-label and explainable approach**
2412.17651v1 by Francisco de Arriba-Pérez, Silvia García-Méndez

Anxiety and depression are the most common mental health issues worldwide,
affecting a non-negligible part of the population. Accordingly, stakeholders,
including governments' health systems, are developing new strategies to promote
early detection and prevention from a holistic perspective (i.e., addressing
several disorders simultaneously). In this work, an entirely novel system for
the multi-label classification of anxiety and depression is proposed. The input
data consists of dialogues from user interactions with an assistant chatbot.
Another relevant contribution lies in using Large Language Models (LLMs) for
feature extraction, provided the complexity and variability of language. The
combination of LLMs, given their high capability for language understanding,
and Machine Learning (ML) models, provided their contextual knowledge about the
classification problem thanks to the labeled data, constitute a promising
approach towards mental health assessment. To promote the solution's
trustworthiness, reliability, and accountability, explainability descriptions
of the model's decision are provided in a graphical dashboard. Experimental
results on a real dataset attain 90 % accuracy, improving those in the prior
literature. The ultimate objective is to contribute in an accessible and
scalable way before formal treatment occurs in the healthcare systems.

摘要：焦慮和憂鬱症是全球最常見的心理健康問題，
影響著人口中不可忽視的一部分。因此，利益相關者，
包括政府的衛生系統，正在制定新的策略來促進
從整體角度及早發現和預防（即同時解決
多種疾病）。在這項工作中，一個完全新穎的系統
用於焦慮和憂鬱症的多標籤分類。輸入
資料包含使用者與助理聊天機器人互動的對話。
另一個相關的貢獻在於使用大型語言模型 (LLM) 進行
特徵萃取，提供了語言的複雜性和可變性。LLM 的組合，
由於它們對語言理解的高能力，以及機器學習 (ML) 模型，
由於它們對分類問題的背景知識，這要歸功於標籤資料，
構成了一種有希望的心理健康評估方法。為了促進解決方案的
可信度、可靠性和問責制，模型決策的可解釋性描述
在圖形儀表板中提供。在真實資料集上的實驗結果達到 90% 的準確度，
改進了先前文獻中的準確度。最終目標是以一種可訪問且
可擴展的方式做出貢獻，在醫療保健系統中進行正式治療之前。

##### **Facial Expression Analysis and Its Potentials in IoT Systems: A Contemporary Survey**
2412.17616v1 by Zixuan Shanggua, Yanjie Dong, Song Guo, Victor C. M. Leung, M. Jamal Deen, Xiping Hu

Facial expressions convey human emotions and can be categorized into
macro-expressions (MaEs) and micro-expressions (MiEs) based on duration and
intensity. While MaEs are voluntary and easily recognized, MiEs are
involuntary, rapid, and can reveal concealed emotions. The integration of
facial expression analysis with Internet-of-Thing (IoT) systems has significant
potential across diverse scenarios. IoT-enhanced MaE analysis enables real-time
monitoring of patient emotions, facilitating improved mental health care in
smart healthcare. Similarly, IoT-based MiE detection enhances surveillance
accuracy and threat detection in smart security. This work aims at providing a
comprehensive overview of research progress in facial expression analysis and
explores its integration with IoT systems. We discuss the distinctions between
our work and existing surveys, elaborate on advancements in MaE and MiE
techniques across various learning paradigms, and examine their potential
applications in IoT. We highlight challenges and future directions for the
convergence of facial expression-based technologies and IoT systems, aiming to
foster innovation in this domain. By presenting recent developments and
practical applications, this study offers a systematic understanding of how
facial expression analysis can enhance IoT systems in healthcare, security, and
beyond.

摘要：面部表情傳達人類的情緒，並可根據持續時間和強度分為宏觀表情（MaE）和微表情（MiE）。雖然 MaE 是自願且易於識別的，但 MiE 是非自願的、快速的，並且可以揭示隱藏的情緒。面部表情分析與物聯網（IoT）系統的整合在不同場景中具有顯著的潛力。增強型 MaE 分析的 IoT 可實現對患者情緒的實時監控，促進智慧醫療中的心理保健改善。類似地，基於 IoT 的 MiE 檢測增強了智慧安全中的監控準確性和威脅檢測。這項工作旨在提供面部表情分析研究進展的全面概述，並探討其與 IoT 系統的整合。我們討論了我們的工作與現有調查之間的區別，闡述了各種學習範例中 MaE 和 MiE 技術的進步，並探討了它們在 IoT 中的潛在應用。我們強調了基於面部表情的技術與 IoT 系統融合的挑戰和未來方向，旨在促進這一領域的創新。通過展示最近的發展和實際應用，本研究提供了面部表情分析如何增強醫療保健、安全等方面的 IoT 系統的系統性理解。

##### **V$^2$-SfMLearner: Learning Monocular Depth and Ego-motion for Multimodal Wireless Capsule Endoscopy**
2412.17595v1 by Long Bai, Beilei Cui, Liangyu Wang, Yanheng Li, Shilong Yao, Sishen Yuan, Yanan Wu, Yang Zhang, Max Q. -H. Meng, Zhen Li, Weiping Ding, Hongliang Ren

Deep learning can predict depth maps and capsule ego-motion from capsule
endoscopy videos, aiding in 3D scene reconstruction and lesion localization.
However, the collisions of the capsule endoscopies within the gastrointestinal
tract cause vibration perturbations in the training data. Existing solutions
focus solely on vision-based processing, neglecting other auxiliary signals
like vibrations that could reduce noise and improve performance. Therefore, we
propose V$^2$-SfMLearner, a multimodal approach integrating vibration signals
into vision-based depth and capsule motion estimation for monocular capsule
endoscopy. We construct a multimodal capsule endoscopy dataset containing
vibration and visual signals, and our artificial intelligence solution develops
an unsupervised method using vision-vibration signals, effectively eliminating
vibration perturbations through multimodal learning. Specifically, we carefully
design a vibration network branch and a Fourier fusion module, to detect and
mitigate vibration noises. The fusion framework is compatible with popular
vision-only algorithms. Extensive validation on the multimodal dataset
demonstrates superior performance and robustness against vision-only
algorithms. Without the need for large external equipment, our V$^2$-SfMLearner
has the potential for integration into clinical capsule robots, providing
real-time and dependable digestive examination tools. The findings show promise
for practical implementation in clinical settings, enhancing the diagnostic
capabilities of doctors.

摘要：深度學習可以從膠囊內視鏡影片預測深度圖和膠囊自我運動，協助進行 3D 場景重建和病灶定位。
然而，膠囊內視鏡在胃腸道內的碰撞會造成訓練資料中的振動擾動。現有的解決方案僅專注於基於視覺的處理，忽略了其他輔助訊號，例如可以降低雜訊和提升效能的振動。因此，我們提出 V$^2$-SfMLearner，這是一種多模態方法，將振動訊號整合到基於視覺的深度和膠囊運動估計中，用於單眼膠囊內視鏡。我們建構了一個包含振動和視覺訊號的多模態膠囊內視鏡資料集，而我們的人工智慧解決方案使用視覺振動訊號開發了一種非監督式方法，透過多模態學習有效消除振動擾動。具體來說，我們仔細設計了一個振動網路分支和一個傅立葉融合模組，以偵測和減輕振動雜訊。融合架構與常見的純視覺演算法相容。在多模態資料集上的廣泛驗證證明了與純視覺演算法相比，其具有優異的效能和穩健性。我們的 V$^2$-SfMLearner 無需大型外部設備，有潛力整合到臨床膠囊機器人中，提供即時且可靠的消化道檢查工具。研究結果顯示在臨床環境中實際執行的可能性，提升醫師的診斷能力。

##### **Improved Cotton Leaf Disease Classification Using Parameter-Efficient Deep Learning Framework**
2412.17587v1 by Aswini Kumar Patra, Tejashwini Gajurel

Cotton crops, often called "white gold," face significant production
challenges, primarily due to various leaf-affecting diseases. As a major global
source of fiber, timely and accurate disease identification is crucial to
ensure optimal yields and maintain crop health. While deep learning and machine
learning techniques have been explored to address this challenge, there remains
a gap in developing lightweight models with fewer parameters which could be
computationally effective for agricultural practitioners. To address this, we
propose an innovative deep learning framework integrating a subset of trainable
layers from MobileNet, transfer learning, data augmentation, a learning rate
decay schedule, model checkpoints, and early stopping mechanisms. Our model
demonstrates exceptional performance, accurately classifying seven cotton
disease types with an overall accuracy of 98.42% and class-wise precision
ranging from 96% to 100%. This results in significantly enhanced efficiency,
surpassing recent approaches in accuracy and model complexity. The existing
models in the literature have yet to attain such high accuracy, even when
tested on data sets with fewer disease types. The substantial performance
improvement, combined with the lightweight nature of the model, makes it
practically suitable for real-world applications in smart farming. By offering
a high-performing and efficient solution, our framework can potentially address
challenges in cotton cultivation, contributing to sustainable agricultural
practices.

摘要：棉花作物常被称为「白色黄金」，但會面臨重大的生產挑戰，主要是因為各種影響葉子的疾病。作為全球主要的纖維來源，及時且準確地辨識疾病對於確保最佳產量和維持作物健康至關重要。儘管深度學習和機器學習技術已被探索用於解決此挑戰，但對於開發具有較少參數的輕量級模型仍存在差距，而這些模型對於農業從業者而言在運算上可能有效。為了解決此問題，我們提出一個創新的深度學習架構，整合了來自 MobileNet 的可訓練層子集、遷移學習、資料擴充、學習率衰減時間表、模型檢查點和早期停止機制。我們的模型展現了非凡的效能，準確地分類了七種棉花疾病類型，整體準確度為 98.42%，且類別準確度介於 96% 到 100% 之間。這導致顯著提升的效率，在準確度和模型複雜度上超越了最近的方法。文獻中的現有模型尚未達到如此高的準確度，即使在較少疾病類型的資料集上進行測試時也是如此。大幅提升的效能，加上模型的輕量級特性，使其在智慧農業的實際應用中具有實用性。透過提供高性能且高效的解決方案，我們的架構有可能解決棉花種植中的挑戰，進而促成永續的農業實務。

##### **Empathetic Response in Audio-Visual Conversations Using Emotion Preference Optimization and MambaCompressor**
2412.17572v1 by Yeonju Kim, Se Jin Park, Yong Man Ro

Chatbot research is advancing with the growing importance of chatbots in
fields that require human interactions, such as customer support and mental
health care. Despite these advancements, chatbots still face significant
challenges in understanding subtle nuances and managing long conversation
histories. To address these issues, our study introduces a dual approach:
firstly, we employ Emotional Preference Optimization (EPO) to train chatbots
not only with correct responses but also with counter-emotional responses-those
that are contextually similar but emotionally divergent. This training enables
the model to discern fine nuance distinctions between correct and
counter-emotional responses, thereby enhancing the quality of its responses.
Secondly, we introduce MambaCompressor to effectively compress and manage
extensive conversation histories, significantly reducing time and memory
complexities while improving the chatbot's contextual understanding. Our
comprehensive experiments across multiple datasets demonstrate that our model
significantly outperforms existing models in generating empathetic responses
and efficiently managing lengthy dialogues.

摘要：聊天機器人的研究隨著聊天機器人在需要人類互動的領域（例如客戶支援和心理保健）中日益重要而進展。儘管有這些進展，聊天機器人在理解微妙的細微差別和管理冗長的對話記錄方面仍然面臨重大挑戰。為了解決這些問題，我們的研究引入了一個雙重方法：首先，我們採用情緒偏好最佳化 (EPO) 來訓練聊天機器人，不僅使用正確的回應，還使用反情緒回應——那些在語境上相似但在情緒上不同的回應。這種訓練使模型能夠辨別正確和反情緒回應之間的細微差別，從而提高其回應的品質。其次，我們引入了 MambaCompressor 來有效壓縮和管理廣泛的對話記錄，大幅減少時間和記憶體複雜度，同時改善聊天機器人的語境理解。我們在多個資料集上的全面實驗表明，我們的模型在產生同理心回應和有效管理冗長的對話方面明顯優於現有的模型。

##### **Enhancing Cancer Diagnosis with Explainable & Trustworthy Deep Learning Models**
2412.17527v1 by Badaru I. Olumuyiwa, The Anh Han, Zia U. Shamszaman

This research presents an innovative approach to cancer diagnosis and
prediction using explainable Artificial Intelligence (XAI) and deep learning
techniques. With cancer causing nearly 10 million deaths globally in 2020,
early and accurate diagnosis is crucial. Traditional methods often face
challenges in cost, accuracy, and efficiency. Our study develops an AI model
that provides precise outcomes and clear insights into its decision-making
process, addressing the "black box" problem of deep learning models. By
employing XAI techniques, we enhance interpretability and transparency,
building trust among healthcare professionals and patients. Our approach
leverages neural networks to analyse extensive datasets, identifying patterns
for cancer detection. This model has the potential to revolutionise diagnosis
by improving accuracy, accessibility, and clarity in medical decision-making,
possibly leading to earlier detection and more personalised treatment
strategies. Furthermore, it could democratise access to high-quality
diagnostics, particularly in resource-limited settings, contributing to global
health equity. The model's applications extend beyond cancer diagnosis,
potentially transforming various aspects of medical decision-making and saving
millions of lives worldwide.

摘要：本研究提出了一個創新的癌症診斷和預測方法，使用可解釋的人工智慧 (XAI) 和深度學習技術。由於癌症在 2020 年造成全球近 1,000 萬人死亡，因此早期準確的診斷至關重要。傳統方法通常面臨成本、準確性和效率方面的挑戰。我們的研究開發了一個 AI 模型，它提供精確的結果並清楚地了解其決策過程，解決了深度學習模型的「黑箱」問題。通過採用 XAI 技術，我們增強了解釋性和透明度，在醫療專業人員和患者之間建立信任。我們的做法利用神經網路分析廣泛的數據集，識別癌症檢測模式。這個模型有可能通過提高醫療決策的準確性、可及性和清晰度來革新診斷，可能導致更早的檢測和更個性化的治療策略。此外，它可以使更多人獲得高品質的診斷，特別是在資源有限的環境中，有助於全球健康公平。該模型的應用範圍不僅限於癌症診斷，還可能轉變醫療決策的各個方面，並拯救全球數百萬人的生命。

##### **Applying LLM and Topic Modelling in Psychotherapeutic Contexts**
2412.17449v1 by Alexander Vanin, Vadim Bolshev, Anastasia Panfilova

This study explores the use of Large language models to analyze therapist
remarks in a psychotherapeutic setting. The paper focuses on the application of
BERTopic, a machine learning-based topic modeling tool, to the dialogue of two
different groups of therapists (classical and modern), which makes it possible
to identify and describe a set of topics that consistently emerge across these
groups. The paper describes in detail the chosen algorithm for BERTopic, which
included creating a vector space from a corpus of therapist remarks, reducing
its dimensionality, clustering the space, and creating and optimizing topic
representation. Along with the automatic topical modeling by the BERTopic, the
research involved an expert assessment of the findings and manual topic
structure optimization. The topic modeling results highlighted the most common
and stable topics in therapists speech, offering insights into how language
patterns in therapy develop and remain stable across different therapeutic
styles. This work contributes to the growing field of machine learning in
psychotherapy by demonstrating the potential of automated methods to improve
both the practice and training of therapists. The study highlights the value of
topic modeling as a tool for gaining a deeper understanding of therapeutic
dialogue and offers new opportunities for improving therapeutic effectiveness
and clinical supervision.

摘要：本研究探討使用大型語言模型來分析心理治療環境中的治療師評論。本文重點關注將基於機器學習的主題建模工具 BERTopic 應用於兩組不同治療師（古典和現代）的對話，這使得識別和描述一組在這些組中持續出現的主題成為可能。本文詳細描述了 BERTopic 的選擇演算法，其中包括從治療師評論語料庫建立向量空間、降低其維度、對空間進行分群，以及建立和最佳化主題表示。除了 BERTopic 的自動主題建模外，該研究還包括對研究結果的專家評估和手動主題結構最佳化。主題建模結果突出了治療師言語中最常見且穩定的主題，提供了有關治療中的語言模式如何發展並在不同的治療風格中保持穩定的見解。這項工作透過展示自動化方法在改善治療師實務和訓練方面的潛力，為心理治療中機器學習的成長領域做出貢獻。本研究強調了主題建模作為深入了解治療對話的工具的價值，並為改善治療效果和臨床督導提供了新的機會。

##### **FFA Sora, video generation as fundus fluorescein angiography simulator**
2412.17346v1 by Xinyuan Wu, Lili Wang, Ruoyu Chen, Bowen Liu, Weiyi Zhang, Xi Yang, Yifan Feng, Mingguang He, Danli Shi

Fundus fluorescein angiography (FFA) is critical for diagnosing retinal
vascular diseases, but beginners often struggle with image interpretation. This
study develops FFA Sora, a text-to-video model that converts FFA reports into
dynamic videos via a Wavelet-Flow Variational Autoencoder (WF-VAE) and a
diffusion transformer (DiT). Trained on an anonymized dataset, FFA Sora
accurately simulates disease features from the input text, as confirmed by
objective metrics: Frechet Video Distance (FVD) = 329.78, Learned Perceptual
Image Patch Similarity (LPIPS) = 0.48, and Visual-question-answering Score
(VQAScore) = 0.61. Specific evaluations showed acceptable alignment between the
generated videos and textual prompts, with BERTScore of 0.35. Additionally, the
model demonstrated strong privacy-preserving performance in retrieval
evaluations, achieving an average Recall@K of 0.073. Human assessments
indicated satisfactory visual quality, with an average score of 1.570(scale: 1
= best, 5 = worst). This model addresses privacy concerns associated with
sharing large-scale FFA data and enhances medical education.

摘要：眼底螢光血管攝影 (FFA) 對診斷視網膜血管疾病至關重要，但初學者常常難以解讀影像。本研究開發出 FFA Sora，一個文字轉影片模型，可透過小波流變動自編碼器 (WF-VAE) 和擴散轉換器 (DiT) 將 FFA 報告轉換成動態影片。FFA Sora 在匿名資料集上訓練，能準確模擬輸入文字中的疾病特徵，並由客觀指標證實：Fréchet 影片距離 (FVD) = 329.78、學習知覺影像區塊相似度 (LPIPS) = 0.48 和視覺問答分數 (VQAScore) = 0.61。特定評估顯示產生的影片和文字提示之間有可接受的一致性，BERTScore 為 0.35。此外，該模型在檢索評估中展現出強大的隱私保護效能，平均 Recall@K 達到 0.073。人類評估顯示令人滿意的視覺品質，平均分數為 1.570（量表：1 = 最佳，5 = 最差）。此模型解決了與分享大規模 FFA 資料相關的隱私疑慮，並增進醫學教育。

##### **QTSeg: A Query Token-Based Architecture for Efficient 2D Medical Image Segmentation**
2412.17241v1 by Phuong-Nam Tran, Nhat Truong Pham, Duc Ngoc Minh Dang, Eui-Nam Huh, Choong Seon Hong

Medical image segmentation is crucial in assisting medical doctors in making
diagnoses and enabling accurate automatic diagnosis. While advanced
convolutional neural networks (CNNs) excel in segmenting regions of interest
with pixel-level precision, they often struggle with long-range dependencies,
which is crucial for enhancing model performance. Conversely, transformer
architectures leverage attention mechanisms to excel in handling long-range
dependencies. However, the computational complexity of transformers grows
quadratically, posing resource-intensive challenges, especially with
high-resolution medical images. Recent research aims to combine CNN and
transformer architectures to mitigate their drawbacks and enhance performance
while keeping resource demands low. Nevertheless, existing approaches have not
fully leveraged the strengths of both architectures to achieve high accuracy
with low computational requirements. To address this gap, we propose a novel
architecture for 2D medical image segmentation (QTSeg) that leverages a feature
pyramid network (FPN) as the image encoder, a multi-level feature fusion (MLFF)
as the adaptive module between encoder and decoder and a multi-query mask
decoder (MQM Decoder) as the mask decoder. In the first step, an FPN model
extracts pyramid features from the input image. Next, MLFF is incorporated
between the encoder and decoder to adapt features from different encoder stages
to the decoder. Finally, an MQM Decoder is employed to improve mask generation
by integrating query tokens with pyramid features at all stages of the mask
decoder. Our experimental results show that QTSeg outperforms state-of-the-art
methods across all metrics with lower computational demands than the baseline
and the existing methods. Code is available at
https://github.com/tpnam0901/QTSeg (v0.1.0)

摘要：醫療影像分割對於協助醫生診斷和實現精確的自動診斷至關重要。儘管先進的卷積神經網路 (CNN) 在以像素層級精準度分割感興趣區域方面表現出色，但它們通常難以處理長距離依賴性，這對於提升模型效能至關重要。相反地，變形器架構利用注意力機制在處理長距離依賴性方面表現出色。然而，變形器的運算複雜度呈二次方成長，造成資源密集型的挑戰，特別是在處理高解析度醫療影像時。最近的研究旨在結合 CNN 和變形器架構，以減輕其缺點並提升效能，同時保持低資源需求。儘管如此，現有方法尚未充分利用這兩種架構的優點，以在低運算需求下達成高準確度。為了解決這個差距，我們提出了一種針對 2D 醫療影像分割的創新架構 (QTSeg)，它利用特徵金字塔網路 (FPN) 作為影像編碼器，多層級特徵融合 (MLFF) 作為編碼器和解碼器之間的自適應模組，以及多查詢遮罩解碼器 (MQM Decoder) 作為遮罩解碼器。在第一步，FPN 模型從輸入影像中萃取金字塔特徵。接下來，MLFF 被整合在編碼器和解碼器之間，以將來自不同編碼器階段的特徵適應到解碼器。最後，採用 MQM 解碼器，透過在遮罩解碼器的所有階段將查詢權杖與金字塔特徵整合，來改善遮罩生成。我們的實驗結果顯示，QTSeg 在所有指標上都優於最先進的方法，且運算需求低於基線和現有方法。程式碼可在 https://github.com/tpnam0901/QTSeg (v0.1.0) 取得

##### **MatchMiner-AI: An Open-Source Solution for Cancer Clinical Trial Matching**
2412.17228v1 by Ethan Cerami, Pavel Trukhanov, Morgan A. Paul, Michael J. Hassett, Irbaz B. Riaz, James Lindsay, Emily Mallaber, Harry Klein, Gufran Gungor, Matthew Galvin, Stephen C. Van Nostrand, Joyce Yu, Tali Mazor, Kenneth L. Kehl

Clinical trials drive improvements in cancer treatments and outcomes.
However, most adults with cancer do not participate in trials, and trials often
fail to enroll enough patients to answer their scientific questions. Artificial
intelligence could accelerate matching of patients to appropriate clinical
trials. Here, we describe the development and evaluation of the MatchMiner-AI
pipeline for clinical trial searching and ranking. MatchMiner-AI focuses on
matching patients to potential trials based on core criteria describing
clinical "spaces," or disease contexts, targeted by a trial. It aims to
accelerate the human work of identifying potential matches, not to fully
automate trial screening. The pipeline includes modules for extraction of key
information from a patient's longitudinal electronic health record; rapid
ranking of candidate trial-patient matches based on embeddings in vector space;
and classification of whether a candidate match represents a reasonable
clinical consideration. Code and synthetic data are available at
https://huggingface.co/ksg-dfci/MatchMiner-AI . Model weights based on
synthetic data are available at https://huggingface.co/ksg-dfci/TrialSpace and
https://huggingface.co/ksg-dfci/TrialChecker . A simple cancer clinical trial
search engine to demonstrate pipeline components is available at
https://huggingface.co/spaces/ksg-dfci/trial_search_alpha .

摘要：臨床試驗推動癌症治療和成果的進展。
然而，大多數癌症成年患者並未參與試驗，而試驗也常無法招募足夠的患者來回答其科學問題。人工
智慧可以加速將患者與適當的臨床試驗配對。在此，我們描述 MatchMiner-AI
管線的開發和評估，用於臨床試驗搜尋和排名。MatchMiner-AI 專注於根據描述
臨床「空間」或試驗針對的疾病背景的核心標準，將患者與潛在試驗配對。其目標是
加速找出潛在配對的人工工作，而非完全自動化試驗篩選。此管線包含模組，用於
從患者的縱向電子健康紀錄中萃取關鍵資訊；根據向量空間中的嵌入快速排名候選試驗
與患者的配對；以及分類候選配對是否代表合理的臨床考量。程式碼和合成資料可於
https://huggingface.co/ksg-dfci/MatchMiner-AI 取得。根據合成資料的模型權重可於
https://huggingface.co/ksg-dfci/TrialSpace 和
https://huggingface.co/ksg-dfci/TrialChecker 取得。一個簡單的癌症臨床試驗
搜尋引擎用於展示管線組成，可於
https://huggingface.co/spaces/ksg-dfci/trial_search_alpha 取得。

##### **COVID-19 on YouTube: A Data-Driven Analysis of Sentiment, Toxicity, and Content Recommendations**
2412.17180v1 by Vanessa Su, Nirmalya Thakur

This study presents a data-driven analysis of COVID-19 discourse on YouTube,
examining the sentiment, toxicity, and thematic patterns of video content
published between January 2023 and October 2024. The analysis involved applying
advanced natural language processing (NLP) techniques: sentiment analysis with
VADER, toxicity detection with Detoxify, and topic modeling using Latent
Dirichlet Allocation (LDA). The sentiment analysis revealed that 49.32% of
video descriptions were positive, 36.63% were neutral, and 14.05% were
negative, indicating a generally informative and supportive tone in
pandemic-related content. Toxicity analysis identified only 0.91% of content as
toxic, suggesting minimal exposure to toxic content. Topic modeling revealed
two main themes, with 66.74% of the videos covering general health information
and pandemic-related impacts and 33.26% focused on news and real-time updates,
highlighting the dual informational role of YouTube. A recommendation system
was also developed using TF-IDF vectorization and cosine similarity, refined by
sentiment, toxicity, and topic filters to ensure relevant and context-aligned
video recommendations. This system achieved 69% aggregate coverage, with
monthly coverage rates consistently above 85%, demonstrating robust performance
and adaptability over time. Evaluation across recommendation sizes showed
coverage reaching 69% for five video recommendations and 79% for ten video
recommendations per video. In summary, this work presents a framework for
understanding COVID-19 discourse on YouTube and a recommendation system that
supports user engagement while promoting responsible and relevant content
related to COVID-19.

摘要：本研究透過資料驅動分析 YouTube 上與 COVID-19 相關的論述，探討 2023 年 1 月至 2024 年 10 月間發布的影片內容中的情緒、毒性與主題模式。分析中採用進階自然語言處理 (NLP) 技術：使用 VADER 進行情緒分析、使用 Detoxify 進行毒性偵測，以及使用隱含狄利克雷配置 (LDA) 進行主題建模。情緒分析顯示，49.32% 的影片說明為正面、36.63% 為中立、14.05% 為負面，表示與疫情相關的內容通常具有資訊性且具支持性。毒性分析指出僅有 0.91% 的內容具有毒性，表示接觸到有毒內容的機率很低。主題建模顯示出兩個主要主題，其中 66.74% 的影片涵蓋一般健康資訊與疫情相關影響，而 33.26% 則著重於新聞和即時更新，突顯出 YouTube 的雙重資訊角色。我們也使用 TF-IDF 向量化和餘弦相似度開發了一套推薦系統，並透過情緒、毒性和主題篩選器進行調整，以確保推薦的影片相關且符合脈絡。此系統達到 69% 的總體覆蓋率，且每月的覆蓋率穩定維持在 85% 以上，顯示出穩健的效能和適應力。針對不同推薦數量進行評估，結果顯示推薦五部影片的覆蓋率達到 69%，推薦十部影片的覆蓋率則達到 79%。總之，這項研究提出一個架構，用於了解 YouTube 上與 COVID-19 相關的論述，並提出一個推薦系統，在促進使用者參與的同時，也能宣傳與 COVID-19 相關的負責任且相關的內容。

##### **AI-Based Teat Shape and Skin Condition Prediction for Dairy Management**
2412.17142v1 by Yuexing Hao, Tiancheng Yuan, Yuting Yang, Aarushi Gupta, Matthias Wieland, Ken Birman, Parminder S. Basran

Dairy owners spend significant effort to keep their animals healthy. There is
good reason to hope that technologies such as computer vision and artificial
intelligence (AI) could reduce these costs, yet obstacles arise when adapting
advanced tools to farming environments. In this work, we adapt AI tools to
dairy cow teat localization, teat shape, and teat skin condition
classifications. We also curate a data collection and analysis methodology for
a Machine Learning (ML) pipeline. The resulting teat shape prediction model
achieves a mean Average Precision (mAP) of 0.783, and the teat skin condition
model achieves a mean average precision of 0.828. Our work leverages existing
ML vision models to facilitate the individualized identification of teat health
and skin conditions, applying AI to the dairy management industry.

摘要：乳製品業者投入大量心力保持動物健康。有充分理由期待電腦視覺與人工智慧 (AI) 等技術可以降低這些成本，然而在將先進工具應用於農業環境時會遇到障礙。在這項工作中，我們將 AI 工具應用於乳牛乳頭定位、乳頭形狀和乳頭皮膚狀況分類。我們也為機器學習 (ML) 管線整理資料收集和分析方法。產生的乳頭形狀預測模型達到 0.783 的平均準確度 (mAP)，而乳頭皮膚狀況模型達到 0.828 的平均準確度。我們的研究利用現有的 ML 視覺模型，促進乳頭健康和皮膚狀況的個別辨識，將 AI 應用於乳製品管理產業。

##### **An OpenMind for 3D medical vision self-supervised learning**
2412.17041v1 by Tassilo Wald, Constantin Ulrich, Jonathan Suprijadi, Michal Nohel, Robin Peretzke, Klaus H. Maier-Hein

The field of 3D medical vision self-supervised learning lacks consistency and
standardization. While many methods have been developed it is impossible to
identify the current state-of-the-art, due to i) varying and small pre-training
datasets, ii) varying architectures, and iii) being evaluated on differing
downstream datasets. In this paper we bring clarity to this field and lay the
foundation for further method advancements: We a) publish the largest publicly
available pre-training dataset comprising 114k 3D brain MRI volumes and b)
benchmark existing SSL methods under common architectures and c) provide the
code of our framework publicly to facilitate rapid adoption and reproduction.
This pre-print \textit{only describes} the dataset contribution (a); Data,
benchmark, and codebase will be made available shortly.

摘要：3D 醫療視覺自監督學習領域缺乏一致性和標準化。雖然已經開發出許多方法，但由於 i) 變化且較小的預訓練資料集、ii) 不同的架構，以及 iii) 在不同的下游資料集上進行評估，因此無法識別目前的最新技術。在本文中，我們為這個領域帶來清晰度，並為進一步的方法進展奠定基礎：我們 a) 發布最大的公開可用預訓練資料集，包含 114k 個 3D 大腦 MRI 卷，以及 b) 在常見架構下對現有的 SSL 方法進行基準測試，以及 c) 公開提供我們架構的程式碼，以促進快速採用和複製。這個預印本\textit{僅描述}資料集貢獻 (a)；資料、基準測試和程式碼庫將很快提供。

##### **On Fusing ChatGPT and Ensemble Learning in Discon-tinuous Named Entity Recognition in Health Corpora**
2412.16976v1 by Tzu-Chieh Chen, Wen-Yang Lin

Named Entity Recognition has traditionally been a key task in natural
language processing, aiming to identify and extract important terms from
unstructured text data. However, a notable challenge for contemporary
deep-learning NER models has been identifying discontinuous entities, which are
often fragmented within the text. To date, methods to address Discontinuous
Named Entity Recognition have not been explored using ensemble learning to the
best of our knowledge. Furthermore, the rise of large language models, such as
ChatGPT in recent years, has shown significant effectiveness across many NLP
tasks. Most existing approaches, however, have primarily utilized ChatGPT as a
problem-solving tool rather than exploring its potential as an integrative
element within ensemble learning algorithms. In this study, we investigated the
integration of ChatGPT as an arbitrator within an ensemble method, aiming to
enhance performance on DNER tasks. Our method combines five state-of-the-art
NER models with ChatGPT using custom prompt engineering to assess the
robustness and generalization capabilities of the ensemble algorithm. We
conducted experiments on three benchmark medical datasets, comparing our method
against the five SOTA models, individual applications of GPT-3.5 and GPT-4, and
a voting ensemble method. The results indicate that our proposed fusion of
ChatGPT with the ensemble learning algorithm outperforms the SOTA results in
the CADEC, ShARe13, and ShARe14 datasets, showcasing its potential to enhance
NLP applications in the healthcare domain.

摘要：命名實體辨識一直是自然語言處理中的關鍵任務，旨在從非結構化文字資料中辨識並擷取重要詞彙。然而，當代深度學習命名實體辨識模型面臨的一項顯著挑戰，就是辨識非連續實體，這些實體通常在文字中呈片段化。迄今為止，我們所知，並未探索使用整體學習來解決非連續命名實體辨識的方法。此外，近年來大型語言模型（如 ChatGPT）的興起，已在許多自然語言處理任務中展現顯著的效能。然而，現有方法大多將 ChatGPT 視為解決問題的工具，而非探索其作為整體學習演算法中整合元素的潛力。在本研究中，我們探討了將 ChatGPT 整合為整體方法中的仲裁者，旨在提升非連續命名實體辨識任務的效能。我們的方法結合了五種最先進的命名實體辨識模型和 ChatGPT，使用自訂提示工程來評估整體演算法的穩健性和泛化能力。我們針對三個基準醫療資料集進行實驗，將我們的方法與五種最先進的模型、GPT-3.5 和 GPT-4 的個別應用，以及投票整體方法進行比較。結果表明，我們提出的將 ChatGPT 與整體學習演算法融合的方法，在 CADEC、ShARe13 和 ShARe14 資料集中的表現優於最先進的結果，展示了其在醫療領域增強自然語言處理應用程式的潛力。

##### **Quantifying Public Response to COVID-19 Events: Introducing the Community Sentiment and Engagement Index**
2412.16925v1 by Nirmalya Thakur, Kesha A. Patel, Audrey Poon, Shuqi Cui, Nazif Azizi, Rishika Shah, Riyan Shah

This study introduces the Community Sentiment and Engagement Index (CSEI),
developed to capture nuanced public sentiment and engagement variations on
social media, particularly in response to major events related to COVID-19.
Constructed with diverse sentiment indicators, CSEI integrates features like
engagement, daily post count, compound sentiment, fine-grain sentiments (fear,
surprise, joy, sadness, anger, disgust, and neutral), readability,
offensiveness, and domain diversity. Each component is systematically weighted
through a multi-step Principal Component Analysis (PCA)-based framework,
prioritizing features according to their variance contributions across temporal
sentiment shifts. This approach dynamically adjusts component importance,
enabling CSEI to precisely capture high-sensitivity shifts in public sentiment.
The development of CSEI showed statistically significant correlations with its
constituent features, underscoring internal consistency and sensitivity to
specific sentiment dimensions. CSEI's responsiveness was validated using a
dataset of 4,510,178 Reddit posts about COVID-19. The analysis focused on 15
major events, including the WHO's declaration of COVID-19 as a pandemic, the
first reported cases of COVID-19 across different countries, national
lockdowns, vaccine developments, and crucial public health measures. Cumulative
changes in CSEI revealed prominent peaks and valleys aligned with these events,
indicating significant patterns in public sentiment across different phases of
the pandemic. Pearson correlation analysis further confirmed a statistically
significant relationship between CSEI daily fluctuations and these events (p =
0.0428), highlighting the capacity of CSEI to infer and interpret shifts in
public sentiment and engagement in response to major events related to
COVID-19.

摘要：本研究引入了社群情緒和參與指數 (CSEI)，其旨在捕捉社群媒體上細微的公眾情緒和參與變化，特別是針對與 COVID-19 相關的重大事件。CSEI 以多樣化的情緒指標建構，整合了參與度、每日發文數、複合情緒、細緻情緒（恐懼、驚訝、快樂、悲傷、憤怒、厭惡和中立）、可讀性、冒犯性和網域多樣性等特徵。每個組成部分都透過多步驟主成分分析 (PCA) 為基礎的架構進行系統性加權，根據特徵對時間情緒變化的貢獻度對特徵進行優先排序。此方法動態調整組成部分的重要性，使 CSEI 能夠精準捕捉公眾情緒中的高敏感度變化。CSEI 的發展顯示出與其組成特徵具有統計顯著相關性，強調了內部一致性和對特定情緒面向的敏感性。CSEI 的反應能力已使用包含 4,510,178 則關於 COVID-19 的 Reddit 貼文的資料集進行驗證。分析重點關注 15 個重大事件，包括 WHO 宣布 COVID-19 為一場大流行病、不同國家首次報告 COVID-19 病例、國家封鎖、疫苗開發和重要的公共衛生措施。CSEI 的累積變化顯示出與這些事件相符的顯著高峰和低谷，表明在疫情的不同階段中公眾情緒存在顯著模式。皮爾森相關分析進一步證實了 CSEI 每日的波動與這些事件之間存在統計顯著相關性 (p = 0.0428)，突顯出 CSEI 推論和詮釋公眾情緒變化以及對與 COVID-19 相關的重大事件參與度變化的能力。

##### **PsychAdapter: Adapting LLM Transformers to Reflect Traits, Personality and Mental Health**
2412.16882v2 by Huy Vu, Huy Anh Nguyen, Adithya V Ganesan, Swanie Juhng, Oscar N. E. Kjell, Joao Sedoc, Margaret L. Kern, Ryan L. Boyd, Lyle Ungar, H. Andrew Schwartz, Johannes C. Eichstaedt

Artificial intelligence-based language generators are now a part of most
people's lives. However, by default, they tend to generate "average" language
without reflecting the ways in which people differ. Here, we propose a
lightweight modification to the standard language model transformer
architecture - "PsychAdapter" - that uses empirically derived trait-language
patterns to generate natural language for specified personality, demographic,
and mental health characteristics (with or without prompting). We applied
PsychAdapters to modify OpenAI's GPT-2, Google's Gemma, and Meta's Llama 3 and
found generated text to reflect the desired traits. For example, expert raters
evaluated PsychAdapter's generated text output and found it matched intended
trait levels with 87.3% average accuracy for Big Five personalities, and 96.7%
for depression and life satisfaction. PsychAdapter is a novel method to
introduce psychological behavior patterns into language models at the
foundation level, independent of prompting, by influencing every transformer
layer. This approach can create chatbots with specific personality profiles,
clinical training tools that mirror language associated with psychological
conditionals, and machine translations that match an authors reading or
education level without taking up LLM context windows. PsychAdapter also allows
for the exploration psychological constructs through natural language
expression, extending the natural language processing toolkit to study human
psychology.

摘要：基於人工智慧的語言產生器現已成為大多數人生活的一部分。然而，預設情況下，它們傾向於產生「普通」語言，而沒有反映出人們的差異性。在此，我們提出了一個對標準語言模型轉換器架構的輕量化修改 - 「PsychAdapter」 - 它使用經驗派生的特質語言模式，為指定的人格、人口統計和心理健康特徵（有或沒有提示）產生自然語言。我們將 PsychAdapter 應用於修改 OpenAI 的 GPT-2、Google 的 Gemma 和 Meta 的 Llama 3，並發現產生的文字反映了所需的特質。例如，專家評分者評估了 PsychAdapter 產生的文字輸出，發現它與預期的特質層級相符，五大性格特質的平均準確度為 87.3%，而憂鬱症和生活滿意度的準確度為 96.7%。PsychAdapter 是一種新方法，可以在基礎層級將心理行為模式引入語言模型，不受提示的影響，進而影響每個轉換器層級。此方法可以創造出具有特定人格特質的聊天機器人、反映與心理條件相關語言的臨床訓練工具，以及與作者的閱讀或教育程度相符的機器翻譯，而無需佔用 LLM 上下文視窗。PsychAdapter 還允許透過自然語言表達來探索心理結構，將自然語言處理工具包擴展到研究人類心理學。

##### **KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis**
2412.16833v1 by Kaiwen Zuo, Yirui Jiang, Fan Mo, Pietro Lio

Integrating Large Language Models (LLMs) in healthcare diagnosis demands
systematic frameworks that can handle complex medical scenarios while
maintaining specialized expertise. We present KG4Diagnosis, a novel
hierarchical multi-agent framework that combines LLMs with automated knowledge
graph construction, encompassing 362 common diseases across medical
specialties. Our framework mirrors real-world medical systems through a
two-tier architecture: a general practitioner (GP) agent for initial assessment
and triage, coordinating with specialized agents for in-depth diagnosis in
specific domains. The core innovation lies in our end-to-end knowledge graph
generation methodology, incorporating: (1) semantic-driven entity and relation
extraction optimized for medical terminology, (2) multi-dimensional decision
relationship reconstruction from unstructured medical texts, and (3)
human-guided reasoning for knowledge expansion. KG4Diagnosis serves as an
extensible foundation for specialized medical diagnosis systems, with
capabilities to incorporate new diseases and medical knowledge. The framework's
modular design enables seamless integration of domain-specific enhancements,
making it valuable for developing targeted medical diagnosis systems. We
provide architectural guidelines and protocols to facilitate adoption across
medical contexts.

摘要：整合大型語言模型 (LLM) 於醫療診斷中，需要系統化架構，能夠處理複雜的醫療場景，同時維持專業知識。我們提出 KG4Diagnosis，一個新穎的分層多代理架構，結合 LLM 與自動化知識圖譜建構，涵蓋醫療專業的 362 種常見疾病。我們的架構透過雙層架構反映真實世界的醫療系統：一位全科醫師 (GP) 代理負責初步評估和分流，並與專業代理協調，針對特定領域進行深入診斷。核心創新在於我們的端對端知識圖譜生成方法，結合：(1) 針對醫療術語最佳化的語意驅動實體和關係萃取，(2) 從非結構化醫療文本重建多面向決策關係，以及 (3) 人類引導的推理進行知識擴充。KG4Diagnosis 可作為專業醫療診斷系統的可擴充基礎，具備整合新疾病和醫療知識的能力。此架構的模組化設計能無縫整合特定領域的強化功能，使其對於開發目標導向的醫療診斷系統極具價值。我們提供架構準則和協定，以利於在醫療情境中採用。

##### **A Comparative Study on Machine Learning Models to Classify Diseases Based on Patient Behaviour and Habits**
2412.16768v1 by Elham Musaaed, Nabil Hewahi, Abdulla Alasaadi

In recent years, ML algorithms have been shown to be useful for predicting
diseases based on health data and posed a potential application area for these
algorithms such as modeling of diseases. The majority of these applications
employ supervised rather than unsupervised ML algorithms. In addition, each
year, the amount of data in medical science grows rapidly. Moreover, these data
include clinical and Patient-Related Factors (PRF), such as height, weight,
age, other physical characteristics, blood sugar, lipids, insulin, etc., all of
which will change continually over time. Analysis of historical data can help
identify disease risk factors and their interactions, which is useful for
disease diagnosis and prediction. This wealth of valuable information in these
data will help doctors diagnose accurately and people can become more aware of
the risk factors and key indicators to act proactively. The purpose of this
study is to use six supervised ML approaches to fill this gap by conducting a
comprehensive experiment to investigate the correlation between PRF and
Diabetes, Stroke, Heart Disease (HD), and Kidney Disease (KD). Moreover, it
will investigate the link between Diabetes, Stroke, and KD and PRF with HD.
Further, the research aims to compare and evaluate various ML algorithms for
classifying diseases based on the PRF. Additionally, it aims to compare and
evaluate ML algorithms for classifying HD based on PRF as well as Diabetes,
Stroke, Asthma, Skin Cancer, and KD as attributes. Lastly, HD predictions will
be provided through a Web-based application on the most accurate classifier,
which allows the users to input their values and predict the output.

摘要：近年來，已證明 ML 演算法可根據健康資料預測疾病，並為這些演算法提出了潛在應用領域，例如疾病建模。這些應用程式大多數採用有監督式而非無監督式的 ML 演算法。此外，每年醫學科學中的資料量都快速成長。而且，這些資料包括臨床和患者相關因素 (PRF)，例如身高、體重、年齡、其他身體特徵、血糖、脂質、胰島素等，所有這些都會隨著時間持續變化。分析歷史資料有助於找出疾病風險因子及其交互作用，這對於疾病診斷和預測很有用。這些資料中豐富的寶貴資訊將有助於醫生準確診斷，而人們可以更了解風險因子和關鍵指標，以採取積極行動。本研究的目的是使用六種有監督式 ML 方法，透過執行全面實驗來填補此差距，以探討 PRF 與糖尿病、中風、心臟病 (HD) 和腎臟病 (KD) 之間的關聯性。此外，它將探討糖尿病、中風和 KD 與 PRF 與 HD 之間的關聯性。此外，該研究旨在比較和評估各種 ML 演算法，以根據 PRF 對疾病進行分類。此外，它旨在比較和評估 ML 演算法，以根據 PRF 對 HD 進行分類，以及將糖尿病、中風、氣喘、皮膚癌和 KD 作為屬性。最後，將透過最準確分類器的網路應用程式提供 HD 預測，使用戶可以輸入其數值並預測輸出。

##### **From Histopathology Images to Cell Clouds: Learning Slide Representations with Hierarchical Cell Transformer**
2412.16715v1 by Zijiang Yang, Zhongwei Qiu, Tiancheng Lin, Hanqing Chao, Wanxing Chang, Yelin Yang, Yunshuo Zhang, Wenpei Jiao, Yixuan Shen, Wenbin Liu, Dongmei Fu, Dakai Jin, Ke Yan, Le Lu, Hui Jiang, Yun Bian

It is clinically crucial and potentially very beneficial to be able to
analyze and model directly the spatial distributions of cells in histopathology
whole slide images (WSI). However, most existing WSI datasets lack cell-level
annotations, owing to the extremely high cost over giga-pixel images. Thus, it
remains an open question whether deep learning models can directly and
effectively analyze WSIs from the semantic aspect of cell distributions. In
this work, we construct a large-scale WSI dataset with more than 5 billion
cell-level annotations, termed WSI-Cell5B, and a novel hierarchical Cell Cloud
Transformer (CCFormer) to tackle these challenges. WSI-Cell5B is based on 6,998
WSIs of 11 cancers from The Cancer Genome Atlas Program, and all WSIs are
annotated per cell by coordinates and types. To the best of our knowledge,
WSI-Cell5B is the first WSI-level large-scale dataset integrating cell-level
annotations. On the other hand, CCFormer formulates the collection of cells in
each WSI as a cell cloud and models cell spatial distribution. Specifically,
Neighboring Information Embedding (NIE) is proposed to characterize the
distribution of cells within the neighborhood of each cell, and a novel
Hierarchical Spatial Perception (HSP) module is proposed to learn the spatial
relationship among cells in a bottom-up manner. The clinical analysis indicates
that WSI-Cell5B can be used to design clinical evaluation metrics based on
counting cells that effectively assess the survival risk of patients. Extensive
experiments on survival prediction and cancer staging show that learning from
cell spatial distribution alone can already achieve state-of-the-art (SOTA)
performance, i.e., CCFormer strongly outperforms other competing methods.

摘要：在组织病理学全切片图像（WSI）中直接分析和建模细胞的空间分布在临床上至关重要，并且可能非常有益。然而，由于千兆像素图像的成本极高，大多数现有的 WSI 数据集缺乏细胞级别的注释。因此，深度学习模型能否从细胞分布的语义方面直接有效地分析 WSI 仍然是一个悬而未决的问题。在这项工作中，我们构建了一个包含超过 50 亿个细胞级注释的大规模 WSI 数据集，称为 WSI-Cell5B，以及一个新颖的分层细胞云 Transformer（CCFormer）来应对这些挑战。WSI-Cell5B 基于癌症基因组图谱计划的 11 种癌症的 6,998 个 WSI，并且所有 WSI 都按细胞坐标和类型进行注释。据我们所知，WSI-Cell5B 是第一个整合细胞级注释的 WSI 级大规模数据集。另一方面，CCFormer 将每个 WSI 中的细胞集合表述为细胞云，并对细胞空间分布进行建模。具体来说，提出了邻域信息嵌入（NIE）来表征每个细胞邻域内细胞的分布，并提出了一个新颖的分层空间感知（HSP）模块来以自下而上的方式学习细胞之间的空间关系。临床分析表明，WSI-Cell5B 可用于设计基于计数细胞的临床评估指标，该指标可有效评估患者的生存风险。在生存预测和癌症分期上的大量实验表明，仅从细胞空间分布中学习就已经可以达到最先进（SOTA）的性能，即 CCFormer 明显优于其他竞争方法。

##### **Multi-atlas Ensemble Graph Neural Network Model For Major Depressive Disorder Detection Using Functional MRI Data**
2412.19833v1 by Nojod M. Alotaibi, Areej M. Alhothali, Manar S. Ali

Major depressive disorder (MDD) is one of the most common mental disorders,
with significant impacts on many daily activities and quality of life. It
stands as one of the most common mental disorders globally and ranks as the
second leading cause of disability. The current diagnostic approach for MDD
primarily relies on clinical observations and patient-reported symptoms,
overlooking the diverse underlying causes and pathophysiological factors
contributing to depression. Therefore, scientific researchers and clinicians
must gain a deeper understanding of the pathophysiological mechanisms involved
in MDD. There is growing evidence in neuroscience that depression is a brain
network disorder, and the use of neuroimaging, such as magnetic resonance
imaging (MRI), plays a significant role in identifying and treating MDD.
Rest-state functional MRI (rs-fMRI) is among the most popular neuroimaging
techniques used to study MDD. Deep learning techniques have been widely applied
to neuroimaging data to help with early mental health disorder detection.
Recent years have seen a rise in interest in graph neural networks (GNNs),
which are deep neural architectures specifically designed to handle
graph-structured data like rs-fMRI. This research aimed to develop an
ensemble-based GNN model capable of detecting discriminative features from
rs-fMRI images for the purpose of diagnosing MDD. Specifically, we constructed
an ensemble model by combining features from multiple brain region segmentation
atlases to capture brain complexity and detect distinct features more
accurately than single atlas-based models. Further, the effectiveness of our
model is demonstrated by assessing its performance on a large multi-site MDD
dataset. The best performing model among all folds achieved an accuracy of
75.80%, a sensitivity of 88.89%, a specificity of 61.84%, a precision of
71.29%, and an F1-score of 79.12%.

摘要：重度憂鬱症 (MDD) 是最常見的精神疾病之一，對許多日常活動和生活品質都有顯著影響。它是全球最常見的精神疾病之一，也是造成失能的第二大原因。目前 MDD 的診斷方法主要依賴臨床觀察和患者報告的症狀，忽略了導致憂鬱症的多種潛在原因和病理生理因素。因此，科學研究人員和臨床醫生必須對 MDD 所涉及的病理生理機制有更深入的了解。神經科學中有越來越多的證據表明，憂鬱症是一種腦部網路疾病，而神經影像技術（例如磁共振造影 (MRI)）的使用在識別和治療 MDD 中扮演重要的角色。靜態功能性磁共振造影 (rs-fMRI) 是用於研究 MDD 最流行的神經影像技術之一。深度學習技術已廣泛應用於神經影像數據，以協助早期精神疾病的偵測。近年來，對圖神經網路 (GNN) 的興趣日益增加，圖神經網路是一種專門設計來處理圖結構化數據（例如 rs-fMRI）的深度神經架構。本研究旨在開發一個基於整體的 GNN 模型，該模型能夠從 rs-fMRI 影像中偵測出區別性特徵，以診斷 MDD。具體來說，我們通過結合來自多個腦區分割圖譜的特徵，構建了一個整體模型，以捕捉腦部複雜性，並比單一圖譜模型更準確地偵測出不同的特徵。此外，我們通過評估模型在大型多中心 MDD 資料集上的效能，證明了模型的有效性。在所有區塊中表現最佳的模型達到了 75.80% 的準確率、88.89% 的敏感度、61.84% 的特異度、71.29% 的精確度和 79.12% 的 F1 分數。

##### **STAMPsy: Towards SpatioTemporal-Aware Mixed-Type Dialogues for Psychological Counseling**
2412.16674v1 by Jieyi Wang, Yue Huang, Zeming Liu, Dexuan Xu, Chuan Wang, Xiaoming Shi, Ruiyuan Guan, Hongxing Wang, Weihua Yue, Yu Huang

Online psychological counseling dialogue systems are trending, offering a
convenient and accessible alternative to traditional in-person therapy.
However, existing psychological counseling dialogue systems mainly focus on
basic empathetic dialogue or QA with minimal professional knowledge and without
goal guidance. In many real-world counseling scenarios, clients often seek
multi-type help, such as diagnosis, consultation, therapy, console, and common
questions, but existing dialogue systems struggle to combine different dialogue
types naturally. In this paper, we identify this challenge as how to construct
mixed-type dialogue systems for psychological counseling that enable clients to
clarify their goals before proceeding with counseling. To mitigate the
challenge, we collect a mixed-type counseling dialogues corpus termed STAMPsy,
covering five dialogue types, task-oriented dialogue for diagnosis,
knowledge-grounded dialogue, conversational recommendation, empathetic
dialogue, and question answering, over 5,000 conversations. Moreover,
spatiotemporal-aware knowledge enables systems to have world awareness and has
been proven to affect one's mental health. Therefore, we link dialogues in
STAMPsy to spatiotemporal state and propose a spatiotemporal-aware mixed-type
psychological counseling dataset. Additionally, we build baselines on STAMPsy
and develop an iterative self-feedback psychological dialogue generation
framework, named Self-STAMPsy. Results indicate that clarifying dialogue goals
in advance and utilizing spatiotemporal states are effective.

摘要：線上心理諮商對話系統正夯，提供便利且容易取得的傳統面對面治療替代方案。
然而，現有的心理諮商對話系統主要專注於基本的同理對話或問答，專業知識最少且沒有目標引導。在許多真實世界的諮商情境中，客戶常尋求多種類型的協助，例如診斷、諮詢、治療、安慰和常見問題，但現有的對話系統難以自然地結合不同的對話類型。在本文中，我們將此挑戰界定為如何建構心理諮商的混合類型對話系統，讓客戶在進行諮商前釐清他們的目標。為了減輕此挑戰，我們收集了一個稱為 STAMPsy 的混合類型諮商對話語料庫，涵蓋五種類型的對話，包括診斷任務導向對話、知識基礎對話、對話式推薦、同理對話和問答，超過 5,000 場對話。此外，時空感知知識讓系統具備世界感知，並已被證實會影響一個人的心理健康。因此，我們將 STAMPsy 中的對話連結到時空狀態，並提出一個時空感知的混合類型心理諮商資料集。此外，我們在 STAMPsy 上建立基線，並開發一個名為 Self-STAMPsy 的迭代式自我回饋心理對話產生架構。結果顯示，事先釐清對話目標和利用時空狀態是有效的。

##### **Automated Bleeding Detection and Classification in Wireless Capsule Endoscopy with YOLOv8-X**
2412.16624v1 by Pavan C Shekar, Vivek Kanhangad, Shishir Maheshwari, T Sunil Kumar

Gastrointestinal (GI) bleeding, a critical indicator of digestive system
disorders, re quires efficient and accurate detection methods. This paper
presents our solution to the Auto-WCEBleedGen Version V1 Challenge, where we
achieved the consolation position. We developed a unified YOLOv8-X model for
both detection and classification of bleeding regions in Wireless Capsule
Endoscopy (WCE) images. Our approach achieved 96.10% classification accuracy
and 76.8% mean Average Precision (mAP) at 0.5 IoU on the val idation dataset.
Through careful dataset curation and annotation, we assembled and trained on
6,345 diverse images to ensure robust model performance. Our implementa tion
code and trained models are publicly available at
https://github.com/pavan98765/Auto-WCEBleedGen.

摘要：胃腸道 (GI) 出血是消化系統疾病的重要指標，需要有效且準確的檢測方法。本文提出我們對 Auto-WCEBleedGen 版本 V1 挑戰的解決方案，我們在其中取得了安慰獎。我們開發了一個統一的 YOLOv8-X 模型，用於無線膠囊內視鏡 (WCE) 影像中出血區域的檢測和分類。我們的做法在驗證資料集上以 0.5 IoU 達到了 96.10% 的分類準確度和 76.8% 的平均平均精度 (mAP)。透過仔細的資料集策劃和註解，我們收集並訓練了 6,345 張不同的影像，以確保模型的強健效能。我們的實作程式碼和訓練模型已公開於 https://github.com/pavan98765/Auto-WCEBleedGen。

##### **Patherea: Cell Detection and Classification for the 2020s**
2412.16425v1 by Dejan Štepec, Maja Jerše, Snežana Đokić, Jera Jeruc, Nina Zidar, Danijel Skočaj

This paper presents a Patherea, a framework for point-based cell detection
and classification that provides a complete solution for developing and
evaluating state-of-the-art approaches. We introduce a large-scale dataset
collected to directly replicate a clinical workflow for Ki-67 proliferation
index estimation and use it to develop an efficient point-based approach that
directly predicts point-based predictions, without the need for intermediate
representations. The proposed approach effectively utilizes point proposal
candidates with the hybrid Hungarian matching strategy and a flexible
architecture that enables the usage of various backbones and (pre)training
strategies. We report state-of-the-art results on existing public datasets -
Lizard, BRCA-M2C, BCData, and the newly proposed Patherea dataset. We show that
the performance on existing public datasets is saturated and that the newly
proposed Patherea dataset represents a significantly harder challenge for the
recently proposed approaches. We also demonstrate the effectiveness of recently
proposed pathology foundational models that our proposed approach can natively
utilize and benefit from. We also revisit the evaluation protocol that is used
in the broader field of cell detection and classification and identify the
erroneous calculation of performance metrics. Patherea provides a benchmarking
utility that addresses the identified issues and enables a fair comparison of
different approaches. The dataset and the code will be publicly released upon
acceptance.

摘要：本文介紹 Patherea，一個基於點的細胞偵測和分類架構，提供一個完整的解決方案，用於開發和評估最先進的方法。我們引入了一個大規模的資料集，用於直接複製 Ki-67 增殖指數估計的臨床工作流程，並使用它來開發一種有效的基於點的方法，該方法直接預測基於點的預測，無需中間表示。所提出的方法有效地利用了具有混合匈牙利匹配策略的點建議候選者和一個靈活的架構，該架構可以使用各種骨幹和（預）訓練策略。我們報告了現有公共資料集的最新結果 - Lizard、BRCA-M2C、BCData 和新提出的 Patherea 資料集。我們表明現有公共資料集上的效能已經飽和，並且新提出的 Patherea 資料集對最近提出的方法來說是一個顯著更困難的挑戰。我們還展示了最近提出的病理基礎模型的有效性，我們的建議方法可以原生利用並受益於這些模型。我們還重新審視了在細胞偵測和分類的廣泛領域中使用的評估協定，並找出效能指標的錯誤計算。Patherea 提供了一個基準測試工具，可以解決已識別的問題，並允許公平地比較不同的方法。在獲得接受後，資料集和程式碼將公開釋出。

##### **Technical Report: Small Language Model for Japanese Clinical and Medicine**
2412.16423v1 by Shogo Watanabe

This report presents a small language model (SLM) for Japanese clinical and
medicine, named NCVC-slm-1. This 1B parameters model was trained using Japanese
text classified to be of high-quality. Moreover, NCVC-slm-1 was augmented with
respect to clinical and medicine content that includes the variety of diseases,
drugs, and examinations. Using a carefully designed pre-processing, a
specialized morphological analyzer and tokenizer, this small and light-weight
model performed not only to generate text but also indicated the feasibility of
understanding clinical and medicine text. In comparison to other large language
models, a fine-tuning NCVC-slm-1 demonstrated the highest scores on 6 tasks of
total 8 on JMED-LLM. According to this result, SLM indicated the feasibility of
performing several downstream tasks in the field of clinical and medicine.
Hopefully, NCVC-slm-1 will be contributed to develop and accelerate the field
of clinical and medicine for a bright future.

摘要：本報告提出一個針對日文臨床和醫學的小型語言模型 (SLM)，名為 NCVC-slm-1。這個 1B 參數模型是使用被分類為高品質的日文文本訓練的。此外，NCVC-slm-1 還針對臨床和醫學內容進行擴充，其中包含各種疾病、藥物和檢查。使用精心設計的預處理、專業形態分析器和分詞器，這個小而輕的模型不僅可以生成文字，還表示了理解臨床和醫學文本的可行性。與其他大型語言模型相比，微調後的 NCVC-slm-1 在 JMED-LLM 的 8 個任務中有 6 個任務上表現出最高的得分。根據這個結果，SLM 表示了執行臨床和醫學領域中多項下游任務的可行性。希望 NCVC-slm-1 能為臨床和醫學領域的發展和加速做出貢獻，邁向光明的未來。

##### **Learning Disease Progression Models That Capture Health Disparities**
2412.16406v1 by Erica Chiang, Divya Shanmugam, Ashley N. Beecy, Gabriel Sayer, Nir Uriel, Deborah Estrin, Nikhil Garg, Emma Pierson

Disease progression models are widely used to inform the diagnosis and
treatment of many progressive diseases. However, a significant limitation of
existing models is that they do not account for health disparities that can
bias the observed data. To address this, we develop an interpretable Bayesian
disease progression model that captures three key health disparities: certain
patient populations may (1) start receiving care only when their disease is
more severe, (2) experience faster disease progression even while receiving
care, or (3) receive follow-up care less frequently conditional on disease
severity. We show theoretically and empirically that failing to account for
disparities produces biased estimates of severity (underestimating severity for
disadvantaged groups, for example). On a dataset of heart failure patients, we
show that our model can identify groups that face each type of health
disparity, and that accounting for these disparities meaningfully shifts which
patients are considered high-risk.

摘要：疾病進程模型廣泛用於告知許多進行性疾病的診斷和治療。然而，現有模型的一個重大限制是它們沒有考慮可能使觀察到的資料產生偏差的健康差異。為了解決這個問題，我們開發了一個可解釋的貝氏疾病進程模型，該模型捕獲了三個主要的健康差異：某些患者群體可能 (1) 只有在他們的疾病更嚴重時才開始接受照護，(2) 即使在接受照護時，疾病進程也更快，或 (3) 根據疾病嚴重程度，接受追蹤照護的頻率較低。我們在理論上和經驗上證明，未能考慮差異會產生嚴重程度的偏差估計（例如，低估弱勢群體的嚴重程度）。在心臟衰竭患者的資料集中，我們證明我們的模型可以識別面對每種類型健康差異的群體，並且考慮這些差異會顯著改變哪些患者被認為是高風險。

##### **Ethics and Technical Aspects of Generative AI Models in Digital Content Creation**
2412.16389v1 by Atahan Karagoz

Generative AI models like GPT-4o and DALL-E 3 are reshaping digital content
creation, offering industries tools to generate diverse and sophisticated text
and images with remarkable creativity and efficiency. This paper examines both
the capabilities and challenges of these models within creative workflows.
While they deliver high performance in generating content with creativity,
diversity, and technical precision, they also raise significant ethical
concerns. Our study addresses two key research questions: (a) how these models
perform in terms of creativity, diversity, accuracy, and computational
efficiency, and (b) the ethical risks they present, particularly concerning
bias, authenticity, and potential misuse. Through a structured series of
experiments, we analyze their technical performance and assess the ethical
implications of their outputs, revealing that although generative models
enhance creative processes, they often reflect biases from their training data
and carry ethical vulnerabilities that require careful oversight. This research
proposes ethical guidelines to support responsible AI integration into industry
practices, fostering a balance between innovation and ethical integrity.

摘要：生成式 AI 模型，例如 GPT-4o 和 DALL-E 3，正在重塑數位內容的創作，為各產業提供工具，以非凡的創造力和效率產生多元且精密的文字和影像。本文探討這些模型在創作工作流程中的功能和挑戰。儘管它們在產生具有創造力、多樣性和技術精確度的內容方面表現出色，但它們也引發了重大的道德問題。我們的研究探討了兩個關鍵的研究問題：(a) 這些模型在創造力、多樣性、準確性和計算效率方面的表現，以及 (b) 它們所帶來的道德風險，特別是關於偏見、真實性和潛在的濫用。透過一連串結構化的實驗，我們分析了它們的技術效能，並評估了它們的輸出結果的道德影響，揭示了儘管生成式模型增強了創作流程，但它們通常會反映其訓練資料的偏見，並存在需要仔細監督的道德漏洞。本研究提出了道德準則，以支援負責任的 AI 整合到產業實務中，在創新和道德操守之間取得平衡。

##### **VerSe: Integrating Multiple Queries as Prompts for Versatile Cardiac MRI Segmentation**
2412.16381v1 by Bangwei Guo, Meng Ye, Yunhe Gao, Bingyu Xin, Leon Axel, Dimitris Metaxas

Despite the advances in learning-based image segmentation approach, the
accurate segmentation of cardiac structures from magnetic resonance imaging
(MRI) remains a critical challenge. While existing automatic segmentation
methods have shown promise, they still require extensive manual corrections of
the segmentation results by human experts, particularly in complex regions such
as the basal and apical parts of the heart. Recent efforts have been made on
developing interactive image segmentation methods that enable human-in-the-loop
learning. However, they are semi-automatic and inefficient, due to their
reliance on click-based prompts, especially for 3D cardiac MRI volumes. To
address these limitations, we propose VerSe, a Versatile Segmentation framework
to unify automatic and interactive segmentation through mutiple queries. Our
key innovation lies in the joint learning of object and click queries as
prompts for a shared segmentation backbone. VerSe supports both fully automatic
segmentation, through object queries, and interactive mask refinement, by
providing click queries when needed. With the proposed integrated prompting
scheme, VerSe demonstrates significant improvement in performance and
efficiency over existing methods, on both cardiac MRI and out-of-distribution
medical imaging datasets. The code is available at
https://github.com/bangwayne/Verse.

摘要：儘管在基於學習的影像分割方法有進展，但從磁振造影 (MRI) 中準確分割出心臟結構仍然是一項關鍵挑戰。雖然現有的自動分割方法已展現出前景，但它們仍然需要人類專家對分割結果進行廣泛的手動修正，特別是在心臟的基底和心尖等複雜區域。最近已針對開發互動式影像分割方法做出努力，這些方法讓人類參與迴圈學習。然而，由於它們依賴於基於點擊的提示，因此它們是半自動且低效率的，特別是對於 3D 心臟 MRI 影像量。為了解決這些限制，我們提出了 VerSe，一個多重查詢的通用分割框架，用於統一自動和互動式分割。我們的關鍵創新在於將物件和點擊查詢作為提示，共同學習共享分割主幹。VerSe 支援透過物件查詢進行全自動分割，並在需要時提供點擊查詢，進行互動式遮罩精煉。透過所提出的整合式提示機制，VerSe 在心臟 MRI 和非分布式醫療影像資料集上，都證明了在效能和效率方面有顯著的進步。程式碼可在 https://github.com/bangwayne/Verse 取得。

##### **FairREAD: Re-fusing Demographic Attributes after Disentanglement for Fair Medical Image Classification**
2412.16373v1 by Yicheng Gao, Jinkui Hao, Bo Zhou

Recent advancements in deep learning have shown transformative potential in
medical imaging, yet concerns about fairness persist due to performance
disparities across demographic subgroups. Existing methods aim to address these
biases by mitigating sensitive attributes in image data; however, these
attributes often carry clinically relevant information, and their removal can
compromise model performance-a highly undesirable outcome. To address this
challenge, we propose Fair Re-fusion After Disentanglement (FairREAD), a novel,
simple, and efficient framework that mitigates unfairness by re-integrating
sensitive demographic attributes into fair image representations. FairREAD
employs orthogonality constraints and adversarial training to disentangle
demographic information while using a controlled re-fusion mechanism to
preserve clinically relevant details. Additionally, subgroup-specific threshold
adjustments ensure equitable performance across demographic groups.
Comprehensive evaluations on a large-scale clinical X-ray dataset demonstrate
that FairREAD significantly reduces unfairness metrics while maintaining
diagnostic accuracy, establishing a new benchmark for fairness and performance
in medical image classification.

摘要：深度學習的最新進展已在醫學影像中展現出變革的潛力，但由於不同人口子群體間的效能差異，公平性的疑慮仍然存在。現有方法旨在通過減輕影像資料中的敏感屬性來解決這些偏差；然而，這些屬性通常包含臨床相關資訊，而移除它們可能會損害模型效能，這是一個非常不理想的結果。為了應對這個挑戰，我們提出公平解糾後重新融合 (FairREAD)，這是一個新穎、簡單且高效的架構，它透過將敏感的人口統計屬性重新整合到公平的影像表示中，來減輕不公平性。FairREAD 使用正交約束和對抗訓練來解開人口統計資訊，同時使用受控重新融合機制來保留臨床相關的細節。此外，特定子群的閾值調整可確保不同人口群體之間的效能公平。在大型臨床 X 光資料集上的全面評估證明，FairREAD 在維持診斷準確性的同時，顯著降低了不公平性指標，為醫學影像分類中的公平性和效能建立了新的基準。

##### **Improving Object Detection for Time-Lapse Imagery Using Temporal Features in Wildlife Monitoring**
2412.16329v1 by Marcus Jenkins, Kirsty A. Franklin, Malcolm A. C. Nicoll, Nik C. Cole, Kevin Ruhomaun, Vikash Tatayah, Michal Mackiewicz

Monitoring animal populations is crucial for assessing the health of
ecosystems. Traditional methods, which require extensive fieldwork, are
increasingly being supplemented by time-lapse camera-trap imagery combined with
an automatic analysis of the image data. The latter usually involves some
object detector aimed at detecting relevant targets (commonly animals) in each
image, followed by some postprocessing to gather activity and population data.
In this paper, we show that the performance of an object detector in a single
frame of a time-lapse sequence can be improved by including spatio-temporal
features from the prior frames. We propose a method that leverages temporal
information by integrating two additional spatial feature channels which
capture stationary and non-stationary elements of the scene and consequently
improve scene understanding and reduce the number of stationary false
positives. The proposed technique achieves a significant improvement of 24\% in
mean average precision (mAP@0.05:0.95) over the baseline (temporal
feature-free, single frame) object detector on a large dataset of breeding
tropical seabirds. We envisage our method will be widely applicable to other
wildlife monitoring applications that use time-lapse imaging.

摘要：監控動物族群對於評估生態系統的健康至關重要。傳統方法需要大量實地工作，現正逐漸由結合自動化影像資料分析的時間縮時相機陷阱影像所補充。後者通常涉及一些目標偵測器，用於偵測每張影像中相關目標（通常是動物），接著進行一些後處理以收集活動和族群資料。在本文中，我們展示了在時間縮時序列的單一影格中，目標偵測器的效能可透過納入先前影格的時空特徵而獲得改善。我們提出了一種方法，透過整合兩個額外的空間特徵通道來利用時間資訊，這些通道捕捉場景的靜態和非靜態元素，並因此改善場景理解，並減少靜態誤報的數量。所提出的技術在大型熱帶海鳥繁殖數據集上，平均準確度 (mAP@0.05:0.95) 較基線（無時間特徵的單一影格）目標偵測器顯著提升了 24%。我們預見我們的技術將廣泛應用於其他使用時間縮時影像的野生動物監控應用程式。

##### **Benchmarking LLMs and SLMs for patient reported outcomes**
2412.16291v1 by Matteo Marengo, Jarod Lévy, Jean-Emmanuel Bibault

LLMs have transformed the execution of numerous tasks, including those in the
medical domain. Among these, summarizing patient-reported outcomes (PROs) into
concise natural language reports is of particular interest to clinicians, as it
enables them to focus on critical patient concerns and spend more time in
meaningful discussions. While existing work with LLMs like GPT-4 has shown
impressive results, real breakthroughs could arise from leveraging SLMs as they
offer the advantage of being deployable locally, ensuring patient data privacy
and compliance with healthcare regulations. This study benchmarks several SLMs
against LLMs for summarizing patient-reported Q\&A forms in the context of
radiotherapy. Using various metrics, we evaluate their precision and
reliability. The findings highlight both the promise and limitations of SLMs
for high-stakes medical tasks, fostering more efficient and privacy-preserving
AI-driven healthcare solutions.

摘要：大型語言模型 (LLM) 已轉變了許多任務的執行方式，包括醫療領域的任務。其中，將患者報告的結果 (PRO) 摘要成簡潔的自然語言報告對臨床醫生特別有幫助，因為這能讓他們專注於患者的關鍵問題，並花更多時間在有意義的討論上。雖然像 GPT-4 等大型語言模型的現有研究成果令人印象深刻，但真正的突破可能來自於利用小型語言模型 (SLM)，因為它們具有可於本地部署的優點，確保患者資料的隱私和符合醫療法規。本研究針對放射治療情境中患者報告的問答表，將多個小型語言模型與大型語言模型進行比較。我們使用各種指標來評估它們的精確度和可靠性。研究結果突顯了小型語言模型在高風險醫療任務中的優點和限制，促進更有效率且能保護隱私的 AI 驅動醫療保健解決方案。

##### **Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG**
2412.16086v1 by Hasan Md Tusfiqur Alam, Devansh Srivastav, Md Abdul Kadir, Daniel Sonntag

Deep learning has advanced medical image classification, but interpretability
challenges hinder its clinical adoption. This study enhances interpretability
in Chest X-ray (CXR) classification by using concept bottleneck models (CBMs)
and a multi-agent Retrieval-Augmented Generation (RAG) system for report
generation. By modeling relationships between visual features and clinical
concepts, we create interpretable concept vectors that guide a multi-agent RAG
system to generate radiology reports, enhancing clinical relevance,
explainability, and transparency. Evaluation of the generated reports using an
LLM-as-a-judge confirmed the interpretability and clinical utility of our
model's outputs. On the COVID-QU dataset, our model achieved 81% classification
accuracy and demonstrated robust report generation performance, with five key
metrics ranging between 84% and 90%. This interpretable multi-agent framework
bridges the gap between high-performance AI and the explainability required for
reliable AI-driven CXR analysis in clinical settings.

摘要：深度學習已進步了醫學影像分類，但可解釋性挑戰阻礙了其臨床採用。本研究透過使用概念瓶頸模型 (CBM) 和多重代理檢索增強生成 (RAG) 系統進行報告生成，增強了胸部 X 光 (CXR) 分類的可解釋性。透過對視覺特徵和臨床概念之間的關係進行建模，我們建立了可解釋的概念向量，用來引導多重代理 RAG 系統生成放射科報告，以增強臨床相關性、可解釋性和透明性。使用 LLM 作為判斷者對生成的報告進行評估，確認了我們模型輸出的可解釋性和臨床實用性。在 COVID-QU 資料集上，我們的模型達到了 81% 的分類準確度，並展示了強健的報告生成效能，五項關鍵指標介於 84% 到 90% 之間。這個可解釋的多重代理架構彌合了高性能 AI 與在臨床環境中進行可靠 AI 驅動 CXR 分析所需的可解釋性之間的差距。

##### **Intelligent Approaches to Predictive Analytics in Occupational Health and Safety in India**
2412.16038v3 by Ritwik Raj Saxena

Concerns associated with occupational health and safety (OHS) remain critical
and often under-addressed aspects of workforce management. This is especially
true for high-risk industries such as manufacturing, construction, and mining.
Such industries dominate the economy of India which is a developing country
with a vast informal sector. Regulatory frameworks have been strengthened over
the decades, particularly with regards to bringing the unorganized sector
within the purview of law. Traditional approaches to OHS have largely been
reactive and rely on post-incident analysis (which is curative) rather than
preventive intervention. This paper portrays the immense potential of
predictive analytics in rejuvenating OHS practices in India. Intelligent
predictive analytics is driven by approaches like machine learning and
statistical modeling. Its data-driven nature serves to overcome the limitations
of conventional OHS methods. Predictive analytics approaches to OHS in India
draw on global case studies and generative applications of predictive analytics
in OHS which are customized to Indian industrial contexts. This paper attempts
to explore in what ways it exhibits the potential to address challenges such as
fragmented data ecosystems, resource constraints, and the variability of
workplace hazards. The paper presents actionable policy recommendations to
create conditions conducive to the widespread implementation of predictive
analytics, which must be advocated as a cornerstone of OHS strategy. In doing
so, the paper aims to spark a collaborational dialogue among policymakers,
industry leaders, and technologists. It urges a shift towards intelligent
practices to safeguard the well-being of India's workforce.

摘要：與職業健康與安全 (OHS) 相關的疑慮仍然是人力資源管理中至關重要且經常被低估的面向。這在製造、建築和採礦等高風險產業中尤其明顯。這些產業主導了印度的經濟，而印度是一個擁有龐大非正式部門的開發中國家。法規架構在過去幾十年中得到加強，特別是在將非組織部門納入法律範圍內方面。傳統的 OHS 方法在很大程度上是被動的，依賴於事後分析（具有治療作用），而不是預防性干預。本文描繪了預測分析在重振印度 OHS 實務中的巨大潛力。智慧預測分析是由機器學習和統計建模等方法驅動的。其數據驅動的本質有助於克服傳統 OHS 方法的限制。印度的 OHS 預測分析方法借鑑了全球案例研究和預測分析在 OHS 中的生成式應用，這些應用已針對印度產業背景進行調整。本文嘗試探討它如何展現出應對分散數據生態系統、資源限制和工作場所危害變異性等挑戰的潛力。本文提出了可行的政策建議，以創造有利於廣泛實施預測分析的條件，必須提倡將其作為 OHS 策略的基石。在這樣做的過程中，本文旨在激發政策制定者、產業領導者和技術人員之間的合作對話。它敦促轉向智慧實務以保障印度勞動力的福祉。

##### **Self-Supervised Radiograph Anatomical Region Classification -- How Clean Is Your Real-World Data?**
2412.15967v1 by Simon Langer, Jessica Ritter, Rickmer Braren, Daniel Rueckert, Paul Hager

Modern deep learning-based clinical imaging workflows rely on accurate labels
of the examined anatomical region. Knowing the anatomical region is required to
select applicable downstream models and to effectively generate cohorts of high
quality data for future medical and machine learning research efforts. However,
this information may not be available in externally sourced data or generally
contain data entry errors. To address this problem, we show the effectiveness
of self-supervised methods such as SimCLR and BYOL as well as supervised
contrastive deep learning methods in assigning one of 14 anatomical region
classes in our in-house dataset of 48,434 skeletal radiographs. We achieve a
strong linear evaluation accuracy of 96.6% with a single model and 97.7% using
an ensemble approach. Furthermore, only a few labeled instances (1% of the
training set) suffice to achieve an accuracy of 92.2%, enabling usage in
low-label and thus low-resource scenarios. Our model can be used to correct
data entry mistakes: a follow-up analysis of the test set errors of our
best-performing single model by an expert radiologist identified 35% incorrect
labels and 11% out-of-domain images. When accounted for, the radiograph
anatomical region labelling performance increased -- without and with an
ensemble, respectively -- to a theoretical accuracy of 98.0% and 98.8%.

摘要：現代的深度學習臨床影像工作流程依賴於檢查解剖區域的準確標籤。了解解剖區域是必要的，用於選擇適用的下游模型，並有效地為未來的醫療和機器學習研究工作生成高品質資料群組。然而，此資訊可能無法在外部來源的資料中取得，或通常包含資料輸入錯誤。為了解決這個問題，我們展示了自監督方法（例如 SimCLR 和 BYOL）以及監督對比深度學習方法在我們內部 48,434 張骨骼 X 光片的資料集中分配 14 個解剖區域類別之一的有效性。我們使用單一模型達到了 96.6% 的強線性評估準確度，並使用整體方法達到了 97.7%。此外，僅有少數標記實例（訓練組的 1%）就足以達到 92.2% 的準確度，這使得在標籤少且資源少的情況下使用成為可能。我們的模型可用於更正資料輸入錯誤：由專業放射科醫師對我們效能最佳的單一模型的測試組錯誤進行後續分析，識別出 35% 的錯誤標籤和 11% 的領域外影像。在考慮到的情況下，X 光片解剖區域標籤效能提高了（分別在沒有和有整體的情況下）達到 98.0% 和 98.8% 的理論準確度。

##### **From General to Specific: Tailoring Large Language Models for Personalized Healthcare**
2412.15957v1 by Ruize Shi, Hong Huang, Wei Zhou, Kehan Yin, Kai Zhao, Yun Zhao

The rapid development of large language models (LLMs) has transformed many
industries, including healthcare. However, previous medical LLMs have largely
focused on leveraging general medical knowledge to provide responses, without
accounting for patient variability and lacking true personalization at the
individual level. To address this, we propose a novel method called
personalized medical language model (PMLM), which explores and optimizes
personalized LLMs through recommendation systems and reinforcement learning
(RL). Specifically, by utilizing self-informed and peer-informed
personalization, PMLM captures changes in behaviors and preferences to design
initial personalized prompts tailored to individual needs. We further refine
these initial personalized prompts through RL, ultimately enhancing the
precision of LLM guidance. Notably, the personalized prompt are hard prompt,
which grants PMLM high adaptability and reusability, allowing it to directly
leverage high-quality proprietary LLMs. We evaluate PMLM using real-world
obstetrics and gynecology data, and the experimental results demonstrate that
PMLM achieves personalized responses, and it provides more refined and
individualized services, offering a potential way for personalized medical
LLMs.

摘要：大型語言模型 (LLM) 的快速發展已轉變許多產業，包括醫療保健。然而，先前的醫療 LLM 主要專注於利用一般醫療知識提供回應，並未考量病患的變異性，且缺乏個人層級的真正個人化。為了解決此問題，我們提出了一種稱為個人化醫療語言模型 (PMLM) 的新方法，透過推薦系統和強化學習 (RL) 來探索和最佳化個人化的 LLM。具體來說，PMLM 透過利用自我知情和同儕知情的個人化，擷取行為和偏好的變化，以設計符合個人需求的初始個人化提示。我們進一步透過 RL 調整這些初始個人化提示，最終提升 LLM 指導的精確度。值得注意的是，個人化提示是硬提示，這賦予 PMLM 高度的適應性和可重複使用性，使其能夠直接利用高品質的專有 LLM。我們使用真實世界的產科和婦科資料評估 PMLM，實驗結果顯示 PMLM 達到了個人化的回應，並提供了更精緻和個人化的服務，為個人化的醫療 LLM 提供了一種潛在的方法。

##### **Development of a Large-scale Dataset of Chest Computed Tomography Reports in Japanese and a High-performance Finding Classification Model**
2412.15907v1 by Yosuke Yamagishi, Yuta Nakamura, Tomohiro Kikuchi, Yuki Sonoda, Hiroshi Hirakawa, Shintaro Kano, Satoshi Nakamura, Shouhei Hanaoka, Takeharu Yoshikawa, Osamu Abe

Background: Recent advances in large language models highlight the need for
high-quality multilingual medical datasets. While Japan leads globally in CT
scanner deployment and utilization, the lack of large-scale Japanese radiology
datasets has hindered the development of specialized language models for
medical imaging analysis. Objective: To develop a comprehensive Japanese CT
report dataset through machine translation and establish a specialized language
model for structured finding classification. Additionally, to create a
rigorously validated evaluation dataset through expert radiologist review.
Methods: We translated the CT-RATE dataset (24,283 CT reports from 21,304
patients) into Japanese using GPT-4o mini. The training dataset consisted of
22,778 machine-translated reports, while the validation dataset included 150
radiologist-revised reports. We developed CT-BERT-JPN based on
"tohoku-nlp/bert-base-japanese-v3" architecture for extracting 18 structured
findings from Japanese radiology reports. Results: Translation metrics showed
strong performance with BLEU scores of 0.731 and 0.690, and ROUGE scores
ranging from 0.770 to 0.876 for Findings and from 0.748 to 0.857 for Impression
sections. CT-BERT-JPN demonstrated superior performance compared to GPT-4o in
11 out of 18 conditions, including lymphadenopathy (+14.2%), interlobular
septal thickening (+10.9%), and atelectasis (+7.4%). The model maintained F1
scores exceeding 0.95 in 14 out of 18 conditions and achieved perfect scores in
four conditions. Conclusions: Our study establishes a robust Japanese CT report
dataset and demonstrates the effectiveness of a specialized language model for
structured finding classification. The hybrid approach of machine translation
and expert validation enables the creation of large-scale medical datasets
while maintaining high quality.

摘要：背景：大型語言模型的最新進展凸顯了對高品質多語言醫療資料集的需求。日本在 CT 掃描儀的部署和使用方面處於全球領先地位，但缺乏大規模的日語放射科資料集阻礙了針對醫學影像分析的專門語言模型的開發。目標：透過機器翻譯開發一個全面的日語 CT 報告資料集，並建立一個專門的語言模型，用於結構化結果分類。此外，透過專家放射科醫師的審查，建立一個嚴格驗證的評估資料集。方法：我們使用 GPT-4o mini 將 CT-RATE 資料集（來自 21,304 名患者的 24,283 份 CT 報告）翻譯成日語。訓練資料集包含 22,778 份機器翻譯報告，而驗證資料集包含 150 份放射科醫師修改過的報告。我們基於「tohoku-nlp/bert-base-japanese-v3」架構開發了 CT-BERT-JPN，用於從日語放射科報告中提取 18 項結構化結果。結果：翻譯指標顯示強勁的表現，BLEU 分數為 0.731 和 0.690，而 ROUGE 分數從結果的 0.770 到 0.876，從印象部分的 0.748 到 0.857 不等。與 GPT-4o 相比，CT-BERT-JPN 在 18 種情況中的 11 種情況下表現出優異的表現，包括淋巴腺病變（+14.2%）、小葉間隔增厚（+10.9%）和肺不張（+7.4%）。該模型在 18 種情況中的 14 種情況下維持 F1 分數超過 0.95，並在四種情況下達到完美分數。結論：我們的研究建立了一個強大的日語 CT 報告資料集，並展示了一個專門的語言模型在結構化結果分類方面的有效性。機器翻譯和專家驗證的混合方法能夠建立大規模的醫療資料集，同時保持高品質。

##### **Linguistic Features Extracted by GPT-4 Improve Alzheimer's Disease Detection based on Spontaneous Speech**
2412.15772v1 by Jonathan Heitz, Gerold Schneider, Nicolas Langer

Alzheimer's Disease (AD) is a significant and growing public health concern.
Investigating alterations in speech and language patterns offers a promising
path towards cost-effective and non-invasive early detection of AD on a large
scale. Large language models (LLMs), such as GPT, have enabled powerful new
possibilities for semantic text analysis. In this study, we leverage GPT-4 to
extract five semantic features from transcripts of spontaneous patient speech.
The features capture known symptoms of AD, but they are difficult to quantify
effectively using traditional methods of computational linguistics. We
demonstrate the clinical significance of these features and further validate
one of them ("Word-Finding Difficulties") against a proxy measure and human
raters. When combined with established linguistic features and a Random Forest
classifier, the GPT-derived features significantly improve the detection of AD.
Our approach proves effective for both manually transcribed and automatically
generated transcripts, representing a novel and impactful use of recent
advancements in LLMs for AD speech analysis.

摘要：阿茲海默症 (AD) 是個重大的且持續增加的公共衛生問題。
調查言語和語言模式的變化提供了一個有前景的途徑，可以大規模地對 AD 進行經濟有效且非侵入性的早期偵測。大型語言模型 (LLM)，例如 GPT，已經為語義文字分析開啟了強大的新可能性。在這項研究中，我們利用 GPT-4 從自發性患者言語的轉錄中提取五個語義特徵。這些特徵捕捉了 AD 的已知症狀，但使用傳統的計算語言學方法很難有效地量化它們。我們展示了這些特徵的臨床意義，並進一步驗證了其中一個特徵（「詞彙尋找困難」）與代理測量和人類評分員的結果。當與既定的語言特徵和隨機森林分類器結合時，GPT 衍生的特徵顯著改善了 AD 的偵測。我們的做法證明了手動轉錄和自動產生的轉錄都是有效的，這代表了 LLM 在 AD 語言分析中最新進展的一種新穎且有影響力的應用。

##### **Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models**
2412.15748v1 by Shamus Sim, Tyrone Chen

Background: Despite the current ubiquity of Large Language Models (LLMs)
across the medical domain, there is a surprising lack of studies which address
their reasoning behaviour. We emphasise the importance of understanding
reasoning behaviour as opposed to high-level prediction accuracies, since it is
equivalent to explainable AI (XAI) in this context. In particular, achieving
XAI in medical LLMs used in the clinical domain will have a significant impact
across the healthcare sector. Results: Therefore, we define the concept of
reasoning behaviour in the specific context of medical LLMs. We then categorise
and discuss the current state of the art of methods which evaluate reasoning
behaviour in medical LLMs. Finally, we propose theoretical frameworks which can
empower medical professionals or machine learning engineers to gain insight
into the low-level reasoning operations of these previously obscure models.
Conclusion: The subsequent increased transparency and trust in medical machine
learning models by clinicians as well as patients will accelerate the
integration, application as well as further development of medical AI for the
healthcare system as a whole

摘要：背景：儘管大型語言模型 (LLM) 目前在醫療領域無所不在，但令人驚訝的是，探討其推理行為的研究卻相當缺乏。我們強調了解推理行為而非高層級的預測準確度非常重要，因為在這種情況下，這等同於可解釋 AI (XAI)。尤其是在臨床領域中使用的醫療 LLM 中實現 XAI，將對整個醫療保健產業產生重大影響。結果：因此，我們在醫療 LLM 的特定背景下定義了推理行為的概念。接著我們分類並探討當前評估醫療 LLM 中推理行為的方法的最新技術。最後，我們提出理論架構，讓醫療專業人員或機器學習工程師得以深入了解這些先前模糊模型的低層級推理運算。結論：臨床醫生和患者對醫療機器學習模型的透明度和信任度隨之提升，將加速醫療 AI 在整個醫療保健系統中的整合、應用和進一步發展。

##### **NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning**
2412.15547v1 by Zheyuan Zhang, Yiyang Li, Nhi Ha Lan Le, Zehong Wang, Tianyi Ma, Vincent Galassi, Keerthiram Murugesan, Nuno Moniz, Werner Geyer, Nitesh V Chawla, Chuxu Zhang, Yanfang Ye

Diet plays a critical role in human health, yet tailoring dietary reasoning
to individual health conditions remains a major challenge. Nutrition Question
Answering (QA) has emerged as a popular method for addressing this problem.
However, current research faces two critical limitations. On one hand, the
absence of datasets involving user-specific medical information severely limits
\textit{personalization}. This challenge is further compounded by the wide
variability in individual health needs. On the other hand, while large language
models (LLMs), a popular solution for this task, demonstrate strong reasoning
abilities, they struggle with the domain-specific complexities of personalized
healthy dietary reasoning, and existing benchmarks fail to capture these
challenges. To address these gaps, we introduce the Nutritional Graph Question
Answering (NGQA) benchmark, the first graph question answering dataset designed
for personalized nutritional health reasoning. NGQA leverages data from the
National Health and Nutrition Examination Survey (NHANES) and the Food and
Nutrient Database for Dietary Studies (FNDDS) to evaluate whether a food is
healthy for a specific user, supported by explanations of the key contributing
nutrients. The benchmark incorporates three question complexity settings and
evaluates reasoning across three downstream tasks. Extensive experiments with
LLM backbones and baseline models demonstrate that the NGQA benchmark
effectively challenges existing models. In sum, NGQA addresses a critical
real-world problem while advancing GraphQA research with a novel
domain-specific benchmark.

摘要：飲食在人類健康中扮演著至關重要的角色，然而根據個人健康狀況調整飲食推理仍然是一項重大的挑戰。營養問題問答 (QA) 已成為解決此問題的流行方法。不過，目前的研究面臨兩項重大的限制。一方面，缺乏包含使用者特定醫療資訊的資料集嚴重限制了「個人化」。這個挑戰進一步受到個人健康需求廣泛變異的影響。另一方面，雖然大型語言模型 (LLM) 是此任務的熱門解決方案，展示出強大的推理能力，但它們在個人化健康飲食推理的特定領域複雜性上仍有困難，而現有的基準也無法捕捉這些挑戰。為了解決這些差距，我們引入了營養圖表問答 (NGQA) 基準，這是第一個專為個人化營養健康推理設計的圖表問答資料集。NGQA 利用國家健康與營養檢查調查 (NHANES) 和飲食研究食物與營養資料庫 (FNDDS) 的資料，評估食物是否對特定使用者健康，並說明主要貢獻營養素。此基準納入了三個問題複雜度設定，並評估三個下游任務的推理。使用 LLM 主幹和基線模型進行的廣泛實驗證明，NGQA 基準有效挑戰了現有模型。總之，NGQA 解決了一個重大的現實世界問題，同時透過新穎的特定領域基準推動了 GraphQA 研究。

##### **The First Multilingual Model For The Detection of Suicide Texts**
2412.15498v1 by Rodolfo Zevallos, Annika Schoene, John E. Ortega

Suicidal ideation is a serious health problem affecting millions of people
worldwide. Social networks provide information about these mental health
problems through users' emotional expressions. We propose a multilingual model
leveraging transformer architectures like mBERT, XML-R, and mT5 to detect
suicidal text across posts in six languages - Spanish, English, German,
Catalan, Portuguese and Italian. A Spanish suicide ideation tweet dataset was
translated into five other languages using SeamlessM4T. Each model was
fine-tuned on this multilingual data and evaluated across classification
metrics. Results showed mT5 achieving the best performance overall with F1
scores above 85%, highlighting capabilities for cross-lingual transfer
learning. The English and Spanish translations also displayed high quality
based on perplexity. Our exploration underscores the importance of considering
linguistic diversity in developing automated multilingual tools to identify
suicidal risk. Limitations exist around semantic fidelity in translations and
ethical implications which provide guidance for future human-in-the-loop
evaluations.

摘要：自殺意念是一個嚴重的健康問題，影響全球數百萬人。社交網路透過使用者的情緒表達，提供這些心理健康問題的資訊。我們提出一個多語言模型，利用像 mBERT、XML-R 和 mT5 的轉換器架構，來偵測六種語言（西班牙文、英文、德文、加泰隆尼亞文、葡萄牙文和義大利文）貼文中具有自殺傾向的文字。一個西班牙文自殺意念推文資料集使用 SeamlessM4T 翻譯成其他五種語言。每個模型都針對這個多語言資料進行微調，並評估分類指標。結果顯示，mT5 在整體表現上達到最佳，F1 分數高於 85%，突顯跨語言轉移學習的能力。英文和西班牙文的翻譯也根據困惑度顯示出高品質。我們的探索強調在開發自動化多語言工具以識別自殺風險時，考慮語言多樣性的重要性。翻譯中的語義忠實度和倫理意涵存在限制，這些限制為未來的人類參與評估提供了指導。

##### **AI-Enhanced Sensemaking: Exploring the Design of a Generative AI-Based Assistant to Support Genetic Professionals**
2412.15444v1 by Angela Mastrianni, Hope Twede, Aleksandra Sarcevic, Jeremiah Wander, Christina Austin-Tse, Scott Saponas, Heidi Rehm, Ashley Mae Conard, Amanda K. Hall

Generative AI has the potential to transform knowledge work, but further
research is needed to understand how knowledge workers envision using and
interacting with generative AI. We investigate the development of generative AI
tools to support domain experts in knowledge work, examining task delegation
and the design of human-AI interactions. Our research focused on designing a
generative AI assistant to aid genetic professionals in analyzing whole genome
sequences (WGS) and other clinical data for rare disease diagnosis. Through
interviews with 17 genetics professionals, we identified current challenges in
WGS analysis. We then conducted co-design sessions with six genetics
professionals to determine tasks that could be supported by an AI assistant and
considerations for designing interactions with the AI assistant. From our
findings, we identified sensemaking as both a current challenge in WGS analysis
and a process that could be supported by AI. We contribute an understanding of
how domain experts envision interacting with generative AI in their knowledge
work, a detailed empirical study of WGS analysis, and three design
considerations for using generative AI to support domain experts in sensemaking
during knowledge work.
  CCS CONCEPTS: Human-centered computing, Human-computer interaction, Empirical
studies in HCI
  Additional Keywords and Phrases: whole genome sequencing, generative AI,
large language models, knowledge work, sensemaking, co-design, rare disease
  Contact Author: Angela Mastrianni (This work was done during the author's
internship at Microsoft Research)
  Ashley Mae Conard and Amanda K. Hall contributed equally

摘要：<paragraph>生成式 AI 有可能轉換知識工作，但需要進一步的研究來了解知識工作者如何設想使用和與生成式 AI 互動。我們研究了生成式 AI 工具的開發，以支援領域專家進行知識工作，探討任務委派和人機互動的設計。我們的研究重點在於設計一個生成式 AI 助理，以協助遺傳學專業人士分析全基因體序列 (WGS) 和其他臨床資料，以診斷罕見疾病。透過訪談 17 位遺傳學專業人士，我們找出 WGS 分析中的現有挑戰。然後，我們與六位遺傳學專業人士進行共同設計會議，以確定 AI 助理可以支援的任務，以及設計與 AI 助理互動的考量因素。根據我們的研究結果，我們將意義建構認定為 WGS 分析中的現有挑戰，以及 AI 可以支援的流程。我們有助於了解領域專家如何設想在知識工作中與生成式 AI 互動，WGS 分析的詳細實證研究，以及在知識工作中使用生成式 AI 支援領域專家進行意義建構的三個設計考量因素。
CCS 概念：以人為本的運算、人機互動、HCI 中的實證研究
其他關鍵字和詞組：全基因體定序、生成式 AI、大型語言模型、知識工作、意義建構、共同設計、罕見疾病
聯絡作者：Angela Mastrianni（這項工作是在作者於 Microsoft Research 實習期間完成的）
Ashley Mae Conard 和 Amanda K. Hall 貢獻相同</paragraph>

##### **GIRAFE: Glottal Imaging Dataset for Advanced Segmentation, Analysis, and Facilitative Playbacks Evaluation**
2412.15054v1 by G. Andrade-Miranda, K. Chatzipapas, J. D. Arias-Londoño, J. I. Godino-Llorente

The advances in the development of Facilitative Playbacks extracted from
High-Speed videoendoscopic sequences of the vocal folds are hindered by a
notable lack of publicly available datasets annotated with the semantic
segmentations corresponding to the area of the glottal gap. This fact also
limits the reproducibility and further exploration of existing research in this
field.
  To address this gap, GIRAFE is a data repository designed to facilitate the
development of advanced techniques for the semantic segmentation, analysis, and
fast evaluation of High-Speed videoendoscopic sequences of the vocal folds. The
repository includes 65 high-speed videoendoscopic recordings from a cohort of
50 patients (30 female, 20 male). The dataset comprises 15 recordings from
healthy controls, 26 from patients with diagnosed voice disorders, and 24 with
an unknown health condition. All of them were manually annotated by an expert,
including the masks corresponding to the semantic segmentation of the glottal
gap. The repository is also complemented with the automatic segmentation of the
glottal area using different state-of-the-art approaches.
  This data set has already supported several studies, which demonstrates its
usefulness for the development of new glottal gap segmentation algorithms from
High-Speed-Videoendoscopic sequences to improve or create new Facilitative
Playbacks. Despite these advances and others in the field, the broader
challenge of performing an accurate and completely automatic semantic
segmentation method of the glottal area remains open.

摘要：<paragraph>從高速聲門內視鏡序列中提取的促進性回放的發展進展受到明顯缺乏公開可用資料集的阻礙，這些資料集帶有與聲門間隙區域相應的語義分割註解。這個事實也限制了現有研究在此領域的可重現性和進一步探索。
  為了解決這個差距，GIRAFE 是旨在促進語義分割、分析和高速聲門內視鏡序列快速評估的先進技術開發的資料庫。這個資料庫包含來自 50 位患者（30 位女性，20 位男性）的 65 份高速聲門內視鏡錄音。該資料集包含 15 份來自健康對照組的錄音、26 份來自被診斷出患有聲音障礙的患者的錄音，以及 24 份來自健康狀況不明的患者的錄音。所有這些錄音都由專家手動註解，包括與聲門間隙語義分割相應的遮罩。該資料庫還使用不同的最先進方法補充了聲門區域的自動分割。
  此資料集已經支援多項研究，這證明了它對於從高速視頻內視鏡序列開發新的聲門間隙分割演算法以改善或建立新的促進性回放很有用。儘管在該領域取得了這些進展和其他進展，但執行準確且完全自動化的聲門區域語義分割方法的更廣泛挑戰仍然存在。</paragraph>

##### **RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response**
2412.14922v1 by Junyu Luo, Xiao Luo, Kaize Ding, Jingyang Yuan, Zhiping Xiao, Ming Zhang

Supervised fine-tuning (SFT) plays a crucial role in adapting large language
models (LLMs) to specific domains or tasks. However, as demonstrated by
empirical experiments, the collected data inevitably contains noise in
practical applications, which poses significant challenges to model performance
on downstream tasks. Therefore, there is an urgent need for a noise-robust SFT
framework to enhance model capabilities in downstream tasks. To address this
challenge, we introduce a robust SFT framework (RobustFT) that performs noise
detection and relabeling on downstream task data. For noise identification, our
approach employs a multi-expert collaborative system with inference-enhanced
models to achieve superior noise detection. In the denoising phase, we utilize
a context-enhanced strategy, which incorporates the most relevant and confident
knowledge followed by careful assessment to generate reliable annotations.
Additionally, we introduce an effective data selection mechanism based on
response entropy, ensuring only high-quality samples are retained for
fine-tuning. Extensive experiments conducted on multiple LLMs across five
datasets demonstrate RobustFT's exceptional performance in noisy scenarios.

摘要：監督式微調（SFT）在將大型語言模型（LLM）適應到特定領域或任務中扮演著至關重要的角色。然而，正如經驗實驗所證明，在實際應用中收集到的資料不可避免地包含雜訊，這對下游任務的模型效能構成了重大挑戰。因此，迫切需要一個抗雜訊的 SFT 框架，以增強模型在下游任務中的能力。為了應對這一挑戰，我們引入了穩健的 SFT 框架（RobustFT），它對下游任務資料執行雜訊偵測和重新標記。對於雜訊識別，我們的方法採用多專家協作系統，並使用增強推論的模型來實現優異的雜訊偵測。在去雜訊階段，我們利用一種情境增強策略，它結合了最相關和最確信的知識，然後進行仔細評估以產生可靠的註解。此外，我們還引入了一種基於回應熵的有效資料選取機制，確保僅保留高品質的樣本進行微調。在五個資料集上對多個 LLM 進行的廣泛實驗證明了 RobustFT 在雜訊情境中的出色效能。

##### **Advances in Artificial Intelligence forDiabetes Prediction: Insights from a Systematic Literature Review**
2412.14736v1 by Pir Bakhsh Khokhar, Carmine Gravino, Fabio Palomba

This systematic review explores the use of machine learning (ML) in
predicting diabetes, focusing on datasets, algorithms, training methods, and
evaluation metrics. It examines datasets like the Singapore National Diabetic
Retinopathy Screening program, REPLACE-BG, National Health and Nutrition
Examination Survey, and Pima Indians Diabetes Database. The review assesses the
performance of ML algorithms like CNN, SVM, Logistic Regression, and XGBoost in
predicting diabetes outcomes. The study emphasizes the importance of
interdisciplinary collaboration and ethical considerations in ML-based diabetes
prediction models.

摘要：這項系統性回顧探討了機器學習 (ML) 在糖尿病預測中的應用，重點在於資料集、演算法、訓練方法和評估指標。它檢驗了資料集，例如新加坡國家糖尿病視網膜病變篩檢計畫、REPLACE-BG、國家健康與營養檢查調查和皮馬印第安人糖尿病資料庫。該回顧評估了 ML 演算法（例如 CNN、SVM、邏輯迴歸和 XGBoost）在預測糖尿病結果方面的表現。這項研究強調了跨領域合作和在基於 ML 的糖尿病預測模型中進行道德考量的重要性。

##### **Pitfalls of topology-aware image segmentation**
2412.14619v1 by Alexander H. Berger, Laurin Lux, Alexander Weers, Martin Menten, Daniel Rueckert, Johannes C. Paetzold

Topological correctness, i.e., the preservation of structural integrity and
specific characteristics of shape, is a fundamental requirement for medical
imaging tasks, such as neuron or vessel segmentation. Despite the recent surge
in topology-aware methods addressing this challenge, their real-world
applicability is hindered by flawed benchmarking practices. In this paper, we
identify critical pitfalls in model evaluation that include inadequate
connectivity choices, overlooked topological artifacts in ground truth
annotations, and inappropriate use of evaluation metrics. Through detailed
empirical analysis, we uncover these issues' profound impact on the evaluation
and ranking of segmentation methods. Drawing from our findings, we propose a
set of actionable recommendations to establish fair and robust evaluation
standards for topology-aware medical image segmentation methods.

摘要：拓撲正確性，即形狀結構完整性和特定特徵的保留，是醫學影像任務（例如神經元或血管分割）的基本要求。儘管最近解決此挑戰的拓撲感知方法激增，但其真實世界的適用性受到有缺陷的基準測試實務的阻礙。在本文中，我們確定了模型評估中的關鍵缺陷，包括不適當的連接選擇、基本事實標註中被忽略的拓撲人工製品，以及評估指標的不適當使用。透過詳細的經驗分析，我們揭示了這些問題對分割方法的評估和排名產生的深遠影響。根據我們的研究結果，我們提出了一組可行的建議，以建立公平且穩健的評估標準，用於拓撲感知醫學影像分割方法。

##### **CwA-T: A Channelwise AutoEncoder with Transformer for EEG Abnormality Detection**
2412.14522v2 by Youshen Zhao, Keiji Iramina

Electroencephalogram (EEG) signals are critical for detecting abnormal brain
activity, but their high dimensionality and complexity pose significant
challenges for effective analysis. In this paper, we propose CwA-T, a novel
framework that combines a channelwise CNN-based autoencoder with a single-head
transformer classifier for efficient EEG abnormality detection. The channelwise
autoencoder compresses raw EEG signals while preserving channel independence,
reducing computational costs and retaining biologically meaningful features.
The compressed representations are then fed into the transformer-based
classifier, which efficiently models long-term dependencies to distinguish
between normal and abnormal signals. Evaluated on the TUH Abnormal EEG Corpus,
the proposed model achieves 85.0% accuracy, 76.2% sensitivity, and 91.2%
specificity at the per-case level, outperforming baseline models such as
EEGNet, Deep4Conv, and FusionCNN. Furthermore, CwA-T requires only 202M FLOPs
and 2.9M parameters, making it significantly more efficient than
transformer-based alternatives. The framework retains interpretability through
its channelwise design, demonstrating great potential for future applications
in neuroscience research and clinical practice. The source code is available at
https://github.com/YossiZhao/CAE-T.

摘要：腦電圖 (EEG) 訊號對於偵測異常腦部活動至關重要，但其高維度和複雜性對有效分析構成重大挑戰。在本文中，我們提出 CwA-T，一個結合通道式 CNN 自動編碼器與單頭轉換器分類器的創新架構，以進行有效的腦電圖異常偵測。通道式自動編碼器壓縮原始腦電圖訊號，同時保留通道獨立性，降低運算成本並保留具有生物意義的特徵。壓縮後的表示接著被輸入到基於轉換器的分類器中，該分類器有效地建模長期依賴性，以區分正常和異常訊號。在 TUH 異常腦電圖語料庫上進行評估，所提出的模型在個案層級達到 85.0% 的準確度、76.2% 的敏感度和 91.2% 的特異性，優於基線模型，例如 EEGNet、Deep4Conv 和 FusionCNN。此外，CwA-T 只需要 202M FLOP 和 2.9M 參數，使其比基於轉換器的替代方案更有效率。該架構透過其通道式設計保留了解釋性，展示了在神經科學研究和臨床實務中未來應用上的巨大潛力。原始程式碼可在 https://github.com/YossiZhao/CAE-T 取得。

##### **GenHMR: Generative Human Mesh Recovery**
2412.14444v1 by Muhammad Usama Saleem, Ekkasit Pinyoanuntapong, Pu Wang, Hongfei Xue, Srijan Das, Chen Chen

Human mesh recovery (HMR) is crucial in many computer vision applications;
from health to arts and entertainment. HMR from monocular images has
predominantly been addressed by deterministic methods that output a single
prediction for a given 2D image. However, HMR from a single image is an
ill-posed problem due to depth ambiguity and occlusions. Probabilistic methods
have attempted to address this by generating and fusing multiple plausible 3D
reconstructions, but their performance has often lagged behind deterministic
approaches. In this paper, we introduce GenHMR, a novel generative framework
that reformulates monocular HMR as an image-conditioned generative task,
explicitly modeling and mitigating uncertainties in the 2D-to-3D mapping
process. GenHMR comprises two key components: (1) a pose tokenizer to convert
3D human poses into a sequence of discrete tokens in a latent space, and (2) an
image-conditional masked transformer to learn the probabilistic distributions
of the pose tokens, conditioned on the input image prompt along with randomly
masked token sequence. During inference, the model samples from the learned
conditional distribution to iteratively decode high-confidence pose tokens,
thereby reducing 3D reconstruction uncertainties. To further refine the
reconstruction, a 2D pose-guided refinement technique is proposed to directly
fine-tune the decoded pose tokens in the latent space, which forces the
projected 3D body mesh to align with the 2D pose clues. Experiments on
benchmark datasets demonstrate that GenHMR significantly outperforms
state-of-the-art methods. Project website can be found at
https://m-usamasaleem.github.io/publication/GenHMR/GenHMR.html

摘要：人體網格重建（HMR）在許多電腦視覺應用中至關重要；
從健康到藝術和娛樂。單目影像的 HMR 主要由確定性方法解決，
該方法針對給定的 2D 影像輸出單一預測。然而，由於深度模糊和遮擋，
單一影像的 HMR 是個病態問題。機率方法嘗試透過產生和融合多個合理的 3D
重建來解決此問題，但其效能通常落後於確定性方法。在本文中，我們介紹
GenHMR，這是一個新穎的生成式架構，將單目 HMR 重新表述為一個影像條件生成任務，
明確建模和減輕 2D 到 3D 對應過程中的不確定性。GenHMR 包含兩個關鍵組成部分：
（1）姿勢標記化器，將 3D 人體姿勢轉換為潛在空間中的離散標記序列，以及
（2）影像條件遮罩轉換器，以輸入影像提示以及隨機遮罩標記序列為條件，
學習姿勢標記的機率分佈。在推論期間，模型從學習到的條件分佈中取樣，
以反覆解碼高置信度姿勢標記，從而減少 3D 重建的不確定性。為了進一步優化
重建，提出了一種 2D 姿勢引導的優化技術，以直接微調潛在空間中解碼的姿勢標記，
這迫使投影的 3D 身體網格與 2D 姿勢線索對齊。基準資料集上的實驗證明，
GenHMR 明顯優於最先進的方法。專案網站可以在
https://m-usamasaleem.github.io/publication/GenHMR/GenHMR.html 找到

##### **FedPIA -- Permuting and Integrating Adapters leveraging Wasserstein Barycenters for Finetuning Foundation Models in Multi-Modal Federated Learning**
2412.14424v1 by Pramit Saha, Divyanshu Mishra, Felix Wagner, Konstantinos Kamnitsas, J. Alison Noble

Large Vision-Language Models typically require large text and image datasets
for effective fine-tuning. However, collecting data from various sites,
especially in healthcare, is challenging due to strict privacy regulations. An
alternative is to fine-tune these models on end-user devices, such as in
medical clinics, without sending data to a server. These local clients
typically have limited computing power and small datasets, which are not enough
for fully fine-tuning large VLMs on their own. A naive solution to these
scenarios is to leverage parameter-efficient fine-tuning (PEFT) strategies and
apply federated learning (FL) algorithms to combine the learned adapter
weights, thereby respecting the resource limitations and data privacy. However,
this approach does not fully leverage the knowledge from multiple adapters
trained on diverse data distributions and for diverse tasks. The adapters are
adversely impacted by data heterogeneity and task heterogeneity across clients
resulting in suboptimal convergence. To this end, we propose a novel framework
called FedPIA that improves upon the naive combinations of FL and PEFT by
introducing Permutation and Integration of the local Adapters in the server and
global Adapters in the clients exploiting Wasserstein barycenters for improved
blending of client-specific and client-agnostic knowledge. This layerwise
permutation helps to bridge the gap in the parameter space of local and global
adapters before integration. We conduct over 2000 client-level experiments
utilizing 48 medical image datasets across five different medical
vision-language FL task settings encompassing visual question answering as well
as image and report-based multi-label disease detection. Our experiments
involving diverse client settings, ten different modalities, and two VLM
backbones demonstrate that FedPIA consistently outperforms the state-of-the-art
PEFT-FL baselines.

摘要：大型視覺語言模型通常需要大型文字和影像資料集才能進行有效的微調。然而，由於嚴格的隱私法規，從各種網站收集資料，特別是在醫療保健方面，是一項挑戰。另一種方法是在終端使用者裝置上微調這些模型，例如在醫療診所，而不將資料傳送至伺服器。這些本機用戶端通常具有受限的運算能力和小型資料集，不足以自行對大型 VLM 進行完全微調。針對這些場景的一個天真解決方案是利用參數有效微調 (PEFT) 策略，並套用聯邦學習 (FL) 演算法來結合學習到的適配器權重，從而尊重資源限制和資料隱私。然而，此方法並未充分利用從訓練於不同資料分佈和不同任務的多個適配器中獲得的知識。適配器受到客戶端間資料異質性和任務異質性的不利影響，導致次佳收斂。為此，我們提出了一個名為 FedPIA 的新架構，透過在伺服器中引入局部適配器的排列和整合，以及在客戶端中引入全球適配器，並利用 Wasserstein 重心來改善客戶端特定和客戶端不可知知識的混合，從而改進 FL 和 PEFT 的天真組合。這種逐層排列有助於在整合之前彌合局部和全球適配器參數空間的差距。我們利用 48 個醫學影像資料集在五個不同的醫學視覺語言 FL 任務設定中進行了 2000 多個客戶端層級實驗，包括視覺問題解答以及基於影像和報告的多標籤疾病檢測。我們涉及不同客戶端設定、十種不同模式和兩個 VLM 主幹的實驗表明，FedPIA 持續優於最先進的 PEFT-FL 基準。

##### **Clinical Trials Ontology Engineering with Large Language Models**
2412.14387v1 by Berkan Çakır

Managing clinical trial information is currently a significant challenge for
the medical industry, as traditional methods are both time-consuming and
costly. This paper proposes a simple yet effective methodology to extract and
integrate clinical trial data in a cost-effective and time-efficient manner.
Allowing the medical industry to stay up-to-date with medical developments.
Comparing time, cost, and quality of the ontologies created by humans, GPT3.5,
GPT4, and Llama3 (8b & 70b). Findings suggest that large language models (LLM)
are a viable option to automate this process both from a cost and time
perspective. This study underscores significant implications for medical
research where real-time data integration from clinical trials could become the
norm.

摘要：管理臨床試驗資訊目前是醫療產業的一項重大挑戰，因為傳統方法既耗時又昂貴。本文提出一個簡單但有效的方法，以經濟有效且省時的方式提取和整合臨床試驗資料。讓醫療產業能隨時掌握醫療發展。比較人類、GPT3.5、GPT4 和 Llama3（8b 和 70b）建立的本体的時間、成本和品質。研究結果表明，大型語言模型 (LLM) 是從成本和時間角度自動化此流程的可行選項。這項研究強調了對醫療研究的重要影響，其中臨床試驗的即時資料整合可能會成為常態。

##### **Multi-OphthaLingua: A Multilingual Benchmark for Assessing and Debiasing LLM Ophthalmological QA in LMICs**
2412.14304v1 by David Restrepo, Chenwei Wu, Zhengxu Tang, Zitao Shuai, Thao Nguyen Minh Phan, Jun-En Ding, Cong-Tinh Dao, Jack Gallifant, Robyn Gayle Dychiao, Jose Carlo Artiaga, André Hiroshi Bando, Carolina Pelegrini Barbosa Gracitelli, Vincenz Ferrer, Leo Anthony Celi, Danielle Bitterman, Michael G Morley, Luis Filipe Nakayama

Current ophthalmology clinical workflows are plagued by over-referrals, long
waits, and complex and heterogeneous medical records. Large language models
(LLMs) present a promising solution to automate various procedures such as
triaging, preliminary tests like visual acuity assessment, and report
summaries. However, LLMs have demonstrated significantly varied performance
across different languages in natural language question-answering tasks,
potentially exacerbating healthcare disparities in Low and Middle-Income
Countries (LMICs). This study introduces the first multilingual
ophthalmological question-answering benchmark with manually curated questions
parallel across languages, allowing for direct cross-lingual comparisons. Our
evaluation of 6 popular LLMs across 7 different languages reveals substantial
bias across different languages, highlighting risks for clinical deployment of
LLMs in LMICs. Existing debiasing methods such as Translation Chain-of-Thought
or Retrieval-augmented generation (RAG) by themselves fall short of closing
this performance gap, often failing to improve performance across all languages
and lacking specificity for the medical domain. To address this issue, We
propose CLARA (Cross-Lingual Reflective Agentic system), a novel inference time
de-biasing method leveraging retrieval augmented generation and
self-verification. Our approach not only improves performance across all
languages but also significantly reduces the multilingual bias gap,
facilitating equitable LLM application across the globe.

摘要：<paragraph>當前眼科臨床工作流程飽受過度轉診、漫長等待時間以及複雜且異質的醫療記錄所苦。大型語言模型 (LLM) 提供了一個有前景的解決方案，可自動化各種程序，例如分流、視力評估等初步測試和報告摘要。然而，LLM 已在自然語言問答任務中展現出跨不同語言的顯著差異效能，這可能會加劇低收入和中等收入國家 (LMIC) 的醫療保健差異。本研究引入了首個多語言眼科問答基準，其中包含手動策劃且跨語言平行的問題，允許直接進行跨語言比較。我們對 7 種不同語言中的 6 個熱門 LLM 進行評估，結果顯示不同語言之間存在顯著偏差，突顯出在 LMIC 中部署 LLM 的臨床風險。現有的去偏方法，例如翻譯思維鏈或檢索增強生成 (RAG)，本身無法縮小此效能差距，通常無法改善所有語言的效能，且缺乏針對醫療領域的專一性。為了解決此問題，我們提出 CLARA (跨語言反射代理系統)，這是一種新穎的推理時間去偏方法，利用檢索增強生成和自我驗證。我們的做法不僅改善了所有語言的效能，還顯著縮小了多語言偏見差距，促進了 LLM 在全球範圍內的公平應用。</paragraph>

##### **Discovering maximally consistent distribution of causal tournaments with Large Language Models**
2412.14019v1 by Federico Baldo, Simon Ferreira, Charles K. Assaad

Causal discovery is essential for understanding complex systems, yet
traditional methods often depend on strong, untestable assumptions, making the
process challenging. Large Language Models (LLMs) present a promising
alternative for extracting causal insights from text-based metadata, which
consolidates domain expertise. However, LLMs are prone to unreliability and
hallucinations, necessitating strategies that account for their limitations.
One such strategy involves leveraging a consistency measure to evaluate
reliability. Additionally, most text metadata does not clearly distinguish
direct causal relationships from indirect ones, further complicating the
inference of causal graphs. As a result, focusing on causal orderings, rather
than causal graphs, emerges as a more practical and robust approach. We propose
a novel method to derive a distribution of acyclic tournaments (representing
plausible causal orders) that maximizes a consistency score. Our approach
begins by computing pairwise consistency scores between variables, yielding a
cyclic tournament that aggregates these scores. From this structure, we
identify optimal acyclic tournaments compatible with the original tournament,
prioritizing those that maximize consistency across all configurations. We
tested our method on both classical and well-established bechmarks, as well as
real-world datasets from epidemiology and public health. Our results
demonstrate the effectiveness of our approach in recovering distributions
causal orders with minimal error.

摘要：因果發現對於理解複雜系統至關重要，但傳統方法通常依賴於強而不可測試的假設，這使得這個過程充滿挑戰。大型語言模型 (LLM) 提供了一個從基於文本的元數據中提取因果見解的有希望的替代方案，它整合了領域專業知識。然而，LLM 容易出現不可靠性和幻覺，這需要考慮其限制的策略。一種這樣的策略涉及利用一致性度量來評估可靠性。此外，大多數文本元數據並未清楚地區分直接因果關係和間接因果關係，這進一步複雜化了因果圖的推論。因此，專注於因果順序，而不是因果圖，成為一種更實用、更穩健的方法。我們提出了一種新方法來推導無環錦標賽的分布（表示合理的因果順序），這最大化了一致性分數。我們的做法首先計算變量之間成對的一致性分數，產生一個彙總這些分數的循環錦標賽。從這個結構中，我們識別出與原始錦標賽相容的最佳無環錦標賽，優先考慮那些在所有配置中最大化一致性的錦標賽。我們在經典且完善的基準以及來自流行病學和公共衛生的真實世界數據集上測試了我們的模型。我們的結果證明了我們的方法在以最小誤差恢復因果順序分布方面的有效性。

##### **SurgSora: Decoupled RGBD-Flow Diffusion Model for Controllable Surgical Video Generation**
2412.14018v1 by Tong Chen, Shuya Yang, Junyi Wang, Long Bai, Hongliang Ren, Luping Zhou

Medical video generation has transformative potential for enhancing surgical
understanding and pathology insights through precise and controllable visual
representations. However, current models face limitations in controllability
and authenticity. To bridge this gap, we propose SurgSora, a
motion-controllable surgical video generation framework that uses a single
input frame and user-controllable motion cues. SurgSora consists of three key
modules: the Dual Semantic Injector (DSI), which extracts object-relevant RGB
and depth features from the input frame and integrates them with segmentation
cues to capture detailed spatial features of complex anatomical structures; the
Decoupled Flow Mapper (DFM), which fuses optical flow with semantic-RGB-D
features at multiple scales to enhance temporal understanding and object
spatial dynamics; and the Trajectory Controller (TC), which allows users to
specify motion directions and estimates sparse optical flow, guiding the video
generation process. The fused features are used as conditions for a frozen
Stable Diffusion model to produce realistic, temporally coherent surgical
videos. Extensive evaluations demonstrate that SurgSora outperforms
state-of-the-art methods in controllability and authenticity, showing its
potential to advance surgical video generation for medical education, training,
and research.

摘要：醫療影片生成具有變革性的潛力，可透過精確且可控的視覺表現來增強手術理解和病理見解。然而，目前的模型在可控性和真實性方面面臨限制。為了彌合這個差距，我們提出了 SurgSora，一個動作可控的手術影片生成框架，使用單一輸入幀和使用者可控的動作提示。SurgSora 包含三個關鍵模組：雙語意注入器 (DSI)，它從輸入幀中提取與物件相關的 RGB 和深度特徵，並將其與分割提示整合，以擷取複雜解剖結構的詳細空間特徵；解耦流對應器 (DFM)，它在多個尺度上將光流與語意 RGB-D 特徵融合，以增強時間理解和物件空間動態；以及軌跡控制器 (TC)，它允許使用者指定動作方向並估計稀疏光流，引導影片生成過程。融合的特徵用作凍結的 Stable Diffusion 模型的條件，以產生逼真、時間連貫的手術影片。廣泛的評估表明，SurgSora 在可控性和真實性方面優於最先進的方法，顯示其在推進手術影片生成以用於醫學教育、培訓和研究方面的潛力。

##### **Cognition Chain for Explainable Psychological Stress Detection on Social Media**
2412.14009v1 by Xin Wang, Boyan Gao, Yi Dai, Lei Cao, Liang Zhao, Yibo Yang, David Clifton

Stress is a pervasive global health issue that can lead to severe mental
health problems. Early detection offers timely intervention and prevention of
stress-related disorders. The current early detection models perform "black
box" inference suffering from limited explainability and trust which blocks the
real-world clinical application. Thanks to the generative properties introduced
by the Large Language Models (LLMs), the decision and the prediction from such
models are semi-interpretable through the corresponding description. However,
the existing LLMs are mostly trained for general purposes without the guidance
of psychological cognitive theory. To this end, we first highlight the
importance of prior theory with the observation of performance boosted by the
chain-of-thoughts tailored for stress detection. This method termed Cognition
Chain explicates the generation of stress through a step-by-step cognitive
perspective based on cognitive appraisal theory with a progress pipeline:
Stimulus $\rightarrow$ Evaluation $\rightarrow$ Reaction $\rightarrow$ Stress
State, guiding LLMs to provide comprehensive reasoning explanations. We further
study the benefits brought by the proposed Cognition Chain format by utilising
it as a synthetic dataset generation template for LLMs instruction-tuning and
introduce CogInstruct, an instruction-tuning dataset for stress detection. This
dataset is developed using a three-stage self-reflective annotation pipeline
that enables LLMs to autonomously generate and refine instructional data. By
instruction-tuning Llama3 with CogInstruct, we develop CogLLM, an explainable
stress detection model. Evaluations demonstrate that CogLLM achieves
outstanding performance while enhancing explainability. Our work contributes a
novel approach by integrating cognitive theories into LLM reasoning processes,
offering a promising direction for future explainable AI research.

摘要：壓力是一個普遍的全球性健康問題，可能會導致嚴重的精神
健康問題。早期發現提供及時的干預和預防
壓力相關疾病。目前的早期發現模型執行「黑
盒子」推論，存在可解釋性和信任度有限的問題，阻礙了
現實世界的臨床應用。多虧了大型語言模型 (LLM) 引入的生成屬性，此類
模型的決策和預測通過對應描述具有半可解釋性。然而，
現有的 LLM 主要針對一般用途進行訓練，沒有心理認知理論的指導。為此，我們首先強調
先驗理論的重要性，並觀察到針對壓力檢測量身定制的思想鏈提升了性能。這種方法稱為認知
鏈通過基於認知評估理論的循序漸進的認知視角闡明了壓力的產生，並具有進度管道：
刺激 $\rightarrow$ 評估 $\rightarrow$ 反應 $\rightarrow$ 壓力
狀態，指導 LLM 提供全面的推理解釋。我們進一步
通過將其用作 LLM 指令調整的合成數據集生成模板來研究所提出的認知鏈格式帶來的優點，並介紹 CogInstruct，這是一個針對壓力檢測的指令調整數據集。這個
數據集是使用一個三階段的自省標註管道開發的，使 LLM 能夠自主生成和優化指令數據。通過
使用 CogInstruct 對 Llama3 進行指令調整，我們開發了 CogLLM，這是一個可解釋的
壓力檢測模型。評估表明，CogLLM 在提高可解釋性的同時實現了出色的性能。我們的研究通過將認知理論整合到 LLM 推理過程中，提出了一種新穎的方法，
為未來的可解釋人工智能研究提供了一個有希望的方向。

##### **Federated Learning and RAG Integration: A Scalable Approach for Medical Large Language Models**
2412.13720v1 by Jincheol Jung, Hongju Jeong, Eui-Nam Huh

This study analyzes the performance of domain-specific Large Language Models
(LLMs) for the medical field by integrating Retrieval-Augmented Generation
(RAG) systems within a federated learning framework. Leveraging the inherent
advantages of federated learning, such as preserving data privacy and enabling
distributed computation, this research explores the integration of RAG systems
with models trained under varying client configurations to optimize
performance. Experimental results demonstrate that the federated learning-based
models integrated with RAG systems consistently outperform their non-integrated
counterparts across all evaluation metrics. This study highlights the potential
of combining federated learning and RAG systems for developing domain-specific
LLMs in the medical field, providing a scalable and privacy-preserving solution
for enhancing text generation capabilities.

摘要：本研究透過在聯邦學習架構中整合檢索擴增生成 (RAG) 系統，分析特定領域的大語言模型 (LLM) 在醫療領域的表現。利用聯邦學習的內在優勢，例如維護資料隱私和啟用分散式運算，本研究探討將 RAG 系統與在不同客戶端組態下訓練的模型整合，以最佳化效能。實驗結果顯示，與 RAG 系統整合的基於聯邦學習的模型在所有評估指標上都持續優於未整合的對應模型。本研究強調在醫療領域結合聯邦學習和 RAG 系統以開發特定領域 LLM 的潛力，提供可擴充且維護隱私的解決方案，以增強文字生成能力。

##### **Clio: Privacy-Preserving Insights into Real-World AI Use**
2412.13678v1 by Alex Tamkin, Miles McCain, Kunal Handa, Esin Durmus, Liane Lovitt, Ankur Rathi, Saffron Huang, Alfred Mountfield, Jerry Hong, Stuart Ritchie, Michael Stern, Brian Clarke, Landon Goldberg, Theodore R. Sumers, Jared Mueller, William McEachen, Wes Mitchell, Shan Carter, Jack Clark, Jared Kaplan, Deep Ganguli

How are AI assistants being used in the real world? While model providers in
theory have a window into this impact via their users' data, both privacy
concerns and practical challenges have made analyzing this data difficult. To
address these issues, we present Clio (Claude insights and observations), a
privacy-preserving platform that uses AI assistants themselves to analyze and
surface aggregated usage patterns across millions of conversations, without the
need for human reviewers to read raw conversations. We validate this can be
done with a high degree of accuracy and privacy by conducting extensive
evaluations. We demonstrate Clio's usefulness in two broad ways. First, we
share insights about how models are being used in the real world from one
million Claude.ai Free and Pro conversations, ranging from providing advice on
hairstyles to providing guidance on Git operations and concepts. We also
identify the most common high-level use cases on Claude.ai (coding, writing,
and research tasks) as well as patterns that differ across languages (e.g.,
conversations in Japanese discuss elder care and aging populations at
higher-than-typical rates). Second, we use Clio to make our systems safer by
identifying coordinated attempts to abuse our systems, monitoring for unknown
unknowns during critical periods like launches of new capabilities or major
world events, and improving our existing monitoring systems. We also discuss
the limitations of our approach, as well as risks and ethical concerns. By
enabling analysis of real-world AI usage, Clio provides a scalable platform for
empirically grounded AI safety and governance.

摘要：人工智能助理在現實世界中如何使用？雖然理論上模型供應商可以透過使用者的資料了解這種影響，但隱私問題和實際挑戰都讓分析這些資料變得困難。為了解決這些問題，我們提出了 Clio（Claude 見解與觀察），一個隱私保護平台，它使用人工智能助理本身來分析並浮出數百萬次對話中的彙整使用模式，而不需要人類審查員閱讀原始對話。我們透過進行廣泛的評估，驗證這可以用高度準確和隱私來完成。我們以兩種廣泛的方式展示 Clio 的用途。首先，我們分享關於模型在現實世界中如何使用的一百萬個 Claude.ai 免費和專業對話的見解，範圍從提供髮型建議到提供有關 Git 操作和概念的指導。我們還找出 Claude.ai 上最常見的高階使用案例（編碼、寫作和研究任務），以及不同語言之間的模式差異（例如，日語對話討論老年照護和老齡化人口的比率高於一般）。其次，我們使用 Clio 透過找出協調濫用我們系統的嘗試、在啟動新功能或重大世界事件等關鍵時期監控未知的未知數，以及改善我們現有的監控系統，讓我們的系統更安全。我們也討論我們方法的限制，以及風險和道德問題。透過啟用對現實世界人工智能使用的分析，Clio 提供了一個可擴充的平台，用於以經驗為基礎的人工智能安全和治理。

##### **Exploring Multi-Modal Integration with Tool-Augmented LLM Agents for Precise Causal Discovery**
2412.13667v1 by ChengAo Shen, Zhengzhang Chen, Dongsheng Luo, Dongkuan Xu, Haifeng Chen, Jingchao Ni

Causal inference is an imperative foundation for decision-making across
domains, such as smart health, AI for drug discovery and AIOps. Traditional
statistical causal discovery methods, while well-established, predominantly
rely on observational data and often overlook the semantic cues inherent in
cause-and-effect relationships. The advent of Large Language Models (LLMs) has
ushered in an affordable way of leveraging the semantic cues for
knowledge-driven causal discovery, but the development of LLMs for causal
discovery lags behind other areas, particularly in the exploration of
multi-modality data. To bridge the gap, we introduce MATMCD, a multi-agent
system powered by tool-augmented LLMs. MATMCD has two key agents: a Data
Augmentation agent that retrieves and processes modality-augmented data, and a
Causal Constraint agent that integrates multi-modal data for knowledge-driven
inference. Delicate design of the inner-workings ensures successful cooperation
of the agents. Our empirical study across seven datasets suggests the
significant potential of multi-modality enhanced causal discovery.

摘要：因果推論是跨領域決策制定中的必要基礎，例如智慧醫療、用於藥物發現的人工智慧和 AIOps。傳統的統計因果發現方法雖然已經確立，但主要依賴於觀察資料，且常常忽略因果關係中固有的語意線索。大型語言模型 (LLM) 的出現，開啟了一種利用語意線索進行知識驅動因果發現的方法，但用於因果發現的 LLM 發展落後於其他領域，特別是在多模態資料的探索方面。為了彌補差距，我們引入了 MATMCD，這是一個由工具增強的 LLM 驅動的多主體系統。MATMCD 有兩個關鍵主體：一個資料擴充主體，用於擷取和處理模態擴充資料，以及一個因果約束主體，用於整合多模態資料進行知識驅動推論。內部運作的精細設計確保了主體之間的成功合作。我們對七個資料集的實證研究表明，多模態增強因果發現具有顯著的潛力。

##### **BadSAD: Clean-Label Backdoor Attacks against Deep Semi-Supervised Anomaly Detection**
2412.13324v1 by He Cheng, Depeng Xu, Shuhan Yuan

Image anomaly detection (IAD) is essential in applications such as industrial
inspection, medical imaging, and security. Despite the progress achieved with
deep learning models like Deep Semi-Supervised Anomaly Detection (DeepSAD),
these models remain susceptible to backdoor attacks, presenting significant
security challenges. In this paper, we introduce BadSAD, a novel backdoor
attack framework specifically designed to target DeepSAD models. Our approach
involves two key phases: trigger injection, where subtle triggers are embedded
into normal images, and latent space manipulation, which positions and clusters
the poisoned images near normal images to make the triggers appear benign.
Extensive experiments on benchmark datasets validate the effectiveness of our
attack strategy, highlighting the severe risks that backdoor attacks pose to
deep learning-based anomaly detection systems.

摘要：影像異常偵測（IAD）在工業檢查、醫療影像和安全等應用中至關重要。儘管深度學習模型（如深度半監督異常偵測（DeepSAD））已取得進展，但這些模型仍然容易受到後門攻擊，造成重大的安全挑戰。在本文中，我們介紹 BadSAD，一個專門針對 DeepSAD 模型設計的新型後門攻擊架構。我們的做法包含兩個關鍵階段：觸發注入，其中將細微觸發嵌入到正常影像中，以及潛在空間操作，將中毒影像定位並群集在正常影像附近，以使觸發看起來是良性的。在基準資料集上進行的廣泛實驗驗證了我們攻擊策略的有效性，突顯了後門攻擊對基於深度學習的異常偵測系統造成的嚴重風險。

##### **In-context learning for medical image segmentation**
2412.13299v1 by Eichi Takaya, Shinnosuke Yamamoto

Annotation of medical images, such as MRI and CT scans, is crucial for
evaluating treatment efficacy and planning radiotherapy. However, the extensive
workload of medical professionals limits their ability to annotate large image
datasets, posing a bottleneck for AI applications in medical imaging. To
address this, we propose In-context Cascade Segmentation (ICS), a novel method
that minimizes annotation requirements while achieving high segmentation
accuracy for sequential medical images. ICS builds on the UniverSeg framework,
which performs few-shot segmentation using support images without additional
training. By iteratively adding the inference results of each slice to the
support set, ICS propagates information forward and backward through the
sequence, ensuring inter-slice consistency. We evaluate the proposed method on
the HVSMR dataset, which includes segmentation tasks for eight cardiac regions.
Experimental results demonstrate that ICS significantly improves segmentation
performance in complex anatomical regions, particularly in maintaining boundary
consistency across slices, compared to baseline methods. The study also
highlights the impact of the number and position of initial support slices on
segmentation accuracy. ICS offers a promising solution for reducing annotation
burdens while delivering robust segmentation results, paving the way for its
broader adoption in clinical and research applications.

摘要：醫學影像的註解，例如 MRI 和 CT 掃描，對於評估治療效果和規劃放射治療至關重要。然而，醫護人員龐大的工作量限制了他們註解大型影像資料集的能力，對醫學影像中的 AI 應用構成瓶頸。為了解決這個問題，我們提出情境串聯分割 (ICS)，這是一種新方法，可最大程度減少註解需求，同時為順序醫學影像實現高分割準確度。ICS 建立在 UniverSeg 架構之上，該架構使用支援影像執行少量分割，而無需額外訓練。透過反覆將每個切片的推論結果新增到支援集，ICS 透過序列向前和向後傳播資訊，確保切片間的一致性。我們在 HVSMR 資料集上評估所提出的方法，其中包括八個心臟區域的分割任務。實驗結果表明，與基準方法相比，ICS 在複雜的解剖區域顯著改善了分割效能，特別是在維護切片間的邊界一致性方面。該研究還強調了初始支援切片的數量和位置對分割準確度的影響。ICS 提供了一個有希望的解決方案，可以在提供穩健的分割結果的同時減少註解負擔，為其在臨床和研究應用中的更廣泛採用鋪平道路。

##### **Continuous Patient Monitoring with AI: Real-Time Analysis of Video in Hospital Care Settings**
2412.13152v1 by Paolo Gabriel, Peter Rehani, Tyler Troy, Tiffany Wyatt, Michael Choma, Narinder Singh

This study introduces an AI-driven platform for continuous and passive
patient monitoring in hospital settings, developed by LookDeep Health.
Leveraging advanced computer vision, the platform provides real-time insights
into patient behavior and interactions through video analysis, securely storing
inference results in the cloud for retrospective evaluation. The dataset,
compiled in collaboration with 11 hospital partners, encompasses over 300
high-risk fall patients and over 1,000 days of inference, enabling applications
such as fall detection and safety monitoring for vulnerable patient
populations. To foster innovation and reproducibility, an anonymized subset of
this dataset is publicly available. The AI system detects key components in
hospital rooms, including individual presence and role, furniture location,
motion magnitude, and boundary crossings. Performance evaluation demonstrates
strong accuracy in object detection (macro F1-score = 0.92) and patient-role
classification (F1-score = 0.98), as well as reliable trend analysis for the
"patient alone" metric (mean logistic regression accuracy = 0.82 \pm 0.15).
These capabilities enable automated detection of patient isolation, wandering,
or unsupervised movement-key indicators for fall risk and other adverse events.
This work establishes benchmarks for validating AI-driven patient monitoring
systems, highlighting the platform's potential to enhance patient safety and
care by providing continuous, data-driven insights into patient behavior and
interactions.

摘要：本研究介紹了一個由 LookDeep Health 開發的 AI 驅動平台，用於在醫院環境中持續且被動地監控患者。該平台利用先進的電腦視覺技術，透過影片分析提供患者行為和互動的即時見解，並將推論結果安全地儲存在雲端以供回顧性評估。該資料集與 11 家合作醫院共同編制，包含 300 多名高風險跌倒患者和 1,000 多天的推論，適用於跌倒偵測和脆弱患者族群的安全監控等應用。為了促進創新和可複製性，這份資料集的匿名子集已公開提供。AI 系統會偵測醫院房間中的關鍵組成部分，包括個人存在和角色、家具位置、動作幅度和邊界穿越。效能評估顯示物件偵測（巨觀 F1 分數 = 0.92）和患者角色分類（F1 分數 = 0.98）具有很高的準確性，以及「患者獨自一人」指標的可靠趨勢分析（平均邏輯迴歸準確性 = 0.82 ± 0.15）。這些功能可自動偵測患者隔離、遊走或無監督的移動，這些都是跌倒風險和其他不良事件的關鍵指標。這項工作為驗證 AI 驅動的患者監控系統建立了基準，突顯了該平台透過提供持續且資料驅動的患者行為和互動見解，增強患者安全和照護的潛力。

##### **Boosting Fine-Grained Visual Anomaly Detection with Coarse-Knowledge-Aware Adversarial Learning**
2412.12850v1 by Qingqing Fang, Qinliang Su, Wenxi Lv, Wenchao Xu, Jianxing Yu

Many unsupervised visual anomaly detection methods train an auto-encoder to
reconstruct normal samples and then leverage the reconstruction error map to
detect and localize the anomalies. However, due to the powerful modeling and
generalization ability of neural networks, some anomalies can also be well
reconstructed, resulting in unsatisfactory detection and localization accuracy.
In this paper, a small coarsely-labeled anomaly dataset is first collected.
Then, a coarse-knowledge-aware adversarial learning method is developed to
align the distribution of reconstructed features with that of normal features.
The alignment can effectively suppress the auto-encoder's reconstruction
ability on anomalies and thus improve the detection accuracy. Considering that
anomalies often only occupy very small areas in anomalous images, a patch-level
adversarial learning strategy is further developed. Although no patch-level
anomalous information is available, we rigorously prove that by simply viewing
any patch features from anomalous images as anomalies, the proposed
knowledge-aware method can also align the distribution of reconstructed patch
features with the normal ones. Experimental results on four medical datasets
and two industrial datasets demonstrate the effectiveness of our method in
improving the detection and localization performance.

摘要：許多無監督視覺異常偵測方法會訓練自動編碼器來重建正常樣本，然後利用重建誤差圖來偵測和定位異常。然而，由於神經網路強大的建模和概化能力，一些異常也可以被良好地重建，導致不令人滿意的偵測和定位準確度。在本文中，首先收集了一個小型粗略標記的異常資料集。然後，開發了一個粗略知識感知對抗學習方法，以將重建特徵的分布與正常特徵的分布對齊。對齊可以有效地抑制自動編碼器對異常的重建能力，從而提高偵測準確度。考慮到異常通常只佔異常影像中很小的區域，進一步開發了區塊級對抗學習策略。儘管沒有區塊級異常資訊可用，但我們嚴格證明，只需將異常影像中的任何區塊特徵視為異常，所提出的知識感知方法也可以將重建區塊特徵的分布與正常特徵對齊。在四個醫學資料集和兩個工業資料集上的實驗結果證明了我們的方法在改善偵測和定位效能方面的有效性。

##### **Rethinking Diffusion-Based Image Generators for Fundus Fluorescein Angiography Synthesis on Limited Data**
2412.12778v1 by Chengzhou Yu, Huihui Fang, Hongqiu Wang, Ting Deng, Qing Du, Yanwu Xu, Weihua Yang

Fundus imaging is a critical tool in ophthalmology, with different imaging
modalities offering unique advantages. For instance, fundus fluorescein
angiography (FFA) can accurately identify eye diseases. However, traditional
invasive FFA involves the injection of sodium fluorescein, which can cause
discomfort and risks. Generating corresponding FFA images from non-invasive
fundus images holds significant practical value but also presents challenges.
First, limited datasets constrain the performance and effectiveness of models.
Second, previous studies have primarily focused on generating FFA for single
diseases or single modalities, often resulting in poor performance for patients
with various ophthalmic conditions. To address these issues, we propose a novel
latent diffusion model-based framework, Diffusion, which introduces a
fine-tuning protocol to overcome the challenge of limited medical data and
unleash the generative capabilities of diffusion models. Furthermore, we
designed a new approach to tackle the challenges of generating across different
modalities and disease types. On limited datasets, our framework achieves
state-of-the-art results compared to existing methods, offering significant
potential to enhance ophthalmic diagnostics and patient care. Our code will be
released soon to support further research in this field.

摘要：眼底成像技術是眼科中的一項重要工具，不同的成像方式各有優勢。例如，眼底螢光素血管攝影 (FFA) 可精準辨識眼部疾病。然而，傳統侵入式的 FFA 會注射螢光素鈉，可能會造成不適和風險。從非侵入式眼底影像中產生相對應的 FFA 影像具有重要的實用價值，但也存在挑戰。首先，有限的資料集會限制模型的效能和效果。其次，先前的研究主要集中在為單一疾病或單一方式產生 FFA，對於患有多種眼科疾病的患者，效能通常不佳。為了解決這些問題，我們提出一個新穎的潛在擴散模型架構，稱為 Diffusion，它引入一個微調協定，以克服醫療資料有限的挑戰，並釋放擴散模型的生成能力。此外，我們設計了一種新方法來應對跨不同方式和疾病類型生成影像的挑戰。在有限的資料集上，與現有方法相比，我們的架構達到了最先進的結果，為增強眼科診斷和患者照護提供了顯著的潛力。我們的程式碼將很快釋出，以支持此領域的進一步研究。

##### **MedMax: Mixed-Modal Instruction Tuning for Training Biomedical Assistants**
2412.12661v1 by Hritik Bansal, Daniel Israel, Siyan Zhao, Shufan Li, Tung Nguyen, Aditya Grover

Recent advancements in mixed-modal generative models have enabled flexible
integration of information across image-text content. These models have opened
new avenues for developing unified biomedical assistants capable of analyzing
biomedical images, answering complex questions about them, and predicting the
impact of medical procedures on a patient's health. However, existing resources
face challenges such as limited data availability, narrow domain coverage, and
restricted sources (e.g., medical papers). To address these gaps, we present
MedMax, the first large-scale multimodal biomedical instruction-tuning dataset
for mixed-modal foundation models. With 1.47 million instances, MedMax
encompasses a diverse range of tasks, including multimodal content generation
(interleaved image-text data), biomedical image captioning and generation,
visual chatting, and report understanding. These tasks span diverse medical
domains such as radiology and histopathology. Subsequently, we fine-tune a
mixed-modal foundation model on the MedMax dataset, achieving significant
performance improvements: a 26% gain over the Chameleon model and an 18.3%
improvement over GPT-4o across 12 downstream biomedical visual
question-answering tasks. Additionally, we introduce a unified evaluation suite
for biomedical tasks, providing a robust framework to guide the development of
next-generation mixed-modal biomedical AI assistants.

摘要：混合模式生成模型的最新进展使得跨图像文本内容灵活整合信息成为可能。这些模型为开发统一的生物医学助手开辟了新途径，这些助手能够分析生物医学图像、回答有关图像的复杂问题，并预测医疗程序对患者健康的影响。然而，现有资源面临着数据可用性有限、领域覆盖范围狭窄和来源受限（例如医学论文）等挑战。为了解决这些差距，我们提出了 MedMax，这是第一个用于混合模式基础模型的大规模多模态生物医学指令微调数据集。MedMax 拥有 147 万个实例，涵盖了各种任务，包括多模态内容生成（交错图像文本数据）、生物医学图像标题和生成、可视化聊天和报告理解。这些任务跨越了放射学和组织病理学等不同的医学领域。随后，我们在 MedMax 数据集上对混合模式基础模型进行微调，取得了显著的性能提升：在 12 个下游生物医学视觉问答任务中，比 Chameleon 模型提升了 26%，比 GPT-4o 提升了 18.3%。此外，我们还引入了用于生物医学任务的统一评估套件，为指导下一代混合模式生物医学 AI 助手的发展提供了稳健的框架。

##### **a2z-1 for Multi-Disease Detection in Abdomen-Pelvis CT: External Validation and Performance Analysis Across 21 Conditions**
2412.12629v1 by Pranav Rajpurkar, Julian N. Acosta, Siddhant Dogra, Jaehwan Jeong, Deepanshu Jindal, Michael Moritz, Samir Rajpurkar

We present a comprehensive evaluation of a2z-1, an artificial intelligence
(AI) model designed to analyze abdomen-pelvis CT scans for 21 time-sensitive
and actionable findings. Our study focuses on rigorous assessment of the
model's performance and generalizability. Large-scale retrospective analysis
demonstrates an average AUC of 0.931 across 21 conditions. External validation
across two distinct health systems confirms consistent performance (AUC 0.923),
establishing generalizability to different evaluation scenarios, with notable
performance in critical findings such as small bowel obstruction (AUC 0.958)
and acute pancreatitis (AUC 0.961). Subgroup analysis shows consistent accuracy
across patient sex, age groups, and varied imaging protocols, including
different slice thicknesses and contrast administration types. Comparison of
high-confidence model outputs to radiologist reports reveals instances where
a2z-1 identified overlooked findings, suggesting potential for quality
assurance applications.

摘要：我們提出 a2z-1 的全面評估，這是一個人工智慧 (AI) 模型，旨在分析腹部骨盆電腦斷層掃描，以找出 21 項時間敏感且可採取行動的發現。我們的研究重點在於嚴格評估模型的效能和概括性。大規模回顧性分析顯示，21 種疾病的平均 AUC 為 0.931。兩個不同醫療系統的外部驗證確認效能一致（AUC 0.923），建立了對不同評估情境的概括性，在小腸阻塞（AUC 0.958）和急性胰臟炎（AUC 0.961）等關鍵發現中表現出色。次群體分析顯示，在患者性別、年齡組和不同的影像協議（包括不同的切片厚度和對比劑施用類型）中，準確度一致。將高信賴度模型輸出與放射科醫師報告進行比較，揭示了 a2z-1 找出被忽略發現的範例，表示有潛力用於品質保證應用。

##### **A Scalable Approach to Benchmarking the In-Conversation Differential Diagnostic Accuracy of a Health AI**
2412.12538v1 by Deep Bhatt, Surya Ayyagari, Anuruddh Mishra

Diagnostic errors in healthcare persist as a critical challenge, with
increasing numbers of patients turning to online resources for health
information. While AI-powered healthcare chatbots show promise, there exists no
standardized and scalable framework for evaluating their diagnostic
capabilities. This study introduces a scalable benchmarking methodology for
assessing health AI systems and demonstrates its application through August, an
AI-driven conversational chatbot. Our methodology employs 400 validated
clinical vignettes across 14 medical specialties, using AI-powered patient
actors to simulate realistic clinical interactions. In systematic testing,
August achieved a top-one diagnostic accuracy of 81.8% (327/400 cases) and a
top-two accuracy of 85.0% (340/400 cases), significantly outperforming
traditional symptom checkers. The system demonstrated 95.8% accuracy in
specialist referrals and required 47% fewer questions compared to conventional
symptom checkers (mean 16 vs 29 questions), while maintaining empathetic
dialogue throughout consultations. These findings demonstrate the potential of
AI chatbots to enhance healthcare delivery, though implementation challenges
remain regarding real-world validation and integration of objective clinical
data. This research provides a reproducible framework for evaluating healthcare
AI systems, contributing to the responsible development and deployment of AI in
clinical settings.

摘要：醫療保健中的診斷錯誤持續成為一項重大挑戰，越來越多的患者求助於線上資源來取得健康資訊。儘管由人工智慧驅動的醫療保健聊天機器人展現出前景，但目前還沒有標準化且可擴充的架構來評估其診斷能力。本研究介紹了一種可擴充的基準測試方法，用於評估健康人工智慧系統，並透過由人工智慧驅動的對話式聊天機器人 August，展示其應用。我們的做法採用了 14 個醫療專科的 400 個已驗證臨床小故事，並使用由人工智慧驅動的患者角色模擬實際的臨床互動。在系統性測試中，August 達到了 81.8% 的前一項診斷準確度（327/400 個案例）和 85.0% 的前兩項準確度（340/400 個案例），顯著優於傳統的症狀檢查器。該系統在專科轉診方面表現出 95.8% 的準確度，並且與傳統症狀檢查器相比，所需的提問數量減少了 47%（平均 16 個問題，相較於 29 個問題），同時在諮詢過程中維持同理的對話。這些發現證明了人工智慧聊天機器人增強醫療保健服務的潛力，儘管在實際驗證和整合客觀臨床數據方面仍存在實作挑戰。本研究提供了一個可複製的架構，用於評估醫療保健人工智慧系統，有助於在臨床環境中負責任地開發和部署人工智慧。

##### **Addressing Small and Imbalanced Medical Image Datasets Using Generative Models: A Comparative Study of DDPM and PGGANs with Random and Greedy K Sampling**
2412.12532v1 by Iman Khazrak, Shakhnoza Takhirova, Mostafa M. Rezaee, Mehrdad Yadollahi, Robert C. Green II, Shuteng Niu

The development of accurate medical image classification models is often
constrained by privacy concerns and data scarcity for certain conditions,
leading to small and imbalanced datasets. To address these limitations, this
study explores the use of generative models, such as Denoising Diffusion
Probabilistic Models (DDPM) and Progressive Growing Generative Adversarial
Networks (PGGANs), for dataset augmentation. The research introduces a
framework to assess the impact of synthetic images generated by DDPM and PGGANs
on the performance of four models: a custom CNN, Untrained VGG16, Pretrained
VGG16, and Pretrained ResNet50. Experiments were conducted using Random
Sampling and Greedy K Sampling to create small, imbalanced datasets. The
synthetic images were evaluated using Frechet Inception Distance (FID) and
compared to original datasets through classification metrics. The results show
that DDPM consistently generated more realistic images with lower FID scores
and significantly outperformed PGGANs in improving classification metrics
across all models and datasets. Incorporating DDPM-generated images into the
original datasets increased accuracy by up to 6%, enhancing model robustness
and stability, particularly in imbalanced scenarios. Random Sampling
demonstrated superior stability, while Greedy K Sampling offered diversity at
the cost of higher FID scores. This study highlights the efficacy of DDPM in
augmenting small, imbalanced medical image datasets, improving model
performance by balancing the dataset and expanding its size.

摘要：<paragraph>準確醫療影像分類模型的開發常受限於隱私疑慮和特定狀況資料的稀缺，這導致資料集規模小且不平衡。為了解決這些限制，本研究探討生成模型，例如去噪擴散機率模型 (DDPM) 和漸進式生成對抗網路 (PGGAN)，用於資料集擴充。本研究引進一個架構，評估由 DDPM 和 PGGAN 生成的合成影像對四個模型效能的影響：自訂 CNN、Untrained VGG16、Pretrained VGG16 和 Pretrained ResNet50。實驗使用隨機取樣和貪婪 K 取樣進行，以建立小規模的不平衡資料集。合成影像使用 Fréchet 起始距離 (FID) 進行評估，並透過分類指標與原始資料集進行比較。結果顯示，DDPM 持續產生較逼真的影像，FID 分數較低，且在改善所有模型和資料集的分類指標方面，表現明顯優於 PGGAN。將 DDPM 生成的影像納入原始資料集，可將準確度提升多達 6%，增強模型的穩健性和穩定性，特別是在不平衡的情況下。隨機取樣展現出優異的穩定性，而貪婪 K 取樣則以較高的 FID 分數為代價，提供了多樣性。本研究強調 DDPM 在擴充小規模、不平衡醫療影像資料集方面的效能，透過平衡資料集和擴充其規模，改善模型效能。</paragraph>

