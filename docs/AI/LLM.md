
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-28**|**Eagle: Exploring The Design Space for Multimodal LLMs with Mixture of Encoders**|Min Shi et.al.|[2408.15998v1](http://arxiv.org/abs/2408.15998v1)|[link](https://github.com/nvlabs/eagle)|
|**2024-08-28**|**Mamba or Transformer for Time Series Forecasting? Mixture of Universals (MoU) Is All You Need**|Sijia Peng et.al.|[2408.15997v1](http://arxiv.org/abs/2408.15997v1)|[link](https://github.com/lunaaa95/mou)|
|**2024-08-28**|**Spatio-Temporal Context Prompting for Zero-Shot Action Detection**|Wei-Jhe Huang et.al.|[2408.15996v2](http://arxiv.org/abs/2408.15996v2)|null|
|**2024-08-28**|**CoGen: Learning from Feedback with Coupled Comprehension and Generation**|Mustafa Omer Gul et.al.|[2408.15992v1](http://arxiv.org/abs/2408.15992v1)|[link](https://github.com/lil-lab/cogen)|
|**2024-08-28**|**In-Context Imitation Learning via Next-Token Prediction**|Letian Fu et.al.|[2408.15980v1](http://arxiv.org/abs/2408.15980v1)|null|
|**2024-08-28**|**WebPilot: A Versatile and Autonomous Multi-Agent System for Web Task Execution with Strategic Exploration**|Yao Zhang et.al.|[2408.15978v1](http://arxiv.org/abs/2408.15978v1)|null|
|**2024-08-28**|**BattleAgentBench: A Benchmark for Evaluating Cooperation and Competition Capabilities of Language Models in Multi-Agent Systems**|Wei Wang et.al.|[2408.15971v1](http://arxiv.org/abs/2408.15971v1)|null|
|**2024-08-28**|**More Text, Less Point: Towards 3D Data-Efficient Point-Language Understanding**|Yuan Tang et.al.|[2408.15966v1](http://arxiv.org/abs/2408.15966v1)|null|
|**2024-08-28**|**Atari-GPT: Investigating the Capabilities of Multimodal Large Language Models as Low-Level Policies for Atari Games**|Nicholas R. Waytowich et.al.|[2408.15950v1](http://arxiv.org/abs/2408.15950v1)|null|
|**2024-08-28**|**Local Descriptors Weighted Adaptive Threshold Filtering For Few-Shot Learning**|Bingchen Yan et.al.|[2408.15924v1](http://arxiv.org/abs/2408.15924v1)|null|
|**2024-08-28**|**Leveraging Open Knowledge for Advancing Task Expertise in Large Language Models**|Yuncheng Yang et.al.|[2408.15915v1](http://arxiv.org/abs/2408.15915v1)|null|
|**2024-08-28**|**LLM-Based Multi-Hop Question Answering with Knowledge Graph Integration in Evolving Environments**|Ruirui Chen et.al.|[2408.15903v1](http://arxiv.org/abs/2408.15903v1)|null|
|**2024-08-28**|**Nexus: Specialization meets Adaptability for Efficiently Training Mixture of Experts**|Nikolas Gritsch et.al.|[2408.15901v1](http://arxiv.org/abs/2408.15901v1)|null|
|**2024-08-28**|**Airfoil Diffusion: Denoising Diffusion Model For Conditional Airfoil Generation**|Reid Graves et.al.|[2408.15898v1](http://arxiv.org/abs/2408.15898v1)|null|
|**2024-08-28**|**A New Method for Cross-Lingual-based Semantic Role Labeling**|Mohammad Ebrahimi et.al.|[2408.15896v1](http://arxiv.org/abs/2408.15896v1)|null|
|**2024-08-28**|**Bias in LLMs as Annotators: The Effect of Party Cues on Labelling Decision by Large Language Models**|Sebastian Vallejo Vera et.al.|[2408.15895v1](http://arxiv.org/abs/2408.15895v1)|null|
|**2024-08-28**|**Enhancing Intrusion Detection in IoT Environments: An Advanced Ensemble Approach Using Kolmogorov-Arnold Networks**|Amar Amouri et.al.|[2408.15886v2](http://arxiv.org/abs/2408.15886v2)|null|
|**2024-08-28**|**Persuasion Games using Large Language Models**|Ganesh Prasath Ramani et.al.|[2408.15879v1](http://arxiv.org/abs/2408.15879v1)|null|
|**2024-08-28**|**GenDDS: Generating Diverse Driving Video Scenarios with Prompt-to-Video Generative Model**|Yongjie Fu et.al.|[2408.15868v1](http://arxiv.org/abs/2408.15868v1)|null|
|**2024-08-28**|**Retrieval-Augmented Instruction Tuning for Automated Process Engineering Calculations : A Tool-Chaining Problem-Solving Framework with Attributable Reflection**|Sagar Srinivas Sakhinana et.al.|[2408.15866v1](http://arxiv.org/abs/2408.15866v1)|null|
|**2024-08-28**|**Knowledge Navigator: LLM-guided Browsing Framework for Exploratory Search in Scientific Literature**|Uri Katz et.al.|[2408.15836v1](http://arxiv.org/abs/2408.15836v1)|null|
|**2024-08-28**|**Automatic Differential Diagnosis using Transformer-Based Multi-Label Sequence Classification**|Abu Adnan Sadi et.al.|[2408.15827v1](http://arxiv.org/abs/2408.15827v1)|null|
|**2024-08-28**|**Object Detection for Vehicle Dashcams using Transformers**|Osama Mustafa et.al.|[2408.15809v1](http://arxiv.org/abs/2408.15809v1)|null|
|**2024-08-28**|**ModalityMirror: Improving Audio Classification in Modality Heterogeneity Federated Learning with Multimodal Distillation**|Tiantian Feng et.al.|[2408.15803v1](http://arxiv.org/abs/2408.15803v1)|null|
|**2024-08-28**|**Scaling Up Summarization: Leveraging Large Language Models for Long Text Extractive Summarization**|Léo Hemamou et.al.|[2408.15801v1](http://arxiv.org/abs/2408.15801v1)|null|
|**2024-08-28**|**Emulating Brain-like Rapid Learning in Neuromorphic Edge Computing**|Kenneth Stewart et.al.|[2408.15800v1](http://arxiv.org/abs/2408.15800v1)|[link](https://github.com/nmi-lab/snn_maml)|
|**2024-08-28**|**Evaluating Named Entity Recognition Using Few-Shot Prompting with Large Language Models**|Hédi Zhegidi et.al.|[2408.15796v1](http://arxiv.org/abs/2408.15796v1)|[link](https://github.com/geode-project/ner-llm)|
|**2024-08-28**|**Language Adaptation on a Tight Academic Compute Budget: Tokenizer Swapping Works and Pure bfloat16 Is Enough**|Konstantin Dobler et.al.|[2408.15793v1](http://arxiv.org/abs/2408.15793v1)|[link](https://github.com/konstantinjdobler/tight-budget-llm-adaptation)|
|**2024-08-28**|**Interactive Agents: Simulating Counselor-Client Psychological Counseling via Role-Playing LLM-to-LLM Interactions**|Huachuan Qiu et.al.|[2408.15787v1](http://arxiv.org/abs/2408.15787v1)|[link](https://github.com/qiuhuachuan/interactive-agents)|
|**2024-08-28**|**LogicGame: Benchmarking Rule-Based Reasoning Abilities of Large Language Models**|Jiayi Gui et.al.|[2408.15778v1](http://arxiv.org/abs/2408.15778v1)|null|
|**2024-08-28**|**Easy, Interpretable, Effective: openSMILE for voice deepfake detection**|Octavian Pascu et.al.|[2408.15775v2](http://arxiv.org/abs/2408.15775v2)|null|
|**2024-08-28**|**A Survey on Evaluation of Multimodal Large Language Models**|Jiaxing Huang et.al.|[2408.15769v1](http://arxiv.org/abs/2408.15769v1)|null|
|**2024-08-28**|**Harmonized Speculative Sampling**|Lefan Zhang et.al.|[2408.15766v1](http://arxiv.org/abs/2408.15766v1)|null|
|**2024-08-28**|**Form and meaning co-determine the realization of tone in Taiwan Mandarin spontaneous speech: the case of Tone 3 sandhi**|Yuxin Lu et.al.|[2408.15747v1](http://arxiv.org/abs/2408.15747v1)|null|
|**2024-08-28**|**LM-PUB-QUIZ: A Comprehensive Framework for Zero-Shot Evaluation of Relational Knowledge in Language Models**|Max Ploner et.al.|[2408.15729v1](http://arxiv.org/abs/2408.15729v1)|null|
|**2024-08-28**|**Advanced POD-Based Performance Evaluation of Classifiers Applied to Human Driver Lane Changing Prediction**|Zahra Rastin et.al.|[2408.15722v1](http://arxiv.org/abs/2408.15722v1)|null|
|**2024-08-28**|**Conan-embedding: General Text Embedding with More and Better Negative Samples**|Shiyu Li et.al.|[2408.15710v2](http://arxiv.org/abs/2408.15710v2)|null|
|**2024-08-28**|**Evaluating Model Robustness Using Adaptive Sparse L0 Regularization**|Weiyou Liu et.al.|[2408.15702v1](http://arxiv.org/abs/2408.15702v1)|null|
|**2024-08-28**|**TempoFormer: A Transformer for Temporally-aware Representations in Change Detection**|Talia Tseriotou et.al.|[2408.15689v1](http://arxiv.org/abs/2408.15689v1)|null|
|**2024-08-28**|**StyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements**|Jillian Fisher et.al.|[2408.15666v1](http://arxiv.org/abs/2408.15666v1)|[link](https://github.com/jfisher52/StyleRemix)|
|**2024-08-28**|**Auxiliary-Loss-Free Load Balancing Strategy for Mixture-of-Experts**|Lean Wang et.al.|[2408.15664v1](http://arxiv.org/abs/2408.15664v1)|null|
|**2024-08-28**|**An Empirical Study on Self-correcting Large Language Models for Data Science Code Generation**|Thai Tang Quoc et.al.|[2408.15658v1](http://arxiv.org/abs/2408.15658v1)|null|
|**2024-08-28**|**Harnessing the Intrinsic Knowledge of Pretrained Language Models for Challenging Text Classification Settings**|Lingyu Gao et.al.|[2408.15650v1](http://arxiv.org/abs/2408.15650v1)|null|
|**2024-08-28**|**Hierarchical Blockmodelling for Knowledge Graphs**|Marcin Pietrasik et.al.|[2408.15649v1](http://arxiv.org/abs/2408.15649v1)|[link](https://github.com/mpietrasik/hb)|
|**2024-08-28**|**GANs Conditioning Methods: A Survey**|Anis Bourou et.al.|[2408.15640v2](http://arxiv.org/abs/2408.15640v2)|null|
|**2024-08-28**|**CodeSift: An LLM-Based Reference-Less Framework for Automatic Code Validation**|Pooja Aggarwal et.al.|[2408.15630v1](http://arxiv.org/abs/2408.15630v1)|null|
|**2024-08-28**|**CBF-LLM: Safe Control for LLM Alignment**|Yuya Miyaoka et.al.|[2408.15625v1](http://arxiv.org/abs/2408.15625v1)|[link](https://github.com/mya-mya/cbf-llm)|
|**2024-08-28**|**SIaM: Self-Improving Code-Assisted Mathematical Reasoning of Large Language Models**|Dian Yu et.al.|[2408.15565v1](http://arxiv.org/abs/2408.15565v1)|[link](https://github.com/tencent-ailab/siam)|
|**2024-08-28**|**Boosting Lossless Speculative Decoding via Feature Sampling and Partial Alignment Distillation**|Lujun Gui et.al.|[2408.15562v1](http://arxiv.org/abs/2408.15562v1)|null|
|**2024-08-28**|**CGRA4ML: A Framework to Implement Modern Neural Networks for Scientific Edge Computing**|G Abarajithan et.al.|[2408.15561v2](http://arxiv.org/abs/2408.15561v2)|null|
|**2024-08-28**|**Trustworthy and Responsible AI for Human-Centric Autonomous Decision-Making Systems**|Farzaneh Dehghani et.al.|[2408.15550v1](http://arxiv.org/abs/2408.15550v1)|null|
|**2024-08-28**|**WildFeedback: Aligning LLMs With In-situ User Interactions And Feedback**|Taiwei Shi et.al.|[2408.15549v1](http://arxiv.org/abs/2408.15549v1)|null|
|**2024-08-28**|**SciLitLLM: How to Adapt LLMs for Scientific Literature Understanding**|Sihang Li et.al.|[2408.15545v1](http://arxiv.org/abs/2408.15545v1)|null|
|**2024-08-28**|**An Investigation of Warning Erroneous Chat Translations in Cross-lingual Communication**|Yunmeng Li et.al.|[2408.15543v1](http://arxiv.org/abs/2408.15543v1)|null|
|**2024-08-28**|**Kangaroo: A Powerful Video-Language Model Supporting Long-context Video Input**|Jiajun Liu et.al.|[2408.15542v1](http://arxiv.org/abs/2408.15542v1)|null|
|**2024-08-28**|**TrafficGamer: Reliable and Flexible Traffic Simulation for Safety-Critical Scenarios with Game-Theoretic Oracles**|Guanren Qiao et.al.|[2408.15538v1](http://arxiv.org/abs/2408.15538v1)|[link](https://github.com/qiaoguanren/TrafficGamer)|
|**2024-08-28**|**LRP4RAG: Detecting Hallucinations in Retrieval-Augmented Generation via Layer-wise Relevance Propagation**|Haichuan Hu et.al.|[2408.15533v2](http://arxiv.org/abs/2408.15533v2)|[link](https://github.com/tomsawyerhu/lrp4rag)|
|**2024-08-28**|**Dolphin: Long Context as a New Modality for Energy-Efficient On-Device Language Models**|Wei Chen et.al.|[2408.15518v1](http://arxiv.org/abs/2408.15518v1)|null|
|**2024-08-28**|**Continual-learning-based framework for structural damage recognition**|Jiangpeng Shu et.al.|[2408.15513v1](http://arxiv.org/abs/2408.15513v1)|null|
|**2024-08-28**|**Towards Fully Autonomous Research Powered by LLMs: Case Study on Simulations**|Zhihan Liu et.al.|[2408.15512v1](http://arxiv.org/abs/2408.15512v1)|[link](https://github.com/zokaraa/autonomous_simulation_agent)|
|**2024-08-28**|**AeroVerse: UAV-Agent Benchmark Suite for Simulating, Pre-training, Finetuning, and Evaluating Aerospace Embodied World Models**|Fanglong Yao et.al.|[2408.15511v1](http://arxiv.org/abs/2408.15511v1)|null|
|**2024-08-28**|**Measuring the Reliability of Causal Probing Methods: Tradeoffs, Limitations, and the Plight of Nullifying Interventions**|Marc Canby et.al.|[2408.15510v1](http://arxiv.org/abs/2408.15510v1)|null|
|**2024-08-28**|**EmoAttack: Utilizing Emotional Voice Conversion for Speech Backdoor Attacks on Deep Speech Classification Models**|Wenhan Yao et.al.|[2408.15508v1](http://arxiv.org/abs/2408.15508v1)|null|
|**2024-08-28**|**What Machine Learning Tells Us About the Mathematical Structure of Concepts**|Jun Otsuka et.al.|[2408.15507v1](http://arxiv.org/abs/2408.15507v1)|null|
|**2024-08-28**|**MODULI: Unlocking Preference Generalization via Diffusion Models for Offline Multi-Objective Reinforcement Learning**|Yifu Yuan et.al.|[2408.15501v1](http://arxiv.org/abs/2408.15501v1)|null|
|**2024-08-28**|**Deep Learning to Predict Late-Onset Breast Cancer Metastasis: the Single Hyperparameter Grid Search (SHGS) Strategy for Meta Tuning Concerning Deep Feed-forward Neural Network**|Yijun Zhou et.al.|[2408.15498v1](http://arxiv.org/abs/2408.15498v1)|null|
|**2024-08-28**|**ReMamba: Equip Mamba with Effective Long-Sequence Modeling**|Danlong Yuan et.al.|[2408.15496v2](http://arxiv.org/abs/2408.15496v2)|null|
|**2024-08-28**|**Remove Symmetries to Control Model Expressivity**|Liu Ziyin et.al.|[2408.15495v1](http://arxiv.org/abs/2408.15495v1)|null|
|**2024-08-28**|**Enhancing and Accelerating Large Language Models via Instruction-Aware Contextual Compression**|Haowen Hou et.al.|[2408.15491v1](http://arxiv.org/abs/2408.15491v1)|[link](https://github.com/howard-hou/instruction-aware-contextual-compressor)|
|**2024-08-28**|**Legilimens: Practical and Unified Content Moderation for Large Language Model Services**|Jialin Wu et.al.|[2408.15488v1](http://arxiv.org/abs/2408.15488v1)|[link](https://github.com/lin000001/Legilimens)|
|**2024-08-28**|**CTRQNets & LQNets: Continuous Time Recurrent and Liquid Quantum Neural Networks**|Alejandro Mayorga et.al.|[2408.15462v1](http://arxiv.org/abs/2408.15462v1)|null|
|**2024-08-27**|**Online Event-Triggered Switching for Frequency Control in Power Grids with Variable Inertia**|Jie Feng et.al.|[2408.15436v1](http://arxiv.org/abs/2408.15436v1)|[link](https://github.com/JieFeng-cse/Online-Event-Triggered-Switching-for-Frequency-Control)|
|**2024-08-27**|**Simultaneous Training of First- and Second-Order Optimizers in Population-Based Reinforcement Learning**|Felix Pfeiffer et.al.|[2408.15421v1](http://arxiv.org/abs/2408.15421v1)|null|
|**2024-08-27**|**Implicit Geometry of Next-token Prediction: From Language Sparsity Patterns to Model Representations**|Yize Zhao et.al.|[2408.15417v1](http://arxiv.org/abs/2408.15417v1)|null|
|**2024-08-27**|**Awes, Laws, and Flaws From Today's LLM Research**|Adrian de Wynter et.al.|[2408.15409v2](http://arxiv.org/abs/2408.15409v2)|[link](https://github.com/adewynter/awes_laws_and_flaws)|
|**2024-08-27**|**Intertwined Biases Across Social Media Spheres: Unpacking Correlations in Media Bias Dimensions**|Yifan Liu et.al.|[2408.15406v1](http://arxiv.org/abs/2408.15406v1)|null|
|**2024-08-27**|**A Statistical Framework for Data-dependent Retrieval-Augmented Models**|Soumya Basu et.al.|[2408.15399v1](http://arxiv.org/abs/2408.15399v1)|null|
|**2024-08-27**|**DualKanbaFormer: Kolmogorov-Arnold Networks and State Space Model DualKanbaFormer: Kolmogorov-Arnold Networks and State Space Model Transformer for Multimodal Aspect-based Sentiment Analysis**|Adamu Lawan et.al.|[2408.15379v1](http://arxiv.org/abs/2408.15379v1)|null|
|**2024-08-27**|**Handling Geometric Domain Shifts in Semantic Segmentation of Surgical RGB and Hyperspectral Images**|Silvia Seidlitz et.al.|[2408.15373v1](http://arxiv.org/abs/2408.15373v1)|[link](https://github.com/imsy-dkfz/htc)|
|**2024-08-27**|**Pitfalls and Outlooks in Using COMET**|Vilém Zouhar et.al.|[2408.15366v1](http://arxiv.org/abs/2408.15366v1)|[link](https://github.com/PinzhenChen/sacreCOMET)|
|**2024-08-27**|**UNA: Unifying Alignments of RLHF/PPO, DPO and KTO by a Generalized Implicit Reward Function**|Zhichao Wang et.al.|[2408.15339v1](http://arxiv.org/abs/2408.15339v1)|null|
|**2024-08-27**|**The Mamba in the Llama: Distilling and Accelerating Hybrid Models**|Junxiong Wang et.al.|[2408.15237v1](http://arxiv.org/abs/2408.15237v1)|[link](https://github.com/jxiw/mambainllama)|
|**2024-08-27**|**Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations**|Yucheng Jiang et.al.|[2408.15232v1](http://arxiv.org/abs/2408.15232v1)|null|
|**2024-08-27**|**LLM Defenses Are Not Robust to Multi-Turn Human Jailbreaks Yet**|Nathaniel Li et.al.|[2408.15221v1](http://arxiv.org/abs/2408.15221v1)|null|
|**2024-08-27**|**Bi-Factorial Preference Optimization: Balancing Safety-Helpfulness in Language Models**|Wenxuan Zhang et.al.|[2408.15313v1](http://arxiv.org/abs/2408.15313v1)|null|
|**2024-08-27**|**Classifying populist language in American presidential and governor speeches using automatic text analysis**|Olaf van der Veen et.al.|[2408.15213v1](http://arxiv.org/abs/2408.15213v1)|null|
|**2024-08-27**|**Can Unconfident LLM Annotations Be Used for Confident Conclusions?**|Kristina Gligorić et.al.|[2408.15204v1](http://arxiv.org/abs/2408.15204v1)|null|
|**2024-08-27**|**Infusing Acoustic Pause Context into Text-Based Dementia Assessment**|Franziska Braun et.al.|[2408.15188v1](http://arxiv.org/abs/2408.15188v1)|null|
|**2024-08-27**|**PoseWatch: A Transformer-based Architecture for Human-centric Video Anomaly Detection Using Spatio-temporal Pose Tokenization**|Ghazal Alinezhad Noghre et.al.|[2408.15185v1](http://arxiv.org/abs/2408.15185v1)|null|
|**2024-08-27**|**Unlocking Potential in Pre-Trained Music Language Models for Versatile Multi-Track Music Arrangement**|Longshen Ou et.al.|[2408.15176v1](http://arxiv.org/abs/2408.15176v1)|null|
|**2024-08-27**|**X-Reflect: Cross-Reflection Prompting for Multimodal Recommendation**|Hanjia Lyu et.al.|[2408.15172v1](http://arxiv.org/abs/2408.15172v1)|null|
|**2024-08-27**|**Measuring text summarization factuality using atomic facts entailment metrics in the context of retrieval augmented generation**|N. E. Kriman et.al.|[2408.15171v1](http://arxiv.org/abs/2408.15171v1)|null|
|**2024-08-27**|**Parameter-Efficient Quantized Mixture-of-Experts Meets Vision-Language Instruction Tuning for Semiconductor Electron Micrograph Analysis**|Sakhinana Sagar Srinivas et.al.|[2408.15305v1](http://arxiv.org/abs/2408.15305v1)|null|
|**2024-08-27**|**TCNFormer: Temporal Convolutional Network Former for Short-Term Wind Speed Forecasting**|Abid Hasan Zim et.al.|[2408.15737v1](http://arxiv.org/abs/2408.15737v1)|null|
|**2024-08-27**|**How transformers learn structured data: insights from hierarchical filtering**|Jerome Garnier-Brun et.al.|[2408.15138v1](http://arxiv.org/abs/2408.15138v1)|null|
|**2024-08-27**|**Evaluating the Energy Consumption of Machine Learning: Systematic Literature Review and Experiments**|Charlotte Rodriguez et.al.|[2408.15128v1](http://arxiv.org/abs/2408.15128v1)|null|
|**2024-08-27**|**The Uniqueness of LLaMA3-70B with Per-Channel Quantization: An Empirical Study**|Minghai Qin et.al.|[2408.15301v1](http://arxiv.org/abs/2408.15301v1)|null|
|**2024-08-27**|**Urdu Digital Text Word Optical Character Recognition Using Permuted Auto Regressive Sequence Modeling**|Ahmed Mustafa et.al.|[2408.15119v2](http://arxiv.org/abs/2408.15119v2)|null|
|**2024-08-27**|**Evaluating Stability of Unreflective Alignment**|James Lucassen et.al.|[2408.15116v1](http://arxiv.org/abs/2408.15116v1)|null|
|**2024-08-27**|**GIFT-SW: Gaussian noise Injected Fine-Tuning of Salient Weights for LLMs**|Maxim Zhelnin et.al.|[2408.15300v1](http://arxiv.org/abs/2408.15300v1)|[link](https://github.com/On-Point-RND/GIFT_SW)|

#### Abstracts
##### **Eagle: Exploring The Design Space for Multimodal LLMs with Mixture of Encoders**
2408.15998v1 by Min Shi, Fuxiao Liu, Shihao Wang, Shijia Liao, Subhashree Radhakrishnan, De-An Huang, Hongxu Yin, Karan Sapra, Yaser Yacoob, Humphrey Shi, Bryan Catanzaro, Andrew Tao, Jan Kautz, Zhiding Yu, Guilin Liu

The ability to accurately interpret complex visual information is a crucial
topic of multimodal large language models (MLLMs). Recent work indicates that
enhanced visual perception significantly reduces hallucinations and improves
performance on resolution-sensitive tasks, such as optical character
recognition and document analysis. A number of recent MLLMs achieve this goal
using a mixture of vision encoders. Despite their success, there is a lack of
systematic comparisons and detailed ablation studies addressing critical
aspects, such as expert selection and the integration of multiple vision
experts. This study provides an extensive exploration of the design space for
MLLMs using a mixture of vision encoders and resolutions. Our findings reveal
several underlying principles common to various existing strategies, leading to
a streamlined yet effective design approach. We discover that simply
concatenating visual tokens from a set of complementary vision encoders is as
effective as more complex mixing architectures or strategies. We additionally
introduce Pre-Alignment to bridge the gap between vision-focused encoders and
language tokens, enhancing model coherence. The resulting family of MLLMs,
Eagle, surpasses other leading open-source models on major MLLM benchmarks.
Models and code: https://github.com/NVlabs/Eagle

摘要：準確地詮釋複雜的視覺資訊的能力是多模態大型語言模型 (MLLM) 的一個關鍵議題。最近的研究指出，增強的視覺感知能顯著減少幻覺，並改善對解析度敏感任務的執行，例如光學字元辨識和文件分析。許多最近的 MLLM 使用視覺編碼器的混合來達成此目標。儘管它們成功，但缺乏系統性的比較和詳細的消融研究來探討關鍵面向，例如專家選擇和整合多個視覺專家。本研究針對使用視覺編碼器和解析度的 MLLM 混合提供了廣泛的設計空間探討。我們的發現揭示了各種現有策略中幾個共同的底層原則，進而引導出簡化但有效的設計方法。我們發現，僅僅連結來自一組互補視覺編碼器的視覺代碼，就和更複雜的混合架構或策略一樣有效。此外，我們引入了預對齊，以彌合以視覺為中心的編碼器和語言代碼之間的差距，增強模型的相干性。由此產生的 MLLM 家族 Eagle，在主要的 MLLM 基準上超越了其他領先的開源模型。模型和程式碼：https://github.com/NVlabs/Eagle

##### **Mamba or Transformer for Time Series Forecasting? Mixture of Universals (MoU) Is All You Need**
2408.15997v1 by Sijia Peng, Yun Xiong, Yangyong Zhu, Zhiqiang Shen

Time series forecasting requires balancing short-term and long-term
dependencies for accurate predictions. Existing methods mainly focus on
long-term dependency modeling, neglecting the complexities of short-term
dynamics, which may hinder performance. Transformers are superior in modeling
long-term dependencies but are criticized for their quadratic computational
cost. Mamba provides a near-linear alternative but is reported less effective
in time series longterm forecasting due to potential information loss. Current
architectures fall short in offering both high efficiency and strong
performance for long-term dependency modeling. To address these challenges, we
introduce Mixture of Universals (MoU), a versatile model to capture both
short-term and long-term dependencies for enhancing performance in time series
forecasting. MoU is composed of two novel designs: Mixture of Feature
Extractors (MoF), an adaptive method designed to improve time series patch
representations for short-term dependency, and Mixture of Architectures (MoA),
which hierarchically integrates Mamba, FeedForward, Convolution, and
Self-Attention architectures in a specialized order to model long-term
dependency from a hybrid perspective. The proposed approach achieves
state-of-the-art performance while maintaining relatively low computational
costs. Extensive experiments on seven real-world datasets demonstrate the
superiority of MoU. Code is available at https://github.com/lunaaa95/mou/.

摘要：時間序列預測需要平衡短期和長期依賴性，才能做出準確的預測。現有方法主要專注於長期依賴性建模，忽略了短期動態的複雜性，這可能會阻礙效能。Transformer 在建模長期依賴性方面表現優異，但因其二次計算成本而受到批評。Mamba 提供了一個接近線性的替代方案，但據報導，由於潛在資訊遺失，在時間序列長期預測中效果較差。目前的架構無法同時提供高效率和強大的效能，以進行長期依賴性建模。為了應對這些挑戰，我們引入了 Mixture of Universals (MoU)，這是一個通用模型，可以捕捉短期和長期依賴性，以增強時間序列預測的效能。MoU 由兩個新穎的設計組成：特徵萃取器混合 (MoF)，一種適應方法，旨在改善時間序列區塊表示，以適應短期依賴性；以及架構混合 (MoA)，它以一種專業的順序分層整合 Mamba、前饋、卷積和自注意力架構，以從混合觀點對長期依賴性進行建模。所提出的方法在保持相對較低計算成本的同時，達到了最先進的效能。在七個真實世界資料集上進行的廣泛實驗證明了 MoU 的優越性。程式碼可在 https://github.com/lunaaa95/mou/ 獲得。

##### **Spatio-Temporal Context Prompting for Zero-Shot Action Detection**
2408.15996v2 by Wei-Jhe Huang, Min-Hung Chen, Shang-Hong Lai

Spatio-temporal action detection encompasses the tasks of localizing and
classifying individual actions within a video. Recent works aim to enhance this
process by incorporating interaction modeling, which captures the relationship
between people and their surrounding context. However, these approaches have
primarily focused on fully-supervised learning, and the current limitation lies
in the lack of generalization capability to recognize unseen action categories.
In this paper, we aim to adapt the pretrained image-language models to detect
unseen actions. To this end, we propose a method which can effectively leverage
the rich knowledge of visual-language models to perform Person-Context
Interaction. Meanwhile, our Context Prompting module will utilize contextual
information to prompt labels, thereby enhancing the generation of more
representative text features. Moreover, to address the challenge of recognizing
distinct actions by multiple people at the same timestamp, we design the
Interest Token Spotting mechanism which employs pretrained visual knowledge to
find each person's interest context tokens, and then these tokens will be used
for prompting to generate text features tailored to each individual. To
evaluate the ability to detect unseen actions, we propose a comprehensive
benchmark on J-HMDB, UCF101-24, and AVA datasets. The experiments show that our
method achieves superior results compared to previous approaches and can be
further extended to multi-action videos, bringing it closer to real-world
applications. The code and data can be found in
https://webber2933.github.io/ST-CLIP-project-page.

摘要：時空動作偵測涵蓋了在影片中定位和分類個別動作的任務。最近的研究旨在透過納入互動建模來增強此程序，這能捕捉人與其周遭環境之間的關係。然而，這些方法主要著重於全監督式學習，而目前的限制在於缺乏辨識未見動作類別的概化能力。在本文中，我們旨在調整預訓練的影像語言模型，以偵測未見的動作。為此，我們提出了一種方法，它能有效利用視覺語言模型豐富的知識來執行人情境互動。同時，我們的脈絡提示模組將利用脈絡資訊來提示標籤，從而增強更具代表性的文字特徵的產生。此外，為了應對在同一個時間戳記中辨識多人不同動作的挑戰，我們設計了興趣標記點選機制，它採用預訓練的視覺知識來尋找每個人的興趣脈絡標記，然後這些標記將用於提示，以產生針對每個個體量身打造的文字特徵。為了評估偵測未見動作的能力，我們在 J-HMDB、UCF101-24 和 AVA 資料集上提出了全面的基準。實驗顯示，與先前的做法相比，我們的方法獲得了優異的結果，並且可以進一步擴展到多動作影片，使其更接近於真實世界的應用。程式碼和資料可以在 https://webber2933.github.io/ST-CLIP-project-page 中找到。

##### **CoGen: Learning from Feedback with Coupled Comprehension and Generation**
2408.15992v1 by Mustafa Omer Gul, Yoav Artzi

Systems with both language comprehension and generation capabilities can
benefit from the tight connection between the two. This work studies coupling
comprehension and generation with focus on continually learning from
interaction with users. We propose techniques to tightly integrate the two
capabilities for both learning and inference. We situate our studies in
two-player reference games, and deploy various models for thousands of
interactions with human users, while learning from interaction feedback
signals. We show dramatic improvements in performance over time, with
comprehension-generation coupling leading to performance improvements up to 26%
in absolute terms and up to 17% higher accuracies compared to a non-coupled
system. Our analysis also shows coupling has substantial qualitative impact on
the system's language, making it significantly more human-like.

摘要：具備語言理解與產生能力的系統能從兩者之間的緊密連結中獲益。這項工作研究了將理解與產生結合，並專注於從與使用者的互動中持續學習。我們提出了一些技術，用於在學習和推理中緊密整合這兩種能力。我們將研究置於雙人參考遊戲中，並部署各種模型，與人類使用者進行數千次互動，同時從互動回饋訊號中學習。我們展示了隨著時間推移而大幅提升的效能，理解產生結合可帶來高達 26% 的絕對效能提升，以及與非結合系統相比，準確度提升高達 17%。我們的分析也顯示，結合對系統語言有實質性的質化影響，使其更接近人類語言。

##### **In-Context Imitation Learning via Next-Token Prediction**
2408.15980v1 by Letian Fu, Huang Huang, Gaurav Datta, Lawrence Yunliang Chen, William Chung-Ho Panitch, Fangchen Liu, Hui Li, Ken Goldberg

We explore how to enhance next-token prediction models to perform in-context
imitation learning on a real robot, where the robot executes new tasks by
interpreting contextual information provided during the input phase, without
updating its underlying policy parameters. We propose In-Context Robot
Transformer (ICRT), a causal transformer that performs autoregressive
prediction on sensorimotor trajectories without relying on any linguistic data
or reward function. This formulation enables flexible and training-free
execution of new tasks at test time, achieved by prompting the model with
sensorimotor trajectories of the new task composing of image observations,
actions and states tuples, collected through human teleoperation. Experiments
with a Franka Emika robot demonstrate that the ICRT can adapt to new tasks
specified by prompts, even in environment configurations that differ from both
the prompt and the training data. In a multitask environment setup, ICRT
significantly outperforms current state-of-the-art next-token prediction models
in robotics on generalizing to unseen tasks. Code, checkpoints and data are
available on https://icrt.dev/

摘要：我們探討如何增強下一個代幣預測模型，以便在真實機器人上執行情境內模仿學習，其中機器人在輸入階段解釋提供的背景資訊來執行新任務，而不會更新其基礎策略參數。我們提出情境內機器人轉換器 (ICRT)，這是一個因果轉換器，對感測運動軌跡執行自迴歸預測，而不依賴任何語言資料或獎勵函數。此公式化能靈活且無需訓練地執行新任務於測試時間，這是透過提示模型包含影像觀察、動作和狀態元組的新任務感測運動軌跡，經由人為遙控收集而達成。使用 Franka Emika 機器的實驗證明，即使在提示和訓練資料不同的環境組態中，ICRT 也能適應由提示指定的任務。在多任務環境設定中，ICRT 在機器人學上顯著優於目前最先進的下一個代幣預測模型，並推廣到未見任務。程式碼、檢查點和資料可於 https://icrt.dev/ 取得

##### **WebPilot: A Versatile and Autonomous Multi-Agent System for Web Task Execution with Strategic Exploration**
2408.15978v1 by Yao Zhang, Zijian Ma, Yunpu Ma, Zhen Han, Yu Wu, Volker Tresp

LLM-based autonomous agents often fail to execute complex web tasks that
require dynamic interaction due to the inherent uncertainty and complexity of
these environments. Existing LLM-based web agents typically rely on rigid,
expert-designed policies specific to certain states and actions, which lack the
flexibility and generalizability needed to adapt to unseen tasks. In contrast,
humans excel by exploring unknowns, continuously adapting strategies, and
resolving ambiguities through exploration. To emulate human-like adaptability,
web agents need strategic exploration and complex decision-making. Monte Carlo
Tree Search (MCTS) is well-suited for this, but classical MCTS struggles with
vast action spaces, unpredictable state transitions, and incomplete information
in web tasks. In light of this, we develop WebPilot, a multi-agent system with
a dual optimization strategy that improves MCTS to better handle complex web
environments. Specifically, the Global Optimization phase involves generating a
high-level plan by breaking down tasks into manageable subtasks and
continuously refining this plan, thereby focusing the search process and
mitigating the challenges posed by vast action spaces in classical MCTS.
Subsequently, the Local Optimization phase executes each subtask using a
tailored MCTS designed for complex environments, effectively addressing
uncertainties and managing incomplete information. Experimental results on
WebArena and MiniWoB++ demonstrate the effectiveness of WebPilot. Notably, on
WebArena, WebPilot achieves SOTA performance with GPT-4, achieving a 93%
relative increase in success rate over the concurrent tree search-based method.
WebPilot marks a significant advancement in general autonomous agent
capabilities, paving the way for more advanced and reliable decision-making in
practical environments.

摘要：<paragraph>基於 LLM 的自主代理通常無法執行複雜的網路任務，因為這些環境具有內在的不確定性和複雜性，需要動態互動。現有的基於 LLM 的網路代理通常依賴於針對特定狀態和動作設計的僵化專家政策，缺乏適應未知任務所需的靈活性與概括性。相反地，人類擅長探索未知、持續調整策略，並透過探索解決模棱兩可的問題。為了模擬類人適應力，網路代理需要策略性探索和複雜的決策制定。蒙地卡羅樹狀搜尋 (MCTS) 非常適合這一點，但傳統的 MCTS 難以應付網路任務中廣大的動作空間、不可預測的狀態轉換和不完整資訊。有鑑於此，我們開發了 WebPilot，一個具有雙重最佳化策略的多代理系統，可改善 MCTS 以更好地處理複雜的網路環境。具體來說，全球最佳化階段涉及透過將任務分解成可管理的子任務並持續優化此計畫來產生高階計畫，從而集中搜尋流程並減輕傳統 MCTS 中廣大動作空間所帶來的挑戰。隨後，局部最佳化階段使用專為複雜環境設計的客製化 MCTS 來執行每個子任務，有效地解決不確定性並管理不完整資訊。在 WebArena 和 MiniWoB++ 上的實驗結果證明了 WebPilot 的有效性。值得注意的是，在 WebArena 上，WebPilot 以 GPT-4 達到了 SOTA 效能，相較於並行的基於樹狀搜尋的方法，成功率增加了 93%。WebPilot 標誌著一般自主代理能力的重大進步，為在實際環境中進行更進階且可靠的決策制定鋪路。</paragraph>

##### **BattleAgentBench: A Benchmark for Evaluating Cooperation and Competition Capabilities of Language Models in Multi-Agent Systems**
2408.15971v1 by Wei Wang, Dan Zhang, Tao Feng, Boyan Wang, Jie Tang

Large Language Models (LLMs) are becoming increasingly powerful and capable
of handling complex tasks, e.g., building single agents and multi-agent
systems. Compared to single agents, multi-agent systems have higher
requirements for the collaboration capabilities of language models. Many
benchmarks are proposed to evaluate their collaborative abilities. However,
these benchmarks lack fine-grained evaluations of LLM collaborative
capabilities. Additionally, multi-agent collaborative and competitive scenarios
are ignored in existing works. To address these two problems, we propose a
benchmark, called BattleAgentBench, which defines seven sub-stages of three
varying difficulty levels and conducts a fine-grained evaluation of language
models in terms of single-agent scenario navigation capabilities, paired-agent
task execution abilities, and multi-agent collaboration and competition
capabilities. We conducted extensive evaluations on leading four closed-source
and seven open-source models. Experimental results indicate that API-based
models perform excellently on simple tasks but open-source small models
struggle with simple tasks. Regarding difficult tasks that require
collaborative and competitive abilities, although API-based models have
demonstrated some collaborative capabilities, there is still enormous room for
improvement.

摘要：大型語言模型（LLM）變得越來越強大，並且能夠處理複雜的任務，例如，建立單一代理和多代理系統。與單一代理相比，多代理系統對語言模型的協作能力有更高的要求。許多基準被提出用於評估它們的協作能力。然而，這些基準缺乏對 LLM 協作能力的細粒度評估。此外，現有工作中忽略了多代理協作和競爭場景。為了解決這兩個問題，我們提出了一個基準，稱為 BattleAgentBench，它定義了三個不同難度級別的七個子階段，並對語言模型在單一代理場景導航能力、配對代理任務執行能力以及多代理協作和競爭能力方面進行了細粒度評估。我們對領先的四個閉源模型和七個開源模型進行了廣泛的評估。實驗結果表明，基於 API 的模型在簡單任務上表現出色，但開源小模型在簡單任務上表現不佳。對於需要協作和競爭能力的困難任務，儘管基於 API 的模型已經展示出了一些協作能力，但仍然有很大的改進空間。

##### **More Text, Less Point: Towards 3D Data-Efficient Point-Language Understanding**
2408.15966v1 by Yuan Tang, Xu Han, Xianzhi Li, Qiao Yu, Jinfeng Xu, Yixue Hao, Long Hu, Min Chen

Enabling Large Language Models (LLMs) to comprehend the 3D physical world
remains a significant challenge. Due to the lack of large-scale 3D-text pair
datasets, the success of LLMs has yet to be replicated in 3D understanding. In
this paper, we rethink this issue and propose a new task: 3D Data-Efficient
Point-Language Understanding. The goal is to enable LLMs to achieve robust 3D
object understanding with minimal 3D point cloud and text data pairs. To
address this task, we introduce GreenPLM, which leverages more text data to
compensate for the lack of 3D data. First, inspired by using CLIP to align
images and text, we utilize a pre-trained point cloud-text encoder to map the
3D point cloud space to the text space. This mapping leaves us to seamlessly
connect the text space with LLMs. Once the point-text-LLM connection is
established, we further enhance text-LLM alignment by expanding the
intermediate text space, thereby reducing the reliance on 3D point cloud data.
Specifically, we generate 6M free-text descriptions of 3D objects, and design a
three-stage training strategy to help LLMs better explore the intrinsic
connections between different modalities. To achieve efficient modality
alignment, we design a zero-parameter cross-attention module for token pooling.
Extensive experimental results show that GreenPLM requires only 12% of the 3D
training data used by existing state-of-the-art models to achieve superior 3D
understanding. Remarkably, GreenPLM also achieves competitive performance using
text-only data. The code and weights are available at:
https://github.com/TangYuan96/GreenPLM.

摘要：<paragraph>讓大型語言模型 (LLM) 理解 3D 物理世界仍然是一項重大挑戰。由於缺乏大規模的 3D-文字對資料集，LLM 的成功尚未在 3D 理解中複製。在本文中，我們重新思考這個問題並提出一個新任務：3D 資料有效點語言理解。目標是讓 LLM 能夠在最少的 3D 點雲和文字資料對的情況下實現穩健的 3D 物件理解。為了解決這個任務，我們引入了 GreenPLM，它利用更多文字資料來彌補 3D 資料的不足。首先，受使用 CLIP 將影像和文字對齊的啟發，我們利用預先訓練好的點雲文字編碼器將 3D 點雲空間映射到文字空間。這個對應讓我們可以無縫地將文字空間與 LLM 連接起來。一旦建立了點文字 LLM 連接，我們進一步透過擴展中間文字空間來增強文字 LLM 對齊，從而減少對 3D 點雲資料的依賴。具體來說，我們生成了 600 萬個 3D 物件的自由文字描述，並設計了一個三階段訓練策略來幫助 LLM 更深入地探索不同模態之間的內在聯繫。為了實現有效的模態對齊，我們設計了一個零參數跨注意力模組進行代碼池化。大量的實驗結果顯示，GreenPLM 只需要現有最先進模型所使用 3D 訓練資料的 12%，就能實現優異的 3D 理解。值得注意的是，GreenPLM 還使用純文字資料達到了有競爭力的效能。程式碼和權重可在以下網址取得：https://github.com/TangYuan96/GreenPLM。</paragraph>

##### **Atari-GPT: Investigating the Capabilities of Multimodal Large Language Models as Low-Level Policies for Atari Games**
2408.15950v1 by Nicholas R. Waytowich, Devin White, MD Sunbeam, Vinicius G. Goecks

Recent advancements in large language models (LLMs) have expanded their
capabilities beyond traditional text-based tasks to multimodal domains,
integrating visual, auditory, and textual data. While multimodal LLMs have been
extensively explored for high-level planning in domains like robotics and
games, their potential as low-level controllers remains largely untapped. This
paper explores the application of multimodal LLMs as low-level controllers in
the domain of Atari video games, introducing Atari game performance as a new
benchmark for evaluating the ability of multimodal LLMs to perform low-level
control tasks. Unlike traditional reinforcement learning (RL) and imitation
learning (IL) methods that require extensive computational resources as well as
reward function specification, these LLMs utilize pre-existing multimodal
knowledge to directly engage with game environments. Our study assesses
multiple multimodal LLMs performance against traditional RL agents, human
players, and random agents, focusing on their ability to understand and
interact with complex visual scenes and formulate strategic responses.
Additionally, we examine the impact of In-Context Learning (ICL) by
incorporating human-demonstrated game-play trajectories to enhance the models
contextual understanding. Through this investigation, we aim to determine the
extent to which multimodal LLMs can leverage their extensive training to
effectively function as low-level controllers, thereby redefining potential
applications in dynamic and visually complex environments. Additional results
and videos are available at our project webpage:
https://sites.google.com/view/atari-gpt/.

摘要：大型語言模型 (LLM) 的最新進展已將其功能從傳統的基於文本任務擴展到多模態領域，整合了視覺、聽覺和文本數據。雖然多模態 LLM 已被廣泛探索用於機器人和遊戲等領域的高階規劃，但它們作為低階控制器仍有很大的潛力尚未開發。本文探討了多模態 LLM 在 Atari 視頻遊戲領域中作為低階控制器的應用，引入了 Atari 遊戲效能作為評估多模態 LLM 執行低階控制任務能力的新基準。與需要大量計算資源和獎勵功能規範的傳統強化學習 (RL) 和模仿學習 (IL) 方法不同，這些 LLM 利用預先存在的多模態知識直接與遊戲環境互動。我們的研究評估了多個多模態 LLM 的效能，並針對傳統 RL 代理、人類玩家和隨機代理進行比較，重點關注它們理解和與複雜視覺場景互動並制定策略反應的能力。此外，我們透過納入人類展示的遊戲軌跡來增強模型的上下文理解，檢視情境學習 (ICL) 的影響。透過這項調查，我們旨在確定多模態 LLM 在多大程度上可以利用其廣泛的訓練來有效地作為低階控制器，從而重新定義在動態和視覺複雜環境中的潛在應用。其他結果和影片可在我們的專案網頁中取得：
https://sites.google.com/view/atari-gpt/。

##### **Local Descriptors Weighted Adaptive Threshold Filtering For Few-Shot Learning**
2408.15924v1 by Bingchen Yan

Few-shot image classification is a challenging task in the field of machine
learning, involving the identification of new categories using a limited number
of labeled samples. In recent years, methods based on local descriptors have
made significant progress in this area. However, the key to improving
classification accuracy lies in effectively filtering background noise and
accurately selecting critical local descriptors highly relevant to image
category information.
  To address this challenge, we propose an innovative weighted adaptive
threshold filtering (WATF) strategy for local descriptors. This strategy can
dynamically adjust based on the current task and image context, thereby
selecting local descriptors most relevant to the image category. This enables
the model to better focus on category-related information while effectively
mitigating interference from irrelevant background regions.
  To evaluate the effectiveness of our method, we adopted the N-way K-shot
experimental framework. Experimental results show that our method not only
improves the clustering effect of selected local descriptors but also
significantly enhances the discriminative ability between image categories.
Notably, our method maintains a simple and lightweight design philosophy
without introducing additional learnable parameters. This feature ensures
consistency in filtering capability during both training and testing phases,
further enhancing the reliability and practicality of the method.

摘要：小样本图像分类是机器学习领域的一项具有挑战性的任务，涉及使用有限数量的标记样本识别新类别。近年来，基于局部描述符的方法在这个领域取得了重大进展。然而，提高分类精度的关键在于有效地过滤背景噪声，并准确地选择与图像类别信息高度相关的关键局部描述符。
为了解决这一挑战，我们提出了一种针对局部描述符的创新加权自适应阈值过滤（WATF）策略。该策略可以根据当前任务和图像上下文动态调整，从而选择与图像类别最相关的局部描述符。这使模型能够更好地关注与类别相关的信息，同时有效地减轻无关背景区域的干扰。
为了评估我们方法的有效性，我们采用了 N 路 K 镜头实验框架。实验结果表明，我们的方法不仅提高了所选局部描述符的聚类效果，而且还显着增强了图像类别之间的判别能力。值得注意的是，我们的方法保持了简单轻量的设计理念，没有引入额外的可学习参数。此功能确保了在训练和测试阶段过滤能力的一致性，进一步增强了该方法的可靠性和实用性。

##### **Leveraging Open Knowledge for Advancing Task Expertise in Large Language Models**
2408.15915v1 by Yuncheng Yang, Yulei Qin, Tong Wu, Zihan Xu, Gang Li, Pengcheng Guo, Hang Shao, Yucheng Shi, Ke Li, Xing Sun, Jie Yang, Yun Gu

The cultivation of expertise for large language models (LLMs) to solve tasks
of specific areas often requires special-purpose tuning with calibrated
behaviors on the expected stable outputs. To avoid huge cost brought by manual
preparation of instruction datasets and training resources up to hundreds of
hours, the exploitation of open knowledge including a wealth of low rank
adaptation (LoRA) models and instruction datasets serves as a good starting
point. However, existing methods on model and data selection focus on the
performance of general-purpose capabilities while neglecting the knowledge gap
exposed in domain-specific deployment. In the present study, we propose to
bridge such gap by introducing few human-annotated samples (i.e., K-shot) for
advancing task expertise of LLMs with open knowledge. Specifically, we develop
an efficient and scalable pipeline to cost-efficiently produce task experts
where K-shot data intervene in selecting the most promising expert candidates
and the task-relevant instructions. A mixture-of-expert (MoE) system is built
to make the best use of individual-yet-complementary knowledge between multiple
experts. We unveil the two keys to the success of a MoE system, 1) the abidance
by K-shot, and 2) the insistence on diversity. For the former, we ensure that
models that truly possess problem-solving abilities on K-shot are selected
rather than those blind guessers. Besides, during data selection, instructions
that share task-relevant contexts with K-shot are prioritized. For the latter,
we highlight the diversity of constituting experts and that of the fine-tuning
instructions throughout the model and data selection process. Extensive
experimental results confirm the superiority of our approach over existing
methods on utilization of open knowledge across various tasks. Codes and models
will be released later.

摘要：<paragraph>為了解決特定領域的任務，培養大型語言模型 (LLM) 的專業知識通常需要透過針對預期穩定輸出進行校準行為的特殊用途微調。為了避免手動準備指令資料集和訓練資源長達數百小時所帶來的龐大成本，利用開放知識（包括大量的低秩適應 (LoRA) 模型和指令資料集）作為一個良好的起點。然而，現有關於模型和資料選擇的方法著重於通用功能的效能，同時忽略了特定領域部署中暴露的知識差距。在本研究中，我們提出透過引入少量的經由人類註解的樣本（即，K-shot）來彌補此差距，藉此提升 LLM 的任務專業知識，並運用開放知識。具體來說，我們開發了一個高效且可擴充的管線，以經濟有效的方式產生任務專家，其中 K-shot 資料介入以選出最有希望的專家候選人和與任務相關的指令。建立一個混合專家 (MoE) 系統，以最佳利用多個專家之間個別且互補的知識。我們揭示了 MoE 系統成功的兩個關鍵：1) 遵守 K-shot，以及 2) 堅持多元性。對於前者，我們確保選擇真正具備 K-shot 問題解決能力的模型，而不是那些盲目猜測的模型。此外，在資料選擇期間，會優先考慮與 K-shot 共享與任務相關脈絡的指令。對於後者，我們強調構成專家的多元性，以及在模型和資料選擇過程中微調指令的多元性。廣泛的實驗結果證實了我們的方法在各種任務中利用開放知識的優越性，優於現有方法。程式碼和模型將稍後釋出。</paragraph>

##### **LLM-Based Multi-Hop Question Answering with Knowledge Graph Integration in Evolving Environments**
2408.15903v1 by Ruirui Chen, Weifeng Jiang, Chengwei Qin, Ishaan Singh Rawal, Cheston Tan, Dongkyu Choi, Bo Xiong, Bo Ai

The rapid obsolescence of information in Large Language Models (LLMs) has
driven the development of various techniques to incorporate new facts. However,
existing methods for knowledge editing still face difficulties with multi-hop
questions that require accurate fact identification and sequential logical
reasoning, particularly among numerous fact updates. To tackle these
challenges, this paper introduces Graph Memory-based Editing for Large Language
Models (GMeLLo), a straitforward and effective method that merges the explicit
knowledge representation of Knowledge Graphs (KGs) with the linguistic
flexibility of LLMs. Beyond merely leveraging LLMs for question answering,
GMeLLo employs these models to convert free-form language into structured
queries and fact triples, facilitating seamless interaction with KGs for rapid
updates and precise multi-hop reasoning. Our results show that GMeLLo
significantly surpasses current state-of-the-art knowledge editing methods in
the multi-hop question answering benchmark, MQuAKE, especially in scenarios
with extensive knowledge edits.

摘要：大型語言模型 (LLM) 中資訊快速過時，促使各種技術發展以納入新事實。然而，現有的知識編輯方法在需要準確事實辨識和順序邏輯推理的多跳問題上仍面臨困難，特別是在眾多事實更新中。為了應對這些挑戰，本文介紹了大型語言模型的圖記憶編輯 (GMeLLo)，這是一種直接且有效的方法，結合了知識圖譜 (KG) 的明確知識表示與 LLM 的語言靈活性。GMeLLo 不僅利用 LLM 來回答問題，還使用這些模型將自由形式的語言轉換為結構化查詢和事實三元組，促進與 KG 的無縫互動，以便快速更新和精確的多跳推理。我們的結果表明，在多跳問題回答基準 MQuAKE 中，GMeLLo 明顯超越了當前最先進的知識編輯方法，特別是在廣泛知識編輯的場景中。

##### **Nexus: Specialization meets Adaptability for Efficiently Training Mixture of Experts**
2408.15901v1 by Nikolas Gritsch, Qizhen Zhang, Acyr Locatelli, Sara Hooker, Ahmet Üstün

Efficiency, specialization, and adaptability to new data distributions are
qualities that are hard to combine in current Large Language Models. The
Mixture of Experts (MoE) architecture has been the focus of significant
research because its inherent conditional computation enables such desirable
properties. In this work, we focus on "upcycling" dense expert models into an
MoE, aiming to improve specialization while also adding the ability to adapt to
new tasks easily. We introduce Nexus, an enhanced MoE architecture with
adaptive routing where the model learns to project expert embeddings from
domain representations. This approach allows Nexus to flexibly add new experts
after the initial upcycling through separately trained dense models, without
requiring large-scale MoE training for unseen data domains. Our experiments
show that Nexus achieves a relative gain of up to 2.1% over the baseline for
initial upcycling, and a 18.8% relative gain for extending the MoE with a new
expert by using limited finetuning data. This flexibility of Nexus is crucial
to enable an open-source ecosystem where every user continuously assembles
their own MoE-mix according to their needs.

摘要：效率、專精度以及適應新資料分佈是當前大型語言模型中難以結合的品質。專家混合 (MoE) 架構一直是重要的研究重點，因為其內在的條件式運算可實現這些理想的特性。在這項研究中，我們專注於將密集的專家模型「升級」至 MoE，目標是改善專精度的同時，也能輕鬆地加入適應新任務的能力。我們引入了 Nexus，一種具備自適應路由的增強式 MoE 架構，其中模型學習從網域表示中投射專家嵌入。這種方法讓 Nexus 能夠在最初的升級後，透過個別訓練的密集模型靈活地加入新的專家，而無需針對未見的資料網域進行大規模的 MoE 訓練。我們的實驗顯示，Nexus 在最初的升級中取得了比基準高達 2.1% 的相對增益，以及透過使用有限的微調資料來擴充 MoE 的新專家時，取得了 18.8% 的相對增益。Nexus 的這種靈活性對於建立一個開放原始碼生態系統至關重要，讓每個使用者都能根據自己的需求持續組裝自己的 MoE 組合。

##### **Airfoil Diffusion: Denoising Diffusion Model For Conditional Airfoil Generation**
2408.15898v1 by Reid Graves, Amir Barati Farimani

The design of aerodynamic shapes, such as airfoils, has traditionally
required significant computational resources and relied on predefined design
parameters, which limit the potential for novel shape synthesis. In this work,
we introduce a data-driven methodology for airfoil generation using a diffusion
model. Trained on a dataset of preexisting airfoils, our model can generate an
arbitrary number of new airfoils from random vectors, which can be conditioned
on specific aerodynamic performance metrics such as lift and drag, or geometric
criteria. Our results demonstrate that the diffusion model effectively produces
airfoil shapes with realistic aerodynamic properties, offering substantial
improvements in efficiency, flexibility, and the potential for discovering
innovative airfoil designs. This approach significantly expands the design
space, facilitating the synthesis of high-performance aerodynamic shapes that
transcend the limitations of traditional methods.

摘要：空氣動力形狀，例如機翼的設計，傳統上需要大量的計算資源，並依賴於預先定義的設計參數，這限制了新形狀合成的可能性。在這項工作中，我們引入了一種使用擴散模型進行翼型的資料驅動方法。根據現有翼型的資料集進行訓練，我們的模型可以從隨機向量中產生任意數量的新的翼型，這些向量可以根據特定的空氣動力效能指標（例如升力和阻力）或幾何標準進行調整。我們的結果表明，擴散模型有效地產生具有實際空氣動力特性的翼型形狀，在效率、靈活性以及發現創新的翼型設計的潛力方面提供了顯著的改進。這種方法顯著擴展了設計空間，促進了超越傳統方法限制的高效能空氣動力形狀的合成。

##### **A New Method for Cross-Lingual-based Semantic Role Labeling**
2408.15896v1 by Mohammad Ebrahimi, Behrouz Minaei Bidgoli, Nasim Khozouei

Semantic role labeling is a crucial task in natural language processing,
enabling better comprehension of natural language. However, the lack of
annotated data in multiple languages has posed a challenge for researchers. To
address this, a deep learning algorithm based on model transfer has been
proposed. The algorithm utilizes a dataset consisting of the English portion of
CoNLL2009 and a corpus of semantic roles in Persian. To optimize the efficiency
of training, only ten percent of the educational data from each language is
used. The results of the proposed model demonstrate significant improvements
compared to Niksirt et al.'s model. In monolingual mode, the proposed model
achieved a 2.05 percent improvement on F1-score, while in cross-lingual mode,
the improvement was even more substantial, reaching 6.23 percent. Worth noting
is that the compared model only trained two of the four stages of semantic role
labeling and employed golden data for the remaining two stages. This suggests
that the actual superiority of the proposed model surpasses the reported
numbers by a significant margin. The development of cross-lingual methods for
semantic role labeling holds promise, particularly in addressing the scarcity
of annotated data for various languages. These advancements pave the way for
further research in understanding and processing natural language across
different linguistic contexts.

摘要：語意角色標籤是自然語言處理中的一項重要任務，
能讓電腦更好地理解自然語言。然而，多語種標註資料的缺乏對研究人員來說是一個挑戰。為了解決這個問題，有人提出了一種基於模型轉移的深度學習演算法。該演算法利用了一個由 CoNLL2009 的英文部分和波斯語語意角色語料庫組成的資料集。為了優化訓練效率，只使用了每種語言中 10% 的教育資料。所提出的模型的結果顯示出與 Niksirt 等人的模型相比有顯著的改進。在單語模式下，所提出的模型在 F1 分數上提高了 2.05%，而在跨語言模式下，改進幅度更大，達到 6.23%。值得注意的是，所比較模型只訓練了語意角色標籤的四個階段中的兩個階段，並在剩下的兩個階段中使用了金資料。這表明所提出的模型的實際優越性比報告的數字高出很多。跨語言語意角色標籤方法的發展很有前景，特別是在解決各種語言標註資料稀缺的問題上。這些進展為在不同的語言環境中理解和處理自然語言的進一步研究鋪平了道路。

##### **Bias in LLMs as Annotators: The Effect of Party Cues on Labelling Decision by Large Language Models**
2408.15895v1 by Sebastian Vallejo Vera, Hunter Driggers

Human coders are biased. We test similar biases in Large Language Models
(LLMs) as annotators. By replicating an experiment run by Ennser-Jedenastik and
Meyer (2018), we find evidence that LLMs use political information, and
specifically party cues, to judge political statements. Not only do LLMs use
relevant information to contextualize whether a statement is positive,
negative, or neutral based on the party cue, they also reflect the biases of
the human-generated data upon which they have been trained. We also find that
unlike humans, who are only biased when faced with statements from extreme
parties, LLMs exhibit significant bias even when prompted with statements from
center-left and center-right parties. The implications of our findings are
discussed in the conclusion.

摘要：人類編碼器有偏見。我們在大型語言模型 (LLM) 中測試了作為註解者的類似偏見。通過複製 Ennser-Jedenastik 和 Meyer (2018) 執行的實驗，我們發現證據表明 LLM 使用政治資訊，特別是政黨線索，來判斷政治聲明。LLM 不僅使用相關資訊根據政黨線索來判斷陳述是正面、負面還是中立，它們還反映了他們接受訓練的人類生成資料的偏見。我們還發現，與只在面對極端政黨的聲明時才會出現偏見的人類不同，即使提示來自中間偏左和中間偏右的政黨的聲明，LLM 仍會表現出顯著的偏見。我們發現的意義在結論中進行了討論。

##### **Enhancing Intrusion Detection in IoT Environments: An Advanced Ensemble Approach Using Kolmogorov-Arnold Networks**
2408.15886v2 by Amar Amouri, Mohamad Mahmoud Al Rahhal, Yakoub Bazi, Ismail Butun, Imad Mahgoub

In recent years, the evolution of machine learning techniques has
significantly impacted the field of intrusion detection, particularly within
the context of the Internet of Things (IoT). As IoT networks expand, the need
for robust security measures to counteract potential threats has become
increasingly critical. This paper introduces a hybrid Intrusion Detection
System (IDS) that synergistically combines Kolmogorov-Arnold Networks (KANs)
with the XGBoost algorithm. Our proposed IDS leverages the unique capabilities
of KANs, which utilize learnable activation functions to model complex
relationships within data, alongside the powerful ensemble learning techniques
of XGBoost, known for its high performance in classification tasks. This hybrid
approach not only enhances the detection accuracy but also improves the
interpretability of the model, making it suitable for dynamic and intricate IoT
environments. Experimental evaluations demonstrate that our hybrid IDS achieves
an impressive detection accuracy exceeding 99% in distinguishing between benign
and malicious activities. Additionally, we were able to achieve F1 scores,
precision, and recall that exceeded 98%. Furthermore, we conduct a comparative
analysis against traditional Multi-Layer Perceptron (MLP) networks, assessing
performance metrics such as Precision, Recall, and F1-score. The results
underscore the efficacy of integrating KANs with XGBoost, highlighting the
potential of this innovative approach to significantly strengthen the security
framework of IoT networks.

摘要：近年來，機器學習技術的演進對入侵偵測領域產生重大影響，特別是在物聯網 (IoT) 的脈絡中。隨著物聯網網路的擴展，對抗潛在威脅的強大安全措施的需求變得越來越關鍵。本文介紹了一種混合入侵偵測系統 (IDS)，它協同結合了 Kolmogorov-Arnold 網路 (KAN) 和 XGBoost 演算法。我們提出的 IDS 利用了 KAN 的獨特功能，它利用可學習的激活函數來模擬資料中的複雜關係，以及 XGBoost 強大的整合學習技術，XGBoost 以其在分類任務中的高性能而聞名。這種混合方法不僅增強了偵測準確性，也改善了模型的可解釋性，使其適用於動態且複雜的物聯網環境。實驗評估表明，我們的混合 IDS 在區分良性和惡意活動方面達到了令人印象深刻的 99% 以上的偵測準確度。此外，我們能夠達到超過 98% 的 F1 分數、精確度和召回率。此外，我們對傳統的多層感知器 (MLP) 網路進行了比較分析，評估了精確度、召回率和 F1 分數等效能指標。結果強調了將 KAN 與 XGBoost 整合的效能，突顯了這種創新方法在顯著強化物聯網網路安全架構方面的潛力。

##### **Persuasion Games using Large Language Models**
2408.15879v1 by Ganesh Prasath Ramani, Shirish Karande, Santhosh V, Yash Bhatia

Large Language Models (LLMs) have emerged as formidable instruments capable
of comprehending and producing human-like text. This paper explores the
potential of LLMs, to shape human perspectives and subsequently influence their
decisions on particular tasks. This capability finds applications in diverse
domains such as Investment, Credit cards and Insurance, wherein they assist
users in selecting appropriate insurance policies, investment plans, Credit
cards, Retail, as well as in Behavioral Change Support Systems (BCSS).
  We present a sophisticated multi-agent framework wherein a consortium of
agents operate in collaborative manner. The primary agent engages directly with
users through persuasive dialogue, while the auxiliary agents perform tasks
such as information retrieval, response analysis, development of persuasion
strategies, and validation of facts. Empirical evidence from our experiments
demonstrates that this collaborative methodology significantly enhances the
persuasive efficacy of the LLM. We analyze user resistance to persuasive
efforts continuously and counteract it by employing a combination of rule-based
and LLM-based resistance-persuasion mapping techniques.
  We employ simulated personas and generate conversations in insurance,
banking, and retail domains to evaluate the proficiency of large language
models (LLMs) in recognizing, adjusting to, and influencing various personality
types. Concurrently, we examine the resistance mechanisms employed by LLM
simulated personas. Persuasion is quantified via measurable surveys before and
after interaction, LLM-generated scores on conversation, and user decisions
(purchase or non-purchase).

摘要：大型語言模型 (LLM) 已成為強大的工具，能夠理解並產生類似人類的文字。本文探討了 LLM 的潛力，以塑造人類觀點，並進而影響他們對特定任務的決策。此功能可在投資、信用卡和保險等不同領域中找到應用，在這些領域中，它們協助使用者選擇適當的保險保單、投資計畫、信用卡、零售，以及行為改變支持系統 (BCSS)。
我們提出了一個複雜的多代理架構，其中一組代理以協作方式運作。主要代理透過有說服力的對話直接與使用者互動，而輔助代理則執行任務，例如資訊檢索、回應分析、說服策略的發展以及事實驗證。我們實驗的實證證據表明，這種協作方法顯著增強了 LLM 的說服力。我們持續分析使用者對說服工作的抵制，並透過結合基於規則和基於 LLM 的抗拒說服對應技術來加以應對。
我們採用模擬角色，並在保險、銀行和零售領域產生對話，以評估大型語言模型 (LLM) 在識別、調整和影響各種人格類型的熟練度。同時，我們檢查 LLM 模擬角色所採用的抵制機制。說服力透過互動前後的可衡量調查、LLM 對對話產生的分數以及使用者決策（購買或不購買）來量化。

##### **GenDDS: Generating Diverse Driving Video Scenarios with Prompt-to-Video Generative Model**
2408.15868v1 by Yongjie Fu, Yunlong Li, Xuan Di

Autonomous driving training requires a diverse range of datasets encompassing
various traffic conditions, weather scenarios, and road types. Traditional data
augmentation methods often struggle to generate datasets that represent rare
occurrences. To address this challenge, we propose GenDDS, a novel approach for
generating driving scenarios generation by leveraging the capabilities of
Stable Diffusion XL (SDXL), an advanced latent diffusion model. Our methodology
involves the use of descriptive prompts to guide the synthesis process, aimed
at producing realistic and diverse driving scenarios. With the power of the
latest computer vision techniques, such as ControlNet and Hotshot-XL, we have
built a complete pipeline for video generation together with SDXL. We employ
the KITTI dataset, which includes real-world driving videos, to train the
model. Through a series of experiments, we demonstrate that our model can
generate high-quality driving videos that closely replicate the complexity and
variability of real-world driving scenarios. This research contributes to the
development of sophisticated training data for autonomous driving systems and
opens new avenues for creating virtual environments for simulation and
validation purposes.

摘要：自動駕駛訓練需要各種各樣涵蓋各種交通狀況、天氣情境和道路類型的資料集。傳統資料擴充方法通常難以產生表示罕見事件的資料集。為了應對這個挑戰，我們提出了 GenDDS，這是一種透過利用先進潛在擴散模型 Stable Diffusion XL (SDXL) 的功能來產生駕駛場景生成的新方法。我們的做法涉及使用描述性提示來引導合成過程，目的是產生逼真且多樣化的駕駛場景。透過運用最新的電腦視覺技術，例如 ControlNet 和 Hotshot-XL，我們已經建立了一個完整的影片生成管道與 SDXL。我們採用包含真實世界駕駛影片的 KITTI 資料集來訓練模型。透過一系列實驗，我們證明我們的模型可以產生高品質的駕駛影片，這些影片可以緊密複製真實世界駕駛場景的複雜性和可變性。這項研究有助於開發用於自動駕駛系統的精密訓練資料，並為建立用於模擬和驗證目的的虛擬環境開啟新的途徑。

##### **Retrieval-Augmented Instruction Tuning for Automated Process Engineering Calculations : A Tool-Chaining Problem-Solving Framework with Attributable Reflection**
2408.15866v1 by Sagar Srinivas Sakhinana, Geethan Sannidhi, Venkataramana Runkana

The current technology landscape lacks a foundational AI model for solving
process engineering calculations. In this work, we introduce a novel autonomous
agent framework leveraging Retrieval-Augmented Instruction-Tuning (RAIT) to
enhance open, customizable small code language models (SLMs) for these
calculations. By combining instruction tuned code SLMs with Retrieval-Augmented
Code Generation (RACG) using external tools, the agent generates, debugs, and
optimizes code from natural language specifications. Our approach addresses the
limitations of the current lack of a foundational AI model for specialized
process engineering tasks and offers benefits of explainability, knowledge
editing, and cost-effectiveness. Additionally, we curate custom datasets of
chemical and process engineering problems and solutions to overcome data
scarcity. Experimental results show that our framework matches the performance
of large-scale proprietary models on benchmark datasets, proving its
effectiveness and usability.

摘要：當前的技術領域缺乏一個基礎 AI 模型來解決製程工程計算。在此工作中，我們介紹一個新穎的自主代理架構，利用檢索增強指令調整 (RAIT) 來增強開放且可自訂的小型程式碼語言模型 (SLM)，以進行這些計算。透過結合指令調整程式碼 SLM 與使用外部工具的檢索增強程式碼產生 (RACG)，代理會根據自然語言規格產生、除錯和最佳化程式碼。我們的做法解決了當前缺乏基礎 AI 模型來執行專業製程工程任務的限制，並提供可解釋性、知識編輯和成本效益的優點。此外，我們策劃化學和製程工程問題與解決方案的客製化資料集，以克服資料稀少的問題。實驗結果顯示，我們的架構在基準資料集上與大型專有模型的效能相符，證明了其有效性和可用性。

##### **Knowledge Navigator: LLM-guided Browsing Framework for Exploratory Search in Scientific Literature**
2408.15836v1 by Uri Katz, Mosh Levy, Yoav Goldberg

The exponential growth of scientific literature necessitates advanced tools
for effective knowledge exploration. We present Knowledge Navigator, a system
designed to enhance exploratory search abilities by organizing and structuring
the retrieved documents from broad topical queries into a navigable, two-level
hierarchy of named and descriptive scientific topics and subtopics. This
structured organization provides an overall view of the research themes in a
domain, while also enabling iterative search and deeper knowledge discovery
within specific subtopics by allowing users to refine their focus and retrieve
additional relevant documents. Knowledge Navigator combines LLM capabilities
with cluster-based methods to enable an effective browsing method. We
demonstrate our approach's effectiveness through automatic and manual
evaluations on two novel benchmarks, CLUSTREC-COVID and SCITOC. Our code,
prompts, and benchmarks are made publicly available.

摘要：科學文獻的指數成長需要進階工具，以有效探索知識。我們提出知識導航器，一個系統，旨在透過將從廣泛主題查詢中擷取的文件組織和建構到可導航的兩層級命名和描述性科學主題和子主題中，來增強探索性搜尋能力。此結構化組織提供特定領域研究主題的整體概觀，同時也透過讓使用者精煉其焦點和擷取額外的相關文件，在特定子主題中啟用反覆搜尋和更深入的知識發現。知識導航器結合 LLM 能力和基於群集的方法，以啟用有效的瀏覽方法。我們透過在兩個新基準 CLUSTREC-COVID 和 SCITOC 上進行自動和手動評估，來證明我們方法的有效性。我們的程式碼、提示和基準已公開提供。

##### **Automatic Differential Diagnosis using Transformer-Based Multi-Label Sequence Classification**
2408.15827v1 by Abu Adnan Sadi, Mohammad Ashrafuzzaman Khan, Lubaba Binte Saber

As the field of artificial intelligence progresses, assistive technologies
are becoming more widely used across all industries. The healthcare industry is
no different, with numerous studies being done to develop assistive tools for
healthcare professionals. Automatic diagnostic systems are one such beneficial
tool that can assist with a variety of tasks, including collecting patient
information, analyzing test results, and diagnosing patients. However, the idea
of developing systems that can provide a differential diagnosis has been
largely overlooked in most of these research studies. In this study, we propose
a transformer-based approach for providing differential diagnoses based on a
patient's age, sex, medical history, and symptoms. We use the DDXPlus dataset,
which provides differential diagnosis information for patients based on 49
disease types. Firstly, we propose a method to process the tabular patient data
from the dataset and engineer them into patient reports to make them suitable
for our research. In addition, we introduce two data modification modules to
diversify the training data and consequently improve the robustness of the
models. We approach the task as a multi-label classification problem and
conduct extensive experiments using four transformer models. All the models
displayed promising results by achieving over 97% F1 score on the held-out test
set. Moreover, we design additional behavioral tests to get a broader
understanding of the models. In particular, for one of our test cases, we
prepared a custom test set of 100 samples with the assistance of a doctor. The
results on the custom set showed that our proposed data modification modules
improved the model's generalization capabilities. We hope our findings will
provide future researchers with valuable insights and inspire them to develop
reliable systems for automatic differential diagnosis.

摘要：隨著人工智慧領域的進展，輔助技術在各行各業的應用日益廣泛。醫療保健產業也不例外，有許多研究致力於為醫療保健專業人員開發輔助工具。自動診斷系統就是一種有益的工具，可以協助執行各種任務，包括收集患者資訊、分析檢驗結果和診斷患者。然而，在這些研究中，開發可提供鑑別診斷的系統的想法在很大程度上被忽視了。在本研究中，我們提出了一種基於 Transformer 的方法，根據患者的年齡、性別、病史和症狀提供鑑別診斷。我們使用 DDXPlus 資料集，該資料集根據 49 種疾病類型提供患者的鑑別診斷資訊。首先，我們提出了一種方法來處理資料集中的表格患者資料，並將其設計成患者報告，使其適合我們的研究。此外，我們引入了兩個資料修改模組，以使訓練資料多樣化，進而提高模型的穩健性。我們將此任務視為多標籤分類問題，並使用四個 Transformer 模型進行廣泛的實驗。所有模型在保留的測試集中都達到了 97% 以上的 F1 分數，表現出令人滿意的結果。此外，我們設計了額外的行為測試，以更廣泛地了解這些模型。特別是，對於我們的其中一個測試案例，我們在一位醫生的協助下準備了一個包含 100 個樣本的客製化測試集。客製化集上的結果顯示，我們提出的資料修改模組改善了模型的泛化能力。我們希望我們的發現能為未來的研究人員提供有價值的見解，並激勵他們開發可靠的自動鑑別診斷系統。

##### **Object Detection for Vehicle Dashcams using Transformers**
2408.15809v1 by Osama Mustafa, Khizer Ali, Anam Bibi, Imran Siddiqi, Momina Moetesum

The use of intelligent automation is growing significantly in the automotive
industry, as it assists drivers and fleet management companies, thus increasing
their productivity. Dash cams are now been used for this purpose which enables
the instant identification and understanding of multiple objects and
occurrences in the surroundings. In this paper, we propose a novel approach for
object detection in dashcams using transformers. Our system is based on the
state-of-the-art DEtection TRansformer (DETR), which has demonstrated strong
performance in a variety of conditions, including different weather and
illumination scenarios. The use of transformers allows for the consideration of
contextual information in decisionmaking, improving the accuracy of object
detection. To validate our approach, we have trained our DETR model on a
dataset that represents real-world conditions. Our results show that the use of
intelligent automation through transformers can significantly enhance the
capabilities of dashcam systems. The model achieves an mAP of 0.95 on
detection.

摘要：智能自動化在汽車產業中正大幅成長，因為它能協助駕駛和車隊管理公司，進而提升他們的生產力。行車記錄器現在被用於此目的，能立即辨識並理解周遭的各種物體和事件。在本文中，我們提出了一個使用Transformer在行車記錄器中進行物體偵測的新穎方法。我們的系統是基於最先進的檢測Transformer (DETR)，它已在各種條件下展現強大的效能，包括不同的天氣和光照場景。Transformer的使用允許在決策中考量脈絡資訊，進而提升物體偵測的準確度。為了驗證我們的做法，我們已在一個代表真實世界條件的資料集上訓練我們的 DETR 模型。我們的結果顯示，使用Transformer進行的智能自動化能大幅提升行車記錄器系統的能力。該模型在偵測上達到 0.95 的 mAP。

##### **ModalityMirror: Improving Audio Classification in Modality Heterogeneity Federated Learning with Multimodal Distillation**
2408.15803v1 by Tiantian Feng, Tuo Zhang, Salman Avestimehr, Shrikanth S. Narayanan

Multimodal Federated Learning frequently encounters challenges of client
modality heterogeneity, leading to undesired performances for secondary
modality in multimodal learning. It is particularly prevalent in audiovisual
learning, with audio is often assumed to be the weaker modality in recognition
tasks. To address this challenge, we introduce ModalityMirror to improve audio
model performance by leveraging knowledge distillation from an audiovisual
federated learning model. ModalityMirror involves two phases: a modality-wise
FL stage to aggregate uni-modal encoders; and a federated knowledge
distillation stage on multi-modality clients to train an unimodal student
model. Our results demonstrate that ModalityMirror significantly improves the
audio classification compared to the state-of-the-art FL methods such as
Harmony, particularly in audiovisual FL facing video missing. Our approach
unlocks the potential for exploiting the diverse modality spectrum inherent in
multi-modal FL.

摘要：多模态联邦学习经常遇到客户端模态异质性的挑战，导致多模态学习中次要模态的性能不佳。这在视听学习中尤为普遍，音频通常被认为是识别任务中较弱的模态。为了应对这一挑战，我们引入了 ModalityMirror，通过利用来自视听联邦学习模型的知识蒸馏来提高音频模型性能。ModalityMirror 涉及两个阶段：一个模态明智的 FL 阶段来聚合单模态编码器；以及一个在多模态客户端上进行联邦知识蒸馏的阶段，以训练单模态学生模型。我们的结果表明，与 Harmony 等最先进的 FL 方法相比，ModalityMirror 显着改进了音频分类，尤其是在面对视频缺失的视听 FL 中。我们的方法释放了利用多模态 FL 中固有的多样化模态频谱的潜力。

##### **Scaling Up Summarization: Leveraging Large Language Models for Long Text Extractive Summarization**
2408.15801v1 by Léo Hemamou, Mehdi Debiane

In an era where digital text is proliferating at an unprecedented rate,
efficient summarization tools are becoming indispensable. While Large Language
Models (LLMs) have been successfully applied in various NLP tasks, their role
in extractive text summarization remains underexplored. This paper introduces
EYEGLAXS (Easy Yet Efficient larGe LAnguage model for eXtractive
Summarization), a framework that leverages LLMs, specifically LLAMA2-7B and
ChatGLM2-6B, for extractive summarization of lengthy text documents. Instead of
abstractive methods, which often suffer from issues like factual inaccuracies
and hallucinations, EYEGLAXS focuses on extractive summarization to ensure
factual and grammatical integrity. Utilizing state-of-the-art techniques such
as Flash Attention and Parameter-Efficient Fine-Tuning (PEFT), EYEGLAXS
addresses the computational and resource challenges typically associated with
LLMs. The system sets new performance benchmarks on well-known datasets like
PubMed and ArXiv. Furthermore, we extend our research through additional
analyses that explore the adaptability of LLMs in handling different sequence
lengths and their efficiency in training on smaller datasets. These
contributions not only set a new standard in the field but also open up
promising avenues for future research in extractive text summarization.

摘要：在數位文字以空前速度激增的時代，高效的摘要工具正變得不可或缺。儘管大型語言模型 (LLM) 已成功應用於各種自然語言處理任務中，但它們在萃取式文字摘要中的角色仍未得到充分探討。本文介紹 EYEGLAXS（用於萃取式摘要的簡易高效大型語言模型），一個利用 LLM（特別是 LLAMA2-7B 和 ChatGLM2-6B）的架構，針對冗長的文字文件進行萃取式摘要。EYEGLAXS 專注於萃取式摘要，以確保事實和語法的完整性，而非抽象方法，後者通常會出現事實不正確和幻覺等問題。EYEGLAXS 利用了最先進的技術，例如 Flash Attention 和參數高效微調 (PEFT)，解決了通常與 LLM 相關的運算和資源挑戰。該系統在 PubMed 和 ArXiv 等知名資料集上設定了新的效能基準。此外，我們透過額外的分析擴展了我們的研究，探討 LLM 在處理不同序列長度時的適應性，以及它們在較小資料集上訓練的效率。這些貢獻不僅為該領域樹立了新的標準，也為萃取式文字摘要的未來研究開闢了有前景的途徑。

##### **Emulating Brain-like Rapid Learning in Neuromorphic Edge Computing**
2408.15800v1 by Kenneth Stewart, Michael Neumeier, Sumit Bam Shrestha, Garrick Orchard, Emre Neftci

Achieving personalized intelligence at the edge with real-time learning
capabilities holds enormous promise in enhancing our daily experiences and
helping decision making, planning, and sensing. However, efficient and reliable
edge learning remains difficult with current technology due to the lack of
personalized data, insufficient hardware capabilities, and inherent challenges
posed by online learning.
  Over time and across multiple developmental stages, the brain has evolved to
efficiently incorporate new knowledge by gradually building on previous
knowledge. In this work, we emulate the multiple stages of learning with
digital neuromorphic technology that simulates the neural and synaptic
processes of the brain using two stages of learning. First, a meta-training
stage trains the hyperparameters of synaptic plasticity for one-shot learning
using a differentiable simulation of the neuromorphic hardware. This
meta-training process refines a hardware local three-factor synaptic plasticity
rule and its associated hyperparameters to align with the trained task domain.
In a subsequent deployment stage, these optimized hyperparameters enable fast,
data-efficient, and accurate learning of new classes. We demonstrate our
approach using event-driven vision sensor data and the Intel Loihi neuromorphic
processor with its plasticity dynamics, achieving real-time one-shot learning
of new classes that is vastly improved over transfer learning. Our methodology
can be deployed with arbitrary plasticity models and can be applied to
situations demanding quick learning and adaptation at the edge, such as
navigating unfamiliar environments or learning unexpected categories of data
through user engagement.

摘要：透過即時學習能力在邊緣實現個人化智能，在提升我們的日常體驗以及協助決策制定、規劃和感測方面極具前景。然而，由於缺乏個人化資料、硬體功能不足以及線上學習所帶來的固有挑戰，使得使用現有技術進行有效且可靠的邊緣學習仍然困難。
隨著時間推移和經歷多個發展階段，大腦已演化為能有效整合新知識，並逐漸建立在先前知識的基礎上。在這項工作中，我們模擬學習的多個階段，使用數位神經型態技術，利用兩個學習階段模擬大腦的神經和突觸過程。首先，元訓練階段使用神經型態硬體的可微分模擬，針對一次性學習訓練突觸可塑性的超參數。這個元訓練過程精進了硬體局部三因子突觸可塑性規則及其相關超參數，以與訓練後的任務領域相符。在後續的部署階段，這些最佳化的超參數能快速、資料有效且準確地學習新類別。我們使用事件驅動的視覺感測器資料和 Intel Loihi 神經型態處理器及其可塑性動態，展示了我們的做法，在一次性學習新類別方面大幅優於遷移學習，達到了即時性。我們的做法可以用於任意可塑性模型，並可應用於需要在邊緣進行快速學習和適應的情況，例如導航不熟悉的環境，或透過使用者參與學習資料的意外類別。

##### **Evaluating Named Entity Recognition Using Few-Shot Prompting with Large Language Models**
2408.15796v1 by Hédi Zhegidi, Ludovic Moncla

This paper evaluates Few-Shot Prompting with Large Language Models for Named
Entity Recognition (NER). Traditional NER systems rely on extensive labeled
datasets, which are costly and time-consuming to obtain. Few-Shot Prompting or
in-context learning enables models to recognize entities with minimal examples.
We assess state-of-the-art models like GPT-4 in NER tasks, comparing their
few-shot performance to fully supervised benchmarks. Results show that while
there is a performance gap, large models excel in adapting to new entity types
and domains with very limited data. We also explore the effects of prompt
engineering, guided output format and context length on performance. This study
underscores Few-Shot Learning's potential to reduce the need for large labeled
datasets, enhancing NER scalability and accessibility.

摘要：本文評估了使用大型語言模型進行命名實體辨識 (NER) 的少樣本提示。傳統的 NER 系統依賴於廣泛標記的資料集，而這些資料集的取得既昂貴又費時。少樣本提示或情境學習讓模型能夠以最少範例辨識實體。我們評估了 GPT-4 等最先進的模型在 NER 任務中的表現，並將它們的少樣本表現與完全監督的基準進行比較。結果顯示，儘管存在效能差距，但大型模型在適應極少資料的新實體類型和領域方面表現出色。我們還探討了提示工程、引導輸出格式和情境長度對效能的影響。這項研究強調了少樣本學習在減少對大型標記資料集需求的潛力，並增強了 NER 的可擴充性和可及性。

##### **Language Adaptation on a Tight Academic Compute Budget: Tokenizer Swapping Works and Pure bfloat16 Is Enough**
2408.15793v1 by Konstantin Dobler, Gerard de Melo

We investigate continued pretraining of LLMs for language adaptation on a
tight academic budget: a setting in which only a few GPUs can be used in
parallel, for a heavily constrained duration. We focus on adapting Mistral-7B
to German or Arabic and evaluate several techniques to improve efficiency and
effectiveness in this setting. Our German models adapted on this tight compute
budget underperform compared to the base Mistral-7B, while our Arabic models
outperform several baselines, showing that for sufficiently well-represented
languages, continued pretraining for specialization is not always helpful. Our
main findings focus on training precision and tokenizer swapping. Our results
show that pure bfloat16 training is a viable alternative to mixed-precision
training, while being much faster when only using a few GPUs. Swapping the
tokenizer for a specialized one yields more efficient tokenization and is
competitive with the original tokenizer, which already contains some German
tokens, but did not significantly increase performance for German. Code and
model weights are available at on GitHub.

摘要：我們研究了在嚴格的學術預算中，持續預訓練 LLM 以適應語言：一種只能並行使用少數 GPU，且時間受到嚴格限制的設定。我們專注於將 Mistral-7B 適應為德語或阿拉伯語，並評估了幾種技術，以提高此設定中的效率和效能。我們在嚴格的運算預算下適應的德語模型，與基礎的 Mistral-7B 相比表現不佳，而我們的阿拉伯語模型則優於幾個基準，顯示對於充分代表的語言，持續預訓練以進行專業化並非總是會有幫助。我們的重點發現集中於訓練精度和 tokenizer 交換。我們的結果顯示，純 bfloat16 訓練是混合精度訓練的可行替代方案，同時在僅使用少數 GPU 時速度快很多。將 tokenizer 交換為專門的 tokenizer 可產生更有效率的 tokenization，並且與原始 tokenizer（其中已包含一些德語 token）具有競爭力，但並未顯著提升德語的效能。程式碼和模型權重可在 GitHub 上取得。

##### **Interactive Agents: Simulating Counselor-Client Psychological Counseling via Role-Playing LLM-to-LLM Interactions**
2408.15787v1 by Huachuan Qiu, Zhenzhong Lan

Virtual counselors powered by large language models (LLMs) aim to create
interactive support systems that effectively assist clients struggling with
mental health challenges. To replicate counselor-client conversations,
researchers have built an online mental health platform that allows
professional counselors to provide clients with text-based counseling services
for about an hour per session. Notwithstanding its effectiveness, challenges
exist as human annotation is time-consuming, cost-intensive, privacy-protected,
and not scalable. To address this issue and investigate the applicability of
LLMs in psychological counseling conversation simulation, we propose a
framework that employs two LLMs via role-playing for simulating
counselor-client interactions. Our framework involves two LLMs, one acting as a
client equipped with a specific and real-life user profile and the other
playing the role of an experienced counselor, generating professional responses
using integrative therapy techniques. We implement both the counselor and the
client by zero-shot prompting the GPT-4 model. In order to assess the
effectiveness of LLMs in simulating counselor-client interactions and
understand the disparities between LLM- and human-generated conversations, we
evaluate the synthetic data from various perspectives. We begin by assessing
the client's performance through automatic evaluations. Next, we analyze and
compare the disparities between dialogues generated by the LLM and those
generated by professional counselors. Furthermore, we conduct extensive
experiments to thoroughly examine the performance of our LLM-based counselor
trained with synthetic interactive dialogues by benchmarking against
state-of-the-art models for mental health.

摘要：<paragraph>由大型語言模型 (LLM) 支援的虛擬諮商師，旨在建立互動式支援系統，有效協助有心理健康問題的客戶。為了複製諮商師與客戶的對話，研究人員建立了一個線上心理健康平台，讓專業諮商師能為客戶提供約一小時的文字諮商服務。儘管有效，但仍存在挑戰，因為人工標註耗時、成本高昂、受隱私保護且無法擴展。為了解決這個問題，並探討 LLM 在心理諮商對話模擬中的適用性，我們提出了一個架構，採用兩個 LLM 透過角色扮演來模擬諮商師與客戶的互動。我們的架構包含兩個 LLM，一個扮演具備特定且真實使用者個人資料的客戶，另一個扮演經驗豐富的諮商師的角色，使用整合治療技術產生專業的回應。我們透過零次提示 GPT-4 模型來實作諮商師和客戶。為了評估 LLM 在模擬諮商師與客戶互動中的有效性，並了解 LLM 和人類產生的對話之間的差異，我們從各種角度評估合成資料。我們從評估客戶的表現透過自動評估開始。接下來，我們分析並比較 LLM 產生的對話和專業諮商師產生的對話之間的差異。此外，我們進行廣泛的實驗，透過對心理健康領域最先進的模型進行基準測試，來徹底檢查我們基於 LLM 的諮商師在經過合成互動對話訓練後的表現。</paragraph>

##### **LogicGame: Benchmarking Rule-Based Reasoning Abilities of Large Language Models**
2408.15778v1 by Jiayi Gui, Yiming Liu, Jiale Cheng, Xiaotao Gu, Xiao Liu, Hongning Wang, Yuxiao Dong, Jie Tang, Minlie Huang

Large Language Models (LLMs) have demonstrated notable capabilities across
various tasks, showcasing complex problem-solving abilities. Understanding and
executing complex rules, along with multi-step planning, are fundamental to
logical reasoning and critical for practical LLM agents and decision-making
systems. However, evaluating LLMs as effective rule-based executors and
planners remains underexplored. In this paper, we introduce LogicGame, a novel
benchmark designed to evaluate the comprehensive rule understanding, execution,
and planning capabilities of LLMs. Unlike traditional benchmarks, LogicGame
provides diverse games that contain a series of rules with an initial state,
requiring models to comprehend and apply predefined regulations to solve
problems. We create simulated scenarios in which models execute or plan
operations to achieve specific outcomes. These game scenarios are specifically
designed to distinguish logical reasoning from mere knowledge by relying
exclusively on predefined rules. This separation allows for a pure assessment
of rule-based reasoning capabilities. The evaluation considers not only final
outcomes but also intermediate steps, providing a comprehensive assessment of
model performance. Moreover, these intermediate steps are deterministic and can
be automatically verified. LogicGame defines game scenarios with varying
difficulty levels, from simple rule applications to complex reasoning chains,
in order to offer a precise evaluation of model performance on rule
understanding and multi-step execution. Utilizing LogicGame, we test various
LLMs and identify notable shortcomings in their rule-based logical reasoning
abilities.

摘要：大型語言模型 (LLM) 已在各種任務中展現出顯著的能力，展示出複雜的問題解決能力。理解和執行複雜的規則，以及多步驟規劃，是邏輯推理的基礎，對於實用的 LLM 代理和決策系統至關重要。然而，將 LLM 評估為有效的基於規則的執行者和規劃者仍未得到充分探討。在本文中，我們介紹了 LogicGame，這是一個新穎的基準，旨在評估 LLM 全面的規則理解、執行和規劃能力。與傳統基準不同，LogicGame 提供了包含一系列規則和初始狀態的不同遊戲，要求模型理解並應用預定義法規來解決問題。我們創建了模擬場景，其中模型執行或規劃操作以實現特定結果。這些遊戲場景經過專門設計，通過完全依賴預定義規則來區分邏輯推理和僅有的知識。這種分離允許對基於規則的推理能力進行純粹的評估。評估不僅考慮最終結果，還考慮中間步驟，對模型性能進行全面評估。此外，這些中間步驟是確定性的，可以自動驗證。LogicGame 定義了具有不同難度級別的遊戲場景，從簡單的規則應用到複雜的推理鏈，以便對模型在規則理解和多步驟執行方面的性能進行精確評估。利用 LogicGame，我們測試了各種 LLM，並發現它們在基於規則的邏輯推理能力方面存在顯著的缺陷。

##### **Easy, Interpretable, Effective: openSMILE for voice deepfake detection**
2408.15775v2 by Octavian Pascu, Dan Oneata, Horia Cucu, Nicolas M. Müller

In this paper, we demonstrate that attacks in the latest ASVspoof5 dataset --
a de facto standard in the field of voice authenticity and deepfake detection
-- can be identified with surprising accuracy using a small subset of very
simplistic features. These are derived from the openSMILE library, and are
scalar-valued, easy to compute, and human interpretable. For example, attack
A10`s unvoiced segments have a mean length of 0.09 +- 0.02, while bona fide
instances have a mean length of 0.18 +- 0.07. Using this feature alone, a
threshold classifier achieves an Equal Error Rate (EER) of 10.3% for attack
A10. Similarly, across all attacks, we achieve up to 0.8% EER, with an overall
EER of 15.7 +- 6.0%. We explore the generalization capabilities of these
features and find that some of them transfer effectively between attacks,
primarily when the attacks originate from similar Text-to-Speech (TTS)
architectures. This finding may indicate that voice anti-spoofing is, in part,
a problem of identifying and remembering signatures or fingerprints of
individual TTS systems. This allows to better understand anti-spoofing models
and their challenges in real-world application.

摘要：在本文中，我們證明了在最新的 ASVspoof5 資料集中攻擊 --
語音真實性和深度偽造偵測領域的既定標準
-- 可以使用非常簡單特徵的子集識別出驚人的準確度。這些特徵來自 openSMILE 函式庫，是標量值，易於計算，且人類可以理解。例如，攻擊 A10 的無聲區段平均長度為 0.09 +- 0.02，而真實案例的平均長度為 0.18 +- 0.07。單獨使用此特徵，閾值分類器可為攻擊 A10 達到 10.3% 的等錯誤率 (EER)。類似地，在所有攻擊中，我們達到 0.8% 的 EER，整體 EER 為 15.7 +- 6.0%。我們探討了這些特徵的泛化能力，發現其中一些特徵在攻擊之間有效轉移，特別是在攻擊源自於類似的文字轉語音 (TTS) 架構時。此發現可能表明語音防偽在某種程度上是識別和記憶個別 TTS 系統的簽章或指紋的問題。這有助於我們進一步了解防偽模型及其在現實世界應用中的挑戰。

##### **A Survey on Evaluation of Multimodal Large Language Models**
2408.15769v1 by Jiaxing Huang, Jingyi Zhang

Multimodal Large Language Models (MLLMs) mimic human perception and reasoning
system by integrating powerful Large Language Models (LLMs) with various
modality encoders (e.g., vision, audio), positioning LLMs as the "brain" and
various modality encoders as sensory organs. This framework endows MLLMs with
human-like capabilities, and suggests a potential pathway towards achieving
artificial general intelligence (AGI). With the emergence of all-round MLLMs
like GPT-4V and Gemini, a multitude of evaluation methods have been developed
to assess their capabilities across different dimensions. This paper presents a
systematic and comprehensive review of MLLM evaluation methods, covering the
following key aspects: (1) the background of MLLMs and their evaluation; (2)
"what to evaluate" that reviews and categorizes existing MLLM evaluation tasks
based on the capabilities assessed, including general multimodal recognition,
perception, reasoning and trustworthiness, and domain-specific applications
such as socioeconomic, natural sciences and engineering, medical usage, AI
agent, remote sensing, video and audio processing, 3D point cloud analysis, and
others; (3) "where to evaluate" that summarizes MLLM evaluation benchmarks into
general and specific benchmarks; (4) "how to evaluate" that reviews and
illustrates MLLM evaluation steps and metrics; Our overarching goal is to
provide valuable insights for researchers in the field of MLLM evaluation,
thereby facilitating the development of more capable and reliable MLLMs. We
emphasize that evaluation should be regarded as a critical discipline,
essential for advancing the field of MLLMs.

摘要：多模態大型語言模型 (MLLM) 透過整合強大的大型語言模型 (LLM) 與各種模態編碼器（例如視覺、音訊），模擬人類的感知和推理系統，將 LLM 定位為「大腦」，而將各種模態編碼器定位為感官器官。此架構賦予 MLLM 類似人類的能力，並提出實現人工通用智慧 (AGI) 的潛在途徑。隨著 GPT-4V 和 Gemini 等全方位 MLLM 的出現，已經開發出多種評估方法來評估它們在不同維度上的能力。本文對 MLLM 評估方法進行了系統且全面的回顧，涵蓋以下幾個關鍵面向：(1) MLLM 及其評估的背景；(2)「要評估什麼」根據評估的能力，回顧並分類現有的 MLLM 評估任務，包括一般多模態辨識、感知、推理和可信度，以及特定領域的應用，例如社會經濟、自然科學和工程、醫療用途、AI 代理、遙測、影片和音訊處理、3D 點雲分析等；(3)「在哪裡評估」將 MLLM 評估基準總結為一般基準和特定基準；(4)「如何評估」回顧並說明 MLLM 評估步驟和指標。我們的首要目標是為 MLLM 評估領域的研究人員提供有價值的見解，從而促進更強大且可靠的 MLLM 的開發。我們強調評估應被視為一項關鍵的學科，對於推進 MLLM 領域至關重要。

##### **Harmonized Speculative Sampling**
2408.15766v1 by Lefan Zhang, Xiaodan Wang, Yanhua Huang, Ruiwen Xu

Speculative sampling has proven to be an effective solution to accelerate
decoding from large language models, where the acceptance rate significantly
determines the performance. Most previous works on improving the acceptance
rate focus on aligned training and efficient decoding, implicitly paying less
attention to the linkage of training and decoding. In this work, we first
investigate the linkage of training and decoding for speculative sampling and
then propose a solution named HArmonized Speculative Sampling (HASS). HASS
improves the acceptance rate without extra inference overhead by harmonizing
training and decoding on their objectives and contexts. Experiments on three
LLaMA models demonstrate that HASS achieves 2.81x-3.65x wall-clock time speedup
ratio averaging across three datasets, which is 8%-15% faster than EAGLE-2.

摘要：推測取樣已被證明是一種加速從大型語言模型解碼的有效解決方案，其中接受率顯著決定效能。大多數先前關於改善接受率的研究都專注於對齊訓練和有效解碼，隱含地較少關注訓練和解碼的聯繫。在此研究中，我們首先探討推測取樣中訓練和解碼的聯繫，然後提出一個名為 HArmonized Speculative Sampling (HASS) 的解決方案。HASS 透過調和訓練和解碼的目標和背景，在沒有額外推論開銷的情況下改善接受率。在三個 LLaMA 模型上的實驗證明，HASS 在三個資料集上的平均時脈時間加速比達到 2.81x-3.65x，比 EAGLE-2 快 8%-15%。

##### **Form and meaning co-determine the realization of tone in Taiwan Mandarin spontaneous speech: the case of Tone 3 sandhi**
2408.15747v1 by Yuxin Lu, Yu-Ying Chuang, R. Harald Baayen

In Standard Chinese, Tone 3 (the dipping tone) becomes Tone 2 (rising tone)
when followed by another Tone 3. Previous studies have noted that this sandhi
process may be incomplete, in the sense that the assimilated Tone 3 is still
distinct from a true Tone 2. While Mandarin Tone 3 sandhi is widely studied
using carefully controlled laboratory speech (Xu, 1997) and more formal
registers of Beijing Mandarin (Yuan and Chen, 2014), less is known about its
realization in spontaneous speech, and about the effect of contextual factors
on tonal realization. The present study investigates the pitch contours of
two-character words with T2-T3 and T3-T3 tone patterns in spontaneous Taiwan
Mandarin conversations. Our analysis makes use of the Generative Additive Mixed
Model (GAMM, Wood, 2017) to examine fundamental frequency (f0) contours as a
function of normalized time. We consider various factors known to influence
pitch contours, including gender, speaking rate, speaker, neighboring tones,
word position, bigram probability, and also novel predictors, word and word
sense (Chuang et al., 2024). Our analyses revealed that in spontaneous Taiwan
Mandarin, T3-T3 words become indistinguishable from T2-T3 words, indicating
complete sandhi, once the strong effect of word (or word sense) is taken into
account. For our data, the shape of f0 contours is not co-determined by word
frequency. In contrast, the effect of word meaning on f0 contours is robust, as
strong as the effect of adjacent tones, and is present for both T2-T3 and T3-T3
words.

摘要：<paragraph>在標準漢語中，第三聲（降調）在遇到另一個第三聲時會變成第二聲（升調）。之前的研究指出，這個連音過程可能是不完全的，意思是被同化的第三聲仍然與真正的第二聲不同。雖然普通話第三聲連音在經過仔細控制的實驗室語音（徐，1997）和較正式的北京官話語域（袁和陳，2014）中廣泛研究，但對於它在自然語音中的實現以及語境因素對聲調實現的影響所知甚少。本研究探討了台灣國語自然對話中具有 T2-T3 和 T3-T3 聲調模式的雙字詞的音高輪廓。我們的分析利用生成加法混合模型 (GAMM, Wood, 2017) 來檢驗基本頻率 (f0) 輪廓作為歸一化時間的函數。我們考慮了各種已知會影響音高輪廓的因素，包括性別、說話速度、說話者、相鄰聲調、詞彙位置、二元詞概率，以及新穎的預測詞彙和詞彙意義（莊等人，2024）。我們的分析顯示，在台灣國語自然對話中，一旦考慮到詞彙（或詞彙意義）的強烈影響，T3-T3 詞彙與 T2-T3 詞彙變得無法區分，這表示連音是完全的。對於我們的資料，f0 輪廓的形狀並非由詞彙頻率共同決定。相反，詞彙意義對 f0 輪廓的影響是強大的，與相鄰聲調的影響一樣強，並且存在於 T2-T3 和 T3-T3 詞彙中。</paragraph>

##### **LM-PUB-QUIZ: A Comprehensive Framework for Zero-Shot Evaluation of Relational Knowledge in Language Models**
2408.15729v1 by Max Ploner, Jacek Wiland, Sebastian Pohl, Alan Akbik

Knowledge probing evaluates the extent to which a language model (LM) has
acquired relational knowledge during its pre-training phase. It provides a
cost-effective means of comparing LMs of different sizes and training setups
and is useful for monitoring knowledge gained or lost during continual learning
(CL). In prior work, we presented an improved knowledge probe called BEAR
(Wiland et al., 2024), which enables the comparison of LMs trained with
different pre-training objectives (causal and masked LMs) and addresses issues
of skewed distributions in previous probes to deliver a more unbiased reading
of LM knowledge. With this paper, we present LM-PUB- QUIZ, a Python framework
and leaderboard built around the BEAR probing mechanism that enables
researchers and practitioners to apply it in their work. It provides options
for standalone evaluation and direct integration into the widely-used training
pipeline of the Hugging Face TRANSFORMERS library. Further, it provides a
fine-grained analysis of different knowledge types to assist users in better
understanding the knowledge in each evaluated LM. We publicly release
LM-PUB-QUIZ as an open-source project.

摘要：知識探測評估語言模型 (LM) 在其預訓練階段中獲取關係知識的程度。它提供一種具有成本效益的方法，用於比較不同規模和訓練設定的 LM，並有助於監控在持續學習 (CL) 期間獲得或失去的知識。在先前的研究中，我們提出了一個名為 BEAR（Wiland 等人，2024 年）的改進知識探測，它能夠比較使用不同預訓練目標（因果和遮罩 LM）訓練的 LM，並解決先前探測中分佈偏斜的問題，以提供更公正的 LM 知識解讀。在本文中，我們提出了 LM-PUB-QUIZ，這是一個圍繞 BEAR 探測機制構建的 Python 框架和排行榜，使研究人員和從業人員能夠將其應用於自己的工作中。它提供了獨立評估和直接整合到 Hugging Face TRANSFORMERS 庫廣泛使用的訓練管道中的選項。此外，它提供了對不同知識類型的細粒度分析，以幫助用戶更好地理解每個評估 LM 中的知識。我們公開發布 LM-PUB-QUIZ 作為一個開源項目。

##### **Advanced POD-Based Performance Evaluation of Classifiers Applied to Human Driver Lane Changing Prediction**
2408.15722v1 by Zahra Rastin, Dirk Söffker

Machine learning (ML) classifiers serve as essential tools facilitating
classification and prediction across various domains. The performance of these
algorithms should be known to ensure their reliable application. In certain
fields, receiver operating characteristic and precision-recall curves are
frequently employed to assess machine learning algorithms without accounting
for the impact of process parameters. However, it may be essential to evaluate
the performance of these algorithms in relation to such parameters. As a
performance evaluation metric capable of considering the effects of process
parameters, this paper uses a modified probability of detection (POD) approach
to assess the reliability of ML-based algorithms. As an example, the POD-based
approach is employed to assess ML models used for predicting the lane changing
behavior of a vehicle driver. The time remaining to the predicted (and
therefore unknown) lane changing event is considered as process parameter. The
hit/miss approach to POD is taken here and modified by considering the
probability of lane changing derived from ML algorithms at each time step, and
obtaining the final result of the analysis accordingly. This improves the
reliability of results compared to the standard hit/miss approach, which
considers the outcome of the classifiers as either 0 or 1, while also
simplifying evaluation compared to the \^a versus a approach. Performance
evaluation results of the proposed approach are compared with those obtained
with the standard hit/miss approach and a pre-developed \^a versus a approach
to validate the effectiveness of the proposed method. The comparison shows that
this method provides an averaging conservative behavior with the advantage of
enhancing the reliability of the hit/miss approach to POD while retaining its
simplicity.

摘要：機器學習 (ML) 分類器是促進各種領域分類和預測的必要工具。應了解這些演算法的效能，以確保其可靠的應用。在某些領域中，接收器操作特性和精準度召回曲線經常被用於評估機器學習演算法，而不會考量流程參數的影響。然而，評估這些演算法相對於這些參數的效能可能至關重要。本文使用改良的偵測機率 (POD) 方法，作為一種能夠考量流程參數影響的效能評估指標，來評估基於 ML 的演算法的可靠性。舉例來說，基於 POD 的方法被用於評估用於預測車輛駕駛變換車道行為的 ML 模型。預測（因此未知）的變換車道事件的剩餘時間被視為流程參數。本文採用 POD 的命中/未命中方法，並透過考量 ML 演算法在每個時間步驟中產生的變換車道機率，以及相應地取得分析的最終結果，來修改該方法。與將分類器的結果視為 0 或 1 的標準命中/未命中方法相比，這改善了結果的可靠性，同時也簡化了與 ^a 相對於 a 方法的評估。將所提出的方法的效能評估結果與使用標準命中/未命中方法和預先開發的 ^a 相對於 a 方法所獲得的結果進行比較，以驗證所提出方法的有效性。比較結果顯示，此方法提供了平均保守的行為，具有增強 POD 的命中/未命中方法的可靠性的優點，同時保留其簡潔性。

##### **Conan-embedding: General Text Embedding with More and Better Negative Samples**
2408.15710v2 by Shiyu Li, Yang Tang, Shizhe Chen, Xi Chen

With the growing popularity of RAG, the capabilities of embedding models are
gaining increasing attention. Embedding models are primarily trained through
contrastive loss learning, with negative examples being a key component.
Previous work has proposed various hard negative mining strategies, but these
strategies are typically employed as preprocessing steps. In this paper, we
propose the conan-embedding model, which maximizes the utilization of more and
higher-quality negative examples. Specifically, since the model's ability to
handle preprocessed negative examples evolves during training, we propose
dynamic hard negative mining method to expose the model to more challenging
negative examples throughout the training process. Secondly, contrastive
learning requires as many negative examples as possible but is limited by GPU
memory constraints. Therefore, we use a Cross-GPU balancing Loss to provide
more negative examples for embedding training and balance the batch size across
multiple tasks. Moreover, we also discovered that the prompt-response pairs
from LLMs can be used for embedding training. Our approach effectively enhances
the capabilities of embedding models, currently ranking first on the Chinese
leaderboard of Massive text embedding benchmark

摘要：随着 RAG 的日益普及，嵌入模型的能力正受到越来越多的关注。嵌入模型主要通过对比损失学习进行训练，其中负样本是一个关键组成部分。以往的工作提出了各种困难的负样本挖掘策略，但这些策略通常被用作预处理步骤。在本文中，我们提出了 conan 嵌入模型，它最大限度地利用了更多更高质量的负样本。具体来说，由于模型处理预处理负样本的能力在训练过程中不断进化，我们提出了动态困难负样本挖掘方法，以在整个训练过程中将模型暴露于更具挑战性的负样本。其次，对比学习需要尽可能多的负样本，但受到 GPU 内存限制。因此，我们使用跨 GPU 平衡损失来为嵌入训练提供更多负样本，并在多个任务中平衡批处理大小。此外，我们还发现，来自 LLM 的提示响应对可用于嵌入训练。我们的方法有效地增强了嵌入模型的能力，目前在中文大规模文本嵌入基准测试排行榜上名列前茅

##### **Evaluating Model Robustness Using Adaptive Sparse L0 Regularization**
2408.15702v1 by Weiyou Liu, Zhenyang Li, Weitong Chen

Deep Neural Networks have demonstrated remarkable success in various domains
but remain susceptible to adversarial examples, which are slightly altered
inputs designed to induce misclassification. While adversarial attacks
typically optimize under Lp norm constraints, attacks based on the L0 norm,
prioritising input sparsity, are less studied due to their complex and non
convex nature. These sparse adversarial examples challenge existing defenses by
altering a minimal subset of features, potentially uncovering more subtle DNN
weaknesses. However, the current L0 norm attack methodologies face a trade off
between accuracy and efficiency either precise but computationally intense or
expedient but imprecise. This paper proposes a novel, scalable, and effective
approach to generate adversarial examples based on the L0 norm, aimed at
refining the robustness evaluation of DNNs against such perturbations.

摘要：深度神经網路在各種領域展現出卓越的成功，但仍然容易受到對抗性範例的影響，對抗性範例是經過輕微修改的輸入，旨在誘發錯誤分類。雖然對抗性攻擊通常在 Lp 範數約束下進行最佳化，但基於 L0 範數的攻擊優先考慮輸入稀疏性，由於其複雜且非凸的性質，因此研究較少。這些稀疏對抗性範例透過改變最小的特徵子集來挑戰現有防禦措施，可能會揭露更微妙的 DNN 弱點。然而，目前的 L0 範數攻擊方法在準確性和效率之間面臨取捨，既精確但計算密集，或快速但不精確。本文提出了一種新穎、可擴充且有效的生成基於 L0 範數的對抗性範例的方法，旨在改善 DNN 對此類擾動的穩健性評估。

##### **TempoFormer: A Transformer for Temporally-aware Representations in Change Detection**
2408.15689v1 by Talia Tseriotou, Adam Tsakalidis, Maria Liakata

Dynamic representation learning plays a pivotal role in understanding the
evolution of linguistic content over time. On this front both context and time
dynamics as well as their interplay are of prime importance. Current approaches
model context via pre-trained representations, which are typically temporally
agnostic. Previous work on modeling context and temporal dynamics has used
recurrent methods, which are slow and prone to overfitting. Here we introduce
TempoFormer, the fist task-agnostic transformer-based and temporally-aware
model for dynamic representation learning. Our approach is jointly trained on
inter and intra context dynamics and introduces a novel temporal variation of
rotary positional embeddings. The architecture is flexible and can be used as
the temporal representation foundation of other models or applied to different
transformer-based architectures. We show new SOTA performance on three
different real-time change detection tasks.

摘要：動態表徵學習在理解語言內容隨時間演變方面扮演著關鍵角色。在這個領域中，脈絡和時間動態以及它們的相互作用都至關重要。目前的做法是透過預先訓練的表徵對脈絡進行建模，而這些表徵通常與時間無關。先前關於對脈絡和時間動態進行建模的研究使用了遞迴方法，這種方法緩慢且容易過度擬合。在此，我們介紹 TempoFormer，這是一個與任務無關且基於Transformer的模型，並具有時間感知能力，可進行動態表徵學習。我們的做法是針對脈絡間和脈絡內動態進行聯合訓練，並引入旋轉位置嵌入的時間變化。這個架構具有彈性，可用作其他模型的時間表徵基礎，或應用於不同的基於Transformer的架構。我們在三個不同的即時變更偵測任務上展現了新的 SOTA 效能。

##### **StyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements**
2408.15666v1 by Jillian Fisher, Skyler Hallinan, Ximing Lu, Mitchell Gordon, Zaid Harchaoui, Yejin Choi

Authorship obfuscation, rewriting a text to intentionally obscure the
identity of the author, is an important but challenging task. Current methods
using large language models (LLMs) lack interpretability and controllability,
often ignoring author-specific stylistic features, resulting in less robust
performance overall.
  To address this, we develop StyleRemix, an adaptive and interpretable
obfuscation method that perturbs specific, fine-grained style elements of the
original input text. StyleRemix uses pre-trained Low Rank Adaptation (LoRA)
modules to rewrite an input specifically along various stylistic axes (e.g.,
formality and length) while maintaining low computational cost. StyleRemix
outperforms state-of-the-art baselines and much larger LLMs in a variety of
domains as assessed by both automatic and human evaluation.
  Additionally, we release AuthorMix, a large set of 30K high-quality,
long-form texts from a diverse set of 14 authors and 4 domains, and DiSC, a
parallel corpus of 1,500 texts spanning seven style axes in 16 unique
directions

摘要：作者混淆，重写文本以故意模糊作者身份，是一项重要但具有挑战性的任务。当前使用大型语言模型 (LLM) 的方法缺乏可解释性和可控性，通常会忽略作者特定的文体特征，从而导致整体性能不够稳健。
为了解决这个问题，我们开发了 StyleRemix，这是一种自适应且可解释的混淆方法，它扰乱了原始输入文本中特定、细粒度的风格元素。StyleRemix 使用预训练的低秩自适应 (LoRA) 模块来专门沿着各种文体轴（例如，正式性和长度）重写输入，同时保持较低的计算成本。StyleRemix 在各种领域中优于最先进的基线和更大的 LLM，这是通过自动和人工评估得出的。
此外，我们发布了 AuthorMix，这是一组来自 14 位作者和 4 个领域的大量 30K 高质量长篇文本，以及 DiSC，这是一个包含 1500 篇文本的平行语料库，跨越 16 个独特方向的七个风格轴

##### **Auxiliary-Loss-Free Load Balancing Strategy for Mixture-of-Experts**
2408.15664v1 by Lean Wang, Huazuo Gao, Chenggang Zhao, Xu Sun, Damai Dai

For Mixture-of-Experts (MoE) models, an unbalanced expert load will lead to
routing collapse or increased computational overhead. Existing methods commonly
employ an auxiliary loss to encourage load balance, but a large auxiliary loss
will introduce non-negligible interference gradients into training and thus
impair the model performance. In order to control load balance while not
producing undesired gradients during training, we propose Loss-Free Balancing,
featured by an auxiliary-loss-free load balancing strategy. To be specific,
before the top-K routing decision, Loss-Free Balancing will first apply an
expert-wise bias to the routing scores of each expert. By dynamically updating
the bias of each expert according to its recent load, Loss-Free Balancing can
consistently maintain a balanced distribution of expert load. In addition,
since Loss-Free Balancing does not produce any interference gradients, it also
elevates the upper bound of model performance gained from MoE training. We
validate the performance of Loss-Free Balancing on MoE models with up to 3B
parameters trained on up to 200B tokens. Experimental results show that
Loss-Free Balancing achieves both better performance and better load balance
compared with traditional auxiliary-loss-controlled load balancing strategies.

摘要：對於 Mixture-of-Experts (MoE) 模型，不平衡的專家負載將導致路由崩潰或增加計算開銷。現有方法通常採用輔助損失來鼓勵負載平衡，但大的輔助損失會在訓練中引入不可忽略的干擾梯度，從而損害模型效能。為了在訓練期間控制負載平衡，同時不產生不必要的梯度，我們提出無損失平衡，其特點是無輔助損失負載平衡策略。具體來說，在頂部 K 路由決策之前，無損失平衡將首先對每個專家的路由分數應用專家偏差。透過根據每個專家的最新負載動態更新偏差，無損失平衡可以持續維持專家負載的平衡分佈。此外，由於無損失平衡不會產生任何干擾梯度，因此它也提升了從 MoE 訓練中獲得的模型效能的上限。我們在訓練多達 200B 個代幣的多達 3B 個參數的 MoE 模型上驗證了無損失平衡的效能。實驗結果表明，與傳統的輔助損失控制負載平衡策略相比，無損失平衡實現了更好的效能和負載平衡。

##### **An Empirical Study on Self-correcting Large Language Models for Data Science Code Generation**
2408.15658v1 by Thai Tang Quoc, Duc Ha Minh, Tho Quan Thanh, Anh Nguyen-Duc

Large Language Models (LLMs) have recently advanced many applications on
software engineering tasks, particularly the potential for code generation.
Among contemporary challenges, code generated by LLMs often suffers from
inaccuracies and hallucinations, requiring external inputs to correct. One
recent strategy to fix these issues is to refine the code generated from LLMs
using the input from the model itself (self-augmented). In this work, we
proposed a novel method, namely CoT-SelfEvolve. CoT-SelfEvolve iteratively and
automatically refines code through a self-correcting process, guided by a chain
of thought constructed from real-world programming problem feedback. Focusing
on data science code, including Python libraries such as NumPy and Pandas, our
evaluations on the DS-1000 dataset demonstrate that CoT-SelfEvolve
significantly outperforms existing models in solving complex problems. The
framework shows substantial improvements in both initial code generation and
subsequent iterations, with the model's accuracy increasing significantly with
each additional iteration. This highlights the effectiveness of using
chain-of-thought prompting to address complexities revealed by program executor
traceback error messages. We also discuss how CoT-SelfEvolve can be integrated
into continuous software engineering environments, providing a practical
solution for improving LLM-based code generation.

摘要：大型語言模型 (LLM) 近期在軟體工程任務中推進許多應用程式，特別是程式碼產生的潛力。在當代挑戰中，LLM 生成的程式碼常常有錯誤和幻覺，需要外部輸入來修正。最近一種修正這些問題的策略是使用模型本身的輸入 (自我增強) 來改善 LLM 生成的程式碼。在這項工作中，我們提出了一個創新的方法，也就是 CoT-SelfEvolve。CoT-SelfEvolve 透過自我修正的過程，迭代且自動改善程式碼，並由從真實世界程式設計問題回饋建構的思考鏈引導。我們針對資料科學程式碼進行評估，包括 NumPy 和 Pandas 等 Python 函式庫，在 DS-1000 資料集上的評估證明，CoT-SelfEvolve 在解決複雜問題上顯著優於現有模型。這個架構在初始程式碼產生和後續迭代中都顯示出大幅進步，模型的準確度會隨著每次額外的迭代而顯著增加。這突顯了使用思考鏈提示來解決程式執行器追蹤錯誤訊息所揭露的複雜性的有效性。我們也討論 CoT-SelfEvolve 如何整合到持續軟體工程環境中，提供一個改善基於 LLM 的程式碼產生的實際解決方案。

##### **Harnessing the Intrinsic Knowledge of Pretrained Language Models for Challenging Text Classification Settings**
2408.15650v1 by Lingyu Gao

Text classification is crucial for applications such as sentiment analysis
and toxic text filtering, but it still faces challenges due to the complexity
and ambiguity of natural language. Recent advancements in deep learning,
particularly transformer architectures and large-scale pretraining, have
achieved inspiring success in NLP fields. Building on these advancements, this
thesis explores three challenging settings in text classification by leveraging
the intrinsic knowledge of pretrained language models (PLMs). Firstly, to
address the challenge of selecting misleading yet incorrect distractors for
cloze questions, we develop models that utilize features based on
contextualized word representations from PLMs, achieving performance that
rivals or surpasses human accuracy. Secondly, to enhance model generalization
to unseen labels, we create small finetuning datasets with domain-independent
task label descriptions, improving model performance and robustness. Lastly, we
tackle the sensitivity of large language models to in-context learning prompts
by selecting effective demonstrations, focusing on misclassified examples and
resolving model ambiguity regarding test example labels.

摘要：文本分類對於情感分析和有毒文本過濾等應用至關重要，但由於自然語言的複雜性和模糊性，它仍然面臨挑戰。深度學習的最新進展，特別是轉換器架構和大規模預訓練，在 NLP 領域取得了鼓舞人心的成功。本論文以這些進展為基礎，通過利用預訓練語言模型 (PLM) 的內在知識，探索了文本分類中的三個具有挑戰性的設置。首先，為了應對為完形填空題選擇具有誤導性但錯誤的干擾項的挑戰，我們開發了利用來自 PLM 的上下文化詞表示特徵的模型，達到了與人類準確性相媲美或超越人類準確性的性能。其次，為了增強模型對未見標籤的泛化，我們使用與領域無關的任務標籤描述創建了小型微調數據集，從而提高了模型性能和魯棒性。最後，我們通過選擇有效的演示來解決大型語言模型對上下文學習提示的敏感性，重點關注分類錯誤的示例並解決模型對測試示例標籤的歧義。

##### **Hierarchical Blockmodelling for Knowledge Graphs**
2408.15649v1 by Marcin Pietrasik, Marek Reformat, Anna Wilbik

In this paper, we investigate the use of probabilistic graphical models,
specifically stochastic blockmodels, for the purpose of hierarchical entity
clustering on knowledge graphs. These models, seldom used in the Semantic Web
community, decompose a graph into a set of probability distributions. The
parameters of these distributions are then inferred allowing for their
subsequent sampling to generate a random graph. In a non-parametric setting,
this allows for the induction of hierarchical clusterings without prior
constraints on the hierarchy's structure. Specifically, this is achieved by the
integration of the Nested Chinese Restaurant Process and the Stick Breaking
Process into the generative model. In this regard, we propose a model
leveraging such integration and derive a collapsed Gibbs sampling scheme for
its inference. To aid in understanding, we describe the steps in this
derivation and provide an implementation for the sampler. We evaluate our model
on synthetic and real-world datasets and quantitatively compare against
benchmark models. We further evaluate our results qualitatively and find that
our model is capable of inducing coherent cluster hierarchies in small scale
settings. The work presented in this paper provides the first step for the
further application of stochastic blockmodels for knowledge graphs on a larger
scale. We conclude the paper with potential avenues for future work on more
scalable inference schemes.

摘要：在本文中，我们研究概率图模型（特别是随机块模型）在知识图谱中进行分层实体聚类时的用途。这些模型在语义网社区中很少使用，可以将图分解为一组概率分布。然后推断这些分布的参数，以便进行后续抽样以生成随机图。在非参数设置中，这允许在没有层次结构约束的情况下归纳层次聚类。具体来说，这是通过将嵌套中国餐馆过程和树枝断裂过程集成到生成模型中来实现的。在这方面，我们提出了一个利用这种集成的模型，并为其推论推导出一个折叠的 Gibbs 采样方案。为了帮助理解，我们描述了此推导中的步骤，并为采样器提供了实现。我们对合成和真实世界数据集评估了我们的模型，并与基准模型进行了定量比较。我们进一步定性评估了我们的结果，发现我们的模型能够在小规模设置中归纳出连贯的聚类层次结构。本文提出的工作为在更大规模上进一步应用知识图谱的随机块模型提供了第一步。我们以未来工作中可扩展推论方案的潜在途径结束了本文。

##### **GANs Conditioning Methods: A Survey**
2408.15640v2 by Anis Bourou, Auguste Genovesio, Valérie Mezger

In recent years, Generative Adversarial Networks (GANs) have seen significant
advancements, leading to their widespread adoption across various fields. The
original GAN architecture enables the generation of images without any specific
control over the content, making it an unconditional generation process.
However, many practical applications require precise control over the generated
output, which has led to the development of conditional GANs (cGANs) that
incorporate explicit conditioning to guide the generation process. cGANs extend
the original framework by incorporating additional information (conditions),
enabling the generation of samples that adhere to that specific criteria.
Various conditioning methods have been proposed, each differing in how they
integrate the conditioning information into both the generator and the
discriminator networks. In this work, we review the conditioning methods
proposed for GANs, exploring the characteristics of each method and
highlighting their unique mechanisms and theoretical foundations. Furthermore,
we conduct a comparative analysis of these methods, evaluating their
performance on various image datasets. Through these analyses, we aim to
provide insights into the strengths and limitations of various conditioning
techniques, guiding future research and application in generative modeling.

摘要：近年來，生成對抗網路 (GAN) 已顯著進步，因而廣泛運用於各個領域。原始 GAN 架構能夠生成影像，但無法特別控制內容，因此屬於無條件生成程序。然而，許多實際應用都需要精準控制所生成的輸出，這促使條件式 GAN (cGAN) 應運而生，它結合明確條件來引導生成程序。cGAN 在原始架構中加入額外的資訊（條件），進而擴充功能，能夠生成符合特定條件的樣本。已提出各種條件式方法，每種方法整合條件資訊至生成器和鑑別器網路的方式各不相同。在這項研究中，我們回顧為 GAN 提出的條件式方法，探討每種方法的特性，並強調其獨特的機制和理論基礎。此外，我們對這些方法進行比較分析，評估它們在各種影像資料集上的效能。透過這些分析，我們旨在提供洞察力，瞭解各種條件式技術的優缺點，引導未來在生成模型中的研究和應用。

##### **CodeSift: An LLM-Based Reference-Less Framework for Automatic Code Validation**
2408.15630v1 by Pooja Aggarwal, Oishik Chatterjee, Ting Dai, Prateeti Mohapatra, Brent Paulovicks, Brad Blancett, Arthur De Magalhaes

The advent of large language models (LLMs) has greatly facilitated code
generation, but ensuring the functional correctness of generated code remains a
challenge. Traditional validation methods are often time-consuming,
error-prone, and impractical for large volumes of code. We introduce CodeSift,
a novel framework that leverages LLMs as the first-line filter of code
validation without the need for execution, reference code, or human feedback,
thereby reducing the validation effort. We assess the effectiveness of our
method across three diverse datasets encompassing two programming languages.
Our results indicate that CodeSift outperforms state-of-the-art code evaluation
methods. Internal testing conducted with subject matter experts reveals that
the output generated by CodeSift is in line with human preference, reinforcing
its effectiveness as a dependable automated code validation tool.

摘要：大型語言模型 (LLM) 的出現極大地方便了程式碼生成，但是確保已生成程式碼的功能正確性仍然是一項挑戰。傳統驗證方法通常耗時、容易出錯，而且不適用於大量程式碼。我們介紹 CodeSift，一個新穎的架構，它利用 LLM 作為程式碼驗證的第一線過濾器，無需執行、參考程式碼或人為回饋，從而減少驗證工作。我們評估了我們的方法在涵蓋兩種程式語言的三個不同資料集中的有效性。我們的結果表明，CodeSift 優於最先進的程式碼評估方法。與主題專家進行的內部測試表明，CodeSift 生成的輸出符合人類偏好，加強了其作為可靠的自動化程式碼驗證工具的有效性。

##### **CBF-LLM: Safe Control for LLM Alignment**
2408.15625v1 by Yuya Miyaoka, Masaki Inoue

This paper proposes a control-based framework for aligning large language
models (LLMs) by leveraging a control barrier function (CBF) to ensure
user-desirable text generation. The presented framework applies the safety
filter, designed based on the CBF, to the output generation of the baseline
LLM, i.e., the sequence of the token, with the aim of intervening in the
generated text. The overall text-generation system is implemented with Llama 3
and a RoBERTa model, and the source code is available at
https://github.com/Mya-Mya/CBF-LLM. The experiment demonstrates its control
ability and effectiveness in reducing the number of interventions needed for
user-specified alignment tasks.

摘要：本文提出了一个基于控制的框架，通过利用控制势垒函数 (CBF) 来确保用户期望的文本生成，从而对大型语言模型 (LLM) 进行对齐。所提出的框架将基于 CBF 设计的安全过滤器应用于基准 LLM 的输出生成，即令牌序列，目的是干预生成的文本。整体文本生成系统使用 Llama 3 和 RoBERTa 模型实现，源代码可在 https://github.com/Mya-Mya/CBF-LLM 获得。实验表明了其在减少用户指定对齐任务所需干预次数方面的控制能力和有效性。

##### **SIaM: Self-Improving Code-Assisted Mathematical Reasoning of Large Language Models**
2408.15565v1 by Dian Yu, Baolin Peng, Ye Tian, Linfeng Song, Haitao Mi, Dong Yu

There is a growing trend of teaching large language models (LLMs) to solve
mathematical problems through coding. Existing studies primarily focus on
prompting powerful, closed-source models to generate seed training data
followed by in-domain data augmentation, equipping LLMs with considerable
capabilities for code-aided mathematical reasoning. However, continually
training these models on augmented data derived from a few datasets such as
GSM8K may impair their generalization abilities and restrict their
effectiveness to a narrow range of question types. Conversely, the potential of
improving such LLMs by leveraging large-scale, expert-written, diverse math
question-answer pairs remains unexplored. To utilize these resources and tackle
unique challenges such as code response assessment, we propose a novel paradigm
that uses a code-based critic model to guide steps including question-code data
construction, quality control, and complementary evaluation. We also explore
different alignment algorithms with self-generated instruction/preference data
to foster continuous improvement. Experiments across both in-domain (up to
+5.7%) and out-of-domain (+4.4%) benchmarks in English and Chinese demonstrate
the effectiveness of the proposed paradigm.

摘要：大型語言模型 (LLM) 透過編碼解決數學問題的教學趨勢正日益盛行。現有研究主要專注於提示強大的閉源模型來產生種子訓練資料，然後進行領域內資料擴充，讓 LLM 具備相當的程式碼輔助數學推理能力。然而，持續針對從少數資料集（例如 GSM8K）衍生的擴充資料訓練這些模型可能會損害其概化能力，並將其效能限制在狹窄的題型範圍內。相反地，透過利用大規模、專家撰寫、多元的數學問答對來提升此類 LLM 的潛力仍未被探索。為了利用這些資源並應對獨特的挑戰（例如程式碼回應評估），我們提出一個創新的範例，它使用基於程式碼的批評模型來引導步驟，包括問答碼資料建構、品質控管和補充評估。我們也探討不同的比對演算法，搭配自產指令/偏好資料，以促進持續改善。在英語和中文的領域內（提升達 +5.7%）和領域外（提升達 +4.4%）基準測試中的實驗證明了所提範例的效能。

##### **Boosting Lossless Speculative Decoding via Feature Sampling and Partial Alignment Distillation**
2408.15562v1 by Lujun Gui, Bin Xiao, Lei Su, Weipeng Chen

Lossless speculative decoding accelerates target large language model (LLM)
inference by employing a lightweight draft model for generating tree-structured
candidates, which are subsequently verified in parallel by the target LLM.
Currently, effective approaches leverage feature-level rather than token-level
autoregression within the draft model to facilitate more straightforward
predictions and enhanced knowledge distillation. In this paper, we reassess
these approaches and propose FSPAD (Feature Sampling and Partial Alignment
Distillation for Lossless Speculative Decoding), which introduces two
straightforward and effective components within the existing framework to boost
lossless speculative decoding. Firstly, FSPAD utilizes token embeddings to
sample features of the target LLM in high-dimensional space before feeding them
into the draft model, due to the inherent uncertainty of the features
preventing the draft model from obtaining the specific token output by the
target LLM. Secondly, FSPAD introduces partial alignment distillation to weaken
the draft model's connection between features and logits, aiming to reduce the
conflict between feature alignment and logit confidence during training. Our
experiments include both greedy and non-greedy decoding on the largest and
smallest models from the Vicuna and LLaMA3-Instruct series, as well as tasks in
multi-turn conversation, translation, summarization, question answering,
mathematical reasoning, and retrieval-augmented generation. The results show
that FSPAD outperforms the state-of-the-art method across all the
aforementioned tasks and target LLMs.

摘要：無失真推測解碼透過採用輕量級草稿模型來加速目標大型語言模型 (LLM) 推論，以產生樹狀結構候選，隨後由目標 LLM 平行驗證。目前，有效的方法利用草稿模型中特徵層級而非代幣層級自迴歸，以促進更直接的預測和增強知識萃取。在本文中，我們重新評估這些方法，並提出 FSPAD（特徵取樣和部分對齊萃取用於無失真推測解碼），在現有架構中引入兩個直接且有效的元件，以提升無失真推測解碼。首先，由於特徵的固有不確定性會妨礙草稿模型取得目標 LLM 的特定代幣輸出，FSPAD 利用代幣嵌入在高維空間中取樣目標 LLM 的特徵，然後將其輸入草稿模型。其次，FSPAD 引入部分對齊萃取，以弱化草稿模型中特徵和 logit 之間的關聯，旨在減少特徵對齊和 logit 信心在訓練期間的衝突。我們的實驗包括在 Vicuna 和 LLaMA3-Instruct 系列中最大和最小的模型上進行貪婪和非貪婪解碼，以及多輪對話、翻譯、摘要、問答、數學推理和檢索增強生成中的任務。結果顯示，FSPAD 在所有上述任務和目標 LLM 中都優於最先進的方法。

##### **CGRA4ML: A Framework to Implement Modern Neural Networks for Scientific Edge Computing**
2408.15561v2 by G Abarajithan, Zhenghua Ma, Zepeng Li, Shrideep Koparkar, Ravidu Munasinghe, Francesco Restuccia, Ryan Kastner

Scientific edge computing increasingly relies on hardware-accelerated neural
networks to implement complex, near-sensor processing at extremely high
throughputs and low latencies. Existing frameworks like HLS4ML are effective
for smaller models, but struggle with larger, modern neural networks due to
their requirement of spatially implementing the neural network layers and
storing all weights in on-chip memory. CGRA4ML is an open-source, modular
framework designed to bridge the gap between neural network model complexity
and extreme performance requirements. CGRA4ML extends the capabilities of
HLS4ML by allowing off-chip data storage and supporting a broader range of
neural network architectures, including models like ResNet, PointNet, and
transformers. Unlike HLS4ML, CGRA4ML generates SystemVerilog RTL, making it
more suitable for targeting ASIC and FPGA design flows. We demonstrate the
effectiveness of our framework by implementing and scaling larger models that
were previously unattainable with HLS4ML, showcasing its adaptability and
efficiency in handling complex computations. CGRA4ML also introduces an
extensive verification framework, with a generated runtime firmware that
enables its integration into different SoC platforms. CGRA4ML's minimal and
modular infrastructure of Python API, SystemVerilog hardware, Tcl toolflows,
and C runtime, facilitates easy integration and experimentation, allowing
scientists to focus on innovation rather than the intricacies of hardware
design and optimization.

摘要：科學邊緣運算越來越依賴硬體加速神經網路，在極高的吞吐量和低延遲下實作複雜的近感測器處理。現有的框架，例如 HLS4ML，對於較小的模型很有效，但對於較大、現代的神經網路卻難以應付，因為它們需要在空間上實作神經網路層，並將所有權重儲存在晶片記憶體中。CGRA4ML 是一個開源的模組化框架，旨在彌合神經網路模型複雜度與極端效能需求之間的差距。CGRA4ML 透過允許晶片外資料儲存和支援更廣泛的神經網路架構（包括 ResNet、PointNet 和 Transformer 等模型）來擴充 HLS4ML 的功能。與 HLS4ML 不同的是，CGRA4ML 會產生 SystemVerilog RTL，使其更適合用於 ASIC 和 FPGA 設計流程。我們透過實作和擴充先前無法使用 HLS4ML 達成的更大模型來展示我們框架的有效性，展示其在處理複雜運算時的適應性和效率。CGRA4ML 也引進一個廣泛的驗證框架，並搭配一個產生的執行時期韌體，讓它能夠整合到不同的 SoC 平台。CGRA4ML 最小且模組化的基礎架構，包含 Python API、SystemVerilog 硬體、Tcl 工具流程和 C 執行時期，促進了輕鬆的整合和實驗，讓科學家可以專注於創新，而不是硬體設計和最佳化的複雜性。

##### **Trustworthy and Responsible AI for Human-Centric Autonomous Decision-Making Systems**
2408.15550v1 by Farzaneh Dehghani, Mahsa Dibaji, Fahim Anzum, Lily Dey, Alican Basdemir, Sayeh Bayat, Jean-Christophe Boucher, Steve Drew, Sarah Elaine Eaton, Richard Frayne, Gouri Ginde, Ashley Harris, Yani Ioannou, Catherine Lebel, John Lysack, Leslie Salgado Arzuaga, Emma Stanley, Roberto Souza, Ronnie Souza, Lana Wells, Tyler Williamson, Matthias Wilms, Zaman Wahid, Mark Ungrin, Marina Gavrilova, Mariana Bento

Artificial Intelligence (AI) has paved the way for revolutionary
decision-making processes, which if harnessed appropriately, can contribute to
advancements in various sectors, from healthcare to economics. However, its
black box nature presents significant ethical challenges related to bias and
transparency. AI applications are hugely impacted by biases, presenting
inconsistent and unreliable findings, leading to significant costs and
consequences, highlighting and perpetuating inequalities and unequal access to
resources. Hence, developing safe, reliable, ethical, and Trustworthy AI
systems is essential.
  Our team of researchers working with Trustworthy and Responsible AI, part of
the Transdisciplinary Scholarship Initiative within the University of Calgary,
conducts research on Trustworthy and Responsible AI, including fairness, bias
mitigation, reproducibility, generalization, interpretability, and
authenticity. In this paper, we review and discuss the intricacies of AI
biases, definitions, methods of detection and mitigation, and metrics for
evaluating bias. We also discuss open challenges with regard to the
trustworthiness and widespread application of AI across diverse domains of
human-centric decision making, as well as guidelines to foster Responsible and
Trustworthy AI models.

摘要：人工智慧 (AI) 為革命性的決策過程鋪路，如果適當運用，可促進從醫療保健到經濟等各個領域的進步。然而，其黑箱性質對偏見和透明度提出了重大的道德挑戰。AI 應用受到偏見的嚴重影響，呈現出不一致且不可靠的發現，導致重大成本和後果，凸顯並延續不平等和資源取得不均的問題。因此，開發安全、可靠、合乎道德且值得信賴的 AI 系統至關重要。
我們的研究團隊與卡加利大學跨學科獎學金計畫中的可信賴且負責任的 AI 合作，對可信賴且負責任的 AI 進行研究，包括公平性、偏見緩解、可複製性、概括性、可解釋性和真實性。在本文中，我們回顧並討論 AI 偏見、定義、偵測和緩解方法，以及評估偏見的指標的複雜性。我們還討論了在以人為中心的決策制定過程中，AI 的可信賴性和廣泛應用所面臨的公開挑戰，以及促進負責任且可信賴的 AI 模型的準則。

##### **WildFeedback: Aligning LLMs With In-situ User Interactions And Feedback**
2408.15549v1 by Taiwei Shi, Zhuoer Wang, Longqi Yang, Ying-Chun Lin, Zexue He, Mengting Wan, Pei Zhou, Sujay Jauhar, Xiaofeng Xu, Xia Song, Jennifer Neville

As large language models (LLMs) continue to advance, aligning these models
with human preferences has emerged as a critical challenge. Traditional
alignment methods, relying on human or LLM annotated datasets, are limited by
their resource-intensive nature, inherent subjectivity, and the risk of
feedback loops that amplify model biases. To overcome these limitations, we
introduce WildFeedback, a novel framework that leverages real-time, in-situ
user interactions to create preference datasets that more accurately reflect
authentic human values. WildFeedback operates through a three-step process:
feedback signal identification, preference data construction, and user-guided
evaluation. We applied this framework to a large corpus of user-LLM
conversations, resulting in a rich preference dataset that reflects genuine
user preferences. This dataset captures the nuances of user preferences by
identifying and classifying feedback signals within natural conversations,
thereby enabling the construction of more representative and context-sensitive
alignment data. Our extensive experiments demonstrate that LLMs fine-tuned on
WildFeedback exhibit significantly improved alignment with user preferences, as
evidenced by both traditional benchmarks and our proposed user-guided
evaluation. By incorporating real-time feedback from actual users, WildFeedback
addresses the scalability, subjectivity, and bias challenges that plague
existing approaches, marking a significant step toward developing LLMs that are
more responsive to the diverse and evolving needs of their users. In summary,
WildFeedback offers a robust, scalable solution for aligning LLMs with true
human values, setting a new standard for the development and evaluation of
user-centric language models.

摘要：隨著大型語言模型 (LLM) 持續進步，將這些模型與人類偏好相符已成為一項關鍵挑戰。傳統比對方法仰賴人工或 LLM 標註資料集，其限制在於耗費大量資源、固有主觀性，以及放大模型偏誤的回饋迴路風險。為了解決這些限制，我們引進 WildFeedback，這是一個創新的架構，它利用即時、原地的使用者互動來建立偏好資料集，更準確地反映真實的人類價值觀。WildFeedback 透過一個三步驟流程運作：回饋訊號識別、偏好資料建構，以及使用者引導評估。我們將這個架構套用於大量使用者-LLM 對話語料庫，產生一個豐富的偏好資料集，反映真實的使用者偏好。這個資料集透過在自然對話中識別和分類回饋訊號，捕捉使用者偏好的細微差別，進而建構更具代表性且對脈絡敏感的比對資料。我們廣泛的實驗證明，使用 WildFeedback 微調的 LLM 與使用者偏好有顯著提升的比對，傳統基準和我們提出的使用者引導評估都證實了這一點。透過納入實際使用者的即時回饋，WildFeedback 解決了現有方法中普遍存在的可擴充性、主觀性和偏誤挑戰，標誌著朝開發對使用者多元且不斷變化的需求更具回應性的 LLM 邁出了一大步。總之，WildFeedback 提供了一個強健、可擴充的解決方案，將 LLM 與真實的人類價值觀相符，為以使用者為中心的語言模型的開發和評估樹立了新標準。

##### **SciLitLLM: How to Adapt LLMs for Scientific Literature Understanding**
2408.15545v1 by Sihang Li, Jian Huang, Jiaxi Zhuang, Yaorui Shi, Xiaochen Cai, Mingjun Xu, Xiang Wang, Linfeng Zhang, Guolin Ke, Hengxing Cai

Scientific literature understanding is crucial for extracting targeted
information and garnering insights, thereby significantly advancing scientific
discovery. Despite the remarkable success of Large Language Models (LLMs), they
face challenges in scientific literature understanding, primarily due to (1) a
lack of scientific knowledge and (2) unfamiliarity with specialized scientific
tasks.
  To develop an LLM specialized in scientific literature understanding, we
propose a hybrid strategy that integrates continual pre-training (CPT) and
supervised fine-tuning (SFT), to simultaneously infuse scientific domain
knowledge and enhance instruction-following capabilities for domain-specific
tasks.cIn this process, we identify two key challenges: (1) constructing
high-quality CPT corpora, and (2) generating diverse SFT instructions. We
address these challenges through a meticulous pipeline, including PDF text
extraction, parsing content error correction, quality filtering, and synthetic
instruction creation. Applying this strategy, we present a suite of LLMs:
SciLitLLM, specialized in scientific literature understanding. These models
demonstrate promising performance on scientific literature understanding
benchmarks.
  Our contributions are threefold: (1) We present an effective framework that
integrates CPT and SFT to adapt LLMs to scientific literature understanding,
which can also be easily adapted to other domains. (2) We propose an LLM-based
synthesis method to generate diverse and high-quality scientific instructions,
resulting in a new instruction set -- SciLitIns -- for supervised fine-tuning
in less-represented scientific domains. (3) SciLitLLM achieves promising
performance improvements on scientific literature understanding benchmarks.

摘要：<paragraph>科學文獻理解對於萃取目標資訊和收集見解至關重要，進而顯著推進科學發現。儘管大型語言模型 (LLM) 獲得非凡的成功，但它們在科學文獻理解方面仍面臨挑戰，其主要原因有：(1) 缺乏科學知識，以及 (2) 不熟悉專業科學任務。
為了開發專精於科學文獻理解的 LLM，我們提出一個整合持續預訓練 (CPT) 和監督微調 (SFT) 的混合策略，以同時灌輸科學領域知識並增強特定領域任務的指令遵循能力。在此過程中，我們找出兩個關鍵挑戰：(1) 建構高品質的 CPT 語料庫，以及 (2) 產生多樣的 SFT 指令。我們透過一個細緻的流程來解決這些挑戰，包括 PDF 文字萃取、解析內容錯誤修正、品質過濾和合成指令建立。透過應用此策略，我們提出了一組 LLM：SciLitLLM，專精於科學文獻理解。這些模型在科學文獻理解基準上展現出令人滿意的效能。
我們的貢獻有三方面：(1) 我們提出一個有效的架構，整合 CPT 和 SFT 以適應 LLM 於科學文獻理解，這也可以輕易地適應到其他領域。(2) 我們提出一個基於 LLM 的合成方法，用於產生多樣且高品質的科學指令，進而產生一個新的指令集 -- SciLitIns -- 用於在代表性較低的科學領域中進行監督微調。(3) SciLitLLM 在科學文獻理解基準上取得令人滿意的效能提升。</paragraph>

##### **An Investigation of Warning Erroneous Chat Translations in Cross-lingual Communication**
2408.15543v1 by Yunmeng Li, Jun Suzuki, Makoto Morishita, Kaori Abe, Kentaro Inui

The complexities of chats pose significant challenges for machine translation
models. Recognizing the need for a precise evaluation metric to address the
issues of chat translation, this study introduces Multidimensional Quality
Metrics for Chat Translation (MQM-Chat). Through the experiments of five models
using MQM-Chat, we observed that all models generated certain fundamental
errors, while each of them has different shortcomings, such as omission, overly
correcting ambiguous source content, and buzzword issues, resulting in the loss
of stylized information. Our findings underscore the effectiveness of MQM-Chat
in evaluating chat translation, emphasizing the importance of stylized content
and dialogue consistency for future studies.

摘要：聊天對話的複雜性對機器翻譯模型造成極大的挑戰。為了滿足對精確評估指標的需求以解決聊天翻譯的問題，本研究引入了聊天翻譯的多維度品質指標 (MQM-Chat)。透過使用 MQM-Chat 對五個模型進行的實驗，我們觀察到所有模型都會產生某些根本性的錯誤，而每個模型都有不同的缺點，例如遺漏、過度修正模稜兩可的原始內容，以及流行用語問題，導致文體化資訊的遺失。我們的研究結果強調了 MQM-Chat 在評估聊天翻譯中的有效性，並強調了文體化內容和對話一致性對未來研究的重要性。

##### **Kangaroo: A Powerful Video-Language Model Supporting Long-context Video Input**
2408.15542v1 by Jiajun Liu, Yibing Wang, Hanghang Ma, Xiaoping Wu, Xiaoqi Ma, Xiaoming Wei, Jianbin Jiao, Enhua Wu, Jie Hu

Rapid advancements have been made in extending Large Language Models (LLMs)
to Large Multi-modal Models (LMMs). However, extending input modality of LLMs
to video data remains a challenging endeavor, especially for long videos. Due
to insufficient access to large-scale high-quality video data and the excessive
compression of visual features, current methods exhibit limitations in
effectively processing long videos. In this paper, we introduce Kangaroo, a
powerful Video LMM aimed at addressing these challenges. Confronted with issue
of inadequate training data, we develop a data curation system to build a
large-scale dataset with high-quality annotations for vision-language
pre-training and instruction tuning. In addition, we design a curriculum
training pipeline with gradually increasing resolution and number of input
frames to accommodate long videos. Evaluation results demonstrate that, with 8B
parameters, Kangaroo achieves state-of-the-art performance across a variety of
video understanding benchmarks while exhibiting competitive results on others.
Particularly, on benchmarks specialized for long videos, Kangaroo excels some
larger models with over 10B parameters and proprietary models.

摘要：大型語言模型 (LLM) 已快速發展，並擴展到大型多模態模型 (LMM)。然而，將 LLM 的輸入模式擴展到影片資料仍是一項艱鉅的任務，尤其是對於長影片。由於無法充分存取大量高品質的影片資料，以及視覺特徵過度壓縮，目前的方法在有效處理長影片方面存在限制。在本文中，我們介紹 Kangaroo，這是一個強大的影片 LMM，旨在解決這些挑戰。面對訓練資料不足的問題，我們開發了一個資料整理系統，以建立一個具備高品質註解的大規模資料集，用於視覺語言預訓練和指令微調。此外，我們設計了一個課程訓練管道，逐步增加解析度和輸入幀數，以容納長影片。評估結果表明，Kangaroo 在 8B 參數下，在各種影片理解基準測試中均達到最先進的效能，同時在其他基準測試中也展現出具有競爭力的結果。特別是在針對長影片的基準測試中，Kangaroo 勝過一些參數超過 10B 的大型模型和專有模型。

##### **TrafficGamer: Reliable and Flexible Traffic Simulation for Safety-Critical Scenarios with Game-Theoretic Oracles**
2408.15538v1 by Guanren Qiao, Guorui Quan, Jiawei Yu, Shujun Jia, Guiliang Liu

While modern Autonomous Vehicle (AV) systems can develop reliable driving
policies under regular traffic conditions, they frequently struggle with
safety-critical traffic scenarios. This difficulty primarily arises from the
rarity of such scenarios in driving datasets and the complexities associated
with predictive modeling among multiple vehicles. To support the testing and
refinement of AV policies, simulating safety-critical traffic events is an
essential challenge to be addressed. In this work, we introduce TrafficGamer,
which facilitates game-theoretic traffic simulation by viewing common road
driving as a multi-agent game. In evaluating the empirical performance across
various real-world datasets, TrafficGamer ensures both fidelity and
exploitability of the simulated scenarios, guaranteeing that they not only
statically align with real-world traffic distribution but also efficiently
capture equilibriums for representing safety-critical scenarios involving
multiple agents. Additionally, the results demonstrate that TrafficGamer
exhibits highly flexible simulation across various contexts. Specifically, we
demonstrate that the generated scenarios can dynamically adapt to equilibriums
of varying tightness by configuring risk-sensitive constraints during
optimization. To the best of our knowledge, TrafficGamer is the first simulator
capable of generating diverse traffic scenarios involving multiple agents. We
have provided a demo webpage for the project at
https://qiaoguanren.github.io/trafficgamer-demo/.

摘要：儘管現代自動駕駛（AV）系統可以在一般交通狀況下發展出可靠的駕駛策略，但它們經常在安全關鍵的交通場景中掙扎。這種困難主要來自於此類場景在駕駛數據集中的稀少性，以及與多輛車輛之間的預測模型相關的複雜性。為了支援 AV 策略的測試和改進，模擬安全關鍵的交通事件是一個必須解決的基本挑戰。在這項工作中，我們引入了 TrafficGamer，它通過將常見的道路駕駛視為多主體遊戲，來促進博弈論交通模擬。在評估各種真實世界數據集中的經驗效能時，TrafficGamer 確保了模擬場景的保真度和可利用性，保證它們不僅在靜態上與真實世界的交通分佈保持一致，而且還能有效地捕捉涉及多個主體的安全關鍵場景的均衡。此外，結果表明，TrafficGamer 在各種背景下表現出高度靈活的模擬。具體來說，我們證明了生成的場景可以通過在最佳化過程中配置風險敏感約束來動態適應不同緊密度的均衡。據我們所知，TrafficGamer 是第一個能夠生成涉及多個主體的多樣化交通場景的模擬器。我們已經為這個專案提供了一個試用網頁，網址是 https://qiaoguanren.github.io/trafficgamer-demo/。

##### **LRP4RAG: Detecting Hallucinations in Retrieval-Augmented Generation via Layer-wise Relevance Propagation**
2408.15533v2 by Haichuan Hu, Yuhan Sun, Quanjun Zhang

Retrieval-Augmented Generation (RAG) has become a primary technique for
mitigating hallucinations in large language models (LLMs). However, incomplete
knowledge extraction and insufficient understanding can still mislead LLMs to
produce irrelevant or even contradictory responses, which means hallucinations
persist in RAG. In this paper, we propose LRP4RAG, a method based on the
Layer-wise Relevance Propagation (LRP) algorithm for detecting hallucinations
in RAG. Specifically, we first utilize LRP to compute the relevance between the
input and output of the RAG generator. We then apply further extraction and
resampling to the relevance matrix. The processed relevance data are input into
multiple classifiers to determine whether the output contains hallucinations.
To the best of our knowledge, this is the first time that LRP has been used for
detecting RAG hallucinations, and extensive experiments demonstrate that
LRP4RAG outperforms existing baselines.

摘要：檢索增強生成（RAG）已成為減輕大型語言模型（LLM）中幻覺的主要技術。然而，不完整的知識提取和理解不足仍可能誤導 LLM 產生不相關甚至相互矛盾的回應，這意味著幻覺在 RAG 中仍然存在。在本文中，我們提出了 LRP4RAG，一種基於層級相關性傳播（LRP）演算法的方法，用於檢測 RAG 中的幻覺。具體來說，我們首先利用 LRP 來計算 RAG 生成器的輸入和輸出之間的相關性。然後，我們對相關性矩陣進行進一步的提取和重新抽樣。處理過的相關性資料被輸入到多個分類器中，以確定輸出是否包含幻覺。據我們所知，這是 LRP 首次用於檢測 RAG 幻覺，大量實驗表明 LRP4RAG 優於現有的基線。

##### **Dolphin: Long Context as a New Modality for Energy-Efficient On-Device Language Models**
2408.15518v1 by Wei Chen, Zhiyuan Li, Shuo Xin, Yihao Wang

This paper presents Dolphin, a novel decoder-decoder architecture for
energy-efficient processing of long contexts in language models. Our approach
addresses the significant energy consumption and latency challenges inherent in
on-device models. Dolphin employs a compact 0.5B parameter decoder to distill
extensive contextual information into a memory embedding, substantially
reducing the input length for the primary 7B parameter decoder model. Inspired
by vision-language models, we repurpose the image embedding projector to encode
long textual contexts, effectively treating extended context as a distinct
modality. This innovative method enables processing of substantially longer
contexts without the typical computational overhead associated with extended
input sequences. Empirical evaluations demonstrate a 10-fold improvement in
energy efficiency and a 5-fold reduction in latency compared to conventional
full-length context processing methods without losing quality of the response.
Our work contributes to the development of more sustainable and scalable
language models for on-device applications, addressing the critical need for
energy-efficient and responsive AI technologies in resource-constrained
environments while maintaining the accuracy to understand long contexts. This
research has implications for the broader field of natural language processing,
particularly in the domain of efficient model design for resource-limited
settings. By enabling more sophisticated AI capabilities on edge devices,
Dolphin paves the way for advanced language processing in a wide range of
applications where computational resources are at a premium. The Dolphin model
is publicly available at https://huggingface.co/NexaAIDev/Dolphin.

摘要：這篇論文提出 Dolphin，一種新穎的解碼器-解碼器架構，用於語言模型中長文本的節能處理。我們的做法解決了設備模型中固有的顯著能耗和延遲挑戰。Dolphin 採用緊湊的 0.5B 參數解碼器，將廣泛的上下文資訊提煉到記憶體嵌入中，大幅減少主要 7B 參數解碼器模型的輸入長度。受到視覺語言模型的啟發，我們重新利用影像嵌入投影器來編碼長文本上下文，有效地將擴充的上下文視為一種不同的模態。這種創新的方法可以在不產生擴充輸入序列通常會有的運算負擔下，處理大幅更長的上下文。經驗評估證明，與傳統的全長度上下文處理方法相比，能效提升了 10 倍，延遲減少了 5 倍，同時不損失回應品質。我們的研究有助於開發更永續且可擴充的設備應用語言模型，滿足資源受限環境中對節能且有反應的 AI 技術的關鍵需求，同時維持理解長文本的準確度。這項研究對自然語言處理的廣泛領域有影響，特別是在資源有限的設定中高效模型設計的領域。透過在邊緣裝置上啟用更精密的 AI 功能，Dolphin 為廣泛的應用中進階的語言處理鋪路，在這些應用中運算資源非常珍貴。Dolphin 模型已在 https://huggingface.co/NexaAIDev/Dolphin 公開。

##### **Continual-learning-based framework for structural damage recognition**
2408.15513v1 by Jiangpeng Shu, Jiawei Zhang, Reachsak Ly, Fangzheng Lin, Yuanfeng Duan

Multi-damage is common in reinforced concrete structures and leads to the
requirement of large number of neural networks, parameters and data storage, if
convolutional neural network (CNN) is used for damage recognition. In addition,
conventional CNN experiences catastrophic forgetting and training inefficiency
as the number of tasks increases during continual learning, leading to large
accuracy decrease of previous learned tasks. To address these problems, this
study proposes a continuallearning-based damage recognition model (CLDRM) which
integrates the learning without forgetting continual learning method into the
ResNet-34 architecture for the recognition of damages in RC structures as well
as relevant structural components. Three experiments for four recognition tasks
were designed to validate the feasibility and effectiveness of the CLDRM
framework. In this way, it reduces both the prediction time and data storage by
about 75% in four tasks of continuous learning. Three experiments for four
recognition tasks were designed to validate the feasibility and effectiveness
of the CLDRM framework. By gradual feature fusion, CLDRM outperformed other
methods by managed to achieve high accuracy in the damage recognition and
classification. As the number of recognition tasks increased, CLDRM also
experienced smaller decrease of the previous learned tasks. Results indicate
that the CLDRM framework successfully performs damage recognition and
classification with reasonable accuracy and effectiveness.

摘要：在鋼筋混凝土結構中，多重損壞很常見，如果使用卷積神經網路 (CNN) 來進行損害辨識，則需要大量的網路、參數和資料儲存。此外，傳統的 CNN 在持續學習過程中，隨著任務數量的增加，會出現災難性遺忘和訓練效率低下的問題，導致先前學習任務的準確度大幅下降。為了解決這些問題，本研究提出了一個基於持續學習的損害辨識模型 (CLDRM)，它將不遺忘的持續學習方法整合到 ResNet-34 架構中，用於辨識 RC 結構及其相關結構組件的損害。設計了四個辨識任務的三個實驗，以驗證 CLDRM 框架的可行性和有效性。這樣一來，在持續學習的四個任務中，預測時間和資料儲存量都減少了約 75%。設計了四個辨識任務的三個實驗，以驗證 CLDRM 框架的可行性和有效性。透過漸進式特徵融合，CLDRM 優於其他方法，在損害辨識和分類中實現了高準確度。隨著辨識任務數量的增加，CLDRM 對先前學習任務的損害也較小。結果表明，CLDRM 框架成功地執行損害辨識和分類，具有合理的準確度和有效性。

##### **Towards Fully Autonomous Research Powered by LLMs: Case Study on Simulations**
2408.15512v1 by Zhihan Liu, Yubo Chai, Jianfeng Li

The advent of Large Language Models (LLMs) has created new opportunities for
the automation of scientific research, spanning both experimental processes and
computational simulations. This study explores the feasibility of constructing
an autonomous simulation agent (ASA) powered by LLM, through sophisticated API
integration, to automate the entire research process, from experimental design,
remote upload and simulation execution, data analysis, to report compilation.
Using a simulation problem of polymer chain conformations as a case study, we
assessed the performance of ASAs powered by different LLMs including
GPT-4-Turbo. Our findings revealed that ASA-GPT-4o achieved near-flawless
execution on designated research missions, underscoring the potential of LLMs
to manage complete scientific investigations autonomously. The outlined
automation can be iteratively performed up to twenty cycles without human
intervention, illustrating the potential of LLMs for large-scale autonomous
research endeavors. Additionally, we discussed the intrinsic traits of ASAs in
managing extensive tasks, focusing on self-validation mechanisms and the
balance between local attention and global oversight.

摘要：大型語言模型 (LLM) 的出現為科學研究的自動化創造了新機會，涵蓋實驗過程和計算模擬。本研究探討了構建由 LLM 驅動的自主模擬代理 (ASA) 的可行性，通過複雜的 API 整合，自動化整個研究過程，從實驗設計、遠程上傳和模擬執行、數據分析到報告編譯。使用聚合物鏈構象的模擬問題作為案例研究，我們評估了由 GPT-4-Turbo 等不同 LLM 驅動的 ASA 的性能。我們的研究結果表明，ASA-GPT-4o 在指定的研究任務中實現了近乎完美的執行，強調了 LLM 自主管理完整科學調查的潛力。概述的自動化可以在沒有人工干預的情況下反覆執行多達 20 個週期，說明了 LLM 在大規模自主研究工作中的潛力。此外，我們討論了 ASA 在管理廣泛任務中的內在特徵，重點關注自我驗證機制以及局部關注與全局監督之間的平衡。

##### **AeroVerse: UAV-Agent Benchmark Suite for Simulating, Pre-training, Finetuning, and Evaluating Aerospace Embodied World Models**
2408.15511v1 by Fanglong Yao, Yuanchang Yue, Youzhi Liu, Xian Sun, Kun Fu

Aerospace embodied intelligence aims to empower unmanned aerial vehicles
(UAVs) and other aerospace platforms to achieve autonomous perception,
cognition, and action, as well as egocentric active interaction with humans and
the environment. The aerospace embodied world model serves as an effective
means to realize the autonomous intelligence of UAVs and represents a necessary
pathway toward aerospace embodied intelligence. However, existing embodied
world models primarily focus on ground-level intelligent agents in indoor
scenarios, while research on UAV intelligent agents remains unexplored. To
address this gap, we construct the first large-scale real-world image-text
pre-training dataset, AerialAgent-Ego10k, featuring urban drones from a
first-person perspective. We also create a virtual image-text-pose alignment
dataset, CyberAgent Ego500k, to facilitate the pre-training of the aerospace
embodied world model. For the first time, we clearly define 5 downstream tasks,
i.e., aerospace embodied scene awareness, spatial reasoning, navigational
exploration, task planning, and motion decision, and construct corresponding
instruction datasets, i.e., SkyAgent-Scene3k, SkyAgent-Reason3k, SkyAgent-Nav3k
and SkyAgent-Plan3k, and SkyAgent-Act3k, for fine-tuning the aerospace
embodiment world model. Simultaneously, we develop SkyAgentEval, the downstream
task evaluation metrics based on GPT-4, to comprehensively, flexibly, and
objectively assess the results, revealing the potential and limitations of
2D/3D visual language models in UAV-agent tasks. Furthermore, we integrate over
10 2D/3D visual-language models, 2 pre-training datasets, 5 finetuning
datasets, more than 10 evaluation metrics, and a simulator into the benchmark
suite, i.e., AeroVerse, which will be released to the community to promote
exploration and development of aerospace embodied intelligence.

摘要：航空體現智能旨在賦予無人機 (UAV) 和其他航空平台自主感知、認知和行動的能力，以及與人類和環境的以自我為中心的主動互動。航空體現世界模型作為實現無人機自主智能的有效手段，並代表了通往航空體現智能的必要途徑。然而，現有的體現世界模型主要關注室內場景中的地面智能代理，而對無人機智能代理的研究仍未探索。為了解決這一差距，我們構建了第一個大型真實世界圖像文本預訓練數據集 AerialAgent-Ego10k，以第一人稱視角展示城市無人機。我們還創建了一個虛擬圖像文本姿勢對齊數據集 CyberAgent Ego500k，以促進航空體現世界模型的預訓練。我們首次明確定義了 5 個下游任務，即航空體現場景感知、空間推理、導航探索、任務規劃和運動決策，並構建了相應的指令數據集，即 SkyAgent-Scene3k、SkyAgent-Reason3k、SkyAgent-Nav3k 和 SkyAgent-Plan3k 以及 SkyAgent-Act3k，用於微調航空體現世界模型。同時，我們開發了 SkyAgentEval，這是一個基於 GPT-4 的下游任務評估指標，用於全面、靈活、客觀地評估結果，揭示了 2D/3D 視覺語言模型在無人機代理任務中的潛力和局限性。此外，我們將超過 10 個 2D/3D 視覺語言模型、2 個預訓練數據集、5 個微調數據集、超過 10 個評估指標和一個模擬器整合到基準套件中，即 AeroVerse，它將發布給社區以促進航空體現智能的探索和發展。

##### **Measuring the Reliability of Causal Probing Methods: Tradeoffs, Limitations, and the Plight of Nullifying Interventions**
2408.15510v1 by Marc Canby, Adam Davies, Chirag Rastogi, Julia Hockenmaier

Causal probing is an approach to interpreting foundation models, such as
large language models, by training probes to recognize latent properties of
interest from embeddings, intervening on probes to modify this representation,
and analyzing the resulting changes in the model's behavior. While some recent
works have cast doubt on the theoretical basis of several leading causal
probing intervention methods, it has been unclear how to systematically and
empirically evaluate their effectiveness in practice. To address this problem,
we propose a general empirical analysis framework to evaluate the reliability
of causal probing interventions, formally defining and quantifying two key
causal probing desiderata: completeness (fully transforming the representation
of the target property) and selectivity (minimally impacting other properties).
Our formalism allows us to make the first direct comparisons between different
families of causal probing methods (e.g., linear vs. nonlinear or
counterfactual vs. nullifying interventions). We conduct extensive experiments
across several leading methods, finding that (1) there is an inherent tradeoff
between these criteria, and no method is able to consistently satisfy both at
once; and (2) across the board, nullifying interventions are always far less
complete than counterfactual interventions, indicating that nullifying methods
may not be an effective approach to causal probing.

摘要：因果探測是一種解釋基礎模型的方法，例如通過訓練探針來識別感興趣的潛在屬性，從嵌入干預探針來修改此表示，並分析模型行為中產生的變化，從而解釋基礎模型，例如大型語言模型。儘管最近一些著作對幾種領先的因果探測干預方法的理論基礎提出質疑，但尚不清楚如何系統且經驗性地評估其在實踐中的有效性。為了解決此問題，我們提出了一個通用的經驗分析框架來評估因果探測干預的可靠性，正式定義和量化了兩個關鍵的因果探測理想：完整性（完全轉換目標屬性的表示）和選擇性（對其他屬性的影響最小）。我們的形式主義使我們能夠在不同的因果探測方法族（例如線性與非線性或反事實與無效化干預）之間進行首次直接比較。我們對幾種領先的方法進行了廣泛的實驗，發現（1）這些標準之間存在固有的權衡，並且沒有任何方法能夠始終同時滿足這兩個標準；（2）總的來說，無效化干預總是遠低於反事實干預，這表明無效化方法可能不是因果探測的有效方法。

##### **EmoAttack: Utilizing Emotional Voice Conversion for Speech Backdoor Attacks on Deep Speech Classification Models**
2408.15508v1 by Wenhan Yao, Zedong XingXiarun Chen, Jia Liu, yongqiang He, Weiping Wen

Deep speech classification tasks, mainly including keyword spotting and
speaker verification, play a crucial role in speech-based human-computer
interaction. Recently, the security of these technologies has been demonstrated
to be vulnerable to backdoor attacks. Specifically speaking, speech samples are
attacked by noisy disruption and component modification in present triggers. We
suggest that speech backdoor attacks can strategically focus on emotion, a
higher-level subjective perceptual attribute inherent in speech. Furthermore,
we proposed that emotional voice conversion technology can serve as the speech
backdoor attack trigger, and the method is called EmoAttack. Based on this, we
conducted attack experiments on two speech classification tasks, showcasing
that EmoAttack method owns impactful trigger effectiveness and its remarkable
attack success rate and accuracy variance. Additionally, the ablation
experiments found that speech with intensive emotion is more suitable to be
targeted for attacks.

摘要：深度語音分類任務，主要包括關鍵字偵測和說話者驗證，在基於語音的人機互動中扮演至關重要的角色。最近，這些技術的安全性已被證明容易受到後門攻擊。具體來說，語音樣本會受到當前觸發器中的雜訊干擾和元件修改攻擊。我們建議語音後門攻擊可以策略性地專注於情緒，這是一個內含於語音中的較高層次主觀感知屬性。此外，我們提出情緒化語音轉換技術可以用作語音後門攻擊觸發器，而此方法稱為 EmoAttack。基於此，我們對兩個語音分類任務進行了攻擊實驗，展示了 EmoAttack 方法擁有強大的觸發效果，以及其顯著的攻擊成功率和準確度差異。此外，消融實驗發現，帶有強烈情緒的語音更適合成為攻擊目標。

##### **What Machine Learning Tells Us About the Mathematical Structure of Concepts**
2408.15507v1 by Jun Otsuka

This paper examines the connections among various approaches to understanding
concepts in philosophy, cognitive science, and machine learning, with a
particular focus on their mathematical nature. By categorizing these approaches
into Abstractionism, the Similarity Approach, the Functional Approach, and the
Invariance Approach, the study highlights how each framework provides a
distinct mathematical perspective for modeling concepts. The synthesis of these
approaches bridges philosophical theories and contemporary machine learning
models, providing a comprehensive framework for future research. This work
emphasizes the importance of interdisciplinary dialogue, aiming to enrich our
understanding of the complex relationship between human cognition and
artificial intelligence.

摘要：本文探討哲學、認知科學和機器學習中理解概念的各種方法之間的關聯，特別關注其數學性質。研究將這些方法歸類為抽象主義、相似性方法、功能方法和不變方法，強調每個架構如何提供一個不同的數學觀點來建模概念。這些方法的綜合彌合了哲學理論和當代機器學習模型，為未來的研究提供了一個全面的框架。這項工作強調跨學科對話的重要性，旨在豐富我們對人類認知和人工智慧之間複雜關係的理解。

##### **MODULI: Unlocking Preference Generalization via Diffusion Models for Offline Multi-Objective Reinforcement Learning**
2408.15501v1 by Yifu Yuan, Zhenrui Zheng, Zibin Dong, Jianye Hao

Multi-objective Reinforcement Learning (MORL) seeks to develop policies that
simultaneously optimize multiple conflicting objectives, but it requires
extensive online interactions. Offline MORL provides a promising solution by
training on pre-collected datasets to generalize to any preference upon
deployment. However, real-world offline datasets are often conservatively and
narrowly distributed, failing to comprehensively cover preferences, leading to
the emergence of out-of-distribution (OOD) preference areas. Existing offline
MORL algorithms exhibit poor generalization to OOD preferences, resulting in
policies that do not align with preferences. Leveraging the excellent
expressive and generalization capabilities of diffusion models, we propose
MODULI (Multi-objective Diffusion Planner with Sliding Guidance), which employs
a preference-conditioned diffusion model as a planner to generate trajectories
that align with various preferences and derive action for decision-making. To
achieve accurate generation, MODULI introduces two return normalization methods
under diverse preferences for refining guidance. To further enhance
generalization to OOD preferences, MODULI proposes a novel sliding guidance
mechanism, which involves training an additional slider adapter to capture the
direction of preference changes. Incorporating the slider, it transitions from
in-distribution (ID) preferences to generating OOD preferences, patching, and
extending the incomplete Pareto front. Extensive experiments on the D4MORL
benchmark demonstrate that our algorithm outperforms state-of-the-art Offline
MORL baselines, exhibiting excellent generalization to OOD preferences.

摘要：多目標強化學習 (MORL) 旨在開發策略，同時最佳化多個衝突目標，但它需要廣泛的線上互動。離線 MORL 提供了一個有前途的解決方案，透過在預先收集的資料集上訓練，以便在部署時概括到任何偏好。然而，真實世界的離線資料集通常保守且分佈狹窄，無法全面涵蓋偏好，導致出現分佈外 (OOD) 偏好區域。現有的離線 MORL 演算法對 OOD 偏好表現出不佳的概括性，導致產生的策略與偏好不符。我們利用擴散模型出色的表達和概括能力，提出了 MODULI（具有滑動引導的多目標擴散規劃器），它採用偏好條件擴散模型作為規劃器，生成與各種偏好相符的軌跡，並推導出決策制定所需的動作。為了實現準確生成，MODULI 引入了兩種回報正規化方法，在不同的偏好下用於精煉引導。為了進一步增強對 OOD 偏好的概括性，MODULI 提出了一種新穎的滑動引導機制，其中涉及訓練一個額外的滑塊適配器來捕捉偏好變化的方向。結合滑塊，它從分佈內 (ID) 偏好過渡到生成 OOD 偏好、修補和擴充不完整的帕累托前緣。在 D4MORL 基準上的廣泛實驗表明，我們的演算法優於最先進的離線 MORL 基準，對 OOD 偏好表現出出色的概括性。

##### **Deep Learning to Predict Late-Onset Breast Cancer Metastasis: the Single Hyperparameter Grid Search (SHGS) Strategy for Meta Tuning Concerning Deep Feed-forward Neural Network**
2408.15498v1 by Yijun Zhou, Om Arora-Jain, Xia Jiang

While machine learning has advanced in medicine, its widespread use in
clinical applications, especially in predicting breast cancer metastasis, is
still limited. We have been dedicated to constructing a DFNN model to predict
breast cancer metastasis n years in advance. However, the challenge lies in
efficiently identifying optimal hyperparameter values through grid search,
given the constraints of time and resources. Issues such as the infinite
possibilities for continuous hyperparameters like l1 and l2, as well as the
time-consuming and costly process, further complicate the task. To address
these challenges, we developed Single Hyperparameter Grid Search (SHGS)
strategy, serving as a preselection method before grid search. Our experiments
with SHGS applied to DFNN models for breast cancer metastasis prediction focus
on analyzing eight target hyperparameters: epochs, batch size, dropout, L1, L2,
learning rate, decay, and momentum. We created three figures, each depicting
the experiment results obtained from three LSM-I-10-Plus-year datasets. These
figures illustrate the relationship between model performance and the target
hyperparameter values. For each hyperparameter, we analyzed whether changes in
this hyperparameter would affect model performance, examined if there were
specific patterns, and explored how to choose values for the particular
hyperparameter. Our experimental findings reveal that the optimal value of a
hyperparameter is not only dependent on the dataset but is also significantly
influenced by the settings of other hyperparameters. Additionally, our
experiments suggested some reduced range of values for a target hyperparameter,
which may be helpful for low-budget grid search. This approach serves as a
prior experience and foundation for subsequent use of grid search to enhance
model performance.

摘要：儘管機器學習在醫學領域已有所進展，但其在臨床應用中的廣泛使用，特別是在預測乳癌轉移方面，仍有其限制。我們致力於建構 DFNN 模型，以預測乳癌轉移 n 年。然而，挑戰在於透過網格搜尋有效率地找出最佳超參數值，這受到時間和資源的限制。諸如 l1 和 l2 等連續超參數的可能性無窮，以及耗時且昂貴的過程等問題，更讓這項任務變得複雜。為了應對這些挑戰，我們開發了單一超參數網格搜尋 (SHGS) 策略，作為網格搜尋前的預選方法。我們針對乳癌轉移預測應用的 DFNN 模型進行 SHGS 實驗，重點分析八個目標超參數：epoch 次數、批次大小、中斷、L1、L2、學習率、衰減和動量。我們製作了三幅圖，每幅圖都描繪了從三個 LSM-I-10-Plus-year 資料集獲得的實驗結果。這些圖表說明了模型效能與目標超參數值之間的關係。對於每個超參數，我們分析了超參數的變動是否會影響模型效能，並檢視是否有特定模式，以及如何針對特定超參數選擇值。我們的實驗結果顯示，超參數的最佳值不僅取決於資料集，也受到其他超參數設定的顯著影響。此外，我們的實驗建議縮小目標超參數值的範圍，這可能有助於低預算的網格搜尋。此方法可作為後續使用網格搜尋以增強模型效能的先前經驗和基礎。

##### **ReMamba: Equip Mamba with Effective Long-Sequence Modeling**
2408.15496v2 by Danlong Yuan, Jiahao Liu, Bei Li, Huishuai Zhang, Jingang Wang, Xunliang Cai, Dongyan Zhao

While the Mamba architecture demonstrates superior inference efficiency and
competitive performance on short-context natural language processing (NLP)
tasks, empirical evidence suggests its capacity to comprehend long contexts is
limited compared to transformer-based models. In this study, we investigate the
long-context efficiency issues of the Mamba models and propose ReMamba, which
enhances Mamba's ability to comprehend long contexts. ReMamba incorporates
selective compression and adaptation techniques within a two-stage re-forward
process, incurring minimal additional inference costs overhead. Experimental
results on the LongBench and L-Eval benchmarks demonstrate ReMamba's efficacy,
improving over the baselines by 3.2 and 1.6 points, respectively, and attaining
performance almost on par with same-size transformer models.

摘要：儘管 Mamba 架構在短語境自然語言處理 (NLP) 任務上展現出優異的推論效率和競爭力，但實證證據顯示，與基於轉換器的模型相比，其理解長語境的容量有限。在這項研究中，我們探討 Mamba 模型在長語境效率上的問題，並提出 ReMamba，它增強了 Mamba 理解長語境的能力。ReMamba 在兩階段的重新前向處理中納入了選擇性壓縮和適應技術，產生最小的額外推論成本負擔。LongBench 和 L-Eval 基準上的實驗結果證明了 ReMamba 的效能，分別比基準線改進了 3.2 和 1.6 個百分點，並達到與相同大小的轉換器模型幾乎相同的效能。

##### **Remove Symmetries to Control Model Expressivity**
2408.15495v1 by Liu Ziyin, Yizhou Xu, Isaac Chuang

When symmetry is present in the loss function, the model is likely to be
trapped in a low-capacity state that is sometimes known as a "collapse." Being
trapped in these low-capacity states can be a major obstacle to training across
many scenarios where deep learning technology is applied. We first prove two
concrete mechanisms through which symmetries lead to reduced capacities and
ignored features during training. We then propose a simple and theoretically
justified algorithm, syre, to remove almost all symmetry-induced low-capacity
states in neural networks. The proposed method is shown to improve the training
of neural networks in scenarios when this type of entrapment is especially a
concern. A remarkable merit of the proposed method is that it is model-agnostic
and does not require any knowledge of the symmetry.

摘要：当损失函数中存在对称性时，模型很可能会陷入一种低容量状态，有时称为“坍塌”。陷入这些低容量状态可能是应用深度学习技术时跨多个场景进行训练的主要障碍。我们首先证明了两种具体机制，通过这些机制，对称性会导致容量减少和在训练期间忽略特征。然后，我们提出了一种简单且理论上合理的算法 syre，以消除神经网络中几乎所有对称性引起的低容量状态。所提出的方法已被证明可以改善神经网络在特别关注这种类型的陷井时的训练。所提出方法的一个显着优点是它与模型无关，并且不需要任何对称性知识。

##### **Enhancing and Accelerating Large Language Models via Instruction-Aware Contextual Compression**
2408.15491v1 by Haowen Hou, Fei Ma, Binwen Bai, Xinxin Zhu, Fei Yu

Large Language Models (LLMs) have garnered widespread attention due to their
remarkable performance across various tasks. However, to mitigate the issue of
hallucinations, LLMs often incorporate retrieval-augmented pipeline to provide
them with rich external knowledge and context. Nevertheless, challenges stem
from inaccurate and coarse-grained context retrieved from the retriever.
Supplying irrelevant context to the LLMs can result in poorer responses,
increased inference latency, and higher costs. This paper introduces a method
called Instruction-Aware Contextual Compression, which filters out less
informative content, thereby accelerating and enhancing the use of LLMs. The
experimental results demonstrate that Instruction-Aware Contextual Compression
notably reduces memory consumption and minimizes generation latency while
maintaining performance levels comparable to those achieved with the use of the
full context. Specifically, we achieved a 50% reduction in context-related
costs, resulting in a 5% reduction in inference memory usage and a 2.2-fold
increase in inference speed, with only a minor drop of 0.047 in Rouge-1. These
findings suggest that our method strikes an effective balance between
efficiency and performance.

摘要：大型語言模型 (LLM) 因其在各種任務中的出色表現而廣受關注。然而，為了減輕幻覺問題，LLM 通常會整合檢索增強管道，為它們提供豐富的外部知識和背景。儘管如此，挑戰來自檢索器檢索到的不準確且粗略的背景。向 LLM 提供無關的背景可能會導致較差的回應、增加的推論延遲和更高的成本。本文介紹了一種稱為指令感知上下文壓縮的方法，它可以過濾掉信息量較少的内容，從而加速和增強 LLM 的使用。實驗結果表明，指令感知上下文壓縮顯著降低了內存消耗，並最大程度地減少了生成延遲，同時保持與使用完整背景時相當的性能水平。具體而言，我們將與上下文相關的成本降低了 50%，從而將推論內存使用量降低了 5%，將推論速度提高了 2.2 倍，而 Rouge-1 僅下降了 0.047。這些發現表明，我們的這種方法在效率和性能之間取得了有效的平衡。

##### **Legilimens: Practical and Unified Content Moderation for Large Language Model Services**
2408.15488v1 by Jialin Wu, Jiangyi Deng, Shengyuan Pang, Yanjiao Chen, Jiayang Xu, Xinfeng Li, Wenyuan Xu

Given the societal impact of unsafe content generated by large language
models (LLMs), ensuring that LLM services comply with safety standards is a
crucial concern for LLM service providers. Common content moderation methods
are limited by an effectiveness-and-efficiency dilemma, where simple models are
fragile while sophisticated models consume excessive computational resources.
In this paper, we reveal for the first time that effective and efficient
content moderation can be achieved by extracting conceptual features from
chat-oriented LLMs, despite their initial fine-tuning for conversation rather
than content moderation. We propose a practical and unified content moderation
framework for LLM services, named Legilimens, which features both effectiveness
and efficiency. Our red-team model-based data augmentation enhances the
robustness of Legilimens against state-of-the-art jailbreaking. Additionally,
we develop a framework to theoretically analyze the cost-effectiveness of
Legilimens compared to other methods. We have conducted extensive experiments
on five host LLMs, seventeen datasets, and nine jailbreaking methods to verify
the effectiveness, efficiency, and robustness of Legilimens against normal and
adaptive adversaries. A comparison of Legilimens with both commercial and
academic baselines demonstrates the superior performance of Legilimens.
Furthermore, we confirm that Legilimens can be applied to few-shot scenarios
and extended to multi-label classification tasks.

摘要：鉴于大型语言模型 (LLM) 所产生的不安全内容对社会造成的影响，确保 LLM 服务符合安全标准是 LLM 服务提供商至关重要的问题。常见的內容审核方法受到效率和效能两难困境的限制，其中简单的模型很脆弱，而复杂的模型则消耗过多的计算资源。在本文中，我们首次揭示了有效的且高效的內容审核可以通过从面向聊天的 LLM 中提取概念特征来实现，尽管它们最初是针对对话而不是內容审核进行微调的。我们为 LLM 服务提出了一种实用且统一的內容审核框架，名为 Legilimens，它同时具有有效性和效率。我们基于红队模型的数据增强增强了 Legilimens 对最先进越狱的鲁棒性。此外，我们开发了一个框架来从理论上分析 Legilimens 与其他方法的成本效益。我们对五个主机 LLM、十七个数据集和九种越狱方法进行了广泛的实验，以验证 Legilimens 对正常和自适应对抗者的有效性、效率和鲁棒性。将 Legilimens 与商业和学术基准进行比较，证明了 Legilimens 的卓越性能。此外，我们确认 Legilimens 可以应用于小样本场景并扩展到多标签分类任务。

##### **CTRQNets & LQNets: Continuous Time Recurrent and Liquid Quantum Neural Networks**
2408.15462v1 by Alejandro Mayorga, Alexander Yuan, Andrew Yuan, Tyler Wooldridge, Xiaodi Wang

Neural networks have continued to gain prevalence in the modern era for their
ability to model complex data through pattern recognition and behavior
remodeling. However, the static construction of traditional neural networks
inhibits dynamic intelligence. This makes them inflexible to temporal changes
in data and unfit to capture complex dependencies. With the advent of quantum
technology, there has been significant progress in creating quantum algorithms.
In recent years, researchers have developed quantum neural networks that
leverage the capabilities of qubits to outperform classical networks. However,
their current formulation exhibits a static construction limiting the system's
dynamic intelligence. To address these weaknesses, we develop a Liquid Quantum
Neural Network (LQNet) and a Continuous Time Recurrent Quantum Neural Network
(CTRQNet). Both models demonstrate a significant improvement in accuracy
compared to existing quantum neural networks (QNNs), achieving accuracy
increases as high as 40\% on CIFAR 10 through binary classification. We propose
LQNets and CTRQNets might shine a light on quantum machine learning's black
box.

摘要：神经網路在現代持續獲得普及，因為它們能夠透過模式辨識和行為改造來建模複雜的資料。然而，傳統神經網路的靜態建構會抑制動態智慧。這使得它們無法靈活應對資料中的時間變化，也不適合擷取複雜的依存關係。隨著量子技術的出現，在建立量子演算法方面有顯著的進展。近年來，研究人員開發了量子神經網路，利用量子位元的能力來超越經典網路。然而，它們目前的公式表現出靜態建構，限制了系統的動態智慧。為了解決這些弱點，我們開發了液態量子神經網路 (LQNet) 和連續時間遞迴量子神經網路 (CTRQNet)。與現有的量子神經網路 (QNN) 相比，這兩個模型都顯著提升了準確性，在 CIFAR 10 中透過二元分類，準確性提高了 40%。我們提出 LQNets 和 CTRQNets 可能有助於了解量子機器學習的黑盒子。

##### **Online Event-Triggered Switching for Frequency Control in Power Grids with Variable Inertia**
2408.15436v1 by Jie Feng, Wenqi Cui, Jorge Cortés, Yuanyuan Shi

The increasing integration of renewable energy resources into power grids has
led to time-varying system inertia and consequent degradation in frequency
dynamics. A promising solution to alleviate performance degradation is using
power electronics interfaced energy resources, such as renewable generators and
battery energy storage for primary frequency control, by adjusting their power
output set-points in response to frequency deviations. However, designing a
frequency controller under time-varying inertia is challenging. Specifically,
the stability or optimality of controllers designed for time-invariant systems
can be compromised once applied to a time-varying system. We model the
frequency dynamics under time-varying inertia as a nonlinear switching system,
where the frequency dynamics under each mode are described by the nonlinear
swing equations and different modes represent different inertia levels. We
identify a key controller structure, named Neural Proportional-Integral
(Neural-PI) controller, that guarantees exponential input-to-state stability
for each mode. To further improve performance, we present an online
event-triggered switching algorithm to select the most suitable controller from
a set of Neural-PI controllers, each optimized for specific inertia levels.
Simulations on the IEEE 39-bus system validate the effectiveness of the
proposed online switching control method with stability guarantees and
optimized performance for frequency control under time-varying inertia.

摘要：隨著可再生能源逐漸併入電網，導致系統慣量出現時間變異，進而造成頻率動態劣化。一個有望緩解效能劣化問題的解決方案，是使用電力電子介面的能源，例如可再生發電機和電池儲能系統，進行一次頻率控制，透過調整其功率輸出設定點來回應頻率偏差。然而，在時間變異慣量下設計頻率控制器是一項挑戰。具體來說，針對時間不變系統設計的控制器的穩定性或最佳性，一旦應用於時間變異系統，可能會受到影響。我們將時間變異慣量下的頻率動態建模為非線性切換系統，其中每個模式下的頻率動態由非線性擺動方程式描述，而不同的模式代表不同的慣量等級。我們找出一個關鍵的控制器結構，稱為神經比例積分 (Neural-PI) 控制器，它保證每個模式的指數輸入至狀態穩定性。為了進一步提升效能，我們提出一個線上事件觸發切換演算法，從一組神經比例積分控制器中選出最適合的控制器，每個控制器針對特定慣量等級進行最佳化。在 IEEE 39 母線系統上的模擬驗證了所提議的線上切換控制方法的有效性，它具備穩定性保證，並針對時間變異慣量下的頻率控制進行最佳化效能。

##### **Simultaneous Training of First- and Second-Order Optimizers in Population-Based Reinforcement Learning**
2408.15421v1 by Felix Pfeiffer, Shahram Eivazi

The tuning of hyperparameters in reinforcement learning (RL) is critical, as
these parameters significantly impact an agent's performance and learning
efficiency. Dynamic adjustment of hyperparameters during the training process
can significantly enhance both the performance and stability of learning.
Population-based training (PBT) provides a method to achieve this by
continuously tuning hyperparameters throughout the training. This ongoing
adjustment enables models to adapt to different learning stages, resulting in
faster convergence and overall improved performance. In this paper, we propose
an enhancement to PBT by simultaneously utilizing both first- and second-order
optimizers within a single population. We conducted a series of experiments
using the TD3 algorithm across various MuJoCo environments. Our results, for
the first time, empirically demonstrate the potential of incorporating
second-order optimizers within PBT-based RL. Specifically, the combination of
the K-FAC optimizer with Adam led to up to a 10% improvement in overall
performance compared to PBT using only Adam. Additionally, in environments
where Adam occasionally fails, such as the Swimmer environment, the mixed
population with K-FAC exhibited more reliable learning outcomes, offering a
significant advantage in training stability without a substantial increase in
computational time.

摘要：在强化学习 (RL) 中，超参数的调整至关重要，因为这些参数会显著影响代理的性能和学习效率。在训练过程中动态调整超参数可以显著提升学习的性能和稳定性。基于种群的训练 (PBT) 提供了一种方法，在整个训练过程中持续调整超参数来实现这一点。这种持续的调整使模型能够适应不同的学习阶段，从而实现更快的收敛速度和整体性能提升。在本文中，我们提出了一种 PBT 增强方法，在单个种群中同时利用一阶和二阶优化器。我们使用 TD3 算法在各种 MuJoCo 环境中进行了一系列实验。我们的结果首次通过实验证明了在基于 PBT 的 RL 中纳入二阶优化器的潜力。具体来说，K-FAC 优化器与 Adam 的结合，与仅使用 Adam 的 PBT 相比，整体性能提高了 10%。此外，在 Adam 偶尔会失败的环境中，例如 Swimmer 环境，具有 K-FAC 的混合种群表现出更可靠的学习结果，在不大幅增加计算时间的情况下，为训练稳定性提供了显著优势。

##### **Implicit Geometry of Next-token Prediction: From Language Sparsity Patterns to Model Representations**
2408.15417v1 by Yize Zhao, Tina Behnia, Vala Vakilian, Christos Thrampoulidis

Next-token prediction (NTP) over large text corpora has become the go-to
paradigm to train large language models. Yet, it remains unclear how NTP
influences the mapping of linguistic patterns to geometric properties of the
resulting model representations. We frame training of large language models as
soft-label classification over sparse probabilistic label vectors, coupled with
an analytical approximation that allows unrestricted generation of context
embeddings. This approach links NTP training to rank-constrained, nuclear-norm
regularized optimization in the logit domain, offering a framework for
analyzing the geometry of word and context embeddings. In large embedding
spaces, we find that NTP implicitly favors learning logits with a sparse plus
low-rank structure. While the sparse component captures the co-occurrence
frequency of context-word pairs, the orthogonal low-rank component, which
becomes dominant as training progresses, depends solely on the sparsity pattern
of the co-occurrence matrix. Consequently, when projected onto an appropriate
subspace, representations of contexts that are followed by the same set of
next-tokens collapse, a phenomenon we term subspace-collapse. We validate our
findings on synthetic and small-scale real language datasets. Finally, we
outline potential research directions aimed at deepening the understanding of
NTP's influence on the learning of linguistic patterns and regularities.

摘要：大型文本语料库上的下一个标记预测 (NTP) 已成为训练大型语言模型的首选范例。然而，NTP 如何影响语言模式映射到所得模型表征的几何属性仍不清楚。我们将大型语言模型的训练构建为稀疏概率标签向量的软标签分类，并结合允许无限制生成上下文嵌入的分析近似。此方法将 NTP 训练与对数几率域中的秩约束核范数正则化优化联系起来，为分析词和上下文嵌入的几何结构提供了一个框架。在大型嵌入空间中，我们发现 NTP 隐式倾向于学习具有稀疏加低秩结构的对数几率。虽然稀疏分量捕获了上下文词对的共现频率，但正交低秩分量（在训练过程中变得占主导地位）仅取决于共现矩阵的稀疏模式。因此，当投影到适当的子空间时，紧随同一组下一个标记的上下文的表征会发生坍缩，我们称之为子空间坍缩。我们在合成和小规模真实语言数据集上验证了我们的发现。最后，我们概述了旨在加深对 NTP 对语言模式和规律性学习的影响的理解的潜在研究方向。

##### **Awes, Laws, and Flaws From Today's LLM Research**
2408.15409v2 by Adrian de Wynter

We perform a critical examination of the scientific methodology behind
contemporary large language model (LLM) research. For this we assess over 2,000
research works based on criteria typical of what is considered good research
(e.g. presence of statistical tests and reproducibility) and cross-validate it
with arguments that are at the centre of controversy (e.g., claims of emergent
behaviour, the use of LLMs as evaluators). We find multiple trends, such as
declines in claims of emergent behaviour and ethics disclaimers; the rise of
LLMs as evaluators in spite of a lack of consensus from the community about
their useability; and an increase of claims of LLM reasoning abilities,
typically without leveraging human evaluation. This paper underscores the need
for more scrutiny and rigour by and from this field to live up to the
fundamentals of a responsible scientific method that is ethical, reproducible,
systematic, and open to criticism.

摘要：我們對當代大型語言模型 (LLM) 研究背後的科學方法進行了嚴格的審查。为此，我們根據被認為是良好研究的典型標準（例如統計檢驗和可複製性）評估了 2,000 多項研究工作，並使用爭議的核心論點（例如，新興行為的說法、將 LLM 用作評估器）對其進行交叉驗證。我們發現了多種趨勢，例如新興行為和道德免責聲明的說法減少；儘管社區對其可用性缺乏共識，但 LLM 作為評估器的地位上升；以及對 LLM 推理能力的說法增加，通常不利用人類評估。本文強調需要該領域更加仔細審查和嚴謹，才能符合負責任的科學方法的基本原則，即道德、可複製、系統化和開放接受批評。

##### **Intertwined Biases Across Social Media Spheres: Unpacking Correlations in Media Bias Dimensions**
2408.15406v1 by Yifan Liu, Yike Li, Dong Wang

Media bias significantly shapes public perception by reinforcing stereotypes
and exacerbating societal divisions. Prior research has often focused on
isolated media bias dimensions such as \textit{political bias} or
\textit{racial bias}, neglecting the complex interrelationships among various
bias dimensions across different topic domains. Moreover, we observe that
models trained on existing media bias benchmarks fail to generalize effectively
on recent social media posts, particularly in certain bias identification
tasks. This shortfall primarily arises because these benchmarks do not
adequately reflect the rapidly evolving nature of social media content, which
is characterized by shifting user behaviors and emerging trends. In response to
these limitations, our research introduces a novel dataset collected from
YouTube and Reddit over the past five years. Our dataset includes automated
annotations for YouTube content across a broad spectrum of bias dimensions,
such as gender, racial, and political biases, as well as hate speech, among
others. It spans diverse domains including politics, sports, healthcare,
education, and entertainment, reflecting the complex interplay of biases across
different societal sectors. Through comprehensive statistical analysis, we
identify significant differences in bias expression patterns and intra-domain
bias correlations across these domains. By utilizing our understanding of the
correlations among various bias dimensions, we lay the groundwork for creating
advanced systems capable of detecting multiple biases simultaneously. Overall,
our dataset advances the field of media bias identification, contributing to
the development of tools that promote fairer media consumption. The
comprehensive awareness of existing media bias fosters more ethical journalism,
promotes cultural sensitivity, and supports a more informed and equitable
public discourse.

摘要：媒體偏見透過強化刻板印象和惡化社會分歧，對公眾認知產生極大的影響。先前的研究通常專注於單一的媒體偏見面向，例如「政治偏見」或「種族偏見」，忽略了不同主題領域中各種偏見面向之間的複雜關聯性。此外，我們觀察到，以現有媒體偏見基準訓練的模型無法有效概化到最近的社群媒體貼文中，特別是在某些偏見辨識任務中。這種不足主要是因為這些基準並未充分反映社群媒體內容快速演變的本質，而這種本質的特徵是使用者行為的轉變和新興趨勢。為了回應這些限制，我們的研究引進了一個新穎的資料集，該資料集是在過去五年從 YouTube 和 Reddit 收集的。我們的資料集包含針對 YouTube 內容的自動化註解，涵蓋廣泛的偏見面向，例如性別、種族和政治偏見，以及仇恨言論等。它橫跨政治、體育、醫療保健、教育和娛樂等不同領域，反映了不同社會部門間偏見的複雜交互作用。透過全面的統計分析，我們找出這些領域中偏見表達模式和領域內部偏見相關性的顯著差異。透過運用我們對各種偏見面向之間相關性的理解，我們奠定了建立先進系統的基礎，該系統能夠同時偵測多種偏見。總體而言，我們的資料集推動了媒體偏見辨識領域的進展，有助於開發促進更公平媒體消費的工具。對現有媒體偏見的全面認識，有助於培養更具道德的新聞工作，促進文化敏感性，並支持更明智且公平的公共論述。

##### **A Statistical Framework for Data-dependent Retrieval-Augmented Models**
2408.15399v1 by Soumya Basu, Ankit Singh Rawat, Manzil Zaheer

Modern ML systems increasingly augment input instances with additional
relevant information to enhance final prediction. Despite growing interest in
such retrieval-augmented models, their fundamental properties and training are
not well understood. We propose a statistical framework to study such models
with two components: 1) a {\em retriever} to identify the relevant information
out of a large corpus via a data-dependent metric; and 2) a {\em predictor}
that consumes the input instances along with the retrieved information to make
the final predictions. We present a principled method for end-to-end training
of both components and draw connections with various training approaches in the
literature. Furthermore, we establish excess risk bounds for
retrieval-augmented models while delineating the contributions of both
retriever and predictor towards the model performance. We validate the utility
of our proposed training methods along with the key takeaways from our
statistical analysis on open domain question answering task where retrieval
augmentation is important.

摘要：現代 ML 系統越來越常透過額外相關資訊來擴充輸入個體，以增強最終預測。儘管對此類檢索擴充模型的興趣日益增加，但其基本屬性和訓練方式仍未被充分理解。我們提出一個統計框架來研究此類模型，該框架包含兩個組成部分：1) 一個「檢索器」，用於透過資料依賴性指標從大型語料庫中找出相關資訊；以及 2) 一個「預測器」，用於消耗輸入個體以及檢索到的資訊，以做出最終預測。我們提出一個有原則的方法，用於對這兩個組成部分進行端到端訓練，並與文獻中的各種訓練方法建立關聯。此外，我們為檢索擴充模型建立超額風險界限，同時描繪出檢索器和預測器對模型效能的貢獻。我們驗證了我們提出的訓練方法的效用，以及我們在開放領域問答任務中從統計分析中獲得的主要見解，其中檢索擴充非常重要。

##### **DualKanbaFormer: Kolmogorov-Arnold Networks and State Space Model DualKanbaFormer: Kolmogorov-Arnold Networks and State Space Model Transformer for Multimodal Aspect-based Sentiment Analysis**
2408.15379v1 by Adamu Lawan, Juhua Pu, Haruna Yunusa, Muhammad Lawan, Aliyu Umar, Adamu Sani Yahya

Multimodal aspect-based sentiment analysis (MABSA) enhances sentiment
detection by combining text with other data types like images. However, despite
setting significant benchmarks, attention mechanisms exhibit limitations in
efficiently modelling long-range dependencies between aspect and opinion
targets within the text. They also face challenges in capturing global-context
dependencies for visual representations. To this end, we propose
Kolmogorov-Arnold Networks (KANs) and Selective State Space model (Mamba)
transformer (DualKanbaFormer), a novel architecture to address the above
issues. We leverage the power of Mamba to capture global context dependencies,
Multi-head Attention (MHA) to capture local context dependencies, and KANs to
capture non-linear modelling patterns for both textual representations (textual
KanbaFormer) and visual representations (visual KanbaFormer). Furthermore, we
fuse the textual KanbaFormer and visual KanbaFomer with a gated fusion layer to
capture the inter-modality dynamics. According to extensive experimental
results, our model outperforms some state-of-the-art (SOTA) studies on two
public datasets.

摘要：多模态面向方面的观点分析 (MABSA) 将文本与图像等其他数据类型相结合，增强了观点检测。然而，尽管设定了重要的基准，但注意力机制在有效建模文本中方面和观点目标之间的长程依赖性方面表现出局限性。它们在捕获视觉表示的全局上下文依赖性方面也面临挑战。为此，我们提出了 Kolmogorov-Arnold 网络 (KAN) 和选择性状态空间模型 (Mamba) 变换器 (DualKanbaFormer)，这是一种解决上述问题的新颖架构。我们利用 Mamba 的强大功能来捕获全局上下文依赖性，多头注意力 (MHA) 来捕获局部上下文依赖性，以及 KAN 来捕获文本表示（文本 KanbaFormer）和视觉表示（视觉 KanbaFormer）的非线性建模模式。此外，我们将文本 KanbaFormer 和视觉 KanbaFomer 与门控融合层融合，以捕获模态间动态。根据广泛的实验结果，我们的模型在两个公共数据集上优于一些最先进 (SOTA) 的研究。

##### **Handling Geometric Domain Shifts in Semantic Segmentation of Surgical RGB and Hyperspectral Images**
2408.15373v1 by Silvia Seidlitz, Jan Sellner, Alexander Studier-Fischer, Alessandro Motta, Berkin Özdemir, Beat P. Müller-Stich, Felix Nickel, Lena Maier-Hein

Robust semantic segmentation of intraoperative image data holds promise for
enabling automatic surgical scene understanding and autonomous robotic surgery.
While model development and validation are primarily conducted on idealistic
scenes, geometric domain shifts, such as occlusions of the situs, are common in
real-world open surgeries. To close this gap, we (1) present the first analysis
of state-of-the-art (SOA) semantic segmentation models when faced with
geometric out-of-distribution (OOD) data, and (2) propose an augmentation
technique called "Organ Transplantation", to enhance generalizability. Our
comprehensive validation on six different OOD datasets, comprising 600 RGB and
hyperspectral imaging (HSI) cubes from 33 pigs, each annotated with 19 classes,
reveals a large performance drop in SOA organ segmentation models on geometric
OOD data. This performance decline is observed not only in conventional RGB
data (with a dice similarity coefficient (DSC) drop of 46 %) but also in HSI
data (with a DSC drop of 45 %), despite the richer spectral information
content. The performance decline increases with the spatial granularity of the
input data. Our augmentation technique improves SOA model performance by up to
67 % for RGB data and 90 % for HSI data, achieving performance at the level of
in-distribution performance on real OOD test data. Given the simplicity and
effectiveness of our augmentation method, it is a valuable tool for addressing
geometric domain shifts in surgical scene segmentation, regardless of the
underlying model. Our code and pre-trained models are publicly available at
https://github.com/IMSY-DKFZ/htc.

摘要：<paragraph>強健的腹腔內影像資料語義分割有望實現自動手術場景理解和自主機器人手術。
雖然模型開發和驗證主要在理想場景中進行，但在現實世界中的開放式手術中，幾何領域轉移（例如部位閉塞）很常見。為了彌補這一差距，我們（1）提出了面對幾何分佈外（OOD）資料時最先進（SOA）語義分割模型的首次分析，以及（2）提出了一種名為「器官移植」的擴充技術，以增強泛化性。我們對六個不同的 OOD 資料集進行了全面驗證，其中包括來自 33 隻豬的 600 個 RGB 和高光譜成像 (HSI) 立方體，每個立方體都標註了 19 個類別，結果顯示 SOA 器官分割模型在幾何 OOD 資料上的性能大幅下降。這種性能下降不僅在傳統 RGB 資料中觀察到（骰子相似性系數 (DSC) 下降 46%），而且在 HSI 資料中也觀察到（DSC 下降 45%），儘管光譜資訊含量更豐富。性能下降隨著輸入資料的空間粒度而增加。我們的擴充技術將 SOA 模型的性能提高了 RGB 資料的 67% 和 HSI 資料的 90%，在真實 OOD 測試資料上實現了與分佈內性能相當的性能。鑑於我們的擴充方法的簡潔性和有效性，它是一個有價值的工具，可用於解決手術場景分割中的幾何領域轉移，而不管基礎模型如何。我們的程式碼和預訓練模型可在 https://github.com/IMSY-DKFZ/htc 公開獲得。</paragraph>

##### **Pitfalls and Outlooks in Using COMET**
2408.15366v1 by Vilém Zouhar, Pinzhen Chen, Tsz Kin Lam, Nikita Moghe, Barry Haddow

Since its introduction, the COMET metric has blazed a trail in the machine
translation community, given its strong correlation with human judgements of
translation quality. Its success stems from being a modified pre-trained
multilingual model finetuned for quality assessment. However, it being a
machine learning model also gives rise to a new set of pitfalls that may not be
widely known. We investigate these unexpected behaviours from three aspects: 1)
technical: obsolete software versions and compute precision; 2) data: empty
content, language mismatch, and translationese at test time as well as
distribution and domain biases in training; 3) usage and reporting:
multi-reference support and model referencing in the literature. All of these
problems imply that COMET scores is not comparable between papers or even
technical setups and we put forward our perspective on fixing each issue.
Furthermore, we release the SacreCOMET package that can generate a signature
for the software and model configuration as well as an appropriate citation.
The goal of this work is to help the community make more sound use of the COMET
metric.

摘要：自推出以來，COMET 指標在機器翻譯社群中開闢了一條道路，因為它與人類對翻譯品質的判斷有很強的相關性。它的成功源於作為一個修改過的預先訓練多語言模型，經過微調以進行品質評估。然而，它作為一個機器學習模型也產生了一組新的陷阱，可能鮮為人知。我們從三個方面探討這些意外的行為：1) 技術：過時的軟體版本和運算精度；2) 資料：測試時的空內容、語言不匹配和翻譯腔，以及訓練中的分佈和領域偏差；3) 使用和報告：文獻中的多參考支援和模型參考。所有這些問題都意味著 COMET 分數在論文或甚至技術設定之間不可比較，我們提出了我們對解決每個問題的觀點。此外，我們發布了 SacreCOMET 套件，它可以為軟體和模型配置以及適當的引文產生簽章。這項工作的目標是幫助社群更妥善地使用 COMET 指標。

##### **UNA: Unifying Alignments of RLHF/PPO, DPO and KTO by a Generalized Implicit Reward Function**
2408.15339v1 by Zhichao Wang, Bin Bi, Can Huang, Shiva Kumar Pentyala, Zixu James Zhu, Sitaram Asur, Na Claire Cheng

An LLM is pretrained on trillions of tokens, but the pretrained LLM may still
generate undesired responses. To solve this problem, alignment techniques such
as RLHF, DPO and KTO are proposed. However, these alignment techniques have
limitations. For example, RLHF requires training the reward model and policy
separately, which is complex, time-consuming, memory intensive and unstable
during training processes. DPO proposes a mapping between an optimal policy and
a reward, greatly simplifying the training process of RLHF. However, it can not
take full advantages of a reward model and it is limited to pairwise preference
data.
  In this paper, we propose \textbf{UN}ified \textbf{A}lignment (UNA) which
unifies RLHF/PPO, DPO and KTO. Firstly, we mathematically prove that given the
classical RLHF objective, the optimal policy is induced by a generalize
implicit reward function. With this novel mapping between a reward model and an
optimal policy, UNA can 1. unify RLHF/PPO, DPO and KTO into a supervised
learning of minimizing the difference between an implicit reward and an
explicit reward; 2. outperform RLHF/PPO while simplify, stabilize, speed up and
reduce memory burden of RL fine-tuning process; 3. accommodate different
feedback types including pairwise, binary and scalar feedback. Downstream
experiments show UNA outperforms DPO, KTO and RLHF.

摘要：LLM 在數兆個符號上進行預訓練，但預訓練的 LLM 仍可能產生不需要的回應。為了解決這個問題，提出了 RLHF、DPO 和 KTO 等對齊技術。然而，這些對齊技術有其限制。例如，RLHF 需要分別訓練獎勵模型和策略，這在訓練過程中很複雜、耗時、佔用大量記憶體且不穩定。DPO 提出了一個最優策略和獎勵之間的對應關係，大大簡化了 RLHF 的訓練過程。然而，它無法充分利用獎勵模型，並且僅限於成對偏好資料。
在本文中，我們提出了統一對齊 (UNA)，它統一了 RLHF/PPO、DPO 和 KTO。首先，我們數學上證明，給定經典的 RLHF 目標，最優策略是由一個廣義的隱式獎勵函數誘導的。有了這個獎勵模型和最優策略之間的新穎對應關係，UNA 可以 1. 將 RLHF/PPO、DPO 和 KTO 統一為監督學習，以最小化隱式獎勵和顯式獎勵之間的差異；2. 在簡化、穩定、加速和減少 RL 微調過程的記憶體負擔的同時，優於 RLHF/PPO；3. 容納不同的回饋類型，包括成對、二元和標量回饋。下游實驗表明，UNA 優於 DPO、KTO 和 RLHF。

##### **The Mamba in the Llama: Distilling and Accelerating Hybrid Models**
2408.15237v1 by Junxiong Wang, Daniele Paliotta, Avner May, Alexander M. Rush, Tri Dao

Linear RNN architectures, like Mamba, can be competitive with Transformer
models in language modeling while having advantageous deployment
characteristics. Given the focus on training large-scale Transformer models, we
consider the challenge of converting these pretrained models for deployment. We
demonstrate that it is feasible to distill large Transformers into linear RNNs
by reusing the linear projection weights from attention layers with academic
GPU resources. The resulting hybrid model, which incorporates a quarter of the
attention layers, achieves performance comparable to the original Transformer
in chat benchmarks and outperforms open-source hybrid Mamba models trained from
scratch with trillions of tokens in both chat benchmarks and general
benchmarks. Moreover, we introduce a hardware-aware speculative decoding
algorithm that accelerates the inference speed of Mamba and hybrid models.
Overall we show how, with limited computation resources, we can remove many of
the original attention layers and generate from the resulting model more
efficiently. Our top-performing model, distilled from Llama3-8B-Instruct,
achieves a 29.61 length-controlled win rate on AlpacaEval 2 against GPT-4 and
7.35 on MT-Bench, surpassing the best instruction-tuned linear RNN model.

摘要：線性 RNN 架構，例如 Mamba，在語言模型中可以與 Transformer 模型競爭，同時具有有利的部署特性。鑑於重點在訓練大型 Transformer 模型，我們考慮將這些預訓練模型轉換為部署的挑戰。我們證明了透過重複使用注意力層的線性投影權重，將大型 Transformer 萃取到線性 RNN 中是可行的，並具備學術 GPU 資源。所產生的混合模型包含四分之一的注意力層，在聊天基準測試中實現與原始 Transformer 相當的效能，並優於從頭開始訓練的開源混合 Mamba 模型，且聊天基準測試和一般基準測試中都有數兆個代幣。此外，我們引入了硬體感知推測解碼演算法，可加速 Mamba 和混合模型的推論速度。總的來說，我們展示了如何透過有限的運算資源，移除許多原始的注意力層，並更有效率地從產生的模型中生成。我們從 Llama3-8B-Instruct 萃取出的效能最佳模型，在 AlpacaEval 2 中對上 GPT-4 和 MT-Bench 中的獲勝率分別達到 29.61 和 7.35，超越了最佳的指令調整線性 RNN 模型。

##### **Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations**
2408.15232v1 by Yucheng Jiang, Yijia Shao, Dekun Ma, Sina J. Semnani, Monica S. Lam

While language model (LM)-powered chatbots and generative search engines
excel at answering concrete queries, discovering information in the terrain of
unknown unknowns remains challenging for users. To emulate the common
educational scenario where children/students learn by listening to and
participating in conversations of their parents/teachers, we create
Collaborative STORM (Co-STORM). Unlike QA systems that require users to ask all
the questions, Co-STORM lets users observe and occasionally steer the discourse
among several LM agents. The agents ask questions on the user's behalf,
allowing the user to discover unknown unknowns serendipitously. To facilitate
user interaction, Co-STORM assists users in tracking the discourse by
organizing the uncovered information into a dynamic mind map, ultimately
generating a comprehensive report as takeaways. For automatic evaluation, we
construct the WildSeek dataset by collecting real information-seeking records
with user goals. Co-STORM outperforms baseline methods on both discourse trace
and report quality. In a further human evaluation, 70% of participants prefer
Co-STORM over a search engine, and 78% favor it over a RAG chatbot.

摘要：<paragraph>雖然語言模型 (LM) 驅動的聊天機器人和生成式搜尋引擎
擅長回答具體的查詢，但在未知的未知領域中發現資訊對使用者來說仍然具有挑戰性。為了模擬常見的教育場景，讓兒童/學生透過聆聽和參與父母/老師的對話來學習，我們建立了協作式 STORM (Co-STORM)。與要求使用者提出所有問題的問答系統不同，Co-STORM 使用者可以觀察並偶爾引導多個 LM 代理之間的討論。代理會代表使用者提出問題，讓使用者可以意外地發現未知的未知。為了促進使用者互動，Co-STORM 透過將發現的資訊組織成動態心智圖來協助使用者追蹤討論，最終產生一份全面的報告作為重點。為了自動評估，我們透過收集包含使用者目標的真實資訊搜尋記錄來建構 WildSeek 資料集。Co-STORM 在討論記錄和報告品質上都優於基準方法。在進一步的人工評估中，70% 的參與者偏好 Co-STORM 而非搜尋引擎，而 78% 的參與者偏好 Co-STORM 而非 RAG 聊天機器人。</paragraph>

##### **LLM Defenses Are Not Robust to Multi-Turn Human Jailbreaks Yet**
2408.15221v1 by Nathaniel Li, Ziwen Han, Ian Steneker, Willow Primack, Riley Goodside, Hugh Zhang, Zifan Wang, Cristina Menghini, Summer Yue

Recent large language model (LLM) defenses have greatly improved models'
ability to refuse harmful queries, even when adversarially attacked. However,
LLM defenses are primarily evaluated against automated adversarial attacks in a
single turn of conversation, an insufficient threat model for real-world
malicious use. We demonstrate that multi-turn human jailbreaks uncover
significant vulnerabilities, exceeding 70% attack success rate (ASR) on
HarmBench against defenses that report single-digit ASRs with automated
single-turn attacks. Human jailbreaks also reveal vulnerabilities in machine
unlearning defenses, successfully recovering dual-use biosecurity knowledge
from unlearned models. We compile these results into Multi-Turn Human
Jailbreaks (MHJ), a dataset of 2,912 prompts across 537 multi-turn jailbreaks.
We publicly release MHJ alongside a compendium of jailbreak tactics developed
across dozens of commercial red teaming engagements, supporting research
towards stronger LLM defenses.

摘要：近期的大型语言模型（LLM）防御功能已大幅提升模型拒绝有害查询的能力，即使在对抗性攻击下也能如此。然而，LLM 防御功能主要针对对话中的单回合自动化对抗性攻击进行评估，这对于现实世界中的恶意使用而言是不够的威胁模型。我们证明，多回合人类越狱揭示了严重的漏洞，在 HarmBench 上对报告单回合自动化攻击时具有个位数 ASR 的防御措施，其攻击成功率 (ASR) 超过 70%。人类越狱还揭示了机器取消学习防御中的漏洞，成功地从未学习的模型中恢复了双重用途的生物安全知识。我们将这些结果汇编成多回合人类越狱 (MHJ)，这是一个包含 537 个多回合越狱的 2,912 个提示的数据集。我们在几十次商业红队参与行动中开发的越狱策略汇编中公开发布了 MHJ，支持针对更强大的 LLM 防御功能的研究。

##### **Bi-Factorial Preference Optimization: Balancing Safety-Helpfulness in Language Models**
2408.15313v1 by Wenxuan Zhang, Philip H. S. Torr, Mohamed Elhoseiny, Adel Bibi

Fine-tuning large language models (LLMs) on human preferences, typically
through reinforcement learning from human feedback (RLHF), has proven
successful in enhancing their capabilities. However, ensuring the safety of
LLMs during the fine-tuning remains a critical concern, and mitigating the
potential conflicts in safety and helpfulness is costly in RLHF. To address
this issue, we propose a supervised learning framework called Bi-Factorial
Preference Optimization (BFPO), which re-parameterizes a joint RLHF objective
of both safety and helpfulness into a single supervised learning objective. In
the supervised optimization, a labeling function is used to capture global
preferences ranking to balance both safety and helpfulness. To evaluate BFPO,
we develop a benchmark including comprehensive discriminative and generative
tasks for helpfulness and harmlessness. The results indicate that our method
significantly outperforms existing approaches in both safety and helpfulness.
Moreover, BFPO eliminates the need for human prompting and annotation in LLM
fine-tuning while achieving the same level of safety as methods that heavily
rely on human labor, with less than 10% of the computational resources. The
training recipes and models will be released.

摘要：針對人類偏好微調大型語言模型 (LLM)，通常透過人類回饋的強化學習 (RLHF)，已被證明能成功提升其能力。然而，在微調過程中確保 LLM 的安全性仍是一項關鍵問題，而且在 RLHF 中緩解安全性與助益性的潛在衝突成本很高。為了解決這個問題，我們提出一個名為雙因子偏好最佳化 (BFPO) 的監督式學習架構，它將安全性與助益性的聯合 RLHF 目標重新參數化為單一的監督式學習目標。在監督式最佳化中，標籤函數用於擷取整體偏好排名，以平衡安全性與助益性。為了評估 BFPO，我們開發了一個基準，其中包含有助益性與無害性的全面判別式和生成式任務。結果顯示，我們的模型在安全性與助益性上都大幅優於現有方法。此外，BFPO 消除了在 LLM 微調中需要人類提示和註解的需求，同時達到與高度依賴人力方法相同的安全性水準，且運算資源不到 10%。訓練食譜和模型將會釋出。

##### **Classifying populist language in American presidential and governor speeches using automatic text analysis**
2408.15213v1 by Olaf van der Veen, Semir Dzebo, Levi Littvay, Kirk Hawkins, Oren Dar

Populism is a concept that is often used but notoriously difficult to
measure. Common qualitative measurements like holistic grading or content
analysis require great amounts of time and labour, making it difficult to
quickly scope out which politicians should be classified as populist and which
should not, while quantitative methods show mixed results when it comes to
classifying populist rhetoric. In this paper, we develop a pipeline to train
and validate an automated classification model to estimate the use of populist
language. We train models based on sentences that were identified as populist
and pluralist in 300 US governors' speeches from 2010 to 2018 and in 45
speeches of presidential candidates in 2016. We find that these models classify
most speeches correctly, including 84% of governor speeches and 89% of
presidential speeches. These results extend to different time periods (with 92%
accuracy on more recent American governors), different amounts of data (with as
few as 70 training sentences per category achieving similar results), and when
classifying politicians instead of individual speeches. This pipeline is thus
an effective tool that can optimise the systematic and swift classification of
the use of populist language in politicians' speeches.

摘要：民粹主義是一個經常被使用，但難以測量的概念。常見的定性測量，例如整體評分或內容分析，需要大量時間和勞力，這使得快速找出哪些政治人物應被歸類為民粹主義者，哪些不應被歸類為民粹主義者變得困難，而定量方法在對民粹主義言論進行分類時則顯示出不同的結果。在本文中，我們開發了一個管道來訓練和驗證一個自動分類模型，以估計民粹主義語言的使用情況。我們根據在 2010 年至 2018 年間 300 位美國州長演講中被確定為民粹主義和多元主義的句子，以及 2016 年 45 位總統候選人的演講來訓練模型。我們發現這些模型正確地對大多數演講進行了分類，包括 84% 的州長演講和 89% 的總統演講。這些結果延伸到不同的時間段（對最近的美國州長有 92% 的準確度）、不同的數據量（每類別少至 70 個訓練句子即可獲得類似的結果），以及在對政治人物進行分類而不是對個別演講進行分類時。因此，這個管道是一個有效的工具，可以優化對政治人物演講中民粹主義語言使用情況的系統且快速的分類。

##### **Can Unconfident LLM Annotations Be Used for Confident Conclusions?**
2408.15204v1 by Kristina Gligorić, Tijana Zrnic, Cinoo Lee, Emmanuel J. Candès, Dan Jurafsky

Large language models (LLMs) have shown high agreement with human raters
across a variety of tasks, demonstrating potential to ease the challenges of
human data collection. In computational social science (CSS), researchers are
increasingly leveraging LLM annotations to complement slow and expensive human
annotations. Still, guidelines for collecting and using LLM annotations,
without compromising the validity of downstream conclusions, remain limited. We
introduce Confidence-Driven Inference: a method that combines LLM annotations
and LLM confidence indicators to strategically select which human annotations
should be collected, with the goal of producing accurate statistical estimates
and provably valid confidence intervals while reducing the number of human
annotations needed. Our approach comes with safeguards against LLM annotations
of poor quality, guaranteeing that the conclusions will be both valid and no
less accurate than if we only relied on human annotations. We demonstrate the
effectiveness of Confidence-Driven Inference over baselines in statistical
estimation tasks across three CSS settings--text politeness, stance, and
bias--reducing the needed number of human annotations by over 25% in each.
Although we use CSS settings for demonstration, Confidence-Driven Inference can
be used to estimate most standard quantities across a broad range of NLP
problems.

摘要：大型語言模型 (LLM) 在各種任務中已展現出與人類評分者高度一致，證明了其減輕人類資料收集挑戰的潛力。在計算社會科學 (CSS) 中，研究人員正日益利用 LLM 標註來補充緩慢且昂貴的人類標註。儘管如此，在不損害下游結論的有效性的前提下，收集和使用 LLM 標註的準則仍然有限。我們引入了信心驅動推論：一種結合 LLM 標註和 LLM 信心指標的方法，以策略性地選擇應收集哪些人類標註，目標是在減少所需人類標註數量的同時產生準確的統計估計和可證明有效的信心區間。我們的做法帶有針對品質不佳的 LLM 標註的保障措施，確保結論既有效又不會比我們僅依賴人類標註時不準確。我們在三個 CSS 設定（文字禮貌、立場和偏見）中，證明了信心驅動推論優於基線的有效性，在每個設定中將所需的人類標註數量減少了 25% 以上。儘管我們使用 CSS 設定進行示範，但信心驅動推論可用於估計廣泛 NLP 問題中的大多數標準量。

##### **Infusing Acoustic Pause Context into Text-Based Dementia Assessment**
2408.15188v1 by Franziska Braun, Sebastian P. Bayerl, Florian Hönig, Hartmut Lehfeld, Thomas Hillemacher, Tobias Bocklet, Korbinian Riedhammer

Speech pauses, alongside content and structure, offer a valuable and
non-invasive biomarker for detecting dementia. This work investigates the use
of pause-enriched transcripts in transformer-based language models to
differentiate the cognitive states of subjects with no cognitive impairment,
mild cognitive impairment, and Alzheimer's dementia based on their speech from
a clinical assessment. We address three binary classification tasks: Onset,
monitoring, and dementia exclusion. The performance is evaluated through
experiments on a German Verbal Fluency Test and a Picture Description Test,
comparing the model's effectiveness across different speech production
contexts. Starting from a textual baseline, we investigate the effect of
incorporation of pause information and acoustic context. We show the test
should be chosen depending on the task, and similarly, lexical pause
information and acoustic cross-attention contribute differently.

摘要：語音停頓與內容和結構並列，為偵測失智症提供了有價值且非侵入性的生物標記。這項研究探討在基於轉換器的語言模型中使用富含停頓的轉錄，以根據臨床評估中受試者的語言區分出無認知障礙、輕度認知障礙和阿茲海默症失智症的認知狀態。我們處理三項二元分類任務：發病、監測和排除失智症。透過對德語流利口語測驗和圖片描述測驗進行實驗，評估效能，比較模型在不同語言產生脈絡中的有效性。從文字基準開始，我們探討加入停頓資訊和音響脈絡的效果。我們顯示測試應根據任務選擇，同樣地，語彙停頓資訊和音響交叉注意力的貢獻也不同。

##### **PoseWatch: A Transformer-based Architecture for Human-centric Video Anomaly Detection Using Spatio-temporal Pose Tokenization**
2408.15185v1 by Ghazal Alinezhad Noghre, Armin Danesh Pazho, Hamed Tabkhi

Video Anomaly Detection (VAD) presents a significant challenge in computer
vision, particularly due to the unpredictable and infrequent nature of
anomalous events, coupled with the diverse and dynamic environments in which
they occur. Human-centric VAD, a specialized area within this domain, faces
additional complexities, including variations in human behavior, potential
biases in data, and substantial privacy concerns related to human subjects.
These issues complicate the development of models that are both robust and
generalizable. To address these challenges, recent advancements have focused on
pose-based VAD, which leverages human pose as a high-level feature to mitigate
privacy concerns, reduce appearance biases, and minimize background
interference. In this paper, we introduce PoseWatch, a novel transformer-based
architecture designed specifically for human-centric pose-based VAD. PoseWatch
features an innovative Spatio-Temporal Pose and Relative Pose (ST-PRP)
tokenization method that enhances the representation of human motion over time,
which is also beneficial for broader human behavior analysis tasks. The
architecture's core, a Unified Encoder Twin Decoders (UETD) transformer,
significantly improves the detection of anomalous behaviors in video data.
Extensive evaluations across multiple benchmark datasets demonstrate that
PoseWatch consistently outperforms existing methods, establishing a new
state-of-the-art in pose-based VAD. This work not only demonstrates the
efficacy of PoseWatch but also highlights the potential of integrating Natural
Language Processing techniques with computer vision to advance human behavior
analysis.

摘要：影片異常偵測 (VAD) 在電腦視覺中是一項重大挑戰，特別是因為異常事件的不可預測性和不頻繁性，加上它們發生的環境多樣且動態。以人為中心的 VAD 是此領域中的專門領域，面臨額外的複雜性，包括人類行為的變化、資料中的潛在偏差，以及與人類受試者相關的重大隱私問題。這些問題使得開發既強健又可概化的模型變得複雜。為了應對這些挑戰，最近的進展專注於基於姿勢的 VAD，它利用人類姿勢作為高級特徵來減輕隱私問題、減少外觀偏差，並將背景干擾降至最低。在本文中，我們介紹 PoseWatch，這是一種新穎的基於Transformer的架構，專門設計用於以人為中心的基於姿勢的 VAD。PoseWatch 採用創新的時空姿勢和相對姿勢 (ST-PRP) 標記化方法，增強了人類動作隨時間的表示，這也有利於更廣泛的人類行為分析任務。該架構的核心，一個統一編碼器雙解碼器 (UETD) Transformer，顯著改善了影片資料中異常行為的偵測。跨多個基準資料集的廣泛評估證明，PoseWatch 持續優於現有方法，在基於姿勢的 VAD 中建立了新的技術水準。這項工作不僅證明了 PoseWatch 的效能，也突出了將自然語言處理技術與電腦視覺整合以推進人類行為分析的潛力。

##### **Unlocking Potential in Pre-Trained Music Language Models for Versatile Multi-Track Music Arrangement**
2408.15176v1 by Longshen Ou, Jingwei Zhao, Ziyu Wang, Gus Xia, Ye Wang

Large language models have shown significant capabilities across various
domains, including symbolic music generation. However, leveraging these
pre-trained models for controllable music arrangement tasks, each requiring
different forms of musical information as control, remains a novel challenge.
In this paper, we propose a unified sequence-to-sequence framework that enables
the fine-tuning of a symbolic music language model for multiple multi-track
arrangement tasks, including band arrangement, piano reduction, drum
arrangement, and voice separation. Our experiments demonstrate that the
proposed approach consistently achieves higher musical quality compared to
task-specific baselines across all four tasks. Furthermore, through additional
experiments on probing analysis, we show the pre-training phase equips the
model with essential knowledge to understand musical conditions, which is hard
to acquired solely through task-specific fine-tuning.

摘要：大型語言模型已在各種領域展現出顯著的能力，包括符號音樂生成。然而，要利用這些預訓練模型進行可控音樂編排任務，每個任務都需要不同的音樂資訊作為控制，這仍然是一個新挑戰。在本文中，我們提出了一個統一的序列到序列框架，可以微調符號音樂語言模型以進行多個多軌編排任務，包括樂隊編排、鋼琴簡化、鼓編排和人聲分離。我們的實驗表明，與所有四項任務中特定於任務的基準相比，所提出的方法始終實現更高的音樂品質。此外，透過探測分析的額外實驗，我們展示了預訓練階段為模型提供了理解音樂條件的基本知識，而僅透過特定於任務的微調很難獲得這些知識。

##### **X-Reflect: Cross-Reflection Prompting for Multimodal Recommendation**
2408.15172v1 by Hanjia Lyu, Ryan Rossi, Xiang Chen, Md Mehrab Tanjim, Stefano Petrangeli, Somdeb Sarkhel, Jiebo Luo

Large Language Models (LLMs) and Large Multimodal Models (LMMs) have been
shown to enhance the effectiveness of enriching item descriptions, thereby
improving the accuracy of recommendation systems. However, most existing
approaches either rely on text-only prompting or employ basic multimodal
strategies that do not fully exploit the complementary information available
from both textual and visual modalities. This paper introduces a novel
framework, Cross-Reflection Prompting, termed X-Reflect, designed to address
these limitations by prompting LMMs to explicitly identify and reconcile
supportive and conflicting information between text and images. By capturing
nuanced insights from both modalities, this approach generates more
comprehensive and contextually richer item representations. Extensive
experiments conducted on two widely used benchmarks demonstrate that our method
outperforms existing prompting baselines in downstream recommendation accuracy.
Additionally, we evaluate the generalizability of our framework across
different LMM backbones and the robustness of the prompting strategies,
offering insights for optimization. This work underscores the importance of
integrating multimodal information and presents a novel solution for improving
item understanding in multimodal recommendation systems.

摘要：大型語言模型 (LLM) 和大型多模態模型 (LMM) 已被證明可以提高豐富商品說明的有效性，從而提高推薦系統的準確性。然而，現有的方法大多依賴於純文字提示，或採用基本的模態策略，無法充分利用文本和視覺模態中可用的互補資訊。本文介紹了一個創新的框架，稱為交叉反射提示 (X-Reflect)，旨在透過提示 LMM 明確找出和調和文本和影像之間的支持和衝突資訊來解決這些限制。透過擷取兩種模態的細微見解，此方法產生更全面且內容更豐富的商品表示。在兩個廣泛使用的基準上進行的廣泛實驗證明，我們的模型在下游推薦準確度方面優於現有的提示基準。此外，我們評估了我們的框架在不同 LMM 主幹中的概括性以及提示策略的穩健性，為最佳化提供見解。這項研究強調了整合多模態資訊的重要性，並提出了一種創新的解決方案，用於改善多模態推薦系統中的商品理解。

##### **Measuring text summarization factuality using atomic facts entailment metrics in the context of retrieval augmented generation**
2408.15171v1 by N. E. Kriman

The use of large language models (LLMs) has significantly increased since the
introduction of ChatGPT in 2022, demonstrating their value across various
applications. However, a major challenge for enterprise and commercial adoption
of LLMs is their tendency to generate inaccurate information, a phenomenon
known as "hallucination." This project proposes a method for estimating the
factuality of a summary generated by LLMs when compared to a source text. Our
approach utilizes Naive Bayes classification to assess the accuracy of the
content produced.

摘要：自 2022 年 ChatGPT 推出以來，大型語言模型 (LLM) 的使用大幅增加，證明它們在各種應用中的價值。然而，企業和商業採用 LLM 的一個主要挑戰是它們傾向於產生不準確的資訊，這種現象稱為「幻覺」。本專案提出了一種方法，用於評估 LLM 生成的摘要與原始文字相比的事實性。我們的做法利用朴素貝氏分類來評估所產生內容的準確性。

##### **Parameter-Efficient Quantized Mixture-of-Experts Meets Vision-Language Instruction Tuning for Semiconductor Electron Micrograph Analysis**
2408.15305v1 by Sakhinana Sagar Srinivas, Chidaksh Ravuru, Geethan Sannidhi, Venkataramana Runkana

Semiconductors, crucial to modern electronics, are generally under-researched
in foundational models. It highlights the need for research to enhance the
semiconductor device technology portfolio and aid in high-end device
fabrication. In this paper, we introduce sLAVA, a small-scale vision-language
assistant tailored for semiconductor manufacturing, with a focus on electron
microscopy image analysis. It addresses challenges of data scarcity and
acquiring high-quality, expert-annotated data. We employ a teacher-student
paradigm, using a foundational vision language model like GPT-4 as a teacher to
create instruction-following multimodal data for customizing the student model,
sLAVA, for electron microscopic image analysis tasks on consumer hardware with
limited budgets. Our approach allows enterprises to further fine-tune the
proposed framework with their proprietary data securely within their own
infrastructure, protecting intellectual property. Rigorous experiments validate
that our framework surpasses traditional methods, handles data shifts, and
enables high-throughput screening.

摘要：半導體對於現代電子產品至關重要，但在基礎模型中卻普遍研究不足。這突顯了加強半導體裝置技術組合和協助高階裝置製造的研究需求。在本文中，我們介紹 sLAVA，這是一個針對半導體製造而設計的小型視覺語言助理，專注於電子顯微鏡影像分析。它解決了資料稀少以及取得高品質、專家註解資料的挑戰。我們採用師生範例，使用基礎視覺語言模型，例如 GPT-4，作為老師，為自訂學生模型 sLAVA 建立遵循指令的多模態資料，以進行電子顯微鏡影像分析任務，並使用預算有限的消費級硬體。我們的做法讓企業能夠使用自己的基礎設施安全地微調建議的架構，同時保護智慧財產權。嚴謹的實驗驗證了我們的架構超越傳統方法、處理資料轉移，並支援高通量篩選。

##### **TCNFormer: Temporal Convolutional Network Former for Short-Term Wind Speed Forecasting**
2408.15737v1 by Abid Hasan Zim, Aquib Iqbal, Asad Malik, Zhicheng Dong, Hanzhou Wu

Global environmental challenges and rising energy demands have led to
extensive exploration of wind energy technologies. Accurate wind speed
forecasting (WSF) is crucial for optimizing wind energy capture and ensuring
system stability. However, predicting wind speed remains challenging due to its
inherent randomness, fluctuation, and unpredictability. This study proposes the
Temporal Convolutional Network Former (TCNFormer) for short-term (12-hour) wind
speed forecasting. The TCNFormer integrates the Temporal Convolutional Network
(TCN) and transformer encoder to capture the spatio-temporal features of wind
speed. The transformer encoder consists of two distinct attention mechanisms:
causal temporal multi-head self-attention (CT-MSA) and temporal external
attention (TEA). CT-MSA ensures that the output of a step derives only from
previous steps, i.e., causality. Locality is also introduced to improve
efficiency. TEA explores potential relationships between different sample
sequences in wind speed data. This study utilizes wind speed data from the NASA
Prediction of Worldwide Energy Resources (NASA POWER) of Patenga Sea Beach,
Chittagong, Bangladesh (latitude 22.2352{\deg} N, longitude 91.7914{\deg} E)
over a year (six seasons). The findings indicate that the TCNFormer outperforms
state-of-the-art models in prediction accuracy. The proposed TCNFormer presents
a promising method for spatio-temporal WSF and may achieve desirable
performance in real-world applications of wind power systems.

摘要：<paragraph>全球環境挑戰和不斷增加的能源需求導致風能技術的廣泛探索。準確的风速預測 (WSF) 對於優化風能捕獲和確保系統穩定至關重要。然而，由於風速固有的隨機性、波動性和不可預測性，預測風速仍然具有挑戰性。本研究提出了時序卷積網路生成器 (TCNFormer) 用於短期 (12 小時) 風速預測。TCNFormer 整合了時序卷積網路 (TCN) 和Transformer編碼器，以擷取風速的時空特徵。Transformer編碼器由兩種不同的注意力機制組成：因果時序多頭自我注意力 (CT-MSA) 和時序外部注意力 (TEA)。CT-MSA 確保一個步驟的輸出僅來自於前一個步驟，即因果關係。局部性也被引入以提高效率。TEA 探索風速資料中不同樣本序列之間的潛在關係。本研究利用了美國國家航空暨太空總署 (NASA) 全球能源資源預測 (NASA POWER) 來自孟加拉吉大港巴廷加海灘 (緯度 22.2352{\deg} N，經度 91.7914{\deg} E) 一年 (六個季節) 的風速資料。研究結果表明，TCNFormer 在預測準確度方面優於最先進的模型。所提出的 TCNFormer 為時空 WSF 提出了一種有前途的方法，並且可以在風力發電系統的實際應用中實現理想的性能。</paragraph>

##### **How transformers learn structured data: insights from hierarchical filtering**
2408.15138v1 by Jerome Garnier-Brun, Marc Mézard, Emanuele Moscato, Luca Saglietti

We introduce a hierarchical filtering procedure for generative models of
sequences on trees, enabling control over the range of positional correlations
in the data. Leveraging this controlled setting, we provide evidence that
vanilla encoder-only transformer architectures can implement the optimal Belief
Propagation algorithm on both root classification and masked language modeling
tasks. Correlations at larger distances corresponding to increasing layers of
the hierarchy are sequentially included as the network is trained. We analyze
how the transformer layers succeed by focusing on attention maps from models
trained with varying degrees of filtering. These attention maps show clear
evidence for iterative hierarchical reconstruction of correlations, and we can
relate these observations to a plausible implementation of the exact inference
algorithm for the network sizes considered.

摘要：我們引入了一個分層過濾程序，用於樹狀結構序列的生成模型，能夠控制資料中位置相關性的範圍。利用這個受控設定，我們提供了證據，表明僅編碼器的香草Transformer架構可以在根分類和遮罩語言建模任務中實作最佳的信念傳播演算法。隨著網路受訓，與層級中遞增層數對應的較大距離相關性會依序納入。我們分析Transformer層如何成功，重點關注使用不同程度過濾訓練的模型的注意力圖。這些注意力圖清楚地證明了相關性的迭代式分層重建，而且我們可以將這些觀察與所考慮的網路大小的精確推論演算法的合理實作相關聯。

##### **Evaluating the Energy Consumption of Machine Learning: Systematic Literature Review and Experiments**
2408.15128v1 by Charlotte Rodriguez, Laura Degioanni, Laetitia Kameni, Richard Vidal, Giovanni Neglia

Monitoring, understanding, and optimizing the energy consumption of Machine
Learning (ML) are various reasons why it is necessary to evaluate the energy
usage of ML. However, there exists no universal tool that can answer this
question for all use cases, and there may even be disagreement on how to
evaluate energy consumption for a specific use case. Tools and methods are
based on different approaches, each with their own advantages and drawbacks,
and they need to be mapped out and explained in order to select the most
suitable one for a given situation. We address this challenge through two
approaches. First, we conduct a systematic literature review of all tools and
methods that permit to evaluate the energy consumption of ML (both at training
and at inference), irrespective of whether they were originally designed for
machine learning or general software. Second, we develop and use an
experimental protocol to compare a selection of these tools and methods. The
comparison is both qualitative and quantitative on a range of ML tasks of
different nature (vision, language) and computational complexity. The
systematic literature review serves as a comprehensive guide for understanding
the array of tools and methods used in evaluating energy consumption of ML, for
various use cases going from basic energy monitoring to consumption
optimization. Two open-source repositories are provided for further
exploration. The first one contains tools that can be used to replicate this
work or extend the current review. The second repository houses the
experimental protocol, allowing users to augment the protocol with new ML
computing tasks and additional energy evaluation tools.

摘要：<paragraph>監控、了解和優化機器學習 (ML) 的能源消耗是評估 ML 能源使用的各種原因。然而，目前尚無萬能工具可以針對所有使用案例回答這個問題，甚至可能對於如何評估特定使用案例的能源消耗存在分歧。工具和方法基於不同的方法，各自有其優點和缺點，並且需要將它們繪製出來並加以說明，才能為特定情況選擇最合適的方法。我們透過兩種方法來解決這個挑戰。首先，我們對所有允許評估 ML 能源消耗（在訓練和推理時）的工具和方法進行系統性的文獻回顧，無論它們最初是為機器學習或一般軟體設計的。其次，我們開發並使用實驗協定來比較這些工具和方法的選項。比較在性質不同（視覺、語言）和計算複雜性範圍的 ML 任務上是定性和定量的。系統性的文獻回顧作為一個全面的指南，用於了解評估 ML 能源消耗所使用的工具和方法陣列，適用於從基本能源監控到消耗優化的各種使用案例。提供兩個開源儲存庫以供進一步探索。第一個包含可複製這項工作或擴展目前回顧的工具。第二個儲存庫容納實驗協定，允許使用者使用新的 ML 計算任務和額外的能源評估工具來擴充協定。</paragraph>

##### **The Uniqueness of LLaMA3-70B with Per-Channel Quantization: An Empirical Study**
2408.15301v1 by Minghai Qin

We have observed a distinctive quantization-related behavior in the
LLaMA3/3.1-70B models that is absent in both the LLaMA2-70B and
LLaMA3/3.1-8B/405B models. Quantization is a crucial technique for deploying
large language models (LLMs) efficiently. Among various bit widths and
representations for weights and activations, the 8-bit integer weight and 8-bit
integer activation (W8A8) configuration is particularly popular due to its
widespread hardware support. However, the impact of W8A8 post-training
quantization on model accuracy remains contentious. While several studies have
suggested calibrating either weights or activations to mitigate accuracy
degradation, a comprehensive solution has yet to be identified. In this paper,
we empirically investigate multiple LLMs featured on an open LLM leaderboard,
discovering that the LLaMA3-70B model series have a unique accuracy degradation
behavior with W8A8 per-channel post-training quantization. In contrast, other
model series such as LLaMA2, LLaMA3-8B, Qwen, Mixtral, Mistral, Phi-3, and
Falcon demonstrate robust performance with W8A8, sometimes surpassing their
FP16 counterparts. Contrary to previous assertions attributing degradation to
the large dynamic range of activations, our findings indicate that the weight
distribution of the LLaMA3-70B is the primary factor behind the vulnerability.
By meticulously analyzing the distinct characteristics of weight distributions
across Transformer blocks, we propose a mixed strategy with less than 3% of the
layers enabling finer W8A8 quantization granularity, while the remaining 97% of
layers retain the per-channel configuration. As a result, the average accuracy
of LLaMA3-70B-W8A8 is increased from 45.5% to 73.4% (just 0.7% shy of
LLaMA3-70B-FP16) across eight reasoning tasks. Notably, our method requires
neither calibration nor fine-tuning.

摘要：<paragraph>我們在 LLaMA3/3.1-70B 模型中觀察到一種獨特的量化相關行為，而 LLaMA2-70B 和 LLaMA3/3.1-8B/405B 模型中沒有這種行為。量化是有效部署大型語言模型 (LLM) 的一項關鍵技術。在各種位元寬度和權重與激活的表示法中，8 位元整數權重和 8 位元整數激活 (W8A8) 組態特別受歡迎，因為它廣泛獲得硬體支援。然而，W8A8 訓練後量化對模型精度的影響仍然存在爭議。雖然有幾項研究建議校正權重或激活以減輕精度的降低，但仍未找出一個全面的解決方案。在本文中，我們根據公開的 LLM 排行榜實證調查了多個 LLM，發現 LLaMA3-70B 模型系列在 W8A8 每通道訓練後量化中具有獨特的精度降低行為。相比之下，其他模型系列，例如 LLaMA2、LLaMA3-8B、Qwen、Mixtral、Mistral、Phi-3 和 Falcon，則展現出對 W8A8 的強健效能，有時甚至超越其 FP16 對應項。與先前將降低歸因於激活的大動態範圍的主張相反，我們的發現表明 LLaMA3-70B 的權重分佈是造成易受影響的主要因素。透過仔細分析 Transformer 區塊中權重分佈的不同特徵，我們提出了一種混合策略，其中不到 3% 的層啟用了更精細的 W8A8 量化粒度，而其餘 97% 的層則保留每通道組態。因此，LLaMA3-70B-W8A8 的平均準確度從 45.5% 提高到 73.4%（僅比 LLaMA3-70B-FP16 低 0.7%），涵蓋八項推理任務。值得注意的是，我們的方法既不需要校正，也不需要微調。</paragraph>

##### **Urdu Digital Text Word Optical Character Recognition Using Permuted Auto Regressive Sequence Modeling**
2408.15119v2 by Ahmed Mustafa, Muhammad Tahir Rafique, Muhammad Ijlal Baig, Hasan Sajid, Muhammad Jawad Khan, Karam Dad Kallu

This research paper presents a novel word-level Optical Character Recognition
(OCR) model developed specifically for digital Urdu text. The model utilizes
transformer-based architectures and attention mechanisms to address the unique
challenges of recognizing Urdu script, which includes handling a diverse range
of text styles, fonts, and variations. Trained on a comprehensive dataset of
approximately 160,000 Urdu text images, the model incorporates a permuted
autoregressive sequence (PARSeq) architecture. This design enables
context-aware inference and iterative refinement by leveraging bidirectional
context information, significantly enhancing its ability to accurately
recognize Urdu characters. The model achieves a character error rate (CER) of
0.178, highlighting its effectiveness and precision in real-world applications.
However, the model has some limitations, such as difficulties with blurred
images, non-horizontal orientations, and the presence of trailing punctuation
marks, which can introduce noise into the recognition process. Addressing these
challenges will be a key focus of future work. Future research will aim to
further refine the model through advanced data augmentation techniques,
optimization of hyperparameters, and the integration of context-aware language
models, ultimately enhancing the model's performance and robustness in Urdu
text recognition.

摘要：這篇研究論文提出了一個新穎的單字層級光學字元辨識 (OCR) 模型，專為數位烏爾都語文字而開發。此模型利用基於轉換器的架構和注意力機制來解決辨識烏爾都語文字的獨特挑戰，包括處理各種文字樣式、字體和變化。在約 160,000 張烏爾都語文字影像的綜合資料集上訓練後，此模型結合了一個排列的自動迴歸序列 (PARSeq) 架構。此設計透過利用雙向脈絡資訊，實現了脈絡感知推論和反覆精煉，大幅提升了其準確辨識烏爾都語字元的能。此模型達到了 0.178 的字元錯誤率 (CER)，突顯了其在實際應用中的效能和精準度。然而，此模型有一些限制，例如難以處理模糊影像、非水平方向和存在尾隨標點符號，這些因素會在辨識過程中產生雜訊。解決這些挑戰將是未來工作的重點。未來的研究將旨在透過進階資料擴充技術、超參數最佳化和整合脈絡感知語言模型，進一步精煉此模型，最終提升此模型在烏爾都語文字辨識中的效能和穩健性。

##### **Evaluating Stability of Unreflective Alignment**
2408.15116v1 by James Lucassen, Mark Henry, Philippa Wright, Owen Yeung

Many theoretical obstacles to AI alignment are consequences of reflective
stability - the problem of designing alignment mechanisms that the AI would not
disable if given the option. However, problems stemming from reflective
stability are not obviously present in current LLMs, leading to disagreement
over whether they will need to be solved to enable safe delegation of cognitive
labor. In this paper, we propose Counterfactual Priority Change (CPC)
destabilization as a mechanism by which reflective stability problems may arise
in future LLMs. We describe two risk factors for CPC-destabilization: 1)
CPC-based stepping back and 2) preference instability. We develop preliminary
evaluations for each of these risk factors, and apply them to frontier LLMs.
Our findings indicate that in current LLMs, increased scale and capability are
associated with increases in both CPC-based stepping back and preference
instability, suggesting that CPC-destabilization may cause reflective stability
problems in future LLMs.

摘要：許多理論上 AI 對齊的障礙是反射穩定性的後果，即設計 AI 在有選項時不會停用的對齊機制的難題。然而，源自反射穩定性的問題在目前的 LLM 中並不明顯，導致對是否需要解決這些問題以實現認知勞動的安全委派產生分歧。在本文中，我們提出反事實優先變更 (CPC) 去穩定化，作為反射穩定性問題可能在未來 LLM 中產生的機制。我們描述了 CPC 去穩定的兩個風險因素：1) 基於 CPC 的後退和 2) 偏好不穩定。我們針對這些風險因素中的每一個開發初步評估，並將它們應用於前沿 LLM。我們的研究結果表明，在目前的 LLM 中，規模和能力的增加與基於 CPC 的後退和偏好不穩定的增加有關，這表明 CPC 去穩定化可能會在未來的 LLM 中導致反射穩定性問題。

##### **GIFT-SW: Gaussian noise Injected Fine-Tuning of Salient Weights for LLMs**
2408.15300v1 by Maxim Zhelnin, Viktor Moskvoretskii, Egor Shvetsov, Egor Venediktov, Mariya Krylova, Aleksandr Zuev, Evgeny Burnaev

Parameter Efficient Fine-Tuning (PEFT) methods have gained popularity and
democratized the usage of Large Language Models (LLMs). Recent studies have
shown that a small subset of weights significantly impacts performance. Based
on this observation, we introduce a novel PEFT method, called Gaussian noise
Injected Fine Tuning of Salient Weights (GIFT-SW). Our method updates only
salient columns, while injecting Gaussian noise into non-salient ones. To
identify these columns, we developeda generalized sensitivity metric that
extends and unifies metrics from previous studies. Experiments with LLaMA
models demonstrate that GIFT-SW outperforms full fine-tuning and modern PEFT
methods under the same computational budget. Moreover, GIFT-SW offers practical
advantages to recover performance of models subjected to mixed-precision
quantization with keeping salient weights in full precision.

摘要：參數高效微調 (PEFT) 方法獲得普及，並讓大型語言模型 (LLM) 的使用民主化。最近的研究顯示，一小部分權重會顯著影響效能。根據此觀察，我們提出了一種新的 PEFT 方法，稱為高斯雜訊注入顯著權重微調 (GIFT-SW)。我們的這種方法僅更新顯著的欄，同時在不顯著的欄注入高斯雜訊。為了識別這些欄，我們開發了一種廣義敏感性指標，它擴充並統一了前人的研究指標。使用 LLaMA 模型進行的實驗證明，在相同的運算預算下，GIFT-SW 優於全微調和現代 PEFT 方法。此外，GIFT-SW 提供了實際優勢，可以透過將顯著權重保持在全精度，來恢復遭受混合精度量化影響的模型效能。

