{"2406.02267": {"publish_time": "2024-06-04", "title": "Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation", "paper_summary": "While large language models (LLMs) pre-trained on massive amounts of unpaired\nlanguage data have reached the state-of-the-art in machine translation (MT) of\ngeneral domain texts, post-editing (PE) is still required to correct errors and\nto enhance term translation quality in specialized domains. In this paper we\npresent a pilot study of enhancing translation memories (TM) produced by PE\n(source segments, machine translations, and reference translations, henceforth\ncalled PE-TM) for the needs of correct and consistent term translation in\ntechnical domains.\n  We investigate a light-weight two-step scenario where, at inference time, a\nhuman translator marks errors in the first translation step, and in a second\nstep a few similar examples are extracted from the PE-TM to prompt an LLM. Our\nexperiment shows that the additional effort of augmenting translations with\nhuman error markings guides the LLM to focus on a correction of the marked\nerrors, yielding consistent improvements over automatic PE (APE) and MT from\nscratch.", "paper_summary_zh": "\u5118\u7ba1\u9810\u5148\u5728\u5927\u91cf\u672a\u914d\u5c0d\u8a9e\u8a00\u8cc7\u6599\u4e0a\u8a13\u7df4\u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5728\u4e00\u822c\u9818\u57df\u6587\u5b57\u7684\u6a5f\u5668\u7ffb\u8b6f (MT) \u4e2d\u9054\u5230\u6700\u5148\u9032\u7684\u5883\u754c\uff0c\u4f46\u4ecd\u9700\u8981\u5f8c\u7de8\u8f2f (PE) \u4f86\u4fee\u6b63\u932f\u8aa4\u4e26\u63d0\u5347\u7279\u5b9a\u9818\u57df\u7684\u8853\u8a9e\u7ffb\u8b6f\u54c1\u8cea\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u8a66\u9a57\u7814\u7a76\uff0c\u4ee5\u63d0\u5347\u5f8c\u7de8\u8f2f\u7522\u751f\u7684\u7ffb\u8b6f\u8a18\u61b6\u9ad4 (TM)\uff08\u539f\u59cb\u5340\u584a\u3001\u6a5f\u5668\u7ffb\u8b6f\u548c\u53c3\u8003\u7ffb\u8b6f\uff0c\u4ee5\u4e0b\u7c21\u7a31 PE-TM\uff09\uff0c\u4ee5\u6eff\u8db3\u6280\u8853\u9818\u57df\u6b63\u78ba\u4e14\u4e00\u81f4\u7684\u8853\u8a9e\u7ffb\u8b6f\u9700\u6c42\u3002\n\n\u6211\u5011\u7814\u7a76\u4e00\u500b\u8f15\u91cf\u7d1a\u7684\u5169\u6b65\u9a5f\u5834\u666f\uff0c\u5728\u63a8\u8ad6\u6642\u9593\u6642\uff0c\u4eba\u985e\u7ffb\u8b6f\u8005\u6703\u5728\u7b2c\u4e00\u500b\u7ffb\u8b6f\u6b65\u9a5f\u4e2d\u6a19\u8a18\u932f\u8aa4\uff0c\u4e26\u5728\u7b2c\u4e8c\u500b\u6b65\u9a5f\u4e2d\u5f9e PE-TM \u4e2d\u63d0\u53d6\u4e00\u4e9b\u985e\u4f3c\u7684\u7bc4\u4f8b\uff0c\u4ee5\u63d0\u793a LLM\u3002\u6211\u5011\u7684\u5be6\u9a57\u986f\u793a\uff0c\u900f\u904e\u4eba\u985e\u932f\u8aa4\u6a19\u8a18\u4f86\u64f4\u5145\u7ffb\u8b6f\u7684\u984d\u5916\u5de5\u4f5c\uff0c\u5f15\u5c0e LLM \u5c08\u6ce8\u65bc\u4fee\u6b63\u6a19\u8a18\u7684\u932f\u8aa4\uff0c\u7522\u751f\u6bd4\u81ea\u52d5\u5f8c\u7de8\u8f2f (APE) \u548c\u5f9e\u982d\u958b\u59cb\u7684 MT \u66f4\u4e00\u81f4\u7684\u9032\u6b65\u3002", "author": "Nathaniel Berger et.al.", "authors": "Nathaniel Berger, Stefan Riezler, Miriam Exel, Matthias Huck", "id": "2406.02267v1", "paper_url": "http://arxiv.org/abs/2406.02267v1", "repo": "null"}}