{"2409.10077": {"publish_time": "2024-09-16", "title": "LLM-DER:A Named Entity Recognition Method Based on Large Language Models for Chinese Coal Chemical Domain", "paper_summary": "Domain-specific Named Entity Recognition (NER), whose goal is to recognize\ndomain-specific entities and their categories, provides an important support\nfor constructing domain knowledge graphs. Currently, deep learning-based\nmethods are widely used and effective in NER tasks, but due to the reliance on\nlarge-scale labeled data. As a result, the scarcity of labeled data in a\nspecific domain will limit its application.Therefore, many researches started\nto introduce few-shot methods and achieved some results. However, the entity\nstructures in specific domains are often complex, and the current few-shot\nmethods are difficult to adapt to NER tasks with complex features.Taking the\nChinese coal chemical industry domain as an example,there exists a complex\nstructure of multiple entities sharing a single entity, as well as multiple\nrelationships for the same pair of entities, which affects the NER task under\nthe sample less condition.In this paper, we propose a Large Language Models\n(LLMs)-based entity recognition framework LLM-DER for the domain-specific\nentity recognition problem in Chinese, which enriches the entity information by\ngenerating a list of relationships containing entity types through LLMs, and\ndesigning a plausibility and consistency evaluation method to remove\nmisrecognized entities, which can effectively solve the complex structural\nentity recognition problem in a specific domain.The experimental results of\nthis paper on the Resume dataset and the self-constructed coal chemical dataset\nCoal show that LLM-DER performs outstandingly in domain-specific entity\nrecognition, not only outperforming the existing GPT-3.5-turbo baseline, but\nalso exceeding the fully-supervised baseline, verifying its effectiveness in\nentity recognition.", "paper_summary_zh": "<paragraph>\u9818\u57df\u7279\u5b9a\u547d\u540d\u5be6\u9ad4\u8fa8\u8b58\uff08NER\uff09\uff0c\u5176\u76ee\u6a19\u662f\u8fa8\u8b58\u9818\u57df\u7279\u5b9a\u5be6\u9ad4\u53ca\u5176\u985e\u5225\uff0c\u70ba\u5efa\u69cb\u9818\u57df\u77e5\u8b58\u5716\u8b5c\u63d0\u4f9b\u91cd\u8981\u7684\u652f\u63f4\u3002\u76ee\u524d\uff0c\u57fa\u65bc\u6df1\u5ea6\u5b78\u7fd2\u7684\u65b9\u6cd5\u5ee3\u6cdb\u7528\u65bc NER \u4efb\u52d9\u4e14\u5341\u5206\u6709\u6548\uff0c\u4f46\u7531\u65bc\u4f9d\u8cf4\u65bc\u5927\u898f\u6a21\u6a19\u8a18\u8cc7\u6599\u3002\u56e0\u6b64\uff0c\u7279\u5b9a\u9818\u57df\u4e2d\u6a19\u8a18\u8cc7\u6599\u7684\u7a00\u5c11\u6703\u9650\u5236\u5176\u61c9\u7528\u3002\u56e0\u6b64\uff0c\u8a31\u591a\u7814\u7a76\u958b\u59cb\u5f15\u5165\u5c11\u91cf\u6a23\u672c\u65b9\u6cd5\u4e26\u7372\u5f97\u4e00\u4e9b\u6210\u679c\u3002\u7136\u800c\uff0c\u7279\u5b9a\u9818\u57df\u4e2d\u7684\u5be6\u9ad4\u7d50\u69cb\u901a\u5e38\u5f88\u8907\u96dc\uff0c\u800c\u76ee\u524d\u7684\u5c11\u91cf\u6a23\u672c\u65b9\u6cd5\u96e3\u4ee5\u9069\u61c9\u5177\u6709\u8907\u96dc\u7279\u5fb5\u7684 NER \u4efb\u52d9\u3002\u4ee5\u4e2d\u570b\u7164\u5316\u5de5\u7522\u696d\u9818\u57df\u70ba\u4f8b\uff0c\u5b58\u5728\u591a\u500b\u5be6\u9ad4\u5171\u7528\u55ae\u4e00\u5be6\u9ad4\u7684\u8907\u96dc\u7d50\u69cb\uff0c\u4ee5\u53ca\u540c\u4e00\u5c0d\u5be6\u9ad4\u6709\u591a\u91cd\u95dc\u4fc2\uff0c\u9019\u6703\u5f71\u97ff\u6a23\u672c\u8f03\u5c11\u689d\u4ef6\u4e0b\u7684 NER \u4efb\u52d9\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u57fa\u65bc\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5be6\u9ad4\u8fa8\u8b58\u67b6\u69cb LLM-DER\uff0c\u7528\u65bc\u4e2d\u6587\u9818\u57df\u7279\u5b9a\u5be6\u9ad4\u8fa8\u8b58\u554f\u984c\uff0c\u901a\u904e LLM \u751f\u6210\u5305\u542b\u5be6\u9ad4\u985e\u578b\u7684\u95dc\u4fc2\u6e05\u55ae\uff0c\u4e26\u8a2d\u8a08\u4e00\u500b\u5408\u7406\u6027\u548c\u4e00\u81f4\u6027\u8a55\u4f30\u65b9\u6cd5\u4f86\u79fb\u9664\u8fa8\u8b58\u932f\u8aa4\u7684\u5be6\u9ad4\uff0c\u5f9e\u800c\u53ef\u4ee5\u6709\u6548\u89e3\u6c7a\u7279\u5b9a\u9818\u57df\u4e2d\u8907\u96dc\u7d50\u69cb\u5be6\u9ad4\u8fa8\u8b58\u554f\u984c\u3002\u672c\u6587\u5728 Resume \u8cc7\u6599\u96c6\u548c\u81ea\u5efa\u7164\u5316\u5de5\u8cc7\u6599\u96c6 Coal \u4e0a\u7684\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0cLLM-DER \u5728\u9818\u57df\u7279\u5b9a\u5be6\u9ad4\u8fa8\u8b58\u4e2d\u8868\u73fe\u51fa\u8272\uff0c\u4e0d\u50c5\u512a\u65bc\u73fe\u6709\u7684 GPT-3.5-turbo \u57fa\u6e96\uff0c\u9084\u8d85\u904e\u4e86\u5b8c\u5168\u76e3\u7763\u7684\u57fa\u7dda\uff0c\u9a57\u8b49\u4e86\u5176\u5728\u5be6\u9ad4\u8fa8\u8b58\u4e2d\u7684\u6709\u6548\u6027\u3002</paragraph>", "author": "Le Xiao et.al.", "authors": "Le Xiao, Yunfei Xu, Jing Zhao", "id": "2409.10077v1", "paper_url": "http://arxiv.org/abs/2409.10077v1", "repo": "null"}}