
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-14**|**TemporalBench: Benchmarking Fine-grained Temporal Understanding for Multimodal Video Models**|Mu Cai et.al.|[2410.10818v1](http://arxiv.org/abs/2410.10818v1)|null|
|**2024-10-14**|**DuoAttention: Efficient Long-Context LLM Inference with Retrieval and Streaming Heads**|Guangxuan Xiao et.al.|[2410.10819v1](http://arxiv.org/abs/2410.10819v1)|[link](https://github.com/mit-han-lab/duo-attention)|
|**2024-10-14**|**LVD-2M: A Long-take Video Dataset with Temporally Dense Captions**|Tianwei Xiong et.al.|[2410.10816v1](http://arxiv.org/abs/2410.10816v1)|[link](https://github.com/silentview/lvd-2m)|
|**2024-10-14**|**Depth Any Video with Scalable Synthetic Data**|Honghui Yang et.al.|[2410.10815v1](http://arxiv.org/abs/2410.10815v1)|null|
|**2024-10-14**|**LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory**|Di Wu et.al.|[2410.10813v1](http://arxiv.org/abs/2410.10813v1)|[link](https://github.com/xiaowu0162/longmemeval)|
|**2024-10-14**|**Your Mixture-of-Experts LLM Is Secretly an Embedding Model For Free**|Ziyue Li et.al.|[2410.10814v1](http://arxiv.org/abs/2410.10814v1)|null|
|**2024-10-14**|**HART: Efficient Visual Generation with Hybrid Autoregressive Transformer**|Haotian Tang et.al.|[2410.10812v1](http://arxiv.org/abs/2410.10812v1)|[link](https://github.com/mit-han-lab/hart)|
|**2024-10-14**|**Local and Global Decoding in Text Generation**|Daniel Gareev et.al.|[2410.10810v1](http://arxiv.org/abs/2410.10810v1)|[link](https://github.com/lowlypalace/global-decoding)|
|**2024-10-14**|**Hard-Constrained Neural Networks with Universal Approximation Guarantees**|Youngjae Min et.al.|[2410.10807v1](http://arxiv.org/abs/2410.10807v1)|null|
|**2024-10-14**|**Boosting Camera Motion Control for Video Diffusion Transformers**|Soon Yau Cheong et.al.|[2410.10802v1](http://arxiv.org/abs/2410.10802v1)|null|
|**2024-10-14**|**Mix Data or Merge Models? Optimizing for Diverse Multi-Task Learning**|Aakanksha et.al.|[2410.10801v1](http://arxiv.org/abs/2410.10801v1)|null|
|**2024-10-14**|**Context-Parametric Inversion: Why Instruction Finetuning May Not Actually Improve Context Reliance**|Sachin Goyal et.al.|[2410.10796v1](http://arxiv.org/abs/2410.10796v1)|[link](https://github.com/locuslab/context-parametric-inversion)|
|**2024-10-14**|**On Information-Theoretic Measures of Predictive Uncertainty**|Kajetan Schweighofer et.al.|[2410.10786v1](http://arxiv.org/abs/2410.10786v1)|[link](https://github.com/ml-jku/uncertainty-measures)|
|**2024-10-14**|**When Attention Sink Emerges in Language Models: An Empirical View**|Xiangming Gu et.al.|[2410.10781v1](http://arxiv.org/abs/2410.10781v1)|[link](https://github.com/sail-sg/attention-sink)|
|**2024-10-14**|**Focused ReAct: Improving ReAct through Reiterate and Early Stop**|Shuoqiu Li et.al.|[2410.10779v1](http://arxiv.org/abs/2410.10779v1)|null|
|**2024-10-14**|**Adaptive Diffusion Terrain Generator for Autonomous Uneven Terrain Navigation**|Youwei Yu et.al.|[2410.10766v1](http://arxiv.org/abs/2410.10766v1)|null|
|**2024-10-14**|**AFlow: Automating Agentic Workflow Generation**|Jiayi Zhang et.al.|[2410.10762v1](http://arxiv.org/abs/2410.10762v1)|[link](https://github.com/geekan/metagpt)|
|**2024-10-14**|**Denial-of-Service Poisoning Attacks against Large Language Models**|Kuofeng Gao et.al.|[2410.10760v1](http://arxiv.org/abs/2410.10760v1)|[link](https://github.com/sail-sg/p-dos)|
|**2024-10-14**|**Arrhythmia Classification Using Graph Neural Networks Based on Correlation Matrix**|Seungwoo Han et.al.|[2410.10758v1](http://arxiv.org/abs/2410.10758v1)|null|
|**2024-10-14**|**Use Random Selection for Now: Investigation of Few-Shot Selection Strategies in LLM-based Text Augmentation for Classification**|Jan Cegin et.al.|[2410.10756v1](http://arxiv.org/abs/2410.10756v1)|null|
|**2024-10-14**|**FlexGen: Flexible Multi-View Generation from Text and Image Inputs**|Xinli Xu et.al.|[2410.10745v1](http://arxiv.org/abs/2410.10745v1)|null|
|**2024-10-14**|**NT-LLM: A Novel Node Tokenizer for Integrating Graph Structure into Large Language Models**|Yanbiao Ji et.al.|[2410.10743v1](http://arxiv.org/abs/2410.10743v1)|null|
|**2024-10-14**|**SensorBench: Benchmarking LLMs in Coding-Based Sensor Processing**|Pengrui Quan et.al.|[2410.10741v1](http://arxiv.org/abs/2410.10741v1)|[link](https://github.com/nesl/llm_sensor_processing)|
|**2024-10-14**|**Balancing Continuous Pre-Training and Instruction Fine-Tuning: Optimizing Instruction-Following in LLMs**|Ishan Jindal et.al.|[2410.10739v1](http://arxiv.org/abs/2410.10739v1)|null|
|**2024-10-14**|**DrivingDojo Dataset: Advancing Interactive and Knowledge-Enriched Driving World Model**|Yuqi Wang et.al.|[2410.10738v1](http://arxiv.org/abs/2410.10738v1)|null|
|**2024-10-14**|**Embedding Self-Correction as an Inherent Ability in Large Language Models for Enhanced Mathematical Reasoning**|Kuofeng Gao et.al.|[2410.10735v1](http://arxiv.org/abs/2410.10735v1)|null|
|**2024-10-14**|**Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models**|Junyu Chen et.al.|[2410.10733v1](http://arxiv.org/abs/2410.10733v1)|[link](https://github.com/mit-han-lab/efficientvit)|
|**2024-10-14**|**Towards LLM-guided Efficient and Interpretable Multi-linear Tensor Network Rank Selection**|Giorgos Iacovides et.al.|[2410.10728v1](http://arxiv.org/abs/2410.10728v1)|null|
|**2024-10-14**|**Large Language Models Are Active Critics in NLG Evaluation**|Shuying Xu et.al.|[2410.10724v1](http://arxiv.org/abs/2410.10724v1)|null|
|**2024-10-14**|**SeedLM: Compressing LLM Weights into Seeds of Pseudo-Random Generators**|Rasoul Shafipour et.al.|[2410.10714v1](http://arxiv.org/abs/2410.10714v1)|null|
|**2024-10-14**|**Early Diagnoses of Acute Lymphoblastic Leukemia Using YOLOv8 and YOLOv11 Deep Learning Models**|Alaa Awad et.al.|[2410.10701v1](http://arxiv.org/abs/2410.10701v1)|null|
|**2024-10-14**|**Derail Yourself: Multi-turn LLM Jailbreak Attack through Self-discovered Clues**|Qibing Ren et.al.|[2410.10700v1](http://arxiv.org/abs/2410.10700v1)|[link](https://github.com/renqibing/actorattack)|
|**2024-10-14**|**Building a Multivariate Time Series Benchmarking Datasets Inspired by Natural Language Processing (NLP)**|Mohammad Asif Ibna Mustafa et.al.|[2410.10687v1](http://arxiv.org/abs/2410.10687v1)|null|
|**2024-10-14**|**Large Language Model Evaluation via Matrix Nuclear-Norm**|Yahan Li et.al.|[2410.10672v1](http://arxiv.org/abs/2410.10672v1)|null|
|**2024-10-14**|**Double Jeopardy and Climate Impact in the Use of Large Language Models: Socio-economic Disparities and Reduced Utility for Non-English Speakers**|Aivin V. Solatorio et.al.|[2410.10665v1](http://arxiv.org/abs/2410.10665v1)|null|
|**2024-10-14**|**Generative AI and Its Impact on Personalized Intelligent Tutoring Systems**|Subhankar Maity et.al.|[2410.10650v1](http://arxiv.org/abs/2410.10650v1)|null|
|**2024-10-14**|**DR-MPC: Deep Residual Model Predictive Control for Real-world Social Navigation**|James R. Han et.al.|[2410.10646v1](http://arxiv.org/abs/2410.10646v1)|null|
|**2024-10-14**|**Adapt-$\infty$: Scalable Lifelong Multimodal Instruction Tuning via Dynamic Data Selection**|Adyasha Maharana et.al.|[2410.10636v1](http://arxiv.org/abs/2410.10636v1)|null|
|**2024-10-14**|**Thinking LLMs: General Instruction Following with Thought Generation**|Tianhao Wu et.al.|[2410.10630v1](http://arxiv.org/abs/2410.10630v1)|null|
|**2024-10-14**|**Efficiently Democratizing Medical LLMs for 50 Languages via a Mixture of Language Family Experts**|Guorui Zheng et.al.|[2410.10626v1](http://arxiv.org/abs/2410.10626v1)|[link](https://github.com/freedomintelligence/apollomoe)|
|**2024-10-14**|**SensorLLM: Aligning Large Language Models with Motion Sensors for Human Activity Recognition**|Zechen Li et.al.|[2410.10624v1](http://arxiv.org/abs/2410.10624v1)|[link](https://github.com/zechenli03/sensorllm)|
|**2024-10-14**|**Modeling News Interactions and Influence for Financial Market Prediction**|Mengyu Wang et.al.|[2410.10614v1](http://arxiv.org/abs/2410.10614v1)|null|
|**2024-10-14**|**Intelligent prospector v2.0: exploration drill planning under epistemic model uncertainty**|John Mern et.al.|[2410.10610v1](http://arxiv.org/abs/2410.10610v1)|null|
|**2024-10-14**|**BrainMVP: Multi-modal Vision Pre-training for Brain Image Analysis using Multi-parametric MRI**|Shaohao Rui et.al.|[2410.10604v1](http://arxiv.org/abs/2410.10604v1)|null|
|**2024-10-14**|**Neural networks that overcome classic challenges through practice**|Kazuki Irie et.al.|[2410.10596v1](http://arxiv.org/abs/2410.10596v1)|null|
|**2024-10-14**|**VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality Documents**|Shi Yu et.al.|[2410.10594v1](http://arxiv.org/abs/2410.10594v1)|null|
|**2024-10-14**|**TRESTLE: A Model of Concept Formation in Structured Domains**|Christopher J. MacLellan et.al.|[2410.10588v1](http://arxiv.org/abs/2410.10588v1)|[link](https://github.com/cmaclell/concept_formation)|
|**2024-10-14**|**TÃ¼bingen-CL at SemEval-2024 Task 1:Ensemble Learning for Semantic Relatedness Estimation**|Leixin Zhang et.al.|[2410.10585v1](http://arxiv.org/abs/2410.10585v1)|null|
|**2024-10-14**|**STACKFEED: Structured Textual Actor-Critic Knowledge Base Editing with FeedBack**|Naman Gupta et.al.|[2410.10584v1](http://arxiv.org/abs/2410.10584v1)|null|
|**2024-10-14**|**Multilingual Controlled Generation And Gold-Standard-Agnostic Evaluation of Code-Mixed Sentences**|Ayushman Gupta et.al.|[2410.10580v1](http://arxiv.org/abs/2410.10580v1)|null|
|**2024-10-14**|**Recipe for Zero-shot POS Tagging: Is It Useful in Realistic Scenarios?**|Zeno Vandenbulcke et.al.|[2410.10576v1](http://arxiv.org/abs/2410.10576v1)|null|
|**2024-10-14**|**When Precedents Clash**|Cecilia Di Florio et.al.|[2410.10567v1](http://arxiv.org/abs/2410.10567v1)|null|
|**2024-10-14**|**Is Structure Dependence Shaped for Efficient Communication?: A Case Study on Coordination**|Kohei Kajikawa et.al.|[2410.10556v1](http://arxiv.org/abs/2410.10556v1)|[link](https://github.com/kohei-kaji/coordination)|
|**2024-10-14**|**ROSAR: An Adversarial Re-Training Framework for Robust Side-Scan Sonar Object Detection**|Martin Aubard et.al.|[2410.10554v1](http://arxiv.org/abs/2410.10554v1)|[link](https://github.com/remaro-network/rosar-framework)|
|**2024-10-14**|**SLaNC: Static LayerNorm Calibration**|Mahsa Salmani et.al.|[2410.10553v1](http://arxiv.org/abs/2410.10553v1)|null|
|**2024-10-14**|**Hybrid Transformer for Early Alzheimer's Detection: Integration of Handwriting-Based 2D Images and 1D Signal Features**|Changqing Gong et.al.|[2410.10547v1](http://arxiv.org/abs/2410.10547v1)|null|
|**2024-10-14**|**Rethinking Legal Judgement Prediction in a Realistic Scenario in the Era of Large Language Models**|Shubham Kumar Nigam et.al.|[2410.10542v1](http://arxiv.org/abs/2410.10542v1)|null|
|**2024-10-14**|**Reproducible Machine Learning-based Voice Pathology Detection: Introducing the Pitch Difference Feature**|Jan Vrba et.al.|[2410.10537v1](http://arxiv.org/abs/2410.10537v1)|[link](https://github.com/aailab-uct/automated-robust-and-reproducible-voice-pathology-detection)|
|**2024-10-14**|**Get Rid of Task Isolation: A Continuous Multi-task Spatio-Temporal Learning Framework**|Zhongchao Yi et.al.|[2410.10524v1](http://arxiv.org/abs/2410.10524v1)|[link](https://github.com/dilab-ustcsz/cmust)|
|**2024-10-14**|**UniGEM: A Unified Approach to Generation and Property Prediction for Molecules**|Shikun Feng et.al.|[2410.10516v1](http://arxiv.org/abs/2410.10516v1)|null|
|**2024-10-14**|**Everyday Speech in the Indian Subcontinent**|Utkarsh Pathak et.al.|[2410.10508v1](http://arxiv.org/abs/2410.10508v1)|null|
|**2024-10-14**|**A Practical Approach to Causal Inference over Time**|Martina Cinquini et.al.|[2410.10502v1](http://arxiv.org/abs/2410.10502v1)|null|
|**2024-10-14**|**Cultural Fidelity in Large-Language Models: An Evaluation of Online Language Resources as a Driver of Model Performance in Value Representation**|Sharif Kazemi et.al.|[2410.10489v1](http://arxiv.org/abs/2410.10489v1)|null|
|**2024-10-14**|**Advancing Newborn Care: Precise Birth Time Detection Using AI-Driven Thermal Imaging with Adaptive Normalization**|Jorge GarcÃ­a-Torres et.al.|[2410.10483v1](http://arxiv.org/abs/2410.10483v1)|[link](https://github.com/jtorres258/image-based-tob)|
|**2024-10-14**|**Model-Based Differentially Private Knowledge Transfer for Large Language Models**|Zhaomin Wu et.al.|[2410.10481v1](http://arxiv.org/abs/2410.10481v1)|null|
|**2024-10-14**|**TMGBench: A Systematic Game Benchmark for Evaluating Strategic Reasoning Abilities of LLMs**|Haochuan Wang et.al.|[2410.10479v1](http://arxiv.org/abs/2410.10479v1)|null|
|**2024-10-14**|**Will LLMs Replace the Encoder-Only Models in Temporal Relation Classification?**|Gabriel Roccabruna et.al.|[2410.10476v1](http://arxiv.org/abs/2410.10476v1)|[link](https://github.com/brownfortress/llms-trc)|
|**2024-10-14**|**TABCF: Counterfactual Explanations for Tabular Data Using a Transformer-Based VAE**|Emmanouil Panagiotou et.al.|[2410.10463v1](http://arxiv.org/abs/2410.10463v1)|[link](https://github.com/panagiotou/tabcf)|
|**2024-10-14**|**Ada-K Routing: Boosting the Efficiency of MoE-based LLMs**|Tongtian Yue et.al.|[2410.10456v2](http://arxiv.org/abs/2410.10456v2)|null|
|**2024-10-14**|**Advancing Academic Knowledge Retrieval via LLM-enhanced Representation Similarity Fusion**|Wei Dai et.al.|[2410.10455v1](http://arxiv.org/abs/2410.10455v1)|null|
|**2024-10-14**|**KBLaM: Knowledge Base augmented Language Model**|Xi Wang et.al.|[2410.10450v1](http://arxiv.org/abs/2410.10450v1)|null|
|**2024-10-14**|**QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios**|Timo Pierre Schrader et.al.|[2410.10449v1](http://arxiv.org/abs/2410.10449v1)|null|
|**2024-10-14**|**Free Video-LLM: Prompt-guided Visual Perception for Efficient Training-free Video LLMs**|Kai Han et.al.|[2410.10441v1](http://arxiv.org/abs/2410.10441v1)|[link](https://github.com/contrastive/freevideollm)|
|**2024-10-14**|**LKASeg:Remote-Sensing Image Semantic Segmentation with Large Kernel Attention and Full-Scale Skip Connections**|Xuezhi Xiang et.al.|[2410.10433v1](http://arxiv.org/abs/2410.10433v1)|null|
|**2024-10-14**|**On Calibration of LLM-based Guard Models for Reliable Content Moderation**|Hongfu Liu et.al.|[2410.10414v1](http://arxiv.org/abs/2410.10414v1)|null|
|**2024-10-14**|**Medico: Towards Hallucination Detection and Correction with Multi-source Evidence Fusion**|Xinping Zhao et.al.|[2410.10408v1](http://arxiv.org/abs/2410.10408v1)|null|
|**2024-10-14**|**MMCFND: Multimodal Multilingual Caption-aware Fake News Detection for Low-resource Indic Languages**|Shubhi Bansal et.al.|[2410.10407v1](http://arxiv.org/abs/2410.10407v1)|[link](https://github.com/shubhi-bansal/MMCFND)|
|**2024-10-14**|**FairMindSim: Alignment of Behavior, Emotion, and Belief in Humans and LLM Agents Amid Ethical Dilemmas**|Yu Lei et.al.|[2410.10398v1](http://arxiv.org/abs/2410.10398v1)|null|
|**2024-10-14**|**PIVOT-R: Primitive-Driven Waypoint-Aware World Model for Robotic Manipulation**|Kaidong Zhang et.al.|[2410.10394v1](http://arxiv.org/abs/2410.10394v1)|null|
|**2024-10-14**|**Optimizing Instruction Synthesis: Effective Exploration of Evolutionary Space with Tree Search**|Chenglin Li et.al.|[2410.10392v1](http://arxiv.org/abs/2410.10392v1)|null|
|**2024-10-14**|**BookWorm: A Dataset for Character Description and Analysis**|Argyrios Papoudakis et.al.|[2410.10372v1](http://arxiv.org/abs/2410.10372v1)|null|
|**2024-10-14**|**Innovative Thinking, Infinite Humor: Humor Research of Large Language Models through Structured Thought Leaps**|Han Wang et.al.|[2410.10370v1](http://arxiv.org/abs/2410.10370v1)|null|
|**2024-10-14**|**Affinity-Graph-Guided Contractive Learning for Pretext-Free Medical Image Segmentation with Minimal Annotation**|Zehua Cheng et.al.|[2410.10366v1](http://arxiv.org/abs/2410.10366v1)|null|
|**2024-10-14**|**SpeGCL: Self-supervised Graph Spectrum Contrastive Learning without Positive Samples**|Yuntao Shou et.al.|[2410.10365v1](http://arxiv.org/abs/2410.10365v1)|null|
|**2024-10-14**|**Parenting: Optimizing Knowledge Selection of Retrieval-Augmented Language Models with Parameter Decoupling and Tailored Tuning**|Yongxin Xu et.al.|[2410.10360v1](http://arxiv.org/abs/2410.10360v1)|null|
|**2024-10-14**|**LLM-based Code-Switched Text Generation for Grammatical Error Correction**|Tom Potter et.al.|[2410.10349v1](http://arxiv.org/abs/2410.10349v1)|null|
|**2024-10-14**|**Augmenting In-Context-Learning in LLMs via Automatic Data Labeling and Refinement**|Joseph Shtok et.al.|[2410.10348v1](http://arxiv.org/abs/2410.10348v1)|null|
|**2024-10-14**|**A Unified Approach to Routing and Cascading for LLMs**|Jasper Dekoninck et.al.|[2410.10347v1](http://arxiv.org/abs/2410.10347v1)|null|
|**2024-10-14**|**Locking Down the Finetuned LLMs Safety**|Minjun Zhu et.al.|[2410.10343v1](http://arxiv.org/abs/2410.10343v1)|[link](https://github.com/zhu-minjun/safetylock)|
|**2024-10-14**|**CoMAT: Chain of Mathematically Annotated Thought Improves Mathematical Reasoning**|Joshua Ong Jun Leang et.al.|[2410.10336v1](http://arxiv.org/abs/2410.10336v1)|null|
|**2024-10-14**|**Disentangling Hate Across Target Identities**|Yiping Jin et.al.|[2410.10332v1](http://arxiv.org/abs/2410.10332v1)|[link](https://github.com/yipingnus/disentangle-hate)|
|**2024-10-14**|**GraphCLIP: Enhancing Transferability in Graph Foundation Models for Text-Attributed Graphs**|Yun Zhu et.al.|[2410.10329v2](http://arxiv.org/abs/2410.10329v2)|[link](https://github.com/zhuyun97/graphclip)|
|**2024-10-14**|**MentalGLM Series: Explainable Large Language Models for Mental Health Analysis on Chinese Social Media**|Wei Zhai et.al.|[2410.10323v1](http://arxiv.org/abs/2410.10323v1)|null|
|**2024-10-14**|**EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations**|Zhangchi Feng et.al.|[2410.10315v2](http://arxiv.org/abs/2410.10315v2)|[link](https://github.com/buaadreamer/easyrag)|
|**2024-10-14**|**A Comparative Study of Translation Bias and Accuracy in Multilingual Large Language Models for Cross-Language Claim Verification**|Aryan Singhal et.al.|[2410.10303v1](http://arxiv.org/abs/2410.10303v1)|[link](https://github.com/3x-dev/Comparative-Study-of-Bias-and-Accuracy-in-Multilingual-LLMs-for-Cross-Language-Claim-Verification)|
|**2024-10-14**|**FunnelRAG: A Coarse-to-Fine Progressive Retrieval Paradigm for RAG**|Xinping Zhao et.al.|[2410.10293v1](http://arxiv.org/abs/2410.10293v1)|null|
|**2024-10-14**|**Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal Perspective**|Xiangru Zhu et.al.|[2410.10291v1](http://arxiv.org/abs/2410.10291v1)|[link](https://github.com/zhuxiangru/semvarbench)|
|**2024-10-14**|**A Multi-Task Text Classification Pipeline with Natural Language Explanations: A User-Centric Evaluation in Sentiment Analysis and Offensive Language Identification in Greek Tweets**|Nikolaos Mylonas et.al.|[2410.10290v1](http://arxiv.org/abs/2410.10290v1)|null|
|**2024-10-14**|**ABBA-VSM: Time Series Classification using Symbolic Representation on the Edge**|Meerzhan Kanatbekova et.al.|[2410.10285v1](http://arxiv.org/abs/2410.10285v1)|null|
|**2024-10-14**|**Machine Translation Evaluation Benchmark for Wu Chinese: Workflow and Analysis**|Hongjian Yu et.al.|[2410.10278v1](http://arxiv.org/abs/2410.10278v1)|null|

#### Abstracts
##### **TemporalBench: Benchmarking Fine-grained Temporal Understanding for Multimodal Video Models**
2410.10818v1 by Mu Cai, Reuben Tan, Jianrui Zhang, Bocheng Zou, Kai Zhang, Feng Yao, Fangrui Zhu, Jing Gu, Yiwu Zhong, Yuzhang Shang, Yao Dou, Jaden Park, Jianfeng Gao, Yong Jae Lee, Jianwei Yang

Understanding fine-grained temporal dynamics is crucial for multimodal video
comprehension and generation. Due to the lack of fine-grained temporal
annotations, existing video benchmarks mostly resemble static image benchmarks
and are incompetent at evaluating models for temporal understanding. In this
paper, we introduce TemporalBench, a new benchmark dedicated to evaluating
fine-grained temporal understanding in videos. TemporalBench consists of ~10K
video question-answer pairs, derived from ~2K high-quality human annotations
detailing the temporal dynamics in video clips. As a result, our benchmark
provides a unique testbed for evaluating various temporal understanding and
reasoning abilities such as action frequency, motion magnitude, event order,
etc. Moreover, it enables evaluations on various tasks like both video question
answering and captioning, both short and long video understanding, as well as
different models such as multimodal video embedding models and text generation
models. Results show that state-of-the-art models like GPT-4o achieve only
38.5% question answering accuracy on TemporalBench, demonstrating a significant
gap (~30%) between humans and AI in temporal understanding. Furthermore, we
notice a critical pitfall for multi-choice QA where LLMs can detect the subtle
changes in negative captions and find a centralized description as a cue for
its prediction, where we propose Multiple Binary Accuracy (MBA) to correct such
bias. We hope that TemporalBench can foster research on improving models'
temporal reasoning capabilities. Both dataset and evaluation code will be made
available.

æè¦ï¼<paragraph>äºè§£ç²¾ç´°çæéåæå°æ¼å¤æ¨¡æå½±ççè§£åçæè³ééè¦ãç±æ¼ç¼ºä¹ç²¾ç´°çæéè¨»è§£ï¼ç¾æçå½±çåºæºæ¸¬è©¦å¤§å¤é¡ä¼¼æ¼éæå½±ååºæºæ¸¬è©¦ï¼ä¸¦ä¸ç¡æ³è©ä¼°æéçè§£æ¨¡åãå¨æ¬æä¸­ï¼æåä»ç´¹äº TemporalBenchï¼éæ¯ä¸åæ°çåºæºæ¸¬è©¦ï¼å°éç¨æ¼è©ä¼°å½±çä¸­çç²¾ç´°æéçè§£ãTemporalBench åå«ç´ 10K åå½±çåç­å°ï¼éäºå°ä¾èªç´ 2K åäººé¡é«åè³ªè¨»è§£ï¼è©³ç´°èªªæäºå½±çåªè¼¯ä¸­çæéåæãå æ­¤ï¼æåçåºæºæ¸¬è©¦æä¾äºä¸åç¨ç¹çæ¸¬è©¦å¹³å°ï¼ç¨æ¼è©ä¼°åç¨®æéçè§£åæ¨çè½åï¼ä¾å¦åä½é »çãåä½å¹åº¦ãäºä»¶é åºç­ãæ­¤å¤ï¼å®æ¯æ´åç¨®ä»»åçè©ä¼°ï¼ä¾å¦å½±çåç­åå­å¹ãç­å½±çåé·å½±ççè§£ï¼ä»¥ååç¨®æ¨¡åï¼ä¾å¦å¤æ¨¡æå½±çåµå¥æ¨¡ååæå­çææ¨¡åãçµæé¡¯ç¤ºï¼å GPT-4o éæ¨£çæåé²æ¨¡åå¨ TemporalBench ä¸åéå° 38.5% çåç­æºç¢ºçï¼éè¡¨æäººé¡å AI å¨æéçè§£ä¸å­å¨é¡¯èå·®è·ï¼ç´ 30%ï¼ãæ­¤å¤ï¼æåæ³¨æå°å¤é¸é¡ QA çä¸åééµç¼ºé·ï¼å¶ä¸­ LLM å¯ä»¥æª¢æ¸¬å°è² é¢å­å¹ä¸­çç´°å¾®è®åï¼ä¸¦æ¾å°ä¸åéä¸­æè¿°ä½çºå¶é æ¸¬çç·ç´¢ï¼æåæåºäºå¤éäºé²å¶æºç¢ºç (MBA) ä¾ç³¾æ­£éç¨®åå·®ãæåå¸æ TemporalBench è½å¤ ä¿é²æ¹åæ¨¡åæéæ¨çè½åçç ç©¶ãè³æéåè©ä¼°ç¨å¼ç¢¼é½å°å¬éã</paragraph>

##### **DuoAttention: Efficient Long-Context LLM Inference with Retrieval and Streaming Heads**
2410.10819v1 by Guangxuan Xiao, Jiaming Tang, Jingwei Zuo, Junxian Guo, Shang Yang, Haotian Tang, Yao Fu, Song Han

Deploying long-context large language models (LLMs) is essential but poses
significant computational and memory challenges. Caching all Key and Value (KV)
states across all attention heads consumes substantial memory. Existing KV
cache pruning methods either damage the long-context capabilities of LLMs or
offer only limited efficiency improvements. In this paper, we identify that
only a fraction of attention heads, a.k.a, Retrieval Heads, are critical for
processing long contexts and require full attention across all tokens. In
contrast, all other heads, which primarily focus on recent tokens and attention
sinks--referred to as Streaming Heads--do not require full attention. Based on
this insight, we introduce DuoAttention, a framework that only applies a full
KV cache to retrieval heads while using a light-weight, constant-length KV
cache for streaming heads, which reduces both LLM's decoding and pre-filling
memory and latency without compromising its long-context abilities.
DuoAttention uses a lightweight, optimization-based algorithm with synthetic
data to identify retrieval heads accurately. Our method significantly reduces
long-context inference memory by up to 2.55x for MHA and 1.67x for GQA models
while speeding up decoding by up to 2.18x and 1.50x and accelerating
pre-filling by up to 1.73x and 1.63x for MHA and GQA models, respectively, with
minimal accuracy loss compared to full attention. Notably, combined with
quantization, DuoAttention enables Llama-3-8B decoding with 3.3 million context
length on a single A100 GPU. Code is provided in
https://github.com/mit-han-lab/duo-attention.

æè¦ï¼é¨ç½²é·èªå¢å¤§åèªè¨æ¨¡å (LLM) æ¯å¿è¦çï¼ä½æå¸¶ä¾
é¡¯èçè¨ç®åè¨æ¶é«ææ°ãå¿«åææéæ³¨é ­ä¸çææéµå¼ (KV)
çæææ¶èå¤§éçè¨æ¶é«ãç¾æç KV å¿«åä¿®åªæ¹æ³ææå®³ LLM çé·èªå¢åè½æ
åæä¾æéçæçæåãå¨æ¬æä¸­ï¼æåç¼ç¾åªæå°æ¸çéæ³¨é ­ï¼åç¨±æª¢ç´¢é ­ï¼å°
èçé·èªå¢è³ééè¦ï¼ä¸¦ä¸éè¦ææä»£å¹£çå®å¨éæ³¨ãç¸åï¼ææå¶ä»ä¸»è¦éæ³¨æè¿ä»£å¹£åæ³¨æåçé ­
æ¥æ¶å¨ââç¨±çºä¸²æµé ­ââä¸éè¦å®å¨éæ³¨ãåºæ¼
éåè¦è§£ï¼æåå¼å¥äº DuoAttentionï¼ä¸ååªå°æª¢ç´¢é ­æç¨å®æ´
KV å¿«åçæ¶æ§ï¼åæå°ä¸²æµé ­ä½¿ç¨è¼éç´ãé·åº¦åºå®ç KV
å¿«åï¼éæ¸å°äº LLM çè§£ç¢¼åé å¡«å
è¨æ¶é«åå»¶é²ï¼åæä¸æå®³å¶é·èªå¢è½åã
DuoAttention ä½¿ç¨ä¸ç¨®åºæ¼åªåçè¼éç´æ¼ç®æ³ï¼ä¸¦ä½¿ç¨åæ
è³ææºç¢ºè­å¥æª¢ç´¢é ­ãæåçæè¡é¡¯èæ¸å°äº
MHA çé·èªå¢æ¨è«è¨æ¶é«ï¼æå¤å¯é 2.55 åï¼GQA æ¨¡åå¯é 1.67 å
åæå°è§£ç¢¼éåº¦æé«äº 2.18 åå 1.50 åï¼ä¸¦å°
MHA å GQA æ¨¡åçé å¡«åéåº¦åå¥æé«äº 1.73 åå 1.63 åï¼è
å®å¨éæ³¨ç¸æ¯ï¼æºç¢ºåº¦æå¤±æå°ãå¼å¾æ³¨æçæ¯ï¼çµå
éåï¼DuoAttention å¯ä»¥è® Llama-3-8B å¨å®å A100 GPU ä¸è§£ç¢¼ 330 è¬åèªå¢é·åº¦ãç¨å¼ç¢¼æä¾å¨
https://github.com/mit-han-lab/duo-attentionã

##### **LVD-2M: A Long-take Video Dataset with Temporally Dense Captions**
2410.10816v1 by Tianwei Xiong, Yuqing Wang, Daquan Zhou, Zhijie Lin, Jiashi Feng, Xihui Liu

The efficacy of video generation models heavily depends on the quality of
their training datasets. Most previous video generation models are trained on
short video clips, while recently there has been increasing interest in
training long video generation models directly on longer videos. However, the
lack of such high-quality long videos impedes the advancement of long video
generation. To promote research in long video generation, we desire a new
dataset with four key features essential for training long video generation
models: (1) long videos covering at least 10 seconds, (2) long-take videos
without cuts, (3) large motion and diverse contents, and (4) temporally dense
captions. To achieve this, we introduce a new pipeline for selecting
high-quality long-take videos and generating temporally dense captions.
Specifically, we define a set of metrics to quantitatively assess video quality
including scene cuts, dynamic degrees, and semantic-level quality, enabling us
to filter high-quality long-take videos from a large amount of source videos.
Subsequently, we develop a hierarchical video captioning pipeline to annotate
long videos with temporally-dense captions. With this pipeline, we curate the
first long-take video dataset, LVD-2M, comprising 2 million long-take videos,
each covering more than 10 seconds and annotated with temporally dense
captions. We further validate the effectiveness of LVD-2M by fine-tuning video
generation models to generate long videos with dynamic motions. We believe our
work will significantly contribute to future research in long video generation.

æè¦ï¼å½±ççææ¨¡åçæè½æ¥µåº¦ä»°è³´å¶è¨ç·´è³æéçåè³ªãå¤§å¤æ¸ååçå½±ççææ¨¡åé½æ¯ä»¥ç­å½±ççæ®µé²è¡è¨ç·´ï¼èæè¿å°æ¼ç´æ¥ä»¥è¼é·çå½±çè¨ç·´é·å½±ççææ¨¡åçèè¶£èæ¥ä¿±å¢ãç¶èï¼æ­¤é¡é«åè³ªé·å½±ççç¼ºä¹é»ç¤äºé·å½±ççæçé²å±ãçºäºä¿é²é·å½±ççæçç¸éç ç©¶ï¼æåéè¦ä¸åå·ååé ééµç¹å¾µçæ°è³æéï¼éäºç¹å¾µå°æ¼è¨ç·´é·å½±ççææ¨¡åè³ééè¦ï¼(1) è³å°æ¶µè 10 ç§çé·å½±çï¼(2) ç¡åªè¼¯çé·é¡é ­å½±çï¼(3) å¤§å¹åä½åå¤åå§å®¹ï¼ä»¥å (4) æéå¯éçå­å¹ãçºæ­¤ï¼æåå¼é²ä¸åæ°çæµç¨ä¾é¸åé«åè³ªé·é¡é ­å½±çä¸¦ç¢çæéå¯éçå­å¹ãå·é«ä¾èªªï¼æåå®ç¾©äºä¸çµææ¨ä¾éåè©ä¼°å½±çåè³ªï¼åæ¬å ´æ¯åªè¼¯ãåæç¨åº¦åèªç¾©å±¤ç´åè³ªï¼è®æåè½å¤ å¾å¤§éçåå§å½±çä¸­ç¯©é¸åºé«åè³ªé·é¡é ­å½±çãé¨å¾ï¼æåéç¼äºä¸åéå±¤å¼å½±çå­å¹èçæµç¨ï¼ä»¥æéå¯éçå­å¹çºé·å½±çå ä¸è¨»è§£ãééæ­¤æµç¨ï¼æåç­åäºç¬¬ä¸åé·é¡é ­å½±çè³æé LVD-2Mï¼å¶ä¸­åå« 200 è¬åé·é¡é ­å½±çï¼æ¯åå½±çé½æ¶µèè¶é 10 ç§ï¼ä¸¦å ä¸æéå¯éçå­å¹ãæåé²ä¸æ­¥é©è­ LVD-2M çæè½ï¼æ¹æ³æ¯å¾®èª¿å½±ççææ¨¡åä»¥ç¢çå·æåæåä½çé·å½±çãæåç¸ä¿¡ï¼æåçç ç©¶å°å°æªä¾é·å½±ççæçç¸éç ç©¶ååºéå¤§è²¢ç»ã

##### **Depth Any Video with Scalable Synthetic Data**
2410.10815v1 by Honghui Yang, Di Huang, Wei Yin, Chunhua Shen, Haifeng Liu, Xiaofei He, Binbin Lin, Wanli Ouyang, Tong He

Video depth estimation has long been hindered by the scarcity of consistent
and scalable ground truth data, leading to inconsistent and unreliable results.
In this paper, we introduce Depth Any Video, a model that tackles the challenge
through two key innovations. First, we develop a scalable synthetic data
pipeline, capturing real-time video depth data from diverse synthetic
environments, yielding 40,000 video clips of 5-second duration, each with
precise depth annotations. Second, we leverage the powerful priors of
generative video diffusion models to handle real-world videos effectively,
integrating advanced techniques such as rotary position encoding and flow
matching to further enhance flexibility and efficiency. Unlike previous models,
which are limited to fixed-length video sequences, our approach introduces a
novel mixed-duration training strategy that handles videos of varying lengths
and performs robustly across different frame rates-even on single frames. At
inference, we propose a depth interpolation method that enables our model to
infer high-resolution video depth across sequences of up to 150 frames. Our
model outperforms all previous generative depth models in terms of spatial
accuracy and temporal consistency.

æè¦ï¼å½±çæ·±åº¦ä¼°è¨é·ä¹ä»¥ä¾åéæ¼ä¸è´ä¸å¯æ´åççå¯¦æ¸æçç¨å°æ§ï¼å°è´çµæä¸ä¸è´ä¸ä¸å¯é ãå¨æ¬æä¸­ï¼æåä»ç´¹ Depth Any Videoï¼éæ¯ä¸åééå©é ééµåµæ°ä¾æå°ææ°çæ¨¡åãé¦åï¼æåéç¼äºä¸åå¯æ´åçåææ¸æç®¡ç·ï¼å¾å¤æ¨£åçåæç°å¢ä¸­æ·åå³æå½±çæ·±åº¦æ¸æï¼ç¢ç 40,000 åé·åº¦çº 5 ç§çå½±çåªè¼¯ï¼æ¯ååªè¼¯é½æç²¾ç¢ºçæ·±åº¦è¨»è§£ãå¶æ¬¡ï¼æåå©ç¨çæå¼å½±çæ´æ£æ¨¡åçå¼·å¤§åé©ç¥è­ä¾ææèççå¯¦ä¸ççå½±çï¼æ´åæè½ä½ç½®ç·¨ç¢¼åæµå¹éç­é²éæè¡ï¼ä»¥é²ä¸æ­¥å¢å¼·éæ´»æ§èæçãèåååéæ¼åºå®é·åº¦å½±çåºåçæ¨¡åä¸åï¼æåçæ¹æ³å¼å¥äºä¸ç¨®æ°ç©çæ··åæçºæéè¨ç·´ç­ç¥ï¼å®å¯ä»¥èçé·åº¦ä¸ä¸çå½±çï¼ä¸¦å¨ä¸åå¹çä¸è¡¨ç¾å¾ç©©å®ï¼çè³å¨å®ä¸å¹ä¸­ä¹æ¯å¦æ­¤ãå¨æ¨è«ä¸­ï¼æåæåºäºä¸ç¨®æ·±åº¦æå¼æ¹æ³ï¼ä½¿æåçæ¨¡åè½å¤ æ¨è«é·é 150 å¹çåºåä¸­çé«è§£æåº¦å½±çæ·±åº¦ãæåçæ¨¡åå¨ç©ºéæºç¢ºåº¦åæéä¸è´æ§æ¹é¢åªæ¼ææååççæå¼æ·±åº¦æ¨¡åã

##### **LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory**
2410.10813v1 by Di Wu, Hongwei Wang, Wenhao Yu, Yuwei Zhang, Kai-Wei Chang, Dong Yu

Recent large language model (LLM)-driven chat assistant systems have
integrated memory components to track user-assistant chat histories, enabling
more accurate and personalized responses. However, their long-term memory
capabilities in sustained interactions remain underexplored. This paper
introduces LongMemEval, a comprehensive benchmark designed to evaluate five
core long-term memory abilities of chat assistants: information extraction,
multi-session reasoning, temporal reasoning, knowledge updates, and abstention.
With 500 meticulously curated questions embedded within freely scalable
user-assistant chat histories, LongMemEval presents a significant challenge to
existing long-term memory systems, with commercial chat assistants and
long-context LLMs showing 30% accuracy drop on memorizing information across
sustained interactions. We then present a unified framework that breaks down
the long-term memory design into four design choices across the indexing,
retrieval, and reading stages. Built upon key experimental insights, we propose
several memory designs including session decomposition for optimizing value
granularity, fact-augmented key expansion for enhancing the index structure,
and time-aware query expansion for refining the search scope. Experiment
results show that these optimizations greatly improve both memory recall and
downstream question answering on LongMemEval. Overall, our study provides
valuable resources and guidance for advancing the long-term memory capabilities
of LLM-based chat assistants, paving the way toward more personalized and
reliable conversational AI.

æè¦ï¼<paragraph>æè¿çå¤§åèªè¨æ¨¡å (LLM) é©åçèå¤©å©çç³»çµ±å·²æ´åè¨æ¶åä»¶ä¾è¿½è¹¤ä½¿ç¨èèå©ççèå¤©è¨éï¼è½æä¾æ´æºç¢ºä¸åäººåçåæãç¶èï¼å®åå¨æçºäºåä¸­çé·æè¨æ¶è½åä»æªè¢«ååæ¢è¨ãæ¬æä»ç´¹ LongMemEvalï¼ä¸åå¨é¢çåºæºæ¸¬è©¦ï¼æ¨å¨è©ä¼°èå¤©å©ççäºé æ ¸å¿é·æè¨æ¶è½åï¼è³è¨æ·åãå¤ååæ¨çãæéæ¨çãç¥è­æ´æ°åæ£æ¬ãLongMemEval å¨å¯èªç±æ´åçä½¿ç¨èèå©çèå¤©è¨éä¸­åµå¥äº 500 åç²¾å¿ç­åçåé¡ï¼å°ç¾æçé·æè¨æ¶ç³»çµ±æåºéå¤§ææ°ï¼èå¸é¢ä¸çèå¤©å©çåé·èªå¢ LLM å¨æçºäºåä¸­è¨æ¶è³è¨çæºç¢ºåº¦ä¸éäº 30%ãæ¥èæåæåºä¸åçµ±ä¸çæ¶æ§ï¼å°é·æè¨æ¶è¨­è¨åè§£çºç´¢å¼ãæ·ååè®åéæ®µçååè¨­è¨é¸æãæ ¹æééµå¯¦é©è¦è§£ï¼æåæåºå¤é è¨æ¶è¨­è¨ï¼åæ¬ç¨æ¼æä½³åå¼ç²åº¦çæè©±åè§£ãç¨æ¼å¢å¼·ç´¢å¼çµæ§çäºå¯¦æ´åééµå­æ´åï¼ä»¥åç¨æ¼ç²¾çæå°ç¯åçæéæç¥æ¥è©¢æ´åãå¯¦é©çµæé¡¯ç¤ºï¼éäºæä½³åå¤§å¹æ¹åäº LongMemEval ä¸çè¨æ¶å¬ååä¸æ¸¸åé¡è§£ç­ãç¸½é«èè¨ï¼æåçç ç©¶çºæå LLM çºåºç¤çèå¤©å©ççé·æè¨æ¶è½åæä¾äºå¯¶è²´çè³æºåæå°ï¼çºæ´åäººåä¸å¯é çå°è©±å¼ AI éªè·¯ã</paragraph>

##### **Your Mixture-of-Experts LLM Is Secretly an Embedding Model For Free**
2410.10814v1 by Ziyue Li, Tianyi Zhou

While large language models (LLMs) excel on generation tasks, their
decoder-only architecture often limits their potential as embedding models if
no further representation finetuning is applied. Does this contradict their
claim of generalists? To answer the question, we take a closer look at
Mixture-of-Experts (MoE) LLMs. Our study shows that the expert routers in MoE
LLMs can serve as an off-the-shelf embedding model with promising performance
on a diverse class of embedding-focused tasks, without requiring any
finetuning. Moreover, our extensive analysis shows that the MoE routing weights
(RW) is complementary to the hidden state (HS) of LLMs, a widely-used
embedding. Compared to HS, we find that RW is more robust to the choice of
prompts and focuses on high-level semantics. Motivated by the analysis, we
propose MoEE combining RW and HS, which achieves better performance than using
either separately. Our exploration of their combination and prompting strategy
shed several novel insights, e.g., a weighted sum of RW and HS similarities
outperforms the similarity on their concatenation. Our experiments are
conducted on 6 embedding tasks with 20 datasets from the Massive Text Embedding
Benchmark (MTEB). The results demonstrate the significant improvement brought
by MoEE to LLM-based embedding without further finetuning.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) å¨çæä»»åä¸­è¡¨ç¾åºè²ï¼ä½å¶åè§£ç¢¼å¨çæ¶æ§éå¸¸æéå¶å¶ä½çºåµå¥æ¨¡åçæ½åï¼é¤éæç¨é²ä¸æ­¥çè¡¨ç¤ºå¾®èª¿ãéæ¯å¦èå¶éæçèªªæ³ç¸çç¾ï¼çºäºåç­éååé¡ï¼æåä»ç´°ç ç©¶äºå°å®¶æ··å (MoE) LLMãæåçç ç©¶è¡¨æï¼MoE LLM ä¸­çå°å®¶è·¯ç±å¨å¯ä»¥ç¨ä½ç¾æçåµå¥æ¨¡åï¼å¨åç¨®ä»¥åµå¥çºä¸­å¿çä»»åä¸å·æä»¤äººæ»¿æçæè½ï¼èç¡éä»»ä½å¾®èª¿ãæ­¤å¤ï¼æåçå»£æ³åæè¡¨æï¼MoE è·¯ç±æ¬é (RW) è LLM çé±èçæ (HS)ï¼ä¸ç¨®å»£æ³ä½¿ç¨çåµå¥ï¼æ¯äºè£çãè HS ç¸æ¯ï¼æåç¼ç¾ RW å°æç¤ºçé¸ææ´å·é­¯æ£æ§ï¼ä¸¦ä¸å°æ³¨æ¼é«å±¤æ¬¡èªç¾©ãååæçåç¼ï¼æåæåºäºçµå RW å HS ç MoEEï¼å¶æè½åªæ¼å®ç¨ä½¿ç¨ä»»ä¸æ¹æ³ãæåå°å¶çµååæç¤ºç­ç¥çæ¢ç´¢æ­ç¤ºäºå¹¾åæ°ç©çè¦è§£ï¼ä¾å¦ï¼RW å HS ç¸ä¼¼æ§çå æ¬ååªæ¼å®åä¸²è¯çç¸ä¼¼æ§ãæåçå¯¦é©æ¯å¨å¤§è¦æ¨¡æå­åµå¥åºæº (MTEB) ä¸­ç 20 åè³æéä¸ç 6 ååµå¥ä»»åä¸­é²è¡çãçµæè­æäº MoEE å¨æ²æé²ä¸æ­¥å¾®èª¿çææ³ä¸çºåºæ¼ LLM çåµå¥å¸¶ä¾çé¡¯èæ¹é²ã

##### **HART: Efficient Visual Generation with Hybrid Autoregressive Transformer**
2410.10812v1 by Haotian Tang, Yecheng Wu, Shang Yang, Enze Xie, Junsong Chen, Junyu Chen, Zhuoyang Zhang, Han Cai, Yao Lu, Song Han

We introduce Hybrid Autoregressive Transformer (HART), an autoregressive (AR)
visual generation model capable of directly generating 1024x1024 images,
rivaling diffusion models in image generation quality. Existing AR models face
limitations due to the poor image reconstruction quality of their discrete
tokenizers and the prohibitive training costs associated with generating 1024px
images. To address these challenges, we present the hybrid tokenizer, which
decomposes the continuous latents from the autoencoder into two components:
discrete tokens representing the big picture and continuous tokens representing
the residual components that cannot be represented by the discrete tokens. The
discrete component is modeled by a scalable-resolution discrete AR model, while
the continuous component is learned with a lightweight residual diffusion
module with only 37M parameters. Compared with the discrete-only VAR tokenizer,
our hybrid approach improves reconstruction FID from 2.11 to 0.30 on MJHQ-30K,
leading to a 31% generation FID improvement from 7.85 to 5.38. HART also
outperforms state-of-the-art diffusion models in both FID and CLIP score, with
4.5-7.7x higher throughput and 6.9-13.4x lower MACs. Our code is open sourced
at https://github.com/mit-han-lab/hart.

æè¦ï¼<paragraph>æåä»ç´¹äºæ··åèªè¿´æ­¸Transformer (HART)ï¼éæ¯ä¸åèªè¿´æ­¸ (AR) è¦è¦ºçææ¨¡åï¼è½å¤ ç´æ¥çæ 1024x1024 å½±åï¼å¨å½±åçæåè³ªä¸èæ´æ£æ¨¡åå¹æµãç¾æç AR æ¨¡åç±æ¼å¶é¢æ£ç¬¦èåå¨çå½±åéå»ºåè³ªä¸ä½³ï¼ä»¥åçæ 1024px å½±åæç¸éçè¨ç·´ææ¬éé«ï¼å æ­¤é¢è¨éå¶ãçºäºæå°éäºææ°ï¼æåæåºäºæ··åç¬¦èåå¨ï¼å®å°ä¾èªèªåç·¨ç¢¼å¨çé£çºæ½å¨è®æ¸åè§£æå©åçµæé¨åï¼ä»£è¡¨å¤§å±çé¢æ£ç¬¦èï¼ä»¥åä»£è¡¨ç¡æ³ç±é¢æ£ç¬¦èè¡¨ç¤ºçæ®å·®çµæçé£çºç¬¦èãé¢æ£çµæé¨åç±å¯èª¿æ´è§£æåº¦çé¢æ£ AR æ¨¡åå»ºæ¨¡ï¼èé£çºçµæé¨ååä½¿ç¨åæ 37M åæ¸çè¼éç´æ®å·®æ´æ£æ¨¡çµé²è¡å­¸ç¿ãèåæé¢æ£ç VAR ç¬¦èåå¨ç¸æ¯ï¼æåçæ··åæ¹æ³å° MJHQ-30K ä¸çéå»º FID å¾ 2.11 æ¹åå° 0.30ï¼å°è´çæ FID å¾ 7.85 æ¹åå° 5.38ï¼æåäº 31%ãHART å¨ FID å CLIP åæ¸ä¸ä¹åªæ¼æåé²çæ´æ£æ¨¡åï¼ä¸èçéé«åº 4.5-7.7 åï¼MACs ä½ 6.9-13.4 åãæåçç¨å¼ç¢¼å·²å¨ https://github.com/mit-han-lab/hart éæºã</paragraph>

##### **Local and Global Decoding in Text Generation**
2410.10810v1 by Daniel Gareev, Thomas Hofmann, Ezhilmathi Krishnasamy, Tiago Pimentel

Text generation, a key component in applications such as dialogue systems,
relies on decoding algorithms that sample strings from a language model
distribution. Traditional methods, such as top-$k$ and top-$\pi$, apply local
normalisation to the model's output distribution, which can distort it. In this
paper, we investigate the effect of this distortion by introducing
globally-normalised versions of these decoding methods. Additionally, we
propose an independent Metropolis-Hastings algorithm to approximate sampling
from globally-normalised distributions without explicitly computing them. Our
empirical analysis compares the performance of local and global normalisation
across two decoding algorithms (top-$k$ and top-$\pi$) with various
hyperparameters, using Pythia language models. Results show that, in most
configurations, global decoding performs worse than the local decoding version
of the same algorithms -- despite preserving the distribution's integrity. Our
results suggest that distortion is an important feature of local decoding
algorithms.

æè¦ï¼æå­çææ¯å°è©±ç³»çµ±ç­æç¨ç¨å¼ä¸­çééµåä»¶ï¼
ä¾è³´æ¼å¾èªè¨æ¨¡ååä½ä¸­åæ¨£å­ä¸²çè§£ç¢¼æ¼ç®æ³ãå³çµ±æ¹æ³ï¼ä¾å¦ top-$k$ å top-$\pi$ï¼å°æ¨¡åçè¼¸åºåä½å¥ç¨å±é¨æ­£è¦åï¼éå¯è½ææ­æ²å®ãå¨æ¬æä¸­ï¼æåééå¼å¥éäºè§£ç¢¼æ¹æ³çå¨å±æ­£è¦åçæ¬ä¾æ¢è¨éç¨®æ­æ²çå½±é¿ãæ­¤å¤ï¼æåæåºä¸åç¨ç«ç Metropolis-Hastings æ¼ç®æ³ä¾è¿ä¼¼å¾å¨å±æ­£è¦ååä½åæ¨£ï¼èä¸ç¨æç¢ºå°è¨ç®å®åãæåçå¯¦è­åææ¯è¼äºå¨ä½¿ç¨ Pythia èªè¨æ¨¡åçææ³ä¸ï¼å¨å©åè§£ç¢¼æ¼ç®æ³ï¼top-$k$ å top-$\pi$ï¼ä»¥ååç¨®è¶åæ¸ä¸­ï¼å±é¨åå¨å±æ­£è¦åçæè½ãçµæé¡¯ç¤ºï¼å¨å¤§é¨åçµæä¸­ï¼å¨å±è§£ç¢¼çæè½æ¯ç¸åæ¼ç®æ³çå±é¨è§£ç¢¼çæ¬å·®ï¼åç®¡ä¿çäºåä½çå®æ´æ§ãæåççµæè¡¨æï¼æ­æ²æ¯å±é¨è§£ç¢¼æ¼ç®æ³çä¸é éè¦ç¹å¾µã

##### **Hard-Constrained Neural Networks with Universal Approximation Guarantees**
2410.10807v1 by Youngjae Min, Anoopkumar Sonar, Navid Azizan

Incorporating prior knowledge or specifications of input-output relationships
into machine learning models has gained significant attention, as it enhances
generalization from limited data and leads to conforming outputs. However, most
existing approaches use soft constraints by penalizing violations through
regularization, which offers no guarantee of constraint satisfaction -- an
essential requirement in safety-critical applications. On the other hand,
imposing hard constraints on neural networks may hinder their representational
power, adversely affecting performance. To address this, we propose HardNet, a
practical framework for constructing neural networks that inherently satisfy
hard constraints without sacrificing model capacity. Specifically, we encode
affine and convex hard constraints, dependent on both inputs and outputs, by
appending a differentiable projection layer to the network's output. This
architecture allows unconstrained optimization of the network parameters using
standard algorithms while ensuring constraint satisfaction by construction.
Furthermore, we show that HardNet retains the universal approximation
capabilities of neural networks. We demonstrate the versatility and
effectiveness of HardNet across various applications: fitting functions under
constraints, learning optimization solvers, optimizing control policies in
safety-critical systems, and learning safe decision logic for aircraft systems.

æè¦ï¼å°ååç¥è­æè¼¸å¥è¼¸åºéä¿çè¦æ ¼ç´å¥æ©å¨å­¸ç¿æ¨¡åå·²ç²å¾æ¥µå¤§çéæ³¨ï¼å çºå®å¢å¼·äºå¾æéè³æä¸­é²è¡æ¦æ¬çè½åï¼ä¸¦ç¢çç¬¦åè¼¸åºççµæãç¶èï¼ç¾æçæ¹æ³å¤§å¤ä½¿ç¨è»ç´æï¼ééæ­£ååæ²ç½°éè¦ï¼éç¡æ³ä¿è­ç´ææ»¿è¶³ââå®å¨ééµæç¨ç¨å¼ä¸­çåºæ¬éæ±ãå¦ä¸æ¹é¢ï¼å°ç¥ç¶ç¶²è·¯æ½å ç¡¬ç´æå¯è½æé»ç¤å¶è¡¨ç¤ºè½åï¼å°æè½é æè² é¢å½±é¿ãçºäºè§£æ±ºæ­¤åé¡ï¼æåæåº HardNetï¼éæ¯ä¸åå¯¦ç¨çæ¶æ§ï¼ç¨æ¼å»ºæ§å¨ä¸ç§ç²æ¨¡åå®¹éçææ³ä¸åºæå°æ»¿è¶³ç¡¬ç´æçç¥ç¶ç¶²è·¯ãå·é«ä¾èªªï¼æåééå°å¯å¾®åæå½±å±¤éå å°ç¶²è·¯çè¼¸åºï¼å°ä¾è³´è¼¸å¥åè¼¸åºçä»¿å°åå¸ç¡¬ç´æé²è¡ç·¨ç¢¼ãæ­¤æ¶æ§åè¨±ä½¿ç¨æ¨æºæ¼ç®æ³å°ç¶²è·¯åæ¸é²è¡ç¡ç´ææä½³åï¼åæééå»ºæ§ç¢ºä¿ç´ææ»¿è¶³ãæ­¤å¤ï¼æåè­æ HardNet ä¿çäºç¥ç¶ç¶²è·¯çéç¨é¼è¿è½åãæåå±ç¤ºäº HardNet å¨åç¨®æç¨ä¸­çå¤åè½æ§åæææ§ï¼å¨ç´æä¸æ¬åå½æ¸ãå­¸ç¿æä½³åæ±è§£å¨ãæä½³åå®å¨ééµç³»çµ±ä¸­çæ§å¶ç­ç¥ï¼ä»¥åå­¸ç¿é£æ©ç³»çµ±çå®å¨æ±ºç­éè¼¯ã

##### **Boosting Camera Motion Control for Video Diffusion Transformers**
2410.10802v1 by Soon Yau Cheong, Duygu Ceylan, Armin Mustafa, Andrew Gilbert, Chun-Hao Paul Huang

Recent advancements in diffusion models have significantly enhanced the
quality of video generation. However, fine-grained control over camera pose
remains a challenge. While U-Net-based models have shown promising results for
camera control, transformer-based diffusion models (DiT)-the preferred
architecture for large-scale video generation - suffer from severe degradation
in camera motion accuracy. In this paper, we investigate the underlying causes
of this issue and propose solutions tailored to DiT architectures. Our study
reveals that camera control performance depends heavily on the choice of
conditioning methods rather than camera pose representations that is commonly
believed. To address the persistent motion degradation in DiT, we introduce
Camera Motion Guidance (CMG), based on classifier-free guidance, which boosts
camera control by over 400%. Additionally, we present a sparse camera control
pipeline, significantly simplifying the process of specifying camera poses for
long videos. Our method universally applies to both U-Net and DiT models,
offering improved camera control for video generation tasks.

æè¦ï¼æè¿å¨æ©æ£æ¨¡åä¸çè¿æ­¥å·²ç»æ¾èæåäºè§é¢çæçè´¨éãç¶èï¼å¯¹æåæºå§¿å¿çç²¾ç»æ§å¶ä»ç¶æ¯ä¸ä¸ªææãè½ç¶åºäº U-Net çæ¨¡åå¨æåæºæ§å¶æ¹é¢æ¾ç¤ºåºäºæå¸æçç»æï¼ä½åºäº transformer çæ©æ£æ¨¡å (DiT) - ç¨äºå¤§è§æ¨¡è§é¢çæçé¦éæ¶æ - å¨æåæºè¿å¨åç¡®æ§æ¹é¢é­åä¸¥éçä¸éãå¨æ¬æä¸­ï¼æä»¬è°æ¥äºè¿ä¸ªé®é¢çæ ¹æ¬åå ï¼å¹¶æåºäºéå¯¹ DiT æ¶æçè§£å³æ¹æ¡ãæä»¬çç ç©¶è¡¨æï¼æåæºæ§å¶æ§è½å¾å¤§ç¨åº¦ä¸åå³äºè°èæ¹æ³çéæ©ï¼èä¸æ¯éå¸¸è®¤ä¸ºçæåæºå§¿å¿è¡¨ç¤ºãä¸ºäºè§£å³ DiT ä¸­æç»­çè¿å¨éåé®é¢ï¼æä»¬å¼å¥äºåºäºæ åç±»å¨å¼å¯¼çæåæºè¿å¨å¼å¯¼ (CMG)ï¼å®å°æåæºæ§å¶æåäº 400% ä»¥ä¸ãæ­¤å¤ï¼æä»¬æåºäºä¸ä¸ªç¨çæåæºæ§å¶ç®¡éï¼æå¤§å°ç®åäºä¸ºé¿è§é¢æå®æåæºå§¿å¿çè¿ç¨ãæä»¬çæ¹æ³æ®ééç¨äº U-Net å DiT æ¨¡åï¼ä¸ºè§é¢çæä»»å¡æä¾äºæ¹è¿çæåæºæ§å¶ã

##### **Mix Data or Merge Models? Optimizing for Diverse Multi-Task Learning**
2410.10801v1 by Aakanksha, Arash Ahmadian, Seraphina Goldfarb-Tarrant, Beyza Ermis, Marzieh Fadaee, Sara Hooker

Large Language Models (LLMs) have been adopted and deployed worldwide for a
broad variety of applications. However, ensuring their safe use remains a
significant challenge. Preference training and safety measures often overfit to
harms prevalent in Western-centric datasets, and safety protocols frequently
fail to extend to multilingual settings. In this work, we explore model merging
in a diverse multi-task setting, combining safety and general-purpose tasks
within a multilingual context. Each language introduces unique and varied
learning challenges across tasks. We find that objective-based merging is more
effective than mixing data, with improvements of up to 8% and 10% in general
performance and safety respectively. We also find that language-based merging
is highly effective -- by merging monolingually fine-tuned models, we achieve a
4% increase in general performance and 7% reduction in harm across all
languages on top of the data mixtures method using the same available data.
Overall, our comprehensive study of merging approaches provides a useful
framework for building strong and safe multilingual models.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨å¨çç¯åå§å»£æ³æ¡ç¨åé¨ç½²ï¼é©ç¨æ¼åç¨®æç¨ç¨å¼ãç¶èï¼ç¢ºä¿å¶å®å¨ä½¿ç¨ä»ç¶æ¯ä¸é éå¤§ææ°ãåå¥½è¨ç·´åå®å¨æªæ½ç¶å¸¸éåº¦ç¬¦åä»¥è¥¿æ¹çºä¸­å¿çè³æéä¸­æ®éå­å¨çå±å®³ï¼èå®å¨åè­°éå¸¸ç¡æ³æ´å±å°å¤èªè¨è¨­å®ãå¨éé å·¥ä½ä¸­ï¼æåå¨å¤ååçå¤ä»»åè¨­å®ä¸­æ¢ç´¢æ¨¡ååä½µï¼å¨å¤èªè¨ç°å¢ä¸­çµåå®å¨æ§åéç¨ä»»åãæ¯ç¨®èªè¨å¨åé ä»»åä¸­é½æå¸¶ä¾ç¨ç¹ä¸å¤æ¨£çå­¸ç¿ææ°ãæåç¼ç¾åºæ¼ç®æ¨çåä½µæ¯æ··åè³ææ´ææï¼å¨ä¸è¬æè½åå®å¨æ§çæ¹é²åå¥é«é 8% å 10%ãæåéç¼ç¾åºæ¼èªè¨çåä½µéå¸¸ææââééåä½µå®èªè¨å¾®èª¿æ¨¡åï¼æåå¨ä¸è¬æè½ä¸æé«äº 4%ï¼å¨ææèªè¨ä¸­æ¸å°äº 7% çå±å®³ï¼é«æ¼ä½¿ç¨ç¸åå¯ç¨è³æçè³ææ··åæ¹æ³ãç¸½é«èè¨ï¼æåå°åä½µæ¹æ³çå¨é¢ç ç©¶çºå»ºæ§å¼·å¤§ä¸å®å¨ççå¤èªè¨æ¨¡åæä¾äºæç¨çæ¶æ§ã

##### **Context-Parametric Inversion: Why Instruction Finetuning May Not Actually Improve Context Reliance**
2410.10796v1 by Sachin Goyal, Christina Baek, J. Zico Kolter, Aditi Raghunathan

Large language models are instruction-finetuned to enhance their ability to
follow user instructions and process the input context. However, even
state-of-the-art models often struggle to follow the instruction, especially
when the input context is not aligned with the model's parametric knowledge.
This manifests as various failures, such as hallucinations where the responses
are outdated, biased or contain unverified facts. In this work, we try to
understand the underlying reason for this poor context reliance, especially
after instruction tuning. We observe an intriguing phenomenon: during
instruction tuning, the context reliance initially increases as expected, but
then gradually decreases as instruction finetuning progresses. We call this
phenomenon context-parametric inversion and observe it across multiple general
purpose instruction tuning datasets like TULU, Alpaca and Ultrachat, as well as
model families such as Llama, Mistral and Pythia. In a simple theoretical
setup, we isolate why context-parametric inversion occurs along the gradient
descent trajectory of instruction finetuning. We tie this phenomena to examples
in the instruction finetuning data mixture where the input context provides
information that is already present in the model's parametric knowledge. Our
analysis suggests natural mitigation strategies that provide some limited
gains, while also validating our theoretical insights. We hope that our work
serves as a starting point in addressing this failure mode in a staple part of
LLM training.

æè¦ï¼å¤§åèªè¨æ¨¡åç¶éæä»¤å¾®èª¿ï¼ä»¥å¢å¼·å¶éµå¾ªä½¿ç¨èæä»¤åèçè¼¸å¥å§å®¹çè½åãç¶èï¼å³ä½¿æ¯ææ°ç©çæ¨¡åä¹ç¶å¸¸é£ä»¥éµå¾ªæä»¤ï¼ç¹å¥æ¯å¨è¼¸å¥å§å®¹èæ¨¡åçåæ¸åç¥è­ä¸ä¸è´æãéæè¡¨ç¾çºåç¨®å¤±æï¼ä¾å¦å¹»è¦ºï¼å¶ä¸­åæéæãæåå·®æåå«æªç¶é©è­çäºå¯¦ãå¨éé å·¥ä½ä¸­ï¼æååè©¦äºè§£éç¨®ä¸è¯å§å®¹ä¾è³´æ§çæ ¹æ¬åå ï¼ç¹å¥æ¯å¨æä»¤å¾®èª¿ä¹å¾ãæåè§å¯å°ä¸åæè¶£çç¾è±¡ï¼å¨æä»¤å¾®èª¿æéï¼å§å®¹ä¾è³´æ§æåå¦é æè¬å¢å ï¼ä½é¨èæä»¤å¾®èª¿çé²è¡ï¼éæ¼¸ä¸éãæåå°éç¨®ç¾è±¡ç¨±çºå§å®¹åæ¸åè½ï¼ä¸¦å¨å¤åéç¨æä»¤å¾®èª¿è³æéï¼ä¾å¦ TULUãAlpaca å Ultrachatï¼ä»¥å LlamaãMistral å Pythia ç­æ¨¡åç³»åä¸­è§å¯å°éç¨®ç¾è±¡ãå¨ä¸åç°¡å®ççè«è¨­å®ä¸­ï¼æåéé¢äºå¨æä»¤å¾®èª¿çæ¢¯åº¦ä¸éè»è·¡ä¸­ç¼çå§å®¹åæ¸åè½çåå ãæåå°éç¨®ç¾è±¡èæä»¤å¾®èª¿è³ææ··åä¸­çç¯ä¾è¯ç¹«èµ·ä¾ï¼å¶ä¸­è¼¸å¥å§å®¹æä¾äºæ¨¡ååæ¸åç¥è­ä¸­å·²å­å¨è³è¨ãæåçåæå»ºè­°äºèªç¶ç·©è§£ç­ç¥ï¼éäºç­ç¥æä¾äºä¸äºæéçæ¶çï¼åæä¹é©è­äºæåççè«è¦è§£ãæåå¸ææåçç ç©¶è½ä½çºè§£æ±º LLM è¨ç·´ä¸­éåå¤±ææ¨¡å¼çèµ·é»ã

##### **On Information-Theoretic Measures of Predictive Uncertainty**
2410.10786v1 by Kajetan Schweighofer, Lukas Aichberger, Mykyta Ielanskyi, Sepp Hochreiter

Reliable estimation of predictive uncertainty is crucial for machine learning
applications, particularly in high-stakes scenarios where hedging against risks
is essential. Despite its significance, a consensus on the correct measurement
of predictive uncertainty remains elusive. In this work, we return to first
principles to develop a fundamental framework of information-theoretic
predictive uncertainty measures. Our proposed framework categorizes predictive
uncertainty measures according to two factors: (I) The predicting model (II)
The approximation of the true predictive distribution. Examining all possible
combinations of these two factors, we derive a set of predictive uncertainty
measures that includes both known and newly introduced ones. We empirically
evaluate these measures in typical uncertainty estimation settings, such as
misclassification detection, selective prediction, and out-of-distribution
detection. The results show that no single measure is universal, but the
effectiveness depends on the specific setting. Thus, our work provides clarity
about the suitability of predictive uncertainty measures by clarifying their
implicit assumptions and relationships.

æè¦ï¼å¯é çé æ¸¬ä¸ç¢ºå®æ§ä¼°è¨å°æ¼æ©å¨å­¸ç¿æç¨è³ééè¦ï¼ç¹å¥æ¯å¨å°æ²é¢¨éªè³ééè¦çééµæå¢ä¸­ãåç®¡å¶æç¾©éå¤§ï¼ä½å°æ¼é æ¸¬ä¸ç¢ºå®æ§çæ­£ç¢ºæ¸¬éæ¹æ³ä»æªéæå±è­ãå¨éé å·¥ä½ä¸­ï¼æååæ­¸ç¬¬ä¸åçï¼ä»¥éç¼è³è¨çè«é æ¸¬ä¸ç¢ºå®æ§æ¸¬éåºæºçåºç¤æ¶æ§ãæåæåºçæ¶æ§æ ¹æå©åå ç´ å°é æ¸¬ä¸ç¢ºå®æ§æ¸¬éåºæºåé¡ï¼(I) é æ¸¬æ¨¡å (II) çå¯¦é æ¸¬åä½çè¿ä¼¼å¼ãééæª¢é©éå©åå ç´ çææå¯è½çµåï¼æåæ¨å°åºä¸çµé æ¸¬ä¸ç¢ºå®æ§æ¸¬éåºæºï¼å¶ä¸­åæ¬å·²ç¥åæ°å¼å¥çæ¸¬éåºæºãæåå¨å¸åçé æ¸¬ä¸ç¢ºå®æ§ä¼°è¨è¨­å®ä¸­ï¼ä¾å¦é¯èª¤åé¡åµæ¸¬ãé¸ææ§é æ¸¬åç°å¸¸åµæ¸¬ï¼å°éäºæ¸¬éåºæºé²è¡ç¶é©è©ä¼°ãçµæé¡¯ç¤ºï¼æ²æå®ä¸æ¸¬éåºæºå·æéç¨æ§ï¼ä½å¶æææ§åæ±ºæ¼ç¹å®è¨­å®ãå æ­¤ï¼æåçç ç©¶éééæ¸é æ¸¬ä¸ç¢ºå®æ§æ¸¬éåºæºçé±å«åè¨­åéä¿ï¼æç¢ºäºå¶é©ç¨æ§ã

##### **When Attention Sink Emerges in Language Models: An Empirical View**
2410.10781v1 by Xiangming Gu, Tianyu Pang, Chao Du, Qian Liu, Fengzhuo Zhang, Cunxiao Du, Ye Wang, Min Lin

Language Models (LMs) assign significant attention to the first token, even
if it is not semantically important, which is known as attention sink. This
phenomenon has been widely adopted in applications such as streaming/long
context generation, KV cache optimization, inference acceleration, model
quantization, and others. Despite its widespread use, a deep understanding of
attention sink in LMs is still lacking. In this work, we first demonstrate that
attention sinks exist universally in LMs with various inputs, even in small
models. Furthermore, attention sink is observed to emerge during the LM
pre-training, motivating us to investigate how optimization, data distribution,
loss function, and model architecture in LM pre-training influence its
emergence. We highlight that attention sink emerges after effective
optimization on sufficient training data. The sink position is highly
correlated with the loss function and data distribution. Most importantly, we
find that attention sink acts more like key biases, storing extra attention
scores, which could be non-informative and not contribute to the value
computation. We also observe that this phenomenon (at least partially) stems
from tokens' inner dependence on attention scores as a result of softmax
normalization. After relaxing such dependence by replacing softmax attention
with other attention operations, such as sigmoid attention without
normalization, attention sinks do not emerge in LMs up to 1B parameters. The
code is available at https://github.com/sail-sg/Attention-Sink.

æè¦ï¼èªè¨æ¨¡å (LM) æå°é¡¯èçæ³¨æååéçµ¦ç¬¬ä¸åç¬¦èï¼å³ä½¿å®å¨èªç¾©ä¸ä¸¦ä¸éè¦ï¼éç¨±çºæ³¨æåæ¥æ¶å¨ãéç¨®ç¾è±¡å·²è¢«å»£æ³æç¨æ¼ä¸²æµ/é·å§å®¹çæãKV å¿«åæä½³åãæ¨è«å éãæ¨¡åéåç­æç¨ç¨å¼ä¸­ãåç®¡å®è¢«å»£æ³ä½¿ç¨ï¼ä½å°æ¼ LM ä¸­çæ³¨æåæ¥æ¶å¨ä»ç¼ºä¹æ·±å¥çäºè§£ãå¨éé å·¥ä½ä¸­ï¼æåé¦åè­ææ³¨æåæ¥æ¶å¨æ®éå­å¨æ¼å·æåç¨®è¼¸å¥ç LM ä¸­ï¼å³ä½¿å¨å°åæ¨¡åä¸­ä¹æ¯å¦æ­¤ãæ­¤å¤ï¼è§å¯å°æ³¨æåæ¥æ¶å¨æå¨ LM é è¨ç·´æéåºç¾ï¼ä¿ä½¿æåæ¢è¨ LM é è¨ç·´ä¸­çæä½³åãè³æåä½ãæå¤±å½æ¸åæ¨¡åæ¶æ§å¦ä½å½±é¿å¶åºç¾ãæåå¼·èª¿ï¼å¨åè¶³çè¨ç·´è³æä¸é²è¡æææä½³åå¾ï¼æ³¨æåæ¥æ¶å¨å°±æåºç¾ãæ¥æ¶å¨ä½ç½®èæå¤±å½æ¸åè³æåä½é«åº¦ç¸éãæéè¦çæ¯ï¼æåç¼ç¾æ³¨æåæ¥æ¶å¨æ´åæ¯éµåå·®ï¼å²å­é¡å¤çæ³¨æååæ¸ï¼éäºåæ¸å¯è½æ¯ç¡æç¾©çï¼èä¸ä¸ææå©æ¼å¼éç®ãæåéè§å¯å°ï¼éç¨®ç¾è±¡ï¼è³å°é¨åï¼æºæ¼ç¬¦èå°æ³¨æååæ¸çå§é¨ä¾è³´æ§ï¼éæ¯ softmax æ­£è¦åççµæãå¨ééå° softmax æ³¨æåæ¿æçºå¶ä»æ³¨æåéç®ï¼ä¾å¦æ²ææ­£è¦åç sigmoid æ³¨æåï¼ä¾æ¾å¯¬éç¨®ä¾è³´æ§å¾ï¼æ³¨æåæ¥æ¶å¨ä¸æåºç¾å¨é«é 1B åæ¸ç LM ä¸­ãç¨å¼ç¢¼å¯å¨ https://github.com/sail-sg/Attention-Sink åå¾ã

##### **Focused ReAct: Improving ReAct through Reiterate and Early Stop**
2410.10779v1 by Shuoqiu Li, Han Xu, Haipeng Chen

Large language models (LLMs) have significantly improved their reasoning and
decision-making capabilities, as seen in methods like ReAct. However, despite
its effectiveness in tackling complex tasks, ReAct faces two main challenges:
losing focus on the original question and becoming stuck in action loops. To
address these issues, we introduce Focused ReAct, an enhanced version of the
ReAct paradigm that incorporates reiteration and early stop mechanisms. These
improvements help the model stay focused on the original query and avoid
repetitive behaviors. Experimental results show accuracy gains of 18% to 530%
and a runtime reduction of up to 34% compared to the original ReAct method.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²é¡¯èæåå¶æ¨çåæ±ºç­è½åï¼éå¨ ReAct ç­æ¹æ³ä¸­å¯è¦ä¸æãç¶èï¼åç®¡ ReAct å¨èçè¤éä»»åæ¹é¢å¾ææï¼ä½å®é¢è¨å©é ä¸»è¦ææ°ï¼å¤±å»å°åå§åé¡çéæ³¨ï¼ä¸¦é·å¥è¡åè¿´åä¸­ãçºäºè§£æ±ºéäºåé¡ï¼æåå¼å¥äº Focused ReActï¼éæ¯ä¸åå¢å¼·çç ReAct å¸ç¯ï¼çµåäºåè¦éç®åæ©æåæ­¢æ©å¶ãéäºæ¹è¯æå©æ¼æ¨¡åä¿æå°åå§æ¥è©¢çéæ³¨ï¼ä¸¦é¿åéè¤çè¡çºãå¯¦é©çµæé¡¯ç¤ºï¼èåå§ ReAct æ¹æ³ç¸æ¯ï¼æºç¢ºåº¦æé«äº 18% è³ 530%ï¼å·è¡æéæ¸å°äº 34%ã

##### **Adaptive Diffusion Terrain Generator for Autonomous Uneven Terrain Navigation**
2410.10766v1 by Youwei Yu, Junhong Xu, Lantao Liu

Model-free reinforcement learning has emerged as a powerful method for
developing robust robot control policies capable of navigating through complex
and unstructured terrains. The effectiveness of these methods hinges on two
essential elements: (1) the use of massively parallel physics simulations to
expedite policy training, and (2) an environment generator tasked with crafting
sufficiently challenging yet attainable terrains to facilitate continuous
policy improvement. Existing methods of environment generation often rely on
heuristics constrained by a set of parameters, limiting the diversity and
realism. In this work, we introduce the Adaptive Diffusion Terrain Generator
(ADTG), a novel method that leverages Denoising Diffusion Probabilistic Models
to dynamically expand existing training environments by adding more diverse and
complex terrains adaptive to the current policy. ADTG guides the diffusion
model's generation process through initial noise optimization, blending
noise-corrupted terrains from existing training environments weighted by the
policy's performance in each corresponding environment. By manipulating the
noise corruption level, ADTG seamlessly transitions between generating similar
terrains for policy fine-tuning and novel ones to expand training diversity.
Our experiments show that the policy trained by ADTG outperforms both
procedural generated and natural environments, along with popular navigation
methods.

æè¦ï¼ç¡æ¨¡åå¼·åå­¸ç¿å·²æçºä¸ç¨®å¼·å¤§çæ¹æ³ï¼ç¨æ¼éç¼å¼·å¥çæ©å¨äººæ§å¶ç­ç¥ï¼è½å¤ å¨è¤éä¸ç¡çµæ§çå°å½¢ä¸­å°èªãéäºæ¹æ³çæææ§åæ±ºæ¼å©ååºæ¬è¦ç´ ï¼(1) ä½¿ç¨å¤§éä¸¦è¡ç©çæ¨¡æ¬ä¾å éç­ç¥è¨ç·´ï¼ä»¥å (2) ä¸åç°å¢çæå¨ï¼è² è²¬è£½ä½è¶³å¤ å·æææ°æ§ä½å¯éæçå°å½¢ï¼ä»¥ä¿é²ç­ç¥çæçºæ¹é²ãç¾æçç°å¢çææ¹æ³éå¸¸ä¾è³´æ¼åä¸çµåæ¸ç´æçåç¼æ³ï¼ééå¶äºå¤æ¨£æ§åçå¯¦æ§ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºèªé©ææ´æ£å°å½¢çæå¨ (ADTG)ï¼éæ¯ä¸ç¨®æ°æ¹æ³ï¼å©ç¨å»åªæ´æ£æ©çæ¨¡åééæ·»å æ´å¤æ¨£åä¸è¤éçå°å½¢ï¼åææ´å±ç¾æçè¨ç·´ç°å¢ï¼ä»¥é©æç¶åç­ç¥ãADTG ééåå§éè¨æä½³åå¼å°æ´æ£æ¨¡åççæéç¨ï¼æ··åä¾èªç¾æè¨ç·´ç°å¢çéè¨æå£å°å½¢ï¼ä¸¦æ ¹æç­ç¥å¨æ¯åå°æç°å¢ä¸­çè¡¨ç¾é²è¡å æ¬ãééæç¸±éè¨æå£ç­ç´ï¼ADTG å¯å¨çºç­ç¥å¾®èª¿ç¢çé¡ä¼¼å°å½¢åç¢çæ°å°å½¢ä»¥æ´å±è¨ç·´å¤æ¨£æ§ä¹éç¡ç¸«è½æãæåçå¯¦é©é¡¯ç¤ºï¼ç± ADTG è¨ç·´çç­ç¥åªæ¼ç¨åºç¢ççç°å¢åèªç¶ç°å¢ï¼ä»¥åæµè¡çå°èªæ¹æ³ã

##### **AFlow: Automating Agentic Workflow Generation**
2410.10762v1 by Jiayi Zhang, Jinyu Xiang, Zhaoyang Yu, Fengwei Teng, Xionghui Chen, Jiaqi Chen, Mingchen Zhuge, Xin Cheng, Sirui Hong, Jinlin Wang, Bingnan Zheng, Bang Liu, Yuyu Luo, Chenglin Wu

Large language models (LLMs) have demonstrated remarkable potential in
solving complex tasks across diverse domains, typically by employing agentic
workflows that follow detailed instructions and operational sequences. However,
constructing these workflows requires significant human effort, limiting
scalability and generalizability. Recent research has sought to automate the
generation and optimization of these workflows, but existing methods still rely
on initial manual setup and fall short of achieving fully automated and
effective workflow generation. To address this challenge, we reformulate
workflow optimization as a search problem over code-represented workflows,
where LLM-invoking nodes are connected by edges. We introduce AFlow, an
automated framework that efficiently explores this space using Monte Carlo Tree
Search, iteratively refining workflows through code modification,
tree-structured experience, and execution feedback. Empirical evaluations
across six benchmark datasets demonstrate AFlow's efficacy, yielding a 5.7%
average improvement over state-of-the-art baselines. Furthermore, AFlow enables
smaller models to outperform GPT-4o on specific tasks at 4.55% of its inference
cost in dollars. The code will be available at
https://github.com/geekan/MetaGPT.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨è§£æ±ºä¸åé åçè¤éä»»åä¸­å±ç¾åºé©äººçæ½åï¼éå¸¸éééµå¾ªè©³ç´°æç¤ºåæä½é åºçä»£çå·¥ä½æµç¨ä¾å·è¡ãç¶èï¼å»ºæ§éäºå·¥ä½æµç¨éè¦å¤§éäººåï¼éå¶äºå¯æ´åæ§åæ¦æ¬æ§ãæè¿çç ç©¶è©¦åèªååéäºå·¥ä½æµç¨çç¢çåæä½³åï¼ä½ç¾ææ¹æ³ä»ä¾è³´æ¼æåçæåè¨­å®ï¼ä¸ç¡æ³éæå®å¨èªååä¸ææçå·¥ä½æµç¨ç¢çãçºäºæå°éé ææ°ï¼æåå°å·¥ä½æµç¨æä½³åéæ°è¡¨è¿°çºä¸åéå°ç¨å¼ç¢¼è¡¨ç¤ºå·¥ä½æµç¨çæå°åé¡ï¼å¶ä¸­å¼å« LLM çç¯é»éééç·£é£æ¥ãæåå¼å¥äº AFlowï¼ä¸åèªååæ¶æ§ï¼å®ä½¿ç¨èå°å¡ç¾æ¨¹çæå°æææ¢ç´¢éåç©ºéï¼ééç¨å¼ç¢¼ä¿®æ¹ãæ¨¹ççµæ§ç¶é©åå·è¡åé¥ï¼åè¦ç²¾é²å·¥ä½æµç¨ãå¨å­ååºæºè³æéä¸çå¯¦è­è©ä¼°è­æäº AFlow çæè½ï¼æ¯ç¾ææè¡åºç·å¹³åæåäº 5.7%ãæ­¤å¤ï¼AFlow ä½¿è¼å°çæ¨¡åè½å¤ ä»¥å¶æ¨è«ææ¬ 4.55% çç¾åå¹æ ¼å¨ç¹å®ä»»åä¸è¶è¶ GPT-4oãç¨å¼ç¢¼å°å¯å¨ https://github.com/geekan/MetaGPT åå¾ã

##### **Denial-of-Service Poisoning Attacks against Large Language Models**
2410.10760v1 by Kuofeng Gao, Tianyu Pang, Chao Du, Yong Yang, Shu-Tao Xia, Min Lin

Recent studies have shown that LLMs are vulnerable to denial-of-service (DoS)
attacks, where adversarial inputs like spelling errors or non-semantic prompts
trigger endless outputs without generating an [EOS] token. These attacks can
potentially cause high latency and make LLM services inaccessible to other
users or tasks. However, when there are speech-to-text interfaces (e.g., voice
commands to a robot), executing such DoS attacks becomes challenging, as it is
difficult to introduce spelling errors or non-semantic prompts through speech.
A simple DoS attack in these scenarios would be to instruct the model to "Keep
repeating Hello", but we observe that relying solely on natural instructions
limits output length, which is bounded by the maximum length of the LLM's
supervised finetuning (SFT) data. To overcome this limitation, we propose
poisoning-based DoS (P-DoS) attacks for LLMs, demonstrating that injecting a
single poisoned sample designed for DoS purposes can break the output length
limit. For example, a poisoned sample can successfully attack GPT-4o and GPT-4o
mini (via OpenAI's finetuning API) using less than $1, causing repeated outputs
up to the maximum inference length (16K tokens, compared to 0.5K before
poisoning). Additionally, we perform comprehensive ablation studies on
open-source LLMs and extend our method to LLM agents, where attackers can
control both the finetuning dataset and algorithm. Our findings underscore the
urgent need for defenses against P-DoS attacks to secure LLMs. Our code is
available at https://github.com/sail-sg/P-DoS.

æè¦ï¼<paragraph>æè¿çç ç©¶è¡¨æï¼LLM å®¹æåå°æç»æå¡ (DoS) æ»å»ï¼å¶ä¸­å¯¹ææ§è¾å¥ï¼å¦æ¼åéè¯¯æéè¯­ä¹æç¤ºï¼ä¼è§¦åæ ç©·æ å°½çè¾åºï¼èä¸ä¼çæ [EOS] ä»¤çãè¿äºæ»å»å¯è½ä¼å¯¼è´é«å»¶è¿ï¼å¹¶ä½¿ LLM æå¡å¯¹å¶ä»ç¨æ·æä»»å¡ä¸å¯è®¿é®ãç¶èï¼å½æè¯­é³å°ææ¬çé¢ï¼ä¾å¦ï¼å¯¹æºå¨äººçè¯­é³å½ä»¤ï¼æ¶ï¼æ§è¡æ­¤ç±» DoS æ»å»åå¾å·ææææ§ï¼å ä¸ºå¾é¾éè¿è¯­é³å¼å¥æ¼åéè¯¯æéè¯­ä¹æç¤ºãå¨è¿äºåºæ¯ä¸­ï¼ä¸ä¸ªç®åç DoS æ»å»æ¯æç¤ºæ¨¡åâç»§ç»­éå¤ Helloâï¼ä½æä»¬è§å¯å°ï¼ä»ä¾èµèªç¶æä»¤ä¼éå¶è¾åºé¿åº¦ï¼è¯¥é¿åº¦å LLM ççç£å¾®è° (SFT) æ°æ®çæå¤§é¿åº¦éå¶ãä¸ºäºåæè¿ä¸éå¶ï¼æä»¬æåºäºéå¯¹ LLM çåºäºä¸­æ¯ç DoS (P-DoS) æ»å»ï¼è¯ææ³¨å¥ä¸ä¸ªä¸ä¸º DoS ç®çèè®¾è®¡çä¸­æ¯æ ·æ¬å¯ä»¥æç ´è¾åºé¿åº¦éå¶ãä¾å¦ï¼ä¸ä¸ªä¸­æ¯æ ·æ¬å¯ä»¥ä½¿ç¨ä¸å° 1 ç¾åæåæ»å» GPT-4o å GPT-4o miniï¼éè¿ OpenAI çå¾®è° APIï¼ï¼å¯¼è´éå¤è¾åºè¾¾å°æå¤§æ¨çé¿åº¦ï¼16K ä¸ªä»¤çï¼èä¸­æ¯åä¸º 0.5Kï¼ãæ­¤å¤ï¼æä»¬å¯¹å¼æº LLM è¿è¡äºå¨é¢çæ¶èç ç©¶ï¼å¹¶å°æä»¬çæ¹æ³æ©å±å° LLM ä»£çï¼æ»å»èå¯ä»¥å¨å¶ä¸­æ§å¶å¾®è°æ°æ®éåç®æ³ãæä»¬çç ç©¶ç»æå¼ºè°äºè¿«åéè¦éå¯¹ P-DoS æ»å»çé²å¾¡æªæ½æ¥ä¿æ¤ LLMãæä»¬çä»£ç å¯å¨ https://github.com/sail-sg/P-DoS è·å¾ã</paragraph>

##### **Arrhythmia Classification Using Graph Neural Networks Based on Correlation Matrix**
2410.10758v1 by Seungwoo Han

With the advancements in graph neural network, there has been increasing
interest in applying this network to ECG signal analysis. In this study, we
generated an adjacency matrix using correlation matrix of extracted features
and applied a graph neural network to classify arrhythmias. The proposed model
was compared with existing approaches from the literature. The results
demonstrated that precision and recall for all arrhythmia classes exceeded 50%,
suggesting that this method can be considered an approach for arrhythmia
classification.

æè¦ï¼é¨èåç¥ç¶ç¶²è·¯çé²æ­¥ï¼å°æ­¤ç¶²è·¯æç¨æ¼å¿é»åè¨èåæçèè¶£ä¹èæ¥ä¿±å¢ãå¨æ¬ç ç©¶ä¸­ï¼æåä½¿ç¨æåç¹å¾µçç¸éç©é£ç¢çé°æ¥ç©é£ï¼ä¸¦æç¨åç¥ç¶ç¶²è·¯å°å¿å¾ä¸æ´é²è¡åé¡ãå°ææåºçæ¨¡åèæç»ä¸­ç¾æçæ¹æ³é²è¡æ¯è¼ãçµæè¡¨æï¼ææå¿å¾ä¸æ´é¡å¥çæºç¢ºåº¦åå¬åçé½è¶é 50%ï¼éè¡¨ææ­¤æ¹æ³å¯ä»¥è¢«è¦çºå¿å¾ä¸æ´åé¡çä¸ç¨®æ¹æ³ã

##### **Use Random Selection for Now: Investigation of Few-Shot Selection Strategies in LLM-based Text Augmentation for Classification**
2410.10756v1 by Jan Cegin, Branislav Pecher, Jakub Simko, Ivan Srba, Maria Bielikova, Peter Brusilovsky

The generative large language models (LLMs) are increasingly used for data
augmentation tasks, where text samples are paraphrased (or generated anew) and
then used for classifier fine-tuning. Existing works on augmentation leverage
the few-shot scenarios, where samples are given to LLMs as part of prompts,
leading to better augmentations. Yet, the samples are mostly selected randomly
and a comprehensive overview of the effects of other (more ``informed'') sample
selection strategies is lacking. In this work, we compare sample selection
strategies existing in few-shot learning literature and investigate their
effects in LLM-based textual augmentation. We evaluate this on in-distribution
and out-of-distribution classifier performance. Results indicate, that while
some ``informed'' selection strategies increase the performance of models,
especially for out-of-distribution data, it happens only seldom and with
marginal performance increases. Unless further advances are made, a default of
random sample selection remains a good option for augmentation practitioners.

æè¦ï¼çæå¼å¤§åè¯­è¨æ¨¡å (LLM) è¶æ¥è¶å¤å°ç¨äºæ°æ®å¢å¼ºä»»å¡ï¼å¶ä¸­ææ¬æ ·æ¬è¢«æ¹åï¼æéæ°çæï¼ï¼ç¶åç¨äºåç±»å¨å¾®è°ãç°æçå¢å¼ºå·¥ä½å©ç¨äºå°æ ·æ¬åºæ¯ï¼å¶ä¸­æ ·æ¬ä½ä¸ºæç¤ºçä¸é¨åæä¾ç» LLMï¼ä»èäº§çæ´å¥½çå¢å¼ºãç¶èï¼è¿äºæ ·æ¬å¤§å¤æ¯éæºéæ©çï¼å¹¶ä¸ç¼ºä¹å¯¹å¶ä»ï¼æ´âç¥æâï¼æ ·æ¬éæ©ç­ç¥çå½±åçå¨é¢æ¦è¿°ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬æ¯è¾äºå°æ ·æ¬å­¦ä¹ æç®ä¸­å­å¨çæ ·æ¬éæ©ç­ç¥ï¼å¹¶ç ç©¶äºå®ä»¬å¨åºäº LLM çææ¬å¢å¼ºä¸­çå½±åãæä»¬å¨åå¸åååå¸å¤åç±»å¨æ§è½ä¸å¯¹æ­¤è¿è¡äºè¯ä¼°ãç»æè¡¨æï¼è½ç¶ä¸äºâç¥æâéæ©ç­ç¥æé«äºæ¨¡åçæ§è½ï¼ç¹å«æ¯å¯¹äºåå¸å¤æ°æ®ï¼ä½è¿åªå¨å°æ°æåµä¸åçï¼å¹¶ä¸æ§è½æåå¹åº¦å¾å°ãé¤éåå¾è¿ä¸æ­¥è¿å±ï¼å¦åéæºæ ·æ¬éæ©ä½ä¸ºå¢å¼ºå®è·µèçé»è®¤éæ©ä»ç¶æ¯ä¸ä¸ªä¸éçéæ©ã

##### **FlexGen: Flexible Multi-View Generation from Text and Image Inputs**
2410.10745v1 by Xinli Xu, Wenhang Ge, Jiantao Lin, Jiawei Feng, Lie Xu, HanFeng Zhao, Shunsi Zhang, Ying-Cong Chen

In this work, we introduce FlexGen, a flexible framework designed to generate
controllable and consistent multi-view images, conditioned on a single-view
image, or a text prompt, or both. FlexGen tackles the challenges of
controllable multi-view synthesis through additional conditioning on 3D-aware
text annotations. We utilize the strong reasoning capabilities of GPT-4V to
generate 3D-aware text annotations. By analyzing four orthogonal views of an
object arranged as tiled multi-view images, GPT-4V can produce text annotations
that include 3D-aware information with spatial relationship. By integrating the
control signal with proposed adaptive dual-control module, our model can
generate multi-view images that correspond to the specified text. FlexGen
supports multiple controllable capabilities, allowing users to modify text
prompts to generate reasonable and corresponding unseen parts. Additionally,
users can influence attributes such as appearance and material properties,
including metallic and roughness. Extensive experiments demonstrate that our
approach offers enhanced multiple controllability, marking a significant
advancement over existing multi-view diffusion models. This work has
substantial implications for fields requiring rapid and flexible 3D content
creation, including game development, animation, and virtual reality. Project
page: https://xxu068.github.io/flexgen.github.io/.

æè¦ï¼å¨éé å·¥ä½ä¸­ï¼æåä»ç´¹äº FlexGenï¼ä¸åè¨­è¨ç¨æ¼çæå¯æ§ä¸ä¸è´çå¤è¦åå½±åçå½æ§æ¡æ¶ï¼ä»¥å®è¦åå½±åãæå­æç¤ºæå©èçºæ¢ä»¶ãFlexGen ééå° 3D æç¥çæå­è¨»è§£é²è¡é¡å¤æ¢ä»¶è¨­å®ï¼ä¾è§£æ±ºå¯æ§å¤è¦ååæçææ°ãæåå©ç¨ GPT-4V å¼·å¤§çæ¨çè½åä¾çæ 3D æç¥çæå­è¨»è§£ãééåæä¸åç©ä»¶çååæ­£äº¤è¦åï¼éäºè¦åè¢«æåæå¹³éªçå¤è¦åå½±åï¼GPT-4V å¯ä»¥ç¢çåå« 3D æç¥è³è¨åç©ºééä¿çæå­è¨»è§£ãééå°æ§å¶è¨èèææåºçèªé©æéæ§å¶æ¨¡çµæ´åï¼æåçæ¨¡åå¯ä»¥çæå°ææ¼æå®æå­çå¤è¦åå½±åãFlexGen æ¯æ´å¤ç¨®å¯æ§åè½ï¼ä½¿ç¨æ¶è½å¤ ä¿®æ¹æå­æç¤ºä¾çæåçä¸å°æçæªè¦é¨åãæ­¤å¤ï¼ä½¿ç¨èå¯ä»¥å½±é¿å±¬æ§ï¼ä¾å¦å¤è§åæè³ªç¹æ§ï¼åæ¬éå±¬åç²ç³åº¦ãå»£æ³çå¯¦é©è­æäºæåçæ¹æ³æä¾äºå¢å¼·çå¤éå¯æ§æ§ï¼æ¨èªèå°ç¾æå¤è¦åæ´æ£æ¨¡åçéå¤§é²æ­¥ãéé å·¥ä½å°éè¦å¿«éä¸éæ´»ç 3D å§å®¹åµä½çé åå·æéå¤§æç¾©ï¼åæ¬éæ²éç¼ãåç«åèæ¬å¯¦å¢ãå°æ¡é é¢ï¼https://xxu068.github.io/flexgen.github.io/ã

##### **NT-LLM: A Novel Node Tokenizer for Integrating Graph Structure into Large Language Models**
2410.10743v1 by Yanbiao Ji, Chang Liu, Xin Chen, Yue Ding, Dan Luo, Mei Li, Wenqing Lin, Hongtao Lu

Graphs are a fundamental data structure for representing relationships in
real-world scenarios. With the success of Large Language Models (LLMs) across
various natural language processing (NLP) tasks, there has been growing
interest in integrating LLMs for graph learning. However, applying LLMs to
graph-related tasks poses significant challenges, as these models are not
inherently designed to capture the complex structural information present in
graphs. Existing approaches address this challenge through two strategies: the
chain of tasks approach, which uses Graph Neural Networks (GNNs) to encode the
graph structure so that LLMs are relieved from understanding spatial positions;
and Graph-to-Text Conversion, which translates graph structures into semantic
text representations that LLMs can process. Despite their progress, these
methods often struggle to fully preserve the topological information of graphs
or require extensive computational resources, limiting their practical
applicability.
  In this work, we introduce Node Tokenizer for Large Language Models (NT-LLM),
a novel framework that efficiently encodes graph structures by selecting key
nodes as anchors and representing each node based on its relative distance to
these anchors. This position-anchored encoding effectively captures the graph
topology, enabling enhanced reasoning capabilities in LLMs over graph data.
Additionally, we implement a task-specific tuning procedure to further improve
structural understanding within LLMs. Through extensive empirical evaluations,
NT-LLM demonstrates significant performance improvements across a variety of
graph-related tasks.

æè¦ï¼åå½¢æ¯ä¸ç¨®åºæ¬è³æçµæ§ï¼ç¨æ¼è¡¨ç¤ºç¾å¯¦ä¸çå ´æ¯ä¸­çéä¿ãé¨èå¤§åèªè¨æ¨¡å (LLM) å¨åç¨®èªç¶èªè¨èç (NLP) ä»»åä¸­çæåï¼æ´å LLM ä»¥é²è¡åå½¢å­¸ç¿çèè¶£æ¥çæ¿åãç¶èï¼å° LLM æç¨æ¼èåå½¢ç¸éçä»»åæå¸¶ä¾éå¤§ææ°ï¼å çºéäºæ¨¡åä¸¦éå¤©çå°±è¨­è¨æç¨ä¾æ·ååå½¢ä¸­å­å¨çè¤éçµæ§è³è¨ãç¾ææ¹æ³ééå©ç¨®ç­ç¥ä¾æå°æ­¤ææ°ï¼ä»»åéæ¹æ³ï¼å®ä½¿ç¨åå½¢ç¥ç¶ç¶²è·¯ (GNN) ç·¨ç¢¼åå½¢çµæ§ï¼ä»¥ä¾¿æ¸è¼ LLM çè§£ç©ºéä½ç½®çè² æï¼ä»¥ååå½¢è½æå­è½æï¼å®å°åå½¢çµæ§è½ææ LLM å¯ä»¥èççèªææå­è¡¨ç¤ºãåç®¡éäºæ¹æ³åå¾äºé²å±ï¼ä½å®åéå¸¸é£ä»¥å®å¨ä¿çåå½¢çææ²è³è¨ï¼æèéè¦å¤§éçéç®è³æºï¼éå¶äºå®åçå¯¦éæç¨æ§ã
å¨æ¬æä¸­ï¼æåä»ç´¹äºå¤§åèªè¨æ¨¡åç¯é»æ¨è¨å¨ (NT-LLM)ï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼å®ééé¸æééµç¯é»ä½çºé¨é»ï¼ä¸¦æ ¹ææ¯åç¯é»èéäºé¨é»çç¸å°è·é¢ä¾è¡¨ç¤ºæ¯åç¯é»ï¼å¾èææå°ç·¨ç¢¼åå½¢çµæ§ãéç¨®åºæ¼ä½ç½®çé¨é»ç·¨ç¢¼ææå°æ·åäºåå½¢ææ²ï¼è® LLM è½å¤ å°åå½¢è³æé²è¡å¢å¼·çæ¨çãæ­¤å¤ï¼æåå¯¦ä½äºä¸åç¹å®æ¼ä»»åçèª¿æ´ç¨åºï¼ä»¥é²ä¸æ­¥æ¹å LLM ä¸­ççµæ§çè§£ãééå»£æ³çå¯¦è­è©ä¼°ï¼NT-LLM å¨åç¨®èåå½¢ç¸éçä»»åä¸­é½å±ç¤ºåºé¡¯èçæè½æåã

##### **SensorBench: Benchmarking LLMs in Coding-Based Sensor Processing**
2410.10741v1 by Pengrui Quan, Xiaomin Ouyang, Jeya Vikranth Jeyakumar, Ziqi Wang, Yang Xing, Mani Srivastava

Effective processing, interpretation, and management of sensor data have
emerged as a critical component of cyber-physical systems. Traditionally,
processing sensor data requires profound theoretical knowledge and proficiency
in signal-processing tools. However, recent works show that Large Language
Models (LLMs) have promising capabilities in processing sensory data,
suggesting their potential as copilots for developing sensing systems.
  To explore this potential, we construct a comprehensive benchmark,
SensorBench, to establish a quantifiable objective. The benchmark incorporates
diverse real-world sensor datasets for various tasks. The results show that
while LLMs exhibit considerable proficiency in simpler tasks, they face
inherent challenges in processing compositional tasks with parameter selections
compared to engineering experts. Additionally, we investigate four prompting
strategies for sensor processing and show that self-verification can outperform
all other baselines in 48% of tasks. Our study provides a comprehensive
benchmark and prompting analysis for future developments, paving the way toward
an LLM-based sensor processing copilot.

æè¦ï¼ææèçãè©®éåç®¡çææ¸¬å¨è³æå·²æçºç¶²è·¯ç©çç³»çµ±çééµçµæé¨åãå³çµ±ä¸ï¼èçææ¸¬å¨è³æéè¦æ·±åççè«ç¥è­åè¨èèçå·¥å·ççç·´åº¦ãç¶èï¼æè¿çç ç©¶é¡¯ç¤ºï¼å¤§åèªè¨æ¨¡å (LLM) å¨èçææ¸¬å¨è³ææ¹é¢å·æè¯å¥½çè½åï¼è¡¨æå®åææ½åæçºéç¼ææ¸¬ç³»çµ±çå¯é§é§ã
çºäºæ¢ç´¢éç¨®æ½åï¼æåå»ºæ§äºä¸åå¨é¢çåºæºæ¸¬è©¦ SensorBenchï¼ä»¥å»ºç«ä¸åå¯éåçç®æ¨ãæ­¤åºæºæ¸¬è©¦æ´åäºåç¨®ä»»åçä¸åçå¯¦ä¸çææ¸¬å¨è³æéãçµæé¡¯ç¤ºï¼åç®¡ LLM å¨è¼ç°¡å®çä»»åä¸­å±ç¾åºç¸ç¶å¥½çè½åï¼ä½å¨èççµåä»»åæï¼å®åå¨åæ¸é¸ææ¹é¢é¢è¨åºæçææ°ï¼éèå·¥ç¨å°å®¶ç¸æ¯ãæ­¤å¤ï¼æåç ç©¶äºåç¨®ææ¸¬å¨èççæç¤ºç­ç¥ï¼ä¸¦é¡¯ç¤ºåºèªæé©è­å¨ 48% çä»»åä¸­åªæ¼ææå¶ä»åºæºãæåçç ç©¶çºæªä¾çç¼å±æä¾äºä¸åå¨é¢çåºæºæ¸¬è©¦åæç¤ºåæï¼çºåºæ¼ LLM çææ¸¬å¨èçå¯é§é§éªå¹³äºéè·¯ã

##### **Balancing Continuous Pre-Training and Instruction Fine-Tuning: Optimizing Instruction-Following in LLMs**
2410.10739v1 by Ishan Jindal, Chandana Badrinath, Pranjal Bharti, Lakkidi Vinay, Sachin Dev Sharma

Large Language Models (LLMs) for public use require continuous pre-training
to remain up-to-date with the latest data. The models also need to be
fine-tuned with specific instructions to maintain their ability to follow
instructions accurately. Typically, LLMs are released in two versions: the Base
LLM, pre-trained on diverse data, and the instruction-refined LLM, additionally
trained with specific instructions for better instruction following. The
question arises as to which model should undergo continuous pre-training to
maintain its instruction-following abilities while also staying current with
the latest data. In this study, we delve into the intricate relationship
between continuous pre-training and instruction fine-tuning of the LLMs and
investigate the impact of continuous pre-training on the instruction following
abilities of both the base and its instruction finetuned model. Further, the
instruction fine-tuning process is computationally intense and requires a
substantial number of hand-annotated examples for the model to learn
effectively. This study aims to find the most compute-efficient strategy to
gain up-to-date knowledge and instruction-following capabilities without
requiring any instruction data and fine-tuning. We empirically prove our
findings on the LLaMa 3, 3.1 and Qwen 2, 2.5 family of base and instruction
models, providing a comprehensive exploration of our hypotheses across varying
sizes of pre-training data corpus and different LLMs settings.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ä¾å¬ç¾ä½¿ç¨éè¦æçºé è¨ç·´ï¼æè½èææ°è³æä¿æåæ­¥ãéäºæ¨¡åä¹éè¦éå°ç¹å®æç¤ºé²è¡å¾®èª¿ï¼ä»¥ç¶­æå¶æºç¢ºéµå¾ªæç¤ºçè½åãLLM éå¸¸åçºå©åçæ¬ç¼å¸ï¼é åéå°åç¨®è³æé²è¡è¨ç·´çåºæ¬ LLMï¼ä»¥åéå°ç¹å®æç¤ºé²è¡é¡å¤è¨ç·´çæç¤ºç²¾ç LLMï¼ä»¥æ´ä½³å°éµå¾ªæç¤ºãåé¡å¨æ¼åªåæ¨¡åæè©²é²è¡æçºé è¨ç·´ï¼ä»¥ç¶­æå¶éµå¾ªæç¤ºçè½åï¼åæä¹è½èææ°è³æä¿æåæ­¥ãå¨æ¬ç ç©¶ä¸­ï¼æåæ·±å¥æ¢è¨ LLM çæçºé è¨ç·´èæç¤ºå¾®èª¿ä¹éçè¤ééä¿ï¼ä¸¦æ¢è¨æçºé è¨ç·´å°åºæ¬æ¨¡ååå¶æç¤ºå¾®èª¿æ¨¡åéµå¾ªæç¤ºè½åçå½±é¿ãæ­¤å¤ï¼æç¤ºå¾®èª¿éç¨å¨éç®ä¸å¾å¯éï¼éè¦å¤§éäººå·¥æ¨è¨»ç¯ä¾ï¼æè½è®æ¨¡åææå­¸ç¿ãæ¬ç ç©¶æ¨å¨æ¾åºæå·éç®æççç­ç¥ï¼ä»¥ç²å¾ææ°çç¥è­åéµå¾ªæç¤ºçè½åï¼èä¸éè¦ä»»ä½æç¤ºè³æåå¾®èª¿ãæåæ ¹æ LLaMa 3ã3.1 å Qwen 2ã2.5 ç³»åçåºæ¬æ¨¡ååæç¤ºæ¨¡åï¼å¯¦è­è­ææåçç ç©¶çµæï¼å¨é¢æ¢è¨æåçåè¨­ï¼æ¶µèä¸åè¦æ¨¡çé è¨ç·´è³æèªæåº«åä¸åç LLM è¨­å®ã

##### **DrivingDojo Dataset: Advancing Interactive and Knowledge-Enriched Driving World Model**
2410.10738v1 by Yuqi Wang, Ke Cheng, Jiawei He, Qitai Wang, Hengchen Dai, Yuntao Chen, Fei Xia, Zhaoxiang Zhang

Driving world models have gained increasing attention due to their ability to
model complex physical dynamics. However, their superb modeling capability is
yet to be fully unleashed due to the limited video diversity in current driving
datasets. We introduce DrivingDojo, the first dataset tailor-made for training
interactive world models with complex driving dynamics. Our dataset features
video clips with a complete set of driving maneuvers, diverse multi-agent
interplay, and rich open-world driving knowledge, laying a stepping stone for
future world model development. We further define an action instruction
following (AIF) benchmark for world models and demonstrate the superiority of
the proposed dataset for generating action-controlled future predictions.

æè¦ï¼é§é§ä¸çæ¨¡åå å¶å»ºæ¨¡è¤éç©çåæçè½åèååéæ³¨ãç¶èï¼ç±æ¼ç¶åé§é§æ¸æéä¸­çå½±çå¤æ¨£æ§æéï¼å¶åè¶çå»ºæ¨¡è½åå°æªå¾å°ååç¼æ®ãæåä»ç´¹äº DrivingDojoï¼éæ¯ç¬¬ä¸åå°éç¨æ¼è¨ç·´å·æè¤éé§é§åæçäºåä¸çæ¨¡åçæ¸æéãæåçæ¸æéåå«ä¸çµå®æ´çé§é§æä½å½±ççæ®µãå¤æ¨£åçå¤ä¸»é«äº¤äºä½ç¨ä»¥åè±å¯çéæ¾ä¸çé§é§ç¥è­ï¼çºæªä¾çä¸çæ¨¡åéç¼å¥ å®äºåºç³ãæåé²ä¸æ­¥å®ç¾©äºä¸çæ¨¡åçåä½æä»¤éµå¾ª (AIF) åºæºï¼ä¸¦å±ç¤ºäºææåºçæ¸æéå¨çæåä½æ§å¶çæªä¾é æ¸¬æ¹é¢çåªè¶æ§ã

##### **Embedding Self-Correction as an Inherent Ability in Large Language Models for Enhanced Mathematical Reasoning**
2410.10735v1 by Kuofeng Gao, Huanqia Cai, Qingyao Shuai, Dihong Gong, Zhifeng Li

Accurate mathematical reasoning with Large Language Models (LLMs) is crucial
in revolutionizing domains that heavily rely on such reasoning. However, LLMs
often encounter difficulties in certain aspects of mathematical reasoning,
leading to flawed reasoning and erroneous results. To mitigate these issues, we
introduce a novel mechanism, the Chain of Self-Correction (CoSC), specifically
designed to embed self-correction as an inherent ability in LLMs, enabling them
to validate and rectify their own results. The CoSC mechanism operates through
a sequence of self-correction stages. In each stage, the LLMs generate a
program to address a given problem, execute this program using program-based
tools to obtain an output, subsequently verify this output. Based on the
verification, the LLMs either proceed to the next correction stage or finalize
the answer. This iterative self-correction process allows the LLMs to refine
their reasoning steps and improve the accuracy of their mathematical reasoning.
To enable the CoSC mechanism at a low cost, we employ a two-phase finetuning
approach. In the first phase, the LLMs are trained with a relatively small
volume of seeding data generated from GPT-4, establishing an initial CoSC
capability. In the second phase, the CoSC capability is further enhanced by
training with a larger volume of self-generated data using the trained model in
the first phase, without relying on the paid GPT-4. Our comprehensive
experiments demonstrate that CoSC significantly improves performance on
traditional mathematical datasets among existing open-source LLMs. Notably, our
CoSC-Code-34B model achieved a 53.5% score on MATH, the most challenging
mathematical reasoning dataset in the public domain, surpassing the performance
of well-established models such as ChatGPT, GPT-4, and even multi-modal LLMs
like GPT-4V, Gemini-1.0 Pro, and Gemini-1.0 Ultra.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çæºç¢ºæ¸å­¸æ¨çå°æ¼å¾¹åºé©æ°é«åº¦ä¾è³´æ­¤é¡æ¨ççé åè³ééè¦ãç¶èï¼LLM å¨æ¸å­¸æ¨ççæäºæ¹é¢å¸¸å¸¸æéå°å°é£ï¼å°è´æ¨çæç¼ºé·ä¸çµæé¯èª¤ãçºäºæ¸è¼éäºåé¡ï¼æåå¼å¥äºä¸ç¨®æ°æ©å¶ï¼å³èªæä¿®æ­£é (CoSC)ï¼å°éè¨­è¨çºå°èªæä¿®æ­£ä½çº LLM çåºæè½åï¼ä½¿å®åè½å¤ é©è­åç³¾æ­£èªå·±ççµæãCoSC æ©å¶ééä¸ç³»åèªæä¿®æ­£éæ®µéè¡ãå¨æ¯åéæ®µï¼LLM æçæä¸åç¨å¼ä¾è§£æ±ºçµ¦å®çåé¡ï¼ä½¿ç¨åºæ¼ç¨å¼çå·¥å·å·è¡æ­¤ç¨å¼ä»¥ç²å¾è¼¸åºï¼é¨å¾é©è­æ­¤è¼¸åºãæ ¹æé©è­ï¼LLM è¦ä¹ç¹¼çºé²è¡ä¸ä¸åä¿®æ­£éæ®µï¼è¦ä¹æçµç¢ºå®ç­æ¡ãéååè¦çèªæä¿®æ­£éç¨ä½¿ LLM è½å¤ åªåå¶æ¨çæ­¥é©ä¸¦æé«å¶æ¸å­¸æ¨ççæºç¢ºæ§ãçºäºä»¥ä½ææ¬åç¨ CoSC æ©å¶ï¼æåæ¡ç¨äºå©éæ®µå¾®èª¿æ¹æ³ãå¨ç¬¬ä¸éæ®µï¼LLM ä½¿ç¨å¾ GPT-4 çæçç¸å°è¼å°éçç¨®å­è³æé²è¡è¨ç·´ï¼å»ºç«äºåå§ç CoSC è½åãå¨ç¬¬äºéæ®µï¼CoSC è½åééä½¿ç¨ç¬¬ä¸éæ®µä¸­è¨ç·´çæ¨¡åè¨ç·´å¤§éèªçè³æé²ä¸æ­¥å¢å¼·ï¼èç¡éä¾è³´ä»è²»ç GPT-4ãæåçç¶åå¯¦é©è¡¨æï¼CoSC å¨ç¾æçéæº LLM ä¸­é¡¯èæé«äºå³çµ±æ¸å­¸è³æéçæè½ãå¼å¾æ³¨æçæ¯ï¼æåç CoSC-Code-34B æ¨¡åå¨ MATH ä¸åå¾äº 53.5% çåæ¸ï¼éæ¯å¬æé åä¸­æå·ææ°æ§çæ¸å­¸æ¨çè³æéï¼è¶è¶äº ChatGPTãGPT-4 çè³å¤æ¨¡æ LLM ç­æçæ¨¡åçæè½ï¼ä¾å¦ GPT-4VãGemini-1.0 Pro å Gemini-1.0 Ultraã

##### **Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models**
2410.10733v1 by Junyu Chen, Han Cai, Junsong Chen, Enze Xie, Shang Yang, Haotian Tang, Muyang Li, Yao Lu, Song Han

We present Deep Compression Autoencoder (DC-AE), a new family of autoencoder
models for accelerating high-resolution diffusion models. Existing autoencoder
models have demonstrated impressive results at a moderate spatial compression
ratio (e.g., 8x), but fail to maintain satisfactory reconstruction accuracy for
high spatial compression ratios (e.g., 64x). We address this challenge by
introducing two key techniques: (1) Residual Autoencoding, where we design our
models to learn residuals based on the space-to-channel transformed features to
alleviate the optimization difficulty of high spatial-compression autoencoders;
(2) Decoupled High-Resolution Adaptation, an efficient decoupled three-phases
training strategy for mitigating the generalization penalty of high
spatial-compression autoencoders. With these designs, we improve the
autoencoder's spatial compression ratio up to 128 while maintaining the
reconstruction quality. Applying our DC-AE to latent diffusion models, we
achieve significant speedup without accuracy drop. For example, on ImageNet
512x512, our DC-AE provides 19.1x inference speedup and 17.9x training speedup
on H100 GPU for UViT-H while achieving a better FID, compared with the widely
used SD-VAE-f8 autoencoder. Our code is available at
https://github.com/mit-han-lab/efficientvit.

æè¦ï¼<paragraph>æåæåºæ·±åº¦å£ç¸®èªç·¨ç¢¼å¨ (DC-AE)ï¼ä¸ç¨®ç¨æ¼å éé«è§£æåº¦æ´æ£æ¨¡åçèªç·¨ç¢¼å¨æ¨¡åçæ°ç³»åãç¾æçèªç·¨ç¢¼å¨æ¨¡åå¨ä¸­ç­ç©ºéå£ç¸®æ¯ (ä¾å¦ 8 å) ä¸å·²å±ç¾ä»¤äººå°è±¡æ·±å»ççµæï¼ä½ç¡æ³ç¶­æé«ç©ºéå£ç¸®æ¯ (ä¾å¦ 64 å) çæ»¿æéå»ºæºç¢ºåº¦ãæåééå¼å¥å©é ééµæè¡ä¾è§£æ±ºæ­¤ææ°ï¼(1) æ®å·®èªç·¨ç¢¼ï¼æåè¨­è¨æåçæ¨¡åä»¥å­¸ç¿åºæ¼ç©ºéå°ééè½æç¹å¾µçæ®å·®ï¼ä»¥æ¸è¼é«ç©ºéå£ç¸®èªç·¨ç¢¼å¨çæä½³åé£åº¦ï¼(2) è§£è¦çé«è§£æåº¦é©æï¼ä¸ç¨®ç¨æ¼æ¸è¼é«ç©ºéå£ç¸®èªç·¨ç¢¼å¨çæ³åæ²ç½°çææè§£è¦ä¸éæ®µè¨ç·´ç­ç¥ãéééäºè¨­è¨ï¼æåå°èªç·¨ç¢¼å¨çç©ºéå£ç¸®æ¯æåè³ 128ï¼åæç¶­æéå»ºåè³ªãå°æåç DC-AE å¥ç¨æ¼æ½å¨æ´æ£æ¨¡åï¼æåå¨ä¸éä½æºç¢ºåº¦çææ³ä¸å¯¦ç¾é¡¯èçå éãä¾å¦ï¼å¨ ImageNet 512x512 ä¸ï¼æåç DC-AE å¨ H100 GPU ä¸çº UViT-H æä¾ 19.1 åçæ¨è«å éå 17.9 åçè¨ç·´å éï¼åæå¯¦ç¾æ¯å»£æ³ä½¿ç¨ç SD-VAE-f8 èªç·¨ç¢¼å¨æ´å¥½ç FIDãæåçç¨å¼ç¢¼å¯æ¼ https://github.com/mit-han-lab/efficientvit åå¾ã</paragraph>

##### **Towards LLM-guided Efficient and Interpretable Multi-linear Tensor Network Rank Selection**
2410.10728v1 by Giorgos Iacovides, Wuyang Zhou, Danilo Mandic

We propose a novel framework that leverages large language models (LLMs) to
guide the rank selection in tensor network models for higher-order data
analysis. By utilising the intrinsic reasoning capabilities and domain
knowledge of LLMs, our approach offers enhanced interpretability of the rank
choices and can effectively optimise the objective function. This framework
enables users without specialised domain expertise to utilise tensor network
decompositions and understand the underlying rationale within the rank
selection process. Experimental results validate our method on financial
higher-order datasets, demonstrating interpretable reasoning, strong
generalisation to unseen test data, and its potential for self-enhancement over
successive iterations. This work is placed at the intersection of large
language models and higher-order data analysis.

æè¦ï¼æåæåºä¸åæ°ç©çæ¶æ§ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾å¼å°å¼µéç¶²è·¯æ¨¡åä¸­çç§©é¸æï¼ä»¥é²è¡é«éè³æåæãééå©ç¨ LLM çå§å¨æ¨çè½ååé åç¥è­ï¼æåçåæ³æä¾äºå¢å¼·çç§©é¸æå¯è§£éæ§ï¼ä¸¦è½ææå°æä½³åç®æ¨å½æ¸ãéåæ¶æ§è®æ²æå°æ¥­é åç¥è­çä½¿ç¨èè½å¤ ä½¿ç¨å¼µéç¶²è·¯åè§£ï¼ä¸¦å¨ç§©é¸æéç¨ä¸­äºè§£å¶åºæ¬åçãå¯¦é©çµæé©è­äºæåå¨éèé«éè³æéä¸çæ¹æ³ï¼å±ç¤ºäºå¯è§£éçæ¨çãå°æªè¦æ¸¬è©¦è³æçå¼·æ³åè½åï¼ä»¥åå®å¨é£çºè¿­ä»£ä¸­èªæå¢å¼·çå¯è½æ§ãéé å·¥ä½ä½æ¼å¤§åèªè¨æ¨¡ååé«éè³æåæçäº¤åé»ä¸ã

##### **Large Language Models Are Active Critics in NLG Evaluation**
2410.10724v1 by Shuying Xu, Junjie Hu, Ming Jiang

The conventional paradigm of using large language models (LLMs) for
evaluating natural language generation (NLG) systems typically relies on two
key inputs: (1) a clear definition of the NLG task to be evaluated and (2) a
list of pre-defined evaluation criteria. This process treats LLMs as ''passive
critics,'' strictly following human-defined criteria for evaluation. However,
as new NLG tasks emerge, the criteria for assessing text quality can vary
greatly. Consequently, these rigid evaluation methods struggle to adapt to
diverse NLG tasks without extensive prompt engineering customized for each
specific task. To address this limitation, we introduce Active-Critic, a novel
LLM-based NLG evaluation protocol that enables LLMs to function as ''active
critics.'' Specifically, our protocol comprises two key stages. In the first
stage, the LLM is instructed to infer the target NLG task and establish
relevant evaluation criteria from the data. Building on this self-inferred
information, the second stage dynamically optimizes the prompt to guide the LLM
toward more human-aligned scoring decisions, while also generating detailed
explanations to justify its evaluations. Experiments across four NLG evaluation
tasks show that our approach achieves stronger alignment with human judgments
than state-of-the-art evaluation methods. Our comprehensive analysis further
highlights the effectiveness and explainability of Active-Critic with only a
small amount of labeled data. We will share our code and data on GitHub.

æè¦ï¼å³çµ±ä¸ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾è©ä¼°èªç¶èªè¨çæ (NLG) ç³»çµ±çç¯ä¾éå¸¸ä¾è³´æ¼å©åééµè¼¸å¥ï¼(1) è¦è©ä¼°ç NLG ä»»åçæç¢ºå®ç¾©ï¼ä»¥å (2) é åå®ç¾©çè©ä¼°æ¨æºæ¸å®ãæ­¤ç¨åºå° LLM è¦çºãè¢«åæ¹è©èãï¼å´æ ¼éµå¾ªäººé¡å®ç¾©çè©ä¼°æ¨æºãç¶èï¼é¨èæ°ç NLG ä»»ååºç¾ï¼è©ä¼°æå­åè³ªçæ¨æºå¯è½æå¤§ä¸ç¸åãå æ­¤ï¼éäºåµåçè©ä¼°æ¹æ³é£ä»¥é©æä¸åç NLG ä»»åï¼èä¸æéå°æ¯åç¹å®ä»»åé²è¡å»£æ³çæç¤ºå·¥ç¨èªè¨ãçºäºè§£æ±ºéåéå¶ï¼æåå¼å¥äº Active-Criticï¼ä¸ç¨®æ°ç©çåºæ¼ LLM ç NLG è©ä¼°åå®ï¼ä½¿ LLM è½å¤ ä½çºãä¸»åæ¹è©èãéä½ãå·é«ä¾èªªï¼æåçåå®åå«å©åééµéæ®µãå¨ç¬¬ä¸éæ®µï¼LLM è¢«æç¤ºå¾è³æä¸­æ¨è«ç®æ¨ NLG ä»»åä¸¦å»ºç«ç¸éè©ä¼°æ¨æºãåºæ¼éåèªææ¨è«çè³è¨ï¼ç¬¬äºéæ®µåææä½³åæç¤ºï¼ä»¥å¼å° LLM æåæ´ç¬¦åäººé¡çè©åæ±ºç­ï¼åæä¹ç¢çè©³ç´°çèªªæä¾è­æå¶è©ä¼°ãè·¨è¶åå NLG è©ä¼°ä»»åçå¯¦é©é¡¯ç¤ºï¼æåçæ¹æ³æ¯æåé²çè©ä¼°æ¹æ³èäººé¡å¤æ·æ´çºä¸è´ãæåçç¶ååæé²ä¸æ­¥å¼·èª¿äº Active-Critic çæææ§åå¯è§£éæ§ï¼èæ¨è¨è³æéåå°ãæåå°å¨ GitHub ä¸åäº«æåçç¨å¼ç¢¼åè³æã

##### **SeedLM: Compressing LLM Weights into Seeds of Pseudo-Random Generators**
2410.10714v1 by Rasoul Shafipour, David Harrison, Maxwell Horton, Jeffrey Marker, Houman Bedayat, Sachin Mehta, Mohammad Rastegari, Mahyar Najibi, Saman Naderiparizi

Large Language Models (LLMs) have transformed natural language processing,
but face significant challenges in widespread deployment due to their high
runtime cost. In this paper, we introduce SeedLM, a novel post-training
compression method that uses seeds of pseudo-random generators to encode and
compress model weights. Specifically, for each block of weights, we find a seed
that is fed into a Linear Feedback Shift Register (LFSR) during inference to
efficiently generate a random matrix. This matrix is then linearly combined
with compressed coefficients to reconstruct the weight block. SeedLM reduces
memory access and leverages idle compute cycles during inference, effectively
speeding up memory-bound tasks by trading compute for fewer memory accesses.
Unlike state-of-the-art compression methods that rely on calibration data, our
approach is data-free and generalizes well across diverse tasks. Our
experiments with Llama 3 70B, which is particularly challenging to compress,
show that SeedLM achieves significantly better zero-shot accuracy retention at
4- and 3-bit than state-of-the-art techniques, while maintaining performance
comparable to FP16 baselines. Additionally, FPGA-based tests demonstrate that
4-bit SeedLM, as model size increases to 70B, approaches a 4x speed-up over an
FP16 Llama 2/3 baseline.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²è½è®èªç¶èªè¨èçï¼ä½ç±æ¼å¶é«å·è¡æéææ¬ï¼å¨å»£æ³é¨ç½²ä¸­é¢è¨éå¤§ææ°ãå¨æ¬æä¸­ï¼æåä»ç´¹äº SeedLMï¼éæ¯ä¸ç¨®æ°ç©çè¨ç·´å¾å£ç¸®æ¹æ³ï¼å®ä½¿ç¨å½é¨æ©çæå¨çç¨®å­å°æ¨¡åæ¬éé²è¡ç·¨ç¢¼åå£ç¸®ãå·é«ä¾èªªï¼å°æ¼æ¯åæ¬éå¡ï¼æåæ¾å°ä¸åç¨®å­ï¼å¨æ¨çæéå°å¶è¼¸å¥ç·æ§åé¥ç§»ä½æ«å­å¨ (LFSR) ä¸­ï¼ä»¥ææçæé¨æ©ç©é£ãç¶å¾å°æ­¤ç©é£èå£ç¸®ä¿æ¸ç·æ§çµåä»¥éå»ºæ¬éå¡ãSeedLM æ¸å°äºè¨æ¶é«å­åï¼ä¸¦å¨æ¨çæéå©ç¨éç½®çéç®é±æï¼ææå°ééç¨éç®äº¤ææ´å°çè¨æ¶é«å­åä¾å éåè¨æ¶é«éå¶çä»»åãèä¾è³´æ ¡æºè³æçææ°å£ç¸®æ¹æ³ä¸åï¼æåçåæ³æ¯ç¡è³æçï¼ä¸¦ä¸å¨åç¨®ä»»åä¸­å·æè¯å¥½çæ³åæ§ãæåä½¿ç¨ç¹å¥é£ä»¥å£ç¸®ç Llama 3 70B é²è¡çå¯¦é©è¡¨æï¼SeedLM å¨ 4 ä½å 3 ä½æå¯¦ç¾äºé¡¯èæ´å¥½çé¶æ¬¡å­¸ç¿æºç¢ºçä¿çï¼åæä¿æè FP16 åºæºç¸ç¶çæè½ãæ­¤å¤ï¼åºæ¼ FPGA çæ¸¬è©¦è¡¨æï¼é¨èæ¨¡åå¤§å°å¢å å° 70Bï¼4 ä½å SeedLM æ¥è¿ FP16 Llama 2/3 åºæºç 4 åå éã

##### **Early Diagnoses of Acute Lymphoblastic Leukemia Using YOLOv8 and YOLOv11 Deep Learning Models**
2410.10701v1 by Alaa Awad, Mohamed Hegazy, Salah A. Aly

Thousands of individuals succumb annually to leukemia alone. This study
explores the application of image processing and deep learning techniques for
detecting Acute Lymphoblastic Leukemia (ALL), a severe form of blood cancer
responsible for numerous annual fatalities. As artificial intelligence
technologies advance, the research investigates the reliability of these
methods in real-world scenarios. The study focuses on recent developments in
ALL detection, particularly using the latest YOLO series models, to distinguish
between malignant and benign white blood cells and to identify different stages
of ALL, including early stages. Additionally, the models are capable of
detecting hematogones, which are often misclassified as ALL. By utilizing
advanced deep learning models like YOLOv8 and YOLOv11, the study achieves high
accuracy rates reaching 98.8%, demonstrating the effectiveness of these
algorithms across multiple datasets and various real-world situations.

æè¦ï¼æ¯å¹´ææ¸åäººåå ç½è¡çèæ­»äº¡ãæ¬ç ç©¶æ¢è¨å½±åèçåæ·±åº¦å­¸ç¿æè¡å¨åµæ¸¬æ¥æ§æ·å·´æ§ç½è¡ç (ALL) ä¸­çæç¨ï¼ALL æ¯ä¸ç¨®å´éçè¡çï¼æ¯å¹´é æè¨±å¤äººæ­»äº¡ãé¨èäººå·¥æºæ§æè¡çé²æ­¥ï¼æ¬ç ç©¶æ¢è¨éäºæ¹æ³å¨å¯¦éå ´æ¯ä¸­çå¯é æ§ãæ¬ç ç©¶éé»å¨æ¼ ALL åµæ¸¬çææ°é²å±ï¼ç¹å¥æ¯ä½¿ç¨ææ°ç YOLO ç³»åæ¨¡åï¼ä»¥ååæ¡æ§åè¯æ§ç½è¡çï¼ä¸¦è­å¥ ALL çä¸åéæ®µï¼åæ¬æ©æéæ®µãæ­¤å¤ï¼éäºæ¨¡åéè½åµæ¸¬å¸¸è¢«èª¤åé¡çº ALL çé è¡æ¯ç´°èãæ¬ç ç©¶å©ç¨ YOLOv8 å YOLOv11 ç­åé²çæ·±åº¦å­¸ç¿æ¨¡åï¼éæé«é 98.8% çé«æºç¢ºçï¼è­æéäºæ¼ç®æ³å¨å¤åè³æéååç¨®å¯¦éææ³ä¸­é½éå¸¸ææã

##### **Derail Yourself: Multi-turn LLM Jailbreak Attack through Self-discovered Clues**
2410.10700v1 by Qibing Ren, Hao Li, Dongrui Liu, Zhanxu Xie, Xiaoya Lu, Yu Qiao, Lei Sha, Junchi Yan, Lizhuang Ma, Jing Shao

This study exposes the safety vulnerabilities of Large Language Models (LLMs)
in multi-turn interactions, where malicious users can obscure harmful intents
across several queries. We introduce ActorAttack, a novel multi-turn attack
method inspired by actor-network theory, which models a network of semantically
linked actors as attack clues to generate diverse and effective attack paths
toward harmful targets. ActorAttack addresses two main challenges in multi-turn
attacks: (1) concealing harmful intents by creating an innocuous conversation
topic about the actor, and (2) uncovering diverse attack paths towards the same
harmful target by leveraging LLMs' knowledge to specify the correlated actors
as various attack clues. In this way, ActorAttack outperforms existing
single-turn and multi-turn attack methods across advanced aligned LLMs, even
for GPT-o1. We will publish a dataset called SafeMTData, which includes
multi-turn adversarial prompts and safety alignment data, generated by
ActorAttack. We demonstrate that models safety-tuned using our safety dataset
are more robust to multi-turn attacks. Code is available at
https://github.com/renqibing/ActorAttack.

æè¦ï¼æ¬ç ç©¶æ­é²äºå¤§åèªè¨æ¨¡å (LLM) å¨å¤è¼ªäºåä¸­çå®å¨æ¼æ´ï¼å¶ä¸­æ¡æä½¿ç¨èå¯ä»¥å¨å¤åæ¥è©¢ä¸­é±èæå®³æåãæåå¼å¥äº ActorAttackï¼éæ¯ä¸ç¨®æ°ç©çå¤è¼ªæ»ææ¹æ³ï¼éæä¾èªæ¼è¡åèç¶²è·¯çè«ï¼å®å°èªç¾©é£çµè¡åèçç¶²è·¯å»ºæ¨¡çºæ»æç·ç´¢ï¼ä»¥ç¢çå¤æ¨£åä¸ææçæ»æè·¯å¾ï¼é²èéå®æå®³ç®æ¨ãActorAttack æå°äºå¤è¼ªæ»æä¸­çå©åä¸»è¦ææ°ï¼(1) ééåµé éæ¼è¡åèçç¡å®³å°è©±ä¸»é¡ä¾é±èæå®³æåï¼ä»¥å (2) ééå©ç¨ LLM çç¥è­å°ç¸éè¡åèæå®çºåç¨®æ»æç·ç´¢ï¼é²èæ­é²éå¾ç¸åæå®³ç®æ¨çå¤æ¨£åæ»æè·¯å¾ãéééç¨®æ¹å¼ï¼ActorAttack å¨åé²çå°é½ LLM ä¸­åªæ¼ç¾æçå®è¼ªåå¤è¼ªæ»ææ¹æ³ï¼å³ä½¿æ¯å°æ¼ GPT-o1 ä¹æ¯å¦æ­¤ãæåå°ç¼å¸ä¸ååçº SafeMTData çè³æéï¼å¶ä¸­åå«ç± ActorAttack çæçå¤è¼ªå°ææç¤ºåå®å¨å°é½è³æãæåè­æä½¿ç¨æåçå®å¨è³æéé²è¡å®å¨èª¿æ´çæ¨¡åå°æ¼å¤è¼ªæ»ææ´å·é­¯æ£æ§ãç¨å¼ç¢¼å¯å¨ https://github.com/renqibing/ActorAttack åå¾ã

##### **Building a Multivariate Time Series Benchmarking Datasets Inspired by Natural Language Processing (NLP)**
2410.10687v1 by Mohammad Asif Ibna Mustafa, Ferdinand Heinrich

Time series analysis has become increasingly important in various domains,
and developing effective models relies heavily on high-quality benchmark
datasets. Inspired by the success of Natural Language Processing (NLP)
benchmark datasets in advancing pre-trained models, we propose a new approach
to create a comprehensive benchmark dataset for time series analysis. This
paper explores the methodologies used in NLP benchmark dataset creation and
adapts them to the unique challenges of time series data. We discuss the
process of curating diverse, representative, and challenging time series
datasets, highlighting the importance of domain relevance and data complexity.
Additionally, we investigate multi-task learning strategies that leverage the
benchmark dataset to enhance the performance of time series models. This
research contributes to the broader goal of advancing the state-of-the-art in
time series modeling by adopting successful strategies from the NLP domain.

æè¦ï¼æåºåæå¨ååé åä¸­è¶ä¾è¶éè¦ï¼èéç¼ææçæ¨¡åæ¥µåº¦ä»°è³´é«åè³ªçåºæºè³æéãåå°èªç¶èªè¨èç (NLP) åºæºè³æéå¨ä¿é²é åè¨ç·´æ¨¡åæ¹é¢çæååç¼ï¼æåæåºä¸åæ°çæ¹æ³ä¾å»ºç«ä¸åå¨é¢çæåºåæåºæºè³æéãæ¬ææ¢è¨äº NLP åºæºè³æéå»ºç«ä¸­æä½¿ç¨çåç¨®æ¹æ³ï¼ä¸¦å°å¶èª¿æ´å°æåºè³æçç¨ç¹ææ°ãæåè¨è«äºæ´çå¤æ¨£åãå·ä»£è¡¨æ§ä¸å·ææ°æ§çæåºè³æéçéç¨ï¼å¼·èª¿äºé åç¸éæ§åè³æè¤éæ§çéè¦æ§ãæ­¤å¤ï¼æåç ç©¶äºå¤ä»»åå­¸ç¿ç­ç¥ï¼è©²ç­ç¥å©ç¨åºæºè³æéä¾å¢å¼·æåºæ¨¡åçæè½ãæ¬ç ç©¶æå©æ¼ä¿é²æåºå»ºæ¨¡çææ°é²å±ï¼æ¹æ³æ¯æ¡ç¨ NLP é åçæåç­ç¥ã

##### **Large Language Model Evaluation via Matrix Nuclear-Norm**
2410.10672v1 by Yahan Li, Tingyu Xia, Yi Chang, Yuan Wu

As large language models (LLMs) continue to evolve, efficient evaluation
metrics are vital for assessing their ability to compress information and
reduce redundancy. While traditional metrics like Matrix Entropy offer valuable
insights, they are computationally intensive for large-scale models due to
their \( O(n^3) \) time complexity with Singular Value Decomposition (SVD). To
mitigate this issue, we introduce the Matrix Nuclear-Norm, which not only
serves as a metric to quantify the data compression proficiency of LLM but also
provides a convex approximation of matrix rank to capture both predictive
discriminability and diversity. By employing the \( L_{1,2}\text{-norm} \) to
further approximate the nuclear norm, we can effectively assess the model's
information compression capabilities. This approach reduces the time complexity
to \( O(n^2) \) and eliminates the need for SVD computation. Consequently, the
Matrix Nuclear-Norm achieves speeds 8 to 24 times faster than Matrix Entropy
for the CEREBRAS-GPT model as sizes increase from 111M to 6.7B. This
performance gap becomes more pronounced with larger models, as validated in
tests with other models like Pythia. Additionally, evaluations on benchmarks
and model responses confirm that our proposed Matrix Nuclear-Norm is a
reliable, scalable, and efficient tool for assessing LLMs' performance,
striking a balance between accuracy and computational efficiency. The code is
available at https://github.com/MLGroupJLU/MatrixNuclearNorm.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) æçºæ¼é²ï¼ææççè©ä¼°ææ¨å°æ¼è©ä¼°å®åå£ç¸®è³è¨èéä½åé¤çè½åè³ééè¦ãéç¶åæ¯ç©é£çµéé¡çå³çµ±ææ¨æä¾äºæå¹å¼çè¦è§£ï¼ä½ç±æ¼å®åèå¥ç°å¼åè§£ (SVD) çæéè¤éåº¦çº \( O(n^3) \)ï¼å°æ¼å¤§åæ¨¡åèè¨å¨è¨ç®ä¸ç¸ç¶å¯éãçºäºæ¸è¼éååé¡ï¼æåå¼å¥äºç©é£æ ¸ç¯æ¸ï¼å®ä¸åå¯ç¨ä½éå LLM è³æå£ç¸®è½åçææ¨ï¼ä¹æä¾äºç©é£ç§©çå¸è¿ä¼¼ï¼ä»¥ææé æ¸¬å¤å¥æ§åå¤æ¨£æ§ãèç±æ¡ç¨ \( L_{1,2}\text{-norm} \) ä¾é²ä¸æ­¥è¿ä¼¼æ ¸ç¯æ¸ï¼æåå¯ä»¥ææå°è©ä¼°æ¨¡åçè³è¨å£ç¸®è½åãéç¨®æ¹æ³å°æéè¤éåº¦éä½å° \( O(n^2) \)ï¼ä¸¦æ¶é¤äºå° SVD è¨ç®çéæ±ãå æ­¤ï¼é¨èæ¨¡åå¤§å°å¾ 111M å¢å å° 6.7Bï¼ç©é£æ ¸ç¯æ¸çéåº¦æ¯ç©é£çµå¿«äº 8 å° 24 åãå¨ä½¿ç¨å¶ä»æ¨¡åï¼ä¾å¦ Pythiaï¼é²è¡æ¸¬è©¦æï¼éç¨®æè½å·®è·å¨è¼å¤§çæ¨¡åä¸­è®å¾æ´å æé¡¯ãæ­¤å¤ï¼éå°åºæºåæ¨¡ååæçè©ä¼°è­å¯¦ï¼æåæåºçç©é£æ ¸ç¯æ¸æ¯ä¸ç¨®å¯é ãå¯æ´åä¸ææççå·¥å·ï¼ç¨æ¼è©ä¼° LLM çæè½ï¼å¨æºç¢ºæ§åè¨ç®æçä¹éåå¾å¹³è¡¡ãç¨å¼ç¢¼å¯å¨ https://github.com/MLGroupJLU/MatrixNuclearNorm åå¾ã

##### **Double Jeopardy and Climate Impact in the Use of Large Language Models: Socio-economic Disparities and Reduced Utility for Non-English Speakers**
2410.10665v1 by Aivin V. Solatorio, Gabriel Stefanini Vicente, Holly Krambeck, Olivier Dupriez

Artificial Intelligence (AI), particularly large language models (LLMs),
holds the potential to bridge language and information gaps, which can benefit
the economies of developing nations. However, our analysis of FLORES-200,
FLORES+, Ethnologue, and World Development Indicators data reveals that these
benefits largely favor English speakers. Speakers of languages in low-income
and lower-middle-income countries face higher costs when using OpenAI's GPT
models via APIs because of how the system processes the input -- tokenization.
Around 1.5 billion people, speaking languages primarily from
lower-middle-income countries, could incur costs that are 4 to 6 times higher
than those faced by English speakers. Disparities in LLM performance are
significant, and tokenization in models priced per token amplifies inequalities
in access, cost, and utility. Moreover, using the quality of translation tasks
as a proxy measure, we show that LLMs perform poorly in low-resource languages,
presenting a ``double jeopardy" of higher costs and poor performance for these
users. We also discuss the direct impact of fragmentation in tokenizing
low-resource languages on climate. This underscores the need for fairer
algorithm development to benefit all linguistic groups.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼ï¼å°¤å¶æ¯å¤§åèªè¨æ¨¡åï¼LLMï¼ï¼
å·æç¸®å°èªè¨åè³è¨å·®è·çæ½åï¼éå¯ä»¥è®éç¼ä¸­åå®¶çç¶æ¿åçãç¶èï¼æåå° FLORES-200ãFLORES+ãæ°æèªåä¸çç¼å±ææ¨è³æçåæé¡¯ç¤ºï¼éäºå¥½èä¸»è¦æå©æ¼è±èªä½¿ç¨èãç±æ¼ç³»çµ±èçè¼¸å¥çæ¹å¼ââåè©ï¼å æ­¤ä½æ¶å¥åä¸­ç­åä¸æ¶å¥åå®¶çèªè¨ä½¿ç¨èå¨éé API ä½¿ç¨ OpenAI ç GPT æ¨¡åææé¢è¨æ´é«çææ¬ãç´æ 15 åäººä¸»è¦ä½¿ç¨ä¸­ç­åä¸æ¶å¥åå®¶çèªè¨ï¼ä»åå¯è½ç¢ççææ¬ææ¯è±èªä½¿ç¨èé«åº 4 å° 6 åãLLM æè½çå·®ç°å¾å¤§ï¼èæä»£å¹£å®å¹çæ¨¡åä¸­çåè©ææ´å¤§å¨å­åãææ¬åæç¨æ¹é¢çå·®è·ãæ­¤å¤ï¼æåä»¥ç¿»è­¯ä»»åçåè³ªä½çºæ¿ä»£è¡¡éæ¨æºï¼é¡¯ç¤º LLM å¨ä½è³æºèªè¨ä¸­çè¡¨ç¾ä¸ä½³ï¼å°éäºä½¿ç¨èä¾èªªï¼éæé æææ¬è¼é«åæè½ä¸ä½³çãééå±æ©ããæåä¹è¨è«äºåè©ä½è³æºèªè¨çç ´ç¢åå°æ°£åçç´æ¥å½±é¿ãéå¼·èª¿äºå¬å¹³æ¼ç®æ³éç¼çå¿è¦æ§ï¼ä»¥è®ææèªè¨ç¾¤é«åçã

##### **Generative AI and Its Impact on Personalized Intelligent Tutoring Systems**
2410.10650v1 by Subhankar Maity, Aniket Deroy

Generative Artificial Intelligence (AI) is revolutionizing educational
technology by enabling highly personalized and adaptive learning environments
within Intelligent Tutoring Systems (ITS). This report delves into the
integration of Generative AI, particularly large language models (LLMs) like
GPT-4, into ITS to enhance personalized education through dynamic content
generation, real-time feedback, and adaptive learning pathways. We explore key
applications such as automated question generation, customized feedback
mechanisms, and interactive dialogue systems that respond to individual learner
needs. The report also addresses significant challenges, including ensuring
pedagogical accuracy, mitigating inherent biases in AI models, and maintaining
learner engagement. Future directions highlight the potential advancements in
multimodal AI integration, emotional intelligence in tutoring systems, and the
ethical implications of AI-driven education. By synthesizing current research
and practical implementations, this report underscores the transformative
potential of Generative AI in creating more effective, equitable, and engaging
educational experiences.

æè¦ï¼çæå¼äººå·¥æºæ§ï¼AIï¼ééå¨æºæ§åæå­¸ç³»çµ±ï¼ITSï¼ä¸­å»ºæ§é«åº¦åäººåä¸é©ææ§çå­¸ç¿ç°å¢ï¼é©æ°æè²æè¡ãæ­¤å ±åæ·±å¥æ¢è¨çæå¼ AIï¼ç¹å¥æ¯å¤§åèªè¨æ¨¡åï¼LLMï¼ï¼ä¾å¦ GPT-4ï¼æ´åè³ ITS ä¸­ï¼èç±åæå§å®¹çæãå³æåé¥åé©ææ§å­¸ç¿è·¯å¾ï¼å¼·ååäººåæè²ãæåæ¢ç´¢äºééµæç¨ï¼ä¾å¦èªåååé¡çæãèªè¨åé¥æ©å¶ï¼ä»¥ååæåå¥å­¸ç¿èéæ±çäºåå°è©±ç³»çµ±ãå ±åä¸­ä¹æ¢è¨äºéå¤§ææ°ï¼åæ¬ç¢ºä¿æå­¸æºç¢ºæ§ãæ¸è¼ AI æ¨¡åä¸­åºæçåè¦ï¼ä»¥åç¶­æå­¸ç¿èçåèåº¦ãæªä¾ç¼å±éé»çªé¡¯äºå¤æ¨¡æ AI æ´åãæå­¸ç³»çµ±ä¸­çæç·æºæ§ï¼ä»¥å AI é©åæè²çå«çææ¶µãééç¶åç¾æç ç©¶åå¯¦åå¯¦æ½ï¼æ­¤å ±åå¼·èª¿äºçæå¼ AI å¨åµé æ´ææãæ´å¬å¹³ä¸æ´å·å¸å¼åçæè²é«é©æ¹é¢çè½åæ½åã

##### **DR-MPC: Deep Residual Model Predictive Control for Real-world Social Navigation**
2410.10646v1 by James R. Han, Hugues Thomas, Jian Zhang, Nicholas Rhinehart, Timothy D. Barfoot

How can a robot safely navigate around people exhibiting complex motion
patterns? Reinforcement Learning (RL) or Deep RL (DRL) in simulation holds some
promise, although much prior work relies on simulators that fail to precisely
capture the nuances of real human motion. To address this gap, we propose Deep
Residual Model Predictive Control (DR-MPC), a method to enable robots to
quickly and safely perform DRL from real-world crowd navigation data. By
blending MPC with model-free DRL, DR-MPC overcomes the traditional DRL
challenges of large data requirements and unsafe initial behavior. DR-MPC is
initialized with MPC-based path tracking, and gradually learns to interact more
effectively with humans. To further accelerate learning, a safety component
estimates when the robot encounters out-of-distribution states and guides it
away from likely collisions. In simulation, we show that DR-MPC substantially
outperforms prior work, including traditional DRL and residual DRL models.
Real-world experiments show our approach successfully enables a robot to
navigate a variety of crowded situations with few errors using less than 4
hours of training data.

æè¦ï¼æ©å¨äººå¦ä½å®å¨å°ç©¿æ¢­å¨è¡¨ç¾åºè¤éåä½æ¨¡å¼çäººç¾¤ä¸­ï¼åç®¡è¨±å¤ååçå·¥ä½é½ä¾è³´æ¼ç¡æ³ç²¾ç¢ºææäººé¡çå¯¦åä½ç´°å¾®å·®å¥çæ¨¡æ¬å¨ï¼ä½æ¨¡æ¬ä¸­çå¼·åå­¸ç¿ (RL) ææ·±åº¦å¼·åå­¸ç¿ (DRL) ä»å·æä¸å®çåæ¯ãçºäºè§£æ±ºéåå·®è·ï¼æåæåºäºæ·±åº¦æ®å·®æ¨¡åé æ¸¬æ§å¶ (DR-MPC)ï¼éæ¯ä¸ç¨®æ¹æ³ï¼è®æ©å¨äººè½å¤ æ ¹æçå¯¦ä¸ççç¾¤ç¾å°èªæ¸æå¿«éä¸å®å¨å°å·è¡ DRLãééå° MPC èç¡æ¨¡å DRL ç¸çµåï¼DR-MPC åæäºå³çµ± DRL å¨å¤§éæ¸æéæ±åä¸å®å¨çåå§è¡çºæ¹é¢çææ°ãDR-MPC ä½¿ç¨åºæ¼ MPC çè·¯å¾è¿½è¹¤é²è¡åå§åï¼ä¸¦éæ¼¸å­¸ç¿èäººé¡é²è¡æ´ææçäºåãçºäºé²ä¸æ­¥å éå­¸ç¿ï¼å®å¨çµä»¶æä¼°è¨æ©å¨äººä½æéå°åå¸å¤çæï¼ä¸¦æå°å®é é¢å¯è½çç¢°æãå¨æ¨¡æ¬ä¸­ï¼æåå±ç¤ºäº DR-MPC æé¡¯åªæ¼ååçç ç©¶ï¼åæ¬å³çµ± DRL åæ®å·® DRL æ¨¡åãçå¯¦ä¸ççå¯¦é©è¡¨æï¼æåçåæ³æåå°è®æ©å¨äººå¨ä¸å° 4 å°æçè¨ç·´æ¸æä¸ï¼ä»¥å¾å°çé¯èª¤å¨åç¨®ææ çææ³ä¸å°èªã

##### **Adapt-$\infty$: Scalable Lifelong Multimodal Instruction Tuning via Dynamic Data Selection**
2410.10636v1 by Adyasha Maharana, Jaehong Yoon, Tianlong Chen, Mohit Bansal

Visual instruction datasets from various distributors are released at
different times and often contain a significant number of semantically
redundant text-image pairs, depending on their task compositions (i.e., skills)
or reference sources. This redundancy greatly limits the efficient deployment
of lifelong adaptable multimodal large language models, hindering their ability
to refine existing skills and acquire new competencies over time. To address
this, we reframe the problem of Lifelong Instruction Tuning (LiIT) via data
selection, where the model automatically selects beneficial samples to learn
from earlier and new datasets based on the current state of acquired knowledge
in the model. Based on empirical analyses that show that selecting the best
data subset using a static importance measure is often ineffective for
multi-task datasets with evolving distributions, we propose Adapt-$\infty$, a
new multi-way and adaptive data selection approach that dynamically balances
sample efficiency and effectiveness during LiIT. We construct pseudo-skill
clusters by grouping gradient-based sample vectors. Next, we select the
best-performing data selector for each skill cluster from a pool of selector
experts, including our newly proposed scoring function, Image Grounding score.
This data selector samples a subset of the most important samples from each
skill cluster for training. To prevent the continuous increase in the size of
the dataset pool during LiIT, which would result in excessive computation, we
further introduce a cluster-wise permanent data pruning strategy to remove the
most semantically redundant samples from each cluster, keeping computational
requirements manageable. Training with samples selected by Adapt-$\infty$
alleviates catastrophic forgetting, especially for rare tasks, and promotes
forward transfer across the continuum using only a fraction of the original
datasets.

æè¦ï¼<paragraph>ä¸åç¼è¡åæä¾çè¦è¦ºæä»¤è³æéç¼å¸æéä¸åï¼èä¸éå¸¸åå«å¤§éèªç¾©ä¸éè¤çæå­å½±åå°ï¼å·é«åæ±ºæ¼å¶ä»»åçµåï¼å³æè½ï¼æåèä¾æºãéç¨®éè¤æ§æ¥µå¤§å°éå¶äºçµèº«é©æå¤æ¨¡æå¤§åèªè¨æ¨¡åçææé¨ç½²ï¼é»ç¤äºå®åé¨èæéæ¨ç§»ç²¾é²ç¾ææè½åç¿å¾æ°è½åãçºäºè§£æ±ºéååé¡ï¼æåééè³æé¸æéæ°å®ç¾©çµèº«æä»¤èª¿æ´ (LiIT) çåé¡ï¼å¶ä¸­æ¨¡åæ ¹ææ¨¡åä¸­å·²ç²åç¥è­çç¶åçæï¼èªåé¸ææççæ¨£æ¬ä¾å¾è¼æ©åæ°çè³æéä¸­å­¸ç¿ãæ ¹æç¶é©åæè¡¨æï¼å°æ¼åä½ä¸æ·è®åçå¤ä»»åè³æéï¼ä½¿ç¨éæéè¦æ§æ¸¬éä¾é¸ææä½³è³æå­ééå¸¸ç¡æï¼æåæåºäº Adapt-$\infty$ï¼éæ¯ä¸ç¨®æ°çå¤è·¯å¾åèªé©æè³æé¸ææ¹æ³ï¼å¯å¨ LiIT æéåæå¹³è¡¡æ¨£æ¬æçåæææ§ãæåééå°åºæ¼æ¢¯åº¦çæ¨£æ¬åéé²è¡åçµä¾æ§å»ºå½æè½ç¾¤éãæ¥ä¸ä¾ï¼æåå¾ä¸åé¸æå¨å°å®¶æ± ä¸­çºæ¯åæè½ç¾¤éé¸ææè½æä½³çè³æé¸æå¨ï¼åæ¬æåæ°æåºçè©åå½æ¸ãå½±ååºç¤è©åãæ­¤è³æé¸æå¨å¾æ¯åæè½ç¾¤éåæ¨£æéè¦çæ¨£æ¬å­éé²è¡è¨ç·´ãçºäºé²æ­¢ LiIT æéè³æéæ± å¤§å°æçºå¢å ï¼éå°å°è´éåº¦éç®ï¼æåé²ä¸æ­¥å¼å¥äºä¸åç¾¤éå¼æ°¸ä¹è³æä¿®åªç­ç¥ï¼å¾æ¯åç¾¤éä¸­ç§»é¤èªç¾©ä¸æéè¤çæ¨£æ¬ï¼ä¿æéç®éæ±å¨å¯æ§ç¯åå§ãä½¿ç¨ Adapt-$\infty$ é¸æçæ¨£æ¬é²è¡è¨ç·´å¯ä»¥æ¸è¼ç½é£æ§éºå¿ï¼ç¹å¥æ¯å°æ¼ç½è¦çä»»åï¼ä¸¦åä½¿ç¨åå§è³æéçä¸å°é¨åä¾ä¿é²å¨æ´åé£çºé«ä¸­çæ­£åè½ç§»ã</paragraph>

##### **Thinking LLMs: General Instruction Following with Thought Generation**
2410.10630v1 by Tianhao Wu, Janice Lan, Weizhe Yuan, Jiantao Jiao, Jason Weston, Sainbayar Sukhbaatar

LLMs are typically trained to answer user questions or follow instructions
similarly to how human experts respond. However, in the standard alignment
framework they lack the basic ability of explicit thinking before answering.
Thinking is important for complex questions that require reasoning and planning
-- but can be applied to any task. We propose a training method for equipping
existing LLMs with such thinking abilities for general instruction following
without use of additional human data. We achieve this by an iterative search
and optimization procedure that explores the space of possible thought
generations, allowing the model to learn how to think without direct
supervision. For each instruction, the thought candidates are scored using a
judge model to evaluate their responses only, and then optimized via preference
optimization. We show that this procedure leads to superior performance on
AlpacaEval and Arena-Hard, and shows gains from thinking on non-reasoning
categories such as marketing, health and general knowledge, in addition to more
traditional reasoning & problem-solving tasks.

æè¦ï¼LLM éå¸¸è¢«è®­ç»æåç­ç¨æ·çæé®æéµå¾ªæä»¤ï¼ç±»ä¼¼äºäººç±»ä¸å®¶å¦ä½ååºãç¶èï¼å¨æ åå¯¹é½æ¡æ¶ä¸­ï¼å®ä»¬ç¼ºä¹å¨åç­ä¹åè¿è¡æç¡®æèçåºæ¬è½åãæèå¯¹äºéè¦æ¨çåè§åçå¤æé®é¢éå¸¸éè¦ï¼ä½å®å¯ä»¥åºç¨äºä»»ä½ä»»å¡ãæä»¬æåºäºä¸ç§è®­ç»æ¹æ³ï¼ä¸ºç°æç LLM æä¾è¿ç§æèè½åï¼ä»¥ä¾¿å¨æ²¡æä½¿ç¨é¢å¤äººç±»æ°æ®çæåµä¸éµå¾ªä¸è¬æä»¤ãæä»¬éè¿ä¸ç§è¿­ä»£æç´¢åä¼åç¨åºæ¥å®ç°è¿ä¸ç¹ï¼è¯¥ç¨åºæ¢ç´¢å¯è½çææ³çæç©ºé´ï¼åè®¸æ¨¡åå­¦ä¹ å¦ä½å¨æ²¡æç´æ¥çç£çæåµä¸è¿è¡æèãå¯¹äºæ¯æ¡æä»¤ï¼ææ³åéèä½¿ç¨è¯å¤æ¨¡åè¿è¡è¯åï¼ä»è¯ä¼°å¶ååºï¼ç¶åéè¿åå¥½ä¼åè¿è¡ä¼åãæä»¬è¡¨æï¼æ­¤ç¨åºå¨ AlpacaEval å Arena-Hard ä¸è¡¨ç°åºåè¶çæ§è½ï¼å¹¶ä¸é¤äºæ´ä¼ ç»çæ¨çåè§£å³é®é¢ä»»å¡ä¹å¤ï¼è¿å±ç¤ºäºå¨éæ¨çç±»å«ï¼ä¾å¦è¥éãå¥åº·åä¸è¬ç¥è¯ï¼ä¸çæèæ¶çã

##### **Efficiently Democratizing Medical LLMs for 50 Languages via a Mixture of Language Family Experts**
2410.10626v1 by Guorui Zheng, Xidong Wang, Juhao Liang, Nuo Chen, Yuping Zheng, Benyou Wang

Adapting medical Large Language Models to local languages can reduce barriers
to accessing healthcare services, but data scarcity remains a significant
challenge, particularly for low-resource languages. To address this, we first
construct a high-quality medical dataset and conduct analysis to ensure its
quality. In order to leverage the generalization capability of multilingual
LLMs to efficiently scale to more resource-constrained languages, we explore
the internal information flow of LLMs from a multilingual perspective using
Mixture of Experts (MoE) modularity. Technically, we propose a novel MoE
routing method that employs language-specific experts and cross-lingual
routing. Inspired by circuit theory, our routing analysis revealed a Spread Out
in the End information flow mechanism: while earlier layers concentrate
cross-lingual information flow, the later layers exhibit language-specific
divergence. This insight directly led to the development of the Post-MoE
architecture, which applies sparse routing only in the later layers while
maintaining dense others. Experimental results demonstrate that this approach
enhances the generalization of multilingual models to other languages while
preserving interpretability. Finally, to efficiently scale the model to 50
languages, we introduce the concept of language family experts, drawing on
linguistic priors, which enables scaling the number of languages without adding
additional parameters.

æè¦ï¼<paragraph>éå°ç¶å°èªè¨èª¿æ´å¤§åé«çèªè¨æ¨¡åè½æ¸å°åå¾é«çä¿å¥æåçéç¤ï¼ä½è³æç¨å°çåé¡ä»ç¶æ¯ä¸é éå¤§ææ°ï¼ç¹å¥æ¯å°æ¼ä½è³æºèªè¨ä¾èªªãçºäºè§£æ±ºéååé¡ï¼æåé¦åå»ºæ§ä¸åé«åè³ªçé«çè³æéï¼ä¸¦é²è¡åæä»¥ç¢ºä¿å¶åè³ªãçºäºåç¨å¤èªè¨ LLM çæ¦åè½åï¼ä»¥æææ´å±å°æ´å¤è³æºåéçèªè¨ï¼æåå¾å¤èªè¨çè§åº¦æ¢ç´¢ LLM çå§é¨è³è¨æµï¼ä¸¦ä½¿ç¨å°å®¶æ··å (MoE) æ¨¡çµåãå¨æè¡ä¸ï¼æåæåºäºä¸ç¨®åµæ°ç MoE è·¯ç±æ¹æ³ï¼æ¡ç¨ç¹å®èªè¨çå°å®¶åè·¨èªè¨è·¯ç±ãåå°é»è·¯çè«çåç¼ï¼æåçè·¯ç±åææ­ç¤ºäºä¸åå¨æå¾åæ£çè³è¨æµæ©å¶ï¼æ©æå±¤éä¸­è·¨èªè¨è³è¨æµï¼èå¾çºå±¤åå±ç¾åºç¹å®èªè¨çåæ­§ãéåè¦è§£ç´æ¥å°è´å¾ MoE æ¶æ§çç¼å±ï¼å®åå¨å¾çºå±¤å¥ç¨ç¨çè·¯ç±ï¼åæç¶­æå¶ä»å±¤çç¨ å¯ãå¯¦é©çµæè­æï¼éç¨®æ¹æ³å¢å¼·äºå¤èªè¨æ¨¡åå°å¶ä»èªè¨çæ¦åè½åï¼åæä¿çäºè§£éè½åãæå¾ï¼çºäºææå°å°æ¨¡åæ´å±å° 50 ç¨®èªè¨ï¼æåå¼å¥äºèªè¨å®¶æå°å®¶çæ¦å¿µï¼å©ç¨èªè¨åé©ï¼éä½¿å¾æåå¯ä»¥å¨ä¸å¢å é¡å¤åæ¸çææ³ä¸æ´å±èªè¨æ¸éã</paragraph>

##### **SensorLLM: Aligning Large Language Models with Motion Sensors for Human Activity Recognition**
2410.10624v1 by Zechen Li, Shohreh Deldari, Linyao Chen, Hao Xue, Flora D. Salim

In this work, we bridge the gap between wearable sensor technology and
personalized AI assistants by enabling Large Language Models (LLMs) to
understand time-series tasks like human activity recognition (HAR). Despite the
strong reasoning and generalization capabilities of LLMs, leveraging them for
sensor data tasks remains largely unexplored. This gap stems from challenges
like the lack of semantic context in time-series data, computational
limitations, and LLMs' difficulty processing numerical inputs. To address these
issues, we introduce SensorLLM, a two-stage framework to unlock LLMs' potential
for sensor data tasks. In the Sensor-Language Alignment Stage, we introduce
special tokens for each sensor channel and automatically generate
trend-descriptive text to align sensor data with textual inputs, enabling
SensorLLM to capture numerical changes, channel-specific information, and
sensor data of varying lengths-capabilities that existing LLMs typically
struggle with, all without the need for human annotations. Next, in Task-Aware
Tuning Stage, we refine the model for HAR classification using the frozen LLM
and alignment module, achieving performance on par with or surpassing
state-of-the-art models. We further demonstrate that SensorLLM evolves into an
effective sensor learner, reasoner, and classifier through Sensor-Language
Alignment, enabling it to generalize across diverse datasets for HAR tasks. We
strongly believe our work lays the stepstone for future time-series and text
alignment research, offering a path toward foundation models for sensor data.

æè¦ï¼å¨éé å·¥ä½ä¸­ï¼æåééè®å¤§åèªè¨æ¨¡å (LLM) äºè§£æéåºåä»»åï¼ä¾å¦äººé¡æ´»åè¾¨è­ (HAR)ï¼ä¾å½åç©¿æ´å¼ææ¸¬å¨æè¡ååäººå AI å©çä¹éçå·®è·ãåç®¡ LLM å·æå¼·å¤§çæ¨çåæ¦æ¬è½åï¼ä½å©ç¨å®åä¾å·è¡ææ¸¬å¨è³æä»»åå¨å¾å¤§ç¨åº¦ä¸ä»æªè¢«æ¢ç´¢ãéåå·®è·æºæ¼ææ°ï¼ä¾å¦æéåºåè³æä¸­ç¼ºä¹èªæèçµ¡ãéç®éå¶ï¼ä»¥å LLM é£ä»¥èçæ¸å¼è¼¸å¥ãçºäºè§£æ±ºéäºåé¡ï¼æåå¼å¥äº SensorLLMï¼ä¸åå©éæ®µæ¶æ§ï¼ç¨æ¼éæ¾ LLM å¨ææ¸¬å¨è³æä»»åä¸­çæ½åãå¨ææ¸¬å¨èªè¨å°é½éæ®µï¼æåçºæ¯åææ¸¬å¨ééå¼å¥äºç¹æ®æ¨è¨ï¼ä¸¦èªåç¢çè¶¨å¢æè¿°æå­ï¼ä»¥å°ææ¸¬å¨è³æèæå­è¼¸å¥å°é½ï¼è® SensorLLM è½å¤ æ·åæ¸å¼è®åãééç¹å®è³è¨ï¼ä»¥åé·åº¦ä¸ä¸çææ¸¬å¨è³æï¼éäºé½æ¯ç¾æ LLM éå¸¸é£ä»¥èççè½åï¼èä¸ç¡éäººå·¥è¨»è§£ãæ¥ä¸ä¾ï¼å¨ä»»åæç¥èª¿æ´éæ®µï¼æåä½¿ç¨åçµç LLM åå°é½æ¨¡çµå¾®èª¿ HAR åé¡æ¨¡åï¼éå°èæåé²æ¨¡åç¸ç¶æè¶è¶çæè½ãæåé²ä¸æ­¥è­æï¼SensorLLM ééææ¸¬å¨èªè¨å°é½æ¼è®æä¸åææçææ¸¬å¨å­¸ç¿å¨ãæ¨çå¨ååé¡å¨ï¼ä½¿å¶è½å¤ å¨ HAR ä»»åçä¸åè³æéä¹éé²è¡æ¦åãæåå ä¿¡ï¼æåçç ç©¶çºæªä¾çæéåºååæå­å°é½ç ç©¶å¥ å®äºåºç¤ï¼çºææ¸¬å¨è³ææä¾åºç¤æ¨¡åçè·¯å¾ã

##### **Modeling News Interactions and Influence for Financial Market Prediction**
2410.10614v1 by Mengyu Wang, Shay B. Cohen, Tiejun Ma

The diffusion of financial news into market prices is a complex process,
making it challenging to evaluate the connections between news events and
market movements. This paper introduces FININ (Financial Interconnected News
Influence Network), a novel market prediction model that captures not only the
links between news and prices but also the interactions among news items
themselves. FININ effectively integrates multi-modal information from both
market data and news articles. We conduct extensive experiments on two
datasets, encompassing the S&P 500 and NASDAQ 100 indices over a 15-year period
and over 2.7 million news articles. The results demonstrate FININ's
effectiveness, outperforming advanced market prediction models with an
improvement of 0.429 and 0.341 in the daily Sharpe ratio for the two markets
respectively. Moreover, our results reveal insights into the financial news,
including the delayed market pricing of news, the long memory effect of news,
and the limitations of financial sentiment analysis in fully extracting
predictive power from news data.

æè¦ï¼éèæ°èå¨å¸å ´å¹æ ¼ä¸­å³æ­æ¯ä¸åè¤éçéç¨ï¼
ä½¿å¾è©ä¼°æ°èäºä»¶èå¸å ´è®åä¹éçéè¯æ§å·æææ°æ§ãæ¬æä»ç´¹ FININï¼éèç¸äºéè¯æ°èå½±é¿ç¶²è·¯ï¼ï¼éæ¯ä¸åæ°ç©çå¸å ´é æ¸¬æ¨¡åï¼ä¸åæææ°èèå¹æ ¼ä¹éçéè¯ï¼éæææ°èé ç®ä¹éçäºåãFININ æææ´åä¾èªå¸å ´æ¸æåæ°èæç« çå¤æ¨¡å¼è³è¨ãæåå°å©åè³æéé²è¡å»£æ³çå¯¦é©ï¼æ¶µè 15 å¹´æéçæ¨æºæ®ç¾ 500 ææ¸åç´æ¯éå 100 ææ¸ï¼ä»¥åè¶é 270 è¬ç¯æ°èæç« ãçµæè­æäº FININ çæææ§ï¼åªæ¼é²éå¸å ´é æ¸¬æ¨¡åï¼åå¥å°å©åå¸å ´çæ¯æ¥å¤æ®æ¯çæé«äº 0.429 å 0.341ãæ­¤å¤ï¼æåççµææ­ç¤ºäºå°éèæ°èçè¦è§£ï¼åæ¬æ°èçå»¶é²å¸å ´å®å¹ãæ°èçé·æè¨æ¶ææï¼ä»¥åè²¡åæç·åæå¨å¾æ°èæ¸æä¸­å®å¨æåé æ¸¬è½åæ¹é¢çéå¶ã

##### **Intelligent prospector v2.0: exploration drill planning under epistemic model uncertainty**
2410.10610v1 by John Mern, Anthony Corso, Damian Burch, Kurt House, Jef Caers

Optimal Bayesian decision making on what geoscientific data to acquire
requires stating a prior model of uncertainty. Data acquisition is then
optimized by reducing uncertainty on some property of interest maximally, and
on average. In the context of exploration, very few, sometimes no data at all,
is available prior to data acquisition planning. The prior model therefore
needs to include human interpretations on the nature of spatial variability, or
on analogue data deemed relevant for the area being explored. In mineral
exploration, for example, humans may rely on conceptual models on the genesis
of the mineralization to define multiple hypotheses, each representing a
specific spatial variability of mineralization. More often than not, after the
data is acquired, all of the stated hypotheses may be proven incorrect, i.e.
falsified, hence prior hypotheses need to be revised, or additional hypotheses
generated. Planning data acquisition under wrong geological priors is likely to
be inefficient since the estimated uncertainty on the target property is
incorrect, hence uncertainty may not be reduced at all. In this paper, we
develop an intelligent agent based on partially observable Markov decision
processes that plans optimally in the case of multiple geological or
geoscientific hypotheses on the nature of spatial variability. Additionally,
the artificial intelligence is equipped with a method that allows detecting,
early on, whether the human stated hypotheses are incorrect, thereby saving
considerable expense in data acquisition. Our approach is tested on a
sediment-hosted copper deposit, and the algorithm presented has aided in the
characterization of an ultra high-grade deposit in Zambia in 2023.

æè¦ï¼å¨ä»éº¼å°è³ªç§å­¸è³æçåå¾ä¸é²è¡æä½³è²æ°æ±ºç­ï¼éè¦é³è¿°ä¸ååé©çä¸ç¢ºå®æ§æ¨¡åãè³æåå¾çæä½³åï¼æ¯ééæå¤§åä¸¦å¹³ååå°æåæèè¶£çå±¬æ§çä¸ç¢ºå®æ§ä¾é²è¡ãå¨æ¢åçèçµ¡ä¸­ï¼å¨è³æåå¾è¦åä¹åï¼å¾å°æè³æï¼ææçè³å®å¨æ²æè³æãå æ­¤ï¼åé©æ¨¡åéè¦åå«äººé¡å°æ¼ç©ºéè®ç°æ§çæ¬è³ªï¼æå°æ¼è¢«èªçºèæ­£å¨æ¢åååç¸éçé¡æ¯è³æçäººçºè©®éãä¾å¦ï¼å¨ç¤¦ç©æ¢åä¸­ï¼äººé¡å¯è½æä¾è³´æç¤¦æ¦å¿µæ¨¡åä¾å®ç¾©å¤éåè¨­ï¼æ¯ååè¨­é½ä»£è¡¨ç¤¦åçç¹å®ç©ºéè®ç°æ§ãå¨è³æåå¾å¾ï¼éå¸¸ææé³è¿°çåè¨­é½å¯è½è¢«è­ææ¯ä¸æ­£ç¢ºçï¼ä¹å°±æ¯è¢«è­å½çï¼å æ­¤åé©åè¨­éè¦è¢«ä¿®æ­£ï¼æç¢çé¡å¤çåè¨­ãå¨é¯èª¤çå°è³ªåé©ä¸è¦åè³æåå¾å¯è½ææ²ææçï¼å çºå°ç®æ¨å±¬æ§çä¼°è¨ä¸ç¢ºå®æ§æ¯ä¸æ­£ç¢ºçï¼å æ­¤ä¸ç¢ºå®æ§å¯è½å®å¨æ²ææ¸å°ãå¨æ¬æä¸­ï¼æåéç¼äºä¸ååºæ¼é¨åå¯è§å¯é¦¬å¯å¤«æ±ºç­éç¨çæºæ§ä»£çï¼å¨å°ç©ºéè®ç°æ§çæ¬è³ªæå¤éå°è³ªæå°è³ªç§å­¸åè¨­çææ³ä¸ï¼é²è¡æä½³è¦åãæ­¤å¤ï¼äººå·¥æºæ§éåäºä¸åæ¹æ³ï¼å¯ä»¥åæ©åµæ¸¬äººé¡é³è¿°çåè¨­æ¯å¦ä¸æ­£ç¢ºï¼å¾èç¯çå¤§éçè³æåå¾è²»ç¨ãæåçåæ³å¨ä¸åæ²ç©éç¤¦åºä¸­é²è¡æ¸¬è©¦ï¼èææåºçæ¼ç®æ³å·²ç¶åå©å¨ 2023 å¹´å°å°æ¯äºçä¸åè¶é«åä½ç¤¦åºé²è¡ç¹å¾µæè¿°ã

##### **BrainMVP: Multi-modal Vision Pre-training for Brain Image Analysis using Multi-parametric MRI**
2410.10604v1 by Shaohao Rui, Lingzhi Chen, Zhenyu Tang, Lilong Wang, Mianxin Liu, Shaoting Zhang, Xiaosong Wang

Accurate diagnosis of brain abnormalities is greatly enhanced by the
inclusion of complementary multi-parametric MRI imaging data. There is
significant potential to develop a universal pre-training model that can be
quickly adapted for image modalities and various clinical scenarios. However,
current models often rely on uni-modal image data, neglecting the cross-modal
correlations among different image modalities or struggling to scale up
pre-training in the presence of missing modality data. In this paper, we
propose BrainMVP, a multi-modal vision pre-training framework for brain image
analysis using multi-parametric MRI scans. First, we collect 16,022 brain MRI
scans (over 2.4 million images), encompassing eight MRI modalities sourced from
a diverse range of centers and devices. Then, a novel pre-training paradigm is
proposed for the multi-modal MRI data, addressing the issue of missing
modalities and achieving multi-modal information fusion. Cross-modal
reconstruction is explored to learn distinctive brain image embeddings and
efficient modality fusion capabilities. A modality-wise data distillation
module is proposed to extract the essence representation of each MR image
modality for both the pre-training and downstream application purposes.
Furthermore, we introduce a modality-aware contrastive learning module to
enhance the cross-modality association within a study. Extensive experiments on
downstream tasks demonstrate superior performance compared to state-of-the-art
pre-training methods in the medical domain, with Dice Score improvement of
0.28%-14.47% across six segmentation benchmarks and a consistent accuracy
improvement of 0.65%-18.07% in four individual classification tasks.

æè¦ï¼<paragraph>æºç¢ºè¨ºæ·è¦é¨ç°å¸¸æééå å¥äºè£çå¤åæ¸ MRI å½±åè³æèå¤§å¹æåãéç¼ä¸åéç¨é è¨ç·´æ¨¡åå·æç¸ç¶å¤§çæ½åï¼èæ­¤æ¨¡åå¯ä»¥å¿«éèª¿æ´ä»¥ç¬¦åå½±åå½¢å¼ååç¨®è¨åºå ´æ¯ãç¶èï¼ç®åçæ¨¡åéå¸¸ä»°è³´å®ä¸å½¢å¼çå½±åè³æï¼å¿½ç¥äºä¸åå½±åå½¢å¼ä¹éçè·¨å½¢å¼éè¯æ§ï¼ææ¯é£ä»¥å¨ç¼ºä¹å½¢å¼è³æçææ³ä¸æ´å±é è¨ç·´ãå¨æ¬æä¸­ï¼æåæåº BrainMVPï¼ä¸åç¨æ¼è¦é¨å½±ååæçå¤å½¢å¼è¦è¦ºé è¨ç·´æ¶æ§ï¼ä½¿ç¨å¤åæ¸ MRI ææãé¦åï¼æåæ¶éäº 16,022 åè¦é¨ MRI ææï¼è¶é 240 è¬å¼µå½±åï¼ï¼æ¶µèäºå«ç¨® MRI å½¢å¼ï¼éäºå½¢å¼ä¾èªæ¼åç¨®ä¸åçä¸­å¿åè£ç½®ãæ¥èï¼éå°å¤å½¢å¼ MRI è³ææåºäºä¸åæ°ç©çé è¨ç·´ç¯ä¾ï¼è§£æ±ºäºç¼ºä¹å½¢å¼çåé¡ï¼ä¸¦éå°äºå¤å½¢å¼è³è¨èåãæ¢ç´¢äºè·¨å½¢å¼éå»ºï¼ä»¥å­¸ç¿ç¨ç¹çè¦é¨å½±ååµå¥åææççå½¢å¼èåè½åãæåºäºä¸åå½¢å¼ææºçè³æèåæ¨¡çµï¼ç¨æ¼èåæ¯å MR å½±åå½¢å¼çæ¬è³ªè¡¨å¾µï¼ä»¥ç¬¦åé è¨ç·´åä¸æ¸¸æç¨ç®çãæ­¤å¤ï¼æåå¼å¥äºå½¢å¼æç¥å°æ¯å­¸ç¿æ¨¡çµï¼ä»¥å å¼·ç ç©¶ä¸­çè·¨å½¢å¼éè¯æ§ãéå°ä¸æ¸¸ä»»åé²è¡çå»£æ³å¯¦é©è­æäºèé«çé åä¸­ç¾ææåé²çé è¨ç·´æ¹æ³ç¸æ¯ï¼å¶å·æåªç°çæè½ï¼å¨å­ååå²åºæºä¸­éª°å­åæ¸æåäº 0.28%-14.47%ï¼å¨åååå¥åé¡ä»»åä¸­ç²¾ç¢ºåº¦ä¸è´æåäº 0.65%-18.07%ã</paragraph>

##### **Neural networks that overcome classic challenges through practice**
2410.10596v1 by Kazuki Irie, Brenden M. Lake

Since the earliest proposals for neural network models of the mind and brain,
critics have pointed out key weaknesses in these models compared to human
cognitive abilities. Here we review recent work that has used metalearning to
help overcome some of these challenges. We characterize their successes as
addressing an important developmental problem: they provide machines with an
incentive to improve X (where X represents the desired capability) and
opportunities to practice it, through explicit optimization for X; unlike
conventional approaches that hope for achieving X through generalization from
related but different objectives. We review applications of this principle to
four classic challenges: systematicity, catastrophic forgetting, few-shot
learning and multi-step reasoning; we also discuss related aspects of human
development in natural environments.

æè¦ï¼èªææ©æåºç¥ç»ç½ç»æ¨¡åå°å¿æºèå¤§è¦çæ¨¡åä»¥ä¾ï¼æ¹è©èå·²æåºéäºæ¨¡åèäººé¡èªç¥è½åç¸æ¯å­å¨ééµå¼±é»ãå¨æ­¤ï¼æååé¡§æè¿ä½¿ç¨åå­¸ç¿ä¾å¹«å©åæå¶ä¸­ä¸äºææ°çç ç©¶ãæåå°å¶æåæ­¸å æ¼è§£æ±ºä¸åéè¦çç¼å±åé¡ï¼å®åçºæ©å¨æä¾äºä¸åæ¹é² Xï¼å¶ä¸­ X ä»£è¡¨æéçæ©è½ï¼çèªå ï¼ä¸¦éééå° X çæç¢ºæä½³åä¾æä¾å¯¦è¸å®çæ©æï¼éèå³çµ±æ¹æ³ä¸åï¼å³çµ±æ¹æ³å¸æééå°ç¸éä½ä¸åçç®æ¨é²è¡æ¦åä¾éæ Xãæååé¡§äºéååçå¨ååç¶å¸ææ°ä¸­çæç¨ï¼ç³»çµ±æ§ãç½é£æ§éºå¿ãå°éå­¸ç¿åå¤æ­¥é©æ¨çï¼æåä¹è¨è«äºäººé¡å¨èªç¶ç°å¢ä¸­ç¼å±çç¸éé¢åã

##### **VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality Documents**
2410.10594v1 by Shi Yu, Chaoyue Tang, Bokai Xu, Junbo Cui, Junhao Ran, Yukun Yan, Zhenghao Liu, Shuo Wang, Xu Han, Zhiyuan Liu, Maosong Sun

Retrieval-augmented generation (RAG) is an effective technique that enables
large language models (LLMs) to utilize external knowledge sources for
generation. However, current RAG systems are solely based on text, rendering it
impossible to utilize vision information like layout and images that play
crucial roles in real-world multi-modality documents. In this paper, we
introduce VisRAG, which tackles this issue by establishing a vision-language
model (VLM)-based RAG pipeline. In this pipeline, instead of first parsing the
document to obtain text, the document is directly embedded using a VLM as an
image and then retrieved to enhance the generation of a VLM. Compared to
traditional text-based RAG, VisRAG maximizes the retention and utilization of
the data information in the original documents, eliminating the information
loss introduced during the parsing process. We collect both open-source and
synthetic data to train the retriever in VisRAG and explore a variety of
generation methods. Experiments demonstrate that VisRAG outperforms traditional
RAG in both the retrieval and generation stages, achieving a 25--39\%
end-to-end performance gain over traditional text-based RAG pipeline. Further
analysis reveals that VisRAG is effective in utilizing training data and
demonstrates strong generalization capability, positioning it as a promising
solution for RAG on multi-modality documents. Our code and data are available
at https://github.com/openbmb/visrag .

æè¦ï¼æª¢ç´¢å¢å¼·çæ (RAG) æ¯ä¸ç¨®æææè¡ï¼å¯è®å¤§åèªè¨æ¨¡å (LLM) å©ç¨å¤é¨ç¥è­ä¾æºé²è¡çæãç¶èï¼ç®åç RAG ç³»çµ±ååºæ¼æå­ï¼ç¡æ³å©ç¨ç¾å¯¦ä¸çå¤æ¨¡ææä»¶ä¸­ççé¢åååç­è¦è¦ºè³è¨ï¼èéäºè³è¨æ®æ¼èè³ééè¦çè§è²ãå¨æ¬æä¸­ï¼æåä»ç´¹äº VisRAGï¼å®ééå»ºç«ä¸ååºæ¼è¦è¦ºèªè¨æ¨¡å (VLM) ç RAG ç®¡ç·ä¾è§£æ±ºéååé¡ãå¨éåç®¡ç·ä¸­ï¼ä¸¦éåè§£ææä»¶ä»¥åå¾æå­ï¼èæ¯ç´æ¥ä½¿ç¨ VLM å°æä»¶åµå¥çºååï¼ç¶å¾æª¢ç´¢ä»¥å¢å¼· VLM ççæãèå³çµ±çåºæ¼æå­ç RAG ç¸æ¯ï¼VisRAG æå¤§åä¿çåå©ç¨åå§æä»¶ä¸­çè³æè³è¨ï¼æ¶é¤äºè§£æéç¨ä¸­ç¢ççè³è¨éºå¤±ãæåæ¶éäºéæºè³æååæè³æä¾è¨ç·´ VisRAG ä¸­çæª¢ç´¢å¨ï¼ä¸¦æ¢ç´¢äºåç¨®çææ¹æ³ãå¯¦é©è­æï¼VisRAG å¨æª¢ç´¢åçæéæ®µé½åªæ¼å³çµ±ç RAGï¼å¨å³çµ±çåºæ¼æå­ç RAG ç®¡ç·ä¸­ï¼ç«¯å°ç«¯æè½æåäº 25--39%ãé²ä¸æ­¥çåæé¡¯ç¤ºï¼VisRAG è½ææå©ç¨è¨ç·´è³æï¼ä¸¦å±ç¾åºå¼·å¤§çæ³åè½åï¼ä½¿å¶æçºå¤æ¨¡ææä»¶ä¸­ RAG çä¸åæåéçè§£æ±ºæ¹æ¡ãæåçç¨å¼ç¢¼åè³æå¯å¨ https://github.com/openbmb/visrag åå¾ã

##### **TRESTLE: A Model of Concept Formation in Structured Domains**
2410.10588v1 by Christopher J. MacLellan, Erik Harpstead, Vincent Aleven, Kenneth R. Koedinger

The literature on concept formation has demonstrated that humans are capable
of learning concepts incrementally, with a variety of attribute types, and in
both supervised and unsupervised settings. Many models of concept formation
focus on a subset of these characteristics, but none account for all of them.
In this paper, we present TRESTLE, an incremental account of probabilistic
concept formation in structured domains that unifies prior concept learning
models. TRESTLE works by creating a hierarchical categorization tree that can
be used to predict missing attribute values and cluster sets of examples into
conceptually meaningful groups. It updates its knowledge by partially matching
novel structures and sorting them into its categorization tree. Finally, the
system supports mixed-data representations, including nominal, numeric,
relational, and component attributes. We evaluate TRESTLE's performance on a
supervised learning task and an unsupervised clustering task. For both tasks,
we compare it to a nonincremental model and to human participants. We find that
this new categorization model is competitive with the nonincremental approach
and more closely approximates human behavior on both tasks. These results serve
as an initial demonstration of TRESTLE's capabilities and show that, by taking
key characteristics of human learning into account, it can better model
behavior than approaches that ignore them.

æè¦ï¼æ¦å¿µå½¢æçæç»å·²è­æï¼äººé¡æè½åéæ­¥å­¸ç¿æ¦å¿µï¼ä½¿ç¨åç¨®å±¬æ§é¡åï¼ä¸¦å¨æç£ç£åç¡ç£ç£çç°å¢ä¸­å­¸ç¿ãè¨±å¤æ¦å¿µå½¢ææ¨¡åå´éæ¼éäºç¹å¾µçå­éï¼ä½æ²æä»»ä½æ¨¡åè½è§£éææéäºç¹å¾µãå¨æ¬æä¸­ï¼æåæåºäº TRESTLEï¼éæ¯ä¸åå¨çµæ§åé åä¸­éæ­¥å½¢ææ¦çæ¦å¿µçèªªæï¼å®çµ±ä¸äºååçæ¦å¿µå­¸ç¿æ¨¡åãTRESTLE ééåµå»ºä¸ååå±¤åé¡æ¨¹ä¾å·¥ä½ï¼è©²æ¨¹å¯ç¨æ¼é æ¸¬ç¼ºå¤±çå±¬æ§å¼åå°ç¤ºä¾éèåå°æ¦å¿µä¸ææç¾©ççµä¸­ãå®ééé¨åå¹éæ°çµæ§ä¸¦å°å®ååé¡å°å¶åé¡æ¨¹ä¸­ä¾æ´æ°å¶ç¥è­ãæå¾ï¼è©²ç³»çµ±æ¯ææ··åæ¸æè¡¨ç¤ºï¼åæ¬æ¨ç¨±ãæ¸å­ãéä¿åçµæå±¬æ§ãæåè©ä¼°äº TRESTLE å¨æç£ç£å­¸ç¿ä»»ååç¡ç£ç£èé¡ä»»åä¸çæ§è½ãå°æ¼éå©åä»»åï¼æåå°å¶èéå¢éæ¨¡ååäººé¡åèèé²è¡äºæ¯è¼ãæåç¼ç¾ï¼éç¨®æ°çåé¡æ¨¡åèéå¢éæ¹æ³å·æç«¶ç­åï¼ä¸¦ä¸å¨å©åä»»åä¸é½æ´æ¥è¿äººé¡è¡çºãéäºçµæåæ­¥è­æäº TRESTLE çè½åï¼ä¸¦è¡¨æï¼ééèæ®äººé¡å­¸ç¿çä¸»è¦ç¹å¾µï¼å®å¯ä»¥æ¯å¿½ç¥éäºç¹å¾µçæ¹æ³æ´å¥½å°å»ºæ¨¡è¡çºã

##### **TÃ¼bingen-CL at SemEval-2024 Task 1:Ensemble Learning for Semantic Relatedness Estimation**
2410.10585v1 by Leixin Zhang, ÃaÄrÄ± ÃÃ¶ltekin

The paper introduces our system for SemEval-2024 Task 1, which aims to
predict the relatedness of sentence pairs. Operating under the hypothesis that
semantic relatedness is a broader concept that extends beyond mere similarity
of sentences, our approach seeks to identify useful features for relatedness
estimation. We employ an ensemble approach integrating various systems,
including statistical textual features and outputs of deep learning models to
predict relatedness scores. The findings suggest that semantic relatedness can
be inferred from various sources and ensemble models outperform many individual
systems in estimating semantic relatedness.

æè¦ï¼æ¬æä»ç´¹äºæåç SemEval-2024 ä»»å 1 ç³»çµ±ï¼å¶ç®æ¨æ¯é æ¸¬å¥å­å°çç¸éæ§ãå¨èªç¾©ç¸éæ§æ¯ä¸åè¶è¶å¥å­ç¸ä¼¼æ§çæ´å»£æ³æ¦å¿µçåè¨­ä¸ï¼æåçåæ³è©¦åæ¾åºç¸éæ§ä¼°è¨çæç¨ç¹å¾µãæåæ¡ç¨æ´ååç¨®ç³»çµ±çæ´é«æ¹æ³ï¼åæ¬çµ±è¨ææ¬ç¹å¾µåæ·±åº¦å­¸ç¿æ¨¡åçè¼¸åºï¼ä¾é æ¸¬ç¸éæ§åæ¸ãç ç©¶çµæè¡¨æï¼èªç¾©ç¸éæ§å¯ä»¥å¾åç¨®ä¾æºæ¨è«åºä¾ï¼èæ´é«æ¨¡åå¨ä¼°è¨èªç¾©ç¸éæ§æ¹é¢åªæ¼è¨±å¤åå¥ç³»çµ±ã

##### **STACKFEED: Structured Textual Actor-Critic Knowledge Base Editing with FeedBack**
2410.10584v1 by Naman Gupta, Shashank Kirtania, Priyanshu Gupta, Krishna Kariya, Sumit Gulwani, Arun Iyer, Suresh Parthasarathy, Arjun Radhakrishna, Sriram K. Rajamani, Gustavo Soares

Large Language Models (LLMs) often generate incorrect or outdated
information, especially in low-resource settings or when dealing with private
data. To address this, Retrieval-Augmented Generation (RAG) uses external
knowledge bases (KBs), but these can also suffer from inaccuracies. We
introduce STACKFEED, a novel Structured Textual Actor-Critic Knowledge base
editing with FEEDback approach that iteratively refines the KB based on expert
feedback using a multi-actor, centralized critic reinforcement learning
framework. Each document is assigned to an actor, modeled as a ReACT agent,
which performs structured edits based on document-specific targeted
instructions from a centralized critic. Experimental results show that
STACKFEED significantly improves KB quality and RAG system performance,
enhancing accuracy by up to 8% over baselines.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ç¶å¸¸æç¢çä¸æ­£ç¢ºæéæçè³è¨ï¼å°¤å¶æ¯å¨è³æºä¸è¶³çç°å¢ä¸­æèçç§äººè³ææãçºäºè§£æ±ºéååé¡ï¼æª¢ç´¢å¢å¼·ç¢ç (RAG) ä½¿ç¨å¤é¨ç¥è­åº« (KB)ï¼ä½éäºç¥è­åº«ä¹å¯è½ä¸æºç¢ºãæåå¼é² STACKFEEDï¼éæ¯ä¸ç¨®æ°ç©ççµæ§åææ¬ Actor-Critic ç¥è­åº«ç·¨è¼¯æ¹æ³ï¼ä½¿ç¨åé¥ï¼æ ¹æå°å®¶çåé¥ï¼ä½¿ç¨å¤ Actorãéä¸­å¼è©è«å¼·åå­¸ç¿æ¶æ§ï¼åè¦æ¹å KBãæ¯ä»½æä»¶æåéçµ¦ä¸å Actorï¼å»ºæ¨¡çº ReACT ä»£çï¼å®ææ ¹æéä¸­å¼è©è«çç¹å®ç®æ¨æä»¶æä»¤ï¼å·è¡çµæ§åçç·¨è¼¯ãå¯¦é©çµæé¡¯ç¤ºï¼STACKFEED å¤§å¹æ¹å KB åè³ªå RAG ç³»çµ±æè½ï¼æºç¢ºåº¦æ¯åºæºé«åº 8%ã

##### **Multilingual Controlled Generation And Gold-Standard-Agnostic Evaluation of Code-Mixed Sentences**
2410.10580v1 by Ayushman Gupta, Akhil Bhogal, Kripabandhu Ghosh

Code-mixing, the practice of alternating between two or more languages in an
utterance, is a common phenomenon in multilingual communities. Due to the
colloquial nature of code-mixing, there is no singular correct way to translate
an English sentence into a code-mixed sentence. For this reason, standard
n-gram-based MT evaluation metrics such as the BLEU score are not appropriate
for code-mixed evaluation. To demonstrate this, we propose a novel method for
code-mixed text generation: Controlled Generation, which parameterizes the
code-mixing degree (CMD) and enables the generation of multiple semantically
equivalent code-mixed sentences from a given English sentence. We introduce a
robust new evaluation metric: GAME: A Gold-Standard Agnostic Measure for
Evaluation of Code-Mixed Sentences. GAME is both language-agnostic and
gold-standard-agnostic, i.e. unlike other metrics, GAME does not require
gold-standard code-mixed sentences for evaluation, thus eliminating the need
for human annotators in the code-mixed evaluation process. When used to
evaluate semantically equivalent code-mixed sentences, we find that GAME scores
have a lower standard deviation than BLEU scores. Further, we create and
release a dataset containing gold-standard code-mixed sentences across 4
language pairs: English-{Hindi, Bengali, French, Spanish} to encourage more
computational research on code-mixing.

æè¦ï¼<paragraph>å¨å¤èªç³»ç¤¾ç¾¤ä¸­ï¼ä»£ç¢¼æ··åæ¯ä¸ç¨®å¸¸è¦ç¾è±¡ï¼ææå¨è¨èªè¡¨éä¸­äº¤æ¿ä½¿ç¨å©ç¨®æå¤ç¨®èªè¨ãç±æ¼ä»£ç¢¼æ··åçå£èªæ¬è³ªï¼ä¸¦æ²æä¸ç¨®æ­£ç¢ºçæ¹æ³å¯ä»¥å°è±æå¥å­ç¿»è­¯æä»£ç¢¼æ··åå¥å­ãå æ­¤ï¼æ¨æºç n-gram åºæ¼ MT è©ä¼°ææ¨ï¼ä¾å¦ BLEU åæ¸ï¼ä¸¦ä¸é©ç¨æ¼ä»£ç¢¼æ··åè©ä¼°ãçºäºè­æéä¸é»ï¼æåæåºäºä¸ç¨®æ°çä»£ç¢¼æ··åææ¬çææ¹æ³ï¼åæ§çæï¼å®åæ¸åäºä»£ç¢¼æ··åç¨åº¦ (CMD)ï¼ä¸¦è½å¤ å¾çµ¦å®çè±æå¥å­çæå¤åèªç¾©ç­å¹çä»£ç¢¼æ··åå¥å­ãæåå¼å¥äºä¸åå¼·å¤§çæ°è©ä¼°ææ¨ï¼GAMEï¼ä¸ç¨®ç¨æ¼è©ä¼°ä»£ç¢¼æ··åå¥å­çéæ¨æºä¸å¯ç¥åº¦éãGAME æ¢èèªè¨ç¡éï¼ä¹èéæ¨æºç¡éï¼äº¦å³èå¶ä»ææ¨ä¸åï¼GAME å¨è©ä¼°æä¸éè¦éæ¨æºä»£ç¢¼æ··åå¥å­ï¼å¾èæ¶é¤äºä»£ç¢¼æ··åè©ä¼°éç¨ä¸­å°äººå·¥è¨»è§£èçéæ±ãç¶ç¨æ¼è©ä¼°èªç¾©ç­å¹çä»£ç¢¼æ··åå¥å­æï¼æåç¼ç¾ GAME åæ¸çæ¨æºå·®ä½æ¼ BLEU åæ¸ãæ­¤å¤ï¼æååµå»ºä¸¦ç¼å¸äºä¸ååå« 4 ç¨®èªè¨å°çéæ¨æºä»£ç¢¼æ··åå¥å­çè³æéï¼è±èª-{å°å°èªãå­å æèªãæ³èªãè¥¿ç­çèª}ï¼ä»¥é¼åµæ´å¤éæ¼ä»£ç¢¼æ··åçè¨ç®ç ç©¶ã</paragraph>

##### **Recipe for Zero-shot POS Tagging: Is It Useful in Realistic Scenarios?**
2410.10576v1 by Zeno Vandenbulcke, Lukas Vermeire, Miryam de Lhoneux

POS tagging plays a fundamental role in numerous applications. While POS
taggers are highly accurate in well-resourced settings, they lag behind in
cases of limited or missing training data. This paper focuses on POS tagging
for languages with limited data. We seek to identify the characteristics of
datasets that make them favourable for training POS tagging models without
using any labelled training data from the target language. This is a zero-shot
approach. We compare the accuracies of a multilingual large language model
(mBERT) fine-tuned on one or more languages related to the target language.
Additionally, we compare these results with models trained directly on the
target language itself. We do this for three target low-resource languages. Our
research highlights the importance of accurate dataset selection for effective
zero-shot POS tagging. Particularly, a strong linguistic relationship and
high-quality datasets ensure optimal results. For extremely low-resource
languages, zero-shot models prove to be a viable option.

æè¦ï¼è©æ§æ¨è¨»å¨è¨±å¤æç¨ç¨å¼ä¸­æ®æ¼èåºæ¬çè§è²ãéç¶è©æ§æ¨è¨»å¨å¨è³æºåè¶³çç°å¢ä¸­éå¸¸ç²¾ç¢ºï¼ä½å®åå¨è¨ç·´è³ææéæéºå¤±çææ³ä¸å»è½å¾æ¼å¶ä»æ¹æ³ãæ¬æå°æ³¨æ¼è³ææéçèªè¨çè©æ§æ¨è¨»ãæåè©¦åæ¾åºè³æéçç¹æ§ï¼ä½¿å¶æå©æ¼è¨ç·´è©æ§æ¨è¨»æ¨¡åï¼èç¡éä½¿ç¨ç®æ¨èªè¨çä»»ä½æ¨ç±¤è¨ç·´è³æãéæ¯ä¸ç¨®é¶æ¬¡å­¸ç¿æ¹æ³ãæåæ¯è¼äºéå°èç®æ¨èªè¨ç¸éçä¸ç¨®æå¤ç¨®èªè¨é²è¡å¾®èª¿çå¤èªè¨å¤§åèªè¨æ¨¡å (mBERT) çæºç¢ºåº¦ãæ­¤å¤ï¼æåå°éäºçµæèç´æ¥éå°ç®æ¨èªè¨æ¬èº«è¨ç·´çæ¨¡åé²è¡æ¯è¼ãæåéå°ä¸ç¨®ç®æ¨ä½è³æºèªè¨å·è¡æ­¤æä½ãæåçç ç©¶å¼·èª¿äºæºç¢ºçè³æéé¸æå°æ¼ææçé¶æ¬¡å­¸ç¿è©æ§æ¨è¨»çéè¦æ§ãç¹å¥æ¯ï¼å¼·æåçèªè¨éä¿åé«åè³ªçè³æéå¯ç¢ºä¿æä½³çµæãå°æ¼æ¥µåº¦ä½è³æºçèªè¨ï¼é¶æ¬¡å­¸ç¿æ¨¡åè¢«è­ææ¯ä¸åå¯è¡çé¸é ã

##### **When Precedents Clash**
2410.10567v1 by Cecilia Di Florio, Huimin Dong, Antonino Rotolo

Consistency of case bases is a way to avoid the problem of retrieving
conflicting constraining precedents for new cases to be decided. However, in
legal practice the consistency requirements for case bases may not be
satisfied. As pointed out in (Broughton 2019), a model of precedential
constraint should take into account the hierarchical structure of the specific
legal system under consideration and the temporal dimension of cases. This
article continues the research initiated in (Liu et al. 2022; Di Florio et al.
2023), which established a connection between Boolean classifiers and legal
case-based reasoning. On this basis, we enrich the classifier models with an
organisational structure that takes into account both the hierarchy of courts
and which courts issue decisions that are binding/constraining on subsequent
cases. We focus on common law systems. We also introduce a temporal relation
between cases. Within this enriched framework, we can formalise the notions of
overruled cases and cases decided per incuriam: such cases are not to be
considered binding on later cases. Finally, we show under which condition
principles based on the hierarchical structure and on the temporal dimension
can provide an unambiguous decision-making process for new cases in the
presence of conflicting binding precedents.

æè¦ï¼æ¡ä¾åºçä¸è´æ§æ¯ä¸ç§é¿åä¸ºå¾å³æ°æ¡ä¾æ£ç´¢å°ç¸äºå²çªççº¦ææ§åä¾çé®é¢çæ¹æ³ãç¶èï¼å¨æ³å¾å®è·µä¸­ï¼æ¡ä¾åºçä¸è´æ§è¦æ±å¯è½æ æ³å¾å°æ»¡è¶³ãæ­£å¦ï¼Broughton 2019ï¼ä¸­æåºçï¼åä¾çº¦ææ¨¡ååºèèæèèçç¹å®æ³å¾ä½ç³»çå±æ¬¡ç»æåæ¡ä¾çæ¶é´ç»´åº¦ãæ¬æç»§ç»­äºï¼Liu et al. 2022ï¼Di Florio et al. 2023ï¼ä¸­å¯å¨çç ç©¶ï¼è¯¥ç ç©¶å»ºç«äºå¸å°åç±»å¨ååºäºæ³å¾æ¡ä¾çæ¨çä¹é´çèç³»ãå¨æ­¤åºç¡ä¸ï¼æä»¬éè¿ç»ç»ç»æä¸°å¯äºåç±»å¨æ¨¡åï¼è¯¥ç»ç»ç»æåæ¶èèäºæ³é¢çç­çº§å¶åº¦ä»¥ååªäºæ³é¢åå¸å¯¹åç»­æ¡ä»¶å·æçº¦æåçå¤å³ãæä»¬ä¸æ³¨äºæ®éæ³ä½ç³»ãæä»¬è¿å¼å¥äºæ¡ä»¶ä¹é´çæ¶é´å³ç³»ãå¨è¿ä¸ªä¸°å¯çæ¡æ¶åï¼æä»¬å¯ä»¥å°è¢«æ¨ç¿»çæ¡ä»¶åæ ¹æ®è¿å¤±ä½åºçå¤å³æ¡ä»¶çæ¦å¿µå½¢å¼åï¼æ­¤ç±»æ¡ä»¶ä¸åºè¢«è§ä¸ºå¯¹åæ¥çæ¡ä»¶å·æçº¦æåãæåï¼æä»¬å±ç¤ºäºå¨å­å¨ç¸äºå²çªççº¦ææ§åä¾çæåµä¸ï¼åºäºå±æ¬¡ç»æåæ¶é´ç»´åº¦çååå¯ä»¥å¨ä½ç§æ¡ä»¶ä¸ä¸ºæ°æ¡ä»¶æä¾æç¡®çå³ç­è¿ç¨ã

##### **Is Structure Dependence Shaped for Efficient Communication?: A Case Study on Coordination**
2410.10556v1 by Kohei Kajikawa, Yusuke Kubota, Yohei Oseki

Natural language exhibits various universal properties. But why do these
universals exist? One explanation is that they arise from functional pressures
to achieve efficient communication, a view which attributes cross-linguistic
properties to domain-general cognitive abilities. This hypothesis has
successfully addressed some syntactic universal properties such as
compositionality and Greenbergian word order universals. However, more abstract
syntactic universals have not been explored from the perspective of efficient
communication. Among such universals, the most notable one is structure
dependence, that is, the existence of grammar-internal operations that
crucially depend on hierarchical representations. This property has
traditionally been taken to be central to natural language and to involve
domain-specific knowledge irreducible to communicative efficiency.
  In this paper, we challenge the conventional view by investigating whether
structure dependence realizes efficient communication, focusing on coordinate
structures. We design three types of artificial languages: (i) one with a
structure-dependent reduction operation, which is similar to natural language,
(ii) one without any reduction operations, and (iii) one with a linear (rather
than structure-dependent) reduction operation. We quantify the communicative
efficiency of these languages. The results demonstrate that the language with
the structure-dependent reduction operation is significantly more
communicatively efficient than the counterfactual languages. This suggests that
the existence of structure-dependent properties can be explained from the
perspective of efficient communication.

æè¦ï¼èªç¶èªè¨å±ç¾åºåç¨®æ®éç¹æ§ãä½çºä½éäºæ®éæ§å­å¨ï¼ä¸ç¨®è§£éæ¯å®åä¾èªæ¼å¯¦ç¾æææºéçåè½å£åï¼ä¸ç¨®å°è·¨èªè¨ç¹æ§æ­¸å æ¼é åéç¨çèªç¥è½åçè§é»ãéååè¨­å·²æåå°èçäºä¸äºå¥æ³æ®éç¹æ§ï¼ä¾å¦çµåæ§åæ ¼æä¼¯æ ¼å¼è©åºæ®éæ§ãç¶èï¼æ´æ½è±¡çå¥æ³æ®éæ§å°æªå¾æææºéçè§åº¦å ä»¥æ¢è¨ãå¨éäºæ®éæ§ä¸­ï¼æé¡¯èçä¸åæ¯çµæ§ä¾è³´æ§ï¼ä¹å°±æ¯ææ³å§é¨éç®çå­å¨ï¼å¶ééµå¨æ¼éå±¤å¼è¡¨å¾µãéåç¹æ§å³çµ±ä¸è¢«èªçºæ¯èªç¶èªè¨çä¸­å¿ï¼ä¸¦æ¶åç¡æ³ç°¡åçºæºéæççé åç¹å®ç¥è­ã
  å¨æ¬æä¸­ï¼æåééæ¢è¨çµæ§ä¾è³´æ§æ¯å¦å¯¦ç¾æææºéä¾ææ°å³çµ±è§é»ï¼éé»å¨æ¼ä¸¦åçµæ§ãæåè¨­è¨äºä¸ç¨®é¡åçèªè¨ï¼(i) ä¸ç¨®å·çµæ§ä¾è³´æ§ç°¡åéç®çèªè¨ï¼é¡ä¼¼æ¼èªç¶èªè¨ï¼(ii) ä¸ç¨®æ²æä»»ä½ç°¡åéç®çèªè¨ï¼ä»¥å (iii) ä¸ç¨®å·æç·æ§ï¼èéçµæ§ä¾è³´æ§ï¼ç°¡åéç®çèªè¨ãæåéåéäºèªè¨çæºéæçãçµæè¡¨æï¼å·æçµæ§ä¾è³´æ§ç°¡åéç®çèªè¨é¡¯èåªæ¼åäºå¯¦èªè¨çæºéæçãéè¡¨æçµæ§ä¾è³´æ§ç¹æ§çå­å¨å¯ä»¥å¾æææºéçè§åº¦ä¾è§£éã

##### **ROSAR: An Adversarial Re-Training Framework for Robust Side-Scan Sonar Object Detection**
2410.10554v1 by Martin Aubard, LÃ¡szlÃ³ Antal, Ana Madureira, Luis F. Teixeira, Erika ÃbrahÃ¡m

This paper introduces ROSAR, a novel framework enhancing the robustness of
deep learning object detection models tailored for side-scan sonar (SSS)
images, generated by autonomous underwater vehicles using sonar sensors. By
extending our prior work on knowledge distillation (KD), this framework
integrates KD with adversarial retraining to address the dual challenges of
model efficiency and robustness against SSS noises. We introduce three novel,
publicly available SSS datasets, capturing different sonar setups and noise
conditions. We propose and formalize two SSS safety properties and utilize them
to generate adversarial datasets for retraining. Through a comparative analysis
of projected gradient descent (PGD) and patch-based adversarial attacks, ROSAR
demonstrates significant improvements in model robustness and detection
accuracy under SSS-specific conditions, enhancing the model's robustness by up
to 1.85%. ROSAR is available at
https://github.com/remaro-network/ROSAR-framework.

æè¦ï¼æ¬è«æä»ç´¹ ROSARï¼ä¸åæ°ç©çæ¡æ¶ï¼ç¨æ¼å¢å¼·æ·±åº¦å­¸ç¿ç©ä»¶åµæ¸¬æ¨¡åçç©©å¥æ§ï¼è©²æ¨¡åå°çºå´æè²ç´ (SSS) å½±åéèº«æé ï¼ç±ä½¿ç¨è²ç´ææ¸¬å¨çèªä¸»æ°´ä¸è¼å·ç¢çãééå»¶ä¼¸æåååå¨ç¥è­èå (KD) ä¸çå·¥ä½ï¼æ­¤æ¡æ¶å° KD èå°ææ§åè¨ç·´æ´åï¼ä»¥è§£æ±ºæ¨¡åæçåå°æ SSS éè¨çç©©å¥æ§éå©é ææ°ãæåä»ç´¹äºä¸åæ°ç©ãå¬éå¯ç¨ç SSS è³æéï¼æ·åä¸åçè²ç´è¨­å®åéè¨æ¢ä»¶ãæåæåºä¸¦å½¢å¼åå©å SSS å®å¨å±¬æ§ï¼ä¸¦å©ç¨å®åä¾ç¢çç¨æ¼åè¨ç·´çå°ææ§è³æéãééå°æå½±æ¢¯åº¦ä¸é (PGD) ååºæ¼ä¿®è£çå°ææ§æ»æé²è¡æ¯è¼åæï¼ROSAR å¨ SSS ç¹å®æ¢ä»¶ä¸é¡¯èæåäºæ¨¡åçç©©å¥æ§ååµæ¸¬æºç¢ºåº¦ï¼å°æ¨¡åçç©©å¥æ§æåäº 1.85%ãROSAR å¯å¨ https://github.com/remaro-network/ROSAR-framework åå¾ã

##### **SLaNC: Static LayerNorm Calibration**
2410.10553v1 by Mahsa Salmani, Nikita Trukhanov, Ilya Soloveychik

The ever increasing sizes of Large Language Models (LLMs) beyond hundreds of
billions of parameters have generated enormous pressure on the manufacturers of
dedicated hardware accelerators and made the innovative design of the latter
one of the most rapidly expanding fields of the AI industry. Various approaches
have been explored to enable efficient and accurate processing of LLMs on the
available accelerators given their computational and storage limitations. Among
these, various quantization techniques have become the main focus of the
community as a means of reducing the compute, communication and storage
requirements. Quantization to lower precision formats naturally poses a number
of challenges caused by the limited range of the available value
representations. When it comes to processing the popular Transformer models on
hardware, one of the main issues becomes calculation of the LayerNorm simply
because accumulation of the variance requires a much wider dynamic range than
the hardware enables. In this article, we address this matter and propose a
computationally-efficient scaling technique that can be easily applied to
Transformer models during inference. Our method suggests a straightforward way
of scaling the LayerNorm inputs based on the static weights of the immediately
preceding linear layers. The scaling factors are computed offline, based solely
on the linear layer weights, hence no latency or computational overhead is
added during inference. Most importantly, our technique ensures that no
numerical issues such as overflow or underflow could happen during the compute.
This approach offers smooth, accurate and resource-effective inference across a
wide range of hardware architectures. The article provides theoretical
justification as well as supporting numerical simulations.

æè¦ï¼<paragraph>å¤§åèªè¨æ¨¡å (LLM) çè¦æ¨¡ä¸æ·å¢å ï¼å·²è¶éæ¸ååååæ¸ï¼å°å°ç¨ç¡¬é«å éå¨çè£½é åé æå·¨å¤§å£åï¼ä¸¦ä½¿å¾èçåµæ°è¨­è¨æçº AI ç¢æ¥­ç¼å±æè¿éçé åä¹ä¸ãçºäºå¨è¨ç®åå²å­éå¶ä¸ï¼å¨ç¾æçå éå¨ä¸è½ææä¸æºç¢ºå°èç LLMï¼å·²æ¢è¨åç¨®æ¹æ³ãå¶ä¸­ï¼åç¨®éåæè¡å·²æçºç¤¾ç¾¤éæ³¨çéé»ï¼ä½çºéä½éç®ãéè¨åå²å­éæ±çæ¹æ³ãéåçºè¼ä½ç²¾åº¦çæ ¼å¼èªç¶æç¢çè¨±å¤ææ°ï¼åå æ¯å¯ç¨å¼è¡¨ç¤ºçç¯åæéãå¨ç¡¬é«ä¸èçæµè¡ç Transformer æ¨¡åæï¼ä¸»è¦åé¡ä¹ä¸å¨æ¼ LayerNorm çè¨ç®ï¼åå æ¯ç´¯ç©è®ç°éè¦æ¯ç¡¬é«æ¯æ´çåæç¯åæ´å»£ãå¨æ¬æä¸­ï¼æåæ¢è¨æ­¤åé¡ï¼ä¸¦æåºä¸åè¨ç®æçé«çç¸®æ¾æè¡ï¼å¯è¼é¬æç¨æ¼æ¨çæéç Transformer æ¨¡åãæåçå»ºè­°æ¹æ³æ¯æ ¹æç·æ¥å¨å¾çç·æ§å±¤çéææ¬éï¼ç¸®æ¾ LayerNorm è¼¸å¥ãç¸®æ¾å å­æ¯æ ¹æç·æ§å±¤æ¬éé¢ç·è¨ç®çï¼å æ­¤å¨æ¨çæéä¸æå¢å å»¶é²æè¨ç®è² æãæéè¦çæ¯ï¼æåçæè¡å¯ç¢ºä¿å¨è¨ç®æéä¸æç¼çæº¢ä½æä¸æº¢ç­æ¸å¼åé¡ãæ­¤æ¹æ³å¯å¨åç¨®ç¡¬é«æ¶æ§ä¸­æä¾æµæ¢ãæºç¢ºä¸è³æºææçæ¨çãæ¬ææä¾äºçè«ä¾æä»¥åæ¯æ´æ¸å¼æ¨¡æ¬ã</paragraph>

##### **Hybrid Transformer for Early Alzheimer's Detection: Integration of Handwriting-Based 2D Images and 1D Signal Features**
2410.10547v1 by Changqing Gong, Huafeng Qin, MounÃ®m A. El-Yacoubi

Alzheimer's Disease (AD) is a prevalent neurodegenerative condition where
early detection is vital. Handwriting, often affected early in AD, offers a
non-invasive and cost-effective way to capture subtle motor changes.
State-of-the-art research on handwriting, mostly online, based AD detection has
predominantly relied on manually extracted features, fed as input to shallow
machine learning models. Some recent works have proposed deep learning
(DL)-based models, either 1D-CNN or 2D-CNN architectures, with performance
comparing favorably to handcrafted schemes. These approaches, however, overlook
the intrinsic relationship between the 2D spatial patterns of handwriting
strokes and their 1D dynamic characteristics, thus limiting their capacity to
capture the multimodal nature of handwriting data. Moreover, the application of
Transformer models remains basically unexplored. To address these limitations,
we propose a novel approach for AD detection, consisting of a learnable
multimodal hybrid attention model that integrates simultaneously 2D handwriting
images with 1D dynamic handwriting signals. Our model leverages a gated
mechanism to combine similarity and difference attention, blending the two
modalities and learning robust features by incorporating information at
different scales. Our model achieved state-of-the-art performance on the DARWIN
dataset, with an F1-score of 90.32\% and accuracy of 90.91\% in Task 8 ('L'
writing), surpassing the previous best by 4.61% and 6.06% respectively.

æè¦ï¼é¿è²æµ·é»ç (AD) æ¯ä¸ç¨®æ®éçç¥ç¶éåæ§ç¾çï¼æ©æç¼ç¾è³ééè¦ãæå¯«å­éå¸¸å¨ AD æ©æåå°å½±é¿ï¼æä¾ä¸ç¨®éä¾µå¥ä¸å·ææ¬æççæ¹å¼ä¾ææç´°å¾®çåä½è®åãæåé²çæå¯«å­ç ç©¶ï¼å¤§å¤æ¸å¨ç·ä¸ï¼åºæ¼ AD åµæ¸¬ä¸»è¦ä¾è³´æåæåçç¹å¾µï¼ä½çºæ·ºå±¤æ©å¨å­¸ç¿æ¨¡åçè¼¸å¥ãä¸äºæè¿çç ç©¶æåºäºåºæ¼æ·±åº¦å­¸ç¿ (DL) çæ¨¡åï¼åæ¬ 1D-CNN æ 2D-CNN æ¶æ§ï¼å¶æè½èæå·¥è£½ä½çæ¹æ¡ç¸æ¯ç¸ç¶æå©ãç¶èï¼éäºæ¹æ³å¿½ç¥äºæå¯«å­ç­è§¸ç 2D ç©ºéæ¨¡å¼èå¶ 1D åæç¹å¾µä¹éçå§å¨éä¿ï¼å æ­¤éå¶äºå¶æææå¯«å­è³æå¤æ¨¡æç¹æ§çè½åãæ­¤å¤ï¼è®å½¢éåæ¨¡åçæç¨åºæ¬ä¸ä»æªæ¢ç´¢ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäºä¸ç¨®æ°ç AD åµæ¸¬æ¹æ³ï¼åæ¬ä¸åå¯å­¸ç¿çå¤æ¨¡ææ··åæ³¨æåæ¨¡åï¼åææ´å 2D æå¯«å­å½±åè 1D åææå¯«å­è¨èãæåçæ¨¡åå©ç¨éæ§æ©å¶çµåç¸ä¼¼æ§åå·®ç°æ§æ³¨æåï¼æ··åéå©ç¨®æ¨¡æä¸¦ééç´å¥ä¸åè¦æ¨¡çè³è¨ä¾å­¸ç¿ç©©å¥çç¹å¾µãæåçæ¨¡åå¨ DARWIN è³æéä¸éå°äºæåé²çæè½ï¼å¨ä»»å 8ï¼ãLãæ¸å¯«ï¼ä¸­ F1 åæ¸çº 90.32%ï¼æºç¢ºççº 90.91%ï¼åå¥æ¯åä¸åæä½³çµæé«åº 4.61% å 6.06%ã

##### **Rethinking Legal Judgement Prediction in a Realistic Scenario in the Era of Large Language Models**
2410.10542v1 by Shubham Kumar Nigam, Aniket Deroy, Subhankar Maity, Arnab Bhattacharya

This study investigates judgment prediction in a realistic scenario within
the context of Indian judgments, utilizing a range of transformer-based models,
including InLegalBERT, BERT, and XLNet, alongside LLMs such as Llama-2 and
GPT-3.5 Turbo. In this realistic scenario, we simulate how judgments are
predicted at the point when a case is presented for a decision in court, using
only the information available at that time, such as the facts of the case,
statutes, precedents, and arguments. This approach mimics real-world
conditions, where decisions must be made without the benefit of hindsight,
unlike retrospective analyses often found in previous studies. For transformer
models, we experiment with hierarchical transformers and the summarization of
judgment facts to optimize input for these models. Our experiments with LLMs
reveal that GPT-3.5 Turbo excels in realistic scenarios, demonstrating robust
performance in judgment prediction. Furthermore, incorporating additional legal
information, such as statutes and precedents, significantly improves the
outcome of the prediction task. The LLMs also provide explanations for their
predictions. To evaluate the quality of these predictions and explanations, we
introduce two human evaluation metrics: Clarity and Linking. Our findings from
both automatic and human evaluations indicate that, despite advancements in
LLMs, they are yet to achieve expert-level performance in judgment prediction
and explanation tasks.

æè¦ï¼æ¬ç ç©¶å¨å°åº¦å¤æ±ºçèæ¯ä¸ï¼å©ç¨ä¸ç³»ååºæ¼Transformerçæ¨¡åï¼åæ¬ InLegalBERTãBERT å XLNetï¼ä»¥åè«¸å¦ Llama-2 å GPT-3.5 Turbo ç­ LLMï¼æ¢è¨äºå¨ç¾å¯¦å ´æ¯ä¸­çå¤æ±ºé æ¸¬ãå¨éåç¾å¯¦å ´æ¯ä¸­ï¼æåæ¨¡æ¬äºå¨æ³åº­ä¸æåºå¤æ±ºæå¦ä½é æ¸¬å¤æ±ºï¼åä½¿ç¨ç¶æå¯ç¨çè³è¨ï¼ä¾å¦æ¡ä»¶çäºå¯¦ãæ³è¦ãåä¾åè«é»ãéç¨®æ¹æ³æ¨¡æ¬äºçå¯¦ä¸ççæ¢ä»¶ï¼å¨éäºæ¢ä»¶ä¸å¿é å¨æ²æäºå¾è¦ä¹æçå¹«å©ä¸ååºæ±ºå®ï¼éèååç ç©¶ä¸­ç¶å¸¸ç¼ç¾çåé¡§æ§åæä¸åãå°æ¼Transformeræ¨¡åï¼æååè©¦äºéå±¤å¼Transformeråå¤æ±ºäºå¯¦æè¦ï¼ä»¥åªåéäºæ¨¡åçè¼¸å¥ãæåå° LLM çå¯¦é©è¡¨æï¼GPT-3.5 Turbo å¨ç¾å¯¦å ´æ¯ä¸­è¡¨ç¾åºè²ï¼å¨å¤æ±ºé æ¸¬ä¸­è¡¨ç¾åºå¼·å¤§çæ§è½ãæ­¤å¤ï¼ç´å¥å¶ä»æ³å¾è³è¨ï¼ä¾å¦æ³è¦ååä¾ï¼é¡¯èæ¹åäºé æ¸¬ä»»åççµæãLLM ä¹çºå¶é æ¸¬æä¾äºè§£éãçºäºè©ä¼°éäºé æ¸¬åè§£éçåè³ªï¼æåå¼å¥äºå©åäººé¡è©ä¼°ææ¨ï¼æ¸æ°åº¦åé£çµæ§ãæåå¾èªååäººé¡è©ä¼°ä¸­å¾åºççµæè¡¨æï¼åç®¡ LLM ææé²æ­¥ï¼ä½å®åå°æªå¨å¤æ±ºé æ¸¬åè§£éä»»åä¸­éå°å°å®¶ç´å¥çè¡¨ç¾ã

##### **Reproducible Machine Learning-based Voice Pathology Detection: Introducing the Pitch Difference Feature**
2410.10537v1 by Jan Vrba, Jakub Steinbach, TomÃ¡Å¡ Jirsa, Laura Verde, Roberta De Fazio, Noriyasu Homma, Yuwen Zeng, Key Ichiji, LukÃ¡Å¡ HÃ¡jek, Zuzana SedlÃ¡kovÃ¡, Jan MareÅ¡

In this study, we propose a robust set of features derived from a thorough
research of contemporary practices in voice pathology detection. The feature
set is based on the combination of acoustic handcrafted features. Additionally,
we introduce pitch difference as a novel feature. We combine this feature set,
containing data from the publicly available Saarbr\"ucken Voice Database (SVD),
with preprocessing using the K-Means Synthetic Minority Over-Sampling Technique
algorithm to address class imbalance.
  Moreover, we applied multiple ML models as binary classifiers. We utilized
support vector machine, k-nearest neighbors, naive Bayes, decision tree, random
forest and AdaBoost classifiers. To determine the best classification approach,
we performed grid search on feasible hyperparameters of respective classifiers
and subsections of features.
  Our approach has achieved the state-of-the-art performance, measured by
unweighted average recall in voice pathology detection on SVD database. We
intentionally omit accuracy as it is highly biased metric in case of unbalanced
data compared to aforementioned metrics. The results are further enhanced by
eliminating the potential overestimation of the results with repeated
stratified cross-validation. This advancement demonstrates significant
potential for the clinical deployment of ML methods, offering a valuable tool
for an objective examination of voice pathologies. To support our claims, we
provide a publicly available GitHub repository with DOI
10.5281/zenodo.13771573. Finally, we provide REFORMS checklist.

æè¦ï¼<paragraph>å¨éé ç ç©¶ä¸­ï¼æåæåºäºä¸çµç©©å¥çåè½ï¼éäºåè½æºèªå°ç¶ä»£èªé³ççæª¢æ¸¬å¯¦åçéå¾¹ç ç©¶ãéçµåè½åºæ¼è²å­¸æå·¥ç¹å¾µççµåãæ­¤å¤ï¼æåå°é³é«å·®å¼å¥ä½çºä¸é æ°ç©çåè½ãæåå°éçµåè½ï¼åå«ä¾èªå¬éçè©ç¾å¸åè¯èªé³è³æåº« (SVD) çè³æï¼èä½¿ç¨ K-Means åæå°æ¸éæ¡æ¨£æè¡æ¼ç®æ³é²è¡é èççµåï¼ä»¥è§£æ±ºé¡å¥ä¸å¹³è¡¡çåé¡ã
  æ­¤å¤ï¼æåå°å¤å ML æ¨¡åæç¨çºäºååé¡å¨ãæåå©ç¨æ¯æ´åéæ©ãk-æè¿é°ãæ¨¸ç´ è²æ°ãæ±ºç­æ¨¹ãé¨æ©æ£®æå AdaBoost åé¡å¨ãçºäºç¢ºå®æä½³åé¡æ¹æ³ï¼æåå°åååé¡å¨çå¯è¡è¶åæ¸ååè½å­éå·è¡ç¶²æ ¼æå°ã
  æåçåæ³å·²éææåé²çæè½ï¼ç± SVD è³æåº«ä¸­èªé³ççæª¢æ¸¬çæªå æ¬å¹³åå¬åçæ¸¬éãæåææçç¥æºç¢ºåº¦ï¼å çºèä¸è¿°ææ¨ç¸æ¯ï¼å¨è³æä¸å¹³è¡¡çææ³ä¸ï¼æºç¢ºåº¦æ¯ä¸åé«åº¦åé çææ¨ãéééè¤åå±¤äº¤åé©è­æ¶é¤çµæçæ½å¨é«ä¼°ï¼é²ä¸æ­¥æ¹åäºçµæãéé é²å±å±ç¤ºäº ML æ¹æ³å¨è¨åºé¨ç½²ä¸çå·¨å¤§æ½åï¼çºå®¢è§æª¢æ¥èªé³ççæä¾äºä¸åæå¹å¼çå·¥å·ãçºäºæ¯ææåçèªªæ³ï¼æåæä¾äºä¸åå¬éç GitHub å²å­åº«ï¼å¶ DOI çº 10.5281/zenodo.13771573ãæå¾ï¼æåæä¾äº REFORMS æ ¸å°æ¸å®ã</paragraph>

##### **Get Rid of Task Isolation: A Continuous Multi-task Spatio-Temporal Learning Framework**
2410.10524v1 by Zhongchao Yi, Zhengyang Zhou, Qihe Huang, Yanjiang Chen, Liheng Yu, Xu Wang, Yang Wang

Spatiotemporal learning has become a pivotal technique to enable urban
intelligence. Traditional spatiotemporal models mostly focus on a specific task
by assuming a same distribution between training and testing sets. However,
given that urban systems are usually dynamic, multi-sourced with imbalanced
data distributions, current specific task-specific models fail to generalize to
new urban conditions and adapt to new domains without explicitly modeling
interdependencies across various dimensions and types of urban data. To this
end, we argue that there is an essential to propose a Continuous Multi-task
Spatio-Temporal learning framework (CMuST) to empower collective urban
intelligence, which reforms the urban spatiotemporal learning from
single-domain to cooperatively multi-dimensional and multi-task learning.
Specifically, CMuST proposes a new multi-dimensional spatiotemporal interaction
network (MSTI) to allow cross-interactions between context and main
observations as well as self-interactions within spatial and temporal aspects
to be exposed, which is also the core for capturing task-level commonality and
personalization. To ensure continuous task learning, a novel Rolling Adaptation
training scheme (RoAda) is devised, which not only preserves task uniqueness by
constructing data summarization-driven task prompts, but also harnesses
correlated patterns among tasks by iterative model behavior modeling. We
further establish a benchmark of three cities for multi-task spatiotemporal
learning, and empirically demonstrate the superiority of CMuST via extensive
evaluations on these datasets. The impressive improvements on both few-shot
streaming data and new domain tasks against existing SOAT methods are achieved.
Code is available at https://github.com/DILab-USTCSZ/CMuST.

æè¦ï¼æç©ºå­¸ç¿å·²æçºå¯¦ç¾åå¸æºè½çééµæè¡ãå³çµ±çæç©ºæ¨¡åå¤§å¤éä¸­å¨ç¹å®ä»»åä¸ï¼åè¨­è¨ç·´éåæ¸¬è©¦éä¹éçåå¸ç¸åãç¶èï¼éæ¼åå¸ç³»çµ±éå¸¸æ¯åæçãå¤æºçï¼ä¸è³æåä½ä¸å¹³è¡¡ï¼ç®åç¹å®ä»»åæ¨¡åç¡æ³æ¦æ¬å°æ°çåå¸æ¢ä»¶ï¼ä¹ç¡æ³é©ææ°çé åï¼èæ²ææç¢ºå°å»ºæ¨¡è·¨åç¨®ç¶­åº¦åé¡ååå¸è³æçç¸äºä¾è³´æ§ãçºæ­¤ï¼æåèªçºæå¿è¦æåºä¸åé£çºå¤ä»»åæç©ºå­¸ç¿æ¡æ¶ (CMuST) ä¾å¢å¼·éé«åå¸æºè½ï¼å¾å®ä¸é åçåå¸æç©ºå­¸ç¿æ¹é©çºåä½çå¤ç¶­åº¦åå¤ä»»åå­¸ç¿ãå·é«ä¾èªªï¼CMuST æåºäºä¸åæ°çå¤ç¶­æç©ºäº¤äºç¶²è·¯ (MSTI)ï¼åè¨±ä¸ä¸æèä¸»è¦è§æ¸¬ä¹éçäº¤äºä½ç¨ä»¥åæç©ºæ¹é¢å§çèªæäº¤äºä½ç¨è¢«æ­ç¤ºï¼éä¹æ¯ææä»»åç´å±æ§ååæ§åçæ ¸å¿ãçºäºç¢ºä¿é£çºä»»åå­¸ç¿ï¼è¨­è¨äºä¸åæ°ç©çæ»¾åé©æè¨ç·´æ¹æ¡ (RoAda)ï¼å®ä¸åééæ§å»ºè³ææè¦é©åçä»»åæç¤ºä¾ä¿çä»»åçç¨ç¹æ§ï¼éééè¿­ä»£æ¨¡åè¡çºå»ºæ¨¡ä¾å©ç¨ä»»åä¹éçéè¯æ¨¡å¼ãæåé²ä¸æ­¥å»ºç«äºä¸ååå¸çå¤ä»»åæç©ºå­¸ç¿åºæºï¼ä¸¦ééå°éäºè³æéçå»£æ³è©ä¼°ï¼å¯¦è­å°è­æäº CMuST çåªè¶æ§ãç¸å°æ¼ç¾æç SOAT æ¹æ³ï¼å¨å°æ¨£æ¬ä¸²æµè³æåæ°é åä»»åä¸é½åå¾äºä»¤äººå°è±¡æ·±å»çé²æ­¥ãç¨å¼ç¢¼å¯å¨ https://github.com/DILab-USTCSZ/CMuST ç²å¾ã

##### **UniGEM: A Unified Approach to Generation and Property Prediction for Molecules**
2410.10516v1 by Shikun Feng, Yuyan Ni, Yan Lu, Zhi-Ming Ma, Wei-Ying Ma, Yanyan Lan

Molecular generation and molecular property prediction are both crucial for
drug discovery, but they are often developed independently. Inspired by recent
studies, which demonstrate that diffusion model, a prominent generative
approach, can learn meaningful data representations that enhance predictive
tasks, we explore the potential for developing a unified generative model in
the molecular domain that effectively addresses both molecular generation and
property prediction tasks. However, the integration of these tasks is
challenging due to inherent inconsistencies, making simple multi-task learning
ineffective. To address this, we propose UniGEM, the first unified model to
successfully integrate molecular generation and property prediction, delivering
superior performance in both tasks. Our key innovation lies in a novel
two-phase generative process, where predictive tasks are activated in the later
stages, after the molecular scaffold is formed. We further enhance task balance
through innovative training strategies. Rigorous theoretical analysis and
comprehensive experiments demonstrate our significant improvements in both
tasks. The principles behind UniGEM hold promise for broader applications,
including natural language processing and computer vision.

æè¦ï¼åå­çæååå­æ§è´¨é¢æµå¯¹äºè¯ç©åç°è³å³éè¦ï¼ä½å®ä»¬éå¸¸æ¯ç¬ç«å¼åçãåæè¿çç ç©¶å¯åï¼è¿äºç ç©¶è¡¨æï¼æ©æ£æ¨¡åï¼ä¸ç§çªåºççææ¹æ³ï¼å¯ä»¥å­¦ä¹ å¢å¼ºé¢æµä»»å¡çææä¹çæ°æ®è¡¨ç¤ºï¼æä»¬æ¢ç´¢äºå¨åå­åä¸­å¼åç»ä¸çææ¨¡åçæ½åï¼è¯¥æ¨¡åææå°è§£å³äºåå­çæåæ§è´¨é¢æµä»»å¡ãç¶èï¼ç±äºåºæçä¸ä¸è´æ§ï¼è¿äºä»»å¡çéæå·ææææ§ï¼ä½¿å¾ç®åçå¤ä»»å¡å­¦ä¹ æ æãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬æåºäº UniGEMï¼è¿æ¯ç¬¬ä¸ä¸ªæåéæåå­çæåæ§è´¨é¢æµçç»ä¸æ¨¡åï¼å¨ä¸¤ä¸ªä»»å¡ä¸­é½æä¾äºåè¶çæ§è½ãæä»¬çå³é®åæ°å¨äºä¸ç§æ°é¢çä¸¤é¶æ®µçæè¿ç¨ï¼å¶ä¸­é¢æµä»»å¡å¨åå­æ¯æ¶å½¢æåçåæè¢«æ¿æ´»ãæä»¬éè¿åæ°çè®­ç»ç­ç¥è¿ä¸æ­¥å¢å¼ºä»»å¡å¹³è¡¡ãä¸¥æ ¼ççè®ºåæåç»¼åå®éªè¡¨æï¼æä»¬å¨ä¸¤é¡¹ä»»å¡ä¸­é½åå¾äºæ¾ççæ¹è¿ãUniGEM èåçåçææç¨äºæ´å¹¿æ³çåºç¨ï¼åæ¬èªç¶è¯­è¨å¤çåè®¡ç®æºè§è§ã

##### **Everyday Speech in the Indian Subcontinent**
2410.10508v1 by Utkarsh Pathak, Chandra Sai Krishna Gunda, Sujitha Sathiyamoorthy, Keshav Agarwal, Hema A. Murthy

India has 1369 languages of which 22 are official. About 13 different scripts
are used to represent these languages. A Common Label Set (CLS) was developed
based on phonetics to address the issue of large vocabulary of units required
in the End to End (E2E) framework for multilingual synthesis. This reduced the
footprint of the synthesizer and also enabled fast adaptation to new languages
which had similar phonotactics, provided language scripts belonged to the same
family. In this paper, we provide new insights into speech synthesis, where the
script belongs to one family, while the phonotactics comes from another. Indian
language text is first converted to CLS, and then a synthesizer that matches
the phonotactics of the language is used. Quality akin to that of a native
speaker is obtained for Sanskrit and Konkani with zero adaptation data, using
Kannada and Marathi synthesizers respectively. Further, this approach also
lends itself seamless code switching across 13 Indian languages and English in
a given native speaker's voice.

æè¦ï¼å°åº¦æ 1369 ç¨®èªè¨ï¼å¶ä¸­ 22 ç¨®æ¯å®æ¹èªè¨ãç´æ 13 ç¨®ä¸åçæå­ç¨æ¼è¡¨ç¤ºéäºèªè¨ãåºæ¼èªé³å­¸éç¼äºä¸åéç¨æ¨ç±¤é (CLS)ï¼ä»¥è§£æ±ºå¤èªè¨åæç«¯å°ç«¯ (E2E) æ¡æ¶ä¸­æéçé¾å¤§å®åè©å½éåé¡ãéæ¸å°äºåæå¨çä½ç¨ç©ºéï¼ä¸¦ä¸éè½å¤ å¿«éé©ææ°èªè¨ï¼éäºæ°èªè¨å·æç¸ä¼¼çé³é»ï¼åææ¯èªè¨æå­å±¬æ¼åä¸èªç³»ãå¨æ¬æä¸­ï¼æåæä¾äºå°èªé³åæçæ°çè¦è§£ï¼å¶ä¸­æå­å±¬æ¼ä¸åèªç³»ï¼èé³é»ä¾èªå¦ä¸åèªç³»ãå°åº¦èªè¨ææ¬é¦åè½æçº CLSï¼ç¶å¾ä½¿ç¨èèªè¨é³é»ç¸å¹éçåæå¨ãä½¿ç¨å¡ç´éèªåé¦¬æå°èªåæå¨ï¼åå¥çºæ¢µèªåå­å¡å°¼èªç²å¾äºæ¥è¿æ¯èªäººå£«çåè³ªï¼èç¡éé©ææ¸æãæ­¤å¤ï¼éç¨®æ¹æ³éå¯ä»¥å¨çµ¦å®çæ¯èªäººå£«çè²é³ä¸­å¨ 13 ç¨®å°åº¦èªè¨åè±èªä¹éé²è¡ç¡ç¸«çä»£ç¢¼åæã

##### **A Practical Approach to Causal Inference over Time**
2410.10502v1 by Martina Cinquini, Isacco Beretta, Salvatore Ruggieri, Isabel Valera

In this paper, we focus on estimating the causal effect of an intervention
over time on a dynamical system. To that end, we formally define causal
interventions and their effects over time on discrete-time stochastic processes
(DSPs). Then, we show under which conditions the equilibrium states of a DSP,
both before and after a causal intervention, can be captured by a structural
causal model (SCM). With such an equivalence at hand, we provide an explicit
mapping from vector autoregressive models (VARs), broadly applied in
econometrics, to linear, but potentially cyclic and/or affected by unmeasured
confounders, SCMs. The resulting causal VAR framework allows us to perform
causal inference over time from observational time series data. Our experiments
on synthetic and real-world datasets show that the proposed framework achieves
strong performance in terms of observational forecasting while enabling
accurate estimation of the causal effect of interventions on dynamical systems.
We demonstrate, through a case study, the potential practical questions that
can be addressed using the proposed causal VAR framework.

æè¦ï¼å¨æ¬æä¸­ï¼æåå°æ³¨æ¼ä¼°è¨ä»å¥å¨ä¸æ®µæéå§å°åæç³»çµ±çå æææãçºæ­¤ï¼æåæ­£å¼å®ç¾©å æä»å¥åå¶å°é¢æ£æéé¨æ©éç¨ (DSP) çæéææãç¶å¾ï¼æåå±ç¤ºå¨åªäºæ¢ä»¶ä¸ï¼DSP çå¹³è¡¡çæï¼ç¡è«æ¯å¨å æä»å¥ä¹åéæ¯ä¹å¾ï¼é½å¯ä»¥ç±çµæ§å ææ¨¡å (SCM) ææãæäºéæ¨£çç­å¹æ§ï¼æåæä¾äºä¸åå¾å»£æ³æç¨æ¼è¨éç¶æ¿å­¸çåéèªè¿´æ­¸æ¨¡å (VAR) å°ç·æ§ï¼ä½æ½å¨å°å¾ªç°å/æåæªæ¸¬éæ··éå ç´ å½±é¿ï¼SCM çæç¢ºæ å°ãç±æ­¤ç¢ççå æ VAR æ¡æ¶åè¨±æåå¾è§æ¸¬æéåºåæ¸æä¸­é¨æéå·è¡å ææ¨è«ãæåå¨åæåçå¯¦ä¸çæ¸æéä¸çå¯¦é©è¡¨æï¼ææåºçæ¡æ¶å¨è§æ¸¬é æ¸¬æ¹é¢å¯¦ç¾äºå¼·å¤§çæ§è½ï¼åæè½å¤ æºç¢ºä¼°è¨ä»å¥å°åæç³»çµ±çå æææãæåééæ¡ä¾ç ç©¶å±ç¤ºäºå¯ä»¥ä½¿ç¨ææåºçå æ VAR æ¡æ¶è§£æ±ºçæ½å¨å¯¦éåé¡ã

##### **Cultural Fidelity in Large-Language Models: An Evaluation of Online Language Resources as a Driver of Model Performance in Value Representation**
2410.10489v1 by Sharif Kazemi, Gloria Gerhardt, Jonty Katz, Caroline Ida Kuria, Estelle Pan, Umang Prabhakar

The training data for LLMs embeds societal values, increasing their
familiarity with the language's culture. Our analysis found that 44% of the
variance in the ability of GPT-4o to reflect the societal values of a country,
as measured by the World Values Survey, correlates with the availability of
digital resources in that language. Notably, the error rate was more than five
times higher for the languages of the lowest resource compared to the languages
of the highest resource. For GPT-4-turbo, this correlation rose to 72%,
suggesting efforts to improve the familiarity with the non-English language
beyond the web-scraped data. Our study developed one of the largest and most
robust datasets in this topic area with 21 country-language pairs, each of
which contain 94 survey questions verified by native speakers. Our results
highlight the link between LLM performance and digital data availability in
target languages. Weaker performance in low-resource languages, especially
prominent in the Global South, may worsen digital divides. We discuss
strategies proposed to address this, including developing multilingual LLMs
from the ground up and enhancing fine-tuning on diverse linguistic datasets, as
seen in African language initiatives.

æè¦ï¼å¤§åèªè¨æ¨¡åçè¨ç·´è³ææå§åµç¤¾æå¹å¼è§ï¼æåå¶å°èªè¨æåççæåº¦ãæåçåæç¼ç¾ï¼GPT-4o åæ ä¸ååå®¶ç¤¾æå¹å¼è§çè½åæ 44% çè®ç°ï¼æ ¹æä¸çå¹å¼è§èª¿æ¥æ¸¬éï¼èè©²èªè¨æ¸ä½è³æºçå¯ç¨æ§ç¸éãå¼å¾æ³¨æçæ¯ï¼è³æºæå°çèªè¨çé¯èª¤çæ¯è³æºæå¤çèªè¨é«åºäºåä»¥ä¸ãå°æ¼ GPT-4-turboï¼æ­¤ç¸éæ§ä¸åè³ 72%ï¼é¡¯ç¤ºåºé¤äºç¶²è·¯æ·åè³æä¹å¤ï¼æ¹åå°éè±èªèªè¨çæåº¦çåªåãæåçç ç©¶éç¼äºéåä¸»é¡é åä¸­æå¤§ä¸æç©©å¥çè³æéä¹ä¸ï¼åå« 21 çµåå®¶èªè¨å°ï¼æ¯çµåå« 94 åç±æ¯èªäººå£«é©è­çèª¿æ¥åé¡ãæåççµæçªé¡¯äºå¤§åèªè¨æ¨¡åæè½èç®æ¨èªè¨ä¸­æ¸ä½è³æå¯ç¨æ§ä¹éçéè¯æ§ãå¨è³æºè¼å°çèªè¨ä¸­æè½è¼å·®ï¼ç¹å¥æ¯å¨å¨çåæ¹é¡¯èï¼å¯è½ææ¡åæ¸ä½é´»æºãæåè¨è«äºçºäºè§£æ±ºæ­¤åé¡èæåºçç­ç¥ï¼åæ¬å¾é ­éå§éç¼å¤èªè¨å¤§åèªè¨æ¨¡åï¼ä»¥åå¨ä¸åçèªè¨è³æéä¸å å¼·å¾®èª¿ï¼å¦åå¨éæ´²èªè¨è¨ç«ä¸­æè¦ã

##### **Advancing Newborn Care: Precise Birth Time Detection Using AI-Driven Thermal Imaging with Adaptive Normalization**
2410.10483v1 by Jorge GarcÃ­a-Torres, Ãyvind Meinich-Bache, Anders Johannessen, Siren Rettedal, Vilde Kolstad, Kjersti Engan

Around 5-10\% of newborns need assistance to start breathing. Currently,
there is a lack of evidence-based research, objective data collection, and
opportunities for learning from real newborn resuscitation emergency events.
Generating and evaluating automated newborn resuscitation algorithm activity
timelines relative to the Time of Birth (ToB) offers a promising opportunity to
enhance newborn care practices. Given the importance of prompt resuscitation
interventions within the "golden minute" after birth, having an accurate ToB
with second precision is essential for effective subsequent analysis of newborn
resuscitation episodes. Instead, ToB is generally registered manually, often
with minute precision, making the process inefficient and susceptible to error
and imprecision. In this work, we explore the fusion of Artificial Intelligence
(AI) and thermal imaging to develop the first AI-driven ToB detector. The use
of temperature information offers a promising alternative to detect the newborn
while respecting the privacy of healthcare providers and mothers. However, the
frequent inconsistencies in thermal measurements, especially in a multi-camera
setup, make normalization strategies critical. Our methodology involves a
three-step process: first, we propose an adaptive normalization method based on
Gaussian mixture models (GMM) to mitigate issues related to temperature
variations; second, we implement and deploy an AI model to detect the presence
of the newborn within the thermal video frames; and third, we evaluate and
post-process the model's predictions to estimate the ToB. A precision of 88.1\%
and a recall of 89.3\% are reported in the detection of the newborn within
thermal frames during performance evaluation. Our approach achieves an absolute
median deviation of 2.7 seconds in estimating the ToB relative to the manual
annotations.

æè¦ï¼<paragraph>ç´ 5-10% çæ°çåéè¦åå©æè½éå§å¼å¸ãç®åï¼ç¼ºä¹åºæ¼è­æçç ç©¶ãå®¢è§çè³æèéï¼ä»¥åå¾å¯¦éæ°çåå¾©ç¦ç·æ¥äºä»¶ä¸­å­¸ç¿çæ©æãçæä¸¦è©ä¼°èªåæ°çåå¾©ç¦æ¼ç®æ³æ´»åæéè¡¨ï¼ç¸å°æ¼åºçæé (ToB)ï¼æä¾äºä¸åæå¸æçæ©æï¼å¯ä»¥å¢å¼·æ°çåç§è­·å¯¦åãéæ¼å¨åºçå¾çãé»éä¸åéãå§é²è¡ç«å³å¾©ç¦å¹²é çéè¦æ§ï¼æææºç¢ºå°ç§ç ToB å°æ¼ææåææ°çåå¾©ç¦äºä»¶è³ééè¦ãç¶èï¼ToB éå¸¸æ¯æåè¨éçï¼éå¸¸åªæåéçç²¾ç¢ºåº¦ï¼éä½¿å¾éåéç¨æçä½ä¸ï¼å®¹æåºé¯ä¸ä¸ç²¾ç¢ºãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äººå·¥æºæ§ (AI) åç±å½±åèåï¼ä»¥éç¼ç¬¬ä¸åç± AI é©åç ToB åµæ¸¬å¨ãæº«åº¦è³è¨çä½¿ç¨æä¾äºä¸åæå¸æçæ¿ä»£æ¹æ¡ï¼å¯ä»¥å¨å°éé«çä¿å¥æä¾èåæ¯è¦ªé±ç§çåæåµæ¸¬æ°çåãç¶èï¼ç±éæ¸¬éä¸­çé »ç¹ä¸ä¸è´ï¼å°¤å¶æ¯å¨å¤é¡é ­è¨­å®ä¸­ï¼ä½¿å¾æ­£è¦åç­ç¥è³ééè¦ãæåçåæ³åæ¬ä¸åä¸æ­¥é©æµç¨ï¼é¦åï¼æåæåºä¸ååºæ¼é«æ¯æ··åæ¨¡å (GMM) çèªé©ææ­£è¦åæ¹æ³ï¼ä»¥æ¸è¼èæº«åº¦è®åç¸éçåé¡ï¼å¶æ¬¡ï¼æåå¯¦ä½ä¸¦é¨ç½²ä¸å AI æ¨¡åï¼ä»¥åµæ¸¬æ°çåå¨ç±å½±åæ¡ä¸­çå­å¨ï¼ç¬¬ä¸ï¼æåè©ä¼°ä¸¦å¾èçæ¨¡åçé æ¸¬ï¼ä»¥ä¼°è¨ ToBãå¨æè½è©ä¼°æéï¼å¨ç±å½±åæ¡ä¸­åµæ¸¬æ°çåæï¼æºç¢ºåº¦çº 88.1%ï¼å¬åççº 89.3%ãæåçåæ³å¨ä¼°è¨ç¸å°æ¼æåè¨»è§£ç ToB æï¼éå° 2.7 ç§ççµå°ä¸­ä½æ¸åå·®ã</paragraph>

##### **Model-Based Differentially Private Knowledge Transfer for Large Language Models**
2410.10481v1 by Zhaomin Wu, Jizhou Guo, Junyi Hou, Bingsheng He, Lixin Fan, Qiang Yang

As large language models (LLMs) become increasingly prevalent in web
services, effectively leveraging domain-specific knowledge while ensuring
privacy has become critical. Existing methods, such as retrieval-augmented
generation (RAG) and differentially private data synthesis, often compromise
either the utility of domain knowledge or the privacy of sensitive data,
limiting their applicability in specialized domains. To address these
challenges, we propose \textit{Llamdex}, a novel framework that integrates
privacy-preserving, domain-specific models into LLMs. Our approach
significantly enhances the accuracy of domain-specific tasks, achieving up to a
26\% improvement compared to existing methods under the same differential
privacy constraints. Experimental results show that Llamdex not only improves
the accuracy of LLM responses but also maintains comparable inference
efficiency to the original LLM, highlighting its potential for real-world
applications.

æè¦ï¼éçå¤§åè¯­è¨æ¨¡å (LLM) å¨ç½ç»æå¡ä¸­åå¾è¶æ¥è¶æ®éï¼ææå°å©ç¨ç¹å®é¢åçç¥è¯ï¼åæ¶ç¡®ä¿éç§å·²åå¾è³å³éè¦ãç°æçæ¹æ³ï¼ä¾å¦æ£ç´¢å¢å¼ºçæ (RAG) åå·®å¼åéç§æ°æ®åæï¼éå¸¸ä¼æå®³é¢åç¥è¯çæç¨ææææ°æ®çéç§ï¼ä»èéå¶å®ä»¬å¨ç¹å®é¢åçéç¨æ§ãä¸ºäºåºå¯¹è¿äºææï¼æä»¬æåºäº \textit{Llamdex}ï¼è¿æ¯ä¸ä¸ªå°éç§ä¿æ¤çç¹å®é¢åæ¨¡åéæå° LLM ä¸­çæ°æ¡æ¶ãæä»¬çæ¹æ³æ¾çæé«äºç¹å®é¢åä»»å¡çåç¡®æ§ï¼ä¸å¨ç¸åå·®å¼éç§çº¦æä¸çç°ææ¹æ³ç¸æ¯ï¼æé«äº 26%ãå®éªç»æè¡¨æï¼Llamdex ä¸ä»æé«äº LLM ååºçåç¡®æ§ï¼èä¸è¿ä¿æäºä¸åå§ LLM ç¸å½çæ¨çæçï¼çªåºäºå¶å¨ç°å®ä¸çåºç¨ä¸­çæ½åã

##### **TMGBench: A Systematic Game Benchmark for Evaluating Strategic Reasoning Abilities of LLMs**
2410.10479v1 by Haochuan Wang, Xiachong Feng, Lei Li, Zhanyue Qin, Dianbo Sui, Lingpeng Kong

The rapid advancement of large language models (LLMs) has accelerated their
application in reasoning, with strategic reasoning drawing increasing
attention. To evaluate LLMs' strategic reasoning capabilities, game theory,
with its concise structure, has become a preferred approach. However, current
research focuses on a limited selection of games, resulting in low coverage.
Classic game scenarios risk data leakage, and existing benchmarks often lack
extensibility, making them inadequate for evaluating state-of-the-art models.
To address these challenges, we propose TMGBench, a benchmark with
comprehensive game type coverage, novel scenarios, and flexible organization.
Specifically, we incorporate all 144 game types summarized by the
Robinson-Goforth topology of 2x2 games, constructed as classic games. We also
employ synthetic data generation to create diverse, higher-quality scenarios
through topic guidance and human inspection, referred to as story-based games.
Lastly, we provide a sustainable framework for increasingly powerful LLMs by
treating these games as atomic units and organizing them into more complex
forms via sequential, parallel, and nested structures. Our comprehensive
evaluation of mainstream LLMs covers tests on rational reasoning, robustness,
Theory-of-Mind (ToM), and reasoning in complex forms. Results reveal flaws in
accuracy, consistency, and varying mastery of ToM. Additionally, o1-mini,
OpenAI's latest reasoning model, achieved accuracy rates of 66.6%, 60.0%, and
70.0% on sequential, parallel, and nested games, highlighting TMGBench's
challenges.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çå¿«éé²å±å éäºå®åå¨æ¨çä¸­çæç¨ï¼å¶ä¸­ç­ç¥æ¨çå¼èµ·äºè¶ä¾è¶å¤çéæ³¨ãçºäºè©ä¼° LLM çç­ç¥æ¨çè½åï¼åå¼è«ä»¥å¶ç°¡æ½ççµæ§æçºäºä¸ç¨®é¦é¸æ¹æ³ãç¶èï¼ç®åçç ç©¶éä¸­å¨æéçéæ²é¸æä¸ï¼å°è´è¦èçä½ãç¶å¸éæ²å ´æ¯ææ¸ææ´©é²çé¢¨éªï¼ç¾æçåºæºéå¸¸ç¼ºä¹å¯æ´å±æ§ï¼éä½¿å¾å®åä¸è¶³ä»¥è©ä¼°æåé²çæ¨¡åãçºäºæå°éäºææ°ï¼æåæåºäº TMGBenchï¼éæ¯ä¸ååºæºï¼å·æå¨é¢çéæ²é¡åè¦èç¯åãæ°ç©çå ´æ¯åéæ´»ççµç¹ãå·é«ä¾èªªï¼æåç´å¥äº Robinson-Goforth ææ²ä¸­ç¸½çµçææ 144 ç¨®éæ²é¡åï¼æ§å»ºçºç¶å¸éæ²ãæåéä½¿ç¨åææ¸æçæä¾ééä¸»é¡æå°åäººå·¥æª¢æ¥åµå»ºå¤æ¨£åãæ´é«è³ªéçå ´æ¯ï¼ç¨±çºåºæ¼æäºçéæ²ãæå¾ï¼æåééå°éäºéæ²è¦çºåå­å®åä¸¦ééé åºãä¸¦è¡ååµå¥çµæ§å°å®åçµç¹ææ´è¤éçå½¢å¼ï¼çºåè½è¶ä¾è¶å¼·å¤§ç LLM æä¾äºä¸åå¯æçºçæ¡æ¶ãæåå°ä¸»æµ LLM çç¶åè©ä¼°æ¶µèäºå°çæ§æ¨çãé­¯æ£æ§ãå¿æºçè« (ToM) åè¤éå½¢å¼ä¸­çæ¨ççæ¸¬è©¦ãçµææ­ç¤ºäºæºç¢ºæ§ãä¸è´æ§åå° ToM ææ¡ç¨åº¦ä¸åçç¼ºé·ãæ­¤å¤ï¼OpenAI ææ°çæ¨çæ¨¡å o1-mini å¨é åºãä¸¦è¡ååµå¥éæ²ä¸­åå¥éå°äº 66.6%ã60.0% å 70.0% çæºç¢ºçï¼çªé¡¯äº TMGBench çææ°ã

##### **Will LLMs Replace the Encoder-Only Models in Temporal Relation Classification?**
2410.10476v1 by Gabriel Roccabruna, Massimo Rizzoli, Giuseppe Riccardi

The automatic detection of temporal relations among events has been mainly
investigated with encoder-only models such as RoBERTa. Large Language Models
(LLM) have recently shown promising performance in temporal reasoning tasks
such as temporal question answering. Nevertheless, recent studies have tested
the LLMs' performance in detecting temporal relations of closed-source models
only, limiting the interpretability of those results. In this work, we
investigate LLMs' performance and decision process in the Temporal Relation
Classification task. First, we assess the performance of seven open and
closed-sourced LLMs experimenting with in-context learning and lightweight
fine-tuning approaches. Results show that LLMs with in-context learning
significantly underperform smaller encoder-only models based on RoBERTa. Then,
we delve into the possible reasons for this gap by applying explainable
methods. The outcome suggests a limitation of LLMs in this task due to their
autoregressive nature, which causes them to focus only on the last part of the
sequence. Additionally, we evaluate the word embeddings of these two models to
better understand their pre-training differences. The code and the fine-tuned
models can be found respectively on GitHub.

æè¦ï¼äºä»¶ä¹éæééä¿çèªååµæ¸¬ä¸»è¦ä½¿ç¨ç·¨ç¢¼å¨æ¨¡åï¼ä¾å¦ RoBERTaï¼é²è¡ç ç©¶ãå¤§åèªè¨æ¨¡å (LLM) è¿æå¨æéæ¨çä»»åä¸­å±ç¾åºä»¤äººæ»¿æçè¡¨ç¾ï¼ä¾å¦æéåé¡åç­ãåç®¡å¦æ­¤ï¼æè¿çç ç©¶åæ¸¬è©¦äº LLM å¨åµæ¸¬å°éåå§ç¢¼æ¨¡åçæééä¿ä¸çè¡¨ç¾ï¼ééå¶äºéäºçµæçå¯è§£éæ§ãå¨éé å·¥ä½ä¸­ï¼æåç ç©¶äº LLM å¨æééä¿åé¡ä»»åä¸­çè¡¨ç¾åæ±ºç­éç¨ãé¦åï¼æåè©ä¼°äºä¸åéæ¾åå°éåå§ç¢¼ LLM å¨æå¢å­¸ç¿åè¼éç´å¾®èª¿æ¹æ³ä¸­çè¡¨ç¾ãçµæé¡¯ç¤ºï¼ä½¿ç¨æå¢å­¸ç¿ç LLM æé¡¯ä½æ¼åºæ¼ RoBERTa çè¼å°ç·¨ç¢¼å¨æ¨¡åãç¶å¾ï¼æåééæç¨å¯è§£éçæ¹æ³æ·±å¥æ¢è¨é æéåå·®è·çå¯è½åå ãçµæè¡¨æï¼LLM å¨æ­¤ä»»åä¸­çéå¶å¨æ¼å®åçèªåè¿´æ­¸æ¬è³ªï¼éå°è´å®ååªéæ³¨åºåçæå¾é¨åãæ­¤å¤ï¼æåè©ä¼°äºéå©åæ¨¡åçè©åµå¥ï¼ä»¥æ´å¥½å°äºè§£å®åçé è¨ç·´å·®ç°ãç¨å¼ç¢¼åå¾®èª¿æ¨¡ååå¥å¯ä»¥å¨ GitHub ä¸æ¾å°ã

##### **TABCF: Counterfactual Explanations for Tabular Data Using a Transformer-Based VAE**
2410.10463v1 by Emmanouil Panagiotou, Manuel Heurich, Tim Landgraf, Eirini Ntoutsi

In the field of Explainable AI (XAI), counterfactual (CF) explanations are
one prominent method to interpret a black-box model by suggesting changes to
the input that would alter a prediction. In real-world applications, the input
is predominantly in tabular form and comprised of mixed data types and complex
feature interdependencies. These unique data characteristics are difficult to
model, and we empirically show that they lead to bias towards specific feature
types when generating CFs. To overcome this issue, we introduce TABCF, a CF
explanation method that leverages a transformer-based Variational Autoencoder
(VAE) tailored for modeling tabular data. Our approach uses transformers to
learn a continuous latent space and a novel Gumbel-Softmax detokenizer that
enables precise categorical reconstruction while preserving end-to-end
differentiability. Extensive quantitative evaluation on five financial datasets
demonstrates that TABCF does not exhibit bias toward specific feature types,
and outperforms existing methods in producing effective CFs that align with
common CF desiderata.

æè¦ï¼å¨å¯è§£é AI (XAI) é åä¸­ï¼åäºå¯¦ (CF) è§£éæ¯ä¸ç¨®éè¦çééå»ºè­°è®æ´è¼¸å¥ä¾æ¹è®é æ¸¬çé»ç®±æ¨¡åè§£éæ¹æ³ãå¨å¯¦éæç¨ä¸­ï¼è¼¸å¥ä¸»è¦ä»¥è¡¨æ ¼å½¢å¼åç¾ï¼ä¸¦åå«æ··åè³æé¡ååè¤éçç¹å¾µç¸äºä¾è³´æ§ãéäºç¨ç¹è³æç¹å¾µé£ä»¥å»ºæ¨¡ï¼æåå¯¦è­é¡¯ç¤ºï¼å¨ç¢ç CF æï¼å®åæå°è´ååç¹å®ç¹å¾µé¡åãçºäºåæéååé¡ï¼æåå¼å¥äº TABCFï¼éæ¯ä¸ç¨® CF è§£éæ¹æ³ï¼å®å©ç¨äºçºè¡¨æ ¼è³æå»ºæ¨¡èéèº«æé çåºæ¼è®æå¨çè®ç°èªåç·¨ç¢¼å¨ (VAE)ãæåçåæ³ä½¿ç¨è®æå¨ä¾å­¸ç¿é£çºæ½å¨ç©ºéåä¸ç¨®æ°ç Gumbel-Softmax å»æ¨è¨å¨ï¼å®å¯ä»¥å¨ä¿çç«¯å°ç«¯å¯å¾®åçåæå¯¦ç¾ç²¾ç¢ºçåé¡éå»ºãå°äºåè²¡åè³æéé²è¡çå»£æ³å®éè©ä¼°è¡¨æï¼TABCF æ²æè¡¨ç¾åºå°ç¹å®ç¹å¾µé¡åçåè¦ï¼ä¸¦ä¸å¨ç¢çç¬¦åå¸¸è¦ CF çæ³æ¢ä»¶çææ CF æ¹é¢åªæ¼ç¾ææ¹æ³ã

##### **Ada-K Routing: Boosting the Efficiency of MoE-based LLMs**
2410.10456v2 by Tongtian Yue, Longteng Guo, Jie Cheng, Xuange Gao, Jing Liu

In the era of Large Language Models (LLMs), Mixture-of-Experts (MoE)
architectures offer a promising approach to managing computational costs while
scaling up model parameters. Conventional MoE-based LLMs typically employ
static Top-K routing, which activates a fixed and equal number of experts for
each token regardless of their significance within the context. In this paper,
we propose a novel Ada-K routing strategy that dynamically adjusts the number
of activated experts for each token, thereby improving the balance between
computational efficiency and model performance. Specifically, our strategy
incorporates learnable and lightweight allocator modules that decide customized
expert resource allocation tailored to the contextual needs for each token.
These allocators are designed to be fully pluggable, making it broadly
applicable across all mainstream MoE-based LLMs. We leverage the Proximal
Policy Optimization (PPO) algorithm to facilitate an end-to-end learning
process for this non-differentiable decision-making framework. Extensive
evaluations on four popular baseline models demonstrate that our Ada-K routing
method significantly outperforms conventional Top-K routing. Compared to Top-K,
our method achieves over 25% reduction in FLOPs and more than 20% inference
speedup while still improving performance across various benchmarks. Moreover,
the training of Ada-K is highly efficient. Even for Mixtral-8x22B, a MoE-based
LLM with more than 140B parameters, the training time is limited to 8 hours.
Detailed analysis shows that harder tasks, middle layers, and content words
tend to activate more experts, providing valuable insights for future adaptive
MoE system designs. Both the training code and model checkpoints will be
publicly available.

æè¦ï¼<paragraph>å¨å¤§åèªè¨æ¨¡å (LLM) æä»£ï¼æ··åå°å®¶ (MoE) æ¶æ§æä¾äºä¸ç¨®æåæ¯çæ¹æ³ï¼å¯ä»¥å¨æ´åæ¨¡ååæ¸çåæç®¡çéç®ææ¬ãåºæ¼ MoE çå³çµ± LLM éå¸¸æ¡ç¨éæ Top-K è·¯ç±ï¼ç¡è«ç¬¦èå¨ä¸ä¸æä¸­çéè¦æ§å¦ä½ï¼é½æçºæ¯åç¬¦èåç¨åºå®ä¸ç¸ç­çå°å®¶æ¸éãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°ç©ç Ada-K è·¯ç±ç­ç¥ï¼å®æåæèª¿æ´æ¯åç¬¦èçå·²åç¨å°å®¶æ¸éï¼å¾èæ¹åéç®æçåæ¨¡åæè½ä¹éçå¹³è¡¡ãå·é«ä¾èªªï¼æåçç­ç¥åå«å¯å­¸ç¿ä¸è¼éåçéç½®å¨æ¨¡çµï¼éäºæ¨¡çµæéå°æ¯åç¬¦èçä¸ä¸æéæ±æ±ºå®èªè¨çå°å®¶è³æºéç½®ãéäºéç½®å¨è¢«è¨­è¨çºå®å¨å¯æå¥ï¼ä½¿å¶å»£æ³é©ç¨æ¼ææä¸»æµçåºæ¼ MoE ç LLMãæåå©ç¨è¿ç«¯ç­ç¥æä½³å (PPO) æ¼ç®æ³ä¾ä¿é²éåä¸å¯å¾®åæ±ºç­å¶å®æ¶æ§çç«¯å°ç«¯å­¸ç¿éç¨ãå°ååæµè¡çåºç·æ¨¡åé²è¡å»£æ³è©ä¼°ï¼è­ææåç Ada-K è·¯ç±æ¹æ³é¡¯èåªæ¼å³çµ±ç Top-K è·¯ç±ãè Top-K ç¸æ¯ï¼æåçæ¨¡åå¨ FLOP æ¹é¢æ¸å°äº 25% ä»¥ä¸ï¼æ¨çéåº¦å å¿«äº 20% ä»¥ä¸ï¼åæä»æ¹åäºåç¨®åºæºæ¸¬è©¦çæè½ãæ­¤å¤ï¼Ada-K çè¨ç·´éå¸¸ææçãå³ä½¿å°æ¼ Mixtral-8x22Bï¼ä¸åå·æè¶é 140B åæ¸çåºæ¼ MoE ç LLMï¼è¨ç·´æéä¹éå¶å¨ 8 å°æå§ãè©³ç´°åæé¡¯ç¤ºï¼è¼å°é£çä»»åãä¸­éå±¤åå§å®¹è©å¾åæ¼åç¨æ´å¤å°å®¶ï¼éçºæªä¾çèªé©æ MoE ç³»çµ±è¨­è¨æä¾äºå¯¶è²´çè¦è§£ãè¨ç·´ç¨å¼ç¢¼åæ¨¡åæª¢æ¥é»å°å¬éæä¾ã</paragraph>

##### **Advancing Academic Knowledge Retrieval via LLM-enhanced Representation Similarity Fusion**
2410.10455v1 by Wei Dai, Peng Fu, Chunjing Gan

In an era marked by robust technological growth and swift information
renewal, furnishing researchers and the populace with top-tier, avant-garde
academic insights spanning various domains has become an urgent necessity. The
KDD Cup 2024 AQA Challenge is geared towards advancing retrieval models to
identify pertinent academic terminologies from suitable papers for scientific
inquiries. This paper introduces the LLM-KnowSimFuser proposed by Robo Space,
which wins the 2nd place in the competition. With inspirations drawed from the
superior performance of LLMs on multiple tasks, after careful analysis of the
provided datasets, we firstly perform fine-tuning and inference using
LLM-enhanced pre-trained retrieval models to introduce the tremendous language
understanding and open-domain knowledge of LLMs into this task, followed by a
weighted fusion based on the similarity matrix derived from the inference
results. Finally, experiments conducted on the competition datasets show the
superiority of our proposal, which achieved a score of 0.20726 on the final
leaderboard.

æè¦ï¼å¨ç§æé£éç¼å±ãè³è¨æ´æ°å¿«éçæä»£ï¼çºç ç©¶èåæ®ç¾å¤§ç¾æä¾è·¨é åçé å°åæ²¿å­¸è¡è¦è§£ï¼å·²æçºå»ä¸å®¹ç·©çå¿è¦ãKDD Cup 2024 AQA ææ°è³½æ¨å¨æ¨é²æª¢ç´¢æ¨¡åï¼å¾åé©çè«æä¸­æ¾åºèç§å­¸æ¢ç©¶ç¸éçå­¸è¡è¡èªãæ¬æä»ç´¹äºç± Robo Space æåºç LLM-KnowSimFuserï¼å¨ç«¶è³½ä¸­ç²å¾ç¬¬äºåãå¨ä»ç´°åææä¾çè³æéå¾ï¼æåå¾ LLM å¨å¤é ä»»åä¸­çåªç°è¡¨ç¾ä¸­æ±²åéæï¼é¦åä½¿ç¨ LLM å¢å¼·çé è¨ç·´æª¢ç´¢æ¨¡åé²è¡å¾®èª¿åæ¨çï¼å° LLM å¼ºå¤§çèªè¨çè§£åéæ¾é åç¥è­å¼å¥æ­¤ä»»åä¸­ï¼æ¥èæ ¹ææ¨ççµæè¡ççç¸ä¼¼ç©é£é²è¡å æ¬èåãæå¾ï¼å¨ç«¶è³½è³æéä¸é²è¡çå¯¦é©é¡¯ç¤ºäºæåææ¡çåªè¶æ§ï¼å¨æçµæè¡æ¦ä¸åå¾ 0.20726 çåæ¸ã

##### **KBLaM: Knowledge Base augmented Language Model**
2410.10450v1 by Xi Wang, Liana Mikaelyan, Taketomo Isazawa, James Hensman

In this paper, we propose Knowledge Base augmented Language Model (KBLaM), a
new method for augmenting Large Language Models (LLMs) with external knowledge.
KBLaM works with a knowledge base (KB) constructed from a corpus of documents,
transforming each piece of knowledge in the KB into continuous key-value vector
pairs via pre-trained sentence encoders with linear adapters and integrating
them into pre-trained LLMs via a specialized rectangular attention mechanism.
Unlike Retrieval-Augmented Generation, KBLaM eliminates external retrieval
modules, and unlike in-context learning, its computational overhead scales
linearly with KB size rather than quadratically. Our approach enables
integrating a large KB of more than 10K triples into an 8B pre-trained LLM of
only 8K context window on one single A100 80GB GPU and allows for dynamic
updates without model fine-tuning or retraining. Experiments demonstrate
KBLaM's effectiveness in various tasks, including question-answering and
open-ended reasoning, while providing interpretable insights into its use of
the augmented knowledge.

æè¦ï¼å¨æ¬æä¸­ï¼æåæåºäºç¥è­åº«å¢å¼·èªè¨æ¨¡å (KBLaM)ï¼éæ¯ä¸ç¨®ä½¿ç¨å¤é¨ç¥è­å¢å¼·å¤§åèªè¨æ¨¡å (LLM) çæ°æ¹æ³ãKBLaM ä½¿ç¨å¾æä»¶èªæåº«ä¸­å»ºæ§çç¥è­åº« (KB)ï¼ééé åè¨ç·´çå¥å­ç·¨ç¢¼å¨åç·æ§é©éå¨ï¼å° KB ä¸­çæ¯æ®µç¥è­è½æçºé£çºçéµå¼åéå°ï¼ä¸¦ééå°éçç©å½¢æ³¨æåæ©å¶å°å®åæ´åå°é åè¨ç·´ç LLM ä¸­ãèæª¢ç´¢å¢å¼·çæä¸åï¼KBLaM æ¶é¤äºå¤é¨æª¢ç´¢æ¨¡çµï¼èæå¢å§å­¸ç¿ä¸åï¼å®çéç®éé·è KB å¤§å°æç·æ§æ¯ä¾ï¼èä¸æ¯äºæ¬¡æ¹æ¯ä¾ãæåçåæ³è½å¤ å°è¶é 10K ä¸åçµçå¤§å KB æ´åå°åæ 8K æå¢è¦çªç 8B é åè¨ç·´ LLM ä¸­ï¼åä½¿ç¨ä¸å A100 80GB GPUï¼ä¸¦åè¨±åææ´æ°ï¼èç¡éæ¨¡åå¾®èª¿æéæ°è¨ç·´ãå¯¦é©è­æäº KBLaM å¨åç¨®ä»»åä¸­çæè½ï¼åæ¬åç­åéæ¾å¼æ¨çï¼åææä¾å°å¶ä½¿ç¨å¢å¼·ç¥è­çå¯è©®éè¦è§£ã

##### **QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios**
2410.10449v1 by Timo Pierre Schrader, Lukas Lange, Simon Razniewski, Annemarie Friedrich

Reasoning is key to many decision making processes. It requires consolidating
a set of rule-like premises that are often associated with degrees of
uncertainty and observations to draw conclusions. In this work, we address both
the case where premises are specified as numeric probabilistic rules and
situations in which humans state their estimates using words expressing degrees
of certainty. Existing probabilistic reasoning datasets simplify the task,
e.g., by requiring the model to only rank textual alternatives, by including
only binary random variables, or by making use of a limited set of templates
that result in less varied text.
  In this work, we present QUITE, a question answering dataset of real-world
Bayesian reasoning scenarios with categorical random variables and complex
relationships. QUITE provides high-quality natural language verbalizations of
premises together with evidence statements and expects the answer to a question
in the form of an estimated probability. We conduct an extensive set of
experiments, finding that logic-based models outperform out-of-the-box large
language models on all reasoning types (causal, evidential, and
explaining-away). Our results provide evidence that neuro-symbolic models are a
promising direction for improving complex reasoning. We release QUITE and code
for training and experiments on Github.

æè¦ï¼æ¨çæ¯è¨±å¤æ±ºç­å¶å®éç¨çééµãééè¦æ´åä¸çµè¦åè¬çåæï¼éäºåæéå¸¸èä¸ç¢ºå®æ§åè§å¯çµæçç¨åº¦ç¸éï¼æè½å¾åºçµè«ãå¨éé å·¥ä½ä¸­ï¼æååæèçäºåæè¢«æå®çºæ¸å­æ©çè¦åçææ³ï¼ä»¥åäººé¡ä½¿ç¨è¡¨éç¢ºå®ç¨åº¦çæå­é³è¿°å¶ä¼°è¨å¼çææ³ãç¾æçæ©çæ¨çè³æéç°¡åäºéé ä»»åï¼ä¾å¦ï¼è¦æ±æ¨¡ååå°æå­é¸é é²è¡æåãååå«äºåé¨æ©è®æ¸ï¼æä½¿ç¨ä¸çµæéçç¯æ¬ï¼éæç¢çè¼å°çæå­è®åã
å¨éé å·¥ä½ä¸­ï¼æåæåºäº QUITEï¼éæ¯ä¸ååé¡è§£ç­è³æéï¼åå«çå¯¦ä¸ççè²æ°æ¨çå ´æ¯ï¼å¶ä¸­åå«åé¡é¨æ©è®æ¸åè¤ééä¿ãQUITE æä¾äºåæçé«åè³ªèªç¶èªè¨è¡¨éï¼ä»¥åè­æé³è¿°ï¼ä¸¦ææä»¥ä¼°è¨æ©ççå½¢å¼åç­åé¡ãæåé²è¡äºä¸ç³»åå»£æ³çå¯¦é©ï¼ç¼ç¾åºæ¼éè¼¯çæ¨¡åå¨æææ¨çé¡åï¼å æãè­æåè§£éï¼ä¸é½åªæ¼ç¾æçå·¨éèªè¨æ¨¡åãæåççµææä¾äºè­æï¼è¡¨æç¥ç¶ç¬¦èæ¨¡åæ¯æ¹é²è¤éæ¨ççæå¸æçæ¹åãæåå¨ Github ä¸ç¼å¸äº QUITE åè¨ç·´èå¯¦é©çç¨å¼ç¢¼ã

##### **Free Video-LLM: Prompt-guided Visual Perception for Efficient Training-free Video LLMs**
2410.10441v1 by Kai Han, Jianyuan Guo, Yehui Tang, Wei He, Enhua Wu, Yunhe Wang

Vision-language large models have achieved remarkable success in various
multi-modal tasks, yet applying them to video understanding remains challenging
due to the inherent complexity and computational demands of video data. While
training-based video-LLMs deliver high performance, they often require
substantial resources for training and inference. Conversely, training-free
approaches offer a more efficient alternative by adapting pre-trained
image-LLMs models for video tasks without additional training, but they face
inference efficiency bottlenecks due to the large number of visual tokens
generated from video frames. In this work, we present a novel prompt-guided
visual perception framework (abbreviated as \emph{Free Video-LLM}) for
efficient inference of training-free video LLMs. The proposed framework
decouples spatial-temporal dimension and performs temporal frame sampling and
spatial RoI cropping respectively based on task-specific prompts. Our method
effectively reduces the number of visual tokens while maintaining high
performance across multiple video question-answering benchmarks. Extensive
experiments demonstrate that our approach achieves competitive results with
significantly fewer tokens, offering an optimal trade-off between accuracy and
computational efficiency compared to state-of-the-art video LLMs. The code will
be available at \url{https://github.com/contrastive/FreeVideoLLM}.

æè¦ï¼è¦è¦ºèªè¨å¤§åæ¨¡åå¨åç¨®å¤æ¨¡æä»»åä¸­åå¾é¡¯èæåï¼ä½ç±æ¼è¦è¨è³ææ¬èº«è¤éä¸è¨ç®éæ±é«ï¼å°å¶æç¨æ¼è¦è¨çè§£ä»æ¯ä¸é ææ°ãéç¶åºæ¼è¨ç·´çè¦è¨ LLM å¯æä¾é«æ§è½ï¼ä½éå¸¸éè¦å¤§éçè³æºé²è¡è¨ç·´åæ¨è«ãç¸åå°ï¼ç¡éè¨ç·´çæ¹æ³æä¾äºä¸ç¨®æ´ææççæ¿ä»£æ¹æ¡ï¼å¯ä»¥èª¿æ´é åè¨ç·´å¥½çå½±å LLM æ¨¡åä»¥å·è¡è¦è¨ä»»åï¼èç¡éé¡å¤è¨ç·´ï¼ä½ç±æ¼è¦è¨å¹ç¢ççè¦è¦ºç¬¦èæ¸éé¾å¤§ï¼å®åé¢è¨æ¨è«æçç¶é ¸ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸åæ°çæç¤ºå¼å°è¦è¦ºæç¥æ¡æ¶ï¼ç°¡ç¨±ãFree Video-LLMãï¼ï¼ç¨æ¼æææ¨è«ç¡éè¨ç·´çè¦è¨ LLMãææåºçæ¡æ¶è§£è¦æç©ºç¶­åº¦ï¼ä¸¦æ ¹æç¹å®æ¼ä»»åçæç¤ºåå¥å·è¡æéå¹æ¡æ¨£åç©ºé RoI è£åªãæåçæ¨¡åæææ¸å°äºè¦è¦ºç¬¦èçæ¸éï¼åæå¨å¤åè¦è¨åç­åºæºä¸­ç¶­æé«æ§è½ãå»£æ³çå¯¦é©è­æï¼æåçæ¨¡åä»¥é¡¯èæ´å°çç¬¦èåå¾æç«¶ç­åççµæï¼èæåé²çè¦è¨ LLM ç¸æ¯ï¼å¨æºç¢ºåº¦åéç®æçä¹éæä¾äºæä½³çæè¡·æ¹æ¡ãç¨å¼ç¢¼å°æå¨ \url{https://github.com/contrastive/FreeVideoLLM} æä¾ã

##### **LKASeg:Remote-Sensing Image Semantic Segmentation with Large Kernel Attention and Full-Scale Skip Connections**
2410.10433v1 by Xuezhi Xiang, Yibo Ning, Lei Zhang, Denis Ombati, Himaloy Himu, Xiantong Zhen

Semantic segmentation of remote sensing images is a fundamental task in
geospatial research. However, widely used Convolutional Neural Networks (CNNs)
and Transformers have notable drawbacks: CNNs may be limited by insufficient
remote sensing modeling capability, while Transformers face challenges due to
computational complexity. In this paper, we propose a remote-sensing image
semantic segmentation network named LKASeg, which combines Large Kernel
Attention(LSKA) and Full-Scale Skip Connections(FSC). Specifically, we propose
a decoder based on Large Kernel Attention (LKA), which extract global features
while avoiding the computational overhead of self-attention and providing
channel adaptability. To achieve full-scale feature learning and fusion, we
apply Full-Scale Skip Connections (FSC) between the encoder and decoder. We
conducted experiments by combining the LKA-based decoder with FSC. On the ISPRS
Vaihingen dataset, the mF1 and mIoU scores achieved 90.33% and 82.77%.

æè¦ï¼éæ¸¬å½±åçèªæåå²æ¯å°çç©ºéç ç©¶ä¸­çåºæ¬ä»»åãç¶èï¼å»£æ³ä½¿ç¨çå·ç©ç¥ç¶ç¶²è·¯ (CNN) å Transformer æé¡¯èçç¼ºé»ï¼CNN å¯è½åå°éæ¸¬å»ºæ¨¡è½åä¸è¶³çéå¶ï¼è Transformer åå è¨ç®è¤éåº¦èé¢è¨ææ°ãå¨æ¬æä¸­ï¼æåæåºä¸ååçº LKASeg çéæ¸¬å½±åèªæåå²ç¶²è·¯ï¼å®çµåäºå¤§æ ¸æ³¨æå (LSKA) åå¨å°ºå¯¸è·³èºé£æ¥ (FSC)ãå·é«ä¾èªªï¼æåæåºäºä¸ååºæ¼å¤§æ ¸æ³¨æå (LKA) çè§£ç¢¼å¨ï¼å®å¨é¿åèªæ³¨æåçè¨ç®éé·ä¸¦æä¾ééé©ææ§çåææåå¨å±ç¹å¾µãçºäºå¯¦ç¾å¨å°ºå¯¸ç¹å¾µå­¸ç¿åèåï¼æåå¨ç·¨ç¢¼å¨åè§£ç¢¼å¨ä¹éæç¨å¨å°ºå¯¸è·³èºé£æ¥ (FSC)ãæåééå°åºæ¼ LKA çè§£ç¢¼å¨è FSC ç¸çµåé²è¡äºå¯¦é©ãå¨ ISPRS Vaihingen è³æéä¸ï¼mF1 å mIoU åæ¸åå¥éå° 90.33% å 82.77%ã

##### **On Calibration of LLM-based Guard Models for Reliable Content Moderation**
2410.10414v1 by Hongfu Liu, Hengguan Huang, Hao Wang, Xiangming Gu, Ye Wang

Large language models (LLMs) pose significant risks due to the potential for
generating harmful content or users attempting to evade guardrails. Existing
studies have developed LLM-based guard models designed to moderate the input
and output of threat LLMs, ensuring adherence to safety policies by blocking
content that violates these protocols upon deployment. However, limited
attention has been given to the reliability and calibration of such guard
models. In this work, we empirically conduct comprehensive investigations of
confidence calibration for 9 existing LLM-based guard models on 12 benchmarks
in both user input and model output classification. Our findings reveal that
current LLM-based guard models tend to 1) produce overconfident predictions, 2)
exhibit significant miscalibration when subjected to jailbreak attacks, and 3)
demonstrate limited robustness to the outputs generated by different types of
response models. Additionally, we assess the effectiveness of post-hoc
calibration methods to mitigate miscalibration. We demonstrate the efficacy of
temperature scaling and, for the first time, highlight the benefits of
contextual calibration for confidence calibration of guard models, particularly
in the absence of validation sets. Our analysis and experiments underscore the
limitations of current LLM-based guard models and provide valuable insights for
the future development of well-calibrated guard models toward more reliable
content moderation. We also advocate for incorporating reliability evaluation
of confidence calibration when releasing future LLM-based guard models.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ç±æ¼æ½å¨çææå®³å§å®¹æä½¿ç¨èä¼åè¦é¿é²è­·æªæ½çé¢¨éªï¼å æ­¤æ§æéå¤§é¢¨éªãç¾æç ç©¶å·²éç¼åºåºæ¼ LLM çé²è­·æ¨¡åï¼æ¨å¨èª¿ç¯å¨è LLM çè¼¸å¥åè¼¸åºï¼ç¢ºä¿å¨é¨ç½²æå°ééåéäºåå®çå§å®¹ï¼å¾èéµå®å®å¨æ¿ç­ãç¶èï¼å°æ¼æ­¤é¡é²è­·æ¨¡åçå¯é æ§åæ ¡æºï¼å»é®®å°åå°éæ³¨ãå¨éé å·¥ä½ä¸­ï¼æåéå° 9 åç¾æçåºæ¼ LLM çé²è­·æ¨¡åï¼å¨ 12 ååºæºä¸å°ä½¿ç¨èè¼¸å¥åæ¨¡åè¼¸åºåé¡é²è¡å¨é¢çä¿¡å¿æ ¡æºèª¿æ¥ãæåçç ç©¶çµæé¡¯ç¤ºï¼ç®åçåºæ¼ LLM çé²è­·æ¨¡åå¾å¾æ 1) ç¢çéåº¦èªä¿¡çé æ¸¬ï¼2) å¨é­åè¶çæ»ææè¡¨ç¾åºé¡¯èçæ ¡æºä¸ç¶ï¼ä»¥å 3) å°ä¸åé¡åçåææ¨¡åæç¢ççè¼¸åºè¡¨ç¾åºæéçç©©å¥æ§ãæ­¤å¤ï¼æåè©ä¼°äºå¾æ ¡æºæ¹æ³å¨æ¸è¼æ ¡æºä¸ç¶æ¹é¢çæææ§ãæåå±ç¤ºäºæº«åº¦èª¿æ´çåæï¼ä¸¦é¦æ¬¡å¼·èª¿äºæå¢æ ¡æºå°æ¼é²è­·æ¨¡åçä¿¡å¿æ ¡æºï¼ç¹å¥æ¯å¨æ²æé©è­éçææ³ä¸ï¼æå¸¶ä¾ççèãæåçåæåå¯¦é©å¼·èª¿äºç®ååºæ¼ LLM çé²è­·æ¨¡åçéå¶ï¼ä¸¦çºæªä¾éç¼æ ¡æºè¯å¥½çé²è­·æ¨¡åä»¥å¯¦ç¾æ´å¯é çå§å®¹å¯©æ ¸æä¾äºå¯¶è²´çè¦è§£ãæåä¹ä¸»å¼µå¨éåºæªä¾çåºæ¼ LLM çé²è­·æ¨¡åæï¼ç´å¥ä¿¡å¿æ ¡æºçå¯é æ§è©ä¼°ã

##### **Medico: Towards Hallucination Detection and Correction with Multi-source Evidence Fusion**
2410.10408v1 by Xinping Zhao, Jindi Yu, Zhenyu Liu, Jifang Wang, Dongfang Li, Yibin Chen, Baotian Hu, Min Zhang

As we all know, hallucinations prevail in Large Language Models (LLMs), where
the generated content is coherent but factually incorrect, which inflicts a
heavy blow on the widespread application of LLMs. Previous studies have shown
that LLMs could confidently state non-existent facts rather than answering ``I
don't know''. Therefore, it is necessary to resort to external knowledge to
detect and correct the hallucinated content. Since manual detection and
correction of factual errors is labor-intensive, developing an automatic
end-to-end hallucination-checking approach is indeed a needful thing. To this
end, we present Medico, a Multi-source evidence fusion enhanced hallucination
detection and correction framework. It fuses diverse evidence from multiple
sources, detects whether the generated content contains factual errors,
provides the rationale behind the judgment, and iteratively revises the
hallucinated content. Experimental results on evidence retrieval (0.964 HR@5,
0.908 MRR@5), hallucination detection (0.927-0.951 F1), and hallucination
correction (0.973-0.979 approval rate) manifest the great potential of Medico.
A video demo of Medico can be found at https://youtu.be/RtsO6CSesBI.

æè¦ï¼ç¾æå¨ç¥ï¼å¤§åèªè¨æ¨¡å (LLM) çè¡å¹»è¦ºï¼å¶ä¸­ç¢ççå§å®¹é£è²«ä½äºå¯¦ä¸æ­£ç¢ºï¼å° LLM çå»£æ³æç¨é ææ²éææãååçç ç©¶è¡¨æï¼LLM å¯ä»¥èªä¿¡å°é³è¿°ä¸å­å¨çäºå¯¦ï¼èä¸æ¯åç­ãæä¸ç¥éããå æ­¤ï¼æå¿è¦è¨´è«¸å¤é¨ç¥è­ä¾æª¢æ¸¬åæ´æ­£å¹»è¦ºå§å®¹ãç±æ¼äººå·¥æª¢æ¸¬åæ´æ­£äºå¯¦é¯èª¤éå¸¸èè²»äººåï¼å æ­¤éç¼ä¸ç¨®èªååçç«¯å°ç«¯å¹»è¦ºæª¢æ¥æ¹æ³ç¢ºå¯¦æ¯ä¸ä»¶å¿è¦çäºæãçºæ­¤ï¼æåæåºäº Medicoï¼ä¸åå¤æºè­æèåå¢å¼·çå¹»è¦ºæª¢æ¸¬åæ´æ­£æ¡æ¶ãå®èåäºä¾èªå¤åä¾æºçä¸åè­æï¼æª¢æ¸¬çæçå§å®¹æ¯å¦åå«äºå¯¦é¯èª¤ï¼æä¾å¤æ·èå¾ççç±ï¼ä¸¦åè¦ä¿®æ¹å¹»è¦ºå§å®¹ãè­ææª¢ç´¢ï¼0.964 HR@5ã0.908 MRR@5ï¼ãå¹»è¦ºæª¢æ¸¬ï¼0.927-0.951 F1ï¼åå¹»è¦ºæ´æ­£ï¼0.973-0.979 èªå¯çï¼çå¯¦é©çµæè­æäº Medico çå·¨å¤§æ½åãå¯ä»¥å¨ https://youtu.be/RtsO6CSesBI æ¾å° Medico çå½±çç¤ºç¯ã

##### **MMCFND: Multimodal Multilingual Caption-aware Fake News Detection for Low-resource Indic Languages**
2410.10407v1 by Shubhi Bansal, Nishit Sushil Singh, Shahid Shafi Dar, Nagendra Kumar

The widespread dissemination of false information through manipulative
tactics that combine deceptive text and images threatens the integrity of
reliable sources of information. While there has been research on detecting
fake news in high resource languages using multimodal approaches, methods for
low resource Indic languages primarily rely on textual analysis. This
difference highlights the need for robust methods that specifically address
multimodal fake news in Indic languages, where the lack of extensive datasets
and tools presents a significant obstacle to progress. To this end, we
introduce the Multimodal Multilingual dataset for Indic Fake News Detection
(MMIFND). This meticulously curated dataset consists of 28,085 instances
distributed across Hindi, Bengali, Marathi, Malayalam, Tamil, Gujarati and
Punjabi. We further propose the Multimodal Multilingual Caption-aware framework
for Fake News Detection (MMCFND). MMCFND utilizes pre-trained unimodal encoders
and pairwise encoders from a foundational model that aligns vision and
language, allowing for extracting deep representations from visual and textual
components of news articles. The multimodal fusion encoder in the foundational
model integrates text and image representations derived from its pairwise
encoders to generate a comprehensive cross modal representation. Furthermore,
we generate descriptive image captions that provide additional context to
detect inconsistencies and manipulations. The retrieved features are then fused
and fed into a classifier to determine the authenticity of news articles. The
curated dataset can potentially accelerate research and development in low
resource environments significantly. Thorough experimentation on MMIFND
demonstrates that our proposed framework outperforms established methods for
extracting relevant fake news detection features.

æè¦ï¼<paragraph>ééçµåå·æ¬ºé¨æ§çæå­ååçï¼ä»¥æå¼ææ³å»£æ³æ£æ­é¯èª¤è³è¨ï¼å¨èå°å¯é è³è¨ä¾æºçå®æ´æ§ãåç®¡æç ç©¶ä½¿ç¨å¤æ¨¡ææ¹æ³åµæ¸¬é«è³æºèªè¨ä¸­çåæ°èï¼ä½ä½è³æºå°åº¦èªè¨çæ¹æ³ä¸»è¦ä¾è³´æå­åæãéç¨®å·®ç°å¸é¡¯äºå°å¥å¨æ¹æ³çéæ±ï¼ç¹å¥æ¯éå°å°åº¦èªè¨çå¤æ¨¡æåæ°èï¼å¶ä¸­ç¼ºä¹å»£æ³çè³æéåå·¥å·å°é²åº¦æ§æéå¤§éç¤ãçºæ­¤ï¼æåå¼å¥äºå°åº¦åæ°èåµæ¸¬çå¤æ¨¡æå¤èªè¨è³æé (MMIFND)ãéåç¶éä»ç´°ç­å±çè³æéåå« 28,085 åæ¡ä¾ï¼åä½å¨å°å°èªãå­å æèªãé¦¬æå°èªãé¦¬æéæå§èªãæ³°ç±³ç¾èªãå¤åæç¹èªåæé®æ®èªãæåé²ä¸æ­¥æåºäºç¨æ¼åæ°èåµæ¸¬çå¤æ¨¡æå¤èªè¨æ¨é¡æç¥æ¡æ¶ (MMCFND)ãMMCFND å©ç¨é åè¨ç·´çå®æ¨¡æç·¨ç¢¼å¨ååºç¤æ¨¡åä¸­çæå°ç·¨ç¢¼å¨ï¼è©²æ¨¡åæå°é½è¦è¦ºåèªè¨ï¼åè¨±å¾æ°èæç« çè¦è¦ºåæå­åä»¶ä¸­æåæ·±åº¦è¡¨å¾µãåºç¤æ¨¡åä¸­çå¤æ¨¡æèåç·¨ç¢¼å¨æ´åäºå¾å¶æå°ç·¨ç¢¼å¨è¡ççæå­ååçè¡¨å¾µï¼ä»¥ç¢çå¨é¢çè·¨æ¨¡æè¡¨å¾µãæ­¤å¤ï¼æåæç¢çæè¿°æ§åçæ¨é¡ï¼æä¾é¡å¤çèçµ¡ä»¥åµæ¸¬ä¸ä¸è´åæå¼ãç¶å¾å°æ·åå°çç¹å¾µèåä¸¦è¼¸å¥åé¡å¨ï¼ä»¥ç¢ºå®æ°èæç« ççå¯¦æ§ãç¶éç­å±çè³æéæå¯è½å¤§å¹å éä½è³æºç°å¢ä¸­çç ç©¶åéç¼ãå¨ MMIFND ä¸çå¾¹åºå¯¦é©è­æï¼æåæåºçæ¡æ¶åªæ¼æ¢å®çæ¹æ³ï¼ç¨æ¼æåç¸éçåæ°èåµæ¸¬ç¹å¾µã</paragraph>

##### **FairMindSim: Alignment of Behavior, Emotion, and Belief in Humans and LLM Agents Amid Ethical Dilemmas**
2410.10398v1 by Yu Lei, Hao Liu, Chengxing Xie, Songjia Liu, Zhiyu Yin, Canyu chen, Guohao Li, Philip Torr, Zhen Wu

AI alignment is a pivotal issue concerning AI control and safety. It should
consider not only value-neutral human preferences but also moral and ethical
considerations. In this study, we introduced FairMindSim, which simulates the
moral dilemma through a series of unfair scenarios. We used LLM agents to
simulate human behavior, ensuring alignment across various stages. To explore
the various socioeconomic motivations, which we refer to as beliefs, that drive
both humans and LLM agents as bystanders to intervene in unjust situations
involving others, and how these beliefs interact to influence individual
behavior, we incorporated knowledge from relevant sociological fields and
proposed the Belief-Reward Alignment Behavior Evolution Model (BREM) based on
the recursive reward model (RRM). Our findings indicate that, behaviorally,
GPT-4o exhibits a stronger sense of social justice, while humans display a
richer range of emotions. Additionally, we discussed the potential impact of
emotions on behavior. This study provides a theoretical foundation for
applications in aligning LLMs with altruistic values.

æè¦ï¼AI å°é½æ¯éæ¼ AI æ§å¶åå®å¨çä¸åæ ¸å¿è­°é¡ãå®ä¸åªæèéå¹å¼ä¸­ç«çäººé¡åå¥½ï¼ä¹æèééå¾·åå«çèéãå¨æ¬ç ç©¶ä¸­ï¼æåå¼å¥äº FairMindSimï¼å®ééä¸ç³»åä¸å¬å¹³æå¢æ¨¡æ¬éå¾·å©é£ãæåä½¿ç¨ LLM ä»£çæ¨¡æ¬äººé¡è¡çºï¼ç¢ºä¿å¨ååéæ®µçä¸è´æ§ãçºäºæ¢ç´¢åç¨®ç¤¾æç¶æ¿åæ©ï¼æåç¨±ä¹çºä¿¡å¿µï¼ï¼éäºåæ©é©ä½¿äººé¡å LLM ä»£çä½çºæè§èä»å¥æ¶åä»äººçä¸å¬æ­£ææ³ï¼ä»¥åéäºä¿¡å¿µå¦ä½äºåä»¥å½±é¿åäººè¡çºï¼æåç´å¥äºç¸éç¤¾æå­¸é åçç¥è­ï¼ä¸¦æ ¹æéè¿´çåµæ¨¡å (RRM) æåºä¿¡å¿µçåµå°é½è¡çºæ¼åæ¨¡å (BREM)ãæåçç¼ç¾è¡¨æï¼å¨è¡çºä¸ï¼GPT-4o è¡¨ç¾åºæ´å¼·ççç¤¾ææ­£ç¾©æï¼èäººé¡åè¡¨ç¾åºæ´è±å¯çæç·ãæ­¤å¤ï¼æåè¨è«äºæç·å°è¡çºçæ½å¨å½±é¿ãæ¬ç ç©¶çºå° LLM èå©ä»å¹å¼è§å°é½çæç¨æä¾äºçè«åºç¤ã

##### **PIVOT-R: Primitive-Driven Waypoint-Aware World Model for Robotic Manipulation**
2410.10394v1 by Kaidong Zhang, Pengzhen Ren, Bingqian Lin, Junfan Lin, Shikui Ma, Hang Xu, Xiaodan Liang

Language-guided robotic manipulation is a challenging task that requires an
embodied agent to follow abstract user instructions to accomplish various
complex manipulation tasks. Previous work trivially fitting the data without
revealing the relation between instruction and low-level executable actions,
these models are prone to memorizing the surficial pattern of the data instead
of acquiring the transferable knowledge, and thus are fragile to dynamic
environment changes. To address this issue, we propose a PrIrmitive-driVen
waypOinT-aware world model for Robotic manipulation (PIVOT-R) that focuses
solely on the prediction of task-relevant waypoints. Specifically, PIVOT-R
consists of a Waypoint-aware World Model (WAWM) and a lightweight action
prediction module. The former performs primitive action parsing and
primitive-driven waypoint prediction, while the latter focuses on decoding
low-level actions. Additionally, we also design an asynchronous hierarchical
executor (AHE), which can use different execution frequencies for different
modules of the model, thereby helping the model reduce computational redundancy
and improve model execution efficiency. Our PIVOT-R outperforms
state-of-the-art (SoTA) open-source models on the SeaWave benchmark, achieving
an average relative improvement of 19.45% across four levels of instruction
tasks. Moreover, compared to the synchronously executed PIVOT-R, the execution
efficiency of PIVOT-R with AHE is increased by 28-fold, with only a 2.9% drop
in performance. These results provide compelling evidence that our PIVOT-R can
significantly improve both the performance and efficiency of robotic
manipulation.

æè¦ï¼<paragraph>èªè¨å°åçæ©å¨äººæä½æ¯ä¸é è±éçä»»åï¼å®è¦æ±å·èº«ä»£çéµå¾ªæ½è±¡ä½¿ç¨èæä»¤ä¾å®æåç¨®è¤éçæä½ä»»åãååçç ç©¶è¼æå°æ¬åè³æï¼èæ²ææ­ç¤ºæä»¤èä½éå¯å·è¡åä½ä¹éçéä¿ï¼éäºæ¨¡åå®¹æè¨ä½è³æçè¡¨é¢æ¨¡å¼ï¼èä¸æ¯ç²å¾å¯è½ç§»çç¥è­ï¼å æ­¤å®¹æåå°åæç°å¢è®åçå½±é¿ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸åç¨æ¼æ©å¨äººæä½çåå§é©åå°èªé»æç¥ä¸çæ¨¡å (PIVOT-R)ï¼å®åå°æ³¨æ¼èä»»åç¸éçå°èªé»çé æ¸¬ãå·é«ä¾èªªï¼PIVOT-R åå«ä¸åå°èªé»æç¥ä¸çæ¨¡å (WAWM) åä¸åè¼éç´åä½é æ¸¬æ¨¡çµãåèå·è¡åå§åä½è§£æååå§é©åå°èªé»é æ¸¬ï¼èå¾èå°æ³¨æ¼è§£ç¢¼ä½éåä½ãæ­¤å¤ï¼æåéè¨­è¨äºä¸åéåæ­¥éå±¤å·è¡å¨ (AHE)ï¼å®å¯ä»¥ä½¿ç¨ä¸åçå·è¡é »çä¾èçæ¨¡åçä¸åæ¨¡çµï¼å¾èå¹«å©æ¨¡åæ¸å°éç®åé¤ä¸¦æé«æ¨¡åå·è¡æçãæåç PIVOT-R å¨ SeaWave åºæºæ¸¬è©¦ä¸­åªæ¼æåé² (SoTA) çéæºæ¨¡åï¼å¨ååå±¤ç´çæä»¤ä»»åä¸­å¹³åç¸å°æ¹åäº 19.45%ãæ­¤å¤ï¼èåæ­¥å·è¡ç PIVOT-R ç¸æ¯ï¼ä½¿ç¨ AHE ç PIVOT-R å·è¡æçæé«äº 28 åï¼æè½åä¸éäº 2.9%ãéäºçµææä¾äºä»¤äººä¿¡æçè­æï¼è­ææåç PIVOT-R å¯ä»¥é¡¯èæé«æ©å¨äººæä½çæè½åæçã</paragraph>

##### **Optimizing Instruction Synthesis: Effective Exploration of Evolutionary Space with Tree Search**
2410.10392v1 by Chenglin Li, Qianglong Chen, Zhi Li, Feng Tao, Yicheng Li, Hao Chen, Fei Yu, Yin Zhang

Instruction tuning is a crucial technique for aligning language models with
humans' actual goals in the real world. Extensive research has highlighted the
quality of instruction data is essential for the success of this alignment.
However, creating high-quality data manually is labor-intensive and
time-consuming, which leads researchers to explore using LLMs to synthesize
data. Recent studies have focused on using a stronger LLM to iteratively
enhance existing instruction data, showing promising results. Nevertheless,
previous work often lacks control over the evolution direction, resulting in
high uncertainty in the data synthesis process and low-quality instructions. In
this paper, we introduce a general and scalable framework, IDEA-MCTS
(Instruction Data Enhancement using Monte Carlo Tree Search), a scalable
framework for efficiently synthesizing instructions. With tree search and
evaluation models, it can efficiently guide each instruction to evolve into a
high-quality form, aiding in instruction fine-tuning. Experimental results show
that IDEA-MCTS significantly enhances the seed instruction data, raising the
average evaluation scores of quality, diversity, and complexity from 2.19 to
3.81. Furthermore, in open-domain benchmarks, experimental results show that
IDEA-MCTS improves the accuracy of real-world instruction-following skills in
LLMs by an average of 5\% in low-resource settings.

æè¦ï¼æä»¤èª¿æ´æ¯è®èªè¨æ¨¡åèäººé¡å¨ç¾å¯¦ä¸çä¸­çå¯¦éç®æ¨ä¿æä¸è´çééµæè¡ãå»£æ³çç ç©¶å¼·èª¿äºæä»¤æ¸æçåè³ªå°æ¼æ­¤èª¿æ´çæåè³ééè¦ãç¶èï¼æåå»ºç«é«åè³ªçæ¸æéè¦å¤§éäººåä¸èæï¼éä¿ä½¿ç ç©¶äººå¡æ¢ç´¢ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾åææ¸æãæè¿çç ç©¶å°æ³¨æ¼ä½¿ç¨ä¸åæ´å¼·å¤§ç LLM ä¾åè¦å¢å¼·ç¾æçæä»¤æ¸æï¼ä¸¦é¡¯ç¤ºåºæå¸æççµæãåç®¡å¦æ­¤ï¼ååçç ç©¶éå¸¸ç¼ºä¹å°æ¼åæ¹åçæ§å¶ï¼å°è´æ¸æåæéç¨çä¸ç¢ºå®æ§é«ä¸æä»¤åè³ªä½ãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸åéç¨ä¸å¯æ´åçæ¶æ§ IDEA-MCTSï¼ä½¿ç¨èå°å¡ç¾æ¨¹æå°çæä»¤æ¸æå¢å¼·ï¼ï¼ä¸åç¨æ¼ææåææä»¤çå¯æ´åæ¶æ§ãééæ¨¹çæå°åè©ä¼°æ¨¡åï¼å®å¯ä»¥ææå¼å°æ¯åæä»¤æ¼åçºé«åè³ªçå½¢å¼ï¼æå©æ¼æä»¤å¾®èª¿ãå¯¦é©çµæé¡¯ç¤º IDEA-MCTS å¤§å¹å¢å¼·äºç¨®å­æä»¤æ¸æï¼å°åè³ªãå¤æ¨£æ§åè¤éæ§çå¹³åè©åå¾ 2.19 æåè³ 3.81ãæ­¤å¤ï¼å¨éæ¾é ååºæºæ¸¬è©¦ä¸­ï¼å¯¦é©çµæé¡¯ç¤º IDEA-MCTS å¨ä½è³æºè¨­å®ä¸­å° LLM ä¸­å¯¦éæä»¤éµå¾ªæè½çæºç¢ºåº¦å¹³åæé«äº 5%ã

##### **BookWorm: A Dataset for Character Description and Analysis**
2410.10372v1 by Argyrios Papoudakis, Mirella Lapata, Frank Keller

Characters are at the heart of every story, driving the plot and engaging
readers. In this study, we explore the understanding of characters in
full-length books, which contain complex narratives and numerous interacting
characters. We define two tasks: character description, which generates a brief
factual profile, and character analysis, which offers an in-depth
interpretation, including character development, personality, and social
context. We introduce the BookWorm dataset, pairing books from the Gutenberg
Project with human-written descriptions and analyses. Using this dataset, we
evaluate state-of-the-art long-context models in zero-shot and fine-tuning
settings, utilizing both retrieval-based and hierarchical processing for
book-length inputs. Our findings show that retrieval-based approaches
outperform hierarchical ones in both tasks. Additionally, fine-tuned models
using coreference-based retrieval produce the most factual descriptions, as
measured by fact- and entailment-based metrics. We hope our dataset,
experiments, and analysis will inspire further research in character-based
narrative understanding.

æè¦ï¼è§è²æ¯æ¯åæäºçæ ¸å¿ï¼æ¨åæç¯ç¼å±ä¸¦å¸å¼è®èãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨äºå°å¨æ¸ä¸­è§è²ççè§£ï¼éäºæ¸åå«è¤éçæè¿°åç¾å¤äºåè§è²ãæåå®ç¾©äºå©é ä»»åï¼è§è²æè¿°ï¼å®æç¢çç°¡ç­çäºå¯¦ç°¡ä»ï¼ä»¥åè§è²åæï¼å®æä¾äºæ·±å¥çè©®éï¼åæ¬è§è²ç¼å±ãåæ§ä»¥åç¤¾æèæ¯ãæåå¼å¥äº BookWorm è³æéï¼å°å¤é¨°å ¡è¨ç«ä¸­çæ¸ç±èäººé¡æ°å¯«çæè¿°ååæéå°ãä½¿ç¨æ­¤è³æéï¼æåå¨é¶æ¬¡å­¸ç¿åå¾®èª¿è¨­å®ä¸­è©ä¼°äºæåé²çé·èªå¢æ¨¡åï¼å©ç¨åºæ¼æª¢ç´¢åéå±¤å¼èççæ¸é·è¼¸å¥ãæåçç ç©¶çµæè¡¨æï¼åºæ¼æª¢ç´¢çæ¹æ³å¨å©é ä»»åä¸­é½åªæ¼éå±¤å¼æ¹æ³ãæ­¤å¤ï¼ä½¿ç¨åºæ¼å±æçæª¢ç´¢é²è¡å¾®èª¿çæ¨¡åæç¢çæç¬¦åäºå¯¦çæè¿°ï¼éæ¯æ ¹æåºæ¼äºå¯¦åèæ¶µçææ¨æ¸¬éçãæåå¸ææåçè³æéãå¯¦é©ååæè½æ¿åµå¨åºæ¼è§è²çæäºçè§£æ¹é¢çé²ä¸æ­¥ç ç©¶ã

##### **Innovative Thinking, Infinite Humor: Humor Research of Large Language Models through Structured Thought Leaps**
2410.10370v1 by Han Wang, Yilin Zhao, Dian Li, Xiaohan Wang, Gang Liu, Xuguang Lan, Hui Wang

Humor is a culturally nuanced aspect of human language that presents
challenges for understanding and generation, requiring participants to possess
good creativity and strong associative thinking. Similar to reasoning tasks
like solving math problems, humor generation requires continuous reflection and
revision to foster creative thinking, rather than relying on a sudden flash of
inspiration like Creative Leap-of-Thought (CLoT) paradigm. Although CLoT can
realize the ability of remote association generation, this paradigm fails to
generate humor content. Therefore, in this paper, we propose a systematic way
of thinking about generating humor and based on it, we built Creative Leap of
Structured Thought (CLoST) frame. First, a reward model is necessary achieve
the purpose of being able to correct errors, since there is currently no expert
model of humor and a usable rule to determine whether a piece of content is
humorous. Judgement-oriented instructions are designed to improve the
capability of a model, and we also propose an open-domain instruction
evolutionary method to fully unleash the potential. Then, through reinforcement
learning, the model learns to hone its rationales of the thought chain and
refine the strategies it uses. Thus, it learns to recognize and correct its
mistakes, and finally generate the most humorous and creative answer. These
findings deepen our understanding of the creative capabilities of LLMs and
provide ways to enhance LLMs' creative abilities for cross-domain innovative
applications.

æè¦ï¼å¹½é»æ¯äººé¡èªè¨ä¸­æåç´°å¾®å·®å¥çä¸é¢ï¼å°çè§£åç¢çæåºææ°ï¼éè¦åèèå·åè¯å¥½çåµé ååå¼·ççè¯æ³æç¶­ãé¡ä¼¼æ¼æ±è§£æ¸å­¸åé¡ç­æ¨çä»»åï¼å¹½é»ç¢çéè¦æçºçåæåä¿®æ­£ï¼ä»¥å¹é¤åµé æ§æç¶­ï¼èä¸æ¯ä¾è³´æ¼ååµé æ§é£èºæèï¼CLoTï¼ç¯ä¾é£æ¨£ççªç¶éæãåç®¡ CLoT å¯ä»¥å¯¦ç¾é ç¨è¯æ³ç¢ççè½åï¼ä½éç¨®ç¯ä¾ç¡æ³ç¢çå¹½é»å§å®¹ãå æ­¤ï¼å¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®ç³»çµ±æ§çæèæ¹å¼ä¾ç¢çå¹½é»ï¼ä¸¦åºæ¼æ­¤ï¼æåå»ºç«äºçµæ§åææ³åµé æ§é£èºï¼CLoSTï¼æ¡æ¶ãé¦åï¼ä¸åçåµæ¨¡åå°æ¼è½å¤ ç³¾æ­£é¯èª¤æ¯å¿è¦çï¼å çºç®åæ²æå¹½é»å°å®¶æ¨¡ååå¯ç¨è¦åä¾ç¢ºå®ä¸æ®µå§å®¹æ¯å¦å¹½é»ãé¢åå¤æ·çæä»¤æ¨å¨æé«æ¨¡åçè½åï¼æåéæåºäºä¸åéæ¾åæä»¤æ¼åæ¹æ³ï¼ä»¥ååç¼æ®å¶æ½åãç¶å¾ï¼ééå¼·åå­¸ç¿ï¼æ¨¡åå­¸æç£¨ç·´å¶ææ³éçä¾æä¸¦æ¹é²å¶ä½¿ç¨çç­ç¥ãå æ­¤ï¼å®å­¸æäºè­å¥åç³¾æ­£å¶é¯èª¤ï¼ä¸¦æçµç¢çæå¹½é»åæå·åµé åçç­æ¡ãéäºç¼ç¾å æ·±äºæåå° LLM åµé è½åççè§£ï¼ä¸¦æä¾äºå¢å¼· LLM çè·¨é ååµæ°æç¨åµé è½åçæ¹æ³ã

##### **Affinity-Graph-Guided Contractive Learning for Pretext-Free Medical Image Segmentation with Minimal Annotation**
2410.10366v1 by Zehua Cheng, Di Yuan, Thomas Lukasiewicz

The combination of semi-supervised learning (SemiSL) and contrastive learning
(CL) has been successful in medical image segmentation with limited
annotations. However, these works often rely on pretext tasks that lack the
specificity required for pixel-level segmentation, and still face overfitting
issues due to insufficient supervision signals resulting from too few
annotations. Therefore, this paper proposes an affinity-graph-guided
semi-supervised contrastive learning framework (Semi-AGCL) by establishing
additional affinity-graph-based supervision signals between the student and
teacher network, to achieve medical image segmentation with minimal annotations
without pretext. The framework first designs an average-patch-entropy-driven
inter-patch sampling method, which can provide a robust initial feature space
without relying on pretext tasks. Furthermore, the framework designs an
affinity-graph-guided loss function, which can improve the quality of the
learned representation and the model generalization ability by exploiting the
inherent structure of the data, thus mitigating overfitting. Our experiments
indicate that with merely 10% of the complete annotation set, our model
approaches the accuracy of the fully annotated baseline, manifesting a marginal
deviation of only 2.52%. Under the stringent conditions where only 5% of the
annotations are employed, our model exhibits a significant enhancement in
performance surpassing the second best baseline by 23.09% on the dice metric
and achieving an improvement of 26.57% on the notably arduous CRAG and ACDC
datasets.

æè¦ï¼åçç£å­¦ä¹  (SemiSL) åå¯¹æ¯å­¦ä¹  (CL) çç»åå·²æåç¨äºå»çå¾ååå²ï¼ä¸æ æ³¨æéãç¶èï¼è¿äºå·¥ä½éå¸¸ä¾èµäºç¼ºä¹åç´ çº§åå²æéç¹å¼æ§çåå£ä»»å¡ï¼å¹¶ä¸ç±äºæ æ³¨å¤ªå°å¯¼è´çç£ä¿¡å·ä¸è¶³ï¼ä»ç¶é¢ä¸´è¿åº¦æåé®é¢ãå æ­¤ï¼æ¬æéè¿å¨å­¦çç½ç»åæå¸ç½ç»ä¹é´å»ºç«åºäºäº²åå¾çéå çç£ä¿¡å·ï¼æåºäºä¸ç§äº²åå¾å¼å¯¼çåçç£å¯¹æ¯å­¦ä¹ æ¡æ¶ (Semi-AGCL)ï¼ä»¥å¨æ²¡æåå£çæåµä¸å®ç°å»çå¾ååå²ï¼ä¸æ æ³¨æå°ãè¯¥æ¡æ¶é¦åè®¾è®¡äºä¸ç§å¹³åè¡¥ä¸çµé©±å¨çè¡¥ä¸é´éæ ·æ¹æ³ï¼è¯¥æ¹æ³å¯ä»¥å¨ä¸ä¾èµåå£ä»»å¡çæåµä¸æä¾é²æ£çåå§ç¹å¾ç©ºé´ãæ­¤å¤ï¼è¯¥æ¡æ¶è®¾è®¡äºä¸ä¸ªäº²åå¾å¼å¯¼çæå¤±å½æ°ï¼è¯¥å½æ°å¯ä»¥éè¿å©ç¨æ°æ®çåºæç»ææ¥æé«å­¦ä¹ è¡¨ç¤ºåæ¨¡åæ³åè½åï¼ä»èåè½»è¿åº¦æåãæä»¬çå®éªè¡¨æï¼æä»¬çæ¨¡åä»ä½¿ç¨ 10% çå®æ´æ æ³¨éï¼å°±æ¥è¿äºå®å¨æ æ³¨åºåçåç¡®åº¦ï¼ä»æ 2.52% çè¾¹éåå·®ãå¨ä»ä½¿ç¨ 5% æ æ³¨çä¸¥æ ¼æ¡ä»¶ä¸ï¼æä»¬çæ¨¡åå¨æ§è½ä¸è¡¨ç°åºæ¾çæåï¼å¨éª°å­ææ ä¸æ¯ç¬¬äºå¥½çåºåé«åº 23.09%ï¼å¹¶å¨éå¸¸è°å·¨ç CRAG å ACDC æ°æ®éä¸æé«äº 26.57%ã

##### **SpeGCL: Self-supervised Graph Spectrum Contrastive Learning without Positive Samples**
2410.10365v1 by Yuntao Shou, Xiangyong Cao, Deyu Meng

Graph Contrastive Learning (GCL) excels at managing noise and fluctuations in
input data, making it popular in various fields (e.g., social networks, and
knowledge graphs). Our study finds that the difference in high-frequency
information between augmented graphs is greater than that in low-frequency
information. However, most existing GCL methods focus mainly on the time domain
(low-frequency information) for node feature representations and cannot make
good use of high-frequency information to speed up model convergence.
Furthermore, existing GCL paradigms optimize graph embedding representations by
pulling the distance between positive sample pairs closer and pushing the
distance between positive and negative sample pairs farther away, but our
theoretical analysis shows that graph contrastive learning benefits from
pushing negative pairs farther away rather than pulling positive pairs closer.
To solve the above-mentioned problems, we propose a novel spectral GCL
framework without positive samples, named SpeGCL. Specifically, to solve the
problem that existing GCL methods cannot utilize high-frequency information,
SpeGCL uses a Fourier transform to extract high-frequency and low-frequency
information of node features, and constructs a contrastive learning mechanism
in a Fourier space to obtain better node feature representation. Furthermore,
SpeGCL relies entirely on negative samples to refine the graph embedding. We
also provide a theoretical justification for the efficacy of using only
negative samples in SpeGCL. Extensive experiments on un-supervised learning,
transfer learning, and semi-supervised learning have validated the superiority
of our SpeGCL framework over the state-of-the-art GCL methods.

æè¦ï¼åå½¢å°æ¯å­¸ç¿ (GCL) æé·èçè¼¸å¥è³æä¸­çéè¨åæ³¢åï¼ä½¿å¶å¨åç¨®é åï¼ä¾å¦ç¤¾ç¾¤ç¶²è·¯åç¥è­åè­ï¼ä¸­æ®åãæåçç ç©¶ç¼ç¾ï¼æ´ååå½¢ä¸­é«é »è³è¨çå·®ç°å¤§æ¼ä½é »è³è¨çå·®ç°ãç¶èï¼ç¾æç GCL æ¹æ³å¤§å¤ä¸»è¦éæ³¨æéåï¼ä½é »è³è¨ï¼çç¯é»ç¹å¾µè¡¨ç¤ºï¼ç¡æ³ååå©ç¨é«é »è³è¨ä¾å éæ¨¡åæ¶æãæ­¤å¤ï¼ç¾æç GCL å¸ç¯ééæè¿æ­£æ¨£æ¬å°ä¹éçè·é¢ä¸¦æ¨éæ­£æ¨£æ¬å°åè² æ¨£æ¬å°ä¹éçè·é¢ä¾æä½³ååå½¢åµå¥è¡¨ç¤ºï¼ä½æåççè«åæè¡¨æï¼åå½¢å°æ¯å­¸ç¿åçæ¼å°è² æ¨£æ¬å°æ¨å¾æ´é ï¼èä¸æ¯å°æ­£æ¨£æ¬å°æå¾æ´è¿ãçºäºè§£æ±ºä¸è¿°åé¡ï¼æåæåºäºä¸åæ²ææ­£æ¨£æ¬çæ°ç©åè­ GCL æ¶æ§ï¼ç¨±çº SpeGCLãå·é«ä¾èªªï¼çºäºè§£æ±ºç¾æç GCL æ¹æ³ç¡æ³å©ç¨é«é »è³è¨çåé¡ï¼SpeGCL ä½¿ç¨åç«èè½æä¾æåç¯é»ç¹å¾µçé«é »åä½é »è³è¨ï¼ä¸¦å¨åç«èç©ºéä¸­å»ºæ§ä¸åå°æ¯å­¸ç¿æ©å¶ï¼ä»¥ç²å¾æ´å¥½çç¯é»ç¹å¾µè¡¨ç¤ºãæ­¤å¤ï¼SpeGCL å®å¨ä¾è³´è² æ¨£æ¬ä¾æ¹ååå½¢åµå¥ãæåä¹æä¾äºåå¨ SpeGCL ä¸­ä½¿ç¨è² æ¨£æ¬çæææ§ççè«ä¾æãå¨ç¡ç£ç£å­¸ç¿ãè½ç§»å­¸ç¿ååç£ç£å­¸ç¿ä¸çå»£æ³å¯¦é©é©è­äºæåç SpeGCL æ¶æ§åªæ¼æåé²ç GCL æ¹æ³ã

##### **Parenting: Optimizing Knowledge Selection of Retrieval-Augmented Language Models with Parameter Decoupling and Tailored Tuning**
2410.10360v1 by Yongxin Xu, Ruizhe Zhang, Xinke Jiang, Yujie Feng, Yuzhen Xiao, Xinyu Ma, Runchuan Zhu, Xu Chu, Junfeng Zhao, Yasha Wang

Retrieval-Augmented Generation (RAG) offers an effective solution to the
issues faced by Large Language Models (LLMs) in hallucination generation and
knowledge obsolescence by incorporating externally retrieved knowledge.
However, due to potential conflicts between internal and external knowledge, as
well as retrieval noise, LLMs often struggle to effectively integrate external
evidence, leading to a decline in performance. Although existing methods
attempt to tackle these challenges, they often struggle to strike a balance
between model adherence and robustness, resulting in significant learning
variance. Inspired by human cognitive processes, we propose Parenting, a novel
framework that decouples adherence and robustness within the parameter space of
LLMs. Specifically, Parenting utilizes a key parameter mining method based on
forward activation gain to identify and isolate the crucial parameter units
that are strongly linked to adherence and robustness. Then, Parenting employs a
type-guided tailored tuning strategy, applying specific and appropriate
fine-tuning methods to parameter units representing different capabilities,
aiming to achieve a balanced enhancement of adherence and robustness. Extensive
experiments on various datasets and models validate the effectiveness and
generalizability of our methods.

æè¦ï¼æ£ç´¢å¢å¼ºçæ (RAG) æä¾äºä¸ä¸ªææçè§£å³æ¹æ¡ï¼ç¨äºè§£å³å¤§åè¯­è¨æ¨¡å (LLM) å¨å¹»è§çæåç¥è¯è¿æ¶æ¹é¢é¢ä¸´çé®é¢ï¼æ¹æ³æ¯ç»åå¤é¨æ£ç´¢çç¥è¯ãç¶èï¼ç±äºåé¨åå¤é¨ç¥è¯ä¹é´æ½å¨çå²çªï¼ä»¥åæ£ç´¢åªå£°ï¼LLM ç»å¸¸é¾ä»¥ææå°æ´åå¤é¨è¯æ®ï¼ä»èå¯¼è´æ§è½ä¸éãè½ç¶ç°ææ¹æ³è¯å¾è§£å³è¿äºææï¼ä½å®ä»¬å¾å¾é¾ä»¥å¨æ¨¡åçä¾ä»æ§åé²æ£æ§ä¹é´åå¾å¹³è¡¡ï¼ä»èå¯¼è´ä¸¥éçå­¦ä¹ å·®å¼ãåäººç±»è®¤ç¥è¿ç¨çå¯åï¼æä»¬æåºäº Parentingï¼è¿æ¯ä¸ä¸ªæ°é¢çæ¡æ¶ï¼å®å¨ LLM çåæ°ç©ºé´åè§£è¦äºä¾ä»æ§åé²æ£æ§ãå·ä½æ¥è¯´ï¼Parenting å©ç¨äºä¸ç§åºäºååæ¿æ´»å¢ççå³é®åæ°æææ¹æ³æ¥è¯å«åéç¦»ä¸ä¾ä»æ§åé²æ£æ§å¯åç¸å³çå³é®åæ°ååãç¶åï¼Parenting éç¨ç±»åæå¯¼çå®å¶è°æ´ç­ç¥ï¼å¯¹ä»£è¡¨ä¸ååè½çåæ°åååºç¨ç¹å®ä¸éå½çå¾®è°æ¹æ³ï¼æ¨å¨å®ç°ä¾ä»æ§åé²æ£æ§çå¹³è¡¡å¢å¼ºãå¨åç§æ°æ®éåæ¨¡åä¸çå¹¿æ³å®éªéªè¯äºæä»¬æ¹æ³çæææ§åæ³åæ§ã

##### **LLM-based Code-Switched Text Generation for Grammatical Error Correction**
2410.10349v1 by Tom Potter, Zheng Yuan

With the rise of globalisation, code-switching (CSW) has become a ubiquitous
part of multilingual conversation, posing new challenges for natural language
processing (NLP), especially in Grammatical Error Correction (GEC). This work
explores the complexities of applying GEC systems to CSW texts. Our objectives
include evaluating the performance of state-of-the-art GEC systems on an
authentic CSW dataset from English as a Second Language (ESL) learners,
exploring synthetic data generation as a solution to data scarcity, and
developing a model capable of correcting grammatical errors in monolingual and
CSW texts. We generated synthetic CSW GEC data, resulting in one of the first
substantial datasets for this task, and showed that a model trained on this
data is capable of significant improvements over existing systems. This work
targets ESL learners, aiming to provide educational technologies that aid in
the development of their English grammatical correctness without constraining
their natural multilingualism.

æè¦ï¼é¨èå¨çåçèèµ·ï¼ä»£ç¢¼åæï¼CSWï¼å·²æçºå¤èªè¨å°è©±ä¸­æ®éå­å¨çä¸é¨åï¼å°èªç¶èªè¨èçï¼NLPï¼æåºäºæ°çææ°ï¼ç¹å¥æ¯å¨èªæ³é¯èª¤æ ¡æ­£ï¼GECï¼ä¸­ãéé å·¥ä½æ¢è¨äºå° GEC ç³»çµ±æç¨æ¼ CSW ææ¬çè¤éæ§ãæåçç®æ¨åæ¬è©ä¼°æåé²ç GEC ç³»çµ±å¨ä»¥è±èªçºç¬¬äºèªè¨ï¼ESLï¼å­¸ç¿èççå¯¦ CSW æ¸æéä¸çæ§è½ï¼æ¢ç´¢åææ¸æçæä½çºè§£æ±ºæ¸æç¨ç¼ºçè§£æ±ºæ¹æ¡ï¼ä»¥åéç¼ä¸ç¨®è½å¤ æ ¡æ­£å®èªå CSW ææ¬ä¸­èªæ³é¯èª¤çæ¨¡åãæåçæäºåæ CSW GEC æ¸æï¼æ§æäºæ­¤ä»»åçç¬¬ä¸æ¹å¯¦è³ªæ§æ¸æéä¹ä¸ï¼ä¸¦è¡¨æå¨éäºæ¸æä¸è¨ç·´çæ¨¡åè½å¤ æ¯ç¾æç³»çµ±é¡¯èæ¹é²ãéé å·¥ä½éå° ESL å­¸ç¿èï¼æ¨å¨æä¾æè²æè¡ï¼å¨ä¸éå¶å¶èªç¶å¤èªè¨è½åçææ³ä¸ï¼å¹«å©ä»åç¼å±è±èªèªæ³æ­£ç¢ºæ§ã

##### **Augmenting In-Context-Learning in LLMs via Automatic Data Labeling and Refinement**
2410.10348v1 by Joseph Shtok, Amit Alfassy, Foad Abo Dahood, Eliyahu Schwartz, Sivan Doveh, Assaf Arbelle

It has been shown that Large Language Models' (LLMs) performance can be
improved for many tasks using Chain of Thought (CoT) or In-Context Learning
(ICL), which involve demonstrating the steps needed to solve a task using a few
examples. However, while datasets with input-output pairs are relatively easy
to produce, providing demonstrations which include intermediate steps requires
cumbersome manual work. These steps may be executable programs, as in agentic
flows, or step-by-step reasoning as in CoT. In this work, we propose Automatic
Data Labeling and Refinement (ADLR), a method to automatically generate and
filter demonstrations which include the above intermediate steps, starting from
a small seed of manually crafted examples. We demonstrate the advantage of ADLR
in code-based table QA and mathematical reasoning, achieving up to a 5.5% gain.
The code implementing our method is provided in the Supplementary material and
will be made available.

æè¦ï¼ç ç©¶è¡¨æï¼ééææ³éï¼CoTï¼ææå¢å­¸ç¿ï¼ICLï¼å¯ä»¥æ¹åå¤§åèªè¨æ¨¡åï¼LLMï¼çè¨±å¤ä»»åè¡¨ç¾ï¼éæ¶åå±ç¤ºä½¿ç¨å¹¾åç¯ä¾è§£æ±ºä»»åæéçæ­¥é©ãç¶èï¼éç¶å·æè¼¸å¥è¼¸åºéå°çè³æéç¸å°å®¹æç¢çï¼ä½æä¾åå«ä¸­éæ­¥é©çç¯ä¾éè¦ç¹ç£çæåå·¥ä½ãéäºæ­¥é©å¯è½æ¯å¯å·è¡ç¨å¼ï¼ä¾å¦ä»£çæµç¨ï¼æå¦ CoT ä¸­çéæ­¥æ¨çãå¨éé å·¥ä½ä¸­ï¼æåæåºèªåè³ææ¨è¨åç²¾çï¼ADLRï¼ï¼éæ¯ä¸ç¨®æ¹æ³ï¼å¯ä»¥å¾å°éæåè£½ä½ç¯ä¾éå§ï¼èªåç¢çåéæ¿¾åå«ä¸è¿°ä¸­éæ­¥é©çç¯ä¾ãæåå¨åºæ¼ç¨å¼ç¢¼çè¡¨æ ¼åç­åæ¸å­¸æ¨çä¸­å±ç¤ºäº ADLR çåªé»ï¼ç²å¾äºé«é 5.5% çå¢çãå¯¦ä½æåæ¹æ³çç¨å¼ç¢¼æä¾å¨è£åè³æä¸­ï¼ä¸¦å°å¬éã

##### **A Unified Approach to Routing and Cascading for LLMs**
2410.10347v1 by Jasper Dekoninck, Maximilian Baader, Martin Vechev

The widespread applicability of large language models (LLMs) has increased
the availability of many fine-tuned models of various sizes targeting specific
tasks. Given a set of such specialized models, to maximize overall performance,
it is important to figure out the optimal strategy for selecting the right
model for a given user query. An effective strategy could drastically increase
overall performance and even offer improvements over a single large monolithic
model. Existing approaches typically fall into two categories: routing, where a
single model is selected for each query, and cascading, which runs a sequence
of increasingly larger models until a satisfactory answer is obtained. However,
both have notable limitations: routing commits to an initial model without
flexibility, while cascading requires executing every model in sequence, which
can be inefficient. Additionally, the conditions under which these strategies
are provably optimal remain unclear. In this work, we derive optimal strategies
for both routing and cascading. Building on this analysis, we propose a novel
approach called cascade routing, which combines the adaptability of routing
with the cost-efficiency of cascading. Our experiments demonstrate that cascade
routing consistently outperforms both routing and cascading across a variety of
settings, improving both output quality and lowering computational cost, thus
offering a unified and efficient solution to the model selection problem.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çå»£æ³æç¨æ§æé«äºåç¨®å°ºå¯¸çè¨±å¤å¾®èª¿æ¨¡åçå¯ç¨æ§ï¼éäºæ¨¡åéå°ç¹å®ä»»åãçµ¦å®ä¸çµéæ¨£çå°æ¥­æ¨¡åï¼çºäºæå¤§åæ´é«æè½ï¼æ¾åºçºç¹å®ä½¿ç¨èæ¥è©¢é¸ææ­£ç¢ºæ¨¡åçæä½³ç­ç¥éå¸¸éè¦ãä¸åææçç­ç¥å¯ä»¥å¤§å¹æåæ´é«æè½ï¼çè³æ¯å®ä¸å¤§åå®é«æ¨¡åææ´å¥½çè¡¨ç¾ãç¾æçæ¹æ³éå¸¸åçºå©é¡ï¼è·¯ç±ï¼å¶ä¸­çºæ¯åæ¥è©¢é¸æä¸åæ¨¡åï¼ä¸²è¯ï¼å¶ä¸­å·è¡ä¸ç³»åè¶ä¾è¶å¤§çæ¨¡åï¼ç´å°ç²å¾ä»¤äººæ»¿æçç­æ¡ãç¶èï¼éå©ç¨®æ¹æ³é½æé¡¯èçéå¶ï¼è·¯ç±å¨æ²æå½æ§çææ³ä¸æ¿è«¾ä½¿ç¨ä¸ååå§æ¨¡åï¼èä¸²è¯éè¦æé åºå·è¡æ¯åæ¨¡åï¼éå¯è½æå¾æ²ææçãæ­¤å¤ï¼éäºç­ç¥å¨åªäºæ¢ä»¶ä¸å¯ä»¥è­ææ¯æä½³çä»ç¶ä¸æ¸æ¥ãå¨éé å·¥ä½ä¸­ï¼æåæ¨å°åºè·¯ç±åä¸²è¯çæä½³ç­ç¥ãå¨æ­¤åæçåºç¤ä¸ï¼æåæåºäºä¸ç¨®ç¨±çºä¸²è¯è·¯ç±çæ°æ¹æ³ï¼å®çµåäºè·¯ç±çé©ææ§åä¸²è¯çææ¬æçãæåçå¯¦é©è¡¨æï¼ä¸²è¯è·¯ç±å¨åç¨®è¨­å®ä¸­é½æçºåªæ¼è·¯ç±åä¸²è¯ï¼æ¢æé«äºè¼¸åºåè³ªï¼åéä½äºéç®ææ¬ï¼å¾èçºæ¨¡åé¸æåé¡æä¾äºä¸åçµ±ä¸ä¸ææçè§£æ±ºæ¹æ¡ã

##### **Locking Down the Finetuned LLMs Safety**
2410.10343v1 by Minjun Zhu, Linyi Yang, Yifan Wei, Ningyu Zhang, Yue Zhang

Fine-tuning large language models (LLMs) on additional datasets is often
necessary to optimize them for specific downstream tasks. However, existing
safety alignment measures, which restrict harmful behavior during inference,
are insufficient to mitigate safety risks during fine-tuning. Alarmingly,
fine-tuning with just 10 toxic sentences can make models comply with harmful
instructions. We introduce SafetyLock, a novel alignment intervention method
that maintains robust safety post-fine-tuning through efficient and
transferable mechanisms. SafetyLock leverages our discovery that fine-tuned
models retain similar safety-related activation representations to their base
models. This insight enables us to extract what we term the Meta-SafetyLock, a
set of safety bias directions representing key activation patterns associated
with safe responses in the original model. We can then apply these directions
universally to fine-tuned models to enhance their safety. By searching for
activation directions across multiple token dimensions, SafetyLock achieves
enhanced robustness and transferability. SafetyLock re-aligns fine-tuned models
in under 0.01 seconds without additional computational cost. Our experiments
demonstrate that SafetyLock can reduce the harmful instruction response rate
from 60% to below 1% in toxic fine-tuned models. It surpasses traditional
methods in both performance and efficiency, offering a scalable, non-invasive
solution for ensuring the safety of customized LLMs. Our analysis across
various fine-tuning scenarios confirms SafetyLock's robustness, advocating its
integration into safety protocols for aligned LLMs. The code is released at
https://github.com/zhu-minjun/SafetyLock.

æè¦ï¼å¾®è°å¤§åè¯­è¨æ¨¡å (LLM) ä»¥ç¨äºå¶ä»æ°æ®ééå¸¸æå¿è¦éå¯¹ç¹å®ä¸æ¸¸ä»»å¡å¯¹å¶è¿è¡ä¼åãç¶èï¼ç°æçå®å¨å¯¹é½æªæ½ï¼å¨æ¨çæé´éå¶æå®³è¡ä¸ºï¼ä¸è¶³ä»¥åè½»å¾®è°æé´çå®å¨é£é©ãä»¤äººæå¿§çæ¯ï¼ä»ä½¿ç¨ 10 ä¸ªææ¯å¥å­è¿è¡å¾®è°å°±è½ä½¿æ¨¡åéµå®æå®³æä»¤ãæä»¬å¼å¥äº SafetyLockï¼è¿æ¯ä¸ç§æ°é¢çå¯¹é½å¹²é¢æ¹æ³ï¼éè¿é«æä¸å¯è½¬ç§»çæºå¶å¨å¾®è°åä¿æå¼ºå¤§çå®å¨æ§ãSafetyLock å©ç¨äºæä»¬åç°å¾®è°æ¨¡åä¿çäºä¸å¶åºç¡æ¨¡åç±»ä¼¼çå®å¨ç¸å³æ¿æ´»è¡¨ç¤ºãè¿ä¸è§è§£ä½¿æä»¬è½å¤æåæä»¬ç§°ä¹ä¸º Meta-SafetyLock çä¸è¥¿ï¼è¿æ¯ä¸ç»å®å¨åå·®æ¹åï¼ä»£è¡¨ä¸åå§æ¨¡åä¸­çå®å¨ååºç¸å³èçå³é®æ¿æ´»æ¨¡å¼ãç¶åï¼æä»¬å¯ä»¥å°è¿äºæ¹åæ®éåºç¨äºå¾®è°æ¨¡åä»¥å¢å¼ºå¶å®å¨æ§ãéè¿å¨å¤ä¸ªæ è®°ç»´åº¦ä¸æç´¢æ¿æ´»æ¹åï¼SafetyLock å®ç°äºå¢å¼ºçé²æ£æ§åå¯è½¬ç§»æ§ãSafetyLock å¨ä¸å° 0.01 ç§çæ¶é´åéæ°å¯¹é½å¾®è°æ¨¡åï¼èæ éé¢å¤çè®¡ç®ææ¬ãæä»¬çå®éªè¡¨æï¼SafetyLock å¯ä»¥å°æå®³æä»¤ååºçä» 60% éä½å°ææ¯å¾®è°æ¨¡åä¸­ç 1% ä»¥ä¸ãå®å¨æ§è½åæçæ¹é¢é½è¶è¶äºä¼ ç»æ¹æ³ï¼ä¸ºç¡®ä¿å®å¶ LLM çå®å¨æ§æä¾äºä¸ä¸ªå¯æ©å±çãéä¾µå¥æ§çè§£å³æ¹æ¡ãæä»¬å¯¹åç§å¾®è°åºæ¯çåæè¯å®äº SafetyLock çç¨³å¥æ§ï¼æå¡å°å¶éæå°å¯¹é½ LLM çå®å¨åè®®ä¸­ãä»£ç å·²å¨ https://github.com/zhu-minjun/SafetyLock ä¸­åå¸ã

##### **CoMAT: Chain of Mathematically Annotated Thought Improves Mathematical Reasoning**
2410.10336v1 by Joshua Ong Jun Leang, Aryo Pradipta Gema, Shay B. Cohen

Mathematical reasoning remains a significant challenge for large language
models (LLMs), despite progress in prompting techniques such as
Chain-of-Thought (CoT). We present Chain of Mathematically Annotated Thought
(CoMAT), which enhances reasoning through two stages: Symbolic Conversion
(converting natural language queries into symbolic form) and Reasoning
Execution (deriving answers from symbolic representations). CoMAT operates
entirely with a single LLM and without external solvers. Across four LLMs,
CoMAT outperforms traditional CoT on six out of seven benchmarks, achieving
gains of 4.48% on MMLU-Redux (MATH) and 4.58% on GaoKao MCQ. In addition to
improved performance, CoMAT ensures faithfulness and verifiability, offering a
transparent reasoning process for complex mathematical tasks

æè¦ï¼åç®¡å¨æç¤ºæè¡ï¼ä¾å¦ææ³éï¼CoTï¼ï¼æ¹é¢åå¾é²å±ï¼æ¸å­¸æ¨çå°æ¼å¤§åèªè¨æ¨¡åï¼LLMï¼èè¨ä»ç¶æ¯ä¸é éå¤§çææ°ãæåæåºæ¸å­¸æ¨è¨ææ³éï¼CoMATï¼ï¼å®ééå©åéæ®µå¢å¼·æ¨çï¼ç¬¦èè½æï¼å°èªç¶èªè¨æ¥è©¢è½ææç¬¦èå½¢å¼ï¼åæ¨çå·è¡ï¼å¾ç¬¦èè¡¨ç¤ºä¸­æ¨å°åºç­æ¡ï¼ãCoMAT å®å¨ä½¿ç¨å®ä¸ LLMï¼ä¸ä¸ä½¿ç¨å¤é¨æ±è§£å¨ãå¨åå LLM ä¸­ï¼CoMAT å¨ä¸ååºæºä¸­çå­ååºæºä¸åªæ¼å³çµ± CoTï¼å¨ MMLU-Reduxï¼MATHï¼ä¸ç²å¾ 4.48% çå¢çï¼å¨é«èé¸æé¡ä¸ç²å¾ 4.58% çå¢çãé¤äºæè½æåä¹å¤ï¼CoMAT ç¢ºä¿äºå¿ å¯¦åº¦åå¯é©è­æ§ï¼çºè¤éçæ¸å­¸ä»»åæä¾äºéæçæ¨çéç¨

##### **Disentangling Hate Across Target Identities**
2410.10332v1 by Yiping Jin, Leo Wanner, Aneesh Moideen Koya

Hate speech (HS) classifiers do not perform equally well in detecting hateful
expressions towards different target identities. They also demonstrate
systematic biases in predicted hatefulness scores. Tapping on two recently
proposed functionality test datasets for HS detection, we quantitatively
analyze the impact of different factors on HS prediction. Experiments on
popular industrial and academic models demonstrate that HS detectors assign a
higher hatefulness score merely based on the mention of specific target
identities. Besides, models often confuse hatefulness and the polarity of
emotions. This result is worrisome as the effort to build HS detectors might
harm the vulnerable identity groups we wish to protect: posts expressing anger
or disapproval of hate expressions might be flagged as hateful themselves. We
also carry out a study inspired by social psychology theory, which reveals that
the accuracy of hatefulness prediction correlates strongly with the intensity
of the stereotype.

æè¦ï¼ä»æ¨è¨è« (HS) åé¡å¨å¨åµæ¸¬éå°ä¸åç®æ¨èº«åçä»æ¨è¨è«æï¼è¡¨ç¾ä¸¦ä¸ç¸åãå®åå¨é æ¸¬çä»æ¨åæ¸ä¸­ä¹è¡¨ç¾åºç³»çµ±æ§çåè¦ãå©ç¨æè¿æåºçå©å HS åµæ¸¬åè½æ¸¬è©¦è³æéï¼æåå®éåæäºä¸åå ç´ å° HS é æ¸¬çå½±é¿ãå¨ç±éç¢æ¥­åå­¸è¡æ¨¡åä¸çå¯¦é©è­æï¼HS åµæ¸¬å¨åæ ¹æç¹å®ç®æ¨èº«åçæåï¼å°±åéäºè¼é«çä»æ¨åæ¸ãæ­¤å¤ï¼æ¨¡åç¶å¸¸æ··æ·ä»æ¨åæç·çæ¥µæ§ãéåçµæä»¤äººææï¼å çºå»ºç« HS åµæ¸¬å¨çåªåå¯è½æå·å®³æåå¸æä¿è­·çå¼±å¢èº«åç¾¤é«ï¼è¡¨éæ¤ææä¸èªåä»æ¨è¨è«çè²¼æå¯è½æè¢«æ¨è¨çºä»æ¨è¨è«ãæåéé²è¡äºä¸é åç¤¾æå¿çå­¸çè«åç¼çç ç©¶ï¼çµæé¡¯ç¤ºä»æ¨é æ¸¬çæºç¢ºæ§èå»æ¿å°è±¡çå¼·åº¦å¯åç¸éã

##### **GraphCLIP: Enhancing Transferability in Graph Foundation Models for Text-Attributed Graphs**
2410.10329v2 by Yun Zhu, Haizhou Shi, Xiaotang Wang, Yongchao Liu, Yaoke Wang, Boci Peng, Chuntao Hong, Siliang Tang

Recently, research on Text-Attributed Graphs (TAGs) has gained significant
attention due to the prevalence of free-text node features in real-world
applications and the advancements in Large Language Models (LLMs) that bolster
TAG methodologies. However, current TAG approaches face two primary challenges:
(i) Heavy reliance on label information and (ii) Limited cross-domain
zero/few-shot transferability. These issues constrain the scaling of both data
and model size, owing to high labor costs and scaling laws, complicating the
development of graph foundation models with strong transferability. In this
work, we propose the GraphCLIP framework to address these challenges by
learning graph foundation models with strong cross-domain zero/few-shot
transferability through a self-supervised contrastive graph-summary pretraining
method. Specifically, we generate and curate large-scale graph-summary pair
data with the assistance of LLMs, and introduce a novel graph-summary
pretraining method, combined with invariant learning, to enhance graph
foundation models with strong cross-domain zero-shot transferability. For
few-shot learning, we propose a novel graph prompt tuning technique aligned
with our pretraining objective to mitigate catastrophic forgetting and minimize
learning costs. Extensive experiments show the superiority of GraphCLIP in both
zero-shot and few-shot settings, while evaluations across various downstream
tasks confirm the versatility of GraphCLIP. Our code is available at:
https://github.com/ZhuYun97/GraphCLIP

æè¦ï¼æè¿ï¼ææ¬å±æ§å¾ï¼TAGï¼çç ç©¶ç±äºç°å®ä¸çåºç¨ä¸­èªç±ææ¬èç¹ç¹å¾çæ®éæ§ä»¥åæ¯æ TAG æ¹æ³çå¤§è¯­è¨æ¨¡åï¼LLMï¼çè¿æ­¥èå¤åå³æ³¨ãç¶èï¼å½åç TAG æ¹æ³é¢ä¸´ä¸¤å¤§ä¸»è¦ææï¼(i) å¯¹æ ç­¾ä¿¡æ¯çä¸¥éä¾èµï¼ä»¥å (ii) è·¨åé¶/å°æ ·æ¬å¯è¿ç§»æ§çåéãç±äºé«æçäººåææ¬åè§æ¨¡åå®å¾ï¼è¿äºé®é¢éå¶äºæ°æ®åæ¨¡åè§æ¨¡çæ©å±ï¼ä½¿å¾å·æå¼ºå¤§å¯è¿ç§»æ§çå¾åºç¡æ¨¡åçå¼ååå¾å¤æãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬æåºäº GraphCLIP æ¡æ¶ï¼éè¿èªçç£å¯¹æ¯å¾æè¦é¢è®­ç»æ¹æ³æ¥å­¦ä¹ å·æå¼ºå¤§è·¨åé¶/å°æ ·æ¬å¯è¿ç§»æ§çå¾åºç¡æ¨¡åï¼ä»¥åºå¯¹è¿äºææãå·ä½æ¥è¯´ï¼æä»¬åå© LLM çæå¹¶æ´çäºå¤§è§æ¨¡å¾æè¦å¯¹æ°æ®ï¼å¹¶å¼å¥äºä¸ç§æ°é¢çå¾æè¦é¢è®­ç»æ¹æ³ï¼ç»åä¸åæ§å­¦ä¹ ï¼ä»¥å¢å¼ºå·æå¼ºå¤§è·¨åé¶æ ·æ¬å¯è¿ç§»æ§çå¾åºç¡æ¨¡åãå¯¹äºå°æ ·æ¬å­¦ä¹ ï¼æä»¬æåºäºä¸ç§æ°é¢çå¾æç¤ºè°æ´ææ¯ï¼è¯¥ææ¯ä¸æä»¬çé¢è®­ç»ç®æ ä¸è´ï¼ä»¥åè½»ç¾é¾æ§éå¿å¹¶æå¤§ç¨åº¦å°éä½å­¦ä¹ ææ¬ãå¤§éçå®éªè¡¨æï¼GraphCLIP å¨é¶æ ·æ¬åå°æ ·æ¬è®¾ç½®ä¸­é½å·æä¼è¶æ§ï¼åæ¶å¯¹åç§ä¸æ¸¸ä»»å¡çè¯ä¼°è¯å®äº GraphCLIP çå¤åè½æ§ãæä»¬çä»£ç å¯å¨ä»¥ä¸ä½ç½®è·å¾ï¼
https://github.com/ZhuYun97/GraphCLIP

##### **MentalGLM Series: Explainable Large Language Models for Mental Health Analysis on Chinese Social Media**
2410.10323v1 by Wei Zhai, Nan Bai, Qing Zhao, Jianqiang Li, Fan Wang, Hongzhi Qi, Meng Jiang, Xiaoqin Wang, Bing Xiang Yang, Guanghui Fu

As the prevalence of mental health challenges, social media has emerged as a
key platform for individuals to express their emotions.Deep learning tends to
be a promising solution for analyzing mental health on social media. However,
black box models are often inflexible when switching between tasks, and their
results typically lack explanations. With the rise of large language models
(LLMs), their flexibility has introduced new approaches to the field. Also due
to the generative nature, they can be prompted to explain decision-making
processes. However, their performance on complex psychological analysis still
lags behind deep learning. In this paper, we introduce the first multi-task
Chinese Social Media Interpretable Mental Health Instructions (C-IMHI) dataset,
consisting of 9K samples, which has been quality-controlled and manually
validated. We also propose MentalGLM series models, the first open-source LLMs
designed for explainable mental health analysis targeting Chinese social media,
trained on a corpus of 50K instructions. The proposed models were evaluated on
three downstream tasks and achieved better or comparable performance compared
to deep learning models, generalized LLMs, and task fine-tuned LLMs. We
validated a portion of the generated decision explanations with experts,
showing promising results. We also evaluated the proposed models on a clinical
dataset, where they outperformed other LLMs, indicating their potential
applicability in the clinical field. Our models show strong performance,
validated across tasks and perspectives. The decision explanations enhance
usability and facilitate better understanding and practical application of the
models. Both the constructed dataset and the models are publicly available via:
https://github.com/zwzzzQAQ/MentalGLM.

æè¦ï¼<paragraph>é¨èå¿çå¥åº·ææ°çæ®éæ§ï¼ç¤¾ç¾¤åªé«å·²æçºåäººè¡¨éæç·çä¸åééµå¹³å°ãæ·±åº¦å­¸ç¿å¾å¾æ¯åæç¤¾ç¾¤åªé«ä¸å¿çå¥åº·çè§£æ±ºæ¹æ¡ãç¶èï¼é»çæ¨¡åå¨ä»»åéåææéå¸¸ç¼ºä¹å½æ§ï¼èå¶çµæéå¸¸ç¼ºä¹è§£éãé¨èå¤§åèªè¨æ¨¡å (LLM) çèèµ·ï¼å®åçéæ´»æ§çºè©²é åå¼å¥äºæ°çæ¹æ³ãç±æ¼çæå¼ç¹æ§ï¼å®åå¯ä»¥è¢«æç¤ºè§£éæ±ºç­å¶å®éç¨ãç¶èï¼å®åå¨è¤éå¿çåæä¸çè¡¨ç¾ä»è½å¾æ¼æ·±åº¦å­¸ç¿ãå¨æ¬æä¸­ï¼æåä»ç´¹ç¬¬ä¸åå¤ä»»åä¸­æç¤¾ç¾¤åªé«å¯è§£éå¿çå¥åº·èªªæ (C-IMHI) è³æéï¼å¶ä¸­åå« 9K åæ¨£æ¬ï¼ç¶éåè³ªæ§ç®¡åæåé©è­ãæåéæåº MentalGLM ç³»åæ¨¡åï¼éæ¯ç¬¬ä¸åéå°ä¸­æç¤¾ç¾¤åªé«çå¯è§£éå¿çå¥åº·åæèè¨­è¨çéæº LLMï¼ä¸¦å¨ 50K åèªªæçèªæåº«ä¸é²è¡è¨ç·´ãææåºçæ¨¡åå¨ä¸åä¸æ¸¸ä»»åä¸é²è¡è©ä¼°ï¼èæ·±åº¦å­¸ç¿æ¨¡åãå»£ç¾© LLM åä»»åå¾®èª¿ LLM ç¸æ¯ï¼åå¾äºæ´å¥½æç¸ç¶çè¡¨ç¾ãæåèå°å®¶é©è­äºé¨åç¢ççæ±ºç­èªªæï¼é¡¯ç¤ºåºæå¸æççµæãæåééå°è¨åºè³æéè©ä¼°ææåºçæ¨¡åï¼å®åçè¡¨ç¾åªæ¼å¶ä» LLMï¼é¡¯ç¤ºåºå®åå¨è¨åºé åçæ½å¨é©ç¨æ§ãæåçæ¨¡åå±ç¾åºå¼·åçè¡¨ç¾ï¼å¨ä»»ååè§é»ä¸é½å¾å°é©è­ãæ±ºç­èªªæå¢å¼·äºå¯ç¨æ§ï¼ä¸¦ä¿é²äºå°æ¨¡åçæ´ä½³çè§£åå¯¦éæç¨ãå»ºæ§çè³æéåæ¨¡åé½å¯ééä»¥ä¸ç¶²åå¬éåå¾ï¼https://github.com/zwzzzQAQ/MentalGLMã</paragraph>

##### **EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations**
2410.10315v2 by Zhangchi Feng, Dongdong Kuang, Zhongyuan Wang, Zhijie Nie, Yaowei Zheng, Richong Zhang

This paper presents EasyRAG, a simple, lightweight, and efficient
retrieval-augmented generation framework for automated network operations. Our
framework has three advantages. The first is accurate question answering. We
designed a straightforward RAG scheme based on (1) a specific data processing
workflow (2) dual-route sparse retrieval for coarse ranking (3) LLM Reranker
for reranking (4) LLM answer generation and optimization. This approach
achieved first place in the GLM4 track in the preliminary round and second
place in the GLM4 track in the semifinals. The second is simple deployment. Our
method primarily consists of BM25 retrieval and BGE-reranker reranking,
requiring no fine-tuning of any models, occupying minimal VRAM, easy to deploy,
and highly scalable; we provide a flexible code library with various search and
generation strategies, facilitating custom process implementation. The last one
is efficient inference. We designed an efficient inference acceleration scheme
for the entire coarse ranking, reranking, and generation process that
significantly reduces the inference latency of RAG while maintaining a good
level of accuracy; each acceleration scheme can be plug-and-play into any
component of the RAG process, consistently enhancing the efficiency of the RAG
system. Our code and data are released at
\url{https://github.com/BUAADreamer/EasyRAG}.

æè¦ï¼æ¬ææåºäº EasyRAGï¼ä¸åç°¡å®ãè¼éä¸é«æçæª¢ç´¢å¢å¼·çææ¡æ¶ï¼ç¨æ¼èªååç¶²è·¯æä½ãæåçæ¡æ¶æä¸ååªé»ãç¬¬ä¸åæ¯ç²¾ç¢ºçåç­ãæåè¨­è¨äºä¸ååºæ¼ (1) ç¹å®è³æèçå·¥ä½æµç¨ (2) éè·¯å¾ç¨çæª¢ç´¢ç¨æ¼ç²ç¥æåº (3) LLM Reranker ç¨æ¼éæ°æåº (4) LLM ç­æ¡çæåæä½³åçç´æ¥ RAG æ¶æ§ãæ­¤æ¹æ³å¨é è³½ä¸­ç²å¾ GLM4 è»éç¬¬ä¸åï¼å¨æºæ±ºè³½ä¸­ç²å¾ GLM4 è»éç¬¬äºåãç¬¬äºåæ¯ç°¡å®çé¨ç½²ãæåçæè¡ä¸»è¦åå« BM25 æª¢ç´¢å BGE-reranker éæ°æåºï¼ä¸éè¦å¾®èª¿ä»»ä½æ¨¡åï¼ä½ç¨æå°ç VRAMï¼ææ¼é¨ç½²ä¸é«åº¦å¯æ´åï¼æåæä¾ä¸åéæ´»çç¨å¼ç¢¼åº«ï¼åå«åç¨®æå°åçæç­ç¥ï¼ä¾¿æ¼èªè¨æµç¨å¯¦ä½ãæå¾ä¸åæ¯ææççæ¨è«ãæåè¨­è¨äºä¸åææçæ¨è«å éæ¶æ§ï¼ç¨æ¼æ´åç²ç¥æåºãéæ°æåºåçææµç¨ï¼å¨ç¶­æè¯å¥½ç²¾ç¢ºåº¦çåæï¼å¤§å¹éä½ RAG çæ¨è«å»¶é²ï¼æ¯åå éæ¶æ§é½å¯ä»¥å³æå³ç¨æ¼ RAG æµç¨çä»»ä½çµæé¨åï¼æçºæå RAG ç³»çµ±çæçãæåçç¨å¼ç¢¼åè³æå·²ç¼ä½æ¼
\url{https://github.com/BUAADreamer/EasyRAG}ã

##### **A Comparative Study of Translation Bias and Accuracy in Multilingual Large Language Models for Cross-Language Claim Verification**
2410.10303v1 by Aryan Singhal, Veronica Shao, Gary Sun, Ryan Ding, Jonathan Lu, Kevin Zhu

The rise of digital misinformation has heightened interest in using
multilingual Large Language Models (LLMs) for fact-checking. This study
systematically evaluates translation bias and the effectiveness of LLMs for
cross-lingual claim verification across 15 languages from five language
families: Romance, Slavic, Turkic, Indo-Aryan, and Kartvelian. Using the XFACT
dataset to assess their impact on accuracy and bias, we investigate two
distinct translation methods: pre-translation and self-translation. We use
mBERT's performance on the English dataset as a baseline to compare
language-specific accuracies. Our findings reveal that low-resource languages
exhibit significantly lower accuracy in direct inference due to
underrepresentation in the training data. Furthermore, larger models
demonstrate superior performance in self-translation, improving translation
accuracy and reducing bias. These results highlight the need for balanced
multilingual training, especially in low-resource languages, to promote
equitable access to reliable fact-checking tools and minimize the risk of
spreading misinformation in different linguistic contexts.

æè¦ï¼æ¸ä½é¯èª¤è³è¨çèèµ·ï¼å åäºäººåå°æ¼ä½¿ç¨å¤èªè¨å¤§åèªè¨æ¨¡å (LLM) é²è¡äºå¯¦æ¥æ ¸çèè¶£ãæ¬ç ç©¶ç³»çµ±æ§å°è©ä¼°äºç¿»è­¯åå·®ä»¥å LLM å¨ 15 ç¨®èªè¨ä¸­é²è¡è·¨èªè¨è²æé©è­çæææ§ï¼éäºèªè¨ä¾èªäºåèªè¨å®¶æï¼ç¾æ¼èªæãæ¯æå¤«èªæãçªå¥èªæãå°åº¦-éå©å®èªæåå¡ç¹ç¶­ç¾èªæãæåä½¿ç¨ XFACT è³æéä¾è©ä¼°å®åå°æºç¢ºæ§ååå·®çå½±é¿ï¼ä¸¦ç ç©¶äºå©ç¨®ä¸åçç¿»è­¯æ¹æ³ï¼é ç¿»è­¯åèªç¿»è­¯ãæåä½¿ç¨ mBERT å¨è±èªè³æéä¸çè¡¨ç¾ä½çºåºæºï¼ä¾æ¯è¼ç¹å®èªè¨çæºç¢ºæ§ãæåçç ç©¶çµæé¡¯ç¤ºï¼ç±æ¼å¨è¨ç·´è³æä¸­ä»£è¡¨æ§ä¸è¶³ï¼ä½è³æºèªè¨å¨ç´æ¥æ¨è«ä¸­è¡¨ç¾åºé¡¯èè¼ä½çæºç¢ºæ§ãæ­¤å¤ï¼è¼å¤§çæ¨¡åå¨èªç¿»è­¯ä¸­è¡¨ç¾åºåªç°çè¡¨ç¾ï¼æé«äºç¿»è­¯æºç¢ºæ§ä¸¦æ¸å°äºåå·®ãéäºçµæçªé¡¯äºå¹³è¡¡å¤èªè¨è¨ç·´çå¿è¦æ§ï¼ç¹å¥æ¯å¨ä½è³æºèªè¨ä¸­ï¼ä»¥ä¿é²å°å¯é äºå¯¦æ¥æ ¸å·¥å·çå¬å¹³ä½¿ç¨ï¼ä¸¦æå¤§ç¨åº¦å°éä½å¨ä¸åèªè¨ç°å¢ä¸­æ£å¸é¯èª¤è³è¨çé¢¨éªã

##### **FunnelRAG: A Coarse-to-Fine Progressive Retrieval Paradigm for RAG**
2410.10293v1 by Xinping Zhao, Yan Zhong, Zetian Sun, Xinshuo Hu, Zhenyu Liu, Dongfang Li, Baotian Hu, Min Zhang

Retrieval-Augmented Generation (RAG) prevails in Large Language Models. It
mainly consists of retrieval and generation. The retrieval modules (a.k.a.
retrievers) aim to find useful information used to facilitate generation
modules (a.k.a. generators). As such, generators' performance largely depends
on the effectiveness and efficiency of retrievers. However, the retrieval
paradigm that we design and use remains flat, which treats the retrieval
procedures as a one-off deal with constant granularity. Despite effectiveness,
we argue that they suffer from two limitations: (1) flat retrieval exerts a
significant burden on one retriever; (2) constant granularity limits the
ceiling of retrieval performance. In this work, we propose a progressive
retrieval paradigm with coarse-to-fine granularity for RAG, termed FunnelRAG,
so as to balance effectiveness and efficiency. Specifically, FunnelRAG
establishes a progressive retrieval pipeline by collaborating coarse-to-fine
granularity, large-to-small quantity, and low-to-high capacity, which can
relieve the burden on one retriever and also promote the ceiling of retrieval
performance. Extensive experiments manifest that FunnelRAG achieves comparable
retrieval performance while the time overhead is reduced by nearly 40 percent.

æè¦ï¼æ·åå¢å¼·çæï¼RAGï¼å¨å¤§åèªè¨æ¨¡åä¸­çè¡ãå®ä¸»è¦åå«æ·ååçæãæ·åæ¨¡çµï¼åç¨±æ·åå¨ï¼æ¨å¨å°æ¾ç¨æ¼ä¿é²çææ¨¡çµï¼åç¨±çæå¨ï¼çæç¨è³è¨ãå æ­¤ï¼çæå¨çæè½å¾å¤§ç¨åº¦åæ±ºæ¼æ·åå¨çæè½åæçãç¶èï¼æåè¨­è¨åä½¿ç¨çæ·åç¯ä¾ä»ç¶æ¯å¹³é¢çï¼å®å°æ·åç¨åºè¦çºä¸æ¬¡æ§èçï¼ä¸å·ææå®ç²åº¦ãåç®¡ææï¼ä½æåèªçºå®åæå©åéå¶ï¼(1) å¹³é¢æ·åå°å®ä¸æ·åå¨é æéå¤§è² æï¼(2) æå®ç²åº¦éå¶äºæ·åæè½çä¸éãå¨éé å·¥ä½ä¸­ï¼æåçº RAG æåºäºä¸åå·æç²å°ç´°ç²åº¦çæ¼¸é²å¼æ·åç¯ä¾ï¼ç¨±çº FunnelRAGï¼ä»¥ä¾¿å¹³è¡¡æè½åæçãå·é«ä¾èªªï¼FunnelRAG ééåèª¿ç²å°ç´°çç²åº¦ãå¤§å°å°çæ¸éä»¥åä½å°é«çå®¹éä¾å»ºç«æ¼¸é²å¼æ·åç®¡éï¼éå¯ä»¥æ¸è¼å®ä¸æ·åå¨çè² æï¼ä¸¦æåæ·åæè½çä¸éãå»£æ³çå¯¦é©è¡¨æï¼FunnelRAG éå°äºç¸ç¶çæ·åæè½ï¼åæå°æééé·æ¸å°äºå°è¿ 40%ã

##### **Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal Perspective**
2410.10291v1 by Xiangru Zhu, Penglei Sun, Yaoxian Song, Yanghua Xiao, Zhixu Li, Chengyu Wang, Jun Huang, Bei Yang, Xiaoxiao Xu

Accurate interpretation and visualization of human instructions are crucial
for text-to-image (T2I) synthesis. However, current models struggle to capture
semantic variations from word order changes, and existing evaluations, relying
on indirect metrics like text-image similarity, fail to reliably assess these
challenges. This often obscures poor performance on complex or uncommon
linguistic patterns by the focus on frequent word combinations. To address
these deficiencies, we propose a novel metric called SemVarEffect and a
benchmark named SemVarBench, designed to evaluate the causality between
semantic variations in inputs and outputs in T2I synthesis. Semantic variations
are achieved through two types of linguistic permutations, while avoiding
easily predictable literal variations. Experiments reveal that the
CogView-3-Plus and Ideogram 2 performed the best, achieving a score of 0.2/1.
Semantic variations in object relations are less understood than attributes,
scoring 0.07/1 compared to 0.17-0.19/1. We found that cross-modal alignment in
UNet or Transformers plays a crucial role in handling semantic variations, a
factor previously overlooked by a focus on textual encoders. Our work
establishes an effective evaluation framework that advances the T2I synthesis
community's exploration of human instruction understanding.

æè¦ï¼æºç¢ºçè©®éåè¦è¦ºåäººé¡çæç¤ºå°æ¼ææ¬å°å½±å (T2I) çåæè³ééè¦ãç¶èï¼ç®åçæ¨¡åé£ä»¥ææè©åºè®åçèªç¾©è®ç°ï¼èç¾æçè©ä¼°ä¾è³´æ¼æå­å½±åç¸ä¼¼åº¦ç­éæ¥ææ¨ï¼ç¡æ³å¯é å°è©ä¼°éäºææ°ãéå¸¸å¸¸å çºå°æ³¨æ¼é »ç¹çè©å½çµåï¼èæ¨¡ç³äºå¨è¤éæä¸å¸¸è¦çèªè¨æ¨¡å¼ä¸çç³ç³è¡¨ç¾ãçºäºè§£æ±ºéäºç¼ºé·ï¼æåæåºäºä¸ååçº SemVarEffect çæ°ææ¨åä¸ååçº SemVarBench çåºæºï¼æ¨å¨è©ä¼° T2I åæä¸­è¼¸å¥åè¼¸åºèªç¾©è®ç°ä¹éçå æéä¿ãèªç¾©è®ç°æ¯ééå©ç¨®èªè¨æåé¡åä¾å¯¦ç¾çï¼åæé¿åäºå®¹æé æ¸¬çå­é¢è®ç°ãå¯¦é©è¡¨æ CogView-3-Plus å Ideogram 2 è¡¨ç¾æä½³ï¼ç²å¾ 0.2/1 çåæ¸ãè 0.17-0.19/1 ç¸æ¯ï¼ç©ä»¶éä¿ä¸­çèªç¾©è®ç°æ¯å±¬æ§æ´é£çè§£ï¼å¾åçº 0.07/1ãæåç¼ç¾ UNet æ Transformer ä¸­çè·¨æ¨¡æå°é½å¨èçèªç¾©è®ç°ä¸­æ®æ¼èè³ééè¦çè§è²ï¼éæ¯ä¸åä»¥åè¢«å°æ³¨æ¼æå­ç·¨ç¢¼å¨æå¿½ç¥çå ç´ ãæåçç ç©¶å»ºç«äºä¸åææçè©ä¼°æ¡æ¶ï¼ä¿é²äº T2I åæç¤¾ç¾¤å°äººé¡æä»¤çè§£çæ¢ç´¢ã

##### **A Multi-Task Text Classification Pipeline with Natural Language Explanations: A User-Centric Evaluation in Sentiment Analysis and Offensive Language Identification in Greek Tweets**
2410.10290v1 by Nikolaos Mylonas, Nikolaos Stylianou, Theodora Tsikrika, Stefanos Vrochidis, Ioannis Kompatsiaris

Interpretability is a topic that has been in the spotlight for the past few
years. Most existing interpretability techniques produce interpretations in the
form of rules or feature importance. These interpretations, while informative,
may be harder to understand for non-expert users and therefore, cannot always
be considered as adequate explanations. To that end, explanations in natural
language are often preferred, as they are easier to comprehend and also more
presentable to end-users. This work introduces an early concept for a novel
pipeline that can be used in text classification tasks, offering predictions
and explanations in natural language. It comprises of two models: a classifier
for labelling the text and an explanation generator which provides the
explanation. The proposed pipeline can be adopted by any text classification
task, given that ground truth rationales are available to train the explanation
generator. Our experiments are centred around the tasks of sentiment analysis
and offensive language identification in Greek tweets, using a Greek Large
Language Model (LLM) to obtain the necessary explanations that can act as
rationales. The experimental evaluation was performed through a user study
based on three different metrics and achieved promising results for both
datasets.

æè¦ï¼å¯è§£éæ§æ¯éå»å¹¾å¹´ååéæ³¨çä¸»é¡ãå¤§å¤æ¸ç¾æçå¯è§£éæ§æè¡ä»¥è¦åæç¹å¾µéè¦æ§çå½¢å¼ç¢çè§£éãéäºè§£ééç¶å·æè³è¨æ§ï¼ä½å°æ¼éå°å®¶ä½¿ç¨èä¾èªªå¯è½è¼é£çè§£ï¼å æ­¤ä¸¦ä¸ç¸½æ¯è½è¢«è¦çºååçè§£éãçºäºè§£æ±ºéååé¡ï¼éå¸¸åªåæ¡ç¨èªç¶èªè¨çè§£éï¼å çºå®åæ´å®¹æçè§£ï¼èä¸å°æçµä½¿ç¨èä¾èªªä¹æ´ææ¼åç¾ãéé å·¥ä½ä»ç´¹äºä¸åæ°ç©ç®¡ç·çæ©ææ¦å¿µï¼å¯ç¨æ¼æå­åé¡ä»»åï¼æä¾èªç¶èªè¨ä¸­çé æ¸¬åè§£éãå®åå«å©åæ¨¡åï¼ä¸åç¨æ¼æ¨è¨æå­çåé¡å¨åä¸åæä¾è§£éçè§£éç¢çå¨ãåªè¦æåºæ¬åçå¯ç¨æ¼è¨ç·´è§£éç¢çå¨ï¼ææåºçç®¡ç·å°±å¯ä»¥è¢«ä»»ä½æå­åé¡ä»»åæ¡ç¨ãæåçå¯¦é©ä¸»è¦éä¸­å¨å¸èæ¨æçæç·åæåæ»ææ§èªè¨è­å¥ä»»åï¼ä½¿ç¨å¸èå¤§åèªè¨æ¨¡å (LLM) ä¾åå¾å¿è¦çè§£éï¼éäºè§£éå¯ä»¥ä½çºåºæ¬åçãå¯¦é©è©ä¼°æ¯ééä½¿ç¨èç ç©¶é²è¡ï¼åºæ¼ä¸åä¸åçææ¨ï¼ä¸¦éå°å©åè³æéç²å¾äºæå¸æççµæã

##### **ABBA-VSM: Time Series Classification using Symbolic Representation on the Edge**
2410.10285v1 by Meerzhan Kanatbekova, Shashikant Ilager, Ivona Brandic

In recent years, Edge AI has become more prevalent with applications across
various industries, from environmental monitoring to smart city management.
Edge AI facilitates the processing of Internet of Things (IoT) data and
provides privacy-enabled and latency-sensitive services to application users
using Machine Learning (ML) algorithms, e.g., Time Series Classification (TSC).
However, existing TSC algorithms require access to full raw data and demand
substantial computing resources to train and use them effectively in runtime.
This makes them impractical for deployment in resource-constrained Edge
environments. To address this, in this paper, we propose an Adaptive Brownian
Bridge-based Symbolic Aggregation Vector Space Model (ABBA-VSM). It is a new
TSC model designed for classification services on Edge. Here, we first
adaptively compress the raw time series into symbolic representations, thus
capturing the changing trends of data. Subsequently, we train the
classification model directly on these symbols. ABBA-VSM reduces communication
data between IoT and Edge devices, as well as computation cycles, in the
development of resource-efficient TSC services on Edge. We evaluate our
solution with extensive experiments using datasets from the UCR time series
classification archive. The results demonstrate that the ABBA-VSM achieves up
to 80% compression ratio and 90-100% accuracy for binary classification.
Whereas, for non-binary classification, it achieves an average compression
ratio of 60% and accuracy ranging from 60-80%.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼éç·£ AI å¨åç¢æ¥­çæç¨è¶ä¾è¶æ®éï¼å¾ç°å¢ç£æ¸¬å°æºæ§åå¸ç®¡ççæå¶æç¨ã
éç·£ AI ééæ©å¨å­¸ç¿ï¼MLï¼æ¼ç®æ³ï¼ä¾å¦æéåºååé¡ï¼TSCï¼ï¼ä¿é²ç©è¯ç¶²ï¼IoTï¼è³æçèçï¼ä¸¦æä¾æ³¨éé±ç§ä¸å°å»¶é²ææçæåçµ¦æç¨ç¨å¼ä½¿ç¨èã
ç¶èï¼ç¾æç TSC æ¼ç®æ³éè¦å­åå®æ´çåå§è³æï¼ä¸¦éè¦å¤§éçéç®è³æºæè½å¨å·è¡éæ®µææå°è¨ç·´åä½¿ç¨å®åã
éä½¿å¾å®åä¸é©åé¨ç½²å¨è³æºåéçéç·£ç°å¢ä¸­ãçºäºè§£æ±ºéååé¡ï¼æåå¨æ¬æä¸­æåºäºä¸ç¨®åºæ¼èªé©æå¸ææ©çç¬¦èèååéç©ºéæ¨¡åï¼ABBA-VSMï¼ãå®æ¯ä¸ç¨®æ°ç TSC æ¨¡åï¼å°çºéç·£çåé¡æåèè¨­è¨ãå¨éè£¡ï¼æåé¦åèªé©æå°å°åå§æéåºåå£ç¸®æç¬¦èè¡¨ç¤ºï¼å¾èææè³æçè®åè¶¨å¢ãé¨å¾ï¼æåç´æ¥å¨éäºç¬¦èä¸è¨ç·´åé¡æ¨¡åãABBA-VSM æ¸å°äºç©è¯ç¶²åéç·£è£ç½®ä¹éçéè¨è³æï¼ä»¥åå¨éç·£éç¼è³æºç¯çç TSC æåä¸­çéç®é±æãæåä½¿ç¨ UCR æéåºååé¡æªæ¡é¤¨ä¸­çè³æéé²è¡å»£æ³çå¯¦é©ä¾è©ä¼°æåçè§£æ±ºæ¹æ¡ãçµæè¡¨æï¼ABBA-VSM å¨äºååé¡ä¸­å¯¦ç¾äºé«é 80% çå£ç¸®æ¯å 90-100% çæºç¢ºåº¦ã
è³æ¼éäºååé¡ï¼å®å¯¦ç¾äº 60% çå¹³åå£ç¸®æ¯ï¼æºç¢ºåº¦å¨ 60-80% ä¹éã</paragraph>

##### **Machine Translation Evaluation Benchmark for Wu Chinese: Workflow and Analysis**
2410.10278v1 by Hongjian Yu, Yiming Shi, Zherui Zhou, Christopher Haberland

We introduce a FLORES+ dataset as an evaluation benchmark for modern Wu
Chinese machine translation models and showcase its compatibility with existing
Wu data. Wu Chinese is mutually unintelligible with other Sinitic languages
such as Mandarin and Yue (Cantonese), but uses a set of Hanzi (Chinese
characters) that profoundly overlaps with others. The population of Wu speakers
is the second largest among languages in China, but the language has been
suffering from significant drop in usage especially among the younger
generations. We identify Wu Chinese as a textually low-resource language and
address challenges for its machine translation models. Our contributions
include: (1) an open-source, manually translated dataset, (2) full
documentations on the process of dataset creation and validation experiments,
(3) preliminary tools for Wu Chinese normalization and segmentation, and (4)
benefits and limitations of our dataset, as well as implications to other
low-resource languages.

æè¦ï¼æåå¼å¥ FLORES+ è³æéä½çºç¾ä»£å³èªæ©å¨ç¿»è­¯æ¨¡åçè©ä¼°åºæºï¼ä¸¦å±ç¤ºå¶èç¾æå³èªè³æçç¸å®¹æ§ãå³èªèå¶ä»æ¼¢èªæèªè¨ï¼å¦æ®éè©±åç²µèªï¼äºä¸çè§£ï¼ä½ä½¿ç¨ä¸å¥èå¶ä»èªè¨é«åº¦éççæ¼¢å­ï¼ä¸­ææ¼¢å­ï¼ãå³èªä½¿ç¨èäººå£æ¸éå¨ä¸­åèªè¨ä¸­æåç¬¬äºï¼ä½è©²èªè¨çä½¿ç¨çå¤§å¹ä¸éï¼ç¹å¥æ¯å¨å¹´è¼ä¸ä»£ä¸­ãæåå°å³èªèªå®çºæå­è³æºå±ä¹çèªè¨ï¼ä¸¦è§£æ±ºå¶æ©å¨ç¿»è­¯æ¨¡åçææ°ãæåçè²¢ç»åæ¬ï¼(1) ä¸åéæºãäººå·¥ç¿»è­¯çè³æéï¼(2) éæ¼è³æéå»ºç«åé©è­å¯¦é©éç¨çå®æ´æä»¶ï¼(3) å³èªæ¨æºåååè©çåæ­¥å·¥å·ï¼ä»¥å (4) æåçè³æéçåªé»åéå¶ï¼ä»¥åå°å¶ä»è³æºå±ä¹èªè¨çå½±é¿ã

