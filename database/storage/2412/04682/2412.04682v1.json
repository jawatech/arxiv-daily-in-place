{"2412.04682": {"publish_time": "2024-12-06", "title": "Two stages domain invariant representation learners solve the large co-variate shift in unsupervised domain adaptation with two dimensional data domains", "paper_summary": "Recent developments in the unsupervised domain adaptation (UDA) enable the\nunsupervised machine learning (ML) prediction for target data, thus this will\naccelerate real world applications with ML models such as image recognition\ntasks in self-driving. Researchers have reported the UDA techniques are not\nworking well under large co-variate shift problems where e.g. supervised source\ndata consists of handwritten digits data in monotone color and unsupervised\ntarget data colored digits data from the street view. Thus there is a need for\na method to resolve co-variate shift and transfer source labelling rules under\nthis dynamics. We perform two stages domain invariant representation learning\nto bridge the gap between source and target with semantic intermediate data\n(unsupervised). The proposed method can learn domain invariant features\nsimultaneously between source and intermediate also intermediate and target.\nFinally this achieves good domain invariant representation between source and\ntarget plus task discriminability owing to source labels. This induction for\nthe gradient descent search greatly eases learning convergence in terms of\nclassification performance for target data even when large co-variate shift. We\nalso derive a theorem for measuring the gap between trained models and\nunsupervised target labelling rules, which is necessary for the free parameters\noptimization. Finally we demonstrate that proposing method is superiority to\nprevious UDA methods using 4 representative ML classification datasets\nincluding 38 UDA tasks. Our experiment will be a basis for challenging UDA\nproblems with large co-variate shift.", "paper_summary_zh": "\u6700\u8fd1\u5728\u7121\u76e3\u7763\u9818\u57df\u9069\u61c9 (UDA) \u7684\u767c\u5c55\uff0c\u4f7f\u5f97\u7121\u76e3\u7763\u6a5f\u5668\u5b78\u7fd2 (ML) \u9810\u6e2c\u53ef\u61c9\u7528\u65bc\u76ee\u6a19\u8cc7\u6599\uff0c\u56e0\u6b64\u9019\u5c07\u52a0\u901f ML \u6a21\u578b\u7684\u5be6\u969b\u61c9\u7528\uff0c\u4f8b\u5982\u81ea\u99d5\u8eca\u4e2d\u7684\u5f71\u50cf\u8fa8\u8b58\u4efb\u52d9\u3002\u7814\u7a76\u4eba\u54e1\u5831\u544a\u6307\u51fa\uff0cUDA \u6280\u8853\u5728\u5927\u578b\u5171\u8b8a\u7570\u6578\u8f49\u79fb\u554f\u984c\u4e0b\u7121\u6cd5\u9806\u5229\u904b\u4f5c\uff0c\u4f8b\u5982\u76e3\u7763\u4f86\u6e90\u8cc7\u6599\u5305\u542b\u55ae\u8272\u624b\u5beb\u6578\u5b57\u8cc7\u6599\uff0c\u800c\u7121\u76e3\u7763\u76ee\u6a19\u8cc7\u6599\u5247\u5305\u542b\u4f86\u81ea\u8857\u666f\u7684\u5f69\u8272\u6578\u5b57\u8cc7\u6599\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u7a2e\u65b9\u6cd5\u4f86\u89e3\u6c7a\u5171\u8b8a\u7570\u6578\u8f49\u79fb\uff0c\u4e26\u5728\u6b64\u52d5\u614b\u4e0b\u8f49\u79fb\u4f86\u6e90\u6a19\u7c64\u898f\u5247\u3002\u6211\u5011\u57f7\u884c\u5169\u968e\u6bb5\u7db2\u57df\u4e0d\u8b8a\u8868\u793a\u5b78\u7fd2\uff0c\u4ee5\u900f\u904e\u8a9e\u610f\u4e2d\u9593\u8cc7\u6599\uff08\u7121\u76e3\u7763\uff09\u4f86\u5f4c\u5408\u4f86\u6e90\u8207\u76ee\u6a19\u4e4b\u9593\u7684\u5dee\u8ddd\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u4ee5\u5728\u4f86\u6e90\u8207\u4e2d\u9593\uff0c\u4ee5\u53ca\u4e2d\u9593\u8207\u76ee\u6a19\u4e4b\u9593\u540c\u6642\u5b78\u7fd2\u7db2\u57df\u4e0d\u8b8a\u7279\u5fb5\u3002\u6700\u5f8c\uff0c\u9019\u5728\u4f86\u6e90\u6a19\u7c64\u7684\u5e6b\u52a9\u4e0b\uff0c\u9054\u5230\u4e86\u4f86\u6e90\u8207\u76ee\u6a19\u4e4b\u9593\u826f\u597d\u7684\u7db2\u57df\u4e0d\u8b8a\u8868\u793a\uff0c\u4ee5\u53ca\u4efb\u52d9\u53ef\u8fa8\u5225\u6027\u3002\u9019\u7a2e\u7528\u65bc\u68af\u5ea6\u4e0b\u964d\u641c\u5c0b\u7684\u6b78\u7d0d\uff0c\u5373\u4f7f\u5728\u5927\u578b\u5171\u8b8a\u7570\u6578\u8f49\u79fb\u7684\u60c5\u6cc1\u4e0b\uff0c\u4e5f\u80fd\u5927\u5e45\u7c21\u5316\u76ee\u6a19\u8cc7\u6599\u5206\u985e\u6548\u80fd\u7684\u5b78\u7fd2\u6536\u6582\u3002\u6211\u5011\u4e5f\u63a8\u5c0e\u4e86\u4e00\u500b\u7528\u65bc\u6e2c\u91cf\u8a13\u7df4\u6a21\u578b\u8207\u7121\u76e3\u7763\u76ee\u6a19\u6a19\u7c64\u898f\u5247\u4e4b\u9593\u5dee\u8ddd\u7684\u5b9a\u7406\uff0c\u9019\u5c0d\u65bc\u81ea\u7531\u53c3\u6578\u6700\u4f73\u5316\u800c\u8a00\u662f\u5fc5\u8981\u7684\u3002\u6700\u5f8c\uff0c\u6211\u5011\u8b49\u660e\u4e86\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u512a\u65bc\u5148\u524d\u7684 UDA \u65b9\u6cd5\uff0c\u4f7f\u7528 4 \u500b\u5177\u4ee3\u8868\u6027\u7684 ML \u5206\u985e\u8cc7\u6599\u96c6\uff0c\u5176\u4e2d\u5305\u62ec 38 \u500b UDA \u4efb\u52d9\u3002\u6211\u5011\u7684\u5be6\u9a57\u5c07\u6210\u70ba\u6311\u6230\u5177\u6709\u5927\u578b\u5171\u8b8a\u7570\u6578\u8f49\u79fb\u7684 UDA \u554f\u984c\u7684\u57fa\u790e\u3002", "author": "Hisashi Oshima et.al.", "authors": "Hisashi Oshima, Tsuyoshi Ishizone, Tomoyuki Higuchi", "id": "2412.04682v1", "paper_url": "http://arxiv.org/abs/2412.04682v1", "repo": "https://github.com/oh-yu/domain-invariant-learning"}}