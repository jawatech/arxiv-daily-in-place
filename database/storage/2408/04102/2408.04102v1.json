{"2408.04102": {"publish_time": "2024-08-07", "title": "ArtVLM: Attribute Recognition Through Vision-Based Prefix Language Modeling", "paper_summary": "Recognizing and disentangling visual attributes from objects is a foundation\nto many computer vision applications. While large vision language\nrepresentations like CLIP had largely resolved the task of zero-shot object\nrecognition, zero-shot visual attribute recognition remains a challenge because\nCLIP's contrastively-learned vision-language representation cannot effectively\ncapture object-attribute dependencies. In this paper, we target this weakness\nand propose a sentence generation-based retrieval formulation for attribute\nrecognition that is novel in 1) explicitly modeling a to-be-measured and\nretrieved object-attribute relation as a conditional probability graph, which\nconverts the recognition problem into a dependency-sensitive language-modeling\nproblem, and 2) applying a large pretrained Vision-Language Model (VLM) on this\nreformulation and naturally distilling its knowledge of image-object-attribute\nrelations to use towards attribute recognition. Specifically, for each\nattribute to be recognized on an image, we measure the visual-conditioned\nprobability of generating a short sentence encoding the attribute's relation to\nobjects on the image. Unlike contrastive retrieval, which measures likelihood\nby globally aligning elements of the sentence to the image, generative\nretrieval is sensitive to the order and dependency of objects and attributes in\nthe sentence. We demonstrate through experiments that generative retrieval\nconsistently outperforms contrastive retrieval on two visual reasoning\ndatasets, Visual Attribute in the Wild (VAW), and our newly-proposed Visual\nGenome Attribute Ranking (VGARank).", "paper_summary_zh": "\u8fa8\u8b58\u548c\u5340\u5206\u7269\u4ef6\u7684\u8996\u89ba\u5c6c\u6027\uff0c\u662f\u8a31\u591a\u96fb\u8166\u8996\u89ba\u61c9\u7528\u7a0b\u5f0f\u7684\u57fa\u790e\u3002\u96d6\u7136\u50cf CLIP \u9019\u6a23\u7684\u5927\u578b\u8996\u89ba\u8a9e\u8a00\u8868\u5fb5\uff0c\u5df2\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u89e3\u6c7a\u4e86\u96f6\u6b21\u5b78\u7fd2\u7269\u4ef6\u8fa8\u8b58\u7684\u4efb\u52d9\uff0c\u4f46\u96f6\u6b21\u5b78\u7fd2\u8996\u89ba\u5c6c\u6027\u8fa8\u8b58\u4ecd\u7136\u662f\u4e00\u500b\u6311\u6230\uff0c\u56e0\u70ba CLIP \u5c0d\u6bd4\u5b78\u7fd2\u7684\u8996\u89ba\u8a9e\u8a00\u8868\u5fb5\uff0c\u7121\u6cd5\u6709\u6548\u64f7\u53d6\u7269\u4ef6\u5c6c\u6027\u4f9d\u8cf4\u6027\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u91dd\u5c0d\u6b64\u5f31\u9ede\uff0c\u4e26\u63d0\u51fa\u4e00\u500b\u57fa\u65bc\u53e5\u5b50\u751f\u6210\u7684\u6aa2\u7d22\u516c\u5f0f\uff0c\u7528\u65bc\u5c6c\u6027\u8fa8\u8b58\uff0c\u5176\u65b0\u7a4e\u4e4b\u8655\u5728\u65bc\uff1a1) \u660e\u78ba\u5730\u5c07\u5f85\u6e2c\u91cf\u548c\u6aa2\u7d22\u7684\u7269\u4ef6\u5c6c\u6027\u95dc\u4fc2\u5efa\u6a21\u70ba\u689d\u4ef6\u6a5f\u7387\u5716\uff0c\u9019\u5c07\u8fa8\u8b58\u554f\u984c\u8f49\u63db\u70ba\u4f9d\u8cf4\u654f\u611f\u7684\u8a9e\u8a00\u6a21\u578b\u554f\u984c\uff1b2) \u5728\u6b64\u91cd\u65b0\u516c\u5f0f\u5316\u4e0a\u61c9\u7528\u5927\u578b\u9810\u8a13\u7df4\u7684\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM)\uff0c\u4e26\u81ea\u7136\u5730\u8403\u53d6\u5176\u5c0d\u5f71\u50cf\u7269\u4ef6\u5c6c\u6027\u95dc\u4fc2\u7684\u77e5\u8b58\uff0c\u7528\u65bc\u5c6c\u6027\u8fa8\u8b58\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u5c0d\u65bc\u8981\u5728\u5f71\u50cf\u4e0a\u8fa8\u8b58\u7684\u6bcf\u500b\u5c6c\u6027\uff0c\u6211\u5011\u6e2c\u91cf\u5728\u5f71\u50cf\u4e0a\u7de8\u78bc\u5c6c\u6027\u8207\u7269\u4ef6\u95dc\u4fc2\u7684\u7c21\u77ed\u53e5\u5b50\u7684\u8996\u89ba\u689d\u4ef6\u6a5f\u7387\u3002\u8207\u5c0d\u6bd4\u6aa2\u7d22\u4e0d\u540c\uff0c\u5c0d\u6bd4\u6aa2\u7d22\u662f\u900f\u904e\u5c07\u53e5\u5b50\u7684\u5143\u7d20\u6574\u9ad4\u6bd4\u5c0d\u5230\u5f71\u50cf\u4f86\u6e2c\u91cf\u53ef\u80fd\u6027\uff0c\u751f\u6210\u6aa2\u7d22\u5247\u5c0d\u53e5\u5b50\u4e2d\u7269\u4ef6\u548c\u5c6c\u6027\u7684\u9806\u5e8f\u548c\u4f9d\u8cf4\u6027\u5f88\u654f\u611f\u3002\u6211\u5011\u900f\u904e\u5be6\u9a57\u8b49\u660e\uff0c\u751f\u6210\u6aa2\u7d22\u5728\u5169\u500b\u8996\u89ba\u63a8\u7406\u8cc7\u6599\u96c6\uff0c\u91ce\u5916\u8996\u89ba\u5c6c\u6027 (VAW) \u548c\u6211\u5011\u65b0\u63d0\u51fa\u7684\u8996\u89ba\u57fa\u56e0\u7d44\u5c6c\u6027\u6392\u540d (VGARank) \u4e0a\uff0c\u59cb\u7d42\u512a\u65bc\u5c0d\u6bd4\u6aa2\u7d22\u3002", "author": "William Y. Zhu et.al.", "authors": "William Y. Zhu, Keren Ye, Junjie Ke, Jiahui Yu, Leonidas Guibas, Peyman Milanfar, Feng Yang", "id": "2408.04102v1", "paper_url": "http://arxiv.org/abs/2408.04102v1", "repo": "null"}}