{"2410.02742": {"publish_time": "2024-10-03", "title": "Grounding Large Language Models In Embodied Environment With Imperfect World Models", "paper_summary": "Despite a widespread success in various applications, large language models\n(LLMs) often stumble when tackling basic physical reasoning or executing\nrobotics tasks, due to a lack of direct experience with the physical nuances of\nthe real world. To address these issues, we propose a Grounding Large language\nmodel with Imperfect world MOdel (GLIMO), which utilizes proxy world models\nsuch as simulators to collect and synthesize trining data. GLIMO incorporates\nan LLM agent-based data generator to automatically create high-quality and\ndiverse instruction datasets. The generator includes an iterative self-refining\nmodule for temporally consistent experience sampling, a diverse set of\nquestion-answering instruction seeds, and a retrieval-augmented generation\nmodule for reflecting on prior experiences. Comprehensive experiments show that\nour approach improve the performance of strong open-source LLMs like LLaMA-3\nwith a performance boost of 2.04 $\\times$, 1.54 $\\times$, and 1.82 $\\times$\nacross three different benchmarks, respectively. The performance is able to\ncompete with or surpass their larger counterparts such as GPT-4.", "paper_summary_zh": "\u5118\u7ba1\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u5404\u7a2e\u61c9\u7528\u4e2d\u7372\u5f97\u5ee3\u6cdb\u6210\u529f\uff0c\u4f46\u7531\u65bc\u7f3a\u4e4f\u5c0d\u73fe\u5be6\u4e16\u754c\u7269\u7406\u7d30\u5fae\u5dee\u5225\u7684\u76f4\u63a5\u7d93\u9a57\uff0c\u5b83\u5011\u5728\u8655\u7406\u57fa\u672c\u7269\u7406\u63a8\u7406\u6216\u57f7\u884c\u6a5f\u5668\u4eba\u4efb\u52d9\u6642\u7d93\u5e38\u6703\u9047\u5230\u56f0\u96e3\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u5177\u6709\u4e0d\u5b8c\u7f8e\u4e16\u754c\u6a21\u578b (GLIMO) \u7684\u57fa\u790e\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff0c\u5b83\u5229\u7528\u4ee3\u7406\u4e16\u754c\u6a21\u578b\uff08\u4f8b\u5982\u6a21\u64ec\u5668\uff09\u4f86\u6536\u96c6\u548c\u7d9c\u5408\u8a13\u7df4\u8cc7\u6599\u3002GLIMO \u7d50\u5408\u4e86\u4e00\u500b\u57fa\u65bc LLM \u4ee3\u7406\u7684\u8cc7\u6599\u751f\u6210\u5668\uff0c\u4ee5\u81ea\u52d5\u5efa\u7acb\u9ad8\u54c1\u8cea\u4e14\u591a\u6a23\u5316\u7684\u6307\u4ee4\u8cc7\u6599\u96c6\u3002\u8a72\u751f\u6210\u5668\u5305\u542b\u4e00\u500b\u53cd\u8986\u81ea\u6211\u7cbe\u7149\u6a21\u7d44\uff0c\u7528\u65bc\u6642\u9593\u4e00\u81f4\u7684\u7d93\u9a57\u53d6\u6a23\u3001\u4e00\u5957\u591a\u6a23\u5316\u7684\u554f\u7b54\u6307\u4ee4\u7a2e\u5b50\uff0c\u4ee5\u53ca\u4e00\u500b\u6aa2\u7d22\u589e\u5f37\u751f\u6210\u6a21\u7d44\uff0c\u7528\u65bc\u53cd\u601d\u5148\u524d\u7684\u7d93\u9a57\u3002\u5168\u9762\u7684\u5be6\u9a57\u8868\u660e\uff0c\u6211\u5011\u7684\u505a\u6cd5\u6539\u5584\u4e86\u5f37\u5927\u7684\u958b\u6e90 LLM\uff08\u4f8b\u5982 LLaMA-3\uff09\u7684\u6548\u80fd\uff0c\u5206\u5225\u5728\u4e09\u500b\u4e0d\u540c\u7684\u57fa\u6e96\u4e2d\u63d0\u5347\u4e86 2.04 \u500d\u30011.54 \u500d\u548c 1.82 \u500d\u3002\u8a72\u6548\u80fd\u80fd\u5920\u8207 GPT-4 \u7b49\u898f\u6a21\u66f4\u5927\u7684\u540c\u985e\u7522\u54c1\u7af6\u722d\u6216\u8d85\u8d8a\u5b83\u5011\u3002", "author": "Haolan Liu et.al.", "authors": "Haolan Liu, Jishen Zhao", "id": "2410.02742v1", "paper_url": "http://arxiv.org/abs/2410.02742v1", "repo": "null"}}