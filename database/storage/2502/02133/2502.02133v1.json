{"2502.02133": {"publish_time": "2025-02-04", "title": "Synthesis of Model Predictive Control and Reinforcement Learning: Survey and Classification", "paper_summary": "The fields of MPC and RL consider two successful control techniques for\nMarkov decision processes. Both approaches are derived from similar fundamental\nprinciples, and both are widely used in practical applications, including\nrobotics, process control, energy systems, and autonomous driving. Despite\ntheir similarities, MPC and RL follow distinct paradigms that emerged from\ndiverse communities and different requirements. Various technical\ndiscrepancies, particularly the role of an environment model as part of the\nalgorithm, lead to methodologies with nearly complementary advantages. Due to\ntheir orthogonal benefits, research interest in combination methods has\nrecently increased significantly, leading to a large and growing set of complex\nideas leveraging MPC and RL. This work illuminates the differences,\nsimilarities, and fundamentals that allow for different combination algorithms\nand categorizes existing work accordingly. Particularly, we focus on the\nversatile actor-critic RL approach as a basis for our categorization and\nexamine how the online optimization approach of MPC can be used to improve the\noverall closed-loop performance of a policy.", "paper_summary_zh": "MPC \u8207 RL \u7684\u9818\u57df\u8003\u91cf\u4e86\u99ac\u53ef\u592b\u6c7a\u7b56\u7a0b\u5e8f\u7684\u5169\u7a2e\u6210\u529f\u63a7\u5236\u6280\u8853\u3002\u5169\u7a2e\u65b9\u6cd5\u7686\u6e90\u81ea\u65bc\u76f8\u4f3c\u7684\u57fa\u672c\u539f\u7406\uff0c\u4e14\u5169\u8005\u7686\u5ee3\u6cdb\u7528\u65bc\u5be6\u969b\u61c9\u7528\uff0c\u5305\u62ec\u6a5f\u5668\u4eba\u3001\u88fd\u7a0b\u63a7\u5236\u3001\u80fd\u6e90\u7cfb\u7d71\u548c\u81ea\u52d5\u99d5\u99db\u3002\u5118\u7ba1\u6709\u76f8\u4f3c\u4e4b\u8655\uff0c\u4f46 MPC \u548c RL \u8ffd\u96a8\u4e0d\u540c\u7684\u5178\u7bc4\uff0c\u9019\u4e9b\u5178\u7bc4\u4f86\u81ea\u4e0d\u540c\u7684\u793e\u7fa4\u548c\u4e0d\u540c\u7684\u9700\u6c42\u3002\u5404\u7a2e\u6280\u8853\u5dee\u7570\uff0c\u7279\u5225\u662f\u74b0\u5883\u6a21\u578b\u5728\u6f14\u7b97\u6cd5\u4e2d\u626e\u6f14\u7684\u89d2\u8272\uff0c\u5c0e\u81f4\u65b9\u6cd5\u8ad6\u5177\u6709\u5e7e\u4e4e\u4e92\u88dc\u7684\u512a\u52e2\u3002\u7531\u65bc\u5176\u6b63\u4ea4\u512a\u9ede\uff0c\u5c0d\u7d44\u5408\u65b9\u6cd5\u7684\u7814\u7a76\u8208\u8da3\u6700\u8fd1\u986f\u8457\u589e\u52a0\uff0c\u5c0e\u81f4\u5927\u91cf\u4e14\u6301\u7e8c\u589e\u52a0\u7684\u8907\u96dc\u60f3\u6cd5\u5229\u7528 MPC \u548c RL\u3002\u9019\u9805\u5de5\u4f5c\u95e1\u660e\u4e86\u5dee\u7570\u3001\u76f8\u4f3c\u6027\u548c\u57fa\u672c\u539f\u7406\uff0c\u9019\u4e9b\u539f\u7406\u5141\u8a31\u4e0d\u540c\u7684\u7d44\u5408\u6f14\u7b97\u6cd5\uff0c\u4e26\u64da\u6b64\u5c0d\u73fe\u6709\u5de5\u4f5c\u9032\u884c\u5206\u985e\u3002\u7279\u5225\u662f\uff0c\u6211\u5011\u5c08\u6ce8\u65bc\u591a\u529f\u80fd\u7684\u52d5\u4f5c-\u8a55\u8ad6 RL \u65b9\u6cd5\u4f5c\u70ba\u6211\u5011\u5206\u985e\u7684\u57fa\u790e\uff0c\u4e26\u63a2\u8a0e\u5982\u4f55\u4f7f\u7528 MPC \u7684\u7dda\u4e0a\u6700\u4f73\u5316\u65b9\u6cd5\u4f86\u6539\u5584\u7b56\u7565\u7684\u6574\u9ad4\u9589\u8ff4\u8def\u6548\u80fd\u3002", "author": "Rudolf Reiter et.al.", "authors": "Rudolf Reiter, Jasper Hoffmann, Dirk Reinhardt, Florian Messerer, Katrin Baumg\u00e4rtner, Shamburaj Sawant, Joschka Boedecker, Moritz Diehl, Sebastien Gros", "id": "2502.02133v1", "paper_url": "http://arxiv.org/abs/2502.02133v1", "repo": "null"}}