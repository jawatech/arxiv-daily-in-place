
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-02-19**|**Autellix: An Efficient Serving Engine for LLM Agents as General Programs**|Michael Luo et.al.|[2502.13965v1](http://arxiv.org/abs/2502.13965v1)|null|
|**2025-02-19**|**A Training-Free Framework for Precise Mobile Manipulation of Small Everyday Objects**|Arjun Gupta et.al.|[2502.13964v1](http://arxiv.org/abs/2502.13964v1)|null|
|**2025-02-19**|**MuDAF: Long-Context Multi-Document Attention Focusing through Contrastive Learning on Attention Heads**|Weihao Liu et.al.|[2502.13963v1](http://arxiv.org/abs/2502.13963v1)|null|
|**2025-02-19**|**Is That Your Final Answer? Test-Time Scaling Improves Selective Question Answering**|William Jurayj et.al.|[2502.13962v1](http://arxiv.org/abs/2502.13962v1)|null|
|**2025-02-19**|**LIDDIA: Language-based Intelligent Drug Discovery Agent**|Reza Averly et.al.|[2502.13959v1](http://arxiv.org/abs/2502.13959v1)|null|
|**2025-02-19**|**RAG-Gym: Optimizing Reasoning and Search Agents with Process Supervision**|Guangzhi Xiong et.al.|[2502.13957v1](http://arxiv.org/abs/2502.13957v1)|null|
|**2025-02-19**|**Latent Distribution Decoupling: A Probabilistic Framework for Uncertainty-Aware Multimodal Emotion Recognition**|Jingwang Huang et.al.|[2502.13954v1](http://arxiv.org/abs/2502.13954v1)|[link](https://github.com/201983290498/lddu_mmer)|
|**2025-02-19**|**Neurosymbolic artificial intelligence via large language models and coherence-driven inference**|Steve Huntsman et.al.|[2502.13953v1](http://arxiv.org/abs/2502.13953v1)|null|
|**2025-02-19**|**Why Safeguarded Ships Run Aground? Aligned Large Language Models' Safety Mechanisms Tend to Be Anchored in The Template Region**|Chak Tou Leong et.al.|[2502.13946v1](http://arxiv.org/abs/2502.13946v1)|null|
|**2025-02-19**|**AdaptiveStep: Automatically Dividing Reasoning Step through Model Confidence**|Yuliang Liu et.al.|[2502.13943v1](http://arxiv.org/abs/2502.13943v1)|null|
|**2025-02-19**|**Continually Learning Structured Visual Representations via Network Refinement with Rerelation**|Zeki Doruk Erden et.al.|[2502.13935v1](http://arxiv.org/abs/2502.13935v1)|null|
|**2025-02-19**|**Symmetrical Visual Contrastive Optimization: Aligning Vision-Language Models with Minimal Contrastive Images**|Shengguang Wu et.al.|[2502.13928v1](http://arxiv.org/abs/2502.13928v1)|null|
|**2025-02-19**|**Beyond Single Frames: Can LMMs Comprehend Temporal and Contextual Narratives in Image Sequences?**|Xiaochen Wang et.al.|[2502.13925v1](http://arxiv.org/abs/2502.13925v1)|null|
|**2025-02-19**|**Qwen2.5-VL Technical Report**|Shuai Bai et.al.|[2502.13923v1](http://arxiv.org/abs/2502.13923v1)|null|
|**2025-02-19**|**LongPO: Long Context Self-Evolution of Large Language Models through Short-to-Long Preference Optimization**|Guanzheng Chen et.al.|[2502.13922v1](http://arxiv.org/abs/2502.13922v1)|[link](https://github.com/DAMO-NLP-SG/LongPO)|
|**2025-02-19**|**Exploring Personalized Health Support through Data-Driven, Theory-Guided LLMs: A Case Study in Sleep Health**|Xingbo Wang et.al.|[2502.13920v1](http://arxiv.org/abs/2502.13920v1)|null|
|**2025-02-19**|**TESS 2: A Large-Scale Generalist Diffusion Language Model**|Jaesung Tae et.al.|[2502.13917v1](http://arxiv.org/abs/2502.13917v1)|null|
|**2025-02-19**|**How Do LLMs Perform Two-Hop Reasoning in Context?**|Tianyu Guo et.al.|[2502.13913v1](http://arxiv.org/abs/2502.13913v1)|null|
|**2025-02-19**|**Lost in Sequence: Do Large Language Models Understand Sequential Recommendation?**|Sein Kim et.al.|[2502.13909v1](http://arxiv.org/abs/2502.13909v1)|null|
|**2025-02-19**|**Partially Observable Gaussian Process Network and Doubly Stochastic Variational Inference**|Saksham Kiroriwal et.al.|[2502.13905v1](http://arxiv.org/abs/2502.13905v1)|null|
|**2025-02-19**|**DataSciBench: An LLM Agent Benchmark for Data Science**|Dan Zhang et.al.|[2502.13897v1](http://arxiv.org/abs/2502.13897v1)|null|
|**2025-02-19**|**PSCon: Toward Conversational Product Search**|Jie Zou et.al.|[2502.13881v1](http://arxiv.org/abs/2502.13881v1)|null|
|**2025-02-19**|**MEX: Memory-efficient Approach to Referring Multi-Object Tracking**|Huu-Thien Tran et.al.|[2502.13875v1](http://arxiv.org/abs/2502.13875v1)|null|
|**2025-02-19**|**NVR: Vector Runahead on NPUs for Sparse Memory Access**|Hui Wang et.al.|[2502.13873v1](http://arxiv.org/abs/2502.13873v1)|null|
|**2025-02-19**|**SPEX: Scaling Feature Interaction Explanations for LLMs**|Justin Singh Kang et.al.|[2502.13870v1](http://arxiv.org/abs/2502.13870v1)|[link](https://github.com/basics-lab/spectral-explain)|
|**2025-02-19**|**DH-RAG: A Dynamic Historical Context-Powered Retrieval-Augmented Generation Method for Multi-Turn Dialogue**|Feiyuan Zhang et.al.|[2502.13847v1](http://arxiv.org/abs/2502.13847v1)|null|
|**2025-02-19**|**Enhancing LLM-Based Recommendations Through Personalized Reasoning**|Jiahao Liu et.al.|[2502.13845v1](http://arxiv.org/abs/2502.13845v1)|null|
|**2025-02-19**|**Enhancing Cross-Domain Recommendations with Memory-Optimized LLM-Based User Agents**|Jiahao Liu et.al.|[2502.13843v1](http://arxiv.org/abs/2502.13843v1)|null|
|**2025-02-19**|**Inner Thinking Transformer: Leveraging Dynamic Depth Scaling to Foster Adaptive Internal Thinking**|Yilong Chen et.al.|[2502.13842v1](http://arxiv.org/abs/2502.13842v1)|null|
|**2025-02-19**|**Quantifying Memorization and Retriever Performance in Retrieval-Augmented Vision-Language Models**|Peter Carragher et.al.|[2502.13836v1](http://arxiv.org/abs/2502.13836v1)|null|
|**2025-02-19**|**Proving Olympiad Inequalities by Synergizing LLMs and Symbolic Reasoning**|Zenan Li et.al.|[2502.13834v1](http://arxiv.org/abs/2502.13834v1)|null|
|**2025-02-19**|**Scoring Verifiers: Evaluating Synthetic Verification in Code and Reasoning**|Aleksander Ficek et.al.|[2502.13820v1](http://arxiv.org/abs/2502.13820v1)|null|
|**2025-02-19**|**On the Duality between Gradient Transformations and Adapters**|Lucas Torroba-Hennigen et.al.|[2502.13811v1](http://arxiv.org/abs/2502.13811v1)|null|
|**2025-02-19**|**LESA: Learnable LLM Layer Scaling-Up**|Yifei Yang et.al.|[2502.13794v1](http://arxiv.org/abs/2502.13794v1)|null|
|**2025-02-19**|**From Tools to Teammates: Evaluating LLMs in Multi-Session Coding Interactions**|NathanaÃ«l Carraz Rakotonirina et.al.|[2502.13791v1](http://arxiv.org/abs/2502.13791v1)|null|
|**2025-02-19**|**Helix-mRNA: A Hybrid Foundation Model For Full Sequence mRNA Therapeutics**|Matthew Wood et.al.|[2502.13785v1](http://arxiv.org/abs/2502.13785v1)|null|
|**2025-02-19**|**Translation in the Hands of Many:Centering Lay Users in Machine Translation Interactions**|Beatrice Savoldi et.al.|[2502.13780v1](http://arxiv.org/abs/2502.13780v1)|null|
|**2025-02-19**|**Poster: SpiderSim: Multi-Agent Driven Theoretical Cybersecurity Simulation for Industrial Digitalization**|Jiaqi Li et.al.|[2502.13778v1](http://arxiv.org/abs/2502.13778v1)|null|
|**2025-02-19**|**EHOP: A Dataset of Everyday NP-Hard Optimization Problems**|Alex Duchnowski et.al.|[2502.13776v1](http://arxiv.org/abs/2502.13776v1)|null|
|**2025-02-19**|**VITAL: A New Dataset for Benchmarking Pluralistic Alignment in Healthcare**|Anudeex Shetty et.al.|[2502.13775v1](http://arxiv.org/abs/2502.13775v1)|null|
|**2025-02-19**|**A consensus set for the aggregation of partial rankings: the case of the Optimal Set of Bucket Orders Problem**|Juan A. Aledo et.al.|[2502.13769v1](http://arxiv.org/abs/2502.13769v1)|null|
|**2025-02-19**|**AI Software Engineer: Programming with Trust**|Abhik Roychoudhury et.al.|[2502.13767v1](http://arxiv.org/abs/2502.13767v1)|null|
|**2025-02-19**|**GIMMICK -- Globally Inclusive Multimodal Multitask Cultural Knowledge Benchmarking**|Florian Schneider et.al.|[2502.13766v1](http://arxiv.org/abs/2502.13766v1)|null|
|**2025-02-19**|**SCALAR: Scientific Citation-based Live Assessment of Long-context Academic Reasoning**|Renxi Wang et.al.|[2502.13753v1](http://arxiv.org/abs/2502.13753v1)|null|
|**2025-02-19**|**RobustX: Robust Counterfactual Explanations Made Easy**|Junqi Jiang et.al.|[2502.13751v1](http://arxiv.org/abs/2502.13751v1)|null|
|**2025-02-19**|**Inference of Abstraction for Grounded Predicate Logic**|Hiroyuki Kido et.al.|[2502.13743v1](http://arxiv.org/abs/2502.13743v1)|null|
|**2025-02-19**|**Enhancing Input-Label Mapping in In-Context Learning with Contrastive Decoding**|Keqin Peng et.al.|[2502.13738v1](http://arxiv.org/abs/2502.13738v1)|null|
|**2025-02-19**|**Robust Counterfactual Inference in Markov Decision Processes**|Jessica Lally et.al.|[2502.13731v1](http://arxiv.org/abs/2502.13731v1)|null|
|**2025-02-19**|**Secure Federated Data Distillation**|Marco Arazzi et.al.|[2502.13728v1](http://arxiv.org/abs/2502.13728v1)|null|
|**2025-02-19**|**Adapting Large Language Models for Time Series Modeling via a Novel Parameter-efficient Adaptation Method**|Juyuan Zhang et.al.|[2502.13725v1](http://arxiv.org/abs/2502.13725v1)|null|
|**2025-02-19**|**Direct Value Optimization: Improving Chain-of-Thought Reasoning in LLMs with Refined Values**|Hongbo Zhang et.al.|[2502.13723v1](http://arxiv.org/abs/2502.13723v1)|null|
|**2025-02-19**|**Learning Novel Transformer Architecture for Time-series Forecasting**|Juyuan Zhang et.al.|[2502.13721v1](http://arxiv.org/abs/2502.13721v1)|null|
|**2025-02-19**|**TrustRAG: An Information Assistant with Retrieval Augmented Generation**|Yixing Fan et.al.|[2502.13719v1](http://arxiv.org/abs/2502.13719v1)|null|
|**2025-02-19**|**Multi-Scale and Multi-Objective Optimization for Cross-Lingual Aspect-Based Sentiment Analysis**|Chengyan Wu et.al.|[2502.13718v1](http://arxiv.org/abs/2502.13718v1)|null|
|**2025-02-19**|**Causes and Strategies in Multiagent Systems**|Sylvia S. Kerkhove et.al.|[2502.13701v1](http://arxiv.org/abs/2502.13701v1)|null|
|**2025-02-19**|**Is This Collection Worth My LLM's Time? Automatically Measuring Information Potential in Text Corpora**|Tristan Karch et.al.|[2502.13691v1](http://arxiv.org/abs/2502.13691v1)|null|
|**2025-02-19**|**MoM: Linear Sequence Modeling with Mixture-of-Memories**|Jusen Du et.al.|[2502.13685v1](http://arxiv.org/abs/2502.13685v1)|null|
|**2025-02-19**|**An LLM-based Agent for Reliable Docker Environment Configuration**|Ruida Hu et.al.|[2502.13681v1](http://arxiv.org/abs/2502.13681v1)|null|
|**2025-02-19**|**SCOPE: A Self-supervised Framework for Improving Faithfulness in Conditional Text Generation**|Song Duong et.al.|[2502.13674v1](http://arxiv.org/abs/2502.13674v1)|null|
|**2025-02-19**|**PeerQA: A Scientific Question Answering Dataset from Peer Reviews**|Tim BaumgÃ¤rtner et.al.|[2502.13668v1](http://arxiv.org/abs/2502.13668v1)|null|
|**2025-02-19**|**Refining Sentence Embedding Model through Ranking Sentences Generation with Large Language Models**|Liyang He et.al.|[2502.13656v1](http://arxiv.org/abs/2502.13656v1)|null|
|**2025-02-19**|**C2T: A Classifier-Based Tree Construction Method in Speculative Decoding**|Feiye Huo et.al.|[2502.13652v1](http://arxiv.org/abs/2502.13652v1)|null|
|**2025-02-19**|**Reliability Across Parametric and External Knowledge: Understanding Knowledge Handling in LLMs**|Youna Kim et.al.|[2502.13648v1](http://arxiv.org/abs/2502.13648v1)|null|
|**2025-02-19**|**Instruction Tuning on Public Government and Cultural Data for Low-Resource Language: a Case Study in Kazakh**|Nurkhan Laiyk et.al.|[2502.13647v1](http://arxiv.org/abs/2502.13647v1)|null|
|**2025-02-19**|**D.Va: Validate Your Demonstration First Before You Use It**|Qi Zhang et.al.|[2502.13646v1](http://arxiv.org/abs/2502.13646v1)|null|
|**2025-02-19**|**Measuring the Effect of Transcription Noise on Downstream Language Understanding Tasks**|Ori Shapira et.al.|[2502.13645v1](http://arxiv.org/abs/2502.13645v1)|null|
|**2025-02-19**|**Qorgau: Evaluating LLM Safety in Kazakh-Russian Bilingual Contexts**|Maiya Goloburda et.al.|[2502.13640v1](http://arxiv.org/abs/2502.13640v1)|null|
|**2025-02-19**|**Integrating Inverse and Forward Modeling for Sparse Temporal Data from Sensor Networks**|Julian Vexler et.al.|[2502.13638v1](http://arxiv.org/abs/2502.13638v1)|null|
|**2025-02-19**|**Concept Layers: Enhancing Interpretability and Intervenability via LLM Conceptualization**|Or Raphael Bidusa et.al.|[2502.13632v1](http://arxiv.org/abs/2502.13632v1)|null|
|**2025-02-19**|**Non-Euclidean Hierarchical Representational Learning using Hyperbolic Graph Neural Networks for Environmental Claim Detection**|Darpan Aswal et.al.|[2502.13628v1](http://arxiv.org/abs/2502.13628v1)|null|
|**2025-02-19**|**REFIND: Retrieval-Augmented Factuality Hallucination Detection in Large Language Models**|DongGeon Lee et.al.|[2502.13622v1](http://arxiv.org/abs/2502.13622v1)|null|
|**2025-02-19**|**Decentralized Planning Using Probabilistic Hyperproperties**|Francesco Pontiggia et.al.|[2502.13621v1](http://arxiv.org/abs/2502.13621v1)|null|
|**2025-02-19**|**Complex Ontology Matching with Large Language Model Embeddings**|Guilherme Sousa et.al.|[2502.13619v1](http://arxiv.org/abs/2502.13619v1)|null|
|**2025-02-19**|**LaVCa: LLM-assisted Visual Cortex Captioning**|Takuya Matsuyama et.al.|[2502.13606v1](http://arxiv.org/abs/2502.13606v1)|null|
|**2025-02-19**|**BeamLoRA: Beam-Constraint Low-Rank Adaptation**|Naibin Gu et.al.|[2502.13604v1](http://arxiv.org/abs/2502.13604v1)|null|
|**2025-02-19**|**Efficient Safety Retrofitting Against Jailbreaking for LLMs**|Dario Garcia-Gasulla et.al.|[2502.13603v1](http://arxiv.org/abs/2502.13603v1)|null|
|**2025-02-19**|**MMTEB: Massive Multilingual Text Embedding Benchmark**|Kenneth Enevoldsen et.al.|[2502.13595v1](http://arxiv.org/abs/2502.13595v1)|null|
|**2025-02-19**|**Don't Stop the Multi-Party! On Generating Synthetic Multi-Party Conversations with Constraints**|NicolÃ² Penzo et.al.|[2502.13592v1](http://arxiv.org/abs/2502.13592v1)|null|
|**2025-02-19**|**Beyond One-Size-Fits-All: Tailored Benchmarks for Efficient Evaluation**|Peiwen Yuan et.al.|[2502.13576v1](http://arxiv.org/abs/2502.13576v1)|null|
|**2025-02-19**|**Model Evolution Framework with Genetic Algorithm for Multi-Task Reinforcement Learning**|Yan Yu et.al.|[2502.13569v1](http://arxiv.org/abs/2502.13569v1)|null|
|**2025-02-19**|**LSR-Adapt: Ultra-Efficient Parameter Tuning with Matrix Low Separation Rank Kernel Adaptation**|Xin Li et.al.|[2502.13568v1](http://arxiv.org/abs/2502.13568v1)|null|
|**2025-02-19**|**Extracting Social Connections from Finnish Karelian Refugee Interviews Using LLMs**|Joonatan Laato et.al.|[2502.13566v1](http://arxiv.org/abs/2502.13566v1)|null|
|**2025-02-19**|**PRIV-QA: Privacy-Preserving Question Answering for Cloud Large Language Models**|Guangwei Li et.al.|[2502.13564v1](http://arxiv.org/abs/2502.13564v1)|null|
|**2025-02-19**|**Are Large Language Models In-Context Graph Learners?**|Jintang Li et.al.|[2502.13562v1](http://arxiv.org/abs/2502.13562v1)|null|
|**2025-02-19**|**Democratizing Large Language Model-Based Graph Data Augmentation via Latent Knowledge Graphs**|Yushi Feng et.al.|[2502.13555v1](http://arxiv.org/abs/2502.13555v1)|null|
|**2025-02-19**|**STaR-SQL: Self-Taught Reasoner for Text-to-SQL**|Mingqian He et.al.|[2502.13550v1](http://arxiv.org/abs/2502.13550v1)|null|
|**2025-02-19**|**Detecting Linguistic Bias in Government Documents Using Large language Models**|Milena de Swart et.al.|[2502.13548v1](http://arxiv.org/abs/2502.13548v1)|null|
|**2025-02-19**|**From Sub-Ability Diagnosis to Human-Aligned Generation: Bridging the Gap for Text Length Control via MARKERGEN**|Peiwen Yuan et.al.|[2502.13544v1](http://arxiv.org/abs/2502.13544v1)|null|
|**2025-02-19**|**Activation-aware Probe-Query: Effective Key-Value Retrieval for Long-Context LLMs Inference**|Qingfa Xiao et.al.|[2502.13542v1](http://arxiv.org/abs/2502.13542v1)|null|
|**2025-02-19**|**Train Small, Infer Large: Memory-Efficient LoRA Training for Large Language Models**|Jun Zhang et.al.|[2502.13533v1](http://arxiv.org/abs/2502.13533v1)|null|
|**2025-02-19**|**Exploiting Prefix-Tree in Structured Output Interfaces for Enhancing Jailbreak Attacking**|Yanzeng Li et.al.|[2502.13527v1](http://arxiv.org/abs/2502.13527v1)|null|
|**2025-02-19**|**MobileViM: A Light-weight and Dimension-independent Vision Mamba for 3D Medical Image Analysis**|Wei Dai et.al.|[2502.13524v1](http://arxiv.org/abs/2502.13524v1)|[link](https://github.com/anthonyweidai/MobileViM_3D)|
|**2025-02-19**|**A Large and Balanced Corpus for Fine-grained Arabic Readability Assessment**|Khalid N. Elmadani et.al.|[2502.13520v1](http://arxiv.org/abs/2502.13520v1)|null|
|**2025-02-19**|**MILE: Model-based Intervention Learning**|Yigit Korkmaz et.al.|[2502.13519v1](http://arxiv.org/abs/2502.13519v1)|null|
|**2025-02-19**|**SPPD: Self-training with Process Preference Learning Using Dynamic Value Margin**|Hao Yi et.al.|[2502.13516v1](http://arxiv.org/abs/2502.13516v1)|null|
|**2025-02-19**|**Shall Your Data Strategy Work? Perform a Swift Study**|Minlong Peng et.al.|[2502.13514v1](http://arxiv.org/abs/2502.13514v1)|null|
|**2025-02-19**|**Unlocking Multimodal Integration in EHRs: A Prompt Learning Framework for Language and Time Series Fusion**|Shuai Niu et.al.|[2502.13509v1](http://arxiv.org/abs/2502.13509v1)|null|
|**2025-02-19**|**PLDR-LLMs Learn A Generalizable Tensor Operator That Can Replace Its Own Deep Neural Net At Inference**|Burc Gokden et.al.|[2502.13502v1](http://arxiv.org/abs/2502.13502v1)|null|
|**2025-02-19**|**Hidden Darkness in LLM-Generated Designs: Exploring Dark Patterns in Ecommerce Web Components Generated by LLMs**|Ziwei Chen et.al.|[2502.13499v1](http://arxiv.org/abs/2502.13499v1)|null|
|**2025-02-19**|**Towards Geo-Culturally Grounded LLM Generations**|Piyawat Lertvittayakumjorn et.al.|[2502.13497v1](http://arxiv.org/abs/2502.13497v1)|null|

#### Abstracts
##### **Autellix: An Efficient Serving Engine for LLM Agents as General Programs**
2502.13965v1 by Michael Luo, Xiaoxiang Shi, Colin Cai, Tianjun Zhang, Justin Wong, Yichuan Wang, Chi Wang, Yanping Huang, Zhifeng Chen, Joseph E. Gonzalez, Ion Stoica

Large language model (LLM) applications are evolving beyond simple chatbots
into dynamic, general-purpose agentic programs, which scale LLM calls and
output tokens to help AI agents reason, explore, and solve complex tasks.
However, existing LLM serving systems ignore dependencies between programs and
calls, missing significant opportunities for optimization. Our analysis reveals
that programs submitted to LLM serving engines experience long cumulative wait
times, primarily due to head-of-line blocking at both the individual LLM
request and the program. To address this, we introduce Autellix, an LLM serving
system that treats programs as first-class citizens to minimize their
end-to-end latencies. Autellix intercepts LLM calls submitted by programs,
enriching schedulers with program-level context. We propose two scheduling
algorithms-for single-threaded and distributed programs-that preempt and
prioritize LLM calls based on their programs' previously completed calls. Our
evaluation demonstrates that across diverse LLMs and agentic workloads,
Autellix improves throughput of programs by 4-15x at the same latency compared
to state-of-the-art systems, such as vLLM.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æç¨æ­£å¾ç°¡å®çèå¤©æ©å¨äººæ¼è®æåæãéç¨çä»£çç¨å¼ï¼å®æ´å±äº LLM çå¼å«ï¼ä¸¦è¼¸åºä»£ç¢¼ï¼ä»¥å¹«å© AI ä»£çæ¨çãæ¢ç´¢åè§£æ±ºè¤éä»»åã
ç¶èï¼ç¾æç LLM æåç³»çµ±å¿½è¦äºç¨å¼åå¼å«ä¹éçä¾è³´éä¿ï¼é¯å¤±äºæä½³åçéè¦æ©æãæåçåæé¡¯ç¤ºï¼æäº¤çµ¦ LLM æåå¼æçç¨å¼æéå°é·æéçç´¯ç©ç­å¾æéï¼éä¸»è¦æ¯å çºå¨åå¥ LLM è«æ±åç¨å¼ä¸­é½æç¼çéåé ­ç«¯å°éãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº Autellixï¼éæ¯ä¸å LLM æåç³»çµ±ï¼å®å°ç¨å¼è¦çºä¸ç´å¬æ°ï¼ä»¥æå°åå¶ç«¯å°ç«¯å»¶é²ãAutellix æææªç¨å¼æäº¤ç LLM å¼å«ï¼ä¸¦ä½¿ç¨ç¨å¼å±¤ç´çå§å®¹è±å¯æç¨å¨ãæåæåºäºå©ç¨®æç¨æ¼ç®æ³ï¼åå¥é©ç¨æ¼å®å·è¡ç·ååæ£å¼ç¨å¼ï¼éäºæ¼ç®æ³ææ ¹æç¨å¼ååå®æçå¼å«ï¼åªåèçåé åèç LLM å¼å«ãæåçè©ä¼°è­æï¼è vLLM ç­æåé²çç³»çµ±ç¸æ¯ï¼å¨ç¸åçå»¶é²ä¸ï¼Autellix å¯å°ç¨å¼çèçéæå 4-15 åï¼ä¸é©ç¨æ¼åç¨® LLM åä»£çå·¥ä½è² è¼ã

##### **A Training-Free Framework for Precise Mobile Manipulation of Small Everyday Objects**
2502.13964v1 by Arjun Gupta, Rishik Sathua, Saurabh Gupta

Many everyday mobile manipulation tasks require precise interaction with
small objects, such as grasping a knob to open a cabinet or pressing a light
switch. In this paper, we develop Servoing with Vision Models (SVM), a
closed-loop training-free framework that enables a mobile manipulator to tackle
such precise tasks involving the manipulation of small objects. SVM employs an
RGB-D wrist camera and uses visual servoing for control. Our novelty lies in
the use of state-of-the-art vision models to reliably compute 3D targets from
the wrist image for diverse tasks and under occlusion due to the end-effector.
To mitigate occlusion artifacts, we employ vision models to out-paint the
end-effector thereby significantly enhancing target localization. We
demonstrate that aided by out-painting methods, open-vocabulary object
detectors can serve as a drop-in module to identify semantic targets (e.g.
knobs) and point tracking methods can reliably track interaction sites
indicated by user clicks. This training-free method obtains an 85% zero-shot
success rate on manipulating unseen objects in novel environments in the real
world, outperforming an open-loop control method and an imitation learning
baseline trained on 1000+ demonstrations by an absolute success rate of 50%.

æè¦ï¼è¨±å¤æ¥å¸¸è¡åæä½ä»»åéè¦èå°ç©ä»¶ç²¾ç¢ºäºåï¼ä¾å¦æ¡ä½æéæéæ«å­ææä¸çééãå¨æ¬æä¸­ï¼æåéç¼äºå·åè¦è¦ºæ¨¡åçä¼ºææ§å¶ (SVM)ï¼éæ¯ä¸åéè¿´è·¯åè¨ç·´æ¶æ§ï¼å¯è®è¡åæä½å¨èçæ­¤é¡ç²¾ç¢ºä»»åï¼åæ¬æä½å°ç©ä»¶ãSVM æ¡ç¨ RGB-D æèç¸æ©ï¼ä¸¦ä½¿ç¨è¦è¦ºä¼ºæé²è¡æ§å¶ãæåçåµæ°ä¹èå¨æ¼ä½¿ç¨æåé²çè¦è¦ºæ¨¡åï¼å¾æèå½±åä¸­å¯é å°è¨ç®åº 3D ç®æ¨ï¼ä»¥æä»åç¨®ä»»åï¼ä¸¦å¨æ«ç«¯å·è¡å¨é æé®æçææ³ä¸é²è¡ãçºäºæ¸è¼é®æå½å½±ï¼æåæ¡ç¨è¦è¦ºæ¨¡åä¾å°æ«ç«¯å·è¡å¨é²è¡å¤ç¹ªï¼å¾èé¡¯èå¢å¼·ç®æ¨å®ä½ãæåè­æï¼å¨è¼å©å¤ç¹ªæ¹æ³ä¸ï¼éæ¾å¼è©å½ç©ä»¶åµæ¸¬å¨å¯ç¨ä½æå¥å¼æ¨¡çµï¼ä»¥è­å¥èªç¾©ç®æ¨ (ä¾å¦æé)ï¼èé»è¿½è¹¤æ¹æ³å¯ä»¥å¯é å°è¿½è¹¤ä½¿ç¨èé»ææç¤ºçäºåä½ç½®ãéç¨®åè¨ç·´æ¹æ³å¨ç¾å¯¦ä¸çä¸­ï¼å°æ°ç°å¢ä¸­çæªè¦ç©ä»¶é²è¡æä½ï¼ç²å¾ 85% çé¶æ¬¡å­¸ç¿æåçï¼åªæ¼éæ¾è¿´è·¯æ§å¶æ¹æ³ååºæ¼ 1000 å¤æ¬¡ç¤ºç¯é²è¡æ¨¡ä»¿å­¸ç¿çåºæºï¼å¾èççµå°æåççº 50%ã

##### **MuDAF: Long-Context Multi-Document Attention Focusing through Contrastive Learning on Attention Heads**
2502.13963v1 by Weihao Liu, Ning Wu, Shiping Yang, Wenbiao Ding, Shining Liang, Ming Gong, Dongmei Zhang

Large Language Models (LLMs) frequently show distracted attention due to
irrelevant information in the input, which severely impairs their long-context
capabilities. Inspired by recent studies on the effectiveness of retrieval
heads in long-context factutality, we aim at addressing this distraction issue
through improving such retrieval heads directly. We propose Multi-Document
Attention Focusing (MuDAF), a novel method that explicitly optimizes the
attention distribution at the head level through contrastive learning.
According to the experimental results, MuDAF can significantly improve the
long-context question answering performance of LLMs, especially in
multi-document question answering. Extensive evaluations on retrieval scores
and attention visualizations show that MuDAF possesses great potential in
making attention heads more focused on relevant information and reducing
attention distractions.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ç¶å¸¸æå çºè¼¸å¥ä¸­çç¡éè³è¨èè¡¨ç¾åºæ³¨æååæ£ï¼éå´éå°æå®³äºå®åçé·ææ¬è½åãåå°æè¿éæ¼æª¢ç´¢é ­å¨é·ææ¬äºå¯¦æ§ä¸­çæææ§çç ç©¶åç¼ï¼æåæ¨å¨ééç´æ¥æ¹åæ­¤é¡æª¢ç´¢é ­ä¾è§£æ±ºéååå¿åé¡ãæåæåºå¤æä»¶æ³¨æåèç¦ (MuDAF)ï¼éæ¯ä¸ç¨®ééå°æ¯å­¸ç¿æç¢ºæä½³åé ­é¨å±¤ç´æ³¨æååéçæ°æ¹æ³ãæ ¹æå¯¦é©çµæï¼MuDAF å¯ä»¥é¡¯èæå LLM çé·ææ¬åç­æè½ï¼ç¹å¥æ¯å¨å¤æä»¶åç­ä¸­ãå¨æª¢ç´¢åæ¸åæ³¨æåè¦è¦ºåä¸çå»£æ³è©ä¼°é¡¯ç¤ºï¼MuDAF å·æè®æ³¨æåé ­é¨æ´å°æ³¨æ¼ç¸éè³è¨ä¸¦æ¸å°æ³¨æååæ£çå·¨å¤§æ½åã

##### **Is That Your Final Answer? Test-Time Scaling Improves Selective Question Answering**
2502.13962v1 by William Jurayj, Jeffrey Cheng, Benjamin Van Durme

Scaling the test-time compute of large language models has demonstrated
impressive performance on reasoning benchmarks. However, existing evaluations
of test-time scaling make the strong assumption that a reasoning system should
always give an answer to any question provided. This overlooks concerns about
whether a model is confident in its answer, and whether it is appropriate to
always provide a response. To address these concerns, we extract confidence
scores during reasoning for thresholding model responses. We find that
increasing compute budget at inference time not only helps models answer more
questions correctly, but also increases confidence in correct responses. We
then extend the current paradigm of zero-risk responses during evaluation by
considering settings with non-zero levels of response risk, and suggest a
recipe for reporting evaluations under these settings.

æè¦ï¼æ´åå¤§åèªè¨æ¨¡åçæ¸¬è©¦æééç®å·²å¨æ¨çåºæºæ¸¬è©¦ä¸­å±ç¾ä»¤äººå°è±¡æ·±å»çæè½ãç¶èï¼ç¾æçæ¸¬è©¦æéæ´åè©ä¼°æååºå¼·ççåè¨­ï¼èªçºæ¨çç³»çµ±æå§çµå°ææä¾çä»»ä½åé¡çµ¦åºç­æ¡ãéå¿½ç¥äºéæ¼æ¨¡åæ¯å¦å°å¶ç­æ¡æä¿¡å¿ï¼ä»¥åæ¯å¦é©ç¶å§çµæä¾åæççæ®ãçºäºè§£æ±ºéäºçæ®ï¼æåå¨æ¨çæéæåä¿¡å¿åæ¸ï¼ä»¥è¨­å®æ¨¡ååæçé¾å¼ãæåç¼ç¾ï¼å¨æ¨è«æéå¢å éç®é ç®ä¸åæå©æ¼æ¨¡åæ­£ç¢ºåç­æ´å¤åé¡ï¼éè½å¢å å°æ­£ç¢ºåæçä¿¡å¿ãç¶å¾ï¼æåééèæ®å·æéé¶åæé¢¨éªå±¤ç´çè¨­å®ï¼æ´åè©ä¼°æéé¶é¢¨éªåæçç¾è¡ç¯ä¾ï¼ä¸¦å»ºè­°å¨éäºè¨­å®ä¸å ±åè©ä¼°çéæ¹ã

##### **LIDDIA: Language-based Intelligent Drug Discovery Agent**
2502.13959v1 by Reza Averly, Frazier N. Baker, Xia Ning

Drug discovery is a long, expensive, and complex process, relying heavily on
human medicinal chemists, who can spend years searching the vast space of
potential therapies. Recent advances in artificial intelligence for chemistry
have sought to expedite individual drug discovery tasks; however, there remains
a critical need for an intelligent agent that can navigate the drug discovery
process. Towards this end, we introduce LIDDiA, an autonomous agent capable of
intelligently navigating the drug discovery process in silico. By leveraging
the reasoning capabilities of large language models, LIDDiA serves as a
low-cost and highly-adaptable tool for autonomous drug discovery. We
comprehensively examine LIDDiA, demonstrating that (1) it can generate
molecules meeting key pharmaceutical criteria on over 70% of 30 clinically
relevant targets, (2) it intelligently balances exploration and exploitation in
the chemical space, and (3) it can identify promising novel drug candidates on
EGFR, a critical target for cancers.

æè¦ï¼è¥ç©ç¼ç¾æ¯ä¸åæ¼«é·ãæè²´ä¸è¤éçéç¨ï¼é«åº¦ä¾è³´äººé¡é«å­¸åå­¸å®¶ï¼ä»åå¯è½è±è²»æ¸å¹´æéæå°æ½å¨çæ³ä¸­çå»£å¤§ç©ºéãæè¿äººå·¥æºæ§å¨åå­¸é åçé²å±è©¦åå éåå¥è¥ç©ç¼ç¾ä»»åï¼ç¶èï¼å°æ¼è½å¤ å¼å°è¥ç©ç¼ç¾éç¨çæºæ§ä»£çäººä»æè¿«åéæ±ãçºæ­¤ï¼æåå¼å¥äº LIDDiAï¼éæ¯ä¸åèªä¸»ä»£çäººï¼è½å¤ å¨é»è¦æ¨¡æ¬ä¸­æºæ§å°å¼å°è¥ç©ç¼ç¾éç¨ãééå©ç¨å¤§åèªè¨æ¨¡åçæ¨çè½åï¼LIDDiA æçºèªä¸»è¥ç©ç¼ç¾çä½ææ¬ä¸é«åº¦é©ææ§å·¥å·ãæåå¨é¢æª¢é© LIDDiAï¼è­æ (1) å®å¯ä»¥å¨ 30 åè¨åºç¸éç®æ¨ä¸­ç 70% ä»¥ä¸ç¢çç¬¦åééµè¥ç©æ¨æºçåå­ï¼(2) å®å¨åå­¸ç©ºéä¸­æºæ§å°å¹³è¡¡æ¢ç´¢åå©ç¨ï¼(3) å®å¯ä»¥è­å¥åº EGFRï¼çççéè¦ç®æ¨ï¼ä¸çæå¸æçæ°è¥åé¸ç©ã

##### **RAG-Gym: Optimizing Reasoning and Search Agents with Process Supervision**
2502.13957v1 by Guangzhi Xiong, Qiao Jin, Xiao Wang, Yin Fang, Haolin Liu, Yifan Yang, Fangyuan Chen, Zhixing Song, Dengyu Wang, Minjia Zhang, Zhiyong Lu, Aidong Zhang

Retrieval-augmented generation (RAG) has shown great potential for
knowledge-intensive tasks, but its traditional architectures rely on static
retrieval, limiting their effectiveness for complex questions that require
sequential information-seeking. While agentic reasoning and search offer a more
adaptive approach, most existing methods depend heavily on prompt engineering.
In this work, we introduce RAG-Gym, a unified optimization framework that
enhances information-seeking agents through fine-grained process supervision at
each search step. We also propose ReSearch, a novel agent architecture that
synergizes answer reasoning and search query generation within the RAG-Gym
framework. Experiments on four challenging datasets show that RAG-Gym improves
performance by up to 25.6\% across various agent architectures, with ReSearch
consistently outperforming existing baselines. Further analysis highlights the
effectiveness of advanced LLMs as process reward judges and the transferability
of trained reward models as verifiers for different LLMs. Additionally, we
examine the scaling properties of training and inference in agentic RAG. The
project homepage is available at https://rag-gym.github.io/.

æè¦ï¼æª¢ç´¢å¢å¼·çæ (RAG) å·²å¨ç¥è­å¯éåä»»åä¸­å±ç¾åºæ¥µå¤§çæ½åï¼ä½å¶å³çµ±æ¶æ§ä¾è³´æ¼éææª¢ç´¢ï¼éå¶äºå¶å°éè¦å¾ªåºè³è¨æå°çè¤éåé¡çæææ§ãéç¶ä»£çæ¨çåæå°æä¾äºæ´å·é©ææ§çæ¹æ³ï¼ä½ç¾ææ¹æ³å¤§å¤é«åº¦ä¾è³´æç¤ºå·¥ç¨ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äº RAG-Gymï¼ä¸åçµ±ä¸çæä½³åæ¶æ§ï¼å®ééå¨æ¯åæå°æ­¥é©ä¸­é²è¡ç´°ç·»çæµç¨ç£ç£ä¾å¢å¼·è³è¨æå°ä»£çãæåéæåºäº ReSearchï¼éæ¯ä¸ç¨®æ°ç©çä»£çæ¶æ§ï¼å®å¨ RAG-Gym æ¶æ§ä¸­ååé²è¡ç­æ¡æ¨çåæå°æ¥è©¢çæãå¨ååå·æææ°æ§çè³æéä¸é²è¡çå¯¦é©è¡¨æï¼RAG-Gym ééåç¨®ä»£çæ¶æ§å°æè½æåäº 25.6%ï¼è ReSearch åå§çµåªæ¼ç¾æçåºç·ãé²ä¸æ­¥çåæçªé¡¯äºé²é LLM ä½çºæµç¨çåµè©å¯©å¡çæææ§ï¼ä»¥åè¨ç·´å¥½ççåµæ¨¡åä½çºä¸å LLM é©è­å¨çå¯è½ç§»æ§ãæ­¤å¤ï¼æåæª¢è¦äºä»£ç RAG ä¸­è¨ç·´åæ¨è«çç¸®æ¾ç¹æ§ãå°æ¡é¦é å¯æ¼ https://rag-gym.github.io/ åå¾ã

##### **Latent Distribution Decoupling: A Probabilistic Framework for Uncertainty-Aware Multimodal Emotion Recognition**
2502.13954v1 by Jingwang Huang, Jiang Zhong, Qin Lei, Jinpeng Gao, Yuming Yang, Sirui Wang, Peiguang Li, Kaiwen Wei

Multimodal multi-label emotion recognition (MMER) aims to identify the
concurrent presence of multiple emotions in multimodal data. Existing studies
primarily focus on improving fusion strategies and modeling modality-to-label
dependencies. However, they often overlook the impact of \textbf{aleatoric
uncertainty}, which is the inherent noise in the multimodal data and hinders
the effectiveness of modality fusion by introducing ambiguity into feature
representations. To address this issue and effectively model aleatoric
uncertainty, this paper proposes Latent emotional Distribution Decomposition
with Uncertainty perception (LDDU) framework from a novel perspective of latent
emotional space probabilistic modeling. Specifically, we introduce a
contrastive disentangled distribution mechanism within the emotion space to
model the multimodal data, allowing for the extraction of semantic features and
uncertainty. Furthermore, we design an uncertainty-aware fusion multimodal
method that accounts for the dispersed distribution of uncertainty and
integrates distribution information. Experimental results show that LDDU
achieves state-of-the-art performance on the CMU-MOSEI and M$^3$ED datasets,
highlighting the importance of uncertainty modeling in MMER. Code is available
at https://github.com/201983290498/lddu\_mmer.git.

æè¦ï¼å¤æ¨¡æå¤æ¨ç±¤æç·è¾¨è­ (MMER) æ¨å¨è­å¥å¤æ¨¡æè³æä¸­å¤ç¨®æç·çåæå­å¨ãç¾æç ç©¶ä¸»è¦éä¸­æ¼æ¹é²èåç­ç¥åå»ºæ¨¡æ¨¡æå°æ¨ç±¤çä¾è³´æ§ãç¶èï¼ä»åç¶å¸¸å¿½è¦ **é¨æ©ä¸ç¢ºå®æ§** çå½±é¿ï¼éæ¯å¤æ¨¡æè³æä¸­çå§å¨éè¨ï¼ä¸¦ä¸ééå¨ç¹å¾µè¡¨ç¤ºä¸­å¼å¥æ¨¡ç³æ§ä¾é»ç¤æ¨¡æèåçæææ§ãçºäºè§£æ±ºéååé¡ä¸¦ææå°å»ºæ¨¡é¨æ©ä¸ç¢ºå®æ§ï¼æ¬æå¾æ½å¨æç·ç©ºéæ©çå»ºæ¨¡çæ°è§é»æåºå·æä¸ç¢ºå®æ§æç¥çæ½å¨æç·åä½åè§£ (LDDU) æ¶æ§ãå·é«ä¾èªªï¼æåå¨æç·ç©ºéä¸­å¼å¥ä¸åå°æ¯æ§çç³¾çºåä½æ©å¶ä¾å»ºæ¨¡å¤æ¨¡æè³æï¼åè¨±æåèªæç¹å¾µåä¸ç¢ºå®æ§ãæ­¤å¤ï¼æåè¨­è¨äºä¸åèéä¸ç¢ºå®æ§åæ£åä½ä¸¦æ´ååä½è³è¨çä¸ç¢ºå®æ§æç¥èåå¤æ¨¡ææ¹æ³ãå¯¦é©çµæé¡¯ç¤ºï¼LDDU å¨ CMU-MOSEI å M$^3$ED è³æéä¸éå°æåé²çæè½ï¼çªé¡¯äºä¸ç¢ºå®æ§å»ºæ¨¡å¨ MMER ä¸­çéè¦æ§ãç¨å¼ç¢¼å¯å¨ https://github.com/201983290498/lddu\_mmer.git åå¾ã

##### **Neurosymbolic artificial intelligence via large language models and coherence-driven inference**
2502.13953v1 by Steve Huntsman, Jewell Thomas

We devise an algorithm to generate sets of propositions that objectively
instantiate graphs that support coherence-driven inference. We then benchmark
the ability of large language models (LLMs) to reconstruct coherence graphs
from (a straightforward transformation of) propositions expressed in natural
language, with promising results from a single prompt to models optimized for
reasoning. Combining coherence-driven inference with consistency evaluations by
neural models may advance the state of the art in machine cognition.

æè¦ï¼æåè¨­è¨ä¸ç¨®æ¼ç®æ³ï¼ç¨ä¾ç¢çå½é¡éåï¼ä»¥å®¢è§å°å¯¦ä¾åæ¯æ´é£è²«æ§é©åæ¨è«çåå½¢ãæ¥èï¼æååºæºåå¤§åèªè¨æ¨¡å (LLM) å¾ä»¥èªç¶èªè¨è¡¨éçå½é¡ï¼ç¶éç´æ¥è½æï¼éå»ºé£è²«æ§åå½¢çè½åï¼çµæé¡¯ç¤ºï¼å®ä¸æç¤ºå°±è½å¾æä½³åç¨æ¼æ¨ççæ¨¡åä¸­ç²å¾æå¸æççµæãå°é£è²«æ§é©åæ¨è«èç¥ç¶æ¨¡åçä¸è´æ§è©ä¼°çµåèµ·ä¾ï¼å¯è½ææåæ©å¨èªç¥çç¾ææè¡ã

##### **Why Safeguarded Ships Run Aground? Aligned Large Language Models' Safety Mechanisms Tend to Be Anchored in The Template Region**
2502.13946v1 by Chak Tou Leong, Qingyu Yin, Jian Wang, Wenjie Li

The safety alignment of large language models (LLMs) remains vulnerable, as
their initial behavior can be easily jailbroken by even relatively simple
attacks. Since infilling a fixed template between the input instruction and
initial model output is a common practice for existing LLMs, we hypothesize
that this template is a key factor behind their vulnerabilities: LLMs'
safety-related decision-making overly relies on the aggregated information from
the template region, which largely influences these models' safety behavior. We
refer to this issue as template-anchored safety alignment. In this paper, we
conduct extensive experiments and verify that template-anchored safety
alignment is widespread across various aligned LLMs. Our mechanistic analyses
demonstrate how it leads to models' susceptibility when encountering
inference-time jailbreak attacks. Furthermore, we show that detaching safety
mechanisms from the template region is promising in mitigating vulnerabilities
to jailbreak attacks. We encourage future research to develop more robust
safety alignment techniques that reduce reliance on the template region.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çå®å¨æ§å°é½ä»ç¶èå¼±ï¼å çºå³ä½¿ç¸å°ç°¡å®çæ»æä¹å¯è½è¼æç ´è§£å¶åå§è¡çºãç±æ¼å¨è¼¸å¥æä»¤ååå§æ¨¡åè¼¸åºä¹éå¡«å¥ä¸ååºå®çç¯æ¬æ¯ç¾æ LLM çå¸¸è¦åæ³ï¼æååè¨­éåç¯æ¬æ¯å¶æ¼æ´èå¾çä¸åééµå ç´ ï¼LLM èå®å¨æ§ç¸éçæ±ºç­å¶å®éåº¦ä¾è³´æ¼ç¯æ¬ååçå½ç¸½è³è¨ï¼éå¨å¾å¤§ç¨åº¦ä¸å½±é¿äºéäºæ¨¡åçå®å¨æ§è¡çºãæåå°æ­¤åé¡ç¨±çºç¯æ¬é¨å®çå®å¨æ§å°é½ãå¨æ¬æä¸­ï¼æåé²è¡äºå»£æ³çå¯¦é©ï¼ä¸¦é©è­äºç¯æ¬é¨å®çå®å¨æ§å°é½å¨åç¨®å°é½ç LLM ä¸­å»£æ³å­å¨ãæåçæ©å¶åæèªªæäºç¶éå°æ¨çæéè¶çæ»ææï¼å®æ¯å¦ä½å°è´æ¨¡åæåæ»æçãæ­¤å¤ï¼æåè¡¨æå°å®å¨æ§æ©å¶å¾ç¯æ¬åååé¢åºä¾æææ¸è¼è¶çæ»æçæ¼æ´ãæåé¼åµæªä¾çç ç©¶éç¼æ´å¼·å¤§çå®å¨æ§å°é½æè¡ï¼ä»¥æ¸å°å°ç¯æ¬ååçä¾è³´ã

##### **AdaptiveStep: Automatically Dividing Reasoning Step through Model Confidence**
2502.13943v1 by Yuliang Liu, Junjie Lu, Zhaoling Chen, Chaofeng Qu, Jason Klein Liu, Chonghan Liu, Zefan Cai, Yunhui Xia, Li Zhao, Jiang Bian, Chuheng Zhang, Wei Shen, Zhouhan Lin

Current approaches for training Process Reward Models (PRMs) often involve
breaking down responses into multiple reasoning steps using rule-based
techniques, such as using predefined placeholder tokens or setting the
reasoning step's length into a fixed size. These approaches overlook the fact
that specific words do not typically mark true decision points in a text. To
address this, we propose AdaptiveStep, a method that divides reasoning steps
based on the model's confidence in predicting the next word. This division
method provides more decision-making information at each step, enhancing
downstream tasks, such as reward model learning. Moreover, our method does not
require manual annotation. We demonstrate its effectiveness through experiments
with AdaptiveStep-trained PRMs in mathematical reasoning and code generation
tasks. Experimental results indicate that the outcome PRM achieves
state-of-the-art Best-of-N performance, surpassing greedy search strategy with
token-level value-guided decoding, while also reducing construction costs by
over 30% compared to existing open-source PRMs. In addition, we provide a
thorough analysis and case study on the PRM's performance, transferability, and
generalization capabilities.

æè¦ï¼ç®åçè¨ç·´æµç¨çåµæ¨¡å (PRM) æ¹æ³éå¸¸æ¶å
ä½¿ç¨åºæ¼è¦åçæè¡å°åæåè§£çºå¤åæ¨çæ­¥é©ï¼ä¾å¦ä½¿ç¨é å®ç¾©çä½ä½ç¬¦ä»£å¹£æå°
æ¨çæ­¥é©çé·åº¦è¨­å®çºåºå®å¤§å°ãéäºæ¹æ³å¿½è¦äºå·é«çå­è©éå¸¸ä¸ææ¨è¨ææ¬ä¸­ççå¯¦æ±ºç­é»ãçºäº
è§£æ±ºæ­¤åé¡ï¼æåæåºäº AdaptiveStepï¼éæ¯ä¸ç¨®åºæ¼æ¨¡åé æ¸¬ä¸ä¸åå­è©çä¿¡å¿ä¾ååæ¨çæ­¥é©çæ¹æ³ãæ­¤åå
æ¹æ³å¨æ¯åæ­¥é©ä¸­æä¾äºæ´å¤æ±ºç­è³è¨ï¼å¢å¼·äºä¸æ¸¸ä»»åï¼ä¾å¦çåµæ¨¡åå­¸ç¿ãæ­¤å¤ï¼æåçæ¨¡åä¸éè¦
æåè¨»è§£ãæåééä½¿ç¨ AdaptiveStep è¨ç·´ç PRM å¨æ¸å­¸æ¨çåç¨å¼ç¢¼çæä»»åä¸­é²è¡å¯¦é©ä¾è­æå¶æææ§ãå¯¦é©çµæè¡¨æï¼ææ PRM éå°äºæåé²ç N é¸ä¸æä½³æè½ï¼è¶è¶äºä½¿ç¨ä»£å¹£å±¤ç´å¼å¼å°è§£ç¢¼çè²ªå©ªæå°ç­ç¥ï¼åæèç¾æçéæº PRM ç¸æ¯ï¼å»ºæ§ææ¬ä¹éä½äº 30% ä»¥ä¸ãæ­¤å¤ï¼æåæä¾äºå° PRM æè½ãå¯ç§»æ¤æ§åæ³åè½åçæ·±å¥åæååæ¡ç ç©¶ã

##### **Continually Learning Structured Visual Representations via Network Refinement with Rerelation**
2502.13935v1 by Zeki Doruk Erden, Boi Faltings

Current machine learning paradigm relies on continuous representations like
neural networks, which iteratively adjust parameters to approximate outcomes
rather than directly learning the structure of problem. This spreads
information across the network, causing issues like information loss and
incomprehensibility Building on prior work in environment dynamics modeling, we
propose a method that learns visual space in a structured, continual manner.
Our approach refines networks to capture the core structure of objects while
representing significant subvariants in structure efficiently. We demonstrate
this with 2D shape detection, showing incremental learning on MNIST without
overwriting knowledge and creating compact, comprehensible representations.
These results offer a promising step toward a transparent, continually learning
alternative to traditional neural networks for visual processing.

æè¦ï¼ç¶åæ©å¨å­¸ç¿ç¯ä¾ä¾è³´æ¼é£çºè¡¨ç¤ºï¼ä¾å¦ç¥ç¶ç¶²è·¯ï¼å®æåè¦èª¿æ´åæ¸ä»¥è¿ä¼¼çµæï¼èä¸æ¯ç´æ¥å­¸ç¿åé¡ççµæ§ãéæå°è³è¨æ£å¸å°æ´åç¶²è·¯ä¸­ï¼å°è´è³è¨éºå¤±åé£ä»¥çè§£ç­åé¡ãæåå»ºç«å¨ç°å¢åæå»ºæ¨¡çååå·¥ä½ä¸ï¼æåºäºä¸ç¨®ä»¥çµæ§åãé£çºçæ¹å¼å­¸ç¿è¦è¦ºç©ºéçæ¹æ³ãæåçåæ³ææ¹åç¶²è·¯ï¼ä»¥æ·åç©ä»¶çæ ¸å¿çµæ§ï¼åæææå°è¡¨ç¤ºçµæ§ä¸­çéå¤§æ¬¡è®ç°ãæåéé 2D å½¢çåµæ¸¬ä¾å±ç¤ºéä¸é»ï¼é¡¯ç¤ºå¨ MNIST ä¸çå¢éå­¸ç¿ï¼èä¸æè¦å¯«ç¥è­ï¼ä¸¦å»ºç«ç²¾ç°¡ãææ¼çè§£çè¡¨ç¤ºãéäºçµæçºè¦è¦ºèççå³çµ±ç¥ç¶ç¶²è·¯æä¾äºä¸åæå¸æçæ­¥é©ï¼æåéæãæçºå­¸ç¿çæ¿ä»£æ¹æ¡ã

##### **Symmetrical Visual Contrastive Optimization: Aligning Vision-Language Models with Minimal Contrastive Images**
2502.13928v1 by Shengguang Wu, Fan-Yun Sun, Kaiyue Wen, Nick Haber

Recent studies have shown that Large Vision-Language Models (VLMs) tend to
neglect image content and over-rely on language-model priors, resulting in
errors in visually grounded tasks and hallucinations. We hypothesize that this
issue arises because existing VLMs are not explicitly trained to generate texts
that are accurately grounded in fine-grained image details. To enhance visual
feedback during VLM training, we propose S-VCO (Symmetrical Visual Contrastive
Optimization), a novel finetuning objective that steers the model toward
capturing important visual details and aligning them with corresponding text
tokens. To further facilitate this detailed alignment, we introduce MVC, a
paired image-text dataset built by automatically filtering and augmenting
visual counterfactual data to challenge the model with hard contrastive cases
involving Minimal Visual Contrasts. Experiments show that our method
consistently improves VLM performance across diverse benchmarks covering
various abilities and domains, achieving up to a 22% reduction in
hallucinations, and significant gains in vision-centric and general tasks.
Notably, these improvements become increasingly pronounced in benchmarks with
higher visual dependency. In short, S-VCO offers a significant enhancement of
VLM's visually-dependent task performance while retaining or even improving the
model's general abilities. We opensource our code at https://s-vco.github.io/

æè¦ï¼<paragraph>æè¿çç ç©¶è¡¨æï¼å¤§åè§è§è¯­è¨æ¨¡å (VLM) å¾åäºå¿½ç¥å¾ååå®¹ï¼è¿åº¦ä¾èµè¯­è¨æ¨¡ååéªï¼å¯¼è´è§è§åºç¡ä»»å¡ä¸­çéè¯¯åå¹»è§ãæä»¬åè®¾è¿ä¸ªé®é¢åºç°æ¯å ä¸ºç°æç VLM å¹¶æªæç¡®è®­ç»æ¥çæç²¾ç¡®å»ºç«å¨ç²¾ç»å¾åç»èä¸çææ¬ãä¸ºäºå¨ VLM è®­ç»æé´å¢å¼ºè§è§åé¦ï¼æä»¬æåºäº S-VCOï¼å¯¹ç§°è§è§å¯¹æ¯ä¼åï¼ï¼è¿æ¯ä¸ç§æ°é¢çå¾®è°ç®æ ï¼å¼å¯¼æ¨¡åææéè¦çè§è§ç»èï¼å¹¶å°å¶ä¸ç¸åºçææ¬æ è®°å¯¹é½ãä¸ºäºè¿ä¸æ­¥ä¿è¿è¿ç§è¯¦ç»å¯¹é½ï¼æä»¬å¼å¥äº MVCï¼è¿æ¯ä¸ç§æå¯¹çå¾åææ¬æ°æ®éï¼éè¿èªå¨è¿æ»¤åæ©åè§è§åäºå®æ°æ®æå»ºèæï¼ä»¥ä½¿ç¨æ¶åæå°è§è§å¯¹æ¯çå°é¾å¯¹æ¯æ¡ä¾æ¥æææ¨¡åãå®éªè¡¨æï¼æä»¬çæ¹æ³å¨æ¶µçåç§è½ååé¢åçåºåæµè¯ä¸­æç»­æåäº VLM æ§è½ï¼å¹»è§åå°äº 22%ï¼å¹¶ä¸å¨ä»¥è§è§ä¸ºä¸­å¿çéç¨ä»»å¡ä¸­è·å¾äºæ¾èæåãå¼å¾æ³¨æçæ¯ï¼è¿äºæ¹è¿å¨è§è§ä¾èµæ§è¾é«çåºåæµè¯ä¸­åå¾è¶æ¥è¶ææ¾ãç®èè¨ä¹ï¼S-VCO æ¾çæåäº VLM çè§è§ä¾èµåä»»å¡æ§è½ï¼åæ¶ä¿ççè³æåäºæ¨¡åçéç¨è½åãæä»¬å¨ https://s-vco.github.io/ ä¸å¼æºäºæä»¬çä»£ç ã</paragraph>

##### **Beyond Single Frames: Can LMMs Comprehend Temporal and Contextual Narratives in Image Sequences?**
2502.13925v1 by Xiaochen Wang, Heming Xia, Jialin Song, Longyu Guan, Yixin Yang, Qingxiu Dong, Weiyao Luo, Yifan Pu, Yiru Wang, Xiangdi Meng, Wenjie Li, Zhifang Sui

Large Multimodal Models (LMMs) have achieved remarkable success across
various visual-language tasks. However, existing benchmarks predominantly focus
on single-image understanding, leaving the analysis of image sequences largely
unexplored. To address this limitation, we introduce StripCipher, a
comprehensive benchmark designed to evaluate capabilities of LMMs to comprehend
and reason over sequential images. StripCipher comprises a human-annotated
dataset and three challenging subtasks: visual narrative comprehension,
contextual frame prediction, and temporal narrative reordering. Our evaluation
of $16$ state-of-the-art LMMs, including GPT-4o and Qwen2.5VL, reveals a
significant performance gap compared to human capabilities, particularly in
tasks that require reordering shuffled sequential images. For instance, GPT-4o
achieves only 23.93% accuracy in the reordering subtask, which is 56.07% lower
than human performance. Further quantitative analysis discuss several factors,
such as input format of images, affecting the performance of LLMs in sequential
understanding, underscoring the fundamental challenges that remain in the
development of LMMs.

æè¦ï¼å¤§åå¤æ¨¡ææ¨¡å (LMM) å·²å¨åç¨®è¦è¦ºèªè¨ä»»åä¸­åå¾é¡¯èæåãç¶èï¼ç¾æçåºæºä¸»è¦éä¸­å¨å®ä¸å½±åçè§£ä¸ï¼å¨å¾å¤§ç¨åº¦ä¸æªæ¢ç´¢å½±ååºåçåæãçºäºè§£æ±ºéåéå¶ï¼æåå¼å¥äº StripCipherï¼ä¸åå¨é¢çåºæºï¼æ¨å¨è©ä¼° LMM çè§£åæ¨çé åºå½±åçè½åãStripCipher åå«ä¸åäººå·¥æ¨è¨»çè³æéåä¸åå·æææ°æ§çå­ä»»åï¼è¦è¦ºæäºçè§£ãæå¢æ¡æ¶é æ¸¬åæéæäºéæ°æåºãæåå° 16 åæåé²ç LMMï¼åæ¬ GPT-4o å Qwen2.5VLï¼çè©ä¼°é¡¯ç¤ºï¼èäººé¡çè½åç¸æ¯ï¼å­å¨é¡¯èçæè½å·®è·ï¼ç¹å¥æ¯å¨éè¦éæ°æåºå·²æ´ççé åºå½±åçä»»åä¸­ãä¾å¦ï¼GPT-4o å¨éæ°æåºå­ä»»åä¸­åéå° 23.93% çæºç¢ºåº¦ï¼æ¯äººé¡æè½ä½ 56.07%ãé²ä¸æ­¥çéååæè¨è«äºå¹¾åå ç´ ï¼ä¾å¦å½±åçè¼¸å¥æ ¼å¼ï¼å½±é¿ LLM å¨é åºçè§£ä¸­çæè½ï¼å¼·èª¿äº LMM ç¼å±ä¸­ä»ç¶å­å¨çåºæ¬ææ°ã

##### **Qwen2.5-VL Technical Report**
2502.13923v1 by Shuai Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, Sibo Song, Kai Dang, Peng Wang, Shijie Wang, Jun Tang, Humen Zhong, Yuanzhi Zhu, Mingkun Yang, Zhaohai Li, Jianqiang Wan, Pengfei Wang, Wei Ding, Zheren Fu, Yiheng Xu, Jiabo Ye, Xi Zhang, Tianbao Xie, Zesen Cheng, Hang Zhang, Zhibo Yang, Haiyang Xu, Junyang Lin

We introduce Qwen2.5-VL, the latest flagship model of Qwen vision-language
series, which demonstrates significant advancements in both foundational
capabilities and innovative functionalities. Qwen2.5-VL achieves a major leap
forward in understanding and interacting with the world through enhanced visual
recognition, precise object localization, robust document parsing, and
long-video comprehension. A standout feature of Qwen2.5-VL is its ability to
localize objects using bounding boxes or points accurately. It provides robust
structured data extraction from invoices, forms, and tables, as well as
detailed analysis of charts, diagrams, and layouts. To handle complex inputs,
Qwen2.5-VL introduces dynamic resolution processing and absolute time encoding,
enabling it to process images of varying sizes and videos of extended durations
(up to hours) with second-level event localization. This allows the model to
natively perceive spatial scales and temporal dynamics without relying on
traditional normalization techniques. By training a native dynamic-resolution
Vision Transformer (ViT) from scratch and incorporating Window Attention, we
reduce computational overhead while maintaining native resolution. As a result,
Qwen2.5-VL excels not only in static image and document understanding but also
as an interactive visual agent capable of reasoning, tool usage, and task
execution in real-world scenarios such as operating computers and mobile
devices. Qwen2.5-VL is available in three sizes, addressing diverse use cases
from edge AI to high-performance computing. The flagship Qwen2.5-VL-72B model
matches state-of-the-art models like GPT-4o and Claude 3.5 Sonnet, particularly
excelling in document and diagram understanding. Additionally, Qwen2.5-VL
maintains robust linguistic performance, preserving the core language
competencies of the Qwen2.5 LLM.

æè¦ï¼<paragraph>æåæ¨åº Qwen2.5-VLï¼éæ¯ Qwen è¦è¦ºèªè¨ç³»åçææ°æè¦æ©åï¼å®å¨åºç¤è½åååµæ°åè½æ¹é¢é½å±ç¾åºé¡¯èçé²æ­¥ãQwen2.5-VL å¨çè§£åèä¸çäºåæ¹é¢åå¾éå¤§é²å±ï¼ééå¢å¼·çè¦è¦ºè¾¨è­ãç²¾ç¢ºçç©ä»¶å®ä½ãç©©å¥çæä»¶è§£æåé·å½±ççè§£ä¾å¯¦ç¾ãQwen2.5-VL çä¸åé¡¯èç¹é»æ¯å®è½å¤ ä½¿ç¨éçæ¡æé»æºç¢ºå®ä½ç©ä»¶ãå®æä¾å¾ç¼ç¥¨ãè¡¨æ ¼åè¡¨æ ¼ä¸­æåç©©å¥ççµæ§åè³æï¼ä»¥åå°åè¡¨ãåè§£åçé¢çè©³ç´°åæãçºäºèçè¤éçè¼¸å¥ï¼Qwen2.5-VL å¼å¥äºåæè§£æèçåçµå°æéç·¨ç¢¼ï¼ä½¿å¶è½å¤ èçä¸åå¤§å°çå½±ååé·æå½±çï¼é·éæ¸å°æï¼ï¼ä¸¦å·æç§ç´äºä»¶å®ä½ãéåè¨±æ¨¡åå¨ä¸ä¾è³´å³çµ±æ­£è¦åæè¡çææ³ä¸ï¼åçæç¥ç©ºéå°ºåº¦åæéåæãééå¾é ­è¨ç·´åçåæè§£æè¦è¦ºè½æå¨ (ViT) ä¸¦æ´åè¦çªæ³¨æåï¼æåå¨ç¶­æåçè§£æåº¦çåææ¸å°äºéç®éé·ãå æ­¤ï¼Qwen2.5-VL ä¸åå¨éæå½±ååæä»¶çè§£æ¹é¢è¡¨ç¾åºè²ï¼éè½å¤ ä½çºä¸åäºåå¼è¦è¦ºä»£çï¼å¨æä½é»è¦åè¡åè£ç½®ç­çå¯¦ä¸çå ´æ¯ä¸­é²è¡æ¨çãå·¥å·ä½¿ç¨åä»»åå·è¡ãQwen2.5-VL æä¸ç¨®å°ºå¯¸ï¼å¯æ»¿è¶³å¾éç·£ AI å°é«æ§è½éç®çåç¨®ä½¿ç¨æ¡ä¾ãæè¦ Qwen2.5-VL-72B æ©åè GPT-4o å Claude 3.5 Sonnet ç­æåé²çæ©åç¸å¹éï¼ç¹å¥æ¯å¨æä»¶ååè§£çè§£æ¹é¢è¡¨ç¾åºè²ãæ­¤å¤ï¼Qwen2.5-VL ç¶­æç©©å¥çèªè¨æè½ï¼ä¿çäº Qwen2.5 LLM çæ ¸å¿èªè¨è½åã</paragraph>

##### **LongPO: Long Context Self-Evolution of Large Language Models through Short-to-Long Preference Optimization**
2502.13922v1 by Guanzheng Chen, Xin Li, Michael Qizhe Shieh, Lidong Bing

Large Language Models (LLMs) have demonstrated remarkable capabilities
through pretraining and alignment. However, superior short-context LLMs may
underperform in long-context scenarios due to insufficient long-context
alignment. This alignment process remains challenging due to the impracticality
of human annotation for extended contexts and the difficulty in balancing
short- and long-context performance. To address these challenges, we introduce
LongPO, that enables short-context LLMs to self-evolve to excel on long-context
tasks by internally transferring short-context capabilities. LongPO harnesses
LLMs to learn from self-generated short-to-long preference data, comprising
paired responses generated for identical instructions with long-context inputs
and their compressed short-context counterparts, respectively. This preference
reveals capabilities and potentials of LLMs cultivated during short-context
alignment that may be diminished in under-aligned long-context scenarios.
Additionally, LongPO incorporates a short-to-long KL constraint to mitigate
short-context performance decline during long-context alignment. When applied
to Mistral-7B-Instruct-v0.2 from 128K to 512K context lengths, LongPO fully
retains short-context performance and largely outperforms naive SFT and DPO in
both long- and short-context tasks. Specifically, \ourMethod-trained models can
achieve results on long-context benchmarks comparable to, or even surpassing,
those of superior LLMs (e.g., GPT-4-128K) that involve extensive long-context
annotation and larger parameter scales.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²ééé è¨ç·´åæ¯å°å±ç¾åºéå¡çè½åãç¶èï¼åè¶çç­èçµ¡ LLM å¯è½æå¨é·èçµ¡å ´æ¯ä¸­è¡¨ç¾ä¸ä½³ï¼å çºé·èçµ¡æ¯å°ä¸è¶³ãæ­¤æ¯å°ç¨åºä»ç¶å·æææ°æ§ï¼åå æ¯éå°å»¶ä¼¸èçµ¡é²è¡äººå·¥è¨»è§£ä¸åå¯¦éï¼ä¸é£ä»¥å¹³è¡¡ç­èçµ¡åé·èçµ¡çæè½ãçºäºæå°éäºææ°ï¼æåå¼å¥äº LongPOï¼å®è½è®ç­èçµ¡ LLM èªææ¼åï¼ééå§é¨è½ç§»ç­èçµ¡è½åï¼å¨é·èçµ¡ä»»åä¸­è¡¨ç¾åºè²ãLongPO å©ç¨ LLM å¾èªæç¢ççç­å°é·åå¥½è³æä¸­å­¸ç¿ï¼åå«çºå·æé·èçµ¡è¼¸å¥çç¸åæä»¤ç¢ççéå°åæï¼ä»¥åå®åå£ç¸®çç­èçµ¡å°æé ãæ­¤åå¥½æ­ç¤ºäº LLM å¨ç­èçµ¡æ¯å°æéå¹é¤çè½ååæ½åï¼éäºè½ååæ½åå¯è½æå¨æ¯å°ä¸è¶³çé·èçµ¡å ´æ¯ä¸­æ¸å¼±ãæ­¤å¤ï¼LongPO çµåäºç­å°é·ç KL ç´æï¼ä»¥æ¸è¼é·èçµ¡æ¯å°æéçç­èçµ¡æè½ä¸éãç¶æç¨æ¼ Mistral-7B-Instruct-v0.2ï¼å¾ 128K å° 512K çèçµ¡é·åº¦æï¼LongPO å®å¨ä¿çäºç­èçµ¡æè½ï¼ä¸¦ä¸å¨é·èçµ¡åç­èçµ¡ä»»åä¸­é½å¤§å¹åªæ¼æ¨¸ç´ ç SFT å DPOãå·é«ä¾èªªï¼ç¶éæåæ¹æ³è¨ç·´çæ¨¡åå¯ä»¥å¨é·èçµ¡åºæºä¸åå¾èåè¶ LLMï¼ä¾å¦ï¼GPT-4-128Kï¼ç¸ç¶çè³è¶è¶ççµæï¼èåè¶ LLM æ¶åå»£æ³çé·èçµ¡è¨»è§£åæ´å¤§çåæ¸è¦æ¨¡ã

##### **Exploring Personalized Health Support through Data-Driven, Theory-Guided LLMs: A Case Study in Sleep Health**
2502.13920v1 by Xingbo Wang, Janessa Griffith, Daniel A. Adler, Joey Castillo, Tanzeem Choudhury, Fei Wang

Despite the prevalence of sleep-tracking devices, many individuals struggle
to translate data into actionable improvements in sleep health. Current methods
often provide data-driven suggestions but may not be feasible and adaptive to
real-life constraints and individual contexts. We present HealthGuru, a novel
large language model-powered chatbot to enhance sleep health through
data-driven, theory-guided, and adaptive recommendations with conversational
behavior change support. HealthGuru's multi-agent framework integrates wearable
device data, contextual information, and a contextual multi-armed bandit model
to suggest tailored sleep-enhancing activities. The system facilitates natural
conversations while incorporating data-driven insights and theoretical behavior
change techniques. Our eight-week in-the-wild deployment study with 16
participants compared HealthGuru to a baseline chatbot. Results show improved
metrics like sleep duration and activity scores, higher quality responses, and
increased user motivation for behavior change with HealthGuru. We also identify
challenges and design considerations for personalization and user engagement in
health chatbots.

æè¦ï¼åç®¡æè¨±å¤ç¡ç è¿½è¹¤è£ç½®çè¡ï¼ä½è¨±å¤äººä»é£ä»¥å°è³æè½åçºæ¹åç¡ç å¥åº·çå¯¦éè¡åãç®åçè¨±å¤æ¹æ³æä¾ä»¥è³æçºåºç¤çå»ºè­°ï¼ä½å¯è½ç¡æ³å¨ç¾å¯¦çæ´»çéå¶èåäººèæ¯ä¸­ç¼æ®ä½ç¨ä¸ç¡æ³é©æãæåæåº HealthGuruï¼éæ¯ä¸åç±å¤§åèªè¨æ¨¡åé©åçæ°åèå¤©æ©å¨äººï¼ééä»¥è³æçºåºç¤ãçè«çºå°åä¸å·é©ææ§çå»ºè­°ï¼æ­éå°è©±å¼è¡çºæ¹è®æ¯æ´ï¼ä¾æ¹åç¡ç å¥åº·ãHealthGuru çå¤éä»£çæ¶æ§æ´åäºç©¿æ´å¼è£ç½®è³æãæå¢è³è¨ï¼ä»¥åæå¢å¼å¤éé¸ææ§è³­åæ©æ¨¡åï¼ä»¥å»ºè­°éèº«æé çå©ç æ´»åãæ­¤ç³»çµ±ä¿é²èªç¶å°è©±ï¼åæç´å¥ä»¥è³æçºåºç¤çè¦è§£åçè«è¡çºæ¹è®æå·§ãæåé²è¡çºæå«é±çéå¤é¨ç½²ç ç©¶ï¼æ 16 ä½åèèæ¯è¼äº HealthGuru åä¸ååºæºèå¤©æ©å¨äººãçµæé¡¯ç¤º HealthGuru æ¹åäºç¡ç ææ¸åæ´»ååæ¸ç­ææ¨ï¼ä¸¦ç²å¾è¼é«åè³ªçåæï¼ä»¥åå¢å ä½¿ç¨èæ¹è®è¡çºçåæ©ãæåä¹æ¾åºåäººååä½¿ç¨èåèå¨å¥åº·èå¤©æ©å¨äººä¸­çææ°åè¨­è¨èéã

##### **TESS 2: A Large-Scale Generalist Diffusion Language Model**
2502.13917v1 by Jaesung Tae, Hamish Ivison, Sachin Kumar, Arman Cohan

We introduce TESS 2, a general instruction-following diffusion language model
that outperforms contemporary instruction-tuned diffusion models, as well as
matches and sometimes exceeds strong autoregressive (AR) models. We train TESS
2 by first adapting a strong AR model via continued pretraining with the usual
cross-entropy as diffusion loss, and then performing further instruction
tuning. We find that adaptation training as well as the choice of the base
model is crucial for training good instruction-following diffusion models. We
further propose reward guidance, a novel and modular inference-time guidance
procedure to align model outputs without needing to train the underlying model.
Finally, we show that TESS 2 further improves with increased inference-time
compute, highlighting the utility of diffusion LMs in having fine-grained
controllability over the amount of compute used at inference time. Code and
models are available at https://github.com/hamishivi/tess-2.

æè¦ï¼æåå¼å¥äº TESS 2ï¼ä¸åä¸è¬æä»¤è¿½è¹¤æ´æ£èªè¨æ¨¡åï¼å®åªæ¼ç¶ä»£æä»¤èª¿æ´æ´æ£æ¨¡åï¼ä»¥åå¹éåææè¶éå¼·å¤§çèªè¿´æ­¸ (AR) æ¨¡åãæåééæçºé è¨ç·´ï¼ä½¿ç¨ä¸è¬äº¤åçµä½çºæ´æ£æå¤±ï¼ä¾é©æå¼·å¤§ç AR æ¨¡åï¼ç¶å¾å·è¡é²ä¸æ­¥çæä»¤èª¿æ´ï¼ä¾è¨ç·´ TESS 2ãæåç¼ç¾é©æè¨ç·´ä»¥ååºç¤æ¨¡åçé¸æå°æ¼è¨ç·´è¯å¥½çæä»¤è¿½è¹¤æ´æ£æ¨¡åè³ééè¦ãæåé²ä¸æ­¥æåºçåµå¼å°ï¼éæ¯ä¸ç¨®æ°ç©ä¸æ¨¡çµåçæ¨è«æéå¼å°ç¨åºï¼ç¨æ¼å¨ä¸éè¦è¨ç·´åºç¤æ¨¡åçææ³ä¸å°é½æ¨¡åè¼¸åºãæå¾ï¼æåå±ç¤º TESS 2 é¨èæ¨è«æééç®çå¢å èé²ä¸æ­¥æ¹åï¼çªé¡¯äºæ´æ£ LM å¨æ¨è«æéå°ä½¿ç¨éç®éçç²¾ç´°å¯æ§æ§æ¹é¢çæç¨ãç¨å¼ç¢¼åæ¨¡åå¯å¨ https://github.com/hamishivi/tess-2 åå¾ã

##### **How Do LLMs Perform Two-Hop Reasoning in Context?**
2502.13913v1 by Tianyu Guo, Hanlin Zhu, Ruiqi Zhang, Jiantao Jiao, Song Mei, Michael I. Jordan, Stuart Russell

"Socrates is human. All humans are mortal. Therefore, Socrates is mortal."
This classical example demonstrates two-hop reasoning, where a conclusion
logically follows from two connected premises. While transformer-based Large
Language Models (LLMs) can make two-hop reasoning, they tend to collapse to
random guessing when faced with distracting premises. To understand the
underlying mechanism, we train a three-layer transformer on synthetic two-hop
reasoning tasks. The training dynamics show two stages: a slow learning phase,
where the 3-layer transformer performs random guessing like LLMs, followed by
an abrupt phase transitions, where the 3-layer transformer suddenly reaches
$100%$ accuracy. Through reverse engineering, we explain the inner mechanisms
for how models learn to randomly guess between distractions initially, and how
they learn to ignore distractions eventually. We further propose a
three-parameter model that supports the causal claims for the mechanisms to the
training dynamics of the transformer. Finally, experiments on LLMs suggest that
the discovered mechanisms generalize across scales. Our methodologies provide
new perspectives for scientific understandings of LLMs and our findings provide
new insights into how reasoning emerges during training.

æè¦ï¼ãèæ ¼æåºæ¯äººãææäººé¡é½æ¯ææ­»çãå æ­¤ï¼èæ ¼æåºææ­»ãã
éåç¶å¸ç¯ä¾å±ç¤ºäºå©æ­¥æ¨çï¼çµè«éè¼¯å°å¾å©åç¸éçåæä¸­æ¨å°åºä¾ãéç¶åºæ¼è½æå¨çå¤§åèªè¨æ¨¡å (LLM) å¯ä»¥é²è¡å©æ­¥æ¨çï¼ä½å®åå¨é¢å°åæ£æ³¨æåçåææå¾å¾æé·å¥é¨æ©çæ¸¬ãçºäºäºè§£å¶åºå±¤æ©å¶ï¼æåå¨åæå©æ­¥æ¨çä»»åä¸è¨ç·´äºä¸åä¸å±¤è½æå¨ãè¨ç·´åæé¡¯ç¤ºäºå©åéæ®µï¼ä¸åç·©æ¢çå­¸ç¿éæ®µï¼å¶ä¸­ 3 å±¤è½æå¨å LLM ä¸æ¨£é²è¡é¨æ©çæ¸¬ï¼ç¶å¾æ¯ä¸åçªç¶çéæ®µè½æï¼å¶ä¸­ 3 å±¤è½æå¨çªç¶éå° 100% çæºç¢ºåº¦ãéééåå·¥ç¨ï¼æåè§£éäºæ¨¡åæåå¦ä½å¨åå¿ä¸­é¨æ©çæ¸¬çå§é¨æ©å¶ï¼ä»¥åå®åå¦ä½æçµå­¸æå¿½ç¥åå¿çãæåé²ä¸æ­¥æåºäºæ¯æè½æå¨è¨ç·´åææ©å¶çå æä¸»å¼µçä¸åæ¸æ¨¡åãæå¾ï¼éå° LLM çå¯¦é©è¡¨æï¼ç¼ç¾çæ©å¶å¨ä¸åè¦æ¨¡ä¸æ¯éç¨çãæåçæè¡çºç§å­¸çè§£ LLM æä¾äºæ°çè§é»ï¼æåçç¼ç¾çºæ¨çå¦ä½å¨è¨ç·´éç¨ä¸­åºç¾æä¾äºæ°çè¦è§£ã

##### **Lost in Sequence: Do Large Language Models Understand Sequential Recommendation?**
2502.13909v1 by Sein Kim, Hongseok Kang, Kibum Kim, Jiwan Kim, Donghyun Kim, Minchul Yang, Kwangjin Oh, Julian McAuley, Chanyoung Park

Large Language Models (LLMs) have recently emerged as promising tools for
recommendation thanks to their advanced textual understanding ability and
context-awareness. Despite the current practice of training and evaluating
LLM-based recommendation (LLM4Rec) models under a sequential recommendation
scenario, we found that whether these models understand the sequential
information inherent in users' item interaction sequences has been largely
overlooked. In this paper, we first demonstrate through a series of experiments
that existing LLM4Rec models do not fully capture sequential information both
during training and inference. Then, we propose a simple yet effective
LLM-based sequential recommender, called LLM-SRec, a method that enhances the
integration of sequential information into LLMs by distilling the user
representations extracted from a pre-trained CF-SRec model into LLMs. Our
extensive experiments show that LLM-SRec enhances LLMs' ability to understand
users' item interaction sequences, ultimately leading to improved
recommendation performance. Furthermore, unlike existing LLM4Rec models that
require fine-tuning of LLMs, LLM-SRec achieves state-of-the-art performance by
training only a few lightweight MLPs, highlighting its practicality in
real-world applications. Our code is available at
https://github.com/Sein-Kim/LLM-SRec.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æè¿å å¶åé²çææ¬çè§£è½ååæå¢æç¥è½åèæçºæ¨è¦çæ½åå·¥å·ãåç®¡ç®åå¨é åºæ¨è¦æå¢ä¸è¨ç·´åè©ä¼° LLM çºåºç¤çæ¨è¦ (LLM4Rec) æ¨¡åçä½æ³ï¼æåç¼ç¾éäºæ¨¡åæ¯å¦çè§£ä½¿ç¨èé ç®äºåé åºä¸­åºæçé åºè³è¨å¨å¾å¤§ç¨åº¦ä¸è¢«å¿½ç¥äºãå¨æ¬æä¸­ï¼æåé¦åééä¸ç³»åå¯¦é©è­æç¾æç LLM4Rec æ¨¡åå¨è¨ç·´åæ¨è«æéä¸¦æªå®å¨æ·åé åºè³è¨ãç¶å¾ï¼æåæåºä¸åç°¡å®ä½ææç LLM çºåºç¤çé åºæ¨è¦å¨ï¼ç¨±çº LLM-SRecï¼ä¸ç¨®ééå°å¾é åè¨ç·´ç CF-SRec æ¨¡åä¸­èåçä½¿ç¨èè¡¨å¾µèåå° LLM ä¸­ä¾å¢å¼·é åºè³è¨æ´åå° LLM çæ¹æ³ãæåå»£æ³çå¯¦é©é¡¯ç¤º LLM-SRec å¢å¼·äº LLM çè§£ä½¿ç¨èé ç®äºåé åºçè½åï¼æçµå°è´æ¨è¦æè½æåãæ­¤å¤ï¼èéè¦å¾®èª¿ LLM çç¾æ LLM4Rec æ¨¡åä¸åï¼LLM-SRec ééåè¨ç·´å°æ¸è¼éç´ MLP ä¾éææåé²çæè½ï¼çªé¡¯å¶å¨çå¯¦ä¸çæç¨ä¸­çå¯¦ç¨æ§ãæåçç¨å¼ç¢¼å¯æ¼ https://github.com/Sein-Kim/LLM-SRec åå¾ã

##### **Partially Observable Gaussian Process Network and Doubly Stochastic Variational Inference**
2502.13905v1 by Saksham Kiroriwal, Julius Pfrommer, JÃ¼rgen Beyerer

To reduce the curse of dimensionality for Gaussian processes (GP), they can
be decomposed into a Gaussian Process Network (GPN) of coupled subprocesses
with lower dimensionality. In some cases, intermediate observations are
available within the GPN. However, intermediate observations are often
indirect, noisy, and incomplete in most real-world systems. This work
introduces the Partially Observable Gaussian Process Network (POGPN) to model
real-world process networks. We model a joint distribution of latent functions
of subprocesses and make inferences using observations from all subprocesses.
POGPN incorporates observation lenses (observation likelihoods) into the
well-established inference method of deep Gaussian processes. We also introduce
two training methods for POPGN to make inferences on the whole network using
node observations. The application to benchmark problems demonstrates how
incorporating partial observations during training and inference can improve
the predictive performance of the overall network, offering a promising outlook
for its practical application.

æè¦ï¼çºäºéä½é«æ¯ç¨åº (GP) çç¶­åº¦è©åï¼å®åå¯ä»¥åè§£çºå·æè¼ä½ç¶­åº¦çè¦åå­ç¨åºçé«æ¯ç¨åºç¶²è·¯ (GPN)ãå¨æäºææ³ä¸ï¼ä¸­éè§å¯å¯ä»¥å¨ GPN ä¸­ä½¿ç¨ãç¶èï¼å¨å¤æ¸çå¯¦ä¸çç³»çµ±ä¸­ï¼ä¸­éè§å¯éå¸¸æ¯éæ¥ãæéè¨ä¸ä¸å®æ´çãéé å·¥ä½å¼å¥äºé¨åå¯è§å¯é«æ¯ç¨åºç¶²è·¯ (POGPN) ä¾å»ºæ¨¡çå¯¦ä¸çç¨åºç¶²è·¯ãæåå»ºæ¨¡å­ç¨åºçæ½å¨å½æ¸çè¯ååä½ï¼ä¸¦ä½¿ç¨ä¾èªææå­ç¨åºçè§å¯é²è¡æ¨è«ãPOGPN å°è§å¯éé¡ (è§å¯ä¼¼ç¶å½æ¸) æ´åå°å·²å»ºç«è¯å¥½çæ·±åº¦é«æ¯ç¨åºæ¨è«æ¹æ³ä¸­ãæåéå¼å¥äºå©ç¨® POPGN è¨ç·´æ¹æ³ï¼ä»¥ä½¿ç¨ç¯é»è§å¯å°æ´åç¶²è·¯é²è¡æ¨è«ãæç¨æ¼åºæºåé¡å±ç¤ºäºå¨è¨ç·´åæ¨è«æéç´å¥é¨åè§å¯å¦ä½è½æ¹åæ´é«ç¶²è·¯çé æ¸¬æè½ï¼çºå¶å¯¦éæç¨æä¾äºæ¨è§çåæ¯ã

##### **DataSciBench: An LLM Agent Benchmark for Data Science**
2502.13897v1 by Dan Zhang, Sining Zhoubian, Min Cai, Fengzu Li, Lekang Yang, Wei Wang, Tianjiao Dong, Ziniu Hu, Jie Tang, Yisong Yue

This paper presents DataSciBench, a comprehensive benchmark for evaluating
Large Language Model (LLM) capabilities in data science. Recent related
benchmarks have primarily focused on single tasks, easily obtainable ground
truth, and straightforward evaluation metrics, which limits the scope of tasks
that can be evaluated. In contrast, DataSciBench is constructed based on a more
comprehensive and curated collection of natural and challenging prompts for
uncertain ground truth and evaluation metrics. We develop a semi-automated
pipeline for generating ground truth (GT) and validating evaluation metrics.
This pipeline utilizes and implements an LLM-based self-consistency and human
verification strategy to produce accurate GT by leveraging collected prompts,
predefined task types, and aggregate functions (metrics). Furthermore, we
propose an innovative Task - Function - Code (TFC) framework to assess each
code execution outcome based on precisely defined metrics and programmatic
rules. Our experimental framework involves testing 6 API-based models, 8
open-source general models, and 9 open-source code generation models using the
diverse set of prompts we have gathered. This approach aims to provide a more
comprehensive and rigorous evaluation of LLMs in data science, revealing their
strengths and weaknesses. Experimental results demonstrate that API-based
models outperform open-sourced models on all metrics and
Deepseek-Coder-33B-Instruct achieves the highest score among open-sourced
models. We release all code and data at https://github.com/THUDM/DataSciBench.

æè¦ï¼<paragraph>éç¯è«ææåºäº DataSciBenchï¼ä¸åç¨æ¼è©ä¼°å¤§åèªè¨æ¨¡å (LLM) å¨è³æç§å­¸è½åçç¶ååºæºãæè¿ç¸éçåºæºä¸»è¦éä¸­å¨å®ä¸ä»»åãå®¹æåå¾çåºç¤çå¯¦å¼åç´æ¥çè©ä¼°ææ¨ä¸ï¼ééå¶äºå¯è©ä¼°ä»»åçç¯åãç¸æ¯ä¹ä¸ï¼DataSciBench æ¯åºæ¼æ´å¨é¢ä¸ç¶éæ´ççèªç¶ä¸å·æææ°æ§çæç¤ºéåï¼ç¨æ¼ä¸ç¢ºå®çåºç¤çå¯¦å¼åè©ä¼°ææ¨ãæåéç¼äºä¸ååèªååçç®¡éï¼ç¨æ¼ç¢çåºç¤çå¯¦å¼ (GT) åé©è­è©ä¼°ææ¨ãæ­¤ç®¡éå©ç¨ä¸¦å¯¦ä½äºåºæ¼ LLM çèªæä¸è´æ§åäººå·¥é©è­ç­ç¥ï¼ééå©ç¨æ¶éçæç¤ºãé å®ç¾©çä»»åé¡ååèåå½æ¸ï¼ææ¨ï¼ä¾ç¢çæºç¢ºç GTãæ­¤å¤ï¼æåæåºäºä¸ååµæ°çä»»å - å½æ¸ - ç¨å¼ç¢¼ (TFC) æ¶æ§ï¼ç¨æ¼æ ¹æç²¾ç¢ºå®ç¾©çææ¨åç¨å¼è¦åè©ä¼°æ¯åç¨å¼ç¢¼å·è¡çµæãæåçå¯¦é©æ¶æ§æ¶åä½¿ç¨æåæ¶éçå¤æ¨£åæç¤ºï¼æ¸¬è©¦ 6 ååºæ¼ API çæ¨¡åã8 åéæºéç¨æ¨¡åå 9 åéæºç¨å¼ç¢¼çææ¨¡åãæ­¤æ¹æ³æ¨å¨æä¾å°è³æç§å­¸ä¸­ LLM çæ´å¨é¢ä¸å´è¬¹çè©ä¼°ï¼æ­ç¤ºå¶åªé»åç¼ºé»ãå¯¦é©çµæè¡¨æï¼åºæ¼ API çæ¨¡åå¨ææææ¨ä¸é½åªæ¼éæºæ¨¡åï¼è Deepseek-Coder-33B-Instruct å¨éæºæ¨¡åä¸­ç²å¾æé«åãæåå¨ https://github.com/THUDM/DataSciBench éåºææç¨å¼ç¢¼åè³æã</paragraph>

##### **PSCon: Toward Conversational Product Search**
2502.13881v1 by Jie Zou, Mohammad Aliannejadi, Evangelos Kanoulas, Shuxi Han, Heli Ma, Zheng Wang, Yang Yang, Heng Tao Shen

Conversational Product Search (CPS) is confined to simulated conversations
due to the lack of real-world CPS datasets that reflect human-like language.
Additionally, current conversational datasets are limited to support
cross-market and multi-lingual usage. In this paper, we introduce a new CPS
data collection protocol and present PSCon, a novel CPS dataset designed to
assist product search via human-like conversations. The dataset is constructed
using a coached human-to-human data collection protocol and supports two
languages and dual markets. Also, the dataset enables thorough exploration of
six subtasks of CPS: user intent detection, keyword extraction, system action
prediction, question selection, item ranking, and response generation.
Furthermore, we also offer an analysis of the dataset and propose a benchmark
model on the proposed CPS dataset.

æè¦ï¼å°è©±å¼ååæå° (CPS) ç±æ¼ç¼ºä¹åæ äººé¡èªè¨ççå¯¦ä¸ç CPS è³æéï¼å æ­¤åéæ¼æ¨¡æ¬å°è©±ãæ­¤å¤ï¼ç®åçå°è©±å¼è³æéåæ¯æ´è·¨å¸å ´åå¤èªè¨ä½¿ç¨ãå¨æ¬æä¸­ï¼æåä»ç´¹ä¸ç¨®æ°ç CPS è³ææ¶éåå®ï¼ä¸¦æåº PSConï¼éæ¯ä¸åæ°ç©ç CPS è³æéï¼æ¨å¨ééé¡ä¼¼äººé¡çå°è©±åå©ååæå°ãè©²è³æéæ¯ä½¿ç¨è¼å°å¼äººå°äººè³ææ¶éåå®å»ºæ§çï¼ä¸¦æ¯æ´å©ç¨®èªè¨åå©åå¸å ´ãæ­¤å¤ï¼è©²è³æéè½å¾¹åºæ¢ç´¢ CPS çå­åå­ä»»åï¼ä½¿ç¨èæååµæ¸¬ãééµå­èåãç³»çµ±åä½é æ¸¬ãåé¡é¸æãååæåååæç¢çãæ­¤å¤ï¼æåéæä¾å°è³æéçåæï¼ä¸¦å¨å»ºè­°ç CPS è³æéä¸æåºä¸ååºæºæ¨¡åã

##### **MEX: Memory-efficient Approach to Referring Multi-Object Tracking**
2502.13875v1 by Huu-Thien Tran, Phuoc-Sang Pham, Thai-Son Tran, Khoa Luu

Referring Multi-Object Tracking (RMOT) is a relatively new concept that has
rapidly gained traction as a promising research direction at the intersection
of computer vision and natural language processing. Unlike traditional
multi-object tracking, RMOT identifies and tracks objects and incorporates
textual descriptions for object class names, making the approach more
intuitive. Various techniques have been proposed to address this challenging
problem; however, most require the training of the entire network due to their
end-to-end nature. Among these methods, iKUN has emerged as a particularly
promising solution. Therefore, we further explore its pipeline and enhance its
performance. In this paper, we introduce a practical module dubbed
Memory-Efficient Cross-modality -- MEX. This memory-efficient technique can be
directly applied to off-the-shelf trackers like iKUN, resulting in significant
architectural improvements. Our method proves effective during inference on a
single GPU with 4 GB of memory. Among the various benchmarks, the Refer-KITTI
dataset, which offers diverse autonomous driving scenes with relevant language
expressions, is particularly useful for studying this problem. Empirically, our
method demonstrates effectiveness and efficiency regarding HOTA tracking
scores, substantially improving memory allocation and processing speed.

æè¦ï¼å¤ç®æ¨è¿½è¹¤ (RMOT) æ¯ä¸åç¸å°è¼æ°çæ¦å¿µï¼å®å¨é»è¦è¦è¦ºåèªç¶èªè¨èççäº¤åé åä¸­è¿éç²å¾éæ³¨ï¼æçºä¸åæåéçç ç©¶æ¹åãèå³çµ±å¤ç®æ¨è¿½è¹¤ä¸åï¼RMOT è­å¥ä¸¦è¿½è¹¤ç®æ¨ï¼ä¸¦å°ç®æ¨é¡å¥åç¨±çæå­æè¿°ç´å¥å¶ä¸­ï¼ä½¿éç¨®æ¹æ³æ´ç´è§ãå·²ç¶æåºåç¨®æè¡ä¾è§£æ±ºéåå·æææ°æ§çåé¡ï¼ç¶èï¼ç±æ¼å¶ç«¯å°ç«¯ç¹æ§ï¼å¤§å¤æ¸æè¡é½éè¦è¨ç·´æ´åç¶²è·¯ãå¨éäºæ¹æ³ä¸­ï¼iKUN å·²æçºä¸åç¹å¥æåéçè§£æ±ºæ¹æ¡ãå æ­¤ï¼æåé²ä¸æ­¥æ¢ç´¢å¶ç®¡éä¸¦å¢å¼·å¶æè½ãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸åç¨±çº Memory-Efficient Cross-modality -- MEX çå¯¦ç¨æ¨¡çµãéç¨®è¨æ¶é«é«æçæè¡å¯ä»¥ç´æ¥æç¨æ¼ç¾æçè¿½è¹¤å¨ï¼ä¾å¦ iKUNï¼å¾èå¸¶ä¾é¡¯èçæ¶æ§æ¹é²ãæåçæè¡è­æäºå¨å®åå·æ 4 GB è¨æ¶é«ç GPU ä¸é²è¡æ¨ççæææ§ãå¨åç¨®åºæºä¸­ï¼Refer-KITTI è³æéæä¾äºå·æç¸éèªè¨è¡¨éçå¤æ¨£åèªåé§é§å ´æ¯ï¼å°æ¼ç ç©¶éååé¡ç¹å¥æç¨ãæ ¹æç¶é©ï¼æåçæè¡å¨ HOTA è¿½è¹¤åæ¸æ¹é¢è­æäºæææ§åæçï¼é¡¯èæ¹åäºè¨æ¶é«éç½®åèçéåº¦ã

##### **NVR: Vector Runahead on NPUs for Sparse Memory Access**
2502.13873v1 by Hui Wang, Zhengpeng Zhao, Jing Wang, Yushu Du, Yuan Cheng, Bing Guo, He Xiao, Chenhao Ma, Xiaomeng Han, Dean You, Jiapeng Guan, Ran Wei, Dawei Yang, Zhe Jiang

Deep Neural Networks are increasingly leveraging sparsity to reduce the
scaling up of model parameter size. However, reducing wall-clock time through
sparsity and pruning remains challenging due to irregular memory access
patterns, leading to frequent cache misses. In this paper, we present NPU
Vector Runahead (NVR), a prefetching mechanism tailored for NPUs to address
cache miss problems in sparse DNN workloads. Rather than optimising memory
patterns with high overhead and poor portability, NVR adapts runahead execution
to the unique architecture of NPUs. NVR provides a general micro-architectural
solution for sparse DNN workloads without requiring compiler or algorithmic
support, operating as a decoupled, speculative, lightweight hardware sub-thread
alongside the NPU, with minimal hardware overhead (under 5%). NVR achieves an
average 90% reduction in cache misses compared to SOTA prefetching in
general-purpose processors, delivering 4x average speedup on sparse workloads
versus NPUs without prefetching. Moreover, we investigate the advantages of
incorporating a small cache (16KB) into the NPU combined with NVR. Our
evaluation shows that expanding this modest cache delivers 5x higher
performance benefits than increasing the L2 cache size by the same amount.

æè¦ï¼æ·±åº¦ç¥ç»ç½ç»è¶æ¥è¶å¤å°å©ç¨ç¨çæ§æ¥åå°æ¨¡ååæ°å¤§å°çæ©å±ãç¶èï¼ç±äºä¸è§åçåå­è®¿é®æ¨¡å¼ï¼éè¿ç¨çæ§ååªææ¥åå°æ¶éæ¶é´ä»ç¶å·ææææ§ï¼å¯¼è´é¢ç¹çç¼å­æªå½ä¸­ãå¨æ¬æä¸­ï¼æä»¬æåºäº NPU ç¢éè¶å (NVR)ï¼è¿æ¯ä¸ç§éå¯¹ NPU éèº«å®å¶çé¢åæºå¶ï¼ä»¥è§£å³ç¨ç DNN å·¥ä½è´è½½ä¸­çç¼å­æªå½ä¸­é®é¢ãNVR ä¸ä¼éè¿é«å¼éåè¾å·®çå¯ç§»æ¤æ§æ¥ä¼ååå­æ¨¡å¼ï¼èæ¯å°è¶åæ§è¡è°æ´ä¸º NPU çç¬ç¹æ¶æãNVR ä¸ºç¨ç DNN å·¥ä½è´è½½æä¾äºä¸ç§éç¨çå¾®æ¶æè§£å³æ¹æ¡ï¼æ éç¼è¯å¨æç®æ³æ¯æï¼ä½ä¸º NPU æè·¯çä¸ä¸ªè§£è¦çãæ¨æµæ§çãè½»éçº§çç¡¬ä»¶å­çº¿ç¨è¿è¡ï¼ä¸ç¡¬ä»¶å¼éæå°ï¼ä½äº 5%ï¼ãä¸éç¨å¤çå¨ä¸­ç SOTA é¢åç¸æ¯ï¼NVR å°ç¼å­æªå½ä¸­çå¹³åéä½äº 90%ï¼å¨æ²¡æé¢åç NPU ä¸ï¼ç¨çå·¥ä½è´è½½çå¹³åå éæ¯ä¸º 4 åãæ­¤å¤ï¼æä»¬ç ç©¶äºå°ä¸ä¸ªå°ç¼å­ï¼16KBï¼ä¸ NVR ç»åå° NPU ä¸­çä¼å¿ãæä»¬çè¯ä¼°è¡¨æï¼æ©å±æ­¤éåº¦ç¼å­æä¾çæ§è½ä¼å¿æ¯å° L2 ç¼å­å¤§å°å¢å ç¸åéé« 5 åã

##### **SPEX: Scaling Feature Interaction Explanations for LLMs**
2502.13870v1 by Justin Singh Kang, Landon Butler, Abhineet Agarwal, Yigit Efe Erginbas, Ramtin Pedarsani, Kannan Ramchandran, Bin Yu

Large language models (LLMs) have revolutionized machine learning due to
their ability to capture complex interactions between input features. Popular
post-hoc explanation methods like SHAP provide marginal feature attributions,
while their extensions to interaction importances only scale to small input
lengths ($\approx 20$). We propose Spectral Explainer (SPEX), a model-agnostic
interaction attribution algorithm that efficiently scales to large input
lengths ($\approx 1000)$. SPEX exploits underlying natural sparsity among
interactions -- common in real-world data -- and applies a sparse Fourier
transform using a channel decoding algorithm to efficiently identify important
interactions. We perform experiments across three difficult long-context
datasets that require LLMs to utilize interactions between inputs to complete
the task. For large inputs, SPEX outperforms marginal attribution methods by up
to 20% in terms of faithfully reconstructing LLM outputs. Further, SPEX
successfully identifies key features and interactions that strongly influence
model output. For one of our datasets, HotpotQA, SPEX provides interactions
that align with human annotations. Finally, we use our model-agnostic approach
to generate explanations to demonstrate abstract reasoning in closed-source
LLMs (GPT-4o mini) and compositional reasoning in vision-language models.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ç±æ¼è½å¤ ææè¼¸å¥ç¹å¾µä¹éçè¤éäº¤äºä½ç¨ï¼å æ­¤å¾¹åºæ¹è®äºæ©å¨å­¸ç¿ãç±éçå¾è¨­è§£éæ¹æ³ï¼å¦ SHAPï¼æä¾ééç¹å¾µæ­¸å ï¼èå¶äº¤äºéè¦æ§æ´åå¥ä»¶åè½æ´åå¥ä»¶è³è¼å°çè¼¸å¥é·åº¦ï¼â 20ï¼ãæåæåºä¸ç¨®æ¨¡åä¸å¯ç¥äºåæ­¸å æ¼ç®æ³ï¼ç¨±çº Spectral Explainer (SPEX)ï¼å®è½æææ´åå¥ä»¶è³è¼å¤§çè¼¸å¥é·åº¦ï¼â 1000ï¼ãSPEX å©ç¨äº¤äºä½ç¨ä¹éçèªç¶ç¨çæ§ï¼å¨ç¾å¯¦ä¸çè³æä¸­å¾å¸¸è¦ï¼ï¼ä¸¦ä½¿ç¨ééè§£ç¢¼æ¼ç®æ³æç¨ç¨çåç«èè½æï¼ä»¥æææ¾åºéè¦çäº¤äºä½ç¨ãæåå¨ä¸åå°é£çé·èçµ¡è³æéä¸å·è¡å¯¦é©ï¼éäºè³æééè¦ LLM å©ç¨è¼¸å¥ä¹éçäº¤äºä½ç¨æè½å®æä»»åãå°æ¼å¤§åè¼¸å¥ï¼SPEX å¨å¿ å¯¦éå»º LLM è¼¸åºçæ¹é¢ï¼æ¯ééæ­¸å æ¹æ³é«åº 20%ãæ­¤å¤ï¼SPEX æåæ¾åºå¼·çå½±é¿æ¨¡åè¼¸åºçééµç¹å¾µåäº¤äºä½ç¨ãå°æ¼æåçå¶ä¸­ä¸åè³æé HotpotQAï¼SPEX æä¾èäººé¡è¨»è§£ä¸è´çäº¤äºä½ç¨ãæå¾ï¼æåä½¿ç¨æåçæ¨¡åä¸å¯ç¥æ¹æ³ä¾ç¢çè§£éï¼ä»¥å±ç¤ºéæº LLMï¼GPT-4o miniï¼ä¸­çæ½è±¡æ¨çåè¦è¦ºèªè¨æ¨¡åä¸­ççµåæ¨çã

##### **DH-RAG: A Dynamic Historical Context-Powered Retrieval-Augmented Generation Method for Multi-Turn Dialogue**
2502.13847v1 by Feiyuan Zhang, Dezhi Zhu, James Ming, Yilun Jin, Di Chai, Liu Yang, Han Tian, Zhaoxin Fan, Kai Chen

Retrieval-Augmented Generation (RAG) systems have shown substantial benefits
in applications such as question answering and multi-turn dialogue
\citep{lewis2020retrieval}. However, traditional RAG methods, while leveraging
static knowledge bases, often overlook the potential of dynamic historical
information in ongoing conversations. To bridge this gap, we introduce DH-RAG,
a Dynamic Historical Context-Powered Retrieval-Augmented Generation Method for
Multi-Turn Dialogue. DH-RAG is inspired by human cognitive processes that
utilize both long-term memory and immediate historical context in
conversational responses \citep{stafford1987conversational}. DH-RAG is
structured around two principal components: a History-Learning based Query
Reconstruction Module, designed to generate effective queries by synthesizing
current and prior interactions, and a Dynamic History Information Updating
Module, which continually refreshes historical context throughout the dialogue.
The center of DH-RAG is a Dynamic Historical Information database, which is
further refined by three strategies within the Query Reconstruction Module:
Historical Query Clustering, Hierarchical Matching, and Chain of Thought
Tracking. Experimental evaluations show that DH-RAG significantly surpasses
conventional models on several benchmarks, enhancing response relevance,
coherence, and dialogue quality.

æè¦ï¼æª¢ç´¢å¢å¼·çæ (RAG) ç³»çµ±å·²å¨åç­åå¤è¼ªå°è©±ç­æç¨ç¨å¼ä¸­å±ç¾é¡¯èçåªå¢\citep{lewis2020retrieval}ãç¶èï¼å³çµ±ç RAG æ¹æ³éç¶å©ç¨éæç¥è­åº«ï¼å»å¸¸å¸¸å¿½ç¥å°è©±éç¨ä¸­åææ­·å²è³è¨çæ½åãçºäºå½è£éåå·®è·ï¼æåå¼é² DH-RAGï¼ä¸ç¨®åææ­·å²èçµ¡é©åçæª¢ç´¢å¢å¼·çææ¹æ³ï¼ç¨æ¼å¤è¼ªå°è©±ãDH-RAG çéæä¾èªäººé¡èªç¥éç¨ï¼å¨å°è©±åæä¸­åæå©ç¨é·æè¨æ¶åå³ææ­·å²èçµ¡\citep{stafford1987conversational}ãDH-RAG çæ¶æ§åç¹å©åä¸»è¦åä»¶ï¼ä¸ååºæ¼æ­·å²å­¸ç¿çæ¥è©¢éå»ºæ¨¡çµï¼æ¨å¨ééç¶åç¶ååååçäºåä¾ç¢çææçæ¥è©¢ï¼ä»¥åä¸ååææ­·å²è³è¨æ´æ°æ¨¡çµï¼æå¨å°è©±éç¨ä¸­æçºæ´æ°æ­·å²èçµ¡ãDH-RAG çæ ¸å¿æ¯ä¸ååææ­·å²è³è¨è³æåº«ï¼ä¸¦å¨æ¥è©¢éå»ºæ¨¡çµä¸­ééä¸ç¨®ç­ç¥é²ä¸æ­¥å ä»¥ç²¾é²ï¼æ­·å²æ¥è©¢åç¾¤ãéå±¤å¼æ¯å°åæç¶­éè¿½è¹¤ãå¯¦é©è©ä¼°é¡¯ç¤ºï¼DH-RAG å¨å¤ååºæºä¸é¡¯èè¶è¶å³çµ±æ¨¡åï¼æååæç¸éæ§ãä¸è´æ§åå°è©±åè³ªã

##### **Enhancing LLM-Based Recommendations Through Personalized Reasoning**
2502.13845v1 by Jiahao Liu, Xueshuo Yan, Dongsheng Li, Guangping Zhang, Hansu Gu, Peng Zhang, Tun Lu, Li Shang, Ning Gu

Current recommendation systems powered by large language models (LLMs) often
underutilize their reasoning capabilities due to a lack of explicit logical
structuring. To address this limitation, we introduce CoT-Rec, a framework that
integrates Chain-of-Thought (CoT) reasoning into LLM-driven recommendations by
incorporating two crucial processes: user preference analysis and item
perception evaluation. CoT-Rec operates in two key phases: (1) personalized
data extraction, where user preferences and item perceptions are identified,
and (2) personalized data application, where this information is leveraged to
refine recommendations. Our experimental analysis demonstrates that CoT-Rec
improves recommendation accuracy by making better use of LLMs' reasoning
potential. The implementation is publicly available at
https://anonymous.4open.science/r/CoT-Rec.

æè¦ï¼ç®åç±å¤§åèªè¨æ¨¡å (LLM) é©åçæ¨è¦ç³»çµ±éå¸¸ç±æ¼ç¼ºä¹æç¢ºçéè¼¯çµæ§èç¡æ³ååå©ç¨å¶æ¨çè½åãçºäºè§£æ±ºæ­¤éå¶ï¼æåå¼å¥äº CoT-Recï¼ä¸åå°æèé (CoT) æ¨çæ´åå° LLM é©åçæ¨è¦ä¸­çæ¡æ¶ï¼æ¹æ³æ¯ç´å¥å©åééµæµç¨ï¼ä½¿ç¨èåå¥½åæåé ç®æç¥è©ä¼°ãCoT-Rec å¨å©åééµéæ®µä¸­éä½ï¼(1) åäººåæ¸æèåï¼å¶ä¸­è­å¥ä½¿ç¨èåå¥½åé ç®æç¥ï¼ä»¥å (2) åäººåæ¸ææç¨ï¼å¶ä¸­å©ç¨éäºè³è¨ä¾åªåæ¨è¦ãæåçå¯¦é©åæè­æï¼CoT-Rec ééæ´ææå°å©ç¨ LLM çæ¨çæ½åä¾æåæ¨è¦æºç¢ºåº¦ãå¯¦ä½å·²å¬éæ¼ https://anonymous.4open.science/r/CoT-Recã

##### **Enhancing Cross-Domain Recommendations with Memory-Optimized LLM-Based User Agents**
2502.13843v1 by Jiahao Liu, Shengkang Gu, Dongsheng Li, Guangping Zhang, Mingzhe Han, Hansu Gu, Peng Zhang, Tun Lu, Li Shang, Ning Gu

Large Language Model (LLM)-based user agents have emerged as a powerful tool
for improving recommender systems by simulating user interactions. However,
existing methods struggle with cross-domain scenarios due to inefficient memory
structures, leading to irrelevant information retention and failure to account
for social influence factors such as popularity. To address these limitations,
we introduce AgentCF++, a novel framework featuring a dual-layer memory
architecture and a two-step fusion mechanism to filter domain-specific
preferences effectively. Additionally, we propose interest groups with shared
memory, allowing the model to capture the impact of popularity trends on users
with similar interests. Through extensive experiments on multiple cross-domain
datasets, AgentCF++ demonstrates superior performance over baseline models,
highlighting its effectiveness in refining user behavior simulation for
recommender systems. Our code is available at
https://anonymous.4open.science/r/AgentCF-plus.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çä½¿ç¨èä»£çå·²æçºä¸ç¨®å¼·å¤§çå·¥å·ï¼å¯ééæ¨¡æ¬ä½¿ç¨èäºåä¾æ¹åæ¨è¦ç³»çµ±ãç¶èï¼ç¾æçæ¹æ³ç±æ¼è¨æ¶é«çµæ§æçä¸å½°ï¼å°è´ä¸ç¸éè³è¨ä¿çï¼ä¸ç¡æ³èéåæ­¡è¿åº¦ç­ç¤¾æå½±é¿å ç´ ï¼å æ­¤å¨è·¨ç¶²åå ´æ¯ä¸­æéå°å°é£ãçºäºè§£æ±ºéäºéå¶ï¼æåå¼å¥äº AgentCF++ï¼éæ¯ä¸åæ°ç©çæ¶æ§ï¼å·åéå±¤è¨æ¶é«æ¶æ§åå©æ­¥é©èåæ©å¶ï¼å¯ææéæ¿¾ç¹å®ç¶²åçåå¥½ãæ­¤å¤ï¼æåæåºäºå·æå±äº«è¨æ¶é«çèè¶£ç¾¤çµï¼è®æ¨¡åè½ææåæ­¡è¿åº¦è¶¨å¢å°å·æç¸ä¼¼èè¶£çä½¿ç¨èé æçå½±é¿ãééå¨å¤åè·¨ç¶²åè³æéä¸çå»£æ³å¯¦é©ï¼AgentCF++ å±ç¾åºåªæ¼åºæºæ¨¡åçæè½ï¼çªé¡¯å¶å¨çºæ¨è¦ç³»çµ±ç²¾é²ä½¿ç¨èè¡çºæ¨¡æ¬æ¹é¢çæææ§ãæåçç¨å¼ç¢¼å¯å¨ https://anonymous.4open.science/r/AgentCF-plus åå¾ã

##### **Inner Thinking Transformer: Leveraging Dynamic Depth Scaling to Foster Adaptive Internal Thinking**
2502.13842v1 by Yilong Chen, Junyuan Shang, Zhenyu Zhang, Yanxi Xie, Jiawei Sheng, Tingwen Liu, Shuohuan Wang, Yu Sun, Hua Wu, Haifeng Wang

Large language models (LLMs) face inherent performance bottlenecks under
parameter constraints, particularly in processing critical tokens that demand
complex reasoning. Empirical analysis reveals challenging tokens induce abrupt
gradient spikes across layers, exposing architectural stress points in standard
Transformers. Building on this insight, we propose Inner Thinking Transformer
(ITT), which reimagines layer computations as implicit thinking steps. ITT
dynamically allocates computation through Adaptive Token Routing, iteratively
refines representations via Residual Thinking Connections, and distinguishes
reasoning phases using Thinking Step Encoding. ITT enables deeper processing of
critical tokens without parameter expansion. Evaluations across 162M-466M
parameter models show ITT achieves 96.5\% performance of a 466M Transformer
using only 162M parameters, reduces training data by 43.2\%, and outperforms
Transformer/Loop variants in 11 benchmarks. By enabling elastic computation
allocation during inference, ITT balances performance and efficiency through
architecture-aware optimization of implicit thinking pathways.

æè¦ï¼å¤§åè¯­è¨æ¨¡å (LLM) å¨åæ°éå¶ä¸ä¼é¢ä¸´åºæçæ§è½ç¶é¢ï¼å°¤å¶æ¯å¨å¤çéè¦å¤ææ¨ççå³é®æ è®°æ¶ãç»éªåæè¡¨æï¼å·ææææ§çæ è®°ä¼å¼èµ·è·¨å±æ¢¯åº¦æ¥å§ä¸åï¼æ´é²äºæ å Transformer ä¸­çæ¶æååç¹ãåºäºè¿ä¸è§è§£ï¼æä»¬æåºäº Inner Thinking Transformer (ITT)ï¼å®å°å±è®¡ç®éæ°ææ³ä¸ºéå¼æèæ­¥éª¤ãITT éè¿èªéåºæ è®°è·¯ç±å¨æåéè®¡ç®ï¼éè¿æ®å·®æèè¿æ¥è¿­ä»£ä¼åè¡¨ç¤ºï¼å¹¶ä½¿ç¨æèæ­¥éª¤ç¼ç åºåæ¨çé¶æ®µãITT å¯ä»¥å¨ä¸æ©å±åæ°çæåµä¸å¯¹å³é®æ è®°è¿è¡æ´æ·±å¥çå¤çãå¯¹ 162M-466M åæ°æ¨¡åçè¯ä¼°è¡¨æï¼ITT ä½¿ç¨ä» 162M åæ°å°±å®ç°äº 466M Transformer ç 96.5% æ§è½ï¼å°è®­ç»æ°æ®åå°äº 43.2%ï¼å¹¶å¨ 11 ä¸ªåºåæµè¯ä¸­ä¼äº Transformer/Loop åä½ãéè¿å¨æ¨çè¿ç¨ä¸­å¯ç¨å¼¹æ§è®¡ç®åéï¼ITT éè¿éå¼æèè·¯å¾çæ¶ææç¥ä¼åæ¥å¹³è¡¡æ§è½åæçã

##### **Quantifying Memorization and Retriever Performance in Retrieval-Augmented Vision-Language Models**
2502.13836v1 by Peter Carragher, Abhinand Jha, R Raghav, Kathleen M. Carley

Large Language Models (LLMs) demonstrate remarkable capabilities in question
answering (QA), but metrics for assessing their reliance on memorization versus
retrieval remain underdeveloped. Moreover, while finetuned models are
state-of-the-art on closed-domain tasks, general-purpose models like GPT-4o
exhibit strong zero-shot performance. This raises questions about the
trade-offs between memorization, generalization, and retrieval. In this work,
we analyze the extent to which multimodal retrieval-augmented VLMs memorize
training data compared to baseline VLMs. Using the WebQA benchmark, we contrast
finetuned models with baseline VLMs on multihop retrieval and question
answering, examining the impact of finetuning on data memorization. To quantify
memorization in end-to-end retrieval and QA systems, we propose several proxy
metrics by investigating instances where QA succeeds despite retrieval failing.
Our results reveal the extent to which finetuned models rely on memorization.
In contrast, retrieval-augmented VLMs have lower memorization scores, at the
cost of accuracy (72% vs 52% on WebQA test set). As such, our measures pose a
challenge for future work to reconcile memorization and generalization in both
Open-Domain QA and joint Retrieval-QA tasks.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å¨åç­ï¼QAï¼ä»»åä¸­å±ç¾åºé©äººçè½åï¼ä½ç¨æ¼è©ä¼°å¶ä¾è³´è¨æ¶èéæª¢ç´¢çææ¨ä»æªç¼å±æçãæ­¤å¤ï¼éç¶å¾®èª¿æ¨¡åå¨å°éé åä»»åä¸­æ¯ç®åæåé²çæè¡ï¼ä½å GPT-4o éæ¨£çéç¨æ¨¡åå±ç¾åºå¼·å¤§çé¶æ¬¡å­¸ç¿æè½ãéå¼ç¼äºéæ¼è¨æ¶ãæ¦ååæª¢ç´¢ä¹éæ¬è¡¡åæ¨çåé¡ãå¨éé ç ç©¶ä¸­ï¼æååæäºå¤æ¨¡ææª¢ç´¢å¢å¼· VLM èåºæº VLM ç¸æ¯ï¼è¨æ¶è¨ç·´è³æçç¨åº¦ãä½¿ç¨ WebQA åºæºï¼æåå¨å¤è·³æª¢ç´¢ååç­æ¹é¢æ¯è¼äºå¾®èª¿æ¨¡åååºæº VLMï¼ä¸¦æ¢è¨å¾®èª¿å°è³æè¨æ¶çå½±é¿ãçºäºéåç«¯å°ç«¯æª¢ç´¢å QA ç³»çµ±ä¸­çè¨æ¶ï¼æåééæ¢è¨æª¢ç´¢å¤±æä½ QA æåçææ³ï¼æåºäºå¹¾åä»£çææ¨ãæåççµææ­ç¤ºäºå¾®èª¿æ¨¡åä¾è³´è¨æ¶çç¨åº¦ãç¸æ¯ä¹ä¸ï¼æª¢ç´¢å¢å¼· VLM çè¨æ¶åæ¸è¼ä½ï¼ä½ä»£å¹æ¯æºç¢ºåº¦ï¼å¨ WebQA æ¸¬è©¦éä¸­çº 72% å° 52%ï¼ãå æ­¤ï¼æåçæ¸¬éå°æªä¾çç ç©¶æåºäºææ°ï¼ä»¥èª¿åéæ¾é å QA åè¯åæª¢ç´¢-QA ä»»åä¸­çè¨æ¶åæ¦åã

##### **Proving Olympiad Inequalities by Synergizing LLMs and Symbolic Reasoning**
2502.13834v1 by Zenan Li, Zhaoyu Li, Wen Tang, Xian Zhang, Yuan Yao, Xujie Si, Fan Yang, Kaiyu Yang, Xiaoxing Ma

Large language models (LLMs) can prove mathematical theorems formally by
generating proof steps (\textit{a.k.a.} tactics) within a proof system.
However, the space of possible tactics is vast and complex, while the available
training data for formal proofs is limited, posing a significant challenge to
LLM-based tactic generation. To address this, we introduce a neuro-symbolic
tactic generator that synergizes the mathematical intuition learned by LLMs
with domain-specific insights encoded by symbolic methods. The key aspect of
this integration is identifying which parts of mathematical reasoning are best
suited to LLMs and which to symbolic methods. While the high-level idea of
neuro-symbolic integration is broadly applicable to various mathematical
problems, in this paper, we focus specifically on Olympiad inequalities
(Figure~1). We analyze how humans solve these problems and distill the
techniques into two types of tactics: (1) scaling, handled by symbolic methods,
and (2) rewriting, handled by LLMs. In addition, we combine symbolic tools with
LLMs to prune and rank the proof goals for efficient proof search. We evaluate
our framework on 161 challenging inequalities from multiple mathematics
competitions, achieving state-of-the-art performance and significantly
outperforming existing LLM and symbolic approaches without requiring additional
training data.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è½ééå¨è­æç³»çµ±ä¸­ç¢çè­ææ­¥é©ï¼åç¨±ç­ç¥ï¼ä¾æ­£å¼è­ææ¸å­¸å®çãç¶èï¼å¯è½çç­ç¥ç©ºéæµ©çä¸è¤éï¼èå½¢å¼åè­æçå¯ç¨è¨ç·´è³ææéï¼å°åºæ¼ LLM çç­ç¥ç¢çæ§æéå¤§ææ°ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äºç¥ç¶ç¬¦èç­ç¥ç¢çå¨ï¼å®å° LLM å­¸å°çæ¸å­¸ç´è¦ºèç¬¦èæ¹æ³ç·¨ç¢¼çç¹å®é åè¦è§£çµåèµ·ä¾ãéç¨®æ´åçééµé¢åå¨æ¼æ¾åºæ¸å­¸æ¨ççåªäºé¨åæé©å LLMï¼åªäºé¨åæé©åç¬¦èæ¹æ³ãéç¶ç¥ç¶ç¬¦èæ´åçé«éæ¦å¿µå»£æ³é©ç¨æ¼åç¨®æ¸å­¸åé¡ï¼ä½å¨æ¬æä¸­ï¼æåç¹å¥éæ³¨å¥§æå¹äºä¸ç­å¼ï¼å 1ï¼ãæååæäººé¡å¦ä½è§£æ±ºéäºåé¡ï¼ä¸¦å°æè¡æçæå©ç¨®ç­ç¥é¡åï¼(1) ç¸®æ¾ï¼ç±ç¬¦èæ¹æ³èçï¼ä»¥å (2) éå¯«ï¼ç± LLM èçãæ­¤å¤ï¼æåå°ç¬¦èå·¥å·è LLM çµåï¼ä»¥ä¿®åªåæåè­æç®æ¨ï¼ä»¥ä¾¿ææé²è¡è­ææå°ãæåå¨å¤åæ¸å­¸ç«¶è³½ä¸­éå° 161 åå·æææ°æ§çä¸ç­å¼è©ä¼°æåçæ¶æ§ï¼éå°äºæåé²çæè½ï¼ä¸¦ä¸é¡¯èåªæ¼ç¾æç LLM åç¬¦èæ¹æ³ï¼èç¡éé¡å¤çè¨ç·´è³æã

##### **Scoring Verifiers: Evaluating Synthetic Verification in Code and Reasoning**
2502.13820v1 by Aleksander Ficek, Somshubra Majumdar, Vahid Noroozi, Boris Ginsburg

Code verification has recently found great success as a critical component in
training large scale reasoning models for coding. Synthetic techniques such as
self-generated test cases and reward models provide a way to enhance code
capabilities beyond predefined tests. Building on these advancements, we
propose new benchmarks designed to systematically evaluate the impact of
synthetic verification methods on assessing solution correctness. We introduce
HE-R, HE-R+, MBPP-R, and MBPP-R+, which transform existing coding benchmarks
into scoring and ranking datasets to evaluate the effectiveness of synthetic
verifiers. Using these benchmarks, we analyze synthetic verification methods in
standard, reasoning-based, and reward-based LLMs. Our results show that recent
reasoning models significantly improve test case generation and that scaling
test cases enhances verification accuracy.

æè¦ï¼ç¨å¼ç¢¼é©è­æè¿è¢«ç¼ç¾ä½çºè¨ç·´å¤§åæ¨çæ¨¡åé²è¡ç·¨ç¢¼çéè¦çµæé¨åèç²å¾å·¨å¤§çæåãèªæç¢ççæ¸¬è©¦æ¡ä¾åçåµæ¨¡åç­åææè¡æä¾äºä¸ç¨®æ¹æ³ï¼å¯ä»¥å¢å¼·ç¨å¼ç¢¼åè½ï¼è¶è¶é å®ç¾©çæ¸¬è©¦ãå¨éäºé²å±çåºç¤ä¸ï¼æåæåºäºæ°çåºæºï¼æ¨å¨ç³»çµ±æ§å°è©ä¼°åæé©è­æ¹æ³å°è©ä¼°è§£æ±ºæ¹æ¡æ­£ç¢ºæ§çå½±é¿ãæåä»ç´¹äº HE-RãHE-R+ãMBPP-R å MBPP-R+ï¼å®åå°ç¾æçç·¨ç¢¼åºæºè½æçºè©ååæåè³æéï¼ä»¥è©ä¼°åæé©è­å¨çæææ§ãä½¿ç¨éäºåºæºï¼æååæäºæ¨æºãåºæ¼æ¨çååºæ¼çåµç LLM ä¸­çåæé©è­æ¹æ³ãæåççµæè¡¨æï¼æè¿çæ¨çæ¨¡åé¡¯èæ¹é²äºæ¸¬è©¦æ¡ä¾çæï¼ä¸¦ä¸æ´åæ¸¬è©¦æ¡ä¾å¢å¼·äºé©è­æºç¢ºæ§ã

##### **On the Duality between Gradient Transformations and Adapters**
2502.13811v1 by Lucas Torroba-Hennigen, Hunter Lang, Han Guo, Yoon Kim

We study memory-efficient optimization of neural networks with linear
gradient transformations, where the gradients are linearly mapped to a lower
dimensional space than the full parameter space, thus saving memory required
for gradient accumulation and optimizer state persistence. The model parameters
are updated by first performing an optimization step in the lower dimensional
space and then going back into the original parameter space via the linear
map's transpose. We show that optimizing the model in this transformed space is
equivalent to reparameterizing the original model through a linear adapter that
additively modifies the model parameters, and then only optimizing the
adapter's parameters. When the transformation is Kronecker-factored, this
establishes an equivalence between GaLore and one-sided LoRA. We show that this
duality between gradient transformations and adapter-based reparameterizations
unifies existing approaches to memory-efficient training and suggests new
techniques for improving training efficiency and memory use.

æè¦ï¼æåç ç©¶å·æç·æ§æ¢¯åº¦è½æçç¥ç¶ç¶²è·¯çè¨æ¶é«é«ææä½³åï¼å¶ä¸­æ¢¯åº¦è¢«ç·æ§æ å°å°æ¯å®æ´åæ¸ç©ºéæ´ä½ç¶­åº¦çç©ºéï¼å¾èç¯çäºæ¢¯åº¦ç´¯ç©åæä½³åå¨çææçºæ§æéçè¨æ¶é«ãæ¨¡ååæ¸æåå¨ä½ç¶­åº¦ç©ºéå·è¡æä½³åæ­¥é©ï¼åééç·æ§æ å°çè½ç½®è¿åå°åå§åæ¸ç©ºéä¾é²è¡æ´æ°ãæåèªªæå¨éåè½æç©ºéæä½³åæ¨¡åç­æ¼ééç·æ§è½æ¥å¨éæ°åæ¸ååå§æ¨¡åï¼éåè½æ¥å¨æç´¯å ä¿®æ¹æ¨¡ååæ¸ï¼ç¶å¾åæä½³åè½æ¥å¨çåæ¸ãç¶è½ææ¯ Kronecker åè§£æï¼éæå¨ GaLore åå®é LoRA ä¹éå»ºç«ç­ææ§ãæåèªªææ¢¯åº¦è½æååºæ¼è½æ¥å¨çéæ°åæ¸åä¹éçéç¨®å°å¶æ§çµ±ä¸äºç¾æçè¨æ¶é«é«æè¨ç·´æ¹æ³ï¼ä¸¦å»ºè­°æ°çæè¡ä¾æ¹åè¨ç·´æçåè¨æ¶é«ä½¿ç¨ã

##### **LESA: Learnable LLM Layer Scaling-Up**
2502.13794v1 by Yifei Yang, Zouying Cao, Xinbei Ma, Yao Yao, Libo Qin, Zhi Chen, Hai Zhao

Training Large Language Models (LLMs) from scratch requires immense
computational resources, making it prohibitively expensive. Model scaling-up
offers a promising solution by leveraging the parameters of smaller models to
create larger ones. However, existing depth scaling-up methods rely on
empirical heuristic rules for layer duplication, which result in poorer
initialization and slower convergence during continual pre-training. We propose
\textbf{LESA}, a novel learnable method for depth scaling-up. By concatenating
parameters from each layer and applying Singular Value Decomposition, we
uncover latent patterns between layers, suggesting that inter-layer parameters
can be learned. LESA uses a neural network to predict the parameters inserted
between adjacent layers, enabling better initialization and faster training.
Experiments show that LESA outperforms existing baselines, achieving superior
performance with less than half the computational cost during continual
pre-training. Extensive analyses demonstrate its effectiveness across different
model sizes and tasks.

æè¦ï¼å¾é ­è¨ç·´å¤§åèªè¨æ¨¡å (LLM) éè¦é¾å¤§çè¨ç®è³æºï¼éè®ææ¬é«å¾ä»¤äººé£ä»¥è² æãæ¨¡åæ´åæä¾äºæå¸æçè§£æ±ºæ¹æ¡ï¼ééå©ç¨è¼å°æ¨¡åçåæ¸ä¾å»ºç«è¼å¤§çæ¨¡åãç¶èï¼ç¾æçæ·±åº¦æ´åæ¹æ³ä¾è³´æ¼å±¤çå¶çç¶é©åç¼å¼è¦åï¼éæå°è´å¨æçºé è¨ç·´æéåå§åè¼å·®ä¸æ¶æè¼æ¢ãæåæåº \textbf{LESA}ï¼ä¸ç¨®ç¨æ¼æ·±åº¦æ´åçæ°åå¯å­¸ç¿æ¹æ³ãééä¸²æ¥ä¾èªæ¯å±¤çåæ¸ä¸¦æç¨å¥ç°å¼åè§£ï¼æåæ­ç¤ºäºå±¤ä¹éçæ½å¨æ¨¡å¼ï¼éè¡¨æå¯ä»¥å­¸ç¿å±¤éåæ¸ãLESA ä½¿ç¨ç¥ç¶ç¶²è·¯ä¾é æ¸¬æå¥ç¸é°å±¤ä¹éçåæ¸ï¼å¾èå¯¦ç¾æ´å¥½çåå§ååæ´å¿«çè¨ç·´ãå¯¦é©è¡¨æï¼LESA åªæ¼ç¾æçåºæºï¼å¨æçºé è¨ç·´æéä»¥ä¸å°ä¸åçè¨ç®ææ¬å¯¦ç¾äºåè¶çæè½ãå»£æ³çåæè­æäºå¶å¨ä¸åæ¨¡åå¤§å°åä»»åä¸­çæææ§ã

##### **From Tools to Teammates: Evaluating LLMs in Multi-Session Coding Interactions**
2502.13791v1 by NathanaÃ«l Carraz Rakotonirina, Mohammed Hamdy, Jon Ander Campos, Lucas Weber, Alberto Testoni, Marzieh Fadaee, Sandro Pezzelle, Marco Del Tredici

Large Language Models (LLMs) are increasingly used in working environments
for a wide range of tasks, excelling at solving individual problems in
isolation. However, are they also able to effectively collaborate over
long-term interactions? To investigate this, we introduce MemoryCode, a
synthetic multi-session dataset designed to test LLMs' ability to track and
execute simple coding instructions amid irrelevant information, simulating a
realistic setting. While all the models we tested handle isolated instructions
well, even the performance of state-of-the-art models like GPT-4o deteriorates
when instructions are spread across sessions. Our analysis suggests this is due
to their failure to retrieve and integrate information over long instruction
chains. Our results highlight a fundamental limitation of current LLMs,
restricting their ability to collaborate effectively in long interactions.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM)  zunehmend in Arbeitsumgebungen fÃ¼r eine Vielzahl von Aufgaben verwendet, die sich bei der isolierten LÃ¶sung einzelner Probleme auszeichnen. Sind sie jedoch auch in der Lage, bei langfristigen Interaktionen effektiv zusammenzuarbeiten? Um dies zu untersuchen, fÃ¼hren wir MemoryCode ein, einen synthetischen Multi-Session-Datensatz, der entwickelt wurde, um die FÃ¤higkeit von LLMs zu testen, einfache Codierungsanweisungen inmitten irrelevanter Informationen zu verfolgen und auszufÃ¼hren, und so eine realistische Umgebung zu simulieren. WÃ¤hrend alle von uns getesteten Modelle isolierte Anweisungen gut handhaben, verschlechtert sich selbst die Leistung modernster Modelle wie GPT-4o, wenn Anweisungen Ã¼ber Sitzungen verteilt werden. Unsere Analyse legt nahe, dass dies auf ihr Versagen zurÃ¼ckzufÃ¼hren ist, Informationen Ã¼ber lange Befehlsketten abzurufen und zu integrieren. Unsere Ergebnisse zeigen eine grundlegende EinschrÃ¤nkung aktueller LLMs auf und schrÃ¤nken ihre FÃ¤higkeit ein, bei langen Interaktionen effektiv zusammenzuarbeiten.

##### **Helix-mRNA: A Hybrid Foundation Model For Full Sequence mRNA Therapeutics**
2502.13785v1 by Matthew Wood, Mathieu Klop, Maxime Allard

mRNA-based vaccines have become a major focus in the pharmaceutical industry.
The coding sequence as well as the Untranslated Regions (UTRs) of an mRNA can
strongly influence translation efficiency, stability, degradation, and other
factors that collectively determine a vaccine's effectiveness. However,
optimizing mRNA sequences for those properties remains a complex challenge.
Existing deep learning models often focus solely on coding region optimization,
overlooking the UTRs. We present Helix-mRNA, a structured state-space-based and
attention hybrid model to address these challenges. In addition to a first
pre-training, a second pre-training stage allows us to specialise the model
with high-quality data. We employ single nucleotide tokenization of mRNA
sequences with codon separation, ensuring prior biological and structural
information from the original mRNA sequence is not lost. Our model, Helix-mRNA,
outperforms existing methods in analysing both UTRs and coding region
properties. It can process sequences 6x longer than current approaches while
using only 10% of the parameters of existing foundation models. Its predictive
capabilities extend to all mRNA regions. We open-source the model
(https://github.com/helicalAI/helical) and model weights
(https://huggingface.co/helical-ai/helix-mRNA).

æè¦ï¼mRNA çºåºç¤çç«èå·²æçºè£½è¥ç¢æ¥­çä¸»è¦ç¦é»ã
mRNA çç·¨ç¢¼åºåä»¥åéè½è­¯å (UTR) æ
å¼·çå½±é¿è½è­¯æçãç©©å®æ§ãéè§£ï¼ä»¥åå¶ä»
å±åæ±ºå®ç«èæææ§çå ç´ ãç¶èï¼
éå°éäºç¹æ§æä½³å mRNA åºåä»ç¶æ¯ä¸é è¤éçææ°ã
ç¾æçæ·±åº¦å­¸ç¿æ¨¡åéå¸¸åªå°æ³¨æ¼ç·¨ç¢¼ååæä½³åï¼
å¿½ç¥äº UTRãæåæåº Helix-mRNAï¼ä¸ç¨®çµæ§åçæç©ºéçºåºç¤ä¸
çµåæ³¨æåçæ··åæ¨¡åä¾è§£æ±ºéäºææ°ãé¤äºç¬¬ä¸å
é è¨ç·´éæ®µï¼ç¬¬äºåé è¨ç·´éæ®µåè¨±æåä½¿ç¨é«åè³ªè³æ
è®æ¨¡åå°éåãæåä½¿ç¨å®æ ¸è·é¸æ¨è¨å mRNA
åºåï¼ä¸¦åé¢å¯ç¢¼å­ï¼ç¢ºä¿ä¸æéºå¤±ä¾èªåå§ mRNA åºåç
åé©çç©åçµæ§è³è¨ãæåçæ¨¡å Helix-mRNAï¼
å¨åæ UTR åç·¨ç¢¼ååç¹æ§æ¹é¢ï¼è¡¨ç¾åªæ¼ç¾ææ¹æ³ãå®å¯ä»¥
èçæ¯ç®åæ¹æ³é· 6 åçåºåï¼åæåä½¿ç¨ç¾æåºç¤æ¨¡å
10% çåæ¸ãå¶é æ¸¬è½åæ´åææ mRNA ååãæåéæ¾åå§ç¢¼
æ¨¡å (https://github.com/helicalAI/helical) åæ¨¡åæ¬é
(https://huggingface.co/helical-ai/helix-mRNA)ã

##### **Translation in the Hands of Many:Centering Lay Users in Machine Translation Interactions**
2502.13780v1 by Beatrice Savoldi, Alan Ramponi, Matteo Negri, Luisa Bentivogli

Converging societal and technical factors have transformed language
technologies into user-facing applications employed across languages. Machine
Translation (MT) has become a global tool, with cross-lingual services now also
supported by dialogue systems powered by multilingual Large Language Models
(LLMs). This accessibility has expanded MT's reach to a vast base of lay users,
often with little to no expertise in the languages or the technology itself.
Despite this, the understanding of MT consumed by this diverse group of users
-- their needs, experiences, and interactions with these systems -- remains
limited. This paper traces the shift in MT user profiles, focusing on
non-expert users and how their engagement with these systems may change with
LLMs. We identify three key factors -- usability, trust, and literacy -- that
shape these interactions and must be addressed to align MT with user needs. By
exploring these dimensions, we offer insights to guide future MT with a
user-centered approach.

æè¦ï¼ç¤¾æåæè¡å ç´ çå¯èï¼å·²å°èªè¨æè¡è½è®çºè·¨èªè¨æç¨çä½¿ç¨èä»é¢æç¨ç¨å¼ãæ©å¨ç¿»è­¯ (MT) å·²æçºå¨çæ§å·¥å·ï¼è·¨èªè¨æåç¾ä¹ç²å¾ç±å¤èªè¨å¤§åèªè¨æ¨¡å (LLM) æä¾ååçå°è©±ç³»çµ±æ¯æ´ãéç¨®æç¨æ§å·²å° MT çè§¸è§å»¶ä¼¸å°å»£å¤§çéå°æ¥­ä½¿ç¨èï¼ä»åéå¸¸å°èªè¨ææè¡æ¬èº«ç¥ä¹çå°ï¼çè³ä¸ç¡æç¥ãåç®¡å¦æ­¤ï¼éç¾¤å¤åä½¿ç¨èå° MT ççè§£ââä»åçéæ±ãç¶é©ï¼ä»¥åèéäºç³»çµ±çäºåââä»ç¶æéãæ¬æè¿½è¹¤ MT ä½¿ç¨èè¼ªå»çè½è®ï¼èéæ¼éå°æ¥­ä½¿ç¨èï¼ä»¥åä»åèéäºç³»çµ±çäºåå¦ä½é¨è LLM èæ¹è®ãæåæ¾åºä¸é ééµå ç´ ââå¯ç¨æ§ãä¿¡ä»»åº¦åè­å­è½åââéäºå ç´ å½¢å¡äºéäºäºåï¼ä¸å¿é å ä»¥èçï¼æè½è® MT èä½¿ç¨èéæ±ä¿æä¸è´ãééæ¢è¨éäºé¢åï¼æåæä¾è¦è§£ï¼ä»¥ä½¿ç¨èçºä¸­å¿çæ¹æ³å¼å°æªä¾ç MTã

##### **Poster: SpiderSim: Multi-Agent Driven Theoretical Cybersecurity Simulation for Industrial Digitalization**
2502.13778v1 by Jiaqi Li, Xizhong Guo, Yang Zhao, Lvyang Zhang, Lidong Zhai

Rapid industrial digitalization has created intricate cybersecurity demands
that necessitate effective validation methods. While cyber ranges and
simulation platforms are widely deployed, they frequently face limitations in
scenario diversity and creation efficiency. In this paper, we present
SpiderSim, a theoretical cybersecurity simulation platform enabling rapid and
lightweight scenario generation for industrial digitalization security
research. At its core, our platform introduces three key innovations: a
structured framework for unified scenario modeling, a multi-agent collaboration
mechanism for automated generation, and modular atomic security capabilities
for flexible scenario composition. Extensive implementation trials across
multiple industrial digitalization contexts, including marine ranch monitoring
systems, validate our platform's capacity for broad scenario coverage with
efficient generation processes. Built on solid theoretical foundations and
released as open-source software, SpiderSim facilitates broader research and
development in automated security testing for industrial digitalization.

æè¦ï¼å¿«éå·¥æ¥­æ¸ä½ååµé äºè¤éçç¶²è·¯å®å¨éæ±ï¼ééè¦ææçé©è­æ¹æ³ãéç¶ç¶²è·¯ç¯ååæ¨¡æ¬å¹³å°å»£æ³é¨ç½²ï¼ä½å®åå¨å ´æ¯å¤æ¨£æ§ååµå»ºæçæ¹é¢ç¶å¸¸é¢è¨éå¶ãå¨æ¬æä¸­ï¼æåæåºäº SpiderSimï¼éæ¯ä¸åçè«ç¶²è·¯å®å¨æ¨¡æ¬å¹³å°ï¼å¯ä»¥çºå·¥æ¥­æ¸ä½åå®å¨ç ç©¶å¿«éä¸è¼é¬å°çæå ´æ¯ãå¾æ ¹æ¬ä¸ä¾èªªï¼æåçå¹³å°å¼å¥äºä¸é ééµåµæ°ï¼çµ±ä¸å ´æ¯å»ºæ¨¡ççµæ§åæ¡æ¶ãç¨æ¼èªåçæçå¤ä»£çåä½æ©å¶ï¼ä»¥åç¨æ¼éæ´»å ´æ¯çµåçæ¨¡çµååå­å®å¨åè½ãæ©«è·¨å¤åå·¥æ¥­æ¸ä½åæå¢çå»£æ³å¯¦ä½è©¦é©ï¼åæ¬æµ·æ´ç§å ´ç£æ§ç³»çµ±ï¼é©è­äºæåçå¹³å°å¨ææçççæç¨åºä¸å·æå»£æ³å ´æ¯æ¶µèç¯åçè½åãSpiderSim å»ºç«å¨ç©©åºççè«åºç¤ä¸ï¼ä¸¦ä½çºéæºè»é«éåºï¼ä¿é²äºå·¥æ¥­æ¸ä½åèªååå®å¨æ¸¬è©¦çæ´å»£æ³ç ç©¶åéç¼ã

##### **EHOP: A Dataset of Everyday NP-Hard Optimization Problems**
2502.13776v1 by Alex Duchnowski, Ellie Pavlick, Alexander Koller

We introduce the dataset of Everyday Hard Optimization Problems (EHOP), a
collection of NP-hard optimization problems expressed in natural language. EHOP
includes problem formulations that could be found in computer science
textbooks, versions that are dressed up as problems that could arise in real
life, and variants of well-known problems with inverted rules. We find that
state-of-the-art LLMs, across multiple prompting strategies, systematically
solve textbook problems more accurately than their real-life and inverted
counterparts. We argue that this constitutes evidence that LLMs adapt solutions
seen during training, rather than leveraging reasoning abilities that would
enable them to generalize to novel problems.

æè¦ï¼æåä»ç´¹æ¥å¸¸é£è§£æä½³ååé¡ (EHOP) çè³æéï¼éæ¯ä»¥èªç¶èªè¨è¡¨ç¤ºçä¸ç³»å NP é£æä½³ååé¡ãEHOP åå«å¯å¨é»è¦ç§å­¸æç§æ¸ä¸­æ¾å°çåé¡è¡¨è¿°ãåè£æç¾å¯¦çæ´»ä¸­å¯è½åºç¾çåé¡ççæ¬ï¼ä»¥åè¦åé¡åçç¥ååé¡è®é«ãæåç¼ç¾æåé²ç LLM å¨å¤ç¨®æç¤ºç­ç¥ä¸­ï¼ç³»çµ±æ§å°æ¯ç¾å¯¦çæ´»åé¡ååé¡æ´æºç¢ºå°è§£æ±ºæç§æ¸åé¡ãæåèªçºéæ§æ LLM æèª¿æ´å¨è¨ç·´æéçå°çè§£æ³çè­æï¼èä¸æ¯å©ç¨è½è®å®åæ¦åå°æ°åé¡çæ¨çè½åã

##### **VITAL: A New Dataset for Benchmarking Pluralistic Alignment in Healthcare**
2502.13775v1 by Anudeex Shetty, Amin Beheshti, Mark Dras, Usman Naseem

Alignment techniques have become central to ensuring that Large Language
Models (LLMs) generate outputs consistent with human values. However, existing
alignment paradigms often model an averaged or monolithic preference, failing
to account for the diversity of perspectives across cultures, demographics, and
communities. This limitation is particularly critical in health-related
scenarios, where plurality is essential due to the influence of culture,
religion, personal values, and conflicting opinions. Despite progress in
pluralistic alignment, no prior work has focused on health, likely due to the
unavailability of publicly available datasets. To address this gap, we
introduce VITAL, a new benchmark dataset comprising 13.1K value-laden
situations and 5.4K multiple-choice questions focused on health, designed to
assess and benchmark pluralistic alignment methodologies. Through extensive
evaluation of eight LLMs of varying sizes, we demonstrate that existing
pluralistic alignment techniques fall short in effectively accommodating
diverse healthcare beliefs, underscoring the need for tailored AI alignment in
specific domains. This work highlights the limitations of current approaches
and lays the groundwork for developing health-specific alignment solutions.

æè¦ï¼å°é½æè¡å·²æçºç¢ºä¿å¤§åèªè¨æ¨¡å (LLM) ç¢çèäººé¡å¹å¼è§ä¸è´çè¼¸åºçæ ¸å¿ãç¶èï¼ç¾æçå°é½ç¯ä¾éå¸¸æå»ºæ¨¡å¹³åæå®ä¸çåå¥½ï¼ç¡æ³èéè·¨æåãäººå£çµ±è¨åç¤¾ç¾¤çä¸åè§é»ãæ­¤éå¶å¨èå¥åº·ç¸éçå ´æ¯ä¸­ç¹å¥éè¦ï¼å çºå¨éç¨®å ´æ¯ä¸­ï¼ç±æ¼æåãå®æãåäººå¹å¼è§åç¸äºè¡çªçæè¦çå½±é¿ï¼å¤åæ§æ¯å¿è¦çãåç®¡å¤åå°é½å·²åå¾é²å±ï¼ä½æ²æä»»ä½ååçå·¥ä½å°æ³¨æ¼å¥åº·ï¼éå¯è½æ¯å çºç¼ºä¹å¬éå¯ç¨çè³æéãçºäºè§£æ±ºæ­¤å·®è·ï¼æåå¼å¥äº VITALï¼éæ¯ä¸åæ°çåºæºè³æéï¼åå« 13.1K åå¹å¼è§å¿µçæå¢å 5.4K åé¸æé¡ï¼å°æ³¨æ¼å¥åº·ï¼æ¨å¨è©ä¼°ååºæºå¤åå°é½æ¹æ³ãééå°å«åä¸åè¦æ¨¡ç LLM é²è¡å»£æ³è©ä¼°ï¼æåè­æç¾æçå¤åå°é½æè¡ç¡æ³ææé©æä¸åçé«çä¿å¥ä¿¡å¿µï¼éå¼·èª¿äºå¨ç¹å®é åä¸­éè¦éèº«æé ç AI å°é½ãéé å·¥ä½çªé¡¯äºç¶åæ¹æ³çéå¶ï¼ä¸¦çºéç¼ç¹å®æ¼å¥åº·çå°é½è§£æ±ºæ¹æ¡å¥ å®äºåºç¤ã

##### **A consensus set for the aggregation of partial rankings: the case of the Optimal Set of Bucket Orders Problem**
2502.13769v1 by Juan A. Aledo, JosÃ© A. GÃ¡mez, Alejandro Rosete

In rank aggregation problems (RAP), the solution is usually a consensus
ranking that generalizes a set of input orderings. There are different variants
that differ not only in terms of the type of rankings that are used as input
and output, but also in terms of the objective function employed to evaluate
the quality of the desired output ranking. In contrast, in some machine
learning tasks (e.g. subgroup discovery) or multimodal optimization tasks,
attention is devoted to obtaining several models/results to account for the
diversity in the input data or across the search landscape. Thus, in this paper
we propose to provide, as the solution to an RAP, a set of rankings to better
explain the preferences expressed in the input orderings. We exemplify our
proposal through the Optimal Bucket Order Problem (OBOP), an RAP which consists
in finding a single consensus ranking (with ties) that generalizes a set of
input rankings codified as a precedence matrix. To address this, we introduce
the Optimal Set of Bucket Orders Problem (OSBOP), a generalization of the OBOP
that aims to produce not a single ranking as output but a set of consensus
rankings. Experimental results are presented to illustrate this proposal,
showing how, by providing a set of consensus rankings, the fitness of the
solution significantly improves with respect to the one of the original OBOP,
without losing comprehensibility.

æè¦ï¼å¨ç­ç´å½ç¸½åé¡ (RAP) ä¸­ï¼è§£æ±ºæ¹æ¡éå¸¸æ¯å±è­æåï¼æ¦æ¬äºä¸çµè¼¸å¥æåºãæä¸åçè®é«ï¼å®åä¹éçå·®ç°ä¸åå¨æ¼ç¨ä½è¼¸å¥åè¼¸åºçæåé¡åï¼éå¨æ¼ç¨æ¼è©ä¼°æéè¼¸åºæåçåè³ªçç®æ¨å½æ¸ãç¸æ¯ä¹ä¸ï¼å¨æäºæ©å¨å­¸ç¿ä»»åï¼ä¾å¦å­ç¾¤ç¼ç¾ï¼æå¤æ¨¡æåªåä»»åä¸­ï¼æ³¨æåéä¸­æ¼ç²å¾å¤åæ¨¡å/çµæï¼ä»¥èªªæè¼¸å¥æ¸æææç´¢ç¯åä¸­çå¤æ¨£æ§ãå æ­¤ï¼å¨æ¬æä¸­ï¼æåå»ºè­°æä¾ä¸çµæåä½çº RAP çè§£æ±ºæ¹æ¡ï¼ä»¥æ´å¥½å°è§£éè¼¸å¥æåºä¸­è¡¨éçåå¥½ãæåééæä½³æ¡¶åºåé¡ (OBOP) ä¾ä¾è­æåçææ¡ï¼OBOP æ¯ä¸å RAPï¼å®åæ¬æ¾å°ä¸åå®ä¸çå±è­æåï¼å¸¶æè¯ç¹«ï¼ï¼æ¦æ¬äºä¸çµç·¨ç¢¼çºåªåç©é£çè¼¸å¥æåãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äºæä½³æ¡¶åºåé¡é (OSBOP)ï¼éæ¯ OBOP çä¸åæ¦æ¬ï¼å¶ç®çæ¯ä¸ç¢çå®ä¸çæåä½çºè¼¸åºï¼èæ¯ç¢çä¸çµå±è­æåãæä¾äºå¯¦é©çµæä¾èªªæéåææ¡ï¼å±ç¤ºäºééæä¾ä¸çµå±è­æåï¼è§£æ±ºæ¹æ¡çé©æåº¦å¦ä½ç¸å°æ¼åå§ OBOP çé©æåº¦é¡¯èæé«ï¼èä¸æå¤±å»å¯çè§£æ§ã

##### **AI Software Engineer: Programming with Trust**
2502.13767v1 by Abhik Roychoudhury, Corina Pasareanu, Michael Pradel, Baishakhi Ray

Large Language Models (LLMs) have shown surprising proficiency in generating
code snippets, promising to automate large parts of software engineering via
artificial intelligence (AI). We argue that successfully deploying AI software
engineers requires a level of trust equal to or even greater than the trust
established by human-driven software engineering practices. The recent trend
toward LLM agents offers a path toward integrating the power of LLMs to create
new code with the power of analysis tools to increase trust in the code. This
opinion piece comments on whether LLM agents could dominate software
engineering workflows in the future and whether the focus of programming will
shift from programming at scale to programming with trust.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨ç¢çç¨å¼ç¢¼çæ®µæ¹é¢å±ç¾åºé©äººçè½åï¼æ¿è«¾ééäººå·¥æºæ§ (AI) èªååè»é«å·¥ç¨çå¤§é¨åãæåèªçºï¼æåé¨ç½² AI è»é«å·¥ç¨å¸«éè¦èäººçºé©åçè»é«å·¥ç¨å¯¦åå»ºç«çä¿¡ä»»ç¨åº¦ç¸åçè³æ´é«çä¿¡ä»»æ°´æºãæè¿æå LLM ä»£çäººçè¶¨å¢æä¾äºä¸æ¢è·¯å¾ï¼å¯ä»¥æ´å LLM çè½åï¼ä»¥å»ºç«æ°çç¨å¼ç¢¼ï¼ä¸¦å©ç¨åæå·¥å·çè½åä¾å¢å å°ç¨å¼ç¢¼çä¿¡ä»»ãéç¯æè¦æç« è©è«äº LLM ä»£çäººæ¯å¦è½å¨æªä¾ä¸»å°è»é«å·¥ç¨å·¥ä½æµç¨ï¼ä»¥åç¨å¼è¨­è¨çéé»æ¯å¦æå¾å¤§è¦æ¨¡ç¨å¼è¨­è¨è½ç§»å°å»ºç«ä¿¡ä»»çç¨å¼è¨­è¨ã

##### **GIMMICK -- Globally Inclusive Multimodal Multitask Cultural Knowledge Benchmarking**
2502.13766v1 by Florian Schneider, Carolin Holtermann, Chris Biemann, Anne Lauscher

Large Vision-Language Models (LVLMs) have recently gained attention due to
their distinctive performance and broad applicability. While it has been
previously shown that their efficacy in usage scenarios involving non-Western
contexts falls short, existing studies are limited in scope, covering just a
narrow range of cultures, focusing exclusively on a small number of cultural
aspects, or evaluating a limited selection of models on a single task only.
Towards globally inclusive LVLM research, we introduce GIMMICK, an extensive
multimodal benchmark designed to assess a broad spectrum of cultural knowledge
across 144 countries representing six global macro-regions. GIMMICK comprises
six tasks built upon three new datasets that span 728 unique cultural events or
facets on which we evaluated 20 LVLMs and 11 LLMs, including five proprietary
and 26 open-weight models of all sizes. We systematically examine (1) regional
cultural biases, (2) the influence of model size, (3) input modalities, and (4)
external cues. Our analyses reveal strong biases toward Western cultures across
models and tasks and highlight strong correlations between model size and
performance, as well as the effectiveness of multimodal input and external
geographic cues. We further find that models have more knowledge of tangible
than intangible aspects (e.g., food vs. rituals) and that they excel in
recognizing broad cultural origins but struggle with a more nuanced
understanding.

æè¦ï¼å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) æè¿å å¶ç¨ç¹çæè½åå»£æ³çé©ç¨æ§èååçç®ãéç¶ååå·²é¡¯ç¤ºåºå®åå¨æ¶åéè¥¿æ¹èªå¢çä½¿ç¨æå¢ä¸­çåæä¸è¶³ï¼ä½ç¾æç ç©¶çç¯åæéï¼åæ¶µèå°æ¸æåï¼å°æ³¨æ¼å°æ¸æåé¢åï¼æåéå°å®ä¸ä»»åè©ä¼°æéçæ¨¡åé¸é ãçºäºä¿é²å¨çåå®¹æ§ç LVLM ç ç©¶ï¼æåå¼å¥äº GIMMICKï¼éæ¯ä¸åå»£æ³çå¤æ¨¡æåºæºï¼æ¨å¨è©ä¼°æ©«è·¨å­åå¨çå·¨åååç 144 ååå®¶çå»£æ³æåç¥è­ãGIMMICK åå«å­é ä»»åï¼å»ºç«å¨ä¸åæ°çè³æéä¸ï¼æ¶µè 728 åç¨ç¹çæåäºä»¶æé¢åï¼æåå¨éäºé¢åè©ä¼°äº 20 å LVLMs å 11 å LLMï¼åæ¬äºåå°ææ¨¡åå 26 ååç¨®è¦æ¨¡çéæ¾æ¬éæ¨¡åãæåç³»çµ±æ§å°æª¢é© (1) ååæååè¦ã(2) æ¨¡åè¦æ¨¡çå½±é¿ã(3) è¼¸å¥æ¨¡å¼ï¼ä»¥å (4) å¤é¨æç¤ºãæåçåææ­ç¤ºäºæææ¨¡ååä»»åä¸­å°è¥¿æ¹æåçå¼·çåè¦ï¼ä¸¦å¼·èª¿äºæ¨¡åè¦æ¨¡åæè½ä¹éçå¼·çç¸éæ§ï¼ä»¥åå¤æ¨¡å¼è¼¸å¥åå¤é¨å°çæç¤ºçæææ§ãæåé²ä¸æ­¥ç¼ç¾ï¼æ¨¡åå°æå½¢é¢åï¼ä¾å¦é£ç©èåå¼ï¼çäºè§£å¤æ¼ç¡å½¢é¢åï¼èä¸å®åæé·è¾¨è­å»£æ³çæåèµ·æºï¼ä½å¨æ´ç´°ç·»ççè§£ä¸åæå°é£ã

##### **SCALAR: Scientific Citation-based Live Assessment of Long-context Academic Reasoning**
2502.13753v1 by Renxi Wang, Honglin Mu, Liqun Ma, Lizhi Lin, Yunlong Feng, Timothy Baldwin, Xudong Han, Haonan Li

Evaluating large language models' (LLMs) long-context understanding
capabilities remains challenging. We present SCALAR (Scientific Citation-based
Live Assessment of Long-context Academic Reasoning), a novel benchmark that
leverages academic papers and their citation networks. SCALAR features
automatic generation of high-quality ground truth labels without human
annotation, controllable difficulty levels, and a dynamic updating mechanism
that prevents data contamination. Using ICLR 2025 papers, we evaluate 8
state-of-the-art LLMs, revealing key insights about their capabilities and
limitations in processing long scientific documents across different context
lengths and reasoning types. Our benchmark provides a reliable and sustainable
way to track progress in long-context understanding as LLM capabilities evolve.

æè¦ï¼è©ä¼°å¤§åèªè¨æ¨¡å (LLM) çé·ææ¬çè§£è½åä»ç¶å·æææ°æ§ãæåæåº SCALARï¼åºæ¼ç§å­¸å¼æçé·ææ¬å­¸è¡æ¨çç¾å ´è©éï¼ï¼éæ¯ä¸åå©ç¨å­¸è¡è«æåå¶å¼æç¶²è·¯çæ°åºæºãSCALAR çç¹é»æ¯èªåçæé«åè³ªççå¯¦æ¨ç±¤ï¼ç¡éäººå·¥è¨»è§£ãå¯æ§çé£åº¦ç­ç´ï¼ä»¥åå¯é²æ­¢è³ææ±¡æçåææ´æ°æ©å¶ãä½¿ç¨ ICLR 2025 å¹´çè«æï¼æåè©ä¼°äº 8 åæåé²ç LLMï¼æ­ç¤ºäºå®åå¨èçä¸åé·åº¦çç§å­¸æä»¶åæ¨çé¡åæçè½ååéå¶æ¹é¢çééµè¦è§£ãæåçåºæºæä¾äºä¸ç¨®å¯é ä¸å¯æçºçæ¹æ³ä¾è¿½è¹¤ LLM è½åæ¼é²æé·ææ¬çè§£çé²åº¦ã

##### **RobustX: Robust Counterfactual Explanations Made Easy**
2502.13751v1 by Junqi Jiang, Luca Marzari, Aaryan Purohit, Francesco Leofante

The increasing use of Machine Learning (ML) models to aid decision-making in
high-stakes industries demands explainability to facilitate trust.
Counterfactual Explanations (CEs) are ideally suited for this, as they can
offer insights into the predictions of an ML model by illustrating how changes
in its input data may lead to different outcomes. However, for CEs to realise
their explanatory potential, significant challenges remain in ensuring their
robustness under slight changes in the scenario being explained. Despite the
widespread recognition of CEs' robustness as a fundamental requirement, a lack
of standardised tools and benchmarks hinders a comprehensive and effective
comparison of robust CE generation methods. In this paper, we introduce
RobustX, an open-source Python library implementing a collection of CE
generation and evaluation methods, with a focus on the robustness property.
RobustX provides interfaces to several existing methods from the literature,
enabling streamlined access to state-of-the-art techniques. The library is also
easily extensible, allowing fast prototyping of novel robust CE generation and
evaluation methods.

æè¦ï¼é¨èæ©å¨å­¸ç¿ (ML) æ¨¡åå¨é«é¢¨éªç¢æ¥­ä¸­è¼å©æ±ºç­å¶å®æ¥çå»£æ³ï¼å¯è§£éæ§éæ±æ¥å¢ï¼ä»¥å©æ¼å»ºç«ä¿¡ä»»ãåäºå¯¦è§£é (CE) éå¸¸é©åæ­¤ç®çï¼å çºå®åå¯ä»¥ééèªªæè¼¸å¥è³æçè®æ´å¦ä½å°è´ä¸åççµæï¼é²èæä¾å° ML æ¨¡åé æ¸¬çè¦è§£ãç¶èï¼è¦è® CE ç¼æ®å¶è§£éæ½åï¼å¨ç¢ºä¿å¶å¨æè§£éæå¢ä¸­å°å¾®å°è®æ´å·æç©©å¥æ§æ¹é¢ï¼ä»æè¨±å¤ææ°ãåç®¡ CE çç©©å¥æ§å»£æ³è¢«èªçºæ¯ä¸é åºæ¬è¦æ±ï¼ä½ç¼ºä¹æ¨æºåå·¥å·ååºæºï¼æé»ç¤å°ç©©å¥ CE çææ¹æ³é²è¡å¨é¢ä¸ææçæ¯è¼ãå¨æ¬æä¸­ï¼æåä»ç´¹äº RobustXï¼éæ¯ä¸åéæºç Python å½å¼åº«ï¼å¯¦ä½äºä¸ç³»å CE çæåè©ä¼°æ¹æ³ï¼ä¸¦å°æ³¨æ¼ç©©å¥æ§å±¬æ§ãRobustX æä¾äºèæç»ä¸­å¤ç¨®ç¾ææ¹æ³çä»é¢ï¼è®ä½¿ç¨èå¯ä»¥ç°¡åå­åæåé²çæè¡ãæ­¤å½å¼åº«ä¹å®¹ææ´åï¼å¯ä»¥å¿«éå»ºæ§ååï¼ä»¥é²è¡æ°ç©çç©©å¥ CE çæåè©ä¼°æ¹æ³ã

##### **Inference of Abstraction for Grounded Predicate Logic**
2502.13743v1 by Hiroyuki Kido

An important open question in AI is what simple and natural principle enables
a machine to reason logically for meaningful abstraction with grounded symbols.
This paper explores a conceptually new approach to combining probabilistic
reasoning and predicative symbolic reasoning over data. We return to the era of
reasoning with a full joint distribution before the advent of Bayesian
networks. We then discuss that a full joint distribution over models of
exponential size in propositional logic and of infinite size in predicate logic
should be simply derived from a full joint distribution over data of linear
size. We show that the same process is not only enough to generalise the
logical consequence relation of predicate logic but also to provide a new
perspective to rethink well-known limitations such as the undecidability of
predicate logic, the symbol grounding problem and the principle of explosion.
The reproducibility of this theoretical work is fully demonstrated by the
included proofs.

æè¦ï¼å¨äººå·¥æºæ§ä¸­ï¼ä¸åéè¦çéæ¾æ§åé¡æ¯ï¼ä»éº¼ç°¡å®ä¸èªç¶çååè½è®æ©å¨ä»¥æ¥å°çç¬¦èé²è¡ææç¾©çæ½è±¡éè¼¯æ¨çã
æ¬ææ¢è¨äºä¸ç¨®æ¦å¿µä¸æ°çæ¹æ³ï¼ç¨æ¼çµåæ©çæ¨çåè³æä¸çè¿°è©ç¬¦èæ¨çãæååå°è²æ°ç¶²è·¯åºç¾ä¹åçï¼ä½¿ç¨å®æ´è¯ååéé²è¡æ¨ççæä»£ãæ¥èæåè¨è«ï¼å½é¡éè¼¯ä¸­ææ¸å¤§å°çæ¨¡ååè¿°è©éè¼¯ä¸­ç¡éå¤§å°çæ¨¡åçå®æ´è¯ååéï¼æè©²å¯ä»¥ç°¡å®å°å¾ç·æ§å¤§å°çè³æå®æ´è¯ååéä¸­å°åºãæåå±ç¤ºç¸åçç¨åºä¸åè¶³ä»¥æ¦æ¬è¿°è©éè¼¯çéè¼¯å¾æéä¿ï¼ä¹è½æä¾ä¸åæ°çè§é»ä¾éæ°æèç¾æå¨ç¥çéå¶ï¼ä¾å¦è¿°è©éè¼¯çä¸å¯å¤å®æ§ãç¬¦èæ¥å°åé¡åçç¸åçã
åå«çè­æååå±ç¤ºäºéé çè«å·¥ä½çå¯è¤è£½æ§ã

##### **Enhancing Input-Label Mapping in In-Context Learning with Contrastive Decoding**
2502.13738v1 by Keqin Peng, Liang Ding, Yuanxin Ouyang, Meng Fang, Yancheng Yuan, Dacheng Tao

Large language models (LLMs) excel at a range of tasks through in-context
learning (ICL), where only a few task examples guide their predictions.
However, prior research highlights that LLMs often overlook input-label mapping
information in ICL, relying more on their pre-trained knowledge. To address
this issue, we introduce In-Context Contrastive Decoding (ICCD), a novel method
that emphasizes input-label mapping by contrasting the output distributions
between positive and negative in-context examples. Experiments on 7 natural
language understanding (NLU) tasks show that our ICCD method brings consistent
and significant improvement (up to +2.1 improvement on average) upon 6
different scales of LLMs without requiring additional training. Our approach is
versatile, enhancing performance with various demonstration selection methods,
demonstrating its broad applicability and effectiveness. The code and scripts
will be publicly released.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ééæå¢å­¸ç¿ (ICL) æé·æ¼åç¨®ä»»åï¼å¶ä¸­åæå°æ¸ä»»åç¯ä¾å¼å°å¶é æ¸¬ã
ç¶èï¼ååçç ç©¶å¼·èª¿ï¼LLM å¨ ICL ä¸­ç¶å¸¸å¿½ç¥è¼¸å¥æ¨ç±¤å°æè³è¨ï¼èæ´å¤ä¾è³´å¶é åè¨ç·´çç¥è­ã
çºäºè§£æ±ºæ­¤åé¡ï¼æåå¼é²æå¢å°æ¯è§£ç¢¼ (ICCD) éä¸ç¨®åµæ°æ¹æ³ï¼ééå°æ¯æ­£è² æå¢ç¯ä¾ä¹éçè¼¸åºåå¸ï¼å¼·èª¿è¼¸å¥æ¨ç±¤å°æã
å¨ 7 é èªç¶èªè¨çè§£ (NLU) ä»»åä¸çå¯¦é©é¡¯ç¤ºï¼æåç ICCD æ¹æ³å¨ 6 ç¨®ä¸åè¦æ¨¡ç LLM ä¸å¸¶ä¾ä¸è´ä¸é¡¯èçæ¹åï¼å¹³åæ¹åå¹åº¦é«é +2.1ï¼ï¼èç¡éé¡å¤è¨ç·´ã
æåçåæ³å¾éæ´»ï¼ééåç¨®ç¤ºç¯é¸ææ¹æ³æåæè½ï¼å±ç¾å¶å»£æ³çé©ç¨æ§åæææ§ã
ç¨å¼ç¢¼åè³æ¬å°å¬ééåºã

##### **Robust Counterfactual Inference in Markov Decision Processes**
2502.13731v1 by Jessica Lally, Milad Kazemi, Nicola Paoletti

This paper addresses a key limitation in existing counterfactual inference
methods for Markov Decision Processes (MDPs). Current approaches assume a
specific causal model to make counterfactuals identifiable. However, there are
usually many causal models that align with the observational and interventional
distributions of an MDP, each yielding different counterfactual distributions,
so fixing a particular causal model limits the validity (and usefulness) of
counterfactual inference. We propose a novel non-parametric approach that
computes tight bounds on counterfactual transition probabilities across all
compatible causal models. Unlike previous methods that require solving
prohibitively large optimisation problems (with variables that grow
exponentially in the size of the MDP), our approach provides closed-form
expressions for these bounds, making computation highly efficient and scalable
for non-trivial MDPs. Once such an interval counterfactual MDP is constructed,
our method identifies robust counterfactual policies that optimise the
worst-case reward w.r.t. the uncertain interval MDP probabilities. We evaluate
our method on various case studies, demonstrating improved robustness over
existing methods.

æè¦ï¼æ¬ææ¢è¨äºé¦¬å¯å¤«æ±ºç­éç¨ (MDP) ä¸­ç¾æåäºå¯¦æ¨è«æ¹æ³çä¸åééµéå¶ãç®åçæ¹æ³åè¨­ä¸åç¹å®çå ææ¨¡åï¼ä»¥ä½¿åäºå¯¦å¯è­å¥ãç¶èï¼éå¸¸æè¨±å¤å ææ¨¡åè MDP çè§å¯åä»å¥åä½ä¸è´ï¼æ¯åæ¨¡åç¢çä¸åçåäºå¯¦åä½ï¼å æ­¤åºå®ä¸åç¹å®çå ææ¨¡åæéå¶åäºå¯¦æ¨è«çæææ§ï¼åå¯¦ç¨æ§ï¼ãæåæåºäºä¸ç¨®æ°ç©çéåæ¸æ¹æ³ï¼å®è¨ç®ææç¸å®¹å ææ¨¡åä¸­åäºå¯¦è½ç§»æ©ççç·å¯çéãèéè¦è§£æ±ºé£ä»¥ç¦æ­¢çæä½³ååé¡ï¼å¶ä¸­è®æ¸é¨è MDP çå¤§å°åææ¸æé·ï¼çååæ¹æ³ä¸åï¼æåçåæ³æä¾äºéäºçéçéåå½¢å¼è¡¨éå¼ï¼ä½¿è¨ç®å°æ¼éå¹³å¡ç MDP å·æé«åº¦æçåå¯æ´åæ§ãä¸æ¦æ§é äºéæ¨£çåéåäºå¯¦ MDPï¼æåçåæ³ä¾¿æè­å¥åºç©©å¥çåäºå¯¦ç­ç¥ï¼ä»¥æä½³åç¸å°æ¼ä¸ç¢ºå®çåé MDP æ©ççæå·®çåµãæåå¨åç¨®æ¡ä¾ç ç©¶ä¸­è©ä¼°æåçåæ³ï¼å±ç¤ºåºæ¯ç¾ææ¹æ³æ´å¥½çç©©å¥æ§ã

##### **Secure Federated Data Distillation**
2502.13728v1 by Marco Arazzi, Mert Cihangiroglu, Serena Nicolazzo, Antonino Nocera

Dataset Distillation (DD) is a powerful technique for reducing large datasets
into compact, representative synthetic datasets, accelerating Machine Learning
training. However, traditional DD methods operate in a centralized manner,
which poses significant privacy threats and reduces its applicability. To
mitigate these risks, we propose a Secure Federated Data Distillation framework
(SFDD) to decentralize the distillation process while preserving privacy.Unlike
existing Federated Distillation techniques that focus on training global models
with distilled knowledge, our approach aims to produce a distilled dataset
without exposing local contributions. We leverage the gradient-matching-based
distillation method, adapting it for a distributed setting where clients
contribute to the distillation process without sharing raw data. The central
aggregator iteratively refines a synthetic dataset by integrating client-side
updates while ensuring data confidentiality. To make our approach resilient to
inference attacks perpetrated by the server that could exploit gradient updates
to reconstruct private data, we create an optimized Local Differential Privacy
approach, called LDPO-RLD (Label Differential Privacy Obfuscation via
Randomized Linear Dispersion). Furthermore, we assess the framework's
resilience against malicious clients executing backdoor attacks and demonstrate
robustness under the assumption of a sufficient number of participating
clients. Our experimental results demonstrate the effectiveness of SFDD and
that the proposed defense concretely mitigates the identified vulnerabilities,
with minimal impact on the performance of the distilled dataset. By addressing
the interplay between privacy and federation in dataset distillation, this work
advances the field of privacy-preserving Machine Learning making our SFDD
framework a viable solution for sensitive data-sharing applications.

æè¦ï¼è³æéèå (DD) æ¯ä¸ç¨®å¼·å¤§çæè¡ï¼ç¨æ¼å°å¤§åè³æéç¸®æ¸æç²¾ç°¡ãå·ä»£è¡¨æ§çåæè³æéï¼å éæ©å¨å­¸ç¿è¨ç·´ãç¶èï¼å³çµ±ç DD æ¹æ³ä»¥éä¸­å¼æ¹å¼éä½ï¼éæé æéå¤§çé±ç§å¨èï¼ä¸¦éä½å¶é©ç¨æ§ãçºäºéä½éäºé¢¨éªï¼æåæåºä¸åå®å¨çè¯é¦è³æèåæ¶æ§ (SFDD)ï¼ä»¥åæ£èåç¨åºï¼åæä¿è­·é±ç§ãèç¾æçè¯é¦èåæè¡ä¸åï¼éäºæè¡å°æ³¨æ¼ä½¿ç¨èåç¥è­è¨ç·´å¨çæ¨¡åï¼æåçåæ³æ¨å¨ç¢çèåè³æéï¼èä¸ææ´é²æ¬å°è²¢ç»ãæåå©ç¨åºæ¼æ¢¯åº¦å¹éçèåæ¹æ³ï¼å°å¶èª¿æ´çºåæ£å¼è¨­å®ï¼å¶ä¸­å®¢æ¶ç«¯æè²¢ç»èåç¨åºï¼èä¸æåäº«åå§è³æãä¸­å¤®èåå¨ééæ´åå®¢æ¶ç«¯æ´æ°ï¼åè¦æ¹ååæè³æéï¼åæç¢ºä¿è³ææ©å¯æ§ãçºäºè®æåçåæ³è½æµæä¼ºæå¨å·è¡çæ¨è«æ»æï¼ä¼ºæå¨å¯è½å©ç¨æ¢¯åº¦æ´æ°éå»ºç§äººè³æï¼æåå»ºç«äºä¸åæä½³åçå±é¨å·®åé±ç§åæ³ï¼ç¨±çº LDPO-RLDï¼æ¨ç±¤å·®åé±ç§æ··æ·ï¼ééé¨æ©ç·æ§åæ£ï¼ãæ­¤å¤ï¼æåè©ä¼°æ¶æ§å°å·è¡å¾éæ»æçæ¡æå®¢æ¶ç«¯çå¾©ååï¼ä¸¦å¨åè¨­æè¶³å¤ åèå®¢æ¶ç«¯çææ³ä¸è­æå¶ç©©å¥æ§ãæåçå¯¦é©çµæè­æäº SFDD çæææ§ï¼èä¸ææåºçé²ç¦¦æªæ½å·é«æ¸è¼äºå·²è­å¥çæ¼æ´ï¼å°èåè³æéçæè½å½±é¿æå°ãééè§£æ±ºè³æéèåä¸­é±ç§åè¯é¦ä¹éçäº¤äºä½ç¨ï¼éé å·¥ä½æ¨åäºé±ç§ä¿è­·æ©å¨å­¸ç¿çé åï¼ä½¿æåç SFDD æ¶æ§æçºææè³æåäº«æç¨ç¨å¼çå¯è¡è§£æ±ºæ¹æ¡ã

##### **Adapting Large Language Models for Time Series Modeling via a Novel Parameter-efficient Adaptation Method**
2502.13725v1 by Juyuan Zhang, Wei Zhu, Jiechao Gao

Time series modeling holds significant importance in many real-world
applications and has been extensively studied. While pre-trained foundation
models have made impressive strides in the fields of natural language
processing (NLP) and computer vision (CV), their development in time series
domains has been constrained by data sparsity. A series of recent studies have
demonstrated that large language models (LLMs) possess robust pattern
recognition and reasoning abilities over complex sequences of tokens. However,
the current literature have yet striked a high-quality balance between (a)
effectively aligning the time series and natural language modalities, and (b)
keeping the inference efficiency. To address the above issues, we now propose
the Time-LlaMA framework. Time-LlaMA first converts the time series input into
token embeddings through a linear tokenization mechanism. Second, the time
series token embeddings are aligned with the text prompts. Third, to further
adapt the LLM backbone for time series modeling, we have developed a dynamic
low-rank adaptation technique (D-LoRA). D-LoRA dynamically chooses the most
suitable LoRA modules at each layer of the Transformer backbone for each time
series input, enhancing the model's predictive capabilities. Our experimental
results on an extensive collection of challenging real-world time series tasks
confirm that our proposed method achieves the state-of-the-art (SOTA)
performance.

æè¦ï¼æåºå»ºæ¨¡å¨è¨±å¤å¯¦éæç¨ä¸­å·æéè¦æç¾©ï¼ä¸¦ä¸å·²è¢«å»£æ³ç ç©¶ãéç¶é åè¨ç·´å¥½çåºç¤æ¨¡åå¨èªç¶èªè¨èç (NLP) åé»è¦è¦è¦º (CV) é ååå¾ä»¤äººå°è±¡æ·±å»çé²å±ï¼ä½å®åå¨æåºé åçç¼å±åå°è³æç¨çæ§çéå¶ãä¸ç³»åæè¿çç ç©¶è¡¨æï¼å¤§åèªè¨æ¨¡å (LLM) å°æ¼è¤éçä»£å¹£åºåå·åå¼·å¤§çæ¨¡å¼è¾¨è­åæ¨çè½åãç¶èï¼ç®åçæç»å°æªå¨ (a) ææå°é½æåºåèªç¶èªè¨æ¨¡æï¼ä»¥å (b) ä¿ææ¨çæçä¹éåå¾é«åè³ªçå¹³è¡¡ãçºäºè§£æ±ºä¸è¿°åé¡ï¼æåç¾å¨æåº Time-LlaMA æ¡æ¶ãTime-LlaMA é¦åééç·æ§æ¨è¨åæ©å¶å°æåºè¼¸å¥è½æçºä»£å¹£åµå¥ãå¶æ¬¡ï¼æåºä»£å¹£åµå¥èæå­æç¤ºå°é½ãç¬¬ä¸ï¼çºäºé²ä¸æ­¥èª¿æ´ LLM ä¸»å¹¹ä»¥é²è¡æåºå»ºæ¨¡ï¼æåéç¼äºä¸ç¨®åæä½ç§©é©ææè¡ (D-LoRA)ãD-LoRA æåæé¸æ Transformer ä¸»å¹¹ä¸­æ¯ä¸å±¤æåé©ç LoRA æ¨¡çµï¼ä»¥å¢å¼·æ¨¡åçé æ¸¬è½åãæåå¨å¤§éå·æææ°æ§ççå¯¦ä¸çæåºä»»åéåä¸­é²è¡çå¯¦é©çµæè­å¯¦ï¼æåæåºçæ¹æ³éå°äºæåé² (SOTA) çæè½ã

##### **Direct Value Optimization: Improving Chain-of-Thought Reasoning in LLMs with Refined Values**
2502.13723v1 by Hongbo Zhang, Han Cui, Guangsheng Bao, Linyi Yang, Jun Wang, Yue Zhang

We introduce Direct Value Optimization (DVO), an innovative reinforcement
learning framework for enhancing large language models in complex reasoning
tasks. Unlike traditional methods relying on preference labels, DVO utilizes
value signals at individual reasoning steps, optimizing models via a mean
squared error loss. The key benefit of DVO lies in its fine-grained
supervision, circumventing the need for labor-intensive human annotations.
Target values within the DVO are estimated using either Monte Carlo Tree Search
or an outcome value model. Our empirical analysis on both mathematical and
commonsense reasoning tasks shows that DVO consistently outperforms existing
offline preference optimization techniques, even with fewer training steps.
These findings underscore the importance of value signals in advancing
reasoning capabilities and highlight DVO as a superior methodology under
scenarios lacking explicit human preference information.

æè¦ï¼æåå¼é²ç´æ¥å¹å¼æä½³å (DVO)ï¼ä¸ç¨®åµæ°çå¼·åå­¸ç¿æ¶æ§ï¼ç¨æ¼å¢å¼·å¤§åèªè¨æ¨¡åå¨è¤éæ¨çä»»åä¸­çè½åãèä¾è³´åå¥½æ¨ç±¤çå³çµ±æ¹æ³ä¸åï¼DVO å©ç¨åå¥æ¨çæ­¥é©ä¸­çå¹å¼ä¿¡èï¼ééåæ¹èª¤å·®æå¤±ä¾æä½³åæ¨¡åãDVO çä¸»è¦åªé»å¨æ¼å¶ç´°ç·»çç£ç£ï¼é¿åäºéè¦å¤§éäººåè¨»è§£ãDVO ä¸­çç®æ¨å¼æ¯ä½¿ç¨èå°å¡ç¾æ¨¹çæå°æçµæå¼æ¨¡åä¾ä¼°è¨çãæåå¨æ¸å­¸åå¸¸è­æ¨çä»»åä¸çå¯¦è­åæé¡¯ç¤ºï¼DVO å§çµåªæ¼ç¾æçé¢ç·åå¥½æä½³åæè¡ï¼å³ä½¿è¨ç·´æ­¥é©è¼å°ãéäºç¼ç¾å¼·èª¿äºå¹å¼ä¿¡èå¨æ¨é²æ¨çè½åæ¹é¢çéè¦æ§ï¼ä¸¦å¼·èª¿ DVO å¨ç¼ºä¹æç¢ºäººé¡åå¥½è³è¨çææ³ä¸æ¯ä¸ç¨®åªè¶çæ¹æ³ã

##### **Learning Novel Transformer Architecture for Time-series Forecasting**
2502.13721v1 by Juyuan Zhang, Wei Zhu, Jiechao Gao

Despite the success of Transformer-based models in the time-series prediction
(TSP) tasks, the existing Transformer architecture still face limitations and
the literature lacks comprehensive explorations into alternative architectures.
To address these challenges, we propose AutoFormer-TS, a novel framework that
leverages a comprehensive search space for Transformer architectures tailored
to TSP tasks. Our framework introduces a differentiable neural architecture
search (DNAS) method, AB-DARTS, which improves upon existing DNAS approaches by
enhancing the identification of optimal operations within the architecture.
AutoFormer-TS systematically explores alternative attention mechanisms,
activation functions, and encoding operations, moving beyond the traditional
Transformer design. Extensive experiments demonstrate that AutoFormer-TS
consistently outperforms state-of-the-art baselines across various TSP
benchmarks, achieving superior forecasting accuracy while maintaining
reasonable training efficiency.

æè¦ï¼åç®¡ Transformer æ¨¡åå¨æåºé æ¸¬ (TSP) ä»»åä¸­åå¾æåï¼ä½ç¾æç Transformer æ¶æ§ä»é¢è¨éå¶ï¼ä¸æç»ä¸­ç¼ºä¹å°æ¿ä»£æ¶æ§çå¨é¢æ¢è¨ãçºäºæå°éäºææ°ï¼æåæåº AutoFormer-TSï¼ä¸åæ°ç©çæ¡æ¶ï¼å®å©ç¨ä¸åå¨é¢çæå°ç©ºéï¼å°ééå° TSP ä»»åè¨­è¨ Transformer æ¶æ§ãæåçæ¡æ¶å¼å¥äºä¸ç¨®å¯å¾®åç¥ç¶æ¶æ§æå° (DNAS) æ¹æ³ AB-DARTSï¼å®ééå¢å¼·å°æ¶æ§ä¸­æä½³éç®çè­å¥ä¾æ¹é²ç¾æç DNAS æ¹æ³ãAutoFormer-TS ç³»çµ±æ§å°æ¢è¨äºæ¿ä»£æ³¨ææ©å¶ãæ´»åå½æ¸åç·¨ç¢¼éç®ï¼è¶è¶äºå³çµ±ç Transformer è¨­è¨ãå»£æ³çå¯¦é©è­æï¼AutoFormer-TS å¨åç¨® TSP åºæºæ¸¬è©¦ä¸­å§çµåªæ¼æåé²çåºæºï¼å¨ç¶­æåççè¨ç·´æççåæï¼éå°äºåªç°çé æ¸¬æºç¢ºåº¦ã

##### **TrustRAG: An Information Assistant with Retrieval Augmented Generation**
2502.13719v1 by Yixing Fan, Qiang Yan, Wenshan Wang, Jiafeng Guo, Ruqing Zhang, Xueqi Cheng

\Ac{RAG} has emerged as a crucial technique for enhancing large models with
real-time and domain-specific knowledge. While numerous improvements and
open-source tools have been proposed to refine the \ac{RAG} framework for
accuracy, relatively little attention has been given to improving the
trustworthiness of generated results. To address this gap, we introduce
TrustRAG, a novel framework that enhances \ac{RAG} from three perspectives:
indexing, retrieval, and generation. Specifically, in the indexing stage, we
propose a semantic-enhanced chunking strategy that incorporates hierarchical
indexing to supplement each chunk with contextual information, ensuring
semantic completeness. In the retrieval stage, we introduce a utility-based
filtering mechanism to identify high-quality information, supporting answer
generation while reducing input length. In the generation stage, we propose
fine-grained citation enhancement, which detects opinion-bearing sentences in
responses and infers citation relationships at the sentence-level, thereby
improving citation accuracy. We open-source the TrustRAG framework and provide
a demonstration studio designed for excerpt-based question answering tasks
\footnote{https://huggingface.co/spaces/golaxy/TrustRAG}. Based on these, we
aim to help researchers: 1) systematically enhancing the trustworthiness of
\ac{RAG} systems and (2) developing their own \ac{RAG} systems with more
reliable outputs.

æè¦ï¼\Ac{RAG} å·²æä¸ºä¸ç§è³å³éè¦çææ¯ï¼ç¨äºå¢å¼ºå¤§åæ¨¡åï¼ä½¿å¶å·æå®æ¶ä¸ç¹å®äºé¢åçç¥è¯ãè½ç¶å·²ç»æåºäºè®¸å¤æ¹è¿åå¼æºå·¥å·æ¥æ¹è¿ \ac{RAG} æ¡æ¶çåç¡®æ§ï¼ä½å¯¹äºæé«çæç»æçå¯ä¿¡åº¦å´é²æå³æ³¨ãä¸ºäºè§£å³è¿ä¸å·®è·ï¼æä»¬å¼å¥äº TrustRAGï¼è¿æ¯ä¸ä¸ªæ°é¢çæ¡æ¶ï¼å®ä»ä¸ä¸ªè§åº¦å¢å¼ºäº \ac{RAG}ï¼ç´¢å¼ãæ£ç´¢åçæãå·ä½æ¥è¯´ï¼å¨ç´¢å¼é¶æ®µï¼æä»¬æåºäºä¸ç§è¯­ä¹å¢å¼ºååç­ç¥ï¼è¯¥ç­ç¥ç»åäºåå±ç´¢å¼æ¥ä¸ºæ¯ä¸ªåè¡¥åä¸ä¸æä¿¡æ¯ï¼ä»èç¡®ä¿è¯­ä¹å®æ´æ§ãå¨æ£ç´¢é¶æ®µï¼æä»¬å¼å¥äºä¸ç§åºäºæç¨çè¿æ»¤æºå¶æ¥è¯å«é«è´¨éä¿¡æ¯ï¼æ¯æç­æ¡çæï¼åæ¶åå°è¾å¥é¿åº¦ãå¨çæé¶æ®µï¼æä»¬æåºäºç»ç²åº¦å¼ç¨å¢å¼ºï¼å®æ£æµååºä¸­çè§ç¹å¥ï¼å¹¶å¨å¥å­çº§å«æ¨æ­å¼ç¨å³ç³»ï¼ä»èæé«å¼ç¨åç¡®æ§ãæä»¬å¼æºäº TrustRAG æ¡æ¶ï¼å¹¶æä¾äºä¸ä¸ªæ¼ç¤ºå·¥ä½å®¤ï¼ä¸ä¸ºåºäºæå½çé®é¢åç­ä»»å¡èè®¾è®¡\footnote{https://huggingface.co/spaces/golaxy/TrustRAG}ãåºäºè¿äºï¼æä»¬çç®æ æ¯å¸®å©ç ç©¶äººåï¼1) ç³»ç»å°æé« \ac{RAG} ç³»ç»çå¯ä¿¡åº¦ï¼ä»¥å (2) å¼åä»ä»¬èªå·±ç \ac{RAG} ç³»ç»ï¼å¹¶è·å¾æ´å¯é çè¾åºã

##### **Multi-Scale and Multi-Objective Optimization for Cross-Lingual Aspect-Based Sentiment Analysis**
2502.13718v1 by Chengyan Wu, Bolei Ma, Ningyuan Deng, Yanqing He, Yun Xue

Aspect-based sentiment analysis (ABSA) is a sequence labeling task that has
garnered growing research interest in multilingual contexts. However, recent
studies lack more robust feature alignment and finer aspect-level alignment. In
this paper, we propose a novel framework, Multi-Scale and Multi-Objective
optimization (MSMO) for cross-lingual ABSA. During multi-scale alignment, we
achieve cross-lingual sentence-level and aspect-level alignment, aligning
features of aspect terms in different contextual environments. Specifically, we
introduce code-switched bilingual sentences into the language discriminator and
consistency training modules to enhance the model's robustness. During
multi-objective optimization, we design two optimization objectives: supervised
training and consistency training, aiming to enhance cross-lingual semantic
alignment. To further improve model performance, we incorporate distilled
knowledge of the target language into the model. Results show that MSMO
significantly enhances cross-lingual ABSA by achieving state-of-the-art
performance across multiple languages and models.

æè¦ï¼é¢åæ¹é¢çè§ç¹åæ (ABSA) æ¯ä¸é åºåæ¨ç±¤ä»»åï¼å¨å¤èªè¨ç°å¢ä¸­å¼èµ·äºè¶ä¾è¶å¤çç ç©¶èè¶£ãç¶èï¼æè¿çç ç©¶ç¼ºä¹æ´å¼·å¤§çç¹å¾µå°é½åæ´ç²¾ç´°çæ¹é¢å±¤ç´å°é½ãå¨æ¬æä¸­ï¼æåæåºäºä¸åæ°çæ¡æ¶ï¼å³å¤å°ºåº¦åå¤ç®æ¨åªå (MSMO) ç¨æ¼è·¨èªè¨ ABSAãå¨å¤å°ºåº¦å°é½æéï¼æåå¯¦ç¾äºè·¨èªè¨å¥å­å±¤ç´åæ¹é¢å±¤ç´å°é½ï¼å°é½äºä¸åä¸ä¸æç°å¢ä¸­æ¹é¢æ¢æ¬¾çç¹å¾µãå·é«ä¾èªªï¼æåå°ä»£ç¢¼è½æçéèªå¥å­å¼å¥èªè¨å¤å¥å¨åä¸è´æ§è¨ç·´æ¨¡çµä¸­ï¼ä»¥å¢å¼·æ¨¡åçå¥å£¯æ§ãå¨å¤ç®æ¨åªåæéï¼æåè¨­è¨äºå©ååªåç®æ¨ï¼ç£ç£è¨ç·´åä¸è´æ§è¨ç·´ï¼æ¨å¨å¢å¼·è·¨èªè¨èªç¾©å°é½ãçºäºé²ä¸æ­¥æé«æ¨¡åæè½ï¼æåå°ç®æ¨èªè¨çè¸é¤¾ç¥è­ç´å¥æ¨¡åä¸­ãçµæè¡¨æï¼MSMO ééå¨å¤ç¨®èªè¨åæ¨¡åä¸­å¯¦ç¾æåé²çæè½ï¼é¡¯èå¢å¼·äºè·¨èªè¨ ABSAã

##### **Causes and Strategies in Multiagent Systems**
2502.13701v1 by Sylvia S. Kerkhove, Natasha Alechina, Mehdi Dastani

Causality plays an important role in daily processes, human reasoning, and
artificial intelligence. There has however not been much research on causality
in multi-agent strategic settings. In this work, we introduce a systematic way
to build a multi-agent system model, represented as a concurrent game
structure, for a given structural causal model. In the obtained so-called
causal concurrent game structure, transitions correspond to interventions on
agent variables of the given causal model. The Halpern and Pearl framework of
causality is used to determine the effects of a certain value for an agent
variable on other variables. The causal concurrent game structure allows us to
analyse and reason about causal effects of agents' strategic decisions. We
formally investigate the relation between causal concurrent game structures and
the original structural causal models.

æè¦ï¼å æéä¿å¨æ¥å¸¸æµç¨ãäººé¡æ¨çåäººå·¥æºæ§ä¸­æ®æ¼èéè¦çè§è²ãç¶èï¼å°æ¼å¤éä»£çç­ç¥è¨­å®ä¸­çå æéä¿ï¼ç®åçç ç©¶ä¸¦ä¸å¤ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºä¸åç³»çµ±æ§çæ¹æ³ï¼ç¨æ¼å»ºæ§ä¸åå¤éä»£çç³»çµ±æ¨¡åï¼è¡¨ç¤ºçºä¸åä¸¦ç¼éæ²çµæ§ï¼ç¨æ¼çµ¦å®ççµæ§å ææ¨¡åãå¨æå¾çæè¬å æä¸¦ç¼éæ²çµæ§ä¸­ï¼è½æå°ææ¼çµ¦å®å ææ¨¡åä¸­ä»£çè®æ¸çä»å¥ãHalpern å Pearl çå æéä¿æ¶æ§ç¨æ¼ç¢ºå®ä»£çè®æ¸å°å¶ä»è®æ¸çç¹å®å¼çå½±é¿ãå æä¸¦ç¼éæ²çµæ§åè¨±æååæåæ¨çä»£çç­ç¥æ±ºç­çå æéä¿ãæåæ­£å¼æ¢è¨å æä¸¦ç¼éæ²çµæ§èåå§çµæ§å ææ¨¡åä¹éçéä¿ã

##### **Is This Collection Worth My LLM's Time? Automatically Measuring Information Potential in Text Corpora**
2502.13691v1 by Tristan Karch, Luca Engel, Philippe Schwaller, FrÃ©dÃ©ric Kaplan

As large language models (LLMs) converge towards similar capabilities, the
key to advancing their performance lies in identifying and incorporating
valuable new information sources. However, evaluating which text collections
are worth the substantial investment required for digitization, preprocessing,
and integration into LLM systems remains a significant challenge. We present a
novel approach to this challenge: an automated pipeline that evaluates the
potential information gain from text collections without requiring model
training or fine-tuning. Our method generates multiple choice questions (MCQs)
from texts and measures an LLM's performance both with and without access to
the source material. The performance gap between these conditions serves as a
proxy for the collection's information potential. We validate our approach
using three strategically selected datasets: EPFL PhD manuscripts (likely
containing novel specialized knowledge), Wikipedia articles (presumably part of
training data), and a synthetic baseline dataset. Our results demonstrate that
this method effectively identifies collections containing valuable novel
information, providing a practical tool for prioritizing data acquisition and
integration efforts.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) æèé¡ä¼¼çè½åæ¶æï¼æåå¶æè½çééµå¨æ¼è­å¥åç´å¥æå¹å¼çæ°è³è¨ä¾æºãç¶èï¼è©ä¼°åªäºæå­éåå¼å¾æå¥æ¸ä½åãåèçåæ´åå° LLM ç³»çµ±ä¸­æéçé¾å¤§æè³ï¼ä»ç¶æ¯ä¸é éå¤§çææ°ãæåæåºäºä¸ç¨®è§£æ±ºæ­¤ææ°çæ°ç©æ¹æ³ï¼ä¸åèªååç®¡éï¼å¯è©ä¼°æå­éåçæ½å¨è³è¨ç²åï¼èç¡éé²è¡æ¨¡åè¨ç·´æå¾®èª¿ãæåçåæ³æå¾æå­ä¸­ç¢çå¤é¸é¡ (MCQ)ï¼ä¸¦è¡¡é LLM å¨æåæ²æåå¾åå§è³æçææ³ä¸çè¡¨ç¾ãéäºæ¢ä»¶ä¹éçè¡¨ç¾å·®è·å¯ä½çºè©²éåè³è¨æ½åçä»£çãæåä½¿ç¨ä¸åç­ç¥æ§é¸å®çè³æéé©è­æåçåæ³ï¼EPFL åå£«è«ææç¨¿ï¼å¯è½åå«æ°çå°æ¥­ç¥è­ï¼ãç¶­åºç¾ç§æ¢ç®ï¼å¯è½æ¯è¨ç·´è³æçä¸é¨åï¼åä¸ååæåºæºè³æéãæåççµæè­æï¼æ­¤æ¹æ³ææå°æ¾åºåå«æå¹å¼æ°è³è¨çéåï¼æä¾ä¸åå¯¦ç¨çå·¥å·ä¾åªåèçè³æåå¾åæ´åå·¥ä½ã

##### **MoM: Linear Sequence Modeling with Mixture-of-Memories**
2502.13685v1 by Jusen Du, Weigao Sun, Disen Lan, Jiaxi Hu, Yu Cheng

Linear sequence modeling methods, such as linear attention, state space
modeling, and linear RNNs, offer significant efficiency improvements by
reducing the complexity of training and inference. However, these methods
typically compress the entire input sequence into a single fixed-size memory
state, which leads to suboptimal performance on recall-intensive downstream
tasks. Drawing inspiration from neuroscience, particularly the brain's ability
to maintain robust long-term memory while mitigating "memory interference", we
introduce a novel architecture called Mixture-of-Memories (MoM). MoM utilizes
multiple independent memory states, with a router network directing input
tokens to specific memory states. This approach greatly enhances the overall
memory capacity while minimizing memory interference. As a result, MoM performs
exceptionally well on recall-intensive tasks, surpassing existing linear
sequence modeling techniques. Despite incorporating multiple memory states, the
computation of each memory state remains linear in complexity, allowing MoM to
retain the linear-complexity advantage during training, while
constant-complexity during inference. Our experimental results show that MoM
significantly outperforms current linear sequence models on downstream language
tasks, particularly recall-intensive tasks, and even achieves performance
comparable to Transformer models. The code is released at
https://github.com/OpenSparseLLMs/MoM and is also released as a part of
https://github.com/OpenSparseLLMs/Linear-MoE.

æè¦ï¼ç·æ§åºåå»ºæ¨¡æ¹æ³ï¼ä¾å¦ç·æ§æ³¨æåãçæç©ºéå»ºæ¨¡åç·æ§ RNNï¼éééä½è¨ç·´åæ¨è«çè¤éæ§ï¼æä¾äºé¡¯èçæçæ¹é²ãç¶èï¼éäºæ¹æ³éå¸¸æå°æ´åè¼¸å¥åºåå£ç¸®æä¸åå®ä¸çåºå®å¤§å°è¨æ¶é«çæï¼éæå°è´å¬åå¯éçä¸æ¸¸ä»»åçæ¬¡ä½³æè½ãå¾ç¥ç¶ç§å­¸ä¸­æ±²åéæï¼ç¹å¥æ¯å¤§è¦å¨æ¸è¼ãè¨æ¶å¹²æ¾ãçåæç¶­æç©©å¥é·æè¨æ¶çè½åï¼æåå¼å¥äºä¸ç¨®åçºè¨æ¶æ··å (MoM) çæ°æ¶æ§ãMoM å©ç¨å¤åç¨ç«çè¨æ¶é«çæï¼ä¸¦ééè·¯ç±å¨ç¶²è·¯å°è¼¸å¥ä»£ç¢¼å°åç¹å®çè¨æ¶é«çæãéç¨®æ¹æ³å¨æå¤§ç¨åº¦æ¸å°è¨æ¶é«å¹²æ¾çåæï¼å¤§å¹æåäºæ´é«è¨æ¶é«å®¹éãå æ­¤ï¼MoM å¨å¬åå¯éä»»åä¸çè¡¨ç¾æ¥µä½³ï¼è¶è¶äºç¾æçç·æ§åºåå»ºæ¨¡æè¡ãåç®¡æ´åäºå¤åè¨æ¶é«çæï¼ä½æ¯åè¨æ¶é«çæçéç®å¨è¤éåº¦ä¸ä»ç¶æ¯ç·æ§çï¼éè® MoM å¨è¨ç·´æéè½ä¿æç·æ§è¤éåº¦çåªå¢ï¼èå¨æ¨è«æéåç¶­ææå®è¤éåº¦ãæåçå¯¦é©çµæé¡¯ç¤ºï¼MoM å¨ä¸æ¸¸èªè¨ä»»åä¸æé¡¯åªæ¼ç®åçç·æ§åºåæ¨¡åï¼ç¹å¥æ¯å¬åå¯éä»»åï¼çè³éå°äºè Transformer æ¨¡åç¸ç¶çæè½ãç¨å¼ç¢¼å·²ç¼å¸æ¼ https://github.com/OpenSparseLLMs/MoMï¼ä¸¦ä½çº https://github.com/OpenSparseLLMs/Linear-MoE çä¸é¨åç¼å¸ã

##### **An LLM-based Agent for Reliable Docker Environment Configuration**
2502.13681v1 by Ruida Hu, Chao Peng, Xinchen Wang, Cuiyun Gao

Environment configuration is a critical yet time-consuming step in software
development, especially when dealing with unfamiliar code repositories. While
Large Language Models (LLMs) demonstrate the potential to accomplish software
engineering tasks, existing methods for environment configuration often rely on
manual efforts or fragile scripts, leading to inefficiencies and unreliable
outcomes. We introduce Repo2Run, the first LLM-based agent designed to fully
automate environment configuration and generate executable Dockerfiles for
arbitrary Python repositories. We address two major challenges: (1) enabling
the LLM agent to configure environments within isolated Docker containers, and
(2) ensuring the successful configuration process is recorded and accurately
transferred to a Dockerfile without error. To achieve this, we propose atomic
configuration synthesis, featuring a dual-environment architecture (internal
and external environment) with a rollback mechanism to prevent environment
"pollution" from failed commands, guaranteeing atomic execution (execute fully
or not at all) and a Dockerfile generator to transfer successful configuration
steps into runnable Dockerfiles. We evaluate Repo2Run~on our proposed benchmark
of 420 recent Python repositories with unit tests, where it achieves an 86.0%
success rate, outperforming the best baseline by 63.9%.

æè¦ï¼ç°å¢è¨­å®æ¯è»é«éç¼ä¸­ä¸åééµä½èæçæ­¥é©ï¼ç¹å¥æ¯å¨èçä¸çæçç¨å¼ç¢¼å²å­åº«æãéç¶å¤§åèªè¨æ¨¡å (LLM) å±ç¤ºäºå®æè»é«å·¥ç¨ä»»åçæ½åï¼ç¾æçç°å¢è¨­å®æ¹æ³éå¸¸ä¾è³´æåå·¥ä½æèå¼±çè³æ¬ï¼å°è´æçä½ä¸åçµæä¸å¯é ãæåä»ç´¹äº Repo2Runï¼éæ¯ç¬¬ä¸ååºæ¼ LLM çä»£çï¼æ¨å¨å®å¨èªååç°å¢è¨­å®ï¼ä¸¦çºä»»æ Python å²å­åº«ç¢çå¯å·è¡ç Dockerfileãæåè§£æ±ºäºå©åä¸»è¦ææ°ï¼(1) ä½¿ LLM ä»£çè½å¤ å¨éé¢ç Docker å®¹å¨ä¸­è¨­å®ç°å¢ï¼ä»¥å (2) ç¢ºä¿æåçè¨­å®éç¨è¢«è¨éä¸¦æºç¢ºå³è¼¸å° Dockerfile ä¸­èä¸æåºé¯ãçºæ­¤ï¼æåæåºäºåå­éç½®åæï¼å®å·æéç°å¢æ¶æ§ï¼å§é¨åå¤é¨ç°å¢ï¼ååæ»¾æ©å¶ï¼ä»¥é²æ­¢ç°å¢è¢«å¤±æçå½ä»¤ãæ±¡æãï¼ä¿è­åå­å·è¡ï¼å®å¨å·è¡æå®å¨ä¸å·è¡ï¼åä¸å Dockerfile ç¢çå¨ï¼å°æåçéç½®æ­¥é©å³è¼¸å°å¯å·è¡ç Dockerfile ä¸­ãæåå¨æåæåºçåºæºæ¸¬è©¦ä¸­è©ä¼°äº Repo2Runï¼å¶ä¸­åå« 420 åæè¿ç Python å²å­åº«åå®åæ¸¬è©¦ï¼å®éå°äº 86.0% çæåçï¼æ¯æä½³åºæºé«åº 63.9%ã

##### **SCOPE: A Self-supervised Framework for Improving Faithfulness in Conditional Text Generation**
2502.13674v1 by Song Duong, Florian Le Bronnec, Alexandre Allauzen, Vincent Guigue, Alberto Lumbreras, Laure Soulier, Patrick Gallinari

Large Language Models (LLMs), when used for conditional text generation,
often produce hallucinations, i.e., information that is unfaithful or not
grounded in the input context. This issue arises in typical conditional text
generation tasks, such as text summarization and data-to-text generation, where
the goal is to produce fluent text based on contextual input. When fine-tuned
on specific domains, LLMs struggle to provide faithful answers to a given
context, often adding information or generating errors. One underlying cause of
this issue is that LLMs rely on statistical patterns learned from their
training data. This reliance can interfere with the model's ability to stay
faithful to a provided context, leading to the generation of ungrounded
information. We build upon this observation and introduce a novel
self-supervised method for generating a training set of unfaithful samples. We
then refine the model using a training process that encourages the generation
of grounded outputs over unfaithful ones, drawing on preference-based training.
Our approach leads to significantly more grounded text generation,
outperforming existing self-supervised techniques in faithfulness, as evaluated
through automatic metrics, LLM-based assessments, and human evaluations.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨ç¨æ¼æ¢ä»¶å¼æå­ç¢çæï¼
ç¶å¸¸æç¢çå¹»è¦ºï¼å³ä¸å¿ å¯¦æä¸åºæ¼è¼¸å¥å§å®¹çè³è¨ãéååé¡åºç¾å¨å¸åçæ¢ä»¶å¼æå­ç¢çä»»åä¸­ï¼ä¾å¦æå­æè¦åè³æå°æå­çç¢çï¼å¶ä¸­ç®æ¨æ¯æ ¹æèçµ¡è¼¸å¥ç¢çæµå©çæå­ãç¶éå°ç¹å®é åé²è¡å¾®èª¿æï¼LLM é£ä»¥å°çµ¦å®çèçµ¡æä¾å¿ å¯¦çç­æ¡ï¼éå¸¸ææ°å¢è³è¨æç¢çé¯èª¤ãéååé¡çä¸åæ ¹æ¬åå æ¯ LLM ä¾è³´å¾å¶è¨ç·´è³æä¸­å­¸ç¿å°ççµ±è¨æ¨¡å¼ãéç¨®ä¾è³´æ§æå¹²æ¾æ¨¡åå¿ æ¼ææä¾èçµ¡çè½åï¼å°è´ç¢çä¸åççè³è¨ãæåå»ºç«å¨éåè§å¯ä¹ä¸ï¼ä¸¦å¼å¥ä¸ç¨®æ°ç©çèªæç£ç£æ¹æ³ä¾ç¢çä¸çµä¸å¿ å¯¦çæ¨£æ¬è¨ç·´éãç¶å¾ï¼æåä½¿ç¨è¨ç·´éç¨æ¹åæ¨¡åï¼è©²éç¨é¼åµç¢çåççè¼¸åºï¼èä¸æ¯ä¸åççè¼¸åºï¼ä¸¦å©ç¨åºæ¼åå¥½çè¨ç·´ãæåçåæ³å°è´æ´åççæå­ç¢çï¼å¨å¿ å¯¦åº¦æ¹é¢åªæ¼ç¾æçèªæç£ç£æè¡ï¼ééèªååææ¨ãåºæ¼ LLM çè©ä¼°åäººå·¥è©ä¼°é²è¡è©ä¼°ã

##### **PeerQA: A Scientific Question Answering Dataset from Peer Reviews**
2502.13668v1 by Tim BaumgÃ¤rtner, Ted Briscoe, Iryna Gurevych

We present PeerQA, a real-world, scientific, document-level Question
Answering (QA) dataset. PeerQA questions have been sourced from peer reviews,
which contain questions that reviewers raised while thoroughly examining the
scientific article. Answers have been annotated by the original authors of each
paper. The dataset contains 579 QA pairs from 208 academic articles, with a
majority from ML and NLP, as well as a subset of other scientific communities
like Geoscience and Public Health. PeerQA supports three critical tasks for
developing practical QA systems: Evidence retrieval, unanswerable question
classification, and answer generation. We provide a detailed analysis of the
collected dataset and conduct experiments establishing baseline systems for all
three tasks. Our experiments and analyses reveal the need for
decontextualization in document-level retrieval, where we find that even simple
decontextualization approaches consistently improve retrieval performance
across architectures. On answer generation, PeerQA serves as a challenging
benchmark for long-context modeling, as the papers have an average size of 12k
tokens. Our code and data is available at https://github.com/UKPLab/peerqa.

æè¦ï¼<paragraph>æåæåº PeerQAï¼ä¸åçå¯¦ä¸çãç§å­¸çãæä»¶å±¤ç´çåç­ (QA) è³æéãPeerQA åé¡ä¾èªæ¼åè¡è©å¯©ï¼å¶ä¸­åå«å¯©æ¥èå¨å¾¹åºå¯©æ¥ç§å­¸æç« ææåºçåé¡ãç­æ¡æ¯ç±æ¯ç¯è«æçåå§ä½èè¨»è§£çãæ­¤è³æéåå«ä¾èª 208 ç¯å­¸è¡æç« ç 579 å QA å°ï¼å¶ä¸­å¤§é¨åä¾èª ML å NLPï¼ä»¥åå¶ä»ç§å­¸ç¤¾ç¾¤ï¼ä¾å¦å°çç§å­¸åå¬å±è¡çï¼çå­éãPeerQA æ¯æ´éç¼å¯¦ç¨ QA ç³»çµ±çä¸é éè¦ä»»åï¼è­ææª¢ç´¢ãç¡è§£ç­åé¡åé¡åç­æ¡ç¢çãæåæä¾æ¶éå°çè³æéçè©³ç´°åæï¼ä¸¦é²è¡å¯¦é©ï¼çºææä¸é ä»»åå»ºç«åºæºç³»çµ±ãæåçå¯¦é©ååææ­ç¤ºäºå¨æä»¶å±¤ç´æª¢ç´¢ä¸­å»èçµ¡åçå¿è¦æ§ï¼æåç¼ç¾å³ä½¿æ¯ç°¡å®çå»èçµ¡åæ¹æ³ä¹è½æçºæ¹åè·¨æ¶æ§çæª¢ç´¢æè½ãå¨ç­æ¡ç¢çæ¹é¢ï¼PeerQA æ¯ä¸åç¨æ¼é·èçµ¡å»ºæ¨¡çå·ææ°æ§åºæºï¼å çºè«æçå¹³åå¤§å°çº 12k åç¬¦èãæåçç¨å¼ç¢¼åè³æå¯æ¼ https://github.com/UKPLab/peerqa åå¾ã</paragraph>

##### **Refining Sentence Embedding Model through Ranking Sentences Generation with Large Language Models**
2502.13656v1 by Liyang He, Chenglong Liu, Rui Li, Zhenya Huang, Shulan Ruan, Jun Zhou, Enhong Chen

Sentence embedding is essential for many NLP tasks, with contrastive learning
methods achieving strong performance using annotated datasets like NLI. Yet,
the reliance on manual labels limits scalability. Recent studies leverage large
language models (LLMs) to generate sentence pairs, reducing annotation
dependency. However, they overlook ranking information crucial for fine-grained
semantic distinctions. To tackle this challenge, we propose a method for
controlling the generation direction of LLMs in the latent space. Unlike
unconstrained generation, the controlled approach ensures meaningful semantic
divergence. Then, we refine exist sentence embedding model by integrating
ranking information and semantic information. Experiments on multiple
benchmarks demonstrate that our method achieves new SOTA performance with a
modest cost in ranking sentence synthesis.

æè¦ï¼å¥å­åµå¥å°æ¼è¨±å¤ NLP ä»»åä¾èªªè³ééè¦ï¼å°æ¯å­¸ç¿æ¹æ³ä½¿ç¨ NLI ç­è¨»è§£è³æéä¾éæå¼·å¤§çæè½ãç¶èï¼ä¾è³´äººå·¥æ¨ç±¤æéå¶å¯æ´åæ§ãæè¿çç ç©¶å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾ç¢çå¥å­å°ï¼æ¸å°æ¨è¨»çä¾è³´æ§ãç¶èï¼ä»åå¿½ç¥äºå°æ¼ç´°ç·»èªç¾©åå¥è³ééè¦çæåè³è¨ãçºäºæå°éåææ°ï¼æåæåºä¸åå¨æ½å¨ç©ºéä¸­æ§å¶ LLM ç¢çæ¹åçæ¹æ³ãèä¸åç´æçç¢çä¸åï¼åæ§æ¹æ³ç¢ºä¿ææç¾©çèªç¾©åæ­§ãç¶å¾ï¼æåééæ´åæåè³è¨åèªç¾©è³è¨ä¾æ¹åç¾æçå¥å­åµå¥æ¨¡åãå¨å¤ååºæºæ¸¬è©¦ä¸çå¯¦é©é¡¯ç¤ºï¼æåçæ¨¡åä»¥é©åº¦çå¥å­åææåææ¬ï¼éå°äºæ°ç SOTA æè½ã

##### **C2T: A Classifier-Based Tree Construction Method in Speculative Decoding**
2502.13652v1 by Feiye Huo, Jianchao Tan, Kefeng Zhang, Xunliang Cai, Shengli Sun

The growing scale of Large Language Models (LLMs) has exacerbated inference
latency and computational costs. Speculative decoding methods, which aim to
mitigate these issues, often face inefficiencies in the construction of token
trees and the verification of candidate tokens. Existing strategies, including
chain mode, static tree, and dynamic tree approaches, have limitations in
accurately preparing candidate token trees for verification. We propose a novel
method named C2T that adopts a lightweight classifier to generate and prune
token trees dynamically. Our classifier considers additional feature variables
beyond the commonly used joint probability to predict the confidence score for
each draft token to determine whether it is the candidate token for
verification. This method outperforms state-of-the-art (SOTA) methods such as
EAGLE-2 on multiple benchmarks, by reducing the total number of candidate
tokens by 25% while maintaining or even improving the acceptance length.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çè¦æ¨¡æ¥çæ´å¤§ï¼å åäºæ¨è«å»¶é²åéç®ææ¬ãæ¨æ¸¬æ§è§£ç¢¼æ¹æ³æ¨å¨ç·©è§£éäºåé¡ï¼ä½éå¸¸å¨ä»¤çæ¨¹çå»ºæ§ååé¸ä»¤ççé©è­éç¨ä¸­æéå°æçä½ä¸çåé¡ãç¾æçç­ç¥ï¼åæ¬éæ¨¡å¼ãéææ¨¹ååææ¨¹æ¹æ³ï¼å¨æºç¢ºæºååé¸ä»¤çæ¨¹ä»¥é²è¡é©è­æ¹é¢å­å¨éå¶ãæåæåºäºä¸ç¨®åçº C2T çæ°æ¹æ³ï¼å®æ¡ç¨ä¸åè¼éç´åé¡å¨ä¾åæçæåä¿®åªä»¤çæ¨¹ãæåçåé¡å¨èæ®äºé¤äºå¸¸ç¨è¯åæ©çä¹å¤çå¶ä»ç¹å¾µè®æ¸ï¼ä»¥é æ¸¬æ¯åèç¨¿ä»¤ççä¿¡å¿åæ¸ï¼ä»¥ç¢ºå®å®æ¯å¦æ¯è¦é©è­çåé¸ä»¤çãæ­¤æ¹æ³å¨å¤ååºæºæ¸¬è©¦ä¸­åªæ¼æåé² (SOTA) æ¹æ³ï¼ä¾å¦ EAGLE-2ï¼å®å°åé¸ä»¤ççç¸½æ¸æ¸å°äº 25%ï¼åæç¶­ææçè³æ¹åäºæ¥åé·åº¦ã

##### **Reliability Across Parametric and External Knowledge: Understanding Knowledge Handling in LLMs**
2502.13648v1 by Youna Kim, Minjoon Choi, Sungmin Cho, Hyuhng Joon Kim, Sang-goo Lee, Taeuk Kim

Large Language Models (LLMs) enhance their problem-solving capability by
leveraging both parametric and external knowledge. Beyond leveraging external
knowledge to improve response accuracy, they require key capabilities for
reliable knowledge-handling: resolving conflicts between knowledge sources,
avoiding distraction from uninformative external knowledge, and abstaining when
sufficient knowledge is unavailable. Prior studies have examined these
scenarios in isolation or with limited scope. To systematically evaluate these
capabilities, we introduce a comprehensive framework for analyzing
knowledge-handling based on two key dimensions: the presence of parametric
knowledge and the informativeness of external knowledge. Through analysis, we
identify biases in knowledge utilization and examine how the ability to handle
one scenario impacts performance in others. Furthermore, we demonstrate that
training on data constructed based on the knowledge-handling scenarios improves
LLMs' reliability in integrating and utilizing knowledge.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ééå©ç¨åæ¸ååå¤é¨ç¥è­ï¼å¢å¼·å®åçè§£æ±ºåé¡è½åãé¤äºå©ç¨å¤é¨ç¥è­ä¾æååææºç¢ºåº¦ä¹å¤ï¼å®åééè¦å·åå¯é çç¥è­èçééµè½åï¼è§£æ±ºç¥è­ä¾æºä¹éçè¡çªãé¿åå ç¡æç¾©çå¤é¨ç¥è­èåå¿ï¼ä»¥åå¨ç¥è­ä¸è¶³æä¿æåå¶ãååçç ç©¶å·²å­¤ç«å°æå¨æéçç¯åå§æ¢è¨éäºæå¢ãçºäºç³»çµ±æ§å°è©ä¼°éäºè½åï¼æåå¼é²ä¸åå¨é¢çæ¶æ§ï¼æ ¹æå©åééµé¢åä¾åæç¥è­èçï¼åæ¸åç¥è­çå­å¨èå¤é¨ç¥è­çè³è¨éãééåæï¼æåæ¾åºç¥è­å©ç¨ä¸­çåèª¤ï¼ä¸¦æ¢è¨èçä¸åæå¢çè½åå¦ä½å½±é¿å¨å¶ä»æå¢ä¸­çè¡¨ç¾ãæ­¤å¤ï¼æåè­æå¨æ ¹æç¥è­èçæå¢å»ºæ§çè³æä¸é²è¡è¨ç·´ï¼å¯ä»¥æå LLM å¨æ´ååå©ç¨ç¥è­æ¹é¢çå¯é æ§ã

##### **Instruction Tuning on Public Government and Cultural Data for Low-Resource Language: a Case Study in Kazakh**
2502.13647v1 by Nurkhan Laiyk, Daniil Orel, Rituraj Joshi, Maiya Goloburda, Yuxia Wang, Preslav Nakov, Fajri Koto

Instruction tuning in low-resource languages remains underexplored due to
limited text data, particularly in government and cultural domains. To address
this, we introduce and open-source a large-scale (10,600 samples)
instruction-following (IFT) dataset, covering key institutional and cultural
knowledge relevant to Kazakhstan. Our dataset enhances LLMs' understanding of
procedural, legal, and structural governance topics. We employ LLM-assisted
data generation, comparing open-weight and closed-weight models for dataset
construction, and select GPT-4o as the backbone. Each entity of our dataset
undergoes full manual verification to ensure high quality. We also show that
fine-tuning Qwen, Falcon, and Gemma on our dataset leads to consistent
performance improvements in both multiple-choice and generative tasks,
demonstrating the potential of LLM-assisted instruction tuning for low-resource
languages.

æè¦ï¼ç±æ¼ææ¬è³ææéï¼ç¹å¥æ¯å¨æ¿åºåæåé åï¼å æ­¤ä½è³æºèªè¨çæä»¤èª¿æ´ä»æªå¾å°ååæ¢ç´¢ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥ä¸¦éæ¾äºä¸åå¤§åï¼10,600 åç¯ä¾ï¼æä»¤éµå¾ª (IFT) è³æéï¼æ¶µèèåè©åç¸éçä¸»è¦å¶åº¦åæåç¥è­ãæåçè³æéå¢å¼·äº LLM å°ç¨åºãæ³å¾åçµæ§æ²»çä¸»é¡ççè§£ãæåæ¡ç¨ LLM è¼å©è³æçæï¼æ¯è¼éæ¾æ¬éåå°éæ¬éæ¨¡åä»¥é²è¡è³æéå»ºæ§ï¼ä¸¦é¸æ GPT-4o ä½çºä¸»å¹¹ãæåè³æéçæ¯åå¯¦é«é½ç¶éå®æ´çæåé©è­ï¼ä»¥ç¢ºä¿é«åè³ªãæåéè¡¨æï¼å¨æåçè³æéä¸å¾®èª¿ QwenãFalcon å Gemma æå¨å¤éé¸æåçæä»»åä¸­æçºæ¹åæè½ï¼éè­æäº LLM è¼å©æä»¤èª¿æ´å¨ä½è³æºèªè¨ä¸­çæ½åã

##### **D.Va: Validate Your Demonstration First Before You Use It**
2502.13646v1 by Qi Zhang, Zhiqing Xiao, Ruixuan Xiao, Lirong Gao, Junbo Zhao

In-context learning (ICL) has demonstrated significant potential in enhancing
the capabilities of large language models (LLMs) during inference. It's
well-established that ICL heavily relies on selecting effective demonstrations
to generate outputs that better align with the expected results. As for
demonstration selection, previous approaches have typically relied on intuitive
metrics to evaluate the effectiveness of demonstrations, which often results in
limited robustness and poor cross-model generalization capabilities. To tackle
these challenges, we propose a novel method, \textbf{D}emonstration
\textbf{VA}lidation (\textbf{D.Va}), which integrates a demonstration
validation perspective into this field. By introducing the demonstration
validation mechanism, our method effectively identifies demonstrations that are
both effective and highly generalizable. \textbf{D.Va} surpasses all existing
demonstration selection techniques across both natural language understanding
(NLU) and natural language generation (NLG) tasks. Additionally, we demonstrate
the robustness and generalizability of our approach across various language
models with different retrieval models.

æè¦ï¼æå¢å¼å­¸ç¿ (ICL) å·²è­æå¨æ¨è«æéå¢å¼·å¤§åèªè¨æ¨¡å (LLM) çè½åæ¹é¢å·æé¡¯èæ½åãç¾æå¨ç¥ï¼ICL å´éä¾è³´æ¼é¸æææçç¤ºç¯ä¾ç¢çæ´ç¬¦åé æçµæçè¼¸åºãè³æ¼ç¤ºç¯é¸æï¼ååçåæ³éå¸¸ä¾è³´æ¼ç´è¦ºææ¨ä¾è©ä¼°ç¤ºç¯çæææ§ï¼ééå¸¸æå°è´ç©©å¥æ§åéåè·¨æ¨¡åæ³åè½åä¸ä½³ãçºäºæå°éäºææ°ï¼æåæåºäºä¸ç¨®æ°æ¹æ³ï¼**D**emonstration **VA**lidationï¼**D.Va**ï¼ï¼å°ç¤ºç¯é©è­è§é»æ´åå°éåé åãééå¼å¥ç¤ºç¯é©è­æ©å¶ï¼æåçåæ³ææå°æ¾åºæ¢ææåé«åº¦å¯æ³åçç¤ºç¯ã**D.Va** è¶è¶ææç¾æçç¤ºç¯é¸ææè¡ï¼æ¶µèèªç¶èªè¨çè§£ (NLU) åèªç¶èªè¨çæ (NLG) ä»»åãæ­¤å¤ï¼æåå±ç¤ºäºæåçæ¹æ³å¨å·æä¸åæª¢ç´¢æ¨¡åçåç¨®èªè¨æ¨¡åä¸­çç©©å¥æ§åå¯æ³åæ§ã

##### **Measuring the Effect of Transcription Noise on Downstream Language Understanding Tasks**
2502.13645v1 by Ori Shapira, Shlomo E. Chazan, Amir DN Cohen

With the increasing prevalence of recorded human speech, spoken language
understanding (SLU) is essential for its efficient processing. In order to
process the speech, it is commonly transcribed using automatic speech
recognition technology. This speech-to-text transition introduces errors into
the transcripts, which subsequently propagate to downstream NLP tasks, such as
dialogue summarization. While it is known that transcript noise affects
downstream tasks, a systematic approach to analyzing its effects across
different noise severities and types has not been addressed. We propose a
configurable framework for assessing task models in diverse noisy settings, and
for examining the impact of transcript-cleaning techniques. The framework
facilitates the investigation of task model behavior, which can in turn support
the development of effective SLU solutions. We exemplify the utility of our
framework on three SLU tasks and four task models, offering insights regarding
the effect of transcript noise on tasks in general and models in particular.
For instance, we find that task models can tolerate a certain level of noise,
and are affected differently by the types of errors in the transcript.

æè¦ï¼é¨èéè£½äººé¡èªé³ççè¡ï¼å£èªçè§£ (SLU) å°æ¼ææèçèªé³è³ééè¦ãçºäºèçèªé³ï¼éå¸¸ä½¿ç¨èªåèªé³è¾¨è­æè¡é²è¡è½éãéç¨®èªé³è½æå­çè½ææå¨è½ééç¨ä¸­ç¢çé¯èª¤ï¼éäºé¯èª¤æé²ä¸æ­¥å³æ­å°ä¸æ¸¸ç NLP ä»»åï¼ä¾å¦å°è©±æè¦ãéç¶å·²ç¥è½ééè¨æå½±é¿ä¸æ¸¸ä»»åï¼ä½å°æªéå°ä¸åéè¨å´éç¨åº¦åé¡åçå½±é¿é²è¡ç³»çµ±ååæãæåæåºä¸åå¯éç½®çæ¶æ§ï¼ç¨æ¼è©ä¼°ä¸åéè¨è¨­å®ä¸­çä»»åæ¨¡åï¼ä¸¦æª¢æ¥è½éæ¸çæè¡çå½±é¿ãæ­¤æ¶æ§æå©æ¼èª¿æ¥ä»»åæ¨¡åè¡çºï¼é²èæ¯æ´éç¼ææç SLU è§£å³æ¹æ¡ãæåå¨ä¸å SLU ä»»ååååä»»åæ¨¡åä¸å±ç¤ºäºæåæ¶æ§çæç¨ï¼æä¾äºéæ¼è½ééè¨å°ä¸è¬ä»»ååç¹å®æ¨¡åçå½±é¿çè¦è§£ãä¾å¦ï¼æåç¼ç¾ä»»åæ¨¡åå¯ä»¥å®¹å¿ä¸å®ç¨åº¦çéè¨ï¼ä¸¦ä¸æåå°è½éä¸­é¯èª¤é¡åçä¸åå½±é¿ã

##### **Qorgau: Evaluating LLM Safety in Kazakh-Russian Bilingual Contexts**
2502.13640v1 by Maiya Goloburda, Nurkhan Laiyk, Diana Turmakhan, Yuxia Wang, Mukhammed Togmanov, Jonibek Mansurov, Askhat Sametov, Nurdaulet Mukhituly, Minghan Wang, Daniil Orel, Zain Muhammad Mujahid, Fajri Koto, Timothy Baldwin, Preslav Nakov

Large language models (LLMs) are known to have the potential to generate
harmful content, posing risks to users. While significant progress has been
made in developing taxonomies for LLM risks and safety evaluation prompts, most
studies have focused on monolingual contexts, primarily in English. However,
language- and region-specific risks in bilingual contexts are often overlooked,
and core findings can diverge from those in monolingual settings. In this
paper, we introduce Qorgau, a novel dataset specifically designed for safety
evaluation in Kazakh and Russian, reflecting the unique bilingual context in
Kazakhstan, where both Kazakh (a low-resource language) and Russian (a
high-resource language) are spoken. Experiments with both multilingual and
language-specific LLMs reveal notable differences in safety performance,
emphasizing the need for tailored, region-specific datasets to ensure the
responsible and safe deployment of LLMs in countries like Kazakhstan. Warning:
this paper contains example data that may be offensive, harmful, or biased.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²ç¥å·æç¢çæå®³å§å®¹çæ½åï¼å°ä½¿ç¨èæ§æé¢¨éªãåç®¡å¨éç¼ LLM é¢¨éªåé¡æ³åå®å¨è©ä¼°æç¤ºæ¹é¢å·²åå¾éå¤§é²å±ï¼ä½å¤§å¤æ¸ç ç©¶é½éä¸­å¨å®èªå¢èªå¢ï¼ä¸»è¦æ¯è±èªãç¶èï¼å¨éèªèªå¢ä¸­ç¹å®æ¼èªè¨åå°åçé¢¨éªéå¸¸è¢«å¿½è¦ï¼èæ ¸å¿ç¼ç¾å¯è½èå®èªå¢è¨­å®ä¸­çç¼ç¾ä¸åãå¨æ¬æä¸­ï¼æåä»ç´¹äº Qorgauï¼éæ¯ä¸åå°éçºåè©åèªåä¿èªçå®å¨è©ä¼°èè¨­è¨çæ°ç©è³æéï¼åæ äºåè©åæ¯å¦ç¨ç¹çéèªèªå¢ï¼åè©åèªï¼ä½è³æºèªè¨ï¼åä¿èªï¼é«è³æºèªè¨ï¼é½å¨æ­¤èä½¿ç¨ãä½¿ç¨å¤èªè¨åç¹å®èªè¨ LLM é²è¡çå¯¦é©æ­ç¤ºäºå®å¨æè½çé¡¯èå·®ç°ï¼å¼·èª¿äºéèº«æé ç¹å®å°åè³æéçå¿è¦æ§ï¼ä»¥ç¢ºä¿å¨åè©åæ¯å¦ç­åå®¶è² è²¬ä»»ä¸å®å¨å°é¨ç½² LLMãè­¦åï¼æ¬æåå«å¯è½ä»¤äººåæãæå®³ææåè¦çç¯ä¾è³æã

##### **Integrating Inverse and Forward Modeling for Sparse Temporal Data from Sensor Networks**
2502.13638v1 by Julian Vexler, BjÃ¶rn Vieten, Martin Nelke, Stefan Kramer

We present CavePerception, a framework for the analysis of sparse data from
sensor networks that incorporates elements of inverse modeling and forward
modeling. By integrating machine learning with physical modeling in a
hypotheses space, we aim to improve the interpretability of sparse, noisy, and
potentially incomplete sensor data. The framework assumes data from a
two-dimensional sensor network laid out in a graph structure that detects
certain objects, with certain motion patterns. Examples of such sensors are
magnetometers. Given knowledge about the objects and the way they act on the
sensors, one can develop a data generator that produces data from simulated
motions of the objects across the sensor field. The framework uses the
simulated data to infer object behaviors across the sensor network. The
approach is experimentally tested on real-world data, where magnetometers are
used on an airport to detect and identify aircraft motions. Experiments
demonstrate the value of integrating inverse and forward modeling, enabling
intelligent systems to better understand and predict complex, sensor-driven
events.

æè¦ï¼æåæåº CavePerceptionï¼ä¸åç¨æ¼åæä¾èªææ¸¬å¨ç¶²è·¯çç¨çè³æçæ¶æ§ï¼å¶ä¸­çµåäºååå»ºæ¨¡åæ­£åå»ºæ¨¡çåç´ ãééå¨åè¨­ç©ºéä¸­æ´åæ©å¨å­¸ç¿åç©çå»ºæ¨¡ï¼æåæ¨å¨æ¹åç¨çãéè¨åæ½å¨ä¸å®æ´çææ¸¬å¨è³æçå¯è§£éæ§ãè©²æ¶æ§åè¨­ä¾èªäºç¶­ææ¸¬å¨ç¶²è·¯çè³æï¼è©²ç¶²è·¯ä»¥åå½¢çµæ§ä½ç½®ï¼ç¨æ¼åµæ¸¬ç¹å®ç©ä»¶ï¼ä¸¦å·åç¹å®åä½æ¨¡å¼ãæ­¤é¡ææ¸¬å¨çç¯ä¾çºç£å¼·è¨ãå¨å·åéæ¼ç©ä»¶åå¶å°ææ¸¬å¨ä½ç¨æ¹å¼çç¥è­ä¸ï¼å¯ä»¥éç¼ä¸åè³æç¢çå¨ï¼ç¨æ¼ç¢çä¾èªç©ä»¶å¨ææ¸¬å¨å ´ä¸­æ¨¡æ¬åä½çè³æãè©²æ¶æ§ä½¿ç¨æ¨¡æ¬è³æä¾æ¨è«ææ¸¬å¨ç¶²è·¯ä¸­ç©ä»¶çè¡çºãè©²æ¹æ³å¨çå¯¦ä¸çè³æä¸ç¶éå¯¦é©æ¸¬è©¦ï¼å¶ä¸­ç£å¼·è¨ç¨æ¼æ©å ´ä¾åµæ¸¬åè­å¥é£æ©åä½ãå¯¦é©è­æäºæ´ååååæ­£åå»ºæ¨¡çå¹å¼ï¼è®æºæ§ç³»çµ±è½å¤ æ´å¥½å°çè§£åé æ¸¬è¤éçãææ¸¬å¨é©åçäºä»¶ã

##### **Concept Layers: Enhancing Interpretability and Intervenability via LLM Conceptualization**
2502.13632v1 by Or Raphael Bidusa, Shaul Markovitch

The opaque nature of Large Language Models (LLMs) has led to significant
research efforts aimed at enhancing their interpretability, primarily through
post-hoc methods. More recent in-hoc approaches, such as Concept Bottleneck
Models (CBMs), offer both interpretability and intervenability by incorporating
explicit concept representations. However, these methods suffer from key
limitations, including reliance on labeled concept datasets and significant
architectural modifications that challenges re-integration into existing system
pipelines. In this work, we introduce a new methodology for incorporating
interpretability and intervenability into an existing model by integrating
Concept Layers (CLs) into its architecture. Our approach projects the model's
internal vector representations into a conceptual, explainable vector space
before reconstructing and feeding them back into the model. Furthermore, we
eliminate the need for a human-selected concept set by algorithmically
searching an ontology for a set of concepts that can be either task-specific or
task-agnostic. We evaluate CLs across multiple tasks, demonstrating that they
maintain the original model's performance and agreement while enabling
meaningful interventions. Additionally, we present a proof of concept
showcasing an intervenability interface, allowing users to adjust model
behavior dynamically, such as mitigating biases during inference.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çä¸éææ¬è³ªå·²å°è´å¤§éçç ç©¶å·¥ä½ï¼æ¨å¨ééå¾è¨­æ¹æ³æåå¶å¯è§£éæ§ãè¼æ°çå§å»ºæ¹æ³ï¼ä¾å¦æ¦å¿µç¶é ¸æ¨¡å (CBM)ï¼ééç´å¥æç¢ºçæ¦å¿µè¡¨å¾µï¼åææä¾å¯è§£éæ§åå¯ä»å¥æ§ãç¶èï¼éäºæ¹æ³æå¶ä¸»è¦çéå¶ï¼åæ¬ä¾è³´æ¨è¨æ¦å¿µè³æéï¼ä»¥åå¤§å¹çæ¶æ§ä¿®æ¹ï¼å°éæ°æ´åå°ç¾æçç³»çµ±ç®¡ç·ä¸­æ§æææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼ééå°æ¦å¿µå±¤ (CL) æ´åå°æ¶æ§ä¸­ï¼å°å¯è§£éæ§åå¯ä»å¥æ§ç´å¥ç¾ææ¨¡åãæåçåæ³æ¯å°æ¨¡åçå§é¨åéè¡¨å¾µæå½±å°ä¸åæ¦å¿µæ§çãå¯è§£éçåéç©ºéï¼ç¶å¾åå°å¶éå»ºä¸¦åé¥å°æ¨¡åä¸­ãæ­¤å¤ï¼æåééæ¼ç®æ³æå°æ¬ä½ï¼ä»¥å°æ¾ä¸çµæ¦å¿µï¼å¯ä»¥æ¯ç¹å®æ¼ä»»åæèä»»åç¡éï¼ï¼ä¾æ¶é¤å°äººé¡é¸ææ¦å¿µéçéæ±ãæåå¨å¤é ä»»åä¸­è©ä¼° CLï¼è­æå®åå¨ç¶­æåå§æ¨¡åçæè½åä¸è´æ§çåæï¼éè½å¯¦ç¾ææç¾©çä»å¥ãæ­¤å¤ï¼æåæåºäºä¸åæ¦å¿µé©è­ï¼å±ç¤ºäºä¸åå¯ä»å¥æ§ä»é¢ï¼è®ä½¿ç¨èå¯ä»¥åæèª¿æ´æ¨¡åè¡çºï¼ä¾å¦å¨æ¨çéç¨ä¸­æ¸è¼åå·®ã

##### **Non-Euclidean Hierarchical Representational Learning using Hyperbolic Graph Neural Networks for Environmental Claim Detection**
2502.13628v1 by Darpan Aswal, Manjira Sinha

Transformer-based models dominate NLP tasks like sentiment analysis, machine
translation, and claim verification. However, their massive computational
demands and lack of interpretability pose challenges for real-world
applications requiring efficiency and transparency. In this work, we explore
Graph Neural Networks (GNNs) and Hyperbolic Graph Neural Networks (HGNNs) as
lightweight yet effective alternatives for Environmental Claim Detection,
reframing it as a graph classification problem. We construct dependency parsing
graphs to explicitly model syntactic structures, using simple word embeddings
(word2vec) for node features with dependency relations encoded as edge
features. Our results demonstrate that these graph-based models achieve
comparable or superior performance to state-of-the-art transformers while using
30x fewer parameters. This efficiency highlights the potential of structured,
interpretable, and computationally efficient graph-based approaches.

æè¦ï¼åºæ¼ Transformer çæ¨¡åä¸»å°è NLP ä»»åï¼ä¾å¦æç·åæãæ©å¨ç¿»è­¯åè²æé©è­ãç¶èï¼å®åé¾å¤§çè¨ç®éæ±åç¼ºä¹å¯è§£éæ§å°éè¦æçåéæåº¦çå¯¦éæç¨æ§æäºææ°ãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨åç¥ç¶ç¶²è·¯ (GNN) åéæ²åç¥ç¶ç¶²è·¯ (HGNN) ä½çºç°å¢è²ææª¢æ¸¬çè¼éç´ä¸ææçæ¿ä»£æ¹æ¡ï¼ä¸¦å°å¶éæ°å®ç¾©çºåå½¢åé¡åé¡ãæåæ§å»ºä¾è³´è§£æåå½¢ä»¥æç¢ºå»ºæ§èªæ³çµæ§ï¼ä½¿ç¨ç°¡å®çè©åµå¥ï¼word2vecï¼ä½çºç¯é»ç¹å¾µï¼ä¸¦å°ä¾è³´éä¿ç·¨ç¢¼çºéç·£ç¹å¾µãæåççµæè­æï¼éäºåºæ¼åå½¢çæ¨¡åå¨ä½¿ç¨å° 30 åçåæ¸æï¼å¯å¯¦ç¾èæåé²ç Transformer ç¸ç¶ææ´åªç°çæè½ãéç¨®æççªé¡¯äºçµæ§åãå¯è§£éä¸è¨ç®æçé«çåºæ¼åå½¢æ¹æ³çæ½åã

##### **REFIND: Retrieval-Augmented Factuality Hallucination Detection in Large Language Models**
2502.13622v1 by DongGeon Lee, Hwanjo Yu

Hallucinations in large language model (LLM) outputs severely limit their
reliability in knowledge-intensive tasks such as question answering. To address
this challenge, we introduce REFIND (Retrieval-augmented Factuality
hallucINation Detection), a novel framework that detects hallucinated spans
within LLM outputs by directly leveraging retrieved documents. As part of the
REFIND, we propose the Context Sensitivity Ratio (CSR), a novel metric that
quantifies the sensitivity of LLM outputs to retrieved evidence. This
innovative approach enables REFIND to efficiently and accurately detect
hallucinations, setting it apart from existing methods. In the evaluation,
REFIND demonstrated robustness across nine languages, including low-resource
settings, and significantly outperformed baseline models, achieving superior
IoU scores in identifying hallucinated spans. This work highlights the
effectiveness of quantifying context sensitivity for hallucination detection,
thereby paving the way for more reliable and trustworthy LLM applications
across diverse languages.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è¼¸åºä¸­çå¹»è¦ºå´ééå¶äºå®åå¨ç¥è­å¯éåä»»åï¼ä¾å¦åç­ï¼ä¸­çå¯é æ§ãçºäºæå°éä¸ææ°ï¼æåå¼å¥äº REFINDï¼æª¢ç´¢å¢å¼·çäºå¯¦å¹»è¦ºæª¢æ¸¬ï¼ï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼å®ééç´æ¥å©ç¨æª¢ç´¢å°çæä»¶ä¾æª¢æ¸¬ LLM è¼¸åºä¸­çå¹»è¦ºè·¨åº¦ãä½çº REFIND çä¸é¨åï¼æåæåºäºèªå¢æææ§æ¯ç (CSR)ï¼éæ¯ä¸åæ°ç©çææ¨ï¼å®éåäº LLM è¼¸åºå°æª¢ç´¢è­æçæææ§ãéç¨®åµæ°æ¹æ³ä½¿ REFIND è½å¤ é«ææºç¢ºå°æª¢æ¸¬å¹»è¦ºï¼ä½¿å¶æå¥æ¼ç¾ææ¹æ³ãå¨è©ä¼°ä¸­ï¼REFIND å¨ä¹ç¨®èªè¨ä¸­å±ç¤ºäºå¶ç©©å¥æ§ï¼åæ¬ä½è³æºè¨­ç½®ï¼ä¸¦ä¸é¡¯èåªæ¼åºç·æ¨¡åï¼å¨è­å¥å¹»è¦ºè·¨åº¦æ¹é¢å¯¦ç¾äºæ´é«ç IoU åæ¸ãéé å·¥ä½çªåºäºéåèªå¢æææ§å°æ¼å¹»è¦ºæª¢æ¸¬çæææ§ï¼å¾èçºè·¨å¤ç¨®èªè¨çæ´å¯é åå¼å¾ä¿¡è³´ç LLM æç¨éªå¹³äºéè·¯ã

##### **Decentralized Planning Using Probabilistic Hyperproperties**
2502.13621v1 by Francesco Pontiggia, Filip MacÃ¡k, Roman Andriushchenko, Michele Chiari, Milan ÄeÅ¡ka

Multi-agent planning under stochastic dynamics is usually formalised using
decentralized (partially observable) Markov decision processes ( MDPs) and
reachability or expected reward specifications. In this paper, we propose a
different approach: we use an MDP describing how a single agent operates in an
environment and probabilistic hyperproperties to capture desired temporal
objectives for a set of decentralized agents operating in the environment. We
extend existing approaches for model checking probabilistic hyperproperties to
handle temporal formulae relating paths of different agents, thus requiring the
self-composition between multiple MDPs. Using several case studies, we
demonstrate that our approach provides a flexible and expressive framework to
broaden the specification capabilities with respect to existing planning
techniques. Additionally, we establish a close connection between a subclass of
probabilistic hyperproperties and planning for a particular type of Dec-MDPs,
for both of which we show undecidability. This lays the ground for the use of
existing decentralized planning tools in the field of probabilistic
hyperproperty verification.

æè¦ï¼å¤æºè½é«å¨é¨æ©åæä¸çè¦åéå¸¸ä½¿ç¨åæ£å¼ï¼é¨åå¯è§å¯ï¼é¦¬å¯å¤«æ±ºç­éç¨ (MDP) åå¯éæ§æé æçåµè¦æ ¼é²è¡å½¢å¼åãå¨æ¬æä¸­ï¼æåæåºä¸åçæ¹æ³ï¼æåä½¿ç¨ MDP ä¾æè¿°å®ä¸æºè½é«å¨ç°å¢ä¸­éä½çæ¹å¼ï¼ä¸¦ä½¿ç¨æ©çè¶å±¬æ§ä¾ææå¨ç°å¢ä¸­éä½çä¸çµåæ£å¼æºè½é«æææçæéç®æ¨ãæåæ´åç¾ææ¹æ³ä¾æª¢æ¥æ©çè¶å±¬æ§ï¼ä»¥èçèä¸åæºè½é«è·¯å¾ç¸éçæéå¬å¼ï¼å æ­¤éè¦å¨å¤å MDP ä¹éé²è¡èªæçµåãä½¿ç¨å¹¾åæ¡ä¾ç ç©¶ï¼æåè­ææåçåæ³æä¾äºä¸åéæ´»ä¸è¡¨éåè±å¯çæ¶æ§ï¼ä»¥æ´å±ç¸å°æ¼ç¾æè¦åæè¡çè¦æ ¼è½åãæ­¤å¤ï¼æåå»ºç«äºæ©çè¶å±¬æ§çå­é¡å¥èè¦åç¹å®é¡å Dec-MDP ä¹éçå¯åéè¯ï¼æåå°éå©èé½é¡¯ç¤ºäºä¸å¯å¤å®æ§ãéçºå¨æ©çè¶å±¬æ§é©è­é åä¸­ä½¿ç¨ç¾æçåæ£å¼è¦åå·¥å·å¥ å®äºåºç¤ã

##### **Complex Ontology Matching with Large Language Model Embeddings**
2502.13619v1 by Guilherme Sousa, Rinaldo Lima, Cassia Trojahn

Ontology, and more broadly, Knowledge Graph Matching is a challenging task in
which expressiveness has not been fully addressed. Despite the increasing use
of embeddings and language models for this task, approaches for generating
expressive correspondences still do not take full advantage of these models, in
particular, large language models (LLMs). This paper proposes to integrate LLMs
into an approach for generating expressive correspondences based on alignment
need and ABox-based relation discovery. The generation of correspondences is
performed by matching similar surroundings of instance sub-graphs. The
integration of LLMs results in different architectural modifications, including
label similarity, sub-graph matching, and entity matching. The performance word
embeddings, sentence embeddings, and LLM-based embeddings, was compared. The
results demonstrate that integrating LLMs surpasses all other models, enhancing
the baseline version of the approach with a 45\% increase in F-measure.

æè¦ï¼æ¬ä½è®ºï¼æ´å¹¿æ³å°è¯´ï¼ç¥è¯å¾è°±å¹éæ¯ä¸é¡¹å·ææææ§çä»»å¡ï¼å¶ä¸­è¡¨è¾¾åå°æªå¾å°ååè§£å³ãå°½ç®¡è¶æ¥è¶å¤å°ä½¿ç¨åµå¥åè¯­è¨æ¨¡åæ¥å®ææ­¤ä»»å¡ï¼ä½çæè¡¨è¾¾æ§å¯¹åºå³ç³»çæ¹æ³ä»ç¶æ²¡æååå©ç¨è¿äºæ¨¡åï¼ç¹å«æ¯å¤§åè¯­è¨æ¨¡å (LLM)ãæ¬ææåºå° LLM éæå°ä¸ç§åºäºå¯¹é½éæ±ååºäº ABox çå³ç³»åç°æ¥çæè¡¨è¾¾æ§å¯¹åºå³ç³»çæ¹æ³ä¸­ãå¯¹åºå³ç³»ççææ¯éè¿å¹éå®ä¾å­å¾çç¸ä¼¼å¨å´ç¯å¢æ¥æ§è¡çãLLM çéæå¯¼è´äºä¸åçæ¶æä¿®æ¹ï¼åæ¬æ ç­¾ç¸ä¼¼æ§ãå­å¾å¹éåå®ä½å¹éãæ¯è¾äºåè¯åµå¥ãå¥å­åµå¥ååºäº LLM çåµå¥çæ§è½ãç»æè¡¨æï¼éæ LLM è¶è¶äºææå¶ä»æ¨¡åï¼éè¿ F-measure æé«äº 45% çåºåçæ¬çæ¹æ³ã

##### **LaVCa: LLM-assisted Visual Cortex Captioning**
2502.13606v1 by Takuya Matsuyama, Shinji Nishimoto, Yu Takagi

Understanding the property of neural populations (or voxels) in the human
brain can advance our comprehension of human perceptual and cognitive
processing capabilities and contribute to developing brain-inspired computer
models. Recent encoding models using deep neural networks (DNNs) have
successfully predicted voxel-wise activity. However, interpreting the
properties that explain voxel responses remains challenging because of the
black-box nature of DNNs. As a solution, we propose LLM-assisted Visual Cortex
Captioning (LaVCa), a data-driven approach that uses large language models
(LLMs) to generate natural-language captions for images to which voxels are
selective. By applying LaVCa for image-evoked brain activity, we demonstrate
that LaVCa generates captions that describe voxel selectivity more accurately
than the previously proposed method. Furthermore, the captions generated by
LaVCa quantitatively capture more detailed properties than the existing method
at both the inter-voxel and intra-voxel levels. Furthermore, a more detailed
analysis of the voxel-specific properties generated by LaVCa reveals
fine-grained functional differentiation within regions of interest (ROIs) in
the visual cortex and voxels that simultaneously represent multiple distinct
concepts. These findings offer profound insights into human visual
representations by assigning detailed captions throughout the visual cortex
while highlighting the potential of LLM-based methods in understanding brain
representations. Please check out our webpage at
https://sites.google.com/view/lavca-llm/

æè¦ï¼çè§£äººé¡å¤§è¦ä¸­ç¥ç¶åç¾¤ï¼æé«ç´ ï¼çç¹æ§ï¼æå©æ¼æåé²ä¸æ­¥äºè§£äººé¡ç¥è¦ºåèªç¥èçè½åï¼ä¸¦æå©æ¼éç¼åå¤§è¦åç¼çé»è¦æ¨¡åãæè¿ä½¿ç¨æ·±åº¦ç¥ç¶ç¶²è·¯ï¼DNNï¼çç·¨ç¢¼æ¨¡åå·²æåé æ¸¬é«ç´ æ´»åãç¶èï¼ç±æ¼ DNN çé»ç®±æ§è³ªï¼è§£éèªªæé«ç´ åæçç¹æ§ä»ç¶å·æææ°æ§ãä½çºè§£æ±ºæ¹æ¡ï¼æåæåº LLM è¼å©è¦è¦ºç®å±¤å­å¹ï¼LaVCaï¼ï¼éæ¯ä¸ç¨®è³æé©åçæ¹æ³ï¼ä½¿ç¨å¤§åèªè¨æ¨¡åï¼LLMï¼çºé«ç´ é¸æçå½±åç¢çèªç¶èªè¨å­å¹ãééå° LaVCa æç¨æ¼å½±åå¼ç¼çå¤§è¦æ´»åï¼æåè­æ LaVCa ç¢ççå­å¹æ¯ååæåºçæ¹æ³æ´æºç¢ºå°æè¿°é«ç´ é¸ææ§ãæ­¤å¤ï¼LaVCa ç¢ççå­å¹å¨é«ç´ éåé«ç´ å§å±¤ç´ä¸ï¼æ¯ç¾ææ¹æ³éåææå°æ´å¤è©³ç´°çç¹æ§ãæ­¤å¤ï¼å° LaVCa ç¢ççé«ç´ ç¹å®ç¹æ§çæ´è©³ç´°åææ­ç¤ºäºè¦è¦ºç®å±¤ä¸­æèè¶£ååï¼ROIï¼å§çç´°ç·»åè½ååï¼ä»¥ååæè¡¨ç¤ºå¤åä¸åæ¦å¿µçé«ç´ ãéäºç¼ç¾ééå¨æ´åè¦è¦ºç®å±¤ä¸­æå®è©³ç´°çå­å¹ï¼æä¾äºäººé¡è¦è¦ºè¡¨å¾µçæ·±å»è¦è§£ï¼åæå¼·èª¿äºåºæ¼ LLM çæ¹æ³å¨çè§£å¤§è¦è¡¨å¾µæ¹é¢çæ½åãè«æ¥çæåçç¶²é ï¼
https://sites.google.com/view/lavca-llm/

##### **BeamLoRA: Beam-Constraint Low-Rank Adaptation**
2502.13604v1 by Naibin Gu, Zhenyu Zhang, Xiyu Liu, Peng Fu, Zheng Lin, Shuohuan Wang, Yu Sun, Hua Wu, Weiping Wang, Haifeng Wang

Due to the demand for efficient fine-tuning of large language models,
Low-Rank Adaptation (LoRA) has been widely adopted as one of the most effective
parameter-efficient fine-tuning methods. Nevertheless, while LoRA improves
efficiency, there remains room for improvement in accuracy. Herein, we adopt a
novel perspective to assess the characteristics of LoRA ranks. The results
reveal that different ranks within the LoRA modules not only exhibit varying
levels of importance but also evolve dynamically throughout the fine-tuning
process, which may limit the performance of LoRA. Based on these findings, we
propose BeamLoRA, which conceptualizes each LoRA module as a beam where each
rank naturally corresponds to a potential sub-solution, and the fine-tuning
process becomes a search for the optimal sub-solution combination. BeamLoRA
dynamically eliminates underperforming sub-solutions while expanding the
parameter space for promising ones, enhancing performance with a fixed rank.
Extensive experiments across three base models and 12 datasets spanning math
reasoning, code generation, and commonsense reasoning demonstrate that BeamLoRA
consistently enhances the performance of LoRA, surpassing the other baseline
methods.

æè¦ï¼ç±æ¼å°å¤§åèªè¨æ¨¡åé²è¡é«æå¾®èª¿çéæ±ï¼
ä½éæ¹ç·¨ (LoRA) å·²è¢«å»£æ³æ¡ç¨çºæææç
åæ¸é«æå¾®èª¿æ¹æ³ä¹ä¸ãåç®¡å¦æ­¤ï¼éç¶ LoRA æé«äº
æçï¼ä½æºç¢ºæ§ä»ææ¹é²ç©ºéãå¨æ­¤ï¼æåæ¡ç¨ä¸
ç¨®æ°ç©çè§é»ä¾è©ä¼° LoRA ç­ç´çç¹å¾µãçµæ
é¡¯ç¤ºï¼LoRA æ¨¡çµå§çä¸åç­ç´ä¸åè¡¨ç¾åºä¸åç
éè¦æ§ï¼èä¸å¨å¾®èª¿éç¨ä¸­ä¹æåææ¼è®ï¼éå¯è½æéå¶ LoRA çæè½ãæ ¹æéäºç¼ç¾ï¼æå
æåº BeamLoRAï¼å°æ¯å LoRA æ¨¡çµæ¦å¿µåçºä¸åæ³¢æï¼å¶ä¸­æ¯å
ç­ç´èªç¶å°ææ¼ä¸åæ½å¨çå­è§£æ±ºæ¹æ¡ï¼èå¾®èª¿
éç¨è®ææå°æä½³å­è§£æ±ºæ¹æ¡çµåãBeamLoRA
åææ¶é¤è¡¨ç¾ä¸ä½³çå­è§£æ±ºæ¹æ¡ï¼åææ´å±æåéçå­è§£æ±ºæ¹æ¡çåæ¸ç©ºéï¼ä»¥åºå®ç­ç´æåæè½ã
è·¨è¶ä¸ååºç¤æ¨¡ååæ¶µèæ¸å­¸
æ¨çãç¨å¼ç¢¼çæåå¸¸è­æ¨çç 12 åè³æéçå»£æ³å¯¦é©è­æï¼BeamLoRA
å§çµæå LoRA çæè½ï¼è¶è¶å¶ä»åºæº
æ¹æ³ã

##### **Efficient Safety Retrofitting Against Jailbreaking for LLMs**
2502.13603v1 by Dario Garcia-Gasulla, Anna Arias-Duart, Adrian Tormos, Daniel Hinjos, Oscar Molina-Sedano, Ashwin Kumar Gururajan, Maria Eugenia Cardello

Direct Preference Optimization (DPO) is an efficient alignment technique that
steers LLMs towards preferable outputs by training on preference data,
bypassing the need for explicit reward models. Its simplicity enables easy
adaptation to various domains and safety requirements. This paper examines
DPO's effectiveness in model safety against jailbreaking attacks while
minimizing data requirements and training costs. We introduce Egida, a dataset
expanded from multiple sources, which includes 27 different safety topics and
18 different attack styles, complemented with synthetic and human labels. This
data is used to boost the safety of state-of-the-art LLMs
(Llama-3.1-8B/70B-Instruct, Qwen-2.5-7B/72B-Instruct) across topics and attack
styles. In addition to safety evaluations, we assess their post-alignment
performance degradation in general purpose tasks, and their tendency to over
refusal. Following the proposed methodology, trained models reduce their Attack
Success Rate by 10%-30%, using small training efforts (2,000 samples) with low
computational cost (3\$ for 8B models, 20\$ for 72B models). Safety aligned
models generalize to unseen topics and attack styles, with the most successful
attack style reaching a success rate around 5%. Size and family are found to
strongly influence model malleability towards safety, pointing at the
importance of pre-training choices. To validate our findings, a large
independent assessment of human preference agreement with Llama-Guard-3-8B is
conducted by the authors and the associated dataset Egida-HSafe is released.
Overall, this study illustrates how affordable and accessible it is to enhance
LLM safety using DPO while outlining its current limitations. All datasets and
models are released to enable reproducibility and further research.

æè¦ï¼ç´æ¥åå¥½æä½³å (DPO) æ¯ä¸ç¨®ææå°é½æè¡ï¼ééåå¥½è³æè¨ç·´ï¼å° LLM å¼å°è³è¼ä½³è¼¸åºï¼ç¡é æç¢ºåé¥æ¨¡åãå¶ç°¡æ½æ§è®å®ææ¼é©æåç¨®é ååå®å¨éæ±ãæ¬ææ¢è¨ DPO å¨æ¨¡åå®å¨æ¹é¢å°æè¶çæ»æçæææ§ï¼åæå°è³æéæ±åè¨ç·´ææ¬éè³æä½ãæåå¼é² Egidaï¼ä¸åå¾å¤åä¾æºæ´å±èä¾çè³æéï¼å¶ä¸­åå« 27 åä¸åçå®å¨ä¸»é¡å 18 ç¨®ä¸åçæ»ææ¨£å¼ï¼ä¸¦éæåæåäººå·¥æ¨ç±¤ãéäºè³æç¨æ¼æåæåé² LLMï¼Llama-3.1-8B/70B-InstructãQwen-2.5-7B/72B-Instructï¼å¨åç¨®ä¸»é¡åæ»ææ¨£å¼ä¸­çå®å¨æ§ãé¤äºå®å¨è©ä¼°å¤ï¼æåè©ä¼°å®åå¨ä¸è¬ä»»åä¸­å°é½å¾æè½çéä½ï¼ä»¥åå®åéåº¦æçµçå¾åãéµå¾ªå»ºè­°çæ¹æ³ï¼è¨ç·´å¾çæ¨¡åå°å®åçæ»ææåçéä½äº 10%-30%ï¼ä¸è¨ç·´å·¥ä½éå°ï¼2,000 åç¯ä¾ï¼ï¼éç®ææ¬ä½ï¼8B æ¨¡åçº 3 ç¾åï¼72B æ¨¡åçº 20 ç¾åï¼ãå®å¨å°é½æ¨¡åæ¦æ¬è³æªè¦ä¸»é¡åæ»ææ¨£å¼ï¼å¶ä¸­ææåçæ»ææ¨£å¼æåçç´çº 5%ãç¼ç¾æ¨¡åå¤§å°åç³»åæå¼·çå½±é¿æ¨¡åå°å®å¨æ§çå¯å¡æ§ï¼éé»åºé è¨ç·´é¸æçéè¦æ§ãçºäºé©è­æåçç¼ç¾ï¼ä½èé²è¡äº Llama-Guard-3-8B äººé¡åå¥½ä¸è´æ§çå»£æ³ç¨ç«è©ä¼°ï¼ä¸¦ç¼å¸äºç¸éè³æé Egida-HSafeãæ´é«èè¨ï¼æ¬ç ç©¶èªªæäºä½¿ç¨ DPO å¢å¼· LLM å®å¨æ§çç¶æ¿æ§åå¯åæ§ï¼åææ¦è¿°äºå¶ç¶åçéå¶ãææè³æéåæ¨¡åçå·²ç¼å¸ï¼ä»¥å©æ¼éç¾æ§åé²ä¸æ­¥ç ç©¶ã

##### **MMTEB: Massive Multilingual Text Embedding Benchmark**
2502.13595v1 by Kenneth Enevoldsen, Isaac Chung, Imene Kerboua, MÃ¡rton Kardos, Ashwin Mathur, David Stap, Jay Gala, Wissam Siblini, Dominik KrzemiÅski, Genta Indra Winata, Saba Sturua, Saiteja Utpala, Mathieu Ciancone, Marion Schaeffer, Gabriel Sequeira, Diganta Misra, Shreeya Dhakal, Jonathan RystrÃ¸m, Roman Solomatin, Ãmer ÃaÄatan, Akash Kundu, Martin Bernstorff, Shitao Xiao, Akshita Sukhlecha, Bhavish Pahwa, RafaÅ PoÅwiata, Kranthi Kiran GV, Shawon Ashraf, Daniel Auras, BjÃ¶rn PlÃ¼ster, Jan Philipp Harries, LoÃ¯c Magne, Isabelle Mohr, Mariya Hendriksen, Dawei Zhu, Hippolyte Gisserot-Boukhlef, Tom Aarsen, Jan Kostkan, Konrad Wojtasik, Taemin Lee, Marek Å uppa, Crystina Zhang, Roberta Rocca, Mohammed Hamdy, Andrianos Michail, John Yang, Manuel Faysse, Aleksei Vatolin, Nandan Thakur, Manan Dey, Dipam Vasani, Pranjal Chitale, Simone Tedeschi, Nguyen Tai, Artem Snegirev, Michael GÃ¼nther, Mengzhou Xia, Weijia Shi, Xing Han LÃ¹, Jordan Clive, Gayatri Krishnakumar, Anna Maksimova, Silvan Wehrli, Maria Tikhonova, Henil Panchal, Aleksandr Abramov, Malte Ostendorff, Zheng Liu, Simon Clematide, Lester James Miranda, Alena Fenogenova, Guangyu Song, Ruqiya Bin Safi, Wen-Ding Li, Alessia Borghini, Federico Cassano, Hongjin Su, Jimmy Lin, Howard Yen, Lasse Hansen, Sara Hooker, Chenghao Xiao, Vaibhav Adlakha, Orion Weller, Siva Reddy, Niklas Muennighoff

Text embeddings are typically evaluated on a limited set of tasks, which are
constrained by language, domain, and task diversity. To address these
limitations and provide a more comprehensive evaluation, we introduce the
Massive Multilingual Text Embedding Benchmark (MMTEB) - a large-scale,
community-driven expansion of MTEB, covering over 500 quality-controlled
evaluation tasks across 250+ languages. MMTEB includes a diverse set of
challenging, novel tasks such as instruction following, long-document
retrieval, and code retrieval, representing the largest multilingual collection
of evaluation tasks for embedding models to date. Using this collection, we
develop several highly multilingual benchmarks, which we use to evaluate a
representative set of models. We find that while large language models (LLMs)
with billions of parameters can achieve state-of-the-art performance on certain
language subsets and task categories, the best-performing publicly available
model is multilingual-e5-large-instruct with only 560 million parameters. To
facilitate accessibility and reduce computational cost, we introduce a novel
downsampling method based on inter-task correlation, ensuring a diverse
selection while preserving relative model rankings. Furthermore, we optimize
tasks such as retrieval by sampling hard negatives, creating smaller but
effective splits. These optimizations allow us to introduce benchmarks that
drastically reduce computational demands. For instance, our newly introduced
zero-shot English benchmark maintains a ranking order similar to the full-scale
version but at a fraction of the computational cost.

æè¦ï¼ææ¬åµå¥éå¸¸å¨åè¯­è¨ãé¢ååä»»å¡å¤æ ·æ§éå¶çä¸ç»æéçä»»å¡ä¸è¿è¡è¯ä¼°ãä¸ºäºè§£å³è¿äºéå¶å¹¶æä¾æ´å¨é¢çè¯ä¼°ï¼æä»¬å¼å¥äºå¤§è§æ¨¡å¤è¯­è¨ææ¬åµå¥åºåï¼MMTEBï¼ââMTEB çä¸é¡¹å¤§è§æ¨¡ãç¤¾åºé©±å¨çæ©å±ï¼æ¶µçäº 250 å¤ç§è¯­è¨ä¸­ç 500 å¤é¡¹è´¨éåæ§è¯ä¼°ä»»å¡ãMMTEB åå«äºä¸ç»å·ææææ§çæ°ä»»å¡ï¼ä¾å¦æä»¤éµå¾ªãé¿ææ¡£æ£ç´¢åä»£ç æ£ç´¢ï¼ä»£è¡¨äºè¿ä»ä¸ºæ­¢æå¤§çå¤è¯­è¨åµå¥æ¨¡åè¯ä¼°ä»»å¡éåãä½¿ç¨æ­¤éåï¼æä»¬å¼åäºå ä¸ªé«åº¦å¤è¯­è¨çåºåï¼æä»¬ä½¿ç¨è¿äºåºåæ¥è¯ä¼°ä¸ç»æä»£è¡¨æ§çæ¨¡åãæä»¬åç°ï¼è½ç¶å·ææ°åäº¿ä¸ªåæ°çå¤§è¯­è¨æ¨¡å (LLM) å¯ä»¥å¯¹æäºè¯­è¨å­éåä»»å¡ç±»å«å®ç°æåè¿çæ§è½ï¼ä½æ§è½æä½³çå¬å¼å¯ç¨æ¨¡åæ¯åªæ 5.6 äº¿ä¸ªåæ°çå¤è¯­è¨ e5 å¤§åæä»¤æ¨¡åãä¸ºäºä¾¿äºè®¿é®å¹¶éä½è®¡ç®ææ¬ï¼æä»¬å¼å¥äºä¸ç§åºäºä»»å¡é´ç¸å³æ§çæ°ééæ ·æ¹æ³ï¼ç¡®ä¿å¤æ ·åçéæ©åæ¶ä¿çç¸å¯¹æ¨¡åæåãæ­¤å¤ï¼æä»¬éè¿å¯¹å°é¾çè´æ ·æ¬è¿è¡éæ ·æ¥ä¼åæ£ç´¢ç­ä»»å¡ï¼åå»ºæ´å°ä½ææçæåãè¿äºä¼åä½¿æä»¬è½å¤å¼å¥å¤§å¹éä½è®¡ç®éæ±çåºåãä¾å¦ï¼æä»¬æ°å¼å¥çé¶æ ·æ¬è±è¯­åºåä¿æäºä¸å¨è§æ¨¡çæ¬ç¸ä¼¼çæåé¡ºåºï¼ä½è®¡ç®ææ¬åªæ¯å¶ä¸å°é¨åã

##### **Don't Stop the Multi-Party! On Generating Synthetic Multi-Party Conversations with Constraints**
2502.13592v1 by NicolÃ² Penzo, Marco Guerini, Bruno Lepri, Goran GlavaÅ¡, Sara Tonelli

Multi-Party Conversations (MPCs) are widely studied across disciplines, with
social media as a primary data source due to their accessibility. However,
these datasets raise privacy concerns and often reflect platform-specific
properties. For example, interactions between speakers may be limited due to
rigid platform structures (e.g., threads, tree-like discussions), which yield
overly simplistic interaction patterns (e.g., as a consequence of ``reply-to''
links). This work explores the feasibility of generating diverse MPCs with
instruction-tuned Large Language Models (LLMs) by providing deterministic
constraints such as dialogue structure and participants' stance. We investigate
two complementary strategies of leveraging LLMs in this context: (i.) LLMs as
MPC generators, where we task the LLM to generate a whole MPC at once and (ii.)
LLMs as MPC parties, where the LLM generates one turn of the conversation at a
time, provided the conversation history. We next introduce an analytical
framework to evaluate compliance with the constraints, content quality, and
interaction complexity for both strategies. Finally, we assess the quality of
obtained MPCs via human annotation and LLM-as-a-judge evaluations. We find
stark differences among LLMs, with only some being able to generate
high-quality MPCs. We also find that turn-by-turn generation yields better
conformance to constraints and higher linguistic variability than generating
MPCs in one pass. Nonetheless, our structural and qualitative evaluation
indicates that both generation strategies can yield high-quality MPCs.

æè¦ï¼å¤æ¹å°è©± (MPC) å·²å¨åå­¸ç§å»£æ³ç ç©¶ï¼å¶ä¸­ç¤¾ç¾¤åªé«å å¶ææ¼åå¾èæçºä¸»è¦çè³æä¾æºãç¶èï¼éäºè³æéå¼ç¼äºé±ç§åé¡ï¼ä¸éå¸¸åæ åºç¹å®å¹³å°çç¹æ§ãä¾å¦ï¼ç±æ¼åµåçå¹³å°çµæ§ï¼ä¾å¦ï¼ä¸²è¯ãæ¨¹çè¨è«ï¼ï¼ç¼è¨èä¹éçäºåå¯è½åå°éå¶ï¼éæç¢çéæ¼ç°¡åçäºåæ¨¡å¼ï¼ä¾å¦ï¼ç±æ¼ãåè¦ãé£çµççµæï¼ãæ¬ç ç©¶æ¢è¨äºééæä¾ç¢ºå®æ§çç´ææ¢ä»¶ï¼ä¾å¦ï¼å°è©±çµæ§ååèèçç«å ´ï¼ä¾ç¢çå¤æ¨£å MPC çå¯è¡æ§ï¼ä¸¦èª¿æ´å¤§åèªè¨æ¨¡å (LLM) çæç¤ºãæåç ç©¶äºå¨éç¨®ææ³ä¸å©ç¨ LLM çå©ç¨®äºè£ç­ç¥ï¼(i.) LLM ä½çº MPC ç¢çå¨ï¼æåè¦æ± LLM ä¸æ¬¡ç¢çæ´å MPCï¼ä»¥å (ii.) LLM ä½çº MPC æ¹ï¼å¶ä¸­ LLM å¨æä¾å°è©±è¨éçææ³ä¸ç¢çå°è©±çä¸åååãæ¥ä¸ä¾ï¼æåå¼å¥ä¸ååææ¶æ§ä¾è©ä¼°å©ç¨®ç­ç¥çç´ææ¢ä»¶ãå§å®¹åè³ªåäºåè¤éæ§ãæå¾ï¼æåééäººå·¥è¨»è§£å LLM ä½çºè©å¯©çè©ä¼°ä¾è©ä¼°ç²å¾ç MPC çåè³ªãæåç¼ç¾ LLM ä¹éå­å¨é¡¯èå·®ç°ï¼åªæé¨å LLM è½å¤ ç¢çé«åè³ªç MPCãæåéç¼ç¾ï¼éååç¢çæ¯ä¸æ¬¡ç¢ç MPC æ´ç¬¦åç´ææ¢ä»¶ï¼ä¸èªè¨è®ç°æ§æ´é«ãåç®¡å¦æ­¤ï¼æåççµæ§æ§ååè³ªè©ä¼°è¡¨æï¼å©ç¨®ç¢çç­ç¥é½å¯ä»¥ç¢çé«åè³ªç MPCã

##### **Beyond One-Size-Fits-All: Tailored Benchmarks for Efficient Evaluation**
2502.13576v1 by Peiwen Yuan, Yueqi Zhang, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Jiayi Shi, Chuyi Tan, Boyuan Pan, Yao Hu, Kan Li

Evaluating models on large benchmarks is very resource-intensive, especially
during the period of rapid model evolution. Existing efficient evaluation
methods estimate the performance of target models by testing them only on a
small and static coreset of the benchmark, which is derived from the publicly
available evaluation results of source models. These methods rely on the
assumption that target models have high prediction consistency with source
models. However, we demonstrate that it doesn't generalize well in practice. To
alleviate the inconsistency issue, we present TailoredBench, a method that
conducts customized evaluation tailored to each target model. Specifically, a
Global-coreset is first constructed as a probe to identify the most consistent
source models for each target model with an adaptive source model selection
strategy. Afterwards, a scalable K-Medoids clustering algorithm is proposed to
extend the Global-coreset to a tailored Native-coreset for each target model.
According to the predictions on Native-coresets, we obtain the performance of
target models on the whole benchmark with a calibrated estimation strategy.
Comprehensive experiments on 5 benchmarks across over 300 models demonstrate
that compared to best performing baselines, TailoredBench achieves an average
reduction of 31.4% in MAE of accuracy estimates under the same inference
budgets, showcasing strong effectiveness and generalizability.

æè¦ï¼å¨å¤§ååºåä¸è©ä¼°æ¨¡åéå¸¸èè²»è³æºï¼ç¹å¥æ¯å¨æ¨¡åå¿«éæ¼åçææãç¾æçé«æè©ä¼°æ¹æ³ééåå¨åºæºçå°åä¸éææ ¸å¿éä¸å°ç®æ¨æ¨¡åé²è¡æ¸¬è©¦ä¾ä¼°è¨å¶æè½ï¼æ ¸å¿éåèªå¬éçä¾æºæ¨¡åè©ä¼°çµæãéäºæ¹æ³ä¾è³´æ¼ç®æ¨æ¨¡åèä¾æºæ¨¡åå·æé«åº¦é æ¸¬ä¸è´æ§çåè¨­ãç¶èï¼æåè­æéå¨å¯¦åä¸­ç¡æ³å¾å¥½å°æ¦åãçºäºæ¸è¼ä¸ä¸è´æ§åé¡ï¼æåæåº TailoredBenchï¼éæ¯ä¸ç¨®éå°æ¯åç®æ¨æ¨¡åé²è¡å®¢è£½åè©ä¼°çæ¹æ³ãå·é«ä¾èªªï¼é¦åå»ºæ§ä¸å Global-coreset ä½çºæ¢éï¼ä»¥è­å¥æ¯åç®æ¨æ¨¡åæä¸è´çä¾æºæ¨¡åï¼ä¸¦æ¡ç¨èªé©æä¾æºæ¨¡åé¸æç­ç¥ãä¹å¾ï¼æåºä¸åå¯æ´åç K-Medoids èé¡æ¼ç®æ³ï¼å° Global-coreset å»¶ä¼¸çºæ¯åç®æ¨æ¨¡åçå®¢è£½å Native-coresetãæ ¹æ Native-coreset çé æ¸¬ï¼æåä»¥æ ¡æºçä¼°è¨ç­ç¥åå¾ç®æ¨æ¨¡åå¨æ´ååºæºä¸çæè½ãéå°è¶é 300 åæ¨¡åç 5 ååºæºé²è¡çå¨é¢å¯¦é©è­æï¼èæè½æä½³çåºæºç·ç¸æ¯ï¼TailoredBench å¨ç¸åçæ¨è«é ç®ä¸ï¼æºç¢ºåº¦ä¼°è¨ç MAE å¹³åæ¸å° 31.4%ï¼å±ç¾åºå¼·å¤§çæææ§åæ¦åè½åã

##### **Model Evolution Framework with Genetic Algorithm for Multi-Task Reinforcement Learning**
2502.13569v1 by Yan Yu, Wengang Zhou, Yaodong Yang, Wanxuan Lu, Yingyan Hou, Houqiang Li

Multi-task reinforcement learning employs a single policy to complete various
tasks, aiming to develop an agent with generalizability across different
scenarios. Given the shared characteristics of tasks, the agent's learning
efficiency can be enhanced through parameter sharing. Existing approaches
typically use a routing network to generate specific routes for each task and
reconstruct a set of modules into diverse models to complete multiple tasks
simultaneously. However, due to the inherent difference between tasks, it is
crucial to allocate resources based on task difficulty, which is constrained by
the model's structure. To this end, we propose a Model Evolution framework with
Genetic Algorithm (MEGA), which enables the model to evolve during training
according to the difficulty of the tasks. When the current model is
insufficient for certain tasks, the framework will automatically incorporate
additional modules, enhancing the model's capabilities. Moreover, to adapt to
our model evolution framework, we introduce a genotype module-level model,
using binary sequences as genotype policies for model reconstruction, while
leveraging a non-gradient genetic algorithm to optimize these genotype
policies. Unlike routing networks with fixed output dimensions, our approach
allows for the dynamic adjustment of the genotype policy length, enabling it to
accommodate models with a varying number of modules. We conducted experiments
on various robotics manipulation tasks in the Meta-World benchmark. Our
state-of-the-art performance demonstrated the effectiveness of the MEGA
framework. We will release our source code to the public.

æè¦ï¼å¤ä»»åå¼·åå­¸ç¿æ¡ç¨å®ä¸ç­ç¥ä¾å®æåç¨®ä»»åï¼æ¨å¨å¹é¤åºå¨ä¸åå ´æ¯ä¸­å·ææ³åè½åçä»£çãéæ¼ä»»åçå±åç¹å¾µï¼ä»£ççå­¸ç¿æçå¯ééåæ¸å±äº«ä¾æåãç¾æçæ¹æ³éå¸¸ä½¿ç¨è·¯ç±ç¶²è·¯çºæ¯åä»»åçæç¹å®è·¯ç±ï¼ä¸¦å°ä¸çµæ¨¡çµéå»ºæä¸åçæ¨¡åï¼ä»¥åæå®æå¤é ä»»åãç¶èï¼ç±æ¼ä»»åä¹éçåºæå·®ç°ï¼æ ¹æä»»åé£åº¦åéè³æºè³ééè¦ï¼èéåå°æ¨¡åçµæ§çéå¶ãçºæ­¤ï¼æåæåºäºä¸åå·æéºå³æ¼ç®æ³ (MEGA) çæ¨¡åæ¼åæ¶æ§ï¼å®ä½¿æ¨¡åè½å¤ æ ¹æä»»åçé£åº¦å¨è¨ç·´æéæ¼åãç¶ç®åçæ¨¡åä¸è¶³ä»¥æä»æäºä»»åæï¼è©²æ¶æ§å°èªåç´å¥é¡å¤çæ¨¡çµï¼å¢å¼·æ¨¡åçè½åãæ­¤å¤ï¼çºäºé©ææåçæ¨¡åæ¼åæ¶æ§ï¼æåå¼å¥äºä¸ååºå åæ¨¡çµç´å¥æ¨¡åï¼ä½¿ç¨äºé²ä½åºåä½çºåºå åç­ç¥ä¾é²è¡æ¨¡åéå»ºï¼åæå©ç¨éæ¢¯åº¦éºå³æ¼ç®æ³ä¾æä½³åéäºåºå åç­ç¥ãèå·æåºå®è¼¸åºç¶­åº¦çè·¯ç±ç¶²è·¯ä¸åï¼æåçåæ³åè¨±åæèª¿æ´åºå åç­ç¥é·åº¦ï¼ä½¿å¶è½å¤ å®¹ç´å·æä¸åæ¸éæ¨¡çµçæ¨¡åãæåå¨ Meta-World åºæºä¸­çåç¨®æ©å¨äººæä½ä»»åä¸é²è¡äºå¯¦é©ãæåçææ°æè¡è­æäº MEGA æ¶æ§çæææ§ãæåå°åå¬ç¾ç¼å¸æåçåå§ç¢¼ã

##### **LSR-Adapt: Ultra-Efficient Parameter Tuning with Matrix Low Separation Rank Kernel Adaptation**
2502.13568v1 by Xin Li, Anand Sarwate

Imposing an effective structural assumption on neural network weight matrices
has been the major paradigm for designing Parameter-Efficient Fine-Tuning
(PEFT) systems for adapting modern large pre-trained models to various
downstream tasks. However, low rank based adaptation has become increasingly
challenging due to the sheer scale of modern large language models. In this
paper, we propose an effective kernelization to further reduce the number of
parameters required for adaptation tasks. Specifically, from the classical idea
in numerical analysis regarding matrix Low-Separation-Rank (LSR)
representations, we develop a kernel using this representation for the low rank
adapter matrices of the linear layers from large networks, named the Low
Separation Rank Adaptation (LSR-Adapt) kernel. With the ultra-efficient kernel
representation of the low rank adapter matrices, we manage to achieve
state-of-the-art performance with even higher accuracy with almost half the
number of parameters as compared to conventional low rank based methods. This
structural assumption also opens the door to further GPU-side optimizations due
to the highly parallelizable nature of Kronecker computations.

æè¦ï¼å¨ç¥ç»ç½ç»æéç©éµä¸æ½å ææçç»æåè®¾ä¸ç´æ¯è®¾è®¡åæ°é«æå¾®è° (PEFT) ç³»ç»çä¸»è¦èä¾ï¼ç¨äºå°ç°ä»£å¤§åé¢è®­ç»æ¨¡åéåºå°åç§ä¸æ¸¸ä»»å¡ãç¶èï¼ç±äºç°ä»£å¤§åè¯­è¨æ¨¡åçåºå¤§è§æ¨¡ï¼åºäºä½ç§©çéåºåå¾è¶æ¥è¶å·ææææ§ãå¨æ¬æä¸­ï¼æä»¬æåºäºä¸ç§ææçæ ¸åæ¹æ³ï¼ä»¥è¿ä¸æ­¥åå°éåºä»»å¡æéçââåæ°æ°éãå·ä½æ¥è¯´ï¼ä»æ°å¼åæä¸­å³äºç©éµä½åç¦»ç§© (LSR) è¡¨ç¤ºçç»å¸ææ³åºåï¼æä»¬ä½¿ç¨è¿ç§è¡¨ç¤ºä¸ºå¤§åç½ç»ççº¿æ§å±çä½ç§©ééå¨ç©éµå¼åäºä¸ä¸ªæ ¸ï¼ç§°ä¸ºä½åç¦»ç§©éåº (LSR-Adapt) æ ¸ãéè¿ä½ç§©ééå¨ç©éµçè¶é«ææ ¸è¡¨ç¤ºï¼æä»¬è®¾æ³ä»¥ä¸åºäºä¼ ç»ä½ç§©æ¹æ³ç¸æ¯å ä¹ä¸åçåæ°æ°éå®ç°äºå·ææ´é«ç²¾åº¦çæåè¿æ§è½ãç±äº Kronecker è®¡ç®çé«åº¦å¹¶è¡åç¹æ§ï¼è¿ç§ç»æåè®¾ä¹ä¸ºè¿ä¸æ­¥ç GPU ç«¯ä¼åæå¼äºå¤§é¨ã

##### **Extracting Social Connections from Finnish Karelian Refugee Interviews Using LLMs**
2502.13566v1 by Joonatan Laato, Jenna Kanerva, John Loehr, Virpi Lummaa, Filip Ginter

We performed a zero-shot information extraction study on a historical
collection of 89,339 brief Finnish-language interviews of refugee families
relocated post-WWII from Finnish Eastern Karelia. Our research objective is
two-fold. First, we aim to extract social organizations and hobbies from the
free text of the interviews, separately for each family member. These can act
as a proxy variable indicating the degree of social integration of refugees in
their new environment. Second, we aim to evaluate several alternative ways to
approach this task, comparing a number of generative models and a supervised
learning approach, to gain a broader insight into the relative merits of these
different approaches and their applicability in similar studies.
  We find that the best generative model (GPT-4) is roughly on par with human
performance, at an F-score of 88.8%. Interestingly, the best open generative
model (Llama-3-70B-Instruct) reaches almost the same performance, at 87.7%
F-score, demonstrating that open models are becoming a viable alternative for
some practical tasks even on non-English data. Additionally, we test a
supervised learning alternative, where we fine-tune a Finnish BERT model
(FinBERT) using GPT-4 generated training data. By this method, we achieved an
F-score of 84.1% already with 6K interviews up to an F-score of 86.3% with 30k
interviews. Such an approach would be particularly appealing in cases where the
computational resources are limited, or there is a substantial mass of data to
process.

æè¦ï¼<paragraph>æåå° 89,339 ä»½è¬è­èªç°¡ç­è¨ªè«çæ­·å²è³æé²è¡äºé¶æ¬¡æ½æ¨£è³è¨èåç ç©¶ï¼éäºè¨ªè«ä¾èªäºæ°å¾å¾è¬è­æ±å¡ç´¯å©äºé·ç§»çé£æ°å®¶åº­ãæåçç ç©¶ç®æ¨æå©åé¢åãé¦åï¼æåæ¨å¨å¾è¨ªè«çèªç±ææ¬ä¸­èååºæ¯åå®¶åº­æå¡çç¤¾æçµç¹ååå¥½ãéäºè³æå¯ä»¥ç¨ä½ä»£çè®æ¸ï¼è¡¨ç¤ºé£æ°å¨å¶æ°ç°å¢ä¸­çç¤¾ææ´åç¨åº¦ãå¶æ¬¡ï¼æåæ¨å¨è©ä¼°èçæ­¤ä»»åçå¹¾ç¨®æ¿ä»£æ¹æ³ï¼æ¯è¼å¤ç¨®çææ¨¡ååç£ç£å¼å­¸ç¿æ¹æ³ï¼ä»¥æ´å»£æ³å°äºè§£éäºä¸åæ¹æ³çç¸å°åªé»åå¶å¨é¡ä¼¼ç ç©¶ä¸­çé©ç¨æ§ã
æåç¼ç¾æä½³ççææ¨¡å (GPT-4) èäººé¡è¡¨ç¾å¤§è´ç¸ç¶ï¼F åæ¸çº 88.8%ãæè¶£çæ¯ï¼æä½³çéæ¾çææ¨¡å (Llama-3-70B-Instruct) éå°äºå¹¾ä¹ç¸åçè¡¨ç¾ï¼F åæ¸çº 87.7%ï¼éè­æäºéæ¾æ¨¡åæ­£æçºéè±èªè³æä¸­ä¸äºå¯¦éä»»åçå¯è¡æ¿ä»£æ¹æ¡ãæ­¤å¤ï¼æåæ¸¬è©¦äºä¸ç¨®ç£ç£å¼å­¸ç¿æ¿ä»£æ¹æ¡ï¼å¶ä¸­æåä½¿ç¨ GPT-4 çæçè¨ç·´è³æå¾®èª¿äºè¬è­ BERT æ¨¡å (FinBERT)ãéééç¨®æ¹æ³ï¼æååä½¿ç¨ 6K ä»½è¨ªè«å°±éå°äº 84.1% ç F åæ¸ï¼ä½¿ç¨ 30k ä»½è¨ªè«åéå°äº 86.3% ç F åæ¸ãéç¨®æ¹æ³å¨è¨ç®è³æºæéææå¤§éè³æéè¦èççææ³ä¸ç¹å¥æå¸å¼åã</paragraph>

##### **PRIV-QA: Privacy-Preserving Question Answering for Cloud Large Language Models**
2502.13564v1 by Guangwei Li, Yuansen Zhang, Yinggui Wang, Shoumeng Yan, Lei Wang, Tao Wei

The rapid development of large language models (LLMs) is redefining the
landscape of human-computer interaction, and their integration into various
user-service applications is becoming increasingly prevalent. However,
transmitting user data to cloud-based LLMs presents significant risks of data
breaches and unauthorized access to personal identification information. In
this paper, we propose a privacy preservation pipeline for protecting privacy
and sensitive information during interactions between users and LLMs in
practical LLM usage scenarios. We construct SensitiveQA, the first privacy
open-ended question-answering dataset. It comprises 57k interactions in Chinese
and English, encompassing a diverse range of user-sensitive information within
the conversations. Our proposed solution employs a multi-stage strategy aimed
at preemptively securing user information while simultaneously preserving the
response quality of cloud-based LLMs. Experimental validation underscores our
method's efficacy in balancing privacy protection with maintaining robust
interaction quality. The code and dataset are available at
https://github.com/ligw1998/PRIV-QA.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çå¿«éç¼å±éæ°å®ç¾©äºäººæ©äºåçæ ¼å±ï¼å®åèåç¨®ä½¿ç¨èæåæç¨ç¨å¼æ´åçç¾è±¡ä¹è¶ä¾è¶æ®éãç¶èï¼å°ä½¿ç¨èè³æå³è¼¸å°é²ç«¯ LLM æé æè³æå¤æ´©ååäººè­å¥è³è¨é­å°æªç¶ææ¬å­åçéå¤§é¢¨éªãå¨æ¬æä¸­ï¼æåæåºä¸åé±ç§ä¿è­·ç®¡ç·ï¼ç¨æ¼å¨å¯¦é LLM ä½¿ç¨æå¢ä¸­ä¿è­·ä½¿ç¨èå LLM äºåæçé±ç§åææè³è¨ãæåå»ºæ§äº SensitiveQAï¼éæ¯ç¬¬ä¸åé±ç§éæ¾å¼åç­è³æéãå®åå« 57k åä¸­æåè±æäºåï¼æ¶µèäºå°è©±ä¸­åç¨®ä½¿ç¨èçææè³è¨ãæåæåºçè§£æ±ºæ¹æ¡æ¡ç¨å¤éæ®µç­ç¥ï¼æ¨å¨é åä¿è­·ä½¿ç¨èè³è¨ï¼åæä¿çé²ç«¯ LLM çåæåè³ªãå¯¦é©é©è­å¼·èª¿äºæåçæ¹æ³å¨å¹³è¡¡é±ç§ä¿è­·åç¶­æç©©å¥äºååè³ªæ¹é¢çæè½ãç¨å¼ç¢¼åè³æéå¯å¨ https://github.com/ligw1998/PRIV-QA åå¾ã

##### **Are Large Language Models In-Context Graph Learners?**
2502.13562v1 by Jintang Li, Ruofan Wu, Yuchang Zhu, Huizhe Zhang, Liang Chen, Zibin Zheng

Large language models (LLMs) have demonstrated remarkable in-context
reasoning capabilities across a wide range of tasks, particularly with
unstructured inputs such as language or images. However, LLMs struggle to
handle structured data, such as graphs, due to their lack of understanding of
non-Euclidean structures. As a result, without additional fine-tuning, their
performance significantly lags behind that of graph neural networks (GNNs) in
graph learning tasks. In this paper, we show that learning on graph data can be
conceptualized as a retrieval-augmented generation (RAG) process, where
specific instances (e.g., nodes or edges) act as queries, and the graph itself
serves as the retrieved context. Building on this insight, we propose a series
of RAG frameworks to enhance the in-context learning capabilities of LLMs for
graph learning tasks. Comprehensive evaluations demonstrate that our proposed
RAG frameworks significantly improve LLM performance on graph-based tasks,
particularly in scenarios where a pretrained LLM must be used without
modification or accessed via an API.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨å»£æ³çä»»åä¸­å±ç¤ºäºéå¡çèªå¢æ¨çè½åï¼ç¹å¥æ¯å°æ¼èªè¨æå½±åç­éçµæ§åè¼¸å¥ãç¶èï¼LLM é£ä»¥èççµæ§åè³æï¼ä¾å¦åå½¢ï¼å çºå®åç¡æ³çè§£éæ­å¹¾ä½çµæ§ãå æ­¤ï¼å¨æ²æé¡å¤å¾®èª¿çææ³ä¸ï¼å®åå¨åå½¢å­¸ç¿ä»»åä¸­çè¡¨ç¾é é è½å¾æ¼åå½¢ç¥ç¶ç¶²è·¯ (GNN)ãå¨æ¬æä¸­ï¼æåå±ç¤ºäºå¨åå½¢è³æä¸å­¸ç¿å¯ä»¥è¢«æ¦å¿µåçºæª¢ç´¢å¢å¼·çæ (RAG) éç¨ï¼å¶ä¸­ç¹å®å¯¦ä¾ï¼ä¾å¦ï¼ç¯é»æéï¼åç¶æ¥è©¢ï¼èåå½¢æ¬èº«åä½çºæª¢ç´¢çèªå¢ãåºæ¼éåè¦è§£ï¼æåæåºäºä¸ç³»å RAG æ¶æ§ï¼ä»¥å¢å¼· LLM å¨åå½¢å­¸ç¿ä»»åä¸­çèªå¢å­¸ç¿è½åãå¨é¢çè©ä¼°è¡¨æï¼æåæåºç RAG æ¶æ§é¡¯èæåäº LLM å¨åºæ¼åå½¢çä»»åä¸çè¡¨ç¾ï¼ç¹å¥æ¯å¨é è¨ç·´ç LLM å¿é å¨ä¸ä¿®æ¹æéé API å­åçææ³ä¸ä½¿ç¨çå ´æ¯ä¸­ã

##### **Democratizing Large Language Model-Based Graph Data Augmentation via Latent Knowledge Graphs**
2502.13555v1 by Yushi Feng, Tsai Hor Chan, Guosheng Yin, Lequan Yu

Data augmentation is necessary for graph representation learning due to the
scarcity and noise present in graph data. Most of the existing augmentation
methods overlook the context information inherited from the dataset as they
rely solely on the graph structure for augmentation. Despite the success of
some large language model-based (LLM) graph learning methods, they are mostly
white-box which require access to the weights or latent features from the
open-access LLMs, making them difficult to be democratized for everyone as
existing LLMs are mostly closed-source for commercial considerations. To
overcome these limitations, we propose a black-box context-driven graph data
augmentation approach, with the guidance of LLMs -- DemoGraph. Leveraging the
text prompt as context-related information, we task the LLM with generating
knowledge graphs (KGs), which allow us to capture the structural interactions
from the text outputs. We then design a dynamic merging schema to
stochastically integrate the LLM-generated KGs into the original graph during
training. To control the sparsity of the augmented graph, we further devise a
granularity-aware prompting strategy and an instruction fine-tuning module,
which seamlessly generates text prompts according to different granularity
levels of the dataset. Extensive experiments on various graph learning tasks
validate the effectiveness of our method over existing graph data augmentation
methods. Notably, our approach excels in scenarios involving electronic health
records (EHRs), which validates its maximal utilization of contextual
knowledge, leading to enhanced predictive performance and interpretability.

æè¦ï¼ç±æ¼åè¡¨è³æçç¨å°æ§åéè¨ï¼è³ææ´åå°æ¼åè¡¨è¡¨ç¤ºå­¸ç¿ä¾èªªæ¯å¿è¦çãç¾æçæ´åæ¹æ³å¤§å¤å¿½ç¥äºå¾è³æéä¸­ç¹¼æ¿çèæ¯è³è¨ï¼å çºå®ååä¾è³´æ¼åè¡¨ççµæ§é²è¡æ´åãåç®¡ä¸äºå¤§åèªè¨æ¨¡å (LLM) åºæ¼åè¡¨å­¸ç¿æ¹æ³ç²å¾æåï¼ä½å®åå¤§å¤æ¯ç½çï¼éè¦å­åéæ¾å¼ LLM çæ¬éææ½å¨ç¹å¾µï¼ç±æ¼ç¾æç LLM ä¸»è¦åºæ¼åæ¥­èéèå°éåå§ç¢¼ï¼å æ­¤é£ä»¥è®ææäººé½è½ä½¿ç¨ãçºäºåæéäºéå¶ï¼æåæåºäºä¸åé»çèæ¯é©ååè¡¨è³ææ´åæ¹æ³ï¼å¨ LLM çæå°ä¸ââDemoGraphãå©ç¨æå­æç¤ºä½çºèèæ¯ç¸éçè³è¨ï¼æåè® LLM ç¢çç¥è­åè­ (KG)ï¼éè®æåè½å¤ å¾æå­è¼¸åºä¸­æ·åçµæ§åäºåãç¶å¾ï¼æåè¨­è¨äºä¸ååæåä½µæ¨¡å¼ï¼å¨è¨ç·´æéå° LLM ç¢çç KG é¨æ©æ´åå°åå§åè¡¨ä¸­ãçºäºæ§å¶æ´ååè¡¨çç¨çæ§ï¼æåé²ä¸æ­¥è¨­è¨äºä¸åç²åº¦æç¥æç¤ºç­ç¥åä¸åæä»¤å¾®èª¿æ¨¡çµï¼å®å¯ä»¥æ ¹æè³æéçä¸åç²åº¦å±¤ç´ç¡ç¸«ç¢çæå­æç¤ºãå¨åç¨®åè¡¨å­¸ç¿ä»»åä¸çå¤§éå¯¦é©é©è­äºæåçæ¹æ³æ¯ç¾æçåè¡¨è³ææ´åæ¹æ³æ´ææãå¼å¾æ³¨æçæ¯ï¼æåçåæ³å¨æ¶åé»å­å¥åº·è¨é (EHR) çå ´æ¯ä¸­è¡¨ç¾åºè²ï¼éé©è­äºå®å°ä¸ä¸æç¥è­çæå¤§å©ç¨ï¼å¾èæé«äºé æ¸¬æè½åå¯è§£éæ§ã

##### **STaR-SQL: Self-Taught Reasoner for Text-to-SQL**
2502.13550v1 by Mingqian He, Yongliang Shen, Wenqi Zhang, Qiuying Peng, Jun Wang, Weiming Lu

Generating step-by-step "chain-of-thought" rationales has proven effective
for improving the performance of large language models on complex reasoning
tasks. However, applying such techniques to structured tasks, such as
text-to-SQL, remains largely unexplored. In this paper, we introduce
Self-Taught Reasoner for text-to-SQL (STaR-SQL), a novel approach that reframes
SQL query generation as a reasoning-driven process. Our method prompts the LLM
to produce detailed reasoning steps for SQL queries and fine-tunes it on
rationales that lead to correct outcomes. Unlike traditional methods, STaR-SQL
dedicates additional test-time computation to reasoning, thereby positioning
LLMs as spontaneous reasoners rather than mere prompt-based agents. To further
scale the inference process, we incorporate an outcome-supervised reward model
(ORM) as a verifier, which enhances SQL query accuracy. Experimental results on
the challenging Spider benchmark demonstrate that STaR-SQL significantly
improves text-to-SQL performance, achieving an execution accuracy of 86.6%.
This surpasses a few-shot baseline by 31.6% and a baseline fine-tuned to
predict answers directly by 18.0%. Additionally, STaR-SQL outperforms
agent-like prompting methods that leverage more powerful yet closed-source
models such as GPT-4. These findings underscore the potential of
reasoning-augmented training for structured tasks and open the door to
extending self-improving reasoning models to text-to-SQL generation and beyond.

æè¦ï¼<paragraph>çæéæ­¥çãæç¶­éãè«è¿°å·²è¢«è­å¯¦è½æææ¹åå¤§åèªè¨æ¨¡åå¨è¤éæ¨çä»»åä¸­çè¡¨ç¾ãç¶èï¼å°æ­¤é¡æè¡æç¨æ¼çµæ§åä»»åï¼ä¾å¦æå­è½ SQLï¼ä»é®®å°è¢«æ¢è¨ãå¨æ¬æä¸­ï¼æåä»ç´¹äºæå­è½ SQL çèªå­¸æ¨çå¨ (STaR-SQL)ï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼å° SQL æ¥è©¢çæéæ°å®ç¾©çºä¸åç±æ¨çé©åçéç¨ãæåçæ¨¡åä¿ä½¿ LLM çº SQL æ¥è©¢ç¢çè©³ç´°çæ¨çæ­¥é©ï¼ä¸¦éå°è½ç¢çæ­£ç¢ºçµæçè«è¿°é²è¡å¾®èª¿ãèå³çµ±æ¹æ³ä¸åï¼STaR-SQL å¨æ¸¬è©¦æé¡å¤æå¥éç®è³æºé²è¡æ¨çï¼å æ­¤å° LLM å®ä½çºèªç¼çæ¨çèï¼èéå®ç´åºæ¼æç¤ºçä»£çäººãçºäºé²ä¸æ­¥æ´å¤§æ¨è«éç¨ï¼æåå°çµæç£ç£åé¥æ¨¡å (ORM) ç´å¥å¶ä¸­ä½çºé©è­å¨ï¼ä»¥æå SQL æ¥è©¢çæºç¢ºåº¦ãå¨å·æææ°æ§ç Spider åºæºæ¸¬è©¦ä¸­çå¯¦é©çµæè­æï¼STaR-SQL å¤§å¹æåäºæå­è½ SQL çè¡¨ç¾ï¼å·è¡æºç¢ºåº¦éå° 86.6%ãéæ¯å°æ¬¡å­¸ç¿çåºæºé«åº 31.6%ï¼æ¯ç´æ¥é æ¸¬ç­æ¡çå¾®èª¿åºæºé«åº 18.0%ãæ­¤å¤ï¼STaR-SQL ä¹åªæ¼å©ç¨åè½æ´å¼·å¤§ä½å°éåå§ç¢¼æ¨¡åï¼ä¾å¦ GPT-4ï¼çä»£çæç¤ºæ¹æ³ãéäºç¼ç¾çªé¡¯äºæ¨çå¢å¼·è¨ç·´å¨çµæ§åä»»åä¸­çæ½åï¼ä¸¦çºå°èªææåæ¨çæ¨¡åæ´å±å°æå­è½ SQL çæåå¶ä»é åéåäºå¤§éã</paragraph>

##### **Detecting Linguistic Bias in Government Documents Using Large language Models**
2502.13548v1 by Milena de Swart, Floris den Hengst, Jieying Chen

This paper addresses the critical need for detecting bias in government
documents, an underexplored area with significant implications for governance.
Existing methodologies often overlook the unique context and far-reaching
impacts of governmental documents, potentially obscuring embedded biases that
shape public policy and citizen-government interactions. To bridge this gap, we
introduce the Dutch Government Data for Bias Detection (DGDB), a dataset
sourced from the Dutch House of Representatives and annotated for bias by
experts. We fine-tune several BERT-based models on this dataset and compare
their performance with that of generative language models. Additionally, we
conduct a comprehensive error analysis that includes explanations of the
models' predictions. Our findings demonstrate that fine-tuned models achieve
strong performance and significantly outperform generative language models,
indicating the effectiveness of DGDB for bias detection. This work underscores
the importance of labeled datasets for bias detection in various languages and
contributes to more equitable governance practices.

æè¦ï¼æ¬ææ¢è¨äºåµæ¸¬æ¿åºæä»¶ä¸­çåè¦ä¹éè¦æ§ï¼éæ¯åå½±é¿æ²»ççéä½å°æªååæ¢è¨çé åãç¾ææ¹æ³è«å¸¸å¿½ç¥æ¿åºæä»¶ç¨ç¹çèçµ¡åæ·±é å½±é¿ï¼å¯è½æ¨¡ç³äºå½¢å¡å¬å±æ¿ç­åå¬æ°èæ¿åºäºåçå§å«åè¦ãçºå½è£æ­¤å·®è·ï¼æåå¼å¥äºè·è­åæç¾è­°é¢æä¾è³æä¾æºï¼ä¸¦ç±å°å®¶è¨»è§£åè¦çè·è­æ¿åºåè¦åµæ¸¬è³æ (DGDB)ãæåéå°æ­¤è³æéå¾®èª¿äºå¤ååºæ¼ BERT çæ¨¡åï¼ä¸¦å°å¶æè½èçæèªè¨æ¨¡åçæè½é²è¡æ¯è¼ãæ­¤å¤ï¼æåé²è¡äºå¨é¢çé¯èª¤åæï¼å¶ä¸­åå«æ¨¡åé æ¸¬çèªªæãæåçç ç©¶çµæé¡¯ç¤ºï¼å¾®èª¿æ¨¡åéå°äºå¼·å¤§çæè½ï¼ä¸é¡¯èåªæ¼çæèªè¨æ¨¡åï¼éè¡¨ç¤º DGDB å°æ¼åè¦åµæ¸¬æ¯ææçãéé ç ç©¶å¼·èª¿äºæ¨ç±¤è³æéå°æ¼åç¨®èªè¨çåè¦åµæ¸¬ä¹éè¦æ§ï¼ä¸¦æå©æ¼æ´å¬å¹³çæ²»çå¯¦åã

##### **From Sub-Ability Diagnosis to Human-Aligned Generation: Bridging the Gap for Text Length Control via MARKERGEN**
2502.13544v1 by Peiwen Yuan, Chuyi Tan, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Yueqi Zhang, Jiayi Shi, Boyuan Pan, Yao Hu, Kan Li

Despite the rapid progress of large language models (LLMs), their
length-controllable text generation (LCTG) ability remains below expectations,
posing a major limitation for practical applications. Existing methods mainly
focus on end-to-end training to reinforce adherence to length constraints.
However, the lack of decomposition and targeted enhancement of LCTG
sub-abilities restricts further progress.To bridge this gap, we conduct a
bottom-up decomposition of LCTG sub-abilities with human patterns as reference
and perform a detailed error analysis.On this basis, we propose MarkerGen, a
simple-yet-effective plug-and-play approach that:(1) mitigates LLM fundamental
deficiencies via external tool integration;(2) conducts explicit length
modeling with dynamically inserted markers;(3) employs a three-stage generation
scheme to better align length constraints while maintaining content
quality.Comprehensive experiments demonstrate that MarkerGen significantly
improves LCTG across various settings, exhibiting outstanding effectiveness and
generalizability.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) å¿«éé²å±ï¼å®åçé·åº¦æ§å¶æå­çæ (LCTG) è½åä»ä½æ¼é æï¼å°å¯¦éæç¨é æéå¤§éå¶ãç¾ææ¹æ³ä¸»è¦å°æ³¨æ¼ç«¯å°ç«¯è¨ç·´ï¼ä»¥å å¼·å°é·åº¦éå¶çéµå®ãç¶èï¼ç¼ºä¹åè§£åæéå°æ§çå¢å¼· LCTG æ¬¡è½åï¼éå¶äºé²ä¸æ­¥çé²å±ãçºäºå½è£éåå·®è·ï¼æåä»¥äººé¡æ¨¡å¼çºåèï¼å° LCTG æ¬¡è½åé²è¡èªä¸èä¸çåè§£ï¼ä¸¦å·è¡è©³ç´°çé¯èª¤åæãå¨æ­¤åºç¤ä¸ï¼æåæåº MarkerGenï¼éæ¯ä¸ç¨®ç°¡å®ä½ææçå³æå³ç¨æ¹æ³ï¼(1) ééå¤é¨å·¥å·æ´åï¼æ¸è¼ LLM åºæ¬ç¼ºé·ï¼(2) ä»¥åææå¥æ¨è¨é²è¡æç¢ºçé·åº¦å»ºæ¨¡ï¼(3) æ¡ç¨ä¸éæ®µçææ¹æ¡ï¼å¨ç¶­æå§å®¹åè³ªçåæï¼æ´å¥½å°èª¿æ´é·åº¦éå¶ãç¶åå¯¦é©è¡¨æï¼MarkerGen å¨åç¨®è¨­å®ä¸­é¡¯èæ¹å LCTGï¼å±ç¾åºååºçæææ§åæ¦æ¬æ§ã

##### **Activation-aware Probe-Query: Effective Key-Value Retrieval for Long-Context LLMs Inference**
2502.13542v1 by Qingfa Xiao, Jiachuan Wang, Haoyang Li, Cheng Deng, Jiaqi Tang, Shuangyin Li, Yongqi Zhang, Jun Wang, Lei Chen

Recent advances in large language models (LLMs) have showcased exceptional
performance in long-context tasks, while facing significant inference
efficiency challenges with limited GPU memory. Existing solutions first
proposed the sliding-window approach to accumulate a set of historical
\textbf{key-value} (KV) pairs for reuse, then further improvements selectively
retain its subsets at each step. However, due to the sparse attention
distribution across a long context, it is hard to identify and recall relevant
KV pairs, as the attention is distracted by massive candidate pairs.
Additionally, we found it promising to select representative tokens as
probe-Query in each sliding window to effectively represent the entire context,
which is an approach overlooked by existing methods. Thus, we propose
\textbf{ActQKV}, a training-free, \textbf{Act}ivation-aware approach that
dynamically determines probe-\textbf{Q}uery and leverages it to retrieve the
relevant \textbf{KV} pairs for inference. Specifically, ActQKV monitors a
token-level indicator, Activation Bias, within each context window, enabling
the proper construction of probe-Query for retrieval at pre-filling stage. To
accurately recall the relevant KV pairs and minimize the irrelevant ones, we
design a dynamic KV cut-off mechanism guided by information density across
layers at the decoding stage. Experiments on the Long-Bench and $\infty$
Benchmarks demonstrate its state-of-the-art performance with competitive
inference quality and resource efficiency.

æè¦ï¼<paragraph>å¤§åèªè¨æ¨¡å (LLM) æè¿çé²å±å¨é·èªå¢ä»»åä¸­å±ç¾åºéå¡çæè½ï¼åæä¹é¢è¨æé GPU è¨æ¶é«æé æçéå¤§æ¨è«æçææ°ãç¾æçè§£æ±ºæ¹æ¡é¦åæåºæ»åè¦çªæ¹æ³ä¾ç´¯ç©ä¸çµæ­·å²æ§çãéµå¼ã(KV) å°ä»¥ä¾éè¤ä½¿ç¨ï¼ç¶å¾é²ä¸æ­¥çæ¹é²å¨æ¯åæ­¥é©ä¸­é¸ææ§å°ä¿çå¶å­éãç¶èï¼ç±æ¼å¨é·èªå¢ä¸­ç¨ççæ³¨æååä½ï¼å¾é£è¾¨è­åå¬åç¸éç KV å°ï¼å çºæ³¨æåè¢«å¤§éçåé¸å°åæ£äºãæ­¤å¤ï¼æåç¼ç¾ææå¨æ¯åæ»åè¦çªä¸­é¸æå·ä»£è¡¨æ§çç¬¦èä½çºæ¢æ¸¬æ¥è©¢ï¼ä»¥ææå°è¡¨ç¤ºæ´åèªå¢ï¼éæ¯ä¸ç¨®ç¾ææ¹æ³æå¿½ç¥çæ¹æ³ãå æ­¤ï¼æåæåº ActQKVï¼ä¸ç¨®ç¡éè¨ç·´çãåºæ¼æ´»åçæ¹æ³ï¼å®åæå°æ±ºå®æ¢æ¸¬æ¥è©¢ä¸¦å©ç¨å®ä¾æ·åç¸éç KV å°ä»¥é²è¡æ¨è«ãå·é«ä¾èªªï¼ActQKV æå¨æ¯åèªå¢è¦çªä¸­ç£æ§ç¬¦èå±¤ç´çææ¨ï¼ä¹å°±æ¯æ´»ååå·®ï¼ä»¥ä¾¿å¨é åå¡«å¥éæ®µé©ç¶å°å»ºæ§æ¢æ¸¬æ¥è©¢ä»¥é²è¡æ·åãçºäºæºç¢ºå°å¬åç¸éç KV å°ä¸¦å°ä¸ç¸éç KV å°æ¸å°æå°ï¼æåè¨­è¨äºä¸ååæç KV æªæ·æ©å¶ï¼å¨è§£ç¢¼éæ®µç±è·¨å±¤ç´è³è¨å¯åº¦å¼å°ãå¨ Long-Bench å $\infty$ Benchmarks ä¸çå¯¦é©è­æäºå¶æåé²çæè½ï¼å·æç«¶ç­åçæ¨è«åè³ªåè³æºæçã</paragraph>

##### **Train Small, Infer Large: Memory-Efficient LoRA Training for Large Language Models**
2502.13533v1 by Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Yang You, Guiming Xie, Xuejian Gong, Kunlong Zhou

Large Language Models (LLMs) have significantly advanced natural language
processing with exceptional task generalization capabilities. Low-Rank Adaption
(LoRA) offers a cost-effective fine-tuning solution, freezing the original
model parameters and training only lightweight, low-rank adapter matrices.
However, the memory footprint of LoRA is largely dominated by the original
model parameters. To mitigate this, we propose LoRAM, a memory-efficient LoRA
training scheme founded on the intuition that many neurons in
over-parameterized LLMs have low training utility but are essential for
inference. LoRAM presents a unique twist: it trains on a pruned (small) model
to obtain pruned low-rank matrices, which are then recovered and utilized with
the original (large) model for inference. Additionally, minimal-cost continual
pre-training, performed by the model publishers in advance, aligns the
knowledge discrepancy between pruned and original models. Our extensive
experiments demonstrate the efficacy of LoRAM across various pruning strategies
and downstream tasks. For a model with 70 billion parameters, LoRAM enables
training on a GPU with only 20G HBM, replacing an A100-80G GPU for LoRA
training and 15 GPUs for full fine-tuning. Specifically, QLoRAM implemented by
structured pruning combined with 4-bit quantization, for LLaMA-3.1-70B
(LLaMA-2-70B), reduces the parameter storage cost that dominates the memory
usage in low-rank matrix training by 15.81$\times$ (16.95$\times$), while
achieving dominant performance gains over both the original LLaMA-3.1-70B
(LLaMA-2-70B) and LoRA-trained LLaMA-3.1-8B (LLaMA-2-13B).

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ééåè¶çä»»åæ³åè½åå¤§å¹æåèªç¶èªè¨èçãä½éé©æ (LoRA) æä¾ä¸ç¨®ç¶æ¿å¯¦æ çå¾®èª¿è§£æ±ºæ¹æ¡ï¼åçµåå§æ¨¡ååæ¸ï¼åªè¨ç·´è¼éç´çä½éé©éå¨ç©é£ãç¶èï¼LoRA çè¨æ¶é«ä½ç¨éå¨å¾å¤§ç¨åº¦ä¸åæ±ºæ¼åå§æ¨¡ååæ¸ãçºäºæ¸è¼éç¨®ææ³ï¼æåæåºäº LoRAMï¼éæ¯ä¸ç¨®ä»¥ç´è¦ºçºåºç¤ççè¨æ¶é« LoRA è¨ç·´æ¹æ¡ï¼ç´è¦ºèªçºéåº¦åæ¸åç LLM ä¸­è¨±å¤ç¥ç¶åå¨è¨ç·´ä¸­æç¨ä½ï¼ä½å¨æ¨è«ä¸­å»æ¯å¿è¦çãLoRAM åç¾åºä¸åç¨ç¹çè½æï¼å®å¨ä¸åä¿®åªéçï¼å°ï¼æ¨¡åä¸é²è¡è¨ç·´ï¼ä»¥åå¾ä¿®åªéçä½éç©é£ï¼ç¶å¾å°éäºç©é£å¾©åä¸¦èåå§çï¼å¤§ï¼æ¨¡åä¸èµ·ç¨æ¼æ¨è«ãæ­¤å¤ï¼ç±æ¨¡åç¼å¸èé åå·è¡çæå°ææ¬æçºé è¨ç·´ï¼èª¿æ´äºä¿®åªæ¨¡åååå§æ¨¡åä¹éçç¥è­å·®ç°ãæåå»£æ³çå¯¦é©è­æäº LoRAM å¨åç¨®ä¿®åªç­ç¥åä¸æ¸¸ä»»åä¸­çåæãå°æ¼ä¸åææ 700 åååæ¸çæ¨¡åï¼LoRAM è½å¤ å¨åªæ 20G HBM ç GPU ä¸é²è¡è¨ç·´ï¼åä»£äº LoRA è¨ç·´ç A100-80G GPU åå¾®èª¿ç 15 å GPUãå·é«ä¾èªªï¼ç±çµæ§åä¿®åªè 4 ä½éåçµåå·è¡ç QLoRAMï¼éå° LLaMA-3.1-70Bï¼LLaMA-2-70Bï¼ï¼å°å¨ä½éç©é£è¨ç·´ä¸­ä½æè¨æ¶é«ä½¿ç¨éä¸»å°å°ä½çåæ¸å²å­ææ¬éä½äº 15.81 åï¼16.95 åï¼ï¼åæå¨åå§ LLaMA-3.1-70Bï¼LLaMA-2-70Bï¼å LoRA è¨ç·´ç LLaMA-3.1-8Bï¼LLaMA-2-13Bï¼ä¸ååå¾äºé¡¯èçæè½æåã

##### **Exploiting Prefix-Tree in Structured Output Interfaces for Enhancing Jailbreak Attacking**
2502.13527v1 by Yanzeng Li, Yunfan Xiong, Jialun Zhong, Jinchao Zhang, Jie Zhou, Lei Zou

The rise of Large Language Models (LLMs) has led to significant applications
but also introduced serious security threats, particularly from jailbreak
attacks that manipulate output generation. These attacks utilize prompt
engineering and logit manipulation to steer models toward harmful content,
prompting LLM providers to implement filtering and safety alignment strategies.
We investigate LLMs' safety mechanisms and their recent applications, revealing
a new threat model targeting structured output interfaces, which enable
attackers to manipulate the inner logit during LLM generation, requiring only
API access permissions. To demonstrate this threat model, we introduce a
black-box attack framework called AttackPrefixTree (APT). APT exploits
structured output interfaces to dynamically construct attack patterns. By
leveraging prefixes of models' safety refusal response and latent harmful
outputs, APT effectively bypasses safety measures. Experiments on benchmark
datasets indicate that this approach achieves higher attack success rate than
existing methods. This work highlights the urgent need for LLM providers to
enhance security protocols to address vulnerabilities arising from the
interaction between safety patterns and structured outputs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çèèµ·å¸¶ä¾äºéè¦çæç¨ï¼ä½ä¹å¼å¥äºå´éçå®å¨å¨èï¼ç¹å¥æ¯ä¾èªæç¸±è¼¸åºçæçè¶çæ»æãéäºæ»æå©ç¨æç¤ºå·¥ç¨å logit æç¸±å°æ¨¡åå°åæå®³å§å®¹ï¼ä¿ä½¿ LLM æä¾èå¯¦æ½éæ¿¾åå®å¨å°é½ç­ç¥ãæåèª¿æ¥äº LLM çå®å¨æ©å¶åå¶æè¿çæç¨ï¼æ­ç¤ºäºä¸åéå°çµæ§åè¼¸åºä»é¢çæ°å¨èæ¨¡åï¼å®ä½¿æ»æèè½å¤ å¨ LLM çææéæç¸±å§é¨ logitï¼åªéè¦ API è¨ªåæ¬éãçºäºå±ç¤ºéåå¨èæ¨¡åï¼æåå¼å¥äºä¸ååçº AttackPrefixTree (APT) çé»çæ»ææ¡æ¶ãAPT å©ç¨çµæ§åè¼¸åºä»é¢åææ§å»ºæ»ææ¨¡å¼ãééå©ç¨æ¨¡åå®å¨æçµåæåæ½å¨æå®³è¼¸åºçåç¶´ï¼APT ææå°ç¹éäºå®å¨æªæ½ãå¨åºæºè³æéä¸çå¯¦é©è¡¨æï¼èç¾ææ¹æ³ç¸æ¯ï¼éç¨®æ¹æ³å¯¦ç¾äºæ´é«çæ»ææåçãéé å·¥ä½å¼·èª¿äº LLM æä¾èè¿«åéè¦å¢å¼·å®å¨åè­°ï¼ä»¥è§£æ±ºå®å¨æ¨¡å¼åçµæ§åè¼¸åºä¹éäº¤äºç¢ççæ¼æ´ã

##### **MobileViM: A Light-weight and Dimension-independent Vision Mamba for 3D Medical Image Analysis**
2502.13524v1 by Wei Dai, Steven Wang, Jun Liu

Efficient evaluation of three-dimensional (3D) medical images is crucial for
diagnostic and therapeutic practices in healthcare. Recent years have seen a
substantial uptake in applying deep learning and computer vision to analyse and
interpret medical images. Traditional approaches, such as convolutional neural
networks (CNNs) and vision transformers (ViTs), face significant computational
challenges, prompting the need for architectural advancements. Recent efforts
have led to the introduction of novel architectures like the ``Mamba'' model as
alternative solutions to traditional CNNs or ViTs. The Mamba model excels in
the linear processing of one-dimensional data with low computational demands.
However, Mamba's potential for 3D medical image analysis remains underexplored
and could face significant computational challenges as the dimension increases.
This manuscript presents MobileViM, a streamlined architecture for efficient
segmentation of 3D medical images. In the MobileViM network, we invent a new
dimension-independent mechanism and a dual-direction traversing approach to
incorporate with a vision-Mamba-based framework. MobileViM also features a
cross-scale bridging technique to improve efficiency and accuracy across
various medical imaging modalities. With these enhancements, MobileViM achieves
segmentation speeds exceeding 90 frames per second (FPS) on a single graphics
processing unit (i.e., NVIDIA RTX 4090). This performance is over 24 FPS faster
than the state-of-the-art deep learning models for processing 3D images with
the same computational resources. In addition, experimental evaluations
demonstrate that MobileViM delivers superior performance, with Dice similarity
scores reaching 92.72%, 86.69%, 80.46%, and 77.43% for PENGWIN, BraTS2024,
ATLAS, and Toothfairy2 datasets, respectively, which significantly surpasses
existing models.

æè¦ï¼<paragraph>ææè©ä¼°ä¸ç¶­ (3D) é«å­¸å½±åå°æ¼é«çä¿å¥ä¸­çè¨ºæ·åæ²»çå¯¦åè³ééè¦ãè¿å¹´ä¾ï¼å°æ·±åº¦å­¸ç¿åé»è¦è¦è¦ºæç¨æ¼åæåè©®éé«å­¸å½±åçæç¨å¤§å¹å¢å ãå³çµ±æ¹æ³ï¼ä¾å¦å·ç©ç¥ç¶ç¶²è·¯ (CNN) åè¦è¦ºTransformer (ViT)ï¼é¢è¨éå¤§çéç®ææ°ï¼ä¿ä½¿éè¦æ¶æ§ä¸çé²æ­¥ãæè¿çåªåå·²å°è´å¼é²åµæ°çæ¶æ§ï¼ä¾å¦ãMambaãæ¨¡åï¼ä½çºå³çµ± CNN æ ViT çæ¿ä»£è§£æ±ºæ¹æ¡ãMamba æ¨¡åæé·ä»¥ä½éç®éæ±é²è¡ä¸ç¶­è³æçç·æ§èçãç¶èï¼Mamba å¨ 3D é«å­¸å½±ååææ¹é¢çæ½åä»æªè¢«ååæ¢ç´¢ï¼ä¸¦ä¸é¨èç¶­åº¦çå¢å å¯è½æé¢è¨éå¤§çéç®ææ°ãæ¬æç¨¿æåº MobileViMï¼éæ¯ä¸ç¨®ç°¡åçæ¶æ§ï¼å¯ææåå² 3D é«å­¸å½±åãå¨ MobileViM ç¶²è·¯ä¸­ï¼æåç¼æäºä¸ç¨®æ°çèç¶­åº¦ç¡éçæ©å¶åéåéæ­·æ¹æ³ï¼ä»¥èåºæ¼è¦è¦º Mamba çæ¶æ§çµåãMobileViM éå·åè·¨å°ºåº¦æ©æ¥æè¡ï¼ä»¥æé«åç¨®é«å­¸å½±åæ¨¡å¼çæçåæºç¢ºæ§ãéééäºå¢å¼·åè½ï¼MobileViM å¨å®ä¸é¡¯ç¤ºå¡ (å³ NVIDIA RTX 4090) ä¸éå°äºæ¯ç§è¶é 90 å¹ (FPS) çåå²éåº¦ãæ­¤æè½æ¯ç¾ææåé²çæ·±åº¦å­¸ç¿æ¨¡åå¿«äºè¶é 24 FPSï¼éäºæ¨¡åä½¿ç¨ç¸åçéç®è³æºèç 3D å½±åãæ­¤å¤ï¼å¯¦é©è©ä¼°è­æ MobileViM æä¾äºåè¶çæè½ï¼Dice ç¸ä¼¼æ§è©åå°æ¼ PENGWINãBraTS2024ãATLAS å Toothfairy2 è³æéåå¥éå° 92.72%ã86.69%ã80.46% å 77.43%ï¼é¡¯èè¶è¶ç¾ææ¨¡åã</paragraph>

##### **A Large and Balanced Corpus for Fine-grained Arabic Readability Assessment**
2502.13520v1 by Khalid N. Elmadani, Nizar Habash, Hanada Taha-Thomure

This paper introduces the Balanced Arabic Readability Evaluation Corpus
BAREC, a large-scale, fine-grained dataset for Arabic readability assessment.
BAREC consists of 68,182 sentences spanning 1+ million words, carefully curated
to cover 19 readability levels, from kindergarten to postgraduate
comprehension. The corpus balances genre diversity, topical coverage, and
target audiences, offering a comprehensive resource for evaluating Arabic text
complexity. The corpus was fully manually annotated by a large team of
annotators. The average pairwise inter-annotator agreement, measured by
Quadratic Weighted Kappa, is 81.3%, reflecting a high level of substantial
agreement. Beyond presenting the corpus, we benchmark automatic readability
assessment across different granularity levels, comparing a range of
techniques. Our results highlight the challenges and opportunities in Arabic
readability modeling, demonstrating competitive performance across various
methods. To support research and education, we will make BAREC openly
available, along with detailed annotation guidelines and benchmark results.

æè¦ï¼æ¬æä»ç´¹äºå¹³è¡¡é¿æä¼¯èªå¯è®æ§è©ä¼°èªæåº« (BAREC)ï¼éæ¯ä¸åéå°é¿æä¼¯èªå¯è®æ§è©ä¼°çå¤§è¦æ¨¡ãç´°ç²åº¦çè³æéã
BAREC åå« 68,182 åå¥å­ï¼è·¨è¶ 100 å¤è¬åå­è©ï¼ç¶éä»ç´°ç­åï¼æ¶µèå¾å¹¼ç¨åå°ç ç©¶æç¨åº¦ç 19 åå¯è®æ§ç­ç´ãèªæåº«å¹³è¡¡äºé«è£çå¤æ¨£æ§ãä¸»é¡çæ¶µèç¯ååç®æ¨åç¾ï¼æä¾äºä¸åå¨é¢çè³æºï¼ç¨æ¼è©ä¼°é¿æä¼¯èªææ¬çè¤éæ§ãèªæåº«ç±ä¸åé¾å¤§çè¨»è§£å°çµå®å¨æåè¨»è§£ãç±äºæ¬¡å æ¬ Kappa æ¸¬éçå¹³åæå°è¨»è§£èéä¸è´æ§çº 81.3%ï¼åæ åºé«åº¦çå¯¦è³ªæ§ä¸è´æ§ãé¤äºåç¾èªæåº«ä¹å¤ï¼æåéæ¯è¼äºä¸ç³»åæè¡ï¼å°ä¸åç²åº¦å±¤ç´çèªåå¯è®æ§è©ä¼°é²è¡åºæºæ¸¬è©¦ãæåççµæçªåºäºé¿æä¼¯èªå¯è®æ§å»ºæ¨¡ä¸­çææ°åæ©æï¼å±ç¤ºäºåç¨®æ¹æ³çç«¶ç­æ§è½ãçºäºæ¯æç ç©¶åæè²ï¼æåå°éæ¾ BARECï¼ä¸¦æä¾è©³ç´°çè¨»è§£æåååºæºæ¸¬è©¦çµæã

##### **MILE: Model-based Intervention Learning**
2502.13519v1 by Yigit Korkmaz, Erdem BÄ±yÄ±k

Imitation learning techniques have been shown to be highly effective in
real-world control scenarios, such as robotics. However, these approaches not
only suffer from compounding error issues but also require human experts to
provide complete trajectories. Although there exist interactive methods where
an expert oversees the robot and intervenes if needed, these extensions usually
only utilize the data collected during intervention periods and ignore the
feedback signal hidden in non-intervention timesteps. In this work, we create a
model to formulate how the interventions occur in such cases, and show that it
is possible to learn a policy with just a handful of expert interventions. Our
key insight is that it is possible to get crucial information about the quality
of the current state and the optimality of the chosen action from expert
feedback, regardless of the presence or the absence of intervention. We
evaluate our method on various discrete and continuous simulation environments,
a real-world robotic manipulation task, as well as a human subject study.
Videos and the code can be found at https://liralab.usc.edu/mile .

æè¦ï¼æ¨¡ä»¿å­¸ç¿æè¡å·²è¢«è­æå¨ç¾å¯¦ä¸ççæ§å¶å ´æ¯ä¸­éå¸¸ææï¼ä¾å¦æ©å¨äººæè¡ãç¶èï¼éäºæ¹æ³ä¸åæç¢çè¤åé¯èª¤åé¡ï¼ééè¦äººé¡å°å®¶æä¾å®æ´çè»è·¡ãåç®¡å­å¨äº¤äºå¼æ¹æ³ï¼å°å®¶å¯ä»¥å¨éè¦æç£ç£æ©å¨äººåé²è¡å¹²é ï¼ä½éäºæ´å±éå¸¸åªå©ç¨å¹²é æéæ¶éçæ¸æï¼èå¿½ç¥éå¹²é æéæ­¥é·ä¸­é±èçåé¥ä¿¡èãå¨éé å·¥ä½ä¸­ï¼æååµå»ºäºä¸åæ¨¡åä¾å¶å®å¨éç¨®ææ³ä¸å¦ä½é²è¡å¹²é ï¼ä¸¦è¡¨æåæèå°æ¸å°å®¶å¹²é å°±å¯ä»¥å­¸ç¿ä¸é ç­ç¥ãæåçééµè¦è§£æ¯ï¼ç¡è«æ¯å¦å­å¨å¹²é ï¼é½å¯ä»¥å¾å°å®¶åé¥ä¸­ç²å¾æéç¶åçæè³ªéåæé¸åä½æåªæ§çééµä¿¡æ¯ãæåå¨åç¨®é¢æ£åé£çºæ¨¡æ¬ç°å¢ãä¸åçå¯¦ä¸ççæ©å¨äººæä½ä»»åä»¥åä¸é äººé¡ä¸»é«ç ç©¶ä¸­è©ä¼°äºæåççæ¹æ³ãå¯ä»¥å¨ https://liralab.usc.edu/mile æ¾å°å½±çåç¨å¼ç¢¼ã

##### **SPPD: Self-training with Process Preference Learning Using Dynamic Value Margin**
2502.13516v1 by Hao Yi, Qingyang Li, Yulan Hu, Fuzheng Zhang, Di Zhang, Yong Liu

Recently, enhancing the numerical and logical reasoning capability of Large
Language Models (LLMs) has emerged as a research hotspot. Existing methods face
several limitations: inference-phase techniques (e.g., Chain of Thoughts) rely
on prompt selection and the pretrained knowledge; sentence-level Supervised
Fine-Tuning (SFT) and Direct Preference Optimization (DPO) struggle with
step-wise mathematical correctness and depend on stronger models distillation
or human annotations; while Reinforcement Learning (RL) approaches incur high
GPU memory costs and unstable training. To address these, we propose
\textbf{S}elf-training framework integrating \textbf{P}rocess
\textbf{P}reference learning using \textbf{D}ynamic value margin (SPPD). SPPD
leverages a process-based Markov Decision Process (MDP) and Bellman optimality
equation to derive \textbf{dynamic value margin} on step-level preference
optimization, which employs tree-based self-sampling on model responses
\textbf{without any distillation} from other models. Furthermore, we
theoretically prove that SPPD is \textbf{equivalent to on-policy policy
gradient methods} under reward constraints. Experiments on 7B-scale models
demonstrate superior performance across in-domain and out-domain mathematical
benchmarks. We open-source our code at
\href{https://anonymous.4open.science/r/SSDPO-D-DCDD}{https://anonymous.4open.science/r/SPPD-DCDD}.

æè¦ï¼<paragraph>è¿æï¼å¢å¼ºå¤§åè¯­è¨æ¨¡å (LLM) çæ°å­åé»è¾æ¨çè½åå·²æä¸ºç ç©¶ç­ç¹ãç°ææ¹æ³é¢ä¸´çä¸äºéå¶ï¼æ¨çé¶æ®µææ¯ï¼ä¾å¦ææ³é¾ï¼ä¾èµäºæç¤ºéæ©åé¢è®­ç»ç¥è¯ï¼å¥å­çº§å«ççç£å¾®è° (SFT) åç´æ¥åå¥½ä¼å (DPO) é¾ä»¥å®ç°éæ­¥çæ°å­¦æ­£ç¡®æ§ï¼å¹¶ä¸ä¾èµäºæ´å¼ºçæ¨¡åè¸é¦æäººå·¥æ³¨éï¼èå¼ºåå­¦ä¹  (RL) æ¹æ³ä¼äº§çé« GPU åå­ææ¬åä¸ç¨³å®çè®­ç»ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬æåºäºå°åºäºè¿ç¨çåå¥½å­¦ä¹ ä¸å¨æå¼è¾¹é (SPPD) ç¸ç»åçèªæè®­ç»æ¡æ¶ãSPPD å©ç¨åºäºè¿ç¨çé©¬å°å¯å¤«å³ç­è¿ç¨ (MDP) åè´å°æ¼æä¼æ§æ¹ç¨ï¼å¨æ­¥éª¤çº§åå¥½ä¼åä¸­æ¨å¯¼åºå¨æå¼è¾¹éï¼è¯¥è¾¹éå¨æ¨¡åååºä¸éç¨åºäºæ çèªéæ ·ï¼èæ éä»å¶ä»æ¨¡åä¸­è¿è¡ä»»ä½è¸é¦ãæ­¤å¤ï¼æä»¬ä»çè®ºä¸è¯æäº SPPD å¨å¥å±çº¦æä¸ç­æäºç­ç¥æ¢¯åº¦æ³ãå¨ 7B çº§æ¨¡åä¸çå®éªè¡¨æï¼å¨ååååå¤æ°å­¦åºåæµè¯ä¸­é½åå¾äºåè¶çæ§è½ãæä»¬å¨
\href{https://anonymous.4open.science/r/SSDPO-D-DCDD}{https://anonymous.4open.science/r/SPPD-DCDD} ä¸å¼æºäºæä»¬çä»£ç ã</paragraph>

##### **Shall Your Data Strategy Work? Perform a Swift Study**
2502.13514v1 by Minlong Peng, Jingyi Yang, Zhongjun He, Hua Wu

This work presents a swift method to assess the efficacy of particular types
of instruction-tuning data, utilizing just a handful of probe examples and
eliminating the need for model retraining. This method employs the idea of
gradient-based data influence estimation, analyzing the gradient projections of
probe examples from the chosen strategy onto evaluation examples to assess its
advantages. Building upon this method, we conducted three swift studies to
investigate the potential of Chain-of-thought (CoT) data, query clarification
data, and response evaluation data in enhancing model generalization.
Subsequently, we embarked on a validation study to corroborate the findings of
these swift studies. In this validation study, we developed training datasets
tailored to each studied strategy and compared model performance with and
without the use of these datasets. The results of the validation study aligned
with the findings of the swift studies, validating the efficacy of our proposed
method.

æè¦ï¼æ¬ç ç©¶æåºäºä¸ç¨®å¿«éçæ¹æ³ä¾è©ä¼°ç¹å®é¡åæä»¤èª¿æ´è³æçæè½ï¼åä½¿ç¨å°æ¸æ¢æ¸¬ç¯ä¾ï¼ä¸¦æ¶é¤éæ°è¨ç·´æ¨¡åçéè¦ãæ­¤æ¹æ³æ¡ç¨åºæ¼æ¢¯åº¦çè³æå½±é¿ä¼°è¨æ¦å¿µï¼åæå¾æé¸ç­ç¥ä¸­æ¢æ¸¬ç¯ä¾çæ¢¯åº¦æå½±ï¼å°è©ä¼°ç¯ä¾ï¼ä»¥è©ä¼°å¶åªé»ãå¨æ­¤æ¹æ³çåºç¤ä¸ï¼æåé²è¡äºä¸é å¿«éç ç©¶ï¼ä»¥æ¢è¨ææ³é (CoT) è³æãæ¥è©¢æ¾æ¸è³æååæè©ä¼°è³æå¨å¢å¼·æ¨¡åæ¦æ¬åä¸­çæ½åãé¨å¾ï¼æåèæé²è¡é©è­ç ç©¶ï¼ä»¥é©è­éäºå¿«éç ç©¶çç¼ç¾ãå¨é©è­ç ç©¶ä¸­ï¼æåéç¼äºéå°æ¯åç ç©¶ç­ç¥éèº«å®å¶çè¨ç·´è³æéï¼ä¸¦æ¯è¼äºä½¿ç¨åä¸ä½¿ç¨éäºè³æéçæ¨¡åæè½ãé©è­ç ç©¶ççµæèå¿«éç ç©¶çç¼ç¾ä¸è´ï¼é©è­äºæåæåºçæ¹æ³çæææ§ã

##### **Unlocking Multimodal Integration in EHRs: A Prompt Learning Framework for Language and Time Series Fusion**
2502.13509v1 by Shuai Niu, Jing Ma, Hongzhan Lin, Liang Bai, Zhihua Wang, Wei Bi, Yida Xu, Guo Li, Xian Yang

Large language models (LLMs) have shown remarkable performance in
vision-language tasks, but their application in the medical field remains
underexplored, particularly for integrating structured time series data with
unstructured clinical notes. In clinical practice, dynamic time series data
such as lab test results capture critical temporal patterns, while clinical
notes provide rich semantic context. Merging these modalities is challenging
due to the inherent differences between continuous signals and discrete text.
To bridge this gap, we introduce ProMedTS, a novel self-supervised multimodal
framework that employs prompt-guided learning to unify these heterogeneous data
types. Our approach leverages lightweight anomaly detection to generate anomaly
captions that serve as prompts, guiding the encoding of raw time series data
into informative embeddings. These embeddings are aligned with textual
representations in a shared latent space, preserving fine-grained temporal
nuances alongside semantic insights. Furthermore, our framework incorporates
tailored self-supervised objectives to enhance both intra- and inter-modal
alignment. We evaluate ProMedTS on disease diagnosis tasks using real-world
datasets, and the results demonstrate that our method consistently outperforms
state-of-the-art approaches.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å¨è¦è¦ºèªè¨ä»»åä¸­è¡¨ç¾åºè²ï¼ä½å¶å¨é«çé åçæç¨ä»æªå¾å°ååæ¢ç´¢ï¼ç¹å¥æ¯å¨å°çµæ§åæéåºåæ¸æèéçµæ§åè¨åºç­è¨æ´åæ¹é¢ãå¨è¨åºå¯¦åä¸­ï¼åææéåºåæ¸æï¼ä¾å¦å¯¦é©å®¤æª¢é©çµæï¼ææ·åééµçæéæ¨¡å¼ï¼èè¨åºç­è¨åæä¾è±å¯çèªæèçµ¡ãç±æ¼é£çºè¨èèé¢æ£æå­ä¹éçåºæå·®ç°ï¼åä½µéäºæ¹å¼å·æææ°æ§ãçºäºå½è£éåå·®è·ï¼æåå¼å¥äº ProMedTSï¼éæ¯ä¸åæ°ç©çèªç£ç£å¤æ¨¡ææ¡æ¶ï¼æ¡ç¨æç¤ºå¼å°å­¸ç¿ä¾çµ±ä¸éäºç°è³ªåçæ¸æé¡åãæåçåæ³å©ç¨è¼éç´ç°å¸¸åµæ¸¬ä¾ç¢çç°å¸¸æ¨é¡ï¼ä½çºæç¤ºï¼å¼å°å°åå§æéåºåæ¸æç·¨ç¢¼æè³è¨æ§çåµå¥ãéäºåµå¥èå±äº«æ½å¨ç©ºéä¸­çæå­è¡¨ç¤ºå°é½ï¼åæä¿çç´°å¾®çæéå·®ç°åèªæè¦è§£ãæ­¤å¤ï¼æåçæ¡æ¶ç´å¥äºå®¢è£½åçèªç£ç£ç®æ¨ï¼ä»¥å¢å¼·æ¨¡æå§åæ¨¡æéå°é½ãæåå¨ç¾çè¨ºæ·ä»»åä¸­ä½¿ç¨çå¯¦ä¸ççæ¸æéè©ä¼° ProMedTSï¼çµæè¡¨æï¼æåçæ¨¡åå§çµåªæ¼æåé²çæ¹æ³ã

##### **PLDR-LLMs Learn A Generalizable Tensor Operator That Can Replace Its Own Deep Neural Net At Inference**
2502.13502v1 by Burc Gokden

We show that Large Language Model from Power Law Decoder Representations
(PLDR-LLM) is a foundational model whose deductive outputs are invariant
tensors up to a small perturbation. PLDR-LLM learns a singularity condition for
the deductive outputs that enable the once-inferred energy-curvature tensor
$\mathbf{G}_{LM}$ to replace the deep neural network of power law graph
attention (PLGA) generating the deductive outputs at inference. We demonstrate
that a cache for $\mathbf{G}_{LM}$ (G-cache) and KV-cache can be implemented in
a straightforward manner to improve the inference time. The invariance and
generalizable nature of deductive outputs is at a very high fidelity where
deductive outputs have same RMSE and determinant values up to 15 decimal places
after caching, and zero-shot benchmark scores remain unchanged. Ablation
studies show that learned deductive outputs have distinct loss and accuracy
characteristics from models pretrained with transferred, randomly initialized
or identity tensors as a constant tensor operator and an LLM with scaled-dot
product attention (SDPA) is a special case of PLDR-LLM where $\mathbf{G}_{LM}$
is predefined as identity. The observed invariance characteristic introduces a
novel asymmetry between training and inference phases with caching. We outline
observed common characteristics of the deductive outputs for the learned
singularity condition. We provide an implementation of a training and inference
framework for PLDR-LLM with KV-cache and G-cache.

æè¦ï¼<paragraph>æåå±ç¤ºäºä¾èªåªå¾è§£ç¢¼å¨è¡¨ç¤º (PLDR-LLM) çå¤§åèªè¨æ¨¡åæ¯ä¸ååºç¤æ¨¡åï¼å¶æ¼ç¹¹è¼¸åºæ¯ç´å°ä¸åå°æ¾åçä¸è®å¼µéãPLDR-LLM å­¸ç¿æ¼ç¹¹è¼¸åºçå¥ç°æ¢ä»¶ï¼ä½¿æ¾ç¶æ¨æ·åºçè½éæ²çå¼µé $\mathbf{G}_{LM}$ è½å¤ åä»£ç¢çæ¼ç¹¹è¼¸åºçåªå¾åæ³¨æå (PLGA) æ·±åº¦ç¥ç¶ç¶²è·¯ï¼é²è¡æ¨è«ãæåè­æäº $\mathbf{G}_{LM}$ å¿«å (G å¿«å) å KV å¿«åè½å¤ ä»¥ä¸ç¨®ç´æ¥çæ¹å¼å¯¦ä½ï¼ä»¥æ¹åæ¨è«æéãæ¼ç¹¹è¼¸åºçä¸è®æ§åå¯æ¦åæ§è³ªå·æéå¸¸é«çä¿çåº¦ï¼å¶ä¸­æ¼ç¹¹è¼¸åºå¨å¿«åå¾å·æç¸åç RMSE åè¡åå¼å¼ï¼ç´å°å°æ¸é»å¾ 15 ä½ï¼ä¸é¶æ¬¡å­¸ç¿åºæºåæ¸ä¿æä¸è®ãæ¶èç ç©¶è¡¨æï¼å­¸ç¿çæ¼ç¹¹è¼¸åºå·æèä½¿ç¨è½ç§»ãé¨æ©åå§åææç­å¼µéä½çºå¸¸æ¸å¼µéç®å­åå·æç¸®æ¾é»ç©æ³¨æåç LLM é åè¨ç·´çæ¨¡åä¸åçæå¤±åæºç¢ºæ§ç¹å¾µï¼ä¸¦ä¸ $\mathbf{G}_{LM}$ è¢«é åå®ç¾©çºæç­ç PLDR-LLM çä¸åç¹ä¾ï¼å¶ä¸­ $\mathbf{G}_{LM}$ è¢«é åå®ç¾©çºæç­ãè§å¯å°çä¸è®ç¹å¾µå¼å¥äºè¨ç·´åæ¨è«éæ®µä¹éä¸åæ°çä¸å°ç¨±æ§ï¼ä¸¦å¸¶æå¿«åãæåæ¦è¿°äºå­¸ç¿çå¥ç°æ¢ä»¶æ¼ç¹¹è¼¸åºçè§å¯å°çå±åç¹å¾µãæåæä¾äºä¸åå·æ KV å¿«åå G å¿«åç PLDR-LLM è¨ç·´åæ¨è«æ¡æ¶çå¯¦ä½ã</paragraph>

##### **Hidden Darkness in LLM-Generated Designs: Exploring Dark Patterns in Ecommerce Web Components Generated by LLMs**
2502.13499v1 by Ziwei Chen, Jiawen Shen, Luna, Kristen Vaccaro

Recent work has highlighted the risks of LLM-generated content for a wide
range of harmful behaviors, including incorrect and harmful code. In this work,
we extend this by studying whether LLM-generated web design contains dark
patterns. This work evaluated designs of ecommerce web components generated by
four popular LLMs: Claude, GPT, Gemini, and Llama. We tested 13 commonly used
ecommerce components (e.g., search, product reviews) and used them as prompts
to generate a total of 312 components across all models. Over one-third of
generated components contain at least one dark pattern. The majority of dark
pattern strategies involve hiding crucial information, limiting users' actions,
and manipulating them into making decisions through a sense of urgency. Dark
patterns are also more frequently produced in components that are related to
company interests. These findings highlight the need for interventions to
prevent dark patterns during front-end code generation with LLMs and emphasize
the importance of expanding ethical design education to a broader audience.

æè¦ï¼è¿æç ç©¶å¼·èª¿åº LLM çæçå§å®¹å°æ¼åç¨®æå®³è¡çºçé¢¨éªï¼åæ¬ä¸æ­£ç¢ºä¸æå®³çç¨å¼ç¢¼ãå¨éé ç ç©¶ä¸­ï¼æåééæ¢è¨ LLM çæçç¶²é è¨­è¨æ¯å¦åå«æ¡ææ¨¡å¼ä¾å»¶ä¼¸éé ç ç©¶ãéé ç ç©¶è©ä¼°äºç±åç¨®å¸¸è¦ LLM çæçé»å­ååç¶²é åä»¶è¨­è¨ï¼ClaudeãGPTãGemini å Llamaãæåæ¸¬è©¦äº 13 åå¸¸ç¨çé»å­åååä»¶ï¼ä¾å¦æå°ãç¢åè©è«ï¼ï¼ä¸¦å°å®åç¨ä½æç¤ºï¼å¨æææ¨¡åä¸­ç¸½å±ç¢çäº 312 ååä»¶ãè¶éä¸åä¹ä¸çå·²çæåä»¶åå«è³å°ä¸åæ¡ææ¨¡å¼ãå¤§å¤æ¸æ¡ææ¨¡å¼ç­ç¥æ¶åé±èééµè³è¨ãéå¶ä½¿ç¨èçæä½ï¼ä»¥åééæ¥è¿«ææç¸±ä»åååºæ±ºå®ãæ¡ææ¨¡å¼ä¹æ´å¸¸åºç¾å¨èå¬å¸å©çç¸éçåä»¶ä¸­ãéäºç¼ç¾å¼·èª¿äºå¨ LLM åç«¯ç¨å¼ç¢¼ç¢çæéé é²æ¡ææ¨¡å¼çå¹²é æªæ½çå¿è¦æ§ï¼ä¸¦å¼·èª¿å°éå¾·è¨­è¨æè²æ´å±å°æ´å»£æ³åç¾çéè¦æ§ã

##### **Towards Geo-Culturally Grounded LLM Generations**
2502.13497v1 by Piyawat Lertvittayakumjorn, David Kinney, Vinodkumar Prabhakaran, Donald Martin, Sunipa Dev

Generative large language models (LLMs) have been demonstrated to have gaps
in diverse, cultural knowledge across the globe. We investigate the effect of
retrieval augmented generation and search-grounding techniques on the ability
of LLMs to display familiarity with a diverse range of national cultures.
Specifically, we compare the performance of standard LLMs, LLMs augmented with
retrievals from a bespoke knowledge base (i.e., KB grounding), and LLMs
augmented with retrievals from a web search (i.e., search grounding) on a
series of cultural familiarity benchmarks. We find that search grounding
significantly improves the LLM performance on multiple-choice benchmarks that
test propositional knowledge (e.g., the norms, artifacts, and institutions of
national cultures), while KB grounding's effectiveness is limited by inadequate
knowledge base coverage and a suboptimal retriever. However, search grounding
also increases the risk of stereotypical judgments by language models, while
failing to improve evaluators' judgments of cultural familiarity in a human
evaluation with adequate statistical power. These results highlight the
distinction between propositional knowledge about a culture and open-ended
cultural fluency when it comes to evaluating the cultural familiarity of
generative LLMs.

æè¦ï¼çæå¼å¤§åè¯­è¨æ¨¡åï¼LLMï¼å·²è¢«è¯æå¨å¨çèå´åå­å¨æåç¥è¯æ¹é¢çå·®è·ãæä»¬è°æ¥äºæ£ç´¢å¢å¼ºçæåæç´¢åºç¡ææ¯å¯¹ LLM å±ç¤ºå¯¹åç§å½å®¶æåçæç¨åº¦çè½åçå½±åãå·ä½æ¥è¯´ï¼æä»¬æ¯è¾äºæ å LLMãä½¿ç¨æ¥èªå®å¶ç¥è¯åºï¼å³ KB åºç¡ï¼çæ£ç´¢å¢å¼º LLM åä½¿ç¨æ¥èªç½ç»æç´¢ï¼å³æç´¢åºç¡ï¼çæ£ç´¢å¢å¼º LLM å¨ä¸ç³»åæåçæåºåä¸çæ§è½ãæä»¬åç°ï¼æç´¢åºç¡æ¾çæé«äº LLM å¨æµè¯å½é¢ç¥è¯ï¼ä¾å¦ï¼å½å®¶æåçè§èãäººå·¥å¶ååå¶åº¦ï¼çå¤é¡¹éæ©åºåä¸çæ§è½ï¼è KB åºç¡çæææ§åå°ç¥è¯åºè¦çä¸è¶³åæ£ç´¢å¨æ¬ ä½³çéå¶ãç¶èï¼æç´¢åºç¡ä¹å¢å äºè¯­è¨æ¨¡åäº§çå»æ¿å°è±¡å¤æ­çé£é©ï¼åæ¶æªè½æé«è¯ä¼°èå¨å·æè¶³å¤ç»è®¡è½åçäººç±»è¯ä¼°ä¸­å¯¹æåçæç¨åº¦çå¤æ­ãè¿äºç»æçªåºäºå¨è¯ä¼°çæå¼ LLM çæåçæåº¦æ¶ï¼å³äºæåçå½é¢ç¥è¯åå¼æ¾å¼æåæµçæ§ä¹é´çåºå«ã

