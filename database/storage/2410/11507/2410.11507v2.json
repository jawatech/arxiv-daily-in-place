{"2410.11507": {"publish_time": "2024-10-15", "title": "Revisiting Benchmark and Assessment: An Agent-based Exploratory Dynamic Evaluation Framework for LLMs", "paper_summary": "While various vertical domain large language models (LLMs) have been\ndeveloped, the challenge of automatically evaluating their performance across\ndifferent domains remains significant. Current benchmark-based evaluation\nmethods exhibit rigid, aimless interactions and rely on pre-collected static\ndatasets that are costly to build, inflexible across domains, and misaligned\nwith practical user needs. To address this issue, we revisit the evaluation\ncomponents and introduce two concepts: Benchmark+, which extends traditional\nquestion-answer benchmark into a more flexible \"strategy-criterion\" format; and\nAssessment+, which enhances the interaction process, enabling deeper\nexploration and supporting both quantitative metrics and qualitative insights.\nThese concepts capture the nuanced behaviors of LLMs through richer, multi-turn\ninteractions. We propose an agent-based evaluation framework called TestAgent,\nwhich implements these concepts through retrieval augmented generation and\nreinforcement learning. Experiments on tasks ranging from constructing vertical\ndomain evaluation to activating existing benchmarks demonstrate the\neffectiveness of TestAgent across various scenarios. We believe this work\noffers an interesting perspective on automatic evaluation for LLMs.", "paper_summary_zh": "\u5118\u7ba1\u5404\u7a2e\u5782\u76f4\u9818\u57df\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u7d93\u958b\u767c\u51fa\u4f86\uff0c\u4f46\u81ea\u52d5\u8a55\u4f30\u5b83\u5011\u5728\u4e0d\u540c\u9818\u57df\u7684\u6548\u80fd\u4ecd\u662f\u4e00\u9805\u91cd\u5927\u7684\u6311\u6230\u3002\u73fe\u6709\u7684\u57fa\u65bc\u57fa\u6e96\u7684\u8a55\u4f30\u65b9\u6cd5\u5c55\u73fe\u51fa\u50f5\u5316\u3001\u7121\u76ee\u6a19\u7684\u4e92\u52d5\uff0c\u4e14\u4f9d\u8cf4\u65bc\u6536\u96c6\u597d\u7684\u975c\u614b\u8cc7\u6599\u96c6\uff0c\u800c\u9019\u4e9b\u8cc7\u6599\u96c6\u5efa\u7f6e\u6210\u672c\u9ad8\u6602\u3001\u7121\u6cd5\u9748\u6d3b\u61c9\u7528\u65bc\u4e0d\u540c\u9818\u57df\uff0c\u4e14\u8207\u5be6\u969b\u4f7f\u7528\u8005\u7684\u9700\u6c42\u4e0d\u7b26\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u91cd\u65b0\u6aa2\u8996\u8a55\u4f30\u7d44\u6210\u90e8\u5206\uff0c\u4e26\u63d0\u51fa\u5169\u500b\u6982\u5ff5\uff1aBenchmark+\uff0c\u5c07\u50b3\u7d71\u554f\u7b54\u57fa\u6e96\u64f4\u5145\u70ba\u66f4\u9748\u6d3b\u7684\u300c\u7b56\u7565\u6e96\u5247\u300d\u683c\u5f0f\uff1b\u4ee5\u53ca Assessment+\uff0c\u5b83\u589e\u5f37\u4e86\u4e92\u52d5\u7a0b\u5e8f\uff0c\u8b93\u63a2\u7d22\u66f4\u6df1\u5165\uff0c\u4e26\u540c\u6642\u652f\u63f4\u91cf\u5316\u6307\u6a19\u548c\u5b9a\u6027\u898b\u89e3\u3002\u9019\u4e9b\u6982\u5ff5\u900f\u904e\u66f4\u8c50\u5bcc\u3001\u591a\u8f2a\u6b21\u7684\u4e92\u52d5\uff0c\u6355\u6349\u5230 LLM \u7684\u7d30\u5fae\u884c\u70ba\u3002\u6211\u5011\u63d0\u51fa\u4e00\u500b\u7a31\u70ba TestAgent \u7684\u57fa\u65bc\u4ee3\u7406\u7684\u8a55\u4f30\u67b6\u69cb\uff0c\u5b83\u900f\u904e\u6aa2\u7d22\u64f4\u5145\u751f\u6210\u548c\u5f37\u5316\u5b78\u7fd2\u4f86\u5be6\u4f5c\u9019\u4e9b\u6982\u5ff5\u3002\u5728\u5f9e\u5efa\u69cb\u5782\u76f4\u9818\u57df\u8a55\u4f30\u5230\u555f\u52d5\u73fe\u6709\u57fa\u6e96\u7b49\u4efb\u52d9\u4e0a\u7684\u5be6\u9a57\uff0c\u90fd\u8b49\u5be6\u4e86 TestAgent \u5728\u5404\u7a2e\u60c5\u5883\u4e0b\u7684\u6548\u80fd\u3002\u6211\u5011\u76f8\u4fe1\u9019\u9805\u7814\u7a76\u70ba LLM \u7684\u81ea\u52d5\u8a55\u4f30\u63d0\u4f9b\u4e86\u6709\u8da3\u7684\u89c0\u9ede\u3002", "author": "Wanying Wang et.al.", "authors": "Wanying Wang, Zeyu Ma, Pengfei Liu, Mingang Chen", "id": "2410.11507v2", "paper_url": "http://arxiv.org/abs/2410.11507v2", "repo": "null"}}