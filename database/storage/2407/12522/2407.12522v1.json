{"2407.12522": {"publish_time": "2024-07-17", "title": "Struct-X: Enhancing Large Language Models Reasoning with Structured Data", "paper_summary": "Structured data, rich in logical and relational information, has the\npotential to enhance the reasoning abilities of large language models (LLMs).\nStill, its integration poses a challenge due to the risk of overwhelming LLMs\nwith excessive tokens and irrelevant context information. To address this, we\npropose Struct-X, a novel framework that operates through five key phases:\n``read-model-fill-reflect-reason'' efficiently enabling LLMs to utilize\nstructured data. It begins by encoding structured data into a topological space\nusing graph embeddings, followed by filling in missing entity information with\nknowledge retrieval modules, and filtering out irrelevant tokens via a\nself-supervised module. The final phase involves constructing a topological\nnetwork with selected tokens to further reduce the total token length for more\neffective LLM inference. Additionally, Struct-X includes an Auxiliary Module\ntrained to generate prompts, aiding LLMs in analyzing structured data.\nExtensive experiments on benchmarks, including the knowledge graph\nquestion-answer task and the long document reading comprehension task, show\nthat Struct-X notably improves LLM reasoning, demonstrating the effectiveness\nof structured data augmentation in improving LLM inference with complex input\ncontext.", "paper_summary_zh": "\u7d50\u69cb\u5316\u8cc7\u6599\u5bcc\u542b\u908f\u8f2f\u548c\u95dc\u4fc2\u8cc7\u8a0a\uff0c\u6709\u6f5b\u529b\u589e\u5f37\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u63a8\u7406\u80fd\u529b\u3002\u5118\u7ba1\u5982\u6b64\uff0c\u7531\u65bc\u904e\u591a\u7b26\u865f\u548c\u7121\u95dc\u8108\u7d61\u8cc7\u8a0a\u53ef\u80fd\u6703\u8b93 LLM \u4e0d\u582a\u8ca0\u8377\uff0c\u56e0\u6b64\u6574\u5408\u6b64\u985e\u8cc7\u6599\u69cb\u6210\u4e86\u4e00\u9805\u6311\u6230\u3002\u70ba\u4e86\u89e3\u6c7a\u6b64\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa Struct-X\uff0c\u9019\u662f\u4e00\u500b\u900f\u904e\u4e94\u500b\u95dc\u9375\u968e\u6bb5\u904b\u4f5c\u7684\u65b0\u7a4e\u67b6\u69cb\uff1a``\u8b80\u53d6-\u5efa\u6a21-\u586b\u88dc-\u53cd\u601d-\u63a8\u7406''\uff0c\u6709\u6548\u5730\u8b93 LLM \u80fd\u5920\u5229\u7528\u7d50\u69cb\u5316\u8cc7\u6599\u3002\u5b83\u9996\u5148\u4f7f\u7528\u5716\u5f62\u5d4c\u5165\u5c07\u7d50\u69cb\u5316\u8cc7\u6599\u7de8\u78bc\u5230\u62d3\u64b2\u7a7a\u9593\u4e2d\uff0c\u63a5\u8457\u5229\u7528\u77e5\u8b58\u64f7\u53d6\u6a21\u7d44\u586b\u88dc\u907a\u5931\u7684\u5be6\u9ad4\u8cc7\u8a0a\uff0c\u4e26\u900f\u904e\u81ea\u6211\u76e3\u7763\u6a21\u7d44\u7be9\u9078\u51fa\u7121\u95dc\u7b26\u865f\u3002\u6700\u5f8c\u4e00\u500b\u968e\u6bb5\u6d89\u53ca\u5efa\u69cb\u4e00\u500b\u62d3\u64b2\u7db2\u8def\uff0c\u5176\u4e2d\u5305\u542b\u9078\u5b9a\u7684\u7b26\u865f\uff0c\u4ee5\u9032\u4e00\u6b65\u6e1b\u5c11\u7e3d\u7b26\u865f\u9577\u5ea6\uff0c\u4ee5\u4fbf\u66f4\u6709\u6548\u5730\u9032\u884c LLM \u63a8\u8ad6\u3002\u6b64\u5916\uff0cStruct-X \u9084\u5305\u62ec\u4e00\u500b\u8f14\u52a9\u6a21\u7d44\uff0c\u7d93\u904e\u8a13\u7df4\u53ef\u4ee5\u7522\u751f\u63d0\u793a\uff0c\u5354\u52a9 LLM \u5206\u6790\u7d50\u69cb\u5316\u8cc7\u6599\u3002\u5728\u57fa\u6e96\u4e0a\u7684\u5927\u91cf\u5be6\u9a57\uff0c\u5305\u62ec\u77e5\u8b58\u5716\u8b5c\u554f\u7b54\u4efb\u52d9\u548c\u9577\u7bc7\u6587\u4ef6\u95b1\u8b80\u7406\u89e3\u4efb\u52d9\uff0c\u986f\u793a Struct-X \u660e\u986f\u6539\u5584\u4e86 LLM \u63a8\u7406\uff0c\u8b49\u660e\u4e86\u7d50\u69cb\u5316\u8cc7\u6599\u64f4\u5145\u5728\u6539\u5584 LLM \u63a8\u8ad6\u6642\u7684\u6709\u6548\u6027\uff0c\u7279\u5225\u662f\u5728\u8f38\u5165\u8108\u7d61\u8907\u96dc\u7684\u60c5\u6cc1\u4e0b\u3002", "author": "Xiaoyu Tan et.al.", "authors": "Xiaoyu Tan, Haoyu Wang, Xihe Qiu, Yuan Cheng, Yinghui Xu, Wei Chu, Yuan Qi", "id": "2407.12522v1", "paper_url": "http://arxiv.org/abs/2407.12522v1", "repo": "null"}}