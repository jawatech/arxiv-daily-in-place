{"2411.12872": {"publish_time": "2024-11-19", "title": "From Text to Pose to Image: Improving Diffusion Model Control and Quality", "paper_summary": "In the last two years, text-to-image diffusion models have become extremely\npopular. As their quality and usage increase, a major concern has been the need\nfor better output control. In addition to prompt engineering, one effective\nmethod to improve the controllability of diffusion models has been to condition\nthem on additional modalities such as image style, depth map, or keypoints.\nThis forms the basis of ControlNets or Adapters. When attempting to apply these\nmethods to control human poses in outputs of text-to-image diffusion models,\ntwo main challenges have arisen. The first challenge is generating poses\nfollowing a wide range of semantic text descriptions, for which previous\nmethods involved searching for a pose within a dataset of (caption, pose)\npairs. The second challenge is conditioning image generation on a specified\npose while keeping both high aesthetic and high pose fidelity. In this article,\nwe fix these two main issues by introducing a text-to-pose (T2P) generative\nmodel alongside a new sampling algorithm, and a new pose adapter that\nincorporates more pose keypoints for higher pose fidelity. Together, these two\nnew state-of-the-art models enable, for the first time, a generative\ntext-to-pose-to-image framework for higher pose control in diffusion models. We\nrelease all models and the code used for the experiments at\nhttps://github.com/clement-bonnet/text-to-pose.", "paper_summary_zh": "\u5728\u904e\u53bb\u5169\u5e74\uff0c\u6587\u5b57\u8f49\u5716\u50cf\u64f4\u6563\u6a21\u578b\u8b8a\u5f97\u6975\u70ba\n\u6d41\u884c\u3002\u96a8\u8457\u5176\u54c1\u8cea\u548c\u4f7f\u7528\u7387\u7684\u63d0\u5347\uff0c\u4e00\u500b\u4e3b\u8981\u7684\u554f\u984c\u5728\u65bc\u9700\u8981\n\u66f4\u597d\u7684\u8f38\u51fa\u63a7\u5236\u3002\u9664\u4e86\u63d0\u793a\u5de5\u7a0b\uff0c\u4e00\u500b\u6709\u6548\u7684\u65b9\u6cd5\u4f86\u6539\u5584\u64f4\u6563\u6a21\u578b\n\u7684\u53ef\u63a7\u6027\uff0c\u662f\u5c07\u5176\u5efa\u7acb\u5728\u984d\u5916\u7684\u6a21\u614b\u4e0a\uff0c\u4f8b\u5982\u5f71\u50cf\u98a8\u683c\u3001\u6df1\u5ea6\u5716\u6216\n\u95dc\u9375\u9ede\u3002\u9019\u5f62\u6210 ControlNets \u6216 Adapters \u7684\u57fa\u790e\u3002\u7576\u5617\u8a66\u5c07\u9019\u4e9b\n\u65b9\u6cd5\u61c9\u7528\u65bc\u63a7\u5236\u6587\u5b57\u8f49\u5716\u50cf\u64f4\u6563\u6a21\u578b\u8f38\u51fa\u7684\u59ff\u52e2\u6642\uff0c\u51fa\u73fe\u4e86\u5169\u500b\n\u4e3b\u8981\u7684\u6311\u6230\u3002\u7b2c\u4e00\u500b\u6311\u6230\u662f\u7522\u751f\u7b26\u5408\u5404\u7a2e\u8a9e\u7fa9\u6587\u5b57\u63cf\u8ff0\u7684\u59ff\u52e2\uff0c\n\u4ee5\u524d\u7684\u4f5c\u6cd5\u662f\u5f9e\uff08\u6a19\u984c\u3001\u59ff\u52e2\uff09\u914d\u5c0d\u7684\u8cc7\u6599\u96c6\u4e2d\u641c\u5c0b\u59ff\u52e2\u3002\u7b2c\u4e8c\u500b\n\u6311\u6230\u662f\u5728\u4fdd\u6301\u9ad8\u7f8e\u611f\u548c\u9ad8\u59ff\u52e2\u4fdd\u771f\u5ea6\u7684\u540c\u6642\uff0c\u5c0d\u6307\u5b9a\u7684\u59ff\u52e2\u9032\u884c\u5f71\u50cf\n\u751f\u6210\u7684\u689d\u4ef6\u5316\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u900f\u904e\u5f15\u5165\u6587\u5b57\u8f49\u59ff\u52e2 (T2P) \u751f\u6210\n\u6a21\u578b\uff0c\u4ee5\u53ca\u65b0\u7684\u53d6\u6a23\u6f14\u7b97\u6cd5\uff0c\u548c\u65b0\u7684\u59ff\u52e2\u9069\u914d\u5668\uff08\u7d50\u5408\u66f4\u591a\u59ff\u52e2\u95dc\u9375\n\u9ede\u4ee5\u7372\u5f97\u66f4\u9ad8\u7684\u59ff\u52e2\u4fdd\u771f\u5ea6\uff09\u4f86\u89e3\u6c7a\u9019\u5169\u500b\u4e3b\u8981\u554f\u984c\u3002\u9019\u5169\u500b\u65b0\u7684\n\u6700\u5148\u9032\u6a21\u578b\u5171\u540c\u5be6\u73fe\u4e86\u751f\u6210\u6587\u5b57\u8f49\u59ff\u52e2\u8f49\u5716\u50cf\u67b6\u69cb\uff0c\u4ee5\u5728\u64f4\u6563\u6a21\u578b\u4e2d\n\u7372\u5f97\u66f4\u9ad8\u7684\u59ff\u52e2\u63a7\u5236\u3002\u6211\u5011\u5728 https://github.com/clement-bonnet/text-to-pose\n\u91cb\u51fa\u6240\u6709\u6a21\u578b\u548c\u7528\u65bc\u5be6\u9a57\u7684\u7a0b\u5f0f\u78bc\u3002", "author": "Cl\u00e9ment Bonnett et.al.", "authors": "Cl\u00e9ment Bonnett, Ariel N. Lee, Franck Wertel, Antoine Tamano, Tanguy Cizain, Pablo Ducru", "id": "2411.12872v1", "paper_url": "http://arxiv.org/abs/2411.12872v1", "repo": "https://github.com/clement-bonnet/text-to-pose"}}