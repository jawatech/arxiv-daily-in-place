{"2408.10902": {"publish_time": "2024-08-20", "title": "Soda-Eval: Open-Domain Dialogue Evaluation in the age of LLMs", "paper_summary": "Although human evaluation remains the gold standard for open-domain dialogue\nevaluation, the growing popularity of automated evaluation using Large Language\nModels (LLMs) has also extended to dialogue. However, most frameworks leverage\nbenchmarks that assess older chatbots on aspects such as fluency and relevance,\nwhich are not reflective of the challenges associated with contemporary models.\nIn fact, a qualitative analysis on Soda, a GPT-3.5 generated dialogue dataset,\nsuggests that current chatbots may exhibit several recurring issues related to\ncoherence and commonsense knowledge, but generally produce highly fluent and\nrelevant responses.\n  Noting the aforementioned limitations, this paper introduces Soda-Eval, an\nannotated dataset based on Soda that covers over 120K turn-level assessments\nacross 10K dialogues, where the annotations were generated by GPT-4. Using\nSoda-Eval as a benchmark, we then study the performance of several open-access\ninstruction-tuned LLMs, finding that dialogue evaluation remains challenging.\nFine-tuning these models improves performance over few-shot inferences, both in\nterms of correlation and explanation.", "paper_summary_zh": "\u5118\u7ba1\u4eba\u5de5\u8a55\u4f30\u4ecd\u7136\u662f\u958b\u653e\u9818\u57df\u5c0d\u8a71\u8a55\u4f30\u7684\u9ec3\u91d1\u6a19\u6e96\uff0c\u4f7f\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u9032\u884c\u81ea\u52d5\u8a55\u4f30\u7684\u666e\u53ca\u7a0b\u5ea6\u4e5f\u5df2\u64f4\u5c55\u5230\u5c0d\u8a71\u3002\u7136\u800c\uff0c\u5927\u591a\u6578\u6846\u67b6\u5229\u7528\u57fa\u6e96\u4f86\u8a55\u4f30\u8f03\u820a\u7684\u804a\u5929\u6a5f\u5668\u4eba\u5728\u6d41\u66a2\u5ea6\u548c\u76f8\u95dc\u6027\u7b49\u65b9\u9762\u7684\u8868\u73fe\uff0c\u9019\u4e26\u672a\u53cd\u6620\u8207\u7576\u4ee3\u6a21\u578b\u76f8\u95dc\u7684\u6311\u6230\u3002\u4e8b\u5be6\u4e0a\uff0c\u5c0d GPT-3.5 \u751f\u6210\u7684\u5c0d\u8a71\u8cc7\u6599\u96c6 Soda \u9032\u884c\u7684\u5b9a\u6027\u5206\u6790\u8868\u660e\uff0c\u7576\u524d\u7684\u804a\u5929\u6a5f\u5668\u4eba\u53ef\u80fd\u6703\u51fa\u73fe\u8207\u9023\u8cab\u6027\u548c\u5e38\u8b58\u77e5\u8b58\u76f8\u95dc\u7684\u5e7e\u500b\u91cd\u8907\u554f\u984c\uff0c\u4f46\u901a\u5e38\u6703\u7522\u751f\u9ad8\u5ea6\u6d41\u66a2\u4e14\u76f8\u95dc\u7684\u56de\u61c9\u3002\u6ce8\u610f\u5230\u4e0a\u8ff0\u9650\u5236\uff0c\u672c\u6587\u4ecb\u7d39\u4e86 Soda-Eval\uff0c\u4e00\u500b\u57fa\u65bc Soda \u7684\u8a3b\u89e3\u8cc7\u6599\u96c6\uff0c\u6db5\u84cb\u4e86 10K \u500b\u5c0d\u8a71\u4e2d\u8d85\u904e 120K \u500b\u56de\u5408\u5c64\u7d1a\u7684\u8a55\u4f30\uff0c\u5176\u4e2d\u8a3b\u89e3\u662f\u7531 GPT-4 \u751f\u6210\u7684\u3002\u4f7f\u7528 Soda-Eval \u4f5c\u70ba\u57fa\u6e96\uff0c\u6211\u5011\u63a5\u8457\u7814\u7a76\u4e86\u5e7e\u500b\u958b\u653e\u5b58\u53d6\u7684\u6307\u4ee4\u8abf\u6574 LLM \u7684\u6548\u80fd\uff0c\u767c\u73fe\u5c0d\u8a71\u8a55\u4f30\u4ecd\u7136\u5177\u6709\u6311\u6230\u6027\u3002\u5fae\u8abf\u9019\u4e9b\u6a21\u578b\u6703\u6539\u5584\u5c0d\u5c11\u6b21\u63a8\u8ad6\u7684\u6548\u80fd\uff0c\u7121\u8ad6\u662f\u5728\u76f8\u95dc\u6027\u9084\u662f\u89e3\u91cb\u65b9\u9762\u3002", "author": "John Mendon\u00e7a et.al.", "authors": "John Mendon\u00e7a, Isabel Trancoso, Alon Lavie", "id": "2408.10902v1", "paper_url": "http://arxiv.org/abs/2408.10902v1", "repo": "null"}}