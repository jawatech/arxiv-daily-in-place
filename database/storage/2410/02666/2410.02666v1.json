{"2410.02666": {"publish_time": "2024-10-03", "title": "AlphaIntegrator: Transformer Action Search for Symbolic Integration Proofs", "paper_summary": "We present the first correct-by-construction learning-based system for\nstep-by-step mathematical integration. The key idea is to learn a policy,\nrepresented by a GPT transformer model, which guides the search for the right\nmathematical integration rule, to be carried out by a symbolic solver.\nConcretely, we introduce a symbolic engine with axiomatically correct actions\non mathematical expressions, as well as the first dataset for step-by-step\nintegration. Our GPT-style transformer model, trained on this synthetic data,\ndemonstrates strong generalization by surpassing its own data generator in\naccuracy and efficiency, using 50% fewer search steps. Our experimental results\nwith SoTA LLMs also demonstrate that the standard approach of fine-tuning LLMs\non a set of question-answer pairs is insufficient for solving this mathematical\ntask. This motivates the importance of discovering creative methods for\ncombining LLMs with symbolic reasoning engines, of which our work is an\ninstance.", "paper_summary_zh": "\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u57fa\u65bc\u5b78\u7fd2\u7684\u7b2c\u4e00\u500b\u6b63\u78ba\u5efa\u69cb\u7cfb\u7d71\uff0c\u7528\u65bc\u9010\u6b65\u7684\u6578\u5b78\u7a4d\u5206\u3002\u95dc\u9375\u60f3\u6cd5\u662f\u5b78\u7fd2\u4e00\u500b\u7b56\u7565\uff0c\u7531 GPT \u8f49\u63db\u5668\u6a21\u578b\u8868\u793a\uff0c\u5b83\u5f15\u5c0e\u5c0b\u627e\u6b63\u78ba\u7684\u6578\u5b78\u7a4d\u5206\u898f\u5247\uff0c\u7531\u7b26\u865f\u6c42\u89e3\u5668\u57f7\u884c\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u7b26\u865f\u5f15\u64ce\uff0c\u5b83\u5c0d\u6578\u5b78\u8868\u9054\u5f0f\u5177\u6709\u516c\u7406\u4e0a\u6b63\u78ba\u7684\u52d5\u4f5c\uff0c\u4ee5\u53ca\u7528\u65bc\u9010\u6b65\u7a4d\u5206\u7684\u9996\u500b\u8cc7\u6599\u96c6\u3002\u6211\u5011\u7684 GPT \u98a8\u683c\u8f49\u63db\u5668\u6a21\u578b\u5728\u9019\u500b\u5408\u6210\u8cc7\u6599\u4e0a\u8a13\u7df4\uff0c\u5c55\u793a\u4e86\u5f37\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u6e96\u78ba\u5ea6\u548c\u6548\u7387\u4e0a\u8d85\u8d8a\u4e86\u81ea\u5df1\u7684\u8cc7\u6599\u751f\u6210\u5668\uff0c\u4f7f\u7528\u5c11 50% \u7684\u641c\u5c0b\u6b65\u9a5f\u3002\u6211\u5011\u4f7f\u7528 SoTA LLM \u7684\u5be6\u9a57\u7d50\u679c\u4e5f\u8868\u660e\uff0c\u5728\u554f\u984c\u7b54\u6848\u5c0d\u4e0a\u5fae\u8abf LLM \u7684\u6a19\u6e96\u65b9\u6cd5\u4e0d\u8db3\u4ee5\u89e3\u6c7a\u9019\u500b\u6578\u5b78\u4efb\u52d9\u3002\u9019\u6fc0\u52f5\u4e86\u767c\u73fe\u5c07 LLM \u8207\u7b26\u865f\u63a8\u7406\u5f15\u64ce\u76f8\u7d50\u5408\u7684\u5275\u9020\u6027\u65b9\u6cd5\u7684\u91cd\u8981\u6027\uff0c\u5176\u4e2d\u6211\u5011\u7684\u4f5c\u54c1\u662f\u4e00\u500b\u5be6\u4f8b\u3002", "author": "Mert \u00dcnsal et.al.", "authors": "Mert \u00dcnsal, Timon Gehr, Martin Vechev", "id": "2410.02666v1", "paper_url": "http://arxiv.org/abs/2410.02666v1", "repo": "null"}}