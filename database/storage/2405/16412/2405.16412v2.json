{"2405.16412": {"publish_time": "2024-05-26", "title": "KG-FIT: Knowledge Graph Fine-Tuning Upon Open-World Knowledge", "paper_summary": "Knowledge Graph Embedding (KGE) techniques are crucial in learning compact\nrepresentations of entities and relations within a knowledge graph,\nfacilitating efficient reasoning and knowledge discovery. While existing\nmethods typically focus either on training KGE models solely based on graph\nstructure or fine-tuning pre-trained language models with classification data\nin KG, KG-FIT leverages LLM-guided refinement to construct a semantically\ncoherent hierarchical structure of entity clusters. By incorporating this\nhierarchical knowledge along with textual information during the fine-tuning\nprocess, KG-FIT effectively captures both global semantics from the LLM and\nlocal semantics from the KG. Extensive experiments on the benchmark datasets\nFB15K-237, YAGO3-10, and PrimeKG demonstrate the superiority of KG-FIT over\nstate-of-the-art pre-trained language model-based methods, achieving\nimprovements of 14.4%, 13.5%, and 11.9% in the Hits@10 metric for the link\nprediction task, respectively. Furthermore, KG-FIT yields substantial\nperformance gains of 12.6%, 6.7%, and 17.7% compared to the structure-based\nbase models upon which it is built. These results highlight the effectiveness\nof KG-FIT in incorporating open-world knowledge from LLMs to significantly\nenhance the expressiveness and informativeness of KG embeddings.", "paper_summary_zh": "\u77e5\u8b58\u5716\u5d4c\u5165 (KGE) \u6280\u8853\u5c0d\u65bc\u5b78\u7fd2\u77e5\u8b58\u5716\u4e2d\u5be6\u9ad4\u548c\u95dc\u4fc2\u7684\u7dca\u6e4a\u8868\u793a\u81f3\u95dc\u91cd\u8981\uff0c\u6709\u52a9\u65bc\u9ad8\u6548\u63a8\u7406\u548c\u77e5\u8b58\u767c\u73fe\u3002\u96d6\u7136\u73fe\u6709\u65b9\u6cd5\u901a\u5e38\u5074\u91cd\u65bc\u50c5\u57fa\u65bc\u5716\u5f62\u7d50\u69cb\u8a13\u7df4 KGE \u6a21\u578b\u6216\u4f7f\u7528 KG \u4e2d\u7684\u5206\u985e\u6578\u64da\u5fae\u8abf\u9810\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b\uff0c\u4f46 KG-FIT \u5229\u7528 LLM \u5f15\u5c0e\u7684\u512a\u5316\u4f86\u69cb\u5efa\u5be6\u9ad4\u7fa4\u96c6\u7684\u8a9e\u7fa9\u4e00\u81f4\u5206\u5c64\u7d50\u69cb\u3002\u900f\u904e\u5728\u5fae\u8abf\u904e\u7a0b\u4e2d\u5c07\u6b64\u5206\u5c64\u77e5\u8b58\u8207\u6587\u672c\u8cc7\u8a0a\u7d50\u5408\uff0cKG-FIT \u6709\u6548\u5730\u64f7\u53d6\u4e86 LLM \u7684\u5168\u5c40\u8a9e\u7fa9\u548c KG \u7684\u5c40\u90e8\u8a9e\u7fa9\u3002\u5728\u57fa\u6e96\u8cc7\u6599\u96c6 FB15K-237\u3001YAGO3-10 \u548c PrimeKG \u4e0a\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u8b49\u660e\u4e86 KG-FIT \u512a\u65bc\u6700\u5148\u9032\u7684\u57fa\u65bc\u9810\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u5728\u9023\u7d50\u9810\u6e2c\u4efb\u52d9\u4e2d\uff0cHits@10 \u6307\u6a19\u5206\u5225\u63d0\u5347\u4e86 14.4%\u300113.5% \u548c 11.9%\u3002\u6b64\u5916\uff0c\u8207\u5176\u5efa\u7acb\u7684\u57fa\u65bc\u7d50\u69cb\u7684\u57fa\u790e\u6a21\u578b\u76f8\u6bd4\uff0cKG-FIT \u7522\u751f\u4e86 12.6%\u30016.7% \u548c 17.7% \u7684\u986f\u8457\u6548\u80fd\u63d0\u5347\u3002\u9019\u4e9b\u7d50\u679c\u7a81\u986f\u4e86 KG-FIT \u5728\u7d50\u5408\u4f86\u81ea LLM \u7684\u958b\u653e\u4e16\u754c\u77e5\u8b58\u4ee5\u986f\u8457\u589e\u5f37 KG \u5d4c\u5165\u7684\u8868\u73fe\u529b\u548c\u8cc7\u8a0a\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "author": "Pengcheng Jiang et.al.", "authors": "Pengcheng Jiang, Lang Cao, Cao Xiao, Parminder Bhatia, Jimeng Sun, Jiawei Han", "id": "2405.16412v2", "paper_url": "http://arxiv.org/abs/2405.16412v2", "repo": "https://github.com/pat-jj/KG-FIT"}}