{"2407.18078": {"publish_time": "2024-07-25", "title": "PEFT-U: Parameter-Efficient Fine-Tuning for User Personalization", "paper_summary": "The recent emergence of Large Language Models (LLMs) has heralded a new era\nof human-AI interaction. These sophisticated models, exemplified by Chat-GPT\nand its successors, have exhibited remarkable capabilities in language\nunderstanding. However, as these LLMs have undergone exponential growth, a\ncrucial dimension that remains understudied is the personalization of these\nmodels. Large foundation models such as GPT-3 etc. focus on creating a\nuniversal model that serves a broad range of tasks and users. This approach\nemphasizes the model's generalization capabilities, treating users as a\ncollective rather than as distinct individuals. While practical for many common\napplications, this one-size-fits-all approach often fails to address the rich\ntapestry of human diversity and individual needs. To explore this issue we\nintroduce the PEFT-U Benchmark: a new dataset for building and evaluating NLP\nmodels for user personalization. \\datasetname{} consists of a series of\nuser-centered tasks containing diverse and individualized expressions where the\npreferences of users can potentially differ for the same input. Using PEFT-U,\nwe explore the challenge of efficiently personalizing LLMs to accommodate\nuser-specific preferences in the context of diverse user-centered tasks.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8fd1\u671f\u8208\u8d77\uff0c\u9810\u793a\u8457\u4eba\u6a5f\u4e92\u52d5\u7684\u65b0\u7d00\u5143\u3002\u9019\u4e9b\u7cbe\u5bc6\u7684\u6a21\u578b\uff0c\u4ee5 Chat-GPT \u53ca\u5176\u5f8c\u7e7c\u8005\u70ba\u4f8b\uff0c\u5728\u8a9e\u8a00\u7406\u89e3\u65b9\u9762\u5c55\u73fe\u4e86\u975e\u51e1\u7684\u80fd\u529b\u3002\u7136\u800c\uff0c\u96a8\u8457\u9019\u4e9b LLM \u7d93\u6b77\u6307\u6578\u7d1a\u589e\u9577\uff0c\u4e00\u500b\u4ecd\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u7684\u91cd\u8981\u9762\u5411\u662f\u9019\u4e9b\u6a21\u578b\u7684\u500b\u4eba\u5316\u3002\u5927\u578b\u57fa\u790e\u6a21\u578b\uff0c\u4f8b\u5982 GPT-3 \u7b49\uff0c\u5c08\u6ce8\u65bc\u5efa\u7acb\u4e00\u500b\u901a\u7528\u7684\u6a21\u578b\uff0c\u670d\u52d9\u65bc\u5ee3\u6cdb\u7684\u4efb\u52d9\u548c\u4f7f\u7528\u8005\u3002\u6b64\u65b9\u6cd5\u5f37\u8abf\u6a21\u578b\u7684\u6982\u5316\u80fd\u529b\uff0c\u5c07\u4f7f\u7528\u8005\u8996\u70ba\u4e00\u500b\u96c6\u9ad4\uff0c\u800c\u975e\u7368\u7acb\u7684\u500b\u9ad4\u3002\u96d6\u7136\u5c0d\u8a31\u591a\u5e38\u898b\u61c9\u7528\u4f86\u8aaa\u5f88\u5be6\u7528\uff0c\u4f46\u9019\u7a2e\u4e00\u9ad4\u9069\u7528\u7684\u65b9\u6cd5\u901a\u5e38\u7121\u6cd5\u6eff\u8db3\u4eba\u985e\u591a\u5143\u6027\u548c\u500b\u5225\u9700\u6c42\u7684\u8c50\u5bcc\u6027\u3002\u70ba\u4e86\u63a2\u8a0e\u6b64\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86 PEFT-U \u57fa\u6e96\uff1a\u4e00\u500b\u7528\u65bc\u5efa\u7acb\u548c\u8a55\u4f30\u4f7f\u7528\u8005\u500b\u4eba\u5316 NLP \u6a21\u578b\u7684\u65b0\u8cc7\u6599\u96c6\u3002\\datasetname{} \u5305\u542b\u4e00\u7cfb\u5217\u4ee5\u4f7f\u7528\u8005\u70ba\u4e2d\u5fc3\u7684\u4efb\u52d9\uff0c\u5176\u4e2d\u5305\u542b\u591a\u6a23\u5316\u4e14\u500b\u6027\u5316\u7684\u8868\u9054\uff0c\u4f7f\u7528\u8005\u7684\u504f\u597d\u53ef\u80fd\u56e0\u76f8\u540c\u7684\u8f38\u5165\u800c\u6709\u6240\u4e0d\u540c\u3002\u4f7f\u7528 PEFT-U\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u5728\u591a\u5143\u5316\u4ee5\u4f7f\u7528\u8005\u70ba\u4e2d\u5fc3\u7684\u4efb\u52d9\u4e2d\uff0c\u6709\u6548\u500b\u4eba\u5316 LLM \u4ee5\u9069\u61c9\u4f7f\u7528\u8005\u7279\u5b9a\u504f\u597d\u7684\u6311\u6230\u3002", "author": "Christopher Clarke et.al.", "authors": "Christopher Clarke, Yuzhao Heng, Lingjia Tang, Jason Mars", "id": "2407.18078v1", "paper_url": "http://arxiv.org/abs/2407.18078v1", "repo": "null"}}