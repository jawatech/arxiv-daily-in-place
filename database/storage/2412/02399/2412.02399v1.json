{"2412.02399": {"publish_time": "2024-12-03", "title": "OMENN: One Matrix to Explain Neural Networks", "paper_summary": "Deep Learning (DL) models are often black boxes, making their decision-making\nprocesses difficult to interpret. This lack of transparency has driven\nadvancements in eXplainable Artificial Intelligence (XAI), a field dedicated to\nclarifying the reasoning behind DL model predictions. Among these,\nattribution-based methods such as LRP and GradCAM are widely used, though they\nrely on approximations that can be imprecise.\n  To address these limitations, we introduce One Matrix to Explain Neural\nNetworks (OMENN), a novel post-hoc method that represents a neural network as a\nsingle, interpretable matrix for each specific input. This matrix is\nconstructed through a series of linear transformations that represent the\nprocessing of the input by each successive layer in the neural network. As a\nresult, OMENN provides locally precise, attribution-based explanations of the\ninput across various modern models, including ViTs and CNNs. We present a\ntheoretical analysis of OMENN based on dynamic linearity property and validate\nits effectiveness with extensive tests on two XAI benchmarks, demonstrating\nthat OMENN is competitive with state-of-the-art methods.", "paper_summary_zh": "\u6df1\u5ea6\u5b78\u7fd2 (DL) \u6a21\u578b\u901a\u5e38\u662f\u9ed1\u76d2\u5b50\uff0c\u9019\u4f7f\u5f97\u5b83\u5011\u7684\u6c7a\u7b56\u5236\u5b9a\u904e\u7a0b\u96e3\u4ee5\u89e3\u91cb\u3002\u9019\u7a2e\u900f\u660e\u5ea6\u7684\u7f3a\u4e4f\u63a8\u52d5\u4e86\u53ef\u89e3\u91cb\u4eba\u5de5\u667a\u6167 (XAI) \u7684\u9032\u5c55\uff0cXAI \u662f\u81f4\u529b\u65bc\u91d0\u6e05 DL \u6a21\u578b\u9810\u6e2c\u80cc\u5f8c\u63a8\u7406\u7684\u9818\u57df\u3002\u5176\u4e2d\uff0c\u57fa\u65bc\u6b78\u56e0\u7684\u65b9\u6cd5\uff08\u4f8b\u5982 LRP \u548c GradCAM\uff09\u88ab\u5ee3\u6cdb\u4f7f\u7528\uff0c\u5118\u7ba1\u5b83\u5011\u4f9d\u8cf4\u65bc\u53ef\u80fd\u4e0d\u7cbe\u78ba\u7684\u8fd1\u4f3c\u3002\n\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u9650\u5236\uff0c\u6211\u5011\u5f15\u5165\u4e86 One Matrix to Explain Neural Networks (OMENN)\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u5f8c\u8a2d\u6cd5\uff0c\u5b83\u5c07\u795e\u7d93\u7db2\u8def\u8868\u793a\u70ba\u91dd\u5c0d\u6bcf\u500b\u7279\u5b9a\u8f38\u5165\u7684\u55ae\u4e00\u53ef\u89e3\u91cb\u77e9\u9663\u3002\u6b64\u77e9\u9663\u662f\u900f\u904e\u4e00\u7cfb\u5217\u7dda\u6027\u8f49\u63db\u5efa\u69cb\u7684\uff0c\u9019\u4e9b\u8f49\u63db\u8868\u793a\u795e\u7d93\u7db2\u8def\u4e2d\u6bcf\u500b\u5f8c\u7e8c\u5c64\u8655\u7406\u8f38\u5165\u7684\u65b9\u5f0f\u3002\u56e0\u6b64\uff0cOMENN \u63d0\u4f9b\u4e86\u5c40\u90e8\u7cbe\u78ba\u7684\u3001\u57fa\u65bc\u6b78\u56e0\u7684\u8f38\u5165\u89e3\u91cb\uff0c\u9069\u7528\u65bc\u5404\u7a2e\u73fe\u4ee3\u6a21\u578b\uff0c\u5305\u62ec ViT \u548c CNN\u3002\u6211\u5011\u57fa\u65bc\u52d5\u614b\u7dda\u6027\u5c6c\u6027\u5c0d OMENN \u9032\u884c\u4e86\u7406\u8ad6\u5206\u6790\uff0c\u4e26\u900f\u904e\u5728\u5169\u500b XAI \u57fa\u6e96\u4e0a\u9032\u884c\u5ee3\u6cdb\u6e2c\u8a66\u9a57\u8b49\u4e86\u5176\u6709\u6548\u6027\uff0c\u8b49\u660e\u4e86 OMENN \u5177\u6709\u8207\u6700\u5148\u9032\u65b9\u6cd5\u76f8\u5ab2\u7f8e\u7684\u7af6\u722d\u529b\u3002", "author": "Adam Wr\u00f3bel et.al.", "authors": "Adam Wr\u00f3bel, Miko\u0142aj Janusz, Bartosz Zieli\u0144ski, Dawid Rymarczyk", "id": "2412.02399v1", "paper_url": "http://arxiv.org/abs/2412.02399v1", "repo": "null"}}