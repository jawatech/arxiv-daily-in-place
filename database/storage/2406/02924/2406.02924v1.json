{"2406.02924": {"publish_time": "2024-06-05", "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models", "paper_summary": "Despite the remarkable capabilities, Large Language Models (LLMs) face\ndeployment challenges due to their extensive size. Pruning methods drop a\nsubset of weights to accelerate, but many of them require retraining, which is\nprohibitively expensive and computationally demanding. Recently, post-training\npruning approaches introduced novel metrics, enabling the pruning of LLMs\nwithout retraining. However, these metrics require the involvement of human\nexperts and tedious trial and error. To efficiently identify superior pruning\nmetrics, we develop an automatic framework for searching symbolic pruning\nmetrics using genetic programming. In particular, we devise an elaborate search\nspace encompassing the existing pruning metrics to discover the potential\nsymbolic pruning metric. We propose an opposing operation simplification\nstrategy to increase the diversity of the population. In this way, Pruner-Zero\nallows auto-generation of symbolic pruning metrics. Based on the searched\nresults, we explore the correlation between pruning metrics and performance\nafter pruning and summarize some principles. Extensive experiments on LLaMA and\nLLaMA-2 on language modeling and zero-shot tasks demonstrate that our\nPruner-Zero obtains superior performance than SOTA post-training pruning\nmethods. Code at: \\url{https://github.com/pprp/Pruner-Zero}.", "paper_summary_zh": "\u5118\u7ba1\u5177\u6709\u975e\u51e1\u7684\u80fd\u529b\uff0c\u4f46\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u56e0\u5176\u9f90\u5927\u898f\u6a21\u800c\u9762\u81e8\u90e8\u7f72\u6311\u6230\u3002\u4fee\u526a\u65b9\u6cd5\u6703\u6368\u68c4\u4e00\u90e8\u5206\u6b0a\u91cd\u4ee5\u52a0\u901f\uff0c\u4f46\u5176\u4e2d\u8a31\u591a\u65b9\u6cd5\u9700\u8981\u91cd\u65b0\u8a13\u7df4\uff0c\u9019\u975e\u5e38\u6602\u8cb4\u4e14\u5728\u904b\u7b97\u4e0a\u8981\u6c42\u5f88\u9ad8\u3002\u6700\u8fd1\uff0c\u8a13\u7df4\u5f8c\u4fee\u526a\u65b9\u6cd5\u5f15\u9032\u4e86\u65b0\u6307\u6a19\uff0c\u80fd\u5920\u5728\u4e0d\u91cd\u65b0\u8a13\u7df4\u7684\u60c5\u6cc1\u4e0b\u4fee\u526a LLM\u3002\u7136\u800c\uff0c\u9019\u4e9b\u6307\u6a19\u9700\u8981\u4eba\u985e\u5c08\u5bb6\u53c3\u8207\u548c\u7e41\u7463\u7684\u8a66\u932f\u904e\u7a0b\u3002\u70ba\u4e86\u6709\u6548\u627e\u51fa\u512a\u8d8a\u7684\u4fee\u526a\u6307\u6a19\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u81ea\u52d5\u5316\u67b6\u69cb\uff0c\u4f7f\u7528\u907a\u50b3\u7a0b\u5f0f\u8a2d\u8a08\u4f86\u641c\u5c0b\u7b26\u865f\u4fee\u526a\u6307\u6a19\u3002\u7279\u5225\u662f\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u7cbe\u7d30\u7684\u641c\u5c0b\u7a7a\u9593\uff0c\u5305\u542b\u73fe\u6709\u7684\u4fee\u526a\u6307\u6a19\uff0c\u4ee5\u627e\u51fa\u6f5b\u5728\u7684\u7b26\u865f\u4fee\u526a\u6307\u6a19\u3002\u6211\u5011\u63d0\u51fa\u4e00\u500b\u5c0d\u7acb\u904b\u7b97\u7c21\u5316\u7b56\u7565\uff0c\u4ee5\u589e\u52a0\u65cf\u7fa4\u7684\u591a\u6a23\u6027\u3002\u85c9\u7531\u9019\u7a2e\u65b9\u5f0f\uff0cPruner-Zero \u5141\u8a31\u81ea\u52d5\u7522\u751f\u7b26\u865f\u4fee\u526a\u6307\u6a19\u3002\u6839\u64da\u641c\u5c0b\u7d50\u679c\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u4fee\u526a\u6307\u6a19\u8207\u4fee\u526a\u5f8c\u6548\u80fd\u4e4b\u9593\u7684\u95dc\u806f\u6027\uff0c\u4e26\u7e3d\u7d50\u4e86\u4e00\u4e9b\u539f\u5247\u3002\u5728 LLaMA \u548c LLaMA-2 \u4e0a\u91dd\u5c0d\u8a9e\u8a00\u5efa\u6a21\u548c\u96f6\u6b21\u5b78\u7fd2\u4efb\u52d9\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u8b49\u660e\uff0c\u6211\u5011\u7684 Pruner-Zero \u7372\u5f97\u6bd4 SOTA \u8a13\u7df4\u5f8c\u4fee\u526a\u65b9\u6cd5\u66f4\u512a\u7570\u7684\u6548\u80fd\u3002\u7a0b\u5f0f\u78bc\u5728\uff1a\\url{https://github.com/pprp/Pruner-Zero}\u3002", "author": "Peijie Dong et.al.", "authors": "Peijie Dong, Lujun Li, Zhenheng Tang, Xiang Liu, Xinglin Pan, Qiang Wang, Xiaowen Chu", "id": "2406.02924v1", "paper_url": "http://arxiv.org/abs/2406.02924v1", "repo": "null"}}