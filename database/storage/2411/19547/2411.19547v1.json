{"2411.19547": {"publish_time": "2024-11-29", "title": "Training Agents with Weakly Supervised Feedback from Large Language Models", "paper_summary": "Large Language Models (LLMs) offer a promising basis for creating agents that\ncan tackle complex tasks through iterative environmental interaction. Existing\nmethods either require these agents to mimic expert-provided trajectories or\nrely on definitive environmental feedback for reinforcement learning which\nlimits their application to specific scenarios like gaming or code generation.\nThis paper introduces a novel training method for LLM-based agents using weakly\nsupervised signals from a critic LLM, bypassing the need for expert\ntrajectories or definitive feedback. Our agents are trained in iterative\nmanner, where they initially generate trajectories through environmental\ninteraction. Subsequently, a critic LLM selects a subset of good trajectories,\nwhich are then used to update the agents, enabling them to generate improved\ntrajectories in the next iteration. Extensive tests on the API-bank dataset\nshow consistent improvement in our agents' capabilities and comparable\nperformance to GPT-4, despite using open-source models with much fewer\nparameters.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u63d0\u4f9b\u4e86\u4e00\u500b\u6709\u5e0c\u671b\u7684\u57fa\u790e\uff0c\u7528\u65bc\u5efa\u7acb\u4ee3\u7406\uff0c\u9019\u4e9b\u4ee3\u7406\u53ef\u4ee5\u901a\u904e\u53cd\u8986\u7684\u74b0\u5883\u4e92\u52d5\u4f86\u8655\u7406\u8907\u96dc\u4efb\u52d9\u3002\u73fe\u6709\u65b9\u6cd5\u8981\u6c42\u9019\u4e9b\u4ee3\u7406\u6a21\u64ec\u5c08\u5bb6\u63d0\u4f9b\u7684\u8ecc\u8de1\uff0c\u6216\u8005\u4f9d\u8cf4\u65bc\u78ba\u5b9a\u6027\u7684\u74b0\u5883\u53cd\u994b\u4f86\u9032\u884c\u5f37\u5316\u5b78\u7fd2\uff0c\u9019\u6703\u5c07\u5b83\u5011\u7684\u61c9\u7528\u9650\u5236\u5728\u7279\u5b9a\u5834\u666f\u4e2d\uff0c\u4f8b\u5982\u904a\u6232\u6216\u7a0b\u5f0f\u78bc\u751f\u6210\u3002\u672c\u6587\u4ecb\u7d39\u4e86\u4e00\u7a2e\u4f7f\u7528\u4f86\u81ea\u8a55\u8ad6 LLM \u7684\u5f31\u76e3\u7763\u4fe1\u865f\u4f86\u8a13\u7df4 LLM \u57fa\u790e\u4ee3\u7406\u7684\u65b0\u7a4e\u8a13\u7df4\u65b9\u6cd5\uff0c\u7e5e\u904e\u4e86\u5c0d\u5c08\u5bb6\u8ecc\u8de1\u6216\u78ba\u5b9a\u6027\u53cd\u994b\u7684\u9700\u6c42\u3002\u6211\u5011\u7684\u4ee3\u7406\u4ee5\u53cd\u8986\u7684\u65b9\u5f0f\u9032\u884c\u8a13\u7df4\uff0c\u5b83\u5011\u6700\u521d\u901a\u904e\u74b0\u5883\u4e92\u52d5\u4f86\u751f\u6210\u8ecc\u8de1\u3002\u96a8\u5f8c\uff0c\u8a55\u8ad6 LLM \u9078\u64c7\u4e86\u4e00\u7d44\u597d\u7684\u8ecc\u8de1\uff0c\u7136\u5f8c\u7528\u65bc\u66f4\u65b0\u4ee3\u7406\uff0c\u4f7f\u5b83\u5011\u80fd\u5920\u5728\u4e0b\u4e00\u6b21\u8fed\u4ee3\u4e2d\u751f\u6210\u6539\u9032\u7684\u8ecc\u8de1\u3002\u5728 API-bank \u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u7684\u5ee3\u6cdb\u6e2c\u8a66\u8868\u660e\uff0c\u6211\u5011\u7684\u4ee3\u7406\u7684\u80fd\u529b\u6301\u7e8c\u63d0\u9ad8\uff0c\u4e26\u4e14\u5118\u7ba1\u4f7f\u7528\u958b\u6e90\u6a21\u578b\u7684\u53c3\u6578\u5c11\u5f97\u591a\uff0c\u4f46\u6027\u80fd\u8207 GPT-4 \u76f8\u7576\u3002", "author": "Dihong Gong et.al.", "authors": "Dihong Gong, Pu Lu, Zelong Wang, Meng Zhou, Xiuqiang He", "id": "2411.19547v1", "paper_url": "http://arxiv.org/abs/2411.19547v1", "repo": "null"}}