{"2407.07551": {"publish_time": "2024-07-10", "title": "Arabic Automatic Story Generation with Large Language Models", "paper_summary": "Large language models (LLMs) have recently emerged as a powerful tool for a\nwide range of language generation tasks. Nevertheless, this progress has been\nslower in Arabic. In this work, we focus on the task of generating stories from\nLLMs. For our training, we use stories acquired through machine translation\n(MT) as well as GPT-4. For the MT data, we develop a careful pipeline that\nensures we acquire high-quality stories. For our GPT-41 data, we introduce\ncrafted prompts that allow us to generate data well-suited to the Arabic\ncontext in both Modern Standard Arabic (MSA) and two Arabic dialects (Egyptian\nand Moroccan). For example, we generate stories tailored to various Arab\ncountries on a wide host of topics. Our manual evaluation shows that our model\nfine-tuned on these training datasets can generate coherent stories that adhere\nto our instructions. We also conduct an extensive automatic and human\nevaluation comparing our models against state-of-the-art proprietary and\nopen-source models. Our datasets and models will be made publicly available at\nhttps: //github.com/UBC-NLP/arastories.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u6700\u8fd1\u5df2\u6210\u70ba\u5404\u7a2e\u8a9e\u8a00\u751f\u6210\u4efb\u52d9\u7684\u5f37\u5927\u5de5\u5177\u3002\u5118\u7ba1\u5982\u6b64\uff0c\u9019\u9805\u9032\u5c55\u5728\u963f\u62c9\u4f2f\u8a9e\u4e2d\u8f03\u70ba\u7de9\u6162\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5c08\u6ce8\u65bc\u5f9e LLM \u751f\u6210\u6545\u4e8b\u7684\u4efb\u52d9\u3002\u5c0d\u65bc\u6211\u5011\u7684\u8a13\u7df4\uff0c\u6211\u5011\u4f7f\u7528\u901a\u904e\u6a5f\u5668\u7ffb\u8b6f\uff08MT\uff09\u4ee5\u53ca GPT-4 \u7372\u5f97\u7684\u6545\u4e8b\u3002\u5c0d\u65bc MT \u8cc7\u6599\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u4ed4\u7d30\u7684\u7ba1\u9053\uff0c\u4ee5\u78ba\u4fdd\u6211\u5011\u7372\u5f97\u9ad8\u54c1\u8cea\u7684\u6545\u4e8b\u3002\u5c0d\u65bc\u6211\u5011\u7684 GPT-41 \u8cc7\u6599\uff0c\u6211\u5011\u5f15\u5165\u4e86\u7cbe\u5fc3\u88fd\u4f5c\u7684\u63d0\u793a\uff0c\u4f7f\u6211\u5011\u80fd\u5920\u751f\u6210\u975e\u5e38\u9069\u5408\u963f\u62c9\u4f2f\u8a9e\u74b0\u5883\u7684\u8cc7\u6599\uff0c\u5305\u62ec\u73fe\u4ee3\u6a19\u6e96\u963f\u62c9\u4f2f\u8a9e\uff08MSA\uff09\u548c\u5169\u7a2e\u963f\u62c9\u4f2f\u8a9e\u65b9\u8a00\uff08\u57c3\u53ca\u8a9e\u548c\u6469\u6d1b\u54e5\u8a9e\uff09\u3002\u4f8b\u5982\uff0c\u6211\u5011\u751f\u6210\u91dd\u5c0d\u5404\u7a2e\u963f\u62c9\u4f2f\u570b\u5bb6\u7684\u6545\u4e8b\uff0c\u4e3b\u984c\u5ee3\u6cdb\u3002\u6211\u5011\u7684\u8a55\u4f30\u986f\u793a\uff0c\u6211\u5011\u91dd\u5c0d\u9019\u4e9b\u8a13\u7df4\u8cc7\u6599\u96c6\u9032\u884c\u5fae\u8abf\u7684\u6a21\u578b\u53ef\u4ee5\u751f\u6210\u7b26\u5408\u6211\u5011\u6307\u793a\u7684\u9023\u8cab\u6545\u4e8b\u3002\u6211\u5011\u9084\u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u81ea\u52d5\u548c\u4eba\u5de5\u8a55\u4f30\uff0c\u5c07\u6211\u5011\u7684\u6a21\u578b\u8207\u6700\u5148\u9032\u7684\u5c08\u6709\u548c\u958b\u653e\u539f\u59cb\u78bc\u6a21\u578b\u9032\u884c\u6bd4\u8f03\u3002\u6211\u5011\u7684\u8cc7\u6599\u96c6\u548c\u6a21\u578b\u5c07\u5728 https: //github.com/UBC-NLP/arastories \u516c\u958b\u3002", "author": "Ahmed Oumar El-Shangiti et.al.", "authors": "Ahmed Oumar El-Shangiti, Fakhraddin Alwajih, Muhammad Abdul-Mageed", "id": "2407.07551v1", "paper_url": "http://arxiv.org/abs/2407.07551v1", "repo": "null"}}