{"2407.10486": {"publish_time": "2024-07-15", "title": "IDEAL: Leveraging Infinite and Dynamic Characterizations of Large Language Models for Query-focused Summarization", "paper_summary": "Query-focused summarization (QFS) aims to produce summaries that answer\nparticular questions of interest, enabling greater user control and\npersonalization. With the advent of large language models (LLMs), shows their\nimpressive capability of textual understanding through large-scale pretraining,\nwhich implies the great potential of extractive snippet generation. In this\npaper, we systematically investigated two indispensable characteristics that\nthe LLMs-based QFS models should be harnessed, Lengthy Document Summarization\nand Efficiently Fine-grained Query-LLM Alignment, respectively.\nCorrespondingly, we propose two modules called Query-aware HyperExpert and\nQuery-focused Infini-attention to access the aforementioned characteristics.\nThese innovations pave the way for broader application and accessibility in the\nfield of QFS technology. Extensive experiments conducted on existing QFS\nbenchmarks indicate the effectiveness and generalizability of the proposed\napproach. Our code is publicly available at\nhttps://github.com/DCDmllm/IDEAL_Summary.", "paper_summary_zh": "\u4ee5\u67e5\u8a62\u70ba\u91cd\u9ede\u7684\u6458\u8981 (QFS) \u65e8\u5728\u7522\u751f\u6458\u8981\u4f86\u56de\u7b54\u7279\u5b9a\u611f\u8208\u8da3\u7684\u554f\u984c\uff0c\u8b93\u4f7f\u7528\u8005\u80fd\u6709\u66f4\u5927\u7684\u63a7\u5236\u6b0a\u548c\u500b\u4eba\u5316\u8a2d\u5b9a\u3002\u96a8\u8457\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u51fa\u73fe\uff0c\u986f\u793a\u51fa\u5b83\u5011\u900f\u904e\u5927\u898f\u6a21\u9810\u8a13\u7df4\u800c\u5177\u5099\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u6587\u5b57\u7406\u89e3\u80fd\u529b\uff0c\u9019\u6697\u793a\u4e86\u8403\u53d6\u7247\u6bb5\u751f\u6210\u7684\u5de8\u5927\u6f5b\u529b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u7cfb\u7d71\u6027\u5730\u63a2\u8a0e\u4e86\u5169\u500b LLM \u70ba\u57fa\u790e\u7684 QFS \u6a21\u578b\u61c9\u8a72\u5177\u5099\u7684\u4e0d\u53ef\u6216\u7f3a\u7279\u5fb5\uff0c\u5206\u5225\u662f\u5197\u9577\u6587\u4ef6\u6458\u8981\u548c\u9ad8\u6548\u7684\u7d30\u7c92\u5ea6\u67e5\u8a62-LLM \u5c0d\u9f4a\u3002\u76f8\u61c9\u5730\uff0c\u6211\u5011\u63d0\u51fa\u5169\u500b\u6a21\u7d44\uff0c\u7a31\u70ba\u67e5\u8a62\u611f\u77e5 HyperExpert \u548c\u67e5\u8a62\u70ba\u91cd\u9ede\u7684 Infini-attention\uff0c\u4ee5\u5b58\u53d6\u4e0a\u8ff0\u7279\u5fb5\u3002\u9019\u4e9b\u5275\u65b0\u70ba QFS \u6280\u8853\u9818\u57df\u7684\u66f4\u5ee3\u6cdb\u61c9\u7528\u548c\u53ef\u53ca\u6027\u92ea\u5e73\u4e86\u9053\u8def\u3002\u5728\u73fe\u6709 QFS \u57fa\u6e96\u4e0a\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u986f\u793a\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u666e\u904d\u6027\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u5df2\u516c\u958b\u767c\u5e03\u5728 https://github.com/DCDmllm/IDEAL_Summary\u3002", "author": "Jie Cao et.al.", "authors": "Jie Cao, Dian Jiao, Qiang Yan, Wenqiao Zhang, Siliang Tang, Yueting Zhuang", "id": "2407.10486v1", "paper_url": "http://arxiv.org/abs/2407.10486v1", "repo": "null"}}