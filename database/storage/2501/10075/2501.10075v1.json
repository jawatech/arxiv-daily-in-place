{"2501.10075": {"publish_time": "2025-01-17", "title": "Robust Change Captioning in Remote Sensing: SECOND-CC Dataset and MModalCC Framework", "paper_summary": "Remote sensing change captioning (RSICC) aims to describe changes between\nbitemporal images in natural language. Existing methods often fail under\nchallenges like illumination differences, viewpoint changes, blur effects,\nleading to inaccuracies, especially in no-change regions. Moreover, the images\nacquired at different spatial resolutions and have registration errors tend to\naffect the captions. To address these issues, we introduce SECOND-CC, a novel\nRSICC dataset featuring high-resolution RGB image pairs, semantic segmentation\nmaps, and diverse real-world scenarios. SECOND-CC which contains 6,041 pairs of\nbitemporal RS images and 30,205 sentences describing the differences between\nimages. Additionally, we propose MModalCC, a multimodal framework that\nintegrates semantic and visual data using advanced attention mechanisms,\nincluding Cross-Modal Cross Attention (CMCA) and Multimodal Gated Cross\nAttention (MGCA). Detailed ablation studies and attention visualizations\nfurther demonstrate its effectiveness and ability to address RSICC challenges.\nComprehensive experiments show that MModalCC outperforms state-of-the-art RSICC\nmethods, including RSICCformer, Chg2Cap, and PSNet with +4.6% improvement on\nBLEU4 score and +9.6% improvement on CIDEr score. We will make our dataset and\ncodebase publicly available to facilitate future research at\nhttps://github.com/ChangeCapsInRS/SecondCC", "paper_summary_zh": "\u9059\u611f\u8b8a\u52d5\u6a19\u984c\uff08RSICC\uff09\u65e8\u5728\u4ee5\u81ea\u7136\u8a9e\u8a00\u63cf\u8ff0\u96d9\u6642\u5e8f\u5f71\u50cf\u9593\u7684\u8b8a\u52d5\u3002\u73fe\u6709\u65b9\u6cd5\u7d93\u5e38\u5728\u5149\u7167\u5dee\u7570\u3001\u8996\u89d2\u8b8a\u52d5\u3001\u6a21\u7cca\u6548\u679c\u7b49\u6311\u6230\u4e0b\u5931\u6548\uff0c\u5c0e\u81f4\u4e0d\u6e96\u78ba\uff0c\u7279\u5225\u662f\u5728\u7121\u8b8a\u52d5\u5340\u57df\u3002\u6b64\u5916\uff0c\u4ee5\u4e0d\u540c\u7a7a\u9593\u89e3\u6790\u5ea6\u53d6\u5f97\u7684\u5f71\u50cf\u548c\u8a3b\u518a\u932f\u8aa4\u5f80\u5f80\u6703\u5f71\u97ff\u6a19\u984c\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86 SECOND-CC\uff0c\u9019\u662f\u4e00\u500b\u65b0\u7a4e\u7684 RSICC \u8cc7\u6599\u96c6\uff0c\u5177\u5099\u9ad8\u89e3\u6790\u5ea6 RGB \u5f71\u50cf\u5c0d\u3001\u8a9e\u610f\u5206\u5272\u5730\u5716\u548c\u591a\u5143\u7684\u771f\u5be6\u4e16\u754c\u5834\u666f\u3002SECOND-CC \u5305\u542b 6,041 \u5c0d\u96d9\u6642\u5e8f RS \u5f71\u50cf\u548c 30,205 \u500b\u63cf\u8ff0\u5f71\u50cf\u5dee\u7570\u7684\u53e5\u5b50\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u4e86 MModalCC\uff0c\u9019\u662f\u4e00\u500b\u591a\u6a21\u614b\u67b6\u69cb\uff0c\u4f7f\u7528\u9032\u968e\u6ce8\u610f\u6a5f\u5236\u6574\u5408\u8a9e\u610f\u548c\u8996\u89ba\u8cc7\u6599\uff0c\u5305\u62ec\u8de8\u6a21\u614b\u4ea4\u53c9\u6ce8\u610f\uff08CMCA\uff09\u548c\u591a\u6a21\u614b\u9598\u63a7\u4ea4\u53c9\u6ce8\u610f\uff08MGCA\uff09\u3002\u8a73\u7d30\u7684\u6d88\u878d\u7814\u7a76\u548c\u6ce8\u610f\u8996\u89ba\u5316\u9032\u4e00\u6b65\u8b49\u660e\u4e86\u5176\u6709\u6548\u6027\u548c\u89e3\u6c7a RSICC \u6311\u6230\u7684\u80fd\u529b\u3002\u7d9c\u5408\u5be6\u9a57\u986f\u793a\uff0cMModalCC \u512a\u65bc\u73fe\u6709 RSICC \u65b9\u6cd5\uff0c\u5305\u62ec RSICCformer\u3001Chg2Cap \u548c PSNet\uff0c\u5728 BLEU4 \u8a55\u5206\u4e0a\u63d0\u5347\u4e86 +4.6%\uff0c\u5728 CIDEr \u8a55\u5206\u4e0a\u63d0\u5347\u4e86 +9.6%\u3002\u6211\u5011\u5c07\u516c\u958b\u6211\u5011\u7684\u8cc7\u6599\u96c6\u548c\u7a0b\u5f0f\u78bc\u5eab\uff0c\u4ee5\u5229\u65bc\u5f8c\u7e8c\u7814\u7a76\uff0c\u7db2\u5740\u70ba https://github.com/ChangeCapsInRS/SecondCC", "author": "Ali Can Karaca et.al.", "authors": "Ali Can Karaca, M. Enes Ozelbas, Saadettin Berber, Orkhan Karimli, Turabi Yildirim, M. Fatih Amasyali", "id": "2501.10075v1", "paper_url": "http://arxiv.org/abs/2501.10075v1", "repo": "null"}}