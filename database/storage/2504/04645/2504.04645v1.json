{"2504.04645": {"publish_time": "2025-04-06", "title": "Here Comes the Explanation: A Shapley Perspective on Multi-contrast Medical Image Segmentation", "paper_summary": "Deep learning has been successfully applied to medical image segmentation,\nenabling accurate identification of regions of interest such as organs and\nlesions. This approach works effectively across diverse datasets, including\nthose with single-image contrast, multi-contrast, and multimodal imaging data.\nTo improve human understanding of these black-box models, there is a growing\nneed for Explainable AI (XAI) techniques for model transparency and\naccountability. Previous research has primarily focused on post hoc pixel-level\nexplanations, using methods gradient-based and perturbation-based apporaches.\nThese methods rely on gradients or perturbations to explain model predictions.\nHowever, these pixel-level explanations often struggle with the complexity\ninherent in multi-contrast magnetic resonance imaging (MRI) segmentation tasks,\nand the sparsely distributed explanations have limited clinical relevance. In\nthis study, we propose using contrast-level Shapley values to explain\nstate-of-the-art models trained on standard metrics used in brain tumor\nsegmentation. Our results demonstrate that Shapley analysis provides valuable\ninsights into different models' behavior used for tumor segmentation. We\ndemonstrated a bias for U-Net towards over-weighing T1-contrast and FLAIR,\nwhile Swin-UNETR provided a cross-contrast understanding with balanced Shapley\ndistribution.", "paper_summary_zh": "<paragraph>\u6df1\u5ea6\u5b78\u7fd2\u5df2\u6210\u529f\u61c9\u7528\u65bc\u91ab\u5b78\u5f71\u50cf\u5206\u5272\uff0c\u80fd\u5920\u6e96\u78ba\u8b58\u5225\u611f\u8208\u8da3\u5340\u57df\uff0c\u4f8b\u5982\u5668\u5b98\u548c\u75c5\u7076\u3002\u9019\u7a2e\u65b9\u6cd5\u5728\u5404\u7a2e\u6578\u64da\u96c6\u4e2d\u90fd\u6709\u6548\uff0c\u5305\u62ec\u5177\u6709\u55ae\u5f71\u50cf\u5c0d\u6bd4\u3001\u591a\u5c0d\u6bd4\u548c\u591a\u6a21\u614b\u6210\u50cf\u6578\u64da\u7684\u6578\u64da\u96c6\u3002\u70ba\u4e86\u63d0\u9ad8\u4eba\u5011\u5c0d\u9019\u4e9b\u9ed1\u76d2\u6a21\u578b\u7684\u7406\u89e3\uff0c\u4eba\u5011\u8d8a\u4f86\u8d8a\u9700\u8981\u53ef\u89e3\u91cb\u4eba\u5de5\u667a\u80fd (XAI) \u6280\u8853\u4f86\u63d0\u9ad8\u6a21\u578b\u7684\u900f\u660e\u5ea6\u548c\u53ef\u9760\u6027\u3002\u5148\u524d\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u4e8b\u5f8c\u50cf\u7d20\u7d1a\u7684\u89e3\u91cb\uff0c\u4f7f\u7528\u57fa\u65bc\u68af\u5ea6\u548c\u57fa\u65bc\u64fe\u52d5\u7684\u65b9\u6cd5\u3002\u9019\u4e9b\u65b9\u6cd5\u4f9d\u8cf4\u68af\u5ea6\u6216\u64fe\u52d5\u4f86\u89e3\u91cb\u6a21\u578b\u9810\u6e2c\u3002\u7136\u800c\uff0c\u9019\u4e9b\u50cf\u7d20\u7d1a\u7684\u89e3\u91cb\u901a\u5e38\u96e3\u4ee5\u61c9\u4ed8\u591a\u5c0d\u6bd4\u78c1\u5171\u632f\u6210\u50cf (MRI) \u5206\u5272\u4efb\u52d9\u4e2d\u56fa\u6709\u7684\u8907\u96dc\u6027\uff0c\u800c\u4e14\u7a00\u758f\u5206\u4f48\u7684\u89e3\u91cb\u8207\u81e8\u5e8a\u7684\u76f8\u95dc\u6027\u6709\u9650\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u5efa\u8b70\u4f7f\u7528\u5c0d\u6bd4\u5ea6\u7d1a Shapley \u503c\u4f86\u89e3\u91cb\u4f7f\u7528\u8166\u816b\u7624\u5206\u5272\u6a19\u6e96\u6307\u6a19\u8a13\u7df4\u7684\u6700\u5148\u9032\u6a21\u578b\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0cShapley \u5206\u6790\u63d0\u4f9b\u4e86\u5c0d\u7528\u65bc\u816b\u7624\u5206\u5272\u7684\u4e0d\u540c\u6a21\u578b\u884c\u70ba\u7684\u5bf6\u8cb4\u898b\u89e3\u3002\u6211\u5011\u8b49\u660e\u4e86 U-Net \u504f\u5411\u65bc\u904e\u5ea6\u91cd\u8996 T1 \u5c0d\u6bd4\u548c FLAIR\uff0c\u800c Swin-UNETR \u63d0\u4f9b\u4e86\u5177\u6709\u5e73\u8861 Shapley \u5206\u4f48\u7684\u8de8\u5c0d\u6bd4\u7406\u89e3\u3002</paragraph>\n", "author": "Tianyi Ren et.al.", "authors": "Tianyi Ren, Juampablo Heras Rivera, Hitender Oswal, Yutong Pan, Agamdeep Chopra, Jacob Ruzevick, Mehmet Kurt", "id": "2504.04645v1", "paper_url": "http://arxiv.org/abs/2504.04645v1", "repo": "null"}}