{"2501.12851": {"publish_time": "2025-01-22", "title": "ACEBench: Who Wins the Match Point in Tool Learning?", "paper_summary": "Large language models (LLMs) have demonstrated significant potential in\ndecision-making and reasoning, especially when combined with various tools to\neffectively solve complex problems. However, existing evaluation systems for\nassessing LLM function calling capabilities have several limitations: (1)\nlimited evaluation scenarios, lacking assessments in real multi-turn dialogue\ncontexts; (2) narrow evaluation dimensions, lacking detailed assessments for\nfine-grained function calls; (3) relying on LLMs or real API executions for\nresult evaluation, which introduces significant overhead. To address these\nissues, we propose a comprehensive evaluation system named ACEBench. This\nsystem is meticulously designed to encompass a wide spectrum of function\ncalling scenarios. Moreover, it categorizes these scenarios into three primary\ntypes according to the evaluation methodology: Normal, Special, and Agent.\nNormal evaluates function calls in basic scenarios; Special evaluates function\ncalls in scenarios with vague or incomplete instructions; Agent introduces\nmulti-agent interactions to simulate function calling evaluation in real-world\nmulti-turn interactions. We conducted extensive experiments on ACEBench,\nanalyzing various LLMs in-depth and performing a more granular analysis of\nerror causes across different data types.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u6c7a\u7b56\u548c\u63a8\u7406\u65b9\u9762\u5c55\u73fe\u51fa\u986f\u8457\u7684\u6f5b\u529b\uff0c\u7279\u5225\u662f\u5728\u7d50\u5408\u5404\u7a2e\u5de5\u5177\u4ee5\u6709\u6548\u89e3\u6c7a\u8907\u96dc\u554f\u984c\u6642\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684\u8a55\u4f30\u7cfb\u7d71\u5728\u8a55\u4f30 LLM \u51fd\u6578\u547c\u53eb\u80fd\u529b\u6642\u6709\u5e7e\u500b\u9650\u5236\uff1a(1) \u8a55\u4f30\u5834\u666f\u6709\u9650\uff0c\u7f3a\u4e4f\u5728\u771f\u5be6\u591a\u8f2a\u5c0d\u8a71\u60c5\u5883\u4e2d\u7684\u8a55\u4f30\uff1b(2) \u8a55\u4f30\u7dad\u5ea6\u72f9\u7a84\uff0c\u7f3a\u4e4f\u5c0d\u7d30\u7c92\u5ea6\u51fd\u6578\u547c\u53eb\u7684\u8a73\u7d30\u8a55\u4f30\uff1b(3) \u4f9d\u8cf4 LLM \u6216\u771f\u5be6 API \u57f7\u884c\u4f86\u9032\u884c\u7d50\u679c\u8a55\u4f30\uff0c\u9019\u6703\u9020\u6210\u986f\u8457\u7684\u958b\u92b7\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u540d\u70ba ACEBench \u7684\u7d9c\u5408\u8a55\u4f30\u7cfb\u7d71\u3002\u6b64\u7cfb\u7d71\u7d93\u904e\u7cbe\u5fc3\u8a2d\u8a08\uff0c\u6db5\u84cb\u4e86\u5ee3\u6cdb\u7684\u51fd\u6578\u547c\u53eb\u5834\u666f\u3002\u6b64\u5916\uff0c\u5b83\u6839\u64da\u8a55\u4f30\u65b9\u6cd5\u5c07\u9019\u4e9b\u5834\u666f\u5206\u70ba\u4e09\u7a2e\u985e\u578b\uff1a\u4e00\u822c\u3001\u7279\u6b8a\u548c\u4ee3\u7406\u3002\u4e00\u822c\u6703\u5728\u57fa\u672c\u5834\u666f\u4e2d\u8a55\u4f30\u51fd\u6578\u547c\u53eb\uff1b\u7279\u6b8a\u6703\u5728\u5177\u6709\u6a21\u7cca\u6216\u4e0d\u5b8c\u6574\u6307\u4ee4\u7684\u5834\u666f\u4e2d\u8a55\u4f30\u51fd\u6578\u547c\u53eb\uff1b\u4ee3\u7406\u6703\u5f15\u5165\u591a\u4ee3\u7406\u4e92\u52d5\uff0c\u4ee5\u6a21\u64ec\u5728\u771f\u5be6\u4e16\u754c\u591a\u8f2a\u4e92\u52d5\u4e2d\u7684\u51fd\u6578\u547c\u53eb\u8a55\u4f30\u3002\u6211\u5011\u5728 ACEBench \u4e0a\u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u6df1\u5165\u5206\u6790\u4e86\u5404\u7a2e LLM\uff0c\u4e26\u5c0d\u4e0d\u540c\u6578\u64da\u985e\u578b\u7684\u932f\u8aa4\u539f\u56e0\u9032\u884c\u4e86\u66f4\u7d30\u7dfb\u7684\u5206\u6790\u3002", "author": "Chen Chen et.al.", "authors": "Chen Chen, Xinlong Hao, Weiwen Liu, Xu Huang, Xingshan Zeng, Shuai Yu, Dexun Li, Shuai Wang, Weinan Gan, Yuefeng Huang, Xinzhi Wang, Defu Lian, Baoqun Yin, Yasheng Wang, Wu Liu", "id": "2501.12851v1", "paper_url": "http://arxiv.org/abs/2501.12851v1", "repo": "null"}}