{"2405.12656": {"publish_time": "2024-05-21", "title": "Retrieval-Augmented Language Model for Extreme Multi-Label Knowledge Graph Link Prediction", "paper_summary": "Extrapolation in Large language models (LLMs) for open-ended inquiry\nencounters two pivotal issues: (1) hallucination and (2) expensive training\ncosts. These issues present challenges for LLMs in specialized domains and\npersonalized data, requiring truthful responses and low fine-tuning costs.\nExisting works attempt to tackle the problem by augmenting the input of a\nsmaller language model with information from a knowledge graph (KG). However,\nthey have two limitations: (1) failing to extract relevant information from a\nlarge one-hop neighborhood in KG and (2) applying the same augmentation\nstrategy for KGs with different characteristics that may result in low\nperformance. Moreover, open-ended inquiry typically yields multiple responses,\nfurther complicating extrapolation. We propose a new task, the extreme\nmulti-label KG link prediction task, to enable a model to perform extrapolation\nwith multiple responses using structured real-world knowledge. Our retriever\nidentifies relevant one-hop neighbors by considering entity, relation, and\ntextual data together. Our experiments demonstrate that (1) KGs with different\ncharacteristics require different augmenting strategies, and (2) augmenting the\nlanguage model's input with textual data improves task performance\nsignificantly. By incorporating the retrieval-augmented framework with KG, our\nframework, with a small parameter size, is able to extrapolate based on a given\nKG. The code can be obtained on GitHub:\nhttps://github.com/exiled1143/Retrieval-Augmented-Language-Model-for-Multi-Label-Knowledge-Graph-Link-Prediction.git", "paper_summary_zh": "<paragraph>\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4e2d\u7528\u65bc\u958b\u653e\u5f0f\u63a2\u7a76\u7684\u63a8\u65b7\u6703\u906d\u9047\u5169\u500b\u95dc\u9375\u554f\u984c\uff1a(1) \u5e7b\u89ba\u548c (2) \u6602\u8cb4\u7684\u8a13\u7df4\u6210\u672c\u3002\u9019\u4e9b\u554f\u984c\u70ba\u5c08\u9580\u9818\u57df\u548c\u500b\u4eba\u5316\u6578\u64da\u4e2d\u7684 LLM \u5e36\u4f86\u6311\u6230\uff0c\u9700\u8981\u771f\u5be6\u7684\u56de\u61c9\u548c\u4f4e\u5fae\u8abf\u6210\u672c\u3002\u73fe\u6709\u4f5c\u54c1\u5617\u8a66\u901a\u904e\u4f7f\u7528\u4f86\u81ea\u77e5\u8b58\u5716 (KG) \u7684\u8cc7\u8a0a\u64f4\u5145\u8f03\u5c0f\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u8f38\u5165\u4f86\u89e3\u6c7a\u554f\u984c\u3002\u7136\u800c\uff0c\u5b83\u5011\u6709\u5169\u500b\u9650\u5236\uff1a(1) \u7121\u6cd5\u5f9e KG \u4e2d\u7684\u5ee3\u5927\u4e00\u8df3\u9130\u57df\u4e2d\u63d0\u53d6\u76f8\u95dc\u8cc7\u8a0a\uff0c\u4ee5\u53ca (2) \u5c0d\u5177\u6709\u4e0d\u540c\u7279\u5fb5\u7684 KG \u61c9\u7528\u76f8\u540c\u7684\u64f4\u5145\u7b56\u7565\uff0c\u9019\u53ef\u80fd\u6703\u5c0e\u81f4\u4f4e\u6548\u80fd\u3002\u6b64\u5916\uff0c\u958b\u653e\u5f0f\u63a2\u7a76\u901a\u5e38\u6703\u7522\u751f\u591a\u91cd\u56de\u61c9\uff0c\u9032\u4e00\u6b65\u8907\u96dc\u5316\u63a8\u65b7\u3002\u6211\u5011\u63d0\u51fa\u4e00\u500b\u65b0\u4efb\u52d9\uff0c\u5373\u6975\u7aef\u591a\u6a19\u7c64 KG \u9023\u7d50\u9810\u6e2c\u4efb\u52d9\uff0c\u4ee5\u4f7f\u6a21\u578b\u80fd\u5920\u4f7f\u7528\u7d50\u69cb\u5316\u7684\u771f\u5be6\u4e16\u754c\u77e5\u8b58\u57f7\u884c\u5177\u6709\u591a\u91cd\u56de\u61c9\u7684\u63a8\u65b7\u3002\u6211\u5011\u7684\u6aa2\u7d22\u5668\u901a\u904e\u540c\u6642\u8003\u616e\u5be6\u9ad4\u3001\u95dc\u4fc2\u548c\u6587\u5b57\u8cc7\u6599\u4f86\u8b58\u5225\u76f8\u95dc\u7684\u4e00\u8df3\u9130\u5c45\u3002\u6211\u5011\u7684\u5be6\u9a57\u8b49\u660e\uff1a(1) \u5177\u6709\u4e0d\u540c\u7279\u5fb5\u7684 KG \u9700\u8981\u4e0d\u540c\u7684\u64f4\u5145\u7b56\u7565\uff0c\u4ee5\u53ca (2) \u4f7f\u7528\u6587\u5b57\u8cc7\u6599\u64f4\u5145\u8a9e\u8a00\u6a21\u578b\u7684\u8f38\u5165\u6703\u986f\u8457\u6539\u5584\u4efb\u52d9\u6548\u80fd\u3002\u900f\u904e\u5c07\u6aa2\u7d22\u64f4\u5145\u6846\u67b6\u8207 KG \u6574\u5408\uff0c\u6211\u5011\u7684\u6846\u67b6\u5728\u53c3\u6578\u898f\u6a21\u8f03\u5c0f\u7684\u60c5\u6cc1\u4e0b\uff0c\u80fd\u5920\u6839\u64da\u7d66\u5b9a\u7684 KG \u9032\u884c\u63a8\u65b7\u3002\u4ee3\u78bc\u53ef\u4ee5\u5728 GitHub \u4e0a\u53d6\u5f97\uff1a\nhttps://github.com/exiled1143/Retrieval-Augmented-Language-Model-for-Multi-Label-Knowledge-Graph-Link-Prediction.git</paragraph>", "author": "Yu-Hsiang Lin et.al.", "authors": "Yu-Hsiang Lin, Huang-Ting Shieh, Chih-Yu Liu, Kuang-Ting Lee, Hsiao-Cheng Chang, Jing-Lun Yang, Yu-Sheng Lin", "id": "2405.12656v1", "paper_url": "http://arxiv.org/abs/2405.12656v1", "repo": "https://github.com/exiled1143/retrieval-augmented-language-model-for-multi-label-knowledge-graph-link-prediction"}}