{"2406.16605": {"publish_time": "2024-06-24", "title": "CLEAR: Can Language Models Really Understand Causal Graphs?", "paper_summary": "Causal reasoning is a cornerstone of how humans interpret the world. To model\nand reason about causality, causal graphs offer a concise yet effective\nsolution. Given the impressive advancements in language models, a crucial\nquestion arises: can they really understand causal graphs? To this end, we\npioneer an investigation into language models' understanding of causal graphs.\nSpecifically, we develop a framework to define causal graph understanding, by\nassessing language models' behaviors through four practical criteria derived\nfrom diverse disciplines (e.g., philosophy and psychology). We then develop\nCLEAR, a novel benchmark that defines three complexity levels and encompasses\n20 causal graph-based tasks across these levels. Finally, based on our\nframework and benchmark, we conduct extensive experiments on six leading\nlanguage models and summarize five empirical findings. Our results indicate\nthat while language models demonstrate a preliminary understanding of causal\ngraphs, significant potential for improvement remains. Our project website is\nat https://github.com/OpenCausaLab/CLEAR.", "paper_summary_zh": "\u56e0\u679c\u63a8\u7406\u662f\u4eba\u985e\u8a6e\u91cb\u4e16\u754c\u7684\u57fa\u77f3\u3002\u70ba\u4e86\u5c0d\u56e0\u679c\u95dc\u4fc2\u5efa\u6a21\u548c\u63a8\u7406\uff0c\u56e0\u679c\u5716\u63d0\u4f9b\u4e86\u4e00\u500b\u7c21\u6f54\u800c\u6709\u6548\u7684\u89e3\u6c7a\u65b9\u6848\u3002\u9451\u65bc\u8a9e\u8a00\u6a21\u578b\u7684\u9a5a\u4eba\u9032\u6b65\uff0c\u4e00\u500b\u95dc\u9375\u554f\u984c\u51fa\u73fe\u4e86\uff1a\u5b83\u5011\u771f\u7684\u80fd\u7406\u89e3\u56e0\u679c\u5716\u55ce\uff1f\u70ba\u6b64\uff0c\u6211\u5011\u7387\u5148\u5c0d\u8a9e\u8a00\u6a21\u578b\u5c0d\u56e0\u679c\u5716\u7684\u7406\u89e3\u9032\u884c\u4e86\u8abf\u67e5\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u6846\u67b6\u4f86\u5b9a\u7fa9\u56e0\u679c\u5716\u7406\u89e3\uff0c\u901a\u904e\u5f9e\u4e0d\u540c\u5b78\u79d1\uff08\u4f8b\u5982\u54f2\u5b78\u548c\u5fc3\u7406\u5b78\uff09\u884d\u751f\u7684\u56db\u500b\u5be6\u7528\u6a19\u6e96\u4f86\u8a55\u4f30\u8a9e\u8a00\u6a21\u578b\u7684\u884c\u70ba\u3002\u7136\u5f8c\uff0c\u6211\u5011\u958b\u767c\u4e86 CLEAR\uff0c\u4e00\u500b\u65b0\u7684\u57fa\u6e96\uff0c\u5b83\u5b9a\u7fa9\u4e86\u4e09\u500b\u8907\u96dc\u6027\u7d1a\u5225\uff0c\u4e26\u6db5\u84cb\u4e86\u9019\u4e9b\u7d1a\u5225\u4e2d\u7684 20 \u500b\u57fa\u65bc\u56e0\u679c\u5716\u7684\u4efb\u52d9\u3002\u6700\u5f8c\uff0c\u57fa\u65bc\u6211\u5011\u7684\u6846\u67b6\u548c\u57fa\u6e96\uff0c\u6211\u5011\u5c0d\u516d\u500b\u9818\u5148\u7684\u8a9e\u8a00\u6a21\u578b\u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u4e26\u7e3d\u7d50\u4e86\u4e94\u9805\u5be6\u8b49\u767c\u73fe\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0c\u5118\u7ba1\u8a9e\u8a00\u6a21\u578b\u5c55\u793a\u4e86\u5c0d\u56e0\u679c\u5716\u7684\u521d\u6b65\u7406\u89e3\uff0c\u4f46\u4ecd\u6709\u5f88\u5927\u7684\u6539\u9032\u6f5b\u529b\u3002\u6211\u5011\u7684\u9805\u76ee\u7db2\u7ad9\u4f4d\u65bc https://github.com/OpenCausaLab/CLEAR\u3002", "author": "Sirui Chen et.al.", "authors": "Sirui Chen, Mengying Xu, Kun Wang, Xingyu Zeng, Rui Zhao, Shengjie Zhao, Chaochao Lu", "id": "2406.16605v1", "paper_url": "http://arxiv.org/abs/2406.16605v1", "repo": "https://github.com/opencausalab/clear"}}