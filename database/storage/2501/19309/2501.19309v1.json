{"2501.19309": {"publish_time": "2025-01-31", "title": "Judge Decoding: Faster Speculative Sampling Requires Going Beyond Model Alignment", "paper_summary": "The performance of large language models (LLMs) is closely linked to their\nunderlying size, leading to ever-growing networks and hence slower inference.\nSpeculative decoding has been proposed as a technique to accelerate\nautoregressive generation, leveraging a fast draft model to propose candidate\ntokens, which are then verified in parallel based on their likelihood under the\ntarget model. While this approach guarantees to reproduce the target output, it\nincurs a substantial penalty: many high-quality draft tokens are rejected, even\nwhen they represent objectively valid continuations. Indeed, we show that even\npowerful draft models such as GPT-4o, as well as human text cannot achieve high\nacceptance rates under the standard verification scheme. This severely limits\nthe speedup potential of current speculative decoding methods, as an early\nrejection becomes overwhelmingly likely when solely relying on alignment of\ndraft and target.\n  We thus ask the following question: Can we adapt verification to recognize\ncorrect, but non-aligned replies? To this end, we draw inspiration from the\nLLM-as-a-judge framework, which demonstrated that LLMs are able to rate answers\nin a versatile way. We carefully design a dataset to elicit the same capability\nin the target model by training a compact module on top of the embeddings to\nproduce ``judgements\" of the current continuation. We showcase our strategy on\nthe Llama-3.1 family, where our 8b/405B-Judge achieves a speedup of 9x over\nLlama-405B, while maintaining its quality on a large range of benchmarks. These\nbenefits remain present even in optimized inference frameworks, where our\nmethod reaches up to 141 tokens/s for 8B/70B-Judge and 129 tokens/s for 8B/405B\non 2 and 8 H100s respectively.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6548\u80fd\u8207\u5176\u57fa\u790e\u5927\u5c0f\u5bc6\u5207\u76f8\u95dc\uff0c\u5c0e\u81f4\u7db2\u8def\u4e0d\u65b7\u64f4\u5927\uff0c\u9032\u800c\u964d\u4f4e\u63a8\u7406\u901f\u5ea6\u3002\n\u63a8\u6e2c\u6027\u89e3\u78bc\u5df2\u88ab\u63d0\u51fa\u4f5c\u70ba\u4e00\u7a2e\u52a0\u901f\u81ea\u8ff4\u6b78\u751f\u6210\u7684\u6280\u8853\uff0c\u5229\u7528\u5feb\u901f\u8349\u7a3f\u6a21\u578b\u4f86\u5efa\u8b70\u5019\u9078\u8a5e\u5143\uff0c\u7136\u5f8c\u6839\u64da\u76ee\u6a19\u6a21\u578b\u4e0b\u7684\u53ef\u80fd\u6027\u4e26\u884c\u9a57\u8b49\u9019\u4e9b\u8a5e\u5143\u3002\u96d6\u7136\u9019\u7a2e\u65b9\u6cd5\u4fdd\u8b49\u91cd\u73fe\u76ee\u6a19\u8f38\u51fa\uff0c\u4f46\u5b83\u6703\u7522\u751f\u5927\u91cf\u7684\u61f2\u7f70\uff1a\u8a31\u591a\u9ad8\u54c1\u8cea\u7684\u8349\u7a3f\u8a5e\u5143\u6703\u88ab\u62d2\u7d55\uff0c\u5373\u4f7f\u5b83\u5011\u4ee3\u8868\u5ba2\u89c0\u6709\u6548\u7684\u5ef6\u7e8c\u3002\u4e8b\u5be6\u4e0a\uff0c\u6211\u5011\u8b49\u660e\u4e86\u5373\u4f7f\u662f\u5f37\u5927\u7684\u8349\u7a3f\u6a21\u578b\uff0c\u4f8b\u5982 GPT-4o\uff0c\u4ee5\u53ca\u4eba\u985e\u6587\u5b57\uff0c\u5728\u6a19\u6e96\u9a57\u8b49\u65b9\u6848\u4e0b\u4e5f\u7121\u6cd5\u9054\u5230\u9ad8\u63a5\u53d7\u7387\u3002\u9019\u56b4\u91cd\u9650\u5236\u4e86\u7576\u524d\u63a8\u6e2c\u6027\u89e3\u78bc\u65b9\u6cd5\u7684\u52a0\u901f\u6f5b\u529b\uff0c\u56e0\u70ba\u7576\u50c5\u4f9d\u8cf4\u8349\u7a3f\u548c\u76ee\u6a19\u7684\u4e00\u81f4\u6027\u6642\uff0c\u65e9\u671f\u62d2\u7d55\u7684\u53ef\u80fd\u6027\u6703\u8b8a\u5f97\u6975\u5927\u3002\n\u56e0\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u4ee5\u4e0b\u554f\u984c\uff1a\u6211\u5011\u80fd\u8abf\u6574\u9a57\u8b49\u4ee5\u8b58\u5225\u6b63\u78ba\u4f46\u672a\u5c0d\u9f4a\u7684\u56de\u8986\u55ce\uff1f\u70ba\u6b64\uff0c\u6211\u5011\u5f9e LLM \u4f5c\u70ba\u8a55\u5224\u8005\u6846\u67b6\u4e2d\u6c72\u53d6\u9748\u611f\uff0c\u8a72\u6846\u67b6\u8b49\u660e LLM \u80fd\u5920\u4ee5\u591a\u6a23\u5316\u7684\u65b9\u5f0f\u8a55\u5206\u7b54\u6848\u3002\u6211\u5011\u4ed4\u7d30\u8a2d\u8a08\u4e86\u4e00\u500b\u6578\u64da\u96c6\uff0c\u4ee5\u5728\u76ee\u6a19\u6a21\u578b\u4e2d\u5f15\u767c\u76f8\u540c\u7684\u6027\u80fd\uff0c\u65b9\u6cd5\u662f\u5728\u5d4c\u5165\u4e4b\u4e0a\u8a13\u7df4\u4e00\u500b\u7cbe\u7c21\u6a21\u7d44\uff0c\u4ee5\u5c0d\u7576\u524d\u5ef6\u7e8c\u7522\u751f\u300c\u5224\u65b7\u300d\u3002\u6211\u5011\u5728 Llama-3.1 \u7cfb\u5217\u4e2d\u5c55\u793a\u4e86\u6211\u5011\u7684\u7b56\u7565\uff0c\u5176\u4e2d\u6211\u5011\u7684 8b/405B-Judge \u5728 Llama-405B \u4e0a\u5be6\u73fe\u4e86 9 \u500d\u7684\u52a0\u901f\uff0c\u540c\u6642\u5728\u5927\u91cf\u7684\u57fa\u6e96\u6e2c\u8a66\u4e2d\u4fdd\u6301\u5176\u54c1\u8cea\u3002\u9019\u4e9b\u512a\u9ede\u5373\u4f7f\u5728\u6700\u4f73\u5316\u7684\u63a8\u7406\u6846\u67b6\u4e2d\u4ecd\u7136\u5b58\u5728\uff0c\u5176\u4e2d\u6211\u5011\u7684\u65b9\u6cd5\u5206\u5225\u5728 2 \u500b\u548c 8 \u500b H100 \u4e0a\uff0c\u91dd\u5c0d 8B/70B-Judge \u9054\u5230\u4e86\u6bcf\u79d2 141 \u500b\u8a5e\u5143\uff0c\u91dd\u5c0d 8B/405B \u9054\u5230\u4e86\u6bcf\u79d2 129 \u500b\u8a5e\u5143\u3002", "author": "Gregor Bachmann et.al.", "authors": "Gregor Bachmann, Sotiris Anagnostidis, Albert Pumarola, Markos Georgopoulos, Artsiom Sanakoyeu, Yuming Du, Edgar Sch\u00f6nfeld, Ali Thabet, Jonas Kohler", "id": "2501.19309v1", "paper_url": "http://arxiv.org/abs/2501.19309v1", "repo": "null"}}