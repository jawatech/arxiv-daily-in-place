{"2405.12434": {"publish_time": "2024-05-21", "title": "Resolving Word Vagueness with Scenario-guided Adapter for Natural Language Inference", "paper_summary": "Natural Language Inference (NLI) is a crucial task in natural language\nprocessing that involves determining the relationship between two sentences,\ntypically referred to as the premise and the hypothesis. However, traditional\nNLI models solely rely on the semantic information inherent in independent\nsentences and lack relevant situational visual information, which can hinder a\ncomplete understanding of the intended meaning of the sentences due to the\nambiguity and vagueness of language. To address this challenge, we propose an\ninnovative ScenaFuse adapter that simultaneously integrates large-scale\npre-trained linguistic knowledge and relevant visual information for NLI tasks.\nSpecifically, we first design an image-sentence interaction module to\nincorporate visuals into the attention mechanism of the pre-trained model,\nallowing the two modalities to interact comprehensively. Furthermore, we\nintroduce an image-sentence fusion module that can adaptively integrate visual\ninformation from images and semantic information from sentences. By\nincorporating relevant visual information and leveraging linguistic knowledge,\nour approach bridges the gap between language and vision, leading to improved\nunderstanding and inference capabilities in NLI tasks. Extensive benchmark\nexperiments demonstrate that our proposed ScenaFuse, a scenario-guided\napproach, consistently boosts NLI performance.", "paper_summary_zh": "\u81ea\u7136\u8a9e\u8a00\u63a8\u7406 (NLI) \u662f\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4e2d\u7684\u4e00\u9805\u95dc\u9375\u4efb\u52d9\uff0c\u6d89\u53ca\u78ba\u5b9a\u5169\u500b\u53e5\u5b50\u4e4b\u9593\u7684\u95dc\u4fc2\uff0c\u901a\u5e38\u7a31\u70ba\u524d\u63d0\u548c\u5047\u8a2d\u3002\u7136\u800c\uff0c\u50b3\u7d71\u7684 NLI \u6a21\u578b\u50c5\u4f9d\u8cf4\u65bc\u7368\u7acb\u53e5\u5b50\u4e2d\u56fa\u6709\u7684\u8a9e\u7fa9\u8cc7\u8a0a\uff0c\u4e26\u4e14\u7f3a\u4e4f\u76f8\u95dc\u7684\u60c5\u5883\u8996\u89ba\u8cc7\u8a0a\uff0c\u9019\u53ef\u80fd\u6703\u963b\u7919\u5c0d\u53e5\u5b50\u7684\u9810\u671f\u542b\u7fa9\u7684\u5b8c\u6574\u7406\u89e3\uff0c\u56e0\u70ba\u8a9e\u8a00\u7684\u6a21\u7cca\u6027\u548c\u542b\u7cca\u6027\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e00\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u5275\u65b0\u7684 ScenaFuse \u9069\u914d\u5668\uff0c\u5b83\u540c\u6642\u6574\u5408\u4e86\u5927\u898f\u6a21\u9810\u8a13\u7df4\u7684\u8a9e\u8a00\u77e5\u8b58\u548c\u76f8\u95dc\u8996\u89ba\u8cc7\u8a0a\uff0c\u7528\u65bc NLI \u4efb\u52d9\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u9996\u5148\u8a2d\u8a08\u4e86\u4e00\u500b\u5f71\u50cf\u53e5\u5b50\u4e92\u52d5\u6a21\u7d44\uff0c\u5c07\u8996\u89ba\u6548\u679c\u7d0d\u5165\u9810\u8a13\u7df4\u6a21\u578b\u7684\u6ce8\u610f\u6a5f\u5236\uff0c\u8b93\u9019\u5169\u7a2e\u6a21\u5f0f\u5168\u9762\u4e92\u52d5\u3002\u6b64\u5916\uff0c\u6211\u5011\u9084\u5f15\u5165\u4e86\u5f71\u50cf\u53e5\u5b50\u878d\u5408\u6a21\u7d44\uff0c\u5b83\u53ef\u4ee5\u9069\u61c9\u6027\u5730\u6574\u5408\u4f86\u81ea\u5f71\u50cf\u7684\u8996\u89ba\u8cc7\u8a0a\u548c\u4f86\u81ea\u53e5\u5b50\u7684\u8a9e\u7fa9\u8cc7\u8a0a\u3002\u900f\u904e\u6574\u5408\u76f8\u95dc\u8996\u89ba\u8cc7\u8a0a\u4e26\u5229\u7528\u8a9e\u8a00\u77e5\u8b58\uff0c\u6211\u5011\u7684\u505a\u6cd5\u7e2e\u5c0f\u4e86\u8a9e\u8a00\u548c\u8996\u89ba\u4e4b\u9593\u7684\u5dee\u8ddd\uff0c\u9032\u800c\u63d0\u5347 NLI \u4efb\u52d9\u4e2d\u7684\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\u3002\u5ee3\u6cdb\u7684\u57fa\u6e96\u5be6\u9a57\u8b49\u660e\uff0c\u6211\u5011\u63d0\u51fa\u7684 ScenaFuse \u662f\u4e00\u7a2e\u60c5\u5883\u5f15\u5c0e\u5f0f\u65b9\u6cd5\uff0c\u53ef\u6301\u7e8c\u63d0\u5347 NLI \u7684\u6548\u80fd\u3002", "author": "Yonghao Liu et.al.", "authors": "Yonghao Liu, Mengyu Li, Di Liang, Ximing Li, Fausto Giunchiglia, Lan Huang, Xiaoyue Feng, Renchu Guan", "id": "2405.12434v1", "paper_url": "http://arxiv.org/abs/2405.12434v1", "repo": "null"}}