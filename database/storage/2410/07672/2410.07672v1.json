{"2410.07672": {"publish_time": "2024-10-10", "title": "MACPO: Weak-to-Strong Alignment via Multi-Agent Contrastive Preference Optimization", "paper_summary": "As large language models (LLMs) are rapidly advancing and achieving\nnear-human capabilities, aligning them with human values is becoming more\nurgent. In scenarios where LLMs outperform humans, we face a weak-to-strong\nalignment problem where we need to effectively align strong student LLMs\nthrough weak supervision generated by weak teachers. Existing alignment methods\nmainly focus on strong-to-weak alignment and self-alignment settings, and it is\nimpractical to adapt them to the much harder weak-to-strong alignment setting.\nTo fill this gap, we propose a multi-agent contrastive preference optimization\n(MACPO) framework. MACPO facilitates weak teachers and strong students to learn\nfrom each other by iteratively reinforcing unfamiliar positive behaviors while\npenalizing familiar negative ones. To get this, we devise a mutual positive\nbehavior augmentation strategy to encourage weak teachers and strong students\nto learn from each other's positive behavior and further provide higher quality\npositive behavior for the next iteration. Additionally, we propose a hard\nnegative behavior construction strategy to induce weak teachers and strong\nstudents to generate familiar negative behavior by fine-tuning on negative\nbehavioral data. Experimental results on the HH-RLHF and PKU-SafeRLHF datasets,\nevaluated using both automatic metrics and human judgments, demonstrate that\nMACPO simultaneously improves the alignment performance of strong students and\nweak teachers. Moreover, as the number of weak teachers increases, MACPO\nachieves better weak-to-strong alignment performance through more iteration\noptimization rounds.", "paper_summary_zh": "\u96a8\u8457\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5feb\u901f\u9032\u6b65\u4e26\u9054\u5230\u63a5\u8fd1\u4eba\u985e\u7684\u80fd\u529b\uff0c\u4f7f\u5176\u8207\u4eba\u985e\u50f9\u503c\u89c0\u4fdd\u6301\u4e00\u81f4\u8b8a\u5f97\u66f4\u52a0\u8feb\u5207\u3002\u5728 LLM \u512a\u65bc\u4eba\u985e\u7684\u5834\u666f\u4e2d\uff0c\u6211\u5011\u9762\u81e8\u4e00\u500b\u5f31\u5c0d\u5f37\u7684\u4e00\u81f4\u6027\u554f\u984c\uff0c\u6211\u5011\u9700\u8981\u901a\u904e\u5f31\u6559\u5e2b\u7522\u751f\u7684\u5f31\u76e3\u7763\u4f86\u6709\u6548\u5730\u8abf\u6574\u5f37\u5b78\u751f LLM\u3002\u73fe\u6709\u7684\u4e00\u81f4\u6027\u65b9\u6cd5\u4e3b\u8981\u95dc\u6ce8\u5f37\u5c0d\u5f31\u7684\u4e00\u81f4\u6027\u548c\u81ea\u5c0d\u9f4a\u8a2d\u5b9a\uff0c\u800c\u4e14\u5c07\u5b83\u5011\u9069\u61c9\u5230\u66f4\u56f0\u96e3\u7684\u5f31\u5c0d\u5f37\u7684\u4e00\u81f4\u6027\u8a2d\u5b9a\u662f\u4e0d\u5207\u5be6\u969b\u7684\u3002\u70ba\u4e86\u586b\u88dc\u9019\u4e00\u7a7a\u767d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u591a\u4e3b\u9ad4\u5c0d\u6bd4\u504f\u597d\u6700\u4f73\u5316 (MACPO) \u6846\u67b6\u3002MACPO \u4fc3\u9032\u5f31\u6559\u5e2b\u548c\u5f37\u5b78\u751f\u901a\u904e\u53cd\u8986\u52a0\u5f37\u4e0d\u719f\u6089\u7684\u6b63\u9762\u884c\u70ba\u4e26\u61f2\u7f70\u719f\u6089\u7684\u8ca0\u9762\u884c\u70ba\u4f86\u76f8\u4e92\u5b78\u7fd2\u3002\u70ba\u4e86\u5be6\u73fe\u9019\u4e00\u76ee\u6a19\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u76f8\u4e92\u7684\u6b63\u9762\u884c\u70ba\u589e\u5f37\u7b56\u7565\u4f86\u9f13\u52f5\u5f31\u6559\u5e2b\u548c\u5f37\u5b78\u751f\u76f8\u4e92\u5b78\u7fd2\u5f7c\u6b64\u7684\u6b63\u9762\u884c\u70ba\uff0c\u4e26\u9032\u4e00\u6b65\u70ba\u4e0b\u4e00\u6b21\u8fed\u4ee3\u63d0\u4f9b\u66f4\u9ad8\u54c1\u8cea\u7684\u6b63\u9762\u884c\u70ba\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u786c\u8ca0\u9762\u884c\u70ba\u69cb\u5efa\u7b56\u7565\uff0c\u4ee5\u8a98\u5c0e\u5f31\u6559\u5e2b\u548c\u5f37\u5b78\u751f\u901a\u904e\u5c0d\u8ca0\u9762\u884c\u70ba\u6578\u64da\u9032\u884c\u5fae\u8abf\u4f86\u7522\u751f\u719f\u6089\u7684\u8ca0\u9762\u884c\u70ba\u3002\u5728 HH-RLHF \u548c PKU-SafeRLHF \u6578\u64da\u96c6\u4e0a\u7684\u5be6\u9a57\u7d50\u679c\uff0c\u4f7f\u7528\u81ea\u52d5\u6307\u6a19\u548c\u4eba\u985e\u5224\u65b7\u9032\u884c\u8a55\u4f30\uff0c\u8868\u660e MACPO \u540c\u6642\u63d0\u9ad8\u4e86\u5f37\u5b78\u751f\u548c\u5f31\u6559\u5e2b\u7684\u4e00\u81f4\u6027\u8868\u73fe\u3002\u6b64\u5916\uff0c\u96a8\u8457\u5f31\u6559\u5e2b\u7684\u6578\u91cf\u589e\u52a0\uff0cMACPO \u901a\u904e\u66f4\u591a\u7684\u8fed\u4ee3\u6700\u4f73\u5316\u56de\u5408\u5be6\u73fe\u4e86\u66f4\u597d\u7684\u5f31\u5c0d\u5f37\u7684\u4e00\u81f4\u6027\u8868\u73fe\u3002", "author": "Yougang Lyu et.al.", "authors": "Yougang Lyu, Lingyong Yan, Zihan Wang, Dawei Yin, Pengjie Ren, Maarten de Rijke, Zhaochun Ren", "id": "2410.07672v1", "paper_url": "http://arxiv.org/abs/2410.07672v1", "repo": "null"}}