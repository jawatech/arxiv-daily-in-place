{"2411.07516": {"publish_time": "2024-11-12", "title": "SparrowVQE: Visual Question Explanation for Course Content Understanding", "paper_summary": "Visual Question Answering (VQA) research seeks to create AI systems to answer\nnatural language questions in images, yet VQA methods often yield overly\nsimplistic and short answers. This paper aims to advance the field by\nintroducing Visual Question Explanation (VQE), which enhances the ability of\nVQA to provide detailed explanations rather than brief responses and address\nthe need for more complex interaction with visual content. We first created an\nMLVQE dataset from a 14-week streamed video machine learning course, including\n885 slide images, 110,407 words of transcripts, and 9,416 designed\nquestion-answer (QA) pairs. Next, we proposed a novel SparrowVQE, a small 3\nbillion parameters multimodal model. We trained our model with a three-stage\ntraining mechanism consisting of multimodal pre-training (slide images and\ntranscripts feature alignment), instruction tuning (tuning the pre-trained\nmodel with transcripts and QA pairs), and domain fine-tuning (fine-tuning slide\nimage and QA pairs). Eventually, our SparrowVQE can understand and connect\nvisual information using the SigLIP model with transcripts using the Phi-2\nlanguage model with an MLP adapter. Experimental results demonstrate that our\nSparrowVQE achieves better performance in our developed MLVQE dataset and\noutperforms state-of-the-art methods in the other five benchmark VQA datasets.\nThe source code is available at\n\\url{https://github.com/YoushanZhang/SparrowVQE}.", "paper_summary_zh": "<paragraph>\u8996\u89ba\u554f\u7b54 (VQA) \u7814\u7a76\u81f4\u529b\u65bc\u5efa\u7acb AI \u7cfb\u7d71\uff0c\u4ee5\u56de\u7b54\u5716\u50cf\u4e2d\u7684\u81ea\u7136\u8a9e\u8a00\u554f\u984c\uff0c\u4f46 VQA \u65b9\u6cd5\u901a\u5e38\u6703\u7522\u751f\u904e\u65bc\u7c21\u5316\u4e14\u7c21\u77ed\u7684\u7b54\u6848\u3002\u672c\u6587\u65e8\u5728\u900f\u904e\u5f15\u5165\u8996\u89ba\u554f\u984c\u89e3\u91cb (VQE) \u4f86\u63a8\u52d5\u8a72\u9818\u57df\u7684\u9032\u6b65\uff0cVQE \u589e\u5f37\u4e86 VQA \u63d0\u4f9b\u8a73\u7d30\u89e3\u91cb\u800c\u975e\u7c21\u77ed\u56de\u61c9\u7684\u80fd\u529b\uff0c\u4e26\u6eff\u8db3\u4e86\u8207\u8996\u89ba\u5167\u5bb9\u9032\u884c\u66f4\u8907\u96dc\u4e92\u52d5\u7684\u9700\u6c42\u3002\u6211\u5011\u9996\u5148\u5f9e 14 \u9031\u4e32\u6d41\u5f71\u7247\u6a5f\u5668\u5b78\u7fd2\u8ab2\u7a0b\u4e2d\u5efa\u7acb\u4e86 MLVQE \u8cc7\u6599\u96c6\uff0c\u5176\u4e2d\u5305\u542b 885 \u5f35\u6295\u5f71\u7247\u5716\u7247\u3001110,407 \u500b\u5b57\u7684\u9010\u5b57\u7a3f\u548c 9,416 \u500b\u8a2d\u8a08\u597d\u7684\u554f\u7b54 (QA) \u5c0d\u3002\u63a5\u4e0b\u4f86\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684 SparrowVQE\uff0c\u9019\u662f\u4e00\u500b\u5177\u6709 30 \u5104\u500b\u53c3\u6578\u7684\u591a\u6a21\u614b\u6a21\u578b\u3002\u6211\u5011\u4f7f\u7528\u4e09\u968e\u6bb5\u8a13\u7df4\u6a5f\u5236\u8a13\u7df4\u6211\u5011\u7684\u6a21\u578b\uff0c\u5305\u62ec\u591a\u6a21\u614b\u9810\u8a13\u7df4\uff08\u6295\u5f71\u7247\u5716\u7247\u548c\u9010\u5b57\u7a3f\u7279\u5fb5\u5c0d\u9f4a\uff09\u3001\u6307\u4ee4\u5fae\u8abf\uff08\u4f7f\u7528\u9010\u5b57\u7a3f\u548c QA \u5c0d\u5fae\u8abf\u9810\u8a13\u7df4\u6a21\u578b\uff09\u548c\u9818\u57df\u5fae\u8abf\uff08\u5fae\u8abf\u6295\u5f71\u7247\u5716\u7247\u548c QA \u5c0d\uff09\u3002\u6700\u7d42\uff0c\u6211\u5011\u7684 SparrowVQE \u80fd\u5920\u4f7f\u7528 SigLIP \u6a21\u578b\u7406\u89e3\u548c\u9023\u7d50\u8996\u89ba\u8cc7\u8a0a\uff0c\u4e26\u4f7f\u7528 Phi-2 \u8a9e\u8a00\u6a21\u578b\u548c MLP \u9069\u914d\u5668\u4f7f\u7528\u9010\u5b57\u7a3f\u3002\u5be6\u9a57\u7d50\u679c\u8b49\u660e\uff0c\u6211\u5011\u7684 SparrowVQE \u5728\u6211\u5011\u958b\u767c\u7684 MLVQE \u8cc7\u6599\u96c6\u4e2d\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u6548\u80fd\uff0c\u4e26\u5728\u5176\u4ed6\u4e94\u500b\u57fa\u6e96 VQA \u8cc7\u6599\u96c6\u4e2d\u512a\u65bc\u6700\u5148\u9032\u7684\u65b9\u6cd5\u3002\u539f\u59cb\u78bc\u53ef\u5728\n\\url{https://github.com/YoushanZhang/SparrowVQE} \u53d6\u5f97\u3002</paragraph>", "author": "Jialu Li et.al.", "authors": "Jialu Li, Manish Kumar Thota, Ruslan Gokhman, Radek Holik, Youshan Zhang", "id": "2411.07516v1", "paper_url": "http://arxiv.org/abs/2411.07516v1", "repo": "https://github.com/youshanzhang/sparrowvqe"}}