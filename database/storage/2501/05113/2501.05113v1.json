{"2501.05113": {"publish_time": "2025-01-09", "title": "Constrained Optimization of Charged Particle Tracking with Multi-Agent Reinforcement Learning", "paper_summary": "Reinforcement learning demonstrated immense success in modelling complex\nphysics-driven systems, providing end-to-end trainable solutions by interacting\nwith a simulated or real environment, maximizing a scalar reward signal. In\nthis work, we propose, building upon previous work, a multi-agent reinforcement\nlearning approach with assignment constraints for reconstructing particle\ntracks in pixelated particle detectors. Our approach optimizes collaboratively\na parametrized policy, functioning as a heuristic to a multidimensional\nassignment problem, by jointly minimizing the total amount of particle\nscattering over the reconstructed tracks in a readout frame. To satisfy\nconstraints, guaranteeing a unique assignment of particle hits, we propose a\nsafety layer solving a linear assignment problem for every joint action.\nFurther, to enforce cost margins, increasing the distance of the local policies\npredictions to the decision boundaries of the optimizer mappings, we recommend\nthe use of an additional component in the blackbox gradient estimation, forcing\nthe policy to solutions with lower total assignment costs. We empirically show\non simulated data, generated for a particle detector developed for proton\nimaging, the effectiveness of our approach, compared to multiple single- and\nmulti-agent baselines. We further demonstrate the effectiveness of constraints\nwith cost margins for both optimization and generalization, introduced by wider\nregions with high reconstruction performance as well as reduced predictive\ninstabilities. Our results form the basis for further developments in RL-based\ntracking, offering both enhanced performance with constrained policies and\ngreater flexibility in optimizing tracking algorithms through the option for\nindividual and team rewards.", "paper_summary_zh": "\u5f37\u5316\u5b78\u7fd2\u5728\u5efa\u6a21\u8907\u96dc\u7684\u7269\u7406\u9a45\u52d5\u7cfb\u7d71\u65b9\u9762\u5c55\u73fe\u51fa\u5de8\u5927\u7684\u6210\u529f\uff0c\u900f\u904e\u8207\u6a21\u64ec\u6216\u771f\u5be6\u74b0\u5883\u4e92\u52d5\uff0c\u63d0\u4f9b\u7aef\u5230\u7aef\u7684\u53ef\u8a13\u7df4\u89e3\u6c7a\u65b9\u6848\uff0c\u6700\u5927\u5316\u6a19\u91cf\u734e\u52f5\u8a0a\u865f\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u5efa\u7acb\u5728\u5148\u524d\u5de5\u4f5c\u4e0a\u7684\u591a\u91cd\u4ee3\u7406\u5f37\u5316\u5b78\u7fd2\u65b9\u6cd5\uff0c\u4f7f\u7528\u6307\u6d3e\u7d04\u675f\u4f86\u91cd\u5efa\u50cf\u7d20\u5316\u7c92\u5b50\u63a2\u6e2c\u5668\u4e2d\u7684\u7c92\u5b50\u8ecc\u8de1\u3002\u6211\u5011\u7684\u505a\u6cd5\u900f\u904e\u5171\u540c\u6700\u5c0f\u5316\u8b80\u53d6\u6846\u67b6\u4e2d\u91cd\u5efa\u8ecc\u8de1\u4e0a\u7c92\u5b50\u7684\u7e3d\u6563\u5c04\u91cf\uff0c\u5354\u8abf\u6700\u4f73\u5316\u4e00\u500b\u53c3\u6578\u5316\u7b56\u7565\uff0c\u4f5c\u70ba\u591a\u7dad\u6307\u6d3e\u554f\u984c\u7684\u555f\u767c\u6cd5\u3002\u70ba\u4e86\u6eff\u8db3\u7d04\u675f\uff0c\u78ba\u4fdd\u7c92\u5b50\u547d\u4e2d\u4e8b\u4ef6\u7684\u552f\u4e00\u6307\u6d3e\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u5b89\u5168\u5c64\uff0c\u70ba\u6bcf\u500b\u806f\u5408\u52d5\u4f5c\u89e3\u6c7a\u7dda\u6027\u6307\u6d3e\u554f\u984c\u3002\u6b64\u5916\uff0c\u70ba\u4e86\u5f37\u5236\u57f7\u884c\u6210\u672c\u908a\u969b\uff0c\u589e\u52a0\u5c40\u90e8\u7b56\u7565\u9810\u6e2c\u8207\u6700\u4f73\u5316\u5c0d\u61c9\u7684\u6c7a\u7b56\u908a\u754c\u7684\u8ddd\u96e2\uff0c\u6211\u5011\u5efa\u8b70\u5728\u9ed1\u76d2\u68af\u5ea6\u4f30\u8a08\u4e2d\u4f7f\u7528\u984d\u5916\u7684\u7d44\u6210\uff0c\u8feb\u4f7f\u7b56\u7565\u63a1\u53d6\u7e3d\u6307\u6d3e\u6210\u672c\u8f03\u4f4e\u7684\u89e3\u6c7a\u65b9\u6848\u3002\u6211\u5011\u5728\u70ba\u8cea\u5b50\u5f71\u50cf\u958b\u767c\u7684\u7c92\u5b50\u63a2\u6e2c\u5668\u7522\u751f\u7684\u6a21\u64ec\u8cc7\u6599\u4e0a\uff0c\u5be6\u8b49\u986f\u793a\u6211\u5011\u7684\u65b9\u6cd5\u6709\u6548\uff0c\u4e26\u8207\u591a\u500b\u55ae\u4e00\u548c\u591a\u91cd\u4ee3\u7406\u57fa\u6e96\u9032\u884c\u6bd4\u8f03\u3002\u6211\u5011\u9032\u4e00\u6b65\u5c55\u793a\u4e86\u7d04\u675f\u5728\u6700\u4f73\u5316\u548c\u6982\u62ec\u4e2d\u7684\u6709\u6548\u6027\uff0c\u9019\u4e9b\u7d04\u675f\u900f\u904e\u5177\u6709\u9ad8\u91cd\u5efa\u6548\u80fd\u7684\u8f03\u5bec\u5ee3\u5340\u57df\u4ee5\u53ca\u6e1b\u5c11\u9810\u6e2c\u4e0d\u7a69\u5b9a\u6027\u800c\u5f15\u5165\u3002\u6211\u5011\u7684\u7d50\u679c\u70ba\u57fa\u65bc RL \u7684\u8ffd\u8e64\u9032\u4e00\u6b65\u767c\u5c55\u5960\u5b9a\u57fa\u790e\uff0c\u900f\u904e\u53d7\u7d04\u675f\u7b56\u7565\u63d0\u4f9b\u589e\u5f37\u7684\u6548\u80fd\uff0c\u4ee5\u53ca\u900f\u904e\u500b\u4eba\u548c\u5718\u968a\u734e\u52f5\u7684\u9078\u9805\uff0c\u5728\u6700\u4f73\u5316\u8ffd\u8e64\u6f14\u7b97\u6cd5\u65b9\u9762\u63d0\u4f9b\u66f4\u5927\u7684\u5f48\u6027\u3002", "author": "Tobias Kortus et.al.", "authors": "Tobias Kortus, Ralf Keidel, Nicolas R. Gauger, Jan Kieseler", "id": "2501.05113v1", "paper_url": "http://arxiv.org/abs/2501.05113v1", "repo": "null"}}