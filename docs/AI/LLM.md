
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-18**|**Gender Representation and Bias in Indian Civil Service Mock Interviews**|Somonnoy Banerjee et.al.|[2409.12194v3](http://arxiv.org/abs/2409.12194v3)|null|
|**2024-09-18**|**DynaMo: In-Domain Dynamics Pretraining for Visuo-Motor Control**|Zichen Jeff Cui et.al.|[2409.12192v1](http://arxiv.org/abs/2409.12192v1)|null|
|**2024-09-18**|**Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution**|Peng Wang et.al.|[2409.12191v1](http://arxiv.org/abs/2409.12191v1)|[link](https://github.com/qwenlm/qwen2-vl)|
|**2024-09-18**|**Qwen2.5-Coder Technical Report**|Binyuan Hui et.al.|[2409.12186v1](http://arxiv.org/abs/2409.12186v1)|[link](https://github.com/qwenlm/qwen2.5-coder)|
|**2024-09-18**|**To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning**|Zayne Sprague et.al.|[2409.12183v1](http://arxiv.org/abs/2409.12183v1)|null|
|**2024-09-18**|**A Controlled Study on Long Context Extension and Generalization in LLMs**|Yi Lu et.al.|[2409.12181v2](http://arxiv.org/abs/2409.12181v2)|[link](https://github.com/leooyii/lceg)|
|**2024-09-18**|**Finetuning Language Models to Emit Linguistic Expressions of Uncertainty**|Arslan Chaudhry et.al.|[2409.12180v1](http://arxiv.org/abs/2409.12180v1)|null|
|**2024-09-18**|**You Only Read Once (YORO): Learning to Internalize Database Knowledge for Text-to-SQL**|Hideo Kobayashi et.al.|[2409.12172v1](http://arxiv.org/abs/2409.12172v1)|null|
|**2024-09-18**|**Decoding Style: Efficient Fine-Tuning of LLMs for Image-Guided Outfit Recommendation with Preference**|Najmeh Forouzandehmehr et.al.|[2409.12150v1](http://arxiv.org/abs/2409.12150v1)|null|
|**2024-09-18**|**MAgICoRe: Multi-Agent, Iterative, Coarse-to-Fine Refinement for Reasoning**|Justin Chih-Yao Chen et.al.|[2409.12147v1](http://arxiv.org/abs/2409.12147v1)|[link](https://github.com/dinobby/magicore)|
|**2024-09-18**|**Takin: A Cohort of Superior Quality Zero-shot Speech Generation Models**|Sijing Chen et.al.|[2409.12139v3](http://arxiv.org/abs/2409.12139v3)|null|
|**2024-09-18**|**GRIN: GRadient-INformed MoE**|Liyuan Liu et.al.|[2409.12136v1](http://arxiv.org/abs/2409.12136v1)|null|
|**2024-09-18**|**BERT-VBD: Vietnamese Multi-Document Summarization Framework**|Tuan-Cuong Vuong et.al.|[2409.12134v1](http://arxiv.org/abs/2409.12134v1)|null|
|**2024-09-18**|**Linguini: A benchmark for language-agnostic linguistic reasoning**|Eduardo Sánchez et.al.|[2409.12126v1](http://arxiv.org/abs/2409.12126v1)|[link](https://github.com/facebookresearch/linguini)|
|**2024-09-18**|**Qwen2.5-Math Technical Report: Toward Mathematical Expert Model via Self-Improvement**|An Yang et.al.|[2409.12122v1](http://arxiv.org/abs/2409.12122v1)|null|
|**2024-09-18**|**Low Frame-rate Speech Codec: a Codec Designed for Fast High-quality Speech LLM Training and Inference**|Edresson Casanova et.al.|[2409.12117v1](http://arxiv.org/abs/2409.12117v1)|null|
|**2024-09-18**|**Measuring Human and AI Values based on Generative Psychometrics with Large Language Models**|Haoran Ye et.al.|[2409.12106v1](http://arxiv.org/abs/2409.12106v1)|[link](https://github.com/value4ai/gpv)|
|**2024-09-18**|**Skill matching at scale: freelancer-project alignment for efficient multilingual candidate retrieval**|Warren Jouanneau et.al.|[2409.12097v2](http://arxiv.org/abs/2409.12097v2)|null|
|**2024-09-18**|**IMRL: Integrating Visual, Physical, Temporal, and Geometric Representations for Enhanced Food Acquisition**|Rui Liu et.al.|[2409.12092v1](http://arxiv.org/abs/2409.12092v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v1](http://arxiv.org/abs/2409.12087v1)|null|
|**2024-09-18**|**PAD-FT: A Lightweight Defense for Backdoor Attacks via Data Purification and Fine-Tuning**|Yukai Xu et.al.|[2409.12072v1](http://arxiv.org/abs/2409.12072v1)|null|
|**2024-09-18**|**Generalized Robot Learning Framework**|Jiahuan Yan et.al.|[2409.12061v1](http://arxiv.org/abs/2409.12061v1)|null|
|**2024-09-18**|**PARAPHRASUS : A Comprehensive Benchmark for Evaluating Paraphrase Detection Models**|Andrianos Michail et.al.|[2409.12060v1](http://arxiv.org/abs/2409.12060v1)|null|
|**2024-09-18**|**Dual-Layer Training and Decoding of Large Language Model with Simultaneously Thinking and Speaking**|Ningyuan Xi et.al.|[2409.12059v1](http://arxiv.org/abs/2409.12059v1)|null|
|**2024-09-18**|**Using Large Language Models to Generate Clinical Trial Tables and Figures**|Yumeng Yang et.al.|[2409.12046v2](http://arxiv.org/abs/2409.12046v2)|null|
|**2024-09-18**|**ASR Benchmarking: Need for a More Representative Conversational Dataset**|Gaurav Maheshwari et.al.|[2409.12042v1](http://arxiv.org/abs/2409.12042v1)|[link](https://github.com/diabolocom-research/conversationaldataset)|
|**2024-09-18**|**Topological Deep Learning with State-Space Models: A Mamba Approach for Simplicial Complexes**|Marco Montagna et.al.|[2409.12033v1](http://arxiv.org/abs/2409.12033v1)|null|
|**2024-09-18**|**Promise and Peril of Collaborative Code Generation Models: Balancing Effectiveness and Memorization**|Zhi Chen et.al.|[2409.12020v1](http://arxiv.org/abs/2409.12020v1)|null|
|**2024-09-18**|**Representing Positional Information in Generative World Models for Object Manipulation**|Stefano Ferraro et.al.|[2409.12005v2](http://arxiv.org/abs/2409.12005v2)|null|
|**2024-09-18**|**Additive-feature-attribution methods: a review on explainable artificial intelligence for fluid dynamics and heat transfer**|Andrés Cremades et.al.|[2409.11992v1](http://arxiv.org/abs/2409.11992v1)|null|
|**2024-09-18**|**Sampling Latent Material-Property Information From LLM-Derived Embedding Representations**|Luke P. J. Gilligan et.al.|[2409.11971v1](http://arxiv.org/abs/2409.11971v1)|null|
|**2024-09-18**|**Efficacy of Synthetic Data as a Benchmark**|Gaurav Maheshwari et.al.|[2409.11968v1](http://arxiv.org/abs/2409.11968v1)|null|
|**2024-09-18**|**LLMs in Education: Novel Perspectives, Challenges, and Opportunities**|Bashar Alhafni et.al.|[2409.11917v1](http://arxiv.org/abs/2409.11917v1)|null|
|**2024-09-18**|**AlignBot: Aligning VLM-powered Customized Task Planning with User Reminders Through Fine-Tuning for Household Robots**|Zhaxizhuoma et.al.|[2409.11905v1](http://arxiv.org/abs/2409.11905v1)|null|
|**2024-09-18**|**Finding the Subjective Truth: Collecting 2 Million Votes for Comprehensive Gen-AI Model Evaluation**|Dimitrios Christodoulou et.al.|[2409.11904v1](http://arxiv.org/abs/2409.11904v1)|null|
|**2024-09-18**|**LLMs + Persona-Plug = Personalized LLMs**|Jiongnan Liu et.al.|[2409.11901v1](http://arxiv.org/abs/2409.11901v1)|null|
|**2024-09-18**|**DocMamba: Efficient Document Pre-training with State Space Model**|Pengfei Hu et.al.|[2409.11887v1](http://arxiv.org/abs/2409.11887v1)|null|
|**2024-09-18**|**Learning Task Planning from Multi-Modal Demonstration for Multi-Stage Contact-Rich Manipulation**|Kejia Chen et.al.|[2409.11863v1](http://arxiv.org/abs/2409.11863v1)|null|
|**2024-09-18**|**Retrieve, Annotate, Evaluate, Repeat: Leveraging Multimodal LLMs for Large-Scale Product Retrieval Evaluation**|Kasra Hosseini et.al.|[2409.11860v1](http://arxiv.org/abs/2409.11860v1)|null|
|**2024-09-18**|**MEOW: MEMOry Supervised LLM Unlearning Via Inverted Facts**|Tianle Gu et.al.|[2409.11844v1](http://arxiv.org/abs/2409.11844v1)|[link](https://github.com/carol-gutianle/meow)|
|**2024-09-18**|**DPI-TTS: Directional Patch Interaction for Fast-Converging and Style Temporal Modeling in Text-to-Speech**|Xin Qi et.al.|[2409.11835v1](http://arxiv.org/abs/2409.11835v1)|null|
|**2024-09-18**|**Extract-and-Abstract: Unifying Extractive and Abstractive Summarization within Single Encoder-Decoder Framework**|Yuping Wu et.al.|[2409.11827v1](http://arxiv.org/abs/2409.11827v1)|null|
|**2024-09-18**|**Optimizing Job Shop Scheduling in the Furniture Industry: A Reinforcement Learning Approach Considering Machine Setup, Batch Variability, and Intralogistics**|Malte Schneevogt et.al.|[2409.11820v1](http://arxiv.org/abs/2409.11820v1)|null|
|**2024-09-18**|**EFCM: Efficient Fine-tuning on Compressed Models for deployment of large models in medical image analysis**|Shaojie Li et.al.|[2409.11817v1](http://arxiv.org/abs/2409.11817v1)|null|
|**2024-09-18**|**EventAug: Multifaceted Spatio-Temporal Data Augmentation Methods for Event-based Learning**|Yukun Tian et.al.|[2409.11813v1](http://arxiv.org/abs/2409.11813v1)|null|
|**2024-09-18**|**Latent fingerprint enhancement for accurate minutiae detection**|Abdul Wahab et.al.|[2409.11802v1](http://arxiv.org/abs/2409.11802v1)|null|
|**2024-09-18**|**The Factuality of Large Language Models in the Legal Domain**|Rajaa El Hamdani et.al.|[2409.11798v1](http://arxiv.org/abs/2409.11798v1)|[link](https://github.com/rajjaa/lexfact)|
|**2024-09-18**|**Efficient Low-Resolution Face Recognition via Bridge Distillation**|Shiming Ge et.al.|[2409.11786v1](http://arxiv.org/abs/2409.11786v1)|null|
|**2024-09-18**|**Distilling Channels for Efficient Deep Tracking**|Shiming Ge et.al.|[2409.11785v1](http://arxiv.org/abs/2409.11785v1)|null|
|**2024-09-18**|**Development and bilingual evaluation of Japanese medical large language model within reasonably low computational resources**|Issey Sukeda et.al.|[2409.11783v2](http://arxiv.org/abs/2409.11783v2)|[link](https://github.com/stardust-coder/japanese-lm-med-harness)|
|**2024-09-18**|**Smart Data-Driven GRU Predictor for SnO$_2$ Thin films Characteristics**|Faiza Bouamra et.al.|[2409.11782v1](http://arxiv.org/abs/2409.11782v1)|null|
|**2024-09-18**|**Explaining Non-monotonic Normative Reasoning using Argumentation Theory with Deontic Logic**|Zhe Yu et.al.|[2409.11780v1](http://arxiv.org/abs/2409.11780v1)|null|
|**2024-09-18**|**Knowledge Adaptation Network for Few-Shot Class-Incremental Learning**|Ye Wang et.al.|[2409.11770v1](http://arxiv.org/abs/2409.11770v1)|null|
|**2024-09-18**|**One Map to Find Them All: Real-time Open-Vocabulary Mapping for Zero-shot Multi-Object Navigation**|Finn Lukas Busch et.al.|[2409.11764v1](http://arxiv.org/abs/2409.11764v1)|null|
|**2024-09-18**|**Synthesizing Evolving Symbolic Representations for Autonomous Systems**|Gabriele Sartor et.al.|[2409.11756v1](http://arxiv.org/abs/2409.11756v1)|[link](https://github.com/gabrielesartor/discover_plan_act)|
|**2024-09-18**|**NPAT Null-Space Projected Adversarial Training Towards Zero Deterioration**|Hanyi Hu et.al.|[2409.11754v1](http://arxiv.org/abs/2409.11754v1)|null|
|**2024-09-18**|**Exploring Gaze Pattern in Autistic Children: Clustering, Visualization, and Prediction**|Weiyan Shi et.al.|[2409.11744v1](http://arxiv.org/abs/2409.11744v1)|null|
|**2024-09-18**|**InverseMeetInsert: Robust Real Image Editing via Geometric Accumulation Inversion in Guided Diffusion Models**|Yan Zheng et.al.|[2409.11734v1](http://arxiv.org/abs/2409.11734v1)|null|
|**2024-09-18**|**Human-like Affective Cognition in Foundation Models**|Kanishk Gandhi et.al.|[2409.11733v2](http://arxiv.org/abs/2409.11733v2)|null|
|**2024-09-18**|**Enabling Real-Time Conversations with Minimal Training Costs**|Wang Xu et.al.|[2409.11727v1](http://arxiv.org/abs/2409.11727v1)|null|
|**2024-09-18**|**Revealing the Challenge of Detecting Character Knowledge Errors in LLM Role-Playing**|Wenyuan Zhang et.al.|[2409.11726v1](http://arxiv.org/abs/2409.11726v1)|[link](https://github.com/wyripple/rp_kw_errors)|
|**2024-09-18**|**TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning**|Xinyuan Lu et.al.|[2409.11724v1](http://arxiv.org/abs/2409.11724v1)|[link](https://github.com/xinyuanlu00/tart)|
|**2024-09-18**|**From Lists to Emojis: How Format Bias Affects Model Alignment**|Xuanchang Zhang et.al.|[2409.11704v1](http://arxiv.org/abs/2409.11704v1)|null|
|**2024-09-18**|**Harnessing LLMs for API Interactions: A Framework for Classification and Synthetic Data Generation**|Chunliang Tao et.al.|[2409.11703v1](http://arxiv.org/abs/2409.11703v1)|null|
|**2024-09-18**|**FLARE: Fusing Language Models and Collaborative Architectures for Recommender Enhancement**|Liam Hebert et.al.|[2409.11699v1](http://arxiv.org/abs/2409.11699v1)|null|
|**2024-09-18**|**GUNet: A Graph Convolutional Network United Diffusion Model for Stable and Diversity Pose Generation**|Shuowen Liang et.al.|[2409.11689v1](http://arxiv.org/abs/2409.11689v1)|[link](https://github.com/liangshuowen/posediffusion)|
|**2024-09-18**|**Detecting Underdiagnosed Medical Conditions with Deep Learning-Based Opportunistic CT Imaging**|Asad Aali et.al.|[2409.11686v1](http://arxiv.org/abs/2409.11686v1)|null|
|**2024-09-18**|**Enhancing Complex Formula Recognition with Hierarchical Detail-Focused Network**|Jiale Wang et.al.|[2409.11677v1](http://arxiv.org/abs/2409.11677v1)|null|
|**2024-09-18**|**Hypergraph-based Motion Generation with Multi-modal Interaction Relational Reasoning**|Keshu Wu et.al.|[2409.11676v1](http://arxiv.org/abs/2409.11676v1)|null|
|**2024-09-18**|**Towards Explainable Goal Recognition Using Weight of Evidence (WoE): A Human-Centered Approach**|Abeer Alshehri et.al.|[2409.11675v1](http://arxiv.org/abs/2409.11675v1)|null|
|**2024-09-18**|**RUIE: Retrieval-based Unified Information Extraction using Large Language Model**|Xincheng Liao et.al.|[2409.11673v1](http://arxiv.org/abs/2409.11673v1)|null|
|**2024-09-18**|**GReDP: A More Robust Approach for Differential Private Training with Gradient-Preserving Noise Reduction**|Haodi Wang et.al.|[2409.11663v2](http://arxiv.org/abs/2409.11663v2)|null|
|**2024-09-18**|**Few-Shot Class-Incremental Learning with Non-IID Decentralized Data**|Cuiwei Liu et.al.|[2409.11657v1](http://arxiv.org/abs/2409.11657v1)|null|
|**2024-09-18**|**How to Build the Virtual Cell with Artificial Intelligence: Priorities and Opportunities**|Charlotte Bunne et.al.|[2409.11654v1](http://arxiv.org/abs/2409.11654v1)|null|
|**2024-09-18**|**Art and Science of Quantizing Large-Scale Models: A Comprehensive Overview**|Yanshu Wang et.al.|[2409.11650v1](http://arxiv.org/abs/2409.11650v1)|null|
|**2024-09-18**|**Combating Phone Scams with LLM-based Detection: Where Do We Stand?**|Zitong Shen et.al.|[2409.11643v1](http://arxiv.org/abs/2409.11643v1)|null|
|**2024-09-18**|**BanStereoSet: A Dataset to Measure Stereotypical Social Biases in LLMs for Bangla**|Mahammed Kamruzzaman et.al.|[2409.11638v1](http://arxiv.org/abs/2409.11638v1)|null|
|**2024-09-18**|**"A Woman is More Culturally Knowledgeable than A Man?": The Effect of Personas on Cultural Norm Interpretation in LLMs**|Mahammed Kamruzzaman et.al.|[2409.11636v1](http://arxiv.org/abs/2409.11636v1)|null|
|**2024-09-18**|**A Metric Hybrid Planning Approach to Solving Pandemic Planning Problems with Simple SIR Models**|Ari Gestetner et.al.|[2409.11631v1](http://arxiv.org/abs/2409.11631v1)|null|
|**2024-09-17**|**Harnessing AI data-driven global weather models for climate attribution: An analysis of the 2017 Oroville Dam extreme atmospheric river**|Jorge Baño-Medina et.al.|[2409.11605v1](http://arxiv.org/abs/2409.11605v1)|null|
|**2024-09-17**|**No Saved Kaleidosope: an 100% Jitted Neural Network Coding Language with Pythonic Syntax**|Augusto Seben da Rosa et.al.|[2409.11600v1](http://arxiv.org/abs/2409.11600v1)|[link](https://github.com/nosaveddata/nosavedkaleidoscope)|
|**2024-09-17**|**Towards Fair RAG: On the Impact of Fair Ranking in Retrieval-Augmented Generation**|To Eun Kim et.al.|[2409.11598v1](http://arxiv.org/abs/2409.11598v1)|[link](https://github.com/kimdanny/fair-rag)|
|**2024-09-17**|**Self-Contrastive Forward-Forward Algorithm**|Xing Chen et.al.|[2409.11593v1](http://arxiv.org/abs/2409.11593v1)|null|
|**2024-09-17**|**ProSLM : A Prolog Synergized Language Model for explainable Domain Specific Knowledge Based Question Answering**|Priyesh Vakharia et.al.|[2409.11589v1](http://arxiv.org/abs/2409.11589v1)|null|
|**2024-09-17**|**Uncertainty Decomposition and Error Margin Detection of Homodyned-K Distribution in Quantitative Ultrasound**|Dorsa Ameri et.al.|[2409.11583v1](http://arxiv.org/abs/2409.11583v1)|null|
|**2024-09-17**|**HEARTS: A Holistic Framework for Explainable, Sustainable and Robust Text Stereotype Detection**|Theo King et.al.|[2409.11579v1](http://arxiv.org/abs/2409.11579v1)|null|
|**2024-09-17**|**Automating proton PBS treatment planning for head and neck cancers using policy gradient-based deep reinforcement learning**|Qingqing Wang et.al.|[2409.11576v1](http://arxiv.org/abs/2409.11576v1)|null|
|**2024-09-17**|**Preference Tuning with Human Feedback on Language, Speech, and Vision Tasks: A Survey**|Genta Indra Winata et.al.|[2409.11564v1](http://arxiv.org/abs/2409.11564v1)|null|
|**2024-09-17**|**Multi-Domain Data Aggregation for Axon and Myelin Segmentation in Histology Images**|Armand Collin et.al.|[2409.11552v1](http://arxiv.org/abs/2409.11552v1)|[link](https://github.com/axondeepseg/axondeepseg)|
|**2024-09-17**|**Small Language Models can Outperform Humans in Short Creative Writing: A Study Comparing SLMs with Humans and LLMs**|Guillermo Marco et.al.|[2409.11547v1](http://arxiv.org/abs/2409.11547v1)|[link](https://github.com/annon-submission/slm-creativity)|
|**2024-09-17**|**NCT-CRC-HE: Not All Histopathological Datasets Are Equally Useful**|Andrey Ignatov et.al.|[2409.11546v1](http://arxiv.org/abs/2409.11546v1)|[link](https://github.com/gmalivenko/nct-crc-he-experiments)|
|**2024-09-17**|**Chain-of-Thought Prompting for Speech Translation**|Ke Hu et.al.|[2409.11538v1](http://arxiv.org/abs/2409.11538v1)|null|
|**2024-09-17**|**Improving LLM Reasoning with Multi-Agent Tree-of-Thought Validator Agent**|Fatemeh Haji et.al.|[2409.11527v1](http://arxiv.org/abs/2409.11527v1)|null|
|**2024-09-17**|**Mamba Fusion: Learning Actions Through Questioning**|Zhikang Dong et.al.|[2409.11513v1](http://arxiv.org/abs/2409.11513v1)|[link](https://github.com/dongzhikang/mambavl)|
|**2024-09-17**|**FedNE: Surrogate-Assisted Federated Neighbor Embedding for Dimensionality Reduction**|Ziwei Li et.al.|[2409.11509v1](http://arxiv.org/abs/2409.11509v1)|null|
|**2024-09-17**|**Egalitarian Language Representation in Language Models: It All Begins with Tokenizers**|Menan Velayuthan et.al.|[2409.11501v1](http://arxiv.org/abs/2409.11501v1)|null|
|**2024-09-17**|**Multi-Document Grounded Multi-Turn Synthetic Dialog Generation**|Young-Suk Lee et.al.|[2409.11500v1](http://arxiv.org/abs/2409.11500v1)|null|
|**2024-09-17**|**Augment, Drop & Swap: Improving Diversity in LLM Captions for Efficient Music-Text Representation Learning**|Ilaria Manco et.al.|[2409.11498v1](http://arxiv.org/abs/2409.11498v1)|null|
|**2024-09-17**|**Enriching Datasets with Demographics through Large Language Models: What's in a Name?**|Khaled AlNuaimi et.al.|[2409.11491v1](http://arxiv.org/abs/2409.11491v1)|null|
|**2024-09-17**|**Beyond Algorithmic Fairness: A Guide to Develop and Deploy Ethical AI-Enabled Decision-Support Tools**|Rosemarie Santa Gonzalez et.al.|[2409.11489v1](http://arxiv.org/abs/2409.11489v1)|null|

#### Abstracts
##### **Gender Representation and Bias in Indian Civil Service Mock Interviews**
2409.12194v3 by Somonnoy Banerjee, Sujan Dutta, Soumyajit Datta, Ashiqur R. KhudaBukhsh

This paper makes three key contributions. First, via a substantial corpus of
51,278 interview questions sourced from 888 YouTube videos of mock interviews
of Indian civil service candidates, we demonstrate stark gender bias in the
broad nature of questions asked to male and female candidates. Second, our
experiments with large language models show a strong presence of gender bias in
explanations provided by the LLMs on the gender inference task. Finally, we
present a novel dataset of 51,278 interview questions that can inform future
social science studies.

摘要：本論文做出三項關鍵貢獻。首先，透過大量語料庫，包含 51,278 個面試問題，這些問題來自 888 個印度公務員面試的 YouTube 模擬影片，我們證明了在詢問男性和女性面試者的問題類型中存在明顯的性別偏見。其次，我們對大型語言模型進行的實驗顯示，在 LLM 對性別推論任務提供的解釋中存在強烈的性別偏見。最後，我們提供了一個新的資料集，包含 51,278 個面試問題，這些問題可以為未來的社會科學研究提供資訊。

##### **DynaMo: In-Domain Dynamics Pretraining for Visuo-Motor Control**
2409.12192v1 by Zichen Jeff Cui, Hengkai Pan, Aadhithya Iyer, Siddhant Haldar, Lerrel Pinto

Imitation learning has proven to be a powerful tool for training complex
visuomotor policies. However, current methods often require hundreds to
thousands of expert demonstrations to handle high-dimensional visual
observations. A key reason for this poor data efficiency is that visual
representations are predominantly either pretrained on out-of-domain data or
trained directly through a behavior cloning objective. In this work, we present
DynaMo, a new in-domain, self-supervised method for learning visual
representations. Given a set of expert demonstrations, we jointly learn a
latent inverse dynamics model and a forward dynamics model over a sequence of
image embeddings, predicting the next frame in latent space, without
augmentations, contrastive sampling, or access to ground truth actions.
Importantly, DynaMo does not require any out-of-domain data such as Internet
datasets or cross-embodied datasets. On a suite of six simulated and real
environments, we show that representations learned with DynaMo significantly
improve downstream imitation learning performance over prior self-supervised
learning objectives, and pretrained representations. Gains from using DynaMo
hold across policy classes such as Behavior Transformer, Diffusion Policy, MLP,
and nearest neighbors. Finally, we ablate over key components of DynaMo and
measure its impact on downstream policy performance. Robot videos are best
viewed at https://dynamo-ssl.github.io

摘要：模仿學習已被證明是訓練複雜視覺運動策略的強大工具。然而，目前的方法通常需要數百到數千個專家示範才能處理高維度視覺觀察。造成此數據效率不佳的一個關鍵原因是視覺表示主要預先訓練於領域外數據或直接透過行為複製目標進行訓練。在這項工作中，我們提出 DynaMo，一種新的領域內自監督方法，用於學習視覺表示。給定一組專家示範，我們共同學習一個潛在逆動態模型和一個正向動態模型，在影像嵌入序列上預測潛在空間中的下一幀，而無需擴充、對比取樣或存取地面真實動作。重要的是，DynaMo 不需要任何領域外數據，例如網際網路資料集或跨體態資料集。在一組六個模擬和真實環境中，我們展示了使用 DynaMo 學習的表示顯著改善了下游模仿學習效能，優於先前的自監督學習目標和預先訓練的表示。使用 DynaMo 的好處適用於各種策略類別，例如行為轉換器、擴散策略、MLP 和最近鄰。最後，我們對 DynaMo 的關鍵組成部分進行消融，並衡量其對下游策略效能的影響。機器人影片最適合在 https://dynamo-ssl.github.io 觀看

##### **Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution**
2409.12191v1 by Peng Wang, Shuai Bai, Sinan Tan, Shijie Wang, Zhihao Fan, Jinze Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, Yang Fan, Kai Dang, Mengfei Du, Xuancheng Ren, Rui Men, Dayiheng Liu, Chang Zhou, Jingren Zhou, Junyang Lin

We present the Qwen2-VL Series, an advanced upgrade of the previous Qwen-VL
models that redefines the conventional predetermined-resolution approach in
visual processing. Qwen2-VL introduces the Naive Dynamic Resolution mechanism,
which enables the model to dynamically process images of varying resolutions
into different numbers of visual tokens. This approach allows the model to
generate more efficient and accurate visual representations, closely aligning
with human perceptual processes. The model also integrates Multimodal Rotary
Position Embedding (M-RoPE), facilitating the effective fusion of positional
information across text, images, and videos. We employ a unified paradigm for
processing both images and videos, enhancing the model's visual perception
capabilities. To explore the potential of large multimodal models, Qwen2-VL
investigates the scaling laws for large vision-language models (LVLMs). By
scaling both the model size-with versions at 2B, 8B, and 72B parameters-and the
amount of training data, the Qwen2-VL Series achieves highly competitive
performance. Notably, the Qwen2-VL-72B model achieves results comparable to
leading models such as GPT-4o and Claude3.5-Sonnet across various multimodal
benchmarks, outperforming other generalist models. Code is available at
\url{https://github.com/QwenLM/Qwen2-VL}.

摘要：我們提出了 Qwen2-VL 系列，這是先前 Qwen-VL 模型的先進升級版，重新定義了視覺處理中傳統的預先設定解析度方法。Qwen2-VL 引入了 Naive Dynamic Resolution 機制，使模型能夠動態處理不同解析度的影像，並轉換成不同數量的視覺符號。此方法讓模型能夠產生更有效率且精確的視覺表示，與人類的知覺過程緊密結合。該模型還整合了多模態旋轉位置嵌入 (M-RoPE)，促進跨文本、影像和影片的位置資訊有效融合。我們採用統一的範例來處理影像和影片，增強模型的視覺感知能力。為了探索大型多模態模型的潛力，Qwen2-VL 探討了大型視覺語言模型 (LVLMs) 的規模定律。透過擴充模型大小（版本有 2B、8B 和 72B 參數）和訓練資料量，Qwen2-VL 系列達到了極具競爭力的效能。值得注意的是，Qwen2-VL-72B 模型在各種多模態基準測試中達到了與 GPT-4o 和 Claude3.5-Sonnet 等領先模型相當的結果，優於其他通用模型。程式碼可以在 \url{https://github.com/QwenLM/Qwen2-VL} 取得。

##### **Qwen2.5-Coder Technical Report**
2409.12186v1 by Binyuan Hui, Jian Yang, Zeyu Cui, Jiaxi Yang, Dayiheng Liu, Lei Zhang, Tianyu Liu, Jiajun Zhang, Bowen Yu, Kai Dang, An Yang, Rui Men, Fei Huang, Xingzhang Ren, Xuancheng Ren, Jingren Zhou, Junyang Lin

In this report, we introduce the Qwen2.5-Coder series, a significant upgrade
from its predecessor, CodeQwen1.5. This series includes two models:
Qwen2.5-Coder-1.5B and Qwen2.5-Coder-7B. As a code-specific model,
Qwen2.5-Coder is built upon the Qwen2.5 architecture and continues pretrained
on a vast corpus of over 5.5 trillion tokens. Through meticulous data cleaning,
scalable synthetic data generation, and balanced data mixing, Qwen2.5-Coder
demonstrates impressive code generation capabilities while retaining general
versatility. The model has been evaluated on a wide range of code-related
tasks, achieving state-of-the-art (SOTA) performance across more than 10
benchmarks, including code generation, completion, reasoning, and repair,
consistently outperforming larger models of the same model size. We believe
that the release of the Qwen2.5-Coder series will not only push the boundaries
of research in code intelligence but also, through its permissive licensing,
encourage broader adoption by developers in real-world applications.

摘要：在本次報告中，我們介紹 Qwen2.5-Coder 系列，這是其前身 CodeQwen1.5 的重大升級。此系列包含兩個模型：Qwen2.5-Coder-1.5B 和 Qwen2.5-Coder-7B。作為一個特定於程式碼的模型，Qwen2.5-Coder 建構於 Qwen2.5 架構之上，並持續在超過 5.5 兆個 token 的龐大語料庫上進行預訓練。透過細心的資料清理、可擴充的合成資料產生，以及平衡的資料混合，Qwen2.5-Coder 展現了令人印象深刻的程式碼產生能力，同時保留了通用的多功能性。此模型已在廣泛的程式碼相關任務中進行評估，在超過 10 個基準測試中（包括程式碼產生、完成、推理和修復）達到最先進 (SOTA) 的效能，持續優於同等模型大小的較大型模型。我們相信，Qwen2.5-Coder 系列的釋出不僅會推動程式碼智能研究的界限，而且透過其寬鬆的授權，也會鼓勵開發人員在實際應用中更廣泛地採用。

##### **To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning**
2409.12183v1 by Zayne Sprague, Fangcong Yin, Juan Diego Rodriguez, Dongwei Jiang, Manya Wadhwa, Prasann Singhal, Xinyu Zhao, Xi Ye, Kyle Mahowald, Greg Durrett

Chain-of-thought (CoT) via prompting is the de facto method for eliciting
reasoning capabilities from large language models (LLMs). But for what kinds of
tasks is this extra ``thinking'' really helpful? To analyze this, we conducted
a quantitative meta-analysis covering over 100 papers using CoT and ran our own
evaluations of 20 datasets across 14 models. Our results show that CoT gives
strong performance benefits primarily on tasks involving math or logic, with
much smaller gains on other types of tasks. On MMLU, directly generating the
answer without CoT leads to almost identical accuracy as CoT unless the
question or model's response contains an equals sign, indicating symbolic
operations and reasoning. Following this finding, we analyze the behavior of
CoT on these problems by separating planning and execution and comparing
against tool-augmented LLMs. Much of CoT's gain comes from improving symbolic
execution, but it underperforms relative to using a symbolic solver. Our
results indicate that CoT can be applied selectively, maintaining performance
while saving inference costs. Furthermore, they suggest a need to move beyond
prompt-based CoT to new paradigms that better leverage intermediate computation
across the whole range of LLM applications.

摘要：透過提示進行的思考鏈 (CoT) 是從大型語言模型 (LLM) 引發推理能力的實際方法。但對於哪些類型的任務，這種額外的「思考」真的有幫助？為了分析這一點，我們進行了一項定量元分析，涵蓋了 100 多篇使用 CoT 的論文，並對 14 個模型中的 20 個資料集執行了我們自己的評估。我們的結果表明，CoT 主要在涉及數學或邏輯的任務上提供強大的效能優勢，而在其他類型的任務上則獲得的收益小得多。在 MMLU 上，直接產生答案而沒有 CoT 會導致與 CoT 幾乎相同的準確度，除非問題或模型的回應包含等號，表示符號運算和推理。根據這一發現，我們透過分離規劃和執行，並與工具增強的 LLM 進行比較，分析了 CoT 在這些問題上的行為。CoT 的許多收益來自於改進符號執行，但它相對於使用符號求解器的執行效果較差。我們的結果表明，CoT 可以有選擇地應用，在節省推理成本的同時維持效能。此外，它們表明需要超越基於提示的 CoT，轉向新的範例，以更好地利用 LLM 應用程式的整個範圍內的中間運算。

##### **A Controlled Study on Long Context Extension and Generalization in LLMs**
2409.12181v2 by Yi Lu, Jing Nathan Yan, Songlin Yang, Justin T. Chiu, Siyu Ren, Fei Yuan, Wenting Zhao, Zhiyong Wu, Alexander M. Rush

Broad textual understanding and in-context learning require language models
that utilize full document contexts. Due to the implementation challenges
associated with directly training long-context models, many methods have been
proposed for extending models to handle long contexts. However, owing to
differences in data and model classes, it has been challenging to compare these
approaches, leading to uncertainty as to how to evaluate long-context
performance and whether it differs from standard evaluation. We implement a
controlled protocol for extension methods with a standardized evaluation,
utilizing consistent base models and extension data. Our study yields several
insights into long-context behavior. First, we reaffirm the critical role of
perplexity as a general-purpose performance indicator even in longer-context
tasks. Second, we find that current approximate attention methods
systematically underperform across long-context tasks. Finally, we confirm that
exact fine-tuning based methods are generally effective within the range of
their extension, whereas extrapolation remains challenging. All codebases,
models, and checkpoints will be made available open-source, promoting
transparency and facilitating further research in this critical area of AI
development.

摘要：廣泛的文字理解和情境學習需要語言模型，利用完整的文檔內容。由於與直接訓練長內容模型相關的實作挑戰，已經提出許多方法來擴充模型以處理長內容。然而，由於資料和模型類別的差異，比較這些方法一直具有挑戰性，導致在如何評估長內容效能以及它是否與標準評估不同的問題上存在不確定性。我們實作了一個受控協定，用於擴充方法，並採用標準化評估，利用一致的基本模型和擴充資料。我們的研究對長內容行為產生了多項見解。首先，我們重申困惑度作為通用效能指標在更長內容任務中仍然至關重要的角色。其次，我們發現目前的近似注意力方法在長內容任務中系統性地表現不佳。最後，我們確認基於精確微調的方法通常在它們的擴充範圍內有效，而外推仍然具有挑戰性。所有程式碼庫、模型和檢查點都將開放原始碼，促進透明度並促進在 AI 開發這個關鍵領域的進一步研究。

##### **Finetuning Language Models to Emit Linguistic Expressions of Uncertainty**
2409.12180v1 by Arslan Chaudhry, Sridhar Thiagarajan, Dilan Gorur

Large language models (LLMs) are increasingly employed in information-seeking
and decision-making tasks. Despite their broad utility, LLMs tend to generate
information that conflicts with real-world facts, and their persuasive style
can make these inaccuracies appear confident and convincing. As a result,
end-users struggle to consistently align the confidence expressed by LLMs with
the accuracy of their predictions, often leading to either blind trust in all
outputs or a complete disregard for their reliability. In this work, we explore
supervised finetuning on uncertainty-augmented predictions as a method to
develop models that produce linguistic expressions of uncertainty.
Specifically, we measure the calibration of pre-trained models and then
fine-tune language models to generate calibrated linguistic expressions of
uncertainty. Through experiments on various question-answering datasets, we
demonstrate that LLMs are well-calibrated in assessing their predictions, and
supervised finetuning based on the model's own confidence leads to
well-calibrated expressions of uncertainty, particularly for single-claim
answers.

摘要：大型語言模型（LLM）正越來越廣泛地用於資訊搜尋和決策制定任務中。儘管其廣泛的效用，LLM 傾向於產生與現實世界事實相衝突的資訊，而且其具有說服力的風格可能會讓這些不準確的資訊看起來充滿自信且令人信服。因此，最終使用者難以持續將 LLM 表達的信心與其預測的準確性保持一致，這常常導致對所有輸出盲目信任或完全忽視其可靠性。在這項工作中，我們探討了在不確定性增強預測上進行監督微調，作為開發產生不確定性語言表達模型的方法。具體來說，我們測量預先訓練模型的校準，然後微調語言模型以產生校準的不確定性語言表達。透過對各種問答資料集的實驗，我們證明 LLM 在評估其預測方面校準良好，而且基於模型自身信心的監督微調會產生校準良好的不確定性表達，特別是對於單一聲明答案。

##### **You Only Read Once (YORO): Learning to Internalize Database Knowledge for Text-to-SQL**
2409.12172v1 by Hideo Kobayashi, Wuwei Lan, Peng Shi, Shuaichen Chang, Jiang Guo, Henghui Zhu, Zhiguo Wang, Patrick Ng

While significant progress has been made on the text-to-SQL task, recent
solutions repeatedly encode the same database schema for every question,
resulting in unnecessary high inference cost and often overlooking crucial
database knowledge. To address these issues, we propose You Only Read Once
(YORO), a novel paradigm that directly internalizes database knowledge into the
parametric knowledge of a text-to-SQL model during training and eliminates the
need for schema encoding during inference. YORO significantly reduces the input
token length by 66%-98%. Despite its shorter inputs, our empirical results
demonstrate YORO's competitive performances with traditional systems on three
benchmarks as well as its significant outperformance on large databases.
Furthermore, YORO excels in handling questions with challenging value
retrievals such as abbreviation.

摘要：儘管在文字轉 SQL 任務上已取得顯著進展，但最近的解決方案反覆為每個問題編碼相同的資料庫架構，導致不必要的推理成本過高，且經常忽略關鍵的資料庫知識。為了解決這些問題，我們提出「You Only Read Once（YORO）」這個新穎的範例，它會在訓練期間將資料庫知識直接內化為文字轉 SQL 模型的參數化知識，並消除推理期間架構編碼的需要。YORO 將輸入權杖長度大幅縮短了 66%-98%。儘管輸入較短，但我們的經驗結果證明了 YORO 在三個基準測試上與傳統系統具有競爭力的效能，且在大型資料庫上具有顯著的優異效能。此外，YORO 在處理具有挑戰性的值擷取（例如縮寫）的問題上表現出色。

##### **Decoding Style: Efficient Fine-Tuning of LLMs for Image-Guided Outfit Recommendation with Preference**
2409.12150v1 by Najmeh Forouzandehmehr, Nima Farrokhsiar, Ramin Giahi, Evren Korpeoglu, Kannan Achan

Personalized outfit recommendation remains a complex challenge, demanding
both fashion compatibility understanding and trend awareness. This paper
presents a novel framework that harnesses the expressive power of large
language models (LLMs) for this task, mitigating their "black box" and static
nature through fine-tuning and direct feedback integration. We bridge the item
visual-textual gap in items descriptions by employing image captioning with a
Multimodal Large Language Model (MLLM). This enables the LLM to extract style
and color characteristics from human-curated fashion images, forming the basis
for personalized recommendations. The LLM is efficiently fine-tuned on the
open-source Polyvore dataset of curated fashion images, optimizing its ability
to recommend stylish outfits. A direct preference mechanism using negative
examples is employed to enhance the LLM's decision-making process. This creates
a self-enhancing AI feedback loop that continuously refines recommendations in
line with seasonal fashion trends. Our framework is evaluated on the Polyvore
dataset, demonstrating its effectiveness in two key tasks: fill-in-the-blank,
and complementary item retrieval. These evaluations underline the framework's
ability to generate stylish, trend-aligned outfit suggestions, continuously
improving through direct feedback. The evaluation results demonstrated that our
proposed framework significantly outperforms the base LLM, creating more
cohesive outfits. The improved performance in these tasks underscores the
proposed framework's potential to enhance the shopping experience with accurate
suggestions, proving its effectiveness over the vanilla LLM based outfit
generation.

摘要：<paragraph>個人化服裝推薦仍然是一項複雜的挑戰，既需要對時尚相容性有深入的了解，又需要了解趨勢。本文提出了一個新穎的框架，利用大型語言模型 (LLM) 的表達能力來執行這項任務，透過微調和直接回饋整合來減輕其「黑盒子」和靜態性質。我們透過使用具有多模態大型語言模型 (MLLM) 的影像標題，來彌合項目視覺與文字在項目描述中的差距。這使 LLM 能夠從人工策展的時尚影像中提取風格和色彩特徵，作為個人化推薦的基礎。LLM 在策展時尚影像的開源 Polyvore 資料集上進行了高效的微調，優化了其推薦時尚服裝的能力。使用負面範例的直接偏好機制被用來增強 LLM 的決策過程。這創造了一個自我增強的 AI 回饋迴路，根據季節性時尚趨勢不斷優化推薦。我們的框架在 Polyvore 資料集上進行了評估，證明了其在兩個關鍵任務中的有效性：填空和互補項目檢索。這些評估強調了該框架生成時尚、符合趨勢的服裝建議的能力，並透過直接回饋不斷改進。評估結果表明，我們提出的框架顯著優於基礎 LLM，創造出更具凝聚力的服裝。在這些任務中改進的效能突顯了所提出的框架在透過準確的建議增強購物體驗方面的潛力，證明了其優於基於香草 LLM 的服裝生成的效能。</paragraph>

##### **MAgICoRe: Multi-Agent, Iterative, Coarse-to-Fine Refinement for Reasoning**
2409.12147v1 by Justin Chih-Yao Chen, Archiki Prasad, Swarnadeep Saha, Elias Stengel-Eskin, Mohit Bansal

Large Language Models' (LLM) reasoning can be improved using test-time
aggregation strategies, i.e., generating multiple samples and voting among
generated samples. While these improve performance, they often reach a
saturation point. Refinement offers an alternative by using LLM-generated
feedback to improve solution quality. However, refinement introduces 3 key
challenges: (1) Excessive refinement: Uniformly refining all instances can
over-correct and reduce the overall performance. (2) Inability to localize and
address errors: LLMs have a limited ability to self-correct and struggle to
identify and correct their own mistakes. (3) Insufficient refinement: Deciding
how many iterations of refinement are needed is non-trivial, and stopping too
soon could leave errors unaddressed. To tackle these issues, we propose
MAgICoRe, which avoids excessive refinement by categorizing problem difficulty
as easy or hard, solving easy problems with coarse-grained aggregation and hard
ones with fine-grained and iterative multi-agent refinement. To improve error
localization, we incorporate external step-wise reward model (RM) scores.
Moreover, to ensure effective refinement, we employ a multi-agent loop with
three agents: Solver, Reviewer (which generates targeted feedback based on
step-wise RM scores), and the Refiner (which incorporates feedback). To ensure
sufficient refinement, we re-evaluate updated solutions, iteratively initiating
further rounds of refinement. We evaluate MAgICoRe on Llama-3-8B and GPT-3.5
and show its effectiveness across 5 math datasets. Even one iteration of
MAgICoRe beats Self-Consistency by 3.4%, Best-of-k by 3.2%, and Self-Refine by
4.0% while using less than half the samples. Unlike iterative refinement with
baselines, MAgICoRe continues to improve with more iterations. Finally, our
ablations highlight the importance of MAgICoRe's RMs and multi-agent
communication.

摘要：大型語言模型 (LLM) 的推理能力可以使用測試時間聚合策略來改善，即生成多個樣本並在生成的樣本中進行投票。雖然這些策略可以提升效能，但它們通常會達到飽和點。精煉提供了一種替代方案，藉由使用 LLM 生成的回饋來改善解決方案的品質。然而，精煉引入了 3 個主要挑戰：(1) 過度精煉：均勻地精煉所有實例可能會過度修正並降低整體效能。(2) 無法定位和解決錯誤：LLM 自我修正的能力有限，且難以辨識和修正自己的錯誤。(3) 精煉不足：決定需要多少次精煉並非易事，而且太快停止可能會讓錯誤未獲解決。為了解決這些問題，我們提出了 MAgICoRe，它透過將問題難度分類為容易或困難，使用粗略聚合解決容易的問題，並使用細緻且反覆的多重代理精煉解決困難的問題，從而避免過度精煉。為了改善錯誤定位，我們納入了外部逐步獎勵模型 (RM) 分數。此外，為了確保精煉有效，我們採用一個包含三個代理的多重代理迴圈：求解器、審查者（根據逐步 RM 分數產生目標回饋），以及精煉器（納入回饋）。為了確保精煉充分，我們重新評估更新的解決方案，反覆啟動進一步的精煉回合。我們在 Llama-3-8B 和 GPT-3.5 上評估 MAgICoRe，並展示了它在 5 個數學資料集中的有效性。即使只進行一次 MAgICoRe 反覆運算，也能比自我一致性高出 3.4%，比最佳 k 高出 3.2%，比自我精煉高出 4.0%，同時使用的樣本不到一半。與使用基準進行反覆精煉不同，MAgICoRe 會隨著反覆運算次數的增加而持續改善。最後，我們的消融實驗突出了 MAgICoRe 的 RM 和多重代理溝通的重要性。

##### **Takin: A Cohort of Superior Quality Zero-shot Speech Generation Models**
2409.12139v3 by Sijing Chen, Yuan Feng, Laipeng He, Tianwei He, Wendi He, Yanni Hu, Bin Lin, Yiting Lin, Yu Pan, Pengfei Tan, Chengwei Tian, Chen Wang, Zhicheng Wang, Ruoye Xie, Jixun Yao, Quanlei Yan, Yuguang Yang, Jianhao Ye, Jingjing Yin, Yanzhen Yu, Huimin Zhang, Xiang Zhang, Guangcheng Zhao, Hongbin Zhou, Pengpeng Zou

With the advent of the big data and large language model era, zero-shot
personalized rapid customization has emerged as a significant trend. In this
report, we introduce Takin AudioLLM, a series of techniques and models, mainly
including Takin TTS, Takin VC, and Takin Morphing, specifically designed for
audiobook production. These models are capable of zero-shot speech production,
generating high-quality speech that is nearly indistinguishable from real human
speech and facilitating individuals to customize the speech content according
to their own needs. Specifically, we first introduce Takin TTS, a neural codec
language model that builds upon an enhanced neural speech codec and a
multi-task training framework, capable of generating high-fidelity natural
speech in a zero-shot way. For Takin VC, we advocate an effective content and
timbre joint modeling approach to improve the speaker similarity, while
advocating for a conditional flow matching based decoder to further enhance its
naturalness and expressiveness. Last, we propose the Takin Morphing system with
highly decoupled and advanced timbre and prosody modeling approaches, which
enables individuals to customize speech production with their preferred timbre
and prosody in a precise and controllable manner. Extensive experiments
validate the effectiveness and robustness of our Takin AudioLLM series models.
For detailed demos, please refer to
https://everest-ai.github.io/takinaudiollm/.

摘要：隨著大數據和大語言模型時代的到來，零樣本個人化快速客製化已成為重要的趨勢。在此報告中，我們介紹 Takin AudioLLM，這是一系列技術和模型，主要包括 Takin TTS、Takin VC 和 Takin Morphing，專門設計用於有聲書製作。這些模型能夠進行零樣本語音製作，產生幾乎與真人語音無法區分的優質語音，並協助個人根據自己的需求客製化語音內容。具體來說，我們首先介紹 Takin TTS，這是一個神經編解碼器語言模型，建立在增強的神經語音編解碼器和多任務訓練架構上，能夠以零樣本的方式產生高保真自然語音。對於 Takin VC，我們提倡一種有效內容和音色聯合建模方法，以提高說話者相似度，同時提倡基於條件流匹配的解碼器，以進一步增強其自然性和表現力。最後，我們提出 Takin Morphing 系統，採用高度解耦和先進的音色和韻律建模方法，使個人能夠以精確且可控的方式客製化語音製作，並採用他們偏好的音色和韻律。大量的實驗驗證了我們的 Takin AudioLLM 系列模型的有效性和穩健性。有關詳細示範，請參閱 https://everest-ai.github.io/takinaudiollm/。

##### **GRIN: GRadient-INformed MoE**
2409.12136v1 by Liyuan Liu, Young Jin Kim, Shuohang Wang, Chen Liang, Yelong Shen, Hao Cheng, Xiaodong Liu, Masahiro Tanaka, Xiaoxia Wu, Wenxiang Hu, Vishrav Chaudhary, Zeqi Lin, Chenruidong Zhang, Jilong Xue, Hany Awadalla, Jianfeng Gao, Weizhu Chen

Mixture-of-Experts (MoE) models scale more effectively than dense models due
to sparse computation through expert routing, selectively activating only a
small subset of expert modules. However, sparse computation challenges
traditional training practices, as discrete expert routing hinders standard
backpropagation and thus gradient-based optimization, which are the cornerstone
of deep learning. To better pursue the scaling power of MoE, we introduce GRIN
(GRadient-INformed MoE training), which incorporates sparse gradient estimation
for expert routing and configures model parallelism to avoid token dropping.
Applying GRIN to autoregressive language modeling, we develop a top-2
16$\times$3.8B MoE model. Our model, with only 6.6B activated parameters,
outperforms a 7B dense model and matches the performance of a 14B dense model
trained on the same data. Extensive evaluations across diverse tasks
demonstrate the potential of GRIN to significantly enhance MoE efficacy,
achieving 79.4 on MMLU, 83.7 on HellaSwag, 74.4 on HumanEval, and 58.9 on MATH.

摘要：混合专家 (MoE) 模型比密集模型更有效地扩展，这是因为通过专家路由进行稀疏计算，有选择地仅激活一小部分专家模块。然而，稀疏计算对传统训练实践提出了挑战，因为离散专家路由阻碍了标准反向传播，从而阻碍了基于梯度的优化，而基于梯度的优化是深度学习的基石。为了更好地追求 MoE 的扩展能力，我们引入了 GRIN（梯度信息 MoE 训练），它结合了专家路由的稀疏梯度估计，并配置模型并行性以避免令牌丢失。将 GRIN 应用于自回归语言建模，我们开发了一个 top-2 16×3.8B MoE 模型。我们的模型仅激活了 6.6B 个参数，优于 7B 密集模型，并且与在相同数据上训练的 14B 密集模型的性能相匹配。跨不同任务的广泛评估证明了 GRIN 在显著提高 MoE 效能方面的潜力，在 MMLU 上达到 79.4，在 HellaSwag 上达到 83.7，在 HumanEval 上达到 74.4，在 MATH 上达到 58.9。

##### **BERT-VBD: Vietnamese Multi-Document Summarization Framework**
2409.12134v1 by Tuan-Cuong Vuong, Trang Mai Xuan, Thien Van Luong

In tackling the challenge of Multi-Document Summarization (MDS), numerous
methods have been proposed, spanning both extractive and abstractive
summarization techniques. However, each approach has its own limitations,
making it less effective to rely solely on either one. An emerging and
promising strategy involves a synergistic fusion of extractive and abstractive
summarization methods. Despite the plethora of studies in this domain, research
on the combined methodology remains scarce, particularly in the context of
Vietnamese language processing. This paper presents a novel Vietnamese MDS
framework leveraging a two-component pipeline architecture that integrates
extractive and abstractive techniques. The first component employs an
extractive approach to identify key sentences within each document. This is
achieved by a modification of the pre-trained BERT network, which derives
semantically meaningful phrase embeddings using siamese and triplet network
structures. The second component utilizes the VBD-LLaMA2-7B-50b model for
abstractive summarization, ultimately generating the final summary document.
Our proposed framework demonstrates a positive performance, attaining ROUGE-2
scores of 39.6% on the VN-MDS dataset and outperforming the state-of-the-art
baselines.

摘要：<paragraph>在解決多文件摘要 (MDS) 的挑戰中，已經提出了許多方法，涵蓋萃取和抽象摘要技術。然而，每種方法都有其限制，單獨依賴任何一種方法的效果都不佳。一種新興且有前景的策略涉及萃取和抽象摘要方法的協同融合。儘管在這個領域有許多研究，但對這種組合方法的研究仍然很少，特別是在越南語處理的背景下。本文提出了一個新穎的越南語 MDS 框架，利用一個兩組件管道架構，整合了萃取和抽象技術。第一個組件採用萃取方法來識別每個文件中的關鍵句子。這是通過修改預先訓練的 BERT 網路來實現的，該網路使用連體和三元組網路結構來推導語義上有意義的短語嵌入。第二個組件利用 VBD-LLaMA2-7B-50b 模型進行抽象摘要，最終生成最終摘要文件。我們提出的框架展示了積極的效能，在 VN-MDS 資料集上獲得了 39.6% 的 ROUGE-2 分數，並優於最先進的基準。</paragraph>

##### **Linguini: A benchmark for language-agnostic linguistic reasoning**
2409.12126v1 by Eduardo Sánchez, Belen Alastruey, Christophe Ropers, Pontus Stenetorp, Mikel Artetxe, Marta R. Costa-jussà

We propose a new benchmark to measure a language model's linguistic reasoning
skills without relying on pre-existing language-specific knowledge. The test
covers 894 questions grouped in 160 problems across 75 (mostly) extremely
low-resource languages, extracted from the International Linguistic Olympiad
corpus. To attain high accuracy on this benchmark, models don't need previous
knowledge of the tested language, as all the information needed to solve the
linguistic puzzle is presented in the context. We find that, while all analyzed
models rank below 25% accuracy, there is a significant gap between open and
closed models, with the best-performing proprietary model at 24.05% and the
best-performing open model at 8.84%.

摘要：我們提出一個新的基準來衡量語言模型的語言推理技能，而不需要依賴於現有的特定語言知識。該測試涵蓋了 894 個問題，分為 160 個問題，橫跨 75 種（大多數）極低資源語言，這些語言取自國際語言奧林匹克競賽語料庫。要在此基準上獲得高準確度，模型不需要先前的測試語言知識，因為解決語言謎題所需的所有資訊都顯示在上下文中。我們發現，雖然所有分析的模型準確度都低於 25%，但開放模型和封閉模型之間存在顯著差距，表現最好的專有模型為 24.05%，表現最好的開放模型為 8.84%。

##### **Qwen2.5-Math Technical Report: Toward Mathematical Expert Model via Self-Improvement**
2409.12122v1 by An Yang, Beichen Zhang, Binyuan Hui, Bofei Gao, Bowen Yu, Chengpeng Li, Dayiheng Liu, Jianhong Tu, Jingren Zhou, Junyang Lin, Keming Lu, Mingfeng Xue, Runji Lin, Tianyu Liu, Xingzhang Ren, Zhenru Zhang

In this report, we present a series of math-specific large language models:
Qwen2.5-Math and Qwen2.5-Math-Instruct-1.5B/7B/72B. The core innovation of the
Qwen2.5 series lies in integrating the philosophy of self-improvement
throughout the entire pipeline, from pre-training and post-training to
inference: (1) During the pre-training phase, Qwen2-Math-Instruct is utilized
to generate large-scale, high-quality mathematical data. (2) In the
post-training phase, we develop a reward model (RM) by conducting massive
sampling from Qwen2-Math-Instruct. This RM is then applied to the iterative
evolution of data in supervised fine-tuning (SFT). With a stronger SFT model,
it's possible to iteratively train and update the RM, which in turn guides the
next round of SFT data iteration. On the final SFT model, we employ the
ultimate RM for reinforcement learning, resulting in the Qwen2.5-Math-Instruct.
(3) Furthermore, during the inference stage, the RM is used to guide sampling,
optimizing the model's performance.
  Qwen2.5-Math-Instruct supports both Chinese and English, and possess advanced
mathematical reasoning capabilities, including Chain-of-Thought (CoT) and
Tool-Integrated Reasoning (TIR). We evaluate our models on 10 mathematics
datasets in both English and Chinese, such as GSM8K, MATH, GaoKao, AMC23, and
AIME24, covering a range of difficulties from grade school level to math
competition problems.

摘要：<paragraph>在這份報告中，我們提出了一系列數學專用的大型語言模型：
Qwen2.5-Math 和 Qwen2.5-Math-Instruct-1.5B/7B/72B。
Qwen2.5 系列的核心創新在於將自我提升的理念整合到整個流程中，從預訓練和後訓練到推理：(1) 在預訓練階段，Qwen2-Math-Instruct 被用於生成大規模、高品質的數學數據。(2) 在後訓練階段，我們通過從 Qwen2-Math-Instruct 進行大量採樣來開發一個獎勵模型 (RM)。然後將此 RM 應用於監督微調 (SFT) 中數據的迭代演化。使用更強大的 SFT 模型，可以迭代訓練和更新 RM，而 RM 又指導下一輪 SFT 數據迭代。在最終的 SFT 模型中，我們採用最終的 RM 進行強化學習，從而得到 Qwen2.5-Math-Instruct。(3) 此外，在推理階段，RM 被用於指導採樣，優化模型的性能。
Qwen2.5-Math-Instruct 同時支援中文和英文，並具備先進的數學推理能力，包括思維鏈 (CoT) 和工具整合推理 (TIR)。我們在 10 個英文和中文數學數據集上評估了我們的模型，例如 GSM8K、MATH、高考、AMC23 和 AIME24，涵蓋了從小學到數學競賽問題的各種難度。</paragraph>

##### **Low Frame-rate Speech Codec: a Codec Designed for Fast High-quality Speech LLM Training and Inference**
2409.12117v1 by Edresson Casanova, Ryan Langman, Paarth Neekhara, Shehzeen Hussain, Jason Li, Subhankar Ghosh, Ante Jukić, Sang-gil Lee

Large language models (LLMs) have significantly advanced audio processing
through audio codecs that convert audio into discrete tokens, enabling the
application of language modeling techniques to audio data. However, audio
codecs often operate at high frame rates, resulting in slow training and
inference, especially for autoregressive models. To address this challenge, we
present the Low Frame-rate Speech Codec (LFSC): a neural audio codec that
leverages finite scalar quantization and adversarial training with large speech
language models to achieve high-quality audio compression with a 1.89 kbps
bitrate and 21.5 frames per second. We demonstrate that our novel codec can
make the inference of LLM-based text-to-speech models around three times faster
while improving intelligibility and producing quality comparable to previous
models.

摘要：大型語言模型 (LLM) 透過將音訊轉換為離散符號的音訊編解碼器，大幅提升了音訊處理，並能將語言模型技術應用於音訊資料。然而，音訊編解碼器通常以高幀率運作，導致訓練和推論速度緩慢，特別是對於自迴歸模型而言。為了應對此挑戰，我們提出了低幀率語音編解碼器 (LFSC)：一種神經音訊編解碼器，它利用有限標量量化和對抗訓練，結合大型語音語言模型，以 1.89 kbps 的比特率和每秒 21.5 幀，達成高品質的音訊壓縮。我們證明了我們的新穎編解碼器可以讓基於 LLM 的文字轉語音模型的推論速度快上約三倍，同時提升可懂度，並產生與先前模型相當的品質。

##### **Measuring Human and AI Values based on Generative Psychometrics with Large Language Models**
2409.12106v1 by Haoran Ye, Yuhang Xie, Yuanyi Ren, Hanjun Fang, Xin Zhang, Guojie Song

Human values and their measurement are long-standing interdisciplinary
inquiry. Recent advances in AI have sparked renewed interest in this area, with
large language models (LLMs) emerging as both tools and subjects of value
measurement. This work introduces Generative Psychometrics for Values (GPV), an
LLM-based, data-driven value measurement paradigm, theoretically grounded in
text-revealed selective perceptions. We begin by fine-tuning an LLM for
accurate perception-level value measurement and verifying the capability of
LLMs to parse texts into perceptions, forming the core of the GPV pipeline.
Applying GPV to human-authored blogs, we demonstrate its stability, validity,
and superiority over prior psychological tools. Then, extending GPV to LLM
value measurement, we advance the current art with 1) a psychometric
methodology that measures LLM values based on their scalable and free-form
outputs, enabling context-specific measurement; 2) a comparative analysis of
measurement paradigms, indicating response biases of prior methods; and 3) an
attempt to bridge LLM values and their safety, revealing the predictive power
of different value systems and the impacts of various values on LLM safety.
Through interdisciplinary efforts, we aim to leverage AI for next-generation
psychometrics and psychometrics for value-aligned AI.

摘要：人類的價值觀及其衡量是長久以來的跨學科探討。最近人工智慧的進展激起了這個領域的興趣，大型語言模型 (LLM) 成為價值衡量的工具和主題。這項工作引入了生成式價值心理測量 (GPV)，一種基於 LLM、資料驅動的價值衡量範例，理論上以文字揭示選擇性知覺為基礎。我們從微調 LLM 開始，以進行準確的知覺層級價值衡量，並驗證 LLM 將文字解析為知覺的能力，形成 GPV 管線的核心。將 GPV 應用於人類撰寫的部落格，我們證明了它的穩定性、效度和優於先前的的心理工具。然後，將 GPV 延伸到 LLM 價值衡量，我們透過以下方式推進目前的技術：1) 一種心理測量方法，根據 LLM 可擴充且自由形式的輸出衡量 LLM 價值，實現特定於情境的衡量；2) 衡量範例的比較分析，指出先前方法的反應偏差；3) 嘗試橋接 LLM 價值及其安全性，揭示不同價值系統的預測能力和各種價值對 LLM 安全性的影響。透過跨學科的努力，我們旨在利用人工智慧進行新一代的心理測量，並利用心理測量進行與價值觀一致的人工智慧。

##### **Skill matching at scale: freelancer-project alignment for efficient multilingual candidate retrieval**
2409.12097v2 by Warren Jouanneau, Marc Palyart, Emma Jouffroy

Finding the perfect match between a job proposal and a set of freelancers is
not an easy task to perform at scale, especially in multiple languages. In this
paper, we propose a novel neural retriever architecture that tackles this
problem in a multilingual setting. Our method encodes project descriptions and
freelancer profiles by leveraging pre-trained multilingual language models. The
latter are used as backbone for a custom transformer architecture that aims to
keep the structure of the profiles and project. This model is trained with a
contrastive loss on historical data. Thanks to several experiments, we show
that this approach effectively captures skill matching similarity and
facilitates efficient matching, outperforming traditional methods.

摘要：在多種語言中，要在大規模情況下找到職務提案和一組自由工作者之間的完美匹配並非易事。在本文中，我們提出了一種新穎的神經檢索器架構，它以多語言設定來解決這個問題。我們的技術利用預先訓練的多語言語言模型來編碼專案描述和自由工作者個人資料。後者用作自訂Transformer架構的骨幹，目的是保留個人資料和專案的結構。此模型使用對比損失針對歷史資料進行訓練。透過多項實驗，我們證明這種方法有效地捕捉到技能匹配相似性，並促進有效匹配，優於傳統方法。

##### **IMRL: Integrating Visual, Physical, Temporal, and Geometric Representations for Enhanced Food Acquisition**
2409.12092v1 by Rui Liu, Zahiruddin Mahammad, Amisha Bhaskar, Pratap Tokekar

Robotic assistive feeding holds significant promise for improving the quality
of life for individuals with eating disabilities. However, acquiring diverse
food items under varying conditions and generalizing to unseen food presents
unique challenges. Existing methods that rely on surface-level geometric
information (e.g., bounding box and pose) derived from visual cues (e.g.,
color, shape, and texture) often lacks adaptability and robustness, especially
when foods share similar physical properties but differ in visual appearance.
We employ imitation learning (IL) to learn a policy for food acquisition.
Existing methods employ IL or Reinforcement Learning (RL) to learn a policy
based on off-the-shelf image encoders such as ResNet-50. However, such
representations are not robust and struggle to generalize across diverse
acquisition scenarios. To address these limitations, we propose a novel
approach, IMRL (Integrated Multi-Dimensional Representation Learning), which
integrates visual, physical, temporal, and geometric representations to enhance
the robustness and generalizability of IL for food acquisition. Our approach
captures food types and physical properties (e.g., solid, semi-solid, granular,
liquid, and mixture), models temporal dynamics of acquisition actions, and
introduces geometric information to determine optimal scooping points and
assess bowl fullness. IMRL enables IL to adaptively adjust scooping strategies
based on context, improving the robot's capability to handle diverse food
acquisition scenarios. Experiments on a real robot demonstrate our approach's
robustness and adaptability across various foods and bowl configurations,
including zero-shot generalization to unseen settings. Our approach achieves
improvement up to $35\%$ in success rate compared with the best-performing
baseline.

摘要：<paragraph>機器人輔助進食對於改善進食障礙者的生活品質有很大的幫助。然而，在不同的條件下取得多樣的食品，並將其推廣到未見過的食品，會帶來獨特的挑戰。現有的方法依賴於從視覺線索（例如顏色、形狀和紋理）衍生的表面幾何資訊（例如邊界框和姿勢），通常缺乏適應性和穩健性，特別是當食物具有相似的物理性質但視覺外觀不同時。我們採用模仿學習 (IL) 來學習食物採集策略。現有的方法採用 IL 或強化學習 (RL) 來學習基於現成圖像編碼器（例如 ResNet-50）的策略。然而，此類表示並不穩健，並且難以推廣到不同的採集場景。為了解決這些限制，我們提出了一種新的方法，IMRL（整合多維表示學習），它整合了視覺、物理、時間和幾何表示，以增強 IL 在食物採集方面的穩健性和概括性。我們的做法捕捉食物類型和物理性質（例如固體、半固體、顆粒狀、液體和混合物），對採集動作的時間動態進行建模，並引入幾何資訊來確定最佳舀取點和評估碗的飽滿度。IMRL 使 IL 能夠根據上下文調整舀取策略，從而提高機器人在處理不同食物採集場景方面的能力。在真實機器人上的實驗證明了我們的方法在各種食物和碗配置中的穩健性和適應性，包括對未見過場景的零次學習概括。與效能最佳的基準相比，我們的做法成功率提高了 $35\%$。</paragraph>

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v1 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

摘要：本研究探討利用行政索賠資料的潛力，結合進階機器學習和深度學習技術，預測慢性腎臟病 (CKD) 進展至末期腎臟疾病 (ESRD)。我們分析由一家大型健康保險組織提供的十年綜合資料集，使用傳統機器學習方法（例如隨機森林和 XGBoost）以及深度學習方法（例如長短期記憶 (LSTM) 網路）開發多個觀察時段的預測模型。我們的研究結果表明，LSTM 模型，特別是具有 24 個月的觀察時段，在預測 ESRD 進展方面表現優異，優於文獻中的現有模型。我們進一步應用 SHapley 加法解釋 (SHAP) 分析來增強可解釋性，深入了解個別特徵對個別患者層級預測的影響。本研究強調了利用行政索賠資料進行 CKD 管理和預測 ESRD 進展的價值。

##### **PAD-FT: A Lightweight Defense for Backdoor Attacks via Data Purification and Fine-Tuning**
2409.12072v1 by Yukai Xu, Yujie Gu, Kouichi Sakurai

Backdoor attacks pose a significant threat to deep neural networks,
particularly as recent advancements have led to increasingly subtle
implantation, making the defense more challenging. Existing defense mechanisms
typically rely on an additional clean dataset as a standard reference and
involve retraining an auxiliary model or fine-tuning the entire victim model.
However, these approaches are often computationally expensive and not always
feasible in practical applications. In this paper, we propose a novel and
lightweight defense mechanism, termed PAD-FT, that does not require an
additional clean dataset and fine-tunes only a very small part of the model to
disinfect the victim model. To achieve this, our approach first introduces a
simple data purification process to identify and select the most-likely clean
data from the poisoned training dataset. The self-purified clean dataset is
then used for activation clipping and fine-tuning only the last classification
layer of the victim model. By integrating data purification, activation
clipping, and classifier fine-tuning, our mechanism PAD-FT demonstrates
superior effectiveness across multiple backdoor attack methods and datasets, as
confirmed through extensive experimental evaluation.

摘要：後門攻擊對深度神經網路構成重大威脅，特別是最近的進展導致越來越精妙的植入，使得防禦更具挑戰性。現有的防禦機制通常依賴於額外的乾淨資料集作為標準參考，並涉及重新訓練輔助模型或微調整個受害者模型。然而，這些方法通常在計算上很昂貴，而且在實際應用中並不總是可行的。在本文中，我們提出了一種新穎且輕量的防禦機制，稱為 PAD-FT，它不需要額外的乾淨資料集，並且僅微調模型的極小部分來對受害者模型進行消毒。為實現此目的，我們的做法首先引入一個簡單的資料淨化程序，以從中毒的訓練資料集中識別並選擇最有可能的乾淨資料。然後將自淨化的乾淨資料集用於激活剪輯和僅微調受害者模型的最後分類層。通過整合資料淨化、激活剪輯和分類器微調，我們的機制 PAD-FT 在多種後門攻擊方法和資料集上展示了卓越的有效性，正如通過廣泛的實驗評估所證實的。

##### **Generalized Robot Learning Framework**
2409.12061v1 by Jiahuan Yan, Zhouyang Hong, Yu Zhao, Yu Tian, Yunxin Liu, Travis Davies, Luhui Hu

Imitation based robot learning has recently gained significant attention in
the robotics field due to its theoretical potential for transferability and
generalizability. However, it remains notoriously costly, both in terms of
hardware and data collection, and deploying it in real-world environments
demands meticulous setup of robots and precise experimental conditions. In this
paper, we present a low-cost robot learning framework that is both easily
reproducible and transferable to various robots and environments. We
demonstrate that deployable imitation learning can be successfully applied even
to industrial-grade robots, not just expensive collaborative robotic arms.
Furthermore, our results show that multi-task robot learning is achievable with
simple network architectures and fewer demonstrations than previously thought
necessary. As the current evaluating method is almost subjective when it comes
to real-world manipulation tasks, we propose Voting Positive Rate (VPR) - a
novel evaluation strategy that provides a more objective assessment of
performance. We conduct an extensive comparison of success rates across various
self-designed tasks to validate our approach. To foster collaboration and
support the robot learning community, we have open-sourced all relevant
datasets and model checkpoints, available at huggingface.co/ZhiChengAI.

摘要：模仿式機器人學習最近在機器人領域獲得了極大的關注，因為它在可轉移性和概括性方面具有理論潛力。然而，它仍然惡名昭彰地昂貴，無論是在硬體還是資料收集方面，而且在現實世界環境中部署它需要對機器人進行細緻的設定和精確的實驗條件。在本文中，我們提出了一個低成本的機器人學習框架，它易於複製，並且可以轉移到各種機器人和環境中。我們證明，可部署的模仿學習可以成功應用於工業級機器人，而不仅仅是昂貴的協作機器人手臂。此外，我們的結果表明，多任務機器人學習可以使用簡單的網路架構和比以前認為必要的更少的演示來實現。由於當前的評估方法在涉及實際操作任務時幾乎是主觀的，因此我們提出了投票陽性率 (VPR) - 一種新穎的評估策略，它提供了對性能更客觀的評估。我們對各種自設計任務的成功率進行了廣泛比較，以驗證我們的做法。為了促進合作並支持機器人學習社群，我們已開放原始碼所有相關資料集和模型檢查點，可在 huggingface.co/ZhiChengAI 獲得。

##### **PARAPHRASUS : A Comprehensive Benchmark for Evaluating Paraphrase Detection Models**
2409.12060v1 by Andrianos Michail, Simon Clematide, Juri Opitz

The task of determining whether two texts are paraphrases has long been a
challenge in NLP. However, the prevailing notion of paraphrase is often quite
simplistic, offering only a limited view of the vast spectrum of paraphrase
phenomena. Indeed, we find that evaluating models in a paraphrase dataset can
leave uncertainty about their true semantic understanding. To alleviate this,
we release paraphrasus, a benchmark designed for multi-dimensional assessment
of paraphrase detection models and finer model selection. We find that
paraphrase detection models under a fine-grained evaluation lens exhibit
trade-offs that cannot be captured through a single classification dataset.

摘要：判定兩段文字是否為同義改寫，長期以來一直是自然語言處理領域的挑戰。然而，同義改寫的主流觀念通常過於簡化，僅提供同義改寫現象廣泛光譜的有限視角。事實上，我們發現，在同義改寫資料集中評估模型可能會對其真正的語義理解力造成不確定性。為了改善這個問題，我們發布了 paraphrasus，這是一個基準，專門用於多面向評估同義改寫偵測模型和更精細的模型選取。我們發現，在細緻的評估基準下，同義改寫偵測模型展現出的權衡無法透過單一分類資料集捕捉。

##### **Dual-Layer Training and Decoding of Large Language Model with Simultaneously Thinking and Speaking**
2409.12059v1 by Ningyuan Xi, Xiaoyu Wang, Yetao Wu, Teng Chen, Qingqing Gu, Jinxian Qu, Zhonglin Jiang, Yong Chen, Luo Ji

Large Language Model can reasonably understand and generate human expressions
but may lack of thorough thinking and reasoning mechanisms. Recently there have
been several studies which enhance the thinking ability of language models but
most of them are not data-driven or training-based. In this paper, we are
motivated by the cognitive mechanism in the natural world, and design a novel
model architecture called TaS which allows it to first consider the thoughts
and then express the response based upon the query. We design several pipelines
to annotate or generate the thought contents from prompt-response samples, then
add language heads in a middle layer which behaves as the thinking layer. We
train the language model by the thoughts-augmented data and successfully let
the thinking layer automatically generate reasonable thoughts and finally
output more reasonable responses. Both qualitative examples and quantitative
results validate the effectiveness and performance of TaS. Our code is
available at https://anonymous.4open.science/r/TadE.

摘要：大型语言模型可以合理地理解和生成人类表达，
但可能缺乏透彻的思考和推理机制。最近有几项研究增强了语言模型的思考能力，但
其中大多数不是数据驱动的或基于训练的。在本文中，我们受到自然界认知机制的启发，并设计了一种新颖的
模型架构称为 TaS，它允许它首先考虑想法，然后根据查询表达响应。我们设计了几个管道
从提示响应样本中注释或生成思想内容，然后在充当思考层的中间层中添加语言头。我们
通过思想增强数据训练语言模型，并成功地让思考层自动生成合理的思想，最终
输出更合理的响应。定性和示例和定量结果验证了 TaS 的有效性和性能。我们的代码可在 https://anonymous.4open.science/r/TadE 获得。

##### **Using Large Language Models to Generate Clinical Trial Tables and Figures**
2409.12046v2 by Yumeng Yang, Peter Krusche, Kristyn Pantoja, Cheng Shi, Ethan Ludmir, Kirk Roberts, Gen Zhu

Tables, figures, and listings (TFLs) are essential tools for summarizing
clinical trial data. Creation of TFLs for reporting activities is often a
time-consuming task encountered routinely during the execution of clinical
trials. This study explored the use of large language models (LLMs) to automate
the generation of TFLs through prompt engineering and few-shot transfer
learning. Using public clinical trial data in ADaM format, our results
demonstrated that LLMs can efficiently generate TFLs with prompt instructions,
showcasing their potential in this domain. Furthermore, we developed a
conservational agent named Clinical Trial TFL Generation Agent: An app that
matches user queries to predefined prompts that produce customized programs to
generate specific predefined TFLs.

摘要：表格、圖表和清單 (TFL) 是總結臨床試驗資料的基本工具。建立 TFL 以報告活動通常是臨床試驗執行過程中例行且耗時的任務。本研究探討使用大型語言模型 (LLM) 透過提示工程和少量轉移學習來自動化 TFL 的產生。使用 ADaM 格式的公開臨床試驗資料，我們的結果證明 LLM 可以有效率地產生 TFL 並提供明確的指示，展示其在這個領域的潛力。此外，我們開發了一個名為「臨床試驗 TFL 產生代理」的對話代理：一個應用程式，它可以將使用者查詢與預先定義的提示配對，產生自訂程式以產生特定的預先定義 TFL。

##### **ASR Benchmarking: Need for a More Representative Conversational Dataset**
2409.12042v1 by Gaurav Maheshwari, Dmitry Ivanov, Théo Johannet, Kevin El Haddad

Automatic Speech Recognition (ASR) systems have achieved remarkable
performance on widely used benchmarks such as LibriSpeech and Fleurs. However,
these benchmarks do not adequately reflect the complexities of real-world
conversational environments, where speech is often unstructured and contains
disfluencies such as pauses, interruptions, and diverse accents. In this study,
we introduce a multilingual conversational dataset, derived from TalkBank,
consisting of unstructured phone conversation between adults. Our results show
a significant performance drop across various state-of-the-art ASR models when
tested in conversational settings. Furthermore, we observe a correlation
between Word Error Rate and the presence of speech disfluencies, highlighting
the critical need for more realistic, conversational ASR benchmarks.

摘要：自動語音辨識 (ASR) 系統在 LibriSpeech 和 Fleurs 等廣泛使用的基準上已達到顯著的效能表現。然而，這些基準並未充分反映現實世界對話環境的複雜性，在這些環境中，語音通常是不結構化的，並包含停頓、中斷和各種口音等不流暢現象。在本研究中，我們引進一個多語言對話資料集，其源自 TalkBank，包含成人之間非結構化的電話對話。我們的結果顯示，在對話式設定中進行測試時，各種最先進的 ASR 模型的效能表現大幅下降。此外，我們觀察到詞彙錯誤率與語音不流暢現象之間存在相關性，這突顯了對更真實、更對話式的 ASR 基準的迫切需求。

##### **Topological Deep Learning with State-Space Models: A Mamba Approach for Simplicial Complexes**
2409.12033v1 by Marco Montagna, Simone Scardapane, Lev Telyatnikov

Graph Neural Networks based on the message-passing (MP) mechanism are a
dominant approach for handling graph-structured data. However, they are
inherently limited to modeling only pairwise interactions, making it difficult
to explicitly capture the complexity of systems with $n$-body relations. To
address this, topological deep learning has emerged as a promising field for
studying and modeling higher-order interactions using various topological
domains, such as simplicial and cellular complexes. While these new domains
provide powerful representations, they introduce new challenges, such as
effectively modeling the interactions among higher-order structures through
higher-order MP. Meanwhile, structured state-space sequence models have proven
to be effective for sequence modeling and have recently been adapted for graph
data by encoding the neighborhood of a node as a sequence, thereby avoiding the
MP mechanism. In this work, we propose a novel architecture designed to operate
with simplicial complexes, utilizing the Mamba state-space model as its
backbone. Our approach generates sequences for the nodes based on the
neighboring cells, enabling direct communication between all higher-order
structures, regardless of their rank. We extensively validate our model,
demonstrating that it achieves competitive performance compared to
state-of-the-art models developed for simplicial complexes.

摘要：基於訊息傳遞 (MP) 機制的圖神經網路是處理圖結構資料的主流方法。然而，它們本質上僅限於建模成對交互作用，這使得難以明確捕捉具有 $n$-body 關係的系統的複雜性。為了解決這個問題，拓撲深度學習已成為一個有前景的領域，它使用各種拓撲域（例如，單純復形和細胞復形）來研究和建模高階交互作用。雖然這些新域提供了強大的表示，但它們也帶來了新的挑戰，例如透過高階 MP 有效地對高階結構之間的交互作用進行建模。同時，結構化狀態空間序列模型已被證明對於序列建模是有效的，並且最近已透過將節點的鄰域編碼為序列來適應圖資料，從而避免了 MP 機制。在這項工作中，我們提出了一種新穎的架構，旨在使用單純復形運作，並利用 Mamba 狀態空間模型作為其主幹。我們的做法基於鄰近單元產生節點的序列，從而實現所有高階結構之間的直接通訊，而不管它們的秩如何。我們廣泛驗證了我們的模型，證明它與為單純復形開發的最新模型相比，達到了有競爭力的效能。

##### **Promise and Peril of Collaborative Code Generation Models: Balancing Effectiveness and Memorization**
2409.12020v1 by Zhi Chen, Lingxiao Jiang

In the rapidly evolving field of machine learning, training models with
datasets from various locations and organizations presents significant
challenges due to privacy and legal concerns. The exploration of effective
collaborative training settings capable of leveraging valuable knowledge from
distributed and isolated datasets is increasingly crucial. This study
investigates key factors that impact the effectiveness of collaborative
training methods in code next-token prediction, as well as the correctness and
utility of the generated code, demonstrating the promise of such methods.
Additionally, we evaluate the memorization of different participant training
data across various collaborative training settings, including centralized,
federated, and incremental training, highlighting their potential risks in
leaking data. Our findings indicate that the size and diversity of code
datasets are pivotal factors influencing the success of collaboratively trained
code models. We show that federated learning achieves competitive performance
compared to centralized training while offering better data protection, as
evidenced by lower memorization ratios in the generated code. However,
federated learning can still produce verbatim code snippets from hidden
training data, potentially violating privacy or copyright. Our study further
explores effectiveness and memorization patterns in incremental learning,
emphasizing the sequence in which individual participant datasets are
introduced. We also identify cross-organizational clones as a prevalent
challenge in both centralized and federated learning scenarios. Our findings
highlight the persistent risk of data leakage during inference, even when
training data remains unseen. We conclude with recommendations for
practitioners and researchers to optimize multisource datasets, propelling
cross-organizational collaboration forward.

摘要：<paragraph>在機器學習快速演進的領域中，使用來自不同位置和組織的資料集來訓練模型，由於隱私和法律問題而面臨重大挑戰。探索有效協作訓練設定，能夠利用分散和孤立資料集中的寶貴知識，變得越來越重要。本研究探討影響協作訓練方法在程式碼下一個代碼預測中的有效性的關鍵因素，以及生成程式碼的正確性和實用性，展示此類方法的潛力。此外，我們評估不同參與者訓練資料在各種協作訓練設定中的記憶，包括集中式、聯合式和增量式訓練，強調其潛在的資料外洩風險。我們的研究結果表明，程式碼資料集的大小和多樣性是影響協作訓練程式碼模型成功的關鍵因素。我們展示了聯合式學習與集中式訓練相比，達到了競爭力的效能，同時提供更好的資料保護，從生成程式碼中較低的記憶比率可以看出。然而，聯合式學習仍可能從隱藏的訓練資料產生逐字的程式碼片段，潛在地侵犯隱私或版權。我們的研究進一步探討了增量式學習中的有效性和記憶模式，強調了引入個別參與者資料集的順序。我們還將跨組織複製識別為集中式和聯合式學習場景中普遍存在的挑戰。我們的研究結果強調了在推論期間資料外洩的持續風險，即使訓練資料仍然不可見。我們最後提出對從業者和研究人員的建議，以最佳化多來源資料集，推進跨組織合作。</paragraph>

##### **Representing Positional Information in Generative World Models for Object Manipulation**
2409.12005v2 by Stefano Ferraro, Pietro Mazzaglia, Tim Verbelen, Bart Dhoedt, Sai Rajeswar

Object manipulation capabilities are essential skills that set apart embodied
agents engaging with the world, especially in the realm of robotics. The
ability to predict outcomes of interactions with objects is paramount in this
setting. While model-based control methods have started to be employed for
tackling manipulation tasks, they have faced challenges in accurately
manipulating objects. As we analyze the causes of this limitation, we identify
the cause of underperformance in the way current world models represent crucial
positional information, especially about the target's goal specification for
object positioning tasks. We introduce a general approach that empowers world
model-based agents to effectively solve object-positioning tasks. We propose
two declinations of this approach for generative world models:
position-conditioned (PCP) and latent-conditioned (LCP) policy learning. In
particular, LCP employs object-centric latent representations that explicitly
capture object positional information for goal specification. This naturally
leads to the emergence of multimodal capabilities, enabling the specification
of goals through spatial coordinates or a visual goal. Our methods are
rigorously evaluated across several manipulation environments, showing
favorable performance compared to current model-based control approaches.

摘要：物體操作能力是讓具身代理與世界互動時不可或缺的重要技能，特別是在機器人領域。在這種情況下，預測與物體互動的結果至關重要。雖然基於模型的控制方法已開始用於處理操作任務，但在精確操作物體方面仍面臨挑戰。在分析此限制的原因時，我們找出當前世界模型表示關鍵位置資訊的方式中，導致效能不佳的原因，特別是關於物件定位任務的目標規格。我們提出了一種通用方法，讓基於世界模型的代理能有效解決物件定位任務。我們針對生成式世界模型提出了兩種此方法的變體：位置條件 (PCP) 和潛在條件 (LCP) 策略學習。特別是，LCP 使用以物件為中心的潛在表示，明確擷取物件位置資訊以進行目標規格。這自然會導致多模態能力的出現，讓目標能透過空間座標或視覺目標來指定。我們的這些方法在多個操作環境中都經過嚴格評估，與當前的基於模型的控制方法相比，顯示出良好的效能。

##### **Additive-feature-attribution methods: a review on explainable artificial intelligence for fluid dynamics and heat transfer**
2409.11992v1 by Andrés Cremades, Sergio Hoyas, Ricardo Vinuesa

The use of data-driven methods in fluid mechanics has surged dramatically in
recent years due to their capacity to adapt to the complex and multi-scale
nature of turbulent flows, as well as to detect patterns in large-scale
simulations or experimental tests. In order to interpret the relationships
generated in the models during the training process, numerical attributions
need to be assigned to the input features. One important example are the
additive-feature-attribution methods. These explainability methods link the
input features with the model prediction, providing an interpretation based on
a linear formulation of the models. The SHapley Additive exPlanations (SHAP
values) are formulated as the only possible interpretation that offers a unique
solution for understanding the model. In this manuscript, the
additive-feature-attribution methods are presented, showing four common
implementations in the literature: kernel SHAP, tree SHAP, gradient SHAP, and
deep SHAP. Then, the main applications of the additive-feature-attribution
methods are introduced, dividing them into three main groups: turbulence
modeling, fluid-mechanics fundamentals, and applied problems in fluid dynamics
and heat transfer. This review shows thatexplainability techniques, and in
particular additive-feature-attribution methods, are crucial for implementing
interpretable and physics-compliant deep-learning models in the fluid-mechanics
field.

摘要：近年來，由於資料驅動方法能夠適應湍流的複雜且多尺度性質，以及偵測大規模模擬或實驗測試中的模式，因此在流體力學中使用資料驅動方法已大幅增加。為了詮釋訓練過程中模型中產生的關係，需要將數值歸因分配給輸入特徵。一個重要的範例是加法特徵歸因方法。這些可解釋性方法將輸入特徵與模型預測連結起來，並根據模型的線性公式提供詮釋。SHapley 加法解釋（SHAP 值）被公式化為唯一可能的詮釋，為理解模型提供獨特的解決方案。在這個手稿中，加法特徵歸因方法會呈現出來，展示文獻中四種常見的實作：核心 SHAP、樹狀 SHAP、梯度 SHAP 和深度 SHAP。然後，介紹加法特徵歸因方法的主要應用，將其分成三組：湍流建模、流體力學基礎，以及流體動力學和熱傳中的應用問題。此評論顯示可解釋性技術，特別是加法特徵歸因方法，對於在流體力學領域實作可解釋且符合物理的深度學習模型至關重要。

##### **Sampling Latent Material-Property Information From LLM-Derived Embedding Representations**
2409.11971v1 by Luke P. J. Gilligan, Matteo Cobelli, Hasan M. Sayeed, Taylor D. Sparks, Stefano Sanvito

Vector embeddings derived from large language models (LLMs) show promise in
capturing latent information from the literature. Interestingly, these can be
integrated into material embeddings, potentially useful for data-driven
predictions of materials properties. We investigate the extent to which
LLM-derived vectors capture the desired information and their potential to
provide insights into material properties without additional training. Our
findings indicate that, although LLMs can be used to generate representations
reflecting certain property information, extracting the embeddings requires
identifying the optimal contextual clues and appropriate comparators. Despite
this restriction, it appears that LLMs still have the potential to be useful in
generating meaningful materials-science representations.

摘要：從大型語言模型 (LLM) 衍生的向量嵌入顯示出從文獻中擷取潛在資訊的潛力。有趣的是，這些資訊可以整合到材料嵌入中，對於資料驅動的材料屬性預測可能很有用。我們探討 LLM 衍生向量擷取所需資訊的程度，以及它們在沒有額外訓練的情況下提供材料屬性見解的潛力。我們的研究結果表明，儘管 LLM 可用於產生反映特定屬性資訊的表示，但擷取嵌入需要找出最佳的脈絡線索和適當的比較器。儘管有此限制，但 LLM 似乎仍有潛力用於產生有意義的材料科學表示。

##### **Efficacy of Synthetic Data as a Benchmark**
2409.11968v1 by Gaurav Maheshwari, Dmitry Ivanov, Kevin El Haddad

Large language models (LLMs) have enabled a range of applications in
zero-shot and few-shot learning settings, including the generation of synthetic
datasets for training and testing. However, to reliably use these synthetic
datasets, it is essential to understand how representative they are of
real-world data. We investigate this by assessing the effectiveness of
generating synthetic data through LLM and using it as a benchmark for various
NLP tasks. Our experiments across six datasets, and three different tasks, show
that while synthetic data can effectively capture performance of various
methods for simpler tasks, such as intent classification, it falls short for
more complex tasks like named entity recognition. Additionally, we propose a
new metric called the bias factor, which evaluates the biases introduced when
the same LLM is used to both generate benchmarking data and to perform the
tasks. We find that smaller LLMs exhibit biases towards their own generated
data, whereas larger models do not. Overall, our findings suggest that the
effectiveness of synthetic data as a benchmark varies depending on the task,
and that practitioners should rely on data generated from multiple larger
models whenever possible.

摘要：大型語言模型 (LLM) 已在零次學習和少次學習設定中啟用了一系列應用程式，包括用於訓練和測試的合成資料集產生。但是，要可靠地使用這些合成資料集，了解它們在多大程度上代表真實世界資料至關重要。我們透過評估透過 LLM 產生合成資料的有效性並將其用作各種 NLP 任務的基準來調查這一點。我們在六個資料集和三個不同任務中的實驗表明，雖然合成資料可以有效地捕捉各種方法在較簡單任務（例如意圖分類）中的效能，但對於更複雜的任務（例如命名實體識別）則有所不足。此外，我們提出一個稱為偏差因子的新指標，用於評估在使用相同的 LLM 來產生基準資料和執行任務時引入的偏差。我們發現較小的 LLM 對其自己產生的資料表現出偏差，而較大的模型則沒有。總體而言，我們的研究結果表明，合成資料作為基準的有效性會根據任務而異，從業者應盡可能依賴從多個較大模型產生的資料。

##### **LLMs in Education: Novel Perspectives, Challenges, and Opportunities**
2409.11917v1 by Bashar Alhafni, Sowmya Vajjala, Stefano Bannò, Kaushal Kumar Maurya, Ekaterina Kochmar

The role of large language models (LLMs) in education is an increasing area
of interest today, considering the new opportunities they offer for teaching,
learning, and assessment. This cutting-edge tutorial provides an overview of
the educational applications of NLP and the impact that the recent advances in
LLMs have had on this field. We will discuss the key challenges and
opportunities presented by LLMs, grounding them in the context of four major
educational applications: reading, writing, and speaking skills, and
intelligent tutoring systems (ITS). This COLING 2025 tutorial is designed for
researchers and practitioners interested in the educational applications of NLP
and the role LLMs have to play in this area. It is the first of its kind to
address this timely topic.

摘要：大型語言模型 (LLM) 在教育中的角色是當前一個越來越受關注的領域，因為它們為教學、學習和評量提供了新的機會。這份尖端的教學指南提供了一個 NLP 教育應用程式的概觀，以及 LLM 最近的進展對此領域的影響。我們將討論 LLM 帶來的主要挑戰和機會，並將它們奠基於四個主要的教育應用程式脈絡中：閱讀、寫作和口說技能，以及智慧型教學系統 (ITS)。這份 COLING 2025 教學指南是為對 NLP 教育應用程式感興趣的研究人員和從業人員所設計的，以及 LLM 在此領域扮演的角色。這是第一份探討這個時事議題的同類型指南。

##### **AlignBot: Aligning VLM-powered Customized Task Planning with User Reminders Through Fine-Tuning for Household Robots**
2409.11905v1 by Zhaxizhuoma, Pengan Chen, Ziniu Wu, Jiawei Sun, Dong Wang, Peng Zhou, Nieqing Cao, Yan Ding, Bin Zhao, Xuelong Li

This paper presents AlignBot, a novel framework designed to optimize
VLM-powered customized task planning for household robots by effectively
aligning with user reminders. In domestic settings, aligning task planning with
user reminders poses significant challenges due to the limited quantity,
diversity, and multimodal nature of the reminders. To address these challenges,
AlignBot employs a fine-tuned LLaVA-7B model, functioning as an adapter for
GPT-4o. This adapter model internalizes diverse forms of user reminders-such as
personalized preferences, corrective guidance, and contextual assistance-into
structured instruction-formatted cues that prompt GPT-4o in generating
customized task plans. Additionally, AlignBot integrates a dynamic retrieval
mechanism that selects task-relevant historical successes as prompts for
GPT-4o, further enhancing task planning accuracy. To validate the effectiveness
of AlignBot, experiments are conducted in real-world household environments,
which are constructed within the laboratory to replicate typical household
settings. A multimodal dataset with over 1,500 entries derived from volunteer
reminders is used for training and evaluation. The results demonstrate that
AlignBot significantly improves customized task planning, outperforming
existing LLM- and VLM-powered planners by interpreting and aligning with user
reminders, achieving 86.8% success rate compared to the vanilla GPT-4o baseline
at 21.6%, reflecting a 65% improvement and over four times greater
effectiveness. Supplementary materials are available at:
https://yding25.com/AlignBot/

摘要：本文提出 AlignBot，這是一個新穎的框架，旨在透過有效地與使用者提醒相符，來最佳化大型語言模型 (VLM) 驅動的客製化任務規劃，以供家用機器人使用。在家庭環境中，將任務規劃與使用者提醒相符會造成重大挑戰，原因在於提醒的數量有限、多樣且具有多模態的性質。為了解決這些挑戰，AlignBot 採用微調過的 LLaVA-7B 模型，作為 GPT-4o 的適配器。這個適配器模型將使用者提醒的各種形式（例如個人化偏好、修正指導和情境協助）內化為結構化的指令格式提示，以提示 GPT-4o 產生客製化的任務計畫。此外，AlignBot 整合了一個動態檢索機制，它會選擇與任務相關的歷史成功經驗作為 GPT-4o 的提示，進一步提升任務規劃的準確度。為了驗證 AlignBot 的有效性，我們在現實世界的家庭環境中進行實驗，這些環境是在實驗室中建構的，以複製典型的家庭環境。我們使用一個多模態的資料集，其中包含來自志工提醒的 1,500 多個條目，用於訓練和評估。結果顯示，AlignBot 大幅改善了客製化的任務規劃，透過詮釋和與使用者提醒相符，其效能優於現有的 LLM 和 VLM 驅動的規劃器，成功率達到 86.8%，而香草 GPT-4o 基準則為 21.6%，顯示改善了 65%，且有效性提高了四倍以上。補充材料可於以下網址取得：https://yding25.com/AlignBot/

##### **Finding the Subjective Truth: Collecting 2 Million Votes for Comprehensive Gen-AI Model Evaluation**
2409.11904v1 by Dimitrios Christodoulou, Mads Kuhlmann-Jørgensen

Efficiently evaluating the performance of text-to-image models is difficult
as it inherently requires subjective judgment and human preference, making it
hard to compare different models and quantify the state of the art. Leveraging
Rapidata's technology, we present an efficient annotation framework that
sources human feedback from a diverse, global pool of annotators. Our study
collected over 2 million annotations across 4,512 images, evaluating four
prominent models (DALL-E 3, Flux.1, MidJourney, and Stable Diffusion) on style
preference, coherence, and text-to-image alignment. We demonstrate that our
approach makes it feasible to comprehensively rank image generation models
based on a vast pool of annotators and show that the diverse annotator
demographics reflect the world population, significantly decreasing the risk of
biases.

摘要：有效評估文字轉圖片模型的效能很困難，因為它本質上需要主觀判斷和人類偏好，這使得比較不同的模型和量化當前技術狀態變得困難。利用 Rapidata 的技術，我們提出了一個有效註解框架，從多元的全球註解者群中獲取人類回饋。我們的研究收集了超過 200 萬個對 4,512 張圖片的註解，評估了四個著名的模型（DALL-E 3、Flux.1、MidJourney 和 Stable Diffusion）在風格偏好、連貫性和文字轉圖片對齊方面的表現。我們證明了我們的做法可以根據大量的註解者全面排名圖片生成模型，並表明多元的註解者人口統計反映了世界人口，顯著降低了偏差風險。

##### **LLMs + Persona-Plug = Personalized LLMs**
2409.11901v1 by Jiongnan Liu, Yutao Zhu, Shuting Wang, Xiaochi Wei, Erxue Min, Yu Lu, Shuaiqiang Wang, Dawei Yin, Zhicheng Dou

Personalization plays a critical role in numerous language tasks and
applications, since users with the same requirements may prefer diverse outputs
based on their individual interests. This has led to the development of various
personalized approaches aimed at adapting large language models (LLMs) to
generate customized outputs aligned with user preferences. Some of them involve
fine-tuning a unique personalized LLM for each user, which is too expensive for
widespread application. Alternative approaches introduce personalization
information in a plug-and-play manner by retrieving the user's relevant
historical texts as demonstrations. However, this retrieval-based strategy may
break the continuity of the user history and fail to capture the user's overall
styles and patterns, hence leading to sub-optimal performance. To address these
challenges, we propose a novel personalized LLM model, \ours{}. It constructs a
user-specific embedding for each individual by modeling all her historical
contexts through a lightweight plug-in user embedder module. By attaching this
embedding to the task input, LLMs can better understand and capture user habits
and preferences, thereby producing more personalized outputs without tuning
their own parameters. Extensive experiments on various tasks in the language
model personalization (LaMP) benchmark demonstrate that the proposed model
significantly outperforms existing personalized LLM approaches.

摘要：個人化在眾多語言任務和應用中扮演著至關重要的角色，因為具有相同需求的使用者可能會基於其個人興趣而偏好不同的輸出。這促成了各種個人化方法的發展，旨在調整大型語言模型 (LLM)，以產生符合使用者偏好的自訂輸出。其中一些方法涉及針對每位使用者微調一個獨特的個人化 LLM，這對於廣泛應用來說過於昂貴。替代方法以即插即用的方式引入個人化資訊，透過擷取使用者的相關歷史文字作為示範。然而，這種基於擷取的策略可能會中斷使用者歷史的連續性，並且無法捕捉使用者的整體風格和模式，因此導致次佳效能。為了應對這些挑戰，我們提出了一種新穎的個人化 LLM 模型，\ours{}。它透過一個輕量級的插入式使用者嵌入模組，透過建模所有她的歷史脈絡，為每個個體建構一個使用者特定的嵌入。透過將此嵌入附加到任務輸入，LLM 可以更好地理解和捕捉使用者的習慣和偏好，從而產生更多個人化的輸出，而無需調整其自身的參數。在語言模型個人化 (LaMP) 基準中的各種任務上進行的廣泛實驗證明，所提出的模型顯著優於現有的個人化 LLM 方法。

##### **DocMamba: Efficient Document Pre-training with State Space Model**
2409.11887v1 by Pengfei Hu, Zhenrong Zhang, Jiefeng Ma, Shuhang Liu, Jun Du, Jianshu Zhang

In recent years, visually-rich document understanding has attracted
increasing attention. Transformer-based pre-trained models have become the
mainstream approach, yielding significant performance gains in this field.
However, the self-attention mechanism's quadratic computational complexity
hinders their efficiency and ability to process long documents. In this paper,
we present DocMamba, a novel framework based on the state space model. It is
designed to reduce computational complexity to linear while preserving global
modeling capabilities. To further enhance its effectiveness in document
processing, we introduce the Segment-First Bidirectional Scan (SFBS) to capture
contiguous semantic information. Experimental results demonstrate that DocMamba
achieves new state-of-the-art results on downstream datasets such as FUNSD,
CORD, and SORIE, while significantly improving speed and reducing memory usage.
Notably, experiments on the HRDoc confirm DocMamba's potential for length
extrapolation. The code will be available online.

摘要：近年來，視覺豐富的文件理解已引起越來越多的關注。基於 Transformer 的預訓練模型已成為主流方法，在該領域產生顯著的效能提升。然而，自注意力機制的二次計算複雜度會阻礙其處理長文件的效率和能力。在本文中，我們提出 DocMamba，一個基於狀態空間模型的新穎框架。它被設計為在保留全局建模能力的同時，將計算複雜度降低為線性。為了進一步提升其在文件處理中的效能，我們引入了片段優先雙向掃描 (SFBS) 來擷取連續的語義資訊。實驗結果證明，DocMamba 在下游資料集（例如 FUNSD、CORD 和 SORIE）上達到了新的最先進結果，同時顯著提升了速度並減少了記憶體使用量。值得注意的是，在 HRDoc 上的實驗證實了 DocMamba 在長度外推方面的潛力。程式碼將在線上提供。

##### **Learning Task Planning from Multi-Modal Demonstration for Multi-Stage Contact-Rich Manipulation**
2409.11863v1 by Kejia Chen, Zheng Shen, Yue Zhang, Lingyun Chen, Fan Wu, Zhenshan Bing, Sami Haddadin, Alois Knoll

Large Language Models (LLMs) have gained popularity in task planning for
long-horizon manipulation tasks. To enhance the validity of LLM-generated
plans, visual demonstrations and online videos have been widely employed to
guide the planning process. However, for manipulation tasks involving subtle
movements but rich contact interactions, visual perception alone may be
insufficient for the LLM to fully interpret the demonstration. Additionally,
visual data provides limited information on force-related parameters and
conditions, which are crucial for effective execution on real robots.
  In this paper, we introduce an in-context learning framework that
incorporates tactile and force-torque information from human demonstrations to
enhance LLMs' ability to generate plans for new task scenarios. We propose a
bootstrapped reasoning pipeline that sequentially integrates each modality into
a comprehensive task plan. This task plan is then used as a reference for
planning in new task configurations. Real-world experiments on two different
sequential manipulation tasks demonstrate the effectiveness of our framework in
improving LLMs' understanding of multi-modal demonstrations and enhancing the
overall planning performance.

摘要：大型語言模型（LLM）在長期操作任務的任務規劃中獲得普及。為了增強 LLM 生成的計畫的有效性，視覺示範和線上影片已被廣泛用於指導規劃過程。然而，對於涉及細微動作但豐富接觸互動的操作任務，僅靠視覺感知可能不足以讓 LLM 充分解讀示範。此外，視覺資料提供與力相關的參數和條件的資訊有限，這些資訊對於在真實機器人上有效執行至關重要。
  在本文中，我們介紹了一個情境學習架構，該架構整合了人類示範的觸覺和力矩資訊，以增強 LLM 為新任務情境生成計畫的能力。我們提出了一個自舉推理管道，將每個模態依序整合到一個綜合任務計畫中。然後將此任務計畫用作在新的任務配置中規劃的參考。在兩個不同的順序操作任務上的真實世界實驗證明了我們的架構在改善 LLM 對多模式示範的理解和增強整體規劃效能方面的有效性。

##### **Retrieve, Annotate, Evaluate, Repeat: Leveraging Multimodal LLMs for Large-Scale Product Retrieval Evaluation**
2409.11860v1 by Kasra Hosseini, Thomas Kober, Josip Krapac, Roland Vollgraf, Weiwei Cheng, Ana Peleteiro Ramallo

Evaluating production-level retrieval systems at scale is a crucial yet
challenging task due to the limited availability of a large pool of
well-trained human annotators. Large Language Models (LLMs) have the potential
to address this scaling issue and offer a viable alternative to humans for the
bulk of annotation tasks. In this paper, we propose a framework for assessing
the product search engines in a large-scale e-commerce setting, leveraging
Multimodal LLMs for (i) generating tailored annotation guidelines for
individual queries, and (ii) conducting the subsequent annotation task. Our
method, validated through deployment on a large e-commerce platform,
demonstrates comparable quality to human annotations, significantly reduces
time and cost, facilitates rapid problem discovery, and provides an effective
solution for production-level quality control at scale.

摘要：評估生產級檢索系統的規模是一項至關重要的任務，但由於缺乏大量訓練有素的人類註解員，這是一項具有挑戰性的任務。大型語言模型 (LLM) 有可能解決這個擴充問題，並為大部分註解任務提供一個可行的替代方案。在本文中，我們提出了一個框架，用於評估大型電子商務環境中的產品搜尋引擎，利用多模態 LLM 進行：(i) 為個別查詢生成客製化的註解指南，以及 (ii) 執行後續的註解任務。我們的這項方法已通過在大型電子商務平台上部署進行驗證，證明其品質與人類註解相當，大幅減少時間和成本，促進快速問題發現，並提供一個有效的解決方案，用於規模化的生產級品質控管。

##### **MEOW: MEMOry Supervised LLM Unlearning Via Inverted Facts**
2409.11844v1 by Tianle Gu, Kexin Huang, Ruilin Luo, Yuanqi Yao, Yujiu Yang, Yan Teng, Yingchun Wang

Large Language Models (LLMs) can memorize sensitive information, raising
concerns about potential misuse. LLM Unlearning, a post-hoc approach to remove
this information from trained LLMs, offers a promising solution to mitigate
these risks. However, previous practices face three key challenges: 1. Utility:
successful unlearning often causes catastrophic collapse on unrelated tasks. 2.
Efficiency: many methods either involve adding similarly sized models, which
slows down unlearning or inference, or require retain data that are difficult
to obtain. 3. Robustness: even effective methods may still leak data via
extraction techniques. To address these challenges, we propose MEOW, a simple
yet effective gradient descent-based unlearning method. Specifically, we use an
offline LLM to generate a set of inverted facts. Then, we design a new metric,
MEMO, to quantify memorization in LLMs. Finally, based on the signals provided
by MEMO, we select the most appropriate set of inverted facts and finetune the
model based on them. We evaluate MEOW on the commonly used unlearn benchmark,
ToFU, with Llama2-7B-Chat and Phi-1.5B, and test it on both NLU and NLG tasks.
Results demonstrate significant improvement of MEOW in forget quality without
substantial loss in model utility. Meanwhile, MEOW does not exhibit significant
degradation in NLU or NLG capabilities, and there is even a slight improvement
in NLU performance.

摘要：大型語言模型 (LLM) 可以記住敏感資訊，這引起了人們對潛在誤用的擔憂。LLM 遺忘是一種事後方法，用於從訓練過的 LLM 中移除這些資訊，這提供了一個有希望的解決方案來減輕這些風險。然而，先前的做法面臨三個關鍵挑戰：1. 實用性：成功的遺忘通常會導致與任務無關的災難性崩潰。2. 效率：許多方法都涉及新增相似大小的模型，這會減慢遺忘或推理速度，或者需要保留難以取得的資料。3. 穩健性：即使是有效的方法，也可能透過萃取技術洩漏資料。為了應對這些挑戰，我們提出了 MEOW，一種簡單但有效的基於梯度下降的遺忘方法。具體來說，我們使用離線 LLM 來產生一組反向事實。然後，我們設計了一個新的指標 MEMO，用於量化 LLM 中的記憶。最後，根據 MEMO 提供的信號，我們選擇最合適的反向事實集，並根據它們微調模型。我們在常用的遺忘基準 ToFU 上評估了 MEOW，其中包含 Llama2-7B-Chat 和 Phi-1.5B，並在 NLU 和 NLG 任務上對其進行了測試。結果表明，MEOW 在遺忘品質上有了顯著的提升，而模型實用性沒有顯著下降。同時，MEOW 在 NLU 或 NLG 能力上沒有表現出顯著的下降，甚至在 NLU 性能上還略有提升。

##### **DPI-TTS: Directional Patch Interaction for Fast-Converging and Style Temporal Modeling in Text-to-Speech**
2409.11835v1 by Xin Qi, Ruibo Fu, Zhengqi Wen, Tao Wang, Chunyu Qiang, Jianhua Tao, Chenxing Li, Yi Lu, Shuchen Shi, Zhiyong Wang, Xiaopeng Wang, Yuankun Xie, Yukun Liu, Xuefei Liu, Guanjun Li

In recent years, speech diffusion models have advanced rapidly. Alongside the
widely used U-Net architecture, transformer-based models such as the Diffusion
Transformer (DiT) have also gained attention. However, current DiT speech
models treat Mel spectrograms as general images, which overlooks the specific
acoustic properties of speech. To address these limitations, we propose a
method called Directional Patch Interaction for Text-to-Speech (DPI-TTS), which
builds on DiT and achieves fast training without compromising accuracy.
Notably, DPI-TTS employs a low-to-high frequency, frame-by-frame progressive
inference approach that aligns more closely with acoustic properties, enhancing
the naturalness of the generated speech. Additionally, we introduce a
fine-grained style temporal modeling method that further improves speaker style
similarity. Experimental results demonstrate that our method increases the
training speed by nearly 2 times and significantly outperforms the baseline
models.

摘要：近年來，語音擴散模型進步神速。除了廣泛使用的 U-Net 架構外，基於 Transformer 的模型，例如 Diffusion Transformer (DiT)，也備受關注。然而，目前的 DiT 語音模型將 Mel 譜圖視為一般影像，忽略了語音的特定聲學特性。為了解決這些限制，我們提出了一種稱為文字轉語音方向性區塊互動 (DPI-TTS) 的方法，它建立在 DiT 的基礎上，並在不損害準確性的情況下實現快速訓練。值得注意的是，DPI-TTS 採用低頻到高頻、逐幀遞進式推論方法，更符合聲學特性，增強了生成語音的自然度。此外，我們引入了一種細粒度風格時間建模方法，進一步改善了說話者風格的相似性。實驗結果表明，我們的模型將訓練速度提高了近 2 倍，並顯著優於基線模型。

##### **Extract-and-Abstract: Unifying Extractive and Abstractive Summarization within Single Encoder-Decoder Framework**
2409.11827v1 by Yuping Wu, Hao Li, Hongbo Zhu, Goran Nenadic, Xiao-Jun Zeng

Extract-then-Abstract is a naturally coherent paradigm to conduct abstractive
summarization with the help of salient information identified by the extractive
model. Previous works that adopt this paradigm train the extractor and
abstractor separately and introduce extra parameters to highlight the extracted
salients to the abstractor, which results in error accumulation and additional
training costs. In this paper, we first introduce a parameter-free highlight
method into the encoder-decoder framework: replacing the encoder attention mask
with a saliency mask in the cross-attention module to force the decoder to
focus only on salient parts of the input. A preliminary analysis compares
different highlight methods, demonstrating the effectiveness of our saliency
mask. We further propose the novel extract-and-abstract paradigm, ExtAbs, which
jointly and seamlessly performs Extractive and Abstractive summarization tasks
within single encoder-decoder model to reduce error accumulation. In ExtAbs,
the vanilla encoder is augmented to extract salients, and the vanilla decoder
is modified with the proposed saliency mask to generate summaries. Built upon
BART and PEGASUS, experiments on three datasets show that ExtAbs can achieve
superior performance than baselines on the extractive task and performs
comparable, or even better than the vanilla models on the abstractive task.

摘要：抽取再摘要是一種自然連貫的範例，可用於在抽取模型識別的顯著資訊的幫助下執行摘要摘要。採用此範例的前人工作會分別訓練抽取器和摘要器，並引入額外參數以突顯抽取的顯著資訊給摘要器，這會導致錯誤累積和額外的訓練成本。在本文中，我們首先將無參數突顯方法引入編碼器-解碼器架構：在交叉注意力模組中用顯著性遮罩取代編碼器注意力遮罩，以強制解碼器僅關注輸入的顯著部分。初步分析比較了不同的突顯方法，證明了我們的顯著性遮罩的有效性。我們進一步提出了新穎的抽取和摘要範例 ExtAbs，它在單一編碼器-解碼器模型中聯合且無縫地執行抽取和摘要摘要任務，以減少錯誤累積。在 ExtAbs 中，香草編碼器被擴充以抽取顯著資訊，而香草解碼器則使用建議的顯著性遮罩進行修改以產生摘要。在 BART 和 PEGASUS 的基礎上，對三個資料集的實驗表明，ExtAbs 在抽取任務上可以達到比基準更好的效能，並且在摘要任務上表現得與香草模型相當，甚至更好。

##### **Optimizing Job Shop Scheduling in the Furniture Industry: A Reinforcement Learning Approach Considering Machine Setup, Batch Variability, and Intralogistics**
2409.11820v1 by Malte Schneevogt, Karsten Binninger, Noah Klarmann

This paper explores the potential application of Deep Reinforcement Learning
in the furniture industry. To offer a broad product portfolio, most furniture
manufacturers are organized as a job shop, which ultimately results in the Job
Shop Scheduling Problem (JSSP). The JSSP is addressed with a focus on extending
traditional models to better represent the complexities of real-world
production environments. Existing approaches frequently fail to consider
critical factors such as machine setup times or varying batch sizes. A concept
for a model is proposed that provides a higher level of information detail to
enhance scheduling accuracy and efficiency. The concept introduces the
integration of DRL for production planning, particularly suited to batch
production industries such as the furniture industry. The model extends
traditional approaches to JSSPs by including job volumes, buffer management,
transportation times, and machine setup times. This enables more precise
forecasting and analysis of production flows and processes, accommodating the
variability and complexity inherent in real-world manufacturing processes. The
RL agent learns to optimize scheduling decisions. It operates within a discrete
action space, making decisions based on detailed observations. A reward
function guides the agent's decision-making process, thereby promoting
efficient scheduling and meeting production deadlines. Two integration
strategies for implementing the RL agent are discussed: episodic planning,
which is suitable for low-automation environments, and continuous planning,
which is ideal for highly automated plants. While episodic planning can be
employed as a standalone solution, the continuous planning approach
necessitates the integration of the agent with ERP and Manufacturing Execution
Systems. This integration enables real-time adjustments to production schedules
based on dynamic changes.

摘要：本文探討深度強化學習在家具產業的潛在應用。為了提供廣泛的產品組合，大多數家具製造商都以工作坊的形式組織，這最終導致工作坊排程問題 (JSSP)。JSSP 的重點在於擴充傳統模型，以更好地呈現現實世界生產環境的複雜性。現有方法經常無法考量關鍵因素，例如機器設定時間或不同的批次大小。本文提出一個模型概念，提供更高層級的資訊細節，以提升排程的準確性和效率。這個概念引入了 DRL 整合，用於生產規劃，特別適用於批次生產產業，例如家具產業。此模型透過納入工作量、緩衝管理、運輸時間和機器設定時間，擴充了 JSSP 的傳統方法。這能更精確地預測和分析生產流程，並適應現實世界製造流程中固有的變異性和複雜性。RL 代理程式會學習最佳化排程決策。它在一個離散動作空間中運作，根據詳細的觀察進行決策。一個獎勵函數引導代理程式的決策過程，進而促進有效的排程並滿足生產期限。本文討論了實作 RL 代理程式的兩個整合策略：適合低自動化環境的分段規劃，以及適用於高度自動化工廠的連續規劃。雖然分段規劃可以用作獨立的解決方案，但連續規劃方法需要將代理程式與 ERP 和製造執行系統整合。這種整合讓生產排程能夠根據動態變化進行即時調整。

##### **EFCM: Efficient Fine-tuning on Compressed Models for deployment of large models in medical image analysis**
2409.11817v1 by Shaojie Li, Zhaoshuo Diao

The recent development of deep learning large models in medicine shows
remarkable performance in medical image analysis and diagnosis, but their large
number of parameters causes memory and inference latency challenges. Knowledge
distillation offers a solution, but the slide-level gradients cannot be
backpropagated for student model updates due to high-resolution pathological
images and slide-level labels. This study presents an Efficient Fine-tuning on
Compressed Models (EFCM) framework with two stages: unsupervised feature
distillation and fine-tuning. In the distillation stage, Feature Projection
Distillation (FPD) is proposed with a TransScan module for adaptive receptive
field adjustment to enhance the knowledge absorption capability of the student
model. In the slide-level fine-tuning stage, three strategies (Reuse CLAM,
Retrain CLAM, and End2end Train CLAM (ETC)) are compared. Experiments are
conducted on 11 downstream datasets related to three large medical models:
RETFound for retina, MRM for chest X-ray, and BROW for histopathology. The
experimental results demonstrate that the EFCM framework significantly improves
accuracy and efficiency in handling slide-level pathological image problems,
effectively addressing the challenges of deploying large medical models.
Specifically, it achieves a 4.33% increase in ACC and a 5.2% increase in AUC
compared to the large model BROW on the TCGA-NSCLC and TCGA-BRCA datasets. The
analysis of model inference efficiency highlights the high efficiency of the
distillation fine-tuning method.

摘要：<paragraph>最近在醫學領域中深度學習大型模型的發展，在醫學影像分析和診斷方面展現了卓越的表現，但其龐大的參數量卻導致記憶體和推論延遲的挑戰。知識蒸餾提供了一種解決方案，但由於高解析度的病理影像和幻燈片層級標籤，幻燈片層級的梯度無法反向傳播以更新學生模型。本研究提出了一個壓縮模型的有效微調 (EFCM) 架構，包含兩個階段：無監督特徵蒸餾和微調。在蒸餾階段，提出特徵投影蒸餾 (FPD) 與 TransScan 模組，以進行適應性感受野調整，以增強學生模型的知識吸收能力。在幻燈片層級微調階段，比較了三種策略（重複使用 CLAM、重新訓練 CLAM 和端對端訓練 CLAM (ETC)）。針對與三個大型醫學模型相關的 11 個下游資料集進行了實驗：針對視網膜的 RETFound、針對胸部 X 光的 MRM 和針對組織病理學的 BROW。實驗結果表明，EFCM 架構顯著提升了處理幻燈片層級病理影像問題的準確性和效率，有效應對了部署大型醫學模型的挑戰。具體來說，與大型模型 BROW 相比，它在 TCGA-NSCLC 和 TCGA-BRCA 資料集上分別提升了 4.33% 的 ACC 和 5.2% 的 AUC。模型推論效率的分析突出了蒸餾微調方法的高效率。</paragraph>

##### **EventAug: Multifaceted Spatio-Temporal Data Augmentation Methods for Event-based Learning**
2409.11813v1 by Yukun Tian, Hao Chen, Yongjian Deng, Feihong Shen, Kepan Liu, Wei You, Ziyang Zhang

The event camera has demonstrated significant success across a wide range of
areas due to its low time latency and high dynamic range. However, the
community faces challenges such as data deficiency and limited diversity, often
resulting in over-fitting and inadequate feature learning. Notably, the
exploration of data augmentation techniques in the event community remains
scarce. This work aims to address this gap by introducing a systematic
augmentation scheme named EventAug to enrich spatial-temporal diversity. In
particular, we first propose Multi-scale Temporal Integration (MSTI) to
diversify the motion speed of objects, then introduce Spatial-salient Event
Mask (SSEM) and Temporal-salient Event Mask (TSEM) to enrich object variants.
Our EventAug can facilitate models learning with richer motion patterns, object
variants and local spatio-temporal relations, thus improving model robustness
to varied moving speeds, occlusions, and action disruptions. Experiment results
show that our augmentation method consistently yields significant improvements
across different tasks and backbones (e.g., a 4.87% accuracy gain on DVS128
Gesture). Our code will be publicly available for this community.

摘要：事件相机因其低时间延迟和高动态范围而在广泛的领域展示出显著的成功。然而，该社区面临着数据不足和多样性受限等挑战，通常会导致过度拟合和特征学习不足。值得注意的是，在事件社区中探索数据增强技术仍然很少。这项工作旨在通过引入一个名为 EventAug 的系统增强方案来解决这一差距，以丰富时空多样性。具体来说，我们首先提出多尺度时间积分（MSTI）来使物体运动速度多样化，然后引入空间显著事件掩码（SSEM）和时间显著事件掩码（TSEM）来丰富物体变体。我们的 EventAug 可以促进模型学习具有更丰富的运动模式、物体变体和局部时空关系，从而提高模型对不同移动速度、遮挡和动作中断的鲁棒性。实验结果表明，我们的增强方法在不同的任务和骨干网络（例如，DVS128 手势上的 4.87% 精度提升）中始终产生显著的改进。我们的代码将为该社区公开。

##### **Latent fingerprint enhancement for accurate minutiae detection**
2409.11802v1 by Abdul Wahab, Tariq Mahmood Khan, Shahzaib Iqbal, Bandar AlShammari, Bandar Alhaqbani, Imran Razzak

Identification of suspects based on partial and smudged fingerprints,
commonly referred to as fingermarks or latent fingerprints, presents a
significant challenge in the field of fingerprint recognition. Although
fixed-length embeddings have shown effectiveness in recognising rolled and slap
fingerprints, the methods for matching latent fingerprints have primarily
centred around local minutiae-based embeddings, failing to fully exploit global
representations for matching purposes. Consequently, enhancing latent
fingerprints becomes critical to ensuring robust identification for forensic
investigations. Current approaches often prioritise restoring ridge patterns,
overlooking the fine-macroeconomic details crucial for accurate fingerprint
recognition. To address this, we propose a novel approach that uses generative
adversary networks (GANs) to redefine Latent Fingerprint Enhancement (LFE)
through a structured approach to fingerprint generation. By directly optimising
the minutiae information during the generation process, the model produces
enhanced latent fingerprints that exhibit exceptional fidelity to ground-truth
instances. This leads to a significant improvement in identification
performance. Our framework integrates minutiae locations and orientation
fields, ensuring the preservation of both local and structural fingerprint
features. Extensive evaluations conducted on two publicly available datasets
demonstrate our method's dominance over existing state-of-the-art techniques,
highlighting its potential to significantly enhance latent fingerprint
recognition accuracy in forensic applications.

摘要：基於部分且模糊的指紋（通常稱為指紋或潛伏指紋）來識別嫌犯，在指紋辨識領域中是一項重大挑戰。儘管固定長度的嵌入在辨識滾動和拍擊指紋方面已展現出效能，但用於比對潛伏指紋的方法主要集中於基於局部微特徵的嵌入，未能充分利用全局表徵進行比對。因此，增強潛伏指紋對於確保鑑識調查中的可靠識別至關重要。目前的做法通常優先還原脊線圖案，忽略了對準確指紋辨識至關重要的細微巨觀特徵。為了解決這個問題，我們提出了一種創新的方法，它使用生成對抗網路 (GAN) 透過結構化的指紋生成方法重新定義潛伏指紋增強 (LFE)。透過在生成過程中直接最佳化微特徵資訊，模型產生增強的潛伏指紋，展現出對真實個體的非凡保真度。這顯著改善了識別效能。我們的架構整合了微特徵位置和方向場，確保保留局部和結構性指紋特徵。在兩個公開可用的資料集上進行的廣泛評估，證明了我們的方法優於現有的最先進技術，突顯了其在鑑識應用中顯著提升潛伏指紋辨識精確度的潛力。

##### **The Factuality of Large Language Models in the Legal Domain**
2409.11798v1 by Rajaa El Hamdani, Thomas Bonald, Fragkiskos Malliaros, Nils Holzenberger, Fabian Suchanek

This paper investigates the factuality of large language models (LLMs) as
knowledge bases in the legal domain, in a realistic usage scenario: we allow
for acceptable variations in the answer, and let the model abstain from
answering when uncertain. First, we design a dataset of diverse factual
questions about case law and legislation. We then use the dataset to evaluate
several LLMs under different evaluation methods, including exact, alias, and
fuzzy matching. Our results show that the performance improves significantly
under the alias and fuzzy matching methods. Further, we explore the impact of
abstaining and in-context examples, finding that both strategies enhance
precision. Finally, we demonstrate that additional pre-training on legal
documents, as seen with SaulLM, further improves factual precision from 63% to
81%.

摘要：這篇論文研究了在法律領域中，大型語言模型 (LLM) 作為知識庫的真實性，並在一個實際的使用情境中進行：我們允許答案有可接受的變化，並讓模型在不確定時避免回答。首先，我們設計了一個關於案例法和立法的多元事實問題的資料集。然後，我們使用該資料集在不同的評估方法下評估多個 LLM，包括完全匹配、別名匹配和模糊匹配。我們的結果顯示，在別名匹配和模糊匹配方法下，效能顯著提升。此外，我們探討了避免回答和語境範例的影響，發現這兩種策略都能提高精準度。最後，我們證明了在法律文件中進行額外的預訓練，例如 SaulLM，進一步將事實精準度從 63% 提升至 81%。

##### **Efficient Low-Resolution Face Recognition via Bridge Distillation**
2409.11786v1 by Shiming Ge, Shengwei Zhao, Chenyu Li, Yu Zhang, Jia Li

Face recognition in the wild is now advancing towards light-weight models,
fast inference speed and resolution-adapted capability. In this paper, we
propose a bridge distillation approach to turn a complex face model pretrained
on private high-resolution faces into a light-weight one for low-resolution
face recognition. In our approach, such a cross-dataset resolution-adapted
knowledge transfer problem is solved via two-step distillation. In the first
step, we conduct cross-dataset distillation to transfer the prior knowledge
from private high-resolution faces to public high-resolution faces and generate
compact and discriminative features. In the second step, the resolution-adapted
distillation is conducted to further transfer the prior knowledge to synthetic
low-resolution faces via multi-task learning. By learning low-resolution face
representations and mimicking the adapted high-resolution knowledge, a
light-weight student model can be constructed with high efficiency and
promising accuracy in recognizing low-resolution faces. Experimental results
show that the student model performs impressively in recognizing low-resolution
faces with only 0.21M parameters and 0.057MB memory. Meanwhile, its speed
reaches up to 14,705, ~934 and 763 faces per second on GPU, CPU and mobile
phone, respectively.

摘要：人臉辨識現在朝向輕量級模型、快速的推論速度和適應解析度的能力邁進。在本文中，我們提出一個橋樑蒸餾方法，將一個複雜的人臉模型預先訓練在私人高解析度人臉上，轉換成一個低解析度人臉辨識的輕量級模型。在我們的做法中，這種跨資料集適應解析度的知識轉移問題透過兩階段蒸餾來解決。在第一階段，我們進行跨資料集蒸餾，將先驗知識從私人高解析度人臉轉移到公開高解析度人臉，並產生緊湊且具區別性的特徵。在第二階段，進行適應解析度的蒸餾，以透過多任務學習進一步將先驗知識轉移到合成低解析度人臉。透過學習低解析度人臉表示和模擬適應的高解析度知識，可以建構一個輕量級的學生模型，在辨識低解析度人臉時具有高效率和良好的準確度。實驗結果顯示，學生模型在辨識低解析度人臉時表現出色，只有 0.21M 參數和 0.057MB 記憶體。同時，它的速度分別在 GPU、CPU 和手機上達到每秒 14,705、~934 和 763 張人臉。

##### **Distilling Channels for Efficient Deep Tracking**
2409.11785v1 by Shiming Ge, Zhao Luo, Chunhui Zhang, Yingying Hua, Dacheng Tao

Deep trackers have proven success in visual tracking. Typically, these
trackers employ optimally pre-trained deep networks to represent all diverse
objects with multi-channel features from some fixed layers. The deep networks
employed are usually trained to extract rich knowledge from massive data used
in object classification and so they are capable to represent generic objects
very well. However, these networks are too complex to represent a specific
moving object, leading to poor generalization as well as high computational and
memory costs. This paper presents a novel and general framework termed channel
distillation to facilitate deep trackers. To validate the effectiveness of
channel distillation, we take discriminative correlation filter (DCF) and ECO
for example. We demonstrate that an integrated formulation can turn feature
compression, response map generation, and model update into a unified energy
minimization problem to adaptively select informative feature channels that
improve the efficacy of tracking moving objects on the fly. Channel
distillation can accurately extract good channels, alleviating the influence of
noisy channels and generally reducing the number of channels, as well as
adaptively generalizing to different channels and networks. The resulting deep
tracker is accurate, fast, and has low memory requirements. Extensive
experimental evaluations on popular benchmarks clearly demonstrate the
effectiveness and generalizability of our framework.

摘要：深度追踪器在视觉追踪中已获证实成功。通常，这些追踪器使用经过最佳预训练的深度网络来表示所有不同的对象，并从某些固定层中提取多通道特征。所采用的深度网络通常经过训练，从用于对象分类的大量数据中提取丰富的知识，因此它们能够很好地表示通用对象。然而，这些网络过于复杂，无法表示特定的移动对象，从而导致泛化能力差以及高计算和内存成本。本文提出了一种新颖且通用的框架，称为通道蒸馏，以促进深度追踪器。为了验证通道蒸馏的有效性，我们以判别相关滤波器 (DCF) 和 ECO 为例。我们证明了一个集成公式可以将特征压缩、响应图生成和模型更新转化为一个统一的能量最小化问题，以自适应地选择信息丰富的特征通道，从而提高对移动对象的追踪效率。通道蒸馏可以准确地提取良好的通道，减轻噪声通道的影响，并通常减少通道的数量，以及自适应地推广到不同的通道和网络。由此产生的深度追踪器准确、快速且内存需求低。在流行基准上的广泛实验评估清楚地证明了我们框架的有效性和通用性。

##### **Development and bilingual evaluation of Japanese medical large language model within reasonably low computational resources**
2409.11783v2 by Issey Sukeda

The recent success of large language models (LLMs) and the scaling law has
led to a widespread adoption of larger models. Particularly in the healthcare
industry, there is an increasing demand for locally operated LLMs due to
security concerns. However, the majority of high quality open-source LLMs have
a size of 70B parameters, imposing significant financial burdens on users for
GPU preparation and operation. To overcome these issues, we present a medical
adaptation based on the recent 7B models, which enables the operation in low
computational resources. We compare the performance on medical
question-answering benchmarks in two languages (Japanese and English),
demonstrating that its scores reach parity with or surpass those of currently
existing medical LLMs that are ten times larger. We find that fine-tuning an
English-centric base model on Japanese medical dataset improves the score in
both language, supporting the effect of cross-lingual knowledge transfer. We
hope that this study will alleviate financial challenges, serving as a stepping
stone for clinical institutions to practically utilize LLMs locally. Our
evaluation code is available at
https://github.com/stardust-coder/japanese-lm-med-harness.

摘要：近期大型語言模型（LLM）和規模定律的成功，導致了較大型模型的廣泛採用。特別是在醫療保健產業，由於安全性考量，對在地運作的 LLM 需求日益增加。然而，大多數高品質的開源 LLM 擁有 70B 的參數規模，對使用者的 GPU 準備和操作造成顯著的財務負擔。為了克服這些問題，我們提出了基於近期 7B 模型的醫療適應，這使得在低運算資源中進行操作成為可能。我們比較了兩種語言（日文和英文）的醫療問答基準的效能，證明其分數達到或超越目前現有醫療 LLM 的十倍。我們發現針對日文醫療資料集微調以英文為中心的基礎模型，改善了兩種語言的分數，支持跨語言知識轉移的效果。我們希望這項研究將減輕財務挑戰，作為臨床機構在當地實際使用 LLM 的踏腳石。我們的評估代碼可在 https://github.com/stardust-coder/japanese-lm-med-harness 取得。

##### **Smart Data-Driven GRU Predictor for SnO$_2$ Thin films Characteristics**
2409.11782v1 by Faiza Bouamra, Mohamed Sayah, Labib Sadek Terrissa, Noureddine Zerhouni

In material physics, characterization techniques are foremost crucial for
obtaining the materials data regarding the physical properties as well as
structural, electronics, magnetic, optic, dielectric, and spectroscopic
characteristics. However, for many materials, ensuring availability and safe
accessibility is not always easy and fully warranted. Moreover, the use of
modeling and simulation techniques need a lot of theoretical knowledge, in
addition of being associated to costly computation time and a great complexity
deal. Thus, analyzing materials with different techniques for multiple samples
simultaneously, still be very challenging for engineers and researchers. It is
worth noting that although of being very risky, X-ray diffraction is the well
known and widely used characterization technique which gathers data from
structural properties of crystalline 1d, 2d or 3d materials. We propose in this
paper, a Smart GRU for Gated Recurrent Unit model to forcast structural
characteristics or properties of thin films of tin oxide SnO$_2$(110). Indeed,
thin films samples are elaborated and managed experimentally and the collected
data dictionary is then used to generate an AI -- Artificial Intelligence --
GRU model for the thin films of tin oxide SnO$_2$(110) structural property
characterization.

摘要：在材料物理中，表徵技術對於取得關於物理特性，以及結構、電子、磁性、光學、電介質和光譜特性的材料資料至關重要。然而，對於許多材料而言，確保取得和安全取得並不總是容易且完全有保障的。此外，使用建模和模擬技術需要大量的理論知識，除了與昂貴的運算時間和大量的複雜性相關。因此，同時使用不同的技術分析多個樣本的材料，對工程師和研究人員來說仍然非常具有挑戰性。值得注意的是，儘管非常有風險，X 射線繞射是一種眾所周知且廣泛使用的表徵技術，它從結晶 1d、2d 或 3d 材料的結構特性中收集資料。我們在這篇論文中提出了一個智慧型 GRU，用於門控遞迴單元模型，以預測氧化錫 SnO$_2$(110) 薄膜的結構特性或性質。事實上，薄膜樣品經過實驗製作和管理，然後使用收集的資料字典為氧化錫 SnO$_2$(110) 薄膜的結構特性表徵產生一個 AI -- 人工智慧 -- GRU 模型。

##### **Explaining Non-monotonic Normative Reasoning using Argumentation Theory with Deontic Logic**
2409.11780v1 by Zhe Yu, Yiwei Lu

In our previous research, we provided a reasoning system (called LeSAC) based
on argumentation theory to provide legal support to designers during the design
process. Building on this, this paper explores how to provide designers with
effective explanations for their legally relevant design decisions. We extend
the previous system for providing explanations by specifying norms and the key
legal or ethical principles for justifying actions in normative contexts.
Considering that first-order logic has strong expressive power, in the current
paper we adopt a first-order deontic logic system with deontic operators and
preferences. We illustrate the advantages and necessity of introducing deontic
logic and designing explanations under LeSAC by modelling two cases in the
context of autonomous driving. In particular, this paper also discusses the
requirements of the updated LeSAC to guarantee rationality, and proves that a
well-defined LeSAC can satisfy the rationality postulate for rule-based
argumentation frameworks. This ensures the system's ability to provide
coherent, legally valid explanations for complex design decisions.

摘要：在我們先前的研究中，我們提供了一個基於論證理論的推理系統（稱為 LeSAC），以便在設計過程中為設計師提供法律支持。在此基礎上，本文探討如何為設計師提供其與法律相關的設計決策的有效解釋。我們通過指定規範和關鍵法律或道德原則來擴展先前的解釋系統，以證明在規範性背景下的行為。考慮到一階邏輯具有強大的表達能力，在當前論文中，我們採用具有本務算子和偏好的一階本務邏輯系統。我們通過在自動駕駛背景下建模兩個案例來說明引入本務邏輯和在 LeSAC 下設計解釋的優點和必要性。特別是，本文還討論了更新 LeSAC 以保證理性的要求，並證明了一個定義良好的 LeSAC 可以滿足基於規則的論證框架的理性公設。這確保了系統為複雜的設計決策提供連貫、合法有效的解釋的能力。

##### **Knowledge Adaptation Network for Few-Shot Class-Incremental Learning**
2409.11770v1 by Ye Wang, Yaxiong Wang, Guoshuai Zhao, Xueming Qian

Few-shot class-incremental learning (FSCIL) aims to incrementally recognize
new classes using a few samples while maintaining the performance on previously
learned classes. One of the effective methods to solve this challenge is to
construct prototypical evolution classifiers. Despite the advancement achieved
by most existing methods, the classifier weights are simply initialized using
mean features. Because representations for new classes are weak and biased, we
argue such a strategy is suboptimal. In this paper, we tackle this issue from
two aspects. Firstly, thanks to the development of foundation models, we employ
a foundation model, the CLIP, as the network pedestal to provide a general
representation for each class. Secondly, to generate a more reliable and
comprehensive instance representation, we propose a Knowledge Adapter (KA)
module that summarizes the data-specific knowledge from training data and fuses
it into the general representation. Additionally, to tune the knowledge learned
from the base classes to the upcoming classes, we propose a mechanism of
Incremental Pseudo Episode Learning (IPEL) by simulating the actual FSCIL.
Taken together, our proposed method, dubbed as Knowledge Adaptation Network
(KANet), achieves competitive performance on a wide range of datasets,
including CIFAR100, CUB200, and ImageNet-R.

摘要：少样本类增量学习 (FSCIL) 旨在使用少量样本增量识别新类别，同时保持对先前学习类别的性能。解决此挑战的有效方法之一是构建原型进化分类器。尽管大多数现有方法取得了进步，但分类器权重只是使用平均特征进行初始化。由于新类别的表示很弱且有偏差，我们认为这种策略不是最优的。在本文中，我们从两个方面解决这个问题。首先，得益于基础模型的发展，我们采用基础模型 CLIP 作为网络基座，为每个类别提供通用表示。其次，为了生成更可靠和全面的实例表示，我们提出了一个知识适配器 (KA) 模块，该模块总结了训练数据中的特定于数据知识，并将其融合到通用表示中。此外，为了将从基础类别学到的知识调整到即将到来的类别，我们通过模拟实际 FSCIL 提出了一种增量伪序列学习 (IPEL) 机制。综上所述，我们提出的方法称为知识适应网络 (KANet)，在广泛的数据集上实现了有竞争力的性能，包括 CIFAR100、CUB200 和 ImageNet-R。

##### **One Map to Find Them All: Real-time Open-Vocabulary Mapping for Zero-shot Multi-Object Navigation**
2409.11764v1 by Finn Lukas Busch, Timon Homberger, Jesús Ortega-Peimbert, Quantao Yang, Olov Andersson

The capability to efficiently search for objects in complex environments is
fundamental for many real-world robot applications. Recent advances in
open-vocabulary vision models have resulted in semantically-informed object
navigation methods that allow a robot to search for an arbitrary object without
prior training. However, these zero-shot methods have so far treated the
environment as unknown for each consecutive query. In this paper we introduce a
new benchmark for zero-shot multi-object navigation, allowing the robot to
leverage information gathered from previous searches to more efficiently find
new objects. To address this problem we build a reusable open-vocabulary
feature map tailored for real-time object search. We further propose a
probabilistic-semantic map update that mitigates common sources of errors in
semantic feature extraction and leverage this semantic uncertainty for informed
multi-object exploration. We evaluate our method on a set of object navigation
tasks in both simulation as well as with a real robot, running in real-time on
a Jetson Orin AGX. We demonstrate that it outperforms existing state-of-the-art
approaches both on single and multi-object navigation tasks. Additional videos,
code and the multi-object navigation benchmark will be available on
https://finnbsch.github.io/OneMap.

摘要：在複雜環境中有效搜尋物體的能力對於許多真實世界的機器人應用來說至關重要。開放式詞彙視覺模型的最新進展已產生語義訊息物件導航方法，允許機器人在沒有事先訓練的情況下搜尋任意物件。然而，到目前為止，這些零次學習方法將環境視為每個連續查詢的未知環境。在本文中，我們介紹了一個新的零次學習多物件導航基準，允許機器人利用從先前搜尋收集的資訊，更有效率地尋找新物件。為了解決這個問題，我們建立了一個可重複使用的開放式詞彙特徵圖，專門用於即時物件搜尋。我們進一步提出了機率語義地圖更新，它可以減輕語義特徵萃取中常見的錯誤來源，並利用這個語義不確定性進行明智的多物件探索。我們在模擬和真實機器人中的一組物件導航任務上評估我們的模型，並在 Jetson Orin AGX 上即時執行。我們證明了它在單一和多物件導航任務上都優於現有的最先進方法。額外的影片、程式碼和多物件導航基準將在 https://finnbsch.github.io/OneMap 上提供。

##### **Synthesizing Evolving Symbolic Representations for Autonomous Systems**
2409.11756v1 by Gabriele Sartor, Angelo Oddi, Riccardo Rasconi, Vieri Giuliano Santucci, Rosa Meo

Recently, AI systems have made remarkable progress in various tasks. Deep
Reinforcement Learning(DRL) is an effective tool for agents to learn policies
in low-level state spaces to solve highly complex tasks. Researchers have
introduced Intrinsic Motivation(IM) to the RL mechanism, which simulates the
agent's curiosity, encouraging agents to explore interesting areas of the
environment. This new feature has proved vital in enabling agents to learn
policies without being given specific goals. However, even though DRL
intelligence emerges through a sub-symbolic model, there is still a need for a
sort of abstraction to understand the knowledge collected by the agent. To this
end, the classical planning formalism has been used in recent research to
explicitly represent the knowledge an autonomous agent acquires and effectively
reach extrinsic goals. Despite classical planning usually presents limited
expressive capabilities, PPDDL demonstrated usefulness in reviewing the
knowledge gathered by an autonomous system, making explicit causal
correlations, and can be exploited to find a plan to reach any state the agent
faces during its experience. This work presents a new architecture implementing
an open-ended learning system able to synthesize from scratch its experience
into a PPDDL representation and update it over time. Without a predefined set
of goals and tasks, the system integrates intrinsic motivations to explore the
environment in a self-directed way, exploiting the high-level knowledge
acquired during its experience. The system explores the environment and
iteratively: (a) discover options, (b) explore the environment using options,
(c) abstract the knowledge collected and (d) plan. This paper proposes an
alternative approach to implementing open-ended learning architectures
exploiting low-level and high-level representations to extend its knowledge in
a virtuous loop.

摘要：<paragraph>最近，AI 系統在各種任務上取得了顯著進展。深度強化學習 (DRL) 是一種有效的工具，可用於代理學習低層級狀態空間中的策略，以解決高度複雜的任務。研究人員已將內在動機 (IM) 引入 RL 機制中，模擬代理的好奇心，鼓勵代理探索環境中有趣的地方。此新功能已被證明對於讓代理學習策略至關重要，而無需給予具體目標。然而，儘管 DRL 智慧是透過次符號模型產生的，但仍需要一種抽象化來理解代理收集的知識。為此，最近的研究中使用了經典規劃形式主義，以明確表示自主代理獲得的知識，並有效地達成外在目標。儘管經典規劃通常表現出有限的表達能力，但 PPDDL 已證明在檢視自主系統收集的知識、明確因果關係方面很有用，並且可用於尋找計畫，以達成代理在經驗中面臨的任何狀態。這項工作提出了一種新的架構，實作一個開放式學習系統，能夠從頭開始將其經驗合成到 PPDDL 表示中，並隨著時間推移更新它。在沒有預定義的目標和任務的情況下，系統整合內在動機，以自導方式探索環境，利用其經驗中獲得的高層級知識。系統探索環境並反覆：(a) 發現選項，(b) 使用選項探索環境，(c) 抽象收集的知識，以及 (d) 規劃。本文提出了一種替代方法，用於實作開放式學習架構，利用低層級和高層級表示來擴展其知識，形成良性循環。</paragraph>

##### **NPAT Null-Space Projected Adversarial Training Towards Zero Deterioration**
2409.11754v1 by Hanyi Hu, Qiao Han, Kui Chen, Yao Yang

To mitigate the susceptibility of neural networks to adversarial attacks,
adversarial training has emerged as a prevalent and effective defense strategy.
Intrinsically, this countermeasure incurs a trade-off, as it sacrifices the
model's accuracy in processing normal samples. To reconcile the trade-off, we
pioneer the incorporation of null-space projection into adversarial training
and propose two innovative Null-space Projection based Adversarial
Training(NPAT) algorithms tackling sample generation and gradient optimization,
named Null-space Projected Data Augmentation (NPDA) and Null-space Projected
Gradient Descent (NPGD), to search for an overarching optimal solutions, which
enhance robustness with almost zero deterioration in generalization
performance. Adversarial samples and perturbations are constrained within the
null-space of the decision boundary utilizing a closed-form null-space
projector, effectively mitigating threat of attack stemming from unreliable
features. Subsequently, we conducted experiments on the CIFAR10 and SVHN
datasets and reveal that our methodology can seamlessly combine with
adversarial training methods and obtain comparable robustness while keeping
generalization close to a high-accuracy model.

摘要：為了減輕神經網路對抗攻擊的敏感性，
對抗訓練已成為一種普遍且有效的防禦策略。
本質上，此對策會產生權衡，因為它犧牲了
模型處理一般樣本的準確性。為了調和權衡，我們
率先將零空間投影納入對抗訓練
並提出兩種創新的基於零空間投影的對抗
訓練（NPAT）演算法來處理樣本產生和梯度最佳化，
稱為零空間投影資料擴充（NPDA）和零空間投影
梯度下降（NPGD），以搜尋一個整體最佳解，這
增強了穩健性，同時幾乎沒有損害泛化
效能。對抗樣本和擾動受限於決策邊界的
零空間，利用閉合形式的零空間
投影器，有效減輕源自於不可靠
特徵的攻擊威脅。隨後，我們在 CIFAR10 和 SVHN
資料集上進行實驗，並揭示我們的技術可以與
對抗訓練方法無縫結合，並在保持
泛化接近高準確度模型的同時獲得可比較的穩健性。

##### **Exploring Gaze Pattern in Autistic Children: Clustering, Visualization, and Prediction**
2409.11744v1 by Weiyan Shi, Haihong Zhang, Jin Yang, Ruiqing Ding, YongWei Zhu, Kenny Tsu Wei Choo

Autism Spectrum Disorder (ASD) significantly affects the social and
communication abilities of children, and eye-tracking is commonly used as a
diagnostic tool by identifying associated atypical gaze patterns. Traditional
methods demand manual identification of Areas of Interest in gaze patterns,
lowering the performance of gaze behavior analysis in ASD subjects. To tackle
this limitation, we propose a novel method to automatically analyze gaze
behaviors in ASD children with superior accuracy. To be specific, we first
apply and optimize seven clustering algorithms to automatically group gaze
points to compare ASD subjects with typically developing peers. Subsequently,
we extract 63 significant features to fully describe the patterns. These
features can describe correlations between ASD diagnosis and gaze patterns.
Lastly, using these features as prior knowledge, we train multiple predictive
machine learning models to predict and diagnose ASD based on their gaze
behaviors. To evaluate our method, we apply our method to three ASD datasets.
The experimental and visualization results demonstrate the improvements of
clustering algorithms in the analysis of unique gaze patterns in ASD children.
Additionally, these predictive machine learning models achieved
state-of-the-art prediction performance ($81\%$ AUC) in the field of
automatically constructed gaze point features for ASD diagnosis. Our code is
available at \url{https://github.com/username/projectname}.

摘要：自閉症譜系障礙 (ASD) 會顯著影響兒童的社交和溝通能力，而眼球追蹤通常用於透過識別相關的非典型注視模式作為診斷工具。傳統方法需要手動識別注視模式中的關注區域，降低 ASD 受試者的注視行為分析效能。為了克服這個限制，我們提出了一種新穎的方法，可以自動分析 ASD 兒童的注視行為，並具有更高的準確度。具體來說，我們首先應用和最佳化七種聚類演算法，以自動將注視點分組，以將 ASD 受試者與正常發展的同儕進行比較。隨後，我們提取 63 個顯著特徵來充分描述模式。這些特徵可以描述 ASD 診斷和注視模式之間的關聯性。最後，使用這些特徵作為先驗知識，我們訓練多個預測機器學習模型，以根據他們的注視行為預測和診斷 ASD。為了評估我們的模型，我們將我們的模型應用於三個 ASD 資料集。實驗和視覺化結果證明了聚類演算法在分析 ASD 兒童獨特注視模式方面的改進。此外，這些預測機器學習模型在 ASD 診斷的自動建構注視點特徵領域中達到了最先進的預測效能 (81% AUC)。我們的程式碼可在 \url{https://github.com/username/projectname} 取得。

##### **InverseMeetInsert: Robust Real Image Editing via Geometric Accumulation Inversion in Guided Diffusion Models**
2409.11734v1 by Yan Zheng, Lemeng Wu

In this paper, we introduce Geometry-Inverse-Meet-Pixel-Insert, short for
GEO, an exceptionally versatile image editing technique designed to cater to
customized user requirements at both local and global scales. Our approach
seamlessly integrates text prompts and image prompts to yield diverse and
precise editing outcomes. Notably, our method operates without the need for
training and is driven by two key contributions: (i) a novel geometric
accumulation loss that enhances DDIM inversion to faithfully preserve pixel
space geometry and layout, and (ii) an innovative boosted image prompt
technique that combines pixel-level editing for text-only inversion with latent
space geometry guidance for standard classifier-free reversion. Leveraging the
publicly available Stable Diffusion model, our approach undergoes extensive
evaluation across various image types and challenging prompt editing scenarios,
consistently delivering high-fidelity editing results for real images.

摘要：在本文中，我們介紹了幾何反向像素插入，簡稱 GEO，這是一種用途廣泛的圖像編輯技術，旨在滿足局部和全局範圍內自訂使用者需求。我們的做法無縫整合文字提示和圖像提示，以產生多樣且精確的編輯結果。值得注意的是，我們的方法無需訓練，並由兩個關鍵貢獻驅動：(i) 一種新穎的幾何累積損失，它增強了 DDIM 反轉以忠實地保留像素空間幾何和佈局，以及 (ii) 一種創新的加強圖像提示技術，它結合了僅文字反轉的像素級別編輯與標準分類器自由反轉的潛在空間幾何指導。利用公開的 Stable Diffusion 模型，我們的方法在各種影像類型和具挑戰性的提示編輯場景中進行廣泛評估，持續提供高保真編輯結果以用於真實影像。

##### **Human-like Affective Cognition in Foundation Models**
2409.11733v2 by Kanishk Gandhi, Zoe Lynch, Jan-Philipp Fränken, Kayla Patterson, Sharon Wambu, Tobias Gerstenberg, Desmond C. Ong, Noah D. Goodman

Understanding emotions is fundamental to human interaction and experience.
Humans easily infer emotions from situations or facial expressions, situations
from emotions, and do a variety of other affective cognition. How adept is
modern AI at these inferences? We introduce an evaluation framework for testing
affective cognition in foundation models. Starting from psychological theory,
we generate 1,280 diverse scenarios exploring relationships between appraisals,
emotions, expressions, and outcomes. We evaluate the abilities of foundation
models (GPT-4, Claude-3, Gemini-1.5-Pro) and humans (N = 567) across carefully
selected conditions. Our results show foundation models tend to agree with
human intuitions, matching or exceeding interparticipant agreement. In some
conditions, models are ``superhuman'' -- they better predict modal human
judgements than the average human. All models benefit from chain-of-thought
reasoning. This suggests foundation models have acquired a human-like
understanding of emotions and their influence on beliefs and behavior.

摘要：理解情緒是人類互動和體驗的基礎。
人類可以輕易從情境或面部表情推斷情緒，從情緒推斷情境，並進行各種其他情感認知。現代 AI 在這些推論方面有多靈活？我們引入了一個評估架構，用於測試基礎模型中的情感認知。從心理學理論出發，我們生成了 1,280 個不同的場景，探討評估、情緒、表達和結果之間的關係。我們評估了基礎模型（GPT-4、Claude-3、Gemini-1.5-Pro）和人類（N = 567）在經過仔細選擇的條件下的能力。我們的結果表明，基礎模型往往與人類直覺一致，達到或超過參與者之間的一致性。在某些條件下，模型是「超人類的」——它們比普通人更好地預測模態人類判斷。所有模型都受益於思維鏈推理。這表明基礎模型已經獲得了類似人類的情緒理解力，以及它們對信念和行為的影響。

##### **Enabling Real-Time Conversations with Minimal Training Costs**
2409.11727v1 by Wang Xu, Shuo Wang, Weilin Zhao, Xu Han, Yukun Yan, Yudi Zhang, Zhe Tao, Zhiyuan Liu, Wanxiang Che

Large language models (LLMs) have demonstrated the ability to improve human
efficiency through conversational interactions. Conventional LLM-powered
dialogue systems, operating on a turn-based paradigm, preclude real-time
interaction during response generation. To address this limitation, researchers
have proposed duplex models. These models can dynamically adapt to user input,
facilitating real-time interactive feedback. However, these methods typically
require substantial computational resources to acquire the ability. To reduce
overhead, this paper presents a new duplex decoding approach that enhances LLMs
with duplex ability, requiring minimal additional training. Specifically, our
method employs parallel decoding of queries and responses in conversations,
effectively implementing a channel-division-multiplexing decoding strategy.
Experimental results indicate that our proposed method significantly enhances
the naturalness and human-likeness of user-AI interactions with minimal
training costs.

摘要：大型語言模型 (LLM) 已展示出透過對話互動來提升人類效率的能力。在回合制範例中運作的傳統 LLM 驅動對話系統，會在回應產生期間排除即時互動。為了解決這個限制，研究人員提出了雙工模型。這些模型可以動態適應使用者輸入，促進即時互動回饋。然而，這些方法通常需要大量的運算資源才能獲得這種能力。為了減少開銷，本文提出了一種新的雙工解碼方法，它以最少的額外訓練來增強 LLM 的雙工能力。具體來說，我們的模型在對話中採用查詢和回應的並行解碼，有效地實作了頻道分割多工解碼策略。實驗結果表明，我們提出的方法顯著地增強了使用者與 AI 互動的自然性和擬人化，同時訓練成本極低。

##### **Revealing the Challenge of Detecting Character Knowledge Errors in LLM Role-Playing**
2409.11726v1 by Wenyuan Zhang, Jiawei Sheng, Shuaiyi Nie, Zefeng Zhang, Xinghua Zhang, Yongquan He, Tingwen Liu

Large language model (LLM) role-playing has gained widespread attention,
where the authentic character knowledge is crucial for constructing realistic
LLM role-playing agents. However, existing works usually overlook the
exploration of LLMs' ability to detect characters' known knowledge errors (KKE)
and unknown knowledge errors (UKE) while playing roles, which would lead to
low-quality automatic construction of character trainable corpus. In this
paper, we propose a probing dataset to evaluate LLMs' ability to detect errors
in KKE and UKE. The results indicate that even the latest LLMs struggle to
effectively detect these two types of errors, especially when it comes to
familiar knowledge. We experimented with various reasoning strategies and
propose an agent-based reasoning method, Self-Recollection and Self-Doubt
(S2RD), to further explore the potential for improving error detection
capabilities. Experiments show that our method effectively improves the LLMs'
ability to detect error character knowledge, but it remains an issue that
requires ongoing attention.

摘要：大型語言模型 (LLM) 角色扮演已廣受關注，其中真實的角色知識對於建構逼真的 LLM 角色扮演代理至關重要。然而，現有作品通常忽略探索 LLM 在扮演角色時偵測角色已知知識錯誤 (KKE) 和未知知識錯誤 (UKE) 的能力，這將導致角色可訓練語料庫的自動建構品質低落。在本文中，我們提出一個探測資料集來評估 LLM 偵測 KKE 和 UKE 中錯誤的能力。結果表明，即使是最新 LLM 也難以有效偵測這兩種類型的錯誤，特別是在涉及熟悉知識時。我們嘗試了各種推理策略，並提出基於代理的推理方法，自我回憶和自我懷疑 (S2RD)，以進一步探索改善錯誤偵測能力的可能性。實驗表明，我們的方法有效地提高了 LLM 偵測錯誤角色知識的能力，但這仍然是一個需要持續關注的問題。

##### **TART: An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning**
2409.11724v1 by Xinyuan Lu, Liangming Pan, Yubo Ma, Preslav Nakov, Min-Yen Kan

Current Large Language Models (LLMs) exhibit limited ability to understand
table structures and to apply precise numerical reasoning, which is crucial for
tasks such as table question answering (TQA) and table-based fact verification
(TFV). To address these challenges, we introduce our Tool-Augmented Reasoning
framework for Tables (TART), which integrates LLMs with specialized tools. TART
contains three key components: a table formatter to ensure accurate data
representation, a tool maker to develop specific computational tools, and an
explanation generator to maintain explainability. We also present the TOOLTAB
dataset, a new benchmark designed specifically for training LLMs in table-tool
integration. Our experiments indicate that TART achieves substantial
improvements over existing methods (e.g., Chain-of-Thought) by improving both
the precision of data processing and the clarity of the reasoning process.
Notably, TART paired with CodeLlama achieves 90.0% of the accuracy of the
closed-sourced LLM GPT-3.5-turbo, highlighting its robustness in diverse
real-world scenarios. All the code and data are available at
https://github.com/XinyuanLu00/TART.

摘要：<paragraph>目前的巨量語言模型 (LLM) 在理解表格結構和應用精確的數值推理方面表現出有限的能力，這對於表格問答 (TQA) 和基於表格的事實驗證 (TFV) 等任務至關重要。為了應對這些挑戰，我們引入了我們的表格工具增強推理框架 (TART)，它將 LLM 與專業工具整合在一起。TART 包含三個關鍵組成部分：一個表格格式化器以確保準確的數據表示、一個工具製造器以開發特定的計算工具，以及一個解釋生成器以維持可解釋性。我們還展示了 TOOLTAB 數據集，這是一個專門為訓練表格工具整合中的 LLM 而設計的新基準。我們的實驗表明，TART 通過提高數據處理的精確度和推理過程的清晰度，比現有方法（例如思想鏈）取得了顯著的改進。值得注意的是，與 CodeLlama 配對的 TART 達到了封閉源 LLM GPT-3.5-turbo 90.0% 的準確度，突出了其在各種現實世界場景中的魯棒性。所有代碼和數據均可在 https://github.com/XinyuanLu00/TART 獲得。</paragraph>

##### **From Lists to Emojis: How Format Bias Affects Model Alignment**
2409.11704v1 by Xuanchang Zhang, Wei Xiong, Lichang Chen, Tianyi Zhou, Heng Huang, Tong Zhang

In this paper, we study format biases in reinforcement learning from human
feedback (RLHF). We observe that many widely-used preference models, including
human evaluators, GPT-4, and top-ranking models on the RewardBench benchmark,
exhibit strong biases towards specific format patterns, such as lists, links,
bold text, and emojis. Furthermore, large language models (LLMs) can exploit
these biases to achieve higher rankings on popular benchmarks like AlpacaEval
and LMSYS Chatbot Arena. One notable example of this is verbosity bias, where
current preference models favor longer responses that appear more
comprehensive, even when their quality is equal to or lower than shorter,
competing responses. However, format biases beyond verbosity remain largely
underexplored in the literature. In this work, we extend the study of biases in
preference learning beyond the commonly recognized length bias, offering a
comprehensive analysis of a wider range of format biases. Additionally, we show
that with a small amount of biased data (less than 1%), we can inject
significant bias into the reward model. Moreover, these format biases can also
be easily exploited by downstream alignment algorithms, such as best-of-n
sampling and online iterative DPO, as it is usually easier to manipulate the
format than to improve the quality of responses. Our findings emphasize the
need to disentangle format and content both for designing alignment algorithms
and evaluating models.

摘要：<paragraph>在本文中，我們研究了人類回饋 (RLHF) 中強化學習的格式偏差。我們觀察到許多廣泛使用的偏好模型，包括人類評估員、GPT-4 和 RewardBench 基準上的排名最高模型，對特定格式模式（例如清單、連結、粗體文字和表情符號）表現出強烈的偏見。此外，大型語言模型 (LLM) 可以利用這些偏見在 AlpacaEval 和 LMSYS Chatbot Arena 等熱門基準上獲得更高的排名。一個顯著的例子是冗長偏見，其中當前的偏好模型偏好看起來更全面的較長回應，即使它們的品質等於或低於較短的競爭回應。然而，除了冗長之外的格式偏差在文獻中仍然很大程度上未被探索。在這項工作中，我們將偏好學習中偏差的研究延伸到常見的長度偏差之外，提供對更廣泛的格式偏差的全面分析。此外，我們表明，只要有少量的偏差資料（小於 1%），我們就可以將顯著的偏差注入獎勵模型。此外，這些格式偏差也可以很容易地被下游對齊演算法（例如最佳 n 採樣和線上反覆 DPO）利用，因為操縱格式通常比提高回應品質更容易。我們的研究結果強調了在設計對齊演算法和評估模型時解開格式和內容的必要性。</paragraph>

##### **Harnessing LLMs for API Interactions: A Framework for Classification and Synthetic Data Generation**
2409.11703v1 by Chunliang Tao, Xiaojing Fan, Yahe Yang

As Large Language Models (LLMs) advance in natural language processing, there
is growing interest in leveraging their capabilities to simplify software
interactions. In this paper, we propose a novel system that integrates LLMs for
both classifying natural language inputs into corresponding API calls and
automating the creation of sample datasets tailored to specific API functions.
By classifying natural language commands, our system allows users to invoke
complex software functionalities through simple inputs, improving interaction
efficiency and lowering the barrier to software utilization. Our dataset
generation approach also enables the efficient and systematic evaluation of
different LLMs in classifying API calls, offering a practical tool for
developers or business owners to assess the suitability of LLMs for customized
API management. We conduct experiments on several prominent LLMs using
generated sample datasets for various API functions. The results show that
GPT-4 achieves a high classification accuracy of 0.996, while LLaMA-3-8B
performs much worse at 0.759. These findings highlight the potential of LLMs to
transform API management and validate the effectiveness of our system in
guiding model testing and selection across diverse applications.

摘要：隨著大型語言模型 (LLM) 在自然語言處理方面的進展，人們越來越有興趣利用其功能來簡化軟體互動。在本文中，我們提出了一個新穎的系統，它整合了 LLM，既可以將自然語言輸入分類為對應的 API 呼叫，又可以自動建立針對特定 API 功能量身打造的範例資料集。透過分類自然語言命令，我們的系統允許使用者透過簡單的輸入來呼叫複雜的軟體功能，進而提升互動效率並降低使用軟體的門檻。我們的資料集生成方法還能有效率且系統性地評估不同的 LLM 在分類 API 呼叫方面的表現，為開發人員或企業主提供一個實用的工具，用於評估 LLM 是否適合自訂的 API 管理。我們使用針對各種 API 功能生成的範例資料集，對幾個知名的 LLM 進行實驗。結果顯示，GPT-4 達到了 0.996 的高分類準確度，而 LLaMA-3-8B 的表現則差很多，僅有 0.759。這些發現突顯了 LLM 轉變 API 管理的潛力，並驗證了我們的系統在引導不同應用程式的模型測試和選擇方面的有效性。

##### **FLARE: Fusing Language Models and Collaborative Architectures for Recommender Enhancement**
2409.11699v1 by Liam Hebert, Marialena Kyriakidi, Hubert Pham, Krishna Sayana, James Pine, Sukhdeep Sodhi, Ambarish Jash

Hybrid recommender systems, combining item IDs and textual descriptions,
offer potential for improved accuracy. However, previous work has largely
focused on smaller datasets and model architectures. This paper introduces
Flare (Fusing Language models and collaborative Architectures for Recommender
Enhancement), a novel hybrid recommender that integrates a language model (mT5)
with a collaborative filtering model (Bert4Rec) using a Perceiver network. This
architecture allows Flare to effectively combine collaborative and content
information for enhanced recommendations.
  We conduct a two-stage evaluation, first assessing Flare's performance
against established baselines on smaller datasets, where it demonstrates
competitive accuracy. Subsequently, we evaluate Flare on a larger, more
realistic dataset with a significantly larger item vocabulary, introducing new
baselines for this setting. Finally, we showcase Flare's inherent ability to
support critiquing, enabling users to provide feedback and refine
recommendations. We further leverage critiquing as an evaluation method to
assess the model's language understanding and its transferability to the
recommendation task.

摘要：混合推薦系統結合項目 ID 和文字描述，
提供改進準確性的潛力。然而，先前的研究主要
集中在較小的資料集和模型架構上。本文介紹
Flare（融合語言模型和協作架構以增強推薦），一種新穎的混合推薦系統，它使用感知器網路將語言模型 (mT5) 與協作過濾模型 (Bert4Rec) 整合在一起。這個
架構允許 Flare 有效地結合協作和內容
資訊以增強推薦。
我們進行了兩階段評估，首先評估 Flare 在較小的資料集上對已建立基準的效能，在這些資料集中，它展現了
競爭力的準確性。隨後，我們在一個較大、更
實際的資料集上評估 Flare，該資料集具有顯著更大的項目詞彙，為此設定引入了新的基準。最後，我們展示了 Flare 內建支援批評的能力，使用戶能夠提供回饋並改善
推薦。我們進一步利用批評作為評估方法來
評估模型的語言理解及其在推薦任務中的可傳輸性。

##### **GUNet: A Graph Convolutional Network United Diffusion Model for Stable and Diversity Pose Generation**
2409.11689v1 by Shuowen Liang, Sisi Li, Qingyun Wang, Cen Zhang, Kaiquan Zhu, Tian Yang

Pose skeleton images are an important reference in pose-controllable image
generation. In order to enrich the source of skeleton images, recent works have
investigated the generation of pose skeletons based on natural language. These
methods are based on GANs. However, it remains challenging to perform diverse,
structurally correct and aesthetically pleasing human pose skeleton generation
with various textual inputs. To address this problem, we propose a framework
with GUNet as the main model, PoseDiffusion. It is the first generative
framework based on a diffusion model and also contains a series of variants
fine-tuned based on a stable diffusion model. PoseDiffusion demonstrates
several desired properties that outperform existing methods. 1) Correct
Skeletons. GUNet, a denoising model of PoseDiffusion, is designed to
incorporate graphical convolutional neural networks. It is able to learn the
spatial relationships of the human skeleton by introducing skeletal information
during the training process. 2) Diversity. We decouple the key points of the
skeleton and characterise them separately, and use cross-attention to introduce
textual conditions. Experimental results show that PoseDiffusion outperforms
existing SoTA algorithms in terms of stability and diversity of text-driven
pose skeleton generation. Qualitative analyses further demonstrate its
superiority for controllable generation in Stable Diffusion.

摘要：姿勢骨架圖像是姿勢可控圖像生成中重要的參考。為了豐富骨架圖像的來源，最近的研究調查了基於自然語言的姿勢骨架生成。這些方法基於 GAN。然而，要執行多樣化、結構正確且美觀的人體姿勢骨架生成，並具有各種文本輸入，仍然具有挑戰性。為了解決這個問題，我們提出了以 GUNet 為主要模型的框架，PoseDiffusion。它是基於擴散模型的第一個生成框架，還包含一系列基於穩定擴散模型進行微調的變體。PoseDiffusion 展示了多項優於現有方法的理想屬性。1) 正確的骨架。PoseDiffusion 的去噪模型 GUNet 被設計為結合圖形卷積神經網路。它能夠透過在訓練過程中引入骨架資訊來學習人體骨架的空間關係。2) 多樣性。我們解耦骨架的關鍵點並分別對其進行表徵，並使用交叉注意力來引入文本條件。實驗結果表明，PoseDiffusion 在文本驅動姿勢骨架生成的穩定性和多樣性方面優於現有的 SoTA 演算法。定性分析進一步證明了它在 Stable Diffusion 中可控生成的優越性。

##### **Detecting Underdiagnosed Medical Conditions with Deep Learning-Based Opportunistic CT Imaging**
2409.11686v1 by Asad Aali, Andrew Johnston, Louis Blankemeier, Dave Van Veen, Laura T Derry, David Svec, Jason Hom, Robert D. Boutin, Akshay S. Chaudhari

Abdominal computed tomography (CT) scans are frequently performed in clinical
settings. Opportunistic CT involves repurposing routine CT images to extract
diagnostic information and is an emerging tool for detecting underdiagnosed
conditions such as sarcopenia, hepatic steatosis, and ascites. This study
utilizes deep learning methods to promote accurate diagnosis and clinical
documentation. We analyze 2,674 inpatient CT scans to identify discrepancies
between imaging phenotypes (characteristics derived from opportunistic CT
scans) and their corresponding documentation in radiology reports and ICD
coding. Through our analysis, we find that only 0.5%, 3.2%, and 30.7% of scans
diagnosed with sarcopenia, hepatic steatosis, and ascites (respectively)
through either opportunistic imaging or radiology reports were ICD-coded. Our
findings demonstrate opportunistic CT's potential to enhance diagnostic
precision and accuracy of risk adjustment models, offering advancements in
precision medicine.

摘要：腹部電腦斷層掃描 (CT) 在臨床環境中經常執行。機會性 CT 涉及將例行 CT 影像重新用於提取診斷資訊，並且是偵測未診斷疾病（例如肌肉減少症、肝臟脂肪變性、腹水）的新興工具。本研究利用深度學習方法促進準確診斷和臨床文件編寫。我們分析 2,674 個住院病人 CT 掃描，以找出影像表型（從機會性 CT 掃描衍生的特徵）與其在放射科報告和 ICD 編碼中對應的文件之間的差異。透過我們的分析，我們發現僅有 0.5%、3.2% 和 30.7% 的掃描被診斷為肌肉減少症、肝臟脂肪變性和腹水（分別）透過機會性影像或放射科報告進行 ICD 編碼。我們的研究結果證明了機會性 CT 增強診斷精準度和風險調整模型精確度的潛力，提供了精準醫療的進展。

##### **Enhancing Complex Formula Recognition with Hierarchical Detail-Focused Network**
2409.11677v1 by Jiale Wang, Junhui Yu, Huanyong Liu, Chenanran Kong

Hierarchical and complex Mathematical Expression Recognition (MER) is
challenging due to multiple possible interpretations of a formula, complicating
both parsing and evaluation. In this paper, we introduce the Hierarchical
Detail-Focused Recognition dataset (HDR), the first dataset specifically
designed to address these issues. It consists of a large-scale training set,
HDR-100M, offering an unprecedented scale and diversity with one hundred
million training instances. And the test set, HDR-Test, includes multiple
interpretations of complex hierarchical formulas for comprehensive model
performance evaluation. Additionally, the parsing of complex formulas often
suffers from errors in fine-grained details. To address this, we propose the
Hierarchical Detail-Focused Recognition Network (HDNet), an innovative
framework that incorporates a hierarchical sub-formula module, focusing on the
precise handling of formula details, thereby significantly enhancing MER
performance. Experimental results demonstrate that HDNet outperforms existing
MER models across various datasets.

摘要：分層且複雜的數學表達式辨識 (MER) 因公式有多種可能的詮釋而具有挑戰性，這使得解析和評估都變得複雜。在本文中，我們介紹了分層細節導向辨識資料集 (HDR)，這是第一個專門設計來解決這些問題的資料集。它包含一個大規模的訓練集 HDR-100M，提供了一個前所未有的規模和多樣性，擁有 1 億個訓練實例。測試集 HDR-Test 包含複雜分層公式的多種詮釋，用於全面的模型效能評估。此外，複雜公式的解析通常會在細微的細節中出現錯誤。為了解決這個問題，我們提出了分層細節導向辨識網路 (HDNet)，這是一個創新的架構，它結合了一個分層子公式模組，專注於精確處理公式細節，從而顯著增強了 MER 效能。實驗結果表明，HDNet 在各種資料集上都優於現有的 MER 模型。

##### **Hypergraph-based Motion Generation with Multi-modal Interaction Relational Reasoning**
2409.11676v1 by Keshu Wu, Yang Zhou, Haotian Shi, Dominique Lord, Bin Ran, Xinyue Ye

The intricate nature of real-world driving environments, characterized by
dynamic and diverse interactions among multiple vehicles and their possible
future states, presents considerable challenges in accurately predicting the
motion states of vehicles and handling the uncertainty inherent in the
predictions. Addressing these challenges requires comprehensive modeling and
reasoning to capture the implicit relations among vehicles and the
corresponding diverse behaviors. This research introduces an integrated
framework for autonomous vehicles (AVs) motion prediction to address these
complexities, utilizing a novel Relational Hypergraph Interaction-informed
Neural mOtion generator (RHINO). RHINO leverages hypergraph-based relational
reasoning by integrating a multi-scale hypergraph neural network to model
group-wise interactions among multiple vehicles and their multi-modal driving
behaviors, thereby enhancing motion prediction accuracy and reliability.
Experimental validation using real-world datasets demonstrates the superior
performance of this framework in improving predictive accuracy and fostering
socially aware automated driving in dynamic traffic scenarios.

摘要：真實世界駕駛環境的複雜性質，其特徵在於多輛車輛之間的動態且多樣化的互動，以及它們可能的未來狀態，在準確預測車輛的運動狀態和處理預測中固有的不確定性方面提出了相當大的挑戰。要應對這些挑戰，需要全面的建模和推理來捕捉車輛之間的隱含關係和相應的多樣化行為。本研究引入了一個用於自動駕駛汽車 (AV) 運動預測的整合框架，以解決這些複雜性，利用一種新穎的關係超圖互動信息神經運動生成器 (RHINO)。RHINO 通過整合一個多尺度超圖神經網路來建模多輛車輛之間的組群互動及其多模式駕駛行為，從而增強運動預測的準確性和可靠性，從而利用基於超圖的關係推理。使用真實世界數據集進行的實驗驗證證明了此框架在提高預測準確性和促進動態交通場景中的社會感知自動駕駛方面的優越性能。

##### **Towards Explainable Goal Recognition Using Weight of Evidence (WoE): A Human-Centered Approach**
2409.11675v1 by Abeer Alshehri, Amal Abdulrahman, Hajar Alamri, Tim Miller, Mor Vered

Goal recognition (GR) involves inferring an agent's unobserved goal from a
sequence of observations. This is a critical problem in AI with diverse
applications. Traditionally, GR has been addressed using 'inference to the best
explanation' or abduction, where hypotheses about the agent's goals are
generated as the most plausible explanations for observed behavior.
Alternatively, some approaches enhance interpretability by ensuring that an
agent's behavior aligns with an observer's expectations or by making the
reasoning behind decisions more transparent. In this work, we tackle a
different challenge: explaining the GR process in a way that is comprehensible
to humans. We introduce and evaluate an explainable model for goal recognition
(GR) agents, grounded in the theoretical framework and cognitive processes
underlying human behavior explanation. Drawing on insights from two human-agent
studies, we propose a conceptual framework for human-centered explanations of
GR. Using this framework, we develop the eXplainable Goal Recognition (XGR)
model, which generates explanations for both why and why not questions. We
evaluate the model computationally across eight GR benchmarks and through three
user studies. The first study assesses the efficiency of generating human-like
explanations within the Sokoban game domain, the second examines perceived
explainability in the same domain, and the third evaluates the model's
effectiveness in aiding decision-making in illegal fishing detection. Results
demonstrate that the XGR model significantly enhances user understanding,
trust, and decision-making compared to baseline models, underscoring its
potential to improve human-agent collaboration.

摘要：目標辨識 (GR) 涉及從一連串觀察中推論出代理人未觀察到的目標。這是 AI 中的一個關鍵問題，有各種應用。傳統上，GR 已使用「推論出最佳解釋」或「假說」來解決，其中關於代理人目標的假設被產生為觀察到的行為最合理的解釋。或者，一些方法通過確保代理人的行為符合觀察者的期望或讓決策背後的推理更加透明，來增強可解釋性。在這項工作中，我們應對了不同的挑戰：以人類可以理解的方式解釋 GR 過程。我們引入並評估了一個可解釋的目標辨識 (GR) 代理模型，它基於人類行為解釋的理論框架和認知過程。借鑒兩項人機研究的見解，我們提出了以人為中心的 GR 解釋的概念框架。使用這個框架，我們開發了可解釋目標辨識 (XGR) 模型，它為為什麼和為什麼不的問題生成解釋。我們通過八個 GR 基準和三項使用者研究在計算上評估模型。第一項研究評估在數獨遊戲領域內生成類人解釋的效率，第二項研究在同一個領域中檢查感知的可解釋性，第三項評估模型在幫助非法捕魚偵測中進行決策的有效性。結果表明，與基線模型相比，XGR 模型顯著增強了使用者的理解、信任和決策制定，這凸顯了其改善人機協作的潛力。

##### **RUIE: Retrieval-based Unified Information Extraction using Large Language Model**
2409.11673v1 by Xincheng Liao, Junwen Duan, Yixi Huang, Jianxin Wang

Unified information extraction (UIE) aims to complete all information
extraction tasks using a single model or framework. While previous work has
primarily focused on instruction-tuning large language models (LLMs) with
constructed datasets, these methods require significant computational resources
and struggle to generalize to unseen tasks. To address these limitations, we
propose RUIE (Retrieval-based Unified Information Extraction), a framework that
leverages in-context learning to enable rapid generalization while reducing
computational costs. The key challenge in RUIE is selecting the most beneficial
demonstrations for LLMs to effectively handle diverse IE tasks. To achieve
this, we integrate LLM preferences for ranking candidate demonstrations and
design a keyword-enhanced reward model to capture fine-grained relationships
between queries and demonstrations. We then train a bi-encoder retriever for
UIE through contrastive learning and knowledge distillation. To the best of our
knowledge, RUIE is the first trainable retrieval framework for UIE.
Experimental results on 8 held-out datasets demonstrate RUIE's effectiveness in
generalizing to unseen tasks, with average F1-score improvements of 19.22 and
3.13 compared to instruction-tuning methods and other retrievers, respectively.
Further analysis confirms RUIE's adaptability to LLMs of varying sizes and the
importance of its key components.

摘要：統一資訊擷取 (UIE) 旨在使用單一模型或架構完成所有資訊擷取任務。雖然先前研究主要集中於使用建構資料集對大型語言模型 (LLM) 進行指令微調，但這些方法需要大量的運算資源，且難以推廣到未見任務。為了解決這些限制，我們提出了 RUIE (基於檢索的統一資訊擷取)，這是一個架構，它利用情境學習來實現快速推廣，同時降低運算成本。RUIE 中的主要挑戰是選擇對 LLM 最有益的示範，以有效處理不同的 IE 任務。為了達成此目的，我們整合了 LLM 偏好，用於對候選示範進行排名，並設計了一個關鍵字增強獎勵模型，以捕捉查詢和示範之間的細微關係。然後，我們透過對比學習和知識萃取訓練一個 UIE 的雙編碼檢索器。據我們所知，RUIE 是第一個可訓練的 UIE 檢索架構。8 個留存資料集的實驗結果證明了 RUIE 在推廣到未見任務方面的有效性，與指令微調方法和其他檢索器相比，平均 F1 分數分別提高了 19.22 和 3.13。進一步的分析證實了 RUIE 對不同大小 LLM 的適應性，以及其關鍵組成的重要性。

##### **GReDP: A More Robust Approach for Differential Private Training with Gradient-Preserving Noise Reduction**
2409.11663v2 by Haodi Wang, Tangyu Jiang, Yu Guo, Chengjun Cai, Cong Wang, Xiaohua Jia

Deep learning models have been extensively adopted in various regions due to
their ability to represent hierarchical features, which highly rely on the
training set and procedures. Thus, protecting the training process and deep
learning algorithms is paramount in privacy preservation. Although Differential
Privacy (DP) as a powerful cryptographic primitive has achieved satisfying
results in deep learning training, the existing schemes still fall short in
preserving model utility, i.e., they either invoke a high noise scale or
inevitably harm the original gradients. To address the above issues, in this
paper, we present a more robust approach for DP training called GReDP.
Specifically, we compute the model gradients in the frequency domain and adopt
a new approach to reduce the noise level. Unlike the previous work, our GReDP
only requires half of the noise scale compared to DPSGD [1] while keeping all
the gradient information intact. We present a detailed analysis of our method
both theoretically and empirically. The experimental results show that our
GReDP works consistently better than the baselines on all models and training
settings.

摘要：深度学习模型因其表示分层特征的能力而在各个领域得到广泛采用，而这种能力在很大程度上依赖于训练集和程序。因此，保护训练过程和深度学习算法对于隐私保护至关重要。尽管差分隐私 (DP) 作为一种强大的密码学原语在深度学习训练中取得了令人满意的结果，但现有方案在保留模型效用方面仍然存在不足，即它们要么调用高噪声比例，要么不可避免地损害原始梯度。为了解决上述问题，在本文中，我们提出了一种更稳健的 DP 训练方法，称为 GReDP。具体来说，我们在频域中计算模型梯度，并采用一种新方法来降低噪声水平。与之前的工作不同，我们的 GReDP 只需要与 DPSGD [1] 相比一半的噪声比例，同时保持所有梯度信息完整。我们从理论和经验上对我们的方法进行了详细分析。实验结果表明，我们的 GReDP 在所有模型和训练设置上始终优于基线。

##### **Few-Shot Class-Incremental Learning with Non-IID Decentralized Data**
2409.11657v1 by Cuiwei Liu, Siang Xu, Huaijun Qiu, Jing Zhang, Zhi Liu, Liang Zhao

Few-shot class-incremental learning is crucial for developing scalable and
adaptive intelligent systems, as it enables models to acquire new classes with
minimal annotated data while safeguarding the previously accumulated knowledge.
Nonetheless, existing methods deal with continuous data streams in a
centralized manner, limiting their applicability in scenarios that prioritize
data privacy and security. To this end, this paper introduces federated
few-shot class-incremental learning, a decentralized machine learning paradigm
tailored to progressively learn new classes from scarce data distributed across
multiple clients. In this learning paradigm, clients locally update their
models with new classes while preserving data privacy, and then transmit the
model updates to a central server where they are aggregated globally. However,
this paradigm faces several issues, such as difficulties in few-shot learning,
catastrophic forgetting, and data heterogeneity. To address these challenges,
we present a synthetic data-driven framework that leverages replay buffer data
to maintain existing knowledge and facilitate the acquisition of new knowledge.
Within this framework, a noise-aware generative replay module is developed to
fine-tune local models with a balance of new and replay data, while generating
synthetic data of new classes to further expand the replay buffer for future
tasks. Furthermore, a class-specific weighted aggregation strategy is designed
to tackle data heterogeneity by adaptively aggregating class-specific
parameters based on local models performance on synthetic data. This enables
effective global model optimization without direct access to client data.
Comprehensive experiments across three widely-used datasets underscore the
effectiveness and preeminence of the introduced framework.

摘要：少樣本類別增量學習對於開發可擴充且適應性的智慧系統至關重要，因為它能讓模型在保護先前累積知識的同時，以最少標註資料取得新類別。儘管如此，現有方法以集中式方式處理連續資料串流，限制了它們在優先考量資料隱私和安全性的場景中的適用性。為此，本文介紹了聯邦少樣本類別增量學習，這是一種分散式機器學習範例，專門用於從分散在多個用戶端中的稀疏資料逐步學習新類別。在此學習範例中，用戶端在保護資料隱私的同時，使用新類別更新其在地端模型，然後將模型更新傳輸到中央伺服器，並在伺服器中進行全域聚合。然而，此範例會面臨許多問題，例如少樣本學習、災難性遺忘和資料異質性。為了應對這些挑戰，我們提出了合成資料驅動架構，利用重播緩衝資料維護現有知識，並促進新知識的取得。在此架構中，開發了一個具備雜訊感知能力的生成式重播模組，以新資料和重播資料的平衡微調在地端模型，同時產生新類別的合成資料，以進一步擴充重播緩衝，用於未來的任務。此外，設計了一個類別特定加權聚合策略，以根據在地端模型在合成資料上的效能，自適應地聚合類別特定參數，來處理資料異質性。這能讓全球模型在不直接存取用戶端資料的情況下，進行有效的最佳化。在三個廣泛使用的資料集上的全面實驗，突顯了所提出的架構的有效性和卓越性。

##### **How to Build the Virtual Cell with Artificial Intelligence: Priorities and Opportunities**
2409.11654v1 by Charlotte Bunne, Yusuf Roohani, Yanay Rosen, Ankit Gupta, Xikun Zhang, Marcel Roed, Theo Alexandrov, Mohammed AlQuraishi, Patricia Brennan, Daniel B. Burkhardt, Andrea Califano, Jonah Cool, Abby F. Dernburg, Kirsty Ewing, Emily B. Fox, Matthias Haury, Amy E. Herr, Eric Horvitz, Patrick D. Hsu, Viren Jain, Gregory R. Johnson, Thomas Kalil, David R. Kelley, Shana O. Kelley, Anna Kreshuk, Tim Mitchison, Stephani Otte, Jay Shendure, Nicholas J. Sofroniew, Fabian Theis, Christina V. Theodoris, Srigokul Upadhyayula, Marc Valer, Bo Wang, Eric Xing, Serena Yeung-Levy, Marinka Zitnik, Theofanis Karaletsos, Aviv Regev, Emma Lundberg, Jure Leskovec, Stephen R. Quake

The cell is arguably the smallest unit of life and is central to
understanding biology. Accurate modeling of cells is important for this
understanding as well as for determining the root causes of disease. Recent
advances in artificial intelligence (AI), combined with the ability to generate
large-scale experimental data, present novel opportunities to model cells. Here
we propose a vision of AI-powered Virtual Cells, where robust representations
of cells and cellular systems under different conditions are directly learned
from growing biological data across measurements and scales. We discuss desired
capabilities of AI Virtual Cells, including generating universal
representations of biological entities across scales, and facilitating
interpretable in silico experiments to predict and understand their behavior
using Virtual Instruments. We further address the challenges, opportunities and
requirements to realize this vision including data needs, evaluation
strategies, and community standards and engagement to ensure biological
accuracy and broad utility. We envision a future where AI Virtual Cells help
identify new drug targets, predict cellular responses to perturbations, as well
as scale hypothesis exploration. With open science collaborations across the
biomedical ecosystem that includes academia, philanthropy, and the biopharma
and AI industries, a comprehensive predictive understanding of cell mechanisms
and interactions is within reach.

摘要：細胞可以說是生命中最小的單位，也是了解生物學的中心。準確地建立細胞模型對於理解生物學以及確定疾病的根本原因非常重要。最近人工智慧 (AI) 的進展，加上產生大規模實驗數據的能力，為細胞建模提供了新的機會。在此，我們提出了一個由 AI 驅動的虛擬細胞願景，其中在不同的條件下，細胞和細胞系統的強健表徵會直接從跨度測量和規模的生物數據中學習而來。我們討論了 AI 虛擬細胞所需的能力，包括產生跨度不同規模的生物實體的通用表徵，以及促進可解釋的電腦模擬實驗，以使用虛擬儀器預測和了解其行為。我們進一步說明了實現此願景的挑戰、機會和需求，包括數據需求、評估策略，以及確保生物準確性和廣泛實用性的社群標準和參與。我們預想一個未來，其中 AI 虛擬細胞有助於識別新的藥物目標、預測細胞對擾動的反應，以及擴大假設探索。透過跨生物醫學生態系統的開放科學合作，其中包括學術界、慈善事業，以及生物製藥和 AI 產業，對於細胞機制和交互作用的全面預測性理解即在我們掌握之中。

##### **Art and Science of Quantizing Large-Scale Models: A Comprehensive Overview**
2409.11650v1 by Yanshu Wang, Tong Yang, Xiyan Liang, Guoan Wang, Hanning Lu, Xu Zhe, Yaoming Li, Li Weitao

This paper provides a comprehensive overview of the principles, challenges,
and methodologies associated with quantizing large-scale neural network models.
As neural networks have evolved towards larger and more complex architectures
to address increasingly sophisticated tasks, the computational and energy costs
have escalated significantly. We explore the necessity and impact of model size
growth, highlighting the performance benefits as well as the computational
challenges and environmental considerations. The core focus is on model
quantization as a fundamental approach to mitigate these challenges by reducing
model size and improving efficiency without substantially compromising
accuracy. We delve into various quantization techniques, including both
post-training quantization (PTQ) and quantization-aware training (QAT), and
analyze several state-of-the-art algorithms such as LLM-QAT, PEQA(L4Q),
ZeroQuant, SmoothQuant, and others. Through comparative analysis, we examine
how these methods address issues like outliers, importance weighting, and
activation quantization, ultimately contributing to more sustainable and
accessible deployment of large-scale models.

摘要：本文全面概述了与量化大规模神经网络模型相关的原则、挑战和方法。
随着神经网络向更大、更复杂的架构发展以解决日益复杂的任务，计算和能源成本大幅增加。我们探讨了模型规模增长的必要性和影响，重点介绍了性能优势以及计算挑战和环境考量。核心重点是模型量化，作为一种通过减小模型规模和提高效率来缓解这些挑战的基本方法，而不会大幅降低准确性。我们深入研究了各种量化技术，包括训练后量化 (PTQ) 和感知量化训练 (QAT)，并分析了几种最先进的算法，例如 LLM-QAT、PEQA(L4Q)、ZeroQuant、SmoothQuant 等。通过比较分析，我们探讨了这些方法如何解决异常值、重要性加权和激活量化等问题，最终有助于大规模模型更可持续、更易于部署。

##### **Combating Phone Scams with LLM-based Detection: Where Do We Stand?**
2409.11643v1 by Zitong Shen, Kangzhong Wang, Youqian Zhang, Grace Ngai, Eugene Y. Fu

Phone scams pose a significant threat to individuals and communities, causing
substantial financial losses and emotional distress. Despite ongoing efforts to
combat these scams, scammers continue to adapt and refine their tactics, making
it imperative to explore innovative countermeasures. This research explores the
potential of large language models (LLMs) to provide detection of fraudulent
phone calls. By analyzing the conversational dynamics between scammers and
victims, LLM-based detectors can identify potential scams as they occur,
offering immediate protection to users. While such approaches demonstrate
promising results, we also acknowledge the challenges of biased datasets,
relatively low recall, and hallucinations that must be addressed for further
advancement in this field

摘要：電話詐騙對個人和社群構成重大威脅，造成龐大的金錢損失和情緒困擾。儘管持續努力打擊這些詐騙，詐騙集團仍持續調整和改進其策略，因此急需探索創新的反制措施。本研究探討大型語言模型 (LLM) 在偵測詐騙電話方面的潛力。透過分析詐騙集團與受害者之間的對話動態，基於 LLM 的偵測器可以識別潛在詐騙，在詐騙發生時提供即時保護給使用者。雖然此類方法展現出有希望的成果，我們也承認有偏誤的資料集、相對較低的召回率和幻覺等挑戰，必須加以解決才能進一步推動此領域的進展

##### **BanStereoSet: A Dataset to Measure Stereotypical Social Biases in LLMs for Bangla**
2409.11638v1 by Mahammed Kamruzzaman, Abdullah Al Monsur, Shrabon Das, Enamul Hassan, Gene Louis Kim

This study presents BanStereoSet, a dataset designed to evaluate
stereotypical social biases in multilingual LLMs for the Bangla language. In an
effort to extend the focus of bias research beyond English-centric datasets, we
have localized the content from the StereoSet, IndiBias, and Kamruzzaman et.
al.'s datasets, producing a resource tailored to capture biases prevalent
within the Bangla-speaking community. Our BanStereoSet dataset consists of
1,194 sentences spanning 9 categories of bias: race, profession, gender,
ageism, beauty, beauty in profession, region, caste, and religion. This dataset
not only serves as a crucial tool for measuring bias in multilingual LLMs but
also facilitates the exploration of stereotypical bias across different social
categories, potentially guiding the development of more equitable language
technologies in Bangladeshi contexts. Our analysis of several language models
using this dataset indicates significant biases, reinforcing the necessity for
culturally and linguistically adapted datasets to develop more equitable
language technologies.

摘要：本研究提出 BanStereoSet，一種資料集，用於評估孟加拉語多語言 LLM 中的刻板社會偏見。為了將偏見研究的重點擴展到以英語為中心的資料集之外，我們已將 StereoSet、IndiBias 和 Kamruzzaman 等人的資料集中的內容在地化，製作出一份量身打造的資源，用於捕捉孟加拉語社群中普遍存在的偏見。我們的 BanStereoSet 資料集包含 1,194 個句子，涵蓋 9 類偏見：種族、職業、性別、年齡歧視、美貌、職業中的美貌、地區、種姓和宗教。此資料集不僅可作為衡量多語言 LLM 中偏見的重要工具，而且有助於探索不同社會類別中的刻板偏見，並可能指導在孟加拉國背景下開發更公平的語言技術。我們使用此資料集對多個語言模型進行分析，結果顯示出顯著的偏見，這強化了開發更公平的語言技術，需要採用文化和語言適應資料集的必要性。

##### **"A Woman is More Culturally Knowledgeable than A Man?": The Effect of Personas on Cultural Norm Interpretation in LLMs**
2409.11636v1 by Mahammed Kamruzzaman, Hieu Nguyen, Nazmul Hassan, Gene Louis Kim

As the deployment of large language models (LLMs) expands, there is an
increasing demand for personalized LLMs. One method to personalize and guide
the outputs of these models is by assigning a persona -- a role that describes
the expected behavior of the LLM (e.g., a man, a woman, an engineer). This
study investigates whether an LLM's understanding of social norms varies across
assigned personas. Ideally, the perception of a social norm should remain
consistent regardless of the persona, since acceptability of a social norm
should be determined by the region the norm originates from, rather than by
individual characteristics such as gender, body size, or race. A norm is
universal within its cultural context. In our research, we tested 36 distinct
personas from 12 sociodemographic categories (e.g., age, gender, beauty) across
four different LLMs. We find that LLMs' cultural norm interpretation varies
based on the persona used and the norm interpretation also varies within a
sociodemographic category (e.g., a fat person and a thin person as in physical
appearance group) where an LLM with the more socially desirable persona (e.g.,
a thin person) interprets social norms more accurately than with the less
socially desirable persona (e.g., a fat person). We also discuss how different
types of social biases may contribute to the results that we observe.

摘要：隨著大型語言模型 (LLM) 的部署擴展，對個性化 LLM 的需求也越來越大。一種個性化和引導這些模型輸出結果的方法是指定一個角色，即描述 LLM 預期行為的角色（例如，男人、女人、工程師）。本研究探討 LLM 對社會規範的理解是否會因指定的角色而異。理想情況下，對社會規範的認知應保持一致，無論角色為何，因為對社會規範的可接受性應取決於規範的來源地區，而不是取決於性別、體型或種族等個人特徵。規範在其文化背景中是普遍的。在我們的研究中，我們在四個不同的 LLM 中測試了來自 12 個社會人口類別（例如，年齡、性別、美麗）的 36 個不同的角色。我們發現，LLM 的文化規範解讀會根據所使用的角色而有所不同，而且規範解讀也會在社會人口類別中有所不同（例如，一個胖子和一個瘦子，就像在身體外觀組中），其中具有較高社會期望的角色（例如，一個瘦子）比具有較低社會期望的角色（例如，一個胖子）更準確地解讀社會規範。我們還討論了不同類型的社會偏見如何導致我們觀察到的結果。

##### **A Metric Hybrid Planning Approach to Solving Pandemic Planning Problems with Simple SIR Models**
2409.11631v1 by Ari Gestetner, Buser Say

A pandemic is the spread of a disease across large regions, and can have
devastating costs to the society in terms of health, economic and social. As
such, the study of effective pandemic mitigation strategies can yield
significant positive impact on the society. A pandemic can be mathematically
described using a compartmental model, such as the Susceptible Infected Removed
(SIR) model. In this paper, we extend the solution equations of the SIR model
to a state transition model with lockdowns. We formalize a metric hybrid
planning problem based on this state transition model, and solve it using a
metric hybrid planner. We improve the runtime effectiveness of the metric
hybrid planner with the addition of valid inequalities, and demonstrate the
success of our approach both theoretically and experimentally under various
challenging settings.

摘要：流行病是指疾病在大範圍地區傳播，且可能對社會在健康、經濟和社會方面造成毀滅性的成本。因此，研究有效的流行病緩解策略可以對社會產生顯著的正面影響。流行病可以用區室模型來數學描述，例如易感者、感染者、移除者 (SIR) 模型。在本文中，我們將 SIR 模型的求解方程式擴展到帶封鎖的狀態轉換模型。我們根據此狀態轉換模型形式化了一個度量混合規劃問題，並使用度量混合規劃器來解決它。我們透過新增有效不等式來改善度量混合規劃器的執行時間效率，並在各種具有挑戰性的設定下理論上和實驗上證明了我們方法的成功。

##### **Harnessing AI data-driven global weather models for climate attribution: An analysis of the 2017 Oroville Dam extreme atmospheric river**
2409.11605v1 by Jorge Baño-Medina, Agniv Sengupta, Allison Michaelis, Luca Delle Monache, Julie Kalansky, Duncan Watson-Parris

AI data-driven models (Graphcast, Pangu Weather, Fourcastnet, and SFNO) are
explored for storyline-based climate attribution due to their short inference
times, which can accelerate the number of events studied, and provide real time
attributions when public attention is heightened. The analysis is framed on the
extreme atmospheric river episode of February 2017 that contributed to the
Oroville dam spillway incident in Northern California. Past and future
simulations are generated by perturbing the initial conditions with the
pre-industrial and the late-21st century temperature climate change signals,
respectively. The simulations are compared to results from a dynamical model
which represents plausible pseudo-realities under both climate environments.
Overall, the AI models show promising results, projecting a 5-6 % increase in
the integrated water vapor over the Oroville dam in the present day compared to
the pre-industrial, in agreement with the dynamical model. Different
geopotential-moisture-temperature dependencies are unveiled for each of the
AI-models tested, providing valuable information for understanding the
physicality of the attribution response. However, the AI models tend to
simulate weaker attribution values than the pseudo-reality imagined by the
dynamical model, suggesting some reduced extrapolation skill, especially for
the late-21st century regime. Large ensembles generated with an AI model (>500
members) produced statistically significant present-day to pre-industrial
attribution results, unlike the >20-member ensemble from the dynamical model.
This analysis highlights the potential of AI models to conduct attribution
analysis, while emphasizing future lines of work on explainable artificial
intelligence to gain confidence in these tools, which can enable reliable
attribution studies in real-time.

摘要：<paragraph>由於 AI 資料驅動模式（Graphcast、Pangu Weather、Fourcastnet 和 SFNO）推論時間短，因此可探索用於基於故事情節的氣候歸因，這可以加速研究事件數量，並在公眾關注度提高時提供實時歸因。分析基於 2017 年 2 月極端大氣河流事件，該事件導致了北加州奧羅維爾大壩溢洪道事件。通過分別用前工業時代和 21 世紀末的溫度氣候變化信號擾動初始條件，產生過去和未來的模擬。將模擬與動態模型的結果進行比較，該模型表示在兩種氣候環境下的合理偽現實。總體而言，AI 模型顯示出有希望的結果，預測與前工業時代相比，當今奧羅維爾大壩上的積分水汽增加 5-6%，與動態模型一致。揭示了每個測試的 AI 模型不同的地勢能-水分-溫度依賴性，為理解歸因響應的物理性提供了有價值的信息。然而，AI 模型傾向於模擬比動態模型想像的偽現實更弱的歸因值，這表明一些外推技能降低了，特別是對於 21 世紀末的狀態。使用 AI 模型生成的大型集合（>500 個成員）產生了統計上顯著的當前到前工業時代的歸因結果，這與動態模型的 >20 個成員集合不同。該分析強調了 AI 模型進行歸因分析的潛力，同時強調了對可解釋人工智能的未來工作線，以增強對這些工具的信心，從而能夠實時進行可靠的歸因研究。</paragraph>

##### **No Saved Kaleidosope: an 100% Jitted Neural Network Coding Language with Pythonic Syntax**
2409.11600v1 by Augusto Seben da Rosa, Marlon Daniel Angeli, Jorge Aikes Junior, Alef Iury Ferreira, Lucas Rafael Gris, Anderson da Silva Soares, Arnaldo Candido Junior, Frederico Santos de Oliveira, Gabriel Trevisan Damke, Rafael Teixeira Sousa

We developed a jitted compiler for training Artificial Neural Networks using
C++, LLVM and Cuda. It features object-oriented characteristics, strong typing,
parallel workers for data pre-processing, pythonic syntax for expressions,
PyTorch like model declaration and Automatic Differentiation. We implement the
mechanisms of cache and pooling in order to manage VRAM, cuBLAS for high
performance matrix multiplication and cuDNN for convolutional layers. Our
experiments with Residual Convolutional Neural Networks on ImageNet, we reach
similar speed but degraded performance. Also, the GRU network experiments show
similar accuracy, but our compiler have degraded speed in that task. However,
our compiler demonstrates promising results at the CIFAR-10 benchmark, in which
we reach the same performance and about the same speed as PyTorch. We make the
code publicly available at: https://github.com/NoSavedDATA/NoSavedKaleidoscope

摘要：我們開發了一個使用 C++、LLVM 和 Cuda 訓練人工神經網路的 jit 編譯器。它具有物件導向特性、強型別、平行工作執行緒以進行資料前處理、pythonic 語法來表示運算式、PyTorch 類型的模型宣告和自動微分。我們實作快取和池化的機制來管理 VRAM，使用 cuBLAS 進行高性能矩陣乘法，並使用 cuDNN 進行卷積層。我們在 ImageNet 上使用殘差卷積神經網路進行的實驗，達到了類似的速度，但效能下降。此外，GRU 網路實驗顯示出類似的準確度，但我們的編譯器在該任務中的速度下降。然而，我們的編譯器在 CIFAR-10 效能測試中表現出令人滿意的結果，其中我們達到了與 PyTorch 相同的效能和速度。我們在 https://github.com/NoSavedDATA/NoSavedKaleidoscope 公開程式碼。

##### **Towards Fair RAG: On the Impact of Fair Ranking in Retrieval-Augmented Generation**
2409.11598v1 by To Eun Kim, Fernando Diaz

Many language models now enhance their responses with retrieval capabilities,
leading to the widespread adoption of retrieval-augmented generation (RAG)
systems. However, despite retrieval being a core component of RAG, much of the
research in this area overlooks the extensive body of work on fair ranking,
neglecting the importance of considering all stakeholders involved. This paper
presents the first systematic evaluation of RAG systems integrated with fair
rankings. We focus specifically on measuring the fair exposure of each relevant
item across the rankings utilized by RAG systems (i.e., item-side fairness),
aiming to promote equitable growth for relevant item providers. To gain a deep
understanding of the relationship between item-fairness, ranking quality, and
generation quality in the context of RAG, we analyze nine different RAG systems
that incorporate fair rankings across seven distinct datasets. Our findings
indicate that RAG systems with fair rankings can maintain a high level of
generation quality and, in many cases, even outperform traditional RAG systems,
despite the general trend of a tradeoff between ensuring fairness and
maintaining system-effectiveness. We believe our insights lay the groundwork
for responsible and equitable RAG systems and open new avenues for future
research. We publicly release our codebase and dataset at
https://github.com/kimdanny/Fair-RAG.

摘要：許多語言模型現在都透過擷取功能來增強其回應，導致廣泛採用擷取增強生成 (RAG) 系統。然而，儘管擷取是 RAG 的核心組成部分，但這個領域的大部分研究都忽略了公平排名的大量研究成果，忽視了考量所有相關利害關係人的重要性。本文首次對整合公平排名的 RAG 系統進行系統性評估。我們特別關注衡量 RAG 系統所使用的排名中每個相關項目的公平曝光度（即項目端公平性），旨在促進相關項目提供者的公平成長。為了深入了解 RAG 背景下項目公平性、排名品質和生成品質之間的關係，我們分析了九個不同的 RAG 系統，這些系統在七個不同的資料集上納入了公平排名。我們的研究結果表明，具有公平排名的 RAG 系統可以維持高水準的生成品質，在許多情況下甚至優於傳統的 RAG 系統，儘管在確保公平性和維持系統效能之間存在權衡取捨的普遍趨勢。我們相信我們的見解為負責任且公平的 RAG 系統奠定了基礎，並為未來的研究打開了新的途徑。我們在 https://github.com/kimdanny/Fair-RAG 上公開發布我們的程式碼庫和資料集。

##### **Self-Contrastive Forward-Forward Algorithm**
2409.11593v1 by Xing Chen, Dongshu Liu, Jeremie Laydevant, Julie Grollier

The Forward-Forward (FF) algorithm is a recent, purely forward-mode learning
method, that updates weights locally and layer-wise and supports supervised as
well as unsupervised learning. These features make it ideal for applications
such as brain-inspired learning, low-power hardware neural networks, and
distributed learning in large models. However, while FF has shown promise on
written digit recognition tasks, its performance on natural images and
time-series remains a challenge. A key limitation is the need to generate
high-quality negative examples for contrastive learning, especially in
unsupervised tasks, where versatile solutions are currently lacking. To address
this, we introduce the Self-Contrastive Forward-Forward (SCFF) method, inspired
by self-supervised contrastive learning. SCFF generates positive and negative
examples applicable across different datasets, surpassing existing local
forward algorithms for unsupervised classification accuracy on MNIST (MLP:
98.7%), CIFAR-10 (CNN: 80.75%), and STL-10 (CNN: 77.3%). Additionally, SCFF is
the first to enable FF training of recurrent neural networks, opening the door
to more complex tasks and continuous-time video and text processing.

摘要：前向-前向 (FF) 算法是一种最近的纯前向模式学习方法，它以局部和逐层的方式更新权重，并支持有监督和无监督学习。这些特性使其非常适合大脑启发式学习、低功耗硬件神经网络以及大型模型中的分布式学习等应用。然而，虽然 FF 在手写数字识别任务上表现出了前景，但其在自然图像和时间序列上的表现仍然是一个挑战。一个关键限制是需要为对比学习生成高质量的负面示例，尤其是在无监督任务中，目前缺乏通用的解决方案。为了解决这个问题，我们引入了自对比前向-前向 (SCFF) 方法，其灵感来自自监督对比学习。SCFF 生成了适用于不同数据集的正负示例，在 MNIST (MLP: 98.7%)、CIFAR-10 (CNN: 80.75%) 和 STL-10 (CNN: 77.3%) 上的无监督分类准确率方面超越了现有的局部前向算法。此外，SCFF 是第一个支持 FF 训练循环神经网络的算法，为更复杂的任务以及连续时间视频和文本处理打开了大门。

##### **ProSLM : A Prolog Synergized Language Model for explainable Domain Specific Knowledge Based Question Answering**
2409.11589v1 by Priyesh Vakharia, Abigail Kufeldt, Max Meyers, Ian Lane, Leilani Gilpin

Neurosymbolic approaches can add robustness to opaque neural systems by
incorporating explainable symbolic representations. However, previous
approaches have not used formal logic to contextualize queries to and validate
outputs of large language models (LLMs). We propose \systemname{}, a novel
neurosymbolic framework, to improve the robustness and reliability of LLMs in
question-answering tasks. We provide \systemname{} with a domain-specific
knowledge base, a logical reasoning system, and an integration to an existing
LLM. This framework has two capabilities (1) context gathering: generating
explainable and relevant context for a given query, and (2) validation:
confirming and validating the factual accuracy of a statement in accordance
with a knowledge base (KB). Our work opens a new area of neurosymbolic
generative AI text validation and user personalization.

摘要：神經符號方法可透過納入可解釋的符號表示，為不透明的神經系統增加穩健性。然而，先前的做法並未使用形式邏輯將查詢脈絡化，也未驗證大型語言模型 (LLM) 的輸出。我們提出創新的神經符號架構 \systemname{}，以提升 LLM 在問答任務中的穩健性和可靠性。我們為 \systemname{} 提供特定領域的知識庫、邏輯推理系統，以及與現有 LLM 的整合。此架構具備兩項功能：(1) 脈絡收集：為特定查詢產生可解釋且相關的脈絡，以及 (2) 驗證：根據知識庫 (KB) 確認並驗證陳述的事實準確性。我們的研究開啟了神經符號生成式 AI 文字驗證和使用者個人化的全新領域。

##### **Uncertainty Decomposition and Error Margin Detection of Homodyned-K Distribution in Quantitative Ultrasound**
2409.11583v1 by Dorsa Ameri, Ali K. Z. Tehrani, Ivan M. Rosado-Mendez, Hassan Rivaz

Homodyned K-distribution (HK-distribution) parameter estimation in
quantitative ultrasound (QUS) has been recently addressed using Bayesian Neural
Networks (BNNs). BNNs have been shown to significantly reduce computational
time in speckle statistics-based QUS without compromising accuracy and
precision. Additionally, they provide estimates of feature uncertainty, which
can guide the clinician's trust in the reported feature value. The total
predictive uncertainty in Bayesian modeling can be decomposed into epistemic
(uncertainty over the model parameters) and aleatoric (uncertainty inherent in
the data) components. By decomposing the predictive uncertainty, we can gain
insights into the factors contributing to the total uncertainty. In this study,
we propose a method to compute epistemic and aleatoric uncertainties for
HK-distribution parameters ($\alpha$ and $k$) estimated by a BNN, in both
simulation and experimental data. In addition, we investigate the relationship
between the prediction error and both uncertainties, shedding light on the
interplay between these uncertainties and HK parameters errors.

摘要：同調 K 分布 (HK 分布) 參數估計在定量超音波 (QUS) 中最近已使用貝氏神經網路 (BNN) 進行處理。已證實 BNN 能顯著減少基於散斑統計的 QUS 中的運算時間，同時不影響準確度和精密度。此外，它們能提供特徵不確定性的估計，這可以引導臨床醫生信任所報告的特徵值。貝氏建模中的總預測不確定性可分解為認識論 (模型參數的不確定性) 和隨機 (資料中固有的不確定性) 組成。透過分解預測不確定性，我們可以深入了解造成總不確定性的因素。在本研究中，我們提出一個方法來計算 BNN 估計的 HK 分布參數 ($\alpha$ 和 $k$) 的認識論和隨機不確定性，這適用於模擬和實驗資料。此外，我們探討預測誤差與這兩種不確定性之間的關係，進而說明這些不確定性和 HK 參數誤差之間的交互作用。

##### **HEARTS: A Holistic Framework for Explainable, Sustainable and Robust Text Stereotype Detection**
2409.11579v1 by Theo King, Zekun Wu, Adriano Koshiyama, Emre Kazim, Philip Treleaven

Stereotypes are generalised assumptions about societal groups, and even
state-of-the-art LLMs using in-context learning struggle to identify them
accurately. Due to the subjective nature of stereotypes, where what constitutes
a stereotype can vary widely depending on cultural, social, and individual
perspectives, robust explainability is crucial. Explainable models ensure that
these nuanced judgments can be understood and validated by human users,
promoting trust and accountability. We address these challenges by introducing
HEARTS (Holistic Framework for Explainable, Sustainable, and Robust Text
Stereotype Detection), a framework that enhances model performance, minimises
carbon footprint, and provides transparent, interpretable explanations. We
establish the Expanded Multi-Grain Stereotype Dataset (EMGSD), comprising
57,201 labeled texts across six groups, including under-represented
demographics like LGBTQ+ and regional stereotypes. Ablation studies confirm
that BERT models fine-tuned on EMGSD outperform those trained on individual
components. We then analyse a fine-tuned, carbon-efficient ALBERT-V2 model
using SHAP to generate token-level importance values, ensuring alignment with
human understanding, and calculate explainability confidence scores by
comparing SHAP and LIME outputs. Finally, HEARTS is applied to assess
stereotypical bias in 12 LLM outputs, revealing a gradual reduction in bias
over time within model families.

摘要：刻板印象是对社会群体的概括性假设，即使是使用情境学习的最新 LLM 也难以准确识别它们。由于刻板印象的主观性，根据文化、社会和个人的观点，构成刻板印象的内容可能差异很大，因此，稳健的可解释性至关重要。可解释模型确保人类用户可以理解和验证这些细微的判断，从而促进信任和问责制。我们通过引入 HEARTS（可解释、可持续和稳健文本刻板印象检测的整体框架）来应对这些挑战，该框架增强了模型性能，最大程度地减少了碳足迹，并提供了透明、可解释的解释。我们建立了扩展的多粒度刻板印象数据集 (EMGSD)，其中包含 57,201 个跨六个组的标记文本，包括 LGBTQ+ 和区域刻板印象等代表性不足的人口统计数据。消融研究证实，在 EMGSD 上微调的 BERT 模型优于在各个组件上训练的模型。然后，我们使用 SHAP 分析经过微调的、碳效率高的 ALBERT-V2 模型，以生成令牌级重要性值，确保与人类理解保持一致，并通过比较 SHAP 和 LIME 输出计算可解释性置信度分数。最后，HEARTS 用于评估 12 个 LLM 输出中的刻板印象偏差，揭示了模型系列中随着时间的推移偏差逐渐减少。

##### **Automating proton PBS treatment planning for head and neck cancers using policy gradient-based deep reinforcement learning**
2409.11576v1 by Qingqing Wang, Chang Chang

Proton pencil beam scanning (PBS) treatment planning for head and neck (H&N)
cancers is a time-consuming and experience-demanding task where a large number
of planning objectives are involved. Deep reinforcement learning (DRL) has
recently been introduced to the planning processes of intensity-modulated
radiation therapy and brachytherapy for prostate, lung, and cervical cancers.
However, existing approaches are built upon the Q-learning framework and
weighted linear combinations of clinical metrics, suffering from poor
scalability and flexibility and only capable of adjusting a limited number of
planning objectives in discrete action spaces. We propose an automatic
treatment planning model using the proximal policy optimization (PPO) algorithm
and a dose distribution-based reward function for proton PBS treatment planning
of H&N cancers. Specifically, a set of empirical rules is used to create
auxiliary planning structures from target volumes and organs-at-risk (OARs),
along with their associated planning objectives. These planning objectives are
fed into an in-house optimization engine to generate the spot monitor unit (MU)
values. A decision-making policy network trained using PPO is developed to
iteratively adjust the involved planning objective parameters in a continuous
action space and refine the PBS treatment plans using a novel dose
distribution-based reward function. Proton H&N treatment plans generated by the
model show improved OAR sparing with equal or superior target coverage when
compared with human-generated plans. Moreover, additional experiments on liver
cancer demonstrate that the proposed method can be successfully generalized to
other treatment sites. To the best of our knowledge, this is the first
DRL-based automatic treatment planning model capable of achieving human-level
performance for H&N cancers.

摘要：質子筆狀束掃描（PBS）治療計畫的頭頸部（H&N）癌症是一個耗時且需要經驗的任務，其中涉及大量的計畫目標。深度強化學習（DRL）最近被引入強度調控放射治療和前列腺、肺和子宮頸癌的近接治療的計畫過程中。然而，現有的方法建立在 Q 學習架構和臨床指標的加權線性組合之上，存在可擴充性和靈活性差，只能在離散動作空間中調整有限數量的計畫目標。我們提出了一個使用近端策略最佳化（PPO）演算法和基於劑量分佈的獎勵函數的自動治療計畫模型，用於 H&N 癌症的質子 PBS 治療計畫。具體來說，使用一組經驗法則從目標體積和受風險器官（OAR）建立輔助計畫結構，連同它們相關的計畫目標。這些計畫目標被輸入到內部最佳化引擎中以產生點監測單位（MU）值。開發了一個使用 PPO 訓練的決策制定策略網路，以在連續動作空間中反覆調整所涉及的計畫目標參數，並使用新的基於劑量分佈的獎勵函數優化 PBS 治療計畫。與人為產生的計畫相比，模型產生的質子 H&N 治療計畫顯示出改善的 OAR 保護，同時具有相等或更好的目標覆蓋率。此外，對肝癌的額外實驗表明，所提出的方法可以成功地推廣到其他治療部位。據我們所知，這是第一個基於 DRL 的自動治療計畫模型，能夠為 H&N 癌症實現人類等級的效能。

##### **Preference Tuning with Human Feedback on Language, Speech, and Vision Tasks: A Survey**
2409.11564v1 by Genta Indra Winata, Hanyang Zhao, Anirban Das, Wenpin Tang, David D. Yao, Shi-Xiong Zhang, Sambit Sahu

Preference tuning is a crucial process for aligning deep generative models
with human preferences. This survey offers a thorough overview of recent
advancements in preference tuning and the integration of human feedback. The
paper is organized into three main sections: 1) introduction and preliminaries:
an introduction to reinforcement learning frameworks, preference tuning tasks,
models, and datasets across various modalities: language, speech, and vision,
as well as different policy approaches, 2) in-depth examination of each
preference tuning approach: a detailed analysis of the methods used in
preference tuning, and 3) applications, discussion, and future directions: an
exploration of the applications of preference tuning in downstream tasks,
including evaluation methods for different modalities, and an outlook on future
research directions. Our objective is to present the latest methodologies in
preference tuning and model alignment, enhancing the understanding of this
field for researchers and practitioners. We hope to encourage further
engagement and innovation in this area.

摘要：偏好調整是將深度生成模型與人類偏好對齊的關鍵過程。這項調查提供了偏好調整和整合人類回饋的最新進展的全面概述。本文分為三個主要部分：1）引言和預備知識：強化學習框架、偏好調整任務、模型和各種模式（語言、語音和視覺）的資料集，以及不同的政策方法的介紹，2）深入探討每種偏好調整方法：詳細分析偏好調整中使用的方法，以及 3）應用、討論和未來方向：探索偏好調整在下游任務中的應用，包括不同模式的評估方法，以及對未來研究方向的展望。我們的目標是介紹偏好調整和模型對齊的最新方法，以增強研究人員和從業人員對這個領域的理解。我們希望鼓勵進一步參與和創新這個領域。

##### **Multi-Domain Data Aggregation for Axon and Myelin Segmentation in Histology Images**
2409.11552v1 by Armand Collin, Arthur Boschet, Mathieu Boudreau, Julien Cohen-Adad

Quantifying axon and myelin properties (e.g., axon diameter, myelin
thickness, g-ratio) in histology images can provide useful information about
microstructural changes caused by neurodegenerative diseases. Automatic tissue
segmentation is an important tool for these datasets, as a single stained
section can contain up to thousands of axons. Advances in deep learning have
made this task quick and reliable with minimal overhead, but a deep learning
model trained by one research group will hardly ever be usable by other groups
due to differences in their histology training data. This is partly due to
subject diversity (different body parts, species, genetics, pathologies) and
also to the range of modern microscopy imaging techniques resulting in a wide
variability of image features (i.e., contrast, resolution). There is a pressing
need to make AI accessible to neuroscience researchers to facilitate and
accelerate their workflow, but publicly available models are scarce and poorly
maintained. Our approach is to aggregate data from multiple imaging modalities
(bright field, electron microscopy, Raman spectroscopy) and species (mouse,
rat, rabbit, human), to create an open-source, durable tool for axon and myelin
segmentation. Our generalist model makes it easier for researchers to process
their data and can be fine-tuned for better performance on specific domains. We
study the benefits of different aggregation schemes. This multi-domain
segmentation model performs better than single-modality dedicated learners
(p=0.03077), generalizes better on out-of-distribution data and is easier to
use and maintain. Importantly, we package the segmentation tool into a
well-maintained open-source software ecosystem (see
https://github.com/axondeepseg/axondeepseg).

摘要：<paragraph>量化组织学图像中的轴突和髓鞘特性（例如，轴突直径、髓鞘厚度、g 比率）可以提供有关神经退行性疾病引起微观结构变化的有用信息。自动组织分割是这些数据集的重要工具，因为一个单一的染色切片可以包含多达数千个轴突。深度学习的进步使这项任务快速且可靠，且开销最小，但是一个研究小组训练的深度学习模型几乎不可能被其他小组使用，因为他们的组织学训练数据存在差异。这部分是由于受试者多样性（不同的身体部位、物种、遗传学、病理学）以及现代显微成像技术的范围导致图像特征（即对比度、分辨率）有很大差异。迫切需要让神经科学研究人员可以使用 AI，以促进和加速他们的工作流程，但公开可用的模型稀缺且维护不善。我们的方法是汇总来自多种成像方式（明场、电子显微镜、拉曼光谱）和物种（小鼠、大鼠、兔子、人类）的数据，以创建用于轴突和髓鞘分割的开源、耐用的工具。我们的通用模型使研究人员更容易处理他们的数据，并且可以针对特定域进行微调以获得更好的性能。我们研究了不同聚合方案的好处。这种多域分割模型比单模态专用学习器（p=0.03077）表现得更好，在分布外数据上泛化得更好，并且更容易使用和维护。重要的是，我们将分割工具打包到维护良好的开源软件生态系统中（请参阅 https://github.com/axondeepseg/axondeepseg）。</paragraph>

##### **Small Language Models can Outperform Humans in Short Creative Writing: A Study Comparing SLMs with Humans and LLMs**
2409.11547v1 by Guillermo Marco, Luz Rello, Julio Gonzalo

In this paper, we evaluate the creative fiction writing abilities of a
fine-tuned small language model (SLM), BART Large, and compare its performance
to humans and two large language models (LLMs): GPT-3.5 and GPT-4o. Our
evaluation consists of two experiments: (i) a human evaluation where readers
assess the stories generated by the SLM compared to human-written stories, and
(ii) a qualitative linguistic analysis comparing the textual characteristics of
the stories generated by the different models. In the first experiment, we
asked 68 participants to rate short stories generated by the models and humans
along dimensions such as grammaticality, relevance, creativity, and
attractiveness. BART Large outperformed human writers in most aspects, except
creativity, with an overall score of 2.11 compared to 1.85 for human-written
texts -- a 14% improvement. In the second experiment, the qualitative analysis
revealed that, while GPT-4o exhibited near-perfect internal and external
coherence, it tended to produce more predictable narratives, with only 3% of
its stories seen as novel. In contrast, 15% of BART's stories were considered
novel, indicating a higher degree of creativity despite its smaller model size.
This study provides both quantitative and qualitative insights into how model
size and fine-tuning influence the balance between creativity, fluency, and
coherence in creative writing tasks.

摘要：<paragraph>在本文中，我們評估了一個微調過的小語言模型 (SLM) BART Large 的創作小說寫作能力，並將其表現與人類和兩個大型語言模型 (LLM) 進行比較：GPT-3.5 和 GPT-4o。我們的評估包含兩個實驗：(i) 人類評估，讀者評估 SLM 生成的故事與人類寫的故事相比，以及 (ii) 定性語言分析，比較由不同模型生成的文本特徵。在第一個實驗中，我們要求 68 位參與者評分由模型和人類生成的小故事，評分面向文法性、相關性、創造力和吸引力等面向。BART Large 在大多數方面都優於人類作家，除了創造力，與人類寫作文本的 1.85 相比，其總分為 2.11，進步了 14%。在第二個實驗中，定性分析顯示，儘管 GPT-4o 表現出近乎完美的內部和外部連貫性，但它傾向於產生更可預測的敘事，只有 3% 的故事被視為新穎。相比之下，15% 的 BART 故事被認為是新穎的，這表明儘管模型規模較小，但創造力程度更高。這項研究提供了定量和定性見解，說明模型大小和微調如何影響創作寫作任務中創造力、流暢度和連貫性之間的平衡。</paragraph>

##### **NCT-CRC-HE: Not All Histopathological Datasets Are Equally Useful**
2409.11546v1 by Andrey Ignatov, Grigory Malivenko

Numerous deep learning-based solutions have been proposed for
histopathological image analysis over the past years. While they usually
demonstrate exceptionally high accuracy, one key question is whether their
precision might be affected by low-level image properties not related to
histopathology but caused by microscopy image handling and pre-processing. In
this paper, we analyze a popular NCT-CRC-HE-100K colorectal cancer dataset used
in numerous prior works and show that both this dataset and the obtained
results may be affected by data-specific biases. The most prominent revealed
dataset issues are inappropriate color normalization, severe JPEG artifacts
inconsistent between different classes, and completely corrupted tissue samples
resulting from incorrect image dynamic range handling. We show that even the
simplest model using only 3 features per image (red, green and blue color
intensities) can demonstrate over 50% accuracy on this 9-class dataset, while
using color histogram not explicitly capturing cell morphology features yields
over 82% accuracy. Moreover, we show that a basic EfficientNet-B0 ImageNet
pretrained model can achieve over 97.7% accuracy on this dataset, outperforming
all previously proposed solutions developed for this task, including dedicated
foundation histopathological models and large cell morphology-aware neural
networks. The NCT-CRC-HE dataset is publicly available and can be freely used
to replicate the presented results. The codes and pre-trained models used in
this paper are available at
https://github.com/gmalivenko/NCT-CRC-HE-experiments

摘要：在過去幾年中，已經提出許多基於深度學習的解決方案，用於組織病理學影像分析。雖然它們通常表現出極高的準確度，但一個關鍵問題是它們的精確度是否會受到與組織病理學無關的低階影像屬性影響，但卻是由於顯微鏡影像處理和預處理所造成。在本文中，我們分析了一個在許多先前工作中使用的流行 NCT-CRC-HE-100K 大腸癌資料集，並表明這個資料集和獲得的結果都可能受到資料特定偏差的影響。最明顯的資料集問題是不適當的色彩標準化、不同類別之間嚴重的 JPEG 人工製品，以及由於影像動態範圍處理不正確而導致組織樣本完全損壞。我們表明，即使是最簡單的模型，每個影像僅使用 3 個特徵（紅色、綠色和藍色色彩強度），也能在這個 9 類別的資料集上表現出超過 50% 的準確度，而使用未明確擷取細胞形態特徵的色彩直方圖則可產生超過 82% 的準確度。此外，我們表明一個基本的 EfficientNet-B0 ImageNet 預訓練模型可以在這個資料集上達到超過 97.7% 的準確度，優於所有先前為此任務開發的解決方案，包括專用的基礎組織病理學模型和大型細胞形態感知神經網路。NCT-CRC-HE 資料集公開可用，可以自由使用來複製呈現的結果。本文中使用的程式碼和預訓練模型可在 https://github.com/gmalivenko/NCT-CRC-HE-experiments 取得。

##### **Chain-of-Thought Prompting for Speech Translation**
2409.11538v1 by Ke Hu, Zhehuai Chen, Chao-Han Huck Yang, Piotr Żelasko, Oleksii Hrinchuk, Vitaly Lavrukhin, Jagadeesh Balam, Boris Ginsburg

Large language models (LLMs) have demonstrated remarkable advancements in
language understanding and generation. Building on the success of text-based
LLMs, recent research has adapted these models to use speech embeddings for
prompting, resulting in Speech-LLM models that exhibit strong performance in
automatic speech recognition (ASR) and automatic speech translation (AST). In
this work, we propose a novel approach to leverage ASR transcripts as prompts
for AST in a Speech-LLM built on an encoder-decoder text LLM. The Speech-LLM
model consists of a speech encoder and an encoder-decoder structure
Megatron-T5. By first decoding speech to generate ASR transcripts and
subsequently using these transcripts along with encoded speech for prompting,
we guide the speech translation in a two-step process like chain-of-thought
(CoT) prompting. Low-rank adaptation (LoRA) is used for the T5 LLM for model
adaptation and shows superior performance to full model fine-tuning.
Experimental results show that the proposed CoT prompting significantly
improves AST performance, achieving an average increase of 2.4 BLEU points
across 6 En->X or X->En AST tasks compared to speech prompting alone.
Additionally, compared to a related CoT prediction method that predicts a
concatenated sequence of ASR and AST transcripts, our method performs better by
an average of 2 BLEU points.

摘要：大型語言模型 (LLM) 在語言理解和生成方面已經展現出顯著的進步。建立在基於文字的 LLM 的成功基礎上，最近的研究已經改編這些模型以使用語音嵌入進行提示，產生在自動語音辨識 (ASR) 和自動語音翻譯 (AST) 中表現出強勁效能的 Speech-LLM 模型。在這項工作中，我們提出了一種新穎的方法，以利用 ASR 轉錄作為提示，用於建立在編碼器-解碼器文字 LLM 上的 Speech-LLM 中的 AST。Speech-LLM 模型包含一個語音編碼器和一個編碼器-解碼器結構 Megatron-T5。透過先解碼語音以產生 ASR 轉錄，然後將這些轉錄與編碼語音一起用於提示，我們指導語音翻譯進入一個類似於思考鏈 (CoT) 提示的兩步驟程序。低秩適應 (LoRA) 用於 T5 LLM 的模型適應，並且顯示出優於完整模型微調的效能。實驗結果顯示，所提出的 CoT 提示顯著改善了 AST 效能，在 6 個 En->X 或 X->En AST 任務中，與單獨的語音提示相比，平均增加了 2.4 個 BLEU 點。此外，與預測 ASR 和 AST 轉錄的串聯序列的相關 CoT 預測方法相比，我們的模型平均效能高出 2 個 BLEU 點。

##### **Improving LLM Reasoning with Multi-Agent Tree-of-Thought Validator Agent**
2409.11527v1 by Fatemeh Haji, Mazal Bethany, Maryam Tabar, Jason Chiang, Anthony Rios, Peyman Najafirad

Multi-agent strategies have emerged as a promising approach to enhance the
reasoning abilities of Large Language Models (LLMs) by assigning specialized
roles in the problem-solving process. Concurrently, Tree of Thoughts (ToT)
methods have shown potential in improving reasoning for complex
question-answering tasks by exploring diverse reasoning paths. A critical
limitation in multi-agent reasoning is the 'Reasoner' agent's shallow
exploration of reasoning paths. While ToT strategies could help mitigate this
problem, they may generate flawed reasoning branches, which could harm the
trustworthiness of the final answer. To leverage the strengths of both
multi-agent reasoning and ToT strategies, we introduce a novel approach
combining ToT-based Reasoner agents with a Thought Validator agent. Multiple
Reasoner agents operate in parallel, employing ToT to explore diverse reasoning
paths. The Thought Validator then scrutinizes these paths, considering a
Reasoner's conclusion only if its reasoning is valid. This method enables a
more robust voting strategy by discarding faulty reasoning paths, enhancing the
system's ability to tackle tasks requiring systematic and trustworthy
reasoning. Our method demonstrates superior performance compared to existing
techniques when evaluated on the GSM8K dataset, outperforming the standard ToT
strategy by an average 5.6\% across four LLMs.

摘要：多代理策略已成為一種有前途的方法，可透過在問題解決過程中分配專門角色來增強大型語言模型 (LLM) 的推理能力。同時，思想樹 (ToT) 方法已展現出改善複雜問答任務推理的潛力，方法是探索多樣的推理路徑。多代理推理的一個關鍵限制是「推理者」代理對推理路徑的探索很淺。雖然 ToT 策略有助於減輕此問題，但它們可能會產生有缺陷的推理分支，這可能會損害最終答案的可信度。為了利用多代理推理和 ToT 策略的優點，我們提出了一種新穎方法，將基於 ToT 的推理代理與思想驗證代理結合起來。多個推理代理並行運作，利用 ToT 探索多樣的推理路徑。然後，思想驗證器會審查這些路徑，只有推理有效時才會考慮推理者的結論。這種方法透過捨棄有缺陷的推理路徑來實現更強大的投票策略，增強系統處理需要系統且可信推理任務的能力。在 GSM8K 資料集上評估時，我們的模型展現出優於現有技術的效能，在四個 LLM 上平均優於標準 ToT 策略 5.6%。

##### **Mamba Fusion: Learning Actions Through Questioning**
2409.11513v1 by Zhikang Dong, Apoorva Beedu, Jason Sheinkopf, Irfan Essa

Video Language Models (VLMs) are crucial for generalizing across diverse
tasks and using language cues to enhance learning. While transformer-based
architectures have been the de facto in vision-language training, they face
challenges like quadratic computational complexity, high GPU memory usage, and
difficulty with long-term dependencies. To address these limitations, we
introduce MambaVL, a novel model that leverages recent advancements in
selective state space modality fusion to efficiently capture long-range
dependencies and learn joint representations for vision and language data.
MambaVL utilizes a shared state transition matrix across both modalities,
allowing the model to capture information about actions from multiple
perspectives within the scene. Furthermore, we propose a question-answering
task that helps guide the model toward relevant cues. These questions provide
critical information about actions, objects, and environmental context, leading
to enhanced performance. As a result, MambaVL achieves state-of-the-art
performance in action recognition on the Epic-Kitchens-100 dataset and
outperforms baseline methods in action anticipation.

摘要：影片語言模型 (VLM) 對於在各種任務中進行概括和使用語言提示增強學習至關重要。雖然基於變換器的架構一直是視覺語言訓練的事實標準，但它們面臨二次計算複雜度、高 GPU 記憶體使用率和長期依賴性的困難等挑戰。為了解決這些限制，我們引入了 MambaVL，這是一個新穎的模型，利用選擇性狀態空間模態融合的最新進展來有效捕捉遠程依賴性並學習視覺和語言資料的聯合表示。MambaVL 在兩種模態中使用共用的狀態轉換矩陣，使模型能夠捕捉場景中多個視角的動作資訊。此外，我們提出了有助於引導模型朝向相關提示的問答任務。這些問題提供了有關動作、物件和環境背景的重要資訊，從而增強了效能。因此，MambaVL 在 Epic-Kitchens-100 資料集上的動作辨識中達到了最先進的效能，並且在動作預測中優於基線方法。

##### **FedNE: Surrogate-Assisted Federated Neighbor Embedding for Dimensionality Reduction**
2409.11509v1 by Ziwei Li, Xiaoqi Wang, Hong-You Chen, Han-Wei Shen, Wei-Lun Chao

Federated learning (FL) has rapidly evolved as a promising paradigm that
enables collaborative model training across distributed participants without
exchanging their local data. Despite its broad applications in fields such as
computer vision, graph learning, and natural language processing, the
development of a data projection model that can be effectively used to
visualize data in the context of FL is crucial yet remains heavily
under-explored. Neighbor embedding (NE) is an essential technique for
visualizing complex high-dimensional data, but collaboratively learning a joint
NE model is difficult. The key challenge lies in the objective function, as
effective visualization algorithms like NE require computing loss functions
among pairs of data. In this paper, we introduce \textsc{FedNE}, a novel
approach that integrates the \textsc{FedAvg} framework with the contrastive NE
technique, without any requirements of shareable data. To address the lack of
inter-client repulsion which is crucial for the alignment in the global
embedding space, we develop a surrogate loss function that each client learns
and shares with each other. Additionally, we propose a data-mixing strategy to
augment the local data, aiming to relax the problems of invisible neighbors and
false neighbors constructed by the local $k$NN graphs. We conduct comprehensive
experiments on both synthetic and real-world datasets. The results demonstrate
that our \textsc{FedNE} can effectively preserve the neighborhood data
structures and enhance the alignment in the global embedding space compared to
several baseline methods.

摘要：聯合式學習 (FL) 已迅速演變為一種有前途的範例，它可以在分布式參與者之間進行協作模型訓練，而無需交換他們的本地數據。儘管它在電腦視覺、圖形學習和自然語言處理等領域有廣泛的應用，但開發一個數據投影模型，可有效用於在 FL 的背景下視覺化數據，這一點至關重要，但仍未得到充分的探索。鄰域嵌入 (NE) 是用於視覺化複雜高維數據的一項基本技術，但協作學習一個聯合 NE 模型很困難。主要的挑戰在於目標函數，因為像 NE 這樣的有效視覺化演算法需要計算數據對之間的損失函數。在本文中，我們介紹了 \textsc{FedNE}，這是一種新穎的方法，它將 \textsc{FedAvg} 框架與對比 NE 技術相整合，而無需任何可共享數據的要求。為了解決對於在全局嵌入空間中對齊至關重要的客戶端間排斥力不足的問題，我們開發了一個代理損失函數，每個客戶端學習此函數並與彼此共享。此外，我們提出了一種數據混合策略來擴充本地數據，旨在緩解由本地 $k$NN 圖形構造的不可見鄰域和錯誤鄰域的問題。我們在合成和真實世界數據集上進行了全面的實驗。結果表明，與幾種基線方法相比，我們的 \textsc{FedNE} 可以有效地保留鄰域數據結構並增強在全局嵌入空間中的對齊。

##### **Egalitarian Language Representation in Language Models: It All Begins with Tokenizers**
2409.11501v1 by Menan Velayuthan, Kengatharaiyer Sarveswaran

Tokenizers act as a bridge between human language and the latent space of
language models, influencing how language is represented in these models. Due
to the immense popularity of English-Centric Large Language Models (LLMs),
efforts are being made to adapt them for other languages. However, we
demonstrate that, from a tokenization standpoint, not all tokenizers offer fair
representation for complex script languages such as Tamil, Sinhala, and Hindi,
primarily due to the choice of pre-tokenization methods. We go further to show
that pre-tokenization plays a more critical role than the tokenization
algorithm itself in achieving an egalitarian representation of these complex
script languages. To address this, we introduce an improvement to the Byte Pair
Encoding (BPE) algorithm by incorporating graphemes, which we term Grapheme
Pair Encoding (GPE). Our experiments show that grapheme-based character
extraction outperforms byte-level tokenizers for complex scripts. We validate
this approach through experiments on Tamil, Sinhala, and Hindi.

摘要：分词器扮演人类语言和语言模型潜在空间之间的桥梁，影响语言在这些模型中的表示方式。由于以英语为中心的语言模型（LLM）的巨大普及，人们正在努力使它们适应其他语言。然而，我们证明，从标记化的角度来看，并非所有标记器都能为泰米尔语、僧伽罗语和印地语等复杂脚本语言提供公平的表示，这主要是由于预标记化方法的选择。我们进一步表明，预标记化在实现这些复杂脚本语言的平等表示中所扮演的角色比标记化算法本身更关键。为了解决这个问题，我们在字节对编码（BPE）算法中引入了一个改进，通过合并音素，我们称之为音素对编码（GPE）。我们的实验表明，基于音素的字符提取优于字节级标记器，适用于复杂脚本。我们通过对泰米尔语、僧伽罗语和印地语的实验验证了这种方法。

##### **Multi-Document Grounded Multi-Turn Synthetic Dialog Generation**
2409.11500v1 by Young-Suk Lee, Chulaka Gunasekara, Danish Contractor, Ramón Fernandez Astudillo, Radu Florian

We introduce a technique for multi-document grounded multi-turn synthetic
dialog generation that incorporates three main ideas. First, we control the
overall dialog flow using taxonomy-driven user queries that are generated with
Chain-of-Thought (CoT) prompting. Second, we support the generation of
multi-document grounded dialogs by mimicking real-world use of retrievers to
update the grounding documents after every user-turn in the dialog. Third, we
apply LLM-as-a-Judge to filter out queries with incorrect answers. Human
evaluation of the synthetic dialog data suggests that the data is diverse,
coherent, and includes mostly correct answers. Both human and automatic
evaluations of answerable queries indicate that models fine-tuned on synthetic
dialogs consistently out-perform those fine-tuned on existing human generated
training data across four publicly available multi-turn document grounded
benchmark test sets.

摘要：我們提出了一種多文件接地式多輪合成對話生成技術，它包含三個主要想法。首先，我們使用鏈式思考 (CoT) 提示生成的分類驅動使用者查詢來控制整體對話流程。其次，我們支援多文件接地式對話的生成，方法是模擬檢索器的實際使用，以便在對話中每次使用者輪流發言後更新接地文件。第三，我們應用 LLM 作為判斷者來篩選出答案不正確的查詢。對合成對話數據的人工評估表明，這些數據多樣化、連貫，且包含大多數正確答案。可回答查詢的人工和自動評估表明，在合成對話中微調的模型在四個公開的多輪文件接地式基準測試集中，始終優於在現有人類生成的訓練數據中微調的模型。

##### **Augment, Drop & Swap: Improving Diversity in LLM Captions for Efficient Music-Text Representation Learning**
2409.11498v1 by Ilaria Manco, Justin Salamon, Oriol Nieto

Audio-text contrastive models have become a powerful approach in music
representation learning. Despite their empirical success, however, little is
known about the influence of key design choices on the quality of music-text
representations learnt through this framework. In this work, we expose these
design choices within the constraints of limited data and computation budgets,
and establish a more solid understanding of their impact grounded in empirical
observations along three axes: the choice of base encoders, the level of
curation in training data, and the use of text augmentation. We find that data
curation is the single most important factor for music-text contrastive
training in resource-constrained scenarios. Motivated by this insight, we
introduce two novel techniques, Augmented View Dropout and TextSwap, which
increase the diversity and descriptiveness of text inputs seen in training.
Through our experiments we demonstrate that these are effective at boosting
performance across different pre-training regimes, model architectures, and
downstream data distributions, without incurring higher computational costs or
requiring additional training data.

摘要：音訊文字對比模型已成為音樂表示學習中的強大方法。然而，儘管它們在經驗上取得成功，但對於關鍵設計選擇對透過此架構學習的音樂文字表示品質的影響，我們所知甚少。在這項工作中，我們在有限的資料和運算預算限制內揭露這些設計選擇，並根據三個軸線的經驗觀察建立對其影響的更紮實理解：基礎編碼器的選擇、訓練資料中的策展層級，以及文字擴充的使用。我們發現，在資源受限的情況下，資料策展是音樂文字對比訓練中最重要的單一因素。受此見解啟發，我們引入了兩種新技術，擴充檢視中斷和文字交換，它們會增加訓練中看到的文字輸入的多樣性和描述性。透過我們的實驗，我們證明這些技術能有效提升不同預訓練機制、模型架構和下游資料分佈的效能，而不會產生更高的運算成本或需要額外的訓練資料。

##### **Enriching Datasets with Demographics through Large Language Models: What's in a Name?**
2409.11491v1 by Khaled AlNuaimi, Gautier Marti, Mathieu Ravaut, Abdulla AlKetbi, Andreas Henschel, Raed Jaradat

Enriching datasets with demographic information, such as gender, race, and
age from names, is a critical task in fields like healthcare, public policy,
and social sciences. Such demographic insights allow for more precise and
effective engagement with target populations. Despite previous efforts
employing hidden Markov models and recurrent neural networks to predict
demographics from names, significant limitations persist: the lack of
large-scale, well-curated, unbiased, publicly available datasets, and the lack
of an approach robust across datasets. This scarcity has hindered the
development of traditional supervised learning approaches. In this paper, we
demonstrate that the zero-shot capabilities of Large Language Models (LLMs) can
perform as well as, if not better than, bespoke models trained on specialized
data. We apply these LLMs to a variety of datasets, including a real-life,
unlabelled dataset of licensed financial professionals in Hong Kong, and
critically assess the inherent demographic biases in these models. Our work not
only advances the state-of-the-art in demographic enrichment but also opens
avenues for future research in mitigating biases in LLMs.

摘要：利用姓名等人口統計資訊（例如性別、種族和年齡）來豐富資料集，在醫療保健、公共政策和社會科學等領域是一項重要的任務。這些人口統計見解可以更精確有效地與目標族群互動。儘管先前採用隱藏馬可夫模型和遞迴神經網路來根據姓名預測人口統計資料，但仍存在重大限制：缺乏大規模、整理完善、無偏見、公開可用的資料集，以及缺乏在資料集之間強健的方法。這種稀缺性阻礙了傳統監督式學習方法的發展。在本文中，我們證明大型語言模型 (LLM) 的零次學習能力可以表現得和在特定資料上訓練的客製化模型一樣好，甚至更好。我們將這些 LLM 應用於各種資料集，包括香港持照金融專業人士的真實、未標記資料集，並批判性地評估這些模型中固有的 demographic bias。我們的研究不僅提升了人口統計豐富化的最新技術，也為未來在減輕 LLM 中的偏見的研究開啟了道路。

##### **Beyond Algorithmic Fairness: A Guide to Develop and Deploy Ethical AI-Enabled Decision-Support Tools**
2409.11489v1 by Rosemarie Santa Gonzalez, Ryan Piansky, Sue M Bae, Justin Biddle, Daniel Molzahn

The integration of artificial intelligence (AI) and optimization hold
substantial promise for improving the efficiency, reliability, and resilience
of engineered systems. Due to the networked nature of many engineered systems,
ethically deploying methodologies at this intersection poses challenges that
are distinct from other AI settings, thus motivating the development of ethical
guidelines tailored to AI-enabled optimization. This paper highlights the need
to go beyond fairness-driven algorithms to systematically address ethical
decisions spanning the stages of modeling, data curation, results analysis, and
implementation of optimization-based decision support tools. Accordingly, this
paper identifies ethical considerations required when deploying algorithms at
the intersection of AI and optimization via case studies in power systems as
well as supply chain and logistics. Rather than providing a prescriptive set of
rules, this paper aims to foster reflection and awareness among researchers and
encourage consideration of ethical implications at every step of the
decision-making process.

摘要：人工智慧 (AI) 與最佳化整合極具潛力，可提升工程系統的效率、可靠性與韌性。由於許多工程系統具有網路性質，因此在這個交集中以合乎道德的方式部署方法會帶來與其他 AI 設定不同的挑戰，因此有必要制定專門針對 AI 驅動最佳化的道德準則。本文強調需要超越公平驅動演算法，以系統性地處理跨越建模、資料策展、結果分析和最佳化決策支援工具實作階段的道德決策。因此，本文透過電力系統以及供應鏈與物流的案例研究，找出在 AI 與最佳化的交集中部署演算法時所需的道德考量。本文並非提供一組規範性規則，而是旨在促進研究人員的反思與意識，並鼓勵在決策過程的每一步驟中考量道德意涵。

