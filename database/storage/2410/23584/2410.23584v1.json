{"2410.23584": {"publish_time": "2024-10-31", "title": "End-to-End Ontology Learning with Large Language Models", "paper_summary": "Ontologies are useful for automatic machine processing of domain knowledge as\nthey represent it in a structured format. Yet, constructing ontologies requires\nsubstantial manual effort. To automate part of this process, large language\nmodels (LLMs) have been applied to solve various subtasks of ontology learning.\nHowever, this partial ontology learning does not capture the interactions\nbetween subtasks. We address this gap by introducing OLLM, a general and\nscalable method for building the taxonomic backbone of an ontology from\nscratch. Rather than focusing on subtasks, like individual relations between\nentities, we model entire subcomponents of the target ontology by finetuning an\nLLM with a custom regulariser that reduces overfitting on high-frequency\nconcepts. We introduce a novel suite of metrics for evaluating the quality of\nthe generated ontology by measuring its semantic and structural similarity to\nthe ground truth. In contrast to standard metrics, our metrics use deep\nlearning techniques to define more robust distance measures between graphs.\nBoth our quantitative and qualitative results on Wikipedia show that OLLM\noutperforms subtask composition methods, producing more semantically accurate\nontologies while maintaining structural integrity. We further demonstrate that\nour model can be effectively adapted to new domains, like arXiv, needing only a\nsmall number of training examples. Our source code and datasets are available\nat https://github.com/andylolu2/ollm.", "paper_summary_zh": "\u672c\u4f53\u5bf9\u4e8e\u9886\u57df\u77e5\u8bc6\u7684\u81ea\u52a8\u673a\u5668\u5904\u7406\u5f88\u6709\u7528\uff0c\u56e0\u4e3a\u5b83\u4eec\u4ee5\u7ed3\u6784\u5316\u683c\u5f0f\u8868\u793a\u77e5\u8bc6\u3002\u7136\u800c\uff0c\u6784\u5efa\u672c\u4f53\u9700\u8981\u5927\u91cf\u7684\u624b\u52a8\u5de5\u4f5c\u3002\u4e3a\u4e86\u81ea\u52a8\u5316\u8fd9\u4e2a\u8fc7\u7a0b\u7684\u4e00\u90e8\u5206\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5df2\u88ab\u5e94\u7528\u4e8e\u89e3\u51b3\u672c\u4f53\u5b66\u4e60\u7684\u5404\u79cd\u5b50\u4efb\u52a1\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u90e8\u5206\u672c\u4f53\u5b66\u4e60\u5e76\u6ca1\u6709\u6355\u6349\u5230\u5b50\u4efb\u52a1\u4e4b\u95f4\u7684\u4ea4\u4e92\u3002\u6211\u4eec\u901a\u8fc7\u5f15\u5165 OLLM \u6765\u89e3\u51b3\u8fd9\u4e00\u5dee\u8ddd\uff0c\u8fd9\u662f\u4e00\u79cd\u4ece\u5934\u5f00\u59cb\u6784\u5efa\u672c\u4f53\u5206\u7c7b\u9aa8\u67b6\u7684\u901a\u7528\u4e14\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u3002\u6211\u4eec\u6ca1\u6709\u4e13\u6ce8\u4e8e\u5b50\u4efb\u52a1\uff0c\u4f8b\u5982\u5b9e\u4f53\u4e4b\u95f4\u7684\u4e2a\u522b\u5173\u7cfb\uff0c\u800c\u662f\u901a\u8fc7\u4f7f\u7528\u81ea\u5b9a\u4e49\u6b63\u5219\u5316\u5668\u5fae\u8c03 LLM \u6765\u5bf9\u76ee\u6807\u672c\u4f53\u7684\u6574\u4e2a\u5b50\u7ec4\u4ef6\u8fdb\u884c\u5efa\u6a21\uff0c\u8be5\u6b63\u5219\u5316\u5668\u51cf\u5c11\u4e86\u5bf9\u9ad8\u9891\u6982\u5ff5\u7684\u8fc7\u5ea6\u62df\u5408\u3002\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u5957\u65b0\u7684\u6307\u6807\u6765\u8bc4\u4f30\u751f\u6210\u672c\u4f53\u7684\u8d28\u91cf\uff0c\u65b9\u6cd5\u662f\u6d4b\u91cf\u5b83\u4e0e\u5730\u9762\u771f\u5b9e\u503c\u7684\u8bed\u4e49\u548c\u7ed3\u6784\u76f8\u4f3c\u6027\u3002\u4e0e\u6807\u51c6\u6307\u6807\u76f8\u53cd\uff0c\u6211\u4eec\u7684\u6307\u6807\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u6765\u5b9a\u4e49\u56fe\u4e4b\u95f4\u7684\u66f4\u7a33\u5065\u7684\u8ddd\u79bb\u5ea6\u91cf\u3002\u6211\u4eec\u5728\u7ef4\u57fa\u767e\u79d1\u4e0a\u7684\u5b9a\u91cf\u548c\u5b9a\u6027\u7ed3\u679c\u8868\u660e\uff0cOLLM \u4f18\u4e8e\u5b50\u4efb\u52a1\u7ec4\u5408\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u7ed3\u6784\u5b8c\u6574\u6027\u7684\u540c\u65f6\u751f\u6210\u8bed\u4e49\u4e0a\u66f4\u51c6\u786e\u7684\u672c\u4f53\u3002\u6211\u4eec\u8fdb\u4e00\u6b65\u8bc1\u660e\uff0c\u6211\u4eec\u7684\u6a21\u578b\u53ef\u4ee5\u6709\u6548\u5730\u9002\u5e94\u65b0\u7684\u9886\u57df\uff0c\u5982 arXiv\uff0c\u53ea\u9700\u8981\u5c11\u91cf\u7684\u8bad\u7ec3\u6837\u672c\u3002\u6211\u4eec\u7684\u6e90\u4ee3\u7801\u548c\u6570\u636e\u96c6\u53ef\u5728 https://github.com/andylolu2/ollm \u83b7\u5f97\u3002", "author": "Andy Lo et.al.", "authors": "Andy Lo, Albert Q. Jiang, Wenda Li, Mateja Jamnik", "id": "2410.23584v1", "paper_url": "http://arxiv.org/abs/2410.23584v1", "repo": "https://github.com/andylolu2/ollm"}}