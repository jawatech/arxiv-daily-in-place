{"2410.19743": {"publish_time": "2024-10-10", "title": "AppBench: Planning of Multiple APIs from Various APPs for Complex User Instruction", "paper_summary": "Large Language Models (LLMs) can interact with the real world by connecting\nwith versatile external APIs, resulting in better problem-solving and task\nautomation capabilities. Previous research primarily focuses on APIs with\nlimited arguments from a single source or overlooks the complex dependency\nrelationship between different APIs. However, it is essential to utilize\nmultiple APIs collaboratively from various sources (e.g., different Apps in the\niPhone), especially for complex user instructions. In this paper, we introduce\n\\texttt{AppBench}, the first benchmark to evaluate LLMs' ability to plan and\nexecute multiple APIs from various sources in order to complete the user's\ntask. Specifically, we consider two significant challenges in multiple APIs:\n\\textit{1) graph structures:} some APIs can be executed independently while\nothers need to be executed one by one, resulting in graph-like execution order;\nand \\textit{2) permission constraints:} which source is authorized to execute\nthe API call. We have experimental results on 9 distinct LLMs; e.g., GPT-4o\nachieves only a 2.0\\% success rate at the most complex instruction, revealing\nthat the existing state-of-the-art LLMs still cannot perform well in this\nsituation even with the help of in-context learning and finetuning. Our code\nand data are publicly available at https://github.com/ruleGreen/AppBench.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u53ef\u4ee5\u900f\u904e\u9023\u63a5\u591a\u529f\u80fd\u7684\u5916\u63a5 API \u8207\u771f\u5be6\u4e16\u754c\u4e92\u52d5\uff0c\u9032\u800c\u63d0\u5347\u554f\u984c\u89e3\u6c7a\u548c\u4efb\u52d9\u81ea\u52d5\u5316\u7684\u80fd\u529b\u3002\u5148\u524d\u7684\u7814\u7a76\u4e3b\u8981\u8457\u91cd\u65bc\u4f86\u81ea\u55ae\u4e00\u4f86\u6e90\u4e14\u53c3\u6578\u6709\u9650\u7684 API\uff0c\u6216\u5ffd\u7565\u4e0d\u540c API \u4e4b\u9593\u8907\u96dc\u7684\u76f8\u4f9d\u95dc\u4fc2\u3002\u7136\u800c\uff0c\u5f9e\u5404\u7a2e\u4f86\u6e90\u5354\u540c\u5229\u7528\u591a\u500b API \u81f3\u95dc\u91cd\u8981\uff08\u4f8b\u5982\uff0ciPhone \u4e2d\u7684\u4e0d\u540c\u61c9\u7528\u7a0b\u5f0f\uff09\uff0c\u7279\u5225\u662f\u5c0d\u65bc\u8907\u96dc\u7684\u4f7f\u7528\u8005\u6307\u4ee4\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 \\texttt{AppBench}\uff0c\u9019\u662f\u7b2c\u4e00\u500b\u57fa\u6e96\u6e2c\u8a66\uff0c\u7528\u65bc\u8a55\u4f30 LLM \u5f9e\u5404\u7a2e\u4f86\u6e90\u898f\u5283\u548c\u57f7\u884c\u591a\u500b API \u4ee5\u5b8c\u6210\u4f7f\u7528\u8005\u4efb\u52d9\u7684\u80fd\u529b\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u8003\u616e\u4e86\u591a\u500b API \u4e2d\u7684\u5169\u500b\u91cd\u5927\u6311\u6230\uff1a\\textit{1) \u5716\u5f62\u7d50\u69cb\uff1a}\u6709\u4e9b API \u53ef\u4ee5\u7368\u7acb\u57f7\u884c\uff0c\u800c\u53e6\u4e00\u4e9b API \u5247\u9700\u8981\u9010\u4e00\u57f7\u884c\uff0c\u5c0e\u81f4\u985e\u5716\u5f62\u57f7\u884c\u9806\u5e8f\uff1b\u4ee5\u53ca \\textit{2) \u6b0a\u9650\u9650\u5236\uff1a}\u54ea\u500b\u4f86\u6e90\u6709\u6b0a\u57f7\u884c API \u547c\u53eb\u3002\u6211\u5011\u5c0d 9 \u500b\u4e0d\u540c\u7684 LLM \u9032\u884c\u4e86\u5be6\u9a57\u7d50\u679c\uff1b\u4f8b\u5982\uff0cGPT-4o \u5728\u6700\u8907\u96dc\u7684\u6307\u4ee4\u4e2d\u50c5\u9054\u5230 2.0% \u7684\u6210\u529f\u7387\uff0c\u9019\u8868\u660e\u73fe\u6709\u7684\u6700\u5148\u9032 LLM \u5373\u4f7f\u5728\u60c5\u5883\u5b78\u7fd2\u548c\u5fae\u8abf\u7684\u5e6b\u52a9\u4e0b\uff0c\u4ecd\u7136\u7121\u6cd5\u5f88\u597d\u5730\u61c9\u5c0d\u9019\u7a2e\u60c5\u6cc1\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\u5df2\u516c\u958b\u65bc https://github.com/ruleGreen/AppBench\u3002", "author": "Hongru Wang et.al.", "authors": "Hongru Wang, Rui Wang, Boyang Xue, Heming Xia, Jingtao Cao, Zeming Liu, Jeff Z. Pan, Kam-Fai Wong", "id": "2410.19743v1", "paper_url": "http://arxiv.org/abs/2410.19743v1", "repo": "null"}}