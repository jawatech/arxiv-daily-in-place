{"2412.18566": {"publish_time": "2024-12-24", "title": "Zero-resource Speech Translation and Recognition with LLMs", "paper_summary": "Despite recent advancements in speech processing, zero-resource speech\ntranslation (ST) and automatic speech recognition (ASR) remain challenging\nproblems. In this work, we propose to leverage a multilingual Large Language\nModel (LLM) to perform ST and ASR in languages for which the model has never\nseen paired audio-text data. We achieve this by using a pre-trained\nmultilingual speech encoder, a multilingual LLM, and a lightweight adaptation\nmodule that maps the audio representations to the token embedding space of the\nLLM. We perform several experiments both in ST and ASR to understand how to\nbest train the model and what data has the most impact on performance in\npreviously unseen languages. In ST, our best model is capable to achieve BLEU\nscores over 23 in CoVoST2 for two previously unseen languages, while in ASR, we\nachieve WERs of up to 28.2\\%. We finally show that the performance of our\nsystem is bounded by the ability of the LLM to output text in the desired\nlanguage.", "paper_summary_zh": "\u5118\u7ba1\u5728\u8a9e\u97f3\u8655\u7406\u65b9\u9762\u6709\u8fd1\u671f\u7684\u9032\u5c55\uff0c\u96f6\u8cc7\u6e90\u8a9e\u97f3\u7ffb\u8b6f (ST) \u548c\u81ea\u52d5\u8a9e\u97f3\u8fa8\u8b58 (ASR) \u4ecd\u7136\u662f\u5177\u6709\u6311\u6230\u6027\u7684\u554f\u984c\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u8b70\u5229\u7528\u591a\u8a9e\u8a00\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4f86\u57f7\u884c ST \u548c ASR\uff0c\u9019\u4e9b\u8a9e\u8a00\u7684\u6a21\u578b\u5f9e\u672a\u898b\u904e\u914d\u5c0d\u7684\u97f3\u8a0a\u6587\u5b57\u8cc7\u6599\u3002\u6211\u5011\u900f\u904e\u4f7f\u7528\u9810\u5148\u8a13\u7df4\u7684\u591a\u8a9e\u8a00\u8a9e\u97f3\u7de8\u78bc\u5668\u3001\u591a\u8a9e\u8a00 LLM \u548c\u8f15\u91cf\u7d1a\u9069\u61c9\u6a21\u7d44\u4f86\u9054\u6210\u6b64\u76ee\u6a19\uff0c\u8a72\u6a21\u7d44\u6703\u5c07\u97f3\u8a0a\u8868\u793a\u5c0d\u61c9\u5230 LLM \u7684\u6a19\u8a18\u5d4c\u5165\u7a7a\u9593\u3002\u6211\u5011\u57f7\u884c\u591a\u9805 ST \u548c ASR \u5be6\u9a57\uff0c\u4ee5\u4e86\u89e3\u5982\u4f55\u6700\u4f73\u8a13\u7df4\u6a21\u578b\uff0c\u4ee5\u53ca\u54ea\u4e9b\u8cc7\u6599\u5c0d\u5148\u524d\u672a\u898b\u8a9e\u8a00\u7684\u6548\u80fd\u5f71\u97ff\u6700\u5927\u3002\u5728 ST \u4e2d\uff0c\u6211\u5011\u7684\u6700\u4f73\u6a21\u578b\u80fd\u5920\u5728 CoVoST2 \u4e2d\u91dd\u5c0d\u5169\u7a2e\u5148\u524d\u672a\u898b\u7684\u8a9e\u8a00\u9054\u6210\u8d85\u904e 23 \u7684 BLEU \u5206\u6578\uff0c\u800c\u5728 ASR \u4e2d\uff0c\u6211\u5011\u9054\u6210\u9ad8\u9054 28.2% \u7684 WER\u3002\u6211\u5011\u6700\u5f8c\u986f\u793a\uff0c\u6211\u5011\u7cfb\u7d71\u7684\u6548\u80fd\u53d7\u9650\u65bc LLM \u4ee5\u6240\u9700\u8a9e\u8a00\u8f38\u51fa\u6587\u5b57\u7684\u80fd\u529b\u3002", "author": "Karel Mundnich et.al.", "authors": "Karel Mundnich, Xing Niu, Prashant Mathur, Srikanth Ronanki, Brady Houston, Veera Raghavendra Elluru, Nilaksh Das, Zejiang Hou, Goeric Huybrechts, Anshu Bhatia, Daniel Garcia-Romero, Kyu J. Han, Katrin Kirchhoff", "id": "2412.18566v1", "paper_url": "http://arxiv.org/abs/2412.18566v1", "repo": "null"}}