{"2407.08733": {"publish_time": "2024-07-11", "title": "Is Your Model Really A Good Math Reasoner? Evaluating Mathematical Reasoning with Checklist", "paper_summary": "Exceptional mathematical reasoning ability is one of the key features that\ndemonstrate the power of large language models (LLMs). How to comprehensively\ndefine and evaluate the mathematical abilities of LLMs, and even reflect the\nuser experience in real-world scenarios, has emerged as a critical issue.\nCurrent benchmarks predominantly concentrate on problem-solving capabilities,\nwhich presents a substantial risk of model overfitting and fails to accurately\nrepresent genuine mathematical reasoning abilities. In this paper, we argue\nthat if a model really understands a problem, it should be robustly and readily\napplied across a diverse array of tasks. Motivated by this, we introduce\nMATHCHECK, a well-designed checklist for testing task generalization and\nreasoning robustness, as well as an automatic tool to generate checklists\nefficiently. MATHCHECK includes multiple mathematical reasoning tasks and\nrobustness test types to facilitate a comprehensive evaluation of both\nmathematical reasoning ability and behavior testing. Utilizing MATHCHECK, we\ndevelop MATHCHECK-GSM and MATHCHECK-GEO to assess mathematical textual\nreasoning and multi-modal reasoning capabilities, respectively, serving as\nupgraded versions of benchmarks including GSM8k, GeoQA, UniGeo, and Geometry3K.\nWe adopt MATHCHECK-GSM and MATHCHECK-GEO to evaluate over 20 LLMs and 11 MLLMs,\nassessing their comprehensive mathematical reasoning abilities. Our results\ndemonstrate that while frontier LLMs like GPT-4o continue to excel in various\nabilities on the checklist, many other model families exhibit a significant\ndecline. Further experiments indicate that, compared to traditional math\nbenchmarks, MATHCHECK better reflects true mathematical abilities and\nrepresents mathematical intelligence more linearly, thereby supporting our\ndesign. On our MATHCHECK, we can easily conduct detailed behavior analysis to\ndeeply investigate models.", "paper_summary_zh": "\u5091\u51fa\u7684\u6578\u5b78\u63a8\u7406\u80fd\u529b\u662f\u5c55\u793a\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5f37\u5927\u7684\u95dc\u9375\u7279\u5fb5\u4e4b\u4e00\u3002\u5982\u4f55\u5168\u9762\u5b9a\u7fa9\u548c\u8a55\u4f30 LLM \u7684\u6578\u5b78\u80fd\u529b\uff0c\u751a\u81f3\u53cd\u6620\u771f\u5be6\u5834\u666f\u4e2d\u7684\u4f7f\u7528\u8005\u9ad4\u9a57\uff0c\u5df2\u6210\u70ba\u4e00\u500b\u95dc\u9375\u554f\u984c\u3002\u76ee\u524d\u7684\u57fa\u6e96\u4e3b\u8981\u96c6\u4e2d\u65bc\u554f\u984c\u89e3\u6c7a\u80fd\u529b\uff0c\u9019\u6703\u9020\u6210\u6a21\u578b\u904e\u5ea6\u64ec\u5408\u7684\u91cd\u5927\u98a8\u96aa\uff0c\u4e14\u7121\u6cd5\u6e96\u78ba\u8868\u793a\u771f\u6b63\u7684\u6578\u5b78\u63a8\u7406\u80fd\u529b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u8ad6\u8b49\u5982\u679c\u4e00\u500b\u6a21\u578b\u771f\u6b63\u7406\u89e3\u4e00\u500b\u554f\u984c\uff0c\u5b83\u61c9\u8a72\u53ef\u4ee5\u7a69\u5065\u4e14\u5bb9\u6613\u5730\u61c9\u7528\u65bc\u5404\u7a2e\u4efb\u52d9\u4e2d\u3002\u53d7\u6b64\u555f\u767c\uff0c\u6211\u5011\u5f15\u5165\u4e86 MATHCHECK\uff0c\u9019\u662f\u4e00\u500b\u7cbe\u5fc3\u8a2d\u8a08\u7684\u6aa2\u67e5\u6e05\u55ae\uff0c\u7528\u65bc\u6e2c\u8a66\u4efb\u52d9\u6982\u5316\u548c\u63a8\u7406\u7a69\u5065\u6027\uff0c\u4ee5\u53ca\u4e00\u500b\u7528\u65bc\u6709\u6548\u7522\u751f\u6aa2\u67e5\u6e05\u55ae\u7684\u81ea\u52d5\u5316\u5de5\u5177\u3002MATHCHECK \u5305\u542b\u591a\u9805\u6578\u5b78\u63a8\u7406\u4efb\u52d9\u548c\u7a69\u5065\u6027\u6e2c\u8a66\u985e\u578b\uff0c\u4ee5\u5229\u65bc\u5c0d\u6578\u5b78\u63a8\u7406\u80fd\u529b\u548c\u884c\u70ba\u6e2c\u8a66\u9032\u884c\u5168\u9762\u8a55\u4f30\u3002\u5229\u7528 MATHCHECK\uff0c\u6211\u5011\u958b\u767c\u4e86 MATHCHECK-GSM \u548c MATHCHECK-GEO\uff0c\u5206\u5225\u7528\u65bc\u8a55\u4f30\u6578\u5b78\u6587\u672c\u63a8\u7406\u548c\u591a\u6a21\u614b\u63a8\u7406\u80fd\u529b\uff0c\u4f5c\u70ba\u5305\u62ec GSM8k\u3001GeoQA\u3001UniGeo \u548c Geometry3K \u5728\u5167\u7684\u57fa\u6e96\u7684\u5347\u7d1a\u7248\u672c\u3002\u6211\u5011\u63a1\u7528 MATHCHECK-GSM \u548c MATHCHECK-GEO \u4f86\u8a55\u4f30\u8d85\u904e 20 \u500b LLM \u548c 11 \u500b MLLM\uff0c\u8a55\u4f30\u5b83\u5011\u7684\u7d9c\u5408\u6578\u5b78\u63a8\u7406\u80fd\u529b\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0c\u5118\u7ba1\u50cf GPT-4o \u9019\u6a23\u7684\u908a\u7586 LLM \u7e7c\u7e8c\u5728\u6aa2\u67e5\u6e05\u55ae\u4e0a\u7684\u5404\u7a2e\u80fd\u529b\u4e2d\u8868\u73fe\u51fa\u8272\uff0c\u4f46\u8a31\u591a\u5176\u4ed6\u6a21\u578b\u7cfb\u5217\u537b\u51fa\u73fe\u986f\u8457\u4e0b\u964d\u3002\u9032\u4e00\u6b65\u7684\u5be6\u9a57\u8868\u660e\uff0c\u8207\u50b3\u7d71\u6578\u5b78\u57fa\u6e96\u76f8\u6bd4\uff0cMATHCHECK \u66f4\u597d\u5730\u53cd\u6620\u4e86\u771f\u6b63\u7684\u6578\u5b78\u80fd\u529b\uff0c\u4e26\u66f4\u7dda\u6027\u5730\u8868\u793a\u6578\u5b78\u667a\u80fd\uff0c\u5f9e\u800c\u652f\u6301\u6211\u5011\u7684\u8a2d\u8a08\u3002\u5728\u6211\u5011\u7684 MATHCHECK \u4e0a\uff0c\u6211\u5011\u53ef\u4ee5\u8f15\u9b06\u9032\u884c\u8a73\u7d30\u7684\u884c\u70ba\u5206\u6790\uff0c\u4ee5\u6df1\u5165\u7814\u7a76\u6a21\u578b\u3002", "author": "Zihao Zhou et.al.", "authors": "Zihao Zhou, Shudong Liu, Maizhen Ning, Wei Liu, Jindong Wang, Derek F. Wong, Xiaowei Huang, Qiufeng Wang, Kaizhu Huang", "id": "2407.08733v1", "paper_url": "http://arxiv.org/abs/2407.08733v1", "repo": "null"}}