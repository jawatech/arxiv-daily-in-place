# arxiv-daily
 Automated deployment @ 2024-11-27 09:10:07 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-25**|**Do Large Language Models Perform Latent Multi-Hop Reasoning without Exploiting Shortcuts?**|Sohee Yang et.al.|[2411.16679v1](http://arxiv.org/abs/2411.16679v1)|null|
|**2024-11-25**|**CatNet: Effective FDR Control in LSTM with Gaussian Mirrors and SHAP Feature Importance**|Jiaan Han et.al.|[2411.16666v1](http://arxiv.org/abs/2411.16666v1)|null|
|**2024-11-25**|**DreamRunner: Fine-Grained Storytelling Video Generation with Retrieval-Augmented Motion Adaptation**|Zun Wang et.al.|[2411.16657v1](http://arxiv.org/abs/2411.16657v1)|null|
|**2024-11-25**|**Self-Generated Critiques Boost Reward Modeling for Language Models**|Yue Yu et.al.|[2411.16646v1](http://arxiv.org/abs/2411.16646v1)|null|
|**2024-11-25**|**Recommender Systems for Good (RS4Good): Survey of Use Cases and a Call to Action for Research that Matters**|Dietmar Jannach et.al.|[2411.16645v1](http://arxiv.org/abs/2411.16645v1)|null|
|**2024-11-25**|**Preventing Jailbreak Prompts as Malicious Tools for Cybercriminals: A Cyber Defense Perspective**|Jean Marie Tshimula et.al.|[2411.16642v1](http://arxiv.org/abs/2411.16642v1)|null|
|**2024-11-25**|**Do Automatic Factuality Metrics Measure Factuality? A Critical Evaluation**|Sanjana Ramprasad et.al.|[2411.16638v1](http://arxiv.org/abs/2411.16638v1)|null|
|**2024-11-25**|**Imperceptible Adversarial Examples in the Physical World**|Weilin Xu et.al.|[2411.16622v1](http://arxiv.org/abs/2411.16622v1)|null|
|**2024-11-25**|**StructFormer: Document Structure-based Masked Attention and its Impact on Language Model Pre-Training**|Kaustubh Ponkshe et.al.|[2411.16618v1](http://arxiv.org/abs/2411.16618v1)|null|
|**2024-11-25**|**Recent Trends in Linear Text Segmentation: a Survey**|Iacopo Ghinassi et.al.|[2411.16613v1](http://arxiv.org/abs/2411.16613v1)|null|
|**2024-11-25**|**F -- A Model of Events based on the Foundational Ontology DOLCE+DnS Ultralite**|Ansgar Scherp et.al.|[2411.16609v1](http://arxiv.org/abs/2411.16609v1)|[link](https://github.com/ascherp/ontologies)|
|**2024-11-25**|**From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge**|Dawei Li et.al.|[2411.16594v1](http://arxiv.org/abs/2411.16594v1)|[link](https://github.com/llm-as-a-judge/awesome-llm-as-a-judge)|
|**2024-11-25**|**Enhancing LLM Reasoning via Critique Models with Test-Time and Training-Time Supervision**|Zhiheng Xi et.al.|[2411.16579v1](http://arxiv.org/abs/2411.16579v1)|null|
|**2024-11-25**|**Naive Algorithmic Collusion: When Do Bandit Learners Cooperate and When Do They Compete?**|Connor Douglas et.al.|[2411.16574v1](http://arxiv.org/abs/2411.16574v1)|null|
|**2024-11-25**|**EnStack: An Ensemble Stacking Framework of Large Language Models for Enhanced Vulnerability Detection in Source Code**|Shahriyar Zaman Ridoy et.al.|[2411.16561v1](http://arxiv.org/abs/2411.16561v1)|null|
|**2024-11-25**|**Representation Collapsing Problems in Vector Quantization**|Wenhao Zhao et.al.|[2411.16550v1](http://arxiv.org/abs/2411.16550v1)|null|
|**2024-11-25**|**RoboSpatial: Teaching Spatial Understanding to 2D and 3D Vision-Language Models for Robotics**|Chan Hee Song et.al.|[2411.16537v1](http://arxiv.org/abs/2411.16537v1)|null|
|**2024-11-25**|**Profiling Bias in LLMs: Stereotype Dimensions in Contextual Word Embeddings**|Carolin M. Schuster et.al.|[2411.16527v1](http://arxiv.org/abs/2411.16527v1)|null|
|**2024-11-25**|**Fundamental Limits of Prompt Tuning Transformers: Universality, Capacity and Efficiency**|Jerry Yao-Chieh Hu et.al.|[2411.16525v1](http://arxiv.org/abs/2411.16525v1)|null|
|**2024-11-25**|**LaB-RAG: Label Boosted Retrieval Augmented Generation for Radiology Report Generation**|Steven Song et.al.|[2411.16523v1](http://arxiv.org/abs/2411.16523v1)|null|
|**2024-11-25**|**All Languages Matter: Evaluating LMMs on Culturally Diverse 100 Languages**|Ashmal Vayani et.al.|[2411.16508v1](http://arxiv.org/abs/2411.16508v1)|null|
|**2024-11-25**|**Interpreting Language Reward Models via Contrastive Explanations**|Junqi Jiang et.al.|[2411.16502v1](http://arxiv.org/abs/2411.16502v1)|null|
|**2024-11-25**|**AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning**|Amy Xin et.al.|[2411.16495v1](http://arxiv.org/abs/2411.16495v1)|null|
|**2024-11-25**|**O1 Replication Journey -- Part 2: Surpassing O1-preview through Simple Distillation, Big Progress or Bitter Lesson?**|Zhen Huang et.al.|[2411.16489v1](http://arxiv.org/abs/2411.16489v1)|[link](https://github.com/gair-nlp/o1-journey)|
|**2024-11-25**|**When Babies Teach Babies: Can student knowledge sharing outperform Teacher-Guided Distillation on small datasets?**|Srikrishna Iyer et.al.|[2411.16487v1](http://arxiv.org/abs/2411.16487v1)|[link](https://github.com/ai-da-stc/generative-ai-research-babylm)|
|**2024-11-25**|**Characterized Diffusion Networks for Enhanced Autonomous Driving Trajectory Prediction**|Haoming Li et.al.|[2411.16457v1](http://arxiv.org/abs/2411.16457v1)|null|
|**2024-11-25**|**Learning by Analogy: Enhancing Few-Shot Prompting for Math Word Problem Solving with Computational Graph-Based Retrieval**|Xiaocong Yang et.al.|[2411.16454v1](http://arxiv.org/abs/2411.16454v1)|null|
|**2024-11-25**|**TIFeD: a Tiny Integer-based Federated learning algorithm with Direct feedback alignment**|Luca Colombo et.al.|[2411.16442v1](http://arxiv.org/abs/2411.16442v1)|[link](https://github.com/ai-tech-research-lab/tifed)|
|**2024-11-25**|**Finding Structure in Language Models**|Jaap Jumelet et.al.|[2411.16433v1](http://arxiv.org/abs/2411.16433v1)|null|
|**2024-11-25**|**TopV-Nav: Unlocking the Top-View Spatial Reasoning Potential of MLLM for Zero-shot Object Navigation**|Linqing Zhong et.al.|[2411.16425v1](http://arxiv.org/abs/2411.16425v1)|null|
|**2024-11-25**|**Turbofan Engine Remaining Useful Life (RUL) Prediction Based on Bi-Directional Long Short-Term Memory (BLSTM)**|Abedin Sherifi et.al.|[2411.16422v1](http://arxiv.org/abs/2411.16422v1)|null|
|**2024-11-25**|**A Study on Unsupervised Domain Adaptation for Semantic Segmentation in the Era of Vision-Language Models**|Manuel Schwonberg et.al.|[2411.16407v1](http://arxiv.org/abs/2411.16407v1)|null|
|**2024-11-25**|**Synthesising Handwritten Music with GANs: A Comprehensive Evaluation of CycleWGAN, ProGAN, and DCGAN**|Elona Shatri et.al.|[2411.16405v1](http://arxiv.org/abs/2411.16405v1)|null|
|**2024-11-25**|**Adapter-based Approaches to Knowledge-enhanced Language Models -- A Survey**|Alexander Fichtl et.al.|[2411.16403v1](http://arxiv.org/abs/2411.16403v1)|null|
|**2024-11-25**|**Human-Calibrated Automated Testing and Validation of Generative Language Models**|Agus Sudjianto et.al.|[2411.16391v1](http://arxiv.org/abs/2411.16391v1)|null|
|**2024-11-25**|**FineWeb-zhtw: Scalable Curation of Traditional Chinese Text Data from the Web**|Cheng-Wei Lin et.al.|[2411.16387v1](http://arxiv.org/abs/2411.16387v1)|null|
|**2024-11-25**|**Privacy-Preserving Federated Foundation Model for Generalist Ultrasound Artificial Intelligence**|Yuncheng Jiang et.al.|[2411.16380v1](http://arxiv.org/abs/2411.16380v1)|null|
|**2024-11-25**|**A Review of Bayesian Uncertainty Quantification in Deep Probabilistic Image Segmentation**|M. M. A. Valiuddin et.al.|[2411.16370v1](http://arxiv.org/abs/2411.16370v1)|null|
|**2024-11-25**|**Multi-modal Retrieval Augmented Multi-modal Generation: A Benchmark, Evaluate Metrics and Strong Baselines**|Zi-Ao Ma et.al.|[2411.16365v1](http://arxiv.org/abs/2411.16365v1)|null|
|**2024-11-25**|**Graph Neural Networks-based Parameter Design towards Large-Scale Superconducting Quantum Circuits for Crosstalk Mitigation**|Hao Ai et.al.|[2411.16354v1](http://arxiv.org/abs/2411.16354v1)|null|
|**2024-11-25**|**The Two-Hop Curse: LLMs trained on A->B, B->C fail to learn A-->C**|Mikita Balesni et.al.|[2411.16353v1](http://arxiv.org/abs/2411.16353v1)|null|
|**2024-11-25**|**Preference Optimization for Reasoning with Pseudo Feedback**|Fangkai Jiao et.al.|[2411.16345v1](http://arxiv.org/abs/2411.16345v1)|null|
|**2024-11-25**|**Can AI grade your essays? A comparative analysis of large language models and teacher ratings in multidimensional essay scoring**|Kathrin Se√üler et.al.|[2411.16337v1](http://arxiv.org/abs/2411.16337v1)|null|
|**2024-11-25**|**One Diffusion to Generate Them All**|Duong H. Le et.al.|[2411.16318v1](http://arxiv.org/abs/2411.16318v1)|[link](https://github.com/lehduong/onediffusion)|
|**2024-11-25**|**CATP-LLM: Empowering Large Language Models for Cost-Aware Tool Planning**|Duo Wu et.al.|[2411.16313v1](http://arxiv.org/abs/2411.16313v1)|null|
|**2024-11-25**|**Learning from Relevant Subgoals in Successful Dialogs using Iterative Training for Task-oriented Dialog Systems**|Magdalena Kaiser et.al.|[2411.16305v1](http://arxiv.org/abs/2411.16305v1)|null|
|**2024-11-25**|**BayLing 2: A Multilingual Large Language Model with Efficient Language Alignment**|Shaolei Zhang et.al.|[2411.16300v1](http://arxiv.org/abs/2411.16300v1)|[link](https://github.com/ictnlp/bayling)|
|**2024-11-25**|**The SVASR System for Text-dependent Speaker Verification (TdSV) AAIC Challenge 2024**|Mohammadreza Molavi et.al.|[2411.16276v1](http://arxiv.org/abs/2411.16276v1)|null|
|**2024-11-25**|**Probing for Consciousness in Machines**|Mathis Immertreu et.al.|[2411.16262v1](http://arxiv.org/abs/2411.16262v1)|null|
|**2024-11-25**|**Unraveling Arithmetic in Large Language Models: The Role of Algebraic Structures**|Fu-Chieh Chang et.al.|[2411.16260v1](http://arxiv.org/abs/2411.16260v1)|null|
|**2024-11-25**|**NormXLogit: The Head-on-Top Never Lies**|Sina Abbasi et.al.|[2411.16252v1](http://arxiv.org/abs/2411.16252v1)|null|
|**2024-11-25**|**Transparent Neighborhood Approximation for Text Classifier Explanation**|Yi Cai et.al.|[2411.16251v1](http://arxiv.org/abs/2411.16251v1)|null|
|**2024-11-25**|**DoubleCCA: Improving Foundation Model Group Robustness with Random Sentence Embeddings**|Hong Liu et.al.|[2411.16236v1](http://arxiv.org/abs/2411.16236v1)|null|
|**2024-11-25**|**MH-MoE:Multi-Head Mixture-of-Experts**|Shaohan Huang et.al.|[2411.16205v1](http://arxiv.org/abs/2411.16205v1)|null|
|**2024-11-25**|**Video-Text Dataset Construction from Multi-AI Feedback: Promoting Weak-to-Strong Preference Learning for Video Large Language Models**|Hao Yi et.al.|[2411.16201v1](http://arxiv.org/abs/2411.16201v1)|null|
|**2024-11-25**|**Enhancing Multi-Agent Consensus through Third-Party LLM Integration: Analyzing Uncertainty and Mitigating Hallucinations in Large Language Models**|Zhihua Duan et.al.|[2411.16189v1](http://arxiv.org/abs/2411.16189v1)|null|
|**2024-11-25**|**SALOVA: Segment-Augmented Long Video Assistant for Targeted Retrieval and Routing in Long-Form Video Analysis**|Junho Kim et.al.|[2411.16173v1](http://arxiv.org/abs/2411.16173v1)|null|
|**2024-11-25**|**MixPE: Quantization and Hardware Co-design for Efficient LLM Inference**|Yu Zhang et.al.|[2411.16158v1](http://arxiv.org/abs/2411.16158v1)|null|
|**2024-11-25**|**Graph Adapter of EEG Foundation Models for Parameter Efficient Fine Tuning**|Toyotaro Suzumura et.al.|[2411.16155v1](http://arxiv.org/abs/2411.16155v1)|null|
|**2024-11-25**|**SKQVC: One-Shot Voice Conversion by K-Means Quantization with Self-Supervised Speech Representations**|Youngjun Sim et.al.|[2411.16147v1](http://arxiv.org/abs/2411.16147v1)|null|
|**2024-11-25**|**End-to-End Steering for Autonomous Vehicles via Conditional Imitation Co-Learning**|Mahmoud M. Kishky et.al.|[2411.16131v1](http://arxiv.org/abs/2411.16131v1)|null|
|**2024-11-25**|**Med-PerSAM: One-Shot Visual Prompt Tuning for Personalized Segment Anything Model in Medical Domain**|Hangyul Yoon et.al.|[2411.16123v1](http://arxiv.org/abs/2411.16123v1)|null|
|**2024-11-25**|**Why the Agent Made that Decision: Explaining Deep Reinforcement Learning with Vision Masks**|Rui Zuo et.al.|[2411.16120v1](http://arxiv.org/abs/2411.16120v1)|null|
|**2024-11-25**|**LLM Augmentations to support Analytical Reasoning over Multiple Documents**|Raquib Bin Yousuf et.al.|[2411.16116v1](http://arxiv.org/abs/2411.16116v1)|[link](https://github.com/discoveryanalyticscenter/speculatores)|
|**2024-11-25**|**LLMPirate: LLMs for Black-box Hardware IP Piracy**|Vasudev Gohil et.al.|[2411.16111v1](http://arxiv.org/abs/2411.16111v1)|null|
|**2024-11-25**|**Adaptive Circuit Behavior and Generalization in Mechanistic Interpretability**|Jatin Nainani et.al.|[2411.16105v1](http://arxiv.org/abs/2411.16105v1)|null|
|**2024-11-25**|**An Empirical Study of Vulnerability Detection using Federated Learning**|Peiheng Zhou et.al.|[2411.16099v1](http://arxiv.org/abs/2411.16099v1)|null|
|**2024-11-25**|**ENCLIP: Ensembling and Clustering-Based Contrastive Language-Image Pretraining for Fashion Multimodal Search with Limited Data and Low-Quality Images**|Prithviraj Purushottam Naik et.al.|[2411.16096v1](http://arxiv.org/abs/2411.16096v1)|null|
|**2024-11-25**|**HiDP: Hierarchical DNN Partitioning for Distributed Inference on Heterogeneous Edge Platforms**|Zain Taufique et.al.|[2411.16086v1](http://arxiv.org/abs/2411.16086v1)|null|
|**2024-11-25**|**Deciphering genomic codes using advanced NLP techniques: a scoping review**|Shuyan Cheng et.al.|[2411.16084v1](http://arxiv.org/abs/2411.16084v1)|null|
|**2024-11-25**|**Boosting 3D Object Generation through PBR Materials**|Yitong Wang et.al.|[2411.16080v1](http://arxiv.org/abs/2411.16080v1)|null|
|**2024-11-25**|**Debiasing Classifiers by Amplifying Bias with Latent Diffusion and Large Language Models**|Donggeun Ko et.al.|[2411.16079v1](http://arxiv.org/abs/2411.16079v1)|null|
|**2024-11-25**|**SAGEval: The frontiers of Satisfactory Agent based NLG Evaluation for reference-free open-ended text**|Reshmi Ghosh et.al.|[2411.16077v1](http://arxiv.org/abs/2411.16077v1)|null|
|**2024-11-25**|**The brain versus AI: World-model-based versatile circuit computation underlying diverse functions in the neocortex and cerebellum**|Shogo Ohmae et.al.|[2411.16075v1](http://arxiv.org/abs/2411.16075v1)|null|
|**2024-11-25**|**UnitedVLN: Generalizable Gaussian Splatting for Continuous Vision-Language Navigation**|Guangzhao Dai et.al.|[2411.16053v1](http://arxiv.org/abs/2411.16053v1)|null|
|**2024-11-25**|**Predicting Emergent Capabilities by Finetuning**|Charlie Snell et.al.|[2411.16035v1](http://arxiv.org/abs/2411.16035v1)|null|
|**2024-11-25**|**From Dashcam Videos to Driving Simulations: Stress Testing Automated Vehicles against Rare Events**|Yan Miao et.al.|[2411.16027v1](http://arxiv.org/abs/2411.16027v1)|null|
|**2024-11-25**|**TransCompressor: LLM-Powered Multimodal Data Compression for Smart Transportation**|Huanqi Yang et.al.|[2411.16020v1](http://arxiv.org/abs/2411.16020v1)|null|
|**2024-11-24**|**Performance Implications of Multi-Chiplet Neural Processing Units on Autonomous Driving Perception**|Mohanad Odema et.al.|[2411.16007v1](http://arxiv.org/abs/2411.16007v1)|null|
|**2024-11-24**|**eFedLLM: Efficient LLM Inference Based on Federated Learning**|Shengwen Ding et.al.|[2411.16003v1](http://arxiv.org/abs/2411.16003v1)|null|
|**2024-11-24**|**Exploring Performance Contrasts in TableQA: Step-by-Step Reasoning Boosts Bigger Language Models, Limits Smaller Language Models**|Haoyan Yang et.al.|[2411.16002v1](http://arxiv.org/abs/2411.16002v1)|null|
|**2024-11-24**|**Multi-ToM: Evaluating Multilingual Theory of Mind Capabilities in Large Language Models**|Jayanta Sadhu et.al.|[2411.15999v1](http://arxiv.org/abs/2411.15999v1)|null|
|**2024-11-24**|**PIANIST: Learning Partially Observable World Models with LLMs for Multi-Agent Decision Making**|Jonathan Light et.al.|[2411.15998v1](http://arxiv.org/abs/2411.15998v1)|null|
|**2024-11-24**|**Ensuring Fair LLM Serving Amid Diverse Applications**|Redwan Ibne Seraj Khan et.al.|[2411.15997v1](http://arxiv.org/abs/2411.15997v1)|null|
|**2024-11-24**|**Investigating Factuality in Long-Form Text Generation: The Roles of Self-Known and Self-Unknown**|Lifu Tu et.al.|[2411.15993v1](http://arxiv.org/abs/2411.15993v1)|null|
|**2024-11-24**|**Anda: Unlocking Efficient LLM Inference with a Variable-Length Grouped Activation Data Format**|Chao Fang et.al.|[2411.15982v1](http://arxiv.org/abs/2411.15982v1)|null|
|**2024-11-24**|**DRIVE: Dual-Robustness via Information Variability and Entropic Consistency in Source-Free Unsupervised Domain Adaptation**|Ruiqiang Xiao et.al.|[2411.15976v1](http://arxiv.org/abs/2411.15976v1)|null|
|**2024-11-24**|**Partial Identifiability and Misspecification in Inverse Reinforcement Learning**|Joar Skalse et.al.|[2411.15951v1](http://arxiv.org/abs/2411.15951v1)|null|
|**2024-11-24**|**Generative Context Distillation**|Haebin Shin et.al.|[2411.15927v1](http://arxiv.org/abs/2411.15927v1)|null|
|**2024-11-24**|**Deep Learning for automated multi-scale functional field boundaries extraction using multi-date Sentinel-2 and PlanetScope imagery: Case Study of Netherlands and Pakistan**|Saba Zahid et.al.|[2411.15923v1](http://arxiv.org/abs/2411.15923v1)|null|
|**2024-11-24**|**A Training-Free Approach for Music Style Transfer with Latent Diffusion Models**|Sooyoung Kim et.al.|[2411.15913v1](http://arxiv.org/abs/2411.15913v1)|null|
|**2024-11-24**|**Bimanual Grasp Synthesis for Dexterous Robot Hands**|Yanming Shao et.al.|[2411.15903v1](http://arxiv.org/abs/2411.15903v1)|null|
|**2024-11-24**|**Distribution-aware Online Continual Learning for Urban Spatio-Temporal Forecasting**|Chengxin Wang et.al.|[2411.15893v1](http://arxiv.org/abs/2411.15893v1)|null|
|**2024-11-24**|**Evaluating Large Language Models for Causal Modeling**|Houssam Razouk et.al.|[2411.15888v1](http://arxiv.org/abs/2411.15888v1)|null|
|**2024-11-24**|**LLMs Do Not Think Step-by-step In Implicit Reasoning**|Yijiong Yu et.al.|[2411.15862v1](http://arxiv.org/abs/2411.15862v1)|null|
|**2024-11-24**|**Unveiling the Superior Paradigm: A Comparative Study of Source-Free Domain Adaptation and Unsupervised Domain Adaptation**|Fan Wang et.al.|[2411.15844v1](http://arxiv.org/abs/2411.15844v1)|null|
|**2024-11-24**|**Efficient and Private: Memorisation under differentially private parameter-efficient fine-tuning in language models**|Olivia Ma et.al.|[2411.15831v1](http://arxiv.org/abs/2411.15831v1)|null|
|**2024-11-24**|**Is Training Data Quality or Quantity More Impactful to Small Language Model Performance?**|Aryan Sajith et.al.|[2411.15821v1](http://arxiv.org/abs/2411.15821v1)|[link](https://github.com/aryan-sajith/urv-data_quantity_vs_data_quality-research)|
|**2024-11-24**|**FastTrackTr:Towards Fast Multi-Object Tracking with Transformers**|Pan Liao et.al.|[2411.15811v1](http://arxiv.org/abs/2411.15811v1)|null|
|**2024-11-24**|**Benchmarking Active Learning for NILM**|Dhruv Patel et.al.|[2411.15805v1](http://arxiv.org/abs/2411.15805v1)|null|

#### Abstracts
##### **Do Large Language Models Perform Latent Multi-Hop Reasoning without Exploiting Shortcuts?**
2411.16679v1 by Sohee Yang, Nora Kassner, Elena Gribovskaya, Sebastian Riedel, Mor Geva

We evaluate how well Large Language Models (LLMs) latently recall and compose
facts to answer multi-hop queries like "In the year Scarlett Johansson was
born, the Summer Olympics were hosted in the country of". One major challenge
in evaluating this ability is that LLMs may have developed shortcuts by
encounters of the head entity "Scarlett Johansson" and the answer entity
"United States" in the same training sequences or merely guess the answer based
on frequency-based priors. To prevent shortcuts, we exclude test queries where
the head and answer entities co-appear in pretraining corpora. Through careful
selection of relations and facts and systematic removal of cases where models
might guess answers or exploit partial matches, we construct an evaluation
dataset SOCRATES (ShOrtCut-fRee lATent rEaSoning). We observe that LLMs
demonstrate promising latent multi-hop reasoning abilities without exploiting
shortcuts, but only for certain types of queries. For queries requiring latent
recall of countries as the intermediate answer, the best models achieve 80%
latent composability, but this drops to just 5% for the recall of years.
Comparisons with Chain-of-Thought composability highlight a significant gap
between the ability of models to reason latently versus explicitly. Analysis
reveals that latent representations of the intermediate answer are constructed
more often in queries with higher latent composability, and shows the emergence
of latent multi-hop reasoning during pretraining.

ÊëòË¶ÅÔºöÊàëÂÄëË©ï‰º∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÊΩõÂú®ÂõûÊÜ∂ÂíåÁµÑÂêà‰∫ãÂØ¶ÊñπÈù¢Ë°®ÁèæÂ¶Ç‰ΩïÔºå‰ª•ÂõûÁ≠îÂ§öÈáçË∑≥Ë∫çÊü•Ë©¢Ôºå‰æãÂ¶Ç„ÄåÂè≤ÂòâËïæÂñ¨ÈüìÊ£ÆÂá∫ÁîüÁöÑÈÇ£‰∏ÄÂπ¥ÔºåÂ§èÂ≠£Â•ßÈÅãÊúÉÂú®ÂúãÂÆ∂ËàâËæ¶„Äç„ÄÇË©ï‰º∞Ê≠§ËÉΩÂäõÁöÑ‰∏ÄÈ†ÖÈáçÂ§ßÊåëÊà∞Âú®ÊñºÔºåLLM ÂèØËÉΩÈÄèÈÅéÂú®Áõ∏ÂêåÁöÑË®ìÁ∑¥Â∫èÂàó‰∏≠ÈÅ≠ÈÅáÈ†≠ÈÉ®ÂØ¶È´î„ÄåÂè≤ÂòâËïæÂñ¨ÈüìÊ£Æ„ÄçÂíåÁ≠îÊ°àÂØ¶È´î„ÄåÁæéÂúã„ÄçËÄåÈñãÁôºÂá∫Êç∑ÂæëÔºåÊàñÂÉÖÊ†πÊìöÂü∫ÊñºÈ†ªÁéáÁöÑÂÖàÈ©óÁåúÊ∏¨Á≠îÊ°à„ÄÇÁÇ∫‰∫ÜÈò≤Ê≠¢Êç∑ÂæëÔºåÊàëÂÄëÊéíÈô§‰∫ÜÈ†≠ÈÉ®ÂíåÁ≠îÊ°àÂØ¶È´îÂú®È†êË®ìÁ∑¥Ë™ûÊñôÂ∫´‰∏≠ÂÖ±ÂêåÂá∫ÁèæÁöÑÊ∏¨Ë©¶Êü•Ë©¢„ÄÇÈÄèÈÅé‰ªîÁ¥∞ÈÅ∏ÊìáÈóú‰øÇÂíå‰∫ãÂØ¶Ôºå‰∏¶Á≥ªÁµ±ÊÄßÂú∞ÁßªÈô§Ê®°ÂûãÂèØËÉΩÁåúÊ∏¨Á≠îÊ°àÊàñÂà©Áî®ÈÉ®ÂàÜÂåπÈÖçÁöÑÊ°à‰æãÔºåÊàëÂÄëÂª∫Êßã‰∫Ü‰∏ÄÂÄãË©ï‰º∞Ë≥áÊñôÈõÜ SOCRATESÔºàShOrtCut-fRee lATent rEaSoningÔºâ„ÄÇÊàëÂÄëËßÄÂØüÂà∞ÔºåLLM Âú®‰∏çÂà©Áî®Êç∑ÂæëÁöÑÊÉÖÊ≥Å‰∏ãÂ±ïÁèæÂá∫ÊΩõÂú®ÁöÑÂ§öÈáçË∑≥Ë∫çÊé®ÁêÜËÉΩÂäõÔºå‰ΩÜÂÉÖÈôêÊñºÁâπÂÆöÈ°ûÂûãÁöÑÊü•Ë©¢„ÄÇÂ∞çÊñºÈúÄË¶ÅÊΩõÂú®ÂõûÊÜ∂ÂúãÂÆ∂‰ΩúÁÇ∫‰∏≠ÈñìÁ≠îÊ°àÁöÑÊü•Ë©¢ÔºåÊúÄ‰Ω≥Ê®°ÂûãÈÅîÂà∞ 80% ÁöÑÊΩõÂú®ÂèØÁµÑÂêàÊÄßÔºå‰ΩÜÈÄôÂ∞çÊñºÂõûÊÜ∂Âπ¥‰ªΩ‰æÜË™™ÂÉÖ‰∏ãÈôçÂà∞ 5%„ÄÇËàáÊÄùËÄÉÈèàÂèØÁµÑÂêàÊÄßÁöÑÊØîËºÉÁ™ÅÈ°Ø‰∫ÜÊ®°ÂûãÊΩõÂú®Êé®ÁêÜËàáÊòéÁ¢∫Êé®ÁêÜËÉΩÂäõ‰πãÈñìÁöÑÈ°ØËëóÂ∑ÆË∑ù„ÄÇÂàÜÊûêÈ°ØÁ§∫ÔºåÂú®ÊΩõÂú®ÂèØÁµÑÂêàÊÄßËºÉÈ´òÁöÑÊü•Ë©¢‰∏≠Ôºå‰∏≠ÈñìÁ≠îÊ°àÁöÑÊΩõÂú®Ë°®Á§∫Êõ¥Â∏∏Ë¢´Âª∫ÊßãÔºå‰∏¶È°ØÁ§∫Âú®È†êË®ìÁ∑¥ÊúüÈñìÂá∫ÁèæÊΩõÂú®ÁöÑÂ§öÈáçË∑≥Ë∫çÊé®ÁêÜ„ÄÇ

##### **CatNet: Effective FDR Control in LSTM with Gaussian Mirrors and SHAP Feature Importance**
2411.16666v1 by Jiaan Han, Junxiao Chen, Yanzhe Fu

We introduce CatNet, an algorithm that effectively controls False Discovery
Rate (FDR) and selects significant features in LSTM with the Gaussian Mirror
(GM) method. To evaluate the feature importance of LSTM in time series, we
introduce a vector of the derivative of the SHapley Additive exPlanations
(SHAP) to measure feature importance. We also propose a new kernel-based
dependence measure to avoid multicollinearity in the GM algorithm, to make a
robust feature selection with controlled FDR. We use simulated data to evaluate
CatNet's performance in both linear models and LSTM models with different link
functions. The algorithm effectively controls the FDR while maintaining a high
statistical power in all cases. We also evaluate the algorithm's performance in
different low-dimensional and high-dimensional cases, demonstrating its
robustness in various input dimensions. To evaluate CatNet's performance in
real world applications, we construct a multi-factor investment portfolio to
forecast the prices of S\&P 500 index components. The results demonstrate that
our model achieves superior predictive accuracy compared to traditional LSTM
models without feature selection and FDR control. Additionally, CatNet
effectively captures common market-driving features, which helps informed
decision-making in financial markets by enhancing the interpretability of
predictions. Our study integrates of the Gaussian Mirror algorithm with LSTM
models for the first time, and introduces SHAP values as a new feature
importance metric for FDR control methods, marking a significant advancement in
feature selection and error control for neural networks.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄë‰ªãÁ¥π CatNetÔºå‰∏ÄÁ®ÆÊúâÊïàÊéßÂà∂ÂÅáÈôΩÊÄßÁôºÁèæÁéá (FDR) ÁöÑÊºîÁÆóÊ≥ïÔºå‰∏¶‰ΩøÁî®È´òÊñØÈè°ÂÉè (GM) ÊñπÊ≥ïÈÅ∏Âèñ LSTM ‰∏≠ÁöÑÈáçË¶ÅÁâπÂæµ„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ LSTM Âú®ÊôÇÈñìÂ∫èÂàó‰∏≠ÁöÑÁâπÂæµÈáçË¶ÅÊÄßÔºåÊàëÂÄëÂºïÂÖ• SHapley Âä†Ê≥ïËß£Èáã (SHAP) ÁöÑÂ∞éÊï∏ÂêëÈáè‰æÜË°°ÈáèÁâπÂæµÈáçË¶ÅÊÄß„ÄÇÊàëÂÄëÈÇÑÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÂü∫ÊñºÊ†∏ÂøÉÁöÑ‰æùË≥¥ÊÄßÊ∏¨ÈáèÔºå‰ª•ÈÅøÂÖç GM ÊºîÁÆóÊ≥ï‰∏≠ÁöÑÂ§öÈáçÂÖ±Á∑öÊÄßÔºå‰ª•ÈÄ≤Ë°åÂÖ∑ÊúâÂèóÊéß FDR ÁöÑÁ©©ÂÅ•ÁâπÂæµÈÅ∏Âèñ„ÄÇÊàëÂÄë‰ΩøÁî®Ê®°Êì¨Ë≥áÊñô‰æÜË©ï‰º∞ CatNet Âú®ÂÖ∑Êúâ‰∏çÂêåÈÄ£ÁµêÂáΩÊï∏ÁöÑÁ∑öÊÄßÊ®°ÂûãÂíå LSTM Ê®°Âûã‰∏≠ÁöÑÊïàËÉΩ„ÄÇË©≤ÊºîÁÆóÊ≥ïÂú®ÊâÄÊúâÊÉÖÊ≥Å‰∏ãÈÉΩËÉΩÊúâÊïàÊéßÂà∂ FDRÔºåÂêåÊôÇ‰øùÊåÅÈ´òÁµ±Ë®àÂäüÊïà„ÄÇÊàëÂÄëÈÇÑË©ï‰º∞‰∫ÜË©≤ÊºîÁÆóÊ≥ïÂú®‰∏çÂêå‰ΩéÁ∂≠Â∫¶ÂíåÈ´òÁ∂≠Â∫¶ÊÉÖÊ≥Å‰∏ãÁöÑÊïàËÉΩÔºåË≠âÊòé‰∫ÜÂÖ∂Âú®ÂêÑÁ®ÆËº∏ÂÖ•Á∂≠Â∫¶‰∏≠ÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ CatNet Âú®ÂØ¶ÈöõÊáâÁî®‰∏≠ÁöÑÊïàËÉΩÔºåÊàëÂÄëÂª∫Êßã‰∫Ü‰∏ÄÂÄãÂ§öÂõ†Â≠êÊäïË≥áÁµÑÂêà‰æÜÈ†êÊ∏¨Ê®ôÊôÆ 500 ÊåáÊï∏ÊàêÂàÜÁöÑÂÉπÊ†º„ÄÇÁµêÊûúË°®ÊòéÔºåËàáÊ≤íÊúâÁâπÂæµÈÅ∏ÂèñÂíå FDR ÊéßÂà∂ÁöÑÂÇ≥Áµ± LSTM Ê®°ÂûãÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂØ¶Áèæ‰∫ÜÂçìË∂äÁöÑÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÊ≠§Â§ñÔºåCatNet ÊúâÊïàÂú∞Êì∑Âèñ‰∫ÜÂÖ±ÂêåÁöÑÂ∏ÇÂ†¥È©ÖÂãïÁâπÂæµÔºåÈÄôÊúâÂä©ÊñºÈÄèÈÅéÂ¢ûÂº∑È†êÊ∏¨ÁöÑÂèØËß£ÈáãÊÄßÔºåÂú®ÈáëËûçÂ∏ÇÂ†¥‰∏≠ÂÅöÂá∫ÊòéÊô∫ÁöÑÊ±∫Á≠ñ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂È¶ñÊ¨°Â∞áÈ´òÊñØÈè°ÂÉèÊºîÁÆóÊ≥ïËàá LSTM Ê®°ÂûãÊï¥ÂêàÔºå‰∏¶Â∞á SHAP ÂÄº‰ΩúÁÇ∫ FDR ÊéßÂà∂ÊñπÊ≥ïÁöÑÊñ∞ÁâπÂæµÈáçË¶ÅÊÄßÊåáÊ®ôÔºåÊ®ôË™åËëóÁ•ûÁ∂ìÁ∂≤Ë∑ØÁâπÂæµÈÅ∏ÂèñÂíåÈåØË™§ÊéßÂà∂ÁöÑÈáçÂ§ßÈÄ≤Â±ï„ÄÇ</paragraph>

##### **DreamRunner: Fine-Grained Storytelling Video Generation with Retrieval-Augmented Motion Adaptation**
2411.16657v1 by Zun Wang, Jialu Li, Han Lin, Jaehong Yoon, Mohit Bansal

Storytelling video generation (SVG) has recently emerged as a task to create
long, multi-motion, multi-scene videos that consistently represent the story
described in the input text script. SVG holds great potential for diverse
content creation in media and entertainment; however, it also presents
significant challenges: (1) objects must exhibit a range of fine-grained,
complex motions, (2) multiple objects need to appear consistently across
scenes, and (3) subjects may require multiple motions with seamless transitions
within a single scene. To address these challenges, we propose DreamRunner, a
novel story-to-video generation method: First, we structure the input script
using a large language model (LLM) to facilitate both coarse-grained scene
planning as well as fine-grained object-level layout and motion planning. Next,
DreamRunner presents retrieval-augmented test-time adaptation to capture target
motion priors for objects in each scene, supporting diverse motion
customization based on retrieved videos, thus facilitating the generation of
new videos with complex, scripted motions. Lastly, we propose a novel
spatial-temporal region-based 3D attention and prior injection module SR3AI for
fine-grained object-motion binding and frame-by-frame semantic control. We
compare DreamRunner with various SVG baselines, demonstrating state-of-the-art
performance in character consistency, text alignment, and smooth transitions.
Additionally, DreamRunner exhibits strong fine-grained condition-following
ability in compositional text-to-video generation, significantly outperforming
baselines on T2V-ComBench. Finally, we validate DreamRunner's robust ability to
generate multi-object interactions with qualitative examples.

ÊëòË¶ÅÔºöÊïÖ‰∫ãÊïòËø∞ÂΩ±ÁâáÁîüÊàê (SVG) ÊúÄËøëÊàêÁÇ∫‰∫ÜÁî¢ÁîüÈï∑ÁØá„ÄÅÂ§öÂãï‰Ωú„ÄÅÂ§öÂ†¥ÊôØÂΩ±ÁâáÁöÑ‰ªªÂãôÔºåÈÄô‰∫õÂΩ±ÁâáËÉΩÊåÅÁ∫åÂëàÁèæËº∏ÂÖ•ÊñáÂ≠óËÖ≥Êú¨‰∏≠ÊâÄÊèèËø∞ÁöÑÊïÖ‰∫ã„ÄÇSVG Âú®Â™íÈ´îÂíåÂ®õÊ®Ç‰∏≠ÊìÅÊúâÂª£Ê≥õÁöÑÂÖßÂÆπÂâµÈÄ†ÊΩõÂäõÔºõÁÑ∂ËÄåÔºåÂÆÉ‰πüÂ∏∂‰æÜ‰∫ÜÈáçÂ§ßÁöÑÊåëÊà∞Ôºö(1) Áâ©‰ª∂ÂøÖÈ†àÂ±ïÁèæ‰∏ÄÁ≥ªÂàóÁ¥∞Á∑ª„ÄÅË§áÈõúÁöÑÂãï‰ΩúÔºå(2) Â§öÂÄãÁâ©‰ª∂ÈúÄË¶ÅÂú®Â†¥ÊôØ‰∏≠ÊåÅÁ∫åÂá∫ÁèæÔºå(3) ‰∏ªÈ°åÂèØËÉΩÈúÄË¶ÅÂú®ÂñÆ‰∏ÄÂ†¥ÊôØ‰∏≠ÈÄ≤Ë°åÂ§öÂÄãÂãï‰ΩúÔºå‰∏¶ÈÄ≤Ë°åÁÑ°Á∏´ËΩâÊèõ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü DreamRunnerÔºå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊïÖ‰∫ãÂà∞ÂΩ±ÁâáÁîüÊàêÊñπÊ≥ïÔºöÈ¶ñÂÖàÔºåÊàëÂÄë‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÂª∫ÊßãËº∏ÂÖ•ËÖ≥Êú¨Ôºå‰ª•‰øÉÈÄ≤Á≤óÁï•ÁöÑÂ†¥ÊôØË¶èÂäÉ‰ª•ÂèäÁ¥∞Á∑ªÁöÑÁâ©‰ª∂Á¥öÂà•‰ΩàÂ±ÄÂíåÂãï‰ΩúË¶èÂäÉ„ÄÇÊé•‰∏ã‰æÜÔºåDreamRunner ÊèêÂá∫Ê™¢Á¥¢Â¢ûÂº∑ÁöÑÊ∏¨Ë©¶ÊôÇÈñìÈÅ©ÊáâÔºå‰ª•Êì∑ÂèñÊØèÂÄãÂ†¥ÊôØ‰∏≠Áâ©‰ª∂ÁöÑÁõÆÊ®ôÂãï‰ΩúÂÖàÈ©óÔºåÊîØÊè¥Âü∫ÊñºÊ™¢Á¥¢ÂΩ±ÁâáÁöÑÂ§öÊ®£ÂåñÂãï‰ΩúËá™Ë®ÇÔºåÂæûËÄå‰øÉÈÄ≤Áî¢ÁîüÂÖ∑ÊúâË§áÈõú„ÄÅËÖ≥Êú¨Âãï‰ΩúÁöÑÊñ∞ÂΩ±Áâá„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÂü∫ÊñºÊôÇÁ©∫ÂçÄÂüüÁöÑ 3D Ê≥®ÊÑèÂäõÂíåÂÖàÈ©óÊ≥®ÂÖ•Ê®°ÁµÑ SR3AIÔºåÁî®ÊñºÁ¥∞Á∑ªÁöÑÁâ©‰ª∂Âãï‰ΩúÁπ´ÁµêÂíåÈÄêÂπÄË™ûÁæ©ÊéßÂà∂„ÄÇÊàëÂÄëÂ∞á DreamRunner ËàáÂêÑÁ®Æ SVG Âü∫Ê∫ñÈÄ≤Ë°åÊØîËºÉÔºåË≠âÊòé‰∫ÜÂÖ∂Âú®ËßíËâ≤‰∏ÄËá¥ÊÄß„ÄÅÊñáÂ≠óÂ∞çÈΩäÂíåÊµÅÊö¢ÈÅéÊ∏°ÊñπÈù¢ÁöÑÊúÄÂÖàÈÄ≤ÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåDreamRunner Âú®ÁµÑÂêàÂºèÊñáÂ≠óÂà∞ÂΩ±ÁâáÁîüÊàê‰∏≠Â±ïÁèæÂá∫Âº∑Â§ßÁöÑÁ¥∞Á∑ªÊ¢ù‰ª∂ÈÅµÂæ™ËÉΩÂäõÔºåÂú® T2V-ComBench ‰∏äÊòéÈ°ØÂÑ™ÊñºÂü∫Ê∫ñ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈ©óË≠â‰∫Ü DreamRunner Áî¢ÁîüÂ§öÁâ©‰ª∂‰∫íÂãïÁöÑÂº∑Â§ßËÉΩÂäõÔºå‰∏¶Êèê‰æõ‰∫ÜÂÆöÊÄßÁØÑ‰æã„ÄÇ

##### **Self-Generated Critiques Boost Reward Modeling for Language Models**
2411.16646v1 by Yue Yu, Zhengxing Chen, Aston Zhang, Liang Tan, Chenguang Zhu, Richard Yuanzhe Pang, Yundi Qian, Xuewei Wang, Suchin Gururangan, Chao Zhang, Melanie Kambadur, Dhruv Mahajan, Rui Hou

Reward modeling is crucial for aligning large language models (LLMs) with
human preferences, especially in reinforcement learning from human feedback
(RLHF). However, current reward models mainly produce scalar scores and
struggle to incorporate critiques in a natural language format. We hypothesize
that predicting both critiques and the scalar reward would improve reward
modeling ability. Motivated by this, we propose Critic-RM, a framework that
improves reward models using self-generated critiques without extra
supervision. Critic-RM employs a two-stage process: generating and filtering
high-quality critiques, followed by joint fine-tuning on reward prediction and
critique generation. Experiments across benchmarks show that Critic-RM improves
reward modeling accuracy by 3.7%-7.3% compared to standard reward models and
LLM judges, demonstrating strong performance and data efficiency. Additional
studies further validate the effectiveness of generated critiques in rectifying
flawed reasoning steps with 2.5%-3.2% gains in improving reasoning accuracy.

ÊëòË¶ÅÔºöÁçéÂãµÂª∫Ê®°Â∞çÊñºÂ∞áÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ëàá‰∫∫È°ûÂÅèÂ•Ω‰øùÊåÅ‰∏ÄËá¥Ëá≥ÈóúÈáçË¶ÅÔºåÁâπÂà•ÊòØÂú®‰∫∫È°ûÂõûÈ•ãÁöÑÂº∑ÂåñÂ≠∏Áøí (RLHF) ‰∏≠„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑÁçéÂãµÊ®°Âûã‰∏ªË¶ÅÁî¢ÁîüÊ®ôÈáèÂàÜÊï∏Ôºå‰∏¶‰∏îÈõ£‰ª•‰ª•Ëá™ÁÑ∂Ë™ûË®ÄÊ†ºÂºèÁ¥çÂÖ•ÊâπË©ï„ÄÇÊàëÂÄëÂÅáË®≠È†êÊ∏¨ÊâπË©ïÂíåÊ®ôÈáèÁçéÂãµÈÉΩÊúÉÊèêÈ´òÁçéÂãµÂª∫Ê®°ËÉΩÂäõ„ÄÇÂü∫ÊñºÊ≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü Critic-RMÔºåÈÄôÊòØ‰∏ÄÂÄãÂà©Áî®Ëá™ÊàëÁîüÊàêÁöÑÊâπË©ï‰æÜÊîπÈÄ≤ÁçéÂãµÊ®°ÂûãÁöÑÊ°ÜÊû∂ÔºåËÄåÁÑ°ÈúÄÈ°çÂ§ñÁöÑÁõ£Áù£„ÄÇCritic-RM Êé°Áî®ÂÖ©ÈöéÊÆµÊµÅÁ®ãÔºöÁîüÊàêÂíåÈÅéÊøæÈ´òÂìÅË≥™ÁöÑÊâπË©ïÔºåÁÑ∂ÂæåÂú®ÁçéÂãµÈ†êÊ∏¨ÂíåÊâπË©ïÁîüÊàê‰∏äÈÄ≤Ë°åËÅØÂêàÂæÆË™ø„ÄÇÂü∫Ê∫ñÊ∏¨Ë©¶ÁöÑÂØ¶È©óË°®ÊòéÔºåËàáÊ®ôÊ∫ñÁçéÂãµÊ®°ÂûãÂíå LLM Ë©ïÂØ©Áõ∏ÊØîÔºåCritic-RM Â∞áÁçéÂãµÂª∫Ê®°Ê∫ñÁ¢∫Â∫¶ÊèêÈ´ò‰∫Ü 3.7%-7.3%ÔºåÂ±ïÁ§∫‰∫ÜÂº∑Â§ßÁöÑÊÄßËÉΩÂíåÊï∏ÊìöÊïàÁéá„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑÁ†îÁ©∂ÈÄ≤‰∏ÄÊ≠•È©óË≠â‰∫ÜÁîüÊàêÁöÑÊâπË©ïÂú®Á≥æÊ≠£ÊúâÁº∫Èô∑ÁöÑÊé®ÁêÜÊ≠•È©ü‰∏≠ÁöÑÊúâÊïàÊÄßÔºåÊé®ÁêÜÊ∫ñÁ¢∫Â∫¶ÊèêÈ´ò‰∫Ü 2.5%-3.2%„ÄÇ

##### **Recommender Systems for Good (RS4Good): Survey of Use Cases and a Call to Action for Research that Matters**
2411.16645v1 by Dietmar Jannach, Alan Said, Marko Tkalƒçiƒç, Markus Zanker

In the area of recommender systems, the vast majority of research efforts is
spent on developing increasingly sophisticated recommendation models, also
using increasingly more computational resources. Unfortunately, most of these
research efforts target a very small set of application domains, mostly
e-commerce and media recommendation. Furthermore, many of these models are
never evaluated with users, let alone put into practice. The scientific,
economic and societal value of much of these efforts by scholars therefore
remains largely unclear. To achieve a stronger positive impact resulting from
these efforts, we posit that we as a research community should more often
address use cases where recommender systems contribute to societal good
(RS4Good). In this opinion piece, we first discuss a number of examples where
the use of recommender systems for problems of societal concern has been
successfully explored in the literature. We then proceed by outlining a
paradigmatic shift that is needed to conduct successful RS4Good research, where
the key ingredients are interdisciplinary collaborations and longitudinal
evaluation approaches with humans in the loop.

ÊëòË¶ÅÔºöÂú®Êé®Ëñ¶Á≥ªÁµ±È†òÂüüÔºåÁµïÂ§ßÂ§öÊï∏ÁöÑÁ†îÁ©∂Â∑•‰ΩúÈÉΩËä±Âú®ÈñãÁôºÊó•ÁõäÁ≤æÂØÜÁöÑÊé®Ëñ¶Ê®°ÂûãÔºåÂêåÊôÇ‰πü‰ΩøÁî®Ë∂ä‰æÜË∂äÂ§öÈÅãÁÆóË≥áÊ∫ê„ÄÇ‰∏çÂπ∏ÁöÑÊòØÔºåÈÄô‰∫õÁ†îÁ©∂Â∑•‰ΩúÂ§ßÂ§öÈáùÂ∞çÈùûÂ∏∏Â∞èÁöÑ‰∏ÄÁµÑÊáâÁî®È†òÂüüÔºå‰∏ªË¶ÅÊòØÈõªÂ≠êÂïÜÂãôÂíåÂ™íÈ´îÊé®Ëñ¶„ÄÇÊ≠§Â§ñÔºåÈÄô‰∫õÊ®°Âûã‰∏≠ÁöÑË®±Â§öÊ®°ÂûãÂæûÊú™Á∂ìÈÅé‰ΩøÁî®ËÄÖË©ï‰º∞ÔºåÊõ¥‰∏çÁî®Ë™™‰ªòË´∏ÂØ¶Ë∏ê‰∫Ü„ÄÇÂõ†Ê≠§ÔºåÂ≠∏ËÄÖÂÄëÂú®ÈÄô‰∫õÂ∑•‰Ωú‰∏äÁöÑÁßëÂ≠∏„ÄÅÁ∂ìÊøüÂíåÁ§æÊúÉÂÉπÂÄºÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰ªç‰∏çÊ∏ÖÊ•ö„ÄÇÁÇ∫‰∫ÜËÆìÈÄô‰∫õÂ∑•‰ΩúÁî¢ÁîüÊõ¥Âº∑Â§ßÁöÑÊ≠£Èù¢ÂΩ±ÈüøÔºåÊàëÂÄëË™çÁÇ∫ÊàëÂÄë‰ΩúÁÇ∫‰∏ÄÂÄãÁ†îÁ©∂Á§æÁæ§ÊáâË©≤Êõ¥Â∏∏Ëß£Ê±∫Êé®Ëñ¶Á≥ªÁµ±Â∞çÁ§æÊúÉÊúâÁõäÁöÑÁî®‰æãÔºàRS4GoodÔºâ„ÄÇÂú®ÈÄôÁØáÊÑèË¶ãÊñáÁ´†‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖàË®éË´ñ‰∫Ü‰∏Ä‰∫õÁØÑ‰æãÔºåÂÖ∂‰∏≠Âú®ÊñáÁçª‰∏≠Â∑≤ÊàêÂäüÊé¢Á¥¢‰∫ÜÂ∞áÊé®Ëñ¶Á≥ªÁµ±Áî®ÊñºÁ§æÊúÉÈóúÊ≥®ÁöÑÂïèÈ°å„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊé•ËëóÊ¶ÇËø∞ÈÄ≤Ë°åÊàêÂäüÁöÑ RS4Good Á†îÁ©∂ÊâÄÈúÄÁöÑÂÖ∏ÁØÑËΩâÁßªÔºåÂÖ∂‰∏≠ÈóúÈçµË¶ÅÁ¥†ÊòØË∑®È†òÂüüÂêà‰ΩúÂíå‰∫∫È°ûÂèÉËàáÁöÑÁ∏±ÂêëË©ï‰º∞ÊñπÊ≥ï„ÄÇ

##### **Preventing Jailbreak Prompts as Malicious Tools for Cybercriminals: A Cyber Defense Perspective**
2411.16642v1 by Jean Marie Tshimula, Xavier Ndona, D'Jeff K. Nkashama, Pierre-Martin Tardif, Froduald Kabanza, Marc Frappier, Shengrui Wang

Jailbreak prompts pose a significant threat in AI and cybersecurity, as they
are crafted to bypass ethical safeguards in large language models, potentially
enabling misuse by cybercriminals. This paper analyzes jailbreak prompts from a
cyber defense perspective, exploring techniques like prompt injection and
context manipulation that allow harmful content generation, content filter
evasion, and sensitive information extraction. We assess the impact of
successful jailbreaks, from misinformation and automated social engineering to
hazardous content creation, including bioweapons and explosives. To address
these threats, we propose strategies involving advanced prompt analysis,
dynamic safety protocols, and continuous model fine-tuning to strengthen AI
resilience. Additionally, we highlight the need for collaboration among AI
researchers, cybersecurity experts, and policymakers to set standards for
protecting AI systems. Through case studies, we illustrate these cyber defense
approaches, promoting responsible AI practices to maintain system integrity and
public trust. \textbf{\color{red}Warning: This paper contains content which the
reader may find offensive.}

ÊëòË¶ÅÔºöË∂äÁçÑÊèêÁ§∫Âú® AI ÂíåÁ∂≤Ë∑ØÂÆâÂÖ®È†òÂüü‰∏≠ÊßãÊàêÈáçÂ§ßÂ®ÅËÑÖÔºåÂõ†ÁÇ∫ÂÆÉÂÄëË¢´Ë®≠Ë®àÊàêÁπûÈÅéÂ§ßÂûãË™ûË®ÄÊ®°Âûã‰∏≠ÁöÑÈÅìÂæ∑Èò≤Ë≠∑Êé™ÊñΩÔºåÈÄôÂèØËÉΩÊúÉËÆìÁ∂≤Ë∑ØÁäØÁΩ™ÂàÜÂ≠êÂæó‰ª•Êø´Áî®„ÄÇÊú¨ÊñáÂæûÁ∂≤Ë∑ØÈò≤Á¶¶ËßíÂ∫¶ÂàÜÊûêË∂äÁçÑÊèêÁ§∫ÔºåÊé¢Ë®éÊèêÁ§∫Ê≥®ÂÖ•ÂíåÂÖßÂÆπÊìçÁ∏±Á≠âÊäÄË°ìÔºåÈÄô‰∫õÊäÄË°ìÂÖÅË®±Áî¢ÁîüÊúâÂÆ≥ÂÖßÂÆπ„ÄÅË¶èÈÅøÂÖßÂÆπÈÅéÊøæÂô®ÂíåÊèêÂèñÊïèÊÑüË≥áË®ä„ÄÇÊàëÂÄëË©ï‰º∞ÊàêÂäüË∂äÁçÑÁöÑÂΩ±ÈüøÔºåÂæûÈåØË™§Ë≥áË®äÂíåËá™ÂãïÂåñÁ§æÊúÉÂ∑•Á®ãÂà∞Âç±Èö™ÂÖßÂÆπÁöÑÂª∫Á´ãÔºåÂåÖÊã¨ÁîüÁâ©Ê≠¶Âô®ÂíåÁÇ∏Ëó•„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÂ®ÅËÑÖÔºåÊàëÂÄëÊèêÂá∫Ê∂âÂèäÈÄ≤ÈöéÊèêÁ§∫ÂàÜÊûê„ÄÅÂãïÊÖãÂÆâÂÖ®ÂçîÂÆöÂíåÊåÅÁ∫åÊ®°ÂûãÂæÆË™øÁöÑÁ≠ñÁï•Ôºå‰ª•Âº∑Âåñ AI ÁöÑÈüåÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂº∑Ë™ø AI Á†îÁ©∂‰∫∫Âì°„ÄÅÁ∂≤Ë∑ØÂÆâÂÖ®Â∞àÂÆ∂ÂíåÊîøÁ≠ñÂà∂ÂÆöËÄÖ‰πãÈñìÈúÄË¶ÅÂêà‰ΩúÔºå‰ª•Âà∂ÂÆö‰øùË≠∑ AI Á≥ªÁµ±ÁöÑÊ®ôÊ∫ñ„ÄÇÈÄèÈÅéÊ°à‰æãÁ†îÁ©∂ÔºåÊàëÂÄëË™™ÊòéÈÄô‰∫õÁ∂≤Ë∑ØÈò≤Á¶¶ÊñπÊ≥ïÔºåÊé®Âª£Ë≤†Ë≤¨‰ªªÁöÑ AI ÂØ¶ÂãôÔºå‰ª•Á∂≠Ë≠∑Á≥ªÁµ±ÂÆåÊï¥ÊÄßÂíåÂÖ¨Áúæ‰ø°‰ªª„ÄÇ\textbf{\color{red}Ë≠¶ÂëäÔºöÊú¨ÊñáÂåÖÂê´ËÆÄËÄÖÂèØËÉΩË¶∫Âæó‰ª§‰∫∫ÂèçÊÑüÁöÑÂÖßÂÆπ„ÄÇ}

##### **Do Automatic Factuality Metrics Measure Factuality? A Critical Evaluation**
2411.16638v1 by Sanjana Ramprasad, Byron C. Wallace

Modern LLMs can now produce highly readable abstractive summaries, to the
point where traditional automated metrics for evaluating summary quality, such
as ROUGE, have become saturated. However, LLMs still sometimes introduce
unwanted content into summaries, i.e., information inconsistent with or
unsupported by their source. Measuring the occurrence of these often subtle
``hallucinations'' automatically has proved to be challenging. This in turn has
motivated development of a variety of metrics intended to measure the factual
consistency of generated summaries against their source. But are these
approaches measuring what they purport to do? In this work, we stress-test
automatic factuality metrics. Specifically, we investigate whether and to what
degree superficial attributes of summary texts suffice to predict
``factuality'', finding that a (supervised) model using only such shallow
features is reasonably competitive with SOTA factuality scoring methods. We
then evaluate how factuality metrics respond to factual corrections in
inconsistent summaries and find that only a few show meaningful improvements.
In contrast, some metrics are more sensitive to benign, non-factual edits.
Motivated by these insights, we show that one can ``game'' (most) automatic
factuality metrics, i.e., reliably inflate ``factuality'' scores by appending
innocuous sentences to generated summaries.Taken together, our results raise
questions about the degree to which we should rely on existing automated
factuality metrics and what exactly we want ``factuality metrics'' to measure.

ÊëòË¶ÅÔºöÁèæ‰ª£ÁöÑ LLM ÁèæÂú®ÂèØ‰ª•Áî¢ÁîüÈ´òÂ∫¶ÂèØËÆÄÁöÑÊäΩË±°ÊëòË¶ÅÔºå‰ª•Ëá≥ÊñºÁî®ÊñºË©ï‰º∞ÊëòË¶ÅÂìÅË≥™ÁöÑÂÇ≥Áµ±Ëá™ÂãïÂåñÊåáÊ®ôÔºå‰æãÂ¶Ç ROUGEÔºåÂ∑≤ËÆäÂæóÈ£ΩÂíå„ÄÇÁÑ∂ËÄåÔºåLLM ÊúâÊôÇ‰ªçÊúÉÂú®ÊëòË¶Å‰∏≠ÂºïÂÖ•‰∏çÈúÄË¶ÅÁöÑÂÖßÂÆπÔºåÂç≥ËàáÂÖ∂‰æÜÊ∫ê‰∏ç‰∏ÄËá¥Êàñ‰∏çÂèóÂÖ∂‰æÜÊ∫êÊîØÊåÅÁöÑË≥áË®ä„ÄÇË°°ÈáèÈÄô‰∫õÈÄöÂ∏∏ÂæàÂæÆÂ¶ôÁöÑ„ÄåÂπªË¶∫„ÄçÁöÑÁôºÁîüÊÉÖÊ≥ÅÂ∑≤Ë≠âÊòéÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÈÄôÂèçÈÅé‰æÜÂèà‰øÉ‰ΩøÈñãÁôºÂêÑÁ®ÆÊåáÊ®ôÔºåÊó®Âú®Ë°°ÈáèÁî¢ÁîüÁöÑÊëòË¶ÅËàáÂÖ∂‰æÜÊ∫êÁöÑ‰∫ãÂØ¶‰∏ÄËá¥ÊÄß„ÄÇ‰ΩÜÈÄô‰∫õÊñπÊ≥ïÊòØÂê¶Ë°°Èáè‰∫ÜÂÆÉÂÄëËÅ≤Á®±Ë¶ÅÂÅöÁöÑÔºüÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ∞çËá™Âãï‰∫ãÂØ¶ÊÄßÊåáÊ®ôÈÄ≤Ë°åÂ£ìÂäõÊ∏¨Ë©¶„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëË™øÊü•ÊëòË¶ÅÊñáÂ≠óÁöÑË°®Èù¢Â±¨ÊÄßÊòØÂê¶Ë∂≥‰ª•È†êÊ∏¨„Äå‰∫ãÂØ¶ÊÄß„ÄçÔºå‰∏¶ÁôºÁèæÂÉÖ‰ΩøÁî®Ê≠§È°ûÊ∑∫Â±§ÁâπÂæµÁöÑÔºàÁõ£Áù£ÔºâÊ®°ÂûãËàá SOTA ‰∫ãÂØ¶ÊÄßË©ïÂàÜÊñπÊ≥ïÁõ∏Áï∂ÊúâÁ´∂Áà≠Âäõ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëË©ï‰º∞‰∫ãÂØ¶ÊÄßÊåáÊ®ôÂ¶Ç‰ΩïÂ∞ç‰∏ç‰∏ÄËá¥ÊëòË¶Å‰∏≠ÁöÑ‰∫ãÂØ¶Êõ¥Ê≠£ÂÅöÂá∫ÂèçÊáâÔºå‰∏¶ÁôºÁèæÂè™ÊúâÂ∞ëÊï∏È°ØÁ§∫Âá∫ÊúâÊÑèÁæ©ÁöÑÊîπÈÄ≤„ÄÇÁõ∏ÂèçÔºå‰∏Ä‰∫õÊåáÊ®ôÂ∞çËâØÊÄßÁöÑÈùû‰∫ãÂØ¶Á∑®ËºØÊõ¥ÊïèÊÑü„ÄÇÂèóÂà∞ÈÄô‰∫õË¶ãËß£ÁöÑÂïüÁôºÔºåÊàëÂÄëË°®Êòé‰∫∫ÂÄëÂèØ‰ª•„ÄåÁé©„ÄçÂ§ßÂ§öÊï∏Ëá™Âãï‰∫ãÂØ¶ÊÄßÊåáÊ®ôÔºåÂç≥ÈÄèÈÅéÂú®Áî¢ÁîüÁöÑÊëòË¶Å‰∏≠ÈôÑÂä†ÁÑ°ÂÆ≥ÁöÑÂè•Â≠ê‰æÜÂèØÈù†Âú∞ÊèêÈ´ò„Äå‰∫ãÂØ¶ÊÄß„ÄçÂàÜÊï∏„ÄÇÁ∂úÂêàËµ∑‰æÜÔºåÊàëÂÄëÁöÑÁµêÊûúÂºïÁôº‰∫ÜÈóúÊñºÊàëÂÄëÊáâÂú®Â§öÂ§ßÁ®ãÂ∫¶‰∏ä‰æùË≥¥ÁèæÊúâÁöÑËá™Âãï‰∫ãÂØ¶ÊÄßÊåáÊ®ô‰ª•ÂèäÊàëÂÄëÁ¢∫ÂàáÂ∏åÊúõ„Äå‰∫ãÂØ¶ÊÄßÊåáÊ®ô„ÄçË°°Èáè‰ªÄÈ∫ºÁöÑÂïèÈ°å„ÄÇ

##### **Imperceptible Adversarial Examples in the Physical World**
2411.16622v1 by Weilin Xu, Sebastian Szyller, Cory Cornelius, Luis Murillo Rojas, Marius Arvinte, Alvaro Velasquez, Jason Martin, Nageen Himayat

Adversarial examples in the digital domain against deep learning-based
computer vision models allow for perturbations that are imperceptible to human
eyes. However, producing similar adversarial examples in the physical world has
been difficult due to the non-differentiable image distortion functions in
visual sensing systems. The existing algorithms for generating physically
realizable adversarial examples often loosen their definition of adversarial
examples by allowing unbounded perturbations, resulting in obvious or even
strange visual patterns. In this work, we make adversarial examples
imperceptible in the physical world using a straight-through estimator (STE,
a.k.a. BPDA). We employ STE to overcome the non-differentiability -- applying
exact, non-differentiable distortions in the forward pass of the
backpropagation step, and using the identity function in the backward pass. Our
differentiable rendering extension to STE also enables imperceptible
adversarial patches in the physical world. Using printout photos, and
experiments in the CARLA simulator, we show that STE enables fast generation of
$\ell_\infty$ bounded adversarial examples despite the non-differentiable
distortions. To the best of our knowledge, this is the first work demonstrating
imperceptible adversarial examples bounded by small $\ell_\infty$ norms in the
physical world that force zero classification accuracy in the global
perturbation threat model and cause near-zero ($4.22\%$) AP50 in object
detection in the patch perturbation threat model. We urge the community to
re-evaluate the threat of adversarial examples in the physical world.

ÊëòË¶ÅÔºö<paragraph>ÈáùÂ∞çÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÈõªËÖ¶Ë¶ñË¶∫Ê®°ÂûãÁöÑÊï∏‰ΩçÈ†òÂüüÂ∞çÊäóÁØÑ‰æãÂÖÅË®±‰∫∫ÁúºÁÑ°Ê≥ïÂØüË¶∫ÁöÑÊìæÂãï„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºË¶ñË¶∫ÊÑüÊ∏¨Á≥ªÁµ±‰∏≠‰∏çÂèØÂæÆÂàÜÁöÑÂΩ±ÂÉèÂ§±ÁúüÂáΩÊï∏ÔºåÂú®Áâ©ÁêÜ‰∏ñÁïå‰∏≠Áî¢ÁîüÈ°û‰ººÁöÑÂ∞çÊäóÁØÑ‰æã‰∏ÄÁõ¥ÂæàÂõ∞Èõ£„ÄÇÁèæÊúâÁöÑÊºîÁÆóÊ≥ïÁî®ÊñºÁî¢ÁîüÁâ©ÁêÜ‰∏äÂèØÂØ¶ÁèæÁöÑÂ∞çÊäóÁØÑ‰æãÔºåÈÄöÂ∏∏ÈÄèÈÅéÂÖÅË®±ÁÑ°ÁïåÁöÑÊìæÂãï‰æÜÊîæÂØ¨Â∞çÊäóÁØÑ‰æãÁöÑÂÆöÁæ©ÔºåÂ∞éËá¥ÊòéÈ°ØÁîöËá≥Â•áÊÄ™ÁöÑË¶ñË¶∫Ê®°Âºè„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ΩøÁî®Áõ¥ÈÄö‰º∞Ë®àÂô® (STEÔºåÂèàÁ®± BPDA) Âú®Áâ©ÁêÜ‰∏ñÁïå‰∏≠Ë£Ω‰ΩúÁÑ°Ê≥ïÂØüË¶∫ÁöÑÂ∞çÊäóÁØÑ‰æã„ÄÇÊàëÂÄëÊé°Áî® STE ‰æÜÂÖãÊúç‰∏çÂèØÂæÆÂàÜÊÄßÔºåÂú®ÂèçÂêëÂÇ≥Êí≠Ê≠•È©üÁöÑÂâçÂêëÂÇ≥ÈÅû‰∏≠ÊáâÁî®Á≤æÁ¢∫ÁöÑ‰∏çÂèØÂæÆÂàÜÂ§±ÁúüÔºå‰∏¶Âú®ÂèçÂêëÂÇ≥ÈÅû‰∏≠‰ΩøÁî®ÊÅÜÁ≠âÂáΩÊï∏„ÄÇÊàëÂÄëÂ∞ç STE ÁöÑÂèØÂæÆÂàÜÊ∏≤ÊüìÂª∂‰º∏‰πüËÆìÁâ©ÁêÜ‰∏ñÁïå‰∏≠ÁöÑÂ∞çÊäóÊÄßË≤ºÁâáÁÑ°Ê≥ïÂØüË¶∫„ÄÇÈÄèÈÅéÂàóÂç∞ÁÖßÁâáÔºå‰ª•ÂèäÂú® CARLA Ê®°Êì¨Âô®‰∏≠ÁöÑÂØ¶È©óÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü STE ËÉΩÂ§†Âø´ÈÄüÁî¢Áîü $\ell_\infty$ ÊúâÁïåÂ∞çÊäóÁØÑ‰æãÔºåÂÑòÁÆ°Êúâ‰∏çÂèØÂæÆÂàÜÁöÑÂ§±Áúü„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂú®Áâ©ÁêÜ‰∏ñÁïå‰∏≠Â±ïÁ§∫Áî±Â∞è $\ell_\infty$ Ë¶èÊ†ºÈôêÂà∂ÁöÑÁÑ°Ê≥ïÂØüË¶∫Â∞çÊäóÁØÑ‰æãÁöÑÂ∑•‰ΩúÔºåÂú®ÂÖ®ÂüüÊìæÂãïÂ®ÅËÑÖÊ®°Âûã‰∏≠Âº∑Âà∂Èõ∂ÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶Ôºå‰∏¶Âú®Ë≤ºÁâáÊìæÂãïÂ®ÅËÑÖÊ®°Âûã‰∏≠Â∞éËá¥Êé•ËøëÈõ∂ ($4.22\%$) ÁöÑ AP50 Áâ©‰ª∂ÂÅµÊ∏¨„ÄÇÊàëÂÄëÊï¶‰øÉÁ§æÁæ§ÈáçÊñ∞Ë©ï‰º∞Áâ©ÁêÜ‰∏ñÁïå‰∏≠Â∞çÊäóÁØÑ‰æãÁöÑÂ®ÅËÑÖ„ÄÇ</paragraph>

##### **StructFormer: Document Structure-based Masked Attention and its Impact on Language Model Pre-Training**
2411.16618v1 by Kaustubh Ponkshe, Venkatapathy Subramanian, Natwar Modani, Ganesh Ramakrishnan

Most state-of-the-art techniques for Language Models (LMs) today rely on
transformer-based architectures and their ubiquitous attention mechanism.
However, the exponential growth in computational requirements with longer input
sequences confines Transformers to handling short passages. Recent efforts have
aimed to address this limitation by introducing selective attention mechanisms,
notably local and global attention. While sparse attention mechanisms, akin to
full attention in being Turing-complete, have been theoretically established,
their practical impact on pre-training remains unexplored. This study focuses
on empirically assessing the influence of global attention on BERT
pre-training. The primary steps involve creating an extensive corpus of
structure-aware text through arXiv data, alongside a text-only counterpart. We
carry out pre-training on these two datasets, investigate shifts in attention
patterns, and assess their implications for downstream tasks. Our analysis
underscores the significance of incorporating document structure into LM
models, demonstrating their capacity to excel in more abstract tasks, such as
document understanding.

ÊëòË¶ÅÔºöÁèæ‰ªäÂ§öÊï∏Ë™ûË®ÄÊ®°Âûã (LM) ÁöÑÊúÄÂÖàÈÄ≤ÊäÄË°ì‰ª∞Ë≥¥ÊñºÂü∫ÊñºËΩâÊèõÂô®ÁöÑÊû∂ÊßãÂèäÂÖ∂ÊôÆÈÅçÁöÑÊ≥®ÊÑèÂäõÊ©üÂà∂„ÄÇ
ÁÑ∂ËÄåÔºåÈö®ËëóËº∏ÂÖ•Â∫èÂàóËÆäÈï∑ÔºåÈÅãÁÆóÈúÄÊ±ÇÂëàÊåáÊï∏ÊàêÈï∑ÔºåÂ∞áËΩâÊèõÂô®ÈôêÂà∂Âú®ËôïÁêÜÁü≠ÁØáÁ´†ÁØÄ„ÄÇÊúÄËøëÁöÑÂä™ÂäõÊó®Âú®ÈÄèÈÅéÂºïÂÖ•ÈÅ∏ÊìáÊÄßÊ≥®ÊÑèÂäõÊ©üÂà∂‰æÜËß£Ê±∫Ê≠§ÈôêÂà∂ÔºåÁâπÂà•ÊòØÂ±ÄÈÉ®ÂíåÂÖ®Â±ÄÊ≥®ÊÑèÂäõ„ÄÇÈõñÁÑ∂Á®ÄÁñèÊ≥®ÊÑèÂäõÊ©üÂà∂È°û‰ººÊñºÂú®ÂúñÈùàÂÆåÂÇôÊÄß‰∏≠ÁöÑÂÆåÊï¥Ê≥®ÊÑèÂäõÔºåÂ∑≤Âú®ÁêÜË´ñ‰∏äÂª∫Á´ãÔºå‰ΩÜÂÖ∂Â∞çÈ†êË®ìÁ∑¥ÁöÑÂØ¶ÈöõÂΩ±Èüø‰ªçÊú™Êé¢Ë®é„ÄÇÊú¨Á†îÁ©∂Â∞àÊ≥®ÊñºÁ∂ìÈ©óË©ï‰º∞ÂÖ®Â±ÄÊ≥®ÊÑèÂäõÂ∞ç BERT È†êË®ìÁ∑¥ÁöÑÂΩ±Èüø„ÄÇ‰∏ªË¶ÅÊ≠•È©üÂåÖÊã¨ÈÄèÈÅé arXiv Ë≥áÊñôÂª∫Á´ãÂª£Ê≥õÁöÑÁµêÊßãÊÑüÁü•ÊñáÂ≠óË™ûÊñôÂ∫´Ôºå‰ª•ÂèäÁ¥îÊñáÂ≠óÂ∞çÊáâÁâàÊú¨„ÄÇÊàëÂÄëÂ∞çÈÄôÂÖ©ÂÄãË≥áÊñôÈõÜÈÄ≤Ë°åÈ†êË®ìÁ∑¥ÔºåÊé¢Ë®éÊ≥®ÊÑèÂäõÊ®°ÂºèÁöÑËΩâËÆäÔºå‰∏¶Ë©ï‰º∞ÂÖ∂Â∞ç‰∏ãÊ∏∏‰ªªÂãôÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÂº∑Ë™øÂ∞áÊñá‰ª∂ÁµêÊßãÁ¥çÂÖ• LM Ê®°ÂûãÁöÑÈáçË¶ÅÊÄßÔºåË≠âÊòéÂÖ∂Âú®Êõ¥ÊäΩË±°‰ªªÂãôÔºà‰æãÂ¶ÇÊñá‰ª∂ÁêÜËß£Ôºâ‰∏≠Ë°®ÁèæÂÑ™Áï∞ÁöÑËÉΩÂäõ„ÄÇ

##### **Recent Trends in Linear Text Segmentation: a Survey**
2411.16613v1 by Iacopo Ghinassi, Lin Wang, Chris Newell, Matthew Purver

Linear Text Segmentation is the task of automatically tagging text documents
with topic shifts, i.e. the places in the text where the topics change. A
well-established area of research in Natural Language Processing, drawing from
well-understood concepts in linguistic and computational linguistic research,
the field has recently seen a lot of interest as a result of the surge of text,
video, and audio available on the web, which in turn require ways of
summarising and categorizing the mole of content for which linear text
segmentation is a fundamental step. In this survey, we provide an extensive
overview of current advances in linear text segmentation, describing the state
of the art in terms of resources and approaches for the task. Finally, we
highlight the limitations of available resources and of the task itself, while
indicating ways forward based on the most recent literature and under-explored
research directions.

ÊëòË¶ÅÔºöÁ∑öÊÄßÊñáÊú¨ÂàÜÊÆµÊòØËá™ÂãïÊ®ôË®òÊñáÊú¨Êñá‰ª∂
‰∏ªÈ°åËΩâÊèõÔºåÂç≥ÊñáÊú¨‰∏≠‰∏ªÈ°åËÆäÊõ¥ÁöÑÂú∞Êñπ„ÄÇËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰∏≠‰∏ÄÂÄãÂª∫Á´ãËâØÂ•ΩÁöÑÁ†îÁ©∂È†òÂüüÔºåÊ±≤Âèñ
Ë™ûË®ÄÂ≠∏ÂíåË®àÁÆóË™ûË®ÄÂ≠∏Á†îÁ©∂‰∏≠ÁêÜËß£ËâØÂ•ΩÁöÑÊ¶ÇÂøµÔºåË©≤È†òÂüüÊúÄËøëÂõ†Á∂≤Ë∑Ø‰∏äÂ§ßÈáèÊπßÁèæÁöÑÊñáÂ≠ó„ÄÅ
ÂΩ±ÁâáÂíåÈü≥Ë®äËÄåÂÇôÂèóÈóúÊ≥®ÔºåËÄåÈÄô‰∫õÂÖßÂÆπÈúÄË¶ÅÁ∏ΩÁµêÂíåÂàÜÈ°ûÔºåËÄåÁ∑öÊÄßÊñáÊú¨ÂàÜÊÆµÊ≠£ÊòØÂü∫Êú¨Ê≠•È©ü„ÄÇÂú®ÈÄôÈ†ÖË™øÊü•‰∏≠ÔºåÊàëÂÄëÊèê‰æõÁ∑öÊÄßÊñáÊú¨ÂàÜÊÆµÁï∂ÂâçÈÄ≤Â±ïÁöÑÂª£Ê≥õÊ¶ÇËø∞ÔºåË™™Êòé‰ªªÂãôÂú®Ë≥áÊ∫êÂíåÊñπÊ≥ïÊñπÈù¢ÁöÑÊúÄÊñ∞ÈÄ≤Â±ï„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂº∑Ë™øÂèØÁî®Ë≥áÊ∫êÂíå‰ªªÂãôÊú¨Ë∫´ÁöÑÈôêÂà∂ÔºåÂêåÊôÇÊ†πÊìöÊúÄÊñ∞ÊñáÁçªÂíåÂ∞öÊú™Êé¢Á¥¢ÁöÑÁ†îÁ©∂ÊñπÂêëÊåáÂá∫ÂâçÈÄ≤ÁöÑÊñπÂêë„ÄÇ

##### **F -- A Model of Events based on the Foundational Ontology DOLCE+DnS Ultralite**
2411.16609v1 by Ansgar Scherp, Thomas Franz, Carsten Saathoff, Steffen Staab

The lack of a formal model of events hinders interoperability in distributed
event-based systems. In this paper, we present a formal model of events, called
Event-Model-F. The model is based on the foundational ontology DOLCE+DnS
Ultralite (DUL) and provides comprehensive support to represent time and space,
objects and persons, as well as mereological, causal, and correlative
relationships between events. In addition, the Event-Model-F provides a
flexible means for event composition, modeling event causality and event
correlation, and representing different interpretations of the same event. The
Event-Model-F is developed following the pattern-oriented approach of DUL, is
modularized in different ontologies, and can be easily extended by domain
specific ontologies.

ÊëòË¶ÅÔºöÁº∫‰πèÊ≠£ÂºèÁöÑ‰∫ã‰ª∂Ê®°ÂûãÊúÉÈòªÁ§ôÂàÜÊï£Âºè‰∫ã‰ª∂Âü∫Á§éÁ≥ªÁµ±‰∏≠ÁöÑ‰∫íÊìç‰ΩúÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∫ã‰ª∂ÁöÑÊ≠£ÂºèÊ®°ÂûãÔºåÁ®±ÁÇ∫‰∫ã‰ª∂Ê®°Âûã F„ÄÇË©≤Ê®°ÂûãÂü∫ÊñºÂü∫Á§éÊú¨‰Ωì DOLCE+DnS Ultralite (DUL)Ôºå‰∏¶Êèê‰æõÂÖ®Èù¢ÁöÑÊîØÊè¥‰æÜË°®Á§∫ÊôÇÈñìÂíåÁ©∫Èñì„ÄÅÁâ©‰ª∂Âíå‰∫∫Áâ©Ôºå‰ª•Âèä‰∫ã‰ª∂‰πãÈñìÁöÑÂîØË±°Â≠∏„ÄÅÂõ†ÊûúÂíåÁõ∏ÈóúÈóú‰øÇ„ÄÇÊ≠§Â§ñÔºå‰∫ã‰ª∂Ê®°Âûã F Êèê‰æõ‰∫Ü‰∏ÄÁ®ÆÈùàÊ¥ªÁöÑÊñπÊ≥ï‰æÜÈÄ≤Ë°å‰∫ã‰ª∂ÁµÑÂêà„ÄÅÂª∫Ê®°‰∫ã‰ª∂Âõ†ÊûúÈóú‰øÇÂíå‰∫ã‰ª∂Áõ∏ÈóúÊÄßÔºå‰ª•ÂèäË°®Á§∫Âêå‰∏ÄÂÄã‰∫ã‰ª∂ÁöÑ‰∏çÂêåËß£Èáã„ÄÇ‰∫ã‰ª∂Ê®°Âûã F ÊòØÈÅµÂæ™ DUL ÁöÑÊ®°ÂºèÂ∞éÂêëÊñπÊ≥ïÈñãÁôºÁöÑÔºåÂú®‰∏çÂêåÁöÑÊú¨‰Ωì‰∏≠Ê®°ÁµÑÂåñÔºå‰∏¶‰∏îÂèØ‰ª•ÈÄèÈÅéÁâπÂÆöÊñºÈ†òÂüüÁöÑÊú¨‰ΩìËºïÈ¨ÜÂª∂‰º∏„ÄÇ

##### **From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge**
2411.16594v1 by Dawei Li, Bohan Jiang, Liangjie Huang, Alimohammad Beigi, Chengshuai Zhao, Zhen Tan, Amrita Bhattacharjee, Yuxuan Jiang, Canyu Chen, Tianhao Wu, Kai Shu, Lu Cheng, Huan Liu

Assessment and evaluation have long been critical challenges in artificial
intelligence (AI) and natural language processing (NLP). However, traditional
methods, whether matching-based or embedding-based, often fall short of judging
subtle attributes and delivering satisfactory results. Recent advancements in
Large Language Models (LLMs) inspire the "LLM-as-a-judge" paradigm, where LLMs
are leveraged to perform scoring, ranking, or selection across various tasks
and applications. This paper provides a comprehensive survey of LLM-based
judgment and assessment, offering an in-depth overview to advance this emerging
field. We begin by giving detailed definitions from both input and output
perspectives. Then we introduce a comprehensive taxonomy to explore
LLM-as-a-judge from three dimensions: what to judge, how to judge and where to
judge. Finally, we compile benchmarks for evaluating LLM-as-a-judge and
highlight key challenges and promising directions, aiming to provide valuable
insights and inspire future research in this promising research area. Paper
list and more resources about LLM-as-a-judge can be found at
\url{https://github.com/llm-as-a-judge/Awesome-LLM-as-a-judge} and
\url{https://llm-as-a-judge.github.io}.

ÊëòË¶ÅÔºöË©ï‰º∞ÂíåË©ïÈáèÈï∑Êúü‰ª•‰æÜ‰∏ÄÁõ¥ÊòØ‰∫∫Â∑•Êô∫ÊÖß (AI) ÂíåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰∏≠ÁöÑÈáçÂ§ßÊåëÊà∞„ÄÇÁÑ∂ËÄåÔºåÂÇ≥Áµ±ÊñπÊ≥ïÔºåÁÑ°Ë´ñÊòØÂü∫ÊñºÊØîÂ∞çÊàñÂµåÂÖ•ÂºèÔºåÈÄöÂ∏∏ÁÑ°Ê≥ïÂà§Êñ∑Á¥∞ÂæÆÂ±¨ÊÄßÂíåÊèê‰æõ‰ª§‰∫∫ÊªøÊÑèÁöÑÁµêÊûú„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂïüÁôº‰∫Ü„ÄåLLM ‰ΩúÁÇ∫Ë©ïÂà§ËÄÖ„ÄçÁöÑÁØÑ‰æãÔºåÂÖ∂‰∏≠ LLM Ë¢´Áî®ÊñºÂü∑Ë°åÂêÑÁ®Æ‰ªªÂãôÂíåÊáâÁî®‰∏≠ÁöÑË©ïÂàÜ„ÄÅÊéíÂêçÊàñÈÅ∏Êìá„ÄÇÊú¨ÊñáÊèê‰æõ‰∫ÜÂü∫Êñº LLM ÁöÑÂà§Êñ∑ÂíåË©ï‰º∞ÁöÑÂÖ®Èù¢Ë™øÊü•ÔºåÊèê‰æõ‰∫ÜÊ∑±ÂÖ•ÁöÑÊ¶ÇËø∞‰ª•Êé®ÈÄ≤ÈÄôÂÄãÊñ∞ËààÈ†òÂüü„ÄÇÊàëÂÄëÂæûËº∏ÂÖ•ÂíåËº∏Âá∫ËßÄÈªûÁµ¶Âá∫Ë©≥Á¥∞ÂÆöÁæ©ÈñãÂßã„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄë‰ªãÁ¥π‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÂàÜÈ°ûÊ≥ïÔºåÂæû‰∏âÂÄãÈù¢ÂêëÊé¢Ë®é LLM ‰ΩúÁÇ∫Ë©ïÂà§ËÄÖÔºöÂà§Êñ∑‰ªÄÈ∫º„ÄÅÂ¶Ç‰ΩïÂà§Êñ∑ÂíåÂú®Âì™Ë£°Âà§Êñ∑„ÄÇÊúÄÂæåÔºåÊàëÂÄëÁ∑®Âà∂‰∫ÜË©ï‰º∞ LLM ‰ΩúÁÇ∫Ë©ïÂà§ËÄÖÁöÑÂü∫Ê∫ñÔºå‰∏¶ÈáçÈªû‰ªãÁ¥πÈóúÈçµÊåëÊà∞ÂíåÊúâÂ∏åÊúõÁöÑÊñπÂêëÔºåÊó®Âú®Êèê‰æõÊúâÂÉπÂÄºÁöÑË¶ãËß£‰∏¶ÊøÄÂãµÈÄôÂÄãÊúâÂ∏åÊúõÁöÑÁ†îÁ©∂È†òÂüüÁöÑÊú™‰æÜÁ†îÁ©∂„ÄÇLLM ‰ΩúÁÇ∫Ë©ïÂà§ËÄÖÁöÑË´ñÊñáÊ∏ÖÂñÆÂíåÊõ¥Â§öË≥áÊ∫êÂèØ‰ª•Âú® \url{https://github.com/llm-as-a-judge/Awesome-LLM-as-a-judge} Âíå \url{https://llm-as-a-judge.github.io} ÊâæÂà∞„ÄÇ

##### **Enhancing LLM Reasoning via Critique Models with Test-Time and Training-Time Supervision**
2411.16579v1 by Zhiheng Xi, Dingwen Yang, Jixuan Huang, Jiafu Tang, Guanyu Li, Yiwen Ding, Wei He, Boyang Hong, Shihan Do, Wenyu Zhan, Xiao Wang, Rui Zheng, Tao Ji, Xiaowei Shi, Yitao Zhai, Rongxiang Weng, Jingang Wang, Xunliang Cai, Tao Gui, Zuxuan Wu, Qi Zhang, Xipeng Qiu, Xuanjing Huang, Yu-Gang Jiang

Training large language models (LLMs) to spend more time thinking and
reflection before responding is crucial for effectively solving complex
reasoning tasks in fields such as science, coding, and mathematics. However,
the effectiveness of mechanisms like self-reflection and self-correction
depends on the model's capacity to accurately assess its own performance, which
can be limited by factors such as initial accuracy, question difficulty, and
the lack of external feedback. In this paper, we delve into a two-player
paradigm that separates the roles of reasoning and critique models, where the
critique model provides step-level feedback to supervise the reasoning (actor)
model during both test-time and train-time. We first propose AutoMathCritique,
an automated and scalable framework for collecting critique data, resulting in
a dataset of $76,321$ responses paired with step-level feedback. Fine-tuning
language models with this dataset enables them to generate natural language
feedback for mathematical reasoning. We demonstrate that the critique models
consistently improve the actor's performance on difficult queries at test-time,
especially when scaling up inference-time computation. Motivated by these
findings, we introduce the critique-based supervision to the actor's
self-training process, and propose a critique-in-the-loop self-improvement
method. Experiments show that the method improves the actor's exploration
efficiency and solution diversity, especially on challenging queries, leading
to a stronger reasoning model. Lastly, we take the preliminary step to explore
training self-talk reasoning models via critique supervision and showcase its
potential. Our code and datasets are at
\href{https://mathcritique.github.io/}{https://mathcritique.github.io/}.

ÊëòË¶ÅÔºö<paragraph>Ë®ìÁ∑¥Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂõûÊáâÂâçËä±Êõ¥Â§öÊôÇÈñìÊÄùËÄÉÂíåÂèçÁúÅÔºåÂ∞çÊñºÂú®ÁßëÂ≠∏„ÄÅÁ®ãÂºèÁ∑®ÂØ´ÂíåÊï∏Â≠∏Á≠âÈ†òÂüüÊúâÊïàËß£Ê±∫Ë§áÈõúÊé®ÁêÜ‰ªªÂãôËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåËá™ÊàëÂèçÁúÅÂíåËá™Êàë‰øÆÊ≠£Á≠âÊ©üÂà∂ÁöÑÊúâÊïàÊÄßÂèñÊ±∫ÊñºÊ®°ÂûãÊ∫ñÁ¢∫Ë©ï‰º∞ÂÖ∂Ëá™Ë∫´ÊïàËÉΩÁöÑËÉΩÂäõÔºåËÄåÈÄôÂèØËÉΩÊúÉÂèóÂà∞ÂàùÂßãÊ∫ñÁ¢∫Â∫¶„ÄÅÂïèÈ°åÈõ£Â∫¶ÂíåÁº∫‰πèÂ§ñÈÉ®ÂõûÈ•ãÁ≠âÂõ†Á¥†ÁöÑÈôêÂà∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊ∑±ÂÖ•Êé¢Ë®é‰∏ÄÂÄãÂ∞áÊé®ÁêÜÂíåÊâπÂà§Ê®°ÂûãÁöÑËßíËâ≤ÂàÜÈñãÁöÑÈõô‰∫∫ÈÅäÊà≤ÁØÑ‰æãÔºåÂÖ∂‰∏≠ÊâπÂà§Ê®°ÂûãÊèê‰æõÊ≠•È©üÂ±§Á¥öÁöÑÂõûÈ•ãÔºå‰ª•Áõ£Áù£Êé®ÁêÜ (actor) Ê®°ÂûãÂú®Ê∏¨Ë©¶ÊôÇÈñìÂíåË®ìÁ∑¥ÊôÇÈñì„ÄÇÊàëÂÄëÈ¶ñÂÖàÊèêÂá∫ AutoMathCritiqueÔºåÈÄôÊòØ‰∏ÄÂÄãÁî®ÊñºÊî∂ÈõÜÊâπÂà§Ë≥áÊñôÁöÑËá™ÂãïÂåñ‰∏îÂèØÊì¥ÂÖÖÁöÑÊû∂ÊßãÔºåÁî¢Áîü‰∏ÄÂÄãÂåÖÂê´ 76,321 ÂÄãËàáÊ≠•È©üÂ±§Á¥öÂõûÈ•ãÈÖçÂ∞çÁöÑÂõûÊáâÁöÑË≥áÊñôÈõÜ„ÄÇ‰ΩøÁî®ÈÄôÂÄãË≥áÊñôÈõÜÂæÆË™øË™ûË®ÄÊ®°ÂûãÔºå‰ΩøÂÆÉÂÄëËÉΩÂ§†ÁÇ∫Êï∏Â≠∏Êé®ÁêÜÁî¢ÁîüËá™ÁÑ∂Ë™ûË®ÄÂõûÈ•ã„ÄÇÊàëÂÄëË≠âÊòéÊâπÂà§Ê®°ÂûãÂú®Ê∏¨Ë©¶ÊôÇÈñìÊåÅÁ∫åÊîπÂñÑ actor Âú®Âõ∞Èõ£Êü•Ë©¢‰∏äÁöÑÊïàËÉΩÔºåÁâπÂà•ÊòØÂú®Êì¥ÂÖÖÊé®Ë´ñÊôÇÈñìÈÅãÁÆóÊôÇ„ÄÇÂèóÂà∞ÈÄô‰∫õÁôºÁèæÁöÑÂïüÁôºÔºåÊàëÂÄëÂ∞áÂü∫ÊñºÊâπÂà§ÁöÑÁõ£Áù£ÂºïÂÖ• actor ÁöÑËá™ÊàëË®ìÁ∑¥Á®ãÂ∫èÔºå‰∏¶ÊèêÂá∫‰∏ÄÂÄãËø¥Âúà‰∏≠ÁöÑÊâπÂà§Ëá™ÊàëÊîπÂñÑÊñπÊ≥ï„ÄÇÂØ¶È©óÈ°ØÁ§∫ÔºåÊ≠§ÊñπÊ≥ïÊîπÂñÑ‰∫Ü actor Âú®Êé¢Á¥¢ÊïàÁéáÂíåËß£Ê±∫ÊñπÊ°àÂ§öÊ®£ÊÄß‰∏äÁöÑË°®ÁèæÔºåÁâπÂà•ÊòØÂú®ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÊü•Ë©¢‰∏äÔºåÈÄ≤ËÄåÁî¢ÁîüÊõ¥Âº∑Â§ßÁöÑÊé®ÁêÜÊ®°Âûã„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊé°ÂèñÂàùÊ≠•Ê≠•È©üÔºåÈÄèÈÅéÊâπÂà§Áõ£Áù£‰æÜÊé¢Á¥¢Ë®ìÁ∑¥Ëá™ÊàëÂ∞çË©±Êé®ÁêÜÊ®°ÂûãÔºå‰∏¶Â±ïÁ§∫ÂÖ∂ÊΩõÂäõ„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜ‰ΩçÊñº
\href{https://mathcritique.github.io/}{https://mathcritique.github.io/}„ÄÇ</paragraph>

##### **Naive Algorithmic Collusion: When Do Bandit Learners Cooperate and When Do They Compete?**
2411.16574v1 by Connor Douglas, Foster Provost, Arun Sundararajan

Algorithmic agents are used in a variety of competitive decision settings,
notably in making pricing decisions in contexts that range from online retail
to residential home rentals. Business managers, algorithm designers, legal
scholars, and regulators alike are all starting to consider the ramifications
of "algorithmic collusion." We study the emergent behavior of multi-armed
bandit machine learning algorithms used in situations where agents are
competing, but they have no information about the strategic interaction they
are engaged in. Using a general-form repeated Prisoner's Dilemma game, agents
engage in online learning with no prior model of game structure and no
knowledge of competitors' states or actions (e.g., no observation of competing
prices). We show that these context-free bandits, with no knowledge of
opponents' choices or outcomes, still will consistently learn collusive
behavior - what we call "naive collusion." We primarily study this system
through an analytical model and examine perturbations to the model through
simulations.
  Our findings have several notable implications for regulators. First, calls
to limit algorithms from conditioning on competitors' prices are insufficient
to prevent algorithmic collusion. This is a direct result of collusion arising
even in the naive setting. Second, symmetry in algorithms can increase
collusion potential. This highlights a new, simple mechanism for
"hub-and-spoke" algorithmic collusion. A central distributor need not imbue its
algorithm with supra-competitive tendencies for apparent collusion to arise; it
can simply arise by using certain (common) machine learning algorithms.
Finally, we highlight that collusive outcomes depend starkly on the specific
algorithm being used, and we highlight market and algorithmic conditions under
which it will be unknown a priori whether collusion occurs.

ÊëòË¶ÅÔºöÊºîÁÆóÊ≥ï‰ª£ÁêÜÁî®ÊñºÂêÑÁ®ÆÁ´∂Áà≠Ê±∫Á≠ñË®≠ÂÆö‰∏≠ÔºåÁâπÂà•ÊòØÂú®ÂæûÁ∑ö‰∏äÈõ∂ÂîÆÂà∞‰ΩèÂÆÖÂá∫ÁßüÁöÑÂêÑÁ®ÆÊÉÖÂ¢É‰∏≠ÂÅöÂá∫ÂÆöÂÉπÊ±∫Á≠ñ„ÄÇ‰ºÅÊ•≠Á∂ìÁêÜ‰∫∫„ÄÅÊºîÁÆóÊ≥ïË®≠Ë®àËÄÖ„ÄÅÊ≥ïÂæãÂ≠∏ËÄÖÂíåÁõ£ÁÆ°Ê©üÊßãÈÉΩÈñãÂßãËÄÉÊÖÆ„ÄåÊºîÁÆóÊ≥ïÂÖ±Ë¨Ä„ÄçÁöÑÂæåÊûú„ÄÇÊàëÂÄëÁ†îÁ©∂Â§öËáÇËÄÅËôéÊ©üÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïÂú®‰ª£ÁêÜÁ´∂Áà≠‰ΩÜÂ∞ç‰ªñÂÄëÂèÉËàáÁöÑÁ≠ñÁï•‰∫íÂãïÊØ´ÁÑ°ÊâÄÊÇâÁöÑÊÉÖÊ≥Å‰∏ãÁöÑÊñ∞ËààË°åÁÇ∫„ÄÇ‰ΩøÁî®‰∏ÄËà¨ÂΩ¢ÂºèÁöÑÈáçË§áÂõöÁäØÂõ∞Â¢ÉÂçöÂºàÔºå‰ª£ÁêÜÂú®Ê≤íÊúâÈÅäÊà≤ÁµêÊßãÂÖàÈ©óÊ®°ÂûãÂíåÂ∞çÁ´∂Áà≠ËÄÖÁãÄÊÖãÊàñË°åÂãï‰∏ÄÁÑ°ÊâÄÁü•Ôºà‰æãÂ¶ÇÔºåÊ≤íÊúâËßÄÂØüÂà∞Á´∂Áà≠ÂÉπÊ†ºÔºâÁöÑÊÉÖÊ≥Å‰∏ãÈÄ≤Ë°åÁ∑ö‰∏äÂ≠∏Áøí„ÄÇÊàëÂÄëË°®ÊòéÔºåÈÄô‰∫õÁÑ°ËÉåÊôØËÄÅËôéÊ©üÂú®‰∏çÁü•ÈÅìÂ∞çÊâãÈÅ∏ÊìáÊàñÁµêÊûúÁöÑÊÉÖÊ≥Å‰∏ãÔºå‰ªçÁÑ∂ÊúÉÊåÅÁ∫åÂ≠∏ÁøíÂÖ±Ë¨ÄË°åÁÇ∫ÔºåÊàëÂÄëÁ®±‰πãÁÇ∫„ÄåÂ§©ÁúüÂÖ±Ë¨Ä„Äç„ÄÇÊàëÂÄë‰∏ªË¶ÅÈÄèÈÅéÂàÜÊûêÊ®°ÂûãÁ†îÁ©∂ÈÄôÂÄãÁ≥ªÁµ±Ôºå‰∏¶ÈÄèÈÅéÊ®°Êì¨Ê™¢Êü•Ê®°ÂûãÁöÑÊìæÂãï„ÄÇÊàëÂÄëÁöÑÁôºÁèæÂ∞çÁõ£ÁÆ°Ê©üÊßãÊúâÂπæÂÄãÈ°ØËëóÁöÑÂΩ±Èüø„ÄÇÈ¶ñÂÖàÔºåË¶ÅÊ±ÇÈôêÂà∂ÊºîÁÆóÊ≥ï‰ª•Á´∂Áà≠Â∞çÊâãÁöÑÂÉπÊ†ºÁÇ∫Ê¢ù‰ª∂‰∏çË∂≥‰ª•Èò≤Ê≠¢ÊºîÁÆóÊ≥ïÂÖ±Ë¨Ä„ÄÇÈÄôÊòØÂÖ±Ë¨ÄÂç≥‰ΩøÂú®ÂñÆÁ¥îÁöÑË®≠ÂÆö‰∏≠‰πüÊúÉÁî¢ÁîüÁöÑÁõ¥Êé•ÁµêÊûú„ÄÇÂÖ∂Ê¨°ÔºåÊºîÁÆóÊ≥ï‰∏≠ÁöÑÂ∞çÁ®±ÊÄßÊúÉÂ¢ûÂä†ÂÖ±Ë¨ÄÁöÑÂèØËÉΩÊÄß„ÄÇÈÄôÁ™ÅÈ°Ø‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑ„ÄÅÁ∞°ÂñÆÁöÑ„ÄåÊ®ûÁ¥êËºªÊ¢ù„ÄçÊºîÁÆóÊ≥ïÂÖ±Ë¨ÄÊ©üÂà∂„ÄÇ‰∏≠Â§ÆÁ∂ìÈä∑ÂïÜ‰∏çÂøÖËÆìÂÖ∂ÊºîÁÆóÊ≥ïÂÖ∑ÊúâË∂ÖÁ´∂Áà≠ÁöÑÂÇæÂêëÔºå‰ª•Ëá¥Áî¢ÁîüÊòéÈ°ØÁöÑÂÖ±Ë¨ÄÔºõÂÆÉÂèØ‰ª•ÈÄèÈÅé‰ΩøÁî®Êüê‰∫õÔºàÂ∏∏Ë¶ãÁöÑÔºâÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïËÄåÁî¢Áîü„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂº∑Ë™øÂÖ±Ë¨ÄÁµêÊûúÊòéÈ°ØÂèñÊ±∫ÊñºÊâÄ‰ΩøÁî®ÁöÑÁâπÂÆöÊºîÁÆóÊ≥ïÔºå‰∏¶‰∏îÊàëÂÄëÂº∑Ë™øÂ∏ÇÂ†¥ÂíåÊºîÁÆóÊ≥ïÊ¢ù‰ª∂ÔºåÂú®ÈÄô‰∫õÊ¢ù‰ª∂‰∏ãÂ∞áÁÑ°Ê≥ïÈ†êÂÖàÂæóÁü•ÊòØÂê¶ÊúÉÁôºÁîüÂÖ±Ë¨Ä„ÄÇ

##### **EnStack: An Ensemble Stacking Framework of Large Language Models for Enhanced Vulnerability Detection in Source Code**
2411.16561v1 by Shahriyar Zaman Ridoy, Md. Shazzad Hossain Shaon, Alfredo Cuzzocrea, Mst Shapna Akter

Automated detection of software vulnerabilities is critical for enhancing
security, yet existing methods often struggle with the complexity and diversity
of modern codebases. In this paper, we introduce EnStack, a novel ensemble
stacking framework that enhances vulnerability detection using natural language
processing (NLP) techniques. Our approach synergizes multiple pre-trained large
language models (LLMs) specialized in code understanding CodeBERT for semantic
analysis, GraphCodeBERT for structural representation, and UniXcoder for
cross-modal capabilities. By fine-tuning these models on the Draper VDISC
dataset and integrating their outputs through meta-classifiers such as Logistic
Regression, Support Vector Machines (SVM), Random Forest, and XGBoost, EnStack
effectively captures intricate code patterns and vulnerabilities that
individual models may overlook. The meta-classifiers consolidate the strengths
of each LLM, resulting in a comprehensive model that excels in detecting subtle
and complex vulnerabilities across diverse programming contexts. Experimental
results demonstrate that EnStack significantly outperforms existing methods,
achieving notable improvements in accuracy, precision, recall, and F1-score.
This work highlights the potential of ensemble LLM approaches in code analysis
tasks and offers valuable insights into applying NLP techniques for advancing
automated vulnerability detection.

ÊëòË¶ÅÔºöËá™ÂãïÂåñÂÅµÊ∏¨ËªüÈ´îÊºèÊ¥ûÂ∞çÊñºÊèêÂçáÂÆâÂÖ®ÊÄßËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÁèæÊúâÊñπÊ≥ïÁ∂ìÂ∏∏Èõ£‰ª•ÊáâÂ∞çÁèæ‰ª£Á®ãÂºèÁ¢ºÂ∫´ÁöÑË§áÈõúÊÄßÂíåÂ§öÊ®£ÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π EnStackÔºå‰∏ÄÂÄãÊñ∞Á©éÁöÑÊï¥È´îÂ†ÜÁñäÊ°ÜÊû∂ÔºåÂÆÉ‰ΩøÁî®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÊäÄË°ì‰æÜÂ¢ûÂº∑ÊºèÊ¥ûÂÅµÊ∏¨„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂ∞áÂ§öÂÄãÈ†êÂÖàË®ìÁ∑¥ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂçîÂêåËµ∑‰æÜÔºåÈÄô‰∫õÊ®°ÂûãÂ∞àÈñÄÁî®ÊñºÁêÜËß£Á®ãÂºèÁ¢ºÔºöCodeBERT Áî®ÊñºË™ûÊÑèÂàÜÊûê„ÄÅGraphCodeBERT Áî®ÊñºÁµêÊßãË°®Á§∫ÔºåËÄå UniXcoder ÂâáÁî®ÊñºË∑®Ê®°ÊÖãËÉΩÂäõ„ÄÇÈÄèÈÅéÂæÆË™øÈÄô‰∫õÊ®°ÂûãÂú® Draper VDISC Ë≥áÊñôÈõÜ‰∏äÔºå‰∏¶ÈÄèÈÅéÂæåË®≠ÂàÜÈ°ûÂô®Ôºà‰æãÂ¶ÇÈÇèËºØËø¥Ê≠∏„ÄÅÊîØÊè¥ÂêëÈáèÊ©ü (SVM)„ÄÅÈö®Ê©üÊ£ÆÊûóÂíå XGBoostÔºâÊï¥ÂêàÂÖ∂Ëº∏Âá∫ÔºåEnStack ÊúâÊïàÂú∞Êì∑Âèñ‰∫ÜÂÄãÂà•Ê®°ÂûãÂèØËÉΩÂøΩÁï•ÁöÑË§áÈõúÁ®ãÂºèÁ¢ºÊ®°ÂºèÂíåÊºèÊ¥û„ÄÇÂæåË®≠ÂàÜÈ°ûÂô®Êï¥Âêà‰∫ÜÊØèÂÄã LLM ÁöÑÂÑ™ÈªûÔºåÁî¢Áîü‰∫Ü‰∏ÄÂÄãÁ∂úÂêàÊ®°ÂûãÔºåÊìÖÈï∑ÂÅµÊ∏¨Ë∑®‰∏çÂêåÁ®ãÂºèË®≠Ë®àËÉåÊôØÁöÑÁ¥∞ÂæÆËÄåË§áÈõúÁöÑÊºèÊ¥û„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòéÔºåEnStack ÊòéÈ°ØÂÑ™ÊñºÁèæÊúâÊñπÊ≥ïÔºåÂú®Ê∫ñÁ¢∫Â∫¶„ÄÅÁ≤æÁ¢∫Â∫¶„ÄÅÂè¨ÂõûÁéáÂíå F1 ÂàÜÊï∏ÊñπÈù¢ÈÉΩÊúâÈ°ØËëóÁöÑÊèêÂçá„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁ™ÅÈ°Ø‰∫ÜÊï¥È´î LLM ÊñπÊ≥ïÂú®Á®ãÂºèÁ¢ºÂàÜÊûê‰ªªÂãô‰∏≠ÁöÑÊΩõÂäõÔºå‰∏¶Êèê‰æõ‰∫ÜÂØ∂Ë≤¥ÁöÑË¶ãËß£ÔºåË™™ÊòéÂ¶Ç‰ΩïÊáâÁî® NLP ÊäÄË°ì‰æÜÊé®ÈÄ≤Ëá™ÂãïÂåñÊºèÊ¥ûÂÅµÊ∏¨„ÄÇ

##### **Representation Collapsing Problems in Vector Quantization**
2411.16550v1 by Wenhao Zhao, Qiran Zou, Rushi Shah, Dianbo Liu

Vector quantization is a technique in machine learning that discretizes
continuous representations into a set of discrete vectors. It is widely
employed in tokenizing data representations for large language models,
diffusion models, and other generative models. Despite its prevalence, the
characteristics and behaviors of vector quantization in generative models
remain largely underexplored. In this study, we investigate representation
collapse in vector quantization - a critical degradation where codebook tokens
or latent embeddings lose their discriminative power by converging to a limited
subset of values. This collapse fundamentally compromises the model's ability
to capture diverse data patterns. By leveraging both synthetic and real
datasets, we identify the severity of each type of collapses and triggering
conditions. Our analysis reveals that restricted initialization and limited
encoder capacity result in tokens collapse and embeddings collapse. Building on
these findings, we propose potential solutions aimed at mitigating each
collapse. To the best of our knowledge, this is the first comprehensive study
examining representation collapsing problems in vector quantization.

ÊëòË¶ÅÔºöÂêëÈáèÈáèÂåñÊòØÊú∫Âô®Â≠¶‰π†‰∏≠Â∞ÜËøûÁª≠Ë°®Á§∫Á¶ªÊï£Âåñ‰∏∫‰∏ÄÁªÑÁ¶ªÊï£ÂêëÈáèÁöÑÊäÄÊúØ„ÄÇÂÆÉÂπøÊ≥õÁî®‰∫éÂØπÂ§ßËØ≠Ë®ÄÊ®°Âûã„ÄÅÊâ©Êï£Ê®°ÂûãÂíåÂÖ∂‰ªñÁîüÊàêÊ®°ÂûãÁöÑÊï∞ÊçÆË°®Á§∫ËøõË°åÊ†áËÆ∞Âåñ„ÄÇÂ∞ΩÁÆ°ÂÆÉÂæàÊôÆÈÅçÔºå‰ΩÜÁîüÊàêÊ®°Âûã‰∏≠ÂêëÈáèÈáèÂåñÁöÑÁâπÂæÅÂíåË°å‰∏∫Âú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Á¥¢„ÄÇÂú®ËøôÈ°πÁ†îÁ©∂‰∏≠ÔºåÊàë‰ª¨Ë∞ÉÊü•‰∫ÜÂêëÈáèÈáèÂåñ‰∏≠ÁöÑË°®Á§∫ÂùçÁº©‚Äî‚Äî‰∏Ä‰∏™ÂÖ≥ÈîÆÁöÑÈÄÄÂåñÔºåÂÖ∂‰∏≠Á†ÅÊú¨Ê†áËÆ∞ÊàñÊΩúÂú®ÂµåÂÖ•ÈÄöËøáÊî∂ÊïõÂà∞ÊúâÈôêÁöÑÂÄºÂ≠êÈõÜËÄåÂ§±ÂéªÂÖ∂Âà§Âà´ËÉΩÂäõ„ÄÇËøôÁßçÂùçÁº©‰ªéÊ†πÊú¨‰∏äÊçüÂÆ≥‰∫ÜÊ®°ÂûãÊçïËé∑‰∏çÂêåÊï∞ÊçÆÊ®°ÂºèÁöÑËÉΩÂäõ„ÄÇÈÄöËøáÂà©Áî®ÂêàÊàêÂíåÁúüÂÆûÊï∞ÊçÆÈõÜÔºåÊàë‰ª¨Á°ÆÂÆö‰∫ÜÊØèÁßçÁ±ªÂûãÂùçÁº©ÁöÑ‰∏•ÈáçÊÄßÂíåËß¶ÂèëÊù°‰ª∂„ÄÇÊàë‰ª¨ÁöÑÂàÜÊûêË°®ÊòéÔºåÂèóÈôêÁöÑÂàùÂßãÂåñÂíåÊúâÈôêÁöÑÁºñÁ†ÅÂô®ÂÆπÈáè‰ºöÂØºËá¥Ê†áËÆ∞ÂùçÁº©ÂíåÂµåÂÖ•ÂùçÁº©„ÄÇÂü∫‰∫éËøô‰∫õÂèëÁé∞ÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÊó®Âú®ÂáèËΩªÊØèÊ¨°ÂùçÁº©ÁöÑÊΩúÂú®Ëß£ÂÜ≥ÊñπÊ°à„ÄÇÊçÆÊàë‰ª¨ÊâÄÁü•ÔºåËøôÊòØÁ¨¨‰∏ÄÈ°πÂÖ®Èù¢Á†îÁ©∂ÂêëÈáèÈáèÂåñ‰∏≠ÁöÑË°®Á§∫ÂùçÁº©ÈóÆÈ¢ò„ÄÇ

##### **RoboSpatial: Teaching Spatial Understanding to 2D and 3D Vision-Language Models for Robotics**
2411.16537v1 by Chan Hee Song, Valts Blukis, Jonathan Tremblay, Stephen Tyree, Yu Su, Stan Birchfield

Spatial understanding is a crucial capability for robots to make grounded
decisions based on their environment. This foundational skill enables robots
not only to perceive their surroundings but also to reason about and interact
meaningfully within the world. In modern robotics, these capabilities are taken
on by visual language models, and they face significant challenges when applied
to spatial reasoning context due to their training data sources. These sources
utilize general-purpose image datasets, and they often lack sophisticated
spatial scene understanding capabilities. For example, the datasets do not
address reference frame comprehension - spatial relationships require clear
contextual understanding, whether from an ego-centric, object-centric, or
world-centric perspective, which allow for effective real-world interaction. To
address this issue, we introduce RoboSpatial, a large-scale spatial
understanding dataset consisting of real indoor and tabletop scenes captured as
3D scans and egocentric images, annotated with rich spatial information
relevant to robotics. The dataset includes 1M images, 5K 3D scans, and 3M
annotated spatial relationships, with paired 2D egocentric images and 3D scans
to make it both 2D and 3D ready. Our experiments show that models trained with
RoboSpatial outperform baselines on downstream tasks such as spatial affordance
prediction, spatial relationship prediction, and robotics manipulation.

ÊëòË¶ÅÔºöÁ©∫ÈñìÁêÜËß£Â∞çÊñºÊ©üÂô®‰∫∫Ê†πÊìöÂÖ∂Áí∞Â¢ÉÂÅöÂá∫Á¥ÆÂØ¶ÁöÑÊ±∫Á≠ñËá≥ÈóúÈáçË¶Å„ÄÇÈÄôÁ®ÆÂü∫Êú¨ÊäÄËÉΩ‰∏çÂÉÖ‰ΩøÊ©üÂô®‰∫∫ËÉΩÂ§†ÊÑüÁü•Âë®ÂúçÁí∞Â¢ÉÔºåÈÇÑËÉΩÂ∞ç‰∏ñÁïåÈÄ≤Ë°åÊé®ÁêÜ‰∏¶ÊúâÊÑèÁæ©Âú∞Ëàá‰πã‰∫íÂãï„ÄÇÂú®Áèæ‰ª£Ê©üÂô®‰∫∫ÊäÄË°ì‰∏≠ÔºåÈÄô‰∫õËÉΩÂäõÁî±Ë¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÊâøÊìîÔºåÁî±ÊñºÂÖ∂Ë®ìÁ∑¥Êï∏ÊìöÊ∫êÔºåÂú®ÊáâÁî®ÊñºÁ©∫ÈñìÊé®ÁêÜÊÉÖÂ¢ÉÊôÇÈù¢Ëá®Âö¥Â≥ªÊåëÊà∞„ÄÇÈÄô‰∫õ‰æÜÊ∫êÂà©Áî®ÈÄöÁî®ÂúñÂÉèÊï∏ÊìöÈõÜÔºåËÄå‰∏îÈÄöÂ∏∏Áº∫‰πèË§áÈõúÁöÑÁ©∫ÈñìÂ†¥ÊôØÁêÜËß£ËÉΩÂäõ„ÄÇ‰æãÂ¶ÇÔºåÈÄô‰∫õÊï∏ÊìöÈõÜ‰∏çËôïÁêÜÂèÉËÄÉÊ°ÜÊû∂ÁêÜËß£‚Äî‚ÄîÁ©∫ÈñìÈóú‰øÇÈúÄË¶ÅÊ∏ÖÊô∞ÁöÑÊÉÖÂ¢ÉÁêÜËß£ÔºåÁÑ°Ë´ñÊòØÂæû‰ª•Ëá™ÊàëÁÇ∫‰∏≠ÂøÉ„ÄÅ‰ª•Â∞çË±°ÁÇ∫‰∏≠ÂøÉÈÇÑÊòØ‰ª•‰∏ñÁïåÁÇ∫‰∏≠ÂøÉÁöÑË¶ñËßíÔºåÈÄôÂÖÅË®±ÈÄ≤Ë°åÊúâÊïàÁöÑÁèæÂØ¶‰∏ñÁïå‰∫íÂãï„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü RoboSpatialÔºå‰∏ÄÂÄãÁî±‰ª• 3D ÊéÉÊèèÂíåËá™Êàë‰∏≠ÂøÉÂúñÂÉèÂΩ¢ÂºèÊçïÊçâÁöÑÁúüÂØ¶ÂÆ§ÂÖßÂíåÊ°åÈù¢Â†¥ÊôØÁµÑÊàêÁöÑÂ§ßË¶èÊ®°Á©∫ÈñìÁêÜËß£Êï∏ÊìöÈõÜÔºå‰∏¶ÈôÑÊúâËàáÊ©üÂô®‰∫∫ÊäÄË°ìÁõ∏ÈóúÁöÑË±êÂØåÁ©∫Èñì‰ø°ÊÅØ„ÄÇË©≤Êï∏ÊìöÈõÜÂåÖÊã¨ 100 Ëê¨ÂºµÂúñÂÉè„ÄÅ5K 3D ÊéÉÊèèÂíå 300 Ëê¨ÂÄãÂ∏∂Ë®ªÈáãÁöÑÁ©∫ÈñìÈóú‰øÇÔºå‰∏¶ÈÖçÂ∞ç‰∫Ü 2D Ëá™Êàë‰∏≠ÂøÉÂúñÂÉèÂíå 3D ÊéÉÊèèÔºå‰ª•‰ΩøÂÖ∂ÂêåÊôÇÂÖ∑ÂÇô 2D Âíå 3D ÂäüËÉΩ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºå‰ΩøÁî® RoboSpatial Ë®ìÁ∑¥ÁöÑÊ®°ÂûãÂú®Á©∫ÈñìÂèØ‰æõÊÄßÈ†êÊ∏¨„ÄÅÁ©∫ÈñìÈóú‰øÇÈ†êÊ∏¨ÂíåÊ©üÂô®‰∫∫Êìç‰ΩúÁ≠â‰∏ãÊ∏∏‰ªªÂãô‰∏äÂÑ™ÊñºÂü∫Ê∫ñ„ÄÇ

##### **Profiling Bias in LLMs: Stereotype Dimensions in Contextual Word Embeddings**
2411.16527v1 by Carolin M. Schuster, Maria-Alexandra Dinisor, Shashwat Ghatiwala, Georg Groh

Large language models (LLMs) are the foundation of the current successes of
artificial intelligence (AI), however, they are unavoidably biased. To
effectively communicate the risks and encourage mitigation efforts these models
need adequate and intuitive descriptions of their discriminatory properties,
appropriate for all audiences of AI. We suggest bias profiles with respect to
stereotype dimensions based on dictionaries from social psychology research.
Along these dimensions we investigate gender bias in contextual embeddings,
across contexts and layers, and generate stereotype profiles for twelve
different LLMs, demonstrating their intuition and use case for exposing and
visualizing bias.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊòØÁõÆÂâç‰∫∫Â∑•Êô∫ÊÖß (AI) ÊàêÂäüÁôºÂ±ïÁöÑÂü∫Á§éÔºåÁÑ∂ËÄåÂÆÉÂÄë‰∏çÂèØÈÅøÂÖçÂú∞ÊúâÂÅèË¶ã„ÄÇÁÇ∫‰∫ÜÊúâÊïàÂú∞ÂÇ≥ÈÅîÈ¢®Èö™‰∏¶ÈºìÂãµÊé°ÂèñÁ∑©Ëß£Êé™ÊñΩÔºåÈÄô‰∫õÊ®°ÂûãÈúÄË¶ÅÂ∞çÂÖ∂Ê≠ßË¶ñÊÄßÂ±¨ÊÄßÊèê‰æõÂÖÖÂàÜ‰∏îÁõ¥ËßÄÁöÑÊèèËø∞Ôºå‰ª•ÈÅ©Áî®ÊñºÊâÄÊúâ AI ÂèóÁúæ„ÄÇÊàëÂÄëÂª∫Ë≠∞Ê†πÊìöÁ§æÊúÉÂøÉÁêÜÂ≠∏Á†îÁ©∂ÁöÑÂ≠óÂÖ∏ÔºåÈáùÂ∞çÂàªÊùøÂç∞Ë±°Èù¢ÂêëÊèêÂá∫ÂÅèË¶ãÊ¶ÇÊ≥Å„ÄÇÊàëÂÄëÊ≤øËëóÈÄô‰∫õÈù¢ÂêëÊé¢Ë®éË™ûÂ¢ÉÂµåÂÖ•‰∏≠ÁöÑÊÄßÂà•ÂÅèË¶ãÔºåË∑®Ë∂äË™ûÂ¢ÉÂíåÂ±§Ê¨°Ôºå‰∏¶ÈáùÂ∞ç 12 ÂÄã‰∏çÂêåÁöÑ LLM Áî¢ÁîüÂàªÊùøÂç∞Ë±°Ê¶ÇÊ≥ÅÔºåÂ±ïÁ§∫ÂÖ∂Áõ¥Ë¶∫ÂíåÊè≠Èú≤ÂíåË¶ñË¶∫ÂåñÂÅèË¶ãÁöÑÁî®‰æã„ÄÇ

##### **Fundamental Limits of Prompt Tuning Transformers: Universality, Capacity and Efficiency**
2411.16525v1 by Jerry Yao-Chieh Hu, Wei-Po Wang, Ammar Gilani, Chenyang Li, Zhao Song, Han Liu

We investigate the statistical and computational limits of prompt tuning for
transformer-based foundation models. Our key contributions are prompt tuning on
\textit{single-head} transformers with only a \textit{single} self-attention
layer: (i) is universal, and (ii) supports efficient (even almost-linear time)
algorithms under the Strong Exponential Time Hypothesis (SETH). Statistically,
we prove that prompt tuning on such simplest possible transformers are
universal approximators for sequence-to-sequence Lipschitz functions. In
addition, we provide an exponential-in-$dL$ and -in-$(1/\epsilon)$ lower bound
on the required soft-prompt tokens for prompt tuning to memorize any dataset
with 1-layer, 1-head transformers. Computationally, we identify a phase
transition in the efficiency of prompt tuning, determined by the norm of the
\textit{soft-prompt-induced} keys and queries, and provide an upper bound
criterion. Beyond this criterion, no sub-quadratic (efficient) algorithm for
prompt tuning exists under SETH. Within this criterion, we showcase our theory
by proving the existence of almost-linear time prompt tuning inference
algorithms. These fundamental limits provide important necessary conditions for
designing expressive and efficient prompt tuning methods for practitioners.

ÊëòË¶ÅÔºöÊàëÂÄëÊé¢Ë®é‰∫ÜÂü∫ÊñºTransformerÁöÑÂü∫Á§éÊ®°ÂûãÊèêÁ§∫Ë™øÊï¥ÁöÑÁµ±Ë®àÂíåË®àÁÆóÈôêÂà∂„ÄÇÊàëÂÄëÁöÑÈóúÈçµË≤¢ÁçªÊòØÂñÆÈ†≠Transformer‰∏äÁöÑÊèêÁ§∫Ë™øÊï¥ÔºåÂÉÖÊúâ‰∏ÄÂÄãÂñÆ‰∏ÄÁöÑËá™Ê≥®ÊÑèÂäõÂ±§Ôºö(i) ÊòØÈÄöÁî®ÁöÑÔºå‰∏¶‰∏î (ii) Âú®Âº∑ÊåáÊï∏ÊôÇÈñìÂÅáË®≠ (SETH) ‰∏ãÊîØÊåÅÈ´òÊïàÔºàÁîöËá≥Âπæ‰πéÁ∑öÊÄßÊôÇÈñìÔºâÊºîÁÆóÊ≥ï„ÄÇÂú®Áµ±Ë®à‰∏äÔºåÊàëÂÄëË≠âÊòé‰∫ÜÂú®ÈÄôÊ®£ÊúÄÁ∞°ÂñÆÁöÑTransformer‰∏äÈÄ≤Ë°åÊèêÁ§∫Ë™øÊï¥ÊòØÂ∫èÂàóÂà∞Â∫èÂàó Lipschitz ÂáΩÊï∏ÁöÑÈÄöÁî®ÈÄºËøëÂô®„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂú® $dL$ Âíå -in-$(1/\epsilon)$ ‰∏≠ÂëàÊåáÊï∏Á¥öÁöÑËºÉ‰ΩéÈÇäÁïåÔºåÁî®ÊñºÊèêÁ§∫Ë™øÊï¥ÊâÄÈúÄÁöÑËªüÊèêÁ§∫Á¨¶ËôüÔºå‰ª•Ë®òÊÜ∂ÂÖ∑Êúâ 1 Â±§„ÄÅ1 È†≠TransformerÁöÑ‰ªª‰ΩïË≥áÊñôÈõÜ„ÄÇÂú®Ë®àÁÆó‰∏äÔºåÊàëÂÄëÂú®ÊèêÁ§∫Ë™øÊï¥ÁöÑÊïàÁéá‰∏≠ÁôºÁèæ‰∫Ü‰∏ÄÂÄãÁõ∏ËÆäÔºåÁî±ËªüÊèêÁ§∫Ë™òÂ∞éÁöÑÈçµÂíåÊü•Ë©¢ÁöÑÁØÑÊï∏Ê±∫ÂÆöÔºå‰∏¶Êèê‰æõ‰∫Ü‰∏ÄÂÄã‰∏äÈôêÊ∫ñÂâá„ÄÇÂú®Ê≠§Ê∫ñÂâá‰πãÂ§ñÔºåÂú® SETH ‰∏ã‰∏çÂ≠òÂú®‰ªª‰ΩïÊ¨°‰∫åÊ¨°ÔºàÈ´òÊïàÔºâÁöÑÊèêÁ§∫Ë™øÊï¥ÊºîÁÆóÊ≥ï„ÄÇÂú®Ê≠§Ê∫ñÂâáÂÖßÔºåÊàëÂÄëÈÄöÈÅéË≠âÊòéÂπæ‰πéÁ∑öÊÄßÊôÇÈñìÊèêÁ§∫Ë™øÊï¥Êé®Ë´ñÊºîÁÆóÊ≥ïÁöÑÂ≠òÂú®‰æÜÂ±ïÁ§∫ÊàëÂÄëÁöÑÁêÜË´ñ„ÄÇÈÄô‰∫õÂü∫Êú¨ÈôêÂà∂ÁÇ∫ÂØ¶ÂãôËÄÖË®≠Ë®àÂÖ∑ÊúâË°®ÈÅîÂäõÂíåÈ´òÊïàÁöÑÊèêÁ§∫Ë™øÊï¥ÊñπÊ≥ïÊèê‰æõ‰∫ÜÈáçË¶ÅÁöÑÂøÖË¶ÅÊ¢ù‰ª∂„ÄÇ

##### **LaB-RAG: Label Boosted Retrieval Augmented Generation for Radiology Report Generation**
2411.16523v1 by Steven Song, Anirudh Subramanyam, Irene Madejski, Robert L. Grossman

In the current paradigm of image captioning, deep learning models are trained
to generate text from image embeddings of latent features. We challenge the
assumption that these latent features ought to be high-dimensional vectors
which require model fine tuning to handle. Here we propose Label Boosted
Retrieval Augmented Generation (LaB-RAG), a text-based approach to image
captioning that leverages image descriptors in the form of categorical labels
to boost standard retrieval augmented generation (RAG) with pretrained large
language models (LLMs). We study our method in the context of radiology report
generation (RRG), where the task is to generate a clinician's report detailing
their observations from a set of radiological images, such as X-rays. We argue
that simple linear classifiers over extracted image embeddings can effectively
transform X-rays into text-space as radiology-specific labels. In combination
with standard RAG, we show that these derived text labels can be used with
general-domain LLMs to generate radiology reports. Without ever training our
generative language model or image feature encoder models, and without ever
directly "showing" the LLM an X-ray, we demonstrate that LaB-RAG achieves
better results across natural language and radiology language metrics compared
with other retrieval-based RRG methods, while attaining competitive results
compared to other fine-tuned vision-language RRG models. We further present
results of our experiments with various components of LaB-RAG to better
understand our method. Finally, we critique the use of a popular RRG metric,
arguing it is possible to artificially inflate its results without true
data-leakage.

ÊëòË¶ÅÔºö<paragraph>Âú®Áï∂ÂâçÂΩ±ÂÉèÊ®ôÈ°åÁöÑÁØÑ‰æã‰∏≠ÔºåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁ∂ìÈÅéË®ìÁ∑¥ÔºåÂèØÂæûÊΩõÂú®ÁâπÂæµÁöÑÂΩ±ÂÉèÂµåÂÖ•Áî¢ÁîüÊñáÂ≠ó„ÄÇÊàëÂÄëÊåëÊà∞‰∫ÜÈÄô‰∫õÊΩõÂú®ÁâπÂæµÊáâÁÇ∫È´òÁ∂≠ÂêëÈáèÁöÑÂÅáË®≠ÔºåËÄåÈÄô‰∫õÂêëÈáèÈúÄË¶ÅÊ®°ÂûãÂæÆË™øÊâçËÉΩËôïÁêÜ„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊèêÂá∫Ê®ôÁ±§ÊèêÂçáÊ™¢Á¥¢Êì¥Â¢ûÁîüÊàê (LaB-RAG)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂü∫ÊñºÊñáÂ≠óÁöÑÂΩ±ÂÉèÊ®ôÈ°åÊñπÊ≥ïÔºåÂÆÉÂà©Áî®È°ûÂà•Ê®ôÁ±§ÂΩ¢ÂºèÁöÑÂΩ±ÂÉèÊèèËø∞Á¨¶‰æÜÊèêÂçáÊ®ôÊ∫ñÊ™¢Á¥¢Êì¥Â¢ûÁîüÊàê (RAG) ËàáÈ†êÂÖàË®ìÁ∑¥ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)„ÄÇÊàëÂÄëÂú®ÊîæÂ∞ÑÁßëÂ†±ÂëäÁîüÊàê (RRG) ÁöÑËÑàÁµ°‰∏≠Á†îÁ©∂ÊàëÂÄëÁöÑÊ®°ÂûãÔºå‰ªªÂãôÊòØÊ†πÊìö‰∏ÄÁµÑÊîæÂ∞ÑÁßëÂΩ±ÂÉèÔºà‰æãÂ¶Ç X ÂÖâÔºâ‰∏≠ÁöÑËßÄÂØüÁµêÊûúÔºåÁî¢ÁîüËá®Â∫äÈÜ´Â∏´ÁöÑÂ†±Âëä„ÄÇÊàëÂÄëË™çÁÇ∫ÔºåÈáùÂ∞çÊèêÂèñÁöÑÂΩ±ÂÉèÂµåÂÖ•ÊâÄÂÅöÁöÑÁ∞°ÂñÆÁ∑öÊÄßÂàÜÈ°ûÂô®ÂèØ‰ª•ÊúâÊïàÂú∞Â∞á X ÂÖâËΩâÊèõÊàêÊñáÂ≠óÁ©∫ÈñìÔºå‰ΩúÁÇ∫ÊîæÂ∞ÑÁßëÂ∞àÁî®ÁöÑÊ®ôÁ±§„ÄÇÁµêÂêàÊ®ôÊ∫ñ RAGÔºåÊàëÂÄëË≠âÊòéÈÄô‰∫õË°çÁîüÁöÑÊñáÂ≠óÊ®ôÁ±§ÂèØÁî®Êñº‰∏ÄËà¨È†òÂüüÁöÑ LLMÔºå‰ª•Áî¢ÁîüÊîæÂ∞ÑÁßëÂ†±Âëä„ÄÇÊàëÂÄëÂæûÊú™Ë®ìÁ∑¥ÈÅéÊàëÂÄëÁöÑÁîüÊàêÂºèË™ûË®ÄÊ®°ÂûãÊàñÂΩ±ÂÉèÁâπÂæµÁ∑®Á¢ºÂô®Ê®°ÂûãÔºå‰πüÂæûÊú™Áõ¥Êé•„ÄåÂ±ïÁ§∫„ÄçLLM X ÂÖâÔºåÊàëÂÄëË≠âÊòé LaB-RAG Âú®Ëá™ÁÑ∂Ë™ûË®ÄÂíåÊîæÂ∞ÑÁßëË™ûË®ÄÊåáÊ®ô‰∏äÁöÑË°®ÁèæÔºåÂÑ™ÊñºÂÖ∂‰ªñÂü∫ÊñºÊ™¢Á¥¢ÁöÑ RRG ÊñπÊ≥ïÔºåÂêåÊôÇËàáÂÖ∂‰ªñÂæÆË™øÁöÑË¶ñË¶∫Ë™ûË®Ä RRG Ê®°ÂûãÁõ∏ÊØîÔºå‰πüÂèñÂæó‰∫ÜÁ´∂Áà≠ÂäõÁöÑÁµêÊûú„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Â±ïÁ§∫‰∫Ü‰ΩøÁî® LaB-RAG ÂêÑÁ®ÆÂÖÉ‰ª∂ÁöÑÂØ¶È©óÁµêÊûúÔºå‰ª•Êõ¥‰∫ÜËß£ÊàëÂÄëÁöÑÊ®°Âûã„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊâπÂà§‰∫Ü‰ΩøÁî®‰∏ÄÁ®ÆÂª£Ê≥õ‰ΩøÁî®ÁöÑ RRG ÊåáÊ®ôÔºå‰∏¶‰∏ªÂºµÂú®Ê≤íÊúâÁúüÊ≠£Ë≥áÊñôÂ§ñÊ¥©ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂ∞±ÊúâÂèØËÉΩ‰∫∫ÁÇ∫Âú∞ËÜ®ËÑπÂÖ∂ÁµêÊûú„ÄÇ</paragraph>

##### **All Languages Matter: Evaluating LMMs on Culturally Diverse 100 Languages**
2411.16508v1 by Ashmal Vayani, Dinura Dissanayake, Hasindri Watawana, Noor Ahsan, Nevasini Sasikumar, Omkar Thawakar, Henok Biadglign Ademtew, Yahya Hmaiti, Amandeep Kumar, Kartik Kuckreja, Mykola Maslych, Wafa Al Ghallabi, Mihail Mihaylov, Chao Qin, Abdelrahman M Shaker, Mike Zhang, Mahardika Krisna Ihsani, Amiel Esplana, Monil Gokani, Shachar Mirkin, Harsh Singh, Ashay Srivastava, Endre Hamerlik, Fathinah Asma Izzati, Fadillah Adamsyah Maani, Sebastian Cavada, Jenny Chim, Rohit Gupta, Sanjay Manjunath, Kamila Zhumakhanova, Feno Heriniaina Rabevohitra, Azril Amirudin, Muhammad Ridzuan, Daniya Kareem, Ketan More, Kunyang Li, Pramesh Shakya, Muhammad Saad, Amirpouya Ghasemaghaei, Amirbek Djanibekov, Dilshod Azizov, Branislava Jankovic, Naman Bhatia, Alvaro Cabrera, Johan Obando-Ceron, Olympiah Otieno, Fabian Farestam, Muztoba Rabbani, Sanoojan Baliah, Santosh Sanjeev, Abduragim Shtanchaev, Maheen Fatima, Thao Nguyen, Amrin Kareem, Toluwani Aremu, Nathan Xavier, Amit Bhatkal, Hawau Toyin, Aman Chadha, Hisham Cholakkal, Rao Muhammad Anwer, Michael Felsberg, Jorma Laaksonen, Thamar Solorio, Monojit Choudhury, Ivan Laptev, Mubarak Shah, Salman Khan, Fahad Khan

Existing Large Multimodal Models (LMMs) generally focus on only a few regions
and languages. As LMMs continue to improve, it is increasingly important to
ensure they understand cultural contexts, respect local sensitivities, and
support low-resource languages, all while effectively integrating corresponding
visual cues. In pursuit of culturally diverse global multimodal models, our
proposed All Languages Matter Benchmark (ALM-bench) represents the largest and
most comprehensive effort to date for evaluating LMMs across 100 languages.
ALM-bench challenges existing models by testing their ability to understand and
reason about culturally diverse images paired with text in various languages,
including many low-resource languages traditionally underrepresented in LMM
research. The benchmark offers a robust and nuanced evaluation framework
featuring various question formats, including true/false, multiple choice, and
open-ended questions, which are further divided into short and long-answer
categories. ALM-bench design ensures a comprehensive assessment of a model's
ability to handle varied levels of difficulty in visual and linguistic
reasoning. To capture the rich tapestry of global cultures, ALM-bench carefully
curates content from 13 distinct cultural aspects, ranging from traditions and
rituals to famous personalities and celebrations. Through this, ALM-bench not
only provides a rigorous testing ground for state-of-the-art open and
closed-source LMMs but also highlights the importance of cultural and
linguistic inclusivity, encouraging the development of models that can serve
diverse global populations effectively. Our benchmark is publicly available.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÂ§ßÂûãÂ§öÊ®°ÊÖãÊ®°ÂûãÔºàLMMÔºâÈÄöÂ∏∏Âè™Â∞àÊ≥®ÊñºÂ∞ëÊï∏ÂçÄÂüüÂíåË™ûË®Ä„ÄÇÈö®Ëëó LMM ÊåÅÁ∫åÈÄ≤Ê≠•ÔºåÁ¢∫‰øùÂÆÉÂÄëËÉΩÁêÜËß£ÊñáÂåñËÉåÊôØ„ÄÅÂ∞äÈáçÁï∂Âú∞ÊïèÊÑüÊÄßÔºå‰ª•ÂèäÊîØÊè¥‰ΩéË≥áÊ∫êË™ûË®ÄËÆäÂæóË∂ä‰æÜË∂äÈáçË¶ÅÔºåÂêåÊôÇÈÇÑË¶ÅÊúâÊïàÊï¥ÂêàÂ∞çÊáâÁöÑË¶ñË¶∫ÊèêÁ§∫„ÄÇÁÇ∫‰∫ÜËøΩÊ±ÇÊñáÂåñÂ§öÂÖÉÁöÑÂÖ®ÁêÉÂ§öÊ®°ÊÖãÊ®°ÂûãÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊâÄÊúâË™ûË®ÄÈáçË¶ÅÂü∫Ê∫ñÔºàALM-benchÔºâ‰ª£Ë°®‰∫ÜËøÑ‰ªäÁÇ∫Ê≠¢Ë©ï‰º∞ 100 Á®ÆË™ûË®ÄÁöÑ LMM ÁöÑÊúÄÂ§ßË¶èÊ®°‰∏îÊúÄÂÖ®Èù¢ÁöÑÂä™Âäõ„ÄÇALM-bench ÈÄèÈÅéÊ∏¨Ë©¶ LMM ÁêÜËß£ÂíåÊé®ÁêÜËàáÂêÑÁ®ÆË™ûË®ÄÔºàÂåÖÊã¨ÂÇ≥Áµ±‰∏äÂú® LMM Á†îÁ©∂‰∏≠‰ª£Ë°®ÊÄß‰∏çË∂≥ÁöÑË®±Â§ö‰ΩéË≥áÊ∫êË™ûË®ÄÔºâÈÖçÂ∞çÁöÑÊñáÂåñÂ§öÂÖÉÂúñÂÉèÁöÑËÉΩÂäõÔºåÂ∞çÁèæÊúâÊ®°ÂûãÊèêÂá∫ÊåëÊà∞„ÄÇÊ≠§Âü∫Ê∫ñÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂº∑ÂÅ•‰∏îÁ¥∞Á∑ªÁöÑË©ï‰º∞Êû∂ÊßãÔºåÂÖ∑ÊúâÂêÑÁ®ÆÂïèÈ°åÊ†ºÂºèÔºåÂåÖÊã¨ÊòØÈùûÈ°å„ÄÅÂ§öÈÅ∏È°åÂíåÈñãÊîæÂºèÂïèÈ°åÔºåÈÄ≤‰∏ÄÊ≠•ÂàÜÁÇ∫Á∞°Á≠îÂíåÈï∑Á≠îÈ°ûÂà•„ÄÇALM-bench Ë®≠Ë®àÁ¢∫‰øùÂÖ®Èù¢Ë©ï‰º∞Ê®°ÂûãÂú®Ë¶ñË¶∫ÂíåË™ûË®ÄÊé®ÁêÜ‰∏≠ËôïÁêÜ‰∏çÂêåÈõ£Â∫¶Á≠âÁ¥öÁöÑËÉΩÂäõ„ÄÇÁÇ∫‰∫ÜÊçïÊçâÂÖ®ÁêÉÊñáÂåñÁöÑË±êÂØåÊ®£Ë≤åÔºåALM-bench Á≤æÂøÉÁ≠ñÂäÉ‰∫Ü‰æÜËá™ 13 ÂÄã‰∏çÂêåÊñáÂåñÈù¢ÂêëÁöÑÂÖßÂÆπÔºåÂæûÂÇ≥Áµ±ÂíåÂÑÄÂºèÂà∞Âêç‰∫∫ËàáÊÖ∂ÂÖ∏„ÄÇÈÄèÈÅéÊ≠§ÊñπÂºèÔºåALM-bench ‰∏çÂÉÖÁÇ∫ÊúÄÂÖàÈÄ≤ÁöÑÈñãÊîæÂíåÈñâÊ∫ê LMM Êèê‰æõ‰∫ÜÂö¥Ê†ºÁöÑÊ∏¨Ë©¶Â†¥ÂüüÔºå‰πüÁ™ÅÈ°Ø‰∫ÜÊñáÂåñÂíåË™ûË®ÄÂåÖÂÆπÊÄßÁöÑÈáçË¶ÅÊÄßÔºåÈºìÂãµÈñãÁôºËÉΩÊúâÊïàÊúçÂãôÂÖ®ÁêÉÂ§öÂÖÉ‰∫∫Âè£ÁöÑÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÂü∫Ê∫ñÊòØÂÖ¨ÈñãÁöÑ„ÄÇ

##### **Interpreting Language Reward Models via Contrastive Explanations**
2411.16502v1 by Junqi Jiang, Tom Bewley, Saumitra Mishra, Freddy Lecue, Manuela Veloso

Reward models (RMs) are a crucial component in the alignment of large
language models' (LLMs) outputs with human values. RMs approximate human
preferences over possible LLM responses to the same prompt by predicting and
comparing reward scores. However, as they are typically modified versions of
LLMs with scalar output heads, RMs are large black boxes whose predictions are
not explainable. More transparent RMs would enable improved trust in the
alignment of LLMs. In this work, we propose to use contrastive explanations to
explain any binary response comparison made by an RM. Specifically, we generate
a diverse set of new comparisons similar to the original one to characterise
the RM's local behaviour. The perturbed responses forming the new comparisons
are generated to explicitly modify manually specified high-level evaluation
attributes, on which analyses of RM behaviour are grounded. In quantitative
experiments, we validate the effectiveness of our method for finding
high-quality contrastive explanations. We then showcase the qualitative
usefulness of our method for investigating global sensitivity of RMs to each
evaluation attribute, and demonstrate how representative examples can be
automatically extracted to explain and compare behaviours of different RMs. We
see our method as a flexible framework for RM explanation, providing a basis
for more interpretable and trustworthy LLM alignment.

ÊëòË¶ÅÔºöÁçéÂãµÊ®°Âûã (RM) ÊòØÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ëº∏Âá∫Ëàá‰∫∫È°ûÂÉπÂÄºËßÄ‰∏ÄËá¥ÊÄßÁöÑÈóúÈçµÁµÑÊàêÈÉ®ÂàÜ„ÄÇRM ÈÄèÈÅéÈ†êÊ∏¨ÂíåÊØîËºÉÁçéÂãµÂàÜÊï∏‰æÜËøë‰ºº‰∫∫È°ûÂ∞çÁõ∏ÂêåÊèêÁ§∫ÁöÑ LLM ÂõûÊáâÁöÑÂÅèÂ•Ω„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÂÆÉÂÄëÈÄöÂ∏∏ÊòØÂÖ∑ÊúâÊ®ôÈáèËº∏Âá∫È†≠ÁöÑ LLM ÁöÑ‰øÆÊîπÁâàÊú¨ÔºåÂõ†Ê≠§ RM ÊòØÂ§ßÂûãÈªëÁõíÂ≠êÔºåÂÖ∂È†êÊ∏¨ÁÑ°Ê≥ïËß£Èáã„ÄÇÊõ¥ÈÄèÊòéÁöÑ RM ÂèØ‰ª•ÊèêÈ´òÂ∞ç LLM ‰∏ÄËá¥ÊÄßÁöÑ‰ø°‰ªª„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂª∫Ë≠∞‰ΩøÁî®Â∞çÊØîËß£Èáã‰æÜËß£Èáã RM ÂÅöÂá∫ÁöÑ‰ªª‰Ωï‰∫åÂÖÉÂõûÊáâÊØîËºÉ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÁîüÊàê‰∏ÄÁµÑËàáÂéüÂßãÊØîËºÉÈ°û‰ººÁöÑÂ§öÊ®£ÂåñÊñ∞ÊØîËºÉÔºå‰ª•Ë°®Âæµ RM ÁöÑÂ±ÄÈÉ®Ë°åÁÇ∫„ÄÇÂΩ¢ÊàêÊñ∞ÊØîËºÉÁöÑÊìæÂãïÂõûÊáâË¢´ÁîüÊàê‰ª•ÊòéÁ¢∫‰øÆÊîπÊâãÂãïÊåáÂÆöÁöÑË©ï‰º∞È´òÂ±§Á¥öÂ±¨ÊÄßÔºåRM Ë°åÁÇ∫ÂàÜÊûê‰ª•Ê≠§ÁÇ∫Âü∫Á§é„ÄÇÂú®ÂÆöÈáèÂØ¶È©ó‰∏≠ÔºåÊàëÂÄëÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®Â∞ãÊâæÈ´òÂìÅË≥™Â∞çÊØîËß£ÈáãÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®Á†îÁ©∂ RM Â∞çÊØèÂÄãË©ï‰º∞Â±¨ÊÄßÁöÑÂÖ®Â±ÄÊïèÊÑüÊÄßÊñπÈù¢ÁöÑÂÆöÊÄßÊúâÁî®ÊÄßÔºå‰∏¶Â±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïËá™ÂãïÊèêÂèñ‰ª£Ë°®ÊÄßÁØÑ‰æã‰æÜËß£ÈáãÂíåÊØîËºÉ‰∏çÂêå RM ÁöÑË°åÁÇ∫„ÄÇÊàëÂÄëÂ∞áÊàëÂÄëÁöÑÁöÑÊñπÊ≥ïË¶ñÁÇ∫ RM Ëß£ÈáãÁöÑÂΩàÊÄßÊ°ÜÊû∂ÔºåÁÇ∫Êõ¥ÂÖ∑ÂèØËß£ÈáãÊÄßÂíåÂèØ‰ø°Ë≥¥ÊÄßÁöÑ LLM ‰∏ÄËá¥ÊÄßÊèê‰æõÂü∫Á§é„ÄÇ

##### **AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning**
2411.16495v1 by Amy Xin, Jinxin Liu, Zijun Yao, Zhicheng Li, Shulin Cao, Lei Hou, Juanzi Li

Recent advancements in large language models (LLMs) have led to significant
improvements in various natural language processing tasks, but it is still
challenging for LLMs to perform knowledge-intensive complex question answering
due to LLMs' inefficacy in reasoning planning and the hallucination problem. A
typical solution is to employ retrieval-augmented generation (RAG) coupled with
chain-of-thought (CoT) reasoning, which decomposes complex questions into
chain-like sub-questions and applies iterative RAG at each sub-question.
However, prior works exhibit sub-optimal reasoning planning and overlook
dynamic knowledge retrieval from heterogeneous sources. In this paper, we
propose AtomR, a novel heterogeneous knowledge reasoning framework that
conducts multi-source reasoning at the atomic level. Drawing inspiration from
the graph modeling of knowledge, AtomR leverages large language models (LLMs)
to decompose complex questions into combinations of three atomic knowledge
operators, significantly enhancing the reasoning process at both the planning
and execution stages. We also introduce BlendQA, a novel evaluation benchmark
tailored to assess complex heterogeneous knowledge reasoning. Experiments show
that AtomR significantly outperforms state-of-the-art baselines across three
single-source and two multi-source reasoning benchmarks, with notable
performance gains of 9.4% on 2WikiMultihop and 9.5% on BlendQA.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂ∑≤Â§ßÂπÖÊîπÂñÑÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãôÔºå‰ΩÜÁî±Êñº LLM Âú®Êé®ÁêÜË¶èÂäÉÂíåÂπªË¶∫ÂïèÈ°å‰∏äÁöÑÁÑ°ËÉΩÔºåÂ∞çÊñº LLM Âü∑Ë°åÈúÄË¶ÅÁü•Ë≠òÁöÑË§áÈõúÂïèÈ°åÂõûÁ≠î‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂÖ∏ÂûãÁöÑËß£Ê±∫ÊñπÊ°àÊòØÊé°Áî®Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) Êê≠ÈÖçÊÄùËÄÉÈèà (CoT) Êé®ÁêÜÔºåÂ∞áË§áÈõúÂïèÈ°åÂàÜËß£ÊàêÈèàÁãÄÂ≠êÂïèÈ°åÔºå‰∏¶Âú®ÊØèÂÄãÂ≠êÂïèÈ°å‰∏äÂ•óÁî®Ëø≠‰ª£ RAG„ÄÇÁÑ∂ËÄåÔºåÂÖàÂâçÁöÑÂ∑•‰ΩúÂ±ïÁèæÂá∫Ê¨°‰Ω≥Êé®ÁêÜË¶èÂäÉÔºå‰∏îÂøΩÁï•‰∫ÜÂæûÁï∞Ë≥™‰æÜÊ∫êÂãïÊÖãÊ™¢Á¥¢Áü•Ë≠ò„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ AtomRÔºå‰∏ÄÂÄãÊñ∞Á©éÁöÑÁï∞Ë≥™Áü•Ë≠òÊé®ÁêÜÊû∂ÊßãÔºåÂú®ÂéüÂ≠êÂ±§Á¥öÂü∑Ë°åÂ§ö‰æÜÊ∫êÊé®ÁêÜ„ÄÇÂæûÁü•Ë≠òÁöÑÂúñÂΩ¢Âª∫Ê®°‰∏≠Ê±≤ÂèñÈùàÊÑüÔºåAtomR Êé°Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∞áË§áÈõúÂïèÈ°åÂàÜËß£Êàê‰∏âÁ®ÆÂéüÂ≠êÁü•Ë≠òÈÅãÁÆóÂ≠êÁöÑÁµÑÂêàÔºåÂ§ßÂπÖÂº∑ÂåñË¶èÂäÉÂíåÂü∑Ë°åÈöéÊÆµÁöÑÊé®ÁêÜÁ®ãÂ∫è„ÄÇÊàëÂÄë‰πüÂºïÂÖ•‰∫Ü BlendQAÔºå‰∏ÄÂÄãÊñ∞Á©éÁöÑË©ïÈáèÂü∫Ê∫ñÔºåÂ∞àÈñÄÁî®‰æÜË©ï‰º∞Ë§áÈõúÁöÑÁï∞Ë≥™Áü•Ë≠òÊé®ÁêÜ„ÄÇÂØ¶È©óÈ°ØÁ§∫ÔºåAtomR Âú®‰∏âÂÄãÂñÆ‰∏Ä‰æÜÊ∫êÂíåÂÖ©ÂÄãÂ§ö‰æÜÊ∫êÊé®ÁêÜÂü∫Ê∫ñ‰∏äÂ§ßÂπÖÂÑ™ÊñºÁèæÊúâÁöÑÂü∫Á∑öÔºåÂú® 2WikiMultihop ‰∏äÊúâ 9.4% ÁöÑÈ°ØËëóÊïàËÉΩÊèêÂçáÔºåÂú® BlendQA ‰∏äÂâáÊúâ 9.5%„ÄÇ

##### **O1 Replication Journey -- Part 2: Surpassing O1-preview through Simple Distillation, Big Progress or Bitter Lesson?**
2411.16489v1 by Zhen Huang, Haoyang Zou, Xuefeng Li, Yixiu Liu, Yuxiang Zheng, Ethan Chern, Shijie Xia, Yiwei Qin, Weizhe Yuan, Pengfei Liu

This paper presents a critical examination of current approaches to
replicating OpenAI's O1 model capabilities, with particular focus on the
widespread but often undisclosed use of knowledge distillation techniques.
While our previous work explored the fundamental technical path to O1
replication, this study reveals how simple distillation from O1's API, combined
with supervised fine-tuning, can achieve superior performance on complex
mathematical reasoning tasks. Through extensive experiments, we show that a
base model fine-tuned on simply tens of thousands of samples O1-distilled
long-thought chains outperforms O1-preview on the American Invitational
Mathematics Examination (AIME) with minimal technical complexity. Moreover, our
investigation extends beyond mathematical reasoning to explore the
generalization capabilities of O1-distilled models across diverse tasks:
hallucination, safety and open-domain QA. Notably, despite training only on
mathematical problem-solving data, our models demonstrated strong
generalization to open-ended QA tasks and became significantly less susceptible
to sycophancy after fine-tuning. We deliberately make this finding public to
promote transparency in AI research and to challenge the current trend of
obscured technical claims in the field. Our work includes: (1) A detailed
technical exposition of the distillation process and its effectiveness, (2) A
comprehensive benchmark framework for evaluating and categorizing O1
replication attempts based on their technical transparency and reproducibility,
(3) A critical discussion of the limitations and potential risks of
over-relying on distillation approaches, our analysis culminates in a crucial
bitter lesson: while the pursuit of more capable AI systems is important, the
development of researchers grounded in first-principles thinking is paramount.

ÊëòË¶ÅÔºöÊú¨Ë´ñÊñáÂ∞çË§áË£Ω OpenAI ÁöÑ O1 Ê®°ÂûãËÉΩÂäõÁöÑÁèæÊúâÊñπÊ≥ïÈÄ≤Ë°åÊâπÂà§ÊÄßÊé¢Ë®éÔºåÁâπÂà•ÈóúÊ≥®Áü•Ë≠òËí∏È§æÊäÄË°ìÁöÑÂª£Ê≥õ‰ΩÜÁ∂ìÂ∏∏Êú™ÂÖ¨ÈñãÁöÑ‰ΩøÁî®„ÄÇÈõñÁÑ∂ÊàëÂÄë‰πãÂâçÁöÑÂ∑•‰ΩúÊé¢Á¥¢‰∫Ü O1 Ë§áË£ΩÁöÑÂü∫Êú¨ÊäÄË°ìË∑ØÂæëÔºå‰ΩÜÊú¨Á†îÁ©∂Êè≠Á§∫‰∫ÜÂæû O1 ÁöÑ API ÈÄ≤Ë°åÁ∞°ÂñÆËí∏È§æÔºåÁµêÂêàÁõ£Áù£ÂæÆË™øÔºåÂèØ‰ª•Âú®Ë§áÈõúÁöÑÊï∏Â≠∏Êé®ÁêÜ‰ªªÂãô‰∏äÂØ¶ÁèæÂçìË∂äÁöÑÊÄßËÉΩ„ÄÇÈÄöÈÅéÂ§ßÈáèÁöÑÂØ¶È©óÔºåÊàëÂÄëË°®ÊòéÂú®ÂÉÖÊï∏Ëê¨ÂÄãÊ®£Êú¨‰∏äÈÄ≤Ë°åÂæÆË™øÁöÑÂü∫Êú¨Ê®°ÂûãÔºåO1 Ëí∏È§æÁöÑÈï∑ÊúüÊÄùËÄÉÈèàÂú®ÁæéÂúãÈÇÄË´ãË≥ΩÊï∏Â≠∏ËÄÉË©¶ (AIME) ‰∏äÂÑ™Êñº O1 È†êË¶ΩÔºå‰∏îÊäÄË°ìË§áÈõúÊÄßÊúÄÂ∞è„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÁ†îÁ©∂‰∏çÂÉÖÈôêÊñºÊï∏Â≠∏Êé®ÁêÜÔºåÈÇÑÊé¢Á¥¢‰∫Ü O1 Ëí∏È§æÊ®°ÂûãÂú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠ÁöÑÊ≥õÂåñËÉΩÂäõÔºöÂπªË¶∫„ÄÅÂÆâÂÖ®ÊÄß„ÄÅÈñãÊîæÂüü QA„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂÑòÁÆ°ÂÉÖÊ†πÊìöÊï∏Â≠∏ÂïèÈ°åËß£Ê±∫Êï∏ÊìöÈÄ≤Ë°åË®ìÁ∑¥ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÈñãÊîæÂºè QA ‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫Âº∑Â§ßÁöÑÊ≥õÂåñËÉΩÂäõÔºå‰∏¶‰∏îÂú®ÂæÆË™øÂæåÂ∞çÈòøË´õÂ•âÊâøÁöÑÂΩ±ÈüøÈ°ØËëóÈôç‰Ωé„ÄÇÊàëÂÄëÊïÖÊÑèÂÖ¨ÈñãÈÄô‰∏ÄÁôºÁèæÔºå‰ª•‰øÉÈÄ≤‰∫∫Â∑•Êô∫ËÉΩÁ†îÁ©∂ÁöÑÈÄèÊòéÂ∫¶Ôºå‰∏¶ÊåëÊà∞Ë©≤È†òÂüüÁï∂ÂâçÊäÄË°ìËÅ≤ÊòéÊ®°Á≥äÁöÑË∂®Âã¢„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÂåÖÊã¨Ôºö(1) Ëí∏È§æÈÅéÁ®ãÂèäÂÖ∂ÊúâÊïàÊÄßÁöÑË©≥Á¥∞ÊäÄË°ìË™™ÊòéÔºå(2) Áî®ÊñºË©ï‰º∞ÂíåÂàÜÈ°û O1 Ë§áË£ΩÂòóË©¶ÁöÑÁ∂úÂêàÂü∫Ê∫ñÊû∂ÊßãÔºåÂü∫ÊñºÂÆÉÂÄëÁöÑÊäÄË°ìÈÄèÊòéÂ∫¶ÂíåÂèØË§áË£ΩÊÄßÔºå(3) ÈÅéÂ∫¶‰æùË≥¥Ëí∏È§æÊñπÊ≥ïÁöÑÂ±ÄÈôêÊÄßÂíåÊΩõÂú®È¢®Èö™ÁöÑÊâπÂà§ÊÄßË®éË´ñÔºåÊàëÂÄëÁöÑÂàÜÊûêÊúÄÁµÇÂæóÂá∫‰∏ÄÂÄãËá≥ÈóúÈáçË¶ÅÁöÑÊÖòÁóõÊïôË®ìÔºöÈõñÁÑ∂ËøΩÊ±ÇÊõ¥Âº∑Â§ßÁöÑ AI Á≥ªÁµ±ÂæàÈáçË¶ÅÔºå‰ΩÜÂüπÈ§ä‰ª•Á¨¨‰∏ÄÊÄßÂéüÁêÜÊÄùÁ∂≠ÁÇ∫Âü∫Á§éÁöÑÁ†îÁ©∂‰∫∫Âì°Ëá≥ÈóúÈáçË¶Å„ÄÇ

##### **When Babies Teach Babies: Can student knowledge sharing outperform Teacher-Guided Distillation on small datasets?**
2411.16487v1 by Srikrishna Iyer

We present our submission to the BabyLM challenge, aiming to push the
boundaries of data-efficient language model pretraining. Our method builds upon
deep mutual learning, introducing a student model search for diverse
initialization. We address the limitation of treating students equally by
formulating weighted mutual learning as a bi-level optimization problem. The
inner loop learns compact students through online distillation, while the outer
loop optimizes weights for better knowledge distillation from diverse students.
This dynamic weighting strategy eliminates the need for a teacher model,
reducing computational requirements. Our evaluations show that teacher-less
methods can match or surpass teacher-supervised approaches.

ÊëòË¶ÅÔºöÊàëÂÄëÊèê‰∫§ BabyLM ÊåëÊà∞ÔºåÊó®Âú®Á™ÅÁ†¥Ë≥áÊñôÊúâÊïàË™ûË®ÄÊ®°ÂûãÈ†êË®ìÁ∑¥ÁöÑÁïåÁ∑ö„ÄÇÊàëÂÄëÁöÑÊäÄË°ìÂª∫Á´ãÂú®Ê∑±Â∫¶‰∫íÂ≠∏ÔºåÂºïÂÖ•Â≠∏ÁîüÊ®°ÂûãÊêúÂ∞ã‰ª•ÈÄ≤Ë°åÂ§öÂÖÉÂàùÂßãÂåñ„ÄÇÊàëÂÄëÈÄèÈÅéÂ∞áÂä†Ê¨ä‰∫íÂ≠∏Ë°®Ëø∞ÁÇ∫ÈõôÂ±§ÊúÄ‰Ω≥ÂåñÂïèÈ°åÔºå‰æÜËß£Ê±∫Âπ≥Á≠âÂ∞çÂæÖÂ≠∏ÁîüÁöÑÈôêÂà∂„ÄÇÂÖßÂ±§Ëø¥ÂúàÈÄèÈÅéÁ∑ö‰∏äËêÉÂèñÂ≠∏ÁøíÁ≤æÁ∞°ÁöÑÂ≠∏ÁîüÔºåËÄåÂ§ñÂ±§Ëø¥ÂúàÊúÄ‰Ω≥ÂåñÊ¨äÈáçÔºå‰ª•ÂæûÂ§öÂÖÉÂ≠∏Áîü‰∏≠ÈÄ≤Ë°åÊõ¥Â•ΩÁöÑÁü•Ë≠òËêÉÂèñ„ÄÇÈÄôÁ®ÆÂãïÊÖãÂä†Ê¨äÁ≠ñÁï•Ê∂àÈô§‰∫ÜÂ∞çÊïôÂ∏´Ê®°ÂûãÁöÑÈúÄÊ±ÇÔºåÊ∏õÂ∞ë‰∫ÜÈÅãÁÆóÈúÄÊ±Ç„ÄÇÊàëÂÄëÁöÑË©ï‰º∞È°ØÁ§∫ÔºåÁÑ°ÊïôÂ∏´ÊñπÊ≥ïÂèØ‰ª•ÊØîÊì¨ÊàñË∂ÖË∂äÊïôÂ∏´Áõ£Áù£ÊñπÊ≥ï„ÄÇ

##### **Characterized Diffusion Networks for Enhanced Autonomous Driving Trajectory Prediction**
2411.16457v1 by Haoming Li

In this paper, we present a novel trajectory prediction model for autonomous
driving, combining a Characterized Diffusion Module and a Spatial-Temporal
Interaction Network to address the challenges posed by dynamic and
heterogeneous traffic environments. Our model enhances the accuracy and
reliability of trajectory predictions by incorporating uncertainty estimation
and complex agent interactions. Through extensive experimentation on public
datasets such as NGSIM, HighD, and MoCAD, our model significantly outperforms
existing state-of-the-art methods. We demonstrate its ability to capture the
underlying spatial-temporal dynamics of traffic scenarios and improve
prediction precision, especially in complex environments. The proposed model
showcases strong potential for application in real-world autonomous driving
systems.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁî®ÊñºËá™ÂãïÈßïÈßõÁöÑÂÖ®Êñ∞ËªåË∑°È†êÊ∏¨Ê®°ÂûãÔºåÁµêÂêàÁâπÂæµÊì¥Êï£Ê®°ÁµÑÂíåÊôÇÁ©∫‰∫íÂãïÁ∂≤Ë∑ØÔºå‰ª•Ëß£Ê±∫ÂãïÊÖã‰∏îÁï∞Ë≥™ÁöÑ‰∫§ÈÄöÁí∞Â¢ÉÊâÄÂ∏∂‰æÜÁöÑÊåëÊà∞„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÈÄèÈÅéÁ¥çÂÖ•‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÂíåË§áÈõúÁöÑ‰ª£ÁêÜ‰∫íÂãïÔºåÂ¢ûÂº∑‰∫ÜËªåË∑°È†êÊ∏¨ÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÈÄèÈÅéÂú® NGSIM„ÄÅHighD Âíå MoCAD Á≠âÂÖ¨ÈñãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÔºåÊàëÂÄëÁöÑÊ®°ÂûãÈ°ØËëóÂÑ™ÊñºÁèæÊúâÁöÑÊúÄÂÖàÈÄ≤ÊñπÊ≥ï„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂÆÉÊçïÊçâ‰∫§ÈÄöÂ†¥ÊôØ‰∏≠Âü∫Á§éÊôÇÁ©∫ÂãïÊÖãÁöÑËÉΩÂäõÔºå‰∏¶ÊèêÈ´ò‰∫ÜÈ†êÊ∏¨Á≤æÂ∫¶ÔºåÁâπÂà•ÊòØÂú®Ë§áÈõúÁöÑÁí∞Â¢É‰∏≠„ÄÇÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂ±ïÁ§∫‰∫ÜÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑËá™ÂãïÈßïÈßõÁ≥ªÁµ±‰∏≠ÊáâÁî®ÁöÑÂº∑Â§ßÊΩõÂäõ„ÄÇ

##### **Learning by Analogy: Enhancing Few-Shot Prompting for Math Word Problem Solving with Computational Graph-Based Retrieval**
2411.16454v1 by Xiaocong Yang, Jiacheng Lin, Ziqi Wang, Chengxiang Zhai

Large language models (LLMs) are known to struggle with complicated reasoning
tasks such as math word problems (MWPs). In this paper, we present how analogy
from similarly structured questions can improve LLMs' problem-solving
capabilities for MWPs. Specifically, we rely on the retrieval of problems with
similar computational graphs to the given question to serve as exemplars in the
prompt, providing the correct reasoning path for the generation model to refer
to. Empirical results across six math word problem datasets demonstrate the
effectiveness of our proposed method, which achieves a significant improvement
of up to 6.7 percent on average in absolute value, compared to baseline
methods. These results highlight our method's potential in addressing the
reasoning challenges in current LLMs.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Áü•Âú®Ë§áÈõúÊé®ÁêÜ‰ªªÂãôÔºà‰æãÂ¶ÇÊï∏Â≠∏ÊñáÂ≠óÈ°å (MWP)Ôºâ‰∏≠ÊúÉÈÅáÂà∞Âõ∞Èõ£„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰æÜËá™ÁµêÊßãÁõ∏‰ººÁöÑÂïèÈ°åÁöÑÈ°ûÊØîÂ¶Ç‰ΩïËÉΩÊîπÂñÑ LLM Â∞ç MWP ÁöÑÂïèÈ°åËß£Ê±∫ËÉΩÂäõ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄë‰æùË≥¥ÊñºÊì∑ÂèñËàáÁµ¶ÂÆöÂïèÈ°åÂÖ∑ÊúâÈ°û‰ººÈÅãÁÆóÂúñÂΩ¢ÁöÑÂïèÈ°åÔºå‰ΩúÁÇ∫ÊèêÁ§∫‰∏≠ÁöÑÁØÑ‰æãÔºåÁÇ∫ÁîüÊàêÊ®°ÂûãÊèê‰æõÊ≠£Á¢∫ÁöÑÊé®ÁêÜË∑ØÂæë‰ª•‰æõÂèÉËÄÉ„ÄÇÂÖ≠ÂÄãÊï∏Â≠∏ÊñáÂ≠óÈ°åÊï∏ÊìöÈõÜÁöÑÂØ¶Ë≠âÁµêÊûúË≠âÊòé‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåËàáÂü∫Á∑öÊñπÊ≥ïÁõ∏ÊØîÔºåÂπ≥ÂùáÁµïÂ∞çÂÄºÊèêÈ´ò‰∫Ü 6.7 ÂÄãÁôæÂàÜÈªû„ÄÇÈÄô‰∫õÁµêÊûúÁ™ÅÂá∫‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®Ëß£Ê±∫Áï∂Ââç LLM ‰∏≠ÁöÑÊé®ÁêÜÊåëÊà∞ÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇ

##### **TIFeD: a Tiny Integer-based Federated learning algorithm with Direct feedback alignment**
2411.16442v1 by Luca Colombo, Alessandro Falcetta, Manuel Roveri

Training machine and deep learning models directly on extremely
resource-constrained devices is the next challenge in the field of tiny machine
learning. The related literature in this field is very limited, since most of
the solutions focus only on on-device inference or model adaptation through
online learning, leaving the training to be carried out on external Cloud
services. An interesting technological perspective is to exploit Federated
Learning (FL), which allows multiple devices to collaboratively train a shared
model in a distributed way. However, the main drawback of state-of-the-art FL
algorithms is that they are not suitable for running on tiny devices. For the
first time in the literature, in this paper we introduce TIFeD, a Tiny
Integer-based Federated learning algorithm with Direct Feedback Alignment (DFA)
entirely implemented by using an integer-only arithmetic and being specifically
designed to operate on devices with limited resources in terms of memory,
computation and energy. Besides the traditional full-network operating
modality, in which each device of the FL setting trains the entire neural
network on its own local data, we propose an innovative single-layer TIFeD
implementation, which enables each device to train only a portion of the neural
network model and opens the door to a new way of distributing the learning
procedure across multiple devices. The experimental results show the
feasibility and effectiveness of the proposed solution. The proposed TIFeD
algorithm, with its full-network and single-layer implementations, is made
available to the scientific community as a public repository.

ÊëòË¶ÅÔºö<paragraph>Âú®Ê•µÂ∫¶ÂèóÈôêË≥áÊ∫êÁöÑË£ùÁΩÆ‰∏äÁõ¥Êé•Ë®ìÁ∑¥Ê©üÂô®ÂíåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÊòØÂæÆÂûãÊ©üÂô®Â≠∏ÁøíÈ†òÂüüÁöÑ‰∏ã‰∏ÄÈ†ÖÊåëÊà∞„ÄÇÊ≠§È†òÂüüÁöÑÁõ∏ÈóúÊñáÁçªÈùûÂ∏∏ÊúâÈôêÔºåÂõ†ÁÇ∫Â§ßÂ§öÊï∏Ëß£Ê±∫ÊñπÊ°àÂÉÖÂ∞àÊ≥®ÊñºÈÄèÈÅéÁ∑ö‰∏äÂ≠∏ÁøíÈÄ≤Ë°åË£ùÁΩÆÂÖßÊé®Ë´ñÊàñÊ®°ÂûãË™øÊï¥ÔºåËÆìË®ìÁ∑¥Âú®Â§ñÈÉ®Èõ≤Á´ØÊúçÂãô‰∏äÂü∑Ë°å„ÄÇ‰∏ÄÂÄãÊúâË∂£ÁöÑÊäÄË°ìËßÄÈªûÊòØÂà©Áî®ËÅØÂêàÂ≠∏Áøí (FL)ÔºåÂÆÉÂÖÅË®±Â§öÂÄãË£ùÁΩÆ‰ª•ÂàÜÊï£ÁöÑÊñπÂºèÂçîÂêåË®ìÁ∑¥‰∏ÄÂÄãÂÖ±‰∫´Ê®°Âûã„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÊúÄÂÖàÈÄ≤ÁöÑ FL ÊºîÁÆóÊ≥ïÁöÑ‰∏ªË¶ÅÁº∫ÈªûÊòØÂÆÉÂÄë‰∏çÈÅ©ÂêàÂú®ÂæÆÂûãË£ùÁΩÆ‰∏äÂü∑Ë°å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈ¶ñÊ¨°Âú®ÊñáÁçª‰∏≠‰ªãÁ¥π TIFeDÔºå‰∏ÄÁ®ÆÂæÆÂûãÊï¥Êï∏ËÅØÂêàÂ≠∏ÁøíÊºîÁÆóÊ≥ïÔºåÂÖ∑ÊúâÁõ¥Êé•ÂõûÈ•ãÂ∞çÈΩä (DFA)ÔºåÂÆåÂÖ®ÈÄèÈÅé‰ΩøÁî®ÂÉÖÊï¥Êï∏ÁöÑÁÆóË°ìÂØ¶‰ΩúÔºå‰∏¶Â∞àÈñÄË®≠Ë®àÁî®ÊñºÂú®Ë®òÊÜ∂È´î„ÄÅÈÅãÁÆóÂíåËÉΩÊ∫êÊñπÈù¢Ë≥áÊ∫êÊúâÈôêÁöÑË£ùÁΩÆ‰∏äÂü∑Ë°å„ÄÇÈô§‰∫ÜÂÇ≥Áµ±ÁöÑÂÖ®Á∂≤Ë∑ØÊìç‰ΩúÊ®°ÂºèÔºàÂú®ÂÖ∂‰∏≠ FL Ë®≠ÂÆöÁöÑÊØèÂÄãË£ùÁΩÆÈÉΩÂú®ÂÖ∂Ëá™Â∑±ÁöÑÊú¨Âú∞Ë≥áÊñô‰∏äË®ìÁ∑¥Êï¥ÂÄãÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºâ‰πãÂ§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÂñÆÂ±§ TIFeD ÂØ¶‰ΩúÔºåÂÆÉËÆìÊØèÂÄãË£ùÁΩÆÂÉÖË®ìÁ∑¥Á•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÁöÑ‰∏ÄÈÉ®ÂàÜÔºå‰∏¶ÈñãÂïü‰∫Ü‰∏ÄÂÄãÂú®Â§öÂÄãË£ùÁΩÆ‰∏äÂàÜÊ¥æÂ≠∏ÁøíÁ®ãÂ∫èÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫‰∫ÜÊâÄÊèêÂá∫Ëß£Ê±∫ÊñπÊ°àÁöÑÂèØË°åÊÄßÂíåÊúâÊïàÊÄß„ÄÇÊâÄÊèêÂá∫ÁöÑ TIFeD ÊºîÁÆóÊ≥ïÔºåÈÄ£ÂêåÂÖ∂ÂÖ®Á∂≤Ë∑ØÂíåÂñÆÂ±§ÂØ¶‰ΩúÔºåÂ∑≤‰ΩúÁÇ∫ÂÖ¨ÂÖ±ÂÑ≤Â≠òÂ∫´Êèê‰æõÁµ¶ÁßëÂ≠∏Á§æÁæ§„ÄÇ</paragraph>

##### **Finding Structure in Language Models**
2411.16433v1 by Jaap Jumelet

When we speak, write or listen, we continuously make predictions based on our
knowledge of a language's grammar. Remarkably, children acquire this
grammatical knowledge within just a few years, enabling them to understand and
generalise to novel constructions that have never been uttered before. Language
models are powerful tools that create representations of language by
incrementally predicting the next word in a sentence, and they have had a
tremendous societal impact in recent years. The central research question of
this thesis is whether these models possess a deep understanding of grammatical
structure similar to that of humans. This question lies at the intersection of
natural language processing, linguistics, and interpretability. To address it,
we will develop novel interpretability techniques that enhance our
understanding of the complex nature of large-scale language models. We approach
our research question from three directions. First, we explore the presence of
abstract linguistic information through structural priming, a key paradigm in
psycholinguistics for uncovering grammatical structure in human language
processing. Next, we examine various linguistic phenomena, such as adjective
order and negative polarity items, and connect a model's comprehension of these
phenomena to the data distribution on which it was trained. Finally, we
introduce a controlled testbed for studying hierarchical structure in language
models using various synthetic languages of increasing complexity and examine
the role of feature interactions in modelling this structure. Our findings
offer a detailed account of the grammatical knowledge embedded in language
model representations and provide several directions for investigating
fundamental linguistic questions using computational methods.

ÊëòË¶ÅÔºö<paragraph>Áï∂ÊàëÂÄëË™™Ë©±„ÄÅÂØ´‰ΩúÊàñËÅÜËÅΩÊôÇÔºåÊàëÂÄëÊúÉÊåÅÁ∫åÊ†πÊìöËá™Â∑±Â∞çË™ûË®ÄÊñáÊ≥ïÁöÑÁü•Ë≠òÂÅöÂá∫È†êÊ∏¨„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂ≠©Á´•ÂÉÖÂú®ÂπæÂπ¥ÂÖß‰æøËÉΩÁøíÂæóÈÄôÁ®ÆÊñáÊ≥ïÁü•Ë≠òÔºå‰Ωø‰ªñÂÄëËÉΩÂ§†ÁêÜËß£‰∏¶Ê¶ÇÊã¨Âá∫ÂâçÊâÄÊú™ËÅûÁöÑÊñ∞Âª∫Êßã„ÄÇË™ûË®ÄÊ®°ÂûãÊòØÂº∑Â§ßÁöÑÂ∑•ÂÖ∑ÔºåÂÆÉÈÄèÈÅéÈÄêÊ≠•È†êÊ∏¨Âè•Â≠ê‰∏≠ÁöÑ‰∏ã‰∏ÄÂÄãÂñÆÂ≠ó‰æÜÂª∫Á´ãË™ûË®ÄË°®ÂæµÔºå‰∏îÂú®ËøëÂπ¥‰æÜÂ∞çÁ§æÊúÉÁî¢Áîü‰∫ÜÂ∑®Â§ßÁöÑÂΩ±Èüø„ÄÇÊú¨Ë´ñÊñáÁöÑÊ†∏ÂøÉÁ†îÁ©∂ÂïèÈ°åÂú®ÊñºÈÄô‰∫õÊ®°ÂûãÊòØÂê¶ÂÖ∑ÂÇôËàá‰∫∫È°ûÁõ∏‰ººÁöÑÊñáÊ≥ïÁµêÊßãÊ∑±Â∫¶ÁêÜËß£„ÄÇÊ≠§ÂïèÈ°å‰ΩçÊñºËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ„ÄÅË™ûË®ÄÂ≠∏ÂíåÂèØËß£ÈáãÊÄß‰πãÈñìÁöÑ‰∫§ÊúÉÈªû„ÄÇÁÇ∫‰∫ÜÊé¢Ë®éÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂ∞áÈñãÁôºÊñ∞Á©éÁöÑÂèØËß£ÈáãÊÄßÊäÄË°ìÔºå‰ª•Â¢ûÂº∑ÊàëÂÄëÂ∞çÂ§ßÂûãË™ûË®ÄÊ®°ÂûãË§áÈõúÊú¨Ë≥™ÁöÑÁêÜËß£„ÄÇÊàëÂÄëÂæû‰∏âÂÄãÊñπÂêëÊé¢Ë®éÊàëÂÄëÁöÑÁ†îÁ©∂ÂïèÈ°å„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÈÄèÈÅéÁµêÊßãÂïüÂãïÔºà‰∏ÄÁ®ÆÂøÉÁêÜË™ûË®ÄÂ≠∏‰∏≠Áî®ÊñºÊè≠Á§∫‰∫∫È°ûË™ûË®ÄËôïÁêÜ‰∏≠ÊñáÊ≥ïÁµêÊßãÁöÑ‰∏ªË¶ÅÁØÑ‰æãÔºâ‰æÜÊé¢Á¥¢ÊäΩË±°Ë™ûË®ÄË≥áË®äÁöÑÂ≠òÂú®„ÄÇÊé•‰∏ã‰æÜÔºåÊàëÂÄëÊ™¢È©óÂêÑÁ®ÆË™ûË®ÄÁèæË±°Ôºå‰æãÂ¶ÇÂΩ¢ÂÆπË©ûÈ†ÜÂ∫èÂíåÂê¶ÂÆöÊ•µÊÄßÈ†ÖÁõÆÔºå‰∏¶Â∞áÊ®°ÂûãÂ∞çÈÄô‰∫õÁèæË±°ÁöÑÁêÜËß£ËàáÂÖ∂ÂèóË®ìÁöÑË≥áÊñôÂàÜ‰ΩàÈÄ£ÁµêËµ∑‰æÜ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÂÄãÂèóÊéßÊ∏¨Ë©¶Âè∞Ôºå‰ΩøÁî®ÂêÑÁ®ÆË§áÈõúÂ∫¶ÈÅûÂ¢ûÁöÑÂêàÊàêË™ûË®Ä‰æÜÁ†îÁ©∂Ë™ûË®ÄÊ®°Âûã‰∏≠ÁöÑÈöéÂ±§ÁµêÊßãÔºå‰∏¶Ê™¢È©óÁâπÂæµ‰∫íÂãïÂú®Âª∫Ê®°Ê≠§ÁµêÊßã‰∏≠ÁöÑ‰ΩúÁî®„ÄÇÊàëÂÄëÁöÑÁôºÁèæÊèê‰æõ‰∫ÜË™ûË®ÄÊ®°ÂûãË°®Âæµ‰∏≠ÂµåÂÖ•ÁöÑÊñáÊ≥ïÁü•Ë≠òÁöÑË©≥Á¥∞Ë™™ÊòéÔºå‰∏¶Êèê‰æõ‰∫Ü‰ΩøÁî®Ë®àÁÆóÊñπÊ≥ïÊé¢Ë®éÂü∫Êú¨Ë™ûË®ÄÂ≠∏ÂïèÈ°åÁöÑÂπæÂÄãÊñπÂêë„ÄÇ</paragraph>

##### **TopV-Nav: Unlocking the Top-View Spatial Reasoning Potential of MLLM for Zero-shot Object Navigation**
2411.16425v1 by Linqing Zhong, Chen Gao, Zihan Ding, Yue Liao, Si Liu

The Zero-Shot Object Navigation (ZSON) task requires embodied agents to find
a previously unseen object by navigating in unfamiliar environments. Such a
goal-oriented exploration heavily relies on the ability to perceive,
understand, and reason based on the spatial information of the environment.
However, current LLM-based approaches convert visual observations to language
descriptions and reason in the linguistic space, leading to the loss of spatial
information. In this paper, we introduce TopV-Nav, a MLLM-based method that
directly reasons on the top-view map with complete spatial information. To
fully unlock the MLLM's spatial reasoning potential in top-view perspective, we
propose the Adaptive Visual Prompt Generation (AVPG) method to adaptively
construct semantically-rich top-view map. It enables the agent to directly
utilize spatial information contained in the top-view map to conduct thorough
reasoning. Besides, we design a Dynamic Map Scaling (DMS) mechanism to
dynamically zoom top-view map at preferred scales, enhancing local fine-grained
reasoning. Additionally, we devise a Target-Guided Navigation (TGN) mechanism
to predict and to utilize target locations, facilitating global and human-like
exploration. Experiments on MP3D and HM3D benchmarks demonstrate the
superiority of our TopV-Nav, e.g., $+3.9\%$ SR and $+2.0\%$ SPL absolute
improvements on HM3D.

ÊëòË¶ÅÔºöÈõ∂Èè°È†≠Áâ©‰ª∂Â∞éËà™ (ZSON) ‰ªªÂãôË¶ÅÊ±ÇÂÖ∑Ë∫´‰ª£ÁêÜÂú®‰∏çÁÜüÊÇâÁöÑÁí∞Â¢É‰∏≠Â∞éËà™Ôºå‰ª•ÊâæÂà∞ÂÖàÂâçÊú™Ë¶ãÁöÑÁâ©‰ª∂„ÄÇÈÄôÁ®Æ‰ª•ÁõÆÊ®ôÁÇ∫Â∞éÂêëÁöÑÊé¢Á¥¢Ê•µÂ∫¶‰æùË≥¥ÊÑüÁü•„ÄÅÁêÜËß£ÂíåÂü∫ÊñºÁí∞Â¢ÉÁ©∫ÈñìË≥áË®äÈÄ≤Ë°åÊé®ÁêÜÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÁï∂ÂâçÁöÑÂü∫Êñº LLM ÁöÑÊñπÊ≥ïÊúÉÂ∞áË¶ñË¶∫ËßÄÂØüËΩâÊèõÁÇ∫Ë™ûË®ÄÊèèËø∞Ôºå‰∏¶Âú®Ë™ûË®ÄÁ©∫Èñì‰∏≠ÈÄ≤Ë°åÊé®ÁêÜÔºåÂ∞éËá¥Á©∫ÈñìË≥áË®äÈÅ∫Â§±„ÄÇÂú®Êú¨ÁØáË´ñÊñá‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü TopV-NavÔºå‰∏ÄÁ®ÆÂü∫Êñº MLLM ÁöÑÊñπÊ≥ïÔºåÂÆÉÁõ¥Êé•Âú®ÂÖ∑ÊúâÂÆåÊï¥Á©∫ÈñìË≥áË®äÁöÑ‰øØË¶ñÂúñ‰∏≠ÈÄ≤Ë°åÊé®ÁêÜ„ÄÇÁÇ∫‰∫ÜÂú®‰øØË¶ñÂúñË¶ñËßí‰∏≠ÂÖÖÂàÜÁôºÊèÆ MLLM ÁöÑÁ©∫ÈñìÊé®ÁêÜÊΩõÂäõÔºåÊàëÂÄëÊèêÂá∫‰∫ÜËá™ÈÅ©ÊáâË¶ñË¶∫ÊèêÁ§∫ÁîüÊàê (AVPG) ÊñπÊ≥ïÔºå‰ª•Ëá™ÈÅ©ÊáâÂú∞Âª∫ÊßãË™ûÊÑèË±êÂØåÁöÑ‰øØË¶ñÂúñ„ÄÇÂÆÉ‰Ωø‰ª£ÁêÜËÉΩÂ§†Áõ¥Êé•Âà©Áî®‰øØË¶ñÂúñ‰∏≠ÂåÖÂê´ÁöÑÁ©∫ÈñìË≥áË®ä‰æÜÈÄ≤Ë°åÂæπÂ∫ïÁöÑÊé®ÁêÜ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂãïÊÖãÂú∞ÂúñÁ∏ÆÊîæ (DMS) Ê©üÂà∂Ôºå‰ª•Âú®È¶ñÈÅ∏ÊØî‰æãÂ∞∫ÂãïÊÖãÁ∏ÆÊîæ‰øØË¶ñÂúñÔºåÂ¢ûÂº∑Â±ÄÈÉ®Á¥∞Á≤íÂ∫¶ÁöÑÊé®ÁêÜ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÁõÆÊ®ôÂ∞éÂºïÂ∞éËà™ (TGN) Ê©üÂà∂Ôºå‰ª•È†êÊ∏¨ÂíåÂà©Áî®ÁõÆÊ®ô‰ΩçÁΩÆÔºå‰øÉÈÄ≤ÂÖ®Â±ÄÂíåÈ°û‰ºº‰∫∫È°ûÁöÑÊé¢Á¥¢„ÄÇÂú® MP3D Âíå HM3D Âü∫Ê∫ñ‰∏äÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÁöÑ TopV-Nav ÁöÑÂÑ™Ë∂äÊÄßÔºå‰æãÂ¶ÇÔºåÂú® HM3D ‰∏äÁöÑÁµïÂ∞çÊîπÈÄ≤ÁÇ∫ $+3.9\%$ SR Âíå $+2.0\%$ SPL„ÄÇ

##### **Turbofan Engine Remaining Useful Life (RUL) Prediction Based on Bi-Directional Long Short-Term Memory (BLSTM)**
2411.16422v1 by Abedin Sherifi

The aviation industry is rapidly evolving, driven by advancements in
technology. Turbofan engines used in commercial aerospace are very complex
systems. The majority of turbofan engine components are susceptible to
degradation over the life of their operation. Turbofan engine degradation has
an impact to engine performance, operability, and reliability. Predicting
accurate remaining useful life (RUL) of a commercial turbofan engine based on a
variety of complex sensor data is of paramount importance for the safety of the
passengers, safety of flight, and for cost effective operations. That is why it
is essential for turbofan engines to be monitored, controlled, and maintained.
RUL predictions can either come from model-based or data-based approaches. The
model-based approach can be very expensive due to the complexity of the
mathematical models and the deep expertise that is required in the domain of
physical systems. The data-based approach is more frequently used nowadays
thanks to the high computational complexity of computers, the advancements in
Machine Learning (ML) models, and advancements in sensors. This paper is going
to be focused on Bi-Directional Long Short-Term Memory (BLSTM) models but will
also provide a benchmark of several RUL prediction databased models. The
proposed RUL prediction models are going to be evaluated based on engine
failure prediction benchmark dataset Commercial Modular Aero-Propulsion System
Simulation (CMAPSS). The CMAPSS dataset is from NASA which contains turbofan
engine run to failure events.

ÊëòË¶ÅÔºöËà™Á©∫Áî¢Ê•≠Ê≠£Âø´ÈÄüÊºîÈÄ≤ÔºåÂÖ∂È©ÖÂãïÂäõÁÇ∫ÊäÄË°ìÈÄ≤Ê≠•„ÄÇÂïÜÁî®Ëà™Á©∫‰∏≠‰ΩøÁî®ÁöÑÊ∏¶ÊâáÁôºÂãïÊ©üÊòØÈùûÂ∏∏Ë§áÈõúÁöÑÁ≥ªÁµ±„ÄÇÊ∏¶ÊâáÁôºÂãïÊ©üÁµÑ‰ª∂ÁöÑÂ§ßÂ§öÊï∏Âú®‰ΩøÁî®Â£ΩÂëΩÊúüÈñìÂÆπÊòìÂä£Âåñ„ÄÇÊ∏¶ÊâáÁôºÂãïÊ©üÂä£ÂåñÊúÉÂΩ±ÈüøÁôºÂãïÊ©üÊïàËÉΩ„ÄÅÂèØÊìç‰ΩúÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÊ†πÊìöÂêÑÁ®ÆË§áÈõúÁöÑÊÑüÊ∏¨Âô®Ë≥áÊñôÈ†êÊ∏¨ÂïÜÁî®Ê∏¶ÊâáÁôºÂãïÊ©üÊ∫ñÁ¢∫ÁöÑÂâ©È§ò‰ΩøÁî®Â£ΩÂëΩ (RUL)ÔºåÂ∞çÊñº‰πòÂÆ¢ÂÆâÂÖ®„ÄÅÈ£õËà™ÂÆâÂÖ®ÂíåÊàêÊú¨ÊïàÁõäÁáüÈÅãËá≥ÈóúÈáçË¶Å„ÄÇÈÄô‰πüÊòØÊ∏¶ÊâáÁôºÂãïÊ©üÂøÖÈ†àÂèóÂà∞Áõ£Êéß„ÄÅÊéßÂà∂ÂíåÁ∂≠Ë≠∑ÁöÑÂéüÂõ†„ÄÇRUL È†êÊ∏¨ÂèØ‰ª•‰æÜËá™Âü∫ÊñºÊ®°ÂûãÊàñÂü∫ÊñºË≥áÊñôÁöÑÊñπÊ≥ï„ÄÇÂü∫ÊñºÊ®°ÂûãÁöÑÊñπÊ≥ïÁî±ÊñºÊï∏Â≠∏Ê®°ÂûãÁöÑË§áÈõúÊÄßÂíåÂú®Áâ©ÁêÜÁ≥ªÁµ±È†òÂüüÊâÄÈúÄÁöÑÊ∑±ÂéöÂ∞àÊ•≠Áü•Ë≠òÔºåÂèØËÉΩÈùûÂ∏∏ÊòÇË≤¥„ÄÇÂü∫ÊñºË≥áÊñôÁöÑÊñπÊ≥ïÁî±ÊñºÈõªËÖ¶ÁöÑÈ´òÈÅãÁÆóË§áÈõúÊÄß„ÄÅÊ©üÂô®Â≠∏Áøí (ML) Ê®°ÂûãÁöÑÈÄ≤Ê≠•ÂíåÊÑüÊ∏¨Âô®ÁöÑÈÄ≤Ê≠•ÔºåÁèæ‰ªä‰ΩøÁî®ÂæóÊõ¥È†ªÁπÅ„ÄÇÊú¨ÊñáÂ∞áÈáçÈªûÊîæÂú®ÈõôÂêëÈï∑Áü≠ÊúüË®òÊÜ∂ (BLSTM) Ê®°ÂûãÔºå‰ΩÜ‰πüÊúÉÊèê‰æõÂ§öÂÄã RUL È†êÊ∏¨Ë≥áÊñôÂ∫´Ê®°ÂûãÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶„ÄÇÊâÄÊèêÂá∫ÁöÑ RUL È†êÊ∏¨Ê®°ÂûãÂ∞áÊ†πÊìöÂºïÊìéÊïÖÈöúÈ†êÊ∏¨Âü∫Ê∫ñË≥áÊñôÈõÜÂïÜÊ•≠Ê®°ÁµÑËà™Á©∫Êé®ÈÄ≤Á≥ªÁµ±Ê®°Êì¨ (CMAPSS) ÈÄ≤Ë°åË©ï‰º∞„ÄÇCMAPSS Ë≥áÊñôÈõÜ‰æÜËá™ NASAÔºåÂÖ∂‰∏≠ÂåÖÂê´Ê∏¶ÊâáÁôºÂãïÊ©üÈÅãË°åËá≥ÊïÖÈöúÁöÑ‰∫ã‰ª∂„ÄÇ

##### **A Study on Unsupervised Domain Adaptation for Semantic Segmentation in the Era of Vision-Language Models**
2411.16407v1 by Manuel Schwonberg, Claus Werner, Hanno Gottschalk, Carsten Meyer

Despite the recent progress in deep learning based computer vision, domain
shifts are still one of the major challenges. Semantic segmentation for
autonomous driving faces a wide range of domain shifts, e.g. caused by changing
weather conditions, new geolocations and the frequent use of synthetic data in
model training. Unsupervised domain adaptation (UDA) methods have emerged which
adapt a model to a new target domain by only using unlabeled data of that
domain. The variety of UDA methods is large but all of them use ImageNet
pre-trained models. Recently, vision-language models have demonstrated strong
generalization capabilities which may facilitate domain adaptation. We show
that simply replacing the encoder of existing UDA methods like DACS by a
vision-language pre-trained encoder can result in significant performance
improvements of up to 10.0% mIoU on the GTA5-to-Cityscapes domain shift. For
the generalization performance to unseen domains, the newly employed
vision-language pre-trained encoder provides a gain of up to 13.7% mIoU across
three unseen datasets. However, we find that not all UDA methods can be easily
paired with the new encoder and that the UDA performance does not always
likewise transfer into generalization performance. Finally, we perform our
experiments on an adverse weather condition domain shift to further verify our
findings on a pure real-to-real domain shift.

ÊëòË¶ÅÔºöÂÑòÁÆ°Ê∑±Â∫¶Â≠∏ÁøíÂü∫Á§éÈõªËÖ¶Ë¶ñË¶∫ÊúâËøëÊúüÁöÑÈÄ≤Â±ïÔºåÈ†òÂüüËΩâÊèõ‰ªçÁÑ∂ÊòØ‰∏ªË¶ÅÊåëÊà∞‰πã‰∏Ä„ÄÇ
ÈáùÂ∞çËá™ÈßïËªäÁöÑË™ûÊÑèÂàÜÂâ≤Èù¢Ëá®Âª£Ê≥õÁöÑÈ†òÂüüËΩâÊèõÔºå‰æãÂ¶ÇÂõ†Â§©Ê∞£ÁãÄÊ≥ÅÊîπËÆä„ÄÅÊñ∞ÁöÑÂú∞ÁêÜ‰ΩçÁΩÆÂíåÊ®°ÂûãË®ìÁ∑¥‰∏≠È†ªÁπÅ‰ΩøÁî®ÂêàÊàêË≥áÊñôËÄåÈÄ†Êàê„ÄÇ
ÁÑ°Áõ£Áù£È†òÂüüÈÅ©Êáâ (UDA) ÊñπÊ≥ïÊáâÈÅãËÄåÁîüÔºåÈÄèÈÅéÂÉÖ‰ΩøÁî®Ë©≤È†òÂüüÁöÑÊú™Ê®ôÁ±§Ë≥áÊñôÂ∞áÊ®°ÂûãÈÅ©ÊáâÂà∞Êñ∞ÁöÑÁõÆÊ®ôÈ†òÂüü„ÄÇ
UDA ÊñπÊ≥ïÁ®ÆÈ°ûÁπÅÂ§öÔºå‰ΩÜÈÉΩ‰ΩøÁî® ImageNet È†êÂÖàË®ìÁ∑¥ÁöÑÊ®°Âûã„ÄÇ
ËøëÊúüÔºåË¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÂ∑≤Â±ïÁèæÂº∑Â§ßÁöÑÊ¶ÇÂåñËÉΩÂäõÔºåÈÄôÂèØËÉΩÊúâÂä©ÊñºÈ†òÂüüÈÅ©Êáâ„ÄÇ
ÊàëÂÄëÈ°ØÁ§∫ÔºåÂÉÖÈÄèÈÅéÂ∞á DACS Á≠âÁèæÊúâ UDA ÊñπÊ≥ïÁöÑÁ∑®Á¢ºÂô®ÊõøÊèõÁÇ∫Ë¶ñË¶∫Ë™ûË®ÄÈ†êÂÖàË®ìÁ∑¥ÁöÑÁ∑®Á¢ºÂô®ÔºåÂ∞±ËÉΩÈ°ØËëóÊèêÂçáÊïàËÉΩÔºåÂú® GTA5 Âà∞ Cityscapes È†òÂüüËΩâÊèõ‰∏≠ÊèêÂçáÈÅî 10.0% mIoU„ÄÇ
Â∞çÊñºÊú™Ë¶ãÈ†òÂüüÁöÑÊ¶ÇÂåñÊïàËÉΩÔºåÊñ∞Êé°Áî®ÁöÑË¶ñË¶∫Ë™ûË®ÄÈ†êÂÖàË®ìÁ∑¥ÁöÑÁ∑®Á¢ºÂô®Âú®‰∏âÂÄãÊú™Ë¶ãË≥áÊñôÈõÜ‰∏äÊèê‰æõ‰∫ÜÈ´òÈÅî 13.7% mIoU ÁöÑÂ¢ûÁõä„ÄÇ
ÁÑ∂ËÄåÔºåÊàëÂÄëÁôºÁèæ‰∏¶ÈùûÊâÄÊúâ UDA ÊñπÊ≥ïÈÉΩËÉΩËºïÊòìËàáÊñ∞Á∑®Á¢ºÂô®ÈÖçÂ∞çÔºåËÄå‰∏î UDA ÊïàËÉΩ‰∏¶ÈùûÁ∏ΩÊòØÂêåÊ®£ËΩâÁßªÂà∞Ê¶ÇÂåñÊïàËÉΩ„ÄÇ
ÊúÄÂæåÔºåÊàëÂÄëÂú®ÊÉ°Âä£Â§©Ê∞£Ê¢ù‰ª∂È†òÂüüËΩâÊèõ‰∏äÂü∑Ë°åÂØ¶È©óÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•È©óË≠âÊàëÂÄëÂú®Á¥îÁ≤πÁúüÂØ¶Âà∞ÁúüÂØ¶È†òÂüüËΩâÊèõ‰∏äÁöÑÁôºÁèæ„ÄÇ

##### **Synthesising Handwritten Music with GANs: A Comprehensive Evaluation of CycleWGAN, ProGAN, and DCGAN**
2411.16405v1 by Elona Shatri, Kalikidhar Palavala, George Fazekas

The generation of handwritten music sheets is a crucial step toward enhancing
Optical Music Recognition (OMR) systems, which rely on large and diverse
datasets for optimal performance. However, handwritten music sheets, often
found in archives, present challenges for digitisation due to their fragility,
varied handwriting styles, and image quality. This paper addresses the data
scarcity problem by applying Generative Adversarial Networks (GANs) to
synthesise realistic handwritten music sheets. We provide a comprehensive
evaluation of three GAN models - DCGAN, ProGAN, and CycleWGAN - comparing their
ability to generate diverse and high-quality handwritten music images. The
proposed CycleWGAN model, which enhances style transfer and training stability,
significantly outperforms DCGAN and ProGAN in both qualitative and quantitative
evaluations. CycleWGAN achieves superior performance, with an FID score of
41.87, an IS of 2.29, and a KID of 0.05, making it a promising solution for
improving OMR systems.

ÊëòË¶ÅÔºöÊâãÂØ´Ê®ÇË≠úÁöÑÁîüÊàêÊòØÊèêÂçáÂÖâÂ≠∏Èü≥Ê®ÇËæ®Ë≠ò (OMR) Á≥ªÁµ±ÁöÑÈóúÈçµÊ≠•È©üÔºåËÄå OMR Á≥ªÁµ±‰ª∞Ë≥¥ÈæêÂ§ß‰∏îÂ§öÂÖÉÁöÑË≥áÊñôÈõÜÊâçËÉΩÁôºÊèÆÊúÄ‰Ω≥ÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÊâãÂØ´Ê®ÇË≠úÈÄöÂ∏∏Â≠òÊîæÂú®Ê™îÊ°àÈ§®‰∏≠ÔºåÁî±ÊñºÂÖ∂ËÑÜÂº±ÊÄß„ÄÅÊõ∏ÂØ´È¢®Ê†ºÂ§öËÆäÔºå‰ª•ÂèäÂΩ±ÂÉèÂìÅË≥™‰∏ç‰Ω≥ÔºåÂõ†Ê≠§Âú®Êï∏‰ΩçÂåñÈÅéÁ®ã‰∏≠ÊúÉÈù¢Ëá®ÊåëÊà∞„ÄÇÊú¨ÊñáÈÄèÈÅéÊáâÁî®ÁîüÊàêÂ∞çÊäóÁ∂≤Ë∑Ø (GAN) ‰æÜÂêàÊàêÈÄºÁúüÁöÑÊâãÂØ´Ê®ÇË≠úÔºå‰ª•Ëß£Ê±∫Ë≥áÊñôÁ®ÄÂ∞ëÁöÑÂïèÈ°å„ÄÇÊàëÂÄëÊèê‰æõ‰∏âÁ®Æ GAN Ê®°ÂûãÁöÑÂÖ®Èù¢Ë©ï‰º∞ÔºåÂåÖÊã¨ DCGAN„ÄÅProGAN Âíå CycleWGANÔºå‰∏¶ÊØîËºÉÂÆÉÂÄëÁîüÊàêÂ§öÊ®£Âåñ‰∏îÈ´òÂìÅË≥™ÊâãÂØ´Ê®ÇË≠úÂΩ±ÂÉèÁöÑËÉΩÂäõ„ÄÇÊâÄÊèêÂá∫ÁöÑ CycleWGAN Ê®°ÂûãÂ¢ûÂº∑‰∫ÜÊ®£ÂºèËΩâÁßªÂíåË®ìÁ∑¥Á©©ÂÆöÊÄßÔºåÂú®ÂÆöÊÄßÂíåÂÆöÈáèË©ï‰º∞‰∏≠ÈÉΩÊòéÈ°ØÂÑ™Êñº DCGAN Âíå ProGAN„ÄÇCycleWGAN ÈÅîÂà∞ÂÑ™Áï∞ÁöÑÊïàËÉΩÔºåFID ÂàÜÊï∏ÁÇ∫ 41.87ÔºåIS ÁÇ∫ 2.29ÔºåKID ÁÇ∫ 0.05Ôºå‰ΩøÂÖ∂ÊàêÁÇ∫ÊîπÂñÑ OMR Á≥ªÁµ±ÁöÑÊΩõÂú®Ëß£Ê±∫ÊñπÊ°à„ÄÇ

##### **Adapter-based Approaches to Knowledge-enhanced Language Models -- A Survey**
2411.16403v1 by Alexander Fichtl, Juraj Vladika, Georg Groh

Knowledge-enhanced language models (KELMs) have emerged as promising tools to
bridge the gap between large-scale language models and domain-specific
knowledge. KELMs can achieve higher factual accuracy and mitigate
hallucinations by leveraging knowledge graphs (KGs). They are frequently
combined with adapter modules to reduce the computational load and risk of
catastrophic forgetting. In this paper, we conduct a systematic literature
review (SLR) on adapter-based approaches to KELMs. We provide a structured
overview of existing methodologies in the field through quantitative and
qualitative analysis and explore the strengths and potential shortcomings of
individual approaches. We show that general knowledge and domain-specific
approaches have been frequently explored along with various adapter
architectures and downstream tasks. We particularly focused on the popular
biomedical domain, where we provided an insightful performance comparison of
existing KELMs. We outline the main trends and propose promising future
directions.

ÊëòË¶ÅÔºöÁü•Ë≠òÂ¢ûÂº∑Ë™ûË®ÄÊ®°ÂûãÔºàKELMÔºâÂ∑≤ÊàêÁÇ∫ÂΩåÂêàÂ§ßË¶èÊ®°Ë™ûË®ÄÊ®°ÂûãËàáÁâπÂÆöÈ†òÂüüÁü•Ë≠òÂ∑ÆË∑ùÁöÑÊúâÂâçÈÄîÁöÑÂ∑•ÂÖ∑„ÄÇKELM ÂèØ‰ª•ÈÄèÈÅéÂà©Áî®Áü•Ë≠òÂúñË≠úÔºàKGÔºâ‰æÜÊèêÈ´ò‰∫ãÂØ¶Ê∫ñÁ¢∫ÊÄß‰∏¶Ê∏õÂ∞ëÂπªË¶∫„ÄÇÂÆÉÂÄëÁ∂ìÂ∏∏ËàáÈÅ©ÈÖçÂô®Ê®°ÁµÑÁµêÂêà‰ΩøÁî®Ôºå‰ª•Èôç‰ΩéÈÅãÁÆóË≤†ËºâÂíåÁÅΩÈõ£ÊÄßÈÅ∫ÂøòÁöÑÈ¢®Èö™„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞çÂü∫ÊñºÈÅ©ÈÖçÂô®ÁöÑ KELM ÊñπÊ≥ïÈÄ≤Ë°åÁ≥ªÁµ±ÊÄßÁöÑÊñáÁçªÂõûÈ°ßÔºàSLRÔºâ„ÄÇÊàëÂÄëÈÄèÈÅéÂÆöÈáèÂíåÂÆöÊÄßÂàÜÊûêÊèê‰æõË©≤È†òÂüüÊó¢ÊúâÊñπÊ≥ïË´ñÁöÑÁµêÊßãÂåñÊ¶ÇËßÄÔºå‰∏¶Êé¢Ë®éÂÄãÂà•ÊñπÊ≥ïÁöÑÂÑ™ÈªûÂíåÊΩõÂú®Áº∫Èªû„ÄÇÊàëÂÄëË°®ÊòéÔºå‰∏ÄËà¨Áü•Ë≠òÂíåÁâπÂÆöÈ†òÂüüÁöÑÊñπÊ≥ïÂ∑≤ËàáÂêÑÁ®ÆÈÅ©ÈÖçÂô®Êû∂ÊßãÂíå‰∏ãÊ∏∏‰ªªÂãô‰∏ÄËµ∑Ë¢´È†ªÁπÅÊé¢Á¥¢„ÄÇÊàëÂÄëÁâπÂà•ÈóúÊ≥®ÁÜ±ÈñÄÁöÑÁîüÁâ©ÈÜ´Â≠∏È†òÂüüÔºåÂú®Ë©≤È†òÂüü‰∏≠ÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÁèæÊúâ KELM ÁöÑÊúâË¶ãÂú∞ÊïàËÉΩÊØîËºÉ„ÄÇÊàëÂÄëÊ¶ÇËø∞‰∫Ü‰∏ªË¶ÅË∂®Âã¢Ôºå‰∏¶ÊèêÂá∫‰∫ÜÊúâÂâçÈÄîÁöÑÊú™‰æÜÊñπÂêë„ÄÇ

##### **Human-Calibrated Automated Testing and Validation of Generative Language Models**
2411.16391v1 by Agus Sudjianto, Aijun Zhang, Srinivas Neppalli, Tarun Joshi, Michal Malohlava

This paper introduces a comprehensive framework for the evaluation and
validation of generative language models (GLMs), with a focus on
Retrieval-Augmented Generation (RAG) systems deployed in high-stakes domains
such as banking. GLM evaluation is challenging due to open-ended outputs and
subjective quality assessments. Leveraging the structured nature of RAG
systems, where generated responses are grounded in a predefined document
collection, we propose the Human-Calibrated Automated Testing (HCAT) framework.
HCAT integrates a) automated test generation using stratified sampling, b)
embedding-based metrics for explainable assessment of functionality, risk and
safety attributes, and c) a two-stage calibration approach that aligns
machine-generated evaluations with human judgments through probability
calibration and conformal prediction.
  In addition, the framework includes robustness testing to evaluate model
performance against adversarial, out-of-distribution, and varied input
conditions, as well as targeted weakness identification using marginal and
bivariate analysis to pinpoint specific areas for improvement. This
human-calibrated, multi-layered evaluation framework offers a scalable,
transparent, and interpretable approach to GLM assessment, providing a
practical and reliable solution for deploying GLMs in applications where
accuracy, transparency, and regulatory compliance are paramount.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÊû∂ÊßãÔºåÁî®ÊñºË©ï‰º∞ÂíåÈ©óË≠âÁîüÊàêË™ûË®ÄÊ®°Âûã (GLM)ÔºåÈáçÈªûÂú®ÊñºÈÉ®ÁΩ≤Âú®È´òÈ¢®Èö™È†òÂüüÔºà‰æãÂ¶ÇÈäÄË°åÊ•≠ÔºâÁöÑÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) Á≥ªÁµ±„ÄÇÁî±ÊñºËº∏Âá∫ÈñãÊîæÂºè‰∏îÂìÅË≥™Ë©ï‰º∞‰∏ªËßÄÔºåÂõ†Ê≠§ GLM Ë©ï‰º∞ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊàëÂÄëÂà©Áî® RAG Á≥ªÁµ±ÁöÑÁµêÊßãÂåñÁâπÊÄßÔºåÂÖ∂‰∏≠ÁîüÊàêÁöÑÂõûÊáâÂª∫Á´ãÂú®È†êÂÖàÂÆöÁæ©ÁöÑÊñá‰ª∂ÈõÜÂêà‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∫∫Ê©üÊ†°Ê∫ñËá™ÂãïÂåñÊ∏¨Ë©¶ (HCAT) Êû∂Êßã„ÄÇHCAT Êï¥Âêà‰∫Ü a) ‰ΩøÁî®ÂàÜÂ±§ÊäΩÊ®£ÈÄ≤Ë°åËá™ÂãïÂåñÊ∏¨Ë©¶Áî¢ÁîüÔºåb) Âü∫ÊñºÂµåÂÖ•ÁöÑÊåáÊ®ôÔºåÁî®ÊñºÂ∞çÂäüËÉΩ„ÄÅÈ¢®Èö™ÂíåÂÆâÂÖ®ÊÄßÂ±¨ÊÄßÈÄ≤Ë°åÂèØËß£ÈáãÁöÑË©ï‰º∞Ôºå‰ª•Âèä c) ‰∏ÄÂÄãÂÖ©ÈöéÊÆµÊ†°Ê∫ñÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÈÄèÈÅéÊ©üÁéáÊ†°Ê∫ñÂíåÂÖ±ÂΩ¢È†êÊ∏¨ÔºåÂ∞áÊ©üÂô®Áî¢ÁîüÁöÑË©ï‰º∞Ëàá‰∫∫È°ûÂà§Êñ∑Áõ∏Á¨¶„ÄÇÊ≠§Â§ñÔºåË©≤Êû∂ÊßãÂåÖÊã¨Á©©ÂÅ•ÊÄßÊ∏¨Ë©¶ÔºåÁî®ÊñºË©ï‰º∞Ê®°ÂûãÈáùÂ∞çÂ∞çÊäóÊÄß„ÄÅÂàÜÂ∏ÉÂ§ñÂíåËÆäÁï∞Ëº∏ÂÖ•Ê¢ù‰ª∂ÁöÑÊïàËÉΩÔºå‰ª•Âèä‰ΩøÁî®ÈÇäÈöõÂíå‰∫åËÆäÈáèÂàÜÊûê‰æÜÊâæÂá∫ÁâπÂÆöÊîπÈÄ≤È†òÂüüÁöÑÁõÆÊ®ôÂº±ÈªûË≠òÂà•„ÄÇÈÄôÂÄã‰∫∫Ê©üÊ†°Ê∫ñ„ÄÅÂ§öÂ±§Ë©ï‰º∞Êû∂ÊßãÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØÊì¥ÂÖÖ„ÄÅÈÄèÊòé‰∏îÂèØËß£ÈáãÁöÑÊñπÊ≥ï‰æÜÈÄ≤Ë°å GLM Ë©ï‰º∞ÔºåÁÇ∫Âú®Ê∫ñÁ¢∫ÊÄß„ÄÅÈÄèÊòéÊÄßÂíåÊ≥ïË¶èÈÅµÂæ™Ëá≥‰∏äÁöÑÊáâÁî®Á®ãÂºè‰∏≠ÈÉ®ÁΩ≤ GLM Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂØ¶Áî®‰∏îÂèØÈù†ÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **FineWeb-zhtw: Scalable Curation of Traditional Chinese Text Data from the Web**
2411.16387v1 by Cheng-Wei Lin, Wan-Hsuan Hsieh, Kai-Xin Guan, Chan-Jan Hsu, Chia-Chen Kuo, Chuan-Lin Lai, Chung-Wei Chung, Ming-Jen Wang, Da-Shan Shiu

The quality and size of a pretraining dataset significantly influence the
performance of large language models (LLMs). While there have been numerous
efforts in the curation of such a dataset for English users, there is a
relative lack of similar initiatives for Traditional Chinese. Building upon
this foundation of FineWeb, we introduce FineWeb-zhtw, a dataset tailored
specifically for Traditional Chinese users. We came up with multiple stages of
meticulously designed filters to cater to the linguistic difference between
English and Traditional Chinese, to ensure comprehensiveness and quality. We
determined effectiveness from querying dataset samples with three main
objectives. Our code and datasets are publicly available.

ÊëòË¶ÅÔºöÈ†êË®ìÁ∑¥Ë≥áÊñôÈõÜÁöÑÂìÅË≥™ÂíåË¶èÊ®°ÊúÉÈ°ØËëóÂΩ±ÈüøÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊïàËÉΩ„ÄÇÈõñÁÑ∂Â∑≤Á∂ìÊúâË®±Â§öÈáùÂ∞çËã±Ë™û‰ΩøÁî®ËÄÖÁöÑÊ≠§È°ûË≥áÊñôÈõÜÁ≠ñÂ±ïÂ∑•‰ΩúÔºå‰ΩÜÈáùÂ∞çÁπÅÈ´î‰∏≠ÊñáÁöÑÈ°û‰ººË®àÁï´ÂçªÁõ∏Â∞çÁº∫‰πè„ÄÇÂú® FineWeb ÁöÑÂü∫Á§é‰∏äÔºåÊàëÂÄëÊé®Âá∫‰∫Ü FineWeb-zhtwÔºåÈÄôÊòØ‰∏ÄÂÄãÂ∞àÁÇ∫ÁπÅÈ´î‰∏≠Êñá‰ΩøÁî®ËÄÖÈáèË∫´ÊâìÈÄ†ÁöÑË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÊèêÂá∫‰∫ÜÂ§öÂÄãÈöéÊÆµÁöÑÁ≤æÁ¥∞Ë®≠Ë®àÈÅéÊøæÂô®Ôºå‰ª•ÊáâÂ∞çËã±Ë™ûÂíåÁπÅÈ´î‰∏≠Êñá‰πãÈñìÁöÑË™ûË®ÄÂ∑ÆÁï∞Ôºå‰ª•Á¢∫‰øùË≥áÊñôÁöÑÂÖ®Èù¢ÊÄßÂíåÂìÅË≥™„ÄÇÊàëÂÄëÈÄèÈÅé‰ª•‰∏âÂÄã‰∏ªË¶ÅÁõÆÊ®ôÊü•Ë©¢Ë≥áÊñôÈõÜÊ®£Êú¨‰æÜÁ¢∫ÂÆöÂÖ∂ÊúâÊïàÊÄß„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜÂÖ¨ÈñãÊèê‰æõ„ÄÇ

##### **Privacy-Preserving Federated Foundation Model for Generalist Ultrasound Artificial Intelligence**
2411.16380v1 by Yuncheng Jiang, Chun-Mei Feng, Jinke Ren, Jun Wei, Zixun Zhang, Yiwen Hu, Yunbi Liu, Rui Sun, Xuemei Tang, Juan Du, Xiang Wan, Yong Xu, Bo Du, Xin Gao, Guangyu Wang, Shaohua Zhou, Shuguang Cui, Rick Siow Mong Goh, Yong Liu, Zhen Li

Ultrasound imaging is widely used in clinical diagnosis due to its
non-invasive nature and real-time capabilities. However, conventional
ultrasound diagnostics face several limitations, including high dependence on
physician expertise and suboptimal image quality, which complicates
interpretation and increases the likelihood of diagnostic errors. Artificial
intelligence (AI) has emerged as a promising solution to enhance clinical
diagnosis, particularly in detecting abnormalities across various biomedical
imaging modalities. Nonetheless, current AI models for ultrasound imaging face
critical challenges. First, these models often require large volumes of labeled
medical data, raising concerns over patient privacy breaches. Second, most
existing models are task-specific, which restricts their broader clinical
utility. To overcome these challenges, we present UltraFedFM, an innovative
privacy-preserving ultrasound foundation model. UltraFedFM is collaboratively
pre-trained using federated learning across 16 distributed medical institutions
in 9 countries, leveraging a dataset of over 1 million ultrasound images
covering 19 organs and 10 ultrasound modalities. This extensive and diverse
data, combined with a secure training framework, enables UltraFedFM to exhibit
strong generalization and diagnostic capabilities. It achieves an average area
under the receiver operating characteristic curve of 0.927 for disease
diagnosis and a dice similarity coefficient of 0.878 for lesion segmentation.
Notably, UltraFedFM surpasses the diagnostic accuracy of mid-level
ultrasonographers and matches the performance of expert-level sonographers in
the joint diagnosis of 8 common systemic diseases. These findings indicate that
UltraFedFM can significantly enhance clinical diagnostics while safeguarding
patient privacy, marking an advancement in AI-driven ultrasound imaging for
future clinical applications.

ÊëòË¶ÅÔºöË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÂõ†ÂÖ∂Èùû‰æµÂÖ•ÊÄßËàáÂç≥ÊôÇÊÄßÂª£Ê≥õÊáâÁî®ÊñºËá®Â∫äË®∫Êñ∑„ÄÇÁÑ∂ËÄåÔºåÂÇ≥Áµ±Ë∂ÖÈü≥Ê≥¢Ë®∫Êñ∑Èù¢Ëá®Êï∏È†ÖÈôêÂà∂ÔºåÂåÖÊã¨È´òÂ∫¶‰æùË≥¥ÈÜ´Â∏´Â∞àÊ•≠Áü•Ë≠òÂíåÊ¨°‰Ω≥ÂΩ±ÂÉèÂìÅË≥™ÔºåÈÄô‰ΩøÂæóÂΩ±ÂÉèÂà§ËÆÄÊõ¥ÁÇ∫Ë§áÈõúÔºå‰∏¶Â¢ûÂä†Ë®∫Êñ∑ÈåØË™§ÁöÑÂèØËÉΩÊÄß„ÄÇ‰∫∫Â∑•Êô∫ÊÖß (AI) Â∑≤ÊàêÁÇ∫Â¢ûÂº∑Ëá®Â∫äË®∫Êñ∑ÁöÑÊΩõÂú®Ëß£Ê±∫ÊñπÊ°àÔºåÁâπÂà•ÊòØÂú®ÂÅµÊ∏¨ÂêÑÁ®ÆÁîüÁâ©ÈÜ´Â≠∏ÂΩ±ÂÉèÊ®°Âºè‰∏≠ÁöÑÁï∞Â∏∏„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÁõÆÂâçÁî®ÊñºË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÁöÑ AI Ê®°ÂûãÈù¢Ëá®Âö¥Â≥ªÊåëÊà∞„ÄÇÈ¶ñÂÖàÔºåÈÄô‰∫õÊ®°ÂûãÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÁöÑÊ®ôÁ±§ÈÜ´Â≠∏Ë≥áÊñôÔºåÈÄôÂºïÁôº‰∫ÜÂ∞çÁóÖÊÇ£Èö±ÁßÅÈÅ≠‰æµÁäØÁöÑÁñëÊÖÆ„ÄÇÂÖ∂Ê¨°ÔºåÁèæÊúâÁöÑÂ§ßÈÉ®ÂàÜÊ®°ÂûãÈÉΩÊòØÈáùÂ∞çÁâπÂÆö‰ªªÂãôËÄåË®≠Ë®àÔºåÈÄôÈôêÂà∂‰∫ÜÂÆÉÂÄëÂú®Êõ¥Âª£Ê≥õÁöÑËá®Â∫äÊáâÁî®„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü UltraFedFMÔºå‰∏ÄÂÄãÂâµÊñ∞ÁöÑÈö±ÁßÅ‰øùË≠∑Ë∂ÖÈü≥Ê≥¢Âü∫Á§éÊ®°Âûã„ÄÇUltraFedFM ÈÄèÈÅé 9 ÂÄãÂúãÂÆ∂/Âú∞ÂçÄÁöÑ 16 ÂÄãÂàÜÊï£ÂºèÈÜ´ÁôÇÊ©üÊßãÁöÑËÅØÂêàÂ≠∏ÁøíÈÄ≤Ë°åÂçî‰ΩúÈ†êË®ìÁ∑¥ÔºåÂà©Áî®ÂåÖÂê´Ë∂ÖÈÅé 100 Ëê¨ÂºµË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÁöÑË≥áÊñôÈõÜÔºåÊ∂µËìã 19 ÂÄãÂô®ÂÆòÂíå 10 Á®ÆË∂ÖÈü≥Ê≥¢Ê®°Âºè„ÄÇÈÄô‰∫õÂª£Ê≥õ‰∏îÂ§öÊ®£ÂåñÁöÑË≥áÊñôÔºåÁµêÂêàÂÆâÂÖ®ÁöÑË®ìÁ∑¥Êû∂ÊßãÔºå‰Ωø UltraFedFM ËÉΩÂ§†Â±ïÁèæÂº∑Â§ßÁöÑÊ¶ÇÂåñÂíåË®∫Êñ∑ËÉΩÂäõ„ÄÇÂú®ÁñæÁóÖË®∫Êñ∑ÊñπÈù¢ÔºåÂÖ∂ÂèóË©¶ËÄÖÂ∑•‰ΩúÁâπÂæµÊõ≤Á∑ö‰∏ãÁöÑÂπ≥ÂùáÈù¢Á©çÈÅîÂà∞ 0.927ÔºåÂú®ÁóÖÁÅ∂ÂàÜÂâ≤ÊñπÈù¢ÔºåÂÖ∂ Dice Áõ∏‰ºº‰øÇÊï∏ÁÇ∫ 0.878„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåUltraFedFM Ë∂ÖË∂ä‰∫Ü‰∏≠ÈöéË∂ÖÈü≥Ê≥¢Ê™¢Êü•Âì°ÁöÑË®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÔºå‰∏¶Âú® 8 Á®ÆÂ∏∏Ë¶ãÂÖ®Ë∫´ÊÄßÁñæÁóÖÁöÑËÅØÂêàË®∫Êñ∑‰∏≠ÈÅîÂà∞Â∞àÂÆ∂Á¥öË∂ÖÈü≥Ê≥¢Ê™¢Êü•Âì°ÁöÑÊ∞¥Ê∫ñ„ÄÇÈÄô‰∫õÁôºÁèæË°®ÊòéÔºåUltraFedFM ÂèØ‰ª•È°ØËëóÂ¢ûÂº∑Ëá®Â∫äË®∫Êñ∑ÔºåÂêåÊôÇ‰øùË≠∑ÁóÖÊÇ£Èö±ÁßÅÔºåÈÄôÊ®ôË™åËëó AI È©ÖÂãïË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÂú®Êú™‰æÜËá®Â∫äÊáâÁî®‰∏≠ÁöÑ‰∏ÄÈ†ÖÈÄ≤Ê≠•„ÄÇ

##### **A Review of Bayesian Uncertainty Quantification in Deep Probabilistic Image Segmentation**
2411.16370v1 by M. M. A. Valiuddin, R. J. G. van Sloun, C. G. A. Viviers, P. H. N. de With, F. van der Sommen

Advancements in image segmentation play an integral role within the greater
scope of Deep Learning-based computer vision. Furthermore, their widespread
applicability in critical real-world tasks has given rise to challenges related
to the reliability of such algorithms. Hence, uncertainty quantification has
been extensively studied within this context, enabling expression of model
ignorance (epistemic uncertainty) or data ambiguity (aleatoric uncertainty) to
prevent uninformed decision making. Due to the rapid adoption of Convolutional
Neural Network (CNN)-based segmentation models in high-stake applications, a
substantial body of research has been published on this very topic, causing its
swift expansion into a distinct field. This work provides a comprehensive
overview of probabilistic segmentation by discussing fundamental concepts in
uncertainty that govern advancements in the field as well as the application to
various tasks. We identify that quantifying aleatoric and epistemic uncertainty
approximates Bayesian inference w.r.t. to either latent variables or model
parameters, respectively. Moreover, literature on both uncertainties trace back
to four key applications; (1) to quantify statistical inconsistencies in the
annotation process due ambiguous images, (2) correlating prediction error with
uncertainty, (3) expanding the model hypothesis space for better
generalization, and (4) active learning. Then, a discussion follows that
includes an overview of utilized datasets for each of the applications and
comparison of the available methods. We also highlight challenges related to
architectures, uncertainty-based active learning, standardization and
benchmarking, and recommendations for future work such as methods based on
single forward passes and models that appropriately leverage volumetric data.

ÊëòË¶ÅÔºöÂΩ±ÂÉèÂàÜÂâ≤ÁöÑÈÄ≤Â±ïÂú®Ê∑±Â∫¶Â≠∏ÁøíÁÇ∫Âü∫Á§éÁöÑÈõªËÖ¶Ë¶ñË¶∫‰∏≠ÊâÆÊºîËëó‰∏çÂèØÊàñÁº∫ÁöÑËßíËâ≤„ÄÇÊ≠§Â§ñÔºåÂÆÉÂÄëÂú®ÈóúÈçµÁèæÂØ¶‰∏ñÁïå‰ªªÂãô‰∏≠Âª£Ê≥õÁöÑÈÅ©Áî®ÊÄßÔºå‰πüÂ∏∂‰æÜ‰∫ÜËàáÊ≠§È°ûÊºîÁÆóÊ≥ïÂèØÈù†ÊÄßÁõ∏ÈóúÁöÑÊåëÊà∞„ÄÇÂõ†Ê≠§Ôºå‰∏çÁ¢∫ÂÆöÊÄßÈáèÂåñÂ∑≤Âú®ÈÄôÂÄãËÑàÁµ°‰∏≠Âª£Ê≥õÂú∞Á†îÁ©∂ÔºåËÆìÊ®°ÂûãÁÑ°Áü•ÔºàË™çË≠ò‰∏çÁ¢∫ÂÆöÊÄßÔºâÊàñË≥áÊñôÊ®°Á≥äÊÄßÔºàÈö®Ê©ü‰∏çÁ¢∫ÂÆöÊÄßÔºâÂæó‰ª•Ë°®ÈÅîÔºå‰ª•Èò≤Ê≠¢Êú™Á∂ìÂëäÁü•ÁöÑÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÁî±ÊñºÂü∫ÊñºÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÁöÑÂàÜÂâ≤Ê®°ÂûãÂú®È´òÈ¢®Èö™ÊáâÁî®‰∏≠Âø´ÈÄüÊé°Áî®ÔºåÂ§ßÈáèÁöÑÁ†îÁ©∂Â∑≤ÁôºË°®ÊñºÈÄôÂÄã‰∏ªÈ°å‰∏äÔºåÂ∞éËá¥ÂÖ∂ËøÖÈÄüÊì¥Â±ïÊàê‰∏ÄÂÄã‰∏çÂêåÁöÑÈ†òÂüü„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÈÄèÈÅéË®éË´ñ‰∏çÁ¢∫ÂÆöÊÄßÁöÑÂü∫Êú¨Ê¶ÇÂøµÔºå‰ª•ÂèäÂú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠ÁöÑÊáâÁî®ÔºåÊèê‰æõ‰∫ÜÊ©üÁéáÂàÜÂâ≤ÁöÑÂÖ®Èù¢Ê¶ÇËßÄÔºåÈÄô‰∫õÊ¶ÇÂøµÊîØÈÖç‰∫ÜË©≤È†òÂüüÁöÑÈÄ≤Â±ï„ÄÇÊàëÂÄëÁôºÁèæÈáèÂåñÈö®Ê©üÂíåË™çË≠ò‰∏çÁ¢∫ÂÆöÊÄßËøë‰ººÊñºË≤ùÊ∞èÊé®Ë´ñÔºåÂàÜÂà•ÈáùÂ∞çÊΩõÂú®ËÆäÊï∏ÊàñÊ®°ÂûãÂèÉÊï∏„ÄÇÊ≠§Â§ñÔºåÈóúÊñºÈÄôÂÖ©Á®Æ‰∏çÁ¢∫ÂÆöÊÄßÁöÑÊñáÁçªÂèØËøΩÊ∫ØÂà∞ÂõõÂÄãÈóúÈçµÊáâÁî®Ôºö(1) ÈáèÂåñÊ®ôË®ªÈÅéÁ®ã‰∏≠Áî±ÊñºÊ®°Á≥äÂΩ±ÂÉèËÄåÁî¢ÁîüÁöÑÁµ±Ë®à‰∏ç‰∏ÄËá¥ÊÄßÔºå(2) Â∞áÈ†êÊ∏¨Ë™§Â∑ÆËàá‰∏çÁ¢∫ÂÆöÊÄßÁõ∏ÈóúËÅØÔºå(3) Êì¥Â±ïÊ®°ÂûãÂÅáË®≠Á©∫Èñì‰ª•Áç≤ÂæóÊõ¥Â•ΩÁöÑÊ¶ÇÊã¨ÂåñÔºå‰ª•Âèä (4) ‰∏ªÂãïÂ≠∏Áøí„ÄÇÊé•ËëóÔºåË®éË´ñÂåÖÊã¨Â∞çÊØèÂÄãÊáâÁî®ÊâÄ‰ΩøÁî®ÁöÑË≥áÊñôÈõÜÁöÑÊ¶ÇËßÄÔºå‰ª•ÂèäÂèØÁî®ÊñπÊ≥ïÁöÑÊØîËºÉ„ÄÇÊàëÂÄë‰πüÂº∑Ë™øËàáÊû∂Êßã„ÄÅÂü∫Êñº‰∏çÁ¢∫ÂÆöÊÄßÁöÑ‰∏ªÂãïÂ≠∏Áøí„ÄÅÊ®ôÊ∫ñÂåñÂíåÂü∫Ê∫ñÊ∏¨Ë©¶Áõ∏ÈóúÁöÑÊåëÊà∞Ôºå‰ª•ÂèäÂ∞çÊú™‰æÜÂ∑•‰ΩúÁöÑÂª∫Ë≠∞Ôºå‰æãÂ¶ÇÂü∫ÊñºÂñÆÊ¨°ÂâçÂêëÂÇ≥ÈÅûÂíåÈÅ©Áï∂Âú∞Âà©Áî®È´îÁ©çË≥áÊñôÁöÑÊ®°Âûã„ÄÇ

##### **Multi-modal Retrieval Augmented Multi-modal Generation: A Benchmark, Evaluate Metrics and Strong Baselines**
2411.16365v1 by Zi-Ao Ma, Tian Lan, Rong-Cheng Tu, Yong Hu, Heyan Huang, Xian-Ling Mao

This paper investigates an intriguing task of Multi-modal Retrieval Augmented
Multi-modal Generation (M$^2$RAG). This task requires foundation models to
browse multi-modal web pages, with mixed text and images, and generate
multi-modal responses for solving user queries, which exhibits better
information density and readability. Given the early researching stage of
M$^2$RAG task, there is a lack of systematic studies and analysis. To fill this
gap, we construct a benchmark for M$^2$RAG task, equipped with a suite of
text-modal metrics and multi-modal metrics to analyze the capabilities of
existing foundation models. Besides, we also propose several effective methods
for foundation models to accomplish this task, based on the comprehensive
evaluation results on our benchmark. Extensive experimental results reveal
several intriguing phenomena worth further research.

ÊëòË¶ÅÔºöÊú¨ÊñáÊé¢Ë®é‰∫Ü‰∏ÄÈ†ÖÂºï‰∫∫ÂÖ•ÂãùÁöÑÂ§öÊ®°ÊÖãÊ™¢Á¥¢Â¢ûÂº∑Â§öÊ®°ÊÖãÁîüÊàê (M$^2$RAG) ‰ªªÂãô„ÄÇÊ≠§‰ªªÂãôË¶ÅÊ±ÇÂü∫Á§éÊ®°ÂûãÁÄèË¶ΩÂåÖÂê´ÊñáÂ≠óÂíåÂúñÁâáÁöÑÊ∑∑ÂêàÂ§öÊ®°ÊÖãÁ∂≤È†ÅÔºå‰∏¶ÈáùÂ∞ç‰ΩøÁî®ËÄÖÊü•Ë©¢Áî¢ÁîüÂ§öÊ®°ÊÖãÂõûÊáâÔºå‰ª•Â±ïÁèæÊõ¥Â•ΩÁöÑË≥áË®äÂØÜÂ∫¶ÂíåÂèØËÆÄÊÄß„ÄÇËÄÉÈáèÂà∞ M$^2$RAG ‰ªªÂãô‰ªçËôïÊñºÊó©ÊúüÁ†îÁ©∂ÈöéÊÆµÔºåÂõ†Ê≠§Áº∫‰πèÁ≥ªÁµ±ÊÄßÁöÑÁ†îÁ©∂ÂíåÂàÜÊûê„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÊ≠§‰∏ÄÁ©∫ÁôΩÔºåÊàëÂÄëÂª∫Êßã‰∫Ü‰∏ÄÂÄã M$^2$RAG ‰ªªÂãôÂü∫Ê∫ñÔºå‰∏¶ÈÖçÂÇô‰∏ÄÁµÑÊñáÂ≠óÊ®°ÊÖãÊåáÊ®ôÂíåÂ§öÊ®°ÊÖãÊåáÊ®ôÔºå‰ª•ÂàÜÊûêÁèæÊúâÂü∫Á§éÊ®°ÂûãÁöÑËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄë‰πüÈáùÂ∞çÂü∫Á§éÊ®°ÂûãÊèêÂá∫ÂπæÁ®ÆÊúâÊïàÁöÑÊñπÊ≥ï‰æÜÂÆåÊàêÊ≠§‰ªªÂãôÔºåÈÄô‰∫õÊñπÊ≥ïÊòØÊ†πÊìöÊàëÂÄëÂü∫Ê∫ñ‰∏äÁöÑÁ∂úÂêàË©ï‰º∞ÁµêÊûúËÄåÂæó„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÁµêÊûúÊè≠Èú≤‰∫ÜÂπæÂÄãÂÄºÂæóÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂ÁöÑÊúâË∂£ÁèæË±°„ÄÇ

##### **Graph Neural Networks-based Parameter Design towards Large-Scale Superconducting Quantum Circuits for Crosstalk Mitigation**
2411.16354v1 by Hao Ai, Yu-xi Liu

To demonstrate supremacy of quantum computing, increasingly large-scale
superconducting quantum computing chips are being designed and fabricated,
sparking the demand for electronic design automation in pursuit of better
efficiency and effectiveness. However, the complexity of simulating quantum
systems poses a significant challenge to computer-aided design of quantum
chips. Harnessing the scalability of graph neural networks (GNNs), we here
propose a parameter designing algorithm for large-scale superconducting quantum
circuits. The algorithm depends on the so-called 'three-stair scaling'
mechanism, which comprises two neural-network models: an evaluator supervisedly
trained on small-scale circuits for applying to medium-scale circuits, and a
designer unsupervisedly trained on medium-scale circuits for applying to
large-scale ones. We demonstrate our algorithm in mitigating quantum crosstalk
errors, which are commonly present and closely related to the graph structures
and parameter assignments of superconducting quantum circuits. Parameters for
both single- and two-qubit gates are considered simultaneously. Numerical
results indicate that the well-trained designer achieves notable advantages not
only in efficiency but also in effectiveness, especially for large-scale
circuits. For example, in superconducting quantum circuits consisting of around
870 qubits, the trained designer requires only 27 seconds to complete the
frequency designing task which necessitates 90 minutes for the traditional
Snake algorithm. More importantly, the crosstalk errors using our algorithm are
only 51% of those produced by the Snake algorithm. Overall, this study
initially demonstrates the advantages of applying graph neural networks to
design parameters in quantum processors, and provides insights for systems
where large-scale numerical simulations are challenging in electronic design
automation.

ÊëòË¶ÅÔºö<paragraph>ÁÇ∫‰∫ÜË≠âÊòéÈáèÂ≠êÈÅãÁÆóÁöÑÂÑ™Ë∂äÊÄßÔºåË¶èÊ®°Ë∂ä‰æÜË∂äÂ§ßÁöÑË∂ÖÂ∞éÈáèÂ≠êÈÅãÁÆóÊô∂ÁâáÊ≠£Ë¢´Ë®≠Ë®àÂíåË£ΩÈÄ†ÔºåÂºïÁôº‰∫ÜÂ∞çÈõªÂ≠êË®≠Ë®àËá™ÂãïÂåñÁöÑÈúÄÊ±ÇÔºå‰ª•ËøΩÊ±ÇÊõ¥Â•ΩÁöÑÊïàÁéáÂíåÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÊ®°Êì¨ÈáèÂ≠êÁ≥ªÁµ±ÁöÑË§áÈõúÊÄßÂ∞çÈáèÂ≠êÊô∂ÁâáÁöÑÈõªËÖ¶ËºîÂä©Ë®≠Ë®àÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÂà©Áî®ÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÁöÑÂèØÊì¥ÂÖÖÊÄßÔºåÊàëÂÄëÂú®Ê≠§ÊèêÂá∫‰∏ÄÂÄãÁî®ÊñºÂ§ßË¶èÊ®°Ë∂ÖÂ∞éÈáèÂ≠êÈõªË∑ØÁöÑÂèÉÊï∏Ë®≠Ë®àÊºîÁÆóÊ≥ï„ÄÇË©≤ÊºîÁÆóÊ≥ï‰æùË≥¥ÊñºÊâÄË¨ÇÁöÑ„Äå‰∏âÈöéÁ∏ÆÊîæ„ÄçÊ©üÂà∂ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂÖ©ÂÄãÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÔºö‰∏ÄÂÄãÁõ£Áù£ÂºèË®ìÁ∑¥ÊñºÂ∞èË¶èÊ®°ÈõªË∑Ø‰∏¶ÊáâÁî®Êñº‰∏≠Ë¶èÊ®°ÈõªË∑ØÁöÑË©ï‰º∞Âô®Ôºå‰ª•Âèä‰∏ÄÂÄãÁÑ°Áõ£Áù£ÂºèË®ìÁ∑¥Êñº‰∏≠Ë¶èÊ®°ÈõªË∑Ø‰∏¶ÊáâÁî®ÊñºÂ§ßË¶èÊ®°ÈõªË∑ØÁöÑË®≠Ë®àÂô®„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÊºîÁÆóÊ≥ïÂú®Ê∏õËºïÈáèÂ≠ê‰∏≤ÊìæË™§Â∑ÆÊñπÈù¢ÁöÑËÉΩÂäõÔºåÈÄô‰∫õË™§Â∑ÆÈÄöÂ∏∏Â≠òÂú®Ôºå‰∏¶‰∏îËàáË∂ÖÂ∞éÈáèÂ≠êÈõªË∑ØÁöÑÂúñÂΩ¢ÁµêÊßãÂíåÂèÉÊï∏ÂàÜÈÖçÂØÜÂàáÁõ∏Èóú„ÄÇÂêåÊôÇËÄÉÊÖÆ‰∫ÜÂñÆÈáèÂ≠ê‰ΩçÂíåÈõôÈáèÂ≠ê‰ΩçÈñòÁöÑÂèÉÊï∏„ÄÇÊï∏ÂÄºÁµêÊûúË°®ÊòéÔºåË®ìÁ∑¥ÊúâÁ¥†ÁöÑË®≠Ë®àÂô®‰∏çÂÉÖÂú®ÊïàÁéáÊñπÈù¢ÔºåËÄå‰∏îÂú®ÊïàËÉΩÊñπÈù¢ÈÉΩÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÂÑ™Âã¢ÔºåÁâπÂà•ÊòØÂ∞çÊñºÂ§ßË¶èÊ®°ÈõªË∑Ø„ÄÇ‰æãÂ¶ÇÔºåÂú®Áî±Â§ßÁ¥Ñ 870 ÂÄãÈáèÂ≠ê‰ΩçÁµÑÊàêÁöÑË∂ÖÂ∞éÈáèÂ≠êÈõªË∑Ø‰∏≠ÔºåË®ìÁ∑¥ÂæåÁöÑË®≠Ë®àÂô®Âè™ÈúÄ 27 ÁßíÂç≥ÂèØÂÆåÊàêÈ†ªÁéáË®≠Ë®à‰ªªÂãôÔºåËÄåÂÇ≥Áµ±ÁöÑ Snake ÊºîÁÆóÊ≥ïÂâáÈúÄË¶Å 90 ÂàÜÈêò„ÄÇÊõ¥ÈáçË¶ÅÁöÑÊòØÔºå‰ΩøÁî®ÊàëÂÄëÊºîÁÆóÊ≥ïÁî¢ÁîüÁöÑ‰∏≤ÊìæË™§Â∑ÆÂÉÖÁÇ∫ Snake ÊºîÁÆóÊ≥ïÊâÄÁî¢ÁîüË™§Â∑ÆÁöÑ 51%„ÄÇÁ∏ΩÁöÑ‰æÜË™™ÔºåÈÄôÈ†ÖÁ†îÁ©∂ÊúÄÂàùÂ±ïÁ§∫‰∫ÜÂ∞áÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑ØÊáâÁî®ÊñºÈáèÂ≠êËôïÁêÜÂô®Ë®≠Ë®àÂèÉÊï∏ÁöÑÂÑ™ÈªûÔºå‰∏¶ÁÇ∫Âú®ÈõªÂ≠êË®≠Ë®àËá™ÂãïÂåñ‰∏≠Â§ßË¶èÊ®°Êï∏ÂÄºÊ®°Êì¨ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÁ≥ªÁµ±Êèê‰æõ‰∫ÜË¶ãËß£„ÄÇ</paragraph>

##### **The Two-Hop Curse: LLMs trained on A->B, B->C fail to learn A-->C**
2411.16353v1 by Mikita Balesni, Tomek Korbak, Owain Evans

While LLMs excel at multi-hop questions (e.g. "Who is the spouse of the
performer of Imagine?") when using chain-of-thought reasoning (CoT), they
struggle when forced to reason internally (without CoT). Previous work on the
size and nature of this gap produced mixed evidence with inconclusive results.
In this paper, we introduce a controlled setting for investigating two-hop
reasoning in LLMs, where the above-chance performance constitutes undeniable
evidence for latent reasoning. We fine-tune LLMs (including Llama 3 8B Instruct
and GPT-4o) on fictional facts and confirm that they generalize to answering
two-hop questions about them using CoT. We find that models can perform latent
reasoning when facts appear together during training or in the prompt. However,
to our surprise, models completely fail at two-hop reasoning without CoT when
learned facts only appear in different documents, achieving chance-level
accuracy and chance-level test loss. We call this complete failure to compose
separately learned facts the Two-Hop Curse. Moreover, we evaluate 9 frontier
LLMs on real-world facts, finding that models completely fail at two-hop no-CoT
reasoning for over half of question categories while maintaining partial
success with CoT across most categories. These results suggest that LLMs lack a
general capability for latent multi-hop reasoning independent of the question
type.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®Â§öË∑≥ÂïèÈ°åÔºà‰æãÂ¶Ç„ÄåÊºîÂî± Imagine ÁöÑË°®ÊºîËÄÖÁöÑÈÖçÂÅ∂ÊòØË™∞Ôºü„ÄçÔºâ‰∏äË°®ÁèæÂá∫Ëâ≤Ôºå‰ΩøÁî®ÊÄùËÄÉÈèàÔºàCoTÔºâÊé®ÁêÜÊôÇÔºå‰ΩÜÁï∂Ë¢´Ëø´Âú®ÂÖßÈÉ®Êé®ÁêÜÔºàÊ≤íÊúâ CoTÔºâÊôÇÔºåÂÆÉÂÄëÊúÉÈô∑ÂÖ•Âõ∞Â¢É„ÄÇÂÖàÂâçÂ∞çÊ≠§Â∑ÆË∑ùÁöÑÂ§ßÂ∞èÂíåÊÄßË≥™ÁöÑÁ†îÁ©∂Áî¢Áîü‰∫Ü‰∏çÂêåÁöÑË≠âÊìöÔºåÁµêÊûúÊ≤íÊúâÂÆöË´ñ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂèóÊéßË®≠ÂÆöÔºåÁî®ÊñºË™øÊü•Â§ßÂûãË™ûË®ÄÊ®°Âûã‰∏≠ÁöÑÂÖ©Ë∑≥Êé®ÁêÜÔºåÂÖ∂‰∏≠È´òÊñºÊ©üÊúÉÁöÑË°®ÁèæÊßãÊàêÊΩõÂú®Êé®ÁêÜÁöÑÁÑ°ÂèØËæØÈßÅÁöÑË≠âÊìö„ÄÇÊàëÂÄëÂæÆË™øÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàÂåÖÊã¨ Llama 3 8B Instruct Âíå GPT-4oÔºâÁöÑËôõÊßã‰∫ãÂØ¶Ôºå‰∏¶Á¢∫Ë™çÂÆÉÂÄëÂèØ‰ª•Ê¶ÇÊã¨ÁÇ∫‰ΩøÁî® CoT ÂõûÁ≠îÊúâÈóúÂÆÉÂÄëÁöÑÂÖ©Ë∑≥ÂïèÈ°å„ÄÇÊàëÂÄëÁôºÁèæÔºåÁï∂‰∫ãÂØ¶Âá∫ÁèæÂú®Ë®ìÁ∑¥ÊúüÈñìÊàñÊèêÁ§∫‰∏≠ÊôÇÔºåÊ®°ÂûãÂèØ‰ª•Âü∑Ë°åÊΩõÂú®Êé®ÁêÜ„ÄÇÁÑ∂ËÄåÔºå‰ª§ÊàëÂÄëÈ©öË®ùÁöÑÊòØÔºåÁï∂Â≠∏ÁøíÂà∞ÁöÑ‰∫ãÂØ¶ÂÉÖÂá∫ÁèæÂú®‰∏çÂêåÁöÑÊñá‰ª∂‰∏≠ÊôÇÔºåÊ®°ÂûãÂú®Ê≤íÊúâ CoT ÁöÑÊÉÖÊ≥Å‰∏ãÂÆåÂÖ®ÁÑ°Ê≥ïÈÄ≤Ë°åÂÖ©Ë∑≥Êé®ÁêÜÔºåÈÅîÂà∞Ê©üÊúÉÊ∞¥Âπ≥ÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÊ©üÊúÉÊ∞¥Âπ≥ÁöÑÊ∏¨Ë©¶ÊêçÂ§±„ÄÇÊàëÂÄëÂ∞áÈÄôÁ®ÆÂÆåÂÖ®ÁÑ°Ê≥ïÁµÑÂêàÂñÆÁç®Â≠∏ÁøíÁöÑ‰∫ãÂØ¶Á®±ÁÇ∫ÂÖ©Ë∑≥Ë©õÂíí„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑ‰∫ãÂØ¶‰∏äË©ï‰º∞‰∫Ü 9 ÂÄãÂâçÊ≤øÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºåÁôºÁèæÊ®°ÂûãÂú®Ë∂ÖÈÅé‰∏ÄÂçäÁöÑÂïèÈ°åÈ°ûÂà•‰∏≠ÂÆåÂÖ®ÁÑ°Ê≥ïÈÄ≤Ë°åÂÖ©Ë∑≥ÁÑ° CoT Êé®ÁêÜÔºåÂêåÊôÇÂú®Â§ßÂ§öÊï∏È°ûÂà•‰∏≠‰ΩøÁî® CoT ‰øùÊåÅÈÉ®ÂàÜÊàêÂäü„ÄÇÈÄô‰∫õÁµêÊûúË°®ÊòéÔºåÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁº∫‰πèÁç®Á´ãÊñºÂïèÈ°åÈ°ûÂûãÁöÑÊΩõÂú®Â§öË∑≥Êé®ÁêÜÁöÑ‰∏ÄËà¨ËÉΩÂäõ„ÄÇ

##### **Preference Optimization for Reasoning with Pseudo Feedback**
2411.16345v1 by Fangkai Jiao, Geyang Guo, Xingxing Zhang, Nancy F. Chen, Shafiq Joty, Furu Wei

Preference optimization techniques, such as Direct Preference Optimization
(DPO), are frequently employed to enhance the reasoning capabilities of large
language models (LLMs) in domains like mathematical reasoning and coding,
typically following supervised fine-tuning. These methods rely on high-quality
labels for reasoning tasks to generate preference pairs; however, the
availability of reasoning datasets with human-verified labels is limited. In
this study, we introduce a novel approach to generate pseudo feedback for
reasoning tasks by framing the labeling of solutions to reason problems as an
evaluation against associated test cases. We explore two forms of pseudo
feedback based on test cases: one generated by frontier LLMs and the other by
extending self-consistency to multi-test-case. We conduct experiments on both
mathematical reasoning and coding tasks using pseudo feedback for preference
optimization, and observe improvements across both tasks. Specifically, using
Mathstral-7B as our base model, we improve MATH results from 58.3 to 68.6,
surpassing both NuminaMath-72B and GPT-4-Turbo-1106-preview. In GSM8K and
College Math, our scores increase from 85.6 to 90.3 and from 34.3 to 42.3,
respectively. Building on Deepseek-coder-7B-v1.5, we achieve a score of 24.6 on
LiveCodeBench (from 21.1), surpassing Claude-3-Haiku.

ÊëòË¶ÅÔºöÂÅèÂ•ΩÂÑ™ÂåñÊäÄË°ìÔºå‰æãÂ¶ÇÁõ¥Êé•ÂÅèÂ•ΩÂÑ™Âåñ (DPO)ÔºåÁ∂ìÂ∏∏Ë¢´Áî®‰æÜÂ¢ûÂº∑Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Êï∏Â≠∏Êé®ÁêÜÂíåÁ∑®Á¢ºÁ≠âÈ†òÂüüÁöÑÊé®ÁêÜËÉΩÂäõÔºåÈÄöÂ∏∏ÈÅµÂæ™Áõ£Áù£ÂæÆË™ø„ÄÇÈÄô‰∫õÊñπÊ≥ï‰æùË≥¥ÊñºÊé®ÁêÜ‰ªªÂãôÁöÑÈ´òÂìÅË≥™Ê®ôÁ±§‰æÜÁî¢ÁîüÂÅèÂ•ΩÂ∞çÔºõÁÑ∂ËÄåÔºåÂÖ∑Êúâ‰∫∫Â∑•È©óË≠âÊ®ôÁ±§ÁöÑÊé®ÁêÜÊï∏ÊìöÈõÜÁöÑÂèØÁî®ÊÄßÊòØÊúâÈôêÁöÑ„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ï‰æÜÁî¢ÁîüÊé®ÁêÜ‰ªªÂãôÁöÑÂÅΩÂõûÈ•ãÔºåÊñπÊ≥ïÊòØÂ∞áÊé®ÁêÜÂïèÈ°åÁöÑËß£Ê®ôË®òÊßãÂª∫ÁÇ∫ÈáùÂ∞çÈóúËÅØÊ∏¨Ë©¶Ê°à‰æãÁöÑË©ï‰º∞„ÄÇÊàëÂÄëÊé¢Á¥¢‰∫ÜÂÖ©Á®ÆÂü∫ÊñºÊ∏¨Ë©¶Ê°à‰æãÁöÑÂÅΩÂõûÈ•ãÂΩ¢ÂºèÔºö‰∏ÄÁ®ÆÁî±ÈÇäÁ∑£ LLM Áî¢ÁîüÔºåÂè¶‰∏ÄÁ®ÆÈÄöÈÅéÂ∞áËá™Êàë‰∏ÄËá¥ÊÄßÊì¥Â±ïÂà∞Â§öÊ∏¨Ë©¶Ê°à‰æã„ÄÇÊàëÂÄëÂ∞çÊï∏Â≠∏Êé®ÁêÜÂíåÁ∑®Á¢º‰ªªÂãôÈÄ≤Ë°å‰∫ÜÂØ¶È©óÔºå‰ΩøÁî®ÂÅΩÂõûÈ•ãÈÄ≤Ë°åÂÅèÂ•ΩÂÑ™ÂåñÔºå‰∏¶ËßÄÂØüÂà∞ÂÖ©È†Ö‰ªªÂãôÈÉΩÊúâÊîπÈÄ≤„ÄÇÂÖ∑È´î‰æÜË™™Ôºå‰ΩøÁî® Mathstral-7B ‰ΩúÁÇ∫ÊàëÂÄëÁöÑÂü∫Á§éÊ®°ÂûãÔºåÊàëÂÄëÂ∞á MATH ÁµêÊûúÂæû 58.3 ÊèêÈ´òÂà∞ 68.6ÔºåË∂ÖÈÅé‰∫Ü NuminaMath-72B Âíå GPT-4-Turbo-1106-preview„ÄÇÂú® GSM8K Âíå College Math ‰∏≠ÔºåÊàëÂÄëÁöÑÂàÜÊï∏ÂàÜÂà•Âæû 85.6 Â¢ûÂä†Âà∞ 90.3ÔºåÂæû 34.3 Â¢ûÂä†Âà∞ 42.3„ÄÇÂú® Deepseek-coder-7B-v1.5 ÁöÑÂü∫Á§é‰∏äÔºåÊàëÂÄëÂú® LiveCodeBench ‰∏äÈÅîÂà∞‰∫Ü 24.6 ÁöÑÂàÜÊï∏ÔºàÂæû 21.1ÔºâÔºåË∂ÖÈÅé‰∫Ü Claude-3-Haiku„ÄÇ

##### **Can AI grade your essays? A comparative analysis of large language models and teacher ratings in multidimensional essay scoring**
2411.16337v1 by Kathrin Se√üler, Maurice F√ºrstenberg, Babette B√ºhler, Enkelejda Kasneci

The manual assessment and grading of student writing is a time-consuming yet
critical task for teachers. Recent developments in generative AI, such as large
language models, offer potential solutions to facilitate essay-scoring tasks
for teachers. In our study, we evaluate the performance and reliability of both
open-source and closed-source LLMs in assessing German student essays,
comparing their evaluations to those of 37 teachers across 10 pre-defined
criteria (i.e., plot logic, expression). A corpus of 20 real-world essays from
Year 7 and 8 students was analyzed using five LLMs: GPT-3.5, GPT-4, o1, LLaMA
3-70B, and Mixtral 8x7B, aiming to provide in-depth insights into LLMs' scoring
capabilities. Closed-source GPT models outperform open-source models in both
internal consistency and alignment with human ratings, particularly excelling
in language-related criteria. The novel o1 model outperforms all other LLMs,
achieving Spearman's $r = .74$ with human assessments in the overall score, and
an internal consistency of $ICC=.80$. These findings indicate that LLM-based
assessment can be a useful tool to reduce teacher workload by supporting the
evaluation of essays, especially with regard to language-related criteria.
However, due to their tendency for higher scores, the models require further
refinement to better capture aspects of content quality.

ÊëòË¶ÅÔºöÊâãÂãïË©ïÈáèËàáË©ïÂàÜÂ≠∏ÁîüÁöÑÂØ´‰ΩúÊòØ‰∏ÄÈ†ÖËÄóÊôÇ‰ΩÜÂ∞çËÄÅÂ∏´‰æÜË™™Ëá≥ÈóúÈáçË¶ÅÁöÑ‰ªªÂãô„ÄÇÁîüÊàêÂºè AI ÁöÑÊúÄÊñ∞ÁôºÂ±ïÔºå‰æãÂ¶ÇÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºåÊèê‰æõ‰∫ÜÊΩõÂú®ÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰ª•‰øÉÈÄ≤ÊïôÂ∏´ÁöÑË´ñÊñáË©ïÂàÜ‰ªªÂãô„ÄÇÂú®ÊàëÂÄëÁöÑÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëË©ï‰º∞‰∫ÜÈñãÊ∫êÂíåÈñâÊ∫ê LLM Âú®Ë©ïÈáèÂæ∑ÂúãÂ≠∏ÁîüË´ñÊñáÊôÇÁöÑË°®ÁèæÂíåÂèØÈù†ÊÄßÔºå‰∏¶Â∞áÂÖ∂Ë©ïÂàÜËàá 37 ‰ΩçËÄÅÂ∏´Âú® 10 ÂÄãÈ†êÂÖàÂÆöÁæ©ÁöÑÊ®ôÊ∫ñÔºà‰æãÂ¶ÇÔºåÊÉÖÁØÄÈÇèËºØ„ÄÅË°®ÈÅîÔºâ‰∏äÁöÑË©ïÂàÜÈÄ≤Ë°åÊØîËºÉ„ÄÇ‰ΩøÁî®‰∫îÂÄã LLM ÂàÜÊûê‰∫Ü‰æÜËá™ 7 Âπ¥Á¥öÂíå 8 Âπ¥Á¥öÂ≠∏ÁîüÁöÑ 20 ÁØáÁúüÂØ¶‰∏ñÁïåË´ñÊñáÔºöGPT-3.5„ÄÅGPT-4„ÄÅo1„ÄÅLLaMA 3-70B Âíå Mixtral 8x7BÔºåÊó®Âú®Ê∑±ÂÖ•‰∫ÜËß£ LLM ÁöÑË©ïÂàÜËÉΩÂäõ„ÄÇÈñâÊ∫ê GPT Ê®°ÂûãÂú®ÂÖßÈÉ®‰∏ÄËá¥ÊÄßÂíåËàá‰∫∫È°ûË©ïÂàÜÁöÑÂêªÂêàÂ∫¶ÊñπÈù¢ÈÉΩÂÑ™ÊñºÈñãÊ∫êÊ®°ÂûãÔºåÂ∞§ÂÖ∂Âú®ËàáË™ûË®ÄÁõ∏ÈóúÁöÑÊ®ôÊ∫ñÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤„ÄÇÊñ∞Á©éÁöÑ o1 Ê®°ÂûãÂÑ™ÊñºÊâÄÊúâÂÖ∂‰ªñ LLMÔºåÂú®Êï¥È´îË©ïÂàÜ‰∏≠ÂØ¶Áèæ‰∫Ü Spearman ÁöÑ r = .74 Ëàá‰∫∫È°ûË©ï‰º∞Ôºå‰ª•Âèä ICC=.80 ÁöÑÂÖßÈÉ®‰∏ÄËá¥ÊÄß„ÄÇÈÄô‰∫õÁôºÁèæË°®ÊòéÔºåÂü∫Êñº LLM ÁöÑË©ï‰º∞ÂèØ‰ª•ÊàêÁÇ∫‰∏ÄÂÄãÊúâÁî®ÁöÑÂ∑•ÂÖ∑ÔºåÈÄöÈÅéÊîØÊåÅË´ñÊñáË©ï‰º∞‰æÜÊ∏õÂ∞ëÊïôÂ∏´ÁöÑÂ∑•‰ΩúÈáèÔºåÁâπÂà•ÊòØÂú®ËàáË™ûË®ÄÁõ∏ÈóúÁöÑÊ®ôÊ∫ñÊñπÈù¢„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÂÖ∂ÂÇæÂêëÊñºÁç≤ÂæóÊõ¥È´òÁöÑÂàÜÊï∏ÔºåÈÄô‰∫õÊ®°ÂûãÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•ÊîπÈÄ≤Ôºå‰ª•Êõ¥Â•ΩÂú∞ÊçïÊçâÂÖßÂÆπÂìÅË≥™ÁöÑÊñπÈù¢„ÄÇ

##### **One Diffusion to Generate Them All**
2411.16318v1 by Duong H. Le, Tuan Pham, Sangho Lee, Christopher Clark, Aniruddha Kembhavi, Stephan Mandt, Ranjay Krishna, Jiasen Lu

We introduce OneDiffusion, a versatile, large-scale diffusion model that
seamlessly supports bidirectional image synthesis and understanding across
diverse tasks. It enables conditional generation from inputs such as text,
depth, pose, layout, and semantic maps, while also handling tasks like image
deblurring, upscaling, and reverse processes such as depth estimation and
segmentation. Additionally, OneDiffusion allows for multi-view generation,
camera pose estimation, and instant personalization using sequential image
inputs. Our model takes a straightforward yet effective approach by treating
all tasks as frame sequences with varying noise scales during training,
allowing any frame to act as a conditioning image at inference time. Our
unified training framework removes the need for specialized architectures,
supports scalable multi-task training, and adapts smoothly to any resolution,
enhancing both generalization and scalability. Experimental results demonstrate
competitive performance across tasks in both generation and prediction such as
text-to-image, multiview generation, ID preservation, depth estimation and
camera pose estimation despite relatively small training dataset. Our code and
checkpoint are freely available at https://github.com/lehduong/OneDiffusion

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÊé®Âá∫ OneDiffusionÔºåÈÄôÊòØ‰∏ÄÂÄãÈÄöÁî®ÁöÑ„ÄÅÂ§ßË¶èÊ®°ÁöÑÊì¥Êï£Ê®°ÂûãÔºåÂèØ‰ª•ÁÑ°Á∏´Âú∞ÊîØÊè¥ÈõôÂêëÂΩ±ÂÉèÂêàÊàêÂíåÁêÜËß£Ôºå‰∏¶‰∏îÈÅ©Áî®ÊñºÂêÑÁ®Æ‰ªªÂãô„ÄÇÂÆÉËÉΩÂ§†ÂæûÊñáÂ≠ó„ÄÅÊ∑±Â∫¶„ÄÅÂßøÂã¢„ÄÅÁâàÈù¢ÂíåË™ûÊÑèÂúñÁ≠âËº∏ÂÖ•ÈÄ≤Ë°åÊ¢ù‰ª∂ÂºèÁîüÊàêÔºåÂêåÊôÇ‰πüËÉΩËôïÁêÜÂΩ±ÂÉèÂéªÊ®°Á≥ä„ÄÅÂçáÈ†ªÂíåÂèçÂêëËôïÁêÜÔºå‰æãÂ¶ÇÊ∑±Â∫¶‰º∞Ë®àÂíåÂàÜÂâ≤„ÄÇÊ≠§Â§ñÔºåOneDiffusion ÈÇÑÂÖÅË®±Â§öË¶ñÂúñÁîüÊàê„ÄÅÁõ∏Ê©üÂßøÂã¢‰º∞Ë®àÂíå‰ΩøÁî®È†ÜÂ∫èÂΩ±ÂÉèËº∏ÂÖ•ÈÄ≤Ë°åÂç≥ÊôÇÂÄã‰∫∫Âåñ„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÊé°Áî®‰∏ÄÁ®ÆÁ∞°ÂñÆ‰ΩÜÊúâÊïàÁöÑÊñπÊ≥ïÔºåÂ∞áÊâÄÊúâ‰ªªÂãôË¶ñÁÇ∫Ë®ìÁ∑¥ÊúüÈñìÂÖ∑Êúâ‰∏çÂêåÈõúË®äÊØî‰æãÁöÑÂπÄÂ∫èÂàóÔºåÂÖÅË®±‰ªª‰ΩïÂπÄÂú®Êé®Ë´ñÊôÇÈñì‰ΩúÁÇ∫Ê¢ù‰ª∂ÂΩ±ÂÉè„ÄÇÊàëÂÄëÁµ±‰∏ÄÁöÑË®ìÁ∑¥Ê°ÜÊû∂Ê∂àÈô§‰∫ÜÂ∞çÂ∞àÁî®Êû∂ÊßãÁöÑÈúÄÊ±ÇÔºåÊîØÊè¥ÂèØÊì¥ÂÖÖÁöÑÂ§ö‰ªªÂãôË®ìÁ∑¥Ôºå‰∏¶ËÉΩÈ†ÜÂà©ÈÅ©Êáâ‰ªª‰ΩïËß£ÊûêÂ∫¶ÔºåÂêåÊôÇÊèêÂçáÊ≥õÂåñÊÄßÂíåÂèØÊì¥ÂÖÖÊÄß„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÂÑòÁÆ°Ë®ìÁ∑¥Ë≥áÊñôÈõÜÁõ∏Â∞çËºÉÂ∞èÔºå‰ΩÜÂÆÉÂú®ÁîüÊàêÂíåÈ†êÊ∏¨‰ªªÂãôÔºà‰æãÂ¶ÇÊñáÂ≠óËΩâÂΩ±ÂÉè„ÄÅÂ§öË¶ñÂúñÁîüÊàê„ÄÅID ‰øùÁïô„ÄÅÊ∑±Â∫¶‰º∞Ë®àÂíåÁõ∏Ê©üÂßøÂã¢‰º∞Ë®àÔºâ‰∏≠ÈÉΩÂ±ïÁèæÂá∫ÂÖ∑ÊúâÁ´∂Áà≠ÂäõÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåÊ™¢Êü•ÈªûÂèØÊñº https://github.com/lehduong/OneDiffusion ÂÖçË≤ªÂèñÂæó</paragraph>

##### **CATP-LLM: Empowering Large Language Models for Cost-Aware Tool Planning**
2411.16313v1 by Duo Wu, Jinghe Wang, Yuan Meng, Yanning Zhang, Le Sun, Zhi Wang

Utilizing large language models (LLMs) for tool planning has emerged as a
promising avenue for developing general AI systems, where LLMs automatically
schedule external tools (e.g. vision models) to tackle complex tasks based on
task descriptions. To push this paradigm toward practical applications, it is
crucial for LLMs to consider tool execution costs (e.g. execution time) for
tool planning. Unfortunately, prior studies overlook the tool execution costs,
leading to the generation of expensive plans of which the costs outweigh task
performance. To fill this gap, we propose the Cost-Aware Tool Planning with
LLMs (CATP-LLM) framework, which for the first time provides a coherent design
to empower LLMs for cost-aware tool planning. Specifically, CATP-LLM
incorporates a tool planning language to enhance the LLM to generate
non-sequential plans of multiple branches for efficient concurrent tool
execution and cost reduction. Moreover, it further designs a cost-aware offline
reinforcement learning algorithm to fine-tune the LLM to optimize the
performance-cost trade-off in tool planning. In lack of public cost-related
datasets, we further present OpenCATP, the first platform for cost-aware
planning evaluation. Experiments on OpenCATP show that CATP-LLM outperforms
GPT-4 even when using Llama2-7B as its backbone, with the average improvement
of 28.2%-30.2% higher plan performance and 24.7%-45.8% lower costs even on the
challenging planning tasks. The codes of CATP-LLM and OpenCATP will be publicly
available.

ÊëòË¶ÅÔºöÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄ≤Ë°åÂ∑•ÂÖ∑Ë¶èÂäÉÂ∑≤ÊàêÁÇ∫ÈñãÁôºÈÄöÁî® AI Á≥ªÁµ±ÁöÑ‰∏ÄÊ¢ùÊúâÂâçÈÄîÁöÑÈÄîÂæëÔºåÂÖ∂‰∏≠ LLM ÊúÉÊ†πÊìö‰ªªÂãôÊèèËø∞Ëá™ÂãïÂÆâÊéíÂ§ñÈÉ®Â∑•ÂÖ∑Ôºà‰æãÂ¶ÇË¶ñË¶∫Ê®°ÂûãÔºâ‰æÜËôïÁêÜË§áÈõúÁöÑ‰ªªÂãô„ÄÇÁÇ∫‰∫ÜÂ∞áÊ≠§ÁØÑ‰æãÊé®ÂêëÂØ¶ÂãôÊáâÁî®ÔºåLLM ÂøÖÈ†àËÄÉÈáèÂ∑•ÂÖ∑Âü∑Ë°åÊàêÊú¨Ôºà‰æãÂ¶ÇÂü∑Ë°åÊôÇÈñìÔºâ‰ª•ÈÄ≤Ë°åÂ∑•ÂÖ∑Ë¶èÂäÉ„ÄÇÈÅ∫ÊÜæÁöÑÊòØÔºåÂÖàÂâçÁöÑÁ†îÁ©∂ÂøΩÁï•‰∫ÜÂ∑•ÂÖ∑Âü∑Ë°åÊàêÊú¨ÔºåÂ∞éËá¥Áî¢Áîü‰∫ÜÊàêÊú¨Â§ßÊñº‰ªªÂãôÊïàËÉΩÁöÑÊòÇË≤¥Ë®àÁï´„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÊ≠§‰∏ÄÁº∫Âè£ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂÖ∑ÂÇôÊàêÊú¨ÊÑèË≠òÁöÑ LLM Â∑•ÂÖ∑Ë¶èÂäÉ (CATP-LLM) Êû∂ÊßãÔºåË©≤Êû∂ÊßãÈ¶ñÊ¨°Êèê‰æõ‰∫ÜÁõ∏Âπ≤ÁöÑË®≠Ë®àÔºå‰ª•Ë≥¶‰∫à LLM ÊàêÊú¨ÊÑèË≠òÁöÑÂ∑•ÂÖ∑Ë¶èÂäÉËÉΩÂäõ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåCATP-LLM ÁµêÂêà‰∫ÜÂ∑•ÂÖ∑Ë¶èÂäÉË™ûË®ÄÔºå‰ª•Â¢ûÂº∑ LLM Áî¢ÁîüÈùûÈ†ÜÂ∫èÁöÑÂ§öÂàÜÊîØË®àÁï´Ôºå‰ª•ÈÄ≤Ë°åÊúâÊïàÁöÑ‰∏¶Ë°åÂ∑•ÂÖ∑Âü∑Ë°åÂíåÈôç‰ΩéÊàêÊú¨„ÄÇÊ≠§Â§ñÔºåÂÆÉÈÄ≤‰∏ÄÊ≠•Ë®≠Ë®à‰∫Ü‰∏ÄÁ®ÆÂÖ∑ÂÇôÊàêÊú¨ÊÑèË≠òÁöÑÈõ¢Á∑öÂº∑ÂåñÂ≠∏ÁøíÊºîÁÆóÊ≥ïÔºå‰ª•ÂæÆË™ø LLMÔºå‰ª•ÊúÄ‰Ω≥ÂåñÂ∑•ÂÖ∑Ë¶èÂäÉ‰∏≠ÁöÑÊïàËÉΩÊàêÊú¨ÂèñÊç®„ÄÇÁî±ÊñºÁº∫‰πèÂÖ¨ÈñãÁöÑÊàêÊú¨Áõ∏ÈóúË≥áÊñôÈõÜÔºåÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÊèêÂá∫‰∫Ü OpenCATPÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÁî®ÊñºÂÖ∑ÂÇôÊàêÊú¨ÊÑèË≠òÁöÑË¶èÂäÉË©ï‰º∞ÁöÑÂπ≥Âè∞„ÄÇÂú® OpenCATP ‰∏äÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåÂç≥‰Ωø‰ΩøÁî® Llama2-7B ‰ΩúÁÇ∫ÂÖ∂‰∏ªÂππÔºåCATP-LLM ‰ªçÂÑ™Êñº GPT-4ÔºåÂπ≥ÂùáÊïàËÉΩÊèêÂçá 28.2%-30.2%ÔºåÊàêÊú¨Èôç‰Ωé 24.7%-45.8%ÔºåÂç≥‰ΩøÂú®ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑË¶èÂäÉ‰ªªÂãô‰∏ä‰πüÊòØÂ¶ÇÊ≠§„ÄÇCATP-LLM Âíå OpenCATP ÁöÑÁ®ãÂºèÁ¢ºÂ∞áÂÖ¨ÈñãÊèê‰æõ„ÄÇ

##### **Learning from Relevant Subgoals in Successful Dialogs using Iterative Training for Task-oriented Dialog Systems**
2411.16305v1 by Magdalena Kaiser, Patrick Ernst, Gy√∂rgy Szarvas

Task-oriented Dialog (ToD) systems have to solve multiple subgoals to
accomplish user goals, whereas feedback is often obtained only at the end of
the dialog. In this work, we propose SUIT (SUbgoal-aware ITerative Training),
an iterative training approach for improving ToD systems. We sample dialogs
from the model we aim to improve and determine subgoals that contribute to
dialog success using distant supervision to obtain high quality training
samples. We show how this data improves supervised fine-tuning or,
alternatively, preference learning results. SUIT is able to iteratively
generate more data instead of relying on fixed static sets. SUIT reaches new
state-of-the-art performance on a popular ToD benchmark.

ÊëòË¶ÅÔºö‰ªªÂãôÂ∞éÂêëÂ∞çË©± (ToD) Á≥ªÁµ±ÂøÖÈ†àËß£Ê±∫Â§öÂÄãÂ≠êÁõÆÊ®ôÊâçËÉΩÈÅîÊàê‰ΩøÁî®ËÄÖÁõÆÊ®ôÔºåËÄåÂõûÈ•ãÂæÄÂæÄÂè™Âú®Â∞çË©±ÁµêÊùüÊôÇÊâçÊúÉÁç≤Âæó„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ SUITÔºàÂ≠êÁõÆÊ®ôÊÑüÁü•Ëø≠‰ª£Ë®ìÁ∑¥ÔºâÔºå‰∏ÄÁ®ÆÁî®ÊñºÊîπÂñÑ ToD Á≥ªÁµ±ÁöÑËø≠‰ª£Ë®ìÁ∑¥ÊñπÊ≥ï„ÄÇÊàëÂÄëÂæûÊàëÂÄëÊâìÁÆóÊîπÂñÑÁöÑÊ®°Âûã‰∏≠ÊäΩÂèñÂ∞çË©±Ôºå‰∏¶‰ΩøÁî®ÈÅ†Ë∑ùÁõ£Áù£‰æÜÁ¢∫ÂÆöÊúâÂä©ÊñºÂ∞çË©±ÊàêÂäüÁöÑÂ≠êÁõÆÊ®ôÔºå‰ª•ÂèñÂæóÈ´òÂìÅË≥™ÁöÑË®ìÁ∑¥ÁØÑ‰æã„ÄÇÊàëÂÄëÂ±ïÁ§∫ÈÄô‰∫õË≥áÊñôÂ¶Ç‰ΩïÊîπÂñÑÁõ£Áù£ÂæÆË™øÊàñÂÅèÂ•ΩÂ≠∏ÁøíÁµêÊûú„ÄÇSUIT ËÉΩÂ§†Ëø≠‰ª£Áî¢ÁîüÊõ¥Â§öË≥áÊñôÔºåËÄå‰∏çÊòØ‰æùË≥¥ÊñºÂõ∫ÂÆöÁöÑÈùúÊÖãÈõÜÂêà„ÄÇSUIT Âú®‰∏ÄÂÄãÊµÅË°åÁöÑ ToD Âü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ÈÅîÂà∞Êñ∞ÁöÑÊúÄÂÖàÈÄ≤ÊïàËÉΩ„ÄÇ

##### **BayLing 2: A Multilingual Large Language Model with Efficient Language Alignment**
2411.16300v1 by Shaolei Zhang, Kehao Zhang, Qingkai Fang, Shoutao Guo, Yan Zhou, Xiaodong Liu, Yang Feng

Large language models (LLMs), with their powerful generative capabilities and
vast knowledge, empower various tasks in everyday life. However, these
abilities are primarily concentrated in high-resource languages, leaving
low-resource languages with weaker generative capabilities and relatively
limited knowledge. Enhancing the multilingual capabilities of LLMs is therefore
crucial for serving over 100 linguistic communities worldwide. An intuitive
approach to enhance the multilingual capabilities would be to construct
instruction data for various languages, but constructing instruction data for
over 100 languages is prohibitively costly. In this paper, we introduce BayLing
2, which efficiently transfers generative capabilities and knowledge from
high-resource languages to low-resource languages through language alignment.
To achieve this, we constructed a dataset of 3.2 million instructions,
comprising high-resource language instructions (Chinese and English) and
cross-lingual instructions for 100+ languages and performed instruction tuning
based on the dataset to facilitate the capability transfer between languages.
Using Llama as the foundation model, we developed BayLing-2-7B, BayLing-2-13B,
and BayLing-3-8B, and conducted a comprehensive evaluation of BayLing. For
multilingual translation across 100+ languages, BayLing shows superior
performance compared to open-source models of similar scale. For multilingual
knowledge and understanding benchmarks, BayLing achieves significant
improvements across over 20 low-resource languages, demonstrating its
capability of effective knowledge transfer from high-resource to low-resource
languages. Furthermore, results on English benchmarks indicate that BayLing
maintains high performance in highresource languages while enhancing the
performance in low-resource languages. Demo, homepage, code and models of
BayLing are available.

ÊëòË¶ÅÔºö<paragraph>Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂÖ∑ÂÇôÂº∑Â§ßÁöÑÁîüÊàêËÉΩÂäõÂíåË±êÂØåÁöÑÁü•Ë≠òÔºåËÉΩË≥¶ËÉΩÊó•Â∏∏ÁîüÊ¥ªÁöÑÂêÑÁ®Æ‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õËÉΩÂäõ‰∏ªË¶ÅÈõÜ‰∏≠Âú®È´òË≥áÊ∫êË™ûË®ÄÔºåÂ∞éËá¥‰ΩéË≥áÊ∫êË™ûË®ÄÁöÑÁîüÊàêËÉΩÂäõËºÉÂº±Ôºå‰∏îÁü•Ë≠òÁõ∏Â∞çÊúâÈôê„ÄÇÂõ†Ê≠§ÔºåÂ¢ûÂº∑ LLM ÁöÑÂ§öË™ûË®ÄËÉΩÂäõÂ∞çÊñºÊúçÂãôÂÖ®ÁêÉË∂ÖÈÅé 100 ÂÄãË™ûË®ÄÁ§æÁæ§Ëá≥ÈóúÈáçË¶Å„ÄÇÂ¢ûÂº∑Â§öË™ûË®ÄËÉΩÂäõÁöÑ‰∏ÄÁ®ÆÁõ¥ËßÄÊñπÊ≥ïÊòØÁÇ∫ÂêÑÁ®ÆË™ûË®ÄÊßãÂª∫Êåá‰ª§Êï∏ÊìöÔºå‰ΩÜÁÇ∫Ë∂ÖÈÅé 100 Á®ÆË™ûË®ÄÊßãÂª∫Êåá‰ª§Êï∏ÊìöÁöÑÊàêÊú¨È´òÂæó‰ª§‰∫∫ÊúõËÄåÂçªÊ≠•„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü BayLing 2ÔºåÂÆÉÈÄöÈÅéË™ûË®ÄÂ∞çÈΩäÊúâÊïàÂú∞Â∞áÁîüÊàêËÉΩÂäõÂíåÁü•Ë≠òÂæûÈ´òË≥áÊ∫êË™ûË®ÄËΩâÁßªÂà∞‰ΩéË≥áÊ∫êË™ûË®Ä„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊßãÂª∫‰∫Ü‰∏ÄÂÄãÂåÖÂê´ 320 Ëê¨Ê¢ùÊåá‰ª§ÁöÑÊï∏ÊìöÈõÜÔºåÂåÖÊã¨È´òË≥áÊ∫êË™ûË®ÄÊåá‰ª§Ôºà‰∏≠ÊñáÂíåËã±ÊñáÔºâ‰ª•Âèä 100 Â§öÁ®ÆË™ûË®ÄÁöÑË∑®Ë™ûË®ÄÊåá‰ª§Ôºå‰∏¶Âü∫ÊñºË©≤Êï∏ÊìöÈõÜÂü∑Ë°åÊåá‰ª§ÂæÆË™øÔºå‰ª•‰øÉÈÄ≤Ë™ûË®Ä‰πãÈñìÁöÑËÉΩÂäõËΩâÁßª„ÄÇÊàëÂÄë‰ΩøÁî® Llama ‰ΩúÁÇ∫Âü∫Á§éÊ®°ÂûãÔºåÈñãÁôº‰∫Ü BayLing-2-7B„ÄÅBayLing-2-13B Âíå BayLing-3-8BÔºå‰∏¶Â∞ç BayLing ÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢Ë©ï‰º∞„ÄÇÂ∞çÊñºË∑®Ë∂ä 100 Â§öÁ®ÆË™ûË®ÄÁöÑÂ§öË™ûË®ÄÁøªË≠ØÔºåËàáË¶èÊ®°Áõ∏‰ººÁöÑÈñãÊ∫êÊ®°ÂûãÁõ∏ÊØîÔºåBayLing Ë°®ÁèæÂá∫ÂÑ™Áï∞ÁöÑÊÄßËÉΩ„ÄÇÂ∞çÊñºÂ§öË™ûË®ÄÁü•Ë≠òÂíåÁêÜËß£Âü∫Ê∫ñÔºåBayLing Âú® 20 Â§öÁ®Æ‰ΩéË≥áÊ∫êË™ûË®Ä‰∏≠ÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÊîπÈÄ≤ÔºåË≠âÊòé‰∫ÜÂÖ∂ÂæûÈ´òË≥áÊ∫êË™ûË®ÄÂà∞‰ΩéË≥áÊ∫êË™ûË®ÄÊúâÊïàÁü•Ë≠òËΩâÁßªÁöÑËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåËã±Ë™ûÂü∫Ê∫ñÁöÑÁµêÊûúË°®ÊòéÔºåBayLing Âú®Â¢ûÂº∑‰ΩéË≥áÊ∫êË™ûË®ÄÊÄßËÉΩÁöÑÂêåÊôÇÔºåÂú®È´òË≥áÊ∫êË™ûË®Ä‰∏≠‰øùÊåÅ‰∫ÜÈ´òÊÄßËÉΩ„ÄÇBayLing ÁöÑÊºîÁ§∫„ÄÅ‰∏ªÈ†Å„ÄÅ‰ª£Á¢ºÂíåÊ®°ÂûãÂùáÂ∑≤Êé®Âá∫„ÄÇ</paragraph>

##### **The SVASR System for Text-dependent Speaker Verification (TdSV) AAIC Challenge 2024**
2411.16276v1 by Mohammadreza Molavi, Reza Khodadadi

This paper introduces an efficient and accurate pipeline for text-dependent
speaker verification (TDSV), designed to address the need for high-performance
biometric systems. The proposed system incorporates a Fast-Conformer-based ASR
module to validate speech content, filtering out Target-Wrong (TW) and
Impostor-Wrong (IW) trials. For speaker verification, we propose a feature
fusion approach that combines speaker embeddings extracted from wav2vec-BERT
and ReDimNet models to create a unified speaker representation. This system
achieves competitive results on the TDSV 2024 Challenge test set, with a
normalized min-DCF of 0.0452 (rank 2), highlighting its effectiveness in
balancing accuracy and robustness.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÁî®ÊñºÊñáÊú¨‰æùË≥¥ÂûãË™™Ë©±ËÄÖÈ©óË≠â (TDSV) ÁöÑÈ´òÊïà‰∏îÊ∫ñÁ¢∫ÁöÑÁÆ°ÈÅìÔºåÊó®Âú®ÊªøË∂≥È´òÊÄßËÉΩÁîüÁâ©Ë≠òÂà•Á≥ªÁµ±ÁöÑÈúÄÊ±Ç„ÄÇÊâÄÊèêÂá∫ÁöÑÁ≥ªÁµ±ÁµêÂêà‰∫Ü‰∏ÄÂÄãÂü∫Êñº Fast-Conformer ÁöÑ ASR Ê®°ÁµÑ‰æÜÈ©óË≠âË™ûÈü≥ÂÖßÂÆπÔºå‰∏¶ÈÅéÊøæÊéâÈåØË™§ÁöÑÁõÆÊ®ô (TW) ÂíåÈåØË™§ÁöÑÂÜíÂÖÖËÄÖ (IW) Ê∏¨Ë©¶„ÄÇÂ∞çÊñºË™™Ë©±ËÄÖÈ©óË≠âÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁâπÂæµËûçÂêàÊñπÊ≥ïÔºåÁµêÂêà‰∫ÜÂæû wav2vec-BERT Âíå ReDimNet Ê®°Âûã‰∏≠ÊèêÂèñÁöÑË™™Ë©±ËÄÖÂµåÂÖ•Ôºå‰ª•Âª∫Á´ãÁµ±‰∏ÄÁöÑË™™Ë©±ËÄÖË°®Á§∫„ÄÇÊ≠§Á≥ªÁµ±Âú® TDSV 2024 ÊåëÊà∞Ê∏¨Ë©¶ÈõÜ‰∏≠ÂèñÂæó‰∫ÜÂÖ∑ÊúâÁ´∂Áà≠ÂäõÁöÑÁµêÊûúÔºåÊ≠£Ë¶èÂåñÊúÄÂ∞è DCF ÁÇ∫ 0.0452ÔºàÊéíÂêçÁ¨¨ 2ÔºâÔºåÁ™ÅÈ°Ø‰∫ÜÂÖ∂Âú®Âπ≥Ë°°Ê∫ñÁ¢∫ÊÄßÂíåÁ©©ÂÅ•ÊÄßÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Probing for Consciousness in Machines**
2411.16262v1 by Mathis Immertreu, Achim Schilling, Andreas Maier, Patrick Krauss

This study explores the potential for artificial agents to develop core
consciousness, as proposed by Antonio Damasio's theory of consciousness.
According to Damasio, the emergence of core consciousness relies on the
integration of a self model, informed by representations of emotions and
feelings, and a world model. We hypothesize that an artificial agent, trained
via reinforcement learning (RL) in a virtual environment, can develop
preliminary forms of these models as a byproduct of its primary task. The
agent's main objective is to learn to play a video game and explore the
environment. To evaluate the emergence of world and self models, we employ
probes-feedforward classifiers that use the activations of the trained agent's
neural networks to predict the spatial positions of the agent itself. Our
results demonstrate that the agent can form rudimentary world and self models,
suggesting a pathway toward developing machine consciousness. This research
provides foundational insights into the capabilities of artificial agents in
mirroring aspects of human consciousness, with implications for future
advancements in artificial intelligence.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®é‰∫Ü‰∫∫Â∑•‰ª£ÁêÜÈñãÁôºÊ†∏ÂøÉÊÑèË≠òÁöÑÊΩõÂäõÔºåÊ≠£Â¶Ç Antonio Damasio ÁöÑÊÑèË≠òÁêÜË´ñÊâÄÊèêÂá∫ÁöÑ„ÄÇÊ†πÊìö Damasio ÁöÑË™™Ê≥ïÔºåÊ†∏ÂøÉÊÑèË≠òÁöÑÂá∫Áèæ‰æùË≥¥ÊñºËá™ÊàëÊ®°ÂûãÁöÑÊï¥ÂêàÔºåË©≤Ê®°ÂûãÁî±ÊÉÖÁ∑íÂíåÊÑüË¶∫ÁöÑË°®Âæµ‰ª•Âèä‰∏ñÁïåÊ®°ÂûãÂëäÁü•„ÄÇÊàëÂÄëÂÅáË®≠ÔºåÈÄöÈÅéÂú®ËôõÊì¨Áí∞Â¢É‰∏≠ÈÄöÈÅéÂº∑ÂåñÂ≠∏Áøí (RL) Ë®ìÁ∑¥ÁöÑ‰∫∫Â∑•‰ª£ÁêÜÔºåÂèØ‰ª•Â∞áÈÄô‰∫õÊ®°ÂûãÁöÑÂàùÊ≠•ÂΩ¢Âºè‰ΩúÁÇ∫ÂÖ∂‰∏ªË¶Å‰ªªÂãôÁöÑÂâØÁî¢ÂìÅÈÄ≤Ë°åÈñãÁôº„ÄÇ‰ª£ÁêÜÁöÑ‰∏ªË¶ÅÁõÆÊ®ôÊòØÂ≠∏ÁøíÁé©Ë¶ñÈ†ªÈÅäÊà≤‰∏¶Êé¢Á¥¢Áí∞Â¢É„ÄÇÁÇ∫‰∫ÜË©ï‰º∞‰∏ñÁïåÂíåËá™ÊàëÊ®°ÂûãÁöÑÂá∫ÁèæÔºåÊàëÂÄëÊé°Áî®Êé¢ÈáùÂâçÈ•ãÂàÜÈ°ûÂô®ÔºåË©≤ÂàÜÈ°ûÂô®‰ΩøÁî®Ë®ìÁ∑¥‰ª£ÁêÜÁ•ûÁ∂ìÁ∂≤Áµ°ÁöÑÊøÄÊ¥ª‰æÜÈ†êÊ∏¨‰ª£ÁêÜÊú¨Ë∫´ÁöÑÁ©∫Èñì‰ΩçÁΩÆ„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºå‰ª£ÁêÜÂèØ‰ª•ÂΩ¢ÊàêÂü∫Êú¨ÁöÑËá™ÊàëÊ®°ÂûãÔºåÈÄôË°®Êòé‰∫ÜÈñãÁôºÊ©üÂô®ÊÑèË≠òÁöÑÈÄîÂæë„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÁÇ∫‰∫∫Â∑•‰ª£ÁêÜÂú®ÂèçÊò†‰∫∫È°ûÊÑèË≠òÊñπÈù¢ÁöÑËÉΩÂäõÊèê‰æõ‰∫ÜÂü∫Á§éË¶ãËß£ÔºåÂ∞ç‰∫∫Â∑•Êô∫ËÉΩÁöÑÊú™‰æÜÁôºÂ±ïÂÖ∑ÊúâÂΩ±Èüø„ÄÇ

##### **Unraveling Arithmetic in Large Language Models: The Role of Algebraic Structures**
2411.16260v1 by Fu-Chieh Chang, Pei-Yuan Wu

Large language models (LLMs) have demonstrated remarkable mathematical
capabilities, largely driven by chain-of-thought (CoT) prompting, which
decomposes complex reasoning into step-by-step solutions. This approach has
enabled significant advancements, as evidenced by performance on benchmarks
like GSM8K and MATH. However, the mechanisms underlying LLMs' ability to
perform arithmetic in a single step of CoT remain poorly understood. Existing
studies debate whether LLMs encode numerical values or rely on symbolic
reasoning, while others explore attention and multi-layered processing in
arithmetic tasks. In this work, we propose that LLMs learn arithmetic by
capturing algebraic structures, such as \emph{Commutativity} and
\emph{Identity} properties. Since these structures are observable through
input-output relationships, they can generalize to unseen data. We empirically
demonstrate that LLMs can learn algebraic structures using a custom dataset of
arithmetic problems. Our findings indicate that leveraging algebraic structures
can enhance the LLMs' arithmetic capabilities, offering insights into improving
their arithmetic performance.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁèæÂá∫ÂçìË∂äÁöÑÊï∏Â≠∏ËÉΩÂäõÔºåÈÄôÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÊòØÁî±ÊÄùËÄÉÈèà (CoT) ÊèêÁ§∫È©ÖÂãïÁöÑÔºåÂÆÉÂ∞áË§áÈõúÁöÑÊé®ÁêÜÂàÜËß£ÁÇ∫ÈÄêÊ≠•Ëß£Ê±∫ÊñπÊ°à„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂ∑≤ÂØ¶ÁèæÈ°ØËëóÁöÑÈÄ≤Ê≠•ÔºåÂ¶Ç GSM8K Âíå MATH Á≠âÂü∫Ê∫ñÊ∏¨Ë©¶ÁöÑË°®ÁèæÊâÄË≠âÊòé„ÄÇÁÑ∂ËÄåÔºåLLM Âú® CoT ÁöÑÂñÆ‰∏ÄÊ≠•È©ü‰∏≠Âü∑Ë°åÁÆóË°ìÁöÑËÉΩÂäõËÉåÂæåÊ©üÂà∂‰ªçÈÆÆÁÇ∫‰∫∫Áü•„ÄÇÁèæÊúâÁ†îÁ©∂Áà≠Ë´ñ LLM ÊòØÂê¶Á∑®Á¢ºÊï∏ÂÄºÊàñ‰æùË≥¥ÊñºÁ¨¶ËôüÊé®ÁêÜÔºåËÄåÂè¶‰∏Ä‰∫õÁ†îÁ©∂ÂâáÊé¢Ë®éÁÆóË°ì‰ªªÂãô‰∏≠ÁöÑÊ≥®ÊÑèÂäõÂíåÂ§öÂ±§ËôïÁêÜ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ LLM ÈÄèÈÅéÊì∑Âèñ‰ª£Êï∏ÁµêÊßãÔºà‰æãÂ¶Ç‰∫§ÊèõÂæãÂíåÊÅÜÁ≠âÊÄßÔºâ‰æÜÂ≠∏ÁøíÁÆóË°ì„ÄÇÁî±ÊñºÈÄô‰∫õÁµêÊßãÂèØÈÄèÈÅéËº∏ÂÖ•Ëº∏Âá∫Èóú‰øÇËßÄÂØüÂà∞ÔºåÂõ†Ê≠§ÂÆÉÂÄëÂèØ‰ª•Êé®Âª£Âà∞Êú™Ë¶ãÁöÑÊï∏Êìö„ÄÇÊàëÂÄëÈÄèÈÅé‰ΩøÁî®ÁÆóË°ìÂïèÈ°åËá™Ë®ÇË≥áÊñôÈõÜÂØ¶Ë≠âË≠âÊòé LLM ÂèØ‰ª•Â≠∏Áøí‰ª£Êï∏ÁµêÊßã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÂà©Áî®‰ª£Êï∏ÁµêÊßãÂèØ‰ª•Â¢ûÂº∑ LLM ÁöÑÁÆóË°ìËÉΩÂäõÔºå‰∏¶Êèê‰æõË¶ãËß£‰ª•ÊîπÂñÑÂÖ∂ÁÆóË°ìË°®Áèæ„ÄÇ

##### **NormXLogit: The Head-on-Top Never Lies**
2411.16252v1 by Sina Abbasi, Mohammad Reza Modarres, Mohammad Taher Pilehvar

The Transformer architecture has emerged as the dominant choice for building
large language models (LLMs). However, with new LLMs emerging on a frequent
basis, it is important to consider the potential value of architecture-agnostic
approaches that can provide interpretability across a variety of architectures.
Despite recent successes in the interpretability of LLMs, many existing
approaches rely on complex methods that are often tied to a specific model
design and come with a significant computational cost. To address these
limitations, we propose a novel technique, called NormXLogit, for assessing the
significance of individual input tokens. This method operates based on the
input and output representations associated with each token. First, we
demonstrate that during the pre-training of LLMs, the norms of word embeddings
capture the importance of input tokens. Second, we reveal a significant
relationship between a token's importance and the extent to which its
representation can resemble the model's final prediction. Through extensive
analysis, we show that our approach consistently outperforms existing
gradient-based methods in terms of faithfulness. Additionally, our method
achieves better performance in layer-wise explanations compared to the most
prominent architecture-specific methods.

ÊëòË¶ÅÔºöTransformer Êû∂ÊßãÂ∑≤ÊàêÁÇ∫Âª∫ÊßãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑ‰∏ªÊµÅÈÅ∏Êìá„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÊñ∞ÁöÑ LLM ‰∏çÊñ∑Âá∫ÁèæÔºåÂõ†Ê≠§ËÄÉÈáèËàáÊû∂ÊßãÁÑ°ÈóúÁöÑÊñπÊ≥ïÁöÑÊΩõÂú®ÂÉπÂÄºÈùûÂ∏∏ÈáçË¶ÅÔºåÈÄô‰∫õÊñπÊ≥ïÂèØ‰ª•Âú®ÂêÑÁ®ÆÊû∂Êßã‰∏≠Êèê‰æõÂèØËß£ÈáãÊÄß„ÄÇÂÑòÁÆ° LLM ÁöÑÂèØËß£ÈáãÊÄßÊúÄËøëÂèñÂæóÊàêÂäüÔºå‰ΩÜË®±Â§öÁèæÊúâÊñπÊ≥ï‰æùË≥¥ÊñºË§áÈõúÁöÑÊñπÊ≥ïÔºåÈÄô‰∫õÊñπÊ≥ïÈÄöÂ∏∏ËàáÁâπÂÆöÊ®°ÂûãË®≠Ë®àÁõ∏ÈóúÔºå‰∏îË®àÁÆóÊàêÊú¨ÂæàÈ´ò„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫ NormXLogit ÁöÑÊñ∞ÊäÄË°ìÔºåÁî®ÊñºË©ï‰º∞ÂÄãÂà•Ëº∏ÂÖ•Ê®ôË®òÁöÑÈáçË¶ÅÊÄß„ÄÇÊ≠§ÊñπÊ≥ïÊ†πÊìöËàáÊØèÂÄãÊ®ôË®òÁõ∏ÈóúÁöÑËº∏ÂÖ•ÂíåËº∏Âá∫Ë°®Á§∫ÈÅã‰Ωú„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëË≠âÊòéÂú® LLM ÁöÑÈ†êË®ìÁ∑¥ÊúüÈñìÔºåË©ûÂµåÂÖ•ÁöÑÁØÑÊï∏ÊúÉÊì∑ÂèñËº∏ÂÖ•Ê®ôË®òÁöÑÈáçË¶ÅÊÄß„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÊè≠Á§∫Ê®ôË®òÁöÑÈáçË¶ÅÊÄßËàáÂÖ∂Ë°®Á§∫Âú®Â§öÂ§ßÁ®ãÂ∫¶‰∏äÈ°û‰ººÊ®°ÂûãÊúÄÁµÇÈ†êÊ∏¨‰πãÈñìÁöÑÈ°ØËëóÈóú‰øÇ„ÄÇÈÄèÈÅéÂª£Ê≥õÁöÑÂàÜÊûêÔºåÊàëÂÄëË°®ÊòéÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®Âø†ÂØ¶Â∫¶ÊñπÈù¢ÂßãÁµÇÂÑ™ÊñºÁèæÊúâÁöÑÂü∫ÊñºÊ¢ØÂ∫¶ÁöÑÂÅöÊ≥ï„ÄÇÊ≠§Â§ñÔºåËàáÊúÄÈ°ØËëóÁöÑÁâπÂÆöÊû∂ÊßãÊñπÊ≥ïÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®ÈÄêÂ±§Ëß£Èáã‰∏≠Áç≤ÂæóÊõ¥Â•ΩÁöÑÊïàËÉΩ„ÄÇ

##### **Transparent Neighborhood Approximation for Text Classifier Explanation**
2411.16251v1 by Yi Cai, Arthur Zimek, Eirini Ntoutsi, Gerhard Wunder

Recent literature highlights the critical role of neighborhood construction
in deriving model-agnostic explanations, with a growing trend toward deploying
generative models to improve synthetic instance quality, especially for
explaining text classifiers. These approaches overcome the challenges in
neighborhood construction posed by the unstructured nature of texts, thereby
improving the quality of explanations. However, the deployed generators are
usually implemented via neural networks and lack inherent explainability,
sparking arguments over the transparency of the explanation process itself. To
address this limitation while preserving neighborhood quality, this paper
introduces a probability-based editing method as an alternative to black-box
text generators. This approach generates neighboring texts by implementing
manipulations based on in-text contexts. Substituting the generator-based
construction process with recursive probability-based editing, the resultant
explanation method, XPROB (explainer with probability-based editing), exhibits
competitive performance according to the evaluation conducted on two real-world
datasets. Additionally, XPROB's fully transparent and more controllable
construction process leads to superior stability compared to the
generator-based explainers.

ÊëòË¶ÅÔºöËøëÊúüÁöÑÊñáÁçªÂº∑Ë™ø‰∫ÜÈÑ∞ÂüüÂª∫ÊßãÂú®Êé®Â∞éËàáÊ®°ÂûãÁÑ°ÈóúÁöÑËß£Èáã‰∏≠ÊâÄÊâÆÊºîÁöÑÈáçË¶ÅËßíËâ≤Ôºå‰∏¶ÊúùËëóÈÉ®ÁΩ≤ÁîüÊàêÊ®°Âûã‰ª•ÊîπÂñÑÂêàÊàêÂØ¶‰æãÂìÅË≥™ÁöÑÊñπÂêëÁôºÂ±ïÔºåÁâπÂà•ÊòØÈáùÂ∞çËß£ÈáãÊñáÂ≠óÂàÜÈ°ûÂô®„ÄÇÈÄô‰∫õÊñπÊ≥ïÂÖãÊúç‰∫ÜÊñáÂ≠óÈùûÁµêÊßãÂåñÊÄßË≥™Âú®ÈÑ∞ÂüüÂª∫Êßã‰∏≠Áî¢ÁîüÁöÑÊåëÊà∞ÔºåÈÄ≤ËÄåÊèêÂçá‰∫ÜËß£ÈáãÁöÑÂìÅË≥™„ÄÇÁÑ∂ËÄåÔºåÊâÄÈÉ®ÁΩ≤ÁöÑÁîüÊàêÂô®ÈÄöÂ∏∏ÈÄèÈÅéÁ•ûÁ∂ìÁ∂≤Ë∑ØÂØ¶‰ΩúÔºå‰∏îÁº∫‰πèÂÖßÂú®ÁöÑÂèØËß£ÈáãÊÄßÔºåÂºïÁôº‰∫ÜÂ∞çÊñºËß£ÈáãÈÅéÁ®ãÊú¨Ë∫´ÈÄèÊòéÂ∫¶ÁöÑÁà≠Ë´ñ„ÄÇÁÇ∫‰∫ÜÂú®Á∂≠ÊåÅÈÑ∞ÂüüÂìÅË≥™ÁöÑÂêåÊôÇËß£Ê±∫Ê≠§ÈôêÂà∂ÔºåÊú¨ÊñáÂºïÂÖ•‰∫ÜÂü∫ÊñºÊ©üÁéáÁöÑÁ∑®ËºØÊñπÊ≥ïÔºå‰ΩúÁÇ∫ÈªëÁÆ±ÊñáÂ≠óÁîüÊàêÂô®ÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇÊ≠§ÊñπÊ≥ïÈÄèÈÅéÂØ¶‰ΩúÂü∫ÊñºÊñáÂ≠óÂÖßÊñáËÑàÁöÑÊìçÊéß‰æÜÁî¢ÁîüÈÑ∞ËøëÊñáÂ≠ó„ÄÇÈÄèÈÅé‰ª•ÈÅûËø¥ÁöÑÂü∫ÊñºÊ©üÁéáÁöÑÁ∑®ËºØÂèñ‰ª£Âü∫ÊñºÁîüÊàêÂô®ÁöÑÂª∫ÊßãÈÅéÁ®ãÔºåÊâÄÁî¢ÁîüÁöÑËß£ÈáãÊñπÊ≥ï XPROBÔºàÂü∫ÊñºÊ©üÁéáÁ∑®ËºØÁöÑËß£ÈáãÂô®ÔºâÂú®ÈáùÂ∞çÂÖ©ÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜÈÄ≤Ë°åÁöÑË©ï‰º∞‰∏≠Â±ïÁèæ‰∫ÜÂÖ∑ÊúâÁ´∂Áà≠ÂäõÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåËàáÂü∫ÊñºÁîüÊàêÂô®ÁöÑËß£ÈáãÂô®Áõ∏ÊØîÔºåXPROB ÂÆåÂÖ®ÈÄèÊòé‰∏îÊõ¥ÂèØÊéßÁöÑÂª∫ÊßãÈÅéÁ®ãÔºåÂ∏∂‰æÜ‰∫ÜÂÑ™Áï∞ÁöÑÁ©©ÂÆöÊÄß„ÄÇ

##### **DoubleCCA: Improving Foundation Model Group Robustness with Random Sentence Embeddings**
2411.16236v1 by Hong Liu, Yitong Lu

This paper presents a novel method to improve the robustness of foundation
models to group-based biases. We propose a simple yet effective method, called
DoubleCCA, that leverages random sentences and Canonical Correlation Analysis
(CCA) to enrich the text embeddings of the foundation model. First, we generate
various random sentences that augment the original prompts, which extends the
original prompts with random words or character sequences. Second, we use an
additional sentence embedding model to generate different text embeddings with
respect to these random sentences. We then use CCA double twice to align the
representations and reconstruct them back to the original representation space.
We demonstrate the effectiveness of our method on a variety of tasks and
datasets, showing that it outperforms existing methods in terms of both
performance and robustness. Our method is simple to implement and can be easily
integrated into existing models, making it a practical solution for improving
the robustness of foundation models to group-based biases.

ÊëòË¶ÅÔºöÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ïÔºå‰ª•ÊèêÈ´òÂü∫Á§éÊ®°ÂûãÂ∞çÁæ§È´îÂÅèË¶ãÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ∞°ÂñÆ‰ΩÜÊúâÊïàÁöÑÊñπÊ≥ïÔºåÁ®±ÁÇ∫ DoubleCCAÔºåÂÆÉÂà©Áî®Èö®Ê©üÂè•Â≠êÂíåÂÖ∏ÂûãÁõ∏ÈóúÂàÜÊûê (CCA) ‰æÜË±êÂØåÂü∫Á§éÊ®°ÂûãÁöÑÊñáÂ≠óÂµåÂÖ•„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÁîüÊàêÂêÑÁ®ÆÈö®Ê©üÂè•Â≠ê‰æÜÊì¥ÂÖÖÂéüÂßãÊèêÁ§∫ÔºåÂÖ∂‰∏≠Áî®Èö®Ê©üÂ≠óË©ûÊàñÂ≠óÂÖÉÂ∫èÂàó‰æÜÂª∂‰º∏ÂéüÂßãÊèêÁ§∫„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄë‰ΩøÁî®‰∏ÄÂÄãÈ°çÂ§ñÁöÑÂè•Â≠êÂµåÂÖ•Ê®°ÂûãÔºåÈáùÂ∞çÈÄô‰∫õÈö®Ê©üÂè•Â≠êÁîüÊàê‰∏çÂêåÁöÑÊñáÂ≠óÂµåÂÖ•„ÄÇÊé•ËëóÔºåÊàëÂÄë‰ΩøÁî® CCA ÂÖ©Ê¨°‰æÜÊØîÂ∞çÈÄô‰∫õË°®ÂæµÔºå‰∏¶Â∞áÂÆÉÂÄëÈáçÂª∫ÂõûÂéüÂßãË°®ÂæµÁ©∫Èñì„ÄÇÊàëÂÄëÂú®ÂêÑÁ®Æ‰ªªÂãôÂíåË≥áÊñôÈõÜ‰∏äÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåÁµêÊûúÈ°ØÁ§∫ÔºåÂÆÉÂú®ÊïàËÉΩÂíåÁ©©ÂÅ•ÊÄßÊñπÈù¢ÈÉΩÂÑ™ÊñºÁèæÊúâÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÊñπÊ≥ïÊòìÊñºÂØ¶‰ΩúÔºå‰∏îÂèØ‰ª•ËºïÈ¨ÜÊï¥ÂêàÂà∞ÁèæÊúâÊ®°Âûã‰∏≠Ôºå‰ΩøÂÖ∂ÊàêÁÇ∫‰∏ÄÁ®ÆÂØ¶Áî®ÁöÑËß£Ê±∫ÊñπÊ°àÔºåÁî®ÊñºÊèêÈ´òÂü∫Á§éÊ®°ÂûãÂ∞çÁæ§È´îÂÅèË¶ãÁöÑÁ©©ÂÅ•ÊÄß„ÄÇ

##### **MH-MoE:Multi-Head Mixture-of-Experts**
2411.16205v1 by Shaohan Huang, Xun Wu, Shuming Ma, Furu Wei

Multi-Head Mixture-of-Experts (MH-MoE) demonstrates superior performance by
using the multi-head mechanism to collectively attend to information from
various representation spaces within different experts. In this paper, we
present a novel implementation of MH-MoE that maintains both FLOPs and
parameter parity with sparse Mixture of Experts models. Experimental results on
language models show that the new implementation yields quality improvements
over both vanilla MoE and fine-grained MoE models. Additionally, our
experiments demonstrate that MH-MoE is compatible with 1-bit Large Language
Models (LLMs) such as BitNet.

ÊëòË¶ÅÔºöÂ§öÈ†≠Â∞àÂÆ∂Ê∑∑ÂêàÔºàMH-MoEÔºâÈÄèÈÅé‰ΩøÁî®Â§öÈ†≠Ê©üÂà∂‰æÜÂÖ±ÂêåÈóúÊ≥®‰æÜËá™‰∏çÂêåÂ∞àÂÆ∂ÂÖßÈÉ®ÂêÑÁ®ÆË°®Á§∫Á©∫ÈñìÁöÑË≥áË®äÔºåÂ±ïÁ§∫Âá∫ÂÑ™Ë∂äÁöÑÊïàËÉΩ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®Æ MH-MoE ÁöÑÊñ∞Á©éÂØ¶‰ΩúÔºåÂÆÉÂêåÊôÇÁ∂≠ÊåÅ‰∫ÜÁ®ÄÁñèÂ∞àÂÆ∂Ê∑∑ÂêàÊ®°ÂûãÁöÑ FLOP ÂíåÂèÉÊï∏Âπ≥ÂÉπ„ÄÇË™ûË®ÄÊ®°ÂûãÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÊñ∞ÁöÑÂØ¶‰ΩúÂú®ÂÇ≥Áµ± MoE ÂíåÁ¥∞Á≤íÂ∫¶ MoE Ê®°Âûã‰∏äÈÉΩÁî¢Áîü‰∫ÜÂìÅË≥™ÁöÑÊèêÂçá„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÂØ¶È©óË≠âÊòé MH-MoE Ëàá 1 ‰ΩçÂÖÉÁöÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÔºå‰æãÂ¶Ç BitNet Áõ∏ÂÆπ„ÄÇ

##### **Video-Text Dataset Construction from Multi-AI Feedback: Promoting Weak-to-Strong Preference Learning for Video Large Language Models**
2411.16201v1 by Hao Yi, Qingyang Li, Yulan Hu, Fuzheng Zhang, Di Zhang, Yong Liu

High-quality video-text preference data is crucial for Multimodal Large
Language Models (MLLMs) alignment. However, existing preference data is very
scarce. Obtaining VQA preference data for preference training is costly, and
manually annotating responses is highly unreliable, which could result in
low-quality pairs. Meanwhile, AI-generated responses controlled by temperature
adjustment lack diversity. To address these issues, we propose a high-quality
VQA preference dataset, called \textit{\textbf{M}ultiple \textbf{M}ultimodal
\textbf{A}rtificial \textbf{I}ntelligence \textbf{P}reference Datasets in
\textbf{V}QA} (\textbf{MMAIP-V}), which is constructed by sampling from the
response distribution set and using an external scoring function for response
evaluation. Furthermore, to fully leverage the preference knowledge in MMAIP-V
and ensure sufficient optimization, we propose \textit{\textbf{Iter}ative
\textbf{W}eak-to-\textbf{S}trong \textbf{R}einforcement \textbf{L}earning from
\textbf{AI} \textbf{F}eedback for video MLLMs} (\textbf{Iter-W2S-RLAIF}), a
framework that gradually enhances MLLMs' alignment capabilities by iteratively
updating the reference model and performing parameter extrapolation. Finally,
we propose an unbiased and information-complete evaluation scheme in VQA
evaluation. Experiments demonstrate that MMAIP-V is beneficial for MLLMs in
preference learning and Iter-W2S-RLAIF fully exploits the alignment information
in MMAIP-V. We believe that the proposed automatic VQA preference data
generation pipeline based on AI feedback can greatly promote future work in the
MLLMs alignment. \textbf{Code and dataset are available}
\href{https://anonymous.4open.science/r/MMAIP-V_Iter-W2S-RLAIF-702F}{MMAIP-V\_Iter-W2S-RLAIF-702F}.

ÊëòË¶ÅÔºöÈ´òË¥®ÈáèÂΩ±ÁâáÊñáÂ≠óÂÅèÂ•ΩË≥áÊñôÂ∞çÊñºÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) ÁöÑÊØîÂ∞çËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÂÅèÂ•ΩË≥áÊñôÈùûÂ∏∏Á®ÄÂ∞ë„ÄÇÂèñÂæó VQA ÂÅèÂ•ΩË≥áÊñô‰ª•ÈÄ≤Ë°åÂÅèÂ•ΩË®ìÁ∑¥ÁöÑÊàêÊú¨ÂæàÈ´òÔºåËÄåÊâãÂãïË®ªËß£ÂõûÊáâÁöÑÂèØÈù†ÊÄßÊ•µ‰ΩéÔºåÂèØËÉΩÊúÉÂ∞éËá¥‰ΩéÂìÅË≥™ÁöÑÈÖçÂ∞ç„ÄÇÂêåÊôÇÔºåÁî±Ê∫´Â∫¶Ë™øÊï¥ÊéßÂà∂ÁöÑ AI ÁîüÊàêÁöÑÂõûÊáâÁº∫‰πèÂ§öÊ®£ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÈ´òÂìÅË≥™ÁöÑ VQA ÂÅèÂ•ΩË≥áÊñôÈõÜÔºåÁ®±ÁÇ∫„ÄåÂ§öÊ®°ÊÖãÂ§öÈáç‰∫∫Â∑•Êô∫ÊÖß VQA ÂÅèÂ•ΩË≥áÊñôÈõÜ„Äç(MMAIP-V)ÔºåÂÖ∂ÈÄèÈÅéÂæûÂõûÊáâÂàÜ‰ΩàÈõÜ‰∏≠ÂèñÊ®£‰∏¶‰ΩøÁî®Â§ñÈÉ®Ë©ïÂàÜÂáΩÊï∏Â∞çÂõûÊáâÈÄ≤Ë°åË©ï‰º∞‰æÜÂª∫Êßã„ÄÇÊ≠§Â§ñÔºåÁÇ∫‰∫ÜÂÖÖÂàÜÂà©Áî® MMAIP-V ‰∏≠ÁöÑÂÅèÂ•ΩÁü•Ë≠ò‰∏¶Á¢∫‰øùÂÖÖÂàÜÁöÑÊúÄ‰Ω≥ÂåñÔºåÊàëÂÄëÊèêÂá∫„ÄåÈÄèÈÅé AI ÂõûÈ•ãÈÄ≤Ë°åÂΩ±Áâá MLLM ÁöÑÂèçË¶ÜÂº±ËΩâÂº∑Âº∑ÂåñÂ≠∏Áøí„Äç(Iter-W2S-RLAIF)ÔºåÈÄôÊòØ‰∏ÄÂÄãÈÄèÈÅéÂèçË¶ÜÊõ¥Êñ∞ÂèÉËÄÉÊ®°Âûã‰∏¶Âü∑Ë°åÂèÉÊï∏Â§ñÊé®‰æÜÈÄêÊº∏ÊèêÂçá MLLM ÊØîÂ∞çËÉΩÂäõÁöÑÊû∂Êßã„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂú® VQA Ë©ï‰º∞‰∏≠ÊèêÂá∫‰∏ÄÂÄãÁÑ°ÂÅèË¶ã‰∏îË≥áË®äÂÆåÊï¥ÁöÑË©ï‰º∞ÊñπÊ°à„ÄÇÂØ¶È©óË≠âÊòéÔºåMMAIP-V ÊúâÂä©Êñº MLLM ÈÄ≤Ë°åÂÅèÂ•ΩÂ≠∏ÁøíÔºåËÄå Iter-W2S-RLAIF ÂâáÂÖÖÂàÜÂà©Áî® MMAIP-V ‰∏≠ÁöÑÊØîÂ∞çË≥áË®ä„ÄÇÊàëÂÄëÁõ∏‰ø°ÔºåÈÄôÂÄãÂü∫Êñº AI ÂõûÈ•ãÁöÑËá™Âãï VQA ÂÅèÂ•ΩË≥áÊñôÁî¢ÁîüÁÆ°ÈÅìÔºåÂèØ‰ª•Ê•µÂ§ßÂú∞‰øÉÈÄ≤Êú™‰æÜÂú® MLLM ÊØîÂ∞çÊñπÈù¢ÁöÑÁ†îÁ©∂„ÄÇ**Á®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜÂ∑≤ÊñºÊ≠§ËôïÊèê‰æõ**\href{https://anonymous.4open.science/r/MMAIP-V_Iter-W2S-RLAIF-702F}{MMAIP-V\_Iter-W2S-RLAIF-702F}„ÄÇ

##### **Enhancing Multi-Agent Consensus through Third-Party LLM Integration: Analyzing Uncertainty and Mitigating Hallucinations in Large Language Models**
2411.16189v1 by Zhihua Duan, Jialin Wang

Large Language Models (LLMs) still face challenges when dealing with complex
reasoning tasks, often resulting in hallucinations, which limit the practical
application of LLMs. To alleviate this issue, this paper proposes a new method
that integrates different LLMs to expand the knowledge boundary, reduce
dependence on a single model, and promote in-depth debate among agents. The
main contributions include: 1) Introducing third-party LLMs to adjust the
attention weights of agents through uncertainty estimation and confidence
analysis, optimizing consensus formation in multi-agent systems; 2) Experiments
on arithmetic datasets have validated the effectiveness of the method,
surpassing traditional multi-agent baselines. This research provides a new
perspective for large models to alleviate hallucination phenomena when dealing
with complex tasks.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ËôïÁêÜË§áÈõúÊé®ÁêÜ‰ªªÂãôÊôÇ‰ªçÈù¢Ëá®ÊåëÊà∞ÔºåÁ∂ìÂ∏∏Â∞éËá¥ÂπªË¶∫ÔºåÈÄôÈôêÂà∂‰∫Ü LLM ÁöÑÂØ¶ÈöõÊáâÁî®„ÄÇÁÇ∫‰∫ÜÁ∑©Ëß£ÈÄôÂÄãÂïèÈ°åÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ïÔºåÂ∞á‰∏çÂêåÁöÑ LLM Êï¥ÂêàËµ∑‰æÜ‰ª•Êì¥Â±ïÁü•Ë≠òÈÇäÁïåÔºåÊ∏õÂ∞ëÂ∞çÂñÆ‰∏ÄÊ®°ÂûãÁöÑ‰æùË≥¥Ôºå‰∏¶‰øÉÈÄ≤‰ª£ÁêÜ‰πãÈñìÁöÑÊ∑±ÂÖ•ËæØË´ñ„ÄÇ‰∏ªË¶ÅË≤¢ÁçªÂåÖÊã¨Ôºö1) ÂºïÂÖ•Á¨¨‰∏âÊñπ LLMÔºåÈÄèÈÅé‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÂíå‰ø°ÂøÉÂàÜÊûê‰æÜË™øÊï¥‰ª£ÁêÜÁöÑÊ≥®ÊÑèÂäõÊ¨äÈáçÔºåÂÑ™ÂåñÂ§ö‰ª£ÁêÜÁ≥ªÁµ±‰∏≠ÁöÑÂÖ±Ë≠òÂΩ¢ÊàêÔºõ2) Âú®ÁÆóË°ìÊï∏ÊìöÈõÜ‰∏äÁöÑÂØ¶È©óÈ©óË≠â‰∫ÜË©≤ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåË∂ÖË∂ä‰∫ÜÂÇ≥Áµ±ÁöÑÂ§ö‰ª£ÁêÜÂü∫Á∑ö„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÁÇ∫Â§ßÂûãÊ®°ÂûãÂú®ËôïÁêÜË§áÈõú‰ªªÂãôÊôÇÊ∏õËºïÂπªË¶∫ÁèæË±°Êèê‰æõ‰∫ÜÊñ∞ÁöÑËßÄÈªû„ÄÇ

##### **SALOVA: Segment-Augmented Long Video Assistant for Targeted Retrieval and Routing in Long-Form Video Analysis**
2411.16173v1 by Junho Kim, Hyunjun Kim, Hosu Lee, Yong Man Ro

Despite advances in Large Multi-modal Models, applying them to long and
untrimmed video content remains challenging due to limitations in context
length and substantial memory overhead. These constraints often lead to
significant information loss and reduced relevance in the model responses. With
the exponential growth of video data across web platforms, understanding
long-form video is crucial for advancing generalized intelligence. In this
paper, we introduce SALOVA: Segment-Augmented LOng Video Assistant, a novel
video-LLM framework designed to enhance the comprehension of lengthy video
content through targeted retrieval process. We address two main challenges to
achieve it: (i) We present the SceneWalk dataset, a high-quality collection of
87.8K long videos, each densely captioned at the segment level to enable models
to capture scene continuity and maintain rich descriptive context. (ii) We
develop robust architectural designs integrating dynamic routing mechanism and
spatio-temporal projector to efficiently retrieve and process relevant video
segments based on user queries. Our framework mitigates the limitations of
current video-LMMs by allowing for precise identification and retrieval of
relevant video segments in response to queries, thereby improving the
contextual relevance of the generated responses. Through extensive experiments,
SALOVA demonstrates enhanced capability in processing complex long-form videos,
showing significant capability to maintain contextual integrity across extended
sequences.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§ßÂûãÂ§öÊ®°ÊÖãÊ®°ÂûãÊúâÈÄ≤Â±ïÔºå‰ΩÜÁî±ÊñºËÑàÁµ°Èï∑Â∫¶ÂíåÂ§ßÈáèË®òÊÜ∂È´îÈñãÈä∑ÁöÑÈôêÂà∂ÔºåÂ∞áÂÆÉÂÄëÊáâÁî®ÊñºÈï∑‰∏îÊú™‰øÆÂâ™ÁöÑÂΩ±ÁâáÂÖßÂÆπ‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÈÄô‰∫õÈôêÂà∂ÈÄöÂ∏∏ÊúÉÂ∞éËá¥Ê®°ÂûãÂõûÊáâ‰∏≠Â§ßÈáèË≥áË®äÈÅ∫Â§±ÂíåÁõ∏ÈóúÊÄßÈôç‰Ωé„ÄÇÈö®ËëóÁ∂≤Ë∑ØÂπ≥Âè∞‰∏äÂΩ±ÁâáË≥áÊñôÁöÑÊåáÊï∏Á¥öÊàêÈï∑ÔºåÁêÜËß£Èï∑ÁØáÂΩ±ÁâáÂ∞çÊñºÊé®ÈÄ≤Âª£Áæ©Êô∫ÊÖßËá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π SALOVAÔºöÂçÄÊÆµÂ¢ûÂº∑Èï∑ÂΩ±ÁâáÂä©ÁêÜÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÂΩ±Áâá LLM Êû∂ÊßãÔºåÊó®Âú®ÈÄèÈÅéÁõÆÊ®ôÊì∑ÂèñÊµÅÁ®ãÂ¢ûÂº∑Â∞çÈï∑ÁØáÂΩ±ÁâáÂÖßÂÆπÁöÑÁêÜËß£„ÄÇÊàëÂÄëËß£Ê±∫‰∫ÜÂØ¶ÁèæÊ≠§ÁõÆÊ®ôÁöÑÂÖ©ÂÄã‰∏ªË¶ÅÊåëÊà∞Ôºö(i) ÊàëÂÄëÊèêÂá∫ SceneWalk Ë≥áÊñôÈõÜÔºåÈÄôÊòØ‰∏ÄÂÄãÈ´òÂìÅË≥™ÁöÑ 87.8K Èï∑ÂΩ±ÁâáÈõÜÂêàÔºåÊØèÂÄãÂΩ±ÁâáÈÉΩÂú®ÂçÄÊÆµÂ±§Á¥öÂØÜÈõÜÂä†Ë®ªÂ≠óÂπïÔºå‰ª•‰ΩøÊ®°ÂûãËÉΩÂ§†Êì∑ÂèñÂ†¥ÊôØÈÄ£Á∫åÊÄß‰∏¶Á∂≠ÊåÅË±êÂØåÁöÑÊèèËø∞ÊÄßËÑàÁµ°„ÄÇ(ii) ÊàëÂÄëÈñãÁôºÂº∑ÂÅ•ÁöÑÊû∂ÊßãË®≠Ë®àÔºåÊï¥ÂêàÂãïÊÖãË∑ØÁî±Ê©üÂà∂ÂíåÊôÇÁ©∫ÊäïÂΩ±ÂÑÄÔºå‰ª•ÊúâÊïàÂú∞Ê†πÊìö‰ΩøÁî®ËÄÖÊü•Ë©¢Êì∑ÂèñÂíåËôïÁêÜÁõ∏ÈóúÂΩ±ÁâáÂçÄÊÆµ„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÈÄèÈÅéÂÖÅË®±Á≤æÁ¢∫Ë≠òÂà•ÂíåÊì∑ÂèñÁõ∏ÈóúÂΩ±ÁâáÂçÄÊÆµ‰æÜÂõûÊáâÊü•Ë©¢ÔºåÂæûËÄåÊ∏õËºïÁï∂ÂâçÂΩ±Áâá LMM ÁöÑÈôêÂà∂ÔºåÈÄ≤ËÄåÊîπÂñÑÁîüÊàêÂõûÊáâÁöÑËÑàÁµ°Áõ∏ÈóúÊÄß„ÄÇÈÄèÈÅéÂª£Ê≥õÁöÑÂØ¶È©óÔºåSALOVA Â±ïÁ§∫‰∫ÜËôïÁêÜË§áÈõúÈï∑ÁØáÂΩ±ÁâáÁöÑÂ¢ûÂº∑ÂäüËÉΩÔºåÈ°ØÁ§∫Âá∫Âú®Âª∂‰º∏Â∫èÂàó‰∏≠Á∂≠ÊåÅËÑàÁµ°ÂÆåÊï¥ÊÄßÁöÑÈ°ØËëóËÉΩÂäõ„ÄÇ

##### **MixPE: Quantization and Hardware Co-design for Efficient LLM Inference**
2411.16158v1 by Yu Zhang, Mingzi Wang, Lancheng Zou, Wulong Liu, Hui-Ling Zhen, Mingxuan Yuan, Bei Yu

Transformer-based large language models (LLMs) have achieved remarkable
success as model sizes continue to grow, yet their deployment remains
challenging due to significant computational and memory demands. Quantization
has emerged as a promising solution, and state-of-the-art quantization
algorithms for LLMs introduce the need for mixed-precision matrix
multiplication (mpGEMM), where lower-precision weights are multiplied with
higher-precision activations. Despite its benefits, current hardware
accelerators such as GPUs and TPUs lack native support for efficient mpGEMM,
leading to inefficient dequantization operations in the main sequential loop.
To address this limitation, we introduce MixPE, a specialized mixed-precision
processing element designed for efficient low-bit quantization in LLM
inference. MixPE leverages two key innovations to minimize dequantization
overhead and unlock the full potential of low-bit quantization. First,
recognizing that scale and zero point are shared within each quantization
group, we propose performing dequantization after per-group mpGEMM,
significantly reducing dequantization overhead. Second, instead of relying on
conventional multipliers, MixPE utilizes efficient shift\&add operations for
multiplication, optimizing both computation and energy efficiency. Our
experimental results demonstrate that MixPE surpasses the state-of-the-art
quantization accelerators by $2.6\times$ speedup and $1.4\times$ energy
reduction.

ÊëòË¶ÅÔºö<paragraph>Èö®ËëóÊ®°ÂûãË¶èÊ®°ÊåÅÁ∫åÊì¥Â§ßÔºåÂü∫Êñº Transformer ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤ÂèñÂæóÈ°ØËëóÊàêÂäüÔºå‰ΩÜÁî±ÊñºÂÖ∂ÈæêÂ§ßÁöÑÈÅãÁÆóÂíåË®òÊÜ∂È´îÈúÄÊ±ÇÔºåÈÉ®ÁΩ≤‰ªçÊòØ‰∏ÄÈ†ÖÊåëÊà∞„ÄÇÈáèÂåñÂ∑≤ÊàêÁÇ∫‰∏ÄÁ®ÆÂæàÊúâÂâçÊôØÁöÑËß£Ê±∫ÊñπÊ°àÔºåËÄå LLM ÁöÑÊúÄÂÖàÈÄ≤ÈáèÂåñÊºîÁÆóÊ≥ïÂºïÂÖ•‰∫ÜÊ∑∑ÂêàÁ≤æÂ∫¶Áü©Èô£‰πòÊ≥ï (mpGEMM) ÁöÑÈúÄÊ±ÇÔºåÂÖ∂‰∏≠ËºÉ‰ΩéÁ≤æÂ∫¶ÁöÑÊ¨äÈáçÊúÉËàáËºÉÈ´òÁ≤æÂ∫¶ÁöÑÊøÄÊ¥ªÁõ∏‰πò„ÄÇÂÑòÁÆ°ÊúâÈÄô‰∫õÂÑ™ÈªûÔºå‰ΩÜÁõÆÂâçÁöÑÁ°¨È´îÂä†ÈÄüÂô®Ôºà‰æãÂ¶Ç GPU Âíå TPUÔºâÁº∫‰πèÂ∞çÈ´òÊïà mpGEMM ÁöÑÂéüÁîüÊîØÊè¥ÔºåÂ∞éËá¥‰∏ªÂ∫èÂêëËø¥Âúà‰∏≠Âá∫Áèæ‰ΩéÊïàÁéáÁöÑÂéªÈáèÂåñ‰ΩúÊ•≠„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÈôêÂà∂ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü MixPEÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂ∞àÈñÄÁöÑÊ∑∑ÂêàÁ≤æÂ∫¶ËôïÁêÜÂÖÉ‰ª∂ÔºåË®≠Ë®àÁî®ÊñºÂú® LLM Êé®Ë´ñ‰∏≠Âü∑Ë°åÈ´òÊïàÁöÑ‰Ωé‰ΩçÂÖÉÈáèÂåñ„ÄÇMixPE Âà©Áî®ÂÖ©È†ÖÈóúÈçµÂâµÊñ∞‰æÜÊúÄÂ∞èÂåñÂéªÈáèÂåñÈñãÈä∑Ôºå‰∏¶ÁôºÊèÆ‰Ωé‰ΩçÂÖÉÈáèÂåñÁöÑÂÖ®ÈÉ®ÊΩõÂäõ„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëË™çÁü•Âà∞Á∏ÆÊîæÂíåÈõ∂ÈªûÂú®ÊØèÂÄãÈáèÂåñÁæ§ÁµÑ‰∏≠ÈÉΩÊòØÂÖ±Áî®ÁöÑÔºåÂõ†Ê≠§ÊàëÂÄëÂª∫Ë≠∞Âú®ÊØèÂÄãÁæ§ÁµÑÁöÑ mpGEMM ‰πãÂæåÂü∑Ë°åÂéªÈáèÂåñÔºåÂ§ßÂπÖÊ∏õÂ∞ëÂéªÈáèÂåñÈñãÈä∑„ÄÇÂÖ∂Ê¨°ÔºåMixPE ‰∏ç‰æùË≥¥ÂÇ≥Áµ±ÁöÑ‰πòÊ≥ïÂô®ÔºåËÄåÊòØÂà©Áî®È´òÊïàÁöÑ‰ΩçÁßªÂíåÂä†Ê≥ïÈÅãÁÆóÈÄ≤Ë°å‰πòÊ≥ïÔºåÂêåÊôÇÊúÄ‰Ω≥ÂåñÈÅãÁÆóÂíåËÉΩÊ∫êÊïàÁéá„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË≠âÊòéÔºåMixPE Âú®Âä†ÈÄüÊñπÈù¢ÊØîÊúÄÂÖàÈÄ≤ÁöÑÈáèÂåñÂä†ÈÄüÂô®Âø´‰∫Ü 2.6 ÂÄçÔºåÂú®ËÉΩÊ∫êÊ∂àËÄóÊñπÈù¢Ê∏õÂ∞ë‰∫Ü 1.4 ÂÄç„ÄÇ</paragraph>

##### **Graph Adapter of EEG Foundation Models for Parameter Efficient Fine Tuning**
2411.16155v1 by Toyotaro Suzumura, Hiroki Kanezashi, Shotaro Akahori

In diagnosing mental diseases from electroencephalography (EEG) data, neural
network models such as Transformers have been employed to capture temporal
dynamics. Additionally, it is crucial to learn the spatial relationships
between EEG sensors, for which Graph Neural Networks (GNNs) are commonly used.
However, fine-tuning large-scale complex neural network models simultaneously
to capture both temporal and spatial features increases computational costs due
to the more significant number of trainable parameters. It causes the limited
availability of EEG datasets for downstream tasks, making it challenging to
fine-tune large models effectively. We propose EEG-GraphAdapter (EGA), a
parameter-efficient fine-tuning (PEFT) approach to address these challenges.
EGA is integrated into pre-trained temporal backbone models as a GNN-based
module and fine-tuned itself alone while keeping the backbone model parameters
frozen. This enables the acquisition of spatial representations of EEG signals
for downstream tasks, significantly reducing computational overhead and data
requirements. Experimental evaluations on healthcare-related downstream tasks
of Major Depressive Disorder and Abnormality Detection demonstrate that our EGA
improves performance by up to 16.1% in the F1-score compared with the backbone
BENDR model.

ÊëòË¶ÅÔºöÂú®Âà©Áî®ËÖ¶ÈõªÂúñ (EEG) Ë≥áÊñôË®∫Êñ∑Á≤æÁ•ûÁñæÁóÖÊôÇÔºåÂ∑≤Êé°Áî®TransformerÁ≠âÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°Âûã‰æÜÊçïÊçâÊôÇÈñìÂãïÊÖã„ÄÇÊ≠§Â§ñÔºåÂ≠∏Áøí EEG ÊÑüÊ∏¨Âô®‰πãÈñìÁöÑÁ©∫ÈñìÈóú‰øÇËá≥ÈóúÈáçË¶ÅÔºåËÄåÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÈÄöÂ∏∏Áî®ÊñºÊ≠§ÁõÆÁöÑ„ÄÇÁÑ∂ËÄåÔºåÂêåÊôÇÂæÆË™øÂ§ßÂûãË§áÈõúÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°Âûã‰ª•ÊçïÊçâÊôÇÈñìÂíåÁ©∫ÈñìÁâπÂæµÊúÉÂ¢ûÂä†ÈÅãÁÆóÊàêÊú¨ÔºåÂõ†ÁÇ∫ÂèØË®ìÁ∑¥ÂèÉÊï∏Êï∏ÈáèËºÉÂ§ö„ÄÇÈÄôÂ∞éËá¥‰∏ãÊ∏∏‰ªªÂãôÁöÑ EEG Ë≥áÊñôÈõÜÂèØÁî®ÊÄßÊúâÈôêÔºå‰ΩøÂæóÊúâÊïàÂæÆË™øÂ§ßÂûãÊ®°ÂûãÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊàëÂÄëÊèêÂá∫ EEG-GraphAdapter (EGA)Ôºå‰∏ÄÁ®ÆÂèÉÊï∏È´òÊïàÂæÆË™ø (PEFT) ÊñπÊ≥ï‰æÜËß£Ê±∫ÈÄô‰∫õÊåëÊà∞„ÄÇEGA ‰ΩúÁÇ∫Âü∫Êñº GNN ÁöÑÊ®°ÁµÑÊï¥ÂêàÂà∞È†êË®ìÁ∑¥ÁöÑÊôÇÈñì‰∏ªÂππÊ®°Âûã‰∏≠Ôºå‰∏¶Âú®‰øùÊåÅ‰∏ªÂππÊ®°ÂûãÂèÉÊï∏ÂáçÁµêÁöÑÂêåÊôÇËá™Ë°åÂæÆË™ø„ÄÇÈÄô‰ΩøÂæóËÉΩÂ§†ÂèñÂæó EEG Ë®äËôüÁöÑÁ©∫ÈñìË°®Á§∫Ôºå‰ª•Áî®Êñº‰∏ãÊ∏∏‰ªªÂãôÔºåÂ§ßÂπÖÈôç‰ΩéÈÅãÁÆóË≤†ÊìîÂíåË≥áÊñôÈúÄÊ±Ç„ÄÇÂú®ËàáÈÜ´ÁôÇ‰øùÂÅ•Áõ∏ÈóúÁöÑ‰∏ãÊ∏∏‰ªªÂãôÔºàÈáçÂ∫¶ÊÜÇÈ¨±ÁóáÂíåÁï∞Â∏∏ÂÅµÊ∏¨ÔºâÁöÑÂØ¶È©óË©ï‰º∞‰∏≠ÔºåÊàëÂÄëÁöÑ EGA Ë≠âÊòéËàá‰∏ªÂππ BENDR Ê®°ÂûãÁõ∏ÊØîÔºåF1 ÂàÜÊï∏ÁöÑÊïàËÉΩÊèêÂçá‰∫Ü 16.1%„ÄÇ

##### **SKQVC: One-Shot Voice Conversion by K-Means Quantization with Self-Supervised Speech Representations**
2411.16147v1 by Youngjun Sim, Jinsung Yoon, Young-Joo Suh

One-shot voice conversion (VC) is a method that enables the transformation
between any two speakers using only a single target speaker utterance. Existing
methods often rely on complex architectures and pre-trained speaker
verification (SV) models to improve the fidelity of converted speech. Recent
works utilizing K-means quantization (KQ) with self-supervised learning (SSL)
features have proven capable of capturing content information from speech.
However, they often struggle to preserve speaking variation, such as prosodic
detail and phonetic variation, particularly with smaller codebooks. In this
work, we propose a simple yet effective one-shot VC model that utilizes the
characteristics of SSL features and speech attributes. Our approach addresses
the issue of losing speaking variation, enabling high-fidelity voice conversion
trained with only reconstruction losses, without requiring external speaker
embeddings. We demonstrate the performance of our model across 6 evaluation
metrics, with results highlighting the benefits of the speaking variation
compensation method.

ÊëòË¶ÅÔºöÂñÆÊ¨°ËÅ≤Èü≥ËΩâÊèõ (VC) ÊòØ‰∏ÄÁ®ÆÊñπÊ≥ïÔºåÂèØ‰ΩøÁî®ÂñÆ‰∏ÄÁõÆÊ®ôË™™Ë©±ËÄÖË™ûÂè•ÔºåÂú®ÂÖ©ÂÄãË™™Ë©±ËÄÖ‰πãÈñìÈÄ≤Ë°åËΩâÊèõ„ÄÇÁèæÊúâÊñπÊ≥ïÈÄöÂ∏∏‰æùË≥¥ÊñºË§áÈõúÁöÑÊû∂ÊßãÂíåÈ†êÂÖàË®ìÁ∑¥ÁöÑË™™Ë©±ËÄÖÈ©óË≠â (SV) Ê®°ÂûãÔºå‰ª•ÊèêÈ´òËΩâÊèõË™ûÈü≥ÁöÑ‰øùÁúüÂ∫¶„ÄÇÊúÄËøëÂà©Áî® K ÂùáÂÄºÈáèÂåñ (KQ) ÂíåËá™Áõ£Áù£Â≠∏Áøí (SSL) ÁâπÂæµÁöÑ‰ΩúÂìÅÂ∑≤Ë¢´Ë≠âÊòéËÉΩÂ§†ÂæûË™ûÈü≥‰∏≠Êì∑ÂèñÂÖßÂÆπË≥áË®ä„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÈÄöÂ∏∏Èõ£‰ª•‰øùÁïôË™™Ë©±ËÆäÁï∞Ôºå‰æãÂ¶ÇÈü≥Ë™øÁ¥∞ÁØÄÂíåË™ûÈü≥ËÆäÁï∞ÔºåÁâπÂà•ÊòØÂú®ËºÉÂ∞èÁöÑÁ¢ºÊú¨‰∏≠„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁ∞°ÂñÆ‰ΩÜÊúâÊïàÁöÑÂñÆÊ¨° VC Ê®°ÂûãÔºåÂÆÉÂà©Áî® SSL ÁâπÂæµÂíåË™ûÈü≥Â±¨ÊÄßÁöÑÁâπÂæµ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïËß£Ê±∫‰∫ÜÂ§±ÂéªË™™Ë©±ËÆäÁï∞ÁöÑÂïèÈ°åÔºåÂØ¶Áèæ‰∫ÜÂÉÖ‰ΩøÁî®ÈáçÂª∫ÊêçÂ§±Ë®ìÁ∑¥ÁöÑÈ´ò‰øùÁúüË™ûÈü≥ËΩâÊèõÔºåËÄå‰∏çÈúÄË¶ÅÂ§ñÈÉ®Ë™™Ë©±ËÄÖÂµåÂÖ•„ÄÇÊàëÂÄëÂú® 6 È†ÖË©ï‰º∞ÊåáÊ®ô‰∏≠Â±ïÁ§∫‰∫ÜÊàëÂÄëÊ®°ÂûãÁöÑÊïàËÉΩÔºåÁµêÊûúÁ™ÅÂá∫‰∫ÜË™™Ë©±ËÆäÁï∞Ë£úÂÑüÊñπÊ≥ïÁöÑÂÑ™Èªû„ÄÇ

##### **End-to-End Steering for Autonomous Vehicles via Conditional Imitation Co-Learning**
2411.16131v1 by Mahmoud M. Kishky, Hesham M. Eraqi, Khaled F. Elsayed

Autonomous driving involves complex tasks such as data fusion, object and
lane detection, behavior prediction, and path planning. As opposed to the
modular approach which dedicates individual subsystems to tackle each of those
tasks, the end-to-end approach treats the problem as a single learnable task
using deep neural networks, reducing system complexity and minimizing
dependency on heuristics. Conditional imitation learning (CIL) trains the
end-to-end model to mimic a human expert considering the navigational commands
guiding the vehicle to reach its destination, CIL adopts specialist network
branches dedicated to learn the driving task for each navigational command.
Nevertheless, the CIL model lacked generalization when deployed to unseen
environments. This work introduces the conditional imitation co-learning (CIC)
approach to address this issue by enabling the model to learn the relationships
between CIL specialist branches via a co-learning matrix generated by gated
hyperbolic tangent units (GTUs). Additionally, we propose posing the steering
regression problem as classification, we use a classification-regression hybrid
loss to bridge the gap between regression and classification, we also propose
using co-existence probability to consider the spatial tendency between the
steering classes. Our model is demonstrated to improve autonomous driving
success rate in unseen environment by 62% on average compared to the CIL
method.

ÊëòË¶ÅÔºöËá™ÂãïÈßïÈßõÊ∂âÂèäË§áÈõúÁöÑ‰ªªÂãôÔºå‰æãÂ¶ÇË≥áÊñôËûçÂêà„ÄÅÁâ©È´îÂíåËªäÈÅìÂÅµÊ∏¨„ÄÅË°åÁÇ∫È†êÊ∏¨ÂíåË∑ØÂæëË¶èÂäÉ„ÄÇËàáÂ∞áÂÄãÂà•Â≠êÁ≥ªÁµ±Â∞àÁî®ÊñºËôïÁêÜÊØèÂÄã‰ªªÂãôÁöÑÊ®°ÁµÑÂåñÊñπÊ≥ïÁõ∏ÂèçÔºåÁ´ØÂà∞Á´ØÊñπÊ≥ïÂ∞áÂïèÈ°åË¶ñÁÇ∫‰ΩøÁî®Ê∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÂñÆ‰∏ÄÂèØÂ≠∏Áøí‰ªªÂãôÔºåÈôç‰ΩéÁ≥ªÁµ±Ë§áÈõúÊÄß‰∏¶ÊúÄÂ∞èÂåñÂ∞çÂïüÁôºÊ≥ïÁöÑ‰æùË≥¥„ÄÇÊ¢ù‰ª∂Ê®°‰ªøÂ≠∏Áøí (CIL) Ë®ìÁ∑¥Á´ØÂà∞Á´ØÊ®°ÂûãÔºå‰ª•Ê®°Êì¨‰∫∫È°ûÂ∞àÂÆ∂ËÄÉÊÖÆÂ∞éËà™ÂëΩ‰ª§ÔºåÂºïÂ∞éËªäËºõÂà∞ÈÅîÁõÆÁöÑÂú∞ÔºåCIL Êé°Áî®Â∞àÈñÄÁ∂≤Ë∑ØÂàÜÊîØÔºåÂ∞àÈñÄÂ≠∏ÁøíÊØèÂÄãÂ∞éËà™ÂëΩ‰ª§ÁöÑÈßïÈßõ‰ªªÂãô„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåCIL Ê®°ÂûãÂú®ÈÉ®ÁΩ≤Âà∞Êú™Ë¶ãÁí∞Â¢ÉÊôÇÁº∫‰πèÊ≥õÂåñÊÄß„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÂºïÂÖ•‰∫ÜÊ¢ù‰ª∂Ê®°‰ªøÂçîÂêåÂ≠∏Áøí (CIC) ÊñπÊ≥ïÔºåÈÄèÈÅéÂïüÁî®Ê®°ÂûãÈÄèÈÅéÈñÄÊéßÈõôÊõ≤Ê≠£ÂàáÂñÆÂÖÉ (GTU) ÁîüÊàêÁöÑÂçîÂêåÂ≠∏ÁøíÁü©Èô£ÔºåÂ≠∏Áøí CIL Â∞àÂÆ∂ÂàÜÊîØ‰πãÈñìÁöÑÈóú‰øÇ‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°å„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂª∫Ë≠∞Â∞áËΩâÂêëËø¥Ê≠∏ÂïèÈ°åË¶ñÁÇ∫ÂàÜÈ°ûÔºåÊàëÂÄë‰ΩøÁî®ÂàÜÈ°ûËø¥Ê≠∏Ê∑∑ÂêàÊêçÂ§±‰æÜÂΩåÂêàËø¥Ê≠∏ÂíåÂàÜÈ°û‰πãÈñìÁöÑÂ∑ÆË∑ùÔºåÊàëÂÄëÈÇÑÂª∫Ë≠∞‰ΩøÁî®ÂÖ±Â≠òÊ©üÁéá‰æÜËÄÉÊÖÆËΩâÂêëÈ°ûÂà•‰πãÈñìÁöÑÁ©∫ÈñìË∂®Âã¢„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãË¢´Ë≠âÊòéÂèØ‰ª•Â∞áÂú®Êú™Ë¶ãÁí∞Â¢É‰∏≠ÁöÑËá™ÂãïÈßïÈßõÊàêÂäüÁéáÂπ≥ÂùáÊèêÈ´ò 62%ÔºåËàá CIL ÊñπÊ≥ïÁõ∏ÊØî„ÄÇ

##### **Med-PerSAM: One-Shot Visual Prompt Tuning for Personalized Segment Anything Model in Medical Domain**
2411.16123v1 by Hangyul Yoon, Doohyuk Jang, Jungeun Kim, Eunho Yang

Leveraging pre-trained models with tailored prompts for in-context learning
has proven highly effective in NLP tasks. Building on this success, recent
studies have applied a similar approach to the Segment Anything Model (SAM)
within a ``one-shot" framework, where only a single reference image and its
label are employed. However, these methods face limitations in the medical
domain, primarily due to SAM's essential requirement for visual prompts and the
over-reliance on pixel similarity for generating them. This dependency may lead
to (1) inaccurate prompt generation and (2) clustering of point prompts,
resulting in suboptimal outcomes. To address these challenges, we introduce
\textbf{Med-PerSAM}, a novel and straightforward one-shot framework designed
for the medical domain. Med-PerSAM uses only visual prompt engineering and
eliminates the need for additional training of the pretrained SAM or human
intervention, owing to our novel automated prompt generation process. By
integrating our lightweight warping-based prompt tuning model with SAM, we
enable the extraction and iterative refinement of visual prompts, enhancing the
performance of the pre-trained SAM. This advancement is particularly meaningful
in the medical domain, where creating visual prompts poses notable challenges
for individuals lacking medical expertise. Our model outperforms various
foundational models and previous SAM-based approaches across diverse 2D medical
imaging datasets.

ÊëòË¶ÅÔºöÂà©Áî®È†êÂÖàË®ìÁ∑¥ÁöÑÊ®°ÂûãÔºå‰∏¶ÈáùÂ∞çÁâπÂÆöÊèêÁ§∫ÈÄ≤Ë°åÊÉÖÂ¢ÉÂ≠∏ÁøíÔºåÂ∑≤Ë≠âÊòéÂú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãô‰∏≠ÈùûÂ∏∏ÊúâÊïà„ÄÇÂú®Ê≠§ÊàêÂäüÂü∫Á§é‰∏äÔºåÊúÄËøëÁöÑÁ†îÁ©∂Â∑≤Â∞áÈ°û‰ººÊñπÊ≥ïÊáâÁî®Êñº„ÄåÁâáÊÆµ‰ªª‰ΩïÊ®°Âûã„Äç(SAM)ÔºåÊé°Áî®„Äå‰∏ÄÊ¨°ÊÄß„ÄçÊû∂ÊßãÔºåÂÖ∂‰∏≠ÂÉÖ‰ΩøÁî®ÂñÆ‰∏ÄÂèÉËÄÉÂΩ±ÂÉèÂèäÂÖ∂Ê®ôÁ±§„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÂú®ÈÜ´ÁôÇÈ†òÂüüÈù¢Ëá®ÈôêÂà∂Ôºå‰∏ªË¶ÅÊòØÁî±Êñº SAM Â∞çË¶ñË¶∫ÊèêÁ§∫ÁöÑÂü∫Êú¨ÈúÄÊ±ÇÔºå‰ª•ÂèäÈÅéÂ∫¶‰æùË≥¥ÂÉèÁ¥†Áõ∏‰ººÊÄß‰æÜÁî¢ÁîüÂÆÉÂÄë„ÄÇÈÄôÁ®Æ‰æùË≥¥ÊÄßÂèØËÉΩÊúÉÂ∞éËá¥ (1) ÊèêÁ§∫Áî¢Áîü‰∏çÊ∫ñÁ¢∫Ôºå‰ª•Âèä (2) ÈªûÊèêÁ§∫Áæ§ÈõÜÔºåÂ∞éËá¥ÁµêÊûúÊ¨°‰Ω≥„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü \textbf{Med-PerSAM}ÔºåÈÄôÊòØ‰∏ÄÂÄãÂ∞àÁÇ∫ÈÜ´ÁôÇÈ†òÂüüË®≠Ë®àÁöÑÊñ∞Á©é‰∏îÁõ¥Êé•ÁöÑ‰∏ÄÊ¨°ÊÄßÊû∂Êßã„ÄÇMed-PerSAM ÂÉÖ‰ΩøÁî®Ë¶ñË¶∫ÊèêÁ§∫Â∑•Á®ãÔºå‰∏¶Ê∂àÈô§‰∫ÜÂ∞çÈ†êË®ìÁ∑¥ SAM Êàñ‰∫∫ÁÇ∫Âπ≤È†êÁöÑÈ°çÂ§ñË®ìÁ∑¥ÈúÄÊ±ÇÔºåÈÄôË¶ÅÊ≠∏ÂäüÊñºÊàëÂÄëÊñ∞Á©éÁöÑËá™ÂãïÂåñÊèêÁ§∫Áî¢ÁîüÊµÅÁ®ã„ÄÇÈÄèÈÅéÂ∞áÊàëÂÄëËºïÈáèÁ¥öÂü∫ÊñºËÆäÂΩ¢ÁöÑÊèêÁ§∫Ë™øÊï¥Ê®°ÂûãËàá SAM Êï¥ÂêàÔºåÊàëÂÄëËÉΩÂ§†ÊèêÂèñÂíåÂèçË¶ÜÊîπÂñÑË¶ñË¶∫ÊèêÁ§∫ÔºåÂ¢ûÂº∑È†êË®ìÁ∑¥ SAM ÁöÑÊïàËÉΩ„ÄÇÈÄôÈ†ÖÈÄ≤Â±ïÂú®ÈÜ´ÁôÇÈ†òÂüüÁâπÂà•ÊúâÊÑèÁæ©ÔºåÂõ†ÁÇ∫Â∞çÊñºÁº∫‰πèÈÜ´ÁôÇÂ∞àÊ•≠Áü•Ë≠òÁöÑ‰∫∫‰æÜË™™ÔºåÂª∫Á´ãË¶ñË¶∫ÊèêÁ§∫ÊúÉÊßãÊàêÈ°ØËëóÁöÑÊåëÊà∞„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÂêÑÁ®Æ 2D ÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñôÈõÜ‰∏äÂÑ™ÊñºÂêÑÁ®ÆÂü∫Á§éÊ®°ÂûãÂíåÂÖàÂâçÁöÑÂü∫Êñº SAM ÁöÑÊñπÊ≥ï„ÄÇ

##### **Why the Agent Made that Decision: Explaining Deep Reinforcement Learning with Vision Masks**
2411.16120v1 by Rui Zuo, Zifan Wang, Simon Khan, Garrett Ethan Katz, Qinru Qiu

Due to the inherent lack of transparency in deep neural networks, it is
challenging for deep reinforcement learning (DRL) agents to gain trust and
acceptance from users, especially in safety-critical applications such as
medical diagnosis and military operations. Existing methods for explaining an
agent's decision either require to retrain the agent using models that support
explanation generation or rely on perturbation-based techniques to reveal the
significance of different input features in the decision making process.
However, retraining the agent may compromise its integrity and performance,
while perturbation-based methods have limited performance and lack knowledge
accumulation or learning capabilities. Moreover, since each perturbation is
performed independently, the joint state of the perturbed inputs may not be
physically meaningful. To address these challenges, we introduce
$\textbf{VisionMask}$, a standalone explanation model trained end-to-end to
identify the most critical regions in the agent's visual input that can explain
its actions. VisionMask is trained in a self-supervised manner without relying
on human-generated labels. Importantly, its training does not alter the agent
model, hence preserving the agent's performance and integrity. We evaluate
VisionMask on Super Mario Bros (SMB) and three Atari games. Compared to
existing methods, VisionMask achieves a 14.9% higher insertion accuracy and a
30.08% higher F1-Score in reproducing original actions from the selected visual
explanations. We also present examples illustrating how VisionMask can be used
for counterfactual analysis.

ÊëòË¶ÅÔºö<paragraph>Áî±ÊñºÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÁº∫‰πèÈÄèÊòéÂ∫¶ÔºåÊ∑±Â∫¶Âº∑ÂåñÂ≠∏Áøí (DRL) ‰ª£ÁêÜÁ®ãÂºèË¶ÅÁç≤Âæó‰ΩøÁî®ËÄÖÁöÑ‰ø°‰ªªÂíåË™çÂèØÊòØ‰∏ÄÈ†ÖÊåëÊà∞ÔºåÁâπÂà•ÊòØÂú®ÂÆâÂÖ®ÈóúÈçµÁöÑÊáâÁî®Á®ãÂºè‰∏≠Ôºå‰æãÂ¶ÇÈÜ´ÁôÇË®∫Êñ∑ÂíåËªç‰∫ãË°åÂãï„ÄÇÁèæÊúâÁöÑÊñπÊ≥ïÁî®ÊñºËß£Èáã‰ª£ÁêÜÁ®ãÂºèÁöÑÊ±∫Á≠ñÔºåÈúÄË¶Å‰ΩøÁî®ÊîØÊè¥Ëß£ÈáãÁî¢ÁîüÁöÑÊ®°ÂûãÈáçÊñ∞Ë®ìÁ∑¥‰ª£ÁêÜÁ®ãÂºèÔºåÊàñ‰æùË≥¥ÊñºÂü∫ÊñºÊìæÂãïÁöÑÊäÄË°ì‰æÜÊè≠Á§∫‰∏çÂêåËº∏ÂÖ•ÁâπÂæµÂú®Ê±∫Á≠ñÂà∂ÂÆöÈÅéÁ®ã‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇÁÑ∂ËÄåÔºåÈáçÊñ∞Ë®ìÁ∑¥‰ª£ÁêÜÁ®ãÂºèÂèØËÉΩÊúÉÊêçÂÆ≥ÂÖ∂ÂÆåÊï¥ÊÄßÂíåÊïàËÉΩÔºåËÄåÂü∫ÊñºÊìæÂãïÁöÑÊñπÊ≥ïÊïàËÉΩÊúâÈôêÔºå‰∏îÁº∫‰πèÁü•Ë≠òÁ¥ØÁ©çÊàñÂ≠∏ÁøíËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÁî±ÊñºÊØèÂÄãÊìæÂãïÈÉΩÊòØÁç®Á´ãÂü∑Ë°åÁöÑÔºåÂõ†Ê≠§ÊìæÂãïËº∏ÂÖ•ÁöÑËÅØÂêàÁãÄÊÖãÂèØËÉΩÊ≤íÊúâÂØ¶ÈöõÊÑèÁæ©„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü $\textbf{VisionMask}$ÔºåÈÄôÊòØ‰∏ÄÂÄãÁç®Á´ãÁöÑËß£ÈáãÊ®°ÂûãÔºåÁ∂ìÈÅéÁ´ØÂ∞çÁ´ØÁöÑË®ìÁ∑¥Ôºå‰ª•Ë≠òÂà•‰ª£ÁêÜÁ®ãÂºèË¶ñË¶∫Ëº∏ÂÖ•‰∏≠ÊúÄÈóúÈçµÁöÑÂçÄÂüüÔºåÈÄô‰∫õÂçÄÂüüÂèØ‰ª•Ëß£ÈáãÂÖ∂Âãï‰Ωú„ÄÇVisionMask ‰ª•Ëá™Áõ£Áù£ÁöÑÊñπÂºèÈÄ≤Ë°åË®ìÁ∑¥ÔºåËÄå‰∏ç‰æùË≥¥Êñº‰∫∫ÁÇ∫Áî¢ÁîüÁöÑÊ®ôÁ±§„ÄÇÈáçË¶ÅÁöÑÊòØÔºåÂÖ∂Ë®ìÁ∑¥‰∏çÊúÉÊîπËÆä‰ª£ÁêÜÁ®ãÂºèÊ®°ÂûãÔºåÂõ†Ê≠§ÂèØ‰ª•‰øùÁïô‰ª£ÁêÜÁ®ãÂºèÁöÑÊïàËÉΩÂíåÂÆåÊï¥ÊÄß„ÄÇÊàëÂÄëÂú® Super Mario Bros (SMB) Âíå‰∏âÊ¨æ Atari ÈÅäÊà≤‰∏äË©ï‰º∞‰∫Ü VisionMask„ÄÇËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåVisionMask Âú®Ê†πÊìöÊâÄÈÅ∏ÁöÑË¶ñË¶∫Ëß£ÈáãË§áË£ΩÂéüÂßãÂãï‰ΩúÊôÇÔºåÊèíÂÖ•Ê∫ñÁ¢∫ÁéáÊèêÈ´ò‰∫Ü 14.9%ÔºåF1 ÂàÜÊï∏ÊèêÈ´ò‰∫Ü 30.08%„ÄÇÊàëÂÄëÈÇÑÊèê‰æõ‰∫ÜÁØÑ‰æã‰æÜË™™ÊòéÂ¶Ç‰Ωï‰ΩøÁî® VisionMask ÈÄ≤Ë°åÂèç‰∫ãÂØ¶ÂàÜÊûê„ÄÇ</paragraph>

##### **LLM Augmentations to support Analytical Reasoning over Multiple Documents**
2411.16116v1 by Raquib Bin Yousuf, Nicholas Defelice, Mandar Sharma, Shengzhe Xu, Naren Ramakrishnan

Building on their demonstrated ability to perform a variety of tasks, we
investigate the application of large language models (LLMs) to enhance in-depth
analytical reasoning within the context of intelligence analysis. Intelligence
analysts typically work with massive dossiers to draw connections between
seemingly unrelated entities, and uncover adversaries' plans and motives. We
explore if and how LLMs can be helpful to analysts for this task and develop an
architecture to augment the capabilities of an LLM with a memory module called
dynamic evidence trees (DETs) to develop and track multiple investigation
threads. Through extensive experiments on multiple datasets, we highlight how
LLMs, as-is, are still inadequate to support intelligence analysts and offer
recommendations to improve LLMs for such intricate reasoning applications.

ÊëòË¶ÅÔºöÂª∫Á´ãÂú®ÂÆÉÂÄëÂü∑Ë°åÂêÑÁ®Æ‰ªªÂãôÁöÑÂ∑≤È©óË≠âËÉΩÂäõ‰∏äÔºåÊàëÂÄëÁ†îÁ©∂Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊáâÁî®Ôºå‰ª•Â¢ûÂº∑ÊÉÖÂ†±ÂàÜÊûêËÉåÊôØ‰∏ãÁöÑÊ∑±ÂÖ•ÂàÜÊûêÊé®ÁêÜ„ÄÇÊÉÖÂ†±ÂàÜÊûêÂ∏´ÈÄöÂ∏∏ÊúÉËôïÁêÜÂ§ßÈáèÊ™îÊ°àÔºå‰ª•ÊâæÂá∫Áúã‰ººÁÑ°ÈóúÂØ¶È´î‰πãÈñìÁöÑÈóúËÅØÔºå‰∏¶Êè≠Èú≤Â∞çÊâãÁöÑË®àÁï´ÂíåÂãïÊ©ü„ÄÇÊàëÂÄëÊé¢Ë®é LLM ÊòØÂê¶‰ª•ÂèäÂ¶Ç‰ΩïËÉΩÂçîÂä©ÂàÜÊûêÂ∏´Âü∑Ë°åÈÄôÈ†Ö‰ªªÂãôÔºå‰∏¶ÈñãÁôº‰∏ÄÁ®ÆÊû∂ÊßãÔºå‰ª•‰∏ÄÂÄãÁ®±ÁÇ∫ÂãïÊÖãË≠âÊìöÊ®π (DET) ÁöÑË®òÊÜ∂È´îÊ®°ÁµÑ‰æÜÊì¥ÂÖÖ LLM ÁöÑÂäüËÉΩÔºå‰ª•ÈñãÁôºÂíåËøΩËπ§Â§öÂÄãË™øÊü•Á∑öÁ¥¢„ÄÇÈÄèÈÅéÂ∞çÂ§öÂÄãË≥áÊñôÈõÜÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÔºåÊàëÂÄëÂº∑Ë™øÂá∫ LLM ÂéüÊú¨ÁöÑÁãÄÊÖã‰ªç‰∏çË∂≥‰ª•ÊîØÊè¥ÊÉÖÂ†±ÂàÜÊûêÂ∏´Ôºå‰∏¶Êèê‰æõÂª∫Ë≠∞Ôºå‰ª•ÊîπÂñÑ LLMÔºåÁî®ÊñºÊ≠§È°ûË§áÈõúÁöÑÊé®ÁêÜÊáâÁî®„ÄÇ

##### **LLMPirate: LLMs for Black-box Hardware IP Piracy**
2411.16111v1 by Vasudev Gohil, Matthew DeLorenzo, Veera Vishwa Achuta Sai Venkat Nallam, Joey See, Jeyavijayan Rajendran

The rapid advancement of large language models (LLMs) has enabled the ability
to effectively analyze and generate code nearly instantaneously, resulting in
their widespread adoption in software development. Following this advancement,
researchers and companies have begun integrating LLMs across the hardware
design and verification process. However, these highly potent LLMs can also
induce new attack scenarios upon security vulnerabilities across the hardware
development process. One such attack vector that has not been explored is
intellectual property (IP) piracy. Given that this attack can manifest as
rewriting hardware designs to evade piracy detection, it is essential to
thoroughly evaluate LLM capabilities in performing this task and assess the
mitigation abilities of current IP piracy detection tools.
  Therefore, in this work, we propose LLMPirate, the first LLM-based technique
able to generate pirated variations of circuit designs that successfully evade
detection across multiple state-of-the-art piracy detection tools. We devise
three solutions to overcome challenges related to integration of LLMs for
hardware circuit designs, scalability to large circuits, and effectiveness,
resulting in an end-to-end automated, efficient, and practical formulation. We
perform an extensive experimental evaluation of LLMPirate using eight LLMs of
varying sizes and capabilities and assess their performance in pirating various
circuit designs against four state-of-the-art, widely-used piracy detection
tools. Our experiments demonstrate that LLMPirate is able to consistently evade
detection on 100% of tested circuits across every detection tool. Additionally,
we showcase the ramifications of LLMPirate using case studies on IBEX and
MOR1KX processors and a GPS module, that we successfully pirate. We envision
that our work motivates and fosters the development of better IP piracy
detection tools.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂø´ÈÄüÈÄ≤Ê≠•‰ΩøÂæóËÉΩÂ§†ÊúâÊïàÂàÜÊûêÂíåÁîüÊàê‰ª£Á¢ºÂπæ‰πéÊòØÁû¨ÈñìÂÆåÊàêÔºåÂ∞éËá¥ÂÆÉÂÄëÂú®ËªüÈ´îÈñãÁôº‰∏≠Ë¢´Âª£Ê≥õÊé°Áî®„ÄÇÂú®ÈÄô‰∏ÄÈÄ≤Ê≠•‰πãÂæåÔºåÁ†îÁ©∂‰∫∫Âì°ÂíåÂÖ¨Âè∏Â∑≤Á∂ìÈñãÂßãÂú®Á°¨È´îË®≠Ë®àÂíåÈ©óË≠âÈÅéÁ®ã‰∏≠Êï¥Âêà LLM„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÈ´òÂ∫¶Âº∑Â§ßÁöÑ LLM ‰πüÂèØ‰ª•Âú®Êï¥ÂÄãÁ°¨È´îÈñãÁôºÈÅéÁ®ã‰∏≠Â∞çÂÆâÂÖ®ÊºèÊ¥ûË™òÁôºÊñ∞ÁöÑÊîªÊìäÂ†¥ÊôØ„ÄÇ‰∏ÄÁ®ÆÂ∞öÊú™Êé¢Á¥¢ÁöÑÊ≠§È°ûÊîªÊìäÂ™í‰ªãÊòØÊô∫ÊÖßË≤°Áî¢Ê¨ä (IP) ÁõúÁâà„ÄÇÈëëÊñºÈÄôÁ®ÆÊîªÊìäÂèØ‰ª•Ë°®ÁèæÁÇ∫ÈáçÂØ´Á°¨È´îË®≠Ë®à‰ª•Ë¶èÈÅøÁõúÁâàÊ™¢Ê∏¨ÔºåÂõ†Ê≠§ÂæπÂ∫ïË©ï‰º∞ LLM Âú®Âü∑Ë°åÊ≠§‰ªªÂãô‰∏≠ÁöÑËÉΩÂäõ‰∏¶Ë©ï‰º∞Áï∂Ââç IP ÁõúÁâàÊ™¢Ê∏¨Â∑•ÂÖ∑ÁöÑÁ∑©Ëß£ËÉΩÂäõËá≥ÈóúÈáçË¶Å„ÄÇ
Âõ†Ê≠§ÔºåÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü LLMPirateÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂü∫Êñº LLM ÁöÑÈ¶ñÂâµÊäÄË°ìÔºåËÉΩÂ§†ÁîüÊàêÈõªË∑ØË®≠Ë®àÁöÑÁõúÁâàËÆäÈ´îÔºåÊàêÂäüË¶èÈÅøÂ§öÁ®ÆÊúÄÂÖàÈÄ≤ÁöÑÁõúÁâàÊ™¢Ê∏¨Â∑•ÂÖ∑ÁöÑÊ™¢Ê∏¨„ÄÇÊàëÂÄëË®≠Ë®à‰∫Ü‰∏âÁ®ÆËß£Ê±∫ÊñπÊ°à‰æÜÂÖãÊúçËàá LLM ÈõÜÊàêÂà∞Á°¨È´îÈõªË∑ØË®≠Ë®à„ÄÅÂ§ßÈõªË∑ØÂèØÊì¥Â±ïÊÄßÂíåÊúâÊïàÊÄßÁõ∏ÈóúÁöÑÊåëÊà∞ÔºåÂæûËÄåÂΩ¢ÊàêÁ´ØÂà∞Á´ØËá™ÂãïÂåñ„ÄÅÈ´òÊïà‰∏îÂØ¶Áî®ÁöÑÂÖ¨Âºè„ÄÇÊàëÂÄë‰ΩøÁî®ÂÖ´Á®Æ‰∏çÂêåÂ§ßÂ∞èÂíåÂäüËÉΩÁöÑ LLM Â∞ç LLMPirate ÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óË©ï‰º∞Ôºå‰∏¶Ë©ï‰º∞‰∫ÜÂÆÉÂÄëÂú®ÈáùÂ∞çÂõõÁ®ÆÊúÄÂÖàÈÄ≤ÁöÑ„ÄÅÂª£Ê≥õ‰ΩøÁî®ÁöÑÁõúÁâàÊ™¢Ê∏¨Â∑•ÂÖ∑ÁõúÁâàÂêÑÁ®ÆÈõªË∑ØË®≠Ë®à‰∏≠ÁöÑÊÄßËÉΩ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåLLMPirate ËÉΩÂ§†Âú®ÊØèÂÄãÊ™¢Ê∏¨Â∑•ÂÖ∑‰∏≠Â∞ç 100% ÁöÑÂèóÊ∏¨ÈõªË∑ØÊåÅÁ∫åË¶èÈÅøÊ™¢Ê∏¨„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü LLMPirate Âú® IBEX Âíå MOR1KX ËôïÁêÜÂô®‰ª•Âèä GPS Ê®°ÁµÑÔºàÊàëÂÄëÊàêÂäüÁõúÁâàÔºâÁöÑÊ°à‰æãÁ†îÁ©∂‰∏≠ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÈ†êË®àÔºåÊàëÂÄëÁöÑËëó‰ΩúÂ∞áÊøÄÂãµÂíå‰øÉÈÄ≤Êõ¥Â•ΩÁöÑ IP ÁõúÁâàÊ™¢Ê∏¨Â∑•ÂÖ∑ÁöÑÈñãÁôº„ÄÇ

##### **Adaptive Circuit Behavior and Generalization in Mechanistic Interpretability**
2411.16105v1 by Jatin Nainani, Sankaran Vaidyanathan, AJ Yeung, Kartik Gupta, David Jensen

Mechanistic interpretability aims to understand the inner workings of large
neural networks by identifying circuits, or minimal subgraphs within the model
that implement algorithms responsible for performing specific tasks. These
circuits are typically discovered and analyzed using a narrowly defined prompt
format. However, given the abilities of large language models (LLMs) to
generalize across various prompt formats for the same task, it remains unclear
how well these circuits generalize. For instance, it is unclear whether the
models generalization results from reusing the same circuit components, the
components behaving differently, or the use of entirely different components.
In this paper, we investigate the generality of the indirect object
identification (IOI) circuit in GPT-2 small, which is well-studied and believed
to implement a simple, interpretable algorithm. We evaluate its performance on
prompt variants that challenge the assumptions of this algorithm. Our findings
reveal that the circuit generalizes surprisingly well, reusing all of its
components and mechanisms while only adding additional input edges. Notably,
the circuit generalizes even to prompt variants where the original algorithm
should fail; we discover a mechanism that explains this which we term S2
Hacking. Our findings indicate that circuits within LLMs may be more flexible
and general than previously recognized, underscoring the importance of studying
circuit generalization to better understand the broader capabilities of these
models.

ÊëòË¶ÅÔºö<paragraph>Ê©üÊ¢∞ÂèØËß£ÈáãÊÄßÊó®Âú®ÈÄèÈÅéË≠òÂà•ÈõªË∑ØÔºåÊàñÊ®°Âûã‰∏≠Ë≤†Ë≤¨Âü∑Ë°åÁâπÂÆö‰ªªÂãôÁöÑÊºîÁÆóÊ≥ïÊâÄÂØ¶‰ΩúÁöÑÊúÄÂ∞èÂ≠êÂúñÂΩ¢Ôºå‰æÜ‰∫ÜËß£Â§ßÂûãÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÂÖßÈÉ®ÈÅã‰Ωú„ÄÇÈÄô‰∫õÈõªË∑ØÈÄöÂ∏∏‰ΩøÁî®ÂÆöÁæ©ÁãπÁ™ÑÁöÑÊèêÁ§∫Ê†ºÂºèÈÄ≤Ë°åÁôºÁèæÂíåÂàÜÊûê„ÄÇÁÑ∂ËÄåÔºåËÄÉÈáèÂà∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∞çÁõ∏Âêå‰ªªÂãôÁöÑÂêÑÁ®ÆÊèêÁ§∫Ê†ºÂºèÈÄ≤Ë°åÊ¶ÇÂåñÁöÑËÉΩÂäõÔºåÈÄô‰∫õÈõªË∑ØÊ¶ÇÂåñÁöÑÁ®ãÂ∫¶‰ªçÁÑ∂‰∏çÊ∏ÖÊ•ö„ÄÇ‰æãÂ¶ÇÔºåÁõÆÂâç‰∏çÊ∏ÖÊ•öÊ®°ÂûãÊ¶ÇÂåñÊòØÂê¶‰æÜËá™ÈáçË§á‰ΩøÁî®Áõ∏ÂêåÁöÑÈõªË∑ØÂÖÉ‰ª∂ÔºåÂÖÉ‰ª∂Ë°®Áèæ‰∏çÂêåÔºåÊàñ‰ΩøÁî®ÂÆåÂÖ®‰∏çÂêåÁöÑÂÖÉ‰ª∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é GPT-2 small ‰∏≠ÈñìÊé•ÂèóË©ûË≠òÂà• (IOI) ÈõªË∑ØÁöÑÊ¶ÇÊã¨ÊÄßÔºåË©≤ÈõªË∑ØÁ∂ìÈÅéÂÖÖÂàÜÁ†îÁ©∂Ôºå‰∏îË¢´Ë™çÁÇ∫ÂØ¶‰Ωú‰∫Ü‰∏ÄÂÄãÁ∞°ÂñÆ„ÄÅÂèØËß£ÈáãÁöÑÊºîÁÆóÊ≥ï„ÄÇÊàëÂÄëË©ï‰º∞ÂÆÉÂú®ÊåëÊà∞Ê≠§ÊºîÁÆóÊ≥ïÂÅáË®≠ÁöÑÊèêÁ§∫ËÆäÈ´î‰∏äÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÁôºÁèæÈ°ØÁ§∫ÔºåË©≤ÈõªË∑ØÊ¶ÇÂåñÂæó‰ª§‰∫∫È©öË®ùÂú∞Â•ΩÔºåÈáçË§á‰ΩøÁî®ÂÖ∂ÊâÄÊúâÂÖÉ‰ª∂ÂíåÊ©üÂà∂ÔºåÂêåÊôÇÂÉÖÊñ∞Â¢ûÈ°çÂ§ñÁöÑËº∏ÂÖ•ÈÇäÁ∑£„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂç≥‰ΩøÂú®ÂéüÂßãÊºîÁÆóÊ≥ïÊáâË©≤ÊúÉÂ§±ÊïóÁöÑÊèêÁ§∫ËÆäÈ´î‰∏≠ÔºåË©≤ÈõªË∑Ø‰ªçËÉΩÊ¶ÇÂåñÔºõÊàëÂÄëÁôºÁèæ‰∏ÄÁ®ÆÊ©üÂà∂ÂèØ‰ª•Ëß£ÈáãÈÄôÁ®ÆÊÉÖÊ≥ÅÔºåÊàëÂÄëÁ®±‰πãÁÇ∫ S2 Hacking„ÄÇÊàëÂÄëÁöÑÁôºÁèæË°®ÊòéÔºåLLM ‰∏≠ÁöÑÈõªË∑ØÂèØËÉΩÊØîÂÖàÂâçË™çÁü•ÁöÑÊõ¥ÈùàÊ¥ª‰∏îÊõ¥ÈÄöÁî®ÔºåÈÄôÂº∑Ë™ø‰∫ÜÁ†îÁ©∂ÈõªË∑ØÊ¶ÇÂåñÁöÑÈáçË¶ÅÊÄßÔºå‰ª•‰æøÊõ¥Ê∑±ÂÖ•‰∫ÜËß£ÈÄô‰∫õÊ®°ÂûãÁöÑÂª£Ê≥õÂäüËÉΩ„ÄÇ</paragraph>

##### **An Empirical Study of Vulnerability Detection using Federated Learning**
2411.16099v1 by Peiheng Zhou, Ming Hu, Xingrun Quan, Yawen Peng, Xiaofei Xie, Yanxin Yang, Chengwei Liu, Yueming Wu, Mingsong Chen

Although Deep Learning (DL) methods becoming increasingly popular in
vulnerability detection, their performance is seriously limited by insufficient
training data. This is mainly because few existing software organizations can
maintain a complete set of high-quality samples for DL-based vulnerability
detection. Due to the concerns about privacy leakage, most of them are
reluctant to share data, resulting in the data silo problem. Since enables
collaboratively model training without data sharing, Federated Learning (FL)
has been investigated as a promising means of addressing the data silo problem
in DL-based vulnerability detection. However, since existing FL-based
vulnerability detection methods focus on specific applications, it is still far
unclear i) how well FL adapts to common vulnerability detection tasks and ii)
how to design a high-performance FL solution for a specific vulnerability
detection task. To answer these two questions, this paper first proposes VulFL,
an effective evaluation framework for FL-based vulnerability detection. Then,
based on VulFL, this paper conducts a comprehensive study to reveal the
underlying capabilities of FL in dealing with different types of CWEs,
especially when facing various data heterogeneity scenarios. Our experimental
results show that, compared to independent training, FL can significantly
improve the detection performance of common AI models on all investigated CWEs,
though the performance of FL-based vulnerability detection is limited by
heterogeneous data. To highlight the performance differences between different
FL solutions for vulnerability detection, we extensively investigate the
impacts of different configuration strategies for each framework component of
VulFL. Our study sheds light on the potential of FL in vulnerability detection,
which can be used to guide the design of FL-based solutions for vulnerability
detection.

ÊëòË¶ÅÔºöÂÑòÁÆ°Ê∑±Â∫¶Â≠∏Áøí (DL) ÊñπÊ≥ïÂú®ÊºèÊ¥ûÂÅµÊ∏¨ÊñπÈù¢Êó•ÁõäÊôÆÂèäÔºå‰ΩÜÂÖ∂ÊïàËÉΩÂçªÂèóÂà∞Ë®ìÁ∑¥Ë≥áÊñô‰∏çË∂≥ÁöÑÂö¥ÈáçÈôêÂà∂„ÄÇÈÄô‰∏ªË¶ÅÊòØÂõ†ÁÇ∫ÁèæÊúâÁöÑËªüÈ´îÁµÑÁπîÂæàÂ∞ëËÉΩÁ∂≠Ë≠∑‰∏ÄÁµÑÂÆåÊï¥ÁöÑÂÑ™Ë≥™Ê®£Êú¨Ôºå‰ª•ÈÄ≤Ë°åÂü∫Êñº DL ÁöÑÊºèÊ¥ûÂÅµÊ∏¨„ÄÇÁî±ÊñºÊìîÂøÉÈö±ÁßÅÂ§ñÊ¥©Ôºå‰ªñÂÄëÂ§ßÂ§ö‰∏çÈ°òÊÑèÂàÜ‰∫´Ë≥áÊñôÔºåÂ∞éËá¥Ë≥áÊñôÂ≠§Â≥∂ÂïèÈ°å„ÄÇÁî±ÊñºËÅØÂêàÂ≠∏Áøí (FL) ËÉΩÂ§†Âú®‰∏çÂÖ±Áî®Ë≥áÊñôÁöÑÊÉÖÊ≥Å‰∏ãÈÄ≤Ë°åÂçî‰ΩúÊ®°ÂûãË®ìÁ∑¥ÔºåÂõ†Ê≠§Â∑≤Â∞áÂÖ∂Ë¶ñÁÇ∫Ëß£Ê±∫Âü∫Êñº DL ÁöÑÊºèÊ¥ûÂÅµÊ∏¨‰∏≠Ë≥áÊñôÂ≠§Â≥∂ÂïèÈ°åÁöÑ‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÁèæÊúâÁöÑÂü∫Êñº FL ÁöÑÊºèÊ¥ûÂÅµÊ∏¨ÊñπÊ≥ïÂ∞àÊ≥®ÊñºÁâπÂÆöÊáâÁî®Á®ãÂºèÔºåÂõ†Ê≠§‰ªç‰∏çÊ∏ÖÊ•ö i) FL Â¶Ç‰ΩïÈÅ©ÊáâÂ∏∏Ë¶ãÁöÑÊºèÊ¥ûÂÅµÊ∏¨‰ªªÂãôÔºå‰ª•Âèä ii) Â¶Ç‰ΩïÁÇ∫ÁâπÂÆöÊºèÊ¥ûÂÅµÊ∏¨‰ªªÂãôË®≠Ë®àÈ´òÊÄßËÉΩÁöÑ FL Ëß£Ê±∫ÊñπÊ°à„ÄÇÁÇ∫‰∫ÜÂõûÁ≠îÈÄôÂÖ©ÂÄãÂïèÈ°åÔºåÊú¨ÊñáÈ¶ñÂÖàÊèêÂá∫‰∫Ü VulFLÔºå‰∏ÄÂÄãÁî®ÊñºÂü∫Êñº FL ÁöÑÊºèÊ¥ûÂÅµÊ∏¨ÁöÑÊúâÊïàË©ï‰º∞Êû∂Êßã„ÄÇÁÑ∂ÂæåÔºåÊú¨ÊñáÂü∫Êñº VulFL ÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÂÖ®Èù¢Á†îÁ©∂Ôºå‰ª•Êè≠Á§∫ FL Âú®ËôïÁêÜ‰∏çÂêåÈ°ûÂûãÁöÑ CWE ÊôÇÁöÑÊΩõÂú®ËÉΩÂäõÔºåÁâπÂà•ÊòØÂú®Èù¢Â∞çÂêÑÁ®ÆË≥áÊñôÁï∞Ë≥™ÊÄßÂ†¥ÊôØÊôÇ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåËàáÁç®Á´ãË®ìÁ∑¥Áõ∏ÊØîÔºåFL ÂèØ‰ª•È°ØËëóÊèêÂçáÊâÄÊúâË™øÊü•ÁöÑ CWE ‰∏äÂ∏∏Ë¶ã AI Ê®°ÂûãÁöÑÂÅµÊ∏¨ÊïàËÉΩÔºåÂÑòÁÆ°Âü∫Êñº FL ÁöÑÊºèÊ¥ûÂÅµÊ∏¨ÁöÑÊïàËÉΩÂèóÂà∞Áï∞Ë≥™ÊÄßË≥áÊñôÁöÑÈôêÂà∂„ÄÇÁÇ∫‰∫ÜÂº∑Ë™ø‰∏çÂêå FL Ëß£Ê±∫ÊñπÊ°àÂú®ÊºèÊ¥ûÂÅµÊ∏¨‰∏äÁöÑÊïàËÉΩÂ∑ÆÁï∞ÔºåÊàëÂÄëÂª£Ê≥õÊé¢Ë®é‰∫Ü VulFL ÂêÑÂÄãÊû∂ÊßãÂÖÉ‰ª∂ÁöÑ‰∏çÂêåÈÖçÁΩÆÁ≠ñÁï•ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Èó°Êòé‰∫Ü FL Âú®ÊºèÊ¥ûÂÅµÊ∏¨ÊñπÈù¢ÁöÑÊΩõÂäõÔºåÂèØÁî®ÊñºÊåáÂ∞éÂü∫Êñº FL ÁöÑÊºèÊ¥ûÂÅµÊ∏¨Ëß£Ê±∫ÊñπÊ°àÁöÑË®≠Ë®à„ÄÇ

##### **ENCLIP: Ensembling and Clustering-Based Contrastive Language-Image Pretraining for Fashion Multimodal Search with Limited Data and Low-Quality Images**
2411.16096v1 by Prithviraj Purushottam Naik, Rohit Agarwal

Multimodal search has revolutionized the fashion industry, providing a
seamless and intuitive way for users to discover and explore fashion items.
Based on their preferences, style, or specific attributes, users can search for
products by combining text and image information. Text-to-image searches enable
users to find visually similar items or describe products using natural
language. This paper presents an innovative approach called ENCLIP, for
enhancing the performance of the Contrastive Language-Image Pretraining (CLIP)
model, specifically in Multimodal Search targeted towards the domain of fashion
intelligence. This method focuses on addressing the challenges posed by limited
data availability and low-quality images. This paper proposes an algorithm that
involves training and ensembling multiple instances of the CLIP model, and
leveraging clustering techniques to group similar images together. The
experimental findings presented in this study provide evidence of the
effectiveness of the methodology. This approach unlocks the potential of CLIP
in the domain of fashion intelligence, where data scarcity and image quality
issues are prevalent. Overall, the ENCLIP method represents a valuable
contribution to the field of fashion intelligence and provides a practical
solution for optimizing the CLIP model in scenarios with limited data and
low-quality images.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÄÅÊêúÁ¥¢ÂΩªÂ∫ïÊîπÂèò‰∫ÜÊó∂Â∞ö‰∫ß‰∏öÔºå‰∏∫Áî®Êà∑Êèê‰æõ‰∫Ü‰∏ÄÁßçÊó†Áºù‰∏îÁõ¥ËßÇÁöÑÊñπÂºèÊù•ÂèëÁé∞ÂíåÊé¢Á¥¢Êó∂Â∞öÂçïÂìÅ„ÄÇÂü∫‰∫é‰ªñ‰ª¨ÁöÑÂÅèÂ•Ω„ÄÅÈ£éÊ†ºÊàñÁâπÂÆöÂ±ûÊÄßÔºåÁî®Êà∑ÂèØ‰ª•ÈÄöËøáÁªìÂêàÊñáÊú¨ÂíåÂõæÂÉè‰ø°ÊÅØÊù•ÊêúÁ¥¢‰∫ßÂìÅ„ÄÇÊñáÊú¨Âà∞ÂõæÂÉèÊêúÁ¥¢‰ΩøÁî®Êà∑ËÉΩÂ§üÊâæÂà∞ËßÜËßâ‰∏äÁõ∏‰ººÁöÑÁâ©ÂìÅÊàñ‰ΩøÁî®Ëá™ÁÑ∂ËØ≠Ë®ÄÊèèËø∞‰∫ßÂìÅ„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫ ENCLIP ÁöÑÂàõÊñ∞ÊñπÊ≥ïÔºåÁî®‰∫éÂ¢ûÂº∫ÂØπÊØîËØ≠Ë®ÄÂõæÂÉèÈ¢ÑËÆ≠ÁªÉ (CLIP) Ê®°ÂûãÁöÑÊÄßËÉΩÔºåÁâπÂà´ÊòØÂú®ÈíàÂØπÊó∂Â∞öÊô∫ËÉΩÈ¢ÜÂüüÁöÑË∑®Ê®°ÊÄÅÊêúÁ¥¢‰∏≠„ÄÇÊ≠§ÊñπÊ≥ï‰æßÈáç‰∫éËß£ÂÜ≥Êï∞ÊçÆÂèØÁî®ÊÄßÊúâÈôêÂíåÂõæÂÉèË¥®Èáè‰Ωé‰∏ãÁöÑÊåëÊàò„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÁÆóÊ≥ïÔºåËØ•ÁÆóÊ≥ïÊ∂âÂèäËÆ≠ÁªÉÂíåÈõÜÊàê CLIP Ê®°ÂûãÁöÑÂ§ö‰∏™ÂÆû‰æãÔºåÂπ∂Âà©Áî®ËÅöÁ±ªÊäÄÊúØÂ∞ÜÁõ∏‰ººÁöÑÂõæÂÉèÂàÜÁªÑÂú®‰∏ÄËµ∑„ÄÇÊú¨Á†îÁ©∂‰∏≠ÊèêÂá∫ÁöÑÂÆûÈ™åÁªìÊûúËØÅÊòé‰∫ÜËØ•ÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇËøôÁßçÊñπÊ≥ïÈáäÊîæ‰∫Ü CLIP Âú®Êó∂Â∞öÊô∫ËÉΩÈ¢ÜÂüü‰∏≠ÁöÑÊΩúÂäõÔºåËÄåÊï∞ÊçÆÁ®ÄÁº∫ÂíåÂõæÂÉèË¥®ÈáèÈóÆÈ¢òÂæàÊôÆÈÅç„ÄÇÊÄª‰ΩìËÄåË®ÄÔºåENCLIP ÊñπÊ≥ï‰ª£Ë°®‰∫ÜÂØπÊó∂Â∞öÊô∫ËÉΩÈ¢ÜÂüüÁöÑÂÆùË¥µË¥°ÁåÆÔºåÂπ∂‰∏∫Âú®Êï∞ÊçÆÊúâÈôêÂíåÂõæÂÉèË¥®Èáè‰Ωé‰∏ãÁöÑÊÉÖÂÜµ‰∏ã‰ºòÂåñ CLIP Ê®°ÂûãÊèê‰æõ‰∫ÜÂÆûÁî®ÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ

##### **HiDP: Hierarchical DNN Partitioning for Distributed Inference on Heterogeneous Edge Platforms**
2411.16086v1 by Zain Taufique, Aman Vyas, Antonio Miele, Pasi Liljeberg, Anil Kanduri

Edge inference techniques partition and distribute Deep Neural Network (DNN)
inference tasks among multiple edge nodes for low latency inference, without
considering the core-level heterogeneity of edge nodes. Further, default DNN
inference frameworks also do not fully utilize the resources of heterogeneous
edge nodes, resulting in higher inference latency. In this work, we propose a
hierarchical DNN partitioning strategy (HiDP) for distributed inference on
heterogeneous edge nodes. Our strategy hierarchically partitions DNN workloads
at both global and local levels by considering the core-level heterogeneity of
edge nodes. We evaluated our proposed HiDP strategy against relevant
distributed inference techniques over widely used DNN models on commercial edge
devices. On average our strategy achieved 38% lower latency, 46% lower energy,
and 56% higher throughput in comparison with other relevant approaches.

ÊëòË¶ÅÔºöÈÇäÁ∑£Êé®ÁêÜÊäÄË°ìÂ∞áÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑Ø (DNN) Êé®Ë´ñ‰ªªÂãôÂàÜÂâ≤‰∏¶ÂàÜÈÖçÁµ¶Â§öÂÄãÈÇäÁ∑£ÁØÄÈªû‰ª•ÈÄ≤Ë°å‰ΩéÂª∂ÈÅ≤Êé®ÁêÜÔºåËÄå‰∏çÊúÉËÄÉÊÖÆÈÇäÁ∑£ÁØÄÈªûÁöÑÊ†∏ÂøÉÂ±§Á¥öÁï∞Ë≥™ÊÄß„ÄÇÊ≠§Â§ñÔºåÈ†êË®≠ÁöÑ DNN Êé®Ë´ñÊ°ÜÊû∂‰πü‰∏çÊúÉÂÆåÂÖ®Âà©Áî®Áï∞Ë≥™ÈÇäÁ∑£ÁØÄÈªûÁöÑË≥áÊ∫êÔºåÂ∞éËá¥Êõ¥È´òÁöÑÊé®Ë´ñÂª∂ÈÅ≤„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÈáùÂ∞çÁï∞Ë≥™ÈÇäÁ∑£ÁØÄÈªûÁöÑÂàÜÂ∏ÉÂºèÊé®Ë´ñÂàÜÂ±§ DNN ÂàÜÂâ≤Á≠ñÁï• (HiDP)„ÄÇÊàëÂÄëÁöÑÁ≠ñÁï•ÈÄèÈÅéËÄÉÊÖÆÈÇäÁ∑£ÁØÄÈªûÁöÑÊ†∏ÂøÉÂ±§Á¥öÁï∞Ë≥™ÊÄßÔºåÂú®ÂÖ®ÁêÉÂíåÂ±ÄÈÉ®Â±§Á¥öÂàÜÂ±§ÂàÜÂâ≤ DNN Â∑•‰ΩúË≤†Ëºâ„ÄÇÊàëÂÄëÈáùÂ∞çÂª£Ê≥õ‰ΩøÁî®ÁöÑ DNN Ê®°ÂûãË©ï‰º∞‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑ HiDP Á≠ñÁï•ËàáÁõ∏ÈóúÁöÑÂàÜÂ∏ÉÂºèÊé®Ë´ñÊäÄË°ìÂú®ÂïÜÁî®ÈÇäÁ∑£Ë£ùÁΩÆ‰∏äÁöÑË°®Áèæ„ÄÇÂπ≥ÂùáËÄåË®ÄÔºåÊàëÂÄëÁöÑÁ≠ñÁï•ËàáÂÖ∂‰ªñÁõ∏ÈóúÊñπÊ≥ïÁõ∏ÊØîÔºåÂª∂ÈÅ≤Èôç‰Ωé‰∫Ü 38%ÔºåËÉΩËÄóÈôç‰Ωé‰∫Ü 46%Ôºå‰∏îÂêûÂêêÈáèÊèêÈ´ò‰∫Ü 56%„ÄÇ

##### **Deciphering genomic codes using advanced NLP techniques: a scoping review**
2411.16084v1 by Shuyan Cheng, Yishu Wei, Yiliang Zhou, Zihan Xu, Drew N Wright, Jinze Liu, Yifan Peng

Objectives: The vast and complex nature of human genomic sequencing data
presents challenges for effective analysis. This review aims to investigate the
application of Natural Language Processing (NLP) techniques, particularly Large
Language Models (LLMs) and transformer architectures, in deciphering genomic
codes, focusing on tokenization, transformer models, and regulatory annotation
prediction. The goal of this review is to assess data and model accessibility
in the most recent literature, gaining a better understanding of the existing
capabilities and constraints of these tools in processing genomic sequencing
data.
  Methods: Following Preferred Reporting Items for Systematic Reviews and
Meta-Analyses (PRISMA) guidelines, our scoping review was conducted across
PubMed, Medline, Scopus, Web of Science, Embase, and ACM Digital Library.
Studies were included if they focused on NLP methodologies applied to genomic
sequencing data analysis, without restrictions on publication date or article
type.
  Results: A total of 26 studies published between 2021 and April 2024 were
selected for review. The review highlights that tokenization and transformer
models enhance the processing and understanding of genomic data, with
applications in predicting regulatory annotations like transcription-factor
binding sites and chromatin accessibility.
  Discussion: The application of NLP and LLMs to genomic sequencing data
interpretation is a promising field that can help streamline the processing of
large-scale genomic data while also providing a better understanding of its
complex structures. It has the potential to drive advancements in personalized
medicine by offering more efficient and scalable solutions for genomic
analysis. Further research is also needed to discuss and overcome current
limitations, enhancing model transparency and applicability.

ÊëòË¶ÅÔºö<paragraph>ÁõÆÊ®ôÔºö‰∫∫È°ûÂü∫Âõ†ÁµÑÂÆöÂ∫èË≥áÊñôÁöÑÂª£Ê≥õ‰∏îË§áÈõúÁöÑÊÄßË≥™ÁÇ∫ÊúâÊïàÂàÜÊûêÂ∏∂‰æÜÊåëÊà∞„ÄÇÊú¨ÁØáË©ïË´ñÊó®Âú®Êé¢Ë®éËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÊäÄË°ìÁöÑÊáâÁî®ÔºåÁâπÂà•ÊòØÂ§ßË™ûË®ÄÊ®°Âûã (LLM) ÂíåTransformerÊû∂ÊßãÔºåÂú®Á†¥Ë≠ØÂü∫Âõ†ÁµÑÂØÜÁ¢º‰∏≠ÁöÑÊáâÁî®ÔºåÈáçÈªûÈóúÊ≥®ÂàÜË©û„ÄÅTransformerÊ®°ÂûãÂíåË™øÊéßË®ªÈáãÈ†êÊ∏¨„ÄÇÊú¨ÁØáË©ïË´ñÁöÑÁõÆÊ®ôÊòØË©ï‰º∞ÊúÄÊñ∞ÊñáÁçª‰∏≠ÁöÑË≥áÊñôÂíåÊ®°ÂûãÂèØÂèäÊÄßÔºå‰ª•Êõ¥Ê∑±ÂÖ•‰∫ÜËß£ÈÄô‰∫õÂ∑•ÂÖ∑Âú®ËôïÁêÜÂü∫Âõ†ÁµÑÂÆöÂ∫èË≥áÊñôÊñπÈù¢ÁöÑÁèæÊúâËÉΩÂäõÂíåÈôêÂà∂„ÄÇ
ÊñπÊ≥ïÔºöÈÅµÂæ™Á≥ªÁµ±ÊÄßÂõûÈ°ßÂíåÂæåË®≠ÂàÜÊûêÁöÑÈ¶ñÈÅ∏Â†±ÂëäÈ†ÖÁõÆ (PRISMA) ÊåáÂçóÔºåÊàëÂÄëÁöÑÁØÑÂúçÂõûÈ°ßÂú® PubMed„ÄÅMedline„ÄÅScopus„ÄÅWeb of Science„ÄÅEmbase Âíå ACM Êï∏‰ΩçÂúñÊõ∏È§®‰∏≠ÈÄ≤Ë°å„ÄÇÂ¶ÇÊûúÁ†îÁ©∂ÈáçÈªûÊòØÊáâÁî®ÊñºÂü∫Âõ†ÁµÑÂÆöÂ∫èË≥áÊñôÂàÜÊûêÁöÑ NLP ÊñπÊ≥ïÔºåÂâáÁ¥çÂÖ•Á†îÁ©∂ÔºåËÄå‰∏çÈôêÂà∂ÁôºË°®Êó•ÊúüÊàñÊñáÁ´†È°ûÂûã„ÄÇ
ÁµêÊûúÔºöÂÖ±ÈÅ∏Âá∫ 2021 Âπ¥Ëá≥ 2024 Âπ¥ 4 ÊúàÈñìÁôºË°®ÁöÑ 26 ÁØáÁ†îÁ©∂ÈÄ≤Ë°åÂõûÈ°ß„ÄÇÂõûÈ°ßÂº∑Ë™øÔºåÂàÜË©ûÂíåTransformerÊ®°ÂûãÂ¢ûÂº∑‰∫ÜÂü∫Âõ†ÁµÑË≥áÊñôÁöÑËôïÁêÜÂíåÁêÜËß£Ôºå‰∏¶ÊáâÁî®ÊñºÈ†êÊ∏¨ËΩâÈåÑÂõ†Â≠êÁµêÂêà‰ΩçÈªûÂíåÊüìËâ≤Ë≥™ÂèØÂèäÊÄßÁ≠âË™øÊéßË®ªÈáã„ÄÇ
Ë®éË´ñÔºöÂ∞á NLP Âíå LLM ÊáâÁî®ÊñºÂü∫Âõ†ÁµÑÂÆöÂ∫èË≥áÊñôËß£ËÆÄÊòØ‰∏ÄÂÄãÊúâÂâçÊôØÁöÑÈ†òÂüüÔºåÊúâÂä©ÊñºÁ∞°ÂåñÂ§ßË¶èÊ®°Âü∫Âõ†ÁµÑË≥áÊñôÁöÑËôïÁêÜÔºåÂêåÊôÇ‰πüÊõ¥Ê∑±ÂÖ•‰∫ÜËß£ÂÖ∂Ë§áÈõúÁµêÊßã„ÄÇÂÆÉÊúâÊΩõÂäõÈÄèÈÅéÊèê‰æõÊõ¥ÊúâÊïàÁéá‰∏îÂèØÊì¥ÂÖÖÁöÑÂü∫Âõ†ÁµÑÂàÜÊûêËß£Ê±∫ÊñπÊ°àÔºåÊé®ÂãïÂÄã‰∫∫ÂåñÈÜ´ÁôÇÁöÑÈÄ≤Ê≠•„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑÁ†îÁ©∂‰πüÈúÄË¶ÅË®éË´ñ‰∏¶ÂÖãÊúçÁõÆÂâçÁöÑÈôêÂà∂Ôºå‰ª•Â¢ûÂº∑Ê®°ÂûãÁöÑÈÄèÊòéÂ∫¶ÂíåÈÅ©Áî®ÊÄß„ÄÇ</paragraph>

##### **Boosting 3D Object Generation through PBR Materials**
2411.16080v1 by Yitong Wang, Xudong Xu, Li Ma, Haoran Wang, Bo Dai

Automatic 3D content creation has gained increasing attention recently, due
to its potential in various applications such as video games, film industry,
and AR/VR. Recent advancements in diffusion models and multimodal models have
notably improved the quality and efficiency of 3D object generation given a
single RGB image. However, 3D objects generated even by state-of-the-art
methods are still unsatisfactory compared to human-created assets. Considering
only textures instead of materials makes these methods encounter challenges in
photo-realistic rendering, relighting, and flexible appearance editing. And
they also suffer from severe misalignment between geometry and high-frequency
texture details. In this work, we propose a novel approach to boost the quality
of generated 3D objects from the perspective of Physics-Based Rendering (PBR)
materials. By analyzing the components of PBR materials, we choose to consider
albedo, roughness, metalness, and bump maps. For albedo and bump maps, we
leverage Stable Diffusion fine-tuned on synthetic data to extract these values,
with novel usages of these fine-tuned models to obtain 3D consistent albedo UV
and bump UV for generated objects. In terms of roughness and metalness maps, we
adopt a semi-automatic process to provide room for interactive adjustment,
which we believe is more practical. Extensive experiments demonstrate that our
model is generally beneficial for various state-of-the-art generation methods,
significantly boosting the quality and realism of their generated 3D objects,
with natural relighting effects and substantially improved geometry.

ÊëòË¶ÅÔºö<paragraph>Ëá™Âãï 3D ÂÖßÂÆπÂâµ‰ΩúËøëÂπ¥‰æÜÂÇôÂèóÈóúÊ≥®ÔºåÂõ†ÁÇ∫ÂÆÉÂú®ÂêÑÁ®ÆÊáâÁî®‰∏≠ÂÖ∑ÊúâÊΩõÂäõÔºå‰æãÂ¶ÇË¶ñË®äÈÅäÊà≤„ÄÅÈõªÂΩ±Áî¢Ê•≠Âíå AR/VR„ÄÇÊì¥Êï£Ê®°ÂûãÂíåÂ§öÊ®°ÊÖãÊ®°ÂûãÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÈ°ØËëóÊèêÂçá‰∫ÜÊ†πÊìöÂñÆ‰∏Ä RGB ÂΩ±ÂÉèÁîüÊàê 3D Áâ©‰ª∂ÁöÑÂìÅË≥™ÂíåÊïàÁéá„ÄÇÁÑ∂ËÄåÔºåÂç≥‰ΩøÊòØ‰ΩøÁî®ÊúÄÂÖàÈÄ≤ÊñπÊ≥ïÁîüÊàêÁöÑ 3D Áâ©‰ª∂ÔºåËàá‰∫∫Â∑•Âª∫Á´ãÁöÑË≥áÁî¢Áõ∏ÊØî‰ªç‰∏çÁõ°ÁêÜÊÉ≥„ÄÇÈÄô‰∫õÊñπÊ≥ïÂÉÖËÄÉÊÖÆÁ¥ãÁêÜËÄåÈùûÊùêË≥™ÔºåÈÄô‰ΩøÂæóÂÆÉÂÄëÂú®ÂØ´ÂØ¶Ê∏≤Êüì„ÄÅÈáçÊñ∞ÊâìÂÖâÂíåÂΩàÊÄßÂ§ñËßÄÁ∑®ËºØÊñπÈù¢ÈÅ≠ÈÅáÊåëÊà∞„ÄÇËÄå‰∏îÂÆÉÂÄëÈÇÑÂ≠òÂú®Âπæ‰ΩïÂΩ¢ÁãÄÂíåÈ´òÈ†ªÁéáÁ¥ãÁêÜÁ¥∞ÁØÄ‰πãÈñìÂö¥ÈáçÁöÑÈåØ‰Ωç„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÂæûÂü∫ÊñºÁâ©ÁêÜÁöÑÊ∏≤Êüì (PBR) ÊùêË≥™ÁöÑËßíÂ∫¶ÊèêÂçáÁîüÊàê 3D Áâ©‰ª∂ÁöÑÂìÅË≥™„ÄÇÈÄèÈÅéÂàÜÊûê PBR ÊùêË≥™ÁöÑÁµÑÊàêÔºåÊàëÂÄëÈÅ∏ÊìáËÄÉÊÖÆÊº´ÂèçÂ∞ÑÁéá„ÄÅÁ≤óÁ≥ôÂ∫¶„ÄÅÈáëÂ±¨Â∫¶ÂíåÂáπÂá∏Ë≤ºÂúñ„ÄÇÂ∞çÊñºÊº´ÂèçÂ∞ÑÁéáÂíåÂáπÂá∏Ë≤ºÂúñÔºåÊàëÂÄëÂà©Áî®Âú®ÂêàÊàêË≥áÊñô‰∏äÂæÆË™øÁöÑ Stable Diffusion ‰æÜÊèêÂèñÈÄô‰∫õÂÄºÔºå‰∏¶ÂâµÊñ∞‰ΩøÁî®ÈÄô‰∫õÂæÆË™øÊ®°Âûã‰æÜÂèñÂæóÁîüÊàêÁâ©‰ª∂ÁöÑ 3D ‰∏ÄËá¥Êº´ÂèçÂ∞ÑÁéá UV ÂíåÂáπÂá∏ UV„ÄÇÂú®Á≤óÁ≥ôÂ∫¶ÂíåÈáëÂ±¨Â∫¶Ë≤ºÂúñÊñπÈù¢ÔºåÊàëÂÄëÊé°Áî®ÂçäËá™ÂãïÁöÑÊµÅÁ®ã‰æÜÊèê‰æõ‰∫íÂãïË™øÊï¥ÁöÑÁ©∫ÈñìÔºåÊàëÂÄëÁõ∏‰ø°ÈÄôÊõ¥ÂØ¶Áî®„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÈÄöÂ∏∏ÊúâÂà©ÊñºÂêÑÁ®ÆÊúÄÂÖàÈÄ≤ÁöÑÁîüÊàêÊñπÊ≥ïÔºåÈ°ØËëóÊèêÂçáÂÖ∂ÁîüÊàê 3D Áâ©‰ª∂ÁöÑÂìÅË≥™ÂíåÁúüÂØ¶ÊÑüÔºåÂÖ∑ÊúâËá™ÁÑ∂ÁöÑÈáçÊñ∞ÊâìÂÖâÊïàÊûúÂíåÂ§ßÂπÖÊîπÂñÑÁöÑÂπæ‰ΩïÂΩ¢ÁãÄ„ÄÇ</paragraph>

##### **Debiasing Classifiers by Amplifying Bias with Latent Diffusion and Large Language Models**
2411.16079v1 by Donggeun Ko, Dongjun Lee, Namjun Park, Wonkyeong Shim, Jaekwang Kim

Neural networks struggle with image classification when biases are learned
and misleads correlations, affecting their generalization and performance.
Previous methods require attribute labels (e.g. background, color) or utilizes
Generative Adversarial Networks (GANs) to mitigate biases. We introduce
DiffuBias, a novel pipeline for text-to-image generation that enhances
classifier robustness by generating bias-conflict samples, without requiring
training during the generation phase. Utilizing pretrained diffusion and image
captioning models, DiffuBias generates images that challenge the biases of
classifiers, using the top-$K$ losses from a biased classifier ($f_B$) to
create more representative data samples. This method not only debiases
effectively but also boosts classifier generalization capabilities. To the best
of our knowledge, DiffuBias is the first approach leveraging a stable diffusion
model to generate bias-conflict samples in debiasing tasks. Our comprehensive
experimental evaluations demonstrate that DiffuBias achieves state-of-the-art
performance on benchmark datasets. We also conduct a comparative analysis of
various generative models in terms of carbon emissions and energy consumption
to highlight the significance of computational efficiency.

ÊëòË¶ÅÔºöÁ•ûÁ∂ìÁ∂≤Ë∑ØÂú®Â≠∏ÁøíÂÅèÂ∑ÆÊôÇÊúÉÂú®ÂΩ±ÂÉèÂàÜÈ°û‰∏äÈÅ≠ÈÅáÂõ∞Èõ£Ôºå‰∏¶Ë™§Â∞éÁõ∏ÈóúÊÄßÔºåÂΩ±ÈüøÂÖ∂Ê¶ÇÂåñÂíåÊïàËÉΩ„ÄÇ
ÂÖàÂâçÁöÑÂÅöÊ≥ïÈúÄË¶ÅÂ±¨ÊÄßÊ®ôÁ±§Ôºà‰æãÂ¶ÇËÉåÊôØ„ÄÅÈ°èËâ≤ÔºâÊàñÂà©Áî®ÁîüÊàêÂ∞çÊäóÁ∂≤Ë∑Ø (GAN) ‰æÜÊ∏õËºïÂÅèÂ∑Æ„ÄÇÊàëÂÄëÂºïÈÄ≤ DiffuBiasÔºåÈÄôÊòØ‰∏ÄÂÄãÁî®ÊñºÊñáÂ≠óËΩâÂΩ±ÂÉèÁîüÊàêÁöÑÊñ∞Á©éÁÆ°Á∑öÔºåÈÄèÈÅéÁî¢ÁîüÂÅèÂ∑ÆË°ùÁ™ÅÊ®£Êú¨‰æÜÂ¢ûÂº∑ÂàÜÈ°ûÂô®ÁöÑÁ©©ÂÅ•ÊÄßÔºåËÄå‰∏çÈúÄË¶ÅÂú®ÁîüÊàêÈöéÊÆµÈÄ≤Ë°åË®ìÁ∑¥„ÄÇDiffuBias Âà©Áî®È†êÂÖàË®ìÁ∑¥Â•ΩÁöÑÊì¥Êï£ÂíåÂΩ±ÂÉèÊ®ôÈ°åÊ®°ÂûãÔºåÁî¢ÁîüÊåëÊà∞ÂàÜÈ°ûÂô®ÂÅèÂ∑ÆÁöÑÂΩ±ÂÉèÔºå‰ΩøÁî®ÊúâÂÅèÂ∑ÆÂàÜÈ°ûÂô® ($f_B$) ‰∏≠ÁöÑÈ†ÇÁ´Ø-$K$ ÊêçÂ§±‰æÜÂª∫Á´ãÊõ¥ÂÖ∑‰ª£Ë°®ÊÄßÁöÑË≥áÊñôÊ®£Êú¨„ÄÇÈÄôÁ®ÆÊñπÊ≥ï‰∏çÂÉÖËÉΩÊúâÊïàÊ∂àÈô§ÂÅèÂ∑ÆÔºåÈÇÑËÉΩÊèêÂçáÂàÜÈ°ûÂô®ÁöÑÊ¶ÇÂåñËÉΩÂäõ„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåDiffuBias ÊòØÁ¨¨‰∏ÄÂÄãÂà©Áî®Á©©ÂÆöÁöÑÊì¥Êï£Ê®°ÂûãÂú®ÂéªÂÅèÂ∑Æ‰ªªÂãô‰∏≠Áî¢ÁîüÂÅèÂ∑ÆË°ùÁ™ÅÊ®£Êú¨ÁöÑÊñπÊ≥ï„ÄÇÊàëÂÄëÂÖ®Èù¢ÁöÑÂØ¶È©óË©ï‰º∞Ë≠âÊòéÔºåDiffuBias Âú®Âü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÂèñÂæó‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÈÇÑÂ∞çÂêÑÁ®ÆÁîüÊàêÊ®°ÂûãÂú®Á¢≥ÊéíÊîæÂíåËÉΩÊ∫êÊ∂àËÄóÊñπÈù¢ÁöÑÈÄ≤Ë°åÊØîËºÉÂàÜÊûêÔºå‰ª•Âº∑Ë™øÈÅãÁÆóÊïàÁéáÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **SAGEval: The frontiers of Satisfactory Agent based NLG Evaluation for reference-free open-ended text**
2411.16077v1 by Reshmi Ghosh, Tianyi Yao, Lizzy Chen, Sadid Hasan, Tianwei Chen, Dario Bernal, Huitian Jiao, H M Sajjad Hossain

Large Language Model (LLM) integrations into applications like Microsoft365
suite and Google Workspace for creating/processing documents, emails,
presentations, etc. has led to considerable enhancements in productivity and
time savings. But as these integrations become more more complex, it is
paramount to ensure that the quality of output from the LLM-integrated
applications are relevant and appropriate for use. Identifying the need to
develop robust evaluation approaches for natural language generation, wherein
references/ground labels doesn't exist or isn't amply available, this paper
introduces a novel framework called "SAGEval" which utilizes a critiquing Agent
to provide feedback on scores generated by LLM evaluators. We show that the
critiquing Agent is able to rectify scores from LLM evaluators, in absence of
references/ground-truth labels, thereby reducing the need for labeled data even
for complex NLG evaluation scenarios, like the generation of JSON-structured
forms/surveys with responses in different styles like multiple choice, likert
ratings, single choice questions, etc.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êï¥ÂêàÂà∞ Microsoft365 Â•ó‰ª∂Âíå Google Workspace Á≠âÊáâÁî®Á®ãÂºè‰∏≠ÔºåÁî®ÊñºÂª∫Á´ã/ËôïÁêÜÊñá‰ª∂„ÄÅÈõªÂ≠êÈÉµ‰ª∂„ÄÅÁ∞°Â†±Á≠âÁ≠âÔºåÈÄôÂ∑≤Á∂ìÂ§ßÂπÖÊèêÂçá‰∫ÜÁîüÁî¢Âäõ‰∏¶ÁØÄÁúÅÊôÇÈñì„ÄÇ‰ΩÜÊòØÈö®ËëóÈÄô‰∫õÊï¥ÂêàËÆäÂæóË∂ä‰æÜË∂äË§áÈõúÔºåÊúÄÈáçË¶ÅÁöÑÊòØË¶ÅÁ¢∫‰øù LLM Êï¥ÂêàÊáâÁî®Á®ãÂºèËº∏Âá∫ÁöÑÂìÅË≥™Ëàá‰ΩøÁî®ÁõÆÁöÑÁõ∏Èóú‰∏îÈÅ©Áï∂„ÄÇÊú¨Ë´ñÊñáËæ®Ë≠òÂá∫ÈñãÁôºÂÅ•ÂÖ®Ëá™ÁÑ∂Ë™ûË®ÄÁî¢ÁîüË©ï‰º∞ÊñπÊ≥ïÁöÑÈúÄÊ±ÇÔºåÂÖ∂‰∏≠ÂèÉËÄÉ/Âü∫Á§éÊ®ôÁ±§‰∏çÂ≠òÂú®ÊàñÁÑ°Ê≥ïÂÖÖÂàÜÂèñÂæóÔºåÂõ†Ê≠§‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫„ÄåSAGEval„ÄçÁöÑÊñ∞Êû∂ÊßãÔºåÂÆÉÂà©Áî®ÊâπË©ï‰ª£ÁêÜÊèê‰æõ LLM Ë©ï‰º∞Âô®Áî¢ÁîüÁöÑÂàÜÊï∏ÂõûÈ•ã„ÄÇÊàëÂÄëÂ±ïÁ§∫Âá∫Âú®Ê≤íÊúâÂèÉËÄÉ/Âü∫Á§éÁúüÂØ¶Ê®ôÁ±§ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊâπË©ï‰ª£ÁêÜËÉΩÂ§†‰øÆÊ≠£ LLM Ë©ï‰º∞Âô®ÁöÑÂàÜÊï∏ÔºåÂõ†Ê≠§Âç≥‰ΩøÂ∞çÊñºË§áÈõúÁöÑ NLG Ë©ï‰º∞ÊÉÖÂ¢ÉÔºå‰æãÂ¶ÇÁî¢ÁîüÂÖ∑Êúâ‰∏çÂêåÊ®£ÂºèÁöÑÂõûÊáâÔºà‰æãÂ¶ÇÂ§öÈáçÈÅ∏Êìá„ÄÅÊùéÂÖãÁâπÈáèË°®„ÄÅÂñÆÈÅ∏È°åÁ≠âÁ≠âÔºâÁöÑ JSON ÁµêÊßãÂåñË°®ÂñÆ/Ë™øÊü•Ôºå‰πüËÉΩÊ∏õÂ∞ëÊ®ôË®òË≥áÊñôÁöÑÈúÄÊ±Ç„ÄÇ

##### **The brain versus AI: World-model-based versatile circuit computation underlying diverse functions in the neocortex and cerebellum**
2411.16075v1 by Shogo Ohmae, Keiko Ohmae

AI's significant recent advances using general-purpose circuit computations
offer a potential window into how the neocortex and cerebellum of the brain are
able to achieve a diverse range of functions across sensory, cognitive, and
motor domains, despite their uniform circuit structures. However, comparing the
brain and AI is challenging unless clear similarities exist, and past reviews
have been limited to comparison of brain-inspired vision AI and the visual
neocortex. Here, to enable comparisons across diverse functional domains, we
subdivide circuit computation into three elements -- circuit structure,
input/outputs, and the learning algorithm -- and evaluate the similarities for
each element. With this novel approach, we identify wide-ranging similarities
and convergent evolution in the brain and AI, providing new insights into key
concepts in neuroscience. Furthermore, inspired by processing mechanisms of AI,
we propose a new theory that integrates established neuroscience theories,
particularly the theories of internal models and the mirror neuron system. Both
the neocortex and cerebellum predict future world events from past information
and learn from prediction errors, thereby acquiring models of the world. These
models enable three core processes: (1) Prediction -- generating future
information, (2) Understanding -- interpreting the external world via
compressed and abstracted sensory information, and (3) Generation --
repurposing the future-information generation mechanism to produce other types
of outputs. The universal application of these processes underlies the ability
of the neocortex and cerebellum to accomplish diverse functions with uniform
circuits. Our systematic approach, insights, and theory promise groundbreaking
advances in understanding the brain.

ÊëòË¶ÅÔºö<paragraph>AI ËøëÊúüÂú®ÈÄöÁî®ÈõªË∑ØÈÅãÁÆó‰∏äÂèñÂæóÈáçÂ§ßÈÄ≤Â±ïÔºå
Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊΩõÂú®Á™óÂè£ÔºåËÆìÊàëÂÄëÂæó‰ª•‰∫ÜËß£Â§ßËÖ¶ÁöÑÊñ∞ÁöÆË≥™ÂíåÂ∞èËÖ¶Â¶Ç‰Ωï
Âú®ÊÑüÂÆò„ÄÅË™çÁü•ÂíåÈÅãÂãïÈ†òÂüüÂØ¶ÁèæÂêÑÁ®ÆÂäüËÉΩÔºåÂÑòÁÆ°ÂÆÉÂÄëÁöÑÈõªË∑ØÁµêÊßãÊòØÁµ±‰∏ÄÁöÑ„ÄÇÁÑ∂ËÄåÔºåÈô§ÈùûÂ≠òÂú®ÊòéÁ¢∫ÁöÑÁõ∏‰ººÊÄßÔºåÂê¶ÂâáÊØîËºÉÂ§ßËÖ¶Âíå AI ÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåËÄå‰∏îÈÅéÂéªÁöÑË©ïË´ñÂÉÖÈôêÊñºÊØîËºÉÂèóÂ§ßËÖ¶ÂïüÁôºÁöÑË¶ñË¶∫ AI ÂíåË¶ñË¶∫Êñ∞ÁöÆË≥™„ÄÇÂú®Ê≠§ÔºåÁÇ∫‰∫ÜËÉΩÂ§†Âú®‰∏çÂêåÁöÑÂäüËÉΩÈ†òÂüüÈÄ≤Ë°åÊØîËºÉÔºåÊàëÂÄëÂ∞áÈõªË∑ØÈÅãÁÆóÁ¥∞ÂàÜÁÇ∫‰∏âÂÄãË¶ÅÁ¥†‚Äî‚ÄîÈõªË∑ØÁµêÊßã„ÄÅËº∏ÂÖ•/Ëº∏Âá∫ÂíåÂ≠∏ÁøíÊºîÁÆóÊ≥ï‚Äî‚Äî‰∏¶Ë©ï‰º∞ÊØèÂÄãË¶ÅÁ¥†ÁöÑÁõ∏‰ººÊÄß„ÄÇÈÄèÈÅéÈÄôÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÊàëÂÄëÁôºÁèæ‰∫ÜÂ§ßËÖ¶Âíå AI ‰πãÈñìÂª£Ê≥õÁöÑÁõ∏‰ººÊÄßÂíåË∂®ÂêåÊºîÂåñÔºåÁÇ∫Á•ûÁ∂ìÁßëÂ≠∏‰∏≠ÁöÑÈóúÈçµÊ¶ÇÂøµÊèê‰æõ‰∫ÜÊñ∞ÁöÑË¶ãËß£„ÄÇÊ≠§Â§ñÔºåÂèóÂà∞ AI ËôïÁêÜÊ©üÂà∂ÁöÑÂïüÁôºÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁêÜË´ñÔºåÊï¥Âêà‰∫ÜÊó¢ÂÆöÁöÑÁ•ûÁ∂ìÁßëÂ≠∏ÁêÜË´ñÔºåÁâπÂà•ÊòØÂÖßÈÉ®Ê®°ÂûãÁêÜË´ñÂíåÈè°ÂÉèÁ•ûÁ∂ìÂÖÉÁ≥ªÁµ±ÁêÜË´ñ„ÄÇÊñ∞ÁöÆË≥™ÂíåÂ∞èËÖ¶ÈÉΩÊ†πÊìöÈÅéÂéªÁöÑË≥áË®äÈ†êÊ∏¨Êú™‰æÜÁöÑ‰∏ñÁïå‰∫ã‰ª∂Ôºå‰∏¶ÂæûÈ†êÊ∏¨Ë™§Â∑Æ‰∏≠Â≠∏ÁøíÔºåÂæûËÄåÁç≤Âæó‰∏ñÁïåÁöÑÊ®°Âûã„ÄÇÈÄô‰∫õÊ®°ÂûãÂïüÁî®‰∫Ü‰∏âÂÄãÊ†∏ÂøÉÊµÅÁ®ãÔºö(1) È†êÊ∏¨‚Äî‚ÄîÁî¢ÁîüÊú™‰æÜË≥áË®äÔºå(2) ÁêÜËß£‚Äî‚ÄîÈÄèÈÅéÂ£ìÁ∏ÆÂíåÊäΩË±°ÁöÑÊÑüÂÆòË≥áË®ä‰æÜË©ÆÈáãÂ§ñÈÉ®‰∏ñÁïåÔºå‰ª•Âèä (3) ÁîüÊàê‚Äî‚ÄîÈáçÊñ∞Âà©Áî®Êú™‰æÜË≥áË®äÁîüÊàêÊ©üÂà∂‰æÜÁî¢ÁîüÂÖ∂‰ªñÈ°ûÂûãÁöÑËº∏Âá∫„ÄÇÈÄô‰∫õÊµÅÁ®ãÁöÑÈÄöÁî®ÊáâÁî®ÊòØÊñ∞ÁöÆË≥™ÂíåÂ∞èËÖ¶ËÉΩÂ§†‰ΩøÁî®Áµ±‰∏ÄÈõªË∑ØÂÆåÊàêÂ§öÁ®ÆÂäüËÉΩÁöÑÂü∫Á§é„ÄÇÊàëÂÄëÁ≥ªÁµ±ÊÄßÁöÑÊñπÊ≥ï„ÄÅË¶ãËß£ÂíåÁêÜË´ñÊúâÊúõÂú®ÁêÜËß£Â§ßËÖ¶ÊñπÈù¢ÂèñÂæóÁ™ÅÁ†¥ÊÄßÁöÑÈÄ≤Â±ï„ÄÇ</paragraph>

##### **UnitedVLN: Generalizable Gaussian Splatting for Continuous Vision-Language Navigation**
2411.16053v1 by Guangzhao Dai, Jian Zhao, Yuantao Chen, Yusen Qin, Hao Zhao, Guosen Xie, Yazhou Yao, Xiangbo Shu, Xuelong Li

Vision-and-Language Navigation (VLN), where an agent follows instructions to
reach a target destination, has recently seen significant advancements. In
contrast to navigation in discrete environments with predefined trajectories,
VLN in Continuous Environments (VLN-CE) presents greater challenges, as the
agent is free to navigate any unobstructed location and is more vulnerable to
visual occlusions or blind spots. Recent approaches have attempted to address
this by imagining future environments, either through predicted future visual
images or semantic features, rather than relying solely on current
observations. However, these RGB-based and feature-based methods lack intuitive
appearance-level information or high-level semantic complexity crucial for
effective navigation. To overcome these limitations, we introduce a novel,
generalizable 3DGS-based pre-training paradigm, called UnitedVLN, which enables
agents to better explore future environments by unitedly rendering
high-fidelity 360 visual images and semantic features. UnitedVLN employs two
key schemes: search-then-query sampling and separate-then-united rendering,
which facilitate efficient exploitation of neural primitives, helping to
integrate both appearance and semantic information for more robust navigation.
Extensive experiments demonstrate that UnitedVLN outperforms state-of-the-art
methods on existing VLN-CE benchmarks.

ÊëòË¶ÅÔºöË¶ñË¶∫ÂíåË™ûË®ÄÂ∞éËà™ (VLN) ËÆì‰ª£ÁêÜ‰∫∫ÈÅµÂæ™ÊåáÁ§∫ÂâçÂæÄÁõÆÊ®ôÁõÆÁöÑÂú∞ÔºåÊúÄËøëÊúâ‰∫ÜÈ°ØËëóÁöÑÈÄ≤Â±ï„ÄÇËàáÂÖ∑ÊúâÈ†êÂÆöÁæ©ËªåË∑°ÁöÑÈõ¢Êï£Áí∞Â¢É‰∏≠ÁöÑÂ∞éËà™Áõ∏ÊØîÔºåÈÄ£Á∫åÁí∞Â¢É‰∏≠ÁöÑ VLN (VLN-CE) ÊèêÂá∫Êõ¥Â§ßÁöÑÊåëÊà∞ÔºåÂõ†ÁÇ∫‰ª£ÁêÜ‰∫∫ÂèØ‰ª•Ëá™Áî±Â∞éËà™‰ªª‰ΩïÁÑ°ÈöúÁ§ô‰ΩçÁΩÆÔºå‰∏¶‰∏îÊõ¥ÂÆπÊòìÂèóÂà∞Ë¶ñË¶∫ÈÅÆÊìãÊàñÁõ≤ÈªûÁöÑÂΩ±Èüø„ÄÇÊúÄËøëÁöÑÊñπÊ≥ïÂòóË©¶ÈÄöÈÅéÊÉ≥ÂÉèÊú™‰æÜÁöÑÁí∞Â¢ÉÔºàÈÄèÈÅéÈ†êÊ∏¨Êú™‰æÜÁöÑË¶ñË¶∫ÂΩ±ÂÉèÊàñË™ûÁæ©ÁâπÂæµÔºâ‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåËÄå‰∏çÊòØÂÉÖ‰æùË≥¥ÁõÆÂâçÁöÑËßÄÂØü„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÂü∫Êñº RGB ÂíåÂü∫ÊñºÁâπÂæµÁöÑÊñπÊ≥ïÁº∫‰πèÊúâÊïàÁöÑÂ∞éËà™ÊâÄÈúÄÁöÑÁõ¥ËßÄÂ§ñËßÄÂ±§Á¥öË≥áË®äÊàñÈ´òÂ±§Á¥öË™ûÁæ©Ë§áÈõúÊÄß„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞Á©é„ÄÅÂèØÊ¶ÇÊã¨ÁöÑÂü∫Êñº 3DGS ÁöÑÈ†êË®ìÁ∑¥ÁØÑ‰æãÔºåÁ®±ÁÇ∫ UnitedVLNÔºåÂÆÉ‰Ωø‰ª£ÁêÜ‰∫∫ËÉΩÂ§†ÈÄèÈÅéÁµ±‰∏ÄÂëàÁèæÈ´ò‰øùÁúü 360 Ë¶ñË¶∫ÂΩ±ÂÉèÂíåË™ûÁæ©ÁâπÂæµ‰æÜÊõ¥Â•ΩÂú∞Êé¢Á¥¢Êú™‰æÜÁöÑÁí∞Â¢É„ÄÇUnitedVLN Êé°Áî®ÂÖ©ÂÄãÈóúÈçµÊñπÊ°àÔºöÂÖàÊêúÂ∞ãÂÜçÊü•Ë©¢ÁöÑÊäΩÊ®£ÂíåÂÖàÂàÜÈñãÂÜçÁµ±‰∏ÄÁöÑÂëàÁèæÔºåÈÄôÊúâÂä©ÊñºÊúâÊïàÂà©Áî®Á•ûÁ∂ìÂü∫ÂÖÉÔºåÂπ´Âä©Êï¥ÂêàÂ§ñËßÄÂíåË™ûÁæ©Ë≥áË®ä‰ª•ÈÄ≤Ë°åÊõ¥Á©©ÂÅ•ÁöÑÂ∞éËà™„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºåUnitedVLN Âú®ÁèæÊúâÁöÑ VLN-CE Âü∫Ê∫ñ‰∏äÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ï„ÄÇ

##### **Predicting Emergent Capabilities by Finetuning**
2411.16035v1 by Charlie Snell, Eric Wallace, Dan Klein, Sergey Levine

A fundamental open challenge in modern LLM scaling is the lack of
understanding around emergent capabilities. In particular, language model
pretraining loss is known to be highly predictable as a function of compute.
However, downstream capabilities are far less predictable -- sometimes even
exhibiting emergent jumps -- which makes it challenging to anticipate the
capabilities of future models. In this work, we first pose the task of
emergence prediction: given access to current LLMs that have random few-shot
accuracy on a task, can we predict whether future models (GPT-N+1) will have
non-trivial accuracy on that task? We then discover a simple insight for this
problem: finetuning LLMs on a given task can shift the point in scaling at
which emergence occurs towards less capable models. To operationalize this
insight, we can finetune LLMs with varying amounts of data and fit a parametric
function that predicts when emergence will occur (i.e., "emergence laws"). We
validate this approach using four standard NLP benchmarks where large-scale
open-source LLMs already demonstrate emergence (MMLU, GSM8K, CommonsenseQA, and
CoLA). Using only small-scale LLMs, we find that, in some cases, we can
accurately predict whether models trained with up to 4x more compute have
emerged. Finally, we present a case study of two realistic uses for emergence
prediction.

ÊëòË¶ÅÔºöÁèæ‰ª£ LLM Êì¥ÂÖÖÁöÑ‰∏ÄÂÄãÂü∫Êú¨ÂÖ¨ÈñãÊåëÊà∞ÊòØÁº∫‰πèÂ∞çÊñ∞ËààËÉΩÂäõÁöÑÁêÜËß£„ÄÇÁâπÂà•ÊòØÔºåË™ûË®ÄÊ®°ÂûãÈ†êË®ìÁ∑¥ÊêçÂ§±Â∑≤Áü•È´òÂ∫¶ÂèØÈ†êÊ∏¨ÁÇ∫Ë®àÁÆóÂáΩÊï∏„ÄÇÁÑ∂ËÄåÔºå‰∏ãÊ∏∏ËÉΩÂäõÁöÑÂèØÈ†êÊ∏¨ÊÄßÈÅ†‰ΩéÂæóÂ§öÔºåÊúâÊôÇÁîöËá≥Ë°®ÁèæÂá∫Êñ∞ËààË∑≥Ë∫çÔºåÈÄô‰ΩøÂæóÈ†êÊ∏¨Êú™‰æÜÊ®°ÂûãÁöÑËÉΩÂäõÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖàÊèêÂá∫Êñ∞ËààÈ†êÊ∏¨‰ªªÂãôÔºöÂú®Ë®™ÂïèÂÖ∑Êúâ‰ªªÂãô‰∏≠Èö®Ê©üÂ∞ëÊ¨°Ê∫ñÁ¢∫Â∫¶ÁöÑÁï∂Ââç LLM ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊàëÂÄëËÉΩÈ†êÊ∏¨Êú™‰æÜÊ®°Âûã (GPT-N+1) ÊòØÂê¶ÊúÉÂú®Ë©≤‰ªªÂãô‰∏≠ÂÖ∑ÊúâÈùûÂπ≥Âá°Ê∫ñÁ¢∫Â∫¶ÔºüÁÑ∂ÂæåÔºåÊàëÂÄëÁôºÁèæ‰∫Ü‰∏ÄÂÄãÁ∞°ÂñÆÁöÑË¶ãËß£‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºöÂú®ÁâπÂÆö‰ªªÂãô‰∏äÂæÆË™ø LLM ÂèØ‰ª•Â∞áÂá∫ÁèæÁôºÁîüÊôÇÁöÑÊì¥ÂÖÖÈªûËΩâÁßªÂà∞ÂäüËÉΩËºÉÂº±ÁöÑÊ®°Âûã„ÄÇÁÇ∫‰∫ÜÂ∞áÊ≠§Ë¶ãËß£‰ªòË´∏ÂØ¶ÊñΩÔºåÊàëÂÄëÂèØ‰ª•‰ΩøÁî®‰∏çÂêåÊï∏ÈáèÁöÑÊï∏ÊìöÂæÆË™ø LLMÔºå‰∏¶Êì¨ÂêàÂèÉÊï∏ÂáΩÊï∏‰æÜÈ†êÊ∏¨Êñ∞Ëàà‰ΩïÊôÇÊúÉÁôºÁîüÔºàÂç≥„ÄåÊñ∞ËààÂÆöÂæã„ÄçÔºâ„ÄÇÊàëÂÄë‰ΩøÁî®ÂõõÂÄãÊ®ôÊ∫ñ NLP Âü∫Ê∫ñÈ©óË≠âÊ≠§ÊñπÊ≥ïÔºåÂÖ∂‰∏≠Â§ßË¶èÊ®°ÈñãÊ∫ê LLM Â∑≤Â±ïÁ§∫Êñ∞ËààÔºàMMLU„ÄÅGSM8K„ÄÅÂ∏∏Ë≠òÂïèÁ≠îÂíå CoLAÔºâ„ÄÇÂÉÖ‰ΩøÁî®Â∞èË¶èÊ®° LLMÔºåÊàëÂÄëÁôºÁèæÔºåÂú®Êüê‰∫õÊÉÖÊ≥Å‰∏ãÔºåÊàëÂÄëÂèØ‰ª•Ê∫ñÁ¢∫È†êÊ∏¨‰ΩøÁî®Â§öÈÅî 4 ÂÄçË®àÁÆóË®ìÁ∑¥ÁöÑÊ®°ÂûãÊòØÂê¶Â∑≤Âá∫Áèæ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊ°à‰æãÁ†îÁ©∂ÔºåË™™ÊòéÊñ∞ËààÈ†êÊ∏¨ÁöÑÂÖ©ÂÄãÂØ¶ÈöõÁî®ÈÄî„ÄÇ

##### **From Dashcam Videos to Driving Simulations: Stress Testing Automated Vehicles against Rare Events**
2411.16027v1 by Yan Miao, Georgios Fainekos, Bardh Hoxha, Hideki Okamoto, Danil Prokhorov, Sayan Mitra

Testing Automated Driving Systems (ADS) in simulation with realistic driving
scenarios is important for verifying their performance. However, converting
real-world driving videos into simulation scenarios is a significant challenge
due to the complexity of interpreting high-dimensional video data and the
time-consuming nature of precise manual scenario reconstruction. In this work,
we propose a novel framework that automates the conversion of real-world car
crash videos into detailed simulation scenarios for ADS testing. Our approach
leverages prompt-engineered Video Language Models(VLM) to transform dashcam
footage into SCENIC scripts, which define the environment and driving behaviors
in the CARLA simulator, enabling the generation of realistic simulation
scenarios. Importantly, rather than solely aiming for one-to-one scenario
reconstruction, our framework focuses on capturing the essential driving
behaviors from the original video while offering flexibility in parameters such
as weather or road conditions to facilitate search-based testing. Additionally,
we introduce a similarity metric that helps iteratively refine the generated
scenario through feedback by comparing key features of driving behaviors
between the real and simulated videos. Our preliminary results demonstrate
substantial time efficiency, finishing the real-to-sim conversion in minutes
with full automation and no human intervention, while maintaining high fidelity
to the original driving events.

ÊëòË¶ÅÔºöÂú®Ê®°Êì¨‰∏≠‰ΩøÁî®ÈÄºÁúüÁöÑÈßïÈßõÊÉÖÂ¢ÉÊ∏¨Ë©¶Ëá™ÂãïÈßïÈßõÁ≥ªÁµ± (ADS) Â∞çÊñºÈ©óË≠âÂÖ∂ÊïàËÉΩÈùûÂ∏∏ÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÈõ£‰ª•Ë©ÆÈáãÈ´òÁ∂≠Â∫¶ÁöÑÂΩ±ÁâáË≥áÊñôÔºå‰ª•ÂèäÁ≤æÁ¢∫ÊâãÂãïÂ†¥ÊôØÈáçÂª∫ËÄóÊôÇÔºåÂ∞áÁúüÂØ¶‰∏ñÁïåÁöÑÈßïÈßõÂΩ±ÁâáËΩâÊèõÊàêÊ®°Êì¨Â†¥ÊôØÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊû∂ÊßãÔºåÂèØËá™ÂãïÂ∞áÁúüÂØ¶‰∏ñÁïåÁöÑÊ±ΩËªäÁ¢∞ÊíûÂΩ±ÁâáËΩâÊèõÊàê ADS Ê∏¨Ë©¶ÁöÑË©≥Á¥∞Ê®°Êì¨Â†¥ÊôØ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂà©Áî®ÊèêÁ§∫Â∑•Á®ãÂåñÂΩ±ÁâáË™ûË®ÄÊ®°Âûã (VLM) Â∞áË°åËªäË®òÈåÑÂô®Áï´Èù¢ËΩâÊèõÊàê SCENIC ËÖ≥Êú¨ÔºåÂÆöÁæ© CARLA Ê®°Êì¨Âô®‰∏≠ÁöÑÁí∞Â¢ÉÂíåÈßïÈßõË°åÁÇ∫ÔºåÈÄ≤ËÄåÁî¢ÁîüÈÄºÁúüÁöÑÊ®°Êì¨Â†¥ÊôØ„ÄÇÈáçË¶ÅÁöÑÊòØÔºåÊàëÂÄëÁöÑÊû∂Êßã‰∏¶ÈùûÂÉÖ‰ª•‰∏ÄÂ∞ç‰∏ÄÁöÑÂ†¥ÊôØÈáçÂª∫ÁÇ∫ÁõÆÊ®ôÔºåËÄåÊòØÂ∞àÊ≥®ÊñºÊì∑ÂèñÂéüÂßãÂΩ±Áâá‰∏≠ÁöÑÂü∫Êú¨ÈßïÈßõË°åÁÇ∫ÔºåÂêåÊôÇÂú®Â§©Ê∞£ÊàñÈÅìË∑ØÁãÄÊ≥ÅÁ≠âÂèÉÊï∏‰∏≠Êèê‰æõÂΩàÊÄßÔºå‰ª•Âà©ÊñºÊêúÂ∞ãÂºèÊ∏¨Ë©¶„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÁõ∏‰ººÂ∫¶ÈáèÊï∏ÔºåÊúâÂä©ÊñºÈÄèÈÅéÊØîËºÉÁúüÂØ¶ÂíåÊ®°Êì¨ÂΩ±Áâá‰∏≠ÈßïÈßõË°åÁÇ∫ÁöÑÈóúÈçµÁâπÂæµÔºåÂèçË¶ÜÊîπÂñÑÁî¢ÁîüÁöÑÂ†¥ÊôØ„ÄÇÊàëÂÄëÁöÑÂàùÊ≠•ÁµêÊûúË≠âÊòé‰∫ÜÂ§ßÂπÖÁöÑÁúÅÊôÇÊïàÁéáÔºåÂú®ÂÆåÂÖ®Ëá™ÂãïÂåñ‰∏îÁÑ°ÈúÄ‰∫∫Â∑•‰ªãÂÖ•ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊñºÊï∏ÂàÜÈêòÂÖßÂÆåÊàêÁúüÂØ¶Âà∞Ê®°Êì¨ÁöÑËΩâÊèõÔºåÂêåÊôÇÁ∂≠ÊåÅÂ∞çÂéüÂßãÈßïÈßõ‰∫ã‰ª∂ÁöÑÈ´òÂ∫¶‰øùÁúüÂ∫¶„ÄÇ

##### **TransCompressor: LLM-Powered Multimodal Data Compression for Smart Transportation**
2411.16020v1 by Huanqi Yang, Rucheng Wu, Weitao Xu

The incorporation of Large Language Models (LLMs) into smart transportation
systems has paved the way for improving data management and operational
efficiency. This study introduces TransCompressor, a novel framework that
leverages LLMs for efficient compression and decompression of multimodal
transportation sensor data. TransCompressor has undergone thorough evaluation
with diverse sensor data types, including barometer, speed, and altitude
measurements, across various transportation modes like buses, taxis, and MTRs.
Comprehensive evaluation illustrates the effectiveness of TransCompressor in
reconstructing transportation sensor data at different compression ratios. The
results highlight that, with well-crafted prompts, LLMs can utilize their vast
knowledge base to contribute to data compression processes, enhancing data
storage, analysis, and retrieval in smart transportation settings.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Á¥çÂÖ•Êô∫ÊÖßÈÅãËº∏Á≥ªÁµ±Â∑≤ÁÇ∫ÊîπÂñÑË≥áÊñôÁÆ°ÁêÜÂíåÁáüÈÅãÊïàÁéáÈã™Ë∑Ø„ÄÇÊú¨Á†îÁ©∂‰ªãÁ¥π TransCompressorÔºå‰∏ÄÂÄãÂà©Áî® LLM ÊúâÊïàÂ£ìÁ∏ÆÂíåËß£Â£ìÁ∏ÆÂ§öÊ®°ÊÖãÈÅãËº∏ÊÑüÊ∏¨Âô®Ë≥áÊñôÁöÑÊñ∞Á©éÊû∂Êßã„ÄÇTransCompressor Â∑≤ÈáùÂ∞çÂêÑÁ®ÆÊÑüÊ∏¨Âô®Ë≥áÊñôÈ°ûÂûãÈÄ≤Ë°åÂæπÂ∫ïË©ï‰º∞ÔºåÂåÖÊã¨Ê∞£Â£ìË®à„ÄÅÈÄüÂ∫¶ÂíåÈ´òÂ∫¶Ê∏¨ÈáèÔºåÊ∂µËìãÂÖ¨Ëªä„ÄÅË®àÁ®ãËªäÂíåÂú∞ÈêµÁ≠âÂêÑÁ®ÆÈÅãËº∏Ê®°Âºè„ÄÇÂÖ®Èù¢ÁöÑË©ï‰º∞Ë™™Êòé‰∫Ü TransCompressor Âú®‰ª•‰∏çÂêåÂ£ìÁ∏ÆÊØîÈáçÂª∫ÈÅãËº∏ÊÑüÊ∏¨Âô®Ë≥áÊñôÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÁµêÊûúÂº∑Ë™øÔºåÈÄèÈÅéÁ≤æÂøÉË®≠Ë®àÁöÑÊèêÁ§∫ÔºåLLM ÂèØ‰ª•Âà©Áî®ÂÖ∂ÈæêÂ§ßÁöÑÁü•Ë≠òÂ∫´‰æÜÂçîÂä©Ë≥áÊñôÂ£ìÁ∏ÆÁ®ãÂ∫èÔºåÈÄ≤ËÄåÂº∑ÂåñÊô∫ÊÖßÈÅãËº∏Ë®≠ÂÆö‰∏≠ÁöÑË≥áÊñôÂÑ≤Â≠ò„ÄÅÂàÜÊûêÂíåÊì∑Âèñ„ÄÇ

##### **Performance Implications of Multi-Chiplet Neural Processing Units on Autonomous Driving Perception**
2411.16007v1 by Mohanad Odema, Luke Chen, Hyoukjun Kwon, Mohammad Abdullah Al Faruque

We study the application of emerging chiplet-based Neural Processing Units to
accelerate vehicular AI perception workloads in constrained automotive
settings. The motivation stems from how chiplets technology is becoming
integral to emerging vehicular architectures, providing a cost-effective
trade-off between performance, modularity, and customization; and from
perception models being the most computationally demanding workloads in a
autonomous driving system. Using the Tesla Autopilot perception pipeline as a
case study, we first breakdown its constituent models and profile their
performance on different chiplet accelerators. From the insights, we propose a
novel scheduling strategy to efficiently deploy perception workloads on
multi-chip AI accelerators. Our experiments using a standard DNN performance
simulator, MAESTRO, show our approach realizes 82% and 2.8x increase in
throughput and processing engines utilization compared to monolithic
accelerator designs.

ÊëòË¶ÅÔºöÊàëÂÄëÁ†îÁ©∂‰∫ÜÊñ∞ËààÊô∂ÁâáÁ¥öÁ•ûÁ∂ìËôïÁêÜÂñÆÂÖÉÂú®ÂèóÈôêÊ±ΩËªäÁí∞Â¢É‰∏≠Âä†ÈÄüËªäËºõ AI ÊÑüÁü•Â∑•‰ΩúË≤†ËºâÁöÑÊáâÁî®„ÄÇÂÖ∂ÂãïÊ©üÊ∫êËá™ÊñºÊô∂ÁâáÊäÄË°ìÂ¶Ç‰ΩïÊàêÁÇ∫Êñ∞ËààÊ±ΩËªäÊû∂ÊßãÁöÑÁµÑÊàêÈÉ®ÂàÜÔºåÂú®ÊïàËÉΩ„ÄÅÊ®°ÁµÑÂåñÂíåÂÆ¢Ë£ΩÂåñ‰πãÈñìÊèê‰æõÂÖ∑ÊàêÊú¨ÊïàÁõäÁöÑÊäòË°∑ÊñπÊ°àÔºõ‰ª•ÂèäÊÑüÁü•Ê®°ÂûãÂú®Ëá™ÂãïÈßïÈßõÁ≥ªÁµ±‰∏≠ÊòØÊúÄÈúÄË¶ÅÈÅãÁÆóÁöÑÂ∑•‰ΩúË≤†Ëºâ„ÄÇ‰ΩøÁî® Tesla Autopilot ÊÑüÁü•ÁÆ°Á∑ö‰ΩúÁÇ∫Ê°à‰æãÁ†îÁ©∂ÔºåÊàëÂÄëÈ¶ñÂÖàÂàÜËß£ÂÖ∂ÁµÑÊàêÊ®°ÂûãÔºå‰∏¶ÂàÜÊûêÂÖ∂Âú®‰∏çÂêåÊô∂ÁâáÂä†ÈÄüÂô®‰∏äÁöÑÊïàËÉΩ„ÄÇÊ†πÊìöÈÄô‰∫õË¶ãËß£ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊéíÁ®ãÁ≠ñÁï•Ôºå‰ª•ÊúâÊïàÁéáÁöÑÊñπÂºèÂú®Â§öÊô∂Áâá AI Âä†ÈÄüÂô®‰∏äÈÉ®ÁΩ≤ÊÑüÁü•Â∑•‰ΩúË≤†Ëºâ„ÄÇÊàëÂÄë‰ΩøÁî®Ê®ôÊ∫ñ DNN ÊïàËÉΩÊ®°Êì¨Âô® MAESTRO ÈÄ≤Ë°åÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåËàáÂñÆ‰∏ÄÂä†ÈÄüÂô®Ë®≠Ë®àÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂèØÂØ¶ÁèæÂêûÂêêÈáèÂíåËôïÁêÜÂºïÊìé‰ΩøÁî®ÁéáÂàÜÂà•ÊèêÂçá 82% Âíå 2.8 ÂÄç„ÄÇ

##### **eFedLLM: Efficient LLM Inference Based on Federated Learning**
2411.16003v1 by Shengwen Ding, Chenhui Hu

Large Language Models (LLMs) herald a transformative era in artificial
intelligence (AI). However, the expansive scale of data and parameters of LLMs
requires high-demand computational and memory resources, restricting their
accessibility to a broader range of users and researchers. This paper
introduces an effective approach that enhances the operational efficiency and
affordability of LLM inference. By utilizing transformer-based federated
learning (FL) with model-parallel distributed training, our model efficiently
distributes the computational loads and memory requirements across a network of
participants. This strategy permits users, especially those with limited
resources to train state-of-the-art LLMs collaboratively. We also innovate an
incentive mechanism within the FL framework, rewarding constructive
contributions and filtering out malicious activities, thereby safeguarding the
integrity and reliability of the training process. Concurrently, we leverage
memory hierarchy strategies and Singular Value Decomposition (SVD) on weight
matrices to boost computational and memory efficiencies further. Our results,
derived from formulaic analyses and numerical calculations, demonstrate
significant optimization of resource use and democratize access to cutting-edge
LLMs, ensuring that a wide scale of users can both contribute to and benefit
from these advanced models.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) È†êÂëäËëó‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑËÆäÈù©ÊôÇ‰ª£„ÄÇÁÑ∂ËÄåÔºåLLM ÁöÑË≥áÊñôÂíåÂèÉÊï∏Ë¶èÊ®°ÈæêÂ§ßÔºåÈúÄË¶ÅÂ§ßÈáèÁöÑÈÅãÁÆóÂíåË®òÊÜ∂È´îË≥áÊ∫êÔºåÈôêÂà∂‰∫ÜÂÖ∂Â∞çÊõ¥Âª£Ê≥õÁöÑ‰ΩøÁî®ËÄÖÂíåÁ†îÁ©∂‰∫∫Âì°ÁöÑÂèØÂèäÊÄß„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊúâÊïàÁöÑÊñπÊ≥ïÔºåÂèØ‰ª•ÊèêÈ´ò LLM Êé®Ë´ñÁöÑÈÅã‰ΩúÊïàÁéáÂíåË≤†ÊìîËÉΩÂäõ„ÄÇÈÄèÈÅéÂà©Áî®Âü∫Êñº Transformer ÁöÑËÅØÈÇ¶Â≠∏Áøí (FL) ÂíåÊ®°Âûã‰∏¶Ë°åÂàÜÂ∏ÉÂºèË®ìÁ∑¥ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ª•ÊúâÊïàÂú∞Â∞áÈÅãÁÆóË≤†ËºâÂíåË®òÊÜ∂È´îÈúÄÊ±ÇÂàÜ‰ΩàÂú®ÂèÉËàáËÄÖÁöÑÁ∂≤Ë∑Ø‰∏≠„ÄÇÊ≠§Á≠ñÁï•ÂÖÅË®±‰ΩøÁî®ËÄÖÔºàÁâπÂà•ÊòØÈÇ£‰∫õË≥áÊ∫êÊúâÈôêÁöÑ‰ΩøÁî®ËÄÖÔºâÂêà‰ΩúË®ìÁ∑¥ÊúÄÂÖàÈÄ≤ÁöÑ LLM„ÄÇÊàëÂÄëÈÇÑÂú® FL Êû∂Êßã‰∏≠ÂâµÊñ∞‰∫Ü‰∏ÄÁ®ÆÊøÄÂãµÊ©üÂà∂ÔºåÁçéÂãµÂª∫Ë®≠ÊÄßÁöÑË≤¢Áçª‰∏¶ÈÅéÊøæÊéâÊÉ°ÊÑèÊ¥ªÂãïÔºåÂæûËÄå‰øùË≠∑Ë®ìÁ∑¥ÈÅéÁ®ãÁöÑÂÆåÊï¥ÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÂêåÊôÇÔºåÊàëÂÄëÂà©Áî®Ë®òÊÜ∂È´îÈöéÂ±§Á≠ñÁï•ÂíåÊ¨äÈáçÁü©Èô£‰∏äÁöÑÂ•áÁï∞ÂÄºÂàÜËß£ (SVD) ‰æÜÈÄ≤‰∏ÄÊ≠•ÊèêÂçáÈÅãÁÆóÂíåË®òÊÜ∂È´îÊïàÁéá„ÄÇÊàëÂÄëÂæûÂÖ¨ÂºèÂàÜÊûêÂíåÊï∏ÂÄºË®àÁÆó‰∏≠ÂæóÂá∫ÁöÑÁµêÊûúÔºåË≠âÊòé‰∫ÜË≥áÊ∫ê‰ΩøÁî®ÁöÑÈ°ØËëóÊúÄ‰Ω≥ÂåñÔºå‰∏¶‰ΩøÂ∞ñÁ´ØÁöÑ LLM Ê∞ë‰∏ªÂåñÔºåÁ¢∫‰øùÂª£Ê≥õÁöÑ‰ΩøÁî®ËÄÖÊó¢ËÉΩË≤¢ÁçªÈÄô‰∫õÂÖàÈÄ≤Ê®°ÂûãÔºå‰πüËÉΩÂæû‰∏≠ÂèóÁõä„ÄÇ

##### **Exploring Performance Contrasts in TableQA: Step-by-Step Reasoning Boosts Bigger Language Models, Limits Smaller Language Models**
2411.16002v1 by Haoyan Yang, Yixuan Wang, Keyue Tong, Hongjin Zhu, Yuanxin Zhang

This paper proposes a detailed prompting flow, termed Table-Logic, to
investigate the performance contrasts between bigger and smaller language
models (LMs) utilizing step-by-step reasoning methods in the TableQA task. The
method processes tasks by sequentially identifying critical columns and rows
given question and table with its structure, determining necessary
aggregations, calculations, or comparisons, and finally inferring the results
to generate a precise prediction. By deploying this method, we observe a 7.8%
accuracy improvement in bigger LMs like Llama-3-70B compared to the vanilla on
HybridQA, while smaller LMs like Llama-2-7B shows an 11% performance decline.
We empirically investigate the potential causes of performance contrasts by
exploring the capabilities of bigger and smaller LMs from various dimensions in
TableQA task. Our findings highlight the limitations of the step-by-step
reasoning method in small models and provide potential insights for making
improvements.

ÊëòË¶ÅÔºöÈÄôÁØáË´ñÊñáÊèêÂá∫‰∫ÜË©≥Áõ°ÁöÑÊèêÁ§∫ÊµÅÁ®ãÔºåÁ®±ÁÇ∫ Table-LogicÔºå‰ª•Êé¢Ë®éÂú® TableQA ‰ªªÂãô‰∏≠Âà©Áî®ÈÄêÊ≠•Êé®ÁêÜÊñπÊ≥ïÁöÑÂ§ßÂûãÂíåÂ∞èÂûãË™ûË®ÄÊ®°Âûã (LM) ‰πãÈñìÁöÑÊïàËÉΩÂ∞çÊØî„ÄÇÊ≠§ÊñπÊ≥ïÈÄèÈÅéÊåâÈ†ÜÂ∫èË≠òÂà•ÈóúÈçµÊ¨Ñ‰ΩçÂíåÂàóÔºàÁµ¶ÂÆöÂïèÈ°åÂíåË°®Ê†ºÂèäÂÖ∂ÁµêÊßãÔºâ„ÄÅÊ±∫ÂÆöÂøÖË¶ÅÁöÑÂΩôÁ∏Ω„ÄÅË®àÁÆóÊàñÊØîËºÉÔºåÊúÄÂæåÊé®Ë´ñÁµêÊûú‰ª•Áî¢ÁîüÁ≤æÁ¢∫È†êÊ∏¨Ôºå‰æÜËôïÁêÜ‰ªªÂãô„ÄÇÈÄèÈÅéÈÉ®ÁΩ≤Ê≠§ÊñπÊ≥ïÔºåÊàëÂÄëËßÄÂØüÂà∞ Llama-3-70B Á≠âÂ§ßÂûã LM Âú® HybridQA ‰∏äÁöÑÊ∫ñÁ¢∫Â∫¶ÊèêÂçá‰∫Ü 7.8%ÔºåËÄå Llama-2-7B Á≠âÂ∞èÂûã LM ÂâáÈ°ØÁ§∫Âá∫ÊïàËÉΩ‰∏ãÈôç 11%„ÄÇÊàëÂÄëÈÄèÈÅéÊé¢Á¥¢Â§ßÂûãÂíåÂ∞èÂûã LM Âú® TableQA ‰ªªÂãô‰∏≠ÂêÑÊñπÈù¢ÁöÑËÉΩÂäõÔºåÂØ¶Ë≠âË™øÊü•ÊïàËÉΩÂ∞çÊØîÁöÑÊΩõÂú®ÂéüÂõ†„ÄÇÊàëÂÄëÁöÑÁôºÁèæÁ™ÅÈ°Ø‰∫ÜÂ∞èÂûãÊ®°Âûã‰∏≠ÈÄêÊ≠•Êé®ÁêÜÊñπÊ≥ïÁöÑÈôêÂà∂Ôºå‰∏¶Êèê‰æõÊΩõÂú®Ë¶ãËß£‰ª•ÈÄ≤Ë°åÊîπÈÄ≤„ÄÇ

##### **Multi-ToM: Evaluating Multilingual Theory of Mind Capabilities in Large Language Models**
2411.15999v1 by Jayanta Sadhu, Ayan Antik Khan, Noshin Nawal, Sanju Basak, Abhik Bhattacharjee, Rifat Shahriyar

Theory of Mind (ToM) refers to the cognitive ability to infer and attribute
mental states to oneself and others. As large language models (LLMs) are
increasingly evaluated for social and cognitive capabilities, it remains
unclear to what extent these models demonstrate ToM across diverse languages
and cultural contexts. In this paper, we introduce a comprehensive study of
multilingual ToM capabilities aimed at addressing this gap. Our approach
includes two key components: (1) We translate existing ToM datasets into
multiple languages, effectively creating a multilingual ToM dataset and (2) We
enrich these translations with culturally specific elements to reflect the
social and cognitive scenarios relevant to diverse populations. We conduct
extensive evaluations of six state-of-the-art LLMs to measure their ToM
performance across both the translated and culturally adapted datasets. The
results highlight the influence of linguistic and cultural diversity on the
models' ability to exhibit ToM, and questions their social reasoning
capabilities. This work lays the groundwork for future research into enhancing
LLMs' cross-cultural social cognition and contributes to the development of
more culturally aware and socially intelligent AI systems. All our data and
code are publicly available.

ÊëòË¶ÅÔºöÂøÉÊô∫ÁêÜË´ñ (ToM) ÊåáÁöÑÊòØÊé®Ë´ñÂíåÊ≠∏Âõ†ÂøÉÊô∫ÁãÄÊÖãÁµ¶Ëá™Â∑±ÂíåÂà•‰∫∫ÁöÑË™çÁü•ËÉΩÂäõ„ÄÇÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄêÊº∏Ë¢´Ë©ï‰º∞ÂÖ∂Á§æ‰∫§ÂíåË™çÁü•ËÉΩÂäõÔºåÈÄô‰∫õÊ®°ÂûãÂú®‰∏çÂêåË™ûË®ÄÂíåÊñáÂåñËÉåÊôØ‰∏≠Â±ïÁèæ ToM ÁöÑÁ®ãÂ∫¶‰ªç‰∏çÊòéÁ¢∫„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÈ†ÖÈáùÂ∞çÂ§öË™ûË®Ä ToM ËÉΩÂäõÁöÑÂÖ®Èù¢Á†îÁ©∂ÔºåÊó®Âú®Ëß£Ê±∫ÈÄôÂÄãÂïèÈ°å„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂåÖÂê´ÂÖ©ÂÄãÈóúÈçµÁµÑÊàêÈÉ®ÂàÜÔºö(1) ÊàëÂÄëÂ∞áÁèæÊúâÁöÑ ToM Ë≥áÊñôÈõÜÁøªË≠ØÊàêÂ§öÁ®ÆË™ûË®ÄÔºåÊúâÊïàÂú∞Âª∫Á´ã‰∫Ü‰∏ÄÂÄãÂ§öË™ûË®Ä ToM Ë≥áÊñôÈõÜÔºå(2) ÊàëÂÄëÁî®ÊñáÂåñÁâπÂÆöÂÖÉÁ¥†Ë±êÂØåÈÄô‰∫õÁøªË≠ØÔºå‰ª•ÂèçÊò†Ëàá‰∏çÂêåÊóèÁæ§Áõ∏ÈóúÁöÑÁ§æÊúÉÂíåË™çÁü•ÊÉÖÂ¢É„ÄÇÊàëÂÄëÂ∞çÂÖ≠ÂÄãÊúÄÂÖàÈÄ≤ÁöÑ LLM ÈÄ≤Ë°åÂª£Ê≥õÁöÑË©ï‰º∞Ôºå‰ª•Ë°°ÈáèÂÆÉÂÄëÂú®ÁøªË≠ØÂíåÊñáÂåñÊîπÁ∑®Ë≥áÊñôÈõÜ‰∏≠ÁöÑ ToM Ë°®Áèæ„ÄÇÁµêÊûúÁ™ÅÈ°Ø‰∫ÜË™ûË®ÄÂíåÊñáÂåñÂ§öÊ®£ÊÄßÂ∞çÊ®°ÂûãÂ±ïÁèæ ToM ËÉΩÂäõÁöÑÂΩ±ÈüøÔºå‰∏¶Ë≥™ÁñëÂÆÉÂÄëÁöÑÁ§æÊúÉÊé®ÁêÜËÉΩÂäõ„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫Êú™‰æÜÂ¢ûÂº∑ LLM ÁöÑË∑®ÊñáÂåñÁ§æÊúÉË™çÁü•ÁöÑÁ†îÁ©∂Â•†ÂÆö‰∫ÜÂü∫Á§éÔºå‰∏¶ÊúâÂä©ÊñºÈñãÁôºÊõ¥ÂÖ∑ÊñáÂåñÊÑèË≠òÂíåÁ§æÊúÉÊô∫ÊÖßÁöÑ AI Á≥ªÁµ±„ÄÇÊàëÂÄëÁöÑË≥áÊñôÂíåÁ®ãÂºèÁ¢ºÁöÜÂÖ¨ÈñãÊèê‰æõ„ÄÇ

##### **PIANIST: Learning Partially Observable World Models with LLMs for Multi-Agent Decision Making**
2411.15998v1 by Jonathan Light, Sixue Xing, Yuanzhe Liu, Weiqin Chen, Min Cai, Xiusi Chen, Guanzhi Wang, Wei Cheng, Yisong Yue, Ziniu Hu

Effective extraction of the world knowledge in LLMs for complex
decision-making tasks remains a challenge. We propose a framework PIANIST for
decomposing the world model into seven intuitive components conducive to
zero-shot LLM generation. Given only the natural language description of the
game and how input observations are formatted, our method can generate a
working world model for fast and efficient MCTS simulation. We show that our
method works well on two different games that challenge the planning and
decision making skills of the agent for both language and non-language based
action taking, without any training on domain-specific training data or
explicitly defined world model.

ÊëòË¶ÅÔºöÂ∞çÊñºË§áÈõúÁöÑÊ±∫Á≠ñ‰ªªÂãôÔºåÂú® LLM ‰∏≠ÊúâÊïàÊèêÂèñ‰∏ñÁïåÁü•Ë≠ò‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÊåëÊà∞„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊû∂Êßã PIANISTÔºåÂ∞á‰∏ñÁïåÊ®°ÂûãÂàÜËß£ÁÇ∫‰∏ÉÂÄãÁõ¥ËßÄÁöÑÁµÑÊàêÈÉ®ÂàÜÔºåÊúâÂà©ÊñºÈõ∂Ê¨°Â≠∏Áøí LLM ÁîüÊàê„ÄÇÂÉÖÁµ¶ÂÆöÈÅäÊà≤ÁöÑËá™ÁÑ∂Ë™ûË®ÄÊèèËø∞ÂíåËº∏ÂÖ•ËßÄÊ∏¨ÂÄºÁöÑÊ†ºÂºèÂåñÊñπÂºèÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂ∞±ËÉΩÁî¢Áîü‰∏ÄÂÄãÈÅã‰ΩúÁöÑ‰∏ñÁïåÊ®°ÂûãÔºåÁî®ÊñºÂø´ÈÄü‰∏îÊúâÊïàÁéáÁöÑ MCTS Ê®°Êì¨„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÂÖ©Á®Æ‰∏çÂêåÁöÑÈÅäÊà≤‰∏≠ÈÅã‰ΩúËâØÂ•ΩÔºåÈÄô‰∫õÈÅäÊà≤ÊåëÊà∞‰∫Ü‰ª£ÁêÜ‰∫∫Âú®Ë™ûË®ÄÂíåÈùûË™ûË®ÄÂãï‰ΩúÊé°ÂèñÊñπÈù¢ÁöÑË¶èÂäÉÂíåÊ±∫Á≠ñÂà∂ÂÆöÊäÄËÉΩÔºåËÄåÁÑ°ÈúÄÈáùÂ∞çÁâπÂÆöÈ†òÂüüÁöÑË®ìÁ∑¥Ë≥áÊñôÊàñÊòéÁ¢∫ÂÆöÁæ©ÁöÑ‰∏ñÁïåÊ®°ÂûãÈÄ≤Ë°å‰ªª‰ΩïË®ìÁ∑¥„ÄÇ

##### **Ensuring Fair LLM Serving Amid Diverse Applications**
2411.15997v1 by Redwan Ibne Seraj Khan, Kunal Jain, Haiying Shen, Ankur Mallick, Anjaly Parayil, Anoop Kulkarni, Steve Kofsky, Pankhuri Choudhary, Ren√®e St. Amant, Rujia Wang, Yue Cheng, Ali R. Butt, Victor R√ºhle, Chetan Bansal, Saravan Rajmohan

In a multi-tenant large language model (LLM) serving platform hosting diverse
applications, some users may submit an excessive number of requests, causing
the service to become unavailable to other users and creating unfairness.
Existing fairness approaches do not account for variations in token lengths
across applications and multiple LLM calls, making them unsuitable for such
platforms. To address the fairness challenge, this paper analyzes millions of
requests from thousands of users on MS CoPilot, a real-world multi-tenant LLM
platform hosted by Microsoft. Our analysis confirms the inadequacy of existing
methods and guides the development of FairServe, a system that ensures fair LLM
access across diverse applications. FairServe proposes
application-characteristic aware request throttling coupled with a weighted
service counter based scheduling technique to curb abusive behavior and ensure
fairness. Our experimental results on real-world traces demonstrate FairServe's
superior performance compared to the state-of-the-art method in ensuring
fairness. We are actively working on deploying our system in production,
expecting to benefit millions of customers world-wide.

ÊëòË¶ÅÔºöÂú®‰∏ÄÂÄãÂ§öÁßüÊà∂ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊúçÂãôÂπ≥Âè∞‰∏äÔºåË®óÁÆ°ËëóÂêÑÁ®ÆÊáâÁî®Á®ãÂºèÔºå‰∏Ä‰∫õ‰ΩøÁî®ËÄÖÂèØËÉΩÊúÉÊèê‰∫§ÈÅéÂ§öÁöÑË¶ÅÊ±ÇÔºåÂ∞éËá¥ÊúçÂãôÂ∞çÂÖ∂‰ªñ‰ΩøÁî®ËÄÖ‰∏çÂèØÁî®Ôºå‰∏¶ÈÄ†Êàê‰∏çÂÖ¨Âπ≥„ÄÇÁèæÊúâÁöÑÂÖ¨Âπ≥ÊñπÊ≥ïÊ≤íÊúâËÄÉÊÖÆÂà∞‰∏çÂêåÊáâÁî®Á®ãÂºèÈñìÁöÑÁ¨¶ËôüÈï∑Â∫¶Â∑ÆÁï∞ÂíåÂ§öÂÄã LLM ÂëºÂè´ÔºåÈÄô‰ΩøÂæóÂÆÉÂÄë‰∏çÈÅ©ÂêàÊ≠§È°ûÂπ≥Âè∞„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÂÖ¨Âπ≥ÊÄßÁöÑÊåëÊà∞ÔºåÊú¨ÊñáÂàÜÊûê‰∫Ü‰æÜËá™Êï∏ÂçÉÂêç‰ΩøÁî®ËÄÖÁöÑÊï∏ÁôæËê¨ÂÄãË´ãÊ±ÇÔºåÈÄô‰∫õ‰ΩøÁî®ËÄÖÂú® MS CoPilot ‰∏äÔºåÈÄôÊòØ‰∏ÄÂÄãÁî± Microsoft Ë®óÁÆ°ÁöÑÁúüÂØ¶‰∏ñÁïåÂ§öÁßüÊà∂ LLM Âπ≥Âè∞„ÄÇÊàëÂÄëÁöÑÂàÜÊûêË≠âÂØ¶‰∫ÜÁèæÊúâÊñπÊ≥ïÁöÑ‰∏çË∂≥Ôºå‰∏¶ÊåáÂ∞é‰∫Ü FairServe ÁöÑÈñãÁôºÔºåFairServe ÊòØ‰∏ÄÂÄãÁ≥ªÁµ±ÔºåÂèØÁ¢∫‰øù‰∏çÂêåÊáâÁî®Á®ãÂºè‰πãÈñìÁöÑ LLM ÂÖ¨Âπ≥Â≠òÂèñ„ÄÇFairServe ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊáâÁî®Á®ãÂºèÁâπÂæµÊÑüÁü•Ë´ãÊ±ÇÁØÄÊµÅÔºåÂÜçÂä†‰∏ä‰∏ÄÂÄãÂü∫ÊñºÂä†Ê¨äÊúçÂãôË®àÊï∏Âô®ÁöÑÊéíÁ®ãÊäÄË°ìÔºå‰ª•ÈÅèÂà∂Êø´Áî®Ë°åÁÇ∫‰∏¶Á¢∫‰øùÂÖ¨Âπ≥ÊÄß„ÄÇÊàëÂÄëÂú®ÁúüÂØ¶‰∏ñÁïåËøΩËπ§‰∏äÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫Ü FairServe ËàáÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåÂú®Á¢∫‰øùÂÖ¨Âπ≥ÊÄßÊñπÈù¢ÂÖ∑ÊúâÂÑ™Áï∞ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÊ≠£Âú®Á©çÊ•µÂú∞Â∞áÊàëÂÄëÁöÑÁ≥ªÁµ±ÈÉ®ÁΩ≤Âà∞ÁîüÁî¢Áí∞Â¢É‰∏≠ÔºåÈ†êË®àÂ∞á‰ΩøÂÖ®ÁêÉÊï∏ÁôæËê¨ÂÆ¢Êà∂ÂèóÁõä„ÄÇ

##### **Investigating Factuality in Long-Form Text Generation: The Roles of Self-Known and Self-Unknown**
2411.15993v1 by Lifu Tu, Rui Meng, Shafiq Joty, Yingbo Zhou, Semih Yavuz

Large language models (LLMs) have demonstrated strong capabilities in text
understanding and generation. However, they often lack factuality, producing a
mixture of true and false information, especially in long-form generation. In
this work, we investigates the factuality of long-form text generation across
various large language models (LLMs), including GPT-4, Gemini-1.5-Pro,
Claude-3-Opus, Llama-3-70B, and Mistral. Our analysis reveals that factuality
scores tend to decline in later sentences of the generated text, accompanied by
a rise in the number of unsupported claims. Furthermore, we explore the
effectiveness of different evaluation settings to assess whether LLMs can
accurately judge the correctness of their own outputs: Self-Known (the
percentage of supported atomic claims, decomposed from LLM outputs, that the
corresponding LLMs judge as correct) and Self-Unknown (the percentage of
unsupported atomic claims that the corresponding LLMs judge as incorrect). The
results indicate that even advanced models like GPT-4 and Gemini-1.5-Pro fail
to achieve perfect Self-Known scores, while their Self-Unknown scores remain
notably above zero, reflecting ongoing uncertainty in their self-assessments.
Moreover, we find a correlation between higher Self-Known scores and improved
factuality, while higher Self-Unknown scores are associated with lower
factuality. Interestingly, even without significant changes in the models'
self-judgment (Self-Known and Self-Unknown), the number of unsupported claims
can increases, likely as an artifact of long-form generation. These findings
show the limitations of current LLMs in long-form generation, and provide
valuable insights for improving factuality in long-form text generation.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁèæÂá∫Âº∑Â§ßÁöÑÊñáÂ≠óÁêÜËß£ÂíåÁîüÊàêËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÂæÄÂæÄÁº∫‰πè‰∫ãÂØ¶ÊÄßÔºåÁî¢ÁîüÁúüÂÅáË®äÊÅØÊ∑∑ÈõúÁöÑÂÖßÂÆπÔºåÁâπÂà•ÊòØÂú®Èï∑ÁØáÁîüÊàê‰∏≠„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂêÑÁ®ÆÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈï∑ÁØáÊñáÂ≠óÁîüÊàêÁöÑÁúüÂØ¶ÊÄßÔºåÂåÖÊã¨ GPT-4„ÄÅGemini-1.5-Pro„ÄÅClaude-3-Opus„ÄÅLlama-3-70B Âíå Mistral„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÁîüÊàêÊñáÂ≠óÁöÑÂæåÁ∫åÂè•Â≠ê‰∏≠ÁúüÂØ¶ÊÄßÂàÜÊï∏ÂæÄÂæÄ‰∏ãÈôçÔºåÂêåÊôÇÁº∫‰πè‰æùÊìöÁöÑ‰∏ªÂºµÊï∏ÈáèÂ¢ûÂä†„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫Ü‰∏çÂêåË©ï‰º∞Ë®≠ÂÆöÁöÑÊúâÊïàÊÄßÔºå‰ª•Ë©ï‰º∞ LLM ÊòØÂê¶ËÉΩÊ∫ñÁ¢∫Âà§Êñ∑ÂÖ∂Ëá™Ë∫´Ëº∏Âá∫ÁöÑÊ≠£Á¢∫ÊÄßÔºöËá™Áü•ÔºàLLM Ëº∏Âá∫‰∏≠ÂàÜËß£Âá∫ÁöÑÂ∑≤ÊîØÊåÅÂéüÂ≠ê‰∏ªÂºµÁöÑÁôæÂàÜÊØîÔºåÂ∞çÊáâÁöÑ LLM Âà§Êñ∑ÁÇ∫Ê≠£Á¢∫ÔºâÂíåËá™‰∏çÁü•ÔºàLLM Ëº∏Âá∫‰∏≠ÂàÜËß£Âá∫ÁöÑÊú™ÊîØÊåÅÂéüÂ≠ê‰∏ªÂºµÁöÑÁôæÂàÜÊØîÔºåÂ∞çÊáâÁöÑ LLM Âà§Êñ∑ÁÇ∫‰∏çÊ≠£Á¢∫Ôºâ„ÄÇÁµêÊûúË°®ÊòéÔºåÂç≥‰ΩøÊòØ GPT-4 Âíå Gemini-1.5-Pro Á≠âÈÄ≤ÈöéÊ®°Âûã‰πüÁÑ°Ê≥ïÈÅîÂà∞ÂÆåÁæéÁöÑËá™Áü•ÂàÜÊï∏ÔºåËÄåÂÖ∂Ëá™‰∏çÁü•ÂàÜÊï∏‰ªçÈ°ØËëóÈ´òÊñºÈõ∂ÔºåÂèçÊò†Âá∫ÂÖ∂Ëá™ÊàëË©ï‰º∞‰∏≠ÊåÅÁ∫åÂ≠òÂú®ÁöÑ‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁôºÁèæËá™Áü•ÂàÜÊï∏ËºÉÈ´òËàáÁúüÂØ¶ÊÄßÊèêÂçá‰πãÈñìÂ≠òÂú®ÈóúËÅØÔºåËÄåËá™‰∏çÁü•ÂàÜÊï∏ËºÉÈ´òÂâáËàáÁúüÂØ¶ÊÄßÈôç‰ΩéÁõ∏Èóú„ÄÇÊúâË∂£ÁöÑÊòØÔºåÂç≥‰ΩøÊ®°ÂûãÁöÑËá™Âà§Êñ∑ÔºàËá™Áü•ÂíåËá™‰∏çÁü•ÔºâÊ≤íÊúâÈ°ØËëóËÆäÂåñÔºåÊú™ÊîØÊåÅ‰∏ªÂºµÁöÑÊï∏Èáè‰ªçÂèØËÉΩÂ¢ûÂä†ÔºåÈÄôÂèØËÉΩÊòØÈï∑ÁØáÁîüÊàêÁöÑÁî¢Áâ©„ÄÇÈÄô‰∫õÁôºÁèæÈ°ØÁ§∫‰∫ÜÁï∂Ââç LLM Âú®Èï∑ÁØáÁîüÊàê‰∏≠ÁöÑÂ±ÄÈôêÊÄßÔºå‰∏¶ÁÇ∫ÊîπÂñÑÈï∑ÁØáÊñáÂ≠óÁîüÊàêÁöÑÁúüÂØ¶ÊÄßÊèê‰æõ‰∫ÜÊúâÂÉπÂÄºÁöÑË¶ãËß£„ÄÇ

##### **Anda: Unlocking Efficient LLM Inference with a Variable-Length Grouped Activation Data Format**
2411.15982v1 by Chao Fang, Man Shi, Robin Geens, Arne Symons, Zhongfeng Wang, Marian Verhelst

The widely-used, weight-only quantized large language models (LLMs), which
leverage low-bit integer (INT) weights and retain floating-point (FP)
activations, reduce storage requirements while maintaining accuracy. However,
this shifts the energy and latency bottlenecks towards the FP activations that
are associated with costly memory accesses and computations. Existing LLM
accelerators focus primarily on computation optimizations, overlooking the
potential of jointly optimizing FP computations and data movement, particularly
for the dominant FP-INT GeMM operations in LLM inference.
  To address these challenges, we investigate the sensitivity of activation
precision across various LLM modules and its impact on overall model accuracy.
Based on our findings, we first propose the Anda data type: an adaptive data
format with group-shared exponent bits and dynamic mantissa bit allocation.
Secondly, we develop an iterative post-training adaptive precision search
algorithm that optimizes the bit-width for different LLM modules to balance
model accuracy, energy efficiency, and inference speed. Lastly, a suite of
hardware optimization techniques is proposed to maximally exploit the benefits
of the Anda format. These include a bit-plane-based data organization scheme,
Anda-enhanced processing units with bit-serial computation, and a runtime
bit-plane Anda compressor to simultaneously optimize storage, computation, and
memory footprints. Our evaluations on FPINT GeMM operations show that Anda
achieves a 2.4x speedup, 4.0x area efficiency, and 3.1x energy efficiency
improvement on average for popular LLMs including OPT, LLaMA, and LLaMA-2
series over the GPU-like FP-FP baseline. Anda demonstrates strong adaptability
across various application scenarios, accuracy requirements, and system
performance, enabling efficient LLM inference across a wide range of deployment
scenarios.

ÊëòË¶ÅÔºöÂª£Ê≥õ‰ΩøÁî®ÁöÑ„ÄÅÂÉÖÊ¨äÈáçÈáèÂåñÁöÑÂ∑®ÈáèË™ûË®ÄÊ®°Âûã (LLM) Âà©Áî®‰Ωé‰ΩçÂÖÉÊï¥Êï∏ (INT) Ê¨äÈáç‰∏¶‰øùÁïôÊµÆÈªû (FP) ÊøÄÊ¥ªÔºåÂú®Á∂≠ÊåÅÁ≤æÊ∫ñÂ∫¶ÁöÑÂêåÊôÇÈôç‰ΩéÂÑ≤Â≠òÈúÄÊ±Ç„ÄÇÁÑ∂ËÄåÔºåÈÄôÂ∞áËÉΩÈáèÂíåÂª∂ÈÅ≤Áì∂È†∏ËΩâÁßªÂà∞ËàáÊòÇË≤¥ÁöÑË®òÊÜ∂È´îÂ≠òÂèñÂíåÈÅãÁÆóÁõ∏ÈóúÁöÑ FP ÊøÄÊ¥ª„ÄÇÁèæÊúâÁöÑ LLM Âä†ÈÄüÂô®‰∏ªË¶ÅÂ∞àÊ≥®ÊñºÈÅãÁÆóÊúÄ‰Ω≥ÂåñÔºåÂøΩË¶ñ‰∫ÜËÅØÂêàÊúÄ‰Ω≥Âåñ FP ÈÅãÁÆóÂíåË≥áÊñôÁßªÂãïÁöÑÊΩõÂäõÔºåÁâπÂà•ÊòØÈáùÂ∞ç LLM Êé®Ë´ñ‰∏≠‰Ωî‰∏ªÂ∞éÂú∞‰ΩçÁöÑ FP-INT GeMM ÈÅãÁÆó„ÄÇ
ÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂêÑÁ®Æ LLM Ê®°ÁµÑ‰∏≠ÊøÄÊ¥ªÁ≤æÂ∫¶ÁöÑÊïèÊÑüÊÄßÂèäÂÖ∂Â∞çÊï¥È´îÊ®°ÂûãÁ≤æÂ∫¶ÁöÑÂΩ±Èüø„ÄÇÊ†πÊìöÊàëÂÄëÁöÑÁôºÁèæÔºåÊàëÂÄëÈ¶ñÂÖàÊèêÂá∫ Anda Ë≥áÊñôÈ°ûÂûãÔºö‰∏ÄÁ®ÆÂÖ∑ÊúâÁæ§ÁµÑÂÖ±Áî®ÊåáÊï∏‰ΩçÂÖÉÂíåÂãïÊÖãÂ∞æÊï∏‰ΩçÂÖÉÈÖçÁΩÆÁöÑËá™ÈÅ©ÊáâË≥áÊñôÊ†ºÂºè„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÂèçË¶ÜË®ìÁ∑¥ÂæåËá™ÈÅ©ÊáâÁ≤æÂ∫¶ÁöÑÊêúÂ∞ãÊºîÁÆóÊ≥ïÔºåÈáùÂ∞ç‰∏çÂêåÁöÑ LLM Ê®°ÁµÑÊúÄ‰Ω≥Âåñ‰ΩçÂÖÉÂØ¨Â∫¶Ôºå‰ª•Âπ≥Ë°°Ê®°ÂûãÁ≤æÂ∫¶„ÄÅËÉΩÊ∫êÊïàÁéáÂíåÊé®Ë´ñÈÄüÂ∫¶„ÄÇÊúÄÂæåÔºåÊèêÂá∫‰∫Ü‰∏ÄÂ•óÁ°¨È´îÊúÄ‰Ω≥ÂåñÊäÄË°ìÔºå‰ª•ÊúÄÂ§ßÁ®ãÂ∫¶Âú∞Âà©Áî® Anda Ê†ºÂºèÁöÑÂÑ™Èªû„ÄÇÈÄô‰∫õÊäÄË°ìÂåÖÊã¨Âü∫Êñº‰ΩçÂÖÉÂπ≥Èù¢ÁöÑË≥áÊñôÁµÑÁπîÊû∂Êßã„ÄÅÂÖ∑Êúâ‰ΩçÂÖÉÂ∫èÂàóÈÅãÁÆóÁöÑ Anda Â¢ûÂº∑ËôïÁêÜÂñÆÂÖÉÔºå‰ª•ÂèäÂêåÊôÇÊúÄ‰Ω≥ÂåñÂÑ≤Â≠ò„ÄÅÈÅãÁÆóÂíåË®òÊÜ∂È´î‰ΩîÁî®Á©∫ÈñìÁöÑÂü∑Ë°åÊôÇÊúü‰ΩçÂÖÉÂπ≥Èù¢ Anda Â£ìÁ∏ÆÂô®„ÄÇÊàëÂÄëÂ∞ç FPINT GeMM ÈÅãÁÆóÁöÑË©ï‰º∞È°ØÁ§∫ÔºåËàáÈ°û GPU ÁöÑ FP-FP Âü∫Ê∫ñÁõ∏ÊØîÔºåAnda Â∞çÂåÖÊã¨ OPT„ÄÅLLaMA Âíå LLaMA-2 Á≥ªÂàóÂú®ÂÖßÁöÑÁÜ±ÈñÄ LLM Âπ≥ÂùáÂèØÂØ¶Áèæ 2.4 ÂÄçÁöÑÈÄüÂ∫¶ÊèêÂçá„ÄÅ4.0 ÂÄçÁöÑÈù¢Á©çÊïàÁéáÂíå 3.1 ÂÄçÁöÑËÉΩÊ∫êÊïàÁéáÊèêÂçá„ÄÇAnda Âú®ÂêÑÁ®ÆÊáâÁî®Â†¥ÊôØ„ÄÅÁ≤æÂ∫¶Ë¶ÅÊ±ÇÂíåÁ≥ªÁµ±ÊïàËÉΩ‰∏≠Â±ïÁèæÂá∫Âº∑Â§ßÁöÑÈÅ©ÊáâÊÄßÔºåÂèØÂú®Âª£Ê≥õÁöÑÈÉ®ÁΩ≤Â†¥ÊôØ‰∏≠ÂØ¶ÁèæÈ´òÊïàÁöÑ LLM Êé®Ë´ñ„ÄÇ

##### **DRIVE: Dual-Robustness via Information Variability and Entropic Consistency in Source-Free Unsupervised Domain Adaptation**
2411.15976v1 by Ruiqiang Xiao, Songning Lai, Yijun Yang, Jiemin Wu, Yutao Yue, Lei Zhu

Adapting machine learning models to new domains without labeled data,
especially when source data is inaccessible, is a critical challenge in
applications like medical imaging, autonomous driving, and remote sensing. This
task, known as Source-Free Unsupervised Domain Adaptation (SFUDA), involves
adapting a pre-trained model to a target domain using only unlabeled target
data, which can lead to issues such as overfitting, underfitting, and poor
generalization due to domain discrepancies and noise. Existing SFUDA methods
often rely on single-model architectures, struggling with uncertainty and
variability in the target domain. To address these challenges, we propose DRIVE
(Dual-Robustness through Information Variability and Entropy), a novel SFUDA
framework leveraging a dual-model architecture. The two models, initialized
with identical weights, work in parallel to capture diverse target domain
characteristics. One model is exposed to perturbations via projection gradient
descent (PGD) guided by mutual information, focusing on high-uncertainty
regions. We also introduce an entropy-aware pseudo-labeling strategy that
adjusts label weights based on prediction uncertainty, ensuring the model
focuses on reliable data while avoiding noisy regions. The adaptation process
has two stages: the first aligns the models on stable features using a mutual
information consistency loss, and the second dynamically adjusts the
perturbation level based on the loss from the first stage, encouraging the
model to explore a broader range of the target domain while preserving existing
performance. This enhances generalization capabilities and robustness against
interference. Evaluations on standard SFUDA benchmarks show that DRIVE
consistently outperforms previous methods, delivering improved adaptation
accuracy and stability across complex target domains.

ÊëòË¶ÅÔºö<paragraph>Âú®Ê≤íÊúâÊ®ôÁ±§Ë≥áÊñôÁöÑÊÉÖÊ≥Å‰∏ãÂ∞áÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãË™øÊï¥Âà∞Êñ∞ÁöÑÈ†òÂüüÔºåÁâπÂà•ÊòØÂú®ÁÑ°Ê≥ïÂèñÂæóÂéüÂßãË≥áÊñôÊôÇÔºåÊòØÈÜ´ÁôÇÂΩ±ÂÉè„ÄÅËá™ÂãïÈßïÈßõÂíåÈÅôÊ∏¨Á≠âÊáâÁî®‰∏≠ÁöÑ‰∏ÄÈ†ÖÈóúÈçµÊåëÊà∞„ÄÇÈÄôÈ†Ö‰ªªÂãôÁ®±ÁÇ∫ÁÑ°‰æÜÊ∫êÈùûÁõ£Áù£È†òÂüüÈÅ©Êáâ (SFUDA)ÔºåÊ∂âÂèä‰ΩøÁî®ÂÉÖÊúâÁöÑÊú™Ê®ôÁ±§ÁõÆÊ®ôË≥áÊñôÂ∞áÈ†êÂÖàË®ìÁ∑¥ÁöÑÊ®°ÂûãË™øÊï¥Âà∞ÁõÆÊ®ôÈ†òÂüüÔºåÈÄôÂèØËÉΩÊúÉÂ∞éËá¥ÈÅéÂ∫¶Êì¨Âêà„ÄÅÊ¨†Êì¨ÂêàÂíåÂõ†È†òÂüüÂ∑ÆÁï∞ÂíåÈõúË®äËÄåÂ∞éËá¥ÁöÑÊ¶ÇÂåñ‰∏çËâØÁ≠âÂïèÈ°å„ÄÇÁèæÊúâÁöÑ SFUDA ÊñπÊ≥ïÈÄöÂ∏∏‰æùË≥¥ÊñºÂñÆ‰∏ÄÊ®°ÂûãÊû∂ÊßãÔºåÈõ£‰ª•ÊáâÂ∞çÁõÆÊ®ôÈ†òÂüü‰∏≠ÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÂíåËÆäÁï∞ÊÄß„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü DRIVEÔºàÈÄèÈÅéË≥áË®äËÆäÁï∞ÊÄßÂíåÁÜµÁöÑÈõôÈáçÁ©©ÂÅ•ÊÄßÔºâÔºå‰∏ÄÁ®ÆÂà©Áî®ÈõôÊ®°ÂûãÊû∂ÊßãÁöÑÊñ∞Á©é SFUDA Êû∂Êßã„ÄÇÈÄôÂÖ©ÂÄãÊ®°Âûã‰ª•Áõ∏ÂêåÁöÑÊ¨äÈáçÂàùÂßãÂåñÔºå‰∏¶Ë°åÂ∑•‰Ωú‰ª•Êì∑Âèñ‰∏çÂêåÁöÑÁõÆÊ®ôÈ†òÂüüÁâπÂæµ„ÄÇÂÖ∂‰∏≠‰∏ÄÂÄãÊ®°ÂûãÈÄèÈÅéÁî±‰∫íË≥áË®äÂºïÂ∞éÁöÑÊäïÂΩ±Ê¢ØÂ∫¶‰∏ãÈôç (PGD) Êö¥Èú≤ÊñºÊìæÂãïÔºåÈáçÈªûÂú®ÊñºÈ´òÂ∫¶‰∏çÁ¢∫ÂÆöÁöÑÂçÄÂüü„ÄÇÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÁÜµÊÑüÁü•ÂÅΩÊ®ôÁ±§Á≠ñÁï•ÔºåË©≤Á≠ñÁï•Ê†πÊìöÈ†êÊ∏¨‰∏çÁ¢∫ÂÆöÊÄßË™øÊï¥Ê®ôÁ±§Ê¨äÈáçÔºåÁ¢∫‰øùÊ®°ÂûãÂ∞àÊ≥®ÊñºÂèØÈù†ÁöÑË≥áÊñôÔºåÂêåÊôÇÈÅøÂÖçÈõúË®äÂçÄÂüü„ÄÇÈÅ©ÊáâÈÅéÁ®ãÂàÜÁÇ∫ÂÖ©ÂÄãÈöéÊÆµÔºöÁ¨¨‰∏ÄÂÄãÈöéÊÆµ‰ΩøÁî®‰∫íË≥áË®ä‰∏ÄËá¥ÊÄßÊêçÂ§±Âú®Á©©ÂÆöÁâπÂæµ‰∏äÂ∞çÈΩäÊ®°ÂûãÔºåÁ¨¨‰∫åÂÄãÈöéÊÆµÊ†πÊìöÁ¨¨‰∏ÄÂÄãÈöéÊÆµÁöÑÊêçÂ§±ÂãïÊÖãË™øÊï¥ÊìæÂãïÁ¥öÂà•ÔºåÈºìÂãµÊ®°ÂûãÊé¢Á¥¢ÁõÆÊ®ôÈ†òÂüüÁöÑÊõ¥Âª£Ê≥õÁØÑÂúçÔºåÂêåÊôÇ‰øùÁïôÁèæÊúâÁöÑÊïàËÉΩ„ÄÇÈÄôÂ¢ûÂº∑‰∫ÜÊ¶ÇÂåñËÉΩÂäõÂíåÂ∞çÂπ≤ÊìæÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÂú®Ê®ôÊ∫ñ SFUDA Âü∫Ê∫ñ‰∏äÁöÑË©ï‰º∞È°ØÁ§∫ÔºåDRIVE ÊåÅÁ∫åÂÑ™ÊñºÂÖàÂâçÁöÑÂêÑÁ®ÆÊñπÊ≥ïÔºåÂú®Ë§áÈõúÁöÑÁõÆÊ®ôÈ†òÂüü‰∏≠Êèê‰æõÊîπÂñÑÁöÑÈÅ©ÊáâÊ∫ñÁ¢∫ÊÄßÂíåÁ©©ÂÆöÊÄß„ÄÇ</paragraph>

##### **Partial Identifiability and Misspecification in Inverse Reinforcement Learning**
2411.15951v1 by Joar Skalse, Alessandro Abate

The aim of Inverse Reinforcement Learning (IRL) is to infer a reward function
$R$ from a policy $\pi$. This problem is difficult, for several reasons. First
of all, there are typically multiple reward functions which are compatible with
a given policy; this means that the reward function is only *partially
identifiable*, and that IRL contains a certain fundamental degree of ambiguity.
Secondly, in order to infer $R$ from $\pi$, an IRL algorithm must have a
*behavioural model* of how $\pi$ relates to $R$. However, the true relationship
between human preferences and human behaviour is very complex, and practically
impossible to fully capture with a simple model. This means that the
behavioural model in practice will be *misspecified*, which raises the worry
that it might lead to unsound inferences if applied to real-world data. In this
paper, we provide a comprehensive mathematical analysis of partial
identifiability and misspecification in IRL. Specifically, we fully
characterise and quantify the ambiguity of the reward function for all of the
behavioural models that are most common in the current IRL literature. We also
provide necessary and sufficient conditions that describe precisely how the
observed demonstrator policy may differ from each of the standard behavioural
models before that model leads to faulty inferences about the reward function
$R$. In addition to this, we introduce a cohesive framework for reasoning about
partial identifiability and misspecification in IRL, together with several
formal tools that can be used to easily derive the partial identifiability and
misspecification robustness of new IRL models, or analyse other kinds of reward
learning algorithms.

ÊëòË¶ÅÔºöÈÄÜÂêëÂº∑ÂåñÂ≠∏Áøí (IRL) ÁöÑÁõÆÊ®ôÊòØÂæûÁ≠ñÁï• $\pi$ Êé®Ë´ñÁçéÂãµÂáΩÊï∏ $R$„ÄÇÈÄôÂÄãÂïèÈ°åÂæàÂõ∞Èõ£ÔºåÂéüÂõ†ÊúâÂπæÂÄã„ÄÇÈ¶ñÂÖàÔºåÈÄöÂ∏∏ÊúâÂ§öÂÄãÁçéÂãµÂáΩÊï∏ËàáÁµ¶ÂÆöÁöÑÁ≠ñÁï•Áõ∏ÂÆπÔºõÈÄôË°®Á§∫ÁçéÂãµÂáΩÊï∏ÂÉÖ *ÈÉ®ÂàÜÂèØË≠òÂà•*ÔºåËÄå IRL ÂåÖÂê´‰∏ÄÂÆöÁ®ãÂ∫¶ÁöÑÂü∫Êú¨Ê®°Á®úÂÖ©ÂèØÊÄß„ÄÇÂÖ∂Ê¨°ÔºåÁÇ∫‰∫ÜÂæû $\pi$ Êé®Ë´ñ $R$ÔºåIRL ÊºîÁÆóÊ≥ïÂøÖÈ†àÂÖ∑ÂÇô $\pi$ Ëàá $R$ Áõ∏ÈóúÊÄßÁöÑ *Ë°åÁÇ∫Ê®°Âºè*„ÄÇÁÑ∂ËÄåÔºå‰∫∫È°ûÂÅèÂ•ΩËàá‰∫∫È°ûË°åÁÇ∫‰πãÈñìÁöÑÁúüÊ≠£Èóú‰øÇÈùûÂ∏∏Ë§áÈõúÔºåËÄå‰∏îÂØ¶Èöõ‰∏ä‰∏çÂèØËÉΩ‰ΩøÁî®Á∞°ÂñÆÊ®°ÂûãÂÆåÂÖ®ÊçïÊçâ„ÄÇÈÄôË°®Á§∫ÂØ¶Èöõ‰∏äÁöÑË°åÁÇ∫Ê®°ÂºèÂ∞áÊúÉ *ÈåØË™§ÊåáÂÆö*ÔºåÈÄôÂºïÁôº‰∫ÜÊìîÊÜÇÔºåÂç≥Â¶ÇÊûúÂ∞áÂÖ∂ÊáâÁî®ÊñºÁúüÂØ¶‰∏ñÁïåË≥áÊñôÔºåÂèØËÉΩÊúÉÂ∞éËá¥‰∏çÂÅ•ÂÖ®ÁöÑÊé®Ë´ñ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÂ∞ç IRL ‰∏≠ÈÉ®ÂàÜÂèØË≠òÂà•ÊÄßÂíåÈåØË™§ÊåáÂÆöÁöÑÂÖ®Èù¢Êï∏Â≠∏ÂàÜÊûê„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂÖ®Èù¢ÊèèËø∞‰∏¶ÈáèÂåñ‰∫ÜÁï∂Ââç IRL ÊñáÁçª‰∏≠ÊúÄÂ∏∏Ë¶ãÁöÑÊâÄÊúâË°åÁÇ∫Ê®°ÂºèÁöÑÁçéÂãµÂáΩÊï∏ÁöÑÊ®°Á®úÂÖ©ÂèØÊÄß„ÄÇÊàëÂÄëÈÇÑÊèê‰æõ‰∫ÜÂøÖË¶Å‰∏îÂÖÖÂàÜÁöÑÊ¢ù‰ª∂ÔºåÁ≤æÁ¢∫ÊèèËø∞‰∫ÜËßÄÂØüÂà∞ÁöÑÁ§∫ÁØÑÁ≠ñÁï•ÂèØËÉΩËàáÊØèÂÄãÊ®ôÊ∫ñË°åÁÇ∫Ê®°ÂºèÊúâ‰Ωï‰∏çÂêåÔºåÁÑ∂ÂæåË©≤Ê®°ÂûãÊâçÊúÉÂ∞çÁçéÂãµÂáΩÊï∏ $R$ Áî¢ÁîüÈåØË™§ÁöÑÊé®Ë´ñ„ÄÇÈô§Ê≠§‰πãÂ§ñÔºåÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÈóúÊñº IRL ‰∏≠ÈÉ®ÂàÜÂèØË≠òÂà•ÊÄßÂíåÈåØË™§ÊåáÂÆöÁöÑÊé®ÁêÜÁöÑÂÖßËÅöÊ°ÜÊû∂Ôºå‰ª•ÂèäÂπæÂÄãÂèØ‰ª•ËºïÈ¨ÜÊé®Â∞éÊñ∞ IRL Ê®°ÂûãÁöÑÈÉ®ÂàÜÂèØË≠òÂà•ÊÄßÂíåÈåØË™§ÊåáÂÆöÂÅ•ÂÖ®ÊÄßÁöÑÊ≠£ÂºèÂ∑•ÂÖ∑ÔºåÊàñÂàÜÊûêÂÖ∂‰ªñÈ°ûÂûãÁöÑÁçéÂãµÂ≠∏ÁøíÊºîÁÆóÊ≥ï„ÄÇ

##### **Generative Context Distillation**
2411.15927v1 by Haebin Shin, Lei Ji, Yeyun Gong, Sungdong Kim, Eunbi Choi, Minjoon Seo

Prompts used in recent large language model based applications are often
fixed and lengthy, leading to significant computational overhead. To address
this challenge, we propose Generative Context Distillation (GCD), a lightweight
prompt internalization method that employs a joint training approach. This
method not only replicates the behavior of models with prompt inputs but also
generates the content of the prompt along with reasons for why the model's
behavior should change accordingly. We demonstrate that our approach
effectively internalizes complex prompts across various agent-based application
scenarios. For effective training without interactions with the dedicated
environments, we introduce a data synthesis technique that autonomously
collects conversational datasets by swapping the roles of the agent and
environment. This method is especially useful in scenarios where only a
predefined prompt is available without a corresponding training dataset. By
internalizing complex prompts, Generative Context Distillation enables
high-performance and efficient inference without the need for explicit prompts.

ÊëòË¶ÅÔºöÊúÄËøëÂü∫ÊñºÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÊáâÁî®Á®ãÂºèÊâÄ‰ΩøÁî®ÁöÑÊèêÁ§∫ÈÄöÂ∏∏ÊòØÂõ∫ÂÆöÁöÑ‰∏îÂÜóÈï∑ÁöÑÔºåÂ∞éËá¥È°ØËëóÁöÑÈÅãÁÆóË≤†Êìî„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄôÂÄãÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫ÁîüÊàêÂºèËÑàÁµ°Ëí∏È§æ (GCD)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆËºïÈáèÁ¥öÁöÑÊèêÁ§∫ÂÖßÂåñÊñπÊ≥ïÔºåÊé°Áî®ËÅØÂêàË®ìÁ∑¥ÊñπÊ≥ï„ÄÇÊ≠§ÊñπÊ≥ï‰∏çÂÉÖË§áË£Ω‰∫ÜÂÖ∑ÊúâÊèêÁ§∫Ëº∏ÂÖ•ÁöÑÊ®°ÂûãÁöÑË°åÁÇ∫ÔºåÈÇÑÁîüÊàê‰∫ÜÊèêÁ§∫ÁöÑÂÖßÂÆπ‰ª•ÂèäÊ®°ÂûãË°åÁÇ∫ÊáâÁõ∏ÊáâÊîπËÆäÁöÑÂéüÂõ†„ÄÇÊàëÂÄëË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÂÅöÊ≥ïÊúâÊïàÂú∞Â∞áË§áÈõúÁöÑÊèêÁ§∫ÂÖßÂåñÂà∞ÂêÑÁ®ÆÂü∫Êñº‰ª£ÁêÜÁöÑÊáâÁî®Â†¥ÊôØ‰∏≠„ÄÇÁÇ∫‰∫ÜÂú®‰∏çËàáÂ∞àÁî®Áí∞Â¢É‰∫íÂãïÁöÑÊÉÖÊ≥Å‰∏ãÈÄ≤Ë°åÊúâÊïàË®ìÁ∑¥ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆË≥áÊñôÂêàÊàêÊäÄË°ìÔºåË©≤ÊäÄË°ìÈÄöÈÅé‰∫§Êèõ‰ª£ÁêÜÂíåÁí∞Â¢ÉÁöÑËßíËâ≤‰æÜËá™‰∏ªÊî∂ÈõÜÂ∞çË©±Ë≥áÊñôÈõÜ„ÄÇÊ≠§ÊñπÊ≥ïÂú®Âè™ÊúâÈ†êÂÆöÁæ©ÊèêÁ§∫ËÄåÊ≤íÊúâÁõ∏ÊáâË®ìÁ∑¥Ë≥áÊñôÈõÜÁöÑÊÉÖÊ≥Å‰∏ãÁâπÂà•ÊúâÁî®„ÄÇÈÄöÈÅéÂÖßÂåñË§áÈõúÁöÑÊèêÁ§∫ÔºåÁîüÊàêÂºèËÑàÁµ°Ëí∏È§æÂèØ‰ª•Âú®‰∏çÈúÄË¶ÅÊòéÁ¢∫ÊèêÁ§∫ÁöÑÊÉÖÊ≥Å‰∏ãÂØ¶ÁèæÈ´òÊÄßËÉΩÂíåÊúâÊïàÁöÑÊé®ÁêÜ„ÄÇ

##### **Deep Learning for automated multi-scale functional field boundaries extraction using multi-date Sentinel-2 and PlanetScope imagery: Case Study of Netherlands and Pakistan**
2411.15923v1 by Saba Zahid, Sajid Ghuffar, Obaid-ur-Rehman, Syed Roshaan Ali Shah

This study explores the effectiveness of multi-temporal satellite imagery for
better functional field boundary delineation using deep learning semantic
segmentation architecture on two distinct geographical and multi-scale farming
systems of Netherlands and Pakistan. Multidate images of April, August and
October 2022 were acquired for PlanetScope and Sentinel-2 in sub regions of
Netherlands and November 2022, February and March 2023 for selected area of
Dunyapur in Pakistan. For Netherlands, Basic registration crop parcels (BRP)
vector layer was used as labeled training data. while self-crafted field
boundary vector data were utilized for Pakistan. Four deep learning models with
UNET architecture were evaluated using different combinations of multi-date
images and NDVI stacks in the Netherlands subregions. A comparative analysis of
IoU scores assessed the effectiveness of the proposed multi-date NDVI stack
approach. These findings were then applied for transfer learning, using
pre-trained models from the Netherlands on the selected area in Pakistan.
Additionally, separate models were trained using self-crafted field boundary
data for Pakistan, and combined models were developed using data from both the
Netherlands and Pakistan. Results indicate that multi-date NDVI stacks provide
additional temporal context, reflecting crop growth over different times of the
season. The study underscores the critical role of multi-scale ground
information from diverse geographical areas in developing robust and
universally applicable models for field boundary delineation. The results also
highlight the importance of fine spatial resolution for extraction of field
boundaries in regions with small scale framing. The findings can be extended to
multi-scale implementations for improved automatic field boundary delineation
in heterogeneous agricultural environments.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÂ§öÊôÇÁõ∏Ë°õÊòüÂΩ±ÂÉèÁöÑÊúâÊïàÊÄßÔºå‰ª•‰ΩøÁî®Ê∑±Â∫¶Â≠∏ÁøíË™ûÁæ©ÂàÜÂâ≤ÁµêÊßãÂú®Ëç∑Ëò≠ÂíåÂ∑¥Âü∫ÊñØÂù¶ÂÖ©ÂÄã‰∏çÂêåÁöÑÂú∞ÁêÜÂíåÂ§öÂ∞∫Â∫¶Ëæ≤Ê•≠Á≥ªÁµ±‰∏≠ÔºåÈÄ≤Ë°åÊõ¥Â•ΩÁöÑÂäüËÉΩÊÄßÁî∞ÈñìÈÇäÁïåÊèèÁπ™„ÄÇ2022 Âπ¥ 4 Êúà„ÄÅ8 ÊúàÂíå 10 ÊúàÁöÑÂ§öÊó•ÊúüÂΩ±ÂÉèÂ∑≤ÈáùÂ∞ç PlanetScope Âíå Sentinel-2 Áç≤ÂèñÔºå‰ΩçÊñºËç∑Ëò≠ÁöÑÊ¨°ÂçÄÂüüÔºå‰ª•Âèä 2022 Âπ¥ 11 Êúà„ÄÅ2023 Âπ¥ 2 ÊúàÂíå 3 ÊúàÔºå‰ΩçÊñºÂ∑¥Âü∫ÊñØÂù¶ Dunyapur ÁöÑÁâπÂÆöÂçÄÂüü„ÄÇÂ∞çÊñºËç∑Ëò≠ÔºåÂü∫Êú¨Ë®ªÂÜä‰ΩúÁâ©Âú∞Â°ä (BRP) ÂêëÈáèÂúñÂ±§Áî®‰ΩúÊ®ôÁ±§Ë®ìÁ∑¥Ë≥áÊñô„ÄÇËÄåËá™Ë£ΩÁöÑÁî∞ÈñìÈÇäÁïåÂêëÈáèË≥áÊñôÂâáÁî®ÊñºÂ∑¥Âü∫ÊñØÂù¶„ÄÇ‰ΩøÁî® UNET ÁµêÊßãÁöÑÂõõÁ®ÆÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂú®Ëç∑Ëò≠Ê¨°ÂçÄÂüü‰∏≠‰ΩøÁî®Â§öÊó•ÊúüÂΩ±ÂÉèÂíå NDVI Â†ÜÁñäÁöÑ‰∏çÂêåÁµÑÂêàÈÄ≤Ë°åË©ï‰º∞„ÄÇIoU ÂàÜÊï∏ÁöÑÊØîËºÉÂàÜÊûêË©ï‰º∞‰∫ÜÊâÄÊèêÂá∫ÁöÑÂ§öÊó•Êúü NDVI Â†ÜÁñäÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÁÑ∂ÂæåÂ∞áÈÄô‰∫õÁôºÁèæÊáâÁî®ÊñºÈÅ∑ÁßªÂ≠∏ÁøíÔºå‰ΩøÁî®‰æÜËá™Ëç∑Ëò≠ÁöÑÈ†êË®ìÁ∑¥Ê®°ÂûãÔºåÊñºÂ∑¥Âü∫ÊñØÂù¶ÁöÑÁâπÂÆöÂçÄÂüü„ÄÇÊ≠§Â§ñÔºå‰ΩøÁî®Ëá™Ë£ΩÁöÑÁî∞ÈñìÈÇäÁïåË≥áÊñôÁÇ∫Â∑¥Âü∫ÊñØÂù¶Ë®ìÁ∑¥‰∫ÜÂñÆÁç®ÁöÑÊ®°ÂûãÔºå‰∏¶‰ΩøÁî®‰æÜËá™Ëç∑Ëò≠ÂíåÂ∑¥Âü∫ÊñØÂù¶ÁöÑË≥áÊñôÈñãÁôº‰∫ÜÁµÑÂêàÊ®°Âûã„ÄÇÁµêÊûúË°®ÊòéÔºåÂ§öÊó•Êúü NDVI Â†ÜÁñäÊèê‰æõ‰∫ÜÈ°çÂ§ñÁöÑÊôÇÈñìËÑàÁµ°ÔºåÂèçÊò†‰∫Ü‰∏çÂêåÂ≠£ÁØÄ‰ΩúÁâ©ÁöÑÁîüÈï∑ÊÉÖÊ≥Å„ÄÇÊú¨Á†îÁ©∂Âº∑Ë™ø‰∫Ü‰æÜËá™‰∏çÂêåÂú∞ÁêÜÂçÄÂüüÁöÑÂ§öÂ∞∫Â∫¶Âú∞Èù¢Ë≥áË®äÂú®ÈñãÁôºÁî®ÊñºÁî∞ÈñìÈÇäÁïåÊèèÁπ™ÁöÑÂº∑ÂÅ•‰∏îÊôÆÈÅçÈÅ©Áî®ÁöÑÊ®°Âûã‰∏≠ÁöÑÈóúÈçµ‰ΩúÁî®„ÄÇÁµêÊûú‰πüÁ™ÅÂá∫‰∫ÜÁ≤æÁ¥∞Á©∫ÈñìËß£ÊûêÂ∫¶Â∞çÊñºÂú®Â∞èË¶èÊ®°ÂèñÊôØÂçÄÂüü‰∏≠ËêÉÂèñÁî∞ÈñìÈÇäÁïåÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄô‰∫õÁôºÁèæÂèØ‰ª•Êì¥Â±ïÂà∞Â§öÂ∞∫Â∫¶ÂØ¶‰ΩúÔºå‰ª•ÊîπÂñÑÁï∞Ë≥™Ëæ≤Ê•≠Áí∞Â¢É‰∏≠ÁöÑËá™ÂãïÁî∞ÈñìÈÇäÁïåÊèèÁπ™„ÄÇ

##### **A Training-Free Approach for Music Style Transfer with Latent Diffusion Models**
2411.15913v1 by Sooyoung Kim, Joonwoo Kwon, Heehwan Wang, Shinjae Yoo, Yuewei Lin, Jiook Cha

Music style transfer, while offering exciting possibilities for personalized
music generation, often requires extensive training or detailed textual
descriptions. This paper introduces a novel training-free approach leveraging
pre-trained Latent Diffusion Models (LDMs). By manipulating the self-attention
features of the LDM, we effectively transfer the style of reference music onto
content music without additional training. Our method achieves superior style
transfer and melody preservation compared to existing methods. This work opens
new creative avenues for personalized music generation.

ÊëòË¶ÅÔºöÈü≥Ê®ÇÈ¢®Ê†ºËΩâÁßªÂú®Êèê‰æõÂÄã‰∫∫ÂåñÈü≥Ê®ÇÁîüÊàêÁöÑ‰ª§‰∫∫ËààÂ•ÆÁöÑÂèØËÉΩÊÄßÊôÇÔºåÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÁöÑË®ìÁ∑¥ÊàñË©≥Á¥∞ÁöÑÊñáÂ≠óÊèèËø∞„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÂà©Áî®È†êË®ìÁ∑¥ÊΩõÂú®Êì¥Êï£Ê®°Âûã (LDM) ÁöÑÊñ∞ÁÑ°Ë®ìÁ∑¥ÊñπÊ≥ï„ÄÇÈÄöÈÅéÊìçÁ∏± LDM ÁöÑËá™ÊàëÊ≥®ÊÑèÁâπÂæµÔºåÊàëÂÄëÊúâÊïàÂú∞Â∞áÂèÉËÄÉÈü≥Ê®ÇÁöÑÈ¢®Ê†ºËΩâÁßªÂà∞ÂÖßÂÆπÈü≥Ê®Ç‰∏äÔºåËÄåÁÑ°ÈúÄÈ°çÂ§ñÁöÑË®ìÁ∑¥„ÄÇËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÊäÄË°ìÂØ¶Áèæ‰∫ÜÂá∫Ëâ≤ÁöÑÈ¢®Ê†ºËΩâÁßªÂíåÊóãÂæã‰øùÁïô„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫ÂÄã‰∫∫ÂåñÈü≥Ê®ÇÁîüÊàêÈñãÂïü‰∫ÜÊñ∞ÁöÑÂâµ‰ΩúÈÄîÂæë„ÄÇ

##### **Bimanual Grasp Synthesis for Dexterous Robot Hands**
2411.15903v1 by Yanming Shao, Chenxi Xiao

Humans naturally perform bimanual skills to handle large and heavy objects.
To enhance robots' object manipulation capabilities, generating effective
bimanual grasp poses is essential. Nevertheless, bimanual grasp synthesis for
dexterous hand manipulators remains underexplored. To bridge this gap, we
propose the BimanGrasp algorithm for synthesizing bimanual grasps on 3D
objects. The BimanGrasp algorithm generates grasp poses by optimizing an energy
function that considers grasp stability and feasibility. Furthermore, the
synthesized grasps are verified using the Isaac Gym physics simulation engine.
These verified grasp poses form the BimanGrasp-Dataset, the first large-scale
synthesized bimanual dexterous hand grasp pose dataset to our knowledge. The
dataset comprises over 150k verified grasps on 900 objects, facilitating the
synthesis of bimanual grasps through a data-driven approach. Last, we propose
BimanGrasp-DDPM, a diffusion model trained on the BimanGrasp-Dataset. This
model achieved a grasp synthesis success rate of 69.87\% and significant
acceleration in computational speed compared to BimanGrasp algorithm.

ÊëòË¶ÅÔºö‰∫∫È°ûËá™ÁÑ∂ÊúÉÂü∑Ë°åÈõôÊâãÊäÄËÉΩ‰æÜËôïÁêÜÂ§ßÂûãÂíåÈáçÂûãÁâ©È´î„ÄÇ
ÁÇ∫‰∫ÜÂ¢ûÂº∑Ê©üÂô®‰∫∫ÁöÑÁâ©È´îÊìç‰ΩúËÉΩÂäõÔºåÁî¢ÁîüÊúâÊïàÁöÑ
ÈõôÊâãÊäìÊè°ÂßøÂã¢Ëá≥ÈóúÈáçË¶Å„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÈùàÂ∑ßÁöÑÊâãÈÉ®ÊìçÁ∏±Âô®ÁöÑ
ÈõôÊâãÊäìÊè°ÂêàÊàê‰ªçÁÑ∂Êú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Á¥¢„ÄÇÁÇ∫‰∫ÜÂΩåË£úÈÄô‰∏ÄÂ∑ÆË∑ùÔºåÊàëÂÄë
ÊèêÂá∫‰∫Ü BimanGrasp ÊºîÁÆóÊ≥ïÔºåÁî®ÊñºÂú® 3D
Áâ©È´î‰∏äÂêàÊàêÈõôÊâãÊäìÊè°„ÄÇBimanGrasp ÊºîÁÆóÊ≥ïÈÄèÈÅéÊúÄ‰Ω≥ÂåñËÄÉÈáèÊäìÊè°Á©©ÂÆöÊÄßÂíåÂèØË°åÊÄßÁöÑËÉΩÈáèÂáΩÊï∏‰æÜÁî¢ÁîüÊäìÊè°ÂßøÂã¢„ÄÇÊ≠§Â§ñÔºå
ÂêàÊàêÁöÑÊäìÊè°‰ΩøÁî® Isaac Gym Áâ©ÁêÜÊ®°Êì¨ÂºïÊìéÈÄ≤Ë°åÈ©óË≠â„ÄÇ
ÈÄô‰∫õÁ∂ìÈÅéÈ©óË≠âÁöÑÊäìÊè°ÂßøÂã¢ÊßãÊàê‰∫Ü BimanGrasp-DatasetÔºåÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂ§ßË¶èÊ®°ÂêàÊàêÁöÑÈõôÊâãÈùàÂ∑ßÊâãÊäìÊè°ÂßøÂã¢Ë≥áÊñôÈõÜ„ÄÇË©≤
Ë≥áÊñôÈõÜÂåÖÂê´Âú® 900 ÂÄãÁâ©È´î‰∏äÁ∂ìÈÅéÈ©óË≠âÁöÑ 150k ÂÄãÊäìÊè°Ôºå‰øÉÈÄ≤‰∫ÜÈÄèÈÅéË≥áÊñôÈ©ÖÂãïÊñπÊ≥ïÂêàÊàêÈõôÊâãÊäìÊè°„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫‰∫Ü
BimanGrasp-DDPMÔºåÈÄôÊòØ‰∏ÄÂÄãÂú® BimanGrasp-Dataset ‰∏äË®ìÁ∑¥ÁöÑÊì¥Êï£Ê®°Âûã„ÄÇËàá BimanGrasp ÊºîÁÆóÊ≥ïÁõ∏ÊØîÔºåÊ≠§
Ê®°ÂûãÂØ¶Áèæ‰∫Ü 69.87% ÁöÑÊäìÊè°ÂêàÊàêÊàêÂäüÁéáÔºå‰∏¶È°ØËëóÂä†ÈÄü‰∫ÜÈÅãÁÆóÈÄüÂ∫¶„ÄÇ

##### **Distribution-aware Online Continual Learning for Urban Spatio-Temporal Forecasting**
2411.15893v1 by Chengxin Wang, Gary Tan, Swagato Barman Roy, Beng Chin Ooi

Urban spatio-temporal (ST) forecasting is crucial for various urban
applications such as intelligent scheduling and trip planning. Previous studies
focus on modeling ST correlations among urban locations in offline settings,
which often neglect the non-stationary nature of urban ST data, particularly,
distribution shifts over time. This oversight can lead to degraded performance
in real-world scenarios. In this paper, we first analyze the distribution
shifts in urban ST data, and then introduce DOST, a novel online continual
learning framework tailored for ST data characteristics. DOST employs an
adaptive ST network equipped with a variable-independent adapter to address the
unique distribution shifts at each urban location dynamically. Further, to
accommodate the gradual nature of these shifts, we also develop an
awake-hibernate learning strategy that intermittently fine-tunes the adapter
during the online phase to reduce computational overhead. This strategy
integrates a streaming memory update mechanism designed for urban ST sequential
data, enabling effective network adaptation to new patterns while preventing
catastrophic forgetting. Experimental results confirm DOST's superiority over
state-of-the-art models on four real-world datasets, providing online forecasts
within an average of 0.1 seconds and achieving a 12.89% reduction in forecast
errors compared to baseline models.

ÊëòË¶ÅÔºöÂüéÂ∏ÇÊôÇÁ©∫ (ST) È†êÊ∏¨Â∞çÊñºÂêÑÈ†ÖÂüéÂ∏ÇÊáâÁî®Ëá≥ÈóúÈáçË¶ÅÔºå‰æãÂ¶ÇÊô∫ÊÖßÊéíÁ®ãÂíåË°åÁ®ãË¶èÂäÉ„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂Â∞àÊ≥®ÊñºÂú®Èõ¢Á∑öË®≠ÂÆö‰∏≠Âª∫Ê®°ÂüéÂ∏Ç‰ΩçÁΩÆ‰πãÈñìÁöÑ ST ÈóúËÅØÊÄßÔºåÈÄôÂ∏∏Â∏∏ÂøΩÁï•‰∫ÜÂüéÂ∏Ç ST Ë≥áÊñôÁöÑÈùûÂπ≥Á©©ÁâπÊÄßÔºåÁâπÂà•ÊòØÈö®ËëóÊôÇÈñìÊé®ÁßªÁöÑÂàÜÈÖçËΩâÁßª„ÄÇÈÄôÁ®ÆÁñèÂøΩÂèØËÉΩÂ∞éËá¥ÂØ¶ÈöõÂ†¥ÊôØ‰∏≠ÁöÑÊïàËÉΩ‰∏ãÈôç„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖàÂàÜÊûêÂüéÂ∏Ç ST Ë≥áÊñô‰∏≠ÁöÑÂàÜÈÖçËΩâÁßªÔºåÁÑ∂Âæå‰ªãÁ¥π DOSTÔºå‰∏ÄÂÄãÈáùÂ∞ç ST Ë≥áÊñôÁâπÊÄßÁöÑÊñ∞Á©éÁ∑ö‰∏äÊåÅÁ∫åÂ≠∏ÁøíÊû∂Êßã„ÄÇDOST ‰ΩøÁî®ÈÖçÂÇôÂèØËÆäÁç®Á´ãÈÅ©ÈÖçÂô®ÁöÑËá™ÈÅ©Êáâ ST Á∂≤Ë∑ØÔºå‰ª•ÂãïÊÖãËß£Ê±∫ÊØèÂÄãÂüéÂ∏Ç‰ΩçÁΩÆÁöÑÁç®ÁâπÂàÜÈÖçËΩâÁßª„ÄÇÊ≠§Â§ñÔºåÁÇ∫‰∫ÜÈÅ©ÊáâÈÄô‰∫õËΩâÁßªÁöÑÊº∏ÈÄ≤ÂºèÁâπÊÄßÔºåÊàëÂÄëÈÇÑÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÊ∏ÖÈÜí‰ºëÁú†Â≠∏ÁøíÁ≠ñÁï•ÔºåÂú®Á∑ö‰∏äÈöéÊÆµÈñìÊ≠áÊÄßÂú∞ÂæÆË™øÈÅ©ÈÖçÂô®Ôºå‰ª•Èôç‰ΩéÈÅãÁÆóË≤†Êìî„ÄÇÊ≠§Á≠ñÁï•Êï¥Âêà‰∫Ü‰∏ÄÂÄãÂ∞àÁÇ∫ÂüéÂ∏Ç ST È†ÜÂ∫èË≥áÊñôË®≠Ë®àÁöÑ‰∏≤ÊµÅË®òÊÜ∂È´îÊõ¥Êñ∞Ê©üÂà∂ÔºåËÆìÁ∂≤Ë∑ØËÉΩÊúâÊïàÈÅ©ÊáâÊñ∞ÁöÑÊ®°ÂºèÔºåÂêåÊôÇÈò≤Ê≠¢ÁÅΩÈõ£ÊÄßÈÅ∫Âøò„ÄÇÂØ¶È©óÁµêÊûúË≠âÂØ¶ DOST Âú®ÂõõÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÔºåÂú®Âπ≥Âùá 0.1 ÁßíÂÖßÊèê‰æõÁ∑ö‰∏äÈ†êÊ∏¨Ôºå‰∏¶ËàáÂü∫Ê∫ñÊ®°ÂûãÁõ∏ÊØîÔºåÈ†êÊ∏¨Ë™§Â∑ÆÊ∏õÂ∞ë‰∫Ü 12.89%„ÄÇ

##### **Evaluating Large Language Models for Causal Modeling**
2411.15888v1 by Houssam Razouk, Leonie Benischke, Georg Niess, Roman Kern

In this paper, we consider the process of transforming causal domain
knowledge into a representation that aligns more closely with guidelines from
causal data science. To this end, we introduce two novel tasks related to
distilling causal domain knowledge into causal variables and detecting
interaction entities using LLMs. We have determined that contemporary LLMs are
helpful tools for conducting causal modeling tasks in collaboration with human
experts, as they can provide a wider perspective. Specifically, LLMs, such as
GPT-4-turbo and Llama3-70b, perform better in distilling causal domain
knowledge into causal variables compared to sparse expert models, such as
Mixtral-8x22b. On the contrary, sparse expert models such as Mixtral-8x22b
stand out as the most effective in identifying interaction entities. Finally,
we highlight the dependency between the domain where the entities are generated
and the performance of the chosen LLM for causal modeling.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ËÄÉÊÖÆÂ∞áÂõ†ÊûúÈ†òÂüüÁü•Ë≠òËΩâÊèõÁÇ∫ËàáÂõ†ÊûúÊï∏ÊìöÁßëÂ≠∏ÊåáÂçóÊõ¥Á∑äÂØÜÂ∞çÈΩäÁöÑË°®Á§∫ÂΩ¢ÂºèÁöÑÈÅéÁ®ã„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂÖ©ÂÄãÊñ∞‰ªªÂãôÔºåÂàÜÂà•ÊòØÂ∞áÂõ†ÊûúÈ†òÂüüÁü•Ë≠òÊèêÁÖâÁÇ∫Âõ†ÊûúËÆäÊï∏Ôºå‰ª•Âèä‰ΩøÁî® LLM Ê™¢Ê∏¨‰∫§‰∫í‰ΩúÁî®ÂØ¶È´î„ÄÇÊàëÂÄëÂ∑≤Á¢∫ÂÆöÔºåÁï∂‰ª£ LLM ÊòØËàá‰∫∫È°ûÂ∞àÂÆ∂Âêà‰ΩúÈÄ≤Ë°åÂõ†ÊûúÂª∫Ê®°‰ªªÂãôÁöÑÊúâÁî®Â∑•ÂÖ∑ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÂèØ‰ª•Êèê‰æõÊõ¥Âª£ÈóäÁöÑËßÄÈªû„ÄÇÂÖ∑È´î‰æÜË™™ÔºåËàáÁ®ÄÁñèÂ∞àÂÆ∂Ê®°ÂûãÔºà‰æãÂ¶Ç Mixtral-8x22bÔºâÁõ∏ÊØîÔºåLLMÔºà‰æãÂ¶Ç GPT-4-turbo Âíå Llama3-70bÔºâÂú®Â∞áÂõ†ÊûúÈ†òÂüüÁü•Ë≠òÊèêÁÖâÁÇ∫Âõ†ÊûúËÆäÊï∏ÊñπÈù¢Ë°®ÁèæÂæóÊõ¥Â•Ω„ÄÇÁõ∏ÂèçÔºåÁ®ÄÁñèÂ∞àÂÆ∂Ê®°ÂûãÔºà‰æãÂ¶Ç Mixtral-8x22bÔºâÂú®Ë≠òÂà•‰∫§‰∫í‰ΩúÁî®ÂØ¶È´îÊñπÈù¢Ë°®ÁèæÊúÄÁÇ∫Âá∫Ëâ≤„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂº∑Ë™ø‰∫ÜÂØ¶È´îÁîüÊàêÊâÄÂú®ÁöÑÈ†òÂüüËàáÊâÄÈÅ∏ LLM Âú®Âõ†ÊûúÂª∫Ê®°‰∏≠ÁöÑÊïàËÉΩ‰πãÈñìÁöÑ‰æùË≥¥Èóú‰øÇ„ÄÇ

##### **LLMs Do Not Think Step-by-step In Implicit Reasoning**
2411.15862v1 by Yijiong Yu

It has been well-known that Chain-of-Thought can remarkably enhance LLMs'
performance on complex tasks. However, because it also introduces slower
inference speeds and higher computational costs, many researches have attempted
to use implicit CoT, which does not need LLMs to explicitly generate the
intermediate steps. But there is still gap between their efficacy and typical
explicit CoT methods. This leaves us a doubt that, does implicit CoT really
equal to explicit CoT? Therefore, in this study, we address this question
through experiments. We probe the information of intermediate steps from the
model's hidden states when it is performing implicit CoT. The results
surprisingly indicate that LLMs hardly think about intermediate steps,
suggesting they may just rely on experience rather than strict step-by-step
reasoning. Moreover, we find LLMs' implicit reasoning capabilities are
susceptible and unstable, reaffirming the necessity of explicit CoT to
effectively support complex tasks.

ÊëòË¶ÅÔºöÁúæÊâÄÂë®Áü•ÔºåÊÄùÊÉ≥ÈèàÂèØ‰ª•È°ØËëóÂ¢ûÂº∑ LLM Âú®Ë§áÈõú‰ªªÂãô‰∏äÁöÑÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÂÆÉÈÇÑÊúÉÂ∞éËá¥ËºÉÊÖ¢ÁöÑÊé®Ë´ñÈÄüÂ∫¶ÂíåËºÉÈ´òÁöÑË®àÁÆóÊàêÊú¨ÔºåË®±Â§öÁ†îÁ©∂ÂòóË©¶‰ΩøÁî®Èö±Âºè CoTÔºåÂÆÉ‰∏çÈúÄË¶Å LLM ÊòéÁ¢∫ÁîüÊàê‰∏≠ÈñìÊ≠•È©ü„ÄÇ‰ΩÜÂÆÉÂÄëÁöÑÊïàËÉΩËàáÂÖ∏ÂûãÁöÑÈ°ØÂºè CoT ÊñπÊ≥ï‰πãÈñì‰ªçÁÑ∂Â≠òÂú®Â∑ÆË∑ù„ÄÇÈÄôËÆìÊàëÂÄëÁî¢Áîü‰∏ÄÂÄãÁñëÂïèÔºåÈö±Âºè CoT ÊòØÂê¶ÁúüÁöÑÁ≠âÊñºÈ°ØÂºè CoTÔºüÂõ†Ê≠§ÔºåÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéÂØ¶È©ó‰æÜÊé¢Ë®éÈÄôÂÄãÂïèÈ°å„ÄÇÊàëÂÄëÂú®Ê®°ÂûãÂü∑Ë°åÈö±Âºè CoT ÊôÇÔºåÊé¢Ë®éÂÖ∂Èö±ËóèÁãÄÊÖã‰∏≠ÈóúÊñº‰∏≠ÈñìÊ≠•È©üÁöÑË≥áË®ä„ÄÇÁµêÊûú‰ª§‰∫∫È©öË®ùÂú∞Ë°®ÊòéÔºåLLM Âπæ‰πé‰∏çÊúÉËÄÉÊÖÆ‰∏≠ÈñìÊ≠•È©üÔºåÈÄôË°®ÊòéÂÆÉÂÄëÂèØËÉΩÂÉÖ‰æùË≥¥ÊñºÁ∂ìÈ©óÔºåËÄå‰∏çÊòØÂö¥Ê†ºÁöÑÈÄêÊ≠•Êé®ÁêÜ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁôºÁèæ LLM ÁöÑÈö±ÂºèÊé®ÁêÜËÉΩÂäõÊòØÊïèÊÑü‰∏î‰∏çÁ©©ÂÆöÁöÑÔºåÈÄôÂÜçÊ¨°ËÇØÂÆö‰∫ÜÈ°ØÂºè CoT Âú®ÊúâÊïàÊîØÊè¥Ë§áÈõú‰ªªÂãô‰∏≠ÁöÑÂøÖË¶ÅÊÄß„ÄÇ

##### **Unveiling the Superior Paradigm: A Comparative Study of Source-Free Domain Adaptation and Unsupervised Domain Adaptation**
2411.15844v1 by Fan Wang, Zhongyi Han, Xingbo Liu, Xin Gao, Yilong Yin

In domain adaptation, there are two popular paradigms: Unsupervised Domain
Adaptation (UDA), which aligns distributions using source data, and Source-Free
Domain Adaptation (SFDA), which leverages pre-trained source models without
accessing source data. Evaluating the superiority of UDA versus SFDA is an open
and timely question with significant implications for deploying adaptive
algorithms in practical applications. In this study, we demonstrate through
predictive coding theory and extensive experiments on multiple benchmark
datasets that SFDA generally outperforms UDA in real-world scenarios.
Specifically, SFDA offers advantages in time efficiency, storage requirements,
targeted learning objectives, reduced risk of negative transfer, and increased
robustness against overfitting. Notably, SFDA is particularly effective in
mitigating negative transfer when there are substantial distribution
discrepancies between source and target domains. Additionally, we introduce a
novel data-model fusion scenario, where data sharing among stakeholders varies
(e.g., some provide raw data while others provide only models), and reveal that
traditional UDA and SFDA methods do not fully exploit their potential in this
context. To address this limitation and capitalize on the strengths of SFDA, we
propose a novel weight estimation method that effectively integrates available
source data into multi-SFDA (MSFDA) approaches, thereby enhancing model
performance within this scenario. This work provides a thorough analysis of UDA
versus SFDA and advances a practical approach to model adaptation across
diverse real-world environments.

ÊëòË¶ÅÔºö<paragraph>Âú®È†òÂüüÈÅ©Êáâ‰∏≠ÔºåÊúâÂÖ©Á®ÆÊµÅË°åÁöÑÁØÑ‰æãÔºöÁÑ°Áõ£Áù£È†òÂüüÈÅ©Êáâ (UDA)ÔºåÂÆÉ‰ΩøÁî®‰æÜÊ∫êÊï∏ÊìöÂ∞çÈΩäÂàÜ‰ΩàÔºå‰ª•ÂèäÁÑ°‰æÜÊ∫êÈ†òÂüüÈÅ©Êáâ (SFDA)ÔºåÂÆÉÂà©Áî®È†êË®ìÁ∑¥ÁöÑ‰æÜÊ∫êÊ®°ÂûãËÄåÁÑ°ÈúÄÂ≠òÂèñ‰æÜÊ∫êÊï∏Êìö„ÄÇË©ï‰º∞ UDA Ëàá SFDA ÁöÑÂÑ™Ë∂äÊÄßÊòØ‰∏ÄÂÄãÈñãÊîæ‰∏îÂèäÊôÇÁöÑÂïèÈ°åÔºåÂ∞çÊñºÂú®ÂØ¶ÈöõÊáâÁî®‰∏≠ÈÉ®ÁΩ≤ÈÅ©ÊáâÊÄßÊºîÁÆóÊ≥ïÂÖ∑ÊúâÈáçÂ§ßÊÑèÁæ©„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéÈ†êÊ∏¨Á∑®Á¢ºÁêÜË´ñÂíåÂú®Â§öÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòéÔºåSFDA ÈÄöÂ∏∏Âú®ÂØ¶ÈöõÂ†¥ÊôØ‰∏≠ÂÑ™Êñº UDA„ÄÇÂÖ∑È´î‰æÜË™™ÔºåSFDA Âú®ÊôÇÈñìÊïàÁéá„ÄÅÂÑ≤Â≠òÈúÄÊ±Ç„ÄÅÁõÆÊ®ôÂ≠∏ÁøíÁõÆÊ®ô„ÄÅÈôç‰ΩéË≤†Èù¢ËΩâÁßªÈ¢®Èö™ÂíåÂ¢ûÂä†Â∞çÈÅéÂ∫¶Êì¨ÂêàÁöÑÁ©©ÂÅ•ÊÄßÊñπÈù¢ÂÖ∑ÊúâÂÑ™Âã¢„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÁï∂‰æÜÊ∫êÂíåÁõÆÊ®ôÈ†òÂüü‰πãÈñìÂ≠òÂú®ÂØ¶Ë≥™ÊÄßÂàÜ‰ΩàÂ∑ÆÁï∞ÊôÇÔºåSFDA Âú®Ê∏õËºïË≤†Èù¢ËΩâÁßªÊñπÈù¢ÁâπÂà•ÊúâÊïà„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑË≥áÊñôÊ®°ÂûãËûçÂêàÂ†¥ÊôØÔºåÂÖ∂‰∏≠Âà©ÁõäÁõ∏ÈóúËÄÖ‰πãÈñìÁöÑË≥áÊñôÂÖ±‰∫´ÊúâÊâÄ‰∏çÂêåÔºà‰æãÂ¶ÇÔºå‰∏Ä‰∫õÊèê‰æõÂéüÂßãË≥áÊñôÔºåËÄåÂè¶‰∏Ä‰∫õÂè™Êèê‰æõÊ®°ÂûãÔºâÔºå‰∏¶Êè≠Á§∫ÂÇ≥Áµ±ÁöÑ UDA Âíå SFDA ÊñπÊ≥ï‰∏¶Êú™ÂÖÖÂàÜÁôºÊèÆÂÖ∂Âú®ÈÄôÁ®ÆÊÉÖÊ≥Å‰∏ãÁöÑÊΩõÂäõ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÈôêÂà∂‰∏¶Âà©Áî® SFDA ÁöÑÂÑ™Âã¢ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊ¨äÈáç‰º∞Ë®àÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÊúâÊïàÂú∞Â∞áÂèØÁî®ÁöÑ‰æÜÊ∫êÊï∏ÊìöÊï¥ÂêàÂà∞Â§ö SFDA (MSFDA) ÊñπÊ≥ï‰∏≠ÔºåÂæûËÄåÂ¢ûÂº∑Ê®°ÂûãÂú®ÈÄôÁ®ÆÂ†¥ÊôØ‰∏≠ÁöÑÊïàËÉΩ„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÂ∞ç UDA Ëàá SFDA ÈÄ≤Ë°å‰∫ÜÂæπÂ∫ïÁöÑÂàÜÊûêÔºå‰∏¶ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂØ¶Áî®ÁöÑÊñπÊ≥ï‰æÜÈÅ©Êáâ‰∏çÂêåÂØ¶ÈöõÁí∞Â¢É‰∏≠ÁöÑÊ®°Âûã„ÄÇ</paragraph>

##### **Efficient and Private: Memorisation under differentially private parameter-efficient fine-tuning in language models**
2411.15831v1 by Olivia Ma, Jonathan Passerat-Palmbach, Dmitrii Usynin

Fine-tuning large language models (LLMs) for specific tasks introduces
privacy risks, as models may inadvertently memorise and leak sensitive training
data. While Differential Privacy (DP) offers a solution to mitigate these
risks, it introduces significant computational and performance trade-offs,
particularly with standard fine-tuning approaches. Previous work has primarily
focused on full-parameter updates, which are computationally intensive and may
not fully leverage DPs potential in large models. In this work, we address
these shortcomings by investigating Parameter-Efficient Fine-Tuning (PEFT)
methods under DP constraints. We show that PEFT methods achieve comparable
performance to standard fine-tuning while requiring fewer parameters and
significantly reducing privacy leakage. Furthermore, we incorporate a data
poisoning experiment involving intentional mislabelling to assess model
memorisation and directly measure privacy risks. Our findings indicate that
PEFT methods not only provide a promising alternative but also serve as a
complementary approach for privacy-preserving, resource-efficient fine-tuning
of LLMs.

ÊëòË¶ÅÔºöÂæÆË™øÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰ª•ÊáâÂ∞çÁâπÂÆö‰ªªÂãôÊôÇÊúÉÂºïÁôºÈö±ÁßÅÈ¢®Èö™ÔºåÂõ†ÁÇ∫Ê®°ÂûãÂèØËÉΩÊúÉÁÑ°ÊÑèÈñìË®òÊÜ∂‰∏¶Ê¥©Èú≤ÊïèÊÑüÁöÑË®ìÁ∑¥Ë≥áÊñô„ÄÇÈõñÁÑ∂Â∑ÆÂàÜÈö±ÁßÅ (DP) Êèê‰æõ‰∫ÜËß£Ê±∫ÈÄô‰∫õÈ¢®Èö™ÁöÑÊñπÊ≥ïÔºå‰ΩÜÂÆÉÊúÉÈÄ†ÊàêÈ°ØËëóÁöÑÈÅãÁÆóÂíåÊïàËÉΩÂèñÊç®ÔºåÁâπÂà•ÊòØÊé°Áî®Ê®ôÊ∫ñÂæÆË™øÊñπÊ≥ïÊôÇ„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂‰∏ªË¶ÅÈõÜ‰∏≠ÊñºÂÖ®ÂèÉÊï∏Êõ¥Êñ∞ÔºåÈÄôÂú®ÈÅãÁÆó‰∏äÂæàÂØÜÈõÜÔºåËÄå‰∏îÂèØËÉΩÁÑ°Ê≥ïÂÖÖÂàÜÁôºÊèÆÂ§ßÂûãÊ®°Âûã‰∏≠ DP ÁöÑÊΩõÂäõ„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéÁ†îÁ©∂ DP Á¥ÑÊùü‰∏ãÁöÑÂèÉÊï∏ÊúâÊïàÂæÆË™ø (PEFT) ÊñπÊ≥ï‰æÜËß£Ê±∫ÈÄô‰∫õÁº∫Èªû„ÄÇÊàëÂÄëÈ°ØÁ§∫ PEFT ÊñπÊ≥ïÂèØÈÅîÊàêËàáÊ®ôÊ∫ñÂæÆË™øÁõ∏Áï∂ÁöÑÊïàËÉΩÔºåÂêåÊôÇÊâÄÈúÄÂèÉÊï∏ËºÉÂ∞ëÔºå‰∏¶Â§ßÂπÖÈôç‰ΩéÈö±ÁßÅÂ§ñÊ¥©„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁ¥çÂÖ•‰∏ÄÈ†ÖË≥áÊñô‰∏≠ÊØíÂØ¶È©óÔºåÂÖ∂‰∏≠Ê∂âÂèäÊïÖÊÑèÈåØË™§Ê®ôÁ±§Ôºå‰ª•Ë©ï‰º∞Ê®°ÂûãË®òÊÜ∂‰∏¶Áõ¥Êé•Ë°°ÈáèÈö±ÁßÅÈ¢®Èö™„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåPEFT ÊñπÊ≥ï‰∏çÂÉÖÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂ∏åÊúõÁöÑÊõø‰ª£ÊñπÊ°àÔºå‰πü‰ΩúÁÇ∫‰∏ÄÁ®ÆË£úÂÖÖÊñπÊ≥ïÔºåÁî®Êñº LLM ÁöÑÈö±ÁßÅ‰øùË≠∑„ÄÅË≥áÊ∫êÊúâÊïàÂæÆË™ø„ÄÇ

##### **Is Training Data Quality or Quantity More Impactful to Small Language Model Performance?**
2411.15821v1 by Aryan Sajith, Krishna Chaitanya Rao Kathala

This study investigates the relative impact of training data quality versus
quantity on the performance of small language models (SLMs), utilizing the
TinyStories dataset for empirical analysis. Analysis of dataset variations with
respect to size (25% and 50% of the original size) and duplication (controlled
rates of 25%, 50%, 75%, and 100%) were performed. Model performance was
evaluated based on the validation loss, accuracy, and perplexity metrics.
Results indicate training data quality plays a more significant role in the
overall performance of SLMs, especially given scale of this experiment. Minimal
duplication positively impacted model accuracy (+0.87% increase in accuracy at
25% duplication) without significantly increasing perplexity (+0.52% increase
going from 0% to 25% duplication) but excessive duplication led to pronounced
performance degradation (-40% drop in accuracy at 100% duplication). The
implications of this exploration extend beyond just model performance; training
large-scale models imposes significant financial and computational burdens,
which can be prohibitive for organizations, individuals, and the public at
large, especially in developing countries. Additionally, the energy consumption
associated with large-scale training raises environmental concerns.
Understanding the relative importance of data quality versus quantity could
democratize AI technology, making advanced models more accessible and
sustainable for all.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Ë™øÊü•Ë®ìÁ∑¥Ë≥áÊñôÂìÅË≥™Áõ∏Â∞çÊñºÊï∏ÈáèÂ∞çÂ∞èÂûãË™ûË®ÄÊ®°Âûã (SLM) ÊïàËÉΩÁöÑÁõ∏Â∞çÂΩ±ÈüøÔºå‰∏¶Âà©Áî® TinyStories Ë≥áÊñôÈõÜÈÄ≤Ë°åÂØ¶Ë≠âÂàÜÊûê„ÄÇÂàÜÊûêË≥áÊñôÈõÜËÆäÁï∞ÔºåÂåÖÊã¨Â§ßÂ∞èÔºàÂéüÂßãÂ§ßÂ∞èÁöÑ 25% Âíå 50%ÔºâÂíåÈáçË§áÔºàÂèóÊéßÊØîÁéá 25%„ÄÅ50%„ÄÅ75% Âíå 100%Ôºâ„ÄÇÊ®°ÂûãÊïàËÉΩÊ†πÊìöÈ©óË≠âÊêçÂ§±„ÄÅÊ∫ñÁ¢∫Â∫¶ÂíåÂõ∞ÊÉëÂ∫¶ÊåáÊ®ôÈÄ≤Ë°åË©ï‰º∞„ÄÇÁµêÊûúÈ°ØÁ§∫Ë®ìÁ∑¥Ë≥áÊñôÂìÅË≥™Âú® SLM ÁöÑÊï¥È´îÊïàËÉΩ‰∏≠ÊâÆÊºîÊõ¥ÈáçË¶ÅÁöÑËßíËâ≤ÔºåÁâπÂà•ÊòØÂú®Ê≠§ÂØ¶È©óÁöÑË¶èÊ®°‰∏ã„ÄÇÊúÄÂ∞èÁöÑÈáçË§áÂ∞çÊ®°ÂûãÊ∫ñÁ¢∫Â∫¶Áî¢ÁîüÊ≠£Èù¢ÂΩ±ÈüøÔºàÈáçË§áÁéá 25% ÊôÇÊ∫ñÁ¢∫Â∫¶Â¢ûÂä† +0.87%ÔºâÔºå‰∏î‰∏çÊúÉÈ°ØËëóÂ¢ûÂä†Âõ∞ÊÉëÂ∫¶ÔºàÂæû 0% Âà∞ 25% ÈáçË§áÊôÇÂ¢ûÂä† +0.52%ÔºâÔºå‰ΩÜÈÅéÂ∫¶ÈáçË§áÊúÉÂ∞éËá¥ÊïàËÉΩÈ°ØËëó‰∏ãÈôçÔºàÈáçË§áÁéá 100% ÊôÇÊ∫ñÁ¢∫Â∫¶‰∏ãÈôç -40%Ôºâ„ÄÇÊ≠§Êé¢Ë®éÁöÑÊÑèÁæ©‰∏çÂè™Âú®ÊñºÊ®°ÂûãÊïàËÉΩÔºõË®ìÁ∑¥Â§ßÂûãÊ®°ÂûãÊúÉÈÄ†ÊàêÈ°ØËëóÁöÑË≤°ÂãôÂíåÈÅãÁÆóË≤†ÊìîÔºåÂ∞çÁµÑÁπî„ÄÅÂÄã‰∫∫ÂíåÂª£Â§ßÊ∞ëÁúæËÄåË®ÄÂèØËÉΩÈõ£‰ª•Ë≤†ÊìîÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈñãÁôº‰∏≠ÂúãÂÆ∂„ÄÇÊ≠§Â§ñÔºåËàáÂ§ßÂûãË®ìÁ∑¥Áõ∏ÈóúÁöÑËÉΩÊ∫êÊ∂àËÄó‰πüÂºïÁôºÁí∞Â¢ÉÂïèÈ°å„ÄÇ‰∫ÜËß£Ë≥áÊñôÂìÅË≥™Áõ∏Â∞çÊñºÊï∏ÈáèÁöÑÁõ∏Â∞çÈáçË¶ÅÊÄßÂèØ‰ª•‰Ωø AI ÊäÄË°ìÊ∞ë‰∏ªÂåñÔºåËÆìÂÖàÈÄ≤Ê®°ÂûãÊõ¥ÊòìÊñºÂèñÂæóÔºå‰∏îÂ∞çÊâÄÊúâ‰∫∫ËÄåË®ÄÊõ¥ÂÖ∑Ê∞∏Á∫åÊÄß„ÄÇ

##### **FastTrackTr:Towards Fast Multi-Object Tracking with Transformers**
2411.15811v1 by Pan Liao, Feng Yang, Di Wu, Jinwen Yu, Wenhui Zhao, Bo Liu

Transformer-based multi-object tracking (MOT) methods have captured the
attention of many researchers in recent years. However, these models often
suffer from slow inference speeds due to their structure or other issues. To
address this problem, we revisited the Joint Detection and Tracking (JDT)
method by looking back at past approaches. By integrating the original JDT
approach with some advanced theories, this paper employs an efficient method of
information transfer between frames on the DETR, constructing a fast and novel
JDT-type MOT framework: FastTrackTr. Thanks to the superiority of this
information transfer method, our approach not only reduces the number of
queries required during tracking but also avoids the excessive introduction of
network structures, ensuring model simplicity. Experimental results indicate
that our method has the potential to achieve real-time tracking and exhibits
competitive tracking accuracy across multiple datasets.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºåÂü∫Êñº Transformer ÁöÑÂ§öÁõÆÊ®ôËøΩËπ§ (MOT) ÊñπÊ≥ïÂ∑≤ÂºïËµ∑Ë®±Â§öÁ†îÁ©∂‰∫∫Âì°ÁöÑÈóúÊ≥®„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°ÂûãÁî±ÊñºÂÖ∂ÁµêÊßãÊàñÂÖ∂‰ªñÂïèÈ°åÔºåÈÄöÂ∏∏ÊúÉÂ∞éËá¥Êé®Ë´ñÈÄüÂ∫¶ËºÉÊÖ¢„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂõûÈ°ßÈÅéÂéªÁöÑÊñπÊ≥ïÔºåÈáçÊñ∞ÂØ©Ë¶ñ‰∫ÜËÅØÂêàÂÅµÊ∏¨ËàáËøΩËπ§ (JDT) ÊñπÊ≥ï„ÄÇÊú¨ÊñáÈÄèÈÅéÂ∞áÂéüÂßã JDT ÊñπÊ≥ïËàá‰∏Ä‰∫õÂÖàÈÄ≤ÁöÑÁêÜË´ñÊï¥ÂêàÔºåÂú® DETR ‰∏äÊé°Áî®‰∫Ü‰∏ÄÁ®ÆÊúâÊïàÁöÑÂπÄÈñìË≥áË®äÂÇ≥ÈÅûÊñπÊ≥ïÔºåÂª∫Êßã‰∫Ü‰∏ÄÂÄãÂø´ÈÄü‰∏îÊñ∞Á©éÁöÑ JDT È°ûÂûã MOT Ê°ÜÊû∂ÔºöFastTrackTr„ÄÇÁî±ÊñºÈÄôÁ®ÆË≥áË®äÂÇ≥ÈÅûÊñπÊ≥ïÁöÑÂÑ™Ë∂äÊÄßÔºåÊàëÂÄëÁöÑÂÅöÊ≥ï‰∏çÂÉÖÊ∏õÂ∞ë‰∫ÜËøΩËπ§ÈÅéÁ®ã‰∏≠ÊâÄÈúÄÁöÑÊü•Ë©¢Êï∏ÈáèÔºåÈÇÑÈÅøÂÖç‰∫ÜÈÅéÂ∫¶ÂºïÂÖ•Á∂≤Ë∑ØÁµêÊßãÔºåÁ¢∫‰øù‰∫ÜÊ®°ÂûãÁöÑÁ∞°ÊΩîÊÄß„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂÖ∑ÊúâÂØ¶ÁèæÂç≥ÊôÇËøΩËπ§ÁöÑÊΩõÂäõÔºå‰∏¶Âú®Â§öÂÄãË≥áÊñôÈõÜ‰∏äÂ±ïÁèæÂá∫ÂÖ∑ÊúâÁ´∂Áà≠ÂäõÁöÑËøΩËπ§Ê∫ñÁ¢∫Â∫¶„ÄÇ

##### **Benchmarking Active Learning for NILM**
2411.15805v1 by Dhruv Patel, Ankita Kumari Jain, Haikoo Khandor, Xhitij Choudhary, Nipun Batra

Non-intrusive load monitoring (NILM) focuses on disaggregating total
household power consumption into appliance-specific usage. Many advanced NILM
methods are based on neural networks that typically require substantial amounts
of labeled appliance data, which can be challenging and costly to collect in
real-world settings. We hypothesize that appliance data from all households
does not uniformly contribute to NILM model improvements. Thus, we propose an
active learning approach to selectively install appliance monitors in a limited
number of houses. This work is the first to benchmark the use of active
learning for strategically selecting appliance-level data to optimize NILM
performance. We first develop uncertainty-aware neural networks for NILM and
then install sensors in homes where disaggregation uncertainty is highest.
Benchmarking our method on the publicly available Pecan Street Dataport
dataset, we demonstrate that our approach significantly outperforms a standard
random baseline and achieves performance comparable to models trained on the
entire dataset. Using this approach, we achieve comparable NILM accuracy with
approximately 30% of the data, and for a fixed number of sensors, we observe up
to a 2x reduction in disaggregation errors compared to random sampling.

ÊëòË¶ÅÔºöÈùû‰æµÂÖ•ÂºèË≤†ËºâÁõ£Êéß (NILM) Â∞àÊ≥®ÊñºÂ∞áÂÆ∂Â∫≠Á∏ΩÁî®ÈõªÈáèÂàÜËß£ÁÇ∫ÁâπÂÆöÈõªÂô®ÁöÑÁî®Èáè„ÄÇË®±Â§öÂÖàÈÄ≤ÁöÑ NILM ÊñπÊ≥ïÈÉΩÂü∫ÊñºÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºåËÄåÁ•ûÁ∂ìÁ∂≤Ë∑ØÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÁöÑÊ®ôÁ±§ÈõªÂô®Ë≥áÊñôÔºåÈÄôÂú®ÁèæÂØ¶‰∏ñÁïå‰∏≠ÂèØËÉΩÂæàÈõ£‰∏îÊàêÊú¨È´òÊòÇ„ÄÇÊàëÂÄëÂÅáË®≠‰æÜËá™ÊâÄÊúâÂÆ∂Â∫≠ÁöÑÈõªÂô®Ë≥áÊñô‰∏¶‰∏çÊúÉÂ∞ç NILM Ê®°ÂûãÁöÑÊîπÈÄ≤Áî¢ÁîüÂùáÁ≠âÁöÑË≤¢Áçª„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®Æ‰∏ªÂãïÂ≠∏ÁøíÊñπÊ≥ïÔºå‰ª•ÈÅ∏ÊìáÊÄßÂú∞ÂÆâË£ùÈõªÂô®Áõ£ÊéßÂô®Âú®ÊúâÈôêÊï∏ÈáèÁöÑÊàøÂ±ã‰∏≠„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÈ¶ñÊ¨°Â∞ç‰∏ªÂãïÂ≠∏ÁøíÁöÑ‰ΩøÁî®ÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶Ôºå‰ª•Á≠ñÁï•ÊÄßÂú∞ÈÅ∏ÊìáÈõªÂô®Â±§Á¥öË≥áÊñô‰æÜÊúÄ‰Ω≥Âåñ NILM ÊïàËÉΩ„ÄÇÊàëÂÄëÈ¶ñÂÖàÁÇ∫ NILM ÈñãÁôº‰∫ÜÂÖ∑Êúâ‰∏çÁ¢∫ÂÆöÊÄßÊÑüÁü•ÁöÑÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºåÁÑ∂ÂæåÂú®ÂàÜËß£‰∏çÁ¢∫ÂÆöÊÄßÊúÄÈ´òÁöÑÂÆ∂Êà∂‰∏≠ÂÆâË£ùÊÑüÊ∏¨Âô®„ÄÇÂú®ÂÖ¨ÈñãÁöÑ Pecan Street Dataport Ë≥áÊñôÈõÜ‰∏äÂ∞çÊàëÂÄëÁöÑÊ®°ÂûãÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶ÔºåÊàëÂÄëË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÈ°ØËëóÂÑ™ÊñºÊ®ôÊ∫ñÈö®Ê©üÂü∫Ê∫ñÔºå‰∏¶‰∏îÈÅîÂà∞‰∫ÜËàáÂú®Êï¥ÂÄãË≥áÊñôÈõÜ‰∏äË®ìÁ∑¥ÁöÑÊ®°ÂûãÁõ∏Áï∂ÁöÑÊïàËÉΩ„ÄÇ‰ΩøÁî®ÈÄôÁ®ÆÊñπÊ≥ïÔºåÊàëÂÄë‰ª•Â§ßÁ¥Ñ 30% ÁöÑË≥áÊñôÈÅîÂà∞‰∫ÜÁõ∏Áï∂ÁöÑ NILM Á≤æÁ¢∫Â∫¶Ôºå‰∏¶‰∏îÂ∞çÊñºÂõ∫ÂÆöÊï∏ÈáèÁöÑÊÑüÊ∏¨Âô®ÔºåÊàëÂÄëËßÄÂØüÂà∞ËàáÈö®Ê©üÊäΩÊ®£Áõ∏ÊØîÔºåÂàÜËß£Ë™§Â∑ÆÊ∏õÂ∞ë‰∫Ü 2 ÂÄç„ÄÇ


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-25**|**AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning**|Amy Xin et.al.|[2411.16495v1](http://arxiv.org/abs/2411.16495v1)|null|
|**2024-11-25**|**Learning by Analogy: Enhancing Few-Shot Prompting for Math Word Problem Solving with Computational Graph-Based Retrieval**|Xiaocong Yang et.al.|[2411.16454v1](http://arxiv.org/abs/2411.16454v1)|null|
|**2024-11-25**|**Adapter-based Approaches to Knowledge-enhanced Language Models -- A Survey**|Alexander Fichtl et.al.|[2411.16403v1](http://arxiv.org/abs/2411.16403v1)|null|
|**2024-11-24**|**Decoding Urban Industrial Complexity: Enhancing Knowledge-Driven Insights via IndustryScopeGPT**|Siqi Wang et.al.|[2411.15758v1](http://arxiv.org/abs/2411.15758v1)|[link](https://github.com/tongji-kgllm/industryscope)|
|**2024-11-22**|**One to rule them all: natural language to bind communication, perception and action**|Simone Colombani et.al.|[2411.15033v1](http://arxiv.org/abs/2411.15033v1)|null|
|**2024-11-22**|**Time is on my sight: scene graph filtering for dynamic environment perception in an LLM-driven robot**|Simone Colombani et.al.|[2411.15027v1](http://arxiv.org/abs/2411.15027v1)|null|
|**2024-11-22**|**GOT4Rec: Graph of Thoughts for Sequential Recommendation**|Zewen Long et.al.|[2411.14922v1](http://arxiv.org/abs/2411.14922v1)|null|
|**2024-11-22**|**VisGraphVar: A Benchmark Generator for Assessing Variability in Graph Analysis Using Large Vision-Language Models**|Camilo Chac√≥n Sartori et.al.|[2411.14832v1](http://arxiv.org/abs/2411.14832v1)|null|
|**2024-11-22**|**MolReFlect: Towards In-Context Fine-grained Alignments between Molecules and Texts**|Jiatong Li et.al.|[2411.14721v1](http://arxiv.org/abs/2411.14721v1)|null|
|**2024-11-21**|**G-RAG: Knowledge Expansion in Material Science**|Radeen Mostafa et.al.|[2411.14592v1](http://arxiv.org/abs/2411.14592v1)|[link](https://github.com/RadeenXALNW/G-RAG_1.0)|
|**2024-11-21**|**Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective**|Ernests Lavrinovics et.al.|[2411.14258v1](http://arxiv.org/abs/2411.14258v1)|null|
|**2024-11-21**|**Logic Augmented Generation**|Aldo Gangemi et.al.|[2411.14012v1](http://arxiv.org/abs/2411.14012v1)|null|
|**2024-11-21**|**FastRAG: Retrieval Augmented Generation for Semi-structured Data**|Amar Abane et.al.|[2411.13773v1](http://arxiv.org/abs/2411.13773v1)|null|
|**2024-11-20**|**Predictive Insights into LGBTQ+ Minority Stress: A Transductive Exploration of Social Media Discourse**|S. Chapagain et.al.|[2411.13534v1](http://arxiv.org/abs/2411.13534v1)|[link](https://github.com/chapagaisa/transductive)|
|**2024-11-20**|**KAAE: Numerical Reasoning for Knowledge Graphs via Knowledge-aware Attributes Learning**|Ming Yin et.al.|[2411.12950v2](http://arxiv.org/abs/2411.12950v2)|null|
|**2024-11-19**|**Neurosymbolic Graph Enrichment for Grounded World Models**|Stefano De Giorgis et.al.|[2411.12671v1](http://arxiv.org/abs/2411.12671v1)|null|
|**2024-11-19**|**Instant Policy: In-Context Imitation Learning via Graph Diffusion**|Vitalis Vosylius et.al.|[2411.12633v1](http://arxiv.org/abs/2411.12633v1)|null|
|**2024-11-19**|**Bias-Free Sentiment Analysis through Semantic Blinding and Graph Neural Networks**|Hubert Plisiecki et.al.|[2411.12493v2](http://arxiv.org/abs/2411.12493v2)|null|
|**2024-11-19**|**Neon: News Entity-Interaction Extraction for Enhanced Question Answering**|Sneha Singhania et.al.|[2411.12449v2](http://arxiv.org/abs/2411.12449v2)|null|
|**2024-11-19**|**GRL-Prompt: Towards Knowledge Graph based Prompt Optimization via Reinforcement Learning**|Yuze Liu et.al.|[2411.14479v1](http://arxiv.org/abs/2411.14479v1)|null|
|**2024-11-19**|**Just KIDDIN: Knowledge Infusion and Distillation for Detection of INdecent Memes**|Rahul Garg et.al.|[2411.12174v1](http://arxiv.org/abs/2411.12174v1)|null|
|**2024-11-18**|**Regret-Free Reinforcement Learning for LTL Specifications**|Rupak Majumdar et.al.|[2411.12019v1](http://arxiv.org/abs/2411.12019v1)|null|
|**2024-11-18**|**Semantic-Geometric-Physical-Driven Robot Manipulation Skill Transfer via Skill Library and Tactile Representation**|Mingchao Qi et.al.|[2411.11714v1](http://arxiv.org/abs/2411.11714v1)|[link](https://github.com/mingchaoqi/skill_transfer)|
|**2024-11-18**|**Addressing Hallucinations in Language Models with Knowledge Graph Embeddings as an Additional Modality**|Viktoriia Chekalina et.al.|[2411.11531v1](http://arxiv.org/abs/2411.11531v1)|null|
|**2024-11-17**|**RPN 2: On Interdependence Function Learning Towards Unifying and Advancing CNN, RNN, GNN, and Transformer**|Jiawei Zhang et.al.|[2411.11162v1](http://arxiv.org/abs/2411.11162v1)|null|
|**2024-11-16**|**LLaSA: Large Language and Structured Data Assistant**|Yao Xu et.al.|[2411.14460v1](http://arxiv.org/abs/2411.14460v1)|null|
|**2024-11-16**|**Unveiling User Preferences: A Knowledge Graph and LLM-Driven Approach for Conversational Recommendation**|Zhangchi Qiu et.al.|[2411.14459v1](http://arxiv.org/abs/2411.14459v1)|null|
|**2024-11-16**|**A Novel Approach to Eliminating Hallucinations in Large Language Model-Assisted Causal Discovery**|Grace Sng et.al.|[2411.12759v1](http://arxiv.org/abs/2411.12759v1)|null|
|**2024-11-15**|**VeriGraph: Scene Graphs for Execution Verifiable Robot Planning**|Daniel Ekpo et.al.|[2411.10446v2](http://arxiv.org/abs/2411.10446v2)|null|
|**2024-11-15**|**A Survey of Event Causality Identification: Principles, Taxonomy, Challenges, and Assessment**|Qing Cheng et.al.|[2411.10371v2](http://arxiv.org/abs/2411.10371v2)|null|
|**2024-11-15**|**Prompting and Fine-tuning Large Language Models for Automated Code Review Comment Generation**|Md. Asif Haider et.al.|[2411.10129v1](http://arxiv.org/abs/2411.10129v1)|null|
|**2024-11-15**|**HistoLens: An LLM-Powered Framework for Multi-Layered Analysis of Historical Texts -- A Case Application of Yantie Lun**|Yifan Zeng et.al.|[2411.09978v1](http://arxiv.org/abs/2411.09978v1)|null|
|**2024-11-14**|**Accelerating Knowledge Graph and Ontology Engineering with Large Language Models**|Cogan Shimizu et.al.|[2411.09601v1](http://arxiv.org/abs/2411.09601v1)|null|
|**2024-11-14**|**Automating Reformulation of Essence Specifications via Graph Rewriting**|Ian Miguel et.al.|[2411.09576v1](http://arxiv.org/abs/2411.09576v1)|null|
|**2024-11-13**|**Towards Evaluating Large Language Models for Graph Query Generation**|Siraj Munir et.al.|[2411.08449v2](http://arxiv.org/abs/2411.08449v2)|null|
|**2024-11-13**|**Knowledge Bases in Support of Large Language Models for Processing Web News**|Yihe Zhang et.al.|[2411.08278v2](http://arxiv.org/abs/2411.08278v2)|null|
|**2024-11-12**|**Retrieval, Reasoning, Re-ranking: A Context-Enriched Framework for Knowledge Graph Completion**|Muzhi Li et.al.|[2411.08165v1](http://arxiv.org/abs/2411.08165v1)|null|
|**2024-11-12**|**Language Models as Causal Effect Generators**|Lucius E. J. Bynum et.al.|[2411.08019v1](http://arxiv.org/abs/2411.08019v1)|[link](https://github.com/lbynum/sequence-driven-scms)|
|**2024-11-12**|**From General to Specific: Utilizing General Hallucination to Benchmark Specific Role-Playing Agents**|Chuyi Kong et.al.|[2411.07965v2](http://arxiv.org/abs/2411.07965v2)|null|
|**2024-11-12**|**Chain Association-based Attacking and Shielding Natural Language Processing Systems**|Jiacheng Huang et.al.|[2411.07843v1](http://arxiv.org/abs/2411.07843v1)|null|
|**2024-11-11**|**Gradual Fine-Tuning with Graph Routing for Multi-Source Unsupervised Domain Adaptation**|Yao Ma et.al.|[2411.07185v1](http://arxiv.org/abs/2411.07185v1)|null|
|**2024-11-11**|**A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19**|Vedant Khandelwal et.al.|[2411.07163v1](http://arxiv.org/abs/2411.07163v1)|null|
|**2024-11-11**|**A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs**|Myeongsoo Kim et.al.|[2411.07098v1](http://arxiv.org/abs/2411.07098v1)|null|
|**2024-11-11**|**Bridge: A Unified Framework to Knowledge Graph Completion via Language Models and Knowledge Representation**|Qiao Qiao et.al.|[2411.06660v1](http://arxiv.org/abs/2411.06660v1)|null|
|**2024-11-10**|**CausalStock: Deep End-to-end Causal Discovery for News-driven Stock Movement Prediction**|Shuqi Li et.al.|[2411.06391v1](http://arxiv.org/abs/2411.06391v1)|null|
|**2024-11-09**|**Analyzing the Evolution of Graphs and Texts**|Xingzhi Guo et.al.|[2411.06295v1](http://arxiv.org/abs/2411.06295v1)|null|
|**2024-11-09**|**An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models**|Fatemeh Shiri et.al.|[2411.06048v1](http://arxiv.org/abs/2411.06048v1)|[link](https://github.com/fatemehshiri/spatial-mm)|
|**2024-11-08**|**Mitigating Hallucination with ZeroG: An Advanced Knowledge Management Engine**|Anantha Sharma et.al.|[2411.05936v1](http://arxiv.org/abs/2411.05936v1)|null|
|**2024-11-08**|**SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark**|Sithursan Sivasubramaniam et.al.|[2411.05521v2](http://arxiv.org/abs/2411.05521v2)|[link](https://github.com/jf87/sm3-text-to-query)|
|**2024-11-08**|**EUREKHA: Enhancing User Representation for Key Hackers Identification in Underground Forums**|Abdoul Nasser Hassane Amadou et.al.|[2411.05479v1](http://arxiv.org/abs/2411.05479v1)|[link](https://github.com/jumbo110/eurekha)|
|**2024-11-08**|**When are 1.58 bits enough? A Bottom-up Exploration of BitNet Quantization**|Jacob Nielsen et.al.|[2411.05882v1](http://arxiv.org/abs/2411.05882v1)|null|
|**2024-11-08**|**Exploring the Alignment Landscape: LLMs and Geometric Deep Models in Protein Representation**|Dong Shu et.al.|[2411.05316v1](http://arxiv.org/abs/2411.05316v1)|[link](https://github.com/tizzzzy/llm-gdm-alignment)|
|**2024-11-07**|**AMSnet-KG: A Netlist Dataset for LLM-based AMS Circuit Auto-Design Using Knowledge Graph RAG**|Yichen Shi et.al.|[2411.13560v1](http://arxiv.org/abs/2411.13560v1)|null|
|**2024-11-06**|**LEGO-GraphRAG: Modularizing Graph-based Retrieval-Augmented Generation for Design Space Exploration**|Yukun Cao et.al.|[2411.05844v1](http://arxiv.org/abs/2411.05844v1)|null|
|**2024-11-06**|**MEG: Medical Knowledge-Augmented Large Language Models for Question Answering**|Laura Cabello et.al.|[2411.03883v2](http://arxiv.org/abs/2411.03883v2)|[link](https://github.com/lautel/meg)|
|**2024-11-06**|**A Library Perspective on Supervised Text Processing in Digital Libraries: An Investigation in the Biomedical Domain**|Hermann Kroll et.al.|[2411.12752v1](http://arxiv.org/abs/2411.12752v1)|[link](https://github.com/hermannkroll/supervisedtextprocessing)|
|**2024-11-06**|**The American Sign Language Knowledge Graph: Infusing ASL Models with Linguistic Knowledge**|Lee Kezar et.al.|[2411.03568v1](http://arxiv.org/abs/2411.03568v1)|null|
|**2024-11-05**|**Graph-DPEP: Decomposed Plug and Ensemble Play for Few-Shot Document Relation Extraction with Graph-of-Thoughts Reasoning**|Tao Zhang et.al.|[2411.02864v1](http://arxiv.org/abs/2411.02864v1)|null|
|**2024-11-05**|**Multimodal Commonsense Knowledge Distillation for Visual Question Answering**|Shuo Yang et.al.|[2411.02722v1](http://arxiv.org/abs/2411.02722v1)|null|
|**2024-11-04**|**Geometry of orofacial neuromuscular signals: speech articulation decoding using surface electromyography**|Harshavardhana T. Gowda et.al.|[2411.02591v2](http://arxiv.org/abs/2411.02591v2)|[link](https://github.com/HarshavardhanaTG/geometryOfOrofacialNeuromuscularSystem)|
|**2024-11-04**|**GraphXAIN: Narratives to Explain Graph Neural Networks**|Mateusz Cedro et.al.|[2411.02540v2](http://arxiv.org/abs/2411.02540v2)|[link](https://github.com/ADMAntwerp/GraphXAIN)|
|**2024-11-04**|**Improving Scientific Hypothesis Generation with Knowledge Grounded Large Language Models**|Guangzhi Xiong et.al.|[2411.02382v1](http://arxiv.org/abs/2411.02382v1)|null|
|**2024-11-04**|**QCG-Rerank: Chunks Graph Rerank with Query Expansion in Retrieval-Augmented LLMs for Tourism Domain**|Qikai Wei et.al.|[2411.08724v1](http://arxiv.org/abs/2411.08724v1)|null|
|**2024-11-04**|**Can Language Models Enable In-Context Database?**|Yu Pan et.al.|[2411.01807v1](http://arxiv.org/abs/2411.01807v1)|null|
|**2024-11-03**|**Graph-based Confidence Calibration for Large Language Models**|Yukun Li et.al.|[2411.02454v1](http://arxiv.org/abs/2411.02454v1)|null|
|**2024-11-03**|**Ontology Population using LLMs**|Sanaz Saki Norouzi et.al.|[2411.01612v1](http://arxiv.org/abs/2411.01612v1)|null|
|**2024-11-03**|**Pre-trained Molecular Language Models with Random Functional Group Masking**|Tianhao Peng et.al.|[2411.01401v1](http://arxiv.org/abs/2411.01401v1)|null|
|**2024-11-01**|**Narrative Analysis of True Crime Podcasts With Knowledge Graph-Augmented Large Language Models**|Xinyi Leng et.al.|[2411.02435v1](http://arxiv.org/abs/2411.02435v1)|null|
|**2024-11-01**|**WLPlan: Relational Features for Symbolic Planning**|Dillon Z. Chen et.al.|[2411.00577v1](http://arxiv.org/abs/2411.00577v1)|null|
|**2024-11-01**|**GRS-QA -- Graph Reasoning-Structured Question Answering Dataset**|Anish Pahilajani et.al.|[2411.00369v3](http://arxiv.org/abs/2411.00369v3)|null|
|**2024-11-01**|**Evaluating the Impact of Lab Test Results on Large Language Models Generated Differential Diagnoses from Clinical Case Vignettes**|Balu Bhasuran et.al.|[2411.02523v1](http://arxiv.org/abs/2411.02523v1)|null|
|**2024-10-31**|**Compositional Automata Embeddings for Goal-Conditioned Reinforcement Learning**|Beyazit Yalcinkaya et.al.|[2411.00205v1](http://arxiv.org/abs/2411.00205v1)|null|
|**2024-10-31**|**Building Multi-Agent Copilot towards Autonomous Agricultural Data Management and Analysis**|Yu Pan et.al.|[2411.00188v1](http://arxiv.org/abs/2411.00188v1)|null|
|**2024-10-31**|**Exploring the Knowledge Mismatch Hypothesis: Hallucination Propensity in Small Models Fine-tuned on Data from Larger Models**|Phil Wee et.al.|[2411.00878v1](http://arxiv.org/abs/2411.00878v1)|null|
|**2024-10-31**|**Failure Modes of LLMs for Causal Reasoning on Narratives**|Khurram Yamin et.al.|[2410.23884v1](http://arxiv.org/abs/2410.23884v1)|[link](https://github.com/shantanu95/llm_causal_reasoning)|
|**2024-10-31**|**Plan-on-Graph: Self-Correcting Adaptive Planning of Large Language Model on Knowledge Graphs**|Liyi Chen et.al.|[2410.23875v1](http://arxiv.org/abs/2410.23875v1)|[link](https://github.com/liyichen-cly/pog)|
|**2024-10-31**|**LLaMo: Large Language Model-based Molecular Graph Assistant**|Jinyoung Park et.al.|[2411.00871v1](http://arxiv.org/abs/2411.00871v1)|[link](https://github.com/mlvlab/llamo)|
|**2024-10-31**|**End-to-End Ontology Learning with Large Language Models**|Andy Lo et.al.|[2410.23584v1](http://arxiv.org/abs/2410.23584v1)|[link](https://github.com/andylolu2/ollm)|
|**2024-10-30**|**Graph-Augmented Relation Extraction Model with LLMs-Generated Support Document**|Vicky Dong et.al.|[2410.23452v1](http://arxiv.org/abs/2410.23452v1)|null|
|**2024-10-30**|**FlowLLM: Flow Matching for Material Generation with Large Language Models as Base Distributions**|Anuroop Sriram et.al.|[2410.23405v1](http://arxiv.org/abs/2410.23405v1)|[link](https://github.com/facebookresearch/flowmm)|
|**2024-10-30**|**EMMA: End-to-End Multimodal Model for Autonomous Driving**|Jyh-Jing Hwang et.al.|[2410.23262v2](http://arxiv.org/abs/2410.23262v2)|null|
|**2024-10-30**|**ProTransformer: Robustify Transformers via Plug-and-Play Paradigm**|Zhichao Hou et.al.|[2410.23182v1](http://arxiv.org/abs/2410.23182v1)|null|
|**2024-10-30**|**Semantic Enrichment of the Quantum Cascade Laser Properties in Text- A Knowledge Graph Generation Approach**|Deperias Kerre et.al.|[2410.22996v1](http://arxiv.org/abs/2410.22996v1)|null|
|**2024-10-30**|**How Well Do Large Language Models Disambiguate Swedish Words?**|Richard Johansson et.al.|[2410.22827v1](http://arxiv.org/abs/2410.22827v1)|null|
|**2024-10-30**|**Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot**|Sejin Lee et.al.|[2410.22767v1](http://arxiv.org/abs/2410.22767v1)|[link](https://github.com/eastha0526/beyond-ontology-in-dst)|
|**2024-10-30**|**The Graph's Apprentice: Teaching an LLM Low Level Knowledge for Circuit Quality Estimation**|Reza Moravej et.al.|[2411.00843v1](http://arxiv.org/abs/2411.00843v1)|null|
|**2024-10-29**|**Are Large-Language Models Graph Algorithmic Reasoners?**|Alexander K Taylor et.al.|[2410.22597v1](http://arxiv.org/abs/2410.22597v1)|[link](https://github.com/ataylor24/magma)|
|**2024-10-29**|**Advancing Agentic Systems: Dynamic Task Decomposition, Tool Integration and Evaluation using Novel Metrics and Dataset**|Adrian Garret Gabriel et.al.|[2410.22457v1](http://arxiv.org/abs/2410.22457v1)|null|
|**2024-10-29**|**DynaMath: A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models**|Chengke Zou et.al.|[2411.00836v1](http://arxiv.org/abs/2411.00836v1)|null|
|**2024-10-29**|**ADAM: An Embodied Causal Agent in Open-World Environments**|Shu Yu et.al.|[2410.22194v1](http://arxiv.org/abs/2410.22194v1)|null|
|**2024-10-29**|**GraphAide: Advanced Graph-Assisted Query and Reasoning System**|Sumit Purohit et.al.|[2411.08041v1](http://arxiv.org/abs/2411.08041v1)|null|
|**2024-10-29**|**Synergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN**|Zhilun Zhou et.al.|[2411.00028v2](http://arxiv.org/abs/2411.00028v2)|null|
|**2024-10-29**|**A Hierarchical Language Model For Interpretable Graph Reasoning**|Sambhav Khurana et.al.|[2410.22372v1](http://arxiv.org/abs/2410.22372v1)|null|
|**2024-10-28**|**LLM-Forest for Health Tabular Data Imputation**|Xinrui He et.al.|[2410.21520v1](http://arxiv.org/abs/2410.21520v1)|null|
|**2024-10-28**|**Hierarchical Knowledge Graph Construction from Images for Scalable E-Commerce**|Zhantao Yang et.al.|[2410.21237v1](http://arxiv.org/abs/2410.21237v1)|null|
|**2024-10-28**|**CRAT: A Multi-Agent Framework for Causality-Enhanced Reflective and Retrieval-Augmented Translation with Large Language Models**|Meiqi Chen et.al.|[2410.21067v1](http://arxiv.org/abs/2410.21067v1)|null|
|**2024-10-28**|**CTINEXUS: Leveraging Optimized LLM In-Context Learning for Constructing Cybersecurity Knowledge Graphs Under Data Scarcity**|Yutong Cheng et.al.|[2410.21060v1](http://arxiv.org/abs/2410.21060v1)|null|
|**2024-10-28**|**Graph-based Uncertainty Metrics for Long-form Language Model Outputs**|Mingjian Jiang et.al.|[2410.20783v1](http://arxiv.org/abs/2410.20783v1)|[link](https://github.com/mingjianjiang-1/graph-based-uncertainty)|
|**2024-10-28**|**Plan$\times$RAG: Planning-guided Retrieval Augmented Generation**|Prakhar Verma et.al.|[2410.20753v1](http://arxiv.org/abs/2410.20753v1)|null|
|**2024-10-28**|**Simple is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation**|Mufei Li et.al.|[2410.20724v2](http://arxiv.org/abs/2410.20724v2)|[link](https://github.com/graph-com/subgraphrag)|

#### Abstracts
##### **AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning**
2411.16495v1 by Amy Xin, Jinxin Liu, Zijun Yao, Zhicheng Li, Shulin Cao, Lei Hou, Juanzi Li

Recent advancements in large language models (LLMs) have led to significant
improvements in various natural language processing tasks, but it is still
challenging for LLMs to perform knowledge-intensive complex question answering
due to LLMs' inefficacy in reasoning planning and the hallucination problem. A
typical solution is to employ retrieval-augmented generation (RAG) coupled with
chain-of-thought (CoT) reasoning, which decomposes complex questions into
chain-like sub-questions and applies iterative RAG at each sub-question.
However, prior works exhibit sub-optimal reasoning planning and overlook
dynamic knowledge retrieval from heterogeneous sources. In this paper, we
propose AtomR, a novel heterogeneous knowledge reasoning framework that
conducts multi-source reasoning at the atomic level. Drawing inspiration from
the graph modeling of knowledge, AtomR leverages large language models (LLMs)
to decompose complex questions into combinations of three atomic knowledge
operators, significantly enhancing the reasoning process at both the planning
and execution stages. We also introduce BlendQA, a novel evaluation benchmark
tailored to assess complex heterogeneous knowledge reasoning. Experiments show
that AtomR significantly outperforms state-of-the-art baselines across three
single-source and two multi-source reasoning benchmarks, with notable
performance gains of 9.4% on 2WikiMultihop and 9.5% on BlendQA.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂ∑≤Â§ßÂπÖÊîπÂñÑÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãôÔºå‰ΩÜÁî±Êñº LLM Âú®Êé®ÁêÜË¶èÂäÉÂíåÂπªË¶∫ÂïèÈ°å‰∏äÁöÑÁÑ°ËÉΩÔºåÂ∞çÊñº LLM Âü∑Ë°åÈúÄË¶ÅÁü•Ë≠òÁöÑË§áÈõúÂïèÈ°åÂõûÁ≠î‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂÖ∏ÂûãÁöÑËß£Ê±∫ÊñπÊ°àÊòØÊé°Áî®Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) Êê≠ÈÖçÊÄùËÄÉÈèà (CoT) Êé®ÁêÜÔºåÂ∞áË§áÈõúÂïèÈ°åÂàÜËß£ÊàêÈèàÁãÄÂ≠êÂïèÈ°åÔºå‰∏¶Âú®ÊØèÂÄãÂ≠êÂïèÈ°å‰∏äÂ•óÁî®Ëø≠‰ª£ RAG„ÄÇÁÑ∂ËÄåÔºåÂÖàÂâçÁöÑÂ∑•‰ΩúÂ±ïÁèæÂá∫Ê¨°‰Ω≥Êé®ÁêÜË¶èÂäÉÔºå‰∏îÂøΩÁï•‰∫ÜÂæûÁï∞Ë≥™‰æÜÊ∫êÂãïÊÖãÊ™¢Á¥¢Áü•Ë≠ò„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ AtomRÔºå‰∏ÄÂÄãÊñ∞Á©éÁöÑÁï∞Ë≥™Áü•Ë≠òÊé®ÁêÜÊû∂ÊßãÔºåÂú®ÂéüÂ≠êÂ±§Á¥öÂü∑Ë°åÂ§ö‰æÜÊ∫êÊé®ÁêÜ„ÄÇÂæûÁü•Ë≠òÁöÑÂúñÂΩ¢Âª∫Ê®°‰∏≠Ê±≤ÂèñÈùàÊÑüÔºåAtomR Êé°Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∞áË§áÈõúÂïèÈ°åÂàÜËß£Êàê‰∏âÁ®ÆÂéüÂ≠êÁü•Ë≠òÈÅãÁÆóÂ≠êÁöÑÁµÑÂêàÔºåÂ§ßÂπÖÂº∑ÂåñË¶èÂäÉÂíåÂü∑Ë°åÈöéÊÆµÁöÑÊé®ÁêÜÁ®ãÂ∫è„ÄÇÊàëÂÄë‰πüÂºïÂÖ•‰∫Ü BlendQAÔºå‰∏ÄÂÄãÊñ∞Á©éÁöÑË©ïÈáèÂü∫Ê∫ñÔºåÂ∞àÈñÄÁî®‰æÜË©ï‰º∞Ë§áÈõúÁöÑÁï∞Ë≥™Áü•Ë≠òÊé®ÁêÜ„ÄÇÂØ¶È©óÈ°ØÁ§∫ÔºåAtomR Âú®‰∏âÂÄãÂñÆ‰∏Ä‰æÜÊ∫êÂíåÂÖ©ÂÄãÂ§ö‰æÜÊ∫êÊé®ÁêÜÂü∫Ê∫ñ‰∏äÂ§ßÂπÖÂÑ™ÊñºÁèæÊúâÁöÑÂü∫Á∑öÔºåÂú® 2WikiMultihop ‰∏äÊúâ 9.4% ÁöÑÈ°ØËëóÊïàËÉΩÊèêÂçáÔºåÂú® BlendQA ‰∏äÂâáÊúâ 9.5%„ÄÇ

##### **Learning by Analogy: Enhancing Few-Shot Prompting for Math Word Problem Solving with Computational Graph-Based Retrieval**
2411.16454v1 by Xiaocong Yang, Jiacheng Lin, Ziqi Wang, Chengxiang Zhai

Large language models (LLMs) are known to struggle with complicated reasoning
tasks such as math word problems (MWPs). In this paper, we present how analogy
from similarly structured questions can improve LLMs' problem-solving
capabilities for MWPs. Specifically, we rely on the retrieval of problems with
similar computational graphs to the given question to serve as exemplars in the
prompt, providing the correct reasoning path for the generation model to refer
to. Empirical results across six math word problem datasets demonstrate the
effectiveness of our proposed method, which achieves a significant improvement
of up to 6.7 percent on average in absolute value, compared to baseline
methods. These results highlight our method's potential in addressing the
reasoning challenges in current LLMs.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Áü•Âú®Ë§áÈõúÊé®ÁêÜ‰ªªÂãôÔºà‰æãÂ¶ÇÊï∏Â≠∏ÊñáÂ≠óÈ°å (MWP)Ôºâ‰∏≠ÊúÉÈÅáÂà∞Âõ∞Èõ£„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰æÜËá™ÁµêÊßãÁõ∏‰ººÁöÑÂïèÈ°åÁöÑÈ°ûÊØîÂ¶Ç‰ΩïËÉΩÊîπÂñÑ LLM Â∞ç MWP ÁöÑÂïèÈ°åËß£Ê±∫ËÉΩÂäõ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄë‰æùË≥¥ÊñºÊì∑ÂèñËàáÁµ¶ÂÆöÂïèÈ°åÂÖ∑ÊúâÈ°û‰ººÈÅãÁÆóÂúñÂΩ¢ÁöÑÂïèÈ°åÔºå‰ΩúÁÇ∫ÊèêÁ§∫‰∏≠ÁöÑÁØÑ‰æãÔºåÁÇ∫ÁîüÊàêÊ®°ÂûãÊèê‰æõÊ≠£Á¢∫ÁöÑÊé®ÁêÜË∑ØÂæë‰ª•‰æõÂèÉËÄÉ„ÄÇÂÖ≠ÂÄãÊï∏Â≠∏ÊñáÂ≠óÈ°åÊï∏ÊìöÈõÜÁöÑÂØ¶Ë≠âÁµêÊûúË≠âÊòé‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåËàáÂü∫Á∑öÊñπÊ≥ïÁõ∏ÊØîÔºåÂπ≥ÂùáÁµïÂ∞çÂÄºÊèêÈ´ò‰∫Ü 6.7 ÂÄãÁôæÂàÜÈªû„ÄÇÈÄô‰∫õÁµêÊûúÁ™ÅÂá∫‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®Ëß£Ê±∫Áï∂Ââç LLM ‰∏≠ÁöÑÊé®ÁêÜÊåëÊà∞ÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇ

##### **Adapter-based Approaches to Knowledge-enhanced Language Models -- A Survey**
2411.16403v1 by Alexander Fichtl, Juraj Vladika, Georg Groh

Knowledge-enhanced language models (KELMs) have emerged as promising tools to
bridge the gap between large-scale language models and domain-specific
knowledge. KELMs can achieve higher factual accuracy and mitigate
hallucinations by leveraging knowledge graphs (KGs). They are frequently
combined with adapter modules to reduce the computational load and risk of
catastrophic forgetting. In this paper, we conduct a systematic literature
review (SLR) on adapter-based approaches to KELMs. We provide a structured
overview of existing methodologies in the field through quantitative and
qualitative analysis and explore the strengths and potential shortcomings of
individual approaches. We show that general knowledge and domain-specific
approaches have been frequently explored along with various adapter
architectures and downstream tasks. We particularly focused on the popular
biomedical domain, where we provided an insightful performance comparison of
existing KELMs. We outline the main trends and propose promising future
directions.

ÊëòË¶ÅÔºöÁü•Ë≠òÂ¢ûÂº∑Ë™ûË®ÄÊ®°ÂûãÔºàKELMÔºâÂ∑≤ÊàêÁÇ∫ÂΩåÂêàÂ§ßË¶èÊ®°Ë™ûË®ÄÊ®°ÂûãËàáÁâπÂÆöÈ†òÂüüÁü•Ë≠òÂ∑ÆË∑ùÁöÑÊúâÂâçÈÄîÁöÑÂ∑•ÂÖ∑„ÄÇKELM ÂèØ‰ª•ÈÄèÈÅéÂà©Áî®Áü•Ë≠òÂúñË≠úÔºàKGÔºâ‰æÜÊèêÈ´ò‰∫ãÂØ¶Ê∫ñÁ¢∫ÊÄß‰∏¶Ê∏õÂ∞ëÂπªË¶∫„ÄÇÂÆÉÂÄëÁ∂ìÂ∏∏ËàáÈÅ©ÈÖçÂô®Ê®°ÁµÑÁµêÂêà‰ΩøÁî®Ôºå‰ª•Èôç‰ΩéÈÅãÁÆóË≤†ËºâÂíåÁÅΩÈõ£ÊÄßÈÅ∫ÂøòÁöÑÈ¢®Èö™„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞çÂü∫ÊñºÈÅ©ÈÖçÂô®ÁöÑ KELM ÊñπÊ≥ïÈÄ≤Ë°åÁ≥ªÁµ±ÊÄßÁöÑÊñáÁçªÂõûÈ°ßÔºàSLRÔºâ„ÄÇÊàëÂÄëÈÄèÈÅéÂÆöÈáèÂíåÂÆöÊÄßÂàÜÊûêÊèê‰æõË©≤È†òÂüüÊó¢ÊúâÊñπÊ≥ïË´ñÁöÑÁµêÊßãÂåñÊ¶ÇËßÄÔºå‰∏¶Êé¢Ë®éÂÄãÂà•ÊñπÊ≥ïÁöÑÂÑ™ÈªûÂíåÊΩõÂú®Áº∫Èªû„ÄÇÊàëÂÄëË°®ÊòéÔºå‰∏ÄËà¨Áü•Ë≠òÂíåÁâπÂÆöÈ†òÂüüÁöÑÊñπÊ≥ïÂ∑≤ËàáÂêÑÁ®ÆÈÅ©ÈÖçÂô®Êû∂ÊßãÂíå‰∏ãÊ∏∏‰ªªÂãô‰∏ÄËµ∑Ë¢´È†ªÁπÅÊé¢Á¥¢„ÄÇÊàëÂÄëÁâπÂà•ÈóúÊ≥®ÁÜ±ÈñÄÁöÑÁîüÁâ©ÈÜ´Â≠∏È†òÂüüÔºåÂú®Ë©≤È†òÂüü‰∏≠ÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÁèæÊúâ KELM ÁöÑÊúâË¶ãÂú∞ÊïàËÉΩÊØîËºÉ„ÄÇÊàëÂÄëÊ¶ÇËø∞‰∫Ü‰∏ªË¶ÅË∂®Âã¢Ôºå‰∏¶ÊèêÂá∫‰∫ÜÊúâÂâçÈÄîÁöÑÊú™‰æÜÊñπÂêë„ÄÇ

##### **Decoding Urban Industrial Complexity: Enhancing Knowledge-Driven Insights via IndustryScopeGPT**
2411.15758v1 by Siqi Wang, Chao Liang, Yunfan Gao, Yang Liu, Jing Li, Haofen Wang

Industrial parks are critical to urban economic growth. Yet, their
development often encounters challenges stemming from imbalances between
industrial requirements and urban services, underscoring the need for strategic
planning and operations. This paper introduces IndustryScopeKG, a pioneering
large-scale multi-modal, multi-level industrial park knowledge graph, which
integrates diverse urban data including street views, corporate,
socio-economic, and geospatial information, capturing the complex relationships
and semantics within industrial parks. Alongside this, we present the
IndustryScopeGPT framework, which leverages Large Language Models (LLMs) with
Monte Carlo Tree Search to enhance tool-augmented reasoning and decision-making
in Industrial Park Planning and Operation (IPPO). Our work significantly
improves site recommendation and functional planning, demonstrating the
potential of combining LLMs with structured datasets to advance industrial park
management. This approach sets a new benchmark for intelligent IPPO research
and lays a robust foundation for advancing urban industrial development. The
dataset and related code are available at
https://github.com/Tongji-KGLLM/IndustryScope.

ÊëòË¶ÅÔºöÂ∑•Ê•≠ÂúíÂçÄÂ∞çÊñºÈÉΩÂ∏ÇÁ∂ìÊøüÊàêÈï∑Ëá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÂÖ∂ÁôºÂ±ïÁ∂ìÂ∏∏ÊúÉÈÅáÂà∞Â∑•Ê•≠ÈúÄÊ±ÇËàáÈÉΩÂ∏ÇÊúçÂãô‰πãÈñì‰∏çÂπ≥Ë°°ÊâÄÁî¢ÁîüÁöÑÊåëÊà∞ÔºåÈÄôÂá∏È°Ø‰∫ÜÁ≠ñÁï•ÊÄßË¶èÂäÉËàáÁáüÈÅãÁöÑÈúÄÊ±Ç„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü IndustryScopeKGÔºå‰∏ÄÂÄãÂÖàÈ©ÖÊÄßÁöÑ„ÄÅÂ§ßË¶èÊ®°„ÄÅÂ§öÊ®°Âºè„ÄÅÂ§öÂ±§Á¥öÁöÑÂ∑•Ê•≠ÂúíÂçÄÁü•Ë≠òÂúñË≠úÔºåÂÆÉÊï¥Âêà‰∫ÜÂåÖÂê´Ë°óÊôØ„ÄÅÂÖ¨Âè∏„ÄÅÁ§æÊúÉÁ∂ìÊøüÂíåÂú∞ÁêÜÁ©∫ÈñìË≥áË®äÂú®ÂÖßÁöÑÂêÑÁ®ÆÈÉΩÂ∏ÇË≥áÊñôÔºåÊçïÊçâÂ∑•Ê•≠ÂúíÂçÄÂÖßË§áÈõúÁöÑÈóú‰øÇÂíåË™ûÊÑè„ÄÇÈô§Ê≠§‰πãÂ§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü IndustryScopeGPT Êû∂ÊßãÔºåÂÆÉÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËàáËíôÂú∞Âç°ÁæÖÊ®πÁãÄÊêúÂ∞ãÔºå‰ª•Â¢ûÂº∑Â∑•ÂÖ∑ËºîÂä©Êé®ÁêÜÂíåÂú®Â∑•Ê•≠ÂúíÂçÄË¶èÂäÉÂíåÁáüÈÅã (IPPO) ‰∏≠ÁöÑÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Â§ßÂπÖÊîπÂñÑ‰∫ÜÂ†¥Âú∞Êé®Ëñ¶ÂíåÂäüËÉΩË¶èÂäÉÔºåÂ±ïÁ§∫‰∫ÜÁµêÂêà LLM ÂíåÁµêÊßãÂåñË≥áÊñôÈõÜ‰ª•Êé®ÈÄ≤Â∑•Ê•≠ÂúíÂçÄÁÆ°ÁêÜÁöÑÊΩõÂäõ„ÄÇÈÄôÂÄãÊñπÊ≥ïÁÇ∫Êô∫ÊÖß IPPO Á†îÁ©∂Ë®≠ÂÆö‰∫ÜÊñ∞ÁöÑÂü∫Ê∫ñÔºå‰∏¶ÁÇ∫Êé®ÈÄ≤ÈÉΩÂ∏ÇÁî¢Ê•≠ÁôºÂ±ïÂ•†ÂÆö‰∫ÜÁ©©Âõ∫ÁöÑÂü∫Á§é„ÄÇË≥áÊñôÈõÜÂíåÁõ∏ÈóúÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/Tongji-KGLLM/IndustryScope ÂèñÂæó„ÄÇ

##### **One to rule them all: natural language to bind communication, perception and action**
2411.15033v1 by Simone Colombani, Dimitri Ognibene, Giuseppe Boccignone

In recent years, research in the area of human-robot interaction has focused
on developing robots capable of understanding complex human instructions and
performing tasks in dynamic and diverse environments. These systems have a wide
range of applications, from personal assistance to industrial robotics,
emphasizing the importance of robots interacting flexibly, naturally and safely
with humans. This paper presents an advanced architecture for robotic action
planning that integrates communication, perception, and planning with Large
Language Models (LLMs). Our system is designed to translate commands expressed
in natural language into executable robot actions, incorporating environmental
information and dynamically updating plans based on real-time feedback. The
Planner Module is the core of the system where LLMs embedded in a modified
ReAct framework are employed to interpret and carry out user commands. By
leveraging their extensive pre-trained knowledge, LLMs can effectively process
user requests without the need to introduce new knowledge on the changing
environment. The modified ReAct framework further enhances the execution space
by providing real-time environmental perception and the outcomes of physical
actions. By combining robust and dynamic semantic map representations as graphs
with control components and failure explanations, this architecture enhances a
robot adaptability, task execution, and seamless collaboration with human users
in shared and dynamic environments. Through the integration of continuous
feedback loops with the environment the system can dynamically adjusts the plan
to accommodate unexpected changes, optimizing the robot ability to perform
tasks. Using a dataset of previous experience is possible to provide detailed
feedback about the failure. Updating the LLMs context of the next iteration
with suggestion on how to overcame the issue.

ÊëòË¶ÅÔºöËøëÂπ¥Êù•Ôºå‰∫∫Êú∫‰∫§‰∫íÈ¢ÜÂüüÁöÑÁ†îÁ©∂ÈáçÁÇπ
Âú®‰∫éÂºÄÂèëËÉΩÂ§üÁêÜËß£Â§çÊùÇ‰∫∫Á±ªÊåá‰ª§Âπ∂Âú®Âä®ÊÄÅÂíåÂ§öÊ†∑ÂåñÁéØÂ¢É‰∏≠ÊâßË°å‰ªªÂä°ÁöÑÊú∫Âô®‰∫∫„ÄÇËøô‰∫õÁ≥ªÁªüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®Ôºå‰ªé‰∏™‰∫∫Âä©ÁêÜÂà∞Â∑•‰∏öÊú∫Âô®‰∫∫ÔºåÂº∫Ë∞É‰∫ÜÊú∫Âô®‰∫∫‰∏é‰∫∫Á±ªÁÅµÊ¥ª„ÄÅËá™ÁÑ∂ÂíåÂÆâÂÖ®‰∫§‰∫íÁöÑÈáçË¶ÅÊÄß„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂÖàËøõÁöÑÊú∫Âô®‰∫∫Âä®‰ΩúËßÑÂàíÊû∂ÊûÑÔºåËØ•Êû∂ÊûÑÈõÜÊàê‰∫ÜÈÄö‰ø°„ÄÅÊÑüÁü•ÂíåËßÑÂàí‰∏éÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM)„ÄÇÊàë‰ª¨ÁöÑÁ≥ªÁªüÊó®Âú®Â∞Ü‰ª•Ëá™ÁÑ∂ËØ≠Ë®ÄË°®ËææÁöÑÂëΩ‰ª§ÁøªËØëÊàêÂèØÊâßË°åÁöÑÊú∫Âô®‰∫∫Âä®‰ΩúÔºåÂπ∂ÁªìÂêàÁéØÂ¢É‰ø°ÊÅØÂπ∂Ê†πÊçÆÂÆûÊó∂ÂèçÈ¶àÂä®ÊÄÅÊõ¥Êñ∞ËÆ°Âàí„ÄÇËßÑÂàíÂô®Ê®°ÂùóÊòØÁ≥ªÁªüÁöÑÊ†∏ÂøÉÔºåÂÖ∂‰∏≠ÂµåÂÖ•Âú®‰øÆÊîπÂêéÁöÑ ReAct Ê°ÜÊû∂‰∏≠ÁöÑ LLM Áî®‰∫éËß£ÈáäÂíåÊâßË°åÁî®Êà∑ÂëΩ‰ª§„ÄÇÈÄöËøáÂà©Áî®ÂÖ∂ÂπøÊ≥õÁöÑÈ¢ÑËÆ≠ÁªÉÁü•ËØÜÔºåLLM ÂèØ‰ª•ÊúâÊïàÂ§ÑÁêÜÁî®Êà∑ËØ∑Ê±ÇÔºåËÄåÊó†ÈúÄÂºïÂÖ•ÊúâÂÖ≥‰∏çÊñ≠ÂèòÂåñÁöÑÁéØÂ¢ÉÁöÑÊñ∞Áü•ËØÜ„ÄÇ‰øÆÊîπÂêéÁöÑ ReAct Ê°ÜÊû∂ÈÄöËøáÊèê‰æõÂÆûÊó∂ÁéØÂ¢ÉÊÑüÁü•ÂíåÁâ©ÁêÜÂä®‰ΩúÁöÑÁªìÊûúËøõ‰∏ÄÊ≠•Â¢ûÂº∫‰∫ÜÊâßË°åÁ©∫Èó¥„ÄÇÈÄöËøáÂ∞ÜÈ≤ÅÊ£í‰∏îÂä®ÊÄÅËØ≠‰πâÂú∞ÂõæË°®Á§∫‰∏éÊéßÂà∂ÁªÑ‰ª∂ÂíåÊïÖÈöúËß£ÈáäÁõ∏ÁªìÂêàÔºåËØ•Êû∂ÊûÑÂ¢ûÂº∫‰∫ÜÊú∫Âô®‰∫∫ÁöÑÈÄÇÂ∫îÊÄß„ÄÅ‰ªªÂä°ÊâßË°å‰ª•Âèä‰∏é‰∫∫Á±ªÁî®Êà∑Âú®ÂÖ±‰∫´ÂíåÂä®ÊÄÅÁéØÂ¢É‰∏≠ÁöÑÊó†ÁºùÂçè‰Ωú„ÄÇÈÄöËøáÂ∞ÜËøûÁª≠ÂèçÈ¶àÂõûË∑Ø‰∏éÁéØÂ¢ÉÁõ∏ÁªìÂêàÔºåÁ≥ªÁªüÂèØ‰ª•Âä®ÊÄÅË∞ÉÊï¥ËÆ°Âàí‰ª•ÈÄÇÂ∫îÊÑèÂ§ñÂèòÂåñÔºå‰ªéËÄå‰ºòÂåñÊú∫Âô®‰∫∫ÊâßË°å‰ªªÂä°ÁöÑËÉΩÂäõ„ÄÇÂà©Áî®ÂÖàÂâçÁöÑÁªèÈ™åÊï∞ÊçÆÈõÜÔºåÂèØ‰ª•Êèê‰æõÊúâÂÖ≥ÊïÖÈöúÁöÑËØ¶ÁªÜÂèçÈ¶à„ÄÇ‰ΩøÁî®ÊúâÂÖ≥Â¶Ç‰ΩïÂÖãÊúçÈóÆÈ¢òÁöÑÂª∫ËÆÆÊõ¥Êñ∞‰∏ã‰∏Ä‰∏™Ëø≠‰ª£ÁöÑ LLM ‰∏ä‰∏ãÊñá„ÄÇ

##### **Time is on my sight: scene graph filtering for dynamic environment perception in an LLM-driven robot**
2411.15027v1 by Simone Colombani, Luca Brini, Dimitri Ognibene, Giuseppe Boccignone

Robots are increasingly being used in dynamic environments like workplaces,
hospitals, and homes. As a result, interactions with robots must be simple and
intuitive, with robots perception adapting efficiently to human-induced
changes. This paper presents a robot control architecture that addresses key
challenges in human-robot interaction, with a particular focus on the dynamic
creation and continuous update of the robot state representation. The
architecture uses Large Language Models to integrate diverse information
sources, including natural language commands, robotic skills representation,
real-time dynamic semantic mapping of the perceived scene. This enables
flexible and adaptive robotic behavior in complex, dynamic environments.
Traditional robotic systems often rely on static, pre-programmed instructions
and settings, limiting their adaptability to dynamic environments and real-time
collaboration. In contrast, this architecture uses LLMs to interpret complex,
high-level instructions and generate actionable plans that enhance human-robot
collaboration. At its core, the system Perception Module generates and
continuously updates a semantic scene graph using RGB-D sensor data, providing
a detailed and structured representation of the environment. A particle filter
is employed to ensure accurate object localization in dynamic, real-world
settings. The Planner Module leverages this up-to-date semantic map to break
down high-level tasks into sub-tasks and link them to robotic skills such as
navigation, object manipulation (e.g., PICK and PLACE), and movement (e.g.,
GOTO). By combining real-time perception, state tracking, and LLM-driven
communication and task planning, the architecture enhances adaptability, task
efficiency, and human-robot collaboration in dynamic environments.

ÊëòË¶ÅÔºö<paragraph>Ê©üÂô®‰∫∫Ê≠£Ë∂ä‰æÜË∂äÂª£Ê≥õÂú∞ÊáâÁî®ÊñºÂ∑•‰ΩúÂ†¥ÊâÄ„ÄÅÈÜ´Èô¢ÂíåÂÆ∂Â∫≠Á≠âÂãïÊÖãÁí∞Â¢É‰∏≠„ÄÇÂõ†Ê≠§ÔºåËàáÊ©üÂô®‰∫∫ÁöÑ‰∫íÂãïÂøÖÈ†àÁ∞°ÂñÆÁõ¥ËßÄÔºåÊ©üÂô®‰∫∫ÁöÑÊÑüÁü•ËÉΩÂäõÂøÖÈ†àÊúâÊïàÈÅ©Êáâ‰∫∫È°ûÂºïÁôºÁöÑËÆäÂåñ„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊ©üÂô®‰∫∫ÊéßÂà∂Êû∂ÊßãÔºåÁî®ÊñºËß£Ê±∫‰∫∫Ê©ü‰∫íÂãï‰∏≠ÁöÑÈóúÈçµÊåëÊà∞ÔºåÁâπÂà•ÈóúÊ≥®Ê©üÂô®‰∫∫ÁãÄÊÖãË°®Á§∫ÁöÑÂãïÊÖãÂª∫Á´ãÂíåÊåÅÁ∫åÊõ¥Êñ∞„ÄÇË©≤Êû∂Êßã‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÊï¥ÂêàÂ§öÁ®ÆË≥áË®ä‰æÜÊ∫êÔºåÂåÖÊã¨Ëá™ÁÑ∂Ë™ûË®ÄÂëΩ‰ª§„ÄÅÊ©üÂô®‰∫∫ÊäÄËÉΩË°®Á§∫„ÄÅÊÑüÁü•Â†¥ÊôØÁöÑÂç≥ÊôÇÂãïÊÖãË™ûÁæ©Â∞çÊáâ„ÄÇÈÄô‰ΩøÂæóÊ©üÂô®‰∫∫Âú®Ë§áÈõúÁöÑÂãïÊÖãÁí∞Â¢É‰∏≠ËÉΩÂ§†ÈùàÊ¥ªÈÅ©Êáâ„ÄÇÂÇ≥Áµ±ÁöÑÊ©üÂô®‰∫∫Á≥ªÁµ±ÈÄöÂ∏∏‰æùË≥¥ÊñºÈùúÊÖãÁöÑ„ÄÅÈ†êÂÖàÁ∑®Á®ãÁöÑÊåá‰ª§ÂíåË®≠ÂÆöÔºåÈÄôÈôêÂà∂‰∫ÜÂÆÉÂÄëÂ∞çÂãïÊÖãÁí∞Â¢ÉÂíåÂç≥ÊôÇÂçî‰ΩúÁöÑÈÅ©ÊáâËÉΩÂäõ„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåÊ≠§Êû∂Êßã‰ΩøÁî® LLM ‰æÜË©ÆÈáãË§áÈõúÁöÑÈ´òÂ±§Á¥öÊåá‰ª§Ôºå‰∏¶Âà∂ÂÆöÂèØË°åÁöÑË®àÁï´Ôºå‰ª•Â¢ûÂº∑‰∫∫Ê©üÂçî‰Ωú„ÄÇÂú®Á≥ªÁµ±ÁöÑÊ†∏ÂøÉÔºåÊÑüÁü•Ê®°ÁµÑ‰ΩøÁî® RGB-D ÊÑüÊ∏¨Âô®Ë≥áÊñôÁî¢Áîü‰∏¶ÊåÅÁ∫åÊõ¥Êñ∞Ë™ûÁæ©Â†¥ÊôØÂúñÔºåÊèê‰æõÁí∞Â¢ÉÁöÑË©≥Á¥∞‰∏îÁµêÊßãÂåñÁöÑË°®Á§∫„ÄÇÊé°Áî®Á≤íÂ≠êÊøæÊ≥¢Âô®‰ª•Á¢∫‰øùÂú®ÂãïÊÖãÁöÑÁúüÂØ¶‰∏ñÁïåË®≠ÂÆö‰∏≠Ê∫ñÁ¢∫ÂÆö‰ΩçÁâ©‰ª∂„ÄÇË¶èÂäÉÊ®°ÁµÑÂà©Áî®ÈÄôÂÄãÊúÄÊñ∞ÁöÑË™ûÁæ©Âú∞ÂúñÔºåÂ∞áÈ´òÂ±§Á¥ö‰ªªÂãôÂàÜËß£ÁÇ∫Â≠ê‰ªªÂãôÔºå‰∏¶Â∞áÂÆÉÂÄëÈÄ£ÁµêÂà∞Ê©üÂô®‰∫∫ÊäÄËÉΩÔºå‰æãÂ¶ÇÂ∞éËà™„ÄÅÁâ©‰ª∂Êìç‰ΩúÔºà‰æãÂ¶ÇÔºåÂèñÊîæÔºâÂíåÁßªÂãïÔºà‰æãÂ¶ÇÔºåÂâçÂæÄÔºâ„ÄÇÈÄèÈÅéÁµêÂêàÂç≥ÊôÇÊÑüÁü•„ÄÅÁãÄÊÖãËøΩËπ§Âíå LLM È©ÖÂãïÁöÑÊ∫ùÈÄöÂíå‰ªªÂãôË¶èÂäÉÔºåÊ≠§Êû∂ÊßãÂ¢ûÂº∑‰∫ÜÂãïÊÖãÁí∞Â¢É‰∏≠ÁöÑÈÅ©ÊáâËÉΩÂäõ„ÄÅ‰ªªÂãôÊïàÁéáÂíå‰∫∫Ê©üÂçî‰Ωú„ÄÇ</paragraph>

##### **GOT4Rec: Graph of Thoughts for Sequential Recommendation**
2411.14922v1 by Zewen Long, Liang Wang, Shu Wu, Qiang Liu, Liang Wang

With the advancement of large language models (LLMs), researchers have
explored various methods to optimally leverage their comprehension and
generation capabilities in sequential recommendation scenarios. However,
several challenges persist in this endeavor. Firstly, most existing approaches
rely on the input-output prompting paradigm, which can result in irrelevant or
inaccurate responses. Secondly, while there have been attempts to enhance LLMs
using prompting strategies such as chain-of-thought (CoT), these efforts have
not fully harnessed the reasoning abilities of LLMs or effectively captured the
multifaceted information contained within user sequences. To address these
limitations, we propose GOT4Rec, a sequential recommendation method that
utilizes the graph of thoughts (GoT) prompting strategy. Specifically, we
identify and utilize three key types of information within user history
sequences: short-term interests, long-term interests and collaborative
information from other users. Our approach enables LLMs to independently reason
and generate recommendations based on these distinct types of information,
subsequently aggregating the results within the GoT framework to derive the
final recommended items. This method allows LLMs, with enhanced reasoning
capabilities, to more effectively consider the diverse information within user
sequences, resulting in more accurate recommendations and more comprehensive
explanations. Extensive experiments on real-world datasets demonstrate the
effectiveness of GOT4Rec, indicating that it outperforms existing
state-of-the-art baselines. Our code is available at
https://anonymous.4open.science/r/GOT4Rec-ED99.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈÄ≤Ê≠•ÔºåÁ†îÁ©∂‰∫∫Âì°Â∑≤Êé¢Á¥¢ÂêÑÁ®ÆÊñπÊ≥ïÔºå‰ª•ÊúÄ‰Ω≥ÊñπÂºèÂà©Áî®ÂÖ∂ÁêÜËß£ÂíåÁîüÊàêËÉΩÂäõÂú®È†ÜÂ∫èÊé®Ëñ¶Â†¥ÊôØ‰∏≠„ÄÇÁÑ∂ËÄåÔºåÂú®ÈÄôÂÄãÂä™Âäõ‰∏≠‰ªçÂ≠òÂú®‰∏Ä‰∫õÊåëÊà∞„ÄÇÈ¶ñÂÖàÔºåÂ§ßÂ§öÊï∏ÁèæÊúâÊñπÊ≥ï‰æùË≥¥ÊñºËº∏ÂÖ•Ëº∏Âá∫ÊèêÁ§∫ÁØÑ‰æãÔºåÈÄôÂèØËÉΩÊúÉÂ∞éËá¥‰∏çÁõ∏ÈóúÊàñ‰∏çÊ∫ñÁ¢∫ÁöÑÂõûÊáâ„ÄÇÂÖ∂Ê¨°ÔºåÈõñÁÑ∂Êúâ‰∫∫ÂòóË©¶‰ΩøÁî®ÊèêÁ§∫Á≠ñÁï•Ôºà‰æãÂ¶ÇÊÄùÊÉ≥Èèà (CoT)Ôºâ‰æÜÂ¢ûÂº∑ LLMÔºå‰ΩÜÈÄô‰∫õÂä™Âäõ‰∏¶Êú™ÂÖÖÂàÜÂà©Áî® LLM ÁöÑÊé®ÁêÜËÉΩÂäõÊàñÊúâÊïàÊì∑Âèñ‰ΩøÁî®ËÄÖÂ∫èÂàó‰∏≠ÂåÖÂê´ÁöÑÂ§öÊñπÈù¢Ë≥áË®ä„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫ GOT4RecÔºåÈÄôÊòØ‰∏ÄÁ®ÆÈ†ÜÂ∫èÊé®Ëñ¶ÊñπÊ≥ïÔºåÂà©Áî®‰∫ÜÊÄùÊÉ≥Âúñ (GoT) ÊèêÁ§∫Á≠ñÁï•„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂú®‰ΩøÁî®ËÄÖÊ≠∑Âè≤Â∫èÂàó‰∏≠Ë≠òÂà•‰∏¶Âà©Áî®‰∏âÁ®ÆÈ°ûÂûãÁöÑÈóúÈçµË≥áË®äÔºöÁü≠ÊúüËààË∂£„ÄÅÈï∑ÊúüËààË∂£Âíå‰æÜËá™ÂÖ∂‰ªñ‰ΩøÁî®ËÄÖÁöÑÂçî‰ΩúË≥áË®ä„ÄÇÊàëÂÄëÁöÑÊñπÊ≥ï‰Ωø LLM ËÉΩÂ§†Ê†πÊìöÈÄô‰∫õ‰∏çÂêåÈ°ûÂûãÁöÑË≥áË®äÁç®Á´ãÊé®ÁêÜ‰∏¶Áî¢ÁîüÂª∫Ë≠∞ÔºåÁÑ∂ÂæåÂú® GoT Ê°ÜÊû∂ÂÖßÂåØÁ∏ΩÁµêÊûú‰ª•Êé®Â∞éÂá∫ÊúÄÁµÇÊé®Ëñ¶ÁöÑÈ†ÖÁõÆ„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂÖÅË®± LLM Âú®Â¢ûÂº∑Êé®ÁêÜËÉΩÂäõÁöÑÂêåÊôÇÔºåÊõ¥ÊúâÊïàÂú∞ËÄÉÊÖÆ‰ΩøÁî®ËÄÖÂ∫èÂàó‰∏≠ÁöÑ‰∏çÂêåË≥áË®äÔºåÂæûËÄåÁî¢ÁîüÊõ¥Ê∫ñÁ¢∫ÁöÑÂª∫Ë≠∞ÂíåÊõ¥ÂÖ®Èù¢ÁöÑË™™Êòé„ÄÇÂú®ÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÁöÑÂ§ßÈáèÂØ¶È©óË≠âÊòé‰∫Ü GOT4Rec ÁöÑÊúâÊïàÊÄßÔºåË°®ÊòéÂÆÉÂÑ™ÊñºÁèæÊúâÁöÑÊúÄÂÖàÈÄ≤Âü∫Ê∫ñ„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú® https://anonymous.4open.science/r/GOT4Rec-ED99 ÂèñÂæó„ÄÇ

##### **VisGraphVar: A Benchmark Generator for Assessing Variability in Graph Analysis Using Large Vision-Language Models**
2411.14832v1 by Camilo Chac√≥n Sartori, Christian Blum, Filippo Bistaffa

The fast advancement of Large Vision-Language Models (LVLMs) has shown
immense potential. These models are increasingly capable of tackling abstract
visual tasks. Geometric structures, particularly graphs with their inherent
flexibility and complexity, serve as an excellent benchmark for evaluating
these models' predictive capabilities. While human observers can readily
identify subtle visual details and perform accurate analyses, our investigation
reveals that state-of-the-art LVLMs exhibit consistent limitations in specific
visual graph scenarios, especially when confronted with stylistic variations.
In response to these challenges, we introduce VisGraphVar (Visual Graph
Variability), a customizable benchmark generator able to produce graph images
for seven distinct task categories (detection, classification, segmentation,
pattern recognition, link prediction, reasoning, matching), designed to
systematically evaluate the strengths and limitations of individual LVLMs. We
use VisGraphVar to produce 990 graph images and evaluate six LVLMs, employing
two distinct prompting strategies, namely zero-shot and chain-of-thought. The
findings demonstrate that variations in visual attributes of images (e.g., node
labeling and layout) and the deliberate inclusion of visual imperfections, such
as overlapping nodes, significantly affect model performance. This research
emphasizes the importance of a comprehensive evaluation across graph-related
tasks, extending beyond reasoning alone. VisGraphVar offers valuable insights
to guide the development of more reliable and robust systems capable of
performing advanced visual graph analysis.

ÊëòË¶ÅÔºöÂ§ßÂûãË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (LVLMs) ÁöÑÂø´ÈÄüÈÄ≤Ê≠•Â∑≤Â±ïÁèæÂá∫Â∑®Â§ßÁöÑÊΩõÂäõ„ÄÇÈÄô‰∫õÊ®°ÂûãË∂ä‰æÜË∂äÊúâËÉΩÂäõËôïÁêÜÊäΩË±°ÁöÑË¶ñË¶∫‰ªªÂãô„ÄÇÂπæ‰ΩïÁµêÊßãÔºåÁâπÂà•ÊòØÂÖ∑ÊúâÂÖßÂú®ÈùàÊ¥ªÊÄßËàáË§áÈõúÊÄßÁöÑÂúñÂΩ¢ÔºåÂèØÁî®‰ΩúË©ï‰º∞ÈÄô‰∫õÊ®°ÂûãÈ†êÊ∏¨ËÉΩÂäõÁöÑÁµï‰Ω≥Âü∫Ê∫ñ„ÄÇ‰∫∫È°ûËßÄÂØüËÄÖÂèØ‰ª•ËºïÊòìËæ®Ë≠òÂæÆÂ¶ôÁöÑË¶ñË¶∫Á¥∞ÁØÄ‰∏¶Âü∑Ë°åÊ∫ñÁ¢∫ÁöÑÂàÜÊûêÔºå‰ΩÜÊàëÂÄëÁöÑË™øÊü•È°ØÁ§∫ÔºåÊúÄÂÖàÈÄ≤ÁöÑ LVLMs Âú®ÁâπÂÆöÁöÑË¶ñË¶∫ÂúñÂΩ¢Â†¥ÊôØ‰∏≠Ë°®ÁèæÂá∫ÊåÅÁ∫åÁöÑÈôêÂà∂ÔºåÁâπÂà•ÊòØÂú®Èù¢Â∞çÈ¢®Ê†ºËÆäÂåñÊôÇ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü VisGraphVarÔºàË¶ñË¶∫ÂúñÂΩ¢ËÆäÁï∞ÔºâÔºåÈÄôÊòØ‰∏ÄÂÄãÂèØËá™Ë®ÇÁöÑÂü∫Ê∫ñÁî¢ÁîüÂô®ÔºåËÉΩÂ§†Áî¢Áîü‰∏ÉÂÄã‰∏çÂêå‰ªªÂãôÈ°ûÂà•ÁöÑÂúñÂΩ¢ÂΩ±ÂÉèÔºàÂÅµÊ∏¨„ÄÅÂàÜÈ°û„ÄÅÂàÜÂâ≤„ÄÅÊ®°ÂºèËæ®Ë≠ò„ÄÅÈÄ£ÁµêÈ†êÊ∏¨„ÄÅÊé®ÁêÜ„ÄÅÈÖçÂ∞çÔºâÔºåÊó®Âú®Á≥ªÁµ±ÊÄßÂú∞Ë©ï‰º∞ÂÄãÂà• LVLMs ÁöÑÂÑ™ÈªûÂíåÈôêÂà∂„ÄÇÊàëÂÄë‰ΩøÁî® VisGraphVar Áî¢Áîü 990 ÂÄãÂúñÂΩ¢ÂΩ±ÂÉè‰∏¶Ë©ï‰º∞ÂÖ≠ÂÄã LVLMsÔºåÊé°Áî®ÂÖ©Á®Æ‰∏çÂêåÁöÑÊèêÁ§∫Á≠ñÁï•ÔºåÂç≥Èõ∂Ê¨°Â≠∏ÁøíÂíåÊÄùÁ∂≠Èèà„ÄÇÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÂΩ±ÂÉèË¶ñË¶∫Â±¨ÊÄßÁöÑËÆäÂåñÔºà‰æãÂ¶ÇÁØÄÈªûÊ®ôÁ±§ÂíåÁâàÈù¢Ôºâ‰ª•ÂèäË¶ñË¶∫ÁëïÁñµÁöÑÊïÖÊÑèÂä†ÂÖ•Ôºà‰æãÂ¶ÇÈáçÁñäÁØÄÈªûÔºâÊúÉÈ°ØËëóÂΩ±ÈüøÊ®°ÂûãÊïàËÉΩ„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Âº∑Ë™ø‰∫ÜË∑®ÂúñÂΩ¢Áõ∏Èóú‰ªªÂãôÈÄ≤Ë°åÂÖ®Èù¢Ë©ï‰º∞ÁöÑÈáçË¶ÅÊÄßÔºåËÄå‰∏çÂÉÖÈôêÊñºÊé®ÁêÜ„ÄÇVisGraphVar Êèê‰æõ‰∫ÜÂØ∂Ë≤¥ÁöÑË¶ãËß£Ôºå‰ª•ÊåáÂ∞éÊõ¥ÂèØÈù†‰∏îÂº∑Â§ßÁöÑÁ≥ªÁµ±ÁöÑÈñãÁôºÔºåÈÄô‰∫õÁ≥ªÁµ±ËÉΩÂ§†Âü∑Ë°åÈÄ≤ÈöéÁöÑË¶ñË¶∫ÂúñÂΩ¢ÂàÜÊûê„ÄÇ

##### **MolReFlect: Towards In-Context Fine-grained Alignments between Molecules and Texts**
2411.14721v1 by Jiatong Li, Yunqing Liu, Wei Liu, Jingdi Le, Di Zhang, Wenqi Fan, Dongzhan Zhou, Yuqiang Li, Qing Li

Molecule discovery is a pivotal research field, impacting everything from the
medicines we take to the materials we use. Recently, Large Language Models
(LLMs) have been widely adopted in molecule understanding and generation, yet
the alignments between molecules and their corresponding captions remain a
significant challenge. Previous endeavours often treat the molecule as a
general SMILES string or molecular graph, neglecting the fine-grained
alignments between the molecular sub-structures and the descriptive textual
phrases, which are crucial for accurate and explainable predictions. In this
case, we introduce MolReFlect, a novel teacher-student framework designed to
contextually perform the molecule-caption alignments in a fine-grained way. Our
approach initially leverages a larger teacher LLM to label the detailed
alignments by directly extracting critical phrases from molecule captions or
SMILES strings and implying them to corresponding sub-structures or
characteristics. To refine these alignments, we propose In-Context Selective
Reflection, which retrieves previous extraction results as context examples for
teacher LLM to reflect and lets a smaller student LLM select from in-context
reflection and previous extraction results. Finally, we enhance the learning
process of the student LLM through Chain-of-Thought In-Context Molecule Tuning,
integrating the fine-grained alignments and the reasoning processes within the
Chain-of-Thought format. Our experimental results demonstrate that MolReFlect
enables LLMs like Mistral-7B to significantly outperform the previous
baselines, achieving SOTA performance on the ChEBI-20 dataset. This advancement
not only enhances the generative capabilities of LLMs in the molecule-caption
translation task, but also contributes to a more explainable framework.

ÊëòË¶ÅÔºöÂàÜÂ≠êÁôºÁèæÊòØ‰∏ÄÂÄãÈóúÈçµÁöÑÁ†îÁ©∂È†òÂüüÔºåÂæûÊàëÂÄëÊúçÁî®ÁöÑËó•Áâ©Âà∞ÊàëÂÄë‰ΩøÁî®ÁöÑÊùêÊñôÔºåÂΩ±ÈüøËëó‰∏ÄÂàá„ÄÇÊúÄËøëÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âª£Ê≥õÊáâÁî®ÊñºÂàÜÂ≠êÁêÜËß£ÂíåÁîüÊàê‰∏≠Ôºå‰ΩÜÂàÜÂ≠êÂèäÂÖ∂Â∞çÊáâÊ®ôÈ°å‰πãÈñìÁöÑÂ∞çÈΩä‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÊåëÊà∞„ÄÇÂÖàÂâçÁöÑÂä™ÂäõÈÄöÂ∏∏Â∞áÂàÜÂ≠êË¶ñÁÇ∫‰∏ÄËà¨ÁöÑ SMILES Â≠óÁ¨¶‰∏≤ÊàñÂàÜÂ≠êÂúñÔºåÂøΩÁï•‰∫ÜÂàÜÂ≠êÂ≠êÁµêÊßãÂíåÊèèËø∞ÊÄßÊñáÊú¨Áü≠Ë™û‰πãÈñìÁöÑÁ¥∞Á≤íÂ∫¶Â∞çÈΩäÔºåÈÄôÂ∞çÊñºÊ∫ñÁ¢∫‰∏îÂèØËß£ÈáãÁöÑÈ†êÊ∏¨Ëá≥ÈóúÈáçË¶Å„ÄÇÂú®ÈÄôÁ®ÆÊÉÖÊ≥Å‰∏ãÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü MolReFlectÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÂ∏´ÁîüÊ°ÜÊû∂ÔºåÊó®Âú®‰ª•Á¥∞Á≤íÂ∫¶ÁöÑÊñπÂºèÂ∞çÂàÜÂ≠êÊ®ôÈ°åÂ∞çÈΩäÈÄ≤Ë°å‰∏ä‰∏ãÊñáÂü∑Ë°å„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊúÄÂàùÂà©Áî®‰∏ÄÂÄãÊõ¥Â§ßÁöÑÊïôÂ∏´ LLM ‰æÜÊ®ôË®òË©≥Á¥∞Â∞çÈΩäÔºåÊñπÊ≥ïÊòØÁõ¥Êé•ÂæûÂàÜÂ≠êÊ®ôÈ°åÊàñ SMILES Â≠óÁ¨¶‰∏≤‰∏≠ÊèêÂèñÈóúÈçµÁü≠Ë™ûÔºå‰∏¶Â∞áÂÆÉÂÄëÊöóÁ§∫ÁÇ∫Â∞çÊáâÁöÑÂ≠êÁµêÊßãÊàñÁâπÂæµ„ÄÇÁÇ∫‰∫ÜÂÑ™ÂåñÈÄô‰∫õÂ∞çÈΩäÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ä‰∏ãÊñáÈÅ∏ÊìáÊÄßÂèçÂ∞ÑÔºåÂÆÉÂ∞á‰ª•ÂâçÁöÑÊèêÂèñÁµêÊûú‰ΩúÁÇ∫‰∏ä‰∏ãÊñáÁØÑ‰æãÔºå‰æõÊïôÂ∏´ LLM ÈÄ≤Ë°åÂèçÂ∞ÑÔºå‰∏¶ËÆì‰∏ÄÂÄãËºÉÂ∞èÁöÑÂ≠∏Áîü LLM Âæû‰∏ä‰∏ãÊñáÂèçÂ∞ÑÂíå‰ª•ÂâçÁöÑÊèêÂèñÁµêÊûú‰∏≠ÈÄ≤Ë°åÈÅ∏Êìá„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈÄöÈÅéÊÄùÊÉ≥Èèà‰∏ä‰∏ãÊñáÂàÜÂ≠êË™øÊï¥Â¢ûÂº∑‰∫ÜÂ≠∏Áîü LLM ÁöÑÂ≠∏ÁøíÈÅéÁ®ãÔºåÂ∞áÁ¥∞Á≤íÂ∫¶Â∞çÈΩäÂíåÊé®ÁêÜÈÅéÁ®ãÊï¥ÂêàÂà∞ÊÄùÊÉ≥ÈèàÊ†ºÂºè‰∏≠„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåMolReFlect ‰ΩøÂÉè Mistral-7B ÈÄôÊ®£ÁöÑ LLM ËÉΩÂ§†È°ØËëóÂÑ™ÊñºÂÖàÂâçÁöÑÂü∫Ê∫ñÔºåÂú® ChEBI-20 Êï∏ÊìöÈõÜ‰∏äÂØ¶Áèæ‰∫Ü SOTA ÊÄßËÉΩ„ÄÇÈÄô‰∏ÄÈÄ≤Ê≠•‰∏çÂÉÖÂ¢ûÂº∑‰∫Ü LLM Âú®ÂàÜÂ≠êÊ®ôÈ°åÁøªË≠Ø‰ªªÂãô‰∏≠ÁöÑÁîüÊàêËÉΩÂäõÔºåËÄå‰∏îÈÇÑÊúâÂä©ÊñºÂª∫Á´ã‰∏ÄÂÄãÊõ¥ÂÖ∑ÂèØËß£ÈáãÊÄßÁöÑÊ°ÜÊû∂„ÄÇ

##### **G-RAG: Knowledge Expansion in Material Science**
2411.14592v1 by Radeen Mostafa, Mirza Nihal Baig, Mashaekh Tausif Ehsan, Jakir Hasan

In the field of Material Science, effective information retrieval systems are
essential for facilitating research. Traditional Retrieval-Augmented Generation
(RAG) approaches in Large Language Models (LLMs) often encounter challenges
such as outdated information, hallucinations, limited interpretability due to
context constraints, and inaccurate retrieval. To address these issues, Graph
RAG integrates graph databases to enhance the retrieval process. Our proposed
method processes Material Science documents by extracting key entities
(referred to as MatIDs) from sentences, which are then utilized to query
external Wikipedia knowledge bases (KBs) for additional relevant information.
We implement an agent-based parsing technique to achieve a more detailed
representation of the documents. Our improved version of Graph RAG called G-RAG
further leverages a graph database to capture relationships between these
entities, improving both retrieval accuracy and contextual understanding. This
enhanced approach demonstrates significant improvements in performance for
domains that require precise information retrieval, such as Material Science.

ÊëòË¶ÅÔºöÂú®ÊùêÊñôÁßëÂ≠∏È†òÂüü‰∏≠ÔºåÊúâÊïàÁöÑË≥áË®äÊ™¢Á¥¢Á≥ªÁµ±Â∞çÊñº‰øÉÈÄ≤Á†îÁ©∂Ëá≥ÈóúÈáçË¶Å„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠ÁöÑÂÇ≥Áµ±Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÊñπÊ≥ïÁ∂ìÂ∏∏ÊúÉÈÅáÂà∞Ë´∏Â¶ÇË≥áË®äÈÅéÊôÇ„ÄÅÂπªË¶∫„ÄÅÁî±ÊñºËÑàÁµ°ÈôêÂà∂ËÄåÂ∞éËá¥ÁöÑÂèØËß£ÈáãÊÄßÊúâÈôê‰ª•ÂèäÊ™¢Á¥¢‰∏çÊ∫ñÁ¢∫Á≠âÊåëÊà∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåGraph RAG Êï¥ÂêàÂúñÂΩ¢Ë≥áÊñôÂ∫´‰ª•Â¢ûÂº∑Ê™¢Á¥¢ÈÅéÁ®ã„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÈÄèÈÅéÂæûÂè•Â≠ê‰∏≠ËêÉÂèñÈóúÈçµÂØ¶È´îÔºàÁ®±ÁÇ∫ MatIDÔºâ‰æÜËôïÁêÜÊùêÊñôÁßëÂ≠∏Êñá‰ª∂ÔºåÁÑ∂ÂæåÂà©Áî®ÈÄô‰∫õÂØ¶È´îÊü•Ë©¢Â§ñÈÉ®ÁöÑÁ∂≠Âü∫ÁôæÁßëÁü•Ë≠òÂ∫´ (KB) ‰ª•ÂèñÂæóÂÖ∂‰ªñÁõ∏ÈóúË≥áË®ä„ÄÇÊàëÂÄëÂØ¶‰Ωú‰∫Ü‰∏ÄÁ®ÆÂü∫Êñº‰ª£ÁêÜÁöÑËß£ÊûêÊäÄË°ìÔºå‰ª•ÈÅîÊàêÊõ¥Ë©≥Á¥∞ÁöÑÊñá‰ª∂Ë°®Á§∫„ÄÇÊàëÂÄëÊîπËâØÁöÑ Graph RAG ÁâàÊú¨Á®±ÁÇ∫ G-RAGÔºåÈÄ≤‰∏ÄÊ≠•Âà©Áî®ÂúñÂΩ¢Ë≥áÊñôÂ∫´‰æÜÊì∑ÂèñÈÄô‰∫õÂØ¶È´î‰πãÈñìÁöÑÈóú‰øÇÔºåÈÄ≤ËÄåÊîπÂñÑÊ™¢Á¥¢Ê∫ñÁ¢∫Â∫¶ÂíåËÑàÁµ°ÁêÜËß£„ÄÇÊ≠§Â¢ûÂº∑ÁöÑÊñπÊ≥ïÂ∞çÊñºÈúÄË¶ÅÁ≤æÁ¢∫Ë≥áË®äÊ™¢Á¥¢ÁöÑÈ†òÂüüÔºà‰æãÂ¶ÇÊùêÊñôÁßëÂ≠∏ÔºâÂ±ïÁèæÂá∫È°ØËëóÁöÑÊïàËÉΩÊèêÂçá„ÄÇ

##### **Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective**
2411.14258v1 by Ernests Lavrinovics, Russa Biswas, Johannes Bjerva, Katja Hose

Large Language Models (LLMs) have revolutionized Natural Language Processing
(NLP) based applications including automated text generation, question
answering, chatbots, and others. However, they face a significant challenge:
hallucinations, where models produce plausible-sounding but factually incorrect
responses. This undermines trust and limits the applicability of LLMs in
different domains. Knowledge Graphs (KGs), on the other hand, provide a
structured collection of interconnected facts represented as entities (nodes)
and their relationships (edges). In recent research, KGs have been leveraged to
provide context that can fill gaps in an LLM understanding of certain topics
offering a promising approach to mitigate hallucinations in LLMs, enhancing
their reliability and accuracy while benefiting from their wide applicability.
Nonetheless, it is still a very active area of research with various unresolved
open problems. In this paper, we discuss these open challenges covering
state-of-the-art datasets and benchmarks as well as methods for knowledge
integration and evaluating hallucinations. In our discussion, we consider the
current use of KGs in LLM systems and identify future directions within each of
these challenges.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂæπÂ∫ïÊîπËÆä‰∫ÜÂü∫ÊñºËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÔºàNLPÔºâÁöÑÊáâÁî®ÔºåÂåÖÊã¨Ëá™ÂãïÊñáÂ≠óÁîüÊàê„ÄÅÂïèÈ°åËß£Á≠î„ÄÅËÅäÂ§©Ê©üÂô®‰∫∫Á≠â„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÈù¢Ëá®Ëëó‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞ÔºöÂπªË¶∫ÔºåÊ®°ÂûãÁî¢ÁîüËÅΩËµ∑‰æÜÂêàÁêÜ‰ΩÜ‰∫ãÂØ¶‰∏ä‰∏çÊ≠£Á¢∫ÁöÑÂõûÊáâ„ÄÇÈÄôÊúÉÁ†¥Â£û‰ø°‰ªªÔºå‰∏¶ÈôêÂà∂ LLM Âú®‰∏çÂêåÈ†òÂüüÁöÑÈÅ©Áî®ÊÄß„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÁü•Ë≠òÂúñË≠úÔºàKGÔºâÊèê‰æõ‰∫Ü‰ª•ÂØ¶È´îÔºàÁØÄÈªûÔºâÂèäÂÖ∂Èóú‰øÇÔºàÈÇäÁ∑£ÔºâË°®Á§∫ÁöÑÁõ∏‰∫íÈÄ£Êé•‰∫ãÂØ¶ÁöÑÁµêÊßãÂåñÈõÜÂêà„ÄÇÂú®ÊúÄËøëÁöÑÁ†îÁ©∂‰∏≠ÔºåKG Â∑≤Ë¢´Áî®ÊñºÊèê‰æõ‰∏ä‰∏ãÊñáÔºåÂèØ‰ª•Â°´Ë£ú LLM Â∞çÊüê‰∫õ‰∏ªÈ°åÁêÜËß£ÁöÑÁ©∫ÁôΩÔºåÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊúâÂ∏åÊúõÁöÑÊñπÊ≥ï‰æÜÊ∏õËºï LLM ‰∏≠ÁöÑÂπªË¶∫ÔºåÊèêÈ´òÂÆÉÂÄëÁöÑÂèØÈù†ÊÄßÂíåÊ∫ñÁ¢∫ÊÄßÔºåÂêåÊôÇÂèóÁõäÊñºÂÆÉÂÄëÁöÑÂª£Ê≥õÈÅ©Áî®ÊÄß„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÈÄô‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÈùûÂ∏∏Ê¥ªË∫çÁöÑÁ†îÁ©∂È†òÂüüÔºåÊúâÂêÑÁ®ÆÊú™Ëß£Ê±∫ÁöÑÈñãÊîæÂïèÈ°å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëË®éË´ñ‰∫ÜÈÄô‰∫õÈñãÊîæÊåëÊà∞ÔºåÊ∂µËìã‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊï∏ÊìöÈõÜÂíåÂü∫Ê∫ñÔºå‰ª•ÂèäÁü•Ë≠òÊï¥ÂêàÂíåË©ï‰º∞ÂπªË¶∫ÁöÑÊñπÊ≥ï„ÄÇÂú®ÊàëÂÄëÁöÑË®éË´ñ‰∏≠ÔºåÊàëÂÄëËÄÉÊÖÆ‰∫Ü LLM Á≥ªÁµ±‰∏≠ KG ÁöÑÁï∂Ââç‰ΩøÁî®Ôºå‰∏¶Á¢∫ÂÆö‰∫ÜÈÄô‰∫õÊåëÊà∞‰∏≠ÁöÑÊØè‰∏ÄÂÄãÊú™‰æÜÁöÑÊñπÂêë„ÄÇ

##### **Logic Augmented Generation**
2411.14012v1 by Aldo Gangemi, Andrea Giovanni Nuzzolese

Semantic Knowledge Graphs (SKG) face challenges with scalability,
flexibility, contextual understanding, and handling unstructured or ambiguous
information. However, they offer formal and structured knowledge enabling
highly interpretable and reliable results by means of reasoning and querying.
Large Language Models (LLMs) overcome those limitations making them suitable in
open-ended tasks and unstructured environments. Nevertheless, LLMs are neither
interpretable nor reliable. To solve the dichotomy between LLMs and SKGs we
envision Logic Augmented Generation (LAG) that combines the benefits of the two
worlds. LAG uses LLMs as Reactive Continuous Knowledge Graphs that can generate
potentially infinite relations and tacit knowledge on-demand. SKGs are key for
injecting a discrete heuristic dimension with clear logical and factual
boundaries. We exemplify LAG in two tasks of collective intelligence, i.e.,
medical diagnostics and climate projections. Understanding the properties and
limitations of LAG, which are still mostly unknown, is of utmost importance for
enabling a variety of tasks involving tacit knowledge in order to provide
interpretable and effective results.

ÊëòË¶ÅÔºöË™ûÊÑèÁü•Ë≠òÂúñÔºàSKGÔºâÂú®ÂèØÊì¥ÂÖÖÊÄß„ÄÅÈùàÊ¥ªÊÄß„ÄÅÊÉÖÂ¢ÉÁêÜËß£‰ª•ÂèäËôïÁêÜÈùûÁµêÊßãÂåñÊàñÂê´Á≥äË≥áË®äÊñπÈù¢Èù¢Ëá®ÊåëÊà∞„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÊèê‰æõÊ≠£Âºè‰∏îÁµêÊßãÂåñÁöÑÁü•Ë≠òÔºåËÉΩÈÄèÈÅéÊé®ÁêÜÂíåÊü•Ë©¢Êèê‰æõÈ´òÂ∫¶ÂèØËß£Èáã‰∏îÂèØÈù†ÁöÑÁµêÊûú„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂÖãÊúç‰∫ÜÈÄô‰∫õÈôêÂà∂Ôºå‰ΩøÂÖ∂ÈÅ©Áî®ÊñºÈñãÊîæÂºè‰ªªÂãôÂíåÈùûÁµêÊßãÂåñÁí∞Â¢É„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåLLM Êó¢‰∏çÂèØËß£Èáã‰πü‰∏çÂèØÈù†„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ LLM Âíå SKG ‰πãÈñìÁöÑ‰∫åÂàÜÊ≥ïÔºåÊàëÂÄëË®≠ÊÉ≥‰∫ÜÈÇèËºØÂ¢ûÂº∑ÁîüÊàêÔºàLAGÔºâÔºåÂÆÉÁµêÂêà‰∫ÜÂÖ©ÂÄã‰∏ñÁïåÁöÑÂÑ™Èªû„ÄÇLAG ‰ΩøÁî® LLM ‰ΩúÁÇ∫ÂèçÊáâÂºèÈÄ£Á∫åÁü•Ë≠òÂúñÔºåÂÆÉÂèØ‰ª•ÊåâÈúÄÁî¢ÁîüÊΩõÂú®ÁöÑÁÑ°ÈôêÈóú‰øÇÂíåÈªòÊúÉÁü•Ë≠ò„ÄÇSKG ÊòØÊ≥®ÂÖ•Èõ¢Êï£ÂïüÁôºÂºèÁ∂≠Â∫¶ÔºàÂÖ∑ÊúâÊòéÁ¢∫ÈÇèËºØÂíå‰∫ãÂØ¶ÈÇäÁïåÔºâÁöÑÈóúÈçµ„ÄÇÊàëÂÄëÂú®ÈõÜÈ´îÊô∫ÊÖßÁöÑÂÖ©ÂÄã‰ªªÂãô‰∏≠Ëàâ‰æãË™™Êòé LAGÔºåÂç≥ÈÜ´ÁôÇË®∫Êñ∑ÂíåÊ∞£ÂÄôÈ†êÊ∏¨„ÄÇÁêÜËß£ LAG ÁöÑÁâπÊÄßÂíåÈôêÂà∂ÔºàÁõÆÂâç‰ªçÁÑ∂Â§ßÂ§öÊï∏Êú™Áü•ÔºâÂ∞çÊñºÂïüÁî®Ê∂âÂèäÈªòÊúÉÁü•Ë≠òÁöÑÂêÑÁ®Æ‰ªªÂãô‰ª•Êèê‰æõÂèØËß£Èáã‰∏îÊúâÊïàÁöÑÁµêÊûúËá≥ÈóúÈáçË¶Å„ÄÇ

##### **FastRAG: Retrieval Augmented Generation for Semi-structured Data**
2411.13773v1 by Amar Abane, Anis Bekri, Abdella Battou

Efficiently processing and interpreting network data is critical for the
operation of increasingly complex networks. Recent advances in Large Language
Models (LLM) and Retrieval-Augmented Generation (RAG) techniques have improved
data processing in network management. However, existing RAG methods like
VectorRAG and GraphRAG struggle with the complexity and implicit nature of
semi-structured technical data, leading to inefficiencies in time, cost, and
retrieval. This paper introduces FastRAG, a novel RAG approach designed for
semi-structured data. FastRAG employs schema learning and script learning to
extract and structure data without needing to submit entire data sources to an
LLM. It integrates text search with knowledge graph (KG) querying to improve
accuracy in retrieving context-rich information. Evaluation results demonstrate
that FastRAG provides accurate question answering, while improving up to 90% in
time and 85% in cost compared to GraphRAG.

ÊëòË¶ÅÔºöÊúâÊïàÁéáÂú∞ËôïÁêÜÂíåËß£ËÆÄÁ∂≤Ë∑ØË≥áÊñôÂ∞çÊñºÊó•ÁõäË§áÈõúÁöÑÁ∂≤Ë∑ØÊìç‰ΩúËá≥ÈóúÈáçË¶Å„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÊ™¢Á¥¢Â¢ûÂº∑Áî¢Áîü (RAG) ÊäÄË°ìÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂ∑≤Á∂ìÊîπÂñÑ‰∫ÜÁ∂≤Ë∑ØÁÆ°ÁêÜ‰∏≠ÁöÑË≥áÊñôËôïÁêÜ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑ RAG ÊñπÊ≥ïÔºà‰æãÂ¶Ç VectorRAG Âíå GraphRAGÔºâÈõ£‰ª•Êáâ‰ªòÂçäÁµêÊßãÂåñÊäÄË°ìË≥áÊñôÁöÑË§áÈõúÊÄßÂíåÈö±Âê´ÊÄßË≥™ÔºåÂ∞éËá¥ÊôÇÈñì„ÄÅÊàêÊú¨ÂíåÊ™¢Á¥¢ÊïàÁéá‰∏çÂΩ∞„ÄÇÊú¨Êñá‰ªãÁ¥π FastRAGÔºå‰∏ÄÁ®ÆÂ∞àÁÇ∫ÂçäÁµêÊßãÂåñË≥áÊñôË®≠Ë®àÁöÑÊñ∞Á©é RAG ÊñπÊ≥ï„ÄÇFastRAG ‰ΩøÁî®Êû∂ÊßãÂ≠∏ÁøíÂíåËÖ≥Êú¨Â≠∏Áøí‰æÜËêÉÂèñÂíåÂª∫ÊßãË≥áÊñôÔºåËÄåÁÑ°ÈúÄÂ∞áÊï¥ÂÄãË≥áÊñô‰æÜÊ∫êÊèê‰∫§Áµ¶ LLM„ÄÇÂÆÉÂ∞áÊñáÂ≠óÊêúÂ∞ãËàáÁü•Ë≠òÂúñË≠ú (KG) Êü•Ë©¢Êï¥ÂêàÔºå‰ª•ÊèêÈ´òÊ™¢Á¥¢ÂÖßÂÆπË±êÂØåË≥áË®äÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇË©ï‰º∞ÁµêÊûúË≠âÊòéÔºåFastRAG Êèê‰æõ‰∫ÜÊ∫ñÁ¢∫ÁöÑÂïèÁ≠îÔºåÂêåÊôÇËàá GraphRAG Áõ∏ÊØîÔºåÊôÇÈñìÊîπÂñÑ‰∫Ü 90%ÔºåÊàêÊú¨ÊîπÂñÑ‰∫Ü 85%„ÄÇ

##### **Predictive Insights into LGBTQ+ Minority Stress: A Transductive Exploration of Social Media Discourse**
2411.13534v1 by S. Chapagain, Y. Zhao, T. K. Rohleen, S. M. Hamdi, S. F. Boubrahimi, R. E. Flinn, E. M. Lund, D. Klooster, J. R. Scheer, C. J. Cascalheira

Individuals who identify as sexual and gender minorities, including lesbian,
gay, bisexual, transgender, queer, and others (LGBTQ+) are more likely to
experience poorer health than their heterosexual and cisgender counterparts.
One primary source that drives these health disparities is minority stress
(i.e., chronic and social stressors unique to LGBTQ+ communities' experiences
adapting to the dominant culture). This stress is frequently expressed in
LGBTQ+ users' posts on social media platforms. However, these expressions are
not just straightforward manifestations of minority stress. They involve
linguistic complexity (e.g., idiom or lexical diversity), rendering them
challenging for many traditional natural language processing methods to detect.
In this work, we designed a hybrid model using Graph Neural Networks (GNN) and
Bidirectional Encoder Representations from Transformers (BERT), a pre-trained
deep language model to improve the classification performance of minority
stress detection. We experimented with our model on a benchmark social media
dataset for minority stress detection (LGBTQ+ MiSSoM+). The dataset is
comprised of 5,789 human-annotated Reddit posts from LGBTQ+ subreddits. Our
approach enables the extraction of hidden linguistic nuances through
pretraining on a vast amount of raw data, while also engaging in transductive
learning to jointly develop representations for both labeled training data and
unlabeled test data. The RoBERTa-GCN model achieved an accuracy of 0.86 and an
F1 score of 0.86, surpassing the performance of other baseline models in
predicting LGBTQ+ minority stress. Improved prediction of minority stress
expressions on social media could lead to digital health interventions to
improve the wellbeing of LGBTQ+ people-a community with high rates of
stress-sensitive health problems.

ÊëòË¶ÅÔºö<paragraph>Ë™çÂêåËá™Â∑±ÊòØÊÄßËàáÊÄßÂà•Â∞ëÊï∏ÊóèÁæ§ÁöÑ‰∫∫ÔºåÂåÖÊã¨Â•≥ÂêåÊÄßÊàÄ„ÄÅÁî∑ÂêåÊÄßÊàÄ„ÄÅÈõôÊÄßÊàÄ„ÄÅË∑®ÊÄßÂà•„ÄÅÈÖ∑ÂÖíÂíåÂÖ∂‰ªñ LGBTQ+ ÊóèÁæ§ÔºåÊØîÁï∞ÊÄßÊàÄÂíåÈ†ÜÊÄßÂà•ËÄÖÊõ¥ÂÆπÊòìÊúâËºÉÂ∑ÆÁöÑÂÅ•Â∫∑ÁãÄÊ≥Å„ÄÇÈÄ†ÊàêÈÄô‰∫õÂÅ•Â∫∑Â∑ÆÁï∞ÁöÑ‰∏ªË¶Å‰æÜÊ∫ê‰πã‰∏ÄÊòØÂ∞ëÊï∏ÊóèÁæ§Â£ìÂäõÔºàÂç≥ LGBTQ+ Á§æÁæ§Âú®ÈÅ©Êáâ‰∏ªÊµÅÊñáÂåñÊôÇÁç®ÊúâÁöÑÊÖ¢ÊÄßËàáÁ§æÊúÉÂ£ìÂäõÔºâ„ÄÇÈÄôÁ®ÆÂ£ìÂäõÁ∂ìÂ∏∏Âú® LGBTQ+ ‰ΩøÁî®ËÄÖÊñºÁ§æÁæ§Â™íÈ´îÂπ≥Âè∞‰∏äÁöÑË≤ºÊñá‰∏≠Ë°®ÈÅîÂá∫‰æÜ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õË°®ÈÅî‰∏¶‰∏çÂÉÖÂÉÖÊòØÂ∞ëÊï∏ÊóèÁæ§Â£ìÂäõÁöÑÁõ¥Êé•Ë°®Áèæ„ÄÇÂÆÉÂÄëÂåÖÂê´‰∫ÜË™ûË®ÄË§áÈõúÊÄßÔºà‰æãÂ¶ÇÊÖ£Áî®Ë™ûÊàñË©ûÂΩôÂ§öÊ®£ÊÄßÔºâÔºåËÆìË®±Â§öÂÇ≥Áµ±ÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÊñπÊ≥ïÈõ£‰ª•Ëæ®Ë≠ò„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÊ∑∑ÂêàÊ®°ÂûãÔºå‰ΩøÁî®ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) Âíå‰æÜËá™ Transformer ÁöÑÈõôÂêëÁ∑®Á¢ºÂô®Ë°®Âæµ (BERT)ÔºåÈÄôÊòØ‰∏ÄÂÄãÁ∂ìÈÅéÈ†êÂÖàË®ìÁ∑¥ÁöÑÊ∑±Â∫¶Ë™ûË®ÄÊ®°ÂûãÔºå‰ª•ÊèêÂçáÂ∞ëÊï∏ÊóèÁæ§Â£ìÂäõËæ®Ë≠òÁöÑÂàÜÈ°ûÊïàËÉΩ„ÄÇÊàëÂÄëÂú®‰∏ÄÂÄãÁî®ÊñºÂ∞ëÊï∏ÊóèÁæ§Â£ìÂäõËæ®Ë≠òÁöÑÂü∫Ê∫ñÁ§æÁæ§Â™íÈ´îË≥áÊñôÈõÜ (LGBTQ+ MiSSoM+) ‰∏äÂ∞çÊàëÂÄëÁöÑÊ®°ÂûãÈÄ≤Ë°åÂØ¶È©ó„ÄÇË©≤Ë≥áÊñôÈõÜÂåÖÂê´‰∫Ü 5,789 ÁØáÁî±‰∫∫È°ûË®ªËß£ÁöÑ Reddit Ë≤ºÊñáÔºå‰æÜËá™Êñº LGBTQ+ ÁöÑ subreddit„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïËÉΩÂ§†ÈÄèÈÅéÂú®Â§ßÈáèÁöÑÂéüÂßãË≥áÊñô‰∏äÈÄ≤Ë°åÈ†êË®ìÁ∑¥‰æÜËêÉÂèñÈö±ËóèÁöÑË™ûË®ÄÂ∑ÆÁï∞ÔºåÂêåÊôÇ‰πüÂèÉËàáËΩâÂ∞éÂºèÂ≠∏ÁøíÔºå‰ª•ÂÖ±ÂêåÈñãÁôºÊ®ôÁ±§Ë®ìÁ∑¥Ë≥áÊñôÂíåÊú™Ê®ôÁ±§Ê∏¨Ë©¶Ë≥áÊñôÁöÑË°®Âæµ„ÄÇRoBERTa-GCN Ê®°ÂûãÈÅîÂà∞‰∫Ü 0.86 ÁöÑÊ∫ñÁ¢∫ÁéáÂíå 0.86 ÁöÑ F1 ÂàÜÊï∏ÔºåÂú®È†êÊ∏¨ LGBTQ+ Â∞ëÊï∏ÊóèÁæ§Â£ìÂäõÊñπÈù¢Ë∂ÖË∂ä‰∫ÜÂÖ∂‰ªñÂü∫Á∑öÊ®°ÂûãÁöÑÊïàËÉΩ„ÄÇÂú®Á§æÁæ§Â™íÈ´î‰∏äÂ∞çÂ∞ëÊï∏ÊóèÁæ§Â£ìÂäõË°®ÈÅîÁöÑÈ†êÊ∏¨ÊîπÂñÑÔºåÂèØ‰ª•Â∞éËá¥Êï∏‰ΩçÂÅ•Â∫∑‰ªãÂÖ•Êé™ÊñΩÔºå‰ª•ÊîπÂñÑ LGBTQ+ ÊóèÁæ§ÁöÑÁ¶èÁ•âÔºåËÄåÈÄôÂÄãÊóèÁæ§ÊúâÂæàÈ´òÁöÑÂ£ìÂäõÊïèÊÑüÊÄßÂÅ•Â∫∑ÂïèÈ°åÁôºÁîüÁéá„ÄÇ</paragraph>

##### **KAAE: Numerical Reasoning for Knowledge Graphs via Knowledge-aware Attributes Learning**
2411.12950v2 by Ming Yin, Qiang Zhou, Zongsheng Cao, Mei Li

Numerical reasoning is pivotal in various artificial intelligence
applications, such as natural language processing and recommender systems,
where it involves using entities, relations, and attribute values (e.g.,
weight, length) to infer new factual relations (e.g., the Nile is longer than
the Amazon). However, existing approaches encounter two critical challenges in
modeling: (1) semantic relevance-the challenge of insufficiently capturing the
necessary contextual interactions among entities, relations, and numerical
attributes, often resulting in suboptimal inference; and (2) semantic
ambiguity-the difficulty in accurately distinguishing ordinal relationships
during numerical reasoning, which compromises the generation of high-quality
samples and limits the effectiveness of contrastive learning. To address these
challenges, we propose the novel Knowledge-Aware Attributes Embedding model
(KAAE) for knowledge graph embeddings in numerical reasoning. Specifically, to
overcome the challenge of semantic relevance, we introduce a
Mixture-of-Experts-Knowledge-Aware (MoEKA) Encoder, designed to integrate the
semantics of entities, relations, and numerical attributes into a joint
semantic space. To tackle semantic ambiguity, we implement a new ordinal
knowledge contrastive learning (OKCL) strategy that generates high-quality
ordinal samples from the original data with the aid of ordinal relations,
capturing fine-grained semantic nuances essential for accurate numerical
reasoning. Experiments on three public benchmark datasets demonstrate the
superior performance of KAAE across various attribute value distributions.

ÊëòË¶ÅÔºöÊï∏ÂÄºÊé®ÁêÜÂú®ÂêÑÁ®Æ‰∫∫Â∑•Êô∫ÊÖßÊáâÁî®‰∏≠Ëá≥ÈóúÈáçË¶ÅÔºå‰æãÂ¶ÇËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÂíåÊé®Ëñ¶Á≥ªÁµ±ÔºåÂÖ∂‰∏≠Ê∂âÂèä‰ΩøÁî®ÂØ¶È´î„ÄÅÈóú‰øÇÂíåÂ±¨ÊÄßÂÄºÔºà‰æãÂ¶ÇÔºåÈáçÈáè„ÄÅÈï∑Â∫¶Ôºâ‰æÜÊé®Ë´ñÊñ∞ÁöÑ‰∫ãÂØ¶Èóú‰øÇÔºà‰æãÂ¶ÇÔºåÂ∞ºÁæÖÊ≤≥ÊØî‰∫ûÈ¶¨ÈÅúÊ≤≥Èï∑Ôºâ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÊñπÊ≥ïÂú®Âª∫Ê®°‰∏≠ÈÅáÂà∞ÂÖ©ÂÄãÈóúÈçµÊåëÊà∞ÔºöÔºà1ÔºâË™ûÁæ©Áõ∏ÈóúÊÄß - ÁÑ°Ê≥ïÂÖÖÂàÜÊçïÊçâÂØ¶È´î„ÄÅÈóú‰øÇÂíåÊï∏ÂÄºÂ±¨ÊÄß‰πãÈñìÂøÖË¶ÅÁöÑ‰∏ä‰∏ãÊñá‰∫§‰∫íÁöÑÊåëÊà∞ÔºåÈÄöÂ∏∏Â∞éËá¥Ê¨°ÂÑ™Êé®ÁêÜÔºõ‰ª•ÂèäÔºà2ÔºâË™ûÁæ©Ê≠ßÁæ© - Âú®Êï∏ÂÄºÊé®ÁêÜÊúüÈñìÊ∫ñÁ¢∫ÂçÄÂàÜÂ∫èÊï∏Èóú‰øÇÁöÑÈõ£Â∫¶ÔºåÈÄôÊúÉÊêçÂÆ≥È´òÂìÅË≥™Ê®£Êú¨ÁöÑÁî¢Áîü‰∏¶ÈôêÂà∂Â∞çÊØîÂ≠∏ÁøíÁöÑÊúâÊïàÊÄß„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÁî®ÊñºÊï∏ÂÄºÊé®ÁêÜÁöÑÁü•Ë≠òÂúñË≠úÂµåÂÖ•ÁöÑÊñ∞ÂûãÁü•Ë≠òÊÑüÁü•Â±¨ÊÄßÂµåÂÖ•Ê®°Âûã (KAAE)„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÁÇ∫‰∫ÜÂÖãÊúçË™ûÁæ©Áõ∏ÈóúÊÄßÁöÑÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊ∑∑ÂêàÂ∞àÂÆ∂Áü•Ë≠òÊÑüÁü• (MoEKA) Á∑®Á¢ºÂô®ÔºåÊó®Âú®Â∞áÂØ¶È´î„ÄÅÈóú‰øÇÂíåÊï∏ÂÄºÂ±¨ÊÄßÁöÑË™ûÁæ©Êï¥ÂêàÂà∞‰∏ÄÂÄãËÅØÂêàË™ûÁæ©Á©∫Èñì‰∏≠„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çË™ûÁæ©Ê≠ßÁæ©ÔºåÊàëÂÄëÂØ¶ÊñΩ‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÂ∫èÊï∏Áü•Ë≠òÂ∞çÊØîÂ≠∏Áøí (OKCL) Á≠ñÁï•ÔºåË©≤Á≠ñÁï•Âà©Áî®Â∫èÊï∏Èóú‰øÇÂæûÂéüÂßãÊï∏Êìö‰∏≠ÁîüÊàêÈ´òÂìÅË≥™Â∫èÊï∏Ê®£Êú¨ÔºåÊçïÊçâÂ∞çÊ∫ñÁ¢∫Êï∏ÂÄºÊé®ÁêÜËá≥ÈóúÈáçË¶ÅÁöÑÁ¥∞Á∑ªË™ûÁæ©Â∑ÆÁï∞„ÄÇÂú®‰∏âÂÄãÂÖ¨ÈñãÂü∫Ê∫ñÊï∏ÊìöÈõÜ‰∏äÁöÑÂØ¶È©óË≠âÊòé‰∫Ü KAAE Âú®ÂêÑÁ®ÆÂ±¨ÊÄßÂÄºÂàÜ‰Ωà‰∏≠ÁöÑÂÑ™Áï∞ÊÄßËÉΩ„ÄÇ

##### **Neurosymbolic Graph Enrichment for Grounded World Models**
2411.12671v1 by Stefano De Giorgis, Aldo Gangemi, Alessandro Russo

The development of artificial intelligence systems capable of understanding
and reasoning about complex real-world scenarios is a significant challenge. In
this work we present a novel approach to enhance and exploit LLM reactive
capability to address complex problems and interpret deeply contextual
real-world meaning. We introduce a method and a tool for creating a multimodal,
knowledge-augmented formal representation of meaning that combines the
strengths of large language models with structured semantic representations.
Our method begins with an image input, utilizing state-of-the-art large
language models to generate a natural language description. This description is
then transformed into an Abstract Meaning Representation (AMR) graph, which is
formalized and enriched with logical design patterns, and layered semantics
derived from linguistic and factual knowledge bases. The resulting graph is
then fed back into the LLM to be extended with implicit knowledge activated by
complex heuristic learning, including semantic implicatures, moral values,
embodied cognition, and metaphorical representations. By bridging the gap
between unstructured language models and formal semantic structures, our method
opens new avenues for tackling intricate problems in natural language
understanding and reasoning.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁµ±ÁöÑÁôºÂ±ïËÉΩÂ§†ÁêÜËß£‰∏¶Êé®ÁêÜË§áÈõúÁöÑÁúüÂØ¶‰∏ñÁïåÂ†¥ÊôØÊòØ‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ï‰æÜÂ¢ûÂº∑ÂíåÂà©Áî® LLM ÂèçÊáâËÉΩÂäõÔºå‰ª•Ëß£Ê±∫Ë§áÈõúÁöÑÂïèÈ°å‰∏¶Ëß£ÈáãÊ∑±Â±§ÁöÑË™ûÂ¢ÉÁúüÂØ¶‰∏ñÁïåÊÑèÁæ©„ÄÇÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÂíåÂ∑•ÂÖ∑ÔºåÁî®ÊñºÂª∫Á´ãÂ§öÊ®°ÊÖã„ÄÅÁü•Ë≠òÂ¢ûÂº∑ÁöÑÊÑèÁæ©ÂΩ¢ÂºèÂåñË°®Á§∫ÔºåÁµêÂêà‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°ÂûãËàáÁµêÊßãÂåñË™ûÁæ©Ë°®Á§∫ÁöÑÂÑ™Èªû„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂæûÂΩ±ÂÉèËº∏ÂÖ•ÈñãÂßãÔºåÂà©Áî®ÊúÄÂÖàÈÄ≤ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã‰æÜÁî¢ÁîüËá™ÁÑ∂Ë™ûË®ÄÊèèËø∞„ÄÇÁÑ∂ÂæåÂ∞áÊ≠§ÊèèËø∞ËΩâÊèõÁÇ∫ÊäΩË±°ÊÑèÁæ©Ë°®Á§∫ (AMR) ÂúñÂΩ¢Ôºå‰∏¶‰ΩøÁî®ÈÇèËºØË®≠Ë®àÊ®°ÂºèÈÄ≤Ë°åÂΩ¢ÂºèÂåñÂíåË±êÂØåÔºå‰ª•ÂèäÂæûË™ûË®ÄÂíå‰∫ãÂØ¶Áü•Ë≠òÂ∫´‰∏≠Ë°çÁîüÁöÑÂàÜÂ±§Ë™ûÁæ©„ÄÇÁÑ∂ÂæåÂ∞áÁµêÊûúÂúñÂΩ¢ÂõûÈ•ãÂà∞ LLMÔºå‰ª•Êì¥ÂÖÖ LLM ‰∏≠Áî±Ë§áÈõúÁöÑÂïüÁôºÂºèÂ≠∏ÁøíÊâÄÂïüÁî®ÁöÑÂÖßÈö±Áü•Ë≠òÔºåÂåÖÊã¨Ë™ûÁæ©ËòäÊ∂µ„ÄÅÈÅìÂæ∑ÂÉπÂÄº„ÄÅÂÖ∑Ë∫´Ë™çÁü•ÂíåÈö±ÂñªË°®Á§∫„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÈÄèÈÅéÂΩåÂêàÈùûÁµêÊßãÂåñË™ûË®ÄÊ®°ÂûãËàáÂΩ¢ÂºèË™ûÁæ©ÁµêÊßã‰πãÈñìÁöÑÂ∑ÆË∑ùÔºåÁÇ∫Ëß£Ê±∫Ëá™ÁÑ∂Ë™ûË®ÄÁêÜËß£ÂíåÊé®ÁêÜ‰∏≠ÁöÑË§áÈõúÂïèÈ°åÈñãÈó¢‰∫ÜÊñ∞ÁöÑÈÄîÂæë„ÄÇ

##### **Instant Policy: In-Context Imitation Learning via Graph Diffusion**
2411.12633v1 by Vitalis Vosylius, Edward Johns

Following the impressive capabilities of in-context learning with large
transformers, In-Context Imitation Learning (ICIL) is a promising opportunity
for robotics. We introduce Instant Policy, which learns new tasks instantly
(without further training) from just one or two demonstrations, achieving ICIL
through two key components. First, we introduce inductive biases through a
graph representation and model ICIL as a graph generation problem with a
learned diffusion process, enabling structured reasoning over demonstrations,
observations, and actions. Second, we show that such a model can be trained
using pseudo-demonstrations - arbitrary trajectories generated in simulation -
as a virtually infinite pool of training data. Simulated and real experiments
show that Instant Policy enables rapid learning of various everyday robot
tasks. We also show how it can serve as a foundation for cross-embodiment and
zero-shot transfer to language-defined tasks. Code and videos are available at
https://www.robot-learning.uk/instant-policy.

ÊëòË¶ÅÔºöÁπºÂ§ßÂûãTransformerÂú®ÊÉÖÂ¢ÉÂ≠∏Áøí‰∏≠Ë°®ÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËÉΩÂäõÂæåÔºåÊÉÖÂ¢ÉÊ®°‰ªøÂ≠∏Áøí (ICIL) ÊàêÁÇ∫‰∫ÜÊ©üÂô®‰∫∫È†òÂüü‰∏≠‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑÊ©üÊúÉ„ÄÇÊàëÂÄëÂºïÂÖ•‰∫ÜÂç≥ÊôÇÁ≠ñÁï•ÔºåÂÆÉÂÉÖÂæû‰∏ÄÊàñÂÖ©Ê¨°Á§∫ÁØÑ‰∏≠Á´ãÂç≥Â≠∏ÁøíÊñ∞‰ªªÂãôÔºàÁÑ°ÈúÄÈÄ≤‰∏ÄÊ≠•Ë®ìÁ∑¥ÔºâÔºå‰∏¶ÈÄöÈÅéÂÖ©ÂÄãÈóúÈçµÁµÑÊàêÈÉ®ÂàÜÂØ¶Áèæ ICIL„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÈÄöÈÅéÂúñÂΩ¢Ë°®Á§∫ÂíåÊ®°Âûã ICIL ÂºïÂÖ•Ê≠∏Á¥çÂÅèÂ∑ÆÔºå‰∏¶Â∞áÂÖ∂‰ΩúÁÇ∫ÂÖ∑ÊúâÂ≠∏ÁøíÊì¥Êï£ÈÅéÁ®ãÁöÑÂúñÂΩ¢ÁîüÊàêÂïèÈ°åÔºåÂæûËÄåËÉΩÂ§†Â∞çÁ§∫ÁØÑ„ÄÅËßÄÂØüÂíåÂãï‰ΩúÈÄ≤Ë°åÁµêÊßãÂåñÊé®ÁêÜ„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÈÄôÁ®ÆÊ®°ÂûãÂèØ‰ª•‰ΩøÁî®ÂÅΩÁ§∫ÁØÑÈÄ≤Ë°åË®ìÁ∑¥ÔºåËÄåÂÅΩÁ§∫ÁØÑÊòØÊ®°Êì¨‰∏≠Áî¢ÁîüÁöÑ‰ªªÊÑèËªåË∑°ÔºåÂèØÁî®‰ΩúÂπæ‰πéÁÑ°ÈôêÁöÑË®ìÁ∑¥Êï∏ÊìöÊ±†„ÄÇÊ®°Êì¨ÂíåÁúüÂØ¶ÂØ¶È©óË°®ÊòéÔºåÂç≥ÊôÇÁ≠ñÁï•ËÉΩÂ§†Âø´ÈÄüÂ≠∏ÁøíÂêÑÁ®ÆÊó•Â∏∏Ê©üÂô®‰∫∫‰ªªÂãô„ÄÇÊàëÂÄëÈÇÑÂ±ïÁ§∫‰∫ÜÂÆÉÂ¶Ç‰Ωï‰ΩúÁÇ∫Ë∑®ÂÖ∑Ë∫´ÂíåÈõ∂Ê¨°ÂÇ≥Ëº∏Âà∞Ë™ûË®ÄÂÆöÁæ©‰ªªÂãôÁöÑÂü∫Á§é„ÄÇ‰ª£Á¢ºÂíåÂΩ±ÁâáÂèØÂú® https://www.robot-learning.uk/instant-policy ÂèñÂæó„ÄÇ

##### **Bias-Free Sentiment Analysis through Semantic Blinding and Graph Neural Networks**
2411.12493v2 by Hubert Plisiecki

This paper introduces the Semantic Propagation Graph Neural Network (SProp
GNN), a machine learning sentiment analysis (SA) architecture that relies
exclusively on syntactic structures and word-level emotional cues to predict
emotions in text. By semantically blinding the model to information about
specific words, it is robust to biases such as political or gender bias that
have been plaguing previous machine learning-based SA systems. The SProp GNN
shows performance superior to lexicon-based alternatives such as VADER and
EmoAtlas on two different prediction tasks, and across two languages.
Additionally, it approaches the accuracy of transformer-based models while
significantly reducing bias in emotion prediction tasks. By offering improved
explainability and reducing bias, the SProp GNN bridges the methodological gap
between interpretable lexicon approaches and powerful, yet often opaque, deep
learning models, offering a robust tool for fair and effective emotion analysis
in understanding human behavior through text.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π‰∫ÜË™ûÁæ©ÂÇ≥Êí≠ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (SProp GNN)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊ©üÂô®Â≠∏ÁøíÊÉÖÁ∑íÂàÜÊûê (SA) Êû∂ÊßãÔºåÂ∞àÈñÄ‰æùË≥¥Âè•Ê≥ïÁµêÊßãÂíåË©ûÂΩôÂ±§Á¥öÁöÑÊÉÖÁ∑íÁ∑öÁ¥¢‰æÜÈ†êÊ∏¨ÊñáÂ≠ó‰∏≠ÁöÑÊÉÖÁ∑í„ÄÇÈÄèÈÅéÂú®Ë™ûÁæ©‰∏äËÆìÊ®°ÂûãÂ∞çÁâπÂÆöÂ≠óË©ûÁöÑË≥áË®äË¶ñËÄå‰∏çË¶ãÔºåÂÆÉËÉΩÊúâÊïàÊ∂àÈô§ÊîøÊ≤ªÊàñÊÄßÂà•ÂÅèË¶ãÁ≠âÂÅèË™§ÔºåÈÄô‰∫õÂÅèË™§‰∏ÄÁõ¥Âõ∞ÊìæËëóÂÖàÂâçÁöÑÊ©üÂô®Â≠∏ÁøíÂºè SA Á≥ªÁµ±„ÄÇSProp GNN Âú®ÂÖ©È†Ö‰∏çÂêåÁöÑÈ†êÊ∏¨‰ªªÂãôÂíåÂÖ©Á®ÆË™ûË®Ä‰∏äÁöÑË°®ÁèæÈÉΩÂÑ™ÊñºÂü∫ÊñºË©ûÂΩôÂ∫´ÁöÑÊõø‰ª£ÊñπÊ°àÔºå‰æãÂ¶Ç VADER Âíå EmoAtlas„ÄÇÊ≠§Â§ñÔºåÂÆÉÂú®Â§ßÂπÖÊ∏õÂ∞ëÊÉÖÁ∑íÈ†êÊ∏¨‰ªªÂãô‰∏≠ÁöÑÂÅèË™§ÂêåÊôÇÔºå‰πüÊé•Ëøë‰∫ÜÂü∫ÊñºËΩâÊèõÂô®ÁöÑÊ®°ÂûãÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÈÄèÈÅéÊèê‰æõÊõ¥Â•ΩÁöÑÂèØËß£ÈáãÊÄß‰∏¶Ê∏õÂ∞ëÂÅèË™§ÔºåSProp GNN Êê≠Ëµ∑‰∫ÜÂèØË©ÆÈáãË©ûÂΩôÊñπÊ≥ïËàáÂº∑Â§ß‰ΩÜÁ∂ìÂ∏∏‰∏çÈÄèÊòéÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã‰πãÈñìÁöÑÊñπÊ≥ïË´ñÈ¥ªÊ∫ùÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂº∑ÂÅ•ÁöÑÂ∑•ÂÖ∑ÔºåÂèØ‰ª•ÈÄèÈÅéÊñáÂ≠óÁêÜËß£‰∫∫È°ûË°åÁÇ∫ÔºåÈÄ≤Ë°åÂÖ¨Âπ≥‰∏îÊúâÊïàÁöÑÂàÜÊûê„ÄÇ

##### **Neon: News Entity-Interaction Extraction for Enhanced Question Answering**
2411.12449v2 by Sneha Singhania, Silviu Cucerzan, Allen Herring, Sujay Kumar Jauhar

Capturing fresh information in near real-time and using it to augment
existing large language models (LLMs) is essential to generate up-to-date,
grounded, and reliable output. This problem becomes particularly challenging
when LLMs are used for informational tasks in rapidly evolving fields, such as
Web search related to recent or unfolding events involving entities, where
generating temporally relevant responses requires access to up-to-the-hour news
sources. However, the information modeled by the parametric memory of LLMs is
often outdated, and Web results from prototypical retrieval systems may fail to
capture the latest relevant information and struggle to handle conflicting
reports in evolving news. To address this challenge, we present the NEON
framework, designed to extract emerging entity interactions -- such as events
or activities -- as described in news articles. NEON constructs an
entity-centric timestamped knowledge graph that captures such interactions,
thereby facilitating enhanced QA capabilities related to news events. Our
framework innovates by integrating open Information Extraction (openIE) style
tuples into LLMs to enable in-context retrieval-augmented generation. This
integration demonstrates substantial improvements in QA performance when
tackling temporal, entity-centric search queries. Through NEON, LLMs can
deliver more accurate, reliable, and up-to-date responses.

ÊëòË¶ÅÔºöÊçïÊçâËøë‰πéÂØ¶ÊôÇÁöÑÊúÄÊñ∞Ë≥áË®äÔºå‰∏¶Âà©Áî®ÂÆÉ‰æÜÊì¥ÂÖÖÁèæÊúâÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÂ∞çÊñºÁî¢ÁîüÂç≥ÊôÇ„ÄÅÊúâÊ†πÊìö‰∏îÂèØÈù†ÁöÑËº∏Âá∫Ëá≥ÈóúÈáçË¶Å„ÄÇÁï∂ LLM Ë¢´Áî®ÊñºÂø´ÈÄüÊºîÂåñÁöÑÈ†òÂüü‰∏≠ÁöÑË®äÊÅØ‰ªªÂãôÊôÇÔºåÈÄôÂÄãÂïèÈ°åÊúÉËÆäÂæóÁâπÂà•ÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºå‰æãÂ¶ÇËàáÊ∂âÂèäÂØ¶È´îÁöÑËøëÊúüÊàñÊ≠£Âú®ÁôºÁîüÁöÑ‰∫ã‰ª∂Áõ∏ÈóúÁöÑÁ∂≤Ë∑ØÊêúÂ∞ãÔºåÂú®ÈÄôÁ®ÆÊÉÖÊ≥Å‰∏ãÔºåÁî¢ÁîüÊôÇÈñìÁõ∏ÈóúÁöÑÂõûÊáâÈúÄË¶ÅÂèñÂæóÊúÄÊñ∞ÁöÑÊñ∞ËÅû‰æÜÊ∫ê„ÄÇÁÑ∂ËÄåÔºåLLM ÁöÑÂèÉÊï∏Ë®òÊÜ∂È´îÂª∫Ê®°ÁöÑË≥áË®äÁ∂ìÂ∏∏ÈÅéÊôÇÔºåËÄåÂéüÂûãÊ™¢Á¥¢Á≥ªÁµ±ÁöÑÁ∂≤Ë∑ØÁµêÊûúÂèØËÉΩÁÑ°Ê≥ïÊçïÊçâÊúÄÊñ∞ÁöÑÁõ∏ÈóúË≥áË®äÔºå‰∏¶‰∏îÈõ£‰ª•ËôïÁêÜÊºîÂåñ‰∏≠ÁöÑÊñ∞ËÅû‰∏≠ÁöÑÁõ∏‰∫íÁüõÁõæÁöÑÂ†±Â∞é„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄôÂÄãÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü NEON Ê°ÜÊû∂ÔºåÊó®Âú®ËêÉÂèñÊñ∞ËààÂØ¶È´î‰∫íÂãïÔºà‰æãÂ¶Ç‰∫ã‰ª∂ÊàñÊ¥ªÂãïÔºâÔºåÂ¶ÇÊñ∞ËÅûÊñáÁ´†‰∏≠ÊâÄÊèèËø∞ÁöÑ„ÄÇNEON Âª∫Êßã‰∫Ü‰∏ÄÂÄã‰ª•ÂØ¶È´îÁÇ∫‰∏≠ÂøÉÁöÑÂ∏∂ÊôÇÈñìÊà≥Ë®òÁöÑÁü•Ë≠òÂúñË≠úÔºåÁî®‰æÜÊçïÊçâÊ≠§È°û‰∫íÂãïÔºåÂæûËÄå‰øÉÈÄ≤ËàáÊñ∞ËÅû‰∫ã‰ª∂Áõ∏ÈóúÁöÑÂ¢ûÂº∑ÂºèÂïèÁ≠îËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÊ°ÜÊû∂ÈÄèÈÅéÂ∞áÈñãÊîæË≥áË®äËêÉÂèñ (openIE) È¢®Ê†ºÂÖÉÁµÑÊï¥ÂêàÂà∞ LLM ‰∏≠Ôºå‰ª•ÂïüÁî®ÊÉÖÂ¢ÉÂÖßÊ™¢Á¥¢Â¢ûÂº∑ÂºèÁî¢ÁîüÔºåÈÄ≤ËÄåÂâµÊñ∞„ÄÇÁï∂ËôïÁêÜÊôÇÈñì„ÄÅ‰ª•ÂØ¶È´îÁÇ∫‰∏≠ÂøÉÁöÑÊêúÂ∞ãÊü•Ë©¢ÊôÇÔºåÈÄôÁ®ÆÊï¥ÂêàÈ°ØÁ§∫Âá∫ÂïèÁ≠îÊïàËÉΩÁöÑÈ°ØËëóÊèêÂçá„ÄÇÈÄèÈÅé NEONÔºåLLM ÂèØ‰ª•Êèê‰æõÊõ¥Ê∫ñÁ¢∫„ÄÅÂèØÈù†‰∏îÊúÄÊñ∞ÁöÑÂõûÊáâ„ÄÇ

##### **GRL-Prompt: Towards Knowledge Graph based Prompt Optimization via Reinforcement Learning**
2411.14479v1 by Yuze Liu, Tingjie Liu, Tiehua Zhang, Youhua Xia, Jinze Wang, Zhishu Shen, Jiong Jin, Fei Richard Yu

Large language models (LLMs) have demonstrated impressive success in a wide
range of natural language processing (NLP) tasks due to their extensive general
knowledge of the world. Recent works discovered that the performance of LLMs is
heavily dependent on the input prompt. However, prompt engineering is usually
done manually in a trial-and-error fashion, which can be labor-intensive and
challenging in order to find the optimal prompts. To address these problems and
unleash the utmost potential of LLMs, we propose a novel LLMs-agnostic
framework for prompt optimization, namely GRL-Prompt, which aims to
automatically construct optimal prompts via reinforcement learning (RL) in an
end-to-end manner. To provide structured action/state representation for
optimizing prompts, we construct a knowledge graph (KG) that better encodes the
correlation between the user query and candidate in-context examples.
Furthermore, a policy network is formulated to generate the optimal action by
selecting a set of in-context examples in a rewardable order to construct the
prompt. Additionally, the embedding-based reward shaping is utilized to
stabilize the RL training process. The experimental results show that
GRL-Prompt outperforms recent state-of-the-art methods, achieving an average
increase of 0.10 in ROUGE-1, 0.07 in ROUGE-2, 0.07 in ROUGE-L, and 0.05 in
BLEU.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Âª£Ê≥õÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊàêÂäüÔºåÈÄôÊ≠∏ÂäüÊñºÂÆÉÂÄëÂ∞ç‰∏ñÁïåÁöÑÂª£Ê≥õ‰∏ÄËà¨Áü•Ë≠ò„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂ÁôºÁèæÔºåLLM ÁöÑÊïàËÉΩÈ´òÂ∫¶‰æùË≥¥ÊñºËº∏ÂÖ•ÊèêÁ§∫„ÄÇÁÑ∂ËÄåÔºåÊèêÁ§∫Â∑•Á®ãÈÄöÂ∏∏‰ª•Ë©¶ÈåØÁöÑÊñπÂºèÊâãÂãïÂÆåÊàêÔºåÈÄôÂú®Â∞ãÊâæÊúÄ‰Ω≥ÊèêÁ§∫ÊôÇÂèØËÉΩÊúÉËÄóË≤ªÂ§ßÈáè‰∫∫Âäõ‰∏îÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°å‰∏¶ÁôºÊèÆ LLM ÁöÑÊúÄÂ§ßÊΩõÂäõÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑ LLM ‰∏çÂèØÁü•Ê°ÜÊû∂ÔºåÁî®ÊñºÊèêÁ§∫ÊúÄ‰Ω≥ÂåñÔºåÂç≥ GRL-PromptÔºåÂÖ∂Êó®Âú®ÈÄèÈÅéÂº∑ÂåñÂ≠∏Áøí (RL) ‰ª•Á´ØÂà∞Á´ØÁöÑÊñπÂºèËá™ÂãïÂª∫ÊßãÊúÄ‰Ω≥ÊèêÁ§∫„ÄÇÁÇ∫‰∫ÜÊèê‰æõÁµêÊßãÂåñÁöÑÂãï‰Ωú/ÁãÄÊÖãË°®Á§∫‰ª•ÊúÄ‰Ω≥ÂåñÊèêÁ§∫ÔºåÊàëÂÄëÂª∫Êßã‰∫Ü‰∏ÄÂÄãÁü•Ë≠òÂúñË≠ú (KG)ÔºåÂÆÉËÉΩÊõ¥Â•ΩÂú∞Á∑®Á¢º‰ΩøÁî®ËÄÖÊü•Ë©¢ËàáÂÄôÈÅ∏ÊÉÖÂ¢ÉÁØÑ‰æã‰πãÈñìÁöÑÈóúËÅØÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂà∂ÂÆö‰∫Ü‰∏ÄÂÄãÁ≠ñÁï•Á∂≤Ë∑ØÔºåÈÄèÈÅé‰ª•ÂèØÁçéÂãµÁöÑÈ†ÜÂ∫èÈÅ∏Êìá‰∏ÄÁµÑÊÉÖÂ¢ÉÁØÑ‰æã‰æÜÂª∫ÊßãÊèêÁ§∫Ôºå‰ª•Áî¢ÁîüÊúÄ‰Ω≥Âãï‰Ωú„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂà©Áî®Âü∫ÊñºÂµåÂÖ•ÁöÑÁçéÂãµÂ°ëÈÄ†‰æÜÁ©©ÂÆö RL Ë®ìÁ∑¥ÈÅéÁ®ã„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåGRL-Prompt ÂÑ™ÊñºÊúÄËøëÁöÑÊúÄÊñ∞ÊñπÊ≥ïÔºåÂú® ROUGE-1 ‰∏≠Âπ≥ÂùáÂ¢ûÂä† 0.10ÔºåÂú® ROUGE-2 ‰∏≠Â¢ûÂä† 0.07ÔºåÂú® ROUGE-L ‰∏≠Â¢ûÂä† 0.07ÔºåÂú® BLEU ‰∏≠Â¢ûÂä† 0.05„ÄÇ

##### **Just KIDDIN: Knowledge Infusion and Distillation for Detection of INdecent Memes**
2411.12174v1 by Rahul Garg, Trilok Padhi, Hemang Jain, Ugur Kursuncu, Ponnurangam Kumaraguru

Toxicity identification in online multimodal environments remains a
challenging task due to the complexity of contextual connections across
modalities (e.g., textual and visual). In this paper, we propose a novel
framework that integrates Knowledge Distillation (KD) from Large Visual
Language Models (LVLMs) and knowledge infusion to enhance the performance of
toxicity detection in hateful memes. Our approach extracts sub-knowledge graphs
from ConceptNet, a large-scale commonsense Knowledge Graph (KG) to be infused
within a compact VLM framework. The relational context between toxic phrases in
captions and memes, as well as visual concepts in memes enhance the model's
reasoning capabilities. Experimental results from our study on two hate speech
benchmark datasets demonstrate superior performance over the state-of-the-art
baselines across AU-ROC, F1, and Recall with improvements of 1.1%, 7%, and 35%,
respectively. Given the contextual complexity of the toxicity detection task,
our approach showcases the significance of learning from both explicit (i.e.
KG) as well as implicit (i.e. LVLMs) contextual cues incorporated through a
hybrid neurosymbolic approach. This is crucial for real-world applications
where accurate and scalable recognition of toxic content is critical for
creating safer online environments.

ÊëòË¶ÅÔºöÁ∂≤Ë∑ØÂ§öÊ®°ÊÖãÁí∞Â¢É‰∏≠ÁöÑÊØíÊÄßËæ®Ë≠òÔºåÁî±ÊñºÊ®°ÊÖãÈñìÔºà‰æãÂ¶ÇÊñáÂ≠óÂíåË¶ñË¶∫ÔºâÁöÑËÑàÁµ°ÈóúËÅØË§áÈõúÔºåÂõ†Ê≠§‰ªçÊòØ‰∏ÄÈ†ÖÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãô„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÊû∂ÊßãÔºåÊï¥Âêà‰æÜËá™Â§ßÂûãË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (LVLMs) ÁöÑÁü•Ë≠òËí∏È§æ (KD) ÂíåÁü•Ë≠òÊ≥®ÂÖ•Ôºå‰ª•Â¢ûÂº∑‰ªáÊÅ®Ëø∑Âõ†‰∏≠ÊØíÊÄßÂÅµÊ∏¨ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂæû ConceptNetÔºà‰∏ÄÂÄãÂ§ßÂûãÂ∏∏Ë≠òÁü•Ë≠òÂúñË≠ú (KG)Ôºâ‰∏≠ËêÉÂèñÂ≠êÁü•Ë≠òÂúñÔºå‰∏¶Ê≥®ÂÖ•Âà∞‰∏ÄÂÄãÁ∑äÊπäÁöÑ VLM Êû∂Êßã‰∏≠„ÄÇÊ®ôÈ°åÂíåËø∑Âõ†‰∏≠ÂÖ∑ÊúâÊØíÊÄßÁöÑË©ûÂΩô‰πãÈñìÁöÑÈóú‰øÇËÑàÁµ°Ôºå‰ª•ÂèäËø∑Âõ†‰∏≠ÁöÑË¶ñË¶∫Ê¶ÇÂøµÔºåÂ¢ûÂº∑‰∫ÜÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄã‰ªáÊÅ®Ë®ÄË´ñÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÁ†îÁ©∂ÁöÑÂØ¶È©óÁµêÊûúÔºåË≠âÊòé‰∫ÜÂú® AU-ROC„ÄÅF1 ÂíåÂè¨ÂõûÁéáÊñπÈù¢ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÂü∫Ê∫ñÔºåÂàÜÂà•ÊèêÂçá‰∫Ü 1.1%„ÄÅ7% Âíå 35%„ÄÇÈëëÊñºÊØíÊÄßÂÅµÊ∏¨‰ªªÂãôÁöÑËÑàÁµ°Ë§áÈõúÊÄßÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂ±ïÁ§∫‰∫ÜÂæûÊòéÁ¢∫Ôºà‰æãÂ¶Ç KGÔºâÂíåÈö±Âê´Ôºà‰æãÂ¶Ç LVLMsÔºâËÑàÁµ°Á∑öÁ¥¢‰∏≠Â≠∏ÁøíÔºå‰∏¶ÈÄèÈÅéÊ∑∑ÂêàÁ•ûÁ∂ìÁ¨¶ËôüÊñπÊ≥ïÊï¥ÂêàËµ∑‰æÜÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄôÂ∞çÊñºÁúüÂØ¶‰∏ñÁïåÁöÑÊáâÁî®Ëá≥ÈóúÈáçË¶ÅÔºåÂú®ÈÄô‰∫õÊáâÁî®‰∏≠ÔºåÊ∫ñÁ¢∫‰∏îÂèØÊì¥ÂÖÖÁöÑÊØíÊÄßÂÖßÂÆπËæ®Ë≠òÂ∞çÊñºÂâµÈÄ†Êõ¥ÂÆâÂÖ®ÁöÑÁ∂≤Ë∑ØÁí∞Â¢ÉËá≥ÈóúÈáçË¶Å„ÄÇ

##### **Regret-Free Reinforcement Learning for LTL Specifications**
2411.12019v1 by Rupak Majumdar, Mahmoud Salamati, Sadegh Soudjani

Reinforcement learning (RL) is a promising method to learn optimal control
policies for systems with unknown dynamics. In particular, synthesizing
controllers for safety-critical systems based on high-level specifications,
such as those expressed in temporal languages like linear temporal logic (LTL),
presents a significant challenge in control systems research. Current RL-based
methods designed for LTL tasks typically offer only asymptotic guarantees,
which provide no insight into the transient performance during the learning
phase. While running an RL algorithm, it is crucial to assess how close we are
to achieving optimal behavior if we stop learning.
  In this paper, we present the first regret-free online algorithm for learning
a controller that addresses the general class of LTL specifications over Markov
decision processes (MDPs) with a finite set of states and actions. We begin by
proposing a regret-free learning algorithm to solve infinite-horizon
reach-avoid problems. For general LTL specifications, we show that the
synthesis problem can be reduced to a reach-avoid problem when the graph
structure is known. Additionally, we provide an algorithm for learning the
graph structure, assuming knowledge of a minimum transition probability, which
operates independently of the main regret-free algorithm.

ÊëòË¶ÅÔºöÂº∑ÂåñÂ≠∏Áøí (RL) ÊòØ‰∏ÄÁ®ÆÊúâÂ∏åÊúõÁöÑÊñπÊ≥ïÔºåÂèØ‰ª•Â≠∏ÁøíÊú™Áü•ÂãïÊÖãÁ≥ªÁµ±ÁöÑÊúÄ‰Ω≥ÊéßÂà∂Á≠ñÁï•„ÄÇÁâπÂà•ÊòØÔºåÂü∫ÊñºÈ´òÈöéË¶èÁØÑÔºà‰æãÂ¶ÇÁî®Á∑öÊÄßÊôÇÂ∫èÈÇèËºØ (LTL) Á≠âÊôÇÂ∫èË™ûË®ÄË°®ÈÅîÁöÑË¶èÁØÑÔºâÁÇ∫ÂÆâÂÖ®ÈóúÈçµÁ≥ªÁµ±ÂêàÊàêÊéßÂà∂Âô®ÔºåÈÄôÂú®ÊéßÂà∂Á≥ªÁµ±Á†îÁ©∂‰∏≠ÊòØ‰∏ÄÂÄãÈáçÂ§ßÊåëÊà∞„ÄÇÁõÆÂâçÁöÑÂü∫Êñº RL ÁöÑ LTL ‰ªªÂãôÊñπÊ≥ïÈÄöÂ∏∏ÂÉÖÊèê‰æõÊº∏Ëøë‰øùË≠âÔºåÈÄôÂú®Â≠∏ÁøíÈöéÊÆµÊ≤íÊúâÊèê‰æõÊö´ÊÖãÊïàËÉΩÁöÑË¶ãËß£„ÄÇÂú®Âü∑Ë°å RL ÊºîÁÆóÊ≥ïÊôÇÔºåÂ¶ÇÊûúÊàëÂÄëÂÅúÊ≠¢Â≠∏ÁøíÔºåË©ï‰º∞ÊàëÂÄëË∑ùÈõ¢ÈÅîÊàêÊúÄ‰Ω≥Ë°åÁÇ∫ÊúâÂ§öËøëËá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÁ¨¨‰∏ÄÂÄãÁÑ°ÈÅ∫ÊÜæÁ∑ö‰∏äÊºîÁÆóÊ≥ïÔºåÁî®ÊñºÂ≠∏Áøí‰∏ÄÂÄãÊéßÂà∂Âô®ÔºåË©≤ÊéßÂà∂Âô®Ëß£Ê±∫‰∫ÜÈ¶¨ÂèØÂ§´Ê±∫Á≠ñÈÅéÁ®ã (MDP) ‰∏äÁöÑ‰∏ÄËà¨È°ûÂà• LTL Ë¶èÁØÑÔºåÂÖ∂‰∏≠ÂåÖÂê´ÊúâÈôêÁöÑÁãÄÊÖãÂíåÂãï‰ΩúÈõÜÂêà„ÄÇÊàëÂÄëÈ¶ñÂÖàÊèêÂá∫‰∏ÄÂÄãÁÑ°ÈÅ∫ÊÜæÂ≠∏ÁøíÊºîÁÆóÊ≥ï‰æÜËß£Ê±∫ÁÑ°ÈôêÊôÇÂüüÂà∞ÈÅîÈÅøÂÖçÂïèÈ°å„ÄÇÂ∞çÊñº‰∏ÄËà¨ LTL Ë¶èÁØÑÔºåÊàëÂÄëË°®ÊòéÁï∂ÂúñÂΩ¢ÁµêÊßãÂ∑≤Áü•ÊôÇÔºåÂêàÊàêÂïèÈ°åÂèØ‰ª•Á∞°ÂåñÁÇ∫Âà∞ÈÅîÈÅøÂÖçÂïèÈ°å„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊºîÁÆóÊ≥ï‰æÜÂ≠∏ÁøíÂúñÂΩ¢ÁµêÊßãÔºåÂÅáË®≠Áü•ÈÅìÊúÄÂ∞èËΩâÁßªÊ©üÁéáÔºåÂÆÉÁç®Á´ãÊñº‰∏ªË¶ÅÁöÑÁÑ°ÈÅ∫ÊÜæÊºîÁÆóÊ≥ïÈÅã‰Ωú„ÄÇ

##### **Semantic-Geometric-Physical-Driven Robot Manipulation Skill Transfer via Skill Library and Tactile Representation**
2411.11714v1 by Mingchao Qi, Yuanjin Li, Xing Liu, Zhengxiong Liu, Panfeng Huang

Deploying robots in open-world environments involves complex tasks
characterized by long sequences and rich interactions, necessitating efficient
transfer of robotic skills across diverse and complex scenarios. To address
this challenge, we propose a skill library framework based on knowledge graphs,
which endows robots with high-level skill awareness and spatial semantic
understanding. The framework hierarchically organizes operational knowledge by
constructing a "task graph" and a "scene graph" to represent task and scene
semantic information, respectively. We introduce a "state graph" to facilitate
interaction between high-level task planning and low-level scene information.
Furthermore, we propose a hierarchical transfer framework for operational
skills. At the task level, the framework integrates contextual learning and
chain-of-thought prompting within a four-stage prompt paradigm, leveraging
large language models' (LLMs) reasoning and generalization capabilities to
achieve task-level subtask sequence transfer. At the motion level, an adaptive
trajectory transfer method is developed using the A* algorithm and the skill
library, enabling motion-level adaptive trajectory transfer. At the physical
level, we introduce an adaptive contour extraction and posture perception
method based on tactile perception. This method dynamically obtains
high-precision contour and posture information from visual-tactile texture data
and adjusts transferred skills, such as contact positions and postures, to
ensure effectiveness in new environments. Experimental results validate the
effectiveness of the proposed methods. Project
website:https://github.com/MingchaoQi/skill_transfer

ÊëòË¶ÅÔºö<paragraph>Âú®ÂºÄÊîæ‰∏ñÁïåÁéØÂ¢É‰∏≠ÈÉ®ÁΩ≤Êú∫Âô®‰∫∫Ê∂âÂèäÂ§çÊùÇÁöÑ‰ªªÂä°ÔºåÂÖ∂ÁâπÁÇπÊòØÂ∫èÂàóÈïø„ÄÅ‰∫§‰∫í‰∏∞ÂØåÔºåÈúÄË¶ÅÂú®‰∏çÂêå‰∏îÂ§çÊùÇÁöÑÂú∫ÊôØ‰∏≠È´òÊïàÂú∞ËΩ¨ÁßªÊú∫Âô®‰∫∫ÊäÄËÉΩ„ÄÇ‰∏∫‰∫ÜÂ∫îÂØπËøô‰∏ÄÊåëÊàòÔºåÊàë‰ª¨ÊèêÂá∫‰∏Ä‰∏™Âü∫‰∫éÁü•ËØÜÂõæË∞±ÁöÑÊäÄËÉΩÂ∫ìÊ°ÜÊû∂ÔºåÂÆÉËµã‰∫àÊú∫Âô®‰∫∫È´òÁ∫ßÊäÄËÉΩÊÑèËØÜÂíåÁ©∫Èó¥ËØ≠‰πâÁêÜËß£„ÄÇËØ•Ê°ÜÊû∂ÈÄöËøáÊûÑÂª∫‚Äú‰ªªÂä°Âõæ‚ÄùÂíå‚ÄúÂú∫ÊôØÂõæ‚ÄùÊù•ÂàÜÂ±ÇÁªÑÁªáÊìç‰ΩúÁü•ËØÜÔºåÂàÜÂà´Ë°®Á§∫‰ªªÂä°ÂíåÂú∫ÊôØËØ≠‰πâ‰ø°ÊÅØ„ÄÇÊàë‰ª¨ÂºïÂÖ•‰∏Ä‰∏™‚ÄúÁä∂ÊÄÅÂõæ‚ÄùÊù•‰øÉËøõÈ´òÁ∫ß‰ªªÂä°ËßÑÂàíÂíå‰ΩéÁ∫ßÂú∫ÊôØ‰ø°ÊÅØ‰πãÈó¥ÁöÑ‰∫§‰∫í„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Êìç‰ΩúÊäÄËÉΩÁöÑÂàÜÂ±ÇËΩ¨ÁßªÊ°ÜÊû∂„ÄÇÂú®‰ªªÂä°Â±ÇÈù¢ÔºåËØ•Ê°ÜÊû∂Âú®‰∏Ä‰∏™ÂõõÈò∂ÊÆµÊèêÁ§∫ËåÉÂºè‰∏≠ÈõÜÊàê‰∫Ü‰∏ä‰∏ãÊñáÂ≠¶‰π†ÂíåÊÄùÊÉ≥ÈìæÊèêÁ§∫ÔºåÂà©Áî®Â§ßËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑÊé®ÁêÜÂíåÊ≥õÂåñËÉΩÂäõÊù•ÂÆûÁé∞‰ªªÂä°Á∫ßÂ≠ê‰ªªÂä°Â∫èÂàóËΩ¨Áßª„ÄÇÂú®ËøêÂä®Â±ÇÈù¢Ôºå‰ΩøÁî® A* ÁÆóÊ≥ïÂíåÊäÄËÉΩÂ∫ìÂºÄÂèë‰∫Ü‰∏ÄÁßçËá™ÈÄÇÂ∫îËΩ®ËøπËΩ¨ÁßªÊñπÊ≥ïÔºåÂÆûÁé∞ËøêÂä®Á∫ßËá™ÈÄÇÂ∫îËΩ®ËøπËΩ¨Áßª„ÄÇÂú®Áâ©ÁêÜÂ±ÇÈù¢ÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏ÄÁßçÂü∫‰∫éËß¶ËßâÊÑüÁü•ÁöÑËá™ÈÄÇÂ∫îËΩÆÂªìÊèêÂèñÂíåÂßøÊÄÅÊÑüÁü•ÊñπÊ≥ï„ÄÇËØ•ÊñπÊ≥ï‰ªéËßÜËßâËß¶ËßâÁ∫πÁêÜÊï∞ÊçÆ‰∏≠Âä®ÊÄÅËé∑ÂèñÈ´òÁ≤æÂ∫¶ÁöÑËΩÆÂªìÂíåÂßøÊÄÅ‰ø°ÊÅØÔºåÂπ∂Ë∞ÉÊï¥ËΩ¨ÁßªÁöÑÊäÄËÉΩÔºå‰æãÂ¶ÇÊé•Ëß¶‰ΩçÁΩÆÂíåÂßøÊÄÅÔºå‰ª•Á°Æ‰øùÂú®Êñ∞ÁöÑÁéØÂ¢É‰∏≠ÊúâÊïà„ÄÇÂÆûÈ™åÁªìÊûúÈ™åËØÅ‰∫ÜÊâÄÊèêÂá∫ÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÈ°πÁõÆÁΩëÁ´ôÔºöhttps://github.com/MingchaoQi/skill_transfer</paragraph>

##### **Addressing Hallucinations in Language Models with Knowledge Graph Embeddings as an Additional Modality**
2411.11531v1 by Viktoriia Chekalina, Anton Razzigaev, Elizaveta Goncharova, Andrey Kuznetsov

In this paper we present an approach to reduce hallucinations in Large
Language Models (LLMs) by incorporating Knowledge Graphs (KGs) as an additional
modality. Our method involves transforming input text into a set of KG
embeddings and using an adapter to integrate these embeddings into the language
model space, without relying on external retrieval processes.
  To facilitate this, we created WikiEntities, a dataset containing over 3
million Wikipedia texts annotated with entities from Wikidata and their
corresponding embeddings from PyTorch-BigGraph. This dataset serves as a
valuable resource for training Entity Linking models and adapting the described
method to various LLMs using specialized adapters.
  Our method does not require fine-tuning of the language models themselves;
instead, we only train the adapter. This ensures that the model's performance
on other tasks is not affected. We trained an adapter for the Mistral 7B, LLaMA
2-7B (chat), and LLaMA 3-8B (instruct) models using this dataset and
demonstrated that our approach improves performance on the HaluEval, True-False
benchmarks and FEVER dataset. The results indicate that incorporating KGs as a
new modality can effectively reduce hallucinations and improve the factual
accuracy of language models, all without the need for external retrieval.

ÊëòË¶ÅÔºö<paragraph>Âú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåÈÄèÈÅéÂ∞áÁü•Ë≠òÂúñË≠ú (KG) ‰ΩúÁÇ∫ÈôÑÂä†ÊñπÂºèÁ¥çÂÖ•Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)Ôºå‰ª•Ê∏õÂ∞ëÂπªË¶∫„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂåÖÊã¨Â∞áËº∏ÂÖ•ÊñáÂ≠óËΩâÊèõÊàê‰∏ÄÁµÑ KG ÂµåÂÖ•Ôºå‰∏¶‰ΩøÁî®ÈÅ©ÈÖçÂô®Â∞áÈÄô‰∫õÂµåÂÖ•Êï¥ÂêàÂà∞Ë™ûË®ÄÊ®°ÂûãÁ©∫ÈñìÔºåËÄåÁÑ°ÈúÄ‰æùË≥¥Â§ñÈÉ®Ê™¢Á¥¢Á®ãÂ∫è„ÄÇ
ÁÇ∫‰∫Ü‰øÉÈÄ≤ÈÄô‰∏ÄÈªûÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü WikiEntitiesÔºåÈÄôÊòØ‰∏ÄÂÄãÂåÖÂê´Ë∂ÖÈÅé 300 Ëê¨ÂÄãÁ∂≠Âü∫ÁôæÁßëÊñáÂ≠óÁöÑË≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÈôÑÊúâ‰æÜËá™ Wikidata ÁöÑÂØ¶È´îË®ªËß£Ôºå‰ª•ÂèäÂÆÉÂÄë‰æÜËá™ PyTorch-BigGraph ÁöÑÂ∞çÊáâÂµåÂÖ•„ÄÇÊ≠§Ë≥áÊñôÈõÜ‰ΩúÁÇ∫Ë®ìÁ∑¥ÂØ¶È´îÈÄ£ÁµêÊ®°ÂûãÂíå‰ΩøÁî®Â∞àÈñÄÈÅ©ÈÖçÂô®Â∞áÊâÄËø∞ÊñπÊ≥ïË™øÊï¥Âà∞ÂêÑÁ®Æ LLM ÁöÑÂØ∂Ë≤¥Ë≥áÊ∫ê„ÄÇ
ÊàëÂÄëÁöÑÂÅöÊ≥ï‰∏çÈúÄË¶ÅÂæÆË™øË™ûË®ÄÊ®°ÂûãÊú¨Ë∫´ÔºõÁõ∏ÂèçÔºåÊàëÂÄëÂè™Ë®ìÁ∑¥ÈÅ©ÈÖçÂô®„ÄÇÈÄôÁ¢∫‰øù‰∫ÜÊ®°ÂûãÂú®ÂÖ∂‰ªñ‰ªªÂãô‰∏äÁöÑÊïàËÉΩ‰∏çÂèóÂΩ±Èüø„ÄÇÊàëÂÄë‰ΩøÁî®Ê≠§Ë≥áÊñôÈõÜË®ìÁ∑¥‰∫Ü Mistral 7B„ÄÅLLaMA 2-7B (ËÅäÂ§©) Âíå LLaMA 3-8B (Êåá‰ª§) Ê®°ÂûãÁöÑÈÅ©ÈÖçÂô®Ôºå‰∏¶Ë≠âÊòé‰∫ÜÊàëÂÄëÁöÑÂÅöÊ≥ïÊîπÂñÑ‰∫Ü HaluEval„ÄÅÁúüÂÅáÂü∫Ê∫ñÂíå FEVER Ë≥áÊñôÈõÜÁöÑÊïàËÉΩ„ÄÇÁµêÊûúË°®ÊòéÔºåÂ∞á KG ‰ΩúÁÇ∫‰∏ÄÁ®ÆÊñ∞ÊñπÂºèÁ¥çÂÖ•ÂèØ‰ª•ÊúâÊïàÊ∏õÂ∞ëÂπªË¶∫Ôºå‰∏¶ÊèêÈ´òË™ûË®ÄÊ®°ÂûãÁöÑ‰∫ãÂØ¶Ê∫ñÁ¢∫ÊÄßÔºåËÄåÁÑ°ÈúÄÂ§ñÈÉ®Ê™¢Á¥¢„ÄÇ</paragraph>

##### **RPN 2: On Interdependence Function Learning Towards Unifying and Advancing CNN, RNN, GNN, and Transformer**
2411.11162v1 by Jiawei Zhang

This paper builds upon our previous work on the Reconciled Polynomial Network
(RPN). The original RPN model was designed under the assumption of input data
independence, presuming the independence among both individual instances within
data batches and attributes in each data instance. However, this assumption
often proves invalid for function learning tasks involving complex,
interdependent data such as language, images, time series, and graphs. Ignoring
such data interdependence may inevitably lead to significant performance
degradation.
  To overcome these limitations, we introduce the new Reconciled Polynomial
Network (version 2), namely RPN 2, in this paper. By incorporating data and
structural interdependence functions, RPN 2 explicitly models data
interdependence via new component functions in its architecture.
  This enhancement not only significantly improves RPN 2's learning performance
but also substantially expands its unifying potential, enabling it to encompass
a broader range of contemporary dominant backbone models within its canonical
representation. These backbones include, but are not limited to, convolutional
neural networks (CNNs), recurrent neural networks (RNNs), graph neural networks
(GNNs), and Transformers. Our analysis reveals that the fundamental
distinctions among these backbone models primarily stem from their diverse
approaches to defining the interdependence functions. Furthermore, this unified
representation opens up new opportunities for designing innovative
architectures with the potential to surpass the performance of these dominant
backbones.

ÊëòË¶ÅÔºöÊú¨ÊñáÂª∫Á´ãÂú®Êàë‰ª¨ÂÖàÂâçÂÖ≥‰∫éÂçèË∞ÉÂ§öÈ°πÂºèÁΩëÁªú (RPN) ÁöÑÂ∑•‰Ωú‰πã‰∏ä„ÄÇÊúÄÂàùÁöÑ RPN Ê®°ÂûãÊòØÂú®ËæìÂÖ•Êï∞ÊçÆÁã¨Á´ãÊÄßÁöÑÂÅáËÆæ‰∏ãËÆæËÆ°ÁöÑÔºåÂÅáÂÆöÊï∞ÊçÆÊâπÊ¨°‰∏≠ÂêÑ‰∏™ÂÆû‰æã‰πãÈó¥ÁöÑÁã¨Á´ãÊÄß‰ª•ÂèäÊØè‰∏™Êï∞ÊçÆÂÆû‰æã‰∏≠ÁöÑÂ±ûÊÄß‰πãÈó¥ÁöÑÁã¨Á´ãÊÄß„ÄÇÁÑ∂ËÄåÔºåÂØπ‰∫éÊ∂âÂèäÂ§çÊùÇÁõ∏‰∫í‰æùËµñÊï∞ÊçÆÔºà‰æãÂ¶ÇËØ≠Ë®Ä„ÄÅÂõæÂÉè„ÄÅÊó∂Èó¥Â∫èÂàóÂíåÂõæÂΩ¢ÔºâÁöÑÂäüËÉΩÂ≠¶‰π†‰ªªÂä°ÔºåËøôÁßçÂÅáËÆæÈÄöÂ∏∏Ë¢´ËØÅÊòéÊòØÊó†ÊïàÁöÑ„ÄÇÂøΩÁï•Ê≠§Á±ªÊï∞ÊçÆÁõ∏‰∫í‰æùËµñÊÄß‰∏çÂèØÈÅøÂÖçÂú∞‰ºöÂØºËá¥ÊÄßËÉΩÊòæÁùÄ‰∏ãÈôç„ÄÇ
‰∏∫‰∫ÜÂÖãÊúçËøô‰∫õÈôêÂà∂ÔºåÊàë‰ª¨Âú®Êú¨Êñá‰∏≠ÂºïÂÖ•‰∫ÜÊñ∞ÁöÑÂçèË∞ÉÂ§öÈ°πÂºèÁΩëÁªúÔºàÁâàÊú¨ 2ÔºâÔºåÂç≥ RPN 2„ÄÇÈÄöËøáÁªìÂêàÊï∞ÊçÆÂíåÁªìÊûÑÁõ∏‰∫í‰æùËµñÂáΩÊï∞ÔºåRPN 2 ÈÄöËøáÂÖ∂Êû∂ÊûÑ‰∏≠ÁöÑÊñ∞ÁªÑ‰ª∂ÂáΩÊï∞ÊòéÁ°ÆÂú∞ÂØπÊï∞ÊçÆÁõ∏‰∫í‰æùËµñÊÄßËøõË°åÂª∫Ê®°„ÄÇ
ËøôÁßçÂ¢ûÂº∫‰∏ç‰ªÖÊòæÁùÄÊèêÈ´ò‰∫Ü RPN 2 ÁöÑÂ≠¶‰π†ÊÄßËÉΩÔºåËÄå‰∏îËøòÂ§ßÂπÖÊâ©Â±ï‰∫ÜÂÖ∂Áªü‰∏ÄÊΩúÂäõÔºå‰ΩøÂÖ∂ËÉΩÂ§üÂú®ÂÖ∂ËßÑËåÉË°®Á§∫‰∏≠ÂåÖÂê´Êõ¥ÂπøÊ≥õÁöÑÂΩì‰ª£‰∏ªÂπ≤Ê®°Âûã„ÄÇËøô‰∫õ‰∏ªÂπ≤ÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫éÂç∑ÁßØÁ•ûÁªèÁΩëÁªú (CNN)„ÄÅÂæ™ÁéØÁ•ûÁªèÁΩëÁªú (RNN)„ÄÅÂõæÁ•ûÁªèÁΩëÁªú (GNN) Âíå Transformer„ÄÇÊàë‰ª¨ÁöÑÂàÜÊûêË°®ÊòéÔºåËøô‰∫õ‰∏ªÂπ≤Ê®°Âûã‰πãÈó¥ÁöÑÊ†πÊú¨Âå∫Âà´‰∏ªË¶ÅÊ∫ê‰∫éÂÆÉ‰ª¨ÂÆö‰πâÁõ∏‰∫í‰æùËµñÂáΩÊï∞ÁöÑ‰∏çÂêåÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåËøôÁßçÁªü‰∏ÄË°®Á§∫‰∏∫ËÆæËÆ°ÂàõÊñ∞Êû∂ÊûÑÂºÄËæü‰∫ÜÊñ∞ÁöÑÊú∫‰ºöÔºåËøô‰∫õÊû∂ÊûÑÊúâÂèØËÉΩË∂ÖË∂äËøô‰∫õ‰∏ªÂπ≤ÁöÑÊÄßËÉΩ„ÄÇ

##### **LLaSA: Large Language and Structured Data Assistant**
2411.14460v1 by Yao Xu, Shizhu He, Zeng Xiangrong, Jiabei Chen, Guang Liu, Bingning Wang, Jun Zhao, Kang Liu

Structured data, such as tables, graphs, and databases, play a critical role
in plentiful NLP tasks such as question answering and dialogue system.
Recently, inspired by Vision-Language Models, Graph Neutral Networks (GNNs)
have been introduced as an additional modality into the input of Large Language
Models (LLMs) to improve their performance on Structured Knowledge Grounding
(SKG) tasks. However, those GNN-enhanced LLMs have the following limitations:
(1) They employ diverse GNNs to model varying types of structured data,
rendering them unable to uniformly process various forms of structured data.
(2) The pretraining of GNNs is coupled with specific LLMs, which prevents GNNs
from fully aligning with the textual space and limits their adaptability to
other LLMs. To address these issues, we propose \textbf{L}arge
\textbf{L}anguage and \textbf{S}tructured Data \textbf{A}ssistant (LLaSA), a
general framework for enhancing LLMs' ability to handle structured data.
Specifically, we represent various types of structured data in a unified
hypergraph format, and use self-supervised learning to pretrain a hypergraph
encoder, and a G-Former compressing encoded hypergraph representations with
cross-attention. The compressed hypergraph representations are appended to the
serialized inputs during training and inference stages of LLMs. Experimental
results on multiple SKG tasks show that our pretrained hypergraph encoder can
adapt to various LLMs and enhance their ability to process different types of
structured data. Besides, LLaSA, with LoRA fine-tuning, outperforms previous
SOTA method using full parameters tuning.

ÊëòË¶ÅÔºö<paragraph>ÁµêÊßãÂåñË≥áÊñôÔºå‰æãÂ¶ÇË°®Ê†º„ÄÅÂúñË°®ÂíåË≥áÊñôÂ∫´ÔºåÂú®Ë±êÂØåÁöÑ NLP ‰ªªÂãô‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤Ôºå‰æãÂ¶ÇÂïèÁ≠îÂíåÂ∞çË©±Á≥ªÁµ±„ÄÇ
ÊúÄËøëÔºåÂèóÂà∞Ë¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÁöÑÂïüÁôºÔºåÂúñÂΩ¢‰∏≠Á´ãÁ∂≤Ë∑Ø (GNN) Â∑≤Ë¢´ÂºïÂÖ•Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËº∏ÂÖ•‰∏≠‰ΩúÁÇ∫‰∏ÄÁ®ÆÈ°çÂ§ñÁöÑÊ®°ÂºèÔºå‰ª•ÊèêÂçáÂÖ∂Âú®ÁµêÊßãÂåñÁü•Ë≠òÂü∫Á§é (SKG) ‰ªªÂãô‰∏äÁöÑË°®Áèæ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õ GNN Â¢ûÂº∑ÁöÑ LLM ÂÖ∑Êúâ‰ª•‰∏ãÈôêÂà∂Ôºö
(1) ÂÆÉÂÄë‰ΩøÁî®‰∏çÂêåÁöÑ GNN ‰æÜÂª∫Ê®°ÂêÑÁ®ÆÁµêÊßãÂåñË≥áÊñôÈ°ûÂûãÔºåÂ∞éËá¥ÂÆÉÂÄëÁÑ°Ê≥ïÁµ±‰∏ÄËôïÁêÜÂêÑÁ®ÆÂΩ¢ÂºèÁöÑÁµêÊßãÂåñË≥áÊñô„ÄÇ
(2) GNN ÁöÑÈ†êË®ìÁ∑¥ËàáÁâπÂÆöÁöÑ LLM ÁµêÂêàÂú®‰∏ÄËµ∑ÔºåÈÄôÊúÉÈòªÊ≠¢ GNN ËàáÊñáÊú¨Á©∫ÈñìÂÆåÂÖ®Â∞çÈΩäÔºå‰∏¶ÈôêÂà∂ÂÖ∂ÈÅ©ÊáâÂÖ∂‰ªñ LLM„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü**L**arge **L**anguage and **S**tructured Data **A**ssistant (LLaSA)Ôºå‰∏ÄÂÄãÁî®ÊñºÂ¢ûÂº∑ LLM ËôïÁêÜÁµêÊßãÂåñË≥áÊñôËÉΩÂäõÁöÑÈÄöÁî®Ê°ÜÊû∂„ÄÇ
ÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄë‰ª•Áµ±‰∏ÄÁöÑË∂ÖÂúñÊ†ºÂºèË°®Á§∫ÂêÑÁ®ÆÁµêÊßãÂåñË≥áÊñôÈ°ûÂûãÔºå‰∏¶‰ΩøÁî®Ëá™ÊàëÁõ£Áù£Â≠∏Áøí‰æÜÈ†êË®ìÁ∑¥Ë∂ÖÂúñÁ∑®Á¢ºÂô®Ôºå‰ª•Âèä‰ΩøÁî®Ë∑®Ê≥®ÊÑèÂäõÂ£ìÁ∏ÆÁ∑®Á¢ºË∂ÖÂúñË°®Á§∫ÁöÑ G-Former„ÄÇÂ£ìÁ∏ÆÁöÑË∂ÖÂúñË°®Á§∫ÊúÉÈôÑÂä†Âà∞ LLM ÁöÑË®ìÁ∑¥ÂíåÊé®Ë´ñÈöéÊÆµÁöÑÂ∫èÂàóÂåñËº∏ÂÖ•‰∏≠„ÄÇÂ§öÂÄã SKG ‰ªªÂãôÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÈ†êË®ìÁ∑¥ÁöÑË∂ÖÂúñÁ∑®Á¢ºÂô®ÂèØ‰ª•ÈÅ©ÊáâÂêÑÁ®Æ LLMÔºå‰∏¶Â¢ûÂº∑ÂÖ∂ËôïÁêÜ‰∏çÂêåÈ°ûÂûãÁµêÊßãÂåñË≥áÊñôÁöÑËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåLLaSA ‰ΩøÁî® LoRA ÂæÆË™øÔºåÂÑ™Êñº‰ΩøÁî®ÂÖ®ÂèÉÊï∏ÂæÆË™øÁöÑÂÖàÂâç SOTA ÊñπÊ≥ï„ÄÇ</paragraph>

##### **Unveiling User Preferences: A Knowledge Graph and LLM-Driven Approach for Conversational Recommendation**
2411.14459v1 by Zhangchi Qiu, Linhao Luo, Shirui Pan, Alan Wee-Chung Liew

Conversational Recommender Systems (CRSs) aim to provide personalized
recommendations through dynamically capturing user preferences in interactive
conversations. Conventional CRSs often extract user preferences as hidden
representations, which are criticized for their lack of interpretability. This
diminishes the transparency and trustworthiness of the recommendation process.
Recent works have explored combining the impressive capabilities of Large
Language Models (LLMs) with the domain-specific knowledge of Knowledge Graphs
(KGs) to generate human-understandable recommendation explanations. Despite
these efforts, the integration of LLMs and KGs for CRSs remains challenging due
to the modality gap between unstructured dialogues and structured KGs.
Moreover, LLMs pre-trained on large-scale corpora may not be well-suited for
analyzing user preferences, which require domain-specific knowledge. In this
paper, we propose COMPASS, a plug-and-play framework that synergizes LLMs and
KGs to unveil user preferences, enhancing the performance and explainability of
existing CRSs. To address integration challenges, COMPASS employs a two-stage
training approach: first, it bridges the gap between the structured KG and
natural language through an innovative graph entity captioning pre-training
mechanism. This enables the LLM to transform KG entities into concise natural
language descriptions, allowing them to comprehend domain-specific knowledge.
Following, COMPASS optimizes user preference modeling via knowledge-aware
instruction fine-tuning, where the LLM learns to reason and summarize user
preferences from both dialogue histories and KG-augmented context. This enables
COMPASS to perform knowledge-aware reasoning and generate comprehensive and
interpretable user preferences that can seamlessly integrate with existing CRS
models for improving recommendation performance and explainability.

ÊëòË¶ÅÔºöÂ∞çË©±ÂºèÊé®Ëñ¶Á≥ªÁµ± (CRS) Êó®Âú®ÈÄèÈÅéÂãïÊÖãÊçïÊçâ‰∫íÂãïÂ∞çË©±‰∏≠ÁöÑ‰ΩøÁî®ËÄÖÂÅèÂ•ΩÔºåÊèê‰æõÂÄã‰∫∫ÂåñÊé®Ëñ¶„ÄÇÂÇ≥Áµ±ÁöÑ CRS ÈÄöÂ∏∏ÊúÉÂ∞á‰ΩøÁî®ËÄÖÂÅèÂ•ΩÊì∑ÂèñÁÇ∫Èö±ËóèÂºèË°®ÂæµÔºåËÄåÂÖ∂Áº∫ÈªûÂú®ÊñºÁº∫‰πèÂèØËß£ÈáãÊÄßÔºåÈÄôÈôç‰Ωé‰∫ÜÊé®Ëñ¶Á®ãÂºèÁöÑÈÄèÊòéÂ∫¶ÂíåÂèØ‰ø°Â∫¶„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Êé¢Ë®éÂ∞áÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂº∑Â§ßÂäüËÉΩËàáÁü•Ë≠òÂúñË≠ú (KG) ÁöÑÁâπÂÆöÈ†òÂüüÁü•Ë≠òÁµêÂêàÔºå‰ª•Áî¢Áîü‰∫∫È°ûÂèØ‰ª•ÁêÜËß£ÁöÑÊé®Ëñ¶Ë™™Êòé„ÄÇÂÑòÁÆ°ÊúâÈÄô‰∫õÂä™ÂäõÔºåÁî±ÊñºÈùûÁµêÊßãÂåñÂ∞çË©±ÂíåÁµêÊßãÂåñ KG ‰πãÈñìÁöÑÊ®°ÂºèÂ∑ÆÁï∞ÔºåLLM Âíå KG Âú® CRS ‰∏≠ÁöÑÊï¥Âêà‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊ≠§Â§ñÔºåÈáùÂ∞çÂ§ßÂûãË™ûÊñôÂ∫´È†êÂÖàË®ìÁ∑¥ÁöÑ LLM ÂèØËÉΩ‰∏çÈÅ©ÂêàÂàÜÊûê‰ΩøÁî®ËÄÖÂÅèÂ•ΩÔºåÂõ†ÁÇ∫ÈÄôÈúÄË¶ÅÁâπÂÆöÈ†òÂüüÁöÑÁü•Ë≠ò„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ COMPASSÔºåÈÄôÊòØ‰∏ÄÂÄãÂç≥ÊèíÂç≥Áî®ÁöÑÊû∂ÊßãÔºåÂÆÉÂçîÂêåÈÅãÁî® LLM Âíå KG ‰æÜÊè≠Á§∫‰ΩøÁî®ËÄÖÂÅèÂ•ΩÔºåÂ¢ûÂº∑ÁèæÊúâ CRS ÁöÑÊïàËÉΩÂíåÂèØËß£ÈáãÊÄß„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÊï¥ÂêàÊåëÊà∞ÔºåCOMPASS Êé°Áî®‰∫ÜÂÖ©ÈöéÊÆµÁöÑË®ìÁ∑¥ÊñπÊ≥ïÔºöÈ¶ñÂÖàÔºåÂÆÉÈÄèÈÅéÂâµÊñ∞ÁöÑÂúñÂΩ¢ÂØ¶È´îÊ®ôÈ°åÈ†êË®ìÁ∑¥Ê©üÂà∂ÔºåÂΩåÂêàÁµêÊßãÂåñ KG ÂíåËá™ÁÑ∂Ë™ûË®Ä‰πãÈñìÁöÑÂ∑ÆË∑ù„ÄÇÈÄôËÆì LLM ËÉΩÂ§†Â∞á KG ÂØ¶È´îËΩâÊèõÁÇ∫Á∞°ÊΩîÁöÑËá™ÁÑ∂Ë™ûË®ÄÊèèËø∞ÔºåËÆìÂÆÉÂÄëËÉΩÂ§†ÁêÜËß£ÁâπÂÆöÈ†òÂüüÁöÑÁü•Ë≠ò„ÄÇÊé•‰∏ã‰æÜÔºåCOMPASS ÈÄèÈÅéÁü•Ë≠òÊÑüÁü•Êåá‰ª§ÂæÆË™ø‰æÜÊúÄ‰Ω≥Âåñ‰ΩøÁî®ËÄÖÂÅèÂ•ΩÂª∫Ê®°ÔºåÂÖ∂‰∏≠ LLM Â≠∏ÁøíÂæûÂ∞çË©±Ë®òÈåÑÂíå KG Êì¥ÂÖÖÁöÑÂÖßÂÆπ‰∏≠Êé®Ë´ñÂíåÁ∏ΩÁµê‰ΩøÁî®ËÄÖÂÅèÂ•Ω„ÄÇÈÄôËÆì COMPASS ËÉΩÂ§†Âü∑Ë°åÁü•Ë≠òÊÑüÁü•Êé®ÁêÜÔºå‰∏¶Áî¢ÁîüÂÖ®Èù¢‰∏îÂèØËß£ÈáãÁöÑ‰ΩøÁî®ËÄÖÂÅèÂ•ΩÔºåÈÄô‰∫õÂÅèÂ•ΩÂèØ‰ª•ÁÑ°Á∏´Êï¥ÂêàÂà∞ÁèæÊúâÁöÑ CRS Ê®°Âûã‰∏≠Ôºå‰ª•ÊîπÂñÑÊé®Ëñ¶ÊïàËÉΩÂíåÂèØËß£ÈáãÊÄß„ÄÇ

##### **A Novel Approach to Eliminating Hallucinations in Large Language Model-Assisted Causal Discovery**
2411.12759v1 by Grace Sng, Yanming Zhang, Klaus Mueller

The increasing use of large language models (LLMs) in causal discovery as a
substitute for human domain experts highlights the need for optimal model
selection. This paper presents the first hallucination survey of popular LLMs
for causal discovery. We show that hallucinations exist when using LLMs in
causal discovery so the choice of LLM is important. We propose using Retrieval
Augmented Generation (RAG) to reduce hallucinations when quality data is
available. Additionally, we introduce a novel method employing multiple LLMs
with an arbiter in a debate to audit edges in causal graphs, achieving a
comparable reduction in hallucinations to RAG.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Âõ†ÊûúÁôºÁèæ‰∏≠‰ΩúÁÇ∫‰∫∫È°ûÈ†òÂüüÂ∞àÂÆ∂ÁöÑÊõø‰ª£ÂìÅ‰ΩøÁî®Êó•ÁõäÂ¢ûÂä†ÔºåÈÄôÂá∏È°Ø‰∫ÜÊúÄ‰Ω≥Ê®°ÂûãÈÅ∏ÊìáÁöÑÈúÄÊ±Ç„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜÁ¨¨‰∏Ä‰ªΩÊµÅË°å LLM ÁöÑÂπªË¶∫Ë™øÊü•‰ª•ÈÄ≤Ë°åÂõ†ÊûúÁôºÁèæ„ÄÇÊàëÂÄëË°®ÊòéÂú®Âõ†ÊûúÁôºÁèæ‰∏≠‰ΩøÁî® LLM ÊôÇÂ≠òÂú®ÂπªË¶∫ÔºåÂõ†Ê≠§ LLM ÁöÑÈÅ∏ÊìáÂæàÈáçË¶Å„ÄÇÊàëÂÄëÂª∫Ë≠∞‰ΩøÁî®Ê™¢Á¥¢Âº∑ÂåñÁîüÊàê (RAG) ‰æÜÊ∏õÂ∞ëÂú®ÊúâÂìÅË≥™Ë≥áÊñôÊôÇÁî¢ÁîüÁöÑÂπªË¶∫„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ïÔºåÂú®ËæØË´ñ‰∏≠‰ΩøÁî®Â§öÂÄã LLM Âíå‰ª≤Ë£ÅËÄÖ‰æÜÂØ©Ê†∏Âõ†ÊûúÂúñ‰∏≠ÁöÑÈÇäÁ∑£ÔºåËàá RAG Áõ∏ÊØîÔºåÂπªË¶∫Ê∏õÂ∞ë‰∫ÜË®±Â§ö„ÄÇ

##### **VeriGraph: Scene Graphs for Execution Verifiable Robot Planning**
2411.10446v2 by Daniel Ekpo, Mara Levy, Saksham Suri, Chuong Huynh, Abhinav Shrivastava

Recent advancements in vision-language models (VLMs) offer potential for
robot task planning, but challenges remain due to VLMs' tendency to generate
incorrect action sequences. To address these limitations, we propose VeriGraph,
a novel framework that integrates VLMs for robotic planning while verifying
action feasibility. VeriGraph employs scene graphs as an intermediate
representation, capturing key objects and spatial relationships to improve plan
verification and refinement. The system generates a scene graph from input
images and uses it to iteratively check and correct action sequences generated
by an LLM-based task planner, ensuring constraints are respected and actions
are executable. Our approach significantly enhances task completion rates
across diverse manipulation scenarios, outperforming baseline methods by 58%
for language-based tasks and 30% for image-based tasks.

ÊëòË¶ÅÔºöË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÁÇ∫Ê©üÂô®‰∫∫‰ªªÂãôË¶èÂäÉÊèê‰æõ‰∫ÜÊΩõÂäõÔºå‰ΩÜÁî±Êñº VLM ÂÇæÂêëÊñºÁîüÊàê‰∏çÊ≠£Á¢∫ÁöÑÂãï‰ΩúÂ∫èÂàóÔºåÂõ†Ê≠§‰ªçÂ≠òÂú®ÊåëÊà∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü VeriGraphÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÊû∂ÊßãÔºåÂÆÉÊï¥Âêà‰∫Ü VLM ‰ª•ÈÄ≤Ë°åÊ©üÂô®‰∫∫Ë¶èÂäÉÔºåÂêåÊôÇÈ©óË≠âÂãï‰ΩúÁöÑÂèØË°åÊÄß„ÄÇVeriGraph ‰ΩøÁî®Â†¥ÊôØÂúñ‰ΩúÁÇ∫‰∏≠ÈñìË°®Á§∫ÔºåÊì∑ÂèñÈóúÈçµÁâ©‰ª∂ÂíåÁ©∫ÈñìÈóú‰øÇ‰ª•ÊîπÂñÑË®àÁï´È©óË≠âÂíåÁ≤æÁÖâ„ÄÇÁ≥ªÁµ±ÂæûËº∏ÂÖ•ÂΩ±ÂÉè‰∏≠ÁîüÊàêÂ†¥ÊôØÂúñÔºå‰∏¶‰ΩøÁî®ÂÆÉ‰æÜÂèçË¶ÜÊ™¢Êü•Âíå‰øÆÊ≠£Áî±Âü∫Êñº LLM ÁöÑ‰ªªÂãôË¶èÂäÉÂô®Áî¢ÁîüÁöÑÂãï‰ΩúÂ∫èÂàóÔºåÁ¢∫‰øùÈÅµÂÆàÁ¥ÑÊùü‰∏îÂãï‰ΩúÂèØÂü∑Ë°å„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂ§ßÂπÖÊèêÈ´ò‰∫ÜÂú®ÂêÑÁ®ÆÊìç‰ΩúÂ†¥ÊôØ‰∏≠ÁöÑ‰ªªÂãôÂÆåÊàêÁéáÔºåÂú®Âü∫ÊñºË™ûË®ÄÁöÑ‰ªªÂãô‰∏≠ÂÑ™ÊñºÂü∫Á∑öÊñπÊ≥ï 58%ÔºåÂú®Âü∫ÊñºÂΩ±ÂÉèÁöÑ‰ªªÂãô‰∏≠ÂÑ™Êñº 30%„ÄÇ

##### **A Survey of Event Causality Identification: Principles, Taxonomy, Challenges, and Assessment**
2411.10371v2 by Qing Cheng, Zefan Zeng, Xingchen Hu, Yuehang Si, Zhong Liu

Event Causality Identification (ECI) has become a crucial task in Natural
Language Processing (NLP), aimed at automatically extracting causalities from
textual data. In this survey, we systematically address the foundational
principles, technical frameworks, and challenges of ECI, offering a
comprehensive taxonomy to categorize and clarify current research
methodologies, as well as a quantitative assessment of existing models. We
first establish a conceptual framework for ECI, outlining key definitions,
problem formulations, and evaluation standards. Our taxonomy classifies ECI
methods according to the two primary tasks of sentence-level (SECI) and
document-level (DECI) event causality identification. For SECI, we examine
feature pattern-based matching, deep semantic encoding, causal knowledge
pre-training and prompt-based fine-tuning, and external knowledge enhancement
methods. For DECI, we highlight approaches focused on event graph reasoning and
prompt-based techniques to address the complexity of cross-sentence causal
inference. Additionally, we analyze the strengths, limitations, and open
challenges of each approach. We further conduct an extensive quantitative
evaluation of various ECI methods on two benchmark datasets. Finally, we
explore future research directions, highlighting promising pathways to overcome
current limitations and broaden ECI applications.

ÊëòË¶ÅÔºö‰∫ã‰ª∂Âõ†ÊûúÈóú‰øÇË≠òÂà• (ECI) Â∑≤ÊàêÁÇ∫Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰∏≠‰∏ÄÈ†ÖËá≥ÈóúÈáçË¶ÅÁöÑ‰ªªÂãôÔºåÊó®Âú®ÂæûÊñáÊú¨Ë≥áÊñô‰∏≠Ëá™ÂãïËêÉÂèñÂõ†ÊûúÈóú‰øÇ„ÄÇÂú®Ê≠§Ë™øÊü•‰∏≠ÔºåÊàëÂÄëÁ≥ªÁµ±ÊÄßÂú∞Êé¢Ë®é ECI ÁöÑÂü∫Á§éÂéüÁêÜ„ÄÅÊäÄË°ìÊû∂ÊßãÂíåÊåëÊà∞ÔºåÊèê‰æõ‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÂàÜÈ°ûÊ≥ï‰æÜÂàÜÈ°ûÂíåÈáêÊ∏ÖÁï∂ÂâçÁöÑÁ†îÁ©∂ÊñπÊ≥ïÔºå‰ª•ÂèäÂ∞çÁèæÊúâÊ®°ÂûãÁöÑÈáèÂåñË©ï‰º∞„ÄÇÊàëÂÄëÈ¶ñÂÖàÁÇ∫ ECI Âª∫Á´ã‰∏ÄÂÄãÊ¶ÇÂøµÊ°ÜÊû∂ÔºåÊ¶ÇËø∞ÈóúÈçµÂÆöÁæ©„ÄÅÂïèÈ°åË°®Ëø∞ÂíåË©ï‰º∞Ê®ôÊ∫ñ„ÄÇÊàëÂÄëÁöÑÂàÜÈ°ûÊ≥ïÊ†πÊìöÂè•Â≠êÂ±§Á¥ö (SECI) ÂíåÊñá‰ª∂Â±§Á¥ö (DECI) ‰∫ã‰ª∂Âõ†ÊûúÈóú‰øÇË≠òÂà•ÈÄôÂÖ©ÂÄã‰∏ªË¶Å‰ªªÂãôÔºåÂ∞ç ECI ÊñπÊ≥ïÈÄ≤Ë°åÂàÜÈ°û„ÄÇÂ∞çÊñº SECIÔºåÊàëÂÄëÊ™¢Ë¶ñÂü∫ÊñºÁâπÂæµÊ®°ÂºèÁöÑÊØîÂ∞ç„ÄÅÊ∑±Â∫¶Ë™ûÊÑèÁ∑®Á¢º„ÄÅÂõ†ÊûúÁü•Ë≠òÈ†êË®ìÁ∑¥ÂíåÂü∫ÊñºÊèêÁ§∫ÁöÑÂæÆË™øÔºå‰ª•ÂèäÂ§ñÈÉ®Áü•Ë≠òÂ¢ûÂº∑ÊñπÊ≥ï„ÄÇÂ∞çÊñº DECIÔºåÊàëÂÄëÂº∑Ë™ø‰ª•‰∫ã‰ª∂ÂúñÊé®Ë´ñÂíåÂü∫ÊñºÊèêÁ§∫ÁöÑÊäÄË°ìÁÇ∫ÈáçÈªûÁöÑÊñπÊ≥ïÔºå‰ª•Ëß£Ê±∫Ë∑®Âè•Â≠êÂõ†ÊûúÊé®Ë´ñÁöÑË§áÈõúÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂàÜÊûêÊØèÁ®ÆÊñπÊ≥ïÁöÑÂÑ™Èªû„ÄÅÈôêÂà∂ÂíåÈñãÊîæÊÄßÊåëÊà∞„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Â∞çÂêÑÁ®Æ ECI ÊñπÊ≥ïÂú®ÂÖ©ÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂª£Ê≥õÁöÑÈáèÂåñË©ï‰º∞„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊé¢Ë®éÊú™‰æÜÁöÑÁ†îÁ©∂ÊñπÂêëÔºåÂº∑Ë™øÊúâÂ∏åÊúõÂÖãÊúçÁï∂ÂâçÈôêÂà∂ÂíåÊì¥Â±ï ECI ÊáâÁî®Á®ãÂºèÁöÑÈÄîÂæë„ÄÇ

##### **Prompting and Fine-tuning Large Language Models for Automated Code Review Comment Generation**
2411.10129v1 by Md. Asif Haider, Ayesha Binte Mostofa, Sk. Sabit Bin Mosaddek, Anindya Iqbal, Toufique Ahmed

Generating accurate code review comments remains a significant challenge due
to the inherently diverse and non-unique nature of the task output. Large
language models pretrained on both programming and natural language data tend
to perform well in code-oriented tasks. However, large-scale pretraining is not
always feasible due to its environmental impact and project-specific
generalizability issues. In this work, first we fine-tune open-source Large
language models (LLM) in parameter-efficient, quantized low-rank (QLoRA)
fashion on consumer-grade hardware to improve review comment generation. Recent
studies demonstrate the efficacy of augmenting semantic metadata information
into prompts to boost performance in other code-related tasks. To explore this
in code review activities, we also prompt proprietary, closed-source LLMs
augmenting the input code patch with function call graphs and code summaries.
Both of our strategies improve the review comment generation performance, with
function call graph augmented few-shot prompting on the GPT-3.5 model
surpassing the pretrained baseline by around 90% BLEU-4 score on the
CodeReviewer dataset. Moreover, few-shot prompted Gemini-1.0 Pro, QLoRA
fine-tuned Code Llama and Llama 3.1 models achieve competitive results (ranging
from 25% to 83% performance improvement) on this task. An additional human
evaluation study further validates our experimental findings, reflecting
real-world developers' perceptions of LLM-generated code review comments based
on relevant qualitative metrics.

ÊëòË¶ÅÔºö<paragraph>Áî¢ÁîüÊ∫ñÁ¢∫ÁöÑÁ®ãÂºèÁ¢ºÂØ©Êü•Ë©ïË´ñ‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÈáçÂ§ßÊåëÊà∞ÔºåÂõ†ÁÇ∫‰ªªÂãôËº∏Âá∫ÁöÑÊú¨Ë≥™‰∏äÊòØÂ§öÊ®£‰∏îÈùûÁç®ÁâπÁöÑ„ÄÇÂú®Á®ãÂºèË®≠Ë®àÂíåËá™ÁÑ∂Ë™ûË®ÄË≥áÊñô‰∏äÈÄ≤Ë°åÈ†êË®ìÁ∑¥ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂæÄÂæÄÂú®‰ª•Á®ãÂºèÁ¢ºÁÇ∫Â∞éÂêëÁöÑ‰ªªÂãô‰∏≠Ë°®ÁèæËâØÂ•Ω„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÂÖ∂Â∞çÁí∞Â¢ÉÁöÑÂΩ±ÈüøÂíåÂ∞àÊ°àÁâπÂÆöÁöÑ‰∏ÄËà¨ÂåñÂïèÈ°åÔºåÂ§ßË¶èÊ®°È†êË®ìÁ∑¥‰∏¶ÈùûÁ∏ΩÊòØÂèØË°åÁöÑ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖàÂú®ÂèÉÊï∏ÊúâÊïà„ÄÅÈáèÂåñÁöÑ‰ΩéÁß© (QLoRA) ÊñπÂºè‰∏≠ÂæÆË™øÈñãÊ∫êÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÂú®Ê∂àË≤ªÁ¥öÁ°¨È´î‰∏äÊîπÂñÑÂØ©Êü•Ë©ïË´ñÁöÑÁî¢Áîü„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Ë≠âÊòé‰∫ÜÂú®ÊèêÁ§∫‰∏≠Â¢ûÂä†Ë™ûÁæ©ÂÖÉË≥áÊñôË≥áË®ä‰ª•ÊèêÂçáÂÖ∂‰ªñËàáÁ®ãÂºèÁ¢ºÁõ∏Èóú‰ªªÂãô‰∏≠ÊïàËÉΩÁöÑÂäüÊïà„ÄÇÁÇ∫‰∫ÜÂú®Á®ãÂºèÁ¢ºÂØ©Êü•Ê¥ªÂãï‰∏≠Êé¢Á¥¢ÈÄô‰∏ÄÈªûÔºåÊàëÂÄë‰πüÊèêÁ§∫Â∞àÊúâÁöÑ„ÄÅÈñâÊ∫ê LLMÔºå‰ΩøÁî®ÂáΩÊï∏ÂëºÂè´ÂúñÂíåÁ®ãÂºèÁ¢ºÊëòË¶Å‰æÜÂ¢ûÂä†Ëº∏ÂÖ•Á®ãÂºèÁ¢º‰øÆË£úÁ®ãÂºè„ÄÇÊàëÂÄëÁöÑÂÖ©Á®ÆÁ≠ñÁï•ÈÉΩÊîπÂñÑ‰∫ÜÂØ©Êü•Ë©ïË´ñÁî¢ÁîüÁöÑÊïàËÉΩÔºåÂú® GPT-3.5 Ê®°Âûã‰∏ä‰ΩøÁî®ÂáΩÊï∏ÂëºÂè´ÂúñÂ¢ûÂä†ÁöÑÂ∞ëÈáèÊèêÁ§∫ÔºåÂú® CodeReviewer Ë≥áÊñôÈõÜ‰∏äË∂ÖË∂ä‰∫ÜÈ†êË®ìÁ∑¥Âü∫Ê∫ñÔºåBLEU-4 ÂàÜÊï∏ÊèêÈ´ò‰∫ÜÁ¥Ñ 90%„ÄÇÊ≠§Â§ñÔºåÂ∞ëÈáèÊèêÁ§∫ÁöÑ Gemini-1.0 Pro„ÄÅQLoRA ÂæÆË™øÁöÑ Code Llama Âíå Llama 3.1 Ê®°ÂûãÂú®Ê≠§‰ªªÂãô‰∏äÈÅîÂà∞‰∫ÜÊúâÁ´∂Áà≠ÂäõÁöÑÁµêÊûúÔºàÊïàËÉΩÊèêÂçáÁØÑÂúçÁÇ∫ 25% Ëá≥ 83%Ôºâ„ÄÇÈ°çÂ§ñÁöÑ‰ΩøÁî®ËÄÖË©ï‰º∞Á†îÁ©∂ÈÄ≤‰∏ÄÊ≠•È©óË≠â‰∫ÜÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúÔºåÂèçÊò†‰∫ÜÂØ¶ÈöõÈñãÁôº‰∫∫Âì°Â∞ç LLM Áî¢ÁîüÁöÑÁ®ãÂºèÁ¢ºÂØ©Êü•Ë©ïË´ñÁöÑÁúãÊ≥ïÔºåÈÄô‰∫õÁúãÊ≥ïÂü∫ÊñºÁõ∏ÈóúÁöÑÂÆöÊÄßÊåáÊ®ô„ÄÇ</paragraph>

##### **HistoLens: An LLM-Powered Framework for Multi-Layered Analysis of Historical Texts -- A Case Application of Yantie Lun**
2411.09978v1 by Yifan Zeng

This paper proposes HistoLens, a multi-layered analysis framework for
historical texts based on Large Language Models (LLMs). Using the important
Western Han dynasty text "Yantie Lun" as a case study, we demonstrate the
framework's potential applications in historical research and education.
HistoLens integrates NLP technology (especially LLMs), including named entity
recognition, knowledge graph construction, and geographic information
visualization. The paper showcases how HistoLens explores Western Han culture
in "Yantie Lun" through multi-dimensional, visual, and quantitative methods,
focusing particularly on the influence of Confucian and Legalist thoughts on
political, economic, military, and ethnic. We also demonstrate how HistoLens
constructs a machine teaching scenario using LLMs for explainable analysis,
based on a dataset of Confucian and Legalist ideas extracted with LLM
assistance. This approach offers novel and diverse perspectives for studying
historical texts like "Yantie Lun" and provides new auxiliary tools for history
education. The framework aims to equip historians and learners with
LLM-assisted tools to facilitate in-depth, multi-layered analysis of historical
texts and foster innovation in historical education.

ÊëòË¶ÅÔºöÊú¨ÊñáÊèêÂá∫ HistoLensÔºå‰∏ÄÂÄãÂü∫ÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂ§öÂ±§ÂàÜÊûêÊû∂ÊßãÔºåÁî®ÊñºÊ≠∑Âè≤ÊñáÊú¨„ÄÇ‰ΩøÁî®ÈáçË¶ÅÁöÑË•øÊº¢ÁéãÊúùÊñáÊú¨„ÄåÈπΩÈêµË´ñ„Äç‰ΩúÁÇ∫ÂÄãÊ°àÁ†îÁ©∂ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜË©≤Êû∂ÊßãÂú®Ê≠∑Âè≤Á†îÁ©∂ÂíåÊïôËÇ≤‰∏≠ÁöÑÊΩõÂú®ÊáâÁî®„ÄÇHistoLens Êï¥Âêà‰∫Ü NLP ÊäÄË°ìÔºàÂ∞§ÂÖ∂ÊòØ LLMÔºâÔºåÂåÖÊã¨ÂëΩÂêçÂØ¶È´îË≠òÂà•„ÄÅÁü•Ë≠òÂúñË≠úÂª∫ÊßãÂíåÂú∞ÁêÜË≥áË®äË¶ñË¶∫Âåñ„ÄÇÊú¨ÊñáÂ±ïÁ§∫‰∫Ü HistoLens Â¶Ç‰ΩïÈÄèÈÅéÂ§öÁ∂≠Â∫¶„ÄÅË¶ñË¶∫ÂåñÂíåÈáèÂåñÊñπÊ≥ïÊé¢Á¥¢„ÄåÈπΩÈêµË´ñ„Äç‰∏≠ÁöÑË•øÊº¢ÊñáÂåñÔºåÁâπÂà•ÈóúÊ≥®ÂÑíÂÆ∂ÂíåÊ≥ïÂÆ∂ÊÄùÊÉ≥Â∞çÊîøÊ≤ª„ÄÅÁ∂ìÊøü„ÄÅËªç‰∫ãÂíåÁ®ÆÊóèÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÈÇÑÂ±ïÁ§∫‰∫Ü HistoLens Â¶Ç‰ΩïÂª∫Êßã‰∏ÄÂÄã‰ΩøÁî® LLM ÁöÑÊ©üÂô®ÊïôÂ≠∏Â†¥ÊôØÔºå‰ª•ÈÄ≤Ë°åÂèØËß£ÈáãÂàÜÊûêÔºåÈÄôÊòØÂü∫Êñº LLM ÂçîÂä©ÊèêÂèñÁöÑÂÑíÂÆ∂ÂíåÊ≥ïÂÆ∂ÊÄùÊÉ≥Ë≥áÊñôÈõÜ„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÁÇ∫Á†îÁ©∂„ÄåÈπΩÈêµË´ñ„ÄçÁ≠âÊ≠∑Âè≤ÊñáÊú¨Êèê‰æõ‰∫ÜÊñ∞Á©é‰∏îÂ§öÊ®£ÂåñÁöÑËßÄÈªûÔºå‰∏¶ÁÇ∫Ê≠∑Âè≤ÊïôËÇ≤Êèê‰æõ‰∫ÜÊñ∞ÁöÑËºîÂä©Â∑•ÂÖ∑„ÄÇË©≤Êû∂ÊßãÊó®Âú®ÁÇ∫Ê≠∑Âè≤Â≠∏ÂÆ∂ÂíåÂ≠∏ÁøíËÄÖÊèê‰æõ LLM ÂçîÂä©ÁöÑÂ∑•ÂÖ∑Ôºå‰ª•Âà©ÊñºÊ∑±ÂÖ•„ÄÅÂ§öÂ±§Ê¨°Âú∞ÂàÜÊûêÊ≠∑Âè≤ÊñáÊú¨Ôºå‰∏¶‰øÉÈÄ≤Ê≠∑Âè≤ÊïôËÇ≤ÁöÑÂâµÊñ∞„ÄÇ

##### **Accelerating Knowledge Graph and Ontology Engineering with Large Language Models**
2411.09601v1 by Cogan Shimizu, Pascal Hitzler

Large Language Models bear the promise of significant acceleration of key
Knowledge Graph and Ontology Engineering tasks, including ontology modeling,
extension, modification, population, alignment, as well as entity
disambiguation. We lay out LLM-based Knowledge Graph and Ontology Engineering
as a new and coming area of research, and argue that modular approaches to
ontologies will be of central importance.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÊâøË´æÂ§ßÂπÖÂä†ÈÄüÈóúÈçµÁü•Ë≠òÂúñË≠úÂíåÊú¨‰ΩìÂ∑•Á®ã‰ªªÂãôÔºåÂåÖÊã¨Êú¨‰ΩìÂª∫Ê®°„ÄÅÊì¥ÂÖÖ„ÄÅ‰øÆÊîπ„ÄÅÂ°´ÂÖÖ„ÄÅÊØîÂ∞ç‰ª•ÂèäÂØ¶È´îÊ∂àÊ≠ß„ÄÇÊàëÂÄëÂ∞á LLM ÁÇ∫Âü∫Á§éÁöÑÁü•Ë≠òÂúñË≠úÂíåÊú¨‰ΩìÂ∑•Á®ãË¶èÂäÉÁÇ∫‰∏ÄÂÄãÊñ∞ËààÁöÑÁ†îÁ©∂È†òÂüüÔºå‰∏¶‰∏ªÂºµÊ®°ÁµÑÂåñÊú¨‰ΩìÊñπÊ≥ïÂ∞áËá≥ÈóúÈáçË¶Å„ÄÇ

##### **Automating Reformulation of Essence Specifications via Graph Rewriting**
2411.09576v1 by Ian Miguel, Andr√°s Z. Salamon, Christopher Stone

Formulating an effective constraint model of a parameterised problem class is
crucial to the efficiency with which instances of the class can subsequently be
solved. It is difficult to know beforehand which of a set of candidate models
will perform best in practice. This paper presents a system that employs graph
rewriting to reformulate an input model for improved performance automatically.
By situating our work in the Essence abstract constraint specification
language, we can use the structure in its high level variable types to trigger
rewrites directly. We implement our system via rewrite rules expressed in the
Graph Programs 2 language, applied to the abstract syntax tree of an input
specification. We show how to automatically translate the solution of the
reformulated problem into a solution of the original problem for verification
and presentation. We demonstrate the efficacy of our system with a detailed
case study.

ÊëòË¶ÅÔºöÂà∂ÂÆö‰∏ÄÂÄãÂèÉÊï∏ÂåñÂïèÈ°åÈ°ûÂà•ÁöÑÊúâÊïàÁ¥ÑÊùüÊ®°ÂûãÂ∞çÊñºÈö®ÂæåÊ±ÇËß£Ë©≤È°ûÂà•ÁöÑÂØ¶‰æãÁöÑÊïàÁéáËá≥ÈóúÈáçË¶Å„ÄÇ‰∫ãÂÖàÂæàÈõ£Áü•ÈÅì‰∏ÄÁµÑÂÄôÈÅ∏Ê®°Âûã‰∏≠Âì™‰∏ÄÂÄãÂú®ÂØ¶Âãô‰∏äË°®ÁèæÊúÄ‰Ω≥„ÄÇÊú¨ÊñáÊèêÂá∫‰∏ÄÂÄãÁ≥ªÁµ±ÔºåÊé°Áî®ÂúñÂΩ¢ÈáçÂØ´‰æÜËá™ÂãïÈáçÊñ∞Âà∂ÂÆöËº∏ÂÖ•Ê®°Âûã‰ª•ÊîπÂñÑÊïàËÉΩ„ÄÇÈÄèÈÅéÂ∞áÊàëÂÄëÁöÑÂ∑•‰ΩúÁΩÆÊñº Essence ÊäΩË±°Á¥ÑÊùüË¶èÁØÑË™ûË®Ä‰∏≠ÔºåÊàëÂÄëÂèØ‰ª•‰ΩøÁî®ÂÖ∂È´òÂ±§Á¥öËÆäÊï∏È°ûÂûã‰∏≠ÁöÑÁµêÊßã‰æÜÁõ¥Êé•Ëß∏ÁôºÈáçÂØ´„ÄÇÊàëÂÄëÈÄèÈÅé‰ª• Graph Programs 2 Ë™ûË®ÄË°®Á§∫ÁöÑÈáçÂØ´Ë¶èÂâá‰æÜÂØ¶‰ΩúÊàëÂÄëÁöÑÁ≥ªÁµ±ÔºåÊáâÁî®ÊñºËº∏ÂÖ•Ë¶èÁØÑÁöÑÊäΩË±°Ë™ûÊ≥ïÊ®π„ÄÇÊàëÂÄëÂ±ïÁ§∫Â¶Ç‰ΩïËá™ÂãïÂ∞áÈáçÊñ∞Âà∂ÂÆöÂïèÈ°åÁöÑËß£Ê≥ïËΩâÊèõÁÇ∫ÂéüÂßãÂïèÈ°åÁöÑËß£Ê≥ïÔºå‰ª•ÈÄ≤Ë°åÈ©óË≠âÂíåÂëàÁèæ„ÄÇÊàëÂÄëÈÄèÈÅéË©≥Á¥∞ÁöÑÂÄãÊ°àÁ†îÁ©∂‰æÜÂ±ïÁ§∫ÊàëÂÄëÁ≥ªÁµ±ÁöÑÊïàËÉΩ„ÄÇ

##### **Towards Evaluating Large Language Models for Graph Query Generation**
2411.08449v2 by Siraj Munir, Alessandro Aldini

Large Language Models (LLMs) are revolutionizing the landscape of Generative
Artificial Intelligence (GenAI), with innovative LLM-backed solutions emerging
rapidly. However, when applied to database technologies, specifically query
generation for graph databases and Knowledge Graphs (KGs), LLMs still face
significant challenges. While research on LLM-driven query generation for
Structured Query Language (SQL) exists, similar systems for graph databases
remain underdeveloped. This paper presents a comparative study addressing the
challenge of generating Cypher queries a powerful language for interacting with
graph databases using open-access LLMs. We rigorously evaluate several LLM
agents (OpenAI ChatGPT 4o, Claude Sonnet 3.5, Google Gemini Pro 1.5, and a
locally deployed Llama 3.1 8B) using a designed few-shot learning prompt and
Retrieval Augmented Generation (RAG) backed by Chain-of-Thoughts (CoT)
reasoning. Our empirical analysis of query generation accuracy reveals that
Claude Sonnet 3.5 outperforms its counterparts in this specific domain.
Further, we highlight promising future research directions to address the
identified limitations and advance LLM-driven query generation for graph
databases.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ê≠£Âú®Èù©Êñ∞ÁîüÊàêÂºè‰∫∫Â∑•Êô∫ÊÖß (GenAI) ÁöÑÈ†òÂüüÔºåÂâµÊñ∞ÁöÑ LLM ÊîØÊåÅËß£Ê±∫ÊñπÊ°àËøÖÈÄüÊπßÁèæ„ÄÇÁÑ∂ËÄåÔºåÁï∂ÊáâÁî®ÊñºË≥áÊñôÂ∫´ÊäÄË°ìÔºåÁâπÂà•ÊòØÂúñÂΩ¢Ë≥áÊñôÂ∫´ÂíåÁü•Ë≠òÂúñË≠ú (KG) ÁöÑÊü•Ë©¢Áî¢ÁîüÊôÇÔºåLLM ‰ªçÁÑ∂Èù¢Ëá®ÈáçÂ§ßÊåëÊà∞„ÄÇÈõñÁÑ∂Â≠òÂú®ÈáùÂ∞çÁµêÊßãÂåñÊü•Ë©¢Ë™ûË®Ä (SQL) ÁöÑ LLM È©ÖÂãïÊü•Ë©¢Áî¢ÁîüÁöÑÁ†îÁ©∂Ôºå‰ΩÜÂúñÂΩ¢Ë≥áÊñôÂ∫´ÁöÑÈ°û‰ººÁ≥ªÁµ±‰ªçÊú™ÂÖÖÂàÜÁôºÂ±ï„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÈ†ÖÊØîËºÉÁ†îÁ©∂Ôºå‰ª•Ëß£Ê±∫‰ΩøÁî®ÈñãÊîæÂºè LLM Áî¢Áîü Cypher Êü•Ë©¢ÁöÑÊåëÊà∞ÔºåCypher Êü•Ë©¢ÊòØ‰∏ÄÁ®ÆÁî®ÊñºËàáÂúñÂΩ¢Ë≥áÊñôÂ∫´‰∫íÂãïÁöÑÂº∑Â§ßË™ûË®Ä„ÄÇÊàëÂÄë‰ΩøÁî®Ë®≠Ë®àÁöÑÂ∞ëÈáèÂ≠∏ÁøíÊèêÁ§∫ÂíåÁî±ÊÄùÊÉ≥Èèà (CoT) Êé®ÁêÜÊîØÊåÅÁöÑÊ™¢Á¥¢Êì¥ÂÖÖÁîüÊàê (RAG) Âö¥Ê†ºË©ï‰º∞‰∫ÜÂ§öÂÄã LLM ‰ª£ÁêÜÔºàOpenAI ChatGPT 4o„ÄÅClaude Sonnet 3.5„ÄÅGoogle Gemini Pro 1.5 ÂíåÊú¨Âú∞ÈÉ®ÁΩ≤ÁöÑ Llama 3.1 8BÔºâ„ÄÇÊàëÂÄëÂ∞çÊü•Ë©¢Áî¢ÁîüÊ∫ñÁ¢∫ÊÄßÁöÑÂØ¶Ë≠âÂàÜÊûêË°®ÊòéÔºåClaude Sonnet 3.5 Âú®ÈÄôÂÄãÁâπÂÆöÈ†òÂüüÂÑ™ÊñºÂÖ∂ÂêåÈ°ûÁî¢ÂìÅ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈáçÈªû‰ªãÁ¥π‰∫ÜÊúâÂ∏åÊúõÁöÑÊú™‰æÜÁ†îÁ©∂ÊñπÂêëÔºå‰ª•Ëß£Ê±∫Â∑≤Ë≠òÂà•ÁöÑÈôêÂà∂‰∏¶Êé®ÈÄ≤ LLM È©ÖÂãïÁöÑÂúñÂΩ¢Ë≥áÊñôÂ∫´Êü•Ë©¢Áî¢Áîü„ÄÇ

##### **Knowledge Bases in Support of Large Language Models for Processing Web News**
2411.08278v2 by Yihe Zhang, Nabin Pakka, Nian-Feng Tzeng

Large Language Models (LLMs) have received considerable interest in wide
applications lately. During pre-training via massive datasets, such a model
implicitly memorizes the factual knowledge of trained datasets in its hidden
parameters. However, knowledge held implicitly in parameters often makes its
use by downstream applications ineffective due to the lack of common-sense
reasoning. In this article, we introduce a general framework that permits to
build knowledge bases with an aid of LLMs, tailored for processing Web news.
The framework applies a rule-based News Information Extractor (NewsIE) to news
items for extracting their relational tuples, referred to as knowledge bases,
which are then graph-convoluted with the implicit knowledge facts of news items
obtained by LLMs, for their classification. It involves two lightweight
components: 1) NewsIE: for extracting the structural information of every news
item, in the form of relational tuples; 2) BERTGraph: for graph convoluting the
implicit knowledge facts with relational tuples extracted by NewsIE. We have
evaluated our framework under different news-related datasets for news category
classification, with promising experimental results.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ëøë‰æÜÂú®Âª£Ê≥õÁöÑÊáâÁî®‰∏≠ÂÇôÂèóÈóúÊ≥®„ÄÇÂú®ÈÄèÈÅéÂ§ßÈáèË≥áÊñôÈõÜÈÄ≤Ë°åÈ†êË®ìÁ∑¥ÊúüÈñìÔºåÊ≠§È°ûÊ®°ÂûãÊúÉÈö±Âê´Âú∞Â∞áË®ìÁ∑¥Ë≥áÊñôÈõÜÁöÑ‰∫ãÂØ¶Áü•Ë≠òË®òÊÜ∂Âú®ÂÖ∂Èö±ËóèÂèÉÊï∏‰∏≠„ÄÇÁÑ∂ËÄåÔºåÈö±Âê´Âú®ÂèÉÊï∏‰∏≠ÁöÑÁü•Ë≠òÈÄöÂ∏∏ÊúÉÂõ†ÁÇ∫Áº∫‰πèÂ∏∏Ë≠òÊé®ÁêÜËÄåÂ∞éËá¥‰∏ãÊ∏∏ÊáâÁî®ÁÑ°Ê≥ïÊúâÊïà‰ΩøÁî®„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÈÄöÁî®Êû∂ÊßãÔºåÂÖÅË®±Âú® LLM ÁöÑÂçîÂä©‰∏ãÂª∫Á´ãÁü•Ë≠òÂ∫´ÔºåÂ∞àÈñÄÁî®ÊñºËôïÁêÜÁ∂≤Ë∑ØÊñ∞ËÅû„ÄÇÊ≠§Êû∂ÊßãÂ∞áÂü∫ÊñºË¶èÂâáÁöÑÊñ∞ËÅûË≥áË®äËêÉÂèñÂô® (NewsIE) Â•óÁî®Âà∞Êñ∞ËÅûÈ†ÖÁõÆÔºå‰ª•ËêÉÂèñÂÖ∂Èóú‰øÇÂÖÉÁµÑÔºàÁ®±ÁÇ∫Áü•Ë≠òÂ∫´ÔºâÔºåÁÑ∂ÂæåÂ∞áÂÖ∂Ëàá LLM ÂèñÂæóÁöÑÊñ∞ËÅûÈ†ÖÁõÆÁöÑÈö±Âê´Áü•Ë≠ò‰∫ãÂØ¶ÈÄ≤Ë°åÂúñÂΩ¢Âç∑Á©çÔºå‰ª•ÈÄ≤Ë°åÂàÜÈ°û„ÄÇÂÆÉÂåÖÂê´ÂÖ©ÂÄãËºïÈáèÁ¥öÂÖÉ‰ª∂Ôºö1) NewsIEÔºöÁî®ÊñºËêÉÂèñÊØèÂÄãÊñ∞ËÅûÈ†ÖÁõÆÁöÑÁµêÊßãÂåñË≥áË®äÔºå‰ª•Èóú‰øÇÂÖÉÁµÑÁöÑÂΩ¢ÂºèÂëàÁèæÔºõ2) BERTGraphÔºöÁî®ÊñºÂ∞á NewsIE ËêÉÂèñÁöÑÈóú‰øÇÂÖÉÁµÑËàáÈö±Âê´Áü•Ë≠ò‰∫ãÂØ¶ÈÄ≤Ë°åÂúñÂΩ¢Âç∑Á©ç„ÄÇÊàëÂÄëÂ∑≤Âú®‰∏çÂêåÁöÑËàáÊñ∞ËÅûÁõ∏ÈóúÁöÑË≥áÊñôÈõÜ‰∏ãË©ï‰º∞ÊàëÂÄëÁöÑÊû∂ÊßãÔºåÁî®ÊñºÊñ∞ËÅûÈ°ûÂà•ÂàÜÈ°ûÔºå‰∏¶Áç≤ÂæóÊúâÂ∏åÊúõÁöÑÂØ¶È©óÁµêÊûú„ÄÇ

##### **Retrieval, Reasoning, Re-ranking: A Context-Enriched Framework for Knowledge Graph Completion**
2411.08165v1 by Muzhi Li, Cehao Yang, Chengjin Xu, Xuhui Jiang, Yiyan Qi, Jian Guo, Ho-fung Leung, Irwin King

The Knowledge Graph Completion~(KGC) task aims to infer the missing entity
from an incomplete triple. Existing embedding-based methods rely solely on
triples in the KG, which is vulnerable to specious relation patterns and
long-tail entities. On the other hand, text-based methods struggle with the
semantic gap between KG triples and natural language. Apart from triples,
entity contexts (e.g., labels, descriptions, aliases) also play a significant
role in augmenting KGs. To address these limitations, we propose KGR3, a
context-enriched framework for KGC. KGR3 is composed of three modules. Firstly,
the Retrieval module gathers supporting triples from the KG, collects plausible
candidate answers from a base embedding model, and retrieves context for each
related entity. Then, the Reasoning module employs a large language model to
generate potential answers for each query triple. Finally, the Re-ranking
module combines candidate answers from the two modules mentioned above, and
fine-tunes an LLM to provide the best answer. Extensive experiments on widely
used datasets demonstrate that KGR3 consistently improves various KGC methods.
Specifically, the best variant of KGR3 achieves absolute Hits@1 improvements of
12.3% and 5.6% on the FB15k237 and WN18RR datasets.

ÊëòË¶ÅÔºöÁü•Ë≠òÂúñË≠úÂÆåÊàêÂäüËÉΩ (KGC) ÁöÑ‰ªªÂãôÊó®Âú®Âæû‰∏çÂÆåÊï¥ÁöÑ 3 ÂÖÉÁµÑ‰∏≠Êé®Êñ∑Âá∫ÈÅ∫Â§±ÁöÑÂØ¶È´î„ÄÇÁèæÊúâÁöÑÂµåÂÖ•ÂºèÊñπÊ≥ïÂÉÖ‰æùË≥¥Êñº KG ‰∏≠ÁöÑ 3 ÂÖÉÁµÑÔºåÈÄôÂÆπÊòìÂèóÂà∞ËôõÂÅáÈóú‰øÇÊ®°ÂºèÂíåÈï∑Â∞æÂØ¶È´îÁöÑÂΩ±Èüø„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÂü∫ÊñºÊñáÊú¨ÁöÑÊñπÊ≥ïÈõ£‰ª•ËôïÁêÜ KG 3 ÂÖÉÁµÑÂíåËá™ÁÑ∂Ë™ûË®Ä‰πãÈñìÁöÑË™ûÁæ©Â∑ÆË∑ù„ÄÇÈô§‰∫Ü 3 ÂÖÉÁµÑ‰πãÂ§ñÔºåÂØ¶È´î‰∏ä‰∏ãÊñáÔºà‰æãÂ¶ÇÊ®ôÁ±§„ÄÅÊèèËø∞„ÄÅÂà•ÂêçÔºâÂú®Êì¥ÂÖÖ KG ‰∏≠‰πüÊâÆÊºîËëóÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü KGR3Ôºå‰∏ÄÂÄãÁî®Êñº KGC ÁöÑ‰∏ä‰∏ãÊñáË±êÂØåÊû∂Êßã„ÄÇKGR3 Áî±‰∏âÂÄãÊ®°ÁµÑÁµÑÊàê„ÄÇÈ¶ñÂÖàÔºåÊ™¢Á¥¢Ê®°ÁµÑÂæû KG ‰∏≠Êî∂ÈõÜÊîØÊè¥ 3 ÂÖÉÁµÑÔºåÂæûÂü∫Á§éÂµåÂÖ•Ê®°Âûã‰∏≠Êî∂ÈõÜÂèØËÉΩÁöÑÂÄôÈÅ∏Á≠îÊ°àÔºå‰∏¶ÁÇ∫ÊØèÂÄãÁõ∏ÈóúÂØ¶È´îÊ™¢Á¥¢‰∏ä‰∏ãÊñá„ÄÇÊé•ËëóÔºåÊé®ÁêÜÊ®°ÁµÑÊé°Áî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÁÇ∫ÊØèÂÄãÊü•Ë©¢ 3 ÂÖÉÁµÑÁîüÊàêÊΩõÂú®Á≠îÊ°à„ÄÇÊúÄÂæåÔºåÈáçÊñ∞ÊéíÂêçÊ®°ÁµÑÂ∞á‰∏äËø∞ÂÖ©ÂÄãÊ®°ÁµÑÁöÑÂÄôÈÅ∏Á≠îÊ°àÁµêÂêàËµ∑‰æÜÔºå‰∏¶ÂæÆË™ø LLM ‰ª•Êèê‰æõÊúÄ‰Ω≥Á≠îÊ°à„ÄÇÂú®Âª£Ê≥õ‰ΩøÁî®ÁöÑË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòéÔºåKGR3 ÊåÅÁ∫åÊîπÈÄ≤ÂêÑÁ®Æ KGC ÊñπÊ≥ï„ÄÇÂÖ∑È´î‰æÜË™™ÔºåKGR3 ÁöÑÊúÄ‰Ω≥ËÆäÈ´îÂú® FB15k237 Âíå WN18RR Ë≥áÊñôÈõÜ‰∏äÂàÜÂà•ÂØ¶Áèæ‰∫Ü 12.3% Âíå 5.6% ÁöÑÁµïÂ∞ç Hits@1 ÊîπÈÄ≤„ÄÇ

##### **Language Models as Causal Effect Generators**
2411.08019v1 by Lucius E. J. Bynum, Kyunghyun Cho

We present a framework for large language model (LLM) based data generation
with controllable causal structure. In particular, we define a procedure for
turning any language model and any directed acyclic graph (DAG) into a
sequence-driven structural causal model (SD-SCM). Broadly speaking, an SD-SCM
is a causal model with user-defined structure and LLM-defined structural
equations. We characterize how an SD-SCM allows sampling from observational,
interventional, and counterfactual distributions according to the desired
causal structure. We then leverage this procedure to propose a new type of
benchmark for causal inference methods, generating individual-level
counterfactual data without needing to manually specify functional
relationships between variables. We create an example benchmark consisting of
thousands of datasets, and test a suite of popular estimation methods on these
datasets for average, conditional average, and individual treatment effect
estimation, both with and without hidden confounding. Apart from generating
data, the same procedure also allows us to test for the presence of a causal
effect that might be encoded in an LLM. This procedure can underpin auditing
LLMs for misinformation, discrimination, or otherwise undesirable behavior. We
believe SD-SCMs can serve as a useful tool in any application that would
benefit from sequential data with controllable causal structure.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑË≥áÊñôÁîüÊàêÊû∂ÊßãÔºåÂÖ∑ÊúâÂèØÊéßÂà∂ÁöÑÂõ†ÊûúÁµêÊßã„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂÆöÁæ©‰∫Ü‰∏ÄÂÄãÁ®ãÂ∫èÔºåÂ∞á‰ªª‰ΩïË™ûË®ÄÊ®°ÂûãÂíå‰ªª‰ΩïÊúâÂêëÁÑ°Áí∞Âúñ (DAG) ËΩâÊèõÊàê‰∏ÄÂÄãÂ∫èÂàóÈ©ÖÂãïÁöÑÁµêÊßãÂõ†ÊûúÊ®°Âûã (SD-SCM)„ÄÇÂª£Áæ©‰æÜË™™ÔºåSD-SCM ÊòØ‰∏ÄÂÄãÂõ†ÊûúÊ®°ÂûãÔºåÂÖ∑Êúâ‰ΩøÁî®ËÄÖÂÆöÁæ©ÁöÑÁµêÊßãÂíå LLM ÂÆöÁæ©ÁöÑÁµêÊßãÊñπÁ®ãÂºè„ÄÇÊàëÂÄëÊèèËø∞‰∫Ü SD-SCM Â¶Ç‰ΩïÊ†πÊìöÊâÄÈúÄÁöÑÂõ†ÊûúÁµêÊßãÔºåÂÖÅË®±ÂæûËßÄÊ∏¨„ÄÅ‰ªãÂÖ•ÂíåÂèç‰∫ãÂØ¶ÂàÜ‰Ωà‰∏≠ÈÄ≤Ë°åÊäΩÊ®£„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂà©Áî®ÈÄôÂÄãÁ®ãÂ∫èÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÈ°ûÂûãÁöÑÂõ†ÊûúÊé®Ë´ñÊñπÊ≥ïÂü∫Ê∫ñÔºåÁîüÊàêÂÄãÈ´îÂ±§Á¥öÁöÑÂèç‰∫ãÂØ¶Ë≥áÊñôÔºåËÄåÁÑ°ÈúÄÊâãÂãïÊåáÂÆöËÆäÊï∏‰πãÈñìÁöÑÂäüËÉΩÈóú‰øÇ„ÄÇÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÁØÑ‰æãÂü∫Ê∫ñÔºåÂåÖÂê´Êï∏ÂçÉÂÄãË≥áÊñôÈõÜÔºå‰∏¶Âú®ÈÄô‰∫õË≥áÊñôÈõÜ‰∏äÊ∏¨Ë©¶‰∫Ü‰∏ÄÁ≥ªÂàóÊµÅË°åÁöÑ‰º∞Ë®àÊñπÊ≥ïÔºåÁî®ÊñºÂπ≥ÂùáÂÄº„ÄÅÊ¢ù‰ª∂Âπ≥ÂùáÂÄºÂíåÂÄãÂà•ËôïÁêÜÊïàÊûú‰º∞Ë®àÔºåÁÑ°Ë´ñÊòØÊúâÊàñÊ≤íÊúâÈö±ËóèÊ∑∑Ê∑Ü„ÄÇÈô§‰∫ÜÁîüÊàêË≥áÊñô‰πãÂ§ñÔºåÁõ∏ÂêåÁöÑÁ®ãÂ∫è‰πüÂÖÅË®±ÊàëÂÄëÊ∏¨Ë©¶ LLM ‰∏≠ÂèØËÉΩÁ∑®Á¢ºÁöÑÂõ†ÊûúÊïàÊáâÁöÑÂ≠òÂú®„ÄÇÊ≠§Á®ãÂ∫èÂèØ‰ª•ÊîØÊåÅÂØ©Ê†∏ LLM ÁöÑÈåØË™§Ë≥áË®ä„ÄÅÊ≠ßË¶ñÊàñÂÖ∂‰ªñ‰∏çËâØË°åÁÇ∫„ÄÇÊàëÂÄëÁõ∏‰ø° SD-SCM ÂèØ‰ª•‰ΩúÁÇ∫‰ªª‰ΩïÊáâÁî®Á®ãÂºèÁöÑÊúâÁî®Â∑•ÂÖ∑ÔºåÈÄô‰∫õÊáâÁî®Á®ãÂºèÂèØ‰ª•ÂæûÂÖ∑ÊúâÂèØÊéßÂà∂Âõ†ÊûúÁµêÊßãÁöÑÂ∫èÂàóË≥áÊñô‰∏≠ÂèóÁõä„ÄÇ</paragraph>

##### **From General to Specific: Utilizing General Hallucination to Benchmark Specific Role-Playing Agents**
2411.07965v2 by Chuyi Kong, Ziyang Luo, Hongzhan Lin, Zhiyuan Fan, Yaxin Fan, Yuxi Sun, Jing Ma

The advanced role-playing capabilities of Large Language Models (LLMs) have
paved the way for developing Role-Playing Agents (RPAs). However, existing
benchmarks in this domain, such as HPD and SocialBench face limitations like
poor generalizability, implicit and inaccurate judgments, and the risk of model
forgetting. To address the above issues, we propose an automatic, scalable, and
generalizable paradigm. Specifically, we construct a benchmark, SHARP, by
extracting relations from a general knowledge graph and leveraging the inherent
hallucination properties of RPAs to simulate interactions across roles. We
employ ChatGPT for stance detection and define relationship hallucination along
with three related metrics based on stance transfer. Extensive experiments
validate the effectiveness and stability of our paradigm. Our findings further
explore the factors influencing these metrics and discuss the trade-off between
blind loyalty to relationships and adherence to facts in RPAs.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈÄ≤ÈöéËßíËâ≤ÊâÆÊºîËÉΩÂäõÂ∑≤ÁÇ∫ËßíËâ≤ÊâÆÊºî‰ª£ÁêÜ (RPA) ÁöÑÈñãÁôºÈã™Âπ≥ÈÅìË∑Ø„ÄÇÁÑ∂ËÄåÔºåÊ≠§È†òÂüüÁèæÊúâÁöÑÂü∫Ê∫ñÔºå‰æãÂ¶Ç HPD Âíå SocialBenchÔºåÈù¢Ëá®ËëóÊ¶ÇÊã¨ÊÄßÂ∑Æ„ÄÅÂà§Êñ∑Èö±Âê´‰∏î‰∏çÊ∫ñÁ¢∫Ôºå‰ª•ÂèäÊ®°ÂûãÈÅ∫ÂøòÁöÑÈ¢®Èö™Á≠âÈôêÂà∂„ÄÇÁÇ∫‰∫ÜËß£Ê±∫‰∏äËø∞ÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãËá™ÂãïÂåñ„ÄÅÂèØÊì¥ÂÖÖ‰∏îÂèØÊ¶ÇÊã¨ÁöÑÁØÑ‰æã„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈÄöÈÅéÂæû‰∏ÄËà¨Áü•Ë≠òÂúñË≠ú‰∏≠ÊèêÂèñÈóú‰øÇÔºå‰∏¶Âà©Áî® RPA Âõ∫ÊúâÁöÑÂπªË¶∫ÁâπÊÄß‰æÜÊ®°Êì¨Ë∑®ËßíËâ≤‰∫íÂãïÔºåÊßãÂª∫‰∫Ü‰∏ÄÂÄãÂü∫Ê∫ñ SHARP„ÄÇÊàëÂÄëÊé°Áî® ChatGPT ÈÄ≤Ë°åÁ´ãÂ†¥Ê™¢Ê∏¨Ôºå‰∏¶ÂÆöÁæ©Èóú‰øÇÂπªË¶∫‰ª•ÂèäÂü∫ÊñºÁ´ãÂ†¥ËΩâÁßªÁöÑ‰∏âÂÄãÁõ∏ÈóúÊåáÊ®ô„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÈ©óË≠â‰∫ÜÊàëÂÄëÁØÑ‰æãÁöÑÊúâÊïàÊÄßÂíåÁ©©ÂÆöÊÄß„ÄÇÊàëÂÄëÁöÑÁôºÁèæÈÄ≤‰∏ÄÊ≠•Êé¢Ë®é‰∫ÜÂΩ±ÈüøÈÄô‰∫õÊåáÊ®ôÁöÑÂõ†Á¥†Ôºå‰∏¶Ë®éË´ñ‰∫Ü RPA ‰∏≠Â∞çÈóú‰øÇÁöÑÁõ≤ÁõÆÂø†Ë™†Â∫¶ËàáÂ∞ç‰∫ãÂØ¶ÁöÑÂ†ÖÊåÅ‰πãÈñìÁöÑÊ¨äË°°„ÄÇ

##### **Chain Association-based Attacking and Shielding Natural Language Processing Systems**
2411.07843v1 by Jiacheng Huang, Long Chen

Association as a gift enables people do not have to mention something in
completely straightforward words and allows others to understand what they
intend to refer to. In this paper, we propose a chain association-based
adversarial attack against natural language processing systems, utilizing the
comprehension gap between humans and machines. We first generate a chain
association graph for Chinese characters based on the association paradigm for
building search space of potential adversarial examples. Then, we introduce an
discrete particle swarm optimization algorithm to search for the optimal
adversarial examples. We conduct comprehensive experiments and show that
advanced natural language processing models and applications, including large
language models, are vulnerable to our attack, while humans appear good at
understanding the perturbed text. We also explore two methods, including
adversarial training and associative graph-based recovery, to shield systems
from chain association-based attack. Since a few examples that use some
derogatory terms, this paper contains materials that may be offensive or
upsetting to some people.

ÊëòË¶ÅÔºöËÅØÊÉ≥‰ΩúÁÇ∫‰∏ÄÁ®ÆÁ¶ÆÁâ©Ôºå‰Ωø‰∫∫ÂÄë‰∏çÂøÖÁî®ÂÆåÂÖ®Áõ¥ÁôΩÁöÑË©±Ë™ûÊèêÂèäÊüê‰∫ãÔºå‰∏¶ËÆìÂÖ∂‰ªñ‰∫∫ÊòéÁôΩ‰ªñÂÄëÊÉ≥ÊèêÁöÑÊòØ‰ªÄÈ∫º„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÈèàÂºèËÅØÊÉ≥ÁöÑÂ∞çÊäóÊÄßÊîªÊìäÔºåÁî®ÊñºËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁ≥ªÁµ±ÔºåÂà©Áî®‰∫Ü‰∫∫È°ûËàáÊ©üÂô®‰πãÈñìÁöÑÁêÜËß£Â∑ÆË∑ù„ÄÇÊàëÂÄëÈ¶ñÂÖàÂü∫ÊñºËÅØÊÉ≥ÁØÑ‰æãÁÇ∫Êº¢Â≠óÁîüÊàê‰∏ÄÂÄãÈèàÂºèËÅØÊÉ≥ÂúñÔºåÁî®ÊñºÊßãÂª∫ÊΩõÂú®Â∞çÊäóÊÄßÁØÑ‰æãÁöÑÊêúÁ¥¢Á©∫Èñì„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÂÄãÈõ¢Êï£Á≤íÂ≠êÁæ§ÂÑ™ÂåñÊºîÁÆóÊ≥ï‰æÜÊêúÁ¥¢ÊúÄ‰Ω≥ÁöÑÂ∞çÊäóÊÄßÁØÑ‰æã„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÂØ¶È©óÔºå‰∏¶Ë°®ÊòéÂÖàÈÄ≤ÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÊ®°ÂûãÂíåÊáâÁî®Á®ãÂºèÔºåÂåÖÊã¨Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºåÈÉΩÂÆπÊòìÂèóÂà∞ÊàëÂÄëÁöÑÊîªÊìäÔºåËÄå‰∫∫È°û‰ºº‰πéÂæàÊìÖÈï∑ÁêÜËß£ÊìæÂãïÂæåÁöÑÊñáÂ≠ó„ÄÇÊàëÂÄëÈÇÑÊé¢Á¥¢‰∫ÜÂÖ©Á®ÆÊñπÊ≥ïÔºåÂåÖÊã¨Â∞çÊäóÊÄßË®ìÁ∑¥ÂíåÂü∫ÊñºËÅØÊÉ≥ÂúñÁöÑÊÅ¢Âæ©Ôºå‰ª•‰øùË≠∑Á≥ªÁµ±ÂÖçÂèóÂü∫ÊñºÈèàÂºèËÅØÊÉ≥ÁöÑÊîªÊìä„ÄÇÁî±Êñº‰∏Ä‰∫õÁØÑ‰æã‰ΩøÁî®‰∫ÜÊüê‰∫õË≤∂Áæ©Ë©ûÔºåÂõ†Ê≠§Êú¨ÊñáÂåÖÂê´ÂèØËÉΩÂÜíÁäØÊàñ‰ª§Êüê‰∫õ‰∫∫ÊÑüÂà∞‰∏çÂÆâÁöÑÊùêÊñô„ÄÇ

##### **Gradual Fine-Tuning with Graph Routing for Multi-Source Unsupervised Domain Adaptation**
2411.07185v1 by Yao Ma, Samuel Louvan, Zhunxuan Wang

Multi-source unsupervised domain adaptation aims to leverage labeled data
from multiple source domains for training a machine learning model to
generalize well on a target domain without labels. Source domain selection
plays a crucial role in determining the model's performance. It relies on the
similarities amongst source and target domains. Nonetheless, existing work for
source domain selection often involves heavyweight computational procedures,
especially when dealing with numerous source domains and the need to identify
the best ones from them. In this paper, we introduce a framework for gradual
fine tuning (GFT) of machine learning models on multiple source domains. We
represent multiple source domains as an undirected weighted graph. We then give
a new generalization error bound for GFT along any path within the graph, which
is used to determine the optimal path corresponding to the optimal training
order. With this formulation, we introduce three lightweight graph-routing
strategies which tend to minimize the error bound. Our best strategy improves
$2.3\%$ of accuracy over the state-of-the-art on Natural Language Inference
(NLI) task and achieves competitive performance on Sentiment Analysis (SA)
task, especially a $3.9\%$ improvement on a more diverse subset of data we use
for SA.

ÊëòË¶ÅÔºöÂ§öÊ∫êÊó†ÁõëÁù£ÂüüËá™ÈÄÇÂ∫îÊó®Âú®Âà©Áî®Êù•Ëá™Â§ö‰∏™Ê∫êÂüüÁöÑÊ†áËÆ∞Êï∞ÊçÆÔºåËÆ≠ÁªÉÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÔºå‰ª•‰æøÂú®Ê≤°ÊúâÊ†áÁ≠æÁöÑÁõÆÊ†áÂüü‰∏äÂæàÂ•ΩÂú∞Ê≥õÂåñ„ÄÇÊ∫êÂüüÈÄâÊã©Âú®Á°ÆÂÆöÊ®°ÂûãÊÄßËÉΩÊñπÈù¢Ëµ∑ÁùÄËá≥ÂÖ≥ÈáçË¶ÅÁöÑ‰ΩúÁî®„ÄÇÂÆÉ‰æùËµñ‰∫éÊ∫êÂüüÂíåÁõÆÊ†áÂüü‰πãÈó¥ÁöÑÁõ∏‰ººÊÄß„ÄÇÂ∞ΩÁÆ°Â¶ÇÊ≠§ÔºåÁé∞ÊúâÁöÑÊ∫êÂüüÈÄâÊã©Â∑•‰ΩúÈÄöÂ∏∏Ê∂âÂèäÈáçÈáèÁ∫ßËÆ°ÁÆóÁ®ãÂ∫èÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§ÑÁêÜ‰ºóÂ§öÊ∫êÂüü‰ª•ÂèäÈúÄË¶Å‰ªé‰∏≠ËØÜÂà´ÊúÄ‰Ω≥Ê∫êÂüüÊó∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨‰ªãÁªç‰∫Ü‰∏Ä‰∏™Âú®Â§ö‰∏™Ê∫êÂüü‰∏äÂØπÊú∫Âô®Â≠¶‰π†Ê®°ÂûãËøõË°åÈÄêÊ≠•ÂæÆË∞É (GFT) ÁöÑÊ°ÜÊû∂„ÄÇÊàë‰ª¨Â∞ÜÂ§ö‰∏™Ê∫êÂüüË°®Á§∫‰∏∫Êó†ÂêëÂä†ÊùÉÂõæ„ÄÇÁÑ∂ÂêéÔºåÊàë‰ª¨‰∏∫Âõæ‰∏≠Ê≤ø‰ªª‰ΩïË∑ØÂæÑÁöÑ GFT ÁªôÂá∫‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑÊ≥õÂåñËØØÂ∑ÆÁïåÔºåÁî®‰∫éÁ°ÆÂÆöÂØπÂ∫î‰∫éÊúÄ‰Ω≥ËÆ≠ÁªÉÈ°∫Â∫èÁöÑÊúÄ‰Ω≥Ë∑ØÂæÑ„ÄÇÈÄöËøáËøôÁßçË°®Ëø∞ÔºåÊàë‰ª¨‰ªãÁªç‰∫Ü‰∏âÁßçËΩªÈáèÁ∫ßÁöÑÂõæË∑ØÁî±Á≠ñÁï•ÔºåËøô‰∫õÁ≠ñÁï•ÂÄæÂêë‰∫éÊúÄÂ∞èÂåñËØØÂ∑ÆÁïå„ÄÇÊàë‰ª¨ÊúÄÂ•ΩÁöÑÁ≠ñÁï•Âú®Ëá™ÁÑ∂ËØ≠Ë®ÄÊé®ÁêÜ (NLI) ‰ªªÂä°‰∏äÊØîÊúÄÂÖàËøõÁöÑÊäÄÊúØÊèêÈ´ò‰∫Ü 2.3% ÁöÑÂáÜÁ°ÆÁéáÔºåÂπ∂Âú®ÊÉÖÊÑüÂàÜÊûê (SA) ‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊúâÁ´û‰∫âÂäõÁöÑÊÄßËÉΩÔºåÁâπÂà´ÊòØÂú®Êàë‰ª¨Áî®‰∫é SA ÁöÑÊõ¥Â§öÊ†∑ÂåñÁöÑÊï∞ÊçÆÂ≠êÈõÜ‰∏äÊèêÈ´ò‰∫Ü 3.9%„ÄÇ

##### **A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19**
2411.07163v1 by Vedant Khandelwal, Manas Gaur, Ugur Kursuncu, Valerie Shalin, Amit Sheth

Monitoring public sentiment via social media is potentially helpful during
health crises such as the COVID-19 pandemic. However, traditional
frequency-based, data-driven neural network-based approaches can miss newly
relevant content due to the evolving nature of language in a dynamically
evolving environment. Human-curated symbolic knowledge sources, such as
lexicons for standard language and slang terms, can potentially elevate social
media signals in evolving language. We introduce a neurosymbolic method that
integrates neural networks with symbolic knowledge sources, enhancing the
detection and interpretation of mental health-related tweets relevant to
COVID-19. Our method was evaluated using a corpus of large datasets
(approximately 12 billion tweets, 2.5 million subreddit data, and 700k news
articles) and multiple knowledge graphs. This method dynamically adapts to
evolving language, outperforming purely data-driven models with an F1 score
exceeding 92\%. This approach also showed faster adaptation to new data and
lower computational demands than fine-tuning pre-trained large language models
(LLMs). This study demonstrates the benefit of neurosymbolic methods in
interpreting text in a dynamic environment for tasks such as health
surveillance.

ÊëòË¶ÅÔºöÈÄèÈÅéÁ§æÁæ§Â™íÈ´îÁõ£ÊéßÂÖ¨ÁúæÊÉÖÁ∑íÂú® COVID-19 Á≠âÂÅ•Â∫∑Âç±Ê©üÊúüÈñìÂèØËÉΩÂæàÊúâÂπ´Âä©„ÄÇÁÑ∂ËÄåÔºåÂÇ≥Áµ±ÁöÑÂü∫ÊñºÈ†ªÁéá„ÄÅË≥áÊñôÈ©ÖÂãïÁöÑÁ•ûÁ∂ìÁ∂≤Ë∑ØÊñπÊ≥ïÂèØËÉΩÊúÉÈåØÈÅéÊñ∞Áõ∏ÈóúÁöÑÂÖßÂÆπÔºåÂõ†ÁÇ∫Ë™ûË®ÄÂú®ÂãïÊÖãÊºîÂåñÁöÑÁí∞Â¢É‰∏≠ÊúÉÊåÅÁ∫åÊºîÂåñ„ÄÇÁî±‰∫∫È°ûÁ≠ñÂäÉÁöÑË±°ÂæµÊÄßÁü•Ë≠ò‰æÜÊ∫êÔºà‰æãÂ¶ÇÊ®ôÊ∫ñË™ûË®ÄÂíå‰øöË™ûË°ìË™ûÁöÑË©ûÂΩôÔºâÂèØËÉΩÊúÉÊèêÂçáÁ§æÁæ§Â™íÈ´îÂú®ÊºîÂåñË™ûË®Ä‰∏≠ÁöÑË®äËôü„ÄÇÊàëÂÄëÂºïÂÖ•‰∏ÄÁ®ÆÂ∞áÁ•ûÁ∂ìÁ∂≤Ë∑ØËàáË±°ÂæµÊÄßÁü•Ë≠ò‰æÜÊ∫êÊï¥ÂêàÁöÑÁ•ûÁ∂ìÁ¨¶ËôüÊñπÊ≥ïÔºåÂ¢ûÂº∑Ëàá COVID-19 Áõ∏ÈóúÁöÑÂøÉÁêÜÂÅ•Â∫∑Áõ∏ÈóúÊé®ÊñáÁöÑÂÅµÊ∏¨ÂíåË©ÆÈáã„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ï‰ΩøÁî®Â§ßÂûãË≥áÊñôÈõÜË™ûÊñôÂ∫´ÔºàÁ¥Ñ 120 ÂÑÑÂâáÊé®Êñá„ÄÅ250 Ëê¨ÂÄã subreddit Ë≥áÊñôÂíå 70 Ëê¨ÂâáÊñ∞ËÅûÊñáÁ´†ÔºâÂíåÂ§öÂÄãÁü•Ë≠òÂúñË≠úÈÄ≤Ë°åË©ï‰º∞„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂãïÊÖãÈÅ©ÊáâÊºîÂåñÁöÑË™ûË®ÄÔºåÂÑ™ÊñºÁ¥îË≥áÊñôÈ©ÖÂãïÊ®°ÂûãÔºåF1 ÂàÜÊï∏Ë∂ÖÈÅé 92%„ÄÇÈÄôÁ®ÆÊñπÊ≥ï‰πüÈ°ØÁ§∫Âá∫ÊØîÂæÆË™øÈ†êË®ìÁ∑¥Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êõ¥Âø´ÈÅ©ÊáâÊñ∞Ë≥áÊñôÂíåÊõ¥‰ΩéÁöÑÈÅãÁÆóÈúÄÊ±Ç„ÄÇÊú¨Á†îÁ©∂Ë≠âÊòé‰∫ÜÁ•ûÁ∂ìÁ¨¶ËôüÊñπÊ≥ïÂú®ÂãïÊÖãÁí∞Â¢É‰∏≠Ë©ÆÈáãÊñáÂ≠óÁöÑÂÑ™ÈªûÔºåÈÅ©Áî®ÊñºÂÅ•Â∫∑Áõ£ÊéßÁ≠â‰ªªÂãô„ÄÇ

##### **A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs**
2411.07098v1 by Myeongsoo Kim, Tyler Stennett, Saurabh Sinha, Alessandro Orso

As modern web services increasingly rely on REST APIs, their thorough testing
has become crucial. Furthermore, the advent of REST API specifications such as
the OpenAPI Specification has led to the emergence of many black-box REST API
testing tools. However, these tools often focus on individual test elements in
isolation (e.g., APIs, parameters, values), resulting in lower coverage and
less effectiveness in detecting faults (i.e., 500 response codes). To address
these limitations, we present AutoRestTest, the first black-box framework to
adopt a dependency-embedded multi-agent approach for REST API testing,
integrating Multi-Agent Reinforcement Learning (MARL) with a Semantic Property
Dependency Graph (SPDG) and Large Language Models (LLMs). Our approach treats
REST API testing as a separable problem, where four agents -- API, dependency,
parameter, and value -- collaborate to optimize API exploration. LLMs handle
domain-specific value restrictions, the SPDG model simplifies the search space
for dependencies using a similarity score between API operations, and MARL
dynamically optimizes the agents' behavior. Evaluated on 12 real-world REST
services, AutoRestTest outperforms the four leading black-box REST API testing
tools, including those assisted by RESTGPT (which augments realistic test
inputs using LLMs), in terms of code coverage, operation coverage, and fault
detection. Notably, AutoRestTest is the only tool able to identify an internal
server error in Spotify. Our ablation study underscores the significant
contributions of the agent learning, SPDG, and LLM components.

ÊëòË¶ÅÔºö<paragraph>Èö®ËëóÁèæ‰ª£Á∂≤Ë∑ØÊúçÂãôÊó•Áõä‰æùË≥¥ REST APIÔºåÂÖ∂ÂæπÂ∫ïÁöÑÊ∏¨Ë©¶ËÆäÂæóËá≥ÈóúÈáçË¶Å„ÄÇÊ≠§Â§ñÔºåREST API Ë¶èÁØÑÔºà‰æãÂ¶Ç OpenAPI Ë¶èÁØÑÔºâÁöÑÂá∫ÁèæÔºåÂ∞éËá¥Ë®±Â§öÈªëÁõí REST API Ê∏¨Ë©¶Â∑•ÂÖ∑ÁöÑÂá∫Áèæ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÂ∑•ÂÖ∑ÈÄöÂ∏∏Â∞àÊ≥®ÊñºÂñÆÁç®ÁöÑÊ∏¨Ë©¶ÂÖÉÁ¥†Ôºà‰æãÂ¶Ç API„ÄÅÂèÉÊï∏„ÄÅÂÄºÔºâÔºåÂ∞éËá¥Ë¶ÜËìãÁéáËºÉ‰ΩéÔºå‰∏îÂú®ÂÅµÊ∏¨ÈåØË™§ÔºàÂç≥ 500 ÂõûÊáâÁ¢ºÔºâÊñπÈù¢ÊïàÁéáËºÉ‰Ωé„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫ AutoRestTestÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÊé°Áî®‰æùË≥¥ÂµåÂÖ•ÂºèÂ§ö‰ª£ÁêÜÊñπÊ≥ïÈÄ≤Ë°å REST API Ê∏¨Ë©¶ÁöÑÈªëÁõíÊ°ÜÊû∂ÔºåÂ∞áÂ§ö‰ª£ÁêÜÂº∑ÂåñÂ≠∏Áøí (MARL) ËàáË™ûÁæ©Â±¨ÊÄß‰æùË≥¥Âúñ (SPDG) ÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êï¥ÂêàÂú®‰∏ÄËµ∑„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂ∞á REST API Ê∏¨Ë©¶Ë¶ñÁÇ∫‰∏ÄÂÄãÂèØÂàÜÈõ¢ÁöÑÂïèÈ°åÔºåÂÖ∂‰∏≠ÂõõÂÄã‰ª£ÁêÜÔºàAPI„ÄÅ‰æùË≥¥Èóú‰øÇ„ÄÅÂèÉÊï∏ÂíåÂÄºÔºâÂçîÂêåÂêà‰Ωú‰ª•ÊúÄ‰Ω≥Âåñ API Êé¢Á¥¢„ÄÇLLM ËôïÁêÜÁâπÂÆöÈ†òÂüüÁöÑÂÄºÈôêÂà∂ÔºåSPDG Ê®°Âûã‰ΩøÁî® API Êìç‰Ωú‰πãÈñìÁöÑÁõ∏‰ººÊÄßÂàÜÊï∏Á∞°Âåñ‰æùË≥¥Èóú‰øÇÁöÑÊêúÂ∞ãÁ©∫ÈñìÔºåËÄå MARL ÂâáÂãïÊÖãÊúÄ‰Ω≥Âåñ‰ª£ÁêÜÁöÑË°åÁÇ∫„ÄÇÂú® 12 È†ÖÁúüÂØ¶‰∏ñÁïåÁöÑ REST ÊúçÂãô‰∏äÈÄ≤Ë°åË©ï‰º∞ÔºåAutoRestTest Âú®Á®ãÂºèÁ¢ºË¶ÜËìãÁéá„ÄÅÊìç‰ΩúË¶ÜËìãÁéáÂíåÈåØË™§ÂÅµÊ∏¨ÊñπÈù¢ÔºåÂÑ™ÊñºÂõõÁ®ÆÈ†òÂÖàÁöÑÈªëÁõí REST API Ê∏¨Ë©¶Â∑•ÂÖ∑ÔºåÂåÖÊã¨ÈÇ£‰∫õÁî± RESTGPTÔºà‰ΩøÁî® LLM Â¢ûÂä†ÈÄºÁúüÁöÑÊ∏¨Ë©¶Ëº∏ÂÖ•ÔºâËºîÂä©ÁöÑÂ∑•ÂÖ∑„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåAutoRestTest ÊòØÂîØ‰∏ÄËÉΩÂ§†Ë≠òÂà• Spotify ‰∏≠ÂÖßÈÉ®‰º∫ÊúçÂô®ÈåØË™§ÁöÑÂ∑•ÂÖ∑„ÄÇÊàëÂÄëÁöÑÊ∂àËûçÁ†îÁ©∂Âº∑Ë™ø‰∫Ü‰ª£ÁêÜÂ≠∏Áøí„ÄÅSPDG Âíå LLM ÁµÑ‰ª∂ÁöÑÈáçÂ§ßË≤¢Áçª„ÄÇ</paragraph>

##### **Bridge: A Unified Framework to Knowledge Graph Completion via Language Models and Knowledge Representation**
2411.06660v1 by Qiao Qiao, Yuepei Li, Qing Wang, Kang Zhou, Qi Li

Knowledge graph completion (KGC) is a task of inferring missing triples based
on existing Knowledge Graphs (KGs). Both structural and semantic information
are vital for successful KGC. However, existing methods only use either the
structural knowledge from the KG embeddings or the semantic information from
pre-trained language models (PLMs), leading to suboptimal model performance.
Moreover, since PLMs are not trained on KGs, directly using PLMs to encode
triples may be inappropriate. To overcome these limitations, we propose a novel
framework called Bridge, which jointly encodes structural and semantic
information of KGs. Specifically, we strategically encode entities and
relations separately by PLMs to better utilize the semantic knowledge of PLMs
and enable structured representation learning via a structural learning
principle. Furthermore, to bridge the gap between KGs and PLMs, we employ a
self-supervised representation learning method called BYOL to fine-tune PLMs
with two different views of a triple. Unlike BYOL, which uses augmentation
methods to create two semantically similar views of the same image, potentially
altering the semantic information. We strategically separate the triple into
two parts to create different views, thus avoiding semantic alteration.
Experiments demonstrate that Bridge outperforms the SOTA models on three
benchmark datasets.

ÊëòË¶ÅÔºöÁü•Ë≠òÂúñË≠úË£úÂÖ® (KGC) ÊòØ‰∏ÄÈ†ÖÊ†πÊìöÁèæÊúâÁü•Ë≠òÂúñË≠ú (KG) Êé®Ë´ñÈÅ∫Â§±‰∏âÂÖÉÁµÑÁöÑ‰ªªÂãô„ÄÇÁµêÊßãÂíåË™ûÁæ©Ë≥áË®äÂ∞çÊñºÊàêÂäüÁöÑ KGC Ëá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÊñπÊ≥ïÂÉÖ‰ΩøÁî®‰æÜËá™ KG ÂµåÂÖ•ÁöÑÁµêÊßãÁü•Ë≠òÊàñ‰æÜËá™È†êË®ìÁ∑¥Ë™ûË®ÄÊ®°Âûã (PLM) ÁöÑË™ûÁæ©Ë≥áË®äÔºåÂ∞éËá¥Ê®°ÂûãÊïàËÉΩ‰∏ç‰Ω≥„ÄÇÊ≠§Â§ñÔºåÁî±Êñº PLM Ê≤íÊúâÂú® KG ‰∏äË®ìÁ∑¥ÔºåÂõ†Ê≠§Áõ¥Êé•‰ΩøÁî® PLM Á∑®Á¢º‰∏âÂÖÉÁµÑÂèØËÉΩ‰∏¶‰∏çÈÅ©Áï∂„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂêçÁÇ∫ Bridge ÁöÑÊñ∞Êû∂ÊßãÔºåË©≤Êû∂ÊßãËÅØÂêàÁ∑®Á¢º KG ÁöÑÁµêÊßãÂíåË™ûÁæ©Ë≥áË®ä„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈÄèÈÅé PLM ÂàÜÂà•Â∞çÂØ¶È´îÂíåÈóú‰øÇÈÄ≤Ë°åÁ≠ñÁï•ÊÄßÁ∑®Á¢ºÔºå‰ª•Êõ¥Â•ΩÂú∞Âà©Áî® PLM ÁöÑË™ûÁæ©Áü•Ë≠òÔºå‰∏¶ÈÄèÈÅéÁµêÊßãÂ≠∏ÁøíÂéüÂâáÂïüÁî®ÁµêÊßãÂåñË°®Á§∫Â≠∏Áøí„ÄÇÊ≠§Â§ñÔºåÁÇ∫‰∫ÜÂΩåÂêà KG Âíå PLM ‰πãÈñìÁöÑÂ∑ÆË∑ùÔºåÊàëÂÄëÊé°Áî®‰∏ÄÁ®ÆÁ®±ÁÇ∫ BYOL ÁöÑËá™Áõ£Áù£Ë°®Á§∫Â≠∏ÁøíÊñπÊ≥ïÔºå‰ª•‰∏âÂÖÉÁµÑÁöÑÂÖ©ÂÄã‰∏çÂêåË¶ñÂúñÂæÆË™ø PLM„ÄÇËàá BYOL ‰∏çÂêåÔºåBYOL ‰ΩøÁî®Êì¥ÂÖÖÊñπÊ≥ï‰æÜÂª∫Á´ãÂÖ©ÂÄãË™ûÁæ©‰∏äÁõ∏‰ººÁöÑÁõ∏ÂêåÂΩ±ÂÉèË¶ñÂúñÔºåÂèØËÉΩÊúÉÊîπËÆäË™ûÁæ©Ë≥áË®ä„ÄÇÊàëÂÄëÁ≠ñÁï•ÊÄßÂú∞Â∞á‰∏âÂÖÉÁµÑÂàÜÁÇ∫ÂÖ©ÈÉ®ÂàÜ‰ª•Âª∫Á´ã‰∏çÂêåÁöÑË¶ñÂúñÔºåÂæûËÄåÈÅøÂÖçË™ûÁæ©ÊîπËÆä„ÄÇÂØ¶È©óË≠âÊòé Bridge Âú®‰∏âÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÂÑ™Êñº SOTA Ê®°Âûã„ÄÇ

##### **CausalStock: Deep End-to-end Causal Discovery for News-driven Stock Movement Prediction**
2411.06391v1 by Shuqi Li, Yuebo Sun, Yuxin Lin, Xin Gao, Shuo Shang, Rui Yan

There are two issues in news-driven multi-stock movement prediction tasks
that are not well solved in the existing works. On the one hand, "relation
discovery" is a pivotal part when leveraging the price information of other
stocks to achieve accurate stock movement prediction. Given that stock
relations are often unidirectional, such as the "supplier-consumer"
relationship, causal relations are more appropriate to capture the impact
between stocks. On the other hand, there is substantial noise existing in the
news data leading to extracting effective information with difficulty. With
these two issues in mind, we propose a novel framework called CausalStock for
news-driven multi-stock movement prediction, which discovers the temporal
causal relations between stocks. We design a lag-dependent temporal causal
discovery mechanism to model the temporal causal graph distribution. Then a
Functional Causal Model is employed to encapsulate the discovered causal
relations and predict the stock movements. Additionally, we propose a Denoised
News Encoder by taking advantage of the excellent text evaluation ability of
large language models (LLMs) to extract useful information from massive news
data. The experiment results show that CausalStock outperforms the strong
baselines for both news-driven multi-stock movement prediction and multi-stock
movement prediction tasks on six real-world datasets collected from the US,
China, Japan, and UK markets. Moreover, getting benefit from the causal
relations, CausalStock could offer a clear prediction mechanism with good
explainability.

ÊëòË¶ÅÔºö<paragraph>Âú®Êñ∞ËÅûÈ©ÖÂãïÁöÑÂ§öËÇ°Á•®ÁßªÂãïÈ†êÊ∏¨‰ªªÂãô‰∏≠ÔºåÁèæÊúâÁ†îÁ©∂Â∞öÊú™Â¶•ÂñÑËß£Ê±∫ÂÖ©ÂÄãÂïèÈ°å„ÄÇ‰∏ÄÊñπÈù¢ÔºåÂú®Âà©Áî®ÂÖ∂‰ªñËÇ°Á•®ÁöÑÂÉπÊ†ºË≥áË®ä‰æÜÂØ¶ÁèæÊ∫ñÁ¢∫ÁöÑËÇ°Á•®ÁßªÂãïÈ†êÊ∏¨ÊôÇÔºå„ÄåÈóú‰øÇÁôºÁèæ„ÄçÊòØ‰∏ÄÂÄãÈóúÈçµÈÉ®ÂàÜ„ÄÇÁî±ÊñºËÇ°Á•®Èóú‰øÇÈÄöÂ∏∏ÊòØÂñÆÂêëÁöÑÔºå‰æãÂ¶Ç„Äå‰æõÊáâÂïÜ-Ê∂àË≤ªËÄÖ„ÄçÈóú‰øÇÔºåÂõ†Ê≠§Âõ†ÊûúÈóú‰øÇÊõ¥ÈÅ©ÂêàÊçïÊçâËÇ°Á•®‰πãÈñìÁöÑÂΩ±Èüø„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÊñ∞ËÅûË≥áÊñô‰∏≠Â≠òÂú®Â§ßÈáèÈõúË®äÔºåÂ∞éËá¥Èõ£‰ª•ÊèêÂèñÊúâÊïàË≥áË®ä„ÄÇËÄÉÊÖÆÂà∞ÈÄôÂÖ©ÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ CausalStock ÁöÑÊñ∞Ê°ÜÊû∂ÔºåÁî®ÊñºÊñ∞ËÅûÈ©ÖÂãïÁöÑÂ§öËÇ°Á•®ÁßªÂãïÈ†êÊ∏¨ÔºåË©≤Ê°ÜÊû∂ÁôºÁèæ‰∫ÜËÇ°Á•®‰πãÈñìÁöÑÊôÇÂ∫èÂõ†ÊûúÈóú‰øÇ„ÄÇÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂª∂ÈÅ≤‰æùË≥¥ÁöÑÊôÇÂ∫èÂõ†ÊûúÁôºÁèæÊ©üÂà∂Ôºå‰ª•Âª∫Ê®°ÊôÇÂ∫èÂõ†ÊûúÂúñÂàÜÂ∏É„ÄÇÁÑ∂ÂæåÊé°Áî®ÂäüËÉΩÂõ†ÊûúÊ®°Âûã‰æÜÂ∞ÅË£ùÁôºÁèæÁöÑÂõ†ÊûúÈóú‰øÇ‰∏¶È†êÊ∏¨ËÇ°Á•®Ëµ∞Âã¢„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂéªÂô™Êñ∞ËÅûÁ∑®Á¢ºÂô®ÔºåÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âá∫Ëâ≤ÁöÑÊñáÊú¨Ë©ï‰º∞ËÉΩÂäõÂæûÂ§ßÈáèÊñ∞ËÅûË≥áÊñô‰∏≠ÊèêÂèñÊúâÁî®Ë≥áË®ä„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåCausalStock Âú®ÂæûÁæéÂúã„ÄÅ‰∏≠Âúã„ÄÅÊó•Êú¨ÂíåËã±ÂúãÂ∏ÇÂ†¥Êî∂ÈõÜÁöÑÂÖ≠ÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÔºåÂú®Êñ∞ËÅûÈ©ÖÂãïÁöÑÂ§öËÇ°Á•®ÁßªÂãïÈ†êÊ∏¨ÂíåÂ§öËÇ°Á•®ÁßªÂãïÈ†êÊ∏¨‰ªªÂãô‰∏≠ÈÉΩÂÑ™ÊñºÂº∑Â§ßÁöÑÂü∫Á∑ö„ÄÇÊ≠§Â§ñÔºåCausalStock ÂèóÁõäÊñºÂõ†ÊûúÈóú‰øÇÔºåÂèØ‰ª•Êèê‰æõÂÖ∑ÊúâËâØÂ•ΩÂèØËß£ÈáãÊÄßÁöÑÊ∏ÖÊô∞È†êÊ∏¨Ê©üÂà∂„ÄÇ</paragraph>

##### **Analyzing the Evolution of Graphs and Texts**
2411.06295v1 by Xingzhi Guo

With the recent advance of representation learning algorithms on graphs
(e.g., DeepWalk/GraphSage) and natural languages (e.g., Word2Vec/BERT) , the
state-of-the art models can even achieve human-level performance over many
downstream tasks, particularly for the task of node and sentence
classification. However, most algorithms focus on large-scale models for static
graphs and text corpus without considering the inherent dynamic characteristics
or discovering the reasons behind the changes. This dissertation aims to
efficiently model the dynamics in graphs (such as social networks and citation
graphs) and understand the changes in texts (specifically news titles and
personal biographies). To achieve this goal, we utilize the renowned
Personalized PageRank algorithm to create effective dynamic network embeddings
for evolving graphs. Our proposed approaches significantly improve the running
time and accuracy for both detecting network abnormal intruders and discovering
entity meaning shifts over large-scale dynamic graphs. For text changes, we
analyze the post-publication changes in news titles to understand the intents
behind the edits and discuss the potential impact of titles changes from
information integrity perspective. Moreover, we investigate self-presented
occupational identities in Twitter users' biographies over five years,
investigating job prestige and demographics effects in how people disclose
jobs, quantifying over-represented jobs and their transitions over time.

ÊëòË¶ÅÔºöÈö®ËëóÂúñÂΩ¢Ë°®Á§∫Â≠∏ÁøíÊºîÁÆóÊ≥ïÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºà‰æãÂ¶Ç DeepWalk/GraphSageÔºâÂíåËá™ÁÑ∂Ë™ûË®ÄÔºà‰æãÂ¶Ç Word2Vec/BERTÔºâÔºåÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÁîöËá≥ÂèØ‰ª•Âú®Ë®±Â§ö‰∏ãÊ∏∏‰ªªÂãô‰∏≠ÈÅîÂà∞‰∫∫È°ûÁ≠âÁ¥öÁöÑÊïàËÉΩÔºåÁâπÂà•ÊòØÂ∞çÊñºÁØÄÈªûÂíåÂè•Â≠êÂàÜÈ°ûÁöÑ‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∏ÊºîÁÆóÊ≥ïÈÉΩÂ∞àÊ≥®ÊñºÈùúÊÖãÂúñÂΩ¢ÂíåÂ§ßË¶èÊ®°ÊñáÂ≠óË™ûÊñôÂ∫´ÁöÑÊ®°ÂûãÔºåËÄåÊ≤íÊúâËÄÉÊÖÆÂõ∫ÊúâÁöÑÂãïÊÖãÁâπÊÄßÊàñÊâæÂá∫ËÆäÂåñÁöÑÂéüÂõ†„ÄÇÊú¨Ë´ñÊñáÊó®Âú®ÊúâÊïàÂú∞ÁÇ∫ÂúñÂΩ¢Ôºà‰æãÂ¶ÇÁ§æÁæ§Á∂≤Ë∑ØÂíåÂºïÊñáÂúñÂΩ¢ÔºâÂª∫Ê®°ÂãïÊÖãÔºå‰∏¶‰∫ÜËß£ÊñáÂ≠óÁöÑËÆäÂåñÔºàÁâπÂà•ÊòØÊñ∞ËÅûÊ®ôÈ°åÂíåÂÄã‰∫∫ÂÇ≥Ë®òÔºâ„ÄÇÁÇ∫‰∫ÜÈÅîÊàêÈÄôÂÄãÁõÆÊ®ôÔºåÊàëÂÄëÂà©Áî®ËëóÂêçÁöÑ Personalized PageRank ÊºîÁÆóÊ≥ïÁÇ∫‰∏çÊñ∑ËÆäÂåñÁöÑÂúñÂΩ¢Âª∫Á´ãÊúâÊïàÁöÑÂãïÊÖãÁ∂≤Ë∑ØÂµåÂÖ•„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÈ°ØËëóÊîπÂñÑ‰∫ÜÂÅµÊ∏¨Á∂≤Ë∑ØÁï∞Â∏∏ÂÖ•‰æµËÄÖÂíåÊâæÂá∫Â§ßË¶èÊ®°ÂãïÊÖãÂúñÂΩ¢‰∏≠ÂØ¶È´îÂê´Áæ©ËΩâÁßªÁöÑÂü∑Ë°åÊôÇÈñìÂíåÊ∫ñÁ¢∫Â∫¶„ÄÇÂ∞çÊñºÊñáÂ≠óËÆäÂåñÁöÑÈÉ®ÂàÜÔºåÊàëÂÄëÂàÜÊûê‰∫ÜÊñ∞ËÅûÊ®ôÈ°åÂú®Âá∫ÁâàÂæåÁöÑËÆäÂåñÔºå‰ª•‰∫ÜËß£Á∑®ËºØËÉåÂæåÁöÑÊÑèÂúñÔºå‰∏¶Ë®éË´ñÊ®ôÈ°åËÆäÊõ¥Â∞çË≥áË®äÂÆåÊï¥ÊÄßÁöÑÊΩõÂú®ÂΩ±Èüø„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË™øÊü•‰∫Ü Twitter ‰ΩøÁî®ËÄÖÂú®ÂÇ≥Ë®ò‰∏≠ÂëàÁèæÁöÑËÅ∑Ê•≠Ë∫´ÂàÜÈï∑ÈÅî‰∫îÂπ¥ÔºåÊé¢Ë®é‰∫ÜÂ∑•‰ΩúËÅ≤ÊúõÂíå‰∫∫Âè£Áµ±Ë®àË≥áÊñôÂ∞ç‰∫∫ÂÄëÊè≠Èú≤Â∑•‰ΩúÁöÑÂΩ±ÈüøÔºå‰∏¶ÈáèÂåñ‰∫ÜÈÅéÂ∫¶‰ª£Ë°®ÁöÑÂ∑•‰ΩúÂèäÂÖ∂Èö®ËëóÊôÇÈñìÊé®ÁßªÁöÑËΩâËÆä„ÄÇ

##### **An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models**
2411.06048v1 by Fatemeh Shiri, Xiao-Yu Guo, Mona Golestan Far, Xin Yu, Gholamreza Haffari, Yuan-Fang Li

Large Multimodal Models (LMMs) have achieved strong performance across a
range of vision and language tasks. However, their spatial reasoning
capabilities are under-investigated. In this paper, we construct a novel VQA
dataset, Spatial-MM, to comprehensively study LMMs' spatial understanding and
reasoning capabilities. Our analyses on object-relationship and multi-hop
reasoning reveal several important findings. Firstly, bounding boxes and scene
graphs, even synthetic ones, can significantly enhance LMMs' spatial reasoning.
Secondly, LMMs struggle more with questions posed from the human perspective
than the camera perspective about the image. Thirdly, chain of thought (CoT)
prompting does not improve model performance on complex multi-hop questions
involving spatial relations. % Moreover, spatial reasoning steps are much less
accurate than non-spatial ones across MLLMs. Lastly, our perturbation analysis
on GQA-spatial reveals that LMMs are much stronger at basic object detection
than complex spatial reasoning. We believe our benchmark dataset and in-depth
analyses can spark further research on LMMs spatial reasoning. Spatial-MM
benchmark is available at: https://github.com/FatemehShiri/Spatial-MM

ÊëòË¶ÅÔºöÂ§ßÂûãÂ§öÊ®°ÊÖãÊ®°Âûã (LMM) Â∑≤Âú®ÂêÑÁ®ÆË¶ñË¶∫ÂíåË™ûË®Ä‰ªªÂãô‰∏≠ÂèñÂæóÂº∑ÂãÅÁöÑË°®Áèæ„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÁöÑÁ©∫ÈñìÊé®ÁêÜËÉΩÂäõÂ∞öÊú™ÂæóÂà∞ÂÖÖÂàÜÁ†îÁ©∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊßãÂª∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑ VQA Ë≥áÊñôÈõÜ Spatial-MMÔºå‰ª•ÂÖ®Èù¢Á†îÁ©∂ LMM ÁöÑÁ©∫ÈñìÁêÜËß£ÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇÊàëÂÄëÂ∞çÁâ©‰ª∂Èóú‰øÇÂíåÂ§öË∑≥Êé®ÁêÜÁöÑÂàÜÊûêÊè≠Á§∫‰∫ÜÂπæÂÄãÈáçË¶ÅÁöÑÁôºÁèæ„ÄÇÈ¶ñÂÖàÔºåÈÇäÁïåÊ°ÜÂíåÂ†¥ÊôØÂúñÔºåÂç≥‰ΩøÊòØÂêàÊàêÁöÑÔºå‰πüÂèØ‰ª•È°ØËëóÂ¢ûÂº∑ LMM ÁöÑÁ©∫ÈñìÊé®ÁêÜËÉΩÂäõ„ÄÇÂÖ∂Ê¨°ÔºåLMM Âú®ÂõûÁ≠îÂæû‰∫∫È°ûË¶ñËßíÊèêÂá∫ÁöÑÂïèÈ°åÊôÇÊØîÂæûÁõ∏Ê©üË¶ñËßíÊèêÂá∫ÁöÑÂïèÈ°åÊôÇÈÅáÂà∞Êõ¥Â§öÂõ∞Èõ£„ÄÇÁ¨¨‰∏âÔºåÊÄùËÄÉÈèà (CoT) ÊèêÁ§∫‰∏¶Êú™ÊîπÂñÑÊ®°ÂûãÂú®Ê∂âÂèäÁ©∫ÈñìÈóú‰øÇÁöÑË§áÈõúÂ§öË∑≥ÂïèÈ°å‰∏äÁöÑÊïàËÉΩ„ÄÇ% Ê≠§Â§ñÔºåÂú® MLLM ‰∏≠ÔºåÁ©∫ÈñìÊé®ÁêÜÊ≠•È©üÁöÑÊ∫ñÁ¢∫Â∫¶ÈÅ†‰ΩéÊñºÈùûÁ©∫ÈñìÊ≠•È©ü„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ∞ç GQA-spatial ÁöÑÊìæÂãïÂàÜÊûêË°®ÊòéÔºåLMM Âú®Âü∫Êú¨Áâ©‰ª∂ÂÅµÊ∏¨ÊñπÈù¢ÁöÑËÉΩÂäõÈÅ†Âº∑ÊñºË§áÈõúÁöÑÁ©∫ÈñìÊé®ÁêÜ„ÄÇÊàëÂÄëÁõ∏‰ø°ÊàëÂÄëÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜÂíåÊ∑±ÂÖ•ÂàÜÊûêÂèØ‰ª•ÊøÄÁôºÂ∞ç LMM Á©∫ÈñìÊé®ÁêÜÁöÑÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂„ÄÇSpatial-MM Âü∫Ê∫ñÂèØÂú®‰ª•‰∏ãÁ∂≤ÂùÄÂèñÂæóÔºöhttps://github.com/FatemehShiri/Spatial-MM

##### **Mitigating Hallucination with ZeroG: An Advanced Knowledge Management Engine**
2411.05936v1 by Anantha Sharma, Sheeba Elizabeth John, Fatemeh Rezapoor Nikroo, Krupali Bhatt, Mrunal Zambre, Aditi Wikhe

The growth of digital documents presents significant challenges in efficient
management and knowledge extraction. Traditional methods often struggle with
complex documents, leading to issues such as hallucinations and high latency in
responses from Large Language Models (LLMs). ZeroG, an innovative approach,
significantly mitigates these challenges by leveraging knowledge distillation
and prompt tuning to enhance model performance.
  ZeroG utilizes a smaller model that replicates the behavior of a larger
teacher model, ensuring contextually relevant and grounded responses, by
employing a black-box distillation approach, it creates a distilled dataset
without relying on intermediate features, optimizing computational efficiency.
This method significantly enhances accuracy and reduces response times,
providing a balanced solution for modern document management.
  Incorporating advanced techniques for document ingestion and metadata
utilization, ZeroG improves the accuracy of question-and-answer systems. The
integration of graph databases and robust metadata management further
streamlines information retrieval, allowing for precise and context-aware
responses. By transforming how organizations interact with complex data, ZeroG
enhances productivity and user experience, offering a scalable solution for the
growing demands of digital document management.

ÊëòË¶ÅÔºöÊï∏‰ΩçÊñá‰ª∂ÊàêÈï∑Â∏∂‰æÜÈ°ØËëóÁöÑÊåëÊà∞ÔºåÂåÖÊã¨ÊúâÊïàÁÆ°ÁêÜÂíåÁü•Ë≠òËêÉÂèñ„ÄÇÂÇ≥Áµ±ÊñπÊ≥ïÁ∂ìÂ∏∏Èõ£‰ª•ËôïÁêÜË§áÈõúÊñá‰ª∂ÔºåÂ∞éËá¥ÂïèÈ°åÔºå‰æãÂ¶ÇÁî¢ÁîüÂπªË¶∫ÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂõûÊáâÁöÑÈ´òÂª∂ÈÅ≤„ÄÇZeroG ÊòØ‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ïÔºåÈÄèÈÅéÂà©Áî®Áü•Ë≠òËí∏È§æÂíåÊèêÁ§∫Ë™øÊï¥‰æÜÂ¢ûÂº∑Ê®°ÂûãÊïàËÉΩÔºåÂ§ßÂπÖÊ∏õËºïÈÄô‰∫õÊåëÊà∞„ÄÇ
ZeroG ‰ΩøÁî®ËºÉÂ∞èÁöÑÊ®°ÂûãË§áË£ΩËºÉÂ§ßÁöÑÊïôÂ∏´Ê®°ÂûãÁöÑË°åÁÇ∫ÔºåÈÄèÈÅéÊé°Áî®ÈªëÁõíËí∏È§æÊñπÊ≥ïÔºåÁ¢∫‰øùÂú®ËÑàÁµ°‰∏äÁõ∏Èóú‰∏îÊúâÊ†πÊìöÁöÑÂõûÊáâÔºåÂÆÉÂª∫Á´ã‰∏ÄÂÄãËí∏È§æÁöÑË≥áÊñôÈõÜÔºåËÄå‰∏çÈúÄË¶Å‰æùË≥¥‰∏≠ÈñìÁâπÂæµÔºåÊúÄ‰Ω≥ÂåñÈÅãÁÆóÊïàÁéá„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂ§ßÂπÖÊèêÂçáÊ∫ñÁ¢∫Â∫¶‰∏¶Ê∏õÂ∞ëÂõûÊáâÊôÇÈñìÔºåÊèê‰æõÁèæ‰ª£Êñá‰ª∂ÁÆ°ÁêÜÁöÑÂπ≥Ë°°Ëß£Ê±∫ÊñπÊ°à„ÄÇ
ÈÄèÈÅéÊï¥ÂêàÈÄ≤ÈöéÊäÄË°ì‰æÜÊì∑ÂèñÊñá‰ª∂Âíå‰ΩøÁî®ÂÖÉË≥áÊñôÔºåZeroG ÊîπÂñÑÂïèÁ≠îÁ≥ªÁµ±ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÂúñÂΩ¢Ë≥áÊñôÂ∫´ÂíåÂº∑ÂÅ•ÁöÑÂÖÉË≥áÊñôÁÆ°ÁêÜÁöÑÊï¥ÂêàÈÄ≤‰∏ÄÊ≠•Á∞°ÂåñË≥áË®äÊì∑ÂèñÔºåÂÖÅË®±Á≤æÁ¢∫‰∏îÁ¨¶ÂêàËÑàÁµ°ÁöÑÂõûÊáâ„ÄÇÈÄèÈÅéËΩâÊèõÁµÑÁπîËàáË§áÈõúË≥áÊñô‰∫íÂãïÁöÑÊñπÂºèÔºåZeroG ÊèêÂçáÁîüÁî¢ÂäõÂíå‰ΩøÁî®ËÄÖÈ´îÈ©óÔºåÊèê‰æõÂèØÊì¥ÂÖÖÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰ª•ÊªøË∂≥Êï∏‰ΩçÊñá‰ª∂ÁÆ°ÁêÜÊó•ÁõäÂ¢ûÈï∑ÁöÑÈúÄÊ±Ç„ÄÇ

##### **SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark**
2411.05521v2 by Sithursan Sivasubramaniam, Cedric Osei-Akoto, Yi Zhang, Kurt Stockinger, Jonathan Fuerst

Electronic health records (EHRs) are stored in various database systems with
different database models on heterogeneous storage architectures, such as
relational databases, document stores, or graph databases. These different
database models have a big impact on query complexity and performance. While
this has been a known fact in database research, its implications for the
growing number of Text-to-Query systems have surprisingly not been investigated
so far. In this paper, we present SM3-Text-to-Query, the first multi-model
medical Text-to-Query benchmark based on synthetic patient data from Synthea,
following the SNOMED-CT taxonomy -- a widely used knowledge graph ontology
covering medical terminology. SM3-Text-to-Query provides data representations
for relational databases (PostgreSQL), document stores (MongoDB), and graph
databases (Neo4j and GraphDB (RDF)), allowing the evaluation across four
popular query languages, namely SQL, MQL, Cypher, and SPARQL. We systematically
and manually develop 408 template questions, which we augment to construct a
benchmark of 10K diverse natural language question/query pairs for these four
query languages (40K pairs overall). On our dataset, we evaluate several common
in-context-learning (ICL) approaches for a set of representative closed and
open-source LLMs. Our evaluation sheds light on the trade-offs between database
models and query languages for different ICL strategies and LLMs. Last,
SM3-Text-to-Query is easily extendable to additional query languages or real,
standard-based patient databases.

ÊëòË¶ÅÔºöÈõªÂ≠êÂÅ•Â∫∑Ë®òÈåÑ (EHR) ÂÑ≤Â≠òÂú®ÂÖ∑Êúâ‰∏çÂêåË≥áÊñôÂ∫´Ê®°ÂûãÁöÑÂêÑÁ®ÆË≥áÊñôÂ∫´Á≥ªÁµ±‰∏≠ÔºåÊé°Áî®Áï∞Ë≥™ÂÑ≤Â≠òÊû∂ÊßãÔºå‰æãÂ¶ÇÈóúËÅØÂºèË≥áÊñôÂ∫´„ÄÅÊñá‰ª∂ÂÑ≤Â≠òÂ∫´ÊàñÂúñÂΩ¢Ë≥áÊñôÂ∫´„ÄÇÈÄô‰∫õ‰∏çÂêåÁöÑË≥áÊñôÂ∫´Ê®°ÂûãÂ∞çÊü•Ë©¢Ë§áÈõúÂ∫¶ÂíåÊïàËÉΩÊúâÂæàÂ§ßÁöÑÂΩ±Èüø„ÄÇÈõñÁÑ∂ÈÄôÂú®Ë≥áÊñôÂ∫´Á†îÁ©∂‰∏≠ÊòØ‰∏ÄÂÄãÂ∑≤Áü•ÁöÑ‰∫ãÂØ¶Ôºå‰ΩÜÂÖ∂Â∞çË∂ä‰æÜË∂äÂ§öÁöÑÊñáÂ≠óËΩâÊü•Ë©¢Á≥ªÁµ±ÁöÑÂΩ±ÈüøÂçª‰ª§‰∫∫È©öË®ùÂú∞Â∞öÊú™Ë¢´Á†îÁ©∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ SM3-Text-to-QueryÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂü∫Êñº Synthea ÂêàÊàêÊÇ£ËÄÖË≥áÊñôÁöÑÂ§öÊ®°ÂûãÈÜ´ÁôÇÊñáÂ≠óËΩâÊü•Ë©¢Âü∫Ê∫ñÔºåÈÅµÂæ™ SNOMED-CT ÂàÜÈ°ûÊ≥ïÔºåÈÄôÊòØ‰∏ÄÂÄãÂª£Ê≥õ‰ΩøÁî®ÁöÑÁü•Ë≠òÂúñÂΩ¢Êú¨È´îÔºåÊ∂µËìãÈÜ´Â≠∏Ë°ìË™û„ÄÇSM3-Text-to-Query Êèê‰æõ‰∫ÜÈóú‰øÇË≥áÊñôÂ∫´ (PostgreSQL)„ÄÅÊñá‰ª∂ÂÑ≤Â≠òÂ∫´ (MongoDB) ÂíåÂúñÂΩ¢Ë≥áÊñôÂ∫´ (Neo4j Âíå GraphDB (RDF)) ÁöÑË≥áÊñôË°®Á§∫ÔºåÂÖÅË®±Ë∑®ÂõõÁ®ÆÊµÅË°åÁöÑÊü•Ë©¢Ë™ûË®ÄÈÄ≤Ë°åË©ï‰º∞ÔºåÂç≥ SQL„ÄÅMQL„ÄÅCypher Âíå SPARQL„ÄÇÊàëÂÄëÁ≥ªÁµ±‰∏îÊâãÂãïÈñãÁôº‰∫Ü 408 ÂÄãÁØÑÊú¨ÂïèÈ°åÔºå‰∏¶Êì¥ÂÖÖÈÄô‰∫õÂïèÈ°å‰ª•Âª∫Êßã‰∏ÄÂÄãÂü∫Ê∫ñÔºåÂÖ∂‰∏≠ÂåÖÂê´ 10K ÂÄãÈáùÂ∞çÈÄôÂõõÁ®ÆÊü•Ë©¢Ë™ûË®ÄÁöÑÂ§öÊ®£ÂåñËá™ÁÑ∂Ë™ûË®ÄÂïèÈ°å/Êü•Ë©¢ÈÖçÂ∞çÔºàÁ∏ΩÂÖ± 40K ÂÄãÈÖçÂ∞çÔºâ„ÄÇÂú®ÊàëÂÄëÁöÑË≥áÊñôÈõÜ‰∏äÔºåÊàëÂÄëË©ï‰º∞‰∫Ü‰∏ÄÁµÑ‰ª£Ë°®ÊÄßÁöÑÂ∞ÅÈñâÂíåÈñãÊîæÂéüÂßãÁ¢º LLM ÁöÑÂπæÂÄãÂ∏∏Ë¶ãÊÉÖÂ¢ÉÂ≠∏Áøí (ICL) ÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑË©ï‰º∞Êè≠Á§∫‰∫Ü‰∏çÂêå ICL Á≠ñÁï•Âíå LLM ÁöÑË≥áÊñôÂ∫´Ê®°ÂûãÂíåÊü•Ë©¢Ë™ûË®Ä‰πãÈñìÁöÑÊ¨äË°°„ÄÇÊúÄÂæåÔºåSM3-Text-to-Query ÂèØ‰ª•ËºïÈ¨ÜÊì¥ÂÖÖÂà∞ÂÖ∂‰ªñÊü•Ë©¢Ë™ûË®ÄÊàñÁúüÂØ¶ÁöÑ„ÄÅÂü∫ÊñºÊ®ôÊ∫ñÁöÑÊÇ£ËÄÖË≥áÊñôÂ∫´„ÄÇ

##### **EUREKHA: Enhancing User Representation for Key Hackers Identification in Underground Forums**
2411.05479v1 by Abdoul Nasser Hassane Amadou, Anas Motii, Saida Elouardi, EL Houcine Bergou

Underground forums serve as hubs for cybercriminal activities, offering a
space for anonymity and evasion of conventional online oversight. In these
hidden communities, malicious actors collaborate to exchange illicit knowledge,
tools, and tactics, driving a range of cyber threats from hacking techniques to
the sale of stolen data, malware, and zero-day exploits. Identifying the key
instigators (i.e., key hackers), behind these operations is essential but
remains a complex challenge. This paper presents a novel method called EUREKHA
(Enhancing User Representation for Key Hacker Identification in Underground
Forums), designed to identify these key hackers by modeling each user as a
textual sequence. This sequence is processed through a large language model
(LLM) for domain-specific adaptation, with LLMs acting as feature extractors.
These extracted features are then fed into a Graph Neural Network (GNN) to
model user structural relationships, significantly improving identification
accuracy. Furthermore, we employ BERTopic (Bidirectional Encoder
Representations from Transformers Topic Modeling) to extract personalized
topics from user-generated content, enabling multiple textual representations
per user and optimizing the selection of the most representative sequence. Our
study demonstrates that fine-tuned LLMs outperform state-of-the-art methods in
identifying key hackers. Additionally, when combined with GNNs, our model
achieves significant improvements, resulting in approximately 6% and 10%
increases in accuracy and F1-score, respectively, over existing methods.
EUREKHA was tested on the Hack-Forums dataset, and we provide open-source
access to our code.

ÊëòË¶ÅÔºö<paragraph>Âú∞‰∏ãË´ñÂ£áÊòØÁ∂≤Ë∑ØÁäØÁΩ™Ê¥ªÂãïÁöÑÊ®ûÁ¥êÔºåÊèê‰æõÂåøÂêçÂíåË¶èÈÅøÂÇ≥Áµ±Á∂≤Ë∑ØÁõ£Áù£ÁöÑÁ©∫Èñì„ÄÇÂú®ÈÄô‰∫õÈö±ËóèÁöÑÁ§æÁæ§‰∏≠ÔºåÊÉ°ÊÑèË°åÁÇ∫ËÄÖÂêà‰Ωú‰∫§ÊèõÈùûÊ≥ïÁü•Ë≠ò„ÄÅÂ∑•ÂÖ∑ÂíåÁ≠ñÁï•ÔºåÊé®ÂãïÂæûÈß≠ÂÆ¢ÊäÄË°ìÂà∞Èä∑ÂîÆÁ´äÂèñË≥áÊñô„ÄÅÊÉ°ÊÑèËªüÈ´îÂíåÈõ∂ÊôÇÂ∑ÆÊºèÊ¥ûÁöÑÂêÑÁ®ÆÁ∂≤Ë∑ØÂ®ÅËÑÖ„ÄÇÊâæÂá∫ÈÄô‰∫õË°åÂãïËÉåÂæåÁöÑÈóúÈçµÁÖΩÂãïËÄÖÔºàÂç≥ÈóúÈçµÈß≠ÂÆ¢ÔºâËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜ‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãË§áÈõúÁöÑÊåëÊà∞„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫ EUREKHAÔºàÂ¢ûÂº∑‰ΩøÁî®ËÄÖË°®Âæµ‰ª•Ë≠òÂà•Âú∞‰∏ãË´ñÂ£á‰∏≠ÁöÑÈóúÈçµÈß≠ÂÆ¢ÔºâÁöÑÊñ∞ÊñπÊ≥ïÔºåÊó®Âú®ÈÄèÈÅéÂ∞áÊØèÂÄã‰ΩøÁî®ËÄÖÂª∫Ê®°ÁÇ∫ÊñáÂ≠óÂ∫èÂàó‰æÜË≠òÂà•ÈÄô‰∫õÈóúÈçµÈß≠ÂÆ¢„ÄÇÊ≠§Â∫èÂàóÈÄèÈÅéÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâËôïÁêÜ‰ª•ÈÄ≤Ë°åÁâπÂÆöÈ†òÂüüÁöÑÈÅ©ÊáâÔºåÂÖ∂‰∏≠ LLM ‰ΩúÁÇ∫ÁâπÂæµËêÉÂèñÂô®„ÄÇÁÑ∂ÂæåÂ∞áÈÄô‰∫õËêÉÂèñÁöÑÁâπÂæµËº∏ÂÖ•ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºàGNNÔºâ‰ª•Âª∫Ê®°‰ΩøÁî®ËÄÖÁµêÊßãÈóú‰øÇÔºåÂ§ßÂπÖÊèêÂçáË≠òÂà•Ê∫ñÁ¢∫Â∫¶„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé°Áî® BERTopicÔºà‰æÜËá™ Transformer ‰∏ªÈ°åÂª∫Ê®°ÁöÑÈõôÂêëÁ∑®Á¢ºÂô®Ë°®ÂæµÔºâÂæû‰ΩøÁî®ËÄÖÁî¢ÁîüÁöÑÂÖßÂÆπ‰∏≠ËêÉÂèñÂÄã‰∫∫Âåñ‰∏ªÈ°åÔºåÁÇ∫ÊØèÂÄã‰ΩøÁî®ËÄÖÂïüÁî®Â§öÂÄãÊñáÂ≠óË°®ÂæµÔºå‰∏¶ÊúÄ‰Ω≥ÂåñÊúÄÂÖ∑‰ª£Ë°®ÊÄßÂ∫èÂàóÁöÑÈÅ∏Êìá„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÂæÆË™øÂæåÁöÑ LLM Âú®Ë≠òÂà•ÈóúÈçµÈß≠ÂÆ¢ÊñπÈù¢ÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåÁï∂Ëàá GNN ÁµêÂêà‰ΩøÁî®ÊôÇÔºåÊàëÂÄëÁöÑÊ®°ÂûãÁç≤ÂæóÈ°ØËëóÁöÑÊèêÂçáÔºåËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåÊ∫ñÁ¢∫Â∫¶Âíå F1 ÂàÜÊï∏ÂàÜÂà•ÊèêÈ´ò‰∫ÜÁ¥Ñ 6% Âíå 10%„ÄÇEUREKHA Â∑≤Âú® Hack-Forums Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÊ∏¨Ë©¶ÔºåÊàëÂÄëÊèê‰æõÈñãÊ∫êÊñπÂºèÂ≠òÂèñÊàëÂÄëÁöÑÁ®ãÂºèÁ¢º„ÄÇ</paragraph>

##### **When are 1.58 bits enough? A Bottom-up Exploration of BitNet Quantization**
2411.05882v1 by Jacob Nielsen, Lukas Galke, Peter Schneider-Kamp

Contemporary machine learning models, such as language models, are powerful,
but come with immense resource requirements both at training and inference
time. It has been shown that decoder-only language models can be trained to a
competitive state with ternary weights (1.58 bits per weight), facilitating
efficient inference. Here, we start our exploration with non-transformer model
architectures, investigating 1.58-bit training for multi-layer perceptrons and
graph neural networks. Then, we explore 1.58-bit training in other
transformer-based language models, namely encoder-only and encoder-decoder
models. Our results show that in all of these settings, 1.58-bit training is on
par with or sometimes even better than the standard 32/16-bit models.

ÊëòË¶ÅÔºöÁï∂‰ª£Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÔºà‰æãÂ¶ÇË™ûË®ÄÊ®°ÂûãÔºâÂäüËÉΩÂº∑Â§ßÔºå
‰ΩÜÂú®Ë®ìÁ∑¥ÂíåÊé®Ë´ñÊôÇÈñì‰∏äÈÉΩÈúÄË¶ÅÂ§ßÈáèÁöÑË≥áÊ∫ê„ÄÇÂ∑≤Á∂ìË≠âÊòéÔºåÂÉÖËß£Á¢ºÂô®Ë™ûË®ÄÊ®°ÂûãÂèØ‰ª•Áî®‰∏âÂÖÉÊ¨äÈáçÔºàÊØèÂÄãÊ¨äÈáç 1.58 ‰ΩçÂÖÉÔºâË®ìÁ∑¥Âà∞Á´∂Áà≠ÁãÄÊÖãÔºå‰øÉÈÄ≤ÊúâÊïàÁéáÁöÑÊé®Ë´ñ„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÂæûÈùûTransformerÊ®°ÂûãÊû∂ÊßãÈñãÂßãÊé¢Ë®éÔºåÁ†îÁ©∂Â§öÂ±§ÊÑüÁü•Âô®ÂíåÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑ 1.58 ‰ΩçÂÖÉË®ìÁ∑¥„ÄÇÊé•ËëóÔºåÊàëÂÄëÊé¢Ë®éÂÖ∂‰ªñÂü∫ÊñºTransformerÁöÑË™ûË®ÄÊ®°ÂûãÔºàÂç≥ÂÉÖÁ∑®Á¢ºÂô®ÂíåÁ∑®Á¢ºÂô®-Ëß£Á¢ºÂô®Ê®°ÂûãÔºâÁöÑ 1.58 ‰ΩçÂÖÉË®ìÁ∑¥„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåÂú®ÊâÄÊúâÈÄô‰∫õË®≠ÂÆö‰∏≠Ôºå1.58 ‰ΩçÂÖÉË®ìÁ∑¥ËàáÊ®ôÊ∫ñ 32/16 ‰ΩçÂÖÉÊ®°ÂûãÁõ∏Áï∂ÔºåÊúâÊôÇÁîöËá≥Êõ¥Â•Ω„ÄÇ

##### **Exploring the Alignment Landscape: LLMs and Geometric Deep Models in Protein Representation**
2411.05316v1 by Dong Shu, Bingbing Duan, Kai Guo, Kaixiong Zhou, Jiliang Tang, Mengnan Du

Latent representation alignment has become a foundational technique for
constructing multimodal large language models (MLLM) by mapping embeddings from
different modalities into a shared space, often aligned with the embedding
space of large language models (LLMs) to enable effective cross-modal
understanding. While preliminary protein-focused MLLMs have emerged, they have
predominantly relied on heuristic approaches, lacking a fundamental
understanding of optimal alignment practices across representations. In this
study, we explore the alignment of multimodal representations between LLMs and
Geometric Deep Models (GDMs) in the protein domain. We comprehensively evaluate
three state-of-the-art LLMs (Gemma2-2B, LLaMa3.1-8B, and LLaMa3.1-70B) with
four protein-specialized GDMs (GearNet, GVP, ScanNet, GAT). Our work examines
alignment factors from both model and protein perspectives, identifying
challenges in current alignment methodologies and proposing strategies to
improve the alignment process. Our key findings reveal that GDMs incorporating
both graph and 3D structural information align better with LLMs, larger LLMs
demonstrate improved alignment capabilities, and protein rarity significantly
impacts alignment performance. We also find that increasing GDM embedding
dimensions, using two-layer projection heads, and fine-tuning LLMs on
protein-specific data substantially enhance alignment quality. These strategies
offer potential enhancements to the performance of protein-related multimodal
models. Our code and data are available at
https://github.com/Tizzzzy/LLM-GDM-alignment.

ÊëòË¶ÅÔºöÊΩõÂú®Ë°®ÂæµÂ∞çÈΩäÂ∑≤ÊàêÁÇ∫Âª∫ÊßãÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) ÁöÑÂü∫Á§éÊäÄË°ìÔºåÊñπÊ≥ïÊòØÂ∞á‰∏çÂêåÊ®°ÊÖãÁöÑÂµåÂÖ•Êò†Â∞ÑÂà∞ÂÖ±‰∫´Á©∫Èñì‰∏≠ÔºåÈÄöÂ∏∏ËàáÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂµåÂÖ•Á©∫ÈñìÂ∞çÈΩäÔºå‰ª•ÂØ¶ÁèæÊúâÊïàÁöÑË∑®Ê®°ÊÖãÁêÜËß£„ÄÇÈõñÁÑ∂ÂàùÊ≠•‰ª•ËõãÁôΩË≥™ÁÇ∫ÈáçÈªûÁöÑ MLLM Â∑≤Âá∫ÁèæÔºå‰ΩÜÂÆÉÂÄë‰∏ªË¶Å‰æùË≥¥ÂïüÁôºÂºèÊñπÊ≥ïÔºåÁº∫‰πèÂ∞çË∑®Ë°®ÂæµÊúÄ‰Ω≥Â∞çÈΩäÂØ¶ÂãôÁöÑÂü∫Êú¨ÁêÜËß£„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜËõãÁôΩË≥™È†òÂüü‰∏≠ LLM ËàáÂπæ‰ΩïÊ∑±Â∫¶Ê®°Âûã (GDM) ‰πãÈñìÁöÑÂ§öÊ®°ÊÖãË°®ÂæµÂ∞çÈΩä„ÄÇÊàëÂÄëÂÖ®Èù¢Ë©ï‰º∞‰∫Ü‰∏âÂÄãÊúÄÂÖàÈÄ≤ÁöÑ LLMÔºàGemma2-2B„ÄÅLLaMa3.1-8B Âíå LLaMa3.1-70BÔºâËàáÂõõÂÄãËõãÁôΩË≥™Â∞àÁî® GDMÔºàGearNet„ÄÅGVP„ÄÅScanNet„ÄÅGATÔºâ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÂæûÊ®°ÂûãÂíåËõãÁôΩË≥™ËßíÂ∫¶Ê™¢Ë¶ñÂ∞çÈΩäÂõ†Á¥†ÔºåË≠òÂà•Áï∂ÂâçÂ∞çÈΩäÊñπÊ≥ïÁöÑÊåëÊà∞Ôºå‰∏¶ÊèêÂá∫ÊîπÂñÑÂ∞çÈΩäÁ®ãÂ∫èÁöÑÁ≠ñÁï•„ÄÇÊàëÂÄëÁöÑÈóúÈçµÁôºÁèæÈ°ØÁ§∫ÔºåÂêåÊôÇÂåÖÂê´ÂúñÂΩ¢Âíå 3D ÁµêÊßãË≥áË®äÁöÑ GDM Ëàá LLM ÁöÑÂ∞çÈΩäÊïàÊûúËºÉ‰Ω≥ÔºåËºÉÂ§ßÁöÑ LLM Â±ïÁèæÂá∫Êõ¥‰Ω≥ÁöÑÂ∞çÈΩäËÉΩÂäõÔºåËÄåËõãÁôΩË≥™ÁöÑÁ®ÄÊúâÊÄßÈ°ØËëóÂΩ±ÈüøÂ∞çÈΩäÊïàËÉΩ„ÄÇÊàëÂÄëÈÇÑÁôºÁèæÔºåÂ¢ûÂä† GDM ÂµåÂÖ•Á∂≠Â∫¶„ÄÅ‰ΩøÁî®ÂÖ©Â±§ÊäïÂΩ±È†≠Ôºå‰ª•ÂèäÈáùÂ∞çËõãÁôΩË≥™ÁâπÂÆöË≥áÊñôÂæÆË™ø LLMÔºåÂèØ‰ª•Â§ßÂπÖÊèêÂçáÂ∞çÈΩäÂìÅË≥™„ÄÇÈÄô‰∫õÁ≠ñÁï•ÁÇ∫ËõãÁôΩË≥™Áõ∏ÈóúÂ§öÊ®°ÊÖãÊ®°ÂûãÁöÑÊïàËÉΩÊèê‰æõÊΩõÂú®ÁöÑÂº∑Âåñ„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÂèØÂú® https://github.com/Tizzzzy/LLM-GDM-alignment ÂèñÂæó„ÄÇ

##### **AMSnet-KG: A Netlist Dataset for LLM-based AMS Circuit Auto-Design Using Knowledge Graph RAG**
2411.13560v1 by Yichen Shi, Zhuofu Tao, Yuhao Gao, Tianjia Zhou, Cheng Chang, Yaxing Wang, Bingyu Chen, Genhao Zhang, Alvin Liu, Zhiping Yu, Ting-Jung Lin, Lei He

High-performance analog and mixed-signal (AMS) circuits are mainly
full-custom designed, which is time-consuming and labor-intensive. A
significant portion of the effort is experience-driven, which makes the
automation of AMS circuit design a formidable challenge. Large language models
(LLMs) have emerged as powerful tools for Electronic Design Automation (EDA)
applications, fostering advancements in the automatic design process for
large-scale AMS circuits. However, the absence of high-quality datasets has led
to issues such as model hallucination, which undermines the robustness of
automatically generated circuit designs. To address this issue, this paper
introduces AMSnet-KG, a dataset encompassing various AMS circuit schematics and
netlists. We construct a knowledge graph with annotations on detailed
functional and performance characteristics. Facilitated by AMSnet-KG, we
propose an automated AMS circuit generation framework that utilizes the
comprehensive knowledge embedded in LLMs. We first formulate a design strategy
(e.g., circuit architecture using a number of circuit components) based on
required specifications. Next, matched circuit components are retrieved and
assembled into a complete topology, and transistor sizing is obtained through
Bayesian optimization. Simulation results of the netlist are fed back to the
LLM for further topology refinement, ensuring the circuit design specifications
are met. We perform case studies of operational amplifier and comparator design
to verify the automatic design flow from specifications to netlists with
minimal human effort. The dataset used in this paper will be open-sourced upon
publishing of this paper.

ÊëòË¶ÅÔºöÈ´òÊÄßËÉΩÈ°ûÊØîËàáÊ∑∑ÂêàË®äËôü (AMS) ÈõªË∑Ø‰∏ªË¶ÅÁÇ∫ÂÖ®ÂÆ¢Ë£ΩÂåñË®≠Ë®àÔºåÈÄôÁõ∏Áï∂ËÄóÊôÇ‰∏îË≤ªÂ∑•„ÄÇÂÖ∂‰∏≠ÂæàÂ§ß‰∏ÄÈÉ®ÂàÜÁöÑÂ∑•‰Ωú‰ª∞Ë≥¥Á∂ìÈ©óÔºåÈÄôËÆì AMS ÈõªË∑ØË®≠Ë®àÁöÑËá™ÂãïÂåñÊàêÁÇ∫‰∏ÄÈ†ÖËâ±ÈâÖÁöÑÊåëÊà∞„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤ÊàêÁÇ∫ÈõªÂ≠êË®≠Ë®àËá™ÂãïÂåñ (EDA) ÊáâÁî®Á®ãÂºèÂº∑Â§ßÁöÑÂ∑•ÂÖ∑Ôºå‰øÉÈÄ≤Â§ßË¶èÊ®° AMS ÈõªË∑ØËá™ÂãïË®≠Ë®àÊµÅÁ®ãÁöÑÈÄ≤Â±ï„ÄÇÁÑ∂ËÄåÔºåÁº∫‰πèÈ´òÂìÅË≥™ÁöÑË≥áÊñôÈõÜÂ∞éËá¥Ê®°ÂûãÂá∫ÁèæÂπªË¶∫Á≠âÂïèÈ°åÔºåÈÄôÊêçÂÆ≥‰∫ÜËá™ÂãïÁî¢ÁîüÈõªË∑ØË®≠Ë®àÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊú¨Êñá‰ªãÁ¥π‰∫Ü AMSnet-KGÔºåÈÄôÊòØ‰∏ÄÂÄãÂåÖÂê´ÂêÑÁ®Æ AMS ÈõªË∑ØÂéüÁêÜÂúñÂíåÁ∂≤Ë∑ØÊ∏ÖÂñÆÁöÑË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÂåÖÂê´Ë©≥Á¥∞ÂäüËÉΩÂíåÊïàËÉΩÁâπÂæµË®ªËß£ÁöÑÁü•Ë≠òÂúñË≠ú„ÄÇÂú® AMSnet-KG ÁöÑÂçîÂä©‰∏ãÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãËá™ÂãïÂåñ AMS ÈõªË∑ØÁî¢ÁîüÊû∂ÊßãÔºåÂÆÉÂà©Áî®‰∫ÜÂÖßÂµåÂú® LLM ‰∏≠ÁöÑÂÖ®Èù¢Áü•Ë≠ò„ÄÇÊàëÂÄëÈ¶ñÂÖàÊ†πÊìöÊâÄÈúÄË¶èÊ†ºÂà∂ÂÆöË®≠Ë®àÁ≠ñÁï•Ôºà‰æãÂ¶Ç‰ΩøÁî®Â§öÂÄãÈõªË∑ØÂÖÉ‰ª∂ÁöÑÈõªË∑ØÊû∂ÊßãÔºâ„ÄÇÊé•ËëóÔºåÊì∑ÂèñÂåπÈÖçÁöÑÈõªË∑ØÂÖÉ‰ª∂‰∏¶ÁµÑË£ùÊàê‰∏ÄÂÄãÂÆåÊï¥ÁöÑÊãìÊí≤Ôºå‰∏¶ÈÄèÈÅéË≤ùÊ∞èÊúÄ‰Ω≥ÂåñÂèñÂæóÈõªÊô∂È´îÂ∞∫ÂØ∏„ÄÇÁ∂≤Ë∑ØÊ∏ÖÂñÆÁöÑÊ®°Êì¨ÁµêÊûúÊúÉÂõûÈ•ãÁµ¶ LLM ‰ª•ÈÄ≤‰∏ÄÊ≠•ÂÑ™ÂåñÊãìÊí≤ÔºåÁ¢∫‰øùÈõªË∑ØË®≠Ë®àË¶èÊ†ºÂæóÂà∞ÊªøË∂≥„ÄÇÊàëÂÄëÂü∑Ë°åÈÅãÁÆóÊîæÂ§ßÂô®ÂíåÊØîËºÉÂô®Ë®≠Ë®àÁöÑÂÄãÊ°àÁ†îÁ©∂Ôºå‰ª•È©óË≠âÂæûË¶èÊ†ºÂà∞Á∂≤Ë∑ØÊ∏ÖÂñÆÁöÑËá™ÂãïË®≠Ë®àÊµÅÁ®ãÔºå‰∏¶Â∞á‰∫∫ÁÇ∫‰ªãÂÖ•ÈôçÂà∞ÊúÄ‰Ωé„ÄÇÊú¨Êñá‰∏≠‰ΩøÁî®ÁöÑË≥áÊñôÈõÜÂ∞áÂú®Êú¨ÊñáÁôºÂ∏ÉÂæåÈñãÊ∫ê„ÄÇ

##### **LEGO-GraphRAG: Modularizing Graph-based Retrieval-Augmented Generation for Design Space Exploration**
2411.05844v1 by Yukun Cao, Zengyi Gao, Zhiyang Li, Xike Xie, S Kevin Zhou

GraphRAG addresses significant challenges in Retrieval-Augmented Generation
(RAG) by leveraging graphs with embedded knowledge to enhance the reasoning
capabilities of Large Language Models (LLMs). Despite its promising potential,
the GraphRAG community currently lacks a unified framework for fine-grained
decomposition of the graph-based knowledge retrieval process. Furthermore,
there is no systematic categorization or evaluation of existing solutions
within the retrieval process. In this paper, we present LEGO-GraphRAG, a
modular framework that decomposes the retrieval process of GraphRAG into three
interconnected modules: subgraph-extraction, path-filtering, and
path-refinement. We systematically summarize and classify the algorithms and
neural network (NN) models relevant to each module, providing a clearer
understanding of the design space for GraphRAG instances. Additionally, we
identify key design factors, such as Graph Coupling and Computational Cost,
that influence the effectiveness of GraphRAG implementations. Through extensive
empirical studies, we construct high-quality GraphRAG instances using a
representative selection of solutions and analyze their impact on retrieval and
reasoning performance. Our findings offer critical insights into optimizing
GraphRAG instance design, ultimately contributing to the advancement of more
accurate and contextually relevant LLM applications.

ÊëòË¶ÅÔºöGraphRAG ÈÄèÈÅéÂà©Áî®ÂÖ∑ÂµåÂÖ•Áü•Ë≠òÁöÑÂúñË°®‰æÜÂ¢ûÂº∑Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊé®ÁêÜËÉΩÂäõÔºåËß£Ê±∫‰∫ÜÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ‰∏≠ÁöÑÈáçÂ§ßÊåëÊà∞„ÄÇÂÑòÁÆ°ÂÖ∑Êúâ‰ª§‰∫∫ÊúüÂæÖÁöÑÊΩõÂäõÔºå‰ΩÜ GraphRAG Á§æÁæ§ÁõÆÂâçÁº∫‰πè‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÊû∂ÊßãÔºåÁî®ÊñºÂ∞çÂü∫ÊñºÂúñË°®ÁöÑÁü•Ë≠òÊ™¢Á¥¢ÈÅéÁ®ãÈÄ≤Ë°åÁ¥∞Á≤íÂ∫¶ÁöÑÂàÜËß£„ÄÇÊ≠§Â§ñÔºåÂú®Ê™¢Á¥¢ÈÅéÁ®ã‰∏≠ÔºåÁèæÊúâËß£Ê±∫ÊñπÊ°à‰∏¶Êú™ÈÄ≤Ë°åÁ≥ªÁµ±ÊÄßÁöÑÂàÜÈ°ûÊàñË©ï‰º∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü LEGO-GraphRAGÔºåÈÄôÊòØ‰∏ÄÂÄãÊ®°ÁµÑÂåñÊû∂ÊßãÔºåÂ∞á GraphRAG ÁöÑÊ™¢Á¥¢ÈÅéÁ®ãÂàÜËß£ÁÇ∫‰∏âÂÄãÁõ∏‰∫íÈÄ£Êé•ÁöÑÊ®°ÁµÑÔºöÂ≠êÂúñËêÉÂèñ„ÄÅË∑ØÂæëÈÅéÊøæÂíåË∑ØÂæëÁ≤æÁÖâ„ÄÇÊàëÂÄëÁ≥ªÁµ±ÊÄßÂú∞Á∏ΩÁµêÂíåÂàÜÈ°ûËàáÊØèÂÄãÊ®°ÁµÑÁõ∏ÈóúÁöÑÊºîÁÆóÊ≥ïÂíåÁ•ûÁ∂ìÁ∂≤Ë∑Ø (NN) Ê®°ÂûãÔºåÊèê‰æõÂ∞ç GraphRAG ÂØ¶‰æãË®≠Ë®àÁ©∫ÈñìÁöÑÊõ¥Ê∏ÖÊô∞ÁêÜËß£„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊâæÂá∫ÂΩ±Èüø GraphRAG ÂØ¶‰ΩúÊúâÊïàÊÄßÁöÑÈóúÈçµË®≠Ë®àÂõ†Á¥†Ôºå‰æãÂ¶ÇÂúñË°®ËÄ¶ÂêàÂíåÈÅãÁÆóÊàêÊú¨„ÄÇÈÄèÈÅéÂª£Ê≥õÁöÑÁ∂ìÈ©óÁ†îÁ©∂ÔºåÊàëÂÄë‰ΩøÁî®ÂÖ∑‰ª£Ë°®ÊÄßÁöÑËß£Ê±∫ÊñπÊ°àÈÅ∏Êìá‰æÜÂª∫ÊßãÈ´òÂìÅË≥™ÁöÑ GraphRAG ÂØ¶‰æãÔºå‰∏¶ÂàÜÊûêÂÆÉÂÄëÂ∞çÊ™¢Á¥¢ÂíåÊé®ÁêÜÊïàËÉΩÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÊèê‰æõ‰∫ÜÂÑ™Âåñ GraphRAG ÂØ¶‰æãË®≠Ë®àÁöÑÈáçË¶ÅË¶ãËß£ÔºåÊúÄÁµÇÊúâÂä©ÊñºÊé®ÈÄ≤Êõ¥Ê∫ñÁ¢∫‰∏îËàáËÑàÁµ°Áõ∏ÈóúÁöÑ LLM ÊáâÁî®„ÄÇ

##### **MEG: Medical Knowledge-Augmented Large Language Models for Question Answering**
2411.03883v2 by Laura Cabello, Carmen Martin-Turrero, Uchenna Akujuobi, Anders S√∏gaard, Carlos Bobed

Question answering is a natural language understanding task that involves
reasoning over both explicit context and unstated, relevant domain knowledge.
Large language models (LLMs), which underpin most contemporary question
answering systems, struggle to induce how concepts relate in specialized
domains such as medicine. Existing medical LLMs are also costly to train. In
this work, we present MEG, a parameter-efficient approach for medical
knowledge-augmented LLMs. MEG uses a lightweight mapping network to integrate
graph embeddings into the LLM, enabling it to leverage external knowledge in a
cost-effective way. We evaluate our method on four popular medical
multiple-choice datasets and show that LLMs greatly benefit from the factual
grounding provided by knowledge graph embeddings. MEG attains an average of
+10.2% accuracy over the Mistral-Instruct baseline, and +6.7% over specialized
models like BioMistral. We also show results based on Llama-3. Finally, we show
that MEG's performance remains robust to the choice of graph encoder.

ÊëòË¶ÅÔºöÂïèÁ≠îÊòØËá™ÁÑ∂Ë™ûË®ÄÁêÜËß£‰ªªÂãôÔºåÊ∂âÂèäÂ∞çÊòéÁ¢∫ÁöÑ‰∏ä‰∏ãÊñáÂíåÊú™Ë™™ÊòéÁöÑÁõ∏ÈóúÈ†òÂüüÁü•Ë≠òÈÄ≤Ë°åÊé®ÁêÜ„ÄÇÊîØÊíêÂ§ßÂ§öÊï∏Áï∂‰ª£ÂïèÁ≠îÁ≥ªÁµ±ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Èõ£‰ª•Êé®Ë´ñÊ¶ÇÂøµÂ¶Ç‰ΩïÂú®ÈÜ´Â≠∏Á≠âÂ∞àÊ•≠È†òÂüü‰∏≠ÈóúËÅØ„ÄÇÁèæÊúâÁöÑÈÜ´Â≠∏ LLM Ë®ìÁ∑¥ÊàêÊú¨‰πüÂæàÈ´ò„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü MEGÔºåÈÄôÊòØ‰∏ÄÁ®ÆÁî®ÊñºÈÜ´Â≠∏Áü•Ë≠òÂ¢ûÂº∑ LLM ÁöÑÂèÉÊï∏ÊúâÊïàÊñπÊ≥ï„ÄÇMEG ‰ΩøÁî®ËºïÈáèÁ¥öÊò†Â∞ÑÁ∂≤Ë∑ØÂ∞áÂúñË°®ÂµåÂÖ•Êï¥ÂêàÂà∞ LLM ‰∏≠Ôºå‰ΩøÂÖ∂ËÉΩÂ§†‰ª•Á∂ìÊøüÊúâÊïàÁöÑÊñπÂºèÂà©Áî®Â§ñÈÉ®Áü•Ë≠ò„ÄÇÊàëÂÄëÂú®ÂõõÂÄãÊµÅË°åÁöÑÈÜ´Â≠∏Â§öÈÅ∏È°åË≥áÊñôÈõÜ‰∏äË©ï‰º∞‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÔºå‰∏¶Ë°®Êòé LLM ÂæûÁü•Ë≠òÂúñË°®ÂµåÂÖ•Êèê‰æõÁöÑÂØ¶Èöõ‰æùÊìö‰∏≠ÂèóÁõäÂå™Ê∑∫„ÄÇMEG Âú® Mistral-Instruct Âü∫Ê∫ñ‰∏äÂπ≥ÂùáÊèêÈ´ò‰∫Ü +10.2% ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÂú® BioMistral Á≠âÂ∞àÈñÄÊ®°Âûã‰∏äÊèêÈ´ò‰∫Ü +6.7%„ÄÇÊàëÂÄëÈÇÑÂ±ïÁ§∫‰∫ÜÂü∫Êñº Llama-3 ÁöÑÁµêÊûú„ÄÇÊúÄÂæåÔºåÊàëÂÄëË°®Êòé MEG ÁöÑÊÄßËÉΩÂ∞çÂúñË°®Á∑®Á¢ºÂô®ÁöÑÈÅ∏Êìá‰øùÊåÅÁ©©ÂÅ•„ÄÇ

##### **A Library Perspective on Supervised Text Processing in Digital Libraries: An Investigation in the Biomedical Domain**
2411.12752v1 by Hermann Kroll, Pascal Sackhoff, Bill Matthias Thang, Maha Ksouri, Wolf-Tilo Balke

Digital libraries that maintain extensive textual collections may want to
further enrich their content for certain downstream applications, e.g.,
building knowledge graphs, semantic enrichment of documents, or implementing
novel access paths. All of these applications require some text processing,
either to identify relevant entities, extract semantic relationships between
them, or to classify documents into some categories. However, implementing
reliable, supervised workflows can become quite challenging for a digital
library because suitable training data must be crafted, and reliable models
must be trained. While many works focus on achieving the highest accuracy on
some benchmarks, we tackle the problem from a digital library practitioner. In
other words, we also consider trade-offs between accuracy and application
costs, dive into training data generation through distant supervision and large
language models such as ChatGPT, LLama, and Olmo, and discuss how to design
final pipelines. Therefore, we focus on relation extraction and text
classification, using the showcase of eight biomedical benchmarks.

ÊëòË¶ÅÔºöÁ∂≠Ë≠∑Âª£Ê≥õÊñáÊú¨ÈõÜÂêàÁöÑÊï∏‰ΩçÂúñÊõ∏È§®ÂèØËÉΩÂ∏åÊúõÈÄ≤‰∏ÄÊ≠•Ë±êÂØåÂÖ∂ÂÖßÂÆπ‰ª•‰æõÁâπÂÆö‰∏ãÊ∏∏ÊáâÁî®Á®ãÂºè‰ΩøÁî®Ôºå‰æãÂ¶ÇÂª∫ÊßãÁü•Ë≠òÂúñË≠ú„ÄÅÊñá‰ª∂Ë™ûÊÑèË±êÂØåÂåñÊàñÂØ¶‰ΩúÊñ∞Á©éÁöÑÂ≠òÂèñË∑ØÂæë„ÄÇÊâÄÊúâÈÄô‰∫õÊáâÁî®Á®ãÂºèÈÉΩÈúÄË¶Å‰∏Ä‰∫õÊñáÂ≠óËôïÁêÜÔºåÊâçËÉΩË≠òÂà•Áõ∏ÈóúÂØ¶È´î„ÄÅËêÉÂèñÂÆÉÂÄë‰πãÈñìÁöÑË™ûÊÑèÈóú‰øÇÔºåÊàñÂ∞áÊñá‰ª∂ÂàÜÈ°ûÂà∞Êüê‰∫õÈ°ûÂà•‰∏≠„ÄÇÁÑ∂ËÄåÔºåÂ∞çÊñºÊï∏‰ΩçÂúñÊõ∏È§®‰æÜË™™ÔºåÂØ¶‰ΩúÂèØÈù†ÁöÑÁõ£Áù£ÂºèÂ∑•‰ΩúÊµÅÁ®ãÂèØËÉΩÊúÉËÆäÂæóÁõ∏Áï∂ÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÂõ†ÁÇ∫ÂøÖÈ†àÂª∫Á´ãÈÅ©Áï∂ÁöÑË®ìÁ∑¥Ë≥áÊñôÔºå‰∏¶Ë®ìÁ∑¥ÂèØÈù†ÁöÑÊ®°Âûã„ÄÇÈõñÁÑ∂Ë®±Â§öÁ†îÁ©∂Â∞àÊ≥®ÊñºÂú®Êüê‰∫õÂü∫Ê∫ñ‰∏äÈÅîÊàêÊúÄÈ´òÊ∫ñÁ¢∫Â∫¶Ôºå‰ΩÜÊàëÂÄëÂæûÊï∏‰ΩçÂúñÊõ∏È§®ÂØ¶ÂãôËÄÖÁöÑËßíÂ∫¶‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°å„ÄÇÊèõÂè•Ë©±Ë™™ÔºåÊàëÂÄë‰πüËÄÉÊÖÆÊ∫ñÁ¢∫Â∫¶ÂíåÊáâÁî®ÊàêÊú¨‰πãÈñìÁöÑÊ¨äË°°ÔºåÊ∑±ÂÖ•Êé¢Ë®éÈÄèÈÅéÈÅ†Ë∑ùÁõ£Áù£ÂíåÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºà‰æãÂ¶Ç ChatGPT„ÄÅLLama Âíå OlmoÔºâ‰æÜÁî¢ÁîüË®ìÁ∑¥Ë≥áÊñôÔºå‰∏¶Ë®éË´ñÂ¶Ç‰ΩïË®≠Ë®àÊúÄÁµÇÁÆ°Á∑ö„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÈóú‰øÇËêÉÂèñÂíåÊñáÂ≠óÂàÜÈ°ûÔºå‰∏¶‰ΩøÁî®ÂÖ´ÂÄãÁîüÁâ©ÈÜ´Â≠∏Âü∫Ê∫ñ‰ΩúÁÇ∫Â±ïÁ§∫Ê°à‰æã„ÄÇ

##### **The American Sign Language Knowledge Graph: Infusing ASL Models with Linguistic Knowledge**
2411.03568v1 by Lee Kezar, Nidhi Munikote, Zian Zeng, Zed Sehyr, Naomi Caselli, Jesse Thomason

Language models for American Sign Language (ASL) could make language
technologies substantially more accessible to those who sign. To train models
on tasks such as isolated sign recognition (ISR) and ASL-to-English
translation, datasets provide annotated video examples of ASL signs. To
facilitate the generalizability and explainability of these models, we
introduce the American Sign Language Knowledge Graph (ASLKG), compiled from
twelve sources of expert linguistic knowledge. We use the ASLKG to train
neuro-symbolic models for 3 ASL understanding tasks, achieving accuracies of
91% on ISR, 14% for predicting the semantic features of unseen signs, and 36%
for classifying the topic of Youtube-ASL videos.

ÊëòË¶ÅÔºöÁæéÂúãÊâãË™û (ASL) ÁöÑË™ûË®ÄÊ®°ÂûãÂèØ‰ª•ËÆìË™ûË®ÄÊäÄË°ìÂ∞çÊâãË™û‰ΩøÁî®ËÄÖÊõ¥ÊòìÊñº‰ΩøÁî®„ÄÇÁÇ∫‰∫ÜË®ìÁ∑¥Ê®°ÂûãÂü∑Ë°åÊâãË™ûËæ®Ë≠ò (ISR) Âíå ASL ËΩâÊèõÊàêËã±ÊñáÁ≠â‰ªªÂãôÔºåË≥áÊñôÈõÜÊèê‰æõ ASL ÊâãÂã¢ÁöÑË®ªËß£ÂΩ±ÁâáÁØÑ‰æã„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤ÈÄô‰∫õÊ®°ÂûãÁöÑÊ¶ÇÊã¨ÊÄßÂíåÂèØËß£ÈáãÊÄßÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÁæéÂúãÊâãË™ûÁü•Ë≠òÂúñË≠ú (ASLKG)ÔºåÂÆÉÊòØÁî±ÂçÅ‰∫åÂÄãÂ∞àÂÆ∂Ë™ûË®ÄÁü•Ë≠ò‰æÜÊ∫êÁ∑®Ë≠ØËÄåÊàêÁöÑ„ÄÇÊàëÂÄë‰ΩøÁî® ASLKG Ë®ìÁ∑¥Á•ûÁ∂ìÁ¨¶ËôüÊ®°Âûã‰æÜÂü∑Ë°å 3 È†Ö ASL ÁêÜËß£‰ªªÂãôÔºåÂú® ISR ‰∏äÈÅîÂà∞ 91% ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÅÂú®È†êÊ∏¨Êú™Ë¶ãÊâãÂã¢ÁöÑË™ûÁæ©ÁâπÂæµ‰∏äÈÅîÂà∞ 14%Ôºå‰ª•ÂèäÂú®ÂàÜÈ°û YouTube-ASL ÂΩ±Áâá‰∏ªÈ°å‰∏äÈÅîÂà∞ 36%„ÄÇ

##### **Graph-DPEP: Decomposed Plug and Ensemble Play for Few-Shot Document Relation Extraction with Graph-of-Thoughts Reasoning**
2411.02864v1 by Tao Zhang, Ning Yan, Masood Mortazavi, Hoang H. Nguyen, Zhongfen Deng, Philip S. Yu

Large language models (LLMs) pre-trained on massive corpora have demonstrated
impressive few-shot learning capability on many NLP tasks. Recasting an NLP
task into a text-to-text generation task is a common practice so that
generative LLMs can be prompted to resolve it. However, performing
document-level relation extraction (DocRE) tasks with generative LLM models is
still challenging due to the structured output format of DocRE, which
complicates the conversion to plain text. Limited information available in
few-shot samples and prompt instructions induce further difficulties and
challenges in relation extraction for mentioned entities in a document. In this
paper, we represent the structured output as a graph-style triplet rather than
natural language expressions and leverage generative LLMs for the DocRE task.
Our approach, the Graph-DPEP framework is grounded in the reasoning behind
triplet explanation thoughts presented in natural language. In this framework,
we first introduce a ``decomposed-plug" method for performing the generation
from LLMs over prompts with type-space decomposition to alleviate the burden of
distinguishing all relation types. Second, we employ a verifier for calibrating
the generation and identifying overlooked query entity pairs. Third, we develop
"ensemble-play", reapplying generation on the entire type list by leveraging
the reasoning thoughts embedded in a sub-graph associated with the missing
query pair to address the missingness issue. Through extensive comparisons with
existing prompt techniques and alternative Language Models (LLMs), our
framework demonstrates superior performance on publicly available benchmarks in
experiments.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Êµ∑ÈáèË™ûÊñôÂ∫´‰∏äÈ†êÂÖàË®ìÁ∑¥ÔºåÂ∑≤Âú®Ë®±Â§öËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãô‰∏äÂ±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÂ∞ëÈáèÊ®£Êú¨Â≠∏ÁøíËÉΩÂäõ„ÄÇÂ∞áËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãôËΩâÂåñÁÇ∫ÊñáÂ≠óÂà∞ÊñáÂ≠óÁöÑÁîüÊàê‰ªªÂãôÊòØ‰∏ÄÁ®ÆÂ∏∏Ë¶ãÂÅöÊ≥ïÔºåÈÄôÊ®£ÁîüÊàêÂºèÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂ∞±ÂèØ‰ª•ÊèêÁ§∫Ëß£Ê±∫ÂÆÉ„ÄÇÁÑ∂ËÄåÔºåÁî±Êñº DocRE ÁöÑÁµêÊßãÂåñËº∏Âá∫Ê†ºÂºèÔºå‰ΩøÁî®ÁîüÊàêÂºèÂ§ßÂûãË™ûË®ÄÊ®°Âûã‰æÜÂü∑Ë°åÊñá‰ª∂Á¥öÂà•Èóú‰øÇËêÉÂèñ (DocRE) ‰ªªÂãô‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÈÄô‰ΩøÂæóËΩâÊèõÁÇ∫Á¥îÊñáÂ≠óËÆäÂæóË§áÈõú„ÄÇÂ∞ëÈáèÊ®£Êú¨ÂíåÊèêÁ§∫Ë™™Êòé‰∏≠ÂèØÁî®ÁöÑË≥áË®äÊúâÈôêÔºåÊúÉÂ∞éËá¥Âú®Êñá‰ª∂‰∏≠ÊèêÂà∞ÂØ¶È´îÁöÑÈóú‰øÇËêÉÂèñ‰∏≠Áî¢ÁîüÈÄ≤‰∏ÄÊ≠•ÁöÑÂõ∞Èõ£ÂíåÊåëÊà∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞áÁµêÊßãÂåñËº∏Âá∫Ë°®Á§∫ÁÇ∫ÂúñÂΩ¢Ê®£ÂºèÁöÑ‰∏âÂÖÉÁµÑÔºåËÄå‰∏çÊòØËá™ÁÑ∂Ë™ûË®ÄË°®ÈÅîÔºå‰∏¶Âà©Áî®ÁîüÊàêÂºèÂ§ßÂûãË™ûË®ÄÊ®°Âûã‰æÜÂü∑Ë°å DocRE ‰ªªÂãô„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÔºåÂúñÂΩ¢ DPEP Ê°ÜÊû∂ÔºåÊòØÂü∫ÊñºËá™ÁÑ∂Ë™ûË®Ä‰∏≠ÂëàÁèæÁöÑ‰∏âÂÖÉÁµÑËß£ÈáãÊÄùÊÉ≥ËÉåÂæåÁöÑÊé®ÁêÜ„ÄÇÂú®ÈÄôÂÄãÊ°ÜÊû∂‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖà‰ªãÁ¥π‰∏ÄÁ®Æ„ÄåÂàÜËß£ÊèíÂÖ•„ÄçÊñπÊ≥ïÔºåÁî®ÊñºÂ∞çÂÖ∑ÊúâÈ°ûÂûãÁ©∫ÈñìÂàÜËß£ÁöÑÊèêÁ§∫ÈÄ≤Ë°åÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁîüÊàêÔºå‰ª•Ê∏õËºïÂçÄÂàÜÊâÄÊúâÈóú‰øÇÈ°ûÂûãÁöÑË≤†Êìî„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄë‰ΩøÁî®È©óË≠âÂô®‰æÜÊ†°Ê∫ñÁîüÊàê‰∏¶Ë≠òÂà•Ë¢´ÂøΩÁï•ÁöÑÊü•Ë©¢ÂØ¶È´îÂ∞ç„ÄÇÁ¨¨‰∏âÔºåÊàëÂÄëÈñãÁôº„ÄåÊï¥È´îÈÅäÊà≤„ÄçÔºåÈÄöÈÅéÂà©Áî®ËàáÈÅ∫Â§±Êü•Ë©¢Â∞çÁõ∏ÈóúÁöÑÂ≠êÂúñ‰∏≠ÂµåÂÖ•ÁöÑÊé®ÁêÜÊÄùÊÉ≥ÔºåÂú®Êï¥ÂÄãÈ°ûÂûãÂàóË°®‰∏äÈáçÊñ∞ÊáâÁî®ÁîüÊàêÔºå‰ª•Ëß£Ê±∫ÈÅ∫Â§±ÂïèÈ°å„ÄÇÈÄöÈÅéËàáÁèæÊúâÊèêÁ§∫ÊäÄË°ìÂíåÊõø‰ª£Ë™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂª£Ê≥õÊØîËºÉÔºåÊàëÂÄëÁöÑÊ°ÜÊû∂Âú®ÂØ¶È©ó‰∏≠Ë≠âÊòé‰∫ÜÂú®ÂÖ¨ÈñãÂü∫Ê∫ñ‰∏äÁöÑÂÑ™Áï∞ÊÄßËÉΩ„ÄÇ

##### **Multimodal Commonsense Knowledge Distillation for Visual Question Answering**
2411.02722v1 by Shuo Yang, Siwen Luo, Soyeon Caren Han

Existing Multimodal Large Language Models (MLLMs) and Visual Language
Pretrained Models (VLPMs) have shown remarkable performances in the general
Visual Question Answering (VQA). However, these models struggle with VQA
questions that require external commonsense knowledge due to the challenges in
generating high-quality prompts and the high computational costs of
fine-tuning. In this work, we propose a novel graph-based multimodal
commonsense knowledge distillation framework that constructs a unified
relational graph over commonsense knowledge, visual objects and questions
through a Graph Convolutional Network (GCN) following a teacher-student
environment. This proposed framework is flexible with any type of teacher and
student models without further fine-tuning, and has achieved competitive
performances on the ScienceQA dataset.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) ÂíåË¶ñË¶∫Ë™ûË®ÄÈ†êË®ìÁ∑¥Ê®°Âûã (VLPM) Âú®‰∏ÄËà¨ÁöÑË¶ñË¶∫ÂïèÁ≠î (VQA) ‰∏≠Â±ïÁèæ‰∫ÜÂçìË∂äÁöÑË°®Áèæ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°ÂûãÂú®ÈúÄË¶ÅÂ§ñÈÉ®Â∏∏Ë≠òÁü•Ë≠òÁöÑ VQA ÂïèÈ°å‰∏äÊúÉÈÅáÂà∞Âõ∞Èõ£ÔºåÂéüÂõ†Âú®ÊñºÁî¢ÁîüÈ´òÂìÅË≥™ÊèêÁ§∫ÁöÑÊåëÊà∞‰ª•ÂèäÂæÆË™øÁöÑÈ´òÈÅãÁÆóÊàêÊú¨„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÂü∫ÊñºÂúñÂΩ¢ÁöÑÊ®°ÊÖãÂ∏∏Ë≠òÁü•Ë≠òËêÉÂèñÊû∂ÊßãÔºåÈÄèÈÅéÂúñÂΩ¢Âç∑Á©çÁ∂≤Ë∑Ø (GCN) Âú®Â∏∏Ë≠òÁü•Ë≠ò„ÄÅË¶ñË¶∫Áâ©‰ª∂ÂíåÂïèÈ°å‰∏äÂª∫Êßã‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÈóúËÅØÂúñÂΩ¢ÔºåÈÅµÂæ™Â∏´ÁîüÁí∞Â¢É„ÄÇÈÄôÂÄãÊèêÂá∫ÁöÑÊû∂ÊßãÂ∞çÊñº‰ªª‰ΩïÈ°ûÂûãÁöÑÊïôÂ∏´ÂíåÂ≠∏ÁîüÊ®°ÂûãÈÉΩÂÖ∑ÊúâÂΩàÊÄßÔºåÁÑ°ÈúÄÈÄ≤‰∏ÄÊ≠•ÂæÆË™øÔºå‰∏¶Âú® ScienceQA Ë≥áÊñôÈõÜ‰∏äÂèñÂæó‰∫ÜÊúâÁ´∂Áà≠ÂäõÁöÑË°®Áèæ„ÄÇ

##### **Geometry of orofacial neuromuscular signals: speech articulation decoding using surface electromyography**
2411.02591v2 by Harshavardhana T. Gowda, Zachary D. McNaughton, Lee M. Miller

Each year, millions of individuals lose the ability to speak intelligibly due
to causes such as neuromuscular disease, stroke, trauma, and head/neck cancer
surgery (e.g. laryngectomy) or treatment (e.g. radiotherapy toxicity to the
speech articulators). Effective communication is crucial for daily activities,
and losing the ability to speak leads to isolation, depression, anxiety, and a
host of detrimental sequelae. Noninvasive surface electromyography (sEMG) has
shown promise to restore speech output in these individuals. The goal is to
collect sEMG signals from multiple articulatory sites as people silently
produce speech and then decode the signals to enable fluent and natural
communication. Currently, many fundamental properties of orofacial
neuromuscular signals relating to speech articulation remain unanswered. They
include questions relating to 1) the data structure of the orofacial sEMG
signals, 2)the signal distribution shift of sEMG across individuals, 3) ability
of sEMG signals to span the entire English language phonetic space during
silent speech articulations, and 4) the generalization capability of
non-invasive sEMG based silent speech interfaces. We address these questions
through a series of experiments involving healthy human subjects. We show that
sEMG signals evince graph data structure and that the signal distribution shift
is given by a change of basis. Furthermore, we show that silently voiced
articulations spanning the entire English language phonetic space can be
decoded using small neural networks which can be trained with little data and
that such architectures work well across individuals. To ensure transparency
and reproducibility, we open-source all the data and codes used in this study.

ÊëòË¶ÅÔºöÊØèÂπ¥ÔºåÊï∏ÁôæËê¨‰∫∫Âõ†Á•ûÁ∂ìËÇåËÇâÁñæÁóÖ„ÄÅ‰∏≠È¢®„ÄÅÂâµÂÇ∑„ÄÅÈ†≠È†∏ÁôåÊâãË°ìÔºà‰æãÂ¶ÇÂñâÂàáÈô§Ë°ìÔºâÊàñÊ≤ªÁôÇÔºà‰æãÂ¶ÇÊîæÂ∞ÑÊ≤ªÁôÇÂ∞çË®ÄË™ûÊßãÈü≥Âô®ÂÆòÁöÑÊØíÊÄßÔºâËÄåÂ§±ÂéªÊ∏ÖÊô∞Ë™™Ë©±ÁöÑËÉΩÂäõ„ÄÇÊúâÊïàÁöÑÊ∫ùÈÄöÂ∞çÊñºÊó•Â∏∏Ê¥ªÂãïËá≥ÈóúÈáçË¶ÅÔºåËÄåÂ§±ÂéªË™™Ë©±ÁöÑËÉΩÂäõÊúÉÂ∞éËá¥Â≠§Á´ã„ÄÅÊ≤ÆÂñ™„ÄÅÁÑ¶ÊÖÆÂíå‰∏ÄÁ≥ªÂàóÊúâÂÆ≥ÁöÑÂæåÈÅ∫Áóá„ÄÇÈùû‰æµÂÖ•ÊÄßË°®Èù¢ËÇåÈõªÂúñ (sEMG) Â∑≤È°ØÁ§∫Âá∫ÊÅ¢Âæ©ÈÄô‰∫õ‰∫∫Ë™™Ë©±Ëº∏Âá∫ÁöÑÂ∏åÊúõ„ÄÇÁõÆÊ®ôÊòØÂæûÂ§öÂÄãÊßãÈü≥ÈÉ®‰ΩçÊî∂ÈõÜ sEMG ‰ø°ËôüÔºåÂõ†ÁÇ∫‰∫∫ÂÄëÂú®ÁÑ°ËÅ≤Âú∞ÁôºÈü≥ÔºåÁÑ∂ÂæåËß£Á¢º‰ø°Ëôü‰ª•ÂØ¶ÁèæÊµÅÂà©ËÄåËá™ÁÑ∂ÁöÑÊ∫ùÈÄö„ÄÇÁõÆÂâçÔºåË®±Â§öËàáË®ÄË™ûÊßãÈü≥ÊúâÈóúÁöÑÈù¢ÈÉ®Á•ûÁ∂ìËÇåËÇâ‰ø°ËôüÁöÑÂü∫Êú¨ÁâπÊÄß‰ªçÊú™ÂæóÂà∞Ëß£Á≠î„ÄÇÂÆÉÂÄëÂåÖÊã¨Ëàá 1) Èù¢ÈÉ® sEMG ‰ø°ËôüÁöÑÊï∏ÊìöÁµêÊßã„ÄÅ2) sEMG Âú®ÂÄã‰∫∫‰πãÈñìÁöÑ‰ø°ËôüÂàÜ‰ΩàËΩâÁßª„ÄÅ3) sEMG ‰ø°ËôüÂú®ÁÑ°ËÅ≤Ë®ÄË™ûÊßãÈü≥ÈÅéÁ®ã‰∏≠Ë∑®Ë∂äÊï¥ÂÄãËã±Ë™ûË™ûÈü≥Á©∫ÈñìÁöÑËÉΩÂäõ‰ª•Âèä 4) Âü∫ÊñºÈùû‰æµÂÖ•ÊÄß sEMG ÁöÑÁÑ°ËÅ≤Ë®ÄË™û‰ªãÈù¢ÁöÑÊ≥õÂåñËÉΩÂäõÁõ∏ÈóúÁöÑÂïèÈ°å„ÄÇÊàëÂÄëÈÄöÈÅé‰∏ÄÁ≥ªÂàóÊ∂âÂèäÂÅ•Â∫∑‰∫∫È°ûÂèóË©¶ËÄÖÁöÑÂØ¶È©ó‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°å„ÄÇÊàëÂÄëË°®Êòé sEMG ‰ø°ËôüË°®ÁèæÂá∫ÂúñÊï∏ÊìöÁµêÊßãÔºå‰∏¶‰∏î‰ø°ËôüÂàÜ‰ΩàËΩâÁßªÊòØÁî±Âü∫ËÆäÂåñÁöÑÁµ¶Âá∫ÁöÑ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË°®ÊòéÔºå‰ΩøÁî®ÂèØ‰ª•ÈÄöÈÅéÂ∞ëÈáèÊï∏ÊìöË®ìÁ∑¥ÁöÑÂ∞èÁ•ûÁ∂ìÁ∂≤Ë∑ØÂèØ‰ª•Ëß£Á¢ºË∑®Ë∂äÊï¥ÂÄãËã±Ë™ûË™ûÈü≥Á©∫ÈñìÁöÑÁÑ°ËÅ≤ÁôºÈü≥Ôºå‰∏¶‰∏îÈÄôÁ®ÆÊû∂ÊßãÂú®‰∏çÂêåÂÄãÈ´î‰πãÈñìÈÉΩËÉΩÂæàÂ•ΩÂú∞Â∑•‰Ωú„ÄÇÁÇ∫‰∫ÜÁ¢∫‰øùÈÄèÊòéÂ∫¶ÂíåÂèØË§áË£ΩÊÄßÔºåÊàëÂÄëÂÖ¨Èñã‰∫ÜÊú¨Á†îÁ©∂‰∏≠‰ΩøÁî®ÁöÑÊâÄÊúâÊï∏ÊìöÂíå‰ª£Á¢º„ÄÇ

##### **GraphXAIN: Narratives to Explain Graph Neural Networks**
2411.02540v2 by Mateusz Cedro, David Martens

Graph Neural Networks (GNNs) are a powerful technique for machine learning on
graph-structured data, yet they pose interpretability challenges, especially
for non-expert users. Existing GNN explanation methods often yield technical
outputs such as subgraphs and feature importance scores, which are not easily
understood. Building on recent insights from social science and other
Explainable AI (XAI) methods, we propose GraphXAIN, a natural language
narrative that explains individual predictions made by GNNs. We present a
model-agnostic and explainer-agnostic XAI approach that complements graph
explainers by generating GraphXAINs, using Large Language Models (LLMs) and
integrating graph data, individual predictions from GNNs, explanatory
subgraphs, and feature importances. We define XAI Narratives and XAI
Descriptions, highlighting their distinctions and emphasizing the importance of
narrative principles in effective explanations. By incorporating natural
language narratives, our approach supports graph practitioners and non-expert
users, aligning with social science research on explainability and enhancing
user understanding and trust in complex GNN models. We demonstrate GraphXAIN's
capabilities on a real-world graph dataset, illustrating how its generated
narratives can aid understanding compared to traditional graph explainer
outputs or other descriptive explanation methods.

ÊëòË¶ÅÔºöÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÊòØÁî®ÊñºÂúñÂΩ¢ÁµêÊßãË≥áÊñôÁöÑÊ©üÂô®Â≠∏ÁøíÂº∑Â§ßÊäÄË°ìÔºå‰ΩÜÂÆÉÂÄëÊúÉÈÄ†ÊàêÂèØËß£ÈáãÊÄßÊåëÊà∞ÔºåÁâπÂà•ÊòØÂ∞çÊñºÈùûÂ∞àÂÆ∂‰ΩøÁî®ËÄÖ„ÄÇÁèæÊúâÁöÑ GNN Ëß£ÈáãÊñπÊ≥ïÈÄöÂ∏∏ÊúÉÁî¢ÁîüÊäÄË°ìËº∏Âá∫Ôºå‰æãÂ¶ÇÂ≠êÂúñÂíåÁâπÂæµÈáçË¶ÅÊÄßÂàÜÊï∏ÔºåÈÄô‰∫õËº∏Âá∫‰∏çÂÆπÊòìÁêÜËß£„ÄÇÂª∫ÊßãÊñºÁ§æÊúÉÁßëÂ≠∏ÂíåÂÖ∂‰ªñÂèØËß£Èáã AI (XAI) ÊñπÊ≥ïÁöÑÊúÄÊñ∞Ë¶ãËß£ÔºåÊàëÂÄëÊèêÂá∫ GraphXAINÔºåÈÄôÊòØ‰∏ÄÁ®ÆËá™ÁÑ∂Ë™ûË®ÄÊïòËø∞ÔºåÂèØ‰ª•Ëß£Èáã GNN ÂÅöÂá∫ÁöÑÂÄãÂà•È†êÊ∏¨„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãËàáÊ®°ÂûãÁÑ°Èóú‰∏îËàáËß£ÈáãÂô®ÁÑ°ÈóúÁöÑ XAI ÊñπÊ≥ïÔºåÂÆÉÈÄèÈÅé‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÊï¥ÂêàÂúñÂΩ¢Ë≥áÊñô„ÄÅGNN ÁöÑÂÄãÂà•È†êÊ∏¨„ÄÅË™™ÊòéÊÄßÂ≠êÂúñÂíåÁâπÂæµÈáçË¶ÅÊÄß‰æÜË£úÂÖÖÂúñÂΩ¢Ëß£ÈáãÂô®ÔºåÈÄ≤ËÄåÁî¢Áîü GraphXAIN„ÄÇÊàëÂÄëÂÆöÁæ© XAI ÊïòËø∞Âíå XAI ÊèèËø∞ÔºåÂº∑Ë™øÂÆÉÂÄëÁöÑÂçÄÂà•Ôºå‰∏¶Âº∑Ë™øÊïòËø∞ÂéüÂâáÂú®ÊúâÊïàËß£Èáã‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄèÈÅéÁµêÂêàËá™ÁÑ∂Ë™ûË®ÄÊïòËø∞ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊîØÊè¥ÂúñÂΩ¢ÂæûÊ•≠ËÄÖÂíåÈùûÂ∞àÂÆ∂‰ΩøÁî®ËÄÖÔºåËàáÂèØËß£ÈáãÊÄßÁöÑÁ§æÊúÉÁßëÂ≠∏Á†îÁ©∂‰øùÊåÅ‰∏ÄËá¥Ôºå‰∏¶Â¢ûÂº∑‰ΩøÁî®ËÄÖÂ∞çË§áÈõú GNN Ê®°ÂûãÁöÑÁêÜËß£Âíå‰ø°‰ªª„ÄÇÊàëÂÄëÂú®ÁúüÂØ¶‰∏ñÁïåÂúñÂΩ¢Ë≥áÊñôÈõÜ‰∏äÂ±ïÁ§∫ GraphXAIN ÁöÑÂäüËÉΩÔºåË™™ÊòéËàáÂÇ≥Áµ±ÂúñÂΩ¢Ëß£ÈáãÂô®Ëº∏Âá∫ÊàñÂÖ∂‰ªñÊèèËø∞ÊÄßËß£ÈáãÊñπÊ≥ïÁõ∏ÊØîÔºåÂÖ∂Áî¢ÁîüÁöÑÊïòËø∞Â¶Ç‰ΩïÊúâÂä©ÊñºÁêÜËß£„ÄÇ

##### **Improving Scientific Hypothesis Generation with Knowledge Grounded Large Language Models**
2411.02382v1 by Guangzhi Xiong, Eric Xie, Amir Hassan Shariatmadari, Sikun Guo, Stefan Bekiranov, Aidong Zhang

Large language models (LLMs) have demonstrated remarkable capabilities in
various scientific domains, from natural language processing to complex
problem-solving tasks. Their ability to understand and generate human-like text
has opened up new possibilities for advancing scientific research, enabling
tasks such as data analysis, literature review, and even experimental design.
One of the most promising applications of LLMs in this context is hypothesis
generation, where they can identify novel research directions by analyzing
existing knowledge. However, despite their potential, LLMs are prone to
generating ``hallucinations'', outputs that are plausible-sounding but
factually incorrect. Such a problem presents significant challenges in
scientific fields that demand rigorous accuracy and verifiability, potentially
leading to erroneous or misleading conclusions. To overcome these challenges,
we propose KG-CoI (Knowledge Grounded Chain of Ideas), a novel system that
enhances LLM hypothesis generation by integrating external, structured
knowledge from knowledge graphs (KGs). KG-CoI guides LLMs through a structured
reasoning process, organizing their output as a chain of ideas (CoI), and
includes a KG-supported module for the detection of hallucinations. With
experiments on our newly constructed hypothesis generation dataset, we
demonstrate that KG-CoI not only improves the accuracy of LLM-generated
hypotheses but also reduces the hallucination in their reasoning chains,
highlighting its effectiveness in advancing real-world scientific research.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®ÂêÑÁ®ÆÁßëÂ≠∏È†òÂüüÂ±ïÁèæÂçìË∂äÁöÑËÉΩÂäõÔºåÂæûËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÂà∞Ë§áÈõúÁöÑËß£Ê±∫ÂïèÈ°å‰ªªÂãô„ÄÇÂÆÉÂÄëÁêÜËß£ÂíåÁî¢ÁîüÈ°û‰ºº‰∫∫È°ûÊñáÂ≠óÁöÑËÉΩÂäõÁÇ∫Êé®ÈÄ≤ÁßëÂ≠∏Á†îÁ©∂ÈñãÂïü‰∫ÜÊñ∞ÁöÑÂèØËÉΩÊÄßÔºåËÆìË≥áÊñôÂàÜÊûê„ÄÅÊñáÁçªÂõûÈ°ßÔºåÁîöËá≥ÂØ¶È©óË®≠Ë®àÁ≠â‰ªªÂãôÊàêÁÇ∫ÂèØËÉΩ„ÄÇLLM Âú®Ê≠§ËÑàÁµ°‰∏≠ÊúÄÊúâÂ∏åÊúõÁöÑÊáâÁî®‰πã‰∏ÄÊòØÂÅáË®≠Áî¢ÁîüÔºåÂÆÉÂÄëËÉΩÈÄèÈÅéÂàÜÊûêÁèæÊúâÁü•Ë≠ò‰æÜÊâæÂá∫Êñ∞ÁöÑÁ†îÁ©∂ÊñπÂêë„ÄÇÁÑ∂ËÄåÔºåÂÑòÁÆ° LLM ÂÖ∑ÊúâÊΩõÂäõÔºåÂÆÉÂÄëÂçªÂÆπÊòìÁî¢Áîü„ÄåÂπªË¶∫„ÄçÔºå‰πüÂ∞±ÊòØËÅΩËµ∑‰æÜÂêàÁêÜ‰ΩÜ‰∫ãÂØ¶‰∏ä‰∏çÊ≠£Á¢∫ÁöÑËº∏Âá∫„ÄÇÊ≠§È°ûÂïèÈ°åÂú®ÈúÄË¶ÅÂö¥Ë¨πÊ∫ñÁ¢∫ÊÄßÂíåÂèØÈ©óË≠âÊÄßÁöÑÁßëÂ≠∏È†òÂüü‰∏≠ÊúÉÈÄ†ÊàêÈáçÂ§ßÊåëÊà∞ÔºåÊúâÂèØËÉΩÂ∞éËá¥ÈåØË™§ÊàñË™§Â∞éÊÄßÁöÑÁµêË´ñ„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫ KG-CoIÔºàÁü•Ë≠òÂü∫Á§éËßÄÂøµÈèàÔºâÔºåÈÄôÊòØ‰∏ÄÂÄãÂâµÊñ∞ÁöÑÁ≥ªÁµ±ÔºåÂÆÉÈÄèÈÅéÊï¥ÂêàÁü•Ë≠òÂúñË≠ú (KG) ‰∏≠ÁöÑÂ§ñÈÉ®ÁµêÊßãÂåñÁü•Ë≠ò‰æÜÂ¢ûÂº∑ LLM ÂÅáË®≠Áî¢Áîü„ÄÇKG-CoI ÂºïÂ∞é LLM ÈÄ≤Ë°åÁµêÊßãÂåñÊé®ÁêÜÁ®ãÂ∫èÔºåÂ∞áÂÖ∂Ëº∏Âá∫Êï¥ÁêÜÊàêËßÄÂøµÈèà (CoI)Ôºå‰∏¶ÂåÖÂê´‰∏ÄÂÄãÁî± KG ÊîØÊè¥ÁöÑÊ®°ÁµÑ‰æÜÂÅµÊ∏¨ÂπªË¶∫„ÄÇÈÄèÈÅéÊàëÂÄëÊñ∞Âª∫Á´ãÁöÑÂÅáË®≠Áî¢ÁîüË≥áÊñôÈõÜÈÄ≤Ë°åÁöÑÂØ¶È©óÔºåÊàëÂÄëË≠âÊòé KG-CoI ‰∏çÂÉÖÊîπÂñÑ‰∫Ü LLM Áî¢ÁîüÁöÑÂÅáË®≠ÁöÑÊ∫ñÁ¢∫ÊÄßÔºå‰πüÊ∏õÂ∞ë‰∫ÜÂÖ∂Êé®ÁêÜÈèà‰∏≠ÁöÑÂπªË¶∫ÔºåÁ™ÅÈ°Ø‰∫ÜÂÖ∂Âú®Êé®ÈÄ≤ÁèæÂØ¶‰∏ñÁïåÁßëÂ≠∏Á†îÁ©∂‰∏≠ÁöÑÊïàËÉΩ„ÄÇ

##### **QCG-Rerank: Chunks Graph Rerank with Query Expansion in Retrieval-Augmented LLMs for Tourism Domain**
2411.08724v1 by Qikai Wei, Mingzhi Yang, Chunlong Han, Jingfu Wei, Minghao Zhang, Feifei Shi, Huansheng Ning

Retrieval-Augmented Generation (RAG) mitigates the issue of hallucination in
Large Language Models (LLMs) by integrating information retrieval techniques.
However, in the tourism domain, since the query is usually brief and the
content in the database is diverse, existing RAG may contain a significant
amount of irrelevant or contradictory information contents after retrieval. To
address this challenge, we propose the QCG-Rerank model. This model first
performs an initial retrieval to obtain candidate chunks and then enhances
semantics by extracting critical information to expand the original query.
Next, we utilize the expanded query and candidate chunks to calculate
similarity scores as the initial transition probability and construct the
chunks graph. Subsequently, We iteratively compute the transition probabilities
based on an initial estimate until convergence. The chunks with the highest
score are selected and input into the LLMs to generate responses. We evaluate
the model on Cultour, IIRC, StrategyQA, HotpotQA, SQuAD, and MuSiQue datasets.
The experimental results demonstrate the effectiveness and superiority of the
QCG-Rerank method.

ÊëòË¶ÅÔºöÊì∑ÂèñÂ¢ûÂº∑ÁîüÊàêÔºàRAGÔºâÈÄèÈÅéÊï¥ÂêàË≥áË®äÊì∑ÂèñÊäÄË°ì‰æÜÁ∑©Ëß£Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâ‰∏≠ÁöÑÂπªË¶∫ÂïèÈ°å„ÄÇÁÑ∂ËÄåÔºåÂú®ÊóÖÈÅäÈ†òÂüü‰∏≠ÔºåÁî±ÊñºÊü•Ë©¢ÈÄöÂ∏∏ÂæàÁ∞°Áü≠ÔºåËÄåË≥áÊñôÂ∫´‰∏≠ÁöÑÂÖßÂÆπÂ§öÊ®£ÔºåÂõ†Ê≠§ÁèæÊúâÁöÑ RAG ÂèØËÉΩÊúÉÂú®Êì∑ÂèñÂæåÂåÖÂê´Â§ßÈáè‰∏çÁõ∏ÈóúÊàñÁüõÁõæÁöÑË≥áË®äÂÖßÂÆπ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄôÂÄãÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü QCG-Rerank Ê®°Âûã„ÄÇÊ≠§Ê®°ÂûãÈ¶ñÂÖàÂü∑Ë°åÂàùÂßãÊì∑Âèñ‰ª•ÂèñÂæóÂÄôÈÅ∏ÂçÄÂ°äÔºåÁÑ∂ÂæåÈÄèÈÅéÊì∑ÂèñÈóúÈçµË≥áË®ä‰æÜÊì¥ÂÖÖÂéüÂßãÊü•Ë©¢‰ª•Â¢ûÂº∑Ë™ûÊÑè„ÄÇÊé•ËëóÔºåÊàëÂÄëÂà©Áî®Êì¥ÂÖÖÁöÑÊü•Ë©¢ÂíåÂÄôÈÅ∏ÂçÄÂ°ä‰æÜË®àÁÆóÁõ∏‰ººÂ∫¶ÂàÜÊï∏‰ΩúÁÇ∫ÂàùÂßãËΩâÁßªÊ©üÁéáÔºå‰∏¶Âª∫ÊßãÂçÄÂ°äÂúñ„ÄÇÈö®ÂæåÔºåÊàëÂÄëÊ†πÊìöÂàùÂßã‰º∞Ë®àÂèçË¶ÜË®àÁÆóËΩâÁßªÊ©üÁéáÔºåÁõ¥Âà∞Êî∂ÊñÇ„ÄÇÊúÉÈÅ∏ÂèñÂàÜÊï∏ÊúÄÈ´òÁöÑÂçÄÂ°äÔºå‰∏¶Ëº∏ÂÖ•Âà∞ LLM ‰ª•Áî¢ÁîüÂõûÊáâ„ÄÇÊàëÂÄëÂú® Cultour„ÄÅIIRC„ÄÅStrategyQA„ÄÅHotpotQA„ÄÅSQuAD Âíå MuSiQue Ë≥áÊñôÈõÜ‰∏äË©ï‰º∞Ê≠§Ê®°Âûã„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòé‰∫Ü QCG-Rerank ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÂíåÂÑ™Ë∂äÊÄß„ÄÇ

##### **Can Language Models Enable In-Context Database?**
2411.01807v1 by Yu Pan, Hongfeng Yu, Tianjiao Zhao, Jianxin Sun

Large language models (LLMs) are emerging as few-shot learners capable of
handling a variety of tasks, including comprehension, planning, reasoning,
question answering, arithmetic calculations, and more. At the core of these
capabilities is LLMs' proficiency in representing and understanding structural
or semi-structural data, such as tables and graphs. Numerous studies have
demonstrated that reasoning on tabular data or graphs is not only feasible for
LLMs but also gives a promising research direction which treats these data as
in-context data. The lightweight and human readable characteristics of
in-context database can potentially make it an alternative for the traditional
database in typical RAG (Retrieval Augmented Generation) settings. However,
almost all current work focuses on static in-context data, which does not allow
dynamic update. In this paper, to enable dynamic database update, delta
encoding of database is proposed. We explore how data stored in traditional
RDBMS can be encoded as in-context text and evaluate LLMs' proficiency for CRUD
(Create, Read, Update and Delete) operations on in-context databases. A
benchmark named InConDB is presented and extensive experiments are conducted to
show the performance of different language models in enabling in-context
database by varying the database encoding method, prompting method, operation
type and input data distribution, revealing both the proficiency and
limitations.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄêÊº∏ÊàêÁÇ∫ÂÉÖÈúÄÂ∞ëÈáèÁØÑ‰æãÂ∞±ËÉΩËôïÁêÜÂêÑÁ®Æ‰ªªÂãôÁöÑÂ≠∏ÁøíËÄÖÔºåÂåÖÊã¨ÁêÜËß£„ÄÅË¶èÂäÉ„ÄÅÊé®ÁêÜ„ÄÅÂïèÁ≠î„ÄÅÁÆóË°ìË®àÁÆóÁ≠â„ÄÇÈÄô‰∫õËÉΩÂäõÁöÑÊ†∏ÂøÉÊòØ LLM Âú®Ë°®Á§∫ÂíåÁêÜËß£ÁµêÊßãÂåñÊàñÂçäÁµêÊßãÂåñË≥áÊñôÔºà‰æãÂ¶ÇË°®Ê†ºÂíåÂúñÂΩ¢ÔºâÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇË®±Â§öÁ†îÁ©∂Â∑≤Ë≠âÊòéÔºåLLM ‰∏çÂÉÖÂèØ‰ª•Êé®Ë´ñË°®Ê†ºË≥áÊñôÊàñÂúñÂΩ¢ÔºåÈÇÑÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÊôØÁöÑÁ†îÁ©∂ÊñπÂêëÔºåÂ∞áÈÄô‰∫õË≥áÊñôË¶ñÁÇ∫Ë™ûÂ¢ÉË≥áÊñô„ÄÇË™ûÂ¢ÉË≥áÊñôÂ∫´ÁöÑËºïÈáèÁ¥öÂíå‰∫∫È°ûÂèØËÆÄÂèñÁâπÊÄßÊúâÂèØËÉΩ‰ΩøÂÖ∂ÊàêÁÇ∫ÂÖ∏Âûã RAGÔºàÊ™¢Á¥¢Êì¥ÂÖÖÁîüÊàêÔºâË®≠ÂÆö‰∏≠ÂÇ≥Áµ±Ë≥áÊñôÂ∫´ÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇÁÑ∂ËÄåÔºåÂπæ‰πéÊâÄÊúâÁõÆÂâçÁöÑÂ∑•‰ΩúÈÉΩÂ∞àÊ≥®ÊñºÈùúÊÖãË™ûÂ¢ÉË≥áÊñôÔºåÈÄô‰∏çÂÖÅË®±ÂãïÊÖãÊõ¥Êñ∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÁÇ∫‰∫ÜÂØ¶ÁèæÂãïÊÖãË≥áÊñôÂ∫´Êõ¥Êñ∞ÔºåÊèêÂá∫‰∫ÜË≥áÊñôÂ∫´ÁöÑ delta Á∑®Á¢º„ÄÇÊàëÂÄëÊé¢Ë®é‰∫ÜÂ¶Ç‰ΩïÂ∞áÂÑ≤Â≠òÂú®ÂÇ≥Áµ± RDBMS ‰∏≠ÁöÑË≥áÊñôÁ∑®Á¢ºÁÇ∫Ë™ûÂ¢ÉÊñáÂ≠óÔºå‰∏¶Ë©ï‰º∞ LLM Âú®Ë™ûÂ¢ÉË≥áÊñôÂ∫´‰∏äÈÄ≤Ë°å CRUDÔºàÂª∫Á´ã„ÄÅËÆÄÂèñ„ÄÅÊõ¥Êñ∞ÂíåÂà™Èô§ÔºâÊìç‰ΩúÁöÑËÉΩÂäõ„ÄÇÊèêÂá∫‰∫ÜÂêçÁÇ∫ InConDB ÁöÑÂü∫Ê∫ñÔºå‰∏¶ÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºå‰ª•È°ØÁ§∫‰∏çÂêåË™ûË®ÄÊ®°ÂûãÂú®ÈÄöÈÅéÊîπËÆäË≥áÊñôÂ∫´Á∑®Á¢ºÊñπÊ≥ï„ÄÅÊèêÁ§∫ÊñπÊ≥ï„ÄÅÊìç‰ΩúÈ°ûÂûãÂíåËº∏ÂÖ•Ë≥áÊñôÂàÜ‰Ωà‰æÜÂïüÁî®Ë™ûÂ¢ÉË≥áÊñôÂ∫´ÊñπÈù¢ÁöÑÊïàËÉΩÔºåÊè≠Á§∫‰∫ÜËÉΩÂäõÂíåÈôêÂà∂„ÄÇ

##### **Graph-based Confidence Calibration for Large Language Models**
2411.02454v1 by Yukun Li, Sijia Wang, Lifu Huang, Li-Ping Liu

One important approach to improving the reliability of large language models
(LLMs) is to provide accurate confidence estimations regarding the correctness
of their answers. However, developing a well-calibrated confidence estimation
model is challenging, as mistakes made by LLMs can be difficult to detect. We
propose a novel method combining the LLM's self-consistency with labeled data
and training an auxiliary model to estimate the correctness of its responses to
questions. This auxiliary model predicts the correctness of responses based
solely on their consistent information. To set up the learning problem, we use
a weighted graph to represent the consistency among the LLM's multiple
responses to a question. Correctness labels are assigned to these responses
based on their similarity to the correct answer. We then train a graph neural
network to estimate the probability of correct responses. Experiments
demonstrate that the proposed approach substantially outperforms several of the
most recent methods in confidence calibration across multiple widely adopted
benchmark datasets. Furthermore, the proposed approach significantly improves
the generalization capability of confidence calibration on out-of-domain (OOD)
data.

ÊëòË¶ÅÔºö‰∏ÄÁ®ÆÊîπÂñÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂèØÈù†ÊÄßÁöÑÈáçË¶ÅÊñπÊ≥ïÊòØÊèê‰æõÊúâÈóúÂÖ∂Á≠îÊ°àÊ≠£Á¢∫ÊÄßÁöÑÊ∫ñÁ¢∫‰ø°ÂøÉ‰º∞Ë®à„ÄÇÁÑ∂ËÄåÔºåÈñãÁôº‰∏ÄÂÄãÊ†°Ê∫ñËâØÂ•ΩÁöÑ‰ø°ÂøÉ‰º∞Ë®àÊ®°ÂûãÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÂõ†ÁÇ∫ LLM ÊâÄÁäØÁöÑÈåØË™§ÂèØËÉΩÈõ£‰ª•ÂÅµÊ∏¨„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÊñπÊ≥ïÔºåÁµêÂêà LLM ÁöÑËá™Êàë‰∏ÄËá¥ÊÄßËàáÊ®ôÁ±§Ë≥áÊñôÔºå‰∏¶Ë®ìÁ∑¥‰∏ÄÂÄãËºîÂä©Ê®°Âûã‰æÜ‰º∞Ë®àÂÖ∂Â∞çÂïèÈ°åÁöÑÂõûÊáâÊ≠£Á¢∫ÊÄß„ÄÇÈÄôÂÄãËºîÂä©Ê®°ÂûãÂÉÖÊ†πÊìöÂÖ∂‰∏ÄËá¥ÊÄßË≥áË®ä‰æÜÈ†êÊ∏¨ÂõûÊáâÁöÑÊ≠£Á¢∫ÊÄß„ÄÇÁÇ∫‰∫ÜË®≠ÂÆöÂ≠∏ÁøíÂïèÈ°åÔºåÊàëÂÄë‰ΩøÁî®‰∏ÄÂÄãÂä†Ê¨äÂúñÂΩ¢‰æÜË°®Á§∫ LLM Â∞ç‰∏ÄÂÄãÂïèÈ°åÁöÑÂ§öÊ¨°ÂõûÊáâ‰πãÈñìÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÊ≠£Á¢∫ÊÄßÊ®ôÁ±§ÊúÉÊ†πÊìöÈÄô‰∫õÂõûÊáâËàáÊ≠£Á¢∫Á≠îÊ°àÁöÑÁõ∏‰ººÊÄßÂàÜÈÖçÁµ¶ÈÄô‰∫õÂõûÊáâ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëË®ìÁ∑¥‰∏ÄÂÄãÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø‰æÜ‰º∞Ë®àÊ≠£Á¢∫ÂõûÊáâÁöÑÊ©üÁéá„ÄÇÂØ¶È©óË≠âÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®Â§öÂÄãÂª£Ê≥õÊé°Áî®ÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÔºåÂú®‰ø°ÂøÉÊ†°Ê∫ñÊñπÈù¢ÊòéÈ°ØÂÑ™ÊñºÂ§öÁ®ÆÊúÄÊñ∞ÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÈ°ØËëóÊîπÂñÑ‰∫ÜÂú®È†òÂüüÂ§ñ (OOD) Ë≥áÊñô‰∏ä‰ø°ÂøÉÊ†°Ê∫ñÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

##### **Ontology Population using LLMs**
2411.01612v1 by Sanaz Saki Norouzi, Adrita Barua, Antrea Christou, Nikita Gautam, Andrew Eells, Pascal Hitzler, Cogan Shimizu

Knowledge graphs (KGs) are increasingly utilized for data integration,
representation, and visualization. While KG population is critical, it is often
costly, especially when data must be extracted from unstructured text in
natural language, which presents challenges, such as ambiguity and complex
interpretations. Large Language Models (LLMs) offer promising capabilities for
such tasks, excelling in natural language understanding and content generation.
However, their tendency to ``hallucinate'' can produce inaccurate outputs.
Despite these limitations, LLMs offer rapid and scalable processing of natural
language data, and with prompt engineering and fine-tuning, they can
approximate human-level performance in extracting and structuring data for KGs.
This study investigates LLM effectiveness for the KG population, focusing on
the Enslaved.org Hub Ontology. In this paper, we report that compared to the
ground truth, LLM's can extract ~90% of triples, when provided a modular
ontology as guidance in the prompts.

ÊëòË¶ÅÔºöÁü•Ë≠òÂúñË≠ú (KG) ÊÑà‰æÜÊÑàÂ§öÁî®ÊñºË≥áÊñôÊï¥Âêà„ÄÅË°®Á§∫ÂíåË¶ñË¶∫Âåñ„ÄÇÂÑòÁÆ° KG Â°´ÂÖÖËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÂÆÉÈÄöÂ∏∏ÂæàÊòÇË≤¥ÔºåÁâπÂà•ÊòØÂú®ÂøÖÈ†àÂæûËá™ÁÑ∂Ë™ûË®Ä‰∏≠ÈùûÁµêÊßãÂåñÊñáÂ≠ó‰∏≠ÊèêÂèñË≥áÊñôÊôÇÔºåÈÄôÊúÉÂ∏∂‰æÜÊåëÊà∞Ôºå‰æãÂ¶ÇÊ≠ßÁæ©ÂíåË§áÈõúÁöÑË©ÆÈáã„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁÇ∫Ê≠§È°û‰ªªÂãôÊèê‰æõ‰∫ÜÊúâÂâçÊôØÁöÑËÉΩÂäõÔºåÊìÖÈï∑Ëá™ÁÑ∂Ë™ûË®ÄÁêÜËß£ÂíåÂÖßÂÆπÁîüÊàê„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄë„ÄåÁî¢ÁîüÂπªË¶∫„ÄçÁöÑÂÇæÂêëÂèØËÉΩÊúÉÁî¢Áîü‰∏çÊ∫ñÁ¢∫ÁöÑËº∏Âá∫„ÄÇÂÑòÁÆ°ÊúâÈÄô‰∫õÈôêÂà∂ÔºåLLM Êèê‰æõ‰∫ÜËá™ÁÑ∂Ë™ûË®ÄË≥áÊñôÁöÑÂø´ÈÄü‰∏îÂèØÊì¥ÂÖÖËôïÁêÜÔºå‰∏¶‰∏îÈÄèÈÅéÊèêÁ§∫Â∑•Á®ãÂíåÂæÆË™øÔºåÂÆÉÂÄëÂèØ‰ª•Ëøë‰ºº‰∫∫È°ûÂ±§Á¥öÁöÑÊïàËÉΩÔºå‰ª•ÊèêÂèñÂíåÂª∫Êßã KG ÁöÑË≥áÊñô„ÄÇÊú¨Á†îÁ©∂Ë™øÊü• LLM Â∞ç KG Â°´ÂÖÖÁöÑÊúâÊïàÊÄßÔºåÈáçÈªûÈóúÊ≥® Enslaved.org Hub Ontology„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ†±ÂëäËàáÁúüÂØ¶ÊÉÖÊ≥ÅÁõ∏ÊØîÔºåÁï∂Âú®ÊèêÁ§∫‰∏≠Êèê‰æõÊ®°ÁµÑÂåñÊú¨‰Ωì‰ΩúÁÇ∫ÊåáÂ∞éÊôÇÔºåLLM ÂèØ‰ª•ÊèêÂèñÁ¥Ñ 90% ÁöÑ‰∏âÂÖÉÁµÑ„ÄÇ

##### **Pre-trained Molecular Language Models with Random Functional Group Masking**
2411.01401v1 by Tianhao Peng, Yuchen Li, Xuhong Li, Jiang Bian, Zeke Xie, Ning Sui, Shahid Mumtaz, Yanwu Xu, Linghe Kong, Haoyi Xiong

Recent advancements in computational chemistry have leveraged the power of
trans-former-based language models, such as MoLFormer, pre-trained using a vast
amount of simplified molecular-input line-entry system (SMILES) sequences, to
understand and predict molecular properties and activities, a critical step in
fields like drug discovery and materials science. To further improve
performance, researchers have introduced graph neural networks with graph-based
molecular representations, such as GEM, incorporating the topology, geometry,
2D or even 3D structures of molecules into pre-training. While most of
molecular graphs in existing studies were automatically converted from SMILES
sequences, it is to assume that transformer-based language models might be able
to implicitly learn structure-aware representations from SMILES sequences. In
this paper, we propose \ours{} -- a SMILES-based \underline{\em M}olecular
\underline{\em L}anguage \underline{\em M}odel, which randomly masking SMILES
subsequences corresponding to specific molecular \underline{\em F}unctional
\underline{\em G}roups to incorporate structure information of atoms during the
pre-training phase. This technique aims to compel the model to better infer
molecular structures and properties, thus enhancing its predictive
capabilities. Extensive experimental evaluations across 11 benchmark
classification and regression tasks in the chemical domain demonstrate the
robustness and superiority of \ours{}. Our findings reveal that \ours{}
outperforms existing pre-training models, either based on SMILES or graphs, in
9 out of the 11 downstream tasks, ranking as a close second in the remaining
ones.

ÊëòË¶ÅÔºö<paragraph>Ë®àÁÆóÂåñÂ≠∏ÁöÑËøëÊúüÈÄ≤Â±ïÂ∑≤Âà©Áî®ËΩâÊèõÂô®Ë™ûË®ÄÊ®°ÂûãÁöÑÂäõÈáèÔºå‰æãÂ¶Ç MoLFormerÔºå‰ΩøÁî®Â§ßÈáèÁ∞°ÂåñÂàÜÂ≠êËº∏ÂÖ•Á∑öÊ¢ùËº∏ÂÖ•Á≥ªÁµ± (SMILES) Â∫èÂàóÈÄ≤Ë°åÈ†êË®ìÁ∑¥Ôºå‰ª•‰∫ÜËß£ÂíåÈ†êÊ∏¨ÂàÜÂ≠êÁâπÊÄßÂíåÊ¥ªÊÄßÔºåÈÄôÊòØËó•Áâ©ÁôºÁèæÂíåÊùêÊñôÁßëÂ≠∏Á≠âÈ†òÂüüÁöÑÈáçË¶ÅÊ≠•È©ü„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•ÊèêÂçáÊïàËÉΩÔºåÁ†îÁ©∂‰∫∫Âì°ÂºïÂÖ•‰∫ÜÂÖ∑ÊúâÂúñÂΩ¢ÁÇ∫Âü∫Á§éÁöÑÂàÜÂ≠êË°®Á§∫ÁöÑÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑ØÔºå‰æãÂ¶Ç GEMÔºåÂ∞áÂàÜÂ≠êÁöÑÊãìÊ®∏„ÄÅÂπæ‰Ωï„ÄÅ2D ÁîöËá≥ 3D ÁµêÊßãÁ¥çÂÖ•È†êË®ìÁ∑¥‰∏≠„ÄÇÈõñÁÑ∂ÁèæÊúâÁ†îÁ©∂‰∏≠ÁöÑÂ§ßÂ§öÊï∏ÂàÜÂ≠êÂúñÂΩ¢ÈÉΩÊòØÂæû SMILES Â∫èÂàóËá™ÂãïËΩâÊèõËÄå‰æÜÁöÑÔºå‰ΩÜÂèØ‰ª•ÂÅáË®≠Âü∫ÊñºËΩâÊèõÂô®ÁöÑË™ûË®ÄÊ®°ÂûãÂèØËÉΩËÉΩÂ§†Âæû SMILES Â∫èÂàó‰∏≠Èö±ÂºèÂ≠∏ÁøíÁµêÊßãÊÑüÁü•Ë°®Á§∫„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ \ours{} -- ‰∏ÄÂÄãÂü∫Êñº SMILES ÁöÑ\underline{\em M}olecular\underline{\em L}anguage \underline{\em M}odelÔºåÂÆÉÈö®Ê©üÈÅÆËîΩÂ∞çÊáâÊñºÁâπÂÆöÂàÜÂ≠ê\underline{\em F}unctional\underline{\em G}roups ÁöÑ SMILES Â≠êÂ∫èÂàóÔºå‰ª•Âú®È†êË®ìÁ∑¥ÈöéÊÆµÁ¥çÂÖ•ÂéüÂ≠êÁöÑÁµêÊßãË≥áË®ä„ÄÇÊ≠§ÊäÄË°ìÊó®Âú®Âº∑Âà∂Ê®°ÂûãÊõ¥Â•ΩÂú∞Êé®Êñ∑ÂàÜÂ≠êÁµêÊßãÂíåÁâπÊÄßÔºåÂæûËÄåÂ¢ûÂº∑ÂÖ∂È†êÊ∏¨ËÉΩÂäõ„ÄÇÂú®ÂåñÂ≠∏È†òÂüüÁöÑ 11 ÂÄãÂü∫Ê∫ñÂàÜÈ°ûÂíåÂõûÊ≠∏‰ªªÂãô‰∏≠ÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË©ï‰º∞Ë≠âÊòé‰∫Ü \ours{} ÁöÑÁ©©ÂÅ•ÊÄßÂíåÂÑ™Ë∂äÊÄß„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫Ôºå\ours{} Âú® 11 ÂÄã‰∏ãÊ∏∏‰ªªÂãô‰∏≠ÁöÑ 9 ÂÄã‰ªªÂãô‰∏≠ÂÑ™ÊñºÁèæÊúâÁöÑÈ†êË®ìÁ∑¥Ê®°ÂûãÔºàÂü∫Êñº SMILES ÊàñÂúñÂΩ¢ÔºâÔºåÂú®Ââ©‰∏ãÁöÑ‰ªªÂãô‰∏≠ÊéíÂêçÁ¨¨‰∫å„ÄÇ</paragraph>

##### **Narrative Analysis of True Crime Podcasts With Knowledge Graph-Augmented Large Language Models**
2411.02435v1 by Xinyi Leng, Jason Liang, Jack Mauro, Xu Wang, Andrea L. Bertozzi, James Chapman, Junyuan Lin, Bohan Chen, Chenchen Ye, Temple Daniel, P. Jeffrey Brantingham

Narrative data spans all disciplines and provides a coherent model of the
world to the reader or viewer. Recent advancement in machine learning and Large
Language Models (LLMs) have enable great strides in analyzing natural language.
However, Large language models (LLMs) still struggle with complex narrative
arcs as well as narratives containing conflicting information. Recent work
indicates LLMs augmented with external knowledge bases can improve the accuracy
and interpretability of the resulting models. In this work, we analyze the
effectiveness of applying knowledge graphs (KGs) in understanding true-crime
podcast data from both classical Natural Language Processing (NLP) and LLM
approaches. We directly compare KG-augmented LLMs (KGLLMs) with classical
methods for KG construction, topic modeling, and sentiment analysis.
Additionally, the KGLLM allows us to query the knowledge base in natural
language and test its ability to factually answer questions. We examine the
robustness of the model to adversarial prompting in order to test the model's
ability to deal with conflicting information. Finally, we apply classical
methods to understand more subtle aspects of the text such as the use of
hearsay and sentiment in narrative construction and propose future directions.
Our results indicate that KGLLMs outperform LLMs on a variety of metrics, are
more robust to adversarial prompts, and are more capable of summarizing the
text into topics.

ÊëòË¶ÅÔºöÊïò‰∫ãË≥áÊñôÊ∂µËìãÊâÄÊúâÂ≠∏ÁßëÔºå‰∏¶ÁÇ∫ËÆÄËÄÖÊàñËßÄÁúæÊèê‰æõ‰∏ÄÂÄãÈÄ£Ë≤´ÁöÑ‰∏ñÁïåÊ®°Âûã„ÄÇÊ©üÂô®Â≠∏ÁøíÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂú®ÂàÜÊûêËá™ÁÑ∂Ë™ûË®ÄÊñπÈù¢ÂèñÂæó‰∫ÜÈï∑Ë∂≥ÁöÑÈÄ≤Ê≠•„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰ªçÁÑ∂Èõ£‰ª•Êáâ‰ªòË§áÈõúÁöÑÊïò‰∫ãÂºßÁ∑ö‰ª•ÂèäÂåÖÂê´Áõ∏‰∫íÁüõÁõæË≥áË®äÁöÑÊïò‰∫ã„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºå‰ΩøÁî®Â§ñÈÉ®Áü•Ë≠òÂ∫´Â¢ûÂº∑ÁöÑ LLM ÂèØ‰ª•ÊèêÈ´òÊâÄÁî¢ÁîüÊ®°ÂûãÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂèØËß£ÈáãÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂàÜÊûê‰∫ÜÂú®ÂæûÂÇ≥Áµ±Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) Âíå LLM ÊñπÊ≥ï‰∏≠ÁêÜËß£ÁúüÂØ¶ÁäØÁΩ™Êí≠ÂÆ¢Ë≥áÊñôÊôÇÔºåÊáâÁî®Áü•Ë≠òÂúñË≠ú (KG) ÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÁõ¥Êé•ÊØîËºÉ‰∫Ü KG Â¢ûÂº∑ÁöÑ LLM (KGLLM) ËàáÁî®Êñº KG Âª∫Êßã„ÄÅ‰∏ªÈ°åÂª∫Ê®°ÂíåÊÉÖÁ∑íÂàÜÊûêÁöÑÂÇ≥Áµ±ÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåKGLLM ÂÖÅË®±ÊàëÂÄë‰ª•Ëá™ÁÑ∂Ë™ûË®ÄÊü•Ë©¢Áü•Ë≠òÂ∫´Ôºå‰∏¶Ê∏¨Ë©¶ÂÖ∂‰∫ãÂØ¶ÂõûÁ≠îÂïèÈ°åÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÊ™¢Êü•‰∫ÜÊ®°ÂûãÂ∞çÂ∞çÊäóÊÄßÊèêÁ§∫ÁöÑÁ©©ÂÅ•ÊÄßÔºå‰ª•Ê∏¨Ë©¶Ê®°ÂûãËôïÁêÜÁõ∏‰∫íÁüõÁõæË≥áË®äÁöÑËÉΩÂäõ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊáâÁî®ÂÇ≥Áµ±ÊñπÊ≥ï‰æÜÁêÜËß£ÊñáÊú¨ÁöÑÊõ¥Á¥∞ÂæÆÊñπÈù¢Ôºå‰æãÂ¶ÇÂú®Êïò‰∫ãÂª∫Êßã‰∏≠‰ΩøÁî®ÈÅìËÅΩÈÄîË™™ÂíåÊÉÖÁ∑íÔºå‰∏¶ÊèêÂá∫Êú™‰æÜÁöÑÊñπÂêë„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåKGLLM Âú®ÂêÑÁ®ÆÊåáÊ®ô‰∏äÂÑ™Êñº LLMÔºåÂ∞çÂ∞çÊäóÊèêÁ§∫Êõ¥Á©©ÂÅ•Ôºå‰∏¶‰∏îÊõ¥ËÉΩÂ§†Â∞áÊñáÊú¨Á∏ΩÁµêÁÇ∫‰∏ªÈ°å„ÄÇ

##### **WLPlan: Relational Features for Symbolic Planning**
2411.00577v1 by Dillon Z. Chen

Scalable learning for planning research generally involves juggling between
different programming languages for handling learning and planning modules
effectively. Interpreted languages such as Python are commonly used for
learning routines due to their ease of use and the abundance of highly
maintained learning libraries they exhibit, while compiled languages such as
C++ are used for planning routines due to their optimised resource usage.
Motivated by the need for tools for developing scalable learning planners, we
introduce WLPlan, a C++ package with Python bindings which implements recent
promising work for automatically generating relational features of planning
tasks. Such features can be used for any downstream routine, such as learning
domain control knowledge or probing and understanding planning tasks. More
specifically, WLPlan provides functionality for (1) transforming planning tasks
into graphs, and (2) embedding planning graphs into feature vectors via graph
kernels. The source code and instructions for the installation and usage of
WLPlan are available at tinyurl.com/42kymswc

ÊëòË¶ÅÔºöÂèØÊì¥ÂÖÖÁöÑÂ≠∏ÁøíË¶èÂäÉÁ†îÁ©∂ÈÄöÂ∏∏ÈúÄË¶ÅÂú®‰∏çÂêåÁöÑÁ®ãÂºèË™ûË®Ä‰πãÈñìÂàáÊèõÔºåÊâçËÉΩÊúâÊïàÂú∞ËôïÁêÜÂ≠∏ÁøíÂíåË¶èÂäÉÊ®°ÁµÑ„ÄÇ‰æãÂ¶Ç Python Á≠âÁõ¥Ë≠ØË™ûË®ÄÈÄöÂ∏∏Áî®ÊñºÂ≠∏ÁøíÂ∏∏ÂºèÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÊòìÊñº‰ΩøÁî®Ôºå‰∏îÊúâË®±Â§öÁ∂≠Ë≠∑ÂÆåÂñÑÁöÑÂ≠∏ÁøíÂáΩÂºèÂ∫´ÔºõËÄå‰æãÂ¶Ç C++ Á≠âÁ∑®Ë≠ØË™ûË®ÄÂâáÁî®ÊñºË¶èÂäÉÂ∏∏ÂºèÔºåÂõ†ÁÇ∫ÂÆÉÂÄëËÉΩÊúÄ‰Ω≥ÂåñË≥áÊ∫ê‰ΩøÁî®„ÄÇÁî±ÊñºÈúÄË¶ÅÈñãÁôºÂèØÊì¥ÂÖÖÂ≠∏ÁøíË¶èÂäÉÂô®ÁöÑÂ∑•ÂÖ∑ÔºåÊàëÂÄëÂºïÈÄ≤‰∫Ü WLPlanÔºåÈÄôÊòØ‰∏ÄÂÄãÂÖ∑Êúâ Python Áπ´ÁµêÁöÑ C++ Â•ó‰ª∂ÔºåÂØ¶‰Ωú‰∫ÜËøëÊúüÊúâÂâçÈÄîÁöÑËá™ÂãïÁî¢ÁîüË¶èÂäÉ‰ªªÂãôÈóú‰øÇÁâπÂæµÁöÑÂ∑•‰Ωú„ÄÇÊ≠§È°ûÁâπÂæµÂèØÁî®Êñº‰ªª‰Ωï‰∏ãÊ∏∏Â∏∏ÂºèÔºå‰æãÂ¶ÇÂ≠∏ÁøíÈ†òÂüüÊéßÂà∂Áü•Ë≠òÊàñÊé¢Ê∏¨ÂíåÁêÜËß£Ë¶èÂäÉ‰ªªÂãô„ÄÇÊõ¥ÂÖ∑È´îÂú∞Ë™™ÔºåWLPlan Êèê‰æõ‰∫Ü‰ª•‰∏ãÂäüËÉΩÔºö(1) Â∞áË¶èÂäÉ‰ªªÂãôËΩâÊèõÁÇ∫ÂúñÂΩ¢Ôºå‰ª•Âèä (2) ÈÄèÈÅéÂúñÂΩ¢Ê†∏Â∞áË¶èÂäÉÂúñÂΩ¢ÂµåÂÖ•ÁâπÂæµÂêëÈáè„ÄÇWLPlan ÁöÑÂéüÂßãÁ¢ºÂíåÂÆâË£ùÂèä‰ΩøÁî®Ë™™ÊòéÂèØÂú® tinyurl.com/42kymswc ÂèñÂæó

##### **GRS-QA -- Graph Reasoning-Structured Question Answering Dataset**
2411.00369v3 by Anish Pahilajani, Devasha Trivedi, Jincen Shuai, Khin S. Yone, Samyak Rajesh Jain, Namyong Park, Ryan A. Rossi, Nesreen K. Ahmed, Franck Dernoncourt, Yu Wang

Large Language Models (LLMs) have excelled in multi-hop question-answering
(M-QA) due to their advanced reasoning abilities. However, the impact of the
inherent reasoning structures on LLM M-QA performance remains unclear, largely
due to the absence of QA datasets that provide fine-grained reasoning
structures. To address this gap, we introduce the Graph Reasoning-Structured
Question Answering Dataset (GRS-QA), which includes both semantic contexts and
reasoning structures for QA pairs. Unlike existing M-QA datasets, where
different reasoning structures are entangled together, GRS-QA explicitly
captures intricate reasoning pathways by constructing reasoning graphs, where
nodes represent textual contexts and edges denote logical flows. These
reasoning graphs of different structures enable a fine-grained evaluation of
LLM reasoning capabilities across various reasoning structures. Our empirical
analysis reveals that LLMs perform differently when handling questions with
varying reasoning structures. This finding facilitates the exploration of
textual structures as compared with semantics.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Áî±ÊñºÂÖ∂ÂÖàÈÄ≤ÁöÑÊé®ÁêÜËÉΩÂäõÔºåÂú®Â§öË∑≥ÂïèÁ≠î (M-QA) ‰∏≠Ë°®ÁèæÂá∫Ëâ≤„ÄÇÁÑ∂ËÄåÔºåÂõ∫ÊúâÊé®ÁêÜÁµêÊßãÂ∞ç LLM M-QA ÊïàËÉΩÁöÑÂΩ±Èüø‰ªç‰∏çÊ∏ÖÊ•öÔºåÈÄô‰∏ªË¶ÅÊòØÁî±ÊñºÁº∫‰πèÊèê‰æõÁ¥∞Á≤íÂ∫¶Êé®ÁêÜÁµêÊßãÁöÑ QA Ë≥áÊñôÈõÜ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂúñÂΩ¢Êé®ÁêÜÁµêÊßãÂåñÂïèÁ≠îË≥áÊñôÈõÜ (GRS-QA)ÔºåÂÖ∂‰∏≠ÂåÖÂê´Ë™ûÁæ©ËÑàÁµ°Âíå QA Â∞çÊáâÁöÑÊé®ÁêÜÁµêÊßã„ÄÇËàáÁèæÊúâÁöÑ M-QA Ë≥áÊñôÈõÜ‰∏çÂêåÔºåÂÖ∂‰∏≠‰∏çÂêåÁöÑÊé®ÁêÜÁµêÊßãÁ≥æÁ∫èÂú®‰∏ÄËµ∑ÔºåGRS-QA ÈÄèÈÅéÂª∫ÊßãÊé®ÁêÜÂúñÂΩ¢ÊòéÁ¢∫ÊçïÊçâË§áÈõúÁöÑÊé®ÁêÜË∑ØÂæëÔºåÂÖ∂‰∏≠ÁØÄÈªûË°®Á§∫ÊñáÂ≠óËÑàÁµ°ÔºåÈÇäÁ∑£Ë°®Á§∫ÈÇèËºØÊµÅÁ®ã„ÄÇÈÄô‰∫õ‰∏çÂêåÁµêÊßãÁöÑÊé®ÁêÜÂúñÂΩ¢ËÉΩÂ§†Á¥∞Á∑ªÂú∞Ë©ï‰º∞ LLM Âú®ÂêÑÁ®ÆÊé®ÁêÜÁµêÊßã‰∏≠ÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÂØ¶Ë≠âÂàÜÊûêÈ°ØÁ§∫ÔºåLLM Âú®ËôïÁêÜÂÖ∑Êúâ‰∏çÂêåÊé®ÁêÜÁµêÊßãÁöÑÂïèÈ°åÊôÇË°®Áèæ‰∏çÂêå„ÄÇÈÄôÂÄãÁôºÁèæ‰øÉÈÄ≤‰∫ÜÂ∞çÊñáÂ≠óÁµêÊßãËàáË™ûÁæ©ÁöÑÊØîËºÉÊé¢Á¥¢„ÄÇ

##### **Evaluating the Impact of Lab Test Results on Large Language Models Generated Differential Diagnoses from Clinical Case Vignettes**
2411.02523v1 by Balu Bhasuran, Qiao Jin, Yuzhang Xie, Carl Yang, Karim Hanna, Jennifer Costa, Cindy Shavor, Zhiyong Lu, Zhe He

Differential diagnosis is crucial for medicine as it helps healthcare
providers systematically distinguish between conditions that share similar
symptoms. This study assesses the impact of lab test results on differential
diagnoses (DDx) made by large language models (LLMs). Clinical vignettes from
50 case reports from PubMed Central were created incorporating patient
demographics, symptoms, and lab results. Five LLMs GPT-4, GPT-3.5, Llama-2-70b,
Claude-2, and Mixtral-8x7B were tested to generate Top 10, Top 5, and Top 1 DDx
with and without lab data. A comprehensive evaluation involving GPT-4, a
knowledge graph, and clinicians was conducted. GPT-4 performed best, achieving
55% accuracy for Top 1 diagnoses and 60% for Top 10 with lab data, with lenient
accuracy up to 80%. Lab results significantly improved accuracy, with GPT-4 and
Mixtral excelling, though exact match rates were low. Lab tests, including
liver function, metabolic/toxicology panels, and serology/immune tests, were
generally interpreted correctly by LLMs for differential diagnosis.

ÊëòË¶ÅÔºöÈëëÂà•Ë®∫Êñ∑Â∞çÊñºÈÜ´Â≠∏Ëá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫ÂÆÉÊúâÂä©ÊñºÈÜ´ÁôÇ‰øùÂÅ•Êèê‰æõËÄÖÁ≥ªÁµ±ÂçÄÂàÜÂÖ∑ÊúâÁõ∏‰ººÁóáÁãÄÁöÑÁñæÁóÖ„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Ë©ï‰º∞‰∫ÜÂØ¶È©óÂÆ§Ê™¢È©óÁµêÊûúÂ∞çÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂÅöÂá∫ÁöÑÈëëÂà•Ë®∫Êñ∑ (DDx) ÁöÑÂΩ±Èüø„ÄÇÂæû PubMed Central ÁöÑ 50 ‰ªΩÁóÖ‰æãÂ†±Âëä‰∏≠Âª∫Á´ã‰∫ÜËá®Â∫äÁ∞°Â†±ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÊÇ£ËÄÖ‰∫∫Âè£Áµ±Ë®à„ÄÅÁóáÁãÄÂíåÂØ¶È©óÂÆ§ÁµêÊûú„ÄÇÊ∏¨Ë©¶‰∫Ü‰∫îÂÄã LLM GPT-4„ÄÅGPT-3.5„ÄÅLlama-2-70b„ÄÅClaude-2 Âíå Mixtral-8x7BÔºå‰ª•ÁîüÊàêÂ∏∂Âíå‰∏çÂ∏∂ÂØ¶È©óÂÆ§Êï∏ÊìöÁöÑÂâç 10„ÄÅÂâç 5 ÂíåÂâç 1 DDx„ÄÇÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÊ∂âÂèä GPT-4„ÄÅÁü•Ë≠òÂúñË≠úÂíåËá®Â∫äÈÜ´ÁîüÁöÑÁ∂úÂêàË©ï‰º∞„ÄÇGPT-4 Ë°®ÁèæÊúÄ‰Ω≥ÔºåÂú®ÊúâÂØ¶È©óÂÆ§Êï∏ÊìöÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂâç 1 ÂêçË®∫Êñ∑ÁöÑÊ∫ñÁ¢∫ÁéáÈÅîÂà∞ 55%ÔºåÂâç 10 ÂêçÁöÑÊ∫ñÁ¢∫ÁéáÈÅîÂà∞ 60%ÔºåÂØ¨È¨ÜÊ∫ñÁ¢∫ÁéáÈ´òÈÅî 80%„ÄÇÂØ¶È©óÂÆ§ÁµêÊûúÈ°ØËëóÊèêÈ´ò‰∫ÜÊ∫ñÁ¢∫ÁéáÔºåGPT-4 Âíå Mixtral Ë°®ÁèæÂá∫Ëâ≤ÔºåÂÑòÁÆ°ÂÆåÂÖ®ÂåπÈÖçÁéáËºÉ‰Ωé„ÄÇLLM ÈÄöÂ∏∏ÂèØ‰ª•Ê≠£Á¢∫Ëß£ÈáãÂåÖÊã¨ËÇùÂäüËÉΩ„ÄÅ‰ª£Ë¨ù/ÊØíÁêÜÂ≠∏Ê™¢Êü•ÂíåË°ÄÊ∏ÖÂ≠∏/ÂÖçÁñ´Ê∏¨Ë©¶Âú®ÂÖßÁöÑÂØ¶È©óÂÆ§Ê™¢È©óÔºå‰ª•ÈÄ≤Ë°åÈëëÂà•Ë®∫Êñ∑„ÄÇ

##### **Compositional Automata Embeddings for Goal-Conditioned Reinforcement Learning**
2411.00205v1 by Beyazit Yalcinkaya, Niklas Lauffer, Marcell Vazquez-Chanlatte, Sanjit A. Seshia

Goal-conditioned reinforcement learning is a powerful way to control an AI
agent's behavior at runtime. That said, popular goal representations, e.g.,
target states or natural language, are either limited to Markovian tasks or
rely on ambiguous task semantics. We propose representing temporal goals using
compositions of deterministic finite automata (cDFAs) and use cDFAs to guide RL
agents. cDFAs balance the need for formal temporal semantics with ease of
interpretation: if one can understand a flow chart, one can understand a cDFA.
On the other hand, cDFAs form a countably infinite concept class with Boolean
semantics, and subtle changes to the automaton can result in very different
tasks, making them difficult to condition agent behavior on. To address this,
we observe that all paths through a DFA correspond to a series of reach-avoid
tasks and propose pre-training graph neural network embeddings on "reach-avoid
derived" DFAs. Through empirical evaluation, we demonstrate that the proposed
pre-training method enables zero-shot generalization to various cDFA task
classes and accelerated policy specialization without the myopic suboptimality
of hierarchical methods.

ÊëòË¶ÅÔºöÁõÆÊ®ôÊ¢ù‰ª∂Âº∑ÂåñÂ≠∏ÁøíÊòØ‰∏ÄÁ®ÆÂú®Âü∑Ë°åÈöéÊÆµÊéßÂà∂ AI ‰ª£ÁêÜË°åÁÇ∫ÁöÑÂº∑Â§ßÊñπÊ≥ï„ÄÇË©±ÈõñÂ¶ÇÊ≠§ÔºåÁÜ±ÈñÄÁöÑÁõÆÊ®ôË°®Á§∫Ôºå‰æãÂ¶ÇÁõÆÊ®ôÁãÄÊÖãÊàñËá™ÁÑ∂Ë™ûË®ÄÔºåÂÉÖÈôêÊñºÈ¶¨ÂèØÂ§´‰ªªÂãôÊàñ‰æùË≥¥ÊñºÂê´Á≥ä‰∏çÊ∏ÖÁöÑ‰ªªÂãôË™ûÁæ©„ÄÇÊàëÂÄëÂª∫Ë≠∞‰ΩøÁî®Á¢∫ÂÆöÊÄßÊúâÈôêÁãÄÊÖãËá™ÂãïÊ©ü (cDFA) ÁöÑÁµÑÂêà‰æÜË°®Á§∫ÊôÇÈñìÁõÆÊ®ôÔºå‰∏¶‰ΩøÁî® cDFA ‰æÜÊåáÂ∞é RL ‰ª£ÁêÜ„ÄÇcDFA Âπ≥Ë°°‰∫ÜÂ∞çÂΩ¢ÂºèÊôÇÈñìË™ûÁæ©ÁöÑÈúÄÊ±ÇËàáÊòìÊñºËß£Èáã‰πãÈñìÁöÑÈóú‰øÇÔºöÂ¶ÇÊûú‰∏ÄÂÄã‰∫∫ËÉΩÁêÜËß£ÊµÅÁ®ãÂúñÔºåÈÇ£È∫º‰ªñÂ∞±ËÉΩÁêÜËß£ cDFA„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåcDFA ÂΩ¢Êàê‰∫Ü‰∏ÄÂÄãÂÖ∑ÊúâÂ∏ÉÊûóË™ûÁæ©ÁöÑÂèØÊï∏ÁÑ°ÈôêÊ¶ÇÂøµÈ°ûÔºåËÄåÂ∞çËá™ÂãïÊ©üÁöÑÁ¥∞ÂæÆÊõ¥ÊîπÂèØËÉΩÊúÉÂ∞éËá¥ÈùûÂ∏∏‰∏çÂêåÁöÑ‰ªªÂãôÔºåÈÄô‰ΩøÂæóÂÆÉÂÄëÈõ£‰ª•Â∞ç‰ª£ÁêÜË°åÁÇ∫ÈÄ≤Ë°åÊ¢ù‰ª∂Âåñ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëËßÄÂØüÂà∞ÈÄöÈÅé DFA ÁöÑÊâÄÊúâË∑ØÂæëÈÉΩÂ∞çÊáâÊñº‰∏ÄÁ≥ªÂàóÂà∞ÈÅîÈÅøÂÖç‰ªªÂãôÔºå‰∏¶ÊèêÂá∫Â∞ç„ÄåÂà∞ÈÅîÈÅøÂÖçË°çÁîü„ÄçDFA ÈÄ≤Ë°åÈ†êË®ìÁ∑¥ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÂµåÂÖ•„ÄÇÈÄöÈÅéÁ∂ìÈ©óË©ï‰º∞ÔºåÊàëÂÄëË≠âÊòé‰∫ÜÊâÄÊèêÂá∫ÁöÑÈ†êË®ìÁ∑¥ÊñπÊ≥ïËÉΩÂ§†Â∞çÂêÑÁ®Æ cDFA ‰ªªÂãôÈ°ûÂà•ÈÄ≤Ë°åÈõ∂Ê¨°Â≠∏ÁøíÊ≥õÂåñÔºå‰∏¶Âä†ÈÄüÁ≠ñÁï•Â∞àÊ•≠ÂåñÔºåËÄåÊ≤íÊúâÂàÜÂ±§ÊñπÊ≥ïÁöÑËøëË¶ñÊ¨°ÂÑ™ÊÄß„ÄÇ

##### **Building Multi-Agent Copilot towards Autonomous Agricultural Data Management and Analysis**
2411.00188v1 by Yu Pan, Jianxin Sun, Hongfeng Yu, Joe Luck, Geng Bai, Nipuna Chamara, Yufeng Ge, Tala Awada

Current agricultural data management and analysis paradigms are to large
extent traditional, in which data collecting, curating, integration, loading,
storing, sharing and analyzing still involve too much human effort and
know-how. The experts, researchers and the farm operators need to understand
the data and the whole process of data management pipeline to make fully use of
the data. The essential problem of the traditional paradigm is the lack of a
layer of orchestrational intelligence which can understand, organize and
coordinate the data processing utilities to maximize data management and
analysis outcome. The emerging reasoning and tool mastering abilities of large
language models (LLM) make it a potentially good fit to this position, which
helps a shift from the traditional user-driven paradigm to AI-driven paradigm.
In this paper, we propose and explore the idea of a LLM based copilot for
autonomous agricultural data management and analysis. Based on our previously
developed platform of Agricultural Data Management and Analytics (ADMA), we
build a proof-of-concept multi-agent system called ADMA Copilot, which can
understand user's intent, makes plans for data processing pipeline and
accomplishes tasks automatically, in which three agents: a LLM based
controller, an input formatter and an output formatter collaborate together.
Different from existing LLM based solutions, by defining a meta-program graph,
our work decouples control flow and data flow to enhance the predictability of
the behaviour of the agents. Experiments demonstrates the intelligence,
autonomy, efficacy, efficiency, extensibility, flexibility and privacy of our
system. Comparison is also made between ours and existing systems to show the
superiority and potential of our system.

ÊëòË¶ÅÔºö<paragraph>ÁõÆÂâçÁöÑËæ≤Ê•≠Ë≥áÊñôÁÆ°ÁêÜËàáÂàÜÊûêÊ®°ÂºèÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰ªçÊòØÂÇ≥Áµ±ÁöÑÔºåÂÖ∂‰∏≠Ë≥áÊñôÊî∂ÈõÜ„ÄÅÊï¥ÁêÜ„ÄÅÊï¥Âêà„ÄÅËºâÂÖ•„ÄÅÂÑ≤Â≠ò„ÄÅÂàÜ‰∫´ÂíåÂàÜÊûê‰ªçÁÑ∂ÈúÄË¶ÅÂ§™Â§öÁöÑ‰∫∫ÂäõËàáÂ∞àÊ•≠Áü•Ë≠ò„ÄÇÂ∞àÂÆ∂„ÄÅÁ†îÁ©∂‰∫∫Âì°ÂíåËæ≤Â†¥Á∂ìÁáüËÄÖÈúÄË¶Å‰∫ÜËß£Ë≥áÊñôÂíåÊï¥ÂÄãË≥áÊñôÁÆ°ÁêÜÊµÅÁ®ãÔºåÊâçËÉΩÂÖÖÂàÜÂà©Áî®Ë≥áÊñô„ÄÇÂÇ≥Áµ±Ê®°ÂºèÁöÑÂü∫Êú¨ÂïèÈ°åÊòØÁº∫‰πè‰∏ÄÂ±§Á∑®ÊéíÊô∫ËÉΩÔºåÁÑ°Ê≥ïÁêÜËß£„ÄÅÁµÑÁπîÂíåÂçîË™øË≥áÊñôËôïÁêÜÂ∑•ÂÖ∑Ôºå‰ª•ÊúÄÂ§ßÂåñË≥áÊñôÁÆ°ÁêÜÂíåÂàÜÊûêÊàêÊûú„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êñ∞ËààÁöÑÊé®ÁêÜÂíåÂ∑•ÂÖ∑ÊéåÊè°ËÉΩÂäõ‰ΩøÂÖ∂ÊΩõÂú®ÈÅ©ÂêàÈÄôÂÄãËÅ∑‰ΩçÔºåÈÄôÊúâÂä©ÊñºÂæûÂÇ≥Áµ±ÁöÑ‰ΩøÁî®ËÄÖÈ©ÖÂãïÊ®°ÂºèËΩâËÆäÁÇ∫ AI È©ÖÂãïÊ®°Âºè„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏¶Êé¢Ë®é‰∫ÜÂü∫Êñº LLM ÁöÑÂâØÈßïÈßõÁöÑÊÉ≥Ê≥ïÔºåÁî®ÊñºËá™ÂãïÂåñËæ≤Ê•≠Ë≥áÊñôÁÆ°ÁêÜÂíåÂàÜÊûê„ÄÇÂü∫ÊñºÊàëÂÄëÂÖàÂâçÈñãÁôºÁöÑËæ≤Ê•≠Ë≥áÊñôÁÆ°ÁêÜÂíåÂàÜÊûê (ADMA) Âπ≥Âè∞ÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ ADMA Copilot ÁöÑÊ¶ÇÂøµÈ©óË≠âÂ§ö‰ª£ÁêÜÁ≥ªÁµ±ÔºåÂÆÉÂèØ‰ª•ÁêÜËß£‰ΩøÁî®ËÄÖÁöÑÊÑèÂúñ„ÄÅË¶èÂäÉË≥áÊñôËôïÁêÜÊµÅÁ®ã‰∏¶Ëá™ÂãïÂÆåÊàê‰ªªÂãôÔºåÂÖ∂‰∏≠‰∏âÂÄã‰ª£ÁêÜÔºöÂü∫Êñº LLM ÁöÑÊéßÂà∂Âô®„ÄÅËº∏ÂÖ•Ê†ºÂºèÂåñÁ®ãÂºèÂíåËº∏Âá∫Ê†ºÂºèÂåñÁ®ãÂºèÂÖ±ÂêåÂêà‰Ωú„ÄÇËàáÁèæÊúâÁöÑÂü∫Êñº LLM ÁöÑËß£Ê±∫ÊñπÊ°à‰∏çÂêåÔºåÈÄèÈÅéÂÆöÁæ©ÂÖÉÁ®ãÂºèÂúñÔºåÊàëÂÄëÁöÑÁ†îÁ©∂Â∞áÊéßÂà∂ÊµÅÁ®ãÂíåË≥áÊñôÊµÅÁ®ãËß£ËÄ¶Ôºå‰ª•Â¢ûÂº∑‰ª£ÁêÜË°åÁÇ∫ÁöÑÂèØÈ†êÊ∏¨ÊÄß„ÄÇÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÁ≥ªÁµ±ÁöÑÊô∫ÊÖß„ÄÅËá™‰∏ªÊÄß„ÄÅÊïàËÉΩ„ÄÅÊïàÁéá„ÄÅÂèØÊì¥ÂÖÖÊÄß„ÄÅÈùàÊ¥ªÊÄßËàáÈö±ÁßÅÊÄß„ÄÇÊàëÂÄë‰πüËàáÁèæÊúâÁ≥ªÁµ±ÈÄ≤Ë°åÊØîËºÉÔºå‰ª•È°ØÁ§∫ÊàëÂÄëÁ≥ªÁµ±ÁöÑÂÑ™Ë∂äÊÄßÂíåÊΩõÂäõ„ÄÇ</paragraph>

##### **Exploring the Knowledge Mismatch Hypothesis: Hallucination Propensity in Small Models Fine-tuned on Data from Larger Models**
2411.00878v1 by Phil Wee, Riyadh Baghdadi

Recently, there has been an explosion of large language models created
through fine-tuning with data from larger models. These small models able to
produce outputs that appear qualitatively similar to significantly larger
models. However, one of the key limitations that have been observed with these
models is their propensity to hallucinate significantly more often than larger
models. In particular, they have been observed to generate coherent outputs
that involve factually incorrect information and spread misinformation,
toxicity, and stereotypes. There are many potential causes of hallucination, of
which, one hypothesis is that fine-tuning a model on data produced by a larger
model leads to a knowledge mismatch which contributes to hallucination. In
particular, it is hypothesized that there is a mismatch between the knowledge
that is fed to the model to fine-tune it and the knowledge that is already
present in the graph. Fine-tuning the model on data that has such mismatch
could contribute to an increased propensity to hallucinate. We show that on an
unseen test set, a smaller model fine-tuned on data generated from a larger
model produced more wrong answers when compared to models fine-tuned on data
created by the small model, which confirms the hypothesis.

ÊëòË¶ÅÔºöÊúÄËøëÔºåÈÄöËøá‰ΩøÁî®Êõ¥Â§ßÊ®°ÂûãÁöÑÊï∞ÊçÆËøõË°åÂæÆË∞ÉÔºåÂàõÂª∫‰∫ÜÂ§ßÈáèËØ≠Ë®ÄÊ®°ÂûãÁàÜÁÇ∏„ÄÇËøô‰∫õÂ∞èÊ®°ÂûãËÉΩÂ§ü‰∫ßÁîü‰∏éÊòéÊòæÊõ¥Â§ßÁöÑÊ®°ÂûãÂú®Ë¥®Èáè‰∏äÁ±ª‰ººÁöÑËæìÂá∫„ÄÇÁÑ∂ËÄåÔºåÂú®Ëøô‰∫õÊ®°Âûã‰∏≠ËßÇÂØüÂà∞ÁöÑ‰∏Ä‰∏™ÂÖ≥ÈîÆÈôêÂà∂ÊòØÔºåÂÆÉ‰ª¨ÊØîÊõ¥Â§ßÁöÑÊ®°ÂûãÊõ¥ÂÆπÊòìÂá∫Áé∞ÂπªËßâ„ÄÇÁâπÂà´ÊòØÔºåÂ∑≤ÁªèËßÇÂØüÂà∞ÂÆÉ‰ª¨‰ºöÁîüÊàêÊ∂âÂèä‰∫ãÂÆû‰∏çÊ≠£Á°ÆÁöÑ‰ø°ÊÅØÂπ∂‰º†Êí≠ÈîôËØØ‰ø°ÊÅØ„ÄÅÊØíÊÄßÂíåÂàªÊùøÂç∞Ë±°ÁöÑËøûË¥ØËæìÂá∫„ÄÇÂπªËßâÊúâÂæàÂ§öÊΩúÂú®ÂéüÂõ†ÔºåÂÖ∂‰∏≠‰∏Ä‰∏™ÂÅáËÆæÊòØÔºåÂú®Êõ¥Â§ßÊ®°ÂûãÁîüÊàêÁöÑÊï∞ÊçÆ‰∏äÂæÆË∞ÉÊ®°Âûã‰ºöÂØºËá¥Áü•ËØÜ‰∏çÂåπÈÖçÔºå‰ªéËÄåÂØºËá¥ÂπªËßâ„ÄÇÁâπÂà´ÊòØÔºåÂÅáËÆæÊ®°ÂûãÂæÆË∞ÉÊâÄÈ¶àÈÄÅÁöÑÁü•ËØÜ‰∏éÂõæ‰∏≠Â∑≤ÊúâÁöÑÁü•ËØÜ‰πãÈó¥Â≠òÂú®‰∏çÂåπÈÖç„ÄÇÂú®ÂÖ∑ÊúâËøôÁßç‰∏çÂåπÈÖçÁöÑÊï∞ÊçÆ‰∏äÂæÆË∞ÉÊ®°ÂûãÂèØËÉΩ‰ºöÂØºËá¥ÂπªËßâÂÄæÂêëÂ¢ûÂä†„ÄÇÊàë‰ª¨Ë°®ÊòéÔºåÂú®‰∏Ä‰∏™Áúã‰∏çËßÅÁöÑÊµãËØïÈõÜ‰∏≠Ôºå‰∏Ä‰∏™Âú®‰ªé‰∏Ä‰∏™Êõ¥Â§ßÁöÑÊ®°ÂûãÁîüÊàêÁöÑÊï∞ÊçÆ‰∏äÂæÆË∞ÉÁöÑÂ∞èÊ®°ÂûãÔºå‰∏éÂú®Â∞èÊ®°ÂûãÂàõÂª∫ÁöÑÊï∞ÊçÆ‰∏äÂæÆË∞ÉÁöÑÊ®°ÂûãÁõ∏ÊØîÔºå‰∫ßÁîü‰∫ÜÊõ¥Â§öÈîôËØØÁöÑÁ≠îÊ°àÔºåËøôËØÅÂÆû‰∫ÜËøô‰∏ÄÂÅáËÆæ„ÄÇ

##### **Failure Modes of LLMs for Causal Reasoning on Narratives**
2410.23884v1 by Khurram Yamin, Shantanu Gupta, Gaurav R. Ghosal, Zachary C. Lipton, Bryan Wilder

In this work, we investigate the causal reasoning abilities of large language
models (LLMs) through the representative problem of inferring causal
relationships from narratives. We find that even state-of-the-art language
models rely on unreliable shortcuts, both in terms of the narrative
presentation and their parametric knowledge. For example, LLMs tend to
determine causal relationships based on the topological ordering of events
(i.e., earlier events cause later ones), resulting in lower performance
whenever events are not narrated in their exact causal order. Similarly, we
demonstrate that LLMs struggle with long-term causal reasoning and often fail
when the narratives are long and contain many events. Additionally, we show
LLMs appear to rely heavily on their parametric knowledge at the expense of
reasoning over the provided narrative. This degrades their abilities whenever
the narrative opposes parametric knowledge. We extensively validate these
failure modes through carefully controlled synthetic experiments, as well as
evaluations on real-world narratives. Finally, we observe that explicitly
generating a causal graph generally improves performance while naive
chain-of-thought is ineffective. Collectively, our results distill precise
failure modes of current state-of-the-art models and can pave the way for
future techniques to enhance causal reasoning in LLMs.

ÊëòË¶ÅÔºöÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéÊé®Ë´ñÊïòËø∞‰∏≠ÁöÑÂõ†ÊûúÈóú‰øÇÈÄôÂÄã‰ª£Ë°®ÊÄßÂïèÈ°åÔºå‰æÜÊé¢Ë®éÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂõ†ÊûúÊé®ÁêÜËÉΩÂäõ„ÄÇÊàëÂÄëÁôºÁèæÔºåÂç≥‰ΩøÊòØÊúÄÂÖàÈÄ≤ÁöÑË™ûË®ÄÊ®°ÂûãÔºå‰πüÊúÉ‰æùË≥¥Êñº‰∏çÂèØÈù†ÁöÑÊç∑ÂæëÔºåÁÑ°Ë´ñÊòØÂú®ÊïòËø∞ÂëàÁèæÊàñÂÖ∂ÂèÉÊï∏Áü•Ë≠òÊñπÈù¢„ÄÇ‰æãÂ¶ÇÔºåLLM ÂÇæÂêëÊñºÊ†πÊìö‰∫ã‰ª∂ÁöÑÊãìÊí≤È†ÜÂ∫èÔºàÂç≥ÔºåËºÉÊó©ÁöÑ‰∫ã‰ª∂Â∞éËá¥ËºÉÊôöÁöÑ‰∫ã‰ª∂Ôºâ‰æÜÁ¢∫ÂÆöÂõ†ÊûúÈóú‰øÇÔºåÁï∂‰∫ã‰ª∂Êú™ÊåâÂÖ∂Á¢∫ÂàáÁöÑÂõ†ÊûúÈ†ÜÂ∫èÊïòËø∞ÊôÇÔºåÂ∞±ÊúÉÂ∞éËá¥ËºÉ‰ΩéÁöÑÊïàËÉΩ„ÄÇÂêåÊ®£Âú∞ÔºåÊàëÂÄëË≠âÊòé LLM Èõ£‰ª•ÈÄ≤Ë°åÈï∑ÊúüÂõ†ÊûúÊé®ÁêÜÔºå‰∏¶‰∏îÁï∂ÊïòËø∞ÂæàÈï∑‰∏îÂåÖÂê´Ë®±Â§ö‰∫ã‰ª∂ÊôÇÔºåÂÆÉÂÄëÈÄöÂ∏∏ÊúÉÂ§±Êïó„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË°®Êòé LLM ‰ºº‰πéÈÅéÂ∫¶‰æùË≥¥ÂÖ∂ÂèÉÊï∏Áü•Ë≠òÔºåËÄåÁäßÁâ≤‰∫ÜÂ∞çÊâÄÊèê‰æõÊïòËø∞ÁöÑÊé®ÁêÜ„ÄÇÊØèÁï∂ÊïòËø∞ËàáÂèÉÊï∏Áü•Ë≠òÁõ∏Ë°ùÁ™ÅÊôÇÔºåÈÄôÂ∞±ÊúÉÈôç‰ΩéÂÆÉÂÄëÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÈÄèÈÅé‰ªîÁ¥∞ÊéßÂà∂ÁöÑÂêàÊàêÂØ¶È©ó‰ª•ÂèäÂ∞çÁúüÂØ¶‰∏ñÁïåÊïòËø∞ÁöÑË©ï‰º∞ÔºåÂª£Ê≥õÈ©óË≠â‰∫ÜÈÄô‰∫õÂ§±ÊïóÊ®°Âºè„ÄÇÊúÄÂæåÔºåÊàëÂÄëËßÄÂØüÂà∞ÔºåÊòéÁ¢∫Áî¢ÁîüÂõ†ÊûúÂúñÈÄöÂ∏∏ÊúÉÊîπÂñÑÊïàËÉΩÔºåËÄåÂ§©ÁúüÁöÑÊÄùËÄÉÈèàÂâáÁÑ°Êïà„ÄÇÁ∏ΩÁöÑ‰æÜË™™ÔºåÊàëÂÄëÁöÑÁµêÊûúÁ≤æÁ¢∫Âú∞ÊèêÁÖâ‰∫ÜÁï∂ÂâçÊúÄÂÖàÈÄ≤Ê®°ÂûãÁöÑÂ§±ÊïóÊ®°ÂºèÔºå‰∏¶ÂèØ‰ª•ÁÇ∫Êú™‰æÜÂ¢ûÂº∑ LLM ‰∏≠Âõ†ÊûúÊé®ÁêÜÁöÑÊäÄË°ìÈã™Ë∑Ø„ÄÇ

##### **Plan-on-Graph: Self-Correcting Adaptive Planning of Large Language Model on Knowledge Graphs**
2410.23875v1 by Liyi Chen, Panrong Tong, Zhongming Jin, Ying Sun, Jieping Ye, Hui Xiong

Large Language Models (LLMs) have shown remarkable reasoning capabilities on
complex tasks, but they still suffer from out-of-date knowledge,
hallucinations, and opaque decision-making. In contrast, Knowledge Graphs (KGs)
can provide explicit and editable knowledge for LLMs to alleviate these issues.
Existing paradigm of KG-augmented LLM manually predefines the breadth of
exploration space and requires flawless navigation in KGs. However, this
paradigm cannot adaptively explore reasoning paths in KGs based on the question
semantics and self-correct erroneous reasoning paths, resulting in a bottleneck
in efficiency and effect. To address these limitations, we propose a novel
self-correcting adaptive planning paradigm for KG-augmented LLM named
Plan-on-Graph (PoG), which first decomposes the question into several
sub-objectives and then repeats the process of adaptively exploring reasoning
paths, updating memory, and reflecting on the need to self-correct erroneous
reasoning paths until arriving at the answer. Specifically, three important
mechanisms of Guidance, Memory, and Reflection are designed to work together,
to guarantee the adaptive breadth of self-correcting planning for graph
reasoning. Finally, extensive experiments on three real-world datasets
demonstrate the effectiveness and efficiency of PoG.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ë§áÈõú‰ªªÂãô‰∏≠Â±ïÁèæÂá∫ÈùûÂá°ÁöÑÊé®ÁêÜËÉΩÂäõÔºå‰ΩÜ‰ªçÂ≠òÂú®Áü•Ë≠òÈÅéÊôÇ„ÄÅÂπªË¶∫ÂíåÊ±∫Á≠ñ‰∏çÈÄèÊòéÁöÑÂïèÈ°å„ÄÇÁõ∏ÂèçÂú∞ÔºåÁü•Ë≠òÂúñË≠ú (KG) ÂèØ‰ª•Êèê‰æõÊòéÁ¢∫‰∏îÂèØÁ∑®ËºØÁöÑÁü•Ë≠òÔºå‰æõ LLM Á∑©Ëß£ÈÄô‰∫õÂïèÈ°å„ÄÇÁèæÊúâÁöÑ KG Â¢ûÂº∑ LLM ÂÖ∏ÁØÑÊâãÂãïÈ†êÂÖàÂÆöÁæ©Êé¢Á¥¢Á©∫ÈñìÁöÑÂª£Â∫¶Ôºå‰∏¶ÈúÄË¶ÅÂú® KG ‰∏≠ÂÆåÁæéÂ∞éËà™„ÄÇÁÑ∂ËÄåÔºåÊ≠§ÂÖ∏ÁØÑÁÑ°Ê≥ïÊ†πÊìöÂïèÈ°åË™ûÊÑèËá™ÈÅ©ÊáâÂú∞Êé¢Á¥¢ KG ‰∏≠ÁöÑÊé®ÁêÜË∑ØÂæëÔºå‰∏¶Ëá™Ë°åÁ≥æÊ≠£ÈåØË™§ÁöÑÊé®ÁêÜË∑ØÂæëÔºåÂ∞éËá¥ÊïàÁéáÂíåÊïàÊûúÁöÑÁì∂È†∏„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ÂúñÂΩ¢Ë®àÁï´ (PoG) ÁöÑ KG Â¢ûÂº∑ LLM ÁöÑÊñ∞Á©éËá™‰øÆÊ≠£Ëá™ÈÅ©ÊáâË¶èÂäÉÂÖ∏ÁØÑÔºåÂÆÉÈ¶ñÂÖàÂ∞áÂïèÈ°åÂàÜËß£ÊàêÂπæÂÄãÂ≠êÁõÆÊ®ôÔºåÁÑ∂ÂæåÈáçË§áËá™ÈÅ©ÊáâÊé¢Á¥¢Êé®ÁêÜË∑ØÂæë„ÄÅÊõ¥Êñ∞Ë®òÊÜ∂È´îÂíåÂèçÊÄùÈúÄË¶ÅËá™Ë°åÁ≥æÊ≠£ÈåØË™§Êé®ÁêÜË∑ØÂæëÁöÑÈÅéÁ®ãÔºåÁõ¥Âà∞ÂæóÂá∫Á≠îÊ°à„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊåáÂ∞é„ÄÅË®òÊÜ∂ÂíåÂèçÊÄùÈÄô‰∏âÂÄãÈáçË¶ÅÊ©üÂà∂Ë¢´Ë®≠Ë®àÁÇ∫ÂçîÂêåÈÅã‰ΩúÔºå‰ª•‰øùË≠âËá™‰øÆÊ≠£Ë¶èÂäÉÂú®ÂúñÂΩ¢Êé®ÁêÜ‰∏≠ÁöÑËá™ÈÅ©ÊáâÂª£Â∫¶„ÄÇÊúÄÂæåÔºåÂú®‰∏âÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫Ü PoG ÁöÑÊúâÊïàÊÄßÂíåÊïàÁéá„ÄÇ

##### **LLaMo: Large Language Model-based Molecular Graph Assistant**
2411.00871v1 by Jinyoung Park, Minseong Bae, Dohwan Ko, Hyunwoo J. Kim

Large Language Models (LLMs) have demonstrated remarkable generalization and
instruction-following capabilities with instruction tuning. The advancements in
LLMs and instruction tuning have led to the development of Large
Vision-Language Models (LVLMs). However, the competency of the LLMs and
instruction tuning have been less explored in the molecular domain. Thus, we
propose LLaMo: Large Language Model-based Molecular graph assistant, which is
an end-to-end trained large molecular graph-language model. To bridge the
discrepancy between the language and graph modalities, we present the
multi-level graph projector that transforms graph representations into graph
tokens by abstracting the output representations of each GNN layer and motif
representations with the cross-attention mechanism. We also introduce
machine-generated molecular graph instruction data to instruction-tune the
large molecular graph-language model for general-purpose molecule and language
understanding. Our extensive experiments demonstrate that LLaMo shows the best
performance on diverse tasks, such as molecular description generation,
property prediction, and IUPAC name prediction. The code of LLaMo is available
at https://github.com/mlvlab/LLaMo.

ÊëòË¶ÅÔºöÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁ§∫Âá∫ÂçìË∂äÁöÑÊ¶ÇÊã¨ÂíåÊåá‰ª§ÈÅµÂæ™ËÉΩÂäõÔºåÂπ∂ËøõË°åÊåá‰ª§Ë∞ÉÊï¥„ÄÇLLM ÂíåÊåá‰ª§Ë∞ÉÊï¥ÁöÑËøõÊ≠•ÂØºËá¥‰∫ÜÂ§ßÂûãËßÜËßâËØ≠Ë®ÄÊ®°Âûã (LVLMs) ÁöÑÂèëÂ±ï„ÄÇÁÑ∂ËÄåÔºåLLM ÂíåÊåá‰ª§Ë∞ÉÊï¥ÁöÑËÉΩÂäõÂú®ÂàÜÂ≠êÈ¢ÜÂüüÁöÑÁ†îÁ©∂ËæÉÂ∞ë„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü LLaMoÔºöÂü∫‰∫éÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÂàÜÂ≠êÂõæÂä©ÊâãÔºåËøôÊòØ‰∏Ä‰∏™Á´ØÂà∞Á´ØËÆ≠ÁªÉÁöÑÂ§ßÂàÜÂ≠êÂõæËØ≠Ë®ÄÊ®°Âûã„ÄÇ‰∏∫‰∫ÜÂº•ÂêàËØ≠Ë®ÄÂíåÂõæÊ®°Âºè‰πãÈó¥ÁöÑÂ∑ÆÂºÇÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÂ§öÁ∫ßÂõæÊäïÂΩ±‰ª™ÔºåÂÆÉÈÄöËøáÊäΩË±°ÊØè‰∏™ GNN Â±ÇÁöÑËæìÂá∫Ë°®Á§∫ÂíåÂü∫Â∫èË°®Á§∫Ôºà‰ΩøÁî®‰∫§ÂèâÊ≥®ÊÑèÂäõÊú∫Âà∂ÔºâÂ∞ÜÂõæË°®Á§∫ËΩ¨Êç¢‰∏∫ÂõæÊ†áËÆ∞„ÄÇÊàë‰ª¨ËøòÂºïÂÖ•‰∫ÜÊú∫Âô®ÁîüÊàêÁöÑÂàÜÂ≠êÂõæÊåá‰ª§Êï∞ÊçÆÔºå‰ª•ÂØπÂ§ßÂûãÂàÜÂ≠êÂõæËØ≠Ë®ÄÊ®°ÂûãËøõË°åÊåá‰ª§Ë∞ÉÊï¥Ôºå‰ª•Áî®‰∫éÈÄöÁî®ÂàÜÂ≠êÂíåËØ≠Ë®ÄÁêÜËß£„ÄÇÊàë‰ª¨ÂπøÊ≥õÁöÑÂÆûÈ™åË°®ÊòéÔºåLLaMo Âú®ÂàÜÂ≠êÊèèËø∞ÁîüÊàê„ÄÅÂ±ûÊÄßÈ¢ÑÊµãÂíå IUPAC ÂêçÁß∞È¢ÑÊµãÁ≠â‰∏çÂêå‰ªªÂä°‰∏äË°®Áé∞Âá∫ÊúÄ‰Ω≥ÊÄßËÉΩ„ÄÇLLaMo ÁöÑ‰ª£Á†ÅÂèØÂú® https://github.com/mlvlab/LLaMo Ëé∑Âæó„ÄÇ

##### **End-to-End Ontology Learning with Large Language Models**
2410.23584v1 by Andy Lo, Albert Q. Jiang, Wenda Li, Mateja Jamnik

Ontologies are useful for automatic machine processing of domain knowledge as
they represent it in a structured format. Yet, constructing ontologies requires
substantial manual effort. To automate part of this process, large language
models (LLMs) have been applied to solve various subtasks of ontology learning.
However, this partial ontology learning does not capture the interactions
between subtasks. We address this gap by introducing OLLM, a general and
scalable method for building the taxonomic backbone of an ontology from
scratch. Rather than focusing on subtasks, like individual relations between
entities, we model entire subcomponents of the target ontology by finetuning an
LLM with a custom regulariser that reduces overfitting on high-frequency
concepts. We introduce a novel suite of metrics for evaluating the quality of
the generated ontology by measuring its semantic and structural similarity to
the ground truth. In contrast to standard metrics, our metrics use deep
learning techniques to define more robust distance measures between graphs.
Both our quantitative and qualitative results on Wikipedia show that OLLM
outperforms subtask composition methods, producing more semantically accurate
ontologies while maintaining structural integrity. We further demonstrate that
our model can be effectively adapted to new domains, like arXiv, needing only a
small number of training examples. Our source code and datasets are available
at https://github.com/andylolu2/ollm.

ÊëòË¶ÅÔºöÊú¨‰ΩìÂØπ‰∫éÈ¢ÜÂüüÁü•ËØÜÁöÑËá™Âä®Êú∫Âô®Â§ÑÁêÜÂæàÊúâÁî®ÔºåÂõ†‰∏∫ÂÆÉ‰ª¨‰ª•ÁªìÊûÑÂåñÊ†ºÂºèË°®Á§∫Áü•ËØÜ„ÄÇÁÑ∂ËÄåÔºåÊûÑÂª∫Êú¨‰ΩìÈúÄË¶ÅÂ§ßÈáèÁöÑÊâãÂä®Â∑•‰Ωú„ÄÇ‰∏∫‰∫ÜËá™Âä®ÂåñËøô‰∏™ËøáÁ®ãÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÂ∑≤Ë¢´Â∫îÁî®‰∫éËß£ÂÜ≥Êú¨‰ΩìÂ≠¶‰π†ÁöÑÂêÑÁßçÂ≠ê‰ªªÂä°„ÄÇÁÑ∂ËÄåÔºåËøôÁßçÈÉ®ÂàÜÊú¨‰ΩìÂ≠¶‰π†Âπ∂Ê≤°ÊúâÊçïÊçâÂà∞Â≠ê‰ªªÂä°‰πãÈó¥ÁöÑ‰∫§‰∫í„ÄÇÊàë‰ª¨ÈÄöËøáÂºïÂÖ• OLLM Êù•Ëß£ÂÜ≥Ëøô‰∏ÄÂ∑ÆË∑ùÔºåËøôÊòØ‰∏ÄÁßç‰ªéÂ§¥ÂºÄÂßãÊûÑÂª∫Êú¨‰ΩìÂàÜÁ±ªÈ™®Êû∂ÁöÑÈÄöÁî®‰∏îÂèØÊâ©Â±ïÁöÑÊñπÊ≥ï„ÄÇÊàë‰ª¨Ê≤°Êúâ‰∏ìÊ≥®‰∫éÂ≠ê‰ªªÂä°Ôºå‰æãÂ¶ÇÂÆû‰Ωì‰πãÈó¥ÁöÑ‰∏™Âà´ÂÖ≥Á≥ªÔºåËÄåÊòØÈÄöËøá‰ΩøÁî®Ëá™ÂÆö‰πâÊ≠£ÂàôÂåñÂô®ÂæÆË∞É LLM Êù•ÂØπÁõÆÊ†áÊú¨‰ΩìÁöÑÊï¥‰∏™Â≠êÁªÑ‰ª∂ËøõË°åÂª∫Ê®°ÔºåËØ•Ê≠£ÂàôÂåñÂô®ÂáèÂ∞ë‰∫ÜÂØπÈ´òÈ¢ëÊ¶ÇÂøµÁöÑËøáÂ∫¶ÊãüÂêà„ÄÇÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏ÄÂ•óÊñ∞ÁöÑÊåáÊ†áÊù•ËØÑ‰º∞ÁîüÊàêÊú¨‰ΩìÁöÑË¥®ÈáèÔºåÊñπÊ≥ïÊòØÊµãÈáèÂÆÉ‰∏éÂú∞Èù¢ÁúüÂÆûÂÄºÁöÑËØ≠‰πâÂíåÁªìÊûÑÁõ∏‰ººÊÄß„ÄÇ‰∏éÊ†áÂáÜÊåáÊ†áÁõ∏ÂèçÔºåÊàë‰ª¨ÁöÑÊåáÊ†á‰ΩøÁî®Ê∑±Â∫¶Â≠¶‰π†ÊäÄÊúØÊù•ÂÆö‰πâÂõæ‰πãÈó¥ÁöÑÊõ¥Á®≥ÂÅ•ÁöÑË∑ùÁ¶ªÂ∫¶Èáè„ÄÇÊàë‰ª¨Âú®Áª¥Âü∫ÁôæÁßë‰∏äÁöÑÂÆöÈáèÂíåÂÆöÊÄßÁªìÊûúË°®ÊòéÔºåOLLM ‰ºò‰∫éÂ≠ê‰ªªÂä°ÁªÑÂêàÊñπÊ≥ïÔºåÂú®‰øùÊåÅÁªìÊûÑÂÆåÊï¥ÊÄßÁöÑÂêåÊó∂ÁîüÊàêËØ≠‰πâ‰∏äÊõ¥ÂáÜÁ°ÆÁöÑÊú¨‰Ωì„ÄÇÊàë‰ª¨Ëøõ‰∏ÄÊ≠•ËØÅÊòéÔºåÊàë‰ª¨ÁöÑÊ®°ÂûãÂèØ‰ª•ÊúâÊïàÂú∞ÈÄÇÂ∫îÊñ∞ÁöÑÈ¢ÜÂüüÔºåÂ¶Ç arXivÔºåÂè™ÈúÄË¶ÅÂ∞ëÈáèÁöÑËÆ≠ÁªÉÊ†∑Êú¨„ÄÇÊàë‰ª¨ÁöÑÊ∫ê‰ª£Á†ÅÂíåÊï∞ÊçÆÈõÜÂèØÂú® https://github.com/andylolu2/ollm Ëé∑Âæó„ÄÇ

##### **Graph-Augmented Relation Extraction Model with LLMs-Generated Support Document**
2410.23452v1 by Vicky Dong, Hao Yu, Yao Chen

This study introduces a novel approach to sentence-level relation extraction
(RE) that integrates Graph Neural Networks (GNNs) with Large Language Models
(LLMs) to generate contextually enriched support documents. By harnessing the
power of LLMs to generate auxiliary information, our approach crafts an
intricate graph representation of textual data. This graph is subsequently
processed through a Graph Neural Network (GNN) to refine and enrich the
embeddings associated with each entity ensuring a more nuanced and
interconnected understanding of the data. This methodology addresses the
limitations of traditional sentence-level RE models by incorporating broader
contexts and leveraging inter-entity interactions, thereby improving the
model's ability to capture complex relationships across sentences. Our
experiments, conducted on the CrossRE dataset, demonstrate the effectiveness of
our approach, with notable improvements in performance across various domains.
The results underscore the potential of combining GNNs with LLM-generated
context to advance the field of relation extraction.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂè•Â≠êÂ±§Á¥öÈóú‰øÇËêÉÂèñ (RE) ÁöÑÊñ∞ÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÊï¥Âêà‰∫ÜÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)Ôºå‰ª•Áî¢ÁîüËÑàÁµ°Ë±êÂØåÁöÑÊîØÊè¥Êñá‰ª∂„ÄÇÈÄèÈÅéÂà©Áî® LLM ÁöÑÂäüËÉΩ‰æÜÁî¢ÁîüËºîÂä©Ë≥áË®äÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÊñáÊú¨Ë≥áÊñôÁöÑË§áÈõúÂúñÂΩ¢Ë°®Á§∫„ÄÇÊ≠§ÂúñÂΩ¢Èö®ÂæåÈÄèÈÅéÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÈÄ≤Ë°åËôïÁêÜÔºå‰ª•ÊîπÂñÑÂíåË±êÂØåËàáÊØèÂÄãÂØ¶È´îÁõ∏ÈóúÁöÑÂµåÂÖ•ÔºåÁ¢∫‰øùÂ∞çË≥áÊñôÊúâÊõ¥Á¥∞Á∑ª‰∏îÁõ∏‰∫íÈÄ£ÁµêÁöÑÁêÜËß£„ÄÇÊ≠§ÊñπÊ≥ïÈÄèÈÅéÁ¥çÂÖ•Êõ¥Âª£Ê≥õÁöÑËÑàÁµ°‰∏¶Âà©Áî®ÂØ¶È´îÈñì‰∫íÂãïÔºå‰æÜËß£Ê±∫ÂÇ≥Áµ±Âè•Â≠êÂ±§Á¥ö RE Ê®°ÂûãÁöÑÈôêÂà∂ÔºåÈÄ≤ËÄåÊèêÂçáÊ®°ÂûãÊçïÊçâË∑®Âè•Â≠êÁöÑË§áÈõúÈóú‰øÇÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÂú® CrossRE Ë≥áÊñôÈõÜ‰∏äÂü∑Ë°åÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåÂú®ÂêÑÁ®ÆÈ†òÂüüÁöÑÊïàËÉΩÈÉΩÊúâÈ°ØËëóÁöÑÊèêÂçá„ÄÇÈÄô‰∫õÁµêÊûúÂº∑Ë™ø‰∫ÜÂ∞á GNN Ëàá LLM Áî¢ÁîüÁöÑËÑàÁµ°Áõ∏ÁµêÂêàÔºå‰ª•Êé®ÈÄ≤Èóú‰øÇËêÉÂèñÈ†òÂüüÁöÑÊΩõÂäõ„ÄÇ

##### **FlowLLM: Flow Matching for Material Generation with Large Language Models as Base Distributions**
2410.23405v1 by Anuroop Sriram, Benjamin Kurt Miller, Ricky T. Q. Chen, Brandon M. Wood

Material discovery is a critical area of research with the potential to
revolutionize various fields, including carbon capture, renewable energy, and
electronics. However, the immense scale of the chemical space makes it
challenging to explore all possible materials experimentally. In this paper, we
introduce FlowLLM, a novel generative model that combines large language models
(LLMs) and Riemannian flow matching (RFM) to design novel crystalline
materials. FlowLLM first fine-tunes an LLM to learn an effective base
distribution of meta-stable crystals in a text representation. After converting
to a graph representation, the RFM model takes samples from the LLM and
iteratively refines the coordinates and lattice parameters. Our approach
significantly outperforms state-of-the-art methods, increasing the generation
rate of stable materials by over three times and increasing the rate for
stable, unique, and novel crystals by $\sim50\%$ - a huge improvement on a
difficult problem. Additionally, the crystals generated by FlowLLM are much
closer to their relaxed state when compared with another leading model,
significantly reducing post-hoc computational cost.

ÊëòË¶ÅÔºöÊùêÊñôÁôºÁèæÊòØ‰∏ÄÂÄãÈáçË¶ÅÁöÑÁ†îÁ©∂È†òÂüüÔºåÂÖ∑ÊúâÈù©Êñ∞ÂêÑÁ®ÆÈ†òÂüüÁöÑÊΩõÂäõÔºåÂåÖÊã¨Á¢≥ÊçïÈõÜ„ÄÅÂèØÂÜçÁîüËÉΩÊ∫êÂíåÈõªÂ≠êÁî¢ÂìÅ„ÄÇÁÑ∂ËÄåÔºåÂåñÂ≠∏Á©∫ÈñìÁöÑÂ∑®Â§ßË¶èÊ®°‰ΩøÂæóÂØ¶È©óÊé¢Á¥¢ÊâÄÊúâÂèØËÉΩÁöÑÊùêÊñôÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü FlowLLMÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÁîüÊàêÊ®°ÂûãÔºåÁµêÂêà‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÈªéÊõºÊµÅÂåπÈÖç (RFM) ‰æÜË®≠Ë®àÊñ∞ÂûãÊô∂È´îÊùêÊñô„ÄÇFlowLLM È¶ñÂÖàÂæÆË™ø LLMÔºå‰ª•Â≠∏ÁøíÊñáÊú¨Ë°®Á§∫‰∏≠‰∫ûÁ©©ÊÖãÊô∂È´îÁöÑÊúâÊïàÂü∫Á§éÂàÜ‰Ωà„ÄÇÂú®ËΩâÊèõÁÇ∫ÂúñÂΩ¢Ë°®Á§∫ÂæåÔºåRFM Ê®°ÂûãÂæû LLM ‰∏≠Áç≤ÂèñÊ®£Êú¨Ôºå‰∏¶ÂèçË¶ÜÁ≤æÁÖâÂùêÊ®ôÂíåÊô∂Ê†ºÂèÉÊï∏„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÈ°ØËëóÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÔºåÂ∞áÁ©©ÂÆöÊùêÊñôÁöÑÁîüÊàêÁéáÊèêÈ´ò‰∫Ü‰∏âÂÄç‰ª•‰∏äÔºå‰∏¶Â∞áÁ©©ÂÆö„ÄÅÁç®ÁâπÂíåÊñ∞Á©éÊô∂È´îÁöÑÁîüÊàêÁéáÊèêÈ´ò‰∫ÜÁ¥Ñ 50%‚Äî‚ÄîÈÄôÂú®‰∏ÄÂÄãÂõ∞Èõ£ÁöÑÂïèÈ°å‰∏äÊòØ‰∏ÄÂÄãÂ∑®Â§ßÁöÑÊîπÈÄ≤„ÄÇÊ≠§Â§ñÔºåËàáÂè¶‰∏ÄÁ®ÆÈ†òÂÖàÊ®°ÂûãÁõ∏ÊØîÔºåFlowLLM ÁîüÊàêÁöÑÊô∂È´îÊõ¥Êé•ËøëÂÖ∂È¨ÜÂºõÁãÄÊÖãÔºåÈ°ØËëóÈôç‰Ωé‰∫Ü‰∫ãÂæåË®àÁÆóÊàêÊú¨„ÄÇ

##### **EMMA: End-to-End Multimodal Model for Autonomous Driving**
2410.23262v2 by Jyh-Jing Hwang, Runsheng Xu, Hubert Lin, Wei-Chih Hung, Jingwei Ji, Kristy Choi, Di Huang, Tong He, Paul Covington, Benjamin Sapp, Yin Zhou, James Guo, Dragomir Anguelov, Mingxing Tan

We introduce EMMA, an End-to-end Multimodal Model for Autonomous driving.
Built on a multi-modal large language model foundation, EMMA directly maps raw
camera sensor data into various driving-specific outputs, including planner
trajectories, perception objects, and road graph elements. EMMA maximizes the
utility of world knowledge from the pre-trained large language models, by
representing all non-sensor inputs (e.g. navigation instructions and ego
vehicle status) and outputs (e.g. trajectories and 3D locations) as natural
language text. This approach allows EMMA to jointly process various driving
tasks in a unified language space, and generate the outputs for each task using
task-specific prompts. Empirically, we demonstrate EMMA's effectiveness by
achieving state-of-the-art performance in motion planning on nuScenes as well
as competitive results on the Waymo Open Motion Dataset (WOMD). EMMA also
yields competitive results for camera-primary 3D object detection on the Waymo
Open Dataset (WOD). We show that co-training EMMA with planner trajectories,
object detection, and road graph tasks yields improvements across all three
domains, highlighting EMMA's potential as a generalist model for autonomous
driving applications. However, EMMA also exhibits certain limitations: it can
process only a small amount of image frames, does not incorporate accurate 3D
sensing modalities like LiDAR or radar and is computationally expensive. We
hope that our results will inspire further research to mitigate these issues
and to further evolve the state of the art in autonomous driving model
architectures.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄë‰ªãÁ¥π EMMAÔºå‰∏ÄÁ®ÆÁî®ÊñºËá™ÂãïÈßïÈßõÁöÑÁ´ØÂà∞Á´ØÂ§öÊ®°ÊÖãÊ®°Âûã„ÄÇ
Âª∫Á´ãÂú®Â§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂü∫Á§é‰∏äÔºåEMMA Áõ¥Êé•Â∞áÂéüÂßã
Áõ∏Ê©üÊÑüÊ∏¨Âô®Ë≥áÊñôÂ∞çÊáâÂà∞ÂêÑÁ®ÆÁâπÂÆöÊñºÈßïÈßõÁöÑËº∏Âá∫ÔºåÂåÖÊã¨Ë¶èÂäÉÂô®
ËªåË∑°„ÄÅÊÑüÁü•Áâ©‰ª∂ÂíåÈÅìË∑ØÂúñÂΩ¢ÂÖÉÁ¥†„ÄÇEMMA ÊúÄÂ§ßÂåñÂà©Áî®È†êË®ìÁ∑¥Â§ßÂûãË™ûË®ÄÊ®°Âûã‰∏≠ÁöÑ‰∏ñÁïåÁü•Ë≠òÔºåÊñπÊ≥ïÊòØ
Â∞áÊâÄÊúâÈùûÊÑüÊ∏¨Âô®Ëº∏ÂÖ•Ôºà‰æãÂ¶ÇÂ∞éËà™ÊåáÁ§∫ÂíåËá™Êàë
ËªäËºõÁãÄÊÖãÔºâÂíåËº∏Âá∫Ôºà‰æãÂ¶ÇËªåË∑°Âíå 3D ‰ΩçÁΩÆÔºâË°®Á§∫ÁÇ∫Ëá™ÁÑ∂
Ë™ûË®ÄÊñáÂ≠ó„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂÖÅË®± EMMA Âú®Áµ±‰∏ÄÁöÑË™ûË®ÄÁ©∫Èñì‰∏≠ÂÖ±ÂêåËôïÁêÜÂêÑÁ®ÆÈßïÈßõ
‰ªªÂãôÔºå‰∏¶‰ΩøÁî®ÁâπÂÆöÊñº‰ªªÂãôÁöÑÊèêÁ§∫ÁÇ∫ÊØèÂÄã‰ªªÂãôÁî¢ÁîüËº∏Âá∫„ÄÇ
Ê†πÊìöÁ∂ìÈ©óÔºåÊàëÂÄëË≠âÊòé‰∫Ü EMMA ÁöÑÊúâÊïàÊÄßÔºåÂú® nuScenes ‰∏äÁöÑÈÅãÂãïË¶èÂäÉ‰∏≠ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊÄßËÉΩÔºå‰ª•Âèä
Âú® Waymo ÈñãÊîæÈÅãÂãïË≥áÊñôÈõÜ (WOMD) ‰∏äÂèñÂæó‰∫ÜÊúâÁ´∂Áà≠ÂäõÁöÑÁµêÊûú„ÄÇEMMA ‰πü
Âú® Waymo ÈñãÊîæË≥áÊñôÈõÜ (WOD) ‰∏äÂ∞çÁõ∏Ê©üÂÑ™ÂÖàÁöÑ 3D Áâ©‰ª∂ÂÅµÊ∏¨Áî¢Áîü‰∫ÜÊúâÁ´∂Áà≠ÂäõÁöÑÁµêÊûú„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰ΩøÁî®Ë¶èÂäÉÂô®ËªåË∑°„ÄÅ
Áâ©‰ª∂ÂÅµÊ∏¨ÂíåÈÅìË∑ØÂúñÂΩ¢‰ªªÂãôÂÖ±ÂêåË®ìÁ∑¥ EMMA ÊúÉÂú®ÊâÄÊúâ‰∏âÂÄã
È†òÂüüÁî¢ÁîüÊîπÈÄ≤ÔºåÁ™ÅÈ°Ø‰∫Ü EMMA ‰ΩúÁÇ∫Ëá™ÂãïÈßïÈßõÊáâÁî®Á®ãÂºèÈÄöÁî®Ê®°ÂûãÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåEMMA ‰πüË°®ÁèæÂá∫Êüê‰∫õÈôêÂà∂ÔºöÂÆÉÂè™ËÉΩ
ËôïÁêÜÂ∞ëÈáèÁöÑÂΩ±ÂÉèÂπÄÔºå‰∏çÂåÖÂê´ÂÉè LiDAR ÊàñÈõ∑ÈÅîÁ≠âÊ∫ñÁ¢∫ÁöÑ 3D ÊÑüÊ∏¨Ê®°ÂºèÔºå‰∏¶‰∏îË®àÁÆóÊàêÊú¨ÊòÇË≤¥„ÄÇÊàëÂÄë
Â∏åÊúõÊàëÂÄëÁöÑÁµêÊûúËÉΩÊøÄÂãµÈÄ≤‰∏ÄÊ≠•ÁöÑÁ†îÁ©∂Ôºå‰ª•Ê∏õËºïÈÄô‰∫õÂïèÈ°å‰∏¶ÈÄ≤‰∏ÄÊ≠•ÁôºÂ±ïËá™ÂãïÈßïÈßõÊ®°Âûã
Êû∂ÊßãÁöÑÊúÄÊñ∞ÊäÄË°ì„ÄÇ</paragraph>

##### **ProTransformer: Robustify Transformers via Plug-and-Play Paradigm**
2410.23182v1 by Zhichao Hou, Weizhi Gao, Yuchen Shen, Feiyi Wang, Xiaorui Liu

Transformer-based architectures have dominated various areas of machine
learning in recent years. In this paper, we introduce a novel robust attention
mechanism designed to enhance the resilience of transformer-based
architectures. Crucially, this technique can be integrated into existing
transformers as a plug-and-play layer, improving their robustness without the
need for additional training or fine-tuning. Through comprehensive experiments
and ablation studies, we demonstrate that our ProTransformer significantly
enhances the robustness of transformer models across a variety of prediction
tasks, attack mechanisms, backbone architectures, and data domains. Notably,
without further fine-tuning, the ProTransformer consistently improves the
performance of vanilla transformers by 19.5%, 28.3%, 16.1%, and 11.4% for BERT,
ALBERT, DistilBERT, and RoBERTa, respectively, under the classical TextFooler
attack. Furthermore, ProTransformer shows promising resilience in large
language models (LLMs) against prompting-based attacks, improving the
performance of T5 and LLaMA by 24.8% and 17.8%, respectively, and enhancing
Vicuna by an average of 10.4% against the Jailbreaking attack. Beyond the
language domain, ProTransformer also demonstrates outstanding robustness in
both vision and graph domains.

ÊëòË¶ÅÔºö<paragraph>ËøëÂπ¥‰æÜÔºåÂü∫Êñº Transformer ÁöÑÊû∂Êßã‰∏ªÂ∞é‰∫ÜÊ©üÂô®Â≠∏ÁøíÁöÑÂêÑÂÄãÈ†òÂüü„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©é‰∏îÂº∑Â§ßÁöÑÊ≥®ÊÑèÂäõÊ©üÂà∂ÔºåÊó®Âú®Â¢ûÂº∑Âü∫Êñº Transformer ÁöÑÊû∂ÊßãÁöÑÈüåÊÄß„ÄÇËá≥ÈóúÈáçË¶ÅÁöÑÊòØÔºåÊ≠§ÊäÄË°ìÂèØ‰ª•‰ΩúÁÇ∫Âç≥ÊèíÂç≥Áî®ÁöÑÂ±§Êï¥ÂêàÂà∞ÁèæÊúâÁöÑ Transformer ‰∏≠ÔºåÂú®ÁÑ°ÈúÄÈ°çÂ§ñË®ìÁ∑¥ÊàñÂæÆË™øÁöÑÊÉÖÊ≥Å‰∏ãÊèêÈ´òÂÖ∂Á©©ÂÅ•ÊÄß„ÄÇÈÄöÈÅéÂÖ®Èù¢ÁöÑÂØ¶È©óÂíåÊ∂àËûçÁ†îÁ©∂ÔºåÊàëÂÄëË≠âÊòé‰∫ÜÊàëÂÄëÁöÑ ProTransformer Âú®ÂêÑÁ®ÆÈ†êÊ∏¨‰ªªÂãô„ÄÅÊîªÊìäÊ©üÂà∂„ÄÅ‰∏ªÂππÊû∂ÊßãÂíåÊï∏ÊìöÈ†òÂüü‰∏≠È°ØËëóÂ¢ûÂº∑‰∫Ü Transformer Ê®°ÂûãÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂú®‰∏çÈÄ≤‰∏ÄÊ≠•ÂæÆË™øÁöÑÊÉÖÊ≥Å‰∏ãÔºåProTransformer Âú®Á∂ìÂÖ∏ÁöÑ TextFooler ÊîªÊìä‰∏ãÔºåÂàÜÂà•ÁÇ∫ BERT„ÄÅALBERT„ÄÅDistilBERT Âíå RoBERTa ÊèêÂçá‰∫Ü 19.5%„ÄÅ28.3%„ÄÅ16.1% Âíå 11.4% ÁöÑÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåProTransformer Âú®Âü∫ÊñºÊèêÁ§∫ÁöÑÊîªÊìä‰∏≠Â∞çÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) È°ØÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑÈüåÊÄßÔºåÂàÜÂà•Â∞á T5 Âíå LLaMA ÁöÑÊÄßËÉΩÊèêÂçá‰∫Ü 24.8% Âíå 17.8%Ôºå‰∏¶Âú®Ë∂äÁçÑÊîªÊìä‰∏≠Â∞á Vicuna ÁöÑÊÄßËÉΩÂπ≥ÂùáÊèêÂçá‰∫Ü 10.4%„ÄÇÈô§‰∫ÜË™ûË®ÄÈ†òÂüü‰πãÂ§ñÔºåProTransformer Âú®Ë¶ñË¶∫ÂíåÂúñÂΩ¢È†òÂüü‰πüË°®ÁèæÂá∫Âá∫Ëâ≤ÁöÑÁ©©ÂÅ•ÊÄß„ÄÇ</paragraph>

##### **Semantic Enrichment of the Quantum Cascade Laser Properties in Text- A Knowledge Graph Generation Approach**
2410.22996v1 by Deperias Kerre, Anne Laurent, Kenneth Maussang, Dickson Owuor

A well structured collection of the various Quantum Cascade Laser (QCL)
design and working properties data provides a platform to analyze and
understand the relationships between these properties. By analyzing these
relationships, we can gain insights into how different design features impact
laser performance properties such as the working temperature. Most of these QCL
properties are captured in scientific text. There is therefore need for
efficient methodologies that can be utilized to extract QCL properties from
text and generate a semantically enriched and interlinked platform where the
properties can be analyzed to uncover hidden relations. There is also the need
to maintain provenance and reference information on which these properties are
based. Semantic Web technologies such as Ontologies and Knowledge Graphs have
proven capability in providing interlinked data platforms for knowledge
representation in various domains. In this paper, we propose an approach for
generating a QCL properties Knowledge Graph (KG) from text for semantic
enrichment of the properties. The approach is based on the QCL ontology and a
Retrieval Augmented Generation (RAG) enabled information extraction pipeline
based on GPT 4-Turbo language model. The properties of interest include:
working temperature, laser design type, lasing frequency, laser optical power
and the heterostructure. The experimental results demonstrate the feasibility
and effectiveness of this approach for efficiently extracting QCL properties
from unstructured text and generating a QCL properties Knowledge Graph, which
has potential applications in semantic enrichment and analysis of QCL data.

ÊëòË¶ÅÔºö‰∏ÄÂÄãÁµêÊßãËâØÂ•ΩÁöÑÂêÑÁ®ÆÈáèÂ≠êÂ±§ÁñäÈõ∑Â∞Ñ (QCL) Ë®≠Ë®àÂíåÂ∑•‰ΩúÁâπÊÄßÊï∏ÊìöÈõÜÂêàÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂπ≥Âè∞‰æÜÂàÜÊûêÂíåÁêÜËß£ÈÄô‰∫õÁâπÊÄß‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÈÄèÈÅéÂàÜÊûêÈÄô‰∫õÈóú‰øÇÔºåÊàëÂÄëÂèØ‰ª•Ê∑±ÂÖ•‰∫ÜËß£‰∏çÂêåÁöÑË®≠Ë®àÁâπÂæµÂ¶Ç‰ΩïÂΩ±ÈüøÈõ∑Â∞ÑÊïàËÉΩÁâπÊÄßÔºå‰æãÂ¶ÇÂ∑•‰ΩúÊ∫´Â∫¶„ÄÇÈÄô‰∫õ QCL ÁâπÊÄßÂ§ßÂ§öÊï∏ÈÉΩÊçïÊçâÂú®ÁßëÂ≠∏ÊñáÂ≠ó‰∏≠„ÄÇÂõ†Ê≠§ÔºåÈúÄË¶ÅÊúâÊïàÁöÑÊñπÊ≥ïÔºåÂèØ‰ª•Áî®ÊñºÂæûÊñáÂ≠ó‰∏≠ËêÉÂèñ QCL ÁâπÊÄßÔºå‰∏¶Áî¢Áîü‰∏ÄÂÄãË™ûÁæ©Ë±êÂØå‰∏îÁõ∏‰∫íÈÄ£ÁµêÁöÑÂπ≥Âè∞ÔºåÂèØ‰ª•Âú®ÂÖ∂‰∏≠ÂàÜÊûêÈÄô‰∫õÁâπÊÄß‰ª•ÁôºÁèæÈö±ËóèÁöÑÈóú‰øÇ„ÄÇÈÇÑÈúÄË¶ÅÁ∂≠Ë≠∑ÈÄô‰∫õÁâπÊÄßÊâÄ‰æùÊìöÁöÑ‰æÜÊ∫êÂíåÂèÉËÄÉË≥áË®ä„ÄÇË™ûÁæ©Á∂≤Ë∑ØÊäÄË°ìÔºå‰æãÂ¶ÇÊú¨‰ΩìÂíåÁü•Ë≠òÂúñË≠úÔºåÂ∑≤Ë≠âÊòéÂÆÉÂÄëÂú®Êèê‰æõÂêÑÁ®ÆÈ†òÂüü‰∏≠Áü•Ë≠òË°®ÂæµÁöÑÁõ∏‰∫íÈÄ£ÁµêË≥áÊñôÂπ≥Âè∞ÊñπÈù¢ÂÖ∑ÊúâËÉΩÂäõ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂæûÊñáÂ≠ó‰∏≠Áî¢Áîü QCL ÁâπÊÄßÁü•Ë≠òÂúñË≠ú (KG) ÁöÑÊñπÊ≥ïÔºå‰ª•ÈÄ≤Ë°åÁâπÊÄßÁöÑË™ûÁæ©Ë±êÂØåÂåñ„ÄÇÊ≠§ÊñπÊ≥ïÂü∫Êñº QCL Êú¨‰ΩìÂíåÂü∫Êñº GPT 4-Turbo Ë™ûË®ÄÊ®°ÂûãÁöÑÊ™¢Á¥¢Êì¥Â¢ûÁîüÊàê (RAG) ÂïüÁî®Ë≥áË®äËêÉÂèñÁÆ°Á∑ö„ÄÇÊÑüËààË∂£ÁöÑÁâπÊÄßÂåÖÊã¨ÔºöÂ∑•‰ΩúÊ∫´Â∫¶„ÄÅÈõ∑Â∞ÑË®≠Ë®àÈ°ûÂûã„ÄÅÈõ∑Â∞ÑÈ†ªÁéá„ÄÅÈõ∑Â∞ÑÂÖâÂäüÁéáÂíåÁï∞Ë≥™ÁµêÊßã„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÊ≠§ÊñπÊ≥ïÂ∞çÊñºÂæûÈùûÁµêÊßãÂåñÊñáÂ≠ó‰∏≠ÊúâÊïàËêÉÂèñ QCL ÁâπÊÄßÂíåÁî¢Áîü QCL ÁâπÊÄßÁü•Ë≠òÂúñË≠úÁöÑÂèØË°åÊÄßÂíåÊúâÊïàÊÄßÔºåÈÄôÂú® QCL Êï∏ÊìöÁöÑË™ûÁæ©Ë±êÂØåÂåñÂíåÂàÜÊûê‰∏≠ÂÖ∑ÊúâÊΩõÂú®ÊáâÁî®„ÄÇ

##### **How Well Do Large Language Models Disambiguate Swedish Words?**
2410.22827v1 by Richard Johansson

We evaluate a battery of recent large language models on two benchmarks for
word sense disambiguation in Swedish. At present, all current models are less
accurate than the best supervised disambiguators in cases where a training set
is available, but most models outperform graph-based unsupervised systems.
Different prompting approaches are compared, with a focus on how to express the
set of possible senses in a given context. The best accuracies are achieved
when human-written definitions of the senses are included in the prompts.

ÊëòË¶ÅÔºöÊàëÂÄëÈáùÂ∞çÂÖ©ÂÄãÁëûÂÖ∏Ë™ûË©ûÂΩôÊÑèÁæ©Ê∂àÊ≠ßÂü∫Ê∫ñÔºåË©ï‰º∞‰∏ÄÁ≥ªÂàóËøëÊúüÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã„ÄÇÁõÆÂâçÔºåÂú®ÊúâË®ìÁ∑¥ÈõÜÂèØÁî®ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊâÄÊúâÁèæÊúâÊ®°ÂûãÁöÑÊ∫ñÁ¢∫Â∫¶ÈÉΩ‰ΩéÊñºÊúÄ‰Ω≥Áõ£Áù£ÂºèÊ∂àÊ≠ßÂô®Ôºå‰ΩÜÂ§ßÂ§öÊï∏Ê®°ÂûãÁöÑË°®ÁèæÈÉΩÂÑ™ÊñºÂü∫ÊñºÂúñÂΩ¢ÁöÑÈùûÁõ£Áù£ÂºèÁ≥ªÁµ±„ÄÇÊØîËºÉ‰∫Ü‰∏çÂêåÁöÑÊèêÁ§∫ÊñπÊ≥ïÔºåÈáçÈªûÂú®ÊñºÂ¶Ç‰ΩïÂú®ÁâπÂÆöËÑàÁµ°‰∏≠Ë°®ÈÅîÂèØËÉΩÁöÑÊÑèÁæ©ÈõÜÂêà„ÄÇÁï∂ÊèêÁ§∫‰∏≠ÂåÖÂê´‰∫∫È°ûÊí∞ÂØ´ÁöÑÊÑèÁæ©ÂÆöÁæ©ÊôÇÔºåÂèØÈÅîÂà∞ÊúÄ‰Ω≥Ê∫ñÁ¢∫Â∫¶„ÄÇ

##### **Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot**
2410.22767v1 by Sejin Lee, Dongha Kim, Min Song

Goal-oriented chatbots are essential for automating user tasks, such as
booking flights or making restaurant reservations. A key component of these
systems is Dialogue State Tracking (DST), which interprets user intent and
maintains the dialogue state. However, existing DST methods often rely on fixed
ontologies and manually compiled slot values, limiting their adaptability to
open-domain dialogues. We propose a novel approach that leverages instruction
tuning and advanced prompt strategies to enhance DST performance, without
relying on any predefined ontologies. Our method enables Large Language Model
(LLM) to infer dialogue states through carefully designed prompts and includes
an anti-hallucination mechanism to ensure accurate tracking in diverse
conversation contexts. Additionally, we employ a Variational Graph Auto-Encoder
(VGAE) to model and predict subsequent user intent. Our approach achieved
state-of-the-art with a JGA of 42.57% outperforming existing ontology-less DST
models, and performed well in open-domain real-world conversations. This work
presents a significant advancement in creating more adaptive and accurate
goal-oriented chatbots.

ÊëòË¶ÅÔºö‰ª•ÁõÆÊ®ôÁÇ∫Â∞éÂêëÁöÑËÅäÂ§©Ê©üÂô®‰∫∫Âú®Ëá™ÂãïÂåñ‰ΩøÁî®ËÄÖ‰ªªÂãô‰∏≠Ëá≥ÈóúÈáçË¶ÅÔºå‰æãÂ¶ÇÈ†êË®ÇËà™Áè≠ÊàñÈÄ≤Ë°åÈ§êÂª≥Ë®Ç‰Ωç„ÄÇÈÄô‰∫õÁ≥ªÁµ±ÁöÑ‰∏ÄÂÄãÈóúÈçµÁµÑÊàêÈÉ®ÂàÜÊòØÂ∞çË©±ÁãÄÊÖãËøΩËπ§ (DST)ÔºåÂÆÉÊúÉËß£Ë≠Ø‰ΩøÁî®ËÄÖÁöÑÊÑèÂúñ‰∏¶Á∂≠Ë≠∑Â∞çË©±ÁãÄÊÖã„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑ DST ÊñπÊ≥ïÈÄöÂ∏∏‰æùË≥¥ÊñºÂõ∫ÂÆöÁöÑÊú¨‰ΩìÂíåÊâãÂãïÁ∑®Ë≠ØÁöÑÊßΩ‰ΩçÂÄºÔºåÈÄôÈôêÂà∂‰∫ÜÂÆÉÂÄëÂ∞çÈñãÊîæÈ†òÂüüÂ∞çË©±ÁöÑÈÅ©ÊáâÊÄß„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÂÆÉÂà©Áî®Êåá‰ª§Ë™øÊï¥ÂíåÂÖàÈÄ≤ÁöÑÊèêÁ§∫Á≠ñÁï•‰æÜÂ¢ûÂº∑ DST ÊïàËÉΩÔºåËÄåÁÑ°ÈúÄ‰æùË≥¥‰ªª‰ΩïÈ†êÂÆöÁæ©ÁöÑÊú¨‰Ωì„ÄÇÊàëÂÄëÁöÑÊñπÊ≥ï‰ΩøÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËÉΩÂ§†ÈÄèÈÅéÁ≤æÂøÉË®≠Ë®àÁöÑÊèêÁ§∫‰æÜÊé®Ë´ñÂ∞çË©±ÁãÄÊÖãÔºå‰∏¶ÂåÖÂê´‰∏ÄÂÄãÂèçÂπªË¶∫Ê©üÂà∂Ôºå‰ª•Á¢∫‰øùÂú®‰∏çÂêåÁöÑÂ∞çË©±ÊÉÖÂ¢É‰∏≠Ê∫ñÁ¢∫ËøΩËπ§„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé°Áî®ËÆäÂàÜÂúñËá™Á∑®Á¢ºÂô® (VGAE) ‰æÜÂª∫Ê®°ÂíåÈ†êÊ∏¨ÂæåÁ∫å‰ΩøÁî®ËÄÖÁöÑÊÑèÂúñ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ï‰ª• 42.57% ÁöÑ JGA ÈÅîÂà∞‰∫ÜÁèæÊúâÊäÄË°ìÁöÑÈ†ÇÂ≥∞ÔºåÂÑ™ÊñºÁèæÊúâÁöÑÁÑ°Êú¨‰Ωì DST Ê®°ÂûãÔºå‰∏¶Âú®ÈñãÊîæÈ†òÂüüÁöÑÁúüÂØ¶Â∞çË©±‰∏≠Ë°®ÁèæËâØÂ•Ω„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÂú®Âª∫Á´ãÊõ¥ÂÖ∑ÈÅ©ÊáâÊÄßÂíåÊ∫ñÁ¢∫ÊÄßÁöÑ‰ª•ÁõÆÊ®ôÁÇ∫Â∞éÂêëÁöÑËÅäÂ§©Ê©üÂô®‰∫∫ÊñπÈù¢ÂèñÂæó‰∫ÜÈáçÂ§ßÈÄ≤Â±ï„ÄÇ

##### **The Graph's Apprentice: Teaching an LLM Low Level Knowledge for Circuit Quality Estimation**
2411.00843v1 by Reza Moravej, Saurabh Bodhe, Zhanguang Zhang, Didier Chetelat, Dimitrios Tsaras, Yingxue Zhang, Hui-Ling Zhen, Jianye Hao, Mingxuan Yuan

Logic synthesis is a crucial phase in the circuit design process, responsible
for transforming hardware description language (HDL) designs into optimized
netlists. However, traditional logic synthesis methods are computationally
intensive, restricting their iterative use in refining chip designs. Recent
advancements in large language models (LLMs), particularly those fine-tuned on
programming languages, present a promising alternative. In this paper, we
introduce VeriDistill, the first end-to-end machine learning model that
directly processes raw Verilog code to predict circuit quality-of-result
metrics. Our model employs a novel knowledge distillation method, transferring
low-level circuit insights via graphs into the predictor based on LLM.
Experiments show VeriDistill outperforms state-of-the-art baselines on
large-scale Verilog datasets and demonstrates robust performance when evaluated
on out-of-distribution datasets.

ÊëòË¶ÅÔºöÈÇèËºØÂêàÊàêÊòØÈõªË∑ØË®≠Ë®àÈÅéÁ®ã‰∏≠Ëá≥ÈóúÈáçË¶ÅÁöÑ‰∏ÄÂÄãÈöéÊÆµÔºåË≤†Ë≤¨Â∞áÁ°¨È´îÊèèËø∞Ë™ûË®Ä (HDL) Ë®≠Ë®àËΩâÊèõÁÇ∫ÊúÄ‰Ω≥ÂåñÁöÑÁ∂≤Ë∑ØË°®„ÄÇÁÑ∂ËÄåÔºåÂÇ≥Áµ±ÁöÑÈÇèËºØÂêàÊàêÊñπÊ≥ïÂú®ÈÅãÁÆó‰∏äÂæàÂØÜÈõÜÔºåÈôêÂà∂‰∫ÜÂÆÉÂÄëÂú®Á≤æÁÖâÊô∂ÁâáË®≠Ë®à‰∏≠ÁöÑÂèçË¶Ü‰ΩøÁî®„ÄÇÊúÄËøëÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈÄ≤Â±ïÔºåÁâπÂà•ÊòØÈÇ£‰∫õÁ∂ìÈÅéÁ®ãÂºèË™ûË®ÄÂæÆË™øÁöÑÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂ∏åÊúõÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü VeriDistillÔºåÁ¨¨‰∏ÄÂÄãÁ´ØÂà∞Á´ØÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÔºåÂÆÉÁõ¥Êé•ËôïÁêÜÂéüÂßã Verilog Á®ãÂºèÁ¢º‰ª•È†êÊ∏¨ÈõªË∑ØÂìÅË≥™ÁµêÊûúÊåáÊ®ô„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÊé°Áî®‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÁü•Ë≠òÊèêÁÖâÊñπÊ≥ïÔºåÈÄöÈÅéÂúñË°®Â∞á‰ΩéÈöéÈõªË∑ØË¶ãËß£ÂÇ≥Ëº∏Âà∞Âü∫Êñº LLM ÁöÑÈ†êÊ∏¨Âô®‰∏≠„ÄÇÂØ¶È©óË°®ÊòéÔºåVeriDistill Âú®Â§ßË¶èÊ®° Verilog Ë≥áÊñôÈõÜ‰∏äÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÂü∫Ê∫ñÔºå‰∏¶‰∏îÂú®Âú®ÂàÜ‰ΩàÂ§ñË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åË©ï‰º∞ÊôÇË°®ÁèæÂá∫Á©©ÂÅ•ÁöÑÊïàËÉΩ„ÄÇ

##### **Are Large-Language Models Graph Algorithmic Reasoners?**
2410.22597v1 by Alexander K Taylor, Anthony Cuturrufo, Vishal Yathish, Mingyu Derek Ma, Wei Wang

We seek to address a core challenge facing current Large Language Models
(LLMs). LLMs have demonstrated superior performance in many tasks, yet continue
to struggle with reasoning problems on explicit graphs that require multiple
steps. To address this gap, we introduce a novel benchmark designed to evaluate
LLM performance on classical algorithmic reasoning tasks on explicit graphs.
Our benchmark encompasses five fundamental algorithms: Breadth-First Search
(BFS) and Depth-First Search (DFS) for connectivity, Dijkstra's algorithm and
Floyd-Warshall algorithm for all nodes shortest path, and Prim's Minimum
Spanning Tree (MST-Prim's) algorithm. Through extensive experimentation, we
assess the capabilities of state-of-the-art LLMs in executing these algorithms
step-by-step and systematically evaluate their performance at each stage. Our
findings highlight the persistent challenges LLMs face in this domain and
underscore the necessity for advanced prompting techniques and algorithmic
instruction to enhance their graph reasoning abilities. This work presents
MAGMA, the first comprehensive benchmark focused on LLMs completing classical
graph algorithms, and provides a critical step toward understanding and
improving their structured problem-solving skills.

ÊëòË¶ÅÔºöÊàëÂÄëË©¶ÂúñËß£Ê±∫Áï∂ÂâçÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Èù¢Ëá®ÁöÑÊ†∏ÂøÉÊåëÊà∞„ÄÇLLM Âú®Ë®±Â§ö‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫ÂÑ™Áï∞ÁöÑÊÄßËÉΩÔºå‰ΩÜ‰ªçÈõ£‰ª•ÊáâÂ∞çÈúÄË¶ÅÂ§öÂÄãÊ≠•È©üÁöÑÊòéÁ¢∫ÂúñË°®‰∏≠ÁöÑÊé®ÁêÜÂïèÈ°å„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂü∫Ê∫ñÔºåÁî®ÊñºË©ï‰º∞ LLM Âú®ÊòéÁ¢∫ÂúñË°®‰∏äÁöÑÁ∂ìÂÖ∏ÊºîÁÆóÊ≥ïÊé®ÁêÜ‰ªªÂãô‰∏äÁöÑÊÄßËÉΩ„ÄÇÊàëÂÄëÁöÑÂü∫Ê∫ñÂåÖÂê´‰∫îÂÄãÂü∫Êú¨ÊºîÁÆóÊ≥ïÔºöÂª£Â∫¶ÂÑ™ÂÖàÊêúÂ∞ã (BFS) ÂíåÊ∑±Â∫¶ÂÑ™ÂÖàÊêúÂ∞ã (DFS) ‰ª•ÈÄ≤Ë°åÈÄ£ÈÄöÊÄß„ÄÅDijkstra ÊºîÁÆóÊ≥ïÂíå Floyd-Warshall ÊºîÁÆóÊ≥ï‰ª•ÊâæÂá∫ÊâÄÊúâÁØÄÈªûÁöÑÊúÄÁü≠Ë∑ØÂæëÔºå‰ª•Âèä Prim ÊúÄÂ∞èÁîüÊàêÊ®π (MST-Prim) ÊºîÁÆóÊ≥ï„ÄÇÈÄèÈÅéÂª£Ê≥õÁöÑÂØ¶È©óÔºåÊàëÂÄëË©ï‰º∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑ LLM Âú®ÈÄêÊ≠•Âü∑Ë°åÈÄô‰∫õÊºîÁÆóÊ≥ïÁöÑËÉΩÂäõÔºå‰∏¶Á≥ªÁµ±ÊÄßÂú∞Ë©ï‰º∞ÂÆÉÂÄëÂú®ÊØèÂÄãÈöéÊÆµÁöÑÊÄßËÉΩ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÁ™ÅÂá∫‰∫Ü LLM Âú®ÈÄôÂÄãÈ†òÂüüÈù¢Ëá®ÁöÑÊåÅÁ∫åÊåëÊà∞Ôºå‰∏¶Âº∑Ë™ø‰∫Ü‰ΩøÁî®ÈÄ≤ÈöéÊèêÁ§∫ÊäÄË°ìÂíåÊºîÁÆóÊ≥ïÊåá‰ª§‰æÜÂ¢ûÂº∑ÂÖ∂ÂúñÂΩ¢Êé®ÁêÜËÉΩÂäõÁöÑÂøÖË¶ÅÊÄß„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊèêÂá∫‰∫Ü MAGMAÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂ∞àÊ≥®Êñº LLM ÂÆåÊàêÁ∂ìÂÖ∏ÂúñÂΩ¢ÊºîÁÆóÊ≥ïÁöÑÁ∂úÂêàÂü∫Ê∫ñÔºå‰∏¶ÁÇ∫‰∫ÜËß£ÂíåÊîπÈÄ≤ÂÖ∂ÁµêÊßãÂåñÂïèÈ°åËß£Ê±∫ÊäÄËÉΩÊèê‰æõ‰∫ÜÈóúÈçµÁöÑ‰∏ÄÊ≠•„ÄÇ

##### **Advancing Agentic Systems: Dynamic Task Decomposition, Tool Integration and Evaluation using Novel Metrics and Dataset**
2410.22457v1 by Adrian Garret Gabriel, Alaa Alameer Ahmad, Shankar Kumar Jeyakumar

Advancements in Large Language Models (LLMs) are revolutionizing the
development of autonomous agentic systems by enabling dynamic, context-aware
task decomposition and automated tool selection. These sophisticated systems
possess significant automation potential across various industries, managing
complex tasks, interacting with external systems to enhance knowledge, and
executing actions independently. This paper presents three primary
contributions to advance this field:
  - Advanced Agentic Framework: A system that handles multi-hop queries,
generates and executes task graphs, selects appropriate tools, and adapts to
real-time changes.
  - Novel Evaluation Metrics: Introduction of Node F1 Score, Structural
Similarity Index (SSI), and Tool F1 Score to comprehensively assess agentic
systems.
  - Specialized Dataset: Development of an AsyncHow-based dataset for analyzing
agent behavior across different task complexities.
  Our findings reveal that asynchronous and dynamic task graph decomposition
significantly enhances system responsiveness and scalability, particularly for
complex, multi-step tasks. Detailed analysis shows that structural and
node-level metrics are crucial for sequential tasks, while tool-related metrics
are more important for parallel tasks. Specifically, the Structural Similarity
Index (SSI) is the most significant predictor of performance in sequential
tasks, and the Tool F1 Score is essential for parallel tasks. These insights
highlight the need for balanced evaluation methods that capture both structural
and operational dimensions of agentic systems. Additionally, our evaluation
framework, validated through empirical analysis and statistical testing,
provides valuable insights for improving the adaptability and reliability of
agentic systems in dynamic environments.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈÄ≤Â±ïÊ≠£ÈÄèÈÅéÂïüÁî®ÂãïÊÖã„ÄÅÂÖ∑ÊÉÖÂ¢ÉÊÑüÁü•ËÉΩÂäõÁöÑ‰ªªÂãôÂàÜËß£ÂíåËá™ÂãïÂåñÂ∑•ÂÖ∑ÈÅ∏ÊìáÔºåÈù©Êñ∞Ëá™‰∏ª‰ª£ÁêÜÁ≥ªÁµ±ÁöÑÈñãÁôº„ÄÇÈÄô‰∫õÁ≤æÂØÜÁöÑÁ≥ªÁµ±Âú®ÂêÑÁî¢Ê•≠‰∏≠ÊìÅÊúâÈ°ØËëóÁöÑËá™ÂãïÂåñÊΩõÂäõÔºåÁÆ°ÁêÜË§áÈõúÁöÑ‰ªªÂãô„ÄÅËàáÂ§ñÈÉ®Á≥ªÁµ±‰∫íÂãï‰ª•Â¢ûÂº∑Áü•Ë≠òÔºå‰∏¶Áç®Á´ãÂü∑Ë°åÂãï‰Ωú„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏âÂÄã‰∏ªË¶ÅË≤¢Áçª‰ª•Êé®ÂãïÈÄôÂÄãÈ†òÂüüÁöÑÈÄ≤Â±ïÔºö
  - ÈÄ≤Èöé‰ª£ÁêÜÊû∂ÊßãÔºö‰∏ÄÁ®ÆËôïÁêÜÂ§öÈáçË∑≥Ë∫çÊü•Ë©¢„ÄÅÁî¢Áîü‰∏¶Âü∑Ë°å‰ªªÂãôÂúñË°®„ÄÅÈÅ∏ÊìáÈÅ©Áï∂ÁöÑÂ∑•ÂÖ∑Ôºå‰∏¶ÈÅ©ÊáâÂç≥ÊôÇËÆäÂåñÁöÑÁ≥ªÁµ±„ÄÇ
  - Êñ∞Á©éÁöÑË©ï‰º∞ÊåáÊ®ôÔºöÂ∞éÂÖ•ÁØÄÈªû F1 ÂàÜÊï∏„ÄÅÁµêÊßãÁõ∏‰ººÊÄßÊåáÊ®ô (SSI) ÂíåÂ∑•ÂÖ∑ F1 ÂàÜÊï∏Ôºå‰ª•ÂÖ®Èù¢Ë©ï‰º∞‰ª£ÁêÜÁ≥ªÁµ±„ÄÇ
  - Â∞àÊ•≠Ë≥áÊñôÈõÜÔºöÈñãÁôº‰∏ÄÂÄãÂü∫Êñº AsyncHow ÁöÑË≥áÊñôÈõÜÔºåÁî®ÊñºÂàÜÊûê‰ª£ÁêÜË°åÁÇ∫Âú®‰∏çÂêå‰ªªÂãôË§áÈõúÂ∫¶‰πãÈñìÁöÑÂ∑ÆÁï∞„ÄÇ
  ÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåÈùûÂêåÊ≠•ÂíåÂãïÊÖã‰ªªÂãôÂúñË°®ÂàÜËß£ËÉΩÈ°ØËëóÂ¢ûÂº∑Á≥ªÁµ±ÁöÑÂõûÊáâËÉΩÂäõÂíåÂèØÊì¥ÂÖÖÊÄßÔºåÁâπÂà•ÊòØÂ∞çÊñºË§áÈõúÁöÑÂ§öÊ≠•È©ü‰ªªÂãô„ÄÇË©≥Á¥∞ÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÁµêÊßãÂíåÁØÄÈªûÂ±§Á¥öÁöÑÊåáÊ®ôÂ∞çÊñºÈ†ÜÂ∫è‰ªªÂãôËá≥ÈóúÈáçË¶ÅÔºåËÄåËàáÂ∑•ÂÖ∑Áõ∏ÈóúÁöÑÊåáÊ®ôÂ∞çÊñº‰∏¶Ë°å‰ªªÂãôÊõ¥ÁÇ∫ÈáçË¶Å„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÁµêÊßãÁõ∏‰ººÊÄßÊåáÊ®ô (SSI) ÊòØÈ†ÜÂ∫è‰ªªÂãô‰∏≠ÊïàËÉΩÊúÄÈ°ØËëóÁöÑÈ†êÊ∏¨ÊåáÊ®ôÔºåËÄåÂ∑•ÂÖ∑ F1 ÂàÜÊï∏Â∞çÊñº‰∏¶Ë°å‰ªªÂãôËá≥ÈóúÈáçË¶Å„ÄÇÈÄô‰∫õË¶ãËß£Á™ÅÈ°Ø‰∫ÜÂπ≥Ë°°Ë©ï‰º∞ÊñπÊ≥ïÁöÑÈúÄÊ±ÇÔºåË©≤ÊñπÊ≥ïËÉΩÊçïÊçâ‰ª£ÁêÜÁ≥ªÁµ±ÁöÑÁµêÊßãÂíåÊìç‰ΩúÈù¢Âêë„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑË©ï‰º∞Êû∂ÊßãÈÄèÈÅéÂØ¶Ë≠âÂàÜÊûêÂíåÁµ±Ë®àÊ™¢ÂÆöÈ©óË≠âÔºåÁÇ∫ÊîπÂñÑ‰ª£ÁêÜÁ≥ªÁµ±Âú®ÂãïÊÖãÁí∞Â¢É‰∏≠ÁöÑÈÅ©ÊáâÊÄßÂíåÂèØÈù†ÊÄßÊèê‰æõ‰∫ÜÊúâÂÉπÂÄºÁöÑË¶ãËß£„ÄÇ

##### **DynaMath: A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models**
2411.00836v1 by Chengke Zou, Xingang Guo, Rui Yang, Junyu Zhang, Bin Hu, Huan Zhang

The rapid advancements in Vision-Language Models (VLMs) have shown great
potential in tackling mathematical reasoning tasks that involve visual context.
Unlike humans who can reliably apply solution steps to similar problems with
minor modifications, we found that SOTA VLMs like GPT-4o can consistently fail
in these scenarios, revealing limitations in their mathematical reasoning
capabilities. In this paper, we investigate the mathematical reasoning
robustness in VLMs and evaluate how well these models perform under different
variants of the same question, such as changes in visual numerical values or
function graphs. While several vision-based math benchmarks have been developed
to assess VLMs' problem-solving capabilities, these benchmarks contain only
static sets of problems and cannot easily evaluate mathematical reasoning
robustness. To fill this gap, we introduce DynaMath, a dynamic visual math
benchmark designed for in-depth assessment of VLMs. DynaMath includes 501
high-quality, multi-topic seed questions, each represented as a Python program.
Those programs are carefully designed and annotated to enable the automatic
generation of a much larger set of concrete questions, including many different
types of visual and textual variations. DynaMath allows us to evaluate the
generalization ability of VLMs, by assessing their performance under varying
input conditions of a seed question. We evaluated 14 SOTA VLMs with 5,010
generated concrete questions. Our results show that the worst-case model
accuracy, defined as the percentage of correctly answered seed questions in all
10 variants, is significantly lower than the average-case accuracy. Our
analysis emphasizes the need to study the robustness of VLMs' reasoning
abilities, and DynaMath provides valuable insights to guide the development of
more reliable models for mathematical reasoning.

ÊëòË¶ÅÔºö<paragraph>Ë¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) ÁöÑÂø´ÈÄüÈÄ≤Ê≠•Âú®Ëß£Ê±∫Ê∂âÂèäË¶ñË¶∫ËÉåÊôØÁöÑÊï∏Â≠∏Êé®ÁêÜ‰ªªÂãôÊñπÈù¢Â±ïÁèæ‰∫ÜÂ∑®Â§ßÁöÑÊΩõÂäõ„ÄÇËàá‰∫∫È°ûÂèØ‰ª•Â∞áËß£Ê±∫Ê≠•È©üÂèØÈù†Âú∞ÊáâÁî®ÊñºÈ°û‰ººÂïèÈ°åÔºà‰∏¶ÈÄ≤Ë°åÂæÆÂ∞èÁöÑ‰øÆÊîπÔºâ‰∏çÂêåÔºåÊàëÂÄëÁôºÁèæÂÉè GPT-4o Á≠â SOTA VLM Âú®ÈÄô‰∫õÂ†¥ÊôØ‰∏≠ÂèØËÉΩÊúÉÊåÅÁ∫åÂ§±ÊïóÔºåÊè≠Èú≤‰∫ÜÂÖ∂Êï∏Â≠∏Êé®ÁêÜËÉΩÂäõÁöÑÈôêÂà∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁ†îÁ©∂‰∫Ü VLM ‰∏≠ÁöÑÊï∏Â≠∏Êé®ÁêÜÁ©©ÂÅ•ÊÄßÔºå‰∏¶Ë©ï‰º∞‰∫ÜÈÄô‰∫õÊ®°ÂûãÂú®Âêå‰∏ÄÂïèÈ°åÁöÑ‰∏çÂêåËÆäÈ´îÔºà‰æãÂ¶ÇË¶ñË¶∫Êï∏ÂÄºÊàñÂáΩÊï∏ÂúñÂΩ¢ÁöÑËÆäÂåñÔºâ‰∏ãÁöÑË°®Áèæ„ÄÇÈõñÁÑ∂Â∑≤Á∂ìÈñãÁôº‰∫ÜÂ§öÂÄãÂü∫ÊñºË¶ñË¶∫ÁöÑÊï∏Â≠∏Âü∫Ê∫ñ‰æÜË©ï‰º∞ VLM ÁöÑÂïèÈ°åËß£Ê±∫ËÉΩÂäõÔºå‰ΩÜÈÄô‰∫õÂü∫Ê∫ñÂè™ÂåÖÂê´ÈùúÊÖãÂïèÈ°åÈõÜÔºåÁÑ°Ê≥ïËºïÈ¨ÜË©ï‰º∞Êï∏Â≠∏Êé®ÁêÜÁ©©ÂÅ•ÊÄß„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄô‰∏ÄÁ©∫ÁôΩÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü DynaMathÔºåÈÄôÊòØ‰∏ÄÂÄãÂãïÊÖãË¶ñË¶∫Êï∏Â≠∏Âü∫Ê∫ñÔºåÂ∞àÈñÄÁî®ÊñºÊ∑±ÂÖ•Ë©ï‰º∞ VLM„ÄÇDynaMath ÂåÖÂê´ 501 ÂÄãÈ´òÂìÅË≥™„ÄÅÂ§ö‰∏ªÈ°åÁ®ÆÂ≠êÂïèÈ°åÔºåÊØèÂÄãÂïèÈ°åÈÉΩË°®Á§∫ÁÇ∫‰∏ÄÂÄã Python Á®ãÂºè„ÄÇÈÄô‰∫õÁ®ãÂºèÁ∂ìÈÅé‰ªîÁ¥∞Ë®≠Ë®àÂíåË®ªËß£Ôºå‰ª•‰æøËá™ÂãïÁî¢Áîü‰∏ÄÁµÑÊõ¥Â§ßÁöÑÂÖ∑È´îÂïèÈ°åÔºåÂåÖÊã¨Ë®±Â§ö‰∏çÂêåÈ°ûÂûãÁöÑË¶ñË¶∫ÂíåÊñáÂ≠óËÆäÈ´î„ÄÇDynaMath ÂÖÅË®±ÊàëÂÄëË©ï‰º∞ VLM ÁöÑÊ≥õÂåñËÉΩÂäõÔºåÊñπÊ≥ïÊòØÂú®Á®ÆÂ≠êÂïèÈ°åÁöÑ‰∏çÂêåËº∏ÂÖ•Ê¢ù‰ª∂‰∏ãË©ï‰º∞ÂÖ∂Ë°®Áèæ„ÄÇÊàëÂÄë‰ΩøÁî® 5,010 ÂÄãÁîüÊàêÁöÑÂÖ∑È´îÂïèÈ°åË©ï‰º∞‰∫Ü 14 ÂÄã SOTA VLM„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåÊúÄÂ∑ÆÊÉÖÊ≥ÅÁöÑÊ®°ÂûãÊ∫ñÁ¢∫Â∫¶ÔºàÂÆöÁæ©ÁÇ∫Âú®ÊâÄÊúâ 10 ÂÄãËÆäÈ´î‰∏≠Ê≠£Á¢∫ÂõûÁ≠îÁöÑÁ®ÆÂ≠êÂïèÈ°åÁöÑÁôæÂàÜÊØîÔºâÈ°ØËëó‰ΩéÊñºÂπ≥ÂùáÊÉÖÊ≥ÅÊ∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÂº∑Ë™ø‰∫ÜÁ†îÁ©∂ VLM Êé®ÁêÜËÉΩÂäõÁ©©ÂÅ•ÊÄßÁöÑÂøÖË¶ÅÊÄßÔºåËÄå DynaMath Êèê‰æõ‰∫ÜÊúâÂÉπÂÄºÁöÑË¶ãËß£Ôºå‰ª•ÊåáÂ∞éÈñãÁôºÊõ¥ÂèØÈù†ÁöÑÊï∏Â≠∏Êé®ÁêÜÊ®°Âûã„ÄÇ</paragraph>

##### **ADAM: An Embodied Causal Agent in Open-World Environments**
2410.22194v1 by Shu Yu, Chaochao Lu

In open-world environments like Minecraft, existing agents face challenges in
continuously learning structured knowledge, particularly causality. These
challenges stem from the opacity inherent in black-box models and an excessive
reliance on prior knowledge during training, which impair their
interpretability and generalization capability. To this end, we introduce ADAM,
An emboDied causal Agent in Minecraft, that can autonomously navigate the open
world, perceive multimodal contexts, learn causal world knowledge, and tackle
complex tasks through lifelong learning. ADAM is empowered by four key
components: 1) an interaction module, enabling the agent to execute actions
while documenting the interaction processes; 2) a causal model module, tasked
with constructing an ever-growing causal graph from scratch, which enhances
interpretability and diminishes reliance on prior knowledge; 3) a controller
module, comprising a planner, an actor, and a memory pool, which uses the
learned causal graph to accomplish tasks; 4) a perception module, powered by
multimodal large language models, which enables ADAM to perceive like a human
player. Extensive experiments show that ADAM constructs an almost perfect
causal graph from scratch, enabling efficient task decomposition and execution
with strong interpretability. Notably, in our modified Minecraft games where no
prior knowledge is available, ADAM maintains its performance and shows
remarkable robustness and generalization capability. ADAM pioneers a novel
paradigm that integrates causal methods and embodied agents in a synergistic
manner. Our project page is at https://opencausalab.github.io/ADAM.

ÊëòË¶ÅÔºöÂú®ÂÉè Minecraft ÈÄôÊ®£ÁöÑÈñãÊîæ‰∏ñÁïåÁí∞Â¢É‰∏≠ÔºåÁèæÊúâÁöÑ‰ª£ÁêÜ‰∫∫Èù¢Ëá®ÊåÅÁ∫åÂ≠∏ÁøíÁµêÊßãÂåñÁü•Ë≠òÁöÑÊåëÊà∞ÔºåÂ∞§ÂÖ∂ÊòØÂõ†ÊûúÈóú‰øÇ„ÄÇÈÄô‰∫õÊåëÊà∞Ê∫êÊñºÈªëÁõíÊ®°ÂûãÂõ∫ÊúâÁöÑ‰∏çÈÄèÊòéÊÄßÔºå‰ª•ÂèäÂú®Ë®ìÁ∑¥ÊúüÈñìÈÅéÂ∫¶‰æùË≥¥ÂÖàÈ©óÁü•Ë≠òÔºåÈÄôÊúÉÊêçÂÆ≥ÂÆÉÂÄëÁöÑÂèØËß£ÈáãÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü ADAMÔºåMinecraft ‰∏≠ÁöÑ‰∏ÄÂÄãÂÖ∑Ë∫´Âõ†Êûú‰ª£ÁêÜÔºåÂÆÉÂèØ‰ª•Ëá™‰∏ªÂ∞éËà™ÈñãÊîæ‰∏ñÁïåÔºåÊÑüÁü•Â§öÊ®°Âºè‰∏ä‰∏ãÊñáÔºåÂ≠∏ÁøíÂõ†Êûú‰∏ñÁïåÁü•Ë≠òÔºå‰∏¶ÈÄöÈÅéÁµÇË∫´Â≠∏Áøí‰æÜÊáâÂ∞çË§áÈõú‰ªªÂãô„ÄÇADAM Áî±ÂõõÂÄãÈóúÈçµÁµÑÊàêÈÉ®ÂàÜË≥¶ËÉΩÔºö1) ‰∏ÄÂÄã‰∫§‰∫íÊ®°ÁµÑÔºå‰Ωø‰ª£ÁêÜËÉΩÂ§†Âü∑Ë°åÂãï‰ΩúÔºåÂêåÊôÇË®òÈåÑ‰∫§‰∫íÈÅéÁ®ãÔºõ2) ‰∏ÄÂÄãÂõ†ÊûúÊ®°ÂûãÊ®°ÁµÑÔºåË≤†Ë≤¨ÂæûÈ†≠ÈñãÂßãÊßãÂª∫‰∏ÄÂÄã‰∏çÊñ∑Â¢ûÈï∑ÁöÑÂõ†ÊûúÂúñÔºåÈÄôÂ¢ûÂº∑‰∫ÜÂèØËß£ÈáãÊÄß‰∏¶Ê∏õÂ∞ë‰∫ÜÂ∞çÂÖàÈ©óÁü•Ë≠òÁöÑ‰æùË≥¥Ôºõ3) ‰∏ÄÂÄãÊéßÂà∂Âô®Ê®°ÁµÑÔºåÂåÖÊã¨‰∏ÄÂÄãË¶èÂäÉÂô®„ÄÅ‰∏ÄÂÄãÂü∑Ë°åÂô®Âíå‰∏ÄÂÄãË®òÊÜ∂Ê±†ÔºåÂÆÉ‰ΩøÁî®Â≠∏ÁøíÂà∞ÁöÑÂõ†ÊûúÂúñ‰æÜÂÆåÊàê‰ªªÂãôÔºõ4) ‰∏ÄÂÄãÊÑüÁü•Ê®°ÁµÑÔºåÁî±Â§öÊ®°ÂºèÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÊèê‰æõÊîØÊè¥Ôºå‰Ωø ADAM ËÉΩÂ§†ÂÉè‰∫∫È°ûÁé©ÂÆ∂‰∏ÄÊ®£ÊÑüÁü•„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óË°®ÊòéÔºåADAM ÂæûÈ†≠ÈñãÂßãÊßãÂª∫‰∫Ü‰∏ÄÂÄãÂπæ‰πéÂÆåÁæéÁöÑÂõ†ÊûúÂúñÔºåÂØ¶Áèæ‰∫ÜÈ´òÊïàÁöÑ‰ªªÂãôÂàÜËß£ÂíåÂü∑Ë°åÔºå‰∏¶ÂÖ∑ÊúâÂæàÂº∑ÁöÑÂèØËß£ÈáãÊÄß„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂú®ÊàëÂÄë‰øÆÊîπÈÅéÁöÑ Minecraft ÈÅäÊà≤‰∏≠ÔºåÊ≤íÊúâÂèØÁî®ÁöÑÂÖàÈ©óÁü•Ë≠òÔºåADAM ‰øùÊåÅ‰∫ÜÂÖ∂ÊÄßËÉΩÔºå‰∏¶Ë°®ÁèæÂá∫È°ØËëóÁöÑÈ≠ØÊ£íÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇADAM ÈñãÂâµ‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÁØÑ‰æãÔºå‰ª•ÂçîÂêåÊñπÂºèÊï¥ÂêàÂõ†ÊûúÊñπÊ≥ïÂíåÂÖ∑Ë∫´‰ª£ÁêÜ„ÄÇÊàëÂÄëÁöÑÂ∞àÊ°àÈ†ÅÈù¢‰ΩçÊñº https://opencausalab.github.io/ADAM„ÄÇ

##### **GraphAide: Advanced Graph-Assisted Query and Reasoning System**
2411.08041v1 by Sumit Purohit, George Chin, Patrick S Mackey, Joseph A Cottam

Curating knowledge from multiple siloed sources that contain both structured
and unstructured data is a major challenge in many real-world applications.
Pattern matching and querying represent fundamental tasks in modern data
analytics that leverage this curated knowledge. The development of such
applications necessitates overcoming several research challenges, including
data extraction, named entity recognition, data modeling, and designing query
interfaces. Moreover, the explainability of these functionalities is critical
for their broader adoption.
  The emergence of Large Language Models (LLMs) has accelerated the development
lifecycle of new capabilities. Nonetheless, there is an ongoing need for
domain-specific tools tailored to user activities. The creation of digital
assistants has gained considerable traction in recent years, with LLMs offering
a promising avenue to develop such assistants utilizing domain-specific
knowledge and assumptions.
  In this context, we introduce an advanced query and reasoning system,
GraphAide, which constructs a knowledge graph (KG) from diverse sources and
allows to query and reason over the resulting KG. GraphAide harnesses both the
KG and LLMs to rapidly develop domain-specific digital assistants. It
integrates design patterns from retrieval augmented generation (RAG) and the
semantic web to create an agentic LLM application. GraphAide underscores the
potential for streamlined and efficient development of specialized digital
assistants, thereby enhancing their applicability across various domains.

ÊëòË¶ÅÔºöÂæûÂåÖÂê´ÁµêÊßãÂåñÂíåÈùûÁµêÊßãÂåñË≥áÊñôÁöÑÂ§öÂÄãÂ≠§Á´ã‰æÜÊ∫ê‰∏≠Êï¥ÁêÜÁü•Ë≠òÔºåÊòØË®±Â§öÂØ¶ÈöõÊáâÁî®‰∏≠ÁöÑ‰∏ÄÈ†ÖÈáçÂ§ßÊåëÊà∞„ÄÇ
Ê®°ÂºèÊØîÂ∞çÂíåÊü•Ë©¢‰ª£Ë°®‰∫ÜÁèæ‰ª£Ë≥áÊñôÂàÜÊûêÁöÑÂü∫Êú¨‰ªªÂãôÔºåÂà©Áî®ÈÄô‰∫õÊï¥ÁêÜÂ•ΩÁöÑÁü•Ë≠ò„ÄÇÈÄôÁ®ÆÊáâÁî®ÁöÑÁôºÂ±ïÈúÄË¶ÅÂÖãÊúçÂ§öÈ†ÖÁ†îÁ©∂ÊåëÊà∞ÔºåÂåÖÊã¨Ë≥áÊñôËêÉÂèñ„ÄÅÂëΩÂêçÂØ¶È´îËæ®Ë≠ò„ÄÅË≥áÊñôÂª∫Ê®°ÂíåË®≠Ë®àÊü•Ë©¢‰ªãÈù¢„ÄÇÊ≠§Â§ñÔºåÈÄô‰∫õÂäüËÉΩÁöÑÂèØËß£ÈáãÊÄßÂ∞çÊñºÂÖ∂Êõ¥Âª£Ê≥õÁöÑÊé°Áî®Ëá≥ÈóúÈáçË¶Å„ÄÇ
Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂá∫ÁèæÂä†ÈÄü‰∫ÜÊñ∞ÂäüËÉΩÁöÑÈñãÁôºÈÄ±Êúü„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§Ôºå‰ªçÁÑ∂ÈúÄË¶ÅÈáùÂ∞ç‰ΩøÁî®ËÄÖÊ¥ªÂãïÈáèË∫´ÊâìÈÄ†ÁöÑÁâπÂÆöÈ†òÂüüÂ∑•ÂÖ∑„ÄÇËøëÂπ¥‰æÜÔºåÊï∏‰ΩçÂä©ÁêÜÁöÑÂª∫Á´ãÁç≤Âæó‰∫ÜÁõ∏Áï∂Â§ßÁöÑÈÄ≤Â±ïÔºåLLM Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑÈÄîÂæëÔºåÂèØ‰ª•Âà©Áî®ÁâπÂÆöÈ†òÂüüÁöÑÁü•Ë≠òÂíåÂÅáË®≠‰æÜÈñãÁôºÊ≠§È°ûÂä©ÁêÜ„ÄÇ
Âú®Ê≠§ËÉåÊôØ‰∏ãÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂÖàÈÄ≤ÁöÑÊü•Ë©¢ÂíåÊé®ÁêÜÁ≥ªÁµ± GraphAideÔºåÂÆÉÂæû‰∏çÂêåÁöÑ‰æÜÊ∫êÊßãÂª∫‰∏ÄÂÄãÁü•Ë≠òÂúñË≠ú (KG)Ôºå‰∏¶ÂÖÅË®±Êü•Ë©¢ÂíåÊé®ÁêÜÊâÄÂæóÁöÑ KG„ÄÇGraphAide Âà©Áî® KG Âíå LLM ‰æÜÂø´ÈÄüÈñãÁôºÁâπÂÆöÈ†òÂüüÁöÑÊï∏‰ΩçÂä©ÁêÜ„ÄÇÂÆÉÊï¥Âêà‰∫ÜÊ™¢Á¥¢Êì¥ÂÖÖÁîüÊàê (RAG) ÂíåË™ûÁæ©Á∂≤Ë∑ØÁöÑË®≠Ë®àÊ®°ÂºèÔºå‰ª•Âª∫Á´ã‰∏ÄÂÄã‰ª£ÁêÜ LLM ÊáâÁî®Á®ãÂºè„ÄÇGraphAide Âº∑Ë™ø‰∫ÜÁ∞°ÂåñÂíåÊúâÊïàÈñãÁôºÂ∞àÊ•≠Êï∏‰ΩçÂä©ÁêÜÁöÑÊΩõÂäõÔºåÂæûËÄåÂ¢ûÂº∑ÂÖ∂Âú®ÂêÑÂÄãÈ†òÂüüÁöÑÈÅ©Áî®ÊÄß„ÄÇ

##### **Synergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN**
2411.00028v2 by Zhilun Zhou, Jingyang Fan, Yu Liu, Fengli Xu, Depeng Jin, Yong Li

The fast development of location-based social networks (LBSNs) has led to
significant changes in society, resulting in popular studies of using LBSN data
for socioeconomic prediction, e.g., regional population and commercial activity
estimation. Existing studies design various graphs to model heterogeneous LBSN
data, and further apply graph representation learning methods for socioeconomic
prediction. However, these approaches heavily rely on heuristic ideas and
expertise to extract task-relevant knowledge from diverse data, which may not
be optimal for specific tasks. Additionally, they tend to overlook the inherent
relationships between different indicators, limiting the prediction accuracy.
Motivated by the remarkable abilities of large language models (LLMs) in
commonsense reasoning, embedding, and multi-agent collaboration, in this work,
we synergize LLM agents and knowledge graph for socioeconomic prediction. We
first construct a location-based knowledge graph (LBKG) to integrate
multi-sourced LBSN data. Then we leverage the reasoning power of LLM agent to
identify relevant meta-paths in the LBKG for each type of socioeconomic
prediction task, and design a semantic-guided attention module for knowledge
fusion with meta-paths. Moreover, we introduce a cross-task communication
mechanism to further enhance performance by enabling knowledge sharing across
tasks at both LLM agent and KG levels. On the one hand, the LLM agents for
different tasks collaborate to generate more diverse and comprehensive
meta-paths. On the other hand, the embeddings from different tasks are
adaptively merged for better socioeconomic prediction. Experiments on two
datasets demonstrate the effectiveness of the synergistic design between LLM
and KG, providing insights for information sharing across socioeconomic
prediction tasks.

ÊëòË¶ÅÔºö<paragraph>Âü∫Êñº‰ΩçÁΩÆÁöÑÁ§æÁæ§Á∂≤Ë∑Ø (LBSN) Âø´ÈÄüÁôºÂ±ïÔºåÂ∑≤Â∞çÁ§æÊúÉÈÄ†ÊàêÈáçÂ§ßËÆäÈù©ÔºåÂ∞éËá¥ÈáùÂ∞ç‰ΩøÁî® LBSN Ë≥áÊñôÈÄ≤Ë°åÁ§æÊúÉÁ∂ìÊøüÈ†êÊ∏¨Ôºà‰æãÂ¶ÇÂçÄÂüü‰∫∫Âè£ÂíåÂïÜÊ•≠Ê¥ªÂãï‰º∞Ë®àÔºâÁöÑÁ†îÁ©∂ËîöÁÇ∫È¢®Ë°å„ÄÇÁèæÊúâÁ†îÁ©∂Ë®≠Ë®àÂêÑÁ®ÆÂúñÂΩ¢‰æÜÂª∫Ê®°Áï∞Ë≥™ÁöÑ LBSN Ë≥áÊñôÔºå‰∏¶ÈÄ≤‰∏ÄÊ≠•ÊáâÁî®ÂúñÂΩ¢Ë°®Á§∫Â≠∏ÁøíÊñπÊ≥ïÈÄ≤Ë°åÁ§æÊúÉÁ∂ìÊøüÈ†êÊ∏¨„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÈ´òÂ∫¶‰æùË≥¥Ë©¶Êé¢Ê≥ïÊßãÊÉ≥ÂíåÂ∞àÊ•≠Áü•Ë≠òÔºåÂæû‰∏çÂêåÁöÑË≥áÊñô‰∏≠ËêÉÂèñËàá‰ªªÂãôÁõ∏ÈóúÁöÑÁü•Ë≠òÔºåÈÄôÂèØËÉΩÁÑ°Ê≥ïÈáùÂ∞çÁâπÂÆö‰ªªÂãôÈÄ≤Ë°åÊúÄ‰Ω≥Âåñ„ÄÇÊ≠§Â§ñÔºåÈÄô‰∫õÊñπÊ≥ïÂæÄÂæÄÂøΩÁï•‰∏çÂêåÊåáÊ®ô‰πãÈñìÁöÑÂÖßÂú®ÈóúËÅØÊÄßÔºåÈôêÂà∂‰∫ÜÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÂèóÂà∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Â∏∏Ë≠òÊé®ÁêÜ„ÄÅÂµåÂÖ•ÂíåÂ§öÈáç‰ª£ÁêÜÂçî‰ΩúÊñπÈù¢ÁöÑÈ°ØËëóËÉΩÂäõÊâÄÊøÄÂãµÔºåÂõ†Ê≠§Âú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ∞á LLM ‰ª£ÁêÜÂíåÁü•Ë≠òÂúñË≠úÂçîÂêåÊáâÁî®ÊñºÁ§æÊúÉÁ∂ìÊøüÈ†êÊ∏¨„ÄÇÊàëÂÄëÈ¶ñÂÖàÂª∫Êßã‰∏ÄÂÄãÂü∫Êñº‰ΩçÁΩÆÁöÑÁü•Ë≠òÂúñË≠ú (LBKG)Ôºå‰ª•Êï¥ÂêàÂ§ö‰æÜÊ∫êÁöÑ LBSN Ë≥áÊñô„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂà©Áî® LLM ‰ª£ÁêÜÁöÑÊé®ÁêÜËÉΩÂäõÔºåÈáùÂ∞çÊØèÁ®ÆÈ°ûÂûãÁöÑÁ§æÊúÉÁ∂ìÊøüÈ†êÊ∏¨‰ªªÂãôË≠òÂà• LBKG ‰∏≠Áõ∏ÈóúÁöÑÂÖÉË∑ØÂæëÔºå‰∏¶Ë®≠Ë®à‰∏ÄÂÄãË™ûÁæ©Â∞éÂêëÁöÑÊ≥®ÊÑèÂäõÊ®°ÁµÑÔºåÁî®ÊñºËàáÂÖÉË∑ØÂæëËûçÂêàÁü•Ë≠ò„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÂÄãË∑®‰ªªÂãôÊ∫ùÈÄöÊ©üÂà∂ÔºåÈÄèÈÅéÂú® LLM ‰ª£ÁêÜÂíå KG Â±§Á¥ö‰∏äËÆìÁü•Ë≠òË∑®‰ªªÂãôÂàÜ‰∫´ÔºåÈÄ≤‰∏ÄÊ≠•ÊèêÂçáÊïàËÉΩ„ÄÇ‰∏ÄÊñπÈù¢Ôºå‰∏çÂêå‰ªªÂãôÁöÑ LLM ‰ª£ÁêÜÂçî‰ΩúÔºå‰ª•Áî¢ÁîüÊõ¥Â§öÊ®£Âåñ‰∏îÂÖ®Èù¢ÁöÑÂÖÉË∑ØÂæë„ÄÇÂè¶‰∏ÄÊñπÈù¢Ôºå‰∏çÂêå‰ªªÂãôÁöÑÂµåÂÖ•ÂºèÊúÉ‰ª•ÈÅ©ÊáâÊÄßÊñπÂºèÂêà‰ΩµÔºå‰ª•ÈÄ≤Ë°åÊõ¥‰Ω≥ÁöÑÁ§æÊúÉÁ∂ìÊøüÈ†êÊ∏¨„ÄÇÈáùÂ∞çÂÖ©ÂÄãË≥áÊñôÈõÜÁöÑÂØ¶È©óË≠âÊòé‰∫Ü LLM Âíå KG ‰πãÈñìÂçîÂêåË®≠Ë®àÁöÑÊúâÊïàÊÄßÔºå‰∏¶ÁÇ∫Ë∑®Á§æÊúÉÁ∂ìÊøüÈ†êÊ∏¨‰ªªÂãôÁöÑË≥áË®äÂàÜ‰∫´Êèê‰æõË¶ãËß£„ÄÇ</paragraph>

##### **A Hierarchical Language Model For Interpretable Graph Reasoning**
2410.22372v1 by Sambhav Khurana, Xiner Li, Shurui Gui, Shuiwang Ji

Large language models (LLMs) are being increasingly explored for graph tasks.
Despite their remarkable success in text-based tasks, LLMs' capabilities in
understanding explicit graph structures remain limited, particularly with large
graphs. In this work, we introduce Hierarchical Language Model for Graph
(HLM-G), which employs a two-block architecture to capture node-centric local
information and interaction-centric global structure, effectively enhancing
graph structure understanding abilities. The proposed scheme allows LLMs to
address various graph queries with high efficacy, efficiency, and robustness,
while reducing computational costs on large-scale graph tasks. Furthermore, we
demonstrate the interpretability of our model using intrinsic attention weights
and established explainers. Comprehensive evaluations across diverse graph
reasoning and real-world tasks of node, link, and graph-levels highlight the
superiority of our method, marking a significant advancement in the application
of LLMs to graph understanding.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊÑà‰æÜÊÑàÂ§öÁî®ÊñºÂúñÂΩ¢‰ªªÂãô„ÄÇ
ÂÑòÁÆ° LLM Âú®Âü∫ÊñºÊñáÂ≠óÁöÑ‰ªªÂãô‰∏≠ÂèñÂæóÈ°ØËëóÁöÑÊàêÂäüÔºå‰ΩÜÂÖ∂Âú®ÁêÜËß£ÊòéÁ¢∫ÂúñÂΩ¢ÁµêÊßãÊñπÈù¢ÁöÑËÉΩÂäõ‰ªçÁÑ∂ÊúâÈôêÔºåÁâπÂà•ÊòØÂ∞çÊñºÂ§ßÂûãÂúñÂΩ¢„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂúñÂΩ¢ÈöéÂ±§Ë™ûË®ÄÊ®°Âûã (HLM-G)ÔºåÂÆÉÊé°Áî®ÈõôÂçÄÂ°äÊû∂Êßã‰æÜÊì∑Âèñ‰ª•ÁØÄÈªûÁÇ∫‰∏≠ÂøÉÁöÑÂ±ÄÈÉ®Ë≥áË®äÂíå‰ª•‰∫íÂãïÁÇ∫‰∏≠ÂøÉÁöÑÊï¥È´îÁµêÊßãÔºåÊúâÊïàÂú∞Â¢ûÂº∑‰∫ÜÂúñÂΩ¢ÁµêÊßãÁêÜËß£ËÉΩÂäõ„ÄÇÊâÄÊèêÂá∫ÁöÑÊû∂ÊßãÂÖÅË®± LLM ‰ª•È´òÊïàÁéá„ÄÅÈ´òÊïàÁéáÂíåÈ´òÁ©©ÂÅ•ÊÄß‰æÜËôïÁêÜÂêÑÁ®ÆÂúñÂΩ¢Êü•Ë©¢ÔºåÂêåÊôÇÈôç‰ΩéÂ§ßÂûãÂúñÂΩ¢‰ªªÂãôÁöÑÈÅãÁÆóÊàêÊú¨„ÄÇÊ≠§Â§ñÔºåÊàëÂÄë‰ΩøÁî®ÂÖßÂú®Ê≥®ÊÑèÂäõÊ¨äÈáçÂíåÂ∑≤Âª∫Á´ãÁöÑËß£ÈáãÂô®‰æÜÂ±ïÁ§∫ÊàëÂÄëÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄß„ÄÇÂú®ÁØÄÈªû„ÄÅÈÄ£ÁµêÂíåÂúñÂΩ¢Â±§Á¥öÁöÑÂêÑÁ®ÆÂúñÂΩ¢Êé®ÁêÜÂíåÁúüÂØ¶‰∏ñÁïå‰ªªÂãô‰∏≠ÈÄ≤Ë°åÁöÑÂÖ®Èù¢Ë©ï‰º∞Á™ÅÈ°Ø‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÂÑ™Ë∂äÊÄßÔºåÊ®ôË™åËëó LLM Âú®ÂúñÂΩ¢ÁêÜËß£ÊáâÁî®ÊñπÈù¢ÂèñÂæóÈáçÂ§ßÈÄ≤Â±ï„ÄÇ

##### **LLM-Forest for Health Tabular Data Imputation**
2410.21520v1 by Xinrui He, Yikun Ban, Jiaru Zou, Tianxin Wei, Curtiss B. Cook, Jingrui He

Missing data imputation is a critical challenge in tabular datasets,
especially in healthcare, where data completeness is vital for accurate
analysis. Large language models (LLMs), trained on vast corpora, have shown
strong potential in data generation, making them a promising tool for tabular
data imputation. However, challenges persist in designing effective prompts for
a finetuning-free process and in mitigating the risk of LLM hallucinations. To
address these issues, we propose a novel framework, LLM-Forest, which
introduces a "forest" of few-shot learning LLM "trees" with confidence-based
weighted voting. This framework is established on a new concept of bipartite
information graphs to identify high-quality relevant neighboring entries with
both feature and value granularity. Extensive experiments on four real-world
healthcare datasets demonstrate the effectiveness and efficiency of LLM-Forest.

ÊëòË¶ÅÔºöÈÅ∫Â§±Ë≥áÊñôÊé®‰º∞ÊòØË°®Ê†ºË≥áÊñôÈõÜ‰∏≠ÁöÑÈáçÂ§ßÊåëÊà∞Ôºå
ÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÔºåË≥áÊñôÂÆåÊï¥ÊÄßÂ∞çÊñºÊ∫ñÁ¢∫ÂàÜÊûêËá≥ÈóúÈáçË¶Å„ÄÇ
Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÈæêÂ§ßÁöÑË™ûÊñôÂ∫´‰∏äË®ìÁ∑¥ÔºåÂú®Ë≥áÊñôÁî¢ÁîüÊñπÈù¢Â±ïÁèæÂá∫Âº∑Â§ßÁöÑÊΩõÂäõÔºå‰ΩøÂÖ∂ÊàêÁÇ∫Ë°®Ê†ºË≥áÊñôÊé®‰º∞ÁöÑÊúâÂâçÈÄîÂ∑•ÂÖ∑„ÄÇ
ÁÑ∂ËÄåÔºåÂú®Ë®≠Ë®àÊúâÊïàÊèêÁ§∫‰ª•ÈÄ≤Ë°åÂæÆË™øÂÖçË≤ªÊµÅÁ®ãÂíåÊ∏õËºï LLM ÂπªË¶∫È¢®Èö™ÊñπÈù¢‰ªçÂ≠òÂú®ÊåëÊà∞„ÄÇ
ÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÊ°ÜÊû∂ÔºåLLM-ForestÔºåÂÆÉÂºïÂÖ•‰∫Ü‰∏ÄÂÄã„ÄåÊ£ÆÊûó„ÄçÁöÑÂ∞ëÈáèÂ≠∏Áøí LLM„ÄåÊ®π„ÄçÔºå‰∏¶Êé°Áî®Âü∫Êñº‰ø°ÂøÉÁöÑÂä†Ê¨äÊäïÁ•®„ÄÇ
ÈÄôÂÄãÊ°ÜÊû∂Âª∫Á´ãÂú®ÈõôÂàÜË≥áË®äÂúñÁöÑÊñ∞Ê¶ÇÂøµ‰∏äÔºå‰ª•Ë≠òÂà•ÂÖ∑ÊúâÁâπÂæµÂíåÂÄºÁ≤íÂ∫¶ÁöÑÂÑ™Ë≥™Áõ∏ÈóúÈÑ∞ËøëÈ†ÖÁõÆ„ÄÇ
Âú®ÂõõÂÄãÁúüÂØ¶‰∏ñÁïåÁöÑÈÜ´ÁôÇ‰øùÂÅ•Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫Ü LLM-Forest ÁöÑÊúâÊïàÊÄßÂíåÊïàÁéá„ÄÇ

##### **Hierarchical Knowledge Graph Construction from Images for Scalable E-Commerce**
2410.21237v1 by Zhantao Yang, Han Zhang, Fangyi Chen, Anudeepsekhar Bolimera, Marios Savvides

Knowledge Graph (KG) is playing an increasingly important role in various AI
systems. For e-commerce, an efficient and low-cost automated knowledge graph
construction method is the foundation of enabling various successful downstream
applications. In this paper, we propose a novel method for constructing
structured product knowledge graphs from raw product images. The method
cooperatively leverages recent advances in the vision-language model (VLM) and
large language model (LLM), fully automating the process and allowing timely
graph updates. We also present a human-annotated e-commerce product dataset for
benchmarking product property extraction in knowledge graph construction. Our
method outperforms our baseline in all metrics and evaluated properties,
demonstrating its effectiveness and bright usage potential.

ÊëòË¶ÅÔºöÁü•Ë≠òÂúñË≠ú (KG) Âú®ÂêÑÁ®Æ AI Á≥ªÁµ±‰∏≠ÊâÆÊºîË∂ä‰æÜË∂äÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÂ∞çÊñºÈõªÂ≠êÂïÜÂãô‰æÜË™™Ôºå‰∏ÄÁ®ÆÊúâÊïà‰∏î‰ΩéÊàêÊú¨ÁöÑËá™ÂãïÂåñÁü•Ë≠òÂúñË≠úÂª∫ÊßãÊñπÊ≥ïÊòØ‰øÉÊàêÂêÑÁ®ÆÊàêÂäüÁöÑ‰∏ãÊ∏∏ÊáâÁî®Á®ãÂºèÁöÑÂü∫Á§é„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂæûÂéüÂßãÁî¢ÂìÅÂΩ±ÂÉèÂª∫ÊßãÁµêÊßãÂåñÁî¢ÂìÅÁü•Ë≠òÂúñË≠úÁöÑÊñ∞Á©éÊñπÊ≥ï„ÄÇË©≤ÊñπÊ≥ïÂçîÂêåÂà©Áî®‰∫ÜË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) ÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºåÂÆåÂÖ®Ëá™ÂãïÂåñ‰∫ÜÊµÅÁ®ã‰∏¶ÂÖÅË®±ÂèäÊôÇÊõ¥Êñ∞ÂúñË≠ú„ÄÇÊàëÂÄëÈÇÑÊèê‰æõ‰∫Ü‰∏ÄÂÄãÁî±‰∫∫Â∑•Ê®ôË®ªÁöÑÈõªÂ≠êÂïÜÂãôÁî¢ÂìÅË≥áÊñôÈõÜÔºåÁî®ÊñºË©ïÈáèÁü•Ë≠òÂúñË≠úÂª∫Êßã‰∏≠ÁöÑÁî¢ÂìÅÂ±¨ÊÄßËêÉÂèñ„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÊâÄÊúâÊåáÊ®ôÂíåË©ï‰º∞Â±¨ÊÄß‰∏äÈÉΩÂÑ™ÊñºÊàëÂÄëÁöÑÂü∫Ê∫ñÔºåË≠âÊòé‰∫ÜÂÖ∂ÊúâÊïàÊÄßÂíåÂª£ÈóäÁöÑ‰ΩøÁî®ÊΩõÂäõ„ÄÇ

##### **CRAT: A Multi-Agent Framework for Causality-Enhanced Reflective and Retrieval-Augmented Translation with Large Language Models**
2410.21067v1 by Meiqi Chen, Fandong Meng, Yingxue Zhang, Yan Zhang, Jie Zhou

Large language models (LLMs) have shown great promise in machine translation,
but they still struggle with contextually dependent terms, such as new or
domain-specific words. This leads to inconsistencies and errors that are
difficult to address. Existing solutions often depend on manual identification
of such terms, which is impractical given the complexity and evolving nature of
language. While Retrieval-Augmented Generation (RAG) could provide some
assistance, its application to translation is limited by issues such as
hallucinations from information overload. In this paper, we propose CRAT, a
novel multi-agent translation framework that leverages RAG and
causality-enhanced self-reflection to address these challenges. This framework
consists of several specialized agents: the Unknown Terms Identification agent
detects unknown terms within the context, the Knowledge Graph (KG) Constructor
agent extracts relevant internal knowledge about these terms and retrieves
bilingual information from external sources, the Causality-enhanced Judge agent
validates the accuracy of the information, and the Translator agent
incorporates the refined information into the final output. This automated
process allows for more precise and consistent handling of key terms during
translation. Our results show that CRAT significantly improves translation
accuracy, particularly in handling context-sensitive terms and emerging
vocabulary.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂú®Ê©üÂô®ÁøªË≠ØÊñπÈù¢Â±ïÁèæÂá∫Ê•µÂ§ßÁöÑÂâçÊôØÔºå
‰ΩÜÂÆÉÂÄë‰ªçÁÑ∂Èõ£‰ª•ÊáâÂ∞ç‰æùË≥¥ÊñºË™ûÂ¢ÉÁöÑË©ûÂΩôÔºå‰æãÂ¶ÇÊñ∞Ë©ûÊàñÁâπÂÆöÈ†òÂüüÁöÑË©ûÂΩô„ÄÇÈÄôÊúÉÂ∞éËá¥‰∏ç‰∏ÄËá¥ÂíåÈåØË™§ÔºåËÄåÈÄô‰∫õÈåØË™§ÂæàÈõ£Ëß£Ê±∫„ÄÇÁèæÊúâÁöÑËß£Ê±∫ÊñπÊ°àÈÄöÂ∏∏‰æùË≥¥ÊñºÊâãÂãïË≠òÂà•Ê≠§È°ûË©ûÂΩôÔºå‰ΩÜÁî±ÊñºË™ûË®ÄÁöÑË§áÈõúÊÄßÂíå‰∏çÊñ∑ÊºîËÆäÁöÑÁâπÊÄßÔºåÈÄô‰∏¶‰∏çÂèØË°å„ÄÇÈõñÁÑ∂Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÔºàRAGÔºâÂèØ‰ª•Êèê‰æõ‰∏Ä‰∫õÂçîÂä©Ôºå‰ΩÜÂÖ∂Âú®ÁøªË≠Ø‰∏≠ÁöÑÊáâÁî®ÂèóÂà∞Ë´∏Â¶ÇË≥áË®äË∂ÖËºâÁî¢ÁîüÁöÑÂπªË¶∫Á≠âÂïèÈ°åÁöÑÈôêÂà∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ CRATÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÂ§ö‰ª£ÁêÜÁøªË≠ØÊû∂ÊßãÔºåÂÆÉÂà©Áî® RAG ÂíåÂõ†ÊûúÂ¢ûÂº∑Ëá™ÁúÅ‰æÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞„ÄÇÊ≠§Êû∂ÊßãÂåÖÂê´ÂπæÂÄãÂ∞àÈñÄÁöÑ‰ª£ÁêÜÔºöÊú™Áü•Ë©ûÂΩôË≠òÂà•‰ª£ÁêÜÊúÉÂÅµÊ∏¨Ë™ûÂ¢É‰∏≠ÁöÑÊú™Áü•Ë©ûÂΩôÔºåÁü•Ë≠òÂúñË≠úÔºàKGÔºâÂª∫Êßã‰ª£ÁêÜÊúÉÊì∑ÂèñÈÄô‰∫õË©ûÂΩôÁõ∏ÈóúÁöÑÂÖßÈÉ®Áü•Ë≠òÔºå‰∏¶ÂæûÂ§ñÈÉ®‰æÜÊ∫ê‰∏≠Ê™¢Á¥¢ÈõôË™ûË≥áË®äÔºåÂõ†ÊûúÂ¢ûÂº∑Âà§Êñ∑‰ª£ÁêÜÊúÉÈ©óË≠âË≥áË®äÁöÑÊ∫ñÁ¢∫ÊÄßÔºåËÄåÁøªË≠Ø‰ª£ÁêÜÊúÉÂ∞áÁ≤æÁÖâÈÅéÁöÑË≥áË®äÁ¥çÂÖ•ÊúÄÁµÇËº∏Âá∫„ÄÇÈÄôÂÄãËá™ÂãïÂåñÁöÑÊµÅÁ®ãÂÖÅË®±Âú®ÁøªË≠ØÈÅéÁ®ã‰∏≠Êõ¥Á≤æÁ¢∫‰∏î‰∏ÄËá¥Âú∞ËôïÁêÜÈóúÈçµË©ûÂΩô„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåCRAT Â§ßÂπÖÊèêÂçá‰∫ÜÁøªË≠ØÊ∫ñÁ¢∫ÊÄßÔºåÁâπÂà•ÊòØÂú®ËôïÁêÜÂ∞çË™ûÂ¢ÉÊïèÊÑüÁöÑË©ûÂΩôÂíåÊñ∞ËààË©ûÂΩôÊñπÈù¢„ÄÇ

##### **CTINEXUS: Leveraging Optimized LLM In-Context Learning for Constructing Cybersecurity Knowledge Graphs Under Data Scarcity**
2410.21060v1 by Yutong Cheng, Osama Bajaber, Saimon Amanuel Tsegai, Dawn Song, Peng Gao

Textual descriptions in cyber threat intelligence (CTI) reports, such as
security articles and news, are rich sources of knowledge about cyber threats,
crucial for organizations to stay informed about the rapidly evolving threat
landscape. However, current CTI extraction methods lack flexibility and
generalizability, often resulting in inaccurate and incomplete knowledge
extraction. Syntax parsing relies on fixed rules and dictionaries, while model
fine-tuning requires large annotated datasets, making both paradigms
challenging to adapt to new threats and ontologies. To bridge the gap, we
propose CTINexus, a novel framework leveraging optimized in-context learning
(ICL) of large language models (LLMs) for data-efficient CTI knowledge
extraction and high-quality cybersecurity knowledge graph (CSKG) construction.
Unlike existing methods, CTINexus requires neither extensive data nor parameter
tuning and can adapt to various ontologies with minimal annotated examples.
This is achieved through (1) a carefully designed automatic prompt construction
strategy with optimal demonstration retrieval for extracting a wide range of
cybersecurity entities and relations; (2) a hierarchical entity alignment
technique that canonicalizes the extracted knowledge and removes redundancy;
(3) an ICL-enhanced long-distance relation prediction technique to further
complete the CKSG with missing links. Our extensive evaluations using 150
real-world CTI reports collected from 10 platforms demonstrate that CTINexus
significantly outperforms existing methods in constructing accurate and
complete CSKGs, highlighting its potential to transform CTI analysis with an
efficient and adaptable solution for the dynamic threat landscape.

ÊëòË¶ÅÔºöÁ∂≤Ë∑ØÂ®ÅËÑÖÊÉÖÂ†± (CTI) Â†±Âëä‰∏≠ÁöÑÊñáÂ≠óÊèèËø∞Ôºå‰æãÂ¶ÇÂÆâÂÖ®ÊñáÁ´†ÂíåÊñ∞ËÅûÔºåÊòØÁ∂≤Ë∑ØÂ®ÅËÑÖÁöÑË±êÂØåÁü•Ë≠ò‰æÜÊ∫êÔºåÂ∞çÊñºÁµÑÁπîËÄåË®ÄËá≥ÈóúÈáçË¶ÅÔºåÂèØ‰ª•Èö®ÊôÇ‰∫ÜËß£Âø´ÈÄüÊºîËÆäÁöÑÂ®ÅËÑÖÁí∞Â¢É„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑ CTI ÊèêÂèñÊñπÊ≥ïÁº∫‰πèÈùàÊ¥ªÊÄß‰∏îÈõ£‰ª•Ê¶ÇÊã¨ÔºåÈÄöÂ∏∏ÊúÉÂ∞éËá¥Áü•Ë≠òÊèêÂèñ‰∏çÊ∫ñÁ¢∫‰∏î‰∏çÂÆåÊï¥„ÄÇË™ûÊ≥ïËß£Êûê‰æùË≥¥ÊñºÂõ∫ÂÆöË¶èÂâáÂíåÂ≠óÂÖ∏ÔºåËÄåÊ®°ÂûãÂæÆË™øÈúÄË¶ÅÂ§ßÈáèÊ®ôË®ªÁöÑË≥áÊñôÈõÜÔºåÈÄô‰ΩøÂæóÈÄôÂÖ©Á®ÆÁØÑ‰æãÈÉΩÈõ£‰ª•ÈÅ©ÊáâÊñ∞ÁöÑÂ®ÅËÑÖÂíåÊú¨‰Ωì„ÄÇÁÇ∫‰∫ÜÂΩåË£úÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∫Ü CTINexusÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ°ÜÊû∂ÔºåÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄ‰Ω≥ÂåñÊÉÖÂ¢ÉÂ≠∏Áøí (ICL) ‰æÜÈÄ≤Ë°åË≥áÊñôÊúâÊïàÁéáÁöÑ CTI Áü•Ë≠òÊèêÂèñÂíåÈ´òÂìÅË≥™ÁöÑÁ∂≤Ë∑ØÂÆâÂÖ®Áü•Ë≠òÂúñ (CSKG) Âª∫Êßã„ÄÇËàáÁèæÊúâÊñπÊ≥ï‰∏çÂêåÔºåCTINexus ‰∏çÈúÄË¶ÅÂª£Ê≥õÁöÑË≥áÊñôÊàñÂèÉÊï∏Ë™øÊï¥Ôºå‰∏¶‰∏îÂèØ‰ª•ÈÄèÈÅéÊúÄÂ∞ëÁöÑÊ®ôË®ªÁØÑ‰æãÈÅ©ÊáâÂêÑÁ®ÆÊú¨‰Ωì„ÄÇÈÄôÊòØÈÄèÈÅé (1) Á∂ìÈÅéÁ≤æÂøÉË®≠Ë®àÁöÑËá™ÂãïÊèêÁ§∫Âª∫ÊßãÁ≠ñÁï•Ôºå‰∏¶ÈÄèÈÅéÊúÄ‰Ω≥Á§∫ÁØÑÊ™¢Á¥¢‰æÜÊèêÂèñÂª£Ê≥õÁöÑÁ∂≤Ë∑ØÂÆâÂÖ®ÂØ¶È´îÂíåÈóú‰øÇ‰æÜÂØ¶ÁèæÁöÑÔºõ(2) ‰∏ÄÁ®ÆÈöéÂ±§ÂºèÂØ¶È´îÊØîÂ∞çÊäÄË°ìÔºåÂèØ‰ª•Â∞áÊèêÂèñÁöÑÁü•Ë≠òÊ®ôÊ∫ñÂåñ‰∏¶Ê∂àÈô§ÂÜóÈ§òÔºõ(3) ‰∏ÄÁ®Æ ICL Â¢ûÂº∑ÁöÑÈï∑Ë∑ùÈõ¢Èóú‰øÇÈ†êÊ∏¨ÊäÄË°ìÔºåÂèØ‰ª•ÈÄ≤‰∏ÄÊ≠•ÂÆåÊàêÂÖ∑ÊúâÈÅ∫Â§±ÈÄ£ÁµêÁöÑ CKSG„ÄÇÊàëÂÄë‰ΩøÁî®Âæû 10 ÂÄãÂπ≥Âè∞Êî∂ÈõÜÁöÑ 150 ‰ªΩÁúüÂØ¶‰∏ñÁïå CTI Â†±ÂëäÈÄ≤Ë°åÂª£Ê≥õË©ï‰º∞ÔºåË≠âÊòé CTINexus Âú®Âª∫ÊßãÊ∫ñÁ¢∫‰∏îÂÆåÊï¥ÁöÑ CSKG ÊñπÈù¢ÊòéÈ°ØÂÑ™ÊñºÁèæÊúâÊñπÊ≥ïÔºåÁ™ÅÈ°Ø‰∫ÜÂÖ∂‰ª•ÊúâÊïà‰∏îÈÅ©ÊáâÊÄßÂº∑ÁöÑËß£Ê±∫ÊñπÊ°àËΩâÊèõ CTI ÂàÜÊûêÁöÑÊΩõÂäõÔºå‰ª•ÊáâÂ∞çÂãïÊÖãÁöÑÂ®ÅËÑÖÁí∞Â¢É„ÄÇ

##### **Graph-based Uncertainty Metrics for Long-form Language Model Outputs**
2410.20783v1 by Mingjian Jiang, Yangjun Ruan, Prasanna Sattigeri, Salim Roukos, Tatsunori Hashimoto

Recent advancements in Large Language Models (LLMs) have significantly
improved text generation capabilities, but these systems are still known to
hallucinate, and granular uncertainty estimation for long-form LLM generations
remains challenging. In this work, we propose Graph Uncertainty -- which
represents the relationship between LLM generations and claims within them as a
bipartite graph and estimates the claim-level uncertainty with a family of
graph centrality metrics. Under this view, existing uncertainty estimation
methods based on the concept of self-consistency can be viewed as using degree
centrality as an uncertainty measure, and we show that more sophisticated
alternatives such as closeness centrality provide consistent gains at
claim-level uncertainty estimation. Moreover, we present uncertainty-aware
decoding techniques that leverage both the graph structure and uncertainty
estimates to improve the factuality of LLM generations by preserving only the
most reliable claims. Compared to existing methods, our graph-based uncertainty
metrics lead to an average of 6.8% relative gains on AUPRC across various
long-form generation settings, and our end-to-end system provides consistent
2-4% gains in factuality over existing decoding techniques while significantly
improving the informativeness of generated responses.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÈ°ØËëóÊèêÂçá‰∫ÜÊñáÂ≠óÁîüÊàêËÉΩÂäõÔºå‰ΩÜÈÄô‰∫õÁ≥ªÁµ±‰ªç‰ª•Áî¢ÁîüÂπªË¶∫ËëóÁ®±ÔºåËÄåÈáùÂ∞çÈï∑ÁØá LLM ÁîüÊàêÁöÑÁ¥∞Á∑ª‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®à‰ªçÊòØ‰∏ÄÈ†ÖÊåëÊà∞„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ÂúñÂΩ¢‰∏çÁ¢∫ÂÆöÊÄßÔºåÂÆÉÂ∞á LLM ÁîüÊàêÂíåÂÖ∂‰∏≠ÁöÑ‰∏ªÂºµË°®Á§∫ÁÇ∫‰∫åÈÉ®ÂúñÔºå‰∏¶‰ΩøÁî®‰∏ÄÁ≥ªÂàóÂúñÂΩ¢‰∏≠ÂøÉÊÄßÊåáÊ®ô‰º∞Ë®à‰∏ªÂºµÂ±§Á¥öÁöÑ‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÂú®Ê≠§ËßÄÈªû‰∏ãÔºåÁèæÊúâÁöÑÂü∫ÊñºËá™Ê¥ΩÊÄßÊ¶ÇÂøµÁöÑ‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÊñπÊ≥ïÂèØË¶ñÁÇ∫‰ΩøÁî®Â∫¶Èáè‰∏≠ÂøÉÊÄß‰ΩúÁÇ∫‰∏çÁ¢∫ÂÆöÊÄßÊåáÊ®ôÔºåÊàëÂÄëË≠âÊòé‰∫ÜÊõ¥Á≤æÂØÜÁöÑÊõø‰ª£ÊñπÊ°àÔºà‰æãÂ¶ÇÊé•Ëøë‰∏≠ÂøÉÊÄßÔºâÂú®‰∏ªÂºµÂ±§Á¥ö‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®à‰∏≠Êèê‰æõ‰∫ÜÁ©©ÂÆöÁöÑÂ¢ûÁõä„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏çÁ¢∫ÂÆöÊÄßÊÑüÁü•Ëß£Á¢ºÊäÄË°ìÔºåË©≤ÊäÄË°ìÂà©Áî®ÂúñÂΩ¢ÁµêÊßãÂíå‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®à‰æÜÊèêÂçá LLM ÁîüÊàêÁöÑÁúüÂØ¶ÊÄßÔºåÊñπÊ≥ïÊòØÂÉÖ‰øùÁïôÊúÄÂèØÈù†ÁöÑ‰∏ªÂºµ„ÄÇËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÂü∫ÊñºÂúñÂΩ¢ÁöÑÊåáÊ®ôÂú®ÂêÑÁ®ÆÈï∑ÁØáÁîüÊàêË®≠ÂÆö‰∏≠Âπ≥ÂùáÊèêÂçá‰∫Ü AUPRC ÁöÑ 6.8%ÔºåËÄåÊàëÂÄëÁöÑÁ´ØÂà∞Á´ØÁ≥ªÁµ±Âú®ÁúüÂØ¶ÊÄßÊñπÈù¢Êèê‰æõ‰∫Ü 2-4% ÁöÑÁ©©ÂÆöÂ¢ûÁõäÔºåÂêåÊôÇÈ°ØËëóÊèêÂçá‰∫ÜÁîüÊàêÂõûÊáâÁöÑË≥áË®äÊÄß„ÄÇ

##### **Plan$\times$RAG: Planning-guided Retrieval Augmented Generation**
2410.20753v1 by Prakhar Verma, Sukruta Prakash Midigeshi, Gaurav Sinha, Arno Solin, Nagarajan Natarajan, Amit Sharma

We introduce Planning-guided Retrieval Augmented Generation
(Plan$\times$RAG), a novel framework that augments the
\emph{retrieve-then-reason} paradigm of existing RAG frameworks to
\emph{plan-then-retrieve}. Plan$\times$RAG formulates a reasoning plan as a
directed acyclic graph (DAG), decomposing queries into interrelated atomic
sub-queries. Answer generation follows the DAG structure, allowing significant
gains in efficiency through parallelized retrieval and generation. While
state-of-the-art RAG solutions require extensive data generation and
fine-tuning of language models (LMs), Plan$\times$RAG incorporates frozen LMs
as plug-and-play experts to generate high-quality answers. Compared to existing
RAG solutions, Plan$\times$RAG demonstrates significant improvements in
reducing hallucinations and bolstering attribution due to its structured
sub-query decomposition. Overall, Plan$\times$RAG offers a new perspective on
integrating external knowledge in LMs while ensuring attribution by design,
contributing towards more reliable LM-based systems.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÂºïÂÖ•‰∫ÜË¶èÂäÉÂºïÂ∞éÁöÑÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (Plan$\times$RAG)ÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ°ÜÊû∂ÔºåÂÆÉÊì¥ÂÖÖ‰∫ÜÁèæÊúâ RAG Ê°ÜÊû∂ÁöÑ„ÄåÂÖàÊ™¢Á¥¢ÂæåÊé®ÁêÜ„ÄçÁØÑ‰æãÔºåÊîπÁÇ∫„ÄåÂÖàË¶èÂäÉÂæåÊ™¢Á¥¢„Äç„ÄÇPlan$\times$RAG Â∞áÊé®ÁêÜË®àÁï´Âà∂ÂÆöÁÇ∫ÊúâÂêëÁÑ°Áí∞Âúñ (DAG)ÔºåÂ∞áÊü•Ë©¢ÂàÜËß£ÊàêÁõ∏‰∫íÈóúËÅØÁöÑÂéüÂ≠êÂ≠êÊü•Ë©¢„ÄÇÁ≠îÊ°àÁîüÊàêÈÅµÂæ™ DAG ÁµêÊßãÔºåÈÄèÈÅé‰∏¶Ë°åÊ™¢Á¥¢ÂíåÁîüÊàêÔºåÂ§ßÂπÖÊèêÂçáÊïàÁéá„ÄÇÈõñÁÑ∂ÊúÄÂÖàÈÄ≤ÁöÑ RAG Ëß£ÂÜ≥ÊñπÊ°àÈúÄË¶ÅÂ§ßÈáèË≥áÊñôÁîüÊàêÂíåË™ûË®ÄÊ®°Âûã (LM) ÁöÑÂæÆË™øÔºå‰ΩÜ Plan$\times$RAG Â∞áÂáçÁµêÁöÑ LM Êï¥ÂêàÁÇ∫Âç≥ÊèíÂç≥Áî®ÁöÑÂ∞àÂÆ∂Ôºå‰ª•ÁîüÊàêÈ´òÂìÅË≥™ÁöÑÁ≠îÊ°à„ÄÇËàáÁèæÊúâÁöÑ RAG Ëß£ÂÜ≥ÊñπÊ°àÁõ∏ÊØîÔºåPlan$\times$RAG Âú®Ê∏õÂ∞ëÂπªË¶∫ÂíåÂä†Âº∑Ê≠∏Âõ†ÊñπÈù¢Ë°®ÁèæÂá∫È°ØËëóÁöÑÈÄ≤Ê≠•ÔºåÈÄôË¶ÅÊ≠∏ÂäüÊñºÂÖ∂ÁµêÊßãÂåñÁöÑÂ≠êÊü•Ë©¢ÂàÜËß£„ÄÇÁ∏ΩÈ´îËÄåË®ÄÔºåPlan$\times$RAG Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑËßÄÈªûÔºå‰ª•Êï¥Âêà LM ‰∏≠ÁöÑÂ§ñÈÉ®Áü•Ë≠òÔºåÂêåÊôÇÁ¢∫‰øùÊ≠∏Âõ†Ë®≠Ë®àÔºåÊúâÂä©ÊñºÂª∫Á´ãÊõ¥ÂèØÈù†ÁöÑÂü∫Êñº LM ÁöÑÁ≥ªÁµ±„ÄÇ</paragraph>

##### **Simple is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation**
2410.20724v2 by Mufei Li, Siqi Miao, Pan Li

Large Language Models (LLMs) demonstrate strong reasoning abilities but face
limitations such as hallucinations and outdated knowledge. Knowledge Graph
(KG)-based Retrieval-Augmented Generation (RAG) addresses these issues by
grounding LLM outputs in structured external knowledge from KGs. However,
current KG-based RAG frameworks still struggle to optimize the trade-off
between retrieval effectiveness and efficiency in identifying a suitable amount
of relevant graph information for the LLM to digest. We introduce SubgraphRAG,
extending the KG-based RAG framework that retrieves subgraphs and leverages
LLMs for reasoning and answer prediction. Our approach innovatively integrates
a lightweight multilayer perceptron with a parallel triple-scoring mechanism
for efficient and flexible subgraph retrieval while encoding directional
structural distances to enhance retrieval effectiveness. The size of retrieved
subgraphs can be flexibly adjusted to match the query's need and the downstream
LLM's capabilities. This design strikes a balance between model complexity and
reasoning power, enabling scalable and generalizable retrieval processes.
Notably, based on our retrieved subgraphs, smaller LLMs like
Llama3.1-8B-Instruct deliver competitive results with explainable reasoning,
while larger models like GPT-4o achieve state-of-the-art accuracy compared with
previous baselines -- all without fine-tuning. Extensive evaluations on the
WebQSP and CWQ benchmarks highlight SubgraphRAG's strengths in efficiency,
accuracy, and reliability by reducing hallucinations and improving response
grounding.

ÊëòË¶ÅÔºö<paragraph>Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂÖ∑ÊúâÂº∑Â§ßÁöÑÊé®ÁêÜËÉΩÂäõÔºå‰ΩÜÈù¢Ëá®ÂπªË¶∫ÂíåÈÅéÊôÇÁü•Ë≠òÁ≠âÈôêÂà∂„ÄÇÂü∫ÊñºÁü•Ë≠òÂúñË≠ú (KG) ÁöÑÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÈÄèÈÅéÂ∞á LLM Ëº∏Âá∫ÁµêÊûúÂ•†Âü∫Êñº KG ‰∏≠ÁöÑÁµêÊßãÂåñÂ§ñÈÉ®Áü•Ë≠òÔºå‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°å„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÂü∫Êñº KG ÁöÑ RAG Êû∂Êßã‰ªçÈõ£‰ª•Âú®Ê™¢Á¥¢ÊïàËÉΩÂíåÊïàÁéá‰πãÈñìÂèñÂæóÊúÄ‰Ω≥Âπ≥Ë°°Ôºå‰ª•ÊâæÂá∫ LLM ËÉΩÂ§†Ê∂àÂåñÁöÑÈÅ©Áï∂Áõ∏ÈóúÂúñË°®Ë≥áË®äÈáè„ÄÇÊàëÂÄëÂºïÈÄ≤ SubgraphRAGÔºåÊì¥ÂÖÖÂü∫Êñº KG ÁöÑ RAG Êû∂ÊßãÔºå‰ª•Ê™¢Á¥¢Â≠êÂúñË°®‰∏¶Âà©Áî® LLM ÈÄ≤Ë°åÊé®ÁêÜÂíåÁ≠îÊ°àÈ†êÊ∏¨„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂâµÊñ∞Âú∞Êï¥Âêà‰∫Ü‰∏ÄÂÄãËºïÈáèÂ§öÂ±§ÊÑüÁü•Âô®Ëàá‰∏ÄÂÄã‰∏¶Ë°å‰∏âÂÖÉÁµÑË®àÂàÜÊ©üÂà∂ÔºåÁî®ÊñºÈ´òÊïà‰∏îÈùàÊ¥ªÂú∞Ê™¢Á¥¢Â≠êÂúñË°®ÔºåÂêåÊôÇÁ∑®Á¢ºÊñπÂêëÁµêÊßãË∑ùÈõ¢‰ª•Â¢ûÂº∑Ê™¢Á¥¢ÊïàËÉΩ„ÄÇÊ™¢Á¥¢Âà∞ÁöÑÂ≠êÂúñË°®Â§ßÂ∞èÂèØ‰ª•ÈùàÊ¥ªË™øÊï¥Ôºå‰ª•Á¨¶ÂêàÊü•Ë©¢ÈúÄÊ±ÇÂíå‰∏ãÊ∏∏ LLM ÁöÑÂäüËÉΩ„ÄÇÈÄôÁ®ÆË®≠Ë®àÂú®Ê®°ÂûãË§áÈõúÂ∫¶ÂíåÊé®ÁêÜËÉΩÂäõ‰πãÈñìÂèñÂæóÂπ≥Ë°°ÔºåÂØ¶ÁèæÂèØÊì¥ÂÖÖ‰∏îÂèØÊ¶ÇÂåñÁöÑÊ™¢Á¥¢Á®ãÂ∫è„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊ†πÊìöÊàëÂÄëÊ™¢Á¥¢Âà∞ÁöÑÂ≠êÂúñË°®ÔºåËºÉÂ∞èÁöÑ LLMÔºà‰æãÂ¶Ç Llama3.1-8B-InstructÔºâÂèØ‰ª•Êèê‰æõÂÖ∑ÂÇôÂèØËß£ÈáãÊé®ÁêÜÁöÑÁ´∂Áà≠ÁµêÊûúÔºåËÄåËºÉÂ§ßÁöÑÊ®°ÂûãÔºà‰æãÂ¶Ç GPT-4oÔºâÂâáÈÅîÂà∞ËàáÂÖàÂâçÂü∫Ê∫ñÁõ∏ÊØîÁöÑÊúÄÊñ∞Ê∫ñÁ¢∫Â∫¶ÔºåËÄå‰∏îÊâÄÊúâÈÄô‰∫õÈÉΩ‰∏çÈúÄË¶ÅÂæÆË™ø„ÄÇÂú® WebQSP Âíå CWQ Âü∫Ê∫ñ‰∏äÁöÑÂª£Ê≥õË©ï‰º∞Á™ÅÈ°Ø‰∫Ü SubgraphRAG Âú®ÊïàÁéá„ÄÅÊ∫ñÁ¢∫Â∫¶ÂíåÂèØÈù†ÊÄßÊñπÈù¢ÁöÑÂÑ™Âã¢ÔºåÈÄèÈÅéÊ∏õÂ∞ëÂπªË¶∫‰∏¶ÊîπÂñÑÂõûÊáâ‰æùÊìö„ÄÇ</paragraph>


### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-18**|**Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**|Jeffrey N. Clark et.al.|[2411.11774v1](http://arxiv.org/abs/2411.11774v1)|null|
|**2024-11-15**|**Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**|Mohammed Yaseen Jabarulla et.al.|[2411.10255v1](http://arxiv.org/abs/2411.10255v1)|null|
|**2024-11-01**|**Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**|Mehdi Hosseini Chagahi et.al.|[2411.00916v2](http://arxiv.org/abs/2411.00916v2)|null|
|**2024-10-25**|**A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**|Muath Alsuhaibani et.al.|[2410.19898v1](http://arxiv.org/abs/2410.19898v1)|null|
|**2024-10-23**|**An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**|Shruthi Chari et.al.|[2410.17504v1](http://arxiv.org/abs/2410.17504v1)|[link](https://github.com/tetherless-world/metaexplainer)|
|**2024-10-22**|**Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**|Lukas Hughes-Noehrer et.al.|[2410.16879v1](http://arxiv.org/abs/2410.16879v1)|null|
|**2024-10-19**|**Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**|Gesa Mittmann et.al.|[2410.15012v1](http://arxiv.org/abs/2410.15012v1)|null|
|**2024-10-15**|**Explainable AI Methods for Multi-Omics Analysis: A Survey**|Ahmad Hussein et.al.|[2410.11910v1](http://arxiv.org/abs/2410.11910v1)|null|
|**2024-10-14**|**Study on the Helpfulness of Explainable Artificial Intelligence**|Tobias Labarta et.al.|[2410.11896v1](http://arxiv.org/abs/2410.11896v1)|[link](https://github.com/tlabarta/helpfulnessofxai)|
|**2024-10-12**|**Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**|Abdullah Mamun et.al.|[2410.09635v1](http://arxiv.org/abs/2410.09635v1)|[link](https://github.com/ab9mamun/aimen)|
|**2024-10-10**|**Artificial intelligence techniques in inherited retinal diseases: A review**|Han Trinh et.al.|[2410.09105v1](http://arxiv.org/abs/2410.09105v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|[link](https://github.com/ixa-ehu/antidote-casimedicos)|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v1](http://arxiv.org/abs/2410.01855v1)|null|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v3](http://arxiv.org/abs/2409.12087v3)|null|
|**2024-09-09**|**Explainable AI: Definition and attributes of a good explanation for health AI**|Evangelia Kyrimi et.al.|[2409.15338v1](http://arxiv.org/abs/2409.15338v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing Œ¥-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v2](http://arxiv.org/abs/2407.15851v2)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-17**|**Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**|Vincent Olesen et.al.|[2406.12142v2](http://arxiv.org/abs/2406.12142v2)|[link](https://github.com/volesen/slicing-through-bias)|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. ZajƒÖc et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel Mir√≥-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|S√©amus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Cause and Effect: Can Large Language Models Truly Understand Causality?**|Swagata Ashwani et.al.|[2402.18139v3](http://arxiv.org/abs/2402.18139v3)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|Timoth√©e Schmude et.al.|[2401.13324v6](http://arxiv.org/abs/2401.13324v6)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-12-04**|**Class-Discriminative Attention Maps for Vision Transformers**|Lennart Brocki et.al.|[2312.02364v3](http://arxiv.org/abs/2312.02364v3)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v3](http://arxiv.org/abs/2311.12573v3)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|
|**2023-11-03**|**Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**|Emma A. M. Stanley et.al.|[2311.02115v2](http://arxiv.org/abs/2311.02115v2)|[link](https://github.com/estanley16/simba)|
|**2023-10-29**|**Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**|Adam White et.al.|[2310.19174v1](http://arxiv.org/abs/2310.19174v1)|null|
|**2023-10-03**|**Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**|Hossein Shreim et.al.|[2310.01828v2](http://arxiv.org/abs/2310.01828v2)|[link](https://github.com/geoaigroup/geoai-ecrs2023)|

#### Abstracts
##### **Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**
2411.11774v1 by Jeffrey N. Clark, Matthew Wragg, Emily Nielsen, Miquel Perello-Nieto, Nawid Keshtmand, Michael Ambler, Shiv Sharma, Christopher P. Bourdeaux, Amberly Brigden, Raul Santos-Rodriguez

There is a growing need to understand how digital systems can support
clinical decision-making, particularly as artificial intelligence (AI) models
become increasingly complex and less human-interpretable. This complexity
raises concerns about trustworthiness, impacting safe and effective adoption of
such technologies. Improved understanding of decision-making processes and
requirements for explanations coming from decision support tools is a vital
component in providing effective explainable solutions. This is particularly
relevant in the data-intensive, fast-paced environments of intensive care units
(ICUs). To explore these issues, group interviews were conducted with seven ICU
clinicians, representing various roles and experience levels. Thematic analysis
revealed three core themes: (T1) ICU decision-making relies on a wide range of
factors, (T2) the complexity of patient state is challenging for shared
decision-making, and (T3) requirements and capabilities of AI decision support
systems. We include design recommendations from clinical input, providing
insights to inform future AI systems for intensive care.

ÊëòË¶ÅÔºöÈö®Ëëó‰∫∫Â∑•Êô∫ÊÖß (AI) Ê®°ÂûãËÆäÂæóË∂ä‰æÜË∂äË§áÈõúÔºå‰∏îË∂ä‰æÜË∂äÈõ£‰ª•Ë¢´‰∫∫ÁêÜËß£Ôºå‰∫ÜËß£Êï∏‰ΩçÁ≥ªÁµ±Â¶Ç‰ΩïÊîØÊè¥Ëá®Â∫äÊ±∫Á≠ñÁöÑÈúÄÊ±Ç‰πüÊó•ÁõäÂ¢ûÂä†„ÄÇÈÄôÁ®ÆË§áÈõúÊÄßÂºïÁôº‰∫ÜÂ∞çÂèØ‰ø°Â∫¶ÁöÑÁñëÊÖÆÔºåÂΩ±Èüø‰∫ÜÊ≠§È°ûÊäÄË°ìÁöÑÂÆâÂÖ®‰∏îÊúâÊïàÊé°Áî®„ÄÇÊîπÂñÑÂ∞çÊ±∫Á≠ñÂà∂ÂÆöÊµÅÁ®ãÁöÑÁêÜËß£Ôºå‰ª•ÂèäÂ∞çÊ±∫Á≠ñÊîØÊè¥Â∑•ÂÖ∑ÊâÄÊèê‰æõË™™ÊòéÁöÑË¶ÅÊ±ÇÔºåÊòØÊèê‰æõÊúâÊïàÂèØËß£ÈáãËß£Ê±∫ÊñπÊ°àÁöÑÈáçË¶ÅÁµÑÊàêÈÉ®ÂàÜ„ÄÇÈÄôÂú®Ë≥áÊñôÂØÜÈõÜ„ÄÅÂø´ÁØÄÂ•èÁöÑÂä†Ë≠∑ÁóÖÊàø (ICU) Áí∞Â¢É‰∏≠ÁâπÂà•Áõ∏Èóú„ÄÇÁÇ∫‰∫ÜÊé¢Ë®éÈÄô‰∫õÂïèÈ°åÔºåÂ∞ç‰∏É‰Ωç ICU Ëá®Â∫äÈÜ´Â∏´ÈÄ≤Ë°å‰∫ÜÂ∞èÁµÑË®™Ë´áÔºåÈÄô‰∫õÈÜ´Â∏´‰ª£Ë°®‰∫Ü‰∏çÂêåÁöÑËßíËâ≤ÂíåÁ∂ìÈ©óÂ±§Á¥ö„ÄÇ‰∏ªÈ°åÂàÜÊûêÊè≠Èú≤‰∫Ü‰∏âÂÄãÊ†∏ÂøÉ‰∏ªÈ°åÔºö(T1) ICU Ê±∫Á≠ñÂà∂ÂÆö‰æùË≥¥ÊñºÂª£Ê≥õÁöÑÂõ†Á¥†Ôºå(T2) ÁóÖÊÇ£ÁãÄÊÖãÁöÑË§áÈõúÊÄßÂ∞çÂÖ±ÂêåÊ±∫Á≠ñÂà∂ÂÆöÊßãÊàêÊåëÊà∞Ôºå‰ª•Âèä (T3) AI Ê±∫Á≠ñÊîØÊè¥Á≥ªÁµ±ÁöÑË¶ÅÊ±ÇÂíåËÉΩÂäõ„ÄÇÊàëÂÄëÁ¥çÂÖ•‰∫ÜËá®Â∫äËº∏ÂÖ•ÁöÑË®≠Ë®àÂª∫Ë≠∞ÔºåÊèê‰æõË¶ãËß£‰ª•Êèê‰æõË≥áË®äÁµ¶Êú™‰æÜÁî®ÊñºÂä†Ë≠∑ÁöÑ AI Á≥ªÁµ±„ÄÇ

##### **Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**
2411.10255v1 by Mohammed Yaseen Jabarulla, Theodor Uden, Thomas Jack, Philipp Beerbaum, Steffen Oeltze-Jafra

Pediatric heart diseases present a broad spectrum of congenital and acquired
diseases. More complex congenital malformations require a differentiated and
multimodal decision-making process, usually including echocardiography as a
central imaging method. Artificial intelligence (AI) offers considerable
promise for clinicians by facilitating automated interpretation of pediatric
echocardiography data. However, adapting AI technologies for pediatric
echocardiography analysis has challenges such as limited public data
availability, data privacy, and AI model transparency. Recently, researchers
have focused on disruptive technologies, such as federated learning (FL) and
explainable AI (XAI), to improve automatic diagnostic and decision support
workflows. This study offers a comprehensive overview of the limitations and
opportunities of AI in pediatric echocardiography, emphasizing the synergistic
workflow and role of XAI and FL, identifying research gaps, and exploring
potential future developments. Additionally, three relevant clinical use cases
demonstrate the functionality of XAI and FL with a focus on (i) view
recognition, (ii) disease classification, (iii) segmentation of cardiac
structures, and (iv) quantitative assessment of cardiac function.

ÊëòË¶ÅÔºöÂ∞èÂÖíÂøÉËáüÁñæÁóÖÂëàÁèæÂÖàÂ§©ÊÄßËàáÂæåÂ§©ÊÄßÁñæÁóÖÁöÑÂª£Ê≥õÂÖâË≠ú„ÄÇËºÉË§áÈõúÁöÑÂÖàÂ§©ÊÄßÁï∏ÂΩ¢ÈúÄË¶Å‰∏ÄÂÄãÂ∑ÆÁï∞Âåñ‰∏îÂ§öÊ®°ÂºèÁöÑÊ±∫Á≠ñÈÅéÁ®ãÔºåÈÄöÂ∏∏ÂåÖÊã¨Ë∂ÖÈü≥Ê≥¢Ê™¢Êü•‰ΩúÁÇ∫‰∏ªË¶ÅÁöÑÂΩ±ÂÉèÊñπÊ≥ï„ÄÇ‰∫∫Â∑•Êô∫ÊÖß (AI) ÁÇ∫Ëá®Â∫äÈÜ´ÁîüÊèê‰æõ‰∫ÜÁõ∏Áï∂Â§ßÁöÑÂ∏åÊúõÔºåÂõ†ÁÇ∫ÂÆÉÂèØ‰ª•‰øÉÈÄ≤Â∞èÂÖíË∂ÖÈü≥Ê≥¢Ê™¢Êü•Ë≥áÊñôÁöÑËá™ÂãïÂåñËß£ËÆÄ„ÄÇÁÑ∂ËÄåÔºåÂ∞á‰∫∫Â∑•Êô∫ÊÖßÊäÄË°ìÊáâÁî®ÊñºÂ∞èÂÖíË∂ÖÈü≥Ê≥¢Ê™¢Êü•ÂàÜÊûêÊúâË®±Â§öÊåëÊà∞Ôºå‰æãÂ¶ÇÊúâÈôêÁöÑÂÖ¨ÈñãË≥áÊñôÂèØÁî®ÊÄß„ÄÅË≥áÊñôÈö±ÁßÅÂíå‰∫∫Â∑•Êô∫ÊÖßÊ®°ÂûãÈÄèÊòéÂ∫¶„ÄÇÊúÄËøëÔºåÁ†îÁ©∂‰∫∫Âì°Â∞àÊ≥®ÊñºÁ†¥Â£ûÊÄßÊäÄË°ìÔºå‰æãÂ¶ÇËÅØÂêàÂ≠∏Áøí (FL) ÂíåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI)Ôºå‰ª•ÊîπÂñÑËá™ÂãïË®∫Êñ∑ÂíåÊ±∫Á≠ñÊîØÊè¥Â∑•‰ΩúÊµÅÁ®ã„ÄÇÊú¨Á†îÁ©∂Êèê‰æõ‰∫Ü‰∫∫Â∑•Êô∫ÊÖßÂú®Â∞èÂÖíË∂ÖÈü≥Ê≥¢Ê™¢Êü•‰∏≠ÁöÑÈôêÂà∂ÂíåÊ©üÊúÉÁöÑÂÖ®Èù¢Ê¶ÇËø∞ÔºåÂº∑Ë™ø‰∫Ü XAI Âíå FL ÁöÑÂçîÂêåÂ∑•‰ΩúÊµÅÁ®ãÂíåËßíËâ≤ÔºåÊâæÂá∫Á†îÁ©∂Â∑ÆË∑ù‰∏¶Êé¢Ë®éÊΩõÂú®ÁöÑÊú™‰æÜÁôºÂ±ï„ÄÇÊ≠§Â§ñÔºå‰∏âÂÄãÁõ∏ÈóúÁöÑËá®Â∫ä‰ΩøÁî®Ê°à‰æãÂ±ïÁ§∫‰∫Ü XAI Âíå FL ÁöÑÂäüËÉΩÔºåÈáçÈªûÂú®Êñº (i) Ê™¢Ë¶ñËæ®Ë≠ò„ÄÅ(ii) ÁñæÁóÖÂàÜÈ°û„ÄÅ(iii) ÂøÉËáüÁµêÊßãÂàÜÂâ≤Âíå (iv) ÂøÉËáüÂäüËÉΩÁöÑÈáèÂåñË©ï‰º∞„ÄÇ

##### **Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**
2411.00916v2 by Mehdi Hosseini Chagahi, Saeed Mohammadi Dashtaki, Niloufar Delfan, Nadia Mohammadi, Alireza Samari, Behzad Moshiri, Md. Jalil Piran, Oliver Faust

Osteoporosis is a common condition that increases fracture risk, especially
in older adults. Early diagnosis is vital for preventing fractures, reducing
treatment costs, and preserving mobility. However, healthcare providers face
challenges like limited labeled data and difficulties in processing medical
images. This study presents a novel multi-modal learning framework that
integrates clinical and imaging data to improve diagnostic accuracy and model
interpretability. The model utilizes three pre-trained networks-VGG19,
InceptionV3, and ResNet50-to extract deep features from X-ray images. These
features are transformed using PCA to reduce dimensionality and focus on the
most relevant components. A clustering-based selection process identifies the
most representative components, which are then combined with preprocessed
clinical data and processed through a fully connected network (FCN) for final
classification. A feature importance plot highlights key variables, showing
that Medical History, BMI, and Height were the main contributors, emphasizing
the significance of patient-specific data. While imaging features were
valuable, they had lower importance, indicating that clinical data are crucial
for accurate predictions. This framework promotes precise and interpretable
predictions, enhancing transparency and building trust in AI-driven diagnoses
for clinical integration.

ÊëòË¶ÅÔºöÈ™®Ë≥™ÁñèÈ¨ÜÁóáÊòØ‰∏ÄÁ®ÆÂ∏∏Ë¶ãÁöÑÁñæÁóÖÔºåÊúÉÂ¢ûÂä†È™®ÊäòÁöÑÈ¢®Èö™ÔºåÁâπÂà•ÊòØËÄÅÂπ¥‰∫∫„ÄÇÊó©ÊúüË®∫Êñ∑Â∞çÊñºÈ†êÈò≤È™®Êäò„ÄÅÈôç‰ΩéÊ≤ªÁôÇÊàêÊú¨ÂíåÁ∂≠ÊåÅË°åÂãïËÉΩÂäõËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÈÜ´ÁôÇ‰øùÂÅ•Êèê‰æõËÄÖÈù¢Ëá®ËëóÊ®ôË®òÊï∏ÊìöÊúâÈôêÂíåËôïÁêÜÈÜ´Â≠∏ÂΩ±ÂÉèÂõ∞Èõ£Á≠âÊåëÊà∞„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÂ§öÊ®°ÂºèÂ≠∏ÁøíÊ°ÜÊû∂ÔºåË©≤Ê°ÜÊû∂Êï¥Âêà‰∫ÜËá®Â∫äÂíåÂΩ±ÂÉèÊï∏ÊìöÔºå‰ª•ÊèêÈ´òË®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÂíåÊ®°ÂûãÂèØËß£ÈáãÊÄß„ÄÇË©≤Ê®°ÂûãÂà©Áî®‰∏âÂÄãÈ†êË®ìÁ∑¥ÁöÑÁ∂≤Ë∑ØÔºåVGG19„ÄÅInceptionV3 Âíå ResNet50ÔºåÂæû X Â∞ÑÁ∑öÂΩ±ÂÉè‰∏≠ÊèêÂèñÊ∑±Â∫¶ÁâπÂæµ„ÄÇÈÄô‰∫õÁâπÂæµ‰ΩøÁî® PCA ËΩâÊèõ‰ª•Èôç‰ΩéÁ∂≠Â∫¶‰∏¶Â∞àÊ≥®ÊñºÊúÄÁõ∏ÈóúÁöÑÁµÑÊàêÈÉ®ÂàÜ„ÄÇÂü∫ÊñºËÅöÈ°ûÁöÑÈÅ∏ÊìáÈÅéÁ®ãË≠òÂà•Âá∫ÊúÄÂÖ∑‰ª£Ë°®ÊÄßÁöÑÁµÑÊàêÈÉ®ÂàÜÔºåÁÑ∂ÂæåÂ∞áÈÄô‰∫õÁµÑÊàêÈÉ®ÂàÜËàáÈ†êËôïÁêÜÁöÑËá®Â∫äÊï∏ÊìöÁµêÂêàÔºå‰∏¶ÈÄöÈÅéÂÖ®ÈÄ£Êé•Á∂≤Ë∑Ø (FCN) ÈÄ≤Ë°åÊúÄÁµÇÂàÜÈ°û„ÄÇÁâπÂæµÈáçË¶ÅÊÄßÂúñÁ™ÅÂá∫‰∫ÜÈóúÈçµËÆäÊï∏ÔºåË°®ÊòéÁóÖÂè≤„ÄÅBMI ÂíåË∫´È´òÊòØ‰∏ªË¶ÅË≤¢ÁçªÂõ†Á¥†ÔºåÂº∑Ë™ø‰∫ÜÊÇ£ËÄÖÁâπÂÆöÊï∏ÊìöÁöÑÈáçË¶ÅÊÄß„ÄÇÈõñÁÑ∂ÂΩ±ÂÉèÁâπÂæµÂæàÊúâÂÉπÂÄºÔºå‰ΩÜÂÆÉÂÄëÁöÑÈáçË¶ÅÊÄßËºÉ‰ΩéÔºåÈÄôË°®ÊòéËá®Â∫äÊï∏ÊìöÂ∞çÊñºÊ∫ñÁ¢∫È†êÊ∏¨Ëá≥ÈóúÈáçË¶Å„ÄÇÊ≠§Ê°ÜÊû∂‰øÉËøõ‰∫ÜÊ∫ñÁ¢∫‰∏îÂèØËß£ÈáãÁöÑÈ†êÊ∏¨ÔºåÊèêÈ´ò‰∫ÜÈÄèÊòéÂ∫¶Ôºå‰∏¶Âª∫Á´ã‰∫ÜÂ∞ç AI È©ÖÂãïË®∫Êñ∑Âú®Ëá®Â∫äÊï¥Âêà‰∏≠ÁöÑ‰ø°‰ªª„ÄÇ

##### **A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**
2410.19898v1 by Muath Alsuhaibani, Ali Pourramezan Fard, Jian Sun, Farida Far Poor, Peter S. Pressman, Mohammad H. Mahoor

This review paper explores recent advances in deep learning approaches for
non-invasive cognitive impairment detection. We examine various non-invasive
indicators of cognitive decline, including speech and language, facial, and
motoric mobility. The paper provides an overview of relevant datasets,
feature-extracting techniques, and deep-learning architectures applied to this
domain. We have analyzed the performance of different methods across modalities
and observed that speech and language-based methods generally achieved the
highest detection performance. Studies combining acoustic and linguistic
features tended to outperform those using a single modality. Facial analysis
methods showed promise for visual modalities but were less extensively studied.
Most papers focused on binary classification (impaired vs. non-impaired), with
fewer addressing multi-class or regression tasks. Transfer learning and
pre-trained language models emerged as popular and effective techniques,
especially for linguistic analysis. Despite significant progress, several
challenges remain, including data standardization and accessibility, model
explainability, longitudinal analysis limitations, and clinical adaptation.
Lastly, we propose future research directions, such as investigating
language-agnostic speech analysis methods, developing multi-modal diagnostic
systems, and addressing ethical considerations in AI-assisted healthcare. By
synthesizing current trends and identifying key obstacles, this review aims to
guide further development of deep learning-based cognitive impairment detection
systems to improve early diagnosis and ultimately patient outcomes.

ÊëòË¶ÅÔºöÊú¨ÁØáË©ïË´ñÊé¢Ë®é‰∫ÜÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÂú®Èùû‰æµÂÖ•ÂºèË™çÁü•ÂäüËÉΩÈöúÁ§ôÊ™¢Ê∏¨‰∏äÁöÑÊúÄÊñ∞ÈÄ≤Â±ï„ÄÇÊàëÂÄëÊ™¢Ë¶ñ‰∫ÜÂêÑÁ®ÆÈùû‰æµÂÖ•ÂºèÁöÑË™çÁü•Ë°∞ÈÄÄÊåáÊ®ôÔºåÂåÖÊã¨Ë™ûË®ÄÂíåË™ûË®Ä„ÄÅÈù¢ÈÉ®ÂíåÈÅãÂãïÊ©üËÉΩ„ÄÇÊú¨ÊñáÊ¶ÇËø∞‰∫ÜËàáÊ≠§È†òÂüüÁõ∏ÈóúÁöÑË≥áÊñôÈõÜ„ÄÅÁâπÂæµÊèêÂèñÊäÄË°ìÂíåÊ∑±Â∫¶Â≠∏ÁøíÊû∂Êßã„ÄÇÊàëÂÄëÂàÜÊûê‰∫Ü‰∏çÂêåÊñπÊ≥ïÂú®‰∏çÂêåÊñπÂºè‰∏äÁöÑË°®ÁèæÔºå‰∏¶ËßÄÂØüÂà∞Âü∫ÊñºË™ûË®ÄÂíåË™ûË®ÄÁöÑÊñπÊ≥ïÈÄöÂ∏∏ËÉΩÈÅîÂà∞ÊúÄÈ´òÁöÑÊ™¢Ê∏¨Ë°®Áèæ„ÄÇÁµêÂêàËÅ≤Â≠∏ÂíåË™ûË®ÄÁâπÂæµÁöÑÁ†îÁ©∂ÂæÄÂæÄÂÑ™Êñº‰ΩøÁî®ÂñÆ‰∏ÄÊñπÂºèÁöÑÁ†îÁ©∂„ÄÇÈù¢ÈÉ®ÂàÜÊûêÊñπÊ≥ïÈ°ØÁ§∫Âá∫Ë¶ñË¶∫ÊñπÂºèÁöÑÊΩõÂäõÔºå‰ΩÜÁ†îÁ©∂ËºÉÂ∞ë„ÄÇÂ§ßÂ§öÊï∏Ë´ñÊñáÂ∞àÊ≥®Êñº‰∫åÂÖÉÂàÜÈ°ûÔºàÂèóÊêçËàáÊú™ÂèóÊêçÔºâÔºåËºÉÂ∞ëÊé¢Ë®éÂ§öÈ°ûÊàñÂõûÊ≠∏‰ªªÂãô„ÄÇÈÅ∑ÁßªÂ≠∏ÁøíÂíåÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÂ∑≤ÊàêÁÇ∫ÊµÅË°å‰∏îÊúâÊïàÁöÑÊäÄË°ìÔºåÁâπÂà•ÊòØÂ∞çÊñºË™ûË®ÄÂàÜÊûê„ÄÇÂÑòÁÆ°ÂèñÂæó‰∫ÜÈáçÂ§ßÈÄ≤Â±ïÔºå‰ΩÜ‰ªçÂ≠òÂú®‰∏Ä‰∫õÊåëÊà∞ÔºåÂåÖÊã¨Ë≥áÊñôÊ®ôÊ∫ñÂåñÂíåÂèØÂèäÊÄß„ÄÅÊ®°ÂûãÂèØËß£ÈáãÊÄß„ÄÅÁ∏±ÂêëÂàÜÊûêÈôêÂà∂ÂíåËá®Â∫äÈÅ©ÊáâÊÄß„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÊú™‰æÜÁöÑÁ†îÁ©∂ÊñπÂêëÔºå‰æãÂ¶ÇË™øÊü•ËàáË™ûË®ÄÁÑ°ÈóúÁöÑË™ûÈü≥ÂàÜÊûêÊñπÊ≥ï„ÄÅÈñãÁôºÂ§öÊ®°ÂºèË®∫Êñ∑Á≥ªÁµ±Ôºå‰ª•ÂèäËß£Ê±∫‰∫∫Â∑•Êô∫ÊÖßËºîÂä©ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÂÄ´ÁêÜËÄÉÈáè„ÄÇÈÄèÈÅéÁ∂úÂêàÁõÆÂâçÁöÑË∂®Âã¢ÂíåÊâæÂá∫ÈóúÈçµÈöúÁ§ôÔºåÊú¨ÁØáË©ïË´ñÊó®Âú®ÂºïÂ∞éÊ∑±Â∫¶Â≠∏ÁøíÁÇ∫Âü∫Á§éÁöÑË™çÁü•ÂäüËÉΩÈöúÁ§ôÊ™¢Ê∏¨Á≥ªÁµ±ÁöÑÈÄ≤‰∏ÄÊ≠•ÁôºÂ±ïÔºå‰ª•ÊîπÂñÑÊó©ÊúüË®∫Êñ∑Ôºå‰∏¶ÊúÄÁµÇÊîπÂñÑÊÇ£ËÄÖÁöÑÊ≤ªÁôÇÁµêÊûú„ÄÇ

##### **An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**
2410.17504v1 by Shruthi Chari

Explainable Artificial Intelligence (AI) focuses on helping humans understand
the working of AI systems or their decisions and has been a cornerstone of AI
for decades. Recent research in explainability has focused on explaining the
workings of AI models or model explainability. There have also been several
position statements and review papers detailing the needs of end-users for
user-centered explainability but fewer implementations. Hence, this thesis
seeks to bridge some gaps between model and user-centered explainability. We
create an explanation ontology (EO) to represent literature-derived explanation
types via their supporting components. We implement a knowledge-augmented
question-answering (QA) pipeline to support contextual explanations in a
clinical setting. Finally, we are implementing a system to combine explanations
from different AI methods and data modalities. Within the EO, we can represent
fifteen different explanation types, and we have tested these representations
in six exemplar use cases. We find that knowledge augmentations improve the
performance of base large language models in the contextualized QA, and the
performance is variable across disease groups. In the same setting, clinicians
also indicated that they prefer to see actionability as one of the main foci in
explanations. In our explanations combination method, we plan to use similarity
metrics to determine the similarity of explanations in a chronic disease
detection setting. Overall, through this thesis, we design methods that can
support knowledge-enabled explanations across different use cases, accounting
for the methods in today's AI era that can generate the supporting components
of these explanations and domain knowledge sources that can enhance them.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÂ∞àÊ≥®ÊñºÂçîÂä©‰∫∫È°û‰∫ÜËß£ AI Á≥ªÁµ±ÈÅã‰ΩúÊàñÂÖ∂Ê±∫Á≠ñÔºåÊï∏ÂçÅÂπ¥‰æÜ‰∏ÄÁõ¥ÊòØ AI ÁöÑÂü∫Áü≥„ÄÇÊúÄËøëÁöÑÂèØËß£ÈáãÊÄßÁ†îÁ©∂Â∞àÊ≥®ÊñºËß£Èáã AI Ê®°ÂûãÊàñÊ®°ÂûãÂèØËß£ÈáãÊÄßÁöÑÈÅã‰Ωú„ÄÇ‰πüÊúâÂπæ‰ªΩÁ´ãÂ†¥ËÅ≤ÊòéÂíåË©ïË´ñË´ñÊñáË©≥Á¥∞Ë™™Êòé‰∫ÜÊúÄÁµÇ‰ΩøÁî®ËÄÖÂ∞ç‰ª•‰ΩøÁî®ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑÂèØËß£ÈáãÊÄßÁöÑÈúÄÊ±ÇÔºå‰ΩÜÂØ¶‰ΩúËºÉÂ∞ë„ÄÇÂõ†Ê≠§ÔºåÊú¨Ë´ñÊñáÊó®Âú®ÂΩåË£úÊ®°ÂûãÂíå‰ª•‰ΩøÁî®ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑÂèØËß£ÈáãÊÄß‰πãÈñìÁöÑ‰∏Ä‰∫õÂ∑ÆË∑ù„ÄÇÊàëÂÄëÂª∫Á´ã‰∏ÄÂÄãËß£ÈáãÊú¨È´îÔºàEOÔºâ‰ª•ÈÄèÈÅéÂÖ∂ÊîØÊè¥ÂÖÉ‰ª∂‰æÜË°®Á§∫ÂæûÊñáÁçª‰∏≠Ë°çÁîüÁöÑËß£ÈáãÈ°ûÂûã„ÄÇÊàëÂÄëÂØ¶‰Ωú‰∏ÄÂÄãÁü•Ë≠òÂ¢ûÂº∑ÁöÑÂïèÁ≠îÔºàQAÔºâÁÆ°Á∑öÔºå‰ª•Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÊîØÊè¥ÊÉÖÂ¢ÉËß£Èáã„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊ≠£Âú®ÂØ¶‰Ωú‰∏ÄÂÄãÁ≥ªÁµ±Ôºå‰ª•ÁµêÂêà‰æÜËá™‰∏çÂêå AI ÊñπÊ≥ïÂíåË≥áÊñôÊ®°ÂºèÁöÑËß£Èáã„ÄÇÂú® EO ‰∏≠ÔºåÊàëÂÄëÂèØ‰ª•Ë°®Á§∫ 15 Á®Æ‰∏çÂêåÁöÑËß£ÈáãÈ°ûÂûãÔºå‰∏¶‰∏îÊàëÂÄëÂ∑≤Âú®ÂÖ≠ÂÄãÁØÑ‰æã‰ΩøÁî®Ê°à‰æã‰∏≠Ê∏¨Ë©¶ÈÄô‰∫õË°®Á§∫„ÄÇÊàëÂÄëÁôºÁèæÔºåÁü•Ë≠òÂ¢ûÂº∑ÊîπÂñÑ‰∫ÜÂü∫Á§éÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®ÊÉÖÂ¢ÉÂåñ QA ‰∏≠ÁöÑÊïàËÉΩÔºå‰∏¶‰∏îÊïàËÉΩÂõ†ÁñæÁóÖÁæ§ÁµÑËÄåÁï∞„ÄÇÂú®Áõ∏ÂêåÁöÑÁí∞Â¢É‰∏≠ÔºåËá®Â∫äÈÜ´Áîü‰πüË°®Á§∫‰ªñÂÄëÂ∏åÊúõÂ∞áÂèØÊìç‰ΩúÊÄßË¶ñÁÇ∫Ëß£Èáã‰∏≠ÁöÑ‰∏ªË¶ÅÁÑ¶Èªû‰πã‰∏Ä„ÄÇÂú®ÊàëÂÄëÁöÑËß£ÈáãÁµÑÂêàÊñπÊ≥ï‰∏≠ÔºåÊàëÂÄëË®àÁï´‰ΩøÁî®Áõ∏‰ººÊÄßÊåáÊ®ô‰æÜÁ¢∫ÂÆöÊÖ¢ÊÄßÁóÖÂÅµÊ∏¨Áí∞Â¢É‰∏≠Ëß£ÈáãÁöÑÁõ∏‰ººÊÄß„ÄÇÁ∏ΩÈ´îËÄåË®ÄÔºåÈÄèÈÅéÊú¨Ë´ñÊñáÔºåÊàëÂÄëË®≠Ë®à‰∫ÜÂèØ‰ª•Âú®‰∏çÂêå‰ΩøÁî®Ê°à‰æã‰∏≠ÊîØÊè¥Áü•Ë≠òÂïüÁî®Ëß£ÈáãÁöÑÊñπÊ≥ïÔºåËÄÉÈáèÂà∞Áï∂‰ªä AI ÊôÇ‰ª£‰∏≠ÂèØ‰ª•Áî¢ÁîüÈÄô‰∫õËß£ÈáãÁöÑÊîØÊè¥ÂÖÉ‰ª∂ÂíåÂèØ‰ª•Â¢ûÂº∑ÈÄô‰∫õËß£ÈáãÁöÑÈ†òÂüüÁü•Ë≠ò‰æÜÊ∫êÁöÑÊñπÊ≥ï„ÄÇ

##### **Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**
2410.16879v1 by Lukas Hughes-Noehrer, Leda Channer, Gabriel Strain, Gregory Yates, Richard Body, Caroline Jay

Objectives: To investigate clinicians' attitudes towards current automated
interpretation of ECG and novel AI technologies and their perception of
computer-assisted interpretation. Materials and Methods: We conducted a series
of interviews with clinicians in the UK. Our study: (i) explores the potential
for AI, specifically future 'human-like' computing approaches, to facilitate
ECG interpretation and support clinical decision making, and (ii) elicits their
opinions about the importance of explainability and trustworthiness of AI
algorithms. Results: We performed inductive thematic analysis on interview
transcriptions from 23 clinicians and identified the following themes: (i) a
lack of trust in current systems, (ii) positive attitudes towards future AI
applications and requirements for these, (iii) the relationship between the
accuracy and explainability of algorithms, and (iv) opinions on education,
possible deskilling, and the impact of AI on clinical competencies. Discussion:
Clinicians do not trust current computerised methods, but welcome future 'AI'
technologies. Where clinicians trust future AI interpretation to be accurate,
they are less concerned that it is explainable. They also preferred ECG
interpretation that demonstrated the results of the algorithm visually. Whilst
clinicians do not fear job losses, they are concerned about deskilling and the
need to educate the workforce to use AI responsibly. Conclusion: Clinicians are
positive about the future application of AI in clinical decision-making.
Accuracy is a key factor of uptake and visualisations are preferred over
current computerised methods. This is viewed as a potential means of training
and upskilling, in contrast to the deskilling that automation might be
perceived to bring.

ÊëòË¶ÅÔºö<paragraph>ÁõÆÁöÑÔºöË™øÊü•Ëá®Â∫äÈÜ´ÁîüÂ∞çÁõÆÂâçËá™ÂãïÂåñÂøÉÈõªÂúñËß£ËÆÄÂíåÊñ∞ÁöÑ‰∫∫Â∑•Êô∫ÊÖßÊäÄË°ìÁöÑÊÖãÂ∫¶Ôºå‰ª•Âèä‰ªñÂÄëÂ∞çÈõªËÖ¶ËºîÂä©Ëß£ËÆÄÁöÑÁúãÊ≥ï„ÄÇÊùêÊñôÂíåÊñπÊ≥ïÔºöÊàëÂÄëÂ∞çËã±ÂúãÁöÑËá®Â∫äÈÜ´ÁîüÈÄ≤Ë°å‰∫Ü‰∏ÄÁ≥ªÂàóË®™Ë´á„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ôºö(i) Êé¢Ë®é‰∫∫Â∑•Êô∫ÊÖßÁöÑÊΩõÂäõÔºåÁâπÂà•ÊòØÊú™‰æÜÁöÑ„ÄåÈ°û‰∫∫È°û„ÄçÈÅãÁÆóÊñπÊ≥ïÔºå‰ª•‰øÉÈÄ≤ÂøÉÈõªÂúñËß£ËÆÄ‰∏¶ÊîØÊåÅËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÔºå‰ª•Âèä (ii) ÂæµÊ±Ç‰ªñÂÄëÂ∞ç‰∫∫Â∑•Êô∫ÊÖßÊºîÁÆóÊ≥ïÁöÑÂèØËß£ÈáãÊÄßÂíåÂèØ‰ø°Â∫¶ÁöÑÁúãÊ≥ï„ÄÇÁµêÊûúÔºöÊàëÂÄëÂ∞ç 23 ‰ΩçËá®Â∫äÈÜ´ÁîüÁöÑË®™Ë´áË®òÈåÑÈÄ≤Ë°å‰∫ÜÊ≠∏Á¥ç‰∏ªÈ°åÂàÜÊûêÔºå‰∏¶ÊâæÂá∫‰ª•‰∏ã‰∏ªÈ°åÔºö(i) Â∞çÁõÆÂâçÁ≥ªÁµ±Áº∫‰πè‰ø°‰ªªÔºå(ii) Â∞çÊú™‰æÜ‰∫∫Â∑•Êô∫ÊÖßÊáâÁî®ÂíåÂ∞çÈÄô‰∫õÊáâÁî®ÁöÑË¶ÅÊ±ÇÊåÅÊ≠£Èù¢ÊÖãÂ∫¶Ôºå(iii) ÊºîÁÆóÊ≥ïÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂèØËß£ÈáãÊÄß‰πãÈñìÁöÑÈóú‰øÇÔºå‰ª•Âèä (iv) Â∞çÊïôËÇ≤„ÄÅÂèØËÉΩÁöÑÊäÄËÉΩÈÄÄÂåñÔºå‰ª•Âèä‰∫∫Â∑•Êô∫ÊÖßÂ∞çËá®Â∫äËÉΩÂäõÁöÑÂΩ±ÈüøÁöÑÁúãÊ≥ï„ÄÇË®éË´ñÔºöËá®Â∫äÈÜ´Áîü‰∏ç‰ø°‰ªªÁõÆÂâçÁöÑÈõªËÖ¶ÂåñÊñπÊ≥ïÔºå‰ΩÜÊ≠°ËøéÊú™‰æÜÁöÑ„Äå‰∫∫Â∑•Êô∫ÊÖß„ÄçÊäÄË°ì„ÄÇÂú®Ëá®Â∫äÈÜ´ÁîüÁõ∏‰ø°Êú™‰æÜÁöÑ AI Ëß£ËÆÄÊ∫ñÁ¢∫ÁöÑÊÉÖÊ≥Å‰∏ãÔºå‰ªñÂÄë‰∏çÂ§™ÊìîÂøÉÂÆÉÊòØÂê¶ÂèØËß£Èáã„ÄÇ‰ªñÂÄë‰πüÊØîËºÉÂñúÊ≠°ËÉΩ‰ª•Ë¶ñË¶∫ÊñπÂºèÂëàÁèæÊºîÁÆóÊ≥ïÁµêÊûúÁöÑÂøÉÈõªÂúñËß£ËÆÄ„ÄÇÈõñÁÑ∂Ëá®Â∫äÈÜ´Áîü‰∏çÂÆ≥ÊÄïÂ§±Ê•≠Ôºå‰ΩÜ‰ªñÂÄëÊìîÂøÉÊäÄËÉΩÈÄÄÂåñÔºå‰ª•ÂèäÈúÄË¶ÅÊïôËÇ≤Âì°Â∑•Ë≤†Ë≤¨‰ªªÂú∞‰ΩøÁî®‰∫∫Â∑•Êô∫ÊÖß„ÄÇÁµêË´ñÔºöËá®Â∫äÈÜ´ÁîüÂ∞ç‰∫∫Â∑•Êô∫ÊÖßÂú®Ëá®Â∫äÊ±∫Á≠ñÂà∂ÂÆö‰∏≠ÁöÑÊú™‰æÜÊáâÁî®ÊåÅÊ≠£Èù¢ÊÖãÂ∫¶„ÄÇÊ∫ñÁ¢∫ÊÄßÊòØÊé°Áî®‰∫∫Â∑•Êô∫ÊÖßÁöÑ‰∏ÄÂÄãÈóúÈçµÂõ†Á¥†ÔºåËÄåË¶ñË¶∫ÂåñÊØîÁõÆÂâçÁöÑÈõªËÖ¶ÂåñÊñπÊ≥ïÊõ¥ÂèóÈùíÁùû„ÄÇÈÄôË¢´Ë¶ñÁÇ∫‰∏ÄÁ®ÆÊΩõÂú®ÁöÑÂüπË®ìÂíåÊèêÂçáÊäÄËÉΩÁöÑÊñπÊ≥ïÔºåËàáËá™ÂãïÂåñÂèØËÉΩÂ∏∂‰æÜÁöÑÊäÄËÉΩÈÄÄÂåñÂΩ¢ÊàêÂ∞çÊØî„ÄÇ</paragraph>

##### **Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**
2410.15012v1 by Gesa Mittmann, Sara Laiouar-Pedari, Hendrik A. Mehrtens, Sarah Haggenm√ºller, Tabea-Clara Bucher, Tirtha Chanda, Nadine T. Gaisa, Mathias Wagner, Gilbert Georg Klamminger, Tilman T. Rau, Christina Neppl, Eva Maria Comp√©rat, Andreas Gocht, Monika H√§mmerle, Niels J. Rupp, Jula Westhoff, Irene Kr√ºcken, Maximillian Seidl, Christian M. Sch√ºrch, Marcus Bauer, Wiebke Solass, Yu Chun Tam, Florian Weber, Rainer Grobholz, Jaroslaw Augustyniak, Thomas Kalinski, Christian H√∂rner, Kirsten D. Mertz, Constanze D√∂ring, Andreas Erbersdobler, Gabriele Deubler, Felix Bremmer, Ulrich Sommer, Michael Brodhun, Jon Griffin, Maria Sarah L. Lenon, Kiril Trpkov, Liang Cheng, Fei Chen, Angelique Levi, Guoping Cai, Tri Q. Nguyen, Ali Amin, Alessia Cimadamore, Ahmed Shabaik, Varsha Manucha, Nazeel Ahmad, Nidia Messias, Francesca Sanguedolce, Diana Taheri, Ezra Baraban, Liwei Jia, Rajal B. Shah, Farshid Siadat, Nicole Swarbrick, Kyung Park, Oudai Hassan, Siamak Sakhaie, Michelle R. Downes, Hiroshi Miyamoto, Sean R. Williamson, Tim Holland-Letz, Carolin V. Schneider, Jakob Nikolas Kather, Yuri Tolkach, Titus J. Brinker

The aggressiveness of prostate cancer, the most common cancer in men
worldwide, is primarily assessed based on histopathological data using the
Gleason scoring system. While artificial intelligence (AI) has shown promise in
accurately predicting Gleason scores, these predictions often lack inherent
explainability, potentially leading to distrust in human-machine interactions.
To address this issue, we introduce a novel dataset of 1,015 tissue microarray
core images, annotated by an international group of 54 pathologists. The
annotations provide detailed localized pattern descriptions for Gleason grading
in line with international guidelines. Utilizing this dataset, we develop an
inherently explainable AI system based on a U-Net architecture that provides
predictions leveraging pathologists' terminology. This approach circumvents
post-hoc explainability methods while maintaining or exceeding the performance
of methods trained directly for Gleason pattern segmentation (Dice score: 0.713
$\pm$ 0.003 trained on explanations vs. 0.691 $\pm$ 0.010 trained on Gleason
patterns). By employing soft labels during training, we capture the intrinsic
uncertainty in the data, yielding strong results in Gleason pattern
segmentation even in the context of high interobserver variability. With the
release of this dataset, we aim to encourage further research into segmentation
in medical tasks with high levels of subjectivity and to advance the
understanding of pathologists' reasoning processes.

ÊëòË¶ÅÔºöÂâçÂàóËÖ∫ÁôåÊòØÂÖ®ÁêÉÁî∑ÊÄßÊúÄÂ∏∏Ë¶ãÁöÑÁôåÁóáÔºåÂÖ∂ÊÉ°ÊÄßÁ®ãÂ∫¶‰∏ªË¶ÅÊ†πÊìö Gleason Ë©ïÂàÜÁ≥ªÁµ±‰ΩøÁî®ÁµÑÁπîÁóÖÁêÜÂ≠∏Êï∏ÊìöÈÄ≤Ë°åË©ï‰º∞„ÄÇÈõñÁÑ∂‰∫∫Â∑•Êô∫ÊÖß (AI) Âú®Ê∫ñÁ¢∫È†êÊ∏¨ Gleason Ë©ïÂàÜÊñπÈù¢Â∑≤Â±ïÁèæÊΩõÂäõÔºå‰ΩÜÈÄô‰∫õÈ†êÊ∏¨ÈÄöÂ∏∏Áº∫‰πèÂÖßÂú®ÁöÑÂèØËß£ÈáãÊÄßÔºåÂèØËÉΩÊúÉÂ∞éËá¥Â∞ç‰∫∫Ê©ü‰∫íÂãïÁöÑ‰∏ç‰ø°‰ªª„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÈÄ≤‰∫Ü‰∏ÄÂÄãÁî± 54 ‰ΩçÁóÖÁêÜÂ≠∏ÂÆ∂ÁµÑÊàêÁöÑÂúãÈöõÂúòÈöäË®ªËß£ÁöÑ 1,015 ÂÄãÁµÑÁπîÂæÆÈô£ÂàóÊ†∏ÂøÉÂΩ±ÂÉèÁöÑÊñ∞Á©éË≥áÊñôÈõÜ„ÄÇÈÄô‰∫õË®ªËß£Êèê‰æõ‰∫ÜË©≥Á¥∞ÁöÑÂ±ÄÈÉ®Ê®°ÂºèÊèèËø∞ÔºåÁî®ÊñºÁ¨¶ÂêàÂúãÈöõÊ∫ñÂâáÁöÑ Gleason ÂàÜÁ¥ö„ÄÇÂà©Áî®ÈÄôÂÄãË≥áÊñôÈõÜÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÂü∫Êñº U-Net Êû∂ÊßãÁöÑÂÖßÂú®ÂèØËß£Èáã AI Á≥ªÁµ±ÔºåË©≤Á≥ªÁµ±Êèê‰æõ‰∫ÜÂà©Áî®ÁóÖÁêÜÂ≠∏ÂÆ∂Ë°ìË™ûÈÄ≤Ë°åÈ†êÊ∏¨„ÄÇÈÄôÁ®ÆÊñπÊ≥ïË¶èÈÅø‰∫Ü‰∫ãÂæåÂèØËß£ÈáãÊÄßÊñπÊ≥ïÔºåÂêåÊôÇÁ∂≠ÊåÅÊàñË∂ÖË∂ä‰∫ÜÁõ¥Êé•Ë®ìÁ∑¥Áî®Êñº Gleason Ê®°ÂºèÂàÜÂâ≤ÁöÑÊñπÊ≥ïÁöÑÊïàËÉΩÔºàDice ÂàÜÊï∏Ôºö0.713 ¬± 0.003ÔºåË®ìÁ∑¥ÊñºËß£ÈáãÔºåÁõ∏Â∞çÊñº 0.691 ¬± 0.010ÔºåË®ìÁ∑¥Êñº Gleason Ê®°ÂºèÔºâ„ÄÇÈÄèÈÅéÂú®Ë®ìÁ∑¥ÊúüÈñìÊé°Áî®ËªüÊ®ôÁ±§ÔºåÊàëÂÄëÊçïÊçâ‰∫ÜË≥áÊñô‰∏≠ÁöÑÂÖßÂú®‰∏çÁ¢∫ÂÆöÊÄßÔºåÂç≥‰ΩøÂú®ËßÄÂØüËÄÖÈñìËÆäÁï∞ÊÄßÈ´òÁöÑÊÉÖÊ≥Å‰∏ãÔºå‰πüËÉΩÂú® Gleason Ê®°ÂºèÂàÜÂâ≤‰∏≠Áî¢ÁîüÂº∑Â§ßÁöÑÁµêÊûú„ÄÇÈÄèÈÅéÈáãÂá∫ÈÄôÂÄãË≥áÊñôÈõÜÔºåÊàëÂÄëÊó®Âú®ÈºìÂãµÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂‰∏ªËßÄÊÄßÈ´òÁöÑÈÜ´ÁôÇ‰ªªÂãô‰∏≠ÁöÑÂàÜÂâ≤Ôºå‰∏¶Â¢ûÈÄ≤Â∞çÁóÖÁêÜÂ≠∏ÂÆ∂Êé®ÁêÜÈÅéÁ®ãÁöÑÁêÜËß£„ÄÇ

##### **Explainable AI Methods for Multi-Omics Analysis: A Survey**
2410.11910v1 by Ahmad Hussein, Mukesh Prasad, Ali Braytee

Advancements in high-throughput technologies have led to a shift from
traditional hypothesis-driven methodologies to data-driven approaches.
Multi-omics refers to the integrative analysis of data derived from multiple
'omes', such as genomics, proteomics, transcriptomics, metabolomics, and
microbiomics. This approach enables a comprehensive understanding of biological
systems by capturing different layers of biological information. Deep learning
methods are increasingly utilized to integrate multi-omics data, offering
insights into molecular interactions and enhancing research into complex
diseases. However, these models, with their numerous interconnected layers and
nonlinear relationships, often function as black boxes, lacking transparency in
decision-making processes. To overcome this challenge, explainable artificial
intelligence (xAI) methods are crucial for creating transparent models that
allow clinicians to interpret and work with complex data more effectively. This
review explores how xAI can improve the interpretability of deep learning
models in multi-omics research, highlighting its potential to provide
clinicians with clear insights, thereby facilitating the effective application
of such models in clinical settings.

ÊëòË¶ÅÔºöÈ´òÈÄöÈáèÊäÄË°ìÁöÑÈÄ≤Ê≠•Â∞éËá¥ÂæûÂÇ≥Áµ±ÁöÑÂÅáË®≠È©ÖÂãïÊñπÊ≥ïËΩâËÆäÁÇ∫Ë≥áÊñôÈ©ÖÂãïÁöÑÊñπÊ≥ï„ÄÇÂ§öÁµÑÂ≠∏ÊòØÊåáÊï¥ÂêàÂàÜÊûê‰æÜËá™Â§öÂÄã„ÄåÁµÑÂ≠∏„ÄçÁöÑË≥áÊñôÔºå‰æãÂ¶ÇÂü∫Âõ†ÁµÑÂ≠∏„ÄÅËõãÁôΩË≥™ÁµÑÂ≠∏„ÄÅËΩâÈåÑÁµÑÂ≠∏„ÄÅ‰ª£Ë¨ùÁµÑÂ≠∏ÂíåÂæÆÁîüÁâ©ÁµÑÂ≠∏„ÄÇÊ≠§ÊñπÊ≥ïÈÄèÈÅéÊì∑ÂèñÁîüÁâ©Ë≥áË®äÁöÑ‰∏çÂêåÂ±§Èù¢ÔºåËÉΩÂÖ®Èù¢‰∫ÜËß£ÁîüÁâ©Á≥ªÁµ±„ÄÇÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÊÑà‰æÜÊÑàÂ∏∏Ë¢´Áî®ÊñºÊï¥ÂêàÂ§öÁµÑÂ≠∏Ë≥áÊñôÔºåÊèê‰æõÂàÜÂ≠ê‰∫§‰∫í‰ΩúÁî®ÁöÑÊ¥ûÂØüÂäõÔºå‰∏¶Âä†Âº∑Â∞çË§áÈõúÁñæÁóÖÁöÑÁ†îÁ©∂„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°ÂûãÂÖ∑ÊúâË®±Â§öÁõ∏‰∫íÈÄ£Êé•ÁöÑÂ±§Á¥öÂíåÈùûÁ∑öÊÄßÈóú‰øÇÔºåÈÄöÂ∏∏ÊúÉÂÉèÈªëÁõíÂ≠ê‰∏ÄÊ®£ÈÅã‰ΩúÔºåÁº∫‰πèÊ±∫Á≠ñÈÅéÁ®ãÁöÑÈÄèÊòéÂ∫¶„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÊ≠§ÊåëÊà∞ÔºåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (xAI) ÊñπÊ≥ïÂ∞çÊñºÂª∫Á´ãÈÄèÊòéÊ®°ÂûãËá≥ÈóúÈáçË¶ÅÔºåËÆìËá®Â∫äÈÜ´ÁîüÂèØ‰ª•Êõ¥ÊúâÊïàÂú∞Ëß£ÈáãÂíåËôïÁêÜË§áÈõúË≥áÊñô„ÄÇÊ≠§Ë©ïË´ñÊé¢Ë®é xAI Â¶Ç‰ΩïËÉΩÊîπÂñÑÂ§öÁµÑÂ≠∏Á†îÁ©∂‰∏≠Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÔºåÂº∑Ë™øÂÖ∂Êèê‰æõËá®Â∫äÈÜ´ÁîüÊòéÁ¢∫Ë¶ãËß£ÁöÑÊΩõÂäõÔºåÈÄ≤ËÄå‰øÉÈÄ≤Ê≠§È°ûÊ®°ÂûãÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊúâÊïàÊáâÁî®„ÄÇ

##### **Study on the Helpfulness of Explainable Artificial Intelligence**
2410.11896v1 by Tobias Labarta, Elizaveta Kulicheva, Ronja Froelian, Christian Gei√üler, Xenia Melman, Julian von Klitzing

Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) Â∞çÊñºÂª∫ÊßãÂÖàÈÄ≤ÁöÑÊ©üÂô®Â≠∏ÁøíÈ©ÖÂãïÊáâÁî®Á®ãÂºèËá≥ÈóúÈáçË¶ÅÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇË®∫Êñ∑ÊàñËá™ÂãïÈßïÈßõÁ≠âÈóúÈçµÈ†òÂüü„ÄÇÊ≥ïÂæã„ÄÅÂïÜÊ•≠ÂíåÂÄ´ÁêÜË¶ÅÊ±Ç‰øÉ‰Ωø‰ΩøÁî®ÊúâÊïàÁöÑ XAIÔºå‰ΩÜÊï∏ÈáèÊó•ÁõäÂ¢ûÂä†ÁöÑ‰∏çÂêåÊñπÊ≥ï‰ΩøÂæóÊåëÈÅ∏Ê≠£Á¢∫ÁöÑÊñπÊ≥ïÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊ≠§Â§ñÔºåÁî±ÊñºËß£ÈáãÈ´òÂ∫¶‰æùË≥¥ÊñºËÉåÊôØÔºåÂú®Ê≤íÊúâ‰ΩøÁî®ËÄÖÁöÑÊÉÖÊ≥Å‰∏ãË°°Èáè XAI ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÂè™ËÉΩÊè≠Á§∫ÊúâÈôêÁöÑË≥áË®äÔºåÊéíÈô§‰∫∫È°ûÂõ†Á¥†Ôºå‰æãÂ¶ÇÁêÜËß£ÂÆÉÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÂª∫Ë≠∞ÈÄèÈÅé‰ΩøÁî®ËÄÖÊàêÂäüÂü∑Ë°å‰ª£ÁêÜ‰ªªÂãôÁöÑËÉΩÂäõ‰æÜË©ï‰º∞ XAI ÊñπÊ≥ïÔºåË®≠Ë®à‰ΩøÂæóËâØÂ•ΩÁöÑÂü∑Ë°åË°®ÁèæÊòØËß£ÈáãÊèê‰æõÊúâÁî®Ë≥áË®äÁöÑÊåáÊ®ô„ÄÇÊèõÂè•Ë©±Ë™™ÔºåÊàëÂÄëÊé¢Ë®é XAI Â∞ç‰∫∫È°ûÊ±∫Á≠ñÂà∂ÂÆöÁöÑÂπ´Âä©„ÄÇÊ≠§Â§ñÔºåÂ∞çÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÈÄ≤Ë°å‰ΩøÁî®ËÄÖÁ†îÁ©∂ÔºåÈ°ØÁ§∫Âá∫ÂÆÉÂÄëÂú®Áî¢Áîü‰ø°‰ªªÂíåÊá∑ÁñëÁöÑËÉΩÂäõ‰ª•ÂèäÊ≠£Á¢∫Âà§Êñ∑ AI Ê±∫Á≠ñÊòØÂê¶Ê≠£Á¢∫ÁöÑËÉΩÂäõÊñπÈù¢Â≠òÂú®Â∑ÆÁï∞„ÄÇÊ†πÊìöÁµêÊûúÔºåÊàëÂÄëÂº∑ÁÉàÂª∫Ë≠∞‰ΩøÁî®ÂíåÊì¥ÂÖÖÈÄôÁ®ÆÊñπÊ≥ïÔºå‰ª•ÈÄ≤Ë°åÊõ¥Â§ö‰ª•ÁõÆÊ®ôÁÇ∫Âü∫Á§éÁöÑ‰∫∫ÁÇ∫‰∏≠ÂøÉ‰ΩøÁî®ËÄÖÁ†îÁ©∂Ôºå‰ª•ÁµÇÁ´ØÂà∞ÁµÇÁ´ØÁöÑÊñπÂºèË°°Èáè XAI ÊïàËÉΩ„ÄÇ

##### **Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**
2410.09635v1 by Abdullah Mamun, Lawrence D. Devoe, Mark I. Evans, David W. Britt, Judith Klein-Seetharaman, Hassan Ghasemzadeh

Early detection of intrapartum risk enables interventions to potentially
prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently,
there is no accurate automated system to predict such events to assist with
clinical decision-making. To fill this gap, we propose "Artificial Intelligence
(AI) for Modeling and Explaining Neonatal Health" (AIMEN), a deep learning
framework that not only predicts adverse labor outcomes from maternal, fetal,
obstetrical, and intrapartum risk factors but also provides the model's
reasoning behind the predictions made. The latter can provide insights into
what modifications in the input variables of the model could have changed the
predicted outcome. We address the challenges of imbalance and small datasets by
synthesizing additional training data using Adaptive Synthetic Sampling
(ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN
uses an ensemble of fully-connected neural networks as the backbone for its
classification with the data augmentation supported by either ADASYN or CTGAN.
AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in
classification. AIMEN can predict a high risk for adverse labor outcomes with
an average F1 score of 0.784. It also provides counterfactual explanations that
can be achieved by changing 2 to 3 attributes on average. Resources available:
https://github.com/ab9mamun/AIMEN.

ÊëòË¶ÅÔºöÁî¢Á®ã‰∏≠È¢®Èö™ÁöÑÊó©ÊúüÂÅµÊ∏¨ÊúâÂä©ÊñºÈÄ≤Ë°åÂπ≤È†êÊé™ÊñΩÔºå‰ª•È†êÈò≤ÊàñÊ∏õËºï‰∏çÂà©ÁöÑÁîüÁî¢ÁµêÊûúÔºå‰æãÂ¶ÇËÖ¶ÊÄßÈ∫ªÁó∫„ÄÇÁõÆÂâçÔºåÊ≤íÊúâÊ∫ñÁ¢∫ÁöÑËá™ÂãïÂåñÁ≥ªÁµ±ÂèØ‰ª•È†êÊ∏¨Ê≠§È°û‰∫ã‰ª∂Ôºå‰ª•ÂçîÂä©Ëá®Â∫äÊ±∫Á≠ñ„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄô‰∏ÄÁ©∫ÁôΩÔºåÊàëÂÄëÊèêÂá∫„ÄåÁî®ÊñºÂª∫Ê®°ÂíåËß£ÈáãÊñ∞ÁîüÂÖíÂÅ•Â∫∑ÁöÑ‰∫∫Â∑•Êô∫ÊÖß„Äç(AIMEN)ÔºåÈÄôÊòØ‰∏ÄÂÄãÊ∑±Â∫¶Â≠∏ÁøíÊû∂ÊßãÔºåÂÆÉ‰∏çÂÉÖÂèØ‰ª•Ê†πÊìöÂ≠ïÁî¢Â©¶„ÄÅËÉéÂÖí„ÄÅÁî¢ÁßëÂíåÁî¢Á®ãÈ¢®Èö™Âõ†Á¥†È†êÊ∏¨‰∏çÂà©ÁöÑÁîüÁî¢ÁµêÊûúÔºåÈÇÑËÉΩÊèê‰æõÊ®°ÂûãÂÅöÂá∫È†êÊ∏¨ËÉåÂæåÁöÑÂéüÂõ†„ÄÇÂæåËÄÖÂèØ‰ª•Êèê‰æõË¶ãËß£ÔºåË™™ÊòéÊ®°ÂûãËº∏ÂÖ•ËÆäÊï∏‰∏≠ÁöÑÂì™‰∫õ‰øÆÊîπÂèØËÉΩÊúÉÊîπËÆäÈ†êÊ∏¨ÁµêÊûú„ÄÇÊàëÂÄëÈÄèÈÅé‰ΩøÁî®ÈÅ©ÊáâÊÄßÂêàÊàêÊäΩÊ®£ (ADASYN) ÂíåÊ¢ù‰ª∂Ë°®Ê†ºÁîüÊàêÂ∞çÊäóÁ∂≤Ë∑Ø (CTGAN) ‰æÜÂêàÊàêÈ°çÂ§ñÁöÑË®ìÁ∑¥Ë≥áÊñôÔºå‰ª•Ëß£Ê±∫‰∏çÂπ≥Ë°°ÂíåÂ∞èÂûãË≥áÊñôÈõÜÁöÑÊåëÊà∞„ÄÇAIMEN ‰ΩøÁî®ÂÖ®ÈÄ£Êé•Á•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÈõÜÂêà‰ΩúÁÇ∫ÂÖ∂ÂàÜÈ°ûÁöÑÈ™®ÂππÔºå‰∏¶ÈÄèÈÅé ADASYN Êàñ CTGAN ÊîØÊè¥Ë≥áÊñôÊì¥ÂÖÖ„ÄÇÁî± CTGAN ÊîØÊè¥ÁöÑ AIMEN Âú®ÂàÜÈ°ûÊñπÈù¢ÂÑ™ÊñºÁî± ADASYN ÊîØÊè¥ÁöÑ AIMEN„ÄÇAIMEN ÂèØ‰ª•È†êÊ∏¨‰∏çÂà©ÁöÑÁîüÁî¢ÁµêÊûúÁöÑÈ´òÈ¢®Èö™ÔºåÂπ≥Âùá F1 ÂàÜÊï∏ÁÇ∫ 0.784„ÄÇÂÆÉÈÇÑÊèê‰æõÂèç‰∫ãÂØ¶Ëß£ÈáãÔºåÂèØÈÄèÈÅéÂπ≥ÂùáËÆäÊõ¥ 2 Ëá≥ 3 ÂÄãÂ±¨ÊÄß‰æÜÈÅîÊàê„ÄÇÂèØÁî®Ë≥áÊ∫êÔºöhttps://github.com/ab9mamun/AIMEN„ÄÇ

##### **Artificial intelligence techniques in inherited retinal diseases: A review**
2410.09105v1 by Han Trinh, Jordan Vice, Jason Charng, Zahra Tajbakhsh, Khyber Alam, Fred K. Chen, Ajmal Mian

Inherited retinal diseases (IRDs) are a diverse group of genetic disorders
that lead to progressive vision loss and are a major cause of blindness in
working-age adults. The complexity and heterogeneity of IRDs pose significant
challenges in diagnosis, prognosis, and management. Recent advancements in
artificial intelligence (AI) offer promising solutions to these challenges.
However, the rapid development of AI techniques and their varied applications
have led to fragmented knowledge in this field. This review consolidates
existing studies, identifies gaps, and provides an overview of AI's potential
in diagnosing and managing IRDs. It aims to structure pathways for advancing
clinical applications by exploring AI techniques like machine learning and deep
learning, particularly in disease detection, progression prediction, and
personalized treatment planning. Special focus is placed on the effectiveness
of convolutional neural networks in these areas. Additionally, the integration
of explainable AI is discussed, emphasizing its importance in clinical settings
to improve transparency and trust in AI-based systems. The review addresses the
need to bridge existing gaps in focused studies on AI's role in IRDs, offering
a structured analysis of current AI techniques and outlining future research
directions. It concludes with an overview of the challenges and opportunities
in deploying AI for IRDs, highlighting the need for interdisciplinary
collaboration and the continuous development of robust, interpretable AI models
to advance clinical applications.

ÊëòË¶ÅÔºöÈÅ∫ÂÇ≥ÊÄßË¶ñÁ∂≤ËÜúÁñæÁóÖ (IRD) ÊòØ‰∏ÄÁµÑÂ§öÊ®£ÂåñÁöÑÈÅ∫ÂÇ≥ÁñæÁóÖÔºå
ÊúÉÂ∞éËá¥Ë¶ñÂäõÈÄêÊº∏Âñ™Â§±ÔºåÊòØÂ∑•‰ΩúÂπ¥ÈΩ°Êàê‰∫∫Â§±ÊòéÁöÑ‰∏ªË¶ÅÂéüÂõ†„ÄÇIRD ÁöÑË§áÈõúÊÄßÂíåÁï∞Ë≥™ÊÄßÂ∞çË®∫Êñ∑„ÄÅÈ†êÂæåÂíåÁÆ°ÁêÜÊèêÂá∫‰∫ÜÈáçÂ§ßÊåëÊà∞„ÄÇÊúÄËøë‰∫∫Â∑•Êô∫ËÉΩ (AI) ÁöÑÈÄ≤Ê≠•ÁÇ∫ÈÄô‰∫õÊåëÊà∞Êèê‰æõ‰∫ÜÊúâÂ∏åÊúõÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ
ÁÑ∂ËÄåÔºåAI ÊäÄË°ìÁöÑÂø´ÈÄüÁôºÂ±ïÂèäÂÖ∂Â§öÁ®ÆÊáâÁî®Â∞éËá¥‰∫ÜË©≤È†òÂüüÁöÑÁü•Ë≠òÂàÜÊï£„ÄÇÊú¨Á∂úËø∞Êï¥Âêà‰∫ÜÁèæÊúâÁ†îÁ©∂ÔºåÊâæÂá∫Â∑ÆË∑ùÔºå‰∏¶Ê¶ÇËø∞‰∫Ü AI Âú®Ë®∫Êñ∑ÂíåÁÆ°ÁêÜ IRD ‰∏≠ÁöÑÊΩõÂäõ„ÄÇÂÆÉÊó®Âú®ÈÄöÈÅéÊé¢Á¥¢Ê©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÁ≠â AI ÊäÄË°ìÔºåÁâπÂà•ÊòØÂú®ÁñæÁóÖÊ™¢Ê∏¨„ÄÅÈÄ≤Á®ãÈ†êÊ∏¨ÂíåÂÄãÊÄßÂåñÊ≤ªÁôÇË®àÂäÉ‰∏≠ÔºåÁÇ∫Êé®ÈÄ≤Ëá®Â∫äÊáâÁî®ÊßãÂª∫ÈÄîÂæë„ÄÇÁâπÂà•ÈóúÊ≥®ÈÄô‰∫õÈ†òÂüü‰∏≠Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÊúâÊïàÊÄß„ÄÇÊ≠§Â§ñÔºåË®éË´ñ‰∫ÜÂèØËß£Èáã AI ÁöÑÊï¥ÂêàÔºåÂº∑Ë™ø‰∫ÜÂÖ∂Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÊèêÈ´òÈÄèÊòéÂ∫¶ÂíåÂ∞çÂü∫Êñº AI ÁöÑÁ≥ªÁµ±ÁöÑ‰ø°‰ªªÁöÑÈáçË¶ÅÊÄß„ÄÇË©≤Á∂úËø∞Ëß£Ê±∫‰∫ÜÂΩåÂêà AI Âú® IRD ‰∏≠‰ΩúÁî®ÁöÑÈáçÈªûÁ†îÁ©∂‰∏≠ÁèæÊúâÂ∑ÆË∑ùÁöÑÂøÖË¶ÅÊÄßÔºåÊèê‰æõ‰∫ÜÂ∞çÁï∂Ââç AI ÊäÄË°ìÁöÑÁµêÊßãÂåñÂàÜÊûêÔºå‰∏¶Ê¶ÇËø∞‰∫ÜÊú™‰æÜÁöÑÁ†îÁ©∂ÊñπÂêë„ÄÇÊúÄÂæåÊ¶ÇËø∞‰∫ÜÂú® IRD ‰∏≠ÈÉ®ÁΩ≤ AI ÁöÑÊåëÊà∞ÂíåÊ©üÈÅáÔºåÂº∑Ë™ø‰∫ÜË∑®Â≠∏ÁßëÂêà‰ΩúÂíåÊåÅÁ∫åÈñãÁôºÂº∑Â§ß„ÄÅÂèØËß£ÈáãÁöÑ AI Ê®°Âûã‰ª•Êé®ÈÄ≤Ëá®Â∫äÊáâÁî®ÁöÑÂøÖË¶ÅÊÄß„ÄÇ

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

ÊëòË¶ÅÔºöËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÊ±∫Á≠ñÊòØÁèæÂú® AI ÁöÑ‰∏ÄÈ†ÖÈáçÂ§ßÊåëÊà∞ÔºåÁâπÂà•ÊòØÊáâÁî®ÊñºÂÉèÈÜ´Â≠∏ÂíåÊ≥ïÂæãÁ≠âÊïèÊÑüÊÉÖÂ¢ÉÊôÇ„ÄÇÁÑ∂ËÄåÔºåËß£ÈáãÊ±∫Á≠ñËÉåÂæåÁêÜÁî±ÁöÑÈúÄÊ±Ç‰πüÊòØÂü∫Êñº‰∫∫È°ûÁöÑËÄÉÈáèÁöÑ‰∏ÄÂÄã‰∏ªË¶ÅÂïèÈ°åÔºåÂõ†ÁÇ∫ÊúâÂøÖË¶ÅË≠âÊòéÁÇ∫‰ªÄÈ∫ºÂÅöÂá∫ÊüêÂÄãÊ±∫Á≠ñ„ÄÇ‰æãÂ¶ÇÔºå‰ΩèÈô¢ÈÜ´Â∏´‰∏çÂÉÖÈúÄË¶ÅÊèê‰æõÔºàÂèØËÉΩÊòØÊ≠£Á¢∫ÁöÑÔºâË®∫Êñ∑ÔºåÈÇÑÈúÄË¶ÅËß£Èáã‰ªñÂÄëÂ¶Ç‰ΩïÈÅîÊàêÊüêÂÄãÁµêË´ñ„ÄÇÂõ†Ê≠§ÔºåÈñãÁôºÊñ∞ÁöÑÂ∑•ÂÖ∑‰æÜÂπ´Âä©‰ΩèÈô¢ÈÜ´Â∏´Ë®ìÁ∑¥‰ªñÂÄëÁöÑËß£ÈáãÊäÄÂ∑ßÊòØÊïôËÇ≤‰∏≠ AI ÁöÑ‰∏ÄÈ†ÖÊ†∏ÂøÉÁõÆÊ®ô„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÅµÂæ™ÈÄôÂÄãÊñπÂêëÔºå‰∏¶‰∏îÊ†πÊìöÊàëÂÄëÁöÑ‰∫ÜËß£ÔºåÊèêÂá∫Á¨¨‰∏ÄÂÄãÂ§öË™ûË®ÄÈÜ´Â≠∏ÂïèÁ≠îË≥áÊñôÈõÜÔºåÂÖ∂‰∏≠Ëá®Â∫äÁóÖ‰æãÁöÑÊ≠£Á¢∫Âíå‰∏çÊ≠£Á¢∫Ë®∫Êñ∑ÈÉΩÈôÑÊúâÁî±ÈÜ´ÁîüÊí∞ÂØ´ÁöÑËá™ÁÑ∂Ë™ûË®ÄËß£Èáã„ÄÇÈÄô‰∫õËß£ÈáãÂ∑≤‰ΩøÁî®Ë´ñË≠âÁµÑÊàêÔºàÂç≥ÂâçÊèê„ÄÅ‰∏ªÂºµÔºâÂíåË´ñË≠âÈóú‰øÇÔºàÂç≥ÊîªÊìä„ÄÅÊîØÊåÅÔºâÈÄ≤Ë°åÊâãÂãïË®ªËß£ÔºåÁî¢ÁîüÂ§öË™ûË®Ä CasiMedicos-Arg Ë≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ 558 ÂÄãÂÖ∑ÊúâËß£ÈáãÁöÑÂõõÁ®ÆË™ûË®ÄÔºàËã±Ë™û„ÄÅË•øÁè≠ÁâôË™û„ÄÅÊ≥ïË™û„ÄÅÁæ©Â§ßÂà©Ë™ûÔºâÁöÑËá®Â∫äÁóÖ‰æãÔºåÊàëÂÄëË®ªËß£‰∫Ü 5021 ÂÄã‰∏ªÂºµ„ÄÅ2313 ÂÄãÂâçÊèê„ÄÅ2431 ÂÄãÊîØÊåÅÈóú‰øÇÂíå 1106 ÂÄãÊîªÊìäÈóú‰øÇ„ÄÇÊàëÂÄëÊúÄÂæåÂ±ïÁ§∫‰∫ÜÁ´∂Áà≠Âü∫Ê∫ñÂ¶Ç‰ΩïÈáùÂ∞çË´ñË≠âÊé¢Âãò‰ªªÂãôÂü∑Ë°åÊ≠§ÂÖ∑ÊåëÊà∞ÊÄßÁöÑË≥áÊñôÈõÜ„ÄÇ

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v1 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

ÊëòË¶ÅÔºöË®∫Êñ∑È†êÊ∏¨ÊòØÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑ‰∏ÄÈ†ÖÈóúÈçµ‰ªªÂãôÔºåÂèäÊôÇ‰∏îÊ∫ñÁ¢∫Âú∞Ë≠òÂà•ÈÜ´ÁôÇÁãÄÊ≥ÅÊúÉÂ∞çÊÇ£ËÄÖÁöÑÁµêÊûúÁî¢ÁîüÈáçÂ§ßÂΩ±Èüø„ÄÇÂÇ≥Áµ±Ê©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂ∑≤Âú®Ê≠§È†òÂüüÂèñÂæóÈ°ØËëóÊàêÂäüÔºå‰ΩÜÈÄöÂ∏∏Áº∫‰πèÂèØËß£ÈáãÊÄßÔºåÈÄôÊòØËá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÈóúÈçµË¶ÅÊ±Ç„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÁ•ûÁ∂ìÁ¨¶ËôüÊñπÊ≥ïÔºåÁâπÂà•ÊòØÈÇèËºØÁ•ûÁ∂ìÁ∂≤Ë∑Ø (LNN)Ôºå‰ª•ÈñãÁôºÂèØËß£ÈáãÁöÑË®∫Êñ∑È†êÊ∏¨Ê®°Âûã„ÄÇÂü∫Êú¨‰∏äÔºåÊàëÂÄëË®≠Ë®à‰∏¶ÂØ¶‰Ωú‰∫ÜÂü∫Êñº LNN ÁöÑÊ®°ÂûãÔºåË©≤Ê®°ÂûãÈÄèÈÅéÈÇèËºØË¶èÂâáÂíåÂèØÂ≠∏ÁøíÁöÑÈñæÂÄºÊï¥ÂêàÈ†òÂüüÁâπÂÆöÁöÑÁü•Ë≠ò„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÔºåÁâπÂà•ÊòØ $M_{\text{multi-pathway}}$ Âíå $M_{\text{comprehensive}}$ÔºåË°®ÁèæÂá∫ÂÑ™ÊñºÂÇ≥Áµ±Ê®°ÂûãÔºàÂ¶ÇÈÇèËºØËø¥Ê≠∏„ÄÅSVM ÂíåÈö®Ê©üÊ£ÆÊûóÔºâÁöÑÂçìË∂äÊïàËÉΩÔºåÂú®Á≥ñÂ∞øÁóÖÈ†êÊ∏¨ÁöÑÊ°à‰æãÁ†îÁ©∂‰∏≠ÔºåÈÅîÂà∞‰∫ÜÊõ¥È´òÁöÑÊ∫ñÁ¢∫Â∫¶ÔºàÈ´òÈÅî 80.52%ÔºâÂíå AUROC ÂàÜÊï∏ÔºàÈ´òÈÅî 0.8457Ôºâ„ÄÇLNN Ê®°Âûã‰∏≠Â≠∏ÁøíÁöÑÊ¨äÈáçÂíåÈñæÂÄºÊèê‰æõ‰∫ÜÂ∞çÁâπÂæµË≤¢ÁçªÁöÑÁõ¥Êé•Ë¶ãËß£ÔºåÂ¢ûÂº∑‰∫ÜÂèØËß£ÈáãÊÄßÔºåÂêåÊôÇ‰∏çÊêçÂÆ≥È†êÊ∏¨ËÉΩÂäõ„ÄÇÈÄô‰∫õÁôºÁèæÁ™ÅÈ°Ø‰∫ÜÁ•ûÁ∂ìÁ¨¶ËôüÊñπÊ≥ïÂú®ÂΩåÂêàÈÜ´ÁôÇ‰øùÂÅ• AI ÊáâÁî®‰∏≠Ê∫ñÁ¢∫ÊÄßÂíåÂèØËß£ÈáãÊÄßÂ∑ÆË∑ùÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇÈÄèÈÅéÊèê‰æõÈÄèÊòé‰∏îÈÅ©ÊáâÊÄßÂº∑ÁöÑË®∫Êñ∑Ê®°ÂûãÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÊúâÂä©ÊñºÁ≤æÊ∫ñÈÜ´ÁôÇÁöÑÈÄ≤Ê≠•Ôºå‰∏¶ÊîØÊè¥ÂÖ¨Âπ≥ÈÜ´ÁôÇ‰øùÂÅ•Ëß£Ê±∫ÊñπÊ°àÁöÑÈñãÁôº„ÄÇÊú™‰æÜÁöÑÁ†îÁ©∂Â∞áÂ∞àÊ≥®ÊñºÂ∞áÈÄô‰∫õÊñπÊ≥ïÊì¥Â±ïÂà∞Êõ¥Â§ß‰∏îÊõ¥Â§öÊ®£ÂåñÁöÑË≥áÊñôÈõÜÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•È©óË≠âÂÖ∂Âú®‰∏çÂêåÈÜ´ÁôÇÁãÄÊ≥ÅÂíå‰∫∫Áæ§‰∏≠ÁöÑÈÅ©Áî®ÊÄß„ÄÇ

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÂø´ÈÄüÈÄ≤Â±ïÂæπÂ∫ïÊîπËÆä‰∫ÜÊô∫ÊÖßÈÜ´ÁôÇ‰øùÂÅ•ÔºåÊé®Âãï‰∫ÜÂèØÁ©øÊà¥ÊäÄË°ì„ÄÅÊåÅÁ∫åÁõ£ÊéßË£ùÁΩÆÂíåÊô∫ÊÖßË®∫Êñ∑Á≥ªÁµ±ÁöÑÂâµÊñ∞„ÄÇÁÑ∂ËÄåÔºåÂÆâÂÖ®ÊÄß„ÄÅÂèØËß£ÈáãÊÄß„ÄÅÁ©©ÂÅ•ÊÄßÂíåÊïàËÉΩÊúÄ‰Ω≥ÂåñÊåëÊà∞‰ªçÁÑ∂ÊòØËá®Â∫äÁí∞Â¢É‰∏≠Âª£Ê≥õÊé°Áî®ÁöÑÈóúÈçµÈöúÁ§ô„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊºîÁÆóÊ≥ïÊñπÊ≥ïÔºå‰ΩøÁî®Ëá™ÈÅ©ÊáâÁâπÂæµË©ï‰º∞Âô® (AFE) ÊºîÁÆóÊ≥ï‰æÜÊîπÂñÑÈÜ´ÁôÇ‰øùÂÅ•Ë≥áÊñôÈõÜ‰∏≠ÁöÑÁâπÂæµÈÅ∏Âèñ‰∏¶ÂÖãÊúçÂïèÈ°å„ÄÇAFE Êï¥Âêà‰∫ÜÈÅ∫ÂÇ≥ÊºîÁÆóÊ≥ï (GA)„ÄÅÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÂíåÊéíÂàóÁµÑÂêàÊäÄË°ì (PCT)ÔºåË©≤ÊºîÁÆóÊ≥ïÊúÄ‰Ω≥Âåñ‰∫ÜËá®Â∫äÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ± (CDSS)ÔºåÂæûËÄåÊèêÈ´ò‰∫ÜÈ†êÊ∏¨Ê∫ñÁ¢∫ÊÄßÂíåÂèØËß£ÈáãÊÄß„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ï‰ΩøÁî®ÂÖ≠Á®Æ‰∏çÂêåÁöÑÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïÈ©óË≠â‰∫Ü‰∏âÂÄã‰∏çÂêåÁöÑÈÜ´ÁôÇ‰øùÂÅ•Ë≥áÊñôÈõÜÔºåË≠âÊòé‰∫ÜÂÖ∂Á©©ÂÅ•ÊÄßÂíåÂÑ™ÊñºÂÇ≥Áµ±ÁâπÂæµÈÅ∏ÂèñÊäÄË°ì„ÄÇÁµêÊûúÂº∑Ë™ø‰∫Ü AFE Âú®Êô∫ÊÖßÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑËΩâËÆäÊΩõÂäõÔºåÂØ¶Áèæ‰∫ÜÂÄã‰∫∫ÂåñÂíåÈÄèÊòéÁöÑÊÇ£ËÄÖÁÖßË≠∑„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåAFE ÊºîÁÆóÊ≥ïËàáÂ§öÂ±§ÊÑüÁü•Âô® (MLP) ÁµêÂêà‰ΩøÁî®ÊôÇÔºåÊ∫ñÁ¢∫Â∫¶È´òÈÅî 98.5%ÔºåÁ™ÅÈ°Ø‰∫ÜÂÖ∂ÊîπÂñÑÂØ¶ÈöõÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®‰∏≠Ëá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÊµÅÁ®ãÁöÑËÉΩÂäõ„ÄÇ

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) Á≥ªÁµ±Â∑≤Â§ßÂπÖÊîπÂñÑÁöÆËÜöÁßëÈÜ´Â∏´Â∞çÈªëËâ≤Á¥†Áò§ÁöÑË®∫Êñ∑Ê∫ñÁ¢∫Â∫¶ÔºåËÄåÂèØËß£Èáã AI (XAI) Á≥ªÁµ±ÈÄ≤‰∏ÄÊ≠•ÊèêÂçáËá®Â∫äÈÜ´Â∏´Â∞ç AI È©ÖÂãïÊ±∫Á≠ñÁöÑ‰ø°ÂøÉËàá‰ø°Ë≥¥„ÄÇÂÑòÁÆ°ÊúâÈÄô‰∫õÈÄ≤Â±ïÔºåÂ∞çÊñºÁöÆËÜöÁßëÈÜ´Â∏´Â¶Ç‰Ωï‰ΩøÁî® AI Âíå XAI Â∑•ÂÖ∑Ôºå‰ªçÊúâÂÆ¢ËßÄË©ï‰º∞ÁöÑËø´ÂàáÈúÄÊ±Ç„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠Ôºå76 ‰ΩçÁöÆËÜöÁßëÈÜ´Â∏´ÂèÉËàá‰∫Ü‰∏ÄÈ†ÖËÆÄËÄÖÁ†îÁ©∂Ôºå‰ΩøÁî® XAI Á≥ªÁµ±Ë®∫Êñ∑ 16 ÂºµÈªëËâ≤Á¥†Áò§ÂíåÁó£ÁöÑÁöÆËÜöÈè°ÂΩ±ÂÉèÔºåË©≤Á≥ªÁµ±Êèê‰æõË©≥Á¥∞ÁöÑÈ†òÂüüÁâπÂÆöË™™Êòé„ÄÇÊé°Áî®ÁúºÁêÉËøΩËπ§ÊäÄË°ì‰æÜË©ï‰º∞‰ªñÂÄëÁöÑ‰∫íÂãï„ÄÇÂ∞áË®∫Êñ∑Ë°®ÁèæËàáÁº∫‰πèË™™ÊòéÂäüËÉΩÁöÑÊ®ôÊ∫ñ AI Á≥ªÁµ±ÈÄ≤Ë°åÊØîËºÉ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåXAI Á≥ªÁµ±Áõ∏ËºÉÊñºÊ®ôÊ∫ñ AIÔºåÂ∞áÂπ≥Ë°°Ë®∫Êñ∑Ê∫ñÁ¢∫Â∫¶ÊèêÂçá‰∫Ü 2.8 ÂÄãÁôæÂàÜÈªû„ÄÇÊ≠§Â§ñÔºåËàá AI/XAI Á≥ªÁµ±ÁöÑË®∫Êñ∑ÂàÜÊ≠ßÂíåË§áÈõúÁöÑÁóÖÁÅ∂ËàáË™çÁü•Ë≤†ÊìîÂçáÈ´òÊúâÈóúÔºåÈÄôÁî±Â¢ûÂä†ÁöÑÁúºÁùõÊ≥®Ë¶ñÊ¨°Êï∏ÊâÄË≠âÂØ¶„ÄÇÈÄô‰∫õË¶ãËß£Â∞çËá®Â∫äÂØ¶Âãô„ÄÅË¶ñË¶∫‰ªªÂãô AI Â∑•ÂÖ∑ÁöÑË®≠Ë®àÂíåÈÜ´Â≠∏Ë®∫Êñ∑‰∏≠ XAI ÁöÑÂª£Ê≥õÁôºÂ±ïÂÖ∑ÊúâÈáçÂ§ßÊÑèÁæ©„ÄÇ

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

ÊëòË¶ÅÔºöËá™ÈñâÁóáË≠úÁ≥ªÈöúÁ§ô (ASD) ÁöÑÊó©ÊúüË®∫Êñ∑Âíå‰ªãÂÖ•Â∑≤Ë¢´Ë≠âÂØ¶ËÉΩÈ°ØËëóÊîπÂñÑËá™ÈñâÁóáÊÇ£ËÄÖÁöÑÁîüÊ¥ªÂìÅË≥™„ÄÇÁÑ∂ËÄåÔºåASD ÁöÑË®∫Êñ∑ÊñπÊ≥ï‰æùË≥¥ÊñºÂü∫ÊñºËá®Â∫äË°®ÁèæÁöÑË©ï‰º∞ÔºåÂÆπÊòìÁî¢ÁîüÂÅèË¶ãÔºå‰∏îÂèØËÉΩÈõ£‰ª•ÂÅöÂá∫Êó©ÊúüË®∫Êñ∑„ÄÇÊúâÂøÖË¶ÅÊâæÂá∫ ASD ÁöÑÂÆ¢ËßÄÁîüÁâ©Ê®ôË®òÔºå‰ª•Âπ´Âä©ÊèêÈ´òË®∫Êñ∑Ê∫ñÁ¢∫ÊÄß„ÄÇÊ∑±Â∫¶Â≠∏Áøí (DL) Âú®ÂæûÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñôË®∫Êñ∑ÁñæÁóÖÂíåÁóÖÁóáÊñπÈù¢ÂèñÂæóÂÇëÂá∫ÁöÑË°®Áèæ„ÄÇÂ∑≤Á∂ìÈáùÂ∞çÂª∫Á´ã‰ΩøÁî®ÈùúÊÖãÂäüËÉΩÊÄßÁ£ÅÊåØÈÄ†ÂΩ± (fMRI) Ë≥áÊñôÂ∞ç ASD ÈÄ≤Ë°åÂàÜÈ°ûÁöÑÊ®°ÂûãÈÄ≤Ë°åÂª£Ê≥õÁöÑÁ†îÁ©∂„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÊ®°ÂûãÁº∫‰πèÂèØËß£ÈáãÊÄß„ÄÇÊú¨Á†îÁ©∂Êó®Âú®ÈÄèÈÅéÂª∫Á´ã‰∏ÄÂÄã‰∏çÂÉÖËÉΩÊ∫ñÁ¢∫ÂàÜÈ°û ASDÔºåÈÇÑËÉΩÊèê‰æõÂèØËß£ÈáãË¶ãËß£Ë™™ÊòéÂÖ∂ÈÅã‰ΩúÂéüÁêÜÁöÑ DL Ê®°ÂûãÔºå‰æÜÊîπÂñÑ ASD Ë®∫Êñ∑ÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂèØËß£ÈáãÊÄß„ÄÇÊâÄ‰ΩøÁî®ÁöÑË≥áÊñôÈõÜÊòØËá™ÈñâÁóáÂ§ßËÖ¶ÂΩ±ÂÉèË≥áÊñô‰∫§Êèõ (ABIDE) ÁöÑÈ†êËôïÁêÜÁâàÊú¨ÔºåÂåÖÂê´ 884 ÂÄãÊ®£Êú¨„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåË©≤Ê®°ÂûãËÉΩÊ∫ñÁ¢∫ÂàÜÈ°û ASDÔºå‰∏¶Âº∑Ë™ø ASD ËàáÂÖ∏ÂûãÂ∞çÁÖßÁµÑ‰πãÈñìÂ≠òÂú®Â∑ÆÁï∞ÁöÑÈóúÈçµËÖ¶ÂçÄÔºåÂ∞çÊñº ASD ÁöÑÊó©ÊúüË®∫Êñ∑ÂíåÁ•ûÁ∂ìÂü∫Á§éÁöÑÁêÜËß£ÂÖ∑ÊúâÊΩõÂú®ÁöÑÊÑèÁæ©„ÄÇÈÄô‰∫õÁ†îÁ©∂ÁµêÊûúÂ∑≤Áî±‰ΩøÁî®‰∏çÂêåË≥áÊñôÈõÜÂíåÊñπÂºèÁöÑÊñáÁçªÁ†îÁ©∂È©óË≠âÔºåË≠âÂØ¶Ë©≤Ê®°ÂûãÂØ¶Èöõ‰∏äÂ≠∏Áøí‰∫Ü ASD ÁöÑÁâπÂæµÔºåËÄå‰∏çÂÉÖÂÉÖÊòØË≥áÊñôÈõÜ„ÄÇÊú¨Á†îÁ©∂ÈÄèÈÅéÊèê‰æõ‰∏ÄÂÄãÂº∑ÂÅ•‰∏îÂèØËß£ÈáãÁöÑÊ®°ÂûãÔºåÊé®Âãï‰∫ÜÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÂèØËß£Èáã AI ÁöÑÈ†òÂüüÔºåÂæûËÄåÁÇ∫Êú™‰æÜÊèê‰æõÂÆ¢ËßÄ‰∏îÂèØÈù†ÁöÑ ASD Ë®∫Êñ∑ÂÅöÂá∫Ë≤¢Áçª„ÄÇ

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, Cl√©ment Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

ÊëòË¶ÅÔºöÂ∞øË∑ØÈè°Ê™¢Êü•‰∏≠ËÖéÁµêÁü≥È°ûÂûãÁöÑÈ´îÂÖßË≠òÂà•Â∞áÊòØÊ≥åÂ∞øÁßëÁöÑ‰∏ÄÈ†ÖÈáçÂ§ßÈÄ≤Â±ïÔºåÂõ†ÁÇ∫ÂÆÉÂèØ‰ª•Ê∏õÂ∞ëÁπÅÁë£ÁöÑËÖéÁµêÁü≥ÂèñÂá∫ÈÅéÁ®ãÁöÑÊôÇÈñìÔºåÂêåÊôÇÈôç‰ΩéÊÑüÊüìÈ¢®Èö™„ÄÇÊ≠§Â§ñÔºåÈÄôÁ®ÆËá™ÂãïÂåñÁ®ãÂ∫èÂ∞á‰ΩøÁ´ãÂç≥ÈñãÁ´ãÊäóÂæ©ÁôºÊ≤ªÁôÇÊàêÁÇ∫ÂèØËÉΩ„ÄÇÂ¶Ç‰ªäÔºåÂè™ÊúâÂ∞ëÊï∏Á∂ìÈ©óË±êÂØåÁöÑÊ≥åÂ∞øÁßëÈÜ´ÁîüËÉΩÂ§†Âú®ÂÖßË¶ñÈè°Ê™¢Êü•ÊúüÈñìÂ±èÂπï‰∏äÈ°ØÁ§∫ÁöÑË¶ñÈ†ªÂúñÂÉè‰∏≠Ë≠òÂà•ËÖéÁµêÁü≥È°ûÂûã„ÄÇÂõ†Ê≠§ÔºåÊúÄËøëÂ∑≤ÊèêÂá∫Â§öÁ®ÆÊ∑±Â∫¶Â≠∏Áøí (DL) Ê®°ÂûãÔºå‰ª•‰ΩøÁî®Ëº∏Â∞øÁÆ°Èè°ÂúñÂÉèËá™ÂãïË≠òÂà•ËÖéÁµêÁü≥È°ûÂûã„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õ DL Ê®°ÂûãÊú¨Ë≥™‰∏äÊòØÈªëÁõíÂ≠êÔºåÈÄôÈôêÂà∂‰∫ÜÂÆÉÂÄëÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊáâÁî®ÊÄß„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÊ°à‰æãÊé®ÁêÜÁöÑ DL Ê®°ÂûãÔºåÂÆÉ‰ΩøÁî®ÂéüÂûãÈÉ®ÂàÜ (PP) ‰∏¶ÁîüÊàêÂ±ÄÈÉ®ÂíåÂÖ®Â±ÄÊèèËø∞Á¨¶„ÄÇPP ÁÇ∫ÊØèÁ®ÆÈ°ûÂûãÔºàÂç≥ËÖéÁµêÁü≥È°ûÂûãÔºâÁ∑®Á¢ºË¶ñË¶∫ÁâπÂæµ‰ø°ÊÅØÔºàËâ≤Ë™ø„ÄÅÈ£ΩÂíåÂ∫¶„ÄÅÂº∑Â∫¶ÂíåÁ¥ãÁêÜÔºâÔºåÈ°û‰ººÊñºÁîüÁâ©Â≠∏ÂÆ∂‰ΩøÁî®ÁöÑ‰ø°ÊÅØ„ÄÇÁî±ÊñºÂú®Ê®°ÂûãË®ìÁ∑¥ÊúüÈñì‰ΩøÁî®ÁöÑÊñ∞ÊêçÂ§±ÂáΩÊï∏ÔºåPP ÂæóÂà∞‰∫ÜÊúÄ‰Ω≥ÁîüÊàê„ÄÇÊ≠§Â§ñÔºåPP ÁöÑÂ±ÄÈÉ®ÂíåÂÖ®Â±ÄÊèèËø∞Á¨¶ÂÖÅË®±‰ª•ÁîüÁâ©Â≠∏ÂÆ∂ÂíåÊ≥åÂ∞øÁßëÈÜ´ÁîüÂèØ‰ª•ÁêÜËß£ÁöÑÊñπÂºèËß£ÈáãÊ±∫Á≠ñÔºà‚Äú‰ªÄÈ∫º‚Äù‰ø°ÊÅØÔºå‚ÄúÂúñÂÉè‰∏≠ÁöÑ‰ªÄÈ∫º‰ΩçÁΩÆ‚ÄùÔºâ„ÄÇÊâÄÊèêÂá∫ÁöÑ DL Ê®°ÂûãÂ∑≤Âú®‰∏ÄÂÄãÂåÖÂê´ÂÖ≠Á®ÆÊúÄÂª£Ê≥õÁöÑËÖéÁµêÁü≥È°ûÂûãÂúñÂÉèÁöÑÊï∏ÊìöÂ∫´‰∏äÈÄ≤Ë°å‰∫ÜÊ∏¨Ë©¶„ÄÇÁ∏ΩÈ´îÂπ≥ÂùáÂàÜÈ°ûÊ∫ñÁ¢∫ÁéáÁÇ∫ 90.37„ÄÇÂ∞áÊ≠§ÁµêÊûúËàáËÖéÁµêÁü≥ÊúÄÂÖàÈÄ≤ÁöÑÂÖ´ÂÄãÂÖ∂‰ªñ DL Ê®°ÂûãÁöÑÁµêÊûúÈÄ≤Ë°åÊØîËºÉÊôÇÔºåÂèØ‰ª•ÁúãÂá∫ÔºåÂèØËß£ÈáãÊÄßÁöÑÂØ∂Ë≤¥Â¢ûÁõä‰∏¶Êú™‰ª•Ê∫ñÁ¢∫ÊÄßÁÇ∫‰ª£ÂÉπÔºåÁîöËá≥Áï•ÊúâÂ¢ûÂä†ËàáÊñáÁçª‰∏≠ÊúÄÂ•ΩÁöÑÊñπÊ≥ï (88.2) Áõ∏ÊØî„ÄÇÈÄô‰∫õÊúâÂ∏åÊúõ‰∏îÂèØËß£ÈáãÁöÑÁµêÊûú‰πüÈºìÂãµÊ≥åÂ∞øÁßëÈÜ´ÁîüÁõ∏‰ø°Âü∫Êñº‰∫∫Â∑•Êô∫ËÉΩÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v3 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®éÂà©Áî®Ë°åÊîøÁî≥Â†±Ë≥áÊñôÔºåÁµêÂêàÂÖàÈÄ≤Ê©üÂô®Â≠∏ÁøíËàáÊ∑±Â∫¶Â≠∏ÁøíÊäÄË°ìÔºåÈ†êÊ∏¨ÊÖ¢ÊÄßËÖéËáüÁóÖ (CKD) ÈÄ≤Â±ïËá≥Êú´ÊúüËÖéËáüÁñæÁóÖ (ESRD) ÁöÑÂèØËÉΩÊÄß„ÄÇÊàëÂÄëÂàÜÊûê‰∏ÄÂÆ∂Â§ßÂûãÂÅ•Â∫∑‰øùÈö™ÁµÑÁπîÊèê‰æõÁöÑ 10 Âπ¥Á∂úÂêàË≥áÊñôÈõÜÔºå‰ΩøÁî®ÂÇ≥Áµ±Ê©üÂô®Â≠∏ÁøíÊñπÊ≥ïÔºà‰æãÂ¶ÇÈö®Ê©üÊ£ÆÊûóÂíå XGBoostÔºâ‰ª•ÂèäÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÔºà‰æãÂ¶ÇÈï∑ÊúüÁü≠ÊúüË®òÊÜ∂ (LSTM) Á∂≤Ë∑ØÔºâÈñãÁôºÂ§öÂÄãËßÄÂØüË¶ñÁ™óÁöÑÈ†êÊ∏¨Ê®°Âûã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåLSTM Ê®°ÂûãÔºàÂ∞§ÂÖ∂ÊòØ 24 ÂÄãÊúàËßÄÂØüË¶ñÁ™óÔºâÂú®È†êÊ∏¨ ESRD ÈÄ≤Â±ïÊñπÈù¢Ë°®ÁèæÂÑ™Áï∞ÔºåÂÑ™ÊñºÊñáÁçª‰∏≠ÁöÑÁèæÊúâÊ®°Âûã„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÊáâÁî® SHapley ÂèØÂä†ÊÄßËß£Èáã (SHAP) ÂàÜÊûê‰ª•Â¢ûÂº∑ÂèØËß£ÈáãÊÄßÔºåÊ∑±ÂÖ•‰∫ÜËß£ÂÄãÂà•ÁâπÂæµÂ∞çÂÄãÂà•ÊÇ£ËÄÖÂ±§Á¥öÈ†êÊ∏¨ÁöÑÂΩ±Èüø„ÄÇÊú¨Á†îÁ©∂Âº∑Ë™ø‰∫ÜÂà©Áî®Ë°åÊîøÁî≥Â†±Ë≥áÊñôÈÄ≤Ë°å CKD ÁÆ°ÁêÜÂíåÈ†êÊ∏¨ ESRD ÈÄ≤Â±ïÁöÑÂÉπÂÄº„ÄÇ

##### **Explainable AI: Definition and attributes of a good explanation for health AI**
2409.15338v1 by Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group

Proposals of artificial intelligence (AI) solutions based on increasingly
complex and accurate predictive models are becoming ubiquitous across many
disciplines. As the complexity of these models grows, transparency and users'
understanding often diminish. This suggests that accurate prediction alone is
insufficient for making an AI-based solution truly useful. In the development
of healthcare systems, this introduces new issues related to accountability and
safety. Understanding how and why an AI system makes a recommendation may
require complex explanations of its inner workings and reasoning processes.
Although research on explainable AI (XAI) has significantly increased in recent
years and there is high demand for XAI in medicine, defining what constitutes a
good explanation remains ad hoc, and providing adequate explanations continues
to be challenging. To fully realize the potential of AI, it is critical to
address two fundamental questions about explanations for safety-critical AI
applications, such as health-AI: (1) What is an explanation in health-AI? and
(2) What are the attributes of a good explanation in health-AI? In this study,
we examined published literature and gathered expert opinions through a
two-round Delphi study. The research outputs include (1) a definition of what
constitutes an explanation in health-AI and (2) a comprehensive list of
attributes that characterize a good explanation in health-AI.

ÊëòË¶ÅÔºöÈö®ËëóË∂ä‰æÜË∂äË§áÈõú‰∏îÊ∫ñÁ¢∫ÁöÑÈ†êÊ∏¨Ê®°ÂûãÔºåÂü∫Êñº‰∫∫Â∑•Êô∫ÊÖß (AI) Ëß£Ê±∫ÊñπÊ°àÁöÑÊèêÊ°àÂú®Ë®±Â§öÈ†òÂüü‰∏≠ËÆäÂæóÁÑ°Ëôï‰∏çÂú®„ÄÇÈö®ËëóÈÄô‰∫õÊ®°ÂûãË§áÈõúÊÄßÁöÑÂ¢ûÂä†ÔºåÈÄèÊòéÂ∫¶Âíå‰ΩøÁî®ËÄÖÁöÑÁêÜËß£ÂäõÂæÄÂæÄÊúÉÈôç‰Ωé„ÄÇÈÄôË°®Á§∫ÂÉÖÊúâÊ∫ñÁ¢∫ÁöÑÈ†êÊ∏¨‰∏¶‰∏çË∂≥‰ª•ËÆì AI Ëß£Ê±∫ÊñπÊ°àÁúüÊ≠£ÊúâÁî®„ÄÇÂú®ÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±ÁöÑÈñãÁôº‰∏≠ÔºåÈÄôÂºïÂÖ•‰∫ÜËàáÂïèË≤¨Âà∂ÂíåÂÆâÂÖ®ÊÄßÁõ∏ÈóúÁöÑÊñ∞ÂïèÈ°å„ÄÇÁû≠Ëß£ AI Á≥ªÁµ±Â¶Ç‰Ωï‰ª•ÂèäÁÇ∫‰ΩïÊèêÂá∫Âª∫Ë≠∞ÂèØËÉΩÈúÄË¶ÅÂ∞çÂÖ∂ÂÖßÈÉ®ÈÅã‰ΩúÂíåÊé®ÁêÜÈÅéÁ®ãÈÄ≤Ë°åË§áÈõúÁöÑË™™Êòé„ÄÇÂÑòÁÆ°ËøëÂπ¥‰æÜÂ∞çÂèØËß£Èáã AI (XAI) ÁöÑÁ†îÁ©∂Â∑≤Â§ßÂπÖÂ¢ûÂä†Ôºå‰∏îÈÜ´Â≠∏È†òÂüüÂ∞ç XAI ÊúâÂæàÈ´òÁöÑÈúÄÊ±ÇÔºå‰ΩÜÂÆöÁæ©‰ªÄÈ∫ºÊßãÊàê‰∏ÄÂÄãÂ•ΩÁöÑËß£Èáã‰ªçÊòØËá®ÊôÇÊÄßÁöÑÔºåËÄåÊèê‰æõÈÅ©Áï∂ÁöÑËß£Èáã‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÁÇ∫‰∫ÜÂÖÖÂàÜÁôºÊèÆ AI ÁöÑÊΩõÂäõÔºåÂ∞çÊñºÂÆâÂÖ®ÈóúÈçµÂûã AI ÊáâÁî®Ôºà‰æãÂ¶ÇÂÅ•Â∫∑ AIÔºâÁöÑËß£ÈáãÔºåÊé¢Ë®éÂÖ©ÂÄãÂü∫Êú¨ÂïèÈ°åËá≥ÈóúÈáçË¶ÅÔºö(1) ‰ªÄÈ∫ºÊòØÂÅ•Â∫∑ AI ‰∏≠ÁöÑËß£ÈáãÔºü‰ª•Âèä (2) ÂÅ•Â∫∑ AI ‰∏≠‰∏ÄÂÄãÂ•ΩÁöÑËß£ÈáãÊúâÂì™‰∫õÂ±¨ÊÄßÔºüÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊ™¢Ë¶ñ‰∫ÜÂ∑≤ÁôºË°®ÁöÑÊñáÁçªÔºå‰∏¶ÈÄèÈÅéÂÖ©Ëº™Âæ∑ÁàæËè≤Á†îÁ©∂Êî∂ÈõÜ‰∫ÜÂ∞àÂÆ∂ÊÑèË¶ã„ÄÇÁ†îÁ©∂ÊàêÊûúÂåÖÊã¨Ôºö(1) ÂÅ•Â∫∑ AI ‰∏≠‰ªÄÈ∫ºÊßãÊàêËß£ÈáãÁöÑÂÆöÁæ©Ôºå‰ª•Âèä (2) ÂÅ•Â∫∑ AI ‰∏≠‰∏ÄÂÄãÂ•ΩËß£ÈáãÁöÑÂ±¨ÊÄßÊ∏ÖÂñÆ„ÄÇ

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

ÊëòË¶ÅÔºö<paragraph>ËøëÂπ¥‰æÜÔºåÂ∑≤Á∂ìÂºïÈÄ≤ÂêÑÁ®ÆÊñπÊ≥ï‰æÜËß£Èáã„ÄåÈªëÁÆ±„ÄçAI Ê®°ÂûãÁöÑËº∏Âá∫„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâç‰∏¶‰∏çÊ∏ÖÊ•ö‰ΩøÁî®ËÄÖÊòØÂê¶ÂØ¶ÈöõÁêÜËß£Âíå‰ø°‰ªªÈÄô‰∫õËß£Èáã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºË©ï‰º∞ÁôåÁóáÈ¢®Èö™ÁöÑÂõûÊ≠∏Â∑•ÂÖ∑ÁöÑËß£ÈáãÔºå‰∏¶Êé¢Ë®éËß£ÈáãÁöÑÂÖßÂÆπÂíåÊ†ºÂºèÂ∞ç‰ª•‰ΩøÁî®ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑÁêÜËß£Âíå‰ø°‰ªªÊåáÊ®ôÁöÑÂΩ±Èüø„ÄÇÈóúÊñºÂÖßÂÆπÔºåÊàëÂÄëÂØ¶È©ó‰∫ÜÂÖ©Á®ÆËß£ÈáãÊñπÊ≥ïÔºöÊµÅË°åÁöÑ SHAPÔºåÂü∫ÊñºÂçöÂºàË´ñÊ¶ÇÂøµÔºåÂõ†Ê≠§Â∞çÊñºÊó•Â∏∏‰ΩøÁî®ËÄÖ‰æÜË™™ÂèØËÉΩÂæàË§áÈõúÔºå‰ª•ÂèäÂü∫ÊñºÁâπÂæµÈÅÆËîΩÁöÑ occlusion-1ÔºåÂèØËÉΩÊõ¥ÊòìÊñºÁêÜËß£„ÄÇÈóúÊñºÊ†ºÂºèÔºåÊàëÂÄëÂ∞á SHAP Ëß£ÈáãÂëàÁèæÁÇ∫ÂúñË°® (SC)ÔºåÈÄôÊòØÊÖ£‰æãÔºåËÄåÂ∞á occlusion-1 Ëß£ÈáãÂëàÁèæÁÇ∫ÂúñË°® (OC) ‰ª•ÂèäÊñáÂ≠ó (OT)ÔºåÂÖ∂ËºÉÁÇ∫Á∞°ÂñÆÁöÑÊÄßË≥™‰πüÈÅ©Áî®ÊñºÊ≠§„ÄÇÈÄô‰∫õÂØ¶È©óÁ≠âÂêåÊñº‰ΩøÁî®ËÄÖÁ†îÁ©∂ÔºåË©¢ÂïèÂèÉËàáËÄÖÔºåÂÖ∑ÊúâÂÖ©Á®Æ‰∏çÂêåÁ®ãÂ∫¶ÁöÑÂ∞àÊ•≠Áü•Ë≠òÔºà‰∏ÄËà¨Ê∞ëÁúæÂíåÂÖ∑ÂÇô‰∏Ä‰∫õÈÜ´Â≠∏Ë®ìÁ∑¥ÁöÑ‰∫∫ÔºâÔºå‰ªñÂÄëÂ∞çÂõûÊ≠∏Â∑•ÂÖ∑Ëº∏Âá∫Ëß£ÈáãÁöÑ‰∏ªËßÄÂíåÂÆ¢ËßÄÁêÜËß£Âíå‰ø°‰ªª„ÄÇÂú®ÂÖ©È†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÁôºÁèæÔºåÂú®Âü∫ÊñºÂÖßÂÆπÈÄ≤Ë°åÊØîËºÉÊôÇÔºå‰∏ÄËà¨‰æÜË™™Ôºåocclusion-1 ÂÑ™Êñº SHAP Ëß£ÈáãÔºåÂú®‰∏ªËßÄÁêÜËß£Âíå‰ø°‰ªªÊñπÈù¢ÊúâÊòéÈ°ØÁöÑÂÅèÂ•Ω„ÄÇÁÑ∂ËÄåÔºåÂú®ÂÉÖÊéßÂà∂Ê†ºÂºèÁöÑÊÉÖÊ≥Å‰∏ãÁõ¥Êé•ÊØîËºÉËß£ÈáãÔºåÂú®Â§ßÂ§öÊï∏ÊÉÖÊ≥Å‰∏ãÂè™È°ØÁ§∫ OT ÂÑ™Êñº SC Ëß£ÈáãÁöÑË≠âÊìöÔºåÈÄôË°®Êòé occlusion-1 ÂÑ™Êñº SHAP Ëß£ÈáãÁöÑ‰∏ªÂ∞éÂú∞‰ΩçÂèØËÉΩÊòØÁî±ÂÅèÂ•ΩÊñáÂ≠óËÄåÈùûÂúñË°®‰ΩúÁÇ∫Ëß£ÈáãÊâÄÈ©ÖÂãïÁöÑ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊ≤íÊúâÁôºÁèæËß£ÈáãÈ°ûÂûãÂú®ÂÆ¢ËßÄÁêÜËß£ÊñπÈù¢ÁöÑÂ∑ÆÁï∞Ë≠âÊìö„ÄÇÂõ†Ê≠§ÔºåÁ∏ΩÈ´îËÄåË®ÄÔºåÂ∞çËß£ÈáãÁöÑÂÖßÂÆπÂíåÊ†ºÂºèÁöÑÈÅ∏ÊìáÈúÄË¶Å‰ªîÁ¥∞Ê≥®ÊÑèÔºåÂõ†ÁÇ∫Âú®Êüê‰∫õÊÉÖÊ≥Å‰∏ãÔºåÊ†ºÂºèËÄåÈùûÂÖßÂÆπÔºåÂèØËÉΩÂú®ÊîπÂñÑ‰ΩøÁî®ËÄÖÈ´îÈ©óÊñπÈù¢ÁôºÊèÆÈóúÈçµ‰ΩúÁî®„ÄÇ</paragraph>

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro Li√≤, Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞Á™ÅÁ†¥Êèê‰æõ‰∫ÜÂâçÊâÄÊú™ÊúâÁöÑËá™ÁÑ∂Ë™ûË®ÄÁêÜËß£ÂíåÁîüÊàêËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÈóúÊñºÁîüÁâ©ÈÜ´Â≠∏‰∏≠ LLM ÁöÑË™øÊü•ÈÄöÂ∏∏Â∞àÊ≥®ÊñºÁâπÂÆöÊáâÁî®ÊàñÊ®°ÂûãÊû∂ÊßãÔºåÁº∫‰πèÊï¥ÂêàÂêÑÁ®ÆÁîüÁâ©ÈÜ´Â≠∏È†òÂüüÊúÄÊñ∞ÈÄ≤Â±ïÁöÑÂÖ®Èù¢ÂàÜÊûê„ÄÇÊú¨Á∂úËø∞Âü∫ÊñºÂ∞ç‰æÜËá™ PubMed„ÄÅWeb of Science Âíå arXiv Á≠âÊï∏ÊìöÂ∫´ÁöÑ 484 ÁØáÂá∫ÁâàÁâ©ÁöÑÂàÜÊûêÔºåÊ∑±ÂÖ•Êé¢Ë®é‰∫ÜÁîüÁâ©ÈÜ´Â≠∏‰∏≠ LLM ÁöÑÁï∂ÂâçÁèæÊ≥Å„ÄÅÊáâÁî®„ÄÅÊåëÊà∞ÂíåÂâçÊôØÔºåÂÖ∂ÁâπÈªûÊòØÈóúÊ≥®ÈÄô‰∫õÊ®°ÂûãÂú®ÁèæÂØ¶‰∏ñÁïåÁîüÁâ©ÈÜ´Â≠∏ËÉåÊôØ‰∏≠ÁöÑÂØ¶ÈöõÊáâÁî®„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÊé¢Ë®é‰∫Ü LLM Âú®Âª£Ê≥õÁöÑÁîüÁâ©ÈÜ´Â≠∏‰ªªÂãô‰∏≠ÁöÑÈõ∂Ê¨°Â≠∏ÁøíËÉΩÂäõÔºåÂåÖÊã¨Ë®∫Êñ∑ËºîÂä©„ÄÅËó•Áâ©ÁôºÁèæÂíåÂÄãÊÄßÂåñÈÜ´ÁôÇÁ≠âÔºå‰∏¶Âæû 137 È†ÖÈóúÈçµÁ†îÁ©∂‰∏≠Ê±≤ÂèñË¶ãËß£„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëË®éË´ñ‰∫Ü LLM ÁöÑÈÅ©ÊáâÁ≠ñÁï•ÔºåÂåÖÊã¨ÂñÆÊ®°ÊÖãÂíåÂ§öÊ®°ÊÖã LLM ÁöÑÂæÆË™øÊñπÊ≥ïÔºå‰ª•Â¢ûÂº∑ÂÆÉÂÄëÂú®Èõ∂Ê¨°Â≠∏ÁøíÁÑ°Ê≥ïÂØ¶ÁèæÁöÑÂ∞àÊ•≠ÁîüÁâ©ÈÜ´Â≠∏ËÉåÊôØ‰∏≠ÁöÑÊÄßËÉΩÔºå‰æãÂ¶ÇÈÜ´ÁôÇÂïèÈ°åËß£Á≠îÂíåÁîüÁâ©ÈÜ´Â≠∏ÊñáÁçªÁöÑÊúâÊïàËôïÁêÜ„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñ‰∫Ü LLM Âú®ÁîüÁâ©ÈÜ´Â≠∏È†òÂüüÈù¢Ëá®ÁöÑÊåëÊà∞ÔºåÂåÖÊã¨Êï∏ÊìöÈö±ÁßÅÂïèÈ°å„ÄÅÊ®°ÂûãÂèØËß£ÈáãÊÄßÊúâÈôê„ÄÅÊï∏ÊìöÈõÜË≥™ÈáèÂïèÈ°å‰ª•ÂèäÁî±ÊñºÁîüÁâ©ÈÜ´Â≠∏Êï∏ÊìöÁöÑÊïèÊÑüÊÄß„ÄÅÂ∞çÈ´òÂ∫¶ÂèØÈù†Ê®°ÂûãËº∏Âá∫ÁöÑÈúÄÊ±Ç‰ª•ÂèäÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÈÉ®ÁΩ≤ AI ÁöÑÂÄ´ÁêÜÂΩ±ÈüøËÄåÁî¢ÁîüÁöÑÂÄ´ÁêÜÂïèÈ°å„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÈÇÑÁ¢∫ÂÆö‰∫ÜÁîüÁâ©ÈÜ´Â≠∏‰∏≠ LLM Êú™‰æÜÁöÑÁ†îÁ©∂ÊñπÂêëÔºåÂåÖÊã¨Áî®Êñº‰øùË≠∑Êï∏ÊìöÈö±ÁßÅÁöÑËÅØÂêàÂ≠∏ÁøíÊñπÊ≥ï‰ª•ÂèäÊï¥ÂêàÂèØËß£Èáã AI ÊñπÊ≥ï‰ª•Â¢ûÂº∑ LLM ÁöÑÈÄèÊòéÂ∫¶„ÄÇ

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÂú®ÈÜ´ÁôÇÂíå‰øùÂÅ•ÊáâÁî®‰∏≠ÊäïÂÖ•‰∫ÜÂ§ßÈáèÁöÑÊäïË≥áÂíåÈñãÁôºÔºåÈÄ≤ËÄåÂ∞éËá¥ÈÜ´ÁôÇÊäÄË°ì‰∏≠ÁöÑÂÖàÈÄ≤ÊéßÂà∂Á≥ªÁµ±„ÄÇÁÑ∂ËÄåÔºåAI Á≥ªÁµ±ÁöÑ‰∏çÈÄèÊòéÊÄßÂºïÁôº‰∫ÜÂ∞çÊ≠§È°ûÊïèÊÑüÊáâÁî®‰∏≠ÊâÄÈúÄÂü∫Êú¨ÁâπÊÄßÁöÑÊìîÊÜÇÔºå‰æãÂ¶ÇÈÄèÊòéÂ∫¶ÂíåÂèØ‰ø°Â∫¶„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÈÄèÈÅéË™øÊü•‰∏ÄÂÄãÁ®ãÂ∫è‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÁî®ÊñºÈÅ∏ÊìáÊúÄÂÖÖÂàÜÁöÑÂèØËß£Èáã AIÔºàXAIÔºâÊñπÊ≥ïÔºå‰ª•Á¨¶ÂêàÊ≠êÁõüÊ≥ïË¶èÂú®ÈÜ´ÁôÇÂô®ÊùêÁöÑÊô∫ÊÖßÂûãÁîüÁâ©ÈõªÂ≠êÂ≠∏‰∏≠ÁöÑË™™ÊòéË¶ÅÊ±Ç„ÄÇÊé°Áî®ÁöÑÊñπÊ≥ïÂæûÈÄèÈÅéÂÖ∂ÊéßÂà∂Ê©üÂà∂ÔºàÈñãËø¥Ë∑Ø„ÄÅÈñâËø¥Ë∑ØÂíåÂçäÈñâËø¥Ë∑ØÁ≥ªÁµ±ÔºâÂ∞çÊô∫ÊÖßÂûãË£ùÁΩÆÈÄ≤Ë°åÂàÜÈ°ûÔºå‰∏¶Ê∑±ÂÖ•Êé¢Ë®éÂÖ∂ÊäÄË°ìÈñãÂßã„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂàÜÊûêÈÄô‰∫õÊ≥ïË¶è‰ª•ÂÆöÁæ©ÂÖ∂Â∞çÂêÑÁ®ÆË£ùÁΩÆÂíåÁõ∏ÈóúÁõÆÊ®ôÁöÑÂèØËß£ÈáãÊÄßË¶ÅÊ±Ç„ÄÇÂêåÊôÇÔºåÊàëÂÄëÈÄèÈÅéÂÖ∂Ë™™ÊòéÁõÆÊ®ôÂ∞ç XAI ÊñπÊ≥ïÈÄ≤Ë°åÂàÜÈ°û„ÄÇÈÄôÂÖÅË®±Â∞áÊ≥ïÂæãÂèØËß£ÈáãÊÄßË¶ÅÊ±ÇËàá XAI Ë™™ÊòéÁõÆÊ®ôÁõ∏ÂåπÈÖçÔºå‰∏¶Á¢∫ÂÆöÈÅ©Áï∂ÁöÑ XAI ÊºîÁÆóÊ≥ï‰æÜÈÅîÊàêÂÆÉÂÄë„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÊèê‰æõ‰∫ÜÂ∞çÂì™‰∫õ XAI ÊºîÁÆóÊ≥ïÊõ¥Á¨¶ÂêàÊ≠êÁõüÊ≥ïË¶è‰ª•ÈÅ©Áî®Êñº‰∏çÂêåÈ°ûÂûãÁöÑÈÜ´ÁôÇÂô®ÊùêÁöÑÁ¥∞Á∑ªÁêÜËß£„ÄÇÊàëÂÄëÈÄèÈÅé‰∏çÂêåÁ•ûÁ∂ìÊ§çÂÖ•Áâ©ÁöÑÂØ¶ÈöõÊ°à‰æãÁ†îÁ©∂‰æÜË≠âÊòéÈÄô‰∏ÄÈªûÔºåÂæûÊÖ¢ÊÄßÁñæÁóÖÁÆ°ÁêÜÂà∞ÂÖàÈÄ≤ÁöÑÁæ©ËÇ¢„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Â°´Ë£ú‰∫ÜÂ∞áÁîüÁâ©ÈõªÂ≠êÂ≠∏‰∏≠ÁöÑ XAI ÊáâÁî®ËàáÊ≠êÁõüÊ≥ïË¶èÁöÑÂö¥Ê†ºË¶èÂÆöÁõ∏Á¨¶ÁöÑÈáçË¶ÅÁ©∫ÁôΩ„ÄÇÂÆÉÁÇ∫ÈñãÁôº‰∫∫Âì°ÂíåÁ†îÁ©∂‰∫∫Âì°Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂØ¶Áî®ÁöÑÊû∂ÊßãÔºåÁ¢∫‰øùÂÖ∂ AI ÂâµÊñ∞ËÉΩ‰øÉÈÄ≤ÈÜ´ÁôÇÊäÄË°ì‰∏¶ÈÅµÂÆàÊ≥ïÂæãÂíåÈÅìÂæ∑Ê®ôÊ∫ñ„ÄÇ

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

ÊëòË¶ÅÔºöÊàëÂÄëÊé¢Á¥¢Ê∑±Â∫¶ÁîüÊàêÊ®°ÂûãÔºåÂú®ÈÜ´ÁôÇËÅØÈÇ¶Â≠∏ÁøíË®≠ÁΩÆ‰∏≠ÁîüÊàêÂü∫ÊñºÊ°à‰æãÁöÑË™™Êòé„ÄÇÈÄèÈÅéÂü∫ÊñºÊ°à‰æãÁöÑÂèØËß£ÈáãÊÄß‰æÜËß£Èáã AI Ê®°ÂûãÊ±∫Á≠ñÔºåÂ∞çÊñºÂ¢ûÂä†‰ø°‰ªª‰∏¶ÂÖÅË®± AI Âú®Ëá®Â∫äÂØ¶Âãô‰∏≠Âª£Ê≥õÊé°Áî®Ëá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÈÜ´ÁôÇ AI Ë®ìÁ∑¥ÁØÑ‰æãÊ≠£ËΩâÂêëËÅØÈÇ¶Â≠∏ÁøíË®≠ÁΩÆÔºå‰ª•Á¨¶ÂêàË≥áÊñô‰øùË≠∑Ê≥ïË¶è„ÄÇÂú®ËÅØÈÇ¶ÊÉÖÂ¢É‰∏≠ÔºåÈÅéÂéªÁöÑË≥áÊñôÂ∞çÁõÆÂâçÁöÑ‰ΩøÁî®ËÄÖËÄåË®ÄÊòØÁÑ°Ê≥ïÂèñÂæóÁöÑ„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄë‰ΩøÁî®Ê∑±Â∫¶ÁîüÊàêÊ®°Âûã‰æÜÁî¢Áîü‰øùË≠∑Èö±ÁßÅÂíåËß£ÈáãÊ±∫Á≠ñÁöÑÂêàÊàêÁØÑ‰æã„ÄÇÊàëÂÄëÁöÑÊ¶ÇÂøµÈ©óË≠âËëóÈáçÊñºËÉ∏ËÖîÁ©çÊ∂≤Ë®∫Êñ∑Ôºå‰∏¶‰ΩøÁî®ÂÖ¨ÈñãÂèØÂèñÂæóÁöÑËÉ∏ÈÉ® X ÂÖâË≥áÊñô„ÄÇ

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. Gru√ºhagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

ÊëòË¶ÅÔºöËªüÁµÑÁπîÂíåÈ™®È™ºËÖ´Áò§ÔºàSTBTÔºâÊòØÁΩïË¶ã„ÄÅË®∫Êñ∑ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÁóÖÁÅ∂ÔºåÂÖ∂Ëá®Â∫äË°åÁÇ∫ÂíåÊ≤ªÁôÇÊñπÊ≥ïÂêÑ‰∏çÁõ∏Âêå„ÄÇÈÄôÁØáÁ≥ªÁµ±ÊÄßÂõûÈ°ßÊèê‰æõ‰∫Ü‰ΩøÁî®ÊîæÂ∞ÑÂΩ±ÂÉèÈÄ≤Ë°åË®∫Êñ∑ÂíåÈ†êÂæåÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊñπÊ≥ïÁöÑÊ¶ÇËßÄÔºåÈáçÈªûË™™Êòé‰∫ÜËá®Â∫äËΩâË≠ØÁöÑÊåëÊà∞Ôºå‰∏¶Ë©ï‰º∞Á†îÁ©∂ËàáÈÜ´ÁôÇÂΩ±ÂÉè AI Ê†∏Êü•Ë°® (CLAIM) Âíå FUTURE-AI ÂèØ‰ø°Ë≥¥‰∏îÂèØÈÉ®ÁΩ≤ AI ÁöÑÂúãÈöõÂÖ±Ë≠òÊ∫ñÂâáÁöÑ‰∏ÄËá¥ÊÄßÔºå‰ª•‰øÉÈÄ≤ AI ÊñπÊ≥ïÁöÑËá®Â∫äËΩâË≠Ø„ÄÇÈÄôÁØáÂõûÈ°ßÊ∂µËìã‰∫ÜÂπæÂÄãÊõ∏ÁõÆË≥áÊñôÂ∫´‰∏≠ÁöÑÊñáÁçªÔºåÂåÖÊã¨Âú® 2024 Âπ¥ 7 Êúà 17 Êó•‰πãÂâçÁôºË°®ÁöÑË´ñÊñá„ÄÇÁ¥çÂÖ•‰∫Ü‰ª•ÊîæÂ∞ÑÁÇ∫Âü∫Á§éÁöÑ AI Ë®∫Êñ∑ÊàñÈ†êÂæåÂéüÁôºÊÄß STBT ÁöÑÂêåË°åË©ïÂØ©ÊúüÂàä‰∏≠ÁöÑÂéüÂßãÁ†îÁ©∂„ÄÇÊéíÈô§Ê®ôÊ∫ñÊòØÂãïÁâ©„ÄÅÂ±çÈ´îÊàñÂØ¶È©óÂÆ§Á†îÁ©∂Ôºå‰ª•ÂèäÈùûËã±ÊñáË´ñÊñá„ÄÇÊëòË¶ÅÁî±‰∏â‰ΩçÁç®Á´ãÂØ©Êü•Âì°‰∏≠ÁöÑÂÖ©‰ΩçÁØ©ÈÅ∏Ë≥áÊ†º„ÄÇÂêàÊ†ºÁöÑË´ñÊñáÁî±‰∏â‰ΩçÁç®Á´ãÂØ©Êü•Âì°‰∏≠ÁöÑ‰∏Ä‰ΩçÊ†πÊìöÊ∫ñÂâáÈÄ≤Ë°åË©ï‰º∞„ÄÇÊêúÁ¥¢Ë≠òÂà•Âá∫ 15,015 ÁØáÊëòË¶ÅÔºåÂÖ∂‰∏≠ 325 ÁØáÊñáÁ´†Ë¢´Á¥çÂÖ•Ë©ï‰º∞„ÄÇÂ§ßÂ§öÊï∏Á†îÁ©∂Âú® CLAIM ‰∏≠Ë°®Áèæ‰∏≠Á≠âÔºåÂπ≥ÂùáÂæóÂàÜÁÇ∫ 53 ÂàÜ‰∏≠ÁöÑ 28.9¬±7.5 ÂàÜÔºå‰ΩÜÂú® FUTURE-AI ‰∏≠Ë°®Áèæ‰∏ç‰Ω≥ÔºåÂπ≥ÂùáÂæóÂàÜÁÇ∫ 30 ÂàÜ‰∏≠ÁöÑ 5.1¬±2.1 ÂàÜ„ÄÇSTBT ÁöÑÂΩ±ÂÉè AI Â∑•ÂÖ∑‰ªçËôïÊñºÊ¶ÇÂøµÈ©óË≠âÈöéÊÆµÔºåË°®ÊòéÊúâÈ°ØËëóÁöÑÊîπÈÄ≤Á©∫Èñì„ÄÇAI ÈñãÁôº‰∫∫Âì°Êú™‰æÜÁöÑÂä™ÂäõÊáâÈõÜ‰∏≠Âú®Ë®≠Ë®àÔºà‰æãÂ¶ÇÂÆöÁæ©Êú™ÊªøË∂≥ÁöÑËá®Â∫äÈúÄÊ±Ç„ÄÅÈ†êÊúüÁöÑËá®Â∫äÁí∞Â¢É‰ª•Âèä AI Â¶Ç‰ΩïÊï¥ÂêàÂà∞Ëá®Â∫äÂ∑•‰ΩúÊµÅÁ®ã‰∏≠Ôºâ„ÄÅÈñãÁôºÔºà‰æãÂ¶ÇÂª∫Á´ãÂú®ÂÖàÂâçÁöÑÂ∑•‰Ωú„ÄÅÂèØËß£ÈáãÊÄßÔºâ„ÄÅË©ï‰º∞Ôºà‰æãÂ¶ÇË©ï‰º∞ÂíåËß£Ê±∫ÂÅèÂ∑Æ„ÄÅË©ï‰º∞ AI ËàáÊúÄ‰Ω≥ÂØ¶ÂãôÔºâ„ÄÅ‰ª•ÂèäÊï∏ÊìöÂèØË§áË£ΩÊÄßÂíåÂèØÁî®ÊÄßÔºàÂÖ¨ÈñãÊèê‰æõÊñá‰ª∂ÂåñÁöÑ‰ª£Á¢ºÂíåÊï∏ÊìöÔºâ„ÄÇÈÅµÂæ™ÈÄô‰∫õÂª∫Ë≠∞ÂèØ‰ª•ÊîπÂñÑ AI ÊñπÊ≥ïÁöÑËá®Â∫äËΩâË≠Ø„ÄÇ

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga Str√ºmke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

ÊëòË¶ÅÔºöËÖ¶ÊÄßÈ∫ªÁó∫ (CP) ÁöÑÊó©ÊúüÂÅµÊ∏¨Â∞çÊñºÊúâÊïàÁöÑ‰ªãÂÖ•ÂíåÁõ£Ê∏¨Ëá≥ÈóúÈáçË¶Å„ÄÇÊú¨ÊñáÊ∏¨Ë©¶‰∫ÜÂèØËß£Èáã AI (XAI) ÊñπÊ≥ïÁöÑÂèØÈù†ÊÄßÂíåÈÅ©Áî®ÊÄßÔºå‰ΩøÁî®Ê∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÔºåÈÄèÈÅéÂàÜÊûêÂæûÂ¨∞ÂÖíÂãï‰ΩúÂΩ±ÁâáË®òÈåÑ‰∏≠ÊèêÂèñÁöÑÈ™®È™ºË≥áÊñô‰æÜÈ†êÊ∏¨ CP„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄë‰ΩøÁî® XAI Ë©ï‰º∞ÊåáÊ®ôÔºàÂç≥Âø†ÂØ¶Â∫¶ÂíåÁ©©ÂÆöÊÄßÔºâ‰æÜÈáèÂåñË©ï‰º∞È°ûÂà•ÊøÄÊ¥ªÊò†Â∞Ñ (CAM) ÂíåÊ¢ØÂ∫¶Âä†Ê¨äÈ°ûÂà•ÊøÄÊ¥ªÊò†Â∞Ñ (Grad-CAM) Âú®ÈÄôÂÄãÁâπÂÆöÈÜ´ÁôÇÊáâÁî®‰∏≠ÁöÑÂèØÈù†ÊÄß„ÄÇÊàëÂÄëÂà©Áî®‰∏ÄÂÄãÁç®ÁâπÁöÑÂ¨∞ÂÖíÂãï‰ΩúË≥áÊñôÈõÜÔºå‰∏¶ÊáâÁî®È™®È™ºË≥áÊñôÊìæÂãïÔºåËÄå‰∏çÊúÉÊâ≠Êõ≤Â¨∞ÂÖíÂãï‰ΩúÁöÑÂéüÂßãÂãïÂäõ„ÄÇÊàëÂÄëÁöÑ CP È†êÊ∏¨Ê®°ÂûãÂà©Áî®Êï¥È´îÊñπÊ≥ïÔºåÂõ†Ê≠§ÊàëÂÄëË©ï‰º∞‰∫ÜÊï¥È´îÊï¥È´îÂíåÂÄãÂà•Ê®°ÂûãÁöÑ XAI ÊåáÊ®ôË°®Áèæ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÂÖ©Á®Æ XAI ÊñπÊ≥ïÈÉΩËÉΩÊúâÊïàË≠òÂà•ÂΩ±Èüø CP È†êÊ∏¨ÁöÑÈóúÈçµË∫´È´îÈÉ®‰ΩçÔºå‰∏¶‰∏îÈÄô‰∫õËß£ÈáãÂ∞çÊñºÂæÆÂ∞èÁöÑË≥áÊñôÊìæÂãïÂÖ∑ÊúâÈ≠ØÊ£íÊÄß„ÄÇGrad-CAM Âú® RISv ÊåáÊ®ô‰∏≠È°ØËëóÂÑ™Êñº CAMÔºåË©≤ÊåáÊ®ôË°°ÈáèÈÄüÂ∫¶ÊñπÈù¢ÁöÑÁ©©ÂÆöÊÄß„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåCAM Âú® RISb ÊåáÊ®ô‰∏≠Ë°®ÁèæÂæóÊõ¥Â•ΩÔºåË©≤ÊåáÊ®ôËàáÈ™®È™ºÁ©©ÂÆöÊÄßÊúâÈóúÔºåËÄå RRS ÊåáÊ®ôÂâáË©ï‰º∞ÂÖßÈÉ®Ë°®Á§∫ÁöÑÈ≠ØÊ£íÊÄß„ÄÇÊï¥È´î‰∏≠ÁöÑÂÄãÂà•Ê®°ÂûãÈ°ØÁ§∫Âá∫‰∏çÂêåÁöÑÁµêÊûúÔºåCAM Âíå Grad-CAM ÈÉΩ‰∏ç‰∏ÄËá¥Âú∞ÂÑ™ÊñºÂè¶‰∏ÄÁ®ÆÔºåÊï¥È´îÊñπÊ≥ïÊèê‰æõ‰∫ÜÂÖ∂ÁµÑÊàêÊ®°ÂûãÁµêÊûúÁöÑË°®Á§∫„ÄÇ

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

ÊëòË¶ÅÔºöÊúÄËøëÁöÑÂÖ®ÁêÉ‰º∞Ë®àË°®ÊòéÔºåÂ§öÈÅî 24.1 ÂÑÑ‰∫∫Êúâ
ÂÅ•Â∫∑ÁãÄÊ≥ÅÂèØÂæûÂæ©ÂÅ•ÊúçÂãô‰∏≠ÂèóÁõä„ÄÇÂ±ÖÂÆ∂
Áâ©ÁêÜÊ≤ªÁôÇ (PT) Âú®Êèê‰æõ‰∫íÂãïÂºè
ÂõûÈ•ãÂíåÊúâÊÑèÁæ©ÁöÑËßÄÂØüÊñπÈù¢Èù¢Ëá®ÈáçÂ§ßÊåëÊà∞Ôºå‰æõÊ≤ªÁôÇÂ∏´ÂíåÊÇ£ËÄÖ‰ΩøÁî®„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄô
ÂÄãÁº∫Âè£ÔºåÊàëÂÄëÊèêÂá∫ MicroXerciseÔºåÂÆÉÂ∞áÂæÆÂãï‰ΩúÂàÜÊûêËàá
ÂèØÁ©øÊà¥ÂºèÊÑüÊ∏¨Âô®Êï¥ÂêàÂú®‰∏ÄËµ∑ÔºåÁÇ∫Ê≤ªÁôÇÂ∏´ÂíåÊÇ£ËÄÖÊèê‰æõ‰∏ÄÂÄãÂÖ®Èù¢ÁöÑ
ÂõûÈ•ã‰ªãÈù¢ÔºåÂåÖÊã¨ÂΩ±Áâá„ÄÅÊñáÂ≠óÂíåÂàÜÊï∏„ÄÇËá≥ÈóúÈáçË¶ÅÁöÑÊòØÔºåÂÆÉÊé°Áî®
Â§öÁ∂≠ÂãïÊÖãÊôÇÈñìË¶èÊï¥ (DTW) ÂíåÂü∫ÊñºÊ≠∏Âõ†ÁöÑÂèØËß£Èáã
ÊñπÊ≥ï‰æÜÂàÜÊûêÁõ£ÊéßÈÅãÂãï‰∏≠ÁèæÊúâÁöÑÊ∑±Â∫¶Â≠∏ÁøíÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºåÂ∞àÊ≥®ÊñºÈÅãÂãïÁöÑÈ´òÁ≤íÂ∫¶„ÄÇÈÄôÁ®ÆÂçîÂêå
ÊñπÊ≥ïËá≥ÈóúÈáçË¶ÅÔºåÊèê‰æõËàáËº∏ÂÖ•Â§ßÂ∞èÂåπÈÖçÁöÑËº∏Âá∫Ôºå‰ª•Á≤æÁ¢∫Âú∞
Á™ÅÂá∫ PT ‰∏≠ÈóúÈçµÁöÑÁ¥∞ÂæÆÂ∑ÆÂà•ÂíåÂãï‰ΩúÔºåÂæûËÄåÂ∞áË§áÈõúÁöÑ AI
ÂàÜÊûêËΩâÊèõÁÇ∫Ê∏ÖÊô∞„ÄÅÂèØÊìç‰ΩúÁöÑÂõûÈ•ã„ÄÇÈÄèÈÅéÂú®‰∏çÂêåÊåáÊ®ô‰∏≠Á™ÅÈ°ØÈÄô‰∫õÂæÆÂãï‰ΩúÔºå‰æãÂ¶ÇÁ©©ÂÆöÊÄßÂíåÂãï‰ΩúÁØÑÂúçÔºåMicroXercise
È°ØËëóÊèêÂçáÊúÄÁµÇ‰ΩøÁî®ËÄÖÂ∞çÂõûÈ•ãÁöÑÁêÜËß£ÂíåÁõ∏ÈóúÊÄß„ÄÇÊØîËºÉÊïàËÉΩÊåáÊ®ôÂº∑Ë™øÂÖ∂ÂÑ™Êñº
ÂÇ≥Áµ±ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºå‰æãÂ¶ÇÁâπÂæµ‰∫íÊÉ†Ë≥áË®ä (FMI) ÂíåÈÄ£Á∫åÊÄßÂàÜÂà•ÊèêÂçá‰∫Ü 39% Âíå 42%„ÄÇMicroXercise Âú®Â±ÖÂÆ∂
Áâ©ÁêÜÊ≤ªÁôÇÊñπÈù¢Êõ¥ÈÄ≤‰∏ÄÊ≠•ÔºåÊèê‰æõÊäÄË°ìÂÖàÈÄ≤‰∏îÁõ¥Ë¶∫ÊúâÁî®ÁöÑ
Ëß£Ê±∫ÊñπÊ°àÔºå‰ª•ÊèêÂçáÊÇ£ËÄÖÁÖßË≠∑ÂíåÁµêÊûú„ÄÇ

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah R√∂sman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

ÊëòË¶ÅÔºöÁ≥ªÁµ±ÊÄßÊñáÁçªÂõûÈ°ßÊòØÁ†îÁ©∂‰∏≠Ë≠âÊìöÂìÅË≥™ÊúÄÈ´òÁöÑ„ÄÇÁÑ∂ËÄåÔºåÂõûÈ°ßÈÅéÁ®ãÂèóÂà∞È°ØËëóË≥áÊ∫êÂíåË≥áÊñôÈôêÂà∂ÁöÑÈòªÁ§ô„ÄÇÊñáÁçªÂõûÈ°ßÁ∂≤Ë∑Ø (LRN) ÊòØÁ¨¨‰∏ÄÂÄãÈÅµÂæ™ PRISMA 2020 Ê®ôÊ∫ñÁöÑÂèØËß£Èáã AI Âπ≥Âè∞ÔºåÊó®Âú®Ëá™ÂãïÂåñÊï¥ÂÄãÊñáÁçªÂõûÈ°ßÈÅéÁ®ã„ÄÇLRN Âú®Â§ñÁßëÊâãÂ•óÂØ¶ÂãôÈ†òÂüü‰∏≠ÈÄ≤Ë°åË©ï‰º∞Ôºå‰ΩøÁî®Â∞àÂÆ∂ÈñãÁôºÁöÑ 3 ÂÄãÊêúÂ∞ãÂ≠ó‰∏≤‰æÜÊü•Ë©¢ PubMed„ÄÇÈùûÂ∞àÂÆ∂Ë®ìÁ∑¥ÊâÄÊúâ LRN Ê®°Âûã„ÄÇÊïàËÉΩ‰ª•Â∞àÂÆ∂ÊâãÂãïÂõûÈ°ß‰ΩúÁÇ∫Âü∫Ê∫ñ„ÄÇÂèØËß£ÈáãÊÄßÂíåÊïàËÉΩÊåáÊ®ôË©ï‰º∞ LRN Ë§áË£ΩÂ∞àÂÆ∂ÂõûÈ°ßÁöÑËÉΩÂäõ„ÄÇ‰∏ÄËá¥ÊÄß‰ª• Jaccard ÊåáÊï∏ÂíåÊ∑∑Ê∑ÜÁü©Èô£Ê∏¨Èáè„ÄÇÁ†îÁ©∂‰∫∫Âì°Âú®Á†îÁ©∂ÂÆåÊàêÂâçÂ∞çÂΩºÊ≠§ÁöÑÁµêÊûú‰øùÂØÜ„ÄÇÈáçÁñäÁöÑÁ†îÁ©∂Êï¥ÂêàÂà∞ LRN ÁîüÊàêÁöÑÁ≥ªÁµ±ÊÄßÂõûÈ°ß‰∏≠„ÄÇLRN Ê®°ÂûãÂú®Ê≤íÊúâÂ∞àÂÆ∂Ë®ìÁ∑¥ÁöÑÊÉÖÊ≥Å‰∏ãÂ±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫ÁéáÔºåÈÅîÂà∞ 84.78% Âíå 85.71% ÁöÑÊ∫ñÁ¢∫Áéá„ÄÇÊïàËÉΩÊúÄÈ´òÁöÑÊ®°ÂûãÈÅîÂà∞‰∫ÜÈ´òË©ïÂàÜËÄÖÈñì‰ø°Ë≥¥Â∫¶ (k = 0.4953) ÂíåÂèØËß£ÈáãÊÄßÊåáÊ®ôÔºåÂ∞á„ÄåÊ∏õÂ∞ë„Äç„ÄÅ„ÄåÊÑèÂ§ñ„ÄçÂíå„ÄåÈä≥Âà©„ÄçËàá„ÄåÈõôÈáçÊà¥ÊâãÂ•ó„ÄçÈÄ£ÁµêÂú®‰∏ÄËµ∑„ÄÇÂè¶‰∏ÄÂÄã LRN Ê®°ÂûãÊ∂µËìã‰∫Ü 91.51% ÁöÑÁõ∏ÈóúÊñáÁçªÔºåÂÑòÁÆ°ËàáÈùûÂ∞àÂÆ∂ÁöÑÂà§Êñ∑‰∏çÂêå (k = 0.2174)Ôºå‰ΩÜÂåÖÂê´‰∫Ü„Äå‰π≥ËÜ†„Äç„ÄÅ„ÄåÈõôÈáç„ÄçÔºàÊâãÂ•óÔºâÂíå„ÄåÈÅ©ÊáâÁóá„ÄçÁ≠âË©ûÂΩô„ÄÇLRN ÂÑ™ÊñºÊâãÂãïÂõûÈ°ßÔºà11 ÂÄãÊúàË∂ÖÈÅé 19,920 ÂàÜÈêòÔºâÔºåÂ∞áÊï¥ÂÄãÈÅéÁ®ãÁ∏ÆÁü≠ÁÇ∫ 5 Â§©Ë∂ÖÈÅé 288.6 ÂàÜÈêò„ÄÇÈÄôÈ†ÖÁ†îÁ©∂È°ØÁ§∫ÔºåÂèØËß£ÈáãÁöÑ AI ‰∏çÈúÄË¶ÅÂ∞àÂÆ∂Ë®ìÁ∑¥Âç≥ÂèØÊàêÂäüÈÄ≤Ë°åÂ∞àÂÆ∂Á≠âÁ¥öÁöÑ PRISMA Áõ∏ÂÆπÁ≥ªÁµ±ÊÄßÊñáÁçªÂõûÈ°ß„ÄÇLRN Á∏ΩÁµê‰∫ÜÂ§ñÁßëÊâãÂ•óÁ†îÁ©∂ÁöÑÁµêÊûúÔºå‰∏¶ÊâæÂá∫ËàáËá®Â∫äÁ†îÁ©∂‰∫∫Âì°ÁôºÁèæÂπæ‰πéÁõ∏ÂêåÁöÑ‰∏ªÈ¢ò„ÄÇÂèØËß£ÈáãÁöÑ AI ÂèØ‰ª•Ê∫ñÁ¢∫Âú∞Âä†Âø´ÊàëÂÄëÂ∞çËá®Â∫äÂØ¶ÂãôÁöÑÁêÜËß£ÔºåÊúâÊΩõÂäõÈù©Êñ∞ÈÜ´ÁôÇ‰øùÂÅ•Á†îÁ©∂„ÄÇ

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂‰ΩøÁî®ÁõíÂ≠êÂ≠∏Ê°ÜÊû∂ÂàÜÊûêÊ∑∑Âêà‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±ÁöÑË®≠Ë®àÊ®°ÂºèÂèäÂÖ∂Âú®Ëá®Â∫äÊ±∫Á≠ñ‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÂÆÉÂàÜÈ°û‰∏¶ÊØîËºÉÁµêÂêàÊ©üÂô®Â≠∏ÁøíÂíåÂü∫ÊñºË¶èÂâáÁöÑÊé®ÁêÜÁöÑÂêÑÁ®ÆÊû∂ÊßãÔºå‰ª•Ê∑±ÂÖ•‰∫ÜËß£ÂÖ∂ÁµêÊßãÂü∫Á§éÂíåÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®„ÄÇÈáùÂ∞çÂÖ©ÂÄã‰∏ªË¶ÅÂïèÈ°åÔºåÂ¶Ç‰ΩïÊ†πÊìöÊó¢ÂÆöÁöÑË®≠Ë®àÊ®°ÂºèÂ∞çÈÄô‰∫õÁ≥ªÁµ±ÈÄ≤Ë°åÂàÜÈ°ûÔºå‰ª•ÂèäÂ¶Ç‰ΩïÈÄöÈÅéÊØîËºÉÂàÜÊûêÊèêÂèñË¶ãËß£ÔºåÊú¨Á†îÁ©∂‰ΩøÁî®ËªüÈ´îÂ∑•Á®ã‰∏≠ÁöÑË®≠Ë®àÊ®°Âºè‰æÜ‰∫ÜËß£ÂíåÂÑ™ÂåñÈÜ´ÁôÇ‰øùÂÅ•‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±„ÄÇÁõíÂ≠êÂ≠∏ÊúâÂä©ÊñºË≠òÂà•ÂÖ±ÊÄß‰∏¶Âª∫Á´ãÂèØÈáçË§á‰ΩøÁî®ÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂæûËÄåÂ¢ûÂº∑ÈÄô‰∫õÁ≥ªÁµ±ÁöÑÂèØÊì¥ÂÖÖÊÄß„ÄÅÂèØÈù†ÊÄßÂíåÊïàËÉΩ„ÄÇÊ™¢Êü•‰∫Ü‰∫îÁ®Æ‰∏ªË¶ÅÁöÑÊû∂ÊßãÔºöREML„ÄÅMLRB„ÄÅRBML„ÄÅRMLT Âíå PERML„ÄÇÊØèÁ®ÆÊû∂ÊßãÈÉΩÊúâÁç®ÁâπÁöÑÂÑ™Áº∫ÈªûÔºåÂº∑Ë™ø‰∫ÜÂú®Ëá®Â∫ä‰ªªÂãô‰∏≠ÈúÄË¶ÅÈáèË∫´ÊâìÈÄ†ÁöÑÊñπÊ≥ï„ÄÇREML Âú®Ë≥áÊñôÊúâÈôêÁöÑË≥áÊñôÈõÜ‰∏≠Ë°®ÁèæÂá∫È´òÁ≤æÂ∫¶ÁöÑÈ†êÊ∏¨ÔºõMLRB Âú®ËôïÁêÜÂ§ßÂûãË≥áÊñôÈõÜÂíåË§áÈõúË≥áÊñôÊï¥ÂêàÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÔºõRBML Âú®ÂèØËß£ÈáãÊÄßÂíåÂèØ‰ø°Â∫¶ÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÔºõRMLT Âú®ÁÆ°ÁêÜÈ´òÁ∂≠Ë≥áÊñôÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÔºõËÄå PERML ÂÑòÁÆ°Âú®ÂàÜÊûêÊñπÈù¢ÊúâÈôêÔºå‰ΩÜÂú®Á∑äÊÄ•ÁÖßË≠∑Â†¥ÊôØ‰∏≠Ë°®ÁèæÂá∫ÊΩõÂäõ„ÄÇÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫ÜÂõõÁ®ÆÊñ∞Ê®°ÂºèÔºåÂª∫Á´ã‰∫Ü‰∫îÁ®ÆÊäΩË±°ÂàÜÈ°ûÊ®°ÂºèÔºå‰∏¶ÈÄ≤‰∏ÄÊ≠•Â∞áÈÄô‰∫îÁ®ÆÊ®°ÂºèÁ¥∞ÂåñÁÇ∫ÂÖ∑È´îÁöÑÁ≥ªÁµ±„ÄÇÈÄô‰∫õË≤¢ÁçªÂ¢ûÂº∑‰∫ÜÁõíÂ≠êÂ≠∏ÁöÑÂàÜÈ°ûÁµÑÁπîÔºå‰∏¶Êèê‰æõ‰∫ÜÂ∞áÂ∞àÂÆ∂Áü•Ë≠òËàáÊ©üÂô®Â≠∏ÁøíÊï¥ÂêàÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÁõíÂ≠êÂ≠∏ÁöÑÁµêÊßãÂåñ„ÄÅÊ®°ÁµÑÂåñÊñπÊ≥ïÂú®ÈñãÁôºÂíåÂàÜÊûêÊ∑∑Âêà‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±„ÄÅÊè≠Á§∫ÂÖ±ÊÄß‰ª•ÂèäÊé®Âª£ÂèØÈáçË§á‰ΩøÁî®ÁöÑËß£Ê±∫ÊñπÊ°àÊñπÈù¢ÂÖ∑ÊúâÈ°ØËëóÂÑ™Âã¢„ÄÇÁ∏Ω‰πãÔºåÊú¨Á†îÁ©∂Âº∑Ë™ø‰∫ÜÊ∑∑Âêà‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±Âú®Êé®ÈÄ≤ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÈóúÈçµ‰ΩúÁî®Ôºå‰ª•ÂèäÁõíÂ≠êÂ≠∏Âú®Êé®Âãï‰∫∫Â∑•Êô∫ÊÖßÊï¥ÂêàÈÄ≤‰∏ÄÊ≠•ÂâµÊñ∞ÊñπÈù¢ÁöÑÊΩõÂäõÔºåÊúÄÁµÇÊîπÂñÑËá®Â∫äÊ±∫Á≠ñÊîØÊè¥ÂíåÊÇ£ËÄÖÁöÑÊ≤ªÁôÇÊàêÊûú„ÄÇ

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

ÊëòË¶ÅÔºöÁî±ÊñºÂÖ∂Âº∑Â§ßÁöÑÈ†êÊ∏¨ËÉΩÂäõÔºåÊ∑±Â∫¶Â≠∏ÁøíÂ∑≤ÊàêÁÇ∫Ë®±Â§öÁî¢Ê•≠‰∏≠‰∏çÂèØÊàñÁº∫ÁöÑÂ∑•ÂÖ∑ÔºåÂåÖÊã¨ÈÜ´ÁôÇ‰øùÂÅ•„ÄÇÁÑ∂ËÄåÔºåÂÇ≥Áµ±ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÈÄöÂ∏∏Áº∫‰πèÂèØËß£ÈáãÊÄßÔºå‰∏¶‰∏îÂøΩÁï•‰∫ÜÂ∞áÈ†êÊ∏¨‰∏çÁ¢∫ÂÆöÊÄßÁ¥çÂÖ•ËÄÉÈáèÔºåËÄåÈÄôÂÖ©ÂÄãÂõ†Á¥†ÊòØËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÁöÑÈóúÈçµÁµÑÊàêÈÉ®ÂàÜ„ÄÇÁÇ∫‰∫ÜÁî¢ÁîüÂèØËß£Èáã‰∏îÂÖ∑Êúâ‰∏çÁ¢∫ÂÆöÊÄßÊÑèË≠òÁöÑÈ†êÊ∏¨ÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫Ë≤ùÊ∞èÊüØÁàæËé´Âì•Ê¥õÂ§´ÈòøË´æÂæ∑Á∂≤Ë∑Ø (BKAN) ÁöÑÊñ∞Êû∂ÊßãÔºåÂÆÉÁµêÂêà‰∫ÜÊüØÁàæËé´Âì•Ê¥õÂ§´ÈòøË´æÂæ∑Á∂≤Ë∑ØÁöÑË°®ÈÅîËÉΩÂäõËàáË≤ùÊ∞èÊé®Ë´ñ„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄãÈÜ´Â≠∏Ë≥áÊñôÈõÜ‰∏ä‰ΩøÁî® BKANÔºåÈÄô‰∫õË≥áÊñôÈõÜÊòØË©ï‰º∞Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÂú®ÈÜ´Â≠∏Ë®∫Êñ∑‰∏≠ÁöÑÂª£Ê≥õ‰ΩøÁî®Âü∫Ê∫ñÔºöÁöÆÈ¶¨Âç∞Á¨¨ÂÆâ‰∫∫Á≥ñÂ∞øÁóÖË≥áÊñôÈõÜÂíåÂÖãÈáåÂ§´Ëò≠ÂøÉËáüÁóÖË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÊèê‰æõ‰∫ÜÂ∞çÈ†êÊ∏¨‰ø°ÂøÉÂíåÊ±∫Á≠ñÈÇäÁïåÁöÑÊúâÁõäË¶ãËß£Ôºå‰∏¶‰∏îÂú®È†êÊ∏¨Ê∫ñÁ¢∫Â∫¶ÊñπÈù¢ÂÑ™ÊñºÂÇ≥Áµ±ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåBKAN Ë°®ÁèæÈö®Ê©üÂíåË™çË≠ò‰∏çÁ¢∫ÂÆöÊÄßÁöÑËÉΩÂäõÔºåÂèØÁ¢∫‰øùÈÜ´ÁîüÁç≤ÂæóÊõ¥ÂèØÈù†‰∏îÂÄºÂæó‰ø°Ë≥¥ÁöÑÊ±∫Á≠ñÊîØÊè¥„ÄÇÊ†πÊìöÂØ¶È©óÁµêÊûúÔºåÊàëÂÄëÁöÑË≤ùÊ∞èÁ≠ñÁï•ÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÔºå‰∏¶Â§ßÂπÖÊ∏õÂ∞ë‰∫ÜÈÅéÂ∫¶Êì¨ÂêàÔºåÈÄôÂ∞çÊñºÂ∞èÂûã‰∏î‰∏çÂπ≥Ë°°ÁöÑÈÜ´Â≠∏Ë≥áÊñôÈõÜÈùûÂ∏∏ÈáçË¶Å„ÄÇÊàëÂÄëÊèêÂá∫‰∫ÜÂèØËÉΩÁöÑÊì¥ÂÖÖÂäüËÉΩÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•Â∞á BKAN Áî®ÊñºÊõ¥Ë§áÈõúÁöÑÂ§öÊ®°ÂºèË≥áÊñôÈõÜÔºå‰∏¶Êé¢Ë®éÈÄô‰∫õÁôºÁèæÂ∞çÊñºÊú™‰æÜÂª∫Á´ãÂèØÈù†ÁöÑÈÜ´ÁôÇ‰øùÂÅ• AI Á≥ªÁµ±Á†îÁ©∂ÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÈÉ®ÁΩ≤Âú®ÈÄèÊòéÂ∫¶ÂíåÂèØÈù†ÊÄßËá≥ÈóúÈáçË¶ÅÁöÑÈáçË¶ÅÈ†òÂüü‰∏≠ÈñãÂïü‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂÖ∏ÁØÑ„ÄÇ

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

ÊëòË¶ÅÔºöÂú®Áèæ‰ª£ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÔºåËß£Ê±∫Ê∫ñÁ¢∫ÁñæÁóÖÈ†êÊ∏¨ÂíåÂÄãÊÄßÂåñÂª∫Ë≠∞ÁöÑË§áÈõúÊÄßÊó¢Ëá≥ÈóúÈáçË¶ÅÂèàÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫Ü MLtoGAIÔºåÂÆÉÂ∞áË™ûÁæ©Á∂≤Ë∑ØÊäÄË°ìËàáÊ©üÂô®Â≠∏Áøí (ML) Áõ∏ÁµêÂêàÔºå‰ª•Â¢ûÂº∑ÁñæÁóÖÈ†êÊ∏¨‰∏¶ÈÄèÈÅé ChatGPT Êèê‰æõ‰ΩøÁî®ËÄÖÂèãÂñÑÁöÑË™™Êòé„ÄÇË©≤Á≥ªÁµ±ÂåÖÂê´‰∏âÂÄãÈóúÈçµÁµÑÊàêÈÉ®ÂàÜÔºö‰∏ÄÂÄãÂèØÈáçË§á‰ΩøÁî®ÁöÑÁñæÁóÖÊú¨‰ΩìÔºåÂÖ∂‰∏≠ÂåÖÂê´ÊúâÈóúÂêÑÁ®ÆÁñæÁóÖÁöÑË©≥Á¥∞Áü•Ë≠òÔºõ‰∏ÄÂÄãË®∫Êñ∑ÂàÜÈ°ûÊ®°ÂûãÔºåÂÆÉ‰ΩøÁî®ÊÇ£ËÄÖÁóáÁãÄ‰æÜÊ∫ñÁ¢∫Ê™¢Ê∏¨ÁâπÂÆöÁñæÁóÖÔºõ‰ª•ÂèäË™ûÁæ©Á∂≤Ë∑ØË¶èÂâáË™ûË®Ä (SWRL) ËàáÊú¨‰ΩìÂíå ChatGPT ÁöÑÊï¥ÂêàÔºå‰ª•Áî¢ÁîüÊ∏ÖÊô∞„ÄÅÂÄãÊÄßÂåñÁöÑÂÅ•Â∫∑Âª∫Ë≠∞„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÈ°ØËëóÊèêÈ´ò‰∫ÜÈ†êÊ∏¨Ê∫ñÁ¢∫ÊÄßÔºå‰∏¶Á¢∫‰øù‰∫ÜÊòìÊñºÁêÜËß£ÁöÑÁµêÊûúÔºåËß£Ê±∫‰∫ÜÁñæÁóÖÂíå‰∏çÂêåÁóáÁãÄÁöÑË§áÈõúÊÄß„ÄÇMLtoGAI Á≥ªÁµ±Â±ïÁ§∫‰∫ÜÊ∫ñÁ¢∫ÊÄßÂíå‰ΩøÁî®ËÄÖÊªøÊÑèÂ∫¶ÁöÑÂØ¶Ë≥™ÊÄßÈÄ≤Ê≠•ÔºåÊúâÂä©ÊñºÈñãÁôºÊõ¥Êô∫ÊÖß‰∏îÊõ¥ÊòìÊñºÂèñÂæóÁöÑÈÜ´ÁôÇ‰øùÂÅ•Ëß£Ê±∫ÊñπÊ°à„ÄÇÈÄôÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ïÁµêÂêà‰∫Ü ML ÊºîÁÆóÊ≥ïÁöÑÂÑ™ÈªûÔºå‰ª•ÂèäÈÄèÈÅé ChatGPT Êèê‰æõÈÄèÊòé‰∏î‰∫∫È°ûÂèØ‰ª•ÁêÜËß£ÁöÑË™™ÊòéÁöÑËÉΩÂäõÔºåÂú®È†êÊ∏¨Ê∫ñÁ¢∫ÊÄßÂíå‰ΩøÁî®ËÄÖÁêÜËß£ÊñπÈù¢ÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÈÄ≤Ê≠•„ÄÇÈÄèÈÅéÂà©Áî®Ë™ûÁæ©ÊäÄË°ìÂíåÂèØËß£ÈáãÁöÑ AIÔºåË©≤Á≥ªÁµ±ÊèêÈ´ò‰∫ÜÁñæÁóÖÈ†êÊ∏¨ÁöÑÊ∫ñÁ¢∫ÊÄßÔºå‰∏¶Á¢∫‰øù‰∫ÜÂª∫Ë≠∞ËàáÂÄãÂà•ÊÇ£ËÄÖÁõ∏Èóú‰∏îÊòìÊñºÁêÜËß£„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Âº∑Ë™ø‰∫ÜÊï¥ÂêàÂÖàÈÄ≤ÊäÄË°ì‰ª•ÂÖãÊúçÈÜ´ÁôÇË®∫Êñ∑‰∏≠ÁèæÊúâÊåëÊà∞ÁöÑÊΩõÂäõÔºåÁÇ∫Êô∫ÊÖßÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±ÁöÑÊú™‰æÜÁôºÂ±ïÈã™Ë∑Ø„ÄÇÊ≠§Â§ñÔºåË©≤Á≥ªÁµ±‰ΩøÁî® 200 ÂÄãÂêàÊàêÊÇ£ËÄÖË≥áÊñôË®òÈåÑÈÄ≤Ë°åÈ©óË≠âÔºåÁ¢∫‰øù‰∫ÜÁ©©ÂÅ•ÁöÑÊïàËÉΩÂíåÂèØÈù†ÊÄß„ÄÇ

##### **Introducing Œ¥-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊòØÂ∞á‰∫∫Â∑•Êô∫ÊÖß (AI) ÂíåÊ©üÂô®Â≠∏Áøí (ML) ÊºîÁÆóÊ≥ïÊï¥ÂêàÂà∞Ëá®Â∫äÂØ¶Âãô‰∏≠ÁöÑËæØË´ñÊ†∏ÂøÉ„ÄÇÈ´òÂü∑Ë°åÊïàËÉΩÁöÑ AI/ML Ê®°ÂûãÔºå‰æãÂ¶ÇÊï¥È´îÂ≠∏ÁøíÂô®ÂíåÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÔºåÈÄöÂ∏∏Áº∫‰πèÂèØËß£ÈáãÊÄßÔºåÈòªÁ§ôËá®Â∫äÈÜ´ÁîüÂ∞çÂÖ∂È†êÊ∏¨ÁöÑ‰ø°‰ªª„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊ≠£Âú®ÈñãÁôº XAI ÊäÄË°ìÔºå‰ª•‰∫∫È°ûÂèØ‰ª•ÁêÜËß£ÁöÑË°ìË™ûÊèèËø∞ AI/ML È†êÊ∏¨„ÄÇ‰∏ÄÂÄãÊúâÂ∏åÊúõÁöÑÊñπÂêëÊòØÊé°Áî®ÊïèÊÑüÂ∫¶ÂàÜÊûê (SA) ÂíåÂÖ®ÁêÉÊïèÊÑüÂ∫¶ÂàÜÊûê (GSA)ÔºåÂÆÉÂÄëÊú¨Ë≥™‰∏äÊúÉ‰æùÊìöÊ®°ÂûãËº∏ÂÖ•Â∞çÈ†êÊ∏¨ÁöÑÂΩ±Èüø‰æÜÂ∞çÂÖ∂ÈÄ≤Ë°åÊéíÂêç„ÄÇÂú®Ê≠§ÔºåÊàëÂÄë‰ªãÁ¥π‰∏ÄÁ®ÆÊñ∞ÁöÑ delta-XAI ÊñπÊ≥ïÔºåÈÄèÈÅéÊì¥ÂÖÖ GSA ÊåáÊ®ô delta ÊåáÊï∏‰æÜÊèê‰æõ ML Ê®°ÂûãÈ†êÊ∏¨ÁöÑÂ±ÄÈÉ®Ëß£Èáã„ÄÇdelta-XAI ÊåáÊï∏Ë©ï‰º∞ÊØèÂÄãÁâπÂæµÂÄºÂ∞çÂõûÊ≠∏ÂíåÂàÜÈ°ûÂïèÈ°å‰∏≠ÂÄãÂà•‰æãÈ†ÖÁöÑÈ†êÊ∏¨Ëº∏Âá∫‰πãÂΩ±Èüø„ÄÇÊàëÂÄëÂ∞á delta-XAI ÊåáÊï∏ÂΩ¢ÂºèÂåñÔºå‰∏¶Êèê‰æõÂÖ∂ÂØ¶‰ΩúÁöÑÁ®ãÂºèÁ¢º„ÄÇ‰ΩøÁî®Á∑öÊÄßÂõûÊ≠∏Ê®°ÂûãÂ∞çÊ®°Êì¨ÊÉÖÂ¢ÉË©ï‰º∞ delta-XAI ÊñπÊ≥ïÔºå‰∏¶‰ª• Shapley ÂÄº‰ΩúÁÇ∫Âü∫Ê∫ñ„ÄÇÁµêÊûúÈ°ØÁ§∫ delta-XAI ÊåáÊï∏ÈÄöÂ∏∏Ëàá Shapley ÂÄº‰∏ÄËá¥Ôºå‰ΩÜÂú®ÂÖ∑ÊúâÈ´òÂ∫¶ÂΩ±ÈüøÂäõÊàñÊ•µÁ´ØÁâπÂæµÂÄºÁöÑÊ®°Âûã‰∏≠Â≠òÂú®È°ØËëóÂ∑ÆÁï∞„ÄÇdelta-XAI ÊåáÊï∏Âú®ÂÅµÊ∏¨‰∏ªË¶ÅÁâπÂæµÂíåËôïÁêÜÊ•µÁ´ØÁâπÂæµÂÄºÊñπÈù¢Ë°®ÁèæÂá∫Êõ¥È´òÁöÑÊïèÊÑüÂ∫¶„ÄÇÂÆöÊÄßÂú∞‰æÜË™™Ôºådelta-XAI ÈÄèÈÅéÂà©Áî®Ê©üÁéáÂØÜÂ∫¶ÂáΩÊï∏Êèê‰æõÁõ¥ËßÄÁöÑËß£ÈáãÔºå‰ΩøÁâπÂæµÊéíÂêçÊõ¥Ê∏ÖÊô∞‰∏îÂ∞çÂæûÊ•≠‰∫∫Âì°‰æÜË™™Êõ¥ÂÖ∑ÂèØËß£ÈáãÊÄß„ÄÇÁ∏ΩÈ´îËÄåË®ÄÔºådelta-XAI ÊñπÊ≥ïÂ∞çÊñºÁ©©ÂÅ•Âú∞ÂèñÂæó ML Ê®°ÂûãÈ†êÊ∏¨ÁöÑÂ±ÄÈÉ®Ëß£Èáã‰ºº‰πéÂæàÊúâÂ∏åÊúõ„ÄÇÂ∞áÂú®ÁúüÂØ¶‰∏ñÁïåÁöÑËá®Â∫äÁí∞Â¢É‰∏≠ÈÄ≤Ë°åÈÄ≤‰∏ÄÊ≠•Ë™øÊü•Ôºå‰ª•Ë©ï‰º∞ÂÖ∂Â∞ç AI ËºîÂä©Ëá®Â∫äÂ∑•‰ΩúÊµÅÁ®ãÁöÑÂΩ±Èüø„ÄÇ

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

ÊëòË¶ÅÔºöÂ§±Êô∫ÁóáÊòØ‰∏ÄÁ®ÆÂΩ±ÈüøÂÖ®ÁêÉÊï∏ÁôæËê¨‰∫∫ÁöÑË°∞Âº±ÊÄßÁ•ûÁ∂ìÁñæÁóÖÔºåÂú®Ë®∫Êñ∑‰∏äÂÖ∑ÊúâÈáçÂ§ßÊåëÊà∞„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂ∞çÂ§±Êô∫ÂíåÈùûÂ§±Êô∫ËÄÅÂπ¥ÊÇ£ËÄÖÈÄ≤Ë°åÂàÜÈ°ûÔºå‰ΩøÁî® 3D Â§ßËÖ¶Á£ÅÊåØÈÄ†ÂΩ± (MRI) ÊéÉÊèè„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊé°Áî®‰∫Ü‰∏ÄÁ®ÆÁç®ÁâπÊäÄË°ìÔºåÁî®ÊñºÈÅ∏ÊìáÊÄßËôïÁêÜ MRI ÂàáÁâáÔºåÈáçÈªûÈóúÊ≥®ÊúÄÁõ∏ÈóúÁöÑÂ§ßËÖ¶ÂçÄÂüüÔºå‰∏¶ÊéíÈô§‰ø°ÊÅØÈáèËºÉÂ∞ëÁöÑÈÉ®ÂàÜ„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÁî±‰∏ÄÂÄãÂü∫Êñº‰ø°ÂøÉÁöÑÂàÜÈ°ûÂßîÂì°ÊúÉË£úÂÖÖÔºåË©≤ÂßîÂì°ÊúÉÁî±‰∏âÂÄãËá™ÂÆöÁæ©Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁµÑÊàêÔºöDem3D ResNet„ÄÅDem3D CNN Âíå Dem3D EfficientNet„ÄÇÈÄô‰∫õÊ®°ÂûãÂçîÂêåÂ∑•‰Ωú‰ª•Â¢ûÂº∑Ê±∫Á≠ñÁöÑÊ∫ñÁ¢∫ÊÄßÔºåÂà©Áî®ÂÆÉÂÄëÁöÑÈõÜÈ´îÂÑ™Âã¢„ÄÇÂú®ÂΩ±ÂÉèÁ†îÁ©∂ÈñãÊîæÂ≠òÂèñÁ≥ªÂàó (OASIS) Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÊ∏¨Ë©¶ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÈÅîÂà∞‰∫Ü 94.12% ÁöÑÈ©ö‰∫∫Ê∫ñÁ¢∫Â∫¶ÔºåË∂ÖÈÅé‰∫ÜÁèæÊúâÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåÂú®ÈòøËå≤Êµ∑ÈªòÁóáÁ•ûÁ∂ìÂΩ±ÂÉèÂÄ°Ë≠∞ (ADNI) Ë≥áÊñôÈõÜ‰∏äÁöÑÈ©óË≠âË≠âÂØ¶‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÁ©©ÂÅ•ÊÄßÂíåÊôÆÈÅçÊÄß„ÄÇÂèØËß£Èáã AI (XAI) ÊäÄË°ìÂíåÂÖ®Èù¢ÁöÑÊ∂àËûçÁ†îÁ©∂ÈÄ≤‰∏ÄÊ≠•Ë≠âÂØ¶‰∫ÜÊàëÂÄëÊäÄË°ìÁöÑÊúâÊïàÊÄßÔºåÊèê‰æõ‰∫ÜÂ∞çÊ±∫Á≠ñÈÅéÁ®ãÂíåÊàëÂÄëÊñπÊ≥ïÈáçË¶ÅÊÄßÁöÑË¶ãËß£„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÁÇ∫Â§±Êô∫ÁóáË®∫Êñ∑Êèê‰æõ‰∫ÜÈáçÂ§ßÈÄ≤Â±ïÔºåÁÇ∫Ëá®Â∫äÊáâÁî®Êèê‰æõ‰∫Ü‰∏ÄÂÄãÈ´òÂ∫¶Ê∫ñÁ¢∫‰∏îÈ´òÊïàÁöÑÂ∑•ÂÖ∑„ÄÇ

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

ÊëòË¶ÅÔºöËóâÁî±Êô∫ÊÖßÁí∞Â¢É‰∏≠‰∏çÂºï‰∫∫Ê≥®ÁõÆÁöÑÊÑüÊ∏¨Âô®Ëæ®Ë≠òÊó•Â∏∏Ê¥ªÂãïÔºåËÉΩÂïüÁî®ÂêÑÁ®ÆÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®„ÄÇÁõ£ÊéßÂèóË©¶ËÄÖÂú®ÂÆ∂‰∏≠Â¶Ç‰ΩïÂü∑Ë°åÊ¥ªÂãïÔºå‰ª•ÂèäÂÖ∂Èö®ËëóÊôÇÈñìÁöÑËÆäÂåñÔºåÂèØ‰ª•Êè≠Á§∫ÂÅ•Â∫∑ÂïèÈ°åÁöÑÊó©ÊúüÁóáÁãÄÔºå‰æãÂ¶ÇË™çÁü•ËÉΩÂäõ‰∏ãÈôç„ÄÇÊ≠§È†òÂüü‰∏≠ÁöÑÂ§ßÂ§öÊï∏ÊñπÊ≥ïÈÉΩ‰ΩøÁî®Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºåÈÄô‰∫õÊ®°ÂûãÈÄöÂ∏∏Ë¢´Ë¶ñÁÇ∫Â∞áÊÑüÊ∏¨Âô®Ë≥áÊñôÂ∞çÊáâËá≥Ê¥ªÂãïÁöÑÈªëÁõíÂ≠ê„ÄÇÁÑ∂ËÄåÔºåÈùûÂ∞àÂÆ∂‰ΩøÁî®ËÄÖÔºà‰æãÂ¶ÇËá®Â∫äÈÜ´Â∏´ÔºâÈúÄË¶Å‰ø°‰ªª‰∏¶‰∫ÜËß£ÈÄô‰∫õÊ®°ÂûãÁöÑËº∏Âá∫„ÄÇÂõ†Ê≠§Ôºå‰∫∫È°ûÊ¥ªÂãïËæ®Ë≠òÁöÑÂèØËß£Èáã AI (XAI) ÊñπÊ≥ïÊáâÈÅãËÄåÁîüÔºå‰ª•Êèê‰æõ‰æÜËá™ÈÄô‰∫õÊ®°ÂûãÁöÑÁõ¥Ë¶∫Ëá™ÁÑ∂Ë™ûË®ÄË™™Êòé„ÄÇ‰∏çÂêåÁöÑ XAI ÊñπÊ≥ïÊúÉÁî¢Áîü‰∏çÂêåÁöÑË™™ÊòéÔºåËÄåÂÖ∂ÊúâÊïàÊÄßÈÄöÂ∏∏ÈÄèÈÅé‰ΩøÁî®ËÄÖË™øÊü•‰æÜË©ï‰º∞ÔºåÈÄôÂú®ÊàêÊú¨ÂíåÂÖ¨Âπ≥ÊÄßÊñπÈù¢ÈÄöÂ∏∏ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊú¨ÊñáÊèêÂá∫‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËá™ÂãïË©ï‰º∞ÊñπÊ≥ïÔºå‰ª•Âú®ÂÄôÈÅ∏ËÄÖ‰∏≠ÊâæÂá∫ÊúÄÈÅ©ÂêàÈùûÂ∞àÂÆ∂‰ΩøÁî®ËÄÖÁöÑ XAI ÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÂàùÊ≠•ÁµêÊûúË°®ÊòéÔºåLLM Ë©ï‰º∞Ëàá‰ΩøÁî®ËÄÖË™øÊü•‰∏ÄËá¥„ÄÇ

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

ÊëòË¶ÅÔºöÂ∑•Ê•≠ 5.0 ËëóÈáçÊñº‰∫∫È°ûËàá‰∫∫Â∑•Êô∫ÊÖß (AI) Âêà‰ΩúÂü∑Ë°åË£ΩÈÄ†‰∏≠ÁöÑ‰∏çÂêå‰ªªÂãôÔºåÊ∂âÂèäÊõ¥Â§öÊ©üÂô®‰∫∫„ÄÅÁâ©ËÅØÁ∂≤ (IoT) Ë£ùÁΩÆÂíå‰∫íÈÄ£„ÄÅÊì¥Â¢û/ËôõÊì¨ÂØ¶Â¢É (AR) ÂíåÂÖ∂‰ªñÊô∫ÊÖßË£ùÁΩÆ„ÄÇÈÄô‰∫õË£ùÁΩÆÂíå‰∫íÈÄ£Âú®Á∂ìÊøü„ÄÅÈÜ´ÁôÇ‰øùÂÅ•„ÄÅÊïôËÇ≤ÂíåÂúãÈò≤Á≥ªÁµ±Á≠âÂêÑÁ®ÆÈóúÈçµÈ†òÂüüÁöÑÂª£Ê≥õÂèÉËàáÔºåÂºïÁôº‰∫ÜÂ§öÁ®ÆÈ°ûÂûãÁöÑÊΩõÂú®ÂÆâÂÖ®ÊºèÊ¥û„ÄÇAI Êú¨Ë∫´Â∑≤Ë¢´Ë≠âÊòéÊòØÁ∂≤Ë∑ØÂÆâÂÖ®‰∏çÂêåÈ†òÂüü‰∏≠ÈùûÂ∏∏ÊúâÊïà‰∏îÂº∑Â§ßÁöÑÂ∑•ÂÖ∑Ôºå‰æãÂ¶ÇÂÖ•‰æµÂÅµÊ∏¨„ÄÅÊÉ°ÊÑèËªüÈ´îÂÅµÊ∏¨ÂíåÁ∂≤Ë∑ØÈá£È≠öÂÅµÊ∏¨Á≠â„ÄÇÂ∞±ÂÉèÂú®Ë®±Â§öÊáâÁî®È†òÂüü‰∏ÄÊ®£ÔºåÁ∂≤Ë∑ØÂÆâÂÖ®Â∞àÊ•≠‰∫∫Âì°‰∏çÈ°òÊÑèÊé•ÂèóÈªëÁõí ML Ëß£Ê±∫ÊñπÊ°à‰æÜÊáâÁî®ÊñºÁ∂≤Ë∑ØÂÆâÂÖ®„ÄÇÈÄôÁ®Æ‰∏çÈ°òÊÑè‰øÉ‰ΩøÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ‰ΩúÁÇ∫‰∏ÄÁ®ÆÂ∑•ÂÖ∑Ë¢´Êé°Áî®ÔºåÊúâÂä©ÊñºË™™ÊòéÂú®Âü∫Êñº ML ÁöÑÁ≥ªÁµ±‰∏≠Â¶Ç‰ΩïÂÅöÂá∫Ê±∫Á≠ñ„ÄÇÂú®ÈÄôÈ†ÖË™øÊü•‰∏≠ÔºåÊàëÂÄëÂ∞çÂ∑•Ê•≠ 5.0 ÁöÑ‰∏çÂêåÂü∫Êñº XAI ÁöÑÂÖ•‰æµÂÅµÊ∏¨Á≥ªÁµ±ÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÁ†îÁ©∂Ôºå‰∏¶‰∏îÊàëÂÄë‰πüÈÄèÈÅéÂ∞çÊäóÂºè XIDS (Adv-XIDS) ÊñπÊ≥ïÁöÑËßÄÈªû‰æÜÊé¢Ë®éÂèØËß£ÈáãÊÄßÂíåÂèØË©ÆÈáãÊÄßÂ∞çÁ∂≤Ë∑ØÂÆâÂÖ®ÂØ¶ÂãôÁöÑÂΩ±Èüø„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂàÜÊûê‰∫ÜÂ∑•Ê•≠ 5.0 ÁöÑ XAI Á∂≤Ë∑ØÂÆâÂÖ®Á≥ªÁµ±‰∏≠ÂèØËÉΩÂ≠òÂú®ÁöÑÊ©üÊúÉÂíåÊåëÊà∞ÔºåÂºïÁôº‰∫ÜÊú™‰æÜÈáùÂ∞ç XAI Âü∫Á§éËß£Ê±∫ÊñπÊ°àÁöÑÁ†îÁ©∂Ôºå‰ª•‰æõÈ´òÈ¢®Èö™ÁöÑÂ∑•Ê•≠ 5.0 ÊáâÁî®Êé°Áî®„ÄÇÊàëÂÄëÁõ∏‰ø°ÈÄôÈ†ÖÂö¥Ë¨πÁöÑÂàÜÊûêÂ∞áÁÇ∫ÊåáÂÆöÈ†òÂüüÂÖßÁöÑÂæåÁ∫åÁ†îÁ©∂Â∑•‰ΩúÂª∫Á´ãÂü∫Á§éÊû∂Êßã„ÄÇ

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êó®Âú®Êé¢Ë®éÂ∞áËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÂíåÊ©üÂô®Â≠∏Áøí (ML) ÊäÄË°ìÂØ¶‰ΩúÊñºÈÜ´ÁôÇ‰ø°ÂáΩÁ∑®Á¢ºËá™ÂãïÂåñÔºå‰∏¶ÂÖ∑ÂÇôË¶ñË¶∫ÂåñË™™ÊòéËÉΩÂäõÂíåËºïÈáèÂåñÁöÑÊú¨Âú∞ÈõªËÖ¶Ë®≠ÂÆö„ÄÇÁõÆÂâçÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÔºåÁ∑®Á¢ºÊòØ‰∏ÄÁ®ÆÊâãÂãïÊµÅÁ®ãÔºåÊ∂âÂèäÁÇ∫ÁóÖÊÇ£Êñá‰ª∂‰∏≠ÁöÑÊØèÈ†ÖÁóÖÁóá„ÄÅÁ®ãÂ∫èÂíåËó•Áâ©ÊåáÊ¥æ‰ª£Á¢º (‰æãÂ¶ÇÔºå‰ΩøÁî® SNOMED CT ‰ª£Á¢º 56265001 Ë°®Á§∫ÂøÉËáüÁóÖ)„ÄÇÊ≠§È†òÂüüÊúâ‰ΩøÁî®ÊúÄÊñ∞ ML Ê®°ÂûãÈÄ≤Ë°åËá™ÂãïÁ∑®Á¢ºÁöÑÂàùÊ≠•Á†îÁ©∂ÔºõÁÑ∂ËÄåÔºåÁî±ÊñºÊ®°ÂûãÁöÑË§áÈõúÊÄßÂíåÂ§ßÂ∞èÔºå‰∏¶Êú™ÂØ¶ÁèæÂØ¶ÈöõÈÉ®ÁΩ≤„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•‰øÉÈÄ≤Ëá™ÂãïÁ∑®Á¢ºÂØ¶ÂãôÁöÑÂèØËÉΩÊÄßÔºåÊàëÂÄëÂú®Êú¨Âú∞ÈõªËÖ¶Ë®≠ÂÆö‰∏≠Êé¢Ë®é‰∫Ü‰∏Ä‰∫õËß£Ê±∫ÊñπÊ°àÔºõÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜË™™ÊòéÂäüËÉΩÂú® AI Ê®°ÂûãÈÄèÊòéÂ∫¶‰∏≠ÁöÑÂäüËÉΩ„ÄÇÊàëÂÄë‰ΩøÁî®ÂÖ¨ÈñãÁöÑ MIMIC-III Ë≥áÊñôÂ∫´Âíå HAN/HLAN Á∂≤Ë∑ØÊ®°ÂûãÈÄ≤Ë°å ICD ‰ª£Á¢ºÈ†êÊ∏¨„ÄÇÊàëÂÄëÈÇÑË©¶È©ó‰∫Ü ICD Âíå SNOMED CT Áü•Ë≠òÂ∫´‰πãÈñìÁöÑÂ∞çÊáâ„ÄÇÂú®ÊàëÂÄëÁöÑÂØ¶È©ó‰∏≠ÔºåÈÄô‰∫õÊ®°ÂûãÊèê‰æõ‰∫Ü 97.98% ‰ª£Á¢ºÁöÑÊúâÁî®Ë≥áË®ä„ÄÇÈÄôÈ†ÖË™øÊü•ÁµêÊûúÂèØ‰ª•ÁÇ∫ÂØ¶Âãô‰∏≠ÁöÑËá™ÂãïËá®Â∫äÁ∑®Á¢ºÂØ¶‰ΩúÊèê‰æõ‰∏Ä‰∫õË¶ãËß£Ôºå‰æãÂ¶ÇÂú®ÈÜ´Èô¢Áí∞Â¢É‰∏≠ÔºåÁî±Ëá®Â∫äÈÜ´Áîü‰ΩøÁî®ÁöÑÊú¨Âú∞ÈõªËÖ¶ÔºåÂ∞àÊ°àÈ†ÅÈù¢ \url{https://github.com/Glenj01/Medical-Coding}„ÄÇ

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ËÉΩ (AI) ÊîØÊåÅÁöÑÊ±∫Á≠ñÂà∂ÂÆöÊòØÊú™‰æÜ 6G Á∂≤Ë∑Ø‰∏≠ÁöÑÈóúÈçµÂÖÉÁ¥†ÔºåÂÖ∂‰∏≠Â∞áÂºïÂÖ•ÂéüÁîü AI ÁöÑÊ¶ÇÂøµ„ÄÇÊ≠§Â§ñÔºåAI Âª£Ê≥õÁî®Êñº‰∏çÂêåÁöÑÈóúÈçµÊáâÁî®‰∏≠Ôºå‰æãÂ¶ÇËá™ÂãïÈßïÈßõÂíåÈÜ´ÁôÇË®∫Êñ∑„ÄÇÂú®ÈÄô‰∫õÊáâÁî®‰∏≠Ôºå‰ΩøÁî® AI ‰ΩúÁÇ∫ÈªëÁõíÊ®°ÂûãÊòØÊúâÈ¢®Èö™‰∏îÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ„ÄÇÂõ†Ê≠§ÔºåÁêÜËß£Âíå‰ø°‰ªªÈÄô‰∫õÊ®°ÂûãÂÅöÂá∫ÁöÑÊ±∫Á≠ñËá≥ÈóúÈáçË¶Å„ÄÇËß£Ê±∫Ê≠§ÂïèÈ°åÁöÑÊñπÊ≥ïÊòØÈñãÁôºÂèØËß£Èáã AI (XAI) Êû∂ÊßãÔºåÊó®Âú®Ëß£ÈáãÈªëÁõíÊ®°ÂûãË°åÁÇ∫ËÉåÂæåÁöÑÈÇèËºØÔºåÂæûËÄåÁ¢∫‰øùÂÖ∂ÊúâÊïà‰∏îÂÆâÂÖ®ÁöÑÈÉ®ÁΩ≤„ÄÇÊúÄËøëÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂü∫ÊñºÊìæÂãïÁöÑ XAI-CHEST Ê°ÜÊû∂ÔºåË©≤Ê°ÜÊû∂Èù¢ÂêëÁÑ°Á∑öÈÄö‰ø°‰∏≠ÁöÑ‰ø°ÈÅì‰º∞Ë®à„ÄÇXAI-CHEST Ê°ÜÊû∂ÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÈÄöÈÅéÂú®ÁÑ°ÈóúËº∏ÂÖ•‰∏äÂºïÂÖ•È´òÂô™ËÅ≤‰æÜË≠òÂà•Áõ∏ÈóúÊ®°ÂûãËº∏ÂÖ•„ÄÇÈÄô‰ªΩÊâãÁ®øÊèê‰æõ‰∫Ü XAI-CHEST Ê°ÜÊû∂ÁöÑË©≥Á¥∞ÁêÜË´ñÂü∫Á§é„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÊé®Â∞é‰∫Ü XAI-CHEST ÊêçÂ§±ÂáΩÊï∏ÂíåÂô™ËÅ≤ÈñæÂÄºÂæÆË™øÂÑ™ÂåñÂïèÈ°åÁöÑËß£ÊûêË°®ÈÅîÂºè„ÄÇÂõ†Ê≠§ÔºåË®≠Ë®àÁöÑ XAI-CHEST Êèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊô∫ËÉΩËº∏ÂÖ•ÁâπÂæµÈÅ∏ÊìáÊñπÊ≥ïÔºåÂèØ‰ª•Âú®ÂÑ™ÂåñÊâÄÁî®Ê®°ÂûãÁöÑÊû∂ÊßãÁöÑÂêåÊôÇÈÄ≤‰∏ÄÊ≠•ÊèêÈ´òÊï¥È´îÊÄßËÉΩ„ÄÇÊ®°Êì¨ÁµêÊûúË°®ÊòéÔºåXAI-CHEST Ê°ÜÊû∂Êèê‰æõ‰∫ÜÊúâÊïàÁöÑËß£ÈáãÔºåÂú®Èôç‰ΩéÊâÄÈúÄÁöÑË®àÁÆóË§áÈõúÂ∫¶ÁöÑÂêåÊôÇÔºåÊèê‰æõ‰∫ÜÊîπÈÄ≤ÁöÑÊØîÁâπÈåØË™§ÁéáÊÄßËÉΩÔºåËÄåÈÄôËàáÂü∫ÊñºÂÇ≥Áµ± DL ÁöÑ‰ø°ÈÅì‰º∞Ë®àÁõ∏ÊØî„ÄÇ

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

ÊëòË¶ÅÔºöËøôÁØáËÆ∫ÊñáÊèêÂá∫‰∫ÜÁî®‰∫é‰ªéËßÜÁΩëËÜúÁúºÂ∫ïÂõæÂÉèËøõË°åÁñæÁóÖÂàÜÁ±ªÁöÑÊâ©Âº†ÊÆãÂ∑ÆÁΩëÁªú (ResNet) Ê®°Âûã„ÄÇÊâ©Âº†Âç∑ÁßØÊª§Ê≥¢Âô®Áî®‰∫éÊõøÊç¢ ResNet Ê®°ÂûãËæÉÈ´òÂ±Ç‰∏≠ÁöÑÊ≠£Â∏∏Âç∑ÁßØÊª§Ê≥¢Âô®ÔºàÊâ©Âº† ResNetÔºâÔºå‰ª•ÊîπÂñÑÊÑüÁü•Âú∫Ôºå‰ªéËÄåÈíàÂØπÁñæÁóÖÂàÜÁ±ªÂØπÊ≠£Â∏∏ ResNet Ê®°ÂûãËøõË°åÊîπËøõ„ÄÇÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫ÜÈááÁî®Ê∑±Â∫¶Â≠¶‰π†ÁöÑËÆ°ÁÆóÊú∫ËæÖÂä©ËØäÊñ≠Â∑•ÂÖ∑ÔºåÂπ∂ÈÄöËøáÂèØËß£ÈáäÁöÑ AI ÊäÄÊúØËøõË°å‰∫ÜÂ¢ûÂº∫„ÄÇËøô‰∫õÊäÄÊúØÊó®Âú®‰ΩøËØ•Â∑•ÂÖ∑ÁöÑÂÜ≥Á≠ñËøáÁ®ãÈÄèÊòéÂåñÔºå‰ªéËÄå‰ΩøÂåªÂ≠¶‰∏ì‰∏ö‰∫∫Â£´ËÉΩÂ§üÁêÜËß£Âíå‰ø°‰ªª AI ÁöÑËØäÊñ≠ÂÜ≥Á≠ñ„ÄÇÂÆÉ‰ª¨‰∏éÂΩì‰ªäÁöÑÂåªÁñó‰øùÂÅ•È¢ÜÂüüÂ∞§‰∏∫Áõ∏ÂÖ≥ÔºåÂú®ËØ•È¢ÜÂüüÔºåÂØπ AI Â∫îÁî®ÁöÑÈÄèÊòéÂ∫¶ÈúÄÊ±Ç‰∏çÊñ≠Â¢ûÈïøÔºå‰ª•Á°Æ‰øùÂÖ∂ÂèØÈù†ÊÄßÂíåÂêà‰πéÈÅìÂæ∑ÁöÑ‰ΩøÁî®„ÄÇÊâ©Âº† ResNet Áî®‰ΩúÊ≠£Â∏∏ ResNet ÁöÑÊõø‰ª£ÂìÅÔºå‰ª•ÊèêÈ´òËßÜÁΩëËÜúÁúºÈÉ®ÁñæÁóÖÁöÑÂàÜÁ±ªÂáÜÁ°ÆÊÄßÂπ∂ÂáèÂ∞ëÊâÄÈúÄÁöÑËÆ°ÁÆóÊó∂Èó¥„ÄÇÊú¨Â∑•‰Ωú‰∏≠‰ΩøÁî®ÁöÑÊï∞ÊçÆÈõÜÊòØÁúºÁßëÁñæÁóÖÊô∫ËÉΩËØÜÂà´ (ODIR) Êï∞ÊçÆÈõÜÔºåËøôÊòØ‰∏Ä‰∏™ÁªìÊûÑÂåñÁöÑÁúºÁßëÊï∞ÊçÆÂ∫ìÔºåÂåÖÂê´ÂÖ´Á±ªÊ∂µÁõñÂ§ßÂ§öÊï∞Â∏∏ËßÅËßÜÁΩëËÜúÁúºÈÉ®ÁñæÁóÖ„ÄÇÊú¨Â∑•‰Ωú‰∏≠‰ΩøÁî®ÁöÑËØÑ‰º∞ÊåáÊ†áÂåÖÊã¨Á≤æÁ°ÆÂ∫¶„ÄÅÂè¨ÂõûÁéá„ÄÅÂáÜÁ°ÆÂ∫¶Âíå F1 ÂæóÂàÜ„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÂØπ ResNet-18„ÄÅResNet-34„ÄÅResNet-50„ÄÅResNet-101 Âíå ResNet-152 ‰∫î‰∏™Âèò‰ΩìÁöÑÊ≠£Â∏∏ ResNet Ê®°ÂûãÂíåÊâ©Âº† ResNet Ê®°ÂûãËøõË°å‰∫ÜÊØîËæÉÁ†îÁ©∂„ÄÇ‰∏éÊ≠£Â∏∏ ResNet Áõ∏ÊØîÔºåÊâ©Âº† ResNet Ê®°ÂûãÊòæÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑÁªìÊûúÔºåÂú® ODIR Â§öÁ±ªÁñæÁóÖÂàÜÁ±ª‰∏≠Ôºå‰∏äËø∞ÂêÑ‰∏™Âèò‰ΩìÁöÑÂπ≥Âùá F1 ÂæóÂàÜ‰∏∫ 0.71„ÄÅ0.70„ÄÅ0.69„ÄÅ0.67 Âíå 0.70„ÄÇ

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v2 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
existing surveys on the trustworthiness of foundation models do not adequately
address their specific variations and applications within the medical imaging
domain. This survey aims to fill that gap by presenting a novel taxonomy of
foundation models used in medical imaging and analyzing the key motivations for
ensuring their trustworthiness. We review current research on foundation models
in major medical imaging applications, focusing on segmentation, medical report
generation, medical question and answering (Q\&A), and disease diagnosis. These
areas are highlighted because they have seen a relatively mature and
substantial number of foundation models compared to other applications. We
focus on literature that discusses trustworthiness in medical image analysis
manuscripts. We explore the complex challenges of building trustworthy
foundation models for each application, summarizing current concerns and
strategies for enhancing trustworthiness. Furthermore, we examine the potential
of these models to revolutionize patient care. Our analysis underscores the
imperative for advancing towards trustworthy AI in medical image analysis,
advocating for a balanced approach that fosters innovation while ensuring
ethical and equitable healthcare delivery.

ÊëòË¶ÅÔºöÂü∫Á§éÊ®°ÂûãÂú®ÈÜ´Â≠∏ÂΩ±ÂÉèÊñπÈù¢ÁöÑÂø´ÈÄüÈÄ≤Â±ïÔºå‰ª£Ë°®ËëóÂú®Âä†Âº∑Ë®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÂíåÂÄã‰∫∫ÂåñÊ≤ªÁôÇÊñπÈù¢ÈÇÅÂá∫‰∏ÄÂ§ßÊ≠•„ÄÇÁÑ∂ËÄåÔºåÂü∫Á§éÊ®°ÂûãÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÈÉ®ÁΩ≤ÈúÄË¶ÅÂ∞çÂÖ∂ÂèØ‰ø°Â∫¶ÈÄ≤Ë°åÂö¥Ê†ºÁöÑÂØ©Êü•ÔºåÂåÖÊã¨Èö±ÁßÅ„ÄÅÁ©©ÂÅ•ÊÄß„ÄÅÂèØÈù†ÊÄß„ÄÅÂèØËß£ÈáãÊÄßÂíåÂÖ¨Âπ≥ÊÄß„ÄÇÁõÆÂâçÈóúÊñºÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠Âü∫Á§éÊ®°ÂûãÁöÑË™øÊü•ÊñáÁçª‰∏≠È°ØÁ§∫Âá∫Áõ∏Áï∂Â§ßÁöÑÂ∑ÆË∑ùÔºåÁâπÂà•ÊòØÂú®ÂèØ‰ø°Â∫¶ÊñπÈù¢„ÄÇÊ≠§Â§ñÔºåÁèæÊúâÈóúÊñºÂü∫Á§éÊ®°ÂûãÂèØ‰ø°Â∫¶ÁöÑË™øÊü•‰∏¶Êú™ÂÖÖÂàÜËß£Ê±∫ÂÖ∂Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèÈ†òÂüü‰∏≠ÁöÑÁâπÂÆöËÆäÂåñÂíåÊáâÁî®„ÄÇÊú¨Ë™øÊü•Êó®Âú®ÈÄöÈÅéÊèêÂá∫ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠‰ΩøÁî®ÁöÑÂü∫Á§éÊ®°ÂûãÁöÑÊñ∞ÂàÜÈ°ûÊ≥ï‰∏¶ÂàÜÊûêÁ¢∫‰øùÂÖ∂ÂèØ‰ø°Â∫¶ÁöÑÈóúÈçµÂãïÊ©üÔºå‰æÜÂ°´Ë£úÈÄô‰∏ÄÁ©∫ÁôΩ„ÄÇÊàëÂÄëÂõûÈ°ß‰∫ÜÂü∫Á§éÊ®°ÂûãÂú®‰∏ªË¶ÅÈÜ´Â≠∏ÂΩ±ÂÉèÊáâÁî®‰∏≠ÁöÑÁï∂ÂâçÁ†îÁ©∂ÔºåÈáçÈªûÈóúÊ≥®ÂàÜÂâ≤„ÄÅÈÜ´ÁôÇÂ†±ÂëäÁîüÊàê„ÄÅÈÜ´ÁôÇÂïèÈ°åÂíåÂõûÁ≠î (Q&A) ‰ª•ÂèäÁñæÁóÖË®∫Êñ∑„ÄÇÈÄô‰∫õÈ†òÂüü‰πãÊâÄ‰ª•Ë¢´Âº∑Ë™øÔºåÊòØÂõ†ÁÇ∫ËàáÂÖ∂‰ªñÊáâÁî®Áõ∏ÊØîÔºåÂÆÉÂÄëÂ∑≤Á∂ìÁúãÂà∞Áõ∏Â∞çÊàêÁÜü‰∏îÂ§ßÈáèÁöÑÂü∫Á§éÊ®°Âûã„ÄÇÊàëÂÄëÂ∞àÊ≥®ÊñºÊé¢Ë®éÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûêÊâãÁ®ø‰∏≠ÂèØ‰ø°Â∫¶ÁöÑÊñáÁçª„ÄÇÊàëÂÄëÊé¢Ë®é‰∫ÜÁÇ∫ÊØèÂÄãÊáâÁî®ÊßãÂª∫ÂèØ‰ø°Âü∫Á§éÊ®°ÂûãÁöÑË§áÈõúÊåëÊà∞ÔºåÁ∏ΩÁµê‰∫ÜÁï∂ÂâçÈóúÊ≥®ÈªûÂíåÂ¢ûÂº∑ÂèØ‰ø°Â∫¶ÁöÑÁ≠ñÁï•„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÈÄô‰∫õÊ®°ÂûãÂú®Èù©Êñ∞ÊÇ£ËÄÖË≠∑ÁêÜÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÂº∑Ë™ø‰∫ÜÂú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûê‰∏≠ÊúùËëóÂèØ‰ø°Ë≥¥ÁöÑ‰∫∫Â∑•Êô∫ÊÖßÈÇÅÈÄ≤ÁöÑÂøÖË¶ÅÊÄßÔºå‰∏¶ÂÄ°Â∞é‰∏ÄÁ®ÆÂπ≥Ë°°ÁöÑÊñπÊ≥ïÔºåÊó¢ËÉΩ‰øÉÈÄ≤ÂâµÊñ∞ÔºåÂèàËÉΩÁ¢∫‰øùÈÅìÂæ∑ÂíåÂÖ¨Âπ≥ÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÊúçÂãô„ÄÇ

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

ÊëòË¶ÅÔºöÂ∫äÈÇäË∂ÖÈü≥Ê≥¢ (POCUS) ÊòØËá®Â∫äÈÜ´Â∏´Âú®ÊÇ£ËÄÖÂ∫äÈÇäÈÄ≤Ë°åÂíåËß£ËÆÄË∂ÖÈü≥Ê≥¢ÊéÉÊèèÁöÑÂØ¶Âãô„ÄÇÁÑ∂ËÄåÔºåËß£ËÆÄÈÄô‰∫õÂΩ±ÂÉèÊâÄÈúÄÁöÑÂ∞àÊ•≠Áü•Ë≠òÁõ∏Áï∂ÂèØËßÄÔºåËÄå‰∏îÂú®Á∑äÊÄ•ÊÉÖÊ≥Å‰∏ãÂèØËÉΩ‰∏¶ÈùûÈö®ÊôÇÂÖ∑ÂÇô„ÄÇÈÄôÁ®ÆÁèæÂØ¶ÊÉÖÊ≥Å‰ΩøÂæóÊ©üÂô®Â≠∏ÁøíÂàÜÈ°ûÂô®Á≠âÊºîÁÆóÊ≥ïÂ∞çÊñºÂä†Âº∑‰∫∫È°ûÊ±∫Á≠ñËÆäÂæóÊ•µÁÇ∫ÊúâÂÉπÂÄº„ÄÇPOCUS Ë£ùÁΩÆÊ≠£‰ª•ÂêàÁêÜÊàêÊú¨Êé®Âá∫ÔºåÂ∞∫ÂØ∏ÁÇ∫ÊâãÊ©üÂ§ßÂ∞è„ÄÇÂ∞á POCUS Ë£ùÁΩÆËΩâËÆäÁÇ∫ÊïëÁîüÂ∑•ÂÖ∑ÁöÑÊåëÊà∞Âú®ÊñºÔºåËß£ËÆÄË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÈúÄË¶ÅÂ∞àÈñÄË®ìÁ∑¥ÂíåÁ∂ìÈ©ó„ÄÇ‰∏çÂπ∏ÁöÑÊòØÔºåÂèñÂæóÊ≠£ÂêëË®ìÁ∑¥ÂΩ±ÂÉèÁöÑÂõ∞Èõ£Â∫¶‰ª£Ë°®ËëóÂª∫ÁΩÆÊúâÊïàÁéá‰∏îÊ∫ñÁ¢∫ÁöÑÂàÜÈ°ûÂô®ÁöÑ‰∏ÄÂ§ßÈöúÁ§ô„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂòóË©¶Êé¢Ë®éÁöÑÂïèÈ°åÊòØÂ¶Ç‰ΩïÊé¢Á¥¢Á≠ñÁï•Ôºå‰ª•ÊèêÈ´ò‰ΩøÁî®Á®ÄÁñèË≥áÊñôË®ìÁ∑¥ÁöÑÂàÜÈ°ûÂô®ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÂÅáË®≠‰ΩøÁî®Â∞ëÊï∏Ë≥áÊñôÂØ¶‰æãÈÄ≤Ë°åË®ìÁ∑¥ÂèØËÉΩ‰∏çË∂≥‰ª•ËÆìÂàÜÈ°ûÂô®Ê¶ÇÊã¨ÔºåÂ∞éËá¥ÂÆÉÂÄëÈÅéÂ∫¶Êì¨Âêà„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ï‰ΩøÁî®ÂèØËß£Èáã AI Â¢ûÂº∑ÊñπÊ≥ïÔºå‰ª•ÂçîÂä©ÊºîÁÆóÊ≥ïÂæûËºÉÂ∞ëÁöÑË≥áÊñô‰∏≠Â≠∏ÁøíÊõ¥Â§öÔºå‰∏¶ÊΩõÂú®ÂçîÂä©ÂàÜÈ°ûÂô®Êõ¥Â•ΩÂú∞Ê¶ÇÊã¨„ÄÇ

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºåÁæéÂúãË¶ãË≠â‰∫ÜÈõªÂ≠êÁÖôÊàñÈõªÂ≠êÈ¶ôËè∏‰ΩøÁî®ÁéáÂ§ßÂπÖÊøÄÂ¢ûÔºåÂ∞éËá¥ÈõªÂ≠êÁÖôÂíåÈõªÂ≠êÁÖô‰ΩøÁî®Áõ∏ÈóúËÇ∫ÊêçÂÇ∑ (EVALI) ÁóÖ‰æãÈ°ØËëóÂ¢ûÂä†ÔºåÂú® 2019 Âπ¥ EVALI ÁàÜÁôºÊúüÈñìÈÄ†Êàê‰ΩèÈô¢ÂíåÊ≠ª‰∫°ÔºåÂá∏È°Ø‰∫ÜÁêÜËß£ÈõªÂ≠êÁÖôË°åÁÇ∫ÂíåÂà∂ÂÆöÊúâÊïàÊàíËè∏Á≠ñÁï•ÁöÑËø´ÂàáÊÄß„ÄÇÁî±ÊñºÁ§æÁæ§Â™íÈ´îÂπ≥Âè∞ÁöÑÊôÆÂèäÔºåÂÖ®ÁêÉË∂ÖÈÅé 47 ÂÑÑ‰ΩøÁî®ËÄÖ‰ΩøÁî®ÂÆÉÂÄëÈÄ≤Ë°åÈÄ£Áµê„ÄÅÊ∫ùÈÄö„ÄÅÊñ∞ËÅûÂíåÂ®õÊ®ÇÔºåÂÖ∂‰∏≠ÂæàÂ§ß‰∏ÄÈÉ®ÂàÜËàáÂÅ•Â∫∑Áõ∏ÈóúÔºåÂõ†Ê≠§Â∞áÁ§æÁæ§Â™íÈ´îË≥áÊñôÂª∫Á´ãÁÇ∫ÂÖ¨ÂÖ±Ë°õÁîüÁ†îÁ©∂‰∏≠ÁÑ°ÂÉπÁöÑÊúâÊ©üË≥áÊñôË≥áÊ∫ê„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂæû Reddit ‰∏ä‰∏ÄÂÄãÈõªÂ≠êÁÖôÂ≠êÁ§æÁæ§‰∏≠ÊèêÂèñ‰∏ÄÂÄãÁØÑ‰æãË≥áÊñôÈõÜÔºå‰ª•ÂàÜÊûê‰ΩøÁî®ËÄÖÁöÑÊàíÈõªÂ≠êÁÖôÊÑèÂúñ„ÄÇÂà©Áî® OpenAI ÊúÄÊñ∞ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã GPT-4 ÈÄ≤Ë°åÂè•Â≠êÂ±§Á¥öÁöÑÊàíÈõªÂ≠êÁÖôÊÑèÂúñÂÅµÊ∏¨ÔºåÊú¨Á†îÁ©∂ÊØîËºÉ‰∫ÜÊ≠§Ê®°ÂûãÁöÑÁµêÊûúËàáÂ§ñË°å‰∫∫ÂíåËá®Â∫äÂ∞àÂÆ∂Ë®ªËß£„ÄÇ‰ΩøÁî®‰∏çÂêåÁöÑÊèêÁ§∫Á≠ñÁï•Ôºå‰æãÂ¶ÇÈõ∂Ê¨°Â≠∏Áøí„ÄÅ‰∏ÄÊ¨°Â≠∏Áøí„ÄÅÂ∞ëÊ¨°Â≠∏ÁøíÂíåÊÄùËÄÉÈèàÊèêÁ§∫ÔºåÊàëÂÄëÈñãÁôº‰∫Ü 8 ÂÄãÊèêÁ§∫ÔºåË©≥Á¥∞Á®ãÂ∫¶‰∏çÂêåÔºåÂêë GPT-4 Ëß£Èáã‰ªªÂãôÔºå‰∏¶Ë©ï‰º∞ÈÄô‰∫õÁ≠ñÁï•ÂΩºÊ≠§‰πãÈñìÁöÑÊïàËÉΩ„ÄÇÈÄô‰∫õÂàùÊ≠•ÁôºÁèæÂº∑Ë™ø‰∫Ü GPT-4 Âú®Á§æÁæ§Â™íÈ´îË≥áÊñôÂàÜÊûê‰∏≠ÁöÑÊΩõÂäõÔºåÁâπÂà•ÊòØÂú®Ë≠òÂà•‰∫∫È°ûÂÅµÊ∏¨ÂèØËÉΩÁÑ°Ê≥ïÂØüË¶∫ÁöÑ‰ΩøÁî®ËÄÖÂæÆÂ¶ôÊÑèÂúñÊñπÈù¢„ÄÇ

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

ÊëòË¶ÅÔºö<paragraph>‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÁõÆÂâçÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰æùË≥¥ÊñºÁº∫‰πèÂèØËß£ÈáãÊÄßÁöÑÈªëÁõíÊ©üÂô®Â≠∏ÁøíÊ®°Âûã„ÄÇÂèØËß£ÈáãÊÄß‰∫∫Â∑•Êô∫ÊÖßÔºàXAIÔºâÈ†òÂüüËá¥ÂäõÊñºËß£Ê±∫ÈÄôÂÄã‰∏ªË¶ÅÂïèÈ°åÔºåÈÄôÂú®ÈáëËûç„ÄÅÊ≥ïÂæãÂíåÂÅ•Â∫∑Á≠âÈ´òÈ¢®Èö™È†òÂüüËá≥ÈóúÈáçË¶Å„ÄÇ
ÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÁØÑÁñáË´ñÂÆöÁæ© AI Ê®°ÂûãÂèäÂÖ∂ÂèØËß£ÈáãÊÄßÁöÑÊñπÊ≥ï„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊé°Áî®ÁµÑÂêàÊ®°ÂûãÁöÑÊ¶ÇÂøµÔºåÂÆÉ‰ª•ÂΩ¢ÂºèÂº¶ÂúñÁöÑÂΩ¢ÂºèÁúãÂæÖÊ®°ÂûãÔºåÈÄô‰∫õÂº¶ÂúñÊçïÁç≤‰∫ÜÊ®°ÂûãÁöÑÊäΩË±°ÁµêÊßãÂèäÂÖ∂ÂÖ∑È´îÂØ¶Áèæ„ÄÇÈÄôÁ®ÆÁ∂úÂêàËßÄÈªûÂåÖÂê´‰∫ÜÁ¢∫ÂÆöÊÄß„ÄÅÊ¶ÇÁéáÊÄßÂíåÈáèÂ≠êÊ®°Âûã„ÄÇÊàëÂÄëÂ∞áÂêÑÁ®Æ AI Ê®°Âûã‰ΩúÁÇ∫ÁµÑÂêàÊ®°ÂûãÈÄ≤Ë°åÊØîËºÉÔºåÂåÖÊã¨Á∑öÊÄßÂíåÂü∫ÊñºË¶èÂâáÁöÑÊ®°Âûã„ÄÅÔºàÈÅûËø¥ÔºâÁ•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÅTransformer„ÄÅVAEÔºå‰ª•ÂèäÂõ†ÊûúÂíå DisCoCirc Ê®°Âûã„ÄÇ
Êé•‰∏ã‰æÜÔºåÊàëÂÄëÊ†πÊìöÊ®°ÂûãÁöÑÁµÑÂêàÁµêÊßãÁµ¶Âá∫Ê®°ÂûãËß£ÈáãÁöÑÂÆöÁæ©ÔºåÂ±ïÁ§∫Â¶Ç‰ΩïÂàÜÊûêÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÔºå‰∏¶‰ΩøÁî®ÂÆÉ‰æÜÊæÑÊ∏Ö XAI ‰∏≠ÁöÑÂ∏∏Ë¶ã‰∏ªÈ°å„ÄÇÊàëÂÄëÁôºÁèæÔºåËÆìÊ®ôÊ∫ñÁöÑ„ÄåÂÖßÂú®ÂèØËß£Èáã„ÄçÊ®°ÂûãÂ¶ÇÊ≠§ÈÄèÊòéÁöÑÂéüÂõ†Âú®ÂúñË°®‰∏≠Ë°®ÁèæÂæóÊúÄÁÇ∫Ê∏ÖÊ•ö„ÄÇÈÄôÂºïÂ∞éÊàëÂÄëÂæóÂá∫Êõ¥‰∏ÄËà¨ÁöÑÁµÑÂêàÂèØËß£ÈáãÔºàCIÔºâÊ®°ÂûãÊ¶ÇÂøµÔºåÂÆÉÂè¶Â§ñÈÇÑÂåÖÊã¨Âõ†Êûú„ÄÅÊ¶ÇÂøµÁ©∫ÈñìÂíå DisCoCirc Ê®°Âûã„ÄÇ
Êé•‰∏ã‰æÜÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü CI Ê®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÂÑ™Âã¢„ÄÇÈ¶ñÂÖàÔºåÂÆÉÂÄëÁöÑÁµÑÂêàÁµêÊßãÂÖÅË®±Ë®àÁÆóÂÖ∂‰ªñÊÑüËààË∂£ÁöÑÈáèÔºå‰∏¶ÂèØËÉΩÈÄöÈÅéÂåπÈÖçÊ®°ÂûãÁöÑÁµêÊßã‰æÜ‰øÉÈÄ≤ÂæûÊ®°ÂûãÂà∞Ë¢´Âª∫Ê®°ÁèæË±°ÁöÑÊé®ÁêÜ„ÄÇÂÖ∂Ê¨°ÔºåÂÆÉÂÄëÂÖÅË®±Â∞çÂÖ∂Ë°åÁÇ∫ÈÄ≤Ë°åÂúñËß£Ë™™ÊòéÔºåÈÄô‰∫õË™™ÊòéÂü∫ÊñºÂΩ±ÈüøÁ¥ÑÊùü„ÄÅÂúñËß£ÊâãË°ìÂíåÈáçÂØ´Ë™™Êòé„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñ‰∫ÜÈÄôÁ®ÆÊñπÊ≥ïÁöÑË®±Â§öÊú™‰æÜÊñπÂêëÔºåÊèêÂá∫‰∫ÜÂ¶Ç‰ΩïÂú®ÂØ¶Ë∏ê‰∏≠Â≠∏ÁøíÈÄôÁ®ÆÊúâÊÑèÁæ©ÁöÑÁµêÊßãÂåñÊ®°ÂûãÁöÑÂïèÈ°å„ÄÇ</paragraph>

##### **Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**
2406.12142v2 by Vincent Olesen, Nina Weng, Aasa Feragen, Eike Petersen

Machine learning models have achieved high overall accuracy in medical image
analysis. However, performance disparities on specific patient groups pose
challenges to their clinical utility, safety, and fairness. This can affect
known patient groups - such as those based on sex, age, or disease subtype - as
well as previously unknown and unlabeled groups. Furthermore, the root cause of
such observed performance disparities is often challenging to uncover,
hindering mitigation efforts. In this paper, to address these issues, we
leverage Slice Discovery Methods (SDMs) to identify interpretable
underperforming subsets of data and formulate hypotheses regarding the cause of
observed performance disparities. We introduce a novel SDM and apply it in a
case study on the classification of pneumothorax and atelectasis from chest
x-rays. Our study demonstrates the effectiveness of SDMs in hypothesis
formulation and yields an explanation of previously observed but unexplained
performance disparities between male and female patients in widely used chest
X-ray datasets and models. Our findings indicate shortcut learning in both
classification tasks, through the presence of chest drains and ECG wires,
respectively. Sex-based differences in the prevalence of these shortcut
features appear to cause the observed classification performance gap,
representing a previously underappreciated interaction between shortcut
learning and model fairness analyses.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÂú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûê‰∏≠Â∑≤ÈÅîÂà∞Êï¥È´îÈ´òÊ∫ñÁ¢∫Â∫¶„ÄÇÁÑ∂ËÄåÔºåÁâπÂÆöÊÇ£ËÄÖÁæ§È´îÁöÑÊïàËÉΩÂ∑ÆÁï∞Â∞çÂÖ∂Ëá®Â∫äÊïàÁî®„ÄÅÂÆâÂÖ®ÊÄßËàáÂÖ¨Âπ≥ÊÄßÊßãÊàêÊåëÊà∞„ÄÇÈÄôÂèØËÉΩÊúÉÂΩ±ÈüøÂ∑≤Áü•ÁöÑÊÇ£ËÄÖÁæ§È´îÔºà‰æãÂ¶ÇÂü∫ÊñºÊÄßÂà•„ÄÅÂπ¥ÈΩ°ÊàñÁñæÁóÖ‰∫ûÂûãÔºâ‰ª•ÂèäÂÖàÂâçÊú™Áü•‰∏îÊú™Ê®ôÁ±§ÁöÑÁæ§È´î„ÄÇÊ≠§Â§ñÔºåÊ≠§È°ûËßÄÂØüÂà∞ÁöÑÊïàËÉΩÂ∑ÆÁï∞ÁöÑÊ†πÊú¨ÂéüÂõ†ÈÄöÂ∏∏Èõ£‰ª•ÁôºÁèæÔºåÈòªÁ§ô‰∫ÜÁ∑©Ëß£Êé™ÊñΩ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÂà©Áî®ÂàáÁâáÁôºÁèæÊñπÊ≥ï (SDM) ‰æÜË≠òÂà•ÂèØËß£ÈáãÁöÑË≥áÊñôÊïàËÉΩ‰∏ç‰Ω≥Â≠êÈõÜÔºå‰∏¶ÈáùÂ∞çËßÄÂØüÂà∞ÁöÑÊïàËÉΩÂ∑ÆÁï∞ÂéüÂõ†Âà∂ÂÆöÂÅáË®≠„ÄÇÊàëÂÄëÂºïÂÖ•‰∏ÄÁ®ÆÊñ∞ÁöÑ SDMÔºå‰∏¶Âú®ËÉ∏ÈÉ® X ÂÖâÁâá‰∏≠ËÇ∫ÁÇéÂíåËÇ∫‰∏çÂºµÂàÜÈ°ûÁöÑÊ°à‰æãÁ†îÁ©∂‰∏≠ÊáâÁî®ÂÆÉ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ë≠âÊòé‰∫Ü SDM Âú®ÂÅáË®≠Âà∂ÂÆö‰∏≠ÁöÑÊúâÊïàÊÄßÔºå‰∏¶Â∞çÂª£Ê≥õ‰ΩøÁî®ÁöÑËÉ∏ÈÉ® X ÂÖâÁâáË≥áÊñôÈõÜÂíåÊ®°Âûã‰∏≠ÂÖàÂâçËßÄÂØüÂà∞‰ΩÜÁÑ°Ê≥ïËß£ÈáãÁöÑÁî∑ÊÄßÂíåÂ•≥ÊÄßÊÇ£ËÄÖ‰πãÈñìÁöÑÊïàËÉΩÂ∑ÆÁï∞Êèê‰æõ‰∫ÜËß£Èáã„ÄÇÊàëÂÄëÁöÑÁôºÁèæË°®ÊòéÔºåÂú®ÂàÜÈ°û‰ªªÂãô‰∏≠ÔºåÈÄèÈÅéËÉ∏ËÖîÂºïÊµÅÁÆ°ÂíåÂøÉÈõªÂúñÂ∞éÁ∑öÁöÑÂ≠òÂú®ÔºåÂ≠òÂú®Êç∑ÂæëÂ≠∏Áøí„ÄÇÈÄô‰∫õÊç∑ÂæëÁâπÂæµÁöÑÁõõË°åÁéáÂ≠òÂú®Âü∫ÊñºÊÄßÂà•ÁöÑÂ∑ÆÁï∞Ôºå‰ºº‰πéÊúÉÂ∞éËá¥ËßÄÂØüÂà∞ÁöÑÂàÜÈ°ûÊïàËÉΩÂ∑ÆË∑ùÔºåÈÄô‰ª£Ë°®Êç∑ÂæëÂ≠∏ÁøíÂíåÊ®°ÂûãÂÖ¨Âπ≥ÊÄßÂàÜÊûê‰πãÈñìÂÖàÂâçÊú™ÂèóÂà∞ÈáçË¶ñÁöÑ‰∫§‰∫í‰ΩúÁî®„ÄÇ

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

ÊëòË¶ÅÔºöÂÖÉÂÆáÂÆôÁöÑÊ¶ÇÂøµÂú®ÂêÑÂÄãÈ†òÂüüÈÉΩÂÇôÂèóÈóúÊ≥®ÔºåÂÖ∂ÈáçË¶ÅÊáâÁî®‰πã‰∏Ä‰æøÊòØÈÜ´ÁôÇ‰øùÂÅ•„ÄÇÂÖÉÂÆáÂÆôÊúâÂ∑®Â§ßÁöÑÊΩõÂäõÈÄèÈÅéÊîπËÆäÁóÖÊÇ£ÁÖßË≠∑„ÄÅÈÜ´Â≠∏ÊïôËÇ≤Ôºå‰ª•ÂèäÊïôÂ≠∏/Â≠∏ÁøíÂíåÁ†îÁ©∂ÁöÑÊñπÂºè‰æÜËΩâÂûãÈÜ´ÁôÇ‰øùÂÅ•„ÄÇÊú¨Á†îÁ©∂ÁöÑÁõÆÁöÑÊòØÊèê‰æõÂÖÉÂÆáÂÆôÂü∫Êú¨Ê¶ÇÂøµÂíåÂü∫Á§éÊäÄË°ìÁöÑ‰ªãÁ¥π„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÂÖÉÂÆáÂÆôÂú®ÈÜ´ÁôÇ‰øùÂÅ•ËÉåÊôØ‰∏ãÁöÑÂÑ™Áº∫ÈªûÔºå‰∏¶ÂæûÊäÄË°ìÂíå AI ÁöÑËßíÂ∫¶ÂàÜÊûêÂÖ∂ÊΩõÂäõ„ÄÇÁâπÂà•ÊòØÔºåË®éË´ñ‰∫ÜÊ©üÂô®Â≠∏ÁøíÊñπÊ≥ïÁöÑËßíËâ≤ÔºõÊàëÂÄëÂ∞áË™™ÊòéÂ¶Ç‰ΩïÂ∞áÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïÊáâÁî®ÊñºÂÖÉÂÆáÂÆôÁî¢ÁîüÁöÑË≥áÊñôÔºå‰ª•Áç≤ÂæóÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®ÊñπÈù¢ÁöÑÊõ¥‰Ω≥Ë¶ãËß£„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄèÈÅéÊé¢Ë®éÂçÄÂ°äÈèàÁ≠âÊñ∞ËààÊäÄË°ìÔºå‰∏¶Ëß£Ê±∫Èö±ÁßÅÂïèÈ°åÔºå‰æÜÊé¢Ë®éÂÖÉÂÆáÂÆôÂú®ÈÜ´ÁôÇ‰øùÂÅ•ÊñπÈù¢ÁöÑÊú™‰æÜÈ°òÊôØ„ÄÇÊú¨Á†îÁ©∂ÁöÑÁôºÁèæÊúâÂä©ÊñºÊõ¥Ê∑±ÂÖ•Âú∞‰∫ÜËß£ÂÖÉÂÆáÂÆôÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÊáâÁî®Ôºå‰ª•ÂèäÂÖ∂Âú®ÈÜ´ÁôÇÊúçÂãôÊèê‰æõÊñπÈù¢ÁôºÊèÆÈù©ÂëΩÊÄßËÆäÈù©ÁöÑÊΩõÂäõ„ÄÇ

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

ÊëòË¶ÅÔºöÊÖ¢ÊÄßËÖéËáüÁóÖÔºàCKDÔºâÊòØ‰∏ÄÁ®ÆÂª£Ê≥õÁöÑÊÖ¢ÊÄßÁñæÁóÖÔºåÊ≤íÊúâÂ∑≤Áü•ÁöÑÊúÄÁµÇÁôÇÊ≥ï‰∏îÁôºÁóÖÁéáÂæàÈ´ò„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåÈÄ≤Ë°åÊÄßÊÖ¢ÊÄßËÖéËáüÁóÖÔºàCKDÔºâÊòØ‰∏ÄÁ®ÆÁï∞Ë≥™ÊÄßÁñæÁóÖÔºåÊúÉÈ°ØËëóÂΩ±ÈüøËÖéËáüÁµêÊßãÂíåÂäüËÉΩÔºåÊúÄÁµÇÂ∞éËá¥ËÖéË°∞Á´≠„ÄÇÈö®ËëóÊôÇÈñìÁöÑÊé®ÁßªÔºåÊÖ¢ÊÄßËÖéËáüÁóÖÂ∑≤ÂæûÂΩ±ÈüøÂ∞ëÊï∏‰∫∫ÁöÑËá¥ÂëΩÁñæÁóÖËΩâËÆäÁÇ∫‰∏ÄÁ®ÆÂö¥ÈáçÁ®ãÂ∫¶‰∏çÂêåÁöÑÂ∏∏Ë¶ãÁñæÁóÖ„ÄÇÊú¨Á†îÁ©∂ÁöÑÁõÆÊ®ôÊòØ‰ΩøÁî®ÈõÜÊàêÂ≠∏ÁøíÂíåÂèØËß£ÈáãÁöÑ AI ÈÄ≤Ë°åÊó©ÊúüÈ†êÂæåÂíå CKD Ê™¢Ê∏¨Ôºå‰∏¶Ë¶ñË¶∫Âåñ‰∏ªÂ∞éÁâπÂæµ„ÄÅÁâπÂæµÂàÜÊï∏ÂíåË°®ÁèæÂá∫ÁöÑÂÄº„ÄÇÁÇ∫Ê≠§ÔºåÊèêÂá∫‰∫Ü‰∏ÄÁ®Æ AI È©ÖÂãïÁöÑÈ†êÊ∏¨ÂàÜÊûêÊñπÊ≥ïÔºå‰ª•Âπ´Âä©Ëá®Â∫äÈÜ´ÁîüÁÇ∫ÂÄãÂà•ÊÇ£ËÄÖÈñãÂÖ∑ÁîüÊ¥ªÊñπÂºè‰øÆÊîπÂª∫Ë≠∞Ôºå‰ª•Èôç‰ΩéÈÄôÁ®ÆÁñæÁóÖÁöÑÈÄ≤Â±ïÈÄüÂ∫¶„ÄÇÊàëÂÄëÁöÑÊï∏ÊìöÈõÜÊòØÂæû CKD ÊÇ£ËÄÖÂíåÂÅ•Â∫∑ÂèóË©¶ËÄÖÁöÑË∫´È´îÁîüÂëΩÈ´îÂæµ‰∏≠Êî∂ÈõÜÁöÑÔºå‰ª•Ê∫ñÁ¢∫ÈñãÁôºÊàëÂÄëÊèêÂá∫ÁöÑ AI È©ÖÂãïÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÂú®ÈÄôÊñπÈù¢ÔºåÊèê‰æõ‰∫ÜË°ÄÊ∂≤ÂíåÂ∞øÊ∂≤Ê™¢Ê∏¨ÁµêÊûúÔºå‰∏¶ÊáâÁî®Âü∫ÊñºÈõÜÊàêÊ®πÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°Âûã‰æÜÈ†êÊ∏¨Êú™ÁôºÁèæÁöÑ CKD ÁóÖ‰æã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÁ∂ìÈÅéËàáËÖéËáüÁßëÈÜ´ÁîüÁöÑÈï∑ÊúüË´ÆË©¢ÂæåÂæóÂà∞È©óË≠â„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÂíåËß£ÈáãÁµêÊûúËàáÂêÑÁ®ÆÈÜ´ÁôÇ‰øùÂÅ•È†òÂüü‰∏≠ÁèæÊúâÁöÑÂèØËß£Èáã AI ÊáâÁî®ÈÄ≤Ë°å‰∫ÜÊØîËºÉÔºåÂåÖÊã¨ CKD„ÄÇÊØîËºÉË°®ÊòéÔºåÊàëÂÄëÈñãÁôºÁöÑ AI Ê®°ÂûãÔºåÁâπÂà•ÊòØÈö®Ê©üÊ£ÆÊûóÊ®°ÂûãÔºåÂ∑≤Á∂ìÁ¢∫ÂÆö‰∫ÜÊØî XgBoost Êõ¥Â§ö‰ΩúÁÇ∫ÈáçË¶ÅË≤¢ÁçªËÄÖÁöÑÁâπÂæµ„ÄÇÂèØËß£ÈáãÊÄß (I) Ë°°ÈáèÈáçË¶ÅÁâπÂæµËàáÊé©ËìãÁâπÂæµÁöÑÊØîÁéáÔºåË°®ÊòéÊàëÂÄëÁöÑ XgBoost Ê®°ÂûãÂú®ÈÄôÂÄãÊåáÊ®ô‰∏≠Áç≤Âæó‰∫ÜÊõ¥È´òÁöÑÂàÜÊï∏ÔºåÁâπÂà•ÊòØ 98% ÁöÑ‰øùÁúüÂ∫¶Ôºå‰∏¶‰∏îÂú® FII ÊåáÊï∏‰∏≠Ëá™ÁÑ∂È´òÊñºÁ´∂Áà≠Ê®°Âûã„ÄÇ

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

ÊëòË¶ÅÔºöÂøÉÁêÜÂÅ•Â∫∑ÊßãÊàê‰∫Ü‰∏ÄÈ†ÖË§áÈõú‰∏îÊôÆÈÅçÁöÑÂÖ®ÁêÉÊåëÊà∞ÔºåÂΩ±Èüø‰∫ÜÊï∏ÁôæËê¨‰∫∫ÁöÑÁîüÊ¥ªÔºå‰∏¶Á∂ìÂ∏∏Â∞éËá¥Âö¥ÈáçÁöÑÂæåÊûú„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÂæπÂ∫ïÁöÑË™øÊü•Ôºå‰ª•Êé¢Á¥¢Êï∏ÊìöÁßëÂ≠∏„ÄÅ‰∫∫Â∑•Êô∫ÊÖßÂíåÂøÉÁêÜ‰øùÂÅ•ÁöÑ‰∫§ÈõÜÔºåÈáçÈªûÈóúÊ≥®ÈÄöÈÅéÁ∑ö‰∏äÁ§æ‰∫§Â™íÈ´î (OSM) ÈÄ≤Ë°åÂøÉÁêÜÁñæÁóÖÊ™¢Ê∏¨ÁöÑÊúÄÊñ∞ÁôºÂ±ï„ÄÇÂæàÂ§ß‰∏ÄÈÉ®ÂàÜ‰∫∫Âè£Á©çÊ•µÂèÉËàá OSM Âπ≥Âè∞ÔºåÂâµÈÄ†‰∫Ü‰∏ÄÂÄãÈæêÂ§ßÁöÑ‰∫∫Âì°Ë≥áÊñôÂ∫´ÔºåÂ∞çÂøÉÁêÜÂÅ•Â∫∑ÂàÜÊûêÂÖ∑ÊúâÂ∑®Â§ßÁöÑÊΩõÂäõ„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÂÇ≥Áµ±ÁöÑË®∫Êñ∑ÊñπÊ≥ï„ÄÅÊúÄÂÖàÈÄ≤ÁöÑË≥áÊñôÂíå AI È©ÖÂãïÁöÑÁ†îÁ©∂Ôºå‰ª•ÂèäÂøÉÁêÜ‰øùÂÅ•‰∏≠ÂèØËß£Èáã AI (XAI) Ê®°ÂûãÁöÑÂá∫Áèæ„ÄÇÊàëÂÄëÂõûÈ°ß‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊ©üÂô®Â≠∏ÁøíÊñπÊ≥ïÔºåÁâπÂà•ÊòØÈÇ£‰∫õÂü∫ÊñºÁèæ‰ª£Ê∑±Â∫¶Â≠∏ÁøíÁöÑÊñπÊ≥ïÔºåÂêåÊôÇÂº∑Ë™ø‰∫ÜÈÜ´ÁôÇ‰øùÂÅ• AI Ê®°Âûã‰∏≠ÂèØËß£ÈáãÊÄßÁöÑÂøÖË¶ÅÊÄß„ÄÇÂØ¶È©óË®≠Ë®àÈÉ®ÂàÜÊèê‰æõ‰∫ÜÂ∞çÊôÆÈÅçÂÅöÊ≥ïÁöÑË¶ãËß£ÔºåÂåÖÊã¨ÂèØÁî®ÁöÑË≥áÊñôÈõÜÂíåË©ï‰º∞ÊñπÊ≥ï„ÄÇÊàëÂÄëÈÇÑÊâæÂá∫Ë©≤È†òÂüüÁöÑ‰∏ªË¶ÅÂïèÈ°åÂíåÊåëÊà∞Ôºå‰∏¶ÊèêÂá∫‰∫ÜÊúâÂ∏åÊúõÁöÑÊú™‰æÜÁ†îÁ©∂ÊñπÂêë„ÄÇÁî±ÊñºÂøÉÁêÜÂÅ•Â∫∑Ê±∫Á≠ñÈúÄË¶ÅÈÄèÊòéÂ∫¶„ÄÅÂèØËß£ÈáãÊÄßÂíåÈÅìÂæ∑ËÄÉÈáèÔºåÊú¨ÊñáÊúâÂä©ÊñºÊé®ÈÄ≤ÂøÉÁêÜ‰øùÂÅ•‰∏≠ÈÄèÈÅéÁ§æ‰∫§Â™íÈ´îÊé®ÈÄ≤ XAI ÁöÑÊåÅÁ∫åË®éË´ñ„ÄÇÈÄôË£°ÊèêÂá∫ÁöÑÂÖ®Èù¢Ê¶ÇËø∞Êó®Âú®ÂºïÂ∞éÁ†îÁ©∂‰∫∫Âì°„ÄÅÂæûÊ•≠‰∫∫Âì°ÂíåÊîøÁ≠ñÂà∂ÂÆöËÄÖÁôºÂ±ïÂøÉÁêÜÁñæÁóÖÊ™¢Ê∏¨È†òÂüü„ÄÇ

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

ÊëòË¶ÅÔºö<paragraph>ÈÜ´ÁôÇÁÖßË≠∑‰∏≠ÈúÄË¶Å AI ËºîÂä©ÁöÑËá®Â∫äË®∫Êñ∑„ÄÇÁèæÊúâÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁº∫‰πèÂèØËß£ÈáãÊÄßÔºå‰∏¶‰∏î‰∏ªË¶ÅÂ∞àÊ≥®ÊñºÂΩ±ÂÉèÂàÜÊûê„ÄÇÊúÄËøëÈñãÁôºÁöÑÂãïÊÖã‰∏çÁ¢∫ÂÆöÂõ†ÊûúÈóú‰øÇÂúñ (DUCG) ÊñπÊ≥ïÊòØÂõ†ÊûúÈ©ÖÂãïÁöÑ„ÄÅÂèØËß£ÈáãÁöÑÔºå‰∏¶‰∏îÂú®‰∏çÂêåÁöÑÊáâÁî®Â†¥ÊôØ‰∏≠ÊòØ‰∏çËÆäÁöÑÔºåÊ≤íÊúâË≥áÊñôÊî∂ÈõÜ„ÄÅÊ®ôË®ò„ÄÅÊì¨Âêà„ÄÅÈö±ÁßÅ„ÄÅÂÅèË¶ã„ÄÅÊ¶ÇÂåñ„ÄÅÈ´òÊàêÊú¨ÂíåÈ´òËÉΩËÄóÁöÑÂïèÈ°å„ÄÇÈÄöÈÅéËá®Â∫äÂ∞àÂÆ∂Âíå DUCG ÊäÄË°ì‰∫∫Âì°‰πãÈñìÁöÑÂØÜÂàáÂêà‰ΩúÔºåÊßãÂª∫‰∫ÜÊ∂µËìã 54 ÂÄã‰∏ªË®¥ÁöÑ 46 ÂÄã DUCG Ê®°Âûã„ÄÇÂèØ‰ª•Âú®Ê≤íÊúâÂàÜÊµÅÁöÑÊÉÖÊ≥Å‰∏ãË®∫Êñ∑Âá∫ 1,000 Â§öÁ®ÆÁñæÁóÖ„ÄÇÂú®ÊáâÁî®ÊñºÂØ¶Èöõ‰∏ñÁïå‰πãÂâçÔºå46 ÂÄã DUCG Ê®°ÂûãÂ∑≤Áî±Á¨¨‰∏âÊñπÈÜ´Èô¢ÂõûÊ∫ØÊÄßÈ©óË≠â„ÄÇÈ©óË≠âÁöÑË®∫Êñ∑Á≤æÂ∫¶‰∏ç‰ΩéÊñº 95%ÔºåÂÖ∂‰∏≠ÂåÖÊã¨ÁΩïË¶ãÁñæÁóÖÂú®ÂÖßÁöÑÊØèÁ®ÆÁñæÁóÖÁöÑË®∫Êñ∑Á≤æÂ∫¶‰∏ç‰ΩéÊñº 80%„ÄÇÈ©óË≠âÂæåÔºå46 ÂÄã DUCG Ê®°ÂûãÂ∑≤Âú®‰∏≠ÂúãÂØ¶ÈöõÊáâÁî®„ÄÇÂ∑≤Á∂ìÂü∑Ë°å‰∫ÜË∂ÖÈÅé‰∏ÄÁôæËê¨ÂÄãÁúüÂØ¶Ë®∫Êñ∑Ê°à‰æãÔºåÂÉÖÁôºÁèæ 17 ÂÄã‰∏çÊ≠£Á¢∫ÁöÑË®∫Êñ∑„ÄÇÁî±Êñº DUCG ÁöÑÈÄèÊòéÊÄßÔºåÁôºÁèæ‰∏¶Á≥æÊ≠£‰∫ÜÂ∞éËá¥‰∏çÊ≠£Á¢∫Ë®∫Êñ∑ÁöÑÈåØË™§„ÄÇÈ†ªÁπÅÊáâÁî® DUCG ÁöÑËá®Â∫äÈÜ´ÁîüÁöÑË®∫Êñ∑ËÉΩÂäõÂæóÂà∞‰∫ÜÈ°ØËëóÊèêÈ´ò„ÄÇÂú®‰ªãÁ¥π‰∫ÜÂâçÈù¢ÊèêÂá∫ÁöÑ DUCG ÊñπÊ≥ïË´ñ‰πãÂæåÔºåÊèêÂá∫‰∫ÜÊΩõÂú®ÂÅ•Â∫∑Ê™¢Êü•ÁöÑÊé®Ëñ¶ÊºîÁÆóÊ≥ïÔºå‰∏¶ÊèêÂèñ‰∫Ü DUCG ÁöÑÈóúÈçµÊÄùÊÉ≥„ÄÇ</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

ÊëòË¶ÅÔºöÁ≤æÁ¢∫‰∏îÂèäÊôÇÂú∞ÂÅµÊ∏¨‰π≥ÁôåÂ∞çÊñºÊîπÂñÑÊÇ£ËÄÖÈ†êÂæåËá≥ÈóúÈáçË¶Å„ÄÇË®∫Êñ∑ÊñπÊ≥ïÂÇ≥Áµ±‰∏ä‰æùË≥¥ÊñºÂñÆ‰∏ÄÊ®°ÂºèÊñπÊ≥ïÔºõÁÑ∂ËÄåÔºåÈÜ´ÁôÇË≥áÊñôÂàÜÊûêÊ≠£Âú®Êï¥ÂêàË∂ÖË∂äÂÇ≥Áµ±ÂΩ±ÂÉèÁöÑÂêÑÁ®ÆË≥áÊñô‰æÜÊ∫ê„ÄÇ‰ΩøÁî®Êï¥ÂêàÂΩ±ÂÉèÂíåÈùûÂΩ±ÂÉèË≥áÊñôÁöÑÂ§öÊ®°ÂºèÊäÄË°ìÔºåÊ®ôË™åËëó‰π≥ÁôåË®∫Êñ∑ÁöÑËÆäÈù©ÊÄßÈÄ≤Â±ï„ÄÇÊú¨ÁØáÁ∂úËø∞ÁöÑÁõÆÁöÑÊòØÊé¢Ë®éÂ§öÊ®°ÂºèÊäÄË°ìÁöÑÊñ∞ËààÈ†òÂüüÔºåÁâπÂà•ÊòØÂ∞áÁµÑÁπîÁóÖÁêÜÂ≠∏ÂΩ±ÂÉèËàáÈùûÂΩ±ÂÉèË≥áÊñôËûçÂêà„ÄÇÊ≠§Â§ñÔºåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) Â∞áÁî®ÊñºÈó°ÊòéË§áÈõúÊºîÁÆóÊ≥ïÁöÑÊ±∫Á≠ñÈÅéÁ®ãÔºåÂº∑Ë™øË®∫Êñ∑ÈÅéÁ®ã‰∏≠ÂèØËß£ÈáãÊÄßÁöÑÂøÖË¶ÅÊÄß„ÄÇÊú¨Á∂úËø∞Âà©Áî®Â§öÊ®°ÂºèË≥áÊñô‰∏¶Âº∑Ë™øÂèØËß£ÈáãÊÄßÔºå‰ª•ÊèêÈ´òË®∫Êñ∑Ê∫ñÁ¢∫ÊÄß„ÄÅËá®Â∫äÈÜ´Â∏´ÁöÑ‰ø°ÂøÉÂíåÊÇ£ËÄÖÂèÉËàáÂ∫¶ÔºåÊúÄÁµÇ‰øÉÈÄ≤‰π≥ÁôåÊõ¥ÂÄã‰∫∫ÂåñÁöÑÊ≤ªÁôÇÁ≠ñÁï•ÔºåÂêåÊôÇ‰πüÊâæÂá∫Â§öÊ®°ÂºèÂíåÂèØËß£ÈáãÊÄßÁöÑÁ†îÁ©∂Â∑ÆË∑ùÔºåÂºïÂ∞éÊú™‰æÜÁöÑÁ†îÁ©∂Ôºå‰∏¶ÁÇ∫Ë©≤È†òÂüüÁöÑÁ≠ñÁï•ÊñπÂêëÂÅöÂá∫Ë≤¢Áçª„ÄÇ

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

ÊëòË¶ÅÔºöËá™Ê≥®ÊÑèÂäõÊ©üÂà∂Â∑≤Ë¢´Êé°Áî®ÊñºÂ§öÂÄãÂª£Ê≥õ‰ΩøÁî®ÁöÑË®äÊÅØÂÇ≥ÈÅûÁ•ûÁ∂ìÁ∂≤Ë∑Ø (MPNN)Ôºà‰æãÂ¶Ç GATÔºâÔºåÂÆÉÂèØ‰ª•Ëá™ÈÅ©ÊáâÂú∞ÊéßÂà∂Ê≤øËëóÂ∫ïÂ±§ÂúñÂΩ¢ÈÇäÁ∑£ÊµÅÂãïÁöÑË≥áË®äÈáè„ÄÇÈÄôÁ®ÆÊ≥®ÊÑèÂäõÁöÑ‰ΩøÁî®‰ΩøÂæóÊ≠§È°ûÊ®°ÂûãÊàêÁÇ∫ÂèØËß£Èáã AI (XAI) Á†îÁ©∂ÁöÑÂü∫Á∑öÔºåÂõ†ÁÇ∫ÈÄèÈÅéÊ≥®ÊÑèÂäõÁöÑË©ÆÈáãÂ∑≤Âú®ÂêÑÁ®ÆÈ†òÂüüÔºà‰æãÂ¶ÇËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÂíåÈõªËÖ¶Ë¶ñË¶∫Ôºâ‰∏≠ÊôÆÂèä„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÁ†îÁ©∂ÈÄöÂ∏∏‰ΩøÁî®Â§©ÁúüÁöÑË®àÁÆóÊñπÊ≥ïÂæûÊ≥®ÊÑèÂäõ‰∏≠Êé®Â∞éÂá∫Ê≠∏Âõ†ÂàÜÊï∏Ôºå‰∏¶‰∏îÊ≤íÊúâËÄÉÊÖÆÂà∞ÈÇäÁ∑£Ê≠∏Âõ†ÁöÑÁ≤æÁ¢∫‰∏î‰ªîÁ¥∞ÁöÑË®àÁÆó„ÄÇÂú®ÊàëÂÄëÁöÑÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊó®Âú®Â°´Ë£úÊ≥®ÊÑèÂäõÂïüÁî® MPNN ÁöÑÂª£Ê≥õ‰ΩøÁî®ËàáÂÆÉÂÄëÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÊú™Ë¢´ÂÖÖÂàÜÊé¢Á¥¢ÁöÑÂèØËß£ÈáãÊÄß‰πãÈñìÁöÑÂ∑ÆË∑ùÔºåÈÄôÂÄã‰∏ªÈ°åÂ∑≤Âú®ÂÖ∂‰ªñÈ†òÂüüÁ©çÊ•µÁ†îÁ©∂„ÄÇÁÇ∫Ê≠§Ôºå‰ΩúÁÇ∫Á¨¨‰∏ÄÊ¨°ÂòóË©¶ÔºåÊàëÂÄëÂ∞á GNN ‰∏≠Ê≥®ÊÑèÂäõÊ¨äÈáçÁöÑÈÇäÁ∑£Ê≠∏Âõ†ÂïèÈ°åÂΩ¢ÂºèÂåñ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊèêÂá∫ GATTÔºå‰∏ÄÁ®ÆÂª∫Á´ãÂú®Ë®àÁÆóÊ®π‰∏äÁöÑÈÇäÁ∑£Ê≠∏Âõ†Ë®àÁÆóÊñπÊ≥ï„ÄÇÈÄèÈÅéÂÖ®Èù¢ÁöÑÂØ¶È©óÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®Ë©ï‰º∞ GAT ÁöÑÊ≠∏Âõ†ÊôÇÊâÄÂÖ∑ÊúâÁöÑÊïàÊûú„ÄÇÁõ∏ÂèçÂú∞ÔºåÊàëÂÄëÊÜëÁ∂ìÈ©óÈ©óË≠â‰∫ÜÂÉÖÂ∞çÂúñÊ≥®ÊÑèÂäõÂ±§‰∏äÁöÑÊ≥®ÊÑèÂäõÊ¨äÈáçÂèñÂπ≥ÂùáÂÄº‰∏çË∂≥‰ª•Ë©ÆÈáã GAT Ê®°ÂûãÁöÑË°åÁÇ∫„ÄÇÁ®ãÂºèÁ¢ºÂ∑≤ÂÖ¨ÈñãÊñº https://github.com/jordan7186/GAtt/tree/main„ÄÇ

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

ÊëòË¶ÅÔºöÊñ∞ÁîüÂÖíÊúüÊòØÂ§ßËÖ¶ÁôºËÇ≤ÊúÄËÑÜÂº±ÁöÑÊôÇÊúüÔºåÂÆπÊòìÂá∫ÁèæÁô≤ÁôáÁôº‰Ωú„ÄÇÂ§ßËÖ¶ÁôºËÇ≤‰∏çÊàêÁÜüÊôÇÂá∫ÁèæÁô≤ÁôáÁôº‰ΩúÊúÉÈÄ†Êàê‰∏çËâØÂæåÊûúÔºåÂõ†Ê≠§ÈúÄË¶ÅÂèäÊó©Ë®∫Êñ∑„ÄÇÁõÆÂâçÊñ∞ÁîüÂÖíÁô≤ÁôáÁôº‰ΩúÁöÑÈªÉÈáëÊ®ôÊ∫ñ‰æùË≥¥ÊñºÈÄ£Á∫åÁöÑË¶ñË®äËÖ¶ÈõªÂúñ (EEG) Áõ£Ê∏¨ÔºõÂÖ∂‰∏≠ÂåÖÊã¨Âú®Êñ∞ÁîüÂÖíÂä†Ë≠∑ÁóÖÊàø (NICU) ÂÖßÂêåÊôÇÈÄ≤Ë°åÂ§öÈ†ªÈÅìËÖ¶ÈõªÂúñ (EEG) Ë®òÈåÑÂíåÂç≥ÊôÇË¶ñË®äÁõ£Êéß„ÄÇÁÑ∂ËÄåÔºåË¶ñË®äËÖ¶ÈõªÂúñÁõ£ÊéßÊäÄË°ìÈúÄË¶ÅËá®Â∫äÂ∞àÊ•≠Áü•Ë≠òÔºåËÄå‰∏îÈÄöÂ∏∏ÂÉÖÈôêÊñºÊäÄË°ìÂÖàÈÄ≤‰∏îË≥áÊ∫êË±êÂØåÁöÑÁí∞Â¢É„ÄÇÂÖ∑ÊàêÊú¨ÊïàÁõäÁöÑÊñ∞ÊäÄË°ìÂèØ‰ª•Âπ´Âä©ÈÜ´ÁôÇÁïåÊ∫ñÁ¢∫Ë®∫Êñ∑‰∏¶Á´ãÂç≥ÊèêÂÄ°Ê≤ªÁôÇ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÂèØËß£ÈáãÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºå‰ª•Ëá™ÂãïÂåñÊñ∞ÁîüÂÖíÁô≤ÁôáÁôº‰ΩúÂÅµÊ∏¨ÈÅéÁ®ãÔºå‰∏¶Êé°Áî®Ê∏õÂ∞ëÁöÑËÖ¶ÈõªÂúñË£ùÁΩÆÔºåÂÖ∂‰∏≠Êé°Áî®‰∫ÜÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÅÂúñÂΩ¢Ê≥®ÊÑèÂäõÂ±§ÂíåÂÖ®ÈÄ£Êé•Â±§„ÄÇÈô§‰∫ÜËÉΩÂ§†‰ΩøÁî®Ê∏õÂ∞ëÁöÑË£ùÁΩÆÂç≥ÊôÇÂÅµÊ∏¨Áô≤ÁôáÁôº‰ΩúÂ§ñÔºåÊ≠§Ê®°ÂûãÈÇÑÊèê‰æõ‰∫ÜÂç≥ÊôÇÂèØËß£ÈáãÊÄßÁöÑÁç®ÁâπÂÑ™Âã¢„ÄÇÈÄèÈÅéÂú® Zenodo Ë≥áÊñôÈõÜ‰∏ä‰ΩøÁî® 10 ÂÄç‰∫§ÂèâÈ©óË≠âË©ï‰º∞ÊïàËÉΩÔºåÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂú®Êõ≤Á∑ö‰∏ãÈù¢Á©ç (AUC) ÂíåÂè¨ÂõûÁéáÊñπÈù¢ÂàÜÂà•ÈÅîÂà∞‰∫Ü 8.31% Âíå 42.86% ÁöÑÁµïÂ∞çÊîπÂñÑ„ÄÇ

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

ÊëòË¶ÅÔºö‰π≥Áôå (BC) ÊòØÂΩ±ÈüøÂÖ®ÁêÉÂ•≥ÊÄßÊúÄÂ∏∏Ë¶ãÁöÑÊÉ°ÊÄßËÖ´Áò§‰πã‰∏ÄÔºåÂõ†Ê≠§ÈúÄË¶ÅÈÄ≤Ê≠•ÁöÑË®∫Êñ∑ÊñπÊ≥ïÔºå‰ª•ÊîπÂñÑËá®Â∫äÁµêÊûú„ÄÇÊú¨ÊñáÂÖ®Èù¢Êé¢Ë®é‰∫ÜÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊäÄË°ìÂú®‰π≥ÁôåÂÅµÊ∏¨ÂíåË®∫Êñ∑‰∏≠ÁöÑÊáâÁî®„ÄÇÈö®Ëëó‰∫∫Â∑•Êô∫ÊÖß (AI) ÊäÄË°ìÊåÅÁ∫åÊª≤ÈÄèÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÔºåÁâπÂà•ÊòØÂú®ËÖ´Áò§Â≠∏‰∏≠ÔºåÈÄèÊòé‰∏îÂèØËß£ÈáãÁöÑÊ®°ÂûãÈúÄÊ±ÇËÆäÂæóÂã¢Âú®ÂøÖË°åÔºå‰ª•Â¢ûÂº∑Ëá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÂíåÊÇ£ËÄÖÁÖßË≠∑„ÄÇÊ≠§ÁØáË©ïË´ñÊé¢Ë®é‰∫ÜÂêÑÁ®Æ XAI ÊñπÊ≥ïÁöÑÊï¥ÂêàÔºå‰æãÂ¶Ç SHAP„ÄÅLIME„ÄÅGrad-CAM Á≠âÔºå‰ª•ÂèäÁî®Êñº‰π≥ÁôåÂÅµÊ∏¨ÂíåÂàÜÈ°ûÁöÑÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã„ÄÇÈÄèÈÅéÊé¢Ë®é‰π≥ÁôåË≥áÊñôÈõÜÁöÑÊ®°ÂºèÔºåÂåÖÊã¨‰π≥ÊàøÊîùÂΩ±„ÄÅË∂ÖÈü≥Ê≥¢ÂèäÂÖ∂Âú® AI ‰∏≠ÁöÑËôïÁêÜÔºåÊú¨ÊñáÈáçÈªûË™™Êòé XAI Â¶Ç‰ΩïËÉΩÂ∞éËá¥Êõ¥Ê∫ñÁ¢∫ÁöÑË®∫Êñ∑ÂíåÂÄã‰∫∫ÂåñÊ≤ªÁôÇË®àÁï´„ÄÇÂÆÉ‰πüÊé¢Ë®é‰∫ÜÂØ¶ÊñΩÈÄô‰∫õÊäÄË°ìÁöÑÊåëÊà∞Ôºå‰ª•ÂèäÂà∂ÂÆöÊ®ôÊ∫ñÂåñË©ïÈáèÊåáÊ®ô‰ª•Ë©ï‰º∞ XAI Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊúâÊïàÊÄßÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄèÈÅéË©≥Á¥∞ÁöÑÂàÜÊûêÂíåË®éË´ñÔºåÊú¨ÊñáÊó®Âú®Âº∑Ë™ø XAI Âú®Á∏ÆÂ∞èË§áÈõú AI Ê®°ÂûãËàáÂØ¶ÂãôÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®‰πãÈñìÂ∑ÆË∑ùÁöÑÊΩõÂäõÔºåÈÄ≤ËÄå‰øÉÈÄ≤ÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°‰πãÈñìÁöÑ‰ø°‰ªªËàáÁêÜËß£Ôºå‰∏¶ÊîπÂñÑÊÇ£ËÄÖÁöÑÁµêÊûú„ÄÇ

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

ÊëòË¶ÅÔºöË™ûÈü≥ÊÉÖÁ∑íËæ®Ë≠ò (SER) Áî±ÊñºÂÖ∂Âú®ÂøÉÁêÜÂÅ•Â∫∑„ÄÅÊïôËÇ≤Âíå‰∫∫Ê©ü‰∫íÂãïÁ≠âÂ§öÂÄãÊáâÁî®È†òÂüüËÄåÂÇôÂèóÈóúÊ≥®„ÄÇÁÑ∂ËÄåÔºåSER Á≥ªÁµ±ÁöÑÊ∫ñÁ¢∫ÊÄßÂèóÂà∞È´òÁ∂≠ÁâπÂæµÈõÜÁöÑÈòªÁ§ôÔºåÈÄô‰∫õÁâπÂæµÈõÜÂèØËÉΩÂåÖÂê´‰∏çÁõ∏ÈóúÂíåÂÜóÈ§òÁöÑË≥áË®ä„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄôÂÄãÊåëÊà∞ÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁî®Êñº SER ÁöÑËø≠‰ª£ÁâπÂæµÊèêÂçáÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÂº∑Ë™øÁâπÂæµÁõ∏ÈóúÊÄßÂíåÂèØËß£ÈáãÊÄßÔºå‰ª•Â¢ûÂº∑Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊ∂âÂèä‰ªîÁ¥∞ÁöÑÁâπÂæµÈÅ∏ÊìáÂíåÂàÜÊûêÔºå‰ª•Âª∫Á´ãÈ´òÊïàÁöÑ SER Á≥ªÁµ±„ÄÇÁÇ∫‰∫ÜÈÄèÈÅéÊ®°ÂûãÂèØËß£ÈáãÊÄßËß£Ê±∫ÊàëÂÄëÁöÑÊ†∏ÂøÉÂïèÈ°åÔºåÊàëÂÄëÊé°Áî®‰∫ÜÂÖ∑Êúâ Shapley ÂÄºÁöÑÁâπÂæµË©ï‰º∞Ëø¥ÂúàÔºå‰ª•ÂèçË¶ÜÊîπÂñÑÁâπÂæµÈõÜ„ÄÇÈÄôÂÄãÈÅéÁ®ãÂú®Ê®°ÂûãÊïàËÉΩÂíåÈÄèÊòéÂ∫¶‰πãÈñìÂèñÂæóÂπ≥Ë°°ÔºåÈÄô‰ΩøÂæóÊàëÂÄëËÉΩÂ§†ÂÖ®Èù¢‰∫ÜËß£Ê®°ÂûãÁöÑÈ†êÊ∏¨„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÊèê‰æõ‰∫ÜÂ§öÈ†ÖÂÑ™ÈªûÔºåÂåÖÊã¨Ë≠òÂà•ÂíåÁßªÈô§‰∏çÁõ∏ÈóúÂíåÂÜóÈ§òÁöÑÁâπÂæµÔºåÂæûËÄåÂª∫Á´ãÊõ¥ÊúâÊïàÁöÑÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåÂÆÉ‰øÉÈÄ≤‰∫ÜÂèØËß£ÈáãÊÄßÔºåÊúâÂä©ÊñºÁêÜËß£Ê®°ÂûãÁöÑÈ†êÊ∏¨‰ª•ÂèäË≠òÂà•ÊÉÖÁ∑íÊ±∫ÂÆöÁöÑÈóúÈçµÁâπÂæµ„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÂ∑≤Âú®Â§öÂÄ´Â§öÊÉÖÁ∑íË™ûÈü≥ÈõÜ (TESS)„ÄÅÊüèÊûóÊÉÖÁ∑íË™ûÈü≥Ë≥áÊñôÂ∫´ (EMO-DB)„ÄÅË≥¥ÁàæÊ£ÆÈü≥Ë®äË¶ñË¶∫ÊÉÖÁ∑íË™ûÈü≥ÂíåÊ≠åÊõ≤Ë≥áÊñôÂ∫´ (RAVDESS) ÂíåËñ©ÈáåÈü≥Ë®äË¶ñË¶∫Ë°®ÈÅîÊÉÖÁ∑í (SAVEE) Ë≥áÊñôÈõÜÁöÑ SER Âü∫Ê∫ñ‰∏äÂæóÂà∞È©óË≠âÔºåÂÖ∂ÊïàËÉΩÂÑ™ÊñºÁèæÊúâÊñπÊ≥ï„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂ∞áÊ®°ÂûãÂèØËß£ÈáãÊÄßÁ¥çÂÖ• SER Êû∂ÊßãÁöÑÁ†îÁ©∂„ÄÇÊú¨ÊñáÁöÑÂéüÂßãÁ¢ºÂèØÈÄèÈÅéÊ≠§ÈÄ£ÁµêÂÖ¨ÈñãÂèñÂæóÔºöhttps://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition„ÄÇ

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, H√©lo√Øse de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

ÊëòË¶ÅÔºöÂèØËß£ÈáäÊÄßÈÄöÂ∏∏ÂØπ‰∫é‰∫∫Â∑•Êô∫ËÉΩ (AI) ÁöÑÂèØÊé•ÂèóÂÆûÊñΩËá≥ÂÖ≥ÈáçË¶Å„ÄÇÂú®ÂåªÁñó‰øùÂÅ•È¢ÜÂüüÔºåËøô‰∏ÄÁÇπÂ∞§‰∏∫ÈáçË¶ÅÔºåÂõ†‰∏∫ÂÜ≥Á≠ñÁõ¥Êé•ÂΩ±ÂìçÊÇ£ËÄÖÔºåÂπ∂‰∏îÂØπ AI Á≥ªÁªüÁöÑ‰ø°‰ªªËá≥ÂÖ≥ÈáçË¶Å„ÄÇËøôÁßç‰ø°‰ªªÈÄöÂ∏∏Âª∫Á´ãÂú® AI Êèê‰æõÁöÑËß£ÈáäÂíåËØ†Èáä‰πã‰∏ä„ÄÇÂ∞ΩÁÆ° AI ÂèØËß£ÈáäÊÄßÂèñÂæó‰∫ÜÈáçÂ§ßËøõÂ±ïÔºå‰ΩÜ‰ªçÁÑ∂ÈúÄË¶ÅÊòéÁ°ÆÁöÑÊåáÂØºÊñπÈíàÔºåËØ¥ÊòéÂú®ÂåªÁñóÁéØÂ¢É‰∏≠‰ΩïÊó∂‰ª•ÂèäÂú®Â§öÂ§ßÁ®ãÂ∫¶‰∏äÈúÄË¶ÅËß£Èáä„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂàÜÁ±ªÁ≥ªÁªüÔºåËØ•Á≥ªÁªüÂÖ∑ÊúâÂõõÁßç‰∏çÂêåÁöÑËß£ÈáäÂøÖË¶ÅÊÄßÁ±ªÂà´ÔºåÊåáÂØºÊâÄÈúÄÁöÑËß£ÈáäÁ∫ßÂà´ÔºöÊÇ£ËÄÖÊàñÊ†∑Êú¨ÔºàÂ±ÄÈÉ®ÔºâÁ∫ßÂà´„ÄÅÈòüÂàóÊàñÊï∞ÊçÆÈõÜÔºàÂÖ®Â±ÄÔºâÁ∫ßÂà´ÔºåÊàñ‰∏§‰∏™Á∫ßÂà´„ÄÇÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™Êï∞Â≠¶ÂÖ¨ÂºèÔºåËØ•ÂÖ¨ÂºèÂå∫ÂàÜ‰∫ÜËøô‰∫õÁ±ªÂà´ÔºåÂπ∂‰∏∫Á†îÁ©∂‰∫∫ÂëòÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÂÆûÁî®Ê°ÜÊû∂Ôºå‰ª•Á°ÆÂÆöÂåªÁñó AI Â∫îÁî®‰∏≠ÊâÄÈúÄÁöÑËß£ÈáäÁöÑÂøÖË¶ÅÊÄßÂíåÊ∑±Â∫¶„ÄÇËÄÉËôë‰∫Ü‰∏â‰∏™ÂÖ≥ÈîÆÂõ†Á¥†ÔºöËØÑ‰º∞ÂçèËÆÆÁöÑÁ®≥ÂÅ•ÊÄß„ÄÅ‰∏ìÂÆ∂ËßÇÂØüÁöÑÂèØÂèòÊÄß‰ª•ÂèäÂ∫îÁî®Á®ãÂ∫èÁöÑË°®Á§∫Áª¥Êï∞„ÄÇ‰ªéËøô‰∏™ËßíÂ∫¶Êù•ÁúãÔºåÊàë‰ª¨Ëß£ÂÜ≥‰∫ÜËøô‰∏™ÈóÆÈ¢òÔºöAI ÂåªÁñóÂ∫îÁî®‰ΩïÊó∂ÈúÄË¶ÅËß£ÈáäÔºå‰ª•ÂèäÈúÄË¶ÅËß£ÈáäÂà∞‰ΩïÁßçÁ®ãÂ∫¶Ôºü

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) È†òÂüüÊ≠£Âø´ÈÄüÂΩ±ÈüøËëóÂÅ•Â∫∑ËàáÈÜ´ÁôÇ‰øùÂÅ•Ôºå‰ΩÜÂ∞çÊñºÈù¢Ëá®Âª£Ê≥õÁµêÊßãÊÄßÂ£ìËø´ÁöÑ‰∫∫Áæ§‰æÜË™™ÔºåÂÅèË¶ãÂíå‰∏çËâØË°®Áèæ‰æùÁÑ∂Â≠òÂú®„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂Â∑≤Ê∏ÖÊ•öË™™ÊòéÔºåÈúÄË¶ÅÊõ¥Âö¥Ê†ºÂú∞Ê≥®ÊÑèË≥áÊñô‰ª£Ë°®ÊÄßÂíåÊ®°ÂûãÊïàËÉΩÔºå‰ª•‰øÉÈÄ≤ÂÖ¨Âπ≥ÊÄß‰∏¶Ê∏õÂ∞ëÂÅèË¶ã„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÊúâÊ©üÊúÉÈÄèÈÅéÈÅãÁî®Á§æÊúÉÊµÅË°åÁóÖÂ≠∏ÂíåÂÅ•Â∫∑ÂÖ¨Âπ≥ÁöÑÊúÄ‰Ω≥ÂØ¶ÂãôÔºå‰æÜÊîπÂñÑ AI ÁöÑÂèØËß£ÈáãÊÄßÔºå‰ª•Âπ´Âä©ÊàëÂÄëÈáùÂ∞çÁôºÁèæÁöÑÈóúËÅØÊÄßÔºåÁôºÂ±ïÂÅáË®≠„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÂèØËß£Èáã AI (XAI)Ôºå‰∏¶ÊèèËø∞‰∏ÄÂÄãË∑®È†òÂüüÂ∞àÂÆ∂Â∞èÁµÑÂØ©Êü•Êû∂ÊßãÔºå‰ª•ÂæûÂ§öÈáçËßÄÈªûË®éË´ñÂíåÊâπÂà§ÊÄßË©ï‰º∞ AI Ê®°ÂûãÁöÑËß£ÈáãÔºå‰∏¶ÊâæÂá∫ÂÅèË¶ãÈ†òÂüüÂíåÊú™‰æÜÁ†îÁ©∂ÁöÑÊñπÂêë„ÄÇÊàëÂÄëÂº∑Ë™øË∑®È†òÂüüÂ∞àÂÆ∂Â∞èÁµÑÂ∞çÊñºÁî¢ÁîüÊõ¥Ê∫ñÁ¢∫„ÄÅÂÖ¨Âπ≥ÁöÑË©ÆÈáãËá≥ÈóúÈáçË¶ÅÔºåËÄåÈÄô‰∫õË©ÆÈáãÊòØÊ†πÊìöÊ≠∑Âè≤ÂíåËÑàÁµ°ËÄå‰æÜÁöÑ„ÄÇË∑®È†òÂüüÂ∞èÁµÑË®éË´ñÊúâÂä©ÊñºÊ∏õÂ∞ëÂÅèË¶ã„ÄÅÊâæÂá∫ÊΩõÂú®ÁöÑÊ∑∑Ê∑ÜÂõ†Á¥†Ôºå‰∏¶Âú®ÊñáÁçª‰∏≠ÊúâÁº∫Âè£ÊôÇÊâæÂá∫È°çÂ§ñÁ†îÁ©∂ÁöÑÊ©üÊúÉ„ÄÇÂèçÈÅé‰æÜÔºåÈÄô‰∫õË¶ãËß£ÂèØ‰ª•Âª∫Ë≠∞ AI Ê®°ÂûãÊîπÈÄ≤ÁöÑÊ©üÊúÉ„ÄÇ

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. ZajƒÖc, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÂú®ÂØ¶È©óÂÆ§ÂØ¶È©ó‰∏≠‰∏çÊñ∑Âú∞ËàáÊîæÂ∞ÑÁßëÈÜ´Â∏´ÂåπÊïµÊàñË°®ÁèæÂæóÊõ¥Âá∫Ëâ≤„ÄÇÁÑ∂ËÄåÔºåÁôºÁèæÊîæÂ∞ÑÁßë AI ÁÇ∫Âü∫Á§éÁ≥ªÁµ±ÁöÑÂØ¶ÈöõÂü∑Ë°åÂπæ‰πéÊ≤íÊúâÊèê‰æõËá®Â∫äÂÉπÂÄº„ÄÇÊú¨ÊñáÊé¢Ë®éÂ¶Ç‰ΩïÁÇ∫ AI Ë®≠Ë®àÂú®‰∏çÂêåÊÉÖÂ¢É‰∏≠Ëá®Â∫ä‰∏äÁöÑÊïàÁî®„ÄÇÊàëÂÄëÊ†πÊìöÂäüËÉΩÊÄß AI ÁÇ∫Âü∫Á§éÂéüÂûãÁöÑ‰∏âÊ¨°Ëø≠‰ª£ÔºåÂú®‰∏πÈ∫•ÂíåËÇØ‰∫ûÁöÑ 7 ÂÄãËá®Â∫äÂ†¥ÂüüËàá 13 ‰ΩçÊîæÂ∞ÑÁßëÈÜ´Â∏´ÈÄ≤Ë°å‰∫Ü 19 Ê¨°Ë®≠Ë®àÊúÉË≠∞ÂíåË®≠Ë®à‰ªãÂÖ•„ÄÇÂçÅÂÄãÁ§æÊúÉÊäÄË°ì‰æùË≥¥Èóú‰øÇË¢´Ë™çÁÇ∫Â∞çÊñºÊîæÂ∞ÑÁßë‰∏≠ AI ÁöÑË®≠Ë®àËá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÊ¶ÇÂøµÂåñ‰∫ÜÂõõÂÄãÊäÄË°ìÈù¢ÂêëÔºåÂøÖÈ†àÊ†πÊìöÈ†êÊúüÁöÑËá®Â∫ä‰ΩøÁî®ÊÉÖÂ¢ÉÈÄ≤Ë°åË®≠ÂÆöÔºöAI ÂäüËÉΩ„ÄÅAI ÈÜ´ÁôÇÈáçÈªû„ÄÅAI Ê±∫Á≠ñÈñÄÊ™ªÔºå‰ª•Âèä AI ÂèØËß£ÈáãÊÄß„ÄÇÊàëÂÄëÊèêÂá∫ÂõõÈ†ÖË®≠Ë®àÂª∫Ë≠∞ÔºåË™™ÊòéÂ¶Ç‰ΩïËôïÁêÜËàáÈÜ´ÁôÇÁü•Ë≠ò„ÄÅË®∫ÊâÄÈ°ûÂûã„ÄÅ‰ΩøÁî®ËÄÖÂ∞àÊ•≠Áü•Ë≠òÁ≠âÁ¥ö„ÄÅÊÇ£ËÄÖÊÉÖÂ¢ÉÔºå‰ª•ÂèäÂΩ±ÈüøÈÄô‰∫õÊäÄË°ìÈù¢ÂêëË®≠ÂÆöÁöÑ‰ΩøÁî®ËÄÖÊÉÖÂ¢ÉÁõ∏ÈóúÁöÑ‰æùË≥¥Èóú‰øÇ„ÄÇ

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

ÊëòË¶ÅÔºöÈö®ËëóÂÖàÈÄ≤ÁöÑ AI/MLÔºåÂ∞çÂèØËß£Èáã AI (XAI) ÁöÑÁ†îÁ©∂‰∏çÊñ∑Â¢ûÂä†Ôºå‰ª•ÂèäÈóúÊñº‰∫∫È°ûÂ¶Ç‰ΩïËàá AI Âíå XAI ‰∫íÂãï‰ª•ÈÄ≤Ë°åÊúâÊïàÁöÑ‰∫∫Â∑•Êô∫ÊÖßÂçî‰ΩúÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄë‰ªçÁÑ∂Áº∫‰πèÂ∞ç AI Á≥ªÁµ±Âíå XAI ÊáâÂ¶Ç‰ΩïÈ¶ñÂÖàÂëàÁèæÁµ¶Ê≤íÊúâÊäÄË°ìËÉåÊôØÁöÑÁî®Êà∂ÁöÑ‰∫ÜËß£„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜËàáÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì° (n=12) Âíå‰∏ª‰øÆÈÜ´Â≠∏ÂíåÂÅ•Â∫∑ÁöÑÂ≠∏Áîü (n=4) ÈÄ≤Ë°åÂçäÁµêÊßãÂåñË®™Ë´áÁöÑÁµêÊûúÔºå‰ª•Á†îÁ©∂Â¶Ç‰ΩïÊîπÂñÑ AI Âíå XAI ÁöÑÂÖ•ÈñÄ„ÄÇÂ∞çÊñºË®™Ë´áÔºåÊàëÂÄëÂª∫Á´ãÂú®‰∫∫Ê©ü‰∫íÂãïÊ∫ñÂâá‰πã‰∏äÔºåÁÇ∫‰∏≠È¢®Â∫∑Âæ©Ë©ï‰º∞Âíå AI Ëß£ÈáãÁöÑ AI Á≥ªÁµ±ÂâµÂª∫ÂÖ•ÈñÄÊùêÊñôÔºå‰∏¶Â∞áÂÆÉÂÄë‰ªãÁ¥πÁµ¶ÂèÉËàáËÄÖ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÈô§‰∫ÜÂëàÁèæÂÇ≥Áµ±ÁöÑ AI ÊÄßËÉΩÊåáÊ®ôÂ§ñÔºåÂèÉËàáËÄÖÈÇÑÂ∏åÊúõÂü∫ÂáÜ‰ø°ÊÅØ„ÄÅAI ÁöÑÂØ¶ÈöõÂ•ΩËôï‰ª•Âèä‰∫§‰∫íË©¶È©óÔºå‰ª•Êõ¥Â•ΩÂú∞Â∞á AI ÊÄßËÉΩÊÉÖÂ¢ÉÂåñÔºå‰∏¶ÂÆåÂñÑ AI ÁöÑÁõÆÊ®ôÂíåÊÄßËÉΩ„ÄÇÊ†πÊìöÈÄô‰∫õÁôºÁèæÔºåÊàëÂÄëÂº∑Ë™ø‰∫ÜÊîπÈÄ≤ AI Âíå XAI ‰ª•Âèä‰∫∫Ê©üÂçî‰ΩúÊ±∫Á≠ñÂà∂ÂÆöÁöÑÂÖ•ÈñÄÊñπÂêë„ÄÇ

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

ÊëòË¶ÅÔºöÊú¨Êñá‰ΩøÁî®Ê©üÂô®Â≠∏Áøí (ML) ÂíåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊäÄË°ì‰æÜÊé¢Ë®éÁáüÈ§äÁãÄÊ≥ÅËàáÈòøËå≤Êµ∑ÈªòÁóá (AD) Áõ∏ÈóúÁöÑÊ≠ª‰∫°Áéá‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊé°Áî®Á¨¨‰∏âÊ¨°ÂÖ®ÂúãÂÅ•Â∫∑ËàáÁáüÈ§äÊ™¢Êü•Ë™øÊü• (NHANES III) Ë≥áÊñôÂ∫´ÈÄ≤Ë°åÂàÜÊûê„ÄÇÈÅ∏ÊìáÈö®Ê©üÊ£ÆÊûóÊ®°Âûã‰ΩúÁÇ∫ XAI ÂàÜÊûêÁöÑÂü∫Á§éÊ®°ÂûãÔºå‰∏¶‰ΩøÁî® Shapley Additive Explanations (SHAP) ÊñπÊ≥ï‰æÜË©ï‰º∞ÁâπÂæµÈáçË¶ÅÊÄß„ÄÇÁµêÊûúÁ™ÅÈ°Ø‰∫ÜÈáçË¶ÅÁöÑÁáüÈ§äÂõ†Á¥†Ôºå‰æãÂ¶ÇË°ÄÊ∏ÖÁ∂≠ÁîüÁ¥† B12 ÂíåÁ≥ñÂåñË°ÄÁ¥ÖËõãÁôΩ„ÄÇË©≤Á†îÁ©∂Ë≠âÊòé‰∫ÜÈö®Ê©üÊ£ÆÊûóÂú®È†êÊ∏¨ AD Ê≠ª‰∫°ÁéáÊñπÈù¢Áõ∏ËºÉÊñºÂÖ∂‰ªñÁñæÁóÖÁöÑÊúâÊïàÊÄß„ÄÇÊú¨Á†îÁ©∂Êèê‰æõ‰∫ÜÁáüÈ§äÂ∞ç AD ÁöÑÂΩ±ÈüøÁöÑË¶ãËß£Ôºå‰∏¶ÊúâÂä©ÊñºÊõ¥Ê∑±ÂÖ•Âú∞‰∫ÜËß£ÁñæÁóÖÁöÑÈÄ≤Â±ï„ÄÇ

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

ÊëòË¶ÅÔºö<paragraph>ÂàùÁ¥ö‰øùÂÅ•Êèê‰æõËÄÖÂ∞çÊñºÊúÄÂàùÁöÑÂàÜÊµÅÂíåËΩâË®∫Âà∞Â∞àÁßëÁÖßË≠∑Ëá≥ÈóúÈáçË¶Å„ÄÇÂú®ÈùíÂÖâÁúºÁöÑÊÉÖÊ≥Å‰∏ãÔºåÁÑ°ÁóáÁãÄ‰∏îÂø´ÈÄüÊÉ°ÂåñÂèØËÉΩÂ∞éËá¥Ë¶ñÂäõÂñ™Â§±ÔºåÂõ†Ê≠§ÈúÄË¶ÅÂèäÊôÇËΩâË®∫Áµ¶Â∞àÂÆ∂„ÄÇÁÑ∂ËÄåÔºåÂàùÁ¥öÁúºÁßë‰øùÂÅ•Êèê‰æõËÄÖÂèØËÉΩÁÑ°Ê≥ïË≠òÂà•Á∑äÊÄ•ÊÉÖÊ≥ÅÔºåÂèØËÉΩÊúÉÂª∂Ë™§ÁÖßË≠∑„ÄÇÊèê‰æõËß£ÈáãÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÂèØ‰ª•Âä†Âº∑‰ªñÂÄëÁöÑËΩâË®∫Ê±∫Á≠ñ„ÄÇÊàëÂÄëÁ†îÁ©∂ÂêÑÁ®Æ AI Ëß£ÈáãÂ¶Ç‰ΩïÂπ´Âä©Êèê‰æõËÄÖÂçÄÂàÜÈúÄË¶ÅÁ´ãÂç≥ÊàñÈùûÁ∑äÊÄ•Â∞àÁßëËΩâË®∫ÁöÑÊÇ£ËÄÖ„ÄÇÊàëÂÄëÂª∫Á´ã‰∫ÜËß£ÈáãÊÄß AI ÊºîÁÆóÊ≥ïÔºå‰ª•Âæû‰æãË°åÁúºÁßëË≠∑ÁêÜË≥áÊñôÈ†êÊ∏¨ÈùíÂÖâÁúºÊâãË°ìÈúÄÊ±ÇÔºå‰ΩúÁÇ∫Ë≠òÂà•È´òÈ¢®Èö™ÊÇ£ËÄÖÁöÑ‰ª£ÁêÜ„ÄÇÊàëÂÄëÁ¥çÂÖ•‰∫ÜÂÖßÂú®Âíå‰∫ãÂæåËß£ÈáãÊÄßÔºå‰∏¶ËàáÈ©óÂÖâÂ∏´ÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÁ∑ö‰∏äÁ†îÁ©∂Ôºå‰ª•Ë©ï‰º∞‰∫∫Ê©üÂúòÈöäÁöÑË°®ÁèæÔºåË°°ÈáèËΩâË®∫Ê∫ñÁ¢∫Â∫¶‰∏¶ÂàÜÊûêËàá AI ÁöÑ‰∫íÂãïÔºåÂåÖÊã¨ÂêåÊÑèÁéá„ÄÅ‰ªªÂãôÊôÇÈñìÂíå‰ΩøÁî®ËÄÖÈ´îÈ©óÊÑüÁü•„ÄÇÂú® 87 ÂêçÂèÉËàáËÄÖ‰∏≠ÔºåAI ÊîØÊè¥ÊèêÈ´ò‰∫ÜËΩâË®∫Ê∫ñÁ¢∫Â∫¶Ôºà‰ΩøÁî® AI/Êú™‰ΩøÁî®ÁöÑÊØî‰æãÁÇ∫ 59.9%/50.8%ÔºâÔºåÂÑòÁÆ°‰∫∫Ê©üÂúòÈöäÁöÑË°®Áèæ‰∏çÂ¶ÇÂñÆÁç®‰ΩøÁî® AI„ÄÇÂèÉËàáËÄÖË™çÁÇ∫‰ªñÂÄëÂú®‰ΩøÁî®ÂÖßÂú®Ê®°ÂûãÊôÇÊõ¥Â§öÂú∞Á¥çÂÖ•‰∫Ü AI Âª∫Ë≠∞Ôºå‰∏¶Ë™çÁÇ∫ÂÆÉÊõ¥ÊúâÁî®‰∏îÊõ¥ÊúâÂ∏åÊúõ„ÄÇÊ≤íÊúâËß£ÈáãÔºåAI Âª∫Ë≠∞ÁöÑÂÅèÂ∑ÆÊúÉÂ¢ûÂä†„ÄÇAI ÊîØÊè¥‰∏¶Êú™Â¢ûÂä†Â∑•‰ΩúÈáè„ÄÅ‰ø°ÂøÉÂíå‰ø°‰ªªÔºå‰ΩÜÊ∏õÂ∞ë‰∫ÜÊåëÊà∞„ÄÇÂú®‰∏ÄÂÄãÂñÆÁç®ÁöÑÊ∏¨Ë©¶ÈõÜ‰∏≠ÔºåÊàëÂÄëÁöÑÈªëÁõíÂ≠êÂíåÂÖßÂú®Ê®°ÂûãÂú®È†êÊ∏¨ÊâãË°ìÁµêÊûúÊñπÈù¢ÂàÜÂà•ÈÅîÂà∞‰∫Ü 77% Âíå 71% ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÊâæÂá∫Âú®ÂàùÁ¥öÁúºÁßë‰øùÂÅ•‰∏≠Ôºå‰∫∫Ê©üÂúòÈöäÂêà‰ΩúÁÆ°ÁêÜÈùíÂÖâÁúºÁöÑÊ©üÊúÉÔºå‰∏¶Ê≥®ÊÑèÂà∞ÈõñÁÑ∂ AI ÊèêÈ´ò‰∫ÜËΩâË®∫Ê∫ñÁ¢∫Â∫¶Ôºå‰ΩÜÂç≥‰ΩøÊúâËß£ÈáãÔºåÂÆÉ‰πüÈ°ØÁ§∫Âá∫ËàáÂñÆÁç®‰ΩøÁî® AI Áõ∏ÊØîÁöÑÊïàËÉΩÂ∑ÆË∑ù„ÄÇ‰∫∫È°ûÂèÉËàáÂú®ÈÜ´ÁôÇÊ±∫Á≠ñ‰∏≠‰ªçÁÑ∂Ëá≥ÈóúÈáçË¶ÅÔºåÈÄôÂº∑Ë™ø‰∫ÜÊú™‰æÜÁ†îÁ©∂ÂÑ™ÂåñÂçî‰Ωú„ÄÅÁ¢∫‰øùÊ≠£Èù¢Á∂ìÈ©óÂíåÂÆâÂÖ®‰ΩøÁî® AI ÁöÑÂøÖË¶ÅÊÄß„ÄÇ</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

ÊëòË¶ÅÔºöÂú®ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÔºåÁâπÂà•ÊòØÂú®Êó©ÊúüÁñæÁóÖÊ™¢Ê∏¨ÂíåÈ†êÂæå‰ªªÂãô‰∏≠ÔºåËæ®Âà• AI Ê®°ÂûãÈ†êÊ∏¨ËÉåÂæåÁöÑÂéüÁêÜÂ∞çÊñºË©ï‰º∞ÂÖ∂Ê±∫Á≠ñÁöÑÂèØÈù†ÊÄßËá≥ÈóúÈáçË¶Å„ÄÇÂÇ≥Áµ±ÁöÑËß£ÈáãÊñπÊ≥ïÂú®Ë≠òÂà•ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°û‰∏≠ÂèØË≠òÂà•ÁöÑÊ±∫ÂÆöÊÄßÁâπÂæµÊôÇÈù¢Ëá®ÊåëÊà∞ÔºåÂÖ∂‰∏≠ÂçÄÂà•ÊÄßÁâπÂæµÂæàÂæÆÂ¶ôÊàñ‰∏¶‰∏çÊòéÈ°Ø„ÄÇÁÇ∫‰∫ÜÂΩåÂêàÈÄô‰∏ÄÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÊ®°ÂûãÔºåË©≤Ê®°ÂûãÂÖ∑ÂÇôÊ±∫Á≠ñÊé®ÁêÜÂíåÁâπÂæµË≠òÂà•ËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ï‰∏çÂÉÖÊ™¢Ê∏¨ÊúâÂΩ±ÈüøÂäõÁöÑÂΩ±ÂÉèÊ®°ÂºèÔºåÈÇÑÊè≠Á§∫‰∫ÜÊé®ÂãïÊ®°ÂûãÊúÄÁµÇÈ†êÊ∏¨ÁöÑÊ±∫ÂÆöÊÄßÁâπÂæµ„ÄÇÈÄöÈÅéÂØ¶ÊñΩÊàëÂÄëÁöÑÊ®°ÂûãÔºåÊàëÂÄëÂèØ‰ª•ÊúâÊïàË≠òÂà•ÂíåË¶ñË¶∫ÂåñÁî±Êï∏ÊìöÈ©ÖÂãïÊ®°ÂûãÂà©Áî®ÁöÑÈ°ûÁâπÂÆöÁâπÂæµÔºåÂæûËÄåÊ∑±ÂÖ•‰∫ÜËß£Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÊ±∫Á≠ñÈÅéÁ®ã„ÄÇÊàëÂÄëÂú®Ë¶ÅÊ±ÇÂö¥Ê†ºÁöÑÈÜ´Â≠∏È†êÂæå‰ªªÂãôÈ†òÂüüÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÊ®°ÂûãÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÊèêÈ´ò AI Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÂèØÈù†ÊÄßÂíåÁôºÁèæÈ†êÂæåÁêÜËß£ÂèóÈôêÁñæÁóÖÁöÑÊñ∞Áü•Ë≠òÊñπÈù¢ÁöÑÂäüÊïàÂíåÊΩõÂäõ„ÄÇ

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®éÁ∑ö‰∏äÂÅ•Â∫∑Á§æÁæ§‰∏≠Â∞ãÊ±ÇË≥áË®äÊîØÊåÅÁöÑÂïèÈ°å„ÄÅÂõûÊáâÔºå‰ª•ÂèäÊúâÂπ´Âä©ÁöÑË©ïÂàÜ‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÁµÑÊ®ôË®òÁöÑÂïèÁ≠îÈÖçÂ∞çË≥áÊñôÈõÜÔºå‰∏¶ÈñãÁôº‰∫ÜÂ§öÊ®°ÊÖãÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºå‰ª•ÂèØÈù†Âú∞È†êÊ∏¨Ë≥áË®äÊîØÊåÅÂïèÈ°åÂíåÂõûÊáâ„ÄÇÊàëÂÄëÊé°Áî®ÂèØËß£ÈáãÁöÑ AI ‰æÜÊè≠Á§∫Ë≥áË®äÊîØÊåÅ‰∫§ÊµÅ‰∏≠ËòäÂê´ÁöÑÊÉÖÁ∑íÔºåË≠âÊòéÊÉÖÁ∑íÂú®Êèê‰æõË≥áË®äÊîØÊåÅ‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇÈÄôÁ®ÆÊÉÖÁ∑íÊîØÊåÅÂíåË≥áË®äÊîØÊåÅ‰πãÈñìÁöÑË§áÈõú‰∫§‰∫í‰ΩúÁî®‰ª•Ââç‰∏¶Êú™Ë¢´Á†îÁ©∂ÈÅé„ÄÇÊú¨Á†îÁ©∂ÊîπÈÄ≤‰∫ÜÁ§æÊúÉÊîØÊåÅÁêÜË´ñÔºå‰∏¶ÁÇ∫‰ΩøÁî®ËÄÖÊ±∫Á≠ñËºîÂä©Â∑•ÂÖ∑ÁöÑÈñãÁôºÂ•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇË®éË´ñ‰∫ÜÈÄ≤‰∏ÄÊ≠•ÁöÑÂΩ±Èüø„ÄÇ

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

ÊëòË¶ÅÔºöÂú®ÁßëÊäÄÈ£õÈÄüÁôºÂ±ïÁöÑÊôÇ‰ª£Ôºå‰∏Ä‰ΩçÊÑèÂ§ñÁöÑË®™ÂÆ¢Â∑≤Âú®ÂÖ®ÁêÉÊïôÂÆ§‰∏≠‰ΩîÊúâ‰∏ÄÂ∏≠‰πãÂú∞ÔºåÈÇ£Â∞±ÊòØ‰∫∫Â∑•Êô∫ÊÖß„ÄÇÁîüÊàêÂºè AIÔºå‰æãÂ¶Ç ChatGPTÔºåÊâøË´æÂú®ÊïôËÇ≤È†òÂüüÊéÄËµ∑‰∏ÄÂ†¥Èù©ÂëΩÔºå‰ΩÜÂÆÉÂçªÊòØ‰∏ÄÊääÈõôÈù¢ÂàÉ„ÄÇÂÆÉÂú®ÂÄã‰∫∫ÂåñÂ≠∏ÁøíÊñπÈù¢ÁöÑÊΩõÂäõÔºåÂçªÂõ†‰ΩúÂºä„ÄÅ‰∏çÊ∫ñÁ¢∫‰ª•ÂèäÊïôËÇ≤Â∑•‰ΩúËÄÖÈõ£‰ª•Â∞áÂÖ∂ÊúâÊïàËûçÂÖ•ÊïôÂ≠∏Ë®≠Ë®àÁ≠âÂïèÈ°åËÄåÊäµÈä∑„ÄÇÊàëÂÄëÊ≠£Á´ôÂú®ÈÄôÊïôËÇ≤ÂâçÊ≤øÁöÑÈÇäÁ∑£ÔºåÈ°ØÁÑ∂ÊàëÂÄëÈúÄË¶ÅÈùûÂ∏∏Â∞èÂøÉÂú∞Êé¢Á¥¢ÈÄôÁâáÈ†òÂüü„ÄÇÈÄôÊòØ‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞ÔºåÂèØËÉΩÊúÉÊêçÂÆ≥ÊàëÂÄëÊïôËÇ≤ÈÅéÁ®ãÁöÑÂÆåÊï¥ÊÄßÂíåÂÉπÂÄº„ÄÇÈÇ£È∫ºÔºåÊàëÂÄëÂ¶Ç‰ΩïÂ∞áÈÄô‰∫õÊåëÊà∞ËΩâÂåñÁÇ∫Ê©üÈÅáÔºüÁï∂‰∏çÈÅ©Áï∂Âú∞‰ΩøÁî®ÊôÇÔºåAI Â∑•ÂÖ∑ÂèØËÉΩÊúÉÊàêÁÇ∫Ë§áË£ΩË≤º‰∏äÂøÉÊÖãÁöÑÂÆåÁæéÂ∑•ÂÖ∑Ôºå‰∏¶ËøÖÈÄüËÖêËùïÊâπÂà§ÊÄßÊÄùÁ∂≠„ÄÅÂâµÈÄ†ÂäõÂíåÊ∑±ÂÖ•ÁêÜËß£ÔºåÈÄô‰∫õÈÉΩÊòØÊàëÂÄëÂø´ÈÄüËÆäÂåñÁöÑ‰∏ñÁïå‰∏≠ÊúÄÈáçË¶ÅÁöÑÊäÄËÉΩ„ÄÇÊïôÂ∏´ÂÄëË¶∫Âæó‰ªñÂÄëÊ≤íÊúâËÉΩÂäõÂà©Áî®ÈÄôÈ†ÖÊäÄË°ìÔºåÈÄôÊì¥Â§ß‰∫ÜÊïôËÇ≤Â∑•‰ΩúËÄÖÂíåÊ©üÊßã‰πãÈñìÁöÑÊï∏‰ΩçÈ¥ªÊ∫ù„ÄÇËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÈúÄË¶ÅÊ∑±ÂÖ•ÁöÑÁ†îÁ©∂ÊñπÊ≥ï„ÄÇÊàëÂÄëÂ∞áÊé°Áî®ÂØ¶Ë≠âÁ†îÁ©∂ÔºåÂÄüÈëëÊäÄË°ìÊé•ÂèóÊ®°ÂûãÔºå‰æÜË©ï‰º∞ÊïôËÇ≤Â∑•‰ΩúËÄÖÂíåÂ≠∏ÁîüÂ∞çÁîüÊàêÂºè AI ÁöÑÊÖãÂ∫¶„ÄÇ‰∫ÜËß£‰ªñÂÄëÁöÑÁúãÊ≥ï„ÄÅ‰ΩøÁî®Ê®°ÂºèÂíåÈöúÁ§ôÊòØÂâµÈÄ†ÊúâÊïàËß£Ê±∫ÊñπÊ°àÁöÑÁ¨¨‰∏ÄÂÄãÈóúÈçµÊ≠•È©ü„ÄÇÊú¨Á†îÁ©∂Â∞á‰ΩúÁÇ∫Êú™‰æÜÁ†îÁ©∂‰∫∫Âì°ÊáâÁî®ÁöÑÊµÅÁ®ãÊâãÂÜäÔºåÊ†πÊìöÊ≠§ËôïË™™ÊòéÁöÑÊ≠•È©üÈÅãË°å‰ªñÂÄëËá™Â∑±ÁöÑÊï∏Êìö

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike Gr√ºne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, Andr√© Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

ÊëòË¶ÅÔºöÈö®ËëóÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±ÁöÑÊï∏‰ΩçÂåñÔºå‰∫∫Â∑•Êô∫ÊÖßÂú®ÈÜ´Â≠∏È†òÂüü‰∏≠ËÆäÂæóÊõ¥Âä†ÊôÆÂèä„ÄÇÁâπÂà•ÊòØÊ©üÂô®Â≠∏ÁøíÂú®ÊôÇÈñìÂ∫èÂàóÂàÜÈ°ûÁ≠âË§áÈõú‰ªªÂãô‰∏≠Â±ïÁèæÂá∫Ê•µÂ§ßÁöÑÊΩõÂäõÔºå‰ΩÜÈÄöÂ∏∏ÊòØ‰ª•ÈÄèÊòéÂ∫¶ÂíåÂèØÁêÜËß£ÊÄßÁÇ∫‰ª£ÂÉπ„ÄÇÈÄôÂ∞éËá¥‰∫∫È°ûÁº∫‰πè‰ø°‰ªªÔºåÂæûËÄåÈòªÁ§ô‰∫ÜÂÖ∂Á©çÊ•µ‰ΩøÁî®„ÄÇÂèØËß£ÈáãÁöÑ‰∫∫Â∑•Êô∫ÊÖßË©¶ÂúñÈÄöÈÅéÊèê‰æõÂ∞çÊ±∫Á≠ñÈÅéÁ®ãÁöÑÊ¥ûÂØü‰æÜÂΩåË£úÈÄô‰∏ÄÂ∑ÆË∑ùÔºå‰ΩÜÂÖ∂‰∏çÂêåÊñπÊ≥ïÁöÑÂØ¶ÈöõÊïàÁî®Â∞ö‰∏çÊ∏ÖÊ•ö„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫Êñº‰ΩøÁî®ËÄÖÁ†îÁ©∂ÁöÑË©ï‰º∞ÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∫Ü Grad-CAM Ëß£ÈáãÊñπÊ≥ïÔºå‰∏¶Â∞áÂÖ∂ÊáâÁî®ÊñºÁ•ûÁ∂ìÁ∂≤Ë∑Ø‰ª•ÂàÜÈ°ûÊôÇÈñìÂ∫èÂàóÊñ∞ÁîüÂÖíÂëºÂê∏Êï∏Êìö‰∏≠ÁöÑÂëºÂê∏„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰∏çÂêåÂà©ÁõäÁõ∏ÈóúËÄÖÂ∞çÂèØËß£ÈáãÊÄßÊñπÊ≥ïÁöÑÊÑüÁü•ÊïàÁî®ÔºåÊè≠Á§∫‰∫ÜÂØ¶ÁèæÂØ¶ÈöõÈÄèÊòéÂ∫¶ÁöÑÈõ£Â∫¶Ôºå‰ª•ÂèäË®±Â§öÂèÉËàáËÄÖÂ∏åÊúõÁç≤ÂæóÊõ¥Ê∑±ÂÖ•ÁöÑËß£Èáã„ÄÇ

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËàáÈÜ´ÁôÇË®∫Êñ∑Êï¥Âêà
ÁÇ∫Ëá®Â∫äÊ±∫Á≠ñÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÊôØÁöÑÈÄîÂæë„ÄÇÊú¨Á†îÁ©∂Ê¶ÇËø∞‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÊñπÊ≥ïÁöÑÈñãÁôºÔºåÁî®ÊñºÈõ∂Ê¨°Â≠∏Áøí/Â∞ëÈáèÂ≠∏ÁøíÊÉÖÂ¢ÉÂ≠∏Áøí (ICL)ÔºåÊñπÊ≥ïÊòØ‰ΩøÁî®Â§öÂ±§ÁµêÊßãÂåñÊèêÁ§∫Êï¥ÂêàÈÜ´ÁôÇÈ†òÂüüÁü•Ë≠ò„ÄÇÊàëÂÄëÈÇÑÊé¢Ë®é‰∫Ü‰ΩøÁî®ËÄÖËàá LLM ‰πãÈñìÂÖ©Á®ÆÊ∫ùÈÄöÊñπÂºèÁöÑÂäüÊïàÔºöÊï∏ÂÄºÂ∞çË©± (NC) ÊñπÂºèÔºåÂÆÉÊúÉÈÄêÊ≠•ËôïÁêÜË≥áÊñôÔºå‰ª•ÂèäËá™ÁÑ∂Ë™ûË®ÄÂñÆÂõûÂêà (NL-ST) ÊñπÂºèÔºåÂÆÉÊúÉ‰ΩøÁî®Èï∑ÁØáÊïò‰∫ãÊèêÁ§∫„ÄÇ
ÊàëÂÄëÁöÑÁ†îÁ©∂Á≥ªÁµ±ÊÄßÂú∞Ë©ï‰º∞‰∫ÜË®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÂíåÈ¢®Èö™Âõ†Â≠êÔºåÂåÖÊã¨ÊÄßÂà•ÂÅèË¶ãÂíåÂÅáÈô∞ÊÄßÁéáÔºå‰ΩøÁî®‰∫Ü‰∏ÄÂÄãÂåÖÂê´ 920 ÂÄãÊÇ£ËÄÖË®òÈåÑÁöÑË≥áÊñôÈõÜÔºåÊé°Áî®ÂêÑÁ®ÆÂ∞ëÈáèÂ≠∏ÁøíÊÉÖÂ¢É„ÄÇÁµêÊûúË°®ÊòéÔºåÂÇ≥Áµ±ÁöÑËá®Â∫äÊ©üÂô®Â≠∏Áøí (ML) Ê®°ÂûãÈÄöÂ∏∏Âú®Èõ∂Ê¨°Â≠∏ÁøíÂíåÂ∞ëÈáèÂ≠∏ÁøíË®≠ÂÆö‰∏≠Ë°®ÁèæÂÑ™Êñº LLM„ÄÇÁÑ∂ËÄåÔºåÁï∂‰ΩøÁî®Â∞ëÈáèÂ≠∏ÁøíÁØÑ‰æã‰ª•ÂèäÊúâÊïàÁöÑÂèØËß£Èáã AI (XAI) ÊñπÊ≥ï‰ΩúÁÇ∫È†òÂüüÁü•Ë≠ò‰æÜÊ∫êÊôÇÔºåÊïàËÉΩÂ∑ÆË∑ùÊúÉÈ°ØËëóÁ∏ÆÂ∞è„ÄÇÊ≠§Â§ñÔºåÈö®ËëóÊôÇÈñìÂÖÖË∂≥ÂíåÁØÑ‰æãÊï∏ÈáèÂ¢ûÂä†ÔºåÂ∞çË©±ÊñπÂºè (NC) Âπæ‰πéÂèØ‰ª•Â™≤Áæé ML Ê®°ÂûãÁöÑÊïàËÉΩ„ÄÇÊúÄÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåLLM Áõ∏Â∞çÊñº ML Ê®°ÂûãÂ±ïÁèæÂá∫Áõ∏Áï∂ÊàñÊõ¥‰Ω≥ÁöÑÊàêÊú¨ÊïèÊÑüÊ∫ñÁ¢∫Â∫¶„ÄÇ
Êú¨Á†îÁ©∂Ë≠âÂØ¶ÔºåÈÄèÈÅéÈÅ©Áï∂ÁöÑÈ†òÂüüÁü•Ë≠òÂíåÈáèË∫´ÊâìÈÄ†ÁöÑÊ∫ùÈÄöÁ≠ñÁï•ÔºåLLM ÂèØ‰ª•È°ØËëóÂ¢ûÂº∑Ë®∫Êñ∑Á®ãÂ∫è„ÄÇÈÄô‰∫õÁôºÁèæÁ™ÅÈ°Ø‰∫ÜÊúÄ‰Ω≥ÂåñË®ìÁ∑¥ÁØÑ‰æãÊï∏ÈáèÂíåÊ∫ùÈÄöÊñπÂºèÁöÑÈáçË¶ÅÊÄßÔºå‰ª•ÊèêÈ´òÊ∫ñÁ¢∫Â∫¶‰∏¶Ê∏õÂ∞ë LLM ÊáâÁî®‰∏≠ÁöÑÂÅèÂ∑Æ„ÄÇ

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel Mir√≥-Nicolau, Gabriel Moy√†-Alcover, Antoni Jaume-i-Cap√≥, Manuel Gonz√°lez-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

ÊëòË¶ÅÔºöÈö®ËëóÂ∞çÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã‰æùË≥¥ÊÄßÁöÑÂ¢ûÂä†ÔºåÂä†‰∏äÂÖ∂Âõ∫ÊúâÁöÑÈÄèÊòéÂ∫¶‰∏çË∂≥Ôºå‰øÉ‰Ωø‰∏ÄÂÄãÊñ∞ÁöÑÁ†îÁ©∂È†òÂüüÁôºÂ±ïÔºåÁ®±ÁÇ∫ÂèØËß£Èáã AI (XAI) ÊñπÊ≥ï„ÄÇÈÄô‰∫õÊñπÊ≥ïÊó®Âú®ÈÄèÈÅéÊ∑±ÂÖ•‰∫ÜËß£Ê±∫Á≠ñËÉåÂæåÁöÑÂéüÁêÜÔºå‰æÜÊèêÂçáÊúÄÁµÇ‰ΩøÁî®ËÄÖÂ∞çËá™ÂãïÂåñÁ≥ªÁµ±ÁöÑ‰ø°Ë≥¥„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆË°°Èáè‰ΩøÁî®ËÄÖÂ∞ç XAI Á≥ªÁµ±‰ø°Ë≥¥Â∫¶ÁöÑÊñ∞Á©éÊñπÊ≥ïÔºåÂÖÅË®±Â∞çÂÖ∂ÈÄ≤Ë°åÊîπÈÄ≤„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊåáÊ®ôÁµêÂêà‰∫ÜÂÆ¢ËßÄËßÄÈªû‰∏ãÁöÑÊïàËÉΩÊåáÊ®ôÂíå‰ø°Ë≥¥ÊåáÊ®ô„ÄÇÁÇ∫‰∫ÜÈ©óË≠âÈÄôÂÄãÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÊàëÂÄëÂú®‰∏ÄÂÄãÁúüÂØ¶ÁöÑÈÜ´ÁôÇÂ†¥ÊôØ‰∏≠ÈÄ≤Ë°å‰∫Ü‰∏ÄÂÄãÊ°à‰æãÁ†îÁ©∂Ôºö‰ΩøÁî® XAI Á≥ªÁµ±Âæû X ÂÖâÂΩ±ÂÉè‰∏≠ÂÅµÊ∏¨ËÇ∫ÁÇé„ÄÇ

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

ÊëòË¶ÅÔºöCOVID-19 Áñ´ÊÉÖÂ∞çÂÖ®ÁêÉÂÖ¨ÂÖ±Ë°õÁîüÈÄ†ÊàêÂ£ìÂäõÔºåÂøÖÈ†àÈÄ≤Ë°åÊ∫ñÁ¢∫ÁöÑË®∫Êñ∑ÂíåÂπ≤È†êÔºå‰ª•ÊéßÂà∂ÁñæÁóÖÂÇ≥Êí≠‰∏¶Èôç‰ΩéÊ≠ª‰∫°Áéá„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÊ∑±Â∫¶ÁîüÂ≠òÈ†êÊ∏¨Ê®°ÂûãÔºåÂ∞àÈñÄË®≠Ë®àÁî®ÊñºÈÄèÈÅéËÉ∏ÈÉ® X ÂÖâ (CXR) ÂΩ±ÂÉèÊîπÂñÑÂ∞ç COVID-19 È†êÂæåÁöÑÁêÜËß£Âíå‰ø°Ë≥¥„ÄÇÈÄèÈÅéÊï¥ÂêàÂ§ßË¶èÊ®°È†êË®ìÁ∑¥ÂΩ±ÂÉèÁ∑®Á¢ºÂô®„ÄÅÈ¢®Èö™ÁâπÂÆö Grad-CAM ÂíåËß£ÂâñÂçÄÂüüÂÅµÊ∏¨ÊäÄË°ìÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÁî¢ÁîüÂçÄÂüüÂèØËß£ÈáãÁöÑÁµêÊûúÔºåÊúâÊïàÊçïÊçâÂøÖË¶ÅÁöÑÁñæÁóÖÁâπÂæµÔºåÂêåÊôÇÂ∞àÊ≥®ÊñºÁΩïË¶ã‰ΩÜÈóúÈçµÁöÑÁï∞Â∏∏ÂçÄÂüü„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÈ†êÊ∏¨ÁµêÊûúÈÄèÈÅéÈ¢®Èö™ÂçÄÂüüÂÆö‰ΩçÊèê‰æõÂ¢ûÂº∑ÁöÑÊ∏ÖÊô∞Â∫¶ÂíåÈÄèÊòéÂ∫¶ÔºåËÆìËá®Â∫äÈÜ´ÁîüËÉΩÂ§†Âú®Êõ¥‰∫ÜËß£È†êÂæåË¶ãËß£ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂ∞± COVID-19 Ë®∫Êñ∑ÂÅöÂá∫ÊòéÊô∫ÁöÑÊ±∫Á≠ñ„ÄÇÊàëÂÄëÂú®Â§ö‰∏≠ÂøÉÁîüÂ≠òË≥áÊñôÈõÜ‰∏äË©ï‰º∞ÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÔºå‰∏¶ÈÄèÈÅéÈáèÂåñÂíåË≥™ÂåñË©ï‰º∞Ë≠âÊòéÂÖ∂ÊúâÊïàÊÄßÔºåÈÅîÂà∞ÂÑ™Áï∞ÁöÑ C ÊåáÊï∏Ôºà0.764 Âíå 0.727ÔºâÂíåÊôÇÈñìÁõ∏Èóú AUCÔºà0.799 Âíå 0.691Ôºâ„ÄÇÈÄô‰∫õÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÂèØËß£ÈáãÁöÑÊ∑±Â∫¶ÁîüÂ≠òÈ†êÊ∏¨Ê®°ÂûãÂú®È¢®Èö™È†êÊ∏¨ÊñπÈù¢Ë∂ÖË∂äÂÇ≥Áµ±ÁöÑÁîüÂ≠òÂàÜÊûêÊñπÊ≥ïÔºåÊèêÂçáËá®Â∫äÊ±∫Á≠ñÁöÑËß£ÈáãÊÄßÔºå‰∏¶Â¢ûÂº∑ AI Á≥ªÁµ±ÁöÑ‰ø°Ë≥¥Â∫¶„ÄÇ

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

ÊëòË¶ÅÔºö<paragraph>Âú®ÈÅéÂéªÂπæÂπ¥ÔºåËá®Â∫äÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ± (CDSS) ‰∏≠ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) Âú®Âà©Áî®Ê©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊû∂ÊßãÊñπÈù¢ÁôºÊèÆ‰∫ÜÈóúÈçµ‰ΩúÁî®„ÄÇÂÑòÁÆ° AI Ê®°ÂûãÂÖ∑Êúâ‰ª§‰∫∫ÊªøÊÑèÁöÑËÉΩÂäõÔºå‰ΩÜÁº∫‰πèÈÄèÊòéÂ∫¶ÂíåÂèØËß£ÈáãÊÄßÔºåÁâπÂà•ÊòØÂú®ÂèØÈù†ÊÄßÁÇ∫ÂøÖË¶ÅËÄÉÈáèÁöÑÈÜ´ÁôÇËÉåÊôØ‰∏ãÔºåÈÄôÂ∏∂‰æÜ‰∫ÜÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÂú®‰∏çÂΩ±ÈüøÈ†êÊ∏¨Á≤æÊ∫ñÂ∫¶ÁöÑÊÉÖÊ≥Å‰∏ãÂØ¶ÁèæÈÄèÊòéÂ∫¶‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÈóúÈçµÊåëÊà∞„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÂç≥ Rad4XCNNÔºå‰ª•Â¢ûÂº∑ CNN Ë°çÁîüÁâπÂæµÁöÑÈ†êÊ∏¨ËÉΩÂäõÔºåÂêåÊôÇÂÖ∑ÂÇôÊîæÂ∞ÑÁâπÂæµÂõ∫ÊúâÁöÑÂèØËß£ÈáãÊÄß„ÄÇRad4XCNN ‰∏çÂêåÊñºÂü∫ÊñºÈ°ØËëóÊÄßÂúñÁöÑÂÇ≥Áµ±ÊñπÊ≥ïÔºåÂÆÉÈÄöÈÅéÊîæÂ∞ÑÁµÑÂ≠∏Â∞áÂèØÁêÜËß£ÁöÑÂê´Áæ©Ëàá CNN Ë°çÁîüÁâπÂæµÈóúËÅØËµ∑‰æÜÔºåÁÇ∫Ë∂ÖË∂äË¶ñË¶∫ÂåñÂúñË°®ÁöÑËß£ÈáãÊñπÊ≥ïÊèê‰æõ‰∫ÜÊñ∞ÁöÑËßÄÈªû„ÄÇÊàëÂÄë‰ª•‰π≥ÁôåÂàÜÈ°û‰ªªÂãô‰ΩúÁÇ∫Ê°à‰æãÁ†îÁ©∂ÔºåÂú®Ë∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèË≥áÊñôÈõÜ‰∏äË©ï‰º∞ Rad4XCNNÔºåÂåÖÊã¨‰∏ÄÂÄãÁ∑ö‰∏äË≥áÊñôÈõÜÂíåÂÖ©ÂÄãÁî®ÊñºÂÖßÈÉ®ÂíåÂ§ñÈÉ®È©óË≠âÁöÑÂÖßÈÉ®Ë≥áÊñôÈõÜ„ÄÇ‰∏Ä‰∫õÈóúÈçµÁµêÊûúÂ¶Ç‰∏ãÔºöi) Ëàá ViT Ë°çÁîüÁâπÂæµÂíåÊîæÂ∞ÑÁâπÂæµÁõ∏ÊØîÔºåCNN Ë°çÁîüÁâπÂæµ‰øùË≠â‰∫ÜÊõ¥Á©©ÂÅ•ÁöÑÊ∫ñÁ¢∫Â∫¶Ôºõii) ÂÇ≥Áµ±ÁöÑË¶ñË¶∫ÂåñÂúñËß£ÈáãÊñπÊ≥ïÂ≠òÂú®‰∏Ä‰∫õÁº∫Èô∑Ôºõiii) Rad4XCNN Ê≤íÊúâÁäßÁâ≤Ê®°ÂûãÊ∫ñÁ¢∫Â∫¶‰æÜÊèõÂèñÂÖ∂ÂèØËß£ÈáãÊÄßÔºõiv) Rad4XCNN Êèê‰æõ‰∫ÜÂÖ®Â±ÄËß£ÈáãË¶ãËß£Ôºå‰ΩøÈÜ´Â∏´ËÉΩÂ§†ÂàÜÊûêÊ®°ÂûãËº∏Âá∫ÂíåÁôºÁèæ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂº∑Ë™øÂ∞áÂèØËß£ÈáãÊÄßÊï¥ÂêàÂà∞ AI Ê®°Âûã‰∏≠Â∞çÊñºÂ¢ûÂº∑Ëá®Â∫äÂØ¶Âãô‰∏≠ÁöÑ‰ø°‰ªªÂíåÊé°Áî®Ëá≥ÈóúÈáçË¶ÅÔºå‰∏¶Âº∑Ë™ø‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂ¶Ç‰ΩïËÉΩÁ∑©Ëß£ËàáÂèØËß£Èáã AI ÊñπÊ≥ïÁõ∏ÈóúÁöÑ‰∏Ä‰∫õÁñëÊÖÆ„ÄÇ</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

ÊëòË¶ÅÔºöÈö®Ëëó‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÊôÆÂèäÊï¥ÂêàÔºåÂú®Ê∂âÂèä AI È©ÖÂãïÁ≥ªÁµ±ÁöÑ‰∫ãÊïÖ‰∏≠ÔºåË≤¨‰ªªÂíåÁæ©ÂãôÊ≠∏Â±¨Áî¢Áîü‰∫ÜË§áÈõúÁöÑÊåëÊà∞„ÄÇÈÄô‰∫õÁ≥ªÁµ±ÁöÑ‰∫íÈÄ£ÊÄß„ÄÅAI ÂºïÁôº‰∫ãÊïÖÁöÑÂÄ´ÁêÜÂïèÈ°åÔºåÂä†‰∏ä AI ÊäÄË°ìÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÂíåÁº∫‰πèÁõ∏ÊáâÊ≥ïË¶èÔºå‰ΩøÂæóÂÇ≥Áµ±Ë≤¨‰ªªÊ≠∏Â±¨Èù¢Ëá®ÊåëÊà∞„ÄÇÁÇ∫Ê≠§ÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆË®àÁÆóÂèçÊÄùÂùáË°° (CRE) ÊñπÊ≥ïÔºå‰ª•Âª∫Á´ã‰∏ÄÂÄãÈÄ£Ë≤´‰∏îÂú®ÂÄ´ÁêÜ‰∏äÂèØÊé•ÂèóÁöÑË≤¨‰ªªÊ≠∏Â±¨Êû∂ÊßãÔºåÈÅ©Áî®ÊñºÊâÄÊúâÂà©ÂÆ≥Èóú‰øÇ‰∫∫„ÄÇË®àÁÆóÊñπÊ≥ïÊèê‰æõ‰∫ÜÁµêÊßãÂåñÁöÑÂàÜÊûêÔºåÂÖãÊúç‰∫ÜÊ¶ÇÂøµÊñπÊ≥ïÂú®ËôïÁêÜÂãïÊÖã‰∏îÂ§öÈù¢ÂêëÊÉÖÂ¢ÉÊôÇÁöÑÈôêÂà∂ÔºåÂ±ïÁ§∫‰∫ÜË©≤Êû∂ÊßãÂú®Ë≤¨‰ªªÊ≠∏Â±¨ÈÅéÁ®ã‰∏≠ÂÖ∑ÂÇôÁöÑÂèØËß£ÈáãÊÄß„ÄÅÈÄ£Ë≤´ÊÄßÂíåÈÅ©ÊáâÊÄß„ÄÇÊàëÂÄëÊé¢Ë®é‰∫ÜËàáÂùáË°°Ë®àÁÆó‰∏≠Á¥¢Ë≥†Áõ∏ÈóúÁöÑÂàùÂßãÂïüÂãïÂ±§Á¥öÁöÑÈóúÈçµ‰ΩúÁî®„ÄÇÊàëÂÄë‰ª• AI ËºîÂä©ÈÜ´ÁôÇÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ±ÁÇ∫Ê°à‰æãÁ†îÁ©∂ÔºåË™™Êòé‰∏çÂêåÁöÑÂàùÂßãÂåñÂ¶Ç‰ΩïÂ∞éËá¥‰∏çÂêåÁöÑË≤¨‰ªªÂàÜÈÖç„ÄÇË©≤Êû∂ÊßãÊèê‰æõ‰∫ÜÂ∞ç AI ÂºïÁôº‰∫ãÊïÖ‰∏≠ÂïèË≤¨Âà∂ÁöÑÂØ∂Ë≤¥Ë¶ãËß£ÔºåÈÄèÈÅéÊåÅÁ∫åÁõ£Êéß„ÄÅ‰øÆË®ÇÂíåÂèçÊÄùÔºå‰øÉÈÄ≤‰∫ÜÊ∞∏Á∫å‰∏îÊúâÈüåÊÄßÁöÑÁ≥ªÁµ±ÁôºÂ±ï„ÄÇ

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÈÄèÈÅéÈ†êÊ∏¨Ê®°ÂûãÂçîÂä©ÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°ÔºåÂ§ßÂπÖËΩâËÆä‰∫ÜËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÂú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠‰ΩøÁî®‰∫∫Â∑•Êô∫ÊÖßÊáâÁî®Á®ãÂºèÊôÇÂÖ¨Âπ≥ÊÄßÂíåÂèØËß£ÈáãÊÄßÁöÑÈóúÈçµÈúÄÊ±ÇÔºå‰ª•Á¢∫‰øùÂú®‰∏çÂêåÁöÑÊÇ£ËÄÖ‰∫∫Âè£Áµ±Ë®àË≥áÊñô‰∏≠Áç≤ÂæóÂÖ¨Âπ≥ÁöÑÁµêÊûú„ÄÇÈÄèÈÅéÂ∞àÊ≥®ÊñºÊïóË°ÄÁóáÁõ∏ÈóúÊ≠ª‰∫°ÁéáÁöÑÈ†êÊ∏¨Ê®°ÂûãÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÊúÉÂ≠∏Áøí‰∏ÄÂÄãÊïàËÉΩÊúÄ‰Ω≥ÂåñÁöÑÈ†êÊ∏¨Ê®°ÂûãÔºåÁÑ∂ÂæåÊé°Áî®ËΩâÁßªÂ≠∏ÁøíÈÅéÁ®ã‰æÜÁî¢Áîü‰∏ÄÂÄãÂÖ∑ÊúâÊõ¥Â•ΩÂÖ¨Âπ≥ÊÄßÁöÑÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÈÇÑÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂü∫ÊñºÊéíÂàóÁöÑÁâπÂæµÈáçË¶ÅÊÄßÊºîÁÆóÊ≥ïÔºåÊó®Âú®Èó°ÊòéÊØèÂÄãÁâπÂæµÂú®Â¢ûÂº∑È†êÊ∏¨ÂÖ¨Âπ≥ÊÄßÊñπÈù¢ÁöÑË≤¢Áçª„ÄÇËàáÁèæÊúâÁöÑÂèØËß£ÈáãÊÄßÊñπÊ≥ïÂ∞àÊ≥®ÊñºËß£ÈáãÁâπÂæµÂ∞çÈ†êÊ∏¨ÊïàËÉΩÁöÑË≤¢Áçª‰∏çÂêåÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÁç®ÁâπÂú∞ÂΩåË£ú‰∫ÜÁêÜËß£ÊØèÂÄãÁâπÂæµÂ¶Ç‰ΩïÊúâÂä©ÊñºÂÖ¨Âπ≥ÊÄßÁöÑÂ∑ÆË∑ù„ÄÇÈÄôÈ†ÖÈÄ≤Â±ïËá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫ÊïóË°ÄÁóáÁöÑÊ≠ª‰∫°ÁéáÂæàÈ´òÔºå‰∏îÂú®‰∏âÂàÜ‰πã‰∏ÄÁöÑÈÜ´Èô¢Ê≠ª‰∫°‰∏≠ÊâÆÊºîËëóËßíËâ≤„ÄÇÊàëÂÄëÁöÑÊ®°Âûã‰∏çÂÉÖÊúâÂä©ÊñºË≠òÂà•ÂíåÊ∏õËºïÈ†êÊ∏¨Ê®°Âûã‰∏≠ÁöÑÂÅèÂ∑ÆÔºåÈÇÑËÉΩÈÄèÈÅéÊèêÈ´òÊ®°ÂûãÈ†êÊ∏¨ÁöÑÈÄèÊòéÂ∫¶ÂíåÂÖ¨Âπ≥ÊÄß‰æÜÂüπÈ§äÈÜ´ÁôÇ‰øùÂÅ•Âà©ÁõäÁõ∏ÈóúËÄÖ‰πãÈñìÁöÑ‰ø°‰ªªÔºåÈÄ≤ËÄåÊúâÂä©ÊñºÊèê‰æõÊõ¥ÂÖ¨Âπ≥‰∏îÂÄºÂæó‰ø°Ë≥¥ÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÊúçÂãô„ÄÇ

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

ÊëòË¶ÅÔºöÁèæ‰ªäÔºåÊÜÇÈ¨±ÁóáÊòØ‰∏ÄÂÄãÈáçË¶ÅÁöÑË≠∞È°å„ÄÇÊ†πÊìö‰∏ñÁïåË°õÁîüÁµÑÁπî (WHO) ÁöÑË≥áÊñôÔºåÂú® 2023 Âπ¥ÔºåË∂ÖÈÅé 2.8 ÂÑÑ‰∫∫Ê≠£Âú®ËàáÊÜÇÈ¨±ÁóáÊêèÈ¨•„ÄÇÈÄôÊòØ‰∏ÄÂÄãÈæêÂ§ßÁöÑÊï∏Â≠óÔºõÂ¶ÇÊûú‰∏çË™çÁúüÁúãÂæÖÔºåÈÄô‰∫õÊï∏Â≠óÂ∞áÊúÉÂø´ÈÄüÂ¢ûÂä†„ÄÇÂ§ßÁ¥ÑÊúâ 48.9 ÂÑÑ‰∫∫ÊòØÁ§æÁæ§Â™íÈ´î‰ΩøÁî®ËÄÖ„ÄÇ‰∫∫ÂÄëÂú® Twitter„ÄÅFacebook„ÄÅReddit„ÄÅInstagram Á≠âÂπ≥Âè∞‰∏äË°®ÈÅîËá™Â∑±ÁöÑÊÑüÂèóÂíåÊÉÖÁ∑í„ÄÇÈÄô‰∫õÂπ≥Âè∞ÂåÖÂê´ÊúâÂÉπÂÄºÁöÑË≥áË®äÔºåÂèØÁî®ÊñºÁ†îÁ©∂ÁõÆÁöÑ„ÄÇÂ∑≤Á∂ìÂú®ÂêÑÁ®ÆÁ§æÁæ§Â™íÈ´îÂπ≥Âè∞‰∏äÈÄ≤Ë°å‰∫ÜÂ§ßÈáèÁöÑÁ†îÁ©∂„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÂä™Âäõ‰ªçÂ≠òÂú®Êüê‰∫õÈôêÂà∂„ÄÇÁâπÂà•ÊòØÔºåÂÖàÂâçÁöÑÁ†îÁ©∂ÂÉÖÂ∞àÊ≥®ÊñºÂÅµÊ∏¨Êé®Êñá‰∏≠ÁöÑÊÜÇÈ¨±ÁóáÂíåÊÜÇÈ¨±ÁóáÁöÑÂº∑Â∫¶„ÄÇÊ≠§Â§ñÔºåË≥áÊñôÈõÜÊ®ôÁ±§‰∏≠Â≠òÂú®‰∏çÊ∫ñÁ¢∫ÁöÑÊÉÖÊ≥Å„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂Â∑•‰Ωú‰∏≠Ôºå‰ΩøÁî®Âü∫ÊñºË©ûÂΩôÊ®ôÁ±§ÁöÑ Twitter Ë≥áÊñôÂ∫´‰∏≠ÁöÑÊé®ÊñáÈ†êÊ∏¨‰∫Ü‰∫îÁ®ÆÈ°ûÂûãÁöÑÊÜÇÈ¨±ÁóáÔºàÈõôÊ•µÂûã„ÄÅÈáçÂ∫¶„ÄÅÁ≤æÁ•ûÁóÖÂûã„ÄÅÈùûÂÖ∏ÂûãÂíåÁî¢ÂæåÔºâ„ÄÇÂèØËß£ÈáãÁöÑ AI Áî®ÊñºÈÄèÈÅéÂº∑Ë™ø‰ª£Ë°®ÊÜÇÈ¨±ÁóáÈ°ûÂûãÁöÑÊé®ÊñáÈÉ®ÂàÜ‰æÜÊèê‰æõÊé®ÁêÜ„ÄÇÂæû TransformersÔºàBERTÔºâ‰∏≠ÊèêÂèñÁöÑÈõôÂêëÁ∑®Á¢ºÂô®Ë°®Á§∫Áî®ÊñºÁâπÂæµÊèêÂèñÂíåË®ìÁ∑¥„ÄÇÊ©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÁî®ÊñºË®ìÁ∑¥Ê®°Âûã„ÄÇBERT Ê®°ÂûãÂëàÁèæÂá∫ÊúÄÊúâÂ∏åÊúõÁöÑÁµêÊûúÔºåÈÅîÂà∞ 0.96 ÁöÑÊï¥È´îÊ∫ñÁ¢∫Â∫¶„ÄÇ

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠¶‰π†Ê≠£Â§ßÂπÖËΩâËÆäÈÜ´Â≠∏ÂΩ±ÂÉèÂíåÊîæÂ∞ÑÁ∑öÂ≠∏È†òÂüüÔºåËÉΩËæ®Ë≠òÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÁöÑÁóÖÁêÜÔºåÂåÖÊã¨ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèè (CT) Âíå X ÂÖâÊéÉÊèè„ÄÇÁÑ∂ËÄåÔºåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÊïàËÉΩÔºåÁâπÂà•ÊòØÂú®ÂàÜÂâ≤‰ªªÂãô‰∏≠ÔºåÂ∏∏Â∏∏ÂèóÂà∞Âª£Ê≥õË®ªËß£Ë≥áÊñôÈõÜÈúÄÊ±ÇÁöÑÈôêÂà∂„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÊ≠§ÊåëÊà∞ÔºåÈÄèÈÅéÂèØËß£Èáã AI ÂíåÂèç‰∫ãÂØ¶Ëß£ÈáãÁöÑÁî¢ÁîüÔºåÊé¢Á¥¢Âº±Áõ£Áù£Ë™ûÊÑèÂàÜÂâ≤ÁöÑËÉΩÂäõ„ÄÇÊú¨Á†îÁ©∂ÁöÑÁØÑÂúçÊòØÈñãÁôº‰∏ÄÁ®ÆÊñ∞ÁöÑÂèç‰∫ãÂØ¶ÂÖßÊèíÊñπÊ≥ï (COIN)ÔºåË©≤ÊñπÊ≥ï‰ΩøÁî®ÁîüÊàêÊ®°ÂûãÂ∞áÈ†êÊ∏¨ÁöÑÂàÜÈ°ûÊ®ôÁ±§ÂæûÁï∞Â∏∏ÁøªËΩâÁÇ∫Ê≠£Â∏∏„ÄÇ‰æãÂ¶ÇÔºåÂ¶ÇÊûúÂàÜÈ°ûÂô®Â∞áËº∏ÂÖ•ÁöÑÈÜ´Â≠∏ÂΩ±ÂÉè X Ë¶ñÁÇ∫Áï∞Â∏∏ÔºåË°®Á§∫Â≠òÂú®ÁóÖÁêÜÔºåÂâáÁîüÊàêÊ®°ÂûãÊó®Âú®ÂÖßÊèíÁï∞Â∏∏ÂçÄÂüüÔºåÂæûËÄåÈÄÜËΩâÂàÜÈ°ûÂô®ÁöÑÂéüÂßãÈ†êÊ∏¨Ê®ôÁ±§„ÄÇÊ≠§ÊñπÊ≥ï‰ΩøÊàëÂÄëËÉΩÂ§†Áî¢ÁîüÁóÖÁêÜÁöÑÁ≤æÁ¢∫ÂàÜÂâ≤ÔºåËÄåÁÑ°ÈúÄ‰æùË≥¥ÊñºÈ†êÂÖàÂ≠òÂú®ÁöÑÂàÜÂâ≤ÈÅÆÁΩ©„ÄÇËá≥ÈóúÈáçË¶ÅÁöÑÊòØÔºåÂà©Áî®ÂΩ±ÂÉèÂ±§Á¥öÊ®ôÁ±§ÔºåÈÄôÊØîÂª∫Á´ãË©≥Á¥∞ÁöÑÂàÜÂâ≤ÈÅÆÁΩ©ÂÆπÊòìÂèñÂæó„ÄÇË©≤ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÈÄèÈÅéÂàÜÂâ≤ÂêàÊàêÁõÆÊ®ôÂíåÂæûÊÑõÊ≤ôÂ∞º‰∫ûÂ°îÁàæÂúñÂ§ßÂ≠∏ÈÜ´Èô¢ÂèñÂæóÁöÑ CT ÂΩ±ÂÉè‰∏≠ÁöÑÂØ¶ÈöõËÖéËáüËÖ´Áò§‰æÜË≠âÊòé„ÄÇÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåCOIN ÈÅ†ÈÅ†Ë∂ÖÈÅéÂ∑≤Âª∫Á´ãÁöÑÊ≠∏Âõ†ÊñπÊ≥ïÔºå‰æãÂ¶Ç RISE„ÄÅScoreCAM Âíå LayerCAMÔºå‰ª•Âèä Singla Á≠â‰∫∫ÊèêÂá∫ÁöÑÂè¶‰∏ÄÁ®ÆÂèç‰∫ãÂØ¶Ëß£ÈáãÊñπÊ≥ï„ÄÇÊ≠§Ë≠âÊìöË°®ÊòéÔºåCOIN ÊòØ‰∏ÄÁ®ÆÂæàÊúâÂâçÈÄîÁöÑ CT ÂΩ±ÂÉè‰∏≠ËÖ´Áò§Ë™ûÊÑèÂàÜÂâ≤ÊñπÊ≥ïÔºå‰∏¶Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ËÆìÊ∑±Â∫¶Â≠∏ÁøíÊáâÁî®Êõ¥ÊòìÊñºÂèñÂæóÂíåÊõ¥ÊúâÊïàÁéáÈÇÅÈÄ≤‰∏ÄÊ≠•ÔºåÂÖ∂‰∏≠Ë®ªËß£Ë≥áÊñôÂæàÁ®ÄÂ∞ë„ÄÇ

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÊï∏‰Ωç‰∫∫ÊñáÂ≠∏Áßë (DH) ‰ΩúÁÇ∫‰∏ÄÈñÄÂ≠∏ÁßëËàáÊ∑∑ÂêàÊô∫ËÉΩ (HI) ‰ΩúÁÇ∫‰∏ÄÂÄãÁ†îÁ©∂ÂÖ∏ÁØÑ‰πãÈñìÁöÑÂçîÂêå‰ΩúÁî®„ÄÇÂú® DH Á†îÁ©∂‰∏≠ÔºåÊï∏‰ΩçÊñπÊ≥ïÁöÑ‰ΩøÁî®ÔºåÁâπÂà•ÊòØ‰∫∫Â∑•Êô∫ÊÖßÁöÑ‰ΩøÁî®ÔºåÂèóÂà∞‰∏ÄÁ≥ªÂàóË¶ÅÊ±ÇÂíåÈôêÂà∂„ÄÇÊàëÂÄëË™çÁÇ∫ÈÄô‰∫õË¶ÅÊ±ÇÂíåÈôêÂà∂Áç≤Âæó HI ÁöÑËÉΩÂäõÂíåÁõÆÊ®ôÁöÑÂÖÖÂàÜÊîØÊåÅ„ÄÇÊàëÂÄëÁöÑË≤¢ÁçªÂåÖÊã¨ÊâæÂá∫‰∫îÂÄãÈÄôÊ®£ÁöÑ DH Ë¶ÅÊ±ÇÔºöÊàêÂäüÁöÑ AI Á≥ªÁµ±ÈúÄË¶ÅËÉΩÂ§† 1) ËàáÔºà‰∫∫È°ûÔºâÂ≠∏ËÄÖÂêà‰ΩúÔºõ2) ÊîØÊè¥Ë≥áÊñôÊâπË©ïÔºõ3) ÊîØÊè¥Â∑•ÂÖ∑ÊâπË©ïÔºõ4) ÂØüË¶∫‰∏¶ËøéÂêàÂêÑÁ®ÆËßÄÈªûÔºõ5) ÊîØÊè¥ÈÅ†Ë∑ùÂíåËøëË∑ùÈõ¢Èñ±ËÆÄ„ÄÇÊàëÂÄëÂ∞áÊ∑∑ÂêàÊô∫ËÉΩÁöÑ CARE ÂéüÂâáÔºàÂçî‰Ωú„ÄÅÈÅ©Êáâ„ÄÅË≤†Ë≤¨ÂíåÂèØËß£ÈáãÔºâ‰ΩúÁÇ∫ÁêÜË´ñÊû∂ÊßãÔºå‰∏¶Â∞áÈÄô‰∫õÂéüÂâáÂ∞çÊáâÂà∞ DH Ë¶ÅÊ±Ç„ÄÇÂú®Ê≠§Â∞çÊáâ‰∏≠ÔºåÊàëÂÄëÁ¥çÂÖ•ÁØÑ‰æãÁ†îÁ©∂Â∞àÊ°à„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊé¢Ë®éÂ¶Ç‰ΩïÂ∞á DH ÁöÑË¶ãËß£ÊáâÁî®Êñº HIÔºå‰∏¶Ë®éË´ñÁµêÂêàÈÄôÂÖ©ÂÄãÂ≠∏ÁßëÁöÑÈñãÊîæÊåëÊà∞„ÄÇ

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

ÊëòË¶ÅÔºöÂü∫Á§éÊ®°Âûã (FM) ÂÖ∑ÊúâÂæπÂ∫ïÊîπËÆäÈÜ´Â≠∏ÂΩ±ÂÉèÁöÑÂ∑®Â§ßÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÂú®ÁèæÂØ¶‰∏ñÁïåËá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÈÉ®ÁΩ≤ÈúÄË¶ÅÂª£Ê≥õÁöÑÂÄ´ÁêÜËÄÉÈáè„ÄÇÊú¨ÊñáÊó®Âú®Âº∑Ë™øËàá FM Áõ∏ÈóúÁöÑÂÄ´ÁêÜÂïèÈ°åÔºå‰∏¶ÊèêÂá∫‰∏ÄÂÄãÊ°ÜÊû∂‰æÜÊåáÂ∞éÂÆÉÂÄëÂú®ÈÜ´Â≠∏‰∏≠ÁöÑË≤†Ë≤¨‰ªªÈñãÁôºÂíåÂØ¶ÊñΩ„ÄÇÊàëÂÄë‰ªîÁ¥∞ÂØ©Êü•‰∫ÜÂÄ´ÁêÜÂïèÈ°åÔºå‰æãÂ¶ÇÊÇ£ËÄÖÊï∏ÊìöÈö±ÁßÅ„ÄÅÂÅèÂ∑ÆÁ∑©Ëß£„ÄÅÊºîÁÆóÊ≥ïÈÄèÊòéÂ∫¶„ÄÅÂèØËß£ÈáãÊÄßÂíåÂïèË≤¨Âà∂„ÄÇÊâÄÊèêÂá∫ÁöÑÊ°ÜÊû∂Êó®Âú®ÂÑ™ÂÖàËÄÉÊÖÆÊÇ£ËÄÖÁ¶èÂà©„ÄÅÊ∏õËºïÊΩõÂú®È¢®Èö™Ôºå‰∏¶ÂüπÈ§äÂ∞ç AI ËºîÂä©ÈÜ´ÁôÇ‰øùÂÅ•ÁöÑ‰ø°‰ªª„ÄÇ

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

ÊëòË¶ÅÔºöÁî≤ÁãÄËÖ∫ÁôåÊòØ‰∏ÄÁ®ÆÊó•ÁõäÂö¥ÈáçÁöÑÂÖ®ÁêÉÂÅ•Â∫∑ÂïèÈ°åÔºåÈúÄË¶ÅÂÖàÈÄ≤ÁöÑË®∫Êñ∑ÊñπÊ≥ï„ÄÇÊú¨ÁØáË©ïË´ñÊé¢Ë®é‰∫Ü‰∫∫Â∑•Êô∫ËÉΩËàáÊîæÂ∞ÑÁâπÂæµÂàÜÊûêÂú®Áî≤ÁãÄËÖ∫ÁôåË®∫Êñ∑‰∏≠ÁöÑÊáâÁî®„ÄÇÂú®Á¨¶Âêà PRISMA ÊåáÂçóÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂ∞çÂ§öÂÄãË≥áÊñôÂ∫´ÈÄ≤Ë°å‰∫ÜÂõûÈ°ßÔºåÁõ¥Âà∞ 2023 Âπ¥ 10 Êúà„ÄÇÈÄöÈÅéÁµêÂêàÈóúÈçµÂ≠óÔºåÁôºÁèæ‰∫Ü‰∏ÄÁØáÈóúÊñºÁî≤ÁãÄËÖ∫ÁôåÂíåÁõ∏Èóú‰∏ªÈ°åÁöÑËã±ÊñáÂ≠∏Ë°ìÂá∫ÁâàÁâ©„ÄÇÂú®ÁßªÈô§ 109 ÁØáÈáçË§áÊñáÁçªÂæåÔºåÂéüÂßãÊêúÂ∞ãÂÖ±ÂõûÂÇ≥ 267 ÁØáË´ñÊñá„ÄÇÂú®Ê†πÊìöÈ†êÂÖàÁ¢∫ÂÆöÁöÑÊ®ôÊ∫ñÔºåÊ∑òÊ±∞‰∫Ü 124 ÁØáÊñáÁ´†ÁöÑÊëòË¶ÅÂíåÊ®ôÈ°åÂæåÔºåÈÅ∏Âá∫‰∫ÜÁõ∏ÈóúÁ†îÁ©∂„ÄÇÂú®ÈÄ≤Ë°åÂÖ®Èù¢ÂàÜÊûêÂæåÔºåÈ°çÂ§ñÊéíÈô§‰∫ÜÂÖ≠È†ÖÁ†îÁ©∂„ÄÇÂú®Á¥çÂÖ•ÁöÑ 28 È†ÖÁ†îÁ©∂‰∏≠ÔºåÁµêÂêàË∂ÖÈü≥Ê≥¢ (US) ÂΩ±ÂÉèÁöÑÊîæÂ∞ÑÁâπÂæµÂàÜÊûêÔºåË≠âÊòé‰∫ÜÂÖ∂Âú®Ë®∫Êñ∑Áî≤ÁãÄËÖ∫ÁôåÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÁ†îÁ©∂ÁµêÊûú‰∏ç‰∏ÄÔºåÊúâ‰∫õÁ†îÁ©∂ÊèêÂá∫‰∫ÜÂÑ™ÊñºÁèæÁãÄÁöÑÊñ∞Á≠ñÁï•„ÄÇÊñáÁçªÂº∑Ë™ø‰∫Ü‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÈù¢Ëá®ÁöÑÂêÑÁ®ÆÊåëÊà∞ÔºåÂåÖÊã¨ÂèØËß£ÈáãÊÄßÂïèÈ°å„ÄÅË≥áÊñôÈõÜÈôêÂà∂ÂíåÊìç‰ΩúÂì°‰æùË≥¥ÊÄß„ÄÇ28 È†ÖÁ¥çÂÖ•Á†îÁ©∂ÁöÑÁ∂úÂêàÁôºÁèæÊèêÂà∞ÔºåÈúÄË¶ÅÊ®ôÊ∫ñÂåñÂ∑•‰ΩúÂíåÂâçÁûªÊÄßÂ§ö‰∏≠ÂøÉÁ†îÁ©∂‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°å„ÄÇÊ≠§Â§ñÔºåÈÇÑÁ¢∫ÂÆö‰∫ÜÂÖãÊúçÈÄô‰∫õÈöúÁ§ôÁöÑÊñπÊ≥ïÔºå‰æãÂ¶ÇÂèØËß£Èáã‰∫∫Â∑•Êô∫ËÉΩÊäÄË°ìÂíåÂÄã‰∫∫ÂåñÈÜ´ÁôÇÊäÄË°ìÁöÑÈÄ≤Ê≠•„ÄÇÊú¨ÁØáË©ïË´ñÈáçÈªûÊé¢Ë®é‰∫Ü‰∫∫Â∑•Êô∫ËÉΩÂíåÊîæÂ∞ÑÁâπÂæµÂàÜÊûêÂ¶Ç‰ΩïËΩâËÆäÁî≤ÁãÄËÖ∫ÁôåÁöÑË®∫Êñ∑ÂíåÊ≤ªÁôÇ„ÄÇÂÑòÁÆ°Â≠òÂú®ÊåëÊà∞Ôºå‰ΩÜÊú™‰æÜÂ∞çÂ§öÂ≠∏ÁßëÂêà‰Ωú„ÄÅËá®Â∫äÈÅ©Áî®ÊÄßÈ©óË≠âÂíåÊºîÁÆóÊ≥ïÊîπÈÄ≤ÁöÑÁ†îÁ©∂Ôºå‰ªçÊúâÊΩõÂäõÊîπÂñÑÁî≤ÁãÄËÖ∫ÁôåÊ≤ªÁôÇ‰∏≠ÁöÑÊÇ£ËÄÖÈ†êÂæåÂíåË®∫Êñ∑Á≤æÊ∫ñÂ∫¶„ÄÇ

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

ÊëòË¶ÅÔºö<paragraph>ËøëÂπ¥‰æÜÔºå‰π≥ÁôåÁöÑÁõõË°åÁéáËøÖÈÄüÂ¢ûÂä†Ôºå‰ΩøÂÖ∂ÊàêÁÇ∫ÂÖ®ÁêÉ‰∏ªË¶ÅÁöÑÊ≠ª‰∫°ÂéüÂõ†‰πã‰∏Ä„ÄÇÂú®ÊâÄÊúâÁôåÁóá‰∏≠Ôºå‰π≥ÁôåËøÑ‰ªäÁÇ∫Ê≠¢ÊòØÊúÄÂ∏∏Ë¶ãÁöÑ„ÄÇÊâãÂãïË®∫Êñ∑Ê≠§ÁñæÁóÖÈúÄË¶ÅÂ§ßÈáèÁöÑÊôÇÈñìÂíåÂ∞àÊ•≠Áü•Ë≠ò„ÄÇÁî±Êñº‰π≥ÁôåÁöÑÊ™¢Ê∏¨ÈÅéÁ®ãËÄóÊôÇÔºåÂõ†Ê≠§ÈÄèÈÅéÂª∫Á´ãÊ©üÂô®Â≠∏ÁøíÊ®°Âûã‰æÜÈ†êÊ∏¨ÔºåÊúâÂä©ÊñºÈò≤Ê≠¢ÂÖ∂ÈÄ≤‰∏ÄÊ≠•Êì¥Êï£„ÄÇÊ©üÂô®Â≠∏ÁøíÂíåÂèØËß£Èáã AI Âú®ÂàÜÈ°û‰∏≠Ëá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫ÂÆÉÂÄë‰∏çÂÉÖÂèØ‰ª•Êèê‰æõÊ∫ñÁ¢∫ÁöÑÈ†êÊ∏¨ÔºåÈÇÑÂèØ‰ª•Ê∑±ÂÖ•‰∫ÜËß£Ê®°ÂûãÂ¶Ç‰ΩïÂÅöÂá∫Ê±∫Á≠ñÔºåÊúâÂä©ÊñºÁêÜËß£Âíå‰ø°Ë≥¥ÂàÜÈ°ûÁµêÊûú„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëË©ï‰º∞‰∏¶ÊØîËºÉ‰∫Ü‰∫îÁ®Æ‰∏çÂêåÁöÑÊ©üÂô®Â≠∏ÁøíÊñπÊ≥ïÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶„ÄÅÁ≤æÁ¢∫Â∫¶„ÄÅÂè¨ÂõûÁéáÂíå F1 ÂàÜÊï∏Ôºå‰ΩøÁî®‰∫Ü‰∏ÄÂÄã‰∏ªË¶ÅÁöÑË≥áÊñôÈõÜÔºàÈÅîÂç°ÈÜ´Â≠∏Èô¢ÈÜ´Èô¢ÁöÑ 500 ÂêçÊÇ£ËÄÖÔºâ„ÄÇ‰∫îÁ®Æ‰∏çÂêåÁöÑÁõ£Áù£ÂºèÊ©üÂô®Â≠∏ÁøíÊäÄË°ìÔºåÂåÖÊã¨Ê±∫Á≠ñÊ®π„ÄÅÈö®Ê©üÊ£ÆÊûó„ÄÅÈÇèËºØËø¥Ê≠∏„ÄÅÊú¥Á¥†Ë≤ùÊ∞èÂíå XGBoostÔºåÂ∑≤Áî®ÊñºÂú®ÊàëÂÄëÁöÑË≥áÊñôÈõÜ‰∏äÂèñÂæóÊúÄ‰Ω≥ÁµêÊûú„ÄÇÊ≠§Â§ñÔºåÊú¨Á†îÁ©∂Â∞á SHAP ÂàÜÊûêÊáâÁî®Êñº XGBoost Ê®°ÂûãÔºå‰ª•Ëß£ÈáãÊ®°ÂûãÁöÑÈ†êÊ∏¨‰∏¶‰∫ÜËß£ÊØèÂÄãÁâπÂæµÂ∞çÊ®°ÂûãËº∏Âá∫ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÊØîËºÉ‰∫ÜÂπæÁ®ÆÊºîÁÆóÊ≥ïÂ∞çË≥áÊñôÈÄ≤Ë°åÂàÜÈ°ûÁöÑÊ∫ñÁ¢∫Â∫¶Ôºå‰∏¶ËàáË©≤È†òÂüüÁöÑÂÖ∂‰ªñÊñáÁçªÈÄ≤Ë°åÂ∞çÊØî„ÄÇÂú®ÊúÄÂæåË©ï‰º∞ÂæåÔºåÊú¨Á†îÁ©∂ÁôºÁèæ XGBoost ÈÅîÂà∞‰∫ÜÊúÄ‰Ω≥ÁöÑÊ®°ÂûãÊ∫ñÁ¢∫Â∫¶ÔºåÁÇ∫ 97%„ÄÇ</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏Áøí (DL) Áî®ÊñºÂæû‰π≥ÊàøÊîùÂΩ±Ë°ìÂΩ±ÂÉèË®∫Êñ∑‰π≥ÁôåÁöÑÊ®°ÂûãÈÄöÂ∏∏‰ª•„ÄåÈªëÁõíÂ≠ê„ÄçÊñπÂºèÈÅã‰ΩúÔºåÈÄô‰ΩøÂæóÈÜ´ÁôÇ‰øùÂÅ•Â∞àÊ•≠‰∫∫Âì°Èõ£‰ª•‰ø°‰ªªÂíåÁêÜËß£ÂÖ∂Ê±∫Á≠ñÈÅéÁ®ã„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÊï¥ÂêàÊû∂ÊßãÔºåÁµêÂêàÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÂíåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI)Ôºå‰ª•‰ΩøÁî® CBIS-DDSM Ë≥áÊñôÈõÜÂ¢ûÂº∑‰π≥ÁôåÁöÑË®∫Êñ∑„ÄÇÊñπÊ≥ïÂåÖÂê´‰∏ÄÂÄãÁ≤æÁ¥∞ÁöÑË≥áÊñôÂâçËôïÁêÜÁÆ°Á∑öÂíåÈÄ≤ÈöéË≥áÊñôÊì¥ÂÖÖÊäÄË°ìÔºå‰ª•Â∞çÊäóË≥áÊñôÈõÜÈôêÂà∂Ôºå‰∏¶Êé°Áî®È†êÂÖàË®ìÁ∑¥ÁöÑÁ∂≤Ë∑ØÔºà‰æãÂ¶Ç VGG-16„ÄÅInception-V3 Âíå ResNetÔºâÈÄ≤Ë°åÈÅ∑ÁßªÂ≠∏Áøí„ÄÇÊàëÂÄëÁ†îÁ©∂ÁöÑÈáçÈªûÊòØË©ï‰º∞ XAI Âú®Ëß£ÈáãÊ®°ÂûãÈ†êÊ∏¨‰∏≠ÁöÑÊúâÊïàÊÄßÔºåÈáçÈªûÂà©Áî®Ë±™ÊñØÂ§öÂ§´Ê∏¨Â∫¶ÈáèÂåñË©ï‰º∞ AI ÁîüÊàêÁöÑËß£ÈáãÂíåÂ∞àÂÆ∂Ë®ªËß£‰πãÈñìÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂ∞çÊñº XAI Âú®‰øÉÈÄ≤ AI ËºîÂä©Ë®∫Êñ∑‰∏≠ÁöÑÂèØ‰ø°Â∫¶ÂíåÂÄ´ÁêÜÂÖ¨Âπ≥ÊÄßËá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÁ†îÁ©∂ÁöÑÁôºÁèæË™™Êòé‰∫Ü CNN Âíå XAI Âú®Êé®ÈÄ≤‰π≥ÁôåË®∫Êñ∑ÊñπÊ≥ï‰∏≠ÁöÑÊúâÊïàÂçî‰ΩúÔºåÂæûËÄå‰øÉÈÄ≤‰∫ÜÂÖàÈÄ≤ AI ÊäÄË°ìÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊõ¥È†ÜÊö¢Êï¥Âêà„ÄÇÈÄèÈÅéÂ¢ûÂº∑ AI È©ÖÂãïÊ±∫Á≠ñÁöÑÂèØËß£ÈáãÊÄßÔºåÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫ AI Á≥ªÁµ±ÂíåÈÜ´ÁôÇÂæûÊ•≠‰∫∫Âì°‰πãÈñìÁöÑÊîπÂñÑÂçî‰ΩúÂ•†ÂÆö‰∫ÜÂü∫Á§éÔºåÊúÄÁµÇË±êÂØå‰∫ÜÊÇ£ËÄÖÁÖßË≠∑„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁ†îÁ©∂ÁöÑÂΩ±ÈüøÈÅ†ÈÅ†Ë∂ÖÂá∫‰∫ÜÁõÆÂâçÁöÑÊäÄË°ì„ÄÇÂÆÉÈºìÂãµÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂Â¶Ç‰ΩïÁµêÂêàÂ§öÊ®°ÂºèË≥áÊñô‰∏¶ÊîπÂñÑ AI Ëß£ÈáãÔºå‰ª•ÊªøË∂≥Ëá®Â∫äÂØ¶ÂãôÁöÑÈúÄÊ±Ç„ÄÇ

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÂ§öÊ®°ÊÖãÊï∏ÊìöËûçÂêàÊñπÊ≥ïÔºåÁî®ÊñºÁñºÁóõË°åÁÇ∫Ë≠òÂà•ÔºåÂ∞áÁµ±Ë®àÁõ∏ÈóúÂàÜÊûêËàá‰ª•‰∫∫ÁÇ∫‰∏≠ÂøÉÁöÑË¶ãËß£Áõ∏ÁµêÂêà„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂºïÂÖ•‰∫ÜÂÖ©È†ÖÈóúÈçµÂâµÊñ∞Ôºö1) Â∞áÊï∏ÊìöÈ©ÖÂãïÁöÑÁµ±Ë®àÁõ∏ÈóúÊ¨äÈáçÊï¥ÂêàÂà∞ËûçÂêàÁ≠ñÁï•‰∏≠Ôºå‰ª•ÊúâÊïàÂà©Áî®‰æÜËá™Áï∞Ë≥™Ê®°ÊÖãÁöÑË£úÂÖÖ‰ø°ÊÅØÔºå‰ª•Âèä 2) Â∞á‰ª•‰∫∫ÁÇ∫‰∏≠ÂøÉÁöÑÈÅãÂãïÁâπÂæµÁ¥çÂÖ•Â§öÊ®°ÊÖãË°®Á§∫Â≠∏Áøí‰∏≠Ôºå‰ª•Ë©≥Á¥∞Âª∫Ê®°ÁñºÁóõË°åÁÇ∫„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÂêÑÁ®ÆÊ∑±Â∫¶Â≠∏ÁøíÊû∂Êßã‰∏≠ÂæóÂà∞È©óË≠âÔºåÂ±ïÁ§∫‰∫ÜÂçìË∂äÁöÑÊÄßËÉΩÂíåÂª£Ê≥õÁöÑÈÅ©Áî®ÊÄß„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂèØËá™ÂÆöÁæ©ÁöÑÊ°ÜÊû∂ÔºåÊ†πÊìöÁµ±Ë®àÈ°ØËëóÊÄßÂ∞áÊØèÂÄãÊ®°ÊÖãËàáÂêàÈÅ©ÁöÑÂàÜÈ°ûÂô®Â∞çÈΩäÔºåÊé®ÈÄ≤ÂÄãÊÄßÂåñÂíåÊúâÊïàÁöÑÂ§öÊ®°ÊÖãËûçÂêà„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊ®°ÂûãÊèê‰æõÂ∞çÂ§öÊ®°ÊÖãÊï∏ÊìöÁöÑÂèØËß£ÈáãÂàÜÊûêÔºåÊúâÂä©ÊñºÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÂèØËß£ÈáãÂíåÂèØËß£Èáã AI„ÄÇÈÄöÈÅéÂº∑Ë™øÊï∏ÊìöÂ§öÊ®£ÊÄßÂíåÊ®°ÊÖãÁâπÂÆöË°®Á§∫ÁöÑÈáçË¶ÅÊÄßÔºåÊàëÂÄëÂ¢ûÂº∑‰∫ÜÂÇ≥Áµ±ÁöÑËûçÂêàÊäÄË°ìÔºå‰∏¶ÁÇ∫Ë≠òÂà•Ë§áÈõúÁöÑÁñºÁóõË°åÁÇ∫Ë®≠ÂÆö‰∫ÜÊñ∞ÁöÑÊ®ôÊ∫ñ„ÄÇÊàëÂÄëÁöÑÁôºÁèæÂ∞ç‰øÉÈÄ≤‰ª•ÊÇ£ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑÈÜ´ÁôÇ‰øùÂÅ•Âπ≤È†êÂíåÊîØÊåÅÂèØËß£ÈáãÁöÑËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÂÖ∑ÊúâÈáçË¶ÅÊÑèÁæ©„ÄÇ

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

ÊëòË¶ÅÔºö‰ª•‰∫∫‰∏∫Êú¨ÁöÑÂèØËß£Èáä AI (HCXAI) ÂÄ°ÂØºÂ∞ÜÁ§æ‰ºöÂ±ÇÈù¢Êï¥ÂêàÂà∞ AI Ëß£Èáä‰∏≠„ÄÇHCXAI ËØùËØ≠ÁöÑÊ†∏ÂøÉÊòØÁ§æ‰ºöÈÄèÊòéÂ∫¶ (ST) Ê°ÜÊû∂ÔºåÂÖ∂ÁõÆÊ†áÊòØËÆ© AI Á≥ªÁªüÁöÑÁ§æ‰ºöÁªÑÁªáËÉåÊôØÂØπÁî®Êà∑Êù•ËØ¥ÊòØÂèØÁêÜËß£ÁöÑ„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨Âª∫ËÆÆÊâ©Â±ï ST Ê°ÜÊû∂‰ª•Ëß£ÂÜ≥Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ‰∏≠Á§æ‰ºöÈîôËØØÂΩíÂõ†ÁöÑÈ£éÈô©ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂøÉÁêÜÂÅ•Â∫∑Á≠âÊïèÊÑüÈ¢ÜÂüü„ÄÇ‰∫ãÂÆû‰∏äÔºåLLM ËÉΩÂ§üÂá∫Ëâ≤Âú∞Ê®°ÊãüËßíËâ≤Âíå‰∫∫Ê†ºÔºåËøôÂèØËÉΩÂØºËá¥ËÆæËÆ°ËÄÖÁöÑÊÑèÂõæÂíåÁî®Êà∑ÂØπÁ§æ‰ºöÂ±ûÊÄßÁöÑËÆ§Áü•‰πãÈó¥Âá∫Áé∞ÈîôÈÖçÔºå‰ªéËÄåÊúâÈ£éÈô©‰øÉËøõÊÉÖÁª™ÊìçÁ∫µÂíåÂç±Èô©Ë°å‰∏∫„ÄÅËÆ§Áü•‰∏çÂÖ¨Ê≠£Âíå‰∏çÂêàÁêÜÁöÑ‰ø°‰ªª„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊàë‰ª¨Âª∫ËÆÆÁî®Á¨¨‰∫î‰∏™‚ÄúW ÈóÆÈ¢ò‚ÄùÊù•Â¢ûÂº∫ ST Ê°ÜÊû∂Ôºå‰ª•ÊòéÁ°ÆËÆæËÆ°ËÄÖÂíåÁî®Êà∑Ëµã‰∫à LLM ÁöÑÂÖ∑‰ΩìÁ§æ‰ºöÂ±ûÊÄß„ÄÇÊ≠§Ë°•ÂÖÖÊó®Âú®Âº•Âêà LLM ËÉΩÂäõÂíåÁî®Êà∑ËÆ§Áü•‰πãÈó¥ÁöÑÂ∑ÆË∑ùÔºå‰øÉËøõÂü∫‰∫é LLM ÁöÑÊäÄÊúØÂú®ÈÅìÂæ∑‰∏äË¥üË¥£‰ªªÂú∞ÂºÄÂèëÂíå‰ΩøÁî®„ÄÇ

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

ÊëòË¶ÅÔºö<paragraph>ËÉåÊôØÔºöÊ∞£ËÉ∏ÊòØ‰∏ÄÁ®ÆÂõ†ËÇ∫ÈÉ®ËàáËÉ∏Â£Å‰πãÈñìÁï∞Â∏∏ÈõÜÊ∞£ÊâÄÂºïËµ∑ÁöÑÊÄ•ÊÄßËÉ∏ËÖîÁñæÁóÖ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê∑±Â∫¶Â≠∏ÁøíÔºàDLÔºâÊ®°ÂûãÁ∂ìÂ∏∏‰º¥Èö®ÁöÑ‰∏çÈÄèÊòéÊÄßÔºåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖßÔºàXAIÔºâÊñπÊ≥ïÂ∑≤Ë¢´ÂºïÂÖ•ÔºåÁî®ÊñºÊ¶ÇËø∞Ëàá DL Ê®°ÂûãÂÅöÂá∫ÁöÑÊ∞£ËÉ∏Ë®∫Êñ∑Áõ∏ÈóúÁöÑÂçÄÂüü„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õËß£ÈáãÊúâÊôÇÊúÉËàáÂØ¶ÈöõÁóÖÁÅ∂ÂçÄÂüüÊúâÊâÄÂá∫ÂÖ•ÔºåÁ™ÅÈ°ØÂá∫ÈÄ≤‰∏ÄÊ≠•ÊîπÈÄ≤ÁöÑÂøÖË¶ÅÊÄß„ÄÇÊñπÊ≥ïÔºöÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊ®°ÊùøÂºïÂ∞éÂºèÊñπÊ≥ïÔºåÂ∞áÊ∞£ËÉ∏ÁöÑËá®Â∫äÁü•Ë≠òÁ¥çÂÖ• XAI ÊñπÊ≥ïÁî¢ÁîüÁöÑÊ®°ÂûãËß£Èáã‰∏≠ÔºåÂæûËÄåÊèêÂçáÈÄô‰∫õËß£ÈáãÁöÑÂìÅË≥™„ÄÇÂà©Áî®ÊîæÂ∞ÑÁßëÈÜ´Â∏´Âª∫Á´ãÁöÑÁóÖÁÅ∂ÊèèÁπ™ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÈ¶ñÂÖàÁî¢Áîü‰∏ÄÂÄãÊ®°ÊùøÔºåÁî®ÊñºË°®Á§∫Ê∞£ËÉ∏ÂèØËÉΩÁôºÁîüÁöÑÂçÄÂüü„ÄÇÁÑ∂ÂæåÂ∞áÊ≠§Ê®°ÊùøÁñäÂä†Âú®Ê®°ÂûãËß£Èáã‰∏äÔºå‰ª•ÁØ©ÈÅ∏Âá∫Ë∂ÖÂá∫Ê®°ÊùøÈÇäÁïåÁöÑÁÑ°ÈóúËß£Èáã„ÄÇÁÇ∫‰∫ÜÈ©óË≠âÂÖ∂ÊïàÂäõÔºåÊàëÂÄëÂ∞ç‰∏âÁ®Æ XAI ÊñπÊ≥ïÈÄ≤Ë°å‰∫ÜÊØîËºÉÂàÜÊûêÔºåÂú®ÂÖ©ÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏≠Ëß£ÈáãÂÖ©ÂÄã DL Ê®°ÂûãÊôÇÔºåÂàÜÂà•Êé°Áî®Âíå‰∏çÊé°Áî®ÊàëÂÄëÁöÑÊ®°ÊùøÂºïÂ∞é„ÄÇÁµêÊûúÔºöÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®Âª∫Á´ãÊñº‰∏âÁ®Æ XAI ÊñπÊ≥ï„ÄÅÂÖ©ÂÄã DL Ê®°ÂûãÂíåÂÖ©ÂÄãË≥áÊñôÈõÜÁöÑÂçÅ‰∫åÁ®ÆÂü∫Ê∫ñÊÉÖÂ¢É‰∏≠ÔºåÂßãÁµÇÊîπÂñÑ‰∫ÜÂü∫Ê∫ñ XAI ÊñπÊ≥ï„ÄÇÂú®ÊØîËºÉÊ®°ÂûãËß£ÈáãÂíåÁúüÂØ¶ÁóÖÁÅ∂ÂçÄÂüüÊôÇÔºåÈÄèÈÅéÂü∫Ê∫ñÊïàËÉΩÁöÑÊïàËÉΩÊîπÈÄ≤Ë®àÁÆóÂá∫ÁöÑÂπ≥ÂùáÂ¢ûÈáèÁôæÂàÜÊØîÁÇ∫‰∫§ÈõÜÊØîÔºàIoUÔºâÁöÑ 97.8% ÂíåÈ™∞Â≠êÁõ∏‰ººÊÄß‰øÇÊï∏ÔºàDSCÔºâÁöÑ 94.1%„ÄÇÁµêË´ñÔºöÂú®Ê∞£ËÉ∏Ë®∫Êñ∑ÁöÑËÉåÊôØ‰∏ãÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊ®°ÊùøÂºïÂ∞éÂºèÊñπÊ≥ïÔºåÁî®ÊñºÊîπÂñÑ AI Ëß£Èáã„ÄÇÊàëÂÄëÈ†êÊúüÊàëÂÄëÁöÑÊ®°ÊùøÂºïÂ∞éÂ∞áÈÄèÈÅéÊï¥ÂêàËá®Â∫äÈ†òÂüüÂ∞àÊ•≠Áü•Ë≠òÔºåÁÇ∫Èó°Êòé AI Ê®°ÂûãÂª∫Á´ã‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ï„ÄÇ</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by S√©amus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

ÊëòË¶ÅÔºö<paragraph>Âú®Áï∂ÂâçÊ©üÂô®ÁøªË≠Ø (MT) È†òÂüü‰∏≠ÔºåTransformer Êû∂ÊßãËÑ´Á©éËÄåÂá∫ÔºåÊàêÁÇ∫ÈªÉÈáëÊ®ôÊ∫ñÔºåÁâπÂà•ÊòØÂ∞çÊñºÈ´òË≥áÊ∫êË™ûË®ÄÂ∞ç„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®éÂÖ∂Â∞ç‰ΩéË≥áÊ∫êË™ûË®ÄÂ∞çÁöÑÊïàËÉΩÔºåÂåÖÊã¨Ëã±Ë™û‚ÜîÊÑõÁàæËò≠Ë™ûÂíåËã±Ë™û‚ÜîÈ¶¨ÊãâÂú∞Ë™ûË™ûË®ÄÂ∞ç„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊú¨Á†îÁ©∂Ë≠òÂà•Âá∫ÊúÄ‰Ω≥Ë∂ÖÂèÉÊï∏ÂíåÂ≠êË©ûÊ®°ÂûãÈ°ûÂûãÔºå‰ª•È°ØËëóÊèêÈ´ò Transformer Ê®°ÂûãÂ∞ç‰ΩéË≥áÊ∫êË™ûË®ÄÂ∞çÁöÑÁøªË≠ØÂìÅË≥™„ÄÇ
‰ΩéË≥áÊ∫êË™ûË®ÄÁöÑÂπ≥Ë°åË≥áÊñôÈõÜÁöÑÁ®ÄÁº∫ÊúÉÈòªÁ§ô MT ÁöÑÁôºÂ±ï„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÈñãÁôº‰∫Ü gaHealthÔºåÈÄôÊòØÊÑõÁàæËò≠Ë™ûÁöÑÁ¨¨‰∏ÄÂÄãÈõôË™ûÂÅ•Â∫∑Ë≥áÊñôË™ûÊñôÂ∫´„ÄÇÂ∞àÊ≥®ÊñºÂÅ•Â∫∑È†òÂüüÔºå‰ΩøÁî®Ê≠§ÂüüÂÖßË≥áÊñôÈõÜÈñãÁôºÁöÑÊ®°ÂûãÂú® BLEU ÂæóÂàÜÊñπÈù¢Ë°®ÁèæÂá∫ÈùûÂ∏∏È°ØËëóÁöÑÈÄ≤Ê≠•ÔºåËàá LoResMT2021 ÂÖ±‰∫´‰ªªÂãô‰∏≠ÁöÑÊ®°ÂûãÁõ∏ÊØî„ÄÇÈö®Âæå‰ΩøÁî®Â§öÁ∂≠ÂìÅË≥™ÊåáÊ®ôÈåØË™§ÂàÜÈ°ûÊ≥ïÈÄ≤Ë°åÁöÑ‰∫∫Â∑•Ë©ï‰º∞È°ØÁ§∫ÔºåËàáÂü∫Êñº RNN ÁöÑÂ∞çÊáâÊ®°ÂûãÁõ∏ÊØîÔºåTransformer Á≥ªÁµ±Âú®Ê∏õÂ∞ëÊ∫ñÁ¢∫ÊÄßÂíåÊµÅÊö¢ÊÄßÈåØË™§ÊñπÈù¢Ë°®ÁèæÂá∫ÂÑ™Áï∞ÁöÑÊÄßËÉΩ„ÄÇ
Ê≠§Â§ñÔºåÊú¨Ë´ñÊñá‰ªãÁ¥π‰∫Ü adaptNMT Âíå adaptMLLMÔºåÈÄôÂÖ©ÂÄãÈñãÊ∫êÊáâÁî®Á®ãÂºèÁ∞°Âåñ‰∫ÜÁ•ûÁ∂ìÊ©üÂô®ÁøªË≠ØÊ®°ÂûãÁöÑÈñãÁôº„ÄÅÂæÆË™øÂíåÈÉ®ÁΩ≤„ÄÇÈÄô‰∫õÂ∑•ÂÖ∑Â§ßÂπÖÁ∞°Âåñ‰∫ÜË®≠ÂÆöÂíåË©ï‰º∞ÊµÅÁ®ãÔºåËÆì MT Êõ¥ÂÆπÊòìËÆìÈñãÁôº‰∫∫Âì°ÂíåÁøªË≠Ø‰∫∫Âì°‰ΩøÁî®„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåadaptNMT ‰ª• OpenNMT ÁîüÊÖãÁ≥ªÁµ±ÁÇ∫Âü∫Á§éÔºåÈÄöÈÅéÂº∑Ë™øÊ®°ÂûãÈñãÁôºÁöÑÁí∞Â¢ÉË∂≥Ë∑°‰æÜ‰øÉÈÄ≤ÁîüÊÖãÂèãÂ•ΩÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁ†îÁ©∂„ÄÇËàá LoResMT2021 ÂÖ±‰∫´‰ªªÂãô‰∏≠ÁöÑÂü∫Ê∫ñÁõ∏ÊØîÔºåadaptMLLM Â∞ç MLLM ÁöÑÂæÆË™øË≠âÊòé‰∫ÜËã±Ë™û‚ÜîÊÑõÁàæËò≠Ë™ûÂíåËã±Ë™û‚ÜîÈ¶¨ÊãâÂú∞Ë™ûÈÄôÂÖ©ÂÄã‰ΩéË≥áÊ∫êË™ûË®ÄÂ∞çÁöÑÁøªË≠ØÊÄßËÉΩÈÄ≤Ê≠•„ÄÇ</paragraph>

##### **Cause and Effect: Can Large Language Models Truly Understand Causality?**
2402.18139v3 by Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Mayank Jindal, Dushyant Singh Sengar, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, Aman Chadha

With the rise of Large Language Models(LLMs), it has become crucial to
understand their capabilities and limitations in deciphering and explaining the
complex web of causal relationships that language entails. Current methods use
either explicit or implicit causal reasoning, yet there is a strong need for a
unified approach combining both to tackle a wide array of causal relationships
more effectively. This research proposes a novel architecture called Context
Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to
enhance causal reasoning and explainability. The proposed framework
incorporates an explicit causal detection module with ConceptNet and
counterfactual statements, as well as implicit causal detection through LLMs.
Our framework goes one step further with a layer of counterfactual explanations
to accentuate LLMs understanding of causality. The knowledge from ConceptNet
enhances the performance of multiple causal reasoning tasks such as causal
discovery, causal identification and counterfactual reasoning. The
counterfactual sentences add explicit knowledge of the not caused by scenarios.
By combining these powerful modules, our model aims to provide a deeper
understanding of causal relationships, enabling enhanced interpretability.
Evaluation of benchmark datasets shows improved performance across all metrics,
such as accuracy, precision, recall, and F1 scores. We also introduce
CausalNet, a new dataset accompanied by our code, to facilitate further
research in this domain.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËààËµ∑Ôºå‰∫ÜËß£ÂÆÉÂÄëÂú®Ëß£Á¢ºÂíåËß£ÈáãË™ûË®ÄÊâÄËòäÂê´ÁöÑË§áÈõúÂõ†ÊûúÈóú‰øÇÁ∂≤Ë∑Ø‰∏≠ÁöÑËÉΩÂäõÂíåÈôêÂà∂ËÆäÂæóËá≥ÈóúÈáçË¶Å„ÄÇÁõÆÂâçÁöÑÊäÄË°ì‰ΩøÁî®ÊòéÁ¢∫ÊàñÈö±Âê´ÁöÑÂõ†ÊûúÊé®ÁêÜÔºå‰ΩÜÂº∑ÁÉàÈúÄË¶Å‰∏ÄÁ®ÆÁµ±‰∏ÄÁöÑÊñπÊ≥ïÔºåÁµêÂêàÂÖ©ËÄÖ‰ª•Êõ¥ÊúâÊïàÂú∞ËôïÁêÜÂª£Ê≥õÁöÑÂõ†ÊûúÈóú‰øÇ„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫ÊÉÖÂ¢ÉÊÑüÁü•Êé®ÁêÜÂ¢ûÂº∑ËàáÂèç‰∫ãÂØ¶ÂàÜÊûê (CARE CA) Ê°ÜÊû∂ÁöÑÊñ∞Êû∂ÊßãÔºå‰ª•Â¢ûÂº∑Âõ†ÊûúÊé®ÁêÜÂíåÂèØËß£ÈáãÊÄß„ÄÇÊèêÂá∫ÁöÑÊ°ÜÊû∂ÁµêÂêà‰∫Ü‰ΩøÁî® ConceptNet ÂíåÂèç‰∫ãÂØ¶Èô≥Ëø∞ÁöÑÊòéÁ¢∫Âõ†ÊûúÊ™¢Ê∏¨Ê®°ÁµÑÔºå‰ª•ÂèäÈÄèÈÅé LLM ÈÄ≤Ë°åÁöÑÈö±Âê´Âõ†ÊûúÊ™¢Ê∏¨„ÄÇÊàëÂÄëÁöÑÊ°ÜÊû∂Êõ¥ÈÄ≤‰∏ÄÊ≠•ÔºåÂä†ÂÖ•‰∏ÄÂ±§Âèç‰∫ãÂØ¶Ëß£ÈáãÔºå‰ª•Âº∑Ë™ø LLM Â∞çÂõ†ÊûúÈóú‰øÇÁöÑÁêÜËß£„ÄÇ‰æÜËá™ ConceptNet ÁöÑÁü•Ë≠òÂ¢ûÂº∑‰∫ÜÂ§öÈ†ÖÂõ†ÊûúÊé®ÁêÜ‰ªªÂãôÁöÑÂü∑Ë°åÔºå‰æãÂ¶ÇÂõ†ÊûúÁôºÁèæ„ÄÅÂõ†ÊûúË≠òÂà•ÂíåÂèç‰∫ãÂØ¶Êé®ÁêÜ„ÄÇÂèç‰∫ãÂØ¶Âè•Âä†ÂÖ•‰∫ÜÊú™Áî±ÊÉÖÂ¢ÉÈÄ†ÊàêÁöÑÊòéÁ¢∫Áü•Ë≠ò„ÄÇÈÄèÈÅéÁµêÂêàÈÄô‰∫õÂº∑Â§ßÁöÑÊ®°ÁµÑÔºåÊàëÂÄëÁöÑÊ®°ÂûãÊó®Âú®Êèê‰æõÂ∞çÂõ†ÊûúÈóú‰øÇÊõ¥Ê∑±ÂÖ•ÁöÑÁêÜËß£ÔºåÂØ¶ÁèæÂ¢ûÂº∑ÁöÑÂèØËß£ÈáãÊÄß„ÄÇÂü∫Ê∫ñË≥áÊñôÈõÜÁöÑË©ï‰º∞È°ØÁ§∫Âú®ÊâÄÊúâÊåáÊ®ôÔºà‰æãÂ¶ÇÊ∫ñÁ¢∫Â∫¶„ÄÅÁ≤æÁ¢∫Â∫¶„ÄÅÂè¨ÂõûÁéáÂíå F1 ÂàÜÊï∏Ôºâ‰∏äÈÉΩÊúâÊâÄÊèêÂçá„ÄÇÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü CausalNetÔºå‰∏ÄÂÄãÊñ∞ÁöÑË≥áÊñôÈõÜÔºå‰∏¶ÈôÑ‰∏ä‰∫ÜÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÔºå‰ª•‰øÉÈÄ≤Âú®ÈÄôÂÄãÈ†òÂüüÁöÑÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂„ÄÇ

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

ÊëòË¶ÅÔºöÁ≥ñÂ∞øÁóÖÔºàDMÔºâ‰ΩøÊÇ£ËÄÖÂÆπÊòìÂá∫ÁèæË°ÄÁÆ°‰ΩµÁôºÁóá„ÄÇ
Ë¶ñÁ∂≤ËÜúÂΩ±ÂÉèÂíåË°ÄÁÆ°ÂèçÊò†Ë∫´È´îÁöÑÂæÆË°ÄÁÆ°ÂíåÂ∑®Ë°ÄÁÆ°ÂÅ•Â∫∑ÁãÄÊ≥Å„ÄÇÂÆÉÂÄëÂèØÁî®ÊñºË®∫Êñ∑Á≥ñÂ∞øÁóÖ‰ΩµÁôºÁóáÔºåÂåÖÊã¨Á≥ñÂ∞øÁóÖË¶ñÁ∂≤ËÜúÁóÖËÆäÔºàDRÔºâ„ÄÅÁ•ûÁ∂ìÁóÖËÆä„ÄÅËÖéÁóÖÂíåÂãïËÑàÁ≤•Ê®£Á°¨ÂåñÊÄßÂøÉË°ÄÁÆ°ÁñæÁóÖÔºå‰ª•ÂèäÈ†êÊ∏¨ÂøÉË°ÄÁÆ°‰∫ã‰ª∂ÁöÑÈ¢®Èö™„ÄÇÁÇ∫‰ΩøÁî®Êï∏‰ΩçÂåñË¶ñÁ∂≤ËÜúÂΩ±ÂÉèÈÄ≤Ë°åÈ´òÈÄöÈáè DR Ê™¢Ê∏¨ËÄåÈñãÁôºÁöÑ‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÂïüÁî®Á≥ªÁµ±Â∑≤Âú®Ëá®Â∫äÊé°Áî®„ÄÇÈô§‰∫Ü DR ÁØ©Ê™¢Â§ñÔºåAI Êï¥Âêà‰πüÂÖ∑ÊúâÂ∑®Â§ßÁöÑÊΩõÂäõ‰æÜÊáâÂ∞çËàáÁ≥ñÂ∞øÁóÖÊÇ£ËÄÖÊï¥È´îÁÖßË≠∑Áõ∏ÈóúÁöÑÊåëÊà∞„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊó®Âú®ÂÖ®Èù¢ÂõûÈ°ßÂü∫ÊñºË¶ñÁ∂≤ËÜúÂΩ±ÂÉèÁöÑ AI ÊáâÁî®Áõ∏ÈóúÁ†îÁ©∂ÁöÑÊñáÁçªÔºåÈÄô‰∫õÁ†îÁ©∂ËàáÁ≥ñÂ∞øÁóÖÁöÑË®∫Êñ∑„ÄÅÈ†êÂæåÂíåÁÆ°ÁêÜÊúâÈóú„ÄÇÊàëÂÄëÂ∞áÊèèËø∞Êï¥È´î AI ËºîÂä©Á≥ñÂ∞øÁóÖÁÖßË≠∑ÁöÑÁôºÁèæÔºåÂåÖÊã¨‰ΩÜ‰∏çÈôêÊñº DR ÁØ©Ê™¢Ôºå‰∏¶Ë®éË´ñÂØ¶ÊñΩÊ≠§È°ûÁ≥ªÁµ±ÁöÑÈöúÁ§ôÔºåÂåÖÊã¨ËàáÂÄ´ÁêÜ„ÄÅË≥áÊñôÈö±ÁßÅ„ÄÅÂÖ¨Âπ≥Â≠òÂèñÂíåÂèØËß£ÈáãÊÄßÊúâÈóúÁöÑÂïèÈ°å„ÄÇÈÄèÈÅéË©ï‰º∞ÊÇ£ËÄÖÁöÑÂÅ•Â∫∑ÁãÄÊ≥ÅÔºåÂêåÊôÇËÄÉÈáèÁ≥ñÂ∞øÁóÖ‰ΩµÁôºÁóá‰ª•ÂèäÊú™‰æÜÂøÉË°ÄÁÆ°‰ΩµÁôºÁóáÁöÑÈ¢®Èö™È†êÂæåÔºåAI ËºîÂä©Ë¶ñÁ∂≤ËÜúÂΩ±ÂÉèÂàÜÊûêÊúâÊΩõÂäõÊàêÁÇ∫Á≥ñÂ∞øÁóÖÊÇ£ËÄÖÁèæ‰ª£ÂåñÂÄã‰∫∫ÂåñÈÜ´ÁôÇÁöÑ‰∏≠ÂøÉÂ∑•ÂÖ∑„ÄÇ

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

ÊëòË¶ÅÔºöÈÄôÈ†ÖÁ†îÁ©∂ÂæûÂ§öÂÄãÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÁöÑËßíÂ∫¶Êé¢Ë®é‰∏çÂêåÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊáâÁî®Âú®ÊïôËÇ≤‰∏äÁöÑÂèØÊé•ÂèóÊÄßÔºåÂåÖÊã¨Â≠∏Áîü„ÄÅËÄÅÂ∏´ÂíåÂÆ∂Èï∑„ÄÇÊâøË™ç AI Âú®ÊïôËÇ≤‰∏äÁöÑËΩâÂûãÊΩõÂäõÔºåÂÆÉËß£Ê±∫‰∫ÜËàáË≥áÊñôÈö±ÁßÅ„ÄÅAI ‰ª£ÁêÜ„ÄÅÈÄèÊòéÂ∫¶„ÄÅÂèØËß£ÈáãÊÄßÂíå AI ÁöÑÈÅìÂæ∑ÈÉ®ÁΩ≤Áõ∏ÈóúÁöÑÁñëÊÖÆ„ÄÇÈÄèÈÅéÂ∞èÊèíÊõ≤ÊñπÊ≥ïÔºåÂèÉËàáËÄÖË¢´ÂëàÁèæ‰∫ÜÂõõÁ®ÆÊÉÖÂ¢ÉÔºåÂÖ∂‰∏≠ AI ÁöÑ‰ª£ÁêÜ„ÄÅÈÄèÊòéÂ∫¶„ÄÅÂèØËß£ÈáãÊÄßÂíåÈö±ÁßÅÂèóÂà∞ÊìçÁ∏±„ÄÇÂú®ÊØèÂÄãÊÉÖÂ¢ÉÂæåÔºåÂèÉËàáËÄÖÂÆåÊàê‰∫Ü‰∏ÄÈ†ÖË™øÊü•ÔºåË©≤Ë™øÊü•ÊçïÊçâ‰∫Ü‰ªñÂÄëÂ∞ç AI ÁöÑÊï¥È´îÊïàÁî®„ÄÅÂÄã‰∫∫ÊïàÁî®„ÄÅÊ≠£Áæ©„ÄÅ‰ø°ÂøÉ„ÄÅÈ¢®Èö™ÂíåÂ¶ÇÊûúÂèØÁî®Ôºå‰ΩøÁî®ÊØèÂÄãÊÉÖÂ¢ÉÁöÑ AI ÁöÑÊÑèÂúñÁöÑÁúãÊ≥ï„ÄÇË≥áÊñôËíêÈõÜÂåÖÂê´‰æÜËá™Âêà‰ΩúÊ©üÊßãÂíåÁ§æÁæ§Â™íÈ´îÊ¥ªÂãïÁöÑ 1198 ‰ΩçÂ§öÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÂèÉËàáËÄÖÁöÑÊúÄÁµÇÊ®£Êú¨Ôºå‰∏¶Â∞àÊ≥®ÊñºÂ∞çÂõõÂÄã AI ‰ΩøÁî®Ê°à‰æãÁöÑÂÄãÂà•ÂõûÊáâ„ÄÇÂ∞çË≥áÊñôÁöÑË™øËß£ÂàÜÊûêË°®ÊòéÔºåÂ∞ç AI ÁöÑÊé•ÂèóÂ∫¶Âíå‰ø°‰ªªÂú®Âà©ÂÆ≥Èóú‰øÇ‰∫∫ÂúòÈ´î‰πãÈñìÊúâÈ°ØËëóÂ∑ÆÁï∞„ÄÇÊàëÂÄëÁôºÁèæÔºåAI ÁöÑ‰ª£ÁêÜ„ÄÅÈÄèÊòéÂ∫¶ÂíåÂèØËß£ÈáãÊÄßÈ´ò‰ΩéÁ®ãÂ∫¶‰πãÈñìÁöÑÈóúÈçµË™øËß£ËÄÖÔºå‰ª•Âèä‰ΩøÁî®‰∏çÂêåÊïôËÇ≤ AI ÁöÑÊÑèÂúñÔºåÂåÖÊã¨ÊÑüÁü•Âà∞ÁöÑÊï¥È´îÊïàÁî®„ÄÅÊ≠£Áæ©Âíå‰ø°ÂøÉ„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Âº∑Ë™øÔºåÊé•Âèó AI Âú®ÊïôËÇ≤‰∏äÁöÑÊáâÁî®ÊòØ‰∏ÄÂÄãÂæÆÂ¶ô‰∏îÂ§öÈù¢ÂêëÁöÑÂïèÈ°åÔºåÈô§‰∫Ü‰∏çÂêåÁöÑÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÁöÑÁúãÊ≥ïÂ§ñÔºåÈÇÑÈúÄË¶Å‰ªîÁ¥∞ËÄÉÊÖÆÂÖ∑È´îÁöÑ AI ÊáâÁî®ÂèäÂÖ∂ÁâπÂæµ„ÄÇ

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

ÊëòË¶ÅÔºö<paragraph>Âü∫ÊñºÂèØÁ©øÊà¥ÂºèÂñÆÂ∞éÁ®ãÂøÉÈõªÂúñ (ECG) Ë£ùÁΩÆÁöÑÈÅ†Á´ØÁóÖÊÇ£Áõ£Ê∏¨Âú®Êó©ÊúüÂÅµÊ∏¨ÂøÉËáüÁñæÁóÖÊñπÈù¢ÂÖ∑ÊúâÈ°ØËëóÁöÑÊΩõÂäõÔºåÁâπÂà•ÊòØËàáÁî®ÊñºËá™ÂãïÂåñÂøÉËáüÁñæÁóÖÂÅµÊ∏¨ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊñπÊ≥ïÁµêÂêà‰ΩøÁî®ÊôÇ„ÄÇÂÖàÂâçÂ∑≤ÊúâÁ†îÁ©∂ÊáâÁî®Âü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑ AI ÊñπÊ≥ïÈÄ≤Ë°åÂøÉËáüÁñæÁóÖÂÅµÊ∏¨„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°ÂûãÂ∞öÊú™Ë¢´Âª£Ê≥õÊé•ÂèóÁÇ∫Ëá®Â∫äË®∫Êñ∑ÁöÑÂèØÈù†ËºîÂä©Â∑•ÂÖ∑ÔºåÈÉ®ÂàÜÂéüÂõ†Âú®ÊñºÂúçÁπûË®±Â§ö AI ÊºîÁÆóÊ≥ïÁöÑÁï∂ÂâçÈªëÁÆ±ÊÑüÁü•„ÄÇÁâπÂà•ÊòØÔºåÊúâÂøÖË¶ÅÊâæÂá∫ÊúâÂä©ÊñºÂÅöÂá∫Ê∫ñÁ¢∫Ë®∫Êñ∑ÁöÑ ECG Ë®äËôüÈóúÈçµÁâπÂæµÔºåÂæûËÄåÂ¢ûÂº∑Ê®°ÂûãÁöÑÂèØËß£ÈáãÊÄß„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆË¶ñË¶∫ËΩâÊèõÂô®ÊñπÊ≥ïÔºå‰ª•Ê†πÊìöÂñÆÂ∞éÁ®ã ECG Ë≥áÊñôÊâæÂá∫ÂøÉÊàøÈ°´Âãï„ÄÇÊÆòÂ∑ÆÁ∂≤Ë∑Ø (ResNet) ÊñπÊ≥ï‰πüÂ∑≤ÈñãÁôºÂá∫‰æÜÔºå‰ª•‰æøËàáË¶ñË¶∫ËΩâÊèõÂô®ÊñπÊ≥ïÈÄ≤Ë°åÊØîËºÉ„ÄÇÈÄô‰∫õÊ®°ÂûãÊáâÁî®Êñº Chapman-Shaoxing Ë≥áÊñôÈõÜÔºå‰ª•ÂàÜÈ°ûÂøÉÊàøÈ°´ÂãïÔºå‰ª•ÂèäÂè¶‰∏ÄÁ®ÆÂ∏∏Ë¶ãÁöÑÂøÉÂæã‰∏çÊï¥ÔºåÁ´áÊÄßÂøÉÂãïÈÅéÁ∑©ÔºåÂíåÊ≠£Â∏∏Á´áÊÄßÂøÉÂæãÁöÑÂøÉË∑≥„ÄÇÈÄô‰∫õÊ®°ÂûãËÉΩÂ§†ÊâæÂá∫Ê±∫ÂÆöÊúÄÁµÇÂàÜÈ°ûÁöÑÂøÉË∑≥ÈóúÈçµÂçÄÂüüÔºå‰∏¶Âº∑Ë™ø P Ê≥¢Âíå T Ê≥¢Ôºå‰ª•ÂèäÂøÉË∑≥ÊåÅÁ∫åÊôÇÈñìÂíåË®äËôüÊåØÂπÖÂú®ÂçÄÂàÜÊ≠£Â∏∏Á´áÊÄßÂøÉÂæãËàáÂøÉÊàøÈ°´ÂãïÂíåÁ´áÊÄßÂøÉÂãïÈÅéÁ∑©ÊñπÈù¢ÁöÑÈáçË¶ÅÊÄß„ÄÇ</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®Æ‰ΩøÁî®ÂÖàÈÄ≤Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄ≤Ë°åÊÜÇÈ¨±ÁóáÂÅµÊ∏¨ÂíåÊ≤ªÁôÇÁöÑÊñ∞Ê®°ÂºèÔºöÁîüÊàêÂºèÈ†êË®ìÁ∑¥Transformer 4 (GPT-4)„ÄÅLlama 2 ËÅäÂ§©Ê©üÂô®‰∫∫Âíå Gemini„ÄÇÈÄô‰∫õ LLM Á∂ìÈÅéÂæÆË™øÔºåÂÖ∑ÂÇôÂ∞àÊ•≠ÊèêÁ§∫ÔºåÂèØË®∫Êñ∑„ÄÅËß£Èáã‰∏¶Âª∫Ë≠∞ÊÜÇÈ¨±ÁóáÁöÑÊ≤ªÁôÇ‰ªãÂÖ•ÊñπÊ≥ï„ÄÇ‰∏ÄÁ®ÆÁç®ÁâπÁöÑÂ∞ëÊ¨°ÊèêÁ§∫ÊñπÊ≥ïÂ¢ûÂº∑‰∫ÜÊ®°ÂûãÊ†πÊìö DSM-5 Ê®ôÊ∫ñÂàÜÊûêÂíåËß£ÈáãÊÜÇÈ¨±ÁóáÁãÄÁöÑËÉΩÂäõ„ÄÇÂú®‰∫íÂãïÈöéÊÆµÔºåÈÄô‰∫õÊ®°ÂûãÊúÉÂèÉËàáÂêåÁêÜÂøÉÂ∞çË©±ÁÆ°ÁêÜÔºåÂæû PsychDB ÂíåË™çÁü•Ë°åÁÇ∫ÁôÇÊ≥ï (CBT) ÊåáÂçóÁ≠âË≥áÊ∫ê‰∏≠Ê±≤ÂèñÔºå‰øÉÈÄ≤ËàáÁ∂ìÊ≠∑ÈáçÂ∫¶ÊÜÇÈ¨±ÁóáÁöÑ‰∫∫ÂÄëÁöÑÊîØÊåÅÊÄß‰∫íÂãï„ÄÇÊ≠§Â§ñÔºåÈÄôÈ†ÖÁ†îÁ©∂ÈÇÑ‰ªãÁ¥π‰∫Ü Illuminate Ë≥áÊñôÂ∫´ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂêÑÁ®Æ CBT Ê®°ÁµÑÔºåÊúâÂä©ÊñºÂÄãÊÄßÂåñÊ≤ªÁôÇÂª∫Ë≠∞„ÄÇÈÄôÈ†ÖÁ†îÁ©∂‰ΩøÁî® F1 ÂàÜÊï∏„ÄÅÊ∫ñÁ¢∫Áéá„ÄÅÂè¨ÂõûÁéá„ÄÅÈ§òÂº¶Áõ∏‰ººÂ∫¶ÂíåÈù¢ÂêëÂè¨ÂõûÁéáÁöÑ Gisting Ë©ï‰º∞ÊõøË∫´ (ROUGE) Á≠âÊåáÊ®ôÔºåÂú®‰∏çÂêåÁöÑÊ∏¨Ë©¶ÈõÜ‰∏≠Ë©ï‰º∞ LLM ÁöÑË°®ÁèæÔºåË≠âÊòé‰∫ÜÂÆÉÂÄëÁöÑÊúâÊïàÊÄß„ÄÇÈÄôÁ®ÆÁ∂úÂêàÊñπÊ≥ïÁµêÂêà‰∫ÜÂ∞ñÁ´ØÁöÑ AI ËàáÊó¢ÂÆöÁöÑÂøÉÁêÜÊñπÊ≥ïÔºåÁÇ∫ÂøÉÁêÜ‰øùÂÅ•Êèê‰æõ‰∫ÜÊñ∞ÁöÑÂèØËÉΩÊÄßÔºå‰∏¶Â±ïÁ§∫‰∫Ü LLM Âú®Èù©Êñ∞ÊÜÇÈ¨±ÁóáË®∫Êñ∑ÂíåÊ≤ªÁôÇÁ≠ñÁï•ÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇ

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v6 by Timoth√©e Schmude, Laura Koesten, Torsten M√∂ller, Sebastian Tschiatschek

Every AI system that makes decisions about people has a group of stakeholders
that are personally affected by these decisions. However, explanations of AI
systems rarely address the information needs of this stakeholder group, who
often are AI novices. This creates a gap between conveyed information and
information that matters to those who are impacted by the system's decisions,
such as domain experts and decision subjects. To address this, we present the
"XAI Novice Question Bank," an extension of the XAI Question Bank containing a
catalog of information needs from AI novices in two use cases: employment
prediction and health monitoring. The catalog covers the categories of data,
system context, system usage, and system specifications. We gathered
information needs through task-based interviews where participants asked
questions about two AI systems to decide on their adoption and received verbal
explanations in response. Our analysis showed that participants' confidence
increased after receiving explanations but that their understanding faced
challenges. These included difficulties in locating information and in
assessing their own understanding, as well as attempts to outsource
understanding. Additionally, participants' prior perceptions of the systems'
risks and benefits influenced their information needs. Participants who
perceived high risks sought explanations about the intentions behind a system's
deployment, while those who perceived low risks rather asked about the system's
operation. Our work aims to support the inclusion of AI novices in
explainability efforts by highlighting their information needs, aims, and
challenges. We summarize our findings as five key implications that can inform
the design of future explanations for lay stakeholder audiences.

ÊëòË¶ÅÔºö<paragraph>ÊØèÂÄãÂ∞ç‰∫∫ÂÅöÂá∫Ê±∫ÂÆöÁöÑ AI Á≥ªÁµ±ÈÉΩÊúâ‰∏ÄÁæ§Âà©ÂÆ≥Èóú‰øÇ‰∫∫
ÂèóÂà∞ÈÄô‰∫õÊ±∫ÂÆöÁöÑË¶™Ë∫´ÂΩ±Èüø„ÄÇÁÑ∂ËÄåÔºåAI
Á≥ªÁµ±ÁöÑËß£ÈáãÂæàÂ∞ëËÉΩÊªøË∂≥ÈÄôÁæ§Âà©ÂÆ≥Èóú‰øÇ‰∫∫ÁöÑË≥áË®äÈúÄÊ±ÇÔºåËÄå‰ªñÂÄë
ÈÄöÂ∏∏ÈÉΩÊòØ AI Êñ∞Êâã„ÄÇÈÄôÈÄ†Êàê‰∫ÜÂÇ≥ÈÅîË≥áË®äËàá
ÂèóÂà∞Á≥ªÁµ±Ê±∫Á≠ñÂΩ±ÈüøÁöÑ‰∫∫Â£´Ôºà‰æãÂ¶ÇÈ†òÂüüÂ∞àÂÆ∂ÂíåÊ±∫Á≠ñ‰∏ªÈ´îÔºâÈáçË¶ñÁöÑË≥áË®ä‰πãÈñìÁöÑËêΩÂ∑Æ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü
„ÄåXAI Êñ∞ÊâãÂïèÈ°åÂ∫´„ÄçÔºåÂÆÉÊòØ XAI ÂïèÈ°åÂ∫´ÁöÑÂª∂‰º∏ÔºåÂåÖÂê´‰æÜËá™ AI Êñ∞ÊâãÂú®ÂÖ©ÂÄã‰ΩøÁî®Ê°à‰æã‰∏≠ÁöÑË≥áË®äÈúÄÊ±ÇÁõÆÈåÑÔºöÂ∞±Ê•≠
È†êÊ∏¨ÂíåÂÅ•Â∫∑Áõ£Ê∏¨„ÄÇÁõÆÈåÑÊ∂µËìã‰∫ÜË≥áÊñô„ÄÅ
Á≥ªÁµ±ËÉåÊôØ„ÄÅÁ≥ªÁµ±‰ΩøÁî®ÂíåÁ≥ªÁµ±Ë¶èÊ†ºÁ≠âÈ°ûÂà•„ÄÇÊàëÂÄëÈÄèÈÅé‰ªªÂãôÂûãË®™Ë´áÊî∂ÈõÜË≥áË®äÈúÄÊ±ÇÔºåÂèÉËàáËÄÖÂú®Ë®™Ë´á‰∏≠Ë©¢Âïè‰∫ÜÂÖ©ÂÄã AI Á≥ªÁµ±ÁöÑÂïèÈ°åÔºå‰ª•Ê±∫ÂÆöÊòØÂê¶Êé°Áî®ÂÆÉÂÄëÔºå‰∏¶Êî∂Âà∞Âè£È†≠
Ëß£Èáã‰ΩúÁÇ∫ÂõûÊáâ„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÂèÉËàáËÄÖÂú®Êî∂Âà∞Ëß£ÈáãÂæå‰ø°ÂøÉÊúâÊâÄÊèêÂçáÔºå‰ΩÜ‰ªñÂÄëÁöÑÁêÜËß£ÂçªÈù¢Ëá®ÊåëÊà∞„ÄÇÈÄô‰∫õÊåëÊà∞ÂåÖÊã¨Èõ£‰ª•ÊâæÂà∞Ë≥áË®äÂíåË©ï‰º∞Ëá™Â∑±ÁöÑÁêÜËß£Ôºå‰ª•ÂèäË©¶ÂúñÂ§ñÂåÖ
ÁêÜËß£„ÄÇÊ≠§Â§ñÔºåÂèÉËàáËÄÖÂ∞çÁ≥ªÁµ±È¢®Èö™ÂíåÂ•ΩËôïÁöÑÂÖàÂâçÂõûÈ•ãÂΩ±Èüø‰∫Ü‰ªñÂÄëÁöÑË≥áË®äÈúÄÊ±Ç„ÄÇË™çÁÇ∫È¢®Èö™È´òÁöÑÂèÉËàáËÄÖÂ∞ãÊ±ÇËß£ÈáãÁ≥ªÁµ±ÈÉ®ÁΩ≤ËÉåÂæåÁöÑÊÑèÂúñÔºåËÄåË™çÁÇ∫È¢®Èö™‰ΩéÁöÑ‰∫∫ÂâáË©¢ÂïèÁ≥ªÁµ±ÁöÑ
Êìç‰Ωú„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Êó®Âú®ÈÄèÈÅéÂº∑Ë™ø AI Êñ∞ÊâãÁöÑË≥áË®äÈúÄÊ±Ç„ÄÅÁõÆÊ®ôÂíå
ÊåëÊà∞Ôºå‰æÜÊîØÊåÅÂ∞á AI Êñ∞ÊâãÁ¥çÂÖ•ÂèØËß£ÈáãÊÄßÂ∑•‰Ωú‰∏≠„ÄÇÊàëÂÄëÂ∞áÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÁ∏ΩÁµêÁÇ∫‰∫îÂÄãÈóúÈçµÂïüÁ§∫ÔºåÈÄô‰∫õÂïüÁ§∫ÂèØ‰ª•ÁÇ∫Êú™‰æÜÈáùÂ∞çÈùûÂ∞àÊ•≠Âà©ÂÆ≥Èóú‰øÇ‰∫∫ÂèóÁúæÁöÑËß£ÈáãË®≠Ë®àÊèê‰æõÂèÉËÄÉ„ÄÇ</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet G√ºrkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÂø´ÈÄüÊºîÈÄ≤ÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÁîüÊàêÂºè AI ÁöÑÈ†òÂüüÔºåÁÇ∫ÂêÑÂÄãÈ†òÂüüÁöÑÊáâÁî®ÈñãÂïü‰∫ÜÊñ∞ÈÄîÂæëÔºå‰ΩÜÂÖ∂Âú®ÂïÜÊ•≠ÊïôËÇ≤‰∏≠ÁöÑËßíËâ≤‰ªçÊú™Ë¢´ÂÖÖÂàÜÊé¢Ë®é„ÄÇÊú¨Á†îÁ©∂È¶ñÊ¨°ÂºïÂÖ•‰∫ÜÂü∫Ê∫ñÔºåÁî®‰ª•Ë©ï‰º∞‰∏ÉÂÄã‰∏ªË¶Å LLM ÁöÑÊïàËÉΩÔºåÂåÖÊã¨ OpenAI ÁöÑÊ®°Âûã (GPT-3.5 Turbo„ÄÅGPT-4 Âíå GPT-4 Turbo)„ÄÅGoogle ÁöÑÊ®°Âûã (PaLM 2„ÄÅGemini 1.0 Pro) Âíå Anthropic ÁöÑÊ®°Âûã (Claude 2 Âíå Claude 2.1)ÔºåÈÄô‰∫õÊ®°ÂûãÂ∞áÁî®ÊñºÁ†îÁ©∂ÁîüÂïÜÊ•≠Ë™≤Á®ãÂÖ•Â≠∏Á®ãÂ∫è‰∏≠ÁöÑÈóúÈçµËÄÉË©¶ GMAT„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÂ§ßÂ§öÊï∏ LLM ÁöÑË°®ÁèæÈÉΩÂÑ™Êñº‰∫∫È°ûËÄÉÁîüÔºåÂÖ∂‰∏≠ GPT-4 Turbo ‰∏çÂÉÖÂÑ™ÊñºÂÖ∂‰ªñÊ®°ÂûãÔºåÊõ¥Ë∂ÖË∂ä‰∫ÜÈ†ÇÂ∞ñÂïÜÂ≠∏Èô¢ÁöÑÁ†îÁ©∂ÁîüÂπ≥ÂùáÂàÜÊï∏„ÄÇÈÄèÈÅéÊ°à‰æãÁ†îÁ©∂ÔºåÊú¨Á†îÁ©∂Êé¢Ë®é‰∫Ü GPT-4 Turbo Âú®Ëß£ÈáãÁ≠îÊ°à„ÄÅË©ï‰º∞ÂõûÊáâ„ÄÅËæ®Ë≠òÈåØË™§„ÄÅË™øÊï¥Ë™™ÊòéÂíåÁî¢ÁîüÊõø‰ª£ÊÉÖÂ¢ÉÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇËàáÂâç‰∏Ä‰ª£ÁâàÊú¨Áõ∏ÊØîÔºåÊúÄÊñ∞ÁöÑ LLM ÁâàÊú¨ GPT-4 Turbo„ÄÅClaude 2.1 Âíå Gemini 1.0 Pro Âú®Êé®ÁêÜ‰ªªÂãôÊñπÈù¢ÊúâÈ°ØËëóÁöÑÈÄ≤Ê≠•ÔºåÂá∏È°Ø‰∫ÜÂÖ∂Âú®Ëß£Ê±∫Ë§áÈõúÂïèÈ°åÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇÂÑòÁÆ° AI Âú®ÊïôËÇ≤„ÄÅË©ïÈáèÂíåËºîÂ∞éÊñπÈù¢ÁöÑÊâøË´æÂæàÊòéÁ¢∫Ôºå‰ΩÜ‰ªçÊúâÊåëÊà∞Â≠òÂú®„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂‰∏çÂÉÖÈó°Êòé‰∫Ü LLM ÁöÑÂ≠∏Ë°ìÊΩõÂäõÔºå‰πüÂº∑Ë™ø‰∫ÜÂú®ÊïôËÇ≤‰∏≠ÂØ©ÊÖéÈñãÁôºÂíåÊáâÁî® AI ÁöÑÂøÖË¶ÅÊÄß„ÄÇÈö®Ëëó AI ÊäÄË°ìÁöÑÈÄ≤Ê≠•ÔºåÂª∫Á´ã AI ‰∫íÂãïÁöÑÊû∂ÊßãÂíåÂçîÂÆö„ÄÅÈ©óË≠â AI ÁîüÊàêÁöÑÂÖßÂÆπÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÅÁ¢∫‰øùÂÖ®ÁêÉÂêÑÂú∞Â§öÂÖÉÂ≠∏ÁøíËÄÖÁöÑÂ≠òÂèñÊ¨äÔºå‰ª•ÂèäÂâµÈÄ†‰∏ÄÂÄã AI ÊîØÊåÅ‰∫∫È°ûÂ∞àÊ•≠Áü•Ë≠òÁöÑÊïôËÇ≤Áí∞Â¢ÉËá≥ÈóúÈáçË¶Å„ÄÇÊú¨Á†îÁ©∂ÁÇ∫ÈÄ≤‰∏ÄÊ≠•Êé¢Á¥¢Ë≤†Ë≤¨‰ªªÂú∞‰ΩøÁî® AI ‰æÜË±êÂØåÊïôËÇ≤È´îÈ©ó‰∏¶ÊîπÂñÑËÄÉË©¶Ê∫ñÂÇôÂíåË©ïÈáèÊñπÊ≥ïÂ•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇ

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

ÊëòË¶ÅÔºöÈ†êÊ∏¨Âä†Ë≠∑ÁóÖÊàø (ICU) ÁóÖÊÇ£ÁöÑÈô¢ÂÖßÊ≠ª‰∫°ÁéáÊòØÊúÄÁµÇËá®Â∫äÁµêÊûúÁöÑÈóúÈçµ„ÄÇAI Â∑≤Â±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÊ∫ñÁ¢∫Â∫¶Ôºå‰ΩÜÂçªÁº∫‰πèÂèØËß£ÈáãÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÂ§öÊ®°ÂºèÊ≠ª‰∫°ÁéáÈ†êÊ∏¨Âô® (X-MMP)ÔºåÊé°Áî®ÊúâÊïà‰∏îÂèØËß£ÈáãÁöÑ AI ÊñπÂºèÔºåËóâÁî±Â§öÊ®°Âºè ICU Ë≥áÊñô‰æÜÈ†êÊ∏¨Èô¢ÂÖßÊ≠ª‰∫°Áéá„ÄÇÊàëÂÄëÂú®Êû∂Êßã‰∏≠Êé°Áî®Â§öÊ®°ÂºèÂ≠∏ÁøíÔºåÂèØ‰ª•Êé•Êî∂‰æÜËá™Ëá®Â∫äË≥áÊñôÁöÑÁï∞Ë≥™Ëº∏ÂÖ•‰∏¶ÂÅöÂá∫Ê±∫Á≠ñ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÊñπÊ≥ïÔºå‰πüÂ∞±ÊòØÂàÜÂ±§ÂÇ≥Êí≠Ëá≥ TransformerÔºå‰ΩúÁÇ∫ LRP ÊñπÊ≥ïÈÅ©Áï∂Âú∞Âª∂‰º∏Ëá≥ TransformerÔºåÂ∞çÂ§öÊ®°ÂºèËº∏ÂÖ•Áî¢ÁîüËß£ÈáãÔºå‰∏¶Êè≠Èú≤Ê≠∏Âõ†ÊñºÈ†êÊ∏¨ÁöÑÈ°ØËëóÁâπÂæµ„ÄÇÊ≠§Â§ñÔºåÊØèÂÄãÊ®°ÂºèÂ∞çËá®Â∫äÁµêÊûúÁöÑË≤¢ÁçªÂèØ‰ª•Ë¶ñË¶∫ÂåñÔºåÂçîÂä©Ëá®Â∫äÈÜ´Â∏´‰∫ÜËß£Ê±∫Á≠ñËÉåÂæåÁöÑÁêÜÁî±„ÄÇÊàëÂÄëÊ†πÊìö MIMIC-III Âíå MIMIC-III Ê≥¢ÂΩ¢Ë≥áÊñôÂ∫´ÊØîÂ∞çÂ≠êÈõÜÂª∫Êßã‰∫Ü‰∏ÄÂÄãÂ§öÊ®°ÂºèË≥áÊñôÈõÜ„ÄÇÂú®Âü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑÂÖ®Èù¢ÂØ¶È©óË≠âÊòéÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊû∂ÊßãÂèØ‰ª•ÈÅîÊàêÂêàÁêÜÁöÑË©ÆÈáãÔºå‰∏¶ÂÖ∑ÂÇôÁ´∂Áà≠ÂäõÁöÑÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÁöÑÊû∂ÊßãÂèØ‰ª•ËºïÈ¨ÜÂú∞ËΩâÁßªÂà∞ÂÖ∂‰ªñËá®Â∫ä‰ªªÂãôÔºåÈÄôÊúâÂä©ÊñºÂú®ÈÜ´ÁôÇ‰øùÂÅ•Á†îÁ©∂‰∏≠ÁôºÁèæÈóúÈçµÂõ†Á¥†„ÄÇ

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian Gei√üler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, Bj√∂rn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias K√ºster, Andr√© Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

ÊëòË¶ÅÔºöÂú®ÈÅéÂéªÁöÑÂçÅÂπ¥‰∏≠ÔºåÁóÖÁêÜÂ≠∏‰∏≠ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) ÊñπÊ≥ïÂ∑≤Â§ßÂπÖÈÄ≤Ê≠•„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºË®±Â§öÊåëÊà∞ÔºåÂåÖÊã¨Â∞áÁ†îÁ©∂ÁµêÊûúËΩâÂåñÁÇ∫Ëá®Â∫äË®∫Êñ∑Áî¢ÂìÅÂú®ÊäÄË°ìÂíåÊ≥ïË¶èÊñπÈù¢ÁöÑÈöúÁ§ôÔºå‰ª•ÂèäÁº∫‰πèÊ®ôÊ∫ñÂåñ‰ªãÈù¢ÔºåÂ∞éËá¥Êï¥ÂêàÂà∞Â∏∏Ë¶èËá®Â∫äÂØ¶Âãô‰∏≠ÈÄ≤Â±ïÁ∑©ÊÖ¢„ÄÇÈñãÊîæ‰∏îËàá‰æõÊáâÂïÜÁÑ°ÈóúÁöÑ EMPAIA Ë®àÁï´ÊáâÂ∞ç‰∫ÜÈÄô‰∫õÊåëÊà∞„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊèê‰æõ EMPAIA ÁöÑÊàêÂ∞±ÂíåÁ∂ìÈ©óÊïôË®ìÁöÑÊ¶ÇËø∞„ÄÇEMPAIA Êï¥Âêà‰∫ÜÁóÖÁêÜÂ≠∏ AI ÁîüÊÖãÁ≥ªÁµ±ÁöÑÂêÑÂÄãÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÔºåÂç≥ÁóÖÁêÜÂ≠∏ÂÆ∂„ÄÅÈõªËÖ¶ÁßëÂ≠∏ÂÆ∂ÂíåÁî¢Ê•≠„ÄÇÂú®ÂØÜÂàáÂêà‰Ωú‰∏ãÔºåÊàëÂÄëÂà∂ÂÆö‰∫ÜÊäÄË°ì‰∫íÈÄöÊÄßÊ®ôÊ∫ñ„ÄÅAI Ê∏¨Ë©¶ÂíåÁî¢ÂìÅÈñãÁôºÂª∫Ë≠∞Ôºå‰ª•ÂèäÂèØËß£ÈáãÊÄßÊñπÊ≥ï„ÄÇÊàëÂÄëÂØ¶‰Ωú‰∫ÜÊ®°ÁµÑÂåñ‰∏îÈñãÊîæÂéüÂßãÁ¢ºÁöÑ EMPAIA Âπ≥Ëá∫Ôºå‰∏¶ÊàêÂäüÊï¥Âêà‰∫Ü‰æÜËá™ 8 ÂÄã‰∏çÂêå‰æõÊáâÂïÜÁöÑ 14 ÂÄãÂü∫Êñº AI ÁöÑÂΩ±ÂÉèÂàÜÊûêÊáâÁî®Á®ãÂºèÔºåÂ±ïÁ§∫‰∫Ü‰∏çÂêåÁöÑÊáâÁî®Á®ãÂºèÂ¶Ç‰Ωï‰ΩøÁî®ÂñÆ‰∏ÄÁöÑÊ®ôÊ∫ñÂåñ‰ªãÈù¢„ÄÇÊàëÂÄëÂÑ™ÂÖàËÄÉÊÖÆÈúÄÊ±ÇÔºå‰∏¶Ë©ï‰º∞‰∫Ü AI Âú®Ê≠êÊ¥≤Âíå‰∫ûÊ¥≤ÁöÑ 14 ÂÄã‰∏çÂêåÁóÖÁêÜÂØ¶È©óÂÆ§‰∏≠ÁöÑÂØ¶ÈöõËá®Â∫äÊáâÁî®„ÄÇÈô§‰∫ÜÊäÄË°ìÈñãÁôºÂ§ñÔºåÊàëÂÄëÈÇÑÁÇ∫ÊâÄÊúâÂà©ÂÆ≥Èóú‰øÇ‰∫∫Âª∫Á´ã‰∫Ü‰∏ÄÂÄãË´ñÂ£áÔºå‰ª•ÂàÜ‰∫´Êï∏‰ΩçÁóÖÁêÜÂ≠∏Âíå AI ÁöÑË≥áË®äÂíåÁ∂ìÈ©ó„ÄÇÂïÜÊ•≠„ÄÅËá®Â∫äÂíåÂ≠∏Ë°ìÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÁèæÂú®ÂèØ‰ª•Êé°Áî® EMPAIA ÁöÑÂ∏∏Ë¶ãÈñãÊîæÂéüÂßãÁ¢º‰ªãÈù¢ÔºåÈÄôÁÇ∫Â§ßË¶èÊ®°Ê®ôÊ∫ñÂåñÂíåÁ∞°ÂåñÊµÅÁ®ãÊèê‰æõ‰∫ÜÁç®ÁâπÁöÑÊ©üÊúÉ„ÄÇÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•ÁöÑÂä™ÂäõÊâçËÉΩÊúâÊïà‰∏îÂª£Ê≥õÂú∞Âª∫Á´ã‰æãË°åÂØ¶È©óÂÆ§‰ΩøÁî®‰∏≠ÁöÑ AI ËºîÂä©„ÄÇÁÇ∫Ê≠§ÔºåÂ∑≤ÊàêÁ´ãÈùûÁáüÂà©ÂçîÊúÉ EMPAIA InternationalÔºå‰ª•‰ΩúÁÇ∫Ê∞∏Á∫åÂü∫Á§éÊû∂ÊßãÔºåÁπºÁ∫åÈÄ≤Ë°åÊ®ôÊ∫ñÂåñÔºå‰∏¶ÊîØÊè¥Âª£Ê≥õÂØ¶‰ΩúÂíåÂÄ°Â∞é AI ËºîÂä©Êï∏‰ΩçÁóÖÁêÜÂ≠∏ÁöÑÊú™‰æÜ„ÄÇ

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

ÊëòË¶ÅÔºöÂèç‰∫ãÂØ¶Ëß£Èáã (CE) ÊäÄË°ìÂ∑≤ÂºïËµ∑ÈóúÊ≥®Ôºå‰ΩúÁÇ∫‰∏ÄÁ®ÆÁÇ∫Ëàá AI Á≥ªÁµ±‰∫íÂãïÁöÑ‰ΩøÁî®ËÄÖÊèê‰æõË¶ãËß£ÁöÑÊñπÊ≥ï„ÄÇÈõñÁÑ∂Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂíåËá™ÂãïÈßïÈßõÊ±ΩËªäÁ≠âÈ†òÂüüÂª£Ê≥õÁ†îÁ©∂ÔºåÂúñÂΩ¢Âèç‰∫ãÂØ¶Ëß£Èáã (GCE) ÊñπÊ≥ïÁõ∏Â∞çËºÉÂ∞ëË¢´Êé¢Á¥¢„ÄÇGCE ÊúÉÁî¢Áîü‰∏ÄÂÄãÈ°û‰ººÊñºÂéüÂßãÂúñÂΩ¢ÁöÑÊñ∞ÂúñÂΩ¢Ôºå‰∏¶Ê†πÊìöÂü∫Á§éÈ†êÊ∏¨Ê®°ÂûãÁî¢Áîü‰∏çÂêåÁöÑÁµêÊûú„ÄÇÂú®ÈÄô‰∫õ GCE ÊäÄË°ì‰∏≠ÔºåÂÑòÁÆ°Âú®ÂÖ∂‰ªñÈ†òÂüüÔºà‰æãÂ¶ÇËóùË°ìÈ¢®Ê†ºÂíåËá™ÁÑ∂Ë™ûË®ÄÂª∫Ê®°Ôºâ‰∏≠Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊàêÂ∞±Ôºå‰ΩÜÊ§çÂü∫ÊñºÁîüÊàêÊ©üÂà∂ÁöÑÊäÄË°ìÁç≤ÂæóÁöÑÈóúÊ≥®Áõ∏Â∞çÊúâÈôê„ÄÇÂ∞çÁîüÊàêÂºèËß£ÈáãÂô®ÁöÑÂÅèÂ•ΩÊ∫êÊñºÂÆÉÂÄëÂú®Êé®ÁêÜÊúüÈñìÁî¢ÁîüÂèç‰∫ãÂØ¶ÂØ¶‰æãÁöÑËÉΩÂäõÔºåÂà©Áî®Ëº∏ÂÖ•ÂúñÂΩ¢ÁöÑËá™‰∏ªÁç≤ÂèñÊìæÂãï„ÄÇÂü∫Êñº‰∏äËø∞ÁêÜÁî±ÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÂºïÂÖ•‰∫Ü RSGG-CEÔºå‰∏ÄÁ®ÆÁî®ÊñºÂèç‰∫ãÂØ¶Ëß£ÈáãÁöÑÊñ∞ÂûãÁ©©ÂÅ•Èö®Ê©üÂúñÂΩ¢ÁîüÊàêÂô®ÔºåËÉΩÂ§†ÂæûÂ≠∏ÁøíÂà∞ÁöÑÊΩõÂú®Á©∫Èñì‰∏≠Áî¢ÁîüÂèç‰∫ãÂØ¶ÁØÑ‰æãÔºåËÄÉÊÖÆÈÉ®ÂàÜÊúâÂ∫èÁöÑÁîüÊàêÂ∫èÂàó„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄ≤Ë°åÂÆöÈáèÂíåÂÆöÊÄßÂàÜÊûêÔºå‰ª•ÊØîËºÉ RSGG-CE ÁöÑÊïàËÉΩËàá SoA ÁîüÊàêÂºèËß£ÈáãÂô®ÔºåÂº∑Ë™øÂÖ∂Â¢ûÂº∑‰∫ÜÁî¢ÁîüÂêàÁêÜËß£ÈáãÂÄôÈÅ∏ÁöÑËÉΩÂäõ„ÄÇ

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

ÊëòË¶ÅÔºöÂèØËß£Èáã AI ÁöÑÂãïÊ©ü‰πã‰∏ÄÊòØËÆì‰∫∫ÂÄëÂú®‰ΩøÁî®ÂíåÈÉ®ÁΩ≤ AI Ê®°ÂûãÊôÇÂÅöÂá∫Êõ¥Â•Ω„ÄÅÊõ¥ÊòéÊô∫ÁöÑÊ±∫Á≠ñ„ÄÇ‰ΩÜÈúÄË¶Å‰ªîÁ¥∞Ë©ï‰º∞‰ª•Ë©ï‰º∞ÊòØÂê¶Â∑≤ÈÅîÂà∞Ê≠§È†êÊúü„ÄÇÁõÆÂâçÁöÑË©ï‰º∞‰∏ªË¶ÅÈõÜ‰∏≠Âú®Ëß£ÈáãÁöÑÊºîÁÆóÊ≥ïÁâπÊÄßÔºåËÄåÊ∂âÂèä‰∫∫È°ûÂèóË©¶ËÄÖÁöÑË©ï‰º∞ÈÄöÂ∏∏Êé°Áî®‰∏ªËßÄÂïèÈ°å‰æÜÊ∏¨Ë©¶‰∫∫È°ûÂ∞çËß£ÈáãÊúâÁî®ÊÄßÁöÑÁúãÊ≥ïÔºåËÄåÊ≤íÊúâÂü∫ÊñºÂÆ¢ËßÄÊåáÊ®ôÂíåÊ∏¨Èáè„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëË©ï‰º∞Ëß£ÈáãÊòØÂê¶ÂèØ‰ª•Âú®Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÈñãÁôºÁöÑÂØ¶ÈöõÂ†¥ÊôØ‰∏≠ÊîπÂñÑ‰∫∫È°ûÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÊ∂âÂèäÂΩ±ÂÉèË≥áÊñôÁöÑÊ∑∑ÂêàÊñπÊ≥ï‰ΩøÁî®ËÄÖÁ†îÁ©∂Ôºå‰ª•Ë©ï‰º∞ SmoothGrad„ÄÅGradCAM ÂíåÈ†êË®ÄËß£ÈáãÂú®ÂÖ©ÂÄã‰ªªÂãô‰∏≠Áî¢ÁîüÁöÑÈ°ØËëóÊÄßÂúñÔºöÊ®°ÂûãÈÅ∏ÊìáÂíåÂèç‰∫ãÂØ¶Ê®°Êì¨„ÄÇ‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÊàëÂÄëÊ≤íÊúâÁôºÁèæ‰ªª‰ΩïÈ°ØËëóÊÄßÂúñÔºàÂç≥‰ΩøÊòØË®≠Ë®àÁÇ∫ÊòìÊñºÁêÜËß£‰∏îÈ´òÂ∫¶ÊåáÁ§∫Á≠îÊ°àÁöÑÂêàÊàêÈ†êË®ÄËß£ÈáãÔºâËÉΩËÆì‰ΩøÁî®ËÄÖÂú®ÈÄô‰∫õ‰ªªÂãô‰∏äÈ°ØËëóÊîπÂñÑÁöÑË≠âÊìö„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåËß£ÈáãÁ¢∫ÂØ¶ÊúâÂä©Êñº‰ΩøÁî®ËÄÖÊõ¥Ê∫ñÁ¢∫Âú∞ÊèèËø∞Ê®°Âûã„ÄÇÈÄô‰∫õÁôºÁèæÊèêÁ§∫ÊàëÂÄëË¶ÅÂ∞çÂü∫ÊñºÈ°ØËëóÊÄßÁöÑËß£Èáã‰∏≠ÂèØËÉΩÂ≠òÂú®Ë™§Ëß£ÁöÑÊúâÁî®ÊÄß‰øùÊåÅË¨πÊÖé„ÄÇ

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

ÊëòË¶ÅÔºöÂèØËß£ÈáãÊÄßÂíåÂÆâÂÖ®ÊÄßÂª∫Á´ã‰ø°‰ªª„ÄÇÈÄô‰∫õÈúÄË¶Å‰∏ÄÂÄãÊ®°Âûã‰æÜÂ±ïÁ§∫‰∏ÄËá¥ÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÁÇ∫‰∫ÜÂØ¶ÁèæÈÄô‰∫õÔºåÊúâÂøÖË¶Å‰ΩøÁî®ÂíåÂàÜÊûêÊï∏ÊìöÂíåÁü•Ë≠òÔºå‰∏¶‰ΩøÁî®Ëàá AI ÊáâÁî®Áõ∏ÈóúÁöÑÁµ±Ë®àÂíåÁ¨¶Ëôü AI ÊñπÊ≥ï - ÂñÆÁç®‰ΩøÁî®‰ªª‰Ωï‰∏ÄÁ®ÆÊñπÊ≥ïÈÉΩ‰∏çÊúÉÂ•èÊïà„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄë‰∏ªÂºµ‰∏¶Ë©¶ÂúñË≠âÊòé NeuroSymbolic AI ÊñπÊ≥ïÊõ¥ÈÅ©ÂêàÊñº‰Ωø AI ÊàêÁÇ∫Âèó‰ø°‰ªªÁöÑ AI Á≥ªÁµ±„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü CREST Ê°ÜÊû∂ÔºåÂ±ïÁ§∫‰∫Ü‰∏ÄËá¥ÊÄß„ÄÅÂèØÈù†ÊÄß„ÄÅ‰ΩøÁî®ËÄÖÂ±§Á¥öÁöÑÂèØËß£ÈáãÊÄßÂíåÂÆâÂÖ®ÊÄßÊòØÂ¶Ç‰ΩïÂª∫Á´ãÂú® NeuroSymbolic ÊñπÊ≥ï‰∏äÁöÑÔºåË©≤ÊñπÊ≥ï‰ΩøÁî®Êï∏ÊìöÂíåÁü•Ë≠ò‰æÜÊîØÊåÅÈóúÈçµÊáâÁî®Ôºà‰æãÂ¶ÇÂÅ•Â∫∑ÂíåÁ¶èÁ•âÔºâÁöÑË¶ÅÊ±Ç„ÄÇÊú¨ÊñáÈáçÈªûÈóúÊ≥®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÂõ†ÁÇ∫ÂÆÉÊòØ CREST Ê°ÜÊû∂‰∏≠ÈÅ∏ÊìáÁöÑ AI Á≥ªÁµ±„ÄÇLLM Âõ†ÂÖ∂Âú®ËôïÁêÜÂª£Ê≥õÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) Â†¥ÊôØÊñπÈù¢ÁöÑÂ§öÂäüËÉΩÊÄßËÄåÂÇôÂèóÁ†îÁ©∂‰∫∫Âì°ÁöÑÈóúÊ≥®„ÄÇ‰æãÂ¶ÇÔºåChatGPT Âíå Google ÁöÑ MedPaLM Â∑≤ÊàêÁÇ∫Êèê‰æõ‰∏ÄËà¨ÂíåÂÅ•Â∫∑Áõ∏ÈóúÊü•Ë©¢‰ø°ÊÅØÁöÑÊ•µÊúâÂ∏åÊúõÁöÑÂπ≥Âè∞„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÈÄô‰∫õÊ®°Âûã‰ªçÁÑ∂ÊòØÈªëÁõíÂ≠êÔºåÂÑòÁÆ°Á¥çÂÖ•‰∫Ü‰∫∫È°ûÂèçÈ•ãÂíåÊåá‰ª§ÂºïÂ∞éÁöÑË™øÊï¥„ÄÇ‰æãÂ¶ÇÔºåÂÑòÁÆ°Âà∂ÂÆö‰∫ÜÂÆâÂÖ®Èò≤Ë≠∑Êé™ÊñΩÔºåChatGPT ‰ªçÂèØËÉΩÁî¢Áîü‰∏çÂÆâÂÖ®ÁöÑÂõûÊáâ„ÄÇCREST ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂêàÁêÜÁöÑÊñπÊ≥ïÔºåÂú® NeuroSymbolic Ê°ÜÊû∂‰∏≠Âà©Áî®Á®ãÂ∫èÂíåÂü∫ÊñºÂúñË°®ÁöÑÁü•Ë≠òÔºå‰ª•Èó°ÊòéËàá LLM Áõ∏ÈóúÁöÑÊåëÊà∞„ÄÇ

##### **Class-Discriminative Attention Maps for Vision Transformers**
2312.02364v3 by Lennart Brocki, Jakub Binda, Neo Christopher Chung

Importance estimators are explainability methods that quantify feature
importance for deep neural networks (DNN). In vision transformers (ViT), the
self-attention mechanism naturally leads to attention maps, which are sometimes
interpreted as importance scores that indicate which input features ViT models
are focusing on. However, attention maps do not account for signals from
downstream tasks. To generate explanations that are sensitive to downstream
tasks, we have developed class-discriminative attention maps (CDAM), a
gradient-based extension that estimates feature importance with respect to a
known class or a latent concept. CDAM scales attention scores by how relevant
the corresponding tokens are for the predictions of a classifier head. In
addition to targeting the supervised classifier, CDAM can explain an arbitrary
concept shared by selected samples by measuring similarity in the latent space
of ViT. Additionally, we introduce Smooth CDAM and Integrated CDAM, which
average a series of CDAMs with slightly altered tokens. Our quantitative
benchmarks include correctness, compactness, and class sensitivity, in
comparison to 7 other importance estimators. Vanilla, Smooth, and Integrated
CDAM excel across all three benchmarks. In particular, our results suggest that
existing importance estimators may not provide sufficient class-sensitivity. We
demonstrate the utility of CDAM in medical images by training and explaining
malignancy and biomarker prediction models based on lung Computed Tomography
(CT) scans. Overall, CDAM is shown to be highly class-discriminative and
semantically relevant, while providing compact explanations.

ÊëòË¶ÅÔºö<paragraph>ÈáçË¶ÅÊÄß‰º∞Ë®àÂô®ÊòØ‰∏ÄÁ®ÆÂèØËß£ÈáãÊÄßÊñπÊ≥ïÔºåÁî®ÊñºÈáèÂåñÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑Ø (DNN) ÁöÑÁâπÂæµÈáçË¶ÅÊÄß„ÄÇÂú®Ë¶ñË¶∫Transformer (ViT) ‰∏≠ÔºåËá™ÊàëÊ≥®ÊÑèÊ©üÂà∂Ëá™ÁÑ∂ÊúÉÂ∞éËá¥Ê≥®ÊÑèÂäõÂúñÔºåÊúâÊôÇÊúÉÂ∞áÂÖ∂Ëß£ÈáãÁÇ∫ÈáçË¶ÅÊÄßÂàÜÊï∏ÔºåË°®Á§∫ ViT Ê®°ÂûãÈóúÊ≥®Âì™‰∫õËº∏ÂÖ•ÁâπÂæµ„ÄÇÁÑ∂ËÄåÔºåÊ≥®ÊÑèÂäõÂúñ‰∏¶Êú™ËÄÉÊÖÆ‰æÜËá™‰∏ãÊ∏∏‰ªªÂãôÁöÑ‰ø°Ëôü„ÄÇÁÇ∫‰∫ÜÁî¢ÁîüÂ∞ç‰∏ãÊ∏∏‰ªªÂãôÊïèÊÑüÁöÑËß£ÈáãÔºåÊàëÂÄëÈñãÁôº‰∫ÜÈ°ûÂà•ÂçÄÂàÜÊ≥®ÊÑèÂäõÂúñ (CDAM)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂü∫ÊñºÊ¢ØÂ∫¶ÁöÑÊì¥ÂÖÖÔºåÁî®Êñº‰º∞Ë®àÁõ∏Â∞çÊñºÂ∑≤Áü•È°ûÂà•ÊàñÊΩõÂú®Ê¶ÇÂøµÁöÑÁâπÂæµÈáçË¶ÅÊÄß„ÄÇCDAM Ê†πÊìöÂ∞çÊáâÁöÑÁ¨¶ËôüËàáÂàÜÈ°ûÂô®È†≠ÁöÑÈ†êÊ∏¨Áõ∏ÈóúÁ®ãÂ∫¶ÔºåË™øÊï¥Ê≥®ÊÑèÂäõÂàÜÊï∏„ÄÇÈô§‰∫ÜÈáùÂ∞çÁõ£Áù£ÂàÜÈ°ûÂô®Â§ñÔºåCDAM ÈÇÑÂèØ‰ª•ÈÄöÈÅéÊ∏¨Èáè ViT ÁöÑÊΩõÂú®Á©∫Èñì‰∏≠ÁöÑÁõ∏‰ººÊÄß‰æÜËß£ÈáãÈÅ∏ÂÆöÊ®£Êú¨ÂÖ±ÊúâÁöÑ‰ªªÊÑèÊ¶ÇÂøµ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂπ≥Êªë CDAM ÂíåÁ©çÂàÜ CDAMÔºåÂÆÉÂÄëÂ∞ç‰∏ÄÁ≥ªÂàóÂÖ∑ÊúâÁï•ÂæÆÊîπËÆäÁöÑÁ¨¶ËôüÁöÑ CDAM ÈÄ≤Ë°åÂπ≥Âùá„ÄÇÊàëÂÄëÁöÑÈáèÂåñÂü∫Ê∫ñÂåÖÊã¨Ê≠£Á¢∫ÊÄß„ÄÅÁ∑äÊπäÊÄßÂíåÈ°ûÂà•ÊïèÊÑüÊÄßÔºåËàáÂÖ∂‰ªñ 7 ÂÄãÈáçË¶ÅÊÄß‰º∞Ë®àÂô®Áõ∏ÊØî„ÄÇÈ¶ôËçâ„ÄÅÂπ≥ÊªëÂíåÁ©çÂàÜ CDAM Âú®ÊâÄÊúâ‰∏âÂÄãÂü∫Ê∫ñ‰∏≠Ë°®ÁèæÂá∫Ëâ≤„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÁèæÊúâÁöÑÈáçË¶ÅÊÄß‰º∞Ë®àÂô®ÂèØËÉΩÁÑ°Ê≥ïÊèê‰æõË∂≥Â§†ÁöÑÈ°ûÂà•ÊïèÊÑüÊÄß„ÄÇÊàëÂÄëÈÄöÈÅéÂü∫ÊñºËÇ∫ÈÉ®ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèè (CT) ÊéÉÊèèË®ìÁ∑¥ÂíåËß£ÈáãÊÉ°ÊÄßËÖ´Áò§ÂíåÁîüÁâ©Ê®ôË®òÈ†êÊ∏¨Ê®°ÂûãÔºåË≠âÊòé‰∫Ü CDAM Âú®ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÁöÑÊïàÁî®„ÄÇÁ∏ΩÁöÑ‰æÜË™™ÔºåCDAM Ë¢´Ë≠âÊòéÂÖ∑ÊúâÈ´òÂ∫¶È°ûÂà•ÂçÄÂàÜÊÄßÂíåË™ûÁæ©Áõ∏ÈóúÊÄßÔºåÂêåÊôÇÊèê‰æõÁ∞°ÊΩîÁöÑËß£Èáã„ÄÇ</paragraph>

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Ë∞ÉÊü•‰∫ÜÂú® COVID-19 Áñ´ÊÉÖÊúüÈó¥Âèä‰ª•ÂêéÈ¢ÑÊµãÊ≠ª‰∫°ÁéáÊó∂ÔºåÂ∑≤ÈÉ®ÁΩ≤‰∫∫Â∑•Êô∫ËÉΩ (AI) Ê®°ÂûãÁöÑÊÄßËÉΩ„ÄÅÂèØËß£ÈáäÊÄßÂíåÁ®≥ÂÅ•ÊÄß„ÄÇ‰Ωú‰∏∫ÂêåÁ±ªÁ†îÁ©∂‰∏≠ÁöÑÈ¶ñ‰æãÔºåÊàë‰ª¨ÂèëÁé∞Ë¥ùÂè∂ÊñØÁ•ûÁªèÁΩëÁªú (BNN) ÂíåÊô∫ËÉΩËÆ≠ÁªÉÊäÄÊúØËÆ©Êàë‰ª¨ÁöÑÊ®°ÂûãÂú®Êï∞ÊçÆÂèëÁîüÈáçÂ§ßÂèòÂåñÊó∂‰ªçËÉΩ‰øùÊåÅÊÄßËÉΩ„ÄÇÊàë‰ª¨ÁöÑÁªìÊûúÂº∫Ë∞É‰∫ÜÂºÄÂèëÁ®≥ÂÅ•ÁöÑ AI Ê®°ÂûãÁöÑÈáçË¶ÅÊÄßÔºåÂç≥‰ΩøÂú®ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÊù°‰ª∂‰∏ãÔºåËøô‰∫õÊ®°Âûã‰πüËÉΩÂåπÈÖçÊàñË∂ÖË∂ä‰∏¥Â∫äÂåªÁîüÁöÑÈ¢ÑÊµã„ÄÇÊàë‰ª¨ÂØπÊ®°ÂûãÂèØËß£ÈáäÊÄßÁöÑÊé¢Á¥¢Ë°®ÊòéÔºåÈöèÊú∫Ê®°Âûã‰ºö‰∫ßÁîüÊõ¥Â§öÊ†∑Âåñ‰∏î‰∏™ÊÄßÂåñÁöÑËß£ÈáäÔºå‰ªéËÄåÁ™ÅÂá∫‰∫ÜÂú®Áé∞ÂÆû‰∏ñÁïåÁöÑ‰∏¥Â∫äÁéØÂ¢É‰∏≠Êèê‰æõËØ¶ÁªÜ‰∏î‰∏™ÊÄßÂåñËßÅËß£ÁöÑ AI Ê®°ÂûãÁöÑÂøÖË¶ÅÊÄß„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Âº∫Ë∞É‰∫ÜÈáèÂåñ AI Ê®°Âûã‰∏≠‰∏çÁ°ÆÂÆöÊÄßÁöÑÈáçË¶ÅÊÄßÔºåËøô‰Ωø‰∏¥Â∫äÂåªÁîüËÉΩÂ§üÊ†πÊçÆÂèØÈù†ÁöÑÈ¢ÑÊµãÂÅöÂá∫Êõ¥ÊòéÊô∫ÁöÑÂÜ≥Á≠ñ„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂ÊèêÂÄ°Âú®ÂåªÁñó‰øùÂÅ•ÁöÑ AI Á†îÁ©∂‰∏≠‰ºòÂÖàËÄÉËôëÂÆûÊñΩÁßëÂ≠¶ÔºåÂπ∂Á°Æ‰øù AI Ëß£ÂÜ≥ÊñπÊ°àÂú®Áé∞ÂÆû‰∏ñÁïåÁöÑ‰∏¥Â∫äÁéØÂ¢É‰∏≠ÂÆûÁî®„ÄÅÊúâÁõä‰∏îÂèØÊåÅÁª≠„ÄÇÈÄöËøáËß£ÂÜ≥ÂåªÁñó‰øùÂÅ•ÁéØÂ¢É‰∏≠ÁöÑÁã¨ÁâπÊåëÊàòÂíåÂ§çÊùÇÊÄßÔºåÁ†îÁ©∂‰∫∫ÂëòÂèØ‰ª•ÂºÄÂèëÂá∫ÊúâÊïàÊîπÂñÑ‰∏¥Â∫äÂÆûË∑µÂíåÊÇ£ËÄÖÈ¢ÑÂêéÁöÑ AI Ê®°Âûã„ÄÇ

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

ÊëòË¶ÅÔºöËÇ∫ÁôåÂç†Ëã±ÂúãÁôåÁóáÊ≠ª‰∫°‰∫∫Êï∏ÁöÑ 21%Ôºå‰∫îÂπ¥Â≠òÊ¥ªÁéáÂæàÂ§ßÁ®ãÂ∫¶ÂèñÊ±∫ÊñºÁôåÁóáË¢´ÁôºÁèæÁöÑÈöéÊÆµ„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Â∑≤Ë≠âÊòé‰∫∫Â∑•Êô∫ËÉΩÊñπÊ≥ïÂÖ∑ÊúâÂæû‰æãË°åÊéÉÊèè‰∏≠Ê∫ñÁ¢∫ÂèäÊó©Ë®∫Êñ∑ËÇ∫ÁôåÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÊ≠§Ë≠âÊìöÂ∞öÊú™ËΩâÂåñÁÇ∫Ëá®Â∫äÂØ¶ÂãôÔºåÂÖ∂‰∏≠‰∏ÄÂÄãÈöúÁ§ôÊòØÁº∫‰πèÂèØËß£ÈáãÁöÑÊ®°Âûã„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÊáâÁî®ËÆäÂàÜËá™ÂãïÁ∑®Á¢ºÂô® (VAE)Ôºå‰∏ÄÁ®ÆÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊ®°ÂûãÔºåÊñºËÇ∫ÁôåÁóÖÁÅ∂„ÄÇÂ∞áÊèêÂá∫ÁöÑÊ®°ÂûãË®ìÁ∑¥ÊñºÂæû LIDC-IDRI ÂÖ¨ÂÖ±Êï∏ÊìöÈõÜ‰∏≠ÊèêÂèñÁöÑ 3D ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÁóÖÁÅ∂„ÄÇÈÄöÈÅéËÅöÈ°ûÊé¢Á¥¢‰∫Ü VAE ÁîüÊàêÁöÑ 2D ÂàáÁâáÁöÑÊΩõÂú®ÂêëÈáèË°®Á§∫Ôºå‰ª•Ë≠âÊòéÂÖ∂ÂìÅË≥™Ôºå‰∏¶Áî®ÊñºËÇ∫ÁôåË®∫Êñ∑ÁöÑ MLP ÂàÜÈ°ûÂô®Ê®°ÂûãÔºåÊúÄ‰Ω≥Ê®°ÂûãÈÅîÂà∞‰∫Ü AUC 0.98 Âíå 93.1% Ê∫ñÁ¢∫Â∫¶ÁöÑÊúÄÂÖàÈÄ≤ÊåáÊ®ô„ÄÇËÅöÈ°ûÂàÜÊûêÈ°ØÁ§∫ÔºåVAE ÊΩõÂú®Á©∫ÈñìÊ†πÊìöÊúâÊÑèÁæ©ÁöÑÁâπÂæµÁµÑÊàêÔºàÂåÖÊã¨ËÖ´Áò§Â§ßÂ∞è„ÄÅÂΩ¢ÁãÄ„ÄÅÊÇ£ËÄÖÂíåÊÉ°ÊÄßÈ°ûÂà•ÔºâÂ∞áÊÉ°ÊÄßÂíåËâØÊÄßÁóÖÁÅ∂ÁöÑÊï∏ÊìöÈõÜÂàÜÈñã„ÄÇÊàëÂÄëÈÇÑÂåÖÊã¨Ê®ôÊ∫ñÈ´òÊñØ VAE (GVAE) ÂíåÊõ¥Êñ∞ÁöÑÁãÑÂà©ÂÖãÈõ∑ VAE (DirVAE) ÁöÑÊØîËºÉÂàÜÊûêÔºåÂæåËÄÖÁî®ÁãÑÂà©ÂÖãÈõ∑ÂàÜ‰ΩàÂèñ‰ª£ÂÖàÈ©óÔºå‰ª•‰øÉÈÄ≤ÂÖ∑ÊúâËß£ÈñãÁâπÂæµË°®Á§∫ÁöÑÊõ¥ÂÖ∑ÂèØËß£ÈáãÊÄßÁöÑÊΩõÂú®Á©∫Èñì„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜËàáËá®Â∫äÊúâÊÑèÁæ©ÁöÑÁâπÂæµËÆäÂåñÁõ∏ÊáâÁöÑÊΩõÂú®Á©∫ÈñìÊ©´Ë∂äÁöÑÊΩõÂäõ„ÄÇ

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÂúñÂÉèÂàÜÈ°ûÂô®Ëº∏Âá∫Ëß£ÈáãÂ∑•ÂÖ∑ÂèØÂàÜÁÇ∫‰æùË≥¥ÊñºÊ®°ÂûãÂÖßÈÉ®Â≠òÂèñÊ¨äÈôêÁöÑÁôΩÁõíÔºå‰ª•ÂèäËàáÊ®°ÂûãÁÑ°ÈóúÁöÑÈªëÁõí„ÄÇÈö®Ëëó AI Âú®ÈÜ´ÁôÇÈ†òÂüüÁöÑ‰ΩøÁî®Â¢ûÂä†ÔºåÂèØËß£ÈáãÊÄßÂ∑•ÂÖ∑ÁöÑ‰ΩøÁî®‰πüÈö®‰πãÂ¢ûÂä†„ÄÇÁèæÊúâÈÜ´Â≠∏ÂΩ±ÂÉèËß£ÈáãÁöÑÂ∑•‰ΩúÈáçÈªûÂú®ÊñºÁôΩÁõíÂ∑•ÂÖ∑Ôºå‰æãÂ¶Ç gradcam„ÄÇÁÑ∂ËÄåÔºåÂàáÊèõÂà∞ÈªëÁõíÂ∑•ÂÖ∑ÊúâÊòéÈ°ØÁöÑÂÑ™ÈªûÔºåÂåÖÊã¨ËÉΩÂ§†Ëàá‰ªª‰ΩïÂàÜÈ°ûÂô®‰∏ÄËµ∑‰ΩøÁî®Ôºå‰ª•ÂèäÂª£Ê≥õÁöÑÈªëÁõíÂ∑•ÂÖ∑ÂèØ‰æõÈÅ∏Êìá„ÄÇÂú®Ê®ôÊ∫ñÂΩ±ÂÉè‰∏äÔºåÈªëÁõíÂ∑•ÂÖ∑ËàáÁôΩÁõí‰∏ÄÊ®£Á≤æÁ¢∫„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊØîËºÉ‰∫ÜÂ§öÁ®ÆÈªëÁõíÊñπÊ≥ïÂú®ËÖ¶Áôå MRI Ë≥áÊñôÈõÜ‰∏äËàá gradcam ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëË≠âÊòéÂ§ßÂ§öÊï∏ÈªëÁõíÂ∑•ÂÖ∑‰∏çÈÅ©ÂêàËß£ÈáãÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°ûÔºå‰∏¶Ë©≥Á¥∞ÂàÜÊûêÂÖ∂Áº∫ÈªûÁöÑÂéüÂõ†„ÄÇÊàëÂÄëÈÇÑË°®Êòé‰∏ÄÁ®ÆÈªëÁõíÂ∑•ÂÖ∑ÔºåÂü∫ÊñºÂõ†ÊûúÂèØËß£ÈáãÊÄßÁöÑ rexÔºåË°®ÁèæËàá \gradcam ‰∏ÄÊ®£Â•Ω„ÄÇ

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v3 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

ÊëòË¶ÅÔºöAI ÈñãÁôºÁ§æÁæ§Êó•ÁõäÂà©Áî® Hugging Face Á≠âË®óÁÆ°‰∏≠‰ªãÊ©üÊßãÊèê‰æõÁî®Êà∂‰∏äÂÇ≥ÁöÑÊ®°ÂûãÂíåË®ìÁ∑¥Ë≥áÊñôÁöÑÁ∞°ÊòìÂ≠òÂèñÊ¨äÈôê„ÄÇÈÄô‰∫õÊ®°ÂûãÂ∏ÇÈõÜÈôç‰Ωé‰∫ÜÊï∏ÂçÅËê¨ÂêçÁî®Êà∂ÁöÑÊäÄË°ìÈÉ®ÁΩ≤ÈöúÁ§ôÔºå‰ΩÜÂèØËÉΩÊúÉË¢´Áî®ÊñºË®±Â§öÊΩõÂú®ÊúâÂÆ≥ÂíåÈùûÊ≥ïÁöÑÊñπÂºè„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëË™™Êòé AI Á≥ªÁµ±Êó¢ÂèØ‰ª•„ÄåÂåÖÂê´„ÄçÂÖßÂÆπÔºåÂèàÂèØ‰ª•‰ΩúÁÇ∫ÈñãÊîæÂºèÂ∑•ÂÖ∑ÔºåÈÄôÊèêÂá∫‰∫ÜËøÑ‰ªäÁÇ∫Ê≠¢ÊúÄÊ£òÊâãÁöÑÂπ≥Âè∞Ê≤ªÁêÜÊåëÊà∞‰πã‰∏Ä„ÄÇÊàëÂÄëÊèê‰æõ Hugging Face„ÄÅGitHub Âíå Civitai Á≠â‰∏âÂÄãË™™ÊòéÊÄßÂπ≥Âè∞‰∏äÊï∏Ëµ∑‰∫ã‰ª∂ÁöÑÊ°à‰æãÁ†îÁ©∂Ôºå‰ª•Ê™¢Ë¶ñÊ®°ÂûãÂ∏ÇÈõÜÂ¶Ç‰ΩïÂØ©Ê†∏Ê®°Âûã„ÄÇÊ†πÊìöÊ≠§ÂàÜÊûêÔºåÊàëÂÄëÊ¶ÇËø∞Áî¢Ê•≠ÁÇ∫ÂõûÊáâÂØ©Ê†∏ÈúÄÊ±ÇËÄåÈñãÁôºÁöÑÈáçË¶ÅÔºà‰ΩÜ‰ªçÊúâÈôêÔºâÂØ¶ÂãôÔºöÊéàÊ¨ä„ÄÅÂ≠òÂèñÂíå‰ΩøÁî®ÈôêÂà∂„ÄÅËá™ÂãïÂåñÂÖßÂÆπÂØ©Ê†∏ÂíåÈñãÊîæÊîøÁ≠ñÂà∂ÂÆö„ÄÇÈõñÁÑ∂Áï∂ÂâçÊîøÁ≠ñÊåëÊà∞Áõ∏Áï∂ÂèØËßÄÔºåÊàëÂÄëÊúÄÂæåÊèêÂá∫‰∏Ä‰∫õÊßãÊÉ≥ÔºåË™™ÊòéÂπ≥Âè∞Â¶Ç‰ΩïËÉΩÊõ¥Â•ΩÂú∞ÂãïÂì°Ë≥áÊ∫êÔºå‰ΩúÁÇ∫Ë¨πÊÖé„ÄÅÂÖ¨Âπ≥‰∏îÈÅ©Â∫¶ÁöÑÊ≥ïË¶èÂ≠òÂèñÈªû„ÄÇ

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

ÊëòË¶ÅÔºö<paragraph>ËÉåÊôØÂíåÁõÆÊ®ôÔºöÈÄöÈÅéÊèêÂèñÈÄô‰∫õË≥áË®äÔºåÊ©üÂô®ÊàñÊ∑±Â∫¶Â≠∏Áøí (ML/DL) Âü∫ÊñºËá™‰∏ªÊï∏ÊìöÂàÜÊûêÂ∑•ÂÖ∑ÂèØ‰ª•ÂçîÂä©Ëá®Â∫äÈÜ´ÁîüÂíåÁôåÁóáÁ†îÁ©∂‰∫∫Âì°ÂæûË§áÈõúÁöÑÊï∏ÊìöÈõÜ‰∏≠ÁôºÁèæÊ®°ÂºèÂíåÈóú‰øÇ„ÄÇÊúÄËøëÂ∑≤ÁôºË°®Ë®±Â§öÂü∫Êñº DL ÁöÑÂçµÂ∑¢Áôå (OC) Êï∏ÊìöÂàÜÊûê„ÄÇÈÄô‰∫õÂàÜÊûêÂú®ÁôåÁóáÁöÑÂêÑÂÄãÊñπÈù¢Ôºà‰æãÂ¶ÇÔºåÂÆÉÂÄëÊ∂âÂèäÁöÑÂ≠êÈ†òÂüüÂíåÁôåÁóáÈ°ûÂûãÔºâÂíåÊï∏ÊìöÂàÜÊûêÂäüËÉΩÊñπÈù¢È´òÂ∫¶Â§öÊ®£Âåñ„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁº∫‰πèÂ∞çÈÄô‰∫õÂàÜÊûêÂú®ÈÄô‰∫õÁâπÂæµÂíå AI ‰øùË≠â (AIA) ÊñπÈù¢ÁöÑÂÖ®Èù¢ÁêÜËß£„ÄÇÈÄôÁØáÁ≥ªÁµ±ÊÄßÂõûÈ°ßÊó®Âú®ÈÄöÈÅéÊ™¢Ë¶ñÁèæÊúâÊñáÁçª‰∏¶ÊòéÁ¢∫ÈóúÊ≥®ÈóúÈçµÁâπÂæµÂíå AI ‰øùË≠âËßÄÈªûÔºå‰æÜÂ°´Ë£úÈÄôÂÄãÁ©∫ÁôΩ„ÄÇÊñπÊ≥ïÔºö‰ΩøÁî® PRISMA Êû∂ÊßãÂú®‰∏âÂÄãÊúüÂàäË≥áÊñôÂ∫´‰∏≠ÈÄ≤Ë°åÂÖ®Èù¢ÊêúÂ∞ã„ÄÇÂàÜÊûêÂÉÖÂåÖÊã¨ 2015 Âπ¥Ëá≥ 2023 Âπ¥ÈñìÁôºË°®ÊñºÂêåË°åË©ïÂØ©ÊúüÂàäÁöÑÁ†îÁ©∂„ÄÇÁµêÊûúÔºöÂú®ÂõûÈ°ß‰∏≠ÔºåÁ∏ΩÂÖ±Ê™¢Ë¶ñ‰∫Ü 96 È†ÖÁî± DL È©ÖÂãïÁöÑÂàÜÊûê„ÄÇÁ†îÁ©∂ÁµêÊûúÊè≠Á§∫‰∫ÜÂπæÂÄãÈóúÊñºÁî± DL È©ÖÂãïÁöÑÂçµÂ∑¢ÁôåÊï∏ÊìöÂàÜÊûêÁöÑÈáçË¶ÅË¶ãËß£Ôºö- Â§ßÂ§öÊï∏Á†îÁ©∂ 71%Ôºà96 È†Ö‰∏≠Êúâ 68 È†ÖÔºâÂ∞àÊ≥®ÊñºÊ™¢Ê∏¨ÂíåË®∫Êñ∑ÔºåËÄåÊ≤íÊúâÁ†îÁ©∂Êé¢Ë®é OC ÁöÑÈ†êÊ∏¨ÂíåÈ†êÈò≤„ÄÇ- ÈÄô‰∫õÂàÜÊûê‰∏ªË¶ÅÂü∫Êñº‰æÜËá™ÈùûÂ§öÂÖÉÊóèÁæ§ÁöÑÊ®£Êú¨Ôºà75%Ôºà96 È†ÖÁ†îÁ©∂‰∏≠ÁöÑ 72 È†ÖÔºâÔºâÔºåÂÉÖÈôêÊñºÊüêÂÄãÂú∞ÁêÜ‰ΩçÁΩÆÊàñÂúãÂÆ∂„ÄÇ- Âè™ÊúâÂ∞ëÈÉ®ÂàÜÁ†îÁ©∂ÔºàÂÉÖ 33%Ôºà96 È†ÖÁ†îÁ©∂‰∏≠ÁöÑ 32 È†ÖÔºâÂü∑Ë°åÊï¥ÂêàÂàÜÊûêÔºåÂÖ∂‰∏≠Â§ßÂ§öÊï∏‰ΩøÁî®ÂêåË≥™Êï∏ÊìöÔºàËá®Â∫äÊàñÁµÑÂ≠∏Ôºâ„ÄÇ- ÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂè™Êúâ 8.3%Ôºà96 È†ÖÁ†îÁ©∂‰∏≠ÁöÑ 8 È†ÖÔºâ‰ΩøÁî®Â§ñÈÉ®ÂíåÂ§öÂÖÉÊï∏ÊìöÈõÜÈ©óË≠â‰∫ÜÂÖ∂Ê®°ÂûãÔºåÂº∑Ë™ø‰∫ÜÂä†Âº∑Ê®°ÂûãÈ©óË≠âÁöÑÂøÖË¶ÅÊÄßÔºå‰ª•Âèä- Â∞á AIA Á¥çÂÖ•ÁôåÁóáÊï∏ÊìöÂàÜÊûê‰ªçËôïÊñºÈùûÂ∏∏Êó©ÊúüÁöÑÈöéÊÆµÔºõÂè™Êúâ 2.1%Ôºà96 È†ÖÁ†îÁ©∂‰∏≠ÁöÑ 2 È†ÖÔºâÈÄèÈÅéÂèØËß£ÈáãÊÄßÊòéÁ¢∫Êé¢Ë®é‰∫Ü AIA„ÄÇ</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

ÊëòË¶ÅÔºö<paragraph>Ëß£ÈáãÊÄßÊòØÊ∑±Â∫¶Â≠∏Áøí‰∏≠Èï∑ÊúüÁöÑÊåëÊà∞ÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇ‰øùÂÅ•Á≠âÈ´òÈ¢®Èö™È†òÂüü„ÄÇÂ∏∏Ë¶ãÁöÑËß£ÈáãÊÄßÊñπÊ≥ïÊúÉÂº∑Ë™øÈ©ÖÂãï AI Ê®°ÂûãÊ±∫Á≠ñÁöÑÂΩ±ÂÉèÂçÄÂüü„ÄÇÁÑ∂ËÄåÔºå‰∫∫È°ûÂæàÂ§ßÁ®ãÂ∫¶‰æùË≥¥Ë™ûË®Ä‰æÜÂÇ≥ÈÅî‰∏çÂÉÖÊòØ„ÄåÂú®Âì™Ë£°„ÄçÔºåÈÇÑÊúâ„ÄåÊòØ‰ªÄÈ∫º„ÄçÁöÑËß£Èáã„ÄÇÊ≠§Â§ñÔºåÂ§ßÂ§öÊï∏Ëß£ÈáãÊÄßÊñπÊ≥ïÈÉΩÂ∞àÊ≥®ÊñºËß£ÈáãÂÄãÂà• AI È†êÊ∏¨ÔºåËÄå‰∏çÊòØÊèèËø∞ AI Ê®°Âûã‰∏ÄËà¨‰ΩøÁî®ÁöÑÁâπÂæµ„ÄÇÂæåËÄÖÂ∞çÊñºÊ®°ÂûãÂíåË≥áÊñôÈõÜÁ®ΩÊ†∏ÁâπÂà•ÊúâÁî®ÔºåÁîöËá≥ÂèØËÉΩÂú® AI ÊÑà‰æÜÊÑàÁî®ÊñºÊñ∞Á©é‰ªªÂãôÊôÇÁî¢ÁîüÁü•Ë≠ò„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã‰ΩøÁî®Ë¶ñË¶∫Ë™ûË®ÄÊ®°Âûã‰æÜËæ®Ë≠òË¶ñË¶∫ÂàÜÈ°û‰ªªÂãôÁöÑË™ûË®ÄÊèèËø∞Á¨¶ÁöÑËß£ÈáãÊÄßÁ≠ñÁï•„ÄÇÈÄèÈÅéÂà©Áî®ÂΩ±ÂÉèÂíåÊñáÂ≠ó‰πãÈñìÈ†êÂÖàË®ìÁ∑¥ÁöÑËÅØÂêàÂµåÂÖ•Á©∫ÈñìÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂ∞áÊñ∞ÁöÑÂàÜÈ°û‰ªªÂãô‰º∞Ë®àÁÇ∫‰∏ÄÂÄãÁ∑öÊÄßÊñáÂ≠óÁµÑÂêàÔºåÂ∞éËá¥ÊØèÂÄãÊñáÂ≠óÈÉΩÊúâÊ¨äÈáçÔºåË°®Á§∫ÂÆÉËàáÂü∫ÊñºË¶ñË¶∫ÁöÑÂàÜÈ°ûÂô®Â∞çÈΩä„ÄÇÊàëÂÄë‰ΩøÁî®ÂÖ©ÂÄãÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°û‰ªªÂãô‰æÜË©ï‰º∞ÊàëÂÄëÁöÑÂÅöÊ≥ïÔºåÊàëÂÄëÁôºÁèæÁî¢ÁîüÁöÑÊèèËø∞Á¨¶Âú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äËàáËá®Â∫äÁü•Ë≠ò‰∏ÄËá¥ÔºåÂÑòÁÆ°Áº∫‰πèÁâπÂÆöÈ†òÂüüÁöÑË™ûË®ÄË®ìÁ∑¥„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÁöÑÂÅöÊ≥ï‰πüÁôºÁèæ‰∫ÜÊâÄÁî®ÂÖ¨ÈñãË≥áÊñôÈõÜ‰∏≠ÁöÑ„ÄåÊç∑ÂæëÈÄ£Á∑ö„ÄçÁöÑÂèØËÉΩÊÄß„ÄÇÁÇ∫‰∫ÜÈÅîÂà∞Ëß£ÈáãÊÄßÁöÑÂäüËÉΩÊÄßË°°ÈáèÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖË©¶È©óËÆÄËÄÖÁ†îÁ©∂ÔºåÁôºÁèæ AI Ë≠òÂà•ÁöÑÊñáÂ≠óËÉΩËÆìÈùûÂ∞àÂÆ∂‰∫∫È°ûÂú®ÈùûÂπ≥Âá°ÁöÑÂ±§Á¥öÂü∑Ë°åÂ∞àÊ•≠ÁöÑÈÜ´ÁôÇ‰ªªÂãô„ÄÇÁ∏Ω‰πãÔºåÊàëÂÄëÁöÑÁµêÊûúÂº∑Ë™ø‰∫Ü‰ΩøÁî®Â§öÊ®°ÂºèÂü∫Á§éÊ®°Âûã‰æÜÊèê‰æõÁõ¥ËßÄÁöÑ„ÄÅÂü∫ÊñºË™ûË®ÄÁöÑË¶ñË¶∫‰ªªÂãôËß£ÈáãÁöÑÊΩõÂäõ„ÄÇ</paragraph>

##### **Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**
2311.02115v2 by Emma A. M. Stanley, Raissa Souza, Anthony Winder, Vedant Gulve, Kimberly Amador, Matthias Wilms, Nils D. Forkert

Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.

ÊëòË¶ÅÔºö<paragraph>‰ΩøÁî®ÈÜ´ÁôÇÂΩ±ÂÉèË®ìÁ∑¥ÁöÑ‰∫∫Â∑•Êô∫ÊÖß (AI) Ê®°ÂûãÔºåÁî®ÊñºËá®Â∫ä‰ªªÂãôÊôÇÔºåÂ∏∏ÊúÉÂú®ÊïàËÉΩ‰∏äÂ±ïÁèæÂá∫Ê¨°Áæ§È´î‰πãÈñìÁöÑÂ∑ÆÁï∞ÔºåÂΩ¢ÊàêÂÅèË¶ã„ÄÇÁî±Êñº‰∏¶ÈùûÊâÄÊúâÁúüÂØ¶‰∏ñÁïåÈÜ´ÁôÇÂΩ±ÂÉèË≥áÊñô‰∏≠ÁöÑÂÅèË¶ã‰æÜÊ∫êÈÉΩÂÆπÊòìËæ®Ë≠òÔºåÂõ†Ê≠§ÂÖ®Èù¢Ë©ï‰º∞ÈÄô‰∫õÂÅèË¶ãÊòØÂ¶Ç‰ΩïÁ∑®Á¢ºÂà∞Ê®°Âûã‰∏≠Ôºå‰ª•ÂèäÂÅèË¶ãÁ∑©Ëß£ÊñπÊ≥ïÂú®ÊîπÂñÑÊïàËÉΩÂ∑ÆÁï∞ÊñπÈù¢ÁöÑËÉΩÂäõÔºåÊòØ‰∏ÄÈ†ÖÊåëÊà∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÂàÜÊûêÊû∂ÊßãÔºåÁî®ÊñºÁ≥ªÁµ±Âåñ‰∏îÂÆ¢ËßÄÂú∞Ë™øÊü•ÈÜ´ÁôÇÂΩ±ÂÉè‰∏≠ÁöÑÂÅèË¶ãÂ∞ç AI Ê®°ÂûãÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÈñãÁôº‰∏¶Ê∏¨Ë©¶‰∫ÜÈÄôÂÄãÊû∂ÊßãÔºå‰ª•ÈÄ≤Ë°åÂèóÊéßÁöÑÈõªËÖ¶Ê®°Êì¨Ë©¶È©óÔºå‰ΩøÁî®‰∏ÄÂÄãÂ∑•ÂÖ∑‰æÜË©ï‰º∞ÈÜ´ÁôÇÂΩ±ÂÉè AI ‰∏≠ÁöÑÂÅèË¶ãÔºåË©≤Â∑•ÂÖ∑Áî®ÊñºÁî¢ÁîüÂÖ∑ÊúâÂ∑≤Áü•ÁñæÁóÖÂΩ±ÈüøÂíåÂÅèË¶ã‰æÜÊ∫êÁöÑÂêàÊàêÁ£ÅÂÖ±ÊåØÂΩ±ÂÉè„ÄÇÂèØË°åÊÄßÈÄèÈÅé‰ΩøÁî®‰∏âÂÄãÂèç‰∫ãÂØ¶ÂÅèË¶ãÊÉÖÂ¢É‰æÜË°°ÈáèÊ®°Êì¨ÂÅèË¶ãÊïàÊáâÂ∞çÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÂàÜÈ°ûÂô®Âíå‰∏âÂÄãÂÅèË¶ãÁ∑©Ëß£Á≠ñÁï•ÁöÑÂΩ±ÈüøÔºå‰∏¶Â±ïÁ§∫Âá∫‰æÜ„ÄÇÂàÜÊûêÈ°ØÁ§∫ÔºåÁï∂ CNN Âú®ÂêàÊàêË≥áÊñôÈõÜ‰∏äÂèóË®ìÊôÇÔºåÊ®°Êì¨ÂÅèË¶ãÊúÉÂ∞éËá¥È†êÊúüÁöÑÊ¨°Áæ§È´îÊïàËÉΩÂ∑ÆÁï∞„ÄÇÊ≠§Â§ñÔºåÈáçÊñ∞Âä†Ê¨äË¢´Ë™çÁÇ∫ÊòØÊ≠§Ë®≠ÂÆö‰∏≠ÊúÄÊàêÂäüÁöÑÂÅèË¶ãÁ∑©Ëß£Á≠ñÁï•ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜËß£ÈáãÊÄß AI ÊñπÊ≥ïÂ¶Ç‰ΩïÂçîÂä©‰ΩøÁî®ÈÄôÂÄãÊû∂ÊßãË™øÊü•Ê®°Âûã‰∏≠ÂÅèË¶ãÁöÑË°®Áèæ„ÄÇÈñãÁôºÂÖ¨Âπ≥ÁöÑ AI Ê®°ÂûãÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÁöÑÊåëÊà∞ÔºåÂõ†ÁÇ∫ÈÜ´ÁôÇÂΩ±ÂÉèË≥áÊñôÈõÜ‰∏≠ÂèØËÉΩÂ≠òÂú®Ë®±Â§ö‰∏îÁ∂ìÂ∏∏Êú™Áü•ÁöÑÂÅèË¶ã‰æÜÊ∫ê„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂÆ¢ËßÄÂú∞Á†îÁ©∂ÂÅèË¶ãÂíåÁ∑©Ëß£Á≠ñÁï•Â∞çÊ∑±Â∫¶Â≠∏ÁøíÁÆ°Á∑öÁöÑÂΩ±ÈüøÔºåÈÄôÂèØ‰ª•ÊîØÊè¥ÂÅ•ÂÖ®‰∏îË≤†Ë≤¨‰ªªÁöÑËá®Â∫ä AI ÁöÑÈñãÁôº„ÄÇ</paragraph>

##### **Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**
2310.19174v1 by Adam White, Margarita Saranti, Artur d'Avila Garcez, Thomas M. H. Hope, Cathy J. Price, Howard Bowman

Machine learning offers great potential for automated prediction of
post-stroke symptoms and their response to rehabilitation. Major challenges for
this endeavour include the very high dimensionality of neuroimaging data, the
relatively small size of the datasets available for learning, and how to
effectively combine neuroimaging and tabular data (e.g. demographic information
and clinical characteristics). This paper evaluates several solutions based on
two strategies. The first is to use 2D images that summarise MRI scans. The
second is to select key features that improve classification accuracy.
Additionally, we introduce the novel approach of training a convolutional
neural network (CNN) on images that combine regions-of-interest extracted from
MRIs, with symbolic representations of tabular data. We evaluate a series of
CNN architectures (both 2D and a 3D) that are trained on different
representations of MRI and tabular data, to predict whether a composite measure
of post-stroke spoken picture description ability is in the aphasic or
non-aphasic range. MRI and tabular data were acquired from 758 English speaking
stroke survivors who participated in the PLORAS study. The classification
accuracy for a baseline logistic regression was 0.678 for lesion size alone,
rising to 0.757 and 0.813 when initial symptom severity and recovery time were
successively added. The highest classification accuracy 0.854 was observed when
8 regions-of-interest was extracted from each MRI scan and combined with lesion
size, initial severity and recovery time in a 2D Residual Neural Network.Our
findings demonstrate how imaging and tabular data can be combined for high
post-stroke classification accuracy, even when the dataset is small in machine
learning terms. We conclude by proposing how the current models could be
improved to achieve even higher levels of accuracy using images from hospital
scanners.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏ÁøíÁÇ∫Ëá™ÂãïÈ†êÊ∏¨‰∏≠È¢®ÂæåÁóáÁãÄÂèäÂÖ∂Â∞çÂæ©ÂÅ•ÁöÑÂèçÊáâÊèê‰æõ‰∫ÜÊ•µÂ§ßÁöÑÊΩõÂäõ„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁöÑÈáçÂ§ßÊåëÊà∞ÂåÖÊã¨Á•ûÁ∂ìÂΩ±ÂÉèË≥áÊñôÁöÑÁ∂≠Â∫¶ÈùûÂ∏∏È´ò„ÄÅÂèØÁî®ÊñºÂ≠∏ÁøíÁöÑË≥áÊñôÈõÜË¶èÊ®°Áõ∏Â∞çËºÉÂ∞èÔºå‰ª•ÂèäÂ¶Ç‰ΩïÊúâÊïàÁµêÂêàÁ•ûÁ∂ìÂΩ±ÂÉèÂíåË°®Ê†ºË≥áÊñôÔºà‰æãÂ¶Ç‰∫∫Âè£Áµ±Ë®àË≥áË®äÂíåËá®Â∫äÁâπÂæµÔºâ„ÄÇÊú¨ÊñáÊ†πÊìöÂÖ©Á®ÆÁ≠ñÁï•Ë©ï‰º∞‰∫ÜÂ§öÁ®ÆËß£Ê±∫ÊñπÊ°à„ÄÇÁ¨¨‰∏ÄÁ®ÆÊòØ‰ΩøÁî®Á∏ΩÁµê MRI ÊéÉÊèèÁöÑ 2D ÂΩ±ÂÉè„ÄÇÁ¨¨‰∫åÁ®ÆÊòØÈÅ∏ÊìáÊúâÂä©ÊñºÊèêÈ´òÂàÜÈ°ûÁ≤æÁ¢∫Â∫¶ÁöÑÈóúÈçµÁâπÂæµ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂú®ÁµêÂêàÂæû MRI ‰∏≠ÊèêÂèñÁöÑÊÑüËààË∂£ÂçÄÂüüËàáË°®Ê†ºË≥áÊñôÁöÑÁ¨¶ËôüË°®Á§∫ÁöÑÂΩ±ÂÉè‰∏äË®ìÁ∑¥Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÁöÑÊñ∞Á©éÊñπÊ≥ï„ÄÇÊàëÂÄëË©ï‰º∞‰∫Ü‰∏ÄÁ≥ªÂàó CNN Êû∂ÊßãÔºà2D Âíå 3DÔºâÔºåÈÄô‰∫õÊû∂ÊßãÂú® MRI ÂíåË°®Ê†ºË≥áÊñôÁöÑ‰∏çÂêåË°®Á§∫‰∏äÈÄ≤Ë°åË®ìÁ∑¥Ôºå‰ª•È†êÊ∏¨‰∏≠È¢®ÂæåÂè£Ëø∞ÂúñÁâáÊèèËø∞ËÉΩÂäõÁöÑÁ∂úÂêàÊ∏¨ÈáèÊòØÂê¶Âú®Â§±Ë™ûÁóáÊàñÈùûÂ§±Ë™ûÁóáÁØÑÂúçÂÖß„ÄÇMRI ÂíåË°®Ê†ºË≥áÊñô‰æÜËá™ 758 ÂêçÂèÉËàá PLORAS Á†îÁ©∂ÁöÑËã±Ë™û‰∏≠È¢®ÂÄñÂ≠òËÄÖ„ÄÇÂÉÖÈáùÂ∞çÁóÖÁÅ∂Â§ßÂ∞èÁöÑÂü∫Á∑öÈÇèËºØËø¥Ê≠∏ÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶ÁÇ∫ 0.678ÔºåÁï∂‰æùÂ∫èÂä†ÂÖ•ÂàùÂßãÁóáÁãÄÂö¥ÈáçÁ®ãÂ∫¶ÂíåÊÅ¢Âæ©ÊôÇÈñìÊôÇÔºå‰∏äÂçáËá≥ 0.757 Âíå 0.813„ÄÇÂú®ÂæûÊØèÂÄã MRI ÊéÉÊèè‰∏≠ÊèêÂèñ 8 ÂÄãÊÑüËààË∂£ÂçÄÂüü‰∏¶Âú® 2D ÊÆòÂ∑ÆÁ•ûÁ∂ìÁ∂≤Ë∑Ø‰∏≠ËàáÁóÖÁÅ∂Â§ßÂ∞è„ÄÅÂàùÂßãÂö¥ÈáçÁ®ãÂ∫¶ÂíåÊÅ¢Âæ©ÊôÇÈñìÁµêÂêàÊôÇÔºåËßÄÂØüÂà∞ÊúÄÈ´òÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶ 0.854„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂ±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÂ∞áÂΩ±ÂÉèÂíåË°®Ê†ºË≥áÊñôÁµêÂêàËµ∑‰æÜ‰ª•Áç≤ÂæóÈ´òÊñº‰∏≠È¢®ÂæåÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶ÔºåÂç≥‰ΩøÂú®Ê©üÂô®Â≠∏ÁøíË°ìË™û‰∏≠Ë≥áÊñôÈõÜÂæàÂ∞èÁöÑÊÉÖÊ≥Å‰∏ã‰πüÊòØÂ¶ÇÊ≠§„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫Â¶Ç‰ΩïÊîπÈÄ≤ÁõÆÂâçÁöÑÊ®°ÂûãÔºå‰ª•‰ΩøÁî®‰æÜËá™ÈÜ´Èô¢ÊéÉÊèèÂÑÄÁöÑÂΩ±ÂÉè‰æÜÂØ¶ÁèæÊõ¥È´òÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇ

##### **Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**
2310.01828v2 by Hossein Shreim, Abdul Karim Gizzini, Ali J. Ghandour

eXplainable Artificial Intelligence (XAI) has emerged as an essential
requirement when dealing with mission-critical applications, ensuring
transparency and interpretability of the employed black box AI models. The
significance of XAI spans various domains, from healthcare to finance, where
understanding the decision-making process of deep learning algorithms is
essential. Most AI-based computer vision models are often black boxes; hence,
providing explainability of deep neural networks in image processing is crucial
for their wide adoption and deployment in medical image analysis, autonomous
driving, and remote sensing applications. Recently, several XAI methods for
image classification tasks have been introduced. On the contrary, image
segmentation has received comparatively less attention in the context of
explainability, although it is a fundamental task in computer vision
applications, especially in remote sensing. Only some research proposes
gradient-based XAI algorithms for image segmentation. This paper adapts the
recent gradient-free Sobol XAI method for semantic segmentation. To measure the
performance of the Sobol method for segmentation, we propose a quantitative XAI
evaluation method based on a learnable noise model. The main objective of this
model is to induce noise on the explanation maps, where higher induced noise
signifies low accuracy and vice versa. A benchmark analysis is conducted to
evaluate and compare performance of three XAI methods, including Seg-Grad-CAM,
Seg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation
technique. This constitutes the first attempt to run and evaluate XAI methods
using high-resolution satellite images.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) Â∑≤ÊàêÁÇ∫ËôïÁêÜ‰ªªÂãôÈóúÈçµÊáâÁî®Á®ãÂºèÊôÇÁöÑ‰∏ÄÈ†ÖÂü∫Êú¨ÈúÄÊ±ÇÔºåÁ¢∫‰øùÊé°Áî®ÈªëÁõí AI Ê®°ÂûãÁöÑÈÄèÊòéÂ∫¶ÂíåÂèØËß£ÈáãÊÄß„ÄÇXAI ÁöÑÈáçË¶ÅÊÄßÊ∂µËìãÂæûÈÜ´ÁôÇ‰øùÂÅ•Âà∞ÈáëËûçÁöÑÂêÑÁ®ÆÈ†òÂüüÔºåÂú®ÈÄô‰∫õÈ†òÂüü‰∏≠Ôºå‰∫ÜËß£Ê∑±Â∫¶Â≠∏ÁøíÊºîÁÆóÊ≥ïÁöÑÊ±∫Á≠ñÂà∂ÂÆöÈÅéÁ®ãËá≥ÈóúÈáçË¶Å„ÄÇÂ§ßÂ§öÊï∏Âü∫Êñº AI ÁöÑÈõªËÖ¶Ë¶ñË¶∫Ê®°ÂûãÈÄöÂ∏∏ÊòØÈªëÁõíÂ≠êÔºõÂõ†Ê≠§ÔºåÂú®ÂΩ±ÂÉèËôïÁêÜ‰∏≠Êèê‰æõÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÂèØËß£ÈáãÊÄßÂ∞çÊñºÂÖ∂Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûê„ÄÅËá™ÂãïÈßïÈßõÂíåÈÅôÊ∏¨ÊáâÁî®‰∏≠ÁöÑÂª£Ê≥õÊé°Áî®ÂíåÈÉ®ÁΩ≤Ëá≥ÈóúÈáçË¶Å„ÄÇÊúÄËøëÔºåÂ∑≤ÈáùÂ∞çÂΩ±ÂÉèÂàÜÈ°û‰ªªÂãôÂºïÂÖ•‰∫ÜÂ§öÁ®Æ XAI ÊñπÊ≥ï„ÄÇÁõ∏ÂèçÂú∞ÔºåÂΩ±ÂÉèÂàÜÂâ≤Âú®ÂèØËß£ÈáãÊÄßÁöÑËÉåÊôØ‰∏ãÂèóÂà∞ÁöÑÈóúÊ≥®Áõ∏Â∞çËºÉÂ∞ëÔºåÂÑòÁÆ°ÂÆÉÊòØÈõªËÖ¶Ë¶ñË¶∫ÊáâÁî®‰∏≠ÁöÑ‰∏ÄÈ†ÖÂü∫Êú¨‰ªªÂãôÔºåÁâπÂà•ÊòØÂú®ÈÅôÊ∏¨‰∏≠„ÄÇÂè™ÊúâÈÉ®ÂàÜÁ†îÁ©∂ÊèêÂá∫Áî®ÊñºÂΩ±ÂÉèÂàÜÂâ≤ÁöÑÂü∫ÊñºÊ¢ØÂ∫¶ÁöÑ XAI ÊºîÁÆóÊ≥ï„ÄÇÊú¨ÊñáÊîπÁ∑®‰∫ÜÊúÄËøëÁöÑÁÑ°Ê¢ØÂ∫¶ Sobol XAI ÊñπÊ≥ï‰ª•ÈÄ≤Ë°åË™ûÊÑèÂàÜÂâ≤„ÄÇÁÇ∫‰∫ÜË°°Èáè Sobol ÊñπÊ≥ïÂú®ÂàÜÂâ≤‰∏≠ÁöÑÊïàËÉΩÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÂèØÂ≠∏ÁøíÈõúË®äÊ®°ÂûãÁöÑÂÆöÈáè XAI Ë©ï‰º∞ÊñπÊ≥ï„ÄÇÊ≠§Ê®°ÂûãÁöÑ‰∏ªË¶ÅÁõÆÁöÑÊòØÂú®Ëß£ÈáãÂúñ‰∏äË™òÁôºÈõúË®äÔºåÂÖ∂‰∏≠ËºÉÈ´òÁöÑË™òÁôºÈõúË®äË°®Á§∫ËºÉ‰ΩéÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÂèç‰πã‰∫¶ÁÑ∂„ÄÇÈÄ≤Ë°åÂü∫Ê∫ñÂàÜÊûê‰ª•Ë©ï‰º∞ÂíåÊØîËºÉ‰∏âÁ®Æ XAI ÊñπÊ≥ïÁöÑÊïàËÉΩÔºåÂåÖÊã¨ Seg-Grad-CAM„ÄÅSeg-Grad-CAM++ Âíå Seg-SobolÔºå‰∏¶‰ΩøÁî®ÊâÄÊèêÂá∫ÁöÑÂü∫ÊñºÈõúË®äÁöÑË©ï‰º∞ÊäÄË°ì„ÄÇÈÄôÊßãÊàê‰∫Ü‰ΩøÁî®È´òËß£ÊûêÂ∫¶Ë°õÊòüÂΩ±ÂÉèÂü∑Ë°åÂíåË©ï‰º∞ XAI ÊñπÊ≥ïÁöÑÈ¶ñÊ¨°ÂòóË©¶„ÄÇ


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-25**|**Privacy-Preserving Federated Foundation Model for Generalist Ultrasound Artificial Intelligence**|Yuncheng Jiang et.al.|[2411.16380v1](http://arxiv.org/abs/2411.16380v1)|null|
|**2024-11-25**|**Med-PerSAM: One-Shot Visual Prompt Tuning for Personalized Segment Anything Model in Medical Domain**|Hangyul Yoon et.al.|[2411.16123v1](http://arxiv.org/abs/2411.16123v1)|null|
|**2024-11-25**|**Why the Agent Made that Decision: Explaining Deep Reinforcement Learning with Vision Masks**|Rui Zuo et.al.|[2411.16120v1](http://arxiv.org/abs/2411.16120v1)|null|
|**2024-11-24**|**DRIVE: Dual-Robustness via Information Variability and Entropic Consistency in Source-Free Unsupervised Domain Adaptation**|Ruiqiang Xiao et.al.|[2411.15976v1](http://arxiv.org/abs/2411.15976v1)|null|
|**2024-11-24**|**Medical Slice Transformer: Improved Diagnosis and Explainability on 3D Medical Images with DINOv2**|Gustav M√ºller-Franzes et.al.|[2411.15802v1](http://arxiv.org/abs/2411.15802v1)|[link](https://github.com/mueller-franzes/mst)|
|**2024-11-24**|**Enhancing the automatic segmentation and analysis of 3D liver vasculature models**|Yassine Machta et.al.|[2411.15778v1](http://arxiv.org/abs/2411.15778v1)|null|
|**2024-11-24**|**RAMIE: Retrieval-Augmented Multi-task Information Extraction with Large Language Models on Dietary Supplements**|Zaifu Zhan et.al.|[2411.15700v1](http://arxiv.org/abs/2411.15700v1)|null|
|**2024-11-23**|**Ontology-Constrained Generation of Domain-Specific Clinical Summaries**|Gaya Mehenni et.al.|[2411.15666v1](http://arxiv.org/abs/2411.15666v1)|[link](https://github.com/lama-west/ontology-based-decoding_ekaw2024)|
|**2024-11-23**|**A Survey on LLM-as-a-Judge**|Jiawei Gu et.al.|[2411.15594v1](http://arxiv.org/abs/2411.15594v1)|null|
|**2024-11-23**|**Large Language Model with Region-guided Referring and Grounding for CT Report Generation**|Zhixuan Chen et.al.|[2411.15539v1](http://arxiv.org/abs/2411.15539v1)|null|
|**2024-11-23**|**GeoAI-Enhanced Community Detection on Spatial Networks with Graph Deep Learning**|Yunlei Liang et.al.|[2411.15428v1](http://arxiv.org/abs/2411.15428v1)|[link](https://github.com/geods/region2vec-gat)|
|**2024-11-23**|**The Decoy Dilemma in Online Medical Information Evaluation: A Comparative Study of Credibility Assessments by LLM and Human Judges**|Jiqun Liu et.al.|[2411.15396v1](http://arxiv.org/abs/2411.15396v1)|null|
|**2024-11-22**|**Regulator-Manufacturer AI Agents Modeling: Mathematical Feedback-Driven Multi-Agent LLM Framework**|Yu Han et.al.|[2411.15356v1](http://arxiv.org/abs/2411.15356v1)|null|
|**2024-11-22**|**Health AI Developer Foundations**|Atilla P. Kiraly et.al.|[2411.15128v1](http://arxiv.org/abs/2411.15128v1)|null|
|**2024-11-22**|**ReXrank: A Public Leaderboard for AI-Powered Radiology Report Generation**|Xiaoman Zhang et.al.|[2411.15122v1](http://arxiv.org/abs/2411.15122v1)|null|
|**2024-11-22**|**Feature-interactive Siamese graph encoder-based image analysis to predict STAS from histopathology images in lung cancer**|Liangrui Pan et.al.|[2411.15274v1](http://arxiv.org/abs/2411.15274v1)|null|
|**2024-11-22**|**Purrfessor: A Fine-tuned Multimodal LLaVA Diet Health Chatbot**|Linqi Lu et.al.|[2411.14925v1](http://arxiv.org/abs/2411.14925v1)|null|
|**2024-11-22**|**Boundless Across Domains: A New Paradigm of Adaptive Feature and Cross-Attention for Domain Generalization in Medical Image Segmentation**|Yuheng Xu et.al.|[2411.14883v1](http://arxiv.org/abs/2411.14883v1)|null|
|**2024-11-22**|**AI-Driven Real-Time Monitoring of Ground-Nesting Birds: A Case Study on Curlew Detection Using YOLOv10**|Carl Chalmers et.al.|[2411.15263v1](http://arxiv.org/abs/2411.15263v1)|null|
|**2024-11-22**|**Optimized Vessel Segmentation: A Structure-Agnostic Approach with Small Vessel Enhancement and Morphological Correction**|Dongning Song et.al.|[2411.15251v1](http://arxiv.org/abs/2411.15251v1)|null|
|**2024-11-22**|**Adversarial Prompt Distillation for Vision-Language Models**|Lin Luo et.al.|[2411.15244v1](http://arxiv.org/abs/2411.15244v1)|null|
|**2024-11-22**|**Is Attention All You Need For Actigraphy? Foundation Models of Wearable Accelerometer Data for Mental Health Research**|Franklin Y. Ruan et.al.|[2411.15240v1](http://arxiv.org/abs/2411.15240v1)|[link](https://github.com/njacobsonlab/pretrained-actigraphy-transformer)|
|**2024-11-21**|**Uterine Ultrasound Image Captioning Using Deep Learning Techniques**|Abdennour Boulesnane et.al.|[2411.14039v1](http://arxiv.org/abs/2411.14039v1)|null|
|**2024-11-21**|**Logic Augmented Generation**|Aldo Gangemi et.al.|[2411.14012v1](http://arxiv.org/abs/2411.14012v1)|null|
|**2024-11-21**|**AmpliNetECG12: A lightweight SoftMax-based relativistic amplitude amplification architecture for 12 lead ECG classification**|Shreya Srivastava et.al.|[2411.13903v1](http://arxiv.org/abs/2411.13903v1)|null|
|**2024-11-21**|**PIORS: Personalized Intelligent Outpatient Reception based on Large Language Model with Multi-Agents Medical Scenario Simulation**|Zhijie Bao et.al.|[2411.13902v1](http://arxiv.org/abs/2411.13902v1)|null|
|**2024-11-20**|**Advancing Complex Medical Communication in Arabic with Sporo AraSum: Surpassing Existing Large Language Models**|Chanseo Lee et.al.|[2411.13518v1](http://arxiv.org/abs/2411.13518v1)|null|
|**2024-11-20**|**Dist Loss: Enhancing Regression in Few-Shot Region through Distribution Distance Constraint**|Guangkun Nie et.al.|[2411.15216v1](http://arxiv.org/abs/2411.15216v1)|null|
|**2024-11-20**|**SynEHRgy: Synthesizing Mixed-Type Structured Electronic Health Records using Decoder-Only Transformers**|Hojjat Karami et.al.|[2411.13428v1](http://arxiv.org/abs/2411.13428v1)|null|
|**2024-11-20**|**S$^2$ALM: Sequence-Structure Pre-trained Large Language Model for Comprehensive Antibody Representation Learning**|Mingze Yin et.al.|[2411.15215v1](http://arxiv.org/abs/2411.15215v1)|null|
|**2024-11-20**|**Are Large Language Models Memorizing Bug Benchmarks?**|Daniel Ramos et.al.|[2411.13323v1](http://arxiv.org/abs/2411.13323v1)|null|
|**2024-11-20**|**Uni-Mlip: Unified Self-supervision for Medical Vision Language Pre-training**|Ameera Bawazir et.al.|[2411.15207v1](http://arxiv.org/abs/2411.15207v1)|null|
|**2024-11-20**|**GraphCL: Graph-based Clustering for Semi-Supervised Medical Image Segmentation**|Mengzhu Wang et.al.|[2411.13147v2](http://arxiv.org/abs/2411.13147v2)|null|
|**2024-11-20**|**Ensuring Safety and Trust: Analyzing the Risks of Large Language Models in Medicine**|Yifan Yang et.al.|[2411.14487v1](http://arxiv.org/abs/2411.14487v1)|null|
|**2024-11-20**|**Training Physics-Driven Deep Learning Reconstruction without Raw Data Access for Equitable Fast MRI**|Ya≈üar Utku Al√ßalar et.al.|[2411.13022v1](http://arxiv.org/abs/2411.13022v1)|null|
|**2024-11-20**|**Automating Sonologists USG Commands with AI and Voice Interface**|Emad Mohamed et.al.|[2411.13006v1](http://arxiv.org/abs/2411.13006v1)|null|
|**2024-11-20**|**DrugGen: Advancing Drug Discovery with Large Language Models and Reinforcement Learning Feedback**|Mahsa Sheikholeslami et.al.|[2411.14157v1](http://arxiv.org/abs/2411.14157v1)|[link](https://github.com/mahsasheikh/DrugGen)|
|**2024-11-19**|**Deep Learning-Based Classification of Hyperkinetic Movement Disorders in Children**|Nandika Ramamurthy et.al.|[2411.15200v1](http://arxiv.org/abs/2411.15200v1)|null|
|**2024-11-19**|**Efficient Medicinal Image Transmission and Resolution Enhancement via GAN**|Rishabh Kumar Sharma et.al.|[2411.12833v1](http://arxiv.org/abs/2411.12833v1)|null|
|**2024-11-19**|**Conversational Medical AI: Ready for Practice**|Antoine Liz√©e et.al.|[2411.12808v1](http://arxiv.org/abs/2411.12808v1)|null|
|**2024-11-19**|**Enhancing Multi-Class Disease Classification: Neoplasms, Cardiovascular, Nervous System, and Digestive Disorders Using Advanced LLMs**|Ahmed Akib Jawad Karim et.al.|[2411.12712v1](http://arxiv.org/abs/2411.12712v1)|null|
|**2024-11-19**|**AI Guided Early Screening of Cervical Cancer**|Dharanidharan S I et.al.|[2411.12681v1](http://arxiv.org/abs/2411.12681v1)|null|
|**2024-11-19**|**Deep Learning-Driven Heat Map Analysis for Evaluating thickness of Wounded Skin Layers**|Devakumar GR et.al.|[2411.12678v1](http://arxiv.org/abs/2411.12678v1)|null|
|**2024-11-19**|**DiM: $f$-Divergence Minimization Guided Sharpness-Aware Optimization for Semi-supervised Medical Image Segmentation**|Bingli Wang et.al.|[2411.12350v1](http://arxiv.org/abs/2411.12350v1)|null|
|**2024-11-19**|**Can ChatGPT Overcome Behavioral Biases in the Financial Sector? Classify-and-Rethink: Multi-Step Zero-Shot Reasoning in the Gold Investment**|Shuoling Liu et.al.|[2411.13599v1](http://arxiv.org/abs/2411.13599v1)|null|
|**2024-11-19**|**StreetviewLLM: Extracting Geographic Information Using a Chain-of-Thought Multimodal Large Language Model**|Zongrong Li et.al.|[2411.14476v1](http://arxiv.org/abs/2411.14476v1)|null|
|**2024-11-19**|**Contrast Similarity-Aware Dual-Pathway Mamba for Multivariate Time Series Node Classification**|Mingsen Du et.al.|[2411.12222v1](http://arxiv.org/abs/2411.12222v1)|null|
|**2024-11-19**|**CCIS-Diff: A Generative Model with Stable Diffusion Prior for Controlled Colonoscopy Image Synthesis**|Yifan Xie et.al.|[2411.12198v1](http://arxiv.org/abs/2411.12198v1)|null|
|**2024-11-18**|**Leveraging Gene Expression Data and Explainable Machine Learning for Enhanced Early Detection of Type 2 Diabetes**|Aurora Lithe Roy et.al.|[2411.14471v1](http://arxiv.org/abs/2411.14471v1)|null|
|**2024-11-18**|**Medical Video Generation for Disease Progression Simulation**|Xu Cao et.al.|[2411.11943v1](http://arxiv.org/abs/2411.11943v1)|null|
|**2024-11-18**|**Edge-Enhanced Dilated Residual Attention Network for Multimodal Medical Image Fusion**|Meng Zhou et.al.|[2411.11799v1](http://arxiv.org/abs/2411.11799v1)|[link](https://github.com/simonzhou86/en_dran)|
|**2024-11-18**|**Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**|Jeffrey N. Clark et.al.|[2411.11774v1](http://arxiv.org/abs/2411.11774v1)|null|
|**2024-11-18**|**SP${ }^3$ : Superpixel-propagated pseudo-label learning for weakly semi-supervised medical image segmentation**|Shiman Li et.al.|[2411.11636v1](http://arxiv.org/abs/2411.11636v1)|null|
|**2024-11-18**|**HistoEncoder: a digital pathology foundation model for prostate cancer**|Joona Pohjonen et.al.|[2411.11458v2](http://arxiv.org/abs/2411.11458v2)|[link](https://github.com/jopo666/HistoEncoder)|
|**2024-11-18**|**TP-UNet: Temporal Prompt Guided UNet for Medical Image Segmentation**|Ranmin Wang et.al.|[2411.11305v2](http://arxiv.org/abs/2411.11305v2)|null|
|**2024-11-18**|**Deep learning waterways for rural infrastructure development**|Matthew Pierson et.al.|[2411.13590v1](http://arxiv.org/abs/2411.13590v1)|null|
|**2024-11-18**|**Zero-Shot Automatic Annotation and Instance Segmentation using LLM-Generated Datasets: Eliminating Field Imaging and Manual Annotation for Deep Learning Model Development**|Ranjan Sapkota et.al.|[2411.11285v1](http://arxiv.org/abs/2411.11285v1)|null|
|**2024-11-18**|**Continuous K-space Recovery Network with Image Guidance for Fast MRI Reconstruction**|Yucong Meng et.al.|[2411.11282v1](http://arxiv.org/abs/2411.11282v1)|null|
|**2024-11-17**|**F$^3$OCUS -- Federated Finetuning of Vision-Language Foundation Models with Optimal Client Layer Updating Strategy via Multi-objective Meta-Heuristics**|Pramit Saha et.al.|[2411.11912v1](http://arxiv.org/abs/2411.11912v1)|null|
|**2024-11-17**|**MPLite: Multi-Aspect Pretraining for Mining Clinical Health Records**|Eric Yang et.al.|[2411.11161v1](http://arxiv.org/abs/2411.11161v1)|null|
|**2024-11-17**|**Label Sharing Incremental Learning Framework for Independent Multi-Label Segmentation Tasks**|Deepa Anand et.al.|[2411.11105v1](http://arxiv.org/abs/2411.11105v1)|null|
|**2024-11-17**|**BianCang: A Traditional Chinese Medicine Large Language Model**|Sibo Wei et.al.|[2411.11027v1](http://arxiv.org/abs/2411.11027v1)|[link](https://github.com/qlu-nlp/biancang)|
|**2024-11-16**|**MpoxVLM: A Vision-Language Model for Diagnosing Skin Lesions from Mpox Virus Infection**|Xu Cao et.al.|[2411.10888v1](http://arxiv.org/abs/2411.10888v1)|[link](https://github.com/IrohXu/MpoxVLM)|
|**2024-11-16**|**Towards Next-Generation Medical Agent: How o1 is Reshaping Decision-Making in Medical Scenarios**|Shaochen Xu et.al.|[2411.14461v1](http://arxiv.org/abs/2411.14461v1)|null|
|**2024-11-16**|**A Novel Adaptive Hybrid Focal-Entropy Loss for Enhancing Diabetic Retinopathy Detection Using Convolutional Neural Networks**|Pandiyaraju V et.al.|[2411.10843v1](http://arxiv.org/abs/2411.10843v1)|null|
|**2024-11-16**|**Decentralizing Test-time Adaptation under Heterogeneous Data Streams**|Zixian Su et.al.|[2411.15173v1](http://arxiv.org/abs/2411.15173v1)|null|
|**2024-11-16**|**MRI Parameter Mapping via Gaussian Mixture VAE: Breaking the Assumption of Independent Pixels**|Moucheng Xu et.al.|[2411.10772v1](http://arxiv.org/abs/2411.10772v1)|[link](https://github.com/moucheng2017/MRI-GMM-VAE)|
|**2024-11-16**|**Integrated Machine Learning and Survival Analysis Modeling for Enhanced Chronic Kidney Disease Risk Stratification**|Zachary Dana et.al.|[2411.10754v1](http://arxiv.org/abs/2411.10754v1)|null|
|**2024-11-16**|**LTCXNet: Advancing Chest X-Ray Analysis with Solutions for Long-Tailed Multi-Label Classification and Fairness Challenges**|Chin-Wei Huang et.al.|[2411.10746v1](http://arxiv.org/abs/2411.10746v1)|null|
|**2024-11-15**|**Can Artificial Intelligence Generate Quality Research Topics Reflecting Patient Concerns?**|Jiyeong Kim et.al.|[2411.14456v1](http://arxiv.org/abs/2411.14456v1)|null|
|**2024-11-15**|**Chain of Alignment: Integrating Public Will with Expert Intelligence for Language Model Alignment**|Andrew Konya et.al.|[2411.10534v1](http://arxiv.org/abs/2411.10534v1)|null|
|**2024-11-15**|**Deep Learning for Micro-Scale Crack Detection on Imbalanced Datasets Using Key Point Localization**|Fatahlla Moreh et.al.|[2411.10389v1](http://arxiv.org/abs/2411.10389v1)|null|
|**2024-11-15**|**Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**|Mohammed Yaseen Jabarulla et.al.|[2411.10255v1](http://arxiv.org/abs/2411.10255v1)|null|
|**2024-11-15**|**FedCL-Ensemble Learning: A Framework of Federated Continual Learning with Ensemble Transfer Learning Enhanced for Alzheimer's MRI Classifications while Preserving Privacy**|Rishit Kapoor et.al.|[2411.12756v1](http://arxiv.org/abs/2411.12756v1)|null|
|**2024-11-15**|**Evaluating the role of `Constitutions' for learning from AI feedback**|Saskia Redgate et.al.|[2411.10168v1](http://arxiv.org/abs/2411.10168v1)|null|
|**2024-11-15**|**PFML: Self-Supervised Learning of Time-Series Data Without Representation Collapse**|Einari Vaaras et.al.|[2411.10087v1](http://arxiv.org/abs/2411.10087v1)|[link](https://github.com/SPEECHCOG/PFML)|
|**2024-11-15**|**Rethinking Normalization Strategies and Convolutional Kernels for Multimodal Image Fusion**|Dan He et.al.|[2411.10036v1](http://arxiv.org/abs/2411.10036v1)|null|
|**2024-11-15**|**JRadiEvo: A Japanese Radiology Report Generation Model Enhanced by Evolutionary Optimization of Model Merging**|Kaito Baba et.al.|[2411.09933v1](http://arxiv.org/abs/2411.09933v1)|null|
|**2024-11-15**|**A Hybrid Artificial Intelligence System for Automated EEG Background Analysis and Report Generation**|Chin-Sung Tung et.al.|[2411.09874v1](http://arxiv.org/abs/2411.09874v1)|[link](https://github.com/tcs211/ai_eeeg_report)|
|**2024-11-14**|**A Benchmark for Long-Form Medical Question Answering**|Pedram Hosseini et.al.|[2411.09834v2](http://arxiv.org/abs/2411.09834v2)|null|
|**2024-11-14**|**A Self-Supervised Model for Multi-modal Stroke Risk Prediction**|Camille Delgrange et.al.|[2411.09822v1](http://arxiv.org/abs/2411.09822v1)|[link](https://github.com/CamilleDelgrange/SSMSRPM)|
|**2024-11-14**|**Deep Learning for Fetal Inflammatory Response Diagnosis in the Umbilical Cord**|Marina A. Ayad et.al.|[2411.09767v1](http://arxiv.org/abs/2411.09767v1)|null|
|**2024-11-14**|**Med-Bot: An AI-Powered Assistant to Provide Accurate and Reliable Medical Information**|Ahan Bhatt et.al.|[2411.09648v1](http://arxiv.org/abs/2411.09648v1)|null|
|**2024-11-14**|**An Explainable Attention Model for Cervical Precancer Risk Classification using Colposcopic Images**|Smith K. Khare et.al.|[2411.09469v1](http://arxiv.org/abs/2411.09469v1)|null|
|**2024-11-14**|**Script-centric behavior understanding for assisted autism spectrum disorder diagnosis**|Wenxing Liu et.al.|[2411.09413v1](http://arxiv.org/abs/2411.09413v1)|null|
|**2024-11-14**|**NFRs in Medical Imaging**|Amanda Vallentin et.al.|[2411.09718v1](http://arxiv.org/abs/2411.09718v1)|null|
|**2024-11-14**|**Comprehensive and Practical Evaluation of Retrieval-Augmented Generation Systems for Medical Question Answering**|Nghia Trung Ngo et.al.|[2411.09213v1](http://arxiv.org/abs/2411.09213v1)|null|
|**2024-11-14**|**Advancing Diffusion Models: Alias-Free Resampling and Enhanced Rotational Equivariance**|Md Fahim Anjum et.al.|[2411.09174v1](http://arxiv.org/abs/2411.09174v1)|null|
|**2024-11-14**|**Artificial Intelligence for Infectious Disease Prediction and Prevention: A Comprehensive Review**|Selestine Melchane et.al.|[2411.10486v1](http://arxiv.org/abs/2411.10486v1)|null|
|**2024-11-13**|**The Limited Impact of Medical Adaptation of Large Language and Vision-Language Models**|Daniel P. Jeong et.al.|[2411.08870v1](http://arxiv.org/abs/2411.08870v1)|null|
|**2024-11-13**|**MVKTrans: Multi-View Knowledge Transfer for Robust Multiomics Classification**|Shan Cong et.al.|[2411.08703v1](http://arxiv.org/abs/2411.08703v1)|null|
|**2024-11-13**|**TRACE: Transformer-based Risk Assessment for Clinical Evaluation**|Dionysis Christopoulos et.al.|[2411.08701v1](http://arxiv.org/abs/2411.08701v1)|null|
|**2024-11-13**|**Rethinking negative sampling in content-based news recommendation**|Miguel √Çngelo Rebelo et.al.|[2411.08700v1](http://arxiv.org/abs/2411.08700v1)|null|
|**2024-11-13**|**A Survey on Vision Autoregressive Model**|Kai Jiang et.al.|[2411.08666v2](http://arxiv.org/abs/2411.08666v2)|null|
|**2024-11-13**|**Optimizing Automatic Summarization of Long Clinical Records Using Dynamic Context Extension:Testing and Evaluation of the NBCE Method**|Guoqing Zhang et.al.|[2411.08586v2](http://arxiv.org/abs/2411.08586v2)|null|
|**2024-11-13**|**A Heterogeneous Graph Neural Network Fusing Functional and Structural Connectivity for MCI Diagnosis**|Feiyu Yin et.al.|[2411.08424v1](http://arxiv.org/abs/2411.08424v1)|null|
|**2024-11-13**|**A Fuzzy Reinforcement LSTM-based Long-term Prediction Model for Fault Conditions in Nuclear Power Plants**|Siwei Li et.al.|[2411.08370v1](http://arxiv.org/abs/2411.08370v1)|null|
|**2024-11-13**|**TowerDebias: A Novel Debiasing Method based on the Tower Property**|Norman Matloff et.al.|[2411.08297v1](http://arxiv.org/abs/2411.08297v1)|null|
|**2024-11-12**|**Scaling Properties of Diffusion Models for Perceptual Tasks**|Rahul Ravishankar et.al.|[2411.08034v3](http://arxiv.org/abs/2411.08034v3)|null|
|**2024-11-12**|**Investigating the Effectiveness of Explainability Methods in Parkinson's Detection from Speech**|Eleonora Mancini et.al.|[2411.08013v2](http://arxiv.org/abs/2411.08013v2)|null|

#### Abstracts
##### **Privacy-Preserving Federated Foundation Model for Generalist Ultrasound Artificial Intelligence**
2411.16380v1 by Yuncheng Jiang, Chun-Mei Feng, Jinke Ren, Jun Wei, Zixun Zhang, Yiwen Hu, Yunbi Liu, Rui Sun, Xuemei Tang, Juan Du, Xiang Wan, Yong Xu, Bo Du, Xin Gao, Guangyu Wang, Shaohua Zhou, Shuguang Cui, Rick Siow Mong Goh, Yong Liu, Zhen Li

Ultrasound imaging is widely used in clinical diagnosis due to its
non-invasive nature and real-time capabilities. However, conventional
ultrasound diagnostics face several limitations, including high dependence on
physician expertise and suboptimal image quality, which complicates
interpretation and increases the likelihood of diagnostic errors. Artificial
intelligence (AI) has emerged as a promising solution to enhance clinical
diagnosis, particularly in detecting abnormalities across various biomedical
imaging modalities. Nonetheless, current AI models for ultrasound imaging face
critical challenges. First, these models often require large volumes of labeled
medical data, raising concerns over patient privacy breaches. Second, most
existing models are task-specific, which restricts their broader clinical
utility. To overcome these challenges, we present UltraFedFM, an innovative
privacy-preserving ultrasound foundation model. UltraFedFM is collaboratively
pre-trained using federated learning across 16 distributed medical institutions
in 9 countries, leveraging a dataset of over 1 million ultrasound images
covering 19 organs and 10 ultrasound modalities. This extensive and diverse
data, combined with a secure training framework, enables UltraFedFM to exhibit
strong generalization and diagnostic capabilities. It achieves an average area
under the receiver operating characteristic curve of 0.927 for disease
diagnosis and a dice similarity coefficient of 0.878 for lesion segmentation.
Notably, UltraFedFM surpasses the diagnostic accuracy of mid-level
ultrasonographers and matches the performance of expert-level sonographers in
the joint diagnosis of 8 common systemic diseases. These findings indicate that
UltraFedFM can significantly enhance clinical diagnostics while safeguarding
patient privacy, marking an advancement in AI-driven ultrasound imaging for
future clinical applications.

ÊëòË¶ÅÔºöË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÂõ†ÂÖ∂Èùû‰æµÂÖ•ÊÄßËàáÂç≥ÊôÇÊÄßÂª£Ê≥õÊáâÁî®ÊñºËá®Â∫äË®∫Êñ∑„ÄÇÁÑ∂ËÄåÔºåÂÇ≥Áµ±Ë∂ÖÈü≥Ê≥¢Ë®∫Êñ∑Èù¢Ëá®Êï∏È†ÖÈôêÂà∂ÔºåÂåÖÊã¨È´òÂ∫¶‰æùË≥¥ÈÜ´Â∏´Â∞àÊ•≠Áü•Ë≠òÂíåÊ¨°‰Ω≥ÂΩ±ÂÉèÂìÅË≥™ÔºåÈÄô‰ΩøÂæóÂΩ±ÂÉèÂà§ËÆÄÊõ¥ÁÇ∫Ë§áÈõúÔºå‰∏¶Â¢ûÂä†Ë®∫Êñ∑ÈåØË™§ÁöÑÂèØËÉΩÊÄß„ÄÇ‰∫∫Â∑•Êô∫ÊÖß (AI) Â∑≤ÊàêÁÇ∫Â¢ûÂº∑Ëá®Â∫äË®∫Êñ∑ÁöÑÊΩõÂú®Ëß£Ê±∫ÊñπÊ°àÔºåÁâπÂà•ÊòØÂú®ÂÅµÊ∏¨ÂêÑÁ®ÆÁîüÁâ©ÈÜ´Â≠∏ÂΩ±ÂÉèÊ®°Âºè‰∏≠ÁöÑÁï∞Â∏∏„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÁõÆÂâçÁî®ÊñºË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÁöÑ AI Ê®°ÂûãÈù¢Ëá®Âö¥Â≥ªÊåëÊà∞„ÄÇÈ¶ñÂÖàÔºåÈÄô‰∫õÊ®°ÂûãÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÁöÑÊ®ôÁ±§ÈÜ´Â≠∏Ë≥áÊñôÔºåÈÄôÂºïÁôº‰∫ÜÂ∞çÁóÖÊÇ£Èö±ÁßÅÈÅ≠‰æµÁäØÁöÑÁñëÊÖÆ„ÄÇÂÖ∂Ê¨°ÔºåÁèæÊúâÁöÑÂ§ßÈÉ®ÂàÜÊ®°ÂûãÈÉΩÊòØÈáùÂ∞çÁâπÂÆö‰ªªÂãôËÄåË®≠Ë®àÔºåÈÄôÈôêÂà∂‰∫ÜÂÆÉÂÄëÂú®Êõ¥Âª£Ê≥õÁöÑËá®Â∫äÊáâÁî®„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü UltraFedFMÔºå‰∏ÄÂÄãÂâµÊñ∞ÁöÑÈö±ÁßÅ‰øùË≠∑Ë∂ÖÈü≥Ê≥¢Âü∫Á§éÊ®°Âûã„ÄÇUltraFedFM ÈÄèÈÅé 9 ÂÄãÂúãÂÆ∂/Âú∞ÂçÄÁöÑ 16 ÂÄãÂàÜÊï£ÂºèÈÜ´ÁôÇÊ©üÊßãÁöÑËÅØÂêàÂ≠∏ÁøíÈÄ≤Ë°åÂçî‰ΩúÈ†êË®ìÁ∑¥ÔºåÂà©Áî®ÂåÖÂê´Ë∂ÖÈÅé 100 Ëê¨ÂºµË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÁöÑË≥áÊñôÈõÜÔºåÊ∂µËìã 19 ÂÄãÂô®ÂÆòÂíå 10 Á®ÆË∂ÖÈü≥Ê≥¢Ê®°Âºè„ÄÇÈÄô‰∫õÂª£Ê≥õ‰∏îÂ§öÊ®£ÂåñÁöÑË≥áÊñôÔºåÁµêÂêàÂÆâÂÖ®ÁöÑË®ìÁ∑¥Êû∂ÊßãÔºå‰Ωø UltraFedFM ËÉΩÂ§†Â±ïÁèæÂº∑Â§ßÁöÑÊ¶ÇÂåñÂíåË®∫Êñ∑ËÉΩÂäõ„ÄÇÂú®ÁñæÁóÖË®∫Êñ∑ÊñπÈù¢ÔºåÂÖ∂ÂèóË©¶ËÄÖÂ∑•‰ΩúÁâπÂæµÊõ≤Á∑ö‰∏ãÁöÑÂπ≥ÂùáÈù¢Á©çÈÅîÂà∞ 0.927ÔºåÂú®ÁóÖÁÅ∂ÂàÜÂâ≤ÊñπÈù¢ÔºåÂÖ∂ Dice Áõ∏‰ºº‰øÇÊï∏ÁÇ∫ 0.878„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåUltraFedFM Ë∂ÖË∂ä‰∫Ü‰∏≠ÈöéË∂ÖÈü≥Ê≥¢Ê™¢Êü•Âì°ÁöÑË®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÔºå‰∏¶Âú® 8 Á®ÆÂ∏∏Ë¶ãÂÖ®Ë∫´ÊÄßÁñæÁóÖÁöÑËÅØÂêàË®∫Êñ∑‰∏≠ÈÅîÂà∞Â∞àÂÆ∂Á¥öË∂ÖÈü≥Ê≥¢Ê™¢Êü•Âì°ÁöÑÊ∞¥Ê∫ñ„ÄÇÈÄô‰∫õÁôºÁèæË°®ÊòéÔºåUltraFedFM ÂèØ‰ª•È°ØËëóÂ¢ûÂº∑Ëá®Â∫äË®∫Êñ∑ÔºåÂêåÊôÇ‰øùË≠∑ÁóÖÊÇ£Èö±ÁßÅÔºåÈÄôÊ®ôË™åËëó AI È©ÖÂãïË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÂú®Êú™‰æÜËá®Â∫äÊáâÁî®‰∏≠ÁöÑ‰∏ÄÈ†ÖÈÄ≤Ê≠•„ÄÇ

##### **Med-PerSAM: One-Shot Visual Prompt Tuning for Personalized Segment Anything Model in Medical Domain**
2411.16123v1 by Hangyul Yoon, Doohyuk Jang, Jungeun Kim, Eunho Yang

Leveraging pre-trained models with tailored prompts for in-context learning
has proven highly effective in NLP tasks. Building on this success, recent
studies have applied a similar approach to the Segment Anything Model (SAM)
within a ``one-shot" framework, where only a single reference image and its
label are employed. However, these methods face limitations in the medical
domain, primarily due to SAM's essential requirement for visual prompts and the
over-reliance on pixel similarity for generating them. This dependency may lead
to (1) inaccurate prompt generation and (2) clustering of point prompts,
resulting in suboptimal outcomes. To address these challenges, we introduce
\textbf{Med-PerSAM}, a novel and straightforward one-shot framework designed
for the medical domain. Med-PerSAM uses only visual prompt engineering and
eliminates the need for additional training of the pretrained SAM or human
intervention, owing to our novel automated prompt generation process. By
integrating our lightweight warping-based prompt tuning model with SAM, we
enable the extraction and iterative refinement of visual prompts, enhancing the
performance of the pre-trained SAM. This advancement is particularly meaningful
in the medical domain, where creating visual prompts poses notable challenges
for individuals lacking medical expertise. Our model outperforms various
foundational models and previous SAM-based approaches across diverse 2D medical
imaging datasets.

ÊëòË¶ÅÔºöÂà©Áî®È†êÂÖàË®ìÁ∑¥ÁöÑÊ®°ÂûãÔºå‰∏¶ÈáùÂ∞çÁâπÂÆöÊèêÁ§∫ÈÄ≤Ë°åÊÉÖÂ¢ÉÂ≠∏ÁøíÔºåÂ∑≤Ë≠âÊòéÂú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãô‰∏≠ÈùûÂ∏∏ÊúâÊïà„ÄÇÂú®Ê≠§ÊàêÂäüÂü∫Á§é‰∏äÔºåÊúÄËøëÁöÑÁ†îÁ©∂Â∑≤Â∞áÈ°û‰ººÊñπÊ≥ïÊáâÁî®Êñº„ÄåÁâáÊÆµ‰ªª‰ΩïÊ®°Âûã„Äç(SAM)ÔºåÊé°Áî®„Äå‰∏ÄÊ¨°ÊÄß„ÄçÊû∂ÊßãÔºåÂÖ∂‰∏≠ÂÉÖ‰ΩøÁî®ÂñÆ‰∏ÄÂèÉËÄÉÂΩ±ÂÉèÂèäÂÖ∂Ê®ôÁ±§„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÂú®ÈÜ´ÁôÇÈ†òÂüüÈù¢Ëá®ÈôêÂà∂Ôºå‰∏ªË¶ÅÊòØÁî±Êñº SAM Â∞çË¶ñË¶∫ÊèêÁ§∫ÁöÑÂü∫Êú¨ÈúÄÊ±ÇÔºå‰ª•ÂèäÈÅéÂ∫¶‰æùË≥¥ÂÉèÁ¥†Áõ∏‰ººÊÄß‰æÜÁî¢ÁîüÂÆÉÂÄë„ÄÇÈÄôÁ®Æ‰æùË≥¥ÊÄßÂèØËÉΩÊúÉÂ∞éËá¥ (1) ÊèêÁ§∫Áî¢Áîü‰∏çÊ∫ñÁ¢∫Ôºå‰ª•Âèä (2) ÈªûÊèêÁ§∫Áæ§ÈõÜÔºåÂ∞éËá¥ÁµêÊûúÊ¨°‰Ω≥„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü \textbf{Med-PerSAM}ÔºåÈÄôÊòØ‰∏ÄÂÄãÂ∞àÁÇ∫ÈÜ´ÁôÇÈ†òÂüüË®≠Ë®àÁöÑÊñ∞Á©é‰∏îÁõ¥Êé•ÁöÑ‰∏ÄÊ¨°ÊÄßÊû∂Êßã„ÄÇMed-PerSAM ÂÉÖ‰ΩøÁî®Ë¶ñË¶∫ÊèêÁ§∫Â∑•Á®ãÔºå‰∏¶Ê∂àÈô§‰∫ÜÂ∞çÈ†êË®ìÁ∑¥ SAM Êàñ‰∫∫ÁÇ∫Âπ≤È†êÁöÑÈ°çÂ§ñË®ìÁ∑¥ÈúÄÊ±ÇÔºåÈÄôË¶ÅÊ≠∏ÂäüÊñºÊàëÂÄëÊñ∞Á©éÁöÑËá™ÂãïÂåñÊèêÁ§∫Áî¢ÁîüÊµÅÁ®ã„ÄÇÈÄèÈÅéÂ∞áÊàëÂÄëËºïÈáèÁ¥öÂü∫ÊñºËÆäÂΩ¢ÁöÑÊèêÁ§∫Ë™øÊï¥Ê®°ÂûãËàá SAM Êï¥ÂêàÔºåÊàëÂÄëËÉΩÂ§†ÊèêÂèñÂíåÂèçË¶ÜÊîπÂñÑË¶ñË¶∫ÊèêÁ§∫ÔºåÂ¢ûÂº∑È†êË®ìÁ∑¥ SAM ÁöÑÊïàËÉΩ„ÄÇÈÄôÈ†ÖÈÄ≤Â±ïÂú®ÈÜ´ÁôÇÈ†òÂüüÁâπÂà•ÊúâÊÑèÁæ©ÔºåÂõ†ÁÇ∫Â∞çÊñºÁº∫‰πèÈÜ´ÁôÇÂ∞àÊ•≠Áü•Ë≠òÁöÑ‰∫∫‰æÜË™™ÔºåÂª∫Á´ãË¶ñË¶∫ÊèêÁ§∫ÊúÉÊßãÊàêÈ°ØËëóÁöÑÊåëÊà∞„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÂêÑÁ®Æ 2D ÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñôÈõÜ‰∏äÂÑ™ÊñºÂêÑÁ®ÆÂü∫Á§éÊ®°ÂûãÂíåÂÖàÂâçÁöÑÂü∫Êñº SAM ÁöÑÊñπÊ≥ï„ÄÇ

##### **Why the Agent Made that Decision: Explaining Deep Reinforcement Learning with Vision Masks**
2411.16120v1 by Rui Zuo, Zifan Wang, Simon Khan, Garrett Ethan Katz, Qinru Qiu

Due to the inherent lack of transparency in deep neural networks, it is
challenging for deep reinforcement learning (DRL) agents to gain trust and
acceptance from users, especially in safety-critical applications such as
medical diagnosis and military operations. Existing methods for explaining an
agent's decision either require to retrain the agent using models that support
explanation generation or rely on perturbation-based techniques to reveal the
significance of different input features in the decision making process.
However, retraining the agent may compromise its integrity and performance,
while perturbation-based methods have limited performance and lack knowledge
accumulation or learning capabilities. Moreover, since each perturbation is
performed independently, the joint state of the perturbed inputs may not be
physically meaningful. To address these challenges, we introduce
$\textbf{VisionMask}$, a standalone explanation model trained end-to-end to
identify the most critical regions in the agent's visual input that can explain
its actions. VisionMask is trained in a self-supervised manner without relying
on human-generated labels. Importantly, its training does not alter the agent
model, hence preserving the agent's performance and integrity. We evaluate
VisionMask on Super Mario Bros (SMB) and three Atari games. Compared to
existing methods, VisionMask achieves a 14.9% higher insertion accuracy and a
30.08% higher F1-Score in reproducing original actions from the selected visual
explanations. We also present examples illustrating how VisionMask can be used
for counterfactual analysis.

ÊëòË¶ÅÔºö<paragraph>Áî±ÊñºÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÁº∫‰πèÈÄèÊòéÂ∫¶ÔºåÊ∑±Â∫¶Âº∑ÂåñÂ≠∏Áøí (DRL) ‰ª£ÁêÜÁ®ãÂºèË¶ÅÁç≤Âæó‰ΩøÁî®ËÄÖÁöÑ‰ø°‰ªªÂíåË™çÂèØÊòØ‰∏ÄÈ†ÖÊåëÊà∞ÔºåÁâπÂà•ÊòØÂú®ÂÆâÂÖ®ÈóúÈçµÁöÑÊáâÁî®Á®ãÂºè‰∏≠Ôºå‰æãÂ¶ÇÈÜ´ÁôÇË®∫Êñ∑ÂíåËªç‰∫ãË°åÂãï„ÄÇÁèæÊúâÁöÑÊñπÊ≥ïÁî®ÊñºËß£Èáã‰ª£ÁêÜÁ®ãÂºèÁöÑÊ±∫Á≠ñÔºåÈúÄË¶Å‰ΩøÁî®ÊîØÊè¥Ëß£ÈáãÁî¢ÁîüÁöÑÊ®°ÂûãÈáçÊñ∞Ë®ìÁ∑¥‰ª£ÁêÜÁ®ãÂºèÔºåÊàñ‰æùË≥¥ÊñºÂü∫ÊñºÊìæÂãïÁöÑÊäÄË°ì‰æÜÊè≠Á§∫‰∏çÂêåËº∏ÂÖ•ÁâπÂæµÂú®Ê±∫Á≠ñÂà∂ÂÆöÈÅéÁ®ã‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇÁÑ∂ËÄåÔºåÈáçÊñ∞Ë®ìÁ∑¥‰ª£ÁêÜÁ®ãÂºèÂèØËÉΩÊúÉÊêçÂÆ≥ÂÖ∂ÂÆåÊï¥ÊÄßÂíåÊïàËÉΩÔºåËÄåÂü∫ÊñºÊìæÂãïÁöÑÊñπÊ≥ïÊïàËÉΩÊúâÈôêÔºå‰∏îÁº∫‰πèÁü•Ë≠òÁ¥ØÁ©çÊàñÂ≠∏ÁøíËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÁî±ÊñºÊØèÂÄãÊìæÂãïÈÉΩÊòØÁç®Á´ãÂü∑Ë°åÁöÑÔºåÂõ†Ê≠§ÊìæÂãïËº∏ÂÖ•ÁöÑËÅØÂêàÁãÄÊÖãÂèØËÉΩÊ≤íÊúâÂØ¶ÈöõÊÑèÁæ©„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü $\textbf{VisionMask}$ÔºåÈÄôÊòØ‰∏ÄÂÄãÁç®Á´ãÁöÑËß£ÈáãÊ®°ÂûãÔºåÁ∂ìÈÅéÁ´ØÂ∞çÁ´ØÁöÑË®ìÁ∑¥Ôºå‰ª•Ë≠òÂà•‰ª£ÁêÜÁ®ãÂºèË¶ñË¶∫Ëº∏ÂÖ•‰∏≠ÊúÄÈóúÈçµÁöÑÂçÄÂüüÔºåÈÄô‰∫õÂçÄÂüüÂèØ‰ª•Ëß£ÈáãÂÖ∂Âãï‰Ωú„ÄÇVisionMask ‰ª•Ëá™Áõ£Áù£ÁöÑÊñπÂºèÈÄ≤Ë°åË®ìÁ∑¥ÔºåËÄå‰∏ç‰æùË≥¥Êñº‰∫∫ÁÇ∫Áî¢ÁîüÁöÑÊ®ôÁ±§„ÄÇÈáçË¶ÅÁöÑÊòØÔºåÂÖ∂Ë®ìÁ∑¥‰∏çÊúÉÊîπËÆä‰ª£ÁêÜÁ®ãÂºèÊ®°ÂûãÔºåÂõ†Ê≠§ÂèØ‰ª•‰øùÁïô‰ª£ÁêÜÁ®ãÂºèÁöÑÊïàËÉΩÂíåÂÆåÊï¥ÊÄß„ÄÇÊàëÂÄëÂú® Super Mario Bros (SMB) Âíå‰∏âÊ¨æ Atari ÈÅäÊà≤‰∏äË©ï‰º∞‰∫Ü VisionMask„ÄÇËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåVisionMask Âú®Ê†πÊìöÊâÄÈÅ∏ÁöÑË¶ñË¶∫Ëß£ÈáãË§áË£ΩÂéüÂßãÂãï‰ΩúÊôÇÔºåÊèíÂÖ•Ê∫ñÁ¢∫ÁéáÊèêÈ´ò‰∫Ü 14.9%ÔºåF1 ÂàÜÊï∏ÊèêÈ´ò‰∫Ü 30.08%„ÄÇÊàëÂÄëÈÇÑÊèê‰æõ‰∫ÜÁØÑ‰æã‰æÜË™™ÊòéÂ¶Ç‰Ωï‰ΩøÁî® VisionMask ÈÄ≤Ë°åÂèç‰∫ãÂØ¶ÂàÜÊûê„ÄÇ</paragraph>

##### **DRIVE: Dual-Robustness via Information Variability and Entropic Consistency in Source-Free Unsupervised Domain Adaptation**
2411.15976v1 by Ruiqiang Xiao, Songning Lai, Yijun Yang, Jiemin Wu, Yutao Yue, Lei Zhu

Adapting machine learning models to new domains without labeled data,
especially when source data is inaccessible, is a critical challenge in
applications like medical imaging, autonomous driving, and remote sensing. This
task, known as Source-Free Unsupervised Domain Adaptation (SFUDA), involves
adapting a pre-trained model to a target domain using only unlabeled target
data, which can lead to issues such as overfitting, underfitting, and poor
generalization due to domain discrepancies and noise. Existing SFUDA methods
often rely on single-model architectures, struggling with uncertainty and
variability in the target domain. To address these challenges, we propose DRIVE
(Dual-Robustness through Information Variability and Entropy), a novel SFUDA
framework leveraging a dual-model architecture. The two models, initialized
with identical weights, work in parallel to capture diverse target domain
characteristics. One model is exposed to perturbations via projection gradient
descent (PGD) guided by mutual information, focusing on high-uncertainty
regions. We also introduce an entropy-aware pseudo-labeling strategy that
adjusts label weights based on prediction uncertainty, ensuring the model
focuses on reliable data while avoiding noisy regions. The adaptation process
has two stages: the first aligns the models on stable features using a mutual
information consistency loss, and the second dynamically adjusts the
perturbation level based on the loss from the first stage, encouraging the
model to explore a broader range of the target domain while preserving existing
performance. This enhances generalization capabilities and robustness against
interference. Evaluations on standard SFUDA benchmarks show that DRIVE
consistently outperforms previous methods, delivering improved adaptation
accuracy and stability across complex target domains.

ÊëòË¶ÅÔºö<paragraph>Âú®Ê≤íÊúâÊ®ôÁ±§Ë≥áÊñôÁöÑÊÉÖÊ≥Å‰∏ãÂ∞áÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãË™øÊï¥Âà∞Êñ∞ÁöÑÈ†òÂüüÔºåÁâπÂà•ÊòØÂú®ÁÑ°Ê≥ïÂèñÂæóÂéüÂßãË≥áÊñôÊôÇÔºåÊòØÈÜ´ÁôÇÂΩ±ÂÉè„ÄÅËá™ÂãïÈßïÈßõÂíåÈÅôÊ∏¨Á≠âÊáâÁî®‰∏≠ÁöÑ‰∏ÄÈ†ÖÈóúÈçµÊåëÊà∞„ÄÇÈÄôÈ†Ö‰ªªÂãôÁ®±ÁÇ∫ÁÑ°‰æÜÊ∫êÈùûÁõ£Áù£È†òÂüüÈÅ©Êáâ (SFUDA)ÔºåÊ∂âÂèä‰ΩøÁî®ÂÉÖÊúâÁöÑÊú™Ê®ôÁ±§ÁõÆÊ®ôË≥áÊñôÂ∞áÈ†êÂÖàË®ìÁ∑¥ÁöÑÊ®°ÂûãË™øÊï¥Âà∞ÁõÆÊ®ôÈ†òÂüüÔºåÈÄôÂèØËÉΩÊúÉÂ∞éËá¥ÈÅéÂ∫¶Êì¨Âêà„ÄÅÊ¨†Êì¨ÂêàÂíåÂõ†È†òÂüüÂ∑ÆÁï∞ÂíåÈõúË®äËÄåÂ∞éËá¥ÁöÑÊ¶ÇÂåñ‰∏çËâØÁ≠âÂïèÈ°å„ÄÇÁèæÊúâÁöÑ SFUDA ÊñπÊ≥ïÈÄöÂ∏∏‰æùË≥¥ÊñºÂñÆ‰∏ÄÊ®°ÂûãÊû∂ÊßãÔºåÈõ£‰ª•ÊáâÂ∞çÁõÆÊ®ôÈ†òÂüü‰∏≠ÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÂíåËÆäÁï∞ÊÄß„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü DRIVEÔºàÈÄèÈÅéË≥áË®äËÆäÁï∞ÊÄßÂíåÁÜµÁöÑÈõôÈáçÁ©©ÂÅ•ÊÄßÔºâÔºå‰∏ÄÁ®ÆÂà©Áî®ÈõôÊ®°ÂûãÊû∂ÊßãÁöÑÊñ∞Á©é SFUDA Êû∂Êßã„ÄÇÈÄôÂÖ©ÂÄãÊ®°Âûã‰ª•Áõ∏ÂêåÁöÑÊ¨äÈáçÂàùÂßãÂåñÔºå‰∏¶Ë°åÂ∑•‰Ωú‰ª•Êì∑Âèñ‰∏çÂêåÁöÑÁõÆÊ®ôÈ†òÂüüÁâπÂæµ„ÄÇÂÖ∂‰∏≠‰∏ÄÂÄãÊ®°ÂûãÈÄèÈÅéÁî±‰∫íË≥áË®äÂºïÂ∞éÁöÑÊäïÂΩ±Ê¢ØÂ∫¶‰∏ãÈôç (PGD) Êö¥Èú≤ÊñºÊìæÂãïÔºåÈáçÈªûÂú®ÊñºÈ´òÂ∫¶‰∏çÁ¢∫ÂÆöÁöÑÂçÄÂüü„ÄÇÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÁÜµÊÑüÁü•ÂÅΩÊ®ôÁ±§Á≠ñÁï•ÔºåË©≤Á≠ñÁï•Ê†πÊìöÈ†êÊ∏¨‰∏çÁ¢∫ÂÆöÊÄßË™øÊï¥Ê®ôÁ±§Ê¨äÈáçÔºåÁ¢∫‰øùÊ®°ÂûãÂ∞àÊ≥®ÊñºÂèØÈù†ÁöÑË≥áÊñôÔºåÂêåÊôÇÈÅøÂÖçÈõúË®äÂçÄÂüü„ÄÇÈÅ©ÊáâÈÅéÁ®ãÂàÜÁÇ∫ÂÖ©ÂÄãÈöéÊÆµÔºöÁ¨¨‰∏ÄÂÄãÈöéÊÆµ‰ΩøÁî®‰∫íË≥áË®ä‰∏ÄËá¥ÊÄßÊêçÂ§±Âú®Á©©ÂÆöÁâπÂæµ‰∏äÂ∞çÈΩäÊ®°ÂûãÔºåÁ¨¨‰∫åÂÄãÈöéÊÆµÊ†πÊìöÁ¨¨‰∏ÄÂÄãÈöéÊÆµÁöÑÊêçÂ§±ÂãïÊÖãË™øÊï¥ÊìæÂãïÁ¥öÂà•ÔºåÈºìÂãµÊ®°ÂûãÊé¢Á¥¢ÁõÆÊ®ôÈ†òÂüüÁöÑÊõ¥Âª£Ê≥õÁØÑÂúçÔºåÂêåÊôÇ‰øùÁïôÁèæÊúâÁöÑÊïàËÉΩ„ÄÇÈÄôÂ¢ûÂº∑‰∫ÜÊ¶ÇÂåñËÉΩÂäõÂíåÂ∞çÂπ≤ÊìæÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÂú®Ê®ôÊ∫ñ SFUDA Âü∫Ê∫ñ‰∏äÁöÑË©ï‰º∞È°ØÁ§∫ÔºåDRIVE ÊåÅÁ∫åÂÑ™ÊñºÂÖàÂâçÁöÑÂêÑÁ®ÆÊñπÊ≥ïÔºåÂú®Ë§áÈõúÁöÑÁõÆÊ®ôÈ†òÂüü‰∏≠Êèê‰æõÊîπÂñÑÁöÑÈÅ©ÊáâÊ∫ñÁ¢∫ÊÄßÂíåÁ©©ÂÆöÊÄß„ÄÇ</paragraph>

##### **Medical Slice Transformer: Improved Diagnosis and Explainability on 3D Medical Images with DINOv2**
2411.15802v1 by Gustav M√ºller-Franzes, Firas Khader, Robert Siepmann, Tianyu Han, Jakob Nikolas Kather, Sven Nebelung, Daniel Truhn

MRI and CT are essential clinical cross-sectional imaging techniques for
diagnosing complex conditions. However, large 3D datasets with annotations for
deep learning are scarce. While methods like DINOv2 are encouraging for 2D
image analysis, these methods have not been applied to 3D medical images.
Furthermore, deep learning models often lack explainability due to their
"black-box" nature. This study aims to extend 2D self-supervised models,
specifically DINOv2, to 3D medical imaging while evaluating their potential for
explainable outcomes. We introduce the Medical Slice Transformer (MST)
framework to adapt 2D self-supervised models for 3D medical image analysis. MST
combines a Transformer architecture with a 2D feature extractor, i.e., DINOv2.
We evaluate its diagnostic performance against a 3D convolutional neural
network (3D ResNet) across three clinical datasets: breast MRI (651 patients),
chest CT (722 patients), and knee MRI (1199 patients). Both methods were tested
for diagnosing breast cancer, predicting lung nodule dignity, and detecting
meniscus tears. Diagnostic performance was assessed by calculating the Area
Under the Receiver Operating Characteristic Curve (AUC). Explainability was
evaluated through a radiologist's qualitative comparison of saliency maps based
on slice and lesion correctness. P-values were calculated using Delong's test.
MST achieved higher AUC values compared to ResNet across all three datasets:
breast (0.94$\pm$0.01 vs. 0.91$\pm$0.02, P=0.02), chest (0.95$\pm$0.01 vs.
0.92$\pm$0.02, P=0.13), and knee (0.85$\pm$0.04 vs. 0.69$\pm$0.05, P=0.001).
Saliency maps were consistently more precise and anatomically correct for MST
than for ResNet. Self-supervised 2D models like DINOv2 can be effectively
adapted for 3D medical imaging using MST, offering enhanced diagnostic accuracy
and explainability compared to convolutional neural networks.

ÊëòË¶ÅÔºö<paragraph>MRI Âíå CT ÊòØËØäÊñ≠Â§çÊùÇÁñæÁóÖÁöÑÈáçË¶Å‰∏¥Â∫äÊ®™Êñ≠Èù¢ÊàêÂÉèÊäÄÊúØ„ÄÇÁÑ∂ËÄåÔºåÁî®‰∫éÊ∑±Â∫¶Â≠¶‰π†ÁöÑÂ§ßÂûã 3D Êï∞ÊçÆÈõÜÂíåÊ≥®ÈáäÂç¥ÂæàÁ®ÄÁº∫„ÄÇËôΩÁÑ∂ËØ∏Â¶Ç DINOv2 ‰πãÁ±ªÁöÑÊñπÊ≥ïÂØπ 2D ÂõæÂÉèÂàÜÊûêÂæàÊúâÂ∏ÆÂä©Ôºå‰ΩÜËøô‰∫õÊñπÊ≥ïÂ∞öÊú™Â∫îÁî®‰∫é 3D ÂåªÂ≠¶ÂõæÂÉè„ÄÇÊ≠§Â§ñÔºåÊ∑±Â∫¶Â≠¶‰π†Ê®°ÂûãÈÄöÂ∏∏Áº∫‰πèÂèØËß£ÈáäÊÄßÔºåÂõ†‰∏∫ÂÆÉ‰ª¨ÂÖ∑Êúâ‚ÄúÈªëÂå£Â≠ê‚ÄùÁöÑÊÄßË¥®„ÄÇÊú¨Á†îÁ©∂Êó®Âú®Â∞Ü 2D Ëá™ÁõëÁù£Ê®°ÂûãÔºàÁâπÂà´ÊòØ DINOv2ÔºâÊâ©Â±ïÂà∞ 3D ÂåªÂ≠¶ÊàêÂÉèÔºåÂêåÊó∂ËØÑ‰º∞ÂÖ∂ÂØπÂèØËß£ÈáäÁªìÊûúÁöÑÊΩúÂäõ„ÄÇÊàë‰ª¨ÂºïÂÖ•‰∫ÜÂåªÂ≠¶ÂàáÁâáËΩ¨Êç¢Âô® (MST) Ê°ÜÊû∂Ôºå‰ª•Â∞Ü 2D Ëá™ÁõëÁù£Ê®°ÂûãÁî®‰∫é 3D ÂåªÂ≠¶ÂõæÂÉèÂàÜÊûê„ÄÇMST Â∞Ü Transformer Êû∂ÊûÑ‰∏é 2D ÁâπÂæÅÊèêÂèñÂô®ÔºàÂç≥ DINOv2ÔºâÁõ∏ÁªìÂêà„ÄÇÊàë‰ª¨ËØÑ‰º∞‰∫ÜÂÖ∂ÈíàÂØπ‰∏â‰∏™‰∏¥Â∫äÊï∞ÊçÆÈõÜÔºà‰π≥ËÖ∫ MRIÔºà651 ÂêçÊÇ£ËÄÖÔºâ„ÄÅËÉ∏ÈÉ® CTÔºà722 ÂêçÊÇ£ËÄÖÔºâÂíåËÜùÈÉ® MRIÔºà1199 ÂêçÊÇ£ËÄÖÔºâÔºâÁöÑËØäÊñ≠ÊÄßËÉΩÔºå‰∏é 3D Âç∑ÁßØÁ•ûÁªèÁΩëÁªú (3D ResNet) ËøõË°å‰∫ÜÂØπÊØî„ÄÇ‰∏§ÁßçÊñπÊ≥ïÂùáÁªèËøáÊµãËØïÔºåÁî®‰∫éËØäÊñ≠‰π≥ËÖ∫Áôå„ÄÅÈ¢ÑÊµãËÇ∫ÁªìËäÇÊÄßË¥®ÂíåÊ£ÄÊµãÂçäÊúàÊùøÊíïË£Ç„ÄÇÈÄöËøáËÆ°ÁÆóÂèóËØïËÄÖÂ∑•‰ΩúÁâπÂæÅÊõ≤Á∫ø‰∏ãÈù¢ÁßØ (AUC) Êù•ËØÑ‰º∞ËØäÊñ≠ÊÄßËÉΩ„ÄÇÂèØËß£ÈáäÊÄßÈÄöËøáÊîæÂ∞ÑÁßëÂåªÁîüÂØπÂü∫‰∫éÂàáÁâáÂíåÁóÖÂèòÊ≠£Á°ÆÊÄßÁöÑÊòæÁùÄÊÄßÂõæÁöÑÂÆöÊÄßÊØîËæÉÊù•ËØÑ‰º∞„ÄÇP ÂÄº‰ΩøÁî® Delong ÁöÑÊ£ÄÈ™åËÆ°ÁÆó„ÄÇ‰∏éÊâÄÊúâ‰∏â‰∏™Êï∞ÊçÆÈõÜ‰∏≠ÁöÑ ResNet Áõ∏ÊØîÔºåMST Ëé∑Âæó‰∫ÜÊõ¥È´òÁöÑ AUC ÂÄºÔºö‰π≥ËÖ∫Ôºà0.94¬±0.01 vs. 0.91¬±0.02ÔºåP=0.02Ôºâ„ÄÅËÉ∏ÈÉ®Ôºà0.95¬±0.01 vs. 0.92¬±0.02ÔºåP=0.13ÔºâÂíåËÜùÈÉ®Ôºà0.85¬±0.04 vs. 0.69¬±0.05ÔºåP=0.001Ôºâ„ÄÇ‰∏é ResNet Áõ∏ÊØîÔºåMST ÁöÑÊòæÁùÄÊÄßÂõæÂßãÁªàÊõ¥Âä†Á≤æÁ°Æ‰∏îËß£ÂâñÂ≠¶‰∏äÊõ¥Ê≠£Á°Æ„ÄÇËØ∏Â¶Ç DINOv2 ‰πãÁ±ªÁöÑËá™ÁõëÁù£ 2D Ê®°ÂûãÂèØ‰ª•‰ΩøÁî® MST ÊúâÊïàÂú∞ÈÄÇÂ∫î 3D ÂåªÂ≠¶ÊàêÂÉèÔºå‰∏éÂç∑ÁßØÁ•ûÁªèÁΩëÁªúÁõ∏ÊØîÔºåÊèê‰æõ‰∫ÜÂ¢ûÂº∫ÁöÑËØäÊñ≠ÂáÜÁ°ÆÊÄßÂíåÂèØËß£ÈáäÊÄß„ÄÇ</paragraph>

##### **Enhancing the automatic segmentation and analysis of 3D liver vasculature models**
2411.15778v1 by Yassine Machta, Omar Ali, Kevin Hakkakian, Ana Vlascenau, Amaury Facque, Nicolas Golse, Irene Vignon-Clementel

Surgical assessment of liver cancer patients requires identification of the
vessel trees from medical images. Specifically, the venous trees - the portal
(perfusing) and the hepatic (draining) trees are important for understanding
the liver anatomy and disease state, and perform surgery planning. This
research aims to improve the 3D segmentation, skeletonization, and subsequent
analysis of vessel trees, by creating an automatic pipeline based on deep
learning and image processing techniques.
  The first part of this work explores the impact of differentiable
skeletonization methods such as ClDice and morphological skeletonization loss,
on the overall liver vessel segmentation performance. To this aim, it studies
how to improve vessel tree connectivity.
  The second part of this study converts a single class vessel segmentation
into multi-class ones, separating the two venous trees. It builds on the
previous two-class vessel segmentation model, which vessel tree outputs might
be entangled, and on connected components and skeleton analyses of the trees.
  After providing sub-labeling of the specific anatomical branches of each
venous tree, these algorithms also enable a morphometric analysis of the vessel
trees by extracting various geometrical markers.
  In conclusion, we propose a method that successfully improves current
skeletonization methods, for extensive vascular trees that contain vessels of
different calibers. The separation algorithm creates a clean multi-class
segmentation of the vessels, validated by surgeons to provide low error. A new,
publicly shared high-quality liver vessel dataset of 77 cases is thus created.
Finally a method to annotate vessel trees according to anatomy is provided,
enabling a unique liver vessel morphometry analysis.

ÊëòË¶ÅÔºöËÇùÁôåÁóÖÊÇ£ÁöÑÂ§ñÁßëË©ï‰º∞ÈúÄË¶ÅÂæûÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠Ëæ®Ë≠òË°ÄÁÆ°Ê®π„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÈùúËÑàÊ®π - ÈñÄÈùúËÑàÔºàÁÅåÊµÅÔºâÂíåËÇùÈùúËÑàÔºàÂºïÊµÅÔºâÊ®πÂ∞çÊñº‰∫ÜËß£ËÇùËáüËß£ÂâñÁµêÊßãÂíåÁñæÁóÖÁãÄÊÖã‰ª•ÂèäÈÄ≤Ë°åÊâãË°ìË¶èÂäÉÈùûÂ∏∏ÈáçË¶Å„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Êó®Âú®ÈÄèÈÅéÂª∫Á´ãÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÂíåÂΩ±ÂÉèËôïÁêÜÊäÄË°ìÁöÑËá™ÂãïÂåñÊµÅÁ®ãÔºåÊîπÂñÑË°ÄÁÆ°Ê®πÁöÑ 3D ÂàÜÂâ≤„ÄÅÈ™®Êû∂ÂåñÂíåÂæåÁ∫åÂàÜÊûê„ÄÇ
ÈÄôÈ†ÖÂ∑•‰ΩúÁöÑÈ¶ñË¶ÅÈÉ®ÂàÜÊé¢Ë®éÂèØÂæÆÂàÜÈ™®Êû∂ÂåñÊñπÊ≥ïÔºà‰æãÂ¶Ç ClDice ÂíåÂΩ¢ÊÖãÈ™®Êû∂ÂåñÊêçÂ§±ÔºâÂ∞çÊï¥È´îËÇùËáüË°ÄÁÆ°ÂàÜÂâ≤ÊïàËÉΩÁöÑÂΩ±Èüø„ÄÇÁÇ∫Ê≠§ÔºåÂÆÉÁ†îÁ©∂Â¶Ç‰ΩïÊîπÂñÑË°ÄÁÆ°Ê®πÈÄ£ÈÄöÊÄß„ÄÇ
ÈÄôÈ†ÖÁ†îÁ©∂ÁöÑÁ¨¨‰∫åÈÉ®ÂàÜÂ∞áÂñÆ‰∏ÄÈ°ûÂà•ÁöÑË°ÄÁÆ°ÂàÜÂâ≤ËΩâÊèõÁÇ∫Â§öÈ°ûÂà•Ôºå‰ª•ÂçÄÂàÜÂÖ©ÂÄãÈùúËÑàÊ®π„ÄÇÂÆÉÂª∫Á´ãÂú®Ââç‰∏ÄÂÄãÈõôÈ°ûÂà•Ë°ÄÁÆ°ÂàÜÂâ≤Ê®°ÂûãÁöÑÂü∫Á§é‰∏äÔºåË©≤Ê®°ÂûãÁöÑË°ÄÁÆ°Ê®πËº∏Âá∫ÂèØËÉΩÁ≥æÁ∫èÂú®‰∏ÄËµ∑Ôºå‰∏¶Âª∫Á´ãÂú®Ê®πÁöÑÈÄ£ÈÄöÂÖÉ‰ª∂ÂíåÈ™®Êû∂ÂàÜÊûêÁöÑÂü∫Á§é‰∏ä„ÄÇ
Âú®Â∞çÊØèÂÄãÈùúËÑàÊ®πÁöÑÁâπÂÆöËß£ÂâñÂàÜÊîØÈÄ≤Ë°åÊ¨°Ê®ôË®òÂæåÔºåÈÄô‰∫õÊºîÁÆóÊ≥ïÈÇÑËÉΩÈÄèÈÅéËêÉÂèñÂêÑÁ®ÆÂπæ‰ΩïÊ®ôË®ò‰æÜÂ∞çË°ÄÁÆ°Ê®πÈÄ≤Ë°åÂΩ¢ÊÖãË®àÈáèÂàÜÊûê„ÄÇ
ÁµêË´ñ‰æÜË™™ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåÂèØÊàêÂäüÊîπÂñÑÁõÆÂâçÁöÑÈ™®Êû∂ÂåñÊñπÊ≥ïÔºå‰ª•ÈÅ©Áî®ÊñºÂåÖÂê´‰∏çÂêåÂè£ÂæëË°ÄÁÆ°ÁöÑÂª£Ê≥õË°ÄÁÆ°Ê®π„ÄÇÂàÜÈõ¢ÊºîÁÆóÊ≥ïÊúÉÂª∫Á´ãË°ÄÁÆ°ÁöÑ‰πæÊ∑®Â§öÈ°ûÂà•ÂàÜÂâ≤ÔºåÁ∂ìÁî±Â§ñÁßëÈÜ´ÁîüÈ©óË≠â‰ª•Êèê‰æõ‰ΩéË™§Â∑Æ„ÄÇÂõ†Ê≠§Âª∫Á´ã‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑ„ÄÅÂÖ¨ÈñãÂÖ±‰∫´ÁöÑÈ´òÂìÅË≥™ 77 ÂÄãÁóÖ‰æãËÇùËáüË°ÄÁÆ°Ë≥áÊñôÈõÜ„ÄÇÊúÄÂæåÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊ†πÊìöËß£ÂâñÁµêÊßãË®ªËß£Ë°ÄÁÆ°Ê®πÁöÑÊñπÊ≥ïÔºåÂèØÈÄ≤Ë°åÁç®ÁâπÁöÑËÇùËáüË°ÄÁÆ°ÂΩ¢ÊÖãË®àÈáèÂàÜÊûê„ÄÇ

##### **RAMIE: Retrieval-Augmented Multi-task Information Extraction with Large Language Models on Dietary Supplements**
2411.15700v1 by Zaifu Zhan, Shuang Zhou, Mingchen Li, Rui Zhang

\textbf{Objective:} We aimed to develop an advanced multi-task large language
model (LLM) framework to extract multiple types of information about dietary
supplements (DS) from clinical records.
  \textbf{Methods:} We used four core DS information extraction tasks - namely,
named entity recognition (NER: 2,949 clinical sentences), relation extraction
(RE: 4,892 sentences), triple extraction (TE: 2,949 sentences), and usage
classification (UC: 2,460 sentences) as our multitasks. We introduced a novel
Retrieval-Augmented Multi-task Information Extraction (RAMIE) Framework,
including: 1) employed instruction fine-tuning techniques with task-specific
prompts, 2) trained LLMs for multiple tasks with improved storage efficiency
and lower training costs, and 3) incorporated retrieval augmentation generation
(RAG) techniques by retrieving similar examples from the training set. We
compared RAMIE's performance to LLMs with instruction fine-tuning alone and
conducted an ablation study to assess the contributions of multi-task learning
and RAG to improved multitasking performance.
  \textbf{Results:} With the aid of the RAMIE framework, Llama2-13B achieved an
F1 score of 87.39 (3.51\% improvement) on the NER task and demonstrated
outstanding performance on the RE task with an F1 score of 93.74 (1.15\%
improvement). For the TE task, Llama2-7B scored 79.45 (14.26\% improvement),
and MedAlpaca-7B achieved the highest F1 score of 93.45 (0.94\% improvement) on
the UC task. The ablation study revealed that while MTL increased efficiency
with a slight trade-off in performance, RAG significantly boosted overall
accuracy.
  \textbf{Conclusion:} This study presents a novel RAMIE framework that
demonstrates substantial improvements in multi-task information extraction for
DS-related data from clinical records. Our framework can potentially be applied
to other domains.

ÊëòË¶ÅÔºö<paragraph>**ÁõÆÁöÑÔºö**ÊàëÂÄëÊó®Âú®ÈñãÁôº‰∏ÄÂÄãÂÖàÈÄ≤ÁöÑÂ§ö‰ªªÂãôÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êû∂ÊßãÔºåÂæûËá®Â∫äË®òÈåÑ‰∏≠ÊèêÂèñÂ§öÁ®ÆÈ°ûÂûãÁöÑËÜ≥È£üË£úÂÖÖÂìÅ (DS) Ë≥áË®ä„ÄÇ
**ÊñπÊ≥ïÔºö**ÊàëÂÄë‰ΩøÁî®‰∫ÜÂõõÈ†ÖÊ†∏ÂøÉ DS Ë≥áË®äÊèêÂèñ‰ªªÂãôÔºåÂç≥ÂëΩÂêçÂØ¶È´îË≠òÂà• (NERÔºö2,949 ÂÄãËá®Â∫äÂè•Â≠ê)„ÄÅÈóú‰øÇÊèêÂèñ (REÔºö4,892 ÂÄãÂè•Â≠ê)„ÄÅ‰∏âÂÖÉÁµÑÊèêÂèñ (TEÔºö2,949 ÂÄãÂè•Â≠ê) Âíå‰ΩøÁî®ÂàÜÈ°û (UCÔºö2,460 ÂÄãÂè•Â≠ê) ‰ΩúÁÇ∫ÊàëÂÄëÁöÑÂ§ö‰ªªÂãô„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÊ™¢Á¥¢Â¢ûÂº∑Â§ö‰ªªÂãôË≥áË®äÊèêÂèñ (RAMIE) Êû∂ÊßãÔºåÂåÖÊã¨Ôºö1) ‰ΩøÁî®‰ªªÂãôÁâπÂÆöÊèêÁ§∫ÁöÑÊåá‰ª§ÂæÆË™øÊäÄË°ìÔºå2) ‰ª•Êõ¥È´òÁöÑÂÑ≤Â≠òÊïàÁéáÂíåÊõ¥‰ΩéÁöÑË®ìÁ∑¥ÊàêÊú¨Ë®ìÁ∑¥Â§ö‰ªªÂãôÁöÑ LLMÔºå‰ª•Âèä 3) ÈÄöÈÅéÂæûË®ìÁ∑¥ÈõÜ‰∏≠Ê™¢Á¥¢È°û‰ººÁØÑ‰æãÔºåÊï¥ÂêàÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÊäÄË°ì„ÄÇÊàëÂÄëÂ∞á RAMIE ÁöÑÊïàËÉΩËàáÂÉÖ‰ΩøÁî®Êåá‰ª§ÂæÆË™øÁöÑ LLM ÈÄ≤Ë°åÊØîËºÉÔºå‰∏¶ÈÄ≤Ë°åÊ∂àËûçÁ†îÁ©∂ÔºåË©ï‰º∞Â§ö‰ªªÂãôÂ≠∏ÁøíÂíå RAG Â∞çÊîπÂñÑÂ§ö‰ªªÂãôÊïàËÉΩÁöÑË≤¢Áçª„ÄÇ
**ÁµêÊûúÔºö**Âú® RAMIE Êû∂ÊßãÁöÑÂπ´Âä©‰∏ãÔºåLlama2-13B Âú® NER ‰ªªÂãô‰∏äÂèñÂæó‰∫Ü 87.39 ÁöÑ F1 ÂàÜÊï∏ÔºàÊèêÂçá‰∫Ü 3.51%ÔºâÔºå‰∏¶Âú® RE ‰ªªÂãô‰∏äË°®ÁèæÂá∫Ëâ≤ÔºåF1 ÂàÜÊï∏ÁÇ∫ 93.74ÔºàÊèêÂçá‰∫Ü 1.15%Ôºâ„ÄÇÂ∞çÊñº TE ‰ªªÂãôÔºåLlama2-7B ÂæóÂàÜÁÇ∫ 79.45ÔºàÊèêÂçá‰∫Ü 14.26%ÔºâÔºåËÄå MedAlpaca-7B Âú® UC ‰ªªÂãô‰∏äÂèñÂæó‰∫ÜÊúÄÈ´òÁöÑ F1 ÂàÜÊï∏ 93.45ÔºàÊèêÂçá‰∫Ü 0.94%Ôºâ„ÄÇÊ∂àËûçÁ†îÁ©∂Ë°®ÊòéÔºåÂÑòÁÆ° MTL ‰ª•Áï•ÂæÆÁäßÁâ≤ÊïàËÉΩÁÇ∫‰ª£ÂÉπÊèêÈ´ò‰∫ÜÊïàÁéáÔºå‰ΩÜ RAG È°ØËëóÊèêÂçá‰∫ÜÊï¥È´îÊ∫ñÁ¢∫Â∫¶„ÄÇ
**ÁµêË´ñÔºö**Êú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑ RAMIE Êû∂ÊßãÔºåÂ±ïÁ§∫‰∫ÜÂæûËá®Â∫äË®òÈåÑ‰∏≠ÊèêÂèñËàá DS Áõ∏ÈóúË≥áÊñôÁöÑÂ§ö‰ªªÂãôË≥áË®äÁöÑÈ°ØËëóÊîπÈÄ≤„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÊúâÂèØËÉΩÊáâÁî®ÊñºÂÖ∂‰ªñÈ†òÂüü„ÄÇ</paragraph>

##### **Ontology-Constrained Generation of Domain-Specific Clinical Summaries**
2411.15666v1 by Gaya Mehenni, Amal Zouaq

Large Language Models (LLMs) offer promising solutions for text
summarization. However, some domains require specific information to be
available in the summaries. Generating these domain-adapted summaries is still
an open challenge. Similarly, hallucinations in generated content is a major
drawback of current approaches, preventing their deployment. This study
proposes a novel approach that leverages ontologies to create domain-adapted
summaries both structured and unstructured. We employ an ontology-guided
constrained decoding process to reduce hallucinations while improving
relevance. When applied to the medical domain, our method shows potential in
summarizing Electronic Health Records (EHRs) across different specialties,
allowing doctors to focus on the most relevant information to their domain.
Evaluation on the MIMIC-III dataset demonstrates improvements in generating
domain-adapted summaries of clinical notes and hallucination reduction.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁÇ∫ÊñáÂ≠óÊëòË¶ÅÊèê‰æõ‰∫ÜÊúâÂâçÊôØÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÁÑ∂ËÄåÔºåÊüê‰∫õÈ†òÂüüÈúÄË¶ÅÊëòË¶Å‰∏≠Êèê‰æõÁâπÂÆöË≥áË®ä„ÄÇÁî¢ÁîüÈÄô‰∫õÈ†òÂüüÈÅ©ÊáâÂûãÊëòË¶Å‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÂÖ¨ÈñãÊåëÊà∞„ÄÇÂêåÊ®£Âú∞ÔºåÁî¢ÁîüÂºèÂÖßÂÆπ‰∏≠ÁöÑÂπªË¶∫ÊòØÁï∂ÂâçÊñπÊ≥ïÁöÑ‰∏ÄÂ§ßÁº∫ÈªûÔºåÈòªÁ§ô‰∫ÜÂÆÉÂÄëÁöÑÈÉ®ÁΩ≤„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÂà©Áî®Êú¨‰ΩìË´ñ‰æÜÂª∫Á´ãÁµêÊßãÂåñÂíåÈùûÁµêÊßãÂåñÁöÑÈ†òÂüüÈÅ©ÊáâÂûãÊëòË¶Å„ÄÇÊàëÂÄëÊé°Áî®Êú¨‰ΩìË´ñÂºïÂ∞éÁ¥ÑÊùüÂºèËß£Á¢ºÁ®ãÂ∫èÔºå‰ª•Ê∏õÂ∞ëÂπªË¶∫ÔºåÂêåÊôÇÊèêÈ´òÁõ∏ÈóúÊÄß„ÄÇÁï∂ÊáâÁî®ÊñºÈÜ´Â≠∏È†òÂüüÊôÇÔºåÊàëÂÄëÁöÑÈÄôÈ†ÖÊñπÊ≥ïÈ°ØÁ§∫‰∫ÜË∑®‰∏çÂêåÂ∞àÊ•≠È†òÂüüÊëòË¶ÅÈõªÂ≠êÂÅ•Â∫∑Ë®òÈåÑ (EHR) ÁöÑÊΩõÂäõÔºåËÆìÈÜ´ÁîüÂèØ‰ª•Â∞àÊ≥®ÊñºËàáÂÖ∂È†òÂüüÊúÄÁõ∏ÈóúÁöÑË≥áË®ä„ÄÇÂú® MIMIC-III Ë≥áÊñôÈõÜ‰∏äÁöÑË©ï‰º∞Ë≠âÊòéÔºåÂú®Áî¢ÁîüËá®Â∫äÁ≠ÜË®òÁöÑÈ†òÂüüÈÅ©ÊáâÂûãÊëòË¶ÅÂíåÊ∏õÂ∞ëÂπªË¶∫ÊñπÈù¢ÈÉΩÊúâÊâÄÊîπÈÄ≤„ÄÇ

##### **A Survey on LLM-as-a-Judge**
2411.15594v1 by Jiawei Gu, Xuhui Jiang, Zhichao Shi, Hexiang Tan, Xuehao Zhai, Chengjin Xu, Wei Li, Yinghan Shen, Shengjie Ma, Honghao Liu, Yuanzhuo Wang, Jian Guo

Accurate and consistent evaluation is crucial for decision-making across
numerous fields, yet it remains a challenging task due to inherent
subjectivity, variability, and scale. Large Language Models (LLMs) have
achieved remarkable success across diverse domains, leading to the emergence of
"LLM-as-a-Judge," where LLMs are employed as evaluators for complex tasks. With
their ability to process diverse data types and provide scalable,
cost-effective, and consistent assessments, LLMs present a compelling
alternative to traditional expert-driven evaluations. However, ensuring the
reliability of LLM-as-a-Judge systems remains a significant challenge that
requires careful design and standardization. This paper provides a
comprehensive survey of LLM-as-a-Judge, addressing the core question: How can
reliable LLM-as-a-Judge systems be built? We explore strategies to enhance
reliability, including improving consistency, mitigating biases, and adapting
to diverse assessment scenarios. Additionally, we propose methodologies for
evaluating the reliability of LLM-as-a-Judge systems, supported by a novel
benchmark designed for this purpose. To advance the development and real-world
deployment of LLM-as-a-Judge systems, we also discussed practical applications,
challenges, and future directions. This survey serves as a foundational
reference for researchers and practitioners in this rapidly evolving field.

ÊëòË¶ÅÔºö<paragraph>Ê∫ñÁ¢∫‰∏î‰∏ÄËá¥ÁöÑË©ï‰º∞Â∞çÊñºÂêÑÈ†òÂüüÁöÑÊ±∫Á≠ñÂà∂ÂÆöËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÁî±ÊñºÂõ∫ÊúâÁöÑ‰∏ªËßÄÊÄß„ÄÅËÆäÁï∞ÊÄßÂíåË¶èÊ®°ÔºåÈÄô‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãô„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®‰∏çÂêåÈ†òÂüüÂèñÂæóÈ°ØËëóÊàêÂäüÔºåÂ∞éËá¥„ÄåLLM ‰ΩúÁÇ∫Ë©ïÂØ©„ÄçÁöÑÂá∫ÁèæÔºåÂÖ∂‰∏≠ LLM Ë¢´Áî®‰ΩúË§áÈõú‰ªªÂãôÁöÑË©ï‰º∞ËÄÖ„ÄÇÊÜëËóâËôïÁêÜÂêÑÁ®ÆÊï∏ÊìöÈ°ûÂûã‰∏¶Êèê‰æõÂèØÊì¥ÂÖÖ„ÄÅÁ∂ìÊøüÈ´òÊïà‰∏î‰∏ÄËá¥ÁöÑË©ï‰º∞ÁöÑËÉΩÂäõÔºåLLM ÁÇ∫ÂÇ≥Áµ±ÁöÑÂ∞àÂÆ∂È©ÖÂãïË©ï‰º∞Êèê‰æõ‰∫Ü‰ª§‰∫∫‰ø°ÊúçÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇÁÑ∂ËÄåÔºåÁ¢∫‰øù LLM ‰ΩúÁÇ∫Ë©ïÂØ©Á≥ªÁµ±ÁöÑÂèØÈù†ÊÄß‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÈáçÂ§ßÊåëÊà∞ÔºåÈúÄË¶Å‰ªîÁ¥∞Ë®≠Ë®àÂíåÊ®ôÊ∫ñÂåñ„ÄÇÊú¨ÊñáÂ∞ç LLM ‰ΩúÁÇ∫Ë©ïÂØ©ÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑË™øÊü•ÔºåËß£Ê±∫‰∫ÜÊ†∏ÂøÉÂïèÈ°åÔºöÂ¶Ç‰ΩïÊßãÂª∫ÂèØÈù†ÁöÑ LLM ‰ΩúÁÇ∫Ë©ïÂØ©Á≥ªÁµ±ÔºüÊàëÂÄëÊé¢Ë®é‰∫ÜÊèêÈ´òÂèØÈù†ÊÄßÁöÑÁ≠ñÁï•ÔºåÂåÖÊã¨ÊèêÈ´ò‰∏ÄËá¥ÊÄß„ÄÅÊ∏õËºïÂÅèÂ∑ÆÂíåÈÅ©Êáâ‰∏çÂêåÁöÑË©ï‰º∞Â†¥ÊôØ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫ÜË©ï‰º∞ LLM ‰ΩúÁÇ∫Ë©ïÂØ©Á≥ªÁµ±ÂèØÈù†ÊÄßÁöÑÊñπÊ≥ïÔºå‰∏¶Áî±ÁÇ∫Ê≠§ÁõÆÁöÑË®≠Ë®àÁöÑÊñ∞Âü∫Ê∫ñÊ∏¨Ë©¶Êèê‰æõÊîØÊåÅ„ÄÇÁÇ∫‰∫ÜÊé®ÈÄ≤ LLM ‰ΩúÁÇ∫Ë©ïÂØ©Á≥ªÁµ±ÁöÑÈñãÁôºÂíåÂØ¶ÈöõÈÉ®ÁΩ≤ÔºåÊàëÂÄëÈÇÑË®éË´ñ‰∫ÜÂØ¶ÈöõÊáâÁî®„ÄÅÊåëÊà∞ÂíåÊú™‰æÜÊñπÂêë„ÄÇÊú¨Ë™øÊü•‰ΩúÁÇ∫Ë©≤Âø´ÈÄüÁôºÂ±ïÈ†òÂüüÁöÑÁ†îÁ©∂‰∫∫Âì°ÂíåÂæûÊ•≠‰∫∫Âì°ÁöÑÂü∫Êú¨ÂèÉËÄÉ„ÄÇ</paragraph>

##### **Large Language Model with Region-guided Referring and Grounding for CT Report Generation**
2411.15539v1 by Zhixuan Chen, Yequan Bie, Haibo Jin, Hao Chen

Computed tomography (CT) report generation is crucial to assist radiologists
in interpreting CT volumes, which can be time-consuming and labor-intensive.
Existing methods primarily only consider the global features of the entire
volume, making it struggle to focus on specific regions and potentially missing
abnormalities. To address this issue, we propose Reg2RG, the first
region-guided referring and grounding framework for CT report generation, which
enhances diagnostic performance by focusing on anatomical regions within the
volume. Specifically, we utilize masks from a universal segmentation module to
capture local features for each referring region. A local feature decoupling
(LFD) strategy is proposed to preserve the local high-resolution details with
little computational overhead. Then the local features are integrated with
global features to capture inter-regional relationships within a cohesive
context. Moreover, we propose a novel region-report alignment (RRA) training
strategy. It leverages the recognition of referring regions to guide the
generation of region-specific reports, enhancing the model's referring and
grounding capabilities while also improving the report's interpretability. A
large language model (LLM) is further employed as the language decoder to
generate reports from integrated visual features, facilitating region-level
comprehension. Extensive experiments on two large-scale chest CT-report
datasets demonstrate the superiority of our method, which outperforms several
state-of-the-art methods in terms of both natural language generation and
clinical efficacy metrics while preserving promising interpretability. The code
will be made publicly available.

ÊëòË¶ÅÔºöÈõªËÖ¶Êñ∑Â±§ÊéÉÊèè (CT) Â†±ÂëäÁîüÊàêÂ∞çÊñºÂçîÂä©ÊîæÂ∞ÑÁßëÈÜ´Â∏´Âà§ËÆÄ CT ÂΩ±ÂÉèÈ´îÁ©çËá≥ÈóúÈáçË¶ÅÔºåËÄåÈÄôÈ†ÖÂ∑•‰ΩúÂèØËÉΩËÄóÊôÇ‰∏îË≤ªÂäõ„ÄÇÁèæÊúâÊñπÊ≥ï‰∏ªË¶ÅÂè™ËÄÉÈáèÊï¥ÂÄãÂΩ±ÂÉèÈ´îÁ©çÁöÑÂÖ®Â±ÄÁâπÂæµÔºåÂ∞éËá¥Èõ£‰ª•ËÅöÁÑ¶ÊñºÁâπÂÆöÂçÄÂüüÔºå‰∏¶ÂèØËÉΩÈÅ∫ÊºèÁï∞Â∏∏„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫ Reg2RGÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÈáùÂ∞ç CT Â†±ÂëäÁîüÊàêÁöÑÂçÄÂüüÂºïÂ∞éÂèÉÁÖßÂíåÂü∫Á§éÊû∂ÊßãÔºåÈÄèÈÅéËÅöÁÑ¶ÊñºÂΩ±ÂÉèÈ´îÁ©çÂÖßÁöÑËß£ÂâñÂçÄÂüüÔºå‰æÜÂ¢ûÂº∑Ë®∫Êñ∑ÊïàËÉΩ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂà©Áî®ÈÄöÁî®ÂàÜÂâ≤Ê®°ÁµÑ‰∏≠ÁöÑÈÅÆÁΩ©Ôºå‰æÜÊì∑ÂèñÊØèÂÄãÂèÉÁÖßÂçÄÂüüÁöÑÂ±ÄÈÉ®ÁâπÂæµ„ÄÇÊàëÂÄëÊèêÂá∫Â±ÄÈÉ®ÁâπÂæµËß£ËÄ¶ (LFD) Á≠ñÁï•Ôºå‰ª•Âú®ÈÅãÁÆóË≤†Êìî‰∏çÂ§ßÁöÑÊÉÖÊ≥Å‰∏ã‰øùÁïôÂ±ÄÈÉ®È´òËß£ÊûêÂ∫¶Á¥∞ÁØÄ„ÄÇÊé•ËëóÔºåÂ±ÄÈÉ®ÁâπÂæµËàáÂÖ®Â±ÄÁâπÂæµÊï¥ÂêàÔºå‰ª•Âú®‰∏ÄÂÄãÊúâÂáùËÅöÂäõÁöÑËÑàÁµ°‰∏≠Êì∑ÂèñÂçÄÂüüÈñìÁöÑÈóú‰øÇ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÂçÄÂüüÂ†±ÂëäÂ∞çÈΩä (RRA) Ë®ìÁ∑¥Á≠ñÁï•„ÄÇÂÆÉÂà©Áî®ÂèÉÁÖßÂçÄÂüüÁöÑËæ®Ë≠ò‰æÜÂºïÂ∞éÂçÄÂüüÁâπÂÆöÂ†±ÂëäÁöÑÁîüÊàêÔºåÂêåÊôÇÂ¢ûÂº∑Ê®°ÂûãÁöÑÂèÉÁÖßÂíåÂü∫Á§éËÉΩÂäõÔºå‰∏¶ÊîπÂñÑÂ†±ÂëäÁöÑÂèØËß£ËÆÄÊÄß„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄ≤‰∏ÄÊ≠•Áî®‰ΩúË™ûË®ÄËß£Á¢ºÂô®Ôºå‰ª•ÂæûÊï¥ÂêàÁöÑË¶ñË¶∫ÁâπÂæµ‰∏≠ÁîüÊàêÂ†±ÂëäÔºå‰øÉÈÄ≤ÂçÄÂüüÂ±§Á¥öÁöÑÁêÜËß£„ÄÇÂú®ÂÖ©ÂÄãÂ§ßË¶èÊ®°ËÉ∏ÈÉ® CT Â†±ÂëäË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óÔºåË≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÂÑ™Ë∂äÊÄßÔºåÂú®Ëá™ÁÑ∂Ë™ûË®ÄÁîüÊàêÂíåËá®Â∫äÊïàËÉΩÊåáÊ®ôÊñπÈù¢ÈÉΩÂÑ™ÊñºÂ§öÁ®ÆÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÔºåÂêåÊôÇ‰øùÁïô‰∫ÜËâØÂ•ΩÁöÑÂèØËß£ËÆÄÊÄß„ÄÇÊ≠§Á®ãÂºèÁ¢ºÂ∞áÂÖ¨ÈñãÊèê‰æõ„ÄÇ

##### **GeoAI-Enhanced Community Detection on Spatial Networks with Graph Deep Learning**
2411.15428v1 by Yunlei Liang, Jiawei Zhu, Wen Ye, Song Gao

Spatial networks are useful for modeling geographic phenomena where spatial
interaction plays an important role. To analyze the spatial networks and their
internal structures, graph-based methods such as community detection have been
widely used. Community detection aims to extract strongly connected components
from the network and reveal the hidden relationships between nodes, but they
usually do not involve the attribute information. To consider edge-based
interactions and node attributes together, this study proposed a family of
GeoAI-enhanced unsupervised community detection methods called region2vec based
on Graph Attention Networks (GAT) and Graph Convolutional Networks (GCN). The
region2vec methods generate node neural embeddings based on attribute
similarity, geographic adjacency and spatial interactions, and then extract
network communities based on node embeddings using agglomerative clustering.
The proposed GeoAI-based methods are compared with multiple baselines and
perform the best when one wants to maximize node attribute similarity and
spatial interaction intensity simultaneously within the spatial network
communities. It is further applied in the shortage area delineation problem in
public health and demonstrates its promise in regionalization problems.

ÊëòË¶ÅÔºöÁ©∫ÈñìÁ∂≤Ë∑ØÂ∞çÊñºÂª∫Ê®°Á©∫Èñì‰∫íÂãïÊâÆÊºîÈáçË¶ÅËßíËâ≤ÁöÑÂú∞ÁêÜÁèæË±°ÂæàÊúâÁî®„ÄÇÁÇ∫‰∫ÜÂàÜÊûêÁ©∫ÈñìÁ∂≤Ë∑ØÂèäÂÖ∂ÂÖßÈÉ®ÁµêÊßãÔºåÂü∫ÊñºÂúñÂΩ¢ÁöÑÊñπÊ≥ïÔºå‰æãÂ¶ÇÁ§æÁæ§ÂÅµÊ∏¨Â∑≤Âª£Ê≥õ‰ΩøÁî®„ÄÇÁ§æÁæ§ÂÅµÊ∏¨Êó®Âú®ÂæûÁ∂≤Ë∑Ø‰∏≠ÊèêÂèñÂº∑ÈÄ£ÁµêÂÖÉ‰ª∂Ôºå‰∏¶Êè≠Á§∫ÁØÄÈªû‰πãÈñìÁöÑÈö±ËóèÈóú‰øÇÔºå‰ΩÜÂÆÉÂÄëÈÄöÂ∏∏‰∏çÊ∂âÂèäÂ±¨ÊÄßË≥áË®ä„ÄÇÁÇ∫‰∫ÜÂêåÊôÇËÄÉÊÖÆÂü∫ÊñºÈÇäÁ∑£ÁöÑ‰∫íÂãïÂíåÁØÄÈªûÂ±¨ÊÄßÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ≥ªÂàóÁ®±ÁÇ∫ region2vec ÁöÑ GeoAI Â¢ûÂº∑ÂºèÈùûÁõ£Áù£ÂºèÁ§æÁæ§ÂÅµÊ∏¨ÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÂü∫ÊñºÂúñÂΩ¢Ê≥®ÊÑèÂäõÁ∂≤Ë∑Ø (GAT) ÂíåÂúñÂΩ¢Âç∑Á©çÁ∂≤Ë∑Ø (GCN)„ÄÇregion2vec ÊñπÊ≥ïÊ†πÊìöÂ±¨ÊÄßÁõ∏‰ººÊÄß„ÄÅÂú∞ÁêÜÈÑ∞Êé•ÊÄßÂíåÁ©∫Èñì‰∫íÂãïÁî¢ÁîüÁØÄÈªûÁ•ûÁ∂ìÂµåÂÖ•ÔºåÁÑ∂Âæå‰ΩøÁî®ÂáùËÅöÂºèÂàÜÁæ§Ê†πÊìöÁØÄÈªûÂµåÂÖ•ÊèêÂèñÁ∂≤Ë∑ØÁ§æÁæ§„ÄÇÂ∞áÊèêÂá∫ÁöÑÂü∫Êñº GeoAI ÁöÑÊñπÊ≥ïËàáÂ§öÂÄãÂü∫Á∑öÈÄ≤Ë°åÊØîËºÉÔºå‰∏¶Âú®Â∏åÊúõÂêåÊôÇÊúÄÂ§ßÂåñÁ©∫ÈñìÁ∂≤Ë∑ØÁ§æÁæ§‰∏≠ÁöÑÁØÄÈªûÂ±¨ÊÄßÁõ∏‰ººÊÄßÂíåÁ©∫Èñì‰∫íÂãïÂº∑Â∫¶ÊôÇÂü∑Ë°åÊúÄ‰Ω≥„ÄÇÈÄ≤‰∏ÄÊ≠•ÊáâÁî®ÊñºÂÖ¨ÂÖ±Ë°õÁîüÁöÑÁü≠Áº∫ÂçÄÂüüÊèèÁπ™ÂïèÈ°å‰∏≠Ôºå‰∏¶Ë≠âÊòéÂÖ∂Âú®ÂçÄÂüüÂåñÂïèÈ°å‰∏≠ÁöÑÂâçÊôØ„ÄÇ

##### **The Decoy Dilemma in Online Medical Information Evaluation: A Comparative Study of Credibility Assessments by LLM and Human Judges**
2411.15396v1 by Jiqun Liu, Jiangen He

Can AI be cognitively biased in automated information judgment tasks? Despite
recent progresses in measuring and mitigating social and algorithmic biases in
AI and large language models (LLMs), it is not clear to what extent LLMs behave
"rationally", or if they are also vulnerable to human cognitive bias triggers.
To address this open problem, our study, consisting of a crowdsourcing user
experiment and a LLM-enabled simulation experiment, compared the credibility
assessments by LLM and human judges under potential decoy effects in an
information retrieval (IR) setting, and empirically examined the extent to
which LLMs are cognitively biased in COVID-19 medical (mis)information
assessment tasks compared to traditional human assessors as a baseline. The
results, collected from a between-subject user experiment and a LLM-enabled
replicate experiment, demonstrate that 1) Larger and more recent LLMs tend to
show a higher level of consistency and accuracy in distinguishing credible
information from misinformation. However, they are more likely to give higher
ratings for misinformation due to the presence of a more salient, decoy
misinformation result; 2) While decoy effect occurred in both human and LLM
assessments, the effect is more prevalent across different conditions and
topics in LLM judgments compared to human credibility ratings. In contrast to
the generally assumed "rationality" of AI tools, our study empirically confirms
the cognitive bias risks embedded in LLM agents, evaluates the decoy impact on
LLMs against human credibility assessments, and thereby highlights the
complexity and importance of debiasing AI agents and developing
psychology-informed AI audit techniques and policies for automated judgment
tasks and beyond.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊòØÂê¶ÊúÉÂú®Ëá™ÂãïÂåñË≥áË®äÂà§Êñ∑‰ªªÂãô‰∏≠Áî¢ÁîüË™çÁü•ÂÅèÂ∑ÆÔºüÂÑòÁÆ°ÊúÄËøëÂú®Ë°°ÈáèÂíåÊ∏õËºï AI ÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠ÁöÑÁ§æÊúÉÂíåÊºîÁÆóÊ≥ïÂÅèÂ∑ÆÊñπÈù¢ÂèñÂæó‰∫ÜÈÄ≤Â±ïÔºå‰ΩÜÂ∞ö‰∏çÊ∏ÖÊ•ö LLM Âú®‰ΩïÁ®ÆÁ®ãÂ∫¶‰∏äË°®ÁèæÂá∫„ÄåÁêÜÊÄß„ÄçÔºåÊàñËÄÖÂÆÉÂÄëÊòØÂê¶‰πüÂÆπÊòìÂèóÂà∞‰∫∫È°ûË™çÁü•ÂÅèÂ∑ÆËß∏ÁôºÂõ†Á¥†ÁöÑÂΩ±Èüø„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÈñãÊîæÊÄßÂïèÈ°åÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÂåÖÂê´Áæ§ÁúæÂ§ñÂåÖ‰ΩøÁî®ËÄÖÂØ¶È©óÂíå LLM ÂïüÁî®ÁöÑÊ®°Êì¨ÂØ¶È©óÔºåÊØîËºÉ‰∫Ü LLM Âíå‰∫∫È°ûË©ïÂØ©Âì°Âú®Ë≥áË®äÊ™¢Á¥¢ (IR) Ë®≠ÂÆö‰∏≠ÁöÑÊΩõÂú®Ë™òÈ§åÊïàÊáâ‰∏ãÁöÑÂèØ‰ø°Â∫¶Ë©ï‰º∞Ôºå‰∏¶ÂØ¶Ë≠âÊ™¢È©ó‰∫Ü LLM Âú® COVID-19 ÈÜ´ÁôÇ (ÈåØË™§) Ë≥áË®äË©ï‰º∞‰ªªÂãô‰∏≠ËàáÂÇ≥Áµ±‰∫∫È°ûË©ï‰º∞Âì°Áõ∏ÊØîÂú®Ë™çÁü•ÂÅèÂ∑ÆÁöÑÁ®ãÂ∫¶„ÄÇÂæûÂèóË©¶ËÄÖ‰πãÈñìÁöÑ‰ΩøÁî®ËÄÖÂØ¶È©óÂíå LLM ÂïüÁî®ÁöÑË§áË£ΩÂØ¶È©ó‰∏≠Êî∂ÈõÜÁöÑÁµêÊûúÈ°ØÁ§∫Ôºå1) ËºÉÂ§ß‰∏îËºÉÊñ∞ÁöÑ LLM ÂæÄÂæÄÂú®ÂçÄÂàÜÂèØ‰ø°Ë≥áË®äÂíåÈåØË™§Ë≥áË®äÊôÇË°®ÁèæÂá∫ËºÉÈ´òÁ®ãÂ∫¶ÁöÑ‰∏ÄËá¥ÊÄßÂíåÊ∫ñÁ¢∫ÊÄß„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÂ≠òÂú®Êõ¥È°ØËëóÁöÑË™òÈ§åÈåØË™§Ë≥áË®äÁµêÊûúÔºåÂÆÉÂÄëÊõ¥ÊúâÂèØËÉΩÂ∞çÈåØË™§Ë≥áË®äÁµ¶‰∫àËºÉÈ´òÁöÑË©ïÂàÜÔºõ2) ÈõñÁÑ∂Ë™òÈ§åÊïàÊáâÁôºÁîüÂú®‰∫∫È°ûÂíå LLM Ë©ï‰º∞‰∏≠Ôºå‰ΩÜËàá‰∫∫È°ûÂèØ‰ø°Â∫¶Ë©ïÂàÜÁõ∏ÊØîÔºåË©≤ÊïàÊáâÂú® LLM Âà§Êñ∑ÁöÑ‰∏çÂêåÊ¢ù‰ª∂Âíå‰∏ªÈ°å‰∏≠Êõ¥ÁÇ∫ÊôÆÈÅç„ÄÇËàá‰∏ÄËà¨ÂÅáË®≠ÁöÑ AI Â∑•ÂÖ∑„ÄåÁêÜÊÄß„ÄçÁõ∏ÂèçÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÂØ¶Ë≠âË≠âÂØ¶‰∫Ü LLM ‰ª£ÁêÜ‰∏≠ÂµåÂÖ•ÁöÑË™çÁü•ÂÅèÂ∑ÆÈ¢®Èö™ÔºåË©ï‰º∞‰∫ÜË™òÈ§åÂ∞ç LLM ÁöÑÂΩ±ÈüøÔºå‰∏¶Ê†πÊìö‰∫∫È°ûÂèØ‰ø°Â∫¶Ë©ï‰º∞ÔºåÂæûËÄåÁ™ÅÈ°Ø‰∫ÜÊ∂àÈô§ AI ‰ª£ÁêÜÂÅèÂ∑ÆÂíåÈñãÁôºÂøÉÁêÜÂ≠∏Ë≥áË®ä AI Á®ΩÊ†∏ÊäÄË°ìÂíåÊîøÁ≠ñÁöÑË§áÈõúÊÄßÂíåÈáçË¶ÅÊÄßÔºå‰ª•Áî®ÊñºËá™ÂãïÂåñÂà§Êñ∑‰ªªÂãôÂèäÂÖ∂‰ªñ‰ªªÂãô„ÄÇ

##### **Regulator-Manufacturer AI Agents Modeling: Mathematical Feedback-Driven Multi-Agent LLM Framework**
2411.15356v1 by Yu Han, Zekun Guo

The increasing complexity of regulatory updates from global authorities
presents significant challenges for medical device manufacturers, necessitating
agile strategies to sustain compliance and maintain market access.
Concurrently, regulatory bodies must effectively monitor manufacturers'
responses and develop strategic surveillance plans. This study employs a
multi-agent modeling approach, enhanced with Large Language Models (LLMs), to
simulate regulatory dynamics and examine the adaptive behaviors of key actors,
including regulatory bodies, manufacturers, and competitors. These agents
operate within a simulated environment governed by regulatory flow theory,
capturing the impacts of regulatory changes on compliance decisions, market
adaptation, and innovation strategies. Our findings illuminate the influence of
regulatory shifts on industry behaviour and identify strategic opportunities
for improving regulatory practices, optimizing compliance, and fostering
innovation. By leveraging the integration of multi-agent systems and LLMs, this
research provides a novel perspective and offers actionable insights for
stakeholders navigating the evolving regulatory landscape of the medical device
industry.

ÊëòË¶ÅÔºöÈö®ËëóÂÖ®ÁêÉ‰∏ªÁÆ°Ê©üÈóúÊ≥ïË¶èÊõ¥Êñ∞ÁöÑÊó•ÁõäË§áÈõúÔºåÈÜ´ÁôÇÂô®ÊùêË£ΩÈÄ†ÂïÜÈù¢Ëá®ÈáçÂ§ßÊåëÊà∞ÔºåÈúÄË¶ÅÈùàÊ¥ªÁöÑÁ≠ñÁï•‰æÜÁ∂≠ÊåÅÂêàË¶è‰∏¶‰øùÊåÅÂ∏ÇÂ†¥ÂáÜÂÖ•„ÄÇÂêåÊôÇÔºåÊ≥ïË¶èÊ©üÊßãÂøÖÈ†àÊúâÊïàÁõ£ÊéßË£ΩÈÄ†ÂïÜÁöÑÂõûÊáâÔºå‰∏¶Âà∂ÂÆöÁ≠ñÁï•ÊÄßÁõ£ÊéßË®àÁï´„ÄÇÊú¨Á†îÁ©∂Êé°Áî®Â§öÈáç‰ª£ÁêÜ‰∫∫Âª∫Ê®°ÊñπÊ≥ïÔºå‰∏¶ÈÄèÈÅéÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âä†‰ª•Âº∑ÂåñÔºå‰ª•Ê®°Êì¨Ê≥ïË¶èÂãïÊÖã‰∏¶Ê™¢Ë¶ñ‰∏ªË¶ÅÂèÉËàáËÄÖÔºàÂåÖÊã¨Ê≥ïË¶èÊ©üÊßã„ÄÅË£ΩÈÄ†ÂïÜÂíåÁ´∂Áà≠ËÄÖÔºâÁöÑÈÅ©ÊáâË°åÁÇ∫„ÄÇÈÄô‰∫õ‰ª£ÁêÜ‰∫∫ÈÅã‰ΩúÂú®ÂèóÊ≥ïË¶èÊµÅÂãïÁêÜË´ñÊîØÈÖçÁöÑÊ®°Êì¨Áí∞Â¢É‰∏≠ÔºåÊçïÊçâÊ≥ïË¶èËÆäÊõ¥Â∞çÂêàË¶èÊ±∫Á≠ñ„ÄÅÂ∏ÇÂ†¥ÈÅ©ÊáâÂíåÂâµÊñ∞Á≠ñÁï•ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈó°ÊòéÊ≥ïË¶èËÆäÂãïÂ∞çÁî¢Ê•≠Ë°åÁÇ∫ÁöÑÂΩ±ÈüøÔºå‰∏¶ÊâæÂá∫ÊîπÂñÑÊ≥ïË¶èÂØ¶Âãô„ÄÅÊúÄ‰Ω≥ÂåñÂêàË¶èÂíå‰øÉÈÄ≤ÂâµÊñ∞ÁöÑÁ≠ñÁï•ÊÄßÊ©üÊúÉ„ÄÇÈÄèÈÅéÊï¥ÂêàÂ§öÈáç‰ª£ÁêÜ‰∫∫Á≥ªÁµ±Âíå LLMÔºåÊú¨Á†îÁ©∂Êèê‰æõ‰∏ÄÂÄãÊñ∞Á©éËßÄÈªûÔºå‰∏¶ÁÇ∫Âà©ÂÆ≥Èóú‰øÇ‰∫∫Êèê‰æõÂèØË°åÁöÑË¶ãËß£Ôºå‰ª•Âõ†ÊáâÈÜ´ÁôÇÂô®ÊùêÁî¢Ê•≠‰∏çÊñ∑ËÆäÈÅ∑ÁöÑÊ≥ïË¶èÁí∞Â¢É„ÄÇ

##### **Health AI Developer Foundations**
2411.15128v1 by Atilla P. Kiraly, Sebastien Baur, Kenneth Philbrick, Fereshteh Mahvar, Liron Yatziv, Tiffany Chen, Bram Sterling, Nick George, Fayaz Jamil, Jing Tang, Kai Bailey, Faruk Ahmed, Akshay Goel, Abbi Ward, Lin Yang, Andrew Sellergren, Yossi Matias, Avinatan Hassidim, Shravya Shetty, Daniel Golden, Shekoofeh Azizi, David F. Steiner, Yun Liu, Tim Thelin, Rory Pilgrim, Can Kirmizibayrak

Robust medical Machine Learning (ML) models have the potential to
revolutionize healthcare by accelerating clinical research, improving workflows
and outcomes, and producing novel insights or capabilities. Developing such ML
models from scratch is cost prohibitive and requires substantial compute, data,
and time (e.g., expert labeling). To address these challenges, we introduce
Health AI Developer Foundations (HAI-DEF), a suite of pre-trained,
domain-specific foundation models, tools, and recipes to accelerate building ML
for health applications. The models cover various modalities and domains,
including radiology (X-rays and computed tomography), histopathology,
dermatological imaging, and audio. These models provide domain specific
embeddings that facilitate AI development with less labeled data, shorter
training times, and reduced computational costs compared to traditional
approaches. In addition, we utilize a common interface and style across these
models, and prioritize usability to enable developers to integrate HAI-DEF
efficiently. We present model evaluations across various tasks and conclude
with a discussion of their application and evaluation, covering the importance
of ensuring efficacy, fairness, and equity. Finally, while HAI-DEF and
specifically the foundation models lower the barrier to entry for ML in
healthcare, we emphasize the importance of validation with problem- and
population-specific data for each desired usage setting. This technical report
will be updated over time as more modalities and features are added.

ÊëòË¶ÅÔºöÂº∑Â§ßÁöÑÈÜ´ÁôÇÊ©üÂô®Â≠∏Áøí (ML) Ê®°ÂûãÊúâÊΩõÂäõÈÄèÈÅéÂä†ÈÄüËá®Â∫äÁ†îÁ©∂„ÄÅÊîπÂñÑÂ∑•‰ΩúÊµÅÁ®ãÂíåÊàêÊûúÔºå‰ª•ÂèäÁî¢ÁîüÊñ∞Ë¶ãËß£ÊàñËÉΩÂäõÔºåÂæûËÄåÂæπÂ∫ïÊîπËÆäÈÜ´ÁôÇ‰øùÂÅ•„ÄÇÂæûÈ†≠ÈñãÂßãÈñãÁôºÊ≠§È°û ML Ê®°ÂûãÂú®ÊàêÊú¨‰∏äÈÅéÊñºÊòÇË≤¥Ôºå‰∏îÈúÄË¶ÅÂ§ßÈáèÁöÑÈÅãÁÆó„ÄÅË≥áÊñôÂíåÊôÇÈñì (‰æãÂ¶ÇÔºåÂ∞àÂÆ∂Ê®ôÁ±§)„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊé®Âá∫‰∫Ü Health AI Developer Foundations (HAI-DEF)ÔºåÈÄôÊòØ‰∏ÄÂ•óÈ†êÂÖàË®ìÁ∑¥Â•ΩÁöÑ„ÄÅÁâπÂÆöÊñºÈ†òÂüüÁöÑÂü∫Á§éÊ®°Âûã„ÄÅÂ∑•ÂÖ∑ÂíåÁØÑ‰æãÔºåÁî®ÊñºÂä†ÈÄüÂª∫Á´ãÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®ÁöÑ ML„ÄÇÈÄô‰∫õÊ®°ÂûãÊ∂µËìãÂêÑÁ®ÆÊ®°ÂºèÂíåÈ†òÂüüÔºåÂåÖÊã¨ÊîæÂ∞ÑÂ≠∏ (X ÂÖâÂíåÈõªËÖ¶Êñ∑Â±§ÊéÉÊèè)„ÄÅÁµÑÁπîÁóÖÁêÜÂ≠∏„ÄÅÁöÆËÜöÂΩ±ÂÉèÂ≠∏ÂíåÈü≥Ë®ä„ÄÇÈÄô‰∫õÊ®°ÂûãÊèê‰æõÁâπÂÆöÊñºÈ†òÂüüÁöÑÂµåÂÖ•ÔºåËàáÂÇ≥Áµ±ÊñπÊ≥ïÁõ∏ÊØîÔºåÂÆÉÂÄëÊúâÂä©Êñº‰ΩøÁî®ËºÉÂ∞ëÁöÑÊ®ôË®òË≥áÊñô„ÄÅÁ∏ÆÁü≠Ë®ìÁ∑¥ÊôÇÈñìÂíåÈôç‰ΩéÈÅãÁÆóÊàêÊú¨‰æÜÈÄ≤Ë°å AI ÈñãÁôº„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂú®ÈÄô‰∫õÊ®°Âûã‰∏≠‰ΩøÁî®ÈÄöÁî®‰ªãÈù¢ÂíåÊ®£ÂºèÔºå‰∏¶ÂÑ™ÂÖàËÄÉÊÖÆÂèØÁî®ÊÄßÔºå‰ª•‰ΩøÈñãÁôº‰∫∫Âì°ËÉΩÂ§†ÊúâÊïàÊï¥Âêà HAI-DEF„ÄÇÊàëÂÄëÈáùÂ∞çÂêÑÁ®Æ‰ªªÂãôÂ±ïÁ§∫Ê®°ÂûãË©ï‰º∞Ôºå‰∏¶‰ª•Ë®éË´ñÂÖ∂ÊáâÁî®ÂíåË©ï‰º∞‰ΩúÁÇ∫ÁµêË´ñÔºåÊ∂µËìãÁ¢∫‰øùÊïàËÉΩ„ÄÅÂÖ¨Âπ≥ÊÄßÂíåÂÖ¨Ê≠£ÊÄßÁöÑÈáçË¶ÅÊÄß„ÄÇÊúÄÂæåÔºåÂÑòÁÆ° HAI-DEF ÂíåÁâπÂà•ÊòØÂü∫Á§éÊ®°ÂûãÈôç‰Ωé‰∫ÜÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ ML ÁöÑÈÄ≤ÂÖ•ÈñÄÊ™ªÔºå‰ΩÜÊàëÂÄëÂº∑Ë™øÈ©óË≠âÂ∞çÊñºÊØèÂÄãÊâÄÈúÄÁöÑÁî®Ê≥ïË®≠ÂÆö‰æÜË™™ÂÖ∑ÊúâÂïèÈ°åÂíåÁâπÂÆöÊñº‰∫∫Áæ§Ë≥áÊñôÁöÑÈáçË¶ÅÊÄß„ÄÇÈö®ËëóÊõ¥Â§öÊ®°ÂºèÂíåÂäüËÉΩÁöÑÂä†ÂÖ•ÔºåÈÄô‰ªΩÊäÄË°ìÂ†±ÂëäÂ∞áÊúÉÈö®ËëóÊôÇÈñìÊõ¥Êñ∞„ÄÇ

##### **ReXrank: A Public Leaderboard for AI-Powered Radiology Report Generation**
2411.15122v1 by Xiaoman Zhang, Hong-Yu Zhou, Xiaoli Yang, Oishi Banerjee, Juli√°n N. Acosta, Josh Miller, Ouwen Huang, Pranav Rajpurkar

AI-driven models have demonstrated significant potential in automating
radiology report generation for chest X-rays. However, there is no standardized
benchmark for objectively evaluating their performance. To address this, we
present ReXrank, https://rexrank.ai, a public leaderboard and challenge for
assessing AI-powered radiology report generation. Our framework incorporates
ReXGradient, the largest test dataset consisting of 10,000 studies, and three
public datasets (MIMIC-CXR, IU-Xray, CheXpert Plus) for report generation
assessment. ReXrank employs 8 evaluation metrics and separately assesses models
capable of generating only findings sections and those providing both findings
and impressions sections. By providing this standardized evaluation framework,
ReXrank enables meaningful comparisons of model performance and offers crucial
insights into their robustness across diverse clinical settings. Beyond its
current focus on chest X-rays, ReXrank's framework sets the stage for
comprehensive evaluation of automated reporting across the full spectrum of
medical imaging.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ËÉΩÈ©ÖÂãïÁöÑÊ®°ÂûãÂ∑≤Ë≠âÊòéÂú®Ëá™ÂãïÂåñËÉ∏ÈÉ® X Â∞ÑÁ∑öÊîæÂ∞ÑÂ†±ÂëäÁîüÊàêÊñπÈù¢ÂÖ∑ÊúâÈ°ØËëóÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÊ≤íÊúâÊ®ôÊ∫ñÂåñÁöÑÂü∫Ê∫ñ‰æÜÂÆ¢ËßÄË©ï‰º∞ÂÖ∂ÊÄßËÉΩ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü ReXrankÔºåhttps://rexrank.aiÔºå‰∏ÄÂÄãÂÖ¨ÂÖ±ÊéíË°åÊ¶úÂíåÊåëÊà∞ÔºåÁî®ÊñºË©ï‰º∞ AI È©ÖÂãïÁöÑÊîæÂ∞ÑÂ†±ÂëäÁîüÊàê„ÄÇÊàëÂÄëÁöÑÊ°ÜÊû∂ÂåÖÂê´ ReXGradientÔºåÈÄôÊòØÁî± 10,000 È†ÖÁ†îÁ©∂ÁµÑÊàêÁöÑÊúÄÂ§ßÊ∏¨Ë©¶Êï∏ÊìöÈõÜÔºå‰ª•Âèä‰∏âÂÄãÂÖ¨ÂÖ±Êï∏ÊìöÈõÜÔºàMIMIC-CXR„ÄÅIU-Xray„ÄÅCheXpert PlusÔºâÔºåÁî®ÊñºÂ†±ÂëäÁîüÊàêË©ï‰º∞„ÄÇReXrank Êé°Áî® 8 È†ÖË©ï‰º∞ÊåáÊ®ôÔºå‰∏¶ÂàÜÂà•Ë©ï‰º∞Âè™ËÉΩÁîüÊàêÁµêÊûúÈÉ®ÂàÜÁöÑÊ®°ÂûãÂíåÂêåÊôÇÊèê‰æõÁµêÊûúÂíåÂç∞Ë±°ÈÉ®ÂàÜÁöÑÊ®°Âûã„ÄÇÈÄöÈÅéÊèê‰æõÈÄôÂÄãÊ®ôÊ∫ñÂåñÁöÑË©ï‰º∞Ê°ÜÊû∂ÔºåReXrank ËÉΩÂ§†Â∞çÊ®°ÂûãÊÄßËÉΩÈÄ≤Ë°åÊúâÊÑèÁæ©ÁöÑÊØîËºÉÔºå‰∏¶Êèê‰æõÂ∞çÂÖ∂Âú®‰∏çÂêåËá®Â∫äÁí∞Â¢É‰∏≠Á©©ÂÅ•ÊÄßÁöÑÈóúÈçµË¶ãËß£„ÄÇÈô§‰∫ÜÁõÆÂâçÈóúÊ≥®ËÉ∏ÈÉ® X Â∞ÑÁ∑ö‰πãÂ§ñÔºåReXrank ÁöÑÊ°ÜÊû∂ÈÇÑÁÇ∫Ë∑®Ë∂äÊï¥ÂÄãÈÜ´Â≠∏ÂΩ±ÂÉèÁØÑÂúçÁöÑËá™ÂãïÂåñÂ†±ÂëäÁöÑÂÖ®Èù¢Ë©ï‰º∞Â•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇ

##### **Feature-interactive Siamese graph encoder-based image analysis to predict STAS from histopathology images in lung cancer**
2411.15274v1 by Liangrui Pan, Qingchun Liang, Wenwu Zeng, Yijun Peng, Zhenyu Zhao, Yiyi Liang, Jiadi Luo, Xiang Wang, Shaoliang Peng

Spread through air spaces (STAS) is a distinct invasion pattern in lung
cancer, crucial for prognosis assessment and guiding surgical decisions.
Histopathology is the gold standard for STAS detection, yet traditional methods
are subjective, time-consuming, and prone to misdiagnosis, limiting large-scale
applications. We present VERN, an image analysis model utilizing a
feature-interactive Siamese graph encoder to predict STAS from lung cancer
histopathological images. VERN captures spatial topological features with
feature sharing and skip connections to enhance model training. Using 1,546
histopathology slides, we built a large single-cohort STAS lung cancer dataset.
VERN achieved an AUC of 0.9215 in internal validation and AUCs of 0.8275 and
0.8829 in frozen and paraffin-embedded test sections, respectively,
demonstrating clinical-grade performance. Validated on a single-cohort and
three external datasets, VERN showed robust predictive performance and
generalizability, providing an open platform (http://plr.20210706.xyz:5000/) to
enhance STAS diagnosis efficiency and accuracy.

ÊëòË¶ÅÔºö<paragraph>Á∂ìÁî±Á©∫Ê∞£ËÖîÔºàSTASÔºâÊì¥Êï£ÊòØ‰∏ÄÁ®ÆËÇ∫Áôå‰∏≠Áç®ÁâπÁöÑ‰æµË•≤Ê®°ÂºèÔºåÂ∞çÊñºÈ†êÂæåË©ï‰º∞ÂíåÂºïÂ∞éÊâãË°ìÊ±∫Á≠ñËá≥ÈóúÈáçË¶Å„ÄÇÁµÑÁπîÁóÖÁêÜÂ≠∏ÊòØ STAS Ê™¢Ê∏¨ÁöÑÈªÉÈáëÊ®ôÊ∫ñÔºå‰ΩÜÂÇ≥Áµ±ÊñπÊ≥ï‰∏ªËßÄ„ÄÅËÄóÊôÇ‰∏îÂÆπÊòìË™§Ë®∫ÔºåÈôêÂà∂‰∫ÜÂ§ßË¶èÊ®°ÊáâÁî®„ÄÇÊàëÂÄëÊèêÂá∫ VERNÔºå‰∏ÄÁ®ÆÂà©Áî®ÁâπÂæµ‰∫íÂãïÂºèÈÄ£È´îÂúñÁ∑®Á¢ºÂô®ÂæûËÇ∫ÁôåÁµÑÁπîÁóÖÁêÜÂ≠∏ÂΩ±ÂÉèÈ†êÊ∏¨ STAS ÁöÑÂΩ±ÂÉèÂàÜÊûêÊ®°Âûã„ÄÇVERN ÈÄöÈÅéÁâπÂæµÂÖ±‰∫´ÂíåË∑≥Ë∫çÈÄ£Êé•ÊçïÁç≤Á©∫ÈñìÊãìÊí≤ÁâπÂæµÔºå‰ª•Â¢ûÂº∑Ê®°ÂûãË®ìÁ∑¥„ÄÇ‰ΩøÁî® 1,546 ÂºµÁµÑÁπîÁóÖÁêÜÂ≠∏ÂàáÁâáÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÂ§ßÂûãÂñÆ‰∏ÄÈöäÂàó STAS ËÇ∫ÁôåÊï∏ÊìöÈõÜ„ÄÇVERN Âú®ÂÖßÈÉ®È©óË≠â‰∏≠ÈÅîÂà∞ 0.9215 ÁöÑ AUCÔºåÂú®ÂÜ∑ÂáçÂíåÁü≥Ë†üÂåÖÂüãÁöÑË©¶È©óÂàáÁâá‰∏≠ÂàÜÂà•ÈÅîÂà∞ 0.8275 Âíå 0.8829 ÁöÑ AUCÔºåË≠âÊòé‰∫ÜËá®Â∫äÁ¥öÁöÑÊÄßËÉΩ„ÄÇÂú®ÂñÆ‰∏ÄÈöäÂàóÂíå‰∏âÂÄãÂ§ñÈÉ®Êï∏ÊìöÈõÜ‰∏äÈÄ≤Ë°åÈ©óË≠âÔºåVERN Ë°®ÁèæÂá∫Á©©ÂÅ•ÁöÑÈ†êÊ∏¨ÊÄßËÉΩÂíåÊ≥õÂåñËÉΩÂäõÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÈñãÊîæÂπ≥Âè∞ (http://plr.20210706.xyz:5000/)Ôºå‰ª•ÊèêÈ´ò STAS Ë®∫Êñ∑ÊïàÁéáÂíåÊ∫ñÁ¢∫ÊÄß„ÄÇ</paragraph>

##### **Purrfessor: A Fine-tuned Multimodal LLaVA Diet Health Chatbot**
2411.14925v1 by Linqi Lu, Yifan Deng, Chuan Tian, Sijia Yang, Dhavan Shah

This study introduces Purrfessor, an innovative AI chatbot designed to
provide personalized dietary guidance through interactive, multimodal
engagement. Leveraging the Large Language-and-Vision Assistant (LLaVA) model
fine-tuned with food and nutrition data and a human-in-the-loop approach,
Purrfessor integrates visual meal analysis with contextual advice to enhance
user experience and engagement. We conducted two studies to evaluate the
chatbot's performance and user experience: (a) simulation assessments and human
validation were conducted to examine the performance of the fine-tuned model;
(b) a 2 (Profile: Bot vs. Pet) by 3 (Model: GPT-4 vs. LLaVA vs. Fine-tuned
LLaVA) experiment revealed that Purrfessor significantly enhanced users'
perceptions of care ($\beta = 1.59$, $p = 0.04$) and interest ($\beta = 2.26$,
$p = 0.01$) compared to the GPT-4 bot. Additionally, user interviews
highlighted the importance of interaction design details, emphasizing the need
for responsiveness, personalization, and guidance to improve user engagement.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂‰ªãÁ¥π‰∫Ü PurrfessorÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑ AI ËÅäÂ§©Ê©üÂô®‰∫∫ÔºåÊó®Âú®ÈÄèÈÅé‰∫íÂãïÂºèÂ§öÊ®°ÂºèÂèÉËàáÊèê‰æõÂÄã‰∫∫ÂåñÁöÑÈ£≤È£üÊåáÂ∞é„ÄÇPurrfessor Êé°Áî®Á∂ìÈÅéÈ£üÁâ©ÂíåÁáüÈ§äË≥áÊñôÂæÆË™øÁöÑÂ§ßË™ûË®ÄÂíåË¶ñË¶∫Âä©ÁêÜ (LLaVA) Ê®°ÂûãÔºå‰ª•Âèä‰∫∫Â∑•‰ªãÂÖ•ÁöÑÊñπÂºèÔºåÂ∞áË¶ñË¶∫ÂåñÈ§êÈªûÂàÜÊûêËàáÊÉÖÂ¢ÉÂª∫Ë≠∞Êï¥ÂêàÔºå‰ª•Â¢ûÂº∑‰ΩøÁî®ËÄÖÈ´îÈ©óÂíåÂèÉËàáÂ∫¶„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂÖ©È†ÖÁ†îÁ©∂Ôºå‰ª•Ë©ï‰º∞ËÅäÂ§©Ê©üÂô®‰∫∫ÁöÑÊïàËÉΩÂíå‰ΩøÁî®ËÄÖÈ´îÈ©óÔºö(a) ÈÄ≤Ë°åÊ®°Êì¨Ë©ï‰º∞Âíå‰∫∫Â∑•È©óË≠âÔºå‰ª•Ê™¢È©óÂæÆË™øÊ®°ÂûãÁöÑÊïàËÉΩÔºõ(b) ‰∏ÄÈ†Ö 2 (ÂÄã‰∫∫Ë≥áÊñôÔºöÊ©üÂô®‰∫∫ËàáÂØµÁâ©) x 3 (Ê®°ÂûãÔºöGPT-4 Ëàá LLaVA ËàáÂæÆË™ø LLaVA) ÂØ¶È©óÈ°ØÁ§∫ÔºåËàá GPT-4 Ê©üÂô®‰∫∫Áõ∏ÊØîÔºåPurrfessor Â§ßÂπÖÊèêÂçá‰∫Ü‰ΩøÁî®ËÄÖÂ∞çÊñºÈóúÊá∑ ($\beta = 1.59$Ôºå$p = 0.04$) ÂíåËààË∂£ ($\beta = 2.26$Ôºå$p = 0.01$) ÁöÑËßÄÊÑü„ÄÇÊ≠§Â§ñÔºå‰ΩøÁî®ËÄÖË®™Ë´áÂº∑Ë™ø‰∫Ü‰∫íÂãïË®≠Ë®àÁ¥∞ÁØÄÁöÑÈáçË¶ÅÊÄßÔºåÂº∑Ë™øÈúÄË¶ÅÂõûÊáâÊÄß„ÄÅÂÄã‰∫∫ÂåñÂíåÊåáÂ∞éÔºå‰ª•ÊèêÂçá‰ΩøÁî®ËÄÖÂèÉËàáÂ∫¶„ÄÇ

##### **Boundless Across Domains: A New Paradigm of Adaptive Feature and Cross-Attention for Domain Generalization in Medical Image Segmentation**
2411.14883v1 by Yuheng Xu, Taiping Zhang

Domain-invariant representation learning is a powerful method for domain
generalization. Previous approaches face challenges such as high computational
demands, training instability, and limited effectiveness with high-dimensional
data, potentially leading to the loss of valuable features. To address these
issues, we hypothesize that an ideal generalized representation should exhibit
similar pattern responses within the same channel across cross-domain images.
Based on this hypothesis, we use deep features from the source domain as
queries, and deep features from the generated domain as keys and values.
Through a cross-channel attention mechanism, the original deep features are
reconstructed into robust regularization representations, forming an explicit
constraint that guides the model to learn domain-invariant representations.
Additionally, style augmentation is another common method. However, existing
methods typically generate new styles through convex combinations of source
domains, which limits the diversity of training samples by confining the
generated styles to the original distribution. To overcome this limitation, we
propose an Adaptive Feature Blending (AFB) method that generates
out-of-distribution samples while exploring the in-distribution space,
significantly expanding the domain range. Extensive experimental results
demonstrate that our proposed methods achieve superior performance on two
standard domain generalization benchmarks for medical image segmentation.

ÊëòË¶ÅÔºöÈ†òÂüü‰∏çËÆäË°®Á§∫Â≠∏ÁøíÊòØÈ†òÂüüÊ≥õÂåñÁöÑ‰∏ÄÁ®ÆÂº∑Â§ßÊñπÊ≥ï„ÄÇÂÖàÂâçÁöÑÂÅöÊ≥ïÈù¢Ëá®Ë´∏Â¶ÇÈ´òË®àÁÆóÈúÄÊ±Ç„ÄÅË®ìÁ∑¥‰∏çÁ©©ÂÆö‰ª•ÂèäÂ∞çÈ´òÁ∂≠Êï∏ÊìöÁöÑÊúâÊïàÊÄßÊúâÈôêÁ≠âÊåëÊà∞ÔºåÂèØËÉΩÊúÉÂ∞éËá¥ÊúâÂÉπÂÄºÁâπÂæµÁöÑÈÅ∫Â§±„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÂÅáË®≠‰∏ÄÂÄãÁêÜÊÉ≥ÁöÑÊ≥õÂåñË°®Á§∫ÊáâÂú®Ë∑®È†òÂüüÂΩ±ÂÉè‰∏≠Â±ïÁèæÂá∫Áõ∏ÂêåÈÄöÈÅìÂÖßÁõ∏‰ººÁöÑÊ®°ÂºèÂèçÊáâ„ÄÇÂü∫ÊñºÊ≠§ÂÅáË®≠ÔºåÊàëÂÄë‰ΩøÁî®‰æÜËá™‰æÜÊ∫êÈ†òÂüüÁöÑÊ∑±Â∫¶ÁâπÂæµ‰ΩúÁÇ∫Êü•Ë©¢Ôºå‰∏¶‰ΩøÁî®‰æÜËá™ÁîüÊàêÈ†òÂüüÁöÑÊ∑±Â∫¶ÁâπÂæµ‰ΩúÁÇ∫ÈçµÂíåÂÄº„ÄÇÈÄèÈÅéË∑®ÈÄöÈÅìÊ≥®ÊÑèÂäõÊ©üÂà∂ÔºåÂéüÂßãÊ∑±Â∫¶ÁâπÂæµË¢´ÈáçÂª∫ÁÇ∫Á©©ÂÅ•ÁöÑÊ≠£ÂâáÂåñË°®Á§∫ÔºåÂΩ¢Êàê‰∏ÄÂÄãÂºïÂ∞éÊ®°ÂûãÂ≠∏ÁøíÈ†òÂüü‰∏çËÆäË°®Á§∫ÁöÑÊòéÁ¢∫Á¥ÑÊùü„ÄÇÊ≠§Â§ñÔºåÊ®£ÂºèÊì¥ÂÖÖÊòØÂè¶‰∏ÄÁ®ÆÂ∏∏Ë¶ãÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÊñπÊ≥ïÈÄöÂ∏∏ÈÄèÈÅé‰æÜÊ∫êÈ†òÂüüÁöÑÂá∏ÁµÑÂêà‰æÜÁîüÊàêÊñ∞ÁöÑÊ®£ÂºèÔºåÈÄôÊúÉÂ∞áÁîüÊàêÁöÑÊ®£ÂºèÈôêÂà∂Âú®ÂéüÂßãÂàÜ‰Ωà‰∏≠ÔºåÈÄ≤ËÄåÈôêÂà∂Ë®ìÁ∑¥Ê®£Êú¨ÁöÑÂ§öÊ®£ÊÄß„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÊ≠§ÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆËá™ÈÅ©ÊáâÁâπÂæµÊ∑∑Âêà (AFB) ÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÂú®Êé¢Á¥¢ÂàÜ‰ΩàÂÖßÁ©∫ÈñìÁöÑÂêåÊôÇÁîüÊàêÂàÜ‰ΩàÂ§ñÊ®£Êú¨ÔºåÂ§ßÂπÖÊì¥Â±ï‰∫ÜÈ†òÂüüÁØÑÂúç„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÁµêÊûúË≠âÊòéÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®ÂÖ©ÂÄãÊ®ôÊ∫ñÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤È†òÂüüÊ≥õÂåñÂü∫Ê∫ñ‰∏äÂèñÂæó‰∫ÜÂçìË∂äÁöÑÊïàËÉΩ„ÄÇ

##### **AI-Driven Real-Time Monitoring of Ground-Nesting Birds: A Case Study on Curlew Detection Using YOLOv10**
2411.15263v1 by Carl Chalmers, Paul Fergus, Serge Wich, Steven N Longmore, Naomi Davies Walsh, Lee Oliver, James Warrington, Julieanne Quinlan, Katie Appleby

Effective monitoring of wildlife is critical for assessing biodiversity and
ecosystem health, as declines in key species often signal significant
environmental changes. Birds, particularly ground-nesting species, serve as
important ecological indicators due to their sensitivity to environmental
pressures. Camera traps have become indispensable tools for monitoring nesting
bird populations, enabling data collection across diverse habitats. However,
the manual processing and analysis of such data are resource-intensive, often
delaying the delivery of actionable conservation insights. This study presents
an AI-driven approach for real-time species detection, focusing on the curlew
(Numenius arquata), a ground-nesting bird experiencing significant population
declines. A custom-trained YOLOv10 model was developed to detect and classify
curlews and their chicks using 3/4G-enabled cameras linked to the Conservation
AI platform. The system processes camera trap data in real-time, significantly
enhancing monitoring efficiency. Across 11 nesting sites in Wales, the model
achieved high performance, with a sensitivity of 90.56%, specificity of 100%,
and F1-score of 95.05% for curlew detections, and a sensitivity of 92.35%,
specificity of 100%, and F1-score of 96.03% for curlew chick detections. These
results demonstrate the capability of AI-driven monitoring systems to deliver
accurate, timely data for biodiversity assessments, facilitating early
conservation interventions and advancing the use of technology in ecological
research.

ÊëòË¶ÅÔºö<paragraph>ÊúâÊïàÁõ£Ê∏¨ÈáéÁîüÂãïÁâ©Â∞çÊñºË©ï‰º∞ÁîüÁâ©Â§öÊ®£ÊÄßÂíåÁîüÊÖãÁ≥ªÁµ±ÂÅ•Â∫∑Ëá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫ÈóúÈçµÁâ©Á®ÆÁöÑÊï∏ÈáèÊ∏õÂ∞ëÈÄöÂ∏∏Ë°®Á§∫ÈáçÂ§ßÁöÑÁí∞Â¢ÉËÆäÂåñ„ÄÇÈ≥•È°ûÔºåÂ∞§ÂÖ∂ÊòØÁØâÂ∑¢ÊñºÂú∞Èù¢ÁöÑÁâ©Á®ÆÔºåÁî±ÊñºÂ∞çÁí∞Â¢ÉÂ£ìÂäõÁöÑÊïèÊÑüÊÄßÔºåÂõ†Ê≠§ÊòØÈáçË¶ÅÁöÑÁîüÊÖãÊåáÊ®ô„ÄÇÁõ∏Ê©üÈô∑Èò±Â∑≤ÊàêÁÇ∫Áõ£Ê∏¨ÁØâÂ∑¢È≥•È°ûÁ®ÆÁæ§‰∏çÂèØÊàñÁº∫ÁöÑÂ∑•ÂÖ∑ÔºåÂèØ‰ª•Âú®‰∏çÂêåÁöÑÊ£≤ÊÅØÂú∞Êî∂ÈõÜË≥áÊñô„ÄÇÁÑ∂ËÄåÔºåÊ≠§È°ûË≥áÊñôÁöÑÊâãÂãïËôïÁêÜÂíåÂàÜÊûêÈúÄË¶ÅÂ§ßÈáèË≥áÊ∫êÔºåÈÄöÂ∏∏ÊúÉÂª∂ÈÅ≤Êèê‰æõÂèØË°åÁöÑ‰øùËÇ≤Ë¶ãËß£„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁî±‰∫∫Â∑•Êô∫ÊÖßÈ©ÖÂãïÁöÑÂç≥ÊôÇÁâ©Á®ÆÂÅµÊ∏¨ÊñπÊ≥ïÔºåÈáçÈªûÈóúÊ≥®ÊùìÈ∑∏ÔºàNumenius arquataÔºâÔºå‰∏ÄÁ®ÆÁØâÂ∑¢ÊñºÂú∞Èù¢ÁöÑÈ≥•È°ûÔºåÂÖ∂Á®ÆÁæ§Êï∏ÈáèÂ§ßÂπÖ‰∏ãÈôç„ÄÇÈñãÁôº‰∫Ü‰∏ÄÂÄãÂÆ¢Ë£ΩÂåñË®ìÁ∑¥ÁöÑ YOLOv10 Ê®°ÂûãÔºå‰ª•‰ΩøÁî®ÈÄ£ÁµêÂà∞‰øùËÇ≤‰∫∫Â∑•Êô∫ÊÖßÂπ≥Âè∞ÁöÑ 3/4G Áõ∏Ê©üÂÅµÊ∏¨ÂíåÂàÜÈ°ûÊùìÈ∑∏ÂèäÂÖ∂ÈõõÈ≥•„ÄÇÊ≠§Á≥ªÁµ±Âç≥ÊôÇËôïÁêÜÁõ∏Ê©üÈô∑Èò±Ë≥áÊñôÔºåÂ§ßÂπÖÊèêÂçáÁõ£Ê∏¨ÊïàÁéá„ÄÇÂú®Â®ÅÁàæÊñØÁöÑ 11 ÂÄãÁØâÂ∑¢Âú∞Èªû‰∏≠ÔºåÊ≠§Ê®°ÂûãË°®ÁèæÂÑ™Áï∞ÔºåÊùìÈ∑∏ÂÅµÊ∏¨ÁöÑÊïèÊÑüÂ∫¶ÁÇ∫ 90.56%ÔºåÁâπÁï∞Â∫¶ÁÇ∫ 100%ÔºåF1 ÂàÜÊï∏ÁÇ∫ 95.05%ÔºåÊùìÈ∑∏ÈõõÈ≥•ÂÅµÊ∏¨ÁöÑÊïèÊÑüÂ∫¶ÁÇ∫ 92.35%ÔºåÁâπÁï∞Â∫¶ÁÇ∫ 100%ÔºåF1 ÂàÜÊï∏ÁÇ∫ 96.03%„ÄÇÈÄô‰∫õÁµêÊûúË≠âÊòé‰∫ÜÁî±‰∫∫Â∑•Êô∫ÊÖßÈ©ÖÂãïÁöÑÁõ£Ê∏¨Á≥ªÁµ±ËÉΩÂ§†Êèê‰æõÊ∫ñÁ¢∫„ÄÅÂèäÊôÇÁöÑË≥áÊñôÔºå‰ª•ÈÄ≤Ë°åÁîüÁâ©Â§öÊ®£ÊÄßË©ï‰º∞Ôºå‰øÉÈÄ≤Êó©Êúü‰øùËÇ≤‰ªãÂÖ•Ôºå‰∏¶Êé®ÈÄ≤ÊäÄË°ìÂú®ÁîüÊÖãÁ†îÁ©∂‰∏≠ÁöÑÊáâÁî®„ÄÇ</paragraph>

##### **Optimized Vessel Segmentation: A Structure-Agnostic Approach with Small Vessel Enhancement and Morphological Correction**
2411.15251v1 by Dongning Song, Weijian Huang, Jiarun Liu, Md Jahidul Islam, Hao Yang, Shanshan Wang

Accurate segmentation of blood vessels is essential for various clinical
assessments and postoperative analyses. However, the inherent challenges of
vascular imaging, such as sparsity, fine granularity, low contrast, data
distribution variability, and the critical need for preserving topological
structure, making generalized vessel segmentation particularly complex. While
specialized segmentation methods have been developed for specific anatomical
regions, their over-reliance on tailored models hinders broader applicability
and generalization. General-purpose segmentation models introduced in medical
imaging often fail to address critical vascular characteristics, including the
connectivity of segmentation results. To overcome these limitations, we propose
an optimized vessel segmentation framework: a structure-agnostic approach
incorporating small vessel enhancement and morphological correction for
multi-modality vessel segmentation. To train and validate this framework, we
compiled a comprehensive multi-modality dataset spanning 17 datasets and
benchmarked our model against six SAM-based methods and 17 expert models. The
results demonstrate that our approach achieves superior segmentation accuracy,
generalization, and a 34.6% improvement in connectivity, underscoring its
clinical potential. An ablation study further validates the effectiveness of
the proposed improvements. We will release the code and dataset at github
following the publication of this work.

ÊëòË¶ÅÔºöÊ∫ñÁ¢∫ÂàÜÂâ≤Ë°ÄÁÆ°Â∞çÊñºÂêÑÁ®ÆËá®Â∫äË©ï‰º∞ÂíåË°ìÂæåÂàÜÊûêËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåË°ÄÁÆ°ÂΩ±ÂÉèÁöÑÂõ∫ÊúâÊåëÊà∞Ôºå‰æãÂ¶ÇÁ®ÄÁñèÊÄß„ÄÅÁ¥∞Á∑ªÈ°ÜÁ≤íÂ∫¶„ÄÅ‰ΩéÂ∞çÊØîÂ∫¶„ÄÅË≥áÊñôÂàÜ‰ΩàËÆäÁï∞ÊÄßÔºå‰ª•Âèä‰øùÁïôÊãìÊí≤ÁµêÊßãÁöÑÈóúÈçµÈúÄÊ±ÇÔºå‰ΩøÂæóÂª£Áæ©Ë°ÄÁÆ°ÂàÜÂâ≤ÁâπÂà•Ë§áÈõú„ÄÇÈõñÁÑ∂Â∑≤ÈáùÂ∞çÁâπÂÆöËß£ÂâñÂçÄÂüüÈñãÁôº‰∫ÜÂ∞àÈñÄÁöÑÂàÜÂâ≤ÊñπÊ≥ïÔºå‰ΩÜÂÆÉÂÄëÈÅéÂ∫¶‰æùË≥¥ÊñºÂÆ¢Ë£ΩÂåñÊ®°ÂûãÔºåÈòªÁ§ô‰∫ÜÊõ¥Âª£Ê≥õÁöÑÈÅ©Áî®ÊÄßÂíåÊ¶ÇÊã¨ÊÄß„ÄÇÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÂºïÂÖ•ÁöÑÈÄöÁî®ÂàÜÂâ≤Ê®°ÂûãÈÄöÂ∏∏ÁÑ°Ê≥ïËß£Ê±∫ÈóúÈçµÁöÑË°ÄÁÆ°ÁâπÂæµÔºåÂåÖÊã¨ÂàÜÂâ≤ÁµêÊûúÁöÑÈÄ£Êé•ÊÄß„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊúÄ‰Ω≥ÂåñÁöÑË°ÄÁÆ°ÂàÜÂâ≤Ê°ÜÊû∂Ôºö‰∏ÄÁ®ÆÁµêÊßã‰∏çÂèØÁü•ÁöÑÊñπÊ≥ïÔºåÁµêÂêàÂ∞èË°ÄÁÆ°Â¢ûÂº∑ÂíåÂΩ¢ÊÖãÊ†°Ê≠£ÔºåÁî®ÊñºÂ§öÊ®°ÊÖãË°ÄÁÆ°ÂàÜÂâ≤„ÄÇÁÇ∫‰∫ÜË®ìÁ∑¥ÂíåÈ©óË≠âÈÄôÂÄãÊ°ÜÊû∂ÔºåÊàëÂÄëÁ∑®Âà∂‰∫Ü‰∏ÄÂÄãÁ∂úÂêàÁöÑÂ§öÊ®°ÊÖãË≥áÊñôÈõÜÔºåÊ∂µËìã 17 ÂÄãË≥áÊñôÈõÜÔºå‰∏¶Â∞áÊàëÂÄëÁöÑÊ®°ÂûãËàáÂÖ≠Á®ÆÂü∫Êñº SAM ÁöÑÊñπÊ≥ïÂíå 17 Á®ÆÂ∞àÂÆ∂Ê®°ÂûãÈÄ≤Ë°å‰∫ÜÂü∫Ê∫ñÊ∏¨Ë©¶„ÄÇÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂØ¶Áèæ‰∫ÜÂÑ™Áï∞ÁöÑÂàÜÂâ≤Ê∫ñÁ¢∫Â∫¶„ÄÅÊ¶ÇÊã¨ÊÄßÔºå‰ª•ÂèäÈÄ£Êé•ÊÄßÊèêÂçá‰∫Ü 34.6%ÔºåÁ™ÅÈ°Ø‰∫ÜÂÖ∂Ëá®Â∫äÊΩõÂäõ„ÄÇÊ∂àËûçÁ†îÁ©∂ÈÄ≤‰∏ÄÊ≠•È©óË≠â‰∫ÜÊâÄÊèêÂá∫ÊîπÈÄ≤ÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÂ∞áÂú®ÁôºË°®ÈÄôÈ†ÖÂ∑•‰ΩúÂæåÊñº github ‰∏äÁôºÂ∏ÉÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜ„ÄÇ

##### **Adversarial Prompt Distillation for Vision-Language Models**
2411.15244v1 by Lin Luo, Xin Wang, Bojia Zi, Shihao Zhao, Xingjun Ma

Large pre-trained Vision-Language Models (VLMs) such as Contrastive
Language-Image Pre-Training (CLIP) have been shown to be susceptible to
adversarial attacks, raising concerns about their deployment in safety-critical
scenarios like autonomous driving and medical diagnosis. One promising approach
for improving the robustness of pre-trained VLMs is Adversarial Prompt Tuning
(APT), which combines adversarial training with prompt tuning. However,
existing APT methods are mostly single-modal methods that design prompt(s) for
only the visual or textual modality, limiting their effectiveness in either
robustness or clean accuracy. In this work, we propose a novel method called
Adversarial Prompt Distillation (APD) that combines APT with knowledge
distillation to boost the adversarial robustness of CLIP. Specifically, APD is
a bimodal method that adds prompts for both the visual and textual modalities
while leveraging a cleanly pre-trained teacher CLIP model to distill and boost
the performance of the student CLIP model on downstream tasks. Extensive
experiments on multiple benchmark datasets demonstrate the superiority of our
APD over the current state-of-the-art APT methods in terms of both natural and
adversarial performances. The effectiveness of our APD method validates the
possibility of using a non-robust teacher to improve the generalization and
robustness of VLMs.

ÊëòË¶ÅÔºöÂ§ßÂûãÈ†êË®ìÁ∑¥Ë¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM)Ôºå‰æãÂ¶ÇÂ∞çÊØîË™ûË®ÄÂΩ±ÂÉèÈ†êË®ìÁ∑¥ (CLIP)ÔºåÂ∑≤Ë¢´Ë≠âÊòéÂÆπÊòìÂèóÂà∞Â∞çÊäóÊÄßÊîªÊìäÔºåÈÄôÂºïËµ∑‰∫Ü‰∫∫ÂÄëÂ∞çÂÖ∂Âú®Ëá™ÂãïÈßïÈßõÂíåÈÜ´ÁôÇË®∫Êñ∑Á≠âÂÆâÂÖ®ÈóúÈçµÂ†¥ÊôØ‰∏≠ÈÉ®ÁΩ≤ÁöÑÊìîÊÜÇ„ÄÇ‰∏ÄÁ®ÆÊúâÂ∏åÊúõÁöÑÊñπÊ≥ïÊòØÂ∞çÊäóÊèêÁ§∫Ë™øÊï¥ (APT)ÔºåÂÆÉÁµêÂêà‰∫ÜÂ∞çÊäóË®ìÁ∑¥ÂíåÊèêÁ§∫Ë™øÊï¥„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑ APT ÊñπÊ≥ïÂ§ßÂ§öÊòØÂñÆÊ®°ÊÖãÊñπÊ≥ïÔºåÂÉÖÁÇ∫Ë¶ñË¶∫ÊàñÊñáÊú¨Ê®°ÊÖãË®≠Ë®àÊèêÁ§∫ÔºåÈÄôÈôêÂà∂‰∫ÜÂÆÉÂÄëÂú®È≠ØÊ£íÊÄßÊàñ‰πæÊ∑®Ê∫ñÁ¢∫ÊÄßÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫Â∞çÊäóÊèêÁ§∫Ëí∏È§æ (APD) ÁöÑÊñ∞ÊñπÊ≥ïÔºåÂÆÉÂ∞á APT ËàáÁü•Ë≠òËí∏È§æÁõ∏ÁµêÂêàÔºå‰ª•ÊèêÈ´ò CLIP ÁöÑÂ∞çÊäóÈ≠ØÊ£íÊÄß„ÄÇÂÖ∑È´î‰æÜË™™ÔºåAPD ÊòØ‰∏ÄÁ®ÆÈõôÊ®°ÊÖãÊñπÊ≥ïÔºåÂÆÉÁÇ∫Ë¶ñË¶∫ÂíåÊñáÊú¨Ê®°ÊÖãÊ∑ªÂä†ÊèêÁ§∫ÔºåÂêåÊôÇÂà©Áî®È†êÂÖàË®ìÁ∑¥Â•ΩÁöÑ‰πæÊ∑®ÊïôÂ∏´ CLIP Ê®°Âûã‰æÜËí∏È§æÂíåÊèêÂçáÂ≠∏Áîü CLIP Ê®°ÂûãÂú®‰∏ãÊ∏∏‰ªªÂãô‰∏äÁöÑÊÄßËÉΩ„ÄÇÂú®Â§öÂÄãÂü∫Ê∫ñÊï∏ÊìöÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÁöÑ APD Âú®Ëá™ÁÑ∂ÂíåÂ∞çÊäóÊÄßËÉΩÊñπÈù¢ÂÑ™ÊñºÁï∂ÂâçÊúÄÂÖàÈÄ≤ÁöÑ APT ÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑ APD ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÈ©óË≠â‰∫Ü‰ΩøÁî®ÈùûÈ≠ØÊ£íÊïôÂ∏´‰æÜÊèêÈ´ò VLM ÁöÑÊ≥õÂåñÊÄßÂíåÈ≠ØÊ£íÊÄßÁöÑÂèØËÉΩÊÄß„ÄÇ

##### **Is Attention All You Need For Actigraphy? Foundation Models of Wearable Accelerometer Data for Mental Health Research**
2411.15240v1 by Franklin Y. Ruan, Aiwei Zhang, Jenny Y. Oh, SouYoung Jin, Nicholas C Jacobson

Wearable accelerometry (actigraphy) has provided valuable data for clinical
insights since the 1970s and is increasingly important as wearable devices
continue to become widespread. The effectiveness of actigraphy in research and
clinical contexts is heavily dependent on the modeling architecture utilized.
To address this, we developed the Pretrained Actigraphy Transformer (PAT)--the
first pretrained and fully attention-based model designed specifically to
handle actigraphy. PAT was pretrained on actigraphy from 29,307 participants in
NHANES, enabling it to deliver state-of-the-art performance when fine-tuned
across various actigraphy prediction tasks in the mental health domain, even in
data-limited scenarios. For example, when trained to predict benzodiazepine
usage using actigraphy from only 500 labeled participants, PAT achieved an 8.8
percentage-point AUC improvement over the best baseline. With fewer than 2
million parameters and built-in model explainability, PAT is robust yet easy to
deploy in health research settings.
  GitHub: https://github.com/njacobsonlab/Pretrained-Actigraphy-Transformer/

ÊëòË¶ÅÔºöÂèØÁ©øÊà¥ÂºèÂä†ÈÄüÂ∫¶Ë®àÔºàÊ¥ªÂãïÊèèË®òÔºâËá™ 1970 Âπ¥‰ª£‰ª•‰æÜÔºåÁÇ∫Ëá®Â∫äË¶ãËß£Êèê‰æõ‰∫ÜÊúâÂÉπÂÄºÁöÑÊï∏ÊìöÔºå‰∏¶‰∏îÈö®ËëóÂèØÁ©øÊà¥ÂºèË£ùÁΩÆÊó•ÁõäÊôÆÂèäÔºåÂÖ∂ÈáçË¶ÅÊÄß‰πüËàáÊó•‰ø±Â¢û„ÄÇÊ¥ªÂãïÊèèË®òÂú®Á†îÁ©∂ÂíåËá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÊúâÊïàÊÄßÔºåÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂèñÊ±∫ÊñºÊâÄ‰ΩøÁî®ÁöÑÂª∫Ê®°Êû∂Êßã„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÈñãÁôº‰∫ÜÈ†êË®ìÁ∑¥Ê¥ªÂãïÊèèË®òËΩâÊèõÂô® (PAT)ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÈ†êË®ìÁ∑¥‰∏îÂÆåÂÖ®Âü∫ÊñºÊ≥®ÊÑèÂäõÁöÑÊ®°ÂûãÔºåÂ∞àÈñÄË®≠Ë®àÁî®ÊñºËôïÁêÜÊ¥ªÂãïÊèèË®ò„ÄÇPAT ÊòØÊ†πÊìö 29,307 ‰Ωç NHANES ÂèÉËàáËÄÖÁöÑÊ¥ªÂãïÊèèË®òÈÄ≤Ë°åÈ†êË®ìÁ∑¥Ôºå‰ΩøÂÖ∂ËÉΩÂ§†Âú®ÈáùÂ∞çÂøÉÁêÜÂÅ•Â∫∑È†òÂüüÁöÑÂêÑÁ®ÆÊ¥ªÂãïÊèèË®òÈ†êÊ∏¨‰ªªÂãôÈÄ≤Ë°åÂæÆË™øÊôÇÔºåÊèê‰æõÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåÂç≥‰ΩøÂú®Ë≥áÊñôÊúâÈôêÁöÑÊÉÖÊ≥Å‰∏ã‰πüÊòØÂ¶ÇÊ≠§„ÄÇ‰æãÂ¶ÇÔºåÁï∂Ë®ìÁ∑¥‰ΩøÁî®ÂÉÖ‰æÜËá™ 500 ‰ΩçÊ®ôË®òÂèÉËàáËÄÖÁöÑÊ¥ªÂãïÊèèË®ò‰æÜÈ†êÊ∏¨ËãØ‰∫åÊ∞Æ‰ì¨È°ûËó•Áâ©‰ΩøÁî®ÊôÇÔºåPAT Âú®ÊúÄ‰Ω≥Âü∫Ê∫ñ‰∏äÂØ¶Áèæ‰∫Ü 8.8 ÂÄãÁôæÂàÜÈªûÁöÑ AUC ÊîπÈÄ≤„ÄÇPAT ÂÖ∑Êúâ‰∏çÂà∞ 200 Ëê¨ÂÄãÂèÉÊï∏ÂíåÂÖßÂª∫Ê®°ÂûãÂèØËß£ÈáãÊÄßÔºåÂõ†Ê≠§Âú®ÂÅ•Â∫∑Á†îÁ©∂Ë®≠ÂÆö‰∏≠Êó¢Âº∑Â§ßÂèàÂÆπÊòìÈÉ®ÁΩ≤„ÄÇ
GitHubÔºöhttps://github.com/njacobsonlab/Pretrained-Actigraphy-Transformer/

##### **Uterine Ultrasound Image Captioning Using Deep Learning Techniques**
2411.14039v1 by Abdennour Boulesnane, Boutheina Mokhtari, Oumnia Rana Segueni, Slimane Segueni

Medical imaging has significantly revolutionized medical diagnostics and
treatment planning, progressing from early X-ray usage to sophisticated methods
like MRIs, CT scans, and ultrasounds. This paper investigates the use of deep
learning for medical image captioning, with a particular focus on uterine
ultrasound images. These images are vital in obstetrics and gynecology for
diagnosing and monitoring various conditions across different age groups.
However, their interpretation is often challenging due to their complexity and
variability. To address this, a deep learning-based medical image captioning
system was developed, integrating Convolutional Neural Networks with a
Bidirectional Gated Recurrent Unit network. This hybrid model processes both
image and text features to generate descriptive captions for uterine ultrasound
images. Our experimental results demonstrate the effectiveness of this approach
over baseline methods, with the proposed model achieving superior performance
in generating accurate and informative captions, as indicated by higher BLEU
and ROUGE scores. By enhancing the interpretation of uterine ultrasound images,
our research aims to assist medical professionals in making timely and accurate
diagnoses, ultimately contributing to improved patient care.

ÊëòË¶ÅÔºöÈÜ´Â≠∏ÂΩ±ÂÉèÂ§ßÂπÖÈù©Êñ∞‰∫ÜÈÜ´ÁôÇË®∫Êñ∑ÂíåÊ≤ªÁôÇË®àÁï´ÔºåÂæûÊó©ÊúüÁöÑ X ÂÖâ‰ΩøÁî®ÈÄ≤Â±ïÂà∞ MRI„ÄÅÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÂíåË∂ÖÈü≥Ê≥¢Á≠âÁ≤æÂØÜÊñπÊ≥ï„ÄÇÈÄôÁØáË´ñÊñáÊé¢Ë®éÊ∑±Â∫¶Â≠∏ÁøíÂú®ÈÜ´Â≠∏ÂΩ±ÂÉèÊ®ôÈ°å‰∏≠ÁöÑÊáâÁî®ÔºåÁâπÂà•ËëóÈáçÊñºÂ≠êÂÆÆË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉè„ÄÇÈÄô‰∫õÂΩ±ÂÉèÂú®Â©¶Áî¢Áßë‰∏≠Â∞çÊñºË®∫Êñ∑ÂíåËøΩËπ§‰∏çÂêåÂπ¥ÈΩ°Â±§ÁöÑÂêÑÁ®ÆÁñæÁóÖËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÂÖ∂Ë§áÈõúÊÄßÂíåËÆäÁï∞ÊÄßÔºåÂÆÉÂÄëÁöÑË©ÆÈáãÈÄöÂ∏∏ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÈñãÁôº‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèÊ®ôÈ°åÁ≥ªÁµ±ÔºåÂ∞áÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØËàáÈõôÂêëÈñÄÊéßÂæ™Áí∞ÂñÆÂÖÉÁ∂≤Ë∑ØÊï¥ÂêàÂú®‰∏ÄËµ∑„ÄÇÈÄôÂÄãÊ∑∑ÂêàÊ®°ÂûãËôïÁêÜÂΩ±ÂÉèÂíåÊñáÂ≠óÁâπÂæµÔºåÁÇ∫Â≠êÂÆÆË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÁî¢ÁîüÊèèËø∞ÊÄßÊ®ôÈ°å„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÊ≠§ÊñπÊ≥ïÂÑ™ÊñºÂü∫Á∑öÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂú®Áî¢ÁîüÊ∫ñÁ¢∫‰∏îÊúâÊÑèÁæ©ÁöÑÊ®ôÈ°åÊñπÈù¢ÈÅîÂà∞‰∫ÜÂçìË∂äÁöÑÊïàËÉΩÔºåÈÄôÁî±ËºÉÈ´òÁöÑ BLEU Âíå ROUGE ÂàÜÊï∏ÊâÄË≠âÊòé„ÄÇÈÄèÈÅéÂ¢ûÂº∑Â≠êÂÆÆË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÁöÑË©ÆÈáãÔºåÊàëÂÄëÁöÑÁ†îÁ©∂Êó®Âú®ÂçîÂä©ÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°ÈÄ≤Ë°åÂèäÊôÇ‰∏îÊ∫ñÁ¢∫ÁöÑË®∫Êñ∑ÔºåÊúÄÁµÇÊúâÂä©ÊñºÊîπÂñÑÁóÖÊÇ£ÁÖßË≠∑„ÄÇ

##### **Logic Augmented Generation**
2411.14012v1 by Aldo Gangemi, Andrea Giovanni Nuzzolese

Semantic Knowledge Graphs (SKG) face challenges with scalability,
flexibility, contextual understanding, and handling unstructured or ambiguous
information. However, they offer formal and structured knowledge enabling
highly interpretable and reliable results by means of reasoning and querying.
Large Language Models (LLMs) overcome those limitations making them suitable in
open-ended tasks and unstructured environments. Nevertheless, LLMs are neither
interpretable nor reliable. To solve the dichotomy between LLMs and SKGs we
envision Logic Augmented Generation (LAG) that combines the benefits of the two
worlds. LAG uses LLMs as Reactive Continuous Knowledge Graphs that can generate
potentially infinite relations and tacit knowledge on-demand. SKGs are key for
injecting a discrete heuristic dimension with clear logical and factual
boundaries. We exemplify LAG in two tasks of collective intelligence, i.e.,
medical diagnostics and climate projections. Understanding the properties and
limitations of LAG, which are still mostly unknown, is of utmost importance for
enabling a variety of tasks involving tacit knowledge in order to provide
interpretable and effective results.

ÊëòË¶ÅÔºöË™ûÊÑèÁü•Ë≠òÂúñÔºàSKGÔºâÂú®ÂèØÊì¥ÂÖÖÊÄß„ÄÅÈùàÊ¥ªÊÄß„ÄÅÊÉÖÂ¢ÉÁêÜËß£‰ª•ÂèäËôïÁêÜÈùûÁµêÊßãÂåñÊàñÂê´Á≥äË≥áË®äÊñπÈù¢Èù¢Ëá®ÊåëÊà∞„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÊèê‰æõÊ≠£Âºè‰∏îÁµêÊßãÂåñÁöÑÁü•Ë≠òÔºåËÉΩÈÄèÈÅéÊé®ÁêÜÂíåÊü•Ë©¢Êèê‰æõÈ´òÂ∫¶ÂèØËß£Èáã‰∏îÂèØÈù†ÁöÑÁµêÊûú„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂÖãÊúç‰∫ÜÈÄô‰∫õÈôêÂà∂Ôºå‰ΩøÂÖ∂ÈÅ©Áî®ÊñºÈñãÊîæÂºè‰ªªÂãôÂíåÈùûÁµêÊßãÂåñÁí∞Â¢É„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåLLM Êó¢‰∏çÂèØËß£Èáã‰πü‰∏çÂèØÈù†„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ LLM Âíå SKG ‰πãÈñìÁöÑ‰∫åÂàÜÊ≥ïÔºåÊàëÂÄëË®≠ÊÉ≥‰∫ÜÈÇèËºØÂ¢ûÂº∑ÁîüÊàêÔºàLAGÔºâÔºåÂÆÉÁµêÂêà‰∫ÜÂÖ©ÂÄã‰∏ñÁïåÁöÑÂÑ™Èªû„ÄÇLAG ‰ΩøÁî® LLM ‰ΩúÁÇ∫ÂèçÊáâÂºèÈÄ£Á∫åÁü•Ë≠òÂúñÔºåÂÆÉÂèØ‰ª•ÊåâÈúÄÁî¢ÁîüÊΩõÂú®ÁöÑÁÑ°ÈôêÈóú‰øÇÂíåÈªòÊúÉÁü•Ë≠ò„ÄÇSKG ÊòØÊ≥®ÂÖ•Èõ¢Êï£ÂïüÁôºÂºèÁ∂≠Â∫¶ÔºàÂÖ∑ÊúâÊòéÁ¢∫ÈÇèËºØÂíå‰∫ãÂØ¶ÈÇäÁïåÔºâÁöÑÈóúÈçµ„ÄÇÊàëÂÄëÂú®ÈõÜÈ´îÊô∫ÊÖßÁöÑÂÖ©ÂÄã‰ªªÂãô‰∏≠Ëàâ‰æãË™™Êòé LAGÔºåÂç≥ÈÜ´ÁôÇË®∫Êñ∑ÂíåÊ∞£ÂÄôÈ†êÊ∏¨„ÄÇÁêÜËß£ LAG ÁöÑÁâπÊÄßÂíåÈôêÂà∂ÔºàÁõÆÂâç‰ªçÁÑ∂Â§ßÂ§öÊï∏Êú™Áü•ÔºâÂ∞çÊñºÂïüÁî®Ê∂âÂèäÈªòÊúÉÁü•Ë≠òÁöÑÂêÑÁ®Æ‰ªªÂãô‰ª•Êèê‰æõÂèØËß£Èáã‰∏îÊúâÊïàÁöÑÁµêÊûúËá≥ÈóúÈáçË¶Å„ÄÇ

##### **AmpliNetECG12: A lightweight SoftMax-based relativistic amplitude amplification architecture for 12 lead ECG classification**
2411.13903v1 by Shreya Srivastava

The urgent need to promptly detect cardiac disorders from 12-lead
Electrocardiograms using limited computations is motivated by the heart's fast
and complex electrical activity and restricted computational power of portable
devices. Timely and precise diagnoses are crucial since delays might
significantly impact patient health outcomes. This research presents a novel
deep-learning architecture that aims to diagnose heart abnormalities quickly
and accurately. We devised a new activation function called aSoftMax, designed
to improve the visibility of ECG deflections. The proposed activation function
is used with Convolutional Neural Network architecture to includes kernel
weight sharing across the ECG's various leads. This innovative method
thoroughly generalizes the global 12-lead ECG features and minimizes the
model's complexity by decreasing the trainable parameters. aSoftMax, combined
with enhanced CNN architecture yielded AmpliNetECG12, we obtain exceptional
accuracy of 84% in diagnosing cardiac disorders. AmpliNetECG12 shows
outstanding prediction ability when used with the CPSC2018 dataset for
arrhythmia classification. The model attains an F1-score of 80.71% and a
ROC-AUC score of 96.00%, with 280,000 trainable parameters which signifies the
lightweight yet efficient nature of AmpliNetECG12. The stochastic
characteristics of aSoftMax, a fundamental element of AmpliNetECG12, improve
prediction accuracy and also increasse the model's interpretability. This
feature enhances comprehension of important ECG segments in different forms of
arrhythmias, establishing a new standard of explainable architecture for
cardiac disorder classification.

ÊëòË¶ÅÔºö<paragraph>Áî±ÊñºÂøÉËáüÁöÑÂø´ÈÄü‰∏îË§áÈõúÁöÑÈõªÊ∞£Ê¥ªÂãïÂíåÊîúÂ∏∂ÂºèË£ùÁΩÆÂèóÈôêÁöÑÈÅãÁÆóËÉΩÂäõÔºåÂõ†Ê≠§Ëø´ÂàáÈúÄË¶Å‰ΩøÁî® 12 Â∞éÁ®ãÂøÉÈõªÂúñ‰æÜÂø´ÈÄüÂÅµÊ∏¨ÂøÉËáüÁñæÁóÖ„ÄÇÂèäÊôÇ‰∏îÁ≤æÁ¢∫ÁöÑË®∫Êñ∑Ëá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫Âª∂Ë™§ÂèØËÉΩÊúÉÂ∞çÊÇ£ËÄÖÁöÑÂÅ•Â∫∑ÁãÄÊ≥ÅÁî¢ÁîüÈáçÂ§ßÂΩ±Èüø„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊû∂ÊßãÔºåÊó®Âú®Âø´ÈÄü‰∏îÊ∫ñÁ¢∫Âú∞Ë®∫Êñ∑ÂøÉËáüÁï∞Â∏∏„ÄÇÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÁ®±ÁÇ∫ aSoftMax ÁöÑÊñ∞ÊøÄÊ¥ªÂáΩÊï∏ÔºåÊó®Âú®ÊèêÈ´òÂøÉÈõªÂúñÂÅèËΩâÁöÑÂèØË¶ãÂ∫¶„ÄÇÊâÄÊèêÂá∫ÁöÑÊøÄÊ¥ªÂáΩÊï∏ËàáÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÊû∂Êßã‰∏ÄËµ∑‰ΩøÁî®Ôºå‰ª•Âú®ÂøÉÈõªÂúñÁöÑÂêÑÁ®ÆÂ∞éÁ®ã‰πãÈñìÂåÖÂê´Ê†∏Ê¨äÈáçÂÖ±‰∫´„ÄÇÈÄôÁ®ÆÂâµÊñ∞ÊñπÊ≥ïÂæπÂ∫ïÊ¶ÇÊã¨‰∫ÜÂÖ®ÁêÉ 12 Â∞éÁ®ãÂøÉÈõªÂúñÁâπÂæµÔºå‰∏¶ÈÄöÈÅéÊ∏õÂ∞ëÂèØË®ìÁ∑¥ÂèÉÊï∏‰æÜÊúÄÂ∞èÂåñÊ®°ÂûãÁöÑË§áÈõúÊÄß„ÄÇaSoftMax ÁµêÂêàÂ¢ûÂº∑ÁöÑ CNN Êû∂ÊßãÁî¢Áîü‰∫Ü AmpliNetECG12ÔºåÊàëÂÄëÂú®Ë®∫Êñ∑ÂøÉËáüÁñæÁóÖÊñπÈù¢Áç≤Âæó‰∫Ü 84% ÁöÑÂá∫Ëâ≤Ê∫ñÁ¢∫Â∫¶„ÄÇAmpliNetECG12 Âú®Ëàá CPSC2018 Ë≥áÊñôÈõÜ‰∏ÄËµ∑Áî®ÊñºÂøÉÂæã‰∏çÊï¥ÂàÜÈ°ûÊôÇÈ°ØÁ§∫Âá∫Âá∫Ëâ≤ÁöÑÈ†êÊ∏¨ËÉΩÂäõ„ÄÇË©≤Ê®°Âûã‰ª• 280,000 ÂÄãÂèØË®ìÁ∑¥ÂèÉÊï∏Áç≤Âæó 80.71% ÁöÑ F1 ÂàÜÊï∏Âíå 96.00% ÁöÑ ROC-AUC ÂàÜÊï∏ÔºåÈÄôË°®Êòé AmpliNetECG12 ÁöÑËºïÈáèÁ¥ö‰∏îÈ´òÊïàÁöÑÊú¨Ë≥™„ÄÇaSoftMax ÁöÑÈö®Ê©üÁâπÂæµÊòØ AmpliNetECG12 ÁöÑÂü∫Êú¨Ë¶ÅÁ¥†ÔºåÂÆÉÊèêÈ´ò‰∫ÜÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶Ôºå‰πüÂ¢ûÂä†‰∫ÜÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄß„ÄÇÊ≠§ÂäüËÉΩÂ¢ûÂº∑‰∫ÜÂ∞ç‰∏çÂêåÂΩ¢ÂºèÂøÉÂæã‰∏çÊï¥‰∏≠ÈáçË¶ÅÂøÉÈõªÂúñÂçÄÊÆµÁöÑÁêÜËß£ÔºåÁÇ∫ÂøÉËáüÁñæÁóÖÂàÜÈ°ûÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂèØËß£ÈáãÊû∂ÊßãÊ®ôÊ∫ñ„ÄÇ</paragraph>

##### **PIORS: Personalized Intelligent Outpatient Reception based on Large Language Model with Multi-Agents Medical Scenario Simulation**
2411.13902v1 by Zhijie Bao, Qingyun Liu, Ying Guo, Zhengqiang Ye, Jun Shen, Shirong Xie, Jiajie Peng, Xuanjing Huang, Zhongyu Wei

In China, receptionist nurses face overwhelming workloads in outpatient
settings, limiting their time and attention for each patient and ultimately
reducing service quality. In this paper, we present the Personalized
Intelligent Outpatient Reception System (PIORS). This system integrates an
LLM-based reception nurse and a collaboration between LLM and hospital
information system (HIS) into real outpatient reception setting, aiming to
deliver personalized, high-quality, and efficient reception services.
Additionally, to enhance the performance of LLMs in real-world healthcare
scenarios, we propose a medical conversational data generation framework named
Service Flow aware Medical Scenario Simulation (SFMSS), aiming to adapt the LLM
to the real-world environments and PIORS settings. We evaluate the
effectiveness of PIORS and SFMSS through automatic and human assessments
involving 15 users and 15 clinical experts. The results demonstrate that
PIORS-Nurse outperforms all baselines, including the current state-of-the-art
model GPT-4o, and aligns with human preferences and clinical needs. Further
details and demo can be found at https://github.com/FudanDISC/PIORS

ÊëòË¶ÅÔºö<paragraph>Âú®‰∏≠ÂõΩÔºåÊé•ÂæÖÊä§Â£´Âú®Èó®ËØäÁéØÂ¢É‰∏≠Èù¢‰∏¥ÁùÄÁπÅÈáçÁöÑÂ∑•‰ΩúÈáèÔºåÈôêÂà∂‰∫Ü‰ªñ‰ª¨ÂØπÊØè‰ΩçÊÇ£ËÄÖÁöÑÊó∂Èó¥ÂíåÊ≥®ÊÑèÂäõÔºåÊúÄÁªàÈôç‰Ωé‰∫ÜÊúçÂä°Ë¥®Èáè„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏™ÊÄßÂåñÊô∫ËÉΩÈó®ËØäÊé•ÂæÖÁ≥ªÁªü (PIORS)„ÄÇËØ•Á≥ªÁªüÂ∞ÜÂü∫‰∫é LLM ÁöÑÊé•ÂæÖÊä§Â£´Âíå LLM ‰∏éÂåªÈô¢‰ø°ÊÅØÁ≥ªÁªü (HIS) ‰πãÈó¥ÁöÑÂçè‰ΩúÊï¥ÂêàÂà∞ÁúüÂÆûÁöÑÈó®ËØäÊé•ÂæÖÁéØÂ¢É‰∏≠ÔºåÊó®Âú®Êèê‰æõ‰∏™ÊÄßÂåñ„ÄÅÈ´òË¥®ÈáèÂíåÈ´òÊïàÁöÑÊé•ÂæÖÊúçÂä°„ÄÇÊ≠§Â§ñÔºå‰∏∫‰∫ÜÊèêÈ´ò LLM Âú®ÁúüÂÆûÂåªÁñó‰øùÂÅ•Âú∫ÊôØ‰∏≠ÁöÑÊÄßËÉΩÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Âêç‰∏∫ÊúçÂä°ÊµÅÊÑüÁü•ÂåªÁñóÂú∫ÊôØÊ®°Êãü (SFMSS) ÁöÑÂåªÁñó‰ºöËØùÊï∞ÊçÆÁîüÊàêÊ°ÜÊû∂ÔºåÊó®Âú®‰Ωø LLM ÈÄÇÂ∫îÁúüÂÆû‰∏ñÁïåÁéØÂ¢ÉÂíå PIORS ËÆæÁΩÆ„ÄÇÊàë‰ª¨ÈÄöËøáÊ∂âÂèä 15 ÂêçÁî®Êà∑Âíå 15 Âêç‰∏¥Â∫ä‰∏ìÂÆ∂ÁöÑËá™Âä®Âíå‰∫∫Â∑•ËØÑ‰º∞Êù•ËØÑ‰º∞ PIORS Âíå SFMSS ÁöÑÊúâÊïàÊÄß„ÄÇÁªìÊûúË°®ÊòéÔºåPIORS-Nurse ‰ºò‰∫éÊâÄÊúâÂü∫Á∫øÔºåÂåÖÊã¨ÂΩìÂâçÊúÄÂÖàËøõÁöÑÊ®°Âûã GPT-4oÔºåÂπ∂‰∏îÁ¨¶Âêà‰∫∫Á±ªÂÅèÂ•ΩÂíå‰∏¥Â∫äÈúÄÊ±Ç„ÄÇÊõ¥Â§öËØ¶ÁªÜ‰ø°ÊÅØÂíåÊºîÁ§∫ÂèØÂú® https://github.com/FudanDISC/PIORS ‰∏≠ÊâæÂà∞</paragraph>

##### **Advancing Complex Medical Communication in Arabic with Sporo AraSum: Surpassing Existing Large Language Models**
2411.13518v1 by Chanseo Lee, Sonu Kumar, Kimon A. Vogt, Sam Meraj, Antonia Vogt

The increasing demand for multilingual capabilities in healthcare underscores
the need for AI models adept at processing diverse languages, particularly in
clinical documentation and decision-making. Arabic, with its complex
morphology, syntax, and diglossia, poses unique challenges for natural language
processing (NLP) in medical contexts. This case study evaluates Sporo AraSum, a
language model tailored for Arabic clinical documentation, against JAIS, the
leading Arabic NLP model. Using synthetic datasets and modified PDQI-9 metrics
modified ourselves for the purposes of assessing model performances in a
different language. The study assessed the models' performance in summarizing
patient-physician interactions, focusing on accuracy, comprehensiveness,
clinical utility, and linguistic-cultural competence.
  Results indicate that Sporo AraSum significantly outperforms JAIS in
AI-centric quantitative metrics and all qualitative attributes measured in our
modified version of the PDQI-9. AraSum's architecture enables precise and
culturally sensitive documentation, addressing the linguistic nuances of Arabic
while mitigating risks of AI hallucinations. These findings suggest that Sporo
AraSum is better suited to meet the demands of Arabic-speaking healthcare
environments, offering a transformative solution for multilingual clinical
workflows. Future research should incorporate real-world data to further
validate these findings and explore broader integration into healthcare
systems.

ÊëòË¶ÅÔºöÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÂ∞çÂ§öË™ûË®ÄËÉΩÂäõÁöÑÈúÄÊ±ÇÊó•ÁõäÂ¢ûÂä†ÔºåÈÄôÂá∏È°Ø‰∫ÜÂ∞çÂñÑÊñºËôïÁêÜÂêÑÁ®ÆË™ûË®ÄÁöÑ AI Ê®°ÂûãÁöÑÈúÄÊ±ÇÔºåÁâπÂà•ÊòØÂú®Ëá®Â∫äÊñá‰ª∂ÂíåÊ±∫Á≠ñÂà∂ÂÆö‰∏≠„ÄÇÈòøÊãâ‰ºØË™ûÂÖ∑ÊúâË§áÈõúÁöÑÂΩ¢ÊÖã„ÄÅË™ûÊ≥ïÂíåÈõôË™ûÁèæË±°ÔºåÈÄôÂ∞çÈÜ´ÁôÇÁí∞Â¢É‰∏≠ÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÊßãÊàê‰∫ÜÁç®ÁâπÁöÑÊåëÊà∞„ÄÇÊú¨Ê°à‰æãÁ†îÁ©∂Ë©ï‰º∞‰∫Ü Sporo AraSumÔºà‰∏ÄÁ®ÆÂ∞àÁÇ∫ÈòøÊãâ‰ºØË™ûËá®Â∫äÊñá‰ª∂ÈáèË∫´ÊâìÈÄ†ÁöÑË™ûË®ÄÊ®°ÂûãÔºâÂíåÈòøÊãâ‰ºØË™û NLP Ê®°ÂûãÁöÑÈ†òÂ∞éËÄÖ JAIS„ÄÇÊàëÂÄë‰ΩøÁî®ÂêàÊàêË≥áÊñôÈõÜÂíå‰øÆÊîπÂæåÁöÑ PDQI-9 ÊåáÊ®ôÔºàÊàëÂÄëËá™Ë°å‰øÆÊîπÔºå‰ª•Ë©ï‰º∞Ê®°ÂûãÂú®‰∏çÂêåË™ûË®Ä‰∏≠ÁöÑË°®ÁèæÔºâ„ÄÇÊú¨Á†îÁ©∂Ë©ï‰º∞‰∫ÜÊ®°ÂûãÂú®Á∏ΩÁµêÊÇ£ËÄÖËàáÈÜ´Â∏´‰∫íÂãïÊôÇÁöÑË°®ÁèæÔºåÈáçÈªûÂú®ÊñºÊ∫ñÁ¢∫ÊÄß„ÄÅÂÖ®Èù¢ÊÄß„ÄÅËá®Â∫äÊïàÁî®ÂíåË™ûË®ÄÊñáÂåñËÉΩÂäõ„ÄÇ
ÁµêÊûúË°®ÊòéÔºåÂú®‰ª• AI ÁÇ∫‰∏≠ÂøÉÁöÑÂÆöÈáèÊåáÊ®ôÂíåÊàëÂÄë‰øÆÊîπÂæåÁöÑ PDQI-9 ÁâàÊú¨‰∏≠Ê∏¨ÈáèÁöÑÊâÄÊúâÂÆöÊÄßÂ±¨ÊÄß‰∏≠ÔºåSporo AraSum ÊòéÈ°ØÂÑ™Êñº JAIS„ÄÇAraSum ÁöÑÊû∂ÊßãËÉΩÁî¢ÁîüÁ≤æÁ¢∫‰∏îÂÖ∑ÊúâÊñáÂåñÊïèÊÑüÂ∫¶ÁöÑÊñá‰ª∂ÔºåÂÆÉËÉΩËôïÁêÜÈòøÊãâ‰ºØË™ûÁöÑË™ûË®ÄÂ∑ÆÁï∞ÔºåÂêåÊôÇÈôç‰Ωé AI Áî¢ÁîüÂπªË¶∫ÁöÑÈ¢®Èö™„ÄÇÈÄô‰∫õÁôºÁèæË°®ÊòéÔºåSporo AraSum Êõ¥ÈÅ©ÂêàÊªøË∂≥Ë¨õÈòøÊãâ‰ºØË™ûÁöÑÈÜ´ÁôÇ‰øùÂÅ•Áí∞Â¢ÉÁöÑÈúÄÊ±ÇÔºåÁÇ∫Â§öË™ûË®ÄËá®Â∫äÂ∑•‰ΩúÊµÅÁ®ãÊèê‰æõ‰∫Ü‰∏ÄÂÄãËÆäÈù©ÊÄßÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÊú™‰æÜÁöÑÁ†îÁ©∂ÊáâÁ¥çÂÖ•ÁúüÂØ¶‰∏ñÁïåÁöÑË≥áÊñôÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•È©óË≠âÈÄô‰∫õÁôºÁèæÔºå‰∏¶Êé¢Á¥¢Êõ¥Âª£Ê≥õÂú∞Êï¥ÂêàÂà∞ÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±‰∏≠„ÄÇ

##### **Dist Loss: Enhancing Regression in Few-Shot Region through Distribution Distance Constraint**
2411.15216v1 by Guangkun Nie, Gongzheng Tang, Shenda Hong

Imbalanced data distributions are prevalent in real-world scenarios, posing
significant challenges in both imbalanced classification and imbalanced
regression tasks. They often cause deep learning models to overfit in areas of
high sample density (many-shot regions) while underperforming in areas of low
sample density (few-shot regions). This characteristic restricts the utility of
deep learning models in various sectors, notably healthcare, where areas with
few-shot data hold greater clinical relevance. While recent studies have shown
the benefits of incorporating distribution information in imbalanced
classification tasks, such strategies are rarely explored in imbalanced
regression. In this paper, we address this issue by introducing a novel loss
function, termed Dist Loss, designed to minimize the distribution distance
between the model's predictions and the target labels in a differentiable
manner, effectively integrating distribution information into model training.
Dist Loss enables deep learning models to regularize their output distribution
during training, effectively enhancing their focus on few-shot regions. We have
conducted extensive experiments across three datasets spanning computer vision
and healthcare: IMDB-WIKI-DIR, AgeDB-DIR, and ECG-Ka-DIR. The results
demonstrate that Dist Loss effectively mitigates the negative impact of
imbalanced data distribution on model performance, achieving state-of-the-art
results in sparse data regions. Furthermore, Dist Loss is easy to integrate,
complementing existing methods.

ÊëòË¶ÅÔºö<paragraph>‰∏çÂπ≥Ë°°Ë≥áÊñôÂàÜ‰ΩàÂú®ÂØ¶ÈöõÊÉÖÊ≥Å‰∏≠ÂæàÂ∏∏Ë¶ãÔºåÂ∞ç‰∏çÂπ≥Ë°°ÂàÜÈ°ûÂíå‰∏çÂπ≥Ë°°ÂõûÊ≠∏‰ªªÂãôÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÂÆÉÂÄëÈÄöÂ∏∏Â∞éËá¥Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂú®Ê®£Êú¨ÂØÜÂ∫¶È´òÔºàÂ§öÊ®£Êú¨ÂçÄÂüüÔºâÁöÑÂçÄÂüüÈÅéÂ∫¶Êì¨ÂêàÔºåËÄåÂú®Ê®£Êú¨ÂØÜÂ∫¶‰ΩéÔºàÂ∞ëÊ®£Êú¨ÂçÄÂüüÔºâÁöÑÂçÄÂüüË°®Áèæ‰∏ç‰Ω≥„ÄÇÈÄôÁ®ÆÁâπÊÄßÈôêÂà∂‰∫ÜÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂú®ÂêÑÂÄãÈ†òÂüüÁöÑÂØ¶Áî®ÊÄßÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÔºåÂÖ∂‰∏≠Â∞ëÊ®£Êú¨Ë≥áÊñôÂçÄÂüüÂÖ∑ÊúâÊõ¥Â§ßÁöÑËá®Â∫äÁõ∏ÈóúÊÄß„ÄÇÂÑòÁÆ°ÊúÄËøëÁöÑÁ†îÁ©∂È°ØÁ§∫‰∫ÜÂú®‰∏çÂπ≥Ë°°ÂàÜÈ°û‰ªªÂãô‰∏≠Á¥çÂÖ•ÂàÜ‰ΩàË≥áË®äÁöÑÂ•ΩËôïÔºå‰ΩÜÊ≠§È°ûÁ≠ñÁï•Âú®‰∏çÂπ≥Ë°°ÂõûÊ≠∏‰∏≠ÂæàÂ∞ëË¢´Êé¢Ë®é„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéÂºïÂÖ•‰∏ÄÁ®ÆÁ®±ÁÇ∫ Dist Loss ÁöÑÊñ∞ÊêçÂ§±ÂáΩÊï∏‰æÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåË©≤ÂáΩÊï∏Êó®Âú®‰ª•ÂèØÂæÆÂàÜÁöÑÊñπÂºèÊúÄÂ∞èÂåñÊ®°ÂûãÈ†êÊ∏¨ËàáÁõÆÊ®ôÊ®ôÁ±§‰πãÈñìÁöÑÂàÜ‰ΩàË∑ùÈõ¢ÔºåÊúâÊïàÂú∞Â∞áÂàÜ‰ΩàË≥áË®äÊï¥ÂêàÂà∞Ê®°ÂûãË®ìÁ∑¥‰∏≠„ÄÇDist Loss ËÉΩËÆìÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂú®Ë®ìÁ∑¥ÊúüÈñìË™øÊï¥ÂÖ∂Ëº∏Âá∫ÂàÜ‰ΩàÔºåÊúâÊïàÂú∞Âä†Âº∑ÂÆÉÂÄëÂ∞çÂ∞ëÊ®£Êú¨ÂçÄÂüüÁöÑÈóúÊ≥®„ÄÇÊàëÂÄëË∑®Ë∂äÈõªËÖ¶Ë¶ñË¶∫ÂíåÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÁöÑ‰∏âÂÄãË≥áÊñôÈõÜÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºöIMDB-WIKI-DIR„ÄÅAgeDB-DIR Âíå ECG-Ka-DIR„ÄÇÁµêÊûúË°®ÊòéÔºåDist Loss ÊúâÊïàÂú∞Ê∏õËºï‰∫Ü‰∏çÂπ≥Ë°°Ë≥áÊñôÂàÜ‰ΩàÂ∞çÊ®°ÂûãÊïàËÉΩÁöÑË≤†Èù¢ÂΩ±ÈüøÔºåÂú®Á®ÄÁñèË≥áÊñôÂçÄÂüü‰∏≠ÂèñÂæó‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÁµêÊûú„ÄÇÊ≠§Â§ñÔºåDist Loss ÊòìÊñºÊï¥ÂêàÔºåÂèØË£úÂÖÖÁèæÊúâÊñπÊ≥ï„ÄÇ</paragraph>

##### **SynEHRgy: Synthesizing Mixed-Type Structured Electronic Health Records using Decoder-Only Transformers**
2411.13428v1 by Hojjat Karami, David Atienza, Anisoara Ionescu

Generating synthetic Electronic Health Records (EHRs) offers significant
potential for data augmentation, privacy-preserving data sharing, and improving
machine learning model training. We propose a novel tokenization strategy
tailored for structured EHR data, which encompasses diverse data types such as
covariates, ICD codes, and irregularly sampled time series. Using a GPT-like
decoder-only transformer model, we demonstrate the generation of high-quality
synthetic EHRs. Our approach is evaluated using the MIMIC-III dataset, and we
benchmark the fidelity, utility, and privacy of the generated data against
state-of-the-art models.

ÊëòË¶ÅÔºöÁîüÊàêÂêàÊàêÈõªÂ≠êÁóÖÊ≠∑ (EHR) Êèê‰æõ‰∫ÜÈ°ØËëóÁöÑÊï∏ÊìöÊì¥ÂÖÖ„ÄÅÈö±ÁßÅ‰øùË≠∑Êï∏ÊìöÂÖ±‰∫´‰ª•ÂèäÊîπÈÄ≤Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãË®ìÁ∑¥ÁöÑÊΩõÂäõ„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÈáùÂ∞çÁµêÊßãÂåñÈõªÂ≠êÁóÖÊ≠∑Êï∏ÊìöÈáèË∫´ÊâìÈÄ†ÁöÑÊñ∞ÂûãÊ®ôË®òÂåñÁ≠ñÁï•ÔºåÂÆÉÂåÖÂê´‰∫ÜÂêÑÁ®ÆÊï∏ÊìöÈ°ûÂûãÔºå‰æãÂ¶ÇÂçîËÆäÈáè„ÄÅICD ‰ª£Á¢ºÂíå‰∏çË¶èÂâáÊé°Ê®£ÁöÑÊôÇÂ∫è„ÄÇ‰ΩøÁî®È°û‰ºº GPT ÁöÑÂÉÖËß£Á¢ºÂô®TransformerÊ®°ÂûãÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÈ´òÂìÅË≥™ÂêàÊàêÈõªÂ≠êÁóÖÊ≠∑ÁöÑÁîüÊàê„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ï‰ΩøÁî® MIMIC-III Êï∏ÊìöÈõÜÈÄ≤Ë°åË©ï‰º∞ÔºåÊàëÂÄëÊ†πÊìöÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÂ∞çÁîüÊàêÊï∏ÊìöÁöÑ‰øùÁúüÂ∫¶„ÄÅÂØ¶Áî®ÊÄßÂíåÈö±ÁßÅÊÄßÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶„ÄÇ

##### **S$^2$ALM: Sequence-Structure Pre-trained Large Language Model for Comprehensive Antibody Representation Learning**
2411.15215v1 by Mingze Yin, Hanjing Zhou, Jialu Wu, Yiheng Zhu, Yuxuan Zhan, Zitai Kong, Hongxia Xu, Chang-Yu Hsieh, Jintai Chen, Tingjun Hou, Jian Wu

Antibodies safeguard our health through their precise and potent binding to
specific antigens, demonstrating promising therapeutic efficacy in the
treatment of numerous diseases, including COVID-19. Recent advancements in
biomedical language models have shown the great potential to interpret complex
biological structures and functions. However, existing antibody specific models
have a notable limitation that they lack explicit consideration for antibody
structural information, despite the fact that both 1D sequence and 3D structure
carry unique and complementary insights into antibody behavior and
functionality. This paper proposes Sequence-Structure multi-level pre-trained
Antibody Language Model (S$^2$ALM), combining holistic sequential and
structural information in one unified, generic antibody foundation model. We
construct a hierarchical pre-training paradigm incorporated with two customized
multi-level training objectives to facilitate the modeling of comprehensive
antibody representations. S$^2$ALM's representation space uncovers inherent
functional binding mechanisms, biological evolution properties and structural
interaction patterns. Pre-trained over 75 million sequences and 11.7 million
structures, S$^2$ALM can be adopted for diverse downstream tasks: accurately
predicting antigen-antibody binding affinities, precisely distinguishing B cell
maturation stages, identifying antibody crucial binding positions, and
specifically designing novel coronavirus-binding antibodies. Remarkably,
S$^2$ALM outperforms well-established and renowned baselines and sets new
state-of-the-art performance across extensive antibody specific understanding
and generation tasks. S$^2$ALM's ability to model comprehensive and generalized
representations further positions its potential to advance real-world
therapeutic antibody development, potentially addressing unmet academic,
industrial, and clinical needs.

ÊëòË¶ÅÔºö<paragraph>ÊäóÈ´îÈÄèÈÅéÁ≤æÊ∫ñ‰∏îÂº∑ËÄåÊúâÂäõÁöÑÁµêÂêàÔºåÈáùÂ∞çÁâπÂÆöÊäóÂéü‰æÜ‰øùË≠∑ÊàëÂÄëÁöÑÂÅ•Â∫∑ÔºåÂú®ÂåÖÊã¨ COVID-19 Âú®ÂÖßÁöÑË®±Â§öÁñæÁóÖÁöÑÊ≤ªÁôÇ‰∏≠ÔºåÂ±ïÁèæÂá∫ÊúâÂ∏åÊúõÁöÑÊ≤ªÁôÇÂäüÊïà„ÄÇÁîüÁâ©ÈÜ´Â≠∏Ë™ûË®ÄÊ®°ÂûãÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºåÂ∑≤È°ØÁ§∫Âá∫Ë©ÆÈáãË§áÈõúÁîüÁâ©ÁµêÊßãÂíåÂäüËÉΩÁöÑÂ∑®Â§ßÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÊäóÈ´îÁâπÂÆöÊ®°ÂûãÊúâ‰∏ÄÂÄãÈ°ØËëóÁöÑÈôêÂà∂ÔºåÂ∞±ÊòØÂÆÉÂÄëÁº∫‰πèÂ∞çÊäóÈ´îÁµêÊßãË≥áË®äÁöÑÊòéÁ¢∫ËÄÉÈáèÔºåÂÑòÁÆ° 1D Â∫èÂàóÂíå 3D ÁµêÊßãÈÉΩËÉΩÊèê‰æõÁç®Áâπ‰∏î‰∫íË£úÁöÑË¶ãËß£ÔºåÊ∑±ÂÖ•‰∫ÜËß£ÊäóÈ´îË°åÁÇ∫ÂíåÂäüËÉΩ„ÄÇÊú¨ÊñáÊèêÂá∫Â∫èÂàóÁµêÊßãÂ§öÂ±§Á¥öÈ†êË®ìÁ∑¥ÊäóÈ´îË™ûË®ÄÊ®°Âûã (S$^2$ALM)ÔºåÂ∞áÊï¥È´îÂ∫èÂàóÂíåÁµêÊßãË≥áË®äÁµêÂêàÂú®‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÈÄöÁî®ÊäóÈ´îÂü∫Á§éÊ®°Âûã‰∏≠„ÄÇÊàëÂÄëÂª∫Êßã‰∫Ü‰∏ÄÂÄãÂàÜÂ±§È†êË®ìÁ∑¥ÁØÑ‰æãÔºå‰∏¶ÁµêÂêàÂÖ©ÂÄãÂÆ¢Ë£ΩÂåñÂ§öÂ±§Á¥öË®ìÁ∑¥ÁõÆÊ®ôÔºå‰ª•Âà©ÊñºÂª∫Ê®°ÂÖ®Èù¢ÁöÑÊäóÈ´îË°®Á§∫„ÄÇS$^2$ALM ÁöÑË°®Á§∫Á©∫ÈñìÊè≠Á§∫‰∫ÜÂÖßÂú®ÁöÑÂäüËÉΩÁµêÂêàÊ©üÂà∂„ÄÅÁîüÁâ©ÊºîÂåñÁâπÊÄßÂíåÁµêÊßã‰∫íÂãïÊ®°Âºè„ÄÇS$^2$ALM È†êÂÖàË®ìÁ∑¥Ë∂ÖÈÅé 7500 Ëê¨ÂÄãÂ∫èÂàóÂíå 1170 Ëê¨ÂÄãÁµêÊßãÔºåÂèØÊé°Áî®ÊñºÂêÑÁ®Æ‰∏ãÊ∏∏‰ªªÂãôÔºöÊ∫ñÁ¢∫È†êÊ∏¨ÊäóÂéüÊäóÈ´îÁµêÂêàË¶™ÂíåÂäõ„ÄÅÁ≤æÁ¢∫ÂçÄÂàÜ B Á¥∞ËÉûÊàêÁÜüÈöéÊÆµ„ÄÅË≠òÂà•ÊäóÈ´îÈóúÈçµÁµêÂêà‰ΩçÁΩÆÔºå‰ª•ÂèäÁâπÂà•Ë®≠Ë®àÊñ∞ÂûãÂÜ†ÁãÄÁóÖÊØíÁµêÂêàÊäóÈ´î„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåS$^2$ALM ÂÑ™ÊñºÊó¢Êúâ‰∏îÁü•ÂêçÁöÑÂü∫Á∑öÔºå‰∏¶Âú®Âª£Ê≥õÁöÑÊäóÈ´îÁâπÂÆöÁêÜËß£ÂíåÁîüÊàê‰ªªÂãô‰∏≠ÔºåÊ®πÁ´ãÊñ∞ÁöÑÊúÄÂÖàÈÄ≤ÊïàËÉΩ„ÄÇS$^2$ALM Âª∫Ê®°ÂÖ®Èù¢‰∏îÂª£Ê≥õË°®Á§∫ÁöÑËÉΩÂäõÔºåÈÄ≤‰∏ÄÊ≠•Â•†ÂÆö‰∫ÜÂÖ∂Âú®Êé®ÈÄ≤ÁèæÂØ¶‰∏ñÁïåÊ≤ªÁôÇÊÄßÊäóÈ´îÈñãÁôºÁöÑÊΩõÂäõÔºåÊúâÂèØËÉΩÊªøË∂≥Êú™ÊªøË∂≥ÁöÑÂ≠∏Ë°ì„ÄÅÁî¢Ê•≠ÂíåËá®Â∫äÈúÄÊ±Ç„ÄÇ</paragraph>

##### **Are Large Language Models Memorizing Bug Benchmarks?**
2411.13323v1 by Daniel Ramos, Claudia Mamede, Kush Jain, Paulo Canelas, Catarina Gamboa, Claire Le Goues

Large Language Models (LLMs) have become integral to various software
engineering tasks, including code generation, bug detection, and repair. To
evaluate model performance in these domains, numerous bug benchmarks containing
real-world bugs from software projects have been developed. However, a growing
concern within the software engineering community is that these benchmarks may
not reliably reflect true LLM performance due to the risk of data leakage.
Despite this concern, limited research has been conducted to quantify the
impact of potential leakage.
  In this paper, we systematically evaluate popular LLMs to assess their
susceptibility to data leakage from widely used bug benchmarks. To identify
potential leakage, we use multiple metrics, including a study of benchmark
membership within commonly used training datasets, as well as analyses of
negative log-likelihood and n-gram accuracy. Our findings show that certain
models, in particular codegen-multi, exhibit significant evidence of
memorization in widely used benchmarks like Defects4J, while newer models
trained on larger datasets like LLaMa 3.1 exhibit limited signs of leakage.
These results highlight the need for careful benchmark selection and the
adoption of robust metrics to adequately assess models capabilities.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤ÊàêÁÇ∫ÂêÑÁ®ÆËªüÈ´îÂ∑•Á®ã‰ªªÂãô‰∏≠‰∏çÂèØÊàñÁº∫ÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÂåÖÊã¨Á®ãÂºèÁ¢ºÁî¢Áîü„ÄÅÈåØË™§ÂÅµÊ∏¨Âíå‰øÆÂæ©„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ÈÄô‰∫õÈ†òÂüü‰∏≠ÁöÑÊ®°ÂûãÊïàËÉΩÔºåÂ∑≤ÈñãÁôºÂá∫Ë®±Â§öÂåÖÂê´ËªüÈ´îÂ∞àÊ°à‰∏≠ÁúüÂØ¶ÈåØË™§ÁöÑÈåØË™§Âü∫Ê∫ñÊ∏¨Ë©¶„ÄÇÁÑ∂ËÄåÔºåËªüÈ´îÂ∑•Á®ãÁ§æÁæ§‰∏≠Êó•ÁõäÈóúÊ≥®ÁöÑÊòØÔºåÁî±ÊñºË≥áÊñôÂ§ñÊ¥©ÁöÑÈ¢®Èö™ÔºåÈÄô‰∫õÂü∫Ê∫ñÊ∏¨Ë©¶ÂèØËÉΩÁÑ°Ê≥ïÂèØÈù†Âú∞ÂèçÊò†ÁúüÊ≠£ÁöÑ LLM ÊïàËÉΩ„ÄÇÂÑòÁÆ°ÊúâÊ≠§ÁñëÊÖÆÔºå‰ΩÜÈáùÂ∞çÈáèÂåñÊΩõÂú®Â§ñÊ¥©ÂΩ±ÈüøÁöÑÁ†îÁ©∂ÂçªÂçÅÂàÜÊúâÈôê„ÄÇ
Âú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁ≥ªÁµ±ÊÄßÂú∞Ë©ï‰º∞ÁÜ±ÈñÄ LLMÔºå‰ª•Ë©ï‰º∞ÂÆÉÂÄëÂ∞çÂª£Ê≥õ‰ΩøÁî®ÁöÑÈåØË™§Âü∫Ê∫ñÊ∏¨Ë©¶‰∏≠Ë≥áÊñôÂ§ñÊ¥©ÁöÑÊïèÊÑüÊÄß„ÄÇÁÇ∫‰∫ÜË≠òÂà•ÊΩõÂú®ÁöÑÂ§ñÊ¥©ÔºåÊàëÂÄë‰ΩøÁî®Â§öÁ®ÆÊåáÊ®ôÔºåÂåÖÊã¨Á†îÁ©∂Âü∫Ê∫ñÊ∏¨Ë©¶ÊàêÂì°Ë≥áÊ†ºÂú®Â∏∏Áî®ÁöÑË®ìÁ∑¥Ë≥áÊñôÈõÜ‰∏≠ÁöÑÊÉÖÊ≥ÅÔºå‰ª•ÂèäÂ∞çË≤†Â∞çÊï∏‰ººÁÑ∂Âíå n-gram Á≤æÁ¢∫Â∫¶ÁöÑÂàÜÊûê„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåÊüê‰∫õÊ®°ÂûãÔºåÁâπÂà•ÊòØ codegen-multiÔºåÂú® Defects4J Á≠âÂª£Ê≥õ‰ΩøÁî®ÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠Â±ïÁèæÂá∫È°ØËëóÁöÑË®òÊÜ∂Ë≠âÊìöÔºåËÄåË®ìÁ∑¥ÊñºËºÉÂ§ßÂûãË≥áÊñôÈõÜÔºà‰æãÂ¶Ç LLaMa 3.1ÔºâÁöÑËºÉÊñ∞Ê®°ÂûãÂâáÂ±ïÁèæÂá∫ÊúâÈôêÁöÑÂ§ñÊ¥©Ë∑°Ë±°„ÄÇÈÄô‰∫õÁµêÊûúÁ™ÅÈ°Ø‰∫Ü‰ªîÁ¥∞ÈÅ∏ÊìáÂü∫Ê∫ñÊ∏¨Ë©¶ÂíåÊé°Áî®Á©©ÂÅ•ÊåáÊ®ô‰ª•ÂÖÖÂàÜË©ï‰º∞Ê®°ÂûãÂäüËÉΩÁöÑÂøÖË¶ÅÊÄß„ÄÇ

##### **Uni-Mlip: Unified Self-supervision for Medical Vision Language Pre-training**
2411.15207v1 by Ameera Bawazir, Kebin Wu, Wenbin Li

Recent advancements in vision-language pre-training via contrastive learning
have significantly improved performance across computer vision tasks. However,
in the medical domain, obtaining multimodal data is often costly and
challenging due to privacy, sensitivity, and annotation complexity. To mitigate
data scarcity while boosting model performance, we introduce \textbf{Uni-Mlip},
a unified self-supervision framework specifically designed to enhance medical
vision-language pre-training. Uni-Mlip seamlessly integrates cross-modality,
uni-modality, and fused-modality self-supervision techniques at the data-level
and the feature-level. Additionally, Uni-Mlip tailors uni-modal image
self-supervision to accommodate the unique characteristics of medical images.
Our experiments across datasets of varying scales demonstrate that Uni-Mlip
significantly surpasses current state-of-the-art methods in three key
downstream tasks: image-text retrieval, image classification, and visual
question answering (VQA).

ÊëòË¶ÅÔºöÈÄèÈÅéÂ∞çÊØîÂ≠∏ÁøíÈÄ≤Ë°åË¶ñË¶∫Ë™ûË®ÄÈ†êË®ìÁ∑¥ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºåÂ∑≤È°ØËëóÊèêÂçáÈõªËÖ¶Ë¶ñË¶∫‰ªªÂãôÁöÑÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÂú®ÈÜ´Â≠∏È†òÂüü‰∏≠ÔºåÂèñÂæóÂ§öÊ®°ÊÖãË≥áÊñôÈÄöÂ∏∏ÊàêÊú¨È´òÊòÇ‰∏îÂÖ∑ÊåëÊà∞ÊÄßÔºåÂéüÂõ†Âú®ÊñºÈö±ÁßÅ„ÄÅÊïèÊÑüÊÄßÂíåÊ®ôË®ªÁöÑË§áÈõúÊÄß„ÄÇÁÇ∫‰∫ÜÂú®ÊèêÂçáÊ®°ÂûãÊïàËÉΩÁöÑÂêåÊôÇÊ∏õËºïË≥áÊñôÁ®ÄÂ∞ëÁöÑÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü \textbf{Uni-Mlip}ÔºåÈÄôÊòØ‰∏ÄÂÄãÁµ±‰∏ÄÁöÑËá™ÊàëÁõ£Áù£Êû∂ÊßãÔºåÂ∞àÈñÄË®≠Ë®àÁî®ÊñºÂ¢ûÂº∑ÈÜ´Â≠∏Ë¶ñË¶∫Ë™ûË®ÄÈ†êË®ìÁ∑¥„ÄÇUni-Mlip Âú®Ë≥áÊñôÂ±§Á¥öÂíåÁâπÂæµÂ±§Á¥öÁÑ°Á∏´Êï¥ÂêàË∑®Ê®°ÊÖã„ÄÅÂñÆÊ®°ÊÖãÂíåËûçÂêàÊ®°ÊÖãÁöÑËá™ÊàëÁõ£Áù£ÊäÄË°ì„ÄÇÊ≠§Â§ñÔºåUni-Mlip ÈáùÂ∞çÂñÆÊ®°ÊÖãÂΩ±ÂÉèËá™ÊàëÁõ£Áù£ÈÄ≤Ë°åË™øÊï¥Ôºå‰ª•ÈÅ©ÊáâÈÜ´Â≠∏ÂΩ±ÂÉèÁöÑÁç®ÁâπÁâπÊÄß„ÄÇÊàëÂÄëÂú®‰∏çÂêåË¶èÊ®°ÁöÑË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂØ¶È©óË≠âÊòéÔºåUni-Mlip Âú®‰∏âÂÄãÈóúÈçµÁöÑ‰∏ãÊ∏∏‰ªªÂãô‰∏≠È°ØËëóË∂ÖË∂äÁõÆÂâçÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÔºöÂΩ±ÂÉèÊñáÂ≠óÊ™¢Á¥¢„ÄÅÂΩ±ÂÉèÂàÜÈ°ûÂíåË¶ñË¶∫ÂïèÁ≠î (VQA)„ÄÇ

##### **GraphCL: Graph-based Clustering for Semi-Supervised Medical Image Segmentation**
2411.13147v2 by Mengzhu Wang, Jiao Li, Houcheng Su, Nan Yin, Liang Yang, Shen Li

Semi-supervised learning (SSL) has made notable advancements in medical image
segmentation (MIS), particularly in scenarios with limited labeled data and
significantly enhancing data utilization efficiency. Previous methods primarily
focus on complex training strategies to utilize unlabeled data but neglect the
importance of graph structural information. Different from existing methods, we
propose a graph-based clustering for semi-supervised medical image segmentation
(GraphCL) by jointly modeling graph data structure in a unified deep model. The
proposed GraphCL model enjoys several advantages. Firstly, to the best of our
knowledge, this is the first work to model the data structure information for
semi-supervised medical image segmentation (SSMIS). Secondly, to get the
clustered features across different graphs, we integrate both pairwise
affinities between local image features and raw features as inputs. Extensive
experimental results on three standard benchmarks show that the proposed
GraphCL algorithm outperforms state-of-the-art semi-supervised medical image
segmentation methods.

ÊëòË¶ÅÔºöÂçäÁõ£Áù£Â≠∏Áøí (SSL) Â∑≤Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤ (MIS) ‰∏≠ÂèñÂæóÈ°ØËëóÈÄ≤Â±ïÔºåÁâπÂà•ÊòØÂú®Ê®ôÁ±§Ë≥áÊñôÊúâÈôêÁöÑÊÉÖÊ≥Å‰∏ãÔºå‰∏¶È°ØËëóÊèêÂçáË≥áÊñôÂà©Áî®ÊïàÁéá„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂ÊñπÊ≥ï‰∏ªË¶ÅÂ∞àÊ≥®ÊñºË§áÈõúÁöÑË®ìÁ∑¥Á≠ñÁï•‰ª•Âà©Áî®Êú™Ê®ôÁ±§Ë≥áÊñôÔºåÂçªÂøΩÁï•‰∫ÜÂúñÂΩ¢ÁµêÊßãË≥áË®äÁöÑÈáçË¶ÅÊÄß„ÄÇÊúâÂà•ÊñºÁèæÊúâÊñπÊ≥ïÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÂúñÂΩ¢ËÅöÈ°ûÁöÑÂçäÁõ£Áù£ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤ (GraphCL)ÔºåÈÄèÈÅéÂú®‰∏ÄÂÄãÁµ±‰∏ÄÊ∑±Â∫¶Ê®°Âûã‰∏≠ËÅØÂêàÂª∫Ê®°ÂúñÂΩ¢Ë≥áÊñôÁµêÊßã„ÄÇÊâÄÊèêÂá∫ÁöÑ GraphCL Ê®°Âûã‰∫´ÊúâË®±Â§öÂÑ™Èªû„ÄÇÈ¶ñÂÖàÔºåÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÁÇ∫ÂçäÁõ£Áù£ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤ (SSMIS) Âª∫Ê®°Ë≥áÊñôÁµêÊßãË≥áË®äÁöÑÁ†îÁ©∂„ÄÇÂÖ∂Ê¨°ÔºåÁÇ∫‰∫ÜÂèñÂæóË∑®‰∏çÂêåÂúñÂΩ¢ÁöÑËÅöÈ°ûÁâπÂæµÔºåÊàëÂÄëÂ∞áÂ±ÄÈÉ®ÂΩ±ÂÉèÁâπÂæµÂíåÂéüÂßãÁâπÂæµ‰πãÈñìÁöÑÊàêÂ∞çÁõ∏‰ººÊÄßÈÉΩÊï¥ÂêàÁÇ∫Ëº∏ÂÖ•„ÄÇÂú®‰∏âÂÄãÊ®ôÊ∫ñÂü∫Ê∫ñ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÊâÄÊèêÂá∫ÁöÑ GraphCL ÊºîÁÆóÊ≥ïÂÑ™ÊñºÁèæÊúâÊúÄÂÖàÈÄ≤ÁöÑÂçäÁõ£Áù£ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤ÊñπÊ≥ï„ÄÇ

##### **Ensuring Safety and Trust: Analyzing the Risks of Large Language Models in Medicine**
2411.14487v1 by Yifan Yang, Qiao Jin, Robert Leaman, Xiaoyu Liu, Guangzhi Xiong, Maame Sarfo-Gyamfi, Changlin Gong, Santiago Ferri√®re-Steinert, W. John Wilbur, Xiaojun Li, Jiaxin Yuan, Bang An, Kelvin S. Castro, Francisco Erramuspe √Ålvarez, Mat√≠as Stockle, Aidong Zhang, Furong Huang, Zhiyong Lu

The remarkable capabilities of Large Language Models (LLMs) make them
increasingly compelling for adoption in real-world healthcare applications.
However, the risks associated with using LLMs in medical applications have not
been systematically characterized. We propose using five key principles for
safe and trustworthy medical AI: Truthfulness, Resilience, Fairness,
Robustness, and Privacy, along with ten specific aspects. Under this
comprehensive framework, we introduce a novel MedGuard benchmark with 1,000
expert-verified questions. Our evaluation of 11 commonly used LLMs shows that
the current language models, regardless of their safety alignment mechanisms,
generally perform poorly on most of our benchmarks, particularly when compared
to the high performance of human physicians. Despite recent reports indicate
that advanced LLMs like ChatGPT can match or even exceed human performance in
various medical tasks, this study underscores a significant safety gap,
highlighting the crucial need for human oversight and the implementation of AI
safety guardrails.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊìÅÊúâÈùûÂá°ÁöÑËÉΩÂäõÔºå‰ΩøÂÖ∂Âú®ÂØ¶ÈöõÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®‰∏≠Ë∂ä‰æÜË∂äÂºï‰∫∫Ê≥®ÁõÆ„ÄÇ
ÁÑ∂ËÄåÔºåÂú®ÈÜ´ÁôÇÊáâÁî®‰∏≠‰ΩøÁî® LLM Áõ∏ÈóúÁöÑÈ¢®Èö™Â∞öÊú™ÂæóÂà∞Á≥ªÁµ±ÊÄßÁöÑÊèèËø∞„ÄÇÊàëÂÄëÂª∫Ë≠∞‰ΩøÁî®‰∫îÈ†ÖÈóúÈçµÂéüÂâáÔºå‰ª•Á¢∫‰øùÈÜ´ÁôÇ AI ÁöÑÂÆâÂÖ®ÂíåÂèØ‰ø°Ë≥¥ÔºöÁúüÂØ¶ÊÄß„ÄÅÂΩàÊÄß„ÄÅÂÖ¨Âπ≥ÊÄß„ÄÅÁ©©ÂÅ•ÊÄßÂíåÈö±ÁßÅÔºå‰ª•ÂèäÂçÅÂÄãÂÖ∑È´îÊñπÈù¢„ÄÇÂú®ÈÄôÂÄãÂÖ®Èù¢ÁöÑÊû∂Êßã‰∏ãÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑ MedGuard Âü∫Ê∫ñÔºåÂÖ∂‰∏≠ÂåÖÂê´ 1,000 ÂÄãÁî±Â∞àÂÆ∂È©óË≠âÁöÑÂïèÈ°å„ÄÇÊàëÂÄëÂ∞ç 11 ÂÄãÂ∏∏Áî® LLM ÁöÑË©ï‰º∞Ë°®ÊòéÔºåÁÑ°Ë´ñÂÖ∂ÂÆâÂÖ®Â∞çÈΩäÊ©üÂà∂Â¶Ç‰ΩïÔºåÁï∂ÂâçÁöÑË™ûË®ÄÊ®°ÂûãÂú®ÊàëÂÄëÂ§ßÂ§öÊï∏Âü∫Ê∫ñÊ∏¨Ë©¶‰∏≠Ë°®ÁèæÊôÆÈÅç‰∏ç‰Ω≥ÔºåÁâπÂà•ÊòØËàá‰∫∫È°ûÈÜ´ÁîüÁöÑÈ´òË°®ÁèæÁõ∏ÊØîÊôÇ„ÄÇÂÑòÁÆ°ÊúÄËøëÁöÑÂ†±ÂëäË°®ÊòéÔºåÂÉè ChatGPT ÈÄôÊ®£ÁöÑÂÖàÈÄ≤ LLM Âú®ÂêÑÁ®ÆÈÜ´ÁôÇ‰ªªÂãô‰∏≠ÂèØ‰ª•ÈÅîÂà∞ÊàñÁîöËá≥Ë∂ÖÈÅé‰∫∫È°ûÁöÑË°®ÁèæÔºå‰ΩÜÈÄôÈ†ÖÁ†îÁ©∂Âº∑Ë™ø‰∫Ü‰∏ÄÂÄãÈáçÂ§ßÁöÑÂÆâÂÖ®Â∑ÆË∑ùÔºåÁ™ÅÈ°Ø‰∫Ü‰∫∫È°ûÁõ£Áù£ÂíåÂØ¶ÊñΩ AI ÂÆâÂÖ®Ë≠∑Ê¨ÑÁöÑÈóúÈçµÈúÄÊ±Ç„ÄÇ

##### **Training Physics-Driven Deep Learning Reconstruction without Raw Data Access for Equitable Fast MRI**
2411.13022v1 by Ya≈üar Utku Al√ßalar, Merve G√ºlle, Mehmet Ak√ßakaya

Physics-driven deep learning (PD-DL) approaches have become popular for
improved reconstruction of fast magnetic resonance imaging (MRI) scans. Even
though PD-DL offers higher acceleration rates compared to existing clinical
fast MRI techniques, their use has been limited outside specialized MRI
centers. One impediment for their deployment is the difficulties with
generalization to pathologies or population groups that are not
well-represented in training sets. This has been noted in several studies, and
fine-tuning on target populations to improve reconstruction has been suggested.
However, current approaches for PD-DL training require access to raw k-space
measurements, which is typically only available at specialized MRI centers that
have research agreements for such data access. This is especially an issue for
rural and underserved areas, where commercial MRI scanners only provide access
to a final reconstructed image. To tackle these challenges, we propose
Compressibility-inspired Unsupervised Learning via Parallel Imaging Fidelity
(CUPID) for high-quality PD-DL training, using only routine clinical
reconstructed images exported from an MRI scanner. CUPID evaluates the goodness
of the output with a compressibility-based approach, while ensuring that the
output stays consistent with the clinical parallel imaging reconstruction
through well-designed perturbations. Our results show that CUPID achieves
similar quality compared to well-established PD-DL training strategies that
require raw k-space data access, while outperforming conventional compressed
sensing (CS) and state-of-the-art generative methods. We also demonstrate its
effectiveness in a zero-shot training setup for retrospectively and
prospectively sub-sampled acquisitions, attesting to its minimal training
burden.

ÊëòË¶ÅÔºö<paragraph>Áâ©ÁêÜÈ©ÖÂãïÊ∑±Â∫¶Â≠∏Áøí (PD-DL) ÊñπÊ≥ïÂ∑≤Âª£ÂèóÊ≠°ËøéÔºåÁî®ÊñºÊîπÂñÑÂø´ÈÄüÁ£ÅÊåØÈÄ†ÂΩ± (MRI) ÊéÉÊèèÁöÑÈáçÂª∫„ÄÇÂÑòÁÆ°ËàáÁèæÊúâÁöÑËá®Â∫äÂø´ÈÄü MRI ÊäÄË°ìÁõ∏ÊØîÔºåPD-DL Êèê‰æõ‰∫ÜÊõ¥È´òÁöÑÂä†ÈÄüÁéáÔºå‰ΩÜÂÖ∂‰ΩøÁî®Â∑≤Ë¢´ÈôêÂà∂Âú®Â∞àÈñÄÁöÑ MRI ‰∏≠ÂøÉ‰πãÂ§ñ„ÄÇÈÉ®ÁΩ≤ÂÆÉÂÄëÁöÑ‰∏ÄÂÄãÈöúÁ§ôÊòØÈõ£‰ª•Êé®Âª£Âà∞Ë®ìÁ∑¥ÈõÜ‰∏≠Êú™ÂÖÖÂàÜÂëàÁèæÁöÑÁóÖÁêÜÊàñ‰∫∫Áæ§„ÄÇÈÄôÂ∑≤Âú®Â§öÈ†ÖÁ†îÁ©∂‰∏≠Ë®ªÊòéÔºå‰∏¶‰∏îÂª∫Ë≠∞Â∞çÁõÆÊ®ô‰∫∫Áæ§ÈÄ≤Ë°åÂæÆË™ø‰ª•ÊîπÂñÑÈáçÂª∫„ÄÇÁÑ∂ËÄåÔºåÁï∂Ââç PD-DL Ë®ìÁ∑¥ÊñπÊ≥ïÈúÄË¶ÅÂ≠òÂèñÂéüÂßã k-space ÈáèÊ∏¨ÔºåËÄåÈÄôÈÄöÂ∏∏ÂÉÖÂú®ÂÖ∑ÊúâÊ≠§È°ûË≥áÊñôÂ≠òÂèñÁ†îÁ©∂ÂçîË≠∞ÁöÑÂ∞àÈñÄ MRI ‰∏≠ÂøÉÊâçÂèØÂèñÂæó„ÄÇÈÄôÂ∞çÊñºÈÑâÊùëÂíåÊúçÂãô‰∏çË∂≥ÁöÑÂú∞ÂçÄ‰æÜË™™Â∞§ÂÖ∂ÊàêÂïèÈ°åÔºåÂõ†ÁÇ∫ÂïÜÊ•≠ MRI ÊéÉÊèèÂÑÄÂÉÖÊèê‰æõÂ≠òÂèñÊúÄÁµÇÈáçÂª∫ÂΩ±ÂÉè„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫ÈÄèÈÅéÂπ≥Ë°åÂΩ±ÂÉè‰øùÁúüÂ∫¶ (CUPID) ÈÄ≤Ë°åÂèóÂ£ìÁ∏ÆÊÄßÂïüÁôºÁöÑÈùûÁõ£Áù£ÂºèÂ≠∏ÁøíÔºåÂÉÖ‰ΩøÁî®Âæû MRI ÊéÉÊèèÂÑÄËº∏Âá∫ÁöÑ‰æãË°åËá®Â∫äÈáçÂª∫ÂΩ±ÂÉèÔºå‰ª•ÈÄ≤Ë°åÈ´òÂìÅË≥™ PD-DL Ë®ìÁ∑¥„ÄÇCUPID ‰ΩøÁî®Âü∫ÊñºÂ£ìÁ∏ÆÊÄßÁöÑÊñπÊ≥ïË©ï‰º∞Ëº∏Âá∫ÁöÑÂÑ™Âä£ÔºåÂêåÊôÇÁ¢∫‰øùËº∏Âá∫ÈÄèÈÅéÁ≤æÂøÉË®≠Ë®àÁöÑÊìæÂãïËàáËá®Â∫äÂπ≥Ë°åÂΩ±ÂÉèÈáçÂª∫‰øùÊåÅ‰∏ÄËá¥„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåËàáÈúÄË¶ÅÂéüÂßã k-space Ë≥áÊñôÂ≠òÂèñÁöÑÂÆåÂñÑ PD-DL Ë®ìÁ∑¥Á≠ñÁï•Áõ∏ÊØîÔºåCUPID ÈÅîÂà∞‰∫ÜÈ°û‰ººÁöÑÂìÅË≥™ÔºåÂêåÊôÇÂÑ™ÊñºÂÇ≥Áµ±ÁöÑÂ£ìÁ∏ÆÊÑüÊ∏¨ (CS) ÂíåÊúÄÂÖàÈÄ≤ÁöÑÁîüÊàêÊñπÊ≥ï„ÄÇÊàëÂÄëÈÇÑÂ±ïÁ§∫‰∫ÜÂÆÉÂú®Èõ∂Ê¨°Â≠∏ÁøíË®≠ÂÆö‰∏≠Â∞çÂõûÊ∫ØÊÄßÂíåÂâçÁûªÊÄßÂ≠êÊäΩÊ®£Êì∑ÂèñÁöÑÊúâÊïàÊÄßÔºåË≠âÊòé‰∫ÜÂÆÉÁöÑË®ìÁ∑¥Ë≤†ÊìîÂæàÂ∞è„ÄÇ</paragraph>

##### **Automating Sonologists USG Commands with AI and Voice Interface**
2411.13006v1 by Emad Mohamed, Shruti Tiwari, Sheena Christabel Pravin

This research presents an advanced AI-powered ultrasound imaging system that
incorporates real-time image processing, organ tracking, and voice commands to
enhance the efficiency and accuracy of diagnoses in clinical practice.
Traditional ultrasound diagnostics often require significant time and introduce
a degree of subjectivity due to user interaction. The goal of this innovative
solution is to provide Sonologists with a more predictable and productive
imaging procedure utilizing artificial intelligence, computer vision, and voice
technology. The functionality of the system employs computer vision and deep
learning algorithms, specifically adopting the Mask R-CNN model from Detectron2
for semantic segmentation of organs and key landmarks. This automation improves
diagnostic accuracy by enabling the extraction of valuable information with
minimal human input. Additionally, it includes a voice recognition feature that
allows for hands-free operation, enabling users to control the system with
commands such as freeze or liver, all while maintaining their focus on the
patient. The architecture comprises video processing and real-time segmentation
modules that prepare the system to perform essential imaging functions, such as
freezing and zooming in on frames. The liver histopathology module, optimized
for detecting fibrosis, achieved an impressive accuracy of 98.6%. Furthermore,
the organ segmentation module produces output confidence levels between 50% and
95%, demonstrating its efficacy in organ detection.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÈÄ≤ÈöéÁöÑ‰∫∫Â∑•Êô∫ÊÖßË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÁ≥ªÁµ±ÔºåÂÆÉÁµêÂêà‰∫ÜÂç≥ÊôÇÂΩ±ÂÉèËôïÁêÜ„ÄÅÂô®ÂÆòËøΩËπ§ÂíåË™ûÈü≥Êåá‰ª§Ôºå‰ª•Â¢ûÂº∑Ëá®Â∫äÂØ¶Âãô‰∏≠Ë®∫Êñ∑ÁöÑÊïàÁéáÂíåÊ∫ñÁ¢∫ÊÄß„ÄÇÂÇ≥Áµ±ÁöÑË∂ÖÈü≥Ê≥¢Ë®∫Êñ∑ÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÁöÑÊôÇÈñìÔºå‰∏¶Áî±Êñº‰ΩøÁî®ËÄÖÁöÑ‰∫íÂãïËÄåÂºïÂÖ•‰∫Ü‰∏ÄÂÆöÁöÑ‰∏ªËßÄÊÄß„ÄÇÈÄôÂÄãÂâµÊñ∞Ëß£Ê±∫ÊñπÊ°àÁöÑÁõÆÊ®ôÊòØÁÇ∫Ë∂ÖÈü≥Ê≥¢Ê™¢Êü•ÈÜ´Â∏´Êèê‰æõ‰∏ÄÂÄãÊõ¥ÂèØÈ†êÊ∏¨‰∏îÊõ¥ÂÖ∑ÁîüÁî¢ÂäõÁöÑÂΩ±ÂÉèÁ®ãÂ∫èÔºåÂà©Áî®‰∫∫Â∑•Êô∫ÊÖß„ÄÅÈõªËÖ¶Ë¶ñË¶∫ÂíåË™ûÈü≥ÊäÄË°ì„ÄÇË©≤Á≥ªÁµ±ÁöÑÂäüËÉΩÊé°Áî®ÈõªËÖ¶Ë¶ñË¶∫ÂíåÊ∑±Â∫¶Â≠∏ÁøíÊºîÁÆóÊ≥ïÔºåÁâπÂà•ÊòØÊé°Áî® Detectron2 ‰∏≠ÁöÑ Mask R-CNN Ê®°Âûã‰æÜÈÄ≤Ë°åÂô®ÂÆòÂíåÈóúÈçµÂú∞Ê®ôÁöÑË™ûÊÑèÂàÜÂâ≤„ÄÇÊ≠§Ëá™ÂãïÂåñÈÄèÈÅé‰ª•ÊúÄÂ∞ëÁöÑ‰∫∫Â∑•Ëº∏ÂÖ•ÊèêÂèñÊúâÂÉπÂÄºÁöÑË≥áË®ä‰æÜÊèêÈ´òË®∫Êñ∑Ê∫ñÁ¢∫ÊÄß„ÄÇÊ≠§Â§ñÔºåÂÆÉÈÇÑÂåÖÊã¨‰∏ÄÂÄãË™ûÈü≥Ëæ®Ë≠òÂäüËÉΩÔºåÂÖÅË®±ÂÖçÊåÅÊìç‰ΩúÔºå‰ΩøÁî®Êà∂ËÉΩÂ§†‰ΩøÁî®ÂáçÁµêÊàñËÇùËáüÁ≠âÊåá‰ª§‰æÜÊéßÂà∂Á≥ªÁµ±ÔºåÂêåÊôÇÂ∞áÊ≥®ÊÑèÂäõÈõÜ‰∏≠Âú®ÊÇ£ËÄÖË∫´‰∏ä„ÄÇÊû∂ÊßãÂåÖÂê´Ë¶ñË®äËôïÁêÜÂíåÂç≥ÊôÇÂàÜÂâ≤Ê®°ÁµÑÔºåÊ∫ñÂÇôÁ≥ªÁµ±Âü∑Ë°åÂøÖË¶ÅÁöÑÂΩ±ÂÉèÂäüËÉΩÔºå‰æãÂ¶ÇÂáçÁµêÂíåÁ∏ÆÊîæÁï´Èù¢„ÄÇÈáùÂ∞çÁ∫ñÁ∂≠ÂåñÂÅµÊ∏¨ËÄåÊúÄ‰Ω≥ÂåñÁöÑËÇùËáüÁµÑÁπîÁóÖÁêÜÂ≠∏Ê®°ÁµÑÔºåÈÅîÂà∞‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑ 98.6% Ê∫ñÁ¢∫Â∫¶„ÄÇÊ≠§Â§ñÔºåÂô®ÂÆòÂàÜÂâ≤Ê®°ÁµÑÁî¢ÁîüÁöÑËº∏Âá∫‰ø°ÂøÉÊ∞¥Ê∫ñÂú® 50% Âà∞ 95% ‰πãÈñìÔºåË≠âÊòé‰∫ÜÂÖ∂Âú®Âô®ÂÆòÂÅµÊ∏¨‰∏≠ÁöÑÊïàËÉΩ„ÄÇ

##### **DrugGen: Advancing Drug Discovery with Large Language Models and Reinforcement Learning Feedback**
2411.14157v1 by Mahsa Sheikholeslami, Navid Mazrouei, Yousof Gheisari, Afshin Fasihi, Matin Irajpour, Ali Motahharynia

Traditional drug design faces significant challenges due to inherent chemical
and biological complexities, often resulting in high failure rates in clinical
trials. Deep learning advancements, particularly generative models, offer
potential solutions to these challenges. One promising algorithm is DrugGPT, a
transformer-based model, that generates small molecules for input protein
sequences. Although promising, it generates both chemically valid and invalid
structures and does not incorporate the features of approved drugs, resulting
in time-consuming and inefficient drug discovery. To address these issues, we
introduce DrugGen, an enhanced model based on the DrugGPT structure. DrugGen is
fine-tuned on approved drug-target interactions and optimized with proximal
policy optimization. By giving reward feedback from protein-ligand binding
affinity prediction using pre-trained transformers (PLAPT) and a customized
invalid structure assessor, DrugGen significantly improves performance.
Evaluation across multiple targets demonstrated that DrugGen achieves 100%
valid structure generation compared to 95.5% with DrugGPT and produced
molecules with higher predicted binding affinities (7.22 [6.30-8.07]) compared
to DrugGPT (5.81 [4.97-6.63]) while maintaining diversity and novelty. Docking
simulations further validate its ability to generate molecules targeting
binding sites effectively. For example, in the case of fatty acid-binding
protein 5 (FABP5), DrugGen generated molecules with superior docking scores
(FABP5/11, -9.537 and FABP5/5, -8.399) compared to the reference molecule
(Palmitic acid, -6.177). Beyond lead compound generation, DrugGen also shows
potential for drug repositioning and creating novel pharmacophores for existing
targets. By producing high-quality small molecules, DrugGen provides a
high-performance medium for advancing pharmaceutical research and drug
discovery.

ÊëòË¶ÅÔºöÂÇ≥Áµ±Ëó•Áâ©Ë®≠Ë®àÂõ†ÂÖ∂ÂåñÂ≠∏ÂíåÁîüÁâ©Ë§áÈõúÊÄßËÄåÈù¢Ëá®ÈáçÂ§ßÊåëÊà∞ÔºåÈÄôÈÄöÂ∏∏ÊúÉÂ∞éËá¥Ëá®Â∫äË©¶È©óÁöÑÈ´òÂ§±ÊïóÁéá„ÄÇÊ∑±Â∫¶Â≠∏ÁøíÁöÑÈÄ≤Â±ïÔºåÁâπÂà•ÊòØÁîüÊàêÊ®°ÂûãÔºåÁÇ∫ÈÄô‰∫õÊåëÊà∞Êèê‰æõ‰∫ÜÊΩõÂú®ÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÊºîÁÆóÊ≥ïÊòØ DrugGPTÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂü∫ÊñºËΩâÊèõÂô®ÁöÑÊ®°ÂûãÔºåÂÆÉÁÇ∫Ëº∏ÂÖ•ËõãÁôΩË≥™Â∫èÂàóÁîüÊàêÂ∞èÂàÜÂ≠ê„ÄÇÂÑòÁÆ°ÊúâÂâçÊôØÔºå‰ΩÜÂÆÉÊó¢Áî¢ÁîüÂåñÂ≠∏ÊúâÊïàÁµêÊßãÔºå‰πüÁî¢ÁîüÁÑ°ÊïàÁµêÊßãÔºå‰∏¶‰∏î‰∏çÂåÖÂê´Â∑≤Ê†∏ÂáÜËó•Áâ©ÁöÑÁâπÂæµÔºåÂ∞éËá¥ËÄóÊôÇ‰∏î‰ΩéÊïàÁöÑËó•Áâ©ÁôºÁèæ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü DrugGenÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂü∫Êñº DrugGPT ÁµêÊßãÁöÑÂ¢ûÂº∑Ê®°Âûã„ÄÇDrugGen Âú®Â∑≤Ê†∏ÂáÜÁöÑËó•Áâ©ÁõÆÊ®ô‰∫§‰∫í‰ΩúÁî®‰∏äÈÄ≤Ë°åÂæÆË™øÔºå‰∏¶‰ΩøÁî®ËøëÁ´ØÁ≠ñÁï•ÊúÄ‰Ω≥ÂåñÈÄ≤Ë°åÊúÄ‰Ω≥Âåñ„ÄÇÈÄöÈÅé‰ΩøÁî®È†êÂÖàË®ìÁ∑¥ÁöÑËΩâÊèõÂô® (PLAPT) ÂíåËá™Ë®ÇÁÑ°ÊïàÁµêÊßãË©ï‰º∞Âô®ÔºåÂæûËõãÁôΩË≥™ÈÖçÈ´îÁµêÂêàË¶™ÂíåÂäõÈ†êÊ∏¨‰∏≠Êèê‰æõÁçéÂãµÂõûÈ•ãÔºåDrugGen Â§ßÂπÖÊèêÂçá‰∫ÜÊïàËÉΩ„ÄÇÂ§öÂÄãÁõÆÊ®ôÁöÑË©ï‰º∞È°ØÁ§∫ÔºåËàá DrugGPT ÁöÑ 95.5% Áõ∏ÊØîÔºåDrugGen ÈÅîÂà∞‰∫Ü 100% ÁöÑÊúâÊïàÁµêÊßãÁîüÊàêÔºå‰∏¶‰∏îÁî¢Áîü‰∫ÜÈ†êÊ∏¨ÁµêÂêàË¶™ÂíåÂäõËºÉÈ´òÁöÑÂàÜÂ≠ê (7.22 [6.30-8.07])ÔºåËÄå DrugGPT ÁÇ∫ (5.81 [4.97-6.63])ÔºåÂêåÊôÇ‰øùÊåÅ‰∫ÜÂ§öÊ®£ÊÄßÂíåÊñ∞Á©éÊÄß„ÄÇÂ∞çÊé•Ê®°Êì¨ÈÄ≤‰∏ÄÊ≠•È©óË≠â‰∫ÜÂÖ∂ÊúâÊïàÁîüÊàêÂàÜÂ≠ê‰ª•ÈáùÂ∞çÁµêÂêà‰ΩçÈªûÁöÑËÉΩÂäõ„ÄÇ‰æãÂ¶ÇÔºåÂú®ËÑÇËÇ™ÈÖ∏ÁµêÂêàËõãÁôΩ 5 (FABP5) ÁöÑÊÉÖÊ≥Å‰∏ãÔºåËàáÂèÉËÄÉÂàÜÂ≠êÔºàÊ£ïÊ´öÈÖ∏Ôºå-6.177ÔºâÁõ∏ÊØîÔºåDrugGen ÁîüÊàê‰∫ÜÂ∞çÊé•Ë©ïÂàÜËºÉÈ´òÁöÑÂàÜÂ≠ê (FABP5/11Ôºå-9.537 Âíå FABP5/5Ôºå-8.399)„ÄÇÈô§‰∫ÜÂÖàÂ∞éÂåñÂêàÁâ©ÁîüÊàê‰πãÂ§ñÔºåDrugGen ÈÇÑÈ°ØÁ§∫‰∫ÜËó•Áâ©ÈáçÊñ∞ÂÆö‰ΩçÂíåÁÇ∫ÁèæÊúâÁõÆÊ®ôÂª∫Á´ãÊñ∞ÂûãËó•ÊïàÂúòÁöÑÊΩõÂäõ„ÄÇÈÄöÈÅéÁî¢ÁîüÈ´òÂìÅË≥™ÁöÑÂ∞èÂàÜÂ≠êÔºåDrugGen ÁÇ∫Êé®ÈÄ≤Ë£ΩËó•Á†îÁ©∂ÂíåËó•Áâ©ÁôºÁèæÊèê‰æõ‰∫Ü‰∏ÄÂÄãÈ´òÊÄßËÉΩÁöÑÂ™í‰ªã„ÄÇ

##### **Deep Learning-Based Classification of Hyperkinetic Movement Disorders in Children**
2411.15200v1 by Nandika Ramamurthy, Dr Daniel Lumsden, Dr Rachel Sparks

Hyperkinetic movement disorders (HMDs) in children, including dystonia
(abnormal twisting) and chorea (irregular, random movements), pose significant
diagnostic challenges due to overlapping clinical features. The prevalence of
dystonia ranges from 2 to 50 per million, and chorea from 5 to 10 per 100,000.
These conditions are often diagnosed with delays averaging 4.75 to 7.83 years.
Traditional diagnostic methods depend on clinical history and expert physical
examinations, but specialized tests are ineffective due to the complex
pathophysiology of these disorders. This study develops a neural network model
to differentiate between dystonia and chorea from video recordings of
paediatric patients performing motor tasks. The model integrates a Graph
Convolutional Network (GCN) to capture spatial relationships and Long
Short-Term Memory (LSTM) networks to account for temporal dynamics. Attention
mechanisms were incorporated to improve model interpretability. The model was
trained and validated on a dataset of 50 videos (31 chorea-predominant, 19
dystonia-predominant) collected under regulatory approval from Guy's and St
Thomas' NHS Foundation Trust. The model achieved 85% accuracy, 81% sensitivity,
and 88% specificity at 15 frames per second. Attention maps highlighted the
model's ability to correctly identify involuntary movement patterns, with
misclassifications often due to occluded body parts or subtle movement
variations. This work demonstrates the potential of deep learning to improve
the accuracy and efficiency of HMD diagnosis and could contribute to more
reliable, interpretable clinical tools.

ÊëòË¶ÅÔºö<paragraph>ÂÖíÁ´•ÁöÑÈÅãÂãïÈÅéÂãïÁóá (HMDs)ÔºåÂåÖÊã¨ËÇåÂºµÂäõ‰∏çÂÖ®ÔºàÁï∞Â∏∏Êâ≠ÂãïÔºâÂíåËàûËπàÁóáÔºà‰∏çË¶èÂâá„ÄÅÈö®Ê©üÁöÑÂãï‰ΩúÔºâÔºåÁî±ÊñºËá®Â∫äÁâπÂæµÈáçÁñäÔºåÂõ†Ê≠§Âú®Ë®∫Êñ∑‰∏äÂÖ∑ÊúâÈáçÂ§ßÊåëÊà∞„ÄÇËÇåÂºµÂäõ‰∏çÂÖ®ÁöÑÁõõË°åÁéáÁÇ∫ÊØèÁôæËê¨‰∫∫ 2 Ëá≥ 50 ‰∫∫ÔºåËàûËπàÁóáÁöÑÁõõË°åÁéáÁÇ∫ÊØè 10 Ëê¨‰∫∫ 5 Ëá≥ 10 ‰∫∫„ÄÇÈÄô‰∫õÁñæÁóÖÈÄöÂ∏∏Âú®Âπ≥Âùá 4.75 Ëá≥ 7.83 Âπ¥ÂæåÊâçË¢´Ë®∫Êñ∑Âá∫‰æÜ„ÄÇÂÇ≥Áµ±ÁöÑË®∫Êñ∑ÊñπÊ≥ï‰æùË≥¥ÊñºÁóÖÂè≤ÂíåÂ∞àÂÆ∂Ë∫´È´îÊ™¢Êü•Ôºå‰ΩÜÁî±ÊñºÈÄô‰∫õÁñæÁóÖÁöÑË§áÈõúÁóÖÁêÜÁîüÁêÜÔºåÂ∞àÈñÄÁöÑÊ™¢Êü•‰∏¶ÁÑ°Êïà„ÄÇÊú¨Á†îÁ©∂ÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÔºåÁî®ÊñºÂçÄÂàÜËàûËπàÁóáÂíåËÇåÂºµÂäõ‰∏çÂÖ®ÔºåÊñπÊ≥ïÊòØÈÄèÈÅéÈåÑË£ΩÂÖíÁ´•ÊÇ£ËÄÖÂü∑Ë°åÈÅãÂãï‰ªªÂãôÁöÑÂΩ±Áâá„ÄÇË©≤Ê®°ÂûãÊï¥Âêà‰∫ÜÂúñÂΩ¢Âç∑Á©çÁ∂≤Ë∑Ø (GCN) ‰ª•Êì∑ÂèñÁ©∫ÈñìÈóú‰øÇÔºå‰ª•ÂèäÈï∑Áü≠ÊúüË®òÊÜ∂ (LSTM) Á∂≤Ë∑Ø‰ª•ËÄÉÈáèÊôÇÈñìÂãïÊÖã„ÄÇÊ≥®ÊÑèÂäõÊ©üÂà∂Ë¢´Á¥çÂÖ•‰ª•ÊîπÂñÑÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄß„ÄÇË©≤Ê®°ÂûãÂú®‰∏ÄÂÄãÁî± 50 ÂÄãÂΩ±ÁâáÁµÑÊàêÁöÑË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åË®ìÁ∑¥ÂíåÈ©óË≠âÔºà31 ÂÄã‰ª•ËàûËπàÁóáÁÇ∫‰∏ªÔºå19 ÂÄã‰ª•ËÇåÂºµÂäõ‰∏çÂÖ®ÁÇ∫‰∏ªÔºâÔºåÈÄô‰∫õÂΩ±ÁâáÊòØÂú®ÂèñÂæó Guy's and St Thomas' NHS Foundation Trust ÁöÑÊ≥ïË¶èÊ†∏ÂáÜÂæåÊî∂ÈõÜÁöÑ„ÄÇË©≤Ê®°ÂûãÂú®ÊØèÁßí 15 ÂπÄÊôÇÈÅîÂà∞ 85% ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÅ81% ÁöÑÈùàÊïèÂ∫¶Âíå 88% ÁöÑÁâπÁï∞ÊÄß„ÄÇÊ≥®ÊÑèÂäõÂúñÁ™ÅÈ°Ø‰∫ÜË©≤Ê®°ÂûãÊ≠£Á¢∫Ë≠òÂà•ÈùûËá™‰∏ªÈÅãÂãïÊ®°ÂºèÁöÑËÉΩÂäõÔºåËÄåË™§ÂàÜÈ°ûÈÄöÂ∏∏ÊòØÂõ†Ë∫´È´îÈÉ®‰ΩçË¢´ÈÅÆÊìãÊàñÁ¥∞ÂæÆÁöÑÈÅãÂãïËÆäÂåñÊâÄËá¥„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúË≠âÊòé‰∫ÜÊ∑±Â∫¶Â≠∏ÁøíÂú®ÊîπÂñÑ HMD Ë®∫Êñ∑ÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÊïàÁéáÊñπÈù¢ÁöÑÊΩõÂäõÔºå‰∏¶ÂèØËÉΩÊúâÂä©ÊñºÈñãÁôºÊõ¥ÂèØÈù†„ÄÅÂèØËß£ÈáãÁöÑËá®Â∫äÂ∑•ÂÖ∑„ÄÇ</paragraph>

##### **Efficient Medicinal Image Transmission and Resolution Enhancement via GAN**
2411.12833v1 by Rishabh Kumar Sharma, Mukund Sharma, Pushkar Sharma, Jeetashree Aparjeeta

While X-ray imaging is indispensable in medical diagnostics, it inherently
carries with it those noises and limitations on resolution that mask the
details necessary for diagnosis. B/W X-ray images require a careful balance
between noise suppression and high-detail preservation to ensure clarity in
soft-tissue structures and bone edges. While traditional methods, such as CNNs
and early super-resolution models like ESRGAN, have enhanced image resolution,
they often perform poorly regarding high-frequency detail preservation and
noise control for B/W imaging. We are going to present one efficient approach
that improves the quality of an image with the optimization of network
transmission in the following paper. The pre-processing of X-ray images into
low-resolution files by Real-ESRGAN, a version of ESRGAN elucidated and
improved, helps reduce the server load and transmission bandwidth.
Lower-resolution images are upscaled at the receiving end using Real-ESRGAN,
fine-tuned for real-world image degradation. The model integrates
Residual-in-Residual Dense Blocks with perceptual and adversarial loss
functions for high-quality upscaled images with low noise. We further fine-tune
Real-ESRGAN by adapting it to the specific B/W noise and contrast
characteristics. This suppresses noise artifacts without compromising detail.
The comparative evaluation conducted shows that our approach achieves superior
noise reduction and detail clarity compared to state-of-the-art CNN-based and
ESRGAN models, apart from reducing network bandwidth requirements. These
benefits are confirmed both by quantitative metrics, including Peak
Signal-to-Noise Ratio and Structural Similarity Index, and by qualitative
assessments, which indicate the potential of Real-ESRGAN for diagnostic-quality
X-ray imaging and for efficient medical data transmission.

ÊëòË¶ÅÔºöÂÑòÁÆ° X ÂÖâÂΩ±ÂÉèÂú®ÈÜ´ÁôÇË®∫Êñ∑‰∏≠‰∏çÂèØÊàñÁº∫Ôºå‰ΩÜÂÆÉÊú¨Ë∫´Â∞±Â∏∂ÊúâÈÇ£‰∫õÊúÉÈÅÆËîΩË®∫Êñ∑ÊâÄÈúÄÁ¥∞ÁØÄÁöÑÈõúË®äÂíåËß£ÊûêÂ∫¶ÈôêÂà∂„ÄÇÈªëÁôΩ X ÂÖâÂΩ±ÂÉèÈúÄË¶ÅÂú®ÈõúË®äÊäëÂà∂ÂíåÈ´òÁ¥∞ÁØÄ‰øùÁïô‰πãÈñìÂèñÂæó‰ªîÁ¥∞ÁöÑÂπ≥Ë°°Ôºå‰ª•Á¢∫‰øùËªüÁµÑÁπîÁµêÊßãÂíåÈ™®È™ºÈÇäÁ∑£ÁöÑÊ∏ÖÊô∞Â∫¶„ÄÇÂÑòÁÆ° CNN Âíå ESRGAN Á≠âÂÇ≥Áµ±ÊñπÊ≥ïÂíåÊó©ÊúüË∂ÖËß£ÊûêÂ∫¶Ê®°ÂûãÂ∑≤Â¢ûÂº∑ÂΩ±ÂÉèËß£ÊûêÂ∫¶Ôºå‰ΩÜÂÆÉÂÄëÂú®È´òÈ†ªÁéáÁ¥∞ÁØÄ‰øùÁïôÂíåÈªëÁôΩÂΩ±ÂÉèÁöÑÈõúË®äÊéßÂà∂ÊñπÈù¢ÈÄöÂ∏∏Ë°®Áèæ‰∏ç‰Ω≥„ÄÇÊàëÂÄëÂ∞áÂú®‰ª•‰∏ãË´ñÊñá‰∏≠ÊèêÂá∫‰∏ÄÁ®ÆÊúâÊïàÁöÑÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÈÄèÈÅéÊúÄ‰Ω≥ÂåñÁ∂≤Ë∑ØÂÇ≥Ëº∏‰æÜÊèêÂçáÂΩ±ÂÉèÂìÅË≥™„ÄÇÂ∞á X ÂÖâÂΩ±ÂÉèÈ†êËôïÁêÜÊàê‰ΩéËß£ÊûêÂ∫¶Ê™îÊ°àÔºåÈÄèÈÅéÁ∂ìÈÅéÈó°ÊòéÂíåÊîπËâØÁöÑ ESRGAN ÁâàÊú¨ Real-ESRGANÔºåÊúâÂä©ÊñºÈôç‰Ωé‰º∫ÊúçÂô®Ë≤†ËºâÂíåÂÇ≥Ëº∏È†ªÂØ¨„ÄÇ‰ΩéËß£ÊûêÂ∫¶ÂΩ±ÂÉèÂú®Êé•Êî∂Á´Ø‰ΩøÁî®ÈáùÂ∞çÁúüÂØ¶‰∏ñÁïåÂΩ±ÂÉèÂä£ÂåñÈÄ≤Ë°åÂæÆË™øÁöÑ Real-ESRGAN ÂçáÁ¥ö„ÄÇË©≤Ê®°ÂûãÊï¥Âêà‰∫ÜÊÆòÂ∑Æ‰∏≠ÊÆòÂ∑ÆÂØÜÈõÜÂçÄÂ°äËàáÊÑüÁü•ÂíåÂ∞çÊäóÊêçÂ§±ÂáΩÊï∏Ôºå‰ª•Áî¢ÁîüÈõúË®ä‰ΩéÁöÑÈ´òÂìÅË≥™ÂçáÁ¥öÂΩ±ÂÉè„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÂæÆË™ø Real-ESRGANÔºå‰ΩøÂÖ∂ÈÅ©ÊáâÁâπÂÆöÈªëÁôΩÈõúË®äÂíåÂ∞çÊØîÁâπÂæµ„ÄÇÈÄôÊäëÂà∂‰∫ÜÈõúË®äÂÅΩÂΩ±ÔºåÂêåÊôÇ‰∏çÂΩ±ÈüøÁ¥∞ÁØÄ„ÄÇÈÄ≤Ë°åÁöÑÊØîËºÉË©ï‰º∞È°ØÁ§∫ÔºåÈô§‰∫ÜÈôç‰ΩéÁ∂≤Ë∑ØÈ†ªÂØ¨ÈúÄÊ±ÇÂ§ñÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®ÈõúË®äÈôç‰ΩéÂíåÁ¥∞ÁØÄÊ∏ÖÊô∞Â∫¶ÊñπÈù¢ÈÉΩÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÂü∫Êñº CNN Âíå ESRGAN ÁöÑÊ®°Âûã„ÄÇÈÄô‰∫õÂÑ™ÈªûÂ∑≤ÈÄèÈÅéÂÆöÈáèÊåáÊ®ôÔºàÂåÖÊã¨Â≥∞ÂÄº‰ø°Âô™ÊØîÂíåÁµêÊßãÁõ∏‰ººÊÄßÊåáÊ®ôÔºâÂíåÂÆöÊÄßË©ï‰º∞ÂæóÂà∞Ë≠âÂØ¶ÔºåÈÄôË°®Êòé Real-ESRGAN ÂÖ∑ÊúâË®∫Êñ∑ÂìÅË≥™ X ÂÖâÂΩ±ÂÉèÂíåÊúâÊïàÈÜ´ÁôÇË≥áÊñôÂÇ≥Ëº∏ÁöÑÊΩõÂäõ„ÄÇ

##### **Conversational Medical AI: Ready for Practice**
2411.12808v1 by Antoine Liz√©e, Pierre-Auguste Beaucot√©, James Whitbeck, Marion Doumeingts, Ana√´l Beaugnon, Isabelle Feldhaus

The shortage of doctors is creating a critical squeeze in access to medical
expertise. While conversational Artificial Intelligence (AI) holds promise in
addressing this problem, its safe deployment in patient-facing roles remains
largely unexplored in real-world medical settings. We present the first
large-scale evaluation of a physician-supervised LLM-based conversational agent
in a real-world medical setting.
  Our agent, Mo, was integrated into an existing medical advice chat service.
Over a three-week period, we conducted a randomized controlled experiment with
926 cases to evaluate patient experience and satisfaction. Among these, Mo
handled 298 complete patient interactions, for which we report
physician-assessed measures of safety and medical accuracy.
  Patients reported higher clarity of information (3.73 vs 3.62 out of 4, p <
0.05) and overall satisfaction (4.58 vs 4.42 out of 5, p < 0.05) with
AI-assisted conversations compared to standard care, while showing equivalent
levels of trust and perceived empathy. The high opt-in rate (81% among
respondents) exceeded previous benchmarks for AI acceptance in healthcare.
Physician oversight ensured safety, with 95% of conversations rated as "good"
or "excellent" by general practitioners experienced in operating a medical
advice chat service.
  Our findings demonstrate that carefully implemented AI medical assistants can
enhance patient experience while maintaining safety standards through physician
supervision. This work provides empirical evidence for the feasibility of AI
deployment in healthcare communication and insights into the requirements for
successful integration into existing healthcare services.

ÊëòË¶ÅÔºö<paragraph>ÈÜ´ÁîüÁü≠Áº∫Ê≠£Âú®ÈÄ†ÊàêÂèñÂæóÈÜ´ÁôÇÂ∞àÊ•≠Áü•Ë≠òÁöÑÂö¥ÈáçÊì†Â£ì„ÄÇÂÑòÁÆ°Â∞çË©±Âºè‰∫∫Â∑•Êô∫ÊÖß (AI) ÊúâÊúõËß£Ê±∫Ê≠§ÂïèÈ°åÔºå‰ΩÜÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑÈÜ´ÁôÇÁí∞Â¢É‰∏≠ÔºåÂÖ∂Âú®Èù¢Â∞çÊÇ£ËÄÖÁöÑËßíËâ≤‰∏≠ÁöÑÂÆâÂÖ®ÈÉ®ÁΩ≤‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Ë®é„ÄÇÊàëÂÄëÊèêÂá∫Âú®ÁèæÂØ¶‰∏ñÁïåÁöÑÈÜ´ÁôÇÁí∞Â¢É‰∏≠ÔºåÂ∞çÂü∫Êñº LLM ÁöÑÈÜ´Â∏´Áõ£Áù£Â∞çË©±‰ª£ÁêÜÈÄ≤Ë°åÈ¶ñÊ¨°Â§ßË¶èÊ®°Ë©ï‰º∞„ÄÇ
ÊàëÂÄëÁöÑ‰ª£ÁêÜ Mo Â∑≤Êï¥ÂêàÂà∞ÁèæÊúâÁöÑÈÜ´ÁôÇË´ÆË©¢ËÅäÂ§©ÊúçÂãô‰∏≠„ÄÇÂú®‰∏âÈÄ±ÁöÑÊôÇÈñìË£°ÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÈö®Ê©üÂ∞çÁÖßÂØ¶È©óÔºåÂåÖÂê´ 926 ÂÄãÊ°à‰æãÔºå‰ª•Ë©ï‰º∞ÊÇ£ËÄÖÈ´îÈ©óÂíåÊªøÊÑèÂ∫¶„ÄÇÂÖ∂‰∏≠ÔºåMo ËôïÁêÜ‰∫Ü 298 Ê¨°ÂÆåÊï¥ÁöÑÊÇ£ËÄÖ‰∫íÂãïÔºåÊàëÂÄëÂ†±Âëä‰∫ÜÈÜ´Â∏´Ë©ï‰º∞ÁöÑÂÆâÂÖ®ÊÄßÂíåÈÜ´ÁôÇÊ∫ñÁ¢∫ÊÄßÊåáÊ®ô„ÄÇ
ËàáÊ®ôÊ∫ñÁÖßË≠∑Áõ∏ÊØîÔºåÊÇ£ËÄÖÂ†±Âëä‰∫ÜÊõ¥È´òÁöÑË≥áË®äÊ∏ÖÊô∞Â∫¶Ôºà4 ÂàÜ‰∏≠ÁöÑ 3.73 Â∞ç 3.62Ôºåp < 0.05ÔºâÂíåÊï¥È´îÊªøÊÑèÂ∫¶Ôºà5 ÂàÜ‰∏≠ÁöÑ 4.58 Â∞ç 4.42Ôºåp < 0.05ÔºâÔºåÂêåÊôÇÈ°ØÁ§∫Âá∫ÂêåÁ≠âÁöÑ‰ø°‰ªªÂ∫¶ÂíåÂêåÁêÜÂøÉ„ÄÇÈ´òÈÅ∏ÊìáÂèÉËàáÁéáÔºàÂèóË®™ËÄÖ‰∏≠ÁÇ∫ 81%ÔºâË∂ÖÈÅé‰∫ÜÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ AI Êé•ÂèóÂ∫¶ÁöÑÂÖàÂâçÂü∫Ê∫ñ„ÄÇÈÜ´Â∏´Áõ£Áù£Á¢∫‰øù‰∫ÜÂÆâÂÖ®ÊÄßÔºå95% ÁöÑÂ∞çË©±Ë¢´Á∂ìÈ©óË±êÂØåÁöÑÈÜ´ÁôÇË´ÆË©¢ËÅäÂ§©ÊúçÂãôÊìç‰ΩúÂì°Ë©ïÁÇ∫„ÄåËâØÂ•Ω„ÄçÊàñ„ÄåÊ•µ‰Ω≥„Äç„ÄÇ
ÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºå‰ªîÁ¥∞ÂØ¶ÊñΩÁöÑ AI ÈÜ´ÁôÇÂä©ÁêÜÂèØ‰ª•Âú®Á∂≠ÊåÅÈÜ´Â∏´Áõ£Áù£‰∏ãÁöÑÂÆâÂÖ®Ê®ôÊ∫ñÁöÑÂêåÊôÇÔºåÊèêÂçáÊÇ£ËÄÖÈ´îÈ©ó„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫ AI ÈÉ®ÁΩ≤Âú®ÈÜ´ÁôÇ‰øùÂÅ•Ê∫ùÈÄö‰∏≠ÁöÑÂèØË°åÊÄßÊèê‰æõ‰∫ÜÂØ¶Ë≠âÔºå‰∏¶Ê∑±ÂÖ•‰∫ÜËß£‰∫ÜÊàêÂäüÊï¥ÂêàÂà∞ÁèæÊúâÈÜ´ÁôÇ‰øùÂÅ•ÊúçÂãô‰∏≠ÁöÑË¶ÅÊ±Ç„ÄÇ</paragraph>

##### **Enhancing Multi-Class Disease Classification: Neoplasms, Cardiovascular, Nervous System, and Digestive Disorders Using Advanced LLMs**
2411.12712v1 by Ahmed Akib Jawad Karim, Muhammad Zawad Mahmud, Samiha Islam, Aznur Azam

In this research, we explored the improvement in terms of multi-class disease
classification via pre-trained language models over Medical-Abstracts-TC-Corpus
that spans five medical conditions. We excluded non-cancer conditions and
examined four specific diseases. We assessed four LLMs, BioBERT, XLNet, and
BERT, as well as a novel base model (Last-BERT). BioBERT, which was pre-trained
on medical data, demonstrated superior performance in medical text
classification (97% accuracy). Surprisingly, XLNet followed closely (96%
accuracy), demonstrating its generalizability across domains even though it was
not pre-trained on medical data. LastBERT, a custom model based on the lighter
version of BERT, also proved competitive with 87.10% accuracy (just under
BERT's 89.33%). Our findings confirm the importance of specialized models such
as BioBERT and also support impressions around more general solutions like
XLNet and well-tuned transformer architectures with fewer parameters (in this
case, LastBERT) in medical domain tasks.

ÊëòË¶ÅÔºöÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÈÄèÈÅéÈ†êÂÖàË®ìÁ∑¥ÁöÑË™ûË®ÄÊ®°ÂûãÂú®Ë∑®Ë∂ä‰∫îÁ®ÆÈÜ´ÁôÇÁñæÁóÖÁöÑ Medical-Abstracts-TC-Corpus ‰∏äÔºåÂ§öÈ°ûÁñæÁóÖÂàÜÈ°ûÁöÑÊîπÈÄ≤„ÄÇÊàëÂÄëÊéíÈô§‰∫ÜÈùûÁôåÁóáÁñæÁóÖÔºå‰∏¶Ê™¢Êü•‰∫ÜÂõõÁ®ÆÁâπÂÆöÁñæÁóÖ„ÄÇÊàëÂÄëË©ï‰º∞‰∫ÜÂõõÂÄã LLMÔºåBioBERT„ÄÅXLNet Âíå BERTÔºå‰ª•Âèä‰∏ÄÂÄãÊñ∞ÁöÑÂü∫Á§éÊ®°Âûã (Last-BERT)„ÄÇÂú®ÈÜ´Â≠∏ÊñáÊú¨ÂàÜÈ°û‰∏≠ÔºåÁ∂ìÈÅéÈÜ´Â≠∏Ë≥áÊñôÈ†êÂÖàË®ìÁ∑¥ÁöÑ BioBERT Ë°®ÁèæÂá∫ÂÑ™Áï∞ÁöÑÊïàËÉΩÔºà97% Ê∫ñÁ¢∫Â∫¶Ôºâ„ÄÇ‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåXLNet Á∑äÈö®ÂÖ∂ÂæåÔºà96% Ê∫ñÁ¢∫Â∫¶ÔºâÔºåÂ±ïÁ§∫‰∫ÜÂÆÉÂú®‰∏çÂêåÈ†òÂüüÁöÑÊ¶ÇÊã¨ËÉΩÂäõÔºåÂç≥‰ΩøÂÆÉ‰∏çÊòØÂú®ÈÜ´Â≠∏Ë≥áÊñô‰∏äÈ†êÂÖàË®ìÁ∑¥ÁöÑ„ÄÇLastBERT ÊòØ‰∏ÄÂÄãÂü∫ÊñºËºÉËºïÁâàÊú¨ÁöÑ BERT ÁöÑËá™Ë®ÇÊ®°ÂûãÔºå‰πüË≠âÊòé‰∫ÜÁ´∂Áà≠ÂäõÔºåÊ∫ñÁ¢∫Â∫¶ÁÇ∫ 87.10%ÔºàÂÉÖ‰ΩéÊñº BERT ÁöÑ 89.33%Ôºâ„ÄÇÊàëÂÄëÁöÑÁôºÁèæË≠âÂØ¶‰∫Ü BioBERT Á≠âÂ∞àÁî®Ê®°ÂûãÁöÑÈáçË¶ÅÊÄßÔºå‰πüÊîØÊåÅ‰∫ÜÂ∞çÊõ¥ÈÄöÁî®ÁöÑËß£Ê±∫ÊñπÊ°àÁöÑÂç∞Ë±°Ôºå‰æãÂ¶Ç XLNet ÂíåÂú®ÈÜ´Â≠∏È†òÂüü‰ªªÂãô‰∏≠ÂÖ∑ÊúâËºÉÂ∞ëÂèÉÊï∏ÁöÑÂæÆË™øTransformerÊû∂ÊßãÔºàÂú®Êú¨‰æã‰∏≠ÁÇ∫ LastBERTÔºâ„ÄÇ

##### **AI Guided Early Screening of Cervical Cancer**
2411.12681v1 by Dharanidharan S I, Suhitha Renuka S V, Ajishi Singh, Sheena Christabel Pravin

In order to support the creation of reliable machine learning models for
anomaly detection, this project focuses on preprocessing, enhancing, and
organizing a medical imaging dataset. There are two classifications in the
dataset: normal and abnormal, along with extra noise fluctuations. In order to
improve the photographs' quality, undesirable artifacts, including visible
medical equipment at the edges, were eliminated using central cropping.
Adjusting the brightness and contrast was one of the additional preprocessing
processes. Normalization was then performed to normalize the data. To make
classification jobs easier, the dataset was methodically handled by combining
several image subsets into two primary categories: normal and pathological. To
provide a strong training set that adapts well to real-world situations,
sophisticated picture preprocessing techniques were used, such as contrast
enhancement and real-time augmentation (including rotations, zooms, and
brightness modifications). To guarantee efficient model evaluation, the data
was subsequently divided into training and testing subsets. In order to create
precise and effective machine learning models for medical anomaly detection,
high-quality input data is ensured via this thorough approach. Because of the
project pipeline's flexible and scalable design, it can be easily integrated
with bigger clinical decision-support systems.

ÊëòË¶ÅÔºö<paragraph>ÁÇ∫‰∫ÜÊîØÊåÅÂª∫Á´ãÁî®ÊñºÁï∞Â∏∏ÂÅµÊ∏¨ÁöÑÂèØÈù†Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÔºåÊ≠§Â∞àÊ°àÂ∞àÊ≥®ÊñºÈ†êËôïÁêÜ„ÄÅÂ¢ûÂº∑ÂíåÁµÑÁπîÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñôÈõÜ„ÄÇË≥áÊñôÈõÜ‰∏≠ÊúâÂÖ©ÂÄãÂàÜÈ°ûÔºöÊ≠£Â∏∏ÂíåÁï∞Â∏∏Ôºå‰ª•ÂèäÈ°çÂ§ñÁöÑÈõúË®äÊ≥¢Âãï„ÄÇÁÇ∫‰∫ÜÊèêÈ´òÁÖßÁâáÁöÑÂìÅË≥™ÔºåÂåÖÊã¨ÈÇäÁ∑£ÂèØË¶ãÁöÑÈÜ´ÁôÇË®≠ÂÇôÂú®ÂÖßÁöÑ‰∏çÂèØÂèñÁöÑ‰∫∫Â∑•Ë£ΩÂìÅÂ∑≤‰ΩøÁî®‰∏≠Â§ÆË£ÅÂàá‰∫à‰ª•Ê∂àÈô§„ÄÇË™øÊï¥‰∫ÆÂ∫¶ÂíåÂ∞çÊØîÂ∫¶ÊòØÈ°çÂ§ñÈ†êËôïÁêÜÁ®ãÂ∫è‰πã‰∏Ä„ÄÇÁÑ∂ÂæåÂü∑Ë°åÊ≠£Ë¶èÂåñ‰ª•Ê≠£Ë¶èÂåñË≥áÊñô„ÄÇÁÇ∫‰∫Ü‰ΩøÂàÜÈ°ûÂ∑•‰ΩúÊõ¥ËºïÈ¨ÜÔºåË≥áÊñôÈõÜÈÄèÈÅéÂ∞áÂ§öÂÄãÂΩ±ÂÉèÂ≠êÈõÜÁµÑÂêàÊàêÂÖ©ÂÄã‰∏ªË¶ÅÈ°ûÂà•ÔºàÊ≠£Â∏∏ÂíåÁóÖÁêÜÔºâ‰æÜÊúâÊ¢ùÁêÜÂú∞ËôïÁêÜ„ÄÇÁÇ∫‰∫ÜÊèê‰æõ‰∏ÄÂÄãËÉΩËâØÂ•ΩÈÅ©ÊáâÁúüÂØ¶‰∏ñÁïåÊÉÖÊ≥ÅÁöÑÂº∑Â§ßË®ìÁ∑¥ÈõÜÔºå‰ΩøÁî®‰∫ÜÂÖàÈÄ≤ÁöÑÂúñÁâáÈ†êËôïÁêÜÊäÄË°ìÔºå‰æãÂ¶ÇÂ∞çÊØîÂ¢ûÂº∑ÂíåÂç≥ÊôÇÊì¥ÂÖÖÔºàÂåÖÊã¨ÊóãËΩâ„ÄÅÁ∏ÆÊîæÂíå‰∫ÆÂ∫¶‰øÆÊîπÔºâ„ÄÇÁÇ∫‰∫Ü‰øùË≠âÊúâÊïàÁöÑÊ®°ÂûãË©ï‰º∞ÔºåË≥áÊñôÈö®ÂæåË¢´ÂàÜÁÇ∫Ë®ìÁ∑¥ÂíåÊ∏¨Ë©¶Â≠êÈõÜ„ÄÇÁÇ∫‰∫ÜÂª∫Á´ãÁî®ÊñºÈÜ´Â≠∏Áï∞Â∏∏ÂÅµÊ∏¨ÁöÑÁ≤æÁ¢∫‰∏îÊúâÊïàÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÔºåÈÄèÈÅéÊ≠§ÂæπÂ∫ïÁöÑÊñπÊ≥ïÁ¢∫‰øù‰∫ÜÈ´òÂìÅË≥™ÁöÑËº∏ÂÖ•Ë≥áÊñô„ÄÇÁî±ÊñºÂ∞àÊ°àÁÆ°Á∑öÁöÑÈùàÊ¥ª‰∏îÂèØÊì¥ÂÖÖÁöÑË®≠Ë®àÔºåÂÆÉÂèØ‰ª•ËºïÈ¨ÜÂú∞Êï¥ÂêàÂà∞Êõ¥Â§ßÁöÑËá®Â∫äÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ±‰∏≠„ÄÇ</paragraph>

##### **Deep Learning-Driven Heat Map Analysis for Evaluating thickness of Wounded Skin Layers**
2411.12678v1 by Devakumar GR, JB Kaarthikeyan, Dominic Immanuel T, Sheena Christabel Pravin

Understanding the appropriate skin layer thickness in wounded sites is an
important tool to move forward on wound healing practices and treatment
protocols. Methods to measure depth often are invasive and less specific. This
paper introduces a novel method that is non-invasive with deep learning
techniques using classifying of skin layers that helps in measurement of wound
depth through heatmap analysis. A set of approximately 200 labeled images of
skin allows five classes to be distinguished: scars, wounds, and healthy skin,
among others. Each image has annotated key layers, namely the stratum cornetum,
the epidermis, and the dermis, in the software Roboflow. In the preliminary
stage, the Heatmap generator VGG16 was used to enhance the visibility of tissue
layers, based upon which their annotated images were used to train ResNet18
with early stopping techniques. It ended up at a very high accuracy rate of
97.67%. To do this, the comparison of the models ResNet18, VGG16, DenseNet121,
and EfficientNet has been done where both EfficientNet and ResNet18 have
attained accuracy rates of almost 95.35%. For further hyperparameter tuning,
EfficientNet and ResNet18 were trained at six different learning rates to
determine the best model configuration. It has been noted that the accuracy has
huge variations with different learning rates. In the case of EfficientNet, the
maximum achievable accuracy was 95.35% at the rate of 0.0001. The same was true
for ResNet18, which also attained its peak value of 95.35% at the same rate.
These facts indicate that the model can be applied and utilized in actual-time,
non-invasive wound assessment, which holds a great promise to improve clinical
diagnosis and treatment planning.

ÊëòË¶ÅÔºö‰∫ÜËß£ÂÇ∑Âè£ÈÉ®‰ΩçÈÅ©Áï∂ÁöÑÁöÆËÜöÂ±§ÂéöÂ∫¶ÔºåÊòØÊé®ÂãïÂÇ∑Âè£ÁôíÂêàÂØ¶ÂãôÂíåÊ≤ªÁôÇÊñπÊ°àÁöÑÈáçË¶ÅÂ∑•ÂÖ∑„ÄÇÊ∏¨ÈáèÊ∑±Â∫¶ÁöÑÊñπÊ≥ïÈÄöÂ∏∏ÂÖ∑Êúâ‰æµÂÖ•ÊÄß‰∏î‰∏çÂ§†ÂÖ∑È´î„ÄÇÊú¨Êñá‰ªãÁ¥π‰∏ÄÁ®ÆÈùû‰æµÂÖ•ÊÄßÁöÑÊñ∞ÊñπÊ≥ïÔºå‰ΩøÁî®Ê∑±Â∫¶Â≠∏ÁøíÊäÄË°ìÂ∞çÁöÆËÜöÂ±§ÈÄ≤Ë°åÂàÜÈ°ûÔºåÊúâÂä©ÊñºÈÄèÈÅéÁÜ±ÂúñÂàÜÊûêÊ∏¨ÈáèÂÇ∑Âè£Ê∑±Â∫¶„ÄÇ‰∏ÄÁµÑÁ¥Ñ 200 ÂºµÊ®ôË®òÁöÑÁöÆËÜöÂΩ±ÂÉèÔºåÂèØÂçÄÂàÜÁÇ∫‰∫îÈ°ûÔºöÁñ§Áóï„ÄÅÂÇ∑Âè£ÂíåÂÅ•Â∫∑ÁöÆËÜöÁ≠â„ÄÇÊØèÂºµÂΩ±ÂÉèÂú® Roboflow ËªüÈ´î‰∏≠ÈÉΩÊ®ôË®ª‰∫ÜÈóúÈçµÂ±§ÔºåÂç≥ËßíË≥™Â±§„ÄÅË°®ÁöÆÂíåÁúüÁöÆ„ÄÇÂú®ÂàùÊ≠•ÈöéÊÆµÔºå‰ΩøÁî®ÁÜ±ÂúñÁî¢ÁîüÂô® VGG16 ‰æÜÂ¢ûÂº∑ÁµÑÁπîÂ±§ÁöÑÂèØË¶ãÂ∫¶ÔºåÊ†πÊìöÂÖ∂Ê®ôË®ªÁöÑÂΩ±ÂÉèÁî®ÊñºË®ìÁ∑¥ ResNet18Ôºå‰∏¶Êé°Áî®Êó©ÊúüÂÅúÊ≠¢ÊäÄË°ì„ÄÇÊúÄÁµÇÈÅîÂà∞ÈùûÂ∏∏È´òÁöÑÊ∫ñÁ¢∫Áéá 97.67%„ÄÇÁÇ∫Ê≠§ÔºåÂ∞ç ResNet18„ÄÅVGG16„ÄÅDenseNet121 Âíå EfficientNet ÈÄ≤Ë°å‰∫ÜÊ®°ÂûãÊØîËºÉÔºåÂÖ∂‰∏≠ EfficientNet Âíå ResNet18 ÈÉΩÈÅîÂà∞‰∫ÜÊé•Ëøë 95.35% ÁöÑÊ∫ñÁ¢∫Áéá„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•Ë™øÊï¥Ë∂ÖÂèÉÊï∏Ôºå‰ª•ÂÖ≠Á®Æ‰∏çÂêåÁöÑÂ≠∏ÁøíÁéáË®ìÁ∑¥ EfficientNet Âíå ResNet18Ôºå‰ª•Á¢∫ÂÆöÊúÄ‰Ω≥Ê®°ÂûãÈÖçÁΩÆ„ÄÇÂ∑≤Ê≥®ÊÑèÂà∞Ê∫ñÁ¢∫ÁéáÊúÉÈö®Ëëó‰∏çÂêåÁöÑÂ≠∏ÁøíÁéáËÄåÊúâÂæàÂ§ßÁöÑËÆäÂåñ„ÄÇÂú® EfficientNet ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂú® 0.0001 ÁöÑÈÄüÁéá‰∏ãÔºåÂèØÈÅîÂà∞ÁöÑÊúÄÂ§ßÊ∫ñÁ¢∫ÁéáÁÇ∫ 95.35%„ÄÇResNet18 ‰πüÊòØÂ¶ÇÊ≠§ÔºåÂú®Áõ∏ÂêåÁöÑÈÄüÁéá‰∏ã‰πüÈÅîÂà∞‰∫Ü 95.35% ÁöÑÂ≥∞ÂÄº„ÄÇÈÄô‰∫õ‰∫ãÂØ¶Ë°®ÊòéÔºåË©≤Ê®°ÂûãÂèØ‰ª•ÊáâÁî®ÊñºÂØ¶ÈöõÊôÇÈñìÁöÑÈùû‰æµÂÖ•ÊÄßÂÇ∑Âè£Ë©ï‰º∞‰∏≠ÔºåÈÄôÂ∞çÊîπÂñÑËá®Â∫äË®∫Êñ∑ÂíåÊ≤ªÁôÇË®àÁï´ÂÖ∑ÊúâÂæàÂ§ßÁöÑÂâçÊôØ„ÄÇ

##### **DiM: $f$-Divergence Minimization Guided Sharpness-Aware Optimization for Semi-supervised Medical Image Segmentation**
2411.12350v1 by Bingli Wang, Houcheng Su, Nan Yin, Mengzhu Wang, Li Shen

As a technique to alleviate the pressure of data annotation, semi-supervised
learning (SSL) has attracted widespread attention. In the specific domain of
medical image segmentation, semi-supervised methods (SSMIS) have become a
research hotspot due to their ability to reduce the need for large amounts of
precisely annotated data. SSMIS focuses on enhancing the model's generalization
performance by leveraging a small number of labeled samples and a large number
of unlabeled samples. The latest sharpness-aware optimization (SAM) technique,
which optimizes the model by reducing the sharpness of the loss function, has
shown significant success in SSMIS. However, SAM and its variants may not fully
account for the distribution differences between different datasets. To address
this issue, we propose a sharpness-aware optimization method based on
$f$-divergence minimization (DiM) for semi-supervised medical image
segmentation. This method enhances the model's stability by fine-tuning the
sensitivity of model parameters and improves the model's adaptability to
different datasets through the introduction of $f$-divergence. By reducing
$f$-divergence, the DiM method not only improves the performance balance
between the source and target datasets but also prevents performance
degradation due to overfitting on the source dataset.

ÊëòË¶ÅÔºö‰ΩúÁÇ∫‰∏ÄÁ®ÆÊ∏õËºïË≥áÊñôÊ®ôË®ªÂ£ìÂäõÁöÑÊäÄË°ìÔºåÂçäÁõ£Áù£ÂºèÂ≠∏Áøí (SSL) Â∑≤Âª£ÂèóÈóúÊ≥®„ÄÇÂú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤ÁöÑÁâπÂÆöÈ†òÂüü‰∏≠ÔºåÂçäÁõ£Áù£ÂºèÊñπÊ≥ï (SSMIS) Áî±ÊñºËÉΩÂ§†Ê∏õÂ∞ëÂ∞çÂ§ßÈáèÁ≤æÁ¢∫Ê®ôË®ªË≥áÊñôÁöÑÈúÄÊ±ÇËÄåÊàêÁÇ∫Á†îÁ©∂ÁÜ±Èªû„ÄÇSSMIS Â∞àÊ≥®ÊñºÈÄèÈÅéÂà©Áî®Â∞ëÊï∏Ê®ôÁ±§Ê®£Êú¨ÂíåÂ§ßÈáèÊú™Ê®ôÁ±§Ê®£Êú¨‰æÜÂ¢ûÂº∑Ê®°ÂûãÁöÑÊ≥õÂåñÊïàËÉΩ„ÄÇÊúÄÊñ∞ÁöÑÈä≥Âà©Â∫¶ÊÑüÁü•ÊúÄ‰Ω≥Âåñ (SAM) ÊäÄË°ìÈÄèÈÅéÈôç‰ΩéÊêçÂ§±ÂáΩÊï∏ÁöÑÈä≥Âà©Â∫¶‰æÜÊúÄ‰Ω≥ÂåñÊ®°ÂûãÔºåÂ∑≤Âú® SSMIS ‰∏≠Â±ïÁèæÈ°ØËëóÁöÑÊàêÂäü„ÄÇÁÑ∂ËÄåÔºåSAM ÂèäÂÖ∂ËÆäÈ´îÂèØËÉΩÁÑ°Ê≥ïÂÆåÂÖ®ËÄÉÈáè‰∏çÂêåË≥áÊñôÈõÜ‰πãÈñìÁöÑÂàÜÂ∏ÉÂ∑ÆÁï∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫Êñº $f$-Êï£Â∫¶ÊúÄÂ∞èÂåñ (DiM) ÁöÑÈä≥Âà©Â∫¶ÊÑüÁü•ÊúÄ‰Ω≥ÂåñÊñπÊ≥ïÔºåÁî®ÊñºÂçäÁõ£Áù£ÂºèÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤„ÄÇÊ≠§ÊñπÊ≥ïÈÄèÈÅéÂæÆË™øÊ®°ÂûãÂèÉÊï∏ÁöÑÊïèÊÑüÂ∫¶‰∏¶ÈÄèÈÅéÂºïÂÖ• $f$-Êï£Â∫¶‰æÜÊîπÂñÑÊ®°ÂûãÂ∞ç‰∏çÂêåË≥áÊñôÈõÜÁöÑÈÅ©ÊáâÊÄßÔºåÈÄ≤ËÄåÂ¢ûÂº∑Ê®°ÂûãÁöÑÁ©©ÂÆöÊÄß„ÄÇÈÄèÈÅéÈôç‰Ωé $f$-Êï£Â∫¶ÔºåDiM ÊñπÊ≥ï‰∏çÂÉÖÊîπÂñÑ‰∫Ü‰æÜÊ∫êË≥áÊñôÈõÜÂíåÁõÆÊ®ôË≥áÊñôÈõÜ‰πãÈñìÁöÑÊïàËÉΩÂπ≥Ë°°ÔºåÈÇÑÈò≤Ê≠¢‰∫ÜÂõ†ÈÅéÂ∫¶Êì¨Âêà‰æÜÊ∫êË≥áÊñôÈõÜËÄåÂ∞éËá¥ÁöÑÊïàËÉΩ‰∏ãÈôç„ÄÇ

##### **Can ChatGPT Overcome Behavioral Biases in the Financial Sector? Classify-and-Rethink: Multi-Step Zero-Shot Reasoning in the Gold Investment**
2411.13599v1 by Shuoling Liu, Gaoguo Jia, Yuhang Jiang, Liyuan Chen, Qiang Yang

Large Language Models (LLMs) have achieved remarkable success recently,
displaying exceptional capabilities in creating understandable and organized
text. These LLMs have been utilized in diverse fields, such as clinical
research, where domain-specific models like Med-Palm have achieved human-level
performance. Recently, researchers have employed advanced prompt engineering to
enhance the general reasoning ability of LLMs. Despite the remarkable success
of zero-shot Chain-of-Thoughts (CoT) in solving general reasoning tasks, the
potential of these methods still remains paid limited attention in the
financial reasoning task.To address this issue, we explore multiple prompt
strategies and incorporated semantic news information to improve LLMs'
performance on financial reasoning tasks.To the best of our knowledge, we are
the first to explore this important issue by applying ChatGPT to the gold
investment.In this work, our aim is to investigate the financial reasoning
capabilities of LLMs and their capacity to generate logical and persuasive
investment opinions. We will use ChatGPT, one of the most powerful LLMs
recently, and prompt engineering to achieve this goal. Our research will focus
on understanding the ability of LLMs in sophisticated analysis and reasoning
within the context of investment decision-making. Our study finds that ChatGPT
with CoT prompt can provide more explainable predictions and overcome
behavioral biases, which is crucial in finance-related tasks and can achieve
higher investment returns.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËøëÊúüÂ∑≤ÂèñÂæóÈ°ØËëóÊàêÂäüÔºåÂú®Âª∫Á´ãÂèØÁêÜËß£‰∏îÊúâÊ¢ùÁêÜÁöÑÊñáÊú¨ÊñπÈù¢Â±ïÁèæÂá∫ÈùûÂá°ÁöÑËÉΩÂäõ„ÄÇÈÄô‰∫õ LLM Â∑≤ÈÅãÁî®Êñº‰∏çÂêåÁöÑÈ†òÂüüÔºå‰æãÂ¶ÇËá®Â∫äÁ†îÁ©∂ÔºåÂÖ∂‰∏≠ÁâπÂÆöÈ†òÂüüÁöÑÊ®°ÂûãÔºà‰æãÂ¶Ç Med-PalmÔºâÂ∑≤ÈÅîÂà∞‰∫∫È°ûÁ≠âÁ¥öÁöÑË°®Áèæ„ÄÇÊúÄËøëÔºåÁ†îÁ©∂‰∫∫Âì°Êé°Áî®ÈÄ≤ÈöéÊèêÁ§∫Â∑•Á®ã‰æÜÊèêÂçá LLM ÁöÑ‰∏ÄËà¨Êé®ÁêÜËÉΩÂäõ„ÄÇÂÑòÁÆ°Èõ∂Ê¨°Â≠∏ÁøíÊÄùËÄÉÈèà (CoT) Âú®Ëß£Ê±∫‰∏ÄËà¨Êé®ÁêÜ‰ªªÂãôÊñπÈù¢ÂèñÂæóÈ°ØËëóÊàêÂäüÔºå‰ΩÜÈÄô‰∫õÊñπÊ≥ïÁöÑÊΩõÂäõÂú®Ë≤°ÂãôÊé®ÁêÜ‰ªªÂãô‰∏≠‰ªçÊú™ÂèóÂà∞Ë∂≥Â§†ÁöÑÈóúÊ≥®„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊé¢Ë®éÂ§öÁ®ÆÊèêÁ§∫Á≠ñÁï•Ôºå‰∏¶Á¥çÂÖ•Ë™ûÁæ©Êñ∞ËÅûË≥áË®ä‰æÜÊèêÂçá LLM Âú®Ë≤°ÂãôÊé®ÁêÜ‰ªªÂãô‰∏äÁöÑË°®Áèæ„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÊàëÂÄëÊòØÁ¨¨‰∏ÄÂÄãÈÄèÈÅéÂ∞á ChatGPT ÊáâÁî®ÊñºÈªÉÈáëÊäïË≥á‰æÜÊé¢Ë®éÈÄôÂÄãÈáçË¶ÅÂïèÈ°åÁöÑ‰∫∫„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÁöÑÁõÆÊ®ôÊòØË™øÊü• LLM ÁöÑË≤°ÂãôÊé®ÁêÜËÉΩÂäõÔºå‰ª•ÂèäÂÆÉÂÄëÁî¢ÁîüÂêà‰πéÈÇèËºØ‰∏îÊúâË™™ÊúçÂäõÁöÑÊäïË≥áÊÑèË¶ãÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÂ∞á‰ΩøÁî® ChatGPTÔºàÊúÄËøëÊúÄÂº∫Â§ßÁöÑ LLM ‰πã‰∏ÄÔºâÂíåÊèêÁ§∫Â∑•Á®ã‰æÜÈÅîÊàêÈÄôÂÄãÁõÆÊ®ô„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Â∞áÂ∞àÊ≥®Êñº‰∫ÜËß£ LLM Âú®ÊäïË≥áÊ±∫Á≠ñÂà∂ÂÆöËÑàÁµ°‰∏≠ÈÄ≤Ë°åË§áÈõúÂàÜÊûêÂíåÊé®ÁêÜÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁôºÁèæÔºåÂÖ∑ÂÇô CoT ÊèêÁ§∫ÁöÑ ChatGPT ÂèØ‰ª•Êèê‰æõÊõ¥ÂÖ∑Ë™™ÊòéÊÄßÁöÑÈ†êÊ∏¨Ôºå‰∏¶ÂÖãÊúçË°åÁÇ∫ÂÅèÂ∑ÆÔºàÈÄôÂú®ËàáË≤°ÂãôÁõ∏ÈóúÁöÑ‰ªªÂãô‰∏≠Ëá≥ÈóúÈáçË¶ÅÔºâÔºå‰∏¶ËÉΩÁç≤ÂæóÊõ¥È´òÁöÑÊäïË≥áÂ†±ÈÖ¨„ÄÇ

##### **StreetviewLLM: Extracting Geographic Information Using a Chain-of-Thought Multimodal Large Language Model**
2411.14476v1 by Zongrong Li, Junhao Xu, Siqin Wang, Yifan Wu, Haiyang Li

Geospatial predictions are crucial for diverse fields such as disaster
management, urban planning, and public health. Traditional machine learning
methods often face limitations when handling unstructured or multi-modal data
like street view imagery. To address these challenges, we propose
StreetViewLLM, a novel framework that integrates a large language model with
the chain-of-thought reasoning and multimodal data sources. By combining street
view imagery with geographic coordinates and textual data, StreetViewLLM
improves the precision and granularity of geospatial predictions. Using
retrieval-augmented generation techniques, our approach enhances geographic
information extraction, enabling a detailed analysis of urban environments. The
model has been applied to seven global cities, including Hong Kong, Tokyo,
Singapore, Los Angeles, New York, London, and Paris, demonstrating superior
performance in predicting urban indicators, including population density,
accessibility to healthcare, normalized difference vegetation index, building
height, and impervious surface. The results show that StreetViewLLM
consistently outperforms baseline models, offering improved predictive accuracy
and deeper insights into the built environment. This research opens new
opportunities for integrating the large language model into urban analytics,
decision-making in urban planning, infrastructure management, and environmental
monitoring.

ÊëòË¶ÅÔºöÂú∞ÁêÜÁ©∫ÈñìÈ†êÊ∏¨Â∞çÊñºÂêÑÂÄãÈ†òÂüüËá≥ÈóúÈáçË¶ÅÔºå‰æãÂ¶ÇÁÅΩÂÆ≥ÁÆ°ÁêÜ„ÄÅÈÉΩÂ∏ÇË¶èÂäÉÂíåÂÖ¨ÂÖ±Ë°õÁîü„ÄÇÂÇ≥Áµ±Ê©üÂô®Â≠∏ÁøíÊñπÊ≥ïÂú®ËôïÁêÜÈùûÁµêÊßãÂåñÊàñÂ§öÊ®°ÊÖãË≥áÊñôÔºà‰æãÂ¶ÇË°óÊôØÂΩ±ÂÉèÔºâÊôÇÔºåÈÄöÂ∏∏ÊúÉÈù¢Ëá®ÈôêÂà∂„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü StreetViewLLMÔºåÈÄôÊòØ‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊû∂ÊßãÔºåÂÆÉÂ∞áÂ§ßÂûãË™ûË®ÄÊ®°ÂûãËàáÊÄùËÄÉÈèàÊé®ÁêÜÂíåÂ§öÊ®°ÊÖãË≥áÊñô‰æÜÊ∫êÊï¥ÂêàÂú®‰∏ÄËµ∑„ÄÇÈÄèÈÅéÁµêÂêàË°óÊôØÂΩ±ÂÉè„ÄÅÂú∞ÁêÜÂ∫ßÊ®ôÂíåÊñáÂ≠óË≥áÊñôÔºåStreetViewLLM ÊèêÂçá‰∫ÜÂú∞ÁêÜÁ©∫ÈñìÈ†êÊ∏¨ÁöÑÁ≤æÊ∫ñÂ∫¶ÂíåË©≥Á¥∞Á®ãÂ∫¶„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ï‰ΩøÁî®‰∫ÜÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÊäÄË°ìÔºåÂ¢ûÂº∑‰∫ÜÂú∞ÁêÜË≥áË®äËêÉÂèñÔºåËÉΩË©≥Á¥∞ÂàÜÊûêÈÉΩÂ∏ÇÁí∞Â¢É„ÄÇÈÄôÂÄãÊ®°ÂûãÂ∑≤Á∂ìÊáâÁî®Êñº‰∏ÉÂÄãÂÖ®ÁêÉÂüéÂ∏ÇÔºåÂåÖÊã¨È¶ôÊ∏Ø„ÄÅÊù±‰∫¨„ÄÅÊñ∞Âä†Âù°„ÄÅÊ¥õÊùâÁ£Ø„ÄÅÁ¥êÁ¥Ñ„ÄÅÂÄ´Êï¶ÂíåÂ∑¥ÈªéÔºåÂú®È†êÊ∏¨ÈÉΩÂ∏ÇÊåáÊ®ôÔºàÂåÖÊã¨‰∫∫Âè£ÂØÜÂ∫¶„ÄÅÈÜ´ÁôÇ‰øùÂÅ•ÂèØÂèäÊÄß„ÄÅÊ≠£Ë¶èÂåñÂ∑ÆÁï∞Ê§çË¢´ÊåáÊï∏„ÄÅÂª∫ÁØâÁâ©È´òÂ∫¶Âíå‰∏çÈÄèÊ∞¥Ë°®Èù¢ÔºâÊñπÈù¢Â±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÊïàËÉΩ„ÄÇÁµêÊûúÈ°ØÁ§∫ StreetViewLLM ÊåÅÁ∫åÂÑ™ÊñºÂü∫Ê∫ñÊ®°ÂûãÔºåÊèê‰æõ‰∫ÜÊõ¥Â•ΩÁöÑÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶Ôºå‰∏¶Â∞çÂ∑≤Âª∫ÊàêÁöÑÁí∞Â¢ÉÊúâÊõ¥Ê∑±ÂÖ•ÁöÑË¶ãËß£„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÁÇ∫Â∞áÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÊï¥ÂêàÂà∞ÈÉΩÂ∏ÇÂàÜÊûê„ÄÅÈÉΩÂ∏ÇË¶èÂäÉÁöÑÊ±∫Á≠ñÂà∂ÂÆö„ÄÅÂü∫Á§éË®≠ÊñΩÁÆ°ÁêÜÂíåÁí∞Â¢ÉÁõ£Êéß‰∏≠ÔºåÈñãÂïü‰∫ÜÊñ∞ÁöÑÂ•ëÊ©ü„ÄÇ

##### **Contrast Similarity-Aware Dual-Pathway Mamba for Multivariate Time Series Node Classification**
2411.12222v1 by Mingsen Du, Meng Chen, Yongjian Li, Xiuxin Zhang, Jiahui Gao, Cun Ji, Shoushui Wei

Multivariate time series (MTS) data is generated through multiple sensors
across various domains such as engineering application, health monitoring, and
the internet of things, characterized by its temporal changes and high
dimensional characteristics. Over the past few years, many studies have
explored the long-range dependencies and similarities in MTS. However,
long-range dependencies are difficult to model due to their temporal changes
and high dimensionality makes it difficult to obtain similarities effectively
and efficiently. Thus, to address these issues, we propose contrast
similarity-aware dual-pathway Mamba for MTS node classification (CS-DPMamba).
Firstly, to obtain the dynamic similarity of each sample, we initially use
temporal contrast learning module to acquire MTS representations. And then we
construct a similarity matrix between MTS representations using Fast Dynamic
Time Warping (FastDTW). Secondly, we apply the DPMamba to consider the
bidirectional nature of MTS, allowing us to better capture long-range and
short-range dependencies within the data. Finally, we utilize the
Kolmogorov-Arnold Network enhanced Graph Isomorphism Network to complete the
information interaction in the matrix and MTS node classification task. By
comprehensively considering the long-range dependencies and dynamic similarity
features, we achieved precise MTS node classification. We conducted experiments
on multiple University of East Anglia (UEA) MTS datasets, which encompass
diverse application scenarios. Our results demonstrate the superiority of our
method through both supervised and semi-supervised experiments on the MTS
classification task.

ÊëòË¶ÅÔºöÂ§öËÆäÈáèÊôÇÈñìÂ∫èÂàó (MTS) Ë≥áÊñôÊòØÈÄèÈÅéÂ§öÂÄãÊÑüÊ∏¨Âô®Âú®ÂêÑÁ®ÆÈ†òÂüü‰∏≠Áî¢ÁîüÁöÑÔºå‰æãÂ¶ÇÂ∑•Á®ãÊáâÁî®„ÄÅÂÅ•Â∫∑Áõ£Ê∏¨ÂíåÁâ©ËÅØÁ∂≤ÔºåÂÖ∂ÁâπÂæµÂú®ÊñºÂÖ∂ÊôÇÈñìËÆäÂåñÂíåÈ´òÁ∂≠Â∫¶ÁâπÂæµ„ÄÇÂú®ÈÅéÂéªÂπæÂπ¥‰∏≠ÔºåË®±Â§öÁ†îÁ©∂Êé¢Á¥¢‰∫Ü MTS ‰∏≠ÁöÑÈï∑Á®ã‰æùË≥¥ÊÄßÂíåÁõ∏‰ººÊÄß„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÊôÇÈñìËÆäÂåñÔºåÈï∑Á®ã‰æùË≥¥ÊÄßÈõ£‰ª•Âª∫Ê®°ÔºåËÄåÈ´òÁ∂≠Â∫¶ÊÄß‰ΩøÂæóÈõ£‰ª•ÊúâÊïà‰∏îÊúâÊïàÂú∞ÂèñÂæóÁõ∏‰ººÊÄß„ÄÇÂõ†Ê≠§ÔºåÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫Â∞çÊØîÁõ∏‰ººÂ∫¶ÊÑüÁü•ÈõôË∑ØÂæë Mamba ÈÄ≤Ë°å MTS ÁØÄÈªûÂàÜÈ°û (CS-DPMamba)„ÄÇÈ¶ñÂÖàÔºåÁÇ∫‰∫ÜÂèñÂæóÊØèÂÄãÊ®£Êú¨ÁöÑÂãïÊÖãÁõ∏‰ººÂ∫¶ÔºåÊàëÂÄëÊúÄÂàù‰ΩøÁî®ÊôÇÈñìÂ∞çÊØîÂ≠∏ÁøíÊ®°ÁµÑ‰æÜÂèñÂæó MTS Ë°®Âæµ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄë‰ΩøÁî®Âø´ÈÄüÂãïÊÖãÊôÇÈñìÊâ≠Êõ≤ (FastDTW) Âú® MTS Ë°®Âæµ‰πãÈñìÂª∫Á´ãÁõ∏‰ººÁü©Èô£„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÊáâÁî® DPMamba ‰æÜËÄÉÈáè MTS ÁöÑÈõôÂêëÊÄßË≥™ÔºåËÆìÊàëÂÄëËÉΩÂ§†Âú®Ë≥áÊñô‰∏≠Êõ¥Â•ΩÂú∞Êì∑ÂèñÈï∑Á®ãÂíåÁü≠Á®ã‰æùË≥¥ÊÄß„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂà©Áî® Kolmogorov-Arnold Á∂≤Ë∑ØÂ¢ûÂº∑ÂúñÂêåÊßãÁ∂≤Ë∑Ø‰æÜÂÆåÊàêÁü©Èô£‰∏≠ÁöÑË≥áË®ä‰∫íÂãïÂíå MTS ÁØÄÈªûÂàÜÈ°û‰ªªÂãô„ÄÇÈÄèÈÅéÂÖ®Èù¢ËÄÉÈáèÈï∑Á®ã‰æùË≥¥ÊÄßÂíåÂãïÊÖãÁõ∏‰ººÊÄßÁâπÂæµÔºåÊàëÂÄëÈÅîÂà∞‰∫ÜÁ≤æÁ¢∫ÁöÑ MTS ÁØÄÈªûÂàÜÈ°û„ÄÇÊàëÂÄëÂú®Â§öÂÄãÊù±Ëã±Ê†ºËò≠Â§ßÂ≠∏ (UEA) MTS Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°å‰∫ÜÂØ¶È©óÔºåÈÄô‰∫õË≥áÊñôÈõÜÊ∂µËìã‰∫Ü‰∏çÂêåÁöÑÊáâÁî®Â†¥ÊôØ„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈÄèÈÅé MTS ÂàÜÈ°û‰ªªÂãô‰∏äÁöÑÁõ£Áù£ÂºèÂíåÂçäÁõ£Áù£ÂºèÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÂÑ™Ë∂äÊÄß„ÄÇ

##### **CCIS-Diff: A Generative Model with Stable Diffusion Prior for Controlled Colonoscopy Image Synthesis**
2411.12198v1 by Yifan Xie, Jingge Wang, Tao Feng, Fei Ma, Yang Li

Colonoscopy is crucial for identifying adenomatous polyps and preventing
colorectal cancer. However, developing robust models for polyp detection is
challenging by the limited size and accessibility of existing colonoscopy
datasets. While previous efforts have attempted to synthesize colonoscopy
images, current methods suffer from instability and insufficient data
diversity. Moreover, these approaches lack precise control over the generation
process, resulting in images that fail to meet clinical quality standards. To
address these challenges, we propose CCIS-DIFF, a Controlled generative model
for high-quality Colonoscopy Image Synthesis based on a Diffusion architecture.
Our method offers precise control over both the spatial attributes (polyp
location and shape) and clinical characteristics of polyps that align with
clinical descriptions. Specifically, we introduce a blur mask weighting
strategy to seamlessly blend synthesized polyps with the colonic mucosa, and a
text-aware attention mechanism to guide the generated images to reflect
clinical characteristics. Notably, to achieve this, we construct a new
multi-modal colonoscopy dataset that integrates images, mask annotations, and
corresponding clinical text descriptions. Experimental results demonstrate that
our method generates high-quality, diverse colonoscopy images with fine control
over both spatial constraints and clinical consistency, offering valuable
support for downstream segmentation and diagnostic tasks.

ÊëòË¶ÅÔºöÁµêËÖ∏Èè°Ê™¢Êü•Â∞çÊñºËÖ∫Áò§ÊÄßÊÅØËÇâÁöÑËæ®Ë≠òËàáÈ†êÈò≤Â§ßËÖ∏Áõ¥ËÖ∏ÁôåËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÁèæÊúâÁµêËÖ∏Èè°Ê™¢Êü•Ë≥áÊñôÈõÜÁöÑË¶èÊ®°ËàáÂèñÂæó‰∏çÊòìÔºåÈñãÁôºÁ©©ÂÅ•ÁöÑÊÅØËÇâÂÅµÊ∏¨Ê®°ÂûãÊ•µÂÖ∑ÊåëÊà∞ÊÄß„ÄÇÈõñÁÑ∂ÂÖàÂâçÁöÑÁ†îÁ©∂Â∑≤ÂòóË©¶ÂêàÊàêÁµêËÖ∏Èè°ÂΩ±ÂÉèÔºå‰ΩÜÁõÆÂâçÁöÑÊñπÊ≥ïÂ≠òÂú®‰∏çÁ©©ÂÆöËàáË≥áÊñôÂ§öÊ®£ÊÄß‰∏çË∂≥ÁöÑÂïèÈ°å„ÄÇÊ≠§Â§ñÔºåÈÄô‰∫õÊñπÊ≥ïÂ∞çÊñºÁîüÊàêÈÅéÁ®ãÁº∫‰πèÁ≤æÁ¢∫ÁöÑÊéßÂà∂ÔºåÂ∞éËá¥ÂΩ±ÂÉèÁÑ°Ê≥ïÈÅîÂà∞Ëá®Â∫äÂìÅË≥™Ê®ôÊ∫ñ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫ CCIS-DIFFÔºå‰∏ÄÁ®ÆÂü∫ÊñºÊì¥Êï£Êû∂ÊßãÁöÑÈ´òÂìÅË≥™ÁµêËÖ∏Èè°ÂΩ±ÂÉèÂêàÊàêÂèóÊéßÁîüÊàêÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÊñπÊ≥ïËÉΩÁ≤æÁ¢∫ÊéßÂà∂ÊÅØËÇâÁöÑÁ©∫ÈñìÂ±¨ÊÄßÔºàÊÅØËÇâ‰ΩçÁΩÆËàáÂΩ¢ÁãÄÔºâËàáËá®Â∫äÁâπÂæµÔºå‰∏¶ËàáËá®Â∫äÊèèËø∞Áõ∏Á¨¶„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂºïÂÖ•Ê®°Á≥äÈÅÆÁΩ©Âä†Ê¨äÁ≠ñÁï•Ôºå‰ª•ÁÑ°Á∏´Âú∞Â∞áÂêàÊàêÁöÑÊÅØËÇâËàáÁµêËÖ∏ÈªèËÜúËûçÂêàÔºå‰∏¶‰ΩøÁî®ÊñáÂ≠óÊÑüÁü•Ê≥®ÊÑèÂäõÊ©üÂà∂‰æÜÂºïÂ∞éÁîüÊàêÁöÑÂΩ±ÂÉèÂèçÊò†Ëá®Â∫äÁâπÂæµ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÁÇ∫‰∫ÜÈÅîÊàêÊ≠§ÁõÆÊ®ôÔºåÊàëÂÄëÂª∫Êßã‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂ§öÊ®°ÂºèÁµêËÖ∏Èè°Ê™¢Êü•Ë≥áÊñôÈõÜÔºåÂÖ∂‰∏≠Êï¥Âêà‰∫ÜÂΩ±ÂÉè„ÄÅÈÅÆÁΩ©Ê®ôË®ªËàáÂ∞çÊáâÁöÑËá®Â∫äÊñáÂ≠óÊèèËø∞„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòéÔºåÊàëÂÄëÁöÑÊñπÊ≥ïËÉΩÁîüÊàêÈ´òÂìÅË≥™„ÄÅÂ§öÊ®£ÂåñÁöÑÁµêËÖ∏Èè°ÂΩ±ÂÉèÔºå‰∏¶ËÉΩÁ≤æÁ¥∞Âú∞ÊéßÂà∂Á©∫ÈñìÁ¥ÑÊùüËàáËá®Â∫ä‰∏ÄËá¥ÊÄßÔºåÁÇ∫‰∏ãÊ∏∏ÂàÜÂâ≤ËàáË®∫Êñ∑‰ªªÂãôÊèê‰æõÊúâÂÉπÂÄºÁöÑÊîØÊè¥„ÄÇ

##### **Leveraging Gene Expression Data and Explainable Machine Learning for Enhanced Early Detection of Type 2 Diabetes**
2411.14471v1 by Aurora Lithe Roy, Md Kamrul Siam, Nuzhat Noor Islam Prova, Sumaiya Jahan, Abdullah Al Maruf

Diabetes, particularly Type 2 diabetes (T2D), poses a substantial global
health burden, compounded by its associated complications such as
cardiovascular diseases, kidney failure, and vision impairment. Early detection
of T2D is critical for improving healthcare outcomes and optimizing resource
allocation. In this study, we address the gap in early T2D detection by
leveraging machine learning (ML) techniques on gene expression data obtained
from T2D patients. Our primary objective was to enhance the accuracy of early
T2D detection through advanced ML methodologies and increase the model's
trustworthiness using the explainable artificial intelligence (XAI) technique.
Analyzing the biological mechanisms underlying T2D through gene expression
datasets represents a novel research frontier, relatively less explored in
previous studies. While numerous investigations have focused on utilizing
clinical and demographic data for T2D prediction, the integration of molecular
insights from gene expression datasets offers a unique and promising avenue for
understanding the pathophysiology of the disease. By employing six ML
classifiers on data sourced from NCBI's Gene Expression Omnibus (GEO), we
observed promising performance across all models. Notably, the XGBoost
classifier exhibited the highest accuracy, achieving 97%. Our study addresses a
notable gap in early T2D detection methodologies, emphasizing the importance of
leveraging gene expression data and advanced ML techniques.

ÊëòË¶ÅÔºöÁ≥ñÂ∞øÁóÖÔºåÂ∞§ÂÖ∂ÊòØ 2 ÂûãÁ≥ñÂ∞øÁóÖ (T2D)ÔºåÂ∞çÂÖ®ÁêÉÂÅ•Â∫∑ÈÄ†ÊàêÈáçÂ§ßË≤†ÊìîÔºåÂÖ∂Áõ∏Èóú‰ΩµÁôºÁóáÔºàÂ¶ÇÂøÉË°ÄÁÆ°ÁñæÁóÖ„ÄÅËÖéË°∞Á´≠ÂíåË¶ñÂäõÂèóÊêçÔºâÊõ¥‰ΩøÊÉÖÊ≥ÅÈõ™‰∏äÂä†Èúú„ÄÇÂèäÊó©ÁôºÁèæ T2D Â∞çÊñºÊîπÂñÑÈÜ´ÁôÇ‰øùÂÅ•ÊàêÊûúÂíåÂÑ™ÂåñË≥áÊ∫êÈÖçÁΩÆËá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéÂ∞çÂæû T2D ÊÇ£ËÄÖÂèñÂæóÁöÑÂü∫Âõ†Ë°®ÁèæÊï∏ÊìöÊáâÁî®Ê©üÂô®Â≠∏Áøí (ML) ÊäÄË°ìÔºå‰æÜËß£Ê±∫ T2D Êó©ÊúüÊ™¢Ê∏¨ÁöÑÂ∑ÆË∑ù„ÄÇÊàëÂÄëÁöÑÈ¶ñË¶ÅÁõÆÊ®ôÊòØÈÄèÈÅéÈÄ≤Èöé ML ÊñπÊ≥ïÊèêÂçá T2D Êó©ÊúüÊ™¢Ê∏¨ÁöÑÊ∫ñÁ¢∫Â∫¶Ôºå‰∏¶‰ΩøÁî®ÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊäÄË°ì‰æÜÊèêÂçáÊ®°ÂûãÁöÑÂèØ‰ø°Â∫¶„ÄÇÈÄèÈÅéÂü∫Âõ†Ë°®ÁèæÊï∏ÊìöÈõÜÂàÜÊûê T2D ËÉåÂæåÁöÑÁîüÁâ©Ê©üÂà∂Ôºå‰ª£Ë°®‰∫Ü‰∏ÄÈ†ÖÊñ∞ÁöÑÁ†îÁ©∂È†òÂüüÔºåÂú®ÈÅéÂéªÁöÑÁ†îÁ©∂‰∏≠ËºÉÂ∞ëË¢´Êé¢Ë®é„ÄÇÈõñÁÑ∂Ë®±Â§öÁ†îÁ©∂Â∞àÊ≥®ÊñºÂà©Áî®Ëá®Â∫äÂíå‰∫∫Âè£Êï∏Êìö‰æÜÈ†êÊ∏¨ T2DÔºå‰ΩÜÊï¥Âêà‰æÜËá™Âü∫Âõ†Ë°®ÁèæÊï∏ÊìöÈõÜÁöÑÂàÜÂ≠êË¶ãËß£ÔºåÁÇ∫‰∫ÜËß£ÁñæÁóÖÁöÑÁóÖÁêÜÁîüÁêÜÂ≠∏Êèê‰æõ‰∫ÜÁç®Áâπ‰∏îÊúâÂ∏åÊúõÁöÑÈÄîÂæë„ÄÇÊàëÂÄëÂ∞ç‰æÜËá™ NCBI Âü∫Âõ†Ë°®ÁèæÁ∏ΩÁ∑ö (GEO) ÁöÑÊï∏ÊìöÊé°Áî®ÂÖ≠Á®Æ ML ÂàÜÈ°ûÂô®ÔºåËßÄÂØüÂà∞ÊâÄÊúâÊ®°ÂûãÈÉΩÊúâ‰ª§‰∫∫ÊªøÊÑèÁöÑË°®Áèæ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåXGBoost ÂàÜÈ°ûÂô®Ë°®ÁèæÂá∫ÊúÄÈ´òÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÈÅîÂà∞ 97%„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ëß£Ê±∫‰∫Ü T2D Êó©ÊúüÊ™¢Ê∏¨ÊñπÊ≥ï‰∏≠‰∏ÄÂÄãÈ°ØËëóÁöÑÂ∑ÆË∑ùÔºåÂº∑Ë™ø‰∫ÜÂà©Áî®Âü∫Âõ†Ë°®ÁèæÊï∏ÊìöÂíåÈÄ≤Èöé ML ÊäÄË°ìÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **Medical Video Generation for Disease Progression Simulation**
2411.11943v1 by Xu Cao, Kaizhao Liang, Kuei-Da Liao, Tianren Gao, Wenqian Ye, Jintai Chen, Zhiguang Ding, Jianguo Cao, James M. Rehg, Jimeng Sun

Modeling disease progression is crucial for improving the quality and
efficacy of clinical diagnosis and prognosis, but it is often hindered by a
lack of longitudinal medical image monitoring for individual patients. To
address this challenge, we propose the first Medical Video Generation (MVG)
framework that enables controlled manipulation of disease-related image and
video features, allowing precise, realistic, and personalized simulations of
disease progression. Our approach begins by leveraging large language models
(LLMs) to recaption prompt for disease trajectory. Next, a controllable
multi-round diffusion model simulates the disease progression state for each
patient, creating realistic intermediate disease state sequence. Finally, a
diffusion-based video transition generation model interpolates disease
progression between these states. We validate our framework across three
medical imaging domains: chest X-ray, fundus photography, and skin image. Our
results demonstrate that MVG significantly outperforms baseline models in
generating coherent and clinically plausible disease trajectories. Two user
studies by veteran physicians, provide further validation and insights into the
clinical utility of the generated sequences. MVG has the potential to assist
healthcare providers in modeling disease trajectories, interpolating missing
medical image data, and enhancing medical education through realistic, dynamic
visualizations of disease progression.

ÊëòË¶ÅÔºöÁñæÁóÖÈÄ≤Á®ãÂª∫Ê®°Â∞çÊñºÊèêÂçáËá®Â∫äË®∫Êñ∑ÂíåÈ†êÂæåÁöÑÂìÅË≥™ÂíåÊïàËÉΩËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÈÄöÂ∏∏ÊúÉÂèóÂà∞Áº∫‰πèÈáùÂ∞çÂÄãÂà•ÊÇ£ËÄÖÁöÑÁ∏±ÂêëÈÜ´Â≠∏ÂΩ±ÂÉèÁõ£Ê∏¨ÁöÑÈòªÁ§ô„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÊ≠§ÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫Á¨¨‰∏ÄÂÄãÈÜ´Â≠∏ÂΩ±ÁâáÁîüÊàê (MVG) Êû∂ÊßãÔºåÂÆÉËÉΩÊéßÂà∂Êìç‰ΩúËàáÁñæÁóÖÁõ∏ÈóúÁöÑÂΩ±ÂÉèÂíåÂΩ±ÁâáÁâπÂæµÔºåÂÖÅË®±Á≤æÁ¢∫„ÄÅÈÄºÁúü‰∏îÂÆ¢Ë£ΩÂåñÁöÑÁñæÁóÖÈÄ≤Á®ãÊ®°Êì¨„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÈ¶ñÂÖàÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÈáçÊñ∞Ê®ôË®òÁñæÁóÖËªåË∑°ÁöÑÊèêÁ§∫„ÄÇÊé•‰∏ã‰æÜÔºåÂèØÊéßÂà∂ÁöÑÂ§öËº™Êì¥Êï£Ê®°ÂûãÊúÉÊ®°Êì¨ÊØèÂÄãÊÇ£ËÄÖÁöÑÁñæÁóÖÈÄ≤Á®ãÁãÄÊÖãÔºåÂª∫Á´ãÈÄºÁúüÁöÑ‰∏≠ÈñìÁñæÁóÖÁãÄÊÖãÂ∫èÂàó„ÄÇÊúÄÂæåÔºåÂü∫ÊñºÊì¥Êï£ÁöÑÂΩ±ÁâáËΩâÊèõÁîüÊàêÊ®°ÂûãÊúÉÂÖßÊèíÈÄô‰∫õÁãÄÊÖã‰πãÈñìÁöÑÁñæÁóÖÈÄ≤Á®ã„ÄÇÊàëÂÄëÂú®‰∏âÂÄãÈÜ´Â≠∏ÂΩ±ÂÉèÈ†òÂüüÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÊû∂ÊßãÔºöËÉ∏ÈÉ® X ÂÖâ„ÄÅÁúºÂ∫ïÊîùÂΩ±ÂíåÁöÆËÜöÂΩ±ÂÉè„ÄÇÊàëÂÄëÁöÑÁµêÊûúË≠âÊòéÔºåMVG Âú®ÁîüÊàêÈÄ£Ë≤´‰∏îËá®Â∫ä‰∏äÂêàÁêÜÁöÑÁñæÁóÖËªåË∑°ÊñπÈù¢È°ØËëóÂÑ™ÊñºÂü∫Ê∫ñÊ®°Âûã„ÄÇÂÖ©È†ÖÁî±Ë≥áÊ∑±ÈÜ´Â∏´ÈÄ≤Ë°åÁöÑ‰ΩøÁî®ËÄÖÁ†îÁ©∂ÈÄ≤‰∏ÄÊ≠•È©óË≠â‰∏¶Ê∑±ÂÖ•Êé¢Ë®é‰∫ÜÁîüÊàêÂ∫èÂàóÁöÑËá®Â∫äÊïàÁî®„ÄÇMVG ÊúâÊΩõÂäõÂçîÂä©ÈÜ´ÁôÇ‰øùÂÅ•Êèê‰æõËÄÖÂª∫Ê®°ÁñæÁóÖËªåË∑°„ÄÅÂÖßÊèíÈÅ∫Â§±ÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñôÔºå‰∏¶ÈÄèÈÅéÈÄºÁúü„ÄÅÂãïÊÖãÁöÑÁñæÁóÖÈÄ≤Á®ãË¶ñË¶∫Âåñ‰æÜÂä†Âº∑ÈÜ´Â≠∏ÊïôËÇ≤„ÄÇ

##### **Edge-Enhanced Dilated Residual Attention Network for Multimodal Medical Image Fusion**
2411.11799v1 by Meng Zhou, Yuxuan Zhang, Xiaolan Xu, Jiayi Wang, Farzad Khalvati

Multimodal medical image fusion is a crucial task that combines complementary
information from different imaging modalities into a unified representation,
thereby enhancing diagnostic accuracy and treatment planning. While deep
learning methods, particularly Convolutional Neural Networks (CNNs) and
Transformers, have significantly advanced fusion performance, some of the
existing CNN-based methods fall short in capturing fine-grained multiscale and
edge features, leading to suboptimal feature integration. Transformer-based
models, on the other hand, are computationally intensive in both the training
and fusion stages, making them impractical for real-time clinical use.
Moreover, the clinical application of fused images remains unexplored. In this
paper, we propose a novel CNN-based architecture that addresses these
limitations by introducing a Dilated Residual Attention Network Module for
effective multiscale feature extraction, coupled with a gradient operator to
enhance edge detail learning. To ensure fast and efficient fusion, we present a
parameter-free fusion strategy based on the weighted nuclear norm of softmax,
which requires no additional computations during training or inference.
Extensive experiments, including a downstream brain tumor classification task,
demonstrate that our approach outperforms various baseline methods in terms of
visual quality, texture preservation, and fusion speed, making it a possible
practical solution for real-world clinical applications. The code will be
released at https://github.com/simonZhou86/en_dran.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÄÅÂåªÂ≠¶ÂõæÂÉèËûçÂêàÊòØ‰∏ÄÈ°πËá≥ÂÖ≥ÈáçË¶ÅÁöÑ‰ªªÂä°ÔºåÂÆÉÂ∞ÜÊù•Ëá™‰∏çÂêåÊàêÂÉèÊñπÂºèÁöÑ‰∫íË°•‰ø°ÊÅØËûçÂêàÂà∞‰∏Ä‰∏™Áªü‰∏ÄÁöÑË°®Á§∫‰∏≠Ôºå‰ªéËÄåÊèêÈ´òËØäÊñ≠ÂáÜÁ°ÆÊÄßÂíåÊ≤ªÁñóËÆ°Âàí„ÄÇËôΩÁÑ∂Ê∑±Â∫¶Â≠¶‰π†ÊñπÊ≥ïÔºåÂ∞§ÂÖ∂ÊòØÂç∑ÁßØÁ•ûÁªèÁΩëÁªú (CNN) Âíå TransformerÔºåÂ∑≤ÁªèÊòæËëóÊèêÂçá‰∫ÜËûçÂêàÊÄßËÉΩÔºå‰ΩÜ‰∏Ä‰∫õÁé∞ÊúâÁöÑÂü∫‰∫é CNN ÁöÑÊñπÊ≥ïÂú®ÊçïÊçâÁªÜÁ≤íÂ∫¶Â§öÂ∞∫Â∫¶ÂíåËæπÁºòÁâπÂæÅÊñπÈù¢Â≠òÂú®‰∏çË∂≥ÔºåÂØºËá¥Ê¨°‰ºòÁâπÂæÅÈõÜÊàê„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÂü∫‰∫é Transformer ÁöÑÊ®°ÂûãÂú®ËÆ≠ÁªÉÂíåËûçÂêàÈò∂ÊÆµËÆ°ÁÆóÈáèÂæàÂ§ßÔºåËøô‰ΩøÂæóÂÆÉ‰ª¨‰∏çÈÄÇÁî®‰∫éÂÆûÊó∂‰∏¥Â∫ä‰ΩøÁî®„ÄÇÊ≠§Â§ñÔºåËûçÂêàÂõæÂÉèÁöÑ‰∏¥Â∫äÂ∫îÁî®‰ªçÊú™ÂæóÂà∞Êé¢Á¥¢„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂü∫‰∫é CNN ÁöÑÊû∂ÊûÑÔºåÈÄöËøáÂºïÂÖ•ËÜ®ËÉÄÊÆãÂ∑ÆÊ≥®ÊÑèÂäõÁΩëÁªúÊ®°ÂùóÊù•Ëß£ÂÜ≥Ëøô‰∫õÈôêÂà∂Ôºå‰ª•ËøõË°åÊúâÊïàÁöÑÂ§öÂàÜËæ®ÁéáÁâπÂæÅÊèêÂèñÔºåÂπ∂ÁªìÂêàÊ¢ØÂ∫¶ÁÆóÂ≠êÊù•Â¢ûÂº∫ËæπÁºòÁªÜËäÇÂ≠¶‰π†„ÄÇ‰∏∫‰∫ÜÁ°Æ‰øùÂø´ÈÄüËÄåÈ´òÊïàÁöÑËûçÂêàÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫é softmax ÁöÑÂä†ÊùÉÊ†∏ËåÉÊï∞ÁöÑÂèÇÊï∞ÂåñËûçÂêàÁ≠ñÁï•ÔºåÂÆÉÂú®ËÆ≠ÁªÉÊàñÊé®ÁêÜËøáÁ®ã‰∏≠‰∏çÈúÄË¶ÅÈ¢ùÂ§ñÁöÑËÆ°ÁÆó„ÄÇÂπøÊ≥õÁöÑÂÆûÈ™åÔºåÂåÖÊã¨‰∏ãÊ∏∏ËÑëËÇøÁò§ÂàÜÁ±ª‰ªªÂä°ÔºåË°®ÊòéÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®ËßÜËßâË¥®Èáè„ÄÅÁ∫πÁêÜ‰øùÁïôÂíåËûçÂêàÈÄüÂ∫¶ÊñπÈù¢‰ºò‰∫éÂêÑÁßçÂü∫ÂáÜÊñπÊ≥ïÔºå‰ΩøÂÖ∂Êàê‰∏∫Áé∞ÂÆû‰∏ñÁïå‰∏¥Â∫äÂ∫îÁî®ÁöÑÂèØËÉΩÂÆûÁî®Ëß£ÂÜ≥ÊñπÊ°à„ÄÇ‰ª£Á†ÅÂ∞ÜÂú® https://github.com/simonZhou86/en_dran ÂèëÂ∏É„ÄÇ

##### **Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**
2411.11774v1 by Jeffrey N. Clark, Matthew Wragg, Emily Nielsen, Miquel Perello-Nieto, Nawid Keshtmand, Michael Ambler, Shiv Sharma, Christopher P. Bourdeaux, Amberly Brigden, Raul Santos-Rodriguez

There is a growing need to understand how digital systems can support
clinical decision-making, particularly as artificial intelligence (AI) models
become increasingly complex and less human-interpretable. This complexity
raises concerns about trustworthiness, impacting safe and effective adoption of
such technologies. Improved understanding of decision-making processes and
requirements for explanations coming from decision support tools is a vital
component in providing effective explainable solutions. This is particularly
relevant in the data-intensive, fast-paced environments of intensive care units
(ICUs). To explore these issues, group interviews were conducted with seven ICU
clinicians, representing various roles and experience levels. Thematic analysis
revealed three core themes: (T1) ICU decision-making relies on a wide range of
factors, (T2) the complexity of patient state is challenging for shared
decision-making, and (T3) requirements and capabilities of AI decision support
systems. We include design recommendations from clinical input, providing
insights to inform future AI systems for intensive care.

ÊëòË¶ÅÔºöÈö®Ëëó‰∫∫Â∑•Êô∫ÊÖß (AI) Ê®°ÂûãËÆäÂæóË∂ä‰æÜË∂äË§áÈõúÔºå‰∏îË∂ä‰æÜË∂äÈõ£‰ª•Ë¢´‰∫∫ÁêÜËß£Ôºå‰∫ÜËß£Êï∏‰ΩçÁ≥ªÁµ±Â¶Ç‰ΩïÊîØÊè¥Ëá®Â∫äÊ±∫Á≠ñÁöÑÈúÄÊ±Ç‰πüÊó•ÁõäÂ¢ûÂä†„ÄÇÈÄôÁ®ÆË§áÈõúÊÄßÂºïÁôº‰∫ÜÂ∞çÂèØ‰ø°Â∫¶ÁöÑÁñëÊÖÆÔºåÂΩ±Èüø‰∫ÜÊ≠§È°ûÊäÄË°ìÁöÑÂÆâÂÖ®‰∏îÊúâÊïàÊé°Áî®„ÄÇÊîπÂñÑÂ∞çÊ±∫Á≠ñÂà∂ÂÆöÊµÅÁ®ãÁöÑÁêÜËß£Ôºå‰ª•ÂèäÂ∞çÊ±∫Á≠ñÊîØÊè¥Â∑•ÂÖ∑ÊâÄÊèê‰æõË™™ÊòéÁöÑË¶ÅÊ±ÇÔºåÊòØÊèê‰æõÊúâÊïàÂèØËß£ÈáãËß£Ê±∫ÊñπÊ°àÁöÑÈáçË¶ÅÁµÑÊàêÈÉ®ÂàÜ„ÄÇÈÄôÂú®Ë≥áÊñôÂØÜÈõÜ„ÄÅÂø´ÁØÄÂ•èÁöÑÂä†Ë≠∑ÁóÖÊàø (ICU) Áí∞Â¢É‰∏≠ÁâπÂà•Áõ∏Èóú„ÄÇÁÇ∫‰∫ÜÊé¢Ë®éÈÄô‰∫õÂïèÈ°åÔºåÂ∞ç‰∏É‰Ωç ICU Ëá®Â∫äÈÜ´Â∏´ÈÄ≤Ë°å‰∫ÜÂ∞èÁµÑË®™Ë´áÔºåÈÄô‰∫õÈÜ´Â∏´‰ª£Ë°®‰∫Ü‰∏çÂêåÁöÑËßíËâ≤ÂíåÁ∂ìÈ©óÂ±§Á¥ö„ÄÇ‰∏ªÈ°åÂàÜÊûêÊè≠Èú≤‰∫Ü‰∏âÂÄãÊ†∏ÂøÉ‰∏ªÈ°åÔºö(T1) ICU Ê±∫Á≠ñÂà∂ÂÆö‰æùË≥¥ÊñºÂª£Ê≥õÁöÑÂõ†Á¥†Ôºå(T2) ÁóÖÊÇ£ÁãÄÊÖãÁöÑË§áÈõúÊÄßÂ∞çÂÖ±ÂêåÊ±∫Á≠ñÂà∂ÂÆöÊßãÊàêÊåëÊà∞Ôºå‰ª•Âèä (T3) AI Ê±∫Á≠ñÊîØÊè¥Á≥ªÁµ±ÁöÑË¶ÅÊ±ÇÂíåËÉΩÂäõ„ÄÇÊàëÂÄëÁ¥çÂÖ•‰∫ÜËá®Â∫äËº∏ÂÖ•ÁöÑË®≠Ë®àÂª∫Ë≠∞ÔºåÊèê‰æõË¶ãËß£‰ª•Êèê‰æõË≥áË®äÁµ¶Êú™‰æÜÁî®ÊñºÂä†Ë≠∑ÁöÑ AI Á≥ªÁµ±„ÄÇ

##### **SP${ }^3$ : Superpixel-propagated pseudo-label learning for weakly semi-supervised medical image segmentation**
2411.11636v1 by Shiman Li, Jiayue Zhao, Shaolei Liu, Xiaokun Dai, Chenxi Zhang, Zhijian Song

Deep learning-based medical image segmentation helps assist diagnosis and
accelerate the treatment process while the model training usually requires
large-scale dense annotation datasets. Weakly semi-supervised medical image
segmentation is an essential application because it only requires a small
amount of scribbles and a large number of unlabeled data to train the model,
which greatly reduces the clinician's effort to fully annotate images. To
handle the inadequate supervisory information challenge in weakly
semi-supervised segmentation (WSSS), a SuperPixel-Propagated Pseudo-label
(SP${}^3$) learning method is proposed, using the structural information
contained in superpixel for supplemental information. Specifically, the
annotation of scribbles is propagated to superpixels and thus obtains a dense
annotation for supervised training. Since the quality of pseudo-labels is
limited by the low-quality annotation, the beneficial superpixels selected by
dynamic thresholding are used to refine pseudo-labels. Furthermore, aiming to
alleviate the negative impact of noise in pseudo-label, superpixel-level
uncertainty is incorporated to guide the pseudo-label supervision for stable
learning. Our method achieves state-of-the-art performance on both tumor and
organ segmentation datasets under the WSSS setting, using only 3\% of the
annotation workload compared to fully supervised methods and attaining
approximately 80\% Dice score. Additionally, our method outperforms eight
weakly and semi-supervised methods under both weakly supervised and
semi-supervised settings. Results of extensive experiments validate the
effectiveness and annotation efficiency of our weakly semi-supervised
segmentation, which can assist clinicians in achieving automated segmentation
for organs or tumors quickly and ultimately benefit patients.

ÊëòË¶ÅÔºö<paragraph>Âü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤ÊúâÂä©ÊñºË®∫Êñ∑‰∏¶Âä†ÈÄüÊ≤ªÁôÇÈÅéÁ®ãÔºåËÄåÊ®°ÂûãË®ìÁ∑¥ÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßË¶èÊ®°ÂØÜÈõÜÊ®ôË®ªÁöÑË≥áÊñôÈõÜ„ÄÇÂº±ÂçäÁõ£Áù£ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤ÊòØ‰∏ÄÈ†ÖÈáçË¶ÅÁöÑÊáâÁî®ÔºåÂõ†ÁÇ∫ÂÆÉÂè™ÈúÄË¶ÅÂ∞ëÈáèÁöÑÂ°óÈ¥âÂíåÂ§ßÈáèÁöÑÊú™Ê®ôË®ªË≥áÊñô‰æÜË®ìÁ∑¥Ê®°ÂûãÔºåÈÄôÂ§ßÂ§ßÊ∏õÂ∞ë‰∫ÜËá®Â∫äÈÜ´ÁîüÂÆåÂÖ®Ê®ôË®ªÂΩ±ÂÉèÁöÑÂ∑•‰ΩúÈáè„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÂº±ÂçäÁõ£Áù£ÂàÜÂâ≤ (WSSS) ‰∏≠Áõ£Áù£Ë≥áË®ä‰∏çË∂≥ÁöÑÊåëÊà∞ÔºåÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆË∂ÖÂÉèÁ¥†ÂÇ≥Êí≠ÂÅΩÊ®ôÁ±§ (SP${}^3$) Â≠∏ÁøíÊñπÊ≥ïÔºåÂà©Áî®Ë∂ÖÂÉèÁ¥†‰∏≠ÂåÖÂê´ÁöÑÁµêÊßãË≥áË®ä‰ΩúÁÇ∫Ë£úÂÖÖË≥áË®ä„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÂ∞áÂ°óÈ¥âÁöÑÊ®ôË®ªÂÇ≥Êí≠Âà∞Ë∂ÖÂÉèÁ¥†ÔºåÂæûËÄåÁç≤ÂæóÁî®ÊñºÁõ£Áù£Ë®ìÁ∑¥ÁöÑÂØÜÈõÜÊ®ôË®ª„ÄÇÁî±ÊñºÂÅΩÊ®ôÁ±§ÁöÑÂìÅË≥™ÂèóÂà∞‰ΩéÂìÅË≥™Ê®ôË®ªÁöÑÈôêÂà∂ÔºåÂõ†Ê≠§‰ΩøÁî®ÂãïÊÖãÈñæÂÄºÈÅ∏ÂèñÁöÑÊúâÂà©Ë∂ÖÂÉèÁ¥†‰æÜÁ≤æÁ∑ªÂÅΩÊ®ôÁ±§„ÄÇÊ≠§Â§ñÔºåÁÇ∫‰∫ÜÊ∏õËºïÂÅΩÊ®ôÁ±§‰∏≠ÈõúË®äÁöÑË≤†Èù¢ÂΩ±ÈüøÔºåÂ∞áË∂ÖÂÉèÁ¥†Â±§Á¥öÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÁ¥çÂÖ•ÂÖ∂‰∏≠Ôºå‰ª•ÊåáÂ∞éÂÅΩÊ®ôÁ±§Áõ£Áù£‰ª•ÈÄ≤Ë°åÁ©©ÂÆöÁöÑÂ≠∏Áøí„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú® WSSS Ë®≠ÂÆö‰∏ãÔºåÂú®ËÖ´Áò§ÂíåÂô®ÂÆòÂàÜÂâ≤Ë≥áÊñôÈõÜ‰∏äÈÉΩÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåËàáÂÆåÂÖ®Áõ£Áù£ÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåÂè™‰ΩøÁî®‰∫Ü 3% ÁöÑÊ®ôË®ªÂ∑•‰ΩúÈáèÔºå‰∏¶ÈÅîÂà∞‰∫ÜÁ¥Ñ 80% ÁöÑ Dice ÂàÜÊï∏„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú®Âº±Áõ£Áù£ÂíåÂçäÁõ£Áù£Ë®≠ÂÆö‰∏ãÈÉΩÂÑ™ÊñºÂÖ´Á®ÆÂº±Áõ£Áù£ÂíåÂçäÁõ£Áù£ÊñπÊ≥ï„ÄÇÂª£Ê≥õÂØ¶È©óÁöÑÁµêÊûúÈ©óË≠â‰∫ÜÊàëÂÄëÂº±ÂçäÁõ£Áù£ÂàÜÂâ≤ÁöÑÊúâÊïàÊÄßÂíåÊ®ôË®ªÊïàÁéáÔºåÈÄôÂèØ‰ª•ÂçîÂä©Ëá®Â∫äÈÜ´ÁîüÂø´ÈÄüÂØ¶ÁèæÂô®ÂÆòÊàñËÖ´Áò§ÁöÑËá™ÂãïÂàÜÂâ≤Ôºå‰∏¶ÊúÄÁµÇ‰ΩøÊÇ£ËÄÖÂèóÁõä„ÄÇ</paragraph>

##### **HistoEncoder: a digital pathology foundation model for prostate cancer**
2411.11458v2 by Joona Pohjonen, Abderrahim-Oussama Batouche, Antti Rannikko, Kevin Sandeman, Andrew Erickson, Esa Pitkanen, Tuomas Mirtti

Foundation models are trained on massive amounts of data to distinguish
complex patterns and can be adapted to a wide range of downstream tasks with
minimal computational resources. Here, we develop a foundation model for
prostate cancer digital pathology called HistoEncoder by pre-training on 48
million prostate tissue tile images. We demonstrate that HistoEncoder features
extracted from tile images with similar histological patterns map closely
together in the feature space. HistoEncoder outperforms models pre-trained with
natural images, even without fine-tuning or with 1000 times less training data.
We describe two use cases that leverage the capabilities of HistoEncoder by
fine-tuning the model with a limited amount of data and computational
resources. First, we show how HistoEncoder can be used to automatically
annotate large-scale datasets with high accuracy. Second, we combine histomics
with commonly used clinical nomograms, significantly improving prostate
cancer-specific death survival models. Foundation models such as HistoEncoder
can allow organizations with limited resources to build effective clinical
software tools without needing extensive datasets or significant amounts of
computing.

ÊëòË¶ÅÔºöÂü∫Á§éÊ®°ÂûãÊúÉÂú®Â§ßÈáèË≥áÊñô‰∏äË®ìÁ∑¥Ôºå‰ª•ÂçÄÂàÜË§áÈõúÊ®°ÂºèÔºå‰∏¶ËÉΩ‰ª•ÊúÄÂ∞ëÁöÑÈÅãÁÆóË≥áÊ∫êÈÅ©ÊáâÂêÑÁ®Æ‰∏ãÊ∏∏‰ªªÂãô„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ HistoEncoder ÁöÑÊîùË≠∑ËÖ∫ÁôåÊï∏‰ΩçÁóÖÁêÜÂü∫Á§éÊ®°ÂûãÔºåÊñπÊ≥ïÊòØÂú® 4800 Ëê¨ÂÄãÊîùË≠∑ËÖ∫ÁµÑÁπîÂàáÁâáÂΩ±ÂÉè‰∏äÈÄ≤Ë°åÈ†êË®ìÁ∑¥„ÄÇÊàëÂÄëÁ§∫ÁØÑ‰∫ÜÂæûÂÖ∑ÊúâÈ°û‰ººÁµÑÁπîÂ≠∏Ê®°ÂºèÁöÑÂàáÁâáÂΩ±ÂÉè‰∏≠ËêÉÂèñÁöÑ HistoEncoder ÁâπÂæµÔºåÊúÉÂú®ÁâπÂæµÁ©∫Èñì‰∏≠Á∑äÂØÜÂú∞Áõ∏‰∫íÂ∞çÊáâ„ÄÇÂç≥‰ΩøÊ≤íÊúâÂæÆË™øÊàñË®ìÁ∑¥Ë≥áÊñôÂ∞ë 1000 ÂÄçÔºåHistoEncoder ÁöÑË°®Áèæ‰πüÂÑ™Êñº‰ΩøÁî®Ëá™ÁÑ∂ÂΩ±ÂÉèÈÄ≤Ë°åÈ†êË®ìÁ∑¥ÁöÑÊ®°Âûã„ÄÇÊàëÂÄëÊèèËø∞‰∫ÜÂÖ©ÂÄã‰ΩøÁî®Ê°à‰æãÔºåÂÆÉÂÄëÂà©Áî® HistoEncoder ÁöÑÂäüËÉΩÔºå‰ª•ÊúâÈôêÁöÑË≥áÊñôÂíåÈÅãÁÆóË≥áÊ∫êÂæÆË™øÊ®°Âûã„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂ¶Ç‰Ωï‰ΩøÁî® HistoEncoder Ëá™ÂãïÁÇ∫Â§ßÂûãË≥áÊñôÈõÜÂä†‰∏äË®ªËß£Ôºå‰∏¶ÈÅîÂà∞ÂæàÈ´òÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÂ∞áÁµÑÁπîÂ≠∏ËàáÂ∏∏Áî®ÁöÑËá®Â∫äÂàóÁ∑öÂúñÁµêÂêàÔºåÂ§ßÂπÖÊîπÂñÑ‰∫ÜÊîùË≠∑ËÖ∫ÁôåÁâπÂÆöÊ≠ª‰∫°Â≠òÊ¥ªÊ®°Âûã„ÄÇÂÉè HistoEncoder ÈÄôÊ®£ÁöÑÂü∫Á§éÊ®°ÂûãÔºåËÉΩËÆìË≥áÊ∫êÊúâÈôêÁöÑÁµÑÁπîÂª∫Á´ãÊúâÊïàÁöÑËá®Â∫äËªüÈ´îÂ∑•ÂÖ∑ÔºåËÄå‰∏çÈúÄË¶ÅÂª£Ê≥õÁöÑË≥áÊñôÈõÜÊàñÂ§ßÈáèÁöÑÈÅãÁÆó„ÄÇ

##### **TP-UNet: Temporal Prompt Guided UNet for Medical Image Segmentation**
2411.11305v2 by Ranmin Wang, Limin Zhuang, Hongkun Chen, Boyan Xu, Ruichu Cai

The advancement of medical image segmentation techniques has been propelled
by the adoption of deep learning techniques, particularly UNet-based
approaches, which exploit semantic information to improve the accuracy of
segmentations. However, the order of organs in scanned images has been
disregarded by current medical image segmentation approaches based on UNet.
Furthermore, the inherent network structure of UNet does not provide direct
capabilities for integrating temporal information. To efficiently integrate
temporal information, we propose TP-UNet that utilizes temporal prompts,
encompassing organ-construction relationships, to guide the segmentation UNet
model. Specifically, our framework is featured with cross-attention and
semantic alignment based on unsupervised contrastive learning to combine
temporal prompts and image features effectively. Extensive evaluations on two
medical image segmentation datasets demonstrate the state-of-the-art
performance of TP-UNet. Our implementation will be open-sourced after
acceptance.

ÊëòË¶ÅÔºöÈÜ´ÁôÇÂΩ±ÂÉèÂàÜÂâ≤ÊäÄË°ìÁöÑÈÄ≤Ê≠•Â∑≤ÂèóÂà∞Ê∑±Â∫¶Â≠∏ÁøíÊäÄË°ìÁöÑÊé°Áî®ÊâÄÊé®ÂãïÔºåÁâπÂà•ÊòØÂü∫Êñº UNet ÁöÑÊñπÊ≥ïÔºåÂÆÉÂà©Áî®Ë™ûÁæ©Ë≥áË®ä‰æÜÊèêÈ´òÂàÜÂâ≤ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÁÑ∂ËÄåÔºåÁï∂ÂâçÂü∫Êñº UNet ÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤ÊñπÊ≥ïÂøΩÁï•‰∫ÜÊéÉÊèèÂΩ±ÂÉè‰∏≠Âô®ÂÆòÁöÑÈ†ÜÂ∫è„ÄÇÊ≠§Â§ñÔºåUNet ÁöÑÂõ∫ÊúâÁ∂≤Ë∑ØÁµêÊßãÁÑ°Ê≥ïÁõ¥Êé•Êï¥ÂêàÊôÇÈñìË≥áË®ä„ÄÇÁÇ∫‰∫ÜÊúâÊïàÊï¥ÂêàÊôÇÈñìË≥áË®äÔºåÊàëÂÄëÊèêÂá∫‰∫Ü TP-UNetÔºåÂÆÉÂà©Áî®ÊôÇÈñìÊèêÁ§∫ÔºåÂåÖÂê´Âô®ÂÆòÂª∫ÊßãÈóú‰øÇÔºå‰æÜÂºïÂ∞éÂàÜÂâ≤ UNet Ê®°Âûã„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÁöÑÊ°ÜÊû∂‰ª•ÁÑ°Áõ£Áù£Â∞çÊØîÂ≠∏ÁøíÁÇ∫Âü∫Á§éÔºåÂÖ∑Êúâ‰∫§ÂèâÊ≥®ÊÑèÂíåË™ûÁæ©Â∞çÈΩäÔºå‰ª•ÊúâÊïàÁµêÂêàÊôÇÈñìÊèêÁ§∫ÂíåÂΩ±ÂÉèÁâπÂæµ„ÄÇÂú®ÂÖ©ÂÄãÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤Ë≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õË©ï‰º∞Ë≠âÊòé‰∫Ü TP-UNet ÁöÑÊúÄÂÖàÈÄ≤ÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÂØ¶‰ΩúÂ∞áÂú®Êé•ÂèóÂæåÈñãÊ∫ê„ÄÇ

##### **Deep learning waterways for rural infrastructure development**
2411.13590v1 by Matthew Pierson, Zia Mehrabi

Surprisingly a number of Earth's waterways remain unmapped, with a
significant number in low and middle income countries. Here we build a computer
vision model (WaterNet) to learn the location of waterways in the United
States, based on high resolution satellite imagery and digital elevation
models, and then deploy this in novel environments in the African continent.
Our outputs provide detail of waterways structures hereto unmapped. When
assessed against community needs requests for rural bridge building related to
access to schools, health care facilities and agricultural markets, we find
these newly generated waterways capture on average 93% (country range: 88-96%)
of these requests whereas Open Street Map, and the state of the art data from
TDX-Hydro, capture only 36% (5-72%) and 62% (37%-85%), respectively. Because
these new machine learning enabled maps are built on public and operational
data acquisition this approach offers promise for capturing humanitarian needs
and planning for social development in places where cartographic efforts have
so far failed to deliver. The improved performance in identifying community
needs missed by existing data suggests significant value for rural
infrastructure development and better targeting of development interventions.

ÊëòË¶ÅÔºö‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÂú∞ÁêÉ‰∏äÁöÑË®±Â§öÊ∞¥ÈÅì‰ªçÁÑ∂Êú™Áπ™Ë£ΩÔºåÂÖ∂‰∏≠ÊúâÂ§ßÈáè‰ΩéÊî∂ÂÖ•Âíå‰∏≠Á≠âÊî∂ÂÖ•ÂúãÂÆ∂„ÄÇÂú®ÈÄôË£°ÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÈõªËÖ¶Ë¶ñË¶∫Ê®°ÂûãÔºàWaterNetÔºâ‰æÜÂ≠∏ÁøíÁæéÂúãÊ∞¥ÈÅìÁöÑÊâÄÂú®‰ΩçÁΩÆÔºåË©≤Ê®°ÂûãÂü∫ÊñºÈ´òËß£ÊûêÂ∫¶Ë°õÊòüÂΩ±ÂÉèÂíåÊï∏‰ΩçÈ´òÁ®ãÊ®°ÂûãÔºåÁÑ∂ÂæåÂ∞áÂÖ∂ÈÉ®ÁΩ≤Âà∞ÈùûÊ¥≤Â§ßÈô∏ÁöÑÊñ∞Áí∞Â¢É‰∏≠„ÄÇÊàëÂÄëÁöÑËº∏Âá∫Êèê‰æõ‰∫ÜËøÑ‰ªäÊú™Áπ™Ë£ΩÁöÑÊ∞¥ÈÅìÁµêÊßãÁöÑË©≥Á¥∞Ë≥áË®ä„ÄÇÂú®Ê†πÊìöÁ§æÂçÄÈúÄÊ±ÇË©ï‰º∞ËàáÂ≠∏Ê†°„ÄÅÈÜ´ÁôÇ‰øùÂÅ•Ë®≠ÊñΩÂíåËæ≤Ê•≠Â∏ÇÂ†¥ÁöÑÈÄöË∑ØÁõ∏ÈóúÁöÑËæ≤ÊùëÊ©ãÊ®ëÂª∫Ë®≠Ë´ãÊ±ÇÊôÇÔºåÊàëÂÄëÁôºÁèæÈÄô‰∫õÊñ∞ÁîüÊàêÁöÑËà™ÈÅìÂπ≥ÂùáÊ∂µËìã‰∫ÜÈÄô‰∫õË´ãÊ±ÇÁöÑ 93%ÔºàÂúãÂÆ∂ÁØÑÂúçÔºö88-96%ÔºâÔºåËÄå Open Street Map Âíå TDX-Hydro ‰∏≠ÊúÄÂÖàÈÄ≤ÁöÑË≥áÊñôÂàÜÂà•Âè™Ê∂µËìã‰∫Ü 36%Ôºà5-72%ÔºâÂíå 62%Ôºà37%-85%Ôºâ„ÄÇÂõ†ÁÇ∫ÈÄô‰∫õÊñ∞ÁöÑÊ©üÂô®Â≠∏ÁøíÂïüÁî®Âú∞ÂúñÂª∫Á´ãÂú®ÂÖ¨ÈñãÂíåÈÅã‰ΩúÁöÑË≥áÊñôÊé°ÈõÜ‰∏≠ÔºåÊâÄ‰ª•ÈÄôÁ®ÆÊñπÊ≥ïÊúâÊúõÊçïÊçâ‰∫∫ÈÅì‰∏ªÁæ©ÈúÄÊ±ÇÔºå‰∏¶ÁÇ∫Ë£ΩÂúñÂ∑•‰ΩúËøÑ‰ªäÊú™ËÉΩÊèê‰æõÁöÑÂú∞ÂçÄÁöÑÁ§æÊúÉÁôºÂ±ïÈÄ≤Ë°åË¶èÂäÉ„ÄÇÂú®Ë≠òÂà•ÁèæÊúâË≥áÊñôÈÅ∫ÊºèÁöÑÁ§æÂçÄÈúÄÊ±ÇÊñπÈù¢Ë°®ÁèæÁöÑÊîπÂñÑÔºåÈ°ØÁ§∫Âá∫Â∞çËæ≤ÊùëÂü∫Á§éË®≠ÊñΩÈñãÁôºÂíåÊõ¥‰Ω≥ÁöÑÁôºÂ±ïÂπ≤È†êÁõÆÊ®ôÂÖ∑ÊúâÈáçÂ§ßÂÉπÂÄº„ÄÇ

##### **Zero-Shot Automatic Annotation and Instance Segmentation using LLM-Generated Datasets: Eliminating Field Imaging and Manual Annotation for Deep Learning Model Development**
2411.11285v1 by Ranjan Sapkota, Achyut Paudel, Manoj Karkee

Currently, deep learning-based instance segmentation for various applications
(e.g., Agriculture) is predominantly performed using a labor-intensive process
involving extensive field data collection using sophisticated sensors, followed
by careful manual annotation of images, presenting significant logistical and
financial challenges to researchers and organizations. The process also slows
down the model development and training process. In this study, we presented a
novel method for deep learning-based instance segmentation of apples in
commercial orchards that eliminates the need for labor-intensive field data
collection and manual annotation. Utilizing a Large Language Model (LLM), we
synthetically generated orchard images and automatically annotated them using
the Segment Anything Model (SAM) integrated with a YOLO11 base model. This
method significantly reduces reliance on physical sensors and manual data
processing, presenting a major advancement in "Agricultural AI". The synthetic,
auto-annotated dataset was used to train the YOLO11 model for Apple instance
segmentation, which was then validated on real orchard images. The results
showed that the automatically generated annotations achieved a Dice Coefficient
of 0.9513 and an IoU of 0.9303, validating the accuracy and overlap of the mask
annotations. All YOLO11 configurations, trained solely on these synthetic
datasets with automated annotations, accurately recognized and delineated
apples, highlighting the method's efficacy. Specifically, the YOLO11m-seg
configuration achieved a mask precision of 0.902 and a mask mAP@50 of 0.833 on
test images collected from a commercial orchard. Additionally, the YOLO11l-seg
configuration outperformed other models in validation on 40 LLM-generated
images, achieving the highest mask precision and mAP@50 metrics.
  Keywords: YOLO, SAM, SAMv2, YOLO11, YOLOv11, Segment Anything, YOLO-SAM

ÊëòË¶ÅÔºö<paragraph>ÁõÆÂâçÔºåÈáùÂ∞çÂêÑÁ®ÆÊáâÁî®Ôºà‰æãÂ¶ÇËæ≤Ê•≠ÔºâÁöÑÊ∑±Â∫¶Â≠∏ÁøíÂØ¶‰æãÂàÜÂâ≤Ôºå‰∏ªË¶ÅÈÄèÈÅéÂãûÂäõÂØÜÈõÜÁöÑÁ®ãÂ∫èÂü∑Ë°åÔºåÂåÖÊã¨‰ΩøÁî®Á≤æÂØÜÊÑüÊ∏¨Âô®Âª£Ê≥õÊî∂ÈõÜÁèæÂ†¥Ë≥áÊñôÔºåÊé•Ëëó‰ªîÁ¥∞ÊâãÂãïÊ®ôË®ªÂΩ±ÂÉèÔºåÂ∞çÁ†îÁ©∂‰∫∫Âì°ÂíåÁµÑÁπîËÄåË®ÄÔºåÈÄôÊúÉÈÄ†ÊàêÈ°ØËëóÁöÑÂæåÂã§ÂíåË≤°ÂãôÊåëÊà∞„ÄÇÊ≠§Á®ãÂ∫è‰πüÊúÉÊ∏õÁ∑©Ê®°ÂûãÈñãÁôºÂíåË®ìÁ∑¥ÁöÑÈÅéÁ®ã„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ïÔºåÂèØÈáùÂ∞çÂïÜÊ•≠ÊûúÂúí‰∏≠ÁöÑËòãÊûúÂü∑Ë°åÊ∑±Â∫¶Â≠∏ÁøíÂØ¶‰æãÂàÜÂâ≤ÔºåÁÑ°ÈúÄÂãûÂäõÂØÜÈõÜÁöÑÁèæÂ†¥Ë≥áÊñôÊî∂ÈõÜÂíåÊâãÂãïÊ®ôË®ª„ÄÇÊàëÂÄëÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂêàÊàêÁî¢ÁîüÊûúÂúíÂΩ±ÂÉèÔºå‰∏¶‰ΩøÁî®Ëàá YOLO11 Âü∫Á§éÊ®°ÂûãÊï¥ÂêàÁöÑ Segment Anything Model (SAM) Ëá™ÂãïÊ®ôË®ªÈÄô‰∫õÂΩ±ÂÉè„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂ§ßÂπÖÈôç‰ΩéÂ∞çÂØ¶È´îÊÑüÊ∏¨Âô®ÂíåÊâãÂãïË≥áÊñôËôïÁêÜÁöÑ‰æùË≥¥ÊÄßÔºå‰ª£Ë°®„ÄåËæ≤Ê•≠ AI„ÄçÁöÑ‰∏ÄÂ§ßÈÄ≤Ê≠•„ÄÇÂêàÊàêËá™ÂãïÊ®ôË®ªÁöÑË≥áÊñôÈõÜÁî®ÊñºË®ìÁ∑¥ YOLO11 Ê®°ÂûãÔºå‰ª•ÈÄ≤Ë°åËòãÊûúÂØ¶‰æãÂàÜÂâ≤ÔºåÊé•ËëóÂú®ÁúüÂØ¶ÊûúÂúíÂΩ±ÂÉè‰∏≠È©óË≠â„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåËá™ÂãïÁî¢ÁîüÁöÑÊ®ôË®ªÈÅîÂà∞‰∫Ü 0.9513 ÁöÑ Dice ‰øÇÊï∏Âíå 0.9303 ÁöÑ IoUÔºåÈ©óË≠â‰∫ÜÈÅÆÁΩ©Ê®ôË®ªÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÈáçÁñäÊÄß„ÄÇÊâÄÊúâ YOLO11 ÁµÑÊÖãÂÉÖ‰ΩøÁî®ÈÄô‰∫õÂÖ∑ÊúâËá™ÂãïÂåñÊ®ôË®ªÁöÑÂêàÊàêË≥áÊñôÈõÜÈÄ≤Ë°åË®ìÁ∑¥ÔºåÂ∞±ËÉΩÊ∫ñÁ¢∫Ëæ®Ë≠òÂíåÊèèÁπ™ËòãÊûúÔºåÁ™ÅÈ°Ø‰∫ÜÊ≠§ÊñπÊ≥ïÁöÑÊïàËÉΩ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåYOLO11m-seg ÁµÑÊÖãÂú®ÂæûÂïÜÊ•≠ÊûúÂúíÊî∂ÈõÜÁöÑÊ∏¨Ë©¶ÂΩ±ÂÉè‰∏äÈÅîÂà∞‰∫Ü 0.902 ÁöÑÈÅÆÁΩ©Ê∫ñÁ¢∫Â∫¶Âíå 0.833 ÁöÑÈÅÆÁΩ© mAP@50„ÄÇÊ≠§Â§ñÔºåYOLO11l-seg ÁµÑÊÖãÂú®ÈáùÂ∞ç 40 Âºµ LLM ÁîüÊàêÁöÑÂΩ±ÂÉèÈÄ≤Ë°åÈ©óË≠âÊôÇÔºåÂÑ™ÊñºÂÖ∂‰ªñÊ®°ÂûãÔºåÈÅîÂà∞‰∫ÜÊúÄÈ´òÁöÑÈÅÆÁΩ©Ê∫ñÁ¢∫Â∫¶Âíå mAP@50 ÊåáÊ®ô„ÄÇ
ÈóúÈçµÂ≠óÔºöYOLO„ÄÅSAM„ÄÅSAMv2„ÄÅYOLO11„ÄÅYOLOv11„ÄÅSegment Anything„ÄÅYOLO-SAM</paragraph>

##### **Continuous K-space Recovery Network with Image Guidance for Fast MRI Reconstruction**
2411.11282v1 by Yucong Meng, Zhiwei Yang, Minghong Duan, Yonghong Shi, Zhijian Song

Magnetic resonance imaging (MRI) is a crucial tool for clinical diagnosis
while facing the challenge of long scanning time. To reduce the acquisition
time, fast MRI reconstruction aims to restore high-quality images from the
undersampled k-space. Existing methods typically train deep learning models to
map the undersampled data to artifact-free MRI images. However, these studies
often overlook the unique properties of k-space and directly apply general
networks designed for image processing to k-space recovery, leaving the precise
learning of k-space largely underexplored. In this work, we propose a
continuous k-space recovery network from a new perspective of implicit neural
representation with image domain guidance, which boosts the performance of MRI
reconstruction. Specifically, (1) an implicit neural representation based
encoder-decoder structure is customized to continuously query unsampled
k-values. (2) an image guidance module is designed to mine the semantic
information from the low-quality MRI images to further guide the k-space
recovery. (3) a multi-stage training strategy is proposed to recover dense
k-space progressively. Extensive experiments conducted on CC359, fastMRI, and
IXI datasets demonstrate the effectiveness of our method and its superiority
over other competitors.

ÊëòË¶ÅÔºöÁ£ÅÂÖ±ÊåØÊàêÂÉè (MRI) Â∞çÊñºËá®Â∫äË®∫Êñ∑Ëá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÂçªÈù¢Ëá®ÊéÉÊèèÊôÇÈñìÈï∑ÁöÑÂïèÈ°å„ÄÇÁÇ∫‰∫ÜÁ∏ÆÁü≠Êì∑ÂèñÊôÇÈñìÔºåÂø´ÈÄü MRI ÈáçÂª∫Êó®Âú®ÂæûÊ¨†Êé°Ê®£ k Á©∫ÈñìÊÅ¢Âæ©È´òÂìÅË≥™ÂΩ±ÂÉè„ÄÇÁèæÊúâÊñπÊ≥ïÈÄöÂ∏∏Ë®ìÁ∑¥Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºåÂ∞áÊ¨†Êé°Ê®£Ë≥áÊñôÂ∞çÊáâÂà∞Ê≤íÊúâÂÅΩÂΩ±ÁöÑ MRI ÂΩ±ÂÉè„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÁ†îÁ©∂Â∏∏Â∏∏ÂøΩÁï• k Á©∫ÈñìÁöÑÁç®ÁâπÂ±¨ÊÄßÔºå‰∏¶Áõ¥Êé•Â•óÁî®Ë®≠Ë®àÁî®ÊñºÂΩ±ÂÉèËôïÁêÜÁöÑ‰∏ÄËà¨Á∂≤Ë∑ØÂà∞ k Á©∫ÈñìÈáçÂª∫ÔºåÂ∞éËá¥ k Á©∫ÈñìÁöÑÁ≤æÁ¢∫Â≠∏ÁøíÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰ªçÊú™Ë¢´Êé¢Á¥¢„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂæûÈö±ÂºèÁ•ûÁ∂ìË°®ÂæµËàáÂΩ±ÂÉèÁ∂≤ÂüüÂºïÂ∞éÁöÑÊñ∞ËßÄÈªûÊèêÂá∫‰∏ÄÂÄãÈÄ£Á∫åÁöÑ k Á©∫ÈñìÈáçÂª∫Á∂≤Ë∑ØÔºåÊèêÂçá MRI ÈáçÂª∫ÁöÑÊïàËÉΩ„ÄÇÂÖ∑È´î‰æÜË™™Ôºå(1) Ê†πÊìöÈö±ÂºèÁ•ûÁ∂ìË°®ÂæµË®≠Ë®àÁ∑®Á¢ºÂô®-Ëß£Á¢ºÂô®ÁµêÊßãÔºåÁî®ÊñºÈÄ£Á∫åÊü•Ë©¢Êú™Êé°Ê®£ÁöÑ k ÂÄº„ÄÇ(2) Ë®≠Ë®à‰∏ÄÂÄãÂΩ±ÂÉèÂºïÂ∞éÊ®°ÁµÑÔºåÂæû‰ΩéÂìÅË≥™ÁöÑ MRI ÂΩ±ÂÉè‰∏≠ÊåñÊéòË™ûÁæ©Ë≥áË®äÔºåÈÄ≤‰∏ÄÊ≠•ÂºïÂ∞é k Á©∫ÈñìÈáçÂª∫„ÄÇ(3) ÊèêÂá∫‰∏ÄÂÄãÂ§öÈöéÊÆµË®ìÁ∑¥Á≠ñÁï•ÔºåÁî®ÊñºÈÄêÊ≠•ÈáçÂª∫ÂØÜÈõÜÁöÑ k Á©∫Èñì„ÄÇÂú® CC359„ÄÅfastMRI Âíå IXI Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂ§ßÈáèÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºå‰ª•ÂèäÂÖ∂ÂÑ™ÊñºÂÖ∂‰ªñÁ´∂Áà≠Â∞çÊâãÁöÑÂÑ™Ë∂äÊÄß„ÄÇ

##### **F$^3$OCUS -- Federated Finetuning of Vision-Language Foundation Models with Optimal Client Layer Updating Strategy via Multi-objective Meta-Heuristics**
2411.11912v1 by Pramit Saha, Felix Wagner, Divyanshu Mishra, Can Peng, Anshul Thakur, David Clifton, Konstantinos Kamnitsas, J. Alison Noble

Effective training of large Vision-Language Models (VLMs) on
resource-constrained client devices in Federated Learning (FL) requires the
usage of parameter-efficient fine-tuning (PEFT) strategies. To this end, we
demonstrate the impact of two factors \textit{viz.}, client-specific layer
importance score that selects the most important VLM layers for fine-tuning and
inter-client layer diversity score that encourages diverse layer selection
across clients for optimal VLM layer selection. We first theoretically motivate
and leverage the principal eigenvalue magnitude of layerwise Neural Tangent
Kernels and show its effectiveness as client-specific layer importance score.
Next, we propose a novel layer updating strategy dubbed F$^3$OCUS that jointly
optimizes the layer importance and diversity factors by employing a data-free,
multi-objective, meta-heuristic optimization on the server. We explore 5
different meta-heuristic algorithms and compare their effectiveness for
selecting model layers and adapter layers towards PEFT-FL. Furthermore, we
release a new MedVQA-FL dataset involving overall 707,962 VQA triplets and 9
modality-specific clients and utilize it to train and evaluate our method.
Overall, we conduct more than 10,000 client-level experiments on 6
Vision-Language FL task settings involving 58 medical image datasets and 4
different VLM architectures of varying sizes to demonstrate the effectiveness
of the proposed method.

ÊëòË¶ÅÔºö<paragraph>Âú®ËÅØÂêàÂ≠∏Áøí (FL) ‰∏≠ÔºåÂú®Ë≥áÊ∫êÂèóÈôêÁöÑÁî®Êà∂Á´ØË£ùÁΩÆ‰∏äÊúâÊïàË®ìÁ∑¥Â§ßÂûãË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM)ÔºåÈúÄË¶Å‰ΩøÁî®ÂèÉÊï∏ÊúâÊïàÂæÆË™ø (PEFT) Á≠ñÁï•„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂÖ©ÂÄãÂõ†Á¥†ÁöÑÂΩ±ÈüøÔºåÂç≥ÂÆ¢Êà∂Á´ØÁâπÂÆöÂ±§ÈáçË¶ÅÊÄßË©ïÂàÜÔºåÂÆÉÈÅ∏Êìá‰∫ÜÊúÄÈáçË¶ÅÁöÑ VLM Â±§ÈÄ≤Ë°åÂæÆË™øÔºå‰ª•ÂèäÂÆ¢Êà∂Á´ØÈñìÂ±§Â§öÊ®£ÊÄßË©ïÂàÜÔºåÂÆÉÈºìÂãµÂú®ÂÆ¢Êà∂Á´Ø‰πãÈñìÈÄ≤Ë°å‰∏çÂêåÁöÑÂ±§ÈÅ∏ÊìáÔºå‰ª•ÂØ¶ÁèæÊúÄ‰Ω≥ÁöÑ VLM Â±§ÈÅ∏Êìá„ÄÇÊàëÂÄëÈ¶ñÂÖàÂæûÁêÜË´ñ‰∏äÊøÄÂãµ‰∏¶Âà©Áî®Â±§Á¥öÁ•ûÁ∂ìÂàáÁ∑öÊ†∏ÁöÑ‰∏ªÁâπÂæµÂÄºÂ§ßÂ∞èÔºå‰∏¶Â±ïÁ§∫ÂÖ∂‰ΩúÁÇ∫ÂÆ¢Êà∂Á´ØÁâπÂÆöÂ±§ÈáçË¶ÅÊÄßË©ïÂàÜÁöÑÊúâÊïàÊÄß„ÄÇÊé•‰∏ã‰æÜÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂêçÁÇ∫ F$^3$OCUS ÁöÑÊñ∞Á©éÂ±§Êõ¥Êñ∞Á≠ñÁï•ÔºåÂÆÉÈÄöÈÅéÂú®‰º∫ÊúçÂô®‰∏ä‰ΩøÁî®ÁÑ°Êï∏Êìö„ÄÅÂ§öÁõÆÊ®ô„ÄÅÂÖÉÂïüÁôºÂºèÂÑ™ÂåñÔºåÂÖ±ÂêåÂÑ™ÂåñÂ±§ÈáçË¶ÅÊÄßÂíåÂ§öÊ®£ÊÄßÂõ†Á¥†„ÄÇÊàëÂÄëÊé¢Á¥¢‰∫Ü 5 Á®Æ‰∏çÂêåÁöÑÂÖÉÂïüÁôºÂºèÊºîÁÆóÊ≥ïÔºå‰∏¶ÊØîËºÉ‰∫ÜÂÆÉÂÄëÂú®ÈÅ∏ÊìáÊ®°ÂûãÂ±§ÂíåÈÅ©ÈÖçÂô®Â±§‰ª•ÈÄ≤Ë°å PEFT-FL ÁöÑÊúâÊïàÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁôºÂ∏É‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑ MedVQA-FL Ë≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ 707,962 ÂÄã VQA ‰∏âÂÖÉÁµÑÂíå 9 ÂÄãÁâπÂÆöÊñºÊ®°ÂºèÁöÑÁî®Êà∂Á´ØÔºå‰∏¶Âà©Áî®ÂÆÉ‰æÜË®ìÁ∑¥ÂíåË©ï‰º∞ÊàëÂÄëÁöÑÊ®°Âûã„ÄÇÁ∏ΩÈ´îËÄåË®ÄÔºåÊàëÂÄëÂú® 6 ÂÄãË¶ñË¶∫Ë™ûË®Ä FL ‰ªªÂãôË®≠ÁΩÆ‰∏äÈÄ≤Ë°å‰∫Ü 10,000 Â§öÂÄãÁî®Êà∂Á´ØÁ¥öÂà•ÁöÑÂØ¶È©óÔºåÊ∂âÂèä 58 ÂÄãÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñôÈõÜÂíå 4 ÂÄã‰∏çÂêåÂ§ßÂ∞èÁöÑ VLM Êû∂ÊßãÔºå‰ª•Ë≠âÊòéÊâÄÊèêÂá∫ÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ</paragraph>

##### **MPLite: Multi-Aspect Pretraining for Mining Clinical Health Records**
2411.11161v1 by Eric Yang, Pengfei Hu, Xiaoxue Han, Yue Ning

The adoption of digital systems in healthcare has resulted in the
accumulation of vast electronic health records (EHRs), offering valuable data
for machine learning methods to predict patient health outcomes. However,
single-visit records of patients are often neglected in the training process
due to the lack of annotations of next-visit information, thereby limiting the
predictive and expressive power of machine learning models. In this paper, we
present a novel framework MPLite that utilizes Multi-aspect Pretraining with
Lab results through a light-weight neural network to enhance medical concept
representation and predict future health outcomes of individuals. By
incorporating both structured medical data and additional information from lab
results, our approach fully leverages patient admission records. We design a
pretraining module that predicts medical codes based on lab results, ensuring
robust prediction by fusing multiple aspects of features. Our experimental
evaluation using both MIMIC-III and MIMIC-IV datasets demonstrates improvements
over existing models in diagnosis prediction and heart failure prediction
tasks, achieving a higher weighted-F1 and recall with MPLite. This work reveals
the potential of integrating diverse aspects of data to advance predictive
modeling in healthcare.

ÊëòË¶ÅÔºöÊï∏‰ΩçÁ≥ªÁµ±Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÊé°Áî®Â∞éËá¥‰∫ÜÂ§ßÈáèÈõªÂ≠êÂÅ•Â∫∑Ë®òÈåÑ (EHR) ÁöÑÁ¥ØÁ©çÔºåÈÄô‰∫õË®òÈåÑÊèê‰æõ‰∫ÜÊúâÂÉπÂÄºÁöÑË≥áÊñôÔºåÂèØ‰æõÊ©üÂô®Â≠∏ÁøíÊñπÊ≥ïÁî®‰æÜÈ†êÊ∏¨ÊÇ£ËÄÖÁöÑÂÅ•Â∫∑ÁµêÊûú„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÁº∫‰πè‰∏ãÊ¨°Â∞±Ë®∫Ë≥áË®äÁöÑË®ªËß£ÔºåÊÇ£ËÄÖÁöÑÂñÆÊ¨°Â∞±Ë®∫Ë®òÈåÑÂú®Ë®ìÁ∑¥ÈÅéÁ®ã‰∏≠Â∏∏Â∏∏Ë¢´ÂøΩÁï•ÔºåÂõ†Ê≠§ÈôêÂà∂‰∫ÜÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÈ†êÊ∏¨ÂíåË°®ÈÅîËÉΩÂäõ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊ°ÜÊû∂ MPLiteÔºåÂÆÉÂà©Áî®ÈÄèÈÅéËºïÈáèÁ¥öÁ•ûÁ∂ìÁ∂≤Ë∑ØÈÄ≤Ë°åÂ§öÈù¢ÂêëÈ†êË®ìÁ∑¥ËàáÂØ¶È©óÂÆ§ÁµêÊûúÔºå‰æÜÂ¢ûÂº∑ÈÜ´ÁôÇÊ¶ÇÂøµÁöÑË°®Âæµ‰∏¶È†êÊ∏¨ÂÄã‰∫∫ÁöÑÊú™‰æÜÂÅ•Â∫∑ÁµêÊûú„ÄÇÈÄèÈÅéÁµêÂêàÁµêÊßãÂåñÁöÑÈÜ´ÁôÇË≥áÊñôÂíå‰æÜËá™ÂØ¶È©óÂÆ§ÁµêÊûúÁöÑÈ°çÂ§ñË≥áË®äÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂÖÖÂàÜÂà©Áî®‰∫ÜÊÇ£ËÄÖÁöÑÂÖ•Èô¢Ë®òÈåÑ„ÄÇÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÈ†êË®ìÁ∑¥Ê®°ÁµÑÔºåÊ†πÊìöÂØ¶È©óÂÆ§ÁµêÊûúÈ†êÊ∏¨ÈÜ´ÁôÇ‰ª£Á¢ºÔºåÁ¢∫‰øùÈÄèÈÅéËûçÂêàÁâπÂæµÁöÑÂêÑÂÄãÈù¢Âêë‰æÜÈÄ≤Ë°åÁ©©ÂÅ•ÁöÑÈ†êÊ∏¨„ÄÇÊàëÂÄë‰ΩøÁî® MIMIC-III Âíå MIMIC-IV Ë≥áÊñôÈõÜÈÄ≤Ë°åÁöÑÂØ¶È©óË©ï‰º∞Ë≠âÊòéÔºåÂú®Ë®∫Êñ∑È†êÊ∏¨ÂíåÂøÉËáüË°∞Á´≠È†êÊ∏¨‰ªªÂãô‰∏≠ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂÑ™ÊñºÁèæÊúâÁöÑÊ®°ÂûãÔºå‰ΩøÁî® MPLite ÈÅîÂà∞‰∫ÜÊõ¥È´òÁöÑÂä†Ê¨ä F1 ÂíåÂè¨ÂõûÁéá„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊè≠Á§∫‰∫ÜÊï¥ÂêàË≥áÊñô‰∏≠‰∏çÂêåÈù¢ÂêëÁöÑÊΩõÂäõÔºå‰ª•Êé®ÈÄ≤ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÈ†êÊ∏¨Âª∫Ê®°„ÄÇ

##### **Label Sharing Incremental Learning Framework for Independent Multi-Label Segmentation Tasks**
2411.11105v1 by Deepa Anand, Bipul Das, Vyshnav Dangeti, Antony Jerald, Rakesh Mullick, Uday Patil, Pakhi Sharma, Prasad Sudhakar

In a setting where segmentation models have to be built for multiple
datasets, each with its own corresponding label set, a straightforward way is
to learn one model for every dataset and its labels. Alternatively, multi-task
architectures with shared encoders and multiple segmentation heads or shared
weights with compound labels can also be made use of. This work proposes a
novel label sharing framework where a shared common label space is constructed
and each of the individual label sets are systematically mapped to the common
labels. This transforms multiple datasets with disparate label sets into a
single large dataset with shared labels, and therefore all the segmentation
tasks can be addressed by learning a single model. This eliminates the need for
task specific adaptations in network architectures and also results in
parameter and data efficient models. Furthermore, label sharing framework is
naturally amenable for incremental learning where segmentations for new
datasets can be easily learnt. We experimentally validate our method on various
medical image segmentation datasets, each involving multi-label segmentation.
Furthermore, we demonstrate the efficacy of the proposed method in terms of
performance and incremental learning ability vis-a-vis alternative methods.

ÊëòË¶ÅÔºöÂú®ÂøÖÈ†àÁÇ∫Â§öÂÄãË≥áÊñôÈõÜÂª∫Á´ãÂàÜÂâ≤Ê®°ÂûãÁöÑË®≠ÂÆö‰∏≠ÔºåÊØèÂÄãË≥áÊñôÈõÜÈÉΩÊúâËá™Â∑±Â∞çÊáâÁöÑÊ®ôÁ±§ÈõÜÔºå‰∏ÄÂÄãÁõ¥Êé•ÁöÑÊñπÊ≥ïÊòØÁÇ∫ÊØèÂÄãË≥áÊñôÈõÜÂèäÂÖ∂Ê®ôÁ±§Â≠∏Áøí‰∏ÄÂÄãÊ®°Âûã„ÄÇÊàñËÄÖÔºå‰πüÂèØ‰ª•Âà©Áî®ÂÖ∑ÊúâÂÖ±‰∫´Á∑®Á¢ºÂô®ÂíåÂ§öÂÄãÂàÜÂâ≤È†≠ÊàñÂÖ∑ÊúâË§áÂêàÊ®ôÁ±§ÁöÑÂÖ±‰∫´Ê¨äÈáçÁöÑÂ§ö‰ªªÂãôÊû∂Êßã„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ®ôÁ±§ÂÖ±‰∫´Ê°ÜÊû∂ÔºåÂÖ∂‰∏≠ÊßãÂª∫‰∫Ü‰∏ÄÂÄãÂÖ±‰∫´ÁöÑÂÖ±ÂêåÊ®ôÁ±§Á©∫ÈñìÔºå‰∏¶‰∏îÊØèÂÄãÂñÆÁç®ÁöÑÊ®ôÁ±§ÈõÜÈÉΩÁ≥ªÁµ±ÊÄßÂú∞Êò†Â∞ÑÂà∞ÂÖ±ÂêåÊ®ôÁ±§„ÄÇÈÄôÂ∞áÂÖ∑Êúâ‰∏çÂêåÊ®ôÁ±§ÈõÜÁöÑÂ§öÂÄãË≥áÊñôÈõÜËΩâÊèõÁÇ∫ÂÖ∑ÊúâÂÖ±‰∫´Ê®ôÁ±§ÁöÑÂñÆ‰∏ÄÂ§ßÂûãË≥áÊñôÈõÜÔºåÂõ†Ê≠§ÊâÄÊúâÂàÜÂâ≤‰ªªÂãôÈÉΩÂèØ‰ª•ÈÄöÈÅéÂ≠∏ÁøíÂñÆ‰∏ÄÊ®°Âûã‰æÜËß£Ê±∫„ÄÇÈÄôÊ∂àÈô§‰∫ÜÂ∞çÁ∂≤Ë∑ØÊû∂Êßã‰∏≠ÁâπÂÆö‰ªªÂãôÈÅ©ÊáâÁöÑÈúÄÊ±ÇÔºå‰∏¶‰∏îÈÇÑÁî¢Áîü‰∫ÜÂèÉÊï∏ÂíåË≥áÊñôÊúâÊïàÁéáÁöÑÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåÊ®ôÁ±§ÂÖ±‰∫´Ê°ÜÊû∂Ëá™ÁÑ∂ÈÅ©Áî®ÊñºÂ¢ûÈáèÂ≠∏ÁøíÔºåÂÖ∂‰∏≠ÂèØ‰ª•ËºïÈ¨ÜÂ≠∏ÁøíÊñ∞Ë≥áÊñôÈõÜÁöÑÂàÜÂâ≤„ÄÇÊàëÂÄëÂú®Ê∂âÂèäÂ§öÊ®ôÁ±§ÂàÜÂâ≤ÁöÑÂêÑÁ®ÆÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤Ë≥áÊñôÈõÜ‰∏äÂ∞çÊàëÂÄëÁöÑÊ®°ÂûãÈÄ≤Ë°åÂØ¶È©óÈ©óË≠â„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊ†πÊìöÊïàËÉΩÂíåÂ¢ûÈáèÂ≠∏ÁøíËÉΩÂäõË≠âÊòé‰∫ÜÊâÄÊèêÂá∫Ê®°ÂûãÁöÑÊúâÊïàÊÄßÔºåÁõ∏Â∞çÊñºÂÖ∂‰ªñÊñπÊ≥ï„ÄÇ

##### **BianCang: A Traditional Chinese Medicine Large Language Model**
2411.11027v1 by Sibo Wei, Xueping Peng, Yi-fei Wang, Jiasheng Si, Weiyu Zhang, Wenpeng Lu, Xiaoming Wu, Yinglong Wang

The rise of large language models (LLMs) has driven significant progress in
medical applications, including traditional Chinese medicine (TCM). However,
current medical LLMs struggle with TCM diagnosis and syndrome differentiation
due to substantial differences between TCM and modern medical theory, and the
scarcity of specialized, high-quality corpora. This paper addresses these
challenges by proposing BianCang, a TCM-specific LLM, using a two-stage
training process that first injects domain-specific knowledge and then aligns
it through targeted stimulation. To enhance diagnostic and differentiation
capabilities, we constructed pre-training corpora, instruction-aligned datasets
based on real hospital records, and the ChP-TCM dataset derived from the
Pharmacopoeia of the People's Republic of China. We compiled extensive TCM and
medical corpora for continuous pre-training and supervised fine-tuning,
building a comprehensive dataset to refine the model's understanding of TCM.
Evaluations across 11 test sets involving 29 models and 4 tasks demonstrate the
effectiveness of BianCang, offering valuable insights for future research.
Code, datasets, and models are available at
https://github.com/QLU-NLP/BianCang.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËààËµ∑Êé®Âãï‰∫ÜÈÜ´ÁôÇÊáâÁî®È†òÂüüÁöÑÈáçÂ§ßÈÄ≤Â±ïÔºåÂåÖÊã¨‰∏≠ÈÜ´Â≠∏ (TCM)„ÄÇÁÑ∂ËÄåÔºåÁî±Êñº‰∏≠ÈÜ´Â≠∏ËàáÁèæ‰ª£ÈÜ´Â≠∏ÁêÜË´ñ‰πãÈñìÂ≠òÂú®ËëóÂØ¶Ë≥™ÊÄßÁöÑÂ∑ÆÁï∞Ôºå‰ª•ÂèäÁº∫‰πèÂ∞àÊ•≠„ÄÅÈ´òÂìÅË≥™ÁöÑË™ûÊñôÂ∫´ÔºåÁï∂ÂâçÁöÑÈÜ´Â≠∏ LLM Âú®‰∏≠ÈÜ´Ë®∫Êñ∑ÂíåË≠âÂÄôÈëëÂà•ÊñπÈù¢ÈÅáÂà∞‰∫ÜÂõ∞Èõ£„ÄÇÊú¨ÊñáÈÄöÈÅéÊèêÂá∫ BianCangÔºå‰∏ÄÁ®ÆÁâπÂÆöÊñº‰∏≠ÈÜ´Â≠∏ÁöÑ LLMÔºå‰æÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞Ôºå‰ΩøÁî®‰∏ÄÂÄãÂÖ©ÈöéÊÆµË®ìÁ∑¥ÈÅéÁ®ãÔºåÈ¶ñÂÖàÊ≥®ÂÖ•ÁâπÂÆöÈ†òÂüüÁöÑÁü•Ë≠òÔºåÁÑ∂ÂæåÈÄöÈÅéÊúâÈáùÂ∞çÊÄßÁöÑÂà∫ÊøÄ‰æÜÂ∞çÈΩäÂÆÉ„ÄÇÁÇ∫‰∫ÜÂ¢ûÂº∑Ë®∫Êñ∑ÂíåÈëëÂà•ËÉΩÂäõÔºåÊàëÂÄëÊßãÂª∫‰∫ÜÈ†êË®ìÁ∑¥Ë™ûÊñôÂ∫´„ÄÅÂü∫ÊñºÁúüÂØ¶ÈÜ´Èô¢Ë®òÈåÑÁöÑÊåá‰ª§Â∞çÈΩäÊï∏ÊìöÈõÜÔºå‰ª•ÂèäÊ∫êËá™‰∏≠ËèØ‰∫∫Ê∞ëÂÖ±ÂíåÂúãËó•ÂÖ∏ÁöÑ ChP-TCM Êï∏ÊìöÈõÜ„ÄÇÊàëÂÄëÁ∑®Ë≠Ø‰∫ÜÂ§ßÈáèÁöÑ TCM ÂíåÈÜ´Â≠∏Ë™ûÊñôÂ∫´ÔºåÁî®ÊñºÊåÅÁ∫åÁöÑÈ†êË®ìÁ∑¥ÂíåÁõ£Áù£ÂæÆË™øÔºåÊßãÂª∫‰∫Ü‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÊï∏ÊìöÈõÜ‰æÜÂÆåÂñÑÊ®°ÂûãÂ∞ç TCM ÁöÑÁêÜËß£„ÄÇÊ∂âÂèä 29 ÂÄãÊ®°ÂûãÂíå 4 È†Ö‰ªªÂãôÁöÑ 11 ÂÄãÊ∏¨Ë©¶ÈõÜÁöÑË©ï‰º∞Ë≠âÊòé‰∫Ü BianCang ÁöÑÊúâÊïàÊÄßÔºåÁÇ∫Êú™‰æÜÁöÑÁ†îÁ©∂Êèê‰æõ‰∫ÜÊúâÂÉπÂÄºÁöÑË¶ãËß£„ÄÇÁ®ãÂºèÁ¢º„ÄÅÊï∏ÊìöÈõÜÂíåÊ®°ÂûãÂèØÂú® https://github.com/QLU-NLP/BianCang Áç≤Âæó„ÄÇ

##### **MpoxVLM: A Vision-Language Model for Diagnosing Skin Lesions from Mpox Virus Infection**
2411.10888v1 by Xu Cao, Wenqian Ye, Kenny Moise, Megan Coffee

In the aftermath of the COVID-19 pandemic and amid accelerating climate
change, emerging infectious diseases, particularly those arising from zoonotic
spillover, remain a global threat. Mpox (caused by the monkeypox virus) is a
notable example of a zoonotic infection that often goes undiagnosed, especially
as its rash progresses through stages, complicating detection across diverse
populations with different presentations. In August 2024, the WHO
Director-General declared the mpox outbreak a public health emergency of
international concern for a second time. Despite the deployment of deep
learning techniques for detecting diseases from skin lesion images, a robust
and publicly accessible foundation model for mpox diagnosis is still lacking
due to the unavailability of open-source mpox skin lesion images, multimodal
clinical data, and specialized training pipelines. To address this gap, we
propose MpoxVLM, a vision-language model (VLM) designed to detect mpox by
analyzing both skin lesion images and patient clinical information. MpoxVLM
integrates the CLIP visual encoder, an enhanced Vision Transformer (ViT)
classifier for skin lesions, and LLaMA-2-7B models, pre-trained and fine-tuned
on visual instruction-following question-answer pairs from our newly released
mpox skin lesion dataset. Our work achieves 90.38% accuracy for mpox detection,
offering a promising pathway to improve early diagnostic accuracy in combating
mpox.

ÊëòË¶ÅÔºöÂú® COVID-19 Â§ßÊµÅË°å‰πãÂæåÔºåÂú®Âä†ÈÄüÁöÑÊ∞£ÂÄôËÆäÈÅ∑ÂíåÊñ∞ËààÂÇ≥ÊüìÁóÖ‰∏≠ÔºåÁâπÂà•ÊòØÈÇ£‰∫õÊ∫êËá™‰∫∫ÁïúÂÖ±ÈÄöÂÇ≥ÊüìÁóÖÁöÑÁñæÁóÖÔºå‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÂÖ®ÁêÉÊÄßÁöÑÂ®ÅËÑÖ„ÄÇÁå¥ÁóòÔºàÁî±Áå¥ÁóòÁóÖÊØíÂºïËµ∑ÔºâÊòØ‰∏ÄÂÄãÈ°ØËëóÁöÑ‰∫∫ÁïúÂÖ±ÈÄöÂÇ≥ÊüìÁóÖÊÑüÊüìÁØÑ‰æãÔºåÈÄöÂ∏∏Êú™Ë¢´Ë®∫Êñ∑Âá∫‰æÜÔºåÁâπÂà•ÊòØÈö®ËëóÂÖ∂ÁöÆÁñπÈÄ≤Â±ïÂà∞ÂêÑÂÄãÈöéÊÆµÔºå‰ΩøÂæóÂú®ÂÖ∑Êúâ‰∏çÂêåË°®ÁèæÂΩ¢ÂºèÁöÑÂ§öÂÖÉÊóèÁæ§‰∏≠ÈÄ≤Ë°åÂÅµÊ∏¨ËÆäÂæóË§áÈõú„ÄÇ2024 Âπ¥ 8 ÊúàÔºå‰∏ñÁïåË°õÁîüÁµÑÁπîÁ∏ΩÂππ‰∫ãÁ¨¨‰∫åÊ¨°ÂÆ£Â∏ÉÁå¥ÁóòÁñ´ÊÉÖÁÇ∫ÂúãÈöõÈóúÊ≥®ÁöÑÂÖ¨ÂÖ±Ë°õÁîüÁ∑äÊÄ•‰∫ã‰ª∂„ÄÇÂÑòÁÆ°Â∑≤ÈÉ®ÁΩ≤Ê∑±Â∫¶Â≠∏ÁøíÊäÄË°ìÁî®ÊñºÂæûÁöÆËÜöÁóÖÁÅ∂ÂΩ±ÂÉè‰∏≠ÂÅµÊ∏¨ÁñæÁóÖÔºå‰ΩÜÁî±ÊñºÁº∫‰πèÈñãÊîæÂéüÂßãÁ¢ºÁöÑÁå¥ÁóòÁöÆËÜöÁóÖÁÅ∂ÂΩ±ÂÉè„ÄÅÂ§öÊ®°ÂºèËá®Â∫äË≥áÊñôÂíåÂ∞àÊ•≠ÁöÑË®ìÁ∑¥ÁÆ°ÈÅìÔºåÂõ†Ê≠§‰ªçÁÑ∂Áº∫‰πè‰∏ÄÂÄãÁ©©ÂÅ•‰∏îÂÖ¨ÈñãÂèØÁî®ÁöÑÁå¥ÁóòË®∫Êñ∑Âü∫Á§éÊ®°Âûã„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫ MpoxVLMÔºåÈÄôÊòØ‰∏ÄÂÄãË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM)ÔºåÊó®Âú®ÈÄèÈÅéÂàÜÊûêÁöÆËÜöÁóÖÁÅ∂ÂΩ±ÂÉèÂíåÊÇ£ËÄÖËá®Â∫äË≥áË®ä‰æÜÂÅµÊ∏¨Áå¥Áóò„ÄÇMpoxVLM Êï¥Âêà‰∫Ü CLIP Ë¶ñË¶∫Á∑®Á¢ºÂô®„ÄÅ‰∏ÄÂÄãÈáùÂ∞çÁöÆËÜöÁóÖÁÅ∂Â¢ûÂº∑ÁöÑË¶ñË¶∫ËΩâÊèõÂô® (ViT) ÂàÜÈ°ûÂô®Ôºå‰ª•Âèä LLaMA-2-7B Ê®°ÂûãÔºåÈÄô‰∫õÊ®°ÂûãÁ∂ìÈÅéÈ†êÂÖàË®ìÁ∑¥ÂíåÂæÆË™øÔºå‰∏¶Ê†πÊìöÊàëÂÄëÊñ∞ÁôºÂ∏ÉÁöÑÁå¥ÁóòÁöÆËÜöÁóÖÁÅ∂Ë≥áÊñôÈõÜ‰∏≠ÁöÑË¶ñË¶∫Êåá‰ª§ÈÅµÂæ™ÂïèÈ°åËß£Á≠îÈÖçÂ∞ç„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Âú®Áå¥ÁóòÂÅµÊ∏¨ÊñπÈù¢ÈÅîÂà∞‰∫Ü 90.38% ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÁÇ∫ÊèêÈ´òÊó©ÊúüË®∫Êñ∑Ê∫ñÁ¢∫Â∫¶‰ª•Â∞çÊäóÁå¥ÁóòÊèê‰æõ‰∫ÜÊúâÂ∏åÊúõÁöÑÈÄîÂæë„ÄÇ

##### **Towards Next-Generation Medical Agent: How o1 is Reshaping Decision-Making in Medical Scenarios**
2411.14461v1 by Shaochen Xu, Yifan Zhou, Zhengliang Liu, Zihao Wu, Tianyang Zhong, Huaqin Zhao, Yiwei Li, Hanqi Jiang, Yi Pan, Junhao Chen, Jin Lu, Wei Zhang, Tuo Zhang, Lu Zhang, Dajiang Zhu, Xiang Li, Wei Liu, Quanzheng Li, Andrea Sikora, Xiaoming Zhai, Zhen Xiang, Tianming Liu

Artificial Intelligence (AI) has become essential in modern healthcare, with
large language models (LLMs) offering promising advances in clinical
decision-making. Traditional model-based approaches, including those leveraging
in-context demonstrations and those with specialized medical fine-tuning, have
demonstrated strong performance in medical language processing but struggle
with real-time adaptability, multi-step reasoning, and handling complex medical
tasks. Agent-based AI systems address these limitations by incorporating
reasoning traces, tool selection based on context, knowledge retrieval, and
both short- and long-term memory. These additional features enable the medical
AI agent to handle complex medical scenarios where decision-making should be
built on real-time interaction with the environment. Therefore, unlike
conventional model-based approaches that treat medical queries as isolated
questions, medical AI agents approach them as complex tasks and behave more
like human doctors. In this paper, we study the choice of the backbone LLM for
medical AI agents, which is the foundation for the agent's overall reasoning
and action generation. In particular, we consider the emergent o1 model and
examine its impact on agents' reasoning, tool-use adaptability, and real-time
information retrieval across diverse clinical scenarios, including high-stakes
settings such as intensive care units (ICUs). Our findings demonstrate o1's
ability to enhance diagnostic accuracy and consistency, paving the way for
smarter, more responsive AI tools that support better patient outcomes and
decision-making efficacy in clinical practice.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ËÉΩ (AI) Â∑≤ÊàêÁÇ∫Áèæ‰ª£ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠‰∏çÂèØÊàñÁº∫ÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÂÖ∂‰∏≠Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁÇ∫Ëá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÊèê‰æõ‰∫ÜÊúâÂ∏åÊúõÁöÑÈÄ≤Â±ï„ÄÇÂÇ≥Áµ±ÁöÑÂü∫ÊñºÊ®°ÂûãÁöÑÊñπÊ≥ïÔºåÂåÖÊã¨Âà©Áî®ÊÉÖÂ¢É‰∏≠ÁöÑÁ§∫ÁØÑÂíåÂÖ∑ÊúâÂ∞àÊ•≠ÈÜ´ÁôÇÂæÆË™øÁöÑÊñπÊ≥ïÔºåÂ∑≤Ë≠âÊòéÂú®ÈÜ´Â≠∏Ë™ûË®ÄËôïÁêÜ‰∏≠ÂÖ∑ÊúâÂº∑ÂãÅÁöÑÊÄßËÉΩÔºå‰ΩÜÂú®ÂØ¶ÊôÇÈÅ©ÊáâÊÄß„ÄÅÂ§öÊ≠•È©üÊé®ÁêÜÂíåËôïÁêÜË§áÈõúÁöÑÈÜ´ÁôÇ‰ªªÂãôÊñπÈù¢Â≠òÂú®Âõ∞Èõ£„ÄÇÂü∫Êñº‰ª£ÁêÜÁöÑ AI Á≥ªÁµ±ÈÄöÈÅéÊï¥ÂêàÊé®ÁêÜËøΩËπ§„ÄÅÂü∫ÊñºÊÉÖÂ¢ÉÁöÑÂ∑•ÂÖ∑ÈÅ∏Êìá„ÄÅÁü•Ë≠òÊ™¢Á¥¢‰ª•ÂèäÁü≠ÊúüÂíåÈï∑ÊúüË®òÊÜ∂‰æÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂„ÄÇÈÄô‰∫õÈ°çÂ§ñÁöÑÂäüËÉΩ‰ΩøÈÜ´ÁôÇ AI ‰ª£ÁêÜËÉΩÂ§†ËôïÁêÜË§áÈõúÁöÑÈÜ´ÁôÇÂ†¥ÊôØÔºåÂú®ÈÄô‰∫õÂ†¥ÊôØ‰∏≠ÔºåÊ±∫Á≠ñÂà∂ÂÆöÊáâÂª∫Á´ãÂú®ËàáÁí∞Â¢ÉÁöÑÂØ¶ÊôÇ‰∫íÂãï‰πã‰∏ä„ÄÇÂõ†Ê≠§ÔºåËàáÂ∞áÈÜ´ÁôÇÊü•Ë©¢Ë¶ñÁÇ∫Â≠§Á´ãÂïèÈ°åÁöÑÂÇ≥Áµ±Âü∫ÊñºÊ®°ÂûãÁöÑÊñπÊ≥ï‰∏çÂêåÔºåÈÜ´ÁôÇ AI ‰ª£ÁêÜÂ∞áÂÆÉÂÄëË¶ñÁÇ∫Ë§áÈõúÁöÑ‰ªªÂãôÔºå‰∏¶‰∏îÊõ¥ÂÉè‰∫∫È°ûÈÜ´Áîü„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁ†îÁ©∂‰∫ÜÈÜ´ÁôÇ AI ‰ª£ÁêÜÁöÑÈ™®Âππ LLM ÁöÑÈÅ∏ÊìáÔºåÈÄôÊòØ‰ª£ÁêÜÊï¥È´îÊé®ÁêÜÂíåÂãï‰ΩúÁîüÊàêÁöÑÂü∫Á§é„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëËÄÉÊÖÆ‰∫ÜÊñ∞ËààÁöÑ o1 Ê®°ÂûãÔºå‰∏¶Ê™¢Êü•‰∫ÜÂÆÉÂ∞ç‰ª£ÁêÜÊé®ÁêÜ„ÄÅÂ∑•ÂÖ∑‰ΩøÁî®ÈÅ©ÊáâÊÄßÂíåË∑®‰∏çÂêåËá®Â∫äÂ†¥ÊôØÁöÑÂØ¶ÊôÇ‰ø°ÊÅØÊ™¢Á¥¢ÁöÑÂΩ±ÈüøÔºåÂåÖÊã¨ÈáçÁóáÁõ£Ë≠∑ÁóÖÊàø (ICU) Á≠âÈ´òÈ¢®Èö™Áí∞Â¢É„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË≠âÊòé‰∫Ü o1 ÊèêÈ´òË®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÂíå‰∏ÄËá¥ÊÄßÁöÑËÉΩÂäõÔºåÁÇ∫Êõ¥Êô∫ËÉΩ„ÄÅÊõ¥ÈùàÊïèÁöÑ AI Â∑•ÂÖ∑Èã™Âπ≥‰∫ÜÈÅìË∑ØÔºåÈÄô‰∫õÂ∑•ÂÖ∑ÊîØÊåÅÊõ¥Â•ΩÁöÑÊÇ£ËÄÖÈ†êÂæåÂíåËá®Â∫äÂØ¶Ë∏ê‰∏≠ÁöÑÊ±∫Á≠ñÂà∂ÂÆöÊïàÁéá„ÄÇ

##### **A Novel Adaptive Hybrid Focal-Entropy Loss for Enhancing Diabetic Retinopathy Detection Using Convolutional Neural Networks**
2411.10843v1 by Pandiyaraju V, Santhosh Malarvannan, Shravan Venkatraman, Abeshek A, Priyadarshini B, Kannan A

Diabetic retinopathy is a leading cause of blindness around the world and
demands precise AI-based diagnostic tools. Traditional loss functions in
multi-class classification, such as Categorical Cross-Entropy (CCE), are very
common but break down with class imbalance, especially in cases with inherently
challenging or overlapping classes, which leads to biased and less sensitive
models. Since a heavy imbalance exists in the number of examples for higher
severity stage 4 diabetic retinopathy, etc., classes compared to those very
early stages like class 0, achieving class balance is key. For this purpose, we
propose the Adaptive Hybrid Focal-Entropy Loss which combines the ideas of
focal loss and entropy loss with adaptive weighting in order to focus on
minority classes and highlight the challenging samples. The state-of-the art
models applied for diabetic retinopathy detection with AHFE revealed good
performance improvements, indicating the top performances of ResNet50 at
99.79%, DenseNet121 at 98.86%, Xception at 98.92%, MobileNetV2 at 97.84%, and
InceptionV3 at 93.62% accuracy. This sheds light into how AHFE promotes
enhancement in AI-driven diagnostics for complex and imbalanced medical
datasets.

ÊëòË¶ÅÔºöÁ≥ñÂ∞øÁóÖË¶ñÁ∂≤ËÜúÁóÖËÆäÊòØÂÖ®ÁêÉÂ§±ÊòéÁöÑ‰∏ªË¶ÅÂéüÂõ†ÔºåÈúÄË¶ÅÁ≤æÊ∫ñÁöÑ AI Ë®∫Êñ∑Â∑•ÂÖ∑„ÄÇÂ§öÈ°ûÂà•ÂàÜÈ°û‰∏≠ÁöÑÂÇ≥Áµ±ÊêçÂ§±ÂáΩÊï∏Ôºå‰æãÂ¶ÇÂàÜÈ°û‰∫§ÂèâÁÜµ (CCE)ÔºåÈùûÂ∏∏Â∏∏Ë¶ãÔºå‰ΩÜÊúÉÈö®ËëóÈ°ûÂà•Â§±Ë°°ËÄåÂ§±ÊïàÔºåÁâπÂà•ÊòØÂú®È°ûÂà•Êú¨Ë∫´ÂÖ∑ÊúâÊåëÊà∞ÊÄßÊàñÈáçÁñäÁöÑÊÉÖÊ≥Å‰∏ãÔºåÈÄôÊúÉÂ∞éËá¥ÊúâÂÅèÂ∑Æ‰∏î‰∏çÊïèÊÑüÁöÑÊ®°Âûã„ÄÇÁî±ÊñºÂö¥ÈáçÂ∫¶ËºÉÈ´òÁöÑÁ¨¨ 4 ÊúüÁ≥ñÂ∞øÁóÖË¶ñÁ∂≤ËÜúÁóÖËÆäÁ≠âÈ°ûÂà•ÁöÑÁØÑ‰æãÊï∏ÈáèÂö¥ÈáçÂ§±Ë°°ÔºåËàáÁ¨¨ 0 ÊúüÁ≠âÈùûÂ∏∏Êó©ÊúüÁöÑÈ°ûÂà•Áõ∏ÊØîÔºåÈÅîÊàêÈ°ûÂà•Âπ≥Ë°°Ëá≥ÈóúÈáçË¶Å„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫Ëá™ÈÅ©ÊáâÊ∑∑ÂêàÁÑ¶ÈªûÁÜµÊêçÂ§±ÔºåÂÆÉÁµêÂêà‰∫ÜÁÑ¶ÈªûÊêçÂ§±ÂíåÁÜµÊêçÂ§±ÁöÑÊ¶ÇÂøµÔºå‰∏¶Êé°Áî®Ëá™ÈÅ©ÊáâÂä†Ê¨äÔºå‰ª•Â∞àÊ≥®ÊñºÂ∞ëÊï∏È°ûÂà•‰∏¶Á™ÅÈ°ØÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÁØÑ‰æã„ÄÇÊáâÁî®ÊñºÁ≥ñÂ∞øÁóÖË¶ñÁ∂≤ËÜúÁóÖËÆäÂÅµÊ∏¨ÁöÑÊúÄÊñ∞Ê®°ÂûãÊê≠ÈÖç AHFEÔºåÈ°ØÁ§∫Âá∫ËâØÂ•ΩÁöÑÊïàËÉΩÊèêÂçáÔºåË°®Á§∫ ResNet50 ÁöÑÊúÄÈ´òÊïàËÉΩÁÇ∫ 99.79%„ÄÅDenseNet121 ÁÇ∫ 98.86%„ÄÅXception ÁÇ∫ 98.92%„ÄÅMobileNetV2 ÁÇ∫ 97.84%Ôºå‰ª•Âèä InceptionV3 ÁöÑÊ∫ñÁ¢∫Â∫¶ÁÇ∫ 93.62%„ÄÇÈÄôÊè≠Á§∫‰∫Ü AHFE Â¶Ç‰Ωï‰øÉÈÄ≤‰ª• AI ÁÇ∫‰∏ªÁöÑË®∫Êñ∑Ôºå‰ª•ÊáâÂ∞çË§áÈõú‰∏î‰∏çÂπ≥Ë°°ÁöÑÈÜ´ÁôÇË≥áÊñôÈõÜ„ÄÇ

##### **Decentralizing Test-time Adaptation under Heterogeneous Data Streams**
2411.15173v1 by Zixian Su, Jingwei Guo, Xi Yang, Qiufeng Wang, Kaizhu Huang

While Test-Time Adaptation (TTA) has shown promise in addressing distribution
shifts between training and testing data, its effectiveness diminishes with
heterogeneous data streams due to uniform target estimation. As previous
attempts merely stabilize model fine-tuning over time to handle continually
changing environments, they fundamentally assume a homogeneous target domain at
any moment, leaving the intrinsic real-world data heterogeneity unresolved.
This paper delves into TTA under heterogeneous data streams, moving beyond
current model-centric limitations. By revisiting TTA from a data-centric
perspective, we discover that decomposing samples into Fourier space
facilitates an accurate data separation across different frequency levels.
Drawing from this insight, we propose a novel Frequency-based Decentralized
Adaptation (FreDA) framework, which transitions data from globally
heterogeneous to locally homogeneous in Fourier space and employs decentralized
adaptation to manage diverse distribution shifts.Interestingly, we devise a
novel Fourier-based augmentation strategy to assist in decentralizing
adaptation, which individually enhances sample quality for capturing each type
of distribution shifts. Extensive experiments across various settings
(corrupted, natural, and medical environments) demonstrate the superiority of
our proposed framework over the state-of-the-arts.

ÊëòË¶ÅÔºöÈõñÁÑ∂Ê∏¨Ë©¶ÊôÇÈñìÈÅ©Êáâ (TTA) Â∑≤Â±ïÁèæÂá∫Ëß£Ê±∫Ë®ìÁ∑¥ÂíåÊ∏¨Ë©¶Ë≥áÊñô‰πãÈñìÂàÜ‰ΩàËΩâÁßªÁöÑÊΩõÂäõÔºå‰ΩÜÁî±ÊñºÂùáÂãªÁõÆÊ®ô‰º∞Ë®àÔºåÂÖ∂ÊïàËÉΩÊúÉÈö®ËëóÁï∞Ë≥™Ë≥áÊñô‰∏≤ÊµÅËÄåÈôç‰Ωé„ÄÇÁî±ÊñºÂÖàÂâçÁöÑÂòóË©¶ÂÉÖÂÉÖÁ©©ÂÆöÊ®°ÂûãÂæÆË™ø‰ª•Èö®ËëóÊôÇÈñìÊé®ÁßªËôïÁêÜÊåÅÁ∫åËÆäÂåñÁöÑÁí∞Â¢ÉÔºåÂõ†Ê≠§ÂÆÉÂÄëÂú®‰ªª‰ΩïÊôÇÂàªÈÉΩÂÅáË®≠ÂêåË≥™ÁõÆÊ®ôÁ∂≤ÂüüÔºåËÆìÂÖßÂú®ÁöÑÁúüÂØ¶‰∏ñÁïåË≥áÊñôÁï∞Ë≥™ÊÄßÁÑ°Ê≥ïËß£Ê±∫„ÄÇÊú¨ÊñáÊ∑±ÂÖ•Êé¢Ë®éÁï∞Ë≥™Ë≥áÊñô‰∏≤ÊµÅ‰∏ãÁöÑ TTAÔºåË∂ÖË∂äÁõÆÂâç‰ª•Ê®°ÂûãÁÇ∫‰∏≠ÂøÉÁöÑÈôêÂà∂„ÄÇÈÄèÈÅéÂæû‰ª•Ë≥áÊñôÁÇ∫‰∏≠ÂøÉÁöÑËßÄÈªûÈáçÊñ∞Ê™¢Ë¶ñ TTAÔºåÊàëÂÄëÁôºÁèæÂ∞áÊ®£Êú¨ÂàÜËß£ÊàêÂÇÖÁ´ãËëâÁ©∫ÈñìÊúâÂä©ÊñºÂú®‰∏çÂêåÈ†ªÁéáÂ±§Á¥ö‰∏≠Á≤æÁ¢∫ÂçÄÂàÜË≥áÊñô„ÄÇÊ†πÊìöÊ≠§Ë¶ãËß£ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÂü∫ÊñºÈ†ªÁéáÁöÑÂàÜÊï£ÂºèÈÅ©Êáâ (FreDA) Êû∂ÊßãÔºåË©≤Êû∂ÊßãÂ∞áË≥áÊñôÂæûÂÖ®ÁêÉÁï∞Ë≥™ËΩâËÆäÁÇ∫ÂÇÖÁ´ãËëâÁ©∫Èñì‰∏≠ÁöÑÂ±ÄÈÉ®ÂêåË≥™Ôºå‰∏¶Êé°Áî®ÂàÜÊï£ÂºèÈÅ©Êáâ‰æÜÁÆ°ÁêÜ‰∏çÂêåÁöÑÂàÜ‰ΩàËΩâÁßª„ÄÇÊúâË∂£ÁöÑÊòØÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂü∫ÊñºÂÇÖÁ´ãËëâÁöÑÊì¥ÂÖÖÁ≠ñÁï•Ôºå‰ª•ÂçîÂä©ÂàÜÊï£ÈÅ©ÊáâÔºåÂÄãÂà•Â¢ûÂº∑Ê®£Êú¨ÂìÅË≥™‰ª•Êì∑ÂèñÊØèÁ®ÆÈ°ûÂûãÁöÑÂàÜ‰ΩàËΩâÁßª„ÄÇÂú®ÂêÑÁ®ÆË®≠ÂÆöÔºàÂèóÊêç„ÄÅËá™ÁÑ∂ÂíåÈÜ´ÁôÇÁí∞Â¢ÉÔºâ‰∏≠ÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑÊû∂ÊßãÂÑ™ÊñºÁèæÊúâÊäÄË°ì„ÄÇ

##### **MRI Parameter Mapping via Gaussian Mixture VAE: Breaking the Assumption of Independent Pixels**
2411.10772v1 by Moucheng Xu, Yukun Zhou, Tobias Goodwin-Allcock, Kimia Firoozabadi, Joseph Jacob, Daniel C. Alexander, Paddy J. Slator

We introduce and demonstrate a new paradigm for quantitative parameter
mapping in MRI. Parameter mapping techniques, such as diffusion MRI and
quantitative MRI, have the potential to robustly and repeatably measure
biologically-relevant tissue maps that strongly relate to underlying
microstructure. Quantitative maps are calculated by fitting a model to multiple
images, e.g. with least-squares or machine learning. However, the overwhelming
majority of model fitting techniques assume that each voxel is independent,
ignoring any co-dependencies in the data. This makes model fitting sensitive to
voxelwise measurement noise, hampering reliability and repeatability. We
propose a self-supervised deep variational approach that breaks the assumption
of independent pixels, leveraging redundancies in the data to effectively
perform data-driven regularisation of quantitative maps. We demonstrate that
our approach outperforms current model fitting techniques in dMRI simulations
and real data. Especially with a Gaussian mixture prior, our model enables
sharper quantitative maps, revealing finer anatomical details that are not
presented in the baselines. Our approach can hence support the clinical
adoption of parameter mapping methods such as dMRI and qMRI.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄë‰ªãÁ¥π‰∏¶Â±ïÁ§∫‰∏ÄÁ®ÆÊñ∞ÁöÑÁØÑ‰æãÔºåÁî®Êñº MRI ‰∏≠ÁöÑÂÆöÈáèÂèÉÊï∏Â∞çÊáâ„ÄÇÂèÉÊï∏Â∞çÊáâÊäÄË°ìÔºå‰æãÂ¶ÇÊì¥Êï£ MRI ÂíåÂÆöÈáè MRIÔºåÂÖ∑ÊúâÂº∑ÂÅ•‰∏îÂèØÈáçË§áÊ∏¨ÈáèËàáÂ∫ïÂ±§ÂæÆÁµêÊßãÂØÜÂàáÁõ∏ÈóúÁöÑÁîüÁâ©Áõ∏ÈóúÁµÑÁπîÂ∞çÊáâÁöÑËÉΩÂäõ„ÄÇÂÆöÈáèÂ∞çÊáâÊòØÈÄèÈÅéÂ∞áÊ®°ÂûãÂ•óÁî®Âà∞Â§öÂÄãÂΩ±ÂÉè‰æÜË®àÁÆóÔºå‰æãÂ¶Ç‰ΩøÁî®ÊúÄÂ∞èÂπ≥ÊñπÊàñÊ©üÂô®Â≠∏Áøí„ÄÇÁÑ∂ËÄåÔºåÁµïÂ§ßÂ§öÊï∏ÁöÑÊ®°ÂûãÊì¨ÂêàÊäÄË°ìÂÅáË®≠ÊØèÂÄãÈ´îÁ¥†ÈÉΩÊòØÁç®Á´ãÁöÑÔºåÂøΩÁï•Ë≥áÊñô‰∏≠ÁöÑ‰ªª‰ΩïÂÖ±‰æùË≥¥ÊÄß„ÄÇÈÄô‰ΩøÂæóÊ®°ÂûãÊì¨ÂêàÂÆπÊòìÂèóÂà∞È´îÁ¥†Ê∏¨ÈáèÈõúË®äÁöÑÂΩ±ÈüøÔºåÈòªÁ§ô‰∫ÜÂèØÈù†ÊÄßÂíåÂèØÈáçË§áÊÄß„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãËá™ÊàëÁõ£Áù£ÁöÑÊ∑±Â∫¶ËÆäÁï∞ÊñπÊ≥ïÔºåÊâìÁ†¥‰∫ÜÁç®Á´ãÂÉèÁ¥†ÁöÑÂÅáË®≠ÔºåÂà©Áî®Ë≥áÊñô‰∏≠ÁöÑÂÜóÈ§ò‰æÜÊúâÊïàÂü∑Ë°åÂÆöÈáèÂ∞çÊáâÁöÑË≥áÊñôÈ©ÖÂãïÊ≠£Ë¶èÂåñ„ÄÇÊàëÂÄëË≠âÊòéÊàëÂÄëÁöÑÊ®°ÂûãÂú® dMRI Ê®°Êì¨ÂíåÁúüÂØ¶Ë≥áÊñô‰∏≠ÂÑ™ÊñºÁõÆÂâçÁöÑÊ®°ÂûãÊì¨ÂêàÊäÄË°ì„ÄÇÁâπÂà•ÊòØ‰ΩøÁî®È´òÊñØÊ∑∑ÂêàÂÖàÈ©óÔºåÊàëÂÄëÁöÑÊ®°ÂûãËÉΩÁî¢ÁîüÊõ¥Ê∏ÖÊô∞ÁöÑÂÆöÈáèÂ∞çÊáâÔºåÊè≠Á§∫Âá∫Âü∫Ê∫ñÁ∑ö‰∏≠Êú™ÂëàÁèæÁöÑÊõ¥Á≤æÁ¥∞Ëß£ÂâñÁ¥∞ÁØÄ„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ª•ÊîØÊè¥ dMRI Âíå qMRI Á≠âÂèÉÊï∏Â∞çÊáâÊñπÊ≥ïÁöÑËá®Â∫äÊé°Áî®„ÄÇ</paragraph>

##### **Integrated Machine Learning and Survival Analysis Modeling for Enhanced Chronic Kidney Disease Risk Stratification**
2411.10754v1 by Zachary Dana, Ahmed Ammar Naseer, Botros Toro, Sumanth Swaminathan

Chronic kidney disease (CKD) is a significant public health challenge, often
progressing to end-stage renal disease (ESRD) if not detected and managed
early. Early intervention, warranted by silent disease progression, can
significantly reduce associated morbidity, mortality, and financial burden. In
this study, we propose a novel approach to modeling CKD progression using a
combination of machine learning techniques and classical statistical models.
Building on the work of Liu et al. (2023), we evaluate linear models,
tree-based methods, and deep learning models to extract novel predictors for
CKD progression, with feature importance assessed using Shapley values. These
newly identified predictors, integrated with established clinical features from
the Kidney Failure Risk Equation, are then applied within the framework of Cox
proportional hazards models to predict CKD progression.

ÊëòË¶ÅÔºöÊÖ¢ÊÄßËÖéËáüÁóÖ (CKD) ÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÁöÑÂÖ¨ÂÖ±Ë°õÁîüÊåëÊà∞ÔºåÂ¶ÇÊûúÊú™ÂèäÊó©ÁôºÁèæÂíåÁÆ°ÁêÜÔºåÈÄöÂ∏∏ÊúÉÈÄ≤Â±ïÂà∞Êú´ÊúüËÖéËáüÁñæÁóÖ (ESRD)„ÄÇÁÑ°ËÅ≤ÁñæÁóÖÈÄ≤Á®ãÊâÄËá¥ÁöÑÊó©Êúü‰ªãÂÖ•ÔºåÂèØ‰ª•È°ØËëóÈôç‰ΩéÁõ∏ÈóúÁöÑÁôºÁóÖÁéá„ÄÅÊ≠ª‰∫°ÁéáÂíåË≤°ÂãôË≤†Êìî„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®Æ‰ΩøÁî®Ê©üÂô®Â≠∏ÁøíÊäÄË°ìÂíåÁ∂ìÂÖ∏Áµ±Ë®àÊ®°ÂûãÁõ∏ÁµêÂêà‰æÜÂª∫Ê®° CKD ÈÄ≤Á®ãÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÂú® Liu Á≠â‰∫∫ (2023) ÁöÑÁ†îÁ©∂Âü∫Á§é‰∏äÔºåÊàëÂÄëË©ï‰º∞‰∫ÜÁ∑öÊÄßÊ®°Âûã„ÄÅÂü∫ÊñºÊ®πÁöÑÊñπÊ≥ïÂíåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºå‰ª•ÊèêÂèñ CKD ÈÄ≤Á®ãÁöÑÊñ∞È†êÊ∏¨Âõ†Â≠êÔºå‰∏¶‰ΩøÁî® Shapley ÂÄºË©ï‰º∞ÁâπÂæµÈáçË¶ÅÊÄß„ÄÇÈÄô‰∫õÊñ∞Ë≠òÂà•ÁöÑÈ†êÊ∏¨Âõ†Â≠êËàáËÖéËáüË°∞Á´≠È¢®Èö™ÊñπÁ®ãÂºè‰∏≠Â∑≤Âª∫Á´ãÁöÑËá®Â∫äÁâπÂæµÁõ∏ÁµêÂêàÔºåÁÑ∂ÂæåÊáâÁî®Êñº Cox ÊØî‰æãÈ¢®Èö™Ê®°ÂûãÁöÑÊ°ÜÊû∂‰∏≠‰ª•È†êÊ∏¨ CKD ÈÄ≤Á®ã„ÄÇ

##### **LTCXNet: Advancing Chest X-Ray Analysis with Solutions for Long-Tailed Multi-Label Classification and Fairness Challenges**
2411.10746v1 by Chin-Wei Huang, Mu-Yi Shen, Kuan-Chang Shih, Shih-Chih Lin, Chi-Yu Chen, Po-Chih Kuo

Chest X-rays (CXRs) often display various diseases with disparate class
frequencies, leading to a long-tailed, multi-label data distribution. In
response to this challenge, we explore the Pruned MIMIC-CXR-LT dataset, a
curated collection derived from the MIMIC-CXR dataset, specifically designed to
represent a long-tailed and multi-label data scenario. We introduce LTCXNet, a
novel framework that integrates the ConvNeXt model, ML-Decoder, and strategic
data augmentation, further enhanced by an ensemble approach. We demonstrate
that LTCXNet improves the performance of CXR interpretation across all classes,
especially enhancing detection in rarer classes like `Pneumoperitoneum' and
`Pneumomediastinum' by 79\% and 48\%, respectively. Beyond performance metrics,
our research extends into evaluating fairness, highlighting that some methods,
while improving model accuracy, could inadvertently affect fairness across
different demographic groups negatively. This work contributes to advancing the
understanding and management of long-tailed, multi-label data distributions in
medical imaging, paving the way for more equitable and effective diagnostic
tools.

ÊëòË¶ÅÔºöËÉ∏ÈÉ® X ÂÖâÁâá (CXR) ÈÄöÂ∏∏ÊúÉÈ°ØÁ§∫ÂêÑÁ®ÆÁñæÁóÖÔºå‰∏îÂêÑÈ°ûÂà•ÁöÑÈ†ªÁéá‰∏çÂêåÔºåÂ∞éËá¥Èï∑Â∞æÁöÑÂ§öÊ®ôÁ±§Ë≥áÊñôÂàÜ‰Ωà„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄôÈ†ÖÊåëÊà∞ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÁ≤æÁ∞°ÁöÑ MIMIC-CXR-LT Ë≥áÊñôÈõÜÔºåÈÄôÊòØ‰∏ÄÂÄãÂæû MIMIC-CXR Ë≥áÊñôÈõÜË°çÁîüÁöÑÁ≤æÈÅ∏ÈõÜÂêàÔºåÂ∞àÈñÄË®≠Ë®àÁî®ÊñºË°®Á§∫Èï∑Â∞æÂíåÂ§öÊ®ôÁ±§Ë≥áÊñôÊÉÖÂ¢É„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü LTCXNetÔºåÈÄôÊòØ‰∏ÄÂÄãÊï¥Âêà‰∫Ü ConvNeXt Ê®°Âûã„ÄÅML-Decoder ÂíåÁ≠ñÁï•ÊÄßË≥áÊñôÊì¥ÂÖÖÁöÑÊñ∞Êû∂ÊßãÔºå‰∏¶ÈÄèÈÅéÊï¥È´îÊñπÊ≥ïÈÄ≤‰∏ÄÊ≠•Â¢ûÂº∑„ÄÇÊàëÂÄëË≠âÊòé LTCXNet ÂèØÊèêÂçáÊâÄÊúâÈ°ûÂà•ÁöÑ CXR Ëß£ÈáãÊïàËÉΩÔºåÁâπÂà•ÊòØÂ∞áËºÉÁΩïË¶ãÈ°ûÂà•ÔºàÂ¶Ç„ÄåÊ∞£ËÖπ„ÄçÂíå„ÄåÁ∏±ËÜàÊ∞£ËÖ´„ÄçÔºâÁöÑÂÅµÊ∏¨ÂäüËÉΩÂàÜÂà•ÊèêÂçá‰∫Ü 79% Âíå 48%„ÄÇÈô§‰∫ÜÊïàËÉΩÊåáÊ®ô‰πãÂ§ñÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÈÇÑÊì¥Â±ïÂà∞Ë©ï‰º∞ÂÖ¨Âπ≥ÊÄßÔºåÂº∑Ë™ø‰∏Ä‰∫õÊñπÊ≥ïÂú®ÊèêÂçáÊ®°ÂûãÊ∫ñÁ¢∫Â∫¶ÁöÑÂêåÊôÇÔºåÂèØËÉΩÊúÉÁÑ°ÊÑèÈñìÂ∞ç‰∏çÂêå‰∫∫Âè£Áæ§È´îÁöÑÂÖ¨Âπ≥ÊÄßÁî¢ÁîüË≤†Èù¢ÂΩ±Èüø„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊúâÂä©Êñº‰øÉÈÄ≤Â∞çÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠Èï∑Â∞æ„ÄÅÂ§öÊ®ôÁ±§Ë≥áÊñôÂàÜ‰ΩàÁöÑÁêÜËß£ÂíåÁÆ°ÁêÜÔºåÁÇ∫Êõ¥ÂÖ¨Âπ≥„ÄÅÊúâÊïàÁöÑË®∫Êñ∑Â∑•ÂÖ∑Èã™Ë∑Ø„ÄÇ

##### **Can Artificial Intelligence Generate Quality Research Topics Reflecting Patient Concerns?**
2411.14456v1 by Jiyeong Kim, Michael L. Chen, Shawheen J. Rezaei, Mariana Ramirez-Posada, Jennifer L. Caswell-Jin, Allison W. Kurian, Fauzia Riaz, Kavita Y. Sarin, Jean Y. Tang, Steven M. Asch, Eleni Linos

Patient-centered research is increasingly important in narrowing the gap
between research and patient care, yet incorporating patient perspectives into
health research has been inconsistent. We propose an automated framework
leveraging innovative natural language processing (NLP) and artificial
intelligence (AI) with patient portal messages to generate research ideas that
prioritize important patient issues. We further quantified the quality of
AI-generated research topics. To define patient clinical concerns, we analyzed
614,464 patient messages from 25,549 individuals with breast or skin cancer
obtained from a large academic hospital (2013 to 2024), constructing a 2-staged
unsupervised NLP topic model. Then, we generated research topics to resolve the
defined issues using a widely used AI (ChatGPT-4o, OpenAI Inc, April 2024
version) with prompt-engineering strategies. We guided AI to perform
multi-level tasks: 1) knowledge interpretation and summarization (e.g.,
interpreting and summarizing the NLP-defined topics), 2) knowledge generation
(e.g., generating research ideas corresponding to patients issues), 3)
self-reflection and correction (e.g., ensuring and revising the research ideas
after searching for scientific articles), and 4) self-reassurance (e.g.,
confirming and finalizing the research ideas). Six highly experienced breast
oncologists and dermatologists assessed the significance and novelty of
AI-generated research topics using a 5-point Likert scale (1-exceptional,
5-poor). One-third of the AI-suggested research topics were highly significant
and novel when both scores were lower than the average. Two-thirds of the
AI-suggested topics were novel in both cancers. Our findings demonstrate that
AI-generated research topics reflecting patient perspectives via a large volume
of patient messages can meaningfully guide future directions in
patient-centered health research.

ÊëòË¶ÅÔºö<paragraph>‰ª•ÊÇ£ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑÁ†îÁ©∂ÊâÄÂ∞çÊñºÁ∏ÆÂ∞èÁ†îÁ©∂ËàáÊÇ£ËÄÖÁÖßË≠∑‰πãÈñìÁöÑÂ∑ÆË∑ùË∂ä‰æÜË∂äÈáçË¶ÅÔºåÁÑ∂ËÄåÂ∞áÊÇ£ËÄÖËßÄÈªûÁ¥çÂÖ•ÂÅ•Â∫∑Á†îÁ©∂‰∏ÄÁõ¥‰∏ç‰∏ÄËá¥„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãËá™ÂãïÂåñÊû∂ÊßãÔºåÂà©Áî®ÂâµÊñ∞ÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) Âíå‰∫∫Â∑•Êô∫ÊÖß (AI) ËàáÊÇ£ËÄÖÂÖ•Âè£Á∂≤Á´ôË®äÊÅØÔºå‰ª•Áî¢ÁîüÁ†îÁ©∂ÊÉ≥Ê≥ïÔºåÂÑ™ÂÖàËÄÉÊÖÆÈáçË¶ÅÁöÑÊÇ£ËÄÖÂïèÈ°å„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÈáèÂåñ‰∫Ü AI ÁîüÊàêÁöÑÁ†îÁ©∂‰∏ªÈ°åÁöÑÂìÅË≥™„ÄÇÁÇ∫‰∫ÜÂÆöÁæ©ÊÇ£ËÄÖÁöÑËá®Â∫äÂïèÈ°åÔºåÊàëÂÄëÂàÜÊûê‰∫ÜÂæû‰∏ÄÂÄãÂ§ßÂûãÊïôÂ≠∏ÈÜ´Èô¢ (2013 Âπ¥Ëá≥ 2024 Âπ¥) ÂèñÂæóÁöÑ 25,549 ‰Ωç‰π≥ÁôåÊàñÁöÆËÜöÁôåÊÇ£ËÄÖÁöÑ 614,464 ÂâáÊÇ£ËÄÖË®äÊÅØÔºåÂª∫Êßã‰∫Ü‰∏ÄÂÄãÂÖ©ÈöéÊÆµÁÑ°Áõ£Áù£ÁöÑ NLP ‰∏ªÈ°åÊ®°Âûã„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄë‰ΩøÁî®Âª£Ê≥õ‰ΩøÁî®ÁöÑ AI (ChatGPT-4oÔºåOpenAI IncÔºå2024 Âπ¥ 4 ÊúàÁâàÊú¨) ÂíåÊèêÁ§∫Â∑•Á®ãÁ≠ñÁï•ÔºåÁî¢ÁîüÁ†îÁ©∂‰∏ªÈ°å‰ª•Ëß£Ê±∫ÂÆöÁæ©ÁöÑÂïèÈ°å„ÄÇÊàëÂÄëÂºïÂ∞é AI Âü∑Ë°åÂ§öÂ±§Á¥ö‰ªªÂãôÔºö1) Áü•Ë≠òË©ÆÈáãËàáÊëòË¶Å (‰æãÂ¶ÇÔºåË©ÆÈáãÂíåÊëòË¶Å NLP ÂÆöÁæ©ÁöÑ‰∏ªÈ°å)Ôºå2) Áü•Ë≠òÁî¢Áîü (‰æãÂ¶ÇÔºåÁî¢ÁîüËàáÊÇ£ËÄÖÂïèÈ°åÁõ∏ÊáâÁöÑÁ†îÁ©∂ÊÉ≥Ê≥ï)Ôºå3) Ëá™ÊàëÂèçÁúÅÂíå‰øÆÊ≠£ (‰æãÂ¶ÇÔºåÂú®ÊêúÂ∞ãÁßëÂ≠∏ÊñáÁ´†ÂæåÁ¢∫‰øùÂíå‰øÆÊîπÁ†îÁ©∂ÊÉ≥Ê≥ï)Ôºå‰ª•Âèä 4) Ëá™Êàë‰øùË≠â (‰æãÂ¶ÇÔºåÁ¢∫Ë™çÂíåÊúÄÂæåÁ¢∫ÂÆöÁ†îÁ©∂ÊÉ≥Ê≥ï)„ÄÇÂÖ≠‰ΩçÁ∂ìÈ©óË±êÂØåÁöÑ‰π≥ÁôåËÖ´Áò§ÁßëÈÜ´Â∏´ÂíåÁöÆËÜöÁßëÈÜ´Â∏´‰ΩøÁî® 5 ÈªûÊùéÂÖãÁâπÈáèË°® (1-ÂÇëÂá∫Ôºå5-Â∑Æ) Ë©ï‰º∞ AI ÁîüÊàêÁöÑÁ†îÁ©∂‰∏ªÈ°åÁöÑÈáçË¶ÅÊÄßÂíåÊñ∞Á©éÊÄß„ÄÇÁï∂ÂÖ©ÂÄãÂàÜÊï∏ÈÉΩ‰ΩéÊñºÂπ≥ÂùáÂÄºÊôÇÔºå‰∏âÂàÜ‰πã‰∏ÄÁöÑ AI Âª∫Ë≠∞Á†îÁ©∂‰∏ªÈ°åÈùûÂ∏∏ÈáçË¶Å‰∏îÊñ∞Á©é„ÄÇ‰∏âÂàÜ‰πã‰∫åÁöÑ AI Âª∫Ë≠∞‰∏ªÈ°åÂú®ÂÖ©Á®ÆÁôåÁóá‰∏≠ÈÉΩÊòØÊñ∞Á©éÁöÑ„ÄÇÊàëÂÄëÁöÑÁôºÁèæË≠âÊòé‰∫ÜÈÄèÈÅéÂ§ßÈáèÊÇ£ËÄÖË®äÊÅØÂèçÊò†ÊÇ£ËÄÖËßÄÈªûÁöÑ AI ÁîüÊàêÁöÑÁ†îÁ©∂‰∏ªÈ°åÔºåÂèØ‰ª•ÊúâÊÑèÁæ©Âú∞ÂºïÂ∞é‰ª•ÊÇ£ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑÂÅ•Â∫∑Á†îÁ©∂ÁöÑÊú™‰æÜÊñπÂêë„ÄÇ</paragraph>

##### **Chain of Alignment: Integrating Public Will with Expert Intelligence for Language Model Alignment**
2411.10534v1 by Andrew Konya, Aviv Ovadya, Kevin Feng, Quan Ze Chen, Lisa Schirch, Colin Irwin, Amy X. Zhang

We introduce a method to measure the alignment between public will and
language model (LM) behavior that can be applied to fine-tuning, online
oversight, and pre-release safety checks. Our `chain of alignment' (CoA)
approach produces a rule based reward (RBR) by creating model behavior
$\textit{rules}$ aligned to normative $\textit{objectives}$ aligned to
$\textit{public will}$. This factoring enables a nonexpert public to directly
specify their will through the normative objectives, while expert intelligence
is used to figure out rules entailing model behavior that best achieves those
objectives. We validate our approach by applying it across three different
domains of LM prompts related to mental health. We demonstrate a public input
process built on collective dialogues and bridging-based ranking that reliably
produces normative objectives supported by at least $96\% \pm 2\%$ of the US
public. We then show that rules developed by mental health experts to achieve
those objectives enable a RBR that evaluates an LM response's alignment with
the objectives similarly to human experts (Pearson's $r=0.841$, $AUC=0.964$).
By measuring alignment with objectives that have near unanimous public support,
these CoA RBRs provide an approximate measure of alignment between LM behavior
and public will.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ï‰æÜË°°ÈáèÂÖ¨ÁúæÊÑèÈ°òËàáË™ûË®ÄÊ®°Âûã (LM) Ë°åÁÇ∫‰πãÈñìÁöÑ‰∏ÄËá¥ÊÄßÔºåÈÄôÁ®ÆÊñπÊ≥ïÂèØ‰ª•ÊáâÁî®ÊñºÂæÆË™ø„ÄÅÁ∑ö‰∏äÁõ£Áù£ÂíåÈ†êÁôº‰ΩàÂÆâÂÖ®Ê™¢Êü•„ÄÇÊàëÂÄëÁöÑ„Äå‰∏ÄËá¥ÊÄßÈèà„Äç(CoA) ÊñπÊ≥ïÈÄèÈÅéÂª∫Á´ãÊ®°ÂûãË°åÁÇ∫ $\textit{Ë¶èÂâá}$Ôºå‰ΩøÂÖ∂ËàáË¶èÁØÑÊÄß $\textit{ÁõÆÊ®ô}$ ‰øùÊåÅ‰∏ÄËá¥ÔºåÈÄ≤ËÄåËàá $\textit{ÂÖ¨ÁúæÊÑèÈ°ò}$ ‰øùÊåÅ‰∏ÄËá¥ÔºåÂæûËÄåÁî¢ÁîüÂü∫ÊñºË¶èÂâáÁöÑÁçéÂãµ (RBR)„ÄÇÈÄôÁ®ÆÂàÜËß£‰ΩøÈùûÂ∞àÂÆ∂ÂÖ¨ÁúæËÉΩÂ§†ÈÄèÈÅéË¶èÁØÑÊÄßÁõÆÊ®ôÁõ¥Êé•Ë°®ÈÅî‰ªñÂÄëÁöÑÊÑèÈ°òÔºåËÄåÂ∞àÂÆ∂Êô∫ÊÖßÂâáÁî®ÊñºÊâæÂá∫ËòäÂê´Ê®°ÂûãË°åÁÇ∫ÁöÑË¶èÂâáÔºåÈÄô‰∫õË¶èÂâáÊúÄËÉΩÂØ¶ÁèæÈÄô‰∫õÁõÆÊ®ô„ÄÇÊàëÂÄëÈÄèÈÅéÂ∞áÊñπÊ≥ïÊáâÁî®Âú®ËàáÂøÉÁêÜÂÅ•Â∫∑Áõ∏ÈóúÁöÑ LM ÊèêÁ§∫ÁöÑ‰∏âÂÄã‰∏çÂêåÈ†òÂüü‰æÜÈ©óË≠âÊàëÂÄëÁöÑÂÅöÊ≥ï„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰∏ÄÂÄãÂª∫Á´ãÂú®ÈõÜÈ´îÂ∞çË©±ÂíåÂü∫ÊñºÊ©ãÊé•ÁöÑÊéíÂêç‰∏äÁöÑÂÖ¨ÁúæÊÑèË¶ãËº∏ÂÖ•ÊµÅÁ®ãÔºåË©≤ÊµÅÁ®ãÂèØÈù†Âú∞Áî¢ÁîüËá≥Â∞ëÊúâ $96\% \pm 2\%$ ÁöÑÁæéÂúãÂÖ¨ÁúæÊîØÊåÅÁöÑË¶èÁØÑÊÄßÁõÆÊ®ô„ÄÇÁÑ∂ÂæåÊàëÂÄëÂ±ïÁ§∫Áî±ÂøÉÁêÜÂÅ•Â∫∑Â∞àÂÆ∂Âà∂ÂÆö‰ª•ÂØ¶ÁèæÈÄô‰∫õÁõÆÊ®ôÁöÑË¶èÂâáÔºå‰Ωø RBR ËÉΩÂ§†Ë©ï‰º∞ LM ÂõûÊáâËàáÁõÆÊ®ôÁöÑ‰∏ÄËá¥ÊÄßÔºåÂÖ∂ÊñπÂºèËàá‰∫∫È°ûÂ∞àÂÆ∂È°û‰ººÔºàPearson's $r=0.841$Ôºå$AUC=0.964$Ôºâ„ÄÇÈÄèÈÅéË°°ÈáèËàáÁç≤ÂæóËøë‰πé‰∏ÄËá¥ÂÖ¨ÁúæÊîØÊåÅÁöÑÁõÆÊ®ôÁöÑ‰∏ÄËá¥ÊÄßÔºåÈÄô‰∫õ CoA RBR Êèê‰æõ‰∫Ü LM Ë°åÁÇ∫ËàáÂÖ¨ÁúæÊÑèÈ°ò‰πãÈñì‰∏ÄËá¥ÊÄßÁöÑËøë‰ººË°°ÈáèÊ®ôÊ∫ñ„ÄÇ</paragraph>

##### **Deep Learning for Micro-Scale Crack Detection on Imbalanced Datasets Using Key Point Localization**
2411.10389v1 by Fatahlla Moreh, Yusuf Hasan, Bilal Zahid Hussain, Mohammad Ammar, Sven Tomforde

Internal crack detection has been a subject of focus in structural health
monitoring. By focusing on crack detection in structural datasets, it is
demonstrated that deep learning (DL) methods can effectively analyze seismic
wave fields interacting with micro-scale cracks, which are beyond the
resolution of conventional visual inspection. This work explores a novel
application of DL-based key point detection technique, where cracks are
localized by predicting the coordinates of four key points that define a
bounding region of the crack. The study not only opens new research directions
for non-visual applications but also effectively mitigates the impact of
imbalanced data which poses a challenge for previous DL models, as it can be
biased toward predicting the majority class (non-crack regions). Popular DL
techniques, such as the Inception blocks, are used and investigated. The model
shows an overall reduction in loss when applied to micro-scale crack detection
and is reflected in the lower average deviation between the location of actual
and predicted cracks, with an average Intersection over Union (IoU) being 0.511
for all micro cracks (greater than 0.00 micrometers) and 0.631 for larger micro
cracks (greater than 4 micrometers).

ÊëòË¶ÅÔºöÂÖßÈÉ®Ë£ÇÁ∏´ÂÅµÊ∏¨‰∏ÄÁõ¥ÊòØÁµêÊßãÂÅ•Â∫∑Áõ£Ê∏¨ÁöÑÈáçÈªû„ÄÇÈÄèÈÅéÂ∞àÊ≥®ÊñºÁµêÊßãË≥áÊñôÈõÜ‰∏≠ÁöÑË£ÇÁ∏´ÂÅµÊ∏¨ÔºåË≠âÊòéÊ∑±Â∫¶Â≠∏Áøí (DL) ÊñπÊ≥ïÂèØ‰ª•ÊúâÊïàÂàÜÊûêËàáÂæÆÂ∞∫Â∫¶Ë£ÇÁ∏´‰∫§‰∫í‰ΩúÁî®ÁöÑÂú∞ÈúáÊ≥¢Â†¥ÔºåÈÄôË∂ÖÂá∫‰∫ÜÂÇ≥Áµ±ÁõÆË¶ñÊ™¢Êü•ÁöÑËß£ÊûêÂ∫¶„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊé¢Á¥¢‰∫ÜÂü∫Êñº DL ÁöÑÈóúÈçµÈªûÂÅµÊ∏¨ÊäÄË°ìÁöÑ‰∏ÄÈ†ÖÊñ∞ÊáâÁî®ÔºåÂÖ∂‰∏≠ÈÄèÈÅéÈ†êÊ∏¨ÂÆöÁæ©Ë£ÇÁ∏´ÈÇäÁïåÂçÄÂüüÁöÑÂõõÂÄãÈóúÈçµÈªûÁöÑÂ∫ßÊ®ô‰æÜÂÆö‰ΩçË£ÇÁ∏´„ÄÇÈÄôÈ†ÖÁ†îÁ©∂‰∏çÂÉÖÁÇ∫ÈùûË¶ñË¶∫ÊáâÁî®ÈñãÂïü‰∫ÜÊñ∞ÁöÑÁ†îÁ©∂ÊñπÂêëÔºåÈÇÑËÉΩÊúâÊïàÊ∏õËºï‰∏çÂπ≥Ë°°Ë≥áÊñôÁöÑÂΩ±ÈüøÔºåËÄåÈÄôÂ∞çÂÖàÂâçÁöÑ DL Ê®°ÂûãÊßãÊàêÊåëÊà∞ÔºåÂõ†ÁÇ∫ÂÆÉÂèØËÉΩÂÅèÂêëÊñºÈ†êÊ∏¨Â§öÊï∏È°ûÂà•ÔºàÈùûË£ÇÁ∏´ÂçÄÂüüÔºâ„ÄÇ‰ΩøÁî®‰∏¶Á†îÁ©∂‰∫ÜÊµÅË°åÁöÑ DL ÊäÄË°ìÔºå‰æãÂ¶Ç Inception ÂçÄÂ°ä„ÄÇË©≤Ê®°ÂûãÂú®ÊáâÁî®ÊñºÂæÆÂ∞∫Â∫¶Ë£ÇÁ∏´ÂÅµÊ∏¨ÊôÇÈ°ØÁ§∫Âá∫Êï¥È´îÊêçÂ§±Ê∏õÂ∞ëÔºå‰∏¶‰∏îÂèçÊò†Âú®ÂØ¶ÈöõË£ÇÁ∏´ÂíåÈ†êÊ∏¨Ë£ÇÁ∏´ÁöÑ‰ΩçÁΩÆ‰πãÈñìÁöÑËºÉ‰ΩéÂπ≥ÂùáÂÅèÂ∑Æ‰∏≠ÔºåÊâÄÊúâÂæÆË£ÇÁ∏´ÔºàÂ§ßÊñº 0.00 ÂæÆÁ±≥ÔºâÁöÑÂπ≥Âùá‰∫§ÈõÜÊØîËÅØÂêàÔºàIoUÔºâÁÇ∫ 0.511ÔºåËÄåËºÉÂ§ßÁöÑÂæÆË£ÇÁ∏´ÔºàÂ§ßÊñº 4 ÂæÆÁ±≥ÔºâÂâáÁÇ∫ 0.631„ÄÇ

##### **Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**
2411.10255v1 by Mohammed Yaseen Jabarulla, Theodor Uden, Thomas Jack, Philipp Beerbaum, Steffen Oeltze-Jafra

Pediatric heart diseases present a broad spectrum of congenital and acquired
diseases. More complex congenital malformations require a differentiated and
multimodal decision-making process, usually including echocardiography as a
central imaging method. Artificial intelligence (AI) offers considerable
promise for clinicians by facilitating automated interpretation of pediatric
echocardiography data. However, adapting AI technologies for pediatric
echocardiography analysis has challenges such as limited public data
availability, data privacy, and AI model transparency. Recently, researchers
have focused on disruptive technologies, such as federated learning (FL) and
explainable AI (XAI), to improve automatic diagnostic and decision support
workflows. This study offers a comprehensive overview of the limitations and
opportunities of AI in pediatric echocardiography, emphasizing the synergistic
workflow and role of XAI and FL, identifying research gaps, and exploring
potential future developments. Additionally, three relevant clinical use cases
demonstrate the functionality of XAI and FL with a focus on (i) view
recognition, (ii) disease classification, (iii) segmentation of cardiac
structures, and (iv) quantitative assessment of cardiac function.

ÊëòË¶ÅÔºöÂ∞èÂÖíÂøÉËáüÁñæÁóÖÂëàÁèæÂÖàÂ§©ÊÄßËàáÂæåÂ§©ÊÄßÁñæÁóÖÁöÑÂª£Ê≥õÂÖâË≠ú„ÄÇËºÉË§áÈõúÁöÑÂÖàÂ§©ÊÄßÁï∏ÂΩ¢ÈúÄË¶Å‰∏ÄÂÄãÂ∑ÆÁï∞Âåñ‰∏îÂ§öÊ®°ÂºèÁöÑÊ±∫Á≠ñÈÅéÁ®ãÔºåÈÄöÂ∏∏ÂåÖÊã¨Ë∂ÖÈü≥Ê≥¢Ê™¢Êü•‰ΩúÁÇ∫‰∏ªË¶ÅÁöÑÂΩ±ÂÉèÊñπÊ≥ï„ÄÇ‰∫∫Â∑•Êô∫ÊÖß (AI) ÁÇ∫Ëá®Â∫äÈÜ´ÁîüÊèê‰æõ‰∫ÜÁõ∏Áï∂Â§ßÁöÑÂ∏åÊúõÔºåÂõ†ÁÇ∫ÂÆÉÂèØ‰ª•‰øÉÈÄ≤Â∞èÂÖíË∂ÖÈü≥Ê≥¢Ê™¢Êü•Ë≥áÊñôÁöÑËá™ÂãïÂåñËß£ËÆÄ„ÄÇÁÑ∂ËÄåÔºåÂ∞á‰∫∫Â∑•Êô∫ÊÖßÊäÄË°ìÊáâÁî®ÊñºÂ∞èÂÖíË∂ÖÈü≥Ê≥¢Ê™¢Êü•ÂàÜÊûêÊúâË®±Â§öÊåëÊà∞Ôºå‰æãÂ¶ÇÊúâÈôêÁöÑÂÖ¨ÈñãË≥áÊñôÂèØÁî®ÊÄß„ÄÅË≥áÊñôÈö±ÁßÅÂíå‰∫∫Â∑•Êô∫ÊÖßÊ®°ÂûãÈÄèÊòéÂ∫¶„ÄÇÊúÄËøëÔºåÁ†îÁ©∂‰∫∫Âì°Â∞àÊ≥®ÊñºÁ†¥Â£ûÊÄßÊäÄË°ìÔºå‰æãÂ¶ÇËÅØÂêàÂ≠∏Áøí (FL) ÂíåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI)Ôºå‰ª•ÊîπÂñÑËá™ÂãïË®∫Êñ∑ÂíåÊ±∫Á≠ñÊîØÊè¥Â∑•‰ΩúÊµÅÁ®ã„ÄÇÊú¨Á†îÁ©∂Êèê‰æõ‰∫Ü‰∫∫Â∑•Êô∫ÊÖßÂú®Â∞èÂÖíË∂ÖÈü≥Ê≥¢Ê™¢Êü•‰∏≠ÁöÑÈôêÂà∂ÂíåÊ©üÊúÉÁöÑÂÖ®Èù¢Ê¶ÇËø∞ÔºåÂº∑Ë™ø‰∫Ü XAI Âíå FL ÁöÑÂçîÂêåÂ∑•‰ΩúÊµÅÁ®ãÂíåËßíËâ≤ÔºåÊâæÂá∫Á†îÁ©∂Â∑ÆË∑ù‰∏¶Êé¢Ë®éÊΩõÂú®ÁöÑÊú™‰æÜÁôºÂ±ï„ÄÇÊ≠§Â§ñÔºå‰∏âÂÄãÁõ∏ÈóúÁöÑËá®Â∫ä‰ΩøÁî®Ê°à‰æãÂ±ïÁ§∫‰∫Ü XAI Âíå FL ÁöÑÂäüËÉΩÔºåÈáçÈªûÂú®Êñº (i) Ê™¢Ë¶ñËæ®Ë≠ò„ÄÅ(ii) ÁñæÁóÖÂàÜÈ°û„ÄÅ(iii) ÂøÉËáüÁµêÊßãÂàÜÂâ≤Âíå (iv) ÂøÉËáüÂäüËÉΩÁöÑÈáèÂåñË©ï‰º∞„ÄÇ

##### **FedCL-Ensemble Learning: A Framework of Federated Continual Learning with Ensemble Transfer Learning Enhanced for Alzheimer's MRI Classifications while Preserving Privacy**
2411.12756v1 by Rishit Kapoor, Jesher Joshua, Muralidharan Vijayarangan, Natarajan B

This research work introduces a novel approach to the classification of
Alzheimer's disease by using the advanced deep learning techniques combined
with secure data processing methods. This research work primary uses transfer
learning models such as ResNet, ImageNet, and VNet to extract high-level
features from medical image data. Thereafter, these pre-trained models were
fine-tuned for Alzheimer's related subtle patterns such that the model is
capable of robust feature extraction over varying data sources. Further, the
federated learning approaches were incorporated to tackle a few other
challenges related to classification, aimed to provide better prediction
performance and protect data privacy. The proposed model was built using
federated learning without sharing sensitive patient data. This way, the
decentralized model benefits from the large and diversified dataset that it is
trained upon while ensuring confidentiality. The cipher-based encryption
mechanism is added that allows us to secure the transportation of data and
further ensure the privacy and integrity of patient information throughout
training and classification. The results of the experiments not only help to
improve the accuracy of the classification of Alzheimer's but at the same time
provides a framework for secure and collaborative analysis of health care data.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Â∑•‰ΩúÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÈòøËå≤Êµ∑ÈªòÁóáÂàÜÈ°ûÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÁµêÂêà‰∫ÜÂÖàÈÄ≤ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊäÄË°ìÂíåÂÆâÂÖ®ÁöÑÊï∏ÊìöËôïÁêÜÊñπÊ≥ï„ÄÇÊú¨Á†îÁ©∂Â∑•‰Ωú‰∏ªË¶Å‰ΩøÁî® ResNet„ÄÅImageNet Âíå VNet Á≠âÈÅ∑ÁßªÂ≠∏ÁøíÊ®°ÂûãÂæûÈÜ´Â≠∏ÂΩ±ÂÉèÊï∏Êìö‰∏≠ÊèêÂèñÈ´òÁ¥öÁâπÂæµ„ÄÇÈö®ÂæåÔºåÈÄô‰∫õÈ†êË®ìÁ∑¥Ê®°ÂûãÈáùÂ∞çÈòøËå≤Êµ∑ÈªòÁóáÁõ∏ÈóúÁöÑÁ¥∞ÂæÆÊ®°ÂºèÈÄ≤Ë°åÂæÆË™øÔºå‰ΩøÊ®°ÂûãËÉΩÂ§†Â∞ç‰∏çÂêåÊï∏ÊìöÊ∫ê‰∏≠ÁöÑÁâπÂæµÈÄ≤Ë°åÁ©©ÂÅ•ÊèêÂèñ„ÄÇÊ≠§Â§ñÔºåËÅØÈÇ¶Â≠∏ÁøíÊñπÊ≥ïË¢´Á¥çÂÖ•‰ª•ÊáâÂ∞çËàáÂàÜÈ°ûÁõ∏ÈóúÁöÑÂπæÂÄãÂÖ∂‰ªñÊåëÊà∞ÔºåÊó®Âú®Êèê‰æõÊõ¥Â•ΩÁöÑÈ†êÊ∏¨ÊÄßËÉΩÂíå‰øùË≠∑Êï∏ÊìöÈö±ÁßÅ„ÄÇÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÊòØ‰ΩøÁî®ËÅØÈÇ¶Â≠∏ÁøíÊßãÂª∫ÁöÑÔºåËÄåÁÑ°ÈúÄÂÖ±‰∫´ÊïèÊÑüÁöÑÊÇ£ËÄÖÊï∏Êìö„ÄÇÈÄôÊ®£ÔºåÂàÜÊï£ÂºèÊ®°ÂûãÂèØ‰ª•ÂæûÂÖ∂Ë®ìÁ∑¥ÁöÑÂ§ßÂûã‰∏îÂ§öÊ®£ÂåñÁöÑÊï∏ÊìöÈõÜ‰∏≠ÂèóÁõäÔºåÂêåÊôÇÁ¢∫‰øùÊ©üÂØÜÊÄß„ÄÇÊ∑ªÂä†‰∫ÜÂü∫ÊñºÂØÜÁ¢ºÁöÑÂä†ÂØÜÊ©üÂà∂ÔºåÂÆÉ‰ΩøÊàëÂÄëËÉΩÂ§†Á¢∫‰øùÊï∏ÊìöÂÇ≥Ëº∏ÁöÑÂÆâÂÖ®ÊÄßÔºå‰∏¶ÈÄ≤‰∏ÄÊ≠•Á¢∫‰øùÊÇ£ËÄÖ‰ø°ÊÅØÂú®Êï¥ÂÄãË®ìÁ∑¥ÂíåÂàÜÈ°ûÈÅéÁ®ã‰∏≠ÁöÑÈö±ÁßÅÂíåÂÆåÊï¥ÊÄß„ÄÇÂØ¶È©óÁµêÊûú‰∏çÂÉÖÊúâÂä©ÊñºÊèêÈ´òÈòøËå≤Êµ∑ÈªòÁóáÂàÜÈ°ûÁöÑÊ∫ñÁ¢∫ÊÄßÔºåÂêåÊôÇÈÇÑÁÇ∫ÈÜ´ÁôÇ‰øùÂÅ•Êï∏ÊìöÁöÑÂÆâÂÖ®ÂíåÂçî‰ΩúÂàÜÊûêÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊ°ÜÊû∂„ÄÇ

##### **Evaluating the role of `Constitutions' for learning from AI feedback**
2411.10168v1 by Saskia Redgate, Andrew M. Bean, Adam Mahdi

The growing capabilities of large language models (LLMs) have led to their
use as substitutes for human feedback for training and assessing other LLMs.
These methods often rely on `constitutions', written guidelines which a critic
model uses to provide feedback and improve generations. We investigate how the
choice of constitution affects feedback quality by using four different
constitutions to improve patient-centered communication in medical interviews.
In pairwise comparisons conducted by 215 human raters, we found that detailed
constitutions led to better results regarding emotive qualities. However, none
of the constitutions outperformed the baseline in learning more
practically-oriented skills related to information gathering and provision. Our
findings indicate that while detailed constitutions should be prioritised,
there are possible limitations to the effectiveness of AI feedback as a reward
signal in certain areas.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂäüËÉΩ‰∏çÊñ∑Â¢ûÂº∑Ôºå‰øÉ‰ΩøÂÆÉÂÄëË¢´Áî®‰Ωú‰∫∫È°ûÂõûÈ•ãÁöÑÊõø‰ª£ÂìÅÔºå‰ª•Ë®ìÁ∑¥ÂíåË©ï‰º∞ÂÖ∂‰ªñ LLM„ÄÇÈÄô‰∫õÊñπÊ≥ïÈÄöÂ∏∏‰æùË≥¥Êñº„ÄåÊÜ≤Ê≥ï„ÄçÔºå‰πüÂ∞±ÊòØË©ïË´ñÊ®°ÂûãÁî®‰æÜÊèê‰æõÂõûÈ•ãÂíåÊîπÈÄ≤ÁîüÊàêÁöÑÊõ∏Èù¢Ê∫ñÂâá„ÄÇÊàëÂÄëÊé¢Ë®éÊÜ≤Ê≥ïÈÅ∏ÊìáÂ¶Ç‰ΩïÂΩ±ÈüøÂõûÈ•ãÂìÅË≥™ÔºåÊñπÊ≥ïÊòØ‰ΩøÁî®ÂõõÁ®Æ‰∏çÂêåÁöÑÊÜ≤Ê≥ï‰æÜÊîπÂñÑÈÜ´ÁôÇË®™Ë´á‰∏≠ÁöÑ‰ª•ÊÇ£ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑÊ∫ùÈÄö„ÄÇÂú® 215 ‰Ωç‰∫∫È°ûË©ïÂàÜÂì°ÈÄ≤Ë°åÁöÑÊàêÂ∞çÊØîËºÉ‰∏≠ÔºåÊàëÂÄëÁôºÁèæË©≥Á¥∞ÁöÑÊÜ≤Ê≥ïÂú®ÊÉÖÁ∑íÂìÅË≥™ÊñπÈù¢Â∏∂‰æÜÊõ¥Â•ΩÁöÑÁµêÊûú„ÄÇÁÑ∂ËÄåÔºåÊ≤íÊúâ‰ªª‰ΩïÊÜ≤Ê≥ïÂú®Â≠∏ÁøíËàáË≥áË®äÊî∂ÈõÜÂíåÊèê‰æõÁõ∏ÈóúÁöÑÊõ¥ÂØ¶Áî®ÊäÄËÉΩÊñπÈù¢ÂÑ™ÊñºÂü∫Ê∫ñ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÈõñÁÑ∂ÊáâÂÑ™ÂÖàËÄÉÊÖÆË©≥Á¥∞ÁöÑÊÜ≤Ê≥ïÔºå‰ΩÜ AI ÂõûÈ•ã‰ΩúÁÇ∫ÁâπÂÆöÈ†òÂüüÁöÑÁçéÂãµË®äËôüÁöÑÊúâÊïàÊÄßÂèØËÉΩÊúâÈôê„ÄÇ

##### **PFML: Self-Supervised Learning of Time-Series Data Without Representation Collapse**
2411.10087v1 by Einari Vaaras, Manu Airaksinen, Okko R√§s√§nen

Self-supervised learning (SSL) is a data-driven learning approach that
utilizes the innate structure of the data to guide the learning process. In
contrast to supervised learning, which depends on external labels, SSL utilizes
the inherent characteristics of the data to produce its own supervisory signal.
However, one frequent issue with SSL methods is representation collapse, where
the model outputs a constant input-invariant feature representation. This issue
hinders the potential application of SSL methods to new data modalities, as
trying to avoid representation collapse wastes researchers' time and effort.
This paper introduces a novel SSL algorithm for time-series data called
Prediction of Functionals from Masked Latents (PFML). Instead of predicting
masked input signals or their latent representations directly, PFML operates by
predicting statistical functionals of the input signal corresponding to masked
embeddings, given a sequence of unmasked embeddings. The algorithm is designed
to avoid representation collapse, rendering it straightforwardly applicable to
different time-series data domains, such as novel sensor modalities in clinical
data. We demonstrate the effectiveness of PFML through complex, real-life
classification tasks across three different data modalities: infant posture and
movement classification from multi-sensor inertial measurement unit data,
emotion recognition from speech data, and sleep stage classification from EEG
data. The results show that PFML is superior to a conceptually similar
pre-existing SSL method and competitive against the current state-of-the-art
SSL method, while also being conceptually simpler and without suffering from
representation collapse.

ÊëòË¶ÅÔºöËá™ÁõëÁù£Â≠¶‰π† (SSL) ÊòØ‰∏ÄÁßçÊï∞ÊçÆÈ©±Âä®ÁöÑÂ≠¶‰π†ÊñπÊ≥ïÔºåÂÆÉÂà©Áî®Êï∞ÊçÆÁöÑÂÜÖÂú®ÁªìÊûÑÊù•ÊåáÂØºÂ≠¶‰π†ËøáÁ®ã„ÄÇ‰∏é‰æùËµñÂ§ñÈÉ®Ê†áÁ≠æÁöÑÁõëÁù£Â≠¶‰π†Áõ∏ÂèçÔºåSSL Âà©Áî®Êï∞ÊçÆÊú¨Ë∫´ÁöÑÂõ∫ÊúâÁâπÂæÅÊù•‰∫ßÁîüËá™Â∑±ÁöÑÁõëÁù£‰ø°Âè∑„ÄÇÁÑ∂ËÄåÔºåSSL ÊñπÊ≥ïÁöÑ‰∏Ä‰∏™Â∏∏ËßÅÈóÆÈ¢òÊòØË°®Á§∫ÂùçÂ°åÔºåÂÖ∂‰∏≠Ê®°ÂûãËæìÂá∫‰∏Ä‰∏™Â∏∏Êï∞ËæìÂÖ•‰∏çÂèòÁâπÂæÅË°®Á§∫„ÄÇËøô‰∏™ÈóÆÈ¢òÈòªÁ¢ç‰∫Ü SSL ÊñπÊ≥ïÂú®Êñ∞ÁöÑÊï∞ÊçÆÊ®°Âºè‰∏≠ÁöÑÊΩúÂú®Â∫îÁî®ÔºåÂõ†‰∏∫ËØïÂõæÈÅøÂÖçË°®Á§∫ÂùçÂ°å‰ºöÊµ™Ë¥πÁ†îÁ©∂‰∫∫ÂëòÁöÑÊó∂Èó¥ÂíåÁ≤æÂäõ„ÄÇÊú¨Êñá‰ªãÁªç‰∫Ü‰∏ÄÁßçÈíàÂØπÊó∂Èó¥Â∫èÂàóÊï∞ÊçÆÁöÑÊñ∞Âûã SSL ÁÆóÊ≥ïÔºåÁß∞‰∏∫Êé©Á†ÅÊΩúÂú®ÂèòÈáèÁöÑÂäüËÉΩÈ¢ÑÊµã (PFML)„ÄÇPFML ‰∏çÊòØÁõ¥Êé•È¢ÑÊµãÊé©Á†ÅËæìÂÖ•‰ø°Âè∑ÊàñÂÖ∂ÊΩúÂú®Ë°®Á§∫ÔºåËÄåÊòØÈÄöËøáÈ¢ÑÊµãËæìÂÖ•‰ø°Âè∑ÁöÑÁªüËÆ°ÂáΩÊï∞ÔºàÂØπÂ∫î‰∫éÊé©Á†ÅÂµåÂÖ•ÔºâÊù•Êìç‰ΩúÔºåÁªôÂÆö‰∏ÄÁ≥ªÂàóÊú™Êé©Á†ÅÂµåÂÖ•„ÄÇËØ•ÁÆóÊ≥ïÊó®Âú®ÈÅøÂÖçË°®Á§∫ÂùçÂ°åÔºå‰ΩøÂÖ∂ÂèØ‰ª•Áõ¥Êé•Â∫îÁî®‰∫é‰∏çÂêåÁöÑÊó∂Èó¥Â∫èÂàóÊï∞ÊçÆÂüüÔºå‰æãÂ¶Ç‰∏¥Â∫äÊï∞ÊçÆ‰∏≠ÁöÑÊñ∞Âûã‰º†ÊÑüÂô®Ê®°Âºè„ÄÇÊàë‰ª¨ÈÄöËøá‰∏â‰∏™‰∏çÂêåÊï∞ÊçÆÊ®°ÂºèÁöÑÂ§çÊùÇÁé∞ÂÆûÁîüÊ¥ªÂàÜÁ±ª‰ªªÂä°Â±ïÁ§∫‰∫Ü PFML ÁöÑÊúâÊïàÊÄßÔºöÂ§ö‰º†ÊÑüÂô®ÊÉØÊÄßÊµãÈáèÂçïÂÖÉÊï∞ÊçÆÁöÑÂ©¥ÂÑøÂßøÂäøÂíåËøêÂä®ÂàÜÁ±ª„ÄÅËØ≠Èü≥Êï∞ÊçÆÁöÑËØ≠Èü≥ËØÜÂà´‰ª•ÂèäËÑëÁîµÂõæÊï∞ÊçÆÁöÑÁù°Áú†Èò∂ÊÆµÂàÜÁ±ª„ÄÇÁªìÊûúË°®ÊòéÔºåPFML ‰ºò‰∫éÊ¶ÇÂøµ‰∏äÁõ∏‰ººÁöÑÁé∞Êúâ SSL ÊñπÊ≥ïÔºåÂπ∂‰∏î‰∏éÂΩìÂâçÊúÄÂÖàËøõÁöÑ SSL ÊñπÊ≥ïÂÖ∑ÊúâÁ´û‰∫âÂäõÔºåÂêåÊó∂Âú®Ê¶ÇÂøµ‰∏äÊõ¥ÁÆÄÂçïÔºåÂπ∂‰∏î‰∏ç‰ºöÂá∫Áé∞Ë°®Á§∫ÂùçÂ°å„ÄÇ

##### **Rethinking Normalization Strategies and Convolutional Kernels for Multimodal Image Fusion**
2411.10036v1 by Dan He, Guofen Wang, Weisheng Li, Yucheng Shu, Wenbo Li, Lijian Yang, Yuping Huang, Feiyan Li

Multimodal image fusion (MMIF) aims to integrate information from different
modalities to obtain a comprehensive image, aiding downstream tasks. However,
existing methods tend to prioritize natural image fusion and focus on
information complementary and network training strategies. They ignore the
essential distinction between natural and medical image fusion and the
influence of underlying components. This paper dissects the significant
differences between the two tasks regarding fusion goals, statistical
properties, and data distribution. Based on this, we rethink the suitability of
the normalization strategy and convolutional kernels for end-to-end
MMIF.Specifically, this paper proposes a mixture of instance normalization and
group normalization to preserve sample independence and reinforce intrinsic
feature correlation.This strategy promotes the potential of enriching feature
maps, thus boosting fusion performance. To this end, we further introduce the
large kernel convolution, effectively expanding receptive fields and enhancing
the preservation of image detail. Moreover, the proposed multipath adaptive
fusion module recalibrates the decoder input with features of various scales
and receptive fields, ensuring the transmission of crucial information.
Extensive experiments demonstrate that our method exhibits state-of-the-art
performance in multiple fusion tasks and significantly improves downstream
applications. The code is available at https://github.com/HeDan-11/LKC-FUNet.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÖãÂΩ±ÂÉèËûçÂêà (MMIF) Êó®Âú®Êï¥Âêà‰æÜËá™‰∏çÂêåÊ®°ÊÖãÁöÑË≥áË®äÔºå‰ª•ÂèñÂæóÂÖ®Èù¢ÁöÑÂΩ±ÂÉèÔºåÂçîÂä©‰∏ãÊ∏∏‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÊñπÊ≥ïÂÇæÂêëÊñºÂÑ™ÂÖàËÄÉÊÖÆËá™ÁÑ∂ÂΩ±ÂÉèËûçÂêàÔºå‰∏¶Â∞àÊ≥®ÊñºË≥áË®ä‰∫íË£úÂíåÁ∂≤Ë∑ØË®ìÁ∑¥Á≠ñÁï•„ÄÇÂÆÉÂÄëÂøΩÁï•‰∫ÜËá™ÁÑ∂ÂΩ±ÂÉèËûçÂêàËàáÈÜ´Â≠∏ÂΩ±ÂÉèËûçÂêà‰πãÈñìÁöÑÊú¨Ë≥™ÂçÄÂà•Ôºå‰ª•ÂèäÂ∫ïÂ±§ÁµÑÊàêÁöÑÂΩ±Èüø„ÄÇÊú¨ÊñáÂâñÊûê‰∫ÜÈÄôÂÖ©ÂÄã‰ªªÂãôÂú®ËûçÂêàÁõÆÊ®ô„ÄÅÁµ±Ë®àÊÄßË≥™ÂíåË≥áÊñôÂàÜ‰ΩàÊñπÈù¢ÁöÑÈ°ØËëóÂ∑ÆÁï∞„ÄÇÂü∫ÊñºÊ≠§ÔºåÊàëÂÄëÈáçÊñ∞ÊÄùËÄÉÊ≠£Ë¶èÂåñÁ≠ñÁï•ÂíåÊç≤Á©çÊ†∏Â∞çÁ´ØÂà∞Á´Ø MMIF ÁöÑÈÅ©Áî®ÊÄß„ÄÇÂÖ∑È´îËÄåË®ÄÔºåÊú¨ÊñáÊèêÂá∫ÂØ¶‰æãÊ≠£Ë¶èÂåñÂíåÁæ§ÁµÑÊ≠£Ë¶èÂåñÁöÑÊ∑∑ÂêàÔºå‰ª•‰øùÁïôÊ®£Êú¨Áç®Á´ãÊÄß‰∏¶Âä†Âº∑ÂÖßÂú®ÁâπÂæµÈóúËÅØ„ÄÇÊ≠§Á≠ñÁï•ÊèêÂçá‰∫ÜË±êÂØåÁâπÂæµÂúñÁöÑÊΩõÂäõÔºåÂæûËÄåÊèêÂçáËûçÂêàÊïàËÉΩ„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÂºïÂÖ•‰∫ÜÂ§ßÊ†∏Âç∑Á©çÔºåÊúâÊïàÂú∞Êì¥Â±ïÊÑüÂèóÈáé‰∏¶Â¢ûÂº∑ÂΩ±ÂÉèÁ¥∞ÁØÄÁöÑ‰øùÁïô„ÄÇÊ≠§Â§ñÔºåÊèêÂá∫ÁöÑÂ§öË∑ØÂæëËá™ÈÅ©ÊáâËûçÂêàÊ®°ÁµÑÈáçÊñ∞Ê†°Ê∫ñËß£Á¢ºÂô®Ëº∏ÂÖ•ÔºåÂÖ∂ÁâπÂæµÂÖ∑Êúâ‰∏çÂêåÁöÑÊØî‰æãÂíåÊÑüÂèóÈáéÔºåÁ¢∫‰øùÈóúÈçµË≥áË®äÁöÑÂÇ≥Ëº∏„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú®Â§öÂÄãËûçÂêà‰ªªÂãô‰∏≠Â±ïÁèæÂá∫ÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºå‰∏¶È°ØËëóÊîπÂñÑ‰∏ãÊ∏∏ÊáâÁî®„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/HeDan-11/LKC-FUNet ÂèñÂæó„ÄÇ

##### **JRadiEvo: A Japanese Radiology Report Generation Model Enhanced by Evolutionary Optimization of Model Merging**
2411.09933v1 by Kaito Baba, Ryota Yagi, Junichiro Takahashi, Risa Kishikawa, Satoshi Kodera

With the rapid advancement of large language models (LLMs), foundational
models (FMs) have seen significant advancements. Healthcare is one of the most
crucial application areas for these FMs, given the significant time and effort
required for physicians to analyze large volumes of patient data. Recent
efforts have focused on adapting multimodal FMs to the medical domain through
techniques like instruction-tuning, leading to the development of medical
foundation models (MFMs). However, these approaches typically require large
amounts of training data to effectively adapt models to the medical field.
Moreover, most existing models are trained on English datasets, limiting their
practicality in non-English-speaking regions where healthcare professionals and
patients are not always fluent in English. The need for translation introduces
additional costs and inefficiencies. To address these challenges, we propose a
\textbf{J}apanese \textbf{Radi}ology report generation model enhanced by
\textbf{Evo}lutionary optimization of model merging (JRadiEvo). This is the
first attempt to extend a non-medical vision-language foundation model to the
medical domain through evolutionary optimization of model merging. We
successfully created a model that generates accurate Japanese reports from
X-ray images using only 50 translated samples from publicly available data.
This model, developed with highly efficient use of limited data, outperformed
leading models from recent research trained on much larger datasets.
Additionally, with only 8 billion parameters, this relatively compact
foundation model can be deployed locally within hospitals, making it a
practical solution for environments where APIs and other external services
cannot be used due to strict privacy and security requirements.

ÊëòË¶ÅÔºö<paragraph>Èö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂø´ÈÄüÈÄ≤Â±ïÔºåÂü∫Á§éÊ®°Âûã (FM) Â∑≤Á∂ìÁç≤ÂæóÈ°ØËëóÁöÑÈÄ≤Ê≠•„ÄÇÈÜ´ÁôÇ‰øùÂÅ•ÊòØÈÄô‰∫õ FM ÊúÄÈáçË¶ÅÁöÑÊáâÁî®È†òÂüü‰πã‰∏ÄÔºåÂõ†ÁÇ∫ÈÜ´ÁîüÈúÄË¶ÅËä±Ë≤ªÂ§ßÈáèÊôÇÈñìÂíåÁ≤æÂäõ‰æÜÂàÜÊûêÂ§ßÈáèÁöÑÊÇ£ËÄÖË≥áÊñô„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂ÈáçÈªûÂú®ÊñºÈÄèÈÅéÊåá‰ª§ÂæÆË™øÁ≠âÊäÄË°ìÂ∞áÂ§öÊ®°ÊÖã FM ÈÅ©ÊáâÂà∞ÈÜ´ÁôÇÈ†òÂüüÔºåÂæûËÄåÈñãÁôºÂá∫ÈÜ´ÁôÇÂü∫Á§éÊ®°Âûã (MFM)„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÁöÑË®ìÁ∑¥Ë≥áÊñôÊâçËÉΩÊúâÊïàÂú∞Â∞áÊ®°ÂûãÈÅ©ÊáâÂà∞ÈÜ´ÁôÇÈ†òÂüü„ÄÇÊ≠§Â§ñÔºåÂ§ßÂ§öÊï∏ÁèæÊúâÊ®°ÂûãÈÉΩÊòØÈáùÂ∞çËã±Ë™ûË≥áÊñôÈõÜÈÄ≤Ë°åË®ìÁ∑¥ÔºåÈÄôÈôêÂà∂‰∫ÜÂÆÉÂÄëÂú®ÈùûËã±Ë™ûÂú∞ÂçÄÁöÑÂØ¶Áî®ÊÄßÔºåÈÇ£Ë£°ÁöÑÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°ÂíåÊÇ£ËÄÖ‰∏¶‰∏çÁ∏ΩÊòØÁ≤æÈÄöËã±Ë™û„ÄÇÁøªË≠ØÁöÑÈúÄÊ±ÇÂºïÂÖ•‰∫ÜÈ°çÂ§ñÁöÑÊàêÊú¨Âíå‰ΩéÊïàÁéá„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁî±Ê®°ÂûãÂêà‰ΩµÁöÑÈÄ≤ÂåñÂÑ™ÂåñÂ¢ûÂº∑ÁöÑ**J**apanese **Radi**ology Â†±ÂëäÁîüÊàêÊ®°Âûã (JRadiEvo)„ÄÇÈÄôÊòØÈ¶ñÊ¨°ÂòóË©¶ÈÄèÈÅéÊ®°ÂûãÂêà‰ΩµÁöÑÈÄ≤ÂåñÂÑ™ÂåñÂ∞áÈùûÈÜ´ÁôÇË¶ñË¶∫Ë™ûË®ÄÂü∫Á§éÊ®°ÂûãÊì¥Â±ïÂà∞ÈÜ´ÁôÇÈ†òÂüü„ÄÇÊàëÂÄëÊàêÂäüÂú∞Âª∫Á´ã‰∫Ü‰∏ÄÂÄãÊ®°ÂûãÔºåÂÉÖ‰ΩøÁî®‰æÜËá™ÂÖ¨ÈñãË≥áÊñôÁöÑ 50 ÂÄãÁøªË≠ØÁØÑ‰æãÔºåÂ∞±ËÉΩÂæû X ÂÖâÂΩ±ÂÉè‰∏≠Áî¢ÁîüÊ∫ñÁ¢∫ÁöÑÊó•ÊñáÂ†±Âëä„ÄÇÈÄôÂÄãÊ®°Âûã‰ΩøÁî®ÊúâÈôêË≥áÊñôÈÄ≤Ë°åÈ´òÊïàÁéáÁöÑÈñãÁôºÔºåÂÖ∂ÊïàËÉΩÂÑ™ÊñºÊúÄËøëÁ†îÁ©∂‰∏≠Âú®Êõ¥Â§ßË≥áÊñôÈõÜ‰∏äË®ìÁ∑¥Âá∫‰æÜÁöÑÈ†òÂÖàÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåÈÄôÂÄãÁõ∏Â∞çÁ≤æÁ∞°ÁöÑÂü∫Á§éÊ®°ÂûãÂè™Êúâ 80 ÂÑÑÂÄãÂèÉÊï∏ÔºåÂèØ‰ª•Âú®ÈÜ´Èô¢ÂÖßÈÉ®ÈÄ≤Ë°åÊú¨Âú∞ÈÉ®ÁΩ≤Ôºå‰ΩøÂÖ∂ÊàêÁÇ∫Âú®Âö¥Ê†ºÁöÑÈö±ÁßÅÂíåÂÆâÂÖ®Ë¶ÅÊ±Ç‰∏ãÁÑ°Ê≥ï‰ΩøÁî® API ÂíåÂÖ∂‰ªñÂ§ñÈÉ®ÊúçÂãôÁöÑÁí∞Â¢É‰∏≠ÁöÑÂØ¶Áî®Ëß£Ê±∫ÊñπÊ°à„ÄÇ</paragraph>

##### **A Hybrid Artificial Intelligence System for Automated EEG Background Analysis and Report Generation**
2411.09874v1 by Chin-Sung Tung, Sheng-Fu Liang, Shu-Feng Chang, Chung-Ping Young

Electroencephalography (EEG) plays a crucial role in the diagnosis of various
neurological disorders. However, small hospitals and clinics often lack
advanced EEG signal analysis systems and are prone to misinterpretation in
manual EEG reading. This study proposes an innovative hybrid artificial
intelligence (AI) system for automatic interpretation of EEG background
activity and report generation. The system combines deep learning models for
posterior dominant rhythm (PDR) prediction, unsupervised artifact removal, and
expert-designed algorithms for abnormality detection. For PDR prediction, 1530
labeled EEGs were used, and the best ensemble model achieved a mean absolute
error (MAE) of 0.237, a root mean square error (RMSE) of 0.359, an accuracy of
91.8% within a 0.6Hz error, and an accuracy of 99% within a 1.2Hz error. The AI
system significantly outperformed neurologists in detecting generalized
background slowing (p = 0.02; F1: AI 0.93, neurologists 0.82) and demonstrated
improved focal abnormality detection, although not statistically significant (p
= 0.79; F1: AI 0.71, neurologists 0.55). Validation on both an internal dataset
and the Temple University Abnormal EEG Corpus showed consistent performance
(F1: 0.884 and 0.835, respectively; p = 0.66), demonstrating generalizability.
The use of large language models (LLMs) for report generation demonstrated 100%
accuracy, verified by three other independent LLMs. This hybrid AI system
provides an easily scalable and accurate solution for EEG interpretation in
resource-limited settings, assisting neurologists in improving diagnostic
accuracy and reducing misdiagnosis rates.

ÊëòË¶ÅÔºöËÖ¶ÈõªÂúñÔºàEEGÔºâÂú®Ë®∫Êñ∑ÂêÑÁ®ÆÁ•ûÁ∂ìÁñæÁóÖ‰∏≠ÊâÆÊºîËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÁÑ∂ËÄåÔºåÂ∞èÂûãÈÜ´Èô¢ÂíåË®∫ÊâÄÈÄöÂ∏∏Áº∫‰πèÈÄ≤ÈöéÁöÑ EEG Ë®äËôüÂàÜÊûêÁ≥ªÁµ±Ôºå‰∏îÂÆπÊòìÂú®ÊâãÂãïÂà§ËÆÄ EEG ÊôÇÁî¢ÁîüË™§Ëß£„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊ∑∑Âêà‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÁ≥ªÁµ±ÔºåÁî®ÊñºËá™ÂãïÂà§ËÆÄ EEG ËÉåÊôØÊ¥ªÂãï‰∏¶Áî¢ÁîüÂ†±Âëä„ÄÇÊ≠§Á≥ªÁµ±ÁµêÂêàÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºåÁî®ÊñºÈ†êÊ∏¨ÂæåÂÑ™Âã¢ÂæãÂãïÔºàPDRÔºâ„ÄÅÈùûÁõ£Áù£‰∫∫Â∑•Ë£ΩÂìÅÁßªÈô§Ôºå‰ª•ÂèäÂ∞àÂÆ∂Ë®≠Ë®àÁöÑÁï∞Â∏∏ÂÅµÊ∏¨ÊºîÁÆóÊ≥ï„ÄÇÂú® PDR È†êÊ∏¨‰∏≠Ôºå‰ΩøÁî®‰∫Ü 1530 ÂÄãÊ®ôË®ò EEGÔºåÊúÄ‰Ω≥ÁöÑÊï¥È´îÊ®°ÂûãÈÅîÂà∞‰∫Ü 0.237 ÁöÑÂπ≥ÂùáÁµïÂ∞çË™§Â∑ÆÔºàMAEÔºâ„ÄÅ0.359 ÁöÑÂùáÊñπÊ†πË™§Â∑ÆÔºàRMSEÔºâ„ÄÅ91.8% ÁöÑ 0.6Hz Ë™§Â∑ÆÊ∫ñÁ¢∫Â∫¶Ôºå‰ª•Âèä 99% ÁöÑ 1.2Hz Ë™§Â∑ÆÊ∫ñÁ¢∫Â∫¶„ÄÇAI Á≥ªÁµ±Âú®ÂÅµÊ∏¨Âª£Ê≥õËÉåÊôØÊ∏õÊÖ¢ÊñπÈù¢ÊòéÈ°ØÂÑ™ÊñºÁ•ûÁ∂ìÂ≠∏ÂÆ∂Ôºàp = 0.02ÔºõF1ÔºöAI 0.93ÔºåÁ•ûÁ∂ìÂ≠∏ÂÆ∂ 0.82ÔºâÔºå‰∏¶Â±ïÁèæÂá∫ÊîπÂñÑÁöÑÂ±ÄÈÉ®Áï∞Â∏∏ÂÅµÊ∏¨ÔºåÂÑòÁÆ°Ê≤íÊúâÁµ±Ë®àÊÑèÁæ©Ôºàp = 0.79ÔºõF1ÔºöAI 0.71ÔºåÁ•ûÁ∂ìÂ≠∏ÂÆ∂ 0.55Ôºâ„ÄÇÂú®ÂÖßÈÉ®Ë≥áÊñôÈõÜÂíå Temple University Áï∞Â∏∏ EEG Ë™ûÊñôÂ∫´‰∏äÁöÑÈ©óË≠âÈ°ØÁ§∫‰∫Ü‰∏ÄËá¥ÁöÑÊïàËÉΩÔºàF1ÔºöÂàÜÂà•ÁÇ∫ 0.884 Âíå 0.835Ôºõp = 0.66ÔºâÔºåË≠âÊòé‰∫ÜÂÖ∂ÊôÆÈÅçÊÄß„ÄÇ‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâ‰æÜÁî¢ÁîüÂ†±ÂëäË≠âÊòé‰∫Ü 100% ÁöÑÊ∫ñÁ¢∫Â∫¶Ôºå‰∏¶Áî±ÂÖ∂‰ªñ‰∏âÂÄãÁç®Á´ãÁöÑ LLM È©óË≠â„ÄÇÊ≠§Ê∑∑Âêà AI Á≥ªÁµ±Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊòìÊñºÊì¥ÂÖÖ‰∏îÊ∫ñÁ¢∫ÁöÑËß£Ê±∫ÊñπÊ°àÔºåÁî®ÊñºÂú®Ë≥áÊ∫êÊúâÈôêÁöÑÁí∞Â¢É‰∏≠ÈÄ≤Ë°å EEG Âà§ËÆÄÔºåÂçîÂä©Á•ûÁ∂ìÂ≠∏ÂÆ∂ÊèêÈ´òË®∫Êñ∑Ê∫ñÁ¢∫Â∫¶‰∏¶Èôç‰ΩéË™§Ë®∫Áéá„ÄÇ

##### **A Benchmark for Long-Form Medical Question Answering**
2411.09834v2 by Pedram Hosseini, Jessica M. Sin, Bing Ren, Bryceton G. Thomas, Elnaz Nouri, Ali Farahanchi, Saeed Hassanpour

There is a lack of benchmarks for evaluating large language models (LLMs) in
long-form medical question answering (QA). Most existing medical QA evaluation
benchmarks focus on automatic metrics and multiple-choice questions. While
valuable, these benchmarks fail to fully capture or assess the complexities of
real-world clinical applications where LLMs are being deployed. Furthermore,
existing studies on evaluating long-form answer generation in medical QA are
primarily closed-source, lacking access to human medical expert annotations,
which makes it difficult to reproduce results and enhance existing baselines.
In this work, we introduce a new publicly available benchmark featuring
real-world consumer medical questions with long-form answer evaluations
annotated by medical doctors. We performed pairwise comparisons of responses
from various open and closed-source medical and general-purpose LLMs based on
criteria such as correctness, helpfulness, harmfulness, and bias. Additionally,
we performed a comprehensive LLM-as-a-judge analysis to study the alignment
between human judgments and LLMs. Our preliminary results highlight the strong
potential of open LLMs in medical QA compared to leading closed models. Code &
Data: https://github.com/lavita-ai/medical-eval-sphere

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Èï∑ÁØáÈÜ´ÁôÇÂïèÈ°åËß£Á≠î (QA) ‰∏≠ÁöÑË©ï‰º∞Âü∫Ê∫ñÊúâÊâÄ‰∏çË∂≥„ÄÇÁèæÊúâÁöÑÈÜ´ÁôÇ QA Ë©ï‰º∞Âü∫Ê∫ñÂ§ßÂ§öÈõÜ‰∏≠Âú®Ëá™ÂãïÂåñÊåáÊ®ôÂíåÂ§öÈÅ∏È°å‰∏ä„ÄÇÂÑòÁÆ°ÊúâÂÉπÂÄºÔºå‰ΩÜÈÄô‰∫õÂü∫Ê∫ñÁÑ°Ê≥ïÂÆåÂÖ®ÊçïÊçâÊàñË©ï‰º∞ LLM ÈÉ®ÁΩ≤ÁöÑÁèæÂØ¶Ëá®Â∫äÊáâÁî®ÁöÑË§áÈõúÊÄß„ÄÇÊ≠§Â§ñÔºåÁèæÊúâÁöÑÈóúÊñºË©ï‰º∞ÈÜ´ÁôÇ QA ‰∏≠Èï∑ÁØáÁ≠îÊ°àÁîüÊàêÁöÑÁ†îÁ©∂ÊâÄ‰∏ªË¶ÅÊòØÈñâÊ∫êÁöÑÔºåÁº∫‰πèÂ∞ç‰∫∫È°ûÈÜ´Â≠∏Â∞àÂÆ∂Ë®ªÈáãÁöÑË®™ÂïèÊ¨äÈôêÔºåÈÄô‰ΩøÂæóÈõ£‰ª•ÈáçÁèæÁµêÊûú‰∏¶Â¢ûÂº∑ÁèæÊúâÁöÑÂü∫Ê∫ñ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂÖ¨ÈñãÂü∫Ê∫ñÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂØ¶ÈöõÁöÑÊ∂àË≤ªËÄÖÈÜ´ÁôÇÂïèÈ°åÔºå‰ª•ÂèäÁî±ÈÜ´ÁîüË®ªÈáãÁöÑÈï∑ÁØáÁ≠îÊ°àË©ï‰º∞„ÄÇÊàëÂÄëÊ†πÊìöÊ≠£Á¢∫ÊÄß„ÄÅÊúâÁî®ÊÄß„ÄÅÊúâÂÆ≥ÊÄßÂíåÂÅèÂ∑ÆÁ≠âÊ®ôÊ∫ñÔºåÂ∞ç‰æÜËá™ÂêÑÁ®ÆÈñãÊîæÂíåÈñâÊ∫êÈÜ´ÁôÇÂíåÈÄöÁî® LLM ÁöÑÂõûÊáâÈÄ≤Ë°å‰∫ÜÊàêÂ∞çÊØîËºÉ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÂÖ®Èù¢ÁöÑ LLM ‰ΩúÁÇ∫Ë©ïÂØ©ÁöÑÂàÜÊûêÔºå‰ª•Á†îÁ©∂‰∫∫È°ûÂà§Êñ∑Âíå LLM ‰πãÈñìÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÊàëÂÄëÁöÑÂàùÊ≠•ÁµêÊûúÁ™ÅÂá∫‰∫ÜÈñãÊîæÂºè LLM Âú®ÈÜ´ÁôÇ QA ‰∏≠ÁöÑÂº∑Â§ßÊΩõÂäõÔºåËàáÈ†òÂÖàÁöÑÈñâÊ∫êÊ®°ÂûãÁõ∏ÊØî„ÄÇÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÔºöhttps://github.com/lavita-ai/medical-eval-sphere

##### **A Self-Supervised Model for Multi-modal Stroke Risk Prediction**
2411.09822v1 by Camille Delgrange, Olga Demler, Samia Mora, Bjoern Menze, Ezequiel de la Rosa, Neda Davoudi

Predicting stroke risk is a complex challenge that can be enhanced by
integrating diverse clinically available data modalities. This study introduces
a self-supervised multimodal framework that combines 3D brain imaging, clinical
data, and image-derived features to improve stroke risk prediction prior to
onset. By leveraging large unannotated clinical datasets, the framework
captures complementary and synergistic information across image and tabular
data modalities. Our approach is based on a contrastive learning framework that
couples contrastive language-image pretraining with an image-tabular matching
module, to better align multimodal data representations in a shared latent
space. The model is trained on the UK Biobank, which includes structural brain
MRI and clinical data. We benchmark its performance against state-of-the-art
unimodal and multimodal methods using tabular, image, and image-tabular
combinations under diverse frozen and trainable model settings. The proposed
model outperformed self-supervised tabular (image) methods by 2.6% (2.6%) in
ROC-AUC and by 3.3% (5.6%) in balanced accuracy. Additionally, it showed a 7.6%
increase in balanced accuracy compared to the best multimodal supervised model.
Through interpretable tools, our approach demonstrated better integration of
tabular and image data, providing richer and more aligned embeddings.
Gradient-weighted Class Activation Mapping heatmaps further revealed activated
brain regions commonly associated in the literature with brain aging, stroke
risk, and clinical outcomes. This robust self-supervised multimodal framework
surpasses state-of-the-art methods for stroke risk prediction and offers a
strong foundation for future studies integrating diverse data modalities to
advance clinical predictive modelling.

ÊëòË¶ÅÔºö<paragraph>È†êÊ∏¨‰∏≠È¢®È¢®Èö™ÊòØ‰∏ÄÈ†ÖË§áÈõúÁöÑÊåëÊà∞ÔºåÂèØ‰ª•ÈÄèÈÅéÊï¥ÂêàÂ§öÊ®£ÂåñÁöÑËá®Â∫äÂèØÁî®Êï∏ÊìöÊ®°Âºè‰æÜÂä†Âº∑„ÄÇÊú¨Á†îÁ©∂‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãËá™Áõ£Áù£Â§öÊ®°ÂºèÊû∂ÊßãÔºåÁµêÂêà 3D Â§ßËÖ¶ÂΩ±ÂÉè„ÄÅËá®Â∫äÊï∏ÊìöÂíåÂΩ±ÂÉèË°çÁîüÁâπÂæµÔºå‰ª•Âú®Áôº‰ΩúÂâçÊîπÂñÑ‰∏≠È¢®È¢®Èö™È†êÊ∏¨„ÄÇÈÄèÈÅéÂà©Áî®Â§ßÈáèÁöÑÊú™Ê®ôË®òËá®Â∫äÊï∏ÊìöÈõÜÔºåË©≤Êû∂ÊßãÊì∑Âèñ‰∫ÜÂΩ±ÂÉèÂíåË°®Ê†ºÊï∏ÊìöÊ®°Âºè‰πãÈñìÁöÑ‰∫íË£úÂíåÂçîÂêåË≥áË®ä„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂü∫ÊñºÂ∞çÊØîÂ≠∏ÁøíÊû∂ÊßãÔºåÂ∞áÂ∞çÊØîË™ûË®ÄÂΩ±ÂÉèÈ†êË®ìÁ∑¥ËàáÂΩ±ÂÉèË°®Ê†ºÂåπÈÖçÊ®°ÁµÑÁµêÂêàÔºå‰ª•Âú®ÂÖ±‰∫´ÊΩõÂú®Á©∫Èñì‰∏≠Êõ¥Â•ΩÂú∞Â∞çÈΩäÂ§öÊ®°ÂºèÊï∏ÊìöË°®Á§∫„ÄÇË©≤Ê®°ÂûãÊòØÂú®Ëã±ÂúãÁîüÁâ©ÈäÄË°å‰∏≠Ë®ìÁ∑¥ÁöÑÔºåÂÖ∂‰∏≠ÂåÖÊã¨ÁµêÊßãÊÄßËÖ¶ÈÉ® MRI ÂíåËá®Â∫äÊï∏Êìö„ÄÇÊàëÂÄë‰ΩøÁî®Ë°®Ê†º„ÄÅÂΩ±ÂÉèÂíåÂΩ±ÂÉèË°®Ê†ºÁµÑÂêàÔºåÂú®‰∏çÂêåÁöÑÂáçÁµêÂíåÂèØË®ìÁ∑¥Ê®°ÂûãË®≠ÂÆö‰∏ãÔºåÊ†πÊìöÊúÄÂÖàÈÄ≤ÁöÑÂñÆÊ®°ÂºèÂíåÂ§öÊ®°ÂºèÊñπÊ≥ïÂ∞çÂÖ∂ÊïàËÉΩÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶„ÄÇÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂú® ROC-AUC ‰∏≠ÊØîËá™Áõ£Áù£Ë°®Ê†ºÔºàÂΩ±ÂÉèÔºâÊñπÊ≥ïÈ´òÂá∫ 2.6%Ôºà2.6%ÔºâÔºåÂú®Âπ≥Ë°°Ê∫ñÁ¢∫Â∫¶‰∏≠È´òÂá∫ 3.3%Ôºà5.6%Ôºâ„ÄÇÊ≠§Â§ñÔºåËàáÊúÄ‰Ω≥Â§öÊ®°ÂºèÁõ£Áù£Ê®°ÂûãÁõ∏ÊØîÔºåÂÆÉÁöÑÂπ≥Ë°°Ê∫ñÁ¢∫Â∫¶ÊèêÈ´ò‰∫Ü 7.6%„ÄÇÈÄèÈÅéÂèØËß£ÈáãÁöÑÂ∑•ÂÖ∑ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïË≠âÊòé‰∫ÜË°®Ê†ºÂíåÂΩ±ÂÉèÊï∏ÊìöÁöÑÊï¥ÂêàÊÄßÊõ¥Â•ΩÔºåÊèê‰æõ‰∫ÜÊõ¥Ë±êÂØå‰∏îÊõ¥‰∏ÄËá¥ÁöÑÂµåÂÖ•„ÄÇÊ¢ØÂ∫¶Âä†Ê¨äÈ°ûÂà•ÂïüÁî®Â∞çÊáâÁÜ±ÂúñÈÄ≤‰∏ÄÊ≠•Êè≠Á§∫‰∫ÜÊñáÁçª‰∏≠ÈÄöÂ∏∏ËàáËÖ¶ÈÉ®ËÄÅÂåñ„ÄÅ‰∏≠È¢®È¢®Èö™ÂíåËá®Â∫äÁµêÊûúÁõ∏ÈóúÁöÑÊ¥ªÂåñËÖ¶ÂçÄ„ÄÇÈÄôÂÄãÂº∑ÂÅ•ÁöÑËá™Áõ£Áù£Â§öÊ®°ÂºèÊû∂ÊßãË∂ÖË∂ä‰∫Ü‰∏≠È¢®È¢®Èö™È†êÊ∏¨ÁöÑÊúÄÊñ∞ÊñπÊ≥ïÔºå‰∏¶ÁÇ∫Êï¥Âêà‰∏çÂêåÊï∏ÊìöÊ®°Âºè‰ª•Êé®ÈÄ≤Ëá®Â∫äÈ†êÊ∏¨Âª∫Ê®°ÁöÑÊú™‰æÜÁ†îÁ©∂Êèê‰æõ‰∫ÜÂ†ÖÂØ¶ÁöÑÂü∫Á§é„ÄÇ</paragraph>

##### **Deep Learning for Fetal Inflammatory Response Diagnosis in the Umbilical Cord**
2411.09767v1 by Marina A. Ayad, Ramin Nateghi, Abhishek Sharma, Lawrence Chillrud, Tilly Seesillapachai, Lee A. D. Cooper, Jeffery A. Goldstein

Inflammation of the umbilical cord can be seen as a result of ascending
intrauterine infection or other inflammatory stimuli. Acute fetal inflammatory
response (FIR) is characterized by infiltration of the umbilical cord by fetal
neutrophils, and can be associated with neonatal sepsis or fetal inflammatory
response syndrome. Recent advances in deep learning in digital pathology have
demonstrated favorable performance across a wide range of clinical tasks, such
as diagnosis and prognosis. In this study we classified FIR from whole slide
images (WSI). We digitized 4100 histological slides of umbilical cord stained
with hematoxylin and eosin(H&E) and extracted placental diagnoses from the
electronic health record. We build models using attention-based whole slide
learning models. We compared strategies between features extracted by a model
(ConvNeXtXLarge) pretrained on non-medical images (ImageNet), and one
pretrained using histopathology images (UNI). We trained multiple iterations of
each model and combined them into an ensemble. The predictions from the
ensemble of models trained using UNI achieved an overall balanced accuracy of
0.836 on the test dataset. In comparison, the ensembled predictions using
ConvNeXtXLarge had a lower balanced accuracy of 0.7209. Heatmaps generated from
top accuracy model appropriately highlighted arteritis in cases of FIR 2. In
FIR 1, the highest performing model assigned high attention to areas of
activated-appearing stroma in Wharton's Jelly. However, other high-performing
models assigned attention to umbilical vessels. We developed models for
diagnosis of FIR from placental histology images, helping reduce interobserver
variability among pathologists. Future work may examine the utility of these
models for identifying infants at risk of systemic inflammatory response or
early onset neonatal sepsis.

ÊëòË¶ÅÔºöËáçÂ∏∂ÁôºÁÇéÂèØË¶ñÁÇ∫‰∏äË°åÊÄßÂ≠êÂÆÆÂÖßÊÑüÊüìÊàñÂÖ∂‰ªñÁôºÁÇéÂà∫ÊøÄÊâÄËá¥„ÄÇÊÄ•ÊÄßËÉéÂÖíÁôºÁÇéÂèçÊáâ (FIR) ÁöÑÁâπÂæµÊòØËÉéÂÖí‰∏≠ÊÄßÁêÉÊµ∏ÊΩ§ËáçÂ∏∂ÔºåÂèØËÉΩËàáÊñ∞ÁîüÂÖíÊïóË°ÄÁóáÊàñËÉéÂÖíÁôºÁÇéÂèçÊáâÁóáÂÄôÁæ§ÊúâÈóú„ÄÇÊï∏‰ΩçÁóÖÁêÜÂ≠∏‰∏≠Ê∑±Â∫¶Â≠∏ÁøíÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂ∑≤Ë≠âÊòéÂú®Âª£Ê≥õÁöÑËá®Â∫ä‰ªªÂãô‰∏≠Ë°®ÁèæËâØÂ•ΩÔºå‰æãÂ¶ÇË®∫Êñ∑ÂíåÈ†êÂæå„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂæûÂÖ®ÂàáÁâáÂΩ±ÂÉè (WSI) ‰∏≠ÂàÜÈ°û FIR„ÄÇÊàëÂÄëÂ∞á 4100 ÂºµÁî®ËòáÊú®Á≤æÂíåÊõôÁ¥Ö (H&E) ÊüìËâ≤ÁöÑËáçÂ∏∂ÁµÑÁπîÂàáÁâáÊï∏‰ΩçÂåñÔºå‰∏¶ÂæûÈõªÂ≠êÁóÖÊ≠∑‰∏≠ÊèêÂèñËÉéÁõ§Ë®∫Êñ∑„ÄÇÊàëÂÄë‰ΩøÁî®Âü∫ÊñºÊ≥®ÊÑèÂäõÁöÑÂÖ®ÂàáÁâáÂ≠∏ÁøíÊ®°ÂûãÂª∫Á´ãÊ®°Âûã„ÄÇÊàëÂÄëÊØîËºÉ‰∫ÜÈùûÈÜ´ÁôÇÂΩ±ÂÉè (ImageNet) È†êË®ìÁ∑¥Ê®°Âûã (ConvNeXtXLarge) Âíå‰ΩøÁî®ÁµÑÁπîÁóÖÁêÜÂ≠∏ÂΩ±ÂÉè (UNI) È†êË®ìÁ∑¥Ê®°ÂûãÊèêÂèñÁöÑÁâπÂæµ‰πãÈñìÁöÑÁ≠ñÁï•„ÄÇÊàëÂÄëË®ìÁ∑¥‰∫ÜÊØèÂÄãÊ®°ÂûãÁöÑÂ§öÊ¨°Ëø≠‰ª£Ôºå‰∏¶Â∞áÂÆÉÂÄëÁµÑÂêàÊàê‰∏ÄÂÄãÊï¥È´î„ÄÇ‰ΩøÁî® UNI Ë®ìÁ∑¥ÁöÑÊ®°ÂûãÊï¥È´îÁöÑÈ†êÊ∏¨Âú®Ê∏¨Ë©¶Ë≥áÊñôÈõÜ‰∏äÈÅîÂà∞ 0.836 ÁöÑÊï¥È´îÂπ≥Ë°°Ê∫ñÁ¢∫Â∫¶„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºå‰ΩøÁî® ConvNeXtXLarge ÁöÑÊï¥È´îÈ†êÊ∏¨ÁöÑÂπ≥Ë°°Ê∫ñÁ¢∫Â∫¶ËºÉ‰ΩéÔºåÁÇ∫ 0.7209„ÄÇÂæûÊ∫ñÁ¢∫Â∫¶ÊúÄÈ´òÁöÑÊ®°ÂûãÁî¢ÁîüÁöÑÁÜ±ÂúñÈÅ©Áï∂Âú∞Á™ÅÂá∫‰∫Ü FIR 2 ÁóÖ‰æã‰∏≠ÁöÑÂãïËÑàÁÇé„ÄÇÂú® FIR 1 ‰∏≠ÔºåË°®ÁèæÊúÄÂ•ΩÁöÑÊ®°ÂûãÂ∞áÈ´òÂ∫¶ÈóúÊ≥®ÂàÜÈÖçÁµ¶Ê≤ÉÈ†ìÊ∞èËÜ†‰∏≠ÁöÑÊ¥ªÂåñÂ§ñËßÄÂü∫Ë≥™ÂçÄÂüü„ÄÇÁÑ∂ËÄåÔºåÂÖ∂‰ªñË°®ÁèæËâØÂ•ΩÁöÑÊ®°ÂûãÂ∞áÊ≥®ÊÑèÂäõÂàÜÈÖçÁµ¶ËáçÂ∏∂Ë°ÄÁÆ°„ÄÇÊàëÂÄëÈñãÁôº‰∫ÜÂæûËÉéÁõ§ÁµÑÁπîÂ≠∏ÂΩ±ÂÉèË®∫Êñ∑ FIR ÁöÑÊ®°ÂûãÔºåÊúâÂä©ÊñºÊ∏õÂ∞ëÁóÖÁêÜÂ≠∏ÂÆ∂‰πãÈñìÁöÑËßÄÂØüËÄÖÈñìËÆäÁï∞ÊÄß„ÄÇÊú™‰æÜÁöÑÁ†îÁ©∂ÂèØËÉΩÊúÉÊé¢Ë®éÈÄô‰∫õÊ®°ÂûãÂú®Ë≠òÂà•ÊúâÂÖ®Ë∫´ÊÄßÁôºÁÇéÂèçÊáâÈ¢®Èö™ÊàñÊó©ÊúüÁôº‰ΩúÊñ∞ÁîüÂÖíÊïóË°ÄÁóáÁöÑÂ¨∞ÂÖíÊñπÈù¢ÁöÑÊïàÁî®„ÄÇ

##### **Med-Bot: An AI-Powered Assistant to Provide Accurate and Reliable Medical Information**
2411.09648v1 by Ahan Bhatt, Nandan Vaghela

This paper introduces Med-Bot, an AI-powered chatbot designed to provide
users with accurate and reliable medical information. Utilizing advanced
libraries and frameworks such as PyTorch, Chromadb, Langchain and Autogptq,
Med-Bot is built to handle the complexities of natural language understanding
in a healthcare context. The integration of llamaassisted data processing and
AutoGPT-Q provides enhanced performance in processing and responding to queries
based on PDFs of medical literature, ensuring that users receive precise and
trustworthy information. This research details the methodologies employed in
developing Med-Bot and evaluates its effectiveness in disseminating healthcare
information.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π Med-BotÔºå‰∏ÄÂÄãÁî±‰∫∫Â∑•Êô∫ÊÖßÈ©ÖÂãïÁöÑËÅäÂ§©Ê©üÂô®‰∫∫ÔºåÊó®Âú®ÁÇ∫‰ΩøÁî®ËÄÖÊèê‰æõÊ∫ñÁ¢∫‰∏îÂèØÈù†ÁöÑÈÜ´ÁôÇË≥áË®ä„ÄÇMed-Bot Âà©Áî®ÈÄ≤ÈöéÂáΩÂºèÂ∫´ÂíåÊ°ÜÊû∂Ôºå‰æãÂ¶Ç PyTorch„ÄÅChromadb„ÄÅLangchain Âíå AutogptqÔºåÂª∫Êßã‰æÜËôïÁêÜÈÜ´ÁôÇ‰øùÂÅ•Áí∞Â¢É‰∏≠Ëá™ÁÑ∂Ë™ûË®ÄÁêÜËß£ÁöÑË§áÈõúÊÄß„ÄÇÊï¥Âêà‰∫Ü Llama ËºîÂä©Ë≥áÊñôËôïÁêÜÂíå AutoGPT-QÔºåÂú®ËôïÁêÜÂíåÂõûÊáâÂü∫ÊñºÈÜ´Â≠∏ÊñáÁçª PDF ÁöÑÊü•Ë©¢ÊôÇÊèê‰æõ‰∫ÜÂ¢ûÂº∑ÁöÑÊïàËÉΩÔºåÁ¢∫‰øù‰ΩøÁî®ËÄÖÊî∂Âà∞Á≤æÁ¢∫‰∏îÂèØ‰ø°Ë≥¥ÁöÑË≥áË®ä„ÄÇÊú¨Á†îÁ©∂Ë©≥Á¥∞Ë™™Êòé‰∫ÜÈñãÁôº Med-Bot ÊâÄÊé°Áî®ÁöÑÊñπÊ≥ïÔºå‰∏¶Ë©ï‰º∞ÂÖ∂Âú®ÂÇ≥Êí≠ÈÜ´ÁôÇ‰øùÂÅ•Ë≥áË®äÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **An Explainable Attention Model for Cervical Precancer Risk Classification using Colposcopic Images**
2411.09469v1 by Smith K. Khare, Berit Bargum Booth, Victoria Blanes-Vidal, Lone Kjeld Petersen, Esmaeil S. Nadimi

Cervical cancer remains a major worldwide health issue, with early
identification and risk assessment playing critical roles in effective
preventive interventions. This paper presents the Cervix-AID-Net model for
cervical precancer risk classification. The study designs and evaluates the
proposed Cervix-AID-Net model based on patients colposcopy images. The model
comprises a Convolutional Block Attention Module (CBAM) and convolutional
layers that extract interpretable and representative features of colposcopic
images to distinguish high-risk and low-risk cervical precancer. In addition,
the proposed Cervix-AID-Net model integrates four explainable techniques,
namely gradient class activation maps, Local Interpretable Model-agnostic
Explanations, CartoonX, and pixel rate distortion explanation based on output
feature maps and input features. The evaluation using holdout and ten-fold
cross-validation techniques yielded a classification accuracy of 99.33\% and
99.81\%. The analysis revealed that CartoonX provides meticulous explanations
for the decision of the Cervix-AID-Net model due to its ability to provide the
relevant piece-wise smooth part of the image. The effect of Gaussian noise and
blur on the input shows that the performance remains unchanged up to Gaussian
noise of 3\% and blur of 10\%, while the performance reduces thereafter. A
comparison study of the proposed model's performance compared to other deep
learning approaches highlights the Cervix-AID-Net model's potential as a
supplemental tool for increasing the effectiveness of cervical precancer risk
assessment. The proposed method, which incorporates the CBAM and explainable
artificial integration, has the potential to influence cervical cancer
prevention and early detection, improving patient outcomes and lowering the
worldwide burden of this preventable disease.

ÊëòË¶ÅÔºöÂ≠êÂÆÆÈ†∏Áôå‰ªçÁÑ∂ÊòØÂÖ®ÁêÉ‰∏ªË¶ÅÁöÑÂÅ•Â∫∑Ë≠∞È°åÔºåÊó©ÊúüËæ®Ë≠òÂíåÈ¢®Èö™Ë©ï‰º∞Âú®ÊúâÊïàÁöÑÈ†êÈò≤ÊÄßÂπ≤È†êÊé™ÊñΩ‰∏≠ÊâÆÊºîËëóÈóúÈçµÊÄßÁöÑËßíËâ≤„ÄÇÊú¨ÊñáÊèêÂá∫Â≠êÂÆÆÈ†∏ËºîÂä©Á∂≤Ë∑ØÊ®°ÂûãÔºåÁî®ÊñºÂ≠êÂÆÆÈ†∏ÁôåÂâçÁóÖËÆäÈ¢®Èö™ÂàÜÈ°û„ÄÇÊú¨Á†îÁ©∂Âü∫ÊñºÁóÖÊÇ£ÁöÑÈô∞ÈÅìÈè°ÂΩ±ÂÉèË®≠Ë®à‰∏¶Ë©ï‰º∞ÊâÄÊèêÂá∫ÁöÑÂ≠êÂÆÆÈ†∏ËºîÂä©Á∂≤Ë∑ØÊ®°Âûã„ÄÇË©≤Ê®°ÂûãÂåÖÂê´Âç∑Á©çÂçÄÂ°äÊ≥®ÊÑèÂäõÊ®°ÁµÑ (CBAM) ÂíåÂç∑Á©çÂ±§ÔºåÁî®ÊñºËêÉÂèñÂèØËß£Èáã‰∏îÂÖ∑‰ª£Ë°®ÊÄßÁöÑÈô∞ÈÅìÈè°ÂΩ±ÂÉèÁâπÂæµÔºå‰ª•ÂçÄÂàÜÈ´òÈ¢®Èö™Âíå‰ΩéÈ¢®Èö™ÁöÑÂ≠êÂÆÆÈ†∏ÁôåÂâçÁóÖËÆä„ÄÇÊ≠§Â§ñÔºåÊâÄÊèêÂá∫ÁöÑÂ≠êÂÆÆÈ†∏ËºîÂä©Á∂≤Ë∑ØÊ®°ÂûãÊï¥Âêà‰∫ÜÂõõÁ®ÆÂèØËß£ÈáãÁöÑÊäÄË°ìÔºåÂàÜÂà•ÁÇ∫Ê¢ØÂ∫¶È°ûÂà•ÊøÄÊ¥ªÂúñ„ÄÅÂ±ÄÈÉ®ÂèØËß£ÈáãÊ®°Âûã‰∏çÂèØÁü•Ëß£Èáã„ÄÅCartoonX ÂíåÂü∫ÊñºËº∏Âá∫ÁâπÂæµÂúñÂíåËº∏ÂÖ•ÁâπÂæµÁöÑÂÉèÁ¥†ÁéáÂ§±ÁúüËß£Èáã„ÄÇ‰ΩøÁî®ÁïôÂ≠òÊ≥ïÂíåÂçÅÂÄç‰∫§ÂèâÈ©óË≠âÊäÄË°ìÈÄ≤Ë°åË©ï‰º∞ÔºåÂæóÂà∞ 99.33% Âíå 99.81% ÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫Áéá„ÄÇÂàÜÊûêÈ°ØÁ§∫ÔºåCartoonX ËÉΩÂ§†Êèê‰æõÂΩ±ÂÉè‰∏≠Áõ∏ÈóúÁöÑÂàÜÊÆµÂπ≥ÊªëÈÉ®ÂàÜÔºåÂõ†Ê≠§ËÉΩÁÇ∫Â≠êÂÆÆÈ†∏ËºîÂä©Á∂≤Ë∑ØÊ®°ÂûãÁöÑÊ±∫Á≠ñÊèê‰æõÁ¥∞Á∑ªÁöÑËß£Èáã„ÄÇÈ´òÊñØÂô™ËÅ≤ÂíåÊ®°Á≥äÂ∞çËº∏ÂÖ•ÁöÑÂΩ±ÈüøÈ°ØÁ§∫ÔºåÂú®È´òÊñØÂô™ËÅ≤‰ΩéÊñº 3% ÂíåÊ®°Á≥ä‰ΩéÊñº 10% ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊïàËÉΩ‰øùÊåÅ‰∏çËÆäÔºå‰ΩÜ‰πãÂæåÊïàËÉΩ‰æøÊúÉ‰∏ãÈôç„ÄÇÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÊïàËÉΩËàáÂÖ∂‰ªñÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÁöÑÊØîËºÉÁ†îÁ©∂ÔºåÁ™ÅÈ°Ø‰∫ÜÂ≠êÂÆÆÈ†∏ËºîÂä©Á∂≤Ë∑ØÊ®°Âûã‰ΩúÁÇ∫Ë£úÂÖÖÂ∑•ÂÖ∑ÁöÑÊΩõÂäõÔºåÁî®ÊñºÊèêÈ´òÂ≠êÂÆÆÈ†∏ÁôåÂâçÁóÖËÆäÈ¢®Èö™Ë©ï‰º∞ÁöÑÊúâÊïàÊÄß„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÁµêÂêà‰∫Ü CBAM ÂíåÂèØËß£ÈáãÁöÑ‰∫∫Â∑•Êï¥ÂêàÔºåÊúâÊΩõÂäõÂΩ±ÈüøÂ≠êÂÆÆÈ†∏ÁôåÁöÑÈ†êÈò≤ÂíåÊó©ÊúüÂÅµÊ∏¨ÔºåÊîπÂñÑÁóÖÊÇ£ÁöÑÈ†êÂæå‰∏¶Èôç‰ΩéÈÄôÁ®ÆÂèØÈ†êÈò≤ÁñæÁóÖÂú®ÂÖ®ÁêÉÁöÑË≤†Êìî„ÄÇ

##### **Script-centric behavior understanding for assisted autism spectrum disorder diagnosis**
2411.09413v1 by Wenxing Liu, Yueran Pan, Ming Li

Observing and analyzing children's social behaviors is crucial for the early
diagnosis of Autism Spectrum Disorders (ASD). This work focuses on
automatically detecting ASD using computer vision techniques and large language
models (LLMs). Existing methods typically rely on supervised learning. However,
the scarcity of ASD diagnostic datasets and the lack of interpretability in
diagnostic results significantly limits its clinical application. To address
these challenges, we introduce a novel unsupervised approach based on
script-centric behavior understanding. Our pipeline converts video content into
scripts that describe the behavior of characters, leveraging the
generalizability of large language models to detect ASD in a zero-shot or
few-shot manner. Specifically, we propose a scripts transcription module for
multimodal behavior data textualization and a domain prompts module to bridge
LLMs. Our method achieves an accuracy of 92.00\% in diagnosing ASD in children
with an average age of 24 months, surpassing the performance of supervised
learning methods by 3.58\% absolutely. Extensive experiments confirm the
effectiveness of our approach and suggest its potential for advancing ASD
research through LLMs.

ÊëòË¶ÅÔºöËßÄÂØüÂíåÂàÜÊûêÂÖíÁ´•ÁöÑÁ§æ‰∫§Ë°åÁÇ∫Â∞çÊñºËá™ÈñâÁóáË≠úÁ≥ªÈöúÁ§ô (ASD) ÁöÑÊó©ÊúüË®∫Êñ∑Ëá≥ÈóúÈáçË¶Å„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúËëóÈáçÊñº‰ΩøÁî®ÈõªËÖ¶Ë¶ñË¶∫ÊäÄË°ìÂíåÂ§ßË™ûË®ÄÊ®°Âûã (LLM) Ëá™ÂãïÂÅµÊ∏¨ ASD„ÄÇÁèæÊúâÊñπÊ≥ïÈÄöÂ∏∏‰æùË≥¥ÊñºÁõ£Áù£ÂºèÂ≠∏Áøí„ÄÇÁÑ∂ËÄåÔºåASD Ë®∫Êñ∑Ë≥áÊñôÈõÜÁöÑÁ®ÄÂ∞ëÊÄßÂíåË®∫Êñ∑ÁµêÊûúÁº∫‰πèÂèØËß£ÈáãÊÄßÔºåÈ°ØËëóÂú∞ÈôêÂà∂‰∫ÜÂÖ∂Ëá®Â∫äÊáâÁî®„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÂü∫Êñº‰ª•ËÖ≥Êú¨ÁÇ∫‰∏≠ÂøÉÁöÑË°åÁÇ∫ÁêÜËß£ÁöÑÊñ∞ÂûãÈùûÁõ£Áù£ÂºèÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÁÆ°ÈÅìÂ∞áÂΩ±ÁâáÂÖßÂÆπËΩâÊèõÊàêÊèèËø∞ËßíËâ≤Ë°åÁÇ∫ÁöÑËÖ≥Êú¨ÔºåÂà©Áî®Â§ßË™ûË®ÄÊ®°ÂûãÁöÑÊ≥õÂåñÊÄß‰ª•Èõ∂Ê¨°ÊàñÂ∞ëÊ¨°Â≠∏ÁøíÁöÑÊñπÂºèÂÅµÊ∏¨ ASD„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãËÖ≥Êú¨ËΩâÈåÑÊ®°ÁµÑÁî®ÊñºÂ§öÊ®°ÊÖãË°åÁÇ∫Ë≥áÊñôÊñáÂ≠óÂåñÔºå‰ª•Âèä‰∏ÄÂÄãÁ∂≤ÂüüÊèêÁ§∫Ê®°ÁµÑ‰æÜÊ©ãÊé• LLM„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®Ë®∫Êñ∑Âπ≥ÂùáÂπ¥ÈΩ°ÁÇ∫ 24 ÂÄãÊúàÁöÑÂÖíÁ´• ASD ÊôÇÔºåÈÅîÂà∞‰∫Ü 92.00% ÁöÑÊ∫ñÁ¢∫ÁéáÔºåÁµïÂ∞çÂÑ™ÊñºÁõ£Áù£ÂºèÂ≠∏ÁøíÊñπÊ≥ï 3.58%„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óË≠âÂØ¶‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºå‰∏¶Ë°®ÊòéÂÖ∂ÈÄöÈÅé LLM Êé®Âãï ASD Á†îÁ©∂ÁöÑÊΩõÂäõ„ÄÇ

##### **NFRs in Medical Imaging**
2411.09718v1 by Amanda Vallentin

The diagnostic imaging departments are under great pressure due to a growing
workload. The number of required scans is growing and there is a shortage of
qualified labor. AI solutions for medical imaging applications have shown great
potential. However, very few diagnostic imaging models have been approved for
hospital use and even fewer are being implemented at the hospitals. The most
common reason why software projects fail is poor requirement engineering,
especially non-functional requirements (NFRs) can be detrimental to a project.
Research shows that machine learning professionals struggle to work with NFRs
and that there is a need to adapt NFR frameworks to machine learning, AI-based,
software. This study uses qualitative methods to interact with key stakeholders
to identify which types of NFRs are important for medical imaging applications.
The study was done on a single Danish hospital and found that NFRs of type
Efficiency, Accuracy, Interoperability, Reliability, Usability, Adaptability,
and Fairness were important to the stakeholders. Especially Efficiency since
the diagnostic imaging department is trying to spend as little time as possible
on each scan.

ÊëòË¶ÅÔºöÁî±ÊñºÂ∑•‰ΩúË≤†ËºâÂ¢ûÂä†ÔºåË®∫Êñ∑ÂΩ±ÂÉèÈÉ®ÈñÄÊâøÂèóËëóÊ•µÂ§ßÁöÑÂ£ìÂäõ„ÄÇÊâÄÈúÄÊéÉÊèèÁöÑÊï∏ÈáèÊ≠£Âú®Â¢ûÂä†ÔºåËÄå‰∏îÂêàÊ†ºÁöÑÂãûÂãïÂäõÁü≠Áº∫„ÄÇÈÜ´ÁôÇÂΩ±ÂÉèÊáâÁî®ÁöÑ‰∫∫Â∑•Êô∫ÊÖßËß£Ê±∫ÊñπÊ°àÈ°ØÁ§∫Âá∫Â∑®Â§ßÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÂæàÂ∞ëÊúâË®∫Êñ∑ÂΩ±ÂÉèÊ®°ÂûãË¢´ÊâπÂáÜÁî®ÊñºÈÜ´Èô¢ÔºåÁîöËá≥Êõ¥Â∞ëË¢´ÂØ¶ÊñΩÊñºÈÜ´Èô¢„ÄÇËªüÈ´îÂ∞àÊ°àÂ§±ÊïóÁöÑÊúÄÂ∏∏Ë¶ãÂéüÂõ†ÊòØÈúÄÊ±ÇÂ∑•Á®ã‰∏ç‰Ω≥ÔºåÁâπÂà•ÊòØÈùûÂäüËÉΩÊÄßÈúÄÊ±Ç (NFR) ÂèØËÉΩÂ∞çÂ∞àÊ°àÊúâÂÆ≥„ÄÇÁ†îÁ©∂È°ØÁ§∫ÔºåÊ©üÂô®Â≠∏ÁøíÂ∞àÊ•≠‰∫∫Âì°Èõ£‰ª•‰ΩøÁî® NFRÔºå‰∏¶‰∏îÈúÄË¶ÅÂ∞á NFR Ê°ÜÊû∂Ë™øÊï¥ÁÇ∫Ê©üÂô®Â≠∏Áøí„ÄÅÂü∫Êñº AI ÁöÑËªüÈ´î„ÄÇÊú¨Á†îÁ©∂‰ΩøÁî®ÂÆöÊÄßÊñπÊ≥ïËàá‰∏ªË¶ÅÂà©ÂÆ≥Èóú‰øÇ‰∫∫‰∫íÂãïÔºå‰ª•ÊâæÂá∫Âì™‰∫õÈ°ûÂûãÁöÑ NFR Â∞çÈÜ´Â≠∏ÂΩ±ÂÉèÊáâÁî®Á®ãÂºèÂæàÈáçË¶Å„ÄÇË©≤Á†îÁ©∂Âú®‰∏ÄÂÆ∂‰∏πÈ∫•ÈÜ´Èô¢ÈÄ≤Ë°åÔºåÁôºÁèæÊïàÁéá„ÄÅÊ∫ñÁ¢∫ÊÄß„ÄÅ‰∫íÊìç‰ΩúÊÄß„ÄÅÂèØÈù†ÊÄß„ÄÅÂèØÁî®ÊÄß„ÄÅÈÅ©ÊáâÊÄßÂíåÂÖ¨Âπ≥ÊÄßÈ°ûÂûãÁöÑ NFR Â∞çÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÂæàÈáçË¶Å„ÄÇÁâπÂà•ÊòØÊïàÁéáÔºåÂõ†ÁÇ∫Ë®∫Êñ∑ÂΩ±ÂÉèÈÉ®ÈñÄÊ≠£Âä™ÂäõÁõ°ÂèØËÉΩÊ∏õÂ∞ëÊØèÈ†ÖÊéÉÊèèÊâÄËä±ÁöÑÊôÇÈñì„ÄÇ

##### **Comprehensive and Practical Evaluation of Retrieval-Augmented Generation Systems for Medical Question Answering**
2411.09213v1 by Nghia Trung Ngo, Chien Van Nguyen, Franck Dernoncourt, Thien Huu Nguyen

Retrieval-augmented generation (RAG) has emerged as a promising approach to
enhance the performance of large language models (LLMs) in knowledge-intensive
tasks such as those from medical domain. However, the sensitive nature of the
medical domain necessitates a completely accurate and trustworthy system. While
existing RAG benchmarks primarily focus on the standard retrieve-answer
setting, they overlook many practical scenarios that measure crucial aspects of
a reliable medical system. This paper addresses this gap by providing a
comprehensive evaluation framework for medical question-answering (QA) systems
in a RAG setting for these situations, including sufficiency, integration, and
robustness. We introduce Medical Retrieval-Augmented Generation Benchmark
(MedRGB) that provides various supplementary elements to four medical QA
datasets for testing LLMs' ability to handle these specific scenarios.
Utilizing MedRGB, we conduct extensive evaluations of both state-of-the-art
commercial LLMs and open-source models across multiple retrieval conditions.
Our experimental results reveals current models' limited ability to handle
noise and misinformation in the retrieved documents. We further analyze the
LLMs' reasoning processes to provides valuable insights and future directions
for developing RAG systems in this critical medical domain.

ÊëòË¶ÅÔºöÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÔºàRAGÔºâÂ∑≤ÊàêÁÇ∫‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÊñπÊ≥ïÔºåÂèØÂ¢ûÂº∑Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂú®Áü•Ë≠òÂØÜÈõÜÂûã‰ªªÂãô‰∏≠ÁöÑÊïàËÉΩÔºå‰æãÂ¶ÇÈÜ´ÁôÇÈ†òÂüüÁöÑ‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÈÜ´ÁôÇÈ†òÂüüÁöÑÊïèÊÑüÊÄßË≥™ÈúÄË¶Å‰∏ÄÂÄãÂÆåÂÖ®Ê∫ñÁ¢∫‰∏îÂÄºÂæó‰ø°Ë≥¥ÁöÑÁ≥ªÁµ±„ÄÇÈõñÁÑ∂ÁèæÊúâÁöÑ RAG Ë©ïÈáèÂü∫Ê∫ñ‰∏ªË¶ÅËëóÈáçÊñºÊ®ôÊ∫ñÊ™¢Á¥¢ÂõûÁ≠îË®≠ÂÆöÔºå‰ΩÜÂÆÉÂÄëÂøΩÁï•‰∫ÜË®±Â§öË°°ÈáèÂèØÈù†ÈÜ´ÁôÇÁ≥ªÁµ±ÈóúÈçµÈù¢ÂêëÁöÑÂØ¶ÈöõÊÉÖÂ¢É„ÄÇÊú¨ÊñáÈÄèÈÅéÊèê‰æõ‰∏ÄÂÄãÂÖ®Èù¢ÁöÑË©ïÈáèÊû∂Êßã‰æÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÈÄôÂÄãÊû∂ÊßãÈÅ©Áî®ÊñºÈÄô‰∫õÊÉÖÂ¢ÉÁöÑ RAG Ë®≠ÂÆö‰∏≠ÁöÑÈÜ´ÁôÇÂïèÁ≠îÔºàQAÔºâÁ≥ªÁµ±ÔºåÂåÖÊã¨ÂÖÖË∂≥ÊÄß„ÄÅÊï¥ÂêàÊÄßËàáÁ©©ÂÅ•ÊÄß„ÄÇÊàëÂÄëÂºïÂÖ•‰∫ÜÈÜ´ÁôÇÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêË©ïÈáèÂü∫Ê∫ñÔºàMedRGBÔºâÔºåÂÆÉÁÇ∫ÂõõÂÄãÈÜ´ÁôÇ QA Ë≥áÊñôÈõÜÊèê‰æõ‰∫ÜÂêÑÁ®ÆË£úÂÖÖÂÖÉÁ¥†Ôºå‰ª•Ê∏¨Ë©¶ LLM ËôïÁêÜÈÄô‰∫õÁâπÂÆöÊÉÖÂ¢ÉÁöÑÁöÑËÉΩÂäõ„ÄÇÂà©Áî® MedRGBÔºåÊàëÂÄëÂ∞çÂ§öÁ®ÆÊ™¢Á¥¢Ê¢ù‰ª∂‰∏ãÁöÑÊúÄÊñ∞ÂïÜÊ•≠ LLM ÂíåÈñãÊ∫êÊ®°ÂûãÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑË©ïÈáè„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÁõÆÂâçÊ®°ÂûãËôïÁêÜÊ™¢Á¥¢Êñá‰ª∂‰∏≠ÁöÑÈõúË®äÂíåÈåØË™§Ë≥áË®äÁöÑËÉΩÂäõÊúâÈôê„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÂàÜÊûê‰∫Ü LLM ÁöÑÊé®ÁêÜÁ®ãÂ∫èÔºåÁÇ∫Âú®ÈÄôÂÄãÈóúÈçµÁöÑÈÜ´ÁôÇÈ†òÂüüÈñãÁôº RAG Á≥ªÁµ±Êèê‰æõ‰∫ÜÂØ∂Ë≤¥ÁöÑË¶ãËß£ÂíåÊú™‰æÜÁöÑÊñπÂêë„ÄÇ

##### **Advancing Diffusion Models: Alias-Free Resampling and Enhanced Rotational Equivariance**
2411.09174v1 by Md Fahim Anjum

Recent advances in image generation, particularly via diffusion models, have
led to impressive improvements in image synthesis quality. Despite this,
diffusion models are still challenged by model-induced artifacts and limited
stability in image fidelity. In this work, we hypothesize that the primary
cause of this issue is the improper resampling operation that introduces
aliasing in the diffusion model and a careful alias-free resampling dictated by
image processing theory can improve the model's performance in image synthesis.
We propose the integration of alias-free resampling layers into the UNet
architecture of diffusion models without adding extra trainable parameters,
thereby maintaining computational efficiency. We then assess whether these
theory-driven modifications enhance image quality and rotational equivariance.
Our experimental results on benchmark datasets, including CIFAR-10, MNIST, and
MNIST-M, reveal consistent gains in image quality, particularly in terms of FID
and KID scores. Furthermore, we propose a modified diffusion process that
enables user-controlled rotation of generated images without requiring
additional training. Our findings highlight the potential of theory-driven
enhancements such as alias-free resampling in generative models to improve
image quality while maintaining model efficiency and pioneer future research
directions to incorporate them into video-generating diffusion models, enabling
deeper exploration of the applications of alias-free resampling in generative
modeling.

ÊëòË¶ÅÔºöÂΩ±ÂÉèÁîüÊàêÊäÄË°ìÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºåÁâπÂà•ÊòØÈÄèÈÅéÊì¥Êï£Ê®°ÂûãÔºåÂ∑≤Â§ßÂπÖÊèêÂçáÂΩ±ÂÉèÂêàÊàêÂìÅË≥™„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÊì¥Êï£Ê®°Âûã‰ªçÂèóÈôêÊñºÊ®°ÂûãÂºïÁôºÁöÑ‰∫∫Â∑•Ë£ΩÂìÅÔºå‰∏îÂΩ±ÂÉè‰øùÁúüÂ∫¶Á©©ÂÆöÊÄßÊúâÈôê„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂÅáË®≠Ê≠§ÂïèÈ°åÁöÑ‰∏ªË¶ÅÂéüÂõ†ÊòØ‰∏çÈÅ©Áï∂ÁöÑÈáçÊñ∞ÂèñÊ®£ÈÅãÁÆóÔºåÈÄôÊúÉÂú®Êì¥Êï£Ê®°Âûã‰∏≠ÂºïÂÖ•Ê∑∑ÁñäÔºåËÄåÁî±ÂΩ±ÂÉèËôïÁêÜÁêÜË´ñÊåáÂ∞éÁöÑ‰ªîÁ¥∞ÁÑ°Ê∑∑ÁñäÈáçÊñ∞ÂèñÊ®£ÂèØ‰ª•ÊèêÂçáÊ®°ÂûãÂú®ÂΩ±ÂÉèÂêàÊàêÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÂª∫Ë≠∞Â∞áÁÑ°Ê∑∑ÁñäÈáçÊñ∞ÂèñÊ®£Â±§Êï¥ÂêàÂà∞Êì¥Êï£Ê®°ÂûãÁöÑ UNet Êû∂Êßã‰∏≠ÔºåËÄåÁÑ°È†àÂ¢ûÂä†È°çÂ§ñÁöÑÂèØË®ìÁ∑¥ÂèÉÊï∏ÔºåÈÄ≤ËÄåÁ∂≠ÊåÅÈÅãÁÆóÊïàÁéá„ÄÇÊé•ËëóÊàëÂÄëË©ï‰º∞ÈÄô‰∫õÁêÜË´ñÈ©ÖÂãïÁöÑ‰øÆÊîπÊòØÂê¶ËÉΩÊèêÂçáÂΩ±ÂÉèÂìÅË≥™ÂíåÊóãËΩâÁ≠âËÆäÊÄß„ÄÇÊàëÂÄëÂú®Âü∫Ê∫ñË≥áÊñôÈõÜÔºàÂåÖÊã¨ CIFAR-10„ÄÅMNIST Âíå MNIST-MÔºâ‰∏äÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÂΩ±ÂÉèÂìÅË≥™Áç≤Âæó‰∏ÄËá¥ÁöÑÊèêÂçáÔºåÁâπÂà•ÊòØÂú® FID Âíå KID ÂàÜÊï∏ÊñπÈù¢„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã‰øÆÊîπÈÅéÁöÑÊì¥Êï£Á®ãÂ∫èÔºåÂÆÉËÉΩËÆì‰ΩøÁî®ËÄÖÊéßÂà∂ÁîüÊàêÂΩ±ÂÉèÁöÑÊóãËΩâÔºåËÄåÁÑ°ÈúÄÈ°çÂ§ñË®ìÁ∑¥„ÄÇÊàëÂÄëÁöÑÁôºÁèæÁ™ÅÈ°Ø‰∫ÜÁêÜË´ñÈ©ÖÂãïÁöÑÂº∑ÂåñÔºà‰æãÂ¶ÇÁÑ°Ê∑∑ÁñäÈáçÊñ∞ÂèñÊ®£ÔºâÂú®ÁîüÊàêÊ®°Âûã‰∏≠ÁöÑÊΩõÂäõÔºåÂÆÉËÉΩÂú®Á∂≠ÊåÅÊ®°ÂûãÊïàÁéáÁöÑÂêåÊôÇÊèêÂçáÂΩ±ÂÉèÂìÅË≥™Ôºå‰∏¶ÁÇ∫Êú™‰æÜÁ†îÁ©∂ÈñãÊãìÊñπÂêëÔºåÂ∞áÂÖ∂Á¥çÂÖ•ÁîüÊàêÂΩ±ÁâáÁöÑÊì¥Êï£Ê®°Âûã‰∏≠ÔºåÈÄ≤‰∏ÄÊ≠•Êé¢Á¥¢ÁÑ°Ê∑∑ÁñäÈáçÊñ∞ÂèñÊ®£Âú®ÁîüÊàêÊ®°Âûã‰∏≠ÁöÑÊáâÁî®„ÄÇ

##### **Artificial Intelligence for Infectious Disease Prediction and Prevention: A Comprehensive Review**
2411.10486v1 by Selestine Melchane, Youssef Elmir, Farid Kacimi, Larbi Boubchir

Artificial Intelligence (AI) and infectious diseases prediction have recently
experienced a common development and advancement. Machine learning (ML)
apparition, along with deep learning (DL) emergence, extended many approaches
against diseases apparition and their spread. And despite their outstanding
results in predicting infectious diseases, conflicts appeared regarding the
types of data used and how they can be studied, analyzed, and exploited using
various emerging methods. This has led to some ongoing discussions in the
field. This research aims not only to provide an overview of what has been
accomplished, but also to highlight the difficulties related to the types of
data used, and the learning methods applied for each research objective. It
categorizes these contributions into three areas: predictions using Public
Health Data to prevent the spread of a transmissible disease within a region;
predictions using Patients' Medical Data to detect whether a person is infected
by a transmissible disease; and predictions using both Public and patient
medical data to estimate the extent of disease spread in a population. The
paper also critically assesses the potential of AI and outlines its limitations
in infectious disease management.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ËÉΩ (AI) ÂíåÂÇ≥ÊüìÁóÖÈ†êÊ∏¨ÊúÄËøëÁ∂ìÊ≠∑‰∫Ü‰∏ÄÊÆµÂÖ±ÂêåÁôºÂ±ïÂíåÈÄ≤Ê≠•„ÄÇÊ©üÂô®Â≠∏Áøí (ML) ÁöÑÂá∫ÁèæÔºå‰ª•ÂèäÊ∑±Â∫¶Â≠∏Áøí (DL) ÁöÑËààËµ∑ÔºåÊì¥Â±ï‰∫ÜË®±Â§öÂ∞çÊäóÁñæÁóÖÂá∫ÁèæÂèäÂÖ∂ÂÇ≥Êí≠ÁöÑÊñπÊ≥ï„ÄÇÂÑòÁÆ°ÂÆÉÂÄëÂú®È†êÊ∏¨ÂÇ≥ÊüìÁóÖÊñπÈù¢ÂèñÂæó‰∫ÜÂÇëÂá∫ÁöÑÊàêÊûúÔºå‰ΩÜÂ∞çÊñºÊâÄ‰ΩøÁî®Êï∏ÊìöÁöÑÈ°ûÂûã‰ª•ÂèäÂ¶Ç‰Ωï‰ΩøÁî®ÂêÑÁ®ÆÊñ∞ËààÊñπÊ≥ïÂ∞çÂÖ∂ÈÄ≤Ë°åÁ†îÁ©∂„ÄÅÂàÜÊûêÂíåÂà©Áî®ÔºåÂá∫Áèæ‰∫ÜÁà≠Ë≠∞„ÄÇÈÄôÂ∞éËá¥‰∫ÜË©≤È†òÂüüÁöÑ‰∏Ä‰∫õÊåÅÁ∫åË®éË´ñ„ÄÇÊú¨Á†îÁ©∂‰∏çÂÉÖÊó®Âú®Ê¶ÇËø∞Â∑≤ÂèñÂæóÁöÑÊàêÊûúÔºåÈÇÑÊó®Âú®Âº∑Ë™øËàáÊâÄ‰ΩøÁî®Êï∏ÊìöÈ°ûÂûãÁõ∏ÈóúÁöÑÈõ£ÈªûÔºå‰ª•ÂèäÈáùÂ∞çÊØèÂÄãÁ†îÁ©∂ÁõÆÊ®ôÊáâÁî®ÁöÑÂ≠∏ÁøíÊñπÊ≥ï„ÄÇÂÆÉÂ∞áÈÄô‰∫õË≤¢ÁçªÊ≠∏È°ûÁÇ∫‰∏âÂÄãÈ†òÂüüÔºö‰ΩøÁî®ÂÖ¨ÂÖ±Ë°õÁîüÊï∏Êìö‰æÜÈ†êÈò≤ÂÇ≥ÊüìÁóÖÂú®‰∏ÄÂÄãÂú∞ÂçÄÂÖßÂÇ≥Êí≠ÁöÑÈ†êÊ∏¨Ôºõ‰ΩøÁî®ÊÇ£ËÄÖÈÜ´ÁôÇÊï∏Êìö‰æÜÊ™¢Ê∏¨‰∏ÄÂÄã‰∫∫ÊòØÂê¶ÊÑüÊüì‰∫ÜÂÇ≥ÊüìÁóÖÁöÑÈ†êÊ∏¨Ôºõ‰ª•Âèä‰ΩøÁî®ÂÖ¨ÂÖ±ÂíåÊÇ£ËÄÖÈÜ´ÁôÇÊï∏Êìö‰æÜ‰º∞Ë®àÁñæÁóÖÂú®‰∫∫Áæ§‰∏≠ÂÇ≥Êí≠Á®ãÂ∫¶ÁöÑÈ†êÊ∏¨„ÄÇÊú¨ÊñáÈÇÑÊâπÂà§ÊÄßÂú∞Ë©ï‰º∞‰∫Ü‰∫∫Â∑•Êô∫ËÉΩÁöÑÊΩõÂäõÔºå‰∏¶Ê¶ÇËø∞‰∫ÜÂÆÉÂú®ÂÇ≥ÊüìÁóÖÁÆ°ÁêÜ‰∏≠ÁöÑÂ±ÄÈôêÊÄß„ÄÇ

##### **The Limited Impact of Medical Adaptation of Large Language and Vision-Language Models**
2411.08870v1 by Daniel P. Jeong, Pranav Mani, Saurabh Garg, Zachary C. Lipton, Michael Oberst

Several recent works seek to develop foundation models specifically for
medical applications, adapting general-purpose large language models (LLMs) and
vision-language models (VLMs) via continued pretraining on publicly available
biomedical corpora. These works typically claim that such domain-adaptive
pretraining (DAPT) improves performance on downstream medical tasks, such as
answering medical licensing exam questions. In this paper, we compare ten
public "medical" LLMs and two VLMs against their corresponding base models,
arriving at a different conclusion: all medical VLMs and nearly all medical
LLMs fail to consistently improve over their base models in the zero-/few-shot
prompting and supervised fine-tuning regimes for medical question-answering
(QA). For instance, across all tasks and model pairs we consider in the 3-shot
setting, medical LLMs only outperform their base models in 22.7% of cases,
reach a (statistical) tie in 36.8% of cases, and are significantly worse than
their base models in the remaining 40.5% of cases. Our conclusions are based on
(i) comparing each medical model head-to-head, directly against the
corresponding base model; (ii) optimizing the prompts for each model separately
in zero-/few-shot prompting; and (iii) accounting for statistical uncertainty
in comparisons. While these basic practices are not consistently adopted in the
literature, our ablations show that they substantially impact conclusions.
Meanwhile, we find that after fine-tuning on specific QA tasks, medical LLMs
can show performance improvements, but the benefits do not carry over to tasks
based on clinical notes. Our findings suggest that state-of-the-art
general-domain models may already exhibit strong medical knowledge and
reasoning capabilities, and offer recommendations to strengthen the conclusions
of future studies.

ÊëòË¶ÅÔºö<paragraph>ÊúÄËøëÊúâË®±Â§öÁ†îÁ©∂Â∞àÈñÄÈñãÁôºÈÜ´ÁôÇÊáâÁî®Âü∫Á§éÊ®°ÂûãÔºåÈÄèÈÅéÊåÅÁ∫åÈ†êË®ìÁ∑¥ÂÖ¨ÈñãÁöÑÁîüÁâ©ÈÜ´Â≠∏Ë™ûÊñôÂ∫´ÔºåÊîπÁ∑®ÈÄöÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM)„ÄÇÈÄô‰∫õÁ†îÁ©∂ÈÄöÂ∏∏ËÅ≤Á®±Ê≠§È°ûÈ†òÂüüËá™ÈÅ©ÊáâÈ†êË®ìÁ∑¥ (DAPT) ËÉΩÊèêÂçá‰∏ãÊ∏∏ÈÜ´ÁôÇ‰ªªÂãôÁöÑÊïàËÉΩÔºå‰æãÂ¶ÇÂõûÁ≠îÈÜ´ÁôÇÂü∑ÁÖßËÄÉË©¶È°åÁõÆ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊØîËºÉ‰∫ÜÂçÅÂÄãÂÖ¨ÈñãÁöÑ„ÄåÈÜ´ÁôÇ„ÄçLLM ÂíåÂÖ©ÂÄã VLMÔºå‰∏¶Â∞áÂÖ∂ËàáÂ∞çÊáâÁöÑÂü∫Êú¨Ê®°ÂûãÈÄ≤Ë°åÊØîËºÉÔºåÂæóÂá∫‰∫Ü‰∏çÂêåÁöÑÁµêË´ñÔºöÊâÄÊúâÈÜ´ÁôÇ VLM ÂíåÂπæ‰πéÊâÄÊúâÈÜ´ÁôÇ LLM ÈÉΩÁÑ°Ê≥ïÂú®ÈÜ´ÁôÇÂïèÈ°åËß£Á≠î (QA) ÁöÑÈõ∂Ê¨°/Â∞èÊ®£Êú¨ÊèêÁ§∫ÂíåÁõ£Áù£ÂæÆË™øÊ©üÂà∂‰∏≠ÊåÅÁ∫åÂÑ™ÊñºÂÖ∂Âü∫Êú¨Ê®°Âûã„ÄÇ‰æãÂ¶ÇÔºåÂú®ÊàëÂÄëÂú® 3 Ê¨°ÂèñÊ®£Ë®≠ÂÆö‰∏≠ËÄÉÈáèÁöÑÊâÄÊúâ‰ªªÂãôÂíåÊ®°ÂûãÈÖçÂ∞ç‰∏≠ÔºåÈÜ´ÁôÇ LLM ÂÉÖÂú® 22.7% ÁöÑÊ°à‰æã‰∏≠ÂÑ™ÊñºÂÖ∂Âü∫Êú¨Ê®°ÂûãÔºåÂú® 36.8% ÁöÑÊ°à‰æã‰∏≠ÈÅîÂà∞ÔºàÁµ±Ë®àÔºâÂπ≥ÊâãÔºåËÄåÂú®ÂÖ∂È§ò 40.5% ÁöÑÊ°à‰æã‰∏≠ÂâáÈ°ØËëó‰ΩéÊñºÂÖ∂Âü∫Êú¨Ê®°Âûã„ÄÇÊàëÂÄëÁöÑÁµêË´ñÂü∫Êñº (i) Â∞áÊØèÂÄãÈÜ´ÁôÇÊ®°ÂûãËàáÂ∞çÊáâÁöÑÂü∫Êú¨Ê®°ÂûãÈÄ≤Ë°å‰∏ÄÂ∞ç‰∏ÄÊØîËºÉÔºõ(ii) Âú®Èõ∂Ê¨°/Â∞èÊ®£Êú¨ÊèêÁ§∫‰∏≠ÂàÜÂà•ÈáùÂ∞çÊØèÂÄãÊ®°ÂûãÊúÄ‰Ω≥ÂåñÊèêÁ§∫Ôºõ‰ª•Âèä (iii) Âú®ÊØîËºÉ‰∏≠ËÄÉÈáèÁµ±Ë®à‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÂÑòÁÆ°ÈÄô‰∫õÂü∫Êú¨ÂÅöÊ≥ï‰∏¶Êú™Âú®ÊñáÁçª‰∏≠‰∏ÄËá¥Êé°Áî®Ôºå‰ΩÜÊàëÂÄëÁöÑÊ∂àËûçÁ†îÁ©∂È°ØÁ§∫ÔºåÂÆÉÂÄëÂ∞çÁµêË´ñÊúâÈáçÂ§ßÂΩ±Èüø„ÄÇÂêåÊôÇÔºåÊàëÂÄëÁôºÁèæÔºåÂú®ÈáùÂ∞çÁâπÂÆö QA ‰ªªÂãôÈÄ≤Ë°åÂæÆË™øÂæåÔºåÈÜ´ÁôÇ LLM ÂèØ‰ª•Â±ïÁèæÊïàËÉΩÊèêÂçáÔºå‰ΩÜÈÄô‰∫õÂ•ΩËôï‰∏¶Êú™Âª∂Á∫åÂà∞Âü∫ÊñºËá®Â∫äÁ≠ÜË®òÁöÑ‰ªªÂãô„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÊúÄÂÖàÈÄ≤ÁöÑÈÄöÁî®È†òÂüüÊ®°ÂûãÂèØËÉΩÂ∑≤Á∂ìÂ±ïÁèæÂá∫Âº∑Â§ßÁöÑÈÜ´ÁôÇÁü•Ë≠òÂíåÊé®ÁêÜËÉΩÂäõÔºå‰∏¶Êèê‰æõÂª∫Ë≠∞‰ª•Âº∑ÂåñÊú™‰æÜÁ†îÁ©∂ÁöÑÁµêË´ñ„ÄÇ</paragraph>

##### **MVKTrans: Multi-View Knowledge Transfer for Robust Multiomics Classification**
2411.08703v1 by Shan Cong, Zhiling Sang, Hongwei Liu, Haoran Luo, Xin Wang, Hong Liang, Jie Hao, Xiaohui Yao

The distinct characteristics of multiomics data, including complex
interactions within and across biological layers and disease heterogeneity
(e.g., heterogeneity in etiology and clinical symptoms), drive us to develop
novel designs to address unique challenges in multiomics prediction. In this
paper, we propose the multi-view knowledge transfer learning (MVKTrans)
framework, which transfers intra- and inter-omics knowledge in an adaptive
manner by reviewing data heterogeneity and suppressing bias transfer, thereby
enhancing classification performance. Specifically, we design a graph
contrastive module that is trained on unlabeled data to effectively learn and
transfer the underlying intra-omics patterns to the supervised task. This
unsupervised pretraining promotes learning general and unbiased representations
for each modality, regardless of the downstream tasks. In light of the varying
discriminative capacities of modalities across different diseases and/or
samples, we introduce an adaptive and bi-directional cross-omics distillation
module. This module automatically identifies richer modalities and facilitates
dynamic knowledge transfer from more informative to less informative omics,
thereby enabling a more robust and generalized integration. Extensive
experiments on four real biomedical datasets demonstrate the superior
performance and robustness of MVKTrans compared to the state-of-the-art. Code
and data are available at https://github.com/Yaolab-fantastic/MVKTrans.

ÊëòË¶ÅÔºöÂ§öÁµÑÂ≠∏Ë≥áÊñôÁöÑÁç®ÁâπÁâπÂæµÔºåÂåÖÊã¨ÁîüÁâ©Â±§ÂÖßÂíåÂ±§ÈñìÁöÑË§áÈõú‰∫§‰∫í‰ΩúÁî®ÂíåÁñæÁóÖÁï∞Ë≥™ÊÄßÔºà‰æãÂ¶ÇÔºåÁóÖÂõ†ÂíåËá®Â∫äÁóáÁãÄÁöÑÁï∞Ë≥™ÊÄßÔºâÔºå‰øÉ‰ΩøÊàëÂÄëÈñãÁôºÊñ∞Á©éÁöÑË®≠Ë®à‰æÜÊáâÂ∞çÂ§öÁµÑÂ≠∏È†êÊ∏¨‰∏≠ÁöÑÁç®ÁâπÊåëÊà∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂ§öË¶ñËßíÁü•Ë≠òÈÅ∑ÁßªÂ≠∏Áøí (MVKTrans) Ê°ÜÊû∂ÔºåÂÆÉÈÄöÈÅéÂØ©Êü•Êï∏ÊìöÁï∞Ë≥™ÊÄßÂíåÊäëÂà∂ÂÅèÂ∑ÆËΩâÁßªÔºå‰ª•Ëá™ÈÅ©ÊáâÁöÑÊñπÂºèÂÇ≥ÈÅûÁµÑÂÖßÂíåÁµÑÈñìÁü•Ë≠òÔºåÂæûËÄåÂ¢ûÂº∑ÂàÜÈ°ûÊÄßËÉΩ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂúñÂ∞çÊØîÊ®°ÁµÑÔºåÂú®Êú™Ê®ôË®òÊï∏Êìö‰∏äÈÄ≤Ë°åË®ìÁ∑¥Ôºå‰ª•ÊúâÊïàÂú∞Â≠∏ÁøíÂíåÂ∞áÁµÑÂÖßÊ®°ÂºèËΩâÁßªÂà∞Áõ£Áù£‰ªªÂãô‰∏≠„ÄÇÈÄôÁ®ÆÁÑ°Áõ£Áù£ÁöÑÈ†êË®ìÁ∑¥‰øÉÈÄ≤‰∫ÜÂ≠∏Áøí‰∏ÄËà¨‰∏îÁÑ°ÂÅèÂ∑ÆÁöÑË°®Á§∫ÔºåÈÅ©Áî®ÊñºÊØèÂÄãÊ®°ÊÖãÔºåÁÑ°Ë´ñ‰∏ãÊ∏∏‰ªªÂãôÁÇ∫‰Ωï„ÄÇÈëëÊñº‰∏çÂêåÁñæÁóÖÂíå/ÊàñÊ®£Êú¨‰∏≠Ê®°ÊÖãÁöÑ‰∏çÂêåËæ®Âà•ËÉΩÂäõÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãËá™ÈÅ©Êáâ‰∏îÈõôÂêëÁöÑÁµÑÈñìÁü•Ë≠òËí∏È§æÊ®°ÁµÑ„ÄÇÊ≠§Ê®°ÁµÑËá™ÂãïË≠òÂà•Êõ¥Ë±êÂØåÁöÑÊ®°ÊÖãÔºå‰∏¶‰øÉÈÄ≤ÂæûÊõ¥ÊúâË≥áË®äÊÄßÁöÑÁµÑÂ≠∏Âà∞Ë≥áË®äËºÉÂ∞ëÁöÑÁµÑÂ≠∏ÁöÑÂãïÊÖãÁü•Ë≠òËΩâÁßªÔºåÂæûËÄåÂØ¶ÁèæÊõ¥Âº∑ÂÅ•‰∏îÊõ¥Âª£Ê≥õÁöÑÊï¥Âêà„ÄÇÂ∞çÂõõÂÄãÁúüÂØ¶ÁîüÁâ©ÈÜ´Â≠∏Ë≥áÊñôÈõÜÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫Ü MVKTrans ËàáÊúÄÂÖàÈÄ≤ÊäÄË°ìÁõ∏ÊØîÂÖ∑ÊúâÂÑ™Áï∞ÁöÑÊÄßËÉΩÂíåÂº∑ÂÅ•ÊÄß„ÄÇÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÂèØÂú® https://github.com/Yaolab-fantastic/MVKTrans ÂèñÂæó„ÄÇ

##### **TRACE: Transformer-based Risk Assessment for Clinical Evaluation**
2411.08701v1 by Dionysis Christopoulos, Sotiris Spanos, Valsamis Ntouskos, Konstantinos Karantzalos

We present TRACE (Transformer-based Risk Assessment for Clinical Evaluation),
a novel method for clinical risk assessment based on clinical data, leveraging
the self-attention mechanism for enhanced feature interaction and result
interpretation. Our approach is able to handle different data modalities,
including continuous, categorical and multiple-choice (checkbox) attributes.
The proposed architecture features a shared representation of the clinical data
obtained by integrating specialized embeddings of each data modality, enabling
the detection of high-risk individuals using Transformer encoder layers. To
assess the effectiveness of the proposed method, a strong baseline based on
non-negative multi-layer perceptrons (MLPs) is introduced. The proposed method
outperforms various baselines widely used in the domain of clinical risk
assessment, while effectively handling missing values. In terms of
explainability, our Transformer-based method offers easily interpretable
results via attention weights, further enhancing the clinicians'
decision-making process.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫ TRACEÔºàËá®Â∫äË©ï‰º∞ÁöÑÂü∫Êñº Transformer ÁöÑÈ¢®Èö™Ë©ï‰º∞ÔºâÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂü∫ÊñºËá®Â∫äÊï∏ÊìöÁöÑËá®Â∫äÈ¢®Èö™Ë©ï‰º∞Êñ∞ÊñπÊ≥ïÔºåÂà©Áî®Ëá™Ê≥®ÊÑèÂäõÊ©üÂà∂Â¢ûÂº∑ÁâπÂæµ‰∫§‰∫íÂíåÁµêÊûúËß£ËÆÄ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïËÉΩÂ§†ËôïÁêÜ‰∏çÂêåÁöÑÊï∏ÊìöÊ®°ÂºèÔºåÂåÖÊã¨ÈÄ£Á∫å„ÄÅÂàÜÈ°ûÂíåÂ§öÈÅ∏ÔºàÊ†∏ÂèñÊñπÂ°äÔºâÂ±¨ÊÄß„ÄÇÊèêË≠∞ÁöÑÊû∂ÊßãÁâπÂæµÊòØÈÄöÈÅéÊï¥ÂêàÊØèÂÄãÊï∏ÊìöÊ®°ÂºèÁöÑÂ∞àÁî®ÂµåÂÖ•‰æÜÁç≤ÂæóËá®Â∫äÊï∏ÊìöÁöÑÂÖ±‰∫´Ë°®Á§∫ÔºåÂæûËÄåËÉΩÂ§†‰ΩøÁî® Transformer Á∑®Á¢ºÂô®Â±§Ê™¢Ê∏¨È´òÈ¢®Èö™ÂÄãÈ´î„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ÊâÄÊèêÂá∫ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåÂºïÂÖ•‰∫ÜÂü∫ÊñºÈùûË≤†Â§öÂ±§ÊÑüÁü•Âô® (MLP) ÁöÑÂº∑Â§ßÂü∫Á∑ö„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂÑ™ÊñºËá®Â∫äÈ¢®Èö™Ë©ï‰º∞È†òÂüü‰∏≠Âª£Ê≥õ‰ΩøÁî®ÁöÑÂêÑÁ®ÆÂü∫Á∑öÔºåÂêåÊôÇÊúâÊïàÂú∞ËôïÁêÜÁº∫Â§±ÂÄº„ÄÇÂú®ÂèØËß£ÈáãÊÄßÊñπÈù¢ÔºåÊàëÂÄëÂü∫Êñº Transformer ÁöÑÊñπÊ≥ïÈÄöÈÅéÊ≥®ÊÑèÂäõÊ¨äÈáçÊèê‰æõ‰∫ÜÊòìÊñºËß£ÈáãÁöÑÁµêÊûúÔºåÈÄ≤‰∏ÄÊ≠•Â¢ûÂº∑‰∫ÜËá®Â∫äÈÜ´ÁîüÁöÑÊ±∫Á≠ñÂà∂ÂÆöÈÅéÁ®ã„ÄÇ

##### **Rethinking negative sampling in content-based news recommendation**
2411.08700v1 by Miguel √Çngelo Rebelo, Jo√£o Vinagre, Ivo Pereira, √Ålvaro Figueira

News recommender systems are hindered by the brief lifespan of articles, as
they undergo rapid relevance decay. Recent studies have demonstrated the
potential of content-based neural techniques in tackling this problem. However,
these models often involve complex neural architectures and often lack
consideration for negative examples. In this study, we posit that the careful
sampling of negative examples has a big impact on the model's outcome. We
devise a negative sampling technique that not only improves the accuracy of the
model but also facilitates the decentralization of the recommendation system.
The experimental results obtained using the MIND dataset demonstrate that the
accuracy of the method under consideration can compete with that of
State-of-the-Art models. The utilization of the sampling technique is essential
in reducing model complexity and accelerating the training process, while
maintaining a high level of accuracy. Finally, we discuss how decentralized
models can help improve privacy and scalability.

ÊëòË¶ÅÔºöÊñ∞ËÅûÊé®Ëñ¶Á≥ªÁµ±ÂèóÂà∞ÊñáÁ´†ÁîüÂëΩÈÄ±ÊúüÁü≠Êö´ÁöÑÈòªÁ§ôÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÊúÉÂø´ÈÄüË°∞ÈÄÄ„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Â∑≤Ë≠âÊòéÂü∫ÊñºÂÖßÂÆπÁöÑÁ•ûÁ∂ìÊäÄË°ìÂú®Ëß£Ê±∫ÈÄôÂÄãÂïèÈ°å‰∏äÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°ÂûãÈÄöÂ∏∏Ê∂âÂèäË§áÈõúÁöÑÁ•ûÁ∂ìÊû∂ÊßãÔºåËÄå‰∏îÂ∏∏Â∏∏Áº∫‰πèÂ∞çË≤†Èù¢ÁØÑ‰æãÁöÑËÄÉÈáè„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂÅáË®≠Ë≤†Èù¢ÁØÑ‰æãÁöÑ‰ªîÁ¥∞ÊäΩÊ®£Â∞çÊ®°ÂûãÁöÑÁµêÊûúÊúâÂæàÂ§ßÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÁ®ÆË≤†Èù¢ÊäΩÊ®£ÊäÄË°ìÔºåÂÆÉ‰∏çÂÉÖÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÊ∫ñÁ¢∫ÊÄßÔºåÈÇÑ‰øÉËøõ‰∫ÜÊé®Ëñ¶Á≥ªÁµ±ÁöÑÂàÜÊï£Âåñ„ÄÇ‰ΩøÁî® MIND Ë≥áÊñôÈõÜÁç≤ÂæóÁöÑÂØ¶È©óÁµêÊûúË≠âÊòéÔºåÊâÄËÄÉÊÖÆÊñπÊ≥ïÁöÑÊ∫ñÁ¢∫ÊÄßÂèØ‰ª•ËàáÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÁõ∏Â™≤Áæé„ÄÇÊäΩÊ®£ÊäÄË°ìÁöÑ‰ΩøÁî®Â∞çÊñºÈôç‰ΩéÊ®°ÂûãË§áÈõúÊÄßÂíåÂä†ÈÄüË®ìÁ∑¥ÈÅéÁ®ãËá≥ÈóúÈáçË¶ÅÔºåÂêåÊôÇ‰øùÊåÅÈ´òÊ∫ñÁ¢∫Â∫¶„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñ‰∫ÜÂàÜÊï£ÂºèÊ®°ÂûãÂ¶Ç‰ΩïÊúâÂä©ÊñºÊîπÂñÑÈö±ÁßÅÂíåÂèØÊì¥Â±ïÊÄß„ÄÇ

##### **A Survey on Vision Autoregressive Model**
2411.08666v2 by Kai Jiang, Jiaxing Huang

Autoregressive models have demonstrated great performance in natural language
processing (NLP) with impressive scalability, adaptability and
generalizability. Inspired by their notable success in NLP field,
autoregressive models have been intensively investigated recently for computer
vision, which perform next-token predictions by representing visual data as
visual tokens and enables autoregressive modelling for a wide range of vision
tasks, ranging from visual generation and visual understanding to the very
recent multimodal generation that unifies visual generation and understanding
with a single autoregressive model. This paper provides a systematic review of
vision autoregressive models, including the development of a taxonomy of
existing methods and highlighting their major contributions, strengths, and
limitations, covering various vision tasks such as image generation, video
generation, image editing, motion generation, medical image analysis, 3D
generation, robotic manipulation, unified multimodal generation, etc. Besides,
we investigate and analyze the latest advancements in autoregressive models,
including thorough benchmarking and discussion of existing methods across
various evaluation datasets. Finally, we outline key challenges and promising
directions for future research, offering a roadmap to guide further
advancements in vision autoregressive models.

ÊëòË¶ÅÔºöËá™ÂõûÂΩíÊ®°ÂûãÂú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ (NLP) ‰∏≠Â±ïÁé∞‰∫ÜÊûÅ‰Ω≥ÁöÑÊÄßËÉΩÔºåÂÖ∑Êúâ‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÂèØÊâ©Â±ïÊÄß„ÄÅÈÄÇÂ∫îÊÄßÂíåÊ≥õÂåñÊÄß„ÄÇÂèóÂÖ∂Âú® NLP È¢ÜÂüüÁöÑÊòæËëóÊàêÂäüÂêØÂèëÔºåËá™ÂõûÂΩíÊ®°ÂûãÊúÄËøëÂú®ËÆ°ÁÆóÊú∫ËßÜËßâÈ¢ÜÂüüÂæóÂà∞‰∫ÜÊ∑±ÂÖ•Á†îÁ©∂ÔºåÈÄöËøáÂ∞ÜËßÜËßâÊï∞ÊçÆË°®Á§∫‰∏∫ËßÜËßâÊ†áËÆ∞Êù•ÊâßË°å‰∏ã‰∏Ä‰∏™Ê†áËÆ∞È¢ÑÊµãÔºåÂπ∂‰∏∫ÂπøÊ≥õÁöÑËßÜËßâ‰ªªÂä°ÂêØÁî®Ëá™ÂõûÂΩíÂª∫Ê®°Ôºå‰ªéËßÜËßâÁîüÊàêÂíåËßÜËßâÁêÜËß£Âà∞ÊúÄËøëÂ∞ÜËßÜËßâÁîüÊàêÂíåÁêÜËß£Áªü‰∏ÄÂà∞‰∏Ä‰∏™Ëá™ÂõûÂΩíÊ®°Âûã‰∏≠ÁöÑÂ§öÊ®°ÊÄÅÁîüÊàê„ÄÇÊú¨ÊñáÂØπËßÜËßâËá™ÂõûÂΩíÊ®°ÂûãËøõË°å‰∫ÜÁ≥ªÁªüÊÄßÁªºËø∞ÔºåÂåÖÊã¨ÂØπÁé∞ÊúâÊñπÊ≥ïËøõË°åÂàÜÁ±ªÔºåÂπ∂ÈáçÁÇπ‰ªãÁªç‰∫ÜÂÆÉ‰ª¨ÁöÑ‰∏ªË¶ÅË¥°ÁåÆ„ÄÅ‰ºòÁÇπÂíåÂ±ÄÈôêÊÄßÔºåÊ∂µÁõñ‰∫ÜÂõæÂÉèÁîüÊàê„ÄÅËßÜÈ¢ëÁîüÊàê„ÄÅÂõæÂÉèÁºñËæë„ÄÅÂä®‰ΩúÁîüÊàê„ÄÅÂåªÂ≠¶ÂõæÂÉèÂàÜÊûê„ÄÅ3D ÁîüÊàê„ÄÅÊú∫Âô®‰∫∫Êìç‰Ωú„ÄÅÁªü‰∏ÄÂ§öÊ®°ÊÄÅÁîüÊàêÁ≠âÂêÑÁßçËßÜËßâ‰ªªÂä°„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËøòË∞ÉÊü•ÂíåÂàÜÊûê‰∫ÜËá™ÂõûÂΩíÊ®°ÂûãÁöÑÊúÄÊñ∞ËøõÂ±ïÔºåÂåÖÊã¨ÂØπÁé∞ÊúâÊñπÊ≥ïÂú®ÂêÑÁßçËØÑ‰º∞Êï∞ÊçÆÈõÜ‰∏äÁöÑÂÖ®Èù¢Âü∫ÂáÜÊµãËØïÂíåËÆ®ËÆ∫„ÄÇÊúÄÂêéÔºåÊàë‰ª¨Ê¶ÇËø∞‰∫ÜÊú™Êù•Á†îÁ©∂ÁöÑÂÖ≥ÈîÆÊåëÊàòÂíåÊúâÂ∏åÊúõÁöÑÊñπÂêëÔºå‰∏∫ËßÜËßâËá™ÂõûÂΩíÊ®°ÂûãÁöÑËøõ‰∏ÄÊ≠•ÂèëÂ±ïÊèê‰æõ‰∫ÜË∑ØÁ∫øÂõæ„ÄÇ

##### **Optimizing Automatic Summarization of Long Clinical Records Using Dynamic Context Extension:Testing and Evaluation of the NBCE Method**
2411.08586v2 by Guoqing Zhang, Keita Fukuyama, Kazumasa Kishimoto, Tomohiro Kuroda

Summarizing patient clinical notes is vital for reducing documentation
burdens. Current manual summarization makes medical staff struggle. We propose
an automatic method using LLMs, but long inputs cause LLMs to lose context,
reducing output quality especially in small size model. We used a 7B model,
open-calm-7b, enhanced with Native Bayes Context Extend and a redesigned
decoding mechanism to reference one sentence at a time, keeping inputs within
context windows, 2048 tokens. Our improved model achieved near parity with
Google's over 175B Gemini on ROUGE-L metrics with 200 samples, indicating
strong performance using less resources, enhancing automated EMR summarization
feasibility.

ÊëòË¶ÅÔºöÊëòË¶ÅÁóÖÊÇ£Ëá®Â∫äÁ≠ÜË®òÂ∞çÊñºÊ∏õËºïÊñá‰ª∂Ë≤†ÊìîËá≥ÈóúÈáçË¶Å„ÄÇÁõÆÂâçÁöÑÊëòË¶ÅÊâãÂÜäËÆìÈÜ´ÁôÇ‰∫∫Âì°Èõ£‰ª•Êáâ‰ªò„ÄÇÊàëÂÄëÊèêÂá∫‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËá™ÂãïÂåñÊñπÊ≥ïÔºå‰ΩÜÈÅéÈï∑ÁöÑËº∏ÂÖ•ÊúÉÂ∞éËá¥Â§ßÂûãË™ûË®ÄÊ®°ÂûãÂ§±Âéª‰∏ä‰∏ãÊñáÔºåÈôç‰ΩéËº∏Âá∫ÂìÅË≥™ÔºåÁâπÂà•ÊòØÂú®Â∞èÂûãÊ®°Âûã‰∏≠„ÄÇÊàëÂÄë‰ΩøÁî®‰∏ÄÂÄã 7B Ê®°ÂûãÔºåopen-calm-7bÔºå‰∏¶Êê≠ÈÖç Native Bayes Context Extend ÂíåÈáçÊñ∞Ë®≠Ë®àÁöÑËß£Á¢ºÊ©üÂà∂Ôºå‰∏ÄÊ¨°ÂèÉËÄÉ‰∏ÄÂÄãÂè•Â≠êÔºåÂ∞áËº∏ÂÖ•‰øùÊåÅÂú®‰∏ä‰∏ãÊñáË¶ñÁ™ó‰∏≠Ôºå2048 ÂÄãÁ¨¶Ëôü„ÄÇÊàëÂÄëÊîπÈÄ≤ÁöÑÊ®°ÂûãÂú® ROUGE-L ÊåáÊ®ô‰∏äÈÅîÂà∞Êé•Ëøë Google Ë∂ÖÈÅé 175B ÁöÑ GeminiÔºåÊúâ 200 ÂÄãÁØÑÊú¨ÔºåË°®Á§∫‰ΩøÁî®ËºÉÂ∞ëË≥áÊ∫êÂ∞±ËÉΩÊúâÂº∑Â§ßÁöÑÊïàËÉΩÔºåÊèêÂçáËá™ÂãïÂåñÈõªÂ≠êÁóÖÊ≠∑ÊëòË¶ÅÁöÑÂèØË°åÊÄß„ÄÇ

##### **A Heterogeneous Graph Neural Network Fusing Functional and Structural Connectivity for MCI Diagnosis**
2411.08424v1 by Feiyu Yin, Yu Lei, Siyuan Dai, Wenwen Zeng, Guoqing Wu, Liang Zhan, Jinhua Yu

Brain connectivity alternations associated with brain disorders have been
widely reported in resting-state functional imaging (rs-fMRI) and diffusion
tensor imaging (DTI). While many dual-modal fusion methods based on graph
neural networks (GNNs) have been proposed, they generally follow homogenous
fusion ways ignoring rich heterogeneity of dual-modal information. To address
this issue, we propose a novel method that integrates functional and structural
connectivity based on heterogeneous graph neural networks (HGNNs) to better
leverage the rich heterogeneity in dual-modal images. We firstly use blood
oxygen level dependency and whiter matter structure information provided by
rs-fMRI and DTI to establish homo-meta-path, capturing node relationships
within the same modality. At the same time, we propose to establish
hetero-meta-path based on structure-function coupling and brain community
searching to capture relations among cross-modal nodes. Secondly, we further
introduce a heterogeneous graph pooling strategy that automatically balances
homo- and hetero-meta-path, effectively leveraging heterogeneous information
and preventing feature confusion after pooling. Thirdly, based on the
flexibility of heterogeneous graphs, we propose a heterogeneous graph data
augmentation approach that can conveniently address the sample imbalance issue
commonly seen in clinical diagnosis. We evaluate our method on ADNI-3 dataset
for mild cognitive impairment (MCI) diagnosis. Experimental results indicate
the proposed method is effective and superior to other algorithms, with a mean
classification accuracy of 93.3%.

ÊëòË¶ÅÔºöËÖ¶ÈÉ®ÈÄ£ÈÄöÊÄßËÆäÂåñËàáËÖ¶ÈÉ®ÁñæÁóÖÁöÑÈóúËÅØÊÄßÂ∑≤Âú®ÈùúÊÖãÂäüËÉΩÊÄßÂΩ±ÂÉè (rs-fMRI) ÂíåÊì¥Êï£ÂºµÈáèÂΩ±ÂÉè (DTI) ‰∏≠Âª£Ê≥õÂ†±Â∞é„ÄÇÈõñÁÑ∂Â∑≤Á∂ìÊèêÂá∫Ë®±Â§öÂü∫ÊñºÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÁöÑÈõôÊ®°ÊÖãËûçÂêàÊñπÊ≥ïÔºå‰ΩÜÂÆÉÂÄëÈÄöÂ∏∏ÈÅµÂæ™ÂêåË≥™ËûçÂêàÊñπÂºèÔºåÂøΩÁï•‰∫ÜÈõôÊ®°ÊÖãË≥áË®äÁöÑË±êÂØåÁï∞Ë≥™ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÂÆÉÊï¥Âêà‰∫ÜÂü∫ÊñºÁï∞Ë≥™ÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (HGNN) ÁöÑÂäüËÉΩÊÄßÂíåÁµêÊßãÊÄßÈÄ£ÈÄöÊÄßÔºå‰ª•Êõ¥Â•ΩÂú∞Âà©Áî®ÈõôÊ®°ÊÖãÂΩ±ÂÉè‰∏≠ÁöÑË±êÂØåÁï∞Ë≥™ÊÄß„ÄÇÊàëÂÄëÈ¶ñÂÖà‰ΩøÁî® rs-fMRI Âíå DTI Êèê‰æõÁöÑË°ÄÊ∞ßÊøÉÂ∫¶‰æùË≥¥ÊÄßÂíåÁôΩË≥™ÁµêÊßãË≥áË®ä‰æÜÂª∫Á´ãÂêåË≥™ÂÖÉË∑ØÂæëÔºåÊçïÊçâÂêå‰∏ÄÊ®°ÂºèÂÖßÁöÑÁØÄÈªûÈóú‰øÇ„ÄÇÂêåÊôÇÔºåÊàëÂÄëÊèêË≠∞Âª∫Á´ãÂü∫ÊñºÁµêÊßãÂäüËÉΩËÄ¶ÂêàÂíåËÖ¶ÈÉ®Á§æÁæ§ÊêúÂ∞ãÁöÑÁï∞Ë≥™ÂÖÉË∑ØÂæëÔºå‰ª•ÊçïÊçâË∑®Ê®°ÂºèÁØÄÈªû‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÁï∞Ë≥™ÂúñÂΩ¢Ê±†ÂåñÁ≠ñÁï•ÔºåË©≤Á≠ñÁï•Ëá™ÂãïÂπ≥Ë°°ÂêåË≥™ÂíåÁï∞Ë≥™ÂÖÉË∑ØÂæëÔºåÊúâÊïàÂà©Áî®Áï∞Ë≥™Ë≥áË®ä‰∏¶Èò≤Ê≠¢Ê±†ÂåñÂæåÁâπÂæµÊ∑∑Ê∑Ü„ÄÇÁ¨¨‰∏âÔºåÂü∫ÊñºÁï∞Ë≥™ÂúñÂΩ¢ÁöÑÈùàÊ¥ªÊÄßÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁï∞Ë≥™ÂúñÂΩ¢Ë≥áÊñôÊì¥ÂÖÖÊñπÊ≥ïÔºåÂèØ‰ª•Êñπ‰æøÂú∞Ëß£Ê±∫Ëá®Â∫äË®∫Êñ∑‰∏≠Â∏∏Ë¶ãÁöÑÊ®£Êú¨‰∏çÂπ≥Ë°°ÂïèÈ°å„ÄÇÊàëÂÄëÂú® ADNI-3 Ë≥áÊñôÈõÜ‰∏äË©ï‰º∞‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÔºåÁî®ÊñºËºïÂ∫¶Ë™çÁü•ÈöúÁ§ô (MCI) Ë®∫Êñ∑„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÊúâÊïà‰∏îÂÑ™ÊñºÂÖ∂‰ªñÊºîÁÆóÊ≥ïÔºåÂπ≥ÂùáÂàÜÈ°ûÊ∫ñÁ¢∫ÁéáÁÇ∫ 93.3%„ÄÇ

##### **A Fuzzy Reinforcement LSTM-based Long-term Prediction Model for Fault Conditions in Nuclear Power Plants**
2411.08370v1 by Siwei Li, Jiayan Fang, Yichun Wua, Wei Wang, Chengxin Li, Jiangwen Chen

Early fault detection and timely maintenance scheduling can significantly
mitigate operational risks in NPPs and enhance the reliability of operator
decision-making. Therefore, it is necessary to develop an efficient Prognostics
and Health Management (PHM) multi-step prediction model for predicting of
system health status and prompt execution of maintenance operations. In this
study, we propose a novel predictive model that integrates reinforcement
learning with Long Short-Term Memory (LSTM) neural networks and the Expert
Fuzzy Evaluation Method. The model is validated using parameter data for 20
different breach sizes in the Main Steam Line Break (MSLB) accident condition
of the CPR1000 pressurized water reactor simulation model and it demonstrates a
remarkable capability in accurately forecasting NPP parameter changes up to 128
steps ahead (with a time interval of 10 seconds per step, i.e., 1280 seconds),
thereby satisfying the temporal advance requirement for fault prognostics in
NPPs. Furthermore, this method provides an effective reference solution for PHM
applications such as anomaly detection and remaining useful life prediction.

ÊëòË¶ÅÔºöÊó©ÊúüÊïÖÈöúÂÅµÊ∏¨ÂíåÂèäÊôÇÁ∂≠Ë≠∑ÊéíÁ®ãÂèØ‰ª•È°ØËëóÈôç‰ΩéÊ†∏ËÉΩÈõªÂª†ÁöÑÁáüÈÅãÈ¢®Èö™Ôºå‰∏¶ÊèêÂçáÊìç‰Ωú‰∫∫Âì°Ê±∫Á≠ñÁöÑÂèØÈù†ÊÄß„ÄÇÂõ†Ê≠§ÔºåÊúâÂøÖË¶ÅÈñãÁôº‰∏ÄÂÄãÈ´òÊïàÁöÑÈ†êÊ∏¨ËàáÂÅ•Â∫∑ÁÆ°ÁêÜ (PHM) Â§öÊ≠•È©üÈ†êÊ∏¨Ê®°ÂûãÔºåÁî®ÊñºÈ†êÊ∏¨Á≥ªÁµ±ÂÅ•Â∫∑ÁãÄÊÖãÂíåÂèäÊôÇÂü∑Ë°åÁ∂≠Ë≠∑‰ΩúÊ•≠„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂâµÊñ∞ÁöÑÈ†êÊ∏¨Ê®°ÂûãÔºåÂÆÉÊï¥Âêà‰∫ÜÂº∑ÂåñÂ≠∏ÁøíËàáÈï∑ÊúüÁü≠ÊúüË®òÊÜ∂ (LSTM) Á•ûÁ∂ìÁ∂≤Ë∑ØÂíåÂ∞àÂÆ∂Ê®°Á≥äË©ï‰º∞ÊñπÊ≥ï„ÄÇË©≤Ê®°Âûã‰ΩøÁî® CPR1000 Âä†Â£ìÊ∞¥ÂèçÊáâÁàêÊ®°Êì¨Ê®°Âûã‰∏≠‰∏ªËí∏Ê±ΩÁÆ°Á†¥Ë£Ç (MSLB) ‰∫ãÊïÖÊ¢ù‰ª∂‰∏ã 20 Á®Æ‰∏çÂêåÁ†¥Ë£ÇÂ∞∫ÂØ∏ÁöÑÂèÉÊï∏Ë≥áÊñôÈÄ≤Ë°åÈ©óË≠âÔºåÂÆÉÂ±ïÁèæÂá∫Ê∫ñÁ¢∫È†êÊ∏¨Ê†∏ËÉΩÈõªÂª†ÂèÉÊï∏ËÆäÂåñÈï∑ÈÅî 128 ÂÄãÊ≠•È©üÔºàÊØèÂÄãÊ≠•È©üÁöÑÊôÇÈñìÈñìÈöîÁÇ∫ 10 ÁßíÔºåÂç≥ 1280 ÁßíÔºâÁöÑÂçìË∂äËÉΩÂäõÔºåÂæûËÄåÊªøË∂≥Ê†∏ËÉΩÈõªÂª†ÊïÖÈöúÈ†êÊ∏¨ÁöÑÊôÇÈñìÊèêÂâçÈúÄÊ±Ç„ÄÇÊ≠§Â§ñÔºåÊ≠§ÊñπÊ≥ïÁÇ∫Áï∞Â∏∏ÂÅµÊ∏¨ÂíåÂâ©È§ò‰ΩøÁî®Â£ΩÂëΩÈ†êÊ∏¨Á≠â PHM ÊáâÁî®Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÊïàÁöÑÂèÉËÄÉËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **TowerDebias: A Novel Debiasing Method based on the Tower Property**
2411.08297v1 by Norman Matloff, Aditya Mittal

Decision-making processes have increasingly come to rely on sophisticated
machine learning tools, raising concerns about the fairness of their
predictions with respect to any sensitive groups. The widespread use of
commercial black-box machine learning models necessitates careful consideration
of their legal and ethical implications on consumers. In situations where users
have access to these "black-box" models, a key question emerges: how can we
mitigate or eliminate the influence of sensitive attributes, such as race or
gender? We propose towerDebias (tDB), a novel approach designed to reduce the
influence of sensitive variables in predictions made by black-box models. Using
the Tower Property from probability theory, tDB aims to improve prediction
fairness during the post-processing stage in a manner amenable to the
Fairness-Utility Tradeoff. This method is highly flexible, requiring no prior
knowledge of the original model's internal structure, and can be extended to a
range of different applications. We provide a formal improvement theorem for
tDB and demonstrate its effectiveness in both regression and classification
tasks, underscoring its impact on the fairness-utility tradeoff.

ÊëòË¶ÅÔºöÊ±∫Á≠ñÂà∂ÂÆöÈÅéÁ®ãË∂ä‰æÜË∂ä‰æùË≥¥ÊñºÂÖàÈÄ≤Ê©üÂô®Â≠∏ÁøíÂ∑•ÂÖ∑ÔºåÈÄôÂºïËµ∑‰∫Ü‰∫∫ÂÄëÂ∞çÂÖ∂È†êÊ∏¨ÁöÑÂÖ¨Âπ≥ÊÄßÊòØÂê¶ÊúÉÂ∞ç‰ªª‰ΩïÊïèÊÑüÁæ§È´îÈÄ†ÊàêÂΩ±ÈüøÁöÑÊìîÊÜÇ„ÄÇÂïÜÊ•≠ÈªëÁõíÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÂª£Ê≥õ‰ΩøÁî®ÈúÄË¶Å‰ªîÁ¥∞ËÄÉÊÖÆÂÖ∂Â∞çÊ∂àË≤ªËÄÖÁöÑÊ≥ïÂæãÂíåÈÅìÂæ∑ÂΩ±Èüø„ÄÇÂú®‰ΩøÁî®ËÄÖËÉΩÂ§†‰ΩøÁî®ÈÄô‰∫õ„ÄåÈªëÁõí„ÄçÊ®°ÂûãÁöÑÊÉÖÊ≥Å‰∏ãÔºå‰∏ÄÂÄãÈóúÈçµÂïèÈ°åÊµÆÁèæÔºöÊàëÂÄëÂ¶Ç‰ΩïÊ∏õËºïÊàñÊ∂àÈô§ÊïèÊÑüÂ±¨ÊÄßÔºà‰æãÂ¶ÇÁ®ÆÊóèÊàñÊÄßÂà•ÔºâÁöÑÂΩ±ÈüøÔºüÊàëÂÄëÊèêÂá∫ towerDebias (tDB)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÊó®Âú®Ê∏õÂ∞ëÈªëÁõíÊ®°ÂûãÊâÄÂÅöÈ†êÊ∏¨‰∏≠ÊïèÊÑüËÆäÊï∏ÁöÑÂΩ±Èüø„ÄÇtDB ‰ΩøÁî®Ê©üÁéáË´ñ‰∏≠ÁöÑ Tower Â±¨ÊÄßÔºåÊó®Âú®‰ª•ÊúâÂà©ÊñºÂÖ¨Âπ≥ÊÄß-ÊïàÁî®Ê¨äË°°ÁöÑÊñπÂºèÂú®ÂæåËôïÁêÜÈöéÊÆµÊîπÂñÑÈ†êÊ∏¨ÂÖ¨Âπ≥ÊÄß„ÄÇÊ≠§ÊñπÊ≥ïÈùûÂ∏∏ÈùàÊ¥ªÔºå‰∏çÈúÄË¶Å‰∫ãÂÖà‰∫ÜËß£ÂéüÂßãÊ®°ÂûãÁöÑÂÖßÈÉ®ÁµêÊßãÔºå‰∏¶‰∏îÂèØ‰ª•Êì¥Â±ïÂà∞ÂêÑÁ®Æ‰∏çÂêåÁöÑÊáâÁî®Á®ãÂºè„ÄÇÊàëÂÄëÁÇ∫ tDB Êèê‰æõ‰∫ÜÊ≠£ÂºèÁöÑÊîπÈÄ≤ÂÆöÁêÜÔºå‰∏¶Â±ïÁ§∫‰∫ÜÂÆÉÂú®Ëø¥Ê≠∏ÂíåÂàÜÈ°û‰ªªÂãô‰∏≠ÁöÑÊúâÊïàÊÄßÔºåÂº∑Ë™ø‰∫ÜÂÆÉÂ∞çÂÖ¨Âπ≥ÊÄß-ÊïàÁî®Ê¨äË°°ÁöÑÂΩ±Èüø„ÄÇ

##### **Scaling Properties of Diffusion Models for Perceptual Tasks**
2411.08034v3 by Rahul Ravishankar, Zeeshan Patel, Jathushan Rajasegaran, Jitendra Malik

In this paper, we argue that iterative computation with diffusion models
offers a powerful paradigm for not only generation but also visual perception
tasks. We unify tasks such as depth estimation, optical flow, and amodal
segmentation under the framework of image-to-image translation, and show how
diffusion models benefit from scaling training and test-time compute for these
perceptual tasks. Through a careful analysis of these scaling properties, we
formulate compute-optimal training and inference recipes to scale diffusion
models for visual perception tasks. Our models achieve competitive performance
to state-of-the-art methods using significantly less data and compute. To
access our code and models, see https://scaling-diffusion-perception.github.io .

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëË´ñË≠â‰ΩøÁî®Êì¥Êï£Ê®°ÂûãÈÄ≤Ë°åËø≠‰ª£Ë®àÁÆóÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂº∑Â§ßÁöÑÁØÑ‰æãÔºå‰∏çÂÉÖÈÅ©Áî®ÊñºÁîüÊàê‰ªªÂãôÔºå‰πüÈÅ©Áî®ÊñºË¶ñË¶∫ÊÑüÁü•‰ªªÂãô„ÄÇÊàëÂÄëÂ∞áÊ∑±Â∫¶‰º∞Ë®à„ÄÅÂÖâÊµÅÂíåÈùûÊ®°ÊÖãÂàÜÂâ≤Á≠â‰ªªÂãôÁµ±‰∏ÄÂú®ÂúñÂÉèÂà∞ÂúñÂÉèËΩâÊèõÁöÑÊ°ÜÊû∂‰∏ãÔºå‰∏¶Â±ïÁ§∫Êì¥Êï£Ê®°ÂûãÂ¶Ç‰ΩïÂæûÊì¥Â±ïË®ìÁ∑¥ÂíåÊ∏¨Ë©¶ÊôÇÈñìË®àÁÆó‰∏≠ÂèóÁõäÔºå‰ª•Âü∑Ë°åÈÄô‰∫õÊÑüÁü•‰ªªÂãô„ÄÇÈÄèÈÅé‰ªîÁ¥∞ÂàÜÊûêÈÄô‰∫õÊì¥Â±ïÂ±¨ÊÄßÔºåÊàëÂÄëÂà∂ÂÆö‰∫ÜË®àÁÆóÊúÄ‰Ω≥ÁöÑË®ìÁ∑¥ÂíåÊé®Ë´ñÁØÑ‰æãÔºå‰ª•Êì¥Â±ïÁî®ÊñºË¶ñË¶∫ÊÑüÁü•‰ªªÂãôÁöÑÊì¥Êï£Ê®°Âûã„ÄÇÊàëÂÄëÁöÑÊ®°Âûã‰ΩøÁî®ÊòéÈ°ØËºÉÂ∞ëË≥áÊñôÂíåÈÅãÁÆóÔºå‰æøËÉΩÈÅîÂà∞ËàáÊúÄÂÖàÈÄ≤ÊñπÊ≥ïÁõ∏Áï∂ÁöÑÊïàËÉΩ„ÄÇËã•Ë¶ÅÂ≠òÂèñÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåÊ®°ÂûãÔºåË´ãÂèÉÈñ± https://scaling-diffusion-perception.github.io „ÄÇ

##### **Investigating the Effectiveness of Explainability Methods in Parkinson's Detection from Speech**
2411.08013v2 by Eleonora Mancini, Francesco Paissan, Paolo Torroni, Mirco Ravanelli, Cem Subakan

Speech impairments in Parkinson's disease (PD) provide significant early
indicators for diagnosis. While models for speech-based PD detection have shown
strong performance, their interpretability remains underexplored. This study
systematically evaluates several explainability methods to identify PD-specific
speech features, aiming to support the development of accurate, interpretable
models for clinical decision-making in PD diagnosis and monitoring. Our
methodology involves (i) obtaining attributions and saliency maps using
mainstream interpretability techniques, (ii) quantitatively evaluating the
faithfulness of these maps and their combinations obtained via union and
intersection through a range of established metrics, and (iii) assessing the
information conveyed by the saliency maps for PD detection from an auxiliary
classifier. Our results reveal that, while explanations are aligned with the
classifier, they often fail to provide valuable information for domain experts.

ÊëòË¶ÅÔºöÂ∏ïÈáëÊ£ÆÊ∞èÁóá (PD) ÁöÑË®ÄË™ûÈöúÁ§ôÊèê‰æõ‰∫ÜÈáçË¶ÅÁöÑÊó©ÊúüË®∫Êñ∑ÊåáÊ®ô„ÄÇÈõñÁÑ∂Âü∫ÊñºË®ÄË™ûÁöÑ PD Ê™¢Ê∏¨Ê®°ÂûãÂ∑≤È°ØÁ§∫Âá∫Âº∑ÂãÅÁöÑÊïàËÉΩÔºå‰ΩÜÂÖ∂ÂèØËß£ÈáãÊÄß‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Ë®é„ÄÇÊú¨Á†îÁ©∂Á≥ªÁµ±ÊÄßÂú∞Ë©ï‰º∞‰∫ÜÂπæÁ®ÆÂèØËß£ÈáãÊÄßÊñπÊ≥ïÔºå‰ª•Ë≠òÂà• PD ÁâπÊúâÁöÑË®ÄË™ûÁâπÂæµÔºåÊó®Âú®ÊîØÊè¥ÈñãÁôºÊ∫ñÁ¢∫„ÄÅÂèØËß£ÈáãÁöÑÊ®°ÂûãÔºåÁî®Êñº PD Ë®∫Êñ∑ÂíåÁõ£Ê∏¨‰∏≠ÁöÑËá®Â∫äÊ±∫Á≠ñ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÊñπÊ≥ïÂåÖÊã¨Ôºö(i) ‰ΩøÁî®‰∏ªÊµÅÂèØËß£ÈáãÊÄßÊäÄË°ìÁç≤ÂæóÊ≠∏Âõ†ÂíåÈ°ØËëóÊÄßÂúñÔºå(ii) ÂÆöÈáèË©ï‰º∞ÈÄô‰∫õÂúñÂèäÂÖ∂ÈÄöÈÅéËÅØÈõÜÂíå‰∫§ÈõÜÁç≤ÂæóÁöÑÁµÑÂêàÁöÑÂø†ÂØ¶Â∫¶ÔºåÈÄöÈÅé‰∏ÄÁ≥ªÂàóÂ∑≤Âª∫Á´ãÁöÑÊåáÊ®ôÔºå‰ª•Âèä (iii) Ë©ï‰º∞È°ØËëóÊÄßÂúñÂÇ≥ÈÅîÁöÑË≥áË®äÔºåÁî®ÊñºËºîÂä©ÂàÜÈ°ûÂô®ÁöÑ PD Ê™¢Ê∏¨„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÈõñÁÑ∂Ëß£ÈáãËàáÂàÜÈ°ûÂô®‰∏ÄËá¥Ôºå‰ΩÜÂÆÉÂÄëÈÄöÂ∏∏ÁÑ°Ê≥ïÁÇ∫È†òÂüüÂ∞àÂÆ∂Êèê‰æõÊúâÂÉπÂÄºÁöÑË≥áË®ä„ÄÇ

