{"2408.03247": {"publish_time": "2024-08-06", "title": "Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons", "paper_summary": "In this paper, we investigate whether Large Language Models (LLMs) actively\nrecall or retrieve their internal repositories of factual knowledge when faced\nwith reasoning tasks. Through an analysis of LLMs' internal factual recall at\neach reasoning step via Knowledge Neurons, we reveal that LLMs fail to harness\nthe critical factual associations under certain circumstances. Instead, they\ntend to opt for alternative, shortcut-like pathways to answer reasoning\nquestions. By manually manipulating the recall process of parametric knowledge\nin LLMs, we demonstrate that enhancing this recall process directly improves\nreasoning performance whereas suppressing it leads to notable degradation.\nFurthermore, we assess the effect of Chain-of-Thought (CoT) prompting, a\npowerful technique for addressing complex reasoning tasks. Our findings\nindicate that CoT can intensify the recall of factual knowledge by encouraging\nLLMs to engage in orderly and reliable reasoning. Furthermore, we explored how\ncontextual conflicts affect the retrieval of facts during the reasoning process\nto gain a comprehensive understanding of the factual recall behaviors of LLMs.\nCode and data will be available soon.", "paper_summary_zh": "<paragraph>\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u9762\u5c0d\u63a8\u7406\u4efb\u52d9\u6642\uff0c\u662f\u5426\u6703\u4e3b\u52d5\u56de\u61b6\u6216\u6aa2\u7d22\u5176\u5167\u90e8\u4e8b\u5be6\u77e5\u8b58\u5eab\u3002\u900f\u904e\u77e5\u8b58\u795e\u7d93\u5143\u5206\u6790 LLM \u5728\u6bcf\u500b\u63a8\u7406\u6b65\u9a5f\u4e2d\u7684\u5167\u90e8\u4e8b\u5be6\u56de\u61b6\uff0c\u6211\u5011\u767c\u73fe LLM \u5728\u67d0\u4e9b\u60c5\u6cc1\u4e0b\u7121\u6cd5\u5229\u7528\u95dc\u9375\u7684\u4e8b\u5be6\u95dc\u806f\u3002\u76f8\u53cd\u5730\uff0c\u4ed6\u5011\u50be\u5411\u65bc\u9078\u64c7\u66ff\u4ee3\u7684\u6377\u5f91\u9014\u5f91\u4f86\u56de\u7b54\u63a8\u7406\u554f\u984c\u3002\u900f\u904e\u624b\u52d5\u64cd\u4f5c LLM \u4e2d\u53c3\u6578\u5316\u77e5\u8b58\u7684\u56de\u61b6\u904e\u7a0b\uff0c\u6211\u5011\u8b49\u660e\u4e86\u589e\u5f37\u6b64\u56de\u61b6\u904e\u7a0b\u6703\u76f4\u63a5\u6539\u5584\u63a8\u7406\u8868\u73fe\uff0c\u800c\u6291\u5236\u5b83\u5247\u6703\u5c0e\u81f4\u986f\u8457\u7684\u9000\u5316\u3002\u6b64\u5916\uff0c\u6211\u5011\u8a55\u4f30\u4e86\u601d\u60f3\u93c8 (CoT) \u63d0\u793a\u7684\u5f71\u97ff\uff0c\u9019\u662f\u4e00\u7a2e\u89e3\u6c7a\u8907\u96dc\u63a8\u7406\u4efb\u52d9\u7684\u5f37\u5927\u6280\u8853\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u8868\u660e\uff0cCoT \u53ef\u4ee5\u900f\u904e\u9f13\u52f5 LLM \u5f9e\u4e8b\u6709\u5e8f\u4e14\u53ef\u9760\u7684\u63a8\u7406\u4f86\u52a0\u5f37\u5c0d\u4e8b\u5be6\u77e5\u8b58\u7684\u56de\u61b6\u3002\u6b64\u5916\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u80cc\u666f\u885d\u7a81\u5982\u4f55\u5f71\u97ff\u63a8\u7406\u904e\u7a0b\u4e2d\u4e8b\u5be6\u7684\u6aa2\u7d22\uff0c\u4ee5\u5168\u9762\u4e86\u89e3 LLM \u7684\u4e8b\u5be6\u56de\u61b6\u884c\u70ba\u3002\u4ee3\u78bc\u548c\u6578\u64da\u5c07\u5f88\u5feb\u63d0\u4f9b\u3002</paragraph>", "author": "Yifei Wang et.al.", "authors": "Yifei Wang, Yuheng Chen, Wanting Wen, Yu Sheng, Linjing Li, Daniel Dajun Zeng", "id": "2408.03247v1", "paper_url": "http://arxiv.org/abs/2408.03247v1", "repo": "null"}}