{"2502.02249": {"publish_time": "2025-02-04", "title": "Conversation AI Dialog for Medicare powered by Finetuning and Retrieval Augmented Generation", "paper_summary": "Large language models (LLMs) have shown impressive capabilities in natural\nlanguage processing tasks, including dialogue generation. This research aims to\nconduct a novel comparative analysis of two prominent techniques, fine-tuning\nwith LoRA (Low-Rank Adaptation) and the Retrieval-Augmented Generation (RAG)\nframework, in the context of doctor-patient chat conversations with multiple\ndatasets of mixed medical domains. The analysis involves three state-of-the-art\nmodels: Llama-2, GPT, and the LSTM model. Employing real-world doctor-patient\ndialogues, we comprehensively evaluate the performance of models, assessing key\nmetrics such as language quality (perplexity, BLEU score), factual accuracy\n(fact-checking against medical knowledge bases), adherence to medical\nguidelines, and overall human judgments (coherence, empathy, safety). The\nfindings provide insights into the strengths and limitations of each approach,\nshedding light on their suitability for healthcare applications. Furthermore,\nthe research investigates the robustness of the models in handling diverse\npatient queries, ranging from general health inquiries to specific medical\nconditions. The impact of domain-specific knowledge integration is also\nexplored, highlighting the potential for enhancing LLM performance through\ntargeted data augmentation and retrieval strategies.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4efb\u52d9\u4e2d\u5c55\u73fe\u4e86\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u80fd\u529b\uff0c\u5305\u62ec\u5c0d\u8a71\u751f\u6210\u3002\u672c\u7814\u7a76\u65e8\u5728\u5c0d\u5169\u7a2e\u8457\u540d\u7684\u6280\u8853\u9032\u884c\u65b0\u7a4e\u7684\u6bd4\u8f03\u5206\u6790\uff0c\u5373\u5fae\u8abf LoRA (\u4f4e\u79e9\u9069\u61c9) \u548c\u6aa2\u7d22\u589e\u5f37\u751f\u6210 (RAG) \u6846\u67b6\uff0c\u5728\u5177\u6709\u6df7\u5408\u91ab\u7642\u9818\u57df\u7684\u591a\u500b\u8cc7\u6599\u96c6\u7684\u91ab\u60a3\u804a\u5929\u5c0d\u8a71\u4e2d\u3002\u5206\u6790\u6d89\u53ca\u4e09\u500b\u6700\u5148\u9032\u7684\u6a21\u578b\uff1aLlama-2\u3001GPT \u548c LSTM \u6a21\u578b\u3002\u63a1\u7528\u771f\u5be6\u4e16\u754c\u7684\u91ab\u60a3\u5c0d\u8a71\uff0c\u6211\u5011\u5168\u9762\u8a55\u4f30\u6a21\u578b\u7684\u6027\u80fd\uff0c\u8a55\u4f30\u8a9e\u8a00\u54c1\u8cea\uff08\u56f0\u60d1\u5ea6\u3001BLEU \u5206\u6578\uff09\u3001\u4e8b\u5be6\u6e96\u78ba\u6027\uff08\u5c0d\u7167\u91ab\u5b78\u77e5\u8b58\u5eab\u9032\u884c\u4e8b\u5be6\u67e5\u6838\uff09\u3001\u9075\u5b88\u91ab\u7642\u6307\u5357\u4ee5\u53ca\u6574\u9ad4\u4eba\u985e\u5224\u65b7\uff08\u9023\u8cab\u6027\u3001\u540c\u7406\u5fc3\u3001\u5b89\u5168\u6027\uff09\u7b49\u95dc\u9375\u6307\u6a19\u3002\u7814\u7a76\u7d50\u679c\u6df1\u5165\u4e86\u89e3\u4e86\u6bcf\u7a2e\u65b9\u6cd5\u7684\u512a\u9ede\u548c\u9650\u5236\uff0c\u95e1\u660e\u4e86\u5b83\u5011\u9069\u7528\u65bc\u91ab\u7642\u4fdd\u5065\u61c9\u7528\u7684\u9069\u7576\u6027\u3002\u6b64\u5916\uff0c\u8a72\u7814\u7a76\u8abf\u67e5\u4e86\u6a21\u578b\u5728\u8655\u7406\u591a\u6a23\u5316\u60a3\u8005\u67e5\u8a62\u6642\u7684\u7a69\u5065\u6027\uff0c\u7bc4\u570d\u5f9e\u4e00\u822c\u5065\u5eb7\u8a62\u554f\u5230\u7279\u5b9a\u91ab\u7642\u72c0\u6cc1\u3002\u9084\u63a2\u8a0e\u4e86\u7279\u5b9a\u9818\u57df\u77e5\u8b58\u6574\u5408\u7684\u5f71\u97ff\uff0c\u5f37\u8abf\u4e86\u901a\u904e\u6709\u91dd\u5c0d\u6027\u7684\u8cc7\u6599\u64f4\u5145\u548c\u6aa2\u7d22\u7b56\u7565\u4f86\u589e\u5f37 LLM \u6027\u80fd\u7684\u6f5b\u529b\u3002", "author": "Atharva Mangeshkumar Agrawal et.al.", "authors": "Atharva Mangeshkumar Agrawal, Rutika Pandurang Shinde, Vasanth Kumar Bhukya, Ashmita Chakraborty, Sagar Bharat Shah, Tanmay Shukla, Sree Pradeep Kumar Relangi, Nilesh Mutyam", "id": "2502.02249v1", "paper_url": "http://arxiv.org/abs/2502.02249v1", "repo": "null"}}