{"2501.10775": {"publish_time": "2025-01-18", "title": "MedFILIP: Medical Fine-grained Language-Image Pre-training", "paper_summary": "Medical vision-language pretraining (VLP) that leverages naturally-paired\nmedical image-report data is crucial for medical image analysis. However,\nexisting methods struggle to accurately characterize associations between\nimages and diseases, leading to inaccurate or incomplete diagnostic results. In\nthis work, we propose MedFILIP, a fine-grained VLP model, introduces medical\nimage-specific knowledge through contrastive learning, specifically: 1) An\ninformation extractor based on a large language model is proposed to decouple\ncomprehensive disease details from reports, which excels in extracting disease\ndeals through flexible prompt engineering, thereby effectively reducing text\ncomplexity while retaining rich information at a tiny cost. 2) A knowledge\ninjector is proposed to construct relationships between categories and visual\nattributes, which help the model to make judgments based on image features, and\nfosters knowledge extrapolation to unfamiliar disease categories. 3) A semantic\nsimilarity matrix based on fine-grained annotations is proposed, providing\nsmoother, information-richer labels, thus allowing fine-grained image-text\nalignment. 4) We validate MedFILIP on numerous datasets, e.g., RSNA-Pneumonia,\nNIH ChestX-ray14, VinBigData, and COVID-19. For single-label, multi-label, and\nfine-grained classification, our model achieves state-of-the-art performance,\nthe classification accuracy has increased by a maximum of 6.69\\%. The code is\navailable in https://github.com/PerceptionComputingLab/MedFILIP.", "paper_summary_zh": "\u91ab\u5b78\u5f71\u50cf\u8a9e\u8a00\u9810\u8a13\u7df4\uff08VLP\uff09\u5229\u7528\u81ea\u7136\u914d\u5c0d\u7684\u91ab\u5b78\u5f71\u50cf\u5831\u544a\u6578\u64da\uff0c\u5c0d\u65bc\u91ab\u5b78\u5f71\u50cf\u5206\u6790\u81f3\u95dc\u91cd\u8981\u3002\u7136\u800c\uff0c\u73fe\u6709\u65b9\u6cd5\u96e3\u4ee5\u6e96\u78ba\u63cf\u8ff0\u5f71\u50cf\u8207\u75be\u75c5\u4e4b\u9593\u7684\u95dc\u806f\u6027\uff0c\u5c0e\u81f4\u8a3a\u65b7\u7d50\u679c\u4e0d\u6e96\u78ba\u6216\u4e0d\u5b8c\u6574\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa MedFILIP\uff0c\u4e00\u500b\u7d30\u7c92\u5ea6\u7684 VLP \u6a21\u578b\uff0c\u900f\u904e\u5c0d\u6bd4\u5b78\u7fd2\u5f15\u5165\u91ab\u5b78\u5f71\u50cf\u7279\u5b9a\u77e5\u8b58\uff0c\u5177\u9ad4\u4f86\u8aaa\uff1a1) \u63d0\u51fa\u4e00\u500b\u57fa\u65bc\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u8cc7\u8a0a\u8403\u53d6\u5668\uff0c\u5f9e\u5831\u544a\u4e2d\u89e3\u8026\u5168\u9762\u7684\u75be\u75c5\u7d30\u7bc0\uff0c\u900f\u904e\u9748\u6d3b\u7684\u63d0\u793a\u5de5\u7a0b\uff0c\u5728\u63d0\u53d6\u75be\u75c5\u4ea4\u6613\u65b9\u9762\u8868\u73fe\u51fa\u8272\uff0c\u5f9e\u800c\u6709\u6548\u964d\u4f4e\u6587\u5b57\u8907\u96dc\u6027\uff0c\u540c\u6642\u4ee5\u6975\u5c0f\u7684\u4ee3\u50f9\u4fdd\u7559\u8c50\u5bcc\u7684\u8cc7\u8a0a\u30022) \u63d0\u51fa\u4e00\u500b\u77e5\u8b58\u6ce8\u5165\u5668\uff0c\u7528\u65bc\u5efa\u69cb\u985e\u5225\u8207\u8996\u89ba\u5c6c\u6027\u4e4b\u9593\u7684\u95dc\u4fc2\uff0c\u9019\u6709\u52a9\u65bc\u6a21\u578b\u6839\u64da\u5f71\u50cf\u7279\u5fb5\u9032\u884c\u5224\u65b7\uff0c\u4e26\u4fc3\u9032\u77e5\u8b58\u5916\u63a8\u5230\u4e0d\u719f\u6089\u7684\u75be\u75c5\u985e\u5225\u30023) \u63d0\u51fa\u4e00\u500b\u57fa\u65bc\u7d30\u7c92\u5ea6\u8a3b\u89e3\u7684\u8a9e\u7fa9\u76f8\u4f3c\u77e9\u9663\uff0c\u63d0\u4f9b\u66f4\u5e73\u6ed1\u3001\u8cc7\u8a0a\u66f4\u8c50\u5bcc\u7684\u6a19\u7c64\uff0c\u5f9e\u800c\u5141\u8a31\u9032\u884c\u7d30\u7c92\u5ea6\u7684\u5f71\u50cf\u6587\u5b57\u5c0d\u9f4a\u30024) \u6211\u5011\u5728\u8a31\u591a\u8cc7\u6599\u96c6\u4e0a\u9a57\u8b49 MedFILIP\uff0c\u4f8b\u5982 RSNA-Pneumonia\u3001NIH ChestX-ray14\u3001VinBigData \u548c COVID-19\u3002\u5c0d\u65bc\u55ae\u6a19\u7c64\u3001\u591a\u6a19\u7c64\u548c\u7d30\u7c92\u5ea6\u5206\u985e\uff0c\u6211\u5011\u7684\u6a21\u578b\u9054\u5230\u4e86\u6700\u5148\u9032\u7684\u6548\u80fd\uff0c\u5206\u985e\u6e96\u78ba\u7387\u6700\u9ad8\u63d0\u9ad8\u4e86 6.69%\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/PerceptionComputingLab/MedFILIP \u4e2d\u53d6\u5f97\u3002", "author": "Xinjie Liang et.al.", "authors": "Xinjie Liang, Xiangyu Li, Fanding Li, Jie Jiang, Qing Dong, Wei Wang, Kuanquan Wang, Suyu Dong, Gongning Luo, Shuo Li", "id": "2501.10775v1", "paper_url": "http://arxiv.org/abs/2501.10775v1", "repo": "https://github.com/perceptioncomputinglab/medfilip"}}