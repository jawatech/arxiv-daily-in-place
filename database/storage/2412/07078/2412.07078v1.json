{"2412.07078": {"publish_time": "2024-12-10", "title": "Defensive Dual Masking for Robust Adversarial Defense", "paper_summary": "The field of textual adversarial defenses has gained considerable attention\nin recent years due to the increasing vulnerability of natural language\nprocessing (NLP) models to adversarial attacks, which exploit subtle\nperturbations in input text to deceive models. This paper introduces the\nDefensive Dual Masking (DDM) algorithm, a novel approach designed to enhance\nmodel robustness against such attacks. DDM utilizes a unique adversarial\ntraining strategy where [MASK] tokens are strategically inserted into training\nsamples to prepare the model to handle adversarial perturbations more\neffectively. During inference, potentially adversarial tokens are dynamically\nreplaced with [MASK] tokens to neutralize potential threats while preserving\nthe core semantics of the input. The theoretical foundation of our approach is\nexplored, demonstrating how the selective masking mechanism strengthens the\nmodel's ability to identify and mitigate adversarial manipulations. Our\nempirical evaluation across a diverse set of benchmark datasets and attack\nmechanisms consistently shows that DDM outperforms state-of-the-art defense\ntechniques, improving model accuracy and robustness. Moreover, when applied to\nLarge Language Models (LLMs), DDM also enhances their resilience to adversarial\nattacks, providing a scalable defense mechanism for large-scale NLP\napplications.", "paper_summary_zh": "\u8fd1\u5e74\u4f86\uff0c\u7531\u65bc\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u6a21\u578b\u8d8a\u4f86\u8d8a\u5bb9\u6613\u53d7\u5230\u5c0d\u6297\u6027\u653b\u64ca\uff0c\u800c\u5c0d\u6297\u6027\u9632\u79a6\u9818\u57df\u5df2\u7372\u5f97\u76f8\u7576\u5927\u7684\u95dc\u6ce8\uff0c\u5c0d\u6297\u6027\u653b\u64ca\u5229\u7528\u8f38\u5165\u6587\u5b57\u4e2d\u7684\u7d30\u5fae\u64fe\u52d5\u4f86\u6b3a\u9a19\u6a21\u578b\u3002\u672c\u6587\u4ecb\u7d39\u4e86\u9632\u79a6\u6027\u96d9\u91cd\u906e\u7f69 (DDM) \u6f14\u7b97\u6cd5\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u589e\u5f37\u6a21\u578b\u5c0d\u6b64\u985e\u653b\u64ca\u7684\u7a69\u5065\u6027\u3002DDM \u5229\u7528\u4e00\u7a2e\u7368\u7279\u7684\u5c0d\u6297\u6027\u8a13\u7df4\u7b56\u7565\uff0c\u5c07 [MASK] \u6a19\u8a18\u7b56\u7565\u6027\u5730\u63d2\u5165\u8a13\u7df4\u6a23\u672c\u4e2d\uff0c\u4ee5\u6e96\u5099\u6a21\u578b\u66f4\u6709\u6548\u5730\u8655\u7406\u5c0d\u6297\u6027\u64fe\u52d5\u3002\u5728\u63a8\u7406\u671f\u9593\uff0c\u6f5b\u5728\u7684\u5c0d\u6297\u6027\u6a19\u8a18\u6703\u52d5\u614b\u66ff\u63db\u70ba [MASK] \u6a19\u8a18\uff0c\u4ee5\u5728\u4fdd\u7559\u8f38\u5165\u6838\u5fc3\u8a9e\u7fa9\u7684\u540c\u6642\uff0c\u6d88\u9664\u6f5b\u5728\u5a01\u8105\u3002\u63a2\u8a0e\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u7406\u8ad6\u57fa\u790e\uff0c\u5c55\u793a\u4e86\u9078\u64c7\u6027\u906e\u7f69\u6a5f\u5236\u5982\u4f55\u589e\u5f37\u6a21\u578b\u8b58\u5225\u548c\u6e1b\u8f15\u5c0d\u6297\u6027\u64cd\u7e31\u7684\u80fd\u529b\u3002\u6211\u5011\u5728\u5404\u7a2e\u57fa\u6e96\u8cc7\u6599\u96c6\u548c\u653b\u64ca\u6a5f\u5236\u4e2d\u9032\u884c\u7684\u5be6\u8b49\u8a55\u4f30\u6301\u7e8c\u986f\u793a\uff0cDDM \u512a\u65bc\u6700\u5148\u9032\u7684\u9632\u79a6\u6280\u8853\uff0c\u6539\u5584\u4e86\u6a21\u578b\u7684\u6e96\u78ba\u6027\u548c\u7a69\u5065\u6027\u3002\u6b64\u5916\uff0c\u7576\u61c9\u7528\u65bc\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6642\uff0cDDM \u4e5f\u589e\u5f37\u4e86\u5b83\u5011\u5c0d\u6297\u6027\u653b\u64ca\u7684\u97cc\u6027\uff0c\u70ba\u5927\u898f\u6a21 NLP \u61c9\u7528\u63d0\u4f9b\u4e86\u4e00\u7a2e\u53ef\u64f4\u5145\u7684\u9632\u79a6\u6a5f\u5236\u3002", "author": "Wangli Yang et.al.", "authors": "Wangli Yang, Jie Yang, Yi Guo, Johan Barthelemy", "id": "2412.07078v1", "paper_url": "http://arxiv.org/abs/2412.07078v1", "repo": "null"}}