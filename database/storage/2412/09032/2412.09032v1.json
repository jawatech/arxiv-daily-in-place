{"2412.09032": {"publish_time": "2024-12-12", "title": "Speech-Forensics: Towards Comprehensive Synthetic Speech Dataset Establishment and Analysis", "paper_summary": "Detecting synthetic from real speech is increasingly crucial due to the risks\nof misinformation and identity impersonation. While various datasets for\nsynthetic speech analysis have been developed, they often focus on specific\nareas, limiting their utility for comprehensive research. To fill this gap, we\npropose the Speech-Forensics dataset by extensively covering authentic,\nsynthetic, and partially forged speech samples that include multiple segments\nsynthesized by different high-quality algorithms. Moreover, we propose a\nTEmporal Speech LocalizaTion network, called TEST, aiming at simultaneously\nperforming authenticity detection, multiple fake segments localization, and\nsynthesis algorithms recognition, without any complex post-processing. TEST\neffectively integrates LSTM and Transformer to extract more powerful temporal\nspeech representations and utilizes dense prediction on multi-scale pyramid\nfeatures to estimate the synthetic spans. Our model achieves an average mAP of\n83.55% and an EER of 5.25% at the utterance level. At the segment level, it\nattains an EER of 1.07% and a 92.19% F1 score. These results highlight the\nmodel's robust capability for a comprehensive analysis of synthetic speech,\noffering a promising avenue for future research and practical applications in\nthis field.", "paper_summary_zh": "\u7531\u65bc\u932f\u8aa4\u8cc7\u8a0a\u548c\u8eab\u5206\u5192\u7528\u7684\u98a8\u96aa\uff0c\u5075\u6e2c\u5408\u6210\u8a9e\u97f3\u548c\u771f\u5be6\u8a9e\u97f3\u8b8a\u5f97\u8d8a\u4f86\u8d8a\u91cd\u8981\u3002\u96d6\u7136\u5df2\u7d93\u958b\u767c\u51fa\u5404\u7a2e\u5408\u6210\u8a9e\u97f3\u5206\u6790\u7684\u8cc7\u6599\u96c6\uff0c\u4f46\u5b83\u5011\u901a\u5e38\u5c08\u6ce8\u65bc\u7279\u5b9a\u9818\u57df\uff0c\u9650\u5236\u4e86\u5b83\u5011\u5728\u7d9c\u5408\u7814\u7a76\u4e2d\u7684\u6548\u7528\u3002\u70ba\u4e86\u586b\u88dc\u9019\u500b\u7f3a\u53e3\uff0c\u6211\u5011\u63d0\u51fa Speech-Forensics \u8cc7\u6599\u96c6\uff0c\u5ee3\u6cdb\u6db5\u84cb\u771f\u5be6\u3001\u5408\u6210\u548c\u90e8\u5206\u507d\u9020\u7684\u8a9e\u97f3\u6a23\u672c\uff0c\u5176\u4e2d\u5305\u62ec\u7531\u4e0d\u540c\u9ad8\u54c1\u8cea\u6f14\u7b97\u6cd5\u5408\u6210\u7684\u591a\u500b\u5340\u6bb5\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u7a31\u70ba TEST \u7684\u6642\u9593\u8a9e\u97f3\u5b9a\u4f4d\u7db2\u8def\uff0c\u65e8\u5728\u540c\u6642\u57f7\u884c\u771f\u5be6\u6027\u5075\u6e2c\u3001\u591a\u500b\u507d\u9020\u5340\u6bb5\u5b9a\u4f4d\u548c\u5408\u6210\u6f14\u7b97\u6cd5\u8fa8\u8b58\uff0c\u800c\u7121\u9700\u4efb\u4f55\u8907\u96dc\u7684\u5f8c\u8655\u7406\u3002TEST \u6709\u6548\u5730\u6574\u5408 LSTM \u548c Transformer \u4ee5\u63d0\u53d6\u66f4\u5f37\u5927\u7684\u6642\u9593\u8a9e\u97f3\u8868\u793a\uff0c\u4e26\u5229\u7528\u591a\u5c3a\u5ea6\u91d1\u5b57\u5854\u7279\u5fb5\u4e0a\u7684\u5bc6\u96c6\u9810\u6e2c\u4f86\u4f30\u8a08\u5408\u6210\u8de8\u5ea6\u3002\u6211\u5011\u7684\u6a21\u578b\u5728\u8a9e\u53e5\u5c64\u7d1a\u9054\u5230\u4e86 83.55% \u7684\u5e73\u5747 mAP \u548c 5.25% \u7684 EER\u3002\u5728\u5340\u6bb5\u5c64\u7d1a\uff0c\u5b83\u9054\u5230\u4e86 1.07% \u7684 EER \u548c 92.19% \u7684 F1 \u5206\u6578\u3002\u9019\u4e9b\u7d50\u679c\u7a81\u986f\u4e86\u8a72\u6a21\u578b\u5728\u5408\u6210\u8a9e\u97f3\u7d9c\u5408\u5206\u6790\u65b9\u9762\u7684\u5f37\u5927\u529f\u80fd\uff0c\u70ba\u6b64\u9818\u57df\u672a\u4f86\u7684\u7814\u7a76\u548c\u5be6\u969b\u61c9\u7528\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f91\u3002", "author": "Zhoulin Ji et.al.", "authors": "Zhoulin Ji, Chenhao Lin, Hang Wang, Chao Shen", "id": "2412.09032v1", "paper_url": "http://arxiv.org/abs/2412.09032v1", "repo": "null"}}