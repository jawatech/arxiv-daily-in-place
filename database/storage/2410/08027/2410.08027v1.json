{"2410.08027": {"publish_time": "2024-10-10", "title": "Private Language Models via Truncated Laplacian Mechanism", "paper_summary": "Deep learning models for NLP tasks are prone to variants of privacy attacks.\nTo prevent privacy leakage, researchers have investigated word-level\nperturbations, relying on the formal guarantees of differential privacy (DP) in\nthe embedding space. However, many existing approaches either achieve\nunsatisfactory performance in the high privacy regime when using the Laplacian\nor Gaussian mechanism, or resort to weaker relaxations of DP that are inferior\nto the canonical DP in terms of privacy strength. This raises the question of\nwhether a new method for private word embedding can be designed to overcome\nthese limitations. In this paper, we propose a novel private embedding method\ncalled the high dimensional truncated Laplacian mechanism. Specifically, we\nintroduce a non-trivial extension of the truncated Laplacian mechanism, which\nwas previously only investigated in one-dimensional space cases. Theoretically,\nwe show that our method has a lower variance compared to the previous private\nword embedding methods. To further validate its effectiveness, we conduct\ncomprehensive experiments on private embedding and downstream tasks using three\ndatasets. Remarkably, even in the high privacy regime, our approach only incurs\na slight decrease in utility compared to the non-private scenario.", "paper_summary_zh": "\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\u5c0d\u65bc\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4efb\u52d9\u5bb9\u6613\u53d7\u5230\u5404\u7a2e\u96b1\u79c1\u653b\u64ca\u3002\n\u70ba\u4e86\u9632\u6b62\u96b1\u79c1\u5916\u6d29\uff0c\u7814\u7a76\u4eba\u54e1\u5df2\u7d93\u7814\u7a76\u4e86\u8a5e\u7d1a\u64fe\u52d5\uff0c\u4f9d\u8cf4\u65bc\u5d4c\u5165\u7a7a\u9593\u4e2d\u5dee\u5206\u96b1\u79c1 (DP) \u7684\u6b63\u5f0f\u4fdd\u8b49\u3002\u7136\u800c\uff0c\u8a31\u591a\u73fe\u6709\u65b9\u6cd5\u5728\u4f7f\u7528\u62c9\u666e\u62c9\u65af\u6216\u9ad8\u65af\u6a5f\u5236\u6642\uff0c\u5728\u9ad8\u96b1\u79c1\u6a5f\u5236\u4e2d\u7121\u6cd5\u9054\u5230\u4ee4\u4eba\u6eff\u610f\u7684\u6548\u80fd\uff0c\u6216\u8a34\u8af8\u65bc DP \u7684\u8f03\u5f31\u653e\u5bec\uff0c\u5176\u96b1\u79c1\u5f37\u5ea6\u4f4e\u65bc\u6b63\u898f DP\u3002\u9019\u5f15\u767c\u4e86\u4e00\u500b\u554f\u984c\uff0c\u5373\u662f\u5426\u53ef\u4ee5\u8a2d\u8a08\u4e00\u7a2e\u65b0\u7684\u79c1\u6709\u8a5e\u5d4c\u5165\u65b9\u6cd5\u4f86\u514b\u670d\u9019\u4e9b\u9650\u5236\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7684\u79c1\u6709\u5d4c\u5165\u65b9\u6cd5\uff0c\u7a31\u70ba\u9ad8\u7dad\u622a\u65b7\u62c9\u666e\u62c9\u65af\u6a5f\u5236\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u5f15\u5165\u4e86\u622a\u65b7\u62c9\u666e\u62c9\u65af\u6a5f\u5236\u7684\u975e\u5e73\u51e1\u64f4\u5145\uff0c\u8a72\u6a5f\u5236\u4ee5\u524d\u50c5\u5728 \u043e\u0434\u043d\u043e\u043c\u0435\u0440\u043d\u043e\u043c \u7a7a\u9593\u6848\u4f8b\u4e2d\u9032\u884c\u7814\u7a76\u3002\u5728\u7406\u8ad6\u4e0a\uff0c\u6211\u5011\u8868\u660e\u8207\u5148\u524d\u7684\u79c1\u6709\u8a5e\u5d4c\u5165\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6211\u5011\u7684\u65b9\u200b\u200b\u6cd5\u5177\u6709\u8f03\u4f4e\u7684\u8b8a\u7570\u6027\u3002\u70ba\u4e86\u9032\u4e00\u6b65\u9a57\u8b49\u5176\u6709\u6548\u6027\uff0c\u6211\u5011\u4f7f\u7528\u4e09\u500b\u8cc7\u6599\u96c6\u5c0d\u79c1\u6709\u5d4c\u5165\u548c\u4e0b\u6e38\u4efb\u52d9\u9032\u884c\u4e86\u5168\u9762\u7684\u5be6\u9a57\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5373\u4f7f\u5728\u9ad8\u96b1\u79c1\u6a5f\u5236\u4e2d\uff0c\u8207\u975e\u79c1\u6709\u5834\u666f\u76f8\u6bd4\uff0c\u6211\u5011\u7684\u65b9\u200b\u200b\u6cd5\u50c5\u5c0e\u81f4\u6548\u7528\u7565\u6709\u4e0b\u964d\u3002", "author": "Tianhao Huang et.al.", "authors": "Tianhao Huang, Tao Yang, Ivan Habernal, Lijie Hu, Di Wang", "id": "2410.08027v1", "paper_url": "http://arxiv.org/abs/2410.08027v1", "repo": "null"}}