{"2406.02543": {"publish_time": "2024-06-04", "title": "To Believe or Not to Believe Your LLM", "paper_summary": "We explore uncertainty quantification in large language models (LLMs), with\nthe goal to identify when uncertainty in responses given a query is large. We\nsimultaneously consider both epistemic and aleatoric uncertainties, where the\nformer comes from the lack of knowledge about the ground truth (such as about\nfacts or the language), and the latter comes from irreducible randomness (such\nas multiple possible answers). In particular, we derive an\ninformation-theoretic metric that allows to reliably detect when only epistemic\nuncertainty is large, in which case the output of the model is unreliable. This\ncondition can be computed based solely on the output of the model obtained\nsimply by some special iterative prompting based on the previous responses.\nSuch quantification, for instance, allows to detect hallucinations (cases when\nepistemic uncertainty is high) in both single- and multi-answer responses. This\nis in contrast to many standard uncertainty quantification strategies (such as\nthresholding the log-likelihood of a response) where hallucinations in the\nmulti-answer case cannot be detected. We conduct a series of experiments which\ndemonstrate the advantage of our formulation. Further, our investigations shed\nsome light on how the probabilities assigned to a given output by an LLM can be\namplified by iterative prompting, which might be of independent interest.", "paper_summary_zh": "\u6211\u5011\u63a2\u8a0e\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4e2d\u7684\u4e0d\u78ba\u5b9a\u6027\u91cf\u5316\uff0c\u76ee\u6a19\u662f\u627e\u51fa\u5728\u7d66\u5b9a\u67e5\u8a62\u6642\uff0c\u56de\u61c9\u4e2d\u7684\u4e0d\u78ba\u5b9a\u6027\u5f88\u5927\u7684\u60c5\u6cc1\u3002\u6211\u5011\u540c\u6642\u8003\u616e\u8a8d\u8b58\u8ad6\u548c\u96a8\u6a5f\u4e0d\u78ba\u5b9a\u6027\uff0c\u524d\u8005\u4f86\u81ea\u5c0d\u57fa\u672c\u4e8b\u5be6\uff08\u4f8b\u5982\u95dc\u65bc\u4e8b\u5be6\u6216\u8a9e\u8a00\uff09\u7684\u77e5\u8b58\u7f3a\u4e4f\uff0c\u5f8c\u8005\u4f86\u81ea\u4e0d\u53ef\u7d04\u7684\u96a8\u6a5f\u6027\uff08\u4f8b\u5982\u591a\u500b\u53ef\u80fd\u7684\u7b54\u6848\uff09\u3002\u7279\u5225\u662f\uff0c\u6211\u5011\u63a8\u5c0e\u51fa\u4e00\u500b\u8cc7\u8a0a\u7406\u8ad6\u6307\u6a19\uff0c\u53ef\u4ee5\u53ef\u9760\u5730\u6aa2\u6e2c\u5230\u53ea\u6709\u8a8d\u8b58\u8ad6\u4e0d\u78ba\u5b9a\u6027\u5f88\u5927\u7684\u60c5\u6cc1\uff0c\u5728\u9019\u7a2e\u60c5\u6cc1\u4e0b\uff0c\u6a21\u578b\u7684\u8f38\u51fa\u662f\u4e0d\u53ef\u9760\u7684\u3002\u9019\u500b\u689d\u4ef6\u53ef\u4ee5\u50c5\u6839\u64da\u6a21\u578b\u7684\u8f38\u51fa\u8a08\u7b97\uff0c\u800c\u8a72\u8f38\u51fa\u50c5\u900f\u904e\u57fa\u65bc\u5148\u524d\u56de\u61c9\u7684\u4e00\u4e9b\u7279\u6b8a\u53cd\u8986\u63d0\u793a\u7372\u5f97\u3002\u4f8b\u5982\uff0c\u9019\u7a2e\u91cf\u5316\u5141\u8a31\u5728\u55ae\u4e00\u548c\u591a\u91cd\u7b54\u6848\u56de\u61c9\u4e2d\u6aa2\u6e2c\u5230\u5e7b\u89ba\uff08\u8a8d\u8b58\u8ad6\u4e0d\u78ba\u5b9a\u6027\u5f88\u9ad8\u7684\u60c5\u6cc1\uff09\u3002\u9019\u8207\u8a31\u591a\u6a19\u6e96\u4e0d\u78ba\u5b9a\u6027\u91cf\u5316\u7b56\u7565\uff08\u4f8b\u5982\u5c0d\u61c9\u7b54\u7684\u5c0d\u6578\u4f3c\u7136\u6027\u8a2d\u5b9a\u95be\u503c\uff09\u5f62\u6210\u5c0d\u6bd4\uff0c\u5728\u591a\u91cd\u7b54\u6848\u60c5\u6cc1\u4e0b\u7121\u6cd5\u6aa2\u6e2c\u5230\u5e7b\u89ba\u3002\u6211\u5011\u9032\u884c\u4e86\u4e00\u7cfb\u5217\u5be6\u9a57\uff0c\u8b49\u660e\u4e86\u6211\u5011\u516c\u5f0f\u7684\u512a\u9ede\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684\u8abf\u67e5\u63ed\u793a\u4e86\u4e00\u4e9b\u898b\u89e3\uff0c\u8aaa\u660e LLM \u5206\u914d\u7d66\u7279\u5b9a\u8f38\u51fa\u7684\u6a5f\u7387\u5982\u4f55\u900f\u904e\u53cd\u8986\u63d0\u793a\u800c\u653e\u5927\uff0c\u9019\u53ef\u80fd\u5177\u6709\u7368\u7acb\u7684\u8208\u8da3\u3002", "author": "Yasin Abbasi Yadkori et.al.", "authors": "Yasin Abbasi Yadkori, Ilja Kuzborskij, Andr\u00e1s Gy\u00f6rgy, Csaba Szepesv\u00e1ri", "id": "2406.02543v1", "paper_url": "http://arxiv.org/abs/2406.02543v1", "repo": "null"}}