{"2412.04167": {"publish_time": "2024-12-05", "title": "Bench-CoE: a Framework for Collaboration of Experts from Benchmark", "paper_summary": "Large Language Models (LLMs) are key technologies driving intelligent systems\nto handle multiple tasks. To meet the demands of various tasks, an increasing\nnumber of LLMs-driven experts with diverse capabilities have been developed,\naccompanied by corresponding benchmarks to evaluate their performance. This\npaper proposes the Bench-CoE framework, which enables Collaboration of Experts\n(CoE) by effectively leveraging benchmark evaluations to achieve optimal\nperformance across various tasks. Bench-CoE includes a set of expert models, a\nrouter for assigning tasks to corresponding experts, and a benchmark dataset\nfor training the router. Moreover, we formulate Query-Level and Subject-Level\napproaches based on our framework, and analyze the merits and drawbacks of\nthese two approaches. Finally, we conduct a series of experiments with vary\ndata distributions on both language and multimodal tasks to validate that our\nproposed Bench-CoE outperforms any single model in terms of overall\nperformance. We hope this method serves as a baseline for further research in\nthis area. The code is available at\n\\url{https://github.com/ZhangXJ199/Bench-CoE}.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u662f\u9a45\u52d5\u667a\u6167\u7cfb\u7d71\u8655\u7406\u591a\u9805\u4efb\u52d9\u7684\u95dc\u9375\u6280\u8853\u3002\u70ba\u4e86\u6eff\u8db3\u5404\u7a2e\u4efb\u52d9\u7684\u9700\u6c42\uff0c\u5df2\u7d93\u958b\u767c\u51fa\u8d8a\u4f86\u8d8a\u591a\u7684\u5177\u5099\u591a\u6a23\u5316\u529f\u80fd\u7684 LLM \u9a45\u52d5\u5c08\u5bb6\uff0c\u4e26\u4f34\u96a8\u8457\u5c0d\u61c9\u7684\u57fa\u6e96\u4f86\u8a55\u4f30\u5176\u6548\u80fd\u3002\u672c\u6587\u63d0\u51fa\u4e86 Bench-CoE \u6846\u67b6\uff0c\u900f\u904e\u6709\u6548\u5229\u7528\u57fa\u6e96\u8a55\u4f30\u4f86\u9054\u6210\u5c08\u5bb6\u5354\u4f5c (CoE)\uff0c\u4ee5\u5728\u5404\u7a2e\u4efb\u52d9\u4e2d\u9054\u6210\u6700\u4f73\u6548\u80fd\u3002Bench-CoE \u5305\u542b\u4e00\u7d44\u5c08\u5bb6\u6a21\u578b\u3001\u4e00\u500b\u5c07\u4efb\u52d9\u5206\u914d\u7d66\u5c0d\u61c9\u5c08\u5bb6\u7684\u8def\u7531\u5668\uff0c\u4ee5\u53ca\u4e00\u500b\u7528\u65bc\u8a13\u7df4\u8def\u7531\u5668\u7684\u57fa\u6e96\u8cc7\u6599\u96c6\u3002\u6b64\u5916\uff0c\u6211\u5011\u6839\u64da\u6211\u5011\u7684\u6846\u67b6\u5236\u5b9a\u4e86\u67e5\u8a62\u5c64\u7d1a\u548c\u4e3b\u984c\u5c64\u7d1a\u7684\u65b9\u6cd5\uff0c\u4e26\u5206\u6790\u9019\u5169\u7a2e\u65b9\u6cd5\u7684\u512a\u7f3a\u9ede\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5c0d\u8a9e\u8a00\u548c\u591a\u6a21\u614b\u4efb\u52d9\u4e2d\u7684\u5404\u7a2e\u8cc7\u6599\u5206\u4f48\u9032\u884c\u4e86\u4e00\u7cfb\u5217\u5be6\u9a57\uff0c\u4ee5\u9a57\u8b49\u6211\u5011\u63d0\u51fa\u7684 Bench-CoE \u5728\u6574\u9ad4\u6548\u80fd\u65b9\u9762\u512a\u65bc\u4efb\u4f55\u55ae\u4e00\u6a21\u578b\u3002\u6211\u5011\u5e0c\u671b\u6b64\u65b9\u6cd5\u80fd\u4f5c\u70ba\u6b64\u9818\u57df\u9032\u4e00\u6b65\u7814\u7a76\u7684\u57fa\u6e96\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728\n\\url{https://github.com/ZhangXJ199/Bench-CoE} \u53d6\u5f97\u3002", "author": "Yuanshuai Wang et.al.", "authors": "Yuanshuai Wang, Xingjian Zhang, Jinkun Zhao, Siwei Wen, Peilin Feng, Shuhao Liao, Lei Huang, Wenjun Wu", "id": "2412.04167v1", "paper_url": "http://arxiv.org/abs/2412.04167v1", "repo": "null"}}