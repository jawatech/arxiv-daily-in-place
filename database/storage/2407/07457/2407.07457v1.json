{"2407.07457": {"publish_time": "2024-07-10", "title": "GLBench: A Comprehensive Benchmark for Graph with Large Language Models", "paper_summary": "The emergence of large language models (LLMs) has revolutionized the way we\ninteract with graphs, leading to a new paradigm called GraphLLM. Despite the\nrapid development of GraphLLM methods in recent years, the progress and\nunderstanding of this field remain unclear due to the lack of a benchmark with\nconsistent experimental protocols. To bridge this gap, we introduce GLBench,\nthe first comprehensive benchmark for evaluating GraphLLM methods in both\nsupervised and zero-shot scenarios. GLBench provides a fair and thorough\nevaluation of different categories of GraphLLM methods, along with traditional\nbaselines such as graph neural networks. Through extensive experiments on a\ncollection of real-world datasets with consistent data processing and splitting\nstrategies, we have uncovered several key findings. Firstly, GraphLLM methods\noutperform traditional baselines in supervised settings, with LLM-as-enhancers\nshowing the most robust performance. However, using LLMs as predictors is less\neffective and often leads to uncontrollable output issues. We also notice that\nno clear scaling laws exist for current GraphLLM methods. In addition, both\nstructures and semantics are crucial for effective zero-shot transfer, and our\nproposed simple baseline can even outperform several models tailored for\nzero-shot scenarios. The data and code of the benchmark can be found at\nhttps://github.com/NineAbyss/GLBench.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u51fa\u73fe\u5fb9\u5e95\u6539\u8b8a\u4e86\u6211\u5011\u8207\u5716\u8868\u4e92\u52d5\u7684\u65b9\u5f0f\uff0c\u4e26\u5c0e\u81f4\u4e86\u7a31\u70ba GraphLLM \u7684\u65b0\u7bc4\u4f8b\u3002\u5118\u7ba1\u8fd1\u5e74\u4f86 GraphLLM \u65b9\u6cd5\u5feb\u901f\u767c\u5c55\uff0c\u4f46\u7531\u65bc\u7f3a\u4e4f\u5177\u6709\u4e00\u81f4\u5be6\u9a57\u5354\u5b9a\u7684\u57fa\u6e96\uff0c\u56e0\u6b64\u8a72\u9818\u57df\u7684\u9032\u5c55\u548c\u7406\u89e3\u4ecd\u4e0d\u660e\u78ba\u3002\u70ba\u4e86\u5f4c\u88dc\u9019\u4e00\u5dee\u8ddd\uff0c\u6211\u5011\u5f15\u5165\u4e86 GLBench\uff0c\u9019\u662f\u7b2c\u4e00\u500b\u7528\u65bc\u8a55\u4f30 GraphLLM \u65b9\u6cd5\u5728\u76e3\u7763\u5f0f\u548c\u96f6\u6b21\u5b78\u7fd2\u5834\u666f\u4e2d\u7684\u7d9c\u5408\u57fa\u6e96\u3002GLBench \u63d0\u4f9b\u4e86\u5c0d\u4e0d\u540c\u985e\u5225\u7684 GraphLLM \u65b9\u6cd5\u9032\u884c\u516c\u5e73\u800c\u5fb9\u5e95\u7684\u8a55\u4f30\uff0c\u4ee5\u53ca\u5716\u795e\u7d93\u7db2\u8def\u7b49\u50b3\u7d71\u57fa\u6e96\u3002\u901a\u904e\u5c0d\u5177\u6709\u8cc7\u6599\u8655\u7406\u548c\u62c6\u5206\u7b56\u7565\u4e00\u81f4\u7684\u771f\u5be6\u4e16\u754c\u8cc7\u6599\u96c6\u9032\u884c\u5ee3\u6cdb\u5be6\u9a57\uff0c\u6211\u5011\u767c\u73fe\u4e86\u5e7e\u500b\u95dc\u9375\u767c\u73fe\u3002\u9996\u5148\uff0cGraphLLM \u65b9\u6cd5\u5728\u76e3\u7763\u5f0f\u8a2d\u5b9a\u4e2d\u512a\u65bc\u50b3\u7d71\u57fa\u6e96\uff0c\u5176\u4e2d LLM \u4f5c\u70ba\u589e\u5f37\u5668\u986f\u793a\u51fa\u6700\u7a69\u5065\u7684\u6548\u80fd\u3002\u7136\u800c\uff0c\u4f7f\u7528 LLM \u4f5c\u70ba\u9810\u6e2c\u5668\u6548\u679c\u8f03\u5dee\uff0c\u4e14\u7d93\u5e38\u5c0e\u81f4\u7121\u6cd5\u63a7\u5236\u7684\u8f38\u51fa\u554f\u984c\u3002\u6211\u5011\u9084\u6ce8\u610f\u5230\uff0c\u5c0d\u65bc\u76ee\u524d\u7684 GraphLLM \u65b9\u6cd5\u4f86\u8aaa\uff0c\u4e26\u4e0d\u5b58\u5728\u660e\u78ba\u7684\u7e2e\u653e\u5b9a\u5f8b\u3002\u6b64\u5916\uff0c\u7d50\u69cb\u548c\u8a9e\u7fa9\u5c0d\u65bc\u6709\u6548\u7684\u96f6\u6b21\u5b78\u7fd2\u8f49\u79fb\u81f3\u95dc\u91cd\u8981\uff0c\u800c\u6211\u5011\u63d0\u51fa\u7684\u7c21\u55ae\u57fa\u6e96\u751a\u81f3\u53ef\u4ee5\u512a\u65bc\u70ba\u96f6\u6b21\u5b78\u7fd2\u5834\u666f\u91cf\u8eab\u6253\u9020\u7684\u5e7e\u500b\u6a21\u578b\u3002\u57fa\u6e96\u7684\u8cc7\u6599\u548c\u7a0b\u5f0f\u78bc\u53ef\u4ee5\u5728 https://github.com/NineAbyss/GLBench \u4e2d\u627e\u5230\u3002", "author": "Yuhan Li et.al.", "authors": "Yuhan Li, Peisong Wang, Xiao Zhu, Aochuan Chen, Haiyun Jiang, Deng Cai, Victor Wai Kin Chan, Jia Li", "id": "2407.07457v1", "paper_url": "http://arxiv.org/abs/2407.07457v1", "repo": "https://github.com/nineabyss/glbench"}}