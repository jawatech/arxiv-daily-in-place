{"2406.16714": {"publish_time": "2024-06-24", "title": "AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models", "paper_summary": "Although Large Language Models (LLMs) are becoming increasingly powerful,\nthey still exhibit significant but subtle weaknesses, such as mistakes in\ninstruction-following or coding tasks. As these unexpected errors could lead to\nsevere consequences in practical deployments, it is crucial to investigate the\nlimitations within LLMs systematically. Traditional benchmarking approaches\ncannot thoroughly pinpoint specific model deficiencies, while manual\ninspections are costly and not scalable. In this paper, we introduce a unified\nframework, AutoDetect, to automatically expose weaknesses in LLMs across\nvarious tasks. Inspired by the educational assessment process that measures\nstudents' learning outcomes, AutoDetect consists of three LLM-powered agents:\nExaminer, Questioner, and Assessor. The collaboration among these three agents\nis designed to realize comprehensive and in-depth weakness identification. Our\nframework demonstrates significant success in uncovering flaws, with an\nidentification success rate exceeding 30% in prominent models such as ChatGPT\nand Claude. More importantly, these identified weaknesses can guide specific\nmodel improvements, proving more effective than untargeted data augmentation\nmethods like Self-Instruct. Our approach has led to substantial enhancements in\npopular LLMs, including the Llama series and Mistral-7b, boosting their\nperformance by over 10% across several benchmarks. Code and data are publicly\navailable at https://github.com/thu-coai/AutoDetect.", "paper_summary_zh": "\u5118\u7ba1\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8b8a\u5f97\u8d8a\u4f86\u8d8a\u5f37\u5927\uff0c\n\u5b83\u5011\u4ecd\u5c55\u73fe\u51fa\u986f\u8457\u4f46\u7d30\u5fae\u7684\u5f31\u9ede\uff0c\u4f8b\u5982\u5728\u6307\u4ee4\u9075\u5faa\u6216\u7de8\u78bc\u4efb\u52d9\u4e2d\u7684\u932f\u8aa4\u3002\u7531\u65bc\u9019\u4e9b\u610f\u5916\u932f\u8aa4\u53ef\u80fd\u5c0e\u81f4\u5be6\u969b\u90e8\u7f72\u4e2d\u7684\u56b4\u91cd\u5f8c\u679c\uff0c\u56e0\u6b64\u7cfb\u7d71\u5730\u8abf\u67e5 LLM \u4e2d\u7684\u9650\u5236\u81f3\u95dc\u91cd\u8981\u3002\u50b3\u7d71\u7684\u57fa\u6e96\u6e2c\u8a66\u65b9\u6cd5\u7121\u6cd5\u5fb9\u5e95\u627e\u51fa\u5177\u9ad4\u7684\u6a21\u578b\u7f3a\u9677\uff0c\u800c\u624b\u52d5\u6aa2\u67e5\u6210\u672c\u9ad8\u6602\u4e14\u4e0d\u53ef\u64f4\u5c55\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86\u4e00\u500b\u7d71\u4e00\u7684\u6846\u67b6 AutoDetect\uff0c\u7528\u65bc\u81ea\u52d5\u63ed\u9732 LLM \u5728\u5404\u7a2e\u4efb\u52d9\u4e2d\u7684\u5f31\u9ede\u3002\u53d7\u8861\u91cf\u5b78\u751f\u5b78\u7fd2\u6210\u679c\u7684\u6559\u80b2\u8a55\u91cf\u904e\u7a0b\u555f\u767c\uff0cAutoDetect \u5305\u542b\u4e09\u500b\u7531 LLM \u9a45\u52d5\u7684\u4ee3\u7406\uff1a\u8003\u5b98\u3001\u63d0\u554f\u8005\u548c\u8a55\u4f30\u8005\u3002\u9019\u4e09\u500b\u4ee3\u7406\u4e4b\u9593\u7684\u5354\u4f5c\u65e8\u5728\u5be6\u73fe\u5168\u9762\u4e14\u6df1\u5165\u7684\u5f31\u9ede\u8b58\u5225\u3002\u6211\u5011\u7684\u6846\u67b6\u5728\u767c\u73fe\u7f3a\u9677\u65b9\u9762\u8868\u73fe\u51fa\u986f\u8457\u7684\u6210\u529f\uff0c\u5728 ChatGPT \u548c Claude \u7b49\u77e5\u540d\u6a21\u578b\u4e2d\uff0c\u8b58\u5225\u6210\u529f\u7387\u8d85\u904e 30%\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u9019\u4e9b\u5df2\u8b58\u5225\u7684\u5f31\u9ede\u53ef\u4ee5\u6307\u5c0e\u5177\u9ad4\u7684\u6a21\u578b\u6539\u9032\uff0c\u8b49\u660e\u6bd4\u81ea\u6307\u5c0e\u7b49\u7121\u76ee\u6a19\u6578\u64da\u64f4\u5145\u65b9\u6cd5\u66f4\u6709\u6548\u3002\u6211\u5011\u7684\u505a\u6cd5\u5df2\u5927\u5e45\u63d0\u5347\u71b1\u9580 LLM \u7684\u6548\u80fd\uff0c\u5305\u62ec Llama \u7cfb\u5217\u548c Mistral-7b\uff0c\u5728\u591a\u500b\u57fa\u6e96\u6e2c\u8a66\u4e2d\u63d0\u5347\u5176\u6548\u80fd\u8d85\u904e 10%\u3002\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\u5df2\u516c\u958b\u767c\u5e03\u65bc https://github.com/thu-coai/AutoDetect\u3002", "author": "Jiale Cheng et.al.", "authors": "Jiale Cheng, Yida Lu, Xiaotao Gu, Pei Ke, Xiao Liu, Yuxiao Dong, Hongning Wang, Jie Tang, Minlie Huang", "id": "2406.16714v1", "paper_url": "http://arxiv.org/abs/2406.16714v1", "repo": "https://github.com/thu-coai/autodetect"}}