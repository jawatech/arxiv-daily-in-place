{"2410.11710": {"publish_time": "2024-10-15", "title": "MTU-Bench: A Multi-granularity Tool-Use Benchmark for Large Language Models", "paper_summary": "Large Language Models (LLMs) have displayed massive improvements in reasoning\nand decision-making skills and can hold natural conversations with users.\nRecently, many tool-use benchmark datasets have been proposed. However,\nexisting datasets have the following limitations: (1). Insufficient evaluation\nscenarios (e.g., only cover limited tool-use scenes). (2). Extensive evaluation\ncosts (e.g., GPT API costs). To address these limitations, in this work, we\npropose a multi-granularity tool-use benchmark for large language models called\nMTU-Bench. For the \"multi-granularity\" property, our MTU-Bench covers five tool\nusage scenes (i.e., single-turn and single-tool, single-turn and multiple-tool,\nmultiple-turn and single-tool, multiple-turn and multiple-tool, and\nout-of-distribution tasks). Besides, all evaluation metrics of our MTU-Bench\nare based on the prediction results and the ground truth without using any GPT\nor human evaluation metrics. Moreover, our MTU-Bench is collected by\ntransforming existing high-quality datasets to simulate real-world tool usage\nscenarios, and we also propose an instruction dataset called MTU-Instruct data\nto enhance the tool-use abilities of existing LLMs. Comprehensive experimental\nresults demonstrate the effectiveness of our MTU-Bench. Code and data will be\nreleased at https: //github.com/MTU-Bench-Team/MTU-Bench.git.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u63a8\u7406\u548c\u6c7a\u7b56\u5236\u5b9a\u6280\u80fd\u65b9\u9762\u8868\u73fe\u51fa\u5de8\u5927\u7684\u9032\u6b65\uff0c\u4e26\u4e14\u53ef\u4ee5\u8207\u4f7f\u7528\u8005\u9032\u884c\u81ea\u7136\u7684\u5c0d\u8a71\u3002\u6700\u8fd1\uff0c\u5df2\u7d93\u63d0\u51fa\u4e86\u8a31\u591a\u5de5\u5177\u4f7f\u7528\u57fa\u6e96\u8cc7\u6599\u96c6\u3002\u7136\u800c\uff0c\u73fe\u6709\u8cc7\u6599\u96c6\u6709\u4ee5\u4e0b\u9650\u5236\uff1a(1) \u8a55\u4f30\u5834\u666f\u4e0d\u8db3\uff08\u4f8b\u5982\uff0c\u50c5\u6db5\u84cb\u6709\u9650\u7684\u5de5\u5177\u4f7f\u7528\u5834\u666f\uff09\u3002(2) \u8a55\u4f30\u6210\u672c\u9ad8\u6602\uff08\u4f8b\u5982\uff0cGPT API \u6210\u672c\uff09\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u9650\u5236\uff0c\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u540d\u70ba MTU-Bench \u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u591a\u7c92\u5ea6\u5de5\u5177\u4f7f\u7528\u57fa\u6e96\u3002\u5c0d\u65bc\u300c\u591a\u7c92\u5ea6\u300d\u5c6c\u6027\uff0c\u6211\u5011\u7684 MTU-Bench \u6db5\u84cb\u4e94\u7a2e\u5de5\u5177\u4f7f\u7528\u5834\u666f\uff08\u5373\u55ae\u56de\u5408\u548c\u55ae\u4e00\u5de5\u5177\u3001\u55ae\u56de\u5408\u548c\u591a\u91cd\u5de5\u5177\u3001\u591a\u56de\u5408\u548c\u55ae\u4e00\u5de5\u5177\u3001\u591a\u56de\u5408\u548c\u591a\u91cd\u5de5\u5177\uff0c\u4ee5\u53ca\u5206\u5e03\u5916\u4efb\u52d9\uff09\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684 MTU-Bench \u7684\u6240\u6709\u8a55\u4f30\u6307\u6a19\u90fd\u57fa\u65bc\u9810\u6e2c\u7d50\u679c\u548c\u5730\u9762\u5be6\u6cc1\uff0c\u800c\u6c92\u6709\u4f7f\u7528\u4efb\u4f55 GPT \u6216\u4eba\u985e\u8a55\u4f30\u6307\u6a19\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684 MTU-Bench \u662f\u900f\u904e\u8f49\u63db\u73fe\u6709\u7684\u9ad8\u54c1\u8cea\u8cc7\u6599\u96c6\u4f86\u6536\u96c6\uff0c\u4ee5\u6a21\u64ec\u771f\u5be6\u4e16\u754c\u7684\u5de5\u5177\u4f7f\u7528\u5834\u666f\uff0c\u6211\u5011\u9084\u63d0\u51fa\u4e86\u4e00\u500b\u540d\u70ba MTU-Instruct \u7684\u6307\u4ee4\u8cc7\u6599\u96c6\uff0c\u4ee5\u589e\u5f37\u73fe\u6709 LLM \u7684\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u3002\u5168\u9762\u7684\u5be6\u9a57\u7d50\u679c\u8b49\u660e\u4e86\u6211\u5011 MTU-Bench \u7684\u6709\u6548\u6027\u3002\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\u5c07\u5728 https: //github.com/MTU-Bench-Team/MTU-Bench.git \u767c\u5e03\u3002", "author": "Pei Wang et.al.", "authors": "Pei Wang, Yanan Wu, Zekun Wang, Jiaheng Liu, Xiaoshuai Song, Zhongyuan Peng, Ken Deng, Chenchen Zhang, Jiakai Wang, Junran Peng, Ge Zhang, Hangyu Guo, Zhaoxiang Zhang, Wenbo Su, Bo Zheng", "id": "2410.11710v1", "paper_url": "http://arxiv.org/abs/2410.11710v1", "repo": "https://github.com/mtu-bench-team/mtu-bench"}}