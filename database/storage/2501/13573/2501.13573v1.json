{"2501.13573": {"publish_time": "2025-01-23", "title": "Improving Contextual Faithfulness of Large Language Models via Retrieval Heads-Induced Optimization", "paper_summary": "Ensuring contextual faithfulness in retrieval-augmented large language models\n(LLMs) is crucial for building trustworthy information-seeking systems,\nparticularly in long-form question-answering (LFQA) scenarios. In this work, we\nidentify a salient correlation between LFQA faithfulness and retrieval heads, a\nset of attention heads responsible for retrieving contextual information.\nLeveraging this insight, we propose RHIO, a framework designed to teach LLMs to\nexplicitly discriminate between faithful and unfaithful generations. RHIO first\naugments unfaithful samples that simulate realistic model-intrinsic errors by\nselectively masking retrieval heads. Then, these samples are incorporated into\njoint training, enabling the model to distinguish unfaithful outputs from\nfaithful ones conditioned on control tokens. Furthermore, these control tokens\nare leveraged to self-induce contrastive outputs, amplifying their difference\nthrough contrastive decoding. Additionally, to facilitate the evaluation of\ncontextual faithfulness, we also introduce GroundBench, a comprehensive\nbenchmark compiled from five existing LFQA datasets. Extensive experimental\nresults on GroundBench demonstrate that RHIO significantly improves\nfaithfulness, even outperforming GPT-4o.", "paper_summary_zh": "\u78ba\u4fdd\u5728\u6aa2\u7d22\u589e\u5f37\u578b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4e2d\u7684\u4e0a\u4e0b\u6587\u4fdd\u771f\u5ea6\uff0c\u5c0d\u65bc\u5efa\u7acb\u503c\u5f97\u4fe1\u8cf4\u7684\u8cc7\u8a0a\u641c\u5c0b\u7cfb\u7d71\u81f3\u95dc\u91cd\u8981\uff0c\u7279\u5225\u662f\u5728\u9577\u7bc7\u554f\u7b54 (LFQA) \u5834\u666f\u4e2d\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u767c\u73fe LFQA \u4fdd\u771f\u5ea6\u8207\u6aa2\u7d22\u982d\u4e4b\u9593\u5b58\u5728\u986f\u8457\u76f8\u95dc\u6027\uff0c\u6aa2\u7d22\u982d\u662f\u4e00\u7d44\u8ca0\u8cac\u6aa2\u7d22\u4e0a\u4e0b\u6587\u8cc7\u8a0a\u7684\u6ce8\u610f\u529b\u982d\u3002\u5229\u7528\u9019\u9805\u898b\u89e3\uff0c\u6211\u5011\u63d0\u51fa\u4e86 RHIO\uff0c\u4e00\u500b\u65e8\u5728\u6559\u5c0e LLM \u660e\u78ba\u5340\u5206\u4fdd\u771f\u548c\u4e0d\u4fdd\u771f\u7684\u751f\u6210\u3002RHIO \u9996\u5148\u901a\u904e\u9078\u64c7\u6027\u906e\u853d\u6aa2\u7d22\u982d\u4f86\u64f4\u5145\u6a21\u64ec\u5be6\u969b\u6a21\u578b\u5167\u5728\u932f\u8aa4\u7684\u4e0d\u4fdd\u771f\u6a23\u672c\u3002\u7136\u5f8c\uff0c\u5c07\u9019\u4e9b\u6a23\u672c\u7d0d\u5165\u806f\u5408\u8a13\u7df4\u4e2d\uff0c\u4f7f\u6a21\u578b\u80fd\u5920\u6839\u64da\u63a7\u5236\u4ee3\u78bc\u5340\u5206\u4e0d\u4fdd\u771f\u7684\u8f38\u51fa\u548c\u4fdd\u771f\u7684\u8f38\u51fa\u3002\u6b64\u5916\uff0c\u9019\u4e9b\u63a7\u5236\u4ee3\u78bc\u88ab\u7528\u65bc\u81ea\u6211\u8a98\u5c0e\u5c0d\u6bd4\u8f38\u51fa\uff0c\u901a\u904e\u5c0d\u6bd4\u89e3\u78bc\u653e\u5927\u5b83\u5011\u7684\u5dee\u7570\u3002\u6b64\u5916\uff0c\u70ba\u4e86\u4fc3\u9032\u5c0d\u4e0a\u4e0b\u6587\u4fdd\u771f\u5ea6\u7684\u8a55\u4f30\uff0c\u6211\u5011\u9084\u5f15\u5165\u4e86 GroundBench\uff0c\u4e00\u500b\u7531\u4e94\u500b\u73fe\u6709 LFQA \u8cc7\u6599\u96c6\u7de8\u8b6f\u800c\u6210\u7684\u7d9c\u5408\u57fa\u6e96\u3002\u5728 GroundBench \u4e0a\u7684\u5ee3\u6cdb\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0cRHIO \u5927\u5e45\u63d0\u5347\u4e86\u4fdd\u771f\u5ea6\uff0c\u751a\u81f3\u512a\u65bc GPT-4o\u3002", "author": "Lei Huang et.al.", "authors": "Lei Huang, Xiaocheng Feng, Weitao Ma, Yuchun Fan, Xiachong Feng, Yangfan Ye, Weihong Zhong, Yuxuan Gu, Baoxin Wang, Dayong Wu, Guoping Hu, Bing Qin", "id": "2501.13573v1", "paper_url": "http://arxiv.org/abs/2501.13573v1", "repo": "null"}}