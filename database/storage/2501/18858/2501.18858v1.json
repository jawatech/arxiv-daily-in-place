{"2501.18858": {"publish_time": "2025-01-31", "title": "BRiTE: Bootstrapping Reinforced Thinking Process to Enhance Language Model Reasoning", "paper_summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\ncomplex reasoning tasks, yet generating reliable reasoning processes remains a\nsignificant challenge. We present a unified probabilistic framework that\nformalizes LLM reasoning through a novel graphical model incorporating latent\nthinking processes and evaluation signals. Within this framework, we introduce\nthe Bootstrapping Reinforced Thinking Process (BRiTE) algorithm, which works in\ntwo steps. First, it generates high-quality rationales by approximating the\noptimal thinking process through reinforcement learning, using a novel reward\nshaping mechanism. Second, it enhances the base LLM by maximizing the joint\nprobability of rationale generation with respect to the model's parameters.\nTheoretically, we demonstrate BRiTE's convergence at a rate of $1/T$ with $T$\nrepresenting the number of iterations. Empirical evaluations on math and coding\nbenchmarks demonstrate that our approach consistently improves performance\nacross different base models without requiring human-annotated thinking\nprocesses. In addition, BRiTE demonstrates superior performance compared to\nexisting algorithms that bootstrap thinking processes use alternative methods\nsuch as rejection sampling, and can even match or exceed the results achieved\nthrough supervised fine-tuning with human-annotated data.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5728\u8907\u96dc\u63a8\u7406\u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u975e\u51e1\u7684\u80fd\u529b\uff0c\u4f46\u7522\u751f\u53ef\u9760\u7684\u63a8\u7406\u904e\u7a0b\u4ecd\u7136\u662f\u4e00\u9805\u91cd\u5927\u6311\u6230\u3002\u6211\u5011\u63d0\u51fa\u4e00\u500b\u7d71\u4e00\u7684\u6a5f\u7387\u67b6\u69cb\uff0c\u900f\u904e\u4e00\u500b\u7d50\u5408\u6f5b\u5728\u601d\u8003\u904e\u7a0b\u548c\u8a55\u4f30\u8a0a\u865f\u7684\u65b0\u7a4e\u5716\u5f62\u6a21\u578b\uff0c\u5c07 LLM \u63a8\u7406\u5f62\u5f0f\u5316\u3002\u5728\u6b64\u67b6\u69cb\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u81ea\u8209\u5f37\u5316\u601d\u8003\u904e\u7a0b (BRiTE) \u6f14\u7b97\u6cd5\uff0c\u5176\u904b\u4f5c\u5206\u70ba\u5169\u500b\u6b65\u9a5f\u3002\u9996\u5148\uff0c\u5b83\u900f\u904e\u5f37\u5316\u5b78\u7fd2\u8fd1\u4f3c\u6700\u4f73\u601d\u8003\u904e\u7a0b\u4f86\u7522\u751f\u9ad8\u54c1\u8cea\u7684\u57fa\u672c\u539f\u7406\uff0c\u4e26\u4f7f\u7528\u65b0\u7a4e\u7684\u734e\u52f5\u5851\u9020\u6a5f\u5236\u3002\u5176\u6b21\uff0c\u5b83\u900f\u904e\u6700\u5927\u5316\u57fa\u672c\u539f\u7406\u7522\u751f\u548c\u6a21\u578b\u53c3\u6578\u76f8\u95dc\u7684\u806f\u5408\u6a5f\u7387\uff0c\u4f86\u589e\u5f37\u57fa\u790e LLM\u3002\u5728\u7406\u8ad6\u4e0a\uff0c\u6211\u5011\u8b49\u660e\u4e86 BRiTE \u4ee5 $1/T$ \u7684\u901f\u7387\u6536\u6582\uff0c\u5176\u4e2d $T$ \u4ee3\u8868\u8fed\u4ee3\u6b21\u6578\u3002\u5728\u6578\u5b78\u548c\u7de8\u78bc\u57fa\u6e96\u4e0a\u7684\u7d93\u9a57\u8a55\u4f30\u8868\u660e\uff0c\u6211\u5011\u7684\u505a\u6cd5\u6301\u7e8c\u6539\u5584\u4e86\u4e0d\u540c\u57fa\u790e\u6a21\u578b\u7684\u6548\u80fd\uff0c\u800c\u7121\u9700\u4eba\u5de5\u6a19\u8a3b\u7684\u601d\u8003\u904e\u7a0b\u3002\u6b64\u5916\uff0c\u8207\u4f7f\u7528\u62d2\u7d55\u63a1\u6a23\u7b49\u66ff\u4ee3\u65b9\u6cd5\u4f86\u81ea\u8209\u601d\u8003\u904e\u7a0b\u7684\u73fe\u6709\u6f14\u7b97\u6cd5\u76f8\u6bd4\uff0cBRiTE \u5c55\u73fe\u51fa\u512a\u7570\u7684\u6548\u80fd\uff0c\u751a\u81f3\u53ef\u4ee5\u9054\u5230\u6216\u8d85\u8d8a\u900f\u904e\u6709\u4eba\u5de5\u6a19\u8a3b\u8cc7\u6599\u7684\u76e3\u7763\u5fae\u8abf\u6240\u7372\u5f97\u7684\u7d50\u679c\u3002", "author": "Han Zhong et.al.", "authors": "Han Zhong, Yutong Yin, Shenao Zhang, Xiaojun Xu, Yuanxin Liu, Yifei Zuo, Zhihan Liu, Boyi Liu, Sirui Zheng, Hongyi Guo, Liwei Wang, Mingyi Hong, Zhaoran Wang", "id": "2501.18858v1", "paper_url": "http://arxiv.org/abs/2501.18858v1", "repo": "null"}}