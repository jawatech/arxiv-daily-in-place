{"2411.05199": {"publish_time": "2024-11-07", "title": "CodeLutra: Boosting LLM Code Generation via Preference-Guided Refinement", "paper_summary": "Large Language Models (LLMs) have significantly advanced code generation but\noften require substantial resources and tend to over-generalize, limiting their\nefficiency for specific tasks. Fine-tuning smaller, open-source LLMs presents a\nviable alternative; however, it typically lags behind cutting-edge models due\nto supervised fine-tuning's reliance solely on correct code examples, which\nrestricts the model's ability to learn from its own mistakes and adapt to\ndiverse programming challenges. To bridge this gap, we introduce CodeLutra, a\nnovel framework that enhances low-performing LLMs by leveraging both successful\nand failed code generation attempts. Unlike conventional fine-tuning, CodeLutra\nemploys an iterative preference learning mechanism to compare correct and\nincorrect solutions as well as maximize the likelihood of correct codes.\nThrough continuous iterative refinement, CodeLutra enables smaller LLMs to\nmatch or surpass GPT-4's performance in various code generation tasks without\nrelying on vast external datasets or larger auxiliary models. On a challenging\ndata analysis task, using just 500 samples improved Llama-3-8B's accuracy from\n28.2% to 48.6%, approaching GPT-4's performance. These results highlight\nCodeLutra's potential to close the gap between open-source and closed-source\nmodels, making it a promising approach in the field of code generation.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u986f\u8457\u63d0\u5347\u7a0b\u5f0f\u78bc\u7522\u751f\uff0c\u4f46\u901a\u5e38\u9700\u8981\u5927\u91cf\u8cc7\u6e90\uff0c\u4e14\u50be\u5411\u904e\u5ea6\u6982\u5316\uff0c\u9650\u5236\u5176\u5728\u7279\u5b9a\u4efb\u52d9\u4e2d\u7684\u6548\u7387\u3002\u5fae\u8abf\u8f03\u5c0f\u3001\u958b\u653e\u539f\u59cb\u78bc\u7684 LLM \u63d0\u4f9b\u4e86\u4e00\u500b\u53ef\u884c\u7684\u66ff\u4ee3\u65b9\u6848\uff1b\u7136\u800c\uff0c\u7531\u65bc\u76e3\u7763\u5fae\u8abf\u50c5\u4f9d\u8cf4\u65bc\u6b63\u78ba\u7684\u7a0b\u5f0f\u78bc\u7bc4\u4f8b\uff0c\u56e0\u6b64\u901a\u5e38\u843d\u5f8c\u65bc\u5c16\u7aef\u6a21\u578b\uff0c\u9019\u9650\u5236\u4e86\u6a21\u578b\u5f9e\u5176\u81ea\u8eab\u932f\u8aa4\u4e2d\u5b78\u7fd2\u548c\u9069\u61c9\u5404\u7a2e\u7a0b\u5f0f\u8a2d\u8a08\u6311\u6230\u7684\u80fd\u529b\u3002\u70ba\u4e86\u5f4c\u5408\u9019\u4e00\u5dee\u8ddd\uff0c\u6211\u5011\u5f15\u5165\u4e86 CodeLutra\uff0c\u9019\u662f\u4e00\u500b\u901a\u904e\u5229\u7528\u6210\u529f\u548c\u5931\u6557\u7684\u7a0b\u5f0f\u78bc\u751f\u6210\u5617\u8a66\u4f86\u589e\u5f37\u6548\u80fd\u4e0d\u4f73\u7684 LLM \u7684\u65b0\u6846\u67b6\u3002\u8207\u50b3\u7d71\u5fae\u8abf\u4e0d\u540c\uff0cCodeLutra \u63a1\u7528\u53cd\u8986\u504f\u597d\u5b78\u7fd2\u6a5f\u5236\u4f86\u6bd4\u8f03\u6b63\u78ba\u548c\u4e0d\u6b63\u78ba\u7684\u89e3\u6c7a\u65b9\u6848\uff0c\u4e26\u6700\u5927\u5316\u6b63\u78ba\u7a0b\u5f0f\u78bc\u7684\u53ef\u80fd\u6027\u3002\u900f\u904e\u6301\u7e8c\u7684\u53cd\u8986\u6539\u9032\uff0cCodeLutra \u80fd\u8b93\u8f03\u5c0f\u7684 LLM \u5728\u5404\u7a2e\u7a0b\u5f0f\u78bc\u751f\u6210\u4efb\u52d9\u4e2d\u9054\u5230\u6216\u8d85\u8d8a GPT-4 \u7684\u6548\u80fd\uff0c\u800c\u7121\u9700\u4f9d\u8cf4\u65bc\u9f90\u5927\u7684\u5916\u90e8\u8cc7\u6599\u96c6\u6216\u8f03\u5927\u7684\u8f14\u52a9\u6a21\u578b\u3002\u5728\u4e00\u500b\u5177\u6709\u6311\u6230\u6027\u7684\u8cc7\u6599\u5206\u6790\u4efb\u52d9\u4e2d\uff0c\u50c5\u4f7f\u7528 500 \u500b\u7bc4\u4f8b\u5c31\u5c07 Llama-3-8B \u7684\u6e96\u78ba\u5ea6\u5f9e 28.2% \u63d0\u5347\u5230 48.6%\uff0c\u63a5\u8fd1 GPT-4 \u7684\u6548\u80fd\u3002\u9019\u4e9b\u7d50\u679c\u7a81\u986f\u4e86 CodeLutra \u5728\u7e2e\u5c0f\u958b\u653e\u539f\u59cb\u78bc\u548c\u9589\u6e90\u6a21\u578b\u4e4b\u9593\u5dee\u8ddd\u7684\u6f5b\u529b\uff0c\u4f7f\u5176\u6210\u70ba\u7a0b\u5f0f\u78bc\u751f\u6210\u9818\u57df\u4e2d\u4e00\u500b\u6709\u524d\u9014\u7684\u65b9\u6cd5\u3002", "author": "Leitian Tao et.al.", "authors": "Leitian Tao, Xiang Chen, Tong Yu, Tung Mai, Ryan Rossi, Yixuan Li, Saayan Mitra", "id": "2411.05199v1", "paper_url": "http://arxiv.org/abs/2411.05199v1", "repo": "null"}}