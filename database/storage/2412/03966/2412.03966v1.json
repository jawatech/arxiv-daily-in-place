{"2412.03966": {"publish_time": "2024-12-05", "title": "Demonstration Selection for In-Context Learning via Reinforcement Learning", "paper_summary": "Diversity in demonstration selection is crucial for enhancing model\ngeneralization, as it enables a broader coverage of structures and concepts.\nHowever, constructing an appropriate set of demonstrations has remained a focal\npoint of research. This paper presents the Relevance-Diversity Enhanced\nSelection (RDES), an innovative approach that leverages reinforcement learning\nto optimize the selection of diverse reference demonstrations for text\nclassification tasks using Large Language Models (LLMs), especially in few-shot\nprompting scenarios. RDES employs a Q-learning framework to dynamically\nidentify demonstrations that maximize both diversity and relevance to the\nclassification objective by calculating a diversity score based on label\ndistribution among selected demonstrations. This method ensures a balanced\nrepresentation of reference data, leading to improved classification accuracy.\nThrough extensive experiments on four benchmark datasets and involving 12\nclosed-source and open-source LLMs, we demonstrate that RDES significantly\nenhances classification accuracy compared to ten established baselines.\nFurthermore, we investigate the incorporation of Chain-of-Thought (CoT)\nreasoning in the reasoning process, which further enhances the model's\npredictive performance. The results underscore the potential of reinforcement\nlearning to facilitate adaptive demonstration selection and deepen the\nunderstanding of classification challenges.", "paper_summary_zh": "\u793a\u7bc4\u9078\u64c7\u7684\u591a\u6a23\u6027\u5c0d\u65bc\u589e\u5f37\u6a21\u578b\u6982\u5316\u81f3\u95dc\u91cd\u8981\uff0c\u56e0\u70ba\u5b83\u80fd\u66f4\u5ee3\u6cdb\u5730\u6db5\u84cb\u7d50\u69cb\u548c\u6982\u5ff5\u3002\u7136\u800c\uff0c\u5efa\u69cb\u4e00\u7d44\u9069\u7576\u7684\u793a\u7bc4\u4ecd\u7136\u662f\u7814\u7a76\u7684\u91cd\u9ede\u3002\u672c\u6587\u63d0\u51fa\u4e86\u76f8\u95dc\u6027\u591a\u6a23\u6027\u589e\u5f37\u9078\u64c7 (RDES)\uff0c\u9019\u662f\u4e00\u7a2e\u5275\u65b0\u7684\u65b9\u6cd5\uff0c\u5b83\u5229\u7528\u5f37\u5316\u5b78\u7fd2\u4f86\u6700\u4f73\u5316\u9078\u64c7\u7528\u65bc\u6587\u672c\u5206\u985e\u4efb\u52d9\u7684\u4e0d\u540c\u53c3\u8003\u793a\u7bc4\uff0c\u7279\u5225\u662f\u5728\u5c11\u6b21\u63d0\u793a\u5834\u666f\u4e2d\uff0c\u4e26\u4f7f\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\u3002RDES \u4f7f\u7528 Q \u5b78\u7fd2\u67b6\u69cb\u4f86\u52d5\u614b\u8b58\u5225\u793a\u7bc4\uff0c\u9019\u4e9b\u793a\u7bc4\u80fd\u6700\u5927\u5316\u591a\u6a23\u6027\u548c\u8207\u5206\u985e\u76ee\u6a19\u76f8\u95dc\u6027\uff0c\u65b9\u6cd5\u662f\u6839\u64da\u5df2\u9078\u64c7\u793a\u7bc4\u4e2d\u7684\u6a19\u7c64\u5206\u4f48\u8a08\u7b97\u591a\u6a23\u6027\u5206\u6578\u3002\u6b64\u65b9\u6cd5\u80fd\u78ba\u4fdd\u53c3\u8003\u8cc7\u6599\u7684\u5747\u8861\u8868\u793a\uff0c\u9032\u800c\u63d0\u5347\u5206\u985e\u6e96\u78ba\u5ea6\u3002\u900f\u904e\u5728\u56db\u500b\u57fa\u6e96\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u4e26\u6d89\u53ca 12 \u500b\u9589\u6e90\u548c\u958b\u6e90 LLM\uff0c\u6211\u5011\u8b49\u660e RDES \u8207\u5341\u500b\u5df2\u5efa\u7acb\u7684\u57fa\u6e96\u76f8\u6bd4\uff0c\u986f\u8457\u63d0\u5347\u4e86\u5206\u985e\u6e96\u78ba\u5ea6\u3002\u6b64\u5916\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u5728\u63a8\u7406\u904e\u7a0b\u4e2d\u7d0d\u5165\u601d\u8003\u93c8 (CoT) \u63a8\u7406\uff0c\u9019\u9032\u4e00\u6b65\u63d0\u5347\u4e86\u6a21\u578b\u7684\u9810\u6e2c\u6548\u80fd\u3002\u7d50\u679c\u5f37\u8abf\u4e86\u5f37\u5316\u5b78\u7fd2\u4fc3\u9032\u9069\u61c9\u6027\u793a\u7bc4\u9078\u64c7\u7684\u6f5b\u529b\uff0c\u4e26\u52a0\u6df1\u4e86\u5c0d\u5206\u985e\u6311\u6230\u7684\u7406\u89e3\u3002", "author": "Xubin Wang et.al.", "authors": "Xubin Wang, Jianfei Wu, Yichen Yuan, Mingzhe Li, Deyu Cai, Weijia Jia", "id": "2412.03966v1", "paper_url": "http://arxiv.org/abs/2412.03966v1", "repo": "null"}}