{"2407.11654": {"publish_time": "2024-07-16", "title": "R-SFLLM: Jamming Resilient Framework for Split Federated Learning with Large Language Models", "paper_summary": "Split federated learning (SFL) is a compute-efficient paradigm in distributed\nmachine learning (ML), where components of large ML models are outsourced to\nremote servers. A significant challenge in SFL, particularly when deployed over\nwireless channels, is the susceptibility of transmitted model parameters to\nadversarial jamming that could jeopardize the learning process. This is\nparticularly pronounced for word embedding parameters in large language models\n(LLMs), which are crucial for language understanding. In this paper, rigorous\ninsights are provided into the influence of jamming LLM word embeddings in SFL\nby deriving an expression for the ML training loss divergence and showing that\nit is upper-bounded by the mean squared error (MSE). Based on this analysis, a\nphysical layer framework is developed for resilient SFL with LLMs (R-SFLLM)\nover wireless networks. R-SFLLM leverages wireless sensing data to gather\ninformation on the jamming directions-of-arrival (DoAs) for the purpose of\ndevising a novel, sensing-assisted anti-jamming strategy while jointly\noptimizing beamforming, user scheduling, and resource allocation. Extensive\nexperiments using BERT and RoBERTa models demonstrate R-SFLLM's effectiveness,\nachieving close-to-baseline performance across various natural language\nprocessing (NLP) tasks and datasets. The proposed methodology further\nintroduces an adversarial training component, where controlled noise exposure\nsignificantly enhances the LLM's resilience to perturbed parameters during\ntraining. The results show that more noise-sensitive models, such as RoBERTa,\nbenefit from this feature, especially when resource allocation is unfair. It is\nalso shown that worst-case jamming in particular translates into worst-case\nmodel outcomes, thereby necessitating the need for jamming-resilient SFL\nprotocols.", "paper_summary_zh": "\u5206\u5272\u8054\u90a6\u5b78\u7fd2 (SFL) \u662f\u4e00\u7a2e\u5728\u5206\u6563\u5f0f\u6a5f\u5668\u5b78\u7fd2 (ML) \u4e2d\u8a08\u7b97\u6548\u7387\u9ad8\u7684\u7bc4\u4f8b\uff0c\u5176\u4e2d\u5927\u578b ML \u6a21\u578b\u7684\u7d44\u6210\u6703\u5916\u5305\u5230\u9060\u7aef\u4f3a\u670d\u5668\u3002SFL \u4e2d\u7684\u4e00\u9805\u91cd\u5927\u6311\u6230\uff0c\u7279\u5225\u662f\u5728\u7121\u7dda\u983b\u9053\u4e0a\u90e8\u7f72\u6642\uff0c\u5728\u65bc\u50b3\u8f38\u7684\u6a21\u578b\u53c3\u6578\u5bb9\u6613\u53d7\u5230\u5c0d\u6297\u6027\u5e72\u64fe\uff0c\u53ef\u80fd\u6703\u5371\u53ca\u5b78\u7fd2\u904e\u7a0b\u3002\u9019\u5c0d\u65bc\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4e2d\u7684\u8a5e\u5d4c\u5165\u53c3\u6578\u4f86\u8aaa\u5c24\u5176\u660e\u986f\uff0c\u9019\u4e9b\u53c3\u6578\u5c0d\u65bc\u8a9e\u8a00\u7406\u89e3\u81f3\u95dc\u91cd\u8981\u3002\u5728\u672c\u6587\u4e2d\uff0c\u900f\u904e\u63a8\u5c0e ML \u8a13\u7df4\u640d\u5931\u5dee\u7570\u7684\u8868\u9054\u5f0f\uff0c\u4e26\u8b49\u660e\u5b83\u4ee5\u4e0a\u9650\u5747\u65b9\u8aa4\u5dee (MSE) \u70ba\u754c\uff0c\u6df1\u5165\u63a2\u8a0e\u4e86\u5e72\u64fe SFL \u4e2d\u7684 LLM \u8a5e\u5d4c\u5165\u7684\u5f71\u97ff\u3002\u6839\u64da\u6b64\u5206\u6790\uff0c\u958b\u767c\u4e86\u4e00\u500b\u7528\u65bc\u7121\u7dda\u7db2\u8def\u4e0a\u7684\u5f48\u6027 SFL \u8207 LLM (R-SFLLM) \u7684\u7269\u7406\u5c64\u67b6\u69cb\u3002R-SFLLM \u5229\u7528\u7121\u7dda\u611f\u6e2c\u8cc7\u6599\u4f86\u6536\u96c6\u5e72\u64fe\u5230\u4f86\u65b9\u5411 (DoA) \u7684\u8cc7\u8a0a\uff0c\u76ee\u7684\u662f\u8a2d\u8a08\u4e00\u7a2e\u65b0\u7a4e\u7684\u611f\u6e2c\u8f14\u52a9\u6297\u5e72\u64fe\u7b56\u7565\uff0c\u540c\u6642\u6700\u4f73\u5316\u6ce2\u675f\u6210\u5f62\u3001\u4f7f\u7528\u8005\u6392\u7a0b\u548c\u8cc7\u6e90\u5206\u914d\u3002\u4f7f\u7528 BERT \u548c RoBERTa \u6a21\u578b\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u8b49\u660e\u4e86 R-SFLLM \u7684\u6709\u6548\u6027\uff0c\u5728\u5404\u7a2e\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u4efb\u52d9\u548c\u8cc7\u6599\u96c6\u4e0a\u5be6\u73fe\u4e86\u63a5\u8fd1\u57fa\u7dda\u7684\u6548\u80fd\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u9032\u4e00\u6b65\u5f15\u5165\u4e86\u5c0d\u6297\u8a13\u7df4\u7d44\u6210\uff0c\u5176\u4e2d\u53d7\u63a7\u7684\u96dc\u8a0a\u66b4\u9732\u6703\u5728\u8a13\u7df4\u671f\u9593\u986f\u8457\u589e\u5f37 LLM \u5c0d\u64fe\u52d5\u53c3\u6578\u7684\u5f48\u6027\u3002\u7d50\u679c\u8868\u660e\uff0c\u5c0d\u96dc\u8a0a\u66f4\u654f\u611f\u7684\u6a21\u578b\uff08\u4f8b\u5982 RoBERTa\uff09\u53d7\u76ca\u65bc\u6b64\u529f\u80fd\uff0c\u7279\u5225\u662f\u5728\u8cc7\u6e90\u5206\u914d\u4e0d\u516c\u5e73\u7684\u60c5\u6cc1\u4e0b\u3002\u5b83\u4e5f\u8868\u660e\uff0c\u6700\u58de\u60c5\u6cc1\u4e0b\u7684\u5e72\u64fe\u7279\u5225\u6703\u8f49\u5316\u70ba\u6700\u58de\u60c5\u6cc1\u4e0b\u7684\u6a21\u578b\u7d50\u679c\uff0c\u56e0\u6b64\u9700\u8981\u9632\u5e72\u64fe SFL \u5354\u5b9a\u3002", "author": "Aladin Djuhera et.al.", "authors": "Aladin Djuhera, Vlad C. Andrei, Xinyang Li, Ullrich J. M\u00f6nich, Holger Boche, Walid Saad", "id": "2407.11654v1", "paper_url": "http://arxiv.org/abs/2407.11654v1", "repo": "null"}}