{"2408.12249": {"publish_time": "2024-08-22", "title": "LLMs are not Zero-Shot Reasoners for Biomedical Information Extraction", "paper_summary": "Large Language Models (LLMs) are increasingly adopted for applications in\nhealthcare, reaching the performance of domain experts on tasks such as\nquestion answering and document summarisation. Despite their success on these\ntasks, it is unclear how well LLMs perform on tasks that are traditionally\npursued in the biomedical domain, such as structured information extration. To\nbreach this gap, in this paper, we systematically benchmark LLM performance in\nMedical Classification and Named Entity Recognition (NER) tasks. We aim to\ndisentangle the contribution of different factors to the performance,\nparticularly the impact of LLMs' task knowledge and reasoning capabilities,\ntheir (parametric) domain knowledge, and addition of external knowledge. To\nthis end we evaluate various open LLMs -- including BioMistral and Llama-2\nmodels -- on a diverse set of biomedical datasets, using standard prompting,\nChain-of-Thought (CoT) and Self-Consistency based reasoning as well as\nRetrieval-Augmented Generation (RAG) with PubMed and Wikipedia corpora.\nCounter-intuitively, our results reveal that standard prompting consistently\noutperforms more complex techniques across both tasks, laying bare the\nlimitations in the current application of CoT, self-consistency and RAG in the\nbiomedical domain. Our findings suggest that advanced prompting methods\ndeveloped for knowledge- or reasoning-intensive tasks, such as CoT or RAG, are\nnot easily portable to biomedical tasks where precise structured outputs are\nrequired. This highlights the need for more effective integration of external\nknowledge and reasoning mechanisms in LLMs to enhance their performance in\nreal-world biomedical applications.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6108\u4f86\u6108\u591a\u7528\u65bc\u91ab\u7642\u4fdd\u5065\u61c9\u7528\uff0c\u5728\u56de\u7b54\u554f\u984c\u548c\u6587\u4ef6\u6458\u8981\u7b49\u4efb\u52d9\u4e0a\u9054\u5230\u9818\u57df\u5c08\u5bb6\u7684\u8868\u73fe\u3002\u5118\u7ba1\u9019\u4e9b\u4efb\u52d9\u7372\u5f97\u6210\u529f\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a LLM \u5728\u751f\u7269\u91ab\u5b78\u9818\u57df\u50b3\u7d71\u4e0a\u57f7\u884c\u7684\u4efb\u52d9\uff0c\u4f8b\u5982\u7d50\u69cb\u5316\u8cc7\u8a0a\u8403\u53d6\uff0c\u8868\u73fe\u5982\u4f55\u3002\u70ba\u4e86\u5f4c\u88dc\u9019\u500b\u5dee\u8ddd\uff0c\u6211\u5011\u5728\u9019\u7bc7\u8ad6\u6587\u4e2d\u7cfb\u7d71\u6027\u5730\u8a55\u91cf LLM \u5728\u91ab\u5b78\u5206\u985e\u548c\u547d\u540d\u5be6\u9ad4\u8fa8\u8b58 (NER) \u4efb\u52d9\u4e2d\u7684\u8868\u73fe\u3002\u6211\u5011\u7684\u76ee\u6a19\u662f\u91d0\u6e05\u4e0d\u540c\u56e0\u7d20\u5c0d\u8868\u73fe\u7684\u8ca2\u737b\uff0c\u7279\u5225\u662f LLM \u7684\u4efb\u52d9\u77e5\u8b58\u548c\u63a8\u7406\u80fd\u529b\u3001\u5b83\u5011\u7684\uff08\u53c3\u6578\uff09\u9818\u57df\u77e5\u8b58\uff0c\u4ee5\u53ca\u5916\u90e8\u77e5\u8b58\u7684\u52a0\u5165\u3002\u70ba\u6b64\uff0c\u6211\u5011\u8a55\u4f30\u5404\u7a2e\u958b\u653e\u7684 LLM\uff08\u5305\u62ec BioMistral \u548c Llama-2 \u6a21\u578b\uff09\uff0c\u4f7f\u7528\u6a19\u6e96\u63d0\u793a\u3001\u57fa\u65bc\u601d\u8003\u93c8 (CoT) \u548c\u81ea\u6d3d\u6027\u7684\u63a8\u7406\u4ee5\u53ca\u4f7f\u7528 PubMed \u548c\u7dad\u57fa\u767e\u79d1\u8a9e\u6599\u5eab\u7684\u6aa2\u7d22\u589e\u5f37\u751f\u6210 (RAG) \u5728\u591a\u6a23\u5316\u7684\u751f\u7269\u91ab\u5b78\u8cc7\u6599\u96c6\u4e0a\u3002\u8207\u76f4\u89ba\u76f8\u53cd\uff0c\u6211\u5011\u7684\u7d50\u679c\u986f\u793a\u6a19\u6e96\u63d0\u793a\u5728\u5169\u9805\u4efb\u52d9\u4e2d\u59cb\u7d42\u512a\u65bc\u66f4\u8907\u96dc\u7684\u6280\u8853\uff0c\u63ed\u9732\u4e86\u5728\u751f\u7269\u91ab\u5b78\u9818\u57df\u4e2d CoT\u3001\u81ea\u6d3d\u6027\u548c RAG \u7684\u7576\u524d\u61c9\u7528\u4e2d\u7684\u9650\u5236\u3002\u6211\u5011\u7684\u767c\u73fe\u8868\u660e\uff0c\u70ba\u77e5\u8b58\u6216\u63a8\u7406\u5bc6\u96c6\u578b\u4efb\u52d9\uff08\u4f8b\u5982 CoT \u6216 RAG\uff09\u958b\u767c\u7684\u9ad8\u968e\u63d0\u793a\u65b9\u6cd5\u4e0d\u5bb9\u6613\u79fb\u690d\u5230\u9700\u8981\u7cbe\u78ba\u7d50\u69cb\u5316\u8f38\u51fa\u7684\u751f\u7269\u91ab\u5b78\u4efb\u52d9\u3002\u9019\u7a81\u986f\u51fa\u9700\u8981\u66f4\u6709\u6548\u5730\u6574\u5408\u5916\u90e8\u77e5\u8b58\u548c\u63a8\u7406\u6a5f\u5236\u5230 LLM \u4e2d\uff0c\u4ee5\u589e\u5f37\u5b83\u5011\u5728\u5be6\u969b\u751f\u7269\u91ab\u5b78\u61c9\u7528\u4e2d\u7684\u8868\u73fe\u3002", "author": "Aishik Nagar et.al.", "authors": "Aishik Nagar, Viktor Schlegel, Thanh-Tung Nguyen, Hao Li, Yuping Wu, Kuluhan Binici, Stefan Winkler", "id": "2408.12249v1", "paper_url": "http://arxiv.org/abs/2408.12249v1", "repo": "null"}}