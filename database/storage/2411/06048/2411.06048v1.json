{"2411.06048": {"publish_time": "2024-11-09", "title": "An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models", "paper_summary": "Large Multimodal Models (LMMs) have achieved strong performance across a\nrange of vision and language tasks. However, their spatial reasoning\ncapabilities are under-investigated. In this paper, we construct a novel VQA\ndataset, Spatial-MM, to comprehensively study LMMs' spatial understanding and\nreasoning capabilities. Our analyses on object-relationship and multi-hop\nreasoning reveal several important findings. Firstly, bounding boxes and scene\ngraphs, even synthetic ones, can significantly enhance LMMs' spatial reasoning.\nSecondly, LMMs struggle more with questions posed from the human perspective\nthan the camera perspective about the image. Thirdly, chain of thought (CoT)\nprompting does not improve model performance on complex multi-hop questions\ninvolving spatial relations. % Moreover, spatial reasoning steps are much less\naccurate than non-spatial ones across MLLMs. Lastly, our perturbation analysis\non GQA-spatial reveals that LMMs are much stronger at basic object detection\nthan complex spatial reasoning. We believe our benchmark dataset and in-depth\nanalyses can spark further research on LMMs spatial reasoning. Spatial-MM\nbenchmark is available at: https://github.com/FatemehShiri/Spatial-MM", "paper_summary_zh": "\u5927\u578b\u591a\u6a21\u614b\u6a21\u578b (LMM) \u5df2\u5728\u5404\u7a2e\u8996\u89ba\u548c\u8a9e\u8a00\u4efb\u52d9\u4e2d\u53d6\u5f97\u5f37\u52c1\u7684\u8868\u73fe\u3002\u7136\u800c\uff0c\u5b83\u5011\u7684\u7a7a\u9593\u63a8\u7406\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u69cb\u5efa\u4e86\u4e00\u500b\u65b0\u7a4e\u7684 VQA \u8cc7\u6599\u96c6 Spatial-MM\uff0c\u4ee5\u5168\u9762\u7814\u7a76 LMM \u7684\u7a7a\u9593\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\u3002\u6211\u5011\u5c0d\u7269\u4ef6\u95dc\u4fc2\u548c\u591a\u8df3\u63a8\u7406\u7684\u5206\u6790\u63ed\u793a\u4e86\u5e7e\u500b\u91cd\u8981\u7684\u767c\u73fe\u3002\u9996\u5148\uff0c\u908a\u754c\u6846\u548c\u5834\u666f\u5716\uff0c\u5373\u4f7f\u662f\u5408\u6210\u7684\uff0c\u4e5f\u53ef\u4ee5\u986f\u8457\u589e\u5f37 LMM \u7684\u7a7a\u9593\u63a8\u7406\u80fd\u529b\u3002\u5176\u6b21\uff0cLMM \u5728\u56de\u7b54\u5f9e\u4eba\u985e\u8996\u89d2\u63d0\u51fa\u7684\u554f\u984c\u6642\u6bd4\u5f9e\u76f8\u6a5f\u8996\u89d2\u63d0\u51fa\u7684\u554f\u984c\u6642\u9047\u5230\u66f4\u591a\u56f0\u96e3\u3002\u7b2c\u4e09\uff0c\u601d\u8003\u93c8 (CoT) \u63d0\u793a\u4e26\u672a\u6539\u5584\u6a21\u578b\u5728\u6d89\u53ca\u7a7a\u9593\u95dc\u4fc2\u7684\u8907\u96dc\u591a\u8df3\u554f\u984c\u4e0a\u7684\u6548\u80fd\u3002% \u6b64\u5916\uff0c\u5728 MLLM \u4e2d\uff0c\u7a7a\u9593\u63a8\u7406\u6b65\u9a5f\u7684\u6e96\u78ba\u5ea6\u9060\u4f4e\u65bc\u975e\u7a7a\u9593\u6b65\u9a5f\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5c0d GQA-spatial \u7684\u64fe\u52d5\u5206\u6790\u8868\u660e\uff0cLMM \u5728\u57fa\u672c\u7269\u4ef6\u5075\u6e2c\u65b9\u9762\u7684\u80fd\u529b\u9060\u5f37\u65bc\u8907\u96dc\u7684\u7a7a\u9593\u63a8\u7406\u3002\u6211\u5011\u76f8\u4fe1\u6211\u5011\u7684\u57fa\u6e96\u8cc7\u6599\u96c6\u548c\u6df1\u5165\u5206\u6790\u53ef\u4ee5\u6fc0\u767c\u5c0d LMM \u7a7a\u9593\u63a8\u7406\u7684\u9032\u4e00\u6b65\u7814\u7a76\u3002Spatial-MM \u57fa\u6e96\u53ef\u5728\u4ee5\u4e0b\u7db2\u5740\u53d6\u5f97\uff1ahttps://github.com/FatemehShiri/Spatial-MM", "author": "Fatemeh Shiri et.al.", "authors": "Fatemeh Shiri, Xiao-Yu Guo, Mona Golestan Far, Xin Yu, Gholamreza Haffari, Yuan-Fang Li", "id": "2411.06048v1", "paper_url": "http://arxiv.org/abs/2411.06048v1", "repo": "https://github.com/fatemehshiri/spatial-mm"}}