{"2411.15216": {"publish_time": "2024-11-20", "title": "Dist Loss: Enhancing Regression in Few-Shot Region through Distribution Distance Constraint", "paper_summary": "Imbalanced data distributions are prevalent in real-world scenarios, posing\nsignificant challenges in both imbalanced classification and imbalanced\nregression tasks. They often cause deep learning models to overfit in areas of\nhigh sample density (many-shot regions) while underperforming in areas of low\nsample density (few-shot regions). This characteristic restricts the utility of\ndeep learning models in various sectors, notably healthcare, where areas with\nfew-shot data hold greater clinical relevance. While recent studies have shown\nthe benefits of incorporating distribution information in imbalanced\nclassification tasks, such strategies are rarely explored in imbalanced\nregression. In this paper, we address this issue by introducing a novel loss\nfunction, termed Dist Loss, designed to minimize the distribution distance\nbetween the model's predictions and the target labels in a differentiable\nmanner, effectively integrating distribution information into model training.\nDist Loss enables deep learning models to regularize their output distribution\nduring training, effectively enhancing their focus on few-shot regions. We have\nconducted extensive experiments across three datasets spanning computer vision\nand healthcare: IMDB-WIKI-DIR, AgeDB-DIR, and ECG-Ka-DIR. The results\ndemonstrate that Dist Loss effectively mitigates the negative impact of\nimbalanced data distribution on model performance, achieving state-of-the-art\nresults in sparse data regions. Furthermore, Dist Loss is easy to integrate,\ncomplementing existing methods.", "paper_summary_zh": "<paragraph>\u4e0d\u5e73\u8861\u8cc7\u6599\u5206\u4f48\u5728\u5be6\u969b\u60c5\u6cc1\u4e2d\u5f88\u5e38\u898b\uff0c\u5c0d\u4e0d\u5e73\u8861\u5206\u985e\u548c\u4e0d\u5e73\u8861\u56de\u6b78\u4efb\u52d9\u69cb\u6210\u91cd\u5927\u6311\u6230\u3002\u5b83\u5011\u901a\u5e38\u5c0e\u81f4\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\u5728\u6a23\u672c\u5bc6\u5ea6\u9ad8\uff08\u591a\u6a23\u672c\u5340\u57df\uff09\u7684\u5340\u57df\u904e\u5ea6\u64ec\u5408\uff0c\u800c\u5728\u6a23\u672c\u5bc6\u5ea6\u4f4e\uff08\u5c11\u6a23\u672c\u5340\u57df\uff09\u7684\u5340\u57df\u8868\u73fe\u4e0d\u4f73\u3002\u9019\u7a2e\u7279\u6027\u9650\u5236\u4e86\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\u5728\u5404\u500b\u9818\u57df\u7684\u5be6\u7528\u6027\uff0c\u7279\u5225\u662f\u5728\u91ab\u7642\u4fdd\u5065\u9818\u57df\uff0c\u5176\u4e2d\u5c11\u6a23\u672c\u8cc7\u6599\u5340\u57df\u5177\u6709\u66f4\u5927\u7684\u81e8\u5e8a\u76f8\u95dc\u6027\u3002\u5118\u7ba1\u6700\u8fd1\u7684\u7814\u7a76\u986f\u793a\u4e86\u5728\u4e0d\u5e73\u8861\u5206\u985e\u4efb\u52d9\u4e2d\u7d0d\u5165\u5206\u4f48\u8cc7\u8a0a\u7684\u597d\u8655\uff0c\u4f46\u6b64\u985e\u7b56\u7565\u5728\u4e0d\u5e73\u8861\u56de\u6b78\u4e2d\u5f88\u5c11\u88ab\u63a2\u8a0e\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u900f\u904e\u5f15\u5165\u4e00\u7a2e\u7a31\u70ba Dist Loss \u7684\u65b0\u640d\u5931\u51fd\u6578\u4f86\u89e3\u6c7a\u6b64\u554f\u984c\uff0c\u8a72\u51fd\u6578\u65e8\u5728\u4ee5\u53ef\u5fae\u5206\u7684\u65b9\u5f0f\u6700\u5c0f\u5316\u6a21\u578b\u9810\u6e2c\u8207\u76ee\u6a19\u6a19\u7c64\u4e4b\u9593\u7684\u5206\u4f48\u8ddd\u96e2\uff0c\u6709\u6548\u5730\u5c07\u5206\u4f48\u8cc7\u8a0a\u6574\u5408\u5230\u6a21\u578b\u8a13\u7df4\u4e2d\u3002Dist Loss \u80fd\u8b93\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\u5728\u8a13\u7df4\u671f\u9593\u8abf\u6574\u5176\u8f38\u51fa\u5206\u4f48\uff0c\u6709\u6548\u5730\u52a0\u5f37\u5b83\u5011\u5c0d\u5c11\u6a23\u672c\u5340\u57df\u7684\u95dc\u6ce8\u3002\u6211\u5011\u8de8\u8d8a\u96fb\u8166\u8996\u89ba\u548c\u91ab\u7642\u4fdd\u5065\u9818\u57df\u7684\u4e09\u500b\u8cc7\u6599\u96c6\u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u5be6\u9a57\uff1aIMDB-WIKI-DIR\u3001AgeDB-DIR \u548c ECG-Ka-DIR\u3002\u7d50\u679c\u8868\u660e\uff0cDist Loss \u6709\u6548\u5730\u6e1b\u8f15\u4e86\u4e0d\u5e73\u8861\u8cc7\u6599\u5206\u4f48\u5c0d\u6a21\u578b\u6548\u80fd\u7684\u8ca0\u9762\u5f71\u97ff\uff0c\u5728\u7a00\u758f\u8cc7\u6599\u5340\u57df\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u9032\u7684\u7d50\u679c\u3002\u6b64\u5916\uff0cDist Loss \u6613\u65bc\u6574\u5408\uff0c\u53ef\u88dc\u5145\u73fe\u6709\u65b9\u6cd5\u3002</paragraph>", "author": "Guangkun Nie et.al.", "authors": "Guangkun Nie, Gongzheng Tang, Shenda Hong", "id": "2411.15216v1", "paper_url": "http://arxiv.org/abs/2411.15216v1", "repo": "null"}}