{"2411.19870": {"publish_time": "2024-11-29", "title": "DeMo: Decoupled Momentum Optimization", "paper_summary": "Training large neural networks typically requires sharing gradients between\naccelerators through specialized high-speed interconnects. Drawing from the\nsignal processing principles of frequency decomposition and energy compaction,\nwe demonstrate that synchronizing full optimizer states and model parameters\nduring training is unnecessary. By decoupling momentum updates and allowing\ncontrolled divergence in optimizer states across accelerators, we achieve\nimproved convergence compared to state-of-the-art optimizers. We introduce\n{\\textbf{De}}coupled {\\textbf{Mo}}mentum (DeMo), a fused optimizer and data\nparallel algorithm that reduces inter-accelerator communication requirements by\nseveral orders of magnitude. This enables training of large neural networks\neven with limited network bandwidth and heterogeneous hardware. Our method is\ntopology-agnostic and architecture-independent and supports scalable\nclock-synchronous distributed training with negligible compute and memory\noverhead. Empirical results show that models trained with DeMo match or exceed\nthe performance of equivalent models trained with AdamW, while eliminating the\nneed for high-speed interconnects when pre-training large scale foundation\nmodels. An open source reference PyTorch implementation is published on GitHub\nat https://github.com/bloc97/DeMo", "paper_summary_zh": "\u8a13\u7df4\u5927\u578b\u795e\u7d93\u7db2\u8def\u901a\u5e38\u9700\u8981\u900f\u904e\u7279\u6b8a\u7684\u9ad8\u901f\u4e92\u9023\u4f86\u5206\u4eab\u52a0\u901f\u5668\u4e4b\u9593\u7684\u68af\u5ea6\u3002\u6211\u5011\u5f9e\u983b\u7387\u5206\u89e3\u548c\u80fd\u91cf\u58d3\u7e2e\u7684\u8a0a\u865f\u8655\u7406\u539f\u7406\u4e2d\u64f7\u53d6\u9748\u611f\uff0c\u8b49\u660e\u5728\u8a13\u7df4\u671f\u9593\u540c\u6b65\u5b8c\u6574\u7684\u6700\u4f73\u5316\u5668\u72c0\u614b\u548c\u6a21\u578b\u53c3\u6578\u662f\u4e0d\u5fc5\u8981\u7684\u3002\u900f\u904e\u89e3\u8026\u52d5\u91cf\u66f4\u65b0\u4e26\u5141\u8a31\u52a0\u901f\u5668\u4e4b\u9593\u7684\u6700\u4f73\u5316\u5668\u72c0\u614b\u53d7\u63a7\u5206\u6b67\uff0c\u6211\u5011\u8207\u6700\u5148\u9032\u7684\u6700\u4f73\u5316\u5668\u76f8\u6bd4\uff0c\u9054\u5230\u4e86\u66f4\u4f73\u7684\u6536\u6582\u6027\u3002\u6211\u5011\u5f15\u5165\u4e86{\\textbf{De}}coupled {\\textbf{Mo}}mentum (DeMo)\uff0c\u4e00\u500b\u878d\u5408\u7684\u6700\u4f73\u5316\u5668\u548c\u8cc7\u6599\u5e73\u884c\u6f14\u7b97\u6cd5\uff0c\u5b83\u5c07\u52a0\u901f\u5668\u9593\u7684\u901a\u8a0a\u9700\u6c42\u964d\u4f4e\u4e86\u5e7e\u500b\u6578\u91cf\u7d1a\u3002\u9019\u4f7f\u5f97\u5373\u4f7f\u5728\u7db2\u8def\u983b\u5bec\u6709\u9650\u548c\u786c\u9ad4\u7570\u8cea\u7684\u60c5\u6cc1\u4e0b\uff0c\u4e5f\u80fd\u8a13\u7df4\u5927\u578b\u795e\u7d93\u7db2\u8def\u3002\u6211\u5011\u7684\u6a21\u578b\u8207\u62d3\u64b2\u7121\u95dc\u4e14\u8207\u67b6\u69cb\u7121\u95dc\uff0c\u4e26\u652f\u63f4\u53ef\u64f4\u5145\u7684\u6642\u8108\u540c\u6b65\u5206\u6563\u5f0f\u8a13\u7df4\uff0c\u4e14\u904b\u7b97\u548c\u8a18\u61b6\u9ad4\u8ca0\u64d4\u53ef\u4ee5\u5ffd\u7565\u4e0d\u8a08\u3002\u7d93\u9a57\u7d50\u679c\u986f\u793a\uff0c\u4f7f\u7528 DeMo \u8a13\u7df4\u7684\u6a21\u578b\u8207\u4f7f\u7528 AdamW \u8a13\u7df4\u7684\u7b49\u6548\u6a21\u578b\u76f8\u5339\u914d\u6216\u512a\u65bc\u5f8c\u8005\uff0c\u540c\u6642\u5728\u9810\u8a13\u7df4\u5927\u578b\u57fa\u790e\u6a21\u578b\u6642\uff0c\u6d88\u9664\u4e86\u5c0d\u9ad8\u901f\u4e92\u9023\u7684\u9700\u6c42\u3002\u4e00\u500b\u958b\u653e\u539f\u59cb\u78bc\u7684 PyTorch \u53c3\u8003\u5be6\u4f5c\u5df2\u767c\u4f48\u5728 GitHub \u4e0a\uff0c\u7db2\u5740\u70ba https://github.com/bloc97/DeMo", "author": "Bowen Peng et.al.", "authors": "Bowen Peng, Jeffrey Quesnelle, Diederik P. Kingma", "id": "2411.19870v1", "paper_url": "http://arxiv.org/abs/2411.19870v1", "repo": "https://github.com/bloc97/demo"}}