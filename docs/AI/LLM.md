
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-10**|**Hint-AD: Holistically Aligned Interpretability in End-to-End Autonomous Driving**|Kairui Ding et.al.|[2409.06702v1](http://arxiv.org/abs/2409.06702v1)|null|
|**2024-09-10**|**Geometric-Averaged Preference Optimization for Soft Preference Labels**|Hiroki Furuta et.al.|[2409.06691v1](http://arxiv.org/abs/2409.06691v1)|null|
|**2024-09-10**|**Benchmarking Sub-Genre Classification For Mainstage Dance Music**|Hongzhi Shu et.al.|[2409.06690v1](http://arxiv.org/abs/2409.06690v1)|null|
|**2024-09-10**|**E2LLM: Encoder Elongated Large Language Models for Long-Context Understanding and Reasoning**|Zihan Liao et.al.|[2409.06679v1](http://arxiv.org/abs/2409.06679v1)|null|
|**2024-09-10**|**Liability and Insurance for Catastrophic Losses: the Nuclear Power Precedent and Lessons for AI**|Cristian Trout et.al.|[2409.06673v1](http://arxiv.org/abs/2409.06673v1)|null|
|**2024-09-10**|**LLaMA-Omni: Seamless Speech Interaction with Large Language Models**|Qingkai Fang et.al.|[2409.06666v1](http://arxiv.org/abs/2409.06666v1)|[link](https://github.com/ictnlp/llama-omni)|
|**2024-09-10**|**Sortformer: Seamless Integration of Speaker Diarization and ASR by Bridging Timestamps and Tokens**|Taejin Park et.al.|[2409.06656v1](http://arxiv.org/abs/2409.06656v1)|null|
|**2024-09-10**|**EyeCLIP: A visual-language foundation model for multi-modal ophthalmic image analysis**|Danli Shi et.al.|[2409.06644v1](http://arxiv.org/abs/2409.06644v1)|null|
|**2024-09-10**|**TeXBLEU: Automatic Metric for Evaluate LaTeX Format**|Kyudan Jung et.al.|[2409.06639v1](http://arxiv.org/abs/2409.06639v1)|[link](https://github.com/kyudan1/texbleu)|
|**2024-09-10**|**MoWE-Audio: Multitask AudioLLMs with Mixture of Weak Encoders**|Wenyu Zhang et.al.|[2409.06635v1](http://arxiv.org/abs/2409.06635v1)|null|
|**2024-09-10**|**A Practice of Post-Training on Llama-3 70B with Optimal Selection of Additional Language Mixture Ratio**|Ningyuan Xi et.al.|[2409.06624v1](http://arxiv.org/abs/2409.06624v1)|null|
|**2024-09-10**|**Exploring Italian sentence embeddings properties through multi-tasking**|Vivi Nastase et.al.|[2409.06622v1](http://arxiv.org/abs/2409.06622v1)|null|
|**2024-09-10**|**Label-free Monitoring of Self-Supervised Learning Progress**|Isaac Xu et.al.|[2409.06612v1](http://arxiv.org/abs/2409.06612v1)|null|
|**2024-09-10**|**Alleviating Hallucinations in Large Language Models with Scepticism Modeling**|Yetao Wu et.al.|[2409.06601v1](http://arxiv.org/abs/2409.06601v1)|null|
|**2024-09-10**|**GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering**|Sacha Muller et.al.|[2409.06595v1](http://arxiv.org/abs/2409.06595v1)|null|
|**2024-09-10**|**Developing the Temporal Graph Convolutional Neural Network Model to Predict Hip Replacement using Electronic Health Records**|Zoe Hancox et.al.|[2409.06585v1](http://arxiv.org/abs/2409.06585v1)|[link](https://github.com/zoehancox/sparse_tgcnn)|
|**2024-09-10**|**Quantifying and Enabling the Interpretability of CLIP-like Models**|Avinash Madasu et.al.|[2409.06579v1](http://arxiv.org/abs/2409.06579v1)|null|
|**2024-09-10**|**Exploring syntactic information in sentence embeddings through multilingual subject-verb agreement**|Vivi Nastase et.al.|[2409.06567v1](http://arxiv.org/abs/2409.06567v1)|null|
|**2024-09-10**|**Indirect Dynamic Negotiation in the Nash Demand Game**|Tatiana V. Guy et.al.|[2409.06566v1](http://arxiv.org/abs/2409.06566v1)|null|
|**2024-09-10**|**From LIMA to DeepLIMA: following a new path of interoperability**|Victor Bocharov et.al.|[2409.06550v1](http://arxiv.org/abs/2409.06550v1)|null|
|**2024-09-10**|**Mapping News Narratives Using LLMs and Narrative-Structured Text Embeddings**|Jan Elfes et.al.|[2409.06540v1](http://arxiv.org/abs/2409.06540v1)|null|
|**2024-09-10**|**Questioning Internal Knowledge Structure of Large Language Models Through the Lens of the Olympic Games**|Juhwan Choi et.al.|[2409.06518v1](http://arxiv.org/abs/2409.06518v1)|null|
|**2024-09-10**|**Sine, Transient, Noise Neural Modeling of Piano Notes**|Riccardo Simionato et.al.|[2409.06513v1](http://arxiv.org/abs/2409.06513v1)|null|
|**2024-09-10**|**Aligning Machine and Human Visual Representations across Abstraction Levels**|Lukas Muttenthaler et.al.|[2409.06509v1](http://arxiv.org/abs/2409.06509v1)|null|
|**2024-09-10**|**Superior Computer Chess with Model Predictive Control, Reinforcement Learning, and Rollout**|Atharva Gundawar et.al.|[2409.06477v1](http://arxiv.org/abs/2409.06477v1)|null|
|**2024-09-10**|**An Effective Context-Balanced Adaptation Approach for Long-Tailed Speech Recognition**|Yi-Cheng Wang et.al.|[2409.06468v1](http://arxiv.org/abs/2409.06468v1)|null|
|**2024-09-10**|**Multimodal Large Language Model Driven Scenario Testing for Autonomous Vehicles**|Qiujing Lu et.al.|[2409.06450v1](http://arxiv.org/abs/2409.06450v1)|null|
|**2024-09-10**|**HexaCoder: Secure Code Generation via Oracle-Guided Synthetic Training Data**|Hossein Hajipour et.al.|[2409.06446v1](http://arxiv.org/abs/2409.06446v1)|null|
|**2024-09-10**|**Learning Generative Interactive Environments By Trained Agent Exploration**|Naser Kazemi et.al.|[2409.06445v1](http://arxiv.org/abs/2409.06445v1)|[link](https://github.com/insait-institute/genieredux)|
|**2024-09-10**|**GeMuCo: Generalized Multisensory Correlational Model for Body Schema Learning**|Kento Kawaharazuka et.al.|[2409.06427v1](http://arxiv.org/abs/2409.06427v1)|null|
|**2024-09-10**|**Exploring the Integration of Large Language Models in Industrial Test Maintenance Processes**|Ludvig Lemner et.al.|[2409.06416v1](http://arxiv.org/abs/2409.06416v1)|null|
|**2024-09-10**|**Length Desensitization in Directed Preference Optimization**|Wei Liu et.al.|[2409.06411v1](http://arxiv.org/abs/2409.06411v1)|null|
|**2024-09-10**|**Coarse-Grained Sense Inventories Based on Semantic Matching between English Dictionaries**|Masato Kikuchi et.al.|[2409.06386v1](http://arxiv.org/abs/2409.06386v1)|null|
|**2024-09-10**|**Enhancing Sequential Recommendations through Multi-Perspective Reflections and Iteration**|Weicong Qin et.al.|[2409.06377v1](http://arxiv.org/abs/2409.06377v1)|null|
|**2024-09-10**|**SpeechTaxi: On Multilingual Semantic Speech Classification**|Lennart Keller et.al.|[2409.06372v1](http://arxiv.org/abs/2409.06372v1)|null|
|**2024-09-10**|**Distilling Generative-Discriminative Representations for Very Low-Resolution Face Recognition**|Junzheng Zhang et.al.|[2409.06371v1](http://arxiv.org/abs/2409.06371v1)|null|
|**2024-09-10**|**Texture-AD: An Anomaly Detection Dataset and Benchmark for Real Algorithm Development**|Tianwu Lei et.al.|[2409.06367v1](http://arxiv.org/abs/2409.06367v1)|null|
|**2024-09-10**|**Connecting Concept Convexity and Human-Machine Alignment in Deep Neural Networks**|Teresa Dorszewski et.al.|[2409.06362v1](http://arxiv.org/abs/2409.06362v1)|null|
|**2024-09-10**|**MAGDA: Multi-agent guideline-driven diagnostic assistance**|David Bani-Harouni et.al.|[2409.06351v1](http://arxiv.org/abs/2409.06351v1)|null|
|**2024-09-10**|**VoiceWukong: Benchmarking Deepfake Voice Detection**|Ziwei Yan et.al.|[2409.06348v1](http://arxiv.org/abs/2409.06348v1)|null|
|**2024-09-10**|**Compute-Update Federated Learning: A Lattice Coding Approach**|Seyed Mohammad Azimi-Abarghouyi et.al.|[2409.06343v1](http://arxiv.org/abs/2409.06343v1)|null|
|**2024-09-10**|**Retrieval Or Holistic Understanding? Dolce: Differentiate Our Long Context Evaluation Tasks**|Zi Yang et.al.|[2409.06338v1](http://arxiv.org/abs/2409.06338v1)|null|
|**2024-09-10**|**Towards Agentic AI on Particle Accelerators**|Antonin Sulc et.al.|[2409.06336v1](http://arxiv.org/abs/2409.06336v1)|null|
|**2024-09-10**|**Extracting Paragraphs from LLM Token Activations**|Nicholas Pochinkov et.al.|[2409.06328v1](http://arxiv.org/abs/2409.06328v1)|null|
|**2024-09-10**|**LAMP: Learnable Meta-Path Guided Adversarial Contrastive Learning for Heterogeneous Graphs**|Siqing Li et.al.|[2409.06323v1](http://arxiv.org/abs/2409.06323v1)|null|
|**2024-09-10**|**An End-to-End Approach for Chord-Conditioned Song Generation**|Shuochen Gao et.al.|[2409.06307v1](http://arxiv.org/abs/2409.06307v1)|null|
|**2024-09-10**|**Enhancing Long Video Understanding via Hierarchical Event-Based Memory**|Dingxin Cheng et.al.|[2409.06299v1](http://arxiv.org/abs/2409.06299v1)|null|
|**2024-09-10**|**User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study**|Julien Albert et.al.|[2409.06297v1](http://arxiv.org/abs/2409.06297v1)|null|
|**2024-09-10**|**Catch Me if You Can: Detecting Unauthorized Data Use in Deep Learning Models**|Zitao Chen et.al.|[2409.06280v1](http://arxiv.org/abs/2409.06280v1)|null|
|**2024-09-10**|**Ferret: Federated Full-Parameter Tuning at Scale for Large Language Models**|Yao Shu et.al.|[2409.06277v1](http://arxiv.org/abs/2409.06277v1)|[link](https://github.com/allen4747/Ferret)|
|**2024-09-10**|**Keyword-Aware ASR Error Augmentation for Robust Dialogue State Tracking**|Jihyun Lee et.al.|[2409.06263v1](http://arxiv.org/abs/2409.06263v1)|null|
|**2024-09-10**|**DiPT: Enhancing LLM reasoning through diversified perspective-taking**|Hoang Anh Just et.al.|[2409.06241v1](http://arxiv.org/abs/2409.06241v1)|null|
|**2024-09-10**|**NLP-Powered Repository and Search Engine for Academic Papers: A Case Study on Cyber Risk Literature with CyLit**|Linfeng Zhang et.al.|[2409.06226v1](http://arxiv.org/abs/2409.06226v1)|null|
|**2024-09-10**|**Enhancing Temporal Understanding in Audio Question Answering for Large Audio Language Models**|Arvind Krishna Sridhar et.al.|[2409.06223v1](http://arxiv.org/abs/2409.06223v1)|null|
|**2024-09-10**|**Advancing Topic Segmentation of Broadcasted Speech with Multilingual Semantic Embeddings**|Sakshi Deo Shukla et.al.|[2409.06222v1](http://arxiv.org/abs/2409.06222v1)|null|
|**2024-09-10**|**CerviXpert: A Multi-Structural Convolutional Neural Network for Predicting Cervix Type and Cervical Cell Abnormalities**|Rashik Shahriar Akash et.al.|[2409.06220v1](http://arxiv.org/abs/2409.06220v1)|null|
|**2024-09-10**|**SubRegWeigh: Effective and Efficient Annotation Weighing with Subword Regularization**|Kohei Tsuji et.al.|[2409.06216v1](http://arxiv.org/abs/2409.06216v1)|null|
|**2024-09-10**|**Towards Generalizable Scene Change Detection**|Jaewoo Kim et.al.|[2409.06214v1](http://arxiv.org/abs/2409.06214v1)|null|
|**2024-09-10**|**STUN: Structured-Then-Unstructured Pruning for Scalable MoE Pruning**|Jaeseong Lee et.al.|[2409.06211v1](http://arxiv.org/abs/2409.06211v1)|null|
|**2024-09-10**|**Adaptive Transformer Modelling of Density Function for Nonparametric Survival Analysis**|Xin Zhang et.al.|[2409.06209v1](http://arxiv.org/abs/2409.06209v1)|null|
|**2024-09-10**|**SHAPE-IT: Exploring Text-to-Shape-Display for Generative Shape-Changing Behaviors with LLMs**|Wanli Qian et.al.|[2409.06205v1](http://arxiv.org/abs/2409.06205v1)|null|
|**2024-09-10**|**NOVI : Chatbot System for University Novice with BERT and LLMs**|Yoonji Nam et.al.|[2409.06192v1](http://arxiv.org/abs/2409.06192v1)|null|
|**2024-09-10**|**Can Large Language Models Unlock Novel Scientific Research Ideas?**|Sandeep Kumar et.al.|[2409.06185v1](http://arxiv.org/abs/2409.06185v1)|null|
|**2024-09-10**|**SQLucid: Grounding Natural Language Database Queries with Interactive Explanations**|Yuan Tian et.al.|[2409.06178v1](http://arxiv.org/abs/2409.06178v1)|[link](https://github.com/magic-yuantian/sqlucid)|
|**2024-09-10**|**Larger Language Models Don't Care How You Think: Why Chain-of-Thought Prompting Fails in Subjective Tasks**|Georgios Chochlakis et.al.|[2409.06173v1](http://arxiv.org/abs/2409.06173v1)|[link](https://github.com/gchochla/cot-priors)|
|**2024-09-10**|**Deep Learning and Large Language Models for Audio and Text Analysis in Predicting Suicidal Acts in Chinese Psychological Support Hotlines**|Yining Chen et.al.|[2409.06164v1](http://arxiv.org/abs/2409.06164v1)|null|
|**2024-09-10**|**Multiclass Arrhythmia Classification using Smartwatch Photoplethysmography Signals Collected in Real-life Settings**|Dong Han et.al.|[2409.06147v1](http://arxiv.org/abs/2409.06147v1)|null|
|**2024-09-10**|**Draw an Audio: Leveraging Multi-Instruction for Video-to-Audio Synthesis**|Qi Yang et.al.|[2409.06135v1](http://arxiv.org/abs/2409.06135v1)|null|
|**2024-09-10**|**Accelerating Large Language Model Pretraining via LFR Pedagogy: Learn, Focus, and Review**|Neha Prakriya et.al.|[2409.06131v1](http://arxiv.org/abs/2409.06131v1)|null|
|**2024-09-10**|**On the Weaknesses of Backdoor-based Model Watermarking: An Information-theoretic Perspective**|Aoting Hu et.al.|[2409.06130v1](http://arxiv.org/abs/2409.06130v1)|[link](https://github.com/katerina828/iwe)|
|**2024-09-10**|**Case Study: Leveraging GenAI to Build AI-based Surrogates and Regressors for Modeling Radio Frequency Heating in Fusion Energy Science**|E. Wes Bethel et.al.|[2409.06122v1](http://arxiv.org/abs/2409.06122v1)|null|
|**2024-09-09**|**PaRCE: Probabilistic and Reconstruction-Based Competency Estimation for Safe Navigation Under Perception Uncertainty**|Sara Pohland et.al.|[2409.06111v1](http://arxiv.org/abs/2409.06111v1)|null|
|**2024-09-09**|**Doppelgänger's Watch: A Split Objective Approach to Large Language Models**|Shervin Ghasemlou et.al.|[2409.06107v1](http://arxiv.org/abs/2409.06107v1)|null|
|**2024-09-09**|**ClarQ-LLM: A Benchmark for Models Clarifying and Requesting Information in Task-Oriented Dialog**|Yujian Gan et.al.|[2409.06097v1](http://arxiv.org/abs/2409.06097v1)|null|
|**2024-09-09**|**Latent Diffusion Bridges for Unsupervised Musical Audio Timbre Transfer**|Michele Mancusi et.al.|[2409.06096v1](http://arxiv.org/abs/2409.06096v1)|null|
|**2024-09-09**|**Scalable Multitask Learning Using Gradient-based Estimation of Task Affinity**|Dongyue Li et.al.|[2409.06091v1](http://arxiv.org/abs/2409.06091v1)|[link](https://github.com/virtuosoresearch/scalablemtl)|
|**2024-09-09**|**MTLSO: A Multi-Task Learning Approach for Logic Synthesis Optimization**|Faezeh Faez et.al.|[2409.06077v1](http://arxiv.org/abs/2409.06077v1)|null|
|**2024-09-09**|**DetoxBench: Benchmarking Large Language Models for Multitask Fraud & Abuse Detection**|Joymallya Chakraborty et.al.|[2409.06072v1](http://arxiv.org/abs/2409.06072v1)|null|
|**2024-09-09**|**Privacy-Preserving Data Linkage Across Private and Public Datasets for Collaborative Agriculture Research**|Osama Zafar et.al.|[2409.06069v1](http://arxiv.org/abs/2409.06069v1)|null|
|**2024-09-09**|**MLLM-FL: Multimodal Large Language Model Assisted Federated Learning on Heterogeneous and Long-tailed Data**|Jianyi Zhang et.al.|[2409.06067v1](http://arxiv.org/abs/2409.06067v1)|null|
|**2024-09-09**|**Identifying the sources of ideological bias in GPT models through linguistic variation in output**|Christina Walker et.al.|[2409.06043v1](http://arxiv.org/abs/2409.06043v1)|null|
|**2024-09-09**|**Investigating Causal Cues: Strengthening Spoofed Audio Detection with Human-Discernible Linguistic Features**|Zahra Khanjani et.al.|[2409.06033v1](http://arxiv.org/abs/2409.06033v1)|null|
|**2024-09-09**|**SongCreator: Lyrics-based Universal Song Generation**|Shun Lei et.al.|[2409.06029v1](http://arxiv.org/abs/2409.06029v1)|null|
|**2024-09-09**|**Deep Generative Model for Mechanical System Configuration Design**|Yasaman Etesam et.al.|[2409.06016v1](http://arxiv.org/abs/2409.06016v1)|null|
|**2024-09-09**|**Improved Visually Prompted Keyword Localisation in Real Low-Resource Settings**|Leanne Nortje et.al.|[2409.06013v1](http://arxiv.org/abs/2409.06013v1)|null|
|**2024-09-09**|**TransformerRanker: A Tool for Efficiently Finding the Best-Suited Language Models for Downstream Classification Tasks**|Lukas Garbas et.al.|[2409.05997v1](http://arxiv.org/abs/2409.05997v1)|[link](https://github.com/flairnlp/transformer-ranker)|
|**2024-09-09**|**MessIRve: A Large-Scale Spanish Information Retrieval Dataset**|Francisco Valentini et.al.|[2409.05994v1](http://arxiv.org/abs/2409.05994v1)|null|
|**2024-09-09**|**A Comprehensive Comparison Between ANNs and KANs For Classifying EEG Alzheimer's Data**|Akshay Sunkara et.al.|[2409.05989v1](http://arxiv.org/abs/2409.05989v1)|null|
|**2024-09-09**|**AI for Mathematics Mathematical Formalized Problem Solving and Theorem Proving in Different Fields in Lean4**|Xichen Tang et.al.|[2409.05977v1](http://arxiv.org/abs/2409.05977v1)|null|
|**2024-09-09**|**A Small Claims Court for the NLP: Judging Legal Text Classification Strategies With Small Datasets**|Mariana Yukari Noguti et.al.|[2409.05972v1](http://arxiv.org/abs/2409.05972v1)|null|
|**2024-09-09**|**Promptable Closed-loop Traffic Simulation**|Shuhan Tan et.al.|[2409.05863v1](http://arxiv.org/abs/2409.05863v1)|null|
|**2024-09-09**|**MMEvol: Empowering Multimodal Large Language Models with Evol-Instruct**|Run Luo et.al.|[2409.05840v1](http://arxiv.org/abs/2409.05840v1)|null|
|**2024-09-09**|**DeepFM-Crispr: Prediction of CRISPR On-Target Effects via Deep Learning**|Condy Bao et.al.|[2409.05938v1](http://arxiv.org/abs/2409.05938v1)|null|
|**2024-09-09**|**Improving Pretraining Data Using Perplexity Correlations**|Tristan Thrush et.al.|[2409.05816v1](http://arxiv.org/abs/2409.05816v1)|null|
|**2024-09-09**|**The Future of Software Testing: AI-Powered Test Case Generation and Validation**|Mohammad Baqar et.al.|[2409.05808v1](http://arxiv.org/abs/2409.05808v1)|null|
|**2024-09-09**|**Benchmarking Chinese Knowledge Rectification in Large Language Models**|Tianhe Lu et.al.|[2409.05806v1](http://arxiv.org/abs/2409.05806v1)|[link](https://github.com/zjunlp/easyedit)|
|**2024-09-09**|**Enhancing Preference-based Linear Bandits via Human Response Time**|Shen Li et.al.|[2409.05798v1](http://arxiv.org/abs/2409.05798v1)|null|
|**2024-09-09**|**NeurLZ: On Enhancing Lossy Compression Performance based on Error-Controlled Neural Learning for Scientific Data**|Wenqi Jia et.al.|[2409.05785v2](http://arxiv.org/abs/2409.05785v2)|null|
|**2024-09-09**|**Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models**|Emily Cheng et.al.|[2409.05771v1](http://arxiv.org/abs/2409.05771v1)|null|
|**2024-09-09**|**Elucidating Optimal Reward-Diversity Tradeoffs in Text-to-Image Diffusion Models**|Rohit Jena et.al.|[2409.06493v1](http://arxiv.org/abs/2409.06493v1)|null|

#### Abstracts
##### **Hint-AD: Holistically Aligned Interpretability in End-to-End Autonomous Driving**
2409.06702v1 by Kairui Ding, Boyuan Chen, Yuchen Su, Huan-ang Gao, Bu Jin, Chonghao Sima, Wuqiang Zhang, Xiaohui Li, Paul Barsch, Hongyang Li, Hao Zhao

End-to-end architectures in autonomous driving (AD) face a significant
challenge in interpretability, impeding human-AI trust. Human-friendly natural
language has been explored for tasks such as driving explanation and 3D
captioning. However, previous works primarily focused on the paradigm of
declarative interpretability, where the natural language interpretations are
not grounded in the intermediate outputs of AD systems, making the
interpretations only declarative. In contrast, aligned interpretability
establishes a connection between language and the intermediate outputs of AD
systems. Here we introduce Hint-AD, an integrated AD-language system that
generates language aligned with the holistic perception-prediction-planning
outputs of the AD model. By incorporating the intermediate outputs and a
holistic token mixer sub-network for effective feature adaptation, Hint-AD
achieves desirable accuracy, achieving state-of-the-art results in driving
language tasks including driving explanation, 3D dense captioning, and command
prediction. To facilitate further study on driving explanation task on
nuScenes, we also introduce a human-labeled dataset, Nu-X. Codes, dataset, and
models will be publicly available.

摘要：端對端自動駕駛 (AD) 架構在可解釋性上會面臨重大挑戰，阻礙人類對 AI 的信任。人類友善的自然語言已被探索用於駕駛解釋和 3D 字幕等任務。然而，先前的作品主要集中在宣告式可解釋性的範例上，其中自然語言解釋並未奠基於 AD 系統的中間輸出，使得解釋僅為宣告式。相反地，校準的可解釋性在語言和 AD 系統的中間輸出之間建立了連結。在此我們介紹 Hint-AD，一個整合的 AD 語言系統，用於產生與 AD 模型的整體感知預測規劃輸出校準的語言。透過結合中間輸出和一個用於有效特徵適應的整體標記混合器子網路，Hint-AD 達到了理想的準確度，在駕駛語言任務中取得了最先進的成果，包括駕駛解釋、3D 密集字幕和指令預測。為了促進在 nuScenes 上進一步研究駕駛解釋任務，我們還介紹了一個人類標記的資料集 Nu-X。程式碼、資料集和模型將公開提供。

##### **Geometric-Averaged Preference Optimization for Soft Preference Labels**
2409.06691v1 by Hiroki Furuta, Kuang-Huei Lee, Shixiang Shane Gu, Yutaka Matsuo, Aleksandra Faust, Heiga Zen, Izzeddin Gur

Many algorithms for aligning LLMs with human preferences assume that human
preferences are binary and deterministic. However, it is reasonable to think
that they can vary with different individuals, and thus should be
distributional to reflect the fine-grained relationship between the responses.
In this work, we introduce the distributional soft preference labels and
improve Direct Preference Optimization (DPO) with a weighted geometric average
of the LLM output likelihood in the loss function. In doing so, the scale of
learning loss is adjusted based on the soft labels, and the loss with equally
preferred responses would be close to zero. This simple modification can be
easily applied to any DPO family and helps the models escape from the
over-optimization and objective mismatch prior works suffer from. In our
experiments, we simulate the soft preference labels with AI feedback from LLMs
and demonstrate that geometric averaging consistently improves performance on
standard benchmarks for alignment research. In particular, we observe more
preferable responses than binary labels and significant improvements with data
where modestly-confident labels are in the majority.

摘要：許多用於將 LLM 與人類偏好對齊的演算法假設人類偏好是二元的且確定的。然而，可以合理地認為它們會因人而異，因此應以分佈式方式反映回應之間的細微關係。在這項工作中，我們引入了分佈式軟偏好標籤，並使用損失函數中 LLM 輸出似然加權幾何平均值改進了直接偏好最佳化 (DPO)。在這樣做的過程中，學習損失的規模會根據軟標籤進行調整，並且具有相同偏好回應的損失將接近於零。這個簡單的修改可以輕鬆應用於任何 DPO 家族，並幫助模型擺脫過度最佳化和目標不匹配的問題。在我們的實驗中，我們使用來自 LLM 的 AI 回饋模擬軟偏好標籤，並證明幾何平均始終改善對齊研究的標準基準的效能。特別是，我們觀察到比二元標籤更理想的回應，並且在中度自信標籤佔多數的資料中獲得顯著的改進。

##### **Benchmarking Sub-Genre Classification For Mainstage Dance Music**
2409.06690v1 by Hongzhi Shu, Xinglin Li, Hongyu Jiang, Minghao Fu, Xinyu Li

Music classification, with a wide range of applications, is one of the most
prominent tasks in music information retrieval. To address the absence of
comprehensive datasets and high-performing methods in the classification of
mainstage dance music, this work introduces a novel benchmark comprising a new
dataset and a baseline. Our dataset extends the number of sub-genres to cover
most recent mainstage live sets by top DJs worldwide in music festivals. A
continuous soft labeling approach is employed to account for tracks that span
multiple sub-genres, preserving the inherent sophistication. For the baseline,
we developed deep learning models that outperform current state-of-the-art
multimodel language models, which struggle to identify house music sub-genres,
emphasizing the need for specialized models trained on fine-grained datasets.
Our benchmark is applicable to serve for application scenarios such as music
recommendation, DJ set curation, and interactive multimedia, where we also
provide video demos. Our code is on
\url{https://anonymous.4open.science/r/Mainstage-EDM-Benchmark/}.

摘要：音樂分類擁有廣泛的應用，是音樂資訊檢索中最突出的任務之一。為了解決主流舞曲分類中缺乏全面資料集和高性能方法的問題，這項工作引入了一個包含新資料集和基準的新基準。我們的資料集擴展了子類型的數量，涵蓋了全球頂尖 DJ 在音樂節中的最新主流現場表演。採用連續軟標籤方法來考量橫跨多個子類型的曲目，保留其固有的複雜性。對於基準，我們開發了深度學習模型，其效能優於目前的最新多模式語言模型，而後者難以識別浩室音樂子類型，強調了針對細粒度資料集訓練的專門模型的必要性。我們的基準適用於音樂推薦、DJ 組合策展和互動多媒體等應用場景，我們也提供影片示範。我們的程式碼位於
\url{https://anonymous.4open.science/r/Mainstage-EDM-Benchmark/}。

##### **E2LLM: Encoder Elongated Large Language Models for Long-Context Understanding and Reasoning**
2409.06679v1 by Zihan Liao, Jun Wang, Hang Yu, Lingxiao Wei, Jianguo Li, Jun Wang, Wei Zhang

In the realm of Large Language Models (LLMs), the ability to process long
contexts is increasingly crucial for tasks such as multi-round dialogues, code
generation, and document summarization. This paper addresses the challenges of
enhancing the long-context performance, reducing computational complexity, and
leveraging pretrained models collectively termed the "impossible triangle." We
introduce E2LLM (Encoder Elongated Large Language Models), a novel approach
that effectively navigates this paradox. The method involves splitting long
contexts into chunks, compressing each into embedding vectors via a pretrained
text encoder, and utilizing an adapter to align these representations with a
decoder-only LLM. Two training objectives, focusing on reconstruction of the
encoder output and long-context instruction fine-tuning, are employed to
facilitate the understanding of soft prompts by the LLM. Experimental results
demonstrate that E2LLM achieves superior performance in long-context scenarios
while balancing efficiency, performance, and compatibility with pretrained
models. Our framework thus represents a significant advancement in the field,
contributing to effective long-text modeling.

摘要：在大語言模型 (LLM) 領域中，處理長語境的能耐對於多輪對話、程式碼產生和文件摘要等任務越來越重要。本文探討了增強長語境效能、降低計算複雜度和運用預訓練模型的挑戰，這些挑戰統稱為「不可能三角」。我們引入了 E2LLM（編碼器延伸大語言模型），這是一種新穎的方法，可以有效地解決這個悖論。此方法包括將長語境分割成區塊，透過預訓練文本編碼器將每個區塊壓縮成嵌入向量，並使用適配器將這些表示與僅解碼器 LLM 對齊。兩個訓練目標，專注於重建編碼器輸出和長語境指令微調，用於促進 LLM 對軟提示的理解。實驗結果表明，E2LLM 在長語境場景中實現了卓越的效能，同時平衡了效率、效能和與預訓練模型的相容性。因此，我們的架構代表了該領域的重大進展，有助於有效的長文本建模。

##### **Liability and Insurance for Catastrophic Losses: the Nuclear Power Precedent and Lessons for AI**
2409.06673v1 by Cristian Trout

As AI systems become more autonomous and capable, experts warn of them
potentially causing catastrophic losses. Drawing on the successful precedent
set by the nuclear power industry, this paper argues that developers of
frontier AI models should be assigned limited, strict, and exclusive third
party liability for harms resulting from Critical AI Occurrences (CAIOs) -
events that cause or easily could have caused catastrophic losses. Mandatory
insurance for CAIO liability is recommended to overcome developers'
judgment-proofness, mitigate winner's curse dynamics, and leverage insurers'
quasi-regulatory abilities. Based on theoretical arguments and observations
from the analogous nuclear power context, insurers are expected to engage in a
mix of causal risk-modeling, monitoring, lobbying for stricter regulation, and
providing loss prevention guidance in the context of insuring against
heavy-tail risks from AI. While not a substitute for regulation, clear
liability assignment and mandatory insurance can help efficiently allocate
resources to risk-modeling and safe design, facilitating future regulatory
efforts.

摘要：隨著 AI 系統變得更加自主且強大，專家警告它們可能會造成災難性的損失。本文借鑑核能產業設定的成功先例，主張前沿 AI 模型的開發者應承擔有限、嚴格且專屬的第三方責任，以彌補關鍵 AI 事件 (CAIO) 所造成的損害，而 CAIO 是造成或可能造成災難性損失的事件。建議強制為 CAIO 責任投保，以克服開發者的抗辯不能性，減輕贏家的詛咒動態，並利用保險人的準監管能力。根據理論論點和類比核能脈絡的觀察，保險人預計將從事因果風險建模、監控、遊說更嚴格的法規，以及在承保 AI 重尾風險的背景下提供損失預防指導。儘管無法取代法規，但明確的責任分配和強制保險有助於有效分配資源以進行風險建模和安全設計，促進未來的法規制定工作。

##### **LLaMA-Omni: Seamless Speech Interaction with Large Language Models**
2409.06666v1 by Qingkai Fang, Shoutao Guo, Yan Zhou, Zhengrui Ma, Shaolei Zhang, Yang Feng

Models like GPT-4o enable real-time interaction with large language models
(LLMs) through speech, significantly enhancing user experience compared to
traditional text-based interaction. However, there is still a lack of
exploration on how to build speech interaction models based on open-source
LLMs. To address this, we propose LLaMA-Omni, a novel model architecture
designed for low-latency and high-quality speech interaction with LLMs.
LLaMA-Omni integrates a pretrained speech encoder, a speech adaptor, an LLM,
and a streaming speech decoder. It eliminates the need for speech
transcription, and can simultaneously generate text and speech responses
directly from speech instructions with extremely low latency. We build our
model based on the latest Llama-3.1-8B-Instruct model. To align the model with
speech interaction scenarios, we construct a dataset named InstructS2S-200K,
which includes 200K speech instructions and corresponding speech responses.
Experimental results show that compared to previous speech-language models,
LLaMA-Omni provides better responses in both content and style, with a response
latency as low as 226ms. Additionally, training LLaMA-Omni takes less than 3
days on just 4 GPUs, paving the way for the efficient development of
speech-language models in the future.

摘要：LLaMA-Omni 等模型能透過語音與大型語言模型 (LLM) 進行即時互動，與傳統的文字互動相比，大幅提升使用者體驗。然而，關於如何根據開放原始碼 LLM 建構語音互動模型，目前仍缺乏探討。為了解決這個問題，我們提出 LLaMA-Omni，一種新穎的模型架構，專為與 LLM 進行低延遲、高品質的語音互動而設計。LLaMA-Omni 整合了預訓練的語音編碼器、語音適配器、LLM 和串流語音解碼器。它消除了語音轉錄的需要，並能直接從語音指令產生文字和語音回應，且延遲極低。我們根據最新的 Llama-3.1-8B-Instruct 模型建立我們的模型。為了讓模型與語音互動情境相符，我們建構了一個名為 InstructS2S-200K 的資料集，其中包含 200K 個語音指令和對應的語音回應。實驗結果顯示，與先前的語音語言模型相比，LLaMA-Omni 在內容和風格上提供了更好的回應，回應延遲低至 226 毫秒。此外，訓練 LLaMA-Omni 只需要不到 3 天的時間，而且僅使用 4 個 GPU，為未來語音語言模型的有效開發鋪路。

##### **Sortformer: Seamless Integration of Speaker Diarization and ASR by Bridging Timestamps and Tokens**
2409.06656v1 by Taejin Park, Ivan Medennikov, Kunal Dhawan, Weiqing Wang, He Huang, Nithin Rao Koluguri, Krishna C. Puvvada, Jagadeesh Balam, Boris Ginsburg

We propose Sortformer, a novel neural model for speaker diarization, trained
with unconventional objectives compared to existing end-to-end diarization
models. The permutation problem in speaker diarization has long been regarded
as a critical challenge. Most prior end-to-end diarization systems employ
permutation invariant loss (PIL), which optimizes for the permutation that
yields the lowest error. In contrast, we introduce Sort Loss, which enables a
diarization model to autonomously resolve permutation, with or without PIL. We
demonstrate that combining Sort Loss and PIL achieves performance competitive
with state-of-the-art end-to-end diarization models trained exclusively with
PIL. Crucially, we present a streamlined multispeaker ASR architecture that
leverages Sortformer as a speaker supervision model, embedding speaker label
estimation within the ASR encoder state using a sinusoidal kernel function.
This approach resolves the speaker permutation problem through sorted
objectives, effectively bridging speaker-label timestamps and speaker tokens.
In our experiments, we show that the proposed multispeaker ASR architecture,
enhanced with speaker supervision, improves performance via adapter techniques.
Code and trained models will be made publicly available via the NVIDIA NeMo
framework

摘要：我們提出 Sortformer，這是一個用於說話者分組的新型神經模型，它與現有的端到端分組模型相比，採用了非常規的目標進行訓練。說話者分組中的排列問題長期以來一直被認為是一個關鍵挑戰。大多數先前的端到端分組系統採用排列不變損失 (PIL)，它針對產生最低錯誤的排列進行優化。相比之下，我們引入了分類損失，它使分組模型能夠自主解決排列，無論是否使用 PIL。我們證明了將分類損失和 PIL 結合起來，可以實現與僅使用 PIL 訓練的最新端到端分組模型相媲美的效能。至關重要的是，我們提出了一個簡化的多說話者 ASR 架構，它利用 Sortformer 作為說話者監督模型，使用正弦核函數在 ASR 編碼器狀態中嵌入說話者標籤估計。這種方法通過分類目標解決了說話者排列問題，有效地橋接了說話者標籤時間戳和說話者標記。在我們的實驗中，我們展示了通過適配器技術增強的建議多說話者 ASR 架構通過適配器技術改善了效能。程式碼和訓練好的模型將通過 NVIDIA NeMo 框架公開。

##### **EyeCLIP: A visual-language foundation model for multi-modal ophthalmic image analysis**
2409.06644v1 by Danli Shi, Weiyi Zhang, Jiancheng Yang, Siyu Huang, Xiaolan Chen, Mayinuer Yusufu, Kai Jin, Shan Lin, Shunming Liu, Qing Zhang, Mingguang He

Early detection of eye diseases like glaucoma, macular degeneration, and
diabetic retinopathy is crucial for preventing vision loss. While artificial
intelligence (AI) foundation models hold significant promise for addressing
these challenges, existing ophthalmic foundation models primarily focus on a
single modality, whereas diagnosing eye diseases requires multiple modalities.
A critical yet often overlooked aspect is harnessing the multi-view information
across various modalities for the same patient. Additionally, due to the
long-tail nature of ophthalmic diseases, standard fully supervised or
unsupervised learning approaches often struggle. Therefore, it is essential to
integrate clinical text to capture a broader spectrum of diseases. We propose
EyeCLIP, a visual-language foundation model developed using over 2.77 million
multi-modal ophthalmology images with partial text data. To fully leverage the
large multi-modal unlabeled and labeled data, we introduced a pretraining
strategy that combines self-supervised reconstructions, multi-modal image
contrastive learning, and image-text contrastive learning to learn a shared
representation of multiple modalities. Through evaluation using 14 benchmark
datasets, EyeCLIP can be transferred to a wide range of downstream tasks
involving ocular and systemic diseases, achieving state-of-the-art performance
in disease classification, visual question answering, and cross-modal
retrieval. EyeCLIP represents a significant advancement over previous methods,
especially showcasing few-shot, even zero-shot capabilities in real-world
long-tail scenarios.

摘要：早期偵測青光眼、黃斑部病變和糖尿病視網膜病變等眼疾對於預防視力喪失至關重要。儘管人工智慧 (AI) 基礎模型對於解決這些挑戰具有重大意義，但現有的眼科基礎模型主要集中在單一模式上，而診斷眼疾需要多種模式。一個至關重要但經常被忽略的方面是利用同一患者在各種模式中收集多視角資訊。此外，由於眼科疾病的長尾性質，標準的完全監督或非監督學習方法常常難以應付。因此，整合臨床文字以涵蓋更廣泛的疾病非常重要。我們提出 EyeCLIP，這是一個視覺語言基礎模型，使用超過 277 萬張具有部分文字資料的多模式眼科影像開發。為了充分利用大量的多模式未標記和標記資料，我們引入了一種預訓練策略，結合自我監督重建、多模式影像對比學習和影像文字對比學習，以學習多種模式的共享表示。透過使用 14 個基準資料集進行評估，EyeCLIP 可以轉移到廣泛的下游任務中，涉及眼部和全身疾病，在疾病分類、視覺問題解答和跨模式檢索中達到最先進的效能。EyeCLIP 代表了對先前方法的重大進步，特別是在現實世界長尾場景中展示了少量甚至零次學習能力。

##### **TeXBLEU: Automatic Metric for Evaluate LaTeX Format**
2409.06639v1 by Kyudan Jung, Nam-Joon Kim, Hyongon Ryu, Sieun Hyeon, Seung-jun Lee, Hyeok-jae Lee

LaTeX is highly suited to creating documents with special formatting,
particularly in the fields of science, technology, mathematics, and computer
science. Despite the increasing use of mathematical expressions in LaTeX format
with language models, there are no evaluation metrics for evaluating them. In
this study, we propose TeXBLEU, an evaluation metric tailored for mathematical
expressions in LaTeX format, based on the n-gram-based BLEU metric that is
widely used for translation tasks. The proposed TeXBLEU includes a predefined
tokenizer trained on the arXiv paper dataset and a finetuned embedding model.
It also considers the positional embedding of tokens. Simultaneously, TeXBLEU
compares tokens based on n-grams and computes the score using exponentiation of
a logarithmic sum, similar to the original BLEU. Experimental results show that
TeXBLEU outperformed traditional evaluation metrics such as BLEU, Rouge, CER,
and WER when compared to human evaluation data on the test dataset of the
MathBridge dataset, which contains 1,000 data points. The average correlation
coefficient with human evaluation was 0.71, which is an improvement of 87%
compared with BLEU, which had the highest correlation with human evaluation
data among the existing metrics. The code is available at
https://github.com/KyuDan1/TeXBLEU.

摘要：LaTeX 非常適合用於建立具有特殊格式的文件，
尤其是在科學、技術、數學和電腦科學領域。儘管 LaTeX 格式的數學表達式在語言模型中使用越來越多，
但沒有評估指標可以評估它們。在這項研究中，我們提出 TeXBLEU，這是一個針對 LaTeX 格式的數學表達式而設計的評估指標，它基於廣泛用於翻譯任務的 n-gram 為基礎的 BLEU 指標。所提出的 TeXBLEU 包含一個預先定義的標記化器，該標記化器在 arXiv 論文資料集上進行訓練，並包含一個微調的嵌入模型。
它還考慮了標記的位置嵌入。同時，TeXBLEU 根據 n-gram 比較標記，並使用對數和的指數計算分數，類似於原始 BLEU。實驗結果顯示，與 MathBridge 資料集的測試資料集上的人類評估資料相比，TeXBLEU 優於傳統評估指標，例如 BLEU、Rouge、CER 和 WER。MathBridge 資料集包含 1,000 個資料點。與人類評估的平均相關係數為 0.71，與 BLEU 相比，改進了 87%，而 BLEU 在現有指標中與人類評估資料相關性最高。程式碼可在 https://github.com/KyuDan1/TeXBLEU 取得。

##### **MoWE-Audio: Multitask AudioLLMs with Mixture of Weak Encoders**
2409.06635v1 by Wenyu Zhang, Shuo Sun, Bin Wang, Xunlong Zou, Zhuohan Liu, Yingxu He, Geyu Lin, Nancy F. Chen, Ai Ti Aw

The rapid advancements in large language models (LLMs) have significantly
enhanced natural language processing capabilities, facilitating the development
of AudioLLMs that process and understand speech and audio inputs alongside
text. Existing AudioLLMs typically combine a pre-trained audio encoder with a
pre-trained LLM, which are subsequently finetuned on specific audio tasks.
However, the pre-trained audio encoder has constrained capacity to capture
features for new tasks and datasets. To address this, we propose to incorporate
mixtures of `weak' encoders (MoWE) into the AudioLLM framework. MoWE
supplements a base encoder with a pool of relatively light weight encoders,
selectively activated based on the audio input to enhance feature extraction
without significantly increasing model size. Our empirical results demonstrate
that MoWE effectively improves multi-task performance, broadening the
applicability of AudioLLMs to more diverse audio tasks.

摘要：大型語言模型 (LLM) 的快速進展顯著提升了自然語言處理能力，促进了 AudioLLM 的發展，AudioLLM 能處理和理解語音和音訊輸入以及文字。現有的 AudioLLM 通常將預先訓練的音訊編碼器與預先訓練的 LLM 結合，然後針對特定音訊任務進行微調。然而，預先訓練的音訊編碼器在擷取新任務和資料集特徵的能力受到限制。為了解決這個問題，我們提議將「弱」編碼器混合 (MoWE) 納入 AudioLLM 架構。MoWE 使用一群相對輕量的編碼器補充基本編碼器，根據音訊輸入有選擇地啟用，以增強特徵擷取，而不會顯著增加模型大小。我們的實證結果證明，MoWE 有效地改進了多任務效能，擴大了 AudioLLM 在更多元音訊任務中的適用性。

##### **A Practice of Post-Training on Llama-3 70B with Optimal Selection of Additional Language Mixture Ratio**
2409.06624v1 by Ningyuan Xi, Yetao Wu, Kun Fan, Teng Chen, Qingqing Gu, Peng Yu, Jinxian Qu, Chenxi Liu, Zhonglin Jiang, Yong Chen, Luo Ji

Large Language Models (LLM) often needs to be Continual Pre-Trained (CPT) to
obtain the unfamiliar language skill or adapt into new domains. The huge
training cost of CPT often asks for cautious choice of key hyper-parameters
such as the mixture ratio of extra language or domain corpus. However, there is
no systematic study which bridge the gap between the optimal mixture ratio and
the actual model performance, and the gap between experimental scaling law and
the actual deployment in the full model size. In this paper, we perform CPT on
Llama-3 8B and 70B to enhance its Chinese ability. We study the optimal
correlation between the Additional Language Mixture Ratio (ALMR) and the
Learning Rate (LR) on the 8B size which directly indicate the optimal
experimental set up. By thorough choice of hyper-parameter, and subsequent
fine-tuning, the model capability is improved not only on the Chinese-related
benchmark, but also some specific domains including math, coding and emotional
intelligence. We deploy the final 70B version of LLM on an real-life chat
system which obtain satisfying performance.

摘要：大型语言模型 (LLM) 经常需要持续预训练 (CPT) 以获得不熟悉的语言技能或适应新领域。CPT 的巨额训练成本通常需要谨慎选择关键超参数，例如额外语言或领域语料库的混合比例。然而，没有系统性的研究来弥合理想混合比例与实际模型性能之间的差距，以及实验缩放定律与实际部署在完整模型规模之间的差距。在本文中，我们在 Llama-3 8B 和 70B 上执行 CPT 以增强其中文能力。我们研究了 8B 大小上的附加语言混合比例 (ALMR) 和学习率 (LR) 之间的最优相关性，该相关性直接指示最优实验设置。通过彻底选择超参数和随后的微调，模型能力不仅在与中文相关的基准上得到提升，而且在包括数学、编码和情商在内的一些特定领域也得到提升。我们在一个现实生活聊天系统上部署了 LLM 的最终 70B 版本，该系统获得了令人满意的性能。

##### **Exploring Italian sentence embeddings properties through multi-tasking**
2409.06622v1 by Vivi Nastase, Giuseppe Samo, Chunyang Jiang, Paola Merlo

We investigate to what degree existing LLMs encode abstract linguistic
information in Italian in a multi-task setting. We exploit curated synthetic
data on a large scale -- several Blackbird Language Matrices (BLMs) problems in
Italian -- and use them to study how sentence representations built using
pre-trained language models encode specific syntactic and semantic information.
We use a two-level architecture to model separately a compression of the
sentence embeddings into a representation that contains relevant information
for a task, and a BLM task. We then investigate whether we can obtain
compressed sentence representations that encode syntactic and semantic
information relevant to several BLM tasks. While we expected that the sentence
structure -- in terms of sequence of phrases/chunks -- and chunk properties
could be shared across tasks, performance and error analysis show that the
clues for the different tasks are encoded in different manners in the sentence
embeddings, suggesting that abstract linguistic notions such as constituents or
thematic roles does not seem to be present in the pretrained sentence
embeddings.

摘要：我們調查現有 LLM 在多任務設定中編碼義大利文抽象語言資訊的程度。我們利用大量策展的合成資料（義大利文的幾個 Blackbird Language Matrices (BLM) 問題），並用它們來研究使用預先訓練的語言模型建構的句子表徵如何編碼特定的句法和語義資訊。我們使用二層架構來分別模擬句子嵌入壓縮成包含任務相關資訊的表徵，以及 BLM 任務。我們接著調查我們是否能取得編碼句法和語義資訊的壓縮句子表徵，這些資訊與幾個 BLM 任務相關。雖然我們預期句子結構（以詞組/區塊序列表示）和區塊屬性可以在任務間共用，但效能和錯誤分析顯示，不同任務的線索以不同方式編碼在句子嵌入中，這表示抽象語言概念（例如成分或主題角色）似乎不存在於預先訓練的句子嵌入中。

##### **Label-free Monitoring of Self-Supervised Learning Progress**
2409.06612v1 by Isaac Xu, Scott Lowe, Thomas Trappenberg

Self-supervised learning (SSL) is an effective method for exploiting
unlabelled data to learn a high-level embedding space that can be used for
various downstream tasks. However, existing methods to monitor the quality of
the encoder -- either during training for one model or to compare several
trained models -- still rely on access to annotated data. When SSL
methodologies are applied to new data domains, a sufficiently large labelled
dataset may not always be available. In this study, we propose several
evaluation metrics which can be applied on the embeddings of unlabelled data
and investigate their viability by comparing them to linear probe accuracy (a
common metric which utilizes an annotated dataset). In particular, we apply
$k$-means clustering and measure the clustering quality with the silhouette
score and clustering agreement. We also measure the entropy of the embedding
distribution. We find that while the clusters did correspond better to the
ground truth annotations as training of the network progressed, label-free
clustering metrics correlated with the linear probe accuracy only when training
with SSL methods SimCLR and MoCo-v2, but not with SimSiam. Additionally,
although entropy did not always have strong correlations with LP accuracy, this
appears to be due to instability arising from early training, with the metric
stabilizing and becoming more reliable at later stages of learning.
Furthermore, while entropy generally decreases as learning progresses, this
trend reverses for SimSiam. More research is required to establish the cause
for this unexpected behaviour. Lastly, we find that while clustering based
approaches are likely only viable for same-architecture comparisons, entropy
may be architecture-independent.

摘要：<paragraph>自监督学习 (SSL) 是一种有效的方法，可利用未标记的数据学习可用于各种下游任务的高级嵌入空间。然而，用于监控编码器质量的现有方法——无论是针对一个模型的训练期间还是用于比较多个训练模型——仍然依赖于对注释数据的访问。当 SSL 方法应用于新的数据域时，可能并不总是可以使用足够大的标记数据集。在这项研究中，我们提出了几种评估指标，可应用于未标记数据的嵌入，并通过将它们与线性探测准确度（一种利用注释数据集的常见指标）进行比较来调查其可行性。特别是，我们应用 k 均值聚类，并使用轮廓得分和聚类一致性来衡量聚类质量。我们还测量嵌入分布的熵。我们发现，虽然随着网络训练的进行，聚类确实更好地对应于真实注释，但无标签聚类指标仅在使用 SSL 方法 SimCLR 和 MoCo-v2 训练时与线性探测准确度相关，而与 SimSiam 无关。此外，尽管熵并不总是与 LP 准确度有很强的相关性，但这似乎是由于早期训练引起的不稳定性，随着学习的后期，该指标会稳定并变得更加可靠。此外，虽然熵通常随着学习的进行而降低，但对于 SimSiam，这种趋势会逆转。需要更多的研究来确定这种意外行为的原因。最后，我们发现，虽然基于聚类的方法可能只适用于相同架构的比较，但熵可能是与架构无关的。</paragraph>

##### **Alleviating Hallucinations in Large Language Models with Scepticism Modeling**
2409.06601v1 by Yetao Wu, Yihong Wang, Teng Chen, Chenxi Liu, Ningyuan Xi, Qingqing Gu, Hongyang Lei, Zhonglin Jiang, Yong Chen, Luo Ji

Hallucinations is a major challenge for large language models (LLMs),
prevents adoption in diverse fields. Uncertainty estimation could be used for
alleviating the damages of hallucinations. The skeptical emotion of human could
be useful for enhancing the ability of self estimation. Inspirited by this
observation, we proposed a new approach called Skepticism Modeling (SM). This
approach is formalized by combining the information of token and logits for
self estimation. We construct the doubt emotion aware data, perform continual
pre-training, and then fine-tune the LLMs, improve their ability of self
estimation. Experimental results demonstrate this new approach effectively
enhances a model's ability to estimate their uncertainty, and validate its
generalization ability of other tasks by out-of-domain experiments.

摘要：幻覺是大型語言模型 (LLM) 的一項重大挑戰，
防止在不同領域中採用。不確定性估計可用於
減輕幻覺的損害。人類的懷疑情緒可能
有助於增強自我估計的能力。受到這個啟發
觀察，我們提出了一種稱為懷疑建模 (SM) 的新方法。這
種方法透過結合代幣和對數的信息進行自我估計而形式化。我們建構懷疑情緒感知數據，執行持續
預訓練，然後微調 LLM，提升它們自我估計的能力。實驗結果證明這種新方法有效
增強模型估計其不確定性的能力，並透過領域外實驗驗證其對其他任務的泛化能力。

##### **GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering**
2409.06595v1 by Sacha Muller, António Loison, Bilel Omrani, Gautier Viaud

Retrieval-Augmented Generation (RAG) has emerged as a common paradigm to use
Large Language Models (LLMs) alongside private and up-to-date knowledge bases.
In this work, we address the challenges of using LLM-as-a-Judge when evaluating
grounded answers generated by RAG systems. To assess the calibration and
discrimination capabilities of judge models, we identify 7 generator failure
modes and introduce GroUSE (Grounded QA Unitary Scoring of Evaluators), a
meta-evaluation benchmark of 144 unit tests. This benchmark reveals that
existing automated RAG evaluation frameworks often overlook important failure
modes, even when using GPT-4 as a judge.
  To improve on the current design of automated RAG evaluation frameworks, we
propose a novel pipeline and find that while closed models perform well on
GroUSE, state-of-the-art open-source judges do not generalize to our proposed
criteria, despite strong correlation with GPT-4's judgement. Our findings
suggest that correlation with GPT-4 is an incomplete proxy for the practical
performance of judge models and should be supplemented with evaluations on unit
tests for precise failure mode detection.
  We further show that finetuning Llama-3 on GPT-4's reasoning traces
significantly boosts its evaluation capabilities, improving upon both
correlation with GPT-4's evaluations and calibration on reference situations.

摘要：檢索增強生成 (RAG) 已成為一種常見範例，可將大型語言模型 (LLM) 與私人且最新的知識庫一起使用。在這項工作中，我們在評估 RAG 系統生成的基礎答案時，探討了使用 LLM 作為評審時所面臨的挑戰。為了評估評審模型的校準和區分能力，我們找出 7 種生成器故障模式，並引入了 GroUSE（評估人員的基礎問答單元評分），這是一個包含 144 個單元測試的元評估基準。此基準揭示了現有的自動化 RAG 評估架構通常會忽略重要的故障模式，即使使用 GPT-4 作為評審也是如此。為了改善自動化 RAG 評估架構的當前設計，我們提出了一個新的管道，並發現封閉模型在 GroUSE 上表現良好，但最先進的開源評審並未概括到我們提出的標準，儘管與 GPT-4 的判斷有很強的相關性。我們的研究結果表明，與 GPT-4 的相關性是評審模型實際效能的不完整代理，應補充單元測試的評估，以進行精確的故障模式偵測。我們進一步表明，在 GPT-4 的推理軌跡上微調 Llama-3 可顯著提升其評估能力，同時改善與 GPT-4 評估的相關性，並校準參考情況。

##### **Developing the Temporal Graph Convolutional Neural Network Model to Predict Hip Replacement using Electronic Health Records**
2409.06585v1 by Zoe Hancox, Sarah R. Kingsbury, Andrew Clegg, Philip G. Conaghan, Samuel D. Relton

Background: Hip replacement procedures improve patient lives by relieving
pain and restoring mobility. Predicting hip replacement in advance could reduce
pain by enabling timely interventions, prioritising individuals for surgery or
rehabilitation, and utilising physiotherapy to potentially delay the need for
joint replacement. This study predicts hip replacement a year in advance to
enhance quality of life and health service efficiency. Methods: Adapting
previous work using Temporal Graph Convolutional Neural Network (TG-CNN)
models, we construct temporal graphs from primary care medical event codes,
sourced from ResearchOne EHRs of 40-75-year-old patients, to predict hip
replacement risk. We match hip replacement cases to controls by age, sex, and
Index of Multiple Deprivation. The model, trained on 9,187 cases and 9,187
controls, predicts hip replacement one year in advance. We validate the model
on two unseen datasets, recalibrating for class imbalance. Additionally, we
conduct an ablation study and compare against four baseline models. Results:
Our best model predicts hip replacement risk one year in advance with an AUROC
of 0.724 (95% CI: 0.715-0.733) and an AUPRC of 0.185 (95% CI: 0.160-0.209),
achieving a calibration slope of 1.107 (95% CI: 1.074-1.139) after
recalibration. Conclusions: The TG-CNN model effectively predicts hip
replacement risk by identifying patterns in patient trajectories, potentially
improving understanding and management of hip-related conditions.

摘要：背景：髖關節置換手術可減輕疼痛並恢復行動能力，進而改善患者生活。預測髖關節置換手術有助於及時介入、優先安排個人進行手術或復健，並利用物理治療來延緩關節置換手術的必要性，進而減少疼痛。本研究預測一年後的髖關節置換手術，以提升生活品質和醫療服務效率。方法：採用時間圖形卷積神經網路 (TG-CNN) 模型改編先前的研究，我們從 ResearchOne EHR 40-75 歲患者的主要照護醫療事件代碼建構時間圖形，以預測髖關節置換手術風險。我們根據年齡、性別和多重剝奪指數，將髖關節置換手術病例與對照組進行配對。該模型針對 9,187 個病例和 9,187 個對照組進行訓練，預測一年後的髖關節置換手術。我們在兩個未見數據集驗證模型，並重新校準以解決類別不平衡問題。此外，我們進行消融研究，並與四個基準模型進行比較。結果：我們最佳的模型預測一年後的髖關節置換手術風險，AUROC 為 0.724 (95% CI：0.715-0.733)，AUPRC 為 0.185 (95% CI：0.160-0.209)，重新校準後校準斜率為 1.107 (95% CI：1.074-1.139)。結論：TG-CNN 模型可有效預測髖關節置換手術風險，方法是找出患者軌跡中的模式，進而潛在改善對髖關節相關疾病的了解和管理。

##### **Quantifying and Enabling the Interpretability of CLIP-like Models**
2409.06579v1 by Avinash Madasu, Yossi Gandelsman, Vasudev Lal, Phillip Howard

CLIP is one of the most popular foundational models and is heavily used for
many vision-language tasks. However, little is known about the inner workings
of CLIP. To bridge this gap we propose a study to quantify the interpretability
in CLIP like models. We conduct this study on six different CLIP models from
OpenAI and OpenCLIP which vary by size, type of pre-training data and patch
size. Our approach begins with using the TEXTSPAN algorithm and in-context
learning to break down individual attention heads into specific properties. We
then evaluate how easily these heads can be interpreted using new metrics which
measure property consistency within heads and property disentanglement across
heads. Our findings reveal that larger CLIP models are generally more
interpretable than their smaller counterparts. To further assist users in
understanding the inner workings of CLIP models, we introduce CLIP-InterpreT, a
tool designed for interpretability analysis. CLIP-InterpreT offers five types
of analyses: property-based nearest neighbor search, per-head topic
segmentation, contrastive segmentation, per-head nearest neighbors of an image,
and per-head nearest neighbors of text.

摘要：CLIP 是最流行的基础模型之一，被广泛用于许多视觉语言任务。然而，关于 CLIP 的内部工作原理知之甚少。为了弥合这一差距，我们提出了一项研究来量化 CLIP 等模型的可解释性。我们对 OpenAI 和 OpenCLIP 的六个不同的 CLIP 模型进行了这项研究，这些模型的大小、预训练数据类型和补丁大小各不相同。我们的方法首先使用 TEXTSPAN 算法和上下文学习将各个注意力头分解为特定属性。然后我们评估使用新指标解释这些头的容易程度，这些指标测量头内属性一致性和头间属性解耦。我们的研究结果表明，较大的 CLIP 模型通常比较小的模型更具可解释性。为了进一步帮助用户了解 CLIP 模型的内部工作原理，我们引入了 CLIP-InterpreT，这是一个专为可解释性分析而设计的工具。CLIP-InterpreT 提供五种类型的分析：基于属性的最近邻搜索、每个头的主题分割、对比分割、图像的每个头的最近邻和文本的每个头的最近邻。

##### **Exploring syntactic information in sentence embeddings through multilingual subject-verb agreement**
2409.06567v1 by Vivi Nastase, Chunyang Jiang, Giuseppe Samo, Paola Merlo

In this paper, our goal is to investigate to what degree multilingual
pretrained language models capture cross-linguistically valid abstract
linguistic representations. We take the approach of developing curated
synthetic data on a large scale, with specific properties, and using them to
study sentence representations built using pretrained language models. We use a
new multiple-choice task and datasets, Blackbird Language Matrices (BLMs), to
focus on a specific grammatical structural phenomenon -- subject-verb agreement
across a variety of sentence structures -- in several languages. Finding a
solution to this task requires a system detecting complex linguistic patterns
and paradigms in text representations. Using a two-level architecture that
solves the problem in two steps -- detect syntactic objects and their
properties in individual sentences, and find patterns across an input sequence
of sentences -- we show that despite having been trained on multilingual texts
in a consistent manner, multilingual pretrained language models have
language-specific differences, and syntactic structure is not shared, even
across closely related languages.

摘要：在本文中，我们的目标是研究多语言预训练语言模型在多大程度上捕捉到跨语言有效的抽象语言表征。我们采取的方法是在大规模上开发经过整理的合成数据，具有特定属性，并使用它们来研究使用预训练语言模型构建的句子表征。我们使用一项新的多项选择任务和数据集，即黑鸟语言矩阵 (BLM)，以专注于一种特定的语法结构现象——跨多种句子结构的主谓一致——在多种语言中。找到解决此任务的方法需要一个系统来检测文本表征中的复杂语言模式和范例。使用一个两级架构，分两步解决问题——检测单个句子中的句法对象及其属性，并在输入句子序列中查找模式——我们表明，尽管以一致的方式在多语言文本上进行训练，多语言预训练语言模型具有语言特异性差异，即使在密切相关的语言中，句法结构也没有共享。

##### **Indirect Dynamic Negotiation in the Nash Demand Game**
2409.06566v1 by Tatiana V. Guy, Jitka Homolová, Aleksej Gaj

The paper addresses a problem of sequential bilateral bargaining with
incomplete information. We proposed a decision model that helps agents to
successfully bargain by performing indirect negotiation and learning the
opponent's model. Methodologically the paper casts heuristically-motivated
bargaining of a self-interested independent player into a framework of Bayesian
learning and Markov decision processes. The special form of the reward
implicitly motivates the players to negotiate indirectly, via closed-loop
interaction. We illustrate the approach by applying our model to the Nash
demand game, which is an abstract model of bargaining. The results indicate
that the established negotiation: i) leads to coordinating players' actions;
ii) results in maximising success rate of the game and iii) brings more
individual profit to the players.

摘要：本文讨论了在信息不完全的情况下进行顺序双边谈判的问题。我们提出了一种决策模型，通过执行间接谈判和学习对手的模型来帮助代理人成功地进行谈判。从方法论上讲，该论文将自私的独立参与者的启发式激励讨价还价纳入贝叶斯学习和马尔可夫决策过程的框架中。奖励的特殊形式隐含地激励参与者通过闭环交互间接谈判。我们通过将我们的模型应用于纳什需求博弈（一种讨价还价的抽象模型）来说明这种方法。结果表明，既定的谈判：i）导致协调参与者的行动；ii）导致最大化博弈的成功率，并且 iii）为参与者带来更多个人利益。

##### **From LIMA to DeepLIMA: following a new path of interoperability**
2409.06550v1 by Victor Bocharov, Romaric Besançon, Gaël de Chalendar, Olivier Ferret, Nasredine Semmar

In this article, we describe the architecture of the LIMA (Libre Multilingual
Analyzer) framework and its recent evolution with the addition of new text
analysis modules based on deep neural networks. We extended the functionality
of LIMA in terms of the number of supported languages while preserving existing
configurable architecture and the availability of previously developed
rule-based and statistical analysis components. Models were trained for more
than 60 languages on the Universal Dependencies 2.5 corpora, WikiNer corpora,
and CoNLL-03 dataset. Universal Dependencies allowed us to increase the number
of supported languages and to generate models that could be integrated into
other platforms. This integration of ubiquitous Deep Learning Natural Language
Processing models and the use of standard annotated collections using Universal
Dependencies can be viewed as a new path of interoperability, through the
normalization of models and data, that are complementary to a more standard
technical interoperability, implemented in LIMA through services available in
Docker containers on Docker Hub.

摘要：在本文中，我們描述了 LIMA（Libre Multilingual Analyzer）架構及其最近加入基於深度神經網路的新文字分析模組的演進。我們在保留現有可組態架構和先前開發的基於規則和統計分析元件可用性的同時，擴充了 LIMA 在支援語言數量方面的功能。針對 Universal Dependencies 2.5 語料庫、WikiNer 語料庫和 CoNLL-03 資料集為超過 60 種語言訓練模型。Universal Dependencies 讓我們得以增加支援語言的數量，並產生可整合到其他平台的模型。普遍的深度學習自然語言處理模型的整合，以及使用 Universal Dependencies 的標準註解集合，可視為一種透過模型和資料的標準化而產生的新的互操作性途徑，這對於 LIMA 中透過 Docker Hub 上的 Docker 容器中可用的服務所實作的更標準化的技術互操作性而言，具有互補性。

##### **Mapping News Narratives Using LLMs and Narrative-Structured Text Embeddings**
2409.06540v1 by Jan Elfes

Given the profound impact of narratives across various societal levels, from
personal identities to international politics, it is crucial to understand
their distribution and development over time. This is particularly important in
online spaces. On the Web, narratives can spread rapidly and intensify societal
divides and conflicts. While many qualitative approaches exist, quantifying
narratives remains a significant challenge. Computational narrative analysis
lacks frameworks that are both comprehensive and generalizable. To address this
gap, we introduce a numerical narrative representation grounded in
structuralist linguistic theory. Chiefly, Greimas' Actantial Model represents a
narrative through a constellation of six functional character roles. These
so-called actants are genre-agnostic, making the model highly generalizable. We
extract the actants using an open-source LLM and integrate them into a
Narrative-Structured Text Embedding that captures both the semantics and
narrative structure of a text. We demonstrate the analytical insights of the
method on the example of 5000 full-text news articles from Al Jazeera and The
Washington Post on the Israel-Palestine conflict. Our method successfully
distinguishes articles that cover the same topics but differ in narrative
structure.

摘要：由於敘事在各個社會層面，從個人身分到國際政治，都有深遠的影響，因此了解敘事的分布和發展過程至關重要。這在網路空間中尤其重要。在網路上，敘事可以迅速傳播並加劇社會分歧和衝突。儘管有許多定性方法，但量化敘事仍然是一項重大的挑戰。計算敘事分析缺乏既全面又可概括的架構。為了解決這個差距，我們引入了一個基於結構主義語言理論的數值敘事表徵。最重要的是，格雷馬斯的行動者模型通過一組六個功能角色來表示敘事。這些所謂的行動者與類型無關，使得該模型具有高度的概括性。我們使用開源 LLM 提取行動者，並將它們整合到一個敘事結構化文字嵌入中，該嵌入同時捕捉文本的語義和敘事結構。我們在半島電視台和華盛頓郵報上關於巴以衝突的 5000 篇全文新聞文章的範例中展示了該方法的分析見解。我們的模型成功區分了涵蓋相同主題但敘事結構不同的文章。

##### **Questioning Internal Knowledge Structure of Large Language Models Through the Lens of the Olympic Games**
2409.06518v1 by Juhwan Choi, YoungBin Kim

Large language models (LLMs) have become a dominant approach in natural
language processing, yet their internal knowledge structures remain largely
unexplored. In this paper, we analyze the internal knowledge structures of LLMs
using historical medal tallies from the Olympic Games. We task the models with
providing the medal counts for each team and identifying which teams achieved
specific rankings. Our results reveal that while state-of-the-art LLMs perform
remarkably well in reporting medal counts for individual teams, they struggle
significantly with questions about specific rankings. This suggests that the
internal knowledge structures of LLMs are fundamentally different from those of
humans, who can easily infer rankings from known medal counts. To support
further research, we publicly release our code, dataset, and model outputs.

摘要：大型語言模型 (LLM) 已成為自然語言處理領域的主流方法，但它們的內部知識結構在很大程度上仍未被探索。在本文中，我們使用奧運會的歷史獎牌數分析了 LLM 的內部知識結構。我們要求模型提供每個團隊的獎牌數，並找出哪些團隊達到了特定排名。我們的結果表明，雖然最先進的 LLM 在報告個別團隊的獎牌數方面表現出色，但它們在關於特定排名的問題上卻遇到了很大的困難。這表明 LLM 的內部知識結構與人類的內部知識結構有根本的不同，人類可以輕鬆地從已知的獎牌數中推斷出排名。為了支持進一步的研究，我們公開發布了我們的代碼、數據集和模型輸出。

##### **Sine, Transient, Noise Neural Modeling of Piano Notes**
2409.06513v1 by Riccardo Simionato, Stefano Fasciani

This paper introduces a novel method for emulating piano sounds. We propose
to exploit the sine, transient, and noise decomposition to design a
differentiable spectral modeling synthesizer replicating piano notes. Three
sub-modules learn these components from piano recordings and generate the
corresponding harmonic, transient, and noise signals. Splitting the emulation
into three independently trainable models reduces the modeling tasks'
complexity. The quasi-harmonic content is produced using a differentiable
sinusoidal model guided by physics-derived formulas, whose parameters are
automatically estimated from audio recordings. The noise sub-module uses a
learnable time-varying filter, and the transients are generated using a deep
convolutional network. From singular notes, we emulate the coupling between
different keys in trichords with a convolutional-based network. Results show
the model matches the partial distribution of the target while predicting the
energy in the higher part of the spectrum presents more challenges. The energy
distribution in the spectra of the transient and noise components is accurate
overall. While the model is more computationally and memory efficient,
perceptual tests reveal limitations in accurately modeling the attack phase of
notes. Despite this, it generally achieves perceptual accuracy in emulating
single notes and trichords.

摘要：本文介紹一種模擬鋼琴音效的新方法。我們建議利用正弦波、暫態和雜訊分解來設計一個可微分頻譜建模合成器，以複製鋼琴音符。三個子模組從鋼琴錄音中學習這些組成部分，並產生相應的諧波、暫態和雜訊訊號。將模擬拆分為三個獨立可訓練的模型，降低了建模任務的複雜性。準諧波內容是使用由物理公式引導的可微分正弦模型產生的，其參數會從音訊錄音中自動估計。雜訊子模組使用可學習的時間變異濾波器，而暫態是使用深度卷積網路產生的。從單一音符中，我們模擬了三和弦中不同鍵之間的耦合，使用基於卷積的網路。結果顯示，該模型匹配目標的部分分佈，同時預測光譜高部分的能量提出了更多挑戰。暫態和雜訊組成部分光譜中的能量分佈整體上是準確的。雖然該模型在運算和記憶體方面更有效率，但感知測試顯示在準確建模音符的攻擊階段方面有其限制。儘管如此，它通常在模擬單音符和三和弦時達到感知準確度。

##### **Aligning Machine and Human Visual Representations across Abstraction Levels**
2409.06509v1 by Lukas Muttenthaler, Klaus Greff, Frieda Born, Bernhard Spitzer, Simon Kornblith, Michael C. Mozer, Klaus-Robert Müller, Thomas Unterthiner, Andrew K. Lampinen

Deep neural networks have achieved success across a wide range of
applications, including as models of human behavior in vision tasks. However,
neural network training and human learning differ in fundamental ways, and
neural networks often fail to generalize as robustly as humans do, raising
questions regarding the similarity of their underlying representations. What is
missing for modern learning systems to exhibit more human-like behavior? We
highlight a key misalignment between vision models and humans: whereas human
conceptual knowledge is hierarchically organized from fine- to coarse-scale
distinctions, model representations do not accurately capture all these levels
of abstraction. To address this misalignment, we first train a teacher model to
imitate human judgments, then transfer human-like structure from its
representations into pretrained state-of-the-art vision foundation models.
These human-aligned models more accurately approximate human behavior and
uncertainty across a wide range of similarity tasks, including a new dataset of
human judgments spanning multiple levels of semantic abstractions. They also
perform better on a diverse set of machine learning tasks, increasing
generalization and out-of-distribution robustness. Thus, infusing neural
networks with additional human knowledge yields a best-of-both-worlds
representation that is both more consistent with human cognition and more
practically useful, thus paving the way toward more robust, interpretable, and
human-like artificial intelligence systems.

摘要：深度神经网络在广泛的應用中取得成功，包括作為視覺任務中人類行為的模型。然而，神經網路訓練和人類學習在基本方式上有所不同，而且神經網路通常無法像人類那樣穩健地概括，這引發了關於它們底層表徵相似性的問題。現代學習系統缺少什麼才能表現出更像人類的行為？我們強調了視覺模型和人類之間的一個關鍵錯位：人類概念知識從精細到粗略的區別分層組織，而模型表徵並未準確捕捉所有這些抽象層級。為了解決這種錯位，我們首先訓練一個教師模型來模仿人類判斷，然後將其表徵中類人的結構轉移到預先訓練的最新視覺基礎模型中。這些與人類一致的模型更準確地逼近人類行為和不確定性，涵蓋廣泛的相似性任務，包括一個跨越多個語義抽象層級的人類判斷新資料集。它們在各種機器學習任務上的表現也更好，提高了泛化性和分佈外穩健性。因此，為神經網路注入額外的人類知識產生了一個兩全其美的表徵，它既更符合人類認知，又更實用，從而為更穩健、可解釋和類人的人工智慧系統鋪平了道路。

##### **Superior Computer Chess with Model Predictive Control, Reinforcement Learning, and Rollout**
2409.06477v1 by Atharva Gundawar, Yuchao Li, Dimitri Bertsekas

In this paper we apply model predictive control (MPC), rollout, and
reinforcement learning (RL) methodologies to computer chess. We introduce a new
architecture for move selection, within which available chess engines are used
as components. One engine is used to provide position evaluations in an
approximation in value space MPC/RL scheme, while a second engine is used as
nominal opponent, to emulate or approximate the moves of the true opponent
player.
  We show that our architecture improves substantially the performance of the
position evaluation engine. In other words our architecture provides an
additional layer of intelligence, on top of the intelligence of the engines on
which it is based. This is true for any engine, regardless of its strength: top
engines such as Stockfish and Komodo Dragon (of varying strengths), as well as
weaker engines.
  Structurally, our basic architecture selects moves by a one-move lookahead
search, with an intermediate move generated by a nominal opponent engine, and
followed by a position evaluation by another chess engine. Simpler schemes that
forego the use of the nominal opponent, also perform better than the position
evaluator, but not quite by as much. More complex schemes, involving multistep
lookahead, may also be used and generally tend to perform better as the length
of the lookahead increases.
  Theoretically, our methodology relies on generic cost improvement properties
and the superlinear convergence framework of Newton's method, which
fundamentally underlies approximation in value space, and related MPC/RL and
rollout/policy iteration schemes. A critical requirement of this framework is
that the first lookahead step should be executed exactly. This fact has guided
our architectural choices, and is apparently an important factor in improving
the performance of even the best available chess engines.

摘要：<paragraph>在本文中，我们将模型预测控制 (MPC)、展开和强化学习 (RL) 方法应用于计算机国际象棋。我们引入了一种新的走法选择架构，其中可用的国际象棋引擎被用作组件。一个引擎用于在价值空间 MPC/RL 方案中提供位置评估，而另一个引擎则用作名义上的对手，以模拟或近似真实对手玩家的走法。
我们表明我们的架构大幅提升了位置评估引擎的性能。换句话说，我们的架构提供了一层额外的智能，建立在它所基于的引擎的智能之上。这适用于任何引擎，无论其强度如何：顶级引擎，如 Stockfish 和 Komodo Dragon（强度各异），以及较弱的引擎。
在结构上，我们的基本架构通过一步预测搜索选择走法，其中一步是由名义上的对手引擎生成的，然后由另一个国际象棋引擎进行位置评估。舍弃使用名义对手的更简单的方案也比位置评估器表现得更好，但没有好那么多。涉及多步预测的更复杂的方案也可以使用，并且通常随着预测长度的增加而表现得更好。
从理论上讲，我们的方法依赖于通用成本改进属性和牛顿法的超线性收敛框架，该框架从根本上支持价值空间中的近似，以及相关的 MPC/RL 和展开/策略迭代方案。这个框架的一个关键要求是第一步预测应该准确执行。这一事实指导了我们的架构选择，而且显然是提高甚至最好的可用国际象棋引擎性能的一个重要因素。</paragraph>

##### **An Effective Context-Balanced Adaptation Approach for Long-Tailed Speech Recognition**
2409.06468v1 by Yi-Cheng Wang, Li-Ting Pai, Bi-Cheng Yan, Hsin-Wei Wang, Chi-Han Lin, Berlin Chen

End-to-end (E2E) automatic speech recognition (ASR) models have become
standard practice for various commercial applications. However, in real-world
scenarios, the long-tailed nature of word distribution often leads E2E ASR
models to perform well on common words but fall short in recognizing uncommon
ones. Recently, the notion of a contextual adapter (CA) was proposed to infuse
external knowledge represented by a context word list into E2E ASR models.
Although CA can improve recognition performance on rare words, two crucial data
imbalance problems remain. First, when using low-frequency words as context
words during training, since these words rarely occur in the utterance, CA
becomes prone to overfit on attending to the <no-context> token due to
higher-frequency words not being present in the context list. Second, the
long-tailed distribution within the context list itself still causes the model
to perform poorly on low-frequency context words. In light of this, we explore
in-depth the impact of altering the context list to have words with different
frequency distributions on model performance, and meanwhile extend CA with a
simple yet effective context-balanced learning objective. A series of
experiments conducted on the AISHELL-1 benchmark dataset suggests that using
all vocabulary words from the training corpus as the context list and pairing
them with our balanced objective yields the best performance, demonstrating a
significant reduction in character error rate (CER) by up to 1.21% and a more
pronounced 9.44% reduction in the error rate of zero-shot words.

摘要：端對端 (E2E) 自動語音辨識 (ASR) 模型已成為各種商業應用中的標準實務。然而，在真實世界的場景中，詞彙分佈的長尾特性常常導致 E2E ASR 模型在常見詞彙上表現良好，但在辨識不常見詞彙時卻表現不佳。最近，有人提出情境式適配器 (CA) 的概念，將由情境詞彙清單所代表的外部知識注入 E2E ASR 模型中。儘管 CA 能夠提升罕見詞彙的辨識效能，但仍存在兩個關鍵的資料不平衡問題。首先，在訓練期間使用低頻率詞彙作為情境詞彙時，由於這些詞彙很少出現在語句中，因此 CA 容易過度擬合，專注於 <no-context> 權杖，因為較高頻率的詞彙並未出現在情境清單中。其次，情境清單本身內的長尾分佈仍會導致模型在低頻率情境詞彙上的表現不佳。有鑑於此，我們深入探討改變情境清單以納入具有不同頻率分佈的詞彙對模型效能的影響，同時使用一個簡單但有效的平衡情境學習目標來延伸 CA。在 AISHELL-1 基準資料集上進行的一系列實驗顯示，使用訓練語料庫中的所有詞彙作為情境清單，並將其與我們的平衡目標配對，可產生最佳效能，證明字元錯誤率 (CER) 大幅降低了 1.21%，而零次學習詞彙的錯誤率則大幅降低了 9.44%。

##### **Multimodal Large Language Model Driven Scenario Testing for Autonomous Vehicles**
2409.06450v1 by Qiujing Lu, Xuanhan Wang, Yiwei Jiang, Guangming Zhao, Mingyue Ma, Shuo Feng

The generation of corner cases has become increasingly crucial for
efficiently testing autonomous vehicles prior to road deployment. However,
existing methods struggle to accommodate diverse testing requirements and often
lack the ability to generalize to unseen situations, thereby reducing the
convenience and usability of the generated scenarios. A method that facilitates
easily controllable scenario generation for efficient autonomous vehicles (AV)
testing with realistic and challenging situations is greatly needed. To address
this, we proposed OmniTester: a multimodal Large Language Model (LLM) based
framework that fully leverages the extensive world knowledge and reasoning
capabilities of LLMs. OmniTester is designed to generate realistic and diverse
scenarios within a simulation environment, offering a robust solution for
testing and evaluating AVs. In addition to prompt engineering, we employ tools
from Simulation of Urban Mobility to simplify the complexity of codes generated
by LLMs. Furthermore, we incorporate Retrieval-Augmented Generation and a
self-improvement mechanism to enhance the LLM's understanding of scenarios,
thereby increasing its ability to produce more realistic scenes. In the
experiments, we demonstrated the controllability and realism of our approaches
in generating three types of challenging and complex scenarios. Additionally,
we showcased its effectiveness in reconstructing new scenarios described in
crash report, driven by the generalization capability of LLMs.

摘要：自動駕駛車輛在路測前，產生邊緣案例已變得越來越重要，以便能有效地進行測試。然而，現有方法難以適應多樣化的測試需求，而且常常缺乏對未見情況進行概化的能力，因而降低了產生情境的便利性和可用性。我們非常需要一種方法，以便於控制情境產生，以進行有效率的自動駕駛車輛 (AV) 測試，並包含逼真且具挑戰性的情況。為了解決這個問題，我們提出了 OmniTester：一個多模態大型語言模型 (LLM) 基底架構，它充分利用了 LLM 廣泛的世界知識和推理能力。OmniTester 旨在在模擬環境中產生逼真且多樣化的情境，為測試和評估 AV 提供了一個強大的解決方案。除了提示工程外，我們還採用了都市機動模擬工具，以簡化 LLM 所產生程式碼的複雜性。此外，我們整合了檢索強化產生和自我改善機制，以增強 LLM 對情境的理解，從而提高其產生更逼真場景的能力。在實驗中，我們展示了我們的途徑在產生三種類型的具挑戰性和複雜情境中的可控性和真實性。此外，我們展示了它在重建碰撞報告中描述的新情境方面的有效性，這得益於 LLM 的概化能力。

##### **HexaCoder: Secure Code Generation via Oracle-Guided Synthetic Training Data**
2409.06446v1 by Hossein Hajipour, Lea Schönherr, Thorsten Holz, Mario Fritz

Large language models (LLMs) have shown great potential for automatic code
generation and form the basis for various tools such as GitHub Copilot.
However, recent studies highlight that many LLM-generated code contains serious
security vulnerabilities. While previous work tries to address this by training
models that generate secure code, these attempts remain constrained by limited
access to training data and labor-intensive data preparation.
  In this paper, we introduce HexaCoder, a novel approach to enhance the
ability of LLMs to generate secure codes by automatically synthesizing secure
codes, which reduces the effort of finding suitable training data. HexaCoder
comprises two key components: an oracle-guided data synthesis pipeline and a
two-step process for secure code generation. The data synthesis pipeline
generates pairs of vulnerable and fixed codes for specific Common Weakness
Enumeration (CWE) types by utilizing a state-of-the-art LLM for repairing
vulnerable code. A security oracle identifies vulnerabilities, and a
state-of-the-art LLM repairs them by extending and/or editing the codes,
creating data pairs for fine-tuning using the Low-Rank Adaptation (LoRA)
method. Each example of our fine-tuning dataset includes the necessary
security-related libraries and code that form the basis of our novel two-step
generation approach. This allows the model to integrate security-relevant
libraries before generating the main code, significantly reducing the number of
generated vulnerable codes by up to 85% compared to the baseline methods. We
perform extensive evaluations on three different benchmarks for four LLMs,
demonstrating that HexaCoder not only improves the security of the generated
code but also maintains a high level of functional correctness.

摘要：大型語言模型 (LLM) 在自動程式碼生成方面展現了巨大的潛力，並成為各種工具的基礎，例如 GitHub Copilot。然而，最近的研究強調，許多 LLM 生成的程式碼包含嚴重的安全漏洞。雖然先前的研究嘗試透過訓練產生安全程式碼的模型來解決此問題，但這些嘗試仍受到訓練資料取得受限和資料準備工作繁重的限制。在本文中，我們介紹 HexaCoder，這是一種透過自動合成安全程式碼來增強 LLM 產生安全程式碼能力的新方法，它減少了尋找合適訓練資料的精力。HexaCoder 包含兩個關鍵組成部分：一個由 Oracle 引導的資料合成管線，以及一個用於產生安全程式碼的兩步驟程序。資料合成管線透過利用最先進的 LLM 來修復有漏洞的程式碼，為特定常見弱點列舉 (CWE) 類型產生有漏洞和已修復程式碼的配對。安全 Oracle 會識別漏洞，而最先進的 LLM 會透過延伸和/或編輯程式碼來修復這些漏洞，並建立資料配對，以使用低秩適應 (LoRA) 方法進行微調。我們的微調資料集的每個範例都包含必要的安全相關函式庫和程式碼，這些程式碼構成我們新穎兩步驟生成方法的基礎。這允許模型在產生主程式碼之前整合與安全相關的函式庫，與基線方法相比，可顯著減少多達 85% 的有漏洞程式碼數量。我們針對四個 LLM 的三個不同基準進行廣泛評估，證明 HexaCoder 不僅提高了所產生程式碼的安全性，還維持了高水準的功能正確性。

##### **Learning Generative Interactive Environments By Trained Agent Exploration**
2409.06445v1 by Naser Kazemi, Nedko Savov, Danda Paudel, Luc Van Gool

World models are increasingly pivotal in interpreting and simulating the
rules and actions of complex environments. Genie, a recent model, excels at
learning from visually diverse environments but relies on costly
human-collected data. We observe that their alternative method of using random
agents is too limited to explore the environment. We propose to improve the
model by employing reinforcement learning based agents for data generation.
This approach produces diverse datasets that enhance the model's ability to
adapt and perform well across various scenarios and realistic actions within
the environment. In this paper, we first release the model GenieRedux - an
implementation based on Genie. Additionally, we introduce GenieRedux-G, a
variant that uses the agent's readily available actions to factor out action
prediction uncertainty during validation. Our evaluation, including a
replication of the Coinrun case study, shows that GenieRedux-G achieves
superior visual fidelity and controllability using the trained agent
exploration. The proposed approach is reproducable, scalable and adaptable to
new types of environments. Our codebase is available at
https://github.com/insait-institute/GenieRedux .

摘要：世界模型在解釋和模擬複雜環境的規則和動作中愈發重要。Genie 是一個最近的模型，它擅長從視覺多樣的環境中學習，但依賴於昂貴的人工收集的數據。我們觀察到，他們使用隨機代理的替代方法對於探索環境來說過於受限。我們建議通過採用基於強化學習的代理來改進模型以進行數據生成。這種方法產生多樣化的數據集，增強了模型在環境中適應和執行各種場景和現實動作的能力。在本文中，我們首先發布模型 GenieRedux——一個基於 Genie 的實現。此外，我們還介紹了 GenieRedux-G，這是一個變體，它使用代理現成的動作來分解驗證期間的動作預測不確定性。我們的評估，包括複製 Coinrun 案例研究，表明 GenieRedux-G 使用訓練有素的代理探索，實現了卓越的視覺保真度和可控性。所提出的方法可重現、可擴展且適用於新型環境。我們的代碼庫可在 https://github.com/insait-institute/GenieRedux 獲得。

##### **GeMuCo: Generalized Multisensory Correlational Model for Body Schema Learning**
2409.06427v1 by Kento Kawaharazuka, Kei Okada, Masayuki Inaba

Humans can autonomously learn the relationship between sensation and motion
in their own bodies, estimate and control their own body states, and move while
continuously adapting to the current environment. On the other hand, current
robots control their bodies by learning the network structure described by
humans from their experiences, making certain assumptions on the relationship
between sensors and actuators. In addition, the network model does not adapt to
changes in the robot's body, the tools that are grasped, or the environment,
and there is no unified theory, not only for control but also for state
estimation, anomaly detection, simulation, and so on. In this study, we propose
a Generalized Multisensory Correlational Model (GeMuCo), in which the robot
itself acquires a body schema describing the correlation between sensors and
actuators from its own experience, including model structures such as network
input/output. The robot adapts to the current environment by updating this body
schema model online, estimates and controls its body state, and even performs
anomaly detection and simulation. We demonstrate the effectiveness of this
method by applying it to tool-use considering changes in grasping state for an
axis-driven robot, to joint-muscle mapping learning for a musculoskeletal
robot, and to full-body tool manipulation for a low-rigidity plastic-made
humanoid.

摘要：人類可以自主學習身體中感覺和動作之間的關係，估計和控制自己的身體狀態，並在持續適應當前環境的同時移動。另一方面，當前的機器人通過從經驗中學習人類描述的網路結構來控制其身體，對感測器和致動器之間的關係做出某些假設。此外，網路模型不會適應機器人身體、所抓取的工具或環境的變化，而且不僅對於控制，而且對於狀態估計、異常偵測、模擬等，都沒有統一的理論。在本研究中，我們提出了一個廣義的多感官相關模型 (GeMuCo)，其中機器人本身從自己的經驗中獲取描述感測器和致動器之間相關性的身體模式，包括網路輸入/輸出等模型結構。機器人通過在線上更新這個身體模式模型來適應當前環境，估計和控制其身體狀態，甚至執行異常偵測和模擬。我們通過將此方法應用於考慮軸驅動機器人的抓握狀態變化、用於肌肉骨骼機器人的關節肌肉對應學習以及用於低剛性塑膠製成的類人機器人的全身工具操作，來證明此方法的有效性。

##### **Exploring the Integration of Large Language Models in Industrial Test Maintenance Processes**
2409.06416v1 by Ludvig Lemner, Linnea Wahlgren, Gregory Gay, Nasser Mohammadiha, Jingxiong Liu, Joakim Wennerberg

Much of the cost and effort required during the software testing process is
invested in performing test maintenance - the addition, removal, or
modification of test cases to keep the test suite in sync with the
system-under-test or to otherwise improve its quality. Tool support could
reduce the cost - and improve the quality - of test maintenance by automating
aspects of the process or by providing guidance and support to developers.
  In this study, we explore the capabilities and applications of large language
models (LLMs) - complex machine learning models adapted to textual analysis -
to support test maintenance. We conducted a case study at Ericsson AB where we
explored the triggers that indicate the need for test maintenance, the actions
that LLMs can take, and the considerations that must be made when deploying
LLMs in an industrial setting. We also proposed and demonstrated
implementations of two multi-agent architectures that can predict which test
cases require maintenance following a change to the source code. Collectively,
these contributions advance our theoretical and practical understanding of how
LLMs can be deployed to benefit industrial test maintenance processes.

摘要：軟體測試過程中所需的大量成本和精力，都投入在執行測試維護上，包括新增、移除或修改測試案例，以使測試套件與受測系統同步，或以其他方式改善其品質。工具支援可透過自動化處理程序，或提供開發人員指導和支援，來降低成本並改善測試維護的品質。在本研究中，我們探討大型語言模型 (LLM) 的功能和應用，LLM 是複雜的機器學習模型，適用於文本分析，可支援測試維護。我們在愛立信公司進行了一項個案研究，探討了表示需要測試維護的觸發因素、LLM 可執行的動作，以及在工業環境中部署 LLM 時必須考量的因素。我們也提出並展示了兩個多重代理架構的實作，這些架構可以預測在原始碼變更後哪些測試案例需要維護。這些貢獻共同提升了我們對如何部署 LLM 以利於工業測試維護程序的理論和實務理解。

##### **Length Desensitization in Directed Preference Optimization**
2409.06411v1 by Wei Liu, Yang Bai, Chengcheng Han, Rongxiang Weng, Jun Xu, Xuezhi Cao, Jingang Wang, Xunliang Cai

Direct Preference Optimization (DPO) is widely utilized in the Reinforcement
Learning from Human Feedback (RLHF) phase to align Large Language Models (LLMs)
with human preferences, thereby enhancing both their harmlessness and efficacy.
However, it has been observed that DPO tends to over-optimize for verbosity,
which can detrimentally affect both performance and user experience. In this
paper, we conduct an in-depth theoretical analysis of DPO's optimization
objective and reveal a strong correlation between its implicit reward and data
length. This correlation misguides the optimization direction, resulting in
length sensitivity during the DPO training and leading to verbosity. To address
this issue, we propose a length-desensitization improvement method for DPO,
termed LD-DPO. The proposed method aims to desensitize DPO to data length by
decoupling explicit length preference, which is relatively insignificant, from
the other implicit preferences, thereby enabling more effective learning of the
intrinsic preferences. We utilized two settings (Base and Instruct) of
Llama2-13B, Llama3-8B, and Qwen2-7B for experimental validation on various
benchmarks including MT-Bench and AlpacaEval 2. The experimental results
indicate that LD-DPO consistently outperforms DPO and other baseline methods,
achieving more concise responses with a 10-40\% reduction in length compared to
DPO. We conducted in-depth experimental analyses to demonstrate that LD-DPO can
indeed achieve length desensitization and align the model more closely with
human-real preferences.

摘要：直接偏好最佳化（DPO）廣泛用於人類回饋強化學習（RLHF）階段，以將大型語言模型（LLM）與人類偏好結合，從而增強其無害性和效能。然而，觀察到 DPO 傾向於過度最佳化冗長性，這可能會對效能和使用者體驗造成負面影響。在本文中，我們對 DPO 的最佳化目標進行深入的理論分析，並揭示其隱含獎勵與資料長度之間的強烈關聯。這種關聯會誤導最佳化方向，導致 DPO 訓練期間長度敏感，並導致冗長。為了解決這個問題，我們提出了一種長度去敏化改善方法，稱為 LD-DPO。所提出的方法旨在透過將顯式的長度偏好（相對不重要）與其他隱含偏好分開，讓 DPO 對資料長度去敏化，從而能更有效地學習內在偏好。我們利用 Llama2-13B、Llama3-8B 和 Qwen2-7B 的兩個設定（基礎和指令）在各種基準上進行實驗驗證，包括 MT-Bench 和 AlpacaEval 2。實驗結果表明，LD-DPO 持續優於 DPO 和其他基線方法，與 DPO 相比，長度減少了 10-40%，產生了更簡潔的回應。我們進行了深入的實驗分析，以證明 LD-DPO 確實可以實現長度去敏化，並使模型更接近人類真實偏好。

##### **Coarse-Grained Sense Inventories Based on Semantic Matching between English Dictionaries**
2409.06386v1 by Masato Kikuchi, Masatsugu Ono, Toshioki Soga, Tetsu Tanabe, Tadachika Ozono

WordNet is one of the largest handcrafted concept dictionaries visualizing
word connections through semantic relationships. It is widely used as a word
sense inventory in natural language processing tasks. However, WordNet's
fine-grained senses have been criticized for limiting its usability. In this
paper, we semantically match sense definitions from Cambridge dictionaries and
WordNet and develop new coarse-grained sense inventories. We verify the
effectiveness of our inventories by comparing their semantic coherences with
that of Coarse Sense Inventory. The advantages of the proposed inventories
include their low dependency on large-scale resources, better aggregation of
closely related senses, CEFR-level assignments, and ease of expansion and
improvement.

摘要：WordNet 是最大的手工概念字典之一，它通过语义关系可视化单词连接。它被广泛用作自然语言处理任务中的词义清单。然而，WordNet 的细粒度词义因限制其可用性而受到批评。在本文中，我们对剑桥词典和 WordNet 中的词义定义进行了语义匹配，并开发了新的粗粒度词义清单。我们通过比较它们与粗粒度词义清单的语义连贯性来验证我们清单的有效性。所提出清单的优点包括它们对大规模资源的低依赖性、对密切相关的词义的更好聚合、CEFR 级别的分配以及易于扩展和改进。

##### **Enhancing Sequential Recommendations through Multi-Perspective Reflections and Iteration**
2409.06377v1 by Weicong Qin, Yi Xu, Weijie Yu, Chenglei Shen, Xiao Zhang, Ming He, Jianping Fan, Jun Xu

Sequence recommendation (SeqRec) aims to predict the next item a user will
interact with by understanding user intentions and leveraging collaborative
filtering information. Large language models (LLMs) have shown great promise in
recommendation tasks through prompt-based, fixed reflection libraries, and
fine-tuning techniques. However, these methods face challenges, including lack
of supervision, inability to optimize reflection sources, inflexibility to
diverse user needs, and high computational costs. Despite promising results,
current studies primarily focus on reflections of users' explicit preferences
(e.g., item titles) while neglecting implicit preferences (e.g., brands) and
collaborative filtering information. This oversight hinders the capture of
preference shifts and dynamic user behaviors. Additionally, existing approaches
lack mechanisms for reflection evaluation and iteration, often leading to
suboptimal recommendations. To address these issues, we propose the Mixture of
REflectors (MoRE) framework, designed to model and learn dynamic user
preferences in SeqRec. Specifically, MoRE introduces three reflectors for
generating LLM-based reflections on explicit preferences, implicit preferences,
and collaborative signals. Each reflector incorporates a self-improving
strategy, termed refining-and-iteration, to evaluate and iteratively update
reflections. Furthermore, a meta-reflector employs a contextual bandit
algorithm to select the most suitable expert and corresponding reflections for
each user's recommendation, effectively capturing dynamic preferences.
Extensive experiments on three real-world datasets demonstrate that MoRE
consistently outperforms state-of-the-art methods, requiring less training time
and GPU memory compared to other LLM-based approaches in SeqRec.

摘要：序列推薦（SeqRec）旨在透過了解使用者意圖，並利用協同過濾資訊，預測使用者將互動的下一項內容。大型語言模型（LLM）透過基於提示的固定反射函式庫和微調技術，在推薦任務中展現極佳的前景。然而，這些方法面臨挑戰，包括缺乏監督、無法最佳化反射來源、對多元使用者需求缺乏彈性，以及高運算成本。儘管有令人振奮的成果，目前的研究主要關注使用者明確偏好的反射（例如項目標題），而忽略了隱含偏好（例如品牌）和協同過濾資訊。這種疏忽阻礙了偏好轉變和動態使用者行為的捕捉。此外，現有方法缺乏反射評估和迭代機制，通常導致次佳推薦。為了解決這些問題，我們提出混合反射器（MoRE）架構，旨在建模和學習 SeqRec 中的動態使用者偏好。具體來說，MoRE 導入三個反射器，用於針對明確偏好、隱含偏好和協同訊號產生基於 LLM 的反射。每個反射器都包含一個自我提升策略，稱為精煉和迭代，用於評估和反覆更新反射。此外，元反射器採用情境式多臂老虎機演算法，為每個使用者的推薦選擇最合適的專家和對應反射，有效捕捉動態偏好。在三個真實世界資料集上的廣泛實驗證明，與 SeqRec 中其他基於 LLM 的方法相比，MoRE 持續優於最先進的方法，且所需的訓練時間和 GPU 記憶體較少。

##### **SpeechTaxi: On Multilingual Semantic Speech Classification**
2409.06372v1 by Lennart Keller, Goran Glavaš

Recent advancements in multilingual speech encoding as well as transcription
raise the question of the most effective approach to semantic speech
classification. Concretely, can (1) end-to-end (E2E) classifiers obtained by
fine-tuning state-of-the-art multilingual speech encoders (MSEs) match or
surpass the performance of (2) cascading (CA), where speech is first
transcribed into text and classification is delegated to a text-based
classifier. To answer this, we first construct SpeechTaxi, an 80-hour
multilingual dataset for semantic speech classification of Bible verses,
covering 28 diverse languages. We then leverage SpeechTaxi to conduct a wide
range of experiments comparing E2E and CA in monolingual semantic speech
classification as well as in cross-lingual transfer. We find that E2E based on
MSEs outperforms CA in monolingual setups, i.e., when trained on in-language
data. However, MSEs seem to have poor cross-lingual transfer abilities, with
E2E substantially lagging CA both in (1) zero-shot transfer to languages unseen
in training and (2) multilingual training, i.e., joint training on multiple
languages. Finally, we devise a novel CA approach based on transcription to
Romanized text as a language-agnostic intermediate representation and show that
it represents a robust solution for languages without native ASR support. Our
SpeechTaxi dataset is publicly available at: https://huggingface.co/
datasets/LennartKeller/SpeechTaxi/.

摘要：<paragraph>多語言語音編碼和轉錄的最新進展引發了關於語義語音分類最有效方法的問題。具體來說，通過微調最先進的多語言語音編碼器 (MSE) 獲得的 (1) 端到端 (E2E) 分類器是否可以匹配或超越 (2) 串聯 (CA) 的性能，其中語音首先轉錄成文本，分類委派給基於文本的分類器。為了解答這個問題，我們首先構建了 SpeechTaxi，一個用於聖經詩句語義語音分類的 80 小時的語音資料集，涵蓋 28 種不同的語言。然後，我們利用 SpeechTaxi 進行了一系列廣泛的實驗，比較了單語言語義語音分類以及跨語言轉移中的 E2E 和 CA。我們發現基於 MSE 的 E2E 在單語言設置中優於 CA，即在語言內數據上進行訓練時。然而，MSE 似乎具有較差的跨語言傳輸能力，E2E 在 (1) 零次傳輸到訓練中未見的語言和 (2) 多語言訓練，即在多種語言上進行聯合訓練方面都遠遠落後於 CA。最後，我們設計了一種基於轉錄為羅馬化文本的新穎 CA 方法，作為與語言無關的中間表示，並表明它代表了對沒有原生 ASR 支持的語言的強健解決方案。我們的 SpeechTaxi 資料集可在以下位置公開獲得：https://huggingface.co/datasets/LennartKeller/SpeechTaxi/。</paragraph>

##### **Distilling Generative-Discriminative Representations for Very Low-Resolution Face Recognition**
2409.06371v1 by Junzheng Zhang, Weijia Guo, Bochao Liu, Ruixin Shi, Yong Li, Shiming Ge

Very low-resolution face recognition is challenging due to the serious loss
of informative facial details in resolution degradation. In this paper, we
propose a generative-discriminative representation distillation approach that
combines generative representation with cross-resolution aligned knowledge
distillation. This approach facilitates very low-resolution face recognition by
jointly distilling generative and discriminative models via two distillation
modules. Firstly, the generative representation distillation takes the encoder
of a diffusion model pretrained for face super-resolution as the generative
teacher to supervise the learning of the student backbone via feature
regression, and then freezes the student backbone. After that, the
discriminative representation distillation further considers a pretrained face
recognizer as the discriminative teacher to supervise the learning of the
student head via cross-resolution relational contrastive distillation. In this
way, the general backbone representation can be transformed into discriminative
head representation, leading to a robust and discriminative student model for
very low-resolution face recognition. Our approach improves the recovery of the
missing details in very low-resolution faces and achieves better knowledge
transfer. Extensive experiments on face datasets demonstrate that our approach
enhances the recognition accuracy of very low-resolution faces, showcasing its
effectiveness and adaptability.

摘要：由於解析度降低時會嚴重喪失具資訊性的臉部細節，因此解析度極低的臉部辨識具有挑戰性。在本文中，我們提出了一種生成式辨識表徵蒸餾方法，結合生成式表徵與跨解析度對齊知識蒸餾。此方法透過兩個蒸餾模組，共同蒸餾生成式與辨識模型，進而促進解析度極低的臉部辨識。首先，生成式表徵蒸餾將預訓練用於臉部超解析度的擴散模型編碼器視為生成式教師，透過特徵回歸監督學生主幹的學習，然後凍結學生主幹。之後，辨識表徵蒸餾進一步將預訓練的臉部辨識器視為辨識教師，透過跨解析度關係對比蒸餾監督學生頭部的學習。透過這種方式，一般主幹表徵可以轉換為辨識頭部表徵，進而產生一個用於解析度極低的臉部辨識的強健且具辨識力的學生模型。我們的做法改善了解析度極低臉部中遺失細節的復原，並達到了更好的知識傳遞。對臉部資料集進行的廣泛實驗證明，我們的做法增強了解析度極低臉部的辨識精確度，展示了其有效性與適應性。

##### **Texture-AD: An Anomaly Detection Dataset and Benchmark for Real Algorithm Development**
2409.06367v1 by Tianwu Lei, Bohan Wang, Silin Chen, Shurong Cao, Ningmu Zou

Anomaly detection is a crucial process in industrial manufacturing and has
made significant advancements recently. However, there is a large variance
between the data used in the development and the data collected by the
production environment. Therefore, we present the Texture-AD benchmark based on
representative texture-based anomaly detection to evaluate the effectiveness of
unsupervised anomaly detection algorithms in real-world applications. This
dataset includes images of 15 different cloth, 14 semiconductor wafers and 10
metal plates acquired under different optical schemes. In addition, it includes
more than 10 different types of defects produced during real manufacturing
processes, such as scratches, wrinkles, color variations and point defects,
which are often more difficult to detect than existing datasets. All anomalous
areas are provided with pixel-level annotations to facilitate comprehensive
evaluation using anomaly detection models. Specifically, to adapt to diverse
products in automated pipelines, we present a new evaluation method and results
of baseline algorithms. The experimental results show that Texture-AD is a
difficult challenge for state-of-the-art algorithms. To our knowledge,
Texture-AD is the first dataset to be devoted to evaluating industrial defect
detection algorithms in the real world. The dataset is available at
https://XXX.

摘要：異常偵測在工業製造中是一個至關重要的程序，並且最近已取得重大進展。然而，用於開發的資料與生產環境收集的資料之間存在很大的差異。因此，我們提出了基於代表性紋理異常偵測的 Texture-AD 評量基準，以評估無監督異常偵測演算法在實際應用中的有效性。此資料集包含在不同光學方案下取得的 15 種不同布料、14 片半導體晶圓和 10 片金屬板的影像。此外，它還包含在實際製造過程中產生的 10 多種不同類型的缺陷，例如刮痕、皺紋、顏色變化和點缺陷，這些缺陷通常比現有資料集更難偵測。所有異常區域都提供像素級註解，以利於使用異常偵測模型進行全面評估。具體來說，為了適應自動化管道中的各種產品，我們提出了一種新的評估方法和基線演算法的結果。實驗結果表明，Texture-AD 對最先進的演算法來說是一個艱難的挑戰。據我們所知，Texture-AD 是第一個致力於評估實際環境中的工業缺陷偵測演算法的資料集。此資料集可在 https://XXX 取得。

##### **Connecting Concept Convexity and Human-Machine Alignment in Deep Neural Networks**
2409.06362v1 by Teresa Dorszewski, Lenka Tětková, Lorenz Linhardt, Lars Kai Hansen

Understanding how neural networks align with human cognitive processes is a
crucial step toward developing more interpretable and reliable AI systems.
Motivated by theories of human cognition, this study examines the relationship
between \emph{convexity} in neural network representations and
\emph{human-machine alignment} based on behavioral data. We identify a
correlation between these two dimensions in pretrained and fine-tuned vision
transformer models. Our findings suggest that the convex regions formed in
latent spaces of neural networks to some extent align with human-defined
categories and reflect the similarity relations humans use in cognitive tasks.
While optimizing for alignment generally enhances convexity, increasing
convexity through fine-tuning yields inconsistent effects on alignment, which
suggests a complex relationship between the two. This study presents a first
step toward understanding the relationship between the convexity of latent
representations and human-machine alignment.

摘要：了解神经網路如何與人類認知過程相符，是朝開發更具可解釋性與可信賴性的 AI 系統邁進的關鍵一步。本研究受到人類認知理論的啟發，探討神經網路表示中的「凸性」與根據行為資料的「人機對齊」之間的關係。我們在預訓練和微調的視覺轉換器模型中，找出這兩個面向之間的關聯性。我們的發現顯示，在神經網路的潛在空間中形成的凸區域，在某種程度上與人類定義的類別相符，並反映了人類在認知任務中使用的相似性關係。雖然針對對齊進行最佳化通常會增強凸性，但透過微調來增加凸性，對對齊的影響卻不一致，這表明兩者之間的關係很複雜。本研究為了解潛在表示的凸性與人機對齊之間的關係，踏出了第一步。

##### **MAGDA: Multi-agent guideline-driven diagnostic assistance**
2409.06351v1 by David Bani-Harouni, Nassir Navab, Matthias Keicher

In emergency departments, rural hospitals, or clinics in less developed
regions, clinicians often lack fast image analysis by trained radiologists,
which can have a detrimental effect on patients' healthcare. Large Language
Models (LLMs) have the potential to alleviate some pressure from these
clinicians by providing insights that can help them in their decision-making.
While these LLMs achieve high test results on medical exams showcasing their
great theoretical medical knowledge, they tend not to follow medical
guidelines. In this work, we introduce a new approach for zero-shot
guideline-driven decision support. We model a system of multiple LLM agents
augmented with a contrastive vision-language model that collaborate to reach a
patient diagnosis. After providing the agents with simple diagnostic
guidelines, they will synthesize prompts and screen the image for findings
following these guidelines. Finally, they provide understandable
chain-of-thought reasoning for their diagnosis, which is then self-refined to
consider inter-dependencies between diseases. As our method is zero-shot, it is
adaptable to settings with rare diseases, where training data is limited, but
expert-crafted disease descriptions are available. We evaluate our method on
two chest X-ray datasets, CheXpert and ChestX-ray 14 Longtail, showcasing
performance improvement over existing zero-shot methods and generalizability to
rare diseases.

摘要：在急診室、鄉村醫院或欠發達地區的診所，臨床醫師常常缺乏受過訓練的放射科醫師進行快速的影像分析，這可能會對病患的醫療保健造成不利影響。大型語言模型 (LLM) 有潛力減輕這些臨床醫師的一些壓力，方法是提供見解，協助他們進行決策。儘管這些 LLM 在展示其豐富的理論醫學知識的醫學考試中獲得了很高的測試結果，但它們往往不遵循醫療指南。在這項工作中，我們介紹了一種新的零次學習指導方針驅動決策支援方法。我們模擬了一個多個 LLM 代理系統，並增強了一個對比視覺語言模型，該模型協作以達成病患診斷。在為代理提供簡單的診斷指南後，它們將綜合提示並根據這些指南篩選影像以找出發現。最後，它們為其診斷提供可以理解的思路推理，然後自我精進以考量疾病之間的相互依存關係。由於我們的模型是零次學習，因此它可以適應罕見疾病的設定，在這種設定中，訓練資料有限，但有專家製作的疾病描述可用。我們在兩個胸部 X 光片資料集，CheXpert 和 ChestX-ray 14 Longtail，評估我們的模型，展示了相較於現有的零次學習方法的效能提升，以及對罕見疾病的概括性。

##### **VoiceWukong: Benchmarking Deepfake Voice Detection**
2409.06348v1 by Ziwei Yan, Yanjie Zhao, Haoyu Wang

With the rapid advancement of technologies like text-to-speech (TTS) and
voice conversion (VC), detecting deepfake voices has become increasingly
crucial. However, both academia and industry lack a comprehensive and intuitive
benchmark for evaluating detectors. Existing datasets are limited in language
diversity and lack many manipulations encountered in real-world production
environments.
  To fill this gap, we propose VoiceWukong, a benchmark designed to evaluate
the performance of deepfake voice detectors. To build the dataset, we first
collected deepfake voices generated by 19 advanced and widely recognized
commercial tools and 15 open-source tools. We then created 38 data variants
covering six types of manipulations, constructing the evaluation dataset for
deepfake voice detection. VoiceWukong thus includes 265,200 English and 148,200
Chinese deepfake voice samples. Using VoiceWukong, we evaluated 12
state-of-the-art detectors. AASIST2 achieved the best equal error rate (EER) of
13.50%, while all others exceeded 20%. Our findings reveal that these detectors
face significant challenges in real-world applications, with dramatically
declining performance. In addition, we conducted a user study with more than
300 participants. The results are compared with the performance of the 12
detectors and a multimodel large language model (MLLM), i.e., Qwen2-Audio,
where different detectors and humans exhibit varying identification
capabilities for deepfake voices at different deception levels, while the LALM
demonstrates no detection ability at all. Furthermore, we provide a leaderboard
for deepfake voice detection, publicly available at
{https://voicewukong.github.io}.

摘要：<paragraph>隨著文字轉語音 (TTS) 和語音轉換 (VC) 等技術的快速進步，偵測深度造假語音變得越來越重要。然而，學術界和業界都缺乏一個全面且直觀的基準來評估偵測器。現有的資料集在語言多樣性方面受到限制，並且缺乏在現實世界生產環境中遇到的許多操作。
  為了填補這個空白，我們提出了 VoiceWukong，一個旨在評估深度造假語音偵測器效能的基準。為了建立資料集，我們首先收集了由 19 個先進且廣泛認可的商業工具和 15 個開源工具生成的深度造假語音。然後，我們創建了 38 種資料變體，涵蓋六種類型的操作，構建了深度造假語音偵測的評估資料集。因此，VoiceWukong 包含 265,200 個英文和 148,200 個中文深度造假語音範例。使用 VoiceWukong，我們評估了 12 個最先進的偵測器。AASIST2 達到了 13.50% 的最佳等錯率 (EER)，而其他所有偵測器都超過了 20%。我們的研究結果顯示，這些偵測器在現實世界應用中面臨重大挑戰，效能大幅下降。此外，我們進行了一項有超過 300 名參與者的使用者研究。結果與 12 個偵測器的效能以及多模式大型語言模型 (MLLM)（即 Qwen2-Audio）進行比較，其中不同的偵測器和人類在不同欺騙層級對深度造假語音展現出不同的辨識能力，而 LALM 則完全沒有偵測能力。此外，我們提供了一個深度造假語音偵測排行榜，可在 {https://voicewukong.github.io} 公開取得。</paragraph>

##### **Compute-Update Federated Learning: A Lattice Coding Approach**
2409.06343v1 by Seyed Mohammad Azimi-Abarghouyi, Lav R. Varshney

This paper introduces a federated learning framework that enables
over-the-air computation via digital communications, using a new joint
source-channel coding scheme. Without relying on channel state information at
devices, this scheme employs lattice codes to both quantize model parameters
and exploit interference from the devices. We propose a novel receiver
structure at the server, designed to reliably decode an integer combination of
the quantized model parameters as a lattice point for the purpose of
aggregation. We present a mathematical approach to derive a convergence bound
for the proposed scheme and offer design remarks. In this context, we suggest
an aggregation metric and a corresponding algorithm to determine effective
integer coefficients for the aggregation in each communication round. Our
results illustrate that, regardless of channel dynamics and data heterogeneity,
our scheme consistently delivers superior learning accuracy across various
parameters and markedly surpasses other over-the-air methodologies.

摘要：本文提出了一個聯合學習架構，它使用一個新的聯合源通道編碼方案，通過數位通訊進行空中運算。在不依賴於設備上的通道狀態資訊的情況下，此方案採用格碼來量化模型參數並利用來自設備的干擾。我們在伺服器上提出了一個新穎的接收器結構，旨在可靠地將量化模型參數的整數組合解碼為格點，以進行聚合。我們提出了一種數學方法來推導所提出方案的收斂界限，並提供設計說明。在這種情況下，我們建議使用聚合指標和對應演算法來確定每一輪通訊中聚合的有效整數係數。我們的結果表明，無論通道動態和資料異質性如何，我們的方案都能在各種參數中持續提供優異的學習準確度，並顯著超越其他空中方法。

##### **Retrieval Or Holistic Understanding? Dolce: Differentiate Our Long Context Evaluation Tasks**
2409.06338v1 by Zi Yang

We argue that there are two major distinct capabilities in long context
understanding: retrieval and holistic understanding. Understanding and further
improving LLMs' long context capabilities would not be possible without knowing
the tasks' focus categories. We aim to automatically identify retrieval focused
and holistic understanding focused problems from suites of benchmarks and
quantitatively measure the difficulty within each focus. In this paper, we
present the Dolce framework, which parameterizes each problem by $\lambda$
(complexity) and $k$ (redundancy) and assigns to one of five predefined focus
categories. We propose to sample short contexts from the full context and
estimate the probability an LLM solves the problem using the sampled spans. To
find the $\lambda$ and $k$ for each problem, we further propose a mixture model
of a non-parametric background noise component and a parametric/non-parametric
hybrid oracle component, where we derive the probability functions
parameterized by $\lambda$ and $k$ for both the correct-or-wrong (COW) scenario
and the partial-point-in-grading (PIG) scenario. Our proposed methods can
identify 0% to 67% of the problems are retrieval focused and 0% to 90% of the
problems are holistic understanding focused across 44 existing long context
evaluation tasks.

摘要：我們主張長文理解中有兩個主要的區別能力：檢索和整體理解。了解和進一步改進 LLM 的長文理解能力，在不知道任務的重點類別是不可能的。我們的目標是從基準套件中自動識別以檢索為重點和以整體理解為重點的問題，並定量測量每個重點中的難度。在本文中，我們提出了 Dolce 框架，它通過 $\lambda$（複雜性）和 $k$（冗餘）對每個問題進行參數化，並將其分配到五個預定義的重點類別之一。我們建議從完整文中抽取簡短的語境，並估計 LLM 使用抽取的跨度解決問題的機率。為了找到每個問題的 $\lambda$ 和 $k$，我們進一步提出了非參數背景噪音組成和參數/非參數混合神諭組成的混合模型，其中我們推導出在正確或錯誤 (COW) 場景和部分分數評分 (PIG) 場景中由 $\lambda$ 和 $k$ 參數化的機率函數。我們提出的方法可以識別出 0% 到 67% 的問題以檢索為重點，以及 0% 到 90% 的問題以整體理解為重點，涵蓋 44 個現有的長文評估任務。

##### **Towards Agentic AI on Particle Accelerators**
2409.06336v1 by Antonin Sulc, Thorsten Hellert, Raimund Kammering, Hayden Houscher, Jason St. John

As particle accelerators grow in complexity, traditional control methods face
increasing challenges in achieving optimal performance. This paper envisions a
paradigm shift: a decentralized multi-agent framework for accelerator control,
powered by Large Language Models (LLMs) and distributed among autonomous
agents. We present a proposition of a self-improving decentralized system where
intelligent agents handle high-level tasks and communication and each agent is
specialized control individual accelerator components.
  This approach raises some questions: What are the future applications of AI
in particle accelerators? How can we implement an autonomous complex system
such as a particle accelerator where agents gradually improve through
experience and human feedback? What are the implications of integrating a
human-in-the-loop component for labeling operational data and providing expert
guidance? We show two examples, where we demonstrate viability of such
architecture.

摘要：隨著粒子加速器的複雜度不斷提升，傳統的控制方法在達成最佳效能時面臨越來越大的挑戰。本文構想了一種典範轉移：一種由大型語言模型 (LLM) 驅動且分佈在自主代理之間的加速器控制去中心化多代理架構。我們提出了一個自我提升的去中心化系統的命題，其中智慧代理處理高階任務和通訊，且每個代理專門控制個別加速器元件。
這種方法引發了一些問題：AI 在粒子加速器中的未來應用是什麼？我們如何實作一個自主複雜系統，例如粒子加速器，其中代理會透過經驗和人類回饋逐漸提升？將人類置於迴路中元件以標記作業資料並提供專家指導的影響是什麼？我們展示了兩個範例，說明這種架構的可行性。

##### **Extracting Paragraphs from LLM Token Activations**
2409.06328v1 by Nicholas Pochinkov, Angelo Benoit, Lovkush Agarwal, Zainab Ali Majid, Lucile Ter-Minassian

Generative large language models (LLMs) excel in natural language processing
tasks, yet their inner workings remain underexplored beyond token-level
predictions. This study investigates the degree to which these models decide
the content of a paragraph at its onset, shedding light on their contextual
understanding. By examining the information encoded in single-token
activations, specifically the "\textbackslash n\textbackslash n" double newline
token, we demonstrate that patching these activations can transfer significant
information about the context of the following paragraph, providing further
insights into the model's capacity to plan ahead.

摘要：生成式大型語言模型 (LLM) 在自然語言處理任務中表現出色，但它們的內部運作仍未被充分探索，僅止於符號層級的預測。本研究探討這些模型在段落開頭決定內容的程度，進而闡明它們的上下文理解能力。透過檢視單一符號激活中編碼的資訊，特別是「\n\n」雙換行符號，我們證明修補這些激活可以傳遞後續段落上下文的顯著資訊，進一步了解模型的超前規劃能力。

##### **LAMP: Learnable Meta-Path Guided Adversarial Contrastive Learning for Heterogeneous Graphs**
2409.06323v1 by Siqing Li, Jin-Duk Park, Wei Huang, Xin Cao, Won-Yong Shin, Zhiqiang Xu

Heterogeneous graph neural networks (HGNNs) have significantly propelled the
information retrieval (IR) field. Still, the effectiveness of HGNNs heavily
relies on high-quality labels, which are often expensive to acquire. This
challenge has shifted attention towards Heterogeneous Graph Contrastive
Learning (HGCL), which usually requires pre-defined meta-paths. However, our
findings reveal that meta-path combinations significantly affect performance in
unsupervised settings, an aspect often overlooked in current literature.
Existing HGCL methods have considerable variability in outcomes across
different meta-path combinations, thereby challenging the optimization process
to achieve consistent and high performance. In response, we introduce
\textsf{LAMP} (\underline{\textbf{L}}earn\underline{\textbf{A}}ble
\underline{\textbf{M}}eta-\underline{\textbf{P}}ath), a novel adversarial
contrastive learning approach that integrates various meta-path sub-graphs into
a unified and stable structure, leveraging the overlap among these sub-graphs.
To address the denseness of this integrated sub-graph, we propose an
adversarial training strategy for edge pruning, maintaining sparsity to enhance
model performance and robustness. \textsf{LAMP} aims to maximize the difference
between meta-path and network schema views for guiding contrastive learning to
capture the most meaningful information. Our extensive experimental study
conducted on four diverse datasets from the Heterogeneous Graph Benchmark (HGB)
demonstrates that \textsf{LAMP} significantly outperforms existing
state-of-the-art unsupervised models in terms of accuracy and robustness.

摘要：異質圖神經網路 (HGNN) 已顯著推動資訊檢索 (IR) 領域。儘管如此，HGNN 的有效性極度依賴於高品質標籤，而取得這些標籤通常成本高昂。這項挑戰已將注意力轉移到異質圖對比學習 (HGCL)，這通常需要預先定義的元路徑。然而，我們的研究結果顯示，元路徑組合會顯著影響無監督設定中的效能，而這項面向在現行文獻中常被忽略。現有的 HGCL 方法在不同的元路徑組合中具有相當大的結果變異性，因此挑戰了最佳化流程，難以達成一致且高品質的效能。為了解決這個問題，我們引入了 \textsf{LAMP}（可學習元路徑），這是一種新穎的對抗式對比學習方法，將各種元路徑子圖整合到統一且穩定的結構中，並利用這些子圖之間的重疊。為了解決這個整合子圖的稠密度，我們提出了一種對抗訓練策略，用於邊緣修剪，並維持稀疏性以增強模型效能與穩健性。\textsf{LAMP} 旨在最大化元路徑與網路架構檢視之間的差異，以引導對比學習擷取最有意義的資訊。我們在異質圖基準 (HGB) 中的四個不同資料集上進行廣泛的實驗研究，證明 \textsf{LAMP} 在準確度和穩健性方面顯著優於現有的最先進無監督模型。

##### **An End-to-End Approach for Chord-Conditioned Song Generation**
2409.06307v1 by Shuochen Gao, Shun Lei, Fan Zhuo, Hangyu Liu, Feng Liu, Boshi Tang, Qiaochu Huang, Shiyin Kang, Zhiyong Wu

The Song Generation task aims to synthesize music composed of vocals and
accompaniment from given lyrics. While the existing method, Jukebox, has
explored this task, its constrained control over the generations often leads to
deficiency in music performance. To mitigate the issue, we introduce an
important concept from music composition, namely chords, to song generation
networks. Chords form the foundation of accompaniment and provide vocal melody
with associated harmony. Given the inaccuracy of automatic chord extractors, we
devise a robust cross-attention mechanism augmented with dynamic weight
sequence to integrate extracted chord information into song generations and
reduce frame-level flaws, and propose a novel model termed Chord-Conditioned
Song Generator (CSG) based on it. Experimental evidence demonstrates our
proposed method outperforms other approaches in terms of musical performance
and control precision of generated songs.

摘要：歌曲生成任務旨在合成由人聲和伴奏組成的音樂，並從給定的歌詞中生成。雖然現有方法 Jukebox 已探討此任務，但其對生成過程的受限控制通常會導致音樂表現力不足。為了減輕此問題，我們將音樂創作中的重要概念和弦引入歌曲生成網路中。和弦構成伴奏的基礎，並為人聲旋律提供相關的和聲。由於自動和弦提取器的準確性不足，我們設計了一個強健的交叉注意力機制，並使用動態權重序列將提取的和弦資訊整合到歌曲生成中，並減少幀級缺陷，並提出一個基於此的新模型，稱為和弦條件歌曲生成器 (CSG)。實驗證據表明，我們提出的方法在音樂表現力和生成歌曲的控制精度方面優於其他方法。

##### **Enhancing Long Video Understanding via Hierarchical Event-Based Memory**
2409.06299v1 by Dingxin Cheng, Mingda Li, Jingyu Liu, Yongxin Guo, Bin Jiang, Qingbin Liu, Xi Chen, Bo Zhao

Recently, integrating visual foundation models into large language models
(LLMs) to form video understanding systems has attracted widespread attention.
Most of the existing models compress diverse semantic information within the
whole video and feed it into LLMs for content comprehension. While this method
excels in short video understanding, it may result in a blend of multiple event
information in long videos due to coarse compression, which causes information
redundancy. Consequently, the semantics of key events might be obscured within
the vast information that hinders the model's understanding capabilities. To
address this issue, we propose a Hierarchical Event-based Memory-enhanced LLM
(HEM-LLM) for better understanding of long videos. Firstly, we design a novel
adaptive sequence segmentation scheme to divide multiple events within long
videos. In this way, we can perform individual memory modeling for each event
to establish intra-event contextual connections, thereby reducing information
redundancy. Secondly, while modeling current event, we compress and inject the
information of the previous event to enhance the long-term inter-event
dependencies in videos. Finally, we perform extensive experiments on various
video understanding tasks and the results show that our model achieves
state-of-the-art performances.

摘要：最近，将视觉基础模型整合到大型语言模型 (LLM) 中以形成视频理解系统已引起广泛关注。
大多数现有模型都会压缩整个视频中的各种语义信息，并将其输入 LLM 以进行内容理解。虽然此方法在短视频理解方面表现出色，但由于粗略的压缩，它可能会导致长视频中多个事件信息的混合，从而导致信息冗余。因此，关键事件的语义可能会被隐藏在大量信息中，从而阻碍模型的理解能力。为了解决这个问题，我们提出了一种分层事件记忆增强 LLM (HEM-LLM) 以便更好地理解长视频。首先，我们设计了一种新颖的自适应序列分割方案，以划分长视频中的多个事件。通过这种方式，我们可以对每个事件执行单独的记忆建模，以建立事件内部的上下文连接，从而减少信息冗余。其次，在对当前事件进行建模时，我们压缩并注入前一个事件的信息，以增强视频中长期事件间的依赖关系。最后，我们对各种视频理解任务进行了广泛的实验，结果表明我们的模型取得了最先进的性能。

##### **User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study**
2409.06297v1 by Julien Albert, Martin Balfroid, Miriam Doh, Jeremie Bogaert, Luca La Fisca, Liesbet De Vos, Bryan Renard, Vincent Stragier, Emmanuel Jean

Recommender systems have become integral to our digital experiences, from
online shopping to streaming platforms. Still, the rationale behind their
suggestions often remains opaque to users. While some systems employ a
graph-based approach, offering inherent explainability through paths
associating recommended items and seed items, non-experts could not easily
understand these explanations. A popular alternative is to convert graph-based
explanations into textual ones using a template and an algorithm, which we
denote here as ''template-based'' explanations. Yet, these can sometimes come
across as impersonal or uninspiring. A novel method would be to employ large
language models (LLMs) for this purpose, which we denote as ''LLM-based''. To
assess the effectiveness of LLMs in generating more resonant explanations, we
conducted a pilot study with 25 participants. They were presented with three
explanations: (1) traditional template-based, (2) LLM-based rephrasing of the
template output, and (3) purely LLM-based explanations derived from the
graph-based explanations. Although subject to high variance, preliminary
findings suggest that LLM-based explanations may provide a richer and more
engaging user experience, further aligning with user expectations. This study
sheds light on the potential limitations of current explanation methods and
offers promising directions for leveraging large language models to improve
user satisfaction and trust in recommender systems.

摘要：推薦系統已成為我們數位體驗中不可或缺的一部分，從線上購物到串流平台皆是如此。然而，其建議背後的原理通常對使用者來說仍不透明。儘管有些系統採用基於圖形的做法，透過連結推薦項目與種子項目的路徑提供內在的可解釋性，但非專家無法輕易理解這些解釋。一種常見的替代方法是使用範本和演算法將基於圖形的解釋轉換為文字解釋，我們在此將其表示為「基於範本」的解釋。然而，這些解釋有時會顯得制式或缺乏靈感。一種新穎的方法是為此目的採用大型語言模型 (LLM)，我們將其表示為「基於 LLM」。為了評估 LLM 在產生更具共鳴解釋方面的有效性，我們進行了一項有 25 位參與者的試驗研究。我們向他們展示了三種解釋：(1) 傳統基於範本的解釋，(2) LLM 對範本輸出的重新表述，以及 (3) 純粹從基於圖形的解釋衍生的基於 LLM 的解釋。儘管存在高度變異，但初步結果表明，基於 LLM 的解釋可能提供更豐富、更吸引人的使用者體驗，進一步符合使用者的期望。這項研究揭示了當前解釋方法的潛在限制，並為利用大型語言模型來提升使用者滿意度和對推薦系統的信任提供了有希望的方向。

##### **Catch Me if You Can: Detecting Unauthorized Data Use in Deep Learning Models**
2409.06280v1 by Zitao Chen, Karthik Pattabiraman

The rise of deep learning (DL) has led to a surging demand for training data,
which incentivizes the creators of DL models to trawl through the Internet for
training materials. Meanwhile, users often have limited control over whether
their data (e.g., facial images) are used to train DL models without their
consent, which has engendered pressing concerns.
  This work proposes MembershipTracker, a practical data provenance tool that
can empower ordinary users to take agency in detecting the unauthorized use of
their data in training DL models. We view tracing data provenance through the
lens of membership inference (MI). MembershipTracker consists of a lightweight
data marking component to mark the target data with small and targeted changes,
which can be strongly memorized by the model trained on them; and a specialized
MI-based verification process to audit whether the model exhibits strong
memorization on the target samples.
  Overall, MembershipTracker only requires the users to mark a small fraction
of data (0.005% to 0.1% in proportion to the training set), and it enables the
users to reliably detect the unauthorized use of their data (average 0%
FPR@100% TPR). We show that MembershipTracker is highly effective across
various settings, including industry-scale training on the full-size
ImageNet-1k dataset. We finally evaluate MembershipTracker under multiple
classes of countermeasures.

摘要：深度學習 (DL) 的興起導致對訓練資料的需求激增，這激勵了 DL 模型的創建者在網路上搜尋訓練資料。同時，使用者通常無法控制他們的資料（例如：人臉影像）是否在未經他們同意的情況下被用來訓練 DL 模型，這引起了迫切的關注。
這項工作提出了 MembershipTracker，一個實用的資料來源工具，可以讓一般使用者在偵測他們的資料在訓練 DL 模型時被未經授權使用時，採取行動。我們透過成員推論 (MI) 的角度來追蹤資料來源。MembershipTracker 包含一個輕量級資料標記元件，用小而有針對性的變更來標記目標資料，這些變更可以被訓練在這些資料上的模型牢記；以及一個專門的基於 MI 的驗證程序，用來稽核模型是否對目標樣本展現強烈的記憶。
總體而言，MembershipTracker 只需要使用者標記一小部分資料（相對於訓練集，比例為 0.005% 到 0.1%），它讓使用者能夠可靠地偵測到他們的資料被未經授權使用（平均 0% FPR@100% TPR）。我們展示了 MembershipTracker 在各種設定中都非常有效，包括在全尺寸 ImageNet-1k 資料集上進行產業規模的訓練。最後，我們在多種對策類別下評估了 MembershipTracker。

##### **Ferret: Federated Full-Parameter Tuning at Scale for Large Language Models**
2409.06277v1 by Yao Shu, Wenyang Hu, See-Kiong Ng, Bryan Kian Hsiang Low, Fei Richard Yu

Large Language Models (LLMs) have become indispensable in numerous real-world
applications. Unfortunately, fine-tuning these models at scale, especially in
federated settings where data privacy and communication efficiency are
critical, presents significant challenges. Existing methods often resort to
parameter-efficient fine-tuning (PEFT) to mitigate communication overhead, but
this typically comes at the cost of model accuracy. To address these
limitations, we propose federated full-parameter tuning at scale for LLMs
(Ferret), the first first-order method with shared randomness to enable
scalable full-parameter tuning of LLMs across decentralized data sources while
maintaining competitive model accuracy. Ferret accomplishes this through three
aspects: (1) it employs widely applied first-order methods for efficient local
updates; (2) it projects these updates into a low-dimensional space to
considerably reduce communication overhead; and (3) it reconstructs local
updates from this low-dimensional space with shared randomness to facilitate
effective full-parameter global aggregation, ensuring fast convergence and
competitive final performance. Our rigorous theoretical analyses and insights
along with extensive experiments, show that Ferret significantly enhances the
scalability of existing federated full-parameter tuning approaches by achieving
high computational efficiency, reduced communication overhead, and fast
convergence, all while maintaining competitive model accuracy. Our
implementation is available at https://github.com/allen4747/Ferret.

摘要：大型語言模型 (LLM) 已在眾多真實世界的應用中變得不可或缺。不幸的是，要大規模微調這些模型，特別是在資料隱私和通訊效率至關重要的聯邦式設定中，會帶來重大挑戰。現有方法通常訴諸於參數有效微調 (PEFT) 來減輕通訊負擔，但這通常會以模型準確度為代價。為了解決這些限制，我們提出大規模 LLM 的聯邦式全參數調整 (Ferret)，這是第一個使用共享隨機性的第一階方法，可以在分散式資料來源中進行 LLM 的可擴充全參數調整，同時保持有競爭力的模型準確度。Ferret 透過三個面向來達成此目標：(1) 它採用廣泛應用的第一階方法進行有效率的局部更新；(2) 它將這些更新投射到低維度空間，以大幅降低通訊負擔；(3) 它從這個低維度空間使用共享隨機性重建局部更新，以促進有效的全參數全局聚合，確保快速收斂和有競爭力的最終效能。我們嚴謹的理論分析和見解，以及廣泛的實驗，顯示 Ferret 透過達成高運算效率、降低通訊負擔和快速收斂，大幅提升現有聯邦式全參數調整方法的可擴充性，同時保持有競爭力的模型準確度。我們的實作可以在 https://github.com/allen4747/Ferret 取得。

##### **Keyword-Aware ASR Error Augmentation for Robust Dialogue State Tracking**
2409.06263v1 by Jihyun Lee, Solee Im, Wonjun Lee, Gary Geunbae Lee

Dialogue State Tracking (DST) is a key part of task-oriented dialogue
systems, identifying important information in conversations. However, its
accuracy drops significantly in spoken dialogue environments due to named
entity errors from Automatic Speech Recognition (ASR) systems. We introduce a
simple yet effective data augmentation method that targets those entities to
improve the robustness of DST model. Our novel method can control the placement
of errors using keyword-highlighted prompts while introducing phonetically
similar errors. As a result, our method generated sufficient error patterns on
keywords, leading to improved accuracy in noised and low-accuracy ASR
environments.

摘要：對話狀態追蹤 (DST) 是任務導向對話系統的重要部分，用於識別對話中的重要資訊。然而，由於自動語音辨識 (ASR) 系統中的命名實體錯誤，其準確度在口語對話環境中大幅下降。我們引入一種簡單但有效的資料擴充方法，針對這些實體以提高 DST 模型的健全性。我們的創新方法可以在引入音似錯誤的同時，使用關鍵字突顯提示來控制錯誤的放置。因此，我們的模型在關鍵字上產生足夠的錯誤模式，從而提高了有雜訊和低準確度 ASR 環境中的準確度。

##### **DiPT: Enhancing LLM reasoning through diversified perspective-taking**
2409.06241v1 by Hoang Anh Just, Mahavir Dabas, Lifu Huang, Ming Jin, Ruoxi Jia

Existing work on improving language model reasoning typically explores a
single solution path, which can be prone to errors. Inspired by
perspective-taking in social studies, this paper introduces DiPT, a novel
approach that complements current reasoning methods by explicitly incorporating
diversified viewpoints. This approach allows the model to gain a deeper
understanding of the problem's context and identify the most effective solution
path during the inference stage. Additionally, it provides a general
data-centric AI recipe for augmenting existing data to improve their quality
for fine-tuning.
  Our empirical results demonstrate that DiPT can be flexibly integrated into
existing methods that focus on a single reasoning approach, enhancing their
reasoning performance and stability when presented with paraphrased problems.
Furthermore, we illustrate improved context understanding by maintaining the
model's safe outputs against "jailbreaking" prompts intentionally designed to
bypass safeguards built into deployed models. Lastly, we show that fine-tuning
with data enriched with diverse perspectives can boost the reasoning
capabilities of the model compared to fine-tuning with raw data alone.

摘要：現有的改善語言模型推理的工作通常會探索單一的解決方案路徑，這可能會容易出錯。受到社會研究中觀點採用的啟發，本文介紹了 DiPT，這是一種新方法，透過明確納入多元觀點來補充目前的推理方法。此方法允許模型更深入地了解問題的背景，並在推理階段找出最有效的解決方案路徑。此外，它提供了一種通用的以資料為中心的 AI 配方，用於擴充現有資料，以提升其微調品質。
我們的實證結果證明，DiPT 可以靈活地整合到專注於單一推理方法的現有方法中，在遇到轉述問題時，提升其推理效能和穩定性。此外，透過維持模型對於「越獄」提示的安全性輸出，我們展示了改善的背景理解，而這些提示旨在繞過部署模型中內建的防護措施。最後，我們展示了使用豐富多元觀點的資料進行微調，與僅使用原始資料進行微調相比，可以提升模型的推理能力。

##### **NLP-Powered Repository and Search Engine for Academic Papers: A Case Study on Cyber Risk Literature with CyLit**
2409.06226v1 by Linfeng Zhang, Changyue Hu, Zhiyu Quan

As the body of academic literature continues to grow, researchers face
increasing difficulties in effectively searching for relevant resources.
Existing databases and search engines often fall short of providing a
comprehensive and contextually relevant collection of academic literature. To
address this issue, we propose a novel framework that leverages Natural
Language Processing (NLP) techniques. This framework automates the retrieval,
summarization, and clustering of academic literature within a specific research
domain. To demonstrate the effectiveness of our approach, we introduce CyLit,
an NLP-powered repository specifically designed for the cyber risk literature.
CyLit empowers researchers by providing access to context-specific resources
and enabling the tracking of trends in the dynamic and rapidly evolving field
of cyber risk. Through the automatic processing of large volumes of data, our
NLP-powered solution significantly enhances the efficiency and specificity of
academic literature searches. We compare the literature categorization results
of CyLit to those presented in survey papers or generated by ChatGPT,
highlighting the distinctive insights this tool provides into cyber risk
research literature. Using NLP techniques, we aim to revolutionize the way
researchers discover, analyze, and utilize academic resources, ultimately
fostering advancements in various domains of knowledge.

摘要：隨著學術文獻的數量持續增加，研究人員在有效搜尋相關資源時面臨越來越大的困難。現有的資料庫和搜尋引擎通常無法提供全面且與脈絡相關的學術文獻集合。為了解決這個問題，我們提出一個新的架構，它利用自然語言處理 (NLP) 技術。這個架構自動化特定研究領域內學術文獻的檢索、摘要和分群。為了證明我們方法的有效性，我們引入了 CyLit，一個專門為網路風險文獻設計的 NLP 驅動儲存庫。CyLit 透過提供對特定脈絡資源的存取，並在動態且快速演進的網路風險領域追蹤趨勢，賦能研究人員。透過大量資料的自動化處理，我們 NLP 驅動的解決方案大幅提升學術文獻搜尋的效率和專一性。我們將 CyLit 的文獻分類結果與調查論文中提出的結果或由 ChatGPT 產生的結果進行比較，強調這個工具對網路風險研究文獻提供的獨特見解。透過使用 NLP 技術，我們旨在革新研究人員發現、分析和利用學術資源的方式，最終促進各個知識領域的進展。

##### **Enhancing Temporal Understanding in Audio Question Answering for Large Audio Language Models**
2409.06223v1 by Arvind Krishna Sridhar, Yinyi Guo, Erik Visser

The Audio Question Answering task includes audio event classification, audio
captioning, and open ended reasoning. Recently, Audio Question Answering has
garnered attention due to the advent of Large Audio Language Models. Current
literature focuses on constructing LALMs by integrating audio encoders with
text only Large Language Models through a projection module. While Large Audio
Language Models excel in general audio understanding, they are limited in
temporal reasoning which may hinder their commercial applications and on device
deployment. This paper addresses these challenges and limitations in audio
temporal reasoning. First, we introduce a data augmentation technique for
generating reliable audio temporal questions and answers using an LLM. Second,
we propose a continued finetuning curriculum learning strategy to specialize in
temporal reasoning without compromising performance on finetuned tasks.
Finally, we develop a reliable and transparent automated metric, assisted by an
LLM, to measure the correlation between Large Audio Language Model responses
and ground truth data intelligently. We demonstrate the effectiveness of our
proposed techniques using SOTA LALMs on public audio benchmark datasets.

摘要：音訊問答任務包括音訊事件分類、音訊字幕和開放式推理。最近，由於大型音訊語言模型的出現，音訊問答引起了關注。目前的文獻著重於透過投影模組將音訊編碼器與純文字大型語言模型整合，來建構 LALM。雖然大型音訊語言模型在一般音訊理解方面表現出色，但它們在時間推理方面受到限制，這可能會阻礙其商業應用和裝置部署。本文探討了音訊時間推理中的這些挑戰和限制。首先，我們引入一種資料擴充技術，使用 LLM 來產生可靠的音訊時間問題和答案。其次，我們提出一個持續微調課程學習策略，專精於時間推理，同時不影響微調任務的效能。最後，我們開發了一個可靠且透明的自動化指標，由 LLM 協助，以智慧的方式衡量大型音訊語言模型回應與地面實況資料之間的關聯性。我們使用公開音訊基準資料集上的 SOTA LALM，展示了我們所提出技術的有效性。

##### **Advancing Topic Segmentation of Broadcasted Speech with Multilingual Semantic Embeddings**
2409.06222v1 by Sakshi Deo Shukla, Pavel Denisov, Tugtekin Turan

Recent advancements in speech-based topic segmentation have highlighted the
potential of pretrained speech encoders to capture semantic representations
directly from speech. Traditionally, topic segmentation has relied on a
pipeline approach in which transcripts of the automatic speech recognition
systems are generated, followed by text-based segmentation algorithms. In this
paper, we introduce an end-to-end scheme that bypasses this conventional
two-step process by directly employing semantic speech encoders for
segmentation. Focused on the broadcasted news domain, which poses unique
challenges due to the diversity of speakers and topics within single
recordings, we address the challenge of accessing topic change points
efficiently in an end-to-end manner. Furthermore, we propose a new benchmark
for spoken news topic segmentation by utilizing a dataset featuring
approximately 1000 hours of publicly available recordings across six European
languages and including an evaluation set in Hindi to test the model's
cross-domain performance in a cross-lingual, zero-shot scenario. This setup
reflects real-world diversity and the need for models adapting to various
linguistic settings. Our results demonstrate that while the traditional
pipeline approach achieves a state-of-the-art $P_k$ score of 0.2431 for
English, our end-to-end model delivers a competitive $P_k$ score of 0.2564.
When trained multilingually, these scores further improve to 0.1988 and 0.2370,
respectively. To support further research, we release our model along with data
preparation scripts, facilitating open research on multilingual spoken news
topic segmentation.

摘要：<paragraph>最近在基於語音的主題區段化方面的新進展突顯了預先訓練的語音編碼器在直接從語音擷取語義表示方面的潛力。傳統上，主題區段化依賴於管線方法，其中會產生自動語音識別系統的轉錄，然後再進行基於文字的區段化演算法。在本文中，我們介紹了一個端到端的架構，它透過直接採用語義語音編碼器進行區段化，來繞過這個傳統的兩步驟流程。專注於廣播新聞領域，由於單一錄音中講者和主題的多樣性，因此構成了獨特的挑戰，我們以端到端的方式解決了有效存取主題變更點的挑戰。此外，我們透過利用一個包含六種歐洲語言約 1000 小時的公開錄音的資料集，並在印地語中加入一個評估集，來測試模型在跨語言、零次學習場景中的跨網域效能，進而提出一個新的基準，用於口說新聞主題區段化。此設定反映了真實世界的多樣性，以及模型適應各種語言設定的需求。我們的結果顯示，雖然傳統的管線方法達到了 0.2431 的最先進 $P_k$ 分數，但我們的端到端模型提供了 0.2564 的競爭性 $P_k$ 分數。當以多語言方式訓練時，這些分數進一步提高到 0.1988 和 0.2370。為了支持進一步的研究，我們發布了我們的模型以及資料準備腳本，促進了多語言口說新聞主題區段化的公開研究。</paragraph>

##### **CerviXpert: A Multi-Structural Convolutional Neural Network for Predicting Cervix Type and Cervical Cell Abnormalities**
2409.06220v1 by Rashik Shahriar Akash, Radiful Islam, S. M. Saiful Islam Badhon, K. S. M. Tozammel Hossain

Cervical cancer affects millions of women worldwide and has a significantly
higher survival rate when diagnosed early. Pap smears and cervical biopsies are
vital screening tools for detecting such cancer. However, the success of these
screening processes depends on the skills of cytologists. A recent trend in
diagnostic cytology is to apply machine-learning-based models to classify
cancer using cell images. These automated models have been shown to perform
just as well as, or even better than, expert cytologists. Some notable methods
for classifying cervix cancers include ResNet50, VGG16, MobileNetV2, and
InceptionV3, based on deep convolutional neural networks (CNN). However, these
methods are computationally expensive. We present CerviXpert, a
multi-structural Convolutional Neural Network, to identify cervix cancer. We
perform extensive experiments on a publicly available dataset, SiPaKMeD, to
show the efficacy of our method. CerviXpert presents a promising solution for
efficient cervical cancer screening and diagnosis by striking a balance between
accuracy and practical feasibility.

摘要：子宮頸癌影響全球數百萬名女性，且在早期診斷時存活率顯著提高。子宮頸抹片檢查和子宮頸切片檢查是偵測此類癌症的重要篩檢工具。然而，這些篩檢過程的成功與否取決於細胞學家的技能。診斷細胞學的最新趨勢是應用基於機器學習的模型，以使用細胞影像對癌症進行分類。這些自動化模型已被證明執行得與專家細胞學家一樣好，甚至更好。一些用於分類子宮頸癌的著名方法包括 ResNet50、VGG16、MobileNetV2 和 InceptionV3，這些方法基於深度卷積神經網路 (CNN)。然而，這些方法在計算上很昂貴。我們提出 CerviXpert，一種多結構卷積神經網路，用於識別子宮頸癌。我們對一個公開可用的資料集 SiPaKMeD 進行廣泛的實驗，以證明我們方法的有效性。CerviXpert 為有效的子宮頸癌篩檢和診斷提供了一個有前途的解決方案，它在準確性和實用可行性之間取得了平衡。

##### **SubRegWeigh: Effective and Efficient Annotation Weighing with Subword Regularization**
2409.06216v1 by Kohei Tsuji, Tatsuya Hiraoka, Yuchang Cheng, Tomoya Iwakura

Many datasets of natural language processing (NLP) sometimes include
annotation errors. Researchers have attempted to develop methods to reduce the
adverse effect of errors in datasets automatically. However, an existing method
is time-consuming because it requires many trained models to detect errors. We
propose a novel method to reduce the time of error detection. Specifically, we
use a tokenization technique called subword regularization to create
pseudo-multiple models which are used to detect errors. Our proposed method,
SubRegWeigh, can perform annotation weighting four to five times faster than
the existing method. Additionally, SubRegWeigh improved performance in both
document classification and named entity recognition tasks. In experiments with
pseudo-incorrect labels, pseudo-incorrect labels were adequately detected.

摘要：許多自然語言處理 (NLP) 的資料集有時會包含註解錯誤。研究人員已嘗試開發方法，以自動減少資料集中錯誤的不利影響。然而，現有方法很耗時，因為它需要許多訓練過的模型來偵測錯誤。我們提出了一種新方法來減少錯誤偵測的時間。具體來說，我們使用一種稱為次字正規化的標記化技術來建立用於偵測錯誤的偽多重模型。我們提出的方法 SubRegWeigh 可以比現有方法快四到五倍地執行註解加權。此外，SubRegWeigh 在文件分類和命名實體辨識任務中都改進了效能。在使用偽不正確標籤的實驗中，偽不正確標籤被充分地偵測出來。

##### **Towards Generalizable Scene Change Detection**
2409.06214v1 by Jaewoo Kim, Uehwan Kim

Scene Change Detection (SCD) is vital for applications such as visual
surveillance and mobile robotics. However, current SCD methods exhibit a bias
to the temporal order of training datasets and limited performance on unseen
domains; coventional SCD benchmarks are not able to evaluate generalization or
temporal consistency. To tackle these limitations, we introduce a Generalizable
Scene Change Detection Framework (GeSCF) in this work. The proposed GeSCF
leverages localized semantics of a foundation model without any re-training or
fine-tuning -- for generalization over unseen domains. Specifically, we design
an adaptive thresholding of the similarity distribution derived from facets of
the pre-trained foundation model to generate initial pseudo-change mask. We
further utilize Segment Anything Model's (SAM) class-agnostic masks to refine
pseudo-masks. Moreover, our proposed framework maintains commutative operations
in all settings to ensure complete temporal consistency. Finally, we define new
metrics, evaluation dataset, and evaluation protocol for Generalizable Scene
Change Detection (GeSCD). Extensive experiments demonstrate that GeSCF excels
across diverse and challenging environments -- establishing a new benchmark for
SCD performance.

摘要：場景變更偵測 (SCD) 對於視覺監控和行動機器人等應用至關重要。然而，目前的 SCD 方法對訓練資料集的時間順序有偏見，且在未見過的領域中效能有限；傳統的 SCD 評量基準無法評估概化或時間一致性。為了克服這些限制，我們在這項工作中引入了可概化的場景變更偵測架構 (GeSCF)。所提出的 GeSCF 利用基礎模型的局部語意，而無需任何重新訓練或微調，以概化到未見過的領域。具體來說，我們設計了一個自適應閾值，用於從預先訓練好的基礎模型的各個方面衍生的相似性分佈，以產生初始的偽變更遮罩。我們進一步利用 Segment Anything Model (SAM) 的類別不可知遮罩來精緻化偽遮罩。此外，我們提出的架構在所有設定中都維持交換運算，以確保完全的時間一致性。最後，我們定義了新的指標、評量資料集和評量協定，用於可概化的場景變更偵測 (GeSCD)。廣泛的實驗證明，GeSCF 在多樣化且具挑戰性的環境中表現出色，為 SCD 效能建立了一個新的基準。

##### **STUN: Structured-Then-Unstructured Pruning for Scalable MoE Pruning**
2409.06211v1 by Jaeseong Lee, seung-won hwang, Aurick Qiao, Daniel F Campos, Zhewei Yao, Yuxiong He

Mixture-of-experts (MoEs) have been adopted for reducing inference costs by
sparsely activating experts in Large language models (LLMs). Despite this
reduction, the massive number of experts in MoEs still makes them expensive to
serve. In this paper, we study how to address this, by pruning MoEs. Among
pruning methodologies, unstructured pruning has been known to achieve the
highest performance for a given pruning ratio, compared to structured pruning,
since the latter imposes constraints on the sparsification structure. This is
intuitive, as the solution space of unstructured pruning subsumes that of
structured pruning. However, our counterintuitive finding reveals that expert
pruning, a form of structured pruning, can actually precede unstructured
pruning to outperform unstructured-only pruning. As existing expert pruning,
requiring $O(\frac{k^n}{\sqrt{n}})$ forward passes for $n$ experts, cannot
scale for recent MoEs, we propose a scalable alternative with $O(1)$
complexity, yet outperforming the more expensive methods. The key idea is
leveraging a latent structure between experts, based on behavior similarity,
such that the greedy decision of whether to prune closely captures the joint
pruning effect. Ours is highly effective -- for Snowflake Arctic, a 480B-sized
MoE with 128 experts, our method needs only one H100 and two hours to achieve
nearly no loss in performance with 40% sparsity, even in generative tasks such
as GSM8K, where state-of-the-art unstructured pruning fails to. The code will
be made publicly available.

摘要：<paragraph>混合专家 (MoE) 已被采用以通过稀疏激活大型语言模型 (LLM) 中的专家来降低推理成本。尽管有此降低，但 MoE 中大量的专家仍然使其服务成本高昂。在本文中，我们研究了如何通过修剪 MoE 来解决这个问题。在修剪方法中，与结构化修剪相比，非结构化修剪已知可以针对给定的修剪比率实现最高性能，因为后者对稀疏化结构施加了约束。这是直观的，因为非结构化修剪的解空间包含了结构化修剪的解空间。然而，我们的反直觉发现表明，专家修剪（一种结构化修剪形式）实际上可以先于非结构化修剪，以优于仅非结构化修剪的性能。由于现有的专家修剪需要针对 n 个专家进行 O($\frac{k^n}{\sqrt{n}}$) 前向传递，因此无法扩展到最近的 MoE，我们提出了一种具有 O(1) 复杂度且优于更昂贵方法的可扩展替代方案。关键思想是利用专家之间的潜在结构（基于行为相似性），以便贪婪地决定是否修剪可以紧密捕捉联合修剪效果。我们的方法非常有效——对于 Snowflake Arctic（一个具有 128 个专家的 480B 大小的 MoE），我们的方法只需要一个 H100 和两个小时即可在生成性任务（例如 GSM8K）中实现几乎没有性能损失且具有 40% 的稀疏性，而最先进的非结构化修剪无法做到这一点。代码将公开提供。</paragraph>

##### **Adaptive Transformer Modelling of Density Function for Nonparametric Survival Analysis**
2409.06209v1 by Xin Zhang, Deval Mehta, Yanan Hu, Chao Zhu, David Darby, Zhen Yu, Daniel Merlo, Melissa Gresle, Anneke Van Der Walt, Helmut Butzkueven, Zongyuan Ge

Survival analysis holds a crucial role across diverse disciplines, such as
economics, engineering and healthcare. It empowers researchers to analyze both
time-invariant and time-varying data, encompassing phenomena like customer
churn, material degradation and various medical outcomes. Given the complexity
and heterogeneity of such data, recent endeavors have demonstrated successful
integration of deep learning methodologies to address limitations in
conventional statistical approaches. However, current methods typically involve
cluttered probability distribution function (PDF), have lower sensitivity in
censoring prediction, only model static datasets, or only rely on recurrent
neural networks for dynamic modelling. In this paper, we propose a novel
survival regression method capable of producing high-quality unimodal PDFs
without any prior distribution assumption, by optimizing novel
Margin-Mean-Variance loss and leveraging the flexibility of Transformer to
handle both temporal and non-temporal data, coined UniSurv. Extensive
experiments on several datasets demonstrate that UniSurv places a significantly
higher emphasis on censoring compared to other methods.

摘要：存活分析在經濟、工程和醫療保健等不同學科中扮演著至關重要的角色。它讓研究人員能夠分析時不變和時變數據，包含客戶流失、材料降解和各種醫療結果等現象。鑑於此類數據的複雜性和異質性，最近的努力已證明成功整合深度學習方法以解決傳統統計方法的限制。然而，目前的方法通常涉及雜亂的機率分佈函數 (PDF)，在審查預測中具有較低的敏感性，僅對靜態數據集進行建模，或僅依賴遞迴神經網路進行動態建模。在本文中，我們提出了一種新穎的存活迴歸方法，能夠在沒有任何先驗分佈假設的情況下產生高品質的單峰 PDF，藉由最佳化新穎的邊際平均值變異損失，並利用 Transformer 的靈活性來處理時間和非時間數據，稱為 UniSurv。在幾個數據集上的廣泛實驗證明，與其他方法相比，UniSurv 對審查的重視程度顯著提高。

##### **SHAPE-IT: Exploring Text-to-Shape-Display for Generative Shape-Changing Behaviors with LLMs**
2409.06205v1 by Wanli Qian, Chenfeng Gao, Anup Sathya, Ryo Suzuki, Ken Nakagaki

This paper introduces text-to-shape-display, a novel approach to generating
dynamic shape changes in pin-based shape displays through natural language
commands. By leveraging large language models (LLMs) and AI-chaining, our
approach allows users to author shape-changing behaviors on demand through text
prompts without programming. We describe the foundational aspects necessary for
such a system, including the identification of key generative elements
(primitive, animation, and interaction) and design requirements to enhance user
interaction, based on formative exploration and iterative design processes.
Based on these insights, we develop SHAPE-IT, an LLM-based authoring tool for a
24 x 24 shape display, which translates the user's textual command into
executable code and allows for quick exploration through a web-based control
interface. We evaluate the effectiveness of SHAPE-IT in two ways: 1)
performance evaluation and 2) user evaluation (N= 10). The study conclusions
highlight the ability to facilitate rapid ideation of a wide range of
shape-changing behaviors with AI. However, the findings also expose
accuracy-related challenges and limitations, prompting further exploration into
refining the framework for leveraging AI to better suit the unique requirements
of shape-changing systems.

摘要：本文介紹文字轉形狀顯示，這是一種透過自然語言指令在基於釘狀的形狀顯示器上產生動態形狀變化的創新方法。透過利用大型語言模型 (LLM) 和 AI 鏈結，我們的做法讓使用者能夠透過文字提示按需撰寫形狀變換行為，而無需編寫程式。我們描述了這種系統所需的基礎面向，包括識別關鍵的生成元素（基本、動畫和互動）以及基於形成探索和反覆設計流程來增強使用者互動的設計需求。根據這些見解，我們開發了 SHAPE-IT，這是一種針對 24 x 24 形狀顯示器所設計、基於 LLM 的創作工具，它會將使用者的文字指令轉換為可執行的程式碼，並允許透過基於網路的控制介面進行快速探索。我們以兩種方式評估 SHAPE-IT 的有效性：1）效能評估和 2）使用者評估（N= 10）。研究結論強調了透過 AI 促進各種形狀變換行為快速發想的可能性。然而，研究結果也揭露了與準確性相關的挑戰和限制，促使進一步探索精進架構以更好地滿足形狀變換系統的獨特需求。

##### **NOVI : Chatbot System for University Novice with BERT and LLMs**
2409.06192v1 by Yoonji Nam, TaeWoong Seo, Gyeongcheol Shin, Sangji Lee, JaeEun Im

To mitigate the difficulties of university freshmen in adapting to university
life, we developed NOVI, a chatbot system based on GPT-4o. This system utilizes
post and comment data from SKKU 'Everytime', a university community site.
Developed using LangChain, NOVI's performance has been evaluated with a BLEU
score, Perplexity score, ROUGE-1 score, ROUGE-2 score, ROUGE-L score and METEOR
score. This approach is not only limited to help university freshmen but is
also expected to help various people adapting to new environments with
different data. This research explores the development and potential
application of new educational technology tools, contributing to easier social
adaptation for beginners and settling a foundation for future advancement in
LLM studies.

摘要：為了減輕大學新鮮人適應大學生活的困難，我們開發了基於 GPT-4o 的聊天機器人系統 NOVI。此系統利用了 SKKU「Everytime」大學社群網站的貼文和留言資料。NOVI 是使用 LangChain 開發的，其效能已使用 BLEU 分數、困惑度分數、ROUGE-1 分數、ROUGE-2 分數、ROUGE-L 分數和 METEOR 分數進行評估。此方法不僅限於幫助大學新鮮人，也預期可以協助各種人適應新環境，並使用不同的資料。本研究探討了新教育科技工具的開發和潛在應用，有助於初學者更輕鬆地適應社會，並為 LLM 研究的未來進展奠定基礎。

##### **Can Large Language Models Unlock Novel Scientific Research Ideas?**
2409.06185v1 by Sandeep Kumar, Tirthankar Ghosal, Vinayak Goyal, Asif Ekbal

"An idea is nothing more nor less than a new combination of old elements"
(Young, J.W.). The widespread adoption of Large Language Models (LLMs) and
publicly available ChatGPT have marked a significant turning point in the
integration of Artificial Intelligence (AI) into people's everyday lives. This
study explores the capability of LLMs in generating novel research ideas based
on information from research papers. We conduct a thorough examination of 4
LLMs in five domains (e.g., Chemistry, Computer, Economics, Medical, and
Physics). We found that the future research ideas generated by Claude-2 and
GPT-4 are more aligned with the author's perspective than GPT-3.5 and Gemini.
We also found that Claude-2 generates more diverse future research ideas than
GPT-4, GPT-3.5, and Gemini 1.0. We further performed a human evaluation of the
novelty, relevancy, and feasibility of the generated future research ideas.
This investigation offers insights into the evolving role of LLMs in idea
generation, highlighting both its capability and limitations. Our work
contributes to the ongoing efforts in evaluating and utilizing language models
for generating future research ideas. We make our datasets and codes publicly
available.

摘要：「一個想法不過就是舊元素的新組合而已」
(Young, J.W.)。大型語言模型 (LLM) 和公開的 ChatGPT 廣泛採用，標誌著人工智能 (AI) 整合到人們日常生活中的重要轉折點。本研究探討了 LLM 在根據研究論文資訊產生新研究想法方面的能力。我們對五個領域（例如化學、電腦、經濟、醫學和物理）中的 4 個 LLM 進行了徹底檢查。我們發現 Claude-2 和 GPT-4 產生的未來研究想法比 GPT-3.5 和 Gemini 更符合作者的觀點。我們還發現，Claude-2 產生的未來研究想法比 GPT-4、GPT-3.5 和 Gemini 1.0 更為多樣化。我們進一步對產生的未來研究想法的新穎性、相關性和可行性進行了人工評估。本調查提供了對 LLM 在產生想法中不斷演變的角色的見解，突出了其能力和限制。我們的研究有助於評估和利用語言模型來產生未來研究想法的持續努力。我們公開提供我們的數據集和程式碼。

##### **SQLucid: Grounding Natural Language Database Queries with Interactive Explanations**
2409.06178v1 by Yuan Tian, Jonathan K. Kummerfeld, Toby Jia-Jun Li, Tianyi Zhang

Though recent advances in machine learning have led to significant
improvements in natural language interfaces for databases, the accuracy and
reliability of these systems remain limited, especially in high-stakes domains.
This paper introduces SQLucid, a novel user interface that bridges the gap
between non-expert users and complex database querying processes. SQLucid
addresses existing limitations by integrating visual correspondence,
intermediate query results, and editable step-by-step SQL explanations in
natural language to facilitate user understanding and engagement. This unique
blend of features empowers users to understand and refine SQL queries easily
and precisely. Two user studies and one quantitative experiment were conducted
to validate SQLucid's effectiveness, showing significant improvement in task
completion accuracy and user confidence compared to existing interfaces. Our
code is available at https://github.com/magic-YuanTian/SQLucid.

摘要：儘管機器學習的最新進展已大幅提升資料庫的自然語言介面，但這些系統的準確性和可靠性仍然有限，尤其是在高風險領域。本文介紹 SQLucid，這是一種新穎的使用者介面，用以彌補非專家使用者與複雜資料庫查詢流程之間的差距。SQLucid 整合視覺對應、中間查詢結果，以及以自然語言編寫的可編輯分步式 SQL 說明，來解決現有限制，以促進使用者理解和參與。這種獨特的功能組合讓使用者能夠輕鬆且精確地理解和修改 SQL 查詢。進行了兩項使用者研究和一項量化實驗，以驗證 SQLucid 的有效性，結果顯示與現有介面相比，任務完成準確度和使用者信心都有顯著提升。我們的程式碼可在 https://github.com/magic-YuanTian/SQLucid 取得。

##### **Larger Language Models Don't Care How You Think: Why Chain-of-Thought Prompting Fails in Subjective Tasks**
2409.06173v1 by Georgios Chochlakis, Niyantha Maruthu Pandiyan, Kristina Lerman, Shrikanth Narayanan

In-Context Learning (ICL) in Large Language Models (LLM) has emerged as the
dominant technique for performing natural language tasks, as it does not
require updating the model parameters with gradient-based methods. ICL promises
to "adapt" the LLM to perform the present task at a competitive or
state-of-the-art level at a fraction of the computational cost. ICL can be
augmented by incorporating the reasoning process to arrive at the final label
explicitly in the prompt, a technique called Chain-of-Thought (CoT) prompting.
However, recent work has found that ICL relies mostly on the retrieval of task
priors and less so on "learning" to perform tasks, especially for complex
subjective domains like emotion and morality, where priors ossify posterior
predictions. In this work, we examine whether "enabling" reasoning also creates
the same behavior in LLMs, wherein the format of CoT retrieves reasoning priors
that remain relatively unchanged despite the evidence in the prompt. We find
that, surprisingly, CoT indeed suffers from the same posterior collapse as ICL
for larger language models. Code is avalaible at
https://github.com/gchochla/cot-priors.

摘要：大型語言模型 (LLM) 中的語境學習 (ICL) 已成為執行自然語言任務的主流技術，因為它不需要使用基於梯度的模型參數來更新。ICL 承諾以極低的計算成本「調整」LLM，以在競爭或最先進的層級執行當前任務。ICL 可以透過在提示中明確地納入推理過程來擴充，以得出最終標籤，這項技術稱為思考鏈 (CoT) 提示。然而，最近的研究發現，ICL 主要依賴於任務先驗的檢索，較少依賴於「學習」執行任務，特別是對於情緒和道德等複雜的主觀領域，其中先驗會僵化後驗預測。在這項研究中，我們探討「啟用」推理是否也會在 LLM 中產生相同的行為，其中 CoT 的格式會檢索推理先驗，儘管提示中的證據不同，但這些先驗仍然相對不變。我們發現，令人驚訝的是，對於較大的語言模型，CoT 確實會與 ICL 發生相同的後驗崩潰。程式碼可於 https://github.com/gchochla/cot-priors 取得。

##### **Deep Learning and Large Language Models for Audio and Text Analysis in Predicting Suicidal Acts in Chinese Psychological Support Hotlines**
2409.06164v1 by Yining Chen, Jianqiang Li, Changwei Song, Qing Zhao, Yongsheng Tong, Guanghui Fu

Suicide is a pressing global issue, demanding urgent and effective preventive
interventions. Among the various strategies in place, psychological support
hotlines had proved as a potent intervention method. Approximately two million
people in China attempt suicide annually, with many individuals making multiple
attempts. Prompt identification and intervention for high-risk individuals are
crucial to preventing tragedies. With the rapid advancement of artificial
intelligence (AI), especially the development of large-scale language models
(LLMs), new technological tools have been introduced to the field of mental
health. This study included 1284 subjects, and was designed to validate whether
deep learning models and LLMs, using audio and transcribed text from support
hotlines, can effectively predict suicide risk. We proposed a simple LLM-based
pipeline that first summarizes transcribed text from approximately one hour of
speech to extract key features, and then predict suicidial bahaviours in the
future. We compared our LLM-based method with the traditional manual scale
approach in a clinical setting and with five advanced deep learning models.
Surprisingly, the proposed simple LLM pipeline achieved strong performance on a
test set of 46 subjects, with an F1 score of 76\% when combined with manual
scale rating. This is 7\% higher than the best speech-based deep learning
models and represents a 27.82\% point improvement in F1 score compared to using
the manual scale apporach alone. Our study explores new applications of LLMs
and demonstrates their potential for future use in suicide prevention efforts.

摘要：自殺是一個迫切的全球問題，需要緊急且有效的預防性干預措施。在現有各種策略中，心理支持熱線已被證明是一種有效的干預方法。中國每年約有 200 萬人企圖自殺，其中許多人多次企圖。及時識別和干預高風險個體對於預防悲劇至關重要。隨著人工智能 (AI) 的快速發展，特別是大規模語言模型 (LLM) 的發展，新的技術工具已被引入心理健康領域。本研究納入了 1284 名受試者，旨在驗證使用來自支持熱線的音訊和轉錄文字的深度學習模型和 LLM 是否可以有效預測自殺風險。我們提出了一個基於 LLM 的簡單管道，它首先總結大約一小時語音的轉錄文字以提取關鍵特徵，然後預測未來的自殺行為。我們在臨床環境中將基於 LLM 的方法與傳統的手動量表方法以及五種先進的深度學習模型進行了比較。令人驚訝的是，所提出的簡單 LLM 管道在 46 名受試者的測試集中取得了強勁的表現，與手動量表評分相結合時的 F1 分數為 76%。這比最好的基於語音的深度學習模型高出 7%，並且與僅使用手動量表方法相比，F1 分數提高了 27.82%。我們的研究探索了 LLM 的新應用，並展示了它們在未來自殺預防工作中的潛力。

##### **Multiclass Arrhythmia Classification using Smartwatch Photoplethysmography Signals Collected in Real-life Settings**
2409.06147v1 by Dong Han, Jihye Moon, Luís Roberto Mercado Díaz, Darren Chen, Devan Williams, Eric Y. Ding, Khanh-Van Tran, David D. McManus, Ki H. Chon

Most deep learning models of multiclass arrhythmia classification are tested
on fingertip photoplethysmographic (PPG) data, which has higher signal-to-noise
ratios compared to smartwatch-derived PPG, and the best reported sensitivity
value for premature atrial/ventricular contraction (PAC/PVC) detection is only
75%. To improve upon PAC/PVC detection sensitivity while maintaining high AF
detection, we use multi-modal data which incorporates 1D PPG, accelerometers,
and heart rate data as the inputs to a computationally efficient 1D
bi-directional Gated Recurrent Unit (1D-Bi-GRU) model to detect three
arrhythmia classes. We used motion-artifact prone smartwatch PPG data from the
NIH-funded Pulsewatch clinical trial. Our multimodal model tested on 72
subjects achieved an unprecedented 83% sensitivity for PAC/PVC detection while
maintaining a high accuracy of 97.31% for AF detection. These results
outperformed the best state-of-the-art model by 20.81% for PAC/PVC and 2.55%
for AF detection even while our model was computationally more efficient (14
times lighter and 2.7 faster).

摘要：大多數多類心律不整分類的深度學習模型都是在指尖光電容積描記法 (PPG) 資料上進行測試，與智慧手錶衍生的 PPG 相比，其訊號雜訊比更高，而對於期前心房/心室收縮 (PAC/PVC) 偵測所報告的最佳敏感度值僅為 75%。為了在維持高房顫偵測的同時提高 PAC/PVC 偵測敏感度，我們使用多模式資料，將 1D PPG、加速度計和心率資料作為計算效率高的 1D 雙向閘控遞迴單元 (1D-Bi-GRU) 模型的輸入，以偵測三類心律不整。我們使用了美國國家衛生研究院資助的 Pulsewatch 臨床試驗中的運動偽影易感智慧手錶 PPG 資料。我們在 72 名受試者身上測試的多模式模型，對於 PAC/PVC 偵測達到了前所未有的 83% 敏感度，同時對於房顫偵測維持了 97.31% 的高準確度。即使我們的模型在計算上更有效率（輕 14 倍，快 2.7 倍），這些結果仍比最先進的模型在 PAC/PVC 偵測上高出 20.81%，在房顫偵測上高出 2.55%。

##### **Draw an Audio: Leveraging Multi-Instruction for Video-to-Audio Synthesis**
2409.06135v1 by Qi Yang, Binjie Mao, Zili Wang, Xing Nie, Pengfei Gao, Ying Guo, Cheng Zhen, Pengfei Yan, Shiming Xiang

Foley is a term commonly used in filmmaking, referring to the addition of
daily sound effects to silent films or videos to enhance the auditory
experience. Video-to-Audio (V2A), as a particular type of automatic foley task,
presents inherent challenges related to audio-visual synchronization. These
challenges encompass maintaining the content consistency between the input
video and the generated audio, as well as the alignment of temporal and
loudness properties within the video. To address these issues, we construct a
controllable video-to-audio synthesis model, termed Draw an Audio, which
supports multiple input instructions through drawn masks and loudness signals.
To ensure content consistency between the synthesized audio and target video,
we introduce the Mask-Attention Module (MAM), which employs masked video
instruction to enable the model to focus on regions of interest. Additionally,
we implement the Time-Loudness Module (TLM), which uses an auxiliary loudness
signal to ensure the synthesis of sound that aligns with the video in both
loudness and temporal dimensions. Furthermore, we have extended a large-scale
V2A dataset, named VGGSound-Caption, by annotating caption prompts. Extensive
experiments on challenging benchmarks across two large-scale V2A datasets
verify Draw an Audio achieves the state-of-the-art. Project page:
https://yannqi.github.io/Draw-an-Audio/.

摘要：福利是電影製作中常用的術語，指的是在默片或影片中加入日常音效，以增強聽覺體驗。影片轉音訊 (V2A) 是一種特殊的自動福利任務，在音訊視覺同步方面存在固有的挑戰。這些挑戰包括在輸入影片和產生的音訊之間維持內容一致性，以及影片中時間和響度的屬性對齊。為了解決這些問題，我們構建了一個可控的影片轉音訊合成模型，稱為繪製音訊，它支援透過繪製遮罩和響度訊號提供多重輸入指令。為了確保合成音訊和目標影片之間的內容一致性，我們引入了遮罩注意模組 (MAM)，它採用遮罩影片指令，讓模型能夠專注於感興趣的區域。此外，我們實作了時間響度模組 (TLM)，它使用輔助響度訊號來確保合成音訊在響度和時間維度上與影片對齊。此外，我們透過註解字幕提示，擴充了一個名為 VGGSound-Caption 的大型 V2A 資料集。在兩個大型 V2A 資料集中的具有挑戰性的基準上進行的廣泛實驗驗證，繪製音訊達到了最先進的技術水準。專案頁面：https://yannqi.github.io/Draw-an-Audio/。

##### **Accelerating Large Language Model Pretraining via LFR Pedagogy: Learn, Focus, and Review**
2409.06131v1 by Neha Prakriya, Jui-Nan Yen, Cho-Jui Hsieh, Jason Cong

Large Language Model (LLM) pretraining traditionally relies on autoregressive
language modeling on randomly sampled data blocks from web-scale datasets. We
take inspiration from human learning techniques like spaced repetition to
hypothesize that random data sampling for LLMs leads to high training cost and
low quality models which tend to forget data. In order to effectively commit
web-scale information to long-term memory, we propose the LFR (Learn, Focus,
and Review) pedagogy, a new dynamic training paradigm which focuses and
repeatedly reviews complex data blocks at systematic intervals based on the
model's learning pace and progress. LFR records the model perplexities for
different data blocks and frequently revisits blocks with higher perplexity
which are more likely to be forgotten. We pretrain the GPT-2 models (124M -
1.5B) from scratch on the OpenWebText dataset using LFR. We test on downstream
tasks from the language modeling, question answering, translation, and problem
solving domains to achieve consistently lower perplexity and higher accuracy
than the baseline OpenAI models, while obtaining a 20x pretraining speed-up.

摘要：大型語言模型 (LLM) 預訓練傳統上依賴於隨機取樣資料區塊的自動迴歸語言模型化，這些資料區塊來自網路規模的資料集。我們從人類學習技巧（例如間隔重複）中獲得靈感，假設 LLM 的隨機資料取樣會導致高訓練成本和低品質模型，而這些模型往往會遺忘資料。為了有效地將網路規模的資訊提交至長期記憶體，我們提出 LFR（學習、專注和複習）教學法，這是一種新的動態訓練範例，會根據模型的學習步調和進度，在系統性的間隔中專注於複雜的資料區塊並反覆複習。LFR 會記錄模型對於不同資料區塊的困惑度，並頻繁地重新檢視困惑度較高的區塊，因為這些區塊較容易被遺忘。我們從頭開始使用 LFR 在 OpenWebText 資料集上預訓練 GPT-2 模型（124M - 1.5B）。我們在語言模型化、問題解答、翻譯和問題解決領域的下游任務上進行測試，與基準 OpenAI 模型相比，我們始終獲得較低的困惑度和較高的準確度，同時獲得 20 倍的預訓練加速。

##### **On the Weaknesses of Backdoor-based Model Watermarking: An Information-theoretic Perspective**
2409.06130v1 by Aoting Hu, Yanzhi Chen, Renjie Xie, Adrian Weller

Safeguarding the intellectual property of machine learning models has emerged
as a pressing concern in AI security. Model watermarking is a powerful
technique for protecting ownership of machine learning models, yet its
reliability has been recently challenged by recent watermark removal attacks.
In this work, we investigate why existing watermark embedding techniques
particularly those based on backdooring are vulnerable. Through an
information-theoretic analysis, we show that the resilience of watermarking
against erasure attacks hinges on the choice of trigger-set samples, where
current uses of out-distribution trigger-set are inherently vulnerable to
white-box adversaries. Based on this discovery, we propose a novel model
watermarking scheme, In-distribution Watermark Embedding (IWE), to overcome the
limitations of existing method. To further minimise the gap to clean models, we
analyze the role of logits as watermark information carriers and propose a new
approach to better conceal watermark information within the logits. Experiments
on real-world datasets including CIFAR-100 and Caltech-101 demonstrate that our
method robustly defends against various adversaries with negligible accuracy
loss (< 0.1%).

摘要：機器學習模型的智慧財產權保障已成為 AI 安全中迫切的關注事項。模型浮水印是一種強大的技術，用於保護機器學習模型的所有權，但最近的浮水印移除攻擊對其可靠性提出了挑戰。在這項工作中，我們探討了現有的浮水印嵌入技術，特別是那些基於後門的技術，為何容易受到攻擊。透過資訊理論分析，我們表明浮水印對擦除攻擊的復原力取決於觸發器組範例的選擇，其中目前對分布外觸發器組的使用本質上容易受到白盒對手的攻擊。基於這一發現，我們提出了一種新穎的模型浮水印方案，即分佈內浮水印嵌入 (IWE)，以克服現有方法的限制。為了進一步縮小與乾淨模型的差距，我們分析了邏輯作為浮水印資訊載體的作用，並提出了一種新的方法，以便在邏輯中更好地隱藏浮水印資訊。在包括 CIFAR-100 和 Caltech-101 在內的真實世界資料集上的實驗表明，我們的模型可以穩健地抵禦各種對手，而準確度損失可以忽略不計 (< 0.1%)。

##### **Case Study: Leveraging GenAI to Build AI-based Surrogates and Regressors for Modeling Radio Frequency Heating in Fusion Energy Science**
2409.06122v1 by E. Wes Bethel, Vianna Cramer, Alexander del Rio, Lothar Narins, Chris Pestano, Satvik Verma, Erick Arias, Nicola Bertelli, Talita Perciano, Syun'ichi Shiraiwa, Álvaro Sánchez Villar, Greg Wallace, John C. Wright

This work presents a detailed case study on using Generative AI (GenAI) to
develop AI surrogates for simulation models in fusion energy research. The
scope includes the methodology, implementation, and results of using GenAI to
assist in model development and optimization, comparing these results with
previous manually developed models.

摘要：這項工作提供了一個詳細的案例研究，探討使用生成式 AI (GenAI) 來為融合能源研究中的模擬模型開發 AI 代理。範圍包括使用 GenAI 協助模型開發和最佳化的方法、實施和結果，並將這些結果與先前手動開發的模型進行比較。

##### **PaRCE: Probabilistic and Reconstruction-Based Competency Estimation for Safe Navigation Under Perception Uncertainty**
2409.06111v1 by Sara Pohland, Claire Tomlin

Perception-based navigation systems are useful for unmanned ground vehicle
(UGV) navigation in complex terrains, where traditional depth-based navigation
schemes are insufficient. However, these data-driven methods are highly
dependent on their training data and can fail in surprising and dramatic ways
with little warning. To ensure the safety of the vehicle and the surrounding
environment, it is imperative that the navigation system is able to recognize
the predictive uncertainty of the perception model and respond safely and
effectively in the face of uncertainty. In an effort to enable safe navigation
under perception uncertainty, we develop a probabilistic and
reconstruction-based competency estimation (PaRCE) method to estimate the
model's level of familiarity with an input image as a whole and with specific
regions in the image. We find that the overall competency score can correctly
predict correctly classified, misclassified, and out-of-distribution (OOD)
samples. We also confirm that the regional competency maps can accurately
distinguish between familiar and unfamiliar regions across images. We then use
this competency information to develop a planning and control scheme that
enables effective navigation while maintaining a low probability of error. We
find that the competency-aware scheme greatly reduces the number of collisions
with unfamiliar obstacles, compared to a baseline controller with no competency
awareness. Furthermore, the regional competency information is very valuable in
enabling efficient navigation.

摘要：基於感知的導航系統對於無人地面載具 (UGV) 在複雜地形中進行導航很有用，在這些地形中，傳統的基於深度的導航方案是不夠的。然而，這些資料驅動的方法高度依賴於其訓練資料，並且可能會以令人驚訝且戲劇性的方式在幾乎沒有警告的情況下失敗。為了確保車輛和周圍環境的安全，導航系統必須能夠識別感知模型的預測不確定性，並在不確定性面前做出安全有效的回應。為了在感知不確定性下實現安全導航，我們開發了一種基於概率和重建的勝任力估計 (PaRCE) 方法，以估計模型對輸入影像整體和影像中特定區域的熟悉程度。我們發現，整體勝任力評分可以正確預測正確分類、分類錯誤和分佈外 (OOD) 樣本。我們還確認，區域勝任力圖可以準確區分影像中的熟悉和不熟悉區域。然後，我們使用此勝任力資訊來開發一種規劃和控制方案，在保持低錯誤機率的同時，能夠有效導航。我們發現，與沒有勝任力感知的基準控制器相比，具備勝任力感知的方案大幅減少了與不熟悉障礙物的碰撞次數。此外，區域勝任力資訊對於實現有效導航非常有價值。

##### **Doppelgänger's Watch: A Split Objective Approach to Large Language Models**
2409.06107v1 by Shervin Ghasemlou, Ashish Katiyar, Aparajita Saraf, Seungwhan Moon, Mangesh Pujari, Pinar Donmez, Babak Damavandi, Anuj Kumar

In this paper, we investigate the problem of "generation supervision" in
large language models, and present a novel bicameral architecture to separate
supervision signals from their core capability, helpfulness. Doppelg\"anger, a
new module parallel to the underlying language model, supervises the generation
of each token, and learns to concurrently predict the supervision score(s) of
the sequences up to and including each token. In this work, we present the
theoretical findings, and leave the report on experimental results to a
forthcoming publication.

摘要：在本文中，我們探討大型語言模型中的「生成監督」問題，並提出了一種新穎的兩院制架構，以將監督訊號從其核心能力（樂於助人）中分離出來。Doppelgänger 是一個與底層語言模型並行的全新模組，用來監督每個符號的生成，並學習同時預測每個符號（包含符號在內）之前序列的監督分數。在這項工作中，我們提出了理論發現，並將實驗結果報告留待後續出版。

##### **ClarQ-LLM: A Benchmark for Models Clarifying and Requesting Information in Task-Oriented Dialog**
2409.06097v1 by Yujian Gan, Changling Li, Jinxia Xie, Luou Wen, Matthew Purver, Massimo Poesio

We introduce ClarQ-LLM, an evaluation framework consisting of bilingual
English-Chinese conversation tasks, conversational agents and evaluation
metrics, designed to serve as a strong benchmark for assessing agents' ability
to ask clarification questions in task-oriented dialogues. The benchmark
includes 31 different task types, each with 10 unique dialogue scenarios
between information seeker and provider agents. The scenarios require the
seeker to ask questions to resolve uncertainty and gather necessary information
to complete tasks. Unlike traditional benchmarks that evaluate agents based on
fixed dialogue content, ClarQ-LLM includes a provider conversational agent to
replicate the original human provider in the benchmark. This allows both
current and future seeker agents to test their ability to complete information
gathering tasks through dialogue by directly interacting with our provider
agent. In tests, LLAMA3.1 405B seeker agent managed a maximum success rate of
only 60.05\%, showing that ClarQ-LLM presents a strong challenge for future
research.

摘要：我們推出 ClarQ-LLM，這是一個評估框架，由雙語英語-中文對話任務、對話代理和評估指標組成，旨在作為評估代理在任務導向對話中提出澄清問題的能力的強大基準。該基準包含 31 種不同的任務類型，每個任務類型都包含信息尋求者和提供者代理之間的 10 個獨特對話場景。這些場景要求尋求者提出問題以解決不確定性並收集必要的資訊以完成任務。與根據固定對話內容評估代理的傳統基準不同，ClarQ-LLM 包含一個提供者對話代理，以複製基準中的原始人類提供者。這允許當前和未來的尋求者代理透過直接與我們的提供者代理互動來測試他們完成資訊收集任務的能力。在測試中，LLAMA3.1 405B 尋求者代理僅管理 60.05% 的最高成功率，這表明 ClarQ-LLM 對未來的研究提出了嚴峻的挑戰。

##### **Latent Diffusion Bridges for Unsupervised Musical Audio Timbre Transfer**
2409.06096v1 by Michele Mancusi, Yurii Halychansky, Kin Wai Cheuk, Chieh-Hsin Lai, Stefan Uhlich, Junghyun Koo, Marco A. Martínez-Ramírez, Wei-Hsiang Liao, Giorgio Fabbro, Yuhki Mitsufuji

Music timbre transfer is a challenging task that involves modifying the
timbral characteristics of an audio signal while preserving its melodic
structure. In this paper, we propose a novel method based on dual diffusion
bridges, trained using the CocoChorales Dataset, which consists of unpaired
monophonic single-instrument audio data. Each diffusion model is trained on a
specific instrument with a Gaussian prior. During inference, a model is
designated as the source model to map the input audio to its corresponding
Gaussian prior, and another model is designated as the target model to
reconstruct the target audio from this Gaussian prior, thereby facilitating
timbre transfer. We compare our approach against existing unsupervised timbre
transfer models such as VAEGAN and Gaussian Flow Bridges (GFB). Experimental
results demonstrate that our method achieves both better Fr\'echet Audio
Distance (FAD) and melody preservation, as reflected by lower pitch distances
(DPD) compared to VAEGAN and GFB. Additionally, we discover that the noise
level from the Gaussian prior, $\sigma$, can be adjusted to control the degree
of melody preservation and amount of timbre transferred.

摘要：音樂音色轉移是一項具有挑戰性的任務，它涉及修改音訊訊號的音色特徵，同時保留其旋律結構。在本文中，我們提出了一種基於雙擴散橋接的新方法，使用 CocoChorales 資料集進行訓練，該資料集包含未配對的單音單樂器音訊資料。每個擴散模型都使用具有高斯先驗的特定樂器進行訓練。在推理過程中，一個模型被指定為源模型，將輸入音訊對應到其對應的高斯先驗，另一個模型被指定為目標模型，從這個高斯先驗重建目標音訊，從而促進音色轉移。我們將我們的模型與現有的無監督音色轉移模型（例如 VAEGAN 和高斯流橋接 (GFB)）進行比較。實驗結果表明，與 VAEGAN 和 GFB 相比，我們的模型在 Fr\'echet 音訊距離 (FAD) 和旋律保留方面都取得了更好的效果，這反映在較低的音高距離 (DPD) 上。此外，我們發現來自高斯先驗的噪聲級別 $\sigma$ 可以調整，以控制旋律保留的程度和轉移的音色數量。

##### **Scalable Multitask Learning Using Gradient-based Estimation of Task Affinity**
2409.06091v1 by Dongyue Li, Aneesh Sharma, Hongyang R. Zhang

Multitask learning is a widely used paradigm for training models on diverse
tasks, with applications ranging from graph neural networks to language model
fine-tuning. Since tasks may interfere with each other, a key notion for
modeling their relationships is task affinity. This includes pairwise task
affinity, computed among pairs of tasks, and higher-order affinity, computed
among subsets of tasks. Naively computing either of them requires repeatedly
training on data from various task combinations, which is computationally
intensive. We present a new algorithm Grad-TAG that can estimate task
affinities without this repeated training.
  The key idea of Grad-TAG is to train a "base" model for all tasks and then
use a linearization technique to estimate the loss of the model for a specific
task combination. The linearization works by computing a gradient-based
approximation of the loss, using low-dimensional projections of gradients as
features in a logistic regression to predict labels for the task combination.
We show that the linearized model can provably approximate the loss when the
gradient-based approximation is accurate, and also empirically verify that on
several large models. Then, given the estimated task affinity, we design a
semi-definite program for clustering similar tasks by maximizing the average
density of clusters.
  We evaluate Grad-TAG's performance across seven datasets, including
multi-label classification on graphs, and instruction fine-tuning of language
models. Our task affinity estimates are within 2.7% distance to the true
affinities while needing only 3% of FLOPs in full training. On our largest
graph with 21M edges and 500 labeling tasks, our algorithm delivers estimates
within 5% distance to the true affinities, using only 112 GPU hours. Our
results show that Grad-TAG achieves excellent performance and runtime tradeoffs
compared to existing approaches.

摘要：多任務學習是一種廣泛使用的範例，用於在不同的任務上訓練模型，其應用範圍從圖神經網路到語言模型微調。由於任務可能會相互干擾，因此建模它們關係的一個關鍵概念是任務親和性。這包括成對任務親和性，在成對任務之間計算，以及高階親和性，在任務子集之間計算。天真地計算其中任何一個都需要重複訓練來自各種任務組合的資料，這在計算上很密集。我們提出了一種新的演算法 Grad-TAG，它可以在沒有重複訓練的情況下估計任務親和性。
Grad-TAG 的關鍵思想是為所有任務訓練一個「基礎」模型，然後使用線性化技術來估計模型對特定任務組合的損失。線性化通過計算損失的基於梯度的近似值來工作，使用梯度的低維投影作為特徵，在邏輯迴歸中預測任務組合的標籤。我們證明了當基於梯度的近似值準確時，線性化模型可以證明地近似損失，並且在幾個大型模型上經驗驗證了這一點。然後，給定估計的任務親和性，我們設計了一個半定程式，通過最大化叢集的平均密度來對類似的任務進行叢集。
我們評估了 Grad-TAG 在七個資料集上的效能，包括圖形上的多標籤分類，以及語言模型的指令微調。我們的任務親和性估計與真實親和性距離在 2.7% 以內，同時只需要 3% 的 FLOP 進行完整訓練。在我們最大的圖形（有 2100 萬條邊和 500 個標籤任務）上，我們的演算法提供的估計與真實親和性距離在 5% 以內，只使用 112 個 GPU 小時。我們的結果表明，與現有方法相比，Grad-TAG 在效能和執行時間權衡方面取得了優異的表現。

##### **MTLSO: A Multi-Task Learning Approach for Logic Synthesis Optimization**
2409.06077v1 by Faezeh Faez, Raika Karimi, Yingxue Zhang, Xing Li, Lei Chen, Mingxuan Yuan, Mahdi Biparva

Electronic Design Automation (EDA) is essential for IC design and has
recently benefited from AI-based techniques to improve efficiency. Logic
synthesis, a key EDA stage, transforms high-level hardware descriptions into
optimized netlists. Recent research has employed machine learning to predict
Quality of Results (QoR) for pairs of And-Inverter Graphs (AIGs) and synthesis
recipes. However, the severe scarcity of data due to a very limited number of
available AIGs results in overfitting, significantly hindering performance.
Additionally, the complexity and large number of nodes in AIGs make plain GNNs
less effective for learning expressive graph-level representations. To tackle
these challenges, we propose MTLSO - a Multi-Task Learning approach for Logic
Synthesis Optimization. On one hand, it maximizes the use of limited data by
training the model across different tasks. This includes introducing an
auxiliary task of binary multi-label graph classification alongside the primary
regression task, allowing the model to benefit from diverse supervision
sources. On the other hand, we employ a hierarchical graph representation
learning strategy to improve the model's capacity for learning expressive
graph-level representations of large AIGs, surpassing traditional plain GNNs.
Extensive experiments across multiple datasets and against state-of-the-art
baselines demonstrate the superiority of our method, achieving an average
performance gain of 8.22\% for delay and 5.95\% for area.

摘要：電子設計自動化 (EDA) 對 IC 設計至關重要，最近受益於基於 AI 的技術來提高效率。邏輯綜合是 EDA 的關鍵階段，它將高級硬體描述轉換為最佳化的網路表。最近的研究採用機器學習來預測與反相器圖 (AIG) 和綜合配方配對的結果品質 (QoR)。然而，由於可用 AIG 數量極少，導致資料嚴重匱乏，造成過度擬合，嚴重阻礙效能。此外，AIG 中的複雜性和大量節點使純粹的 GNN 在學習表達式圖形級別表示時效率較低。為了應對這些挑戰，我們提出 MTLSO - 一種邏輯綜合最佳化的多任務學習方法。一方面，它透過在不同任務中訓練模型來最大化使用有限的資料。這包括在主要回歸任務的同時引入二元多標籤圖分類的輔助任務，讓模型受益於多樣化的監督來源。另一方面，我們採用階層式圖形表示學習策略來提高模型學習大型 AIG 的表達式圖形級別表示的能力，超越傳統的純粹 GNN。跨多個資料集以及與最先進的基準進行的廣泛實驗證明了我們方法的優越性，在延遲方面獲得了 8.22% 的平均效能提升，在面積方面獲得了 5.95% 的提升。

##### **DetoxBench: Benchmarking Large Language Models for Multitask Fraud & Abuse Detection**
2409.06072v1 by Joymallya Chakraborty, Wei Xia, Anirban Majumder, Dan Ma, Walid Chaabene, Naveed Janvekar

Large language models (LLMs) have demonstrated remarkable capabilities in
natural language processing tasks. However, their practical application in
high-stake domains, such as fraud and abuse detection, remains an area that
requires further exploration. The existing applications often narrowly focus on
specific tasks like toxicity or hate speech detection. In this paper, we
present a comprehensive benchmark suite designed to assess the performance of
LLMs in identifying and mitigating fraudulent and abusive language across
various real-world scenarios. Our benchmark encompasses a diverse set of tasks,
including detecting spam emails, hate speech, misogynistic language, and more.
We evaluated several state-of-the-art LLMs, including models from Anthropic,
Mistral AI, and the AI21 family, to provide a comprehensive assessment of their
capabilities in this critical domain. The results indicate that while LLMs
exhibit proficient baseline performance in individual fraud and abuse detection
tasks, their performance varies considerably across tasks, particularly
struggling with tasks that demand nuanced pragmatic reasoning, such as
identifying diverse forms of misogynistic language. These findings have
important implications for the responsible development and deployment of LLMs
in high-risk applications. Our benchmark suite can serve as a tool for
researchers and practitioners to systematically evaluate LLMs for multi-task
fraud detection and drive the creation of more robust, trustworthy, and
ethically-aligned systems for fraud and abuse detection.

摘要：大型語言模型 (LLM) 已在自然語言處理任務中展現出非凡的能力。然而，它們在高風險領域中的實際應用，例如詐騙和濫用偵測，仍然是一個需要進一步探索的領域。現有的應用程式通常狹隘地專注於特定任務，例如毒性或仇恨言論偵測。在本文中，我們提出一個全面的基準測試套件，旨在評估 LLM 在各種真實世界場景中識別和減輕欺詐和濫用語言的效能。我們的基準涵蓋了一組不同的任務，包括偵測垃圾郵件、仇恨言論、厭惡女性的語言等等。我們評估了幾種最先進的 LLM，包括來自 Anthropic、Mistral AI 和 AI21 家族的模型，以全面評估它們在這個關鍵領域的能力。結果表明，儘管 LLM 在個別的詐騙和濫用偵測任務中表現出熟練的基準效能，但它們的效能因任務而異，特別是在需要細緻務實推理的任務中表現不佳，例如識別各種形式的厭惡女性的語言。這些發現對 LLM 在高風險應用中的負責任開發和部署具有重要的意義。我們的基準測試套件可以作為研究人員和實務工作者的工具，用於系統性地評估 LLM 的多任務詐騙偵測，並推動建立更強大、更值得信賴且在道德上更一致的詐騙和濫用偵測系統。

##### **Privacy-Preserving Data Linkage Across Private and Public Datasets for Collaborative Agriculture Research**
2409.06069v1 by Osama Zafar, Rosemarie Santa Gonzalez, Gabriel Wilkins, Alfonso Morales, Erman Ayday

Digital agriculture leverages technology to enhance crop yield, disease
resilience, and soil health, playing a critical role in agricultural research.
However, it raises privacy concerns such as adverse pricing, price
discrimination, higher insurance costs, and manipulation of resources,
deterring farm operators from sharing data due to potential misuse. This study
introduces a privacy-preserving framework that addresses these risks while
allowing secure data sharing for digital agriculture. Our framework enables
comprehensive data analysis while protecting privacy. It allows stakeholders to
harness research-driven policies that link public and private datasets. The
proposed algorithm achieves this by: (1) identifying similar farmers based on
private datasets, (2) providing aggregate information like time and location,
(3) determining trends in price and product availability, and (4) correlating
trends with public policy data, such as food insecurity statistics. We validate
the framework with real-world Farmer's Market datasets, demonstrating its
efficacy through machine learning models trained on linked privacy-preserved
data. The results support policymakers and researchers in addressing food
insecurity and pricing issues. This work significantly contributes to digital
agriculture by providing a secure method for integrating and analyzing data,
driving advancements in agricultural technology and development.

摘要：數位農業利用科技來提升作物產量、疾病復原力和土壤健康，在農業研究中扮演關鍵角色。
然而，它引發了隱私問題，例如不利定價、價格歧視、較高的保險成本和資源操縱，由於潛在的誤用，阻止了農場經營者分享資料。本研究提出一個保護隱私的架構，它能解決這些風險，同時允許安全的資料共享以進行數位農業。我們的架構能進行全面的資料分析，同時保護隱私。它允許利害關係人利用研究驅動的政策，連結公共和私人資料集。所提出的演算法透過以下方式達成此目標：(1) 根據私人資料集識別類似的農民，(2) 提供總和資訊，例如時間和地點，(3) 確定價格和產品可用性的趨勢，以及 (4) 將趨勢與公共政策資料相關聯，例如糧食不安全統計。我們使用真實世界的農夫市集資料集驗證了這個架構，透過在連結的保護隱私資料上訓練的機器學習模型，證明了它的效力。這些結果支持政策制定者和研究人員解決糧食不安全和定價問題。這項工作透過提供一個整合和分析資料的安全方法，大幅貢獻了數位農業，推動農業技術和發展的進步。

##### **MLLM-FL: Multimodal Large Language Model Assisted Federated Learning on Heterogeneous and Long-tailed Data**
2409.06067v1 by Jianyi Zhang, Hao Frank Yang, Ang Li, Xin Guo, Pu Wang, Haiming Wang, Yiran Chen, Hai Li

Previous studies on federated learning (FL) often encounter performance
degradation due to data heterogeneity among different clients. In light of the
recent advances in multimodal large language models (MLLMs), such as GPT-4v and
LLaVA, which demonstrate their exceptional proficiency in multimodal tasks,
such as image captioning and multimodal question answering. We introduce a
novel federated learning framework, named Multimodal Large Language Model
Assisted Federated Learning (MLLM-FL), which which employs powerful MLLMs at
the server end to address the heterogeneous and long-tailed challenges. Owing
to the advanced cross-modality representation capabilities and the extensive
open-vocabulary prior knowledge of MLLMs, our framework is adept at harnessing
the extensive, yet previously underexploited, open-source data accessible from
websites and powerful server-side computational resources. Hence, the MLLM-FL
not only enhances the performance but also avoids increasing the risk of
privacy leakage and the computational burden on local devices, distinguishing
it from prior methodologies. Our framework has three key stages. Initially,
prior to local training on local datasets of clients, we conduct global
visual-text pretraining of the model. This pretraining is facilitated by
utilizing the extensive open-source data available online, with the assistance
of multimodal large language models. Subsequently, the pretrained model is
distributed among various clients for local training. Finally, once the locally
trained models are transmitted back to the server, a global alignment is
carried out under the supervision of MLLMs to further enhance the performance.
Experimental evaluations on established benchmarks, show that our framework
delivers promising performance in the typical scenarios with data heterogeneity
and long-tail distribution across different clients in FL.

摘要：先前的聯合學習 (FL) 研究通常會遇到效能降低的問題，原因在於不同用戶端之間的資料異質性。有鑑於多模態大型語言模型 (MLLM)（例如 GPT-4v 和 LLaVA）的最新進展，這些模型在多模態任務（例如影像標題和多模態問答）中展現出卓越的熟練度。我們引進一個名為多模態大型語言模型輔助聯合學習 (MLLM-FL) 的創新聯合學習架構，它在伺服器端採用強大的 MLLM 來應對異質性和長尾挑戰。由於 MLLM 具備先進的跨模態表徵能力和廣泛的開放式詞彙先備知識，我們的架構擅長利用從網站和強大的伺服器端運算資源取得的廣泛但先前未充分利用的開放原始碼資料。因此，MLLM-FL 不僅能提升效能，還能避免增加隱私外洩的風險和本地裝置的運算負擔，這讓它有別於先前的研究方法。我們的架構有三個關鍵階段。最初，在用戶端的本地資料集進行本地訓練之前，我們會執行模型的全球視覺文字預訓練。這個預訓練會利用線上取得的廣泛開放原始碼資料，並在多模態大型語言模型的協助下進行。隨後，預訓練模型會分發給各個用戶端進行本地訓練。最後，當本地訓練的模型傳回伺服器後，會在 MLLM 的監督下執行全球比對，以進一步提升效能。在既定的基準上的實驗評估顯示，我們的架構在 FL 中不同用戶端具有資料異質性和長尾分佈的典型場景中，提供了令人滿意的效能。

##### **Identifying the sources of ideological bias in GPT models through linguistic variation in output**
2409.06043v1 by Christina Walker, Joan C. Timoneda

Extant work shows that generative AI models such as GPT-3.5 and 4 perpetuate
social stereotypes and biases. One concerning but less explored source of bias
is ideology. Do GPT models take ideological stances on politically sensitive
topics? In this article, we provide an original approach to identifying
ideological bias in generative models, showing that bias can stem from both the
training data and the filtering algorithm. We leverage linguistic variation in
countries with contrasting political attitudes to evaluate bias in average GPT
responses to sensitive political topics in those languages. First, we find that
GPT output is more conservative in languages that map well onto conservative
societies (i.e., Polish), and more liberal in languages used uniquely in
liberal societies (i.e., Swedish). This result provides strong evidence of
training data bias in GPT models. Second, differences across languages observed
in GPT-3.5 persist in GPT-4, even though GPT-4 is significantly more liberal
due to OpenAI's filtering policy. Our main takeaway is that generative model
training must focus on high-quality, curated datasets to reduce bias, even if
it entails a compromise in training data size. Filtering responses after
training only introduces new biases and does not remove the underlying training
biases.

摘要：現有的研究顯示，生成式 AI 模型（例如 GPT-3.5 和 4）會延續社會刻板印象和偏見。意識形態是一個令人擔憂但較少探討的偏見來源。GPT 模型是否對政治敏感議題採取意識形態立場？在本文中，我們提供一種辨識生成式模型中意識形態偏見的原創方法，並說明偏見可能來自訓練資料和篩選演算法。我們利用政治態度截然不同的國家中的語言差異，來評估 GPT 對這些語言中敏感政治議題的平均回應中的偏見。首先，我們發現 GPT 輸出的保守程度，在對應於保守社會的語言（例如波蘭語）中較高，而在僅用於自由社會的語言（例如瑞典語）中較低。此結果提供了 GPT 模型中訓練資料偏見的有力證據。其次，GPT-3.5 中觀察到的跨語言差異在 GPT-4 中仍然存在，儘管 GPT-4 由於 OpenAI 的篩選政策而顯著地更為自由。我們的重點是，即使這會犧牲訓練資料的大小，生成式模型訓練也必須專注於高品質、經過整理的資料集，以減少偏見。訓練後篩選回應只會引入新的偏見，並不會消除潛在的訓練偏見。

##### **Investigating Causal Cues: Strengthening Spoofed Audio Detection with Human-Discernible Linguistic Features**
2409.06033v1 by Zahra Khanjani, Tolulope Ale, Jianwu Wang, Lavon Davis, Christine Mallinson, Vandana P. Janeja

Several types of spoofed audio, such as mimicry, replay attacks, and
deepfakes, have created societal challenges to information integrity. Recently,
researchers have worked with sociolinguistics experts to label spoofed audio
samples with Expert Defined Linguistic Features (EDLFs) that can be discerned
by the human ear: pitch, pause, word-initial and word-final release bursts of
consonant stops, audible intake or outtake of breath, and overall audio
quality. It is established that there is an improvement in several deepfake
detection algorithms when they augmented the traditional and common features of
audio data with these EDLFs. In this paper, using a hybrid dataset comprised of
multiple types of spoofed audio augmented with sociolinguistic annotations, we
investigate causal discovery and inferences between the discernible linguistic
features and the label in the audio clips, comparing the findings of the causal
models with the expert ground truth validation labeling process. Our findings
suggest that the causal models indicate the utility of incorporating linguistic
features to help discern spoofed audio, as well as the overall need and
opportunity to incorporate human knowledge into models and techniques for
strengthening AI models. The causal discovery and inference can be used as a
foundation of training humans to discern spoofed audio as well as automating
EDLFs labeling for the purpose of performance improvement of the common
AI-based spoofed audio detectors.

摘要：<paragraph>多種類型的偽造音訊，例如模仿、重播攻擊和深度造假，對資訊的完整性造成了社會挑戰。最近，研究人員與社會語言學專家合作，使用人類耳朵可以辨別的專家定義語言特徵 (EDLF) 標註偽造音訊樣本：音高、停頓、輔音停頓的字首和字尾釋放爆破音、可聽見的吸氣或呼氣，以及整體音訊品質。已確立在使用這些 EDLF 擴充傳統且常見的音訊資料特徵時，多種深度造假偵測演算法會有改善。在本文中，使用包含多種類型偽造音訊且擴充社會語言學註解的混合資料集，我們探討可辨別的語言特徵與音訊片段中的標籤之間的因果發現和推論，並將因果模型的發現與專家實地驗證標籤處理程序進行比較。我們的發現表明，因果模型顯示了納入語言特徵以幫助辨別偽造音訊的效用，以及將人類知識納入模型和技術以強化 AI 模型的整體需求和機會。因果發現和推論可用作訓練人類辨別偽造音訊的基礎，以及自動化 EDLF 標籤處理以改善常見的 AI 基於偽造音訊偵測器的效能。</paragraph>

##### **SongCreator: Lyrics-based Universal Song Generation**
2409.06029v1 by Shun Lei, Yixuan Zhou, Boshi Tang, Max W. Y. Lam, Feng Liu, Hangyu Liu, Jingcheng Wu, Shiyin Kang, Zhiyong Wu, Helen Meng

Music is an integral part of human culture, embodying human intelligence and
creativity, of which songs compose an essential part. While various aspects of
song generation have been explored by previous works, such as singing voice,
vocal composition and instrumental arrangement, etc., generating songs with
both vocals and accompaniment given lyrics remains a significant challenge,
hindering the application of music generation models in the real world. In this
light, we propose SongCreator, a song-generation system designed to tackle this
challenge. The model features two novel designs: a meticulously designed
dual-sequence language model (DSLM) to capture the information of vocals and
accompaniment for song generation, and an additional attention mask strategy
for DSLM, which allows our model to understand, generate and edit songs, making
it suitable for various song-related generation tasks. Extensive experiments
demonstrate the effectiveness of SongCreator by achieving state-of-the-art or
competitive performances on all eight tasks. Notably, it surpasses previous
works by a large margin in lyrics-to-song and lyrics-to-vocals. Additionally,
it is able to independently control the acoustic conditions of the vocals and
accompaniment in the generated song through different prompts, exhibiting its
potential applicability. Our samples are available at
https://songcreator.github.io/.

摘要：音樂是人類文化中不可或缺的一部分，體現了人類的智慧和創造力，其中歌曲構成了一個重要的部分。雖然以前的作品已經探索了歌曲生成的各個方面，例如歌唱聲音、人聲作曲和器樂編排等，但給定歌詞生成人聲和伴奏的歌曲仍然是一個重大的挑戰，阻礙了音樂生成模型在現實世界中的應用。有鑑於此，我們提出了 SongCreator，一個旨在應對這一挑戰的歌曲生成系統。該模型具有兩個新穎的設計：一個精心設計的雙序列語言模型 (DSLM) 來擷取歌曲生成的人聲和伴奏資訊，以及一個額外的 DSLM 注意力遮罩策略，它允許我們的模型理解、生成和編輯歌曲，使其適用於各種與歌曲相關的生成任務。廣泛的實驗通過在所有八項任務中實現最先進或有競爭力的表現，證明了 SongCreator 的有效性。值得注意的是，它在歌詞轉歌曲和歌詞轉人聲方面比以前的作品有了很大的進步。此外，它能夠通過不同的提示獨立控制生成歌曲中人聲和伴奏的聲學條件，展示了其潛在的適用性。我們的範例可以在 https://songcreator.github.io/ 取得。

##### **Deep Generative Model for Mechanical System Configuration Design**
2409.06016v1 by Yasaman Etesam, Hyunmin Cheong, Mohammadmehdi Ataei, Pradeep Kumar Jayaraman

Generative AI has made remarkable progress in addressing various design
challenges. One prominent area where generative AI could bring significant
value is in engineering design. In particular, selecting an optimal set of
components and their interfaces to create a mechanical system that meets design
requirements is one of the most challenging and time-consuming tasks for
engineers. This configuration design task is inherently challenging due to its
categorical nature, multiple design requirements a solution must satisfy, and
the reliance on physics simulations for evaluating potential solutions. These
characteristics entail solving a combinatorial optimization problem with
multiple constraints involving black-box functions. To address this challenge,
we propose a deep generative model to predict the optimal combination of
components and interfaces for a given design problem. To demonstrate our
approach, we solve a gear train synthesis problem by first creating a synthetic
dataset using a grammar, a parts catalogue, and a physics simulator. We then
train a Transformer using this dataset, named GearFormer, which can not only
generate quality solutions on its own, but also augment search methods such as
an evolutionary algorithm and Monte Carlo tree search. We show that GearFormer
outperforms such search methods on their own in terms of satisfying the
specified design requirements with orders of magnitude faster generation time.
Additionally, we showcase the benefit of hybrid methods that leverage both
GearFormer and search methods, which further improve the quality of the
solutions.

摘要：生成式 AI 在解決各種設計挑戰方面取得了顯著進展。生成式 AI 可能帶來顯著價值的一個顯著領域是工程設計。特別是，選擇一組最佳的組件及其介面，以建立符合設計要求的機械系統，是工程師最具挑戰性和最耗時的工作之一。此組態設計任務本質上具有挑戰性，因為其分類性質、解決方案必須滿足的各種設計要求，以及依賴物理模擬來評估潛在解決方案。這些特性需要解決一個組合最佳化問題，其中包含涉及黑盒函數的各種約束。為了應對這一挑戰，我們提出了一個深度生成模型，以預測特定設計問題的組件和介面的最佳組合。為了展示我們的做法，我們首先使用語法、零件目錄和物理模擬器建立一個合成資料集，來解決齒輪組合成問題。然後，我們使用此資料集訓練一個 Transformer，命名為 GearFormer，它不僅可以自行產生高品質的解決方案，還可以擴充搜尋方法，例如演化演算法和蒙地卡羅樹搜尋。我們展示了 GearFormer 在滿足指定設計要求方面優於這些搜尋方法，而且生成時間快了幾個數量級。此外，我們展示了同時利用 GearFormer 和搜尋方法的混合方法的優點，這進一步提高了解決方案的品質。

##### **Improved Visually Prompted Keyword Localisation in Real Low-Resource Settings**
2409.06013v1 by Leanne Nortje, Dan Oneata, Herman Kamper

Given an image query, visually prompted keyword localisation (VPKL) aims to
find occurrences of the depicted word in a speech collection. This can be
useful when transcriptions are not available for a low-resource language (e.g.
if it is unwritten). Previous work showed that VPKL can be performed with a
visually grounded speech model trained on paired images and unlabelled speech.
But all experiments were done on English. Moreover, transcriptions were used to
get positive and negative pairs for the contrastive loss. This paper introduces
a few-shot learning scheme to mine pairs automatically without transcriptions.
On English, this results in only a small drop in performance. We also - for the
first time - consider VPKL on a real low-resource language, Yoruba. While
scores are reasonable, here we see a bigger drop in performance compared to
using ground truth pairs because the mining is less accurate in Yoruba.

摘要：給定圖像查詢，視覺提示關鍵字定位 (VPKL) 旨在尋找語音集合中所描繪單詞的出現。當低資源語言沒有轉錄時，這可能會很有用（例如，如果它是未寫的）。先前的研究表明，VPKL 可以使用在配對圖像和未標記語音上訓練的視覺基礎語音模型來執行。但所有實驗都是在英語上進行的。此外，轉錄被用於為對比損失獲得正負對。本文介紹了一種少次學習方案，可以在沒有轉錄的情況下自動挖掘對。在英語中，這只會導致性能略微下降。我們還首次考慮了真正的低資源語言約魯巴語上的 VPKL。雖然分數合理，但與使用地面實況對相比，我們在此看到性能下降更大，因為約魯巴語中的挖掘不太準確。

##### **TransformerRanker: A Tool for Efficiently Finding the Best-Suited Language Models for Downstream Classification Tasks**
2409.05997v1 by Lukas Garbas, Max Ploner, Alan Akbik

Classification tasks in NLP are typically addressed by selecting a
pre-trained language model (PLM) from a model hub, and fine-tuning it for the
task at hand. However, given the very large number of PLMs that are currently
available, a practical challenge is to determine which of them will perform
best for a specific downstream task. With this paper, we introduce
TransformerRanker, a lightweight library that efficiently ranks PLMs for
classification tasks without the need for computationally costly fine-tuning.
Our library implements current approaches for transferability estimation
(LogME, H-Score, kNN), in combination with layer aggregation options, which we
empirically showed to yield state-of-the-art rankings of PLMs (Garbas et al.,
2024). We designed the interface to be lightweight and easy to use, allowing
users to directly connect to the HuggingFace Transformers and Dataset
libraries. Users need only select a downstream classification task and a list
of PLMs to create a ranking of likely best-suited PLMs for their task. We make
TransformerRanker available as a pip-installable open-source library
https://github.com/flairNLP/transformer-ranker.

摘要：NLP 中的分類任務通常透過從模型中心選擇預先訓練好的語言模型 (PLM)，並針對手邊的任務進行微調來處理。然而，考量到目前可用的 PLM 數量龐大，一個實際的挑戰是要找出哪個 PLM 對於特定下游任務的執行成效最佳。透過這篇論文，我們引入了 TransformerRanker，這是一個輕量級的程式庫，可以有效地對 PLM 進行分類任務排名，而無需進行計算成本高昂的微調。我們的程式庫實作了目前用於可轉移性估計的方法 (LogME、H 分數、kNN)，並結合了層聚合選項，我們透過實證證明可產生 PLM 的最先進排名 (Garbas 等人，2024)。我們設計了這個介面，使其輕量且易於使用，讓使用者可以直接連接到 HuggingFace Transformers 和 Dataset 程式庫。使用者只需選擇一個下游分類任務和一個 PLM 清單，即可為任務建立一個可能最適合的 PLM 排名。我們將 TransformerRanker 作為一個可透過 pip 安裝的開源程式庫提供 https://github.com/flairNLP/transformer-ranker。

##### **MessIRve: A Large-Scale Spanish Information Retrieval Dataset**
2409.05994v1 by Francisco Valentini, Viviana Cotik, Damián Furman, Ivan Bercovich, Edgar Altszyler, Juan Manuel Pérez

Information retrieval (IR) is the task of finding relevant documents in
response to a user query. Although Spanish is the second most spoken native
language, current IR benchmarks lack Spanish data, hindering the development of
information access tools for Spanish speakers. We introduce MessIRve, a
large-scale Spanish IR dataset with around 730 thousand queries from Google's
autocomplete API and relevant documents sourced from Wikipedia. MessIRve's
queries reflect diverse Spanish-speaking regions, unlike other datasets that
are translated from English or do not consider dialectal variations. The large
size of the dataset allows it to cover a wide variety of topics, unlike smaller
datasets. We provide a comprehensive description of the dataset, comparisons
with existing datasets, and baseline evaluations of prominent IR models. Our
contributions aim to advance Spanish IR research and improve information access
for Spanish speakers.

摘要：資訊檢索 (IR) 是根據使用者查詢尋找相關文件的工作。儘管西班牙語是第二大母語，但目前的 IR 基準缺乏西班牙語資料，這阻礙了為西班牙語使用者開發資訊存取工具。我們引入了 MessIRve，一個大規模的西班牙語 IR 資料集，其中包含來自 Google 自動完成 API 的約 73 萬個查詢和來自維基百科的相关文件。與從英語翻譯或不考慮方言變異的其他資料集不同，MessIRve 的查詢反映了不同的西班牙語系地區。與較小的資料集不同，該資料集的大規模使它能夠涵蓋各種主題。我們提供了資料集的全面描述、與現有資料集的比較，以及對著名 IR 模型的基線評估。我們的貢獻旨在推進西班牙語 IR 研究，並改善西班牙語使用者的資訊存取。

##### **A Comprehensive Comparison Between ANNs and KANs For Classifying EEG Alzheimer's Data**
2409.05989v1 by Akshay Sunkara, Sriram Sattiraju, Aakarshan Kumar, Zaryab Kanjiani, Himesh Anumala

Alzheimer's Disease is an incurable cognitive condition that affects
thousands of people globally. While some diagnostic methods exist for
Alzheimer's Disease, many of these methods cannot detect Alzheimer's in its
earlier stages. Recently, researchers have explored the use of
Electroencephalogram (EEG) technology for diagnosing Alzheimer's. EEG is a
noninvasive method of recording the brain's electrical signals, and EEG data
has shown distinct differences between patients with and without Alzheimer's.
In the past, Artificial Neural Networks (ANNs) have been used to predict
Alzheimer's from EEG data, but these models sometimes produce false positive
diagnoses. This study aims to compare losses between ANNs and Kolmogorov-Arnold
Networks (KANs) across multiple types of epochs, learning rates, and nodes. The
results show that across these different parameters, ANNs are more accurate in
predicting Alzheimer's Disease from EEG signals.

摘要：阿茲海默症是一種無法治癒的認知疾病，影響全球數千人。雖然阿茲海默症有一些診斷方法，但這些方法中的許多無法在早期階段檢測出阿茲海默症。最近，研究人員探索了使用腦電圖 (EEG) 技術診斷阿茲海默症。EEG 是一種非侵入性的方法，用於記錄大腦的電信號，而 EEG 數據顯示出患有阿茲海默症和未患有阿茲海默症的患者之間存在顯著差異。過去，人工神經網路 (ANN) 已被用於從 EEG 數據中預測阿茲海默症，但這些模型有時會產生假陽性診斷。本研究旨在比較多個類型的時期、學習率和節點之間 ANN 和 Kolmogorov-Arnold 網路 (KAN) 之間的損失。結果表明，在這些不同的參數中，ANN 在從 EEG 信號中預測阿茲海默症方面更準確。

##### **AI for Mathematics Mathematical Formalized Problem Solving and Theorem Proving in Different Fields in Lean4**
2409.05977v1 by Xichen Tang

Using computerized verifiable formal languages like Lean 4 to prove
mathematical theorems has a significant impact on mathematical formalization.
Lean 4 offers prominent potential for advancing mathematical reasoning.
However, existing efforts are limited to mathematical formalization languages
in substantial online corpora and are dedicated to keeping pace with rapidly
evolving languages. To bridge the gap between the traditional and computerized
proof, my approach to formalizing theorem proving involves generating formal
steps and complete proofs using Large Language Models (LLMs) based on Natural
Language (NL) proofs. The method is to introduce the basic structure and
tactics in general, determine how AI can assist the mathematical formalization
process to improve its performance, and give examples of solving problems in
Lean 4 comparing to NL, mainly in IMO, and a sample theorem proving in abstract
algebra.

摘要：使用 Lean 4 等可計算驗證形式語言來證明數學定理對數學形式化有重大影響。
Lean 4 為推進數學推理提供了顯著的潛力。
然而，現有的努力僅限於大量的在線語料庫中的數學形式化語言，並且致力於跟上快速發展的語言。為了彌合傳統和計算機化證明之間的差距，我對定理證明形式化的方法涉及使用基於自然語言 (NL) 證明的生成形式步驟和完整證明的大語言模型 (LLM)。該方法是介紹一般性的基本結構和策略，確定 AI 如何協助數學形式化過程以提高其性能，並給出在 Lean 4 中解決問題的示例，與 NL 進行比較，主要在 IMO 中，以及在抽象代數中的樣本定理證明。

##### **A Small Claims Court for the NLP: Judging Legal Text Classification Strategies With Small Datasets**
2409.05972v1 by Mariana Yukari Noguti, Edduardo Vellasques, Luiz Eduardo Soares Oliveira

Recent advances in language modelling has significantly decreased the need of
labelled data in text classification tasks. Transformer-based models,
pre-trained on unlabeled data, can outmatch the performance of models trained
from scratch for each task. However, the amount of labelled data need to
fine-tune such type of model is still considerably high for domains requiring
expert-level annotators, like the legal domain. This paper investigates the
best strategies for optimizing the use of a small labeled dataset and large
amounts of unlabeled data and perform a classification task in the legal area
with 50 predefined topics. More specifically, we use the records of demands to
a Brazilian Public Prosecutor's Office aiming to assign the descriptions in one
of the subjects, which currently demands deep legal knowledge for manual
filling. The task of optimizing the performance of classifiers in this scenario
is especially challenging, given the low amount of resources available
regarding the Portuguese language, especially in the legal domain. Our results
demonstrate that classic supervised models such as logistic regression and SVM
and the ensembles random forest and gradient boosting achieve better
performance along with embeddings extracted with word2vec when compared to BERT
language model. The latter demonstrates superior performance in association
with the architecture of the model itself as a classifier, having surpassed all
previous models in that regard. The best result was obtained with Unsupervised
Data Augmentation (UDA), which jointly uses BERT, data augmentation, and
strategies of semi-supervised learning, with an accuracy of 80.7% in the
aforementioned task.

摘要：<paragraph>語言模型的最新進展大幅降低了文本分類任務中標註資料的需求。以未標註資料預先訓練的 Transformer 模型，其效能可以超越從頭針對每個任務訓練的模型。然而，對於需要專家級註解者的領域（例如法律領域），微調此類模型所需的標註資料量仍然相當高。本文探討了最佳策略，以最佳化使用小型標註資料集和大量未標註資料，並在法律領域執行分類任務，其中包含 50 個預先定義的主題。更具體地說，我們使用巴西檢察官辦公室的要求記錄，旨在將說明指派到其中一個主題，目前需要深厚的法律知識才能手動填寫。在這種情況下，最佳化分類器效能的任務特別具有挑戰性，因為葡萄牙語可用的資源很少，特別是在法律領域。我們的結果表明，與 BERT 語言模型相比，經典監督模型（例如邏輯迴歸和 SVM）以及隨機森林和梯度提升的集成，在與 word2vec 提取的嵌入式處理時，可以獲得更好的效能。後者與模型本身的架構作為分類器結合使用時，表現出優異的效能，在這個方面超越了所有先前的模型。最佳結果是透過非監督資料擴充 (UDA) 獲得的，它結合使用了 BERT、資料擴充和半監督學習策略，在上述任務中達到了 80.7% 的準確度。</paragraph>

##### **Promptable Closed-loop Traffic Simulation**
2409.05863v1 by Shuhan Tan, Boris Ivanovic, Yuxiao Chen, Boyi Li, Xinshuo Weng, Yulong Cao, Philipp Krähenbühl, Marco Pavone

Simulation stands as a cornerstone for safe and efficient autonomous driving
development. At its core a simulation system ought to produce realistic,
reactive, and controllable traffic patterns. In this paper, we propose ProSim,
a multimodal promptable closed-loop traffic simulation framework. ProSim allows
the user to give a complex set of numerical, categorical or textual prompts to
instruct each agent's behavior and intention. ProSim then rolls out a traffic
scenario in a closed-loop manner, modeling each agent's interaction with other
traffic participants. Our experiments show that ProSim achieves high prompt
controllability given different user prompts, while reaching competitive
performance on the Waymo Sim Agents Challenge when no prompt is given. To
support research on promptable traffic simulation, we create
ProSim-Instruct-520k, a multimodal prompt-scenario paired driving dataset with
over 10M text prompts for over 520k real-world driving scenarios. We will
release code of ProSim as well as data and labeling tools of
ProSim-Instruct-520k at https://ariostgx.github.io/ProSim.

摘要：模擬作為安全且有效率的自動駕駛開發的基石。模擬系統的核心在於產生逼真、具反應性且可控制的交通模式。在本文中，我們提出 ProSim，一個多模態可提示閉環交通模擬架構。ProSim 允許使用者提供一組複雜的數值、類別或文字提示，以指示每個代理的行為和意圖。然後，ProSim 以閉環方式推出交通場景，模擬每個代理與其他交通參與者的互動。我們的實驗顯示，在沒有提示的情況下，ProSim 在不同的使用者提示下實現了很高的提示可控性，同時在 Waymo Sim Agents Challenge 中達到了競爭力的表現。為了支持可提示交通模擬的研究，我們建立了 ProSim-Instruct-520k，一個多模態提示場景配對的駕駛資料集，其中包含超過 10M 個文字提示，適用於超過 520k 個真實世界的駕駛場景。我們將在 https://ariostgx.github.io/ProSim 上釋出 ProSim 的程式碼以及 ProSim-Instruct-520k 的資料和標籤工具。

##### **MMEvol: Empowering Multimodal Large Language Models with Evol-Instruct**
2409.05840v1 by Run Luo, Haonan Zhang, Longze Chen, Ting-En Lin, Xiong Liu, Yuchuan Wu, Min Yang, Minzheng Wang, Pengpeng Zeng, Lianli Gao, Heng Tao Shen, Yunshui Li, Xiaobo Xia, Fei Huang, Jingkuan Song, Yongbin Li

The development of Multimodal Large Language Models (MLLMs) has seen
significant advancements. However, the quantity and quality of multimodal
instruction data have emerged as significant bottlenecks in their progress.
Manually creating multimodal instruction data is both time-consuming and
inefficient, posing challenges in producing instructions of high complexity.
Moreover, distilling instruction data from black-box commercial models (e.g.,
GPT-4o, GPT-4V) often results in simplistic instruction data, which constrains
performance to that of these models. The challenge of curating diverse and
complex instruction data remains substantial. We propose MMEvol, a novel
multimodal instruction data evolution framework that combines fine-grained
perception evolution, cognitive reasoning evolution, and interaction evolution.
This iterative approach breaks through data quality bottlenecks to generate a
complex and diverse image-text instruction dataset, thereby empowering MLLMs
with enhanced capabilities. Beginning with an initial set of instructions,
SEED-163K, we utilize MMEvol to systematically broadens the diversity of
instruction types, integrates reasoning steps to enhance cognitive
capabilities, and extracts detailed information from images to improve visual
understanding and robustness. To comprehensively evaluate the effectiveness of
our data, we train LLaVA-NeXT using the evolved data and conduct experiments
across 13 vision-language tasks. Compared to the baseline trained with seed
data, our approach achieves an average accuracy improvement of 3.1 points and
reaches state-of-the-art (SOTA) performance on 9 of these tasks.

摘要：多模态大语言模型（MLLM）的发展已取得显著进展。然而，多模态指令数据的数量和质量已成为其进步中的重大瓶颈。手动创建多模态指令数据既费时又低效，在生成高复杂度指令时会造成挑战。此外，从黑箱商业模型（例如 GPT-4o、GPT-4V）中提取指令数据通常会导致指令数据过于简单，这会将性能限制在这些模型的性能范围内。对多样且复杂指令数据进行整理的挑战仍然很大。我们提出了 MMEvol，这是一种新颖的多模态指令数据演化框架，它结合了细粒度的感知演化、认知推理演化和交互演化。这种迭代方法突破了数据质量瓶颈，生成复杂且多样的图像文本指令数据集，从而增强了 MLLM 的能力。从一组初始指令 SEED-163K 开始，我们利用 MMEvol 系统地拓宽指令类型的多样性，整合推理步骤以增强认知能力，并从图像中提取详细信息以提高视觉理解和鲁棒性。为了全面评估我们数据的有效性，我们使用演化数据训练 LLaVA-NeXT，并在 13 项视觉语言任务中进行实验。与使用种子数据训练的基线相比，我们的方法将平均准确度提高了 3.1 个百分点，并在其中 9 项任务上达到了最先进 (SOTA) 的性能。

##### **DeepFM-Crispr: Prediction of CRISPR On-Target Effects via Deep Learning**
2409.05938v1 by Condy Bao, Fuxiao Liu

Since the advent of CRISPR-Cas9, a groundbreaking gene-editing technology
that enables precise genomic modifications via a short RNA guide sequence,
there has been a marked increase in the accessibility and application of this
technology across various fields. The success of CRISPR-Cas9 has spurred
further investment and led to the discovery of additional CRISPR systems,
including CRISPR-Cas13. Distinct from Cas9, which targets DNA, Cas13 targets
RNA, offering unique advantages for gene modulation. We focus on Cas13d, a
variant known for its collateral activity where it non-specifically cleaves
adjacent RNA molecules upon activation, a feature critical to its function. We
introduce DeepFM-Crispr, a novel deep learning model developed to predict the
on-target efficiency and evaluate the off-target effects of Cas13d. This model
harnesses a large language model to generate comprehensive representations rich
in evolutionary and structural data, thereby enhancing predictions of RNA
secondary structures and overall sgRNA efficacy. A transformer-based
architecture processes these inputs to produce a predictive efficacy score.
Comparative experiments show that DeepFM-Crispr not only surpasses traditional
models but also outperforms recent state-of-the-art deep learning methods in
terms of prediction accuracy and reliability.

摘要：自 CRISPR-Cas9 問世以來，這項突破性的基因編輯技術
可透過短 RNA 引導序列執行精準的基因體修改，
此技術在各個領域的可近性和應用性都有顯著的提升。CRISPR-Cas9 的成功
激勵了更多投資，並導致發現更多 CRISPR 系統，
包含 CRISPR-Cas13。與鎖定 DNA 的 Cas9 不同，Cas13 鎖定
RNA，提供基因調控的獨特優勢。我們專注於 Cas13d，一種
已知具有附帶活性變異，在活化後會非特定地切割
相鄰的 RNA 分子，此特性對其功能至關重要。我們介紹 DeepFM-Crispr，一種
新穎的深度學習模型，用於預測目標效率並評估 Cas13d 的脫靶效應。此模型
利用大型語言模型來產生包含豐富演化和結構資料的全面表徵，從而增強對 RNA
二級結構和整體 sgRNA 效能的預測。一個基於Transformer的
架構處理這些輸入以產生預測效能分數。比較實驗顯示 DeepFM-Crispr 不僅超越傳統
模型，在預測準確性和可靠性方面也優於近期最先進的深度學習方法。

##### **Improving Pretraining Data Using Perplexity Correlations**
2409.05816v1 by Tristan Thrush, Christopher Potts, Tatsunori Hashimoto

Quality pretraining data is often seen as the key to high-performance
language models. However, progress in understanding pretraining data has been
slow due to the costly pretraining runs required for data selection
experiments. We present a framework that avoids these costs and selects
high-quality pretraining data without any LLM training of our own. Our work is
based on a simple observation: LLM losses on many pretraining texts are
correlated with downstream benchmark performance, and selecting
high-correlation documents is an effective pretraining data selection method.
We build a new statistical framework for data selection centered around
estimates of perplexity-benchmark correlations and perform data selection using
a sample of 90 LLMs taken from the Open LLM Leaderboard on texts from tens of
thousands of web domains. In controlled pretraining experiments at the 160M
parameter scale on 8 benchmarks, our approach outperforms DSIR on every
benchmark, while matching the best data selector found in DataComp-LM, a
hand-engineered bigram classifier.

摘要：高质量预训练数据通常被视为高性能语言模型的关键。然而，由于数据选择实验需要昂贵的预训练运行，因此对预训练数据的理解进展缓慢。我们提出了一个避免这些成本的框架，并在不进行任何 LLM 训练的情况下选择高质量的预训练数据。我们的工作基于一个简单的观察：许多预训练文本上的 LLM 损失与下游基准性能相关，并且选择高相关性文档是一种有效的预训练数据选择方法。我们构建了一个新的统计框架，用于数据选择，该框架围绕困惑度基准相关性的估计展开，并使用从数万个网络域中的文本中获取的 90 个 LLM 样本执行数据选择。在 8 个基准上的 160M 参数规模的受控预训练实验中，我们的方法在每个基准上都优于 DSIR，同时匹配了在 DataComp-LM 中发现的最佳数据选择器，即手工制作的二元分类器。

##### **The Future of Software Testing: AI-Powered Test Case Generation and Validation**
2409.05808v1 by Mohammad Baqar, Rajat Khanda

Software testing is a crucial phase in the software development lifecycle
(SDLC), ensuring that products meet necessary functional, performance, and
quality benchmarks before release. Despite advancements in automation,
traditional methods of generating and validating test cases still face
significant challenges, including prolonged timelines, human error, incomplete
test coverage, and high costs of manual intervention. These limitations often
lead to delayed product launches and undetected defects that compromise
software quality and user satisfaction. The integration of artificial
intelligence (AI) into software testing presents a promising solution to these
persistent challenges. AI-driven testing methods automate the creation of
comprehensive test cases, dynamically adapt to changes, and leverage machine
learning to identify high-risk areas in the codebase. This approach enhances
regression testing efficiency while expanding overall test coverage.
Furthermore, AI-powered tools enable continuous testing and self-healing test
cases, significantly reducing manual oversight and accelerating feedback loops,
ultimately leading to faster and more reliable software releases. This paper
explores the transformative potential of AI in improving test case generation
and validation, focusing on its ability to enhance efficiency, accuracy, and
scalability in testing processes. It also addresses key challenges associated
with adapting AI for testing, including the need for high quality training
data, ensuring model transparency, and maintaining a balance between automation
and human oversight. Through case studies and examples of real-world
applications, this paper illustrates how AI can significantly enhance testing
efficiency across both legacy and modern software systems.

摘要：軟體測試是軟體開發生命週期 (SDLC) 中至關重要的一個階段，確保產品在發布前符合必要的運作、效能和品質基準。儘管自動化技術進步，但產生和驗證測試案例的傳統方法仍然面臨重大挑戰，包括時間線拉長、人為錯誤、測試涵蓋不完全，以及人工介入的高成本。這些限制通常會導致產品發布延誤和未偵測到的缺陷，進而損害軟體品質和使用者滿意度。將人工智慧 (AI) 整合到軟體測試中，為這些持續存在的挑戰提供了有希望的解決方案。AI 驅動的測試方法可以自動建立全面的測試案例，動態適應變更，並利用機器學習來識別程式碼庫中的高風險區域。這種方法可以提升回歸測試效率，同時擴展整體測試涵蓋範圍。此外，AI 驅動的工具可以進行持續測試和自我修復測試案例，大幅減少人工監督並加速回饋迴圈，最終實現更快速且更可靠的軟體發布。本文探討了 AI 在改善測試案例產生和驗證方面的變革潛力，重點在於它增強測試流程中效率、準確性和可擴充性的能力。本文也探討了將 AI 應用於測試時會遇到的主要挑戰，包括對高品質訓練資料的需求、確保模型透明度，以及在自動化和人工監督之間取得平衡。透過案例研究和真實世界應用範例，本文說明了 AI 如何能大幅提升傳統和現代軟體系統的測試效率。

##### **Benchmarking Chinese Knowledge Rectification in Large Language Models**
2409.05806v1 by Tianhe Lu, Jizhan Fang, Yunzhi Yao, Xin Xu, Ningyu Zhang, Huajun Chen

While Large Language Models (LLMs) exhibit remarkable generative
capabilities, they are not without flaws, particularly in the form of
hallucinations. This issue is even more pronounced when LLMs are applied to
specific languages and domains. For example, LLMs may generate nonsense
information when handling Chinese ancient poetry, proverbs, or idioms, owing to
the lack of specific knowledge. To this end, this paper introduces a benchmark
for rectifying Chinese knowledge in LLMs via knowledge editing. Specifically,
we introduce a new Chinese dataset, CKnowEdit, by collecting seven type of
knowledge from various sources, including classical texts, idioms, and content
from Baidu Tieba Ruozhiba, thereby accounting for the unique polyphony,
antithesis, and logical constructs inherent in the Chinese language. Through
the analysis of this dataset, we uncover the challenges faced by current LLMs
in mastering Chinese. Furthermore, our evaluation of state-of-the-art knowledge
editing techniques on this dataset unveil the substantial scope for advancement
in the rectification of Chinese knowledge. Code and dataset are available at
https://github.com/zjunlp/EasyEdit.

摘要：大型语言模型 (LLM) 虽然表现出非凡的生成能力，但也并非没有缺陷，特别是幻觉形式的缺陷。当 LLM 应用于特定语言和领域时，这个问题更为明显。例如，由于缺乏特定知识，LLM 在处理中国古代诗歌、谚语或成语时可能会产生无意义的信息。为此，本文通过知识编辑引入了一个用于纠正 LLM 中中文知识的基准。具体来说，我们通过从各种来源（包括经典文本、成语和百度贴吧若知八的的内容）收集七种类型的知识，引入了新的中文数据集 CKnowEdit，从而解释了中文语言中固有的独特多音、对立和逻辑结构。通过对该数据集的分析，我们发现了当前 LLM 在掌握中文时面临的挑战。此外，我们对该数据集上最先进的知识编辑技术的评估揭示了纠正中文知识的巨大进步空间。代码和数据集可在 https://github.com/zjunlp/EasyEdit 获得。

##### **Enhancing Preference-based Linear Bandits via Human Response Time**
2409.05798v1 by Shen Li, Yuyang Zhang, Zhaolin Ren, Claire Liang, Na Li, Julie A. Shah

Binary human choice feedback is widely used in interactive preference
learning for its simplicity, but it provides limited information about
preference strength. To overcome this limitation, we leverage human response
times, which inversely correlate with preference strength, as complementary
information. Our work integrates the EZ-diffusion model, which jointly models
human choices and response times, into preference-based linear bandits. We
introduce a computationally efficient utility estimator that reformulates the
utility estimation problem using both choices and response times as a linear
regression problem. Theoretical and empirical comparisons with traditional
choice-only estimators reveal that for queries with strong preferences ("easy"
queries), choices alone provide limited information, while response times offer
valuable complementary information about preference strength. As a result,
incorporating response times makes easy queries more useful. We demonstrate
this advantage in the fixed-budget best-arm identification problem, with
simulations based on three real-world datasets, consistently showing
accelerated learning when response times are incorporated.

摘要：二元人類選擇回饋因其簡潔性而廣泛用於互動式偏好學習，但它提供的偏好強度資訊有限。為了克服此限制，我們利用與偏好強度呈反比的人類反應時間，作為補充資訊。我們的研究將 EZ 擴散模型整合到偏好式線性賭徒中，該模型共同建模人類選擇和反應時間。我們引入了一個計算效率高的效用估計器，它使用選擇和反應時間作為線性回歸問題來重新制定效用估計問題。與傳統的僅選擇估計器的理論和實證比較表明，對於具有強烈偏好的查詢（「容易」查詢），僅選擇提供有限的資訊，而反應時間提供有價值的補充資訊，說明偏好強度。因此，納入反應時間使簡單的查詢更有用。我們在固定預算最佳臂識別問題中展示了此優勢，模擬基於三個真實世界資料集，始終顯示在納入反應時間時，加速學習。

##### **NeurLZ: On Enhancing Lossy Compression Performance based on Error-Controlled Neural Learning for Scientific Data**
2409.05785v2 by Wenqi Jia, Youyuan Liu, Zhewen Hu, Jinzhen Wang, Boyuan Zhang, Wei Niu, Junzhou Huang, Stavros Kalafatis, Sian Jin, Miao Yin

Large-scale scientific simulations generate massive datasets that pose
significant challenges for storage and I/O. While traditional lossy compression
techniques can improve performance, balancing compression ratio, data quality,
and throughput remains difficult. To address this, we propose NeurLZ, a novel
cross-field learning-based and error-controlled compression framework for
scientific data. By integrating skipping DNN models, cross-field learning, and
error control, our framework aims to substantially enhance lossy compression
performance. Our contributions are three-fold: (1) We design a lightweight
skipping model to provide high-fidelity detail retention, further improving
prediction accuracy. (2) We adopt a cross-field learning approach to
significantly improve data prediction accuracy, resulting in a substantially
improved compression ratio. (3) We develop an error control approach to provide
strict error bounds according to user requirements. We evaluated NeurLZ on
several real-world HPC application datasets, including Nyx (cosmological
simulation), Miranda (large turbulence simulation), and Hurricane (weather
simulation). Experiments demonstrate that our framework achieves up to a 90%
relative reduction in bit rate under the same data distortion, compared to the
best existing approach.

摘要：大規模的科學模擬會產生大量的資料集，對儲存和 I/O 造成嚴峻的挑戰。雖然傳統的有損壓縮技術可以提升效能，但要在壓縮率、資料品質和處理量之間取得平衡仍很困難。為了解決這個問題，我們提出了 NeurLZ，一個創新的基於跨領域學習和錯誤控制的科學資料壓縮架構。透過整合跳過 DNN 模型、跨領域學習和錯誤控制，我們的架構旨在大幅提升有損壓縮效能。我們的貢獻有三方面：(1) 我們設計了一個輕量級跳過模型來提供高保真細節保留，進一步提升預測準確度。(2) 我們採用跨領域學習方法來大幅提升資料預測準確度，進而大幅提升壓縮率。(3) 我們開發了一個錯誤控制方法來根據使用者需求提供嚴格的錯誤界限。我們在多個真實世界的 HPC 應用程式資料集上評估了 NeurLZ，包括 Nyx (宇宙學模擬)、Miranda (大型湍流模擬) 和 Hurricane (天氣模擬)。實驗證明，與現有的最佳方法相比，我們的架構在相同的資料失真下，可將位元率相對降低多達 90%。

##### **Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models**
2409.05771v1 by Emily Cheng, Richard J. Antonello

Research has repeatedly demonstrated that intermediate hidden states
extracted from large language models are able to predict measured brain
response to natural language stimuli. Yet, very little is known about the
representation properties that enable this high prediction performance. Why is
it the intermediate layers, and not the output layers, that are most capable
for this unique and highly general transfer task? In this work, we show that
evidence from language encoding models in fMRI supports the existence of a
two-phase abstraction process within LLMs. We use manifold learning methods to
show that this abstraction process naturally arises over the course of training
a language model and that the first "composition" phase of this abstraction
process is compressed into fewer layers as training continues. Finally, we
demonstrate a strong correspondence between layerwise encoding performance and
the intrinsic dimensionality of representations from LLMs. We give initial
evidence that this correspondence primarily derives from the inherent
compositionality of LLMs and not their next-word prediction properties.

摘要：研究已一再證明，從大型語言模型中提取的中間隱藏狀態能夠預測大腦對自然語言刺激的測量反應。然而，對於能夠實現這種高預測性能的表徵特性，我們所知甚少。為什麼是中間層，而不是輸出層，最能勝任這項獨特且高度通用的轉移任務？在這項工作中，我們展示了 fMRI 中語言編碼模型的證據支持 LLM 中存在兩階段抽象過程。我們使用流形學習方法來展示這個抽象過程在語言模型訓練過程中自然產生，並且這個抽象過程的第一個「組合」階段會隨著訓練的進行而壓縮到更少的層中。最後，我們展示了層級編碼性能與 LLM 中表徵的內在維度之間的強對應關係。我們給出的初步證據表明，這種對應關係主要源於 LLM 固有的組合性，而不是它們的下一詞預測特性。

##### **Elucidating Optimal Reward-Diversity Tradeoffs in Text-to-Image Diffusion Models**
2409.06493v1 by Rohit Jena, Ali Taghibakhshi, Sahil Jain, Gerald Shen, Nima Tajbakhsh, Arash Vahdat

Text-to-image (T2I) diffusion models have become prominent tools for
generating high-fidelity images from text prompts. However, when trained on
unfiltered internet data, these models can produce unsafe, incorrect, or
stylistically undesirable images that are not aligned with human preferences.
To address this, recent approaches have incorporated human preference datasets
to fine-tune T2I models or to optimize reward functions that capture these
preferences. Although effective, these methods are vulnerable to reward
hacking, where the model overfits to the reward function, leading to a loss of
diversity in the generated images. In this paper, we prove the inevitability of
reward hacking and study natural regularization techniques like KL divergence
and LoRA scaling, and their limitations for diffusion models. We also introduce
Annealed Importance Guidance (AIG), an inference-time regularization inspired
by Annealed Importance Sampling, which retains the diversity of the base model
while achieving Pareto-Optimal reward-diversity tradeoffs. Our experiments
demonstrate the benefits of AIG for Stable Diffusion models, striking the
optimal balance between reward optimization and image diversity. Furthermore, a
user study confirms that AIG improves diversity and quality of generated images
across different model architectures and reward functions.

摘要：文本到图像 (T2I) 扩散模型已成为根据文本提示生成高保真图像的重要工具。然而，当在未经筛选的互联网数据上进行训练时，这些模型可能会产生不安全、不正确或风格上不可取的图像，这些图像与人类偏好不符。为了解决这个问题，最近的方法已经纳入了人类偏好数据集来微调 T2I 模型或优化捕获这些偏好的奖励函数。尽管有效，但这些方法容易受到奖励黑客攻击，其中模型过度拟合奖励函数，导致生成图像的多样性丧失。在本文中，我们证明了奖励黑客攻击的不可避免性，并研究了自然正则化技术，如 KL 散度和 LoRA 缩放，以及它们对扩散模型的限制。我们还引入了退火重要性指导 (AIG)，这是一种受退火重要性采样启发的推理时间正则化，它保留了基础模型的多样性，同时实现了帕累托最优的奖励多样性权衡。我们的实验展示了 AIG 对稳定扩散模型的好处，在奖励优化和图像多样性之间取得了最佳平衡。此外，一项用户研究证实，AIG 提升了不同模型架构和奖励函数下生成图像的多样性和质量。

