{"2405.14445": {"publish_time": "2024-05-23", "title": "Exploring the use of a Large Language Model for data extraction in systematic reviews: a rapid feasibility study", "paper_summary": "This paper describes a rapid feasibility study of using GPT-4, a large\nlanguage model (LLM), to (semi)automate data extraction in systematic reviews.\nDespite the recent surge of interest in LLMs there is still a lack of\nunderstanding of how to design LLM-based automation tools and how to robustly\nevaluate their performance. During the 2023 Evidence Synthesis Hackathon we\nconducted two feasibility studies. Firstly, to automatically extract study\ncharacteristics from human clinical, animal, and social science domain studies.\nWe used two studies from each category for prompt-development; and ten for\nevaluation. Secondly, we used the LLM to predict Participants, Interventions,\nControls and Outcomes (PICOs) labelled within 100 abstracts in the EBM-NLP\ndataset. Overall, results indicated an accuracy of around 80%, with some\nvariability between domains (82% for human clinical, 80% for animal, and 72%\nfor studies of human social sciences). Causal inference methods and study\ndesign were the data extraction items with the most errors. In the PICO study,\nparticipants and intervention/control showed high accuracy (>80%), outcomes\nwere more challenging. Evaluation was done manually; scoring methods such as\nBLEU and ROUGE showed limited value. We observed variability in the LLMs\npredictions and changes in response quality. This paper presents a template for\nfuture evaluations of LLMs in the context of data extraction for systematic\nreview automation. Our results show that there might be value in using LLMs,\nfor example as second or third reviewers. However, caution is advised when\nintegrating models such as GPT-4 into tools. Further research on stability and\nreliability in practical settings is warranted for each type of data that is\nprocessed by the LLM.", "paper_summary_zh": "\u9019\u7bc7\u8ad6\u6587\u63cf\u8ff0\u4e86\u4e00\u500b\u4f7f\u7528 GPT-4\uff08\u4e00\u7a2e\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff0cLLM\uff09\u4f86\uff08\u534a\uff09\u81ea\u52d5\u5316\u7cfb\u7d71\u5316\u56de\u9867\u4e2d\u8cc7\u6599\u8403\u53d6\u7684\u5feb\u901f\u53ef\u884c\u6027\u7814\u7a76\u3002\u5118\u7ba1\u6700\u8fd1\u5c0d LLM \u7684\u8208\u8da3\u6fc0\u589e\uff0c\u4f46\u5c0d\u65bc\u5982\u4f55\u8a2d\u8a08\u57fa\u65bc LLM \u7684\u81ea\u52d5\u5316\u5de5\u5177\u4ee5\u53ca\u5982\u4f55\u7a69\u5065\u5730\u8a55\u4f30\u5176\u6548\u80fd\uff0c\u4ecd\u7136\u7f3a\u4e4f\u4e86\u89e3\u3002\u5728 2023 \u5e74\u8b49\u64da\u7d9c\u5408\u9ed1\u5ba2\u677e\u671f\u9593\uff0c\u6211\u5011\u9032\u884c\u4e86\u5169\u9805\u53ef\u884c\u6027\u7814\u7a76\u3002\u9996\u5148\uff0c\u81ea\u52d5\u5f9e\u4eba\u985e\u81e8\u5e8a\u3001\u52d5\u7269\u548c\u793e\u6703\u79d1\u5b78\u9818\u57df\u7814\u7a76\u4e2d\u8403\u53d6\u7814\u7a76\u7279\u5fb5\u3002\u6211\u5011\u4f7f\u7528\u6bcf\u500b\u985e\u5225\u4e2d\u7684\u5169\u9805\u7814\u7a76\u9032\u884c\u63d0\u793a\u958b\u767c\uff1b\u4e26\u4f7f\u7528\u5341\u9805\u9032\u884c\u8a55\u4f30\u3002\u5176\u6b21\uff0c\u6211\u5011\u4f7f\u7528 LLM \u4f86\u9810\u6e2c EBM-NLP \u8cc7\u6599\u96c6\u4e2d\u7684 100 \u7bc7\u6458\u8981\u4e2d\u6a19\u8a18\u7684\u53c3\u8207\u8005\u3001\u5e72\u9810\u63aa\u65bd\u3001\u5c0d\u7167\u548c\u7d50\u679c\uff08PICOs\uff09\u3002\u7e3d\u9ad4\u800c\u8a00\uff0c\u7d50\u679c\u986f\u793a\u6e96\u78ba\u5ea6\u7d04\u70ba 80%\uff0c\u4e0d\u540c\u9818\u57df\u4e4b\u9593\u5b58\u5728\u4e00\u4e9b\u5dee\u7570\uff08\u4eba\u985e\u81e8\u5e8a\u70ba 82%\uff0c\u52d5\u7269\u70ba 80%\uff0c\u4eba\u985e\u793e\u6703\u79d1\u5b78\u7814\u7a76\u70ba 72%\uff09\u3002\u56e0\u679c\u63a8\u8ad6\u65b9\u6cd5\u548c\u7814\u7a76\u8a2d\u8a08\u662f\u8cc7\u6599\u8403\u53d6\u9805\u76ee\u4e2d\u932f\u8aa4\u6700\u591a\u7684\u3002\u5728 PICO \u7814\u7a76\u4e2d\uff0c\u53c3\u8207\u8005\u548c\u5e72\u9810/\u5c0d\u7167\u986f\u793a\u51fa\u9ad8\u6e96\u78ba\u5ea6\uff08>80%\uff09\uff0c\u7d50\u679c\u66f4\u5177\u6311\u6230\u6027\u3002\u8a55\u4f30\u662f\u624b\u52d5\u5b8c\u6210\u7684\uff1bBLEU \u548c ROUGE \u7b49\u8a08\u5206\u65b9\u6cd5\u986f\u793a\u7684\u50f9\u503c\u6709\u9650\u3002\u6211\u5011\u89c0\u5bdf\u5230 LLM \u9810\u6e2c\u548c\u56de\u61c9\u54c1\u8cea\u8b8a\u5316\u7684\u8b8a\u7570\u6027\u3002\u672c\u6587\u63d0\u4f9b\u4e86 LLM \u5728\u7cfb\u7d71\u5316\u56de\u9867\u81ea\u52d5\u5316\u7684\u8cc7\u6599\u8403\u53d6\u80cc\u666f\u4e0b\u7684\u672a\u4f86\u8a55\u4f30\u7bc4\u672c\u3002\u6211\u5011\u7684\u7d50\u679c\u986f\u793a\u4f7f\u7528 LLM \u53ef\u80fd\u6709\u50f9\u503c\uff0c\u4f8b\u5982\u4f5c\u70ba\u7b2c\u4e8c\u6216\u7b2c\u4e09\u4f4d\u5be9\u67e5\u8005\u3002\u4f46\u662f\uff0c\u5728\u5c07 GPT-4 \u7b49\u6a21\u578b\u6574\u5408\u5230\u5de5\u5177\u4e2d\u6642\uff0c\u5efa\u8b70\u4fdd\u6301\u8b39\u614e\u3002\u5c0d\u65bc LLM \u8655\u7406\u7684\u6bcf\u7a2e\u985e\u578b\u8cc7\u6599\uff0c\u90fd\u6709\u5fc5\u8981\u9032\u4e00\u6b65\u7814\u7a76\u5be6\u969b\u8a2d\u5b9a\u4e2d\u7684\u7a69\u5b9a\u6027\u548c\u53ef\u9760\u6027\u3002", "author": "Lena Schmidt et.al.", "authors": "Lena Schmidt, Kaitlyn Hair, Sergio Graziozi, Fiona Campbell, Claudia Kapp, Alireza Khanteymoori, Dawn Craig, Mark Engelbert, James Thomas", "id": "2405.14445v1", "paper_url": "http://arxiv.org/abs/2405.14445v1", "repo": "null"}}