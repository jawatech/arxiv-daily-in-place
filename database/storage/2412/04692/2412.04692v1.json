{"2412.04692": {"publish_time": "2024-12-06", "title": "Smoothie: Label Free Language Model Routing", "paper_summary": "Large language models (LLMs) are increasingly used in applications where LLM\ninputs may span many different tasks. Recent work has found that the choice of\nLLM is consequential, and different LLMs may be good for different input\nsamples. Prior approaches have thus explored how engineers might select an LLM\nto use for each sample (i.e. routing). While existing routing methods mostly\nrequire training auxiliary models on human-annotated data, our work explores\nwhether it is possible to perform unsupervised routing. We propose Smoothie, a\nweak supervision-inspired routing approach that requires no labeled data. Given\na set of outputs from different LLMs, Smoothie constructs a latent variable\ngraphical model over embedding representations of observable LLM outputs and\nunknown \"true\" outputs. Using this graphical model, we estimate\nsample-dependent quality scores for each LLM, and route each sample to the LLM\nwith the highest corresponding score. We find that Smoothie's LLM\nquality-scores correlate with ground-truth model quality (correctly identifying\nthe optimal model on 9/14 tasks), and that Smoothie outperforms baselines for\nrouting by up to 10 points accuracy.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)  zunehmend in Anwendungen verwendet werden, bei denen LLM-Eingaben viele verschiedene Aufgaben umfassen k\u00f6nnen. J\u00fcngste Arbeiten haben ergeben, dass die Wahl des LLM ausschlaggebend ist und verschiedene LLMs f\u00fcr verschiedene Eingabeproben geeignet sein k\u00f6nnen. Bisherige Ans\u00e4tze haben daher untersucht, wie Ingenieure ein LLM ausw\u00e4hlen k\u00f6nnen, das f\u00fcr jede Probe verwendet werden soll (d. h. Routing). W\u00e4hrend bestehende Routing-Methoden meist erfordern, dass Hilfsmodelle f\u00fcr mit menschlichen Anmerkungen versehene Daten trainiert werden, untersucht unsere Arbeit, ob es m\u00f6glich ist, un\u00fcberwachtes Routing durchzuf\u00fchren. Wir schlagen Smoothie vor, einen von schwacher \u00dcberwachung inspirierten Routing-Ansatz, der keine beschrifteten Daten ben\u00f6tigt. Angesichts einer Reihe von Ausgaben verschiedener LLMs konstruiert Smoothie ein latentes variables grafisches Modell \u00fcber eingebettete Repr\u00e4sentationen von beobachtbaren LLM-Ausgaben und unbekannten \u201ewahren\u201c Ausgaben. Mithilfe dieses grafischen Modells sch\u00e4tzen wir probenabh\u00e4ngige Qualit\u00e4tswerte f\u00fcr jedes LLM und leiten jede Probe an das LLM mit der h\u00f6chsten entsprechenden Punktzahl weiter. Wir stellen fest, dass die LLM-Qualit\u00e4tswerte von Smoothie mit der Grundwahrheitsmodellqualit\u00e4t korrelieren (die das optimale Modell bei 9/14 Aufgaben korrekt identifiziert) und dass Smoothie Basiswerte f\u00fcr Routing um bis zu 10 Punkte Genauigkeit \u00fcbertrifft.", "author": "Neel Guha et.al.", "authors": "Neel Guha, Mayee F. Chen, Trevor Chow, Ishan S. Khare, Christopher R\u00e9", "id": "2412.04692v1", "paper_url": "http://arxiv.org/abs/2412.04692v1", "repo": "null"}}