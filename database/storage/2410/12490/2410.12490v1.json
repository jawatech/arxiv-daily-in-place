{"2410.12490": {"publish_time": "2024-10-16", "title": "Stabilize the Latent Space for Image Autoregressive Modeling: A Unified Perspective", "paper_summary": "Latent-based image generative models, such as Latent Diffusion Models (LDMs)\nand Mask Image Models (MIMs), have achieved notable success in image generation\ntasks. These models typically leverage reconstructive autoencoders like VQGAN\nor VAE to encode pixels into a more compact latent space and learn the data\ndistribution in the latent space instead of directly from pixels. However, this\npractice raises a pertinent question: Is it truly the optimal choice? In\nresponse, we begin with an intriguing observation: despite sharing the same\nlatent space, autoregressive models significantly lag behind LDMs and MIMs in\nimage generation. This finding contrasts sharply with the field of NLP, where\nthe autoregressive model GPT has established a commanding presence. To address\nthis discrepancy, we introduce a unified perspective on the relationship\nbetween latent space and generative models, emphasizing the stability of latent\nspace in image generative modeling. Furthermore, we propose a simple but\neffective discrete image tokenizer to stabilize the latent space for image\ngenerative modeling. Experimental results show that image autoregressive\nmodeling with our tokenizer (DiGIT) benefits both image understanding and image\ngeneration with the next token prediction principle, which is inherently\nstraightforward for GPT models but challenging for other generative models.\nRemarkably, for the first time, a GPT-style autoregressive model for images\noutperforms LDMs, which also exhibits substantial improvement akin to GPT when\nscaling up model size. Our findings underscore the potential of an optimized\nlatent space and the integration of discrete tokenization in advancing the\ncapabilities of image generative models. The code is available at\n\\url{https://github.com/DAMO-NLP-SG/DiGIT}.", "paper_summary_zh": "<paragraph>\u6f5b\u5728\u5716\u50cf\u751f\u6210\u6a21\u578b\uff0c\u4f8b\u5982\u6f5b\u5728\u64f4\u6563\u6a21\u578b (LDM) \u548c\u906e\u7f69\u5716\u50cf\u6a21\u578b (MIM)\uff0c\u5728\u5716\u50cf\u751f\u6210\u4efb\u52d9\u4e2d\u53d6\u5f97\u4e86\u986f\u8457\u7684\u6210\u529f\u3002\u9019\u4e9b\u6a21\u578b\u901a\u5e38\u5229\u7528\u91cd\u5efa\u81ea\u52d5\u7de8\u78bc\u5668\uff0c\u4f8b\u5982 VQGAN \u6216 VAE\uff0c\u5c07\u50cf\u7d20\u7de8\u78bc\u6210\u66f4\u7dca\u6e4a\u7684\u6f5b\u5728\u7a7a\u9593\uff0c\u4e26\u5728\u6f5b\u5728\u7a7a\u9593\u4e2d\u5b78\u7fd2\u8cc7\u6599\u5206\u4f48\uff0c\u800c\u4e0d\u662f\u76f4\u63a5\u5f9e\u50cf\u7d20\u4e2d\u5b78\u7fd2\u3002\u4f46\u662f\uff0c\u9019\u7a2e\u505a\u6cd5\u5f15\u767c\u4e86\u4e00\u500b\u76f8\u95dc\u7684\u554f\u984c\uff1a\u9019\u771f\u7684\u662f\u6700\u4f73\u9078\u64c7\u55ce\uff1f\u4f5c\u70ba\u56de\u61c9\uff0c\u6211\u5011\u5f9e\u4e00\u500b\u6709\u8da3\u7684\u89c0\u5bdf\u958b\u59cb\uff1a\u5118\u7ba1\u5171\u4eab\u76f8\u540c\u7684\u6f5b\u5728\u7a7a\u9593\uff0c\u4f46\u81ea\u8ff4\u6b78\u6a21\u578b\u5728\u5716\u50cf\u751f\u6210\u4e2d\u986f\u8457\u843d\u5f8c\u65bc LDM \u548c MIM\u3002\u9019\u4e00\u767c\u73fe\u8207 NLP \u9818\u57df\u5f62\u6210\u9bae\u660e\u5c0d\u6bd4\uff0c\u5728 NLP \u9818\u57df\uff0c\u81ea\u8ff4\u6b78\u6a21\u578b GPT \u5df2\u78ba\u7acb\u4e86\u4e3b\u5c0e\u5730\u4f4d\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u7a2e\u5dee\u7570\uff0c\u6211\u5011\u5c0d\u6f5b\u5728\u7a7a\u9593\u548c\u751f\u6210\u6a21\u578b\u4e4b\u9593\u7684\u95dc\u4fc2\u5f15\u5165\u4e86\u4e00\u500b\u7d71\u4e00\u7684\u89c0\u9ede\uff0c\u5f37\u8abf\u4e86\u6f5b\u5728\u7a7a\u9593\u5728\u5716\u50cf\u751f\u6210\u5efa\u6a21\u4e2d\u7684\u7a69\u5b9a\u6027\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u7c21\u55ae\u4f46\u6709\u6548\u7684\u96e2\u6563\u5716\u50cf\u5206\u8a5e\u5668\uff0c\u4ee5\u7a69\u5b9a\u5716\u50cf\u751f\u6210\u5efa\u6a21\u7684\u6f5b\u5728\u7a7a\u9593\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u4f7f\u7528\u6211\u5011\u7684\u5206\u8a5e\u5668 (DiGIT) \u7684\u5716\u50cf\u81ea\u8ff4\u6b78\u5efa\u6a21\u65e2\u6709\u5229\u65bc\u5716\u50cf\u7406\u89e3\uff0c\u4e5f\u6709\u5229\u65bc\u5716\u50cf\u751f\u6210\uff0c\u5176\u4e0b\u4e00\u500b\u7b26\u865f\u9810\u6e2c\u539f\u7406\u672c\u8cea\u4e0a\u5c0d GPT \u6a21\u578b\u4f86\u8aaa\u5f88\u7c21\u55ae\uff0c\u4f46\u5c0d\u5176\u4ed6\u751f\u6210\u6a21\u578b\u4f86\u8aaa\u537b\u5f88\u6709\u6311\u6230\u6027\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5c0d\u65bc\u5716\u50cf\uff0cGPT \u98a8\u683c\u81ea\u8ff4\u6b78\u6a21\u578b\u9996\u6b21\u512a\u65bc LDM\uff0c\u9019\u4e5f\u8868\u73fe\u51fa\u985e\u4f3c\u65bc GPT \u5728\u64f4\u5927\u6a21\u578b\u898f\u6a21\u6642\u7684\u986f\u8457\u6539\u9032\u3002\u6211\u5011\u7684\u767c\u73fe\u5f37\u8abf\u4e86\u512a\u5316\u6f5b\u5728\u7a7a\u9593\u548c\u6574\u5408\u96e2\u6563\u5206\u8a5e\u5728\u63d0\u5347\u5716\u50cf\u751f\u6210\u6a21\u578b\u80fd\u529b\u65b9\u9762\u7684\u6f5b\u529b\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728 \\url{https://github.com/DAMO-NLP-SG/DiGIT} \u7372\u5f97\u3002</paragraph>", "author": "Yongxin Zhu et.al.", "authors": "Yongxin Zhu, Bocheng Li, Hang Zhang, Xin Li, Linli Xu, Lidong Bing", "id": "2410.12490v1", "paper_url": "http://arxiv.org/abs/2410.12490v1", "repo": "https://github.com/DAMO-NLP-SG/DiGIT"}}