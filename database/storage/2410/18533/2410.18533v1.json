{"2410.18533": {"publish_time": "2024-10-24", "title": "LOGO -- Long cOntext aliGnment via efficient preference Optimization", "paper_summary": "Long-context models(LCMs) have shown great potential in processing long input\nsequences(even more than 100M tokens) conveniently and effectively. With\nsignificant progress, recent research has pointed out that LCMs can accurately\nlocate token-level salient information within the context. Yet, the generation\nperformance of these LCMs is far from satisfactory and might result in\nmisaligned responses, such as hallucinations. To enhance the generation\ncapability of LCMs, existing works have investigated the effects of data size\nand quality for both pre-training and instruction tuning. Though achieving\nmeaningful improvement, previous methods fall short in either effectiveness or\nefficiency. In this paper, we introduce LOGO(Long cOntext aliGnment via\nefficient preference Optimization), a training strategy that first introduces\npreference optimization for long-context alignment. To overcome the GPU\nmemory-bound issue caused by the long sequence, LOGO employs a reference-free\npreference optimization strategy and adopts a position synthesis method to\nconstruct the training data. By training with only 0.3B data on a single\n8$\\times$A800 GPU machine for 16 hours, LOGO allows the Llama-3-8B-Instruct-80K\nmodel to achieve comparable performance with GPT-4 in real-world long-context\ntasks while preserving the model's original capabilities on other tasks, e.g.,\nlanguage modeling and MMLU. Moreover, LOGO can extend the model's context\nwindow size while enhancing its generation performance.", "paper_summary_zh": "\u9577\u8a9e\u5883\u6a21\u578b (LCM) \u5df2\u5c55\u73fe\u51fa\u4fbf\u5229\u4e14\u6709\u6548\u8655\u7406\u9577\u8f38\u5165\u5e8f\u5217\uff08\u751a\u81f3\u8d85\u904e 100M \u500b\u7b26\u865f\uff09\u7684\u5de8\u5927\u6f5b\u529b\u3002\u96a8\u8457\u986f\u8457\u9032\u5c55\uff0c\u8fd1\u671f\u7814\u7a76\u6307\u51fa LCM \u80fd\u6e96\u78ba\u627e\u51fa\u8a9e\u5883\u4e2d\u7684\u7b26\u865f\u5c64\u7d1a\u986f\u8457\u8cc7\u8a0a\u3002\u7136\u800c\uff0c\u9019\u4e9b LCM \u7684\u751f\u6210\u6548\u80fd\u9060\u672a\u4ee4\u4eba\u6eff\u610f\uff0c\u53ef\u80fd\u6703\u5c0e\u81f4\u53cd\u61c9\u5931\u6e96\uff0c\u4f8b\u5982\u51fa\u73fe\u5e7b\u89ba\u3002\u70ba\u4e86\u63d0\u5347 LCM \u7684\u751f\u6210\u80fd\u529b\uff0c\u73fe\u6709\u7814\u7a76\u5df2\u63a2\u8a0e\u8cc7\u6599\u5927\u5c0f\u548c\u54c1\u8cea\u5c0d\u9810\u8a13\u7df4\u548c\u6307\u4ee4\u5fae\u8abf\u7684\u5f71\u97ff\u3002\u96d6\u7136\u53d6\u5f97\u6709\u610f\u7fa9\u7684\u9032\u5c55\uff0c\u4f46\u5148\u524d\u7684\u505a\u6cd5\u5728\u6548\u80fd\u6216\u6548\u7387\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39 LOGO\uff08\u900f\u904e\u6709\u6548\u504f\u597d\u6700\u4f73\u5316\u9032\u884c\u9577\u8a9e\u5883\u5c0d\u9f4a\uff09\uff0c\u9019\u662f\u4e00\u7a2e\u8a13\u7df4\u7b56\u7565\uff0c\u9996\u5148\u5f15\u5165\u504f\u597d\u6700\u4f73\u5316\u4ee5\u9032\u884c\u9577\u8a9e\u5883\u5c0d\u9f4a\u3002\u70ba\u4e86\u514b\u670d\u9577\u5e8f\u5217\u9020\u6210\u7684 GPU \u8a18\u61b6\u9ad4\u53d7\u9650\u554f\u984c\uff0cLOGO \u63a1\u7528\u7121\u53c3\u8003\u504f\u597d\u6700\u4f73\u5316\u7b56\u7565\uff0c\u4e26\u63a1\u7528\u4f4d\u7f6e\u5408\u6210\u65b9\u6cd5\u4f86\u5efa\u69cb\u8a13\u7df4\u8cc7\u6599\u3002\u900f\u904e\u5728\u55ae\u4e00 8$\\times$A800 GPU \u6a5f\u5668\u4e0a\u53ea\u4f7f\u7528 0.3B \u8cc7\u6599\u8a13\u7df4 16 \u5c0f\u6642\uff0cLOGO \u4f7f Llama-3-8B-Instruct-80K \u6a21\u578b\u5728\u771f\u5be6\u4e16\u754c\u9577\u8a9e\u5883\u4efb\u52d9\u4e2d\u9054\u5230\u8207 GPT-4 \u76f8\u7576\u7684\u6548\u80fd\uff0c\u540c\u6642\u4fdd\u7559\u6a21\u578b\u5728\u5176\u4ed6\u4efb\u52d9\uff08\u4f8b\u5982\u8a9e\u8a00\u5efa\u6a21\u548c MMLU\uff09\u4e0a\u7684\u539f\u59cb\u80fd\u529b\u3002\u6b64\u5916\uff0cLOGO \u80fd\u5728\u63d0\u5347\u751f\u6210\u6548\u80fd\u7684\u540c\u6642\uff0c\u64f4\u5145\u6a21\u578b\u7684\u8a9e\u5883\u8996\u7a97\u5927\u5c0f\u3002", "author": "Zecheng Tang et.al.", "authors": "Zecheng Tang, Zechen Sun, Juntao Li, Qiaoming Zhu, Min Zhang", "id": "2410.18533v1", "paper_url": "http://arxiv.org/abs/2410.18533v1", "repo": "null"}}