{"2411.19774": {"publish_time": "2024-11-29", "title": "PerLA: Perceptive 3D Language Assistant", "paper_summary": "Enabling Large Language Models (LLMs) to understand the 3D physical world is\nan emerging yet challenging research direction. Current strategies for\nprocessing point clouds typically downsample the scene or divide it into\nsmaller parts for separate analysis. However, both approaches risk losing key\nlocal details or global contextual information. In this paper, we introduce\nPerLA, a 3D language assistant designed to be more perceptive to both details\nand context, making visual representations more informative for the LLM. PerLA\ncaptures high-resolution (local) details in parallel from different point cloud\nareas and integrates them with (global) context obtained from a\nlower-resolution whole point cloud. We present a novel algorithm that preserves\npoint cloud locality through the Hilbert curve and effectively aggregates\nlocal-to-global information via cross-attention and a graph neural network.\nLastly, we introduce a novel loss for local representation consensus to promote\ntraining stability. PerLA outperforms state-of-the-art 3D language assistants,\nwith gains of up to +1.34 CiDEr on ScanQA for question answering, and +4.22 on\nScanRefer and +3.88 on Nr3D for dense\ncaptioning.\\url{https://gfmei.github.io/PerLA/}", "paper_summary_zh": "\u8b93\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7406\u89e3 3D \u7269\u7406\u4e16\u754c\u662f\u4e00\u500b\u65b0\u8208\u4f46\u5177\u6709\u6311\u6230\u6027\u7684\u7814\u7a76\u65b9\u5411\u3002\u7576\u524d\u8655\u7406\u9ede\u96f2\u7684\u7b56\u7565\u901a\u5e38\u6703\u5c0d\u5834\u666f\u9032\u884c\u964d\u63a1\u6a23\u6216\u5c07\u5176\u5206\u70ba\u66f4\u5c0f\u7684\u90e8\u5206\u4ee5\u9032\u884c\u55ae\u7368\u5206\u6790\u3002\u7136\u800c\uff0c\u9019\u5169\u7a2e\u65b9\u6cd5\u90fd\u6709\u53ef\u80fd\u907a\u5931\u95dc\u9375\u7684\u5c40\u90e8\u7d30\u7bc0\u6216\u5168\u5c40\u80cc\u666f\u8cc7\u8a0a\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 PerLA\uff0c\u9019\u662f\u4e00\u500b 3D \u8a9e\u8a00\u52a9\u7406\uff0c\u65e8\u5728\u66f4\u654f\u92b3\u5730\u611f\u77e5\u7d30\u7bc0\u548c\u80cc\u666f\uff0c\u8b93\u8996\u89ba\u8868\u73fe\u5c0d LLM \u66f4\u6709\u8cc7\u8a0a\u6027\u3002PerLA \u5f9e\u4e0d\u540c\u7684\u9ede\u96f2\u5340\u57df\u4e26\u884c\u64f7\u53d6\u9ad8\u89e3\u6790\u5ea6\uff08\u5c40\u90e8\uff09\u7d30\u7bc0\uff0c\u4e26\u5c07\u5176\u8207\u5f9e\u4f4e\u89e3\u6790\u5ea6\u5168\u9ede\u96f2\u4e2d\u7372\u5f97\u7684\uff08\u5168\u5c40\uff09\u80cc\u666f\u6574\u5408\u5728\u4e00\u8d77\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u6f14\u7b97\u6cd5\uff0c\u900f\u904e\u5e0c\u723e\u4f2f\u7279\u66f2\u7dda\u4fdd\u7559\u9ede\u96f2\u5c40\u90e8\u6027\uff0c\u4e26\u900f\u904e\u4ea4\u53c9\u6ce8\u610f\u529b\u548c\u5716\u5f62\u795e\u7d93\u7db2\u8def\u6709\u6548\u5730\u532f\u7e3d\u5c40\u90e8\u5230\u5168\u5c40\u8cc7\u8a0a\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u65b0\u7684\u640d\u5931\u51fd\u6578\uff0c\u7528\u65bc\u5c40\u90e8\u8868\u793a\u5171\u8b58\uff0c\u4ee5\u4fc3\u9032\u8a13\u7df4\u7a69\u5b9a\u6027\u3002PerLA \u512a\u65bc\u6700\u5148\u9032\u7684 3D \u8a9e\u8a00\u52a9\u7406\uff0c\u5728 ScanQA \u4e0a\u554f\u7b54\u7372\u5f97\u9ad8\u9054 +1.34 CiDEr \u7684\u589e\u76ca\uff0c\u5728 ScanRefer \u4e0a\u7372\u5f97 +4.22\uff0c\u5728 Nr3D \u4e0a\u7372\u5f97 +3.88 \u7684\u5bc6\u96c6\u6a19\u984c\u3002\\url{https://gfmei.github.io/PerLA/}", "author": "Guofeng Mei et.al.", "authors": "Guofeng Mei, Wei Lin, Luigi Riz, Yujiao Wu, Fabio Poiesi, Yiming Wang", "id": "2411.19774v1", "paper_url": "http://arxiv.org/abs/2411.19774v1", "repo": "null"}}