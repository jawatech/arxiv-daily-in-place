{"2410.01400": {"publish_time": "2024-10-02", "title": "CrowdCounter: A benchmark type-specific multi-target counterspeech dataset", "paper_summary": "Counterspeech presents a viable alternative to banning or suspending users\nfor hate speech while upholding freedom of expression. However, writing\neffective counterspeech is challenging for moderators/users. Hence, developing\nsuggestion tools for writing counterspeech is the need of the hour. One\ncritical challenge in developing such a tool is the lack of quality and\ndiversity of the responses in the existing datasets. Hence, we introduce a new\ndataset - CrowdCounter containing 3,425 hate speech-counterspeech pairs\nspanning six different counterspeech types (empathy, humor, questioning,\nwarning, shaming, contradiction), which is the first of its kind. The design of\nour annotation platform itself encourages annotators to write type-specific,\nnon-redundant and high-quality counterspeech. We evaluate two frameworks for\ngenerating counterspeech responses - vanilla and type-controlled prompts -\nacross four large language models. In terms of metrics, we evaluate the\nresponses using relevance, diversity and quality. We observe that Flan-T5 is\nthe best model in the vanilla framework across different models. Type-specific\nprompts enhance the relevance of the responses, although they might reduce the\nlanguage quality. DialoGPT proves to be the best at following the instructions\nand generating the type-specific counterspeech accurately.", "paper_summary_zh": "\u53cd\u8ad6\u63d0\u4f9b\u4e86\u4e00\u500b\u53ef\u884c\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u65e2\u80fd\u7981\u6b62\u6216\u66ab\u505c\u4ec7\u6068\u8a00\u8ad6\u7684\u4f7f\u7528\u8005\uff0c\u540c\u6642\u53c8\u80fd\u7dad\u8b77\u8a00\u8ad6\u81ea\u7531\u3002\u7136\u800c\uff0c\u64b0\u5beb\u6709\u6548\u7684\u53cd\u8ad6\u5c0d\u7248\u4e3b/\u4f7f\u7528\u8005\u4f86\u8aaa\u662f\u4e00\u500b\u6311\u6230\u3002\u56e0\u6b64\uff0c\u958b\u767c\u7528\u65bc\u64b0\u5beb\u53cd\u8ad6\u7684\u5efa\u8b70\u5de5\u5177\u662f\u7576\u52d9\u4e4b\u6025\u3002\u5728\u958b\u767c\u6b64\u985e\u5de5\u5177\u6642\uff0c\u4e00\u500b\u91cd\u5927\u7684\u6311\u6230\u662f\u73fe\u6709\u8cc7\u6599\u96c6\u4e2d\u56de\u61c9\u7684\u54c1\u8cea\u548c\u591a\u6a23\u6027\u4e0d\u8db3\u3002\u56e0\u6b64\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u65b0\u7684\u8cc7\u6599\u96c6 - CrowdCounter\uff0c\u5176\u4e2d\u5305\u542b 3,425 \u500b\u4ec7\u6068\u8a00\u8ad6 - \u53cd\u8ad6\u914d\u5c0d\uff0c\u6db5\u84cb\u516d\u7a2e\u4e0d\u540c\u7684\u53cd\u8ad6\u985e\u578b\uff08\u540c\u7406\u5fc3\u3001\u5e7d\u9ed8\u3001\u8cea\u7591\u3001\u8b66\u544a\u3001\u7f9e\u8fb1\u3001\u77db\u76fe\uff09\uff0c\u9019\u662f\u540c\u985e\u4e2d\u7684\u7b2c\u4e00\u500b\u3002\u6211\u5011\u7684\u8a3b\u89e3\u5e73\u53f0\u7684\u8a2d\u8a08\u672c\u8eab\u9f13\u52f5\u8a3b\u89e3\u8005\u64b0\u5beb\u7279\u5b9a\u985e\u578b\u3001\u975e\u5197\u9918\u4e14\u9ad8\u54c1\u8cea\u7684\u53cd\u8ad6\u3002\u6211\u5011\u8a55\u4f30\u4e86\u5169\u500b\u7528\u65bc\u7522\u751f\u53cd\u8ad6\u56de\u61c9\u7684\u6846\u67b6 - \u9999\u8349\u548c\u985e\u578b\u63a7\u5236\u63d0\u793a - \u8de8\u8d8a\u56db\u500b\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u3002\u5728\u6307\u6a19\u65b9\u9762\uff0c\u6211\u5011\u4f7f\u7528\u76f8\u95dc\u6027\u3001\u591a\u6a23\u6027\u548c\u54c1\u8cea\u4f86\u8a55\u4f30\u56de\u61c9\u3002\u6211\u5011\u89c0\u5bdf\u5230\uff0c\u5728\u4e0d\u540c\u7684\u6a21\u578b\u4e2d\uff0cFlan-T5 \u662f\u9999\u8349\u6846\u67b6\u4e2d\u7684\u6700\u4f73\u6a21\u578b\u3002\u7279\u5b9a\u985e\u578b\u7684\u63d0\u793a\u6703\u589e\u5f37\u56de\u61c9\u7684\u76f8\u95dc\u6027\uff0c\u5118\u7ba1\u5b83\u5011\u53ef\u80fd\u6703\u964d\u4f4e\u8a9e\u8a00\u54c1\u8cea\u3002DialoGPT \u8b49\u660e\u5728\u9075\u5faa\u8aaa\u660e\u548c\u6e96\u78ba\u7522\u751f\u7279\u5b9a\u985e\u578b\u7684\u53cd\u8ad6\u65b9\u9762\u8868\u73fe\u6700\u4f73\u3002", "author": "Punyajoy Saha et.al.", "authors": "Punyajoy Saha, Abhilash Datta, Abhik Jana, Animesh Mukherjee", "id": "2410.01400v1", "paper_url": "http://arxiv.org/abs/2410.01400v1", "repo": "https://github.com/hate-alert/crowdcounter"}}