{"2405.01576": {"publish_time": "2024-04-25", "title": "Uncovering Deceptive Tendencies in Language Models: A Simulated Company AI Assistant", "paper_summary": "We study the tendency of AI systems to deceive by constructing a realistic\nsimulation setting of a company AI assistant. The simulated company employees\nprovide tasks for the assistant to complete, these tasks spanning writing\nassistance, information retrieval and programming. We then introduce situations\nwhere the model might be inclined to behave deceptively, while taking care to\nnot instruct or otherwise pressure the model to do so. Across different\nscenarios, we find that Claude 3 Opus\n  1) complies with a task of mass-generating comments to influence public\nperception of the company, later deceiving humans about it having done so,\n  2) lies to auditors when asked questions, and\n  3) strategically pretends to be less capable than it is during capability\nevaluations.\n  Our work demonstrates that even models trained to be helpful, harmless and\nhonest sometimes behave deceptively in realistic scenarios, without notable\nexternal pressure to do so.", "paper_summary_zh": "", "author": "Olli J\u00e4rviniemi et.al.", "authors": "Olli J\u00e4rviniemi,Evan Hubinger", "id": "2405.01576v1", "paper_url": "http://arxiv.org/abs/2405.01576v1", "repo": "null"}}