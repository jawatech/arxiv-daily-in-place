{"2406.04614": {"publish_time": "2024-06-07", "title": "LawGPT: A Chinese Legal Knowledge-Enhanced Large Language Model", "paper_summary": "Large language models (LLMs), including both proprietary and open-source\nmodels, have showcased remarkable capabilities in addressing a wide range of\ndownstream tasks. Nonetheless, when it comes to practical Chinese legal tasks,\nthese models fail to meet the actual requirements. Proprietary models do not\nensure data privacy for sensitive legal cases, while open-source models\ndemonstrate unsatisfactory performance due to their lack of legal knowledge. To\naddress this problem, we introduce LawGPT, the first open-source model\nspecifically designed for Chinese legal applications. LawGPT comprises two key\ncomponents: legal-oriented pre-training and legal supervised fine-tuning.\nSpecifically, we employ large-scale Chinese legal documents for legal-oriented\npre-training to incorporate legal domain knowledge. To further improve the\nmodel's performance on downstream legal tasks, we create a knowledge-driven\ninstruction dataset for legal supervised fine-tuning. Our experimental results\ndemonstrate that LawGPT outperforms the open-source LLaMA 7B model. Our code\nand resources are publicly available at https://github.com/pengxiao-song/LaWGPT\nand have received 5.7K stars on GitHub.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\uff0c\u5305\u62ec\u5c08\u6709\u548c\u958b\u6e90\u6a21\u578b\uff0c\u5df2\u5c55\u73fe\u51fa\u5728\u8655\u7406\u5ee3\u6cdb\u7684\u4e0b\u6e38\u4efb\u52d9\u4e2d\u975e\u51e1\u7684\u80fd\u529b\u3002\u5118\u7ba1\u5982\u6b64\uff0c\u7576\u6d89\u53ca\u5230\u5be6\u969b\u7684\u4e2d\u570b\u6cd5\u5f8b\u4efb\u52d9\u6642\uff0c\u9019\u4e9b\u6a21\u578b\u672a\u80fd\u6eff\u8db3\u5be6\u969b\u8981\u6c42\u3002\u5c08\u6709\u6a21\u578b\u7121\u6cd5\u78ba\u4fdd\u654f\u611f\u6cd5\u5f8b\u6848\u4ef6\u7684\u6578\u64da\u96b1\u79c1\uff0c\u800c\u958b\u6e90\u6a21\u578b\u7531\u65bc\u7f3a\u4e4f\u6cd5\u5f8b\u77e5\u8b58\u800c\u8868\u73fe\u4e0d\u4f73\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 LawGPT\uff0c\u9019\u662f\u7b2c\u4e00\u500b\u5c08\u9580\u70ba\u4e2d\u570b\u6cd5\u5f8b\u61c9\u7528\u8a2d\u8a08\u7684\u958b\u6e90\u6a21\u578b\u3002LawGPT \u5305\u542b\u5169\u500b\u95dc\u9375\u7d44\u6210\u90e8\u5206\uff1a\u9762\u5411\u6cd5\u5f8b\u7684\u9810\u8a13\u7df4\u548c\u6cd5\u5f8b\u76e3\u7763\u5fae\u8abf\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u63a1\u7528\u4e86\u5927\u898f\u6a21\u7684\u4e2d\u570b\u6cd5\u5f8b\u6587\u4ef6\u9032\u884c\u9762\u5411\u6cd5\u5f8b\u7684\u9810\u8a13\u7df4\uff0c\u4ee5\u7d0d\u5165\u6cd5\u5f8b\u9818\u57df\u77e5\u8b58\u3002\u70ba\u4e86\u9032\u4e00\u6b65\u63d0\u9ad8\u6a21\u578b\u5728\u4e0b\u6e38\u6cd5\u5f8b\u4efb\u52d9\u4e0a\u7684\u8868\u73fe\uff0c\u6211\u5011\u70ba\u6cd5\u5f8b\u76e3\u7763\u5fae\u8abf\u5275\u5efa\u4e86\u4e00\u500b\u77e5\u8b58\u9a45\u52d5\u7684\u6307\u4ee4\u6578\u64da\u96c6\u3002\u6211\u5011\u7684\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0cLawGPT \u512a\u65bc\u958b\u6e90 LLaMA 7B \u6a21\u578b\u3002\u6211\u5011\u7684\u4ee3\u78bc\u548c\u8cc7\u6e90\u5df2\u5728 https://github.com/pengxiao-song/LaWGPT \u4e0a\u516c\u958b\uff0c\u4e26\u5df2\u5728 GitHub \u4e0a\u7372\u5f97 5.7K \u661f\u3002", "author": "Zhi Zhou et.al.", "authors": "Zhi Zhou, Jiang-Xin Shi, Peng-Xiao Song, Xiao-Wen Yang, Yi-Xuan Jin, Lan-Zhe Guo, Yu-Feng Li", "id": "2406.04614v1", "paper_url": "http://arxiv.org/abs/2406.04614v1", "repo": "https://github.com/pengxiao-song/lawgpt"}}