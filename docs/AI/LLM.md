
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-30**|**MM1.5: Methods, Analysis & Insights from Multimodal LLM Fine-tuning**|Haotian Zhang et.al.|[2409.20566v1](http://arxiv.org/abs/2409.20566v1)|null|
|**2024-09-30**|**Ranking Over Scoring: Towards Reliable and Robust Automated Evaluation of LLM-Generated Medical Explanatory Arguments**|Iker De la Iglesia et.al.|[2409.20565v1](http://arxiv.org/abs/2409.20565v1)|null|
|**2024-09-30**|**LaMMA-P: Generalizable Multi-Agent Long-Horizon Task Allocation and Planning with LM-Driven PDDL Planner**|Xiaopan Zhang et.al.|[2409.20560v1](http://arxiv.org/abs/2409.20560v1)|null|
|**2024-09-30**|**Maia-2: A Unified Model for Human-AI Alignment in Chess**|Zhenwei Tang et.al.|[2409.20553v1](http://arxiv.org/abs/2409.20553v1)|null|
|**2024-09-30**|**LLM Hallucinations in Practical Code Generation: Phenomena, Mechanism, and Mitigation**|Ziyao Zhang et.al.|[2409.20550v1](http://arxiv.org/abs/2409.20550v1)|null|
|**2024-09-30**|**Robi Butler: Remote Multimodal Interactions with Household Robot Assistant**|Anxing Xiao et.al.|[2409.20548v1](http://arxiv.org/abs/2409.20548v1)|null|
|**2024-09-30**|**Word Sense Disambiguation in Native Spanish: A Comprehensive Lexical Evaluation Resource**|Pablo Ortega et.al.|[2409.20524v1](http://arxiv.org/abs/2409.20524v1)|null|
|**2024-09-30**|**SMLE: Safe Machine Learning via Embedded Overapproximation**|Matteo Francobaldi et.al.|[2409.20517v1](http://arxiv.org/abs/2409.20517v1)|null|
|**2024-09-30**|**What Information Contributes to Log-based Anomaly Detection? Insights from a Configurable Transformer-Based Approach**|Xingfang Wu et.al.|[2409.20503v1](http://arxiv.org/abs/2409.20503v1)|null|
|**2024-09-30**|**COLLAGE: Collaborative Human-Agent Interaction Generation using Hierarchical Latent Diffusion and Language Models**|Divyanshu Daiya et.al.|[2409.20502v1](http://arxiv.org/abs/2409.20502v1)|null|
|**2024-09-30**|**Enhancing Romanian Offensive Language Detection through Knowledge Distillation, Multi-Task Learning, and Data Augmentation**|Vlad-Cristian Matei et.al.|[2409.20498v1](http://arxiv.org/abs/2409.20498v1)|null|
|**2024-09-30**|**RecSys Challenge 2024: Balancing Accuracy and Editorial Values in News Recommendations**|Johannes Kruse et.al.|[2409.20483v1](http://arxiv.org/abs/2409.20483v1)|null|
|**2024-09-30**|**A Weakly Supervised Data Labeling Framework for Machine Lexical Normalization in Vietnamese Social Media**|Dung Ha Nguyen et.al.|[2409.20467v1](http://arxiv.org/abs/2409.20467v1)|null|
|**2024-09-30**|**Language Resources in Spanish for Automatic Text Simplification across Domains**|Antonio Moreno-Sandoval et.al.|[2409.20466v1](http://arxiv.org/abs/2409.20466v1)|null|
|**2024-09-30**|**POMONAG: Pareto-Optimal Many-Objective Neural Architecture Generator**|Eugenio Lomurno et.al.|[2409.20447v1](http://arxiv.org/abs/2409.20447v1)|null|
|**2024-09-30**|**Instance-adaptive Zero-shot Chain-of-Thought Prompting**|Xiaosong Yuan et.al.|[2409.20441v2](http://arxiv.org/abs/2409.20441v2)|null|
|**2024-09-30**|**QAEncoder: Towards Aligned Representation Learning in Question Answering System**|Zhengren Wang et.al.|[2409.20434v1](http://arxiv.org/abs/2409.20434v1)|null|
|**2024-09-30**|**HELPD: Mitigating Hallucination of LVLMs by Hierarchical Feedback Learning with Vision-enhanced Penalty Decoding**|Fan Yuan et.al.|[2409.20429v1](http://arxiv.org/abs/2409.20429v1)|null|
|**2024-09-30**|**Sufficient and Necessary Explanations (and What Lies in Between)**|Beepul Bharti et.al.|[2409.20427v1](http://arxiv.org/abs/2409.20427v1)|null|
|**2024-09-30**|**World to Code: Multi-modal Data Generation via Self-Instructed Compositional Captioning and Filtering**|Jiacong Wang et.al.|[2409.20424v1](http://arxiv.org/abs/2409.20424v1)|null|
|**2024-09-30**|**Stream-level flow matching from a Bayesian decision theoretic perspective**|Ganchao Wei et.al.|[2409.20423v1](http://arxiv.org/abs/2409.20423v1)|null|
|**2024-09-30**|**Conformal Prediction for Dose-Response Models with Continuous Treatments**|Jarne Verhaeghe et.al.|[2409.20412v1](http://arxiv.org/abs/2409.20412v1)|null|
|**2024-09-30**|**Anti-stereotypical Predictive Text Suggestions Do Not Reliably Yield Anti-stereotypical Writing**|Connor Baumler et.al.|[2409.20390v1](http://arxiv.org/abs/2409.20390v1)|null|
|**2024-09-30**|**Wait, but Tylenol is Acetaminophen... Investigating and Improving Language Models' Ability to Resist Requests for Misinformation**|Shan Chen et.al.|[2409.20385v1](http://arxiv.org/abs/2409.20385v1)|null|
|**2024-09-30**|**Word-wise intonation model for cross-language TTS systems**|Tomilov A. A. et.al.|[2409.20374v1](http://arxiv.org/abs/2409.20374v1)|null|
|**2024-09-30**|**Frequency Adaptive Normalization For Non-stationary Time Series Forecasting**|Weiwei Ye et.al.|[2409.20371v1](http://arxiv.org/abs/2409.20371v1)|null|
|**2024-09-30**|**The Perfect Blend: Redefining RLHF with Mixture of Judges**|Tengyu Xu et.al.|[2409.20370v1](http://arxiv.org/abs/2409.20370v1)|null|
|**2024-09-30**|**Disentangling Singlish Discourse Particles with Task-Driven Representation**|Linus Tze En Foo et.al.|[2409.20366v1](http://arxiv.org/abs/2409.20366v1)|null|
|**2024-09-30**|**Efficient Driving Behavior Narration and Reasoning on Edge Device Using Large Language Models**|Yizhou Huang et.al.|[2409.20364v1](http://arxiv.org/abs/2409.20364v1)|null|
|**2024-09-30**|**Rotated Runtime Smooth: Training-Free Activation Smoother for accurate INT4 inference**|Ke Yi et.al.|[2409.20361v1](http://arxiv.org/abs/2409.20361v1)|null|
|**2024-09-30**|**Enhancing GANs with Contrastive Learning-Based Multistage Progressive Finetuning SNN and RL-Based External Optimization**|Osama Mustafa et.al.|[2409.20340v2](http://arxiv.org/abs/2409.20340v2)|null|
|**2024-09-30**|**Boosting Hybrid Autoregressive Transducer-based ASR with Internal Acoustic Model Training and Dual Blank Thresholding**|Takafumi Moriya et.al.|[2409.20313v1](http://arxiv.org/abs/2409.20313v1)|null|
|**2024-09-30**|**A Looming Replication Crisis in Evaluating Behavior in Language Models? Evidence and Solutions**|Laur√®ne Vaugrante et.al.|[2409.20303v1](http://arxiv.org/abs/2409.20303v1)|null|
|**2024-09-30**|**PersonalLLM: Tailoring LLMs to Individual Preferences**|Thomas P. Zollo et.al.|[2409.20296v1](http://arxiv.org/abs/2409.20296v1)|null|
|**2024-09-30**|**LexEval: A Comprehensive Chinese Legal Benchmark for Evaluating Large Language Models**|Haitao Li et.al.|[2409.20288v1](http://arxiv.org/abs/2409.20288v1)|[link](https://github.com/cshaitao/lexeval)|
|**2024-09-30**|**Computer-mediated therapies for stroke rehabilitation: a systematic review and meta-Analysis**|Stanley Mugisha. Mirko Job. Matteo Zoppi et.al.|[2409.20260v1](http://arxiv.org/abs/2409.20260v1)|null|
|**2024-09-30**|**What is the Role of Large Language Models in the Evolution of Astronomy Research?**|Morgan Fouesneau et.al.|[2409.20252v1](http://arxiv.org/abs/2409.20252v1)|null|
|**2024-09-30**|**Resource Allocation for Stable LLM Training in Mobile Edge Computing**|Chang Liu et.al.|[2409.20247v1](http://arxiv.org/abs/2409.20247v1)|null|
|**2024-09-30**|**Analysing Zero-Shot Readability-Controlled Sentence Simplification**|Abdullah Barayan et.al.|[2409.20246v1](http://arxiv.org/abs/2409.20246v1)|null|
|**2024-09-30**|**PsyGUARD: An Automated System for Suicide Detection and Risk Assessment in Psychological Counseling**|Huachuan Qiu et.al.|[2409.20243v1](http://arxiv.org/abs/2409.20243v1)|[link](https://github.com/qiuhuachuan/psyguard)|
|**2024-09-30**|**Beyond Prompts: Dynamic Conversational Benchmarking of Large Language Models**|David Castillo-Bolado et.al.|[2409.20222v1](http://arxiv.org/abs/2409.20222v1)|null|
|**2024-09-30**|**Divided by discipline? A systematic literature review on the quantification of online sexism and misogyny using a semi-automated approach**|Aditi Dutta et.al.|[2409.20204v1](http://arxiv.org/abs/2409.20204v1)|null|
|**2024-09-30**|**AfriHuBERT: A self-supervised speech representation model for African languages**|Jesujoba O. Alabi et.al.|[2409.20201v1](http://arxiv.org/abs/2409.20201v1)|null|
|**2024-09-30**|**Melody Is All You Need For Music Generation**|Shaopeng Wei et.al.|[2409.20196v1](http://arxiv.org/abs/2409.20196v1)|[link](https://github.com/shaopengw/Awesome-Music-Generation)|
|**2024-09-30**|**Forecasting Disease Progression with Parallel Hyperplanes in Longitudinal Retinal OCT**|Arunava Chakravarty et.al.|[2409.20195v1](http://arxiv.org/abs/2409.20195v1)|null|
|**2024-09-30**|**Factory Operators' Perspectives on Cognitive Assistants for Knowledge Sharing: Challenges, Risks, and Impact on Work**|Samuel Kernan Freire et.al.|[2409.20192v1](http://arxiv.org/abs/2409.20192v1)|null|
|**2024-09-30**|**TaskComplexity: A Dataset for Task Complexity Classification with In-Context Learning, FLAN-T5 and GPT-4o Benchmarks**|Areeg Fahad Rasheed et.al.|[2409.20189v1](http://arxiv.org/abs/2409.20189v1)|[link](https://github.com/AREEG94FAHAD/TaskComplexityEval-24)|
|**2024-09-30**|**Choosing DAG Models Using Markov and Minimal Edge Count in the Absence of Ground Truth**|Joseph D. Ramsey et.al.|[2409.20187v1](http://arxiv.org/abs/2409.20187v1)|null|
|**2024-09-30**|**Reference Trustable Decoding: A Training-Free Augmentation Paradigm for Large Language Models**|Luohe Shi et.al.|[2409.20181v1](http://arxiv.org/abs/2409.20181v1)|null|
|**2024-09-30**|**Modelando procesos cognitivos de la lectura natural con GPT-2**|Bruno Bianchi et.al.|[2409.20174v1](http://arxiv.org/abs/2409.20174v1)|null|
|**2024-09-30**|**Using Large Multimodal Models to Extract Knowledge Components for Knowledge Tracing from Multimedia Question Information**|Hyeongdon Moon et.al.|[2409.20167v1](http://arxiv.org/abs/2409.20167v1)|null|
|**2024-09-30**|**How Entangled is Factuality and Deception in German?**|Aswathy Velutharambath et.al.|[2409.20165v1](http://arxiv.org/abs/2409.20165v1)|null|
|**2024-09-30**|**MemSim: A Bayesian Simulator for Evaluating Memory of LLM-based Personal Assistants**|Zeyu Zhang et.al.|[2409.20163v1](http://arxiv.org/abs/2409.20163v1)|[link](https://github.com/nuster1128/memsim)|
|**2024-09-30**|**1 Trillion Token (1TT) Platform: A Novel Framework for Efficient Data Sharing and Compensation in Large Language Models**|Chanjun Park et.al.|[2409.20149v1](http://arxiv.org/abs/2409.20149v1)|null|
|**2024-09-30**|**Classification of Radiological Text in Small and Imbalanced Datasets in a Non-English Language**|Vincent Beliveau et.al.|[2409.20147v1](http://arxiv.org/abs/2409.20147v1)|null|
|**2024-09-30**|**Federated Instruction Tuning of LLMs with Domain Coverage Augmentation**|Zezhou Wang et.al.|[2409.20135v2](http://arxiv.org/abs/2409.20135v2)|null|
|**2024-09-30**|**ACE: Abstractions for Communicating Efficiently**|Jonathan D. Thomas et.al.|[2409.20120v1](http://arxiv.org/abs/2409.20120v1)|null|
|**2024-09-30**|**Aggressive Post-Training Compression on Extremely Large Language Models**|Zining Zhang et.al.|[2409.20094v1](http://arxiv.org/abs/2409.20094v1)|null|
|**2024-09-30**|**Robust LLM safeguarding via refusal feature adversarial training**|Lei Yu et.al.|[2409.20089v1](http://arxiv.org/abs/2409.20089v1)|null|
|**2024-09-30**|**BSharedRAG: Backbone Shared Retrieval-Augmented Generation for the E-commerce Domain**|Kaisi Guan et.al.|[2409.20075v1](http://arxiv.org/abs/2409.20075v1)|null|
|**2024-09-30**|**Knowledge Discovery using Unsupervised Cognition**|Alfredo Ibias et.al.|[2409.20064v1](http://arxiv.org/abs/2409.20064v1)|null|
|**2024-09-30**|**Is Preference Alignment Always the Best Option to Enhance LLM-Based Translation? An Empirical Analysis**|Hippolyte Gisserot-Boukhlef et.al.|[2409.20059v1](http://arxiv.org/abs/2409.20059v1)|null|
|**2024-09-30**|**Evaluating and explaining training strategies for zero-shot cross-lingual news sentiment analysis**|Luka Andren≈°ek et.al.|[2409.20054v1](http://arxiv.org/abs/2409.20054v1)|null|
|**2024-09-30**|**GUNDAM: Aligning Large Language Models with Graph Understanding**|Sheng Ouyang et.al.|[2409.20053v1](http://arxiv.org/abs/2409.20053v1)|null|
|**2024-09-30**|**Mitigating Propensity Bias of Large Language Models for Recommender Systems**|Guixian Zhang et.al.|[2409.20052v1](http://arxiv.org/abs/2409.20052v1)|null|
|**2024-09-30**|**Depression detection in social media posts using transformer-based models and auxiliary features**|Marios Kerasiotis et.al.|[2409.20048v1](http://arxiv.org/abs/2409.20048v1)|null|
|**2024-09-30**|**Beyond Scores: A Modular RAG-Based System for Automatic Short Answer Scoring with Feedback**|Menna Fateen et.al.|[2409.20042v1](http://arxiv.org/abs/2409.20042v1)|null|
|**2024-09-30**|**Towards Robust Multimodal Sentiment Analysis with Incomplete Data**|Haoyu Zhang et.al.|[2409.20012v1](http://arxiv.org/abs/2409.20012v1)|null|
|**2024-09-30**|**Customized Information and Domain-centric Knowledge Graph Construction with Large Language Models**|Frank Wawrzik et.al.|[2409.20010v1](http://arxiv.org/abs/2409.20010v1)|null|
|**2024-09-30**|**Developing Instruction-Following Speech Language Model Without Speech Instruction-Tuning Data**|Ke-Han Lu et.al.|[2409.20007v1](http://arxiv.org/abs/2409.20007v1)|null|
|**2024-09-30**|**Model Selection with a Shapelet-based Distance Measure for Multi-source Transfer Learning in Time Series Classification**|Jiseok Lee et.al.|[2409.20005v1](http://arxiv.org/abs/2409.20005v1)|null|
|**2024-09-30**|**Do Influence Functions Work on Large Language Models?**|Zhe Li et.al.|[2409.19998v1](http://arxiv.org/abs/2409.19998v1)|null|
|**2024-09-30**|**Mitigating Backdoor Threats to Large Language Models: Advancement and Challenges**|Qin Liu et.al.|[2409.19993v1](http://arxiv.org/abs/2409.19993v1)|null|
|**2024-09-30**|**Predictive Speech Recognition and End-of-Utterance Detection Towards Spoken Dialog Systems**|Oswald Zink et.al.|[2409.19990v1](http://arxiv.org/abs/2409.19990v1)|null|
|**2024-09-30**|**CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models**|Eitan Wagner et.al.|[2409.19984v1](http://arxiv.org/abs/2409.19984v1)|null|
|**2024-09-30**|**Enhancing High-order Interaction Awareness in LLM-based Recommender Model**|Xinfeng Wang et.al.|[2409.19979v2](http://arxiv.org/abs/2409.19979v2)|[link](https://github.com/WangXFng/ELMRec)|
|**2024-09-30**|**Knowledge Graph Embedding by Normalizing Flows**|Changyi Xiao et.al.|[2409.19977v1](http://arxiv.org/abs/2409.19977v1)|[link](https://github.com/changyi7231/nfe)|
|**2024-09-30**|**Multimodal LLM Enhanced Cross-lingual Cross-modal Retrieval**|Yabing Wang et.al.|[2409.19961v1](http://arxiv.org/abs/2409.19961v1)|null|
|**2024-09-30**|**TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning**|Joshua Feinglass et.al.|[2409.19960v1](http://arxiv.org/abs/2409.19960v1)|null|
|**2024-09-30**|**Attribute-Text Guided Forgetting Compensation for Lifelong Person Re-Identification**|Shiben Liu et.al.|[2409.19954v1](http://arxiv.org/abs/2409.19954v1)|null|
|**2024-09-30**|**Law of the Weakest Link: Cross Capabilities of Large Language Models**|Ming Zhong et.al.|[2409.19951v1](http://arxiv.org/abs/2409.19951v1)|[link](https://github.com/facebookresearch/llm-cross-capabilities)|
|**2024-09-30**|**Task-agnostic Pre-training and Task-guided Fine-tuning for Versatile Diffusion Planner**|Chenyou Fan et.al.|[2409.19949v1](http://arxiv.org/abs/2409.19949v1)|null|
|**2024-09-30**|**JaPOC: Japanese Post-OCR Correction Benchmark using Vouchers**|Masato Fujitake et.al.|[2409.19948v1](http://arxiv.org/abs/2409.19948v1)|null|
|**2024-09-30**|**Positive-Sum Fairness: Leveraging Demographic Attributes to Achieve Fair AI Outcomes Without Sacrificing Group Gains**|Samia Belhadj et.al.|[2409.19940v1](http://arxiv.org/abs/2409.19940v1)|null|
|**2024-09-30**|**Large Language Model Empowered Embedding Generator for Sequential Recommendation**|Qidong Liu et.al.|[2409.19925v1](http://arxiv.org/abs/2409.19925v1)|null|
|**2024-09-30**|**On The Planning Abilities of OpenAI's o1 Models: Feasibility, Optimality, and Generalizability**|Kevin Wang et.al.|[2409.19924v2](http://arxiv.org/abs/2409.19924v2)|[link](https://github.com/vita-group/o1-planning)|
|**2024-09-30**|**Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Object-Oriented Programming**|Ming Li et.al.|[2409.19916v1](http://arxiv.org/abs/2409.19916v1)|null|
|**2024-09-30**|**Scaling Optimal LR Across Token Horizon**|Johan Bjorck et.al.|[2409.19913v1](http://arxiv.org/abs/2409.19913v1)|null|
|**2024-09-30**|**UniSumEval: Towards Unified, Fine-Grained, Multi-Dimensional Summarization Evaluation for LLMs**|Yuho Lee et.al.|[2409.19898v2](http://arxiv.org/abs/2409.19898v2)|[link](https://github.com/disl-lab/unisumeval-v1.0)|
|**2024-09-30**|**TRANSAGENT: An LLM-Based Multi-Agent System for Code Translation**|Zhiqiang Yuan et.al.|[2409.19894v2](http://arxiv.org/abs/2409.19894v2)|null|
|**2024-09-30**|**RouterDC: Query-Based Router by Dual Contrastive Learning for Assembling Large Language Models**|Shuhao Chen et.al.|[2409.19886v1](http://arxiv.org/abs/2409.19886v1)|[link](https://github.com/shuhao02/routerdc)|
|**2024-09-30**|**SWIM: Short-Window CNN Integrated with Mamba for EEG-Based Auditory Spatial Attention Decoding**|Ziyang Zhang et.al.|[2409.19884v1](http://arxiv.org/abs/2409.19884v1)|[link](https://github.com/windowso/swim-asad)|
|**2024-09-30**|**Contrastive Token Learning with Similarity Decay for Repetition Suppression in Machine Translation**|Huangyu Dai et.al.|[2409.19877v1](http://arxiv.org/abs/2409.19877v1)|null|
|**2024-09-30**|**TSI: A Multi-View Representation Learning Approach for Time Series Forecasting**|Wentao Gao et.al.|[2409.19871v1](http://arxiv.org/abs/2409.19871v1)|null|
|**2024-09-30**|**The Construction of Instruction-tuned LLMs for Finance without Instruction Data Using Continual Pretraining and Model Merging**|Masanori Hirano et.al.|[2409.19854v1](http://arxiv.org/abs/2409.19854v1)|null|
|**2024-09-30**|**ForecastBench: A Dynamic Benchmark of AI Forecasting Capabilities**|Ezra Karger et.al.|[2409.19839v1](http://arxiv.org/abs/2409.19839v1)|null|
|**2024-09-29**|**Counterfactual Evaluation of Ads Ranking Models through Domain Adaptation**|Mohamed A. Radwan et.al.|[2409.19824v1](http://arxiv.org/abs/2409.19824v1)|null|
|**2024-09-29**|**Calibrating Language Models with Adaptive Temperature Scaling**|Johnathan Xie et.al.|[2409.19817v1](http://arxiv.org/abs/2409.19817v1)|null|
|**2024-09-29**|**Grounded Curriculum Learning**|Linji Wang et.al.|[2409.19816v1](http://arxiv.org/abs/2409.19816v1)|null|
|**2024-09-29**|**Transforming Hidden States into Binary Semantic Features**|Tom√°≈° Musil et.al.|[2409.19813v1](http://arxiv.org/abs/2409.19813v1)|null|

#### Abstracts
##### **MM1.5: Methods, Analysis & Insights from Multimodal LLM Fine-tuning**
2409.20566v1 by Haotian Zhang, Mingfei Gao, Zhe Gan, Philipp Dufter, Nina Wenzel, Forrest Huang, Dhruti Shah, Xianzhi Du, Bowen Zhang, Yanghao Li, Sam Dodge, Keen You, Zhen Yang, Aleksei Timofeev, Mingze Xu, Hong-You Chen, Jean-Philippe Fauconnier, Zhengfeng Lai, Haoxuan You, Zirui Wang, Afshin Dehghan, Peter Grasch, Yinfei Yang

We present MM1.5, a new family of multimodal large language models (MLLMs)
designed to enhance capabilities in text-rich image understanding, visual
referring and grounding, and multi-image reasoning. Building upon the MM1
architecture, MM1.5 adopts a data-centric approach to model training,
systematically exploring the impact of diverse data mixtures across the entire
model training lifecycle. This includes high-quality OCR data and synthetic
captions for continual pre-training, as well as an optimized visual
instruction-tuning data mixture for supervised fine-tuning. Our models range
from 1B to 30B parameters, encompassing both dense and mixture-of-experts (MoE)
variants, and demonstrate that careful data curation and training strategies
can yield strong performance even at small scales (1B and 3B). Additionally, we
introduce two specialized variants: MM1.5-Video, designed for video
understanding, and MM1.5-UI, tailored for mobile UI understanding. Through
extensive empirical studies and ablations, we provide detailed insights into
the training processes and decisions that inform our final designs, offering
valuable guidance for future research in MLLM development.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫ MM1.5Ôºå‰∏ÄÁ®ÆÊñ∞ÁöÑÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) ÂÆ∂ÊóèÔºåÊó®Âú®Â¢ûÂº∑ÊñáÊú¨Ë±êÂØåÂΩ±ÂÉèÁêÜËß£„ÄÅË¶ñË¶∫ÊåáÊ∂âÂíåÂü∫Á§éÔºå‰ª•ÂèäÂ§öÂΩ±ÂÉèÊé®ÁêÜÁöÑËÉΩÂäõ„ÄÇÂú® MM1 Êû∂ÊßãÁöÑÂü∫Á§é‰∏äÔºåMM1.5 Êé°Áî®‰ª•Ë≥áÊñôÁÇ∫‰∏≠ÂøÉÁöÑÊ®°ÂûãË®ìÁ∑¥ÊñπÊ≥ïÔºåÁ≥ªÁµ±ÊÄßÂú∞Êé¢Ë®éÂêÑÁ®ÆË≥áÊñôÊ∑∑ÂêàÂ∞çÊï¥ÂÄãÊ®°ÂûãË®ìÁ∑¥ÁîüÂëΩÈÄ±ÊúüÁöÑÂΩ±Èüø„ÄÇÈÄôÂåÖÊã¨Áî®ÊñºÊåÅÁ∫åÈ†êË®ìÁ∑¥ÁöÑÈ´òÂìÅË≥™ OCR Ë≥áÊñôÂíåÂêàÊàêÂºèÂ≠óÂπïÔºå‰ª•ÂèäÁî®ÊñºÁõ£Áù£ÂæÆË™øÁöÑÊúÄ‰Ω≥ÂåñË¶ñË¶∫Êåá‰ª§Ë™øÊ†°Ë≥áÊñôÊ∑∑Âêà„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÁØÑÂúçÂæû 1B Âà∞ 30B ÂèÉÊï∏ÔºåÂåÖÂê´ÂØÜÈõÜÂíåÂ∞àÂÆ∂Ê∑∑Âêà (MoE) ËÆäÈ´îÔºå‰∏¶Ë≠âÊòé‰ªîÁ¥∞ÁöÑË≥áÊñôÁ≠ñÂ±ïÂíåË®ìÁ∑¥Á≠ñÁï•Âç≥‰ΩøÂú®Â∞èË¶èÊ®° (1B Âíå 3B) ‰∏ã‰πüËÉΩÁî¢ÁîüÂº∑Â§ßÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑÂºïÂÖ•‰∫ÜÂÖ©ÂÄãÂ∞àÈñÄÁöÑËÆäÈ´îÔºöMM1.5-VideoÔºåÂ∞àÁÇ∫ÂΩ±ÁâáÁêÜËß£ËÄåË®≠Ë®àÔºå‰ª•Âèä MM1.5-UIÔºåÂ∞àÁÇ∫Ë°åÂãïË£ùÁΩÆ UI ÁêÜËß£ËÄåË®≠Ë®à„ÄÇÈÄèÈÅéÂª£Ê≥õÁöÑÂØ¶Ë≠âÁ†îÁ©∂ÂíåÊ∂àËûçÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÂ∞çË®ìÁ∑¥ÊµÅÁ®ãÂíåÊ±∫Á≠ñÁöÑË©≥Á¥∞Ë¶ãËß£ÔºåÈÄô‰∫õË¶ãËß£Ë™™Êòé‰∫ÜÊàëÂÄëÁöÑÊúÄÁµÇË®≠Ë®àÔºåÁÇ∫ MLLM ÈñãÁôºÁöÑÊú™‰æÜÁ†îÁ©∂Êèê‰æõ‰∫ÜÂØ∂Ë≤¥ÁöÑÊåáÂ∞é„ÄÇ

##### **Ranking Over Scoring: Towards Reliable and Robust Automated Evaluation of LLM-Generated Medical Explanatory Arguments**
2409.20565v1 by Iker De la Iglesia, Iakes Goenaga, Johanna Ramirez-Romero, Jose Maria Villa-Gonzalez, Josu Goikoetxea, Ander Barrena

Evaluating LLM-generated text has become a key challenge, especially in
domain-specific contexts like the medical field. This work introduces a novel
evaluation methodology for LLM-generated medical explanatory arguments, relying
on Proxy Tasks and rankings to closely align results with human evaluation
criteria, overcoming the biases typically seen in LLMs used as judges. We
demonstrate that the proposed evaluators are robust against adversarial
attacks, including the assessment of non-argumentative text. Additionally, the
human-crafted arguments needed to train the evaluators are minimized to just
one example per Proxy Task. By examining multiple LLM-generated arguments, we
establish a methodology for determining whether a Proxy Task is suitable for
evaluating LLM-generated medical explanatory arguments, requiring only five
examples and two human experts.

ÊëòË¶ÅÔºöË©ï‰º∞ LLM ÁîüÊàêÁöÑÊñáÂ≠óÂ∑≤ÊàêÁÇ∫‰∏ÄÈ†ÖÈóúÈçµÊåëÊà∞ÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇÈ†òÂüüÁ≠âÁâπÂÆöÈ†òÂüü‰∏≠„ÄÇÈÄôÈ†ÖÂ∑•‰Ωú‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÈáùÂ∞ç LLM ÁîüÊàêÁöÑÈÜ´Â≠∏Ëß£ÈáãÊÄßË´ñÈªûÁöÑÊñ∞Á©éË©ï‰º∞ÊñπÊ≥ïÔºå‰æùË≥¥‰ª£ÁêÜ‰ªªÂãôÂíåÊéíÂêçÔºå‰ª•Â∞áÁµêÊûúËàá‰∫∫È°ûË©ï‰º∞Ê®ôÊ∫ñÁ∑äÂØÜÂ∞çÈΩäÔºåÂÖãÊúç‰∫ÜÈÄöÂ∏∏Âú®Áî®‰ΩúË©ïÂà§ÁöÑ LLM ‰∏≠ÁúãÂà∞ÁöÑÂÅèÂ∑Æ„ÄÇÊàëÂÄëË≠âÊòé‰∫ÜÊâÄÊèêÂá∫ÁöÑË©ï‰º∞Âì°Â∞çÂ∞çÊäóÊÄßÊîªÊìäÂÖ∑ÊúâÈ≠ØÊ£íÊÄßÔºåÂåÖÊã¨Â∞çÈùûË´ñË≠âÊÄßÊñáÂ≠óÁöÑË©ï‰º∞„ÄÇÊ≠§Â§ñÔºåË®ìÁ∑¥Ë©ï‰º∞Âì°ÊâÄÈúÄÁöÑ‰∫∫Â∑•Ë´ñË≠âÂ∑≤ÊúÄÂ∞èÂåñÔºåÊØèÂÄã‰ª£ÁêÜ‰ªªÂãôÂÉÖ‰∏ÄÂÄãÁØÑ‰æã„ÄÇÈÄöÈÅéÊ™¢Êü•Â§öÂÄã LLM ÁîüÊàêÁöÑË´ñÈªûÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ï‰æÜÁ¢∫ÂÆö‰ª£ÁêÜ‰ªªÂãôÊòØÂê¶ÈÅ©ÂêàË©ï‰º∞ LLM ÁîüÊàêÁöÑÈÜ´Â≠∏Ëß£ÈáãÊÄßË´ñÈªûÔºåÂè™ÈúÄË¶Å‰∫îÂÄãÁØÑ‰æãÂíåÂÖ©‰Ωç‰∫∫È°ûÂ∞àÂÆ∂„ÄÇ

##### **LaMMA-P: Generalizable Multi-Agent Long-Horizon Task Allocation and Planning with LM-Driven PDDL Planner**
2409.20560v1 by Xiaopan Zhang, Hao Qin, Fuquan Wang, Yue Dong, Jiachen Li

Language models (LMs) possess a strong capability to comprehend natural
language, making them effective in translating human instructions into detailed
plans for simple robot tasks. Nevertheless, it remains a significant challenge
to handle long-horizon tasks, especially in subtask identification and
allocation for cooperative heterogeneous robot teams. To address this issue, we
propose a Language Model-Driven Multi-Agent PDDL Planner (LaMMA-P), a novel
multi-agent task planning framework that achieves state-of-the-art performance
on long-horizon tasks. LaMMA-P integrates the strengths of the LMs' reasoning
capability and the traditional heuristic search planner to achieve a high
success rate and efficiency while demonstrating strong generalization across
tasks. Additionally, we create MAT-THOR, a comprehensive benchmark that
features household tasks with two different levels of complexity based on the
AI2-THOR environment. The experimental results demonstrate that LaMMA-P
achieves a 105% higher success rate and 36% higher efficiency than existing
LM-based multi-agent planners. The experimental videos, code, and datasets of
this work as well as the detailed prompts used in each module are available at
https://lamma-p.github.io.

ÊëòË¶ÅÔºöË™ûË®ÄÊ®°Âûã (LM) ÊìÅÊúâÂº∑Â§ßÁöÑÁêÜËß£Ëá™ÁÑ∂Ë™ûË®ÄÁöÑËÉΩÂäõÔºåÈÄô‰ΩøÂæóÂÆÉÂÄëËÉΩÂ§†ÊúâÊïàÂú∞Â∞á‰∫∫È°ûÊåá‰ª§ËΩâÊèõÁÇ∫Á∞°ÂñÆÊ©üÂô®‰∫∫‰ªªÂãôÁöÑË©≥Á¥∞Ë®àÁï´„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåËôïÁêÜÈï∑Êúü‰ªªÂãô‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞ÔºåÁâπÂà•ÊòØÂú®Âêà‰ΩúÁï∞Ë≥™Ê©üÂô®‰∫∫ÂúòÈöäÁöÑÂ≠ê‰ªªÂãôË≠òÂà•ÂíåÂàÜÈÖçÊñπÈù¢„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãË™ûË®ÄÊ®°ÂûãÈ©ÖÂãïÁöÑÂ§ö‰ª£ÁêÜ PDDL Ë®àÁï´Âô® (LaMMA-P)ÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÂ§ö‰ª£ÁêÜ‰ªªÂãôË®àÁï´Ê°ÜÊû∂ÔºåÂú®Èï∑Êúü‰ªªÂãô‰∏äÂØ¶Áèæ‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇLaMMA-P Êï¥Âêà‰∫Ü LM Êé®ÁêÜËÉΩÂäõÂíåÂÇ≥Áµ±ÂïüÁôºÂºèÊêúÂ∞ãË®àÁï´Âô®ÁöÑÂÑ™Âã¢Ôºå‰ª•ÂØ¶ÁèæÈ´òÊàêÂäüÁéáÂíåÊïàÁéáÔºåÂêåÊôÇÂú®ÂêÑÈ†Ö‰ªªÂãô‰∏≠Â±ïÁèæÂá∫Âº∑Â§ßÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü MAT-THORÔºå‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶ÔºåÂÆÉÂÖ∑ÊúâÂü∫Êñº AI2-THOR Áí∞Â¢ÉÁöÑÂÖ©ÂÄã‰∏çÂêåË§áÈõúÁ®ãÂ∫¶ÁöÑÂÆ∂Âãô‰ªªÂãô„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåËàáÁèæÊúâÁöÑÂü∫Êñº LM ÁöÑÂ§ö‰ª£ÁêÜË®àÁï´Âô®Áõ∏ÊØîÔºåLaMMA-P ÁöÑÊàêÂäüÁéáÊèêÈ´ò‰∫Ü 105%ÔºåÊïàÁéáÊèêÈ´ò‰∫Ü 36%„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁöÑÂØ¶È©óÂΩ±Áâá„ÄÅÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜ‰ª•ÂèäÊØèÂÄãÊ®°ÁµÑ‰∏≠‰ΩøÁî®ÁöÑË©≥Á¥∞ÊèêÁ§∫ÈÉΩÂèØ‰ª•Âú® https://lamma-p.github.io/ Áç≤Âæó„ÄÇ

##### **Maia-2: A Unified Model for Human-AI Alignment in Chess**
2409.20553v1 by Zhenwei Tang, Difan Jiao, Reid McIlroy-Young, Jon Kleinberg, Siddhartha Sen, Ashton Anderson

There are an increasing number of domains in which artificial intelligence
(AI) systems both surpass human ability and accurately model human behavior.
This introduces the possibility of algorithmically-informed teaching in these
domains through more relatable AI partners and deeper insights into human
decision-making. Critical to achieving this goal, however, is coherently
modeling human behavior at various skill levels. Chess is an ideal model system
for conducting research into this kind of human-AI alignment, with its rich
history as a pivotal testbed for AI research, mature superhuman AI systems like
AlphaZero, and precise measurements of skill via chess rating systems. Previous
work in modeling human decision-making in chess uses completely independent
models to capture human style at different skill levels, meaning they lack
coherence in their ability to adapt to the full spectrum of human improvement
and are ultimately limited in their effectiveness as AI partners and teaching
tools. In this work, we propose a unified modeling approach for human-AI
alignment in chess that coherently captures human style across different skill
levels and directly captures how people improve. Recognizing the complex,
non-linear nature of human learning, we introduce a skill-aware attention
mechanism to dynamically integrate players' strengths with encoded chess
positions, enabling our model to be sensitive to evolving player skill. Our
experimental results demonstrate that this unified framework significantly
enhances the alignment between AI and human players across a diverse range of
expertise levels, paving the way for deeper insights into human decision-making
and AI-guided teaching tools.

ÊëòË¶ÅÔºö<paragraph>Âú®‰∫∫Â∑•Êô∫ËÉΩÔºàAIÔºâÁ≥ªÁµ±Êó¢Ë∂ÖË∂ä‰∫∫È°ûËÉΩÂäõÔºåÂèàËÉΩÊ∫ñÁ¢∫Ê®°Êì¨‰∫∫È°ûË°åÁÇ∫ÁöÑÈ†òÂüü‰∏≠ÔºåÊï∏ÈáèÊ≠£‰∏çÊñ∑Â¢ûÂä†„ÄÇÈÄôÂºïÂÖ•‰∫ÜÂú®ÈÄô‰∫õÈ†òÂüü‰∏≠ÈÄöÈÅéÊõ¥ÂÖ∑ÈóúËÅØÊÄßÁöÑ AI Âêà‰ΩúÂ§•‰º¥ÂíåÊõ¥Ê∑±ÂÖ•ÁöÑ‰∫∫È°ûÊ±∫Á≠ñÂà∂ÂÆöË¶ãËß£ÔºåÈÄ≤Ë°åÊºîÁÆóÊ≥ïÁü•ÊÉÖÊïôÂ≠∏ÁöÑÂèØËÉΩÊÄß„ÄÇÁÑ∂ËÄåÔºåÂØ¶ÁèæÊ≠§ÁõÆÊ®ôÁöÑÈóúÈçµÂú®Êñº‰ª•ÈÄ£Ë≤´ÁöÑÊñπÂºèÊ®°Êì¨‰∏çÂêåÊäÄËÉΩÁ¥öÂà•ÁöÑ‰∫∫È°ûË°åÁÇ∫„ÄÇË•øÊ¥ãÊ£ãÊòØ‰∏ÄÂÄãÁêÜÊÉ≥ÁöÑÊ®°ÂûãÁ≥ªÁµ±ÔºåÂèØÁî®ÊñºÂ∞çÊ≠§È°û‰∫∫Ê©üÂ∞çÈΩäÈÄ≤Ë°åÁ†îÁ©∂ÔºåÂÆÉ‰ΩúÁÇ∫ AI Á†îÁ©∂ÁöÑÈóúÈçµÊ∏¨Ë©¶Âπ≥Âè∞ÔºåÊìÅÊúâË±êÂØåÁöÑÊ≠∑Âè≤ÔºåÊàêÁÜüÁöÑË∂Ö‰∫∫È°û AI Á≥ªÁµ±Ôºå‰æãÂ¶Ç AlphaZeroÔºå‰ª•ÂèäÈÄöÈÅéË•øÊ¥ãÊ£ãË©ïÂàÜÁ≥ªÁµ±ÈÄ≤Ë°åÁöÑÁ≤æÁ¢∫ÊäÄËÉΩÊ∏¨Èáè„ÄÇÂÖàÂâçÂú®Ë•øÊ¥ãÊ£ã‰∏≠Ê®°Êì¨‰∫∫È°ûÊ±∫Á≠ñÂà∂ÂÆöÁöÑÂ∑•‰Ωú‰ΩøÁî®ÂÆåÂÖ®Áç®Á´ãÁöÑÊ®°Âûã‰æÜÊçïÊçâ‰∏çÂêåÊäÄËÉΩÁ¥öÂà•ÁöÑ‰∫∫È°ûÈ¢®Ê†ºÔºåÈÄôË°®Á§∫ÂÆÉÂÄëÂú®ÈÅ©Êáâ‰∫∫È°ûÈÄ≤Ê≠•ÂÖ®ÂÖâË≠úÁöÑËÉΩÂäõ‰∏äÁº∫‰πèÈÄ£Ë≤´ÊÄßÔºå‰∏¶‰∏îÊúÄÁµÇÂú®‰ΩúÁÇ∫ AI Âêà‰ΩúÂ§•‰º¥ÂíåÊïôÂ≠∏Â∑•ÂÖ∑ÊñπÈù¢ÁöÑÊïàËÉΩÂèóÂà∞ÈôêÂà∂„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁµ±‰∏ÄÁöÑÂª∫Ê®°ÊñπÊ≥ïÔºåÁî®ÊñºË•øÊ¥ãÊ£ã‰∏≠ÁöÑ‰∫∫Ê©üÂ∞çÈΩäÔºåÂÆÉ‰ª•ÈÄ£Ë≤´ÁöÑÊñπÂºèÊçïÊçâ‰∏çÂêåÊäÄËÉΩÁ¥öÂà•ÁöÑ‰∫∫È°ûÈ¢®Ê†ºÔºå‰∏¶Áõ¥Êé•ÊçïÊçâ‰∫∫ÂÄëÂ¶Ç‰ΩïÈÄ≤Ê≠•„ÄÇË™çË≠òÂà∞‰∫∫È°ûÂ≠∏ÁøíÁöÑË§áÈõú„ÄÅÈùûÁ∑öÊÄßÊú¨Ë≥™ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊäÄËÉΩÊÑüÁü•Ê≥®ÊÑèÂäõÊ©üÂà∂Ôºå‰ª•ÂãïÊÖãÊï¥ÂêàÁé©ÂÆ∂ÁöÑÂÑ™Âã¢ËàáÁ∑®Á¢ºË•øÊ¥ãÊ£ã‰ΩçÁΩÆÔºå‰ΩøÊàëÂÄëÁöÑÊ®°ÂûãËÉΩÂ§†Â∞ç‰∏çÊñ∑ËÆäÂåñÁöÑÁé©ÂÆ∂ÊäÄËÉΩÂÅöÂá∫ÂèçÊáâ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÈÄôÂÄãÁµ±‰∏ÄÁöÑÊ°ÜÊû∂È°ØËëóÂ¢ûÂº∑‰∫Ü AI Âíå‰∫∫È°ûÁé©ÂÆ∂Âú®ÂêÑÁ®ÆÂ∞àÊ•≠Á¥öÂà•‰πãÈñìÁöÑÂ∞çÈΩäÔºåÁÇ∫Êõ¥Ê∑±ÂÖ•‰∫ÜËß£‰∫∫È°ûÊ±∫Á≠ñÂà∂ÂÆöÂíå AI ÊåáÂ∞éÁöÑÊïôÂ≠∏Â∑•ÂÖ∑Èã™Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ</paragraph>

##### **LLM Hallucinations in Practical Code Generation: Phenomena, Mechanism, and Mitigation**
2409.20550v1 by Ziyao Zhang, Yanlin Wang, Chong Wang, Jiachi Chen, Zibin Zheng

Code generation aims to automatically generate code from input requirements,
significantly enhancing development efficiency. Recent large language models
(LLMs) based approaches have shown promising results and revolutionized code
generation task. Despite the promising performance, LLMs often generate
contents with hallucinations, especially for the code generation scenario
requiring the handling of complex contextual dependencies in practical
development process. Although previous study has analyzed hallucinations in
LLM-powered code generation, the study is limited to standalone function
generation. In this paper, we conduct an empirical study to study the
phenomena, mechanism, and mitigation of LLM hallucinations within more
practical and complex development contexts in repository-level generation
scenario. First, we manually examine the code generation results from six
mainstream LLMs to establish a hallucination taxonomy of LLM-generated code.
Next, we elaborate on the phenomenon of hallucinations, analyze their
distribution across different models. We then analyze causes of hallucinations
and identify four potential factors contributing to hallucinations. Finally, we
propose an RAG-based mitigation method, which demonstrates consistent
effectiveness in all studied LLMs. The replication package including code,
data, and experimental results is available at
https://github.com/DeepSoftwareAnalytics/LLMCodingHallucination

ÊëòË¶ÅÔºöÁ®ãÂºèÁ¢ºÁîüÊàêÊó®Âú®Ê†πÊìöËº∏ÂÖ•ÈúÄÊ±ÇËá™ÂãïÁî¢ÁîüÁ®ãÂºèÁ¢ºÔºåÂ§ßÂπÖÊèêÂçáÈñãÁôºÊïàÁéá„ÄÇÊúÄËøëÂü∫ÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊñπÊ≥ïÂ∑≤Â±ïÁèæÂá∫ÊúâÂ∏åÊúõÁöÑÊàêÊûúÔºå‰∏¶ÂæπÂ∫ïÊîπËÆä‰∫ÜÁ®ãÂºèÁ¢ºÁîüÊàê‰ªªÂãô„ÄÇÂÑòÁÆ°Êúâ‰ª§‰∫∫ÊúüÂæÖÁöÑÊïàËÉΩÔºåLLM Á∂ìÂ∏∏ÊúÉÁî¢ÁîüÂåÖÂê´ÂπªË¶∫ÁöÑÂÖßÂÆπÔºåÁâπÂà•ÊòØÂú®Á®ãÂºèÁ¢ºÁîüÊàêÂ†¥ÊôØÔºåÈúÄË¶ÅËôïÁêÜÂØ¶ÈöõÈñãÁôºÈÅéÁ®ã‰∏≠Ë§áÈõúÁöÑÂÖßÂÆπÁõ∏ÈóúÊÄß„ÄÇÂÑòÁÆ°ÂÖàÂâçÁöÑÁ†îÁ©∂Â∑≤ÂàÜÊûê LLM È©ÖÂãïÁöÑÁ®ãÂºèÁ¢ºÁîüÊàê‰∏≠ÁöÑÂπªË¶∫Ôºå‰ΩÜÁ†îÁ©∂ÂÉÖÈôêÊñºÁç®Á´ãÂáΩÂºèÁîüÊàê„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄ≤Ë°å‰∏ÄÈ†ÖÂØ¶Ë≠âÁ†îÁ©∂‰æÜÁ†îÁ©∂ LLM ÂπªË¶∫Âú®ÂÑ≤Â≠òÂ∫´Â±§Á¥öÁîüÊàêÂ†¥ÊôØ‰∏≠Êõ¥ÂØ¶Èöõ‰∏îË§áÈõúÁöÑÈñãÁôºËÉåÊôØ‰∏ãÁöÑÁèæË±°„ÄÅÊ©üÂà∂ÂíåÁ∑©Ëß£„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÊâãÂãïÊ™¢Êü•‰æÜËá™ÂÖ≠ÂÄã‰∏ªÊµÅ LLM ÁöÑÁ®ãÂºèÁ¢ºÁîüÊàêÁµêÊûúÔºå‰ª•Âª∫Á´ã LLM ÁîüÊàêÁöÑÁ®ãÂºèÁ¢ºÁöÑÂπªË¶∫ÂàÜÈ°ûÊ≥ï„ÄÇÊé•‰∏ã‰æÜÔºåÊàëÂÄëË©≥Á¥∞Ë™™ÊòéÂπªË¶∫ÁöÑÁèæË±°ÔºåÂàÜÊûêÂÆÉÂÄëÂú®‰∏çÂêåÊ®°Âûã‰∏≠ÁöÑÂàÜ‰Ωà„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂàÜÊûêÂπªË¶∫ÁöÑÂéüÂõ†Ôºå‰∏¶ÊâæÂá∫Â∞éËá¥ÂπªË¶∫ÁöÑÂõõÂÄãÊΩõÂú®Âõ†Á¥†„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫Êñº RAG ÁöÑÁ∑©Ëß£ÊñπÊ≥ïÔºåÂú®ÊâÄÊúâÁ†îÁ©∂ÁöÑ LLM ‰∏≠ÈÉΩÂ±ïÁèæÂá∫‰∏ÄËá¥ÁöÑÊúâÊïàÊÄß„ÄÇÂåÖÂê´Á®ãÂºèÁ¢º„ÄÅË≥áÊñôÂíåÂØ¶È©óÁµêÊûúÁöÑË§áË£ΩÂ•ó‰ª∂ÂèØÂú® https://github.com/DeepSoftwareAnalytics/LLMCodingHallucination ÂèñÂæó

##### **Robi Butler: Remote Multimodal Interactions with Household Robot Assistant**
2409.20548v1 by Anxing Xiao, Nuwan Janaka, Tianrun Hu, Anshul Gupta, Kaixin Li, Cunjun Yu, David Hsu

In this paper, we introduce Robi Butler, a novel household robotic system
that enables multimodal interactions with remote users. Building on the
advanced communication interfaces, Robi Butler allows users to monitor the
robot's status, send text or voice instructions, and select target objects by
hand pointing. At the core of our system is a high-level behavior module,
powered by Large Language Models (LLMs), that interprets multimodal
instructions to generate action plans. These plans are composed of a set of
open vocabulary primitives supported by Vision Language Models (VLMs) that
handle both text and pointing queries. The integration of the above components
allows Robi Butler to ground remote multimodal instructions in the real-world
home environment in a zero-shot manner. We demonstrate the effectiveness and
efficiency of this system using a variety of daily household tasks that involve
remote users giving multimodal instructions. Additionally, we conducted a user
study to analyze how multimodal interactions affect efficiency and user
experience during remote human-robot interaction and discuss the potential
improvements.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü Robi ButlerÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÂÆ∂Áî®Ê©üÂô®‰∫∫Á≥ªÁµ±ÔºåÂÆÉËÉΩËàáÈÅ†Á´Ø‰ΩøÁî®ËÄÖÈÄ≤Ë°åÂ§öÊ®°Âºè‰∫íÂãï„ÄÇRobi Butler Âª∫Á´ãÂú®ÂÖàÈÄ≤ÁöÑÈÄöË®ä‰ªãÈù¢‰∏äÔºåËÆì‰ΩøÁî®ËÄÖÂèØ‰ª•Áõ£ÊéßÊ©üÂô®‰∫∫ÁöÑÁãÄÊÖã„ÄÅÂÇ≥ÈÄÅÊñáÂ≠óÊàñË™ûÈü≥Êåá‰ª§Ôºå‰ª•ÂèäÁî®ÊâãÊåáÈªûÈÅ∏ÁõÆÊ®ôÁâ©‰ª∂„ÄÇÊàëÂÄëÁ≥ªÁµ±ÁöÑÊ†∏ÂøÉÊòØ‰∏ÄÂÄãÈ´òÈöéË°åÁÇ∫Ê®°ÁµÑÔºåÁî±Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êèê‰æõÊîØÊè¥ÔºåÂÆÉÊúÉËß£Ë≠ØÂ§öÊ®°ÂºèÊåá‰ª§‰ª•Áî¢ÁîüË°åÂãïË®àÁï´„ÄÇÈÄô‰∫õË®àÁï´Áî±‰∏ÄÁµÑÈñãÊîæÂºèË©ûÂΩôÂü∫Êú¨ÂÖÉÁ¥†ÁµÑÊàêÔºå‰∏¶Áî±ÂêåÊôÇËôïÁêÜÊñáÂ≠óÂíåÊåáÂêëÊü•Ë©¢ÁöÑË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) Êèê‰æõÊîØÊè¥„ÄÇ‰∏äËø∞ÂÖÉ‰ª∂ÁöÑÊï¥ÂêàËÆì Robi Butler ËÉΩÂú®Èõ∂Ê¨°Â≠∏ÁøíÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂ∞áÈÅ†Á´ØÂ§öÊ®°ÂºèÊåá‰ª§ÊáâÁî®ÊñºÁúüÂØ¶‰∏ñÁïåÁöÑÂ±ÖÂÆ∂Áí∞Â¢É‰∏≠„ÄÇÊàëÂÄë‰ΩøÁî®ÂêÑÁ®ÆÊ∂âÂèäÈÅ†Á´Ø‰ΩøÁî®ËÄÖÊèê‰æõÂ§öÊ®°ÂºèÊåá‰ª§ÁöÑÊó•Â∏∏ÂÆ∂Âãô‰ªªÂãôÔºå‰æÜÂ±ïÁ§∫Ê≠§Á≥ªÁµ±ÁöÑÊúâÊïàÊÄßÂíåÊïàÁéá„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†Ö‰ΩøÁî®ËÄÖÁ†îÁ©∂Ôºå‰ª•ÂàÜÊûêÂ§öÊ®°Âºè‰∫íÂãïÂ¶Ç‰ΩïÂΩ±ÈüøÈÅ†Á´Ø‰∫∫Ê©ü‰∫íÂãïÁöÑÊïàÁéáÂíå‰ΩøÁî®ËÄÖÈ´îÈ©óÔºå‰∏¶Ë®éË´ñÊΩõÂú®ÁöÑÊîπÈÄ≤ÊñπÂºè„ÄÇ

##### **Word Sense Disambiguation in Native Spanish: A Comprehensive Lexical Evaluation Resource**
2409.20524v1 by Pablo Ortega, Jordi Luque, Luis Lamiable, Rodrigo L√≥pez, Richard Benjamins

Human language, while aimed at conveying meaning, inherently carries
ambiguity. It poses challenges for speech and language processing, but also
serves crucial communicative functions. Efficiently solve ambiguity is both a
desired and a necessary characteristic. The lexical meaning of a word in
context can be determined automatically by Word Sense Disambiguation (WSD)
algorithms that rely on external knowledge often limited and biased toward
English. When adapting content to other languages, automated translations are
frequently inaccurate and a high degree of expert human validation is necessary
to ensure both accuracy and understanding. The current study addresses previous
limitations by introducing a new resource for Spanish WSD. It includes a sense
inventory and a lexical dataset sourced from the Diccionario de la Lengua
Espa\~nola which is maintained by the Real Academia Espa\~nola. We also review
current resources for Spanish and report metrics on them by a state-of-the-art
system.

ÊëòË¶ÅÔºö‰∫∫È°ûË™ûË®ÄÈõñÁÑ∂Êó®Âú®ÂÇ≥ÈÅîÊÑèÁæ©Ôºå‰ΩÜÊú¨Ë≥™‰∏äÂçªÂÖÖÊªø‰∫ÜÊ≠ßÁæ©„ÄÇÂÆÉÂ∞çË™ûË®ÄÂíåË™ûË®ÄËôïÁêÜÊèêÂá∫‰∫ÜÊåëÊà∞Ôºå‰ΩÜ‰πüÁôºÊèÆ‰∫ÜËá≥ÈóúÈáçË¶ÅÁöÑÊ∫ùÈÄöÂäüËÉΩ„ÄÇÊúâÊïàËß£Ê±∫Ê≠ßÁæ©Êó¢ÊòØ‰∏ÄÁ®ÆÁêÜÊÉ≥Ôºå‰πüÊòØ‰∏ÄÁ®ÆÂøÖË¶ÅÁöÑÁâπË≥™„ÄÇË™ûÂ¢É‰∏≠ÂñÆË©ûÁöÑË©ûÂΩôÊÑèÁæ©ÂèØ‰ª•Áî®Ë©ûÁæ©Ê∂àÊ≠ß (WSD) ÊºîÁÆóÊ≥ïËá™ÂãïÁ¢∫ÂÆöÔºåÈÄô‰∫õÊºîÁÆóÊ≥ï‰æùË≥¥ÊñºÂ§ñÈÉ®Áü•Ë≠òÔºåËÄåÈÄô‰∫õÁü•Ë≠òÈÄöÂ∏∏ÊúâÈôê‰∏îÂÅèÂêëÊñºËã±Ë™û„ÄÇÂú®Â∞áÂÖßÂÆπÊîπÁ∑®ÁÇ∫ÂÖ∂‰ªñË™ûË®ÄÊôÇÔºåËá™ÂãïÁøªË≠ØÈÄöÂ∏∏‰∏çÊ∫ñÁ¢∫ÔºåÈúÄË¶ÅÂ§ßÈáèÂ∞àÂÆ∂ÁöÑ‰∫∫Â∑•È©óË≠âÔºå‰ª•Á¢∫‰øùÊ∫ñÁ¢∫ÊÄßÂíåÁêÜËß£Â∫¶„ÄÇÊú¨Á†îÁ©∂ÈÄöÈÅéÂºïÂÖ•Ë•øÁè≠ÁâôË™û WSD ÁöÑÊñ∞Ë≥áÊ∫ê‰æÜËß£Ê±∫ÂÖàÂâçÁöÑÈôêÂà∂„ÄÇÂÆÉÂåÖÊã¨‰∏ÄÂÄãË™ûÁæ©Â∫´Âíå‰∏ÄÂÄãË©ûÂΩôË≥áÊñôÈõÜÔºåÂÖ∂‰æÜÊ∫êÊòØ Real Academia Espa\~nola Á∂≠Ë≠∑ÁöÑ Diccionario de la Lengua Espa\~nola„ÄÇÊàëÂÄëÈÇÑÂõûÈ°ß‰∫ÜË•øÁè≠ÁâôË™ûÁöÑÁèæÊúâË≥áÊ∫êÔºå‰∏¶ÈÄöÈÅéÊúÄÂÖàÈÄ≤ÁöÑÁ≥ªÁµ±Â∞çÂÆÉÂÄëÈÄ≤Ë°å‰∫ÜÊåáÊ®ôÂ†±Âëä„ÄÇ

##### **SMLE: Safe Machine Learning via Embedded Overapproximation**
2409.20517v1 by Matteo Francobaldi, Michele Lombardi

Despite the extent of recent advances in Machine Learning (ML) and Neural
Networks, providing formal guarantees on the behavior of these systems is still
an open problem, and a crucial requirement for their adoption in regulated or
safety-critical scenarios. We consider the task of training differentiable ML
models guaranteed to satisfy designer-chosen properties, stated as input-output
implications. This is very challenging, due to the computational complexity of
rigorously verifying and enforcing compliance in modern neural models. We
provide an innovative approach based on three components: 1) a general, simple
architecture enabling efficient verification with a conservative semantic; 2) a
rigorous training algorithm based on the Projected Gradient Method; 3) a
formulation of the problem of searching for strong counterexamples. The
proposed framework, being only marginally affected by model complexity, scales
well to practical applications, and produces models that provide full property
satisfaction guarantees. We evaluate our approach on properties defined by
linear inequalities in regression, and on mutually exclusive classes in
multilabel classification. Our approach is competitive with a baseline that
includes property enforcement during preprocessing, i.e. on the training data,
as well as during postprocessing, i.e. on the model predictions. Finally, our
contributions establish a framework that opens up multiple research directions
and potential improvements.

ÊëòË¶ÅÔºöÂÑòÁÆ°Ê©üÂô®Â≠∏Áøí (ML) ÂíåÁ•ûÁ∂ìÁ∂≤Ë∑ØÊúÄËøëÊúâÂæàÂ§ßÁöÑÈÄ≤Â±ïÔºå‰ΩÜË¶ÅÂ∞çÈÄô‰∫õÁ≥ªÁµ±ÁöÑË°åÁÇ∫Êèê‰æõÊ≠£Âºè‰øùË≠â‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÈñãÊîæÁöÑÂïèÈ°åÔºå‰πüÊòØÂú®ÂèóË¶èÁØÑÊàñÂÆâÂÖ®ÈóúÈçµÊÉÖÂ¢É‰∏≠Êé°Áî®ÂÆÉÂÄëÁöÑÈóúÈçµË¶ÅÊ±Ç„ÄÇÊàëÂÄëËÄÉÊÖÆË®ìÁ∑¥ÂèØÂæÆÂàÜ ML Ê®°ÂûãÁöÑ‰ªªÂãôÔºå‰øùË≠âÊªøË∂≥Ë®≠Ë®àÂ∏´ÈÅ∏ÊìáÁöÑÂ±¨ÊÄßÔºå‰∏¶Ë°®Á§∫ÁÇ∫Ëº∏ÂÖ•Ëº∏Âá∫ËòäÊ∂µ„ÄÇÁî±ÊñºÂö¥Ê†ºÈ©óË≠âÂíåÂº∑Âà∂Áèæ‰ª£Á•ûÁ∂ìÊ®°ÂûãÁöÑÁõ∏ÂÆπÊÄßÂú®Ë®àÁÆó‰∏äÂæàË§áÈõúÔºåÂõ†Ê≠§ÈÄôÊòØ‰∏ÄÂÄãÈùûÂ∏∏ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãô„ÄÇÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÂü∫Êñº‰∏âÂÄãÁµÑÊàêÁöÑÂâµÊñ∞ÊñπÊ≥ïÔºö1) ‰∏ÄÁ®ÆÈÄöÁî®„ÄÅÁ∞°ÂñÆÁöÑÊû∂ÊßãÔºåËÉΩÂ§†‰ΩøÁî®‰øùÂÆàË™ûÁæ©ÈÄ≤Ë°åÊúâÊïàÁöÑÈ©óË≠âÔºõ2) ‰∏ÄÁ®ÆÂü∫ÊñºÊäïÂΩ±Ê¢ØÂ∫¶Ê≥ïÁöÑÂö¥Ê†ºË®ìÁ∑¥ÊºîÁÆóÊ≥ïÔºõ3) ‰∏ÄÁ®ÆÂ∞ãÊâæÂº∑Âèç‰æãÁöÑÂïèÈ°åË°®Ëø∞„ÄÇÊâÄÊèêÂá∫ÁöÑÊû∂ÊßãÂÉÖÂèóÊ®°ÂûãË§áÈõúÊÄßÈÇäÈöõÂΩ±ÈüøÔºåÂèØ‰ª•ÂæàÂ•ΩÂú∞Êì¥Â±ïÂà∞ÂØ¶ÈöõÊáâÁî®Ôºå‰∏¶‰∏îÁî¢ÁîüÁöÑÊ®°ÂûãÊèê‰æõ‰∫ÜÂÆåÂÖ®ÁöÑÂ±¨ÊÄßÊªøË∂≥‰øùË≠â„ÄÇÊàëÂÄëÊ†πÊìöÂõûÊ≠∏‰∏≠ÁöÑÁ∑öÊÄß‰∏çÁ≠âÂºèÂíåÂ§öÊ®ôÁ±§ÂàÜÈ°û‰∏≠ÁöÑ‰∫íÊñ•È°ûÂà•‰æÜË©ï‰º∞ÊàëÂÄëÁöÑÂÅöÊ≥ï„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïËàáÂü∫Á∑öÂÖ∑ÊúâÁ´∂Áà≠ÂäõÔºåË©≤Âü∫Á∑öÂú®È†êËôïÁêÜÔºàÂç≥Âú®Ë®ìÁ∑¥Ë≥áÊñô‰∏äÔºâÂíåÂæåËôïÁêÜÔºàÂç≥Âú®Ê®°ÂûãÈ†êÊ∏¨‰∏äÔºâÊúüÈñìÈÉΩÂåÖÊã¨Â±¨ÊÄßÂº∑Âà∂„ÄÇÊúÄÂæåÔºåÊàëÂÄëÁöÑË≤¢ÁçªÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÊ°ÜÊû∂ÔºåÁÇ∫Â§öÂÄãÁ†îÁ©∂ÊñπÂêëÂíåÊΩõÂú®ÊîπÈÄ≤ÈñãÈó¢‰∫ÜÈÅìË∑Ø„ÄÇ

##### **What Information Contributes to Log-based Anomaly Detection? Insights from a Configurable Transformer-Based Approach**
2409.20503v1 by Xingfang Wu, Heng Li, Foutse Khomh

Log data are generated from logging statements in the source code, providing
insights into the execution processes of software applications and systems.
State-of-the-art log-based anomaly detection approaches typically leverage deep
learning models to capture the semantic or sequential information in the log
data and detect anomalous runtime behaviors. However, the impacts of these
different types of information are not clear. In addition, existing approaches
have not captured the timestamps in the log data, which can potentially provide
more fine-grained temporal information than sequential information. In this
work, we propose a configurable transformer-based anomaly detection model that
can capture the semantic, sequential, and temporal information in the log data
and allows us to configure the different types of information as the model's
features. Additionally, we train and evaluate the proposed model using log
sequences of different lengths, thus overcoming the constraint of existing
methods that rely on fixed-length or time-windowed log sequences as inputs.
With the proposed model, we conduct a series of experiments with different
combinations of input features to evaluate the roles of different types of
information in anomaly detection. When presented with log sequences of varying
lengths, the model can attain competitive and consistently stable performance
compared to the baselines. The results indicate that the event occurrence
information plays a key role in identifying anomalies, while the impact of the
sequential and temporal information is not significant for anomaly detection in
the studied public datasets. On the other hand, the findings also reveal the
simplicity of the studied public datasets and highlight the importance of
constructing new datasets that contain different types of anomalies to better
evaluate the performance of anomaly detection models.

ÊëòË¶ÅÔºö<paragraph>Ë®òÈåÑË≥áÊñôÊòØÁî±ÂéüÂßãÁ®ãÂºèÁ¢º‰∏≠ÁöÑË®òÈåÑÈô≥Ëø∞ÊâÄÁî¢ÁîüÔºåÊèê‰æõËªüÈ´îÊáâÁî®Á®ãÂºèÂíåÁ≥ªÁµ±Âü∑Ë°åÁ®ãÂºèÁöÑË¶ãËß£„ÄÇ
ÊúÄÂÖàÈÄ≤ÁöÑÂü∫ÊñºË®òÈåÑÁöÑÁï∞Â∏∏ÂÅµÊ∏¨ÊñπÊ≥ïÈÄöÂ∏∏Âà©Áî®Ê∑±Â∫¶Â≠∏ÁøíÊ®°Âûã‰æÜÊì∑ÂèñË®òÈåÑË≥áÊñô‰∏≠ÁöÑË™ûÁæ©ÊàñÈ†ÜÂ∫èË≥áË®äÔºå‰∏¶ÂÅµÊ∏¨Áï∞Â∏∏ÁöÑÂü∑Ë°åÊôÇÈñìË°åÁÇ∫„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õ‰∏çÂêåÈ°ûÂûãË≥áË®äÁöÑÂΩ±Èüø‰∏¶‰∏çÊ∏ÖÊ•ö„ÄÇÊ≠§Â§ñÔºåÁèæÊúâÁöÑÊñπÊ≥ï‰∏¶Êú™Êì∑ÂèñË®òÈåÑË≥áÊñô‰∏≠ÁöÑÊôÇÈñìÊà≥Ë®òÔºåÈÄôÂèØËÉΩÊúÉÊèê‰æõÊØîÈ†ÜÂ∫èË≥áË®äÊõ¥Á≤æÁ¥∞ÁöÑÊö´ÊôÇË≥áË®ä„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂèØÁµÑÊÖãÁöÑÂü∫ÊñºËΩâÊèõÂô®ÁöÑÁï∞Â∏∏ÂÅµÊ∏¨Ê®°ÂûãÔºåÂÆÉÂèØ‰ª•Êì∑ÂèñË®òÈåÑË≥áÊñô‰∏≠ÁöÑË™ûÁæ©„ÄÅÈ†ÜÂ∫èÂíåÊö´ÊôÇË≥áË®äÔºå‰∏¶ÂÖÅË®±ÊàëÂÄëÂ∞á‰∏çÂêåÈ°ûÂûãÁöÑË≥áË®äÁµÑÊÖãÁÇ∫Ê®°ÂûãÁöÑÁâπÂæµ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄë‰ΩøÁî®‰∏çÂêåÈï∑Â∫¶ÁöÑË®òÈåÑÂ∫èÂàóË®ìÁ∑¥ÂíåË©ï‰º∞ÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÔºåÂæûËÄåÂÖãÊúçÁèæÊúâÊñπÊ≥ïÁöÑÈôêÂà∂ÔºåÈÄô‰∫õÊñπÊ≥ï‰æùË≥¥ÊñºÂõ∫ÂÆöÈï∑Â∫¶ÊàñÊôÇÈñìË¶ñÁ™óÁöÑË®òÈåÑÂ∫èÂàó‰ΩúÁÇ∫Ëº∏ÂÖ•„ÄÇ‰ΩøÁî®ÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÔºåÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÁ≥ªÂàóÂÖ∑Êúâ‰∏çÂêåËº∏ÂÖ•ÁâπÂæµÁµÑÂêàÁöÑÂØ¶È©óÔºå‰ª•Ë©ï‰º∞‰∏çÂêåÈ°ûÂûãË≥áË®äÂú®Áï∞Â∏∏ÂÅµÊ∏¨‰∏≠ÁöÑËßíËâ≤„ÄÇÁï∂Êèê‰æõÈï∑Â∫¶‰∏çÂêåÁöÑË®òÈåÑÂ∫èÂàóÊôÇÔºåËàáÂü∫Á∑öÁõ∏ÊØîÔºåË©≤Ê®°ÂûãÂèØ‰ª•ÈÅîÂà∞Á´∂Áà≠‰∏îÂßãÁµÇÁ©©ÂÆöÁöÑÊïàËÉΩ„ÄÇÁµêÊûúË°®ÊòéÔºå‰∫ã‰ª∂ÁôºÁîüË≥áË®äÂú®Ë≠òÂà•Áï∞Â∏∏‰∏≠ÊâÆÊºîÈóúÈçµËßíËâ≤ÔºåËÄåÈ†ÜÂ∫èÂíåÊö´ÊôÇË≥áË®äÁöÑÂΩ±ÈüøÂ∞çÊñºÊâÄÁ†îÁ©∂ÁöÑÂÖ¨ÈñãË≥áÊñôÈõÜ‰∏≠ÁöÑÁï∞Â∏∏ÂÅµÊ∏¨‰∏¶‰∏çÈ°ØËëó„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÈÄô‰∫õÁôºÁèæ‰πüÊè≠Á§∫‰∫ÜÊâÄÁ†îÁ©∂ÁöÑÂÖ¨ÈñãË≥áÊñôÈõÜÁöÑÁ∞°ÂñÆÊÄßÔºå‰∏¶Âº∑Ë™øÂª∫ÊßãÂåÖÂê´‰∏çÂêåÈ°ûÂûãÁï∞Â∏∏ÁöÑÊñ∞Ë≥áÊñôÈõÜ‰ª•Êõ¥Â•ΩÂú∞Ë©ï‰º∞Áï∞Â∏∏ÂÅµÊ∏¨Ê®°ÂûãÊïàËÉΩÁöÑÈáçË¶ÅÊÄß„ÄÇ</paragraph>

##### **COLLAGE: Collaborative Human-Agent Interaction Generation using Hierarchical Latent Diffusion and Language Models**
2409.20502v1 by Divyanshu Daiya, Damon Conover, Aniket Bera

We propose a novel framework COLLAGE for generating collaborative
agent-object-agent interactions by leveraging large language models (LLMs) and
hierarchical motion-specific vector-quantized variational autoencoders
(VQ-VAEs). Our model addresses the lack of rich datasets in this domain by
incorporating the knowledge and reasoning abilities of LLMs to guide a
generative diffusion model. The hierarchical VQ-VAE architecture captures
different motion-specific characteristics at multiple levels of abstraction,
avoiding redundant concepts and enabling efficient multi-resolution
representation. We introduce a diffusion model that operates in the latent
space and incorporates LLM-generated motion planning cues to guide the
denoising process, resulting in prompt-specific motion generation with greater
control and diversity. Experimental results on the CORE-4D, and InterHuman
datasets demonstrate the effectiveness of our approach in generating realistic
and diverse collaborative human-object-human interactions, outperforming
state-of-the-art methods. Our work opens up new possibilities for modeling
complex interactions in various domains, such as robotics, graphics and
computer vision.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂêçÁÇ∫ COLLAGE ÁöÑÊñ∞Ê°ÜÊû∂ÔºåÈÄèÈÅéÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÂàÜÂ±§Âãï‰ΩúÁâπÂÆöÂêëÈáèÈáèÂåñËÆäÁï∞Ëá™ÂãïÁ∑®Á¢ºÂô® (VQ-VAE) ‰æÜÁî¢ÁîüÂçî‰Ωú‰∏ªÈ´î-Áâ©‰ª∂-‰∏ªÈ´î‰∫íÂãï„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÈÄèÈÅéÊï¥Âêà LLM ÁöÑÁü•Ë≠òÂíåÊé®ÁêÜËÉΩÂäõ‰æÜÂºïÂ∞éÁîüÊàêÊì¥Êï£Ê®°ÂûãÔºå‰æÜËß£Ê±∫Ê≠§È†òÂüü‰∏≠Áº∫‰πèË±êÂØåË≥áÊñôÈõÜÁöÑÂïèÈ°å„ÄÇÂàÜÂ±§ VQ-VAE Êû∂ÊßãÂú®Â§öÂÄãÊäΩË±°Â±§Á¥ö‰∏≠Êì∑Âèñ‰∏çÂêåÁöÑÂãï‰ΩúÁâπÂÆöÁâπÂæµÔºåÈÅøÂÖçÂÜóÈ§òÊ¶ÇÂøµ‰∏¶ÂïüÁî®ÊúâÊïàÁéáÁöÑÂ§öËß£ÊûêÂ∫¶Ë°®Á§∫„ÄÇÊàëÂÄëÂºïÂÖ•‰∏ÄÂÄãÂú®ÊΩõÂú®Á©∫Èñì‰∏≠ÈÅã‰ΩúÁöÑÊì¥Êï£Ê®°ÂûãÔºå‰∏¶Êï¥Âêà LLM ÁîüÊàêÁöÑÂãï‰ΩúË¶èÂäÉÊèêÁ§∫‰æÜÂºïÂ∞éÂéªÂô™Á®ãÂ∫èÔºåÁî¢ÁîüÂÖ∑ÊúâÊõ¥È´òÊéßÂà∂ÂíåÂ§öÊ®£ÊÄßÁöÑÊèêÁ§∫ÁâπÂÆöÂãï‰Ωú„ÄÇÂú® CORE-4D Âíå InterHuman Ë≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®Áî¢ÁîüÁúüÂØ¶‰∏îÂ§öÊ®£ÂåñÁöÑÂçî‰Ωú‰∫∫È´î-Áâ©‰ª∂-‰∫∫È´î‰∫íÂãïÊñπÈù¢ÁöÑÊúâÊïàÊÄßÔºåÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁÇ∫Âú®ÂêÑÁ®ÆÈ†òÂüüÔºà‰æãÂ¶ÇÊ©üÂô®‰∫∫ÊäÄË°ì„ÄÅÂúñÂΩ¢ÂíåÈõªËÖ¶Ë¶ñË¶∫Ôºâ‰∏≠Âª∫Ê®°Ë§áÈõú‰∫íÂãïÈñãÂïü‰∫ÜÊñ∞ÁöÑÂèØËÉΩÊÄß„ÄÇ

##### **Enhancing Romanian Offensive Language Detection through Knowledge Distillation, Multi-Task Learning, and Data Augmentation**
2409.20498v1 by Vlad-Cristian Matei, Iulian-Marius TƒÉiatu, RƒÉzvan-Alexandru SmƒÉdu, Dumitru-Clementin Cercel

This paper highlights the significance of natural language processing (NLP)
within artificial intelligence, underscoring its pivotal role in comprehending
and modeling human language. Recent advancements in NLP, particularly in
conversational bots, have garnered substantial attention and adoption among
developers. This paper explores advanced methodologies for attaining smaller
and more efficient NLP models. Specifically, we employ three key approaches:
(1) training a Transformer-based neural network to detect offensive language,
(2) employing data augmentation and knowledge distillation techniques to
increase performance, and (3) incorporating multi-task learning with knowledge
distillation and teacher annealing using diverse datasets to enhance
efficiency. The culmination of these methods has yielded demonstrably improved
outcomes.

ÊëòË¶ÅÔºöÊú¨ÊñáÈáçÁÇπÈòêËø∞Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ (NLP) Âú®‰∫∫Â∑•Êô∫ËÉΩ‰∏≠ÁöÑÈáçË¶ÅÊÄßÔºåÂº∫Ë∞ÉÂÖ∂Âú®ÁêÜËß£ÂíåÂª∫Ê®°‰∫∫Á±ªËØ≠Ë®Ä‰∏≠Ëá≥ÂÖ≥ÈáçË¶ÅÁöÑ‰ΩúÁî®„ÄÇNLP ÁöÑÊúÄÊñ∞ËøõÂ±ïÔºåÂ∞§ÂÖ∂ÊòØÂú®‰ºöËØùÊú∫Âô®‰∫∫ÊñπÈù¢ÔºåÂ∑≤ÂºïËµ∑ÂºÄÂèë‰∫∫ÂëòÁöÑÊûÅÂ§ßÂÖ≥Ê≥®ÂíåÈááÁî®„ÄÇÊú¨ÊñáÊé¢ËÆ®‰∫ÜÂÆûÁé∞Êõ¥Â∞è„ÄÅÊõ¥È´òÊïàÁöÑ NLP Ê®°ÂûãÁöÑÈ´òÁ∫ßÊñπÊ≥ï„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨ÈááÁî®‰∫Ü‰∏âÁßçÂÖ≥ÈîÆÊñπÊ≥ïÔºö(1) ËÆ≠ÁªÉÂü∫‰∫é Transformer ÁöÑÁ•ûÁªèÁΩëÁªúÊù•Ê£ÄÊµãÊîªÂáªÊÄßËØ≠Ë®ÄÔºå(2) ÈááÁî®Êï∞ÊçÆÂ¢ûÂº∫ÂíåÁü•ËØÜËí∏È¶èÊäÄÊúØÊù•ÊèêÈ´òÊÄßËÉΩÔºå‰ª•Âèä (3) ÁªìÂêàÂ§ö‰ªªÂä°Â≠¶‰π†‰∏éÁü•ËØÜËí∏È¶èÂíåÊïôÂ∏àÈÄÄÁÅ´Ôºå‰ΩøÁî®‰∏çÂêåÁöÑÊï∞ÊçÆÈõÜÊù•ÊèêÈ´òÊïàÁéá„ÄÇËøô‰∫õÊñπÊ≥ïÁöÑÁªìÂêà‰∫ßÁîü‰∫ÜÊòéÊòæÊîπÂñÑÁöÑÁªìÊûú„ÄÇ

##### **RecSys Challenge 2024: Balancing Accuracy and Editorial Values in News Recommendations**
2409.20483v1 by Johannes Kruse, Kasper Lindskow, Saikishore Kalloori, Marco Polignano, Claudio Pomo, Abhishek Srivastava, Anshuk Uppal, Michael Riis Andersen, Jes Frellsen

The RecSys Challenge 2024 aims to advance news recommendation by addressing
both the technical and normative challenges inherent in designing effective and
responsible recommender systems for news publishing. This paper describes the
challenge, including its objectives, problem setting, and the dataset provided
by the Danish news publishers Ekstra Bladet and JP/Politikens Media Group
("Ekstra Bladet"). The challenge explores the unique aspects of news
recommendation, such as modeling user preferences based on behavior, accounting
for the influence of the news agenda on user interests, and managing the rapid
decay of news items. Additionally, the challenge embraces normative
complexities, investigating the effects of recommender systems on news flow and
their alignment with editorial values. We summarize the challenge setup,
dataset characteristics, and evaluation metrics. Finally, we announce the
winners and highlight their contributions. The dataset is available at:
https://recsys.eb.dk.

ÊëòË¶ÅÔºöRecSys Challenge 2024 Êó®Âú®ÈÄèÈÅéËß£Ê±∫Ë®≠Ë®àÊúâÊïà‰∏îË≤†Ë≤¨‰ªªÁöÑÊñ∞ËÅûÁôºÂ∏ÉÊé®Ëñ¶Á≥ªÁµ±ÊôÇÂõ∫ÊúâÁöÑÊäÄË°ìÂíåË¶èÁØÑÊåëÊà∞Ôºå‰æÜÊèêÂçáÊñ∞ËÅûÊé®Ëñ¶„ÄÇÊú¨ÊñáË™™Êòé‰∫ÜÊåëÊà∞ÔºåÂåÖÊã¨ÂÖ∂ÁõÆÊ®ô„ÄÅÂïèÈ°åË®≠ÂÆöÔºå‰ª•Âèä‰∏πÈ∫•Êñ∞ËÅûÂá∫ÁâàÂïÜ Ekstra Bladet Âíå JP/Politikens Media GroupÔºà„ÄåEkstra Bladet„ÄçÔºâÊèê‰æõÁöÑË≥áÊñôÈõÜ„ÄÇÊåëÊà∞Êé¢Ë®éÊñ∞ËÅûÊé®Ëñ¶ÁöÑÁç®ÁâπÈù¢ÂêëÔºå‰æãÂ¶ÇÊ†πÊìöË°åÁÇ∫Âª∫Ê®°‰ΩøÁî®ËÄÖÂÅèÂ•Ω„ÄÅËÄÉÈáèÊñ∞ËÅûË≠∞Á®ãÂ∞ç‰ΩøÁî®ËÄÖËààË∂£ÁöÑÂΩ±ÈüøÔºå‰ª•ÂèäÁÆ°ÁêÜÊñ∞ËÅûÈ†ÖÁõÆÂø´ÈÄüË°∞ÈÄÄ„ÄÇÊ≠§Â§ñÔºåÊåëÊà∞Ê∂µËìãË¶èÁØÑÁöÑË§áÈõúÊÄßÔºåË™øÊü•Êé®Ëñ¶Á≥ªÁµ±Â∞çÊñ∞ËÅûÊµÅÁ®ãÁöÑÂΩ±ÈüøÔºå‰ª•ÂèäÂÆÉÂÄëËàáÁ∑®ËºØÂÉπÂÄºËßÄÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÊàëÂÄëÁ∏ΩÁµêÊåëÊà∞Ë®≠ÂÆö„ÄÅË≥áÊñôÈõÜÁâπÂæµÂíåË©ïÈáèÊåáÊ®ô„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂÆ£Â∏ÉÁç≤ÁçéËÄÖ‰∏¶Âº∑Ë™ø‰ªñÂÄëÁöÑË≤¢Áçª„ÄÇË≥áÊñôÈõÜÂèØÂú®‰ª•‰∏ãÁ∂≤ÂùÄÂèñÂæóÔºöhttps://recsys.eb.dk„ÄÇ

##### **A Weakly Supervised Data Labeling Framework for Machine Lexical Normalization in Vietnamese Social Media**
2409.20467v1 by Dung Ha Nguyen, Anh Thi Hoang Nguyen, Kiet Van Nguyen

This study introduces an innovative automatic labeling framework to address
the challenges of lexical normalization in social media texts for low-resource
languages like Vietnamese. Social media data is rich and diverse, but the
evolving and varied language used in these contexts makes manual labeling
labor-intensive and expensive. To tackle these issues, we propose a framework
that integrates semi-supervised learning with weak supervision techniques. This
approach enhances the quality of training dataset and expands its size while
minimizing manual labeling efforts. Our framework automatically labels raw
data, converting non-standard vocabulary into standardized forms, thereby
improving the accuracy and consistency of the training data. Experimental
results demonstrate the effectiveness of our weak supervision framework in
normalizing Vietnamese text, especially when utilizing Pre-trained Language
Models. The proposed framework achieves an impressive F1-score of 82.72% and
maintains vocabulary integrity with an accuracy of up to 99.22%. Additionally,
it effectively handles undiacritized text under various conditions. This
framework significantly enhances natural language normalization quality and
improves the accuracy of various NLP tasks, leading to an average accuracy
increase of 1-3%.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÂâµÊñ∞ÁöÑËá™ÂãïÊ®ôÁ±§Ê°ÜÊû∂Ôºå‰ª•Ëß£Ê±∫Ë∂äÂçóË™ûÁ≠â‰ΩéË≥áÊ∫êË™ûË®ÄÂú®Á§æÁæ§Â™íÈ´îÊñáÂ≠ó‰∏≠Ë©ûÂΩôÊ®ôÊ∫ñÂåñÁöÑÊåëÊà∞„ÄÇÁ§æÁæ§Â™íÈ´îË≥áÊñôË±êÂØå‰∏îÂ§öÂÖÉÔºå‰ΩÜÈÄô‰∫õÊÉÖÂ¢É‰∏≠‰ΩøÁî®‰∏çÊñ∑ÊºîÈÄ≤‰∏îÂ§öËÆäÁöÑË™ûË®ÄÔºå‰ΩøÂæóÊâãÂãïÊ®ôÁ±§Ë≤ªÊôÇ‰∏îÊòÇË≤¥„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂ∞áÂçäÁõ£Áù£ÂºèÂ≠∏ÁøíËàáÂº±Áõ£Áù£ÂºèÊäÄË°ìÊï¥ÂêàÁöÑÊ°ÜÊû∂„ÄÇÊ≠§ÊñπÊ≥ïÊèêÂçáË®ìÁ∑¥Ë≥áÊñôÈõÜÁöÑÂìÅË≥™‰∏¶Êì¥ÂÖÖÂÖ∂Ë¶èÊ®°ÔºåÂêåÊôÇÂ∞áÊâãÂãïÊ®ôÁ±§Â∑•‰ΩúÈôçËá≥ÊúÄ‰Ωé„ÄÇÊàëÂÄëÁöÑÊ°ÜÊû∂Ëá™ÂãïÊ®ôÁ±§ÂéüÂßãË≥áÊñôÔºåÂ∞áÈùûÊ®ôÊ∫ñË©ûÂΩôËΩâÊèõÁÇ∫Ê®ôÊ∫ñÂåñÂΩ¢ÂºèÔºåÈÄ≤ËÄåÊèêÂçáË®ìÁ∑¥Ë≥áÊñôÁöÑÊ∫ñÁ¢∫Â∫¶Âíå‰∏ÄËá¥ÊÄß„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòéÊàëÂÄëÁöÑÂº±Áõ£Áù£ÂºèÊ°ÜÊû∂Âú®Ê®ôÊ∫ñÂåñË∂äÂçóË™ûÊñáÂ≠ó‰∏äÂÖ∑ÊúâÊàêÊïàÔºåÁâπÂà•ÊòØÂú®‰ΩøÁî®È†êË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÊôÇ„ÄÇÊèêÂá∫ÁöÑÊ°ÜÊû∂ÈÅîÂà∞‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑ 82.72% F1 ÂàÜÊï∏Ôºå‰∏¶‰ª•È´òÈÅî 99.22% ÁöÑÊ∫ñÁ¢∫Â∫¶Á∂≠ÊåÅË©ûÂΩôÂÆåÊï¥ÊÄß„ÄÇÊ≠§Â§ñÔºåÂÆÉÂú®ÂêÑÁ®ÆÊ¢ù‰ª∂‰∏ãÊúâÊïàËôïÁêÜÊú™Âä†ÈôÑÂä†Á¨¶ËôüÁöÑÊñáÂ≠ó„ÄÇÈÄôÂÄãÊ°ÜÊû∂È°ØËëóÊèêÂçáËá™ÁÑ∂Ë™ûË®ÄÊ®ôÊ∫ñÂåñÁöÑÂìÅË≥™Ôºå‰∏¶ÊèêÂçáÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãôÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÂ∞éËá¥Âπ≥ÂùáÊ∫ñÁ¢∫Â∫¶ÊèêÂçá 1-3%„ÄÇ

##### **Language Resources in Spanish for Automatic Text Simplification across Domains**
2409.20466v1 by Antonio Moreno-Sandoval, Leonardo Campillos-Llanos, Ana Garc√≠a-Serrano

This work describes the language resources and models developed for automatic
simplification of Spanish texts in three domains: Finance, Medicine and History
studies. We created several corpora in each domain, annotation and
simplification guidelines, a lexicon of technical and simplified medical terms,
datasets used in shared tasks for the financial domain, and two simplification
tools. The methodology, resources and companion publications are shared
publicly on the web-site: https://clara-nlp.uned.es/.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂ÊèèËø∞‰∫Ü‰∏∫‰∏â‰∏™È¢ÜÂüüÁöÑË•øÁè≠ÁâôËØ≠ÊñáÊú¨Ëá™Âä®ÁÆÄÂåñËÄåÂºÄÂèëÁöÑËØ≠Ë®ÄËµÑÊ∫êÂíåÊ®°ÂûãÔºöÈáëËûç„ÄÅÂåªÂ≠¶ÂíåÂéÜÂè≤Á†îÁ©∂„ÄÇÊàë‰ª¨Âú®ÊØè‰∏™È¢ÜÂüüÂàõÂª∫‰∫ÜÂ§ö‰∏™ËØ≠ÊñôÂ∫ì„ÄÅÊ≥®ÈáäÂíåÁÆÄÂåñÊåáÂçó„ÄÅÊäÄÊúØÂíåÁÆÄÂåñÂåªÂ≠¶ÊúØËØ≠ËØçÂÖ∏„ÄÅÁî®‰∫éÈáëËûçÈ¢ÜÂüüÂÖ±‰∫´‰ªªÂä°ÁöÑÊï∞ÊçÆÈõÜ‰ª•Âèä‰∏§‰∏™ÁÆÄÂåñÂ∑•ÂÖ∑„ÄÇÊñπÊ≥ï„ÄÅËµÑÊ∫êÂíåÈÖçÂ•óÂá∫ÁâàÁâ©Âú®ÁΩëÁ´ô‰∏äÂÖ¨ÂºÄÂÖ±‰∫´Ôºöhttps://clara-nlp.uned.es/„ÄÇ

##### **POMONAG: Pareto-Optimal Many-Objective Neural Architecture Generator**
2409.20447v1 by Eugenio Lomurno, Samuele Mariani, Matteo Monti, Matteo Matteucci

Neural Architecture Search (NAS) automates neural network design, reducing
dependence on human expertise. While NAS methods are computationally intensive
and dataset-specific, auxiliary predictors reduce the models needing training,
decreasing search time. This strategy is used to generate architectures
satisfying multiple computational constraints. Recently, Transferable NAS has
emerged, generalizing the search process from dataset-dependent to
task-dependent. In this field, DiffusionNAG is a state-of-the-art method. This
diffusion-based approach streamlines computation, generating architectures
optimized for accuracy on unseen datasets without further adaptation. However,
by focusing solely on accuracy, DiffusionNAG overlooks other crucial objectives
like model complexity, computational efficiency, and inference latency --
factors essential for deploying models in resource-constrained environments.
This paper introduces the Pareto-Optimal Many-Objective Neural Architecture
Generator (POMONAG), extending DiffusionNAG via a many-objective diffusion
process. POMONAG simultaneously considers accuracy, number of parameters,
multiply-accumulate operations (MACs), and inference latency. It integrates
Performance Predictor models to estimate these metrics and guide diffusion
gradients. POMONAG's optimization is enhanced by expanding its training
Meta-Dataset, applying Pareto Front Filtering, and refining embeddings for
conditional generation. These enhancements enable POMONAG to generate
Pareto-optimal architectures that outperform the previous state-of-the-art in
performance and efficiency. Results were validated on two search spaces --
NASBench201 and MobileNetV3 -- and evaluated across 15 image classification
datasets.

ÊëòË¶ÅÔºö<paragraph>Á•ûÁ∂ìÊû∂ÊßãÊêúÂ∞ã (NAS) Ëá™ÂãïÂåñÁ•ûÁ∂ìÁ∂≤Ë∑ØË®≠Ë®àÔºåÊ∏õÂ∞ëÂ∞ç‰∫∫È°ûÂ∞àÊ•≠Áü•Ë≠òÁöÑ‰æùË≥¥„ÄÇÂÑòÁÆ° NAS ÊñπÊ≥ïÂú®Ë®àÁÆó‰∏äÂæàÂØÜÈõÜ‰∏îÁâπÂÆöÊñºË≥áÊñôÈõÜÔºå‰ΩÜËºîÂä©È†êÊ∏¨Âô®ÂèØÊ∏õÂ∞ëÈúÄË¶ÅË®ìÁ∑¥ÁöÑÊ®°ÂûãÔºåÁ∏ÆÁü≠ÊêúÂ∞ãÊôÇÈñì„ÄÇÊ≠§Á≠ñÁï•Áî®ÊñºÁî¢ÁîüÊªøË∂≥Â§öÈ†ÖÈÅãÁÆóÈôêÂà∂ÁöÑÊû∂Êßã„ÄÇËøëÊúüÔºåÂèØËΩâÁßª NAS Â∑≤ÊµÆÁèæÔºåÂ∞áÊêúÂ∞ãÁ®ãÂ∫èÂæûÁâπÂÆöÊñºË≥áÊñôÈõÜÊ¶ÇÊã¨ÁÇ∫ÁâπÂÆöÊñº‰ªªÂãô„ÄÇÂú®ÈÄôÂÄãÈ†òÂüüÔºåDiffusionNAG ÊòØ‰∏ÄÁ®ÆÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ï„ÄÇÈÄôÁ®ÆÂü∫ÊñºÊì¥Êï£ÁöÑÊñπÊ≥ïÁ∞°Âåñ‰∫ÜÈÅãÁÆóÔºåÁî¢Áîü‰∫ÜÈáùÂ∞çÊú™Ë¶ãË≥áÊñôÈõÜÊúÄ‰Ω≥ÂåñÊ∫ñÁ¢∫Â∫¶ÁöÑÊû∂ÊßãÔºåËÄåÁÑ°ÈúÄÈÄ≤‰∏ÄÊ≠•Ë™øÊï¥„ÄÇÁÑ∂ËÄåÔºåDiffusionNAG ÂÉÖÂ∞àÊ≥®ÊñºÊ∫ñÁ¢∫Â∫¶ÔºåËÄåÂøΩÁï•‰∫ÜÂÖ∂‰ªñÈóúÈçµÁõÆÊ®ôÔºå‰æãÂ¶ÇÊ®°ÂûãË§áÈõúÂ∫¶„ÄÅÈÅãÁÆóÊïàÁéáÂíåÊé®Ë´ñÂª∂ÈÅ≤ÔºåÈÄô‰∫õÂõ†Á¥†Â∞çÊñºÂú®Ë≥áÊ∫êÂèóÈôêÁöÑÁí∞Â¢É‰∏≠ÈÉ®ÁΩ≤Ê®°ÂûãËá≥ÈóúÈáçË¶Å„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü Pareto ÊúÄ‰Ω≥Â§öÁõÆÊ®ôÁ•ûÁ∂ìÊû∂ÊßãÁî¢ÁîüÂô® (POMONAG)ÔºåÈÄèÈÅéÂ§öÁõÆÊ®ôÊì¥Êï£ÈÅéÁ®ãÊì¥ÂÖÖ DiffusionNAG„ÄÇPOMONAG ÂêåÊôÇËÄÉÊÖÆÊ∫ñÁ¢∫Â∫¶„ÄÅÂèÉÊï∏Êï∏Èáè„ÄÅ‰πòÁ¥ØÂä†ÈÅãÁÆó (MAC) ÂíåÊé®Ë´ñÂª∂ÈÅ≤„ÄÇÂÆÉÊï¥Âêà‰∫ÜÊïàËÉΩÈ†êÊ∏¨Âô®Ê®°Âûã‰æÜ‰º∞Ë®àÈÄô‰∫õÊåáÊ®ô‰∏¶ÂºïÂ∞éÊì¥Êï£Ê¢ØÂ∫¶„ÄÇPOMONAG ÁöÑÊúÄ‰Ω≥ÂåñÈÄèÈÅéÊì¥ÂÖÖÂÖ∂Ë®ìÁ∑¥ÂÖÉË≥áÊñôÈõÜ„ÄÅÊáâÁî® Pareto ÂâçÁ∑£ÈÅéÊøæÂíåÁ≤æÁÖâÁî®ÊñºÊ¢ù‰ª∂ÂºèÁî¢ÁîüÁöÑÂµåÂÖ•ÂºèÂÖÉ‰ª∂ËÄåÂ¢ûÂº∑„ÄÇÈÄô‰∫õÂ¢ûÂº∑ÂäüËÉΩËÆì POMONAG ËÉΩÂ§†Áî¢Áîü Pareto ÊúÄ‰Ω≥Êû∂ÊßãÔºåÂÖ∂ÊïàËÉΩÂíåÊïàÁéáÂÑ™ÊñºÂÖàÂâçÁöÑÊúÄÂÖàÈÄ≤ÊäÄË°ì„ÄÇÁµêÊûúÂú®ÂÖ©ÂÄãÊêúÂ∞ãÁ©∫ÈñìÔºàNASBench201 Âíå MobileNetV3Ôºâ‰∏äÂæóÂà∞È©óË≠âÔºå‰∏¶Âú® 15 ÂÄãÂΩ±ÂÉèÂàÜÈ°ûË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åË©ï‰º∞„ÄÇ</paragraph>

##### **Instance-adaptive Zero-shot Chain-of-Thought Prompting**
2409.20441v2 by Xiaosong Yuan, Chen Shen, Shaotian Yan, Xiaofeng Zhang, Liang Xie, Wenxiao Wang, Renchu Guan, Ying Wang, Jieping Ye

Zero-shot Chain-of-Thought (CoT) prompting emerges as a simple and effective
strategy for enhancing the performance of large language models (LLMs) in
real-world reasoning tasks. Nonetheless, the efficacy of a singular, task-level
prompt uniformly applied across the whole of instances is inherently limited
since one prompt cannot be a good partner for all, a more appropriate approach
should consider the interaction between the prompt and each instance
meticulously. This work introduces an instance-adaptive prompting algorithm as
an alternative zero-shot CoT reasoning scheme by adaptively differentiating
good and bad prompts. Concretely, we first employ analysis on LLMs through the
lens of information flow to detect the mechanism under zero-shot CoT reasoning,
in which we discover that information flows from question to prompt and
question to rationale jointly influence the reasoning results most. We notice
that a better zero-shot CoT reasoning needs the prompt to obtain semantic
information from the question then the rationale aggregates sufficient
information from the question directly and via the prompt indirectly. On the
contrary, lacking any of those would probably lead to a bad one. Stem from
that, we further propose an instance-adaptive prompting strategy (IAP) for
zero-shot CoT reasoning. Experiments conducted with LLaMA-2, LLaMA-3, and Qwen
on math, logic, and commonsense reasoning tasks (e.g., GSM8K, MMLU, Causal
Judgement) obtain consistent improvement, demonstrating that the
instance-adaptive zero-shot CoT prompting performs better than other task-level
methods with some curated prompts or sophisticated procedures, showing the
significance of our findings in the zero-shot CoT reasoning mechanism.

ÊëòË¶ÅÔºöÈõ∂Ê¨°ÁôºÊÉ≥ÈèàÔºàCoTÔºâÊèêÁ§∫‰ΩúÁÇ∫‰∏ÄÁ®ÆÁ∞°ÂñÆ‰∏îÊúâÊïàÁöÑÁ≠ñÁï•ÔºåÁî®ÊñºÂ¢ûÂº∑Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂú®ÁèæÂØ¶‰∏ñÁïåÊé®ÁêÜ‰ªªÂãô‰∏≠ÁöÑË°®Áèæ„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÂñÆ‰∏Ä‰ªªÂãôÁ¥öÂà•ÊèêÁ§∫Âú®ÊâÄÊúâÂØ¶‰æã‰∏≠Áµ±‰∏ÄÊáâÁî®ÁöÑÊïàÂäõÊú¨Ë≥™‰∏äÊòØÊúâÈôêÁöÑÔºåÂõ†ÁÇ∫‰∏ÄÂÄãÊèêÁ§∫ÁÑ°Ê≥ïÊàêÁÇ∫ÊâÄÊúâÊèêÁ§∫ÁöÑÂ•ΩÂ§•‰º¥Ôºå‰∏ÄÂÄãÊõ¥ÈÅ©Áï∂ÁöÑÊñπÊ≥ïÊáâË©≤‰ªîÁ¥∞ËÄÉÊÖÆÊèêÁ§∫ËàáÊØèÂÄãÂØ¶‰æã‰πãÈñìÁöÑ‰∫§‰∫í„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂØ¶‰æãËá™ÈÅ©ÊáâÊèêÁ§∫ÊºîÁÆóÊ≥ïÔºå‰ΩúÁÇ∫‰∏ÄÁ®ÆÊõø‰ª£ÁöÑÈõ∂Ê¨°ÁôºÊÉ≥ÈèàÊé®ÁêÜÊñπÊ°àÔºåÈÄöÈÅéËá™ÈÅ©ÊáâÂú∞ÂçÄÂàÜÂ•ΩÊèêÁ§∫ÂíåÂ£ûÊèêÁ§∫„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈ¶ñÂÖàÈÄöÈÅéË≥áË®äÊµÅÁöÑË¶ñËßíÂ∞ç LLM ÈÄ≤Ë°åÂàÜÊûêÔºå‰ª•Ê™¢Ê∏¨Èõ∂Ê¨°ÁôºÊÉ≥ÈèàÊé®ÁêÜ‰∏ãÁöÑÊ©üÂà∂ÔºåÊàëÂÄëÁôºÁèæÂæûÂïèÈ°åÂà∞ÊèêÁ§∫ÂíåÂæûÂïèÈ°åÂà∞ÁêÜÁî±ÁöÑË≥áË®äÊµÅÂÖ±ÂêåÂ∞çÊé®ÁêÜÁµêÊûúÂΩ±ÈüøÊúÄÂ§ß„ÄÇÊàëÂÄëÊ≥®ÊÑèÂà∞Ôºå‰∏ÄÂÄãÊõ¥Â•ΩÁöÑÈõ∂Ê¨°ÁôºÊÉ≥ÈèàÊé®ÁêÜÈúÄË¶ÅÊèêÁ§∫ÂæûÂïèÈ°å‰∏≠Áç≤ÂèñË™ûÁæ©Ë≥áË®äÔºåÁÑ∂ÂæåÁêÜÁî±Áõ¥Êé•ÂæûÂïèÈ°å‰∏≠ËÅöÂêàË∂≥Â§†ÁöÑË≥áË®äÔºå‰∏¶ÈÄöÈÅéÊèêÁ§∫ÈñìÊé•ËÅöÂêà„ÄÇÁõ∏ÂèçÔºåÁº∫Â∞ë‰ªª‰Ωï‰∏ÄÂÄãÈÉΩÂèØËÉΩÂ∞éËá¥‰∏ÄÂÄãÂ£ûÁöÑÊé®ÁêÜ„ÄÇÁî±Ê≠§ÔºåÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂØ¶‰æãËá™ÈÅ©ÊáâÊèêÁ§∫Á≠ñÁï•ÔºàIAPÔºâÔºåÁî®ÊñºÈõ∂Ê¨°ÁôºÊÉ≥ÈèàÊé®ÁêÜ„ÄÇ‰ΩøÁî® LLaMA-2„ÄÅLLaMA-3 Âíå Qwen Âú®Êï∏Â≠∏„ÄÅÈÇèËºØÂíåÂ∏∏Ë≠òÊé®ÁêÜ‰ªªÂãôÔºà‰æãÂ¶Ç GSM8K„ÄÅMMLU„ÄÅÂõ†ÊûúÂà§Êñ∑Ôºâ‰∏äÈÄ≤Ë°åÁöÑÂØ¶È©óÁç≤Âæó‰∫Ü‰∏ÄËá¥ÁöÑÊîπÈÄ≤ÔºåË≠âÊòé‰∫ÜÂØ¶‰æãËá™ÈÅ©ÊáâÈõ∂Ê¨°ÁôºÊÉ≥ÈèàÊèêÁ§∫ÊØîÂÖ∂‰ªñÂÖ∑ÊúâÊüê‰∫õÁ≠ñÂ±ïÊèêÁ§∫ÊàñË§áÈõúÁ®ãÂ∫èÁöÑ‰ªªÂãôÁ¥öÂà•ÊñπÊ≥ïË°®ÁèæÂæóÊõ¥Â•ΩÔºåÈ°ØÁ§∫‰∫ÜÊàëÂÄëÁöÑÁôºÁèæÂ∞çÊñºÈõ∂Ê¨°ÁôºÊÉ≥ÈèàÊé®ÁêÜÊ©üÂà∂ÁöÑÊÑèÁæ©„ÄÇ

##### **QAEncoder: Towards Aligned Representation Learning in Question Answering System**
2409.20434v1 by Zhengren Wang, Qinhan Yu, Shida Wei, Zhiyu Li, Feiyu Xiong, Xiaoxing Wang, Simin Niu, Hao Liang, Wentao Zhang

Modern QA systems entail retrieval-augmented generation (RAG) for accurate
and trustworthy responses. However, the inherent gap between user queries and
relevant documents hinders precise matching. Motivated by our conical
distribution hypothesis, which posits that potential queries and documents form
a cone-like structure in the embedding space, we introduce QAEncoder, a
training-free approach to bridge this gap. Specifically, QAEncoder estimates
the expectation of potential queries in the embedding space as a robust
surrogate for the document embedding, and attaches document fingerprints to
effectively distinguish these embeddings. Extensive experiments on fourteen
embedding models across six languages and eight datasets validate QAEncoder's
alignment capability, which offers a plug-and-play solution that seamlessly
integrates with existing RAG architectures and training-based methods.

ÊëòË¶ÅÔºöÁèæ‰ª£ QA Á≥ªÁµ±ÈúÄË¶ÅÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÊâçËÉΩÊèê‰æõÊ∫ñÁ¢∫‰∏îÂÄºÂæó‰ø°Ë≥¥ÁöÑÂõûÊáâ„ÄÇÁÑ∂ËÄåÔºå‰ΩøÁî®ËÄÖÊü•Ë©¢ËàáÁõ∏ÈóúÊñá‰ª∂‰πãÈñìÁöÑÂõ∫ÊúâÂ∑ÆË∑ùÈòªÁ§ô‰∫ÜÁ≤æÁ¢∫ÁöÑÈÖçÂ∞ç„ÄÇÂú®ÊàëÂÄëÁöÑÈåêÂΩ¢ÂàÜ‰ΩàÂÅáË®≠ÁöÑÊøÄÂãµ‰∏ãÔºåË©≤ÂÅáË®≠Ë™çÁÇ∫ÊΩõÂú®Êü•Ë©¢ÂíåÊñá‰ª∂Âú®ÂµåÂÖ•Á©∫Èñì‰∏≠ÂΩ¢ÊàêÈ°ûÈåêÂΩ¢ÁµêÊßãÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü QAEncoderÔºå‰∏ÄÁ®ÆÁÑ°ÈúÄË®ìÁ∑¥ÁöÑÊñπÊ≥ï‰æÜÂΩåÂêàÈÄô‰∏ÄÂ∑ÆË∑ù„ÄÇÂÖ∑È´î‰æÜË™™ÔºåQAEncoder Â∞áÂµåÂÖ•Á©∫Èñì‰∏≠ÊΩõÂú®Êü•Ë©¢ÁöÑÊúüÊúõÂÄº‰º∞Ë®àÁÇ∫Êñá‰ª∂ÂµåÂÖ•ÁöÑÂº∑ÂÅ•Êõø‰ª£Ôºå‰∏¶ÈôÑÂä†Êñá‰ª∂ÊåáÁ¥ã‰ª•ÊúâÊïàÂçÄÂàÜÈÄô‰∫õÂµåÂÖ•„ÄÇÂú®ÂÖ≠Á®ÆË™ûË®ÄÂíåÂÖ´ÂÄãË≥áÊñôÈõÜ‰∏äÁöÑÂçÅÂõõÂÄãÂµåÂÖ•Ê®°Âûã‰∏äÁöÑÂª£Ê≥õÂØ¶È©óÈ©óË≠â‰∫Ü QAEncoder ÁöÑÂ∞çÈΩäËÉΩÂäõÔºåÈÄôÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂç≥ÊèíÂç≥Áî®ÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂèØ‰ª•ËàáÁèæÊúâÁöÑ RAG Êû∂ÊßãÂíåÂü∫ÊñºË®ìÁ∑¥ÁöÑÊñπÊ≥ïÁÑ°Á∏´Êï¥Âêà„ÄÇ

##### **HELPD: Mitigating Hallucination of LVLMs by Hierarchical Feedback Learning with Vision-enhanced Penalty Decoding**
2409.20429v1 by Fan Yuan, Chi Qin, Xiaogang Xu, Piji Li

Large Vision-Language Models (LVLMs) have shown remarkable performance on
many visual-language tasks. However, these models still suffer from multimodal
hallucination, which means the generation of objects or content that violates
the images. Many existing work detects hallucination by directly judging
whether an object exists in an image, overlooking the association between the
object and semantics. To address this issue, we propose Hierarchical Feedback
Learning with Vision-enhanced Penalty Decoding (HELPD). This framework
incorporates hallucination feedback at both object and sentence semantic
levels. Remarkably, even with a marginal degree of training, this approach can
alleviate over 15% of hallucination. Simultaneously, HELPD penalizes the output
logits according to the image attention window to avoid being overly affected
by generated text. HELPD can be seamlessly integrated with any LVLMs. Our
experiments demonstrate that the proposed framework yields favorable results
across multiple hallucination benchmarks. It effectively mitigates
hallucination for different LVLMs and concurrently improves their text
generation quality.

ÊëòË¶ÅÔºöÂ§ßÂûãË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (LVLMs) Âú®Ë®±Â§öË¶ñË¶∫Ë™ûË®Ä‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫Ëâ≤„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°Âûã‰ªçÁÑ∂Â≠òÂú®Â§öÊ®°ÊÖãÂπªË¶∫ÔºåÈÄôË°®Á§∫Áî¢ÁîüÁöÑÁâ©‰ª∂ÊàñÂÖßÂÆπÈÅïÂèç‰∫ÜÂΩ±ÂÉè„ÄÇË®±Â§öÁèæÊúâÂ∑•‰ΩúÈÄèÈÅéÁõ¥Êé•Âà§Êñ∑Áâ©‰ª∂ÊòØÂê¶Â≠òÂú®ÊñºÂΩ±ÂÉè‰∏≠‰æÜÂÅµÊ∏¨ÂπªË¶∫ÔºåÂøΩÁï•‰∫ÜÁâ©‰ª∂ËàáË™ûÁæ©‰πãÈñìÁöÑÈóúËÅØ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂÖ∑ÊúâË¶ñË¶∫Â¢ûÂº∑Êá≤ÁΩ∞Ëß£Á¢ºÁöÑÈöéÂ±§ÂºèÂõûÈ•ãÂ≠∏Áøí (HELPD)„ÄÇÊ≠§Êû∂ÊßãÂú®Áâ©‰ª∂ÂíåÂè•Â≠êË™ûÁæ©Â±§Á¥ö‰∏≠ÈÉΩÁ¥çÂÖ•‰∫ÜÂπªË¶∫ÂõûÈ•ã„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂç≥‰ΩøË®ìÁ∑¥Á®ãÂ∫¶Âæà‰ΩéÔºåÈÄôÁ®ÆÊñπÊ≥ï‰πüËÉΩÊ∏õËºïË∂ÖÈÅé 15% ÁöÑÂπªË¶∫„ÄÇÂêåÊôÇÔºåHELPD ÊúÉÊ†πÊìöÂΩ±ÂÉèÊ≥®ÊÑèÂäõË¶ñÁ™óÊá≤ÁΩ∞Ëº∏Âá∫ logitÔºå‰ª•ÈÅøÂÖçÂèóÂà∞ÁîüÊàêÊñáÂ≠óÈÅéÂ∫¶ÂΩ±Èüø„ÄÇHELPD ÂèØ‰ª•Ëàá‰ªª‰Ωï LVLMs ÁÑ°Á∏´Êï¥Âêà„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË≠âÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊû∂ÊßãÂú®Â§öÂÄãÂπªË¶∫Âü∫Ê∫ñ‰∏≠Áî¢Áîü‰∫ÜËâØÂ•ΩÁöÑÁµêÊûú„ÄÇÂÆÉÊúâÊïàÂú∞Ê∏õËºï‰∫Ü‰∏çÂêå LVLMs ÁöÑÂπªË¶∫Ôºå‰∏¶ÂêåÊôÇÊèêÂçáÂÖ∂ÊñáÂ≠óÁîüÊàêÂìÅË≥™„ÄÇ

##### **Sufficient and Necessary Explanations (and What Lies in Between)**
2409.20427v1 by Beepul Bharti, Paul Yi, Jeremias Sulam

As complex machine learning models continue to find applications in
high-stakes decision-making scenarios, it is crucial that we can explain and
understand their predictions. Post-hoc explanation methods provide useful
insights by identifying important features in an input $\mathbf{x}$ with
respect to the model output $f(\mathbf{x})$. In this work, we formalize and
study two precise notions of feature importance for general machine learning
models: sufficiency and necessity. We demonstrate how these two types of
explanations, albeit intuitive and simple, can fall short in providing a
complete picture of which features a model finds important. To this end, we
propose a unified notion of importance that circumvents these limitations by
exploring a continuum along a necessity-sufficiency axis. Our unified notion,
we show, has strong ties to other popular definitions of feature importance,
like those based on conditional independence and game-theoretic quantities like
Shapley values. Crucially, we demonstrate how a unified perspective allows us
to detect important features that could be missed by either of the previous
approaches alone.

ÊëòË¶ÅÔºöÈö®ËëóË§áÈõúÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÊåÅÁ∫åÂú®È´òÈ¢®Èö™Ê±∫Á≠ñÊÉÖÂ¢É‰∏≠ÊâæÂà∞ÊáâÁî®ÔºåÊàëÂÄëËÉΩÂ§†Ëß£Èáã‰∏¶‰∫ÜËß£ÂÖ∂È†êÊ∏¨Ëá≥ÈóúÈáçË¶Å„ÄÇ‰∫ãÂæåËß£ÈáãÊñπÊ≥ïÈÄèÈÅéËæ®Ë≠òËº∏ÂÖ• $\mathbf{x}$ ‰∏≠Áõ∏Â∞çÊñºÊ®°ÂûãËº∏Âá∫ $f(\mathbf{x})$ ÁöÑÈáçË¶ÅÁâπÂæµÔºåÊèê‰æõ‰∫ÜÊúâÁî®ÁöÑË¶ãËß£„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂΩ¢ÂºèÂåñ‰∏¶Á†îÁ©∂‰∫ÜÂÖ©Á®ÆÁ≤æÁ¢∫ÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÁâπÂæµÈáçË¶ÅÊÄßÊ¶ÇÂøµÔºöÂÖÖÂàÜÊÄßÂíåÂøÖË¶ÅÊÄß„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÈÄôÂÖ©Á®ÆÈ°ûÂûãÁöÑËß£ÈáãÔºåÂÑòÁÆ°Áõ¥ËßÄ‰∏îÁ∞°ÂñÆÔºå‰ΩÜÂú®Êèê‰æõÊ®°ÂûãË™çÁÇ∫ÈáçË¶ÅÁöÑÁâπÂæµÁöÑÂÆåÊï¥ÂúñÂÉèÊñπÈù¢ÂèØËÉΩÊúÉÊúâÊâÄ‰∏çË∂≥„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÁµ±‰∏ÄÁöÑÈáçË¶ÅÊÄßÊ¶ÇÂøµÔºåÈÄèÈÅéÊé¢Á¥¢ÂøÖË¶ÅÊÄß-ÂÖÖÂàÜÊÄßËª∏‰∏äÁöÑÈÄ£Á∫åÁµ±Êï¥È´î‰æÜË¶èÈÅøÈÄô‰∫õÈôêÂà∂„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÁµ±‰∏ÄÊ¶ÇÂøµËàáÂÖ∂‰ªñÊµÅË°åÁöÑÁâπÂæµÈáçË¶ÅÊÄßÂÆöÁæ©ÊúâÂØÜÂàáÈóúËÅØÔºå‰æãÂ¶ÇÂü∫ÊñºÊ¢ù‰ª∂Áç®Á´ãÊÄßÂíåÂçöÂºàË´ñÈáèÔºàÂ¶Ç Shapley ÂÄºÔºâÁöÑÂÆöÁæ©„ÄÇËá≥ÈóúÈáçË¶ÅÁöÑÊòØÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÁµ±‰∏ÄÁöÑËßÄÈªûÂ¶Ç‰ΩïËÆìÊàëÂÄëËÉΩÂ§†ÂÅµÊ∏¨Âà∞‰ª•Ââç‰ªª‰Ωï‰∏ÄÁ®ÆÊñπÊ≥ïÈÉΩÂèØËÉΩÈåØÂ§±ÁöÑÈáçË¶ÅÁâπÂæµ„ÄÇ

##### **World to Code: Multi-modal Data Generation via Self-Instructed Compositional Captioning and Filtering**
2409.20424v1 by Jiacong Wang, Bohong Wu, Haiyong Jiang, Xun Zhou, Xin Xiao, Haoyuan Guo, Jun Xiao

Recent advances in Vision-Language Models (VLMs) and the scarcity of
high-quality multi-modal alignment data have inspired numerous researches on
synthetic VLM data generation. The conventional norm in VLM data construction
uses a mixture of specialists in caption and OCR, or stronger VLM APIs and
expensive human annotation. In this paper, we present World to Code (W2C), a
meticulously curated multi-modal data construction pipeline that organizes the
final generation output into a Python code format. The pipeline leverages the
VLM itself to extract cross-modal information via different prompts and filter
the generated outputs again via a consistency filtering strategy. Experiments
have demonstrated the high quality of W2C by improving various existing visual
question answering and visual grounding benchmarks across different VLMs.
Further analysis also demonstrates that the new code parsing ability of VLMs
presents better cross-modal equivalence than the commonly used detail caption
ability. Our code is available at
https://github.com/foundation-multimodal-models/World2Code.

ÊëòË¶ÅÔºöËøëÊúüÂú®Ë¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) ÁöÑÈÄ≤Â±ï‰ª•ÂèäÈ´òÂìÅË≥™Â§öÊ®°ÊÖãÂ∞çÈΩäË≥áÊñôÁöÑÁ®ÄÁº∫ÔºåÊøÄÁôº‰∫ÜË®±Â§öÈóúÊñºÂêàÊàê VLM Ë≥áÊñôÁî¢ÁîüÁöÑÁ†îÁ©∂„ÄÇVLM Ë≥áÊñôÂª∫Êßã‰∏≠ÁöÑÂÇ≥Áµ±Ë¶èÁØÑ‰ΩøÁî®Ê®ôÈ°åÂíå OCR Â∞àÂÆ∂ÔºåÊàñÊõ¥Âº∑Â§ßÁöÑ VLM API ÂíåÊòÇË≤¥ÁöÑ‰∫∫Â∑•Ê®ôË®ªÁöÑÊ∑∑Âêà„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ñÁïåÂà∞Á®ãÂºèÁ¢º (W2C)Ôºå‰∏ÄÂÄãÁ≤æÂøÉÁ≠ñÂäÉÁöÑÂ§öÊ®°ÊÖãË≥áÊñôÂª∫ÊßãÁÆ°ÈÅìÔºåÂÆÉÂ∞áÊúÄÁµÇÁî¢ÁîüÁöÑËº∏Âá∫ÁµÑÁπîÊàê Python Á®ãÂºèÁ¢ºÊ†ºÂºè„ÄÇË©≤ÁÆ°ÈÅìÂà©Áî® VLM Êú¨Ë∫´ÈÄèÈÅé‰∏çÂêåÁöÑÊèêÁ§∫‰æÜËêÉÂèñË∑®Ê®°ÊÖãË≥áË®äÔºå‰∏¶ÈÄèÈÅé‰∏ÄËá¥ÊÄßÈÅéÊøæÁ≠ñÁï•ÂÜçÊ¨°ÈÅéÊøæÁî¢ÁîüÁöÑËº∏Âá∫„ÄÇÂØ¶È©óÂ∑≤ÈÄèÈÅéÊîπÂñÑ‰∏çÂêå VLM ‰∏≠ÁöÑÂêÑÁ®ÆÁèæÊúâË¶ñË¶∫ÂïèÁ≠îÂíåË¶ñË¶∫Âü∫Á§éÂü∫Ê∫ñ‰æÜË≠âÊòé W2C ÁöÑÈ´òÂìÅË≥™„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑÂàÜÊûê‰πüË≠âÊòé VLM ÁöÑÊñ∞Á®ãÂºèÁ¢ºËß£ÊûêËÉΩÂäõÂëàÁèæÂá∫ÊØî‰∏ÄËà¨‰ΩøÁî®ÁöÑË©≥Á¥∞Ê®ôÈ°åËÉΩÂäõÊõ¥Â•ΩÁöÑË∑®Ê®°ÊÖãÁ≠âÂÉπÊÄß„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/foundation-multimodal-models/World2Code ÂèñÂæó„ÄÇ

##### **Stream-level flow matching from a Bayesian decision theoretic perspective**
2409.20423v1 by Ganchao Wei, Li Ma

Flow matching (FM) is a family of training algorithms for fitting continuous
normalizing flows (CNFs). A standard approach to FM, called conditional flow
matching (CFM), exploits the fact that the marginal vector field of a CNF can
be learned by fitting least-square regression to the so-called conditional
vector field specified given one or both ends of the flow path. We show that
viewing CFM training from a Bayesian decision theoretic perspective on
parameter estimation opens the door to generalizations of CFM algorithms. We
propose one such extension by introducing a CFM algorithm based on defining
conditional probability paths given what we refer to as ``streams'', instances
of latent stochastic paths that connect pairs of noise and observed data.
Further, we advocates the modeling of these latent streams using Gaussian
processes (GPs). The unique distributional properties of GPs, and in particular
the fact that the velocities of a GP is still a GP, allows drawing samples from
the resulting stream-augmented conditional probability path without simulating
the actual streams, and hence the ``simulation-free" nature of CFM training is
preserved. We show that this generalization of the CFM can substantially reduce
the variance in the estimated marginal vector field at a moderate computational
cost, thereby improving the quality of the generated samples under common
metrics. Additionally, we show that adopting the GP on the streams allows for
flexibly linking multiple related training data points (e.g., time series) and
incorporating additional prior information. We empirically validate our claim
through both simulations and applications to two hand-written image datasets.

ÊëòË¶ÅÔºöÊµÅÂåπÈÖç (FM) ÊòØÁî®ÊñºÊì¨ÂêàÈÄ£Á∫åÊ≠£Ë¶èÂåñÊµÅ (CNF) ÁöÑ‰∏ÄÁµÑË®ìÁ∑¥ÊºîÁÆóÊ≥ï„ÄÇ‰∏ÄÁ®ÆÁ®±ÁÇ∫Ê¢ù‰ª∂ÊµÅÂåπÈÖç (CFM) ÁöÑÊ®ôÊ∫ñ FM ÊñπÊ≥ïÂà©Áî®‰∫Ü CNF ÁöÑÈÇäÈöõÂêëÈáèÂ†¥ÂèØ‰ª•ÈÄèÈÅéÊì¨ÂêàÊúÄÂ∞èÂπ≥ÊñπËø¥Ê≠∏‰æÜÂ≠∏ÁøíÔºå‰ª•ÊåáÂÆöÁµ¶ÂÆöÊµÅË∑ØÂæë‰∏ÄÁ´ØÊàñÂÖ©Á´ØÁöÑÊ¢ù‰ª∂ÂêëÈáèÂ†¥„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂæûË≤ùÊ∞èÊ±∫Á≠ñÁêÜË´ñËßÄÈªûÊ™¢Ë¶ñ CFM Ë®ìÁ∑¥ÔºåÂú®ÂèÉÊï∏‰º∞Ë®à‰∏äÈñãÂïü‰∫Ü CFM ÊºîÁÆóÊ≥ïÁöÑÊ¶ÇÊã¨„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÈÄôÊ®£ÁöÑÂª∂‰º∏ÔºåÈÄèÈÅéÂºïÂÖ•Âü∫ÊñºÂÆöÁæ©Ê¢ù‰ª∂Ê©üÁéáË∑ØÂæëÁöÑ CFM ÊºîÁÆóÊ≥ïÔºåÁµ¶ÂÆöÊàëÂÄëÁ®±ÁÇ∫„Äå‰∏≤ÊµÅ„ÄçÁöÑÊΩõÂú®Èö®Ê©üË∑ØÂæëÔºåÈÄ£Êé•ÈõúË®äÂíåËßÄÂØüË≥áÊñôÂ∞ç„ÄÇÊ≠§Â§ñÔºåÊàëÂÄë‰∏ªÂºµ‰ΩøÁî®È´òÊñØÈÅéÁ®ã (GP) Â∞çÈÄô‰∫õÊΩõÂú®‰∏≤ÊµÅÈÄ≤Ë°åÂª∫Ê®°„ÄÇGP ÁöÑÁç®ÁâπÂàÜ‰ΩàÁâπÊÄßÔºåÁâπÂà•ÊòØ GP ÁöÑÈÄüÂ∫¶‰ªçÁÇ∫ GP ÁöÑ‰∫ãÂØ¶ÔºåÂÖÅË®±Âæû‰∏≤ÊµÅÂ¢ûÂº∑ÁöÑÊ¢ù‰ª∂Ê©üÁéáË∑ØÂæë‰∏≠ÊäΩÂèñÊ®£Êú¨ÔºåËÄåÁÑ°ÈúÄÊ®°Êì¨ÂØ¶Èöõ‰∏≤ÊµÅÔºåÂõ†Ê≠§ CFM Ë®ìÁ∑¥ÁöÑ„ÄåÁÑ°Ê®°Êì¨„ÄçÊÄßË≥™Âæó‰ª•‰øùÁïô„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü CFM ÁöÑÈÄôÁ®ÆÊ¶ÇÊã¨ÂèØ‰ª•Âú®ÈÅ©Â∫¶ÁöÑÈÅãÁÆóÊàêÊú¨‰∏ãÂ§ßÂπÖÊ∏õÂ∞ë‰º∞Ë®àÈÇäÈöõÂêëÈáèÂ†¥ÁöÑËÆäÁï∞ÔºåÂæûËÄåÊîπÂñÑÂ∏∏Ë¶ãÊåáÊ®ô‰∏ãÁî¢ÁîüÊ®£Êú¨ÁöÑÂìÅË≥™„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂú®‰∏≤ÊµÅ‰∏äÊé°Áî® GP ÂèØ‰ª•ÈùàÊ¥ªÂú∞ÈÄ£ÁµêÂ§öÂÄãÁõ∏ÈóúÁöÑË®ìÁ∑¥Ë≥áÊñôÈªûÔºà‰æãÂ¶ÇÊôÇÈñìÂ∫èÂàóÔºâÔºå‰∏¶Á¥çÂÖ•ÂÖ∂‰ªñÂÖàÈ©óË≥áË®ä„ÄÇÊàëÂÄëÈÄèÈÅéÊ®°Êì¨ÂíåÊáâÁî®ÊñºÂÖ©ÂÄãÊâãÂØ´ÂΩ±ÂÉèË≥áÊñôÈõÜÔºåÂØ¶Ë≠âÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑË™™Ê≥ï„ÄÇ

##### **Conformal Prediction for Dose-Response Models with Continuous Treatments**
2409.20412v1 by Jarne Verhaeghe, Jef Jonkers, Sofie Van Hoecke

Understanding the dose-response relation between a continuous treatment and
the outcome for an individual can greatly drive decision-making, particularly
in areas like personalized drug dosing and personalized healthcare
interventions. Point estimates are often insufficient in these high-risk
environments, highlighting the need for uncertainty quantification to support
informed decisions. Conformal prediction, a distribution-free and
model-agnostic method for uncertainty quantification, has seen limited
application in continuous treatments or dose-response models. To address this
gap, we propose a novel methodology that frames the causal dose-response
problem as a covariate shift, leveraging weighted conformal prediction. By
incorporating propensity estimation, conformal predictive systems, and
likelihood ratios, we present a practical solution for generating prediction
intervals for dose-response models. Additionally, our method approximates local
coverage for every treatment value by applying kernel functions as weights in
weighted conformal prediction. Finally, we use a new synthetic benchmark
dataset to demonstrate the significance of covariate shift assumptions in
achieving robust prediction intervals for dose-response models.

ÊëòË¶ÅÔºö‰∫ÜËß£ËøûÁª≠Ê≤ªÁñó‰∏é‰∏™‰∫∫ÁªìÊûú‰πãÈó¥ÁöÑÂâÇÈáèÂèçÂ∫îÂÖ≥Á≥ªÂèØ‰ª•ÊûÅÂ§ßÂú∞Êé®Âä®ÂÜ≥Á≠ñÂà∂ÂÆöÔºåÂ∞§ÂÖ∂ÊòØÂú®‰∏™ÊÄßÂåñËçØÁâ©ÁªôËçØÂíå‰∏™ÊÄßÂåñÂåªÁñó‰øùÂÅ•Âπ≤È¢ÑÁ≠âÈ¢ÜÂüü„ÄÇÂú®Ëøô‰∫õÈ´òÈ£éÈô©ÁéØÂ¢É‰∏≠ÔºåÁÇπ‰º∞ËÆ°ÈÄöÂ∏∏ÊòØ‰∏çÂ§üÁöÑÔºåËøôÁ™ÅÂá∫‰∫ÜÂØπ‰∏çÁ°ÆÂÆöÊÄßÈáèÂåñÁöÑÈúÄÊ±ÇÔºå‰ª•ÊîØÊåÅÊòéÊô∫ÁöÑÂÜ≥Á≠ñ„ÄÇ‰∏ÄËá¥ÊÄßÈ¢ÑÊµãÊòØ‰∏ÄÁßç‰∏ç‰æùËµñÂàÜÂ∏É‰∏î‰∏éÊ®°ÂûãÊó†ÂÖ≥ÁöÑ‰∏çÁ°ÆÂÆöÊÄßÈáèÂåñÊñπÊ≥ïÔºåÂú®ËøûÁª≠Ê≤ªÁñóÊàñÂâÇÈáèÂèçÂ∫îÊ®°Âûã‰∏≠ÁöÑÂ∫îÁî®ÂèóÂà∞ÈôêÂà∂„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÂ∑ÆË∑ùÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÊñπÊ≥ïÔºåÂ∞ÜÂõ†ÊûúÂâÇÈáèÂèçÂ∫îÈóÆÈ¢òÊûÑÂª∫‰∏∫ÂçèÂèòÈáèËΩ¨ÁßªÔºåÂà©Áî®Âä†ÊùÉ‰∏ÄËá¥ÊÄßÈ¢ÑÊµã„ÄÇÈÄöËøáÁ∫≥ÂÖ•ÂÄæÂêë‰º∞ËÆ°„ÄÅ‰∏ÄËá¥ÊÄßÈ¢ÑÊµãÁ≥ªÁªüÂíå‰ººÁÑ∂ÊØîÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÂÆûÁî®ÁöÑËß£ÂÜ≥ÊñπÊ°àÔºåÁî®‰∫éÁîüÊàêÂâÇÈáèÂèçÂ∫îÊ®°ÂûãÁöÑÈ¢ÑÊµãÂå∫Èó¥„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÈÄöËøáÂú®Âä†ÊùÉ‰∏ÄËá¥ÊÄßÈ¢ÑÊµã‰∏≠Â∫îÁî®Ê†∏ÂáΩÊï∞‰Ωú‰∏∫ÊùÉÈáçÔºå‰∏∫ÊØè‰∏™Ê≤ªÁñóÂÄºËøë‰ººÂ±ÄÈÉ®Ë¶ÜÁõñ„ÄÇÊúÄÂêéÔºåÊàë‰ª¨‰ΩøÁî®‰∏Ä‰∏™Êñ∞ÁöÑÂêàÊàêÂü∫ÂáÜÊï∞ÊçÆÈõÜÊù•ËØÅÊòéÂçèÂèòÈáèËΩ¨ÁßªÂÅáËÆæÂú®ÂÆûÁé∞ÂâÇÈáèÂèçÂ∫îÊ®°ÂûãÁöÑÁ®≥ÂÅ•È¢ÑÊµãÂå∫Èó¥‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **Anti-stereotypical Predictive Text Suggestions Do Not Reliably Yield Anti-stereotypical Writing**
2409.20390v1 by Connor Baumler, Hal Daum√© III

AI-based systems such as language models can replicate and amplify social
biases reflected in their training data. Among other questionable behavior,
this can lead to LM-generated text--and text suggestions--that contain
normatively inappropriate stereotypical associations. In this paper, we
consider the question of how "debiasing" a language model impacts stories that
people write using that language model in a predictive text scenario. We find
that (n=414), in certain scenarios, language model suggestions that align with
common social stereotypes are more likely to be accepted by human authors.
Conversely, although anti-stereotypical language model suggestions sometimes
lead to an increased rate of anti-stereotypical stories, this influence is far
from sufficient to lead to "fully debiased" stories.

ÊëòË¶ÅÔºöÂü∫Êñº AI ÁöÑÁ≥ªÁµ±Ôºå‰æãÂ¶ÇË™ûË®ÄÊ®°ÂûãÔºåÂèØ‰ª•Ë§áË£ΩÂíåÊîæÂ§ßË®ìÁ∑¥Ë≥áÊñô‰∏≠ÂèçÊò†ÁöÑÁ§æÊúÉÂÅèË¶ã„ÄÇÂú®ÂÖ∂‰ªñÂèØÁñëË°åÁÇ∫‰∏≠ÔºåÈÄôÂèØËÉΩÂ∞éËá¥ LM ÁîüÊàêÁöÑÊñáÂ≠óÂíåÊñáÂ≠óÂª∫Ë≠∞ÂåÖÂê´Ë¶èÁØÑ‰∏ä‰∏çÈÅ©Áï∂ÁöÑÂàªÊùøÂç∞Ë±°ËÅØÊÉ≥„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëËÄÉÊÖÆ‰∫Ü„ÄåÂéªÂÅèË¶ã„ÄçË™ûË®ÄÊ®°ÂûãÂ¶Ç‰ΩïÂΩ±Èüø‰∫∫ÂÄëÂú®È†êÊ∏¨ÊñáÂ≠óÂ†¥ÊôØ‰∏≠‰ΩøÁî®Ë©≤Ë™ûË®ÄÊ®°ÂûãÊí∞ÂØ´ÁöÑÊïÖ‰∫ãÁöÑÂïèÈ°å„ÄÇÊàëÂÄëÁôºÁèæ (n=414)ÔºåÂú®Êüê‰∫õÊÉÖÊ≥Å‰∏ãÔºåËàáÂ∏∏Ë¶ãÁ§æÊúÉÂàªÊùøÂç∞Ë±°‰∏ÄËá¥ÁöÑË™ûË®ÄÊ®°ÂûãÂª∫Ë≠∞Êõ¥ÊúâÂèØËÉΩË¢´‰∫∫È°û‰ΩúËÄÖÊé•Âèó„ÄÇÁõ∏ÂèçÔºåÂÑòÁÆ°ÂèçÂàªÊùøÂç∞Ë±°Ë™ûË®ÄÊ®°ÂûãÂª∫Ë≠∞ÊúâÊôÇÊúÉÂ∞éËá¥ÂèçÂàªÊùøÂç∞Ë±°ÊïÖ‰∫ãÁöÑÊØîÁéáÂ¢ûÂä†Ôºå‰ΩÜÈÄôÁ®ÆÂΩ±ÈüøÈÅ†‰∏çË∂≥‰ª•Â∞éËá¥„ÄåÂÆåÂÖ®ÂéªÂÅèË¶ã„ÄçÁöÑÊïÖ‰∫ã„ÄÇ

##### **Wait, but Tylenol is Acetaminophen... Investigating and Improving Language Models' Ability to Resist Requests for Misinformation**
2409.20385v1 by Shan Chen, Mingye Gao, Kuleen Sasse, Thomas Hartvigsen, Brian Anthony, Lizhou Fan, Hugo Aerts, Jack Gallifant, Danielle Bitterman

Background: Large language models (LLMs) are trained to follow directions,
but this introduces a vulnerability to blindly comply with user requests even
if they generate wrong information. In medicine, this could accelerate the
generation of misinformation that impacts human well-being.
  Objectives/Methods: We analyzed compliance to requests to generate misleading
content about medications in settings where models know the request is
illogical. We investigated whether in-context directions and instruction-tuning
of LLMs to prioritize logical reasoning over compliance reduced misinformation
risk.
  Results: While all frontier LLMs complied with misinformation requests, both
prompt-based and parameter-based approaches can improve the detection of logic
flaws in requests and prevent the dissemination of medical misinformation.
  Conclusion: Shifting LLMs to prioritize logic over compliance could reduce
risks of exploitation for medical misinformation.

ÊëòË¶ÅÔºöËÉåÊôØÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êé•ÂèóË®ìÁ∑¥‰ª•ÈÅµÂæ™ÊåáÁ§∫Ôºå‰ΩÜÈÄôÂ∞éËá¥‰∫Ü‰∏ÄÂÄãÊºèÊ¥ûÔºåÂç≥‰ΩøÂÆÉÂÄëÊúÉÁî¢ÁîüÈåØË™§Ë≥áË®äÔºå‰πüÊúÉÁõ≤ÁõÆÂú∞ÈÅµÂÆà‰ΩøÁî®ËÄÖÁöÑË¶ÅÊ±Ç„ÄÇÂú®ÈÜ´Â≠∏È†òÂüüÔºåÈÄôÂèØËÉΩÊúÉÂä†ÈÄüÁî¢ÁîüÈåØË™§Ë≥áË®äÔºåÈÄ≤ËÄåÂΩ±Èüø‰∫∫È°ûÁöÑÂÅ•Â∫∑„ÄÇ
ÁõÆÊ®ô/ÊñπÊ≥ïÔºöÊàëÂÄëÂàÜÊûê‰∫ÜÂú®Ê®°ÂûãÁü•ÈÅìË´ãÊ±Ç‰∏çÂêàÁêÜÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂ∞çÁî¢ÁîüÊúâÈóúËó•Áâ©ÁöÑË™§Â∞éÂÖßÂÆπË´ãÊ±ÇÁöÑÈÅµÂÆàÊÉÖÊ≥Å„ÄÇÊàëÂÄëË™øÊü•‰∫ÜÊÉÖÂ¢ÉÊåáÁ§∫Âíå LLM ÁöÑÊåá‰ª§Ë™øÊï¥ÊòØÂê¶ÂèØ‰ª•ÂÑ™ÂÖàËÄÉÊÖÆÈÇèËºØÊé®ÁêÜÔºåÈ´òÊñºÈÅµÂæ™ÊåáÁ§∫ÔºåÈÄ≤ËÄåÈôç‰ΩéÈåØË™§Ë≥áË®äÁöÑÈ¢®Èö™„ÄÇ
ÁµêÊûúÔºöÈõñÁÑ∂ÊâÄÊúâÂâçÊ≤ø LLM ÈÉΩÈÅµÂÆàÈåØË™§Ë≥áË®äË´ãÊ±ÇÔºå‰ΩÜÂü∫ÊñºÊèêÁ§∫ÂíåÂü∫ÊñºÂèÉÊï∏ÁöÑÊñπÊ≥ïÈÉΩÂèØ‰ª•ÊîπÂñÑÂ∞çË´ãÊ±Ç‰∏≠ÈÇèËºØÁº∫Èô∑ÁöÑÂÅµÊ∏¨Ôºå‰∏¶Èò≤Ê≠¢ÈÜ´Â≠∏ÈåØË™§Ë≥áË®äÁöÑÂÇ≥Êí≠„ÄÇ
ÁµêË´ñÔºöÂ∞á LLM ËΩâÁßªÂà∞ÂÑ™ÂÖàËÄÉÊÖÆÈÇèËºØÈ´òÊñºÈÅµÂæ™ÊåáÁ§∫ÔºåÂèØ‰ª•Èôç‰ΩéÈåØË™§Ë≥áË®äË¢´Áî®ÊñºÈÜ´ÁôÇÁõÆÁöÑÁöÑÈ¢®Èö™„ÄÇ

##### **Word-wise intonation model for cross-language TTS systems**
2409.20374v1 by Tomilov A. A., Gromova A. Y., Svischev A. N

In this paper we propose a word-wise intonation model for Russian language
and show how it can be generalized for other languages. The proposed model is
suitable for automatic data markup and its extended application to
text-to-speech systems. It can also be implemented for an intonation contour
modeling by using rule-based algorithms or by predicting contours with language
models. The key idea is a partial elimination of the variability connected with
different placements of a stressed syllable in a word. It is achieved with
simultaneous applying of pitch simplification with a dynamic time warping
clustering. The proposed model could be used as a tool for intonation research
or as a backbone for prosody description in text-to-speech systems. As the
advantage of the model, we show its relations with the existing intonation
systems as well as the possibility of using language models for prosody
prediction. Finally, we demonstrate some practical evidence of the system
robustness to parameter variations.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰øÑËØ≠ÂçïËØçÁ∫ßÁöÑËØ≠Ë∞ÉÊ®°ÂûãÔºåÂπ∂Â±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÂ∞ÜÂÖ∂Êé®ÂπøÂà∞ÂÖ∂‰ªñËØ≠Ë®Ä„ÄÇÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÈÄÇÁî®‰∫éËá™Âä®Êï∞ÊçÆÊ†áËÆ∞ÂèäÂÖ∂Âú®ÊñáÊú¨Âà∞ËØ≠Èü≥Á≥ªÁªüÁöÑÊâ©Â±ïÂ∫îÁî®„ÄÇÂÆÉËøòÂèØ‰ª•ÈÄöËøá‰ΩøÁî®Âü∫‰∫éËßÑÂàôÁöÑÁÆóÊ≥ïÊàñÈÄöËøá‰ΩøÁî®ËØ≠Ë®ÄÊ®°ÂûãÈ¢ÑÊµãËΩÆÂªìÊù•ÂÆûÁé∞ËØ≠Ë∞ÉËΩÆÂªìÂª∫Ê®°„ÄÇÂÖ≥ÈîÆÊÄùÊÉ≥ÊòØÈÉ®ÂàÜÊ∂àÈô§‰∏éÂçïËØç‰∏≠ÈáçËØªÈü≥ËäÇ‰∏çÂêå‰ΩçÁΩÆÁõ∏ÂÖ≥ÁöÑÂèØÂèòÊÄß„ÄÇËøôÊòØÈÄöËøáÂêåÊó∂Â∫îÁî®Èü≥È´òÁÆÄÂåñÂíåÂä®ÊÄÅÊó∂Èó¥Êâ≠Êõ≤ËÅöÁ±ªÊù•ÂÆûÁé∞ÁöÑ„ÄÇÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂèØ‰ª•Áî®‰ΩúËØ≠Ë∞ÉÁ†îÁ©∂ÁöÑÂ∑•ÂÖ∑ÔºåÊàñ‰Ωú‰∏∫ÊñáÊú¨Âà∞ËØ≠Èü≥Á≥ªÁªü‰∏≠ÈüµÂæãÊèèËø∞ÁöÑÈ™®Âπ≤„ÄÇ‰Ωú‰∏∫ËØ•Ê®°ÂûãÁöÑ‰ºòÁÇπÔºåÊàë‰ª¨Â±ïÁ§∫‰∫ÜÂÆÉ‰∏éÁé∞ÊúâËØ≠Ë∞ÉÁ≥ªÁªüÁöÑÂÖ≥Á≥ªÔºå‰ª•Âèä‰ΩøÁî®ËØ≠Ë®ÄÊ®°ÂûãËøõË°åÈüµÂæãÈ¢ÑÊµãÁöÑÂèØËÉΩÊÄß„ÄÇÊúÄÂêéÔºåÊàë‰ª¨Â±ïÁ§∫‰∫ÜÁ≥ªÁªüÂØπÂèÇÊï∞ÂèòÂåñÁöÑÈ≤ÅÊ£íÊÄßÁöÑÂÆûÈôÖËØÅÊçÆ„ÄÇ

##### **Frequency Adaptive Normalization For Non-stationary Time Series Forecasting**
2409.20371v1 by Weiwei Ye, Songgaojun Deng, Qiaosha Zou, Ning Gui

Time series forecasting typically needs to address non-stationary data with
evolving trend and seasonal patterns. To address the non-stationarity,
reversible instance normalization has been recently proposed to alleviate
impacts from the trend with certain statistical measures, e.g., mean and
variance. Although they demonstrate improved predictive accuracy, they are
limited to expressing basic trends and are incapable of handling seasonal
patterns. To address this limitation, this paper proposes a new instance
normalization solution, called frequency adaptive normalization (FAN), which
extends instance normalization in handling both dynamic trend and seasonal
patterns. Specifically, we employ the Fourier transform to identify
instance-wise predominant frequent components that cover most non-stationary
factors. Furthermore, the discrepancy of those frequency components between
inputs and outputs is explicitly modeled as a prediction task with a simple MLP
model. FAN is a model-agnostic method that can be applied to arbitrary
predictive backbones. We instantiate FAN on four widely used forecasting models
as the backbone and evaluate their prediction performance improvements on eight
benchmark datasets. FAN demonstrates significant performance advancement,
achieving 7.76% ~ 37.90% average improvements in MSE.

ÊëòË¶ÅÔºöÊôÇÈñìÂ∫èÂàóÈ†êÊ∏¨ÈÄöÂ∏∏ÈúÄË¶ÅËôïÁêÜÂÖ∑ÊúâÊºîÂåñË∂®Âã¢ÂíåÂ≠£ÁØÄÊÄßÊ®°ÂºèÁöÑÈùûÂπ≥Á©©Êï∏Êìö„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈùûÂπ≥Á©©ÊÄßÔºåÊúÄËøëÊèêÂá∫‰∫ÜÂèØÈÄÜÂØ¶‰æãÊ≠£Ë¶èÂåñÔºå‰ª•‰ΩøÁî®Êüê‰∫õÁµ±Ë®àÈáèÔºà‰æãÂ¶ÇÂπ≥ÂùáÂÄºÂíåËÆäÁï∞Êï∏ÔºâÊ∏õËºïË∂®Âã¢ÁöÑÂΩ±Èüø„ÄÇÂÑòÁÆ°ÂÆÉÂÄëÂ±ïÁ§∫‰∫ÜÊîπÈÄ≤ÁöÑÈ†êÊ∏¨Ê∫ñÁ¢∫ÊÄßÔºå‰ΩÜÂÆÉÂÄëÂÉÖÈôêÊñºË°®ÈÅîÂü∫Êú¨Ë∂®Âã¢Ôºå‰∏¶‰∏îÁÑ°Ê≥ïËôïÁêÜÂ≠£ÁØÄÊÄßÊ®°Âºè„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÈôêÂà∂ÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂØ¶‰æãÊ≠£Ë¶èÂåñËß£Ê±∫ÊñπÊ°àÔºåÁ®±ÁÇ∫È†ªÁéáËá™ÈÅ©ÊáâÊ≠£Ë¶èÂåñ (FAN)ÔºåÂÆÉÊì¥Â±ï‰∫ÜÂØ¶‰æãÊ≠£Ë¶èÂåñÔºå‰ª•ËôïÁêÜÂãïÊÖãË∂®Âã¢ÂíåÂ≠£ÁØÄÊÄßÊ®°Âºè„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄë‰ΩøÁî®ÂÇÖÁ´ãËëâËΩâÊèõ‰æÜË≠òÂà•Ë¶ÜËìãÂ§ßÂ§öÊï∏ÈùûÂπ≥Á©©Âõ†Á¥†ÁöÑÂØ¶‰æãÁ¥ö‰∏ªË¶ÅÈ†ªÁéáÂàÜÈáè„ÄÇÊ≠§Â§ñÔºåËº∏ÂÖ•ÂíåËº∏Âá∫‰πãÈñìÈÄô‰∫õÈ†ªÁéáÂàÜÈáèÁöÑÂ∑ÆÁï∞Ë¢´ÊòéÁ¢∫Âª∫Ê®°ÁÇ∫ÂÖ∑ÊúâÁ∞°ÂñÆ MLP Ê®°ÂûãÁöÑÈ†êÊ∏¨‰ªªÂãô„ÄÇFAN ÊòØ‰∏ÄÂÄãËàáÊ®°ÂûãÁÑ°ÈóúÁöÑÊñπÊ≥ïÔºåÂèØ‰ª•ÊáâÁî®Êñº‰ªªÊÑèÈ†êÊ∏¨‰∏ªÂππ„ÄÇÊàëÂÄëÂú®ÂõõÂÄãÂª£Ê≥õ‰ΩøÁî®ÁöÑÈ†êÊ∏¨Ê®°Âûã‰∏äÂØ¶‰æãÂåñ FAN ‰ΩúÁÇ∫‰∏ªÂππÔºå‰∏¶Âú®ÂÖ´ÂÄãÂü∫Ê∫ñÊï∏ÊìöÈõÜ‰∏äË©ï‰º∞ÂÆÉÂÄëÁöÑÈ†êÊ∏¨ÊÄßËÉΩÊîπÈÄ≤„ÄÇFAN Â±ïÁ§∫‰∫ÜÈ°ØËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÂú® MSE ‰∏≠ÂØ¶Áèæ‰∫Ü 7.76% ~ 37.90% ÁöÑÂπ≥ÂùáÊîπÈÄ≤„ÄÇ

##### **The Perfect Blend: Redefining RLHF with Mixture of Judges**
2409.20370v1 by Tengyu Xu, Eryk Helenowski, Karthik Abinav Sankararaman, Di Jin, Kaiyan Peng, Eric Han, Shaoliang Nie, Chen Zhu, Hejia Zhang, Wenxuan Zhou, Zhouhao Zeng, Yun He, Karishma Mandyam, Arya Talabzadeh, Madian Khabsa, Gabriel Cohen, Yuandong Tian, Hao Ma, Sinong Wang, Han Fang

Reinforcement learning from human feedback (RLHF) has become the leading
approach for fine-tuning large language models (LLM). However, RLHF has
limitations in multi-task learning (MTL) due to challenges of reward hacking
and extreme multi-objective optimization (i.e., trade-off of multiple and/or
sometimes conflicting objectives). Applying RLHF for MTL currently requires
careful tuning of the weights for reward model and data combinations. This is
often done via human intuition and does not generalize. In this work, we
introduce a novel post-training paradigm which we called Constrained Generative
Policy Optimization (CGPO). The core of CGPO is Mixture of Judges (MoJ) with
cost-efficient constrained policy optimization with stratification, which can
identify the perfect blend in RLHF in a principled manner. It shows strong
empirical results with theoretical guarantees, does not require extensive
hyper-parameter tuning, and is plug-and-play in common post-training pipelines.
Together, this can detect and mitigate reward hacking behaviors while reaching
a pareto-optimal point across an extremely large number of objectives.
  Our empirical evaluations demonstrate that CGPO significantly outperforms
standard RLHF algorithms like PPO and DPO across various tasks including
general chat, STEM questions, instruction following, and coding. Specifically,
CGPO shows improvements of 7.4% in AlpacaEval-2 (general chat), 12.5% in
Arena-Hard (STEM & reasoning), and consistent gains in other domains like math
and coding. Notably, PPO, while commonly used, is prone to severe reward
hacking in popular coding benchmarks, which CGPO successfully addresses. This
breakthrough in RLHF not only tackles reward hacking and extreme
multi-objective optimization challenges but also advances the state-of-the-art
in aligning general-purpose LLMs for diverse applications.

ÊëòË¶ÅÔºö‰∫∫È°ûÂõûÈ•ãÂº∑ÂåñÂ≠∏Áøí (RLHF) Â∑≤ÊàêÁÇ∫ÂæÆË™øÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈ†òÂÖàÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåRLHF Âú®Â§ö‰ªªÂãôÂ≠∏Áøí (MTL) ‰∏≠ÂèóÂà∞ÁçéÂãµÁ†¥Ëß£ÂíåÊ•µÁ´ØÂ§öÁõÆÊ®ôÊúÄ‰Ω≥ÂåñÔºà‰æãÂ¶ÇÔºåÂ§öÈáçÂíå/ÊàñÊúâÊôÇÁõ∏‰∫íË°ùÁ™ÅÁöÑÁõÆÊ®ô‰πãÈñìÁöÑÂèñÊç®ÔºâÁöÑÊåëÊà∞ËÄåÊúâÊâÄÈôêÂà∂„ÄÇÁõÆÂâçÔºåÂ∞á RLHF ÊáâÁî®Êñº MTL ÈúÄË¶Å‰ªîÁ¥∞Ë™øÊï¥ÁçéÂãµÊ®°ÂûãÂíåË≥áÊñôÁµÑÂêàÁöÑÊ¨äÈáç„ÄÇÈÄôÈÄöÂ∏∏ÊòØÈÄèÈÅé‰∫∫È°ûÁõ¥Ë¶∫‰æÜÂÆåÊàêÔºåËÄå‰∏îÁÑ°Ê≥ïÊ¶ÇÊã¨„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑË®ìÁ∑¥ÂæåÁØÑ‰æãÔºåÊàëÂÄëÁ®±‰πãÁÇ∫ÂèóÁ¥ÑÊùüÁîüÊàêÁ≠ñÁï•ÊúÄ‰Ω≥Âåñ (CGPO)„ÄÇCGPO ÁöÑÊ†∏ÂøÉÊòØÊ≥ïÂÆòÊ∑∑Âêà (MoJ)ÔºåÈÄèÈÅéÂàÜÂ±§ÈÄ≤Ë°åÂÖ∑ÊúâÊàêÊú¨ÊïàÁõäÁöÑÂèóÁ¥ÑÊùüÁ≠ñÁï•ÊúÄ‰Ω≥ÂåñÔºåÂÆÉÂèØ‰ª•‰ª•ÂéüÂâáÊÄßÁöÑÊñπÂºèÊâæÂá∫ RLHF ‰∏≠ÁöÑÂÆåÁæéËûçÂêà„ÄÇÂÆÉÂú®ÁêÜË´ñ‰øùË≠â‰∏ãÂ±ïÁèæÂº∑Â§ßÁöÑÂØ¶Ë≠âÁµêÊûúÔºå‰∏çÈúÄË¶ÅÂª£Ê≥õÁöÑË∂ÖÂèÉÊï∏Ë™øÊï¥Ôºå‰∏¶‰∏îÂèØ‰ª•Âç≥ÊèíÂç≥Áî®ÊñºÂ∏∏Ë¶ãÁöÑË®ìÁ∑¥ÂæåÁÆ°ÈÅì„ÄÇÁ∏Ω‰πãÔºåÂÆÉÂèØ‰ª•Âú®Ê•µÂ§ßÈáèÁöÑÁõÆÊ®ô‰∏≠ÂÅµÊ∏¨ÂíåÊ∏õËºïÁçéÂãµÁ†¥Ëß£Ë°åÁÇ∫ÔºåÂêåÊôÇÈÅîÂà∞Â∏ïÈõ∑ÊâòÊúÄÂÑ™Èªû„ÄÇÊàëÂÄëÁöÑÂØ¶Ë≠âË©ï‰º∞Ë≠âÊòéÔºåCGPO Âú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠È°ØËëóÂÑ™ÊñºÊ®ôÊ∫ñ RLHF ÊºîÁÆóÊ≥ïÔºå‰æãÂ¶Ç‰∏ÄËà¨ËÅäÂ§©„ÄÅSTEM ÂïèÈ°å„ÄÅÊåá‰ª§ÈÅµÂæ™ÂíåÁ∑®Á¢º„ÄÇÂÖ∑È´î‰æÜË™™ÔºåCGPO Âú® AlpacaEval-2Ôºà‰∏ÄËà¨ËÅäÂ§©Ôºâ‰∏≠ÊèêÂçá‰∫Ü 7.4%ÔºåÂú® Arena-HardÔºàSTEM ÂíåÊé®ÁêÜÔºâ‰∏≠ÊèêÂçá‰∫Ü 12.5%Ôºå‰∏¶‰∏îÂú®Êï∏Â≠∏ÂíåÁ∑®Á¢ºÁ≠âÂÖ∂‰ªñÈ†òÂüü‰∏≠ÊåÅÁ∫åÁç≤ÂæóÊî∂Áõä„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåPPO ÈõñÁÑ∂ÊôÆÈÅç‰ΩøÁî®Ôºå‰ΩÜÂú®ÊµÅË°åÁöÑÁ∑®Á¢ºÂü∫Ê∫ñ‰∏≠ÂÆπÊòìÂèóÂà∞Âö¥ÈáçÁöÑÁçéÂãµÁ†¥Ëß£ÔºåËÄå CGPO ÊàêÂäüÂú∞Ëß£Ê±∫‰∫ÜÈÄôÂÄãÂïèÈ°å„ÄÇRLHF ÁöÑÈÄôÈ†ÖÁ™ÅÁ†¥‰∏çÂÉÖËß£Ê±∫‰∫ÜÁçéÂãµÁ†¥Ëß£ÂíåÊ•µÁ´ØÂ§öÁõÆÊ®ôÊúÄ‰Ω≥ÂåñÁöÑÊåëÊà∞ÔºåËÄå‰∏îÈÇÑÊé®Âãï‰∫ÜÂ∞áÈÄöÁî® LLM ËàáÂêÑÁ®ÆÊáâÁî®Á®ãÂºèÁõ∏ÁµêÂêàÁöÑÊúÄÊñ∞ÊäÄË°ì„ÄÇ

##### **Disentangling Singlish Discourse Particles with Task-Driven Representation**
2409.20366v1 by Linus Tze En Foo, Lynnette Hui Xian Ng

Singlish, or formally Colloquial Singapore English, is an English-based
creole language originating from the SouthEast Asian country Singapore. The
language contains influences from Sinitic languages such as Chinese dialects,
Malay, Tamil and so forth. A fundamental task to understanding Singlish is to
first understand the pragmatic functions of its discourse particles, upon which
Singlish relies heavily to convey meaning. This work offers a preliminary
effort to disentangle the Singlish discourse particles (lah, meh and hor) with
task-driven representation learning. After disentanglement, we cluster these
discourse particles to differentiate their pragmatic functions, and perform
Singlish-to-English machine translation. Our work provides a computational
method to understanding Singlish discourse particles, and opens avenues towards
a deeper comprehension of the language and its usage.

ÊëòË¶ÅÔºöÊòüÂºèËã±ËØ≠ÔºåÊàñÊ≠£ÂºèÂêçÁß∞‰∏∫Êñ∞Âä†Âù°Âè£ËØ≠Ëã±ËØ≠ÔºåÊòØ‰∏ÄÁßç‰ª•Ëã±ËØ≠‰∏∫Âü∫Á°ÄÁöÑÂÖãÈáåÂ••Â∞îËØ≠ÔºåËµ∑Ê∫ê‰∫é‰∏úÂçó‰∫öÂõΩÂÆ∂Êñ∞Âä†Âù°„ÄÇËØ•ËØ≠Ë®ÄÂåÖÂê´Ê±âËØ≠ÊñπË®Ä„ÄÅÈ©¨Êù•ËØ≠„ÄÅÊ≥∞Á±≥Â∞îËØ≠Á≠âÊ±âËØ≠ËØ≠Ë®ÄÁöÑÂΩ±Âìç„ÄÇÁêÜËß£ÊòüÂºèËã±ËØ≠ÁöÑ‰∏ÄÈ°πÂü∫Êú¨‰ªªÂä°ÊòØÈ¶ñÂÖàÁêÜËß£ÂÖ∂ËØùËØ≠Á≤íÂ≠êÁöÑËØ≠Áî®ÂäüËÉΩÔºåÊòüÂºèËã±ËØ≠Âú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰æùËµñ‰∫éÊ≠§Êù•‰º†ËææÊÑè‰πâ„ÄÇËøôÈ°πÂ∑•‰ΩúÊèê‰æõ‰∫Ü‰∏ÄÈ°πÂàùÊ≠•Â∞ùËØïÔºåÂç≥Âà©Áî®‰ªªÂä°È©±Âä®ÁöÑË°®ÂæÅÂ≠¶‰π†Êù•Ëß£ÂºÄÊòüÂºèËã±ËØ≠ËØùËØ≠Á≤íÂ≠êÔºàlah„ÄÅmeh Âíå horÔºâ„ÄÇÂú®Ëß£ÂºÄÁ∫†Áº†ÂêéÔºåÊàë‰ª¨Â∞ÜËøô‰∫õËØùËØ≠Á≤íÂ≠êËøõË°åËÅöÁ±ª‰ª•Âå∫ÂàÜÂÆÉ‰ª¨ÁöÑËØ≠Áî®ÂäüËÉΩÔºåÂπ∂ÊâßË°åÊòüÂºèËã±ËØ≠Âà∞Ëã±ËØ≠ÁöÑÊú∫Âô®ÁøªËØë„ÄÇÊàë‰ª¨ÁöÑÂ∑•‰ΩúÊèê‰æõ‰∫Ü‰∏ÄÁßçËÆ°ÁÆóÊñπÊ≥ïÊù•ÁêÜËß£ÊòüÂºèËã±ËØ≠ËØùËØ≠Á≤íÂ≠êÔºåÂπ∂‰∏∫Êõ¥Ê∑±ÂÖ•Âú∞ÁêÜËß£ËØ•ËØ≠Ë®ÄÂèäÂÖ∂Áî®Ê≥ïÂºÄËæü‰∫ÜÈÄîÂæÑ„ÄÇ

##### **Efficient Driving Behavior Narration and Reasoning on Edge Device Using Large Language Models**
2409.20364v1 by Yizhou Huang, Yihua Cheng, Kezhi Wang

Deep learning architectures with powerful reasoning capabilities have driven
significant advancements in autonomous driving technology. Large language
models (LLMs) applied in this field can describe driving scenes and behaviors
with a level of accuracy similar to human perception, particularly in visual
tasks. Meanwhile, the rapid development of edge computing, with its advantage
of proximity to data sources, has made edge devices increasingly important in
autonomous driving. Edge devices process data locally, reducing transmission
delays and bandwidth usage, and achieving faster response times. In this work,
we propose a driving behavior narration and reasoning framework that applies
LLMs to edge devices. The framework consists of multiple roadside units, with
LLMs deployed on each unit. These roadside units collect road data and
communicate via 5G NSR/NR networks. Our experiments show that LLMs deployed on
edge devices can achieve satisfactory response speeds. Additionally, we propose
a prompt strategy to enhance the narration and reasoning performance of the
system. This strategy integrates multi-modal information, including
environmental, agent, and motion data. Experiments conducted on the
OpenDV-Youtube dataset demonstrate that our approach significantly improves
performance across both tasks.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏ÁøíÊû∂ÊßãÂÖ∑ÂÇôÂº∑Â§ßÁöÑÊé®ÁêÜËÉΩÂäõÔºåÊé®Âãï‰∫ÜËá™ÂãïÈßïÈßõÊäÄË°ìÁöÑÈáçÂ§ßÈÄ≤Â±ï„ÄÇÊáâÁî®ÊñºÊ≠§È†òÂüüÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂèØ‰ª•ÊèèËø∞ÈßïÈßõÂ†¥ÊôØÂíåË°åÁÇ∫ÔºåÂÖ∂Ê∫ñÁ¢∫Â∫¶Ëàá‰∫∫È°ûÊÑüÁü•È°û‰ººÔºåÁâπÂà•ÊòØÂú®Ë¶ñË¶∫‰ªªÂãô‰∏≠„ÄÇÂêåÊôÇÔºåÈÇäÁ∑£ÈÅãÁÆóÁöÑÂø´ÈÄüÁôºÂ±ïÔºåÂõ†ÂÖ∂Èù†ËøëÊï∏ÊìöÊ∫êÁöÑÂÑ™Âã¢Ôºå‰ΩøÂæóÈÇäÁ∑£Ë®≠ÂÇôÂú®Ëá™ÂãïÈßïÈßõ‰∏≠ËÆäÂæóË∂ä‰æÜË∂äÈáçË¶Å„ÄÇÈÇäÁ∑£Ë®≠ÂÇôÂú®Êú¨Âú∞ËôïÁêÜÊï∏ÊìöÔºåÊ∏õÂ∞ëÂÇ≥Ëº∏Âª∂ÈÅ≤ÂíåÈ†ªÂØ¨‰ΩøÁî®Ôºå‰∏¶ÂØ¶ÁèæÊõ¥Âø´ÁöÑÈüøÊáâÊôÇÈñì„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÈßïÈßõË°åÁÇ∫ÊïòËø∞ÂíåÊé®ÁêÜÊ°ÜÊû∂ÔºåÂ∞á LLM ÊáâÁî®ÊñºÈÇäÁ∑£Ë®≠ÂÇô„ÄÇË©≤Ê°ÜÊû∂Áî±Â§öÂÄãË∑ØÈÇäÂñÆÂÖÉÁµÑÊàêÔºåÊØèÂÄãÂñÆÂÖÉ‰∏äÈÉΩÈÉ®ÁΩ≤‰∫Ü LLM„ÄÇÈÄô‰∫õË∑ØÈÇäÂñÆÂÖÉÊî∂ÈõÜÈÅìË∑ØÊï∏Êìö‰∏¶ÈÄöÈÅé 5G NSR/NR Á∂≤Ë∑ØÈÄ≤Ë°åÈÄö‰ø°„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåÈÉ®ÁΩ≤Âú®ÈÇäÁ∑£Ë®≠ÂÇô‰∏äÁöÑ LLM ÂèØ‰ª•ÂØ¶Áèæ‰ª§‰∫∫ÊªøÊÑèÁöÑÈüøÊáâÈÄüÂ∫¶„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊèêÁ§∫Á≠ñÁï•‰æÜÂ¢ûÂº∑Á≥ªÁµ±ÁöÑÊïòËø∞ÂíåÊé®ÁêÜÊÄßËÉΩ„ÄÇÊ≠§Á≠ñÁï•Êï¥Âêà‰∫ÜÂ§öÊ®°ÊÖã‰ø°ÊÅØÔºåÂåÖÊã¨Áí∞Â¢É„ÄÅ‰ª£ÁêÜÂíåÈÅãÂãïÊï∏Êìö„ÄÇÂú® OpenDV-Youtube Êï∏ÊìöÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÊñπÊ°àÈ°ØËëóÊèêÈ´ò‰∫ÜÈÄôÂÖ©È†Ö‰ªªÂãôÁöÑÊÄßËÉΩ„ÄÇ

##### **Rotated Runtime Smooth: Training-Free Activation Smoother for accurate INT4 inference**
2409.20361v1 by Ke Yi, Zengke Liu, Jianwei Zhang, Chengyuan Li, Tong Zhang, Junyang Lin, Jingren Zhou

Large language models have demonstrated promising capabilities upon scaling
up parameters. However, serving large language models incurs substantial
computation and memory movement costs due to their large scale. Quantization
methods have been employed to reduce service costs and latency. Nevertheless,
outliers in activations hinder the development of INT4 weight-activation
quantization. Existing approaches separate outliers and normal values into two
matrices or migrate outliers from activations to weights, suffering from high
latency or accuracy degradation. Based on observing activations from large
language models, outliers can be classified into channel-wise and spike
outliers. In this work, we propose Rotated Runtime Smooth (RRS), a
plug-and-play activation smoother for quantization, consisting of Runtime
Smooth and the Rotation operation. Runtime Smooth (RS) is introduced to
eliminate channel-wise outliers by smoothing activations with channel-wise
maximums during runtime. The rotation operation can narrow the gap between
spike outliers and normal values, alleviating the effect of victims caused by
channel-wise smoothing. The proposed method outperforms the state-of-the-art
method in the LLaMA and Qwen families and improves WikiText-2 perplexity from
57.33 to 6.66 for INT4 inference.

ÊëòË¶ÅÔºöÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®Êâ©Â§ßÂèÇÊï∞Êó∂Â∑≤Â±ïÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÁî±‰∫éÂ§ßËßÑÊ®°ÔºåÊèê‰æõÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã‰ºö‰∫ßÁîüÂ§ßÈáèÁöÑËÆ°ÁÆóÂíåÂÜÖÂ≠òÁßªÂä®ÊàêÊú¨„ÄÇÈáèÂåñÊñπÊ≥ïÂ∑≤Ë¢´Áî®Êù•Èôç‰ΩéÊúçÂä°ÊàêÊú¨ÂíåÂª∂Ëøü„ÄÇÂ∞ΩÁÆ°Â¶ÇÊ≠§ÔºåÊøÄÊ¥ª‰∏≠ÁöÑÂºÇÂ∏∏ÂÄºÈòªÁ¢ç‰∫Ü INT4 ÊùÉÈáçÊøÄÊ¥ªÈáèÂåñÁöÑÂèëÂ±ï„ÄÇÁé∞ÊúâÁöÑÊñπÊ≥ïÂ∞ÜÂºÇÂ∏∏ÂÄºÂíåÊ≠£Â∏∏ÂÄºÂàÜÊàê‰∏§‰∏™Áü©ÈòµÔºåÊàñÂ∞ÜÂºÇÂ∏∏ÂÄº‰ªéÊøÄÊ¥ªËøÅÁßªÂà∞ÊùÉÈáçÔºå‰ªéËÄåÂØºËá¥È´òÂª∂ËøüÊàñÁ≤æÂ∫¶‰∏ãÈôç„ÄÇÂü∫‰∫éÂØπÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÊøÄÊ¥ªËßÇÂØüÔºåÂºÇÂ∏∏ÂÄºÂèØ‰ª•ÂàÜÁ±ª‰∏∫ÈÄöÈÅìÂÜÖÂºÇÂ∏∏ÂÄºÂíåÂ∞ñÂ≥∞ÂºÇÂ∏∏ÂÄº„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÊóãËΩ¨ËøêË°åÊó∂Âπ≥Êªë (RRS)ÔºåËøôÊòØ‰∏ÄÁßçÂç≥ÊèíÂç≥Áî®ÁöÑÊøÄÊ¥ªÂπ≥ÊªëÂô®ÔºåÁî®‰∫éÈáèÂåñÔºåÁî±ËøêË°åÊó∂Âπ≥ÊªëÂíåÊóãËΩ¨Êìç‰ΩúÁªÑÊàê„ÄÇÂºïÂÖ•ËøêË°åÊó∂Âπ≥Êªë (RS) ‰ª•ÈÄöËøáÂú®ËøêË°åÊó∂‰ΩøÁî®ÈÄöÈÅìÂÜÖÊúÄÂ§ßÂÄºÂπ≥ÊªëÊøÄÊ¥ªÊù•Ê∂àÈô§ÈÄöÈÅìÂÜÖÂºÇÂ∏∏ÂÄº„ÄÇÊóãËΩ¨Êìç‰ΩúÂèØ‰ª•Áº©Â∞èÂ∞ñÂ≥∞ÂºÇÂ∏∏ÂÄºÂíåÊ≠£Â∏∏ÂÄº‰πãÈó¥ÁöÑÂ∑ÆË∑ùÔºåÂáèËΩªÈÄöÈÅìÂÜÖÂπ≥ÊªëÈÄ†ÊàêÁöÑÂèóÂÆ≥ÂΩ±Âìç„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ï‰ºò‰∫é LLaMA Âíå Qwen Á≥ªÂàó‰∏≠ÁöÑÊúÄÂÖàËøõÊñπÊ≥ïÔºåÂπ∂Â∞Ü WikiText-2 ÁöÑÂõ∞ÊÉëÂ∫¶‰ªé 57.33 ÊèêÈ´òÂà∞ 6.66ÔºåÁî®‰∫é INT4 Êé®Êñ≠„ÄÇ

##### **Enhancing GANs with Contrastive Learning-Based Multistage Progressive Finetuning SNN and RL-Based External Optimization**
2409.20340v2 by Osama Mustafa

The application of deep learning in cancer research, particularly in early
diagnosis, case understanding, and treatment strategy design, emphasizes the
need for high-quality data. Generative AI, especially Generative Adversarial
Networks (GANs), has emerged as a leading solution to challenges like class
imbalance, robust learning, and model training, while addressing issues
stemming from patient privacy and the scarcity of real data. Despite their
promise, GANs face several challenges, both inherent and specific to
histopathology data. Inherent issues include training imbalance, mode collapse,
linear learning from insufficient discriminator feedback, and hard boundary
convergence due to stringent feedback. Histopathology data presents a unique
challenge with its complex representation, high spatial resolution, and
multiscale features. To address these challenges, we propose a framework
consisting of two components. First, we introduce a contrastive learning-based
Multistage Progressive Finetuning Siamese Neural Network (MFT-SNN) for
assessing the similarity between histopathology patches. Second, we implement a
Reinforcement Learning-based External Optimizer (RL-EO) within the GAN training
loop, serving as a reward signal generator. The modified discriminator loss
function incorporates a weighted reward, guiding the GAN to maximize this
reward while minimizing loss. This approach offers an external optimization
guide to the discriminator, preventing generator overfitting and ensuring
smooth convergence. Our proposed solution has been benchmarked against
state-of-the-art (SOTA) GANs and a Denoising Diffusion Probabilistic model,
outperforming previous SOTA across various metrics, including FID score, KID
score, Perceptual Path Length, and downstream classification tasks.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏ÁøíÂú®ÁôåÁóáÁ†îÁ©∂‰∏≠ÁöÑÊáâÁî®ÔºåÁâπÂà•ÊòØÂú®Êó©ÊúüË®∫Êñ∑„ÄÅÊ°à‰æãÁêÜËß£ÂíåÊ≤ªÁôÇÁ≠ñÁï•Ë®≠Ë®à‰∏≠ÔºåÂº∑Ë™ø‰∫ÜÂ∞çÈ´òÂìÅË≥™Êï∏ÊìöÁöÑÈúÄÊ±Ç„ÄÇÁîüÊàêÂºè AIÔºåÁâπÂà•ÊòØÁîüÊàêÂºèÂ∞çÊäóÁ∂≤Ë∑Ø (GAN)ÔºåÂ∑≤ÊàêÁÇ∫Ëß£Ê±∫È°ûÂà•‰∏çÂπ≥Ë°°„ÄÅÁ©©ÂÅ•Â≠∏ÁøíÂíåÊ®°ÂûãË®ìÁ∑¥Á≠âÊåëÊà∞ÁöÑÈ†òÂÖàËß£Ê±∫ÊñπÊ°àÔºåÂêåÊôÇËß£Ê±∫‰∫ÜÊÇ£ËÄÖÈö±ÁßÅÂíåÁúüÂØ¶Êï∏ÊìöÁ®ÄÁº∫ÁöÑÂïèÈ°å„ÄÇÂÑòÁÆ°ÊúâÂÖ∂ÂÑ™ÈªûÔºå‰ΩÜ GAN Èù¢Ëá®ËëóÂ§öÈ†ÖÊåëÊà∞ÔºåÊó¢ÊúâÂõ∫ÊúâÁöÑÔºå‰πüÊúâÁâπÂÆöÊñºÁµÑÁπîÁóÖÁêÜÂ≠∏Êï∏ÊìöÁöÑ„ÄÇÂõ∫ÊúâÂïèÈ°åÂåÖÊã¨Ë®ìÁ∑¥‰∏çÂπ≥Ë°°„ÄÅÊ®°ÂºèÂ¥©ÊΩ∞„ÄÅÂà§Âà•Âô®ÂõûÈ•ã‰∏çË∂≥Â∞éËá¥ÁöÑÁ∑öÊÄßÂ≠∏ÁøíÔºå‰ª•ÂèäÁî±ÊñºÂö¥Ê†ºÂõûÈ•ãÂ∞éËá¥ÁöÑÁ°¨ÈÇäÁïåÊî∂ÊñÇ„ÄÇÁµÑÁπîÁóÖÁêÜÂ≠∏Êï∏Êìö‰ª•ÂÖ∂Ë§áÈõúÁöÑË°®Á§∫„ÄÅÈ´òÁ©∫ÈñìËß£ÊûêÂ∫¶ÂíåÂ§öÂ∞∫Â∫¶ÁâπÂæµÂëàÁèæÂá∫Áç®ÁâπÁöÑÊåëÊà∞„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁî±ÂÖ©ÂÄãÁµÑÊàêÈÉ®ÂàÜÁµÑÊàêÁöÑÊ°ÜÊû∂„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÂ∞çÊØîÂ≠∏ÁøíÁöÑÂ§öÈöéÊÆµÊº∏ÈÄ≤ÂæÆË™øÈÄ£È´îÁ•ûÁ∂ìÁ∂≤Ë∑Ø (MFT-SNN)ÔºåÁî®ÊñºË©ï‰º∞ÁµÑÁπîÁóÖÁêÜÂ≠∏Ë≤ºÁâá‰πãÈñìÁöÑÁõ∏‰ººÊÄß„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÂú® GAN Ë®ìÁ∑¥Ëø¥Âúà‰∏≠ÂØ¶‰Ωú‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÂº∑ÂåñÂ≠∏ÁøíÁöÑÂ§ñÈÉ®ÂÑ™ÂåñÂô® (RL-EO)Ôºå‰ΩúÁÇ∫ÁçéÂãµË®äËôüÁî¢ÁîüÂô®„ÄÇ‰øÆÊîπÂæåÁöÑÂà§Âà•Âô®ÊêçÂ§±ÂáΩÊï∏ÂåÖÂê´‰∏ÄÂÄãÂä†Ê¨äÁçéÂãµÔºåÊåáÂ∞é GAN Âú®ÊúÄÂ∞èÂåñÊêçÂ§±ÁöÑÂêåÊôÇÊúÄÂ§ßÂåñÈÄôÂÄãÁçéÂãµ„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÁÇ∫Âà§Âà•Âô®Êèê‰æõ‰∫ÜÂ§ñÈÉ®ÂÑ™ÂåñÊåáÂçóÔºåÈò≤Ê≠¢ÁîüÊàêÂô®ÈÅéÂ∫¶Êì¨Âêà‰∏¶Á¢∫‰øùÂπ≥Á©©Êî∂ÊñÇ„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑËß£Ê±∫ÊñπÊ°àÂ∑≤ÈáùÂ∞çÊúÄÂÖàÈÄ≤ (SOTA) GAN ÂíåÂéªÂô™Êì¥Êï£Ê¶ÇÁéáÊ®°ÂûãÈÄ≤Ë°å‰∫ÜÂü∫Ê∫ñÊ∏¨Ë©¶ÔºåÂú® FID ÂàÜÊï∏„ÄÅKID ÂàÜÊï∏„ÄÅÊÑüÁü•Ë∑ØÂæëÈï∑Â∫¶Âíå‰∏ãÊ∏∏ÂàÜÈ°û‰ªªÂãôÁ≠âÂêÑÁ®ÆÊåáÊ®ô‰∏äÂÑ™ÊñºÂÖàÂâçÁöÑ SOTA„ÄÇ

##### **Boosting Hybrid Autoregressive Transducer-based ASR with Internal Acoustic Model Training and Dual Blank Thresholding**
2409.20313v1 by Takafumi Moriya, Takanori Ashihara, Masato Mimura, Hiroshi Sato, Kohei Matsuura, Ryo Masumura, Taichi Asami

A hybrid autoregressive transducer (HAT) is a variant of neural transducer
that models blank and non-blank posterior distributions separately. In this
paper, we propose a novel internal acoustic model (IAM) training strategy to
enhance HAT-based speech recognition. IAM consists of encoder and joint
networks, which are fully shared and jointly trained with HAT. This joint
training not only enhances the HAT training efficiency but also encourages IAM
and HAT to emit blanks synchronously which skips the more expensive non-blank
computation, resulting in more effective blank thresholding for faster
decoding. Experiments demonstrate that the relative error reductions of the HAT
with IAM compared to the vanilla HAT are statistically significant. Moreover,
we introduce dual blank thresholding, which combines both HAT- and IAM-blank
thresholding and a compatible decoding algorithm. This results in a 42-75%
decoding speed-up with no major performance degradation.

ÊëòË¶ÅÔºöÊ∑∑ÂêàËá™Ëø¥Ê≠∏ËΩâÊèõÂô® (HAT) ÊòØÁ•ûÁ∂ìËΩâÊèõÂô®ÁöÑ‰∏ÄÁ®ÆËÆäÈ´îÔºåÂÆÉÂàÜÂà•Â∞çÁ©∫ÁôΩÂíåÈùûÁ©∫ÁôΩÂæåÈ©óÂàÜ‰ΩàÈÄ≤Ë°åÂª∫Ê®°„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂÖßÈÉ®ËÅ≤Â≠∏Ê®°Âûã (IAM) Ë®ìÁ∑¥Á≠ñÁï•Ôºå‰ª•Â¢ûÂº∑Âü∫Êñº HAT ÁöÑË™ûÈü≥Ë≠òÂà•„ÄÇIAM Áî±Á∑®Á¢ºÂô®ÂíåËÅØÂêàÁ∂≤Ë∑ØÁµÑÊàêÔºåÂÆÉÂÄëÂÆåÂÖ®ÂÖ±‰∫´‰∏¶Ëàá HAT ËÅØÂêàË®ìÁ∑¥„ÄÇÈÄôÁ®ÆËÅØÂêàË®ìÁ∑¥‰∏çÂÉÖÊèêÈ´ò‰∫Ü HAT Ë®ìÁ∑¥ÊïàÁéáÔºåÈÇÑÈºìÂãµ IAM Âíå HAT ÂêåÊ≠•ÁôºÂá∫Á©∫ÁôΩÔºåÂæûËÄåË∑≥ÈÅéÊõ¥ÊòÇË≤¥ÁöÑÈùûÁ©∫ÁôΩË®àÁÆóÔºåÂæûËÄåÂ∞çÊõ¥ÊúâÊïàÁöÑÁ©∫ÁôΩÈñæÂÄºÈÄ≤Ë°åÊõ¥Âø´Ëß£Á¢º„ÄÇÂØ¶È©óË°®ÊòéÔºåËàáÈ¶ôËçâ HAT Áõ∏ÊØîÔºåÂ∏∂Êúâ IAM ÁöÑ HAT ÁöÑÁõ∏Â∞çË™§Â∑ÆÊ∏õÂ∞ëÂÖ∑ÊúâÁµ±Ë®àÂ≠∏ÊÑèÁæ©„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÈõôÁ©∫ÁôΩÈñæÂÄºÔºåÂÆÉÁµêÂêà‰∫Ü HAT Âíå IAM Á©∫ÁôΩÈñæÂÄºÂíå‰∏ÄÂÄãÁõ∏ÂÆπÁöÑËß£Á¢ºÊºîÁÆóÊ≥ï„ÄÇÈÄôÂ∞éËá¥Ëß£Á¢ºÈÄüÂ∫¶ÊèêÈ´ò‰∫Ü 42-75%ÔºåËÄåÊïàËÉΩÊ≤íÊúâÊòéÈ°Ø‰∏ãÈôç„ÄÇ

##### **A Looming Replication Crisis in Evaluating Behavior in Language Models? Evidence and Solutions**
2409.20303v1 by Laur√®ne Vaugrante, Mathias Niepert, Thilo Hagendorff

In an era where large language models (LLMs) are increasingly integrated into
a wide range of everyday applications, research into these models' behavior has
surged. However, due to the novelty of the field, clear methodological
guidelines are lacking. This raises concerns about the replicability and
generalizability of insights gained from research on LLM behavior. In this
study, we discuss the potential risk of a replication crisis and support our
concerns with a series of replication experiments focused on prompt engineering
techniques purported to influence reasoning abilities in LLMs. We tested
GPT-3.5, GPT-4o, Gemini 1.5 Pro, Claude 3 Opus, Llama 3-8B, and Llama 3-70B, on
the chain-of-thought, EmotionPrompting, ExpertPrompting, Sandbagging, as well
as Re-Reading prompt engineering techniques, using manually double-checked
subsets of reasoning benchmarks including CommonsenseQA, CRT, NumGLUE,
ScienceQA, and StrategyQA. Our findings reveal a general lack of statistically
significant differences across nearly all techniques tested, highlighting,
among others, several methodological weaknesses in previous research. We
propose a forward-looking approach that includes developing robust
methodologies for evaluating LLMs, establishing sound benchmarks, and designing
rigorous experimental frameworks to ensure accurate and reliable assessments of
model outputs.

ÊëòË¶ÅÔºöÂú®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÊó•ÁõäÊï¥ÂêàÂà∞ÂêÑÁ®ÆÊó•Â∏∏ÊáâÁî®Á®ãÂºèÁöÑÊôÇ‰ª£ÔºåÂ∞çÈÄô‰∫õÊ®°ÂûãË°åÁÇ∫ÁöÑÁ†îÁ©∂ÊøÄÂ¢û„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºË©≤È†òÂüüÁöÑÊñ∞Á©éÊÄßÔºåÁº∫‰πèÊòéÁ¢∫ÁöÑÊñπÊ≥ïË´ñÊåáÂçó„ÄÇÈÄôÂºïËµ∑‰∫ÜÂ∞çÂæû LLM Ë°åÁÇ∫Á†îÁ©∂‰∏≠Áç≤ÂæóÁöÑË¶ãËß£ÁöÑÂèØË§áË£ΩÊÄßÂíåÊ¶ÇÊã¨ÊÄßÁöÑÊìîÊÜÇ„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëË®éË´ñ‰∫ÜË§áË£ΩÂç±Ê©üÁöÑÊΩõÂú®È¢®Èö™Ôºå‰∏¶ÈÄöÈÅé‰∏ÄÁ≥ªÂàóË§áË£ΩÂØ¶È©óÊîØÊåÅÊàëÂÄëÁöÑÊìîÊÜÇÔºåÈÄô‰∫õÂØ¶È©óÂ∞àÊ≥®ÊñºÊìöÁ®±ÂΩ±Èüø LLM Êé®ÁêÜËÉΩÂäõÁöÑÊèêÁ§∫Â∑•Á®ãÊäÄË°ì„ÄÇÊàëÂÄëÂú®ÊÄùÊÉ≥Èèà„ÄÅEmotionPrompting„ÄÅExpertPrompting„ÄÅSandbagging ‰ª•Âèä Re-Reading ÊèêÁ§∫Â∑•Á®ãÊäÄË°ì‰∏äÊ∏¨Ë©¶‰∫Ü GPT-3.5„ÄÅGPT-4o„ÄÅGemini 1.5 Pro„ÄÅClaude 3 Opus„ÄÅLlama 3-8B Âíå Llama 3-70BÔºå‰ΩøÁî®ÊâãÂãïÈõôÈáçÊ™¢Êü•ÁöÑÊé®ÁêÜÂü∫Ê∫ñÂ≠êÈõÜÔºåÂåÖÊã¨ CommonsenseQA„ÄÅCRT„ÄÅNumGLUE„ÄÅScienceQA Âíå StrategyQA„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÊè≠Á§∫‰∫ÜÂú®Âπæ‰πéÊâÄÊúâÊ∏¨Ë©¶ÊäÄË°ì‰∏≠ÊôÆÈÅçÁº∫‰πèÁµ±Ë®àÂ≠∏‰∏äÁöÑÈ°ØËëóÂ∑ÆÁï∞ÔºåÂÖ∂‰∏≠ÂåÖÊã¨Âº∑Ë™ø‰ª•ÂâçÁ†îÁ©∂‰∏≠Â≠òÂú®ÁöÑËã•Âπ≤ÊñπÊ≥ïË´ñÂº±Èªû„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂâçÁûªÊÄßÁöÑÊñπÊ≥ïÔºåÂåÖÊã¨ÈñãÁôºÁî®ÊñºË©ï‰º∞ LLM ÁöÑÂÅ•Â£ØÊñπÊ≥ïË´ñ„ÄÅÂª∫Á´ãÂÅ•ÂÖ®ÁöÑÂü∫Ê∫ñ‰ª•ÂèäË®≠Ë®àÂö¥Ë¨πÁöÑÂØ¶È©óÊ°ÜÊû∂Ôºå‰ª•Á¢∫‰øùÂ∞çÊ®°ÂûãËº∏Âá∫ÁöÑÊ∫ñÁ¢∫‰∏îÂèØÈù†ÁöÑË©ï‰º∞„ÄÇ

##### **PersonalLLM: Tailoring LLMs to Individual Preferences**
2409.20296v1 by Thomas P. Zollo, Andrew Wei Tung Siah, Naimeng Ye, Ang Li, Hongseok Namkoong

As LLMs become capable of complex tasks, there is growing potential for
personalized interactions tailored to the subtle and idiosyncratic preferences
of the user. We present a public benchmark, PersonalLLM, focusing on adapting
LLMs to provide maximal benefits for a particular user. Departing from existing
alignment benchmarks that implicitly assume uniform preferences, we curate
open-ended prompts paired with many high-quality answers over which users would
be expected to display heterogeneous latent preferences. Instead of
persona-prompting LLMs based on high-level attributes (e.g., user's race or
response length), which yields homogeneous preferences relative to humans, we
develop a method that can simulate a large user base with diverse preferences
from a set of pre-trained reward models. Our dataset and generated
personalities offer an innovative testbed for developing personalization
algorithms that grapple with continual data sparsity--few relevant feedback
from the particular user--by leveraging historical data from other (similar)
users. We explore basic in-context learning and meta-learning baselines to
illustrate the utility of PersonalLLM and highlight the need for future
methodological development. Our dataset is available at
https://huggingface.co/datasets/namkoong-lab/PersonalLLM

ÊëòË¶ÅÔºöÈöèÁùÄ LLM ËÉΩÂ§üÊâßË°åÂ§çÊùÇÁöÑ‰ªªÂä°ÔºåÈíàÂØπÁî®Êà∑ÁöÑÂæÆÂ¶ô‰∏îÁã¨ÁâπÁöÑÂÅèÂ•ΩÈáèË∫´ÂÆöÂà∂‰∏™ÊÄßÂåñ‰∫íÂä®ÂÖ∑ÊúâË∂äÊù•Ë∂äÂ§ßÁöÑÊΩúÂäõ„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÂÖ¨ÂÖ±Âü∫ÂáÜ PersonalLLMÔºåÈáçÁÇπÊòØË∞ÉÊï¥ LLM ‰ª•‰∏∫ÁâπÂÆöÁî®Êà∑Êèê‰æõÊúÄÂ§ßÁöÑÂ•ΩÂ§Ñ„ÄÇ‰∏éÈöêÂºèÂÅáËÆæÁªü‰∏ÄÂÅèÂ•ΩÁöÑÁé∞ÊúâÂØπÈΩêÂü∫ÂáÜ‰∏çÂêåÔºåÊàë‰ª¨Á≠ñÂàí‰∫ÜÂºÄÊîæÂºèÊèêÁ§∫ÔºåÂπ∂ÈÖçÊúâËÆ∏Â§öÈ´òË¥®ÈáèÁöÑÁ≠îÊ°àÔºåÁî®Êà∑ÂèØËÉΩ‰ºöÂØπËøô‰∫õÁ≠îÊ°àË°®Áé∞Âá∫ÂºÇË¥®ÁöÑÊΩúÂú®ÂÅèÂ•Ω„ÄÇÊàë‰ª¨Ê≤°ÊúâÊ†πÊçÆÈ´òÁ∫ßÂ±ûÊÄßÔºà‰æãÂ¶ÇÔºåÁî®Êà∑ÁöÑÁßçÊóèÊàñÂìçÂ∫îÈïøÂ∫¶ÔºâÂØπ LLM ËøõË°åËßíËâ≤ÊèêÁ§∫ÔºåËøô‰ºö‰∫ßÁîüÁõ∏ÂØπ‰∫é‰∫∫Á±ªÁöÑÂêåË¥®ÂÅèÂ•ΩÔºåËÄåÊòØÂºÄÂèë‰∫Ü‰∏ÄÁßçÊñπÊ≥ïÔºåËØ•ÊñπÊ≥ïÂèØ‰ª•‰ΩøÁî®‰∏ÄÁªÑÈ¢ÑÂÖàËÆ≠ÁªÉÁöÑÂ•ñÂä±Ê®°ÂûãÊù•Ê®°ÊãüÂÖ∑Êúâ‰∏çÂêåÂÅèÂ•ΩÁöÑÂ§ßÈáèÁî®Êà∑Áæ§„ÄÇÊàë‰ª¨ÁöÑÊï∞ÊçÆÈõÜÂíåÁîüÊàêÁöÑ‰∫∫Ê†º‰∏∫ÂºÄÂèë‰∏™ÊÄßÂåñÁÆóÊ≥ïÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÂàõÊñ∞ÁöÑÊµãËØïÂπ≥Âè∞ÔºåËØ•ÁÆóÊ≥ïÈÄöËøáÂà©Áî®ÂÖ∂‰ªñÔºàÁõ∏‰ººÔºâÁî®Êà∑ÁöÑÂéÜÂè≤Êï∞ÊçÆÊù•Ëß£ÂÜ≥ÊåÅÁª≠ÁöÑÊï∞ÊçÆÁ®ÄÁñèÊÄßÈóÆÈ¢ò‚Äî‚ÄîÊù•Ëá™ÁâπÂÆöÁî®Êà∑ÁöÑÁõ∏ÂÖ≥ÂèçÈ¶àÂæàÂ∞ë„ÄÇÊàë‰ª¨Êé¢Á¥¢‰∫ÜÂü∫Êú¨ÁöÑ‰∏ä‰∏ãÊñáÂ≠¶‰π†ÂíåÂÖÉÂ≠¶‰π†Âü∫Á∫øÔºå‰ª•ËØ¥Êòé PersonalLLM ÁöÑÊïàÁî®ÔºåÂπ∂Âº∫Ë∞ÉÊú™Êù•ÊñπÊ≥ïËÆ∫ÂèëÂ±ïÁöÑÂøÖË¶ÅÊÄß„ÄÇÊàë‰ª¨ÁöÑÊï∞ÊçÆÈõÜÂèØÂú® https://huggingface.co/datasets/namkoong-lab/PersonalLLM Ëé∑Âæó

##### **LexEval: A Comprehensive Chinese Legal Benchmark for Evaluating Large Language Models**
2409.20288v1 by Haitao Li, You Chen, Qingyao Ai, Yueyue Wu, Ruizhe Zhang, Yiqun Liu

Large language models (LLMs) have made significant progress in natural
language processing tasks and demonstrate considerable potential in the legal
domain. However, legal applications demand high standards of accuracy,
reliability, and fairness. Applying existing LLMs to legal systems without
careful evaluation of their potential and limitations could pose significant
risks in legal practice. To this end, we introduce a standardized comprehensive
Chinese legal benchmark LexEval. This benchmark is notable in the following
three aspects: (1) Ability Modeling: We propose a new taxonomy of legal
cognitive abilities to organize different tasks. (2) Scale: To our knowledge,
LexEval is currently the largest Chinese legal evaluation dataset, comprising
23 tasks and 14,150 questions. (3) Data: we utilize formatted existing
datasets, exam datasets and newly annotated datasets by legal experts to
comprehensively evaluate the various capabilities of LLMs. LexEval not only
focuses on the ability of LLMs to apply fundamental legal knowledge but also
dedicates efforts to examining the ethical issues involved in their
application. We evaluated 38 open-source and commercial LLMs and obtained some
interesting findings. The experiments and findings offer valuable insights into
the challenges and potential solutions for developing Chinese legal systems and
LLM evaluation pipelines. The LexEval dataset and leaderboard are publicly
available at \url{https://github.com/CSHaitao/LexEval} and will be continuously
updated.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãôÊñπÈù¢ÂèñÂæó‰∫ÜÈáçÂ§ßÈÄ≤Â±ïÔºå‰∏¶Âú®Ê≥ïÂæãÈ†òÂüüÂ±ïÁèæ‰∫ÜÂ∑®Â§ßÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÊ≥ïÂæãÊáâÁî®Ë¶ÅÊ±ÇÊ•µÈ´òÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÅÂèØÈù†ÊÄßÂíåÂÖ¨Âπ≥ÊÄß„ÄÇÂú®Êú™‰ªîÁ¥∞Ë©ï‰º∞ÂÖ∂ÊΩõÂäõÂíåÈôêÂà∂ÁöÑÊÉÖÊ≥Å‰∏ãÂ∞áÁèæÊúâÁöÑ LLM ÊáâÁî®ÊñºÊ≥ïÂæãÁ≥ªÁµ±ÔºåÂèØËÉΩÊúÉÂú®Ê≥ïÂæãÂØ¶Âãô‰∏≠ÈÄ†ÊàêÈáçÂ§ßÈ¢®Èö™„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÊ®ôÊ∫ñÂåñÁöÑÁ∂úÂêà‰∏≠ÊñáÊ≥ïÂæãÂü∫Ê∫ñ LexEval„ÄÇÊ≠§Âü∫Ê∫ñÂú®‰ª•‰∏ã‰∏âÂÄãÊñπÈù¢ÂÄºÂæóÊ≥®ÊÑèÔºö(1) ËÉΩÂäõÂª∫Ê®°ÔºöÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊ≥ïÂæãË™çÁü•ËÉΩÂäõÂàÜÈ°ûÊ≥ïÔºå‰ª•ÁµÑÁπî‰∏çÂêåÁöÑ‰ªªÂãô„ÄÇ(2) Ë¶èÊ®°ÔºöÊìöÊàëÂÄëÊâÄÁü•ÔºåLexEval ÁõÆÂâçÊòØÊúÄÂ§ßÁöÑ‰∏≠ÊñáÊ≥ïÂæãË©ï‰º∞Ë≥áÊñôÈõÜÔºåÂåÖÂê´ 23 È†Ö‰ªªÂãôÂíå 14,150 ÂÄãÂïèÈ°å„ÄÇ(3) Ë≥áÊñôÔºöÊàëÂÄëÂà©Áî®Ê≥ïÂæãÂ∞àÂÆ∂Ê†ºÂºèÂåñÁöÑÁèæÊúâË≥áÊñôÈõÜ„ÄÅËÄÉË©¶Ë≥áÊñôÈõÜÂíåÊñ∞Ë®ªËß£Ë≥áÊñôÈõÜÔºå‰ª•ÂÖ®Èù¢Ë©ï‰º∞ LLM ÁöÑÂêÑÁ®ÆËÉΩÂäõ„ÄÇLexEval ‰∏çÂÉÖÂ∞àÊ≥®Êñº LLM ÊáâÁî®Âü∫Êú¨Ê≥ïÂæãÁü•Ë≠òÁöÑËÉΩÂäõÔºåÈÇÑËá¥ÂäõÊñºÂØ©Êü•ÂÖ∂ÊáâÁî®‰∏≠Ê∂âÂèäÁöÑÂÄ´ÁêÜÂïèÈ°å„ÄÇÊàëÂÄëË©ï‰º∞‰∫Ü 38 ÂÄãÈñãÊ∫êÂíåÂïÜÊ•≠ LLMÔºå‰∏¶Áç≤Âæó‰∫Ü‰∏Ä‰∫õÊúâË∂£ÁöÑÁôºÁèæ„ÄÇÈÄô‰∫õÂØ¶È©óÂíåÁôºÁèæÁÇ∫ÈñãÁôº‰∏≠ÊñáÊ≥ïÂæãÁ≥ªÁµ±Âíå LLM Ë©ï‰º∞ÁÆ°ÈÅìÊèê‰æõ‰∫ÜÂØ∂Ë≤¥ÁöÑË¶ãËß£„ÄÇLexEval Ë≥áÊñôÈõÜÂíåÊéíË°åÊ¶úÂÖ¨ÈñãÊñº \url{https://github.com/CSHaitao/LexEval}Ôºå‰∏¶Â∞áÊåÅÁ∫åÊõ¥Êñ∞„ÄÇ

##### **Computer-mediated therapies for stroke rehabilitation: a systematic review and meta-Analysis**
2409.20260v1 by Stanley Mugisha. Mirko Job. Matteo Zoppi, Marco Testa, Rezia Molfino

OBJECTIVE: To evaluate the efficacy of different forms of virtual reality
(VR) treatments as either immersive virtual reality (IVR) or non-immersive
virtual reality (NIVR) in comparison to conventional therapy (CT) in improving
physical and psychological status among stroke patients. METHODS: The
literature search was conducted on seven databases. ACM Digital Library,
Medline (via PubMed), Cochrane, IEEE Xplore, Web of Science, and Scopus. The
effect sizes of the main outcomes were calculated using Cohen's d. Pooled
results were used to present an overall estimate of the treatment effect using
a random-effects model. RESULTS: A total of 22 randomized controlled trials
were evaluated. 3 trials demonstrated that immersive virtual reality improved
upper limb activity, function and activity of daily life in a way comparable to
CT. 18 trials showed that NIVR had similar benefits to CT for upper limb
activity and function, balance and mobility, activities of daily living and
participation. A comparison between the different forms of VR showed that IVR
may be more beneficial than NIVR for upper limb training and activities of
daily life. CONCLUSIONS: This study found out that IVR therapies may be more
effective than NIVR but not CT to improve upper limb activity, function, and
daily life activities. However, there is no evidence of the durability of IVR
treatment. More research involving studies with larger samples is needed to
assess the long-term effects and promising benefits of immersive virtual
reality technology.

ÊëòË¶ÅÔºöÁõÆÊ®ôÔºöË©ï‰º∞‰∏çÂêåÂΩ¢ÂºèÁöÑËôõÊì¨ÂØ¶Â¢É (VR) Ê≤ªÁôÇÔºå‰æãÂ¶ÇÊ≤âÊµ∏ÂºèËôõÊì¨ÂØ¶Â¢É (IVR) ÊàñÈùûÊ≤âÊµ∏ÂºèËôõÊì¨ÂØ¶Â¢É (NIVR)ÔºåËàáÂÇ≥Áµ±ÁôÇÊ≥ï (CT) Áõ∏ÊØîÔºåÂú®ÊîπÂñÑ‰∏≠È¢®ÊÇ£ËÄÖÁöÑË∫´È´îÂíåÂøÉÁêÜÁãÄÊÖãÊñπÈù¢ÁöÑÂäüÊïà„ÄÇÊñπÊ≥ïÔºöÂú®‰∏ÉÂÄãË≥áÊñôÂ∫´‰∏≠ÈÄ≤Ë°åÊñáÁçªÊêúÂ∞ã„ÄÇACM Êï∏‰ΩçÂúñÊõ∏È§®„ÄÅMedlineÔºàÈÄèÈÅé PubMedÔºâ„ÄÅCochrane„ÄÅIEEE Xplore„ÄÅWeb of Science Âíå Scopus„ÄÇ‰ΩøÁî® Cohen's d Ë®àÁÆó‰∏ªË¶ÅÁµêÊûúÁöÑÊïàÊáâÂÄº„ÄÇÂåØÁ∏ΩÁµêÊûúÁî®Êñº‰ΩøÁî®Èö®Ê©üÊïàÊáâÊ®°ÂûãÂëàÁèæÊ≤ªÁôÇÊïàÊûúÁöÑÊï¥È´î‰º∞Ë®à„ÄÇÁµêÊûúÔºöÁ∏ΩÂÖ±Ë©ï‰º∞‰∫Ü 22 È†ÖÈö®Ê©üÂ∞çÁÖßË©¶È©ó„ÄÇ3 È†ÖË©¶È©óË°®ÊòéÔºåÊ≤âÊµ∏ÂºèËôõÊì¨ÂØ¶Â¢ÉÊîπÂñÑ‰∫Ü‰∏äËÇ¢Ê¥ªÂãï„ÄÅÂäüËÉΩÂíåÊó•Â∏∏ÁîüÊ¥ªÊ¥ªÂãïÔºåËàá CT Áõ∏Áï∂„ÄÇ18 È†ÖË©¶È©óË°®ÊòéÔºåNIVR Â∞ç‰∏äËÇ¢Ê¥ªÂãïÂíåÂäüËÉΩ„ÄÅÂπ≥Ë°°ÂíåÊ¥ªÂãïËÉΩÂäõ„ÄÅÊó•Â∏∏ÁîüÊ¥ªÊ¥ªÂãïÂíåÂèÉËàáÂ∫¶ÂÖ∑ÊúâËàá CT Áõ∏‰ººÁöÑÁõäËôï„ÄÇ‰∏çÂêåÂΩ¢ÂºèÁöÑ VR ‰πãÈñìÁöÑÊØîËºÉË°®ÊòéÔºåIVR ÂèØËÉΩÊØî NIVR Â∞ç‰∏äËÇ¢Ë®ìÁ∑¥ÂíåÊó•Â∏∏ÁîüÊ¥ªÊ¥ªÂãïÊõ¥ÊúâÁõä„ÄÇÁµêË´ñÔºöÊú¨Á†îÁ©∂ÁôºÁèæ IVR Ê≤ªÁôÇÂèØËÉΩÊØî NIVR Êõ¥ÊúâÊïàÔºå‰ΩÜ‰∏çÂ¶Ç CT ËÉΩÊîπÂñÑ‰∏äËÇ¢Ê¥ªÂãï„ÄÅÂäüËÉΩÂíåÊó•Â∏∏ÁîüÊ¥ªÊ¥ªÂãï„ÄÇÁÑ∂ËÄåÔºåÊ≤íÊúâË≠âÊìöË°®Êòé IVR Ê≤ªÁôÇÁöÑÊåÅ‰πÖÊÄß„ÄÇÈúÄË¶ÅÊõ¥Â§öÊ∂âÂèäÊõ¥Â§ßÊ®£Êú¨ÁöÑÁ†îÁ©∂‰æÜË©ï‰º∞Ê≤âÊµ∏ÂºèËôõÊì¨ÂØ¶Â¢ÉÊäÄË°ìÁöÑÈï∑ÊúüÊïàÊûúÂíåÊúâÂ∏åÊúõÁöÑÁõäËôï„ÄÇ

##### **What is the Role of Large Language Models in the Evolution of Astronomy Research?**
2409.20252v1 by Morgan Fouesneau, Ivelina G. Momcheva, Urmila Chadayammuri, Mariia Demianenko, Antoine Dumont, Raphael E. Hviding, K. Angelique Kahle, Nadiia Pulatova, Bhavesh Rajpoot, Marten B. Scheuck, Rhys Seeburger, Dmitry Semenov, Jaime I. Villase√±or

ChatGPT and other state-of-the-art large language models (LLMs) are rapidly
transforming multiple fields, offering powerful tools for a wide range of
applications. These models, commonly trained on vast datasets, exhibit
human-like text generation capabilities, making them useful for research tasks
such as ideation, literature review, coding, drafting, and outreach. We
conducted a study involving 13 astronomers at different career stages and
research fields to explore LLM applications across diverse tasks over several
months and to evaluate their performance in research-related activities. This
work was accompanied by an anonymous survey assessing participants' experiences
and attitudes towards LLMs. We provide a detailed analysis of the tasks
attempted and the survey answers, along with specific output examples. Our
findings highlight both the potential and limitations of LLMs in supporting
research while also addressing general and research-specific ethical
considerations. We conclude with a series of recommendations, emphasizing the
need for researchers to complement LLMs with critical thinking and domain
expertise, ensuring these tools serve as aids rather than substitutes for
rigorous scientific inquiry.

ÊëòË¶ÅÔºöChatGPT ÂíåÂÖ∂‰ªñÊúÄÂÖàÈÄ≤ÁöÑÂ§ßË™ûË®ÄÊ®°Âûã (LLM) Ê≠£Âø´ÈÄüËΩâËÆäÂ§öÈáçÈ†òÂüüÔºåÁÇ∫Âª£Ê≥õÁöÑÊáâÁî®Á®ãÂºèÊèê‰æõÂº∑Â§ßÁöÑÂ∑•ÂÖ∑„ÄÇÈÄô‰∫õÊ®°ÂûãÈÄöÂ∏∏Âú®ÈæêÂ§ßÁöÑË≥áÊñôÈõÜ‰∏äË®ìÁ∑¥ÔºåÂ±ïÁèæÂá∫È°û‰ºº‰∫∫È°ûÁöÑÊñáÂ≠óÁîüÊàêËÉΩÂäõÔºåËÆìÂÆÉÂÄëÂèØÁî®ÊñºÁ†îÁ©∂‰ªªÂãôÔºå‰æãÂ¶ÇÊßãÊÄù„ÄÅÊñáÁçªÂõûÈ°ß„ÄÅÁ∑®Á¢º„ÄÅËµ∑ËçâÂíåÂ§ñÂ±ï„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÁ†îÁ©∂ÔºåËÆì 13 ‰Ωç‰∏çÂêå‰∫ãÊ•≠ÈöéÊÆµÂíåÁ†îÁ©∂È†òÂüüÁöÑÂ§©ÊñáÂ≠∏ÂÆ∂ÂèÉËàáÔºåÂú®ÂπæÂÄãÊúàÂÖßÊé¢Á¥¢ LLM Âú®‰∏çÂêå‰ªªÂãô‰∏≠ÁöÑÊáâÁî®Ôºå‰∏¶Ë©ï‰º∞ÂÆÉÂÄëÂú®Á†îÁ©∂Áõ∏ÈóúÊ¥ªÂãï‰∏≠ÁöÑË°®Áèæ„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÈôÑÊúâ‰∏Ä‰ªΩÂåøÂêçË™øÊü•ÔºåË©ï‰º∞ÂèÉËàáËÄÖÂ∞ç LLM ÁöÑÁ∂ìÈ©óÂíåÊÖãÂ∫¶„ÄÇÊàëÂÄëÊèê‰æõ‰ªªÂãôÂòóË©¶ÂíåË™øÊü•Á≠îÊ°àÁöÑË©≥Á¥∞ÂàÜÊûêÔºå‰ª•ÂèäÂÖ∑È´îÁöÑËº∏Âá∫ÁØÑ‰æã„ÄÇÊàëÂÄëÁöÑÁôºÁèæÂº∑Ë™ø‰∫Ü LLM Âú®ÊîØÊåÅÁ†îÁ©∂ÊñπÈù¢ÁöÑÊΩõÂäõÂíåÈôêÂà∂ÔºåÂêåÊôÇ‰πüËôïÁêÜ‰∫Ü‰∏ÄËà¨ÊÄßÂíåÁ†îÁ©∂ÁâπÂÆöÁöÑÂÄ´ÁêÜËÄÉÈáè„ÄÇÊàëÂÄëÊúÄÂæåÊèêÂá∫‰∫Ü‰∏ÄÁ≥ªÂàóÂª∫Ë≠∞ÔºåÂº∑Ë™øÁ†îÁ©∂‰∫∫Âì°ÈúÄË¶Å‰ª•ÊâπÂà§ÊÄßÊÄùËÄÉÂíåÈ†òÂüüÂ∞àÊ•≠Áü•Ë≠ò‰æÜË£úÂÖÖ LLMÔºåÁ¢∫‰øùÈÄô‰∫õÂ∑•ÂÖ∑‰ΩúÁÇ∫ËºîÂä©Â∑•ÂÖ∑ÔºåËÄå‰∏çÊòØÂö¥Ë¨πÁßëÂ≠∏Êé¢Á©∂ÁöÑÊõø‰ª£ÂìÅ„ÄÇ

##### **Resource Allocation for Stable LLM Training in Mobile Edge Computing**
2409.20247v1 by Chang Liu, Jun Zhao

As mobile devices increasingly become focal points for advanced applications,
edge computing presents a viable solution to their inherent computational
limitations, particularly in deploying large language models (LLMs). However,
despite the advancements in edge computing, significant challenges remain in
efficient training and deploying LLMs due to the computational demands and data
privacy concerns associated with these models. This paper explores a
collaborative training framework that integrates mobile users with edge servers
to optimize resource allocation, thereby enhancing both performance and
efficiency. Our approach leverages parameter-efficient fine-tuning (PEFT)
methods, allowing mobile users to adjust the initial layers of the LLM while
edge servers handle the more demanding latter layers. Specifically, we
formulate a multi-objective optimization problem to minimize the total energy
consumption and delay during training. We also address the common issue of
instability in model performance by incorporating stability enhancements into
our objective function. Through novel fractional programming technique, we
achieve a stationary point for the formulated problem. Simulations demonstrate
that our method reduces the energy consumption as well as the latency, and
increases the reliability of LLMs across various mobile settings.

ÊëòË¶ÅÔºöÈö®ËëóË°åÂãïË£ùÁΩÆÊó•ÁõäÊàêÁÇ∫ÈÄ≤ÈöéÊáâÁî®Á®ãÂºèÁöÑÈáçÈªûÔºå
ÈÇäÁ∑£ÈÅãÁÆóÁÇ∫ÂÖ∂Âõ∫ÊúâÁöÑÈÅãÁÆóÈôêÂà∂Êèê‰æõ‰∫ÜÂèØË°åÁöÑËß£Ê±∫ÊñπÊ°àÔºåÁâπÂà•ÊòØÂú®ÈÉ®ÁΩ≤Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊôÇ„ÄÇÁÑ∂ËÄåÔºåÂÑòÁÆ°ÈÇäÁ∑£ÈÅãÁÆóÊúâÈÄ≤Â±ïÔºåÁî±ÊñºÈÄô‰∫õÊ®°ÂûãÁõ∏ÈóúÁöÑÈÅãÁÆóÈúÄÊ±ÇÂíåË≥áÊñôÈö±ÁßÅÂïèÈ°åÔºåÂú®Ë®ìÁ∑¥ÂíåÈÉ®ÁΩ≤ LLM ÊôÇ‰ªçÊúâÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫Ü‰∏ÄÂÄãÂçî‰ΩúË®ìÁ∑¥Êû∂ÊßãÔºåÂ∞áË°åÂãïË£ùÁΩÆ‰ΩøÁî®ËÄÖËàáÈÇäÁ∑£‰º∫ÊúçÂô®Êï¥ÂêàÔºå‰ª•ÊúÄ‰Ω≥ÂåñË≥áÊ∫êÈÖçÁΩÆÔºåÈÄ≤ËÄåÊèêÂçáÊïàËÉΩÂíåÊïàÁéá„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂà©Áî®‰∫ÜÂèÉÊï∏ÊúâÊïàÂæÆË™ø (PEFT) ÊñπÊ≥ïÔºåËÆìË°åÂãïË£ùÁΩÆ‰ΩøÁî®ËÄÖË™øÊï¥ LLM ÁöÑÂàùÂßãÂ±§ÔºåËÄåÈÇäÁ∑£‰º∫ÊúçÂô®ÂâáËôïÁêÜË¶ÅÊ±ÇËºÉÈ´òÁöÑÂæåÁ∫åÂ±§„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂà∂ÂÆö‰∫Ü‰∏ÄÂÄãÂ§öÁõÆÊ®ôÊúÄ‰Ω≥ÂåñÂïèÈ°åÔºå‰ª•ÊúÄÂ∞èÂåñË®ìÁ∑¥ÊúüÈñìÁöÑÁ∏ΩËÉΩËÄóÂíåÂª∂ÈÅ≤„ÄÇÊàëÂÄë‰πüÈÄèÈÅéÂ∞áÁ©©ÂÆöÊÄßÂº∑ÂåñÁ¥çÂÖ•ÊàëÂÄëÁöÑÁõÆÊ®ôÂáΩÊï∏Ôºå‰æÜËß£Ê±∫Ê®°ÂûãÊïàËÉΩ‰∏çÁ©©ÂÆöÁöÑÂ∏∏Ë¶ãÂïèÈ°å„ÄÇÈÄèÈÅéÂâµÊñ∞ÁöÑÂàÜÊï∏Ë¶èÂäÉÊäÄË°ìÔºåÊàëÂÄëÁÇ∫Âà∂ÂÆöÁöÑÂïèÈ°åÈÅîÂà∞‰∫ÜÂπ≥Á©©Èªû„ÄÇÊ®°Êì¨ÁµêÊûúÈ°ØÁ§∫ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊ∏õÂ∞ë‰∫ÜËÉΩËÄóÂíåÂª∂ÈÅ≤Ôºå‰∏¶ÊèêÈ´ò‰∫Ü LLM Âú®ÂêÑÁ®ÆË°åÂãïË£ùÁΩÆË®≠ÂÆö‰∏≠ÁöÑÂèØÈù†ÊÄß„ÄÇ

##### **Analysing Zero-Shot Readability-Controlled Sentence Simplification**
2409.20246v1 by Abdullah Barayan, Jose Camacho-Collados, Fernando Alva-Manchego

Readability-controlled text simplification (RCTS) rewrites texts to lower
readability levels while preserving their meaning. RCTS models often depend on
parallel corpora with readability annotations on both source and target sides.
Such datasets are scarce and difficult to curate, especially at the sentence
level. To reduce reliance on parallel data, we explore using instruction-tuned
large language models for zero-shot RCTS. Through automatic and manual
evaluations, we examine: (1) how different types of contextual information
affect a model's ability to generate sentences with the desired readability,
and (2) the trade-off between achieving target readability and preserving
meaning. Results show that all tested models struggle to simplify sentences
(especially to the lowest levels) due to models' limitations and
characteristics of the source sentences that impede adequate rewriting. Our
experiments also highlight the need for better automatic evaluation metrics
tailored to RCTS, as standard ones often misinterpret common simplification
operations, and inaccurately assess readability and meaning preservation.

ÊëòË¶ÅÔºöÂèØËÆÄÊÄßÊéßÂà∂ÊñáÊú¨Á∞°Âåñ (RCTS) ÊúÉÊîπÂØ´ÊñáÂ≠óÔºåÈôç‰ΩéÂèØËÆÄÊÄßÁ≠âÁ¥öÔºåÂêåÊôÇ‰øùÁïôÂÖ∂ÊÑèÁæ©„ÄÇRCTS Ê®°ÂûãÈÄöÂ∏∏‰æùË≥¥Êñº‰æÜÊ∫êÂíåÁõÆÊ®ôÂÖ©ÂÅ¥ÈÉΩÊúâÂèØËÆÄÊÄßË®ªËß£ÁöÑÂπ≥Ë°åË™ûÊñôÂ∫´„ÄÇÊ≠§È°ûË≥áÊñôÈõÜÁ®ÄÂ∞ë‰∏îÈõ£‰ª•Êï¥ÁêÜÔºåÁâπÂà•ÊòØÂú®Âè•Â≠êÂ±§Á¥ö„ÄÇÁÇ∫‰∫ÜÊ∏õÂ∞ëÂ∞çÂπ≥Ë°åË≥áÊñôÁöÑ‰æùË≥¥ÔºåÊàëÂÄëÊé¢Á¥¢‰ΩøÁî®Êåá‰ª§Ë™øÊï¥ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÈÄ≤Ë°åÈõ∂Ê¨°Â≠∏Áøí RCTS„ÄÇÈÄèÈÅéËá™ÂãïÂíåÊâãÂãïË©ï‰º∞ÔºåÊàëÂÄëÊé¢Ë®éÔºö(1) ‰∏çÂêåÈ°ûÂûãÁöÑ‰∏ä‰∏ãÊñáË≥áË®äÂ¶Ç‰ΩïÂΩ±ÈüøÊ®°ÂûãÁî¢ÁîüÂÖ∑ÊúâÊâÄÈúÄÂèØËÆÄÊÄßÂè•Â≠êÁöÑËÉΩÂäõÔºå‰ª•Âèä (2) ÈÅîÂà∞ÁõÆÊ®ôÂèØËÆÄÊÄßËàá‰øùÁïôÊÑèÁæ©‰πãÈñìÁöÑÂèñÊç®„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåÊâÄÊúâÊ∏¨Ë©¶Ê®°ÂûãÈÉΩÈõ£‰ª•Á∞°ÂåñÂè•Â≠êÔºàÁâπÂà•ÊòØÂà∞ÊúÄ‰ΩéÁ≠âÁ¥öÔºâÔºåÂéüÂõ†Âú®ÊñºÊ®°ÂûãÁöÑÈôêÂà∂ÂíåÈòªÁ§ôÂÖÖÂàÜÊîπÂØ´ÁöÑ‰æÜÊ∫êÂè•Â≠êÁâπÊÄß„ÄÇÊàëÂÄëÁöÑÂØ¶È©ó‰πüÂº∑Ë™øÈúÄË¶ÅÈáùÂ∞ç RCTS ÈáèË∫´ÊâìÈÄ†Êõ¥Â•ΩÁöÑËá™ÂãïË©ï‰º∞ÊåáÊ®ôÔºåÂõ†ÁÇ∫Ê®ôÊ∫ñÊåáÊ®ôÈÄöÂ∏∏ÊúÉË™§Ëß£Â∏∏Ë¶ãÁöÑÁ∞°ÂåñÊìç‰ΩúÔºå‰∏¶ÈåØË™§Ë©ï‰º∞ÂèØËÆÄÊÄßÂíåÊÑèÁæ©‰øùÁïô„ÄÇ

##### **PsyGUARD: An Automated System for Suicide Detection and Risk Assessment in Psychological Counseling**
2409.20243v1 by Huachuan Qiu, Lizhi Ma, Zhenzhong Lan

As awareness of mental health issues grows, online counseling support
services are becoming increasingly prevalent worldwide. Detecting whether users
express suicidal ideation in text-based counseling services is crucial for
identifying and prioritizing at-risk individuals. However, the lack of
domain-specific systems to facilitate fine-grained suicide detection and
corresponding risk assessment in online counseling poses a significant
challenge for automated crisis intervention aimed at suicide prevention. In
this paper, we propose PsyGUARD, an automated system for detecting suicide
ideation and assessing risk in psychological counseling. To achieve this, we
first develop a detailed taxonomy for detecting suicide ideation based on
foundational theories. We then curate a large-scale, high-quality dataset
called PsySUICIDE for suicide detection. To evaluate the capabilities of
automated systems in fine-grained suicide detection, we establish a range of
baselines. Subsequently, to assist automated services in providing safe,
helpful, and tailored responses for further assessment, we propose to build a
suite of risk assessment frameworks. Our study not only provides an insightful
analysis of the effectiveness of automated risk assessment systems based on
fine-grained suicide detection but also highlights their potential to improve
mental health services on online counseling platforms. Code, data, and models
are available at https://github.com/qiuhuachuan/PsyGUARD.

ÊëòË¶ÅÔºöÈö®ËëóÂøÉÁêÜÂÅ•Â∫∑ÂïèÈ°åÊÑèË≠òÁöÑÊèêÂçáÔºåÁ∑ö‰∏äË´ÆË©¢ÊúçÂãôÊ≠£ÊñºÂÖ®ÁêÉÂêÑÂú∞Êó•ÁõäÊôÆÂèä„ÄÇÂú®Âü∫ÊñºÊñáÂ≠óÁöÑË´ÆË©¢ÊúçÂãô‰∏≠ÔºåÂÅµÊ∏¨‰ΩøÁî®ËÄÖÊòØÂê¶Ë°®ÈÅîÂá∫Ëá™ÊÆ∫ÊÑèÂøµÂ∞çÊñºËæ®Ë≠ò‰∏¶ÂÑ™ÂÖàËôïÁêÜÊúâÈ¢®Èö™ÁöÑÂÄã‰∫∫Ëá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÁº∫‰πèÁâπÂÆöÈ†òÂüüÁöÑÁ≥ªÁµ±‰æÜ‰øÉÈÄ≤Á≤æÁ¥∞ÂåñÁöÑËá™ÊÆ∫ÂÅµÊ∏¨ËàáÁõ∏ÊáâÁöÑÈ¢®Èö™Ë©ï‰º∞ÔºåÂ∞çÊó®Âú®È†êÈò≤Ëá™ÊÆ∫ÁöÑËá™ÂãïÂåñÂç±Ê©ü‰ªãÂÖ•ÊßãÊàê‰∫ÜÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ PsyGUARDÔºå‰∏ÄÂÄãÁî®ÊñºÂÅµÊ∏¨Ëá™ÊÆ∫ÊÑèÂøµËàáË©ï‰º∞ÂøÉÁêÜË´ÆË©¢È¢®Èö™ÁöÑËá™ÂãïÂåñÁ≥ªÁµ±„ÄÇÁÇ∫ÈÅîÊàêÊ≠§ÁõÆÊ®ôÔºåÊàëÂÄëÈ¶ñÂÖàÊ†πÊìöÂü∫Á§éÁêÜË´ñÔºåÈñãÁôºÂá∫‰∏ÄÂ•óË©≥Á¥∞ÁöÑËá™ÊÆ∫ÊÑèÂøµÂÅµÊ∏¨ÂàÜÈ°ûÊ≥ï„ÄÇÊé•ËëóÔºåÊàëÂÄëÁ≠ñÂäÉ‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ PsySUICIDE ÁöÑÂ§ßË¶èÊ®°„ÄÅÈ´òÂìÅË≥™Ëá™ÊÆ∫ÂÅµÊ∏¨Ë≥áÊñôÈõÜ„ÄÇÁÇ∫‰∫ÜË©ï‰º∞Ëá™ÂãïÂåñÁ≥ªÁµ±Âú®Á≤æÁ¥∞ÂåñËá™ÊÆ∫ÂÅµÊ∏¨‰∏≠ÁöÑËÉΩÂäõÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÁ≥ªÂàóÁöÑÂü∫Ê∫ñ„ÄÇÈö®ÂæåÔºåÁÇ∫‰∫ÜÂçîÂä©Ëá™ÂãïÂåñÊúçÂãôÊèê‰æõÂÆâÂÖ®„ÄÅÊúâÂπ´Âä©‰∏îÂÆ¢Ë£ΩÂåñÁöÑÂõûÊáâ‰ª•ÈÄ≤Ë°åÈÄ≤‰∏ÄÊ≠•ÁöÑË©ï‰º∞ÔºåÊàëÂÄëÊèêË≠∞Âª∫Êßã‰∏ÄÂ•óÈ¢®Èö™Ë©ï‰º∞Êû∂Êßã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂‰∏çÂÉÖÊèê‰æõ‰∫ÜÂü∫ÊñºÁ≤æÁ¥∞ÂåñËá™ÊÆ∫ÂÅµÊ∏¨ÁöÑËá™ÂãïÂåñÈ¢®Èö™Ë©ï‰º∞Á≥ªÁµ±ÁöÑÊúâÊïàÊÄßÂàÜÊûêÔºå‰πüÂº∑Ë™ø‰∫ÜÂÆÉÂÄëÊîπÂñÑÁ∑ö‰∏äË´ÆË©¢Âπ≥Âè∞ÁöÑÂøÉÁêÜÂÅ•Â∫∑ÊúçÂãôÁöÑÊΩõÂäõ„ÄÇÁ®ãÂºèÁ¢º„ÄÅË≥áÊñôÂíåÊ®°ÂûãÂèØÊñº https://github.com/qiuhuachuan/PsyGUARD ÂèñÂæó„ÄÇ

##### **Beyond Prompts: Dynamic Conversational Benchmarking of Large Language Models**
2409.20222v1 by David Castillo-Bolado, Joseph Davidson, Finlay Gray, Marek Rosa

We introduce a dynamic benchmarking system for conversational agents that
evaluates their performance through a single, simulated, and lengthy
user$\leftrightarrow$agent interaction. The interaction is a conversation
between the user and agent, where multiple tasks are introduced and then
undertaken concurrently. We context switch regularly to interleave the tasks,
which constructs a realistic testing scenario in which we assess the Long-Term
Memory, Continual Learning, and Information Integration capabilities of the
agents. Results from both proprietary and open-source Large-Language Models
show that LLMs in general perform well on single-task interactions, but they
struggle on the same tasks when they are interleaved. Notably, short-context
LLMs supplemented with an LTM system perform as well as or better than those
with larger contexts. Our benchmark suggests that there are other challenges
for LLMs responding to more natural interactions that contemporary benchmarks
have heretofore not been able to capture.

ÊëòË¶ÅÔºöÊàëÂÄëÂºïÈÄ≤‰∫Ü‰∏ÄÂ•óÂãïÊÖãÂü∫Ê∫ñÁ≥ªÁµ±ÔºåÁî®ÊñºÂ∞çË©±‰ª£ÁêÜÔºåÈÄèÈÅéÂñÆ‰∏Ä„ÄÅÊ®°Êì¨‰∏îÂÜóÈï∑ÁöÑ‰ΩøÁî®ËÄÖ$\leftrightarrow$‰ª£ÁêÜ‰∫íÂãïÔºåË©ï‰º∞ÂÖ∂ÊïàËÉΩ„ÄÇ‰∫íÂãïÊòØ‰ΩøÁî®ËÄÖËàá‰ª£ÁêÜ‰πãÈñìÁöÑÂ∞çË©±ÔºåÂÖ∂‰∏≠ÊúÉÂ∞éÂÖ•Â§öÈ†Ö‰ªªÂãôÔºåÁÑ∂ÂæåÂêåÊôÇÈÄ≤Ë°å„ÄÇÊàëÂÄëÊúÉÂÆöÊúüÂàáÊèõÂÖßÂÆπÔºå‰ª•‰∫§ÈåØ‰ªªÂãôÔºåÂª∫Êßã‰∏ÄÂÄãÂØ¶ÈöõÁöÑÊ∏¨Ë©¶ÊÉÖÂ¢ÉÔºåÂú®ÂÖ∂‰∏≠Ë©ï‰º∞‰ª£ÁêÜÁöÑÈï∑ÊúüË®òÊÜ∂„ÄÅÊåÅÁ∫åÂ≠∏ÁøíÂíåË≥áË®äÊï¥ÂêàËÉΩÂäõ„ÄÇ‰æÜËá™Â∞àÊúâÂíåÈñãÊîæÂéüÂßãÁ¢ºÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåLLM Âú®ÂñÆ‰∏Ä‰ªªÂãô‰∫íÂãï‰∏≠ÈÄöÂ∏∏Ë°®ÁèæËâØÂ•ΩÔºå‰ΩÜÁï∂‰ªªÂãô‰∫§ÈåØÊôÇÔºåÂÆÉÂÄëÂú®Áõ∏Âêå‰ªªÂãô‰∏äÊúÉÈÅáÂà∞Âõ∞Èõ£„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåË£úÂÖÖ LTM Á≥ªÁµ±ÁöÑÁü≠ÂÖßÂÆπ LLM ÁöÑË°®ÁèæËàáËºÉÂ§ßÂÖßÂÆπÁöÑ LLM ‰∏ÄÊ®£Â•ΩÔºåÁîöËá≥Êõ¥Â•Ω„ÄÇÊàëÂÄëÁöÑÂü∫Ê∫ñË°®ÊòéÔºåLLM Âú®ÂõûÊáâÊõ¥Ëá™ÁÑ∂ÁöÑ‰∫íÂãïÊôÇÈÇÑÊúâÂÖ∂‰ªñÊåëÊà∞ÔºåËÄåÁï∂‰ª£Âü∫Ê∫ñËøÑ‰ªäÁÑ°Ê≥ïÊéåÊè°ÈÄô‰∫õÊåëÊà∞„ÄÇ

##### **Divided by discipline? A systematic literature review on the quantification of online sexism and misogyny using a semi-automated approach**
2409.20204v1 by Aditi Dutta, Susan Banducci, Chico Q. Camargo

In recent years, several computational tools have been developed to detect
and identify sexism, misogyny, and gender-based hate speech, especially on
online platforms. Though these tools intend to draw on knowledge from both
social science and computer science, little is known about the current state of
research in quantifying online sexism or misogyny. Given the growing concern
over the discrimination of women in online spaces and the rise in
interdisciplinary research on capturing the online manifestation of sexism and
misogyny, a systematic literature review on the research practices and their
measures is the need of the hour. We make three main contributions: (i) we
present a semi-automated way to narrow down the search results in the different
phases of selection stage in the PRISMA flowchart; (ii) we perform a systematic
literature review of research papers that focus on the quantification and
measurement of online gender-based hate speech, examining literature from
computer science and the social sciences from 2012 to 2022; and (iii) we
identify the opportunities and challenges for measuring gender-based online
hate speech. Our findings from topic analysis suggest a disciplinary divide
between the themes of research on sexism/misogyny. With evidence-based review,
we summarise the different approaches used by the studies who have explored
interdisciplinary approaches to bridge the knowledge gap. Coupled with both the
existing literature on social science theories and computational modeling, we
provide an analysis of the benefits and shortcomings of the methodologies used.
Lastly, we discuss the challenges and opportunities for future research
dedicated to measuring online sexism and misogyny.

ÊëòË¶ÅÔºö<paragraph>ËøëÂπ¥‰æÜÔºåÂ∑≤Á∂ìÈñãÁôºÂá∫Â§öÁ®ÆË®àÁÆóÂ∑•ÂÖ∑‰æÜÂÅµÊ∏¨ÂíåËæ®Ë≠òÊÄßÂà•Ê≠ßË¶ñ„ÄÅÂé≠Â•≥ÁóáÂíåÂü∫ÊñºÊÄßÂà•ÁöÑ‰ªáÊÅ®Ë®ÄË´ñÔºåÁâπÂà•ÊòØÂú®Á∑ö‰∏äÂπ≥Âè∞‰∏ä„ÄÇÂÑòÁÆ°ÈÄô‰∫õÂ∑•ÂÖ∑Êó®Âú®Âà©Áî®Á§æÊúÉÁßëÂ≠∏ÂíåÈõªËÖ¶ÁßëÂ≠∏ÁöÑÁü•Ë≠òÔºå‰ΩÜÂ∞çÊñºÈáèÂåñÁ∂≤Ë∑ØÊÄßÂà•Ê≠ßË¶ñÊàñÂé≠Â•≥ÁóáÁöÑÁ†îÁ©∂ÁèæÊ≥ÅÊâÄÁü•ÁîöÂ∞ë„ÄÇÈëëÊñºÂ∞çÁ∂≤Ë∑ØÁ©∫Èñì‰∏≠Â•≥ÊÄßÈÅ≠ÂèóÊ≠ßË¶ñÁöÑÈóúÊ≥®Êó•ÁõäÂ¢ûÂä†Ôºå‰ª•ÂèäÊçïÊçâÊÄßÂà•Ê≠ßË¶ñÂíåÂé≠Â•≥ÁóáÁ∂≤Ë∑ØË°®ÁèæÁöÑË∑®È†òÂüüÁ†îÁ©∂ËààËµ∑ÔºåÂ∞çÊñºÁ†îÁ©∂ÂØ¶ÂãôÂèäÂÖ∂Ë°°ÈáèÊ®ôÊ∫ñÈÄ≤Ë°åÁ≥ªÁµ±ÊÄßÁöÑÊñáÁçªÂõûÈ°ßÊòØÁï∂Âãô‰πãÊÄ•„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏âÂÄã‰∏ªË¶ÅÁöÑË≤¢ÁçªÔºö(i) ÊèêÂá∫‰∏ÄÂÄãÂçäËá™ÂãïÂåñÁöÑÊñπÂºèÔºåÁ∏ÆÂ∞è PRISMA ÊµÅÁ®ãÂúñ‰∏≠ÈÅ∏ÊìáÈöéÊÆµ‰∏çÂêåÈöéÊÆµÁöÑÊêúÂ∞ãÁµêÊûúÔºõ(ii) ÈáùÂ∞çÁ∂≤Ë∑ØÊÄßÂà•‰ªáÊÅ®Ë®ÄË´ñÁöÑÈáèÂåñÂíåË°°ÈáèÈÄ≤Ë°åÁ≥ªÁµ±ÊÄßÁöÑÊñáÁçªÂõûÈ°ßÔºåÊé¢Ë®é 2012 Âπ¥Ëá≥ 2022 Âπ¥ÈñìÈõªËÖ¶ÁßëÂ≠∏ÂíåÁ§æÊúÉÁßëÂ≠∏ÁöÑÊñáÁçªÔºõ(iii) ÊâæÂá∫Ë°°ÈáèÁ∂≤Ë∑ØÊÄßÂà•‰ªáÊÅ®Ë®ÄË´ñÁöÑÊ©üÊúÉÂíåÊåëÊà∞„ÄÇÊàëÂÄëÂæû‰∏ªÈ°åÂàÜÊûê‰∏≠ÁôºÁèæÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåÊÄßÂà•Ê≠ßË¶ñ/Âé≠Â•≥ÁóáÁ†îÁ©∂‰∏ªÈ°å‰πãÈñìÂ≠òÂú®Â≠∏ÁßëÈ¥ªÊ∫ù„ÄÇÈÄèÈÅéÂæ™Ë≠âÂõûÈ°ßÔºåÊàëÂÄëÁ∏ΩÁµê‰∫ÜÁ†îÁ©∂‰∏≠Áî®ÊñºÂΩåÂêàÁü•Ë≠òÂ∑ÆË∑ùÁöÑË∑®È†òÂüüÊñπÊ≥ï„ÄÇÁµêÂêàÁ§æÊúÉÁßëÂ≠∏ÁêÜË´ñÂíåË®àÁÆóÊ®°ÂûãÁöÑÊó¢ÊúâÊñáÁçªÔºåÊàëÂÄëÂàÜÊûê‰∫ÜÊâÄ‰ΩøÁî®ÊñπÊ≥ïÁöÑÂÑ™ÈªûÂíåÁº∫Èªû„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñ‰∫ÜËá¥ÂäõÊñºË°°ÈáèÁ∂≤Ë∑ØÊÄßÂà•Ê≠ßË¶ñÂíåÂé≠Â•≥ÁóáÁöÑÊú™‰æÜÁ†îÁ©∂ÁöÑÊåëÊà∞ÂíåÊ©üÊúÉ„ÄÇ</paragraph>

##### **AfriHuBERT: A self-supervised speech representation model for African languages**
2409.20201v1 by Jesujoba O. Alabi, Xuechen Liu, Dietrich Klakow, Junichi Yamagishi

In this work, we present AfriHuBERT, an extension of mHuBERT-147, a
state-of-the-art (SOTA) and compact self-supervised learning (SSL) model,
originally pretrained on 147 languages. While mHuBERT-147 was pretrained on 16
African languages, we expand this to cover 39 African languages through
continued pretraining on 6,500+ hours of speech data aggregated from diverse
sources, including 23 newly added languages. We evaluate AfriHuBERT on two key
speech tasks: Language Identification (LID) and Automatic Speech Recognition
(ASR) using FLEURS dataset. Our results show a +4% F1 score improvement on
average for LID and a -1.2% average Word Error Rate (WER) reduction for ASR.
Further analysis shows that ASR models trained on AfriHuBERT exhibit improved
cross-corpus generalization. Additionally, the analysis indicates that the
FLEURS have data quality limitations that may affect their suitability for
evaluating low-resource African languages, suggesting the need for better
evaluation benchmarks for these languages.

ÊëòË¶ÅÔºöÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü AfriHuBERTÔºåÈÄôÊòØ mHuBERT-147 ÁöÑÂª∂‰º∏Ôºå‰∏ÄÁ®ÆÊúÄÂÖàÈÄ≤ (SOTA) ‰∏îÁ∑äÊπäÁöÑËá™Áõ£Áù£Â≠∏Áøí (SSL) Ê®°ÂûãÔºåÊúÄÂàùÂú® 147 Á®ÆË™ûË®Ä‰∏äÈÄ≤Ë°åÈ†êË®ìÁ∑¥„ÄÇÈõñÁÑ∂ mHuBERT-147 Âú® 16 Á®ÆÈùûÊ¥≤Ë™ûË®Ä‰∏äÈÄ≤Ë°å‰∫ÜÈ†êË®ìÁ∑¥Ôºå‰ΩÜÊàëÂÄëÈÄöÈÅéÂú®Âæû‰∏çÂêå‰æÜÊ∫êÂΩôÈõÜÁöÑ 6,500 Â§öÂ∞èÊôÇË™ûÈü≥Êï∏ÊìöÔºàÂåÖÊã¨ 23 Á®ÆÊñ∞Â¢ûÂä†ÁöÑË™ûË®ÄÔºâ‰∏äÊåÅÁ∫åÈ†êË®ìÁ∑¥ÔºåÂ∞áÂÖ∂Êì¥Â±ïÂà∞Ê∂µËìã 39 Á®ÆÈùûÊ¥≤Ë™ûË®Ä„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄã‰∏ªË¶ÅÁöÑË™ûÈü≥‰ªªÂãô‰∏äË©ï‰º∞‰∫Ü AfriHuBERTÔºöË™ûË®ÄË≠òÂà• (LID) ÂíåËá™ÂãïË™ûÈü≥Ë≠òÂà• (ASR)Ôºå‰ΩøÁî® FLEURS Êï∏ÊìöÈõÜ„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåLID ÁöÑ F1 ÂàÜÊï∏Âπ≥ÂùáÊèêÈ´ò‰∫Ü +4%ÔºåËÄå ASR ÁöÑÂπ≥ÂùáÂ≠óÂÖÉÈåØË™§Áéá (WER) Èôç‰Ωé‰∫Ü -1.2%„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑÂàÜÊûêË°®ÊòéÔºåÂú® AfriHuBERT ‰∏äË®ìÁ∑¥ÁöÑ ASR Ê®°ÂûãË°®ÁèæÂá∫Êõ¥Â•ΩÁöÑË∑®Ë™ûÊñôÂ∫´Ê¶ÇÊã¨ÊÄß„ÄÇÊ≠§Â§ñÔºåÂàÜÊûêË°®Êòé FLEURS Â≠òÂú®Êï∏ÊìöÂìÅË≥™ÈôêÂà∂ÔºåÈÄôÂèØËÉΩÊúÉÂΩ±ÈüøÂÆÉÂÄëË©ï‰º∞‰ΩéË≥áÊ∫êÈùûÊ¥≤Ë™ûË®ÄÁöÑÈÅ©Áî®ÊÄßÔºåÈÄôË°®ÊòéÈúÄË¶ÅÈáùÂ∞çÈÄô‰∫õË™ûË®ÄÂà∂ÂÆöÊõ¥Â•ΩÁöÑË©ï‰º∞Âü∫Ê∫ñ„ÄÇ

##### **Melody Is All You Need For Music Generation**
2409.20196v1 by Shaopeng Wei, Manzhen Wei, Haoyu Wang, Yu Zhao, Gang Kou

We present the Melody Guided Music Generation (MMGen) model, the first novel
approach using melody to guide the music generation that, despite a pretty
simple method and extremely limited resources, achieves excellent performance.
Specifically, we first align the melody with audio waveforms and their
associated descriptions using the multimodal alignment module. Subsequently, we
condition the diffusion module on the learned melody representations. This
allows MMGen to generate music that matches the style of the provided audio
while also producing music that reflects the content of the given text
description. To address the scarcity of high-quality data, we construct a
multi-modal dataset, MusicSet, which includes melody, text, and audio, and will
be made publicly available. We conduct extensive experiments which demonstrate
the superiority of the proposed model both in terms of experimental metrics and
actual performance quality.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫ÊóãÂæãÂºïÂ∞éÈü≥Ê®ÇÁîüÊàêÔºàMMGenÔºâÊ®°ÂûãÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄã‰ΩøÁî®ÊóãÂæã‰æÜÂºïÂ∞éÈü≥Ê®ÇÁîüÊàêÁöÑÊñ∞Á©éÊñπÊ≥ïÔºåÂÑòÁÆ°ÊñπÊ≥ïÁõ∏Áï∂Á∞°ÂñÆ‰∏îË≥áÊ∫êÊ•µÁÇ∫ÊúâÈôêÔºå‰ΩÜ‰ªçËÉΩÈÅîÂà∞Ê•µ‰Ω≥ÁöÑË°®Áèæ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈ¶ñÂÖà‰ΩøÁî®Â§öÊ®°ÊÖãÂ∞çÈΩäÊ®°ÁµÑÂ∞áÊóãÂæãËàáÈü≥Ë®äÊ≥¢ÂΩ¢ÂèäÂÖ∂Áõ∏ÈóúÊèèËø∞Â∞çÈΩä„ÄÇÈö®ÂæåÔºåÊàëÂÄëÂ∞çÊì¥Êï£Ê®°ÁµÑÈÄ≤Ë°åÊ¢ù‰ª∂ËôïÁêÜÔºå‰ª•Â≠∏ÁøíÊóãÂæãË°®Á§∫„ÄÇÈÄôËÆì MMGen ËÉΩÂ§†ÁîüÊàêÁ¨¶ÂêàÊâÄÊèê‰æõÈü≥Ë®äÈ¢®Ê†ºÁöÑÈü≥Ê®ÇÔºåÂêåÊôÇ‰πüËÉΩÁî¢ÁîüÂèçÊò†Áµ¶ÂÆöÊñáÂ≠óÊèèËø∞ÂÖßÂÆπÁöÑÈü≥Ê®Ç„ÄÇÁÇ∫‰∫ÜËß£Ê±∫È´òÂìÅË≥™Ë≥áÊñôÁöÑÁ®ÄÁº∫ÂïèÈ°åÔºåÊàëÂÄëÂª∫Êßã‰∫Ü‰∏ÄÂÄãÂåÖÂê´ÊóãÂæã„ÄÅÊñáÂ≠óÂíåÈü≥Ë®äÁöÑÂ§öÊ®°ÊÖãË≥áÊñôÈõÜ MusicSetÔºå‰∏¶Â∞áÂÖ¨ÈñãÊèê‰æõ„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºåË≠âÊòé‰∫ÜÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂú®ÂØ¶È©óÊåáÊ®ôÂíåÂØ¶ÈöõÊïàËÉΩÂìÅË≥™ÊñπÈù¢ÈÉΩÂÖ∑ÊúâÂÑ™Ë∂äÊÄß„ÄÇ

##### **Forecasting Disease Progression with Parallel Hyperplanes in Longitudinal Retinal OCT**
2409.20195v1 by Arunava Chakravarty, Taha Emre, Dmitrii Lachinov, Antoine Rivail, Hendrik Scholl, Lars Fritsche, Sobha Sivaprasad, Daniel Rueckert, Andrew Lotery, Ursula Schmidt-Erfurth, Hrvoje Bogunoviƒá

Predicting future disease progression risk from medical images is challenging
due to patient heterogeneity, and subtle or unknown imaging biomarkers.
Moreover, deep learning (DL) methods for survival analysis are susceptible to
image domain shifts across scanners. We tackle these issues in the task of
predicting late dry Age-related Macular Degeneration (dAMD) onset from retinal
OCT scans. We propose a novel DL method for survival prediction to jointly
predict from the current scan a risk score, inversely related to
time-to-conversion, and the probability of conversion within a time interval
$t$. It uses a family of parallel hyperplanes generated by parameterizing the
bias term as a function of $t$. In addition, we develop unsupervised losses
based on intra-subject image pairs to ensure that risk scores increase over
time and that future conversion predictions are consistent with AMD stage
prediction using actual scans of future visits. Such losses enable
data-efficient fine-tuning of the trained model on new unlabeled datasets
acquired with a different scanner. Extensive evaluation on two large datasets
acquired with different scanners resulted in a mean AUROCs of 0.82 for
Dataset-1 and 0.83 for Dataset-2, across prediction intervals of 6,12 and 24
months.

ÊëòË¶ÅÔºöÁî±ÊñºÊÇ£ËÄÖÁï∞Ë≥™ÊÄß‰ª•Âèä‰∏çÊòéÈ°ØÊàñÊú™Áü•ÁöÑÂΩ±ÂÉèÁîüÁâ©Ê®ôË®òÔºåÂæûÈÜ´Â≠∏ÂΩ±ÂÉèÈ†êÊ∏¨Êú™‰æÜÁñæÁóÖÈÄ≤Á®ãÈ¢®Èö™ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇ
Ê≠§Â§ñÔºåÁî®ÊñºÂ≠òÊ¥ªÂàÜÊûêÁöÑÊ∑±Â∫¶Â≠∏Áøí (DL) ÊñπÊ≥ïÂÆπÊòìÂèóÂà∞Ë∑®ÊéÉÊèèÂÑÄÁöÑÂΩ±ÂÉèÂüüËΩâÁßªÂΩ±Èüø„ÄÇÊàëÂÄëÂú®È†êÊ∏¨ÊôöÊúü‰πæÊÄßÂπ¥ÈΩ°Áõ∏ÈóúÊÄßÈªÉÊñëÈÉ®ÁóÖËÆä (dAMD) ÂæûË¶ñÁ∂≤ËÜú OCT ÊéÉÊèè‰∏≠ÁôºÁîüÁöÑ‰ªªÂãô‰∏≠Ëß£Ê±∫ÈÄô‰∫õÂïèÈ°å„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑ DL ÊñπÊ≥ïÔºåÁî®ÊñºÂ≠òÊ¥ªÈ†êÊ∏¨Ôºå‰ª•ÂæûÁï∂ÂâçÊéÉÊèè‰∏≠ÂÖ±ÂêåÈ†êÊ∏¨È¢®Èö™Ë©ïÂàÜÔºåËàáËΩâÊèõÊôÇÈñìÊàêÂèçÊØîÔºå‰ª•ÂèäÂú®ÊôÇÈñìÈñìÈöî $t$ ÂÖßËΩâÊèõÁöÑÊ©üÁéá„ÄÇÂÆÉ‰ΩøÁî®‰∏ÄÁµÑÂπ≥Ë°åË∂ÖÂπ≥Èù¢ÔºåÈÄô‰∫õË∂ÖÂπ≥Èù¢ÊòØÈÄèÈÅéÂ∞áÂÅèÂ∑ÆÈ†ÖÂèÉÊï∏ÂåñÁÇ∫ $t$ ÁöÑÂáΩÊï∏ËÄåÁî¢ÁîüÁöÑ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊ†πÊìöÂèóË©¶ËÄÖÂÖßÂΩ±ÂÉèÂ∞çÈñãÁôºÁÑ°Áõ£Áù£ÊêçÂ§±Ôºå‰ª•Á¢∫‰øùÈ¢®Èö™Ë©ïÂàÜÈö®ËëóÊôÇÈñìÂ¢ûÂä†Ôºå‰∏¶‰∏îÊú™‰æÜÁöÑËΩâÊèõÈ†êÊ∏¨Ëàá‰ΩøÁî®Êú™‰æÜÂ∞±Ë®∫ÂØ¶ÈöõÊéÉÊèèÁöÑ AMD ÈöéÊÆµÈ†êÊ∏¨‰∏ÄËá¥„ÄÇÊ≠§È°ûÊêçÂ§±ËÉΩÂ§†Â∞ç‰ΩøÁî®‰∏çÂêåÊéÉÊèèÂÑÄÂèñÂæóÁöÑÊñ∞Êú™Ê®ôÁ±§Ë≥áÊñôÈõÜÈÄ≤Ë°åË≥áÊñôÊúâÊïàÂæÆË™øË®ìÁ∑¥Ê®°Âûã„ÄÇÂ∞ç‰ΩøÁî®‰∏çÂêåÊéÉÊèèÂÑÄÂèñÂæóÁöÑÂÖ©ÂÄãÂ§ßÂûãË≥áÊñôÈõÜÈÄ≤Ë°åÂª£Ê≥õË©ï‰º∞ÔºåÂú® 6„ÄÅ12 Âíå 24 ÂÄãÊúàÁöÑÈ†êÊ∏¨ÂçÄÈñìÂÖßÔºåË≥áÊñôÈõÜ 1 ÁöÑÂπ≥Âùá AUROC ÁÇ∫ 0.82ÔºåË≥áÊñôÈõÜ 2 ÁöÑÂπ≥Âùá AUROC ÁÇ∫ 0.83„ÄÇ

##### **Factory Operators' Perspectives on Cognitive Assistants for Knowledge Sharing: Challenges, Risks, and Impact on Work**
2409.20192v1 by Samuel Kernan Freire, Tianhao He, Chaofan Wang, Evangelos Niforatos, Alessandro Bozzon

In the shift towards human-centered manufacturing, our two-year longitudinal
study investigates the real-world impact of deploying Cognitive Assistants
(CAs) in factories. The CAs were designed to facilitate knowledge sharing among
factory operators. Our investigation focused on smartphone-based voice
assistants and LLM-powered chatbots, examining their usability and utility in a
real-world factory setting. Based on the qualitative feedback we collected
during the deployments of CAs at the factories, we conducted a thematic
analysis to investigate the perceptions, challenges, and overall impact on
workflow and knowledge sharing.
  Our results indicate that while CAs have the potential to significantly
improve efficiency through knowledge sharing and quicker resolution of
production issues, they also introduce concerns around workplace surveillance,
the types of knowledge that can be shared, and shortcomings compared to
human-to-human knowledge sharing. Additionally, our findings stress the
importance of addressing privacy, knowledge contribution burdens, and tensions
between factory operators and their managers.

ÊëòË¶ÅÔºöÂú®‰ª•‰∫∫‰∏∫Êú¨ÁöÑÂà∂ÈÄ†‰∏öËΩ¨Âûã‰∏≠ÔºåÊàë‰ª¨ÁöÑ‰∏§Âπ¥Á∫µÂêëÁ†îÁ©∂Ë∞ÉÊü•‰∫ÜÂú®Â∑•ÂéÇÈÉ®ÁΩ≤ËÆ§Áü•Âä©ÁêÜ (CA) ÁöÑÂÆûÈôÖÂΩ±Âìç„ÄÇCA Ë¢´ËÆæËÆ°‰∏∫‰øÉËøõÂ∑•ÂéÇÊìç‰ΩúÂëò‰πãÈó¥ÁöÑÁü•ËØÜÂÖ±‰∫´„ÄÇÊàë‰ª¨ÁöÑË∞ÉÊü•ÈáçÁÇπÂÖ≥Ê≥®Âü∫‰∫éÊô∫ËÉΩÊâãÊú∫ÁöÑËØ≠Èü≥Âä©ÊâãÂíå LLM È©±Âä®ÁöÑËÅäÂ§©Êú∫Âô®‰∫∫ÔºåËÄÉÂØü‰∫ÜÂÆÉ‰ª¨Âú®ÁúüÂÆûÂ∑•ÂéÇÁéØÂ¢É‰∏≠ÁöÑÂèØÁî®ÊÄßÂíåÂÆûÁî®ÊÄß„ÄÇÂü∫‰∫éÊàë‰ª¨Âú®Â∑•ÂéÇÈÉ®ÁΩ≤ CA ÊúüÈó¥Êî∂ÈõÜÁöÑÂÆöÊÄßÂèçÈ¶àÔºåÊàë‰ª¨ËøõË°å‰∫Ü‰∏ªÈ¢òÂàÜÊûêÊù•Ë∞ÉÊü•ÂØπÂ∑•‰ΩúÊµÅÁ®ãÂíåÁü•ËØÜÂÖ±‰∫´ÁöÑÁúãÊ≥ï„ÄÅÊåëÊàòÂíåÊÄª‰ΩìÂΩ±Âìç„ÄÇ
Êàë‰ª¨ÁöÑÁªìÊûúË°®ÊòéÔºåËôΩÁÑ∂ CA ÊúâÂèØËÉΩÈÄöËøáÁü•ËØÜÂÖ±‰∫´ÂíåÊõ¥Âø´ÈÄüÂú∞Ëß£ÂÜ≥Áîü‰∫ßÈóÆÈ¢òÊù•ÊòæÁùÄÊèêÈ´òÊïàÁéáÔºå‰ΩÜÂÆÉ‰ª¨‰πüÂºïÂèë‰∫ÜÂØπÂ∑•‰ΩúÂú∫ÊâÄÁõëÊéß„ÄÅÂèØÂÖ±‰∫´ÁöÑÁü•ËØÜÁ±ªÂûã‰ª•Âèä‰∏é‰∫∫ÈôÖÁü•ËØÜÂÖ±‰∫´Áõ∏ÊØîÁöÑ‰∏çË∂≥ÁöÑÊãÖÂøß„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÁöÑÁ†îÁ©∂ÁªìÊûúÂº∫Ë∞É‰∫ÜËß£ÂÜ≥ÈöêÁßÅ„ÄÅÁü•ËØÜË¥°ÁåÆË¥üÊãÖ‰ª•ÂèäÂ∑•ÂéÇÊìç‰ΩúÂëò‰∏éÂÖ∂ÁªèÁêÜ‰πãÈó¥ÁöÑÁ¥ßÂº†ÂÖ≥Á≥ªÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **TaskComplexity: A Dataset for Task Complexity Classification with In-Context Learning, FLAN-T5 and GPT-4o Benchmarks**
2409.20189v1 by Areeg Fahad Rasheed, M. Zarkoosh, Safa F. Abbas, Sana Sabah Al-Azzawi

This paper addresses the challenge of classifying and assigning programming
tasks to experts, a process that typically requires significant effort, time,
and cost. To tackle this issue, a novel dataset containing a total of 4,112
programming tasks was created by extracting tasks from various websites. Web
scraping techniques were employed to collect this dataset of programming
problems systematically. Specific HTML tags were tracked to extract key
elements of each issue, including the title, problem description, input-output,
examples, problem class, and complexity score. Examples from the dataset are
provided in the appendix to illustrate the variety and complexity of tasks
included. The dataset's effectiveness has been evaluated and benchmarked using
two approaches; the first approach involved fine-tuning the FLAN-T5 small model
on the dataset, while the second approach used in-context learning (ICL) with
the GPT-4o mini. The performance was assessed using standard metrics: accuracy,
recall, precision, and F1-score. The results indicated that in-context learning
with GPT-4o-mini outperformed the FLAN-T5 model.

ÊëòË¶ÅÔºöÊú¨Ë´ñÊñáÊé¢Ë®é‰∫ÜÂ∞çÁ®ãÂºèË®≠Ë®à‰ªªÂãôÈÄ≤Ë°åÂàÜÈ°ûÂíåÊåáÊ¥æÁµ¶Â∞àÂÆ∂ÁöÑÊåëÊà∞ÔºåÈÄôÊòØ‰∏ÄÂÄãÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÁ≤æÂäõ„ÄÅÊôÇÈñìÂíåÊàêÊú¨ÁöÑÈÅéÁ®ã„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÂåÖÂê´Á∏ΩÂÖ± 4,112 ÂÄãÁ®ãÂºèË®≠Ë®à‰ªªÂãôÁöÑÊñ∞Á©éË≥áÊñôÈõÜÔºåÊñπÊ≥ïÊòØÂæûÂêÑÁ®ÆÁ∂≤Á´ô‰∏≠Êì∑Âèñ‰ªªÂãô„ÄÇ‰ΩøÁî®Á∂≤È†ÅÊì∑ÂèñÊäÄË°ìÁ≥ªÁµ±Âú∞Êî∂ÈõÜÈÄôÂÄãÁ®ãÂºèË®≠Ë®àÂïèÈ°åË≥áÊñôÈõÜ„ÄÇËøΩËπ§ÁâπÂÆöÁöÑ HTML Ê®ôÁ±§Ôºå‰ª•Êì∑ÂèñÊØèÂÄãÂïèÈ°åÁöÑÈóúÈçµÂÖÉÁ¥†ÔºåÂåÖÊã¨Ê®ôÈ°å„ÄÅÂïèÈ°åË™™Êòé„ÄÅËº∏ÂÖ•Ëº∏Âá∫„ÄÅÁØÑ‰æã„ÄÅÂïèÈ°åÈ°ûÂà•ÂíåË§áÈõúÂ∫¶ÂàÜÊï∏„ÄÇË≥áÊñôÈõÜ‰∏≠ÁöÑÁØÑ‰æãÂú®ÈôÑÈåÑ‰∏≠Êèê‰æõÔºå‰ª•Ë™™ÊòéÊâÄÂåÖÂê´‰ªªÂãôÁöÑÂ§öÊ®£ÊÄßÂíåË§áÈõúÊÄß„ÄÇË≥áÊñôÈõÜÁöÑÊúâÊïàÊÄßÂ∑≤‰ΩøÁî®ÂÖ©Á®ÆÊñπÊ≥ïÈÄ≤Ë°åË©ï‰º∞ÂíåÂü∫Ê∫ñÊ∏¨Ë©¶ÔºõÁ¨¨‰∏ÄÁ®ÆÊñπÊ≥ïÊ∂âÂèäÂú®Ë≥áÊñôÈõÜ‰∏äÂæÆË™ø FLAN-T5 Â∞èÂûãÊ®°ÂûãÔºåËÄåÁ¨¨‰∫åÁ®ÆÊñπÊ≥ï‰ΩøÁî® GPT-4o mini ÁöÑÊÉÖÂ¢ÉÂÖßÂ≠∏Áøí (ICL)„ÄÇ‰ΩøÁî®Ê®ôÊ∫ñÊåáÊ®ôË©ï‰º∞ÊïàËÉΩÔºöÊ∫ñÁ¢∫Â∫¶„ÄÅÂè¨ÂõûÁéá„ÄÅÁ≤æÁ¢∫Â∫¶Âíå F1 ÂàÜÊï∏„ÄÇÁµêÊûúË°®ÊòéÔºå‰ΩøÁî® GPT-4o-mini ÁöÑÊÉÖÂ¢ÉÂÖßÂ≠∏ÁøíÂÑ™Êñº FLAN-T5 Ê®°Âûã„ÄÇ

##### **Choosing DAG Models Using Markov and Minimal Edge Count in the Absence of Ground Truth**
2409.20187v1 by Joseph D. Ramsey, Bryan Andrews, Peter Spirtes

We give a novel nonparametric pointwise consistent statistical test (the
Markov Checker) of the Markov condition for directed acyclic graph (DAG) or
completed partially directed acyclic graph (CPDAG) models given a dataset. We
also introduce the Cross-Algorithm Frugality Search (CAFS) for rejecting DAG
models that either do not pass the Markov Checker test or that are not edge
minimal. Edge minimality has been used previously by Raskutti and Uhler as a
nonparametric simplicity criterion, though CAFS readily generalizes to other
simplicity conditions. Reference to the ground truth is not necessary for CAFS,
so it is useful for finding causal structure learning algorithms and tuning
parameter settings that output causal models that are approximately true from a
given data set. We provide a software tool for this analysis that is suitable
for even quite large or dense models, provided a suitably fast pointwise
consistent test of conditional independence is available. In addition, we show
in simulation that the CAFS procedure can pick approximately correct models
without knowing the ground truth.

ÊëòË¶ÅÔºöÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÈùûÂèÉÊï∏ÈªûÊÖã‰∏ÄËá¥ÊÄßÁµ±Ë®àÊ™¢ÂÆöÔºàÈ¶¨ÂèØÂ§´Ê™¢È©óÂô®ÔºâÔºåÁî®ÊñºÊúâÂêëÈùûÂæ™Áí∞ÂúñÔºàDAGÔºâÊàñÂ∑≤ÂÆåÊàêÁöÑÈÉ®ÂàÜÊúâÂêëÈùûÂæ™Áí∞ÂúñÔºàCPDAGÔºâÊ®°ÂûãÁöÑÈ¶¨ÂèØÂ§´Ê¢ù‰ª∂ÔºåÁµ¶ÂÆö‰∏ÄÂÄãË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü‰∫§ÂèâÊºîÁÆóÊ≥ïÁØÄÂÑâÊêúÂ∞ãÔºàCAFSÔºâÔºåÁî®ÊñºÊãíÁµïÊú™ÈÄöÈÅéÈ¶¨ÂèØÂ§´Ê™¢È©óÂô®Ê™¢ÂÆöÊàñÈÇäÁ∑£ÈùûÊúÄÂ∞èÁöÑ DAG Ê®°Âûã„ÄÇÈÇäÁ∑£ÊúÄÂ∞ëÊÄßÂÖàÂâçÂ∑≤Ë¢´ Raskutti Âíå Uhler Áî®‰ΩúÈùûÂèÉÊï∏Á∞°ÊΩîÊÄßÊ∫ñÂâáÔºåÂÑòÁÆ° CAFS ÂæàÂÆπÊòìÊ¶ÇÊã¨Âà∞ÂÖ∂‰ªñÁ∞°ÊΩîÊÄßÊ¢ù‰ª∂„ÄÇCAFS ‰∏çÈúÄË¶ÅÂèÉËÄÉÁúüÂØ¶ÊÉÖÊ≥ÅÔºåÂõ†Ê≠§Â∞çÊñºÂ∞ãÊâæÂõ†ÊûúÁµêÊßãÂ≠∏ÁøíÊºîÁÆóÊ≥ïÂíåË™øÊï¥ÂèÉÊï∏Ë®≠ÂÆöÂæàÊúâÁî®ÔºåÈÄô‰∫õÂèÉÊï∏Ë®≠ÂÆöÊúÉÂæûÁµ¶ÂÆöÁöÑË≥áÊñôÈõÜËº∏Âá∫Ëøë‰ººÁúüÂØ¶ÁöÑÂõ†ÊûúÊ®°Âûã„ÄÇÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãÈÅ©Áî®ÊñºÁõ∏Áï∂Â§ßÊàñÂØÜÈõÜÊ®°ÂûãÁöÑËªüÈ´îÂ∑•ÂÖ∑ÔºåÂè™Ë¶ÅÊúâÈÅ©Áï∂ÁöÑÊ¢ù‰ª∂Áç®Á´ãÈªûÊÖã‰∏ÄËá¥ÊÄßÊ™¢ÂÆöÂèØÁî®Âç≥ÂèØ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂú®Ê®°Êì¨‰∏≠È°ØÁ§∫ÔºåCAFS Á®ãÂ∫èÂèØ‰ª•Âú®‰∏çÁü•ÈÅìÁúüÂØ¶ÊÉÖÊ≥Å‰∏ãÊåëÈÅ∏Ëøë‰ººÊ≠£Á¢∫ÁöÑÊ®°Âûã„ÄÇ

##### **Reference Trustable Decoding: A Training-Free Augmentation Paradigm for Large Language Models**
2409.20181v1 by Luohe Shi, Yao Yao, Zuchao Li, Lefei Zhang, Hai Zhao

Large language models (LLMs) have rapidly advanced and demonstrated
impressive capabilities. In-Context Learning (ICL) and Parameter-Efficient
Fine-Tuning (PEFT) are currently two mainstream methods for augmenting LLMs to
downstream tasks. ICL typically constructs a few-shot learning scenario, either
manually or by setting up a Retrieval-Augmented Generation (RAG) system,
helping models quickly grasp domain knowledge or question-answering patterns
without changing model parameters. However, this approach involves trade-offs,
such as slower inference speed and increased space occupancy. PEFT assists the
model in adapting to tasks through minimal parameter modifications, but the
training process still demands high hardware requirements, even with a small
number of parameters involved. To address these challenges, we propose
Reference Trustable Decoding (RTD), a paradigm that allows models to quickly
adapt to new tasks without fine-tuning, maintaining low inference costs. RTD
constructs a reference datastore from the provided training examples and
optimizes the LLM's final vocabulary distribution by flexibly selecting
suitable references based on the input, resulting in more trustable responses
and enabling the model to adapt to downstream tasks at a low cost. Experimental
evaluations on various LLMs using different benchmarks demonstrate that RTD
establishes a new paradigm for augmenting models to downstream tasks.
Furthermore, our method exhibits strong orthogonality with traditional methods,
allowing for concurrent usage.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âø´ÈÄüÈÄ≤Ê≠•‰∏¶Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËÉΩÂäõ„ÄÇÊÉÖÂ¢ÉÂ≠∏Áøí (ICL) ÂíåÂèÉÊï∏È´òÊïàÂæÆË™ø (PEFT) ÁõÆÂâçÊòØÊì¥ÂÖÖ LLM ‰ª•Âü∑Ë°å‰∏ãÊ∏∏‰ªªÂãôÁöÑÂÖ©Á®Æ‰∏ªÊµÅÊñπÊ≥ï„ÄÇICL ÈÄöÂ∏∏ÊúÉÂª∫Êßã‰∏ÄÂÄãÂ∞èÊ®£Êú¨Â≠∏ÁøíÊÉÖÂ¢ÉÔºåÂèØ‰ª•ÊâãÂãïÊàñÈÄèÈÅéË®≠ÂÆöÊ™¢Á¥¢Êì¥ÂÖÖÁîüÊàê (RAG) Á≥ªÁµ±‰æÜÂü∑Ë°åÔºåÂçîÂä©Ê®°ÂûãÂø´ÈÄüÊéåÊè°È†òÂüüÁü•Ë≠òÊàñÂïèÁ≠îÊ®°ÂºèÔºåËÄåÁÑ°ÈúÄËÆäÊõ¥Ê®°ÂûãÂèÉÊï∏„ÄÇÁÑ∂ËÄåÔºåÈÄôÁ®ÆÊñπÊ≥ïÊúÉÊ∂âÂèäÂèñÊç®Ôºå‰æãÂ¶ÇÊé®Ë´ñÈÄüÂ∫¶ËÆäÊÖ¢ÂíåÁ©∫Èñì‰ΩîÁî®ÈáèÂ¢ûÂä†„ÄÇPEFT ÂçîÂä©Ê®°ÂûãÈÄèÈÅéÊúÄÂ∞ëÁöÑÂèÉÊï∏‰øÆÊîπ‰æÜÈÅ©Êáâ‰ªªÂãôÔºå‰ΩÜË®ìÁ∑¥ÈÅéÁ®ã‰ªçÈúÄË¶ÅÂæàÈ´òÁöÑÁ°¨È´îÈúÄÊ±ÇÔºåÂç≥‰ΩøÊ∂âÂèäÁöÑÂèÉÊï∏Êï∏ÈáèÂæàÂ∞ë„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫ÂèÉËÄÉÂèØ‰ø°Ëß£Á¢º (RTD)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂÖ∏ÁØÑÔºåËÆìÊ®°ÂûãËÉΩÂ§†Âø´ÈÄüÈÅ©ÊáâÊñ∞‰ªªÂãôÔºåËÄåÁÑ°ÈúÄÂæÆË™øÔºå‰∏¶Á∂≠ÊåÅ‰ΩéÊé®Ë´ñÊàêÊú¨„ÄÇRTD ÂæûÊèê‰æõÁöÑË®ìÁ∑¥ÁØÑ‰æãÂª∫ÊßãÂèÉËÄÉË≥áÊñôÂÑ≤Â≠òÂ∫´Ôºå‰∏¶ÈÄèÈÅéÊ†πÊìöËº∏ÂÖ•ÈùàÊ¥ªÂú∞ÈÅ∏ÊìáÂêàÈÅ©ÁöÑÂèÉËÄÉ‰æÜÊúÄ‰Ω≥Âåñ LLM ÁöÑÊúÄÁµÇË©ûÂΩôÂàÜ‰ΩàÔºåÈÄ≤ËÄåÁî¢ÁîüÊõ¥ÂèØ‰ø°ÁöÑÂõûÊáâÔºå‰∏¶ËÆìÊ®°ÂûãËÉΩÂ§†‰ª•‰ΩéÊàêÊú¨ÈÅ©Êáâ‰∏ãÊ∏∏‰ªªÂãô„ÄÇ‰ΩøÁî®‰∏çÂêåÂü∫Ê∫ñÂ∞çÂêÑÁ®Æ LLM ÈÄ≤Ë°åÁöÑÂØ¶È©óË©ï‰º∞È°ØÁ§∫ÔºåRTD ÁÇ∫Êì¥ÂÖÖÊ®°Âûã‰ª•Âü∑Ë°å‰∏ãÊ∏∏‰ªªÂãôÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂÖ∏ÁØÑ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÂ±ïÁèæÂá∫ËàáÂÇ≥Áµ±ÊñπÊ≥ïÁöÑÂº∑Â§ßÊ≠£‰∫§ÊÄßÔºåÂÖÅË®±ÂêåÊôÇ‰ΩøÁî®„ÄÇ

##### **Modelando procesos cognitivos de la lectura natural con GPT-2**
2409.20174v1 by Bruno Bianchi, Alfredo Umfurer, Juan Esteban Kamienkowski

The advancement of the Natural Language Processing field has enabled the
development of language models with a great capacity for generating text. In
recent years, Neuroscience has been using these models to better understand
cognitive processes. In previous studies, we found that models like Ngrams and
LSTM networks can partially model Predictability when used as a co-variable to
explain readers' eye movements. In the present work, we further this line of
research by using GPT-2 based models. The results show that this architecture
achieves better outcomes than its predecessors.

ÊëòË¶ÅÔºöËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÈ†òÂüüÁöÑÈÄ≤Ê≠•‰ΩøÂæóÈñãÁôºÂá∫ÂÖ∑ÊúâÂ∑®Â§ßÊñáÊú¨ÁîüÊàêËÉΩÂäõÁöÑË™ûË®ÄÊ®°ÂûãÊàêÁÇ∫ÂèØËÉΩ„ÄÇËøëÂπ¥‰æÜÔºåÁ•ûÁ∂ìÁßëÂ≠∏‰∏ÄÁõ¥Âú®‰ΩøÁî®ÈÄô‰∫õÊ®°Âûã‰æÜÊõ¥Â•ΩÂú∞ÁêÜËß£Ë™çÁü•ÈÅéÁ®ã„ÄÇÂú®ÂÖàÂâçÁöÑÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÁôºÁèæ Ngrams Âíå LSTM Á∂≤Ë∑ØÁ≠âÊ®°ÂûãÂèØÁî®‰ΩúÂçîËÆäÊï∏‰æÜËß£ÈáãËÆÄËÄÖÁöÑÁúºÁêÉÈÅãÂãïÊôÇÔºåÂèØ‰ª•ÈÉ®ÂàÜÂú∞Ê®°Êì¨ÂèØÈ†êÊ∏¨ÊÄß„ÄÇÂú®ÁõÆÂâçÁöÑÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈÄöÈÅé‰ΩøÁî®Âü∫Êñº GPT-2 ÁöÑÊ®°ÂûãÈÄ≤‰∏ÄÊ≠•Êé®ÈÄ≤‰∫ÜÈÄôÊ¢ùÁ†îÁ©∂Ë∑ØÁ∑ö„ÄÇÁµêÊûúË°®ÊòéÔºåÈÄôÁ®ÆÊû∂ÊßãÊØîÂÖ∂ÂâçË∫´ÂèñÂæó‰∫ÜÊõ¥Â•ΩÁöÑÊàêÊûú„ÄÇ

##### **Using Large Multimodal Models to Extract Knowledge Components for Knowledge Tracing from Multimedia Question Information**
2409.20167v1 by Hyeongdon Moon, Richard Davis, Seyed Parsa Neshaei, Pierre Dillenbourg

Knowledge tracing models have enabled a range of intelligent tutoring systems
to provide feedback to students. However, existing methods for knowledge
tracing in learning sciences are predominantly reliant on statistical data and
instructor-defined knowledge components, making it challenging to integrate
AI-generated educational content with traditional established methods. We
propose a method for automatically extracting knowledge components from
educational content using instruction-tuned large multimodal models. We
validate this approach by comprehensively evaluating it against knowledge
tracing benchmarks in five domains. Our results indicate that the automatically
extracted knowledge components can effectively replace human-tagged labels,
offering a promising direction for enhancing intelligent tutoring systems in
limited-data scenarios, achieving more explainable assessments in educational
settings, and laying the groundwork for automated assessment.

ÊëòË¶ÅÔºöÁü•Ë≠òËøΩËπ§Ê®°ÂûãËÆì‰∏ÄÁ≥ªÂàóÊô∫ÊÖßÊïôÂ≠∏Á≥ªÁµ±ËÉΩÁÇ∫Â≠∏ÁîüÊèê‰æõÂõûÈ•ã„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÁü•Ë≠òËøΩËπ§ÊñπÊ≥ïÂú®Â≠∏ÁøíÁßëÂ≠∏‰∏≠‰∏ªË¶Å‰æùË≥¥Áµ±Ë®àË≥áÊñôÂíåÁî±ÊïôÂ∏´ÂÆöÁæ©ÁöÑÁü•Ë≠òÊàêÂàÜÔºåÈÄô‰ΩøÂæóÂ∞á AI ÁîüÊàêÁöÑÊïôËÇ≤ÂÖßÂÆπËàáÂÇ≥Áµ±Êó¢ÂÆöÊñπÊ≥ïÊï¥ÂêàËµ∑‰æÜÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºå‰ΩøÁî®ÈáùÂ∞çÊïôÂ≠∏Ë™øÊï¥ÈÅéÁöÑÂ§ßÂ§öÊ®°ÊÖãÊ®°ÂûãÂæûÊïôËÇ≤ÂÖßÂÆπ‰∏≠Ëá™ÂãïÊèêÂèñÁü•Ë≠òÊàêÂàÜ„ÄÇÊàëÂÄëÈÄèÈÅéÂú®‰∫îÂÄãÈ†òÂüüÁöÑÁü•Ë≠òËøΩËπ§Âü∫Ê∫ñÂ∞çÂÖ∂ÈÄ≤Ë°åÂÖ®Èù¢Ë©ï‰º∞ÔºåÈ©óË≠â‰∫ÜÈÄôÁ®ÆÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåËá™ÂãïÊèêÂèñÁöÑÁü•Ë≠òÊàêÂàÜÂèØ‰ª•ÊúâÊïàÂèñ‰ª£‰∫∫Â∑•Ê®ôË®òÁöÑÊ®ôÁ±§ÔºåÁÇ∫Âú®Ë≥áÊñôÊúâÈôêÁöÑÊÉÖÊ≥Å‰∏ãÂ¢ûÂº∑Êô∫ÊÖßÊïôÂ≠∏Á≥ªÁµ±„ÄÅÂú®ÊïôËÇ≤Áí∞Â¢É‰∏≠ÂØ¶ÁèæÊõ¥ÂÖ∑Ë™™ÊòéÊÄßÁöÑË©ïÈáèÔºå‰ª•ÂèäÁÇ∫Ëá™ÂãïÂåñË©ïÈáèÂ•†ÂÆöÂü∫Á§éÊèê‰æõ‰∫ÜÊúâÂ∏åÊúõÁöÑÊñπÂêë„ÄÇ

##### **How Entangled is Factuality and Deception in German?**
2409.20165v1 by Aswathy Velutharambath, Amelie W√ºhrl, Roman Klinger

The statement "The earth is flat" is factually inaccurate, but if someone
truly believes and argues in its favor, it is not deceptive. Research on
deception detection and fact checking often conflates factual accuracy with the
truthfulness of statements. This assumption makes it difficult to (a) study
subtle distinctions and interactions between the two and (b) gauge their
effects on downstream tasks. The belief-based deception framework disentangles
these properties by defining texts as deceptive when there is a mismatch
between what people say and what they truly believe. In this study, we assess
if presumed patterns of deception generalize to German language texts. We test
the effectiveness of computational models in detecting deception using an
established corpus of belief-based argumentation. Finally, we gauge the impact
of deception on the downstream task of fact checking and explore if this
property confounds verification models. Surprisingly, our analysis finds no
correlation with established cues of deception. Previous work claimed that
computational models can outperform humans in deception detection accuracy,
however, our experiments show that both traditional and state-of-the-art models
struggle with the task, performing no better than random guessing. For fact
checking, we find that Natural Language Inference-based verification performs
worse on non-factual and deceptive content, while prompting Large Language
Models for the same task is less sensitive to these properties.

ÊëòË¶ÅÔºö„ÄåÂú∞ÁêÉÊòØÂπ≥ÁöÑ„ÄçÈÄôÂè•Ë©±Âú®‰∫ãÂØ¶‰∏äÊòØ‰∏çÊ≠£Á¢∫ÁöÑÔºå‰ΩÜÂ¶ÇÊûúÊúâ‰∫∫ÁúüÁöÑÁõ∏‰ø°‰∏¶‰∏ªÂºµÂÆÉÁöÑÊ≠£Á¢∫ÊÄßÔºåÈÄô‰∏¶ÈùûÊ¨∫È®ô„ÄÇÈóúÊñºÊ¨∫È®ôÂÅµÊ∏¨Âíå‰∫ãÂØ¶Êü•Ê†∏ÁöÑÁ†îÁ©∂ÔºåÁ∂ìÂ∏∏Â∞á‰∫ãÂØ¶Ê≠£Á¢∫ÊÄßËàáÈô≥Ëø∞ÁöÑÁúüÂØ¶ÊÄßÊ∑∑ÁÇ∫‰∏ÄË´á„ÄÇÈÄôÂÄãÂÅáË®≠‰ΩøÂæóÔºàaÔºâÈõ£‰ª•Á†îÁ©∂ÂÖ©ËÄÖ‰πãÈñìÁöÑÁ¥∞ÂæÆÂ∑ÆÁï∞Âíå‰∫§‰∫í‰ΩúÁî®Ôºå‰ª•ÂèäÔºàbÔºâË°°ÈáèÂÆÉÂÄëÂ∞ç‰∏ãÊ∏∏‰ªªÂãôÁöÑÂΩ±Èüø„ÄÇÂü∫Êñº‰ø°ÂøµÁöÑÊ¨∫È®ôÊ°ÜÊû∂ÔºåÈÄèÈÅéÂÆöÁæ©Âú®‰∫∫ÂÄëÊâÄË™™ÁöÑË©±Ëàá‰ªñÂÄëÁúüÊ≠£Áõ∏‰ø°ÁöÑ‰∫ãÊÉÖ‰πãÈñìÂ≠òÂú®‰∏çÂåπÈÖçÊôÇÔºåÂ∞áÈÄô‰∫õÂ±¨ÊÄßÂçÄÂàÜÈñã‰æÜ„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëË©ï‰º∞‰∫ÜÊ¨∫È®ôÁöÑÂÅáÂÆöÊ®°ÂºèÊòØÂê¶ËÉΩÊé®Âª£Âà∞Âæ∑Ë™ûÊñáÊú¨„ÄÇÊàëÂÄë‰ΩøÁî®Êó¢ÂÆöÁöÑÂü∫Êñº‰ø°ÂøµÁöÑË´ñË≠âË™ûÊñôÂ∫´ÔºåÊ∏¨Ë©¶‰∫ÜË®àÁÆóÊ®°ÂûãÂú®ÂÅµÊ∏¨Ê¨∫È®ôÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÊúÄÂæåÔºåÊàëÂÄëË°°Èáè‰∫ÜÊ¨∫È®ôÂ∞ç‰∫ãÂØ¶Êü•Ê†∏‰∏ãÊ∏∏‰ªªÂãôÁöÑÂΩ±ÈüøÔºå‰∏¶Êé¢Ë®éÈÄôÂÄãÂ±¨ÊÄßÊòØÂê¶ÊúÉÊ∑∑Ê∑ÜÈ©óË≠âÊ®°Âûã„ÄÇ‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÊàëÂÄëÁöÑÂàÜÊûêÊ≤íÊúâÁôºÁèæËàáÊó¢ÂÆöÁöÑÊ¨∫È®ôÁ∑öÁ¥¢Áõ∏Èóú„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂ËÅ≤Á®±Ë®àÁÆóÊ®°ÂûãÂú®Ê¨∫È®ôÂÅµÊ∏¨ÁöÑÊ∫ñÁ¢∫ÊÄß‰∏äÂèØ‰ª•ÂÑ™Êñº‰∫∫È°ûÔºåÁÑ∂ËÄåÔºåÊàëÂÄëÁöÑÂØ¶È©óÈ°ØÁ§∫ÂÇ≥Áµ±ÂíåÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÂú®ÈÄôÂÄã‰ªªÂãô‰∏äÈÉΩË°®Áèæ‰∏ç‰Ω≥ÔºåË°®Áèæ‰∏çÊØîÈö®Ê©üÁåúÊ∏¨Â•Ω„ÄÇÂ∞çÊñº‰∫ãÂØ¶Êü•Ê†∏ÔºåÊàëÂÄëÁôºÁèæÂü∫ÊñºËá™ÁÑ∂Ë™ûË®ÄÊé®Ë´ñÁöÑÈ©óË≠âÂú®Èùû‰∫ãÂØ¶ÂíåÊ¨∫È®ôÊÄßÂÖßÂÆπ‰∏äË°®ÁèæËºÉÂ∑ÆÔºåËÄåÊèêÁ§∫Â§ßÂûãË™ûË®ÄÊ®°ÂûãÂü∑Ë°åÁõ∏ÂêåÁöÑ‰ªªÂãôÔºåÂ∞çÈÄô‰∫õÂ±¨ÊÄßËºÉ‰∏çÊïèÊÑü„ÄÇ

##### **MemSim: A Bayesian Simulator for Evaluating Memory of LLM-based Personal Assistants**
2409.20163v1 by Zeyu Zhang, Quanyu Dai, Luyu Chen, Zeren Jiang, Rui Li, Jieming Zhu, Xu Chen, Yi Xie, Zhenhua Dong, Ji-Rong Wen

LLM-based agents have been widely applied as personal assistants, capable of
memorizing information from user messages and responding to personal queries.
However, there still lacks an objective and automatic evaluation on their
memory capability, largely due to the challenges in constructing reliable
questions and answers (QAs) according to user messages. In this paper, we
propose MemSim, a Bayesian simulator designed to automatically construct
reliable QAs from generated user messages, simultaneously keeping their
diversity and scalability. Specifically, we introduce the Bayesian Relation
Network (BRNet) and a causal generation mechanism to mitigate the impact of LLM
hallucinations on factual information, facilitating the automatic creation of
an evaluation dataset. Based on MemSim, we generate a dataset in the daily-life
scenario, named MemDaily, and conduct extensive experiments to assess the
effectiveness of our approach. We also provide a benchmark for evaluating
different memory mechanisms in LLM-based agents with the MemDaily dataset. To
benefit the research community, we have released our project at
https://github.com/nuster1128/MemSim.

ÊëòË¶ÅÔºöÂü∫Êñº LLM ÁöÑ‰ª£ÁêÜÂ∑≤Âª£Ê≥õÁî®‰ΩúÂÄã‰∫∫Âä©ÁêÜÔºåËÉΩÂ§†Ë®ò‰Ωè‰ΩøÁî®ËÄÖË®äÊÅØ‰∏≠ÁöÑË≥áË®ä‰∏¶ÂõûÊáâÂÄã‰∫∫Êü•Ë©¢„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÂú®Ê†πÊìö‰ΩøÁî®ËÄÖË®äÊÅØÂª∫ÊßãÂèØÈù†ÁöÑÂïèÈ°åÂíåËß£Á≠î (QA) ÊôÇÈù¢Ëá®ÊåëÊà∞ÔºåÂõ†Ê≠§‰ªçÁº∫‰πèÂ∞çÂÖ∂Ë®òÊÜ∂ËÉΩÂäõÁöÑÂÆ¢ËßÄ‰∏îËá™ÂãïÂåñÁöÑË©ï‰º∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ MemSimÔºåÈÄôÊòØ‰∏ÄÂÄãË≤ùÊ∞èÊ®°Êì¨Âô®ÔºåÊó®Âú®ÂæûÁî¢ÁîüÁöÑ‰ΩøÁî®ËÄÖË®äÊÅØ‰∏≠Ëá™ÂãïÂª∫ÊßãÂèØÈù†ÁöÑ QAÔºåÂêåÊôÇ‰øùÊåÅÂÖ∂Â§öÊ®£ÊÄßÂíåÂèØÊì¥ÂÖÖÊÄß„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜË≤ùÊ∞èÈóú‰øÇÁ∂≤Ë∑Ø (BRNet) ÂíåÂõ†ÊûúÁîüÊàêÊ©üÂà∂Ôºå‰ª•Ê∏õËºï LLM ÂπªË¶∫Â∞ç‰∫ãÂØ¶Ë≥áË®äÁöÑÂΩ±ÈüøÔºå‰øÉÈÄ≤Ëá™ÂãïÂª∫Á´ãË©ï‰º∞Ë≥áÊñôÈõÜ„ÄÇÂü∫Êñº MemSimÔºåÊàëÂÄëÂú®Êó•Â∏∏ÁîüÊ¥ªÂ†¥ÊôØ‰∏≠Áî¢Áîü‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ MemDaily ÁöÑË≥áÊñôÈõÜÔºå‰∏¶ÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©ó‰ª•Ë©ï‰º∞ÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÈÇÑÊèê‰æõ‰∫Ü‰ΩøÁî® MemDaily Ë≥áÊñôÈõÜË©ï‰º∞ LLM Âü∫Á§é‰ª£ÁêÜ‰∏≠‰∏çÂêåË®òÊÜ∂Ê©üÂà∂ÁöÑÂü∫Ê∫ñ„ÄÇÁÇ∫‰∫ÜÈÄ†Á¶èÁ†îÁ©∂Á§æÁæ§ÔºåÊàëÂÄëÂ∑≤Âú® https://github.com/nuster1128/MemSim ‰∏äÁôºÂ∏É‰∫ÜÊàëÂÄëÁöÑÂ∞àÊ°à„ÄÇ

##### **1 Trillion Token (1TT) Platform: A Novel Framework for Efficient Data Sharing and Compensation in Large Language Models**
2409.20149v1 by Chanjun Park, Hyunsoo Ha, Jihoo Kim, Yungi Kim, Dahyun Kim, Sukyung Lee, Seonghoon Yang

In this paper, we propose the 1 Trillion Token Platform (1TT Platform), a
novel framework designed to facilitate efficient data sharing with a
transparent and equitable profit-sharing mechanism. The platform fosters
collaboration between data contributors, who provide otherwise non-disclosed
datasets, and a data consumer, who utilizes these datasets to enhance their own
services. Data contributors are compensated in monetary terms, receiving a
share of the revenue generated by the services of the data consumer. The data
consumer is committed to sharing a portion of the revenue with contributors,
according to predefined profit-sharing arrangements. By incorporating a
transparent profit-sharing paradigm to incentivize large-scale data sharing,
the 1TT Platform creates a collaborative environment to drive the advancement
of NLP and LLM technologies.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü 1 ÂÖÜÂÄã‰ª£Âπ£Âπ≥Âè∞ (1TT Âπ≥Âè∞)ÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ°ÜÊû∂ÔºåÊó®Âú®ÈÄèÈÅéÈÄèÊòé‰∏îÂÖ¨Âπ≥ÁöÑÂà©ÊΩ§ÂàÜ‰∫´Ê©üÂà∂‰øÉÈÄ≤Ë≥áÊñôÂÖ±‰∫´ÊïàÁéá„ÄÇË©≤Âπ≥Âè∞‰øÉÈÄ≤Ë≥áÊñôË≤¢ÁçªËÄÖÔºàÊèê‰æõÂéüÊú¨‰∏çÊúÉÂÖ¨ÈñãÁöÑË≥áÊñôÈõÜÔºâËàáË≥áÊñô‰ΩøÁî®ËÄÖÔºàÂà©Áî®ÈÄô‰∫õË≥áÊñôÈõÜ‰æÜÊèêÂçáÂÖ∂Ëá™Ë∫´ÊúçÂãôÔºâ‰πãÈñìÁöÑÂêà‰Ωú„ÄÇË≥áÊñôË≤¢ÁçªËÄÖÊúÉÁç≤ÂæóÈáëÈå¢Ë£úÂÑüÔºå‰∏¶ÂæûË≥áÊñô‰ΩøÁî®ËÄÖÊúçÂãôÁî¢ÁîüÁöÑÊî∂Áõä‰∏≠Áç≤Âæó‰∏ÄÈÉ®ÂàÜÂà©ÊΩ§„ÄÇË≥áÊñô‰ΩøÁî®ËÄÖÊâøË´æÊ†πÊìöÈ†êÂÖàÂÆöÁæ©ÁöÑÂà©ÊΩ§ÂàÜ‰∫´ÂÆâÊéíÔºåËàáË≤¢ÁçªËÄÖÂàÜ‰∫´ÈÉ®ÂàÜÊî∂Áõä„ÄÇÈÄèÈÅéÁ¥çÂÖ•ÈÄèÊòéÁöÑÂà©ÊΩ§ÂàÜ‰∫´Ê®°Âºè‰ª•ÊøÄÂãµÂ§ßË¶èÊ®°Ë≥áÊñôÂÖ±‰∫´Ôºå1TT Âπ≥Âè∞ÂâµÈÄ†‰∫Ü‰∏ÄÂÄãÂçî‰ΩúÁí∞Â¢ÉÔºå‰ª•Êé®Âãï NLP Âíå LLM ÊäÄË°ìÁöÑÈÄ≤Ê≠•„ÄÇ

##### **Classification of Radiological Text in Small and Imbalanced Datasets in a Non-English Language**
2409.20147v1 by Vincent Beliveau, Helene Kaas, Martin Prener, Claes N. Ladefoged, Desmond Elliott, Gitte M. Knudsen, Lars H. Pinborg, Melanie Ganz

Natural language processing (NLP) in the medical domain can underperform in
real-world applications involving small datasets in a non-English language with
few labeled samples and imbalanced classes. There is yet no consensus on how to
approach this problem. We evaluated a set of NLP models including BERT-like
transformers, few-shot learning with sentence transformers (SetFit), and
prompted large language models (LLM), using three datasets of radiology reports
on magnetic resonance images of epilepsy patients in Danish, a low-resource
language. Our results indicate that BERT-like models pretrained in the target
domain of radiology reports currently offer the optimal performances for this
scenario. Notably, the SetFit and LLM models underperformed compared to
BERT-like models, with LLM performing the worst. Importantly, none of the
models investigated was sufficiently accurate to allow for text classification
without any supervision. However, they show potential for data filtering, which
could reduce the amount of manual labeling required.

ÊëòË¶ÅÔºöËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) Âú®ÈÜ´ÁôÇÈ†òÂüü‰∏≠ÔºåÂú®Ê∂âÂèäÈùûËã±Ë™ûË™ûË®Ä‰∏≠Â∞èÂûãË≥áÊñôÈõÜ„ÄÅÊ®ôË®òÊ®£Êú¨Â∞ëÂíåÈ°ûÂà•‰∏çÂπ≥Ë°°ÁöÑÂØ¶ÈöõÊáâÁî®‰∏≠Ë°®Áèæ‰∏ç‰Ω≥„ÄÇÂ∞çÊñºÂ¶Ç‰ΩïËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÁõÆÂâçÂ∞öÊú™ÈÅîÊàêÂÖ±Ë≠ò„ÄÇÊàëÂÄë‰ΩøÁî®‰∏âÁµÑ‰∏πÈ∫•Ë™ûÁô≤ÁôáÊÇ£ËÄÖÁ£ÅÂÖ±ÊåØÂΩ±ÂÉèÁöÑÊîæÂ∞ÑÂ†±ÂëäË≥áÊñôÈõÜÔºåË©ï‰º∞‰∫Ü‰∏ÄÁµÑ NLP Ê®°ÂûãÔºåÂåÖÊã¨È°û BERT ËΩâÊèõÂô®„ÄÅ‰ΩøÁî®Âè•Â≠êËΩâÊèõÂô® (SetFit) ÁöÑÂ∞ëÊ®£Êú¨Â≠∏ÁøíÔºå‰ª•ÂèäÊèêÁ§∫ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÁõÆÂâçÂú®ÊîæÂ∞ÑÂ†±ÂëäÁõÆÊ®ôÈ†òÂüü‰∏≠È†êË®ìÁ∑¥ÁöÑÈ°û BERT Ê®°ÂûãÁÇ∫Ê≠§ÊÉÖÂ¢ÉÊèê‰æõÊúÄ‰Ω≥ÊïàËÉΩ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåËàáÈ°û BERT Ê®°ÂûãÁõ∏ÊØîÔºåSetFit Âíå LLM Ê®°ÂûãË°®Áèæ‰∏ç‰Ω≥ÔºåËÄå LLM Ë°®ÁèæÊúÄÂ∑Æ„ÄÇÈáçË¶ÅÁöÑÊòØÔºåÊâÄÁ†îÁ©∂ÁöÑÊ®°Âûã‰∏≠Ê≤íÊúâ‰∏ÄÂÄãË∂≥Â§†Ê∫ñÁ¢∫ÔºåÂèØ‰ª•Âú®Ê≤íÊúâ‰ªª‰ΩïÁõ£Áù£ÁöÑÊÉÖÊ≥Å‰∏ãÈÄ≤Ë°åÊñáÂ≠óÂàÜÈ°û„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÈ°ØÁ§∫Âá∫Ë≥áÊñôÈÅéÊøæÁöÑÊΩõÂäõÔºåÈÄôÂèØ‰ª•Ê∏õÂ∞ëÊâÄÈúÄÁöÑÊâãÂãïÊ®ôË®òÈáè„ÄÇ

##### **Federated Instruction Tuning of LLMs with Domain Coverage Augmentation**
2409.20135v2 by Zezhou Wang, Yaxin Du, Zhuzhong Qian, Siheng Chen

Federated Domain-specific Instruction Tuning (FedDIT) utilizes limited
cross-client private data alongside server-side public data for instruction
augmentation, ultimately enhancing model performance within specific domains.
While the factors affecting FedDIT remain unclear and existing instruction
augmentation methods mainly focus on the centralized setting without
considering the distributed environment. Our experiments reveal that the
cross-client domain coverage, rather than data heterogeneity, drives model
performance in FedDIT. In response, we propose FedDCA, which optimizes domain
coverage through greedy client center selection and retrieval-based
augmentation. To alleviate client-side computational burdens, FedDCA$^*$ uses
heterogeneous encoders with server-side feature alignment. Extensive
experiments across four distinct domains (code, medical, financial, and
mathematical) substantiate the effectiveness of both methods. Additionally, we
investigate privacy preservation against memory extraction attacks utilizing
varying amounts of public data. Results show no significant correlation between
the volume of public data and the privacy-preserving capability. However, as
the fine-tuning round increases, the risk of privacy leakage reduces or
converges.

ÊëòË¶ÅÔºöËÅØÈÇ¶È†òÂüüÁâπÂÆöÊåá‰ª§Ë™øÊï¥ (FedDIT) Âà©Áî®ÊúâÈôêÁöÑË∑®Áî®Êà∂Á´ØÁßÅ‰∫∫Êï∏Êìö‰ª•Âèä‰º∫ÊúçÂô®Á´ØÁöÑÂÖ¨ÈñãÊï∏ÊìöÈÄ≤Ë°åÊåá‰ª§Êì¥ÂÖÖÔºåÊúÄÁµÇÂ¢ûÂº∑ÁâπÂÆöÈ†òÂüüÂÖßÁöÑÊ®°ÂûãÊïàËÉΩ„ÄÇÈõñÁÑ∂ÂΩ±Èüø FedDIT ÁöÑÂõ†Á¥†‰ªç‰∏çÊòéÁ¢∫ÔºåÁèæÊúâÁöÑÊåá‰ª§Êì¥ÂÖÖÊñπÊ≥ï‰∏ªË¶ÅËëóÈáçÊñºÈõÜ‰∏≠ÂºèË®≠ÂÆöÔºåËÄåÊú™ËÄÉÊÖÆÂàÜÊï£ÂºèÁí∞Â¢É„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåË∑®Áî®Êà∂Á´ØÈ†òÂüüÊ∂µËìãÁØÑÂúçÔºåËÄåÈùûÊï∏ÊìöÁï∞Ë≥™ÊÄßÔºåÈ©ÖÂãï‰∫Ü FedDIT ‰∏≠ÁöÑÊ®°ÂûãÊïàËÉΩ„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫ FedDCAÔºåÂÆÉÈÄèÈÅéË≤™Â©™Áî®Êà∂Á´Ø‰∏≠ÂøÉÈÅ∏ÊìáÂíåÂü∫ÊñºÊ™¢Á¥¢ÁöÑÊì¥ÂÖÖÔºåÊúÄ‰Ω≥ÂåñÈ†òÂüüÊ∂µËìãÁØÑÂúç„ÄÇÁÇ∫‰∫ÜÊ∏õËºïÁî®Êà∂Á´ØÁ´ØÁöÑÈÅãÁÆóË≤†ÊìîÔºåFedDCA$^*$ ‰ΩøÁî®ÂÖ∑Êúâ‰º∫ÊúçÂô®Á´ØÁâπÂæµÊØîÂ∞çÁöÑÁï∞Ë≥™Á∑®Á¢ºÂô®„ÄÇË∑®Ë∂äÂõõÂÄã‰∏çÂêåÈ†òÂüüÔºàÁ®ãÂºèÁ¢º„ÄÅÈÜ´ÁôÇ„ÄÅÈáëËûçÂíåÊï∏Â≠∏ÔºâÁöÑÂª£Ê≥õÂØ¶È©óË≠âÂØ¶‰∫ÜÈÄôÂÖ©Á®ÆÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈáùÂ∞çÂà©Áî®‰∏çÂêåÈáèÂÖ¨ÈñãÊï∏ÊìöÁöÑË®òÊÜ∂È´îÊèêÂèñÊîªÊìäË™øÊü•Èö±ÁßÅ‰øùË≠∑„ÄÇÁµêÊûúÈ°ØÁ§∫ÂÖ¨ÈñãÊï∏ÊìöÈáèËàáÈö±ÁßÅ‰øùË≠∑ËÉΩÂäõ‰πãÈñìÊ≤íÊúâÈ°ØËëóÁõ∏ÈóúÊÄß„ÄÇÁÑ∂ËÄåÔºåÈö®ËëóÂæÆË™øÂõûÂêàÊï∏Â¢ûÂä†ÔºåÈö±ÁßÅÊ¥©ÊºèÁöÑÈ¢®Èö™ÊúÉÈôç‰ΩéÊàñÊî∂ÊñÇ„ÄÇ

##### **ACE: Abstractions for Communicating Efficiently**
2409.20120v1 by Jonathan D. Thomas, Andrea Silvi, Devdatt Dubhashi, Vikas Garg, Moa Johansson

A central but unresolved aspect of problem-solving in AI is the capability to
introduce and use abstractions, something humans excel at. Work in cognitive
science has demonstrated that humans tend towards higher levels of abstraction
when engaged in collaborative task-oriented communication, enabling gradually
shorter and more information-efficient utterances. Several computational
methods have attempted to replicate this phenomenon, but all make unrealistic
simplifying assumptions about how abstractions are introduced and learned. Our
method, Abstractions for Communicating Efficiently (ACE), overcomes these
limitations through a neuro-symbolic approach. On the symbolic side, we draw on
work from library learning for proposing abstractions. We combine this with
neural methods for communication and reinforcement learning, via a novel use of
bandit algorithms for controlling the exploration and exploitation trade-off in
introducing new abstractions. ACE exhibits similar tendencies to humans on a
collaborative construction task from the cognitive science literature, where
one agent (the architect) instructs the other (the builder) to reconstruct a
scene of block-buildings. ACE results in the emergence of an efficient language
as a by-product of collaborative communication. Beyond providing mechanistic
insights into human communication, our work serves as a first step to providing
conversational agents with the ability for human-like communicative
abstractions.

ÊëòË¶ÅÔºöÂïèÈ°åËß£Ê±∫Âú® AI ‰∏≠‰∏ÄÂÄãÊ†∏ÂøÉ‰ΩÜÂ∞öÊú™Ëß£Ê±∫ÁöÑÈù¢ÂêëÊòØÊäΩË±°ÂåñÁöÑÂºïÂÖ•Âíå‰ΩøÁî®ËÉΩÂäõÔºåÈÄôÊòØ‰∫∫È°ûÊìÖÈï∑ÁöÑ‰∫ãÊÉÖ„ÄÇË™çÁü•ÁßëÂ≠∏‰∏≠ÁöÑÁ†îÁ©∂Â∑≤Ë≠âÊòéÔºåÁï∂‰∫∫È°ûÂæû‰∫ãÂçî‰Ωú‰ªªÂãôÂ∞éÂêëÊ∫ùÈÄöÊôÇÔºåÊúÉÂÇæÂêëÊñºËºÉÈ´òÂ±§Á¥öÁöÑÊäΩË±°ÂåñÔºåÈÄô‰ΩøÂæóË©±Ë™ûÈÄêÊº∏Á∞°Áü≠‰∏îÊõ¥ÂÖ∑Ë≥áË®äÊïàÁéá„ÄÇÊúâÂπæÁ®ÆÈÅãÁÆóÊñπÊ≥ïÂ∑≤ÂòóË©¶Ë§áË£ΩÊ≠§ÁèæË±°Ôºå‰ΩÜÂÖ®ÈÉ®ÈÉΩÂ∞çÊäΩË±°ÂåñÊòØÂ¶Ç‰ΩïÂºïÂÖ•ÂíåÂ≠∏ÁøíÁöÑÂÅöÂá∫‰∏çÂàáÂØ¶ÈöõÁöÑÁ∞°ÂåñÂÅáË®≠„ÄÇÊàëÂÄëÁöÑÊäΩË±°ÂåñÊúâÊïàÊ∫ùÈÄö (ACE) ÊñπÊ≥ïÈÄèÈÅéÁ•ûÁ∂ìÁ¨¶ËôüÊñπÊ≥ïÂÖãÊúç‰∫ÜÈÄô‰∫õÈôêÂà∂„ÄÇÂú®Á¨¶ËôüÊñπÈù¢ÔºåÊàëÂÄëÂà©Áî®‰æÜËá™Á®ãÂºèÂ∫´Â≠∏ÁøíÁöÑÊàêÊûú‰æÜÊèêÂá∫ÊäΩË±°Âåñ„ÄÇÊàëÂÄëÂ∞áÊ≠§ËàáÁ•ûÁ∂ìÊñπÊ≥ïÁµêÂêàËµ∑‰æÜÔºåÁî®ÊñºÊ∫ùÈÄöÂíåÂº∑ÂåñÂ≠∏ÁøíÔºåÈÄèÈÅé‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂº∑ÁõúÊºîÁÆóÊ≥ï‰ΩøÁî®ÊñπÂºè‰æÜÊéßÂà∂Âú®ÂºïÂÖ•Êñ∞ÊäΩË±°ÂåñÊôÇÊé¢Á¥¢ÂíåÂà©Áî®ÁöÑÊ¨äË°°„ÄÇACE Âú®Ë™çÁü•ÁßëÂ≠∏ÊñáÁçª‰∏≠ÁöÑ‰∏ÄÈ†ÖÂçî‰ΩúÂª∫Êßã‰ªªÂãô‰∏≠Â±ïÁèæÂá∫Ëàá‰∫∫È°ûÁõ∏‰ººÁöÑÂÇæÂêëÔºåÂú®Ë©≤‰ªªÂãô‰∏≠Ôºå‰∏ÄÂÄã‰ª£ÁêÜ‰∫∫ÔºàÂª∫ÁØâÂ∏´ÔºâÊåáÁ§∫Âè¶‰∏ÄÂÄã‰ª£ÁêÜ‰∫∫ÔºàÂª∫ÈÄ†ËÄÖÔºâÈáçÂª∫‰∏ÄÂÄãÁ©çÊú®Âª∫ÁØâÂ†¥ÊôØ„ÄÇACE Â∞éËá¥‰∏ÄÁ®ÆÊúâÊïàË™ûË®ÄÁöÑÂá∫ÁèæÔºå‰ΩúÁÇ∫Âçî‰ΩúÊ∫ùÈÄöÁöÑÂâØÁî¢ÂìÅ„ÄÇÈô§‰∫ÜÊèê‰æõ‰∫∫È°ûÊ∫ùÈÄöÁöÑÊ©üÂà∂Ë¶ãËß£Â§ñÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÈÇÑ‰ΩúÁÇ∫Êèê‰æõÂ∞çË©±‰ª£ÁêÜ‰∫∫ÂÖ∑Êúâ‰∫∫È°ûÂºèÊ∫ùÈÄöÊäΩË±°ÂåñËÉΩÂäõÁöÑÁ¨¨‰∏ÄÊ≠•„ÄÇ

##### **Aggressive Post-Training Compression on Extremely Large Language Models**
2409.20094v1 by Zining Zhang, Yao Chen, Bingsheng He, Zhenjie Zhang

The increasing size and complexity of Large Language Models (LLMs) pose
challenges for their deployment on personal computers and mobile devices.
Aggressive post-training model compression is necessary to reduce the models'
size, but it often results in significant accuracy loss. To address this
challenge, we propose a novel network pruning technology that utilizes over 0.7
sparsity and less than 8 bits of quantization. Our approach enables the
compression of prevailing LLMs within a couple of hours while maintaining a
relatively small accuracy loss. In experimental evaluations, our method
demonstrates effectiveness and potential for practical deployment. By making
LLMs available on domestic devices, our work can facilitate a new era of
natural language processing applications with wide-ranging impacts.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑË¶èÊ®°ÂíåË§áÈõúÊÄßÊó•ÁõäÂ¢ûÂä†ÔºåÂ∞çÂÖ∂Âú®ÂÄã‰∫∫ÈõªËÖ¶ÂíåË°åÂãïË£ùÁΩÆ‰∏äÁöÑÈÉ®ÁΩ≤ÊßãÊàêÊåëÊà∞„ÄÇÁ©çÊ•µÁöÑË®ìÁ∑¥ÂæåÊ®°ÂûãÂ£ìÁ∏ÆÂ∞çÊñºÁ∏ÆÂ∞èÊ®°ÂûãÁöÑË¶èÊ®°ÊòØÂøÖË¶ÅÁöÑÔºå‰ΩÜÂÆÉÈÄöÂ∏∏ÊúÉÂ∞éËá¥È°ØËëóÁöÑÊ∫ñÁ¢∫ÊÄßÊêçÂ§±„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∏ÄÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÁ∂≤Ë∑Ø‰øÆÂâ™ÊäÄË°ìÔºåÂÆÉÂà©Áî®Ë∂ÖÈÅé 0.7 ÁöÑÁ®ÄÁñèÊÄßÂíå‰∏çÂà∞ 8 ‰ΩçÂÖÉÁöÑÈáèÂåñ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂèØ‰ª•Âú®ÂπæÂÄãÂ∞èÊôÇÂÖßÂ£ìÁ∏Æ‰∏ªÊµÅÁöÑ LLMÔºåÂêåÊôÇ‰øùÊåÅÁõ∏Â∞çËºÉÂ∞èÁöÑÊ∫ñÁ¢∫ÊÄßÊêçÂ§±„ÄÇÂú®ÂØ¶È©óË©ï‰º∞‰∏≠ÔºåÊàëÂÄëÁöÑÊ®°ÂûãË≠âÊòé‰∫ÜÂÖ∂Âú®ÂØ¶ÈöõÈÉ®ÁΩ≤‰∏≠ÁöÑÊúâÊïàÊÄßÂíåÊΩõÂäõ„ÄÇÈÄèÈÅéËÆì LLM ÂèØÁî®ÊñºÂÆ∂Áî®Ë£ùÁΩÆÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÂèØ‰ª•‰øÉÈÄ≤Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÊáâÁî®Á®ãÂºèÁöÑÊñ∞ÊôÇ‰ª£Ôºå‰∏¶Áî¢ÁîüÂª£Ê≥õÁöÑÂΩ±Èüø„ÄÇ

##### **Robust LLM safeguarding via refusal feature adversarial training**
2409.20089v1 by Lei Yu, Virginie Do, Karen Hambardzumyan, Nicola Cancedda

Large language models (LLMs) are vulnerable to adversarial attacks that can
elicit harmful responses. Defending against such attacks remains challenging
due to the opacity of jailbreaking mechanisms and the high computational cost
of training LLMs robustly. We demonstrate that adversarial attacks share a
universal mechanism for circumventing LLM safeguards that works by ablating a
dimension in the residual stream embedding space called the refusal feature. We
further show that the operation of refusal feature ablation (RFA) approximates
the worst-case perturbation of offsetting model safety. Based on these
findings, we propose Refusal Feature Adversarial Training (ReFAT), a novel
algorithm that efficiently performs LLM adversarial training by simulating the
effect of input-level attacks via RFA. Experiment results show that ReFAT
significantly improves the robustness of three popular LLMs against a wide
range of adversarial attacks, with considerably less computational overhead
compared to existing adversarial training methods.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂÆπÊòìÂèóÂà∞Â∞çÊäóÊÄßÊîªÊìäÔºåÈÄô‰∫õÊîªÊìäÊúÉÂºïÁôºÊúâÂÆ≥ÁöÑÂõûÊáâ„ÄÇÁî±ÊñºË∂äÁçÑÊ©üÂà∂ÁöÑ‰∏çÈÄèÊòéÊÄß‰ª•ÂèäË®ìÁ∑¥Á©©ÂÅ•ÁöÑ LLM ÁöÑÈ´òÈÅãÁÆóÊàêÊú¨ÔºåÈò≤Á¶¶Ê≠§È°ûÊîªÊìä‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊàëÂÄëË≠âÊòéÂ∞çÊäóÊÄßÊîªÊìäÂÖ±Áî®‰∏ÄÁ®ÆÈÄöÁî®Ê©üÂà∂‰æÜË¶èÈÅø LLM ‰øùÈöúÊé™ÊñΩÔºåÈÄôÁ®ÆÊ©üÂà∂ÈÄöÈÅéÊ∂àËûçÊÆòÂ∑Æ‰∏≤ÊµÅÂµåÂÖ•Á©∫Èñì‰∏≠Á®±ÁÇ∫ÊãíÁµïÁâπÂæµÁöÑÁ∂≠Â∫¶‰æÜÈÅã‰Ωú„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Ë°®ÊòéÔºåÊãíÁµïÁâπÂæµÊ∂àËûç (RFA) ÁöÑÊìç‰ΩúËøë‰ººÊñºÊäµÊ∂àÊ®°ÂûãÂÆâÂÖ®ÊÄßÁöÑÊúÄÂ£ûÊÉÖÊ≥ÅÊìæÂãï„ÄÇÂü∫ÊñºÈÄô‰∫õÁôºÁèæÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÊãíÁµïÁâπÂæµÂ∞çÊäóÊÄßË®ìÁ∑¥ (ReFAT)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊºîÁÆóÊ≥ïÔºåÈÄöÈÅé RFA Ê®°Êì¨Ëº∏ÂÖ•Á¥öÂà•ÊîªÊìäÁöÑÂΩ±ÈüøÔºåÊúâÊïàÂú∞Âü∑Ë°å LLM Â∞çÊäóÊÄßË®ìÁ∑¥„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåËàáÁèæÊúâÁöÑÂ∞çÊäóÊÄßË®ìÁ∑¥ÊñπÊ≥ïÁõ∏ÊØîÔºåReFAT Â§ßÂπÖÊèêÈ´ò‰∫Ü‰∏âÁ®ÆÊµÅË°åÁöÑ LLM Â∞çÂêÑÁ®ÆÂ∞çÊäóÊÄßÊîªÊìäÁöÑÁ©©ÂÅ•ÊÄßÔºå‰∏îÈÅãÁÆóË≤†ÊìîÈ°ØËëóÈôç‰Ωé„ÄÇ

##### **BSharedRAG: Backbone Shared Retrieval-Augmented Generation for the E-commerce Domain**
2409.20075v1 by Kaisi Guan, Qian Cao, Yuchong Sun, Xiting Wang, Ruihua Song

Retrieval Augmented Generation (RAG) system is important in domains such as
e-commerce, which has many long-tail entities and frequently updated
information. Most existing works adopt separate modules for retrieval and
generation, which may be suboptimal since the retrieval task and the generation
task cannot benefit from each other to improve performance. We propose a novel
Backbone Shared RAG framework (BSharedRAG). It first uses a domain-specific
corpus to continually pre-train a base model as a domain-specific backbone
model and then trains two plug-and-play Low-Rank Adaptation (LoRA) modules
based on the shared backbone to minimize retrieval and generation losses
respectively. Experimental results indicate that our proposed BSharedRAG
outperforms baseline models by 5% and 13% in Hit@3 upon two datasets in
retrieval evaluation and by 23% in terms of BLEU-3 in generation evaluation.
Our codes, models, and dataset are available at https://bsharedrag.github.io.

ÊëòË¶ÅÔºöÊì∑ÂèñÂ¢ûÂº∑ÁîüÊàêÔºàRAGÔºâÁ≥ªÁµ±Âú®ÈõªÂ≠êÂïÜÂãôÁ≠âÈ†òÂüü‰∏≠ÈùûÂ∏∏ÈáçË¶ÅÔºåÈõªÂ≠êÂïÜÂãôÊúâË®±Â§öÈï∑Â∞æÂØ¶È´îÂíåÁ∂ìÂ∏∏Êõ¥Êñ∞ÁöÑË≥áË®ä„ÄÇÂ§ßÂ§öÊï∏ÁèæÊúâ‰ΩúÂìÅÊé°Áî®Áç®Á´ãÊ®°ÁµÑÈÄ≤Ë°åÊì∑ÂèñÂíåÁîüÊàêÔºåÈÄôÂèØËÉΩÊòØÊ¨°‰Ω≥ÊñπÊ°àÔºåÂõ†ÁÇ∫Êì∑Âèñ‰ªªÂãôÂíåÁîüÊàê‰ªªÂãôÁÑ°Ê≥ï‰∫íÁõ∏ÂèóÁõä‰ª•ÊîπÂñÑÊïàËÉΩ„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑ Backbone ÂÖ±‰∫´ RAG Êû∂ÊßãÔºàBSharedRAGÔºâ„ÄÇÂÆÉÈ¶ñÂÖà‰ΩøÁî®ÁâπÂÆöÈ†òÂüüÁöÑË™ûÊñôÂ∫´ÊåÅÁ∫åÈ†êË®ìÁ∑¥Âü∫Á§éÊ®°Âûã‰ΩúÁÇ∫ÁâπÂÆöÈ†òÂüüÁöÑ Backbone Ê®°ÂûãÔºåÁÑ∂ÂæåÊ†πÊìöÂÖ±‰∫´ Backbone Ë®ìÁ∑¥ÂÖ©ÂÄãÂç≥ÊèíÂç≥Áî®ÁöÑ‰ΩéÈöéÈÅ©ÊáâÔºàLoRAÔºâÊ®°ÁµÑÔºå‰ª•ÂàÜÂà•ÊúÄÂ∞èÂåñÊì∑ÂèñÂíåÁîüÊàêÊêçÂ§±„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÊèêÂá∫ÁöÑ BSharedRAG Âú®Êì∑ÂèñË©ï‰º∞‰∏≠ÔºåÊñºÂÖ©ÂÄãË≥áÊñôÈõÜÁöÑ Hit@3 ‰∏≠ÂÑ™ÊñºÂü∫Ê∫ñÊ®°Âûã 5% Âíå 13%ÔºåÂú®ÁîüÊàêË©ï‰º∞‰∏≠Ôºå‰ª• BLEU-3 ËÄåË®ÄÂÑ™ÊñºÂü∫Ê∫ñÊ®°Âûã 23%„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢º„ÄÅÊ®°ÂûãÂíåË≥áÊñôÈõÜÂèØÂú® https://bsharedrag.github.io/ ÂèñÂæó„ÄÇ

##### **Knowledge Discovery using Unsupervised Cognition**
2409.20064v1 by Alfredo Ibias, Hector Antona, Guillem Ramirez-Miranda, Enric Guinovart

Knowledge discovery is key to understand and interpret a dataset, as well as
to find the underlying relationships between its components. Unsupervised
Cognition is a novel unsupervised learning algorithm that focus on modelling
the learned data. This paper presents three techniques to perform knowledge
discovery over an already trained Unsupervised Cognition model. Specifically,
we present a technique for pattern mining, a technique for feature selection
based on the previous pattern mining technique, and a technique for
dimensionality reduction based on the previous feature selection technique. The
final goal is to distinguish between relevant and irrelevant features and use
them to build a model from which to extract meaningful patterns. We evaluated
our proposals with empirical experiments and found that they overcome the
state-of-the-art in knowledge discovery.

ÊëòË¶ÅÔºöÁü•Ë≠òÁôºÁèæÊòØ‰∫ÜËß£ÂíåË©ÆÈáãË≥áÊñôÈõÜÁöÑÈóúÈçµÔºå‰ª•ÂèäÊâæÂá∫ÂÖ∂ÁµÑÊàêÈÉ®ÂàÜ‰πãÈñìÁöÑÂü∫Á§éÈóú‰øÇ„ÄÇÁÑ°Áõ£Áù£Ë™çÁü•ÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÁÑ°Áõ£Áù£Â≠∏ÁøíÊºîÁÆóÊ≥ïÔºåÂ∞àÊ≥®ÊñºÂ∞çÂ≠∏ÁøíÂà∞ÁöÑË≥áÊñôÈÄ≤Ë°åÂª∫Ê®°„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏âÁ®ÆÊäÄË°ìÔºå‰ª•Â∞çÂ∑≤Ë®ìÁ∑¥Â•ΩÁöÑÁÑ°Áõ£Áù£Ë™çÁü•Ê®°ÂûãÂü∑Ë°åÁü•Ë≠òÁôºÁèæ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊ®°ÂºèÊé¢ÂãòÊäÄË°ì„ÄÅ‰∏ÄÁ®ÆÂü∫ÊñºÂÖàÂâçÊ®°ÂºèÊé¢ÂãòÊäÄË°ìÁöÑÁâπÂæµÈÅ∏ÂèñÊäÄË°ìÔºå‰ª•Âèä‰∏ÄÁ®ÆÂü∫ÊñºÂÖàÂâçÁâπÂæµÈÅ∏ÂèñÊäÄË°ìÁöÑÈôçÁ∂≠ÊäÄË°ì„ÄÇÊúÄÁµÇÁõÆÊ®ôÊòØÂçÄÂàÜÁõ∏ÈóúÂíåÁÑ°ÈóúÁâπÂæµÔºå‰∏¶‰ΩøÁî®ÂÆÉÂÄë‰æÜÂª∫Á´ã‰∏ÄÂÄãÊ®°ÂûãÔºåÂæû‰∏≠ÊèêÂèñÊúâÊÑèÁæ©ÁöÑÊ®°Âºè„ÄÇÊàëÂÄë‰ΩøÁî®Á∂ìÈ©óÂØ¶È©óË©ï‰º∞‰∫ÜÊàëÂÄëÁöÑÊèêÊ°àÔºåÁôºÁèæÂÆÉÂÄëÂÖãÊúç‰∫ÜÁü•Ë≠òÁôºÁèæÁöÑÊúÄÊñ∞ÊäÄË°ì„ÄÇ

##### **Is Preference Alignment Always the Best Option to Enhance LLM-Based Translation? An Empirical Analysis**
2409.20059v1 by Hippolyte Gisserot-Boukhlef, Ricardo Rei, Emmanuel Malherbe, C√©line Hudelot, Pierre Colombo, Nuno M. Guerreiro

Neural metrics for machine translation (MT) evaluation have become
increasingly prominent due to their superior correlation with human judgments
compared to traditional lexical metrics. Researchers have therefore utilized
neural metrics through quality-informed decoding strategies, achieving better
results than likelihood-based methods. With the rise of Large Language Models
(LLMs), preference-based alignment techniques have gained attention for their
potential to enhance translation quality by optimizing model weights directly
on preferences induced by quality estimators. This study focuses on Contrastive
Preference Optimization (CPO) and conducts extensive experiments to evaluate
the impact of preference-based alignment on translation quality. Our findings
indicate that while CPO consistently outperforms Supervised Fine-Tuning (SFT)
on high-quality data with regard to the alignment metric, it may lead to
instability across downstream evaluation metrics, particularly between neural
and lexical ones. Additionally, we demonstrate that relying solely on the base
model for generating candidate translations achieves performance comparable to
using multiple external systems, while ensuring better consistency across
downstream metrics.

ÊëòË¶ÅÔºöÁ•ûÁ∂ìÊ©üÂô®ÁøªË≠Ø (MT) Ë©ï‰º∞ÊåáÊ®ôÁî±ÊñºËàá‰∫∫È°ûË©ïÂàÜÁõ∏ÊØîÂÖ∑ÊúâÊõ¥È´òÁöÑÁõ∏ÈóúÊÄßÔºåÂõ†Ê≠§Ë∂ä‰æÜË∂äÈáçË¶ÅÔºåËÄåÂÇ≥Áµ±ÁöÑË©ûÂΩôÊåáÊ®ôÂâá‰∏çÁÑ∂„ÄÇÂõ†Ê≠§ÔºåÁ†îÁ©∂‰∫∫Âì°ÈÄèÈÅéÂìÅË≥™Â∞éÂêëÁöÑËß£Á¢ºÁ≠ñÁï•‰æÜÂà©Áî®Á•ûÁ∂ìÊåáÊ®ôÔºåÈÅîÊàêÊØîÂü∫Êñº‰ººÁÑ∂ÊÄßÁöÑÊñπÊ≥ïÊõ¥Â•ΩÁöÑÁµêÊûú„ÄÇÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËààËµ∑ÔºåÂü∫ÊñºÂÅèÂ•ΩÁöÑÂ∞çÈΩäÊäÄË°ìÂõ†ÂÖ∂ÈÄèÈÅéÂìÅË≥™‰º∞Ë®àÂô®Áõ¥Êé•ÊúÄ‰Ω≥ÂåñÊ®°ÂûãÊ¨äÈáç‰æÜÊèêÂçáÁøªË≠ØÂìÅË≥™ÁöÑÊΩõÂäõËÄåÂèóÂà∞ÈóúÊ≥®„ÄÇÊú¨Á†îÁ©∂Â∞àÊ≥®ÊñºÂ∞çÊØîÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (CPO)Ôºå‰∏¶ÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©ó‰æÜË©ï‰º∞Âü∫ÊñºÂÅèÂ•ΩÁöÑÂ∞çÈΩäÂ∞çÁøªË≠ØÂìÅË≥™ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁöÑÁôºÁèæÈ°ØÁ§∫ÔºåÈõñÁÑ∂ CPO Âú®Â∞çÈΩäÊåáÊ®ôÊñπÈù¢ÂßãÁµÇÂÑ™ÊñºÁõ£Áù£ÂæÆË™ø (SFT) ÁöÑÈ´òÂìÅË≥™Ë≥áÊñôÔºå‰ΩÜÂÆÉÂèØËÉΩÊúÉÂ∞éËá¥‰∏ãÊ∏∏Ë©ï‰º∞ÊåáÊ®ôÁöÑ‰∏çÁ©©ÂÆöÊÄßÔºåÁâπÂà•ÊòØÂú®Á•ûÁ∂ìÊåáÊ®ôÂíåË©ûÂΩôÊåáÊ®ô‰πãÈñì„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË≠âÊòéÂÉÖ‰æùË≥¥Âü∫Á§éÊ®°Âûã‰æÜÁî¢ÁîüÂÄôÈÅ∏ÁøªË≠ØÂèØÈÅîÊàêËàá‰ΩøÁî®Â§öÂÄãÂ§ñÈÉ®Á≥ªÁµ±Áõ∏Áï∂ÁöÑÊïàËÉΩÔºåÂêåÊôÇÁ¢∫‰øù‰∏ãÊ∏∏ÊåáÊ®ô‰πãÈñìÁöÑ‰∏ÄËá¥ÊÄß„ÄÇ

##### **Evaluating and explaining training strategies for zero-shot cross-lingual news sentiment analysis**
2409.20054v1 by Luka Andren≈°ek, Boshko Koloski, Andra≈æ Pelicon, Nada Lavraƒç, Senja Pollak, Matthew Purver

We investigate zero-shot cross-lingual news sentiment detection, aiming to
develop robust sentiment classifiers that can be deployed across multiple
languages without target-language training data. We introduce novel evaluation
datasets in several less-resourced languages, and experiment with a range of
approaches including the use of machine translation; in-context learning with
large language models; and various intermediate training regimes including a
novel task objective, POA, that leverages paragraph-level information. Our
results demonstrate significant improvements over the state of the art, with
in-context learning generally giving the best performance, but with the novel
POA approach giving a competitive alternative with much lower computational
overhead. We also show that language similarity is not in itself sufficient for
predicting the success of cross-lingual transfer, but that similarity in
semantic content and structure can be equally important.

ÊëòË¶ÅÔºöÊàëÂÄëÁ†îÁ©∂Èõ∂Ê¨°Â≠∏ÁøíË∑®Ë™ûË®ÄÊñ∞ËÅûÊÉÖÁ∑íÂÅµÊ∏¨ÔºåÁõÆÊ®ôÊòØÈñãÁôºÂº∑ÂÅ•ÁöÑÊÉÖÁ∑íÂàÜÈ°ûÂô®ÔºåÂèØ‰ª•Âú®Ê≤íÊúâÁõÆÊ®ôË™ûË®ÄË®ìÁ∑¥Ë≥áÊñôÁöÑÊÉÖÊ≥Å‰∏ãÈÉ®ÁΩ≤Âà∞Â§öÁ®ÆË™ûË®Ä‰∏≠„ÄÇÊàëÂÄëÂú®ÂπæÁ®ÆË≥áÊ∫êËºÉÂ∞ëÁöÑË™ûË®Ä‰∏≠ÂºïÂÖ•‰∫ÜÊñ∞Á©éÁöÑË©ï‰º∞Ë≥áÊñôÈõÜÔºå‰∏¶ÂòóË©¶‰∫Ü‰∏ÄÁ≥ªÂàóÁöÑÊñπÊ≥ïÔºåÂåÖÊã¨‰ΩøÁî®Ê©üÂô®ÁøªË≠ØÔºõ‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÈÄ≤Ë°åÊÉÖÂ¢ÉÂ≠∏ÁøíÔºõ‰ª•ÂèäÂêÑÁ®Æ‰∏≠ÈñìË®ìÁ∑¥Âà∂Â∫¶ÔºåÂåÖÊã¨Âà©Áî®ÊÆµËêΩÂ±§Á¥öË≥áË®äÁöÑÊñ∞Á©é‰ªªÂãôÁõÆÊ®ô POA„ÄÇÊàëÂÄëÁöÑÁµêÊûúË≠âÊòé‰∫ÜËàáÁèæÊúâÊäÄË°ìÁõ∏ÊØîÊúâÈ°ØËëóÁöÑÊîπÈÄ≤ÔºåÂÖ∂‰∏≠ÊÉÖÂ¢ÉÂ≠∏ÁøíÈÄöÂ∏∏ËÉΩÊèê‰æõÊúÄ‰Ω≥ÊïàËÉΩÔºå‰ΩÜÊñ∞Á©éÁöÑ POA ÊñπÊ≥ïÊèê‰æõ‰∫ÜÂÖ∑ÊúâËºÉ‰ΩéÈÅãÁÆóÊàêÊú¨ÁöÑÁ´∂Áà≠Êõø‰ª£ÊñπÊ°à„ÄÇÊàëÂÄëÈÇÑË°®ÊòéÔºåË™ûË®ÄÁõ∏‰ººÊÄßÊú¨Ë∫´‰∏çË∂≥‰ª•È†êÊ∏¨Ë∑®Ë™ûË®ÄËΩâÁßªÁöÑÊàêÂäüÔºå‰ΩÜË™ûÁæ©ÂÖßÂÆπÂíåÁµêÊßãÁöÑÁõ∏‰ººÊÄßÂèØËÉΩÂêåÊ®£ÈáçË¶Å„ÄÇ

##### **GUNDAM: Aligning Large Language Models with Graph Understanding**
2409.20053v1 by Sheng Ouyang, Yulan Hu, Ge Chen, Yong Liu

Large Language Models (LLMs) have achieved impressive results in processing
text data, which has sparked interest in applying these models beyond textual
data, such as graphs. In the field of graph learning, there is a growing
interest in harnessing LLMs to comprehend and manipulate graph-structured data.
Existing research predominantly focuses on graphs with rich textual features,
such as knowledge graphs or text attribute graphs, leveraging LLMs' ability to
process text but inadequately addressing graph structure. This work
specifically aims to assess and enhance LLMs' abilities to comprehend and
utilize the structural knowledge inherent in graph data itself, rather than
focusing solely on graphs rich in textual content. To achieve this, we
introduce the \textbf{G}raph \textbf{U}nderstanding for \textbf{N}atural
Language \textbf{D}riven \textbf{A}nalytical \textbf{M}odel (\model). This
model adapts LLMs to better understand and engage with the structure of graph
data, enabling them to perform complex reasoning tasks by leveraging the
graph's structure itself. Our experimental evaluations on graph reasoning
benchmarks not only substantiate that \model~ outperforms the SOTA baselines
for comparisons. But also reveals key factors affecting the graph reasoning
capabilities of LLMs. Moreover, we provide a theoretical analysis illustrating
how reasoning paths can enhance LLMs' reasoning capabilities.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ËôïÁêÜÊñáÊú¨Êï∏ÊìöÊñπÈù¢ÂèñÂæó‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊàêÊûúÔºåÈÄôÊøÄÁôº‰∫ÜÂ∞áÈÄô‰∫õÊ®°ÂûãÊáâÁî®ÊñºÊñáÊú¨Êï∏Êìö‰πãÂ§ñÈ†òÂüüÔºà‰æãÂ¶ÇÂúñË°®ÔºâÁöÑËààË∂£„ÄÇÂú®ÂúñË°®Â≠∏ÁøíÈ†òÂüüÔºåÂà©Áî® LLM ‰æÜÁêÜËß£ÂíåÊìç‰ΩúÂúñË°®ÁµêÊßãÊï∏ÊìöÁöÑËààË∂£ËàáÊó•‰ø±Â¢û„ÄÇÁèæÊúâÁöÑÁ†îÁ©∂‰∏ªË¶ÅÈõÜ‰∏≠ÊñºÂÖ∑ÊúâË±êÂØåÊñáÊú¨ÁâπÂæµÁöÑÂúñË°®Ôºå‰æãÂ¶ÇÁü•Ë≠òÂúñË°®ÊàñÊñáÊú¨Â±¨ÊÄßÂúñË°®ÔºåÂà©Áî® LLM ËôïÁêÜÊñáÊú¨ÁöÑËÉΩÂäõÔºå‰ΩÜÊú™ËÉΩÂÖÖÂàÜËß£Ê±∫ÂúñË°®ÁµêÊßã„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁâπÂà•Êó®Âú®Ë©ï‰º∞ÂíåÂ¢ûÂº∑ LLM ÁêÜËß£ÂíåÂà©Áî®ÂúñË°®Êï∏ÊìöÊú¨Ë∫´Âõ∫ÊúâÁöÑÁµêÊßãÁü•Ë≠òÁöÑËÉΩÂäõÔºåËÄå‰∏çÊòØÂÉÖÈóúÊ≥®ÂØåÂê´ÊñáÊú¨ÂÖßÂÆπÁöÑÂúñË°®„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜËá™ÁÑ∂Ë™ûË®ÄÈ©ÖÂãïÂàÜÊûêÊ®°ÂûãÁöÑÂúñË°®ÁêÜËß£ (\model)„ÄÇÊ≠§Ê®°ÂûãÊîπÈÄ≤‰∫Ü LLM ‰ª•‰æøÊõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÂèÉËàáÂúñË°®Êï∏ÊìöÁöÑÁµêÊßãÔºå‰ΩøÂÖ∂ËÉΩÂ§†ÈÄöÈÅéÂà©Áî®ÂúñË°®ÁöÑÁµêÊßãÊú¨Ë∫´‰æÜÂü∑Ë°åË§áÈõúÁöÑÊé®ÁêÜ‰ªªÂãô„ÄÇÊàëÂÄëÂ∞çÂúñË°®Êé®ÁêÜÂü∫Ê∫ñÁöÑÂØ¶È©óË©ï‰º∞‰∏çÂÉÖË≠âÂØ¶‰∫Ü \model~ ÂÑ™ÊñºÁî®ÊñºÊØîËºÉÁöÑ SOTA Âü∫Ê∫ñÔºåÈÇÑÊè≠Á§∫‰∫ÜÂΩ±Èüø LLM ÂúñË°®Êé®ÁêÜËÉΩÂäõÁöÑ‰∏ªË¶ÅÂõ†Á¥†„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÁêÜË´ñÂàÜÊûêÔºåË™™ÊòéÊé®ÁêÜË∑ØÂæëÂ¶Ç‰ΩïÂ¢ûÂº∑ LLM ÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇ

##### **Mitigating Propensity Bias of Large Language Models for Recommender Systems**
2409.20052v1 by Guixian Zhang, Guan Yuan, Debo Cheng, Lin Liu, Jiuyong Li, Shichao Zhang

The rapid development of Large Language Models (LLMs) creates new
opportunities for recommender systems, especially by exploiting the side
information (e.g., descriptions and analyses of items) generated by these
models. However, aligning this side information with collaborative information
from historical interactions poses significant challenges. The inherent biases
within LLMs can skew recommendations, resulting in distorted and potentially
unfair user experiences. On the other hand, propensity bias causes side
information to be aligned in such a way that it often tends to represent all
inputs in a low-dimensional subspace, leading to a phenomenon known as
dimensional collapse, which severely restricts the recommender system's ability
to capture user preferences and behaviours. To address these issues, we
introduce a novel framework named Counterfactual LLM Recommendation (CLLMR).
Specifically, we propose a spectrum-based side information encoder that
implicitly embeds structural information from historical interactions into the
side information representation, thereby circumventing the risk of dimension
collapse. Furthermore, our CLLMR approach explores the causal relationships
inherent in LLM-based recommender systems. By leveraging counterfactual
inference, we counteract the biases introduced by LLMs. Extensive experiments
demonstrate that our CLLMR approach consistently enhances the performance of
various recommender models.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂø´ÈÄüÁôºÂ±ïÁÇ∫Êé®Ëñ¶Á≥ªÁµ±ÂâµÈÄ†‰∫ÜÊñ∞ÁöÑÊ©üÊúÉÔºåÁâπÂà•ÊòØÈÄèÈÅéÂà©Áî®ÈÄô‰∫õÊ®°ÂûãÁî¢ÁîüÁöÑÈôÑÂ∏∂Ë≥áË®ä (‰æãÂ¶ÇÔºåÁâ©ÂìÅÁöÑÊèèËø∞ÂíåÂàÜÊûê)„ÄÇÁÑ∂ËÄåÔºåÂ∞áÊ≠§ÈôÑÂ∏∂Ë≥áË®äËàá‰æÜËá™Ê≠∑Âè≤‰∫íÂãïÁöÑÂçî‰ΩúË≥áË®äÁõ∏ÁµêÂêàÔºåÊúÉÈÄ†ÊàêÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇLLM ÂÖßÈÉ®Âõ∫ÊúâÁöÑÂÅèË¶ãÊúÉÊâ≠Êõ≤Êé®Ëñ¶ÔºåÂ∞éËá¥Â§±Áúü‰∏îÂèØËÉΩ‰∏çÂÖ¨Âπ≥ÁöÑ‰ΩøÁî®ËÄÖÈ´îÈ©ó„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÂÇæÂêëÂÅèË¶ãÊúÉÂ∞éËá¥ÈôÑÂ∏∂Ë≥áË®ä‰ª•ÊüêÁ®ÆÊñπÂºèÂ∞çÈΩäÔºåËÄåÈÄôÁ®ÆÊñπÂºèÈÄöÂ∏∏ÂÇæÂêëÊñºÂú®‰ΩéÁ∂≠Â≠êÁ©∫Èñì‰∏≠Ë°®Á§∫ÊâÄÊúâËº∏ÂÖ•ÔºåÈÄ≤ËÄåÂ∞éËá¥Á®±ÁÇ∫Á∂≠Â∫¶Â¥©ÊΩ∞ÁöÑÁèæË±°ÔºåÈÄôÂö¥ÈáçÈôêÂà∂‰∫ÜÊé®Ëñ¶Á≥ªÁµ±Êì∑Âèñ‰ΩøÁî®ËÄÖÂÅèÂ•ΩÂíåË°åÁÇ∫ÁöÑËÉΩÂäõ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÂºïÈÄ≤‰∏ÄÂÄãÂêçÁÇ∫Âèç‰∫ãÂØ¶ LLM Êé®Ëñ¶ (CLLMR) ÁöÑÊñ∞Á©éÊû∂Êßã„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÈ†ªË≠úÁöÑÈôÑÂ∏∂Ë≥áË®äÁ∑®Á¢ºÂô®ÔºåÂÆÉÂ∞á‰æÜËá™Ê≠∑Âè≤‰∫íÂãïÁöÑÁµêÊßãË≥áË®äÈö±Âê´Âú∞ÂµåÂÖ•ÈôÑÂ∏∂Ë≥áË®äË°®Á§∫‰∏≠ÔºåÂæûËÄåËø¥ÈÅøÁ∂≠Â∫¶Â¥©ÊΩ∞ÁöÑÈ¢®Èö™„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑ CLLMR ÊñπÊ≥ïÊé¢Ë®é‰∫ÜÂü∫Êñº LLM ÁöÑÊé®Ëñ¶Á≥ªÁµ±‰∏≠Âõ∫ÊúâÁöÑÂõ†ÊûúÈóú‰øÇ„ÄÇÈÄèÈÅéÂà©Áî®Âèç‰∫ãÂØ¶Êé®Ë´ñÔºåÊàëÂÄëÊäµÈä∑ LLM ÂºïÂÖ•ÁöÑÂÅèË¶ã„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºåÊàëÂÄëÁöÑ CLLMR ÊñπÊ≥ïÊåÅÁ∫åÊèêÂçáÂêÑÁ®ÆÊé®Ëñ¶Ê®°ÂûãÁöÑÊïàËÉΩ„ÄÇ

##### **Depression detection in social media posts using transformer-based models and auxiliary features**
2409.20048v1 by Marios Kerasiotis, Loukas Ilias, Dimitris Askounis

The detection of depression in social media posts is crucial due to the
increasing prevalence of mental health issues. Traditional machine learning
algorithms often fail to capture intricate textual patterns, limiting their
effectiveness in identifying depression. Existing studies have explored various
approaches to this problem but often fall short in terms of accuracy and
robustness. To address these limitations, this research proposes a neural
network architecture leveraging transformer-based models combined with metadata
and linguistic markers. The study employs DistilBERT, extracting information
from the last four layers of the transformer, applying learned weights, and
averaging them to create a rich representation of the input text. This
representation, augmented by metadata and linguistic markers, enhances the
model's comprehension of each post. Dropout layers prevent overfitting, and a
Multilayer Perceptron (MLP) is used for final classification. Data augmentation
techniques, inspired by the Easy Data Augmentation (EDA) methods, are also
employed to improve model performance. Using BERT, random insertion and
substitution of phrases generate additional training data, focusing on
balancing the dataset by augmenting underrepresented classes. The proposed
model achieves weighted Precision, Recall, and F1-scores of 84.26%, 84.18%, and
84.15%, respectively. The augmentation techniques significantly enhance model
performance, increasing the weighted F1-score from 72.59% to 84.15%.

ÊëòË¶ÅÔºöÁî±ÊñºÂøÉÁêÜÂÅ•Â∫∑ÂïèÈ°åÁöÑÁõõË°åÔºåÂú®Á§æÁæ§Â™íÈ´îË≤ºÊñá‰∏≠ÂÅµÊ∏¨ÊÜÇÈ¨±ÁóáËá≥ÈóúÈáçË¶Å„ÄÇÂÇ≥Áµ±Ê©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïÁ∂ìÂ∏∏ÁÑ°Ê≥ïÊçïÊçâË§áÈõúÁöÑÊñáÂ≠óÊ®°ÂºèÔºåÈôêÂà∂‰∫ÜÂÆÉÂÄëÂú®Ëæ®Ë≠òÊÜÇÈ¨±Áóá‰∏äÁöÑÊïàËÉΩ„ÄÇÁèæÊúâÁöÑÁ†îÁ©∂Êé¢Á¥¢‰∫ÜÂêÑÁ®ÆËß£Ê±∫Ê≠§ÂïèÈ°åÁöÑÊñπÊ≥ïÔºå‰ΩÜÂæÄÂæÄÂú®Ê∫ñÁ¢∫Â∫¶ÂíåÁ©©ÂÅ•ÊÄßÊñπÈù¢ÊúâÊâÄ‰∏çË∂≥„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ•ûÁ∂ìÁ∂≤Ë∑ØÊû∂ÊßãÔºåÂÆÉÂà©Áî®‰∫ÜÂü∫ÊñºËΩâÊèõÂô®ÁöÑÊ®°ÂûãÔºå‰∏¶ÁµêÂêà‰∫ÜÂÖÉË≥áÊñôÂíåË™ûË®ÄÊ®ôË®ò„ÄÇÊú¨Á†îÁ©∂Êé°Áî® DistilBERTÔºåÂæûËΩâÊèõÂô®ÁöÑÊúÄÂæåÂõõÂ±§ÊèêÂèñË≥áË®äÔºåÂ•óÁî®Â≠∏ÁøíÂà∞ÁöÑÊ¨äÈáçÔºå‰∏¶Â∞áÂÆÉÂÄëÂπ≥Âùá‰ª•Âª∫Á´ãËº∏ÂÖ•ÊñáÂ≠óÁöÑË±êÂØåË°®Âæµ„ÄÇÊ≠§Ë°®ÂæµÁî±ÂÖÉË≥áÊñôÂíåË™ûË®ÄÊ®ôË®òÂ¢ûÂº∑ÔºåÂ¢ûÂº∑‰∫ÜÊ®°ÂûãÂ∞çÊØèÂâáË≤ºÊñáÁöÑÁêÜËß£„ÄÇ‰∏≠Êñ∑Â±§Èò≤Ê≠¢ÈÅéÂ∫¶Êì¨ÂêàÔºå‰∏¶‰ΩøÁî®Â§öÂ±§ÊÑüÁü•Âô® (MLP) ÈÄ≤Ë°åÊúÄÁµÇÂàÜÈ°û„ÄÇË≥áÊñôÊì¥ÂÖÖÊäÄË°ìÔºàÂèóÁ∞°ÊòìË≥áÊñôÊì¥ÂÖÖ (EDA) ÊñπÊ≥ïÂïüÁôºÔºâ‰πüÁî®ÊñºÊîπÂñÑÊ®°ÂûãÊïàËÉΩ„ÄÇ‰ΩøÁî® BERTÔºåÈö®Ê©üÊèíÂÖ•ÂíåÊõøÊèõÁâáË™ûÊúÉÁî¢ÁîüÈ°çÂ§ñÁöÑË®ìÁ∑¥Ë≥áÊñôÔºåÈáçÈªûÂú®ÈÄèÈÅéÊì¥ÂÖÖ‰ª£Ë°®ÊÄß‰∏çË∂≥ÁöÑÈ°ûÂà•‰æÜÂπ≥Ë°°Ë≥áÊñôÈõÜ„ÄÇÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂàÜÂà•ÈÅîÂà∞‰∫ÜÂä†Ê¨äÊ∫ñÁ¢∫Áéá„ÄÅÂè¨ÂõûÁéáÂíå F1 ÂàÜÊï∏ 84.26%„ÄÅ84.18% Âíå 84.15%„ÄÇÊì¥ÂÖÖÊäÄË°ìÈ°ØËëóÊèêÂçá‰∫ÜÊ®°ÂûãÊïàËÉΩÔºåÂ∞áÂä†Ê¨ä F1 ÂàÜÊï∏Âæû 72.59% ÊèêÂçáËá≥ 84.15%„ÄÇ

##### **Beyond Scores: A Modular RAG-Based System for Automatic Short Answer Scoring with Feedback**
2409.20042v1 by Menna Fateen, Bo Wang, Tsunenori Mine

Automatic short answer scoring (ASAS) helps reduce the grading burden on
educators but often lacks detailed, explainable feedback. Existing methods in
ASAS with feedback (ASAS-F) rely on fine-tuning language models with limited
datasets, which is resource-intensive and struggles to generalize across
contexts. Recent approaches using large language models (LLMs) have focused on
scoring without extensive fine-tuning. However, they often rely heavily on
prompt engineering and either fail to generate elaborated feedback or do not
adequately evaluate it. In this paper, we propose a modular retrieval augmented
generation based ASAS-F system that scores answers and generates feedback in
strict zero-shot and few-shot learning scenarios. We design our system to be
adaptable to various educational tasks without extensive prompt engineering
using an automatic prompt generation framework. Results show an improvement in
scoring accuracy by 9\% on unseen questions compared to fine-tuning, offering a
scalable and cost-effective solution.

ÊëòË¶ÅÔºöËá™ÂãïÁ∞°Á≠îË©ïÂàÜ (ASAS) ÊúâÂä©ÊñºÊ∏õËºïÊïôËÇ≤ËÄÖÁöÑË©ïÂàÜË≤†ÊìîÔºå‰ΩÜÈÄöÂ∏∏Áº∫‰πèË©≥Á¥∞‰∏îÂèØË™™ÊòéÁöÑÂõûÈ•ã„ÄÇÁèæÊúâÁöÑ ASAS ÈôÑÂõûÈ•ã (ASAS-F) ÊñπÊ≥ï‰ª∞Ë≥¥ÂæÆË™øË™ûË®ÄÊ®°ÂûãÔºå‰ΩÜË≥áÊñôÈõÜÊúâÈôêÔºåÈÄôËÄóË≤ªË≥áÊ∫ê‰∏îÈõ£‰ª•Ê¶ÇÊã¨ÊâÄÊúâÊÉÖÂ¢É„ÄÇËøëÊúü‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊñπÊ≥ïÂ∞àÊ≥®ÊñºË©ïÂàÜÔºåËÄåÁÑ°ÈúÄÂª£Ê≥õÁöÑÂæÆË™ø„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÈÄöÂ∏∏ÈÅéÊñº‰æùË≥¥ÊèêÁ§∫Â∑•Á®ãÔºåËÄå‰∏îÁÑ°Ê≥ïÁî¢ÁîüÁ≤æÁ∑ªÁöÑÂõûÈ•ãÔºåÊàñÁÑ°Ê≥ïÂÖÖÂàÜË©ï‰º∞ÂõûÈ•ã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊ®°ÁµÑÂåñÁöÑÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÂºè ASAS-F Á≥ªÁµ±ÔºåÂÆÉËÉΩÂú®Âö¥Ê†ºÁöÑÈõ∂Ê¨°Â≠∏ÁøíÂíåÂ∞ëÊ¨°Â≠∏ÁøíÊÉÖÂ¢É‰∏≠Ë©ïÂàÜÁ≠îÊ°à‰∏¶Áî¢ÁîüÂõûÈ•ã„ÄÇÊàëÂÄëË®≠Ë®àÁ≥ªÁµ±‰ª•ÈÅ©ÊáâÂêÑÁ®ÆÊïôËÇ≤‰ªªÂãôÔºåËÄåÁÑ°ÈúÄ‰ΩøÁî®Ëá™ÂãïÊèêÁ§∫Áî¢ÁîüÊû∂ÊßãÈÄ≤Ë°åÂª£Ê≥õÁöÑÊèêÁ§∫Â∑•Á®ã„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåËàáÂæÆË™øÁõ∏ÊØîÔºåÂú®Êú™Ë¶ãÈÅéÁöÑÂïèÈ°å‰∏äÔºåË©ïÂàÜÊ∫ñÁ¢∫Â∫¶ÊèêÂçá‰∫Ü 9%ÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØÊì¥ÂÖÖ‰∏îÂÖ∑ÊúâÊàêÊú¨ÊïàÁõäÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **Towards Robust Multimodal Sentiment Analysis with Incomplete Data**
2409.20012v1 by Haoyu Zhang, Wenbin Wang, Tianshu Yu

The field of Multimodal Sentiment Analysis (MSA) has recently witnessed an
emerging direction seeking to tackle the issue of data incompleteness.
Recognizing that the language modality typically contains dense sentiment
information, we consider it as the dominant modality and present an innovative
Language-dominated Noise-resistant Learning Network (LNLN) to achieve robust
MSA. The proposed LNLN features a dominant modality correction (DMC) module and
dominant modality based multimodal learning (DMML) module, which enhances the
model's robustness across various noise scenarios by ensuring the quality of
dominant modality representations. Aside from the methodical design, we perform
comprehensive experiments under random data missing scenarios, utilizing
diverse and meaningful settings on several popular datasets (\textit{e.g.,}
MOSI, MOSEI, and SIMS), providing additional uniformity, transparency, and
fairness compared to existing evaluations in the literature. Empirically, LNLN
consistently outperforms existing baselines, demonstrating superior performance
across these challenging and extensive evaluation metrics.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÄÅÊÉÖÊÑüÂàÜÊûê (MSA) È¢ÜÂüüÊúÄËøëËßÅËØÅ‰∫Ü‰∏Ä‰∏™Êñ∞ÂÖ¥ÁöÑÊñπÂêëÔºåÊó®Âú®Ëß£ÂÜ≥Êï∞ÊçÆ‰∏çÂÆåÊï¥ÁöÑÈóÆÈ¢ò„ÄÇËÆ§ËØÜÂà∞ËØ≠Ë®ÄÊ®°ÊÄÅÈÄöÂ∏∏ÂåÖÂê´ÂØÜÈõÜÁöÑÊÉÖÊÑü‰ø°ÊÅØÔºåÊàë‰ª¨Â∞ÜÂÖ∂ËßÜ‰∏∫‰∏ªË¶ÅÊ®°ÊÄÅÔºåÂπ∂ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂàõÊñ∞ÁöÑËØ≠Ë®Ä‰∏ªÂØºÊäóÂô™Â≠¶‰π†ÁΩëÁªú (LNLN) Êù•ÂÆûÁé∞Á®≥ÂÅ•ÁöÑ MSA„ÄÇÊâÄÊèêÂá∫ÁöÑ LNLN ÂÖ∑Êúâ‰∏ªÂØºÊ®°ÊÄÅÊ†°Ê≠£ (DMC) Ê®°ÂùóÂíåÂü∫‰∫é‰∏ªÂØºÊ®°ÊÄÅÁöÑÂ§öÊ®°ÊÄÅÂ≠¶‰π† (DMML) Ê®°ÂùóÔºåÈÄöËøáÁ°Æ‰øù‰∏ªÂØºÊ®°ÊÄÅË°®Á§∫ÁöÑË¥®ÈáèÔºåÂ¢ûÂº∫‰∫ÜÊ®°ÂûãÂú®ÂêÑÁßçÂô™Â£∞Âú∫ÊôØ‰∏ãÁöÑÁ®≥ÂÅ•ÊÄß„ÄÇÈô§‰∫ÜÊñπÊ≥ïËÆæËÆ°‰πãÂ§ñÔºåÊàë‰ª¨ËøòÂú®ÈöèÊú∫Êï∞ÊçÆÁº∫Â§±Âú∫ÊôØ‰∏ãÊâßË°å‰∫ÜÁªºÂêàÂÆûÈ™åÔºåÂú®Âá†‰∏™ÊµÅË°åÁöÑÊï∞ÊçÆÈõÜÔºà‰æãÂ¶Ç MOSI„ÄÅMOSEI Âíå SIMSÔºâ‰∏äÂà©Áî®Â§öÊ†∑‰∏îÊúâÊÑè‰πâÁöÑËÆæÁΩÆÔºå‰∏éÊñáÁåÆ‰∏≠Áé∞ÊúâÁöÑËØÑ‰º∞Áõ∏ÊØîÔºåÊèê‰æõ‰∫ÜÈ¢ùÂ§ñÁöÑÁªü‰∏ÄÊÄß„ÄÅÈÄèÊòéÊÄßÂíåÂÖ¨Âπ≥ÊÄß„ÄÇÂá≠ÁªèÈ™åÔºåLNLN ÂßãÁªà‰ºò‰∫éÁé∞ÊúâÁöÑÂü∫Á∫øÔºåÂú®Ëøô‰∫õÂÖ∑ÊúâÊåëÊàòÊÄßÂíåÂπøÊ≥õÁöÑËØÑ‰º∞ÊåáÊ†á‰∏≠Â±ïÁ§∫‰∫ÜÂçìË∂äÁöÑÊÄßËÉΩ„ÄÇ

##### **Customized Information and Domain-centric Knowledge Graph Construction with Large Language Models**
2409.20010v1 by Frank Wawrzik, Matthias Plaue, Savan Vekariya, Christoph Grimm

In this paper we propose a novel approach based on knowledge graphs to
provide timely access to structured information, to enable actionable
technology intelligence, and improve cyber-physical systems planning. Our
framework encompasses a text mining process, which includes information
retrieval, keyphrase extraction, semantic network creation, and topic map
visualization. Following this data exploration process, we employ a selective
knowledge graph construction (KGC) approach supported by an electronics and
innovation ontology-backed pipeline for multi-objective decision-making with a
focus on cyber-physical systems. We apply our methodology to the domain of
automotive electrical systems to demonstrate the approach, which is scalable.
Our results demonstrate that our construction process outperforms GraphGPT as
well as our bi-LSTM and transformer REBEL with a pre-defined dataset by several
times in terms of class recognition, relationship construction and correct
"sublass of" categorization. Additionally, we outline reasoning applications
and provide a comparison with Wikidata to show the differences and advantages
of the approach.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÁü•Ë≠òÂúñË≠úÁöÑÊñ∞ÊñπÊ≥ïÔºå‰ª•Êèê‰æõÂ∞çÁµêÊßãÂåñË≥áË®äÁöÑÂç≥ÊôÇÂ≠òÂèñÔºå‰ª•ÂïüÁî®ÂèØÊìç‰ΩúÁöÑÊäÄË°ìÊÉÖÂ†±Ôºå‰∏¶ÊîπÂñÑÁ∂≤Ë∑ØÂØ¶È´îÁ≥ªÁµ±Ë¶èÂäÉ„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÂåÖÂê´‰∏ÄÂÄãÊñáÂ≠óÊé¢ÂãòÁ®ãÂ∫èÔºåÂÖ∂‰∏≠ÂåÖÊã¨Ë≥áË®äÊ™¢Á¥¢„ÄÅÈóúÈçµÂ≠óË©ûËêÉÂèñ„ÄÅË™ûÊÑèÁ∂≤Ë∑ØÂª∫Á´ãÂíå‰∏ªÈ°åÂú∞ÂúñË¶ñË¶∫Âåñ„ÄÇÂú®ÈÄôÂÄãË≥áÊñôÊé¢ÂãòÁ®ãÂ∫è‰πãÂæåÔºåÊàëÂÄëÊé°Áî®‰∏ÄÂÄãÈÅ∏ÊìáÊÄßÁöÑÁü•Ë≠òÂúñË≠úÂª∫Êßã (KGC) ÊñπÊ≥ïÔºåÁî±ÈõªÂ≠êÂíåÂâµÊñ∞Êú¨È´îÊîØÊè¥ÁöÑÁÆ°ÈÅìÊîØÊè¥ÔºåÁî®Êñº‰ª•Á∂≤Ë∑ØÂØ¶È´îÁ≥ªÁµ±ÁÇ∫ÈáçÈªûÁöÑÂ§öÁõÆÊ®ôÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÊàëÂÄëÂ∞áÊàëÂÄëÁöÑÊäÄË°ìÊáâÁî®ÊñºÊ±ΩËªäÈõªÊ∞£Á≥ªÁµ±È†òÂüüÔºå‰ª•Â±ïÁ§∫ÈÄôÁ®ÆÂèØÊì¥ÂÖÖÁöÑÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÂª∫ÊßãÁ®ãÂ∫èÂú®È°ûÂà•Ëæ®Ë≠ò„ÄÅÈóú‰øÇÂª∫ÊßãÂíåÊ≠£Á¢∫ÁöÑ„ÄåÂ≠êÈ°ûÂà•„ÄçÂàÜÈ°ûÊñπÈù¢ÔºåÊØî GraphGPT ‰ª•ÂèäÊàëÂÄë‰ΩøÁî®È†êÂÆöÁæ©Ë≥áÊñôÈõÜÁöÑÈõôÂêë LSTM Âíå Transformer REBEL Âø´Â•ΩÂπæÂÄç„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊ¶ÇËø∞Êé®ÁêÜÊáâÁî®Ôºå‰∏¶Êèê‰æõËàá Wikidata ÁöÑÊØîËºÉÔºå‰ª•È°ØÁ§∫ÈÄôÁ®ÆÊñπÊ≥ïÁöÑÂ∑ÆÁï∞ÂíåÂÑ™Èªû„ÄÇ

##### **Developing Instruction-Following Speech Language Model Without Speech Instruction-Tuning Data**
2409.20007v1 by Ke-Han Lu, Zhehuai Chen, Szu-Wei Fu, Chao-Han Huck Yang, Jagadeesh Balam, Boris Ginsburg, Yu-Chiang Frank Wang, Hung-yi Lee

Recent end-to-end speech language models (SLMs) have expanded upon the
capabilities of large language models (LLMs) by incorporating pre-trained
speech models. However, these SLMs often undergo extensive speech
instruction-tuning to bridge the gap between speech and text modalities. This
requires significant annotation efforts and risks catastrophic forgetting of
the original language capabilities. In this work, we present a simple yet
effective automatic process for creating speech-text pair data that carefully
injects speech paralinguistic understanding abilities into SLMs while
preserving the inherent language capabilities of the text-based LLM. Our model
demonstrates general capabilities for speech-related tasks without the need for
speech instruction-tuning data, achieving impressive performance on
Dynamic-SUPERB and AIR-Bench-Chat benchmarks. Furthermore, our model exhibits
the ability to follow complex instructions derived from LLMs, such as specific
output formatting and chain-of-thought reasoning. Our approach not only
enhances the versatility and effectiveness of SLMs but also reduces reliance on
extensive annotated datasets, paving the way for more efficient and capable
speech understanding systems.

ÊëòË¶ÅÔºöËøëÊúüÁöÑÁ´ØÂà∞Á´ØËØ≠Èü≥ËØ≠Ë®ÄÊ®°Âûã (SLM) Â∑≤ÈÄöËøáÊï¥ÂêàÈ¢ÑÂÖàËÆ≠ÁªÉÁöÑËØ≠Èü≥Ê®°ÂûãÔºåÊâ©Â§ß‰∫ÜÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåËøô‰∫õ SLM ÁªèÂ∏∏ËøõË°åÂπøÊ≥õÁöÑËØ≠Èü≥Êåá‰ª§ÂæÆË∞ÉÔºå‰ª•Âº•ÂêàËØ≠Èü≥ÂíåÊñáÊú¨Ê®°ÊÄÅ‰πãÈó¥ÁöÑÂ∑ÆË∑ù„ÄÇËøôÈúÄË¶ÅÂ§ßÈáèÁöÑÊ†áÊ≥®Â∑•‰ΩúÔºåÂπ∂‰∏îÊúâÁÅæÈöæÊÄßÈÅóÂøòÂéüÂßãËØ≠Ë®ÄËÉΩÂäõÁöÑÈ£éÈô©„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∏Ä‰∏™ÁÆÄÂçï‰ΩÜÊúâÊïàÁöÑËá™Âä®ÊµÅÁ®ãÊù•ÂàõÂª∫ËØ≠Èü≥ÊñáÊú¨ÂØπÊï∞ÊçÆÔºåËØ•Êï∞ÊçÆÂ∞ÜËØ≠Èü≥ÂâØËØ≠Ë®ÄÁêÜËß£ËÉΩÂäõÂ∞èÂøÉÊ≥®ÂÖ• SLMÔºåÂêåÊó∂‰øùÁïôÂü∫‰∫éÊñáÊú¨ÁöÑ LLM ÁöÑÂõ∫ÊúâËØ≠Ë®ÄËÉΩÂäõ„ÄÇÊàë‰ª¨ÁöÑÊ®°ÂûãÂ±ïÁ§∫‰∫ÜÂØπ‰∏éËØ≠Èü≥Áõ∏ÂÖ≥ÁöÑ‰ªªÂä°ÁöÑ‰∏ÄËà¨ËÉΩÂäõÔºåËÄå‰∏çÈúÄË¶ÅËØ≠Èü≥Êåá‰ª§ÂæÆË∞ÉÊï∞ÊçÆÔºåÂú® Dynamic-SUPERB Âíå AIR-Bench-Chat Âü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÁöÑÊ®°ÂûãÂ±ïÁ§∫‰∫ÜÈÅµÂæ™‰ªé LLM Ë°çÁîüÁöÑÂ§çÊùÇÊåá‰ª§ÁöÑËÉΩÂäõÔºå‰æãÂ¶ÇÁâπÂÆöÁöÑËæìÂá∫Ê†ºÂºèÂíåÊÄùÊÉ≥ÈìæÊé®ÁêÜ„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ï‰∏ç‰ªÖÂ¢ûÂº∫‰∫Ü SLM ÁöÑÂ§öÂäüËÉΩÊÄßÂíåÊúâÊïàÊÄßÔºåËÄå‰∏îÂáèÂ∞ë‰∫ÜÂØπÂ§ßÈáèÊ†áÊ≥®Êï∞ÊçÆÈõÜÁöÑ‰æùËµñÔºå‰∏∫Êõ¥È´òÊïà„ÄÅÊõ¥Âº∫Â§ßÁöÑËØ≠Èü≥ÁêÜËß£Á≥ªÁªüÈì∫Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ

##### **Model Selection with a Shapelet-based Distance Measure for Multi-source Transfer Learning in Time Series Classification**
2409.20005v1 by Jiseok Lee, Brian Kenji Iwana

Transfer learning is a common practice that alleviates the need for extensive
data to train neural networks. It is performed by pre-training a model using a
source dataset and fine-tuning it for a target task. However, not every source
dataset is appropriate for each target dataset, especially for time series. In
this paper, we propose a novel method of selecting and using multiple datasets
for transfer learning for time series classification. Specifically, our method
combines multiple datasets as one source dataset for pre-training neural
networks. Furthermore, for selecting multiple sources, our method measures the
transferability of datasets based on shapelet discovery for effective source
selection. While traditional transferability measures require considerable time
for pre-training all the possible sources for source selection of each possible
architecture, our method can be repeatedly used for every possible architecture
with a single simple computation. Using the proposed method, we demonstrate
that it is possible to increase the performance of temporal convolutional
neural networks (CNN) on time series datasets.

ÊëòË¶ÅÔºöÈÅ∑ÁßªÂ≠∏ÁøíÊòØ‰∏ÄÁ®ÆÂ∏∏Ë¶ãÁöÑÂØ¶ÂãôÔºåÂèØ‰ª•Ê∏õËºïË®ìÁ∑¥Á•ûÁ∂ìÁ∂≤Ë∑ØÊôÇÂ∞çÂ§ßÈáèË≥áÊñôÁöÑÈúÄÊ±Ç„ÄÇÂÆÉÊúÉ‰ΩøÁî®‰æÜÊ∫êË≥áÊñôÈõÜÈ†êË®ìÁ∑¥Ê®°ÂûãÔºå‰∏¶ÈáùÂ∞çÁõÆÊ®ô‰ªªÂãôÂæÆË™øÊ®°Âûã„ÄÇÁÑ∂ËÄåÔºå‰∏¶ÈùûÊØèÂÄã‰æÜÊ∫êË≥áÊñôÈõÜÈÉΩÈÅ©Áî®ÊñºÊØèÂÄãÁõÆÊ®ôË≥áÊñôÈõÜÔºåÁâπÂà•ÊòØÂ∞çÊñºÊôÇÈñìÂ∫èÂàó„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÈÅ∏ÊìáÂíå‰ΩøÁî®Â§öÂÄãË≥áÊñôÈõÜÔºå‰ª•ÈÄ≤Ë°åÊôÇÈñìÂ∫èÂàóÂàÜÈ°ûÁöÑÈÅ∑ÁßªÂ≠∏Áøí„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÂ∞áÂ§öÂÄãË≥áÊñôÈõÜÂêà‰ΩµÁÇ∫‰∏ÄÂÄã‰æÜÊ∫êË≥áÊñôÈõÜÔºå‰ª•È†êË®ìÁ∑¥Á•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÇÊ≠§Â§ñÔºåÂ∞çÊñºÈÅ∏ÊìáÂ§öÂÄã‰æÜÊ∫êÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÊúÉÊ†πÊìöÂΩ¢ÁãÄÁâπÂæµÁôºÁèæ‰æÜË°°ÈáèË≥áÊñôÈõÜÁöÑÂèØËΩâÁßªÊÄßÔºå‰ª•ÈÄ≤Ë°åÊúâÊïàÁöÑ‰æÜÊ∫êÈÅ∏Êìá„ÄÇÈõñÁÑ∂ÂÇ≥Áµ±ÁöÑÂèØËΩâÁßªÊÄßÊ∏¨ÈáèÈúÄË¶ÅÂ§ßÈáèÊôÇÈñì‰æÜÈ†êË®ìÁ∑¥ÊâÄÊúâÂèØËÉΩÁöÑ‰æÜÊ∫êÔºå‰ª•ÈÄ≤Ë°åÊØèÂÄãÂèØËÉΩÊû∂ÊßãÁöÑ‰æÜÊ∫êÈÅ∏ÊìáÔºå‰ΩÜÊàëÂÄëÁöÑÊñπÊ≥ïÂèØ‰ª•ÈáçË§áÁî®ÊñºÊØèÂÄãÂèØËÉΩÁöÑÊû∂ÊßãÔºåÂè™ÈúÄÈÄ≤Ë°å‰∏ÄÊ¨°Á∞°ÂñÆÁöÑÈÅãÁÆó„ÄÇ‰ΩøÁî®ÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÔºåÊàëÂÄëË≠âÊòé‰∫ÜÊèêÈ´òÊôÇÈñìÂ∫èÂàóË≥áÊñôÈõÜ‰∏äÊôÇÂ∫èÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÊïàËÉΩÊòØÂèØË°åÁöÑ„ÄÇ

##### **Do Influence Functions Work on Large Language Models?**
2409.19998v1 by Zhe Li, Wei Zhao, Yige Li, Jun Sun

Influence functions aim to quantify the impact of individual training data
points on a model's predictions. While extensive research has been conducted on
influence functions in traditional machine learning models, their application
to large language models (LLMs) has been limited. In this work, we conduct a
systematic study to address a key question: do influence functions work on
LLMs? Specifically, we evaluate influence functions across multiple tasks and
find that they consistently perform poorly in most settings. Our further
investigation reveals that their poor performance can be attributed to: (1)
inevitable approximation errors when estimating the iHVP component due to the
scale of LLMs, (2) uncertain convergence during fine-tuning, and, more
fundamentally, (3) the definition itself, as changes in model parameters do not
necessarily correlate with changes in LLM behavior. Our study thus suggests the
need for alternative approaches for identifying influential samples. To support
future work, our code is made available at
https://github.com/plumprc/Failures-of-Influence-Functions-in-LLMs.

ÊëòË¶ÅÔºöÂΩ±ÈüøÂáΩÊï∏Êó®Âú®ÈáèÂåñÂÄãÂà•Ë®ìÁ∑¥Ë≥áÊñôÈªûÂ∞çÊ®°ÂûãÈ†êÊ∏¨ÁöÑÂΩ±Èüø„ÄÇÈõñÁÑ∂ÈáùÂ∞çÂÇ≥Áµ±Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÂ∑≤ÈÄ≤Ë°åÂª£Ê≥õÁöÑÁ†îÁ©∂Ôºå‰ΩÜÂÖ∂Âú®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠ÁöÑÊáâÁî®ÂèóÂà∞ÈôêÂà∂„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈÄ≤Ë°å‰∏ÄÈ†ÖÁ≥ªÁµ±ÊÄßÁ†îÁ©∂‰ª•Ëß£Ê±∫‰∏ÄÂÄãÈóúÈçµÂïèÈ°åÔºöÂΩ±ÈüøÂáΩÊï∏ÊòØÂê¶ÈÅ©Áî®Êñº LLMÔºüÂÖ∑È´îËÄåË®ÄÔºåÊàëÂÄëË∑®Â§öÂÄã‰ªªÂãôË©ï‰º∞ÂΩ±ÈüøÂáΩÊï∏Ôºå‰∏¶ÁôºÁèæÂÆÉÂÄëÂú®Â§ßÂ§öÊï∏Ë®≠ÂÆö‰∏≠Ë°®ÁèæÊåÅÁ∫å‰∏ç‰Ω≥„ÄÇÊàëÂÄëÁöÑÈÄ≤‰∏ÄÊ≠•Ë™øÊü•È°ØÁ§∫ÔºåÂÖ∂Ë°®Áèæ‰∏ç‰Ω≥ÂèØÊ≠∏Âõ†ÊñºÔºö(1) Áî±Êñº LLM ÁöÑË¶èÊ®°ÔºåÂú®‰º∞Ë®à iHVP ÁµÑÊàêÈÉ®ÂàÜÊôÇÂá∫Áèæ‰∏çÂèØÈÅøÂÖçÁöÑËøë‰ººË™§Â∑ÆÔºå(2) ÂæÆË™øÊúüÈñìÁöÑ‰∏çÁ¢∫ÂÆöÊî∂ÊñÇÔºå‰ª•ÂèäÊõ¥Ê†πÊú¨Âú∞Ôºå(3) ÂÆöÁæ©Êú¨Ë∫´ÔºåÂõ†ÁÇ∫Ê®°ÂûãÂèÉÊï∏ÁöÑËÆäÂåñ‰∏¶‰∏ç‰∏ÄÂÆöËàá LLM Ë°åÁÇ∫ÁöÑËÆäÂåñÁõ∏Èóú„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÁöÑÁ†îÁ©∂Ë°®ÊòéÈúÄË¶ÅÊé°Áî®Êõø‰ª£ÊñπÊ≥ï‰æÜË≠òÂà•ÊúâÂΩ±ÈüøÂäõÁöÑÊ®£Êú¨„ÄÇÁÇ∫‰∫ÜÊîØÊåÅÊú™‰æÜÁöÑÁ†îÁ©∂ÔºåÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂ∑≤Êñº https://github.com/plumprc/Failures-of-Influence-Functions-in-LLMs ÂÖ¨Èñã„ÄÇ

##### **Mitigating Backdoor Threats to Large Language Models: Advancement and Challenges**
2409.19993v1 by Qin Liu, Wenjie Mo, Terry Tong, Jiashu Xu, Fei Wang, Chaowei Xiao, Muhao Chen

The advancement of Large Language Models (LLMs) has significantly impacted
various domains, including Web search, healthcare, and software development.
However, as these models scale, they become more vulnerable to cybersecurity
risks, particularly backdoor attacks. By exploiting the potent memorization
capacity of LLMs, adversaries can easily inject backdoors into LLMs by
manipulating a small portion of training data, leading to malicious behaviors
in downstream applications whenever the hidden backdoor is activated by the
pre-defined triggers. Moreover, emerging learning paradigms like instruction
tuning and reinforcement learning from human feedback (RLHF) exacerbate these
risks as they rely heavily on crowdsourced data and human feedback, which are
not fully controlled. In this paper, we present a comprehensive survey of
emerging backdoor threats to LLMs that appear during LLM development or
inference, and cover recent advancement in both defense and detection
strategies for mitigating backdoor threats to LLMs. We also outline key
challenges in addressing these threats, highlighting areas for future research.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈÄ≤Ê≠•È°ØËëóÂΩ±Èüø‰∫ÜÂêÑÁ®ÆÈ†òÂüüÔºåÂåÖÊã¨Á∂≤Ë∑ØÊêúÂ∞ã„ÄÅÈÜ´ÁôÇ‰øùÂÅ•ÂíåËªüÈ´îÈñãÁôº„ÄÇÁÑ∂ËÄåÔºåÈö®ËëóÈÄô‰∫õÊ®°ÂûãÁöÑÊì¥Â±ïÔºåÂÆÉÂÄëÊõ¥ÂÆπÊòìÂèóÂà∞Á∂≤Ë∑ØÂÆâÂÖ®È¢®Èö™ÁöÑÂΩ±ÈüøÔºåÁâπÂà•ÊòØÂæåÈñÄÊîªÊìä„ÄÇÈÄèÈÅéÂà©Áî® LLM Âº∑Â§ßÁöÑË®òÊÜ∂ËÉΩÂäõÔºåÂ∞çÊâãÂèØ‰ª•ÈÄèÈÅéÊìç‰Ωú‰∏ÄÂ∞èÈÉ®ÂàÜË®ìÁ∑¥Ë≥áÊñôÔºåËºïÈ¨ÜÂú∞Â∞áÂæåÈñÄÊ≥®ÂÖ• LLMÔºåÂ∞éËá¥ÊÉ°ÊÑèË°åÁÇ∫Âá∫ÁèæÂú®‰∏ãÊ∏∏ÊáâÁî®Á®ãÂºè‰∏≠ÔºåÂè™Ë¶ÅÈ†êÂÖàÂÆöÁæ©ÁöÑËß∏ÁôºÂô®ÂïüÂãï‰∫ÜÈö±ËóèÁöÑÂæåÈñÄ„ÄÇÊ≠§Â§ñÔºåÊñ∞ËààÁöÑÂ≠∏ÁøíÁØÑ‰æãÔºå‰æãÂ¶ÇÊåá‰ª§ÂæÆË™øÂíå‰æÜËá™‰∫∫È°ûÂõûÈ•ãÁöÑÂº∑ÂåñÂ≠∏Áøí (RLHF)ÔºåÊúÉÂä†ÂäáÈÄô‰∫õÈ¢®Èö™ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÂö¥Èáç‰æùË≥¥Áæ§ÁúæÂ§ñÂåÖË≥áÊñôÂíå‰∫∫È°ûÂõûÈ•ãÔºåËÄåÈÄô‰∫õË≥áÊñôÂíåÂõûÈ•ã‰∏¶Êú™ÂèóÂà∞ÂÆåÂÖ®ÊéßÂà∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈáùÂ∞ç LLM ÈñãÁôºÊàñÊé®Ë´ñÊúüÈñìÂá∫ÁèæÁöÑÊñ∞ËààÂæåÈñÄÂ®ÅËÑÖÊèêÂá∫ÂÖ®Èù¢ÁöÑË™øÊü•Ôºå‰∏¶Ê∂µËìã‰∫ÜÁ∑©Ëß£ÂæåÈñÄÂ®ÅËÑÖÁöÑÈò≤Á¶¶ÂíåÂÅµÊ∏¨Á≠ñÁï•ÁöÑÊúÄÊñ∞ÈÄ≤Â±ï„ÄÇÊàëÂÄë‰πüÊ¶ÇËø∞‰∫ÜÂõ†ÊáâÈÄô‰∫õÂ®ÅËÑÖÁöÑ‰∏ªË¶ÅÊåëÊà∞Ôºå‰∏¶ÈáçÈªûË™™ÊòéÊú™‰æÜÁ†îÁ©∂È†òÂüü„ÄÇ

##### **Predictive Speech Recognition and End-of-Utterance Detection Towards Spoken Dialog Systems**
2409.19990v1 by Oswald Zink, Yosuke Higuchi, Carlos Mullov, Alexander Waibel, Tetsunori Kobayashi

Effective spoken dialog systems should facilitate natural interactions with
quick and rhythmic timing, mirroring human communication patterns. To reduce
response times, previous efforts have focused on minimizing the latency in
automatic speech recognition (ASR) to optimize system efficiency. However, this
approach requires waiting for ASR to complete processing until a speaker has
finished speaking, which limits the time available for natural language
processing (NLP) to formulate accurate responses. As humans, we continuously
anticipate and prepare responses even while the other party is still speaking.
This allows us to respond appropriately without missing the optimal time to
speak. In this work, as a pioneering study toward a conversational system that
simulates such human anticipatory behavior, we aim to realize a function that
can predict the forthcoming words and estimate the time remaining until the end
of an utterance (EOU), using the middle portion of an utterance. To achieve
this, we propose a training strategy for an encoder-decoder-based ASR system,
which involves masking future segments of an utterance and prompting the
decoder to predict the words in the masked audio. Additionally, we develop a
cross-attention-based algorithm that incorporates both acoustic and linguistic
information to accurately detect the EOU. The experimental results demonstrate
the proposed model's ability to predict upcoming words and estimate future EOU
events up to 300ms prior to the actual EOU. Moreover, the proposed training
strategy exhibits general improvements in ASR performance.

ÊëòË¶ÅÔºöÊúâÊïàÁöÑÂè£Ë™ûÂ∞çË©±Á≥ªÁµ±Êáâ‰øÉÈÄ≤Ëá™ÁÑ∂‰∫íÂãïÔºåÁØÄÂ•èÊòéÂø´ÔºåÂèçÊò†‰∫∫È°ûÊ∫ùÈÄöÊ®°Âºè„ÄÇÁÇ∫‰∫ÜÁ∏ÆÁü≠ÂõûÊáâÊôÇÈñìÔºåÂÖàÂâçÁöÑÂä™ÂäõÈõÜ‰∏≠Âú®ÊúÄÂ∞èÂåñËá™ÂãïË™ûÈü≥Ëæ®Ë≠ò (ASR) ‰∏≠ÁöÑÂª∂ÈÅ≤Ôºå‰ª•ÊúÄ‰Ω≥ÂåñÁ≥ªÁµ±ÊïàÁéá„ÄÇÁÑ∂ËÄåÔºåÈÄôÁ®ÆÊñπÊ≥ïÈúÄË¶ÅÁ≠âÂà∞ ASR ÂÆåÊàêËôïÁêÜÔºåÁõ¥Âà∞Ë™™Ë©±ËÄÖË™™ÂÆåË©±ÁÇ∫Ê≠¢ÔºåÈÄôÈôêÂà∂‰∫ÜËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÂèØÁî®ÊñºÂà∂ÂÆöÊ∫ñÁ¢∫ÂõûÊáâÁöÑÊôÇÈñì„ÄÇ‰ΩúÁÇ∫‰∫∫È°ûÔºåÊàëÂÄëÊúÉÊåÅÁ∫åÈ†êÊúüÂíåÊ∫ñÂÇôÂõûÊáâÔºåÂç≥‰ΩøÂ∞çÊñπ‰ªçÂú®Ë™™Ë©±„ÄÇÈÄôËÆìÊàëÂÄëËÉΩÂ§†Âú®‰∏çÈåØÈÅéÊúÄÈÅ©Ë™™Ë©±ÊôÇÈñìÁöÑÊÉÖÊ≥Å‰∏ãÈÅ©Áï∂Âú∞ÂõûÊáâ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠Ôºå‰ΩúÁÇ∫Ê®°Êì¨ÈÄôÁ®Æ‰∫∫È°ûÈ†êÊúüË°åÁÇ∫ÁöÑÂ∞çË©±Á≥ªÁµ±ÁöÑÈñãÂâµÊÄßÁ†îÁ©∂ÔºåÊàëÂÄëÊó®Âú®ÂØ¶Áèæ‰∏ÄÈ†ÖÂäüËÉΩÔºåË©≤ÂäüËÉΩÂèØ‰ª•‰ΩøÁî®‰∏ÄÊÆµË©±ÁöÑ‰∏≠ÈñìÈÉ®ÂàÜ‰æÜÈ†êÊ∏¨Êé•‰∏ã‰æÜÁöÑÂ≠óË©ûÔºå‰∏¶‰º∞Ë®àÂà∞Ë©±Ë™ûÁµêÊùü (EOU) ÊâÄÂâ©ÁöÑÊôÇÈñì„ÄÇÁÇ∫ÈÅîÊàêÊ≠§ÁõÆÁöÑÔºåÊàëÂÄëÊèêÂá∫Á∑®Á¢ºÂô®Ëß£Á¢ºÂô®Âºè ASR Á≥ªÁµ±ÁöÑË®ìÁ∑¥Á≠ñÁï•ÔºåÂÖ∂‰∏≠Ê∂âÂèäÈÅÆËîΩ‰∏ÄÊÆµË©±ÁöÑÊú™‰æÜÁâáÊÆµÔºå‰∏¶ÊèêÁ§∫Ëß£Á¢ºÂô®È†êÊ∏¨ÈÅÆËîΩÈü≥Ë®ä‰∏≠ÁöÑÂ≠óË©û„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÂü∫Êñº‰∫§ÂèâÊ≥®ÊÑèÂäõÁöÑÊºîÁÆóÊ≥ïÔºåË©≤ÊºîÁÆóÊ≥ïÁµêÂêà‰∫ÜËÅ≤Â≠∏ÂíåË™ûË®ÄË≥áË®äÔºå‰ª•Ê∫ñÁ¢∫ÂÅµÊ∏¨ EOU„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÈ†êÊ∏¨ÂæåÁ∫åÂ≠óË©ûÂíå‰º∞Ë®àÊú™‰æÜ EOU ‰∫ã‰ª∂ÁöÑËÉΩÂäõÔºåÂú®ÂØ¶Èöõ EOU ‰πãÂâçÊúÄÂ§öÂèØÈÅî 300 ÊØ´Áßí„ÄÇÊ≠§Â§ñÔºåÊâÄÊèêÂá∫ÁöÑË®ìÁ∑¥Á≠ñÁï•Âú® ASR ÊïàËÉΩÊñπÈù¢Â±ïÁèæ‰∫Ü‰∏ÄËà¨ÊÄßÁöÑÊîπÈÄ≤„ÄÇ

##### **CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models**
2409.19984v1 by Eitan Wagner, Yuli Slavutsky, Omri Abend

Although language model scores are often treated as probabilities, their
reliability as probability estimators has mainly been studied through
calibration, overlooking other aspects. In particular, it is unclear whether
language models produce the same value for different ways of assigning joint
probabilities to word spans. Our work introduces a novel framework, ConTestS
(Consistency Testing over Spans), involving statistical tests to assess score
consistency across interchangeable completion and conditioning orders. We
conduct experiments on post-release real and synthetic data to eliminate
training effects. Our findings reveal that both Masked Language Models (MLMs)
and autoregressive models exhibit inconsistent predictions, with autoregressive
models showing larger discrepancies. Larger MLMs tend to produce more
consistent predictions, while autoregressive models show the opposite trend.
Moreover, for both model types, prediction entropies offer insights into the
true word span likelihood and therefore can aid in selecting optimal decoding
strategies. The inconsistencies revealed by our analysis, as well their
connection to prediction entropies and differences between model types, can
serve as useful guides for future research on addressing these limitations.

ÊëòË¶ÅÔºöÂÑòÁÆ°Ë™ûË®ÄÊ®°ÂûãÂàÜÊï∏ÈÄöÂ∏∏Ë¢´Ë¶ñÁÇ∫Ê©üÁéáÔºå‰ΩÜÂÖ∂‰ΩúÁÇ∫Ê©üÁéá‰º∞Ë®àÂô®ÁöÑÂèØÈù†ÊÄß‰∏ªË¶ÅÈÄèÈÅéÊ†°Ê∫ñ‰æÜÁ†îÁ©∂ÔºåÂøΩË¶ñ‰∫ÜÂÖ∂‰ªñÈù¢Âêë„ÄÇÁâπÂà•ÊòØ‰∏çÊ∏ÖÊ•öË™ûË®ÄÊ®°ÂûãÊòØÂê¶Â∞çÊåáÂÆöË©ûÂΩôÁØÑÂúçÁöÑËÅØÂêàÊ©üÁéáÁöÑ‰∏çÂêåÊñπÂºèÁî¢ÁîüÁõ∏ÂêåÁöÑÂÄº„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÊû∂ÊßãÔºåConTestSÔºàË∑®ÁØÑÂúçÁöÑ‰∏ÄËá¥ÊÄßÊ∏¨Ë©¶ÔºâÔºåÊ∂âÂèäÁµ±Ë®àÊ∏¨Ë©¶‰ª•Ë©ï‰º∞ÂèØ‰∫íÊèõÂÆåÊàêÂíåÊ¢ù‰ª∂È†ÜÂ∫è‰πãÈñìÁöÑÂàÜÊï∏‰∏ÄËá¥ÊÄß„ÄÇÊàëÂÄëÂ∞çÁôºÂ∏ÉÂæåÁöÑÁúüÂØ¶ÂíåÂêàÊàêË≥áÊñôÈÄ≤Ë°åÂØ¶È©óÔºå‰ª•Ê∂àÈô§Ë®ìÁ∑¥ÊïàÊûú„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåÈÅÆËîΩË™ûË®ÄÊ®°Âûã (MLM) ÂíåËá™Ëø¥Ê≠∏Ê®°ÂûãÈÉΩÊúÉÁî¢Áîü‰∏ç‰∏ÄËá¥ÁöÑÈ†êÊ∏¨ÔºåËÄåËá™Ëø¥Ê≠∏Ê®°ÂûãÈ°ØÁ§∫Âá∫Êõ¥Â§ßÁöÑÂ∑ÆÁï∞„ÄÇËºÉÂ§ßÁöÑ MLM ÂÇæÂêëÊñºÁî¢ÁîüÊõ¥‰∏ÄËá¥ÁöÑÈ†êÊ∏¨ÔºåËÄåËá™Ëø¥Ê≠∏Ê®°ÂûãÂâáÈ°ØÁ§∫Áõ∏ÂèçÁöÑË∂®Âã¢„ÄÇÊ≠§Â§ñÔºåÂ∞çÊñºÈÄôÂÖ©Á®ÆÊ®°ÂûãÈ°ûÂûãÔºåÈ†êÊ∏¨ÁÜµÊèê‰æõ‰∫ÜÂ∞çÁúüÂØ¶Ë©ûÂΩôÁØÑÂúçÊ©üÁéáÁöÑË¶ãËß£ÔºåÂõ†Ê≠§ÊúâÂä©ÊñºÈÅ∏ÊìáÊúÄ‰Ω≥Ëß£Á¢ºÁ≠ñÁï•„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÊè≠Á§∫ÁöÑ‰∏ç‰∏ÄËá¥ÊÄßÔºå‰ª•ÂèäÂÆÉÂÄëËàáÈ†êÊ∏¨ÁÜµÂíåÊ®°ÂûãÈ°ûÂûã‰πãÈñìÁöÑÂ∑ÆÁï∞ÔºåÂèØ‰ª•‰ΩúÁÇ∫Êú™‰æÜÁ†îÁ©∂Ëß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÁöÑÊúâÁî®ÊåáÂçó„ÄÇ

##### **Enhancing High-order Interaction Awareness in LLM-based Recommender Model**
2409.19979v2 by Xinfeng Wang, Jin Cui, Fumiyo Fukumoto, Yoshimi Suzuki

Large language models (LLMs) have demonstrated prominent reasoning
capabilities in recommendation tasks by transforming them into text-generation
tasks. However, existing approaches either disregard or ineffectively model the
user-item high-order interactions. To this end, this paper presents an enhanced
LLM-based recommender (ELMRec). We enhance whole-word embeddings to
substantially enhance LLMs' interpretation of graph-constructed interactions
for recommendations, without requiring graph pre-training. This finding may
inspire endeavors to incorporate rich knowledge graphs into LLM-based
recommenders via whole-word embedding. We also found that LLMs often recommend
items based on users' earlier interactions rather than recent ones, and present
a reranking solution. Our ELMRec outperforms state-of-the-art (SOTA) methods in
both direct and sequential recommendations.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Ë≠âÊòéÂú®Êé®Ëñ¶‰ªªÂãô‰∏≠ÂÖ∑ÊúâÈ°ØËëóÁöÑÊé®ÁêÜËÉΩÂäõÔºåÊñπÊ≥ïÊòØÂ∞áÂÖ∂ËΩâÊèõÁÇ∫ÊñáÊú¨ÁîüÊàê‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÊñπÊ≥ï‰∏çÊòØÂøΩÁï•Áî®Êà∂È†ÖÁõÆÈ´òÈöé‰∫íÂãïÔºåÂ∞±ÊòØÂ∞çÂÖ∂Âª∫Ê®°ÊïàÊûú‰∏ç‰Ω≥„ÄÇÁÇ∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂ¢ûÂº∑ÁöÑÂü∫Êñº LLM ÁöÑÊé®Ëñ¶Âô® (ELMRec)„ÄÇÊàëÂÄëÂ¢ûÂº∑‰∫ÜÂÖ®Ë©ûÂµåÂÖ•Ôºå‰ª•Â§ßÂπÖÂ¢ûÂº∑ LLM Â∞çÂúñÂΩ¢ÊßãÂª∫‰∫íÂãïÁöÑËß£ËÆÄÔºåÁî®ÊñºÊé®Ëñ¶ÔºåËÄå‰∏çÈúÄË¶ÅÂúñÂΩ¢È†êË®ìÁ∑¥„ÄÇÈÄô‰∏ÄÁôºÁèæÂèØËÉΩÊúÉÊøÄÂãµÂ∞áË±êÂØåÁöÑÁü•Ë≠òÂúñË≠úÈÄöÈÅéÂÖ®Ë©ûÂµåÂÖ•Êï¥ÂêàÂà∞Âü∫Êñº LLM ÁöÑÊé®Ëñ¶Âô®‰∏≠ÁöÑÂä™Âäõ„ÄÇÊàëÂÄëÈÇÑÁôºÁèæÔºåLLM ÈÄöÂ∏∏Ê†πÊìöÁî®Êà∂Êó©ÊúüÁöÑ‰∫íÂãïËÄåÈùûÊúÄËøëÁöÑ‰∫íÂãï‰æÜÊé®Ëñ¶È†ÖÁõÆÔºå‰∏¶ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÈáçÊñ∞ÊéíÂ∫èÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÊàëÂÄëÁöÑ ELMRec Âú®Áõ¥Êé•ÂíåÈ†ÜÂ∫èÊé®Ëñ¶‰∏≠ÈÉΩÂÑ™ÊñºÊúÄÂÖàÈÄ≤ (SOTA) ÊñπÊ≥ï„ÄÇ

##### **Knowledge Graph Embedding by Normalizing Flows**
2409.19977v1 by Changyi Xiao, Xiangnan He, Yixin Cao

A key to knowledge graph embedding (KGE) is to choose a proper representation
space, e.g., point-wise Euclidean space and complex vector space. In this
paper, we propose a unified perspective of embedding and introduce uncertainty
into KGE from the view of group theory. Our model can incorporate existing
models (i.e., generality), ensure the computation is tractable (i.e.,
efficiency) and enjoy the expressive power of complex random variables (i.e.,
expressiveness). The core idea is that we embed entities/relations as elements
of a symmetric group, i.e., permutations of a set. Permutations of different
sets can reflect different properties of embedding. And the group operation of
symmetric groups is easy to compute. In specific, we show that the embedding of
many existing models, point vectors, can be seen as elements of a symmetric
group. To reflect uncertainty, we first embed entities/relations as
permutations of a set of random variables. A permutation can transform a simple
random variable into a complex random variable for greater expressiveness,
called a normalizing flow. We then define scoring functions by measuring the
similarity of two normalizing flows, namely NFE. We construct several
instantiating models and prove that they are able to learn logical rules.
Experimental results demonstrate the effectiveness of introducing uncertainty
and our model. The code is available at https://github.com/changyi7231/NFE.

ÊëòË¶ÅÔºöÁü•Ë≠òÂúñË≠úÂµåÂÖ• (KGE) ÁöÑÈóúÈçµÂú®ÊñºÈÅ∏ÊìáÈÅ©Áï∂ÁöÑË°®Á§∫Á©∫ÈñìÔºå‰æãÂ¶ÇÈªûÁãÄÊ≠êÂπæÈáåÂæóÁ©∫ÈñìÂíåË§áÊï∏ÂêëÈáèÁ©∫Èñì„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂµåÂÖ•ÁöÑÁµ±‰∏ÄËßÄÈªûÔºå‰∏¶ÂæûÁæ§Ë´ñÁöÑËßíÂ∫¶Â∞á‰∏çÁ¢∫ÂÆöÊÄßÂºïÂÖ• KGE„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ª•Êï¥ÂêàÁèæÊúâÊ®°ÂûãÔºàÂç≥‰∏ÄËà¨ÊÄßÔºâÔºåÁ¢∫‰øùË®àÁÆóÊòØÂèØË°åÁöÑÔºàÂç≥ÊïàÁéáÔºâÔºå‰∏¶‰∫´ÊúâË§áÊï∏Èö®Ê©üËÆäÊï∏ÁöÑË°®ÈÅîËÉΩÂäõÔºàÂç≥Ë°®ÈÅîÊÄßÔºâ„ÄÇÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÊàëÂÄëÂ∞áÂØ¶È´î/Èóú‰øÇÂµåÂÖ•ÁÇ∫Â∞çÁ®±Áæ§ÁöÑÂÖÉÁ¥†ÔºåÂç≥ÈõÜÂêàÁöÑÊéíÂàó„ÄÇ‰∏çÂêåÈõÜÂêàÁöÑÊéíÂàóÂèØ‰ª•ÂèçÊò†ÂµåÂÖ•ÁöÑ‰∏çÂêåÂ±¨ÊÄß„ÄÇËÄåÂ∞çÁ®±Áæ§ÁöÑÁæ§ÈÅãÁÆóÂæàÂÆπÊòìË®àÁÆó„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëË°®ÊòéË®±Â§öÁèæÊúâÊ®°ÂûãÁöÑÂµåÂÖ•ÔºåÈªûÂêëÈáèÔºåÂèØ‰ª•Áúã‰ΩúÊòØÂ∞çÁ®±Áæ§ÁöÑÂÖÉÁ¥†„ÄÇÁÇ∫‰∫ÜÂèçÊò†‰∏çÁ¢∫ÂÆöÊÄßÔºåÊàëÂÄëÈ¶ñÂÖàÂ∞áÂØ¶È´î/Èóú‰øÇÂµåÂÖ•ÁÇ∫‰∏ÄÁµÑÈö®Ê©üËÆäÊï∏ÁöÑÊéíÂàó„ÄÇ‰∏ÄÂÄãÊéíÂàóÂèØ‰ª•Â∞á‰∏ÄÂÄãÁ∞°ÂñÆÁöÑÈö®Ê©üËÆäÊï∏ËΩâÊèõÁÇ∫‰∏ÄÂÄãË§áÈõúÁöÑÈö®Ê©üËÆäÊï∏‰ª•Áç≤ÂæóÊõ¥Â§ßÁöÑË°®ÈÅîËÉΩÂäõÔºåÁ®±ÁÇ∫Ê≠£Ë¶èÂåñÊµÅ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÈÄöÈÅéÊ∏¨ÈáèÂÖ©ÂÄãÊ≠£Ë¶èÂåñÊµÅÁöÑÁõ∏‰ººÊÄß‰æÜÂÆöÁæ©Ë©ïÂàÜÂáΩÊï∏ÔºåÂç≥ NFE„ÄÇÊàëÂÄëÊßãÂª∫‰∫ÜÂπæÂÄãÂØ¶‰æãÂåñÊ®°ÂûãÔºå‰∏¶Ë≠âÊòéÂÆÉÂÄëËÉΩÂ§†Â≠∏ÁøíÈÇèËºØË¶èÂâá„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÂºïÂÖ•‰∏çÁ¢∫ÂÆöÊÄßÂíåÊàëÂÄëÊ®°ÂûãÁöÑÊúâÊïàÊÄß„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/changyi7231/NFE ÂèñÂæó„ÄÇ

##### **Multimodal LLM Enhanced Cross-lingual Cross-modal Retrieval**
2409.19961v1 by Yabing Wang, Le Wang, Qiang Zhou, Zhibin Wang, Hao Li, Gang Hua, Wei Tang

Cross-lingual cross-modal retrieval (CCR) aims to retrieve visually relevant
content based on non-English queries, without relying on human-labeled
cross-modal data pairs during training. One popular approach involves utilizing
machine translation (MT) to create pseudo-parallel data pairs, establishing
correspondence between visual and non-English textual data. However, aligning
their representations poses challenges due to the significant semantic gap
between vision and text, as well as the lower quality of non-English
representations caused by pre-trained encoders and data noise. To overcome
these challenges, we propose LECCR, a novel solution that incorporates the
multi-modal large language model (MLLM) to improve the alignment between visual
and non-English representations. Specifically, we first employ MLLM to generate
detailed visual content descriptions and aggregate them into multi-view
semantic slots that encapsulate different semantics. Then, we take these
semantic slots as internal features and leverage them to interact with the
visual features. By doing so, we enhance the semantic information within the
visual features, narrowing the semantic gap between modalities and generating
local visual semantics for subsequent multi-level matching. Additionally, to
further enhance the alignment between visual and non-English features, we
introduce softened matching under English guidance. This approach provides more
comprehensive and reliable inter-modal correspondences between visual and
non-English features. Extensive experiments on four CCR benchmarks, \ie
Multi30K, MSCOCO, VATEX, and MSR-VTT-CN, demonstrate the effectiveness of our
proposed method. Code: \url{https://github.com/LiJiaBei-7/leccr}.

ÊëòË¶ÅÔºöË∑®Ë™ûË®ÄË∑®Ê®°ÊÖãÊ™¢Á¥¢ (CCR) Êó®Âú®Ê†πÊìöÈùûËã±Ë™ûÊü•Ë©¢Ê™¢Á¥¢Ë¶ñË¶∫Áõ∏ÈóúÂÖßÂÆπÔºåËÄåÁÑ°ÈúÄÂú®Ë®ìÁ∑¥ÈÅéÁ®ã‰∏≠‰æùË≥¥‰∫∫Â∑•Ê®ôË®òÁöÑË∑®Ê®°ÊÖãË≥áÊñôÂ∞ç„ÄÇ‰∏ÄÁ®ÆÊµÅË°åÁöÑÊñπÊ≥ïÊ∂âÂèäÂà©Áî®Ê©üÂô®ÁøªË≠Ø (MT) ‰æÜÂª∫Á´ãÂÅΩÂπ≥Ë°åË≥áÊñôÂ∞çÔºåÂª∫Á´ãË¶ñË¶∫ËàáÈùûËã±Ë™ûÊñáÊú¨Ë≥áÊñô‰πãÈñìÁöÑÂ∞çÊáâÈóú‰øÇ„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºË¶ñË¶∫ËàáÊñáÊú¨‰πãÈñìÂ≠òÂú®È°ØËëóÁöÑË™ûÁæ©Â∑ÆË∑ùÔºå‰ª•ÂèäÈ†êË®ìÁ∑¥Á∑®Á¢ºÂô®ÂíåË≥áÊñôÈõúË®äÈÄ†ÊàêÁöÑÈùûËã±Ë™ûË°®Á§∫ÂìÅË≥™ËºÉ‰ΩéÔºåÂõ†Ê≠§Â∞çÈΩäÂÖ∂Ë°®Á§∫ÊúÉÂ∏∂‰æÜÊåëÊà∞„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü LECCRÔºåÈÄôÊòØ‰∏ÄÁ®ÆÁµêÂêàÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) ‰æÜÊîπÂñÑË¶ñË¶∫ËàáÈùûËã±Ë™ûË°®Á§∫‰πãÈñìÂ∞çÈΩäÁöÑÊñ∞Á©éËß£Ê±∫ÊñπÊ°à„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈ¶ñÂÖà‰ΩøÁî® MLLM ‰æÜÁî¢ÁîüË©≥Á¥∞ÁöÑË¶ñË¶∫ÂÖßÂÆπÊèèËø∞Ôºå‰∏¶Â∞áÂÆÉÂÄëÂåØÁ∏ΩÂà∞ÂåÖÂê´‰∏çÂêåË™ûÁæ©ÁöÑÂ§öË¶ñËßíË™ûÁæ©ÊßΩ‰∏≠„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂ∞áÈÄô‰∫õË™ûÁæ©ÊßΩ‰ΩúÁÇ∫ÂÖßÈÉ®ÁâπÂæµÔºå‰∏¶Âà©Áî®ÂÆÉÂÄëËàáË¶ñË¶∫ÁâπÂæµÈÄ≤Ë°å‰∫íÂãï„ÄÇÈÄèÈÅéÈÄôÊ®£ÂÅöÔºåÊàëÂÄëÂ¢ûÂº∑‰∫ÜË¶ñË¶∫ÁâπÂæµ‰∏≠ÁöÑË™ûÁæ©Ë≥áË®äÔºåÁ∏ÆÂ∞è‰∫ÜÊ®°ÊÖã‰πãÈñìÁöÑË™ûÁæ©Â∑ÆË∑ùÔºå‰∏¶ÁÇ∫ÂæåÁ∫åÁöÑÂ§öÂ±§Ê¨°ÂåπÈÖçÁî¢Áîü‰∫ÜÂ±ÄÈÉ®Ë¶ñË¶∫Ë™ûÁæ©„ÄÇÊ≠§Â§ñÔºåÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•Â¢ûÂº∑Ë¶ñË¶∫ËàáÈùûËã±Ë™ûÁâπÂæµ‰πãÈñìÁöÑÂ∞çÈΩäÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂú®Ëã±Ë™ûÊåáÂ∞é‰∏ãÁöÑËªüÂåñÂåπÈÖç„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÊèê‰æõ‰∫ÜË¶ñË¶∫ËàáÈùûËã±Ë™ûÁâπÂæµ‰πãÈñìÊõ¥ÂÖ®Èù¢‰∏îÂèØÈù†ÁöÑË∑®Ê®°ÊÖãÂ∞çÊáâÈóú‰øÇ„ÄÇÂú®ÂõõÂÄã CCR Âü∫Ê∫ñ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óÔºåÂç≥ Multi30K„ÄÅMSCOCO„ÄÅVATEX Âíå MSR-VTT-CNÔºåË≠âÊòé‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÁ®ãÂºèÁ¢ºÔºö\url{https://github.com/LiJiaBei-7/leccr}„ÄÇ

##### **TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning**
2409.19960v1 by Joshua Feinglass, Yezhou Yang

Zero-shot inference, where pre-trained models perform tasks without specific
training data, is an exciting emergent ability of large models like CLIP.
Although there has been considerable exploration into enhancing zero-shot
abilities in image captioning (IC) for popular datasets such as MSCOCO and
Flickr8k, these approaches fall short with fine-grained datasets like CUB, FLO,
UCM-Captions, and Sydney-Captions. These datasets require captions to discern
between visually and semantically similar classes, focusing on detailed object
parts and their attributes. To overcome this challenge, we introduce
TRaining-Free Object-Part Enhancement (TROPE). TROPE enriches a base caption
with additional object-part details using object detector proposals and Natural
Language Processing techniques. It complements rather than alters the base
caption, allowing seamless integration with other captioning methods and
offering users enhanced flexibility. Our evaluations show that TROPE
consistently boosts performance across all tested zero-shot IC approaches and
achieves state-of-the-art results on fine-grained IC datasets.

ÊëòË¶ÅÔºöÈõ∂Ê¨°Â≠∏ÁøíÊé®ÁêÜÔºåÂÖ∂‰∏≠È†êË®ìÁ∑¥Ê®°ÂûãÂú®Ê≤íÊúâÁâπÂÆöË®ìÁ∑¥Ë≥áÊñôÁöÑÊÉÖÊ≥Å‰∏ãÂü∑Ë°å‰ªªÂãôÔºåÊòØ CLIP Á≠âÂ§ßÂûãÊ®°Âûã‰ª§‰∫∫ËààÂ•ÆÁöÑÊñ∞ËààËÉΩÂäõ„ÄÇÂÑòÁÆ°Â∑≤Á∂ìÂ∞çÂ¢ûÂº∑ÊµÅË°åË≥áÊñôÈõÜÔºà‰æãÂ¶Ç MSCOCO Âíå Flickr8kÔºâ‰∏≠ÂΩ±ÂÉèÊ®ôÈ°åÔºàICÔºâÁöÑÈõ∂Ê¨°Â≠∏ÁøíËÉΩÂäõÈÄ≤Ë°å‰∫ÜÂ§ßÈáèÁöÑÊé¢Á¥¢Ôºå‰ΩÜÈÄô‰∫õÊñπÊ≥ïÂú® CUB„ÄÅFLO„ÄÅUCM-Captions Âíå Sydney-Captions Á≠âÁ¥∞Á≤íÂ∫¶Ë≥áÊñôÈõÜ‰∏ä‰ªçÊúâ‰∏çË∂≥„ÄÇÈÄô‰∫õË≥áÊñôÈõÜÈúÄË¶ÅÊ®ôÈ°å‰æÜÂçÄÂàÜË¶ñË¶∫‰∏äÂíåË™ûÁæ©‰∏äÁõ∏‰ººÁöÑÈ°ûÂà•ÔºåÈáçÈªûÈóúÊ≥®Ë©≥Á¥∞ÁöÑÁâ©‰ª∂ÈÉ®ÂàÜÂèäÂÖ∂Â±¨ÊÄß„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄôÂÄãÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÁÑ°Ë®ìÁ∑¥Áâ©‰ª∂ÈÉ®ÂàÜÂ¢ûÂº∑ÔºàTROPEÔºâ„ÄÇTROPE ‰ΩøÁî®Áâ©‰ª∂ÂÅµÊ∏¨Âª∫Ë≠∞ÂíåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÊäÄË°ìÔºå‰ΩøÁî®È°çÂ§ñÁöÑÁâ©‰ª∂ÈÉ®ÂàÜÁ¥∞ÁØÄ‰æÜË±êÂØåÂü∫Êú¨Ê®ôÈ°å„ÄÇÂÆÉË£úÂÖÖËÄå‰∏çÊòØÊîπËÆäÂü∫Êú¨Ê®ôÈ°åÔºåÂÖÅË®±ËàáÂÖ∂‰ªñÊ®ôÈ°åÊñπÊ≥ïÁÑ°Á∏´Êï¥ÂêàÔºå‰∏¶ÁÇ∫‰ΩøÁî®ËÄÖÊèê‰æõÂ¢ûÂº∑ÁöÑÈùàÊ¥ªÊÄß„ÄÇÊàëÂÄëÁöÑË©ï‰º∞Ë°®ÊòéÔºåTROPE Âú®ÊâÄÊúâÊ∏¨Ë©¶ÁöÑÈõ∂Ê¨°Â≠∏Áøí IC ÊñπÊ≥ï‰∏≠ÊåÅÁ∫åÊèêÂçáÊïàËÉΩÔºå‰∏¶Âú®Á¥∞Á≤íÂ∫¶ IC Ë≥áÊñôÈõÜ‰∏äÂèñÂæóÊúÄÂÖàÈÄ≤ÁöÑÁµêÊûú„ÄÇ

##### **Attribute-Text Guided Forgetting Compensation for Lifelong Person Re-Identification**
2409.19954v1 by Shiben Liu, Huijie Fan, Qiang Wang, Weihong Ren, Yandong Tang

Lifelong person re-identification (LReID) aims to continuously learn from
non-stationary data to match individuals in different environments. Each task
is affected by variations in illumination and person-related information (such
as pose and clothing), leading to task-wise domain gaps. Current LReID methods
focus on task-specific knowledge and ignore intrinsic task-shared
representations within domain gaps, limiting model performance. Bridging
task-wise domain gaps is crucial for improving anti-forgetting and
generalization capabilities, especially when accessing limited old classes
during training. To address these issues, we propose a novel attribute-text
guided forgetting compensation (ATFC) model, which explores text-driven global
representations of identity-related information and attribute-related local
representations of identity-free information for LReID. Due to the lack of
paired text-image data, we design an attribute-text generator (ATG) to
dynamically generate a text descriptor for each instance. We then introduce a
text-guided aggregation network (TGA) to explore robust text-driven global
representations for each identity and knowledge transfer. Furthermore, we
propose an attribute compensation network (ACN) to investigate
attribute-related local representations, which distinguish similar identities
and bridge domain gaps. Finally, we develop an attribute anti-forgetting (AF)
loss and knowledge transfer (KT) loss to minimize domain gaps and achieve
knowledge transfer, improving model performance. Extensive experiments
demonstrate that our ATFC method achieves superior performance, outperforming
existing LReID methods by over 9.0$\%$/7.4$\%$ in average mAP/R-1 on the seen
dataset.

ÊëòË¶ÅÔºöÁµÇË∫´‰∫∫Áâ©ÂÜçË≠òÂà• (LReID) Êó®Âú®ÊåÅÁ∫åÂæûÈùûÂπ≥Á©©Ë≥áÊñô‰∏≠Â≠∏ÁøíÔºå‰ª•Âú®‰∏çÂêåÁí∞Â¢É‰∏≠ÊØîÂ∞çÂÄã‰∫∫„ÄÇÊØèÂÄã‰ªªÂãôÈÉΩÊúÉÂèóÂà∞ÂÖâÁÖßÂíåÂÄã‰∫∫Áõ∏ÈóúË≥áË®äÔºà‰æãÂ¶ÇÂßøÂã¢ÂíåÊúçË£ùÔºâÁöÑËÆäÂåñÂΩ±ÈüøÔºåÂ∞éËá¥‰ªªÂãôÈñìÁöÑÈ†òÂüüÂ∑ÆË∑ù„ÄÇÁõÆÂâçÁöÑ LReID ÊñπÊ≥ïÂ∞àÊ≥®Êñº‰ªªÂãôÁâπÂÆöÁü•Ë≠òÔºåËÄåÂøΩÁï•È†òÂüüÂ∑ÆË∑ùÂÖßÁöÑÂÖßÂú®‰ªªÂãôÂÖ±‰∫´Ë°®ÂæµÔºåÈôêÂà∂‰∫ÜÊ®°ÂûãÊïàËÉΩ„ÄÇÂΩåÂêà‰ªªÂãôÈñìÁöÑÈ†òÂüüÂ∑ÆË∑ùÂ∞çÊñºÊèêÂçáÊäóÈÅ∫ÂøòÂíåÊ¶ÇÂåñËÉΩÂäõËá≥ÈóúÈáçË¶ÅÔºåÂ∞§ÂÖ∂ÊòØÂú®Ë®ìÁ∑¥ÊúüÈñìÂ≠òÂèñÂèóÈôêÁöÑËàäÈ°ûÂà•ÊôÇ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÂ±¨ÊÄßÊñáÂ≠óÂºïÂ∞éÈÅ∫ÂøòË£úÂÑü (ATFC) Ê®°ÂûãÔºåÊé¢Á¥¢ËàáË∫´ÂàÜÁõ∏ÈóúË≥áË®äÁöÑÊñáÂ≠óÈ©ÖÂãïÂÖ®Â±ÄË°®ÂæµÔºå‰ª•Âèä LReID Ë∫´ÂàÜÁÑ°ÈóúË≥áË®äÁöÑÂ±¨ÊÄßÁõ∏ÈóúÂ±ÄÈÉ®Ë°®Âæµ„ÄÇÁî±ÊñºÁº∫‰πèÊàêÂ∞çÊñáÂ≠óÂΩ±ÂÉèË≥áÊñôÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂ±¨ÊÄßÊñáÂ≠óÁî¢ÁîüÂô® (ATG) ‰æÜÂãïÊÖãÁî¢ÁîüÊØèÂÄãÂØ¶‰æãÁöÑÊñáÂ≠óÊèèËø∞Á¨¶„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÂÄãÊñáÂ≠óÂºïÂ∞éËÅöÂêàÁ∂≤Ë∑Ø (TGA) ‰æÜÊé¢Á¥¢ÊØèÂÄãË∫´ÂàÜÁöÑÂº∑ÂÅ•ÊñáÂ≠óÈ©ÖÂãïÂÖ®Â±ÄË°®ÂæµÂíåÁü•Ë≠òÂÇ≥ÈÅû„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂ±¨ÊÄßË£úÂÑüÁ∂≤Ë∑Ø (ACN) ‰æÜÊé¢Ë®éÂ±¨ÊÄßÁõ∏ÈóúÁöÑÂ±ÄÈÉ®Ë°®ÂæµÔºåÂçÄÂàÜÁõ∏‰ººÁöÑË∫´ÂàÜ‰∏¶ÂΩåÂêàÈ†òÂüüÂ∑ÆË∑ù„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÂ±¨ÊÄßÊäóÈÅ∫Âøò (AF) ÊêçÂ§±ÂíåÁü•Ë≠òÂÇ≥ÈÅû (KT) ÊêçÂ§±Ôºå‰ª•ÊúÄÂ∞èÂåñÈ†òÂüüÂ∑ÆË∑ù‰∏¶ÂØ¶ÁèæÁü•Ë≠òÂÇ≥ÈÅûÔºåÊèêÂçáÊ®°ÂûãÊïàËÉΩ„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºåÊàëÂÄëÁöÑ ATFC ÊñπÊ≥ïÂØ¶Áèæ‰∫ÜÂçìË∂äÁöÑÊïàËÉΩÔºåÂú®Â∑≤Ë¶ãË≥áÊñôÈõÜ‰∏ä‰ª•Âπ≥Âùá mAP/R-1 Ë∂ÖÈÅé 9.0% / 7.4% ÁöÑÂπÖÂ∫¶ÂÑ™ÊñºÁèæÊúâÁöÑ LReID ÊñπÊ≥ï„ÄÇ

##### **Law of the Weakest Link: Cross Capabilities of Large Language Models**
2409.19951v1 by Ming Zhong, Aston Zhang, Xuewei Wang, Rui Hou, Wenhan Xiong, Chenguang Zhu, Zhengxing Chen, Liang Tan, Chloe Bi, Mike Lewis, Sravya Popuri, Sharan Narang, Melanie Kambadur, Dhruv Mahajan, Sergey Edunov, Jiawei Han, Laurens van der Maaten

The development and evaluation of Large Language Models (LLMs) have largely
focused on individual capabilities. However, this overlooks the intersection of
multiple abilities across different types of expertise that are often required
for real-world tasks, which we term cross capabilities. To systematically
explore this concept, we first define seven core individual capabilities and
then pair them to form seven common cross capabilities, each supported by a
manually constructed taxonomy. Building on these definitions, we introduce
CrossEval, a benchmark comprising 1,400 human-annotated prompts, with 100
prompts for each individual and cross capability. To ensure reliable
evaluation, we involve expert annotators to assess 4,200 model responses,
gathering 8,400 human ratings with detailed explanations to serve as reference
examples. Our findings reveal that, in both static evaluations and attempts to
enhance specific abilities, current LLMs consistently exhibit the "Law of the
Weakest Link," where cross-capability performance is significantly constrained
by the weakest component. Specifically, across 58 cross-capability scores from
17 models, 38 scores are lower than all individual capabilities, while 20 fall
between strong and weak, but closer to the weaker ability. These results
highlight the under-performance of LLMs in cross-capability tasks, making the
identification and improvement of the weakest capabilities a critical priority
for future research to optimize performance in complex, multi-dimensional
scenarios.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈñãÁôºÂíåË©ï‰º∞‰∏ªË¶ÅÈõÜ‰∏≠Âú®ÂÄãÂà•ËÉΩÂäõ‰∏ä„ÄÇÁÑ∂ËÄåÔºåÈÄôÂøΩÁï•‰∫ÜÂú®ÁèæÂØ¶‰∏ñÁïå‰ªªÂãô‰∏≠ÈÄöÂ∏∏ÈúÄË¶ÅÁöÑ‰∏çÂêåÈ°ûÂûãÂ∞àÊ•≠Áü•Ë≠òÈñìÂ§öÁ®ÆËÉΩÂäõÁöÑ‰∫§ÈõÜÔºåÊàëÂÄëÁ®±‰πãÁÇ∫‰∫§ÂèâËÉΩÂäõ„ÄÇÁÇ∫‰∫ÜÁ≥ªÁµ±ÊÄßÂú∞Êé¢Ë®éÈÄôÂÄãÊ¶ÇÂøµÔºåÊàëÂÄëÈ¶ñÂÖàÂÆöÁæ©‰∫Ü‰∏ÉÈ†ÖÊ†∏ÂøÉÂÄãÂà•ËÉΩÂäõÔºåÁÑ∂ÂæåÂ∞áÂÆÉÂÄëÈÖçÂ∞çÂΩ¢Êàê‰∏ÉÈ†ÖÂ∏∏Ë¶ãÁöÑ‰∫§ÂèâËÉΩÂäõÔºåÊØèÈ†ÖÈÉΩÁî±‰∫∫Â∑•ÊßãÂª∫ÁöÑÂàÜÈ°ûÊ≥ïÊîØÊåÅ„ÄÇÂª∫Á´ãÂú®ÈÄô‰∫õÂÆöÁæ©‰πã‰∏äÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü CrossEvalÔºå‰∏ÄÂÄãÂåÖÂê´ 1,400 ÂÄã‰∫∫È°ûË®ªËß£ÊèêÁ§∫ÁöÑÂü∫Ê∫ñÔºåÊØèÂÄãÂÄãÂà•Âíå‰∫§ÂèâËÉΩÂäõÊúâ 100 ÂÄãÊèêÁ§∫„ÄÇÁÇ∫‰∫ÜÁ¢∫‰øùÂèØÈù†ÁöÑË©ï‰º∞ÔºåÊàëÂÄëËÆìÂ∞àÂÆ∂Ë®ªËß£ËÄÖË©ï‰º∞ 4,200 ÂÄãÊ®°ÂûãÂõûÊáâÔºåÊî∂ÈõÜ 8,400 ÂÄãÂ∏∂ÊúâË©≥Á¥∞Ë™™ÊòéÁöÑ‰∫∫È°ûË©ïÂàÜ‰ΩúÁÇ∫ÂèÉËÄÉÁØÑ‰æã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåÂú®ÈùúÊÖãË©ï‰º∞ÂíåÂòóË©¶Â¢ûÂº∑ÁâπÂÆöËÉΩÂäõÊôÇÔºåÁõÆÂâçÁöÑ LLM ÊåÅÁ∫åÂ±ïÁèæ„ÄåÊúÄÂº±Áí∞ÁØÄÊ≥ïÂâá„ÄçÔºåÂÖ∂‰∏≠‰∫§ÂèâËÉΩÂäõÁöÑË°®ÁèæÈ°ØËëóÂú∞ÂèóÂà∞ÊúÄÂº±ÁµÑÊàêÁöÑÈôêÂà∂„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÂú® 17 ÂÄãÊ®°ÂûãÁöÑ 58 ÂÄã‰∫§ÂèâËÉΩÂäõÂàÜÊï∏‰∏≠ÔºåÊúâ 38 ÂÄãÂàÜÊï∏‰ΩéÊñºÊâÄÊúâÂÄãÂà•ËÉΩÂäõÔºåËÄå 20 ÂÄã‰ªãÊñºÂº∑ÂíåÂº±‰πãÈñìÔºå‰ΩÜÊõ¥Êé•ËøëËºÉÂº±ÁöÑËÉΩÂäõ„ÄÇÈÄô‰∫õÁµêÊûúÁ™ÅÈ°Ø‰∫Ü LLM Âú®‰∫§ÂèâËÉΩÂäõ‰ªªÂãô‰∏≠ÁöÑË°®Áèæ‰∏ç‰Ω≥Ôºå‰ΩøÂæóË≠òÂà•ÂíåÊîπÂñÑÊúÄÂº±ÁöÑËÉΩÂäõÊàêÁÇ∫Êú™‰æÜÁ†îÁ©∂ÂÑ™ÂåñË§áÈõú„ÄÅÂ§öÁ∂≠Â∫¶Â†¥ÊôØ‰∏≠Ë°®ÁèæÁöÑÈóúÈçµÂÑ™ÂÖà‰∫ãÈ†Ö„ÄÇ

##### **Task-agnostic Pre-training and Task-guided Fine-tuning for Versatile Diffusion Planner**
2409.19949v1 by Chenyou Fan, Chenjia Bai, Zhao Shan, Haoran He, Yang Zhang, Zhen Wang

Diffusion models have demonstrated their capabilities in modeling
trajectories of multi-tasks. However, existing multi-task planners or policies
typically rely on task-specific demonstrations via multi-task imitation, or
require task-specific reward labels to facilitate policy optimization via
Reinforcement Learning (RL). To address these challenges, we aim to develop a
versatile diffusion planner that can leverage large-scale inferior data that
contains task-agnostic sub-optimal trajectories, with the ability to fast adapt
to specific tasks. In this paper, we propose \textbf{SODP}, a two-stage
framework that leverages \textbf{S}ub-\textbf{O}ptimal data to learn a
\textbf{D}iffusion \textbf{P}lanner, which is generalizable for various
downstream tasks. Specifically, in the pre-training stage, we train a
foundation diffusion planner that extracts general planning capabilities by
modeling the versatile distribution of multi-task trajectories, which can be
sub-optimal and has wide data coverage. Then for downstream tasks, we adopt
RL-based fine-tuning with task-specific rewards to fast refine the diffusion
planner, which aims to generate action sequences with higher task-specific
returns. Experimental results from multi-task domains including Meta-World and
Adroit demonstrate that SODP outperforms state-of-the-art methods with only a
small amount of data for reward-guided fine-tuning.

ÊëòË¶ÅÔºöÊì¥Êï£Ê®°ÂûãÂ∑≤Â±ïÁèæÂÖ∂Âú®Ê®°Êì¨Â§ö‰ªªÂãôËªåË∑°‰∏äÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÂ§ö‰ªªÂãôË¶èÂäÉÂô®ÊàñÁ≠ñÁï•ÈÄöÂ∏∏‰æùË≥¥ÊñºÈÄèÈÅéÂ§ö‰ªªÂãôÊ®°‰ªøÈÄ≤Ë°åÁâπÂÆö‰ªªÂãôÁöÑÁ§∫ÁØÑÔºåÊàñÈúÄË¶ÅÁâπÂÆö‰ªªÂãôÁöÑÁçéÂãµÊ®ôÁ±§‰ª•ÈÄèÈÅéÂº∑ÂåñÂ≠∏Áøí (RL) ‰øÉÈÄ≤Á≠ñÁï•ÊúÄ‰Ω≥Âåñ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊó®Âú®ÈñãÁôº‰∏ÄÂÄãÂ§öÂäüËÉΩÊì¥Êï£Ë¶èÂäÉÂô®ÔºåË©≤Ë¶èÂäÉÂô®ÂèØ‰ª•Âà©Áî®ÂåÖÂê´Ëàá‰ªªÂãôÁÑ°ÈóúÁöÑÊ¨°‰Ω≥ËªåË∑°ÁöÑÂ§ßË¶èÊ®°Âä£Ë≥™Ë≥áÊñôÔºå‰∏¶ÂÖ∑ÂÇôÂø´ÈÄüÈÅ©ÊáâÁâπÂÆö‰ªªÂãôÁöÑËÉΩÂäõ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂÖ©ÈöéÊÆµÊû∂Êßã **SODP**ÔºåÂÆÉÂà©Áî® **S**ub-**O**ptimal Ë≥áÊñô‰æÜÂ≠∏Áøí‰∏ÄÂÄã **D**iffusion **P**lannerÔºåË©≤Ë¶èÂäÉÂô®ÂèØ‰ª•Ê≥õÂåñÂà∞ÂêÑÁ®Æ‰∏ãÊ∏∏‰ªªÂãô„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÂú®È†êË®ìÁ∑¥ÈöéÊÆµÔºåÊàëÂÄëË®ìÁ∑¥‰∏ÄÂÄãÂü∫Á§éÊì¥Êï£Ë¶èÂäÉÂô®ÔºåÂÆÉÈÄèÈÅéÊ®°Êì¨Â§ö‰ªªÂãôËªåË∑°ÁöÑÂ§öÂäüËÉΩÂàÜ‰Ωà‰æÜÊèêÂèñ‰∏ÄËà¨Ë¶èÂäÉËÉΩÂäõÔºåË©≤ÂàÜ‰ΩàÂèØ‰ª•ÊòØÊ¨°‰Ω≥ÁöÑÔºå‰∏¶‰∏îÂÖ∑ÊúâÂª£Ê≥õÁöÑË≥áÊñôÊ∂µËìãÁØÑÂúç„ÄÇÁÑ∂ÂæåÔºåÂ∞çÊñº‰∏ãÊ∏∏‰ªªÂãôÔºåÊàëÂÄëÊé°Áî®Âü∫Êñº RL ÁöÑÂæÆË™øÔºå‰∏¶‰ΩøÁî®ÁâπÂÆö‰ªªÂãôÁöÑÁçéÂãµ‰æÜÂø´ÈÄüÂæÆË™øÊì¥Êï£Ë¶èÂäÉÂô®ÔºåÂÖ∂ÁõÆÁöÑÊòØÁîüÊàêÂÖ∑ÊúâËºÉÈ´ò‰ªªÂãôÁâπÂÆöÂõûÂ†±ÁöÑÂãï‰ΩúÂ∫èÂàó„ÄÇ‰æÜËá™Â§ö‰ªªÂãôÈ†òÂüüÔºàÂåÖÊã¨ Meta-World Âíå AdroitÔºâÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåSODP Âú®ÂÉÖ‰ΩøÁî®Â∞ëÈáèË≥áÊñôÈÄ≤Ë°åÁçéÂãµÂºïÂ∞éÂæÆË™øÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ï„ÄÇ

##### **JaPOC: Japanese Post-OCR Correction Benchmark using Vouchers**
2409.19948v1 by Masato Fujitake

In this paper, we create benchmarks and assess the effectiveness of error
correction methods for Japanese vouchers in OCR (Optical Character Recognition)
systems. It is essential for automation processing to correctly recognize
scanned voucher text, such as the company name on invoices. However, perfect
recognition is complex due to the noise, such as stamps. Therefore, it is
crucial to correctly rectify erroneous OCR results. However, no publicly
available OCR error correction benchmarks for Japanese exist, and methods have
not been adequately researched. In this study, we measured text recognition
accuracy by existing services on Japanese vouchers and developed a post-OCR
correction benchmark. Then, we proposed simple baselines for error correction
using language models and verified whether the proposed method could
effectively correct these errors. In the experiments, the proposed error
correction algorithm significantly improved overall recognition accuracy.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂª∫Á´ãÂü∫Ê∫ñ‰∏¶Ë©ï‰º∞ÂÖâÂ≠∏Â≠óÂÖÉËæ®Ë≠ò (OCR) Á≥ªÁµ±‰∏≠Êó•ÊñáÊÜëË≠âÈåØË™§Ê†°Ê≠£ÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÊ≠£Á¢∫Ëæ®Ë≠òÊéÉÊèèÁöÑÊÜëË≠âÊñáÂ≠óÔºà‰æãÂ¶ÇÁôºÁ•®‰∏äÁöÑÂÖ¨Âè∏ÂêçÁ®±ÔºâÂ∞çÊñºËá™ÂãïÂåñËôïÁêÜËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÂç∞Á´†Á≠âÈõúË®äÔºåÂÆåÁæéÁöÑËæ®Ë≠òÂæàË§áÈõú„ÄÇÂõ†Ê≠§ÔºåÊ≠£Á¢∫‰øÆÊ≠£ÈåØË™§ÁöÑ OCR ÁµêÊûúËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÊ≤íÊúâÂÖ¨ÈñãÂèØÁî®ÁöÑÊó•Êñá OCR ÈåØË™§Ê†°Ê≠£Âü∫Ê∫ñÔºå‰∏îÊñπÊ≥ïÂ∞öÊú™ÂæóÂà∞ÂÖÖÂàÜÁ†îÁ©∂„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊ∏¨Èáè‰∫ÜÁèæÊúâÊúçÂãôÂ∞çÊó•ÊñáÊÜëË≠âÁöÑÊñáÂ≠óËæ®Ë≠òÊ∫ñÁ¢∫Â∫¶Ôºå‰∏¶ÈñãÁôº‰∫Ü‰∏ÄÂÄã OCR ÂæåÊ†°Ê≠£Âü∫Ê∫ñ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰ΩøÁî®Ë™ûË®ÄÊ®°ÂûãÈÄ≤Ë°åÈåØË™§Ê†°Ê≠£ÁöÑÁ∞°ÂñÆÂü∫Á∑öÔºå‰∏¶È©óË≠âÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÊòØÂê¶ÂèØ‰ª•ÊúâÊïàÊ†°Ê≠£ÈÄô‰∫õÈåØË™§„ÄÇÂú®ÂØ¶È©ó‰∏≠ÔºåÊâÄÊèêÂá∫ÁöÑÈåØË™§Ê†°Ê≠£ÊºîÁÆóÊ≥ïÈ°ØËëóÊèêÈ´ò‰∫ÜÊï¥È´îËæ®Ë≠òÊ∫ñÁ¢∫Â∫¶„ÄÇ

##### **Positive-Sum Fairness: Leveraging Demographic Attributes to Achieve Fair AI Outcomes Without Sacrificing Group Gains**
2409.19940v1 by Samia Belhadj, Sanguk Park, Ambika Seth, Hesham Dar, Thijs Kooi

Fairness in medical AI is increasingly recognized as a crucial aspect of
healthcare delivery. While most of the prior work done on fairness emphasizes
the importance of equal performance, we argue that decreases in fairness can be
either harmful or non-harmful, depending on the type of change and how
sensitive attributes are used. To this end, we introduce the notion of
positive-sum fairness, which states that an increase in performance that
results in a larger group disparity is acceptable as long as it does not come
at the cost of individual subgroup performance. This allows sensitive
attributes correlated with the disease to be used to increase performance
without compromising on fairness.
  We illustrate this idea by comparing four CNN models that make different use
of the race attribute in the training phase. The results show that removing all
demographic encodings from the images helps close the gap in performance
between the different subgroups, whereas leveraging the race attribute as a
model's input increases the overall performance while widening the disparities
between subgroups. These larger gaps are then put in perspective of the
collective benefit through our notion of positive-sum fairness to distinguish
harmful from non harmful disparities.

ÊëòË¶ÅÔºöÈÜ´ÁôÇ AI ‰∏≠ÁöÑÂÖ¨Âπ≥ÊÄßÊó•ÁõäË¢´Ë¶ñÁÇ∫ÈÜ´ÁôÇ‰øùÂÅ•Êèê‰æõ‰∏≠Ëá≥ÈóúÈáçË¶ÅÁöÑ‰∏ÄÁí∞„ÄÇÈõñÁÑ∂Â§ßÂ§öÊï∏ÂÖàÂâçÈóúÊñºÂÖ¨Âπ≥ÊÄßÁöÑÁ†îÁ©∂ÈÉΩÂº∑Ë™øÂêåÁ≠âË°®ÁèæÁöÑÈáçË¶ÅÊÄßÔºåÊàëÂÄëË™çÁÇ∫ÂÖ¨Âπ≥ÊÄßÁöÑ‰∏ãÈôçÂèØËÉΩÊòØÊúâÂÆ≥ÁöÑÊàñÁÑ°ÂÆ≥ÁöÑÔºåÂÖ∑È´îÂèñÊ±∫ÊñºËÆäÂåñÁöÑÈ°ûÂûãÂíåÊïèÊÑüÂ±¨ÊÄßÁöÑ‰ΩøÁî®ÊñπÂºè„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÊ≠£ÂíåÂÖ¨Âπ≥ÊÄßÁöÑÊ¶ÇÂøµÔºåÂÆÉÊåáÂá∫ÔºåÂè™Ë¶Å‰∏ç‰ª•ÁäßÁâ≤ÂÄãÂà•Â≠êÁæ§È´îË°®ÁèæÁÇ∫‰ª£ÂÉπÔºåÈÇ£È∫ºÂ∞éËá¥Áæ§È´îÂ∑ÆÁï∞Êõ¥Â§ßÁöÑË°®ÁèæÊèêÂçáÊòØÂèØ‰ª•Êé•ÂèóÁöÑ„ÄÇÈÄôÂÖÅË®±Â∞áËàáÁñæÁóÖÁõ∏ÈóúÁöÑÊïèÊÑüÂ±¨ÊÄßÁî®ÊñºÊèêÈ´òË°®ÁèæÔºåËÄå‰∏çÊúÉÊêçÂÆ≥ÂÖ¨Âπ≥ÊÄß„ÄÇ
ÊàëÂÄëÈÄöÈÅéÊØîËºÉÂõõÂÄãÂú®Ë®ìÁ∑¥ÈöéÊÆµÂ∞çÁ®ÆÊóèÂ±¨ÊÄß‰ΩøÁî®‰∏çÂêåÁöÑ CNN Ê®°Âûã‰æÜË™™ÊòéÈÄôÂÄãÊÉ≥Ê≥ï„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåÂæûÂúñÂÉè‰∏≠ÁßªÈô§ÊâÄÊúâ‰∫∫Âè£Á∑®Á¢ºÊúâÂä©ÊñºÁ∏ÆÂ∞è‰∏çÂêåÂ≠êÁæ§È´î‰πãÈñìÁöÑË°®ÁèæÂ∑ÆË∑ùÔºåËÄåÂ∞áÁ®ÆÊóèÂ±¨ÊÄßÁî®‰ΩúÊ®°ÂûãÁöÑËº∏ÂÖ•ÊúÉÊèêÈ´òÊï¥È´îË°®ÁèæÔºåÂêåÊôÇÊì¥Â§ßÂ≠êÁæ§È´î‰πãÈñìÁöÑÂ∑ÆÁï∞„ÄÇÁÑ∂ÂæåÔºåÈÄöÈÅéÊàëÂÄëÊ≠£ÂíåÂÖ¨Âπ≥ÊÄßÁöÑÊ¶ÇÂøµÂ∞áÈÄô‰∫õÊõ¥Â§ßÁöÑÂ∑ÆË∑ùÁΩÆÊñºÊï¥È´îÊïàÁõäÁöÑËßíÂ∫¶Ôºå‰ª•ÂçÄÂàÜÊúâÂÆ≥ÂíåÁÑ°ÂÆ≥ÁöÑÂ∑ÆÁï∞„ÄÇ

##### **Large Language Model Empowered Embedding Generator for Sequential Recommendation**
2409.19925v1 by Qidong Liu, Xian Wu, Wanyu Wang, Yejing Wang, Yuanshao Zhu, Xiangyu Zhao, Feng Tian, Yefeng Zheng

Sequential Recommender Systems (SRS) are extensively applied across various
domains to predict users' next interaction by modeling their interaction
sequences. However, these systems typically grapple with the long-tail problem,
where they struggle to recommend items that are less popular. This challenge
results in a decline in user discovery and reduced earnings for vendors,
negatively impacting the system as a whole. Large Language Model (LLM) has the
potential to understand the semantic connections between items, regardless of
their popularity, positioning them as a viable solution to this dilemma. In our
paper, we present LLMEmb, an innovative technique that harnesses LLM to create
item embeddings that bolster the performance of SRS. To align the capabilities
of general-purpose LLM with the needs of the recommendation domain, we
introduce a method called Supervised Contrastive Fine-Tuning (SCFT). This
method involves attribute-level data augmentation and a custom contrastive loss
designed to tailor LLM for enhanced recommendation performance. Moreover, we
highlight the necessity of incorporating collaborative filtering signals into
LLM-generated embeddings and propose Recommendation Adaptation Training (RAT)
for this purpose. RAT refines the embeddings to be optimally suited for SRS.
The embeddings derived from LLMEmb can be easily integrated with any SRS model,
showcasing its practical utility. Extensive experimentation on three real-world
datasets has shown that LLMEmb significantly improves upon current methods when
applied across different SRS models.

ÊëòË¶ÅÔºöÂ∫èÂàóÊé®Ëñ¶Á≥ªÁµ± (SRS) Âª£Ê≥õÊáâÁî®ÊñºÂêÑÁ®ÆÈ†òÂüüÔºåÈÄèÈÅéÂª∫Ê®°‰ΩøÁî®ËÄÖÁöÑ‰∫íÂãïÂ∫èÂàó‰æÜÈ†êÊ∏¨‰ªñÂÄëÁöÑ‰∏ã‰∏ÄÂÄã‰∫íÂãï„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÁ≥ªÁµ±ÈÄöÂ∏∏ÊúÉÈÅáÂà∞Èï∑Â∞æÂïèÈ°åÔºå‰πüÂ∞±ÊòØÈõ£‰ª•Êé®Ëñ¶ËºÉ‰∏çÂèóÊ≠°ËøéÁöÑÈ†ÖÁõÆ„ÄÇÊ≠§ÊåëÊà∞Â∞éËá¥‰ΩøÁî®ËÄÖÊé¢Á¥¢Ê∏õÂ∞ëÔºå‰ª•Âèä‰æõÊáâÂïÜÊî∂ÁõäÈôç‰ΩéÔºåÂ∞çÁ≥ªÁµ±Êï¥È´îÈÄ†ÊàêË≤†Èù¢ÂΩ±Èüø„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊúâÊΩõÂäõ‰∫ÜËß£È†ÖÁõÆ‰πãÈñìÁöÑË™ûÁæ©ÈóúËÅØÔºåËÄå‰∏çÁÆ°ÂÖ∂ÂèóÊ≠°ËøéÁ®ãÂ∫¶Â¶Ç‰ΩïÔºå‰ΩøÂÖ∂ÊàêÁÇ∫Ëß£Ê±∫Ê≠§Âõ∞Â¢ÉÁöÑÂèØË°åÊñπÊ°à„ÄÇÂú®ÊàëÂÄëÁöÑË´ñÊñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ LLMEmbÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊäÄË°ìÔºåÂà©Áî® LLM ‰æÜÂª∫Á´ãÈ†ÖÁõÆÂµåÂÖ•Ôºå‰ª•ÊèêÂçá SRS ÁöÑÊïàËÉΩ„ÄÇÁÇ∫‰∫ÜÂ∞áÈÄöÁî® LLM ÁöÑÂäüËÉΩËàáÊé®Ëñ¶È†òÂüüÁöÑÈúÄÊ±ÇÁµêÂêàÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÁ®ÆÁ®±ÁÇ∫Áõ£Áù£Â∞çÊØîÂæÆË™ø (SCFT) ÁöÑÊñπÊ≥ï„ÄÇÊ≠§ÊñπÊ≥ïÊ∂âÂèäÂ±¨ÊÄßÂ±§Á¥öË≥áÊñôÊì¥ÂÖÖÂíåËá™Ë®ÇÂ∞çÊØîÊêçÂ§±ÔºåÊó®Âú®Ë™øÊï¥ LLM ‰ª•Â¢ûÂº∑Êé®Ëñ¶ÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂº∑Ë™øÂ∞áÂçîÂêåÈÅéÊøæË®äËôüÁ¥çÂÖ• LLM ÁîüÊàêÁöÑÂµåÂÖ•ÁöÑÂøÖË¶ÅÊÄßÔºå‰∏¶ÊèêÂá∫Êé®Ëñ¶ÈÅ©ÊáâË®ìÁ∑¥ (RAT) ‰ª•ÈÅîÂà∞Ê≠§ÁõÆÁöÑ„ÄÇRAT ÊúÉË™øÊï¥ÂµåÂÖ•Ôºå‰ΩøÂÖ∂ÊúÄÈÅ©Âêà SRS„ÄÇÂæû LLMEmb Ë°çÁîüÁöÑÂµåÂÖ•ÂèØ‰ª•ËºïÈ¨ÜËàá‰ªª‰Ωï SRS Ê®°ÂûãÊï¥ÂêàÔºåÂ±ïÁ§∫ÂÖ∂ÂØ¶Áî®ÊÄß„ÄÇÂú®‰∏âÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óÈ°ØÁ§∫ÔºåLLMEmb Âú®ÊáâÁî®Êñº‰∏çÂêå SRS Ê®°ÂûãÊôÇÔºåÈ°ØËëóÂÑ™ÊñºÁõÆÂâçÁöÑÊñπÊ≥ï„ÄÇ

##### **On The Planning Abilities of OpenAI's o1 Models: Feasibility, Optimality, and Generalizability**
2409.19924v2 by Kevin Wang, Junbo Li, Neel P. Bhatt, Yihan Xi, Qiang Liu, Ufuk Topcu, Zhangyang Wang

Recent advancements in Large Language Models (LLMs) have showcased their
ability to perform complex reasoning tasks, but their effectiveness in planning
remains underexplored. In this study, we evaluate the planning capabilities of
OpenAI's o1 models across a variety of benchmark tasks, focusing on three key
aspects: feasibility, optimality, and generalizability. Through empirical
evaluations on constraint-heavy tasks (e.g., $\textit{Barman}$,
$\textit{Tyreworld}$) and spatially complex environments (e.g.,
$\textit{Termes}$, $\textit{Floortile}$), we highlight o1-preview's strengths
in self-evaluation and constraint-following, while also identifying bottlenecks
in decision-making and memory management, particularly in tasks requiring
robust spatial reasoning. Our results reveal that o1-preview outperforms GPT-4
in adhering to task constraints and managing state transitions in structured
environments. However, the model often generates suboptimal solutions with
redundant actions and struggles to generalize effectively in spatially complex
tasks. This pilot study provides foundational insights into the planning
limitations of LLMs, offering key directions for future research on improving
memory management, decision-making, and generalization in LLM-based planning.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂ±ïÁ§∫‰∫ÜÂÆÉÂÄëÂü∑Ë°åË§áÈõúÊé®ÁêÜ‰ªªÂãôÁöÑËÉΩÂäõÔºå‰ΩÜÂÆÉÂÄëÂú®Ë¶èÂäÉ‰∏≠ÁöÑÊúâÊïàÊÄß‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Ë®é„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëË©ï‰º∞‰∫Ü OpenAI ÁöÑ o1 Ê®°ÂûãÂú®ÂêÑÁ®ÆÂü∫Ê∫ñ‰ªªÂãô‰∏≠ÁöÑË¶èÂäÉËÉΩÂäõÔºåÈáçÈªûÈóúÊ≥®‰∏âÂÄãÈóúÈçµÊñπÈù¢ÔºöÂèØË°åÊÄß„ÄÅÊúÄÂÑ™ÊÄßÂíåÂèØÊ¶ÇÊã¨ÊÄß„ÄÇÈÄöÈÅéÂ∞çÁ¥ÑÊùüÁπÅÈáçÁöÑ‰ªªÂãôÔºà‰æãÂ¶ÇÔºå$\textit{Barman}$„ÄÅ$\textit{Tyreworld}$ÔºâÂíåÁ©∫ÈñìË§áÈõúÁí∞Â¢ÉÔºà‰æãÂ¶ÇÔºå$\textit{Termes}$„ÄÅ$\textit{Floortile}$ÔºâÁöÑÁ∂ìÈ©óË©ï‰º∞ÔºåÊàëÂÄëÂº∑Ë™ø‰∫Ü o1-preview Âú®Ëá™ÊàëË©ï‰º∞ÂíåÁ¥ÑÊùüÈÅµÂæ™ÊñπÈù¢ÁöÑÂÑ™Âã¢ÔºåÂêåÊôÇ‰πüÁôºÁèæ‰∫ÜÊ±∫Á≠ñÂà∂ÂÆöÂíåË®òÊÜ∂È´îÁÆ°ÁêÜ‰∏≠ÁöÑÁì∂È†∏ÔºåÁâπÂà•ÊòØÂú®ÈúÄË¶ÅÂº∑Â§ßÁöÑÁ©∫ÈñìÊé®ÁêÜËÉΩÂäõÁöÑ‰ªªÂãô‰∏≠„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåo1-preview Âú®ÈÅµÂÆà‰ªªÂãôÁ¥ÑÊùüÂíåÁÆ°ÁêÜÁµêÊßãÂåñÁí∞Â¢É‰∏≠ÁöÑÁãÄÊÖãËΩâÊèõÊñπÈù¢ÂÑ™Êñº GPT-4„ÄÇÁÑ∂ËÄåÔºåË©≤Ê®°ÂûãÈÄöÂ∏∏ÊúÉÁîüÊàêÂÖ∑ÊúâÂÜóÈ§òÂãï‰ΩúÁöÑÊ¨°ÂÑ™Ëß£Ôºå‰∏¶‰∏îÈõ£‰ª•Âú®Á©∫ÈñìË§áÈõúÁöÑ‰ªªÂãô‰∏≠ÊúâÊïàÊ¶ÇÊã¨„ÄÇÈÄôÈ†ÖË©¶ÈªûÁ†îÁ©∂Êèê‰æõ‰∫ÜÂ∞ç LLM Ë¶èÂäÉÈôêÂà∂ÁöÑÂü∫Êú¨Ë¶ãËß£ÔºåÁÇ∫ÊîπÈÄ≤Âü∫Êñº LLM ÁöÑË¶èÂäÉ‰∏≠ÁöÑË®òÊÜ∂È´îÁÆ°ÁêÜ„ÄÅÊ±∫Á≠ñÂà∂ÂÆöÂíåÊ¶ÇÊã¨Êèê‰æõ‰∫ÜÊú™‰æÜÁ†îÁ©∂ÁöÑ‰∏ªË¶ÅÊñπÂêë„ÄÇ

##### **Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Object-Oriented Programming**
2409.19916v1 by Ming Li, Ziqian Bi, Tianyang Wang, Keyu Chen, Jiawei Xu, Qian Niu, Junyu Liu, Benji Peng, Sen Zhang, Xuanhe Pan, Jinlang Wang, Pohsun Feng, Caitlyn Heqi Yin, Yizhu Wen, Ming Liu

Object-Oriented Programming (OOP) has become a crucial paradigm for managing
the growing complexity of modern software systems, particularly in fields like
machine learning, deep learning, large language models (LLM), and data
analytics. This work provides a comprehensive introduction to the integration
of OOP techniques within these domains, with a focus on improving code
modularity, maintainability, and scalability. We begin by outlining the
evolution of computing and the rise of OOP, followed by an in-depth discussion
of key OOP principles such as encapsulation, inheritance, polymorphism, and
abstraction. The practical application of these principles is demonstrated
using Python, a widely adopted language in AI and data science. Furthermore, we
examine how design patterns and modular programming can be employed to enhance
the structure and efficiency of machine learning systems. In subsequent
sections, we apply these OOP concepts to real-world AI tasks, including the
encapsulation of preprocessing workflows, machine learning model training, and
evaluation. Detailed examples illustrate how OOP can be used to build reusable,
scalable machine learning systems while maintaining code clarity and reducing
redundancy.This work is intended to serve as a bridge for both beginners and
experienced developers, equipping them with the necessary knowledge to apply
OOP methodologies in AI-driven projects, ultimately fostering the development
of more robust and maintainable systems.

ÊëòË¶ÅÔºö<paragraph>Áâ©‰ª∂Â∞éÂêëÁ®ãÂºèË®≠Ë®àÔºàOOPÔºâÂ∑≤ÊàêÁÇ∫ÁÆ°ÁêÜÁèæ‰ª£ËªüÈ´îÁ≥ªÁµ±Êó•ÁõäÂ¢ûÂä†ÁöÑË§áÈõúÊÄßÁöÑÈóúÈçµÁØÑ‰æãÔºåÁâπÂà•ÊòØÂú®Ê©üÂô®Â≠∏Áøí„ÄÅÊ∑±Â∫¶Â≠∏Áøí„ÄÅÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂíåË≥áÊñôÂàÜÊûêÁ≠âÈ†òÂüü„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊèê‰æõ‰∫ÜÂ∞á OOP ÊäÄË°ìÊï¥ÂêàÂà∞ÈÄô‰∫õÈ†òÂüüÁöÑÂÖ®Èù¢ÊÄß‰ªãÁ¥πÔºåÈáçÈªûÂú®ÊñºÊîπÂñÑÁ®ãÂºèÁ¢ºÁöÑÊ®°ÁµÑÂåñ„ÄÅÂèØÁ∂≠Ë≠∑ÊÄßÂíåÂèØÊì¥ÂÖÖÊÄß„ÄÇÊàëÂÄëÂæûÊ¶ÇËø∞ÈÅãÁÆóÁöÑÊºîÈÄ≤Âíå OOP ÁöÑËààËµ∑ÈñãÂßãÔºåÊé•ËëóÊ∑±ÂÖ•Êé¢Ë®éÂ∞ÅË£ù„ÄÅÁπºÊâø„ÄÅÂ§öÂûãÂíåÊäΩË±°ÂåñÁ≠â OOP ÂéüÂâá„ÄÇÈÄô‰∫õÂéüÂâáÁöÑÂØ¶ÈöõÊáâÁî®ÊòØ‰ΩøÁî® Python ‰æÜÂ±ïÁ§∫ÔºåPython ÊòØ AI ÂíåË≥áÊñôÁßëÂ≠∏‰∏≠Âª£Ê≥õÊé°Áî®ÁöÑË™ûË®Ä„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®éË®≠Ë®àÊ®°ÂºèÂíåÊ®°ÁµÑÂåñÁ®ãÂºèË®≠Ë®àÂ¶Ç‰ΩïÁî®ÊñºÂ¢ûÂº∑Ê©üÂô®Â≠∏ÁøíÁ≥ªÁµ±ÁöÑÁµêÊßãÂíåÊïàÁéá„ÄÇÂú®ÂæåÁ∫åÁöÑÁ´†ÁØÄ‰∏≠ÔºåÊàëÂÄëÂ∞áÈÄô‰∫õ OOP Ê¶ÇÂøµÊáâÁî®ÊñºÁúüÂØ¶‰∏ñÁïåÁöÑ AI ‰ªªÂãôÔºåÂåÖÊã¨È†êËôïÁêÜÂ∑•‰ΩúÊµÅÁ®ãÁöÑÂ∞ÅË£ù„ÄÅÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãË®ìÁ∑¥ÂíåË©ï‰º∞„ÄÇË©≥Á¥∞ÁØÑ‰æãË™™ÊòéÂ¶Ç‰Ωï‰ΩøÁî® OOP ‰æÜÂª∫ÊßãÂèØÈáçË§á‰ΩøÁî®„ÄÅÂèØÊì¥ÂÖÖÁöÑÊ©üÂô®Â≠∏ÁøíÁ≥ªÁµ±ÔºåÂêåÊôÇ‰øùÊåÅÁ®ãÂºèÁ¢ºÊ∏ÖÊô∞Â∫¶‰∏¶Ê∏õÂ∞ëÈáçË§áÊÄß„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊó®Âú®‰ΩúÁÇ∫ÂàùÂ≠∏ËÄÖÂíåÁ∂ìÈ©óË±êÂØåÁöÑÈñãÁôº‰∫∫Âì°ÁöÑÊ©ãÊ®ëÔºåËÆì‰ªñÂÄëÂÖ∑ÂÇôÂú® AI È©ÖÂãïÂ∞àÊ°à‰∏≠ÊáâÁî® OOP ÊñπÊ≥ïË´ñÁöÑÂøÖË¶ÅÁü•Ë≠òÔºåÊúÄÁµÇ‰øÉÈÄ≤Êõ¥Âº∑Â§ß‰∏îÂèØÁ∂≠Ë≠∑ÁöÑÁ≥ªÁµ±ÈñãÁôº„ÄÇ</paragraph>

##### **Scaling Optimal LR Across Token Horizon**
2409.19913v1 by Johan Bjorck, Alon Benhaim, Vishrav Chaudhary, Furu Wei, Xia Song

State-of-the-art LLMs are powered by scaling -- scaling model size, dataset
size and cluster size. It is economically infeasible to extensively tune
hyperparameter for the largest runs. Instead, approximately optimal
hyperparameters must be inferred or \textit{transferred} from smaller
experiments. Hyperparameter transfer across model sizes has been studied in
Yang et al. However, hyperparameter transfer across dataset size -- or token
horizon -- has not been studied yet. To remedy this we conduct a large scale
empirical study on how optimal learning rate (LR) depends on token horizon in
LLM training. We first demonstrate that the optimal LR changes significantly
with token horizon -- longer training necessitates smaller LR. Secondly we
demonstrate the the optimal LR follows a scaling law, and that the optimal LR
for longer horizons can be accurately estimated from shorter horizons via our
scaling laws. We also provide a rule-of-thumb for transferring LR across token
horizons with zero overhead over current practices. Lastly we provide evidence
that LLama-1 used too high LR, and estimate the performance hit from this. We
thus argue that hyperparameter transfer across data size is an important and
overlooked component of LLM training.

ÊëòË¶ÅÔºöÊúÄÂÖàËøõÁöÑ LLM Áî±‰ª•‰∏ãÊñπÂºèÊèê‰æõÊîØÊåÅÔºöÊâ©Â±ïÊ®°ÂûãÂ§ßÂ∞è„ÄÅÊï∞ÊçÆÈõÜÂ§ßÂ∞èÂíåÈõÜÁæ§Â§ßÂ∞è„ÄÇÂπøÊ≥õË∞ÉÊï¥Ë∂ÖÂèÇÊï∞‰ª•ËøõË°åÊúÄÂ§ßËøêË°åÂú®ÁªèÊµé‰∏ä‰∏çÂèØË°å„ÄÇÁõ∏ÂèçÔºåÂøÖÈ°ª‰ªéËæÉÂ∞èÁöÑÂÆûÈ™å‰∏≠Êé®Êñ≠Êàñ‚Äú‰º†Ëæì‚ÄùËøë‰ººÊúÄ‰ºòË∂ÖÂèÇÊï∞„ÄÇYang Á≠â‰∫∫Á†îÁ©∂‰∫ÜË∑®Ê®°ÂûãÂ§ßÂ∞èÁöÑË∂ÖÂèÇÊï∞‰º†Ëæì„ÄÇÁÑ∂ËÄåÔºåÂ∞öÊú™Á†îÁ©∂Ë∑®Êï∞ÊçÆÈõÜÂ§ßÂ∞èÔºàÊàñ‰ª§ÁâåËåÉÂõ¥ÔºâÁöÑË∂ÖÂèÇÊï∞‰º†Ëæì„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÂØπÊúÄ‰ºòÂ≠¶‰π†Áéá (LR) Â¶Ç‰Ωï‰æùËµñ LLM ËÆ≠ÁªÉ‰∏≠ÁöÑ‰ª§ÁâåËåÉÂõ¥ËøõË°å‰∫ÜÂ§ßËßÑÊ®°ÂÆûËØÅÁ†îÁ©∂„ÄÇÊàë‰ª¨È¶ñÂÖàËØÅÊòéÊúÄ‰ºò LR Èöè‰ª§ÁâåËåÉÂõ¥ËÄåÊòæÁùÄÂèòÂåñ‚Äî‚ÄîÊõ¥ÈïøÁöÑËÆ≠ÁªÉÈúÄË¶ÅÊõ¥Â∞èÁöÑ LR„ÄÇÂÖ∂Ê¨°ÔºåÊàë‰ª¨ËØÅÊòéÊúÄ‰ºò LR ÈÅµÂæ™Áº©ÊîæÂÆöÂæãÔºåÂπ∂‰∏îÂèØ‰ª•ÈÄöËøáÊàë‰ª¨ÁöÑÁº©ÊîæÂÆöÂæã‰ªéËæÉÁü≠ÁöÑËåÉÂõ¥ÂáÜÁ°Æ‰º∞ËÆ°ËæÉÈïøËåÉÂõ¥ÁöÑÊúÄ‰ºò LR„ÄÇÊàë‰ª¨ËøòÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÁªèÈ™åÊ≥ïÂàôÔºåÁî®‰∫éÂú®‰ª§ÁâåËåÉÂõ¥‰πãÈó¥‰º†Ëæì LRÔºåËÄåÊó†ÈúÄÂØπÂΩìÂâçÂÆûË∑µËøõË°å‰ªª‰ΩïÂºÄÈîÄ„ÄÇÊúÄÂêéÔºåÊàë‰ª¨Êèê‰æõ‰∫ÜËØÅÊçÆË°®Êòé LLama-1 ‰ΩøÁî®‰∫ÜËøáÈ´òÁöÑ LRÔºåÂπ∂‰º∞ËÆ°‰∫ÜÁî±Ê≠§ÈÄ†ÊàêÁöÑÊÄßËÉΩÊçüÂ§±„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨ËÆ§‰∏∫Ë∑®Êï∞ÊçÆÂ§ßÂ∞èÁöÑË∂ÖÂèÇÊï∞‰º†ËæìÊòØ LLM ËÆ≠ÁªÉÁöÑ‰∏Ä‰∏™ÈáçË¶Å‰∏îË¢´ÂøΩËßÜÁöÑÁªÑÊàêÈÉ®ÂàÜ„ÄÇ

##### **UniSumEval: Towards Unified, Fine-Grained, Multi-Dimensional Summarization Evaluation for LLMs**
2409.19898v2 by Yuho Lee, Taewon Yun, Jason Cai, Hang Su, Hwanjun Song

Existing benchmarks for summarization quality evaluation often lack diverse
input scenarios, focus on narrowly defined dimensions (e.g., faithfulness), and
struggle with subjective and coarse-grained annotation schemes. To address
these shortcomings, we create UniSumEval benchmark, which extends the range of
input context (e.g., domain, length) and provides fine-grained,
multi-dimensional annotations. We use AI assistance in data creation,
identifying potentially hallucinogenic input texts, and also helping human
annotators reduce the difficulty of fine-grained annotation tasks. With
UniSumEval, we benchmark nine latest language models as summarizers, offering
insights into their performance across varying input contexts and evaluation
dimensions. Furthermore, we conduct a thorough comparison of SOTA automated
summary evaluators. Our benchmark data will be available at
https://github.com/DISL-Lab/UniSumEval-v1.0.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÊëòË¶ÅÂìÅË≥™Ë©ï‰º∞Âü∫Ê∫ñÈÄöÂ∏∏Áº∫‰πèÂ§öÊ®£ÂåñÁöÑËº∏ÂÖ•ÊÉÖÂ¢ÉÔºåÂ∞àÊ≥®ÊñºÁãπÁæ©ÁöÑÁ∂≠Â∫¶Ôºà‰æãÂ¶ÇÂø†ÂØ¶Â∫¶ÔºâÔºå‰∏¶Ëàá‰∏ªËßÄ‰∏îÁ≤óÁï•ÁöÑË®ªËß£ÊñπÊ°àÂ•ÆÊà∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÁº∫ÈªûÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü UniSumEval Âü∫Ê∫ñÔºåÂÆÉÊì¥Â±ï‰∫ÜËº∏ÂÖ•ÂÖßÂÆπÁöÑÁØÑÂúçÔºà‰æãÂ¶ÇÔºåÈ†òÂüü„ÄÅÈï∑Â∫¶ÔºâÔºå‰∏¶Êèê‰æõ‰∫ÜÁ¥∞Á∑ª„ÄÅÂ§öÁ∂≠Â∫¶ÁöÑË®ªËß£„ÄÇÊàëÂÄëÂú®Ë≥áÊñôÂª∫Á´ã‰∏≠‰ΩøÁî® AI ÂçîÂä©ÔºåË≠òÂà•ÊΩõÂú®ÁöÑÂπªË¶∫Ëº∏ÂÖ•ÊñáÂ≠óÔºå‰∏¶ÂçîÂä©‰∫∫Â∑•Ë®ªËß£ËÄÖÈôç‰ΩéÁ¥∞Á∑ªË®ªËß£‰ªªÂãôÁöÑÈõ£Â∫¶„ÄÇÊúâ‰∫Ü UniSumEvalÔºåÊàëÂÄëÂ∞á‰πùÂÄãÊúÄÊñ∞ÁöÑË™ûË®ÄÊ®°Âûã‰ΩúÁÇ∫ÊëòË¶ÅËÄÖÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶ÔºåÊèê‰æõÂ∞çÂÆÉÂÄëÂú®‰∏çÂêåËº∏ÂÖ•ÂÖßÂÆπÂíåË©ï‰º∞Á∂≠Â∫¶‰∏≠Ë°®ÁèæÁöÑË¶ãËß£„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ∞ç SOTA Ëá™ÂãïÊëòË¶ÅË©ï‰º∞Âô®ÈÄ≤Ë°å‰∫ÜÂæπÂ∫ïÁöÑÊØîËºÉ„ÄÇÊàëÂÄëÁöÑÂü∫Ê∫ñË≥áÊñôÂ∞áÊñº https://github.com/DISL-Lab/UniSumEval-v1.0 Êèê‰æõ„ÄÇ

##### **TRANSAGENT: An LLM-Based Multi-Agent System for Code Translation**
2409.19894v2 by Zhiqiang Yuan, Weitong Chen, Hanlin Wang, Kai Yu, Xin Peng, Yiling Lou

Code translation converts code from one programming language to another while
maintaining its original functionality, which is crucial for software
migration, system refactoring, and cross-platform development. Traditional
rule-based methods rely on manually-written rules, which can be time-consuming
and often result in less readable code. To overcome this, learning-based
methods have been developed, leveraging parallel data to train models for
automated code translation. More recently, the advance of Large Language Models
(LLMs) further boosts learning-based code translation. Although promising,
LLM-translated program still suffers from diverse quality issues (e.g., syntax
errors and semantic errors). In particular, it can be challenging for LLMs to
self-debug these errors when simply provided with the corresponding error
messages.
  In this work, we propose a novel LLM-based multi-agent system TRANSAGENT,
which enhances LLM-based code translation by fixing the syntax errors and
semantic errors with the synergy between four LLM-based agents, including
Initial Code Translator, Syntax Error Fixer, Code Aligner, and Semantic Error
Fixer. The main insight of TRANSAGENT is to first localize the error code block
in the target program based on the execution alignment between the target and
source program, which can narrow down the fixing space and thus lower down the
fixing difficulties. To evaluate TRANSAGENT, we first construct a new benchmark
from recent programming tasks to mitigate the potential data leakage issue. On
our benchmark, TRANSAGENT outperforms the latest LLM-based code translation
technique UniTrans in both translation effectiveness and efficiency;
additionally, our evaluation on different LLMs show the generalization of
TRANSAGENT and our ablation study shows the contribution of each agent.

ÊëòË¶ÅÔºö<paragraph>Á®ãÂºèÁ¢ºÁøªË≠ØÂ∞áÁ®ãÂºèÁ¢ºÂæû‰∏ÄÁ®ÆÁ®ãÂºèË™ûË®ÄËΩâÊèõÊàêÂè¶‰∏ÄÁ®ÆÁ®ãÂºèË™ûË®ÄÔºåÂêåÊôÇÁ∂≠ÊåÅÂÖ∂ÂéüÂßãÂäüËÉΩÔºåÈÄôÂ∞çËªüÈ´îÈÅ∑Áßª„ÄÅÁ≥ªÁµ±ÈáçÊßãÂíåË∑®Âπ≥Âè∞ÈñãÁôºËá≥ÈóúÈáçË¶Å„ÄÇÂÇ≥Áµ±ÁöÑÂü∫ÊñºË¶èÂâáÁöÑÊñπÊ≥ï‰æùË≥¥ÊñºÊâãÂØ´Ë¶èÂâáÔºåÈÄôÂèØËÉΩÊúÉËÄóÊôÇÔºå‰∏îÁ∂ìÂ∏∏Â∞éËá¥ÂèØËÆÄÊÄßËºÉÂ∑ÆÁöÑÁ®ãÂºèÁ¢º„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄôÂÄãÂïèÈ°åÔºåÂ∑≤Á∂ìÈñãÁôºÂá∫Âü∫ÊñºÂ≠∏ÁøíÁöÑÊñπÊ≥ïÔºåÂà©Áî®Âπ≥Ë°åË≥áÊñô‰æÜË®ìÁ∑¥Ëá™ÂãïÂåñÁ®ãÂºèÁ¢ºÁøªË≠ØÁöÑÊ®°Âûã„ÄÇÊúÄËøëÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈÄ≤Ê≠•ÈÄ≤‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÂü∫ÊñºÂ≠∏ÁøíÁöÑÁ®ãÂºèÁ¢ºÁøªË≠Ø„ÄÇÂÑòÁÆ°ÊúâÂ∏åÊúõÔºå‰ΩÜ LLM ÁøªË≠ØÁöÑÁ®ãÂºè‰ªçÁÑ∂Â≠òÂú®ÂêÑÁ®ÆÂìÅË≥™ÂïèÈ°åÔºà‰æãÂ¶ÇÔºåË™ûÊ≥ïÈåØË™§ÂíåË™ûÁæ©ÈåØË™§Ôºâ„ÄÇÁâπÂà•ÊòØÔºåÁï∂ÂÉÖÊèê‰æõÂ∞çÊáâÁöÑÈåØË™§Ë®äÊÅØÊôÇÔºåLLM ÂèØËÉΩÈõ£‰ª•Ëá™Ë°åÈô§ÈåØÈÄô‰∫õÈåØË™§„ÄÇ
Âú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÂü∫Êñº LLM ÁöÑÂ§ö‰ª£ÁêÜÁ≥ªÁµ± TRANSAGENTÔºåÂÆÉÈÄèÈÅé‰øÆÊ≠£Ë™ûÊ≥ïÈåØË™§ÂíåË™ûÁæ©ÈåØË™§‰æÜÂ¢ûÂº∑Âü∫Êñº LLM ÁöÑÁ®ãÂºèÁ¢ºÁøªË≠ØÔºå‰∏¶ÁµêÂêà‰∫ÜÂõõÂÄãÂü∫Êñº LLM ÁöÑ‰ª£ÁêÜÔºåÂåÖÊã¨ÂàùÂßãÁ®ãÂºèÁ¢ºÁøªË≠ØÂô®„ÄÅË™ûÊ≥ïÈåØË™§‰øÆÊ≠£Âô®„ÄÅÁ®ãÂºèÁ¢ºÂ∞çÈΩäÂô®ÂíåË™ûÁæ©ÈåØË™§‰øÆÊ≠£Âô®„ÄÇTRANSAGENT ÁöÑ‰∏ªË¶ÅË¶ãËß£ÊòØÈ¶ñÂÖàÊ†πÊìöÁõÆÊ®ôÁ®ãÂºèËàáÂéüÂßãÁ®ãÂºèÁ¢º‰πãÈñìÁöÑÂü∑Ë°åÂ∞çÈΩä‰æÜÂÆö‰ΩçÁõÆÊ®ôÁ®ãÂºè‰∏≠ÁöÑÈåØË™§Á®ãÂºèÁ¢ºÂçÄÂ°äÔºåÈÄôÂèØ‰ª•Á∏ÆÂ∞è‰øÆÊ≠£Á©∫ÈñìÔºåÂæûËÄåÈôç‰Ωé‰øÆÊ≠£Èõ£Â∫¶„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ TRANSAGENTÔºåÊàëÂÄëÈ¶ñÂÖàÂæûÊúÄËøëÁöÑÁ®ãÂºèË®≠Ë®à‰ªªÂãô‰∏≠Âª∫Êßã‰∏ÄÂÄãÊñ∞ÁöÑÂü∫Ê∫ñÔºå‰ª•Ê∏õËºïÊΩõÂú®ÁöÑË≥áÊñôÂ§ñÊ¥©ÂïèÈ°å„ÄÇÂú®ÊàëÂÄëÁöÑÂü∫Ê∫ñ‰∏äÔºåTRANSAGENT Âú®ÁøªË≠ØÊïàÊûúÂíåÊïàÁéáÊñπÈù¢ÈÉΩÂÑ™ÊñºÊúÄÊñ∞ÁöÑÂü∫Êñº LLM ÁöÑÁ®ãÂºèÁ¢ºÁøªË≠ØÊäÄË°ì UniTransÔºõÊ≠§Â§ñÔºåÊàëÂÄëÂ∞ç‰∏çÂêå LLM ÁöÑË©ï‰º∞È°ØÁ§∫‰∫Ü TRANSAGENT ÁöÑÊ≥õÂåñÊÄßÔºåËÄåÊàëÂÄëÁöÑÊ∂àËûçÁ†îÁ©∂È°ØÁ§∫‰∫ÜÊØèÂÄã‰ª£ÁêÜÁöÑË≤¢Áçª„ÄÇ</paragraph>

##### **RouterDC: Query-Based Router by Dual Contrastive Learning for Assembling Large Language Models**
2409.19886v1 by Shuhao Chen, Weisen Jiang, Baijiong Lin, James T. Kwok, Yu Zhang

Recent works show that assembling multiple off-the-shelf large language
models (LLMs) can harness their complementary abilities. To achieve this,
routing is a promising method, which learns a router to select the most
suitable LLM for each query. However, existing routing models are ineffective
when multiple LLMs perform well for a query. To address this problem, in this
paper, we propose a method called query-based Router by Dual Contrastive
learning (RouterDC). The RouterDC model consists of an encoder and LLM
embeddings, and we propose two contrastive learning losses to train the
RouterDC model. Experimental results show that RouterDC is effective in
assembling LLMs and largely outperforms individual top-performing LLMs as well
as existing routing methods on both in-distribution (+2.76\%) and
out-of-distribution (+1.90\%) tasks. Source code is available at
https://github.com/shuhao02/RouterDC.

ÊëòË¶ÅÔºöÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÁªÑË£ÖÂ§ö‰∏™Áé∞ÊàêÁöÑ„ÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÂèØ‰ª•Âà©Áî®ÂÆÉ‰ª¨ÁöÑ‰∫íË°•ËÉΩÂäõ„ÄÇ‰∏∫‰∫ÜÂÆûÁé∞Ëøô‰∏ÄÁõÆÊ†áÔºåË∑ØÁî±ÊòØ‰∏ÄÁßçÂæàÊúâÂâçÊôØÁöÑÊñπÊ≥ïÔºåÂÆÉÂ≠¶‰π†Ë∑ØÁî±Âô®‰∏∫ÊØè‰∏™Êü•ËØ¢ÈÄâÊã©ÊúÄÂêàÈÄÇÁöÑ LLM„ÄÇÁÑ∂ËÄåÔºåÂΩìÂ§ö‰∏™ LLM ÂØπÊü•ËØ¢ÊâßË°åËâØÂ•ΩÊó∂ÔºåÁé∞ÊúâÁöÑË∑ØÁî±Ê®°ÂûãÊó†Êïà„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÊü•ËØ¢ÁöÑË∑ØÁî±Âô®ÊñπÊ≥ïÔºåÂç≥ÂèåÂØπÊØîÂ≠¶‰π† (RouterDC)„ÄÇRouterDC Ê®°ÂûãÁî±ÁºñÁ†ÅÂô®Âíå LLM ÂµåÂÖ•ÁªÑÊàêÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏§ÁßçÂØπÊØîÂ≠¶‰π†ÊçüÂ§±Êù•ËÆ≠ÁªÉ RouterDC Ê®°Âûã„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåRouterDC Âú®ÁªÑË£Ö LLM ÊñπÈù¢ÊòØÊúâÊïàÁöÑÔºåÂπ∂‰∏îÂú®ÂàÜÂ∏ÉÂÜÖ (+2.76%) ÂíåÂàÜÂ∏ÉÂ§ñ (+1.90%) ‰ªªÂä°‰∏≠ÈÉΩÂ§ßÂ§ß‰ºò‰∫éÂçïÁã¨ÁöÑÈ°∂Á∫ß LLM ‰ª•ÂèäÁé∞ÊúâÁöÑË∑ØÁî±ÊñπÊ≥ï„ÄÇÊ∫ê‰ª£Á†ÅÂèØÂú® https://github.com/shuhao02/RouterDC Ëé∑Âæó„ÄÇ

##### **SWIM: Short-Window CNN Integrated with Mamba for EEG-Based Auditory Spatial Attention Decoding**
2409.19884v1 by Ziyang Zhang, Andrew Thwaites, Alexandra Woolgar, Brian Moore, Chao Zhang

In complex auditory environments, the human auditory system possesses the
remarkable ability to focus on a specific speaker while disregarding others. In
this study, a new model named SWIM, a short-window convolution neural network
(CNN) integrated with Mamba, is proposed for identifying the locus of auditory
attention (left or right) from electroencephalography (EEG) signals without
relying on speech envelopes. SWIM consists of two parts. The first is a
short-window CNN (SW$_\text{CNN}$), which acts as a short-term EEG feature
extractor and achieves a final accuracy of 84.9% in the leave-one-speaker-out
setup on the widely used KUL dataset. This improvement is due to the use of an
improved CNN structure, data augmentation, multitask training, and model
combination. The second part, Mamba, is a sequence model first applied to
auditory spatial attention decoding to leverage the long-term dependency from
previous SW$_\text{CNN}$ time steps. By joint training SW$_\text{CNN}$ and
Mamba, the proposed SWIM structure uses both short-term and long-term
information and achieves an accuracy of 86.2%, which reduces the classification
errors by a relative 31.0% compared to the previous state-of-the-art result.
The source code is available at https://github.com/windowso/SWIM-ASAD.

ÊëòË¶ÅÔºöÂú®Ë§áÈõúÁöÑËÅΩË¶∫Áí∞Â¢É‰∏≠Ôºå‰∫∫È°ûËÅΩË¶∫Á≥ªÁµ±ÊìÅÊúâÂ∞àÊ≥®ÊñºÁâπÂÆöË™™Ë©±ËÄÖÔºåÂêåÊôÇÂøΩË¶ñÂÖ∂‰ªñË™™Ë©±ËÄÖÁöÑÈùûÂá°ËÉΩÂäõ„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ SWIM ÁöÑÊñ∞Ê®°ÂûãÔºå‰∏ÄÂÄãËàá Mamba Êï¥ÂêàÁöÑÁü≠ÊôÇÁ™óÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN)ÔºåÁî®ÊñºÂæûËÖ¶ÈõªÂúñ (EEG) ‰ø°Ëôü‰∏≠Ë≠òÂà•ËÅΩË¶∫Ê≥®ÊÑèÂäõÁöÑ‰ΩçÁΩÆ (Â∑¶ÊàñÂè≥)ÔºåËÄå‰∏ç‰æùË≥¥Ë™ûÈü≥ÂåÖÁµ°„ÄÇSWIM Áî±ÂÖ©ÈÉ®ÂàÜÁµÑÊàê„ÄÇÁ¨¨‰∏ÄÂÄãÊòØÁü≠ÊôÇÁ™ó CNN (SW$_\text{CNN}$)ÔºåÂÆÉÂÖÖÁï∂Áü≠Êúü EEG ÁâπÂæµÊèêÂèñÂô®Ôºå‰∏¶Âú®Âª£Ê≥õ‰ΩøÁî®ÁöÑ KUL Ë≥áÊñôÈõÜ‰∏äÂú®Áïô‰∏ÄË™™Ë©±ËÄÖÊ≥ïË®≠ÂÆö‰∏≠ÈÅîÂà∞ 84.9% ÁöÑÊúÄÁµÇÊ∫ñÁ¢∫Â∫¶„ÄÇÈÄôÁ®ÆÊîπÈÄ≤ÊòØÊ≠∏ÂäüÊñº‰ΩøÁî®ÊîπÈÄ≤ÁöÑ CNN ÁµêÊßã„ÄÅË≥áÊñôÊì¥ÂÖÖ„ÄÅÂ§ö‰ªªÂãôË®ìÁ∑¥ÂíåÊ®°ÂûãÁµÑÂêà„ÄÇÁ¨¨‰∫åÈÉ®ÂàÜ Mamba ÊòØ‰∏ÄÂÄãÂ∫èÂàóÊ®°ÂûãÔºåÈ¶ñÂÖàÊáâÁî®ÊñºËÅΩË¶∫Á©∫ÈñìÊ≥®ÊÑèÂäõËß£Á¢ºÔºå‰ª•Âà©Áî®‰æÜËá™ÂÖàÂâç SW$_\text{CNN}$ ÊôÇÈñìÊ≠•Èï∑ÁöÑÈï∑Êúü‰æùË≥¥ÊÄß„ÄÇÈÄèÈÅéËÅØÂêàË®ìÁ∑¥ SW$_\text{CNN}$ Âíå MambaÔºåÊèêÂá∫ÁöÑ SWIM ÁµêÊßã‰ΩøÁî®Áü≠ÊúüÂíåÈï∑ÊúüË≥áË®äÔºå‰∏¶ÈÅîÂà∞ 86.2% ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåËàáÂÖàÂâçÁöÑÊúÄÂÖàÈÄ≤ÁµêÊûúÁõ∏ÊØîÔºåÂ∞áÂàÜÈ°ûÈåØË™§Ê∏õÂ∞ë‰∫ÜÁõ∏Â∞çÁöÑ 31.0%„ÄÇÂéüÂßãÁ¢ºÂèØÂú® https://github.com/windowso/SWIM-ASAD ÂèñÂæó„ÄÇ

##### **Contrastive Token Learning with Similarity Decay for Repetition Suppression in Machine Translation**
2409.19877v1 by Huangyu Dai, Ben Chen, Kaidi Chen, Ying Han, Zihan Liang, Wen Jiang

For crosslingual conversation and trade, Neural Machine Translation (NMT) is
pivotal yet faces persistent challenges with monotony and repetition in
generated content. Traditional solutions that rely on penalizing text
redundancy or token reoccurrence have shown limited efficacy, particularly for
lengthy article and e-commerce descriptions with inherent redundancy, even with
the advent of Large Language Models (LLMs). This paper investigates the
underlying causes of textual repetition through the lens of information
entropy, attributing the phenomenon to the elevated uncertainty within the
input text. To address this, a novel algorithm named Contrastive Token Learning
with Similarity Decay (CTSD) is introduced, which modulates the suppression of
tokens dynamically, informed by varying attention weights and inter-token
distances. Furthermore, an e-commerce dataset comprised of title texts of
online real items is compiled and released susceptible to hallucination
translations to benchmark the algorithm. Extensive evaluations demonstrate that
CTSD significantly outperforms existing approaches in precision and
generalizability. Additional online A/B testing underscores its practical
value, showing marked improvements in user engagement and conversion. Notably,
this method has been implemented with full traffic on eight multilingual sites
of alibaba.com, the largest B2B e-commerce platform in the world.

ÊëòË¶ÅÔºöÂ∞çÊñºË∑®Ë™ûË®ÄÂ∞çË©±ÂíåË≤øÊòìËÄåË®ÄÔºåÁ•ûÁ∂ìÊ©üÂô®ÁøªË≠Ø (NMT) Ëá≥ÈóúÈáçË¶ÅÔºå‰ΩÜ‰ªçÈù¢Ëá®ËëóÁîüÊàêÂÖßÂÆπ‰∏≠ÂñÆË™øÂíåÈáçË§áÁöÑÊåÅÁ∫åÊåëÊà∞„ÄÇÂÇ≥Áµ±ÁöÑËß£Ê±∫ÊñπÊ°à‰æùË≥¥ÊñºÊá≤ÁΩ∞ÊñáÂ≠óÂÜóÈ§òÊàñÊ®ôË®òÈáçÁèæÔºåÂ∑≤È°ØÁ§∫Âá∫ÊúâÈôêÁöÑÂäüÊïàÔºåÁâπÂà•ÊòØÂ∞çÊñºÂÖ∑ÊúâÂÖßÂú®ÂÜóÈ§òÁöÑÂÜóÈï∑ÊñáÁ´†ÂíåÈõªÂ≠êÂïÜÂãôÊèèËø∞ÔºåÂç≥‰ΩøÂá∫Áèæ‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)„ÄÇÊú¨ÊñáÈÄöÈÅéË≥áË®äÁÜµÁöÑË¶ñËßíÊé¢Ë®é‰∫ÜÊñáÂ≠óÈáçË§áÁöÑÊ†πÊú¨ÂéüÂõ†ÔºåÂ∞áÈÄôÁ®ÆÁèæË±°Ê≠∏Âõ†ÊñºËº∏ÂÖ•ÊñáÂ≠ó‰∏≠ËºÉÈ´òÁöÑ‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂêçÁÇ∫Â∞çÊØîÊ®ôË®òÂ≠∏ÁøíËàáÁõ∏‰ººÊÄßË°∞Ê∏õ (CTSD) ÁöÑÊñ∞ÊºîÁÆóÊ≥ïÔºåÂÆÉÊ†πÊìö‰∏çÂêåÁöÑÊ≥®ÊÑèÂäõÊ¨äÈáçÂíåÊ®ôË®òÈñìË∑ùÈõ¢ÔºåÂãïÊÖãÂú∞Ë™øÁØÄÊ®ôË®òÁöÑÊäëÂà∂„ÄÇÊ≠§Â§ñÔºåÁ∑®Âà∂‰∏¶ÁôºÂ∏É‰∫Ü‰∏ÄÂÄãÁî±Á∑ö‰∏äÁúüÂØ¶ÂïÜÂìÅÊ®ôÈ°åÊñáÂ≠óÁµÑÊàêÁöÑÈõªÂ≠êÂïÜÂãôË≥áÊñôÈõÜÔºåÂÆπÊòìÁî¢ÁîüÂπªË¶∫ÁøªË≠ØÔºå‰ª•‰ΩúÁÇ∫ÊºîÁÆóÊ≥ïÁöÑÂü∫Ê∫ñ„ÄÇÂª£Ê≥õÁöÑË©ï‰º∞Ë°®ÊòéÔºåCTSD Âú®Á≤æÊ∫ñÂ∫¶ÂíåÊ¶ÇÊã¨ÊÄßÊñπÈù¢ÊòéÈ°ØÂÑ™ÊñºÁèæÊúâÊñπÊ≥ï„ÄÇÈ°çÂ§ñÁöÑÁ∑ö‰∏ä A/B Ê∏¨Ë©¶Âº∑Ë™ø‰∫ÜÂÆÉÁöÑÂØ¶Áî®ÂÉπÂÄºÔºåÈ°ØÁ§∫Âá∫‰ΩøÁî®ËÄÖÂèÉËàáÂ∫¶ÂíåËΩâÊèõÁéáÁöÑÈ°ØËëóÊèêÂçá„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊ≠§ÊñπÊ≥ïÂ∑≤Âú®ÂÖ®ÁêÉÊúÄÂ§ßÁöÑ B2B ÈõªÂ≠êÂïÜÂãôÂπ≥Âè∞ alibaba.com ÁöÑÂÖ´ÂÄãÂ§öË™ûË®ÄÁ∂≤Á´ô‰∏äÂÖ®Èù¢ÂØ¶ÊñΩ„ÄÇ

##### **TSI: A Multi-View Representation Learning Approach for Time Series Forecasting**
2409.19871v1 by Wentao Gao, Ziqi Xu, Jiuyong Li, Lin Liu, Jixue Liu, Thuc Duy Le, Debo Cheng, Yanchang Zhao, Yun Chen

As the growing demand for long sequence time-series forecasting in real-world
applications, such as electricity consumption planning, the significance of
time series forecasting becomes increasingly crucial across various domains.
This is highlighted by recent advancements in representation learning within
the field. This study introduces a novel multi-view approach for time series
forecasting that innovatively integrates trend and seasonal representations
with an Independent Component Analysis (ICA)-based representation. Recognizing
the limitations of existing methods in representing complex and
high-dimensional time series data, this research addresses the challenge by
combining TS (trend and seasonality) and ICA (independent components)
perspectives. This approach offers a holistic understanding of time series
data, going beyond traditional models that often miss nuanced, nonlinear
relationships. The efficacy of TSI model is demonstrated through comprehensive
testing on various benchmark datasets, where it shows superior performance over
current state-of-the-art models, particularly in multivariate forecasting. This
method not only enhances the accuracy of forecasting but also contributes
significantly to the field by providing a more in-depth understanding of time
series data. The research which uses ICA for a view lays the groundwork for
further exploration and methodological advancements in time series forecasting,
opening new avenues for research and practical applications.

ÊëòË¶ÅÔºöÈö®ËëóÂú®ÂØ¶ÈöõÊáâÁî®‰∏≠Â∞çÈï∑Â∫èÂàóÊôÇÈñìÂ∫èÂàóÈ†êÊ∏¨ÁöÑÈúÄÊ±ÇÊó•ÁõäÂ¢ûÈï∑Ôºå‰æãÂ¶ÇÈõªÂäõÊ∂àËÄóË¶èÂäÉÔºåÊôÇÈñìÂ∫èÂàóÈ†êÊ∏¨ÁöÑÈáçË¶ÅÊÄßÂú®ÂêÑÂÄãÈ†òÂüüËÆäÂæóË∂ä‰æÜË∂äÈóúÈçµ„ÄÇÈÄô‰∏ÄÈªûÂæûÊúÄËøëÂú®Ë©≤È†òÂüüÂÖßË°®Á§∫Â≠∏ÁøíÁöÑÈÄ≤Â±ï‰∏≠ÂæóÂà∞‰∫ÜÂº∑Ë™ø„ÄÇÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊôÇÈñìÂ∫èÂàóÈ†êÊ∏¨Â§öË¶ñËßíÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÂâµÊñ∞Âú∞Â∞áË∂®Âã¢ÂíåÂ≠£ÁØÄË°®Á§∫ËàáÂü∫ÊñºÁç®Á´ãÊàêÂàÜÂàÜÊûê (ICA) ÁöÑË°®Á§∫Áõ∏ÁµêÂêà„ÄÇË™çË≠òÂà∞ÁèæÊúâÊñπÊ≥ïÂú®Ë°®Á§∫Ë§áÈõúÂíåÈ´òÁ∂≠ÊôÇÈñìÂ∫èÂàóÊï∏ÊìöÊñπÈù¢ÁöÑÂ±ÄÈôêÊÄßÔºåÊú¨Á†îÁ©∂ÈÄöÈÅéÁµêÂêà TSÔºàË∂®Âã¢ÂíåÂ≠£ÁØÄÊÄßÔºâÂíå ICAÔºàÁç®Á´ãÊàêÂàÜÔºâËßÄÈªû‰æÜÊáâÂ∞çÈÄô‰∏ÄÊåëÊà∞„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÊèê‰æõ‰∫ÜÂ∞çÊôÇÈñìÂ∫èÂàóÊï∏ÊìöÁöÑÊï¥È´îÁêÜËß£ÔºåË∂ÖË∂ä‰∫ÜÂÇ≥Áµ±Ê®°ÂûãÔºåÂæåËÄÖÁ∂ìÂ∏∏ÊúÉÈÅ∫ÊºèÁ¥∞ÂæÆÁöÑÈùûÁ∑öÊÄßÈóú‰øÇ„ÄÇTSI Ê®°ÂûãÁöÑÂäüÊïàÈÄöÈÅéÂú®ÂêÑÁ®ÆÂü∫Ê∫ñÊï∏ÊìöÈõÜ‰∏äÁöÑÂÖ®Èù¢Ê∏¨Ë©¶ÂæóÂà∞Ë≠âÊòéÔºåÂú®ÂÖ∂‰∏≠ÂÆÉÂ±ïÁ§∫‰∫ÜÂÑ™ÊñºÁï∂ÂâçÊúÄÂÖàÈÄ≤Ê®°ÂûãÁöÑÊÄßËÉΩÔºåÁâπÂà•ÊòØÂú®Â§öËÆäÈáèÈ†êÊ∏¨‰∏≠„ÄÇÈÄôÁ®ÆÊñπÊ≥ï‰∏çÂÉÖÊèêÈ´ò‰∫ÜÈ†êÊ∏¨ÁöÑÊ∫ñÁ¢∫ÊÄßÔºåËÄå‰∏îÈÄöÈÅéÊèê‰æõÂ∞çÊôÇÈñìÂ∫èÂàóÊï∏ÊìöÁöÑÊõ¥Ê∑±ÂÖ•ÁêÜËß£ÔºåÈÇÑÁÇ∫Ë©≤È†òÂüüÂÅöÂá∫‰∫ÜÈáçÂ§ßË≤¢Áçª„ÄÇ‰ΩøÁî® ICA ‰ΩúÁÇ∫Ë¶ñËßíÁöÑÁ†îÁ©∂ÁÇ∫ÊôÇÈñìÂ∫èÂàóÈ†êÊ∏¨‰∏≠ÁöÑÈÄ≤‰∏ÄÊ≠•Êé¢Á¥¢ÂíåÊñπÊ≥ïÂ≠∏ÈÄ≤Ê≠•Â•†ÂÆö‰∫ÜÂü∫Á§éÔºåÁÇ∫Á†îÁ©∂ÂíåÂØ¶ÈöõÊáâÁî®ÈñãÈó¢‰∫ÜÊñ∞ÁöÑÈÄîÂæë„ÄÇ

##### **The Construction of Instruction-tuned LLMs for Finance without Instruction Data Using Continual Pretraining and Model Merging**
2409.19854v1 by Masanori Hirano, Kentaro Imajo

This paper proposes a novel method for constructing instruction-tuned large
language models (LLMs) for finance without instruction data. Traditionally,
developing such domain-specific LLMs has been resource-intensive, requiring a
large dataset and significant computational power for continual pretraining and
instruction tuning. Our study proposes a simpler approach that combines
domain-specific continual pretraining with model merging. Given that
general-purpose pretrained LLMs and their instruction-tuned LLMs are often
publicly available, they can be leveraged to obtain the necessary instruction
task vector. By merging this with a domain-specific pretrained vector, we can
effectively create instruction-tuned LLMs for finance without additional
instruction data. Our process involves two steps: first, we perform continual
pretraining on financial data; second, we merge the instruction-tuned vector
with the domain-specific pretrained vector. Our experiments demonstrate the
successful construction of instruction-tuned LLMs for finance. One major
advantage of our method is that the instruction-tuned and domain-specific
pretrained vectors are nearly independent. This independence makes our approach
highly effective. The Japanese financial instruction-tuned LLMs we developed in
this study are available at
https://huggingface.co/pfnet/nekomata-14b-pfn-qfin-inst-merge.

ÊëòË¶ÅÔºöÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÊñπÊ≥ïÔºåÁî®‰∫éÂú®Ê≤°ÊúâÊåá‰ª§Êï∞ÊçÆÁöÑÊÉÖÂÜµ‰∏ãÊûÑÂª∫ÈíàÂØπÈáëËûçÈ¢ÜÂüüÁöÑÊåá‰ª§Ë∞ÉÊï¥Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM)„ÄÇ‰º†Áªü‰∏äÔºåÂºÄÂèëÊ≠§Á±ªÁâπÂÆöÈ¢ÜÂüüÁöÑ LLM ÈúÄË¶ÅÂ§ßÈáèËµÑÊ∫êÔºåÈúÄË¶Å‰∏Ä‰∏™Â§ßÂûãÊï∞ÊçÆÈõÜÂíåÂ§ßÈáèÁöÑËÆ°ÁÆóËÉΩÂäõÊù•ËøõË°åÊåÅÁª≠È¢ÑËÆ≠ÁªÉÂíåÊåá‰ª§Ë∞ÉÊï¥„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊõ¥ÁÆÄÂçïÁöÑÊñπÊ≥ïÔºåËØ•ÊñπÊ≥ïÂ∞ÜÁâπÂÆöÈ¢ÜÂüüÁöÑÊåÅÁª≠È¢ÑËÆ≠ÁªÉ‰∏éÊ®°ÂûãÂêàÂπ∂Áõ∏ÁªìÂêà„ÄÇÈâ¥‰∫éÈÄöÁî®È¢ÑËÆ≠ÁªÉ LLM ÂèäÂÖ∂Êåá‰ª§Ë∞ÉÊï¥ÁöÑ LLM ÈÄöÂ∏∏ÊòØÂÖ¨ÂºÄÂèØÁî®ÁöÑÔºåÂõ†Ê≠§ÂèØ‰ª•Âà©Áî®ÂÆÉ‰ª¨Êù•Ëé∑ÂèñÂøÖË¶ÅÁöÑÊåá‰ª§‰ªªÂä°ÂêëÈáè„ÄÇÈÄöËøáÂ∞ÜÂÖ∂‰∏éÁâπÂÆöÈ¢ÜÂüüÁöÑÈ¢ÑËÆ≠ÁªÉÂêëÈáèÂêàÂπ∂ÔºåÊàë‰ª¨ÂèØ‰ª•ÊúâÊïàÂú∞‰∏∫ÈáëËûçÈ¢ÜÂüüÂàõÂª∫Êåá‰ª§Ë∞ÉÊï¥ÁöÑ LLMÔºåËÄåÊó†ÈúÄÈ¢ùÂ§ñÁöÑÊåá‰ª§Êï∞ÊçÆ„ÄÇÊàë‰ª¨ÁöÑÊµÅÁ®ãÂåÖÊã¨‰∏§‰∏™Ê≠•È™§ÔºöÈ¶ñÂÖàÔºåÊàë‰ª¨ÂØπÈáëËûçÊï∞ÊçÆÊâßË°åÊåÅÁª≠È¢ÑËÆ≠ÁªÉÔºõÂÖ∂Ê¨°ÔºåÊàë‰ª¨Â∞ÜÊåá‰ª§Ë∞ÉÊï¥ÂêëÈáè‰∏éÁâπÂÆöÈ¢ÜÂüüÁöÑÈ¢ÑËÆ≠ÁªÉÂêëÈáèÂêàÂπ∂„ÄÇÊàë‰ª¨ÁöÑÂÆûÈ™åË°®ÊòéÔºåÊàêÂäüÊûÑÂª∫‰∫ÜÈíàÂØπÈáëËûçÈ¢ÜÂüüÁöÑÊåá‰ª§Ë∞ÉÊï¥ LLM„ÄÇÊàë‰ª¨ÊñπÊ≥ïÁöÑ‰∏Ä‰∏™‰∏ªË¶Å‰ºòÁÇπÊòØÔºåÊåá‰ª§Ë∞ÉÊï¥ÁöÑÂêëÈáèÂíåÁâπÂÆöÈ¢ÜÂüüÁöÑÈ¢ÑËÆ≠ÁªÉÂêëÈáèÂá†‰πéÊòØÁã¨Á´ãÁöÑ„ÄÇËøôÁßçÁã¨Á´ãÊÄß‰ΩøÊàë‰ª¨ÁöÑÊñπÊ≥ïÈùûÂ∏∏ÊúâÊïà„ÄÇÊàë‰ª¨Âú®Êú¨Á†îÁ©∂‰∏≠ÂºÄÂèëÁöÑÊó•ËØ≠ÈáëËûçÊåá‰ª§Ë∞ÉÊï¥ LLM ÂèØÂú® https://huggingface.co/pfnet/nekomata-14b-pfn-qfin-inst-merge Ëé∑Âæó„ÄÇ

##### **ForecastBench: A Dynamic Benchmark of AI Forecasting Capabilities**
2409.19839v1 by Ezra Karger, Houtan Bastani, Chen Yueh-Han, Zachary Jacobs, Danny Halawi, Fred Zhang, Philip E. Tetlock

Forecasts of future events are essential inputs into informed
decision-making. Machine learning (ML) systems have the potential to deliver
forecasts at scale, but there is no framework for evaluating the accuracy of ML
systems on a standardized set of forecasting questions. To address this gap, we
introduce ForecastBench: a dynamic benchmark that evaluates the accuracy of ML
systems on an automatically generated and regularly updated set of 1,000
forecasting questions. To avoid any possibility of data leakage, ForecastBench
is comprised solely of questions about future events that have no known answer
at the time of submission. We quantify the ability of current ML systems by
collecting forecasts from expert (human) forecasters, the general public, and
LLMs on a random subset of questions from the benchmark (N = 200). While LLMs
have achieved super-human performance on many benchmarks, they perform less
well here: expert forecasters outperform the top-performing LLM (p-values <=
0.01). We display system and human scores in a public leaderboard at
www.forecastbench.org.

ÊëòË¶ÅÔºöÊú™‰æÜ‰∫ã‰ª∂È†êÊ∏¨ÊòØÊòéÊô∫Ê±∫Á≠ñÂà∂ÂÆö‰∏≠ÁöÑÈáçË¶ÅËº∏ÂÖ•„ÄÇÊ©üÂô®Â≠∏Áøí (ML) Á≥ªÁµ±ÊúâÊΩõÂäõÂ§ßË¶èÊ®°Êèê‰æõÈ†êÊ∏¨Ôºå‰ΩÜÊ≤íÊúâÊ°ÜÊû∂ÂèØ‰ª•Âú®Ê®ôÊ∫ñÂåñÁöÑÈ†êÊ∏¨ÂïèÈ°åÈõÜ‰∏äË©ï‰º∞ ML Á≥ªÁµ±ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü ForecastBenchÔºö‰∏ÄÂÄãÂãïÊÖãÂü∫Ê∫ñÔºåÂÆÉÂú®Ëá™ÂãïÁîüÊàê‰∏¶ÂÆöÊúüÊõ¥Êñ∞ÁöÑ 1,000 ÂÄãÈ†êÊ∏¨ÂïèÈ°åÈõÜ‰∏äË©ï‰º∞ ML Á≥ªÁµ±ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÁÇ∫‰∫ÜÈÅøÂÖç‰ªª‰ΩïË≥áÊñôÂ§ñÊ¥©ÁöÑÂèØËÉΩÊÄßÔºåForecastBench ÂÉÖÂåÖÂê´ÈóúÊñºÊú™‰æÜ‰∫ã‰ª∂ÁöÑÂïèÈ°åÔºåÈÄô‰∫õÂïèÈ°åÂú®Êèê‰∫§ÊôÇÊ≤íÊúâÂ∑≤Áü•ÁöÑÁ≠îÊ°à„ÄÇÊàëÂÄëÈÄèÈÅéÂæûÂ∞àÂÆ∂Ôºà‰∫∫È°ûÔºâÈ†êÊ∏¨Âì°„ÄÅ‰∏ÄËà¨Â§ßÁúæÂíå LLM ‰∏≠Êî∂ÈõÜÈ†êÊ∏¨ÔºåÂú®Âü∫Ê∫ñ‰∏≠ÁöÑÈö®Ê©üÂïèÈ°åÂ≠êÈõÜ‰∏≠ÔºàN = 200ÔºâÈáèÂåñÁï∂Ââç ML Á≥ªÁµ±ÁöÑËÉΩÂäõ„ÄÇÈõñÁÑ∂ LLM Âú®Ë®±Â§öÂü∫Ê∫ñ‰∏äÈÉΩÈÅîÂà∞‰∫ÜË∂Ö‰∫∫È°ûÁöÑË°®ÁèæÔºå‰ΩÜÂÆÉÂÄëÂú®Ê≠§Ë°®Áèæ‰∏ç‰Ω≥ÔºöÂ∞àÂÆ∂È†êÊ∏¨Âì°ÂÑ™ÊñºË°®ÁèæÊúÄ‰Ω≥ÁöÑ LLMÔºàp ÂÄº <= 0.01Ôºâ„ÄÇÊàëÂÄëÂú® www.forecastbench.org ‰∏äÁöÑÂÖ¨ÈñãÊéíË°åÊ¶ú‰∏≠È°ØÁ§∫Á≥ªÁµ±Âíå‰∫∫È°ûÂàÜÊï∏„ÄÇ

##### **Counterfactual Evaluation of Ads Ranking Models through Domain Adaptation**
2409.19824v1 by Mohamed A. Radwan, Himaghna Bhattacharjee, Quinn Lanners, Jiasheng Zhang, Serkan Karakulak, Houssam Nassif, Murat Ali Bayir

We propose a domain-adapted reward model that works alongside an Offline A/B
testing system for evaluating ranking models. This approach effectively
measures reward for ranking model changes in large-scale Ads recommender
systems, where model-free methods like IPS are not feasible. Our experiments
demonstrate that the proposed technique outperforms both the vanilla IPS method
and approaches using non-generalized reward models.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÈ†òÂüüÈÅ©ÊáâÁçéÂãµÊ®°ÂûãÔºåËàáÈõ¢Á∑ö A/B Ê∏¨Ë©¶Á≥ªÁµ±‰∏ÄËµ∑‰ΩøÁî®ÔºåÁî®ÊñºË©ï‰º∞ÊéíÂêçÊ®°Âûã„ÄÇÊ≠§ÊñπÊ≥ïÊúâÊïàÂú∞Ë°°Èáè‰∫ÜÂú®Â§ßÂûãÂª£ÂëäÊé®Ëñ¶Á≥ªÁµ±‰∏≠ÊéíÂêçÊ®°ÂûãËÆäÊõ¥ÁöÑÁçéÂãµÔºåÂÖ∂‰∏≠ÂÉè IPS Á≠âÁÑ°Ê®°ÂûãÊñπÊ≥ï‰∏çÂèØË°å„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊäÄË°ìÂÑ™ÊñºÈ¶ôËçâ IPS ÊñπÊ≥ïÂíå‰ΩøÁî®ÈùûÂª£Áæ©ÁçéÂãµÊ®°ÂûãÁöÑÊñπÊ≥ï„ÄÇ

##### **Calibrating Language Models with Adaptive Temperature Scaling**
2409.19817v1 by Johnathan Xie, Annie S. Chen, Yoonho Lee, Eric Mitchell, Chelsea Finn

The effectiveness of large language models (LLMs) is not only measured by
their ability to generate accurate outputs but also by their calibration-how
well their confidence scores reflect the probability of their outputs being
correct. While unsupervised pre-training has been shown to yield LLMs with
well-calibrated conditional probabilities, recent studies have shown that after
fine-tuning with reinforcement learning from human feedback (RLHF), the
calibration of these models degrades significantly. In this work, we introduce
Adaptive Temperature Scaling (ATS), a post-hoc calibration method that predicts
a temperature scaling parameter for each token prediction. The predicted
temperature values adapt based on token-level features and are fit over a
standard supervised fine-tuning (SFT) dataset. The adaptive nature of ATS
addresses the varying degrees of calibration shift that can occur after RLHF
fine-tuning. ATS improves calibration by over 10-50% across three downstream
natural language evaluation benchmarks compared to prior calibration methods
and does not impede performance improvements from RLHF.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊïàËÉΩ‰∏çÂÉÖÂèñÊ±∫ÊñºÂÆÉÂÄëÁî¢ÁîüÊ∫ñÁ¢∫Ëº∏Âá∫ÁöÑËÉΩÂäõÔºåÈÇÑÂèñÊ±∫ÊñºÂÆÉÂÄëÁöÑÊ†°Ê∫ñËÉΩÂäõÔºå‰πüÂ∞±ÊòØÂÆÉÂÄëÁöÑ‰ø°ÂøÉÂàÜÊï∏ËÉΩÂ§öÊ∫ñÁ¢∫Âú∞ÂèçÊò†ÂÖ∂Ëº∏Âá∫ÁöÑÊ≠£Á¢∫ÊÄß„ÄÇÈõñÁÑ∂Â∑≤Ë≠âÂØ¶ÁÑ°Áõ£Áù£È†êË®ìÁ∑¥ÂèØÁî¢ÁîüÂÖ∑ÊúâËâØÂ•ΩÊ†°Ê∫ñÊ¢ù‰ª∂Ê©üÁéáÁöÑ LLMÔºå‰ΩÜÊúÄËøëÁöÑÁ†îÁ©∂È°ØÁ§∫ÔºåÂú®Á∂ìÈÅé‰∫∫È°ûÂõûÈ•ãÂº∑ÂåñÂ≠∏Áøí (RLHF) ÂæÆË™øÂæåÔºåÈÄô‰∫õÊ®°ÂûãÁöÑÊ†°Ê∫ñÊúÉÈ°ØËëó‰∏ãÈôç„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜËá™ÈÅ©ÊáâÊ∫´Â∫¶Á∏ÆÊîæ (ATS)ÔºåÈÄôÊòØ‰∏ÄÁ®Æ‰∫ãÂæåÊ†°Ê∫ñÊñπÊ≥ïÔºåÂèØÈ†êÊ∏¨ÊØèÂÄãÊ¨äÊùñÈ†êÊ∏¨ÁöÑÊ∫´Â∫¶Á∏ÆÊîæÂèÉÊï∏„ÄÇÈ†êÊ∏¨ÁöÑÊ∫´Â∫¶ÂÄºÊúÉÊ†πÊìöÊ¨äÊùñÂ±§Á¥öÁâπÂæµÈÄ≤Ë°åË™øÊï¥Ôºå‰∏¶ÈáùÂ∞çÊ®ôÊ∫ñÁõ£Áù£ÂºèÂæÆË™ø (SFT) Ë≥áÊñôÈõÜÈÄ≤Ë°åÊì¨Âêà„ÄÇATS ÁöÑËá™ÈÅ©ÊáâÁâπÊÄßÂèØËôïÁêÜ RLHF ÂæÆË™øÂæåÂèØËÉΩÁôºÁîüÁöÑÊ†°Ê∫ñËΩâÁßªÁöÑÁ®ãÂ∫¶Â∑ÆÁï∞„ÄÇËàáÂÖàÂâçÁöÑÊ†°Ê∫ñÊñπÊ≥ïÁõ∏ÊØîÔºåATS ÂèØÂ∞á‰∏âÂÄã‰∏ãÊ∏∏Ëá™ÁÑ∂Ë™ûË®ÄË©ï‰º∞Âü∫Ê∫ñÁöÑÊ†°Ê∫ñÊîπÂñÑË∂ÖÈÅé 10-50%Ôºå‰∏î‰∏çÊúÉÈòªÁ§ô RLHF ÁöÑÊïàËÉΩÊèêÂçá„ÄÇ

##### **Grounded Curriculum Learning**
2409.19816v1 by Linji Wang, Zifan Xu, Peter Stone, Xuesu Xiao

The high cost of real-world data for robotics Reinforcement Learning (RL)
leads to the wide usage of simulators. Despite extensive work on building
better dynamics models for simulators to match with the real world, there is
another, often-overlooked mismatch between simulations and the real world,
namely the distribution of available training tasks. Such a mismatch is further
exacerbated by existing curriculum learning techniques, which automatically
vary the simulation task distribution without considering its relevance to the
real world. Considering these challenges, we posit that curriculum learning for
robotics RL needs to be grounded in real-world task distributions. To this end,
we propose Grounded Curriculum Learning (GCL), which aligns the simulated task
distribution in the curriculum with the real world, as well as explicitly
considers what tasks have been given to the robot and how the robot has
performed in the past. We validate GCL using the BARN dataset on complex
navigation tasks, achieving a 6.8% and 6.5% higher success rate compared to a
state-of-the-art CL method and a curriculum designed by human experts,
respectively. These results show that GCL can enhance learning efficiency and
navigation performance by grounding the simulation task distribution in the
real world within an adaptive curriculum.

ÊëòË¶ÅÔºöÊ©üÂô®‰∫∫Âº∑ÂåñÂ≠∏Áøí (RL) ‰∏≠ÁúüÂØ¶‰∏ñÁïåÊï∏ÊìöÁöÑÈ´òÊòÇÊàêÊú¨Â∞éËá¥Âª£Ê≥õ‰ΩøÁî®Ê®°Êì¨Âô®„ÄÇÂÑòÁÆ°Âú®Âª∫Á´ãÊõ¥Â•ΩÁöÑÂãïÊÖãÊ®°Âûã‰ª•‰ΩøÊ®°Êì¨Âô®ËàáÁúüÂØ¶‰∏ñÁïåÁõ∏ÂåπÈÖçÊñπÈù¢ÂÅö‰∫ÜÂ§ßÈáèÂ∑•‰ΩúÔºå‰ΩÜÊ®°Êì¨ËàáÁúüÂØ¶‰∏ñÁïå‰πãÈñìÈÇÑÂ≠òÂú®Âè¶‰∏ÄÂÄãÁ∂ìÂ∏∏Ë¢´ÂøΩË¶ñÁöÑ‰∏çÂåπÈÖçÔºåÂç≥ÂèØÁî®Ë®ìÁ∑¥‰ªªÂãôÁöÑÂàÜÂ∏É„ÄÇÁèæÊúâÁöÑË™≤Á®ãÂ≠∏ÁøíÊäÄË°ìÈÄ≤‰∏ÄÊ≠•Âä†Âäá‰∫ÜÈÄôÁ®Æ‰∏çÂåπÈÖçÔºåÈÄô‰∫õÊäÄË°ìÊúÉËá™ÂãïÊîπËÆäÊ®°Êì¨‰ªªÂãôÂàÜ‰ΩàÔºåËÄå‰∏çÊúÉËÄÉÊÖÆÂÖ∂ËàáÁúüÂØ¶‰∏ñÁïåÁöÑÁõ∏ÈóúÊÄß„ÄÇËÄÉÊÖÆÂà∞ÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂÅáË®≠Ê©üÂô®‰∫∫ RL ÁöÑË™≤Á®ãÂ≠∏ÁøíÈúÄË¶Å‰ª•ÁúüÂØ¶‰∏ñÁïåÁöÑ‰ªªÂãôÂàÜ‰ΩàÁÇ∫Âü∫Á§é„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂü∫ÊñºÁúüÂØ¶‰∏ñÁïåÁöÑË™≤Á®ãÂ≠∏Áøí (GCL)ÔºåÂÆÉÂ∞áË™≤Á®ã‰∏≠ÁöÑÊ®°Êì¨‰ªªÂãôÂàÜ‰ΩàËàáÁúüÂØ¶‰∏ñÁïå‰øùÊåÅ‰∏ÄËá¥Ôºå‰∏¶ÊòéÁ¢∫ËÄÉÊÖÆ‰∫ÜÊ©üÂô®‰∫∫Â∑≤Áç≤ÂæóÂì™‰∫õ‰ªªÂãô‰ª•ÂèäÊ©üÂô®‰∫∫Âú®ÈÅéÂéªÁöÑË°®Áèæ„ÄÇÊàëÂÄë‰ΩøÁî® BARN Ë≥áÊñôÈõÜÈ©óË≠â‰∫Ü GCL Âú®Ë§áÈõúÂ∞éËà™‰ªªÂãô‰∏≠ÔºåËàáÊúÄÂÖàÈÄ≤ÁöÑ CL ÊñπÊ≥ïÂíåÁî±‰∫∫È°ûÂ∞àÂÆ∂Ë®≠Ë®àÁöÑË™≤Á®ãÁõ∏ÊØîÔºåÂàÜÂà•ÂØ¶Áèæ‰∫Ü 6.8% Âíå 6.5% ÁöÑÊõ¥È´òÊàêÂäüÁéá„ÄÇÈÄô‰∫õÁµêÊûúË°®ÊòéÔºåGCL ËÉΩÂ§†ÈÄöÈÅéÂú®Ëá™ÈÅ©ÊáâË™≤Á®ã‰∏≠Â∞áÊ®°Êì¨‰ªªÂãôÂàÜ‰ΩàÂª∫Á´ãÂú®ÁúüÂØ¶‰∏ñÁïå‰∏≠‰æÜÊèêÈ´òÂ≠∏ÁøíÊïàÁéáÂíåÂ∞éËà™ÊÄßËÉΩ„ÄÇ

##### **Transforming Hidden States into Binary Semantic Features**
2409.19813v1 by Tom√°≈° Musil, David Mareƒçek

Large language models follow a lineage of many NLP applications that were
directly inspired by distributional semantics, but do not seem to be closely
related to it anymore. In this paper, we propose to employ the distributional
theory of meaning once again. Using Independent Component Analysis to overcome
some of its challenging aspects, we show that large language models represent
semantic features in their hidden states.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÈÅµÂæ™Ë®±Â§ö NLP ÊáâÁî®Á®ãÂºèÁöÑË≠úÁ≥ªÔºåÈÄô‰∫õÊáâÁî®Á®ãÂºèÁõ¥Êé•ÂèóÂà∞ÂàÜ‰ΩàË™ûÁæ©ÁöÑÂïüÁôºÔºå‰ΩÜ‰ºº‰πé‰∏çÂÜçËàáÂÖ∂ÂØÜÂàáÁõ∏Èóú„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂª∫Ë≠∞ÂÜçÊ¨°Êé°Áî®ÂàÜ‰ΩàÂºèÁöÑÊÑèÁæ©ÁêÜË´ñ„ÄÇÊàëÂÄë‰ΩøÁî®Áç®Á´ãÊàêÂàÜÂàÜÊûê‰æÜÂÖãÊúçÂÖ∂‰∏Ä‰∫õÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÊñπÈù¢ÔºåÊàëÂÄëË°®ÊòéÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®ÂÖ∂Èö±ËóèÁãÄÊÖã‰∏≠Ë°®Á§∫Ë™ûÁæ©ÁâπÂæµ„ÄÇ

