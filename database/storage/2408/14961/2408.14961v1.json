{"2408.14961": {"publish_time": "2024-08-27", "title": "CVPT: Cross-Attention help Visual Prompt Tuning adapt visual task", "paper_summary": "In recent years, the rapid expansion of model sizes has led to large-scale\npre-trained models demonstrating remarkable capabilities. Consequently, there\nhas been a trend towards increasing the scale of models. However, this trend\nintroduces significant challenges, including substantial computational costs of\ntraining and transfer to downstream tasks. To address these issues,\nParameter-Efficient Fine-Tuning (PEFT) methods have been introduced. These\nmethods optimize large-scale pre-trained models for specific tasks by\nfine-tuning a select group of parameters. Among these PEFT methods,\nadapter-based and prompt-based methods are the primary techniques.\nSpecifically, in the field of visual fine-tuning, adapters gain prominence over\nprompts because of the latter's relatively weaker performance and efficiency.\nUnder the circumstances, we refine the widely-used Visual Prompt Tuning (VPT)\nmethod, proposing Cross Visual Prompt Tuning (CVPT). CVPT calculates\ncross-attention between the prompt tokens and the embedded tokens, which allows\nus to compute the semantic relationship between them and conduct the\nfine-tuning of models exactly to adapt visual tasks better. Furthermore, we\nintroduce the weight-sharing mechanism to initialize the parameters of\ncross-attention, which avoids massive learnable parameters from cross-attention\nand enhances the representative capability of cross-attention. We conduct\ncomprehensive testing across 25 datasets and the result indicates that CVPT\nsignificantly improves VPT's performance and efficiency in visual tasks. For\nexample, on the VTAB-1K benchmark, CVPT outperforms VPT over 4% in average\naccuracy, rivaling the advanced adapter-based methods in performance and\nefficiency. Our experiments confirm that prompt-based methods can achieve\nexceptional results in visual fine-tuning.", "paper_summary_zh": "\u8fd1\u5e74\u6765\uff0c\u6a21\u578b\u89c4\u6a21\u7684\u5feb\u901f\u6269\u5c55\u5bfc\u81f4\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b\u5c55\u73b0\u51fa\u975e\u51e1\u7684\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u51fa\u73b0\u4e86\u6269\u5927\u6a21\u578b\u89c4\u6a21\u7684\u8d8b\u52bf\u3002\u7136\u800c\uff0c\u8fd9\u4e00\u8d8b\u52bf\u5e26\u6765\u4e86\u91cd\u5927\u6311\u6218\uff0c\u5305\u62ec\u8bad\u7ec3\u548c\u8fc1\u79fb\u5230\u4e0b\u6e38\u4efb\u52a1\u7684\u5de8\u5927\u8ba1\u7b97\u6210\u672c\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u5f15\u5165\u4e86\u53c2\u6570\u9ad8\u6548\u5fae\u8c03 (PEFT) \u65b9\u6cd5\u3002\u8fd9\u4e9b\u65b9\u6cd5\u901a\u8fc7\u5fae\u8c03\u9009\u5b9a\u7684\u53c2\u6570\u7ec4\u6765\u4f18\u5316\u7279\u5b9a\u4efb\u52a1\u7684\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b\u3002\u5728\u8fd9\u4e9b PEFT \u65b9\u6cd5\u4e2d\uff0c\u57fa\u4e8e\u9002\u914d\u5668\u548c\u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5\u662f\u4e3b\u8981\u6280\u672f\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5728\u89c6\u89c9\u5fae\u8c03\u9886\u57df\uff0c\u9002\u914d\u5668\u6bd4\u63d0\u793a\u66f4\u7a81\u51fa\uff0c\u56e0\u4e3a\u540e\u8005\u7684\u6027\u80fd\u548c\u6548\u7387\u76f8\u5bf9\u8f83\u5f31\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u6539\u8fdb\u4e86\u5e7f\u6cdb\u4f7f\u7528\u7684\u89c6\u89c9\u63d0\u793a\u5fae\u8c03 (VPT) \u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4ea4\u53c9\u89c6\u89c9\u63d0\u793a\u5fae\u8c03 (CVPT)\u3002CVPT \u8ba1\u7b97\u63d0\u793a\u6807\u8bb0\u548c\u5d4c\u5165\u6807\u8bb0\u4e4b\u95f4\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\uff0c\u8fd9\u4f7f\u6211\u4eec\u80fd\u591f\u8ba1\u7b97\u5b83\u4eec\u4e4b\u95f4\u7684\u8bed\u4e49\u5173\u7cfb\u5e76\u51c6\u786e\u5730\u8fdb\u884c\u6a21\u578b\u5fae\u8c03\u4ee5\u66f4\u597d\u5730\u9002\u5e94\u89c6\u89c9\u4efb\u52a1\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u6743\u91cd\u5171\u4eab\u673a\u5236\u6765\u521d\u59cb\u5316\u4ea4\u53c9\u6ce8\u610f\u529b\u7684\u53c2\u6570\uff0c\u8fd9\u907f\u514d\u4e86\u4ea4\u53c9\u6ce8\u610f\u529b\u7684\u5927\u91cf\u53ef\u5b66\u4e60\u53c2\u6570\uff0c\u5e76\u589e\u5f3a\u4e86\u4ea4\u53c9\u6ce8\u610f\u529b\u7684\u8868\u793a\u80fd\u529b\u3002\u6211\u4eec\u5728 25 \u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u6d4b\u8bd5\uff0c\u7ed3\u679c\u8868\u660e CVPT \u663e\u7740\u63d0\u9ad8\u4e86 VPT \u5728\u89c6\u89c9\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u548c\u6548\u7387\u3002\u4f8b\u5982\uff0c\u5728 VTAB-1K \u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCVPT \u5728\u5e73\u5747\u51c6\u786e\u5ea6\u4e0a\u6bd4 VPT \u9ad8\u51fa 4%\uff0c\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u4e0e\u57fa\u4e8e\u9ad8\u7ea7\u9002\u914d\u5668\u7684\u65b9\u6cd5\u76f8\u5ab2\u7f8e\u3002\u6211\u4eec\u7684\u5b9e\u9a8c\u8bc1\u5b9e\uff0c\u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5\u53ef\u4ee5\u5728\u89c6\u89c9\u5fae\u8c03\u4e2d\u53d6\u5f97\u975e\u51e1\u7684\u6210\u679c\u3002", "author": "Lingyun Huang et.al.", "authors": "Lingyun Huang, Jianxu Mao, Yaonan Wang, Junfei Yi, Ziming Tao", "id": "2408.14961v1", "paper_url": "http://arxiv.org/abs/2408.14961v1", "repo": "null"}}