{"2406.03843": {"publish_time": "2024-06-06", "title": "POEM: Interactive Prompt Optimization for Enhancing Multimodal Reasoning of Large Language Models", "paper_summary": "Large language models (LLMs) have exhibited impressive abilities for\nmultimodal content comprehension and reasoning with proper prompting in zero-\nor few-shot settings. Despite the proliferation of interactive systems\ndeveloped to support prompt engineering for LLMs across various tasks, most\nhave primarily focused on textual or visual inputs, thus neglecting the complex\ninterplay between modalities within multimodal inputs. This oversight hinders\nthe development of effective prompts that guide model multimodal reasoning\nprocesses by fully exploiting the rich context provided by multiple modalities.\nIn this paper, we present POEM, a visual analytics system to facilitate\nefficient prompt engineering for enhancing the multimodal reasoning performance\nof LLMs. The system enables users to explore the interaction patterns across\nmodalities at varying levels of detail for a comprehensive understanding of the\nmultimodal knowledge elicited by various prompts. Through diverse\nrecommendations of demonstration examples and instructional principles, POEM\nsupports users in iteratively crafting and refining prompts to better align and\nenhance model knowledge with human insights. The effectiveness and efficiency\nof our system are validated through two case studies and interviews with\nexperts.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u591a\u6a21\u614b\u5167\u5bb9\u7406\u89e3\u548c\u63a8\u7406\u65b9\u9762\u8868\u73fe\u51fa\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u80fd\u529b\uff0c\u4e26\u5728\u96f6\u6b21\u6216\u5c11\u6b21\u5617\u8a66\u7684\u8a2d\u5b9a\u4e2d\u9069\u7576\u5730\u63d0\u793a\u3002\u5118\u7ba1\u958b\u767c\u4e86\u8a31\u591a\u4e92\u52d5\u5f0f\u7cfb\u7d71\u4f86\u652f\u63f4 LLM \u7684\u63d0\u793a\u5de5\u7a0b\uff0c\u4f46\u5927\u591a\u6578\u4e3b\u8981\u96c6\u4e2d\u5728\u6587\u5b57\u6216\u8996\u89ba\u8f38\u5165\uff0c\u56e0\u6b64\u5ffd\u7565\u4e86\u591a\u6a21\u614b\u8f38\u5165\u4e2d\u6a21\u614b\u4e4b\u9593\u7684\u8907\u96dc\u4ea4\u4e92\u4f5c\u7528\u3002\u9019\u7a2e\u758f\u5ffd\u963b\u7919\u4e86\u6709\u6548\u63d0\u793a\u7684\u767c\u5c55\uff0c\u9019\u4e9b\u63d0\u793a\u901a\u904e\u5145\u5206\u5229\u7528\u591a\u7a2e\u6a21\u614b\u63d0\u4f9b\u7684\u8c50\u5bcc\u80cc\u666f\u4f86\u6307\u5c0e\u6a21\u578b\u591a\u6a21\u614b\u63a8\u7406\u904e\u7a0b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86 POEM\uff0c\u9019\u662f\u4e00\u500b\u8996\u89ba\u5206\u6790\u7cfb\u7d71\uff0c\u7528\u65bc\u4fc3\u9032\u6709\u6548\u7684\u63d0\u793a\u5de5\u7a0b\uff0c\u4ee5\u589e\u5f37 LLM \u7684\u591a\u6a21\u614b\u63a8\u7406\u6548\u80fd\u3002\u8a72\u7cfb\u7d71\u4f7f\u7528\u6236\u80fd\u5920\u63a2\u7d22\u4e0d\u540c\u5c64\u7d1a\u7d30\u7bc0\u4e2d\u8de8\u6a21\u614b\u7684\u4ea4\u4e92\u6a21\u5f0f\uff0c\u4ee5\u5168\u9762\u4e86\u89e3\u5404\u7a2e\u63d0\u793a\u5f15\u767c\u7684\u591a\u6a21\u614b\u77e5\u8b58\u3002\u900f\u904e\u793a\u7bc4\u7bc4\u4f8b\u548c\u6559\u5b78\u539f\u5247\u7684\u591a\u6a23\u5316\u5efa\u8b70\uff0cPOEM \u652f\u63f4\u4f7f\u7528\u8005\u53cd\u8986\u5efa\u69cb\u548c\u8abf\u6574\u63d0\u793a\uff0c\u4ee5\u66f4\u597d\u5730\u8207\u4eba\u985e\u898b\u89e3\u5c0d\u9f4a\u4e26\u589e\u5f37\u6a21\u578b\u77e5\u8b58\u3002\u6211\u5011\u7cfb\u7d71\u7684\u6709\u6548\u6027\u548c\u6548\u7387\u5df2\u901a\u904e\u5169\u500b\u6848\u4f8b\u7814\u7a76\u548c\u5c08\u5bb6\u8a2a\u8ac7\u5f97\u5230\u9a57\u8b49\u3002", "author": "Jianben He et.al.", "authors": "Jianben He, Xingbo Wang, Shiyi Liu, Guande Wu, Claudio Silva, Huamin Qu", "id": "2406.03843v1", "paper_url": "http://arxiv.org/abs/2406.03843v1", "repo": "null"}}