{"2406.09205": {"publish_time": "2024-06-13", "title": "ReadCtrl: Personalizing text generation with readability-controlled instruction learning", "paper_summary": "Content generation conditioning on users's readability is an important\napplication for personalization. In an era of large language models (LLMs),\nreadability-controlled text generation based on LLMs has become increasingly\nimportant. This paper introduces a novel methodology called\n\"Readability-Controlled Instruction Learning (ReadCtrl),\" which aims to\ninstruction-tune LLMs to tailor users' readability levels. Unlike the\ntraditional methods, which primarily focused on categorical readability\nadjustments typically classified as high, medium, and low or expert and\nlayperson levels with limited success, ReadCtrl introduces a dynamic framework\nthat enables LLMs to generate content at various (near continuous level)\ncomplexity levels, thereby enhancing their versatility across different\napplications. Our results show that the ReadCtrl-Mistral-7B models\nsignificantly outperformed strong baseline models such as GPT-4 and Claude-3,\nwith a win rate of 52.1%:35.7% against GPT-4 in human evaluations. Furthermore,\nRead-Ctrl has shown significant improvements in automatic evaluations, as\nevidenced by better readability metrics (e.g., FOG, FKGL) and generation\nquality metrics (e.g., BLEU, SARI, SummaC-Factuality, UniEval-Consistency and\nCoherence). These results underscore Read-Ctrl's effectiveness and tenacity in\nproducing high-quality, contextually appropriate outputs that closely align\nwith targeted readability levels, marking a significant advancement in\npersonalized content generation using LLMs.", "paper_summary_zh": "\u5167\u5bb9\u751f\u6210\u4f9d\u8cf4\u65bc\u4f7f\u7528\u8005\u7684\u53ef\u8b80\u6027\uff0c\u5c0d\u500b\u4eba\u5316\u4f86\u8aaa\u662f\u4e00\u500b\u91cd\u8981\u7684\u61c9\u7528\u3002\u5728\u5927\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6642\u4ee3\uff0c\u57fa\u65bc LLM \u7684\u53ef\u8b80\u6027\u63a7\u5236\u6587\u672c\u751f\u6210\u8b8a\u5f97\u8d8a\u4f86\u8d8a\u91cd\u8981\u3002\u672c\u6587\u4ecb\u7d39\u4e86\u4e00\u7a2e\u540d\u70ba\u300c\u53ef\u8b80\u6027\u63a7\u5236\u6307\u4ee4\u5b78\u7fd2\uff08ReadCtrl\uff09\u300d\u7684\u65b0\u65b9\u6cd5\uff0c\u65e8\u5728\u5c0d LLM \u9032\u884c\u6307\u4ee4\u5fae\u8abf\uff0c\u4ee5\u8abf\u6574\u4f7f\u7528\u8005\u7684\u53ef\u8b80\u6027\u7b49\u7d1a\u3002\u8207\u50b3\u7d71\u65b9\u6cd5\u4e0d\u540c\uff0c\u50b3\u7d71\u65b9\u6cd5\u4e3b\u8981\u95dc\u6ce8\u5206\u985e\u7684\u53ef\u8b80\u6027\u8abf\u6574\uff0c\u901a\u5e38\u5206\u985e\u70ba\u9ad8\u3001\u4e2d\u3001\u4f4e\u6216\u5c08\u5bb6\u548c\u975e\u5c08\u696d\u4eba\u58eb\u7b49\u7d1a\uff0c\u4e14\u6210\u529f\u6709\u9650\uff0cReadCtrl \u5c0e\u5165\u4e86\u4e00\u500b\u52d5\u614b\u67b6\u69cb\uff0c\u4f7f LLM \u80fd\u5920\u751f\u6210\u5404\u7a2e\uff08\u8fd1\u4e4e\u9023\u7e8c\u7b49\u7d1a\uff09\u8907\u96dc\u7a0b\u5ea6\u7684\u5167\u5bb9\uff0c\u5f9e\u800c\u589e\u5f37\u5176\u5728\u4e0d\u540c\u61c9\u7528\u4e2d\u7684\u591a\u529f\u80fd\u6027\u3002\u6211\u5011\u7684\u7d50\u679c\u986f\u793a\uff0cReadCtrl-Mistral-7B \u6a21\u578b\u986f\u8457\u512a\u65bc GPT-4 \u548c Claude-3 \u7b49\u5f37\u5927\u7684\u57fa\u6e96\u6a21\u578b\uff0c\u5728\u4eba\u985e\u8a55\u4f30\u4e2d\u4ee5 52.1%:35.7% \u64ca\u6557 GPT-4\u3002\u6b64\u5916\uff0cRead-Ctrl \u5728\u81ea\u52d5\u8a55\u4f30\u4e2d\u4e5f\u986f\u793a\u51fa\u986f\u8457\u7684\u6539\u9032\uff0c\u9019\u5f9e\u66f4\u597d\u7684\u53ef\u8b80\u6027\u6307\u6a19\uff08\u4f8b\u5982 FOG\u3001FKGL\uff09\u548c\u751f\u6210\u54c1\u8cea\u6307\u6a19\uff08\u4f8b\u5982 BLEU\u3001SARI\u3001SummaC-Factuality\u3001UniEval-Consistency \u548c Coherence\uff09\u4e2d\u53ef\u4ee5\u5f97\u5230\u8b49\u660e\u3002\u9019\u4e9b\u7d50\u679c\u5f37\u8abf\u4e86 Read-Ctrl \u5728\u7522\u751f\u9ad8\u54c1\u8cea\u3001\u7b26\u5408\u8108\u7d61\u7684\u8f38\u51fa\u65b9\u9762\u7684\u6709\u6548\u6027\u548c\u97cc\u6027\uff0c\u9019\u4e9b\u8f38\u51fa\u8207\u76ee\u6a19\u53ef\u8b80\u6027\u7b49\u7d1a\u7dca\u5bc6\u5c0d\u9f4a\uff0c\u6a19\u8a8c\u8457\u4f7f\u7528 LLM \u9032\u884c\u500b\u4eba\u5316\u5167\u5bb9\u751f\u6210\u65b9\u9762\u7684\u4e00\u9805\u91cd\u5927\u9032\u5c55\u3002", "author": "Hieu Tran et.al.", "authors": "Hieu Tran, Zonghai Yao, Lingxi Li, Hong Yu", "id": "2406.09205v1", "paper_url": "http://arxiv.org/abs/2406.09205v1", "repo": "null"}}