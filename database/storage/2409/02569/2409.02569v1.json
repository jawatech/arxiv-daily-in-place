{"2409.02569": {"publish_time": "2024-09-04", "title": "More is More: Addition Bias in Large Language Models", "paper_summary": "In this paper, we investigate the presence of additive bias in Large Language\nModels (LLMs), drawing a parallel to the cognitive bias observed in humans\nwhere individuals tend to favor additive over subtractive changes. Using a\nseries of controlled experiments, we tested various LLMs, including GPT-3.5\nTurbo, Claude 3.5 Sonnet, Mistral, Math$\\Sigma$tral, and Llama 3.1, on tasks\ndesigned to measure their propensity for additive versus subtractive\nmodifications. Our findings demonstrate a significant preference for additive\nchanges across all tested models. For example, in a palindrome creation task,\nLlama 3.1 favored adding letters 97.85% of the time over removing them.\nSimilarly, in a Lego tower balancing task, GPT-3.5 Turbo chose to add a brick\n76.38% of the time rather than remove one. In a text summarization task,\nMistral 7B produced longer summaries in 59.40% to 75.10% of cases when asked to\nimprove its own or others' writing. These results indicate that, similar to\nhumans, LLMs exhibit a marked additive bias, which might have implications when\nLLMs are used on a large scale. Addittive bias might increase resource use and\nenvironmental impact, leading to higher economic costs due to overconsumption\nand waste. This bias should be considered in the development and application of\nLLMs to ensure balanced and efficient problem-solving approaches.", "paper_summary_zh": "<paragraph>\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4e2d\u52a0\u6cd5\u504f\u5dee\u7684\u5b58\u5728\uff0c\u4e26\u8207\u4eba\u985e\u8a8d\u77e5\u504f\u5dee\u9032\u884c\u6bd4\u8f03\uff0c\u5176\u4e2d\u500b\u4eba\u50be\u5411\u65bc\u504f\u597d\u52a0\u6cd5\u800c\u975e\u6e1b\u6cd5\u8b8a\u66f4\u3002\u6211\u5011\u4f7f\u7528\u4e00\u7cfb\u5217\u53d7\u63a7\u5be6\u9a57\uff0c\u6e2c\u8a66\u4e86\u5404\u7a2e LLM\uff0c\u5305\u62ec GPT-3.5 Turbo\u3001Claude 3.5 Sonnet\u3001Mistral\u3001Math$\\Sigma$tral \u548c Llama 3.1\uff0c\u9019\u4e9b\u4efb\u52d9\u65e8\u5728\u8861\u91cf\u5b83\u5011\u5c0d\u52a0\u6cd5\u8207\u6e1b\u6cd5\u4fee\u6539\u7684\u50be\u5411\u6027\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u986f\u793a\uff0c\u6240\u6709\u6e2c\u8a66\u6a21\u578b\u90fd\u986f\u8457\u504f\u597d\u52a0\u6cd5\u8b8a\u66f4\u3002\u4f8b\u5982\uff0c\u5728\u8ff4\u6587\u5275\u5efa\u4efb\u52d9\u4e2d\uff0cLlama 3.1 \u6709 97.85% \u7684\u6642\u9593\u504f\u597d\u65b0\u589e\u5b57\u6bcd\uff0c\u800c\u4e0d\u662f\u79fb\u9664\u5b57\u6bcd\u3002\u985e\u4f3c\u5730\uff0c\u5728\u6a02\u9ad8\u7a4d\u6728\u5e73\u8861\u4efb\u52d9\u4e2d\uff0cGPT-3.5 Turbo \u6709 76.38% \u7684\u6642\u9593\u9078\u64c7\u65b0\u589e\u7a4d\u6728\uff0c\u800c\u4e0d\u662f\u79fb\u9664\u7a4d\u6728\u3002\u5728\u6587\u5b57\u6458\u8981\u4efb\u52d9\u4e2d\uff0cMistral 7B \u5728 59.40% \u5230 75.10% \u7684\u60c5\u6cc1\u4e0b\u7522\u751f\u8f03\u9577\u7684\u6458\u8981\uff0c\u7576\u88ab\u8981\u6c42\u6539\u5584\u5176\u81ea\u8eab\u6216\u4ed6\u4eba\u7684\u5beb\u4f5c\u6642\u3002\u9019\u4e9b\u7d50\u679c\u8868\u660e\uff0c\u8207\u4eba\u985e\u985e\u4f3c\uff0cLLM \u8868\u73fe\u51fa\u660e\u986f\u7684\u52a0\u6cd5\u504f\u5dee\uff0c\u9019\u5728 LLM \u5927\u898f\u6a21\u4f7f\u7528\u6642\u53ef\u80fd\u6703\u7522\u751f\u5f71\u97ff\u3002\u52a0\u6cd5\u504f\u5dee\u53ef\u80fd\u6703\u589e\u52a0\u8cc7\u6e90\u4f7f\u7528\u548c\u74b0\u5883\u5f71\u97ff\uff0c\u5f9e\u800c\u5c0e\u81f4\u56e0\u904e\u5ea6\u6d88\u8cbb\u548c\u6d6a\u8cbb\u800c\u7522\u751f\u7684\u8f03\u9ad8\u7d93\u6fdf\u6210\u672c\u3002\u5728\u958b\u767c\u548c\u61c9\u7528 LLM \u6642\u61c9\u8003\u616e\u9019\u7a2e\u504f\u5dee\uff0c\u4ee5\u78ba\u4fdd\u5e73\u8861\u4e14\u6709\u6548\u7387\u7684\u89e3\u6c7a\u554f\u984c\u65b9\u6cd5\u3002</paragraph>", "author": "Luca Santagata et.al.", "authors": "Luca Santagata, Cristiano De Nobili", "id": "2409.02569v1", "paper_url": "http://arxiv.org/abs/2409.02569v1", "repo": "null"}}