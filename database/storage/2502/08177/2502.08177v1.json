{"2502.08177": {"publish_time": "2025-02-12", "title": "SycEval: Evaluating LLM Sycophancy", "paper_summary": "Large language models (LLMs) are increasingly applied in educational,\nclinical, and professional settings, but their tendency for sycophancy --\nprioritizing user agreement over independent reasoning -- poses risks to\nreliability. This study introduces a framework to evaluate sycophantic behavior\nin ChatGPT-4o, Claude-Sonnet, and Gemini-1.5-Pro across AMPS (mathematics) and\nMedQuad (medical advice) datasets. Sycophantic behavior was observed in 58.19%\nof cases, with Gemini exhibiting the highest rate (62.47%) and ChatGPT the\nlowest (56.71%). Progressive sycophancy, leading to correct answers, occurred\nin 43.52% of cases, while regressive sycophancy, leading to incorrect answers,\nwas observed in 14.66%. Preemptive rebuttals demonstrated significantly higher\nsycophancy rates than in-context rebuttals (61.75% vs. 56.52%, $Z=5.87$,\n$p<0.001$), particularly in computational tasks, where regressive sycophancy\nincreased significantly (preemptive: 8.13%, in-context: 3.54%, $p<0.001$).\nSimple rebuttals maximized progressive sycophancy ($Z=6.59$, $p<0.001$), while\ncitation-based rebuttals exhibited the highest regressive rates ($Z=6.59$,\n$p<0.001$). Sycophantic behavior showed high persistence (78.5%, 95% CI:\n[77.2%, 79.8%]) regardless of context or model. These findings emphasize the\nrisks and opportunities of deploying LLMs in structured and dynamic domains,\noffering insights into prompt programming and model optimization for safer AI\napplications.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u65e5\u76ca\u61c9\u7528\u65bc\u6559\u80b2\u3001\u81e8\u5e8a\u548c\u5c08\u696d\u9818\u57df\uff0c\u4f46\u5b83\u5011\u8da8\u65bc\u8da8\u708e\u9644\u52e2\u2014\u2014\u512a\u5148\u8003\u616e\u7528\u6236\u540c\u610f\u800c\u975e\u7368\u7acb\u63a8\u7406\u2014\u2014\u5c0d\u53ef\u9760\u6027\u69cb\u6210\u98a8\u96aa\u3002\u672c\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u500b\u6846\u67b6\u4f86\u8a55\u4f30 ChatGPT-4o\u3001Claude-Sonnet \u548c Gemini-1.5-Pro \u4e2d\u7684\u8da8\u708e\u9644\u52e2\u884c\u70ba\uff0c\u6d89\u53ca AMPS\uff08\u6578\u5b78\uff09\u548c MedQuad\uff08\u91ab\u7642\u5efa\u8b70\uff09\u6578\u64da\u96c6\u3002\u5728 58.19% \u7684\u6848\u4f8b\u4e2d\u89c0\u5bdf\u5230\u4e86\u8da8\u708e\u9644\u52e2\u884c\u70ba\uff0c\u5176\u4e2d Gemini \u8868\u73fe\u51fa\u6700\u9ad8\u6bd4\u7387\uff0862.47%\uff09\uff0c\u800c ChatGPT \u6700\u4f4e\uff0856.71%\uff09\u3002\u5c0e\u81f4\u6b63\u78ba\u7b54\u6848\u7684\u6f38\u9032\u5f0f\u8da8\u708e\u9644\u52e2\u767c\u751f\u5728 43.52% \u7684\u6848\u4f8b\u4e2d\uff0c\u800c\u5c0e\u81f4\u4e0d\u6b63\u78ba\u7b54\u6848\u7684\u9000\u6b65\u5f0f\u8da8\u708e\u9644\u52e2\u5247\u5728 14.66% \u7684\u6848\u4f8b\u4e2d\u88ab\u89c0\u5bdf\u5230\u3002\u5148\u767c\u5236\u4eba\u7684\u53cd\u99c1\u8868\u73fe\u51fa\u986f\u8457\u9ad8\u65bc\u4e0a\u4e0b\u6587\u53cd\u99c1\u7684\u8da8\u708e\u9644\u52e2\u7387\uff0861.75% \u5c0d 56.52%\uff0cZ=5.87\uff0cp<0.001\uff09\uff0c\u7279\u5225\u662f\u5728\u8a08\u7b97\u4efb\u52d9\u4e2d\uff0c\u5176\u4e2d\u9000\u6b65\u5f0f\u8da8\u708e\u9644\u52e2\u986f\u8457\u589e\u52a0\uff08\u5148\u767c\u5236\u4eba\uff1a8.13%\uff0c\u4e0a\u4e0b\u6587\uff1a3.54%\uff0cp<0.001\uff09\u3002\u7c21\u55ae\u7684\u53cd\u99c1\u6700\u5927\u5316\u4e86\u6f38\u9032\u5f0f\u8da8\u708e\u9644\u52e2\uff08Z=6.59\uff0cp<0.001\uff09\uff0c\u800c\u57fa\u65bc\u5f15\u7528\u7684\u53cd\u99c1\u8868\u73fe\u51fa\u6700\u9ad8\u7684\u9000\u6b65\u5f0f\u6bd4\u7387\uff08Z=6.59\uff0cp<0.001\uff09\u3002\u8da8\u708e\u9644\u52e2\u884c\u70ba\u8868\u73fe\u51fa\u5f88\u9ad8\u7684\u6301\u7e8c\u6027\uff0878.5%\uff0c95% CI\uff1a[77.2%\uff0c79.8%]\uff09\uff0c\u7121\u8ad6\u4e0a\u4e0b\u6587\u6216\u6a21\u578b\u5982\u4f55\u3002\u9019\u4e9b\u767c\u73fe\u5f37\u8abf\u4e86\u5728\u7d50\u69cb\u5316\u548c\u52d5\u614b\u9818\u57df\u90e8\u7f72 LLM \u7684\u98a8\u96aa\u548c\u6a5f\u9047\uff0c\u70ba\u66f4\u5b89\u5168\u7684 AI \u61c9\u7528\u63d0\u4f9b\u4e86\u63d0\u793a\u7de8\u7a0b\u548c\u6a21\u578b\u512a\u5316\u7684\u898b\u89e3\u3002", "author": "Aaron Fanous et.al.", "authors": "Aaron Fanous, Jacob Goldberg, Ank A. Agarwal, Joanna Lin, Anson Zhou, Roxana Daneshjou, Sanmi Koyejo", "id": "2502.08177v1", "paper_url": "http://arxiv.org/abs/2502.08177v1", "repo": "null"}}