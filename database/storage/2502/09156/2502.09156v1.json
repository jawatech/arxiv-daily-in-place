{"2502.09156": {"publish_time": "2025-02-13", "title": "Improving TCM Question Answering through Tree-Organized Self-Reflective Retrieval with LLMs", "paper_summary": "Objectives: Large language models (LLMs) can harness medical knowledge for\nintelligent question answering (Q&A), promising support for auxiliary diagnosis\nand medical talent cultivation. However, there is a deficiency of highly\nefficient retrieval-augmented generation (RAG) frameworks within the domain of\nTraditional Chinese Medicine (TCM). Our purpose is to observe the effect of the\nTree-Organized Self-Reflective Retrieval (TOSRR) framework on LLMs in TCM Q&A\ntasks.\n  Materials and Methods: We introduce the novel approach of knowledge\norganization, constructing a tree structure knowledge base with hierarchy. At\ninference time, our self-reflection framework retrieves from this knowledge\nbase, integrating information across chapters. Questions from the TCM Medical\nLicensing Examination (MLE) and the college Classics Course Exam (CCE) were\nrandomly selected as benchmark datasets.\n  Results: By coupling with GPT-4, the framework can improve the best\nperformance on the TCM MLE benchmark by 19.85% in absolute accuracy, and\nimprove recall accuracy from 27% to 38% on CCE datasets. In manual evaluation,\nthe framework improves a total of 18.52 points across dimensions of safety,\nconsistency, explainability, compliance, and coherence.\n  Conclusion: The TOSRR framework can effectively improve LLM's capability in\nQ&A tasks of TCM.", "paper_summary_zh": "\u76ee\u6a19\uff1a\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u53ef\u4ee5\u5229\u7528\u91ab\u7642\u77e5\u8b58\u9032\u884c\u667a\u80fd\u554f\u7b54\uff08Q&A\uff09\uff0c\u627f\u8afe\u652f\u6301\u8f14\u52a9\u8a3a\u65b7\u548c\u91ab\u7642\u4eba\u624d\u57f9\u990a\u3002\u7136\u800c\uff0c\u5728\u4e2d\u91ab\u9818\u57df\u5167\u7f3a\u4e4f\u9ad8\u6548\u7684\u6aa2\u7d22\u589e\u5f37\u751f\u6210\uff08RAG\uff09\u6846\u67b6\u3002\u6211\u5011\u7684\u76ee\u7684\u662f\u89c0\u5bdf\u6a39\u7d44\u7e54\u81ea\u7701\u6aa2\u7d22\uff08TOSRR\uff09\u6846\u67b6\u5c0d\u4e2d\u91ab\u554f\u7b54\u4efb\u52d9\u4e2d LLM \u7684\u5f71\u97ff\u3002\n\u6750\u6599\u548c\u65b9\u6cd5\uff1a\u6211\u5011\u5f15\u5165\u4e86\u77e5\u8b58\u7d44\u7e54\u7684\u65b0\u65b9\u6cd5\uff0c\u69cb\u5efa\u4e86\u4e00\u500b\u5177\u6709\u5c64\u6b21\u7684\u6a39\u7d50\u69cb\u77e5\u8b58\u5eab\u3002\u5728\u63a8\u7406\u6642\u9593\uff0c\u6211\u5011\u7684\u81ea\u7701\u6846\u67b6\u5f9e\u9019\u500b\u77e5\u8b58\u5eab\u4e2d\u6aa2\u7d22\uff0c\u6574\u5408\u7ae0\u7bc0\u4e2d\u7684\u4fe1\u606f\u3002\u4e2d\u91ab\u91ab\u5e2b\u8cc7\u683c\u8003\u8a66\uff08MLE\uff09\u548c\u5927\u5b78\u7d93\u5178\u8ab2\u7a0b\u8003\u8a66\uff08CCE\uff09\u4e2d\u7684\u554f\u984c\u88ab\u96a8\u6a5f\u9078\u70ba\u57fa\u6e96\u6578\u64da\u96c6\u3002\n\u7d50\u679c\uff1a\u901a\u904e\u8207 GPT-4 \u7d50\u5408\uff0c\u8a72\u6846\u67b6\u53ef\u4ee5\u5c07\u4e2d\u91ab MLE \u57fa\u6e96\u4e0a\u7684\u6700\u4f73\u6027\u80fd\u63d0\u9ad8 19.85% \u7684\u7d55\u5c0d\u6e96\u78ba\u5ea6\uff0c\u4e26\u5c07 CCE \u6578\u64da\u96c6\u4e0a\u7684\u53ec\u56de\u6e96\u78ba\u5ea6\u5f9e 27% \u63d0\u9ad8\u5230 38%\u3002\u5728\u624b\u52d5\u8a55\u4f30\u4e2d\uff0c\u8a72\u6846\u67b6\u5728\u5b89\u5168\u6027\u3001\u4e00\u81f4\u6027\u3001\u53ef\u89e3\u91cb\u6027\u3001\u5408\u898f\u6027\u548c\u9023\u8cab\u6027\u65b9\u9762\u7e3d\u5171\u63d0\u9ad8\u4e86 18.52 \u5206\u3002\n\u7d50\u8ad6\uff1aTOSRR \u6846\u67b6\u53ef\u4ee5\u6709\u6548\u63d0\u5347 LLM \u5728\u4e2d\u91ab\u554f\u7b54\u4efb\u52d9\u4e2d\u7684\u80fd\u529b\u3002", "author": "Chang Liu et.al.", "authors": "Chang Liu, Ying Chang, Jianmin Li, Yiqian Qu, Yu Li, Lingyong Cao, Shuyuan Lin", "id": "2502.09156v1", "paper_url": "http://arxiv.org/abs/2502.09156v1", "repo": "null"}}