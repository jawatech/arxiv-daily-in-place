{"2408.17131": {"publish_time": "2024-08-30", "title": "VQ4DiT: Efficient Post-Training Vector Quantization for Diffusion Transformers", "paper_summary": "The Diffusion Transformers Models (DiTs) have transitioned the network\narchitecture from traditional UNets to transformers, demonstrating exceptional\ncapabilities in image generation. Although DiTs have been widely applied to\nhigh-definition video generation tasks, their large parameter size hinders\ninference on edge devices. Vector quantization (VQ) can decompose model weight\ninto a codebook and assignments, allowing extreme weight quantization and\nsignificantly reducing memory usage. In this paper, we propose VQ4DiT, a fast\npost-training vector quantization method for DiTs. We found that traditional VQ\nmethods calibrate only the codebook without calibrating the assignments. This\nleads to weight sub-vectors being incorrectly assigned to the same assignment,\nproviding inconsistent gradients to the codebook and resulting in a suboptimal\nresult. To address this challenge, VQ4DiT calculates the candidate assignment\nset for each weight sub-vector based on Euclidean distance and reconstructs the\nsub-vector based on the weighted average. Then, using the zero-data and\nblock-wise calibration method, the optimal assignment from the set is\nefficiently selected while calibrating the codebook. VQ4DiT quantizes a DiT\nXL/2 model on a single NVIDIA A100 GPU within 20 minutes to 5 hours depending\non the different quantization settings. Experiments show that VQ4DiT\nestablishes a new state-of-the-art in model size and performance trade-offs,\nquantizing weights to 2-bit precision while retaining acceptable image\ngeneration quality.", "paper_summary_zh": "\u64f4\u6563Transformer\u6a21\u578b (DiT) \u5df2\u5c07\u7db2\u8def\u67b6\u69cb\u5f9e\u50b3\u7d71\u7684 UNet \u8f49\u63db\u70baTransformer\uff0c\u5728\u5f71\u50cf\u751f\u6210\u65b9\u9762\u5c55\u73fe\u51fa\u975e\u51e1\u7684\u80fd\u529b\u3002\u5118\u7ba1 DiT \u5df2\u5ee3\u6cdb\u61c9\u7528\u65bc\u9ad8\u756b\u8cea\u5f71\u7247\u751f\u6210\u4efb\u52d9\uff0c\u4f46\u5176\u9f90\u5927\u7684\u53c3\u6578\u898f\u6a21\u6703\u963b\u7919\u908a\u7de3\u88dd\u7f6e\u4e0a\u7684\u63a8\u8ad6\u3002\u5411\u91cf\u91cf\u5316 (VQ) \u53ef\u4ee5\u5c07\u6a21\u578b\u6b0a\u91cd\u5206\u89e3\u70ba\u78bc\u672c\u548c\u6307\u6d3e\uff0c\u5141\u8a31\u6975\u7aef\u6b0a\u91cd\u91cf\u5316\u4e26\u5927\u5e45\u6e1b\u5c11\u8a18\u61b6\u9ad4\u4f7f\u7528\u91cf\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa VQ4DiT\uff0c\u9019\u662f\u4e00\u7a2e\u91dd\u5c0d DiT \u7684\u5feb\u901f\u8a13\u7df4\u5f8c\u5411\u91cf\u91cf\u5316\u65b9\u6cd5\u3002\u6211\u5011\u767c\u73fe\u50b3\u7d71\u7684 VQ \u65b9\u6cd5\u53ea\u6821\u6e96\u78bc\u672c\uff0c\u800c\u4e0d\u6821\u6e96\u6307\u6d3e\u3002\u9019\u5c0e\u81f4\u6b0a\u91cd\u5b50\u5411\u91cf\u88ab\u932f\u8aa4\u5730\u6307\u6d3e\u7d66\u76f8\u540c\u7684\u6307\u6d3e\uff0c\u63d0\u4f9b\u4e0d\u4e00\u81f4\u7684\u68af\u5ea6\u7d66\u78bc\u672c\uff0c\u4e26\u5c0e\u81f4\u6b21\u4f73\u7d50\u679c\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u500b\u6311\u6230\uff0cVQ4DiT \u6839\u64da\u6b50\u5e7e\u91cc\u5f97\u8ddd\u96e2\u8a08\u7b97\u6bcf\u500b\u6b0a\u91cd\u5b50\u5411\u91cf\u7684\u5019\u9078\u6307\u6d3e\u96c6\uff0c\u4e26\u6839\u64da\u52a0\u6b0a\u5e73\u5747\u503c\u91cd\u5efa\u5b50\u5411\u91cf\u3002\u7136\u5f8c\uff0c\u4f7f\u7528\u96f6\u8cc7\u6599\u548c\u5340\u584a\u6821\u6e96\u65b9\u6cd5\uff0c\u5728\u6821\u6e96\u78bc\u672c\u7684\u540c\u6642\u6709\u6548\u5730\u5f9e\u96c6\u5408\u4e2d\u9078\u64c7\u6700\u4f73\u6307\u6d3e\u3002VQ4DiT \u5728\u55ae\u4e00 NVIDIA A100 GPU \u4e0a\u5c07 DiT XL/2 \u6a21\u578b\u91cf\u5316\u5230 2 \u4f4d\u5143\u7cbe\u78ba\u5ea6\uff0c\u5177\u5099\u53ef\u63a5\u53d7\u7684\u5f71\u50cf\u751f\u6210\u54c1\u8cea\uff0c\u5177\u9ad4\u6642\u9593\u53d6\u6c7a\u65bc\u4e0d\u540c\u7684\u91cf\u5316\u8a2d\u5b9a\uff0c\u7d04\u5728 20 \u5206\u9418\u5230 5 \u5c0f\u6642\u4e4b\u9593\u3002\u5be6\u9a57\u986f\u793a\uff0cVQ4DiT \u5728\u6a21\u578b\u5927\u5c0f\u548c\u6548\u80fd\u6b0a\u8861\u65b9\u9762\u5efa\u7acb\u4e86\u65b0\u7684\u6280\u8853\u6c34\u6e96\u3002", "author": "Juncan Deng et.al.", "authors": "Juncan Deng, Shuaiting Li, Zeyu Wang, Hong Gu, Kedong Xu, Kejie Huang", "id": "2408.17131v1", "paper_url": "http://arxiv.org/abs/2408.17131v1", "repo": "null"}}