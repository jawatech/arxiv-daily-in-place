{"2501.18837": {"publish_time": "2025-01-31", "title": "Constitutional Classifiers: Defending against Universal Jailbreaks across Thousands of Hours of Red Teaming", "paper_summary": "Large language models (LLMs) are vulnerable to universal jailbreaks-prompting\nstrategies that systematically bypass model safeguards and enable users to\ncarry out harmful processes that require many model interactions, like\nmanufacturing illegal substances at scale. To defend against these attacks, we\nintroduce Constitutional Classifiers: safeguards trained on synthetic data,\ngenerated by prompting LLMs with natural language rules (i.e., a constitution)\nspecifying permitted and restricted content. In over 3,000 estimated hours of\nred teaming, no red teamer found a universal jailbreak that could extract\ninformation from an early classifier-guarded LLM at a similar level of detail\nto an unguarded model across most target queries. On automated evaluations,\nenhanced classifiers demonstrated robust defense against held-out\ndomain-specific jailbreaks. These classifiers also maintain deployment\nviability, with an absolute 0.38% increase in production-traffic refusals and a\n23.7% inference overhead. Our work demonstrates that defending against\nuniversal jailbreaks while maintaining practical deployment viability is\ntractable.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5bb9\u6613\u53d7\u5230\u901a\u7528\u8d8a\u7344\u7684\u5f71\u97ff\uff0c\u9019\u4e9b\u7b56\u7565\u7cfb\u7d71\u6027\u5730\u7e5e\u904e\u6a21\u578b\u9632\u8b77\u63aa\u65bd\uff0c\u8b93\u4f7f\u7528\u8005\u5f97\u4ee5\u57f7\u884c\u9700\u8981\u8a31\u591a\u6a21\u578b\u4e92\u52d5\u7684\u6709\u5bb3\u7a0b\u5e8f\uff0c\u4f8b\u5982\u5927\u898f\u6a21\u88fd\u9020\u975e\u6cd5\u7269\u8cea\u3002\u70ba\u4e86\u9632\u79a6\u9019\u4e9b\u653b\u64ca\uff0c\u6211\u5011\u5f15\u5165\u4e86\u61b2\u6cd5\u5206\u985e\u5668\uff1a\u5728\u5408\u6210\u8cc7\u6599\u4e0a\u8a13\u7df4\u7684\u9632\u8b77\u63aa\u65bd\uff0c\u900f\u904e\u63d0\u793a LLM \u81ea\u7136\u8a9e\u8a00\u898f\u5247\uff08\u5373\u61b2\u6cd5\uff09\u4f86\u7522\u751f\uff0c\u8aaa\u660e\u5141\u8a31\u548c\u9650\u5236\u7684\u5167\u5bb9\u3002\u5728\u8d85\u904e 3,000 \u5c0f\u6642\u4f30\u8a08\u7684\u7d05\u968a\u6f14\u7df4\u4e2d\uff0c\u6c92\u6709\u7d05\u968a\u6210\u54e1\u627e\u5230\u4e00\u500b\u901a\u7528\u8d8a\u7344\uff0c\u80fd\u5920\u5f9e\u65e9\u671f\u5206\u985e\u5668\u4fdd\u8b77\u7684 LLM \u4e2d\u63d0\u53d6\u8cc7\u8a0a\uff0c\u5176\u8a73\u7d30\u7a0b\u5ea6\u8207\u5927\u591a\u6578\u76ee\u6a19\u67e5\u8a62\u4e2d\u672a\u53d7\u4fdd\u8b77\u7684\u6a21\u578b\u985e\u4f3c\u3002\u5728\u81ea\u52d5\u5316\u8a55\u4f30\u4e2d\uff0c\u589e\u5f37\u7684\u5206\u985e\u5668\u5c55\u73fe\u4e86\u5c0d\u7279\u5b9a\u9818\u57df\u8d8a\u7344\u7684\u5f37\u5927\u9632\u79a6\u529b\u3002\u9019\u4e9b\u5206\u985e\u5668\u4e5f\u7dad\u6301\u90e8\u7f72\u53ef\u884c\u6027\uff0c\u751f\u7522\u6d41\u91cf\u62d2\u7d55\u7387\u7d55\u5c0d\u589e\u52a0 0.38%\uff0c\u63a8\u8ad6\u8ca0\u64d4\u589e\u52a0 23.7%\u3002\u6211\u5011\u7684\u7814\u7a76\u8b49\u660e\uff0c\u5728\u7dad\u6301\u5be6\u969b\u90e8\u7f72\u53ef\u884c\u6027\u7684\u540c\u6642\u9632\u79a6\u901a\u7528\u8d8a\u7344\u662f\u53ef\u884c\u7684\u3002", "author": "Mrinank Sharma et.al.", "authors": "Mrinank Sharma, Meg Tong, Jesse Mu, Jerry Wei, Jorrit Kruthoff, Scott Goodfriend, Euan Ong, Alwin Peng, Raj Agarwal, Cem Anil, Amanda Askell, Nathan Bailey, Joe Benton, Emma Bluemke, Samuel R. Bowman, Eric Christiansen, Hoagy Cunningham, Andy Dau, Anjali Gopal, Rob Gilson, Logan Graham, Logan Howard, Nimit Kalra, Taesung Lee, Kevin Lin, Peter Lofgren, Francesco Mosconi, Clare O'Hara, Catherine Olsson, Linda Petrini, Samir Rajani, Nikhil Saxena, Alex Silverstein, Tanya Singh, Theodore Sumers, Leonard Tang, Kevin K. Troy, Constantin Weisser, Ruiqi Zhong, Giulio Zhou, Jan Leike, Jared Kaplan, Ethan Perez", "id": "2501.18837v1", "paper_url": "http://arxiv.org/abs/2501.18837v1", "repo": "null"}}