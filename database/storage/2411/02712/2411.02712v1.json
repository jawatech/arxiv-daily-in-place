{"2411.02712": {"publish_time": "2024-11-05", "title": "V-DPO: Mitigating Hallucination in Large Vision Language Models via Vision-Guided Direct Preference Optimization", "paper_summary": "Large vision-language models (LVLMs) suffer from hallucination, resulting in\nmisalignment between the output textual response and the input visual content.\nRecent research indicates that the over-reliance on the Large Language Model\n(LLM) backbone, as one cause of the LVLM hallucination, inherently introduces\nbias from language priors, leading to insufficient context attention to the\nvisual inputs.\n  We tackle this issue of hallucination by mitigating such over-reliance\nthrough preference learning. We propose Vision-guided Direct Preference\nOptimization (V-DPO) to enhance visual context learning at training time. To\ninterpret the effectiveness and generalizability of V-DPO on different types of\ntraining data, we construct a synthetic dataset containing both response- and\nimage-contrast preference pairs, compared against existing human-annotated\nhallucination samples. Our approach achieves significant improvements compared\nwith baseline methods across various hallucination benchmarks. Our analysis\nindicates that V-DPO excels in learning from image-contrast preference data,\ndemonstrating its superior ability to elicit and understand nuances of visual\ncontext. Our code is publicly available at https://github.com/YuxiXie/V-DPO.", "paper_summary_zh": "\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b (LVLMs) \u4f1a\u51fa\u73b0\u5e7b\u89c9\uff0c\u5bfc\u81f4\u8f93\u51fa\u6587\u672c\u54cd\u5e94\u4e0e\u8f93\u5165\u89c6\u89c9\u5185\u5bb9\u4e4b\u95f4\u4e0d\u4e00\u81f4\u3002\n\u6700\u8fd1\u7684\u7814\u7a76\u8868\u660e\uff0c\u8fc7\u5ea6\u4f9d\u8d56\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u4e3b\u5e72\uff0c\u4f5c\u4e3a LVLM \u5e7b\u89c9\u7684\u4e00\u4e2a\u539f\u56e0\uff0c\u672c\u8d28\u4e0a\u4f1a\u5f15\u5165\u8bed\u8a00\u5148\u9a8c\u7684\u504f\u5dee\uff0c\u5bfc\u81f4\u5bf9\u89c6\u89c9\u8f93\u5165\u7684\u4e0a\u4e0b\u6587\u5173\u6ce8\u4e0d\u8db3\u3002\n\u6211\u4eec\u901a\u8fc7\u504f\u597d\u5b66\u4e60\u6765\u89e3\u51b3\u5e7b\u89c9\u95ee\u9898\uff0c\u4ee5\u51cf\u8f7b\u8fd9\u79cd\u8fc7\u5ea6\u4f9d\u8d56\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u89c6\u89c9\u5f15\u5bfc\u76f4\u63a5\u504f\u597d\u4f18\u5316 (V-DPO)\uff0c\u4ee5\u5728\u8bad\u7ec3\u65f6\u589e\u5f3a\u89c6\u89c9\u4e0a\u4e0b\u6587\u5b66\u4e60\u3002\u4e3a\u4e86\u89e3\u91ca V-DPO \u5728\u4e0d\u540c\u7c7b\u578b\u7684\u8bad\u7ec3\u6570\u636e\u4e0a\u7684\u6709\u6548\u6027\u548c\u53ef\u63a8\u5e7f\u6027\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u54cd\u5e94\u548c\u56fe\u50cf\u5bf9\u6bd4\u504f\u597d\u5bf9\u7684\u5408\u6210\u6570\u636e\u96c6\uff0c\u5e76\u4e0e\u73b0\u6709\u4eba\u5de5\u6807\u6ce8\u7684\u5e7b\u89c9\u6837\u672c\u8fdb\u884c\u6bd4\u8f83\u3002\u4e0e\u5404\u79cd\u5e7b\u89c9\u57fa\u51c6\u4e2d\u7684\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u53d6\u5f97\u4e86\u663e\u7740\u7684\u6539\u8fdb\u3002\u6211\u4eec\u7684\u5206\u6790\u8868\u660e\uff0cV-DPO \u64c5\u957f\u4ece\u56fe\u50cf\u5bf9\u6bd4\u504f\u597d\u6570\u636e\u4e2d\u5b66\u4e60\uff0c\u5c55\u793a\u4e86\u5176\u5f15\u51fa\u548c\u7406\u89e3\u89c6\u89c9\u4e0a\u4e0b\u6587\u7ec6\u5fae\u5dee\u522b\u7684\u5353\u8d8a\u80fd\u529b\u3002\u6211\u4eec\u7684\u4ee3\u7801\u53ef\u5728 https://github.com/YuxiXie/V-DPO \u516c\u5f00\u83b7\u5f97\u3002", "author": "Yuxi Xie et.al.", "authors": "Yuxi Xie, Guanzhen Li, Xiao Xu, Min-Yen Kan", "id": "2411.02712v1", "paper_url": "http://arxiv.org/abs/2411.02712v1", "repo": "https://github.com/yuxixie/v-dpo"}}