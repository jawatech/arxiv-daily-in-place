{"2407.13928": {"publish_time": "2024-07-18", "title": "BiasDPO: Mitigating Bias in Language Models through Direct Preference Optimization", "paper_summary": "Large Language Models (LLMs) have become pivotal in advancing natural\nlanguage processing, yet their potential to perpetuate biases poses significant\nconcerns. This paper introduces a new framework employing Direct Preference\nOptimization (DPO) to mitigate gender, racial, and religious biases in\nLLM-generated English text. By developing a loss function that favors less\nbiased over biased completions, our approach cultivates a preference for\nrespectful and non-discriminatory language in LLMs. We also contribute a\nmanually designed dataset for training LLMs to recognize and correct biases.\nThis dataset encompasses a diverse range of prompts paired with both biased and\nunbiased completions. Implementing this approach on the Microsoft Phi-2 model,\nwe demonstrate substantial reductions in biased outputs as our model\noutperforms the baseline model on almost all bias benchmarks. Our model also\nachieves better performance compared to other open-source models on most\nbenchmarks. By reducing biases in the language generated by the model, our\nstudy marks a significant step towards developing more ethical and socially\nresponsible LLMs. We publicly release BiasDPO dataset on HuggingFace.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u6210\u70ba\u63a8\u9032\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u7684\u95dc\u9375\uff0c\u4f46\u5176\u6f5b\u5728\u7684\u504f\u898b\u5ef6\u7e8c\u6027\u5f15\u767c\u4e86\u91cd\u5927\u7684\u64d4\u6182\u3002\u672c\u6587\u4ecb\u7d39\u4e86\u4e00\u500b\u63a1\u7528\u76f4\u63a5\u504f\u597d\u6700\u4f73\u5316 (DPO) \u7684\u65b0\u6846\u67b6\uff0c\u4ee5\u6e1b\u8f15 LLM \u751f\u6210\u7684\u82f1\u6587\u6587\u672c\u4e2d\u7684\u6027\u5225\u3001\u7a2e\u65cf\u548c\u5b97\u6559\u504f\u898b\u3002\u901a\u904e\u958b\u767c\u4e00\u500b\u504f\u597d\u8f03\u5c11\u504f\u898b\u800c\u975e\u504f\u898b\u5b8c\u6210\u7684\u640d\u5931\u51fd\u6578\uff0c\u6211\u5011\u7684\u505a\u6cd5\u57f9\u990a\u4e86\u5c0d LLM \u4e2d\u5c0a\u91cd\u548c\u975e\u6b67\u8996\u6027\u8a9e\u8a00\u7684\u504f\u597d\u3002\u6211\u5011\u9084\u63d0\u4f9b\u4e86\u4e00\u500b\u624b\u52d5\u8a2d\u8a08\u7684\u6578\u64da\u96c6\uff0c\u7528\u65bc\u8a13\u7df4 LLM \u8b58\u5225\u548c\u7cfe\u6b63\u504f\u5dee\u3002\u6b64\u6578\u64da\u96c6\u5305\u542b\u8207\u6709\u504f\u898b\u548c\u7121\u504f\u898b\u5b8c\u6210\u914d\u5c0d\u7684\u5404\u7a2e\u63d0\u793a\u3002\u5728 Microsoft Phi-2 \u6a21\u578b\u4e0a\u5be6\u65bd\u6b64\u65b9\u6cd5\uff0c\u6211\u5011\u8b49\u660e\u4e86\u504f\u898b\u8f38\u51fa\u7684\u986f\u8457\u6e1b\u5c11\uff0c\u56e0\u70ba\u6211\u5011\u7684\u6a21\u578b\u5728\u5e7e\u4e4e\u6240\u6709\u504f\u898b\u57fa\u6e96\u4e0a\u90fd\u512a\u65bc\u57fa\u7dda\u6a21\u578b\u3002\u8207\u5927\u591a\u6578\u57fa\u6e96\u4e0a\u7684\u5176\u4ed6\u958b\u6e90\u6a21\u578b\u76f8\u6bd4\uff0c\u6211\u5011\u7684\u6a21\u578b\u4e5f\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u6027\u80fd\u3002\u901a\u904e\u6e1b\u5c11\u6a21\u578b\u751f\u6210\u7684\u8a9e\u8a00\u4e2d\u7684\u504f\u898b\uff0c\u6211\u5011\u7684\u7814\u7a76\u6a19\u8a8c\u8457\u671d\u8457\u958b\u767c\u66f4\u5177\u9053\u5fb7\u548c\u793e\u6703\u8cac\u4efb\u611f\u7684 LLM \u9081\u51fa\u7684\u91cd\u8981\u4e00\u6b65\u3002\u6211\u5011\u5728 HuggingFace \u4e0a\u516c\u958b\u767c\u5e03\u4e86 BiasDPO \u6578\u64da\u96c6\u3002", "author": "Ahmed Allam et.al.", "authors": "Ahmed Allam", "id": "2407.13928v1", "paper_url": "http://arxiv.org/abs/2407.13928v1", "repo": "null"}}