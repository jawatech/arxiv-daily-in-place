{"2501.02570": {"publish_time": "2025-01-05", "title": "Decoding fMRI Data into Captions using Prefix Language Modeling", "paper_summary": "With the advancements in Large Language and Latent Diffusion models, brain\ndecoding has achieved remarkable results in recent years. The works on the NSD\ndataset, with stimuli images from the COCO dataset, leverage the embeddings\nfrom the CLIP model for image reconstruction and GIT for captioning. However,\nthe current captioning approach introduces the challenge of potential data\ncontamination given that the GIT model was trained on the COCO dataset. In this\nwork, we present an alternative method for decoding brain signals into image\ncaptions by predicting a DINOv2 model's embedding of an image from the\ncorresponding fMRI signal and then providing its [CLS] token as the prefix to\nthe GPT-2 language model which decreases computational requirements\nconsiderably. Additionally, instead of commonly used Linear Regression, we\nexplore 3D Convolutional Neural Network mapping of fMRI signals to image\nembedding space for better accounting positional information of voxels.", "paper_summary_zh": "\u96a8\u8457\u5927\u578b\u8a9e\u8a00\u548c\u6f5b\u5728\u64f4\u6563\u6a21\u578b\u7684\u9032\u6b65\uff0c\u5927\u8166\u89e3\u78bc\u5728\u8fd1\u5e74\u4f86\u53d6\u5f97\u4e86\u986f\u8457\u7684\u6210\u679c\u3002NSD \u8cc7\u6599\u96c6\u7684\u7814\u7a76\uff0c\u4f7f\u7528\u4f86\u81ea COCO \u8cc7\u6599\u96c6\u7684\u523a\u6fc0\u5716\u50cf\uff0c\u5229\u7528 CLIP \u6a21\u578b\u7684\u5d4c\u5165\u9032\u884c\u5f71\u50cf\u91cd\u5efa\u548c GIT \u9032\u884c\u6a19\u984c\u8aaa\u660e\u3002\u7136\u800c\uff0c\u76ee\u524d\u7684\u6a19\u984c\u8aaa\u660e\u65b9\u6cd5\u5f15\u5165\u4e86\u6f5b\u5728\u8cc7\u6599\u6c61\u67d3\u7684\u6311\u6230\uff0c\u56e0\u70ba GIT \u6a21\u578b\u662f\u5728 COCO \u8cc7\u6599\u96c6\u4e0a\u8a13\u7df4\u7684\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u66ff\u4ee3\u65b9\u6cd5\uff0c\u5c07\u5927\u8166\u8a0a\u865f\u89e3\u78bc\u70ba\u5f71\u50cf\u6a19\u984c\uff0c\u65b9\u6cd5\u662f\u6839\u64da\u5c0d\u61c9\u7684 fMRI \u8a0a\u865f\u9810\u6e2c DINOv2 \u6a21\u578b\u7684\u5f71\u50cf\u5d4c\u5165\uff0c\u7136\u5f8c\u5c07\u5176 [CLS] \u6a19\u8a18\u4f5c\u70ba GPT-2 \u8a9e\u8a00\u6a21\u578b\u7684\u524d\u7db4\uff0c\u9019\u986f\u8457\u964d\u4f4e\u4e86\u904b\u7b97\u9700\u6c42\u3002\u6b64\u5916\uff0c\u6211\u5011\u63a2\u7d22\u4e86 3D \u5377\u7a4d\u795e\u7d93\u7db2\u8def\u5c07 fMRI \u8a0a\u865f\u5c0d\u61c9\u5230\u5f71\u50cf\u5d4c\u5165\u7a7a\u9593\uff0c\u4ee5\u66f4\u597d\u5730\u8aaa\u660e\u9ad4\u7d20\u7684\u4f4d\u7f6e\u8cc7\u8a0a\uff0c\u800c\u4e0d\u662f\u5e38\u7528\u7684\u7dda\u6027\u56de\u6b78\u3002", "author": "Vyacheslav Shen et.al.", "authors": "Vyacheslav Shen, Kassymzhomart Kunanbayev, Dae-Shik Kim", "id": "2501.02570v1", "paper_url": "http://arxiv.org/abs/2501.02570v1", "repo": "null"}}