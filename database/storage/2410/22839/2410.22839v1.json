{"2410.22839": {"publish_time": "2024-10-30", "title": "Danoliteracy of Generative, Large Language Models", "paper_summary": "The language technology moonshot moment of Generative, Large Language Models\n(GLLMs) was not limited to English: These models brought a surge of\ntechnological applications, investments and hype to low-resource languages as\nwell. However, the capabilities of these models in languages such as Danish\nwere until recently difficult to verify beyond qualitative demonstrations due\nto a lack of applicable evaluation corpora. We present a GLLM benchmark to\nevaluate Danoliteracy, a measure of Danish language and cultural competency,\nacross eight diverse scenarios such Danish citizenship tests and abstractive\nsocial media question answering. This limited-size benchmark is found to\nproduce a robust ranking that correlates to human feedback at $\\rho \\sim 0.8$\nwith GPT-4 and Claude Opus models achieving the highest rankings. Analyzing\nthese model results across scenarios, we find one strong underlying factor\nexplaining $95\\%$ of scenario performance variance for GLLMs in Danish,\nsuggesting a $g$ factor of model consistency in language adaption.", "paper_summary_zh": "\u751f\u6210\u5f0f\u5927\u578b\u8bed\u8a00\u6a21\u578b (GLLM) \u7684\u8bed\u8a00\u6280\u672f\u98de\u8dc3\u65f6\u523b\u4e0d\u4ec5\u9650\u4e8e\u82f1\u8bed\uff1a\u8fd9\u4e9b\u6a21\u578b\u4e3a\u8d44\u6e90\u532e\u4e4f\u7684\u8bed\u8a00\u5e26\u6765\u4e86\u6280\u672f\u5e94\u7528\u3001\u6295\u8d44\u548c\u7092\u4f5c\u70ed\u6f6e\u3002\u7136\u800c\uff0c\u7531\u4e8e\u7f3a\u4e4f\u9002\u7528\u7684\u8bc4\u4f30\u8bed\u6599\u5e93\uff0c\u76f4\u5230\u6700\u8fd1\uff0c\u8fd9\u4e9b\u6a21\u578b\u5728\u4e39\u9ea6\u8bed\u7b49\u8bed\u8a00\u4e2d\u7684\u80fd\u529b\u624d\u96be\u4ee5\u901a\u8fc7\u5b9a\u6027\u6f14\u793a\u6765\u9a8c\u8bc1\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a GLLM \u57fa\u51c6\u6765\u8bc4\u4f30\u4e39\u9ea6\u8bed\u7d20\u517b\uff0c\u5373\u4e39\u9ea6\u8bed\u8a00\u548c\u6587\u5316\u80fd\u529b\u7684\u8861\u91cf\u6807\u51c6\uff0c\u6db5\u76d6\u516b\u79cd\u4e0d\u540c\u7684\u573a\u666f\uff0c\u5982\u4e39\u9ea6\u516c\u6c11\u8eab\u4efd\u6d4b\u8bd5\u548c\u62bd\u8c61\u793e\u4ea4\u5a92\u4f53\u95ee\u7b54\u3002\u53d1\u73b0\u8fd9\u4e2a\u5c0f\u89c4\u6a21\u57fa\u51c6\u4ea7\u751f\u4e86\u7a33\u5065\u7684\u6392\u540d\uff0c\u4e0e\u4eba\u7c7b\u53cd\u9988\u76f8\u5173\uff0c\u5176\u4e2d GPT-4 \u548c Claude Opus \u6a21\u578b\u83b7\u5f97\u4e86\u6700\u9ad8\u6392\u540d\u3002\u901a\u8fc7\u5206\u6790\u8fd9\u4e9b\u6a21\u578b\u5728\u4e0d\u540c\u573a\u666f\u4e2d\u7684\u7ed3\u679c\uff0c\u6211\u4eec\u53d1\u73b0\u4e86\u4e00\u4e2a\u5f3a\u6709\u529b\u7684\u6f5c\u5728\u56e0\u7d20\uff0c\u89e3\u91ca\u4e86\u4e39\u9ea6\u8bed GLLM 95% \u7684\u573a\u666f\u6027\u80fd\u5dee\u5f02\uff0c\u8868\u660e\u6a21\u578b\u4e00\u81f4\u6027\u5728\u8bed\u8a00\u9002\u5e94\u4e2d\u7684 g \u56e0\u5b50\u3002", "author": "S\u00f8ren Vejlgaard Holm et.al.", "authors": "S\u00f8ren Vejlgaard Holm, Lars Kai Hansen, Martin Carsten Nielsen", "id": "2410.22839v1", "paper_url": "http://arxiv.org/abs/2410.22839v1", "repo": "null"}}