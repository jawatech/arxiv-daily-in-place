{"2502.04667": {"publish_time": "2025-02-07", "title": "Unveiling the Mechanisms of Explicit CoT Training: How Chain-of-Thought Enhances Reasoning Generalization", "paper_summary": "Training large language models (LLMs) with high-quality Chain-of-Thought\n(CoT) annotations has become a widely adopted strategy due to its significant\nenhancement of reasoning capabilities. To fully comprehend this approach, two\nquestions naturally arise: (Q1) What advantages does training with CoT offer\ncompared to training without CoT? (Q2) If there are advantages, what are the\nunderlying mechanisms of explicit CoT training? Analyzing the advantages and\nmechanisms of CoT training is challenging due to the many factors involved. To\naddress this, we conduct a detailed analysis using clear and controllable data\ndistributions and, for the first time, reveal that CoT training offers the\nfollowing advantages: (1) Training with CoT markedly improves reasoning\ngeneralization, extending it from in-distribution (ID) to both ID and\nout-of-distribution (OOD) scenarios, while also speeding up convergence; (2)\nEven when training with CoT includes a certain range of erroneous reasoning\nsteps, it still enables the model to learn reasoning patterns, leading to\nsystematic generalization. We further explore the underlying mechanisms from a\ncircuit perspective: (1) The data distribution (e.g., ratio $\\lambda$ and\npattern) plays a crucial role in influencing the model's systematic\ngeneralization; (2) CoT training (with two-hop facts) internalizes reasoning\ninto a two-stage generalizing circuit, where the number of stages corresponds\nto the explicit reasoning steps during training. Our findings elucidate the\nmechanisms underlying explicit CoT training and offer critical insights into\ntuning strategies for LLMs to achieve robust generalization.", "paper_summary_zh": "<paragraph>\u4f7f\u7528\u9ad8\u54c1\u8cea\u601d\u7dad\u93c8 (CoT) \u6a19\u8a3b\u4f86\u8a13\u7df4\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u6210\u70ba\u5ee3\u6cdb\u63a1\u7528\u7684\u7b56\u7565\uff0c\u56e0\u70ba\u5b83\u986f\u8457\u589e\u5f37\u4e86\u63a8\u7406\u80fd\u529b\u3002\u70ba\u4e86\u5145\u5206\u7406\u89e3\u9019\u7a2e\u65b9\u6cd5\uff0c\u81ea\u7136\u6703\u7522\u751f\u5169\u500b\u554f\u984c\uff1a(Q1) \u8207\u6c92\u6709 CoT \u7684\u8a13\u7df4\u76f8\u6bd4\uff0c\u4f7f\u7528 CoT \u8a13\u7df4\u6709\u54ea\u4e9b\u512a\u9ede\uff1f(Q2) \u5982\u679c\u6709\u512a\u9ede\uff0c\u660e\u78ba\u7684 CoT \u8a13\u7df4\u7684\u5e95\u5c64\u6a5f\u5236\u662f\u4ec0\u9ebc\uff1f\u5206\u6790 CoT \u8a13\u7df4\u7684\u512a\u9ede\u548c\u6a5f\u5236\u5177\u6709\u6311\u6230\u6027\uff0c\u56e0\u70ba\u6d89\u53ca\u8a31\u591a\u56e0\u7d20\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u4f7f\u7528\u6e05\u6670\u4e14\u53ef\u63a7\u7684\u8cc7\u6599\u5206\u4f48\u9032\u884c\u8a73\u7d30\u5206\u6790\uff0c\u4e26\u9996\u6b21\u63ed\u793a CoT \u8a13\u7df4\u63d0\u4f9b\u4ee5\u4e0b\u512a\u9ede\uff1a(1) \u4f7f\u7528 CoT \u9032\u884c\u8a13\u7df4\u986f\u8457\u6539\u5584\u63a8\u7406\u6cdb\u5316\uff0c\u5c07\u5176\u5f9e\u5206\u4f48\u5167 (ID) \u5ef6\u4f38\u5230 ID \u548c\u5206\u4f48\u5916 (OOD) \u5834\u666f\uff0c\u540c\u6642\u4e5f\u52a0\u5feb\u4e86\u6536\u6582\u901f\u5ea6\uff1b(2) \u5373\u4f7f\u4f7f\u7528 CoT \u9032\u884c\u8a13\u7df4\u5305\u542b\u4e00\u5b9a\u7bc4\u570d\u7684\u932f\u8aa4\u63a8\u7406\u6b65\u9a5f\uff0c\u5b83\u4ecd\u7136\u4f7f\u6a21\u578b\u80fd\u5920\u5b78\u7fd2\u63a8\u7406\u6a21\u5f0f\uff0c\u5f9e\u800c\u5c0e\u81f4\u7cfb\u7d71\u6027\u6cdb\u5316\u3002\u6211\u5011\u9032\u4e00\u6b65\u5f9e\u96fb\u8def\u89d2\u5ea6\u63a2\u8a0e\u5176\u5e95\u5c64\u6a5f\u5236\uff1a(1) \u8cc7\u6599\u5206\u4f48\uff08\u4f8b\u5982\u6bd4\u7387 $\\lambda$ \u548c\u6a21\u5f0f\uff09\u5728\u5f71\u97ff\u6a21\u578b\u7684\u7cfb\u7d71\u6027\u6cdb\u5316\u4e2d\u626e\u6f14\u8457\u81f3\u95dc\u91cd\u8981\u7684\u89d2\u8272\uff1b(2) CoT \u8a13\u7df4\uff08\u4f7f\u7528\u5169\u8df3\u4e8b\u5be6\uff09\u5c07\u63a8\u7406\u5167\u5316\u70ba\u5169\u968e\u6bb5\u6cdb\u5316\u96fb\u8def\uff0c\u5176\u4e2d\u968e\u6bb5\u6578\u5c0d\u61c9\u65bc\u8a13\u7df4\u671f\u9593\u7684\u660e\u78ba\u63a8\u7406\u6b65\u9a5f\u3002\u6211\u5011\u7684\u767c\u73fe\u95e1\u660e\u4e86\u660e\u78ba CoT \u8a13\u7df4\u7684\u5e95\u5c64\u6a5f\u5236\uff0c\u4e26\u70ba\u8abf\u6574 LLM \u7684\u7b56\u7565\u63d0\u4f9b\u4e86\u95dc\u9375\u898b\u89e3\uff0c\u4ee5\u5be6\u73fe\u5f37\u5927\u7684\u6cdb\u5316\u3002</paragraph>", "author": "Xinhao Yao et.al.", "authors": "Xinhao Yao, Ruifeng Ren, Yun Liao, Yong Liu", "id": "2502.04667v1", "paper_url": "http://arxiv.org/abs/2502.04667v1", "repo": "null"}}