{"2407.05705": {"publish_time": "2024-07-08", "title": "Fast and Continual Knowledge Graph Embedding via Incremental LoRA", "paper_summary": "Continual Knowledge Graph Embedding (CKGE) aims to efficiently learn new\nknowledge and simultaneously preserve old knowledge. Dominant approaches\nprimarily focus on alleviating catastrophic forgetting of old knowledge but\nneglect efficient learning for the emergence of new knowledge. However, in\nreal-world scenarios, knowledge graphs (KGs) are continuously growing, which\nbrings a significant challenge to fine-tuning KGE models efficiently. To\naddress this issue, we propose a fast CKGE framework (\\model), incorporating an\nincremental low-rank adapter (\\mec) mechanism to efficiently acquire new\nknowledge while preserving old knowledge. Specifically, to mitigate\ncatastrophic forgetting, \\model\\ isolates and allocates new knowledge to\nspecific layers based on the fine-grained influence between old and new KGs.\nSubsequently, to accelerate fine-tuning, \\model\\ devises an efficient \\mec\\\nmechanism, which embeds the specific layers into incremental low-rank adapters\nwith fewer training parameters. Moreover, \\mec\\ introduces adaptive rank\nallocation, which makes the LoRA aware of the importance of entities and\nadjusts its rank scale adaptively. We conduct experiments on four public\ndatasets and two new datasets with a larger initial scale. Experimental results\ndemonstrate that \\model\\ can reduce training time by 34\\%-49\\% while still\nachieving competitive link prediction performance against state-of-the-art\nmodels on four public datasets (average MRR score of 21.0\\% vs.\n21.1\\%).Meanwhile, on two newly constructed datasets, \\model\\ saves 51\\%-68\\%\ntraining time and improves link prediction performance by 1.5\\%.", "paper_summary_zh": "\u9023\u7e8c\u77e5\u8b58\u5716\u8868\u5d4c\u5165 (CKGE) \u65e8\u5728\u6709\u6548\u5b78\u7fd2\u65b0\u77e5\u8b58\uff0c\u4e26\u540c\u6642\u4fdd\u7559\u820a\u77e5\u8b58\u3002\u4e3b\u8981\u7684\u4f5c\u6cd5\u4e3b\u8981\u5c08\u6ce8\u65bc\u6e1b\u8f15\u820a\u77e5\u8b58\u7684\u707d\u96e3\u6027\u907a\u5fd8\uff0c\u4f46\u5ffd\u7565\u4e86\u5c0d\u65b0\u77e5\u8b58\u51fa\u73fe\u7684\u6709\u6548\u5b78\u7fd2\u3002\u7136\u800c\uff0c\u5728\u73fe\u5be6\u4e16\u754c\u7684\u5834\u666f\u4e2d\uff0c\u77e5\u8b58\u5716\u8868 (KG) \u4e0d\u65b7\u589e\u9577\uff0c\u9019\u70ba\u6709\u6548\u5fae\u8abf KGE \u6a21\u578b\u5e36\u4f86\u4e86\u91cd\u5927\u6311\u6230\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u5feb\u901f\u7684 CKGE \u6846\u67b6 (\\model)\uff0c\u7d50\u5408\u4e86\u4e00\u500b\u589e\u91cf\u4f4e\u79e9\u9069\u914d\u5668 (\\mec) \u6a5f\u5236\uff0c\u4ee5\u5728\u4fdd\u7559\u820a\u77e5\u8b58\u7684\u540c\u6642\u6709\u6548\u7372\u53d6\u65b0\u77e5\u8b58\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u70ba\u4e86\u6e1b\u8f15\u707d\u96e3\u6027\u907a\u5fd8\uff0c\\model\\ \u57fa\u65bc\u820a KG \u548c\u65b0 KG \u4e4b\u9593\u7684\u7d30\u7c92\u5ea6\u5f71\u97ff\uff0c\u5c07\u65b0\u77e5\u8b58\u9694\u96e2\u4e26\u5206\u914d\u5230\u7279\u5b9a\u5c64\u3002\u96a8\u5f8c\uff0c\u70ba\u4e86\u52a0\u901f\u5fae\u8abf\uff0c\\model\\ \u8a2d\u8a08\u4e86\u4e00\u500b\u6709\u6548\u7684 \\mec\\ \u6a5f\u5236\uff0c\u5b83\u5c07\u7279\u5b9a\u5c64\u5d4c\u5165\u5230\u5177\u6709\u8f03\u5c11\u8a13\u7df4\u53c3\u6578\u7684\u589e\u91cf\u4f4e\u79e9\u9069\u914d\u5668\u4e2d\u3002\u6b64\u5916\uff0c\\mec\\ \u5f15\u5165\u4e86\u81ea\u9069\u61c9\u79e9\u5206\u914d\uff0c\u9019\u4f7f\u5f97 LoRA \u4e86\u89e3\u5be6\u9ad4\u7684\u91cd\u8981\u6027\u4e26\u81ea\u9069\u61c9\u5730\u8abf\u6574\u5176\u79e9\u5c3a\u5ea6\u3002\u6211\u5011\u5728\u56db\u500b\u516c\u5171\u6578\u64da\u96c6\u548c\u5169\u500b\u5177\u6709\u66f4\u5927\u521d\u59cb\u898f\u6a21\u7684\u65b0\u6578\u64da\u96c6\u4e0a\u9032\u884c\u4e86\u5be6\u9a57\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\\model\\ \u53ef\u4ee5\u5c07\u8a13\u7df4\u6642\u9593\u7e2e\u77ed 34%-49%\uff0c\u540c\u6642\u5728\u56db\u500b\u516c\u5171\u6578\u64da\u96c6\u4e0a\u4ecd\u80fd\u9054\u5230\u8207\u6700\u5148\u9032\u6a21\u578b\u76f8\u6bd4\u5177\u6709\u7af6\u722d\u529b\u7684\u93c8\u8def\u9810\u6e2c\u6027\u80fd\uff08\u5e73\u5747 MRR \u5206\u6578\u70ba 21.0% \u5c0d\u6bd4 21.1%\uff09\u3002\u540c\u6642\uff0c\u5728\u5169\u500b\u65b0\u69cb\u5efa\u7684\u6578\u64da\u96c6\u4e0a\uff0c\\model\\ \u7bc0\u7701\u4e86 51%-68% \u7684\u8a13\u7df4\u6642\u9593\uff0c\u4e26\u5c07\u93c8\u8def\u9810\u6e2c\u6027\u80fd\u63d0\u9ad8\u4e86 1.5%\u3002", "author": "Jiajun Liu et.al.", "authors": "Jiajun Liu, Wenjun Ke, Peng Wang, Jiahao Wang, Jinhua Gao, Ziyu Shang, Guozheng Li, Zijie Xu, Ke Ji, Yining Li", "id": "2407.05705v1", "paper_url": "http://arxiv.org/abs/2407.05705v1", "repo": "https://github.com/seukgcode/fastkge"}}