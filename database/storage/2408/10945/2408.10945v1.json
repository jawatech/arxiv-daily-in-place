{"2408.10945": {"publish_time": "2024-08-20", "title": "HiRED: Attention-Guided Token Dropping for Efficient Inference of High-Resolution Vision-Language Models in Resource-Constrained Environments", "paper_summary": "High-resolution Vision-Language Models (VLMs) have been widely used in\nmultimodal tasks to enhance accuracy by preserving detailed image information.\nHowever, these models often generate excessive visual tokens due to encoding\nmultiple partitions of the input image. Processing these excessive visual\ntokens is computationally challenging, especially in resource-constrained\nenvironments with commodity GPUs. To support high-resolution images while\nmeeting resource constraints, we propose High-Resolution Early Dropping\n(HiRED), a token-dropping scheme that operates within a fixed token budget\nbefore the Large Language Model (LLM) stage. HiRED can be integrated with\nexisting high-resolution VLMs in a plug-and-play manner, as it requires no\nadditional training while still maintaining superior accuracy. We strategically\nuse the vision encoder's attention in the initial layers to assess the visual\ncontent of each image partition and allocate the token budget accordingly.\nThen, using the attention in the final layer, we select the most important\nvisual tokens from each partition within the allocated budget, dropping the\nrest. Empirically, when applied to LLaVA-Next-7B on NVIDIA TESLA P40 GPU, HiRED\nwith a 20% token budget increases token generation throughput by 4.7, reduces\nfirst-token generation latency by 15 seconds, and saves 2.3 GB of GPU memory\nfor a single inference.", "paper_summary_zh": "\u9ad8\u89e3\u6790\u5ea6\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM) \u5df2\u5ee3\u6cdb\u7528\u65bc\u591a\u6a21\u614b\u4efb\u52d9\u4e2d\uff0c\u900f\u904e\u4fdd\u7559\u8a73\u7d30\u7684\u5f71\u50cf\u8cc7\u8a0a\u4f86\u63d0\u5347\u6e96\u78ba\u5ea6\u3002\u7136\u800c\uff0c\u9019\u4e9b\u6a21\u578b\u901a\u5e38\u6703\u56e0\u70ba\u7de8\u78bc\u8f38\u5165\u5f71\u50cf\u7684\u5206\u5272\u5340\u584a\u800c\u7522\u751f\u904e\u91cf\u7684\u8996\u89ba\u7b26\u865f\u3002\u8655\u7406\u9019\u4e9b\u904e\u91cf\u7684\u8996\u89ba\u7b26\u865f\u5728\u8a08\u7b97\u4e0a\u5177\u6709\u6311\u6230\u6027\uff0c\u7279\u5225\u662f\u5728\u8cc7\u6e90\u53d7\u9650\u7684\u74b0\u5883\u4e2d\uff0c\u4f7f\u7528\u7684\u662f\u5546\u54c1\u5316\u7684 GPU\u3002\u70ba\u4e86\u652f\u63f4\u9ad8\u89e3\u6790\u5ea6\u5f71\u50cf\uff0c\u540c\u6642\u6eff\u8db3\u8cc7\u6e90\u9650\u5236\uff0c\u6211\u5011\u63d0\u51fa\u9ad8\u89e3\u6790\u5ea6\u65e9\u671f\u6368\u68c4 (HiRED)\uff0c\u9019\u662f\u4e00\u500b\u7b26\u865f\u6368\u68c4\u65b9\u6848\uff0c\u5728\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u968e\u6bb5\u4e4b\u524d\uff0c\u5728\u56fa\u5b9a\u7684\u7b26\u865f\u9810\u7b97\u4e2d\u904b\u4f5c\u3002HiRED \u53ef\u4ee5\u4ee5\u5373\u63d2\u5373\u7528\u7684\u65b9\u5f0f\u8207\u73fe\u6709\u7684\u9ad8\u89e3\u6790\u5ea6 VLM \u6574\u5408\uff0c\u56e0\u70ba\u5b83\u4e0d\u9700\u8981\u984d\u5916\u7684\u8a13\u7df4\uff0c\u540c\u6642\u4ecd\u80fd\u7dad\u6301\u512a\u7570\u7684\u6e96\u78ba\u5ea6\u3002\u6211\u5011\u7b56\u7565\u6027\u5730\u4f7f\u7528\u8996\u89ba\u7de8\u78bc\u5668\u5728\u521d\u59cb\u5c64\u4e2d\u7684\u6ce8\u610f\u529b\u4f86\u8a55\u4f30\u6bcf\u500b\u5f71\u50cf\u5206\u5272\u5340\u584a\u7684\u8996\u89ba\u5167\u5bb9\uff0c\u4e26\u64da\u6b64\u5206\u914d\u7b26\u865f\u9810\u7b97\u3002\u7136\u5f8c\uff0c\u4f7f\u7528\u6700\u5f8c\u4e00\u5c64\u7684\u6ce8\u610f\u529b\uff0c\u6211\u5011\u5f9e\u6bcf\u500b\u5206\u5272\u5340\u584a\u4e2d\u9078\u64c7\u5728\u5206\u914d\u9810\u7b97\u4e2d\u6700\u91cd\u8981\u7684\u8996\u89ba\u7b26\u865f\uff0c\u6368\u68c4\u5176\u9918\u7684\u7b26\u865f\u3002\u6839\u64da\u7d93\u9a57\uff0c\u7576\u61c9\u7528\u65bc NVIDIA TESLA P40 GPU \u4e0a\u7684 LLaVA-Next-7B \u6642\uff0cHiRED \u4ee5 20% \u7684\u7b26\u865f\u9810\u7b97\u5c07\u7b26\u865f\u7522\u751f\u91cf\u589e\u52a0 4.7 \u500d\uff0c\u5c07\u7b2c\u4e00\u500b\u7b26\u865f\u7522\u751f\u5ef6\u9072\u6e1b\u5c11 15 \u79d2\uff0c\u4e26\u70ba\u55ae\u4e00\u63a8\u8ad6\u7bc0\u7701 2.3 GB \u7684 GPU \u8a18\u61b6\u9ad4\u3002", "author": "Kazi Hasan Ibn Arif et.al.", "authors": "Kazi Hasan Ibn Arif, JinYi Yoon, Dimitrios S. Nikolopoulos, Hans Vandierendonck, Deepu John, Bo Ji", "id": "2408.10945v1", "paper_url": "http://arxiv.org/abs/2408.10945v1", "repo": "https://github.com/hasanar1f/hired"}}