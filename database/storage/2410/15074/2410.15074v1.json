{"2410.15074": {"publish_time": "2024-10-19", "title": "LLaVA-Ultra: Large Chinese Language and Vision Assistant for Ultrasound", "paper_summary": "Multimodal Large Language Model (MLLM) has recently garnered attention as a\nprominent research focus. By harnessing powerful LLM, it facilitates a\ntransition of conversational generative AI from unimodal text to performing\nmultimodal tasks. This boom begins to significantly impact medical field.\nHowever, general visual language model (VLM) lacks sophisticated comprehension\nfor medical visual question answering (Med-VQA). Even models specifically\ntailored for medical domain tend to produce vague answers with weak visual\nrelevance. In this paper, we propose a fine-grained adaptive VLM architecture\nfor Chinese medical visual conversations through parameter-efficient tuning.\nSpecifically, we devise a fusion module with fine-grained vision encoders to\nachieve enhancement for subtle medical visual semantics. Then we note data\nredundancy common to medical scenes is ignored in most prior works. In cases of\na single text paired with multiple figures, we utilize weighted scoring with\nknowledge distillation to adaptively screen valid images mirroring text\ndescriptions. For execution, we leverage a large-scale multimodal Chinese\nultrasound dataset obtained from the hospital. We create instruction-following\ndata based on text from professional doctors, which ensures effective tuning.\nWith enhanced model and quality data, our Large Chinese Language and Vision\nAssistant for Ultrasound (LLaVA-Ultra) shows strong capability and robustness\nto medical scenarios. On three Med-VQA datasets, LLaVA-Ultra surpasses previous\nstate-of-the-art models on various metrics.", "paper_summary_zh": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b (MLLM) \u6700\u8fd1\u4f5c\u4e3a\u4e00\u9879\u91cd\u8981\u7684\u7814\u7a76\u91cd\u70b9\u800c\u5907\u53d7\u5173\u6ce8\u3002\u901a\u8fc7\u5229\u7528\u529f\u80fd\u5f3a\u5927\u7684 LLM\uff0c\u5b83\u4fc3\u8fdb\u4e86\u4f1a\u8bdd\u751f\u6210\u5f0f AI \u4ece\u5355\u6a21\u6001\u6587\u672c\u5411\u6267\u884c\u591a\u6a21\u6001\u4efb\u52a1\u7684\u8f6c\u53d8\u3002\u8fd9\u79cd\u84ec\u52c3\u53d1\u5c55\u5f00\u59cb\u5bf9\u533b\u5b66\u9886\u57df\u4ea7\u751f\u91cd\u5927\u5f71\u54cd\u3002\u7136\u800c\uff0c\u901a\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b (VLM) \u7f3a\u4e4f\u5bf9\u533b\u5b66\u89c6\u89c9\u95ee\u9898\u89e3\u7b54 (Med-VQA) \u7684\u590d\u6742\u7406\u89e3\u3002\u5373\u4f7f\u662f\u4e13\u95e8\u9488\u5bf9\u533b\u5b66\u9886\u57df\u7684\u6a21\u578b\u4e5f\u503e\u5411\u4e8e\u4ea7\u751f\u6a21\u7cca\u7684\u7b54\u6848\uff0c\u4e14\u89c6\u89c9\u76f8\u5173\u6027\u8f83\u5f31\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7ec6\u7c92\u5ea6\u81ea\u9002\u5e94 VLM \u67b6\u6784\uff0c\u7528\u4e8e\u901a\u8fc7\u53c2\u6570\u9ad8\u6548\u8c03\u4f18\u8fdb\u884c\u4e2d\u6587\u533b\u5b66\u89c6\u89c9\u5bf9\u8bdd\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u878d\u5408\u6a21\u5757\uff0c\u5176\u4e2d\u5305\u542b\u7ec6\u7c92\u5ea6\u89c6\u89c9\u7f16\u7801\u5668\uff0c\u4ee5\u589e\u5f3a\u5fae\u5999\u7684\u533b\u5b66\u89c6\u89c9\u8bed\u4e49\u3002\u7136\u540e\uff0c\u6211\u4eec\u6ce8\u610f\u5230\u5927\u591a\u6570\u5148\u524d\u7684\u5de5\u4f5c\u90fd\u5ffd\u7565\u4e86\u533b\u5b66\u573a\u666f\u4e2d\u5e38\u89c1\u7684\u6570\u636e\u5197\u4f59\u3002\u5728\u5355\u4e2a\u6587\u672c\u4e0e\u591a\u4e2a\u56fe\u5f62\u914d\u5bf9\u7684\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u5229\u7528\u52a0\u6743\u8bc4\u5206\u548c\u77e5\u8bc6\u84b8\u998f\u6765\u81ea\u9002\u5e94\u5730\u7b5b\u9009\u53cd\u6620\u6587\u672c\u63cf\u8ff0\u7684\u6709\u6548\u56fe\u50cf\u3002\u4e3a\u4e86\u6267\u884c\uff0c\u6211\u4eec\u5229\u7528\u4ece\u533b\u9662\u83b7\u5f97\u7684\u5927\u89c4\u6a21\u591a\u6a21\u6001\u4e2d\u6587\u8d85\u58f0\u6570\u636e\u96c6\u3002\u6211\u4eec\u57fa\u4e8e\u4e13\u4e1a\u533b\u751f\u7684\u6587\u672c\u521b\u5efa\u4e86\u9075\u5faa\u6307\u4ee4\u7684\u6570\u636e\uff0c\u4ece\u800c\u786e\u4fdd\u4e86\u6709\u6548\u7684\u8c03\u4f18\u3002\u901a\u8fc7\u589e\u5f3a\u7684\u6a21\u578b\u548c\u9ad8\u8d28\u91cf\u6570\u636e\uff0c\u6211\u4eec\u7684\u4e2d\u6587\u8bed\u8a00\u548c\u8d85\u58f0\u89c6\u89c9\u52a9\u7406 (LLaVA-Ultra) \u5bf9\u533b\u5b66\u573a\u666f\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002\u5728\u4e09\u4e2a Med-VQA \u6570\u636e\u96c6\u4e0a\uff0cLLaVA-Ultra \u5728\u5404\u79cd\u6307\u6807\u4e0a\u90fd\u8d85\u8fc7\u4e86\u4ee5\u524d\u6700\u5148\u8fdb\u7684\u6a21\u578b\u3002", "author": "Xuechen Guo et.al.", "authors": "Xuechen Guo, Wenhao Chai, Shi-Yan Li, Gaoang Wang", "id": "2410.15074v1", "paper_url": "http://arxiv.org/abs/2410.15074v1", "repo": "null"}}