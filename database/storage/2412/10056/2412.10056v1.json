{"2412.10056": {"publish_time": "2024-12-13", "title": "GAOKAO-Eval: Does high scores truly reflect strong capabilities in LLMs?", "paper_summary": "Large Language Models (LLMs) are commonly evaluated using human-crafted\nbenchmarks, under the premise that higher scores implicitly reflect stronger\nhuman-like performance. However, there is growing concern that LLMs may ``game\"\nthese benchmarks due to data leakage, achieving high scores while struggling\nwith tasks simple for humans. To substantively address the problem, we create\nGAOKAO-Eval, a comprehensive benchmark based on China's National College\nEntrance Examination (Gaokao), and conduct ``closed-book\" evaluations for\nrepresentative models released prior to Gaokao. Contrary to prevailing\nconsensus, even after addressing data leakage and comprehensiveness,\nGAOKAO-Eval reveals that high scores still fail to truly reflect human-aligned\ncapabilities. To better understand this mismatch, We introduce the Rasch model\nfrom cognitive psychology to analyze LLM scoring patterns and identify two key\ndiscrepancies: 1) anomalous consistent performance across various question\ndifficulties, and 2) high variance in performance on questions of similar\ndifficulty. In addition, We identified inconsistent grading of LLM-generated\nanswers among teachers and recurring mistake patterns. we find that the\nphenomenons are well-grounded in the motivations behind OpenAI o1, and o1's\nreasoning-as-difficulties can mitigate the mismatch. These results show that\nGAOKAO-Eval can reveal limitations in LLM capabilities not captured by current\nbenchmarks and highlight the need for more LLM-aligned difficulty analysis.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u901a\u5e38\u4f7f\u7528\u4eba\u5de5\u8a55\u5206\u57fa\u6e96\u9032\u884c\u8a55\u4f30\uff0c\u524d\u63d0\u662f\u8f03\u9ad8\u7684\u5206\u6578\u96b1\u542b\u8457\u66f4\u5f37\u7684\u4eba\u985e\u8868\u73fe\u3002\u7136\u800c\uff0c\u8d8a\u4f86\u8d8a\u4ee4\u4eba\u64d4\u6182\u7684\u662f\uff0cLLM \u53ef\u80fd\u6703\u7531\u65bc\u8cc7\u6599\u5916\u6d29\u800c\u300c\u73a9\u5f04\u300d\u9019\u4e9b\u8a55\u5206\u57fa\u6e96\uff0c\u5728\u4eba\u985e\u57f7\u884c\u7c21\u55ae\u4efb\u52d9\u6642\u82e6\u82e6\u6399\u624e\uff0c\u537b\u80fd\u7372\u5f97\u9ad8\u5206\u3002\u70ba\u4e86\u5be6\u8cea\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u6839\u64da\u4e2d\u570b\u570b\u5bb6\u5927\u5b78\u5165\u5b78\u8003\u8a66\uff08\u9ad8\u8003\uff09\u5efa\u7acb\u4e86\u4e00\u500b\u5168\u9762\u7684\u8a55\u5206\u57fa\u6e96 GAOKAO-Eval\uff0c\u4e26\u5c0d\u5728\u9ad8\u8003\u4e4b\u524d\u767c\u5e03\u7684\u4ee3\u8868\u6027\u6a21\u578b\u9032\u884c\u300c\u9589\u5377\u300d\u8a55\u4f30\u3002\u8207\u666e\u904d\u5171\u8b58\u76f8\u53cd\uff0c\u5373\u4f7f\u5728\u89e3\u6c7a\u8cc7\u6599\u5916\u6d29\u548c\u5168\u9762\u6027\u554f\u984c\u5f8c\uff0cGAOKAO-Eval \u63ed\u793a\u9ad8\u5206\u4ecd\u7136\u7121\u6cd5\u771f\u6b63\u53cd\u6620\u8207\u4eba\u985e\u4e00\u81f4\u7684\u80fd\u529b\u3002\u70ba\u4e86\u66f4\u597d\u5730\u7406\u89e3\u9019\u7a2e\u4e0d\u5339\u914d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u8a8d\u77e5\u5fc3\u7406\u5b78\u4e2d\u7684 Rasch \u6a21\u578b\u4f86\u5206\u6790 LLM \u8a55\u5206\u6a21\u5f0f\u4e26\u627e\u51fa\u5169\u500b\u95dc\u9375\u5dee\u7570\uff1a1\uff09\u5728\u5404\u7a2e\u554f\u984c\u96e3\u5ea6\u4e2d\u7570\u5e38\u4e00\u81f4\u7684\u8868\u73fe\uff0c\u4ee5\u53ca 2\uff09\u5728\u96e3\u5ea6\u76f8\u4f3c\u7684\u554f\u984c\u4e0a\u8868\u73fe\u51fa\u9ad8\u8b8a\u7570\u6027\u3002\u6b64\u5916\uff0c\u6211\u5011\u767c\u73fe\u6559\u5e2b\u5c0d LLM \u751f\u6210\u7684\u7b54\u6848\u8a55\u5206\u4e0d\u4e00\u81f4\uff0c\u4e26\u4e14\u5b58\u5728\u91cd\u8907\u7684\u932f\u8aa4\u6a21\u5f0f\u3002\u6211\u5011\u767c\u73fe\u9019\u4e9b\u73fe\u8c61\u6df1\u6df1\u690d\u6839\u65bc OpenAI o1 \u80cc\u5f8c\u7684\u52d5\u6a5f\uff0co1 \u7684\u63a8\u7406\u5373\u56f0\u96e3\uff0c\u53ef\u4ee5\u6e1b\u8f15\u9019\u7a2e\u4e0d\u5339\u914d\u3002\u9019\u4e9b\u7d50\u679c\u8868\u660e\uff0cGAOKAO-Eval \u53ef\u4ee5\u63ed\u793a LLM \u80fd\u529b\u4e2d\u7684\u9650\u5236\uff0c\u800c\u76ee\u524d\u7684\u8a55\u5206\u57fa\u6e96\u7121\u6cd5\u6355\u6349\u5230\u9019\u4e9b\u9650\u5236\uff0c\u4e26\u5f37\u8abf\u9700\u8981\u9032\u884c\u66f4\u591a\u8207 LLM \u4e00\u81f4\u7684\u96e3\u5ea6\u5206\u6790\u3002", "author": "Zhikai Lei et.al.", "authors": "Zhikai Lei, Tianyi Liang, Hanglei Hu, Jin Zhang, Yunhua Zhou, Yunfan Shao, Linyang Li, Chenchui Li, Changbo Wang, Hang Yan, Qipeng Guo", "id": "2412.10056v1", "paper_url": "http://arxiv.org/abs/2412.10056v1", "repo": "null"}}