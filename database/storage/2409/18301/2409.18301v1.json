{"2409.18301": {"publish_time": "2024-09-26", "title": "Harnessing Wavelet Transformations for Generalizable Deepfake Forgery Detection", "paper_summary": "The evolution of digital image manipulation, particularly with the\nadvancement of deep generative models, significantly challenges existing\ndeepfake detection methods, especially when the origin of the deepfake is\nobscure. To tackle the increasing complexity of these forgeries, we propose\n\\textbf{Wavelet-CLIP}, a deepfake detection framework that integrates wavelet\ntransforms with features derived from the ViT-L/14 architecture, pre-trained in\nthe CLIP fashion. Wavelet-CLIP utilizes Wavelet Transforms to deeply analyze\nboth spatial and frequency features from images, thus enhancing the model's\ncapability to detect sophisticated deepfakes. To verify the effectiveness of\nour approach, we conducted extensive evaluations against existing\nstate-of-the-art methods for cross-dataset generalization and detection of\nunseen images generated by standard diffusion models. Our method showcases\noutstanding performance, achieving an average AUC of 0.749 for cross-data\ngeneralization and 0.893 for robustness against unseen deepfakes, outperforming\nall compared methods. The code can be reproduced from the repo:\n\\url{https://github.com/lalithbharadwajbaru/Wavelet-CLIP}", "paper_summary_zh": "\u6578\u4f4d\u5f71\u50cf\u8655\u7406\u7684\u6f14\u9032\uff0c\u7279\u5225\u662f\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u7684\u9032\u6b65\uff0c\u5c0d\u73fe\u6709\u7684\u6df1\u5ea6\u507d\u9020\u5075\u6e2c\u65b9\u6cd5\u5e36\u4f86\u91cd\u5927\u6311\u6230\uff0c\u7279\u5225\u662f\u5728\u6df1\u5ea6\u507d\u9020\u7684\u4f86\u6e90\u4e0d\u660e\u6642\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u507d\u9020\u54c1\u65e5\u76ca\u589e\u52a0\u7684\u8907\u96dc\u6027\uff0c\u6211\u5011\u63d0\u51fa**\u5c0f\u6ce2-CLIP**\uff0c\u4e00\u7a2e\u6df1\u5ea6\u507d\u9020\u5075\u6e2c\u67b6\u69cb\uff0c\u5b83\u5c07\u5c0f\u6ce2\u8f49\u63db\u8207\u5f9e ViT-L/14 \u67b6\u69cb\u4e2d\u884d\u751f\u7684\u7279\u5fb5\u6574\u5408\u5728\u4e00\u8d77\uff0c\u4e26\u4ee5 CLIP \u65b9\u5f0f\u9810\u5148\u8a13\u7df4\u3002\u5c0f\u6ce2-CLIP \u5229\u7528\u5c0f\u6ce2\u8f49\u63db\u6df1\u5165\u5206\u6790\u5f71\u50cf\u7684\u7a7a\u9593\u548c\u983b\u7387\u7279\u5fb5\uff0c\u5f9e\u800c\u589e\u5f37\u6a21\u578b\u5075\u6e2c\u7cbe\u7dfb\u6df1\u5ea6\u507d\u9020\u7684\u80fd\u529b\u3002\u70ba\u4e86\u9a57\u8b49\u6211\u5011\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u6211\u5011\u91dd\u5c0d\u73fe\u6709\u7684\u6700\u5148\u9032\u65b9\u6cd5\u9032\u884c\u5ee3\u6cdb\u8a55\u4f30\uff0c\u4ee5\u9032\u884c\u8de8\u8cc7\u6599\u96c6\u6982\u5316\u548c\u5075\u6e2c\u6a19\u6e96\u64f4\u6563\u6a21\u578b\u7522\u751f\u7684\u672a\u898b\u5f71\u50cf\u3002\u6211\u5011\u7684\u6a21\u578b\u5c55\u73fe\u51fa\u5091\u51fa\u7684\u6548\u80fd\uff0c\u5728\u8de8\u8cc7\u6599\u6982\u5316\u65b9\u9762\u9054\u5230 0.749 \u7684\u5e73\u5747 AUC\uff0c\u5728\u5c0d\u6297\u672a\u898b\u6df1\u5ea6\u507d\u9020\u7684\u7a69\u5065\u6027\u65b9\u9762\u9054\u5230 0.893\uff0c\u512a\u65bc\u6240\u6709\u6bd4\u8f03\u65b9\u6cd5\u3002\u7a0b\u5f0f\u78bc\u53ef\u4ee5\u5728\u5132\u5b58\u5eab\u4e2d\u8907\u88fd\uff1a\\url{https://github.com/lalithbharadwajbaru/Wavelet-CLIP}", "author": "Lalith Bharadwaj Baru et.al.", "authors": "Lalith Bharadwaj Baru, Shilhora Akshay Patel, Rohit Boddeda", "id": "2409.18301v1", "paper_url": "http://arxiv.org/abs/2409.18301v1", "repo": "https://github.com/lalithbharadwajbaru/wavelet-clip"}}