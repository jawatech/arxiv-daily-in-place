{"2501.12273": {"publish_time": "2025-01-21", "title": "Condor: Enhance LLM Alignment with Knowledge-Driven Data Synthesis and Refinement", "paper_summary": "The quality of Supervised Fine-Tuning (SFT) data plays a critical role in\nenhancing the conversational capabilities of Large Language Models (LLMs).\nHowever, as LLMs become more advanced, the availability of high-quality\nhuman-annotated SFT data has become a significant bottleneck, necessitating a\ngreater reliance on synthetic training data. In this work, we introduce Condor,\na novel two-stage synthetic data generation framework that incorporates World\nKnowledge Tree and Self-Reflection Refinement to produce high-quality SFT data\nat scale. Our experimental results demonstrate that a base model fine-tuned on\nonly 20K Condor-generated samples achieves superior performance compared to\ncounterparts. The additional refinement stage in Condor further enables\niterative self-improvement for LLMs at various scales (up to 72B), validating\nthe effectiveness of our approach. Furthermore, our investigation into the\nscaling for synthetic data in post-training reveals substantial unexplored\npotential for performance improvements, opening promising avenues for future\nresearch.", "paper_summary_zh": "\u76e3\u7763\u5f0f\u5fae\u8abf (SFT) \u8cc7\u6599\u7684\u54c1\u8cea\u5c0d\u65bc\u589e\u5f37\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5c0d\u8a71\u80fd\u529b\u767c\u63ee\u95dc\u9375\u4f5c\u7528\u3002\u7136\u800c\uff0c\u96a8\u8457 LLM \u8b8a\u5f97\u8d8a\u4f86\u8d8a\u5148\u9032\uff0c\u9ad8\u54c1\u8cea\u4eba\u5de5\u6a19\u8a3b SFT \u8cc7\u6599\u7684\u53ef\u7528\u6027\u5df2\u6210\u70ba\u4e00\u500b\u91cd\u5927\u7684\u74f6\u9838\uff0c\u9019\u4f7f\u5f97\u5c0d\u5408\u6210\u8a13\u7df4\u8cc7\u6599\u7684\u4f9d\u8cf4\u6027\u8d8a\u4f86\u8d8a\u9ad8\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 Condor\uff0c\u4e00\u500b\u65b0\u7a4e\u7684\u5169\u968e\u6bb5\u5408\u6210\u8cc7\u6599\u751f\u6210\u67b6\u69cb\uff0c\u5b83\u7d50\u5408\u4e86\u4e16\u754c\u77e5\u8b58\u6a39\u548c\u81ea\u6211\u53cd\u7701\u7cbe\u7149\uff0c\u4ee5\u5927\u898f\u6a21\u7522\u751f\u9ad8\u54c1\u8cea\u7684 SFT \u8cc7\u6599\u3002\u6211\u5011\u7684\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u50c5\u91dd\u5c0d 20K \u500b Condor \u751f\u6210\u7684\u7bc4\u4f8b\u9032\u884c\u5fae\u8abf\u7684\u57fa\u672c\u6a21\u578b\uff0c\u8207\u540c\u985e\u578b\u6a21\u578b\u76f8\u6bd4\uff0c\u53ef\u7372\u5f97\u512a\u8d8a\u7684\u6548\u80fd\u3002Condor \u4e2d\u7684\u984d\u5916\u7cbe\u7149\u968e\u6bb5\u9032\u4e00\u6b65\u8b93 LLM \u80fd\u5920\u5728\u5404\u7a2e\u898f\u6a21\uff08\u6700\u9ad8 72B\uff09\u4e0b\u9032\u884c\u53cd\u8986\u81ea\u6211\u6539\u5584\uff0c\u9a57\u8b49\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u6b64\u5916\uff0c\u6211\u5011\u5c0d\u8a13\u7df4\u5f8c\u5408\u6210\u8cc7\u6599\u7684\u64f4\u5c55\u6027\u9032\u884c\u8abf\u67e5\uff0c\u63ed\u793a\u4e86\u6548\u80fd\u6539\u5584\u7684\u5de8\u5927\u672a\u958b\u767c\u6f5b\u529b\uff0c\u70ba\u672a\u4f86\u7684\u7814\u7a76\u958b\u95e2\u4e86\u6709\u524d\u666f\u7684\u9014\u5f91\u3002", "author": "Maosong Cao et.al.", "authors": "Maosong Cao, Taolin Zhang, Mo Li, Chuyu Zhang, Yunxin Liu, Haodong Duan, Songyang Zhang, Kai Chen", "id": "2501.12273v1", "paper_url": "http://arxiv.org/abs/2501.12273v1", "repo": "null"}}