{"2407.08216": {"publish_time": "2024-07-11", "title": "Multimodal contrastive learning for spatial gene expression prediction using histology images", "paper_summary": "In recent years, the advent of spatial transcriptomics (ST) technology has\nunlocked unprecedented opportunities for delving into the complexities of gene\nexpression patterns within intricate biological systems. Despite its\ntransformative potential, the prohibitive cost of ST technology remains a\nsignificant barrier to its widespread adoption in large-scale studies. An\nalternative, more cost-effective strategy involves employing artificial\nintelligence to predict gene expression levels using readily accessible\nwhole-slide images (WSIs) stained with Hematoxylin and Eosin (H\\&E). However,\nexisting methods have yet to fully capitalize on multimodal information\nprovided by H&E images and ST data with spatial location. In this paper, we\npropose \\textbf{mclSTExp}, a multimodal contrastive learning with Transformer\nand Densenet-121 encoder for Spatial Transcriptomics Expression prediction. We\nconceptualize each spot as a \"word\", integrating its intrinsic features with\nspatial context through the self-attention mechanism of a Transformer encoder.\nThis integration is further enriched by incorporating image features via\ncontrastive learning, thereby enhancing the predictive capability of our model.\nOur extensive evaluation of \\textbf{mclSTExp} on two breast cancer datasets and\na skin squamous cell carcinoma dataset demonstrates its superior performance in\npredicting spatial gene expression. Moreover, mclSTExp has shown promise in\ninterpreting cancer-specific overexpressed genes, elucidating immune-related\ngenes, and identifying specialized spatial domains annotated by pathologists.\nOur source code is available at https://github.com/shizhiceng/mclSTExp.", "paper_summary_zh": "<paragraph>\u8fd1\u5e74\u4f86\uff0c\u7a7a\u9593\u8f49\u9304\u7d44\u5b78 (ST) \u6280\u8853\u7684\u51fa\u73fe\u70ba\u6df1\u5165\u7814\u7a76\u8907\u96dc\u751f\u7269\u7cfb\u7d71\u4e2d\u57fa\u56e0\u8868\u73fe\u6a21\u5f0f\u7684\u8907\u96dc\u6027\u63d0\u4f9b\u4e86\u524d\u6240\u672a\u6709\u7684\u6a5f\u6703\u3002\u5118\u7ba1\u5177\u6709\u8f49\u8b8a\u6f5b\u529b\uff0c\u4f46 ST \u6280\u8853\u7684\u9ad8\u6602\u6210\u672c\u4ecd\u7136\u662f\u5927\u898f\u6a21\u7814\u7a76\u4e2d\u5ee3\u6cdb\u63a1\u7528\u7684\u91cd\u5927\u969c\u7919\u3002\u4e00\u7a2e\u66ff\u4ee3\u7684\u3001\u66f4\u5177\u6210\u672c\u6548\u76ca\u7684\u7b56\u7565\u6d89\u53ca\u4f7f\u7528\u4eba\u5de5\u667a\u6167\u4f86\u9810\u6e2c\u4f7f\u7528\u6613\u65bc\u53d6\u5f97\u7684\u3001\u67d3\u6709\u8607\u6728\u7cbe\u548c\u66d9\u7d05 (H&E) \u7684\u5168\u73bb\u7247\u5f71\u50cf (WSI) \u7684\u57fa\u56e0\u8868\u73fe\u6c34\u6e96\u3002\u7136\u800c\uff0c\u73fe\u6709\u65b9\u6cd5\u5c1a\u672a\u5145\u5206\u5229\u7528 H&E \u5f71\u50cf\u548c\u5177\u6709\u7a7a\u9593\u4f4d\u7f6e\u7684 ST \u8cc7\u6599\u6240\u63d0\u4f9b\u7684\u591a\u6a21\u614b\u8cc7\u8a0a\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa \\textbf{mclSTExp}\uff0c\u4e00\u500b\u591a\u6a21\u614b\u5c0d\u6bd4\u5b78\u7fd2\uff0c\u4f7f\u7528 Transformer \u548c Densenet-121 \u7de8\u78bc\u5668\u9032\u884c\u7a7a\u9593\u8f49\u9304\u7d44\u5b78\u8868\u73fe\u9810\u6e2c\u3002\u6211\u5011\u5c07\u6bcf\u500b\u9ede\u6982\u5ff5\u5316\u4e3a\u4e00\u500b\u300c\u5b57\u300d\uff0c\u900f\u904e Transformer \u7de8\u78bc\u5668\u7684\u81ea\u6ce8\u610f\u529b\u6a5f\u5236\uff0c\u5c07\u5176\u5167\u5728\u7279\u5fb5\u8207\u7a7a\u9593\u8108\u7d61\u6574\u5408\u5728\u4e00\u8d77\u3002\u9019\u7a2e\u6574\u5408\u901a\u904e\u5c0d\u6bd4\u5b78\u7fd2\u9032\u4e00\u6b65\u8c50\u5bcc\u4e86\u5f71\u50cf\u7279\u5fb5\uff0c\u5f9e\u800c\u589e\u5f37\u4e86\u6211\u5011\u6a21\u578b\u7684\u9810\u6e2c\u80fd\u529b\u3002\u6211\u5011\u5c0d\u5169\u500b\u4e73\u764c\u8cc7\u6599\u96c6\u548c\u4e00\u500b\u76ae\u819a\u9c57\u72c0\u7d30\u80de\u764c\u8cc7\u6599\u96c6\u7684 \\textbf{mclSTExp} \u9032\u884c\u5ee3\u6cdb\u8a55\u4f30\uff0c\u8b49\u660e\u4e86\u5176\u5728\u9810\u6e2c\u7a7a\u9593\u57fa\u56e0\u8868\u73fe\u65b9\u9762\u7684\u512a\u7570\u6548\u80fd\u3002\u6b64\u5916\uff0cmclSTExp \u5df2\u986f\u793a\u51fa\u5728\u89e3\u91cb\u764c\u75c7\u7279\u7570\u6027\u904e\u5ea6\u8868\u73fe\u57fa\u56e0\u3001\u95e1\u660e\u514d\u75ab\u76f8\u95dc\u57fa\u56e0\u4ee5\u53ca\u8b58\u5225\u75c5\u7406\u5b78\u5bb6\u8a3b\u89e3\u7684\u5c08\u9580\u7a7a\u9593\u9818\u57df\u65b9\u9762\u7684\u524d\u666f\u3002\u6211\u5011\u7684\u539f\u59cb\u78bc\u53ef\u5728 https://github.com/shizhiceng/mclSTExp \u53d6\u5f97\u3002</paragraph>", "author": "Wenwen Min et.al.", "authors": "Wenwen Min, Zhiceng Shi, Jun Zhang, Jun Wan, Changmiao Wang", "id": "2407.08216v1", "paper_url": "http://arxiv.org/abs/2407.08216v1", "repo": "https://github.com/shizhiceng/mclstexp"}}