{"2406.01566": {"publish_time": "2024-06-03", "title": "Helix: Distributed Serving of Large Language Models via Max-Flow on Heterogeneous GPUs", "paper_summary": "This paper introduces Helix, a distributed system for high-throughput,\nlow-latency large language model (LLM) serving on heterogeneous GPU clusters. A\nkey idea behind Helix is to formulate inference computation of LLMs over\nheterogeneous GPUs and network connections as a max-flow problem for a\ndirected, weighted graph, whose nodes represent GPU instances and edges capture\nboth GPU and network heterogeneity through their capacities. Helix then uses a\nmixed integer linear programming (MILP) algorithm to discover highly optimized\nstrategies to serve LLMs. This approach allows Helix to jointly optimize model\nplacement and request scheduling, two highly entangled tasks in heterogeneous\nLLM serving. Our evaluation on several heterogeneous cluster settings ranging\nfrom 24 to 42 GPU nodes shows that Helix improves serving throughput by up to\n2.7$\\times$ and reduces prompting and decoding latency by up to 2.8$\\times$ and\n1.3$\\times$, respectively, compared to best existing approaches.", "paper_summary_zh": "\u672c\u6587\u4ecb\u7d39 Helix\uff0c\u9019\u662f\u4e00\u7a2e\u7528\u65bc\u7570\u8cea GPU \u96c6\u7fa4\u4e0a\u63d0\u4f9b\u9ad8\u541e\u5410\u91cf\u3001\u4f4e\u5ef6\u9072\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u670d\u52d9\u7684\u5206\u5e03\u5f0f\u7cfb\u7d71\u3002Helix \u80cc\u5f8c\u7684\u4e00\u500b\u95dc\u9375\u6982\u5ff5\u662f\u5c07 LLM \u5728\u7570\u8cea GPU \u548c\u7db2\u8def\u9023\u7dda\u4e0a\u7684\u63a8\u8ad6\u8a08\u7b97\u8868\u8ff0\u70ba\u4e00\u500b\u6709\u5411\u52a0\u6b0a\u5716\u7684\u6700\u5927\u6d41\u554f\u984c\uff0c\u5176\u7bc0\u9ede\u8868\u793a GPU \u5be6\u4f8b\uff0c\u908a\u7de3\u5247\u900f\u904e\u5176\u5bb9\u91cf\u64f7\u53d6 GPU \u548c\u7db2\u8def\u7570\u8cea\u6027\u3002\u63a5\u8457\uff0cHelix \u4f7f\u7528\u6df7\u5408\u6574\u6578\u7dda\u6027\u898f\u5283 (MILP) \u6f14\u7b97\u6cd5\u627e\u51fa\u9ad8\u5ea6\u6700\u4f73\u5316\u7684\u7b56\u7565\u4f86\u63d0\u4f9b LLM \u670d\u52d9\u3002\u9019\u7a2e\u65b9\u6cd5\u8b93 Helix \u80fd\u5920\u540c\u6642\u6700\u4f73\u5316\u6a21\u578b\u914d\u7f6e\u548c\u8981\u6c42\u6392\u7a0b\uff0c\u9019\u5169\u500b\u5728\u7570\u8cea LLM \u670d\u52d9\u4e2d\u9ad8\u5ea6\u7cfe\u7d50\u7684\u4efb\u52d9\u3002\u6211\u5011\u5728\u5f9e 24 \u5230 42 \u500b GPU \u7bc0\u9ede\u7684\u5e7e\u500b\u7570\u8cea\u96c6\u7fa4\u8a2d\u5b9a\u4e2d\u9032\u884c\u8a55\u4f30\uff0c\u7d50\u679c\u986f\u793a Helix \u5c07\u670d\u52d9\u541e\u5410\u91cf\u63d0\u5347\u4e86\u591a\u9054 2.7 \u500d\uff0c\u4e26\u5c07\u63d0\u793a\u548c\u89e3\u78bc\u5ef6\u9072\u5206\u5225\u964d\u4f4e\u4e86\u591a\u9054 2.8 \u500d\u548c 1.3 \u500d\uff0c\u8207\u73fe\u6709\u6700\u4f73\u65b9\u6cd5\u76f8\u6bd4\u3002", "author": "Yixuan Mei et.al.", "authors": "Yixuan Mei, Yonghao Zhuang, Xupeng Miao, Juncheng Yang, Zhihao Jia, Rashmi Vinayak", "id": "2406.01566v1", "paper_url": "http://arxiv.org/abs/2406.01566v1", "repo": "null"}}