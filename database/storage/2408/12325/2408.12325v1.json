{"2408.12325": {"publish_time": "2024-08-22", "title": "Improving Factuality in Large Language Models via Decoding-Time Hallucinatory and Truthful Comparators", "paper_summary": "Despite their remarkable capabilities, Large Language Models (LLMs) are prone\nto generate responses that contradict verifiable facts, i.e., unfaithful\nhallucination content. Existing efforts generally focus on optimizing model\nparameters or editing semantic representations, which compromise the internal\nfactual knowledge of target LLMs. In addition, hallucinations typically exhibit\nmultifaceted patterns in downstream tasks, limiting the model's holistic\nperformance across tasks. In this paper, we propose a Comparator-driven\nDecoding-Time (CDT) framework to alleviate the response hallucination. Firstly,\nwe construct hallucinatory and truthful comparators with multi-task fine-tuning\nsamples. In this case, we present an instruction prototype-guided mixture of\nexperts strategy to enhance the ability of the corresponding comparators to\ncapture different hallucination or truthfulness patterns in distinct task\ninstructions. CDT constrains next-token predictions to factuality-robust\ndistributions by contrasting the logit differences between the target LLMs and\nthese comparators. Systematic experiments on multiple downstream tasks show\nthat our framework can significantly improve the model performance and response\nfactuality.", "paper_summary_zh": "\u5118\u7ba1\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6709\u5176\u975e\u51e1\u7684\u80fd\u529b\uff0c\u4f46\u5b83\u5011\u5bb9\u6613\u7522\u751f\u8207\u53ef\u9a57\u8b49\u4e8b\u5be6\u76f8\u77db\u76fe\u7684\u56de\u61c9\uff0c\u4e5f\u5c31\u662f\u4e0d\u5fe0\u5be6\u7684\u5e7b\u89ba\u5167\u5bb9\u3002\u73fe\u6709\u7684\u52aa\u529b\u901a\u5e38\u5c08\u6ce8\u65bc\u6700\u4f73\u5316\u6a21\u578b\u53c3\u6578\u6216\u7de8\u8f2f\u8a9e\u610f\u8868\u793a\uff0c\u9019\u6703\u640d\u5bb3\u76ee\u6a19 LLM \u7684\u5167\u90e8\u4e8b\u5be6\u77e5\u8b58\u3002\u6b64\u5916\uff0c\u5e7b\u89ba\u901a\u5e38\u5728\u4e0b\u6e38\u4efb\u52d9\u4e2d\u8868\u73fe\u51fa\u591a\u65b9\u9762\u7684\u6a21\u5f0f\uff0c\u9650\u5236\u4e86\u6a21\u578b\u8de8\u4efb\u52d9\u7684\u6574\u9ad4\u6548\u80fd\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u6bd4\u8f03\u5668\u9a45\u52d5\u7684\u89e3\u78bc\u6642\u9593 (CDT) \u67b6\u69cb\u4f86\u6e1b\u8f15\u56de\u61c9\u5e7b\u89ba\u3002\u9996\u5148\uff0c\u6211\u5011\u4f7f\u7528\u591a\u4efb\u52d9\u5fae\u8abf\u7bc4\u4f8b\u5efa\u69cb\u5e7b\u89ba\u548c\u771f\u5be6\u6bd4\u8f03\u5668\u3002\u5728\u9019\u7a2e\u60c5\u6cc1\u4e0b\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u6307\u4ee4\u539f\u578b\u5f15\u5c0e\u7684\u5c08\u5bb6\u6df7\u5408\u7b56\u7565\uff0c\u4ee5\u589e\u5f37\u5c0d\u61c9\u6bd4\u8f03\u5668\u64f7\u53d6\u4e0d\u540c\u4efb\u52d9\u6307\u4ee4\u4e2d\u4e0d\u540c\u5e7b\u89ba\u6216\u771f\u5be6\u6a21\u5f0f\u7684\u80fd\u529b\u3002CDT \u900f\u904e\u5c0d\u6bd4\u76ee\u6a19 LLM \u548c\u9019\u4e9b\u6bd4\u8f03\u5668\u4e4b\u9593\u7684 logit \u5dee\u7570\uff0c\u5c07\u4e0b\u4e00\u500b\u4ee3\u5e63\u9810\u6e2c\u9650\u5236\u5728\u7a69\u5065\u7684\u4e8b\u5be6\u5206\u4f48\u4e2d\u3002\u5728\u591a\u500b\u4e0b\u6e38\u4efb\u52d9\u4e0a\u7684\u7cfb\u7d71\u5be6\u9a57\u8868\u660e\uff0c\u6211\u5011\u7684\u67b6\u69cb\u53ef\u4ee5\u986f\u8457\u6539\u5584\u6a21\u578b\u6548\u80fd\u548c\u56de\u61c9\u4e8b\u5be6\u6027\u3002", "author": "Dingkang Yang et.al.", "authors": "Dingkang Yang, Dongling Xiao, Jinjie Wei, Mingcheng Li, Zhaoyu Chen, Ke Li, Lihua Zhang", "id": "2408.12325v1", "paper_url": "http://arxiv.org/abs/2408.12325v1", "repo": "null"}}