{"2407.16008": {"publish_time": "2024-07-22", "title": "Boosting Reward Model with Preference-Conditional Multi-Aspect Synthetic Data Generation", "paper_summary": "Reward models (RMs) are crucial for aligning large language models (LLMs)\nwith human preferences. They are trained using preference datasets where each\nexample consists of one input prompt, two responses, and a preference label. As\ncurating a high-quality human labeled preference dataset is both time-consuming\nand expensive, people often rely on existing powerful LLMs for preference label\ngeneration. This can potentially introduce noise and impede RM training. In\nthis work, we present RMBoost, a novel synthetic preference data generation\nparadigm to boost reward model quality. Unlike traditional methods, which\ngenerate two responses before obtaining the preference label, RMBoost first\ngenerates one response and selects a preference label, followed by generating\nthe second more (or less) preferred response conditioned on the pre-selected\npreference label and the first response. This approach offers two main\nadvantages. First, RMBoost reduces labeling noise since preference pairs are\nconstructed intentionally. Second, RMBoost facilitates the creation of more\ndiverse responses by incorporating various quality aspects (e.g., helpfulness,\nrelevance, completeness) into the prompts. We conduct extensive experiments\nacross three diverse datasets and demonstrate that RMBoost outperforms other\nsynthetic preference data generation techniques and significantly boosts the\nperformance of four distinct reward models.", "paper_summary_zh": "\u734e\u52f5\u6a21\u578b (RM) \u5c0d\u65bc\u5c07\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8207\u4eba\u985e\u504f\u597d\u5c0d\u9f4a\u81f3\u95dc\u91cd\u8981\u3002\u5b83\u5011\u4f7f\u7528\u504f\u597d\u8cc7\u6599\u96c6\u9032\u884c\u8a13\u7df4\uff0c\u5176\u4e2d\u6bcf\u500b\u7bc4\u4f8b\u5305\u542b\u4e00\u500b\u8f38\u5165\u63d0\u793a\u3001\u5169\u500b\u56de\u61c9\u548c\u4e00\u500b\u504f\u597d\u6a19\u7c64\u3002\u7531\u65bc\u7b56\u5283\u4e00\u500b\u9ad8\u54c1\u8cea\u7684\u4eba\u985e\u6a19\u8a18\u504f\u597d\u8cc7\u6599\u96c6\u65e2\u8017\u6642\u53c8\u6602\u8cb4\uff0c\u56e0\u6b64\u4eba\u5011\u901a\u5e38\u4f9d\u8cf4\u73fe\u6709\u7684\u5f37\u5927 LLM \u4f86\u7522\u751f\u504f\u597d\u6a19\u7c64\u3002\u9019\u53ef\u80fd\u6703\u5f15\u5165\u96dc\u8a0a\u4e26\u963b\u7919 RM \u8a13\u7df4\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86 RMBoost\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u5408\u6210\u504f\u597d\u8cc7\u6599\u7522\u751f\u7bc4\u4f8b\uff0c\u7528\u65bc\u63d0\u5347\u734e\u52f5\u6a21\u578b\u54c1\u8cea\u3002\u8207\u5728\u53d6\u5f97\u504f\u597d\u6a19\u7c64\u4e4b\u524d\u7522\u751f\u5169\u500b\u56de\u61c9\u7684\u50b3\u7d71\u65b9\u6cd5\u4e0d\u540c\uff0cRMBoost \u9996\u5148\u7522\u751f\u4e00\u500b\u56de\u61c9\u4e26\u9078\u64c7\u4e00\u500b\u504f\u597d\u6a19\u7c64\uff0c\u7136\u5f8c\u5728\u9810\u5148\u9078\u53d6\u7684\u504f\u597d\u6a19\u7c64\u548c\u7b2c\u4e00\u500b\u56de\u61c9\u7684\u689d\u4ef6\u4e0b\u7522\u751f\u7b2c\u4e8c\u500b\u66f4\uff08\u6216\u66f4\u4e0d\uff09\u504f\u597d\u7684\u56de\u61c9\u3002\u9019\u7a2e\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5169\u500b\u4e3b\u8981\u512a\u9ede\u3002\u9996\u5148\uff0cRMBoost \u6e1b\u5c11\u4e86\u6a19\u8a18\u96dc\u8a0a\uff0c\u56e0\u70ba\u504f\u597d\u5c0d\u662f\u6545\u610f\u5efa\u69cb\u7684\u3002\u5176\u6b21\uff0cRMBoost \u900f\u904e\u5c07\u5404\u7a2e\u54c1\u8cea\u9762\u5411\uff08\u4f8b\u5982\uff0c\u6709\u7528\u6027\u3001\u76f8\u95dc\u6027\u3001\u5b8c\u6574\u6027\uff09\u7d0d\u5165\u63d0\u793a\u4e2d\uff0c\u4fc3\u9032\u4e86\u66f4\u591a\u6a23\u5316\u56de\u61c9\u7684\u7522\u751f\u3002\u6211\u5011\u5728\u4e09\u500b\u4e0d\u540c\u7684\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u4e26\u8b49\u660e RMBoost \u512a\u65bc\u5176\u4ed6\u5408\u6210\u504f\u597d\u8cc7\u6599\u7522\u751f\u6280\u8853\uff0c\u4e26\u986f\u8457\u63d0\u5347\u4e86\u56db\u500b\u4e0d\u540c\u734e\u52f5\u6a21\u578b\u7684\u6548\u80fd\u3002", "author": "Jiaming Shen et.al.", "authors": "Jiaming Shen, Ran Xu, Yennie Jun, Zhen Qin, Tianqi Liu, Carl Yang, Yi Liang, Simon Baumgartner, Michael Bendersky", "id": "2407.16008v1", "paper_url": "http://arxiv.org/abs/2407.16008v1", "repo": "null"}}