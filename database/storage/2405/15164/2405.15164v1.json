{"2405.15164": {"publish_time": "2024-05-24", "title": "From Frege to chatGPT: Compositionality in language, cognition, and deep neural networks", "paper_summary": "Compositionality has long been considered a key explanatory property\nunderlying human intelligence: arbitrary concepts can be composed into novel\ncomplex combinations, permitting the acquisition of an open ended, potentially\ninfinite expressive capacity from finite learning experiences. Influential\narguments have held that neural networks fail to explain this aspect of\nbehavior, leading many to dismiss them as viable models of human cognition.\nOver the last decade, however, modern deep neural networks (DNNs), which share\nthe same fundamental design principles as their predecessors, have come to\ndominate artificial intelligence, exhibiting the most advanced cognitive\nbehaviors ever demonstrated in machines. In particular, large language models\n(LLMs), DNNs trained to predict the next word on a large corpus of text, have\nproven capable of sophisticated behaviors such as writing syntactically complex\nsentences without grammatical errors, producing cogent chains of reasoning, and\neven writing original computer programs -- all behaviors thought to require\ncompositional processing. In this chapter, we survey recent empirical work from\nmachine learning for a broad audience in philosophy, cognitive science, and\nneuroscience, situating recent breakthroughs within the broader context of\nphilosophical arguments about compositionality. In particular, our review\nemphasizes two approaches to endowing neural networks with compositional\ngeneralization capabilities: (1) architectural inductive biases, and (2)\nmetalearning, or learning to learn. We also present findings suggesting that\nLLM pretraining can be understood as a kind of metalearning, and can thereby\nequip DNNs with compositional generalization abilities in a similar way. We\nconclude by discussing the implications that these findings may have for the\nstudy of compositionality in human cognition and by suggesting avenues for\nfuture research.", "paper_summary_zh": "\u7d44\u5408\u6027\u9577\u671f\u4ee5\u4f86\u88ab\u8a8d\u70ba\u662f\u4eba\u985e\u667a\u80fd\u80cc\u5f8c\u7684\u4e00\u9805\u95dc\u9375\u89e3\u91cb\u6027\u7279\u8cea\uff1a\u4efb\u610f\u7684\u6982\u5ff5\u53ef\u4ee5\u7d44\u5408\u6210\u65b0\u7a4e\u7684\u8907\u96dc\u7d44\u5408\uff0c\u5141\u8a31\u5f9e\u6709\u9650\u7684\u5b78\u7fd2\u7d93\u9a57\u4e2d\u7372\u5f97\u958b\u653e\u5f0f\u3001\u6f5b\u5728\u7121\u9650\u7684\u8868\u9054\u80fd\u529b\u3002\u6709\u5f71\u97ff\u529b\u7684\u8ad6\u9ede\u8a8d\u70ba\uff0c\u795e\u7d93\u7db2\u8def\u7121\u6cd5\u89e3\u91cb\u884c\u70ba\u7684\u9019\u500b\u9762\u5411\uff0c\u5c0e\u81f4\u8a31\u591a\u4eba\u5c07\u5b83\u5011\u8996\u70ba\u4eba\u985e\u8a8d\u77e5\u7684\u53ef\u884c\u6a21\u578b\u3002\u7136\u800c\uff0c\u5728\u904e\u53bb\u5341\u5e74\u4e2d\uff0c\u73fe\u4ee3\u6df1\u5ea6\u795e\u7d93\u7db2\u8def (DNN) \u8207\u5176\u524d\u8eab\u5171\u4eab\u76f8\u540c\u7684\u57fa\u790e\u8a2d\u8a08\u539f\u7406\uff0c\u5df2\u958b\u59cb\u4e3b\u5c0e\u4eba\u5de5\u667a\u6167\uff0c\u5c55\u73fe\u51fa\u6a5f\u5668\u6709\u53f2\u4ee5\u4f86\u6700\u5148\u9032\u7684\u8a8d\u77e5\u884c\u70ba\u3002\u7279\u5225\u662f\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u662f\u5728\u5927\u91cf\u6587\u672c\u8a9e\u6599\u5eab\u4e2d\u8a13\u7df4\u4f86\u9810\u6e2c\u4e0b\u4e00\u500b\u55ae\u5b57\u7684 DNN\uff0c\u5df2\u88ab\u8b49\u660e\u5177\u5099\u8907\u96dc\u7684\u884c\u70ba\uff0c\u4f8b\u5982\u64b0\u5beb\u8a9e\u6cd5\u4e0a\u6c92\u6709\u932f\u8aa4\u7684\u53e5\u6cd5\u8907\u96dc\u53e5\u5b50\u3001\u7522\u751f\u6709\u529b\u7684\u63a8\u7406\u93c8\uff0c\u751a\u81f3\u64b0\u5beb\u539f\u59cb\u96fb\u8166\u7a0b\u5f0f\uff0c\u9019\u4e9b\u884c\u70ba\u90fd\u88ab\u8a8d\u70ba\u9700\u8981\u7d44\u5408\u8655\u7406\u3002\u5728\u672c\u7ae0\u4e2d\uff0c\u6211\u5011\u91dd\u5c0d\u54f2\u5b78\u3001\u8a8d\u77e5\u79d1\u5b78\u548c\u795e\u7d93\u79d1\u5b78\u7684\u5ee3\u6cdb\u53d7\u773e\u8abf\u67e5\u4e86\u6a5f\u5668\u5b78\u7fd2\u7684\u6700\u65b0\u5be6\u8b49\u7814\u7a76\uff0c\u5c07\u6700\u8fd1\u7684\u7a81\u7834\u7f6e\u65bc\u95dc\u65bc\u7d44\u5408\u6027\u7684\u54f2\u5b78\u8ad6\u9ede\u7684\u66f4\u5ee3\u6cdb\u80cc\u666f\u4e2d\u3002\u7279\u5225\u662f\uff0c\u6211\u5011\u7684\u8a55\u8ad6\u5f37\u8abf\u4e86\u5169\u7a2e\u8ce6\u4e88\u795e\u7d93\u7db2\u8def\u7d44\u5408\u6cdb\u5316\u80fd\u529b\u7684\u65b9\u6cd5\uff1a(1) \u67b6\u69cb\u6b78\u7d0d\u504f\u5dee\uff0c\u4ee5\u53ca (2) \u5143\u5b78\u7fd2\uff0c\u6216\u5b78\u7fd2\u5b78\u7fd2\u3002\u6211\u5011\u4e5f\u63d0\u51fa\u7814\u7a76\u7d50\u679c\uff0c\u8868\u660e LLM \u9810\u8a13\u7df4\u53ef\u4ee5\u7406\u89e3\u70ba\u4e00\u7a2e\u5143\u5b78\u7fd2\uff0c\u5f9e\u800c\u53ef\u4ee5\u7528\u985e\u4f3c\u7684\u65b9\u5f0f\u70ba DNN \u63d0\u4f9b\u7d44\u5408\u6cdb\u5316\u80fd\u529b\u3002\u6211\u5011\u6700\u5f8c\u8a0e\u8ad6\u9019\u4e9b\u767c\u73fe\u53ef\u80fd\u5c0d\u4eba\u985e\u8a8d\u77e5\u4e2d\u7d44\u5408\u6027\u7684\u7814\u7a76\u6709\u4f55\u5f71\u97ff\uff0c\u4e26\u5efa\u8b70\u672a\u4f86\u7684\u7814\u7a76\u9014\u5f91\u3002", "author": "Jacob Russin et.al.", "authors": "Jacob Russin, Sam Whitman McGrath, Danielle J. Williams, Lotem Elber-Dorozko", "id": "2405.15164v1", "paper_url": "http://arxiv.org/abs/2405.15164v1", "repo": "null"}}