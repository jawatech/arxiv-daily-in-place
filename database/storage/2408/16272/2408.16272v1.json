{"2408.16272": {"publish_time": "2024-08-29", "title": "Beyond Uncertainty: Evidential Deep Learning for Robust Video Temporal Grounding", "paper_summary": "Existing Video Temporal Grounding (VTG) models excel in accuracy but often\noverlook open-world challenges posed by open-vocabulary queries and untrimmed\nvideos. This leads to unreliable predictions for noisy, corrupted, and\nout-of-distribution data. Adapting VTG models to dynamically estimate\nuncertainties based on user input can address this issue. To this end, we\nintroduce SRAM, a robust network module that benefits from a two-stage\ncross-modal alignment task. More importantly, it integrates Deep Evidential\nRegression (DER) to explicitly and thoroughly quantify uncertainty during\ntraining, thus allowing the model to say \"I do not know\" in scenarios beyond\nits handling capacity. However, the direct application of traditional DER\ntheory and its regularizer reveals structural flaws, leading to unintended\nconstraints in VTG tasks. In response, we develop a simple yet effective\nGeom-regularizer that enhances the uncertainty learning framework from the\nground up. To the best of our knowledge, this marks the first successful\nattempt of DER in VTG. Our extensive quantitative and qualitative results\naffirm the effectiveness, robustness, and interpretability of our modules and\nthe uncertainty learning paradigm in VTG tasks. The code will be made\navailable.", "paper_summary_zh": "\u73fe\u6709\u7684\u5f71\u7247\u6642\u5e8f\u5b9a\u4f4d (VTG) \u6a21\u578b\u5728\u6e96\u78ba\u5ea6\u65b9\u9762\u8868\u73fe\u51fa\u8272\uff0c\u4f46\u901a\u5e38\u6703\u5ffd\u7565\u958b\u653e\u8a5e\u5f59\u67e5\u8a62\u548c\u672a\u4fee\u526a\u5f71\u7247\u6240\u5e36\u4f86\u7684\u958b\u653e\u4e16\u754c\u6311\u6230\u3002\u9019\u6703\u5c0e\u81f4\u5c0d\u96dc\u8a0a\u3001\u640d\u6bc0\u548c\u5206\u4f48\u5916\u8cc7\u6599\u9032\u884c\u4e0d\u53ef\u9760\u7684\u9810\u6e2c\u3002\u6839\u64da\u4f7f\u7528\u8005\u8f38\u5165\u52d5\u614b\u4f30\u8a08\u4e0d\u78ba\u5b9a\u6027\uff0c\u4ee5\u9069\u61c9 VTG \u6a21\u578b\u53ef\u4ee5\u89e3\u6c7a\u6b64\u554f\u984c\u3002\u70ba\u6b64\uff0c\u6211\u5011\u5f15\u5165\u4e86 SRAM\uff0c\u9019\u662f\u4e00\u500b\u5065\u5168\u7684\u7db2\u8def\u6a21\u7d44\uff0c\u53d7\u76ca\u65bc\u5169\u968e\u6bb5\u8de8\u6a21\u614b\u5c0d\u9f4a\u4efb\u52d9\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u5b83\u6574\u5408\u4e86\u6df1\u5ea6\u8b49\u64da\u56de\u6b78 (DER)\uff0c\u4ee5\u5728\u8a13\u7df4\u671f\u9593\u660e\u78ba\u4e14\u5fb9\u5e95\u5730\u91cf\u5316\u4e0d\u78ba\u5b9a\u6027\uff0c\u5f9e\u800c\u5141\u8a31\u6a21\u578b\u5728\u8d85\u51fa\u5176\u8655\u7406\u80fd\u529b\u7684\u60c5\u6cc1\u4e0b\u8aaa\u300c\u6211\u4e0d\u77e5\u9053\u300d\u3002\u7136\u800c\uff0c\u50b3\u7d71 DER \u7406\u8ad6\u53ca\u5176\u6b63\u5247\u5316\u7684\u76f4\u63a5\u61c9\u7528\u63ed\u793a\u4e86\u7d50\u69cb\u7f3a\u9677\uff0c\u5c0e\u81f4 VTG \u4efb\u52d9\u4e2d\u51fa\u73fe\u610f\u5916\u7684\u7d04\u675f\u3002\u70ba\u4e86\u89e3\u6c7a\u6b64\u554f\u984c\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u7c21\u55ae\u4f46\u6709\u6548\u7684\u5e7e\u4f55\u6b63\u5247\u5316\u5668\uff0c\u5f9e\u982d\u958b\u59cb\u589e\u5f37\u4e0d\u78ba\u5b9a\u6027\u5b78\u7fd2\u67b6\u69cb\u3002\u64da\u6211\u5011\u6240\u77e5\uff0c\u9019\u662f DER \u5728 VTG \u4e2d\u9996\u6b21\u6210\u529f\u5617\u8a66\u3002\u6211\u5011\u5ee3\u6cdb\u7684\u91cf\u5316\u548c\u5b9a\u6027\u7d50\u679c\u80af\u5b9a\u4e86\u6211\u5011\u7684\u6a21\u7d44\u548c VTG \u4efb\u52d9\u4e2d\u4e0d\u78ba\u5b9a\u6027\u5b78\u7fd2\u7bc4\u4f8b\u7684\u6709\u6548\u6027\u3001\u5065\u5168\u6027\u548c\u53ef\u89e3\u91cb\u6027\u3002\u7a0b\u5f0f\u78bc\u5c07\u6703\u63d0\u4f9b\u3002", "author": "Kaijing Ma et.al.", "authors": "Kaijing Ma, Haojian Huang, Jin Chen, Haodong Chen, Pengliang Ji, Xianghao Zang, Han Fang, Chao Ban, Hao Sun, Mulin Chen, Xuelong Li", "id": "2408.16272v1", "paper_url": "http://arxiv.org/abs/2408.16272v1", "repo": "null"}}