# arxiv-daily
 Automated deployment @ 2024-08-10 20:22:27 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-08**|**Towards Synergistic Deep Learning Models for Volumetric Cirrhotic Liver Segmentation in MRIs**|Vandan Gorade et.al.|[2408.04491v1](http://arxiv.org/abs/2408.04491v1)|null|
|**2024-08-08**|**Non-maximizing policies that fulfill multi-criterion aspirations in expectation**|Simon Dima et.al.|[2408.04385v1](http://arxiv.org/abs/2408.04385v1)|null|
|**2024-08-08**|**AI-Driven Chatbot for Intrusion Detection in Edge Networks: Enhancing Cybersecurity with Ethical User Consent**|Mugheez Asif et.al.|[2408.04281v1](http://arxiv.org/abs/2408.04281v1)|null|
|**2024-08-08**|**The Data Addition Dilemma**|Judy Hanwen Shen et.al.|[2408.04154v1](http://arxiv.org/abs/2408.04154v1)|[link](https://github.com/the-chen-lab/data-addition-dilemma)|
|**2024-08-08**|**Enhancing Healthcare through Large Language Models: A Study on Medical Question Answering**|Haoran Yu et.al.|[2408.04138v1](http://arxiv.org/abs/2408.04138v1)|null|
|**2024-08-07**|**Can Rule-Based Insights Enhance LLMs for Radiology Report Classification? Introducing the RadPrompt Methodology**|Panagiotis Fytas et.al.|[2408.04121v1](http://arxiv.org/abs/2408.04121v1)|null|
|**2024-08-07**|**Multimodal Gender Fairness in Depression Prediction: Insights on Data from the USA & China**|Joseph Cameron et.al.|[2408.04026v1](http://arxiv.org/abs/2408.04026v1)|null|
|**2024-08-07**|**Inter-Series Transformer: Attending to Products in Time Series Forecasting**|Rares Cristian et.al.|[2408.03872v1](http://arxiv.org/abs/2408.03872v1)|null|
|**2024-08-07**|**HiQuE: Hierarchical Question Embedding Network for Multimodal Depression Detection**|Juho Jung et.al.|[2408.03648v1](http://arxiv.org/abs/2408.03648v1)|null|
|**2024-08-07**|**Improving the quality of Persian clinical text with a novel spelling correction system**|Seyed Mohammad Sadegh Dashti et.al.|[2408.03622v1](http://arxiv.org/abs/2408.03622v1)|null|
|**2024-08-06**|**Identifying treatment response subgroups in observational time-to-event data**|Vincent Jeanselme et.al.|[2408.03463v1](http://arxiv.org/abs/2408.03463v1)|null|
|**2024-08-06**|**Combining Diverse Information for Coordinated Action: Stochastic Bandit Algorithms for Heterogeneous Agents**|Lucia Gordon et.al.|[2408.03405v1](http://arxiv.org/abs/2408.03405v1)|[link](https://github.com/lgordon99/heterogeneous-stochastic-bandits)|
|**2024-08-06**|**MLC-GCN: Multi-Level Generated Connectome Based GCN for AD Analysis**|Wenqi Zhu et.al.|[2408.03358v1](http://arxiv.org/abs/2408.03358v1)|null|
|**2024-08-06**|**Personalizing Federated Instrument Segmentation with Visual Trait Priors in Robotic Surgery**|Jialang Xu et.al.|[2408.03208v1](http://arxiv.org/abs/2408.03208v1)|null|
|**2024-08-06**|**The Use of Large Language Models (LLM) for Cyber Threat Intelligence (CTI) in Cybercrime Forums**|Vanessa Clairoux-Trepanier et.al.|[2408.03354v2](http://arxiv.org/abs/2408.03354v2)|null|
|**2024-08-06**|**VizECGNet: Visual ECG Image Network for Cardiovascular Diseases Classification with Multi-Modal Training and Knowledge Distillation**|Ju-Hyeon Nam et.al.|[2408.02888v1](http://arxiv.org/abs/2408.02888v1)|null|
|**2024-08-05**|**VisionUnite: A Vision-Language Foundation Model for Ophthalmology Enhanced with Clinical Knowledge**|Zihan Li et.al.|[2408.02865v1](http://arxiv.org/abs/2408.02865v1)|[link](https://github.com/HUANGLIZI/VisionUnite)|
|**2024-08-05**|**Multistain Pretraining for Slide Representation Learning in Pathology**|Guillaume Jaume et.al.|[2408.02859v1](http://arxiv.org/abs/2408.02859v1)|null|
|**2024-08-05**|**A Review on Organ Deformation Modeling Approaches for Reliable Surgical Navigation using Augmented Reality**|Zheng Han et.al.|[2408.02713v1](http://arxiv.org/abs/2408.02713v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-08-05**|**Active Sensing of Knee Osteoarthritis Progression with Reinforcement Learning**|Khanh Nguyen et.al.|[2408.02349v1](http://arxiv.org/abs/2408.02349v1)|null|
|**2024-08-04**|**MetaWearS: A Shortcut in Wearable Systems Lifecycle with Only a Few Shots**|Alireza Amirshahi et.al.|[2408.01988v1](http://arxiv.org/abs/2408.01988v1)|null|
|**2024-08-04**|**DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models**|Bowen Wang et.al.|[2408.01933v2](http://arxiv.org/abs/2408.01933v2)|null|
|**2024-08-03**|**MALADE: Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance**|Jihye Choi et.al.|[2408.01869v1](http://arxiv.org/abs/2408.01869v1)|[link](https://github.com/jihyechoi77/malade)|
|**2024-08-03**|**ST-SACLF: Style Transfer Informed Self-Attention Classifier for Bias-Aware Painting Classification**|Mridula Vijendran et.al.|[2408.01827v1](http://arxiv.org/abs/2408.01827v1)|null|
|**2024-08-03**|**Advancing Mental Health Pre-Screening: A New Custom GPT for Psychological Distress Assessment**|Jinwen Tang et.al.|[2408.01614v1](http://arxiv.org/abs/2408.01614v1)|null|
|**2024-08-02**|**Conformal Diffusion Models for Individual Treatment Effect Estimation and Inference**|Hengrui Cai et.al.|[2408.01582v1](http://arxiv.org/abs/2408.01582v1)|null|
|**2024-08-02**|**High-Throughput Phenotyping of Clinical Text Using Large Language Models**|Daniel B. Hier et.al.|[2408.01214v1](http://arxiv.org/abs/2408.01214v1)|null|
|**2024-08-02**|**Optimizing Variational Quantum Circuits Using Metaheuristic Strategies in Reinforcement Learning**|Michael KÃ¶lle et.al.|[2408.01187v1](http://arxiv.org/abs/2408.01187v1)|null|
|**2024-08-02**|**Six Dragons Fly Again: Reviving 15th-Century Korean Court Music with Transformers and Novel Encoding**|Danbinaerin Han et.al.|[2408.01096v1](http://arxiv.org/abs/2408.01096v1)|null|
|**2024-08-01**|**CIResDiff: A Clinically-Informed Residual Diffusion Model for Predicting Idiopathic Pulmonary Fibrosis Progression**|Caiwen Jiang et.al.|[2408.00938v2](http://arxiv.org/abs/2408.00938v2)|null|
|**2024-08-01**|**Parkinson's Disease Detection from Resting State EEG using Multi-Head Graph Structure Learning with Gradient Weighted Graph Attention Explanations**|Christopher Neves et.al.|[2408.00906v1](http://arxiv.org/abs/2408.00906v1)|null|
|**2024-08-01**|**UlRe-NeRF: 3D Ultrasound Imaging through Neural Rendering with Ultrasound Reflection Direction Parameterization**|Ziwen Guo et.al.|[2408.00860v2](http://arxiv.org/abs/2408.00860v2)|null|
|**2024-08-01**|**Segment anything model 2: an application to 2D and 3D medical images**|Haoyu Dong et.al.|[2408.00756v2](http://arxiv.org/abs/2408.00756v2)|null|
|**2024-08-01**|**Leaf Angle Estimation using Mask R-CNN and LETR Vision Transformer**|Venkat Margapuri et.al.|[2408.00749v1](http://arxiv.org/abs/2408.00749v1)|null|
|**2024-08-01**|**Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions**|Guangzhi Xiong et.al.|[2408.00727v1](http://arxiv.org/abs/2408.00727v1)|null|
|**2024-08-01**|**Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM**|Xiaofeng Liu et.al.|[2408.00706v1](http://arxiv.org/abs/2408.00706v1)|null|
|**2024-08-01**|**HBot: A Chatbot for Healthcare Applications in Traditional Chinese Medicine Based on Human Body 3D Visualization**|Bolin Zhang et.al.|[2408.00481v1](http://arxiv.org/abs/2408.00481v1)|null|
|**2024-08-01**|**Securing the Diagnosis of Medical Imaging: An In-depth Analysis of AI-Resistant Attacks**|Angona Biswas et.al.|[2408.00348v1](http://arxiv.org/abs/2408.00348v1)|null|
|**2024-08-01**|**Advancing Medical Image Segmentation: Morphology-Driven Learning with Diffusion Transformer**|Sungmin Kang et.al.|[2408.00347v1](http://arxiv.org/abs/2408.00347v1)|null|
|**2024-07-31**|**S-SYNTH: Knowledge-Based, Synthetic Generation of Skin Images**|Andrea Kim et.al.|[2408.00191v1](http://arxiv.org/abs/2408.00191v1)|null|
|**2024-07-31**|**A Taxonomy of Stereotype Content in Large Language Models**|Gandalf Nicolas et.al.|[2408.00162v1](http://arxiv.org/abs/2408.00162v1)|null|
|**2024-07-31**|**Preference-Based Abstract Argumentation for Case-Based Reasoning (with Appendix)**|Adam Gould et.al.|[2408.00108v2](http://arxiv.org/abs/2408.00108v2)|null|
|**2024-07-31**|**A Federated Learning-Friendly Approach for Parameter-Efficient Fine-Tuning of SAM in 3D Segmentation**|Mothilal Asokan et.al.|[2407.21739v1](http://arxiv.org/abs/2407.21739v1)|null|
|**2024-07-31**|**Synthetic Simplicity: Unveiling Bias in Medical Data Augmentation**|Krishan Agyakari Raja Babu et.al.|[2407.21674v1](http://arxiv.org/abs/2407.21674v1)|null|
|**2024-07-31**|**Quality Control for Radiology Report Generation Models via Auxiliary Auditing Components**|Hermione Warr et.al.|[2407.21638v1](http://arxiv.org/abs/2407.21638v1)|null|
|**2024-07-31**|**Optimizing Disease Prediction with Artificial Intelligence Driven Feature Selection and Attention Networks**|D. Dhinakaran et.al.|[2408.03151v1](http://arxiv.org/abs/2408.03151v1)|null|
|**2024-07-31**|**Voxel Scene Graph for Intracranial Hemorrhage**|Antoine P. Sanner et.al.|[2407.21580v1](http://arxiv.org/abs/2407.21580v1)|null|
|**2024-07-31**|**Expanding the Medical Decathlon dataset: segmentation of colon and colorectal cancer from computed tomography images**|I. M. Chernenkiy et.al.|[2407.21516v1](http://arxiv.org/abs/2407.21516v1)|null|
|**2024-07-31**|**Explainable and Controllable Motion Curve Guided Cardiac Ultrasound Video Generation**|Junxuan Yu et.al.|[2407.21490v1](http://arxiv.org/abs/2407.21490v1)|null|
|**2024-07-31**|**Deep Learning-Based Longitudinal Prediction of Childhood Myopia Progression Using Fundus Image Sequences and Baseline Refraction Data**|Mengtian Kang et.al.|[2407.21467v1](http://arxiv.org/abs/2407.21467v1)|null|
|**2024-07-31**|**Prompting Medical Large Vision-Language Models to Diagnose Pathologies by Visual Question Answering**|Danfeng Guo et.al.|[2407.21368v1](http://arxiv.org/abs/2407.21368v1)|null|
|**2024-07-31**|**MIST: A Simple and Scalable End-To-End 3D Medical Imaging Segmentation Framework**|Adrian Celaya et.al.|[2407.21343v1](http://arxiv.org/abs/2407.21343v1)|null|
|**2024-07-31**|**Patient-centered data science: an integrative framework for evaluating and predicting clinical outcomes in the digital health era**|Mohsen Amoei et.al.|[2408.02677v1](http://arxiv.org/abs/2408.02677v1)|null|
|**2024-07-31**|**Robust Box Prompt based SAM for Medical Image Segmentation**|Yuhao Huang et.al.|[2407.21284v1](http://arxiv.org/abs/2407.21284v1)|null|
|**2024-07-31**|**Unlocking the Potential of Binding Corporate Rules (BCRs) in Health Data Transfers**|Marcelo Corrales Compagnucci et.al.|[2407.21281v1](http://arxiv.org/abs/2407.21281v1)|null|
|**2024-07-31**|**FreqTSF: Time Series Forecasting Via Simulating Frequency Kramer-Kronig Relations**|Rujia Shen et.al.|[2407.21275v1](http://arxiv.org/abs/2407.21275v1)|null|
|**2024-07-31**|**Enhanced Uncertainty Estimation in Ultrasound Image Segmentation with MSU-Net**|Rohini Banerjee et.al.|[2407.21273v1](http://arxiv.org/abs/2407.21273v1)|null|
|**2024-07-30**|**Domain Shift Analysis in Chest Radiographs Classification in a Veterans Healthcare Administration Population**|Mayanka Chandrashekar et.al.|[2407.21149v1](http://arxiv.org/abs/2407.21149v1)|null|
|**2024-07-30**|**Zero Shot Health Trajectory Prediction Using Transformer**|Pawel Renc et.al.|[2407.21124v1](http://arxiv.org/abs/2407.21124v1)|null|
|**2024-07-30**|**CLEFT: Language-Image Contrastive Learning with Efficient Large Language Model and Prompt Fine-Tuning**|Yuexi Du et.al.|[2407.21011v1](http://arxiv.org/abs/2407.21011v1)|[link](https://github.com/xypb/cleft)|
|**2024-07-30**|**Federated Knowledge Recycling: Privacy-Preserving Synthetic Data Sharing**|Eugenio Lomurno et.al.|[2407.20830v1](http://arxiv.org/abs/2407.20830v1)|null|
|**2024-07-30**|**Architectural Influence on Variational Quantum Circuits in Multi-Agent Reinforcement Learning: Evolutionary Strategies for Optimization**|Michael KÃ¶lle et.al.|[2407.20739v1](http://arxiv.org/abs/2407.20739v1)|null|
|**2024-07-29**|**Dense Self-Supervised Learning for Medical Image Segmentation**|Maxime Seince et.al.|[2407.20395v1](http://arxiv.org/abs/2407.20395v1)|null|
|**2024-07-29**|**Classification, Regression and Segmentation directly from k-Space in Cardiac MRI**|Ruochen Li et.al.|[2407.20108v1](http://arxiv.org/abs/2407.20108v1)|null|
|**2024-07-29**|**Robust Conformal Volume Estimation in 3D Medical Images**|Benjamin Lambert et.al.|[2407.19938v1](http://arxiv.org/abs/2407.19938v1)|[link](https://github.com/benolmbrt/wcp_miccai)|
|**2024-07-29**|**Yucca: A Deep Learning Framework For Medical Image Analysis**|Sebastian NÃ¸rgaard Llambias et.al.|[2407.19888v1](http://arxiv.org/abs/2407.19888v1)|[link](https://github.com/sllambias/yucca)|
|**2024-07-29**|**CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare**|Jingwei Zhu et.al.|[2407.19705v2](http://arxiv.org/abs/2407.19705v2)|[link](https://github.com/cas-siat-xinhai/collectivesft)|
|**2024-07-29**|**Beyond Metrics: A Critical Analysis of the Variability in Large Language Model Evaluation Frameworks**|Marco AF Pimentel et.al.|[2407.21072v1](http://arxiv.org/abs/2407.21072v1)|null|
|**2024-07-29**|**Urban Traffic Accident Risk Prediction Revisited: Regionality, Proximity, Similarity and Sparsity**|Minxiao Chen et.al.|[2407.19668v1](http://arxiv.org/abs/2407.19668v1)|[link](https://github.com/faceless0124/mghstn)|
|**2024-07-28**|**Overcoming Uncertain Incompleteness for Robust Multimodal Sequential Diagnosis Prediction via Knowledge Distillation and Random Data Erasing**|Heejoon Koo et.al.|[2407.19540v1](http://arxiv.org/abs/2407.19540v1)|null|
|**2024-07-28**|**Nudging Consent and the New Opt Out System to the Processing of Health Data in England**|Janos Meszaros et.al.|[2407.19447v1](http://arxiv.org/abs/2407.19447v1)|null|
|**2024-07-28**|**ASI-Seg: Audio-Driven Surgical Instrument Segmentation with Surgeon Intention Understanding**|Zhen Chen et.al.|[2407.19435v1](http://arxiv.org/abs/2407.19435v1)|[link](https://github.com/zonmgin-zhang/asi-seg)|
|**2024-07-28**|**A Generic Review of Integrating Artificial Intelligence in Cognitive Behavioral Therapy**|Meng Jiang et.al.|[2407.19422v1](http://arxiv.org/abs/2407.19422v1)|null|
|**2024-07-28**|**Empowering Clinicians with Medical Decision Transformers: A Framework for Sepsis Treatment**|Aamer Abdul Rahman et.al.|[2407.19380v1](http://arxiv.org/abs/2407.19380v1)|null|
|**2024-07-28**|**Learning to Select the Best Forecasting Tasks for Clinical Outcome Prediction**|Yuan Xue et.al.|[2407.19359v1](http://arxiv.org/abs/2407.19359v1)|null|
|**2024-07-27**|**Integrating Large Language Models into a Tri-Modal Architecture for Automated Depression Classification**|Santosh V. Patapati et.al.|[2407.19340v1](http://arxiv.org/abs/2407.19340v1)|null|
|**2024-07-27**|**Multi-Modal CLIP-Informed Protein Editing**|Mingze Yin et.al.|[2407.19296v1](http://arxiv.org/abs/2407.19296v1)|null|
|**2024-07-27**|**Stochastic Parrots or ICU Experts? Large Language Models in Critical Care Medicine: A Scoping Review**|Tongyue Shi et.al.|[2407.19256v1](http://arxiv.org/abs/2407.19256v1)|null|
|**2024-07-27**|**Channel Boosted CNN-Transformer-based Multi-Level and Multi-Scale Nuclei Segmentation**|Zunaira Rauf et.al.|[2407.19186v1](http://arxiv.org/abs/2407.19186v1)|null|
|**2024-07-27**|**AgentPeerTalk: Empowering Students through Agentic-AI-Driven Discernment of Bullying and Joking in Peer Interactions in Schools**|Aditya Paul et.al.|[2408.01459v1](http://arxiv.org/abs/2408.01459v1)|null|
|**2024-07-26**|**Large Language Models as Co-Pilots for Causal Inference in Medical Studies**|Ahmed Alaa et.al.|[2407.19118v1](http://arxiv.org/abs/2407.19118v1)|null|
|**2024-07-26**|**Solving Robotics Problems in Zero-Shot with Vision-Language Models**|Zidan Wang et.al.|[2407.19094v1](http://arxiv.org/abs/2407.19094v1)|null|
|**2024-07-26**|**Using Large Language Models for the Interpretation of Building Regulations**|Stefan Fuchs et.al.|[2407.21060v1](http://arxiv.org/abs/2407.21060v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-26**|**Is larger always better? Evaluating and prompting large language models for non-generative medical tasks**|Yinghao Zhu et.al.|[2407.18525v1](http://arxiv.org/abs/2407.18525v1)|[link](https://github.com/yhzhu99/ehr-llm-benchmark)|
|**2024-07-26**|**A Role-specific Guided Large Language Model for Ophthalmic Consultation Based on Stylistic Differentiation**|Laiyi Fu et.al.|[2407.18483v4](http://arxiv.org/abs/2407.18483v4)|[link](https://github.com/sperfu/eyedoc)|
|**2024-07-26**|**Towards Automated Solution Recipe Generation for Industrial Asset Management with LLM**|Nianjun Zhou et.al.|[2407.18992v1](http://arxiv.org/abs/2407.18992v1)|null|
|**2024-07-25**|**HDL-GPT: High-Quality HDL is All You Need**|Bhuvnesh Kumar et.al.|[2407.18423v1](http://arxiv.org/abs/2407.18423v1)|null|
|**2024-07-25**|**SCALE: Self-regulated Clustered federAted LEarning in a Homogeneous Environment**|Sai Puppala et.al.|[2407.18387v1](http://arxiv.org/abs/2407.18387v1)|null|
|**2024-07-25**|**Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-25**|**Self-supervised pre-training with diffusion model for few-shot landmark detection in x-ray images**|Roberto Di Via et.al.|[2407.18125v1](http://arxiv.org/abs/2407.18125v1)|null|
|**2024-07-25**|**Multi-Resolution Histopathology Patch Graphs for Ovarian Cancer Subtyping**|Jack Breen et.al.|[2407.18105v1](http://arxiv.org/abs/2407.18105v1)|[link](https://github.com/scjjb/MultiscalePathGraph)|
|**2024-07-25**|**HG-PIPE: Vision Transformer Acceleration with Hybrid-Grained Pipeline**|Qingyu Guo et.al.|[2407.17879v2](http://arxiv.org/abs/2407.17879v2)|null|
|**2024-07-25**|**EEG-SSM: Leveraging State-Space Model for Dementia Detection**|Xuan-The Tran et.al.|[2407.17801v1](http://arxiv.org/abs/2407.17801v1)|null|
|**2024-07-25**|**Closing the gap between open-source and commercial large language models for medical evidence summarization**|Gongbo Zhang et.al.|[2408.00588v1](http://arxiv.org/abs/2408.00588v1)|null|
|**2024-07-25**|**Mpox Detection Advanced: Rapid Epidemic Response Through Synthetic Data**|Yudara Kularathne et.al.|[2407.17762v1](http://arxiv.org/abs/2407.17762v1)|null|
|**2024-07-25**|**Cost-effective Instruction Learning for Pathology Vision and Language Analysis**|Kaitao Chen et.al.|[2407.17734v1](http://arxiv.org/abs/2407.17734v1)|[link](https://github.com/jlinekai/clover)|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|

#### Abstracts
##### **Towards Synergistic Deep Learning Models for Volumetric Cirrhotic Liver Segmentation in MRIs**
2408.04491v1 by Vandan Gorade, Onkar Susladkar, Gorkem Durak, Elif Keles, Ertugrul Aktas, Timurhan Cebeci, Alpay Medetalibeyoglu, Daniela Ladner, Debesh Jha, Ulas Bagci

Liver cirrhosis, a leading cause of global mortality, requires precise
segmentation of ROIs for effective disease monitoring and treatment planning.
Existing segmentation models often fail to capture complex feature interactions
and generalize across diverse datasets. To address these limitations, we
propose a novel synergistic theory that leverages complementary latent spaces
for enhanced feature interaction modeling. Our proposed architecture,
nnSynergyNet3D integrates continuous and discrete latent spaces for 3D volumes
and features auto-configured training. This approach captures both fine-grained
and coarse features, enabling effective modeling of intricate feature
interactions. We empirically validated nnSynergyNet3D on a private dataset of
628 high-resolution T1 abdominal MRI scans from 339 patients. Our model
outperformed the baseline nnUNet3D by approximately 2%. Additionally, zero-shot
testing on healthy liver CT scans from the public LiTS dataset demonstrated
superior cross-modal generalization capabilities. These results highlight the
potential of synergistic latent space models to improve segmentation accuracy
and robustness, thereby enhancing clinical workflows by ensuring consistency
across CT and MRI modalities.

æè¦ï¼èç¡¬åæ¯å¨çæ­»äº¡çä¸»è¦åå ï¼éè¦å¯¹ ROI è¿è¡ç²¾ç¡®åå²ï¼ä»¥è¿è¡ææçç¾ççæµåæ²»çè®¡åãç°æçåå²æ¨¡åéå¸¸æ æ³ææå¤æçç¹å¾äº¤äºï¼å¹¶å¨ä¸åçæ°æ®éä¸è¿è¡æ³åãä¸ºäºè§£å³è¿äºéå¶ï¼æä»¬æåºäºä¸ç§æ°é¢çååçè®ºï¼è¯¥çè®ºå©ç¨äºè¡¥çæ½å¨ç©ºé´æ¥å¢å¼ºç¹å¾äº¤äºå»ºæ¨¡ãæä»¬æåºçæ¶æ nnSynergyNet3D éæäºè¿ç»­åç¦»æ£çæ½å¨ç©ºé´ï¼ç¨äº 3D ä½ç§¯ï¼å¹¶å·æèªå¨éç½®çè®­ç»ãè¿ç§æ¹æ³ææå°äºç»ç²åº¦åç²ç²åº¦ç¹å¾ï¼ä»èè½å¤ææå°å¯¹å¤æçç¹å¾äº¤äºè¿è¡å»ºæ¨¡ãæä»¬æ ¹æ® 339 åæ£èç 628 ä¸ªé«åè¾¨ç T1 è¹é¨ MRI æ«æçç§ææ°æ®éå¯¹ nnSynergyNet3D è¿è¡äºå®è¯éªè¯ãæä»¬çæ¨¡åæ¯åºçº¿ nnUNet3D çæ§è½æé«äºå¤§çº¦ 2%ãæ­¤å¤ï¼å¨æ¥èªå¬å± LiTS æ°æ®éçå¥åº·èè CT æ«æä¸è¿è¡é¶æ ·æ¬æµè¯è¯æäºå¶åè¶çè·¨æ¨¡ææ³åè½åãè¿äºç»æçªåºäºååæ½å¨ç©ºé´æ¨¡åå¨æé«åå²ç²¾åº¦åé²æ£æ§æ¹é¢çæ½åï¼ä»èéè¿ç¡®ä¿ CT å MRI æ¨¡æçä¸è´æ§æ¥å¢å¼ºä¸´åºå·¥ä½æµç¨ã

##### **Non-maximizing policies that fulfill multi-criterion aspirations in expectation**
2408.04385v1 by Simon Dima, Simon Fischer, Jobst Heitzig, Joss Oliver

In dynamic programming and reinforcement learning, the policy for the
sequential decision making of an agent in a stochastic environment is usually
determined by expressing the goal as a scalar reward function and seeking a
policy that maximizes the expected total reward. However, many goals that
humans care about naturally concern multiple aspects of the world, and it may
not be obvious how to condense those into a single reward function.
Furthermore, maximization suffers from specification gaming, where the obtained
policy achieves a high expected total reward in an unintended way, often taking
extreme or nonsensical actions.
  Here we consider finite acyclic Markov Decision Processes with multiple
distinct evaluation metrics, which do not necessarily represent quantities that
the user wants to be maximized. We assume the task of the agent is to ensure
that the vector of expected totals of the evaluation metrics falls into some
given convex set, called the aspiration set. Our algorithm guarantees that this
task is fulfilled by using simplices to approximate feasibility sets and
propagate aspirations forward while ensuring they remain feasible. It has
complexity linear in the number of possible state-action-successor triples and
polynomial in the number of evaluation metrics. Moreover, the explicitly
non-maximizing nature of the chosen policy and goals yields additional degrees
of freedom, which can be used to apply heuristic safety criteria to the choice
of actions. We discuss several such safety criteria that aim to steer the agent
towards more conservative behavior.

æè¦ï¼å¨åæè¦ååå¼·åå­¸ç¿ä¸­ï¼ä»£çäººå¨é¨æ©ç°å¢ä¸­é²è¡é åºæ±ºç­çç­ç¥éå¸¸ééå°ç®æ¨è¡¨éçºæ¨éçåµå½æ¸ä¸¦å°æ±æå¤§åé æç¸½çåµçç­ç¥ä¾ç¢ºå®ãç¶èï¼äººé¡éå¿çè¨±å¤ç®æ¨èªç¶æ¶åä¸ççå¤åæ¹é¢ï¼ä¸¦ä¸å¯è½ä¸¦ä¸æ¸æ¥å¦ä½å°éäºç®æ¨æ¿ç¸®æå®ä¸ççåµå½æ¸ãæ­¤å¤ï¼æå¤§åæåå°è¦ç¯åå¼çå½±é¿ï¼å¶ä¸­ç²å¾çç­ç¥ä»¥æå¤çæ¹å¼å¯¦ç¾äºå¾é«çé æç¸½çåµï¼éå¸¸æ¡åæ¥µç«¯æèè¬¬çè¡åã
å¨éè£¡ï¼æåèæ®å·æå¤åä¸åè©ä¼°ææ¨çæéç¡ç°é¦¬å¯å¤«æ±ºç­éç¨ï¼éäºææ¨ä¸ä¸å®è¡¨ç¤ºç¨æ¶å¸ææå¤§åçæ¸éãæååè¨­ä»£çäººçä»»åæ¯ç¢ºä¿è©ä¼°ææ¨é æç¸½éçåéè½å¥æåçµ¦å®çå¸éï¼ç¨±çºé¡æéãæåçæ¼ç®æ³ä¿è­ééä½¿ç¨å®å½¢ä¾é¼è¿å¯è¡éä¸¦å¨ç¢ºä¿å¯è¡æ§çåæååå³æ­é¡æä¾å®ææ­¤ä»»åãå®çè¤éåº¦èå¯è½ççæ-åä½-å¾ç¹¼ä¸åçµçæ¸éåç·æ§éä¿ï¼èè©ä¼°ææ¨çæ¸éåå¤é å¼éä¿ãæ­¤å¤ï¼æé¸ç­ç¥åç®æ¨çé¡¯å¼éæå¤§åæ§è³ªç¢çäºé¡å¤çèªç±åº¦ï¼å¯ç¨æ¼å°åç¼å¼å®å¨æºåæç¨æ¼åä½çé¸æãæåè¨è«äºå¹¾åéæ¨£çå®å¨æºåï¼æ¨å¨å¼å°ä»£çäººæ¡åæ´ä¿å®çè¡çºã

##### **AI-Driven Chatbot for Intrusion Detection in Edge Networks: Enhancing Cybersecurity with Ethical User Consent**
2408.04281v1 by Mugheez Asif, Abdul Manan, Abdul Moiz ur Rehman, Mamoona Naveed Asghar, Muhammad Umair

In today's contemporary digital landscape, chatbots have become indispensable
tools across various sectors, streamlining customer service, providing personal
assistance, automating routine tasks, and offering health advice. However,
their potential remains underexplored in the realm of network security,
particularly for intrusion detection. To bridge this gap, we propose an
architecture chatbot specifically designed to enhance security within edge
networks specifically for intrusion detection. Leveraging advanced machine
learning algorithms, this chatbot will monitor network traffic to identify and
mitigate potential intrusions. By securing the network environment using an
edge network managed by a Raspberry Pi module and ensuring ethical user consent
promoting transparency and trust, this innovative solution aims to safeguard
sensitive data and maintain a secure workplace, thereby addressing the growing
need for robust network security measures in the digital age.

æè¦ï¼å¨ç¶ä»çç¾ä»£æ¸ä½ç°å¢ä¸­ï¼èå¤©æ©å¨äººå·²æçºååç¢æ¥­ä¸å¯æç¼ºçå·¥å·ï¼ç°¡åå®¢æ¶æåãæä¾åäººåå©ãèªååä¾è¡å·¥ä½ä¸¦æä¾å¥åº·å»ºè­°ãç¶èï¼å®åå¨ç¶²è·¯å®å¨é åçæ½åä»æªå¾å°ååæ¢ç´¢ï¼ç¹å¥æ¯å¨å¥ä¾µåµæ¸¬æ¹é¢ãçºäºå½è£éåå·®è·ï¼æåæåºäºä¸ç¨®å°éè¨­è¨ç¨æ¼å¢å¼·éç·£ç¶²è·¯å§é¨å®å¨æ§çæ¶æ§èå¤©æ©å¨äººï¼ç¹å¥æ¯ç¨æ¼å¥ä¾µåµæ¸¬ãééå©ç¨åé²çæ©å¨å­¸ç¿æ¼ç®æ³ï¼æ­¤èå¤©æ©å¨äººå°ç£æ§ç¶²è·¯æµéä»¥è­å¥åæ¸è¼æ½å¨å¥ä¾µãééä½¿ç¨ç± Raspberry Pi æ¨¡çµç®¡ççéç·£ç¶²è·¯ä¾ä¿è­·ç¶²è·¯ç°å¢ï¼ä¸¦ç¢ºä¿åä¹éå¾·çä½¿ç¨èåæä»¥ä¿é²éæåº¦åä¿¡ä»»ï¼éååµæ°çè§£æ±ºæ¹æ¡æ¨å¨ä¿è­·ææè³æä¸¦ç¶­è­·ä¸åå®å¨çå·¥ä½å ´æï¼å¾èæ»¿è¶³æ¸ä½æä»£å°å¼·å¤§ç¶²è·¯å®å¨æªæ½æ¥çå¢é·çéæ±ã

##### **The Data Addition Dilemma**
2408.04154v1 by Judy Hanwen Shen, Inioluwa Deborah Raji, Irene Y. Chen

In many machine learning for healthcare tasks, standard datasets are
constructed by amassing data across many, often fundamentally dissimilar,
sources. But when does adding more data help, and when does it hinder progress
on desired model outcomes in real-world settings? We identify this situation as
the \textit{Data Addition Dilemma}, demonstrating that adding training data in
this multi-source scaling context can at times result in reduced overall
accuracy, uncertain fairness outcomes, and reduced worst-subgroup performance.
We find that this possibly arises from an empirically observed trade-off
between model performance improvements due to data scaling and model
deterioration from distribution shift. We thus establish baseline strategies
for navigating this dilemma, introducing distribution shift heuristics to guide
decision-making on which data sources to add in data scaling, in order to yield
the expected model performance improvements. We conclude with a discussion of
the required considerations for data collection and suggestions for studying
data composition and scale in the age of increasingly larger models.

æè¦ï¼å¨è¨±å¤é«çä¿å¥ä»»åçæ©å¨å­¸ç¿ä¸­ï¼æ¨æºè³æéæ¯ééæ¶éä¾èªè¨±å¤éå¸¸æ ¹æ¬ä¸åçä¾æºçè³æèå»ºæ§çãä½æ¯ï¼ä½ææ°å¢æ´å¤è³ææå¹«å©ï¼èä½ææé»ç¤å¨ç¾å¯¦ä¸çè¨­å®ä¸­éæé æçæ¨¡åææï¼æåå°æ­¤ææ³èªå®çºãè³ææ°å¢å°å¢ãï¼è­æå¨æ­¤å¤ä¾æºæ´åçèæ¯ä¸æ°å¢è¨ç·´è³æï¼ææå¯è½æå°è´æ´é«æºç¢ºåº¦éä½ãä¸ç¢ºå®çå¬å¹³æ§çµæï¼ä»¥åæå·®å­ç¾¤é«æè½éä½ãæåç¼ç¾éå¯è½æ¯ç±æ¼è³ææ´åå°è´çæ¨¡åæè½æåèåéè½ç§»å°è´çæ¨¡åå£åä¹éçç¶é©æ§æ¬è¡¡æè´ãå æ­¤ï¼æåå»ºç«äºæå°æ­¤å°å¢çåºæ¬ç­ç¥ï¼å¼å¥äºåéè½ç§»åç¼æ³ï¼ä»¥æå°æéå¨è³ææ´åä¸­æ°å¢åªäºè³æä¾æºçæ±ºç­å¶å®ï¼ä»¥ç¢çé æçæ¨¡åæè½æåãæåæå¾è¨è«äºè³ææ¶éæéçèéå ç´ ï¼ä¸¦å»ºè­°ç ç©¶è³æçµæåè¦æ¨¡å¨æ¨¡åè¦æ¨¡æ¥çæ´å¤§çæä»£ã

##### **Enhancing Healthcare through Large Language Models: A Study on Medical Question Answering**
2408.04138v1 by Haoran Yu, Chang Yu, Zihan Wang, Dongxian Zou, Hao Qin

In recent years, the application of Large Language Models (LLMs) in
healthcare has shown significant promise in improving the accessibility and
dissemination of medical knowledge. This paper presents a detailed study of
various LLMs trained on the MedQuAD medical question-answering dataset, with a
focus on identifying the most effective model for providing accurate medical
information. Among the models tested, the Sentence-t5 combined with Mistral 7B
demonstrated superior performance, achieving a precision score of 0.762. This
model's enhanced capabilities are attributed to its advanced pretraining
techniques, robust architecture, and effective prompt construction
methodologies. By leveraging these strengths, the Sentence-t5 + Mistral 7B
model excels in understanding and generating precise medical answers. Our
findings highlight the potential of integrating sophisticated LLMs in medical
contexts to facilitate efficient and accurate medical knowledge retrieval, thus
significantly enhancing patient education and support.

æè¦ï¼è¿å¹´ä¾ï¼å¤§åèªè¨æ¨¡å (LLM) å¨é«çä¿å¥ä¸­çæç¨å·²å±ç¾åºé¡¯èçå¸æï¼å¯æ¹åé«çç¥è­çå¯åæ§åå³æ­ãæ¬æéå°å¨ MedQuAD é«çåç­è³æéä¸è¨ç·´çåç¨® LLM é²è¡è©³ç´°ç ç©¶ï¼éé»å¨æ¼æ¾åºæä¾æºç¢ºé«çè³è¨æææçæ¨¡åãå¨æ¸¬è©¦çæ¨¡åä¸­ï¼Sentence-t5 çµå Mistral 7B è¡¨ç¾åªç°ï¼éå° 0.762 çç²¾æºåº¦åæ¸ãæ­¤æ¨¡åçå¢å¼·åè½æ­¸åæ¼å¶åé²çé è¨ç·´æè¡ãå¼·å¤§çæ¶æ§åææçæç¤ºå»ºæ§æ¹æ³ãSentence-t5 + Mistral 7B æ¨¡åèç±éç¨éäºåªå¢ï¼å¨çè§£åç¢çç²¾ç¢ºçé«çç­æ¡æ¹é¢è¡¨ç¾åºè²ãæåçç ç©¶çµæçªé¡¯äºå°è¤éç LLM æ´åå°é«çèæ¯ä¸­çæ½åï¼ä»¥ä¿é²ææçä¸æºç¢ºçé«çç¥è­æ·åï¼é²èé¡¯èæåçæ£æè²åæ¯æã

##### **Can Rule-Based Insights Enhance LLMs for Radiology Report Classification? Introducing the RadPrompt Methodology**
2408.04121v1 by Panagiotis Fytas, Anna Breger, Ian Selby, Simon Baker, Shahab Shahipasand, Anna Korhonen

Developing imaging models capable of detecting pathologies from chest X-rays
can be cost and time-prohibitive for large datasets as it requires supervision
to attain state-of-the-art performance. Instead, labels extracted from
radiology reports may serve as distant supervision since these are routinely
generated as part of clinical practice. Despite their widespread use, current
rule-based methods for label extraction rely on extensive rule sets that are
limited in their robustness to syntactic variability. To alleviate these
limitations, we introduce RadPert, a rule-based system that integrates an
uncertainty-aware information schema with a streamlined set of rules, enhancing
performance. Additionally, we have developed RadPrompt, a multi-turn prompting
strategy that leverages RadPert to bolster the zero-shot predictive
capabilities of large language models, achieving a statistically significant
improvement in weighted average F1 score over GPT-4 Turbo. Most notably,
RadPrompt surpasses both its underlying models, showcasing the synergistic
potential of LLMs with rule-based models. We have evaluated our methods on two
English Corpora: the MIMIC-CXR gold-standard test set and a gold-standard
dataset collected from the Cambridge University Hospitals.

æè¦ï¼éç¼åºè½å¤ å¾è¸é¨ X åæª¢æ¸¬çççå½±åæ¨¡åï¼å°æ¼å¤§åè³æéä¾èªªï¼å¨ææ¬åæéä¸é½å¯è½æ¯ç¦æ­¢çï¼å çºå®éè¦ç£ç£æè½éå°æåé²çæè½ãç¸åå°ï¼å¾æ¾å°ç§å ±åä¸­æåçæ¨ç±¤å¯ä»¥ç¨ä½é ç«¯ç£ç£ï¼å çºéäºæ¨ç±¤éå¸¸ä½çºè¨åºå¯¦åçä¸é¨åèç¢çãåç®¡å»£æ³ä½¿ç¨ï¼ä½ç®åç¨æ¼æ¨ç±¤æåçåºæ¼è¦åçæ¹æ³ä¾è³´æ¼å»£æ³çè¦åéï¼å¶å°èªæ³è®ç°çå¥å£¯æ§æéãçºäºæ¸è¼éäºéå¶ï¼æåå¼å¥äº RadPertï¼éæ¯ä¸ååºæ¼è¦åçç³»çµ±ï¼å®å°ä¸åä¸ç¢ºå®æ§æç¥è³è¨æ¶æ§èä¸çµç°¡åçè¦åæ´åå¨ä¸èµ·ï¼å¾èå¢å¼·äºæè½ãæ­¤å¤ï¼æåééç¼äº RadPromptï¼éæ¯ä¸åå¤è¼ªæç¤ºç­ç¥ï¼å®å©ç¨ RadPert ä¾å å¼·å¤§åèªè¨æ¨¡åçé¶æ¬¡å­¸ç¿é æ¸¬è½åï¼å¨å æ¬å¹³å F1 åæ¸ä¸å¯¦ç¾äºç¸å°æ¼ GPT-4 Turbo ççµ±è¨é¡¯èæ¹é²ãæå¼å¾æ³¨æçæ¯ï¼RadPrompt è¶è¶äºå¶åºç¤æ¨¡åï¼å±ç¤ºäºåºæ¼è¦åçæ¨¡åè LLM çååæ½åãæåå·²å¨å©åè±æèªæåº«ä¸è©ä¼°äºæåçæ¹æ³ï¼MIMIC-CXR é»éæ¨æºæ¸¬è©¦éåå¾åæ©å¤§å­¸é«é¢æ¶éçé»éæ¨æºè³æéã

##### **Multimodal Gender Fairness in Depression Prediction: Insights on Data from the USA & China**
2408.04026v1 by Joseph Cameron, Jiaee Cheong, Micol Spitale, Hatice Gunes

Social agents and robots are increasingly being used in wellbeing settings.
However, a key challenge is that these agents and robots typically rely on
machine learning (ML) algorithms to detect and analyse an individual's mental
wellbeing. The problem of bias and fairness in ML algorithms is becoming an
increasingly greater source of concern. In concurrence, existing literature has
also indicated that mental health conditions can manifest differently across
genders and cultures. We hypothesise that the representation of features
(acoustic, textual, and visual) and their inter-modal relations would vary
among subjects from different cultures and genders, thus impacting the
performance and fairness of various ML models. We present the very first
evaluation of multimodal gender fairness in depression manifestation by
undertaking a study on two different datasets from the USA and China. We
undertake thorough statistical and ML experimentation and repeat the
experiments for several different algorithms to ensure that the results are not
algorithm-dependent. Our findings indicate that though there are differences
between both datasets, it is not conclusive whether this is due to the
difference in depression manifestation as hypothesised or other external
factors such as differences in data collection methodology. Our findings
further motivate a call for a more consistent and culturally aware data
collection process in order to address the problem of ML bias in depression
detection and to promote the development of fairer agents and robots for
wellbeing.

æè¦ï¼ç¤¾ç¾¤ä»£çäººåæ©å¨äººå¨å¹¸ç¦æè¨­å®ä¸­æ­£è¶ä¾è¶å»£æ³å°è¢«ä½¿ç¨ã
ç¶èï¼ä¸åééµçææ°æ¯éäºä»£çäººåæ©å¨äººéå¸¸ä¾è³´æ©å¨å­¸ç¿ (ML) æ¼ç®æ³ä¾åµæ¸¬ååæåäººå¿çå¥åº·ãML æ¼ç®æ³ä¸­çåå·®åå¬å¹³æ§åé¡æ­£æçºè¶ä¾è¶å¤§çéæ³¨ä¾æºãåæï¼ç¾ææç»ä¹æåºå¿çå¥åº·çæ³æå¨ä¸åæ§å¥åæåä¸­ä»¥ä¸åçæ¹å¼é¡¯ç¾ãæååè¨­ç¹å¾µï¼è²é³ãæå­åè¦è¦ºï¼çåç¾åå¶è·¨æ¨¡æéä¿æå ä¸åæååæ§å¥çåè©¦èèç°ï¼å¾èå½±é¿åç¨® ML æ¨¡åçæè½åå¬å¹³æ§ãæåééå°ä¾èªç¾ååä¸­åçå©åä¸åè³æéé²è¡ç ç©¶ï¼æåºé¦æ¬¡å°æé¬±çè¡¨ç¾çå¤æ¨¡ææ§å¥å¬å¹³æ§è©ä¼°ãæåé²è¡å¾¹åºççµ±è¨å ML å¯¦é©ï¼ä¸¦éå°å¤ç¨®ä¸åçæ¼ç®æ³éè¤å¯¦é©ï¼ä»¥ç¢ºä¿çµæä¸ä¾è³´æ¼æ¼ç®æ³ãæåçç ç©¶çµæè¡¨æï¼åç®¡å©åè³æéä¹éå­å¨å·®ç°ï¼ä½ç¡æ³ç¢ºå®éæ¯å¦æ¯ç±æ¼åè¨­çæé¬±çè¡¨ç¾å·®ç°æå¶ä»å¤é¨å ç´ ï¼ä¾å¦è³ææ¶éæ¹æ³çå·®ç°ï¼æé æãæåçç ç©¶çµæé²ä¸æ­¥å¼ç±²æ¡ç¨æ´ä¸è´ä¸å·ææåæè­çè³ææ¶éç¨åºï¼ä»¥è§£æ±ºæé¬±çåµæ¸¬ä¸­ç ML åå·®åé¡ï¼ä¸¦ä¿é²éç¼æ´å¬å¹³çä»£çäººåæ©å¨äººï¼ä»¥æåå¹¸ç¦æã

##### **Inter-Series Transformer: Attending to Products in Time Series Forecasting**
2408.03872v1 by Rares Cristian, Pavithra Harsha, Clemente Ocejo, Georgia Perakis, Brian Quanz, Ioannis Spantidakis, Hamza Zerhouni

Time series forecasting is an important task in many fields ranging from
supply chain management to weather forecasting. Recently, Transformer neural
network architectures have shown promising results in forecasting on common
time series benchmark datasets. However, application to supply chain demand
forecasting, which can have challenging characteristics such as sparsity and
cross-series effects, has been limited.
  In this work, we explore the application of Transformer-based models to
supply chain demand forecasting. In particular, we develop a new
Transformer-based forecasting approach using a shared, multi-task per-time
series network with an initial component applying attention across time series,
to capture interactions and help address sparsity. We provide a case study
applying our approach to successfully improve demand prediction for a medical
device manufacturing company. To further validate our approach, we also apply
it to public demand forecasting datasets as well and demonstrate competitive to
superior performance compared to a variety of baseline and state-of-the-art
forecast methods across the private and public datasets.

æè¦ï¼æéåºåé æ¸¬å¨è¨±å¤é åä¸­é½æ¯ä¸é éè¦çä»»åï¼å¾ä¾æéç®¡çå°å¤©æ°£é æ¸¬é½ææ¶åãæè¿ï¼Transformer ç¥ç¶ç¶²è·¯æ¶æ§å¨å¸¸è¦æéåºååºæºè³æéçé æ¸¬ä¸­å±ç¾äºä»¤äººæ»¿æçææãç¶èï¼æç¨æ¼ä¾æééæ±é æ¸¬çç¯çåå°éå¶ï¼å çºä¾æééæ±é æ¸¬å¯è½å·æç¨çæ§åè·¨ç³»åææç­å·ææ°æ§çç¹å¾µã
  å¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äºå°åºæ¼ Transformer çæ¨¡åæç¨æ¼ä¾æééæ±é æ¸¬ãç¹å¥æ¯ï¼æåéç¼äºä¸ç¨®æ°çåºæ¼ Transformer çé æ¸¬æ¹æ³ï¼ä½¿ç¨ä¸åå±ç¨çãæ¯åæéåºåçå¤ä»»åç¶²è·¯ï¼ä¸¦å¨åå§åä»¶ä¸­å¥ç¨è·¨æéåºåçæ³¨æåï¼ä»¥æ·åäºåä¸¦åå©è§£æ±ºç¨çæ§åé¡ãæåæä¾äºä¸åæ¡ä¾ç ç©¶ï¼æç¨æåçåæ³æåæ¹åäºä¸å®¶é«çå¨æè£½é å¬å¸çéæ±é æ¸¬ãçºäºé²ä¸æ­¥é©è­æåçåæ³ï¼æåä¹å°å¶æç¨æ¼å¬éçéæ±é æ¸¬è³æéï¼ä¸¦è­æèåç¨®åºç·åæåé²çé æ¸¬æ¹æ³ç¸æ¯ï¼å¨ç§æåå¬éè³æéä¸­çè¡¨ç¾å·æç«¶ç­åæåªæ¼éäºæ¹æ³ã

##### **HiQuE: Hierarchical Question Embedding Network for Multimodal Depression Detection**
2408.03648v1 by Juho Jung, Chaewon Kang, Jeewoo Yoon, Seungbae Kim, Jinyoung Han

The utilization of automated depression detection significantly enhances
early intervention for individuals experiencing depression. Despite numerous
proposals on automated depression detection using recorded clinical interview
videos, limited attention has been paid to considering the hierarchical
structure of the interview questions. In clinical interviews for diagnosing
depression, clinicians use a structured questionnaire that includes routine
baseline questions and follow-up questions to assess the interviewee's
condition. This paper introduces HiQuE (Hierarchical Question Embedding
network), a novel depression detection framework that leverages the
hierarchical relationship between primary and follow-up questions in clinical
interviews. HiQuE can effectively capture the importance of each question in
diagnosing depression by learning mutual information across multiple
modalities. We conduct extensive experiments on the widely-used clinical
interview data, DAIC-WOZ, where our model outperforms other state-of-the-art
multimodal depression detection models and emotion recognition models,
showcasing its clinical utility in depression detection.

æè¦ï¼èªåæé¬±çåµæ¸¬çå©ç¨é¡¯èæåäºæé¬±çæ£èçæ©æä»å¥ãåç®¡æè¨±å¤ä½¿ç¨éè£½è¨åºè¨ªè«å½±ççèªåæé¬±çåµæ¸¬ææ¡ï¼ä½å°æ¼èéè¨ªè«åé¡çéå±¤çµæ§éæ¹é¢å»é®®å°éæ³¨ãå¨ç¨æ¼è¨ºæ·æé¬±ççè¨åºè¨ªè«ä¸­ï¼è¨åºé«å¸«æä½¿ç¨åå«ä¾è¡åºæºåé¡åè¿½è¹¤åé¡ççµæ§ååå·ä¾è©ä¼°åè¨ªèççæ³ãæ¬æä»ç´¹äº HiQuEï¼éå±¤å¼åé¡åµå¥ç¶²è·¯ï¼ï¼éæ¯ä¸ç¨®æ°ç©çæé¬±çåµæ¸¬æ¶æ§ï¼å®å©ç¨äºè¨åºè¨ªè«ä¸­ä¸»è¦åé¡åè¿½è¹¤åé¡ä¹éçéå±¤éä¿ãHiQuE è½å¤ ééå­¸ç¿å¤ç¨®æ¹å¼ä¹éçäºæ è³è¨ï¼ææå°æ·åæ¯ååé¡å¨æé¬±çè¨ºæ·ä¸­çéè¦æ§ãæåå¨å»£æ³ä½¿ç¨çè¨åºè¨ªè«è³æ DAIC-WOZ ä¸é²è¡äºå»£æ³çå¯¦é©ï¼æåçæ¨¡ååªæ¼å¶ä»æåé²çå¤æ¨¡ææé¬±çåµæ¸¬æ¨¡ååæç·è¾¨è­æ¨¡åï¼å±ç¤ºäºå¶å¨æé¬±çåµæ¸¬ä¸­çè¨åºæç¨ã

##### **Improving the quality of Persian clinical text with a novel spelling correction system**
2408.03622v1 by Seyed Mohammad Sadegh Dashti, Seyedeh Fatemeh Dashti

Background: The accuracy of spelling in Electronic Health Records (EHRs) is a
critical factor for efficient clinical care, research, and ensuring patient
safety. The Persian language, with its abundant vocabulary and complex
characteristics, poses unique challenges for real-word error correction. This
research aimed to develop an innovative approach for detecting and correcting
spelling errors in Persian clinical text.
  Methods: Our strategy employs a state-of-the-art pre-trained model that has
been meticulously fine-tuned specifically for the task of spelling correction
in the Persian clinical domain. This model is complemented by an innovative
orthographic similarity matching algorithm, PERTO, which uses visual similarity
of characters for ranking correction candidates.
  Results: The evaluation of our approach demonstrated its robustness and
precision in detecting and rectifying word errors in Persian clinical text. In
terms of non-word error correction, our model achieved an F1-Score of 90.0%
when the PERTO algorithm was employed. For real-word error detection, our model
demonstrated its highest performance, achieving an F1-Score of 90.6%.
Furthermore, the model reached its highest F1-Score of 91.5% for real-word
error correction when the PERTO algorithm was employed.
  Conclusions: Despite certain limitations, our method represents a substantial
advancement in the field of spelling error detection and correction for Persian
clinical text. By effectively addressing the unique challenges posed by the
Persian language, our approach paves the way for more accurate and efficient
clinical documentation, contributing to improved patient care and safety.
Future research could explore its use in other areas of the Persian medical
domain, enhancing its impact and utility.

æè¦ï¼èæ¯ï¼é»å­çæ­· (EHR) ä¸­æ¼å¯«çæºç¢ºæ§æ¯ææè¨åºç§è­·ãç ç©¶åç¢ºä¿æ£èå®å¨æ§çééµå ç´ ãæ³¢æ¯èªææè±å¯çè©å½åè¤éçç¹å¾µï¼å°çå¯¦ä¸ççé¯èª¤æ´æ­£æåºäºç¨ç¹çææ°ãæ¬ç ç©¶æ¨å¨éç¼ä¸ç¨®åµæ°çæ¹æ³ä¾åµæ¸¬åæ´æ­£æ³¢æ¯èªè¨åºææ¬ä¸­çæ¼å¯«é¯èª¤ã
æ¹æ³ï¼æåçç­ç¥æ¡ç¨äºæåé²çé è¨ç·´æ¨¡åï¼è©²æ¨¡åç¶éç²¾å¿å¾®èª¿ï¼å°éç¨æ¼æ³¢æ¯èªè¨åºé åä¸­çæ¼å¯«æ´æ­£ä»»åãæ­¤æ¨¡åç±åµæ°çæ­£å­æ³ç¸ä¼¼æ§å¹éæ¼ç®æ³ PERTO è£åï¼è©²æ¼ç®æ³ä½¿ç¨å­åçè¦è¦ºç¸ä¼¼æ§ä¾å°æ´æ­£åé¸é é²è¡æåã
çµæï¼å°æåæ¹æ³çè©ä¼°è­æäºå¶å¨åµæ¸¬åç³¾æ­£æ³¢æ¯èªè¨åºææ¬ä¸­çæå­é¯èª¤æ¹é¢çç©©å¥æ§åæºç¢ºæ§ãå¨éæå­é¯èª¤æ´æ­£æ¹é¢ï¼ç¶ä½¿ç¨ PERTO æ¼ç®æ³æï¼æåçæ¨¡åå¯¦ç¾äº 90.0% ç F1 åæ¸ãå°æ¼çå¯¦ä¸ççé¯èª¤åµæ¸¬ï¼æåçæ¨¡åå±ç¤ºäºå¶æé«çæè½ï¼å¯¦ç¾äº 90.6% ç F1 åæ¸ãæ­¤å¤ï¼ç¶ä½¿ç¨ PERTO æ¼ç®æ³æï¼è©²æ¨¡åéå°äºå¶æé«ç F1 åæ¸ 91.5%ï¼ç¨æ¼çå¯¦ä¸ççé¯èª¤æ´æ­£ã
çµè«ï¼åç®¡å­å¨æäºéå¶ï¼ä½æåçæ¨¡åä»£è¡¨äºæ³¢æ¯èªè¨åºææ¬æ¼å¯«é¯èª¤åµæ¸¬åæ´æ­£é åçéå¤§é²å±ãééææè§£æ±ºæ³¢æ¯èªæå¸¶ä¾çç¨ç¹ææ°ï¼æåçåæ³çºæ´æºç¢ºåææçè¨åºæä»¶éªè·¯ï¼æå©æ¼æ¹åæ£èç§è­·åå®å¨æ§ãæªä¾çç ç©¶å¯ä»¥æ¢è¨å¶å¨æ³¢æ¯èªé«å­¸é åå¶ä»é åçæç¨ï¼ä»¥å¢å¼·å¶å½±é¿ååå¯¦ç¨æ§ã

##### **Identifying treatment response subgroups in observational time-to-event data**
2408.03463v1 by Vincent Jeanselme, Chang Ho Yoon, Fabian Falck, Brian Tom, Jessica Barrett

Identifying patient subgroups with different treatment responses is an
important task to inform medical recommendations, guidelines, and the design of
future clinical trials. Existing approaches for subgroup analysis primarily
focus on Randomised Controlled Trials (RCTs), in which treatment assignment is
randomised. Furthermore, the patient cohort of an RCT is often constrained by
cost, and is not representative of the heterogeneity of patients likely to
receive treatment in real-world clinical practice. Therefore, when applied to
observational studies, such approaches suffer from significant statistical
biases because of the non-randomisation of treatment. Our work introduces a
novel, outcome-guided method for identifying treatment response subgroups in
observational studies. Our approach assigns each patient to a subgroup
associated with two time-to-event distributions: one under treatment and one
under control regime. It hence positions itself in between individualised and
average treatment effect estimation. The assumptions of our model result in a
simple correction of the statistical bias from treatment non-randomisation
through inverse propensity weighting. In experiments, our approach
significantly outperforms the current state-of-the-art method for
outcome-guided subgroup analysis in both randomised and observational treatment
regimes.

æè¦ï¼è­å¥å·æä¸åæ²»çåæçæ£èå­ç¾¤æ¯çºé«çå»ºè­°ãæååæªä¾è¨åºè©¦é©çè¨­è¨æä¾è³è¨çä¸é éè¦ä»»åãç¾æçå­ç¾¤åææ¹æ³ä¸»è¦éä¸­æ¼é¨æ©å°ç§è©¦é© (RCT)ï¼å¶ä¸­æ²»çåéæ¯é¨æ©çãæ­¤å¤ï¼RCT çæ£èç¾¤é«éå¸¸åå°ææ¬çéå¶ï¼ä¸ç¡æ³ä»£è¡¨å¨ç¾å¯¦ä¸çè¨åºå¯¦åä¸­å¯è½æ¥åæ²»ççæ£èç°è³ªæ§ãå æ­¤ï¼ç¶æç¨æ¼è§å¯æ§ç ç©¶æï¼æ­¤é¡æ¹æ³æå æ²»ççéé¨æ©åèç¢çé¡¯èççµ±è¨åå·®ãæåçç ç©¶å¼å¥äºä¸ç¨®æ°çãçµæå°åçæ¹æ³ï¼ç¨æ¼è­å¥è§å¯æ§ç ç©¶ä¸­çæ²»çåæå­ç¾¤ãæåçåæ³æ¯å°æ¯åæ£èåéå°ä¸åå­ç¾¤ï¼è©²å­ç¾¤èå©åäºä»¶ç¼çæéåéç¸éï¼ä¸åå¨æ²»çä¸ï¼å¦ä¸åå¨å°ç§æ©å¶ä¸ãå æ­¤ï¼å®ä»æ¼åå¥ååå¹³åæ²»çææä¼°è¨ä¹éãæåæ¨¡åçåè¨­å°è´éééåå¾åå æ¬å°ä¾èªæ²»çéé¨æ©åççµ±è¨åå·®é²è¡ç°¡å®æ ¡æ­£ãå¨å¯¦é©ä¸­ï¼æåçåæ³å¨é¨æ©åè§å¯æ§æ²»çæ©å¶ä¸­é½é¡¯èåªæ¼ç¶åæåé²ççµæå°åå­ç¾¤åææ¹æ³ã

##### **Combining Diverse Information for Coordinated Action: Stochastic Bandit Algorithms for Heterogeneous Agents**
2408.03405v1 by Lucia Gordon, Esther Rolf, Milind Tambe

Stochastic multi-agent multi-armed bandits typically assume that the rewards
from each arm follow a fixed distribution, regardless of which agent pulls the
arm. However, in many real-world settings, rewards can depend on the
sensitivity of each agent to their environment. In medical screening, disease
detection rates can vary by test type; in preference matching, rewards can
depend on user preferences; and in environmental sensing, observation quality
can vary across sensors. Since past work does not specify how to allocate
agents of heterogeneous but known sensitivity of these types in a stochastic
bandit setting, we introduce a UCB-style algorithm, Min-Width, which aggregates
information from diverse agents. In doing so, we address the joint challenges
of (i) aggregating the rewards, which follow different distributions for each
agent-arm pair, and (ii) coordinating the assignments of agents to arms.
Min-Width facilitates efficient collaboration among heterogeneous agents,
exploiting the known structure in the agents' reward functions to weight their
rewards accordingly. We analyze the regret of Min-Width and conduct
pseudo-synthetic and fully synthetic experiments to study the performance of
different levels of information sharing. Our results confirm that the gains to
modeling agent heterogeneity tend to be greater when the sensitivities are more
varied across agents, while combining more information does not always improve
performance.

æè¦ï¼é¨æ©å¤æºè½é«å¤èè³­å¾éå¸¸åè¨­æ¯åæèçåå ±éµå¾ªåºå®åä½ï¼ç¡è«åªåæºè½é«æåæèãç¶èï¼å¨è¨±å¤çå¯¦ä¸çè¨­å®ä¸­ï¼åå ±å¯è½åæ±ºæ¼æ¯åæºè½é«å°å¶ç°å¢çææåº¦ãå¨é«å­¸ç¯©æª¢ä¸­ï¼ç¾çæª¢æ¸¬çæå æ¸¬è©¦é¡åèç°ï¼å¨åå¥½å¹éä¸­ï¼åå ±å¯è½åæ±ºæ¼ä½¿ç¨èåå¥½ï¼å¨ç°å¢ææ¸¬ä¸­ï¼è§å¯åè³ªå¯è½å ææ¸¬å¨èç°ãç±æ¼éå»çå·¥ä½æªèªªæå¦ä½éç½®éäºé¡åç°è³ªä½å·²ç¥ææåº¦çæºè½é«å¨é¨æ©è³­å¾è¨­å®ä¸­ï¼æåå¼å¥ä¸ç¨® UCB é¢¨æ ¼æ¼ç®æ³ï¼Min-Widthï¼å®æå½ç¸½ä¾èªä¸åæºè½é«çè³è¨ãå¨éæ¨£åçéç¨ä¸­ï¼æåè§£æ±ºäº (i) å½ç¸½åå ±çå±åææ°ï¼éäºåå ±éµå¾ªæ¯åæºè½é«æèéå°çä¸ååä½ï¼ä»¥å (ii) åèª¿å°æºè½é«æå®çµ¦æèãMin-Width ä¿é²ç°è³ªæºè½é«ä¹éçææåä½ï¼å©ç¨æºè½é«åå ±å½æ¸ä¸­çå·²ç¥çµæ§ä¾é©ç¶å°å æ¬å¶åå ±ãæååæ Min-Width çéºæ¾ï¼ä¸¦é²è¡å½åæåå®å¨åæå¯¦é©ä¾ç ç©¶ä¸åå±¤ç´è³è¨å±äº«çæè½ãæåççµæè­å¯¦ï¼ç¶ææåº¦å¨ä¸åæºè½é«éå·®ç°è¼å¤§æï¼å°æºè½é«ç°è³ªæ§å»ºæ¨¡çæ¶çå¾å¾è¼é«ï¼èçµåæ´å¤è³è¨ä¸¦ä¸ç¸½æ¯ææ¹åæè½ã

##### **MLC-GCN: Multi-Level Generated Connectome Based GCN for AD Analysis**
2408.03358v1 by Wenqi Zhu, Yinghua Fu, Ze Wang

Alzheimer's Disease (AD) is a currently incurable neurodegeneartive disease.
Accurately detecting AD, especially in the early stage, represents a high
research priority. AD is characterized by progressive cognitive impairments
that are related to alterations in brain functional connectivity (FC). Based on
this association, many studies have been published over the decades using FC
and machine learning to differentiate AD from healthy aging. The most recent
development in this detection method highlights the use of graph neural network
(GNN) as the brain functionality analysis. In this paper, we proposed a stack
of spatio-temporal feature extraction and graph generation based AD
classification model using resting state fMRI. The proposed multi-level
generated connectome (MLC) based graph convolutional network (GCN) (MLC-GCN)
contains a multi-graph generation block and a GCN prediction block. The
multi-graph generation block consists of a hierarchy of spatio-temporal feature
extraction layers for extracting spatio-temporal rsfMRI features at different
depths and building the corresponding connectomes. The GCN prediction block
takes the learned multi-level connectomes to build and optimize GCNs at each
level and concatenates the learned graphical features as the final predicting
features for AD classification. Through independent cohort validations, MLC-GCN
shows better performance for differentiating MCI, AD, and normal aging than
state-of-art GCN and rsfMRI based AD classifiers. The proposed MLC-GCN also
showed high explainability in terms of learning clinically reasonable
connectome node and connectivity features from two independent datasets. While
we only tested MLC-GCN on AD, the basic rsfMRI-based multi-level learned GCN
based outcome prediction strategy is valid for other diseases or clinical
outcomes.

æè¦ï¼é¿è²æµ·é»ç (AD) æ¯ä¸ç¨®ç®åç¡æ³æ²»ççç¥ç¶éåæ§ç¾çã
æºç¢ºå°åµæ¸¬ ADï¼ç¹å¥æ¯å¨æ©æéæ®µï¼ä»£è¡¨ä¸é é«åº¦çç ç©¶åªåäºé ãAD çç¹å¾µæ¯æéæ¼¸èªç¥åè½åæï¼éèè¦é¨åè½é£æ¥æ§ (FC) çæ¹è®æéãåºæ¼éç¨®éè¯ï¼å¨éå»çæ¸åå¹´ä¸­ï¼è¨±å¤ç ç©¶å·²ä½¿ç¨ FC åæ©å¨å­¸ç¿ä¾åå AD åå¥åº·èåãéç¨®åµæ¸¬æ¹æ³çææ°ç¼å±ï¼çªé¡¯äºä½¿ç¨åç¥ç¶ç¶²è·¯ (GNN) ä½çºè¦é¨åè½åæãå¨æ¬æä¸­ï¼æåæåºäºä¸åå ççæç©ºç¹å¾µèåååå½¢çæï¼åºæ¼ AD åé¡æ¨¡åï¼ä½¿ç¨éæ­¢çæ fMRIãææåºçå¤å±¤ç´çæé£æ¥çµ (MLC) åºæ¼åå½¢å·ç©ç¶²è·¯ (GCN) (MLC-GCN) åå«ä¸åå¤åå½¢çæåå¡åä¸å GCN é æ¸¬åå¡ãå¤åå½¢çæåå¡åå«ä¸åæç©ºç¹å¾µèåå±¤çéå±¤ï¼ç¨æ¼èåä¸åæ·±åº¦ä¸çæç©º rsfMRI ç¹å¾µï¼ä¸¦å»ºç«å°æçé£æ¥çµãGCN é æ¸¬åå¡æ¡ç¨å·²å­¸ç¿çå¤å±¤ç´é£æ¥çµï¼å¨æ¯åå±¤ç´å»ºç«ä¸¦æä½³å GCNï¼ä¸¦å°å·²å­¸ç¿çåå½¢ç¹å¾µä¸²è¯æç¨æ¼ AD åé¡çæçµé æ¸¬ç¹å¾µãééç¨ç«çç¾¤çµé©è­ï¼MLC-GCN å¨åå MCIãAD åæ­£å¸¸èåæ¹é¢ï¼è¡¨ç¾åªæ¼æåé²ç GCN ååºæ¼ rsfMRI ç AD åé¡å¨ãææåºç MLC-GCN ä¹å¨å¾å©åç¨ç«çè³æéä¸­å­¸ç¿è¨åºä¸åççé£æ¥çµç¯é»åé£æ¥ç¹å¾µæ¹é¢ï¼è¡¨ç¾åºé«åº¦çå¯è§£éæ§ãéç¶æååªå¨ AD ä¸æ¸¬è©¦ MLC-GCNï¼ä½åºæ¬çåºæ¼ rsfMRI çå¤å±¤ç´å­¸ç¿ GCN åºæ¼çµæé æ¸¬ç­ç¥ï¼å°å¶ä»ç¾çæè¨åºçµæææã

##### **Personalizing Federated Instrument Segmentation with Visual Trait Priors in Robotic Surgery**
2408.03208v1 by Jialang Xu, Jiacheng Wang, Lequan Yu, Danail Stoyanov, Yueming Jin, Evangelos B. Mazomenos

Personalized federated learning (PFL) for surgical instrument segmentation
(SIS) is a promising approach. It enables multiple clinical sites to
collaboratively train a series of models in privacy, with each model tailored
to the individual distribution of each site. Existing PFL methods rarely
consider the personalization of multi-headed self-attention, and do not account
for appearance diversity and instrument shape similarity, both inherent in
surgical scenes. We thus propose PFedSIS, a novel PFL method with visual trait
priors for SIS, incorporating global-personalized disentanglement (GPD),
appearance-regulation personalized enhancement (APE), and shape-similarity
global enhancement (SGE), to boost SIS performance in each site. GPD represents
the first attempt at head-wise assignment for multi-headed self-attention
personalization. To preserve the unique appearance representation of each site
and gradually leverage the inter-site difference, APE introduces appearance
regulation and provides customized layer-wise aggregation solutions via
hypernetworks for each site's personalized parameters. The mutual shape
information of instruments is maintained and shared via SGE, which enhances the
cross-style shape consistency on the image level and computes the
shape-similarity contribution of each site on the prediction level for updating
the global parameters. PFedSIS outperforms state-of-the-art methods with +1.51%
Dice, +2.11% IoU, -2.79 ASSD, -15.55 HD95 performance gains. The corresponding
code and models will be released at https://github.com/wzjialang/PFedSIS.

æè¦ï¼<paragraph>éå°æè¡å¨æ¢°åå²ï¼SISï¼çåäººåè¯é¦å­¸ç¿ï¼PFLï¼æ¯ä¸ç¨®æåæ¯çæ¹æ³ãå®è®å¤åè¨åºå°é»è½å¤ å¨é±ç§çæ¢ä»¶ä¸å±åè¨ç·´ä¸ç³»åæ¨¡åï¼æ¯åæ¨¡åé½æ ¹ææ¯åå°é»çåå¥åä½é²è¡èª¿æ´ãç¾æç PFL æ¹æ³å¾å°èæ®å¤é ­èªææ³¨æåçåäººåï¼èä¸æ²æèæ®å¤è§çå¤æ¨£æ§åå¨æ¢°å½¢ççç¸ä¼¼æ§ï¼éå©èé½å­å¨æ¼æè¡å ´æ¯ä¸­ãå æ­¤ï¼æåæåºäº PFedSISï¼éæ¯ä¸ç¨®å·æè¦è¦ºç¹å¾µåé©ç SIS çæ°å PFL æ¹æ³ï¼å®çµåäºå¨å±åæ§åè§£ç³¾çºï¼GPDï¼ãå¤è§èª¿ç¯åæ§åå¢å¼·ï¼APEï¼åå½¢çç¸ä¼¼æ§å¨å±å¢å¼·ï¼SGEï¼ï¼ä»¥æåæ¯åå°é»ç SIS æè½ãGPD ä»£è¡¨äºéå°å¤é ­èªææ³¨æååæ§åé²è¡é ­é¨åéçé¦æ¬¡åè©¦ãçºäºä¿çæ¯åå°é»çç¨ç¹å¤è§è¡¨ç¤ºä¸¦éæ¼¸å©ç¨å°é»éçå·®ç°ï¼APE å¼å¥äºå¤è§èª¿ç¯ï¼ä¸¦ééè¶ç¶²è·¯çºæ¯åå°é»çåæ§ååæ¸æä¾èªè¨çéå±¤èåè§£æ±ºæ¹æ¡ãå¨æ¢°çç¸äºå½¢çè³è¨éé SGE é²è¡ç¶­è­·åå±äº«ï¼éå¢å¼·äºå½±åå±¤ç´ä¸çè·¨é¢¨æ ¼å½¢çä¸è´æ§ï¼ä¸¦è¨ç®æ¯åå°é»å¨é æ¸¬å±¤ç´ä¸çå½¢çç¸ä¼¼æ§è²¢ç»ï¼ä»¥æ´æ°å¨å±åæ¸ãPFedSIS å¨éª°å­ç³»æ¸ä¸åªæ¼ç¾ææåé²çæ¹æ³ï¼åå¥æåäº +1.51%ãIoU æåäº +2.11%ãASSD éä½äº -2.79ãHD95 æè½æåäº -15.55ãå°æçç¨å¼ç¢¼åæ¨¡åå°å¨ https://github.com/wzjialang/PFedSIS ä¸ç¼å¸ã</paragraph>

##### **The Use of Large Language Models (LLM) for Cyber Threat Intelligence (CTI) in Cybercrime Forums**
2408.03354v2 by Vanessa Clairoux-Trepanier, Isa-May Beauchamp, Estelle Ruellan, Masarah Paquet-Clouston, Serge-Olivier Paquette, Eric Clay

Large language models (LLMs) can be used to analyze cyber threat intelligence
(CTI) data from cybercrime forums, which contain extensive information and key
discussions about emerging cyber threats. However, to date, the level of
accuracy and efficiency of LLMs for such critical tasks has yet to be
thoroughly evaluated. Hence, this study assesses the accuracy of an LLM system
built on the OpenAI GPT-3.5-turbo model [7] to extract CTI information. To do
so, a random sample of 500 daily conversations from three cybercrime forums,
XSS, Exploit_in, and RAMP, was extracted, and the LLM system was instructed to
summarize the conversations and code 10 key CTI variables, such as whether a
large organization and/or a critical infrastructure is being targeted. Then,
two coders reviewed each conversation and evaluated whether the information
extracted by the LLM was accurate. The LLM system performed strikingly well,
with an average accuracy score of 98%. Various ways to enhance the model were
uncovered, such as the need to help the LLM distinguish between stories and
past events, as well as being careful with verb tenses in prompts.
Nevertheless, the results of this study highlight the efficiency and relevance
of using LLMs for cyber threat intelligence.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¯ç¨æ¼åæç¶²è·¯ç¯ç½ªè«å£ä¸­çç¶²è·¯å¨èæå ± (CTI) è³æï¼å¶ä¸­åå«æéæ°èç¶²è·¯å¨èçè±å¯è³è¨åééµè¨è«ãç¶èï¼å°ç®åçºæ­¢ï¼LLM å°æ­¤é¡ééµä»»åçæºç¢ºæ§åæçå°æªå¾å°å¾¹åºè©ä¼°ãå æ­¤ï¼æ¬ç ç©¶è©ä¼°äºå»ºç«å¨ OpenAI GPT-3.5-turbo æ¨¡å [7] ä¸ç LLM ç³»çµ±æå CTI è³è¨çæºç¢ºæ§ãçºæ­¤ï¼å¾ä¸åç¶²è·¯ç¯ç½ªè«å£ XSSãExploit_in å RAMP ä¸­é¨æ©æ½åäº 500 åæ¯æ¥å°è©±ï¼ä¸¦æç¤º LLM ç³»çµ±ç¸½çµå°è©±ä¸¦ç·¨ç¢¼ 10 åééµ CTI è®æ¸ï¼ä¾å¦æ¯å¦éå°å¤§åçµç¹å/æééµåºç¤è¨­æ½ãç¶å¾ï¼å©åç·¨ç¢¼å¨æª¢é±æ¯åå°è©±ä¸¦è©ä¼° LLM æåçè³è¨æ¯å¦æºç¢ºãLLM ç³»çµ±è¡¨ç¾åºè²ï¼å¹³åæºç¢ºåº¦åæ¸çº 98%ãç¼ç¾äºå¢å¼·æ¨¡åçåç¨®æ¹æ³ï¼ä¾å¦éè¦å¹«å© LLM ååæäºåéå»äºä»¶ï¼ä»¥åå¨æç¤ºä¸­å°å¿ä½¿ç¨ææãåç®¡å¦æ­¤ï¼æ¬ç ç©¶ççµæçªé¡¯äºä½¿ç¨ LLM é²è¡ç¶²è·¯å¨èæå ±çæçåç¸éæ§ã

##### **VizECGNet: Visual ECG Image Network for Cardiovascular Diseases Classification with Multi-Modal Training and Knowledge Distillation**
2408.02888v1 by Ju-Hyeon Nam, Seo-Hyung Park, Su Jung Kim, Sang-Chul Lee

An electrocardiogram (ECG) captures the heart's electrical signal to assess
various heart conditions. In practice, ECG data is stored as either digitized
signals or printed images. Despite the emergence of numerous deep learning
models for digitized signals, many hospitals prefer image storage due to cost
considerations. Recognizing the unavailability of raw ECG signals in many
clinical settings, we propose VizECGNet, which uses only printed ECG graphics
to determine the prognosis of multiple cardiovascular diseases. During
training, cross-modal attention modules (CMAM) are used to integrate
information from two modalities - image and signal, while self-modality
attention modules (SMAM) capture inherent long-range dependencies in ECG data
of each modality. Additionally, we utilize knowledge distillation to improve
the similarity between two distinct predictions from each modality stream. This
innovative multi-modal deep learning architecture enables the utilization of
only ECG images during inference. VizECGNet with image input achieves higher
performance in precision, recall, and F1-Score compared to signal-based ECG
classification models, with improvements of 3.50%, 8.21%, and 7.38%,
respectively.

æè¦ï¼å¿é»å (ECG) å¯æ·åå¿èçé»æ°£è¨èï¼ç¨æ¼è©ä¼°åç¨®å¿èç¾çãå¯¦éä¸ï¼å¿é»åè³æå²å­å¨æ¸ä½åè¨èæåå°å½±åä¸­ãåç®¡å·²åºç¾è¨±å¤éå°æ¸ä½åè¨èçæ·±åº¦å­¸ç¿æ¨¡åï¼ä½è¨±å¤é«é¢åºæ¼ææ¬èéï¼ä»åå¥½å½±åå²å­ãéæ¼è¨±å¤è¨åºç°å¢ä¸­ç¼ºä¹åå§å¿é»åè¨èï¼æåæåº VizECGNetï¼å®åä½¿ç¨åå°çå¿é»ååå½¢ä¾å¤æ·å¤ç¨®å¿è¡ç®¡ç¾ççé å¾ãå¨è¨ç·´æéï¼è·¨æ¨¡ææ³¨æåæ¨¡çµ (CMAM) ç¨æ¼æ´åä¾èªå©ç¨®æ¨¡æï¼å½±ååè¨èï¼çè³è¨ï¼èèªææ¨¡ææ³¨æåæ¨¡çµ (SMAM) åæ·åæ¯åæ¨¡æä¸­å¿é»åè³æä¸­åºæçé·ç¨ä¾è³´æ§ãæ­¤å¤ï¼æåå©ç¨ç¥è­èåä¾æ¹åæ¯åæ¨¡æä¸²æµä¸­å©åä¸åé æ¸¬ä¹éçç¸ä¼¼æ§ãéç¨®åµæ°çå¤æ¨¡ææ·±åº¦å­¸ç¿æ¶æ§ï¼å¯ä»¥å¨æ¨è«æéåä½¿ç¨å¿é»åå½±åãèåºæ¼è¨èçå¿é»ååé¡æ¨¡åç¸æ¯ï¼è¼¸å¥å½±åç VizECGNet å¨ç²¾æºåº¦ãå¬åçå F1 åæ¸æ¹é¢ç²å¾æ´é«çæè½ï¼åå¥æåäº 3.50%ã8.21% å 7.38%ã

##### **VisionUnite: A Vision-Language Foundation Model for Ophthalmology Enhanced with Clinical Knowledge**
2408.02865v1 by Zihan Li, Diping Song, Zefeng Yang, Deming Wang, Fei Li, Xiulan Zhang, Paul E. Kinahan, Yu Qiao

The need for improved diagnostic methods in ophthalmology is acute,
especially in the less developed regions with limited access to specialists and
advanced equipment. Therefore, we introduce VisionUnite, a novel
vision-language foundation model for ophthalmology enhanced with clinical
knowledge. VisionUnite has been pretrained on an extensive dataset comprising
1.24 million image-text pairs, and further refined using our proposed MMFundus
dataset, which includes 296,379 high-quality fundus image-text pairs and
889,137 simulated doctor-patient dialogue instances. Our experiments indicate
that VisionUnite outperforms existing generative foundation models such as
GPT-4V and Gemini Pro. It also demonstrates diagnostic capabilities comparable
to junior ophthalmologists. VisionUnite performs well in various clinical
scenarios including open-ended multi-disease diagnosis, clinical explanation,
and patient interaction, making it a highly versatile tool for initial
ophthalmic disease screening. VisionUnite can also serve as an educational aid
for junior ophthalmologists, accelerating their acquisition of knowledge
regarding both common and rare ophthalmic conditions. VisionUnite represents a
significant advancement in ophthalmology, with broad implications for
diagnostics, medical education, and understanding of disease mechanisms.

æè¦ï¼ç¼ç§è¨ºæ·æ¹æ³æ¹è¯çå¿è¦æ§ååè¿«åï¼ç¹å¥æ¯å¨è¼ä¸ç¼éå°åï¼é£è£¡å°ç§é«å¸«ååé²è¨­ååå¾ä¸æãå æ­¤ï¼æåå¼é² VisionUniteï¼ä¸ç¨®æ°ç©çè¦è¦ºèªè¨åºç¤æ¨¡åï¼ä¸¦ä»¥è¨åºç¥è­å¼·åç¼ç§ãVisionUnite å·²å¨åå« 124 è¬å¼µå½±åæå­å°çå¤§åè³æéä¸é²è¡é è¨ç·´ï¼ä¸¦ééæåå»ºè­°ç MMFundus è³æéé²ä¸æ­¥åªåï¼å¶ä¸­åå« 296,379 å¼µé«åè³ªç¼åºå½±åæå­å°å 889,137 åæ¨¡æ¬çé«å¸«çæ£å°è©±å¯¦ä¾ãæåçå¯¦é©æåº VisionUnite åªæ¼ç¾æççæå¼åºç¤æ¨¡åï¼ä¾å¦ GPT-4V å Gemini Proãå®ä¹å±ç¾åºèåéç¼ç§é«å¸«ç¸ç¶çè¨ºæ·è½åãVisionUnite å¨åç¨®è¨åºæå¢ä¸­è¡¨ç¾è¯å¥½ï¼åæ¬éæ¾å¼å¤ç¾çè¨ºæ·ãè¨åºèªªæåçæ£äºåï¼ä½¿å¶æçºåæ­¥ç¼ç§ç¾çç¯©æª¢çé«åº¦å¤åè½å·¥å·ãVisionUnite ä¹å¯ç¨ä½åéç¼ç§é«å¸«çæè²è¼å©å·¥å·ï¼å éä»åå°æ¼å¸¸è¦åç½è¦ç¼ç§ç¾çç¥è­çç¿å¾ãVisionUnite ä»£è¡¨äºç¼ç§çéå¤§é²å±ï¼å°è¨ºæ·ãé«å­¸æè²åç¾çæ©è½ççè§£å·æå»£æ³çå½±é¿ã

##### **Multistain Pretraining for Slide Representation Learning in Pathology**
2408.02859v1 by Guillaume Jaume, Anurag Vaidya, Andrew Zhang, Andrew H. Song, Richard J. Chen, Sharifa Sahai, Dandan Mo, Emilio Madrigal, Long Phi Le, Faisal Mahmood

Developing self-supervised learning (SSL) models that can learn universal and
transferable representations of H&E gigapixel whole-slide images (WSIs) is
becoming increasingly valuable in computational pathology. These models hold
the potential to advance critical tasks such as few-shot classification, slide
retrieval, and patient stratification. Existing approaches for slide
representation learning extend the principles of SSL from small images (e.g.,
224 x 224 patches) to entire slides, usually by aligning two different
augmentations (or views) of the slide. Yet the resulting representation remains
constrained by the limited clinical and biological diversity of the views.
Instead, we postulate that slides stained with multiple markers, such as
immunohistochemistry, can be used as different views to form a rich
task-agnostic training signal. To this end, we introduce Madeleine, a
multimodal pretraining strategy for slide representation learning. Madeleine is
trained with a dual global-local cross-stain alignment objective on large
cohorts of breast cancer samples (N=4,211 WSIs across five stains) and kidney
transplant samples (N=12,070 WSIs across four stains). We demonstrate the
quality of slide representations learned by Madeleine on various downstream
evaluations, ranging from morphological and molecular classification to
prognostic prediction, comprising 21 tasks using 7,299 WSIs from multiple
medical centers. Code is available at https://github.com/mahmoodlab/MADELEINE.

æè¦ï¼éç¼èªç£ç£å­¸ç¿ (SSL) æ¨¡åï¼å¯ä»¥å­¸ç¿ H&E ååç´ å¨åçå½±å (WSI) çéç¨ä¸å¯è½ç§»è¡¨ç¤ºï¼å¨è¨ç®ççå­¸ä¸­æ­£è®å¾è¶ä¾è¶æå¹å¼ãéäºæ¨¡åææ½åæ¨é²ééµä»»åï¼ä¾å¦å°æ¬¡åé¡ãåçæª¢ç´¢åæ£èåå±¤ãç¾æçåçè¡¨ç¤ºå­¸ç¿æ¹æ³å° SSL çåçå¾å°å½±åï¼ä¾å¦ 224 x 224 è£ä¸ï¼å»¶ä¼¸å°æ´ååçï¼éå¸¸ééå°é½åççå©åä¸åæ´å¢ï¼æè¦åï¼ãç¶èï¼çæçè¡¨ç¤ºä»åå°è¦åæéçè¨åºåçç©å¤æ¨£æ§çéå¶ãç¸åï¼æååè¨­ä½¿ç¨å¤ç¨®æ¨è¨æè²çåçï¼ä¾å¦åç«çµç¹åå­¸æè²ï¼å¯ä»¥ç¨ä½ä¸åçè¦åä¾å½¢æè±å¯çèä»»åç¡éçè¨ç·´è¨èãçºæ­¤ï¼æåä»ç´¹ Madeleineï¼ä¸ç¨®ç¨æ¼åçè¡¨ç¤ºå­¸ç¿çå¤æ¨¡å¼é è¨ç·´ç­ç¥ãMadeleine ä½¿ç¨ééå¨å±-å±é¨è·¨æè²å°é½ç®æ¨å¨å¤§éä¹³çæ¨£æ¬ï¼N=4,211 åæ©«è·¨äºç¨®æè²ç WSIï¼åèèç§»æ¤æ¨£æ¬ï¼N=12,070 åæ©«è·¨åç¨®æè²ç WSIï¼ä¸é²è¡è¨ç·´ãæåå¨åç¨®ä¸æ¸¸è©ä¼°ä¸­å±ç¤ºäº Madeleine å­¸ç¿çåçè¡¨ç¤ºçåè³ªï¼å¾å½¢æååå­åé¡å°é å¾é æ¸¬ï¼åæ¬ä½¿ç¨ä¾èªå¤åé«çä¸­å¿ç 7,299 å WSI ç 21 é ä»»åãç¨å¼ç¢¼å¯å¨ https://github.com/mahmoodlab/MADELEINE åå¾ã

##### **A Review on Organ Deformation Modeling Approaches for Reliable Surgical Navigation using Augmented Reality**
2408.02713v1 by Zheng Han, Qi Dou

Augmented Reality (AR) holds the potential to revolutionize surgical
procedures by allowing surgeons to visualize critical structures within the
patient's body. This is achieved through superimposing preoperative organ
models onto the actual anatomy. Challenges arise from dynamic deformations of
organs during surgery, making preoperative models inadequate for faithfully
representing intraoperative anatomy. To enable reliable navigation in augmented
surgery, modeling of intraoperative deformation to obtain an accurate alignment
of the preoperative organ model with the intraoperative anatomy is
indispensable. Despite the existence of various methods proposed to model
intraoperative organ deformation, there are still few literature reviews that
systematically categorize and summarize these approaches. This review aims to
fill this gap by providing a comprehensive and technical-oriented overview of
modeling methods for intraoperative organ deformation in augmented reality in
surgery. Through a systematic search and screening process, 112 closely
relevant papers were included in this review. By presenting the current status
of organ deformation modeling methods and their clinical applications, this
review seeks to enhance the understanding of organ deformation modeling in
AR-guided surgery, and discuss the potential topics for future advancements.

æè¦ï¼æ´å¢å¯¦å¢ (AR) å·æééè®å¤ç§é«çå¯è¦åæ£èé«å§ééµçµæ§ä¾é©æ°å¤ç§æè¡ç¨åºçæ½åãéæ¯ééå°è¡åå¨å®æ¨¡åçå å°å¯¦éè§£åçµæ§ä¸ä¾å¯¦ç¾çãæè¡éç¨ä¸­å¨å®çåæè®å½¢å¸¶ä¾äºææ°ï¼éä½¿å¾è¡åæ¨¡åä¸è¶³ä»¥å¿ å¯¦å°åç¾è¡ä¸­è§£åçµæ§ãçºäºå¨æ´å¢æè¡ä¸­å¯¦ç¾å¯é çå°èªï¼å°è¡ä¸­è®å½¢é²è¡å»ºæ¨¡ä»¥ç²å¾è¡åå¨å®æ¨¡åèè¡ä¸­è§£åçµæ§çæºç¢ºå°é½æ¯ä¸å¯æç¼ºçãåç®¡å­å¨åç¨®ç¨æ¼å»ºæ¨¡è¡ä¸­å¨å®è®å½¢çæ¹æ³ï¼ä½ç³»çµ±å°å°éäºæ¹æ³é²è¡åé¡åç¸½çµçæç»åé¡§ä»ç¶å¾å°ãæ¬ç¶è¿°æ¨å¨ééæä¾å°æ´å¢å¯¦å¢æè¡ä¸­è¡ä¸­å¨å®è®å½¢çå»ºæ¨¡æ¹æ³çå¨é¢ä¸æè¡å°åçæ¦è¿°ä¾å¡«è£éä¸ç©ºç½ãééç³»çµ±çæå°åç¯©é¸éç¨ï¼æ¬ç¶è¿°ç´å¥äº 112 ç¯å¯åç¸éçè«æãééåç¾å¨å®è®å½¢å»ºæ¨¡æ¹æ³çç¾çåå¶è¨åºæç¨ï¼æ¬ç¶è¿°æ¨å¨å æ·±å° AR å¼å°æè¡ä¸­å¨å®è®å½¢å»ºæ¨¡ççè§£ï¼ä¸¦æ¢è¨æªä¾é²å±çæ½å¨ä¸»é¡ã

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

æè¦ï¼æ¬ç ç©¶ä½¿ç¨çå­å­¸æ¡æ¶åææ··åäººå·¥æºæ§ç³»çµ±çè¨­è¨æ¨¡å¼åå¶å¨è¨åºæ±ºç­ä¸­çæææ§ãå®åé¡ä¸¦æ¯è¼çµåæ©å¨å­¸ç¿ååºæ¼è¦åçæ¨ççåç¨®æ¶æ§ï¼ä»¥æ·±å¥äºè§£å¶çµæ§åºç¤åé«çä¿å¥æç¨ãéå°å©åä¸»è¦åé¡ï¼å¦ä½æ ¹ææ¢å®çè¨­è¨æ¨¡å¼å°éäºç³»çµ±é²è¡åé¡ï¼ä»¥åå¦ä½ééæ¯è¼åææåè¦è§£ï¼æ¬ç ç©¶ä½¿ç¨è»é«å·¥ç¨ä¸­çè¨­è¨æ¨¡å¼ä¾äºè§£ååªåé«çä¿å¥äººå·¥æºæ§ç³»çµ±ãçå­å­¸æå©æ¼è­å¥å±æ§ä¸¦å»ºç«å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡ï¼å¾èå¢å¼·éäºç³»çµ±çå¯æ´åæ§ãå¯é æ§åæè½ãæª¢æ¥äºäºç¨®ä¸»è¦çæ¶æ§ï¼REMLãMLRBãRBMLãRMLT å PERMLãæ¯ç¨®æ¶æ§é½æç¨ç¹çåªç¼ºé»ï¼å¼·èª¿äºå¨è¨åºä»»åä¸­éè¦éèº«æé çæ¹æ³ãREML å¨è³ææéçè³æéä¸­è¡¨ç¾åºé«ç²¾åº¦çé æ¸¬ï¼MLRB å¨èçå¤§åè³æéåè¤éè³ææ´åæ¹é¢è¡¨ç¾åºè²ï¼RBML å¨å¯è§£éæ§åå¯ä¿¡åº¦æ¹é¢è¡¨ç¾åºè²ï¼RMLT å¨ç®¡çé«ç¶­è³ææ¹é¢è¡¨ç¾åºè²ï¼è PERML åç®¡å¨åææ¹é¢æéï¼ä½å¨ç·æ¥ç§è­·å ´æ¯ä¸­è¡¨ç¾åºæ½åãæ¬ç ç©¶å¼å¥äºåç¨®æ°æ¨¡å¼ï¼å»ºç«äºäºç¨®æ½è±¡åé¡æ¨¡å¼ï¼ä¸¦é²ä¸æ­¥å°éäºç¨®æ¨¡å¼ç´°åçºå·é«çç³»çµ±ãéäºè²¢ç»å¢å¼·äºçå­å­¸çåé¡çµç¹ï¼ä¸¦æä¾äºå°å°å®¶ç¥è­èæ©å¨å­¸ç¿æ´åçæ°æ¹æ³ãçå­å­¸ççµæ§åãæ¨¡çµåæ¹æ³å¨éç¼ååææ··åäººå·¥æºæ§ç³»çµ±ãæ­ç¤ºå±æ§ä»¥åæ¨å»£å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡æ¹é¢å·æé¡¯èåªå¢ãç¸½ä¹ï¼æ¬ç ç©¶å¼·èª¿äºæ··åäººå·¥æºæ§ç³»çµ±å¨æ¨é²é«çä¿å¥ä¸­çééµä½ç¨ï¼ä»¥åçå­å­¸å¨æ¨åäººå·¥æºæ§æ´åé²ä¸æ­¥åµæ°æ¹é¢çæ½åï¼æçµæ¹åè¨åºæ±ºç­æ¯æ´åæ£èçæ²»çææã

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

æè¦ï¼ç±æ¼å¶å¼·å¤§çé æ¸¬è½åï¼æ·±åº¦å­¸ç¿å·²æçºè¨±å¤ç¢æ¥­ä¸­ä¸å¯æç¼ºçå·¥å·ï¼åæ¬é«çä¿å¥ãç¶èï¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åéå¸¸ç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸å¿½ç¥äºå°é æ¸¬ä¸ç¢ºå®æ§ç´å¥èéï¼èéå©åå ç´ æ¯è¨åºæ±ºç­å¶å®çééµçµæé¨åãçºäºç¢çå¯è§£éä¸å·æä¸ç¢ºå®æ§æè­çé æ¸¬ï¼æ¬ç ç©¶æåºäºä¸ååçºè²æ°æ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯ (BKAN) çæ°æ¶æ§ï¼å®çµåäºæ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯çè¡¨éè½åèè²æ°æ¨è«ãæåå¨å©åé«å­¸è³æéä¸ä½¿ç¨ BKANï¼éäºè³æéæ¯è©ä¼°æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸è¨ºæ·ä¸­çå»£æ³ä½¿ç¨åºæºï¼ç®é¦¬å°ç¬¬å®äººç³å°¿çè³æéååéå¤«è­å¿èçè³æéãæåçæ¨¡åæä¾äºå°é æ¸¬ä¿¡å¿åæ±ºç­éççæçè¦è§£ï¼ä¸¦ä¸å¨é æ¸¬æºç¢ºåº¦æ¹é¢åªæ¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åãæ­¤å¤ï¼BKAN è¡¨ç¾é¨æ©åèªè­ä¸ç¢ºå®æ§çè½åï¼å¯ç¢ºä¿é«çç²å¾æ´å¯é ä¸å¼å¾ä¿¡è³´çæ±ºç­æ¯æ´ãæ ¹æå¯¦é©çµæï¼æåçè²æ°ç­ç¥æé«äºæ¨¡åçå¯è§£éæ§ï¼ä¸¦å¤§å¹æ¸å°äºéåº¦æ¬åï¼éå°æ¼å°åä¸ä¸å¹³è¡¡çé«å­¸è³æééå¸¸éè¦ãæåæåºäºå¯è½çæ´ååè½ï¼ä»¥é²ä¸æ­¥å° BKAN ç¨æ¼æ´è¤éçå¤æ¨¡å¼è³æéï¼ä¸¦æ¢è¨éäºç¼ç¾å°æ¼æªä¾å»ºç«å¯é çé«çä¿å¥ AI ç³»çµ±ç ç©¶çéè¦æ§ãéé å·¥ä½çºæ·±åº¦å­¸ç¿æ¨¡åé¨ç½²å¨éæåº¦åå¯é æ§è³ééè¦çéè¦é åä¸­éåäºä¸åæ°çå¸ç¯ã

##### **Active Sensing of Knee Osteoarthritis Progression with Reinforcement Learning**
2408.02349v1 by Khanh Nguyen, Huy Hoang Nguyen, Egor Panfilov, Aleksei Tiulpin

Osteoarthritis (OA) is the most common musculoskeletal disease, which has no
cure. Knee OA (KOA) is one of the highest causes of disability worldwide, and
it costs billions of United States dollars to the global community. Prediction
of KOA progression has been of high interest to the community for years, as it
can advance treatment development through more efficient clinical trials and
improve patient outcomes through more efficient healthcare utilization.
Existing approaches for predicting KOA, however, are predominantly static, i.e.
consider data from a single time point to predict progression many years into
the future, and knee level, i.e. consider progression in a single joint only.
Due to these and related reasons, these methods fail to deliver the level of
predictive performance, which is sufficient to result in cost savings and
better patient outcomes. Collecting extensive data from all patients on a
regular basis could address the issue, but it is limited by the high cost at a
population level. In this work, we propose to go beyond static prediction
models in OA, and bring a novel Active Sensing (AS) approach, designed to
dynamically follow up patients with the objective of maximizing the number of
informative data acquisitions, while minimizing their total cost over a period
of time. Our approach is based on Reinforcement Learning (RL), and it leverages
a novel reward function designed specifically for AS of disease progression in
more than one part of a human body. Our method is end-to-end, relies on
multi-modal Deep Learning, and requires no human input at inference time.
Throughout an exhaustive experimental evaluation, we show that using RL can
provide a higher monetary benefit when compared to state-of-the-art baselines.

æè¦ï¼éª¨éç¯ç (OA) æ¯ä¸ç¨®æå¸¸è¦çèèéª¨éª¼ç¾çï¼ç®åå°ç¡è¥å¯é«ãèéç¯éª¨éç¯ç (KOA) æ¯å¨çæ®ç¾çé¦è¦åå ä¹ä¸ï¼ä¸¦ä½¿å¨çç¤¾ææå¤±æ¸ååç¾åãå¤å¹´ä¾ï¼é æ¸¬ KOA çé²å±ä¸ç´æ¯ç¤¾æéæ³¨çéé»ï¼å çºå®å¯ä»¥ééæ´ææçè¨åºè©¦é©æ¨é²æ²»ççç¼å±ï¼ä¸¦ééæ´ææççé«çä¿å¥å©ç¨ä¾æ¹åæ£èçé å¾ãç¶èï¼ç¾æç KOA é æ¸¬æ¹æ³ä¸»è¦é½æ¯éæçï¼ä¹å°±æ¯èªªï¼åèæ®å®ä¸æéé»çæ¸æä¾é æ¸¬æªä¾å¤å¹´çé²å±ï¼èä¸æ¯èèå±¤é¢çï¼ä¹å°±æ¯èªªï¼åèæ®å®ä¸éç¯çé²å±ãç±æ¼éäºåå åå¶ä»ç¸éåå ï¼éäºæ¹æ³ç¡æ³æä¾è¶³å¤ çé æ¸¬æè½ï¼ä»¥è´æ¼ç¡æ³ç¯çææ¬ä¸¦æ¹åæ£èçé å¾ãå®æå¾æææ£èèº«ä¸æ¶éå»£æ³çæ¸æå¯ä»¥è§£æ±ºéååé¡ï¼ä½éæåå°äººå£å±¤ç´çé«ææ¬æéå¶ãå¨éé å·¥ä½ä¸­ï¼æåå»ºè­°è¶è¶ OA ä¸­çéæé æ¸¬æ¨¡åï¼ä¸¦æåºä¸ååµæ°çä¸»åææ¸¬ (AS) æ¹æ³ï¼æ¨å¨åæè¿½è¹¤æ£èï¼ç®æ¨æ¯æå¤§åå·æè³è¨æ§çæ¸ææ·åæ¬¡æ¸ï¼åæå¨ä¸æ®µæéå§å°å¶ç¸½ææ¬éè³æä½ãæåçåæ³æ¯åºæ¼å¼·åå­¸ç¿ (RL)ï¼ä¸¦å©ç¨å°éçºäººé¡èº«é«å¤åé¨ä½çç¾çé²å±ç AS æè¨­è¨çæ°ååé¥å½æ¸ãæåçåæ³æ¯ç«¯å°ç«¯çï¼ä¾è³´æ¼å¤æ¨¡ææ·±åº¦å­¸ç¿ï¼ä¸¦ä¸å¨æ¨è«æéä¸éè¦äººå·¥è¼¸å¥ãå¨è©³ç¡çå¯¦é©è©ä¼°ä¸­ï¼æåè¡¨æèæåé²çåºæºç¸æ¯ï¼ä½¿ç¨ RL å¯ä»¥æä¾æ´é«çéé¢æçã

##### **MetaWearS: A Shortcut in Wearable Systems Lifecycle with Only a Few Shots**
2408.01988v1 by Alireza Amirshahi, Maedeh H. Toosi, Siamak Mohammadi, Stefano Albini, Pasquale Davide Schiavone, Giovanni Ansaloni, Amir Aminifar, David Atienza

Wearable systems provide continuous health monitoring and can lead to early
detection of potential health issues. However, the lifecycle of wearable
systems faces several challenges. First, effective model training for new
wearable devices requires substantial labeled data from various subjects
collected directly by the wearable. Second, subsequent model updates require
further extensive labeled data for retraining. Finally, frequent model updating
on the wearable device can decrease the battery life in long-term data
monitoring. Addressing these challenges, in this paper, we propose MetaWearS, a
meta-learning method to reduce the amount of initial data collection required.
Moreover, our approach incorporates a prototypical updating mechanism,
simplifying the update process by modifying the class prototype rather than
retraining the entire model. We explore the performance of MetaWearS in two
case studies, namely, the detection of epileptic seizures and the detection of
atrial fibrillation. We show that by fine-tuning with just a few samples, we
achieve 70% and 82% AUC for the detection of epileptic seizures and the
detection of atrial fibrillation, respectively. Compared to a conventional
approach, our proposed method performs better with up to 45% AUC. Furthermore,
updating the model with only 16 minutes of additional labeled data increases
the AUC by up to 5.3%. Finally, MetaWearS reduces the energy consumption for
model updates by 456x and 418x for epileptic seizure and AF detection,
respectively.

æè¦ï¼<paragraph>ç©¿æ´å¼ç³»çµ±æä¾æçºçå¥åº·ç£æ¸¬ï¼ä¸¦å¯åæ©åµæ¸¬æ½å¨çå¥åº·åé¡ãç¶èï¼ç©¿æ´å¼ç³»çµ±ççå½é±æé¢è¨å¹¾åææ°ãé¦åï¼æ°ç©¿æ´å¼è£ç½®çæææ¨¡åè¨ç·´éè¦å¾åç¨®åè©¦èæ¶éçå¤§éæ¨ç±¤è³æï¼ä¸è³æå¿é ç´æ¥ç±ç©¿æ´å¼è£ç½®æ¶éãå¶æ¬¡ï¼å¾çºçæ¨¡åæ´æ°éè¦é²ä¸æ­¥çå¤§éæ¨ç±¤è³ææè½éæ°è¨ç·´ãæå¾ï¼ç©¿æ´å¼è£ç½®ä¸é »ç¹çæ¨¡åæ´æ°æç¸®ç­é·æè³æç£æ¸¬çé»æ± çºèªåãçºäºæå°éäºææ°ï¼æåå¨æ¬æä¸­æåº MetaWearSï¼éæ¯ä¸ç¨®åå­¸ç¿æ¹æ³ï¼å¯æ¸å°æéçåå§è³ææ¶ééãæ­¤å¤ï¼æåçæ¹æ³çµåäºä¸åååæ´æ°æ©å¶ï¼ééä¿®æ¹é¡å¥ååèééæ°è¨ç·´æ´åæ¨¡åä¾ç°¡åæ´æ°éç¨ãæåå¨å©åæ¡ä¾ç ç©¶ä¸­æ¢è¨ MetaWearS çæè½ï¼åå¥æ¯ç²çç¼ä½åµæ¸¬åå¿æ¿é¡«ååµæ¸¬ãæåå±ç¤ºäºééå¾®èª¿åå°æ¸æ¨£æ¬ï¼æååå¥å¨ç²çç¼ä½åµæ¸¬åå¿æ¿é¡«ååµæ¸¬ä¸­éå° 70% å 82% ç AUCãèå³çµ±æ¹æ³ç¸æ¯ï¼æåæåºçæ¹æ³è¡¨ç¾æ´å¥½ï¼AUC æé«å¯é 45%ãæ­¤å¤ï¼åä½¿ç¨ 16 åéçé¡å¤æ¨ç±¤è³ææ´æ°æ¨¡åï¼å³å¯å° AUC æé«å¤é 5.3%ãæå¾ï¼MetaWearS åå¥å°ç²çç¼ä½åå¿æ¿é¡«ååµæ¸¬çæ¨¡åæ´æ°è½èéä½äº 456 åå 418 åã</paragraph>

##### **DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models**
2408.01933v2 by Bowen Wang, Jiuyang Chang, Yiming Qian, Guoxin Chen, Junhao Chen, Zhouqiang Jiang, Jiahao Zhang, Yuta Nakashima, Hajime Nagahara

Large language models (LLMs) have recently showcased remarkable capabilities,
spanning a wide range of tasks and applications, including those in the medical
domain. Models like GPT-4 excel in medical question answering but may face
challenges in the lack of interpretability when handling complex tasks in real
clinical settings. We thus introduce the diagnostic reasoning dataset for
clinical notes (DiReCT), aiming at evaluating the reasoning ability and
interpretability of LLMs compared to human doctors. It contains 511 clinical
notes, each meticulously annotated by physicians, detailing the diagnostic
reasoning process from observations in a clinical note to the final diagnosis.
Additionally, a diagnostic knowledge graph is provided to offer essential
knowledge for reasoning, which may not be covered in the training data of
existing LLMs. Evaluations of leading LLMs on DiReCT bring out a significant
gap between their reasoning ability and that of human doctors, highlighting the
critical need for models that can reason effectively in real-world clinical
scenarios.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æè¿å±ç¤ºäºéå¡çè½åï¼æ¶µèå»£æ³çä»»ååæç¨ï¼åæ¬é«çé åçä»»ååæç¨ãGPT-4 ç­æ¨¡åå¨é«çåé¡è§£ç­æ¹é¢è¡¨ç¾åºè²ï¼ä½å¨èçå¯¦éè¨åºå ´æ¯ä¸­çè¤éä»»åæï¼å¯è½æé¢è¨ç¼ºä¹å¯è§£éæ§çææ°ãå æ­¤ï¼æåå¼å¥äºè¨åºç­è¨è¨ºæ·æ¨çæ¸æé (DiReCT)ï¼æ¨å¨è©ä¼° LLM èäººé¡é«çç¸æ¯çæ¨çè½ååå¯è§£éæ§ãå®åå« 511 åè¨åºç­è¨ï¼æ¯åç­è¨é½ç¶éé«çä»ç´°è¨»è§£ï¼è©³ç´°èªªæäºå¾è¨åºç­è¨ä¸­çè§å¯çµæå°æçµè¨ºæ·çè¨ºæ·æ¨çéç¨ãæ­¤å¤ï¼éæä¾äºè¨ºæ·ç¥è­åè­ï¼ä»¥æä¾æ¨çæéçåºæ¬ç¥è­ï¼éå¯è½æªæ¶µèå¨ç¾æ LLM çè¨ç·´æ¸æä¸­ãå¨ DiReCT ä¸å°é åç LLM é²è¡è©ä¼°ï¼ç¼ç¾å®åçæ¨çè½åèäººé¡é«ççæ¨çè½åä¹éå­å¨é¡¯èå·®è·ï¼éçªé¡¯äºå¨ç¾å¯¦ä¸ççè¨åºå ´æ¯ä¸­è½å¤ æææ¨ççæ¨¡åçééµéæ±ã

##### **MALADE: Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance**
2408.01869v1 by Jihye Choi, Nils Palumbo, Prasad Chalasani, Matthew M. Engelhard, Somesh Jha, Anivarya Kumar, David Page

In the era of Large Language Models (LLMs), given their remarkable text
understanding and generation abilities, there is an unprecedented opportunity
to develop new, LLM-based methods for trustworthy medical knowledge synthesis,
extraction and summarization. This paper focuses on the problem of
Pharmacovigilance (PhV), where the significance and challenges lie in
identifying Adverse Drug Events (ADEs) from diverse text sources, such as
medical literature, clinical notes, and drug labels. Unfortunately, this task
is hindered by factors including variations in the terminologies of drugs and
outcomes, and ADE descriptions often being buried in large amounts of narrative
text. We present MALADE, the first effective collaborative multi-agent system
powered by LLM with Retrieval Augmented Generation for ADE extraction from drug
label data. This technique involves augmenting a query to an LLM with relevant
information extracted from text resources, and instructing the LLM to compose a
response consistent with the augmented data. MALADE is a general LLM-agnostic
architecture, and its unique capabilities are: (1) leveraging a variety of
external sources, such as medical literature, drug labels, and FDA tools (e.g.,
OpenFDA drug information API), (2) extracting drug-outcome association in a
structured format along with the strength of the association, and (3) providing
explanations for established associations. Instantiated with GPT-4 Turbo or
GPT-4o, and FDA drug label data, MALADE demonstrates its efficacy with an Area
Under ROC Curve of 0.90 against the OMOP Ground Truth table of ADEs. Our
implementation leverages the Langroid multi-agent LLM framework and can be
found at https://github.com/jihyechoi77/malade.

æè¦ï¼å¨å¤§è¯­è¨æ¨¡å (LLM) æ¶ä»£ï¼é´äºå¶åè¶çææ¬çè§£åçæè½åï¼åºç°äºä¸ä¸ªåææªæçæºä¼ï¼å¯ä»¥å¼ååºäº LLM çæ°æ¹æ³ï¼ç¨äºå¯ä¿¡çå»å­¦ç¥è¯ç»¼åãæååæè¦ãæ¬æéç¹å³æ³¨è¯ç©è­¦æ (PhV) çé®é¢ï¼å¶éè¦æ§åææå¨äºä»åç§ææ¬æ¥æºï¼å¦å»å­¦æç®ãä¸´åºç¬è®°åè¯ç©æ ç­¾ï¼ä¸­è¯å«ä¸è¯è¯ç©äºä»¶ (ADE)ãä¸å¹¸çæ¯ï¼è¿é¡¹ä»»å¡åå°å¤ç§å ç´ çé»ç¢ï¼åæ¬è¯ç©åç»ææ¯è¯­çååï¼ä»¥å ADE æè¿°éå¸¸åæ²¡å¨å¤§éåè¿°æ§ææ¬ä¸­ãæä»¬å±ç¤ºäº MALADEï¼è¿æ¯ç¬¬ä¸ä¸ªææçåä½å¤æºè½ä½ç³»ç»ï¼ç± LLM æä¾æ¯æï¼å¹¶ä½¿ç¨æ£ç´¢å¢å¼ºçææ¥ä»è¯ç©æ ç­¾æ°æ®ä¸­æå ADEãæ­¤ææ¯æ¶åä½¿ç¨ä»ææ¬èµæºä¸­æåçç¸å³ä¿¡æ¯æ¥æ©åå¯¹ LLM çæ¥è¯¢ï¼å¹¶æç¤º LLM ç¼åä¸æ©åæ°æ®ä¸è´çååºãMALADE æ¯ä¸ç§éç¨ç LLM ä¸å¯ç¥æ¶æï¼å¶ç¬ç¹åè½åæ¬ï¼(1) å©ç¨åç§å¤é¨æ¥æºï¼ä¾å¦å»å­¦æç®ãè¯ç©æ ç­¾å FDA å·¥å·ï¼ä¾å¦ OpenFDA è¯ç©ä¿¡æ¯ APIï¼ï¼(2) ä»¥ç»æåæ ¼å¼æåè¯ç©-ç»æå³èä»¥åå³èå¼ºåº¦ï¼ä»¥å (3) ä¸ºå·²å»ºç«çå³èæä¾è§£éãMALADE ä½¿ç¨ GPT-4 Turbo æ GPT-4o ä»¥å FDA è¯ç©æ ç­¾æ°æ®å®ä¾åï¼å¹¶éè¿éå¯¹ ADE ç OMOP åºæ¬äºå®è¡¨ï¼ä»¥ 0.90 ç ROC æ²çº¿ä¸é¢ç§¯è¯æäºå¶æææ§ãæä»¬çå®ç°å©ç¨äº Langroid å¤æºè½ä½ LLM æ¡æ¶ï¼å¯ä»¥å¨ https://github.com/jihyechoi77/malade ä¸­æ¾å°ã

##### **ST-SACLF: Style Transfer Informed Self-Attention Classifier for Bias-Aware Painting Classification**
2408.01827v1 by Mridula Vijendran, Frederick W. B. Li, Jingjing Deng, Hubert P. H. Shum

Painting classification plays a vital role in organizing, finding, and
suggesting artwork for digital and classic art galleries. Existing methods
struggle with adapting knowledge from the real world to artistic images during
training, leading to poor performance when dealing with different datasets. Our
innovation lies in addressing these challenges through a two-step process.
First, we generate more data using Style Transfer with Adaptive Instance
Normalization (AdaIN), bridging the gap between diverse styles. Then, our
classifier gains a boost with feature-map adaptive spatial attention modules,
improving its understanding of artistic details. Moreover, we tackle the
problem of imbalanced class representation by dynamically adjusting augmented
samples. Through a dual-stage process involving careful hyperparameter search
and model fine-tuning, we achieve an impressive 87.24\% accuracy using the
ResNet-50 backbone over 40 training epochs. Our study explores quantitative
analyses that compare different pretrained backbones, investigates model
optimization through ablation studies, and examines how varying augmentation
levels affect model performance. Complementing this, our qualitative
experiments offer valuable insights into the model's decision-making process
using spatial attention and its ability to differentiate between easy and
challenging samples based on confidence ranking.

æè¦ï¼ç¹ªç«åé¡å¨çµç¹ãå°æ¾åå»ºè­°æ¸ä½åç¶å¸èå»çèè¡åä¸­æ®æ¼éè¦çè§è²ãç¾æçæ¹æ³å¨è¨ç·´æé£ä»¥å°ç¾å¯¦ä¸ççç¥è­é©æå°èè¡ååä¸­ï¼å°è´å¨èçä¸åè³æéææè½ä¸ä½³ãæåçåµæ°å¨æ¼ééå©æ­¥é©çç¨åºä¾è§£æ±ºéäºææ°ãé¦åï¼æåä½¿ç¨å·æèªé©æå¯¦ä¾æ­£è¦å (AdaIN) çé¢¨æ ¼è½ç§»ä¾ç¢çæ´å¤è³æï¼å½åäºä¸åé¢¨æ ¼ä¹éçå·®è·ãæ¥èï¼æåçåé¡å¨ééå·åç¹å¾µåèªé©æç©ºéæ³¨æåæ¨¡çµèç²å¾æåï¼é²èæ¹åå¶å°èè¡ç´°ç¯ççè§£ãæ­¤å¤ï¼æåééåæèª¿æ´æ´åæ¨£æ¬ä¾è§£æ±ºé¡å¥è¡¨ç¤ºä¸å¹³è¡¡çåé¡ãééä¸åæ¶åä»ç´°çè¶åæ¸æå°åæ¨¡åå¾®èª¿çééæ®µç¨åºï¼æåä½¿ç¨ ResNet-50 ä¸»å¹¹å¨è¶é 40 åè¨ç·´ææéå°äºä»¤äººå°è±¡æ·±å»ç 87.24% æºç¢ºåº¦ãæåçç ç©¶æ¢è¨äºæ¯è¼ä¸åé è¨ç·´ä¸»å¹¹çå®éåæï¼ééæ¶èç ç©¶ä¾æ¢è¨æ¨¡åæä½³åï¼ä¸¦æª¢è¦ä¸åçæ´åå±¤ç´å¦ä½å½±é¿æ¨¡åæè½ãä½çºè£åï¼æåçå®æ§å¯¦é©ééç©ºéæ³¨æåæä¾äºæå¹å¼çè¦è§£ï¼äºè§£æ¨¡åçæ±ºç­å¶å®ç¨åºï¼ä»¥åå®æ ¹æä¿¡å¿æåä¾ååå®¹æåå°é£æ¨£æ¬çè½åã

##### **Advancing Mental Health Pre-Screening: A New Custom GPT for Psychological Distress Assessment**
2408.01614v1 by Jinwen Tang, Yi Shang

This study introduces 'Psycho Analyst', a custom GPT model based on OpenAI's
GPT-4, optimized for pre-screening mental health disorders. Enhanced with
DSM-5, PHQ-8, detailed data descriptions, and extensive training data, the
model adeptly decodes nuanced linguistic indicators of mental health disorders.
It utilizes a dual-task framework that includes binary classification and a
three-stage PHQ-8 score computation involving initial assessment, detailed
breakdown, and independent assessment, showcasing refined analytic
capabilities. Validation with the DAIC-WOZ dataset reveals F1 and Macro-F1
scores of 0.929 and 0.949, respectively, along with the lowest MAE and RMSE of
2.89 and 3.69 in PHQ-8 scoring. These results highlight the model's precision
and transformative potential in enhancing public mental health support,
improving accessibility, cost-effectiveness, and serving as a second opinion
for professionals.

æè¦ï¼æ¬ç ç©¶æ¨åºäºãå¿çåæå¸«ãï¼ä¸ååºæ¼ OpenAI ç GPT-4 çèªè¨ GPT æ¨¡åï¼éå°å¿çå¥åº·éç¤çé ç¯©é¸èæä½³åãæ­¤æ¨¡åç¶é DSM-5ãPHQ-8ãè©³ç´°è³ææè¿°åå»£æ³è¨ç·´è³æçå¼·åï¼è½çç·´å°è§£ç¢¼å¿çå¥åº·éç¤çç´°å¾®èªè¨ææ¨ãå®æ¡ç¨ä¸åéä»»åæ¶æ§ï¼åæ¬äºååé¡åä¸åä¸éæ®µ PHQ-8 åæ¸è¨ç®ï¼æ¶ååæ­¥è©ä¼°ãè©³ç´°ç´°ååç¨ç«è©ä¼°ï¼å±ç¤ºäºç²¾ç·»çåæè½åãä½¿ç¨ DAIC-WOZ è³æéé²è¡é©è­ï¼F1 åå·¨é F1 åæ¸åå¥çº 0.929 å 0.949ï¼PHQ-8 è©åä¸­ç MAE å RMSE æä½ï¼åå¥çº 2.89 å 3.69ãéäºçµæçªé¡¯äºæ­¤æ¨¡åå¨æåå¬ç¾å¿çå¥åº·æ¯æãæ¹åå¯åæ§ãææ¬æçï¼ä»¥åä½çºå°æ¥­äººå£«çç¬¬äºæè¦æ¹é¢çç²¾æºåº¦åè®é©æ½åã

##### **Conformal Diffusion Models for Individual Treatment Effect Estimation and Inference**
2408.01582v1 by Hengrui Cai, Huaqing Jin, Lexin Li

Estimating treatment effects from observational data is of central interest
across numerous application domains. Individual treatment effect offers the
most granular measure of treatment effect on an individual level, and is the
most useful to facilitate personalized care. However, its estimation and
inference remain underdeveloped due to several challenges. In this article, we
propose a novel conformal diffusion model-based approach that addresses those
intricate challenges. We integrate the highly flexible diffusion modeling, the
model-free statistical inference paradigm of conformal inference, along with
propensity score and covariate local approximation that tackle distributional
shifts. We unbiasedly estimate the distributions of potential outcomes for
individual treatment effect, construct an informative confidence interval, and
establish rigorous theoretical guarantees. We demonstrate the competitive
performance of the proposed method over existing solutions through extensive
numerical studies.

æè¦ï¼å¾è§å¯è³æä¸­ä¼°è¨æ²»çææå¨è¨±å¤æç¨é åä¸­é½éå¸¸éè¦ãåå¥æ²»çæææä¾äºåäººå±¤ç´æç´°ç·»çæ²»çææè¡¡éï¼ä¸ææå©æ¼ä¿é²åäººåç§è­·ãç¶èï¼ç±æ¼æè¨±å¤ææ°ï¼å¶ä¼°è¨åæ¨è«ä»èæ¼ç¼å±ä¸è¶³ççæãå¨æ¬æä¸­ï¼æåæåºäºåµæ°çå±å½¢æ´æ£æ¨¡åçºåºç¤çæ¹æ³ï¼ä¾å æéäºè¤éçææ°ãæåæ´åäºé«åº¦å½æ§çæ´æ£æ¨¡åãå±å½¢æ¨è«çç¡æ¨¡åçµ±è¨æ¨è«ç¯ä¾ï¼ä»¥åèçåä½è½ç§»çå¾åå¾åååè®æ¸å±é¨è¿ä¼¼ãæåç¡åä¼°è¨åå¥æ²»çææçæ½å¨çµæåä½ï¼å»ºæ§ææç¾©çä¿¡å¿åéï¼ä¸¦å»ºç«å´è¬¹ççè«ä¿è­ãæåééå»£æ³çæ¸å¼ç ç©¶ï¼å±ç¤ºäºææåºæ¹æ³ç¸è¼æ¼ç¾æè§£æ±ºæ¹æ¡çç«¶ç­åã

##### **High-Throughput Phenotyping of Clinical Text Using Large Language Models**
2408.01214v1 by Daniel B. Hier, S. Ilyas Munzir, Anne Stahlfeld, Tayo Obafemi-Ajayi, Michael D. Carrithers

High-throughput phenotyping automates the mapping of patient signs to
standardized ontology concepts and is essential for precision medicine. This
study evaluates the automation of phenotyping of clinical summaries from the
Online Mendelian Inheritance in Man (OMIM) database using large language
models. Due to their rich phenotype data, these summaries can be surrogates for
physician notes. We conduct a performance comparison of GPT-4 and
GPT-3.5-Turbo. Our results indicate that GPT-4 surpasses GPT-3.5-Turbo in
identifying, categorizing, and normalizing signs, achieving concordance with
manual annotators comparable to inter-rater agreement. Despite some limitations
in sign normalization, the extensive pre-training of GPT-4 results in high
performance and generalizability across several phenotyping tasks while
obviating the need for manually annotated training data. Large language models
are expected to be the dominant method for automating high-throughput
phenotyping of clinical text.

æè¦ï¼é«ééè¡¨åèªååå°æ£èççå°æå°æ¨æºåæ¬ä½æ¦å¿µï¼å°æ¼ç²¾æºé«çè³ééè¦ãæ¬ç ç©¶è©ä¼°ä½¿ç¨å¤§åèªè¨æ¨¡åèªååä¾èªäººé¡å­å¾·ç¾éºå³ç·ä¸ï¼OMIMï¼è³æåº«çè¨åºæè¦è¡¨åãç±æ¼å¶è±å¯çè¡¨åè³æï¼éäºæè¦å¯ä»¥ä½çºé«å¸«åå¿éçæ¿ä»£åãæåå° GPT-4 å GPT-3.5-Turbo é²è¡æè½æ¯è¼ãæåççµæé¡¯ç¤ºï¼GPT-4 å¨è­å¥ãåé¡åæ¨æºåççæ¹é¢åªæ¼ GPT-3.5-Turboï¼èæåè¨»è§£èçç¬¦ååº¦å¯åª²ç¾è©åèéçä¸è´æ§ãåç®¡å¨ççæ¨æºåæ¹é¢æä¸äºéå¶ï¼ä½ GPT-4 çå»£æ³é è¨ç·´å¨å¤é è¡¨åä»»åä¸­ä»è½å¸¶ä¾é«æè½åæ¦æ¬æ§ï¼åæç¡éæåè¨»è§£çè¨ç·´è³æãå¤§åèªè¨æ¨¡åé è¨å°æçºèªååè¨åºæå­é«ééè¡¨åçä¸»è¦æ¹æ³ã

##### **Optimizing Variational Quantum Circuits Using Metaheuristic Strategies in Reinforcement Learning**
2408.01187v1 by Michael KÃ¶lle, Daniel Seidl, Maximilian Zorn, Philipp Altmann, Jonas Stein, Thomas Gabor

Quantum Reinforcement Learning (QRL) offers potential advantages over
classical Reinforcement Learning, such as compact state space representation
and faster convergence in certain scenarios. However, practical benefits
require further validation. QRL faces challenges like flat solution landscapes,
where traditional gradient-based methods are inefficient, necessitating the use
of gradient-free algorithms. This work explores the integration of
metaheuristic algorithms -- Particle Swarm Optimization, Ant Colony
Optimization, Tabu Search, Genetic Algorithm, Simulated Annealing, and Harmony
Search -- into QRL. These algorithms provide flexibility and efficiency in
parameter optimization. Evaluations in $5\times5$ MiniGrid Reinforcement
Learning environments show that, all algorithms yield near-optimal results,
with Simulated Annealing and Particle Swarm Optimization performing best. In
the Cart Pole environment, Simulated Annealing, Genetic Algorithms, and
Particle Swarm Optimization achieve optimal results, while the others perform
slightly better than random action selection. These findings demonstrate the
potential of Particle Swarm Optimization and Simulated Annealing for efficient
QRL learning, emphasizing the need for careful algorithm selection and
adaptation.

æè¦ï¼éå­å¼·åå­¸ç¿ (QRL) æ¯å³çµ±å¼·åå­¸ç¿å·ææ½å¨åªå¢ï¼ä¾å¦ç·æ¹ççæç©ºéè¡¨ç¤ºåå¨æäºææ³ä¸æ´å¿«çæ¶æéåº¦ãç¶èï¼å¯¦éå¥½èéè¦é²ä¸æ­¥é©è­ãQRL é¢è¨å¹³å¦çè§£æ±ºæ¹æ¡ç°å¢ç­ææ°ï¼å³çµ±çåºæ¼æ¢¯åº¦çç®æ³æçä½ä¸ï¼å æ­¤éè¦ä½¿ç¨ç¡æ¢¯åº¦ç®æ³ãéé å·¥ä½æ¢è¨äºååç¼å¼æ¼ç®æ³ï¼ç²å­ç¾¤æä½³åãè»ç¾¤æä½³åãç¦å¿æå°ãéºå³æ¼ç®æ³ãæ¨¡æ¬éç«ååè«§æå°ï¼æ´åå° QRL ä¸­ãéäºæ¼ç®æ³å¨åæ¸æä½³åä¸­æä¾äºéæ´»æ§èæçãå¨ $5\times5$ MiniGrid å¼·åå­¸ç¿ç°å¢ä¸­çè©ä¼°é¡¯ç¤ºï¼æææ¼ç®æ³é½ç¢çè¿ä¹æä½³ççµæï¼å¶ä¸­æ¨¡æ¬éç«åç²å­ç¾¤æä½³åè¡¨ç¾æä½³ãå¨æ¡¿é´ç°å¢ä¸­ï¼æ¨¡æ¬éç«ãéºå³æ¼ç®æ³åç²å­ç¾¤æä½³åå¯¦ç¾æä½³çµæï¼èå¶ä»æ¼ç®æ³çæè½ç¥åªæ¼é¨æ©åä½é¸æãéäºç¼ç¾è­æäºç²å­ç¾¤æä½³ååæ¨¡æ¬éç«å¨ææçç QRL å­¸ç¿ä¸­çæ½åï¼å¼·èª¿äºä»ç´°é¸æåèª¿æ´æ¼ç®æ³çå¿è¦æ§ã

##### **Six Dragons Fly Again: Reviving 15th-Century Korean Court Music with Transformers and Novel Encoding**
2408.01096v1 by Danbinaerin Han, Mark Gotham, Dongmin Kim, Hannah Park, Sihun Lee, Dasaem Jeong

We introduce a project that revives a piece of 15th-century Korean court
music, Chihwapyeong and Chwipunghyeong, composed upon the poem Songs of the
Dragon Flying to Heaven. One of the earliest examples of Jeongganbo, a Korean
musical notation system, the remaining version only consists of a rudimentary
melody. Our research team, commissioned by the National Gugak (Korean
Traditional Music) Center, aimed to transform this old melody into a
performable arrangement for a six-part ensemble. Using Jeongganbo data acquired
through bespoke optical music recognition, we trained a BERT-like masked
language model and an encoder-decoder transformer model. We also propose an
encoding scheme that strictly follows the structure of Jeongganbo and denotes
note durations as positions. The resulting machine-transformed version of
Chihwapyeong and Chwipunghyeong were evaluated by experts and performed by the
Court Music Orchestra of National Gugak Center. Our work demonstrates that
generative models can successfully be applied to traditional music with limited
training data if combined with careful design.

æè¦ï¼æåä»ç´¹äºä¸åå¾©å 15 ä¸ç´éåå®®å»·é³æ¨çå°æ¡ï¼å³ãé£é¾æ­ãçãéåæãåãå¹é¢¨è© ããéæ¯éåé³æ¨è¨è­æ³ãæ­£å¹²è­ãææ©çç¯ä¾ä¹ä¸ï¼ç¾å­çæ¬ååå«åºæ¬çæå¾ãæåçç ç©¶åéååå®¶åæ¨ä¸­å¿å§è¨ï¼æ¨å¨å°éé¦å¤èçæå¾è½åçºå­äººåå¥çè¡¨æ¼ç·¨æãæåä½¿ç¨ééå®¢è£½ååå­¸é³æ¨è¾¨è­åå¾çæ­£å¹²è­è³æï¼è¨ç·´äºä¸åé¡ä¼¼ BERT çé®è½èªè¨æ¨¡ååä¸åç·¨ç¢¼å¨-è§£ç¢¼å¨è½æå¨æ¨¡åãæåéæåºäºä¸ç¨®ç·¨ç¢¼æ¹æ¡ï¼å®å´æ ¼éµå¾ªæ­£å¹²è­ççµæ§ï¼ä¸¦å°é³ç¬¦æå¼æ¨ç¤ºçºä½ç½®ãç±æ©å¨è½æå¾çãéåæãåãå¹é¢¨è© ãç±å°å®¶è©ä¼°ï¼ä¸¦ç±åå®¶åæ¨ä¸­å¿çå®®å»·é³æ¨æ¨åæ¼å¥ãæåçç ç©¶è­æï¼å¦æå°çææ¨¡åèè¬¹æçè¨­è¨çµåï¼å³ä½¿è¨ç·´è³ææéï¼ä¹è½æåæç¨æ¼å³çµ±é³æ¨ã

##### **CIResDiff: A Clinically-Informed Residual Diffusion Model for Predicting Idiopathic Pulmonary Fibrosis Progression**
2408.00938v2 by Caiwen Jiang, Xiaodan Xing, Zaixin Ou, Mianxin Liu, Walsh Simon, Guang Yang, Dinggang Shen

The progression of Idiopathic Pulmonary Fibrosis (IPF) significantly
correlates with higher patient mortality rates. Early detection of IPF
progression is critical for initiating timely treatment, which can effectively
slow down the advancement of the disease. However, the current clinical
criteria define disease progression requiring two CT scans with a one-year
interval, presenting a dilemma: a disease progression is identified only after
the disease has already progressed. To this end, in this paper, we develop a
novel diffusion model to accurately predict the progression of IPF by
generating patient's follow-up CT scan from the initial CT scan. Specifically,
from the clinical prior knowledge, we tailor improvements to the traditional
diffusion model and propose a Clinically-Informed Residual Diffusion model,
called CIResDiff. The key innovations of CIResDiff include 1) performing the
target region pre-registration to align the lung regions of two CT scans at
different time points for reducing the generation difficulty, 2) adopting the
residual diffusion instead of traditional diffusion to enable the model focus
more on differences (i.e., lesions) between the two CT scans rather than the
largely identical anatomical content, and 3) designing the clinically-informed
process based on CLIP technology to integrate lung function information which
is highly relevant to diagnosis into the reverse process for assisting
generation. Extensive experiments on clinical data demonstrate that our
approach can outperform state-of-the-art methods and effectively predict the
progression of IPF.

æè¦ï¼ç¹ç¼æ§èºçºç¶­å (IPF) çé²ç¨èè¼é«çæ£èæ­»äº¡çé¡¯èç¸éãæ©æåµæ¸¬ IPF é²ç¨å°æ¼åæéå§æ²»çè³ééè¦ï¼èæ²»çå¯ä»¥æææ¸ç·©ç¾ççé²å±ãç¶èï¼ç®åçè¨åºæ¨æºå®ç¾©ç¾çé²ç¨éè¦å©æ¬¡ç¸éä¸å¹´çé»è¦æ·å±¤ææï¼éé æäºå©é£ï¼åªæå¨ç¾çå·²ç¶é²å±å¾æè½è­å¥åºç¾çé²ç¨ãçºæ­¤ï¼å¨æ¬æä¸­ï¼æåéç¼äºä¸ååµæ°çæ´æ£æ¨¡åï¼ééå¾åå§é»è¦æ·å±¤ææçææ£èçå¾çºé»è¦æ·å±¤ææï¼ä¾æºç¢ºé æ¸¬ IPF çé²ç¨ãå·é«ä¾èªªï¼æ ¹æè¨åºåé©ç¥è­ï¼æåå°å³çµ±æ´æ£æ¨¡åé²è¡äºæ¹é²ï¼ä¸¦æåºäºè¨åºç¥ææ®å·®æ´æ£æ¨¡åï¼ç¨±çº CIResDiffãCIResDiff çééµåµæ°åæ¬ï¼1) å·è¡ç®æ¨ååé è¨»åï¼ä»¥å°é½ä¸åæéé»çå©æ¬¡é»è¦æ·å±¤ææçèºé¨ååï¼ä»¥éä½çæé£åº¦ï¼2) æ¡ç¨æ®å·®æ´æ£èä¸æ¯å³çµ±æ´æ£ï¼ä½¿æ¨¡åæ´å°æ³¨æ¼å©æ¬¡é»è¦æ·å±¤ææä¹éçå·®ç°ï¼å³çç¶ï¼ï¼èä¸æ¯å¨å¾å¤§ç¨åº¦ä¸ç¸åçè§£åçµæ§ï¼3) è¨­è¨åºæ¼ CLIP æè¡çè¨åºç¥ææµç¨ï¼å°èè¨ºæ·é«åº¦ç¸éçèºåè½è³è¨æ´åå°éåéç¨ä¸­ï¼ä»¥åå©çæãè¨åºæ¸æçå¤§éå¯¦é©è¡¨æï¼æåçåæ³å¯ä»¥åªæ¼æåé²çæ¹æ³ï¼ä¸¦ææé æ¸¬ IPF çé²ç¨ã

##### **Parkinson's Disease Detection from Resting State EEG using Multi-Head Graph Structure Learning with Gradient Weighted Graph Attention Explanations**
2408.00906v1 by Christopher Neves, Yong Zeng, Yiming Xiao

Parkinson's disease (PD) is a debilitating neurodegenerative disease that has
severe impacts on an individual's quality of life. Compared with structural and
functional MRI-based biomarkers for the disease, electroencephalography (EEG)
can provide more accessible alternatives for clinical insights. While deep
learning (DL) techniques have provided excellent outcomes, many techniques fail
to model spatial information and dynamic brain connectivity, and face
challenges in robust feature learning, limited data sizes, and poor
explainability. To address these issues, we proposed a novel graph neural
network (GNN) technique for explainable PD detection using resting state EEG.
Specifically, we employ structured global convolutions with contrastive
learning to better model complex features with limited data, a novel multi-head
graph structure learner to capture the non-Euclidean structure of EEG data, and
a head-wise gradient-weighted graph attention explainer to offer neural
connectivity insights. We developed and evaluated our method using the UC San
Diego Parkinson's disease EEG dataset, and achieved 69.40% detection accuracy
in subject-wise leave-one-out cross-validation while generating intuitive
explanations for the learnt graph topology.

æè¦ï¼å¸éæ£®æ°çï¼PDï¼æ¯ä¸ç§è¡°å¼±æ§ç¥ç»éè¡æ§ç¾çï¼å¯¹ä¸ªäººççæ´»è´¨éæä¸¥éå½±åãä¸ç¨äºè¯¥ç¾ççç»ææ§ååè½æ§ MRI çç©æ è®°ç©ç¸æ¯ï¼èçµå¾ (EEG) å¯ä»¥æä¾æ´æäºè·åçä¸´åºè§è§£æ¿ä»£æ¹æ¡ãè½ç¶æ·±åº¦å­¦ä¹  (DL) ææ¯æä¾äºåè¶çç»æï¼ä½è®¸å¤ææ¯æªè½å¯¹ç©ºé´ä¿¡æ¯åå¨æå¤§èè¿æ¥è¿è¡å»ºæ¨¡ï¼å¹¶ä¸å¨ç¨³å¥ç¹å¾å­¦ä¹ ãæéçæ°æ®å¤§å°åè¾å·®çå¯è§£éæ§æ¹é¢é¢ä¸´ææãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬æåºäºä¸ç§æ°é¢çå¾ç¥ç»ç½ç» (GNN) ææ¯ï¼ç¨äºä½¿ç¨éæ¯ç¶æèçµå¾è¿è¡å¯è§£éç PD æ£æµãå·ä½èè¨ï¼æä»¬éç¨å·æå¯¹æ¯å­¦ä¹ çç»æåå¨å±å·ç§¯æ¥æ´å¥½å°å¯¹å·ææéæ°æ®çå¤æç¹å¾è¿è¡å»ºæ¨¡ï¼éç¨æ°é¢çå¤å¤´å¾ç»æå­¦ä¹ å¨æ¥æè·èçµå¾æ°æ®çéæ¬§å éå¾ç»æï¼ä»¥åéç¨å¤´æéæ¢¯åº¦å¾æ³¨æè§£éå¨æ¥æä¾ç¥ç»è¿æ¥è§è§£ãæä»¬ä½¿ç¨å å·å¤§å­¦å£å°äºå¥åæ ¡å¸éæ£®æ°çèçµå¾æ°æ®éå¼åå¹¶è¯ä¼°äºæä»¬çæ¹æ³ï¼å¹¶å¨æåè¯èçä¸æ³äº¤åéªè¯ä¸­å®ç°äº 69.40% çæ£æµåç¡®çï¼åæ¶ä¸ºå­¦ä¹ å°çå¾ææçæç´è§çè§£éã

##### **UlRe-NeRF: 3D Ultrasound Imaging through Neural Rendering with Ultrasound Reflection Direction Parameterization**
2408.00860v2 by Ziwen Guo, Zi Fang, Zhuang Fu

Three-dimensional ultrasound imaging is a critical technology widely used in
medical diagnostics. However, traditional 3D ultrasound imaging methods have
limitations such as fixed resolution, low storage efficiency, and insufficient
contextual connectivity, leading to poor performance in handling complex
artifacts and reflection characteristics. Recently, techniques based on NeRF
(Neural Radiance Fields) have made significant progress in view synthesis and
3D reconstruction, but there remains a research gap in high-quality ultrasound
imaging. To address these issues, we propose a new model, UlRe-NeRF, which
combines implicit neural networks and explicit ultrasound volume rendering into
an ultrasound neural rendering architecture. This model incorporates reflection
direction parameterization and harmonic encoding, using a directional MLP
module to generate view-dependent high-frequency reflection intensity
estimates, and a spatial MLP module to produce the medium's physical property
parameters. These parameters are used in the volume rendering process to
accurately reproduce the propagation and reflection behavior of ultrasound
waves in the medium. Experimental results demonstrate that the UlRe-NeRF model
significantly enhances the realism and accuracy of high-fidelity ultrasound
image reconstruction, especially in handling complex medium structures.

æè¦ï¼ä¸ç¶­è¶é³æ³¢å½±åæ¯ä¸é å»£æ³ç¨æ¼é«çè¨ºæ·çéè¦æè¡ãç¶èï¼å³çµ±ç 3D è¶é³æ³¢å½±åæ¹æ³æè§£æåº¦åºå®ãå²å­æçä½ãèçµ¡é£æ¥æ§ä¸è¶³ç­éå¶ï¼å°è´å¨èçè¤éçå½å½±ååå°ç¹æ§ææè½ä¸ä½³ãæè¿ï¼åºæ¼ NeRFï¼ç¥ç¶è¼»ç§å ´ï¼çæè¡å¨è¦ååæå 3D éå»ºæ¹é¢åå¾éå¤§é²å±ï¼ä½é«åè³ªè¶é³æ³¢å½±åä»å­å¨ç ç©¶ç©ºç½ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºä¸ç¨®æ°çæ¨¡å UlRe-NeRFï¼å®å°é±å¼ç¥ç¶ç¶²è·¯åæç¢ºçè¶é³æ³¢é«ç©æ¸²æçµåå°è¶é³æ³¢ç¥ç¶æ¸²ææ¶æ§ä¸­ãæ­¤æ¨¡åçµåäºåå°æ¹ååæ¸ååè«§æ³¢ç·¨ç¢¼ï¼ä½¿ç¨æ¹åæ§ MLP æ¨¡çµä¾ç¢çè¦è§ä¾è³´çé«é »çåå°å¼·åº¦ä¼°è¨ï¼ä¸¦ä½¿ç¨ç©ºé MLP æ¨¡çµä¾ç¢çä»è³ªçç©çå±¬æ§åæ¸ãéäºåæ¸ç¨æ¼é«ç©æ¸²æéç¨ä¸­ï¼ä»¥æºç¢ºéç¾è¶é³æ³¢å¨ä»è³ªä¸­çå³æ­ååå°è¡çºãå¯¦é©çµæè­æï¼UlRe-NeRF æ¨¡åé¡¯èæåäºé«ä¿çè¶é³æ³¢å½±åéå»ºççå¯¦æ§åæºç¢ºæ§ï¼ç¹å¥æ¯å¨èçè¤éä»è³ªçµæ§æã

##### **Segment anything model 2: an application to 2D and 3D medical images**
2408.00756v2 by Haoyu Dong, Hanxue Gu, Yaqian Chen, Jichen Yang, Maciej A. Mazurowski

Segment Anything Model (SAM) has gained significant attention because of its
ability to segment varous objects in images given a prompt. The recently
developed SAM 2 has extended this ability to video inputs. This opens an
opportunity to apply SAM to 3D images, one of the fundamental tasks in the
medical imaging field. In this paper, we extensively evaluate SAM 2's ability
to segment both 2D and 3D medical images by first collecting 18 medical imaging
datasets, including common 3D modalities such as computed tomography (CT),
magnetic resonance imaging (MRI), and positron emission tomography (PET) as
well as 2D modalities such as X-ray and ultrasound. Two evaluation pipelines of
SAM 2 are considered: (1) multi-frame 3D segmentation, where prompts are
provided to one or multiple slice(s) selected from the volume, and (2)
single-frame 2D segmentation, where prompts are provided to each slice. The
former is only applicable to 3D modalities, while the latter applies to both 2D
and 3D modalities. Our results show that SAM 2 exhibits similar performance as
SAM under single-frame 2D segmentation, and has variable performance under
multi-frame 3D segmentation depending on the choices of slices to annotate, the
direction of the propagation, the predictions utilized during the propagation,
etc.

æè¦ï¼åæ®µä»»ä½æ¨¡å (SAM) å å¶æ ¹ææç¤ºåæ®µååä¸­çä¸åç©ä»¶çè½åèåå°å»£æ³éæ³¨ãæè¿éç¼ç SAM 2 å·²å°æ­¤è½åæ´å±å°å½±çè¼¸å¥ãéçºå° SAM æç¨æ¼ 3D å½±åéåäºæ©æï¼éæ¯é«å­¸å½±åé åçåºæ¬ä»»åä¹ä¸ãå¨æ¬æä¸­ï¼æåå»£æ³è©ä¼°äº SAM 2 åæ®µ 2D å 3D é«å­¸å½±åçè½åï¼é¦åæ¶éäº 18 åé«å­¸å½±åè³æéï¼åæ¬å¸¸è¦ç 3D æ¨¡å¼ï¼ä¾å¦é»è¦æ·å±¤ææ (CT)ãç£æ¯é å½± (MRI) åæ­£å­ç¼å°æ·å±¤ææ (PET)ï¼ä»¥å 2D æ¨¡å¼ï¼ä¾å¦ X å°ç·åè¶é³æ³¢ãèæ®äº SAM 2 çå©åè©ä¼°ç®¡éï¼(1) å¤å¹ 3D åæ®µï¼å¶ä¸­æç¤ºæä¾çµ¦å¾é«ç©ä¸­é¸æçä¸åæå¤ååçï¼ä»¥å (2) å®å¹ 2D åæ®µï¼å¶ä¸­æç¤ºæä¾çµ¦æ¯ååçãåèåé©ç¨æ¼ 3D æ¨¡å¼ï¼èå¾èé©ç¨æ¼ 2D å 3D æ¨¡å¼ãæåççµæè¡¨æï¼SAM 2 å¨å®å¹ 2D åæ®µä¸çè¡¨ç¾è SAM é¡ä¼¼ï¼ä¸¦ä¸å¨å¤å¹ 3D åæ®µä¸çè¡¨ç¾ææ ¹æè¦æ¨è¨»çåçé¸æãå³æ­æ¹åãå³æ­æéä½¿ç¨çé æ¸¬ç­èææä¸åã

##### **Leaf Angle Estimation using Mask R-CNN and LETR Vision Transformer**
2408.00749v1 by Venkat Margapuri, Prapti Thapaliya, Trevor Rife

Modern day studies show a high degree of correlation between high yielding
crop varieties and plants with upright leaf angles. It is observed that plants
with upright leaf angles intercept more light than those without upright leaf
angles, leading to a higher rate of photosynthesis. Plant scientists and
breeders benefit from tools that can directly measure plant parameters in the
field i.e. on-site phenotyping. The estimation of leaf angles by manual means
in a field setting is tedious and cumbersome. We mitigate the tedium using a
combination of the Mask R-CNN instance segmentation neural network, and Line
Segment Transformer (LETR), a vision transformer. The proposed Computer Vision
(CV) pipeline is applied on two image datasets, Summer 2015-Ames ULA and Summer
2015- Ames MLA, with a combined total of 1,827 plant images collected in the
field using FieldBook, an Android application aimed at on-site phenotyping. The
leaf angles estimated by the proposed pipeline on the image datasets are
compared to two independent manual measurements using ImageJ, a Java-based
image processing program developed at the National Institutes of Health and the
Laboratory for Optical and Computational Instrumentation. The results, when
compared for similarity using the Cosine Similarity measure, exhibit 0.98
similarity scores on both independent measurements of Summer 2015-Ames ULA and
Summer 2015-Ames MLA image datasets, demonstrating the feasibility of the
proposed pipeline for on-site measurement of leaf angles.

æè¦ï¼<paragraph>ç¾ä»£ç ç©¶é¡¯ç¤ºï¼é«ç¢éä½ç©åç¨®åèçè§åº¦ç´ç«çæ¤ç©ä¹éæé«åº¦ç¸éæ§ãè§å¯å°èçè§åº¦ç´ç«çæ¤ç©æ¯èçè§åº¦ä¸ç´ç«çæ¤ç©ææªæ´å¤åç·ï¼å¾èå°è´æ´é«çååä½ç¨éçãæ¤ç©ç§å­¸å®¶åè²ç¨®èåçæ¼å¯ä»¥å¨ç°éç´æ¥æ¸¬éæ¤ç©åæ¸çå·¥å·ï¼å³ç¾å ´è¡¨ååæãå¨ç°éç°å¢ä¸­ééæåæ¹å¼ä¼°è¨èçè§åº¦æ¢ç¹ç£åéº»ç©ãæåä½¿ç¨ Mask R-CNN å¯¦ä¾åå²ç¥ç¶ç¶²è·¯åç·æ®µTransformer (LETR)ï¼ä¸ç¨®è¦è¦ºTransformerï¼ççµåä¾æ¸è¼ç¹ç£æ§ãææåºçè¨ç®æ©è¦è¦º (CV) ç®¡ç·æç¨æ¼å©åååè³æéï¼Summer 2015-Ames ULA å Summer 2015- Ames MLAï¼ç¸½å±åå« 1,827 å¼µæ¤ç©ååï¼éäºååæ¯å¨ç°éä½¿ç¨ FieldBookï¼ä¸ç¨®éå°ç¾å ´è¡¨ååæç Android æç¨ç¨å¼ï¼æ¶éçãä½¿ç¨ææåºçç®¡ç·ä¼°è¨çååè³æéä¸çèçè§åº¦èä½¿ç¨ ImageJï¼ä¸ç¨®ç±ç¾ååå®¶è¡çç ç©¶é¢ååå­¸åè¨ç®åå¨å¯¦é©å®¤éç¼çåºæ¼ Java çå½±åèçç¨å¼ï¼é²è¡çå©æ¬¡ç¨ç«æåæ¸¬éé²è¡æ¯è¼ãå°çµæä½¿ç¨é¤å¼¦ç¸ä¼¼åº¦æ¸¬éé²è¡ç¸ä¼¼æ§æ¯è¼æï¼å¨ Summer 2015-Ames ULA å Summer 2015-Ames MLA å½±åè³æéçå©æ¬¡ç¨ç«æ¸¬éä¸­é½é¡¯ç¤ºåº 0.98 çç¸ä¼¼åº¦åæ¸ï¼è­æäºææåºçç®¡ç·ç¨æ¼ç¾å ´æ¸¬éèçè§åº¦çå¯è¡æ§ã</paragraph>

##### **Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions**
2408.00727v1 by Guangzhi Xiong, Qiao Jin, Xiao Wang, Minjia Zhang, Zhiyong Lu, Aidong Zhang

The emergent abilities of large language models (LLMs) have demonstrated
great potential in solving medical questions. They can possess considerable
medical knowledge, but may still hallucinate and are inflexible in the
knowledge updates. While Retrieval-Augmented Generation (RAG) has been proposed
to enhance the medical question-answering capabilities of LLMs with external
knowledge bases, it may still fail in complex cases where multiple rounds of
information-seeking are required. To address such an issue, we propose
iterative RAG for medicine (i-MedRAG), where LLMs can iteratively ask follow-up
queries based on previous information-seeking attempts. In each iteration of
i-MedRAG, the follow-up queries will be answered by a vanilla RAG system and
they will be further used to guide the query generation in the next iteration.
Our experiments show the improved performance of various LLMs brought by
i-MedRAG compared with vanilla RAG on complex questions from clinical vignettes
in the United States Medical Licensing Examination (USMLE), as well as various
knowledge tests in the Massive Multitask Language Understanding (MMLU) dataset.
Notably, our zero-shot i-MedRAG outperforms all existing prompt engineering and
fine-tuning methods on GPT-3.5, achieving an accuracy of 69.68\% on the MedQA
dataset. In addition, we characterize the scaling properties of i-MedRAG with
different iterations of follow-up queries and different numbers of queries per
iteration. Our case studies show that i-MedRAG can flexibly ask follow-up
queries to form reasoning chains, providing an in-depth analysis of medical
questions. To the best of our knowledge, this is the first-of-its-kind study on
incorporating follow-up queries into medical RAG.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼çæ°èè½åå·²è­æå¨è§£æ±ºé«çåé¡æ¹é¢å·æå·¨å¤§æ½åãå®åå¯è½ææå¤§éçé«çç¥è­ï¼ä½ä»å¯è½ç¢çå¹»è¦ºï¼ä¸¦ä¸å¨ç¥è­æ´æ°æ¹é¢ç¼ºä¹éæ´»æ§ãéç¶å·²æåºæª¢ç´¢å¢å¼·çæï¼RAGï¼ä»¥å©ç¨å¤é¨ç¥è­åº«å¢å¼· LLM çé«çåé¡è§£ç­è½åï¼ä½å¨éè¦å¤è¼ªä¿¡æ¯æª¢ç´¢çè¤éææ³ä¸ï¼å®ä»å¯è½å¤±æãçºäºè§£æ±ºéååé¡ï¼æåæåºäºç¨æ¼é«ççè¿­ä»£ RAGï¼i-MedRAGï¼ï¼å¶ä¸­ LLM å¯ä»¥æ ¹æååçä¿¡æ¯æª¢ç´¢åè©¦åè¦è©¢åå¾çºæ¥è©¢ãå¨ i-MedRAG çæ¯æ¬¡è¿­ä»£ä¸­ï¼å¾çºæ¥è©¢å°ç±åºæ¬ç RAG ç³»çµ±åç­ï¼ä¸¦ä¸å®åå°é²ä¸æ­¥ç¨æ¼æå°ä¸ä¸æ¬¡è¿­ä»£ä¸­çæ¥è©¢çæãæåçå¯¦é©è¡¨æï¼èç¾åé«å­¸å·ç§èè©¦ï¼USMLEï¼ä¸­è¨åºå°æåä¸­çè¤éåé¡ä»¥å Massive Multitask Language Understandingï¼MMLUï¼æ¸æéä¸­åç¨®ç¥è­æ¸¬è©¦ä¸­çåºæ¬ RAG ç¸æ¯ï¼i-MedRAG å¸¶ä¾çåç¨® LLM çæ¹é²æ§è½ãå¼å¾æ³¨æçæ¯ï¼æåçé¶æ¬¡å­¸ç¿ i-MedRAG å¨ GPT-3.5 ä¸åªæ¼ææç¾æçæç¤ºå·¥ç¨åå¾®èª¿æ¹æ³ï¼å¨ MedQA æ¸æéä¸éå°äº 69.68% çæºç¢ºçãæ­¤å¤ï¼æåæè¿°äº i-MedRAG çæ´å±å±¬æ§ï¼åæ¬ä¸åçå¾çºæ¥è©¢è¿­ä»£åæ¯åè¿­ä»£çä¸åæ¥è©¢æ¸éãæåçæ¡ä¾ç ç©¶è¡¨æï¼i-MedRAG å¯ä»¥éæ´»å°è©¢åå¾çºæ¥è©¢ä»¥å½¢ææ¨çéï¼å¾èå°é«çåé¡é²è¡æ·±å¥åæãææåæç¥ï¼éæ¯ç¬¬ä¸åå°å¾çºæ¥è©¢ç´å¥é«ç RAG çåé¡ç ç©¶ã

##### **Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM**
2408.00706v1 by Xiaofeng Liu, Jonghye Woo, Chao Ma, Jinsong Ouyang, Georges El Fakhri

Delineating lesions and anatomical structure is important for image-guided
interventions. Point-supervised medical image segmentation (PSS) has great
potential to alleviate costly expert delineation labeling. However, due to the
lack of precise size and boundary guidance, the effectiveness of PSS often
falls short of expectations. Although recent vision foundational models, such
as the medical segment anything model (MedSAM), have made significant
advancements in bounding-box-prompted segmentation, it is not straightforward
to utilize point annotation, and is prone to semantic ambiguity. In this
preliminary study, we introduce an iterative framework to facilitate
semantic-aware point-supervised MedSAM. Specifically, the semantic box-prompt
generator (SBPG) module has the capacity to convert the point input into
potential pseudo bounding box suggestions, which are explicitly refined by the
prototype-based semantic similarity. This is then succeeded by a prompt-guided
spatial refinement (PGSR) module that harnesses the exceptional
generalizability of MedSAM to infer the segmentation mask, which also updates
the box proposal seed in SBPG. Performance can be progressively improved with
adequate iterations. We conducted an evaluation on BraTS2018 for the
segmentation of whole brain tumors and demonstrated its superior performance
compared to traditional PSS methods and on par with box-supervised methods.

æè¦ï¼æç¹ªçç¶åè§£åçµæ§å°æ¼å½±åå°å¼ä»å¥éå¸¸éè¦ãé»ç£ç£é«å­¸å½±ååå²ï¼PSSï¼å·ææ¸è¼æè²´çå°å®¶æç¹ªæ¨ç±¤çå·¨å¤§æ½åãç¶èï¼ç±æ¼ç¼ºä¹ç²¾ç¢ºçå¤§å°åéçå¼å°ï¼PSS çæææ§éå¸¸ä½æ¼é æãåç®¡æè¿çè¦è¦ºåºç¤æ¨¡åï¼ä¾å¦é«å­¸åå²ä»»ä½æ¨¡åï¼MedSAMï¼ï¼å¨éçæ¡æç¤ºåå²æ¹é¢åå¾äºéå¤§é²å±ï¼ä½å©ç¨é»è¨»éä¸¦ä¸å®¹æï¼èä¸å®¹æç¢çèªç¾©æ­§ç¾©ãå¨éé åæ­¥ç ç©¶ä¸­ï¼æåå¼å¥äºä¸åè¿­ä»£æ¡æ¶ä¾ä¿é²èªç¾©æç¥é»ç£ç£ MedSAMãå·é«ä¾èªªï¼èªç¾©æ¡æç¤ºçæå¨ï¼SBPGï¼æ¨¡çµè½å¤ å°é»è¼¸å¥è½æçºæ½å¨çå½éçæ¡å»ºè­°ï¼éäºå»ºè­°ç±åºæ¼ååçèªç¾©ç¸ä¼¼æ§æç¢ºç´°åãç¶å¾ï¼ç±æç¤ºå¼å°çç©ºéç´°åï¼PGSRï¼æ¨¡çµç¹¼æ¿ï¼å®å©ç¨ MedSAM çåºè²å¯æ¦åæ§ä¾æ¨æ·åå²èçï¼éä¹ææ´æ° SBPG ä¸­çæ¡å»ºè­°ç¨®å­ãééååçè¿­ä»£å¯ä»¥éæ­¥æé«æ§è½ãæåå° BraTS2018 é²è¡äºå¨è¦è«ç¤åå²è©ä¼°ï¼ä¸¦è­æå¶æ§è½åªæ¼å³çµ±ç PSS æ¹æ³ï¼ä¸¦ä¸èæ¡ç£ç£æ¹æ³ç¸ç¶ã

##### **HBot: A Chatbot for Healthcare Applications in Traditional Chinese Medicine Based on Human Body 3D Visualization**
2408.00481v1 by Bolin Zhang, Zhiwei Yi, Jiahao Wang, Dianbo Sui, Zhiying Tu, Dianhui Chu

The unique diagnosis and treatment techniques and remarkable clinical
efficacy of traditional Chinese medicine (TCM) make it play an important role
in the field of elderly care and healthcare, especially in the rehabilitation
of some common chronic diseases of the elderly. Therefore, building a TCM
chatbot for healthcare application will help users obtain consultation services
in a direct and natural way. However, concepts such as acupuncture points
(acupoints) and meridians involved in TCM always appear in the consultation,
which cannot be displayed intuitively. To this end, we develop a
\textbf{h}ealthcare chat\textbf{bot} (HBot) based on a human body model in 3D
and knowledge graph, which provides conversational services such as knowledge
Q\&A, prescription recommendation, moxibustion therapy recommendation, and
acupoint search. When specific acupoints are involved in the conversations
between user and HBot, the 3D body will jump to the corresponding acupoints and
highlight them. Moreover, Hbot can also be used in training scenarios to
accelerate the teaching process of TCM by intuitively displaying acupuncture
points and knowledge cards. The demonstration video is available at
https://www.youtube.com/watch?v=UhQhutSKkTU . Our code and dataset are publicly
available at Gitee: https://gitee.com/plabrolin/interactive-3d-acup.git

æè¦ï¼ä¸­é«ç¨ç¹çè¨ºæ²»ææ³åé¡¯èçè¨åºçæï¼å¨èå¹´ç§è­·èä¿å¥é åä¸­æ®æ¼èéè¦çè§è²ï¼ç¹å¥æ¯å¨èå¹´äººå¸¸è¦æ¢æ§ç¾ççå¾©å¥ä¸ãå æ­¤ï¼å»ºæ§ä¸åä¸­é«é«çç§è­·èå¤©æ©å¨äººï¼å°æå©æ¼ä½¿ç¨èä»¥ç´æ¥ä¸èªç¶çæ¹å¼åå¾è«®è©¢æåãç¶èï¼ä¸­é«ææ¶åçç©´ä½ãç¶çµ¡ç­æ¦å¿µï¼å¨è«®è©¢æç¸½æ¯æåºç¾ï¼èéäºç¡æ³ç´è§å°é¡¯ç¤ºåºä¾ãçºäºè§£æ±ºéååé¡ï¼æåéç¼äºä¸ååºæ¼ 3D äººé«æ¨¡ååç¥è­åè­çé«çç§è­·èå¤©æ©å¨äººï¼HBotï¼ï¼å®æä¾äºç¥è­åç­ãèæ¹æ¨è¦ãè¾ç¸çæ³æ¨è¦åç©´ä½æ¥è©¢ç­å°è©±æåãç¶ä½¿ç¨èè HBot çå°è©±ä¸­æ¶åå°å·é«ç©´ä½æï¼3D äººé«æè·³è½å°å°æçç©´ä½ä¸¦å°å¶é«äº®é¡¯ç¤ºãæ­¤å¤ï¼HBot éå¯ä»¥ç¨æ¼å¹è¨å ´æ¯ä¸­ï¼ééç´è§å°é¡¯ç¤ºç©´ä½åç¥è­å¡çï¼ä¾å éä¸­é«æå­¸çé²ç¨ãç¤ºç¯å½±çå¯æ¼ https://www.youtube.com/watch?v=UhQhutSKkTU åå¾ãæåçç¨å¼ç¢¼åè³æéå·²æ¼ Gitee å¬éï¼https://gitee.com/plabrolin/interactive-3d-acup.git

##### **Securing the Diagnosis of Medical Imaging: An In-depth Analysis of AI-Resistant Attacks**
2408.00348v1 by Angona Biswas, MD Abdullah Al Nasim, Kishor Datta Gupta, Roy George, Abdur Rashid

Machine learning (ML) is a rapidly developing area of medicine that uses
significant resources to apply computer science and statistics to medical
issues. ML's proponents laud its capacity to handle vast, complicated, and
erratic medical data. It's common knowledge that attackers might cause
misclassification by deliberately creating inputs for machine learning
classifiers. Research on adversarial examples has been extensively conducted in
the field of computer vision applications. Healthcare systems are thought to be
highly difficult because of the security and life-or-death considerations they
include, and performance accuracy is very important. Recent arguments have
suggested that adversarial attacks could be made against medical image analysis
(MedIA) technologies because of the accompanying technology infrastructure and
powerful financial incentives. Since the diagnosis will be the basis for
important decisions, it is essential to assess how strong medical DNN tasks are
against adversarial attacks. Simple adversarial attacks have been taken into
account in several earlier studies. However, DNNs are susceptible to more risky
and realistic attacks. The present paper covers recent proposed adversarial
attack strategies against DNNs for medical imaging as well as countermeasures.
In this study, we review current techniques for adversarial imaging attacks,
detections. It also encompasses various facets of these techniques and offers
suggestions for the robustness of neural networks to be improved in the future.

æè¦ï¼æ©å¨å­¸ç¿ (ML) æ¯é«å­¸é åä¸­å¿«éç¼å±çä¸åé åï¼å®å©ç¨å¤§éçè³æºå°é»è¦ç§å­¸åçµ±è¨å­¸æç¨æ¼é«çåé¡ãML çæ¯æèè®æå®èçå¤§éãè¤éä¸ä¸è¦åé«çè³æçè½åãç¾æå¨ç¥ï¼æ»æèå¯è½æééææçºæ©å¨å­¸ç¿åé¡å¨å»ºç«è¼¸å¥ä¾å°è´é¯èª¤åé¡ãå°æç¯ä¾çç ç©¶å·²å¨é»è¦è¦è¦ºæç¨é åä¸­å»£æ³é²è¡ãé«çä¿å¥ç³»çµ±è¢«èªçºéå¸¸å°é£ï¼å çºå®ååå«å®å¨æ§åçæ­»æ¸éçèéï¼ä¸æè½æºç¢ºæ§éå¸¸éè¦ãæè¿çè«é»è¡¨æï¼ç±æ¼ä¼´é¨èä¾çæè¡åºç¤è¨­æ½åå¼·å¤§çè²¡åèªå ï¼å°ææ»æå¯è½æéå°é«å­¸å½±ååæ (MedIA) æè¡é²è¡ãç±æ¼è¨ºæ·å°æçºéè¦æ±ºç­çåºç¤ï¼å æ­¤è©ä¼°é«ç DNN ä»»åå°ææ»æçå¼·å¼±éå¸¸éè¦ãå¨ååçå¤é ç ç©¶ä¸­å·²èæ®äºç°¡å®çå°ææ»æãç¶èï¼DNN å®¹æåå°é¢¨éªæ´é«ä¸æ´é¼ççæ»æãæ¬ææ¶µèäºéå°ç¨æ¼é«å­¸å½±åç DNN ææåºçææ°å°ææ»æç­ç¥ä»¥åå°ç­ãå¨æ¬ç ç©¶ä¸­ï¼æååé¡§äºç¶åå°æå½±åæ»æçæè¡åæª¢æ¸¬æ¹æ³ãå®éåå«äºéäºæè¡çååæ¹é¢ï¼ä¸¦æä¾äºæ¹é²ç¥ç¶ç¶²è·¯å¨æªä¾å¼·å¥æ§çå»ºè­°ã

##### **Advancing Medical Image Segmentation: Morphology-Driven Learning with Diffusion Transformer**
2408.00347v1 by Sungmin Kang, Jaeha Song, Jihie Kim

Understanding the morphological structure of medical images and precisely
segmenting the region of interest or abnormality is an important task that can
assist in diagnosis. However, the unique properties of medical imaging make
clear segmentation difficult, and the high cost and time-consuming task of
labeling leads to a coarse-grained representation of ground truth. Facing with
these problems, we propose a novel Diffusion Transformer Segmentation (DTS)
model for robust segmentation in the presence of noise. We propose an
alternative to the dominant Denoising U-Net encoder through experiments
applying a transformer architecture, which captures global dependency through
self-attention. Additionally, we propose k-neighbor label smoothing, reverse
boundary attention, and self-supervised learning with morphology-driven
learning to improve the ability to identify complex structures. Our model,
which analyzes the morphological representation of images, shows better results
than the previous models in various medical imaging modalities, including CT,
MRI, and lesion images.

æè¦ï¼äºè§£é«å­¸å½±åçå½¢æçµæ§ä¸¦ç²¾ç¢ºåå²æèè¶£æç°å¸¸ååæ¯ä¸é éè¦çä»»åï¼æå©æ¼è¨ºæ·ãç¶èï¼é«å­¸å½±åçç¨ç¹å±¬æ§ä½¿å¾æ¸æ°çåå²è®å¾å°é£ï¼èæ¨ç±¤çé«ææ¬åèæä»»åå°è´äºå°é¢å¯¦æ³çç²ç¥è¡¨ç¤ºãé¢å°éäºåé¡ï¼æåæåºäºä¸åæ°çæ´æ£Transformeråå²ï¼DTSï¼æ¨¡åï¼ç¨æ¼å¨æåªè²çææ³ä¸é²è¡ç©©å¥åå²ãæåééæç¨æç²å¨å±ä¾è³´æ§çèªæ³¨æåTransformeræ¶æ§ï¼æåºäºä¸åæ¿ä»£ä¸»æµå»åª U-Net ç·¨ç¢¼å¨çæ¹æ¡ãæ­¤å¤ï¼æåæåºäº k è¿é°æ¨ç±¤å¹³æ»ãååéçæ³¨æåï¼ä»¥åä½¿ç¨å½¢æé©åå­¸ç¿çèªç£ç£å­¸ç¿ï¼ä»¥æé«è­å¥è¤éçµæ§çè½åãæåçæ¨¡ååæäºå½±åçå½¢æè¡¨ç¤ºï¼å¨åç¨®é«å­¸å½±åæ¹å¼ä¸­é¡¯ç¤ºåºæ¯ä»¥åæ¨¡åæ´å¥½ççµæï¼åæ¬ CTãMRI åçç¶å½±åã

##### **S-SYNTH: Knowledge-Based, Synthetic Generation of Skin Images**
2408.00191v1 by Andrea Kim, Niloufar Saharkhiz, Elena Sizikova, Miguel Lago, Berkman Sahiner, Jana Delfino, Aldo Badano

Development of artificial intelligence (AI) techniques in medical imaging
requires access to large-scale and diverse datasets for training and
evaluation. In dermatology, obtaining such datasets remains challenging due to
significant variations in patient populations, illumination conditions, and
acquisition system characteristics. In this work, we propose S-SYNTH, the first
knowledge-based, adaptable open-source skin simulation framework to rapidly
generate synthetic skin, 3D models and digitally rendered images, using an
anatomically inspired multi-layer, multi-component skin and growing lesion
model. The skin model allows for controlled variation in skin appearance, such
as skin color, presence of hair, lesion shape, and blood fraction among other
parameters. We use this framework to study the effect of possible variations on
the development and evaluation of AI models for skin lesion segmentation, and
show that results obtained using synthetic data follow similar comparative
trends as real dermatologic images, while mitigating biases and limitations
from existing datasets including small dataset size, lack of diversity, and
underrepresentation.

æè¦ï¼äººå·¥æºæ§ (AI) æè¡å¨é«å­¸å½±åæ¹é¢çç¼å±éè¦åå¾å¤§è¦æ¨¡ä¸å¤åçè³æéï¼ä»¥é²è¡è¨ç·´åè©ä¼°ãå¨ç®èç§ä¸­ï¼åå¾æ­¤é¡è³æéä»ç¶å·æææ°æ§ï¼åå å¨æ¼æ£èæç¾¤ãç§ææ¢ä»¶ååå¾ç³»çµ±ç¹æ§æé¡¯èçè®åãå¨éé å·¥ä½ä¸­ï¼æåæåº S-SYNTHï¼éæ¯ç¬¬ä¸ååºæ¼ç¥è­ãå¯é©æçéæ¾åå§ç¢¼ç®èæ¨¡æ¬æ¶æ§ï¼å¯ä½¿ç¨è§£åå­¸åç¼çå¤å±¤ãå¤çµæç®èåçé·çç¶æ¨¡åï¼å¿«éç¢çåæç®èã3D æ¨¡ååæ¸ä½æ¸²æå½±åãç®èæ¨¡ååè¨±æ§å¶ç®èå¤è§çè®åï¼ä¾å¦èè²ãæ¯é«®å­å¨ãçç¶å½¢çåè¡æ¶²æ¯ä¾ç­åæ¸ãæåä½¿ç¨éåæ¶æ§ä¾ç ç©¶å¯è½çè®åå°ç®èçç¶åå² AI æ¨¡åçéç¼åè©ä¼°çå½±é¿ï¼ä¸¦é¡¯ç¤ºä½¿ç¨åæè³æåå¾ççµæéµå¾ªèçå¯¦ç®èç§å½±åé¡ä¼¼çæ¯è¼è¶¨å¢ï¼åææ¸è¼ç¾æè³æéçåå·®åéå¶ï¼åæ¬è³æéè¦æ¨¡å°ãç¼ºä¹å¤åæ§ä»¥åä»£è¡¨æ§ä¸è¶³ã

##### **A Taxonomy of Stereotype Content in Large Language Models**
2408.00162v1 by Gandalf Nicolas, Aylin Caliskan

This study introduces a taxonomy of stereotype content in contemporary large
language models (LLMs). We prompt ChatGPT 3.5, Llama 3, and Mixtral 8x7B, three
powerful and widely used LLMs, for the characteristics associated with 87
social categories (e.g., gender, race, occupations). We identify 14 stereotype
dimensions (e.g., Morality, Ability, Health, Beliefs, Emotions), accounting for
~90% of LLM stereotype associations. Warmth and Competence facets were the most
frequent content, but all other dimensions were significantly prevalent.
Stereotypes were more positive in LLMs (vs. humans), but there was significant
variability across categories and dimensions. Finally, the taxonomy predicted
the LLMs' internal evaluations of social categories (e.g., how
positively/negatively the categories were represented), supporting the
relevance of a multidimensional taxonomy for characterizing LLM stereotypes.
Our findings suggest that high-dimensional human stereotypes are reflected in
LLMs and must be considered in AI auditing and debiasing to minimize
unidentified harms from reliance in low-dimensional views of bias in LLMs.

æè¦ï¼æ¬ç ç©¶éå°ç¶ä»£å¤§åèªè¨æ¨¡å (LLM) ä¸­çå»æ¿å°è±¡å§å®¹é²è¡åé¡ãæåæç¤º ChatGPT 3.5ãLlama 3 å Mixtral 8x7B éä¸ç¨®å¼·å¤§ä¸å»£æ³ä½¿ç¨ç LLMï¼äºè§£è 87 åç¤¾æé¡å¥ï¼ä¾å¦æ§å¥ãç¨®æãè·æ¥­ï¼ç¸éçç¹å¾µãæåè­å¥åº 14 åå»æ¿å°è±¡é¢åï¼ä¾å¦éå¾·ãè½åãå¥åº·ãä¿¡ä»°ãæç·ï¼ï¼ç´ä½ LLM å»æ¿å°è±¡éè¯ç 90%ãæº«æåè½åé¢åæ¯æé »ç¹çå§å®¹ï¼ä½ææå¶ä»é¢åé½å¾æ®éãLLM ä¸­çå»æ¿å°è±¡æ¯äººé¡æ´æ­£é¢ï¼ä½ä¸åé¡å¥åé¢åä¹éå­å¨é¡¯èå·®ç°ãæå¾ï¼åé¡æ³é æ¸¬äº LLM å°ç¤¾æé¡å¥çå§é¨è©ä¼°ï¼ä¾å¦é¡å¥çæ­£é¢/è² é¢åç¾æ¹å¼ï¼ï¼æ¯æäºä½¿ç¨å¤ç¶­åé¡æ³ä¾è¡¨å¾µ LLM å»æ¿å°è±¡çç¸éæ§ãæåçç ç©¶çµæè¡¨æï¼é«ç¶­åº¦çäººé¡å»æ¿å°è±¡åæ å¨ LLM ä¸­ï¼ä¸¦ä¸å¿é å¨ AI ç¨½æ ¸åæ¶é¤åè¦ä¸­å ä»¥èæ®ï¼ä»¥å°ä¾è³´ LLM ä¸­åè¦çä½ç¶­åº¦è§é»é æçæªè­å¥å±å®³éå°æä½ã

##### **Preference-Based Abstract Argumentation for Case-Based Reasoning (with Appendix)**
2408.00108v2 by Adam Gould, Guilherme Paulino-Passos, Seema Dadhania, Matthew Williams, Francesca Toni

In the pursuit of enhancing the efficacy and flexibility of interpretable,
data-driven classification models, this work introduces a novel incorporation
of user-defined preferences with Abstract Argumentation and Case-Based
Reasoning (CBR). Specifically, we introduce Preference-Based Abstract
Argumentation for Case-Based Reasoning (which we call AA-CBR-P), allowing users
to define multiple approaches to compare cases with an ordering that specifies
their preference over these comparison approaches. We prove that the model
inherently follows these preferences when making predictions and show that
previous abstract argumentation for case-based reasoning approaches are
insufficient at expressing preferences over constituents of an argument. We
then demonstrate how this can be applied to a real-world medical dataset
sourced from a clinical trial evaluating differing assessment methods of
patients with a primary brain tumour. We show empirically that our approach
outperforms other interpretable machine learning models on this dataset.

æè¦ï¼çºäºæåå¯è§£éãè³æé©ååé¡æ¨¡åçæè½åéæ´»æ§ï¼æ­¤ç ç©¶å¼å¥äºä½¿ç¨èèªè¨åå¥½èæ½è±¡è«è­åæ¡ä¾åºç¤æ¨ç (CBR) çæ°çµåãå·é«ä¾èªªï¼æåå¼å¥äºæ¡ä¾åºç¤æ¨ççåå¥½åºç¤æ½è±¡è«è­ (æåç¨±ä¹çº AA-CBR-P)ï¼åè¨±ä½¿ç¨èå®ç¾©å¤ç¨®æ¹æ³ä¾æ¯è¼æ¡ä¾ï¼ä¸¦ééæåºä¾æå®ä»åå°éäºæ¯è¼æ¹æ³çåå¥½ãæåè­æäºæ­¤æ¨¡åå¨é²è¡é æ¸¬ææèªç¶éµå¾ªéäºåå¥½ï¼ä¸¦é¡¯ç¤ºååæ¡ä¾åºç¤æ¨ççæ½è±¡è«è­æ¹æ³ä¸è¶³ä»¥è¡¨éå°è«è­çµæçåå¥½ãç¶å¾ï¼æåå±ç¤ºäºå¦ä½å°æ­¤æ¹æ³æç¨æ¼å¯¦éçé«çè³æéï¼è©²è³æéä¾èªè©ä¼°åç¼æ§è¦è«ç¤æ£èä¸åè©ä¼°æ¹æ³çè¨åºè©¦é©ãæåç¶é©æ§å°è­æï¼æåçåæ³å¨éåè³æéä¸åªæ¼å¶ä»å¯è§£éçæ©å¨å­¸ç¿æ¨¡åã

##### **A Federated Learning-Friendly Approach for Parameter-Efficient Fine-Tuning of SAM in 3D Segmentation**
2407.21739v1 by Mothilal Asokan, Joseph Geo Benjamin, Mohammad Yaqub, Karthik Nandakumar

Adapting foundation models for medical image analysis requires finetuning
them on a considerable amount of data because of extreme distribution shifts
between natural (source) data used for pretraining and medical (target) data.
However, collecting task-specific medical data for such finetuning at a central
location raises many privacy concerns. Although Federated learning (FL)
provides an effective means for training on private decentralized data,
communication costs in federating large foundation models can quickly become a
significant bottleneck, impacting the solution's scalability. In this work, we
address this problem of efficient communication while ensuring effective
learning in FL by combining the strengths of Parameter-Efficient Fine-tuning
(PEFT) with FL. Specifically, we study plug-and-play Low-Rank Adapters (LoRA)
in a federated manner to adapt the Segment Anything Model (SAM) for 3D medical
image segmentation. Unlike prior works that utilize LoRA and finetune the
entire decoder, we critically analyze the contribution of each granular
component of SAM on finetuning performance. Thus, we identify specific layers
to be federated that are very efficient in terms of communication cost while
producing on-par accuracy. Our experiments show that retaining the parameters
of the SAM model (including most of the decoder) in their original state during
adaptation is beneficial because fine-tuning on small datasets tends to distort
the inherent capabilities of the underlying foundation model. On Fed-KiTS, our
approach decreases communication cost (~48x) compared to full fine-tuning while
increasing performance (~6% Dice score) in 3D segmentation tasks. Our approach
performs similar to SAMed while achieving ~2.8x reduction in communication and
parameters to be finetuned. We further validate our approach with experiments
on Fed-IXI and Prostate MRI datasets.

æè¦ï¼<paragraph>ç±æ¼é è¨ç·´æç¨çèªç¶ï¼ä¾æºï¼è³æåé«çï¼ç®æ¨ï¼è³æä¹éçæ¥µç«¯åä½è½ç§»ï¼å æ­¤å°åºç¤æ¨¡åèª¿æ´ç¨æ¼é«å­¸å½±ååæéè¦å¨å¤§éè³æä¸å°å¶é²è¡å¾®èª¿ã
ç¶èï¼å¨ä¸­å¿ä½ç½®æ¶éæ­¤é¡å¾®èª¿çç¹å®ä»»åé«çè³ææå¼ç¼è¨±å¤é±ç§åé¡ãåç®¡è¯åå­¸ç¿ (FL) æä¾äºä¸ç¨®å¨ç§æåæ£å¼è³æä¸é²è¡è¨ç·´çæææ¹æ³ï¼ä½å¨è¯åå¤§ååºç¤æ¨¡åæï¼éè¨ææ¬å¯è½æè¿éæçºä¸åéå¤§ç¶é ¸ï¼å½±é¿è§£æ±ºæ¹æ¡çå¯æ´åæ§ãå¨éé å·¥ä½ä¸­ï¼æåééçµååæ¸é«æå¾®èª¿ (PEFT) å FL çåªå¢ï¼è§£æ±ºäºå¨ç¢ºä¿ FL ä¸­ææå­¸ç¿çåæé²è¡é«æéè¨çåé¡ãå·é«ä¾èªªï¼æåä»¥è¯åçæ¹å¼ç ç©¶å³æå³ç¨ä½ç§©é©éå¨ (LoRA)ï¼ä»¥èª¿æ´åæ®µä»»ä½æ¨¡å (SAM) ä»¥é²è¡ 3D é«å­¸å½±ååå²ãèå©ç¨ LoRA åå¾®èª¿æ´åè§£ç¢¼å¨çååå·¥ä½ä¸åï¼æåæ¹å¤æ§å°åæäº SAM çæ¯åç²ççµæé¨åå°å¾®èª¿æè½çè²¢ç»ãå æ­¤ï¼æåç¢ºå®äºå¨éè¨ææ¬æ¹é¢éå¸¸é«æçç¹å®å±¤ï¼åæç¢çäºåç­çæºç¢ºåº¦ãæåçå¯¦é©è¡¨æï¼å¨èª¿æ´éç¨ä¸­å° SAM æ¨¡åçåæ¸ï¼åæ¬å¤§é¨åè§£ç¢¼å¨ï¼ä¿çå¨å¶åå§çææ¯æççï¼å çºå¨å°åè³æéä¸é²è¡å¾®èª¿å¾å¾ææ­æ²åºç¤æ¨¡åçå§å¨è½åãå¨ Fed-KiTS ä¸ï¼èå®å¨å¾®èª¿ç¸æ¯ï¼æåçåæ³éä½äºéè¨ææ¬ï¼ç´ 48 åï¼ï¼åææé«äº 3D åå²ä»»åä¸­çæè½ï¼ç´ 6% çéª°å­åæ¸ï¼ãæåçåæ³è SAMed é¡ä¼¼ï¼åæå°éè¨åå¾å¾®èª¿åæ¸æ¸å°äºç´ 2.8 åãæåé²ä¸æ­¥ééå¨ Fed-IXI å Prostate MRI è³æéä¸é²è¡å¯¦é©é©è­äºæåçåæ³ã</paragraph>

##### **Synthetic Simplicity: Unveiling Bias in Medical Data Augmentation**
2407.21674v1 by Krishan Agyakari Raja Babu, Rachana Sathish, Mrunal Pattanaik, Rahul Venkataramani

Synthetic data is becoming increasingly integral in data-scarce fields such
as medical imaging, serving as a substitute for real data. However, its
inherent statistical characteristics can significantly impact downstream tasks,
potentially compromising deployment performance. In this study, we empirically
investigate this issue and uncover a critical phenomenon: downstream neural
networks often exploit spurious distinctions between real and synthetic data
when there is a strong correlation between the data source and the task label.
This exploitation manifests as \textit{simplicity bias}, where models overly
rely on superficial features rather than genuine task-related complexities.
Through principled experiments, we demonstrate that the source of data (real
vs.\ synthetic) can introduce spurious correlating factors leading to poor
performance during deployment when the correlation is absent. We first
demonstrate this vulnerability on a digit classification task, where the model
spuriously utilizes the source of data instead of the digit to provide an
inference. We provide further evidence of this phenomenon in a medical imaging
problem related to cardiac view classification in echocardiograms, particularly
distinguishing between 2-chamber and 4-chamber views. Given the increasing role
of utilizing synthetic datasets, we hope that our experiments serve as
effective guidelines for the utilization of synthetic datasets in model
training.

æè¦ï¼åæè³æå¨è³æç¨å°çé åä¸­è®å¾è¶ä¾è¶ä¸å¯æç¼ºï¼ä¾å¦é«å­¸å½±åï¼ç¨ä½çå¯¦è³æçæ¿ä»£åãç¶èï¼å¶å§å¨ççµ±è¨ç¹æ§æé¡¯èå½±é¿ä¸æ¸¸ä»»åï¼å¯è½æå®³é¨ç½²æè½ãå¨æ¬ç ç©¶ä¸­ï¼æåå¯¦è­èª¿æ¥æ­¤åé¡ï¼ä¸¦æ­é²ä¸åééµç¾è±¡ï¼ç¶è³æä¾æºèä»»åæ¨ç±¤ä¹éæå¾å¼·çç¸éæ§æï¼ä¸æ¸¸ç¥ç¶ç¶²è·¯éå¸¸æå©ç¨çå¯¦è³æèåæè³æä¹éçèååå¥ãéç¨®å©ç¨è¡¨ç¾çºãç°¡ååå·®ãï¼å¶ä¸­æ¨¡åéåº¦ä¾è³´è¡¨é¢ç¹å¾µï¼èä¸æ¯çæ­£çèä»»åç¸éçè¤éæ§ãééæååçå¯¦é©ï¼æåè­æè³æä¾æºï¼çå¯¦è³æèåæè³æï¼å¯è½æå¼å¥èåçç¸éå ç´ ï¼å°è´å¨ç¸éæ§ä¸å­å¨æé¨ç½²æéæè½ä¸ä½³ãæåé¦åå¨æ¸å­åé¡ä»»åä¸­è­ææ­¤æ¼æ´ï¼å¶ä¸­æ¨¡åèåå°å©ç¨è³æä¾æºèéæ¸å­ä¾æä¾æ¨è«ãæåå¨èè¶é³æ³¢å¿èè¦éåé¡ç¸éçé«å­¸å½±ååé¡ä¸­é²ä¸æ­¥æä¾æ­¤ç¾è±¡çè­æï¼ç¹å¥æ¯ååäºèååèè¦éãéæ¼åæè³æéçä½¿ç¨è§è²æ¥çå¢å ï¼æåå¸ææåçå¯¦é©è½ä½çºå¨æ¨¡åè¨ç·´ä¸­å©ç¨åæè³æéçæææåã

##### **Quality Control for Radiology Report Generation Models via Auxiliary Auditing Components**
2407.21638v1 by Hermione Warr, Yasin Ibrahim, Daniel R. McGowan, Konstantinos Kamnitsas

Automation of medical image interpretation could alleviate bottlenecks in
diagnostic workflows, and has become of particular interest in recent years due
to advancements in natural language processing. Great strides have been made
towards automated radiology report generation via AI, yet ensuring clinical
accuracy in generated reports is a significant challenge, hindering deployment
of such methods in clinical practice. In this work we propose a quality control
framework for assessing the reliability of AI-generated radiology reports with
respect to semantics of diagnostic importance using modular auxiliary auditing
components (AC). Evaluating our pipeline on the MIMIC-CXR dataset, our findings
show that incorporating ACs in the form of disease-classifiers can enable
auditing that identifies more reliable reports, resulting in higher F1 scores
compared to unfiltered generated reports. Additionally, leveraging the
confidence of the AC labels further improves the audit's effectiveness.

æè¦ï¼é«çå½±åå¤è®çèªååå¯ä»¥æ¸è¼è¨ºæ·å·¥ä½æµç¨ä¸­çç¶é ¸ï¼ä¸¦ä¸ç±æ¼èªç¶èªè¨èççé²æ­¥ï¼å¨è¿å¹´ä¾ç¹å¥åå°éè¦ãå¨éé AI èªåçææ¾å°ç·å ±åæ¹é¢å·²ç¶åå¾äºé·è¶³çé²å±ï¼ç¶èç¢ºä¿çæå ±åçè¨åºæºç¢ºæ§æ¯ä¸é éå¤§çææ°ï¼é»ç¤äºæ­¤é¡æ¹æ³å¨è¨åºå¯¦åä¸­çé¨ç½²ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ååè³ªæ§å¶æ¶æ§ï¼ç¨æ¼è©ä¼° AI çæçæ¾å°ç·å ±åçå¯é æ§ï¼ä¸¦ä½¿ç¨æ¨¡çµåè¼å©ç¨½æ ¸åä»¶ (AC) éå°è¨ºæ·éè¦æ§çèªç¾©é²è¡è©ä¼°ãå¨ MIMIC-CXR è³æéä¸è©ä¼°æåçç®¡éï¼æåçç¼ç¾é¡¯ç¤ºï¼ä»¥ç¾çåé¡å¨çå½¢å¼ç´å¥ AC å¯ä»¥åç¨ç¨½æ ¸ï¼ä»¥è­å¥æ´å¯é çå ±åï¼èæªç¶ç¯©é¸ççæå ±åç¸æ¯ï¼æç¢çæ´é«ç F1 åæ¸ãæ­¤å¤ï¼é²ä¸æ­¥å©ç¨ AC æ¨ç±¤çä¿¡å¿å¯ä»¥æé«ç¨½æ ¸çæææ§ã

##### **Optimizing Disease Prediction with Artificial Intelligence Driven Feature Selection and Attention Networks**
2408.03151v1 by D. Dhinakaran, S. Edwin Raja, M. Thiyagarajan, J. Jeno Jasmine, P. Raghavan

The rapid integration of machine learning methodologies in healthcare has
ignited innovative strategies for disease prediction, particularly with the
vast repositories of Electronic Health Records (EHR) data. This article delves
into the realm of multi-disease prediction, presenting a comprehensive study
that introduces a pioneering ensemble feature selection model. This model,
designed to optimize learning systems, combines statistical, deep, and
optimally selected features through the innovative Stabilized Energy Valley
Optimization with Enhanced Bounds (SEV-EB) algorithm. The objective is to
achieve unparalleled accuracy and stability in predicting various disorders.
This work proposes an advanced ensemble model that synergistically integrates
statistical, deep, and optimally selected features. This combination aims to
enhance the predictive power of the model by capturing diverse aspects of the
health data. At the heart of the proposed model lies the SEV-EB algorithm, a
novel approach to optimal feature selection. The algorithm introduces enhanced
bounds and stabilization techniques, contributing to the robustness and
accuracy of the overall prediction model. To further elevate the predictive
capabilities, an HSC-AttentionNet is introduced. This network architecture
combines deep temporal convolution capabilities with LSTM, allowing the model
to capture both short-term patterns and long-term dependencies in health data.
Rigorous evaluations showcase the remarkable performance of the proposed model.
Achieving a 95% accuracy and 94% F1-score in predicting various disorders, the
model surpasses traditional methods, signifying a significant advancement in
disease prediction accuracy. The implications of this research extend beyond
the confines of academia.

æè¦ï¼<paragraph>æ©å¨å­¸ç¿æ¹æ³å¨é«çä¿å¥é åçå¿«éæ´åï¼é»çäºç¾çé æ¸¬çåµæ°ç­ç¥ï¼ç¹å¥æ¯é»å­å¥åº·è¨é (EHR) è³æçé¾å¤§å²å­åº«ãæ¬ææ·±å¥æ¢è¨å¤ç¾çé æ¸¬çé åï¼æåºäºä¸é å¨é¢çç ç©¶ï¼ä»ç´¹äºä¸åéåµæ§çéæç¹å¾µé¸ææ¨¡åãéåæ¨¡åæ¨å¨åªåå­¸ç¿ç³»çµ±ï¼çµåçµ±è¨ãæ·±åº¦åæä½³é¸æçç¹å¾µï¼ééåµæ°çç©©å®è½éè°·åªåèå¢å¼·éç (SEV-EB) æ¼ç®æ³ãç®æ¨æ¯å¨é æ¸¬åç¨®ç¾çæéå°ç¡èå«æ¯çæºç¢ºæ§åç©©å®æ§ãéé ç ç©¶æåºäºä¸ååé²çéææ¨¡åï¼ååæ´åçµ±è¨ãæ·±åº¦åæä½³é¸æçç¹å¾µãéç¨®çµåæ¨å¨ééæ·åå¥åº·è³æçä¸åé¢åï¼ä¾å¢å¼·æ¨¡åçé æ¸¬è½åãææåºçæ¨¡åæ ¸å¿å¨æ¼ SEV-EB æ¼ç®æ³ï¼ä¸ç¨®æä½³ç¹å¾µé¸æçæ°æ¹æ³ãè©²æ¼ç®æ³å¼å¥äºå¢å¼·çéçåç©©å®æè¡ï¼æå©æ¼æ´é«é æ¸¬æ¨¡åçç©©å¥æ§åæºç¢ºæ§ãçºäºé²ä¸æ­¥æåé æ¸¬è½åï¼å¼å¥äº HSC-AttentionNetãéåç¶²è·¯æ¶æ§çµåäºæ·±åº¦æéå·ç©åè½è LSTMï¼ä½¿æ¨¡åè½å¤ æ·åå¥åº·è³æä¸­çç­ææ¨¡å¼åé·æä¾è³´æ§ãå´è¬¹çè©ä¼°å±ç¤ºäºææåºæ¨¡åçåè¶æè½ãå¨é æ¸¬åç¨®ç¾çæéå° 95% çæºç¢ºåº¦å 94% ç F1 åæ¸ï¼è©²æ¨¡åè¶è¶äºå³çµ±æ¹æ³ï¼æ¨èªèç¾çé æ¸¬æºç¢ºæ§çéå¤§é²å±ãéé ç ç©¶çæç¾©è¶è¶äºå­¸è¡çã</paragraph>

##### **Voxel Scene Graph for Intracranial Hemorrhage**
2407.21580v1 by Antoine P. Sanner, Nils F. Grauhan, Marc A. Brockmann, Ahmed E. Othman, Anirban Mukhopadhyay

Patients with Intracranial Hemorrhage (ICH) face a potentially
life-threatening condition, and patient-centered individualized treatment
remains challenging due to possible clinical complications. Deep-Learning-based
methods can efficiently analyze the routinely acquired head CTs to support the
clinical decision-making. The majority of early work focuses on the detection
and segmentation of ICH, but do not model the complex relations between ICH and
adjacent brain structures. In this work, we design a tailored object detection
method for ICH, which we unite with segmentation-grounded Scene Graph
Generation (SGG) methods to learn a holistic representation of the clinical
cerebral scene. To the best of our knowledge, this is the first application of
SGG for 3D voxel images. We evaluate our method on two head-CT datasets and
demonstrate that our model can recall up to 74% of clinically relevant
relations. This work lays the foundation towards SGG for 3D voxel data. The
generated Scene Graphs can already provide insights for the clinician, but are
also valuable for all downstream tasks as a compact and interpretable
representation.

æè¦ï¼è¦åºè¡ (ICH) æ£èé¢è¨å¯è½å±åçå½ççæ³ï¼ç±æ¼å¯è½çè¨åºä½µç¼çï¼ä»¥æ£èçºä¸­å¿çåäººåæ²»çä»ç¶å·æææ°æ§ãåºæ¼æ·±åº¦å­¸ç¿çæ¹æ³å¯ä»¥ææåæå¸¸è¦ç²å¾çé ­é¨é»è¦æ·å±¤ææï¼ä»¥æ¯æè¨åºæ±ºç­å¶å®ãå¤§å¤æ¸æ©æå·¥ä½é½éä¸­å¨ ICH çæª¢æ¸¬ååå²ï¼ä½æ²æå° ICH åç¸é°å¤§è¦çµæ§ä¹éçè¤ééä¿é²è¡å»ºæ¨¡ãå¨éé å·¥ä½ä¸­ï¼æåè¨­è¨äºä¸ç¨®éå° ICH çå®¢è£½åç®æ¨æª¢æ¸¬æ¹æ³ï¼æåå°å¶èåºæ¼åå²çå ´æ¯åçæ (SGG) æ¹æ³çµåï¼ä»¥å­¸ç¿è¨åºè¦é¨å ´æ¯çæ´é«è¡¨å¾µãææåæç¥ï¼éæ¯ SGG ç¬¬ä¸æ¬¡æç¨æ¼ 3D é«ç´ å½±åãæåå¨å©åé ­é¨é»è¦æ·å±¤æææ¸æéä¸è©ä¼°æåçæ¨¡åï¼ä¸¦è­ææåçæ¨¡åå¯ä»¥å¬åé«é 74% çè¨åºç¸ééä¿ãéé å·¥ä½çº 3D é«ç´ æ¸æç SGG å¥ å®äºåºç¤ãçæçå ´æ¯åå·²ç¶å¯ä»¥çºè¨åºé«çæä¾è¦è§£ï¼ä½å°æ¼ææä¸æ¸¸ä»»åèè¨ï¼å®ä¹æ¯ä¸ç¨®ç²¾ç°¡ä¸å¯è§£éçè¡¨å¾µï¼å æ­¤éå¸¸æå¹å¼ã

##### **Expanding the Medical Decathlon dataset: segmentation of colon and colorectal cancer from computed tomography images**
2407.21516v1 by I. M. Chernenkiy, Y. A. Drach, S. R. Mustakimova, V. V. Kazantseva, N. A. Ushakov, S. K. Efetov, M. V. Feldsherov

Colorectal cancer is the third-most common cancer in the Western Hemisphere.
The segmentation of colorectal and colorectal cancer by computed tomography is
an urgent problem in medicine. Indeed, a system capable of solving this problem
will enable the detection of colorectal cancer at early stages of the disease,
facilitate the search for pathology by the radiologist, and significantly
accelerate the process of diagnosing the disease. However, scientific
publications on medical image processing mostly use closed, non-public data.
This paper presents an extension of the Medical Decathlon dataset with
colorectal markups in order to improve the quality of segmentation algorithms.
An experienced radiologist validated the data, categorized it into subsets by
quality, and published it in the public domain. Based on the obtained results,
we trained neural network models of the UNet architecture with 5-part
cross-validation and achieved a Dice metric quality of $0.6988 \pm 0.3$. The
published markups will improve the quality of colorectal cancer detection and
simplify the radiologist's job for study description.

æè¦ï¼å¤§è¸çæ¯è¥¿åçç¬¬ä¸å¸¸è¦çççã
å©ç¨é»è¦æ·å±¤ææå°å¤§è¸çèå¤§è¸çé²è¡åæ®µæ¯é«å­¸ä¸çç·æ¥åé¡ãäºå¯¦ä¸ï¼ä¸åè½å¤ è§£æ±ºéååé¡çç³»çµ±å°è½å¤ å¨ç¾ççæ©æéæ®µåµæ¸¬å¤§è¸çï¼åå©æ¾å°ç§é«å¸«å°æ¾ççï¼ä¸¦é¡¯èå éè¨ºæ·ç¾ççéç¨ãç¶èï¼éæ¼é«å­¸å½±åèççç§å­¸åç©å¤§å¤ä½¿ç¨å°éãéå¬éçè³æãéç¯è«ææåºäºä¸åå¸¶æå¤§è¸æ¨è¨çé«å­¸åé å¨è½è³æéçå»¶ä¼¸ï¼ä»¥æé«åæ®µæ¼ç®æ³çåè³ªãä¸ä½ç¶é©è±å¯çæ¾å°ç§é«å¸«é©è­äºè³æï¼å°å¶ä¾åè³ªåé¡æå­éï¼ä¸¦å°å¶ç¼å¸å¨å¬å±é åãæ ¹æç²å¾ççµæï¼æåè¨ç·´äºå·æ 5 é¨åäº¤åé©è­ç UNet æ¶æ§çç¥ç¶ç¶²è·¯æ¨¡åï¼ä¸¦éå°äº $0.6988 \pm 0.3$ ç Dice ææ¨åè³ªãç¼å¸çæ¨è¨å°æé«å¤§è¸çåµæ¸¬çåè³ªï¼ä¸¦ç°¡åæ¾å°ç§é«å¸«ç ç©¶æè¿°çå·¥ä½ã

##### **Explainable and Controllable Motion Curve Guided Cardiac Ultrasound Video Generation**
2407.21490v1 by Junxuan Yu, Rusi Chen, Yongsong Zhou, Yanlin Chen, Yaofei Duan, Yuhao Huang, Han Zhou, Tan Tao, Xin Yang, Dong Ni

Echocardiography video is a primary modality for diagnosing heart diseases,
but the limited data poses challenges for both clinical teaching and machine
learning training. Recently, video generative models have emerged as a
promising strategy to alleviate this issue. However, previous methods often
relied on holistic conditions during generation, hindering the flexible
movement control over specific cardiac structures. In this context, we propose
an explainable and controllable method for echocardiography video generation,
taking an initial frame and a motion curve as guidance. Our contributions are
three-fold. First, we extract motion information from each heart substructure
to construct motion curves, enabling the diffusion model to synthesize
customized echocardiography videos by modifying these curves. Second, we
propose the structure-to-motion alignment module, which can map semantic
features onto motion curves across cardiac structures. Third, The
position-aware attention mechanism is designed to enhance video consistency
utilizing Gaussian masks with structural position information. Extensive
experiments on three echocardiography datasets show that our method outperforms
others regarding fidelity and consistency. The full code will be released at
https://github.com/mlmi-2024-72/ECM.

æè¦ï¼è¶é³æ³¢å¿ååå½±çæ¯è¨ºæ·å¿èç¾ççä¸»è¦æ¹å¼ï¼
ä½æéçæ¸æå°è¨åºæå­¸åæ©å¨å­¸ç¿è¨ç·´é½æ§æææ°ãæè¿ï¼å½±ççææ¨¡åå·²æçºç·©è§£æ­¤åé¡çä¸ç¨®æåéçç­ç¥ãç¶èï¼ååçè¾¦æ³å¨çæéç¨ä¸­éå¸¸ä¾è³´æ´é«æ¢ä»¶ï¼é»ç¤äºå°ç¹å®å¿èçµæ§çéæ´»éåæ§å¶ãå¨æ­¤èæ¯ä¸ï¼æåæåºäºä¸ç¨®å¯è§£éä¸å¯æ§çè¶é³æ³¢å¿ååå½±ççææ¹æ³ï¼ä»¥åå§å¹åéåæ²ç·ä½çºæå°ãæåçè²¢ç»æä¸æ¹é¢ãé¦åï¼æåå¾æ¯åå¿èå­çµæ§ä¸­æåéåè³è¨ä»¥å»ºæ§éåæ²ç·ï¼è®æ´æ£æ¨¡åè½å¤ ééä¿®æ¹éäºæ²ç·ä¾åæå®¢è£½åçè¶é³æ³¢å¿ååå½±çãå¶æ¬¡ï¼æåæåºäºçµæ§å°éåå°é½æ¨¡çµï¼å®å¯ä»¥å°èªç¾©ç¹å¾µå°æå°å¿èçµæ§ä¸­çéåæ²ç·ãç¬¬ä¸ï¼ä½ç½®æç¥æ³¨æåæ©å¶æ¨å¨å©ç¨å·æçµæ§ä½ç½®è³è¨çé«æ¯é®ç½©ä¾å¢å¼·å½±ççä¸è´æ§ãå¨ä¸åè¶é³æ³¢å¿ååè³æéä¸çå»£æ³å¯¦é©é¡¯ç¤ºï¼æåçè¾¦æ³å¨ä¿çåº¦åä¸è´æ§æ¹é¢åªæ¼å¶ä»è¾¦æ³ãå®æ´ç¨å¼ç¢¼å°å¨ https://github.com/mlmi-2024-72/ECM ä¸éåºã

##### **Deep Learning-Based Longitudinal Prediction of Childhood Myopia Progression Using Fundus Image Sequences and Baseline Refraction Data**
2407.21467v1 by Mengtian Kang, Yansong Hu, Shuo Gao, Yuanyuan Liu, Hongbei Meng, Xuemeng Li, Xuhang Chen, Hubin Zhao, Jing Fu, Guohua Hu, Wei Wang, Yanning Dai, Arokia Nathan, Peter Smielewski, Ningli Wang, Shiming Li

Childhood myopia constitutes a significant global health concern. It exhibits
an escalating prevalence and has the potential to evolve into severe,
irreversible conditions that detrimentally impact familial well-being and
create substantial economic costs. Contemporary research underscores the
importance of precisely predicting myopia progression to enable timely and
effective interventions, thereby averting severe visual impairment in children.
Such predictions predominantly rely on subjective clinical assessments, which
are inherently biased and resource-intensive, thus hindering their widespread
application. In this study, we introduce a novel, high-accuracy method for
quantitatively predicting the myopic trajectory and myopia risk in children
using only fundus images and baseline refraction data. This approach was
validated through a six-year longitudinal study of 3,408 children in Henan,
utilizing 16,211 fundus images and corresponding refractive data. Our method
based on deep learning demonstrated predictive accuracy with an error margin of
0.311D per year and AUC scores of 0.944 and 0.995 for forecasting the risks of
developing myopia and high myopia, respectively. These findings confirm the
utility of our model in supporting early intervention strategies and in
significantly reducing healthcare costs, particularly by obviating the need for
additional metadata and repeated consultations. Furthermore, our method was
designed to rely only on fundus images and refractive error data, without the
need for meta data or multiple inquiries from doctors, strongly reducing the
associated medical costs and facilitating large-scale screening. Our model can
even provide good predictions based on only a single time measurement.
Consequently, the proposed method is an important means to reduce medical
inequities caused by economic disparities.

æè¦ï¼åç«¥è¿è¦æ§æå¨çéè¦çå¥åº·åé¡ãå®é¡¯ç¤ºåºæ¥çå¢å ççè¡çï¼ä¸¦å¯è½æ¼è®æå´éãä¸å¯éè½ççæ³ï¼å°å®¶åº­ç¦ç¥é æä¸å©å½±é¿ï¼ä¸¦ç¢çå¤§éçç¶æ¿ææ¬ãç¾ä»£ç ç©¶å¼·èª¿ç²¾æºé æ¸¬è¿è¦é²å±çéè¦æ§ï¼ä»¥å¯¦ç¾åæææçå¹²é ï¼å¾èé¿ååç«¥åºç¾å´éçè¦åæå®³ãæ­¤é¡é æ¸¬ä¸»è¦ä¾è³´ä¸»è§çè¨åºè©ä¼°ï¼å¶æ¬èº«å·æåè¦ä¸è³æºå¯éï¼å¾èé»ç¤äºå®åçå»£æ³æç¨ãå¨æ¬ç ç©¶ä¸­ï¼æåå¼å¥äºä¸ç¨®æ°ç©ãé«ç²¾ç¢ºåº¦çæ¹æ³ï¼åä½¿ç¨ç¼åºååååºç·å±åæ¸æï¼å°±è½å®éé æ¸¬åç«¥çè¿è¦è»è·¡åè¿è¦é¢¨éªãéç¨®æ¹æ³ééå°æ²³åç 3,408 ååç«¥é²è¡çºæå­å¹´çç¸±åç ç©¶ï¼å©ç¨ 16,211 å¼µç¼åºåååç¸æçå±åæ¸æé²è¡äºé©è­ãæååºæ¼æ·±åº¦å­¸ç¿çæ¹æ³å±ç¤ºäºé æ¸¬æºç¢ºåº¦ï¼å¹´èª¤å·®ç¯åçº 0.311Dï¼é æ¸¬ç¼çè¿è¦åé«åº¦è¿è¦çé¢¨éªç AUC åæ¸åå¥çº 0.944 å 0.995ãéäºç¼ç¾è­å¯¦äºæåçæ¨¡åå¨æ¯ææ©æå¹²é ç­ç¥åé¡¯èéä½é«çä¿å¥ææ¬æ¹é¢çæç¨ï¼ç¹å¥æ¯ééæ¶é¤å°é¡å¤åæ¸æåéè¤è«®è©¢çéè¦ãæ­¤å¤ï¼æåçæ¹æ³è¢«è¨­è¨çºåä¾è³´ç¼åºåååå±åä¸æ­£æ¸æï¼èç¡éåæ¸ææé«ççå¤æ¬¡è©¢åï¼å¾èå¤§å¤§éä½äºç¸éçé«çææ¬ï¼ä¸¦ä¿é²äºå¤§è¦æ¨¡ç¯©æ¥ãæåçæ¨¡åçè³å¯ä»¥åæ ¹æå®æ¬¡æéæ¸¬éæä¾è¯å¥½çé æ¸¬ãå æ­¤ï¼ææåºçæ¹æ³æ¯æ¸å°ç±ç¶æ¿å·®è·é æçé«çä¸å¹³ç­çéè¦ææ®µã

##### **Prompting Medical Large Vision-Language Models to Diagnose Pathologies by Visual Question Answering**
2407.21368v1 by Danfeng Guo, Demetri Terzopoulos

Large Vision-Language Models (LVLMs) have achieved significant success in
recent years, and they have been extended to the medical domain. Although
demonstrating satisfactory performance on medical Visual Question Answering
(VQA) tasks, Medical LVLMs (MLVLMs) suffer from the hallucination problem,
which makes them fail to diagnose complex pathologies. Moreover, they readily
fail to learn minority pathologies due to imbalanced training data. We propose
two prompting strategies for MLVLMs that reduce hallucination and improve VQA
performance. In the first strategy, we provide a detailed explanation of the
queried pathology. In the second strategy, we fine-tune a cheap, weak learner
to achieve high performance on a specific metric, and textually provide its
judgment to the MLVLM. Tested on the MIMIC-CXR-JPG and Chexpert datasets, our
methods significantly improve the diagnostic F1 score, with the highest
increase being 0.27. We also demonstrate that our prompting strategies can be
extended to general LVLM domains. Based on POPE metrics, it effectively
suppresses the false negative predictions of existing LVLMs and improves Recall
by approximately 0.07.

æè¦ï¼å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) å¨è¿å¹´ä¾åå¾é¡¯èçæåï¼ä¸¦å·²æ´å±å°é«çé åãåç®¡å¨é«å­¸è¦è¦ºåç­ (VQA) ä»»åä¸­è¡¨ç¾ä»¤äººæ»¿æï¼ä½é«å­¸ LVLMs (MLVLMs) ä»å­å¨å¹»è¦ºåé¡ï¼å°è´å®åç¡æ³è¨ºæ·åºè¤éçççãæ­¤å¤ï¼ç±æ¼è¨ç·´è³æä¸å¹³è¡¡ï¼å®åå¾å®¹æç¡æ³å­¸ç¿å°æ¸ççãæåæåºå©ç¨®éå° MLVLMs çæç¤ºç­ç¥ï¼ä»¥æ¸å°å¹»è¦ºä¸¦æ¹å VQA æè½ãå¨ç¬¬ä¸åç­ç¥ä¸­ï¼æåæä¾æ¥è©¢çççè©³ç´°èªªæãå¨ç¬¬äºåç­ç¥ä¸­ï¼æåå¾®èª¿ä¸åä¾¿å®ãæè½ä¸ä½³çå­¸ç¿å¨ï¼ä»¥å¨ç¹å®ææ¨ä¸ç²å¾é«æè½ï¼ä¸¦ä»¥æå­æ¹å¼å MLVLM æä¾å¶å¤æ·ãå¨ MIMIC-CXR-JPG å Chexpert è³æéä¸é²è¡æ¸¬è©¦å¾ï¼æåçæ¨¡åé¡¯èæ¹åäºè¨ºæ· F1 åæ¸ï¼æé«æåå¹åº¦çº 0.27ãæåéå±ç¤ºäºæåçæç¤ºç­ç¥å¯ä»¥æ´å±å°ä¸è¬ç LVLM é åãæ ¹æ POPE ææ¨ï¼å®ææå°æå¶äºç¾æ LVLMs çåé°æ§é æ¸¬ï¼ä¸¦å°å¬åçæé«äºç´ 0.07ã

##### **MIST: A Simple and Scalable End-To-End 3D Medical Imaging Segmentation Framework**
2407.21343v1 by Adrian Celaya, Evan Lim, Rachel Glenn, Brayden Mi, Alex Balsells, Tucker Netherton, Caroline Chung, Beatrice Riviere, David Fuentes

Medical imaging segmentation is a highly active area of research, with deep
learning-based methods achieving state-of-the-art results in several
benchmarks. However, the lack of standardized tools for training, testing, and
evaluating new methods makes the comparison of methods difficult. To address
this, we introduce the Medical Imaging Segmentation Toolkit (MIST), a simple,
modular, and end-to-end medical imaging segmentation framework designed to
facilitate consistent training, testing, and evaluation of deep learning-based
medical imaging segmentation methods. MIST standardizes data analysis,
preprocessing, and evaluation pipelines, accommodating multiple architectures
and loss functions. This standardization ensures reproducible and fair
comparisons across different methods. We detail MIST's data format
requirements, pipelines, and auxiliary features and demonstrate its efficacy
using the BraTS Adult Glioma Post-Treatment Challenge dataset. Our results
highlight MIST's ability to produce accurate segmentation masks and its
scalability across multiple GPUs, showcasing its potential as a powerful tool
for future medical imaging research and development.

æè¦ï¼é«å­¸å½±ååå²æ¯ä¸åé«åº¦æ´»èºçç ç©¶é åï¼æ·±åº¦å­¸ç¿æ¹æ³å¨å¤ååºæºæ¸¬è©¦ä¸­åå¾äºæåé²çææãç¶èï¼ç¼ºä¹æ¨æºåçè¨ç·´ãæ¸¬è©¦åè©ä¼°æ°æ¹æ³çå·¥å·ï¼ä½¿å¾æ¹æ³çæ¯è¼è®å¾å°é£ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äºé«å­¸å½±ååå²å·¥å·å (MIST)ï¼ä¸åç°¡å®ãæ¨¡çµååç«¯å°ç«¯çé«å­¸å½±ååå²æ¡æ¶ï¼æ¨å¨ä¿é²åºæ¼æ·±åº¦å­¸ç¿çé«å­¸å½±ååå²æ¹æ³çä¸è´è¨ç·´ãæ¸¬è©¦åè©ä¼°ãMIST æ¨æºåäºæ¸æåæãé èçåè©ä¼°ç®¡éï¼å®¹ç´å¤ç¨®æ¶æ§åæå¤±å½æ¸ãéç¨®æ¨æºåç¢ºä¿äºä¸åæ¹æ³ä¹éå¯éç¾ä¸å¬å¹³çæ¯è¼ãæåè©³ç´°èªªæäº MIST çæ¸ææ ¼å¼è¦æ±ãç®¡éåè¼å©åè½ï¼ä¸¦ä½¿ç¨ BraTS æäººç¥ç¶è è³ªç¤æ²»çå¾ææ°æ¸æéå±ç¤ºäºå®çåæãæåççµæçªé¡¯äº MIST ç¢çæºç¢ºåå²é®ç½©çè½åä»¥åå®è·¨å¤å GPU çå¯æ´å±æ§ï¼å±ç¤ºäºå®ä½çºæªä¾é«å­¸å½±åç ç©¶åéç¼çæåå·¥å·çæ½åã

##### **Patient-centered data science: an integrative framework for evaluating and predicting clinical outcomes in the digital health era**
2408.02677v1 by Mohsen Amoei, Dan Poenaru

This study proposes a novel, integrative framework for patient-centered data
science in the digital health era. We developed a multidimensional model that
combines traditional clinical data with patient-reported outcomes, social
determinants of health, and multi-omic data to create comprehensive digital
patient representations. Our framework employs a multi-agent artificial
intelligence approach, utilizing various machine learning techniques including
large language models, to analyze complex, longitudinal datasets. The model
aims to optimize multiple patient outcomes simultaneously while addressing
biases and ensuring generalizability. We demonstrate how this framework can be
implemented to create a learning healthcare system that continuously refines
strategies for optimal patient care. This approach has the potential to
significantly improve the translation of digital health innovations into
real-world clinical benefits, addressing current limitations in AI-driven
healthcare models.

æè¦ï¼æ¬ç ç©¶æåºäºä¸ååµæ°çãæ´åæ§çæ¶æ§ï¼ç¨æ¼æ¸ä½å¥åº·æä»£çä»¥æ£èçºä¸­å¿çè³æç§å­¸ãæåéç¼äºä¸åå¤é¢åæ¨¡åï¼çµåå³çµ±çè¨åºè³æãæ£èåå ±ççµæãå¥åº·çç¤¾ææ±ºå®å ç´ åå¤çµå­¸è³æï¼ä»¥å»ºç«å¨é¢çæ¸ä½æ£èè¡¨å¾µãæåçæ¶æ§æ¡ç¨å¤ä¸»é«äººå·¥æºæ§æ¹æ³ï¼å©ç¨åç¨®æ©å¨å­¸ç¿æè¡ï¼åæ¬å¤§åèªè¨æ¨¡åï¼ä¾åæè¤éçç¸±åè³æéãè©²æ¨¡åæ¨å¨åææä½³åå¤åæ£èçµæï¼åæè§£æ±ºåå·®ä¸¦ç¢ºä¿å¯æ¦åæ§ãæåå±ç¤ºäºå¦ä½å¯¦ä½æ­¤æ¶æ§ï¼ä»¥å»ºç«ä¸åæçºåªåæä½³æ£èç§è­·ç­ç¥çå­¸ç¿åé«çä¿å¥ç³»çµ±ãæ­¤æ¹æ³æå¯è½é¡¯èæ¹åæ¸ä½å¥åº·åµæ°çè½è­¯ï¼ä½¿å¶æçºçå¯¦ä¸ççè¨åºæçï¼è§£æ±º AI é©åçé«çä¿å¥æ¨¡åä¸­çç¶åéå¶ã

##### **Robust Box Prompt based SAM for Medical Image Segmentation**
2407.21284v1 by Yuhao Huang, Xin Yang, Han Zhou, Yan Cao, Haoran Dou, Fajin Dong, Dong Ni

The Segment Anything Model (SAM) can achieve satisfactory segmentation
performance under high-quality box prompts. However, SAM's robustness is
compromised by the decline in box quality, limiting its practicality in
clinical reality. In this study, we propose a novel Robust Box prompt based SAM
(\textbf{RoBox-SAM}) to ensure SAM's segmentation performance under prompts
with different qualities. Our contribution is three-fold. First, we propose a
prompt refinement module to implicitly perceive the potential targets, and
output the offsets to directly transform the low-quality box prompt into a
high-quality one. We then provide an online iterative strategy for further
prompt refinement. Second, we introduce a prompt enhancement module to
automatically generate point prompts to assist the box-promptable segmentation
effectively. Last, we build a self-information extractor to encode the prior
information from the input image. These features can optimize the image
embeddings and attention calculation, thus, the robustness of SAM can be
further enhanced. Extensive experiments on the large medical segmentation
dataset including 99,299 images, 5 modalities, and 25 organs/targets validated
the efficacy of our proposed RoBox-SAM.

æè¦ï¼åæ®µä»»ä½æ¨¡å (SAM) å¯ä»¥å¨é«è´¨éæ¡æç¤ºä¸å®ç°ä»¤äººæ»¡æçåæ®µæ§è½ãç¶èï¼SAM çé²æ£æ§å æ¡è´¨éçä¸éèåå°æå®³ï¼éå¶äºå¶å¨ä¸´åºç°å®ä¸­çå®ç¨æ§ãå¨è¿é¡¹ç ç©¶ä¸­ï¼æä»¬æåºäºä¸ä¸ªåºäº SAM çæ°åé²æ£æ¡æç¤ºï¼**RoBox-SAM**ï¼ï¼ä»¥ç¡®ä¿ SAM å¨å·æä¸åè´¨éçæç¤ºä¸çåæ®µæ§è½ãæä»¬çè´¡ç®æ¯ä¸æ¹é¢çãé¦åï¼æä»¬æåºä¸ä¸ªæç¤ºä¼åæ¨¡åï¼ä»¥éå¼æç¥æ½å¨ç®æ ï¼å¹¶è¾åºåç§»éï¼ä»¥ç´æ¥å°ä½è´¨éæ¡æç¤ºè½¬æ¢ä¸ºé«è´¨éæç¤ºãç¶åï¼æä»¬æä¾äºä¸ä¸ªå¨çº¿è¿­ä»£ç­ç¥ï¼ä»¥ä¾¿è¿ä¸æ­¥ä¼åæç¤ºãå¶æ¬¡ï¼æä»¬å¼å¥äºä¸ä¸ªæç¤ºå¢å¼ºæ¨¡åï¼ä»¥èªå¨çæç¹æç¤ºï¼ä»¥ææå°è¾å©æ¡æç¤ºåæ®µãæåï¼æä»¬æå»ºäºä¸ä¸ªèªä¿¡æ¯æåå¨ï¼ä»¥å¯¹æ¥èªè¾å¥å¾åçåéªä¿¡æ¯è¿è¡ç¼ç ãè¿äºç¹å¾å¯ä»¥ä¼åå¾ååµå¥åæ³¨æåè®¡ç®ï¼å æ­¤ï¼å¯ä»¥è¿ä¸æ­¥å¢å¼º SAM çé²æ£æ§ãå¨åæ¬ 99,299 å¼ å¾åã5 ç§æ¹å¼å 25 ä¸ªå¨å®/ç®æ çå¤§åå»å­¦åæ®µæ°æ®éä¸è¿è¡çå¹¿æ³å®éªéªè¯äºæä»¬æåºç RoBox-SAM çåæã

##### **Unlocking the Potential of Binding Corporate Rules (BCRs) in Health Data Transfers**
2407.21281v1 by Marcelo Corrales Compagnucci, Mark Fenwick, Helena Haapio

This chapter explores the essential role of Binding Corporate Rules (BCRs) in
managing and facilitating secure health data transfers within corporate groups
under the EU General Data Protection Regulation (GDPR). BCRs are tailored to
ensure compliance with the GDPR and similar international data protection laws,
presenting a flexible mechanism for transferring sensitive health and genomic
data. The chapter situates BCRs within the broader spectrum of the GDPR
international data transfer mechanisms, addressing the unique challenges posed
by the sensitive nature of health data and the increased adoption of AI
technologies. The European Data Protection Board (EDPB) Recommendations 1/2022
on BCRs, issued following the Schrems II decision, are critically analyzed,
highlighting their stringent requirements and the need for a balanced approach
that prioritizes data protection and an AI governance framework. The chapter
outlines the BCR approval process, stressing the importance of streamlining
this process to encourage broader adoption. It underscores the necessity of a
multidisciplinary approach in developing BCRs, incorporating recently adopted
international standards and frameworks, which offer valuable guidance for
organizations to build trustworthy AI management systems. They guarantee the
ethical development, deployment, and operation of AI, which is essential for
its successful integration and the broader digital transformation. In
conclusion, BCRs are positioned as essential tools for secure health data
management, fostering transparency, accountability, and collaboration across
international borders. The chapter calls for proactive measures to incentivize
BCR adoption, streamline approval processes, and promote more innovative
approaches, ensuring BCRs remain a robust mechanism for global data protection
and compliance.

æè¦ï¼<paragraph>æ­¤ç« æ¢è¨ç´æä¼æ¥­è¦å (BCR) å¨æ­çä¸è¬è³æä¿è­·æ¢ä¾ (GDPR) ä¸ç®¡çåä¿é²ä¼æ¥­éåå§é¨å®å¨å¥åº·è³æå³è¼¸çåºæ¬è§è²ãBCR å°éç¨æ¼ç¢ºä¿ç¬¦å GDPR åé¡ä¼¼çåéè³æä¿è­·æ³ï¼æä¾å³è¼¸ææå¥åº·ååºå çµè³æçå½æ§æ©å¶ãæ­¤ç« å° BCR å®ä½å¨ GDPR åéè³æå³è¼¸æ©å¶çæ´å»£æ³ç¯åå§ï¼è§£æ±ºå¥åº·è³ææææ§è³ªå AI æè¡æ¡ç¨å¢å æå¸¶ä¾çç¨ç¹ææ°ãæ­æ´²è³æä¿è­·å§å¡æ (EDPB) å¨ Schrems II æ±ºå®å¾ç¼å¸ç BCR å»ºè­° 1/2022 åå°å´æ ¼åæï¼å¼·èª¿å¶å´æ ¼è¦æ±åå¹³è¡¡æ¹æ³çå¿è¦æ§ï¼è©²æ¹æ³åªåèæ®è³æä¿è­·å AI æ²»çæ¶æ§ãæ­¤ç« æ¦è¿° BCR æ ¸åç¨åºï¼å¼·èª¿ç°¡åæ­¤ç¨åºä»¥é¼åµæ´å»£æ³æ¡ç¨çéè¦æ§ãå®å¼·èª¿å¨éç¼ BCR ææ¡ç¨å¤å­¸ç§æ¹æ³çå¿è¦æ§ï¼åæ¬æè¿æ¡ç¨çåéæ¨æºåæ¶æ§ï¼éäºæ¨æºåæ¶æ§çºçµç¹å»ºç«å¯ä¿¡è³´ç AI ç®¡çç³»çµ±æä¾äºå¯¶è²´çæå°ãå®åä¿è­ AI çéå¾·éç¼ãé¨ç½²åéä½ï¼éå°å¶æåæ´ååæ´å»£æ³çæ¸ä½è½åè³ééè¦ãçµè«æ¯ï¼BCR è¢«å®ä½çºå®å¨å¥åº·è³æç®¡ççåºæ¬å·¥å·ï¼ä¿é²è·¨åççéæåº¦ãåè²¬å¶ååä½ãæ­¤ç« å¼ç±²æ¡åç©æ¥µæªæ½ä¾æ¿åµ BCR æ¡ç¨ãç°¡åæ ¸åç¨åºï¼ä¸¦ä¿é²æ´å·åµæ°çæ¹æ³ï¼ç¢ºä¿ BCR ä»ç¶æ¯å¨çè³æä¿è­·ååè¦æ§çå¼·å¤§æ©å¶ã</paragraph>

##### **FreqTSF: Time Series Forecasting Via Simulating Frequency Kramer-Kronig Relations**
2407.21275v1 by Rujia Shen, Liangliang Liu, Boran Wang, Yi Guan, Yang Yang, Jingchi Jiang

Time series forecasting (TSF) is immensely important in extensive
applications, such as electricity transformation, financial trade, medical
monitoring, and smart agriculture. Although Transformer-based methods can
handle time series data, their ability to predict long-term time series is
limited due to the ``anti-order" nature of the self-attention mechanism. To
address this problem, we focus on frequency domain to weaken the impact of
order in TSF and propose the FreqBlock, where we first obtain frequency
representations through the Frequency Transform Module. Subsequently, a newly
designed Frequency Cross Attention is used to obtian enhanced frequency
representations between the real and imaginary parts, thus establishing a link
between the attention mechanism and the inherent Kramer-Kronig relations
(KKRs). Our backbone network, FreqTSF, adopts a residual structure by
concatenating multiple FreqBlocks to simulate KKRs in the frequency domain and
avoid degradation problems. On a theoretical level, we demonstrate that the
proposed two modules can significantly reduce the time and memory complexity
from $\mathcal{O}(L^2)$ to $\mathcal{O}(L)$ for each FreqBlock computation.
Empirical studies on four benchmark datasets show that FreqTSF achieves an
overall relative MSE reduction of 15\% and an overall relative MAE reduction of
11\% compared to the state-of-the-art methods. The code will be available soon.

æè¦ï¼æéåºåé æ¸¬ (TSF) å¨å»£æ³çæç¨ä¸­éå¸¸éè¦ï¼ä¾å¦é»åè½æãéèäº¤æãé«çç£æ§åæºæ§è¾²æ¥­ãéç¶åºæ¼ Transformer çæ¹æ³å¯ä»¥èçæéåºåè³æï¼ä½ç±æ¼èªæ³¨æåæ©å¶çãååºãç¹æ§ï¼å®åé æ¸¬é·ææéåºåçè½ååå°éå¶ãçºäºè§£æ±ºéååé¡ï¼æåå°æ³¨æ¼é »åä»¥æ¸å¼± TSF ä¸­é åºçå½±é¿ï¼ä¸¦æåº FreqBlockï¼æåé¦åééé »çè½ææ¨¡çµåå¾é »çè¡¨ç¤ºãé¨å¾ï¼ä½¿ç¨æ°è¨­è¨çé »çäº¤åæ³¨æåä¾ç²å¾å¯¦é¨åèé¨ä¹éå¢å¼·çé »çè¡¨ç¤ºï¼å¾èå»ºç«æ³¨æåæ©å¶ååºæ Kramer-Kronig éä¿ (KKR) ä¹éçé£çµãæåçéª¨å¹¹ç¶²è·¯ FreqTSF æ¡ç¨æ®å·®çµæ§ï¼ééä¸²æ¥å¤å FreqBlock ä¾æ¨¡æ¬é »åä¸­ç KKR ä¸¦é¿åéååé¡ãå¨çè«å±¤é¢ä¸ï¼æåè­æææåºçå©åæ¨¡çµå¯ä»¥é¡¯èéä½æ¯å FreqBlock è¨ç®çæéåè¨æ¶é«è¤éåº¦ï¼å¾ $\mathcal{O}(L^2)$ éä½å° $\mathcal{O}(L)$ãå¨åååºæºè³æéä¸çå¯¦è­ç ç©¶é¡¯ç¤ºï¼èæåé²çæ¹æ³ç¸æ¯ï¼FreqTSF çæ´é«ç¸å° MSE éä½ 15%ï¼æ´é«ç¸å° MAE éä½ 11%ãç¨å¼ç¢¼å°å¾å¿«æ¨åºã

##### **Enhanced Uncertainty Estimation in Ultrasound Image Segmentation with MSU-Net**
2407.21273v1 by Rohini Banerjee, Cecilia G. Morales, Artur Dubrawski

Efficient intravascular access in trauma and critical care significantly
impacts patient outcomes. However, the availability of skilled medical
personnel in austere environments is often limited. Autonomous robotic
ultrasound systems can aid in needle insertion for medication delivery and
support non-experts in such tasks. Despite advances in autonomous needle
insertion, inaccuracies in vessel segmentation predictions pose risks.
Understanding the uncertainty of predictive models in ultrasound imaging is
crucial for assessing their reliability. We introduce MSU-Net, a novel
multistage approach for training an ensemble of U-Nets to yield accurate
ultrasound image segmentation maps. We demonstrate substantial improvements,
18.1% over a single Monte Carlo U-Net, enhancing uncertainty evaluations, model
transparency, and trustworthiness. By highlighting areas of model certainty,
MSU-Net can guide safe needle insertions, empowering non-experts to accomplish
such tasks.

æè¦ï¼å¨åµå·åéçç§è­·ä¸­ï¼ææçè¡ç®¡å§éè·¯æé¡¯èå½±é¿çæ£çæ²»ççµæãç¶èï¼å¨æ¡å£çç°å¢ä¸­ï¼çç·´çé«çäººå¡å¾å¾ä¸è¶³ãèªä¸»æ©å¨äººè¶é³æ³¢ç³»çµ±å¯ä»¥åå©éé ­æå¥ï¼ä»¥æä¾è¥ç©ä¸¦æ¯æ´éå°å®¶å·è¡æ­¤é¡ä»»åãåç®¡èªä¸»éé ­æå¥æè¡é²æ­¥ï¼ä½è¡ç®¡åå²é æ¸¬çä¸æºç¢ºæ§æé æé¢¨éªãäºè§£è¶é³æ³¢å½±åä¸­é æ¸¬æ¨¡åçä¸ç¢ºå®æ§ï¼å°æ¼è©ä¼°å¶å¯é æ§è³ééè¦ãæåå¼é² MSU-Netï¼éæ¯ä¸ç¨®æ°ç©çå¤éæ®µæ¹æ³ï¼ç¨æ¼è¨ç·´ä¸çµ U-Net ä»¥ç¢çæºç¢ºçè¶é³æ³¢å½±ååå²åãæåå±ç¤ºäºå¤§å¹æ¹åï¼æ¯å®ä¸çèå°å¡ç¾ U-Net æ¹åäº 18.1%ï¼å¢å¼·äºä¸ç¢ºå®æ§è©ä¼°ãæ¨¡åéæåº¦åå¯ä¿¡åº¦ãééå¼·èª¿æ¨¡åç¢ºå®æ§çååï¼MSU-Net å¯ä»¥å¼å°å®å¨çéé ­æå¥ï¼è®éå°å®¶ä¹è½å·è¡æ­¤é¡ä»»åã

##### **Domain Shift Analysis in Chest Radiographs Classification in a Veterans Healthcare Administration Population**
2407.21149v1 by Mayanka Chandrashekar, Ian Goethert, Md Inzamam Ul Haque, Benjamin McMahon, Sayera Dhaubhadel, Kathryn Knight, Joseph Erdos, Donna Reagan, Caroline Taylor, Peter Kuzmak, John Michael Gaziano, Eileen McAllister, Lauren Costa, Yuk-Lam Ho, Kelly Cho, Suzanne Tamang, Samah Fodeh-Jarad, Olga S. Ovchinnikova, Amy C. Justice, Jacob Hinkle, Ioana Danciu

Objectives: This study aims to assess the impact of domain shift on chest
X-ray classification accuracy and to analyze the influence of ground truth
label quality and demographic factors such as age group, sex, and study year.
Materials and Methods: We used a DenseNet121 model pretrained MIMIC-CXR dataset
for deep learning-based multilabel classification using ground truth labels
from radiology reports extracted using the CheXpert and CheXbert Labeler. We
compared the performance of the 14 chest X-ray labels on the MIMIC-CXR and
Veterans Healthcare Administration chest X-ray dataset (VA-CXR). The VA-CXR
dataset comprises over 259k chest X-ray images spanning between the years 2010
and 2022. Results: The validation of ground truth and the assessment of
multi-label classification performance across various NLP extraction tools
revealed that the VA-CXR dataset exhibited lower disagreement rates than the
MIMIC-CXR datasets. Additionally, there were notable differences in AUC scores
between models utilizing CheXpert and CheXbert. When evaluating multi-label
classification performance across different datasets, minimal domain shift was
observed in unseen datasets, except for the label "Enlarged Cardiomediastinum."
The study year's subgroup analyses exhibited the most significant variations in
multi-label classification model performance. These findings underscore the
importance of considering domain shifts in chest X-ray classification tasks,
particularly concerning study years. Conclusion: Our study reveals the
significant impact of domain shift and demographic factors on chest X-ray
classification, emphasizing the need for improved transfer learning and
equitable model development. Addressing these challenges is crucial for
advancing medical imaging and enhancing patient care.

æè¦ï¼<paragraph>ç®æ¨ï¼æ¬ç ç©¶æ¨å¨è©ä¼°é åè½ç§»å°è¸é¨ X ååé¡ç²¾åº¦çå½±é¿ï¼ä¸¦åæåºæ¬äºå¯¦æ¨ç±¤åè³ªåå¹´é½¡çµãæ§å¥åç ç©¶å¹´ä»½ç­äººå£å ç´ çå½±é¿ã
ææåæ¹æ³ï¼æåä½¿ç¨ DenseNet121 æ¨¡åé è¨ç·´ MIMIC-CXR è³æéï¼ä½¿ç¨å¾ä½¿ç¨ CheXpert å CheXbert æ¨ç±¤å¨å¾æ¾å°ç§å ±åä¸­æåçåºæ¬äºå¯¦æ¨ç±¤é²è¡åºæ¼æ·±åº¦å­¸ç¿çå¤æ¨ç±¤åé¡ãæåæ¯è¼äº MIMIC-CXR åéä¼è»äººå¥åº·ç®¡çå±è¸é¨ X åè³æé (VA-CXR) ä¸ 14 åè¸é¨ X åæ¨ç±¤çæ§è½ãVA-CXR è³æéåå«è¶é 259k å¼µè¸é¨ X åå½±åï¼æéè·¨åº¦çº 2010 å¹´è³ 2022 å¹´ãçµæï¼åºæ¬äºå¯¦çé©è­åå°åç¨® NLP æåå·¥å·çå¤æ¨ç±¤åé¡æ§è½çè©ä¼°é¡¯ç¤ºï¼VA-CXR è³æéè¡¨ç¾åºçåæ­§çä½æ¼ MIMIC-CXR è³æéãæ­¤å¤ï¼ä½¿ç¨ CheXpert å CheXbert çæ¨¡åä¹éç AUC å¾åå­å¨é¡¯èå·®ç°ãå¨è©ä¼°ä¸åè³æéä¸çå¤æ¨ç±¤åé¡æ§è½æï¼é¤äºæ¨ç±¤ãå¿ç¸±éå¢å¤§ãä¹å¤ï¼å¨æªè¦è³æéä¸­è§å¯å°çé åè½ç§»å¾å°ãç ç©¶å¹´ä»½çå­ç¾¤åæé¡¯ç¤ºï¼å¤æ¨ç±¤åé¡æ¨¡åæ§è½è®åæå¤§ãéäºç¼ç¾å¼·èª¿äºå¨è¸é¨ X ååé¡ä»»åä¸­èæ®é åè½ç§»çéè¦æ§ï¼ç¹å¥æ¯éæ¼ç ç©¶å¹´ä»½ãçµè«ï¼æåçç ç©¶æ­ç¤ºäºé åè½ç§»åäººå£å ç´ å°è¸é¨ X ååé¡çé¡¯èå½±é¿ï¼å¼·èª¿äºæ¹é²é·ç§»å­¸ç¿åå¬å¹³æ¨¡åéç¼çå¿è¦æ§ãæå°éäºææ°å°æ¼æ¨é²é«å­¸å½±ååå å¼·æ£èè­·çè³ééè¦ã</paragraph>

##### **Zero Shot Health Trajectory Prediction Using Transformer**
2407.21124v1 by Pawel Renc, Yugang Jia, Anthony E. Samir, Jaroslaw Was, Quanzheng Li, David W. Bates, Arkadiusz Sitek

Integrating modern machine learning and clinical decision-making has great
promise for mitigating healthcare's increasing cost and complexity. We
introduce the Enhanced Transformer for Health Outcome Simulation (ETHOS), a
novel application of the transformer deep-learning architecture for analyzing
high-dimensional, heterogeneous, and episodic health data. ETHOS is trained
using Patient Health Timelines (PHTs)-detailed, tokenized records of health
events-to predict future health trajectories, leveraging a zero-shot learning
approach. ETHOS represents a significant advancement in foundation model
development for healthcare analytics, eliminating the need for labeled data and
model fine-tuning. Its ability to simulate various treatment pathways and
consider patient-specific factors positions ETHOS as a tool for care
optimization and addressing biases in healthcare delivery. Future developments
will expand ETHOS' capabilities to incorporate a wider range of data types and
data sources. Our work demonstrates a pathway toward accelerated AI development
and deployment in healthcare.

æè¦ï¼æ´åç¾ä»£æ©å¨å­¸ç¿èè¨åºæ±ºç­å¶å®å°æ¼æ¸è¼é«çä¿å¥æ¥çå¢å çææ¬åè¤éæ§å·æå¾å¤§çåæ¯ãæåå¼å¥äºå¥åº·çµææ¨¡æ¬çå¢å¼·å¼Transformerï¼ETHOSï¼ï¼éæ¯ä¸ç¨®Transformeræ·±åº¦å­¸ç¿æ¶æ§çæ°ç©æç¨ï¼ç¨æ¼åæé«ç¶­ãç°è³ªä¸æç¯æ§çå¥åº·æ¸æãETHOS ä½¿ç¨æ£èå¥åº·æéè»¸ (PHT) é²è¡è¨ç·´ï¼PHT æ¯å¥åº·äºä»¶çè©³ç´°ãæ¨è¨åè¨éï¼ç¨æ¼é æ¸¬æªä¾çå¥åº·è»è·¡ï¼ä¸¦å©ç¨é¶æ¬¡å­¸ç¿æ¹æ³ãETHOS ä»£è¡¨äºé«çä¿å¥åæåºç¤æ¨¡åéç¼çéå¤§é²å±ï¼æ¶é¤äºå°æ¨è¨æ¸æåæ¨¡åå¾®èª¿çéæ±ãå®æ¨¡æ¬åç¨®æ²»çéå¾ä¸¦èæ®æ£èç¹å®å ç´ çè½åï¼ä½¿ ETHOS æçºåªåç§è­·åè§£æ±ºé«çä¿å¥æä¾ä¸­åå·®çå·¥å·ãæªä¾çç¼å±å°æ´å± ETHOS çåè½ï¼ä»¥ç´å¥æ´å»£æ³çæ¸æé¡ååæ¸æä¾æºãæåçç ç©¶å±ç¤ºäºä¸æ¢å éé«çä¿å¥ä¸­ AI éç¼åé¨ç½²çéå¾ã

##### **CLEFT: Language-Image Contrastive Learning with Efficient Large Language Model and Prompt Fine-Tuning**
2407.21011v1 by Yuexi Du, Brian Chang, Nicha C. Dvornek

Recent advancements in Contrastive Language-Image Pre-training (CLIP) have
demonstrated notable success in self-supervised representation learning across
various tasks. However, the existing CLIP-like approaches often demand
extensive GPU resources and prolonged training times due to the considerable
size of the model and dataset, making them poor for medical applications, in
which large datasets are not always common. Meanwhile, the language model
prompts are mainly manually derived from labels tied to images, potentially
overlooking the richness of information within training samples. We introduce a
novel language-image Contrastive Learning method with an Efficient large
language model and prompt Fine-Tuning (CLEFT) that harnesses the strengths of
the extensive pre-trained language and visual models. Furthermore, we present
an efficient strategy for learning context-based prompts that mitigates the gap
between informative clinical diagnostic data and simple class labels. Our
method demonstrates state-of-the-art performance on multiple chest X-ray and
mammography datasets compared with various baselines. The proposed parameter
efficient framework can reduce the total trainable model size by 39% and reduce
the trainable language model to only 4% compared with the current BERT encoder.

æè¦ï¼å°æ¯èªè¨å½±åé è¨ç·´ (CLIP) çææ°é²å±å·²å±ç¾åºå¨åé ä»»åä¸­ä»¥èªæç£ç£è¡¨å¾µå­¸ç¿ç²å¾é¡¯èæåçææãç¶èï¼ç¾æç CLIP é¡ä¼¼æ¹æ³éå¸¸éè¦å¤§éç GPU è³æºåæ¼«é·çè¨ç·´æéï¼å çºæ¨¡ååè³æéçè¦æ¨¡é¾å¤§ï¼éä½¿å¾å®åä¸é©åé«çæç¨ï¼å çºé«çæç¨ä¸­ä¸¦ä¸ç¸½æ¯ææå¤§åè³æéãåæï¼èªè¨æ¨¡åæç¤ºä¸»è¦ä¾èªèå½±åç¸éçæ¨ç±¤ï¼èæåè¡çï¼éå¯è½æå¿½ç¥è¨ç·´æ¨£æ¬ä¸­è±å¯çè³è¨ãæåæåºä¸åæ°ç©çèªè¨å½±åå°æ¯å­¸ç¿æ¹æ³ï¼å¶ä¸­åå«ä¸åé«æçå¤§èªè¨æ¨¡ååæç¤ºå¾®èª¿ (CLEFT)ï¼å®å©ç¨äºå»£æ³é è¨ç·´çèªè¨åè¦è¦ºæ¨¡åçåªå¢ãæ­¤å¤ï¼æåæåºä¸åå­¸ç¿åºæ¼èçµ¡æç¤ºçææç­ç¥ï¼ä»¥ç¸®å°è³è¨è±å¯çè¨åºè¨ºæ·è³æåç°¡å®é¡å¥æ¨ç±¤ä¹éçå·®è·ãèåç¨®åºæºç¸æ¯ï¼æåçæ¨¡åå¨å¤åè¸é¨ X ååä¹³æ¿æå½±è³æéä¸å±ç¾åºæåé²çæè½ãææåºçåæ¸æææ¶æ§å¯ä»¥å°ç¸½é«å¯è¨ç·´æ¨¡åå¤§å°æ¸å° 39%ï¼ä¸¦å°å¯è¨ç·´èªè¨æ¨¡åæ¸å°å°å 4%ï¼èç®åç BERT ç·¨ç¢¼å¨ç¸æ¯ã

##### **Federated Knowledge Recycling: Privacy-Preserving Synthetic Data Sharing**
2407.20830v1 by Eugenio Lomurno, Matteo Matteucci

Federated learning has emerged as a paradigm for collaborative learning,
enabling the development of robust models without the need to centralise
sensitive data. However, conventional federated learning techniques have
privacy and security vulnerabilities due to the exposure of models, parameters
or updates, which can be exploited as an attack surface. This paper presents
Federated Knowledge Recycling (FedKR), a cross-silo federated learning approach
that uses locally generated synthetic data to facilitate collaboration between
institutions. FedKR combines advanced data generation techniques with a dynamic
aggregation process to provide greater security against privacy attacks than
existing methods, significantly reducing the attack surface. Experimental
results on generic and medical datasets show that FedKR achieves competitive
performance, with an average improvement in accuracy of 4.24% compared to
training models from local data, demonstrating particular effectiveness in data
scarcity scenarios.

æè¦ï¼è¯é¦å­¸ç¿å·²æçºåä½å­¸ç¿çå¸ç¯ï¼
ç¡ééä¸­ææè³æå³å¯éç¼ç©©å¥æ¨¡åãç¶èï¼ç±æ¼æ¨¡åãåæ¸
ææ´æ°çå¬éï¼å³çµ±çè¯é¦å­¸ç¿æè¡å·æé±ç§åå®å¨æ¼æ´ï¼å¯ç¨ä½æ»æé¢ãæ¬ææåº
è¯é¦ç¥è­åå©ç¨ (FedKR)ï¼ä¸ç¨®è·¨å­¤å³¶çè¯é¦å­¸ç¿æ¹æ³
ä½¿ç¨æ¬å°çæçåæè³æä¾ä¿é²
æ©æ§ä¹éçåä½ãFedKR å°åé²çè³æçææè¡èåæ
èåéç¨ç¸çµåï¼ä»¥æä¾æ¯
ç¾ææ¹æ³æ´è½æµç¦¦é±ç§æ»æçå®å¨ä¿éï¼å¤§å¹ç¸®å°æ»æé¢ãå¯¦é©
çµæé¡¯ç¤ºï¼å¨ä¸è¬åé«çè³æéä¸ï¼FedKR éå°ç«¶ç­å
è¡¨ç¾ï¼èè¨ç·´æ¨¡åç¸æ¯ï¼æºç¢ºçå¹³åæå 4.24%
ä¾èªæ¬å°è³æï¼å¨è³æç¨ç¼ºçææ³ä¸å±ç¾åºç¹å¥çæææ§ã

##### **Architectural Influence on Variational Quantum Circuits in Multi-Agent Reinforcement Learning: Evolutionary Strategies for Optimization**
2407.20739v1 by Michael KÃ¶lle, Karola Schneider, Sabrina Egger, Felix Topp, Thomy Phan, Philipp Altmann, Jonas NÃ¼Ãlein, Claudia Linnhoff-Popien

In recent years, Multi-Agent Reinforcement Learning (MARL) has found
application in numerous areas of science and industry, such as autonomous
driving, telecommunications, and global health. Nevertheless, MARL suffers
from, for instance, an exponential growth of dimensions. Inherent properties of
quantum mechanics help to overcome these limitations, e.g., by significantly
reducing the number of trainable parameters. Previous studies have developed an
approach that uses gradient-free quantum Reinforcement Learning and
evolutionary optimization for variational quantum circuits (VQCs) to reduce the
trainable parameters and avoid barren plateaus as well as vanishing gradients.
This leads to a significantly better performance of VQCs compared to classical
neural networks with a similar number of trainable parameters and a reduction
in the number of parameters by more than 97 \% compared to similarly good
neural networks. We extend an approach of K\"olle et al. by proposing a
Gate-Based, a Layer-Based, and a Prototype-Based concept to mutate and
recombine VQCs. Our results show the best performance for mutation-only
strategies and the Gate-Based approach. In particular, we observe a
significantly better score, higher total and own collected coins, as well as a
superior own coin rate for the best agent when evaluated in the Coin Game
environment.

æè¦ï¼è¿å¹´ä¾ï¼å¤æºè½é«å¼·åå­¸ç¿ (MARL) å·²å¨ç§å­¸åç¢æ¥­çè¨±å¤é åä¸­æ¾å°æç¨ï¼ä¾å¦èªåé§é§ãé»ä¿¡åå¨çå¥åº·ãåç®¡å¦æ­¤ï¼MARL éæ¯æåå°ä¾å¦ç¶­åº¦ææ¸æé·ç­åé¡çå½±é¿ãéå­åå­¸çå§å¨ç¹æ§æå©æ¼åæéäºéå¶ï¼ä¾å¦ï¼ééå¤§å¹æ¸å°å¯è¨ç·´åæ¸çæ¸éãååçç ç©¶å·²éç¼åºä¸ç¨®æ¹æ³ï¼è©²æ¹æ³ä½¿ç¨ç¡æ¢¯åº¦çéå­å¼·åå­¸ç¿åè®åéå­é»è·¯ (VQC) çæ¼åæä½³åï¼ä»¥æ¸å°å¯è¨ç·´åæ¸ä¸¦é¿åè²§ç é«ååæ¢¯åº¦æ¶å¤±ãèå·æé¡ä¼¼å¯è¨ç·´åæ¸æ¸éçå³çµ±ç¥ç¶ç¶²è·¯ç¸æ¯ï¼éæè® VQC çæè½é¡¯èæåï¼èä¸èåæ¨£åªè¯çç¥ç¶ç¶²è·¯ç¸æ¯ï¼åæ¸æ¸éæ¸å°äºè¶é 97%ãæåæ´åäº K\"olle ç­äººçæ¹æ³ï¼æåºä¸ååºæ¼éãåºæ¼å±¤ååºæ¼ååçæ¦å¿µä¾è®ç°åéçµ VQCãæåççµæé¡¯ç¤ºï¼åè®ç°ç­ç¥ååºæ¼éçæ¹æ³å·ææä½³æè½ãç¹å¥æ¯ï¼æåè§å¯å°å¨ Coin Game ç°å¢ä¸­é²è¡è©ä¼°æï¼æä½³æºè½é«çå¾åé¡¯èæåãç¸½è¨åèªå·±æ¶éçéå¹£æ¸éè¼é«ï¼ä»¥åèªå·±çéå¹£æ¯çè¼é«ã

##### **Dense Self-Supervised Learning for Medical Image Segmentation**
2407.20395v1 by Maxime Seince, Loic Le Folgoc, Luiz Augusto Facury de Souza, Elsa Angelini

Deep learning has revolutionized medical image segmentation, but it relies
heavily on high-quality annotations. The time, cost and expertise required to
label images at the pixel-level for each new task has slowed down widespread
adoption of the paradigm. We propose Pix2Rep, a self-supervised learning (SSL)
approach for few-shot segmentation, that reduces the manual annotation burden
by learning powerful pixel-level representations directly from unlabeled
images. Pix2Rep is a novel pixel-level loss and pre-training paradigm for
contrastive SSL on whole images. It is applied to generic encoder-decoder deep
learning backbones (e.g., U-Net). Whereas most SSL methods enforce invariance
of the learned image-level representations under intensity and spatial image
augmentations, Pix2Rep enforces equivariance of the pixel-level
representations. We demonstrate the framework on a task of cardiac MRI
segmentation. Results show improved performance compared to existing semi- and
self-supervised approaches; and a 5-fold reduction in the annotation burden for
equivalent performance versus a fully supervised U-Net baseline. This includes
a 30% (resp. 31%) DICE improvement for one-shot segmentation under
linear-probing (resp. fine-tuning). Finally, we also integrate the novel
Pix2Rep concept with the Barlow Twins non-contrastive SSL, which leads to even
better segmentation performance.

æè¦ï¼æ·±åº¦å­¸ç¿å¾¹åºæ¹è®äºé«å­¸å½±ååå²ï¼ä½å®æ¥µåº¦ä¾è³´æ¼é«åè³ªçè¨»è§£ãçºæ¯åæ°ä»»åæ¨è¨åç´ å±¤ç´çå½±åæéçæéãææ¬åå°æ¥­ç¥è­ï¼å·²æ¸ç·©äºç¯ä¾çå»£æ³æ¡ç¨ãæåæåº Pix2Repï¼ä¸ç¨®éå°å°æ¬¡åå²çèªç£ç£å¼å­¸ç¿ (SSL) æ¹æ³ï¼å¯ééç´æ¥å¾æªæ¨è¨çå½±åä¸­å­¸ç¿å¼·å¤§çåç´ å±¤ç´è¡¨ç¤ºï¼ä¾æ¸è¼æåè¨»è§£è² æãPix2Rep æ¯ä¸ç¨®éå°å®æ´å½±åå°æ¯å¼ SSL çæ°ç©åç´ å±¤ç´æå¤±åé è¨ç·´ç¯ä¾ãå®è¢«æç¨æ¼éç¨ç·¨ç¢¼å¨-è§£ç¢¼å¨æ·±åº¦å­¸ç¿ä¸»å¹¹ (ä¾å¦ U-Net)ãå¤§å¤æ¸ SSL æ¹æ³å¼·å¶å­¸ç¿çå½±åå±¤ç´è¡¨ç¤ºå¨å¼·åº¦åç©ºéå½±åæ´åä¸å·æä¸è®æ§ï¼è Pix2Rep åå¼·å¶åç´ å±¤ç´è¡¨ç¤ºå·æç­è®æ§ãæåå¨å¿è MRI åå²ä»»åä¸­å±ç¤ºäºéåæ¶æ§ãçµæé¡¯ç¤ºèç¾æçåç£ç£å¼åèªç£ç£å¼æ¹æ³ç¸æ¯ï¼æè½æææåï¼ä¸å¨èå®å¨ç£ç£å¼ U-Net åºæºå·æç¸åæè½çææ³ä¸ï¼è¨»è§£è² ææ¸å°äº 5 åãéåæ¬å¨ç·æ§æ¢æ¸¬ (resp. å¾®èª¿) ä¸ï¼å®æ¬¡åå²ç DICE æåäº 30% (resp. 31%)ãæå¾ï¼æåä¹å°æ°ç©ç Pix2Rep æ¦å¿µè Barlow Twins éå°æ¯å¼ SSL æ´åï¼éå°è´äºæ´å¥½çåå²æè½ã

##### **Classification, Regression and Segmentation directly from k-Space in Cardiac MRI**
2407.20108v1 by Ruochen Li, Jiazhen Pan, Youxiang Zhu, Juncheng Ni, Daniel Rueckert

Cardiac Magnetic Resonance Imaging (CMR) is the gold standard for diagnosing
cardiovascular diseases. Clinical diagnoses predominantly rely on
magnitude-only Digital Imaging and Communications in Medicine (DICOM) images,
omitting crucial phase information that might provide additional diagnostic
benefits. In contrast, k-space is complex-valued and encompasses both magnitude
and phase information, while humans cannot directly perceive. In this work, we
propose KMAE, a Transformer-based model specifically designed to process
k-space data directly, eliminating conventional intermediary conversion steps
to the image domain. KMAE can handle critical cardiac disease classification,
relevant phenotype regression, and cardiac morphology segmentation tasks. We
utilize this model to investigate the potential of k-space-based diagnosis in
cardiac MRI. Notably, this model achieves competitive classification and
regression performance compared to image-domain methods e.g. Masked
Autoencoders (MAEs) and delivers satisfactory segmentation performance with a
myocardium dice score of 0.884. Last but not least, our model exhibits robust
performance with consistent results even when the k-space is 8* undersampled.
We encourage the MR community to explore the untapped potential of k-space and
pursue end-to-end, automated diagnosis with reduced human intervention.

æè¦ï¼å¿èç£æ¯é å½± (CMR) æ¯è¨ºæ·å¿è¡ç®¡ç¾ççé»éæ¨æºãè¨åºè¨ºæ·ä¸»è¦ä¾è³´æ¼é«å­¸æ¸ä½å½±ååéè¨ (DICOM) å½±åçå¹åº¦ï¼èå¿½ç¥äºå¯è½æä¾é¡å¤è¨ºæ·å¥½èçééµç¸ä½è³è¨ãç¸è¼ä¹ä¸ï¼k ç©ºéæ¯è¤æ¸å¼ä¸åå«å¹åº¦åç¸ä½è³è¨ï¼ä½äººé¡ç¡æ³ç´æ¥æç¥ãå¨éé å·¥ä½ä¸­ï¼æåæåº KMAEï¼ä¸ç¨®ç¹å¥è¨­è¨ç¨æ¼ç´æ¥èç k ç©ºéè³æç Transformer åºç¤æ¨¡åï¼æ¶é¤äºè½æå°å½±åé åçå³çµ±ä¸­ä»æ­¥é©ãKMAE å¯ä»¥èçééµçå¿èç¾çåé¡ãç¸éè¡¨ååæ­¸åå¿èå½¢æåå²ä»»åãæåå©ç¨æ­¤æ¨¡åæ¢è¨ k ç©ºéåºç¤è¨ºæ·å¨å¿è MRI ä¸­çæ½åãå¼å¾æ³¨æçæ¯ï¼èå½±åé åæ¹æ³ï¼ä¾å¦é®ç½©å¼èªåç·¨ç¢¼å¨ (MAE)ï¼ç¸æ¯ï¼æ­¤æ¨¡åéå°äºç«¶ç­æ§çåé¡ååæ­¸æè½ï¼ä¸¦ä»¥ 0.884 çå¿èéª°å­åæ¸æä¾äºä»¤äººæ»¿æçåå²æè½ãæå¾ä½ä¸¦éæä¸éè¦çä¸é»æ¯ï¼å³ä½¿å¨ k ç©ºéä¸è¶³æ¡æ¨£ 8* æï¼æåçæ¨¡åä¹è½å±ç¾ç©©å¥çæè½åä¸è´ççµæãæåé¼åµæ ¸ç£å±æ¯ç¤¾ç¾¤æ¢ç´¢ k ç©ºéçæªéç¼æ½åï¼ä¸¦è¿½æ±æ¸å°äººçºå¹²é çç«¯å°ç«¯èªååè¨ºæ·ã

##### **Robust Conformal Volume Estimation in 3D Medical Images**
2407.19938v1 by Benjamin Lambert, Florence Forbes, Senan Doyle, Michel Dojat

Volumetry is one of the principal downstream applications of 3D medical image
segmentation, for example, to detect abnormal tissue growth or for surgery
planning. Conformal Prediction is a promising framework for uncertainty
quantification, providing calibrated predictive intervals associated with
automatic volume measurements. However, this methodology is based on the
hypothesis that calibration and test samples are exchangeable, an assumption
that is in practice often violated in medical image applications. A weighted
formulation of Conformal Prediction can be framed to mitigate this issue, but
its empirical investigation in the medical domain is still lacking. A potential
reason is that it relies on the estimation of the density ratio between the
calibration and test distributions, which is likely to be intractable in
scenarios involving high-dimensional data. To circumvent this, we propose an
efficient approach for density ratio estimation relying on the compressed
latent representations generated by the segmentation model. Our experiments
demonstrate the efficiency of our approach to reduce the coverage error in the
presence of covariate shifts, in both synthetic and real-world settings. Our
implementation is available at https://github.com/benolmbrt/wcp_miccai

æè¦ï¼é«ç©æ¸¬éæ¯ 3D é«å­¸å½±ååå²çä¸»è¦ä¸æ¸¸æç¨ä¹ä¸ï¼ä¾å¦ç¨æ¼åµæ¸¬ç°å¸¸çµç¹çé·ææè¡è¦åãå±å½¢é æ¸¬æ¯ä¸åæåéçä¸ç¢ºå®æ§éåæ¶æ§ï¼æä¾èèªåé«ç©éæ¸¬ç¸éçæ ¡æ­£é æ¸¬åéãç¶èï¼æ­¤æ¹æ³åºæ¼æ ¡æ­£åæ¸¬è©¦æ¨£æ¬å¯äº¤æçåè¨­ï¼èæ­¤åè¨­å¨å¯¦åä¸ç¶å¸¸å¨é«å­¸å½±åæç¨ä¸­é­å°ç ´å£ãå±å½¢é æ¸¬çå æ¬å¬å¼å¯ä»¥è¢«å»ºæ§ä¾æ¸è¼æ­¤åé¡ï¼ä½å¶å¨é«å­¸é åçç¶é©èª¿æ¥ä»ç¶ä¸è¶³ãä¸åæ½å¨åå æ¯å®ä¾è³´æ¼æ ¡æ­£åæ¸¬è©¦åä½ä¹éçå¯åº¦æ¯ä¼°è¨ï¼éå¨æ¶åé«ç¶­åº¦è³æçå ´æ¯ä¸­å¯è½æ¯æ£æçãçºäºè¿´é¿æ­¤åé¡ï¼æåæåºä¸åææççå¯åº¦æ¯ä¼°è¨æ¹æ³ï¼ä¾è³´æ¼åå²æ¨¡åç¢ççå£ç¸®æ½å¨è¡¨ç¤ºãæåçå¯¦é©è­æäºæåçæ¹æ³å¨åæåçå¯¦ä¸çè¨­å®ä¸­æ¸å°å±è®ç°æ¸åç§»å­å¨æçè¦èçèª¤å·®çæçãæåçå¯¦ä½å¯ä»¥å¨ https://github.com/benolmbrt/wcp_miccai åå¾

##### **Yucca: A Deep Learning Framework For Medical Image Analysis**
2407.19888v1 by Sebastian NÃ¸rgaard Llambias, Julia Machnio, AsbjÃ¸rn Munk, Jakob Ambsdorf, Mads Nielsen, Mostafa Mehdipour Ghazi

Medical image analysis using deep learning frameworks has advanced healthcare
by automating complex tasks, but many existing frameworks lack flexibility,
modularity, and user-friendliness. To address these challenges, we introduce
Yucca, an open-source AI framework available at
https://github.com/Sllambias/yucca, designed specifically for medical imaging
applications and built on PyTorch and PyTorch Lightning. Yucca features a
three-tiered architecture: Functional, Modules, and Pipeline, providing a
comprehensive and customizable solution. Evaluated across diverse tasks such as
cerebral microbleeds detection, white matter hyperintensity segmentation, and
hippocampus segmentation, Yucca achieves state-of-the-art results,
demonstrating its robustness and versatility. Yucca offers a powerful,
flexible, and user-friendly platform for medical image analysis, inviting
community contributions to advance its capabilities and impact.

æè¦ï¼ä½¿ç¨æ·±åº¦å­¸ç¿æ¡æ¶é²è¡çé«å­¸å½±ååæå·²ç¶ééèªååè¤éä»»åæ¨åäºé«çä¿å¥çé²æ­¥ï¼ä½è¨±å¤ç¾ææ¡æ¶ç¼ºä¹éæ´»æ§ãæ¨¡çµååä½¿ç¨èååæ§ãçºäºæå°éäºææ°ï¼æåå¼å¥äº Yuccaï¼ä¸åéæ¾åå§ç¢¼ç AI æ¡æ¶ï¼å¯æ¼ https://github.com/Sllambias/yucca åå¾ï¼å°éçºé«å­¸å½±åæç¨è¨­è¨ï¼ä¸¦å»ºç«å¨ PyTorch å PyTorch Lightning ä¹ä¸ãYucca å·æä¸å±¤æ¶æ§ï¼åè½ãæ¨¡çµåç®¡ç·ï¼æä¾å¨é¢ä¸å¯èªè¨çè§£æ±ºæ¹æ¡ãå¨åç¨®ä»»åä¸­é²è¡è©ä¼°ï¼ä¾å¦è¦å¾®åºè¡åµæ¸¬ãç½è³ªé«è¨èåå²åæµ·é¦¬åå²ï¼Yucca éå°äºæåé²ççµæï¼è­æäºå®çç©©å¥æ§åå¤åè½æ§ãYucca æä¾äºä¸åå¼·å¤§ãéæ´»ä¸ä½¿ç¨èååçé«å­¸å½±ååæå¹³å°ï¼æ­¡è¿ç¤¾ç¾¤è²¢ç»ä»¥æåå¶è½ååå½±é¿åã

##### **CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare**
2407.19705v2 by Jingwei Zhu, Minghuan Tan, Min Yang, Ruixue Li, Hamid Alinejad-Rokny

The rapid progress in Large Language Models (LLMs) has prompted the creation
of numerous benchmarks to evaluate their capabilities.This study focuses on the
Comprehensive Medical Benchmark in Chinese (CMB), showcasing how dataset
diversity and distribution in supervised fine-tuning (SFT) may enhance LLM
performance.Remarkably, We successfully trained a smaller base model to achieve
scores comparable to larger models, indicating that a diverse and
well-distributed dataset can optimize performance regardless of model size.This
study suggests that even smaller models may reach high performance levels with
carefully curated and varied datasets. By integrating a wide range of
instructional content, our approach addresses potential issues such as data
quality inconsistencies. Our results imply that a broader spectrum of training
data may enhance a model's ability to generalize and perform effectively across
different medical scenarios, highlighting the importance of dataset quality and
diversity in fine-tuning processes. We open-source the model for future
research at https://github.com/CAS-SIAT-XinHai/CollectiveSFT

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çå¿«éé²å±ä¿æäºè¨±å¤åºæºçå»ºç«ï¼ä»¥è©ä¼°å®åçè½åãæ¬ç ç©¶å°æ³¨æ¼ä¸­æç¶åé«çåºæº (CMB)ï¼å±ç¤ºäºç£ç£å¾®èª¿ (SFT) ä¸­çè³æéå¤æ¨£æ§ååä½å¦ä½å¢å¼· LLM æè½ãå¼å¾æ³¨æçæ¯ï¼æåæåå°è¨ç·´äºä¸åè¼å°çåºç¤æ¨¡åï¼ä»¥éå°èè¼å¤§åæ¨¡åç¸ç¶çåæ¸ï¼éè¡¨æä¸åå¤æ¨£åä¸åä½è¯å¥½çè³æéå¯ä»¥æä½³åæè½ï¼èèæ¨¡åå¤§å°ç¡éãæ¬ç ç©¶è¡¨æï¼å³ä½¿æ¯è¼å°çæ¨¡åï¼åªè¦ä½¿ç¨ç¶éä»ç´°ç­åä¸å¤æ¨£åçè³æéï¼ä¹è½éå°é«æ°´æºçæè½ãééæ´åå»£æ³çæå­¸å§å®¹ï¼æåçåæ³è§£æ±ºäºè³æåè³ªä¸ä¸è´ç­æ½å¨åé¡ãæåççµæè¡¨æï¼æ´å»£æ³çè¨ç·´è³æç¯åå¯è½æå¢å¼·æ¨¡åå¨ä¸åé«çå ´æ¯ä¸­æ¦æ¬åææå·è¡çè½åï¼çªé¡¯äºè³æéåè³ªåå¤æ¨£æ§å¨å¾®èª¿éç¨ä¸­æ®æ¼çéè¦è§è²ãæåå¨ https://github.com/CAS-SIAT-XinHai/CollectiveSFT éæºæ­¤æ¨¡åä»¥ä¾å°ä¾ç ç©¶ã

##### **Beyond Metrics: A Critical Analysis of the Variability in Large Language Model Evaluation Frameworks**
2407.21072v1 by Marco AF Pimentel, ClÃ©ment Christophe, Tathagata Raha, Prateek Munjal, Praveen K Kanithi, Shadab Khan

As large language models (LLMs) continue to evolve, the need for robust and
standardized evaluation benchmarks becomes paramount. Evaluating the
performance of these models is a complex challenge that requires careful
consideration of various linguistic tasks, model architectures, and
benchmarking methodologies. In recent years, various frameworks have emerged as
noteworthy contributions to the field, offering comprehensive evaluation tests
and benchmarks for assessing the capabilities of LLMs across diverse domains.
This paper provides an exploration and critical analysis of some of these
evaluation methodologies, shedding light on their strengths, limitations, and
impact on advancing the state-of-the-art in natural language processing.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) æçºæ¼é²ï¼å°æ¼å¥å¨ä¸æ¨æºåçè©ä¼°åºæºçéæ±è®å¾è³ééè¦ãè©ä¼°éäºæ¨¡åçæè½æ¯ä¸é è¤éçææ°ï¼éè¦ä»ç´°èéåç¨®èªè¨ä»»åãæ¨¡åæ¶æ§ååºæºæ¹æ³ãè¿å¹´ä¾ï¼åç¨®æ¶æ§å·²æçºè©²é åçé¡¯èè²¢ç»ï¼æä¾å¨é¢çè©ä¼°æ¸¬è©¦ååºæºï¼ç¨æ¼è©ä¼° LLM å¨ä¸åé åçè½åãæ¬ææ¢è¨ä¸¦æ¹å¤æ§å°åæå¶ä¸­ä¸äºè©ä¼°æ¹æ³ï¼é¡æå¶åªé»ãéå¶åå°èªç¶èªè¨èçé åé²æ­¥çå½±é¿ã

##### **Urban Traffic Accident Risk Prediction Revisited: Regionality, Proximity, Similarity and Sparsity**
2407.19668v1 by Minxiao Chen, Haitao Yuan, Nan Jiang, Zhifeng Bao, Shangguang Wang

Traffic accidents pose a significant risk to human health and property
safety. Therefore, to prevent traffic accidents, predicting their risks has
garnered growing interest. We argue that a desired prediction solution should
demonstrate resilience to the complexity of traffic accidents. In particular,
it should adequately consider the regional background, accurately capture both
spatial proximity and semantic similarity, and effectively address the sparsity
of traffic accidents. However, these factors are often overlooked or difficult
to incorporate. In this paper, we propose a novel multi-granularity
hierarchical spatio-temporal network. Initially, we innovate by incorporating
remote sensing data, facilitating the creation of hierarchical
multi-granularity structure and the comprehension of regional background. We
construct multiple high-level risk prediction tasks to enhance model's ability
to cope with sparsity. Subsequently, to capture both spatial proximity and
semantic similarity, region feature and multi-view graph undergo encoding
processes to distill effective representations. Additionally, we propose
message passing and adaptive temporal attention module that bridges different
granularities and dynamically captures time correlations inherent in traffic
accident patterns. At last, a multivariate hierarchical loss function is
devised considering the complexity of the prediction purpose. Extensive
experiments on two real datasets verify the superiority of our model against
the state-of-the-art methods.

æè¦ï¼äº¤éäºæå°äººé¡å¥åº·åè²¡ç¢å®å¨æ§æéå¤§é¢¨éªãå æ­¤ï¼é æ¸¬äº¤éäºæé¢¨éªå·²å¼èµ·è¶ä¾è¶å¤§çèè¶£ãæåèªçºï¼çæ³çé æ¸¬è§£æ±ºæ¹æ¡æå±ç¾åºå°äº¤éäºæè¤éæ§çéæ§ãå·é«èè¨ï¼å®æååèæ®ååèæ¯ï¼æºç¢ºææç©ºéæ¥è¿åº¦åèªç¾©ç¸ä¼¼æ§ï¼ä¸¦ææè§£æ±ºäº¤éäºæçç¨çæ§ãç¶èï¼éäºå ç´ éå¸¸è¢«å¿½è¦æé£ä»¥ç´å¥ãå¨æ¬æä¸­ï¼æåæåºäºä¸åæ°ç©çå¤ç²åº¦åå±¤æç©ºç¶²è·¯ãæåï¼æååµæ°å°ç´å¥äºéææ¸æï¼ä¿è¿äºåå±¤å¤ç²åº¦çµæ§çåµå»ºåååèæ¯ççè§£ãæåæ§å»ºäºå¤åé«ç´é¢¨éªé æ¸¬ä»»åï¼ä»¥å¢å¼·æ¨¡åæå°ç¨çæ§çè½åãé¨å¾ï¼çºäºææç©ºéæ¥è¿åº¦åèªç¾©ç¸ä¼¼æ§ï¼ååç¹å¾µåå¤è¦ååè¡¨ç¶éç·¨ç¢¼éç¨ï¼ä»¥æåææçè¡¨ç¤ºãæ­¤å¤ï¼æåæåºäºæ¶æ¯å³éåèªé©ææéæ³¨æåæ¨¡çµï¼å®æ¶èµ·äºä¸åç²åº¦ä¹éçæ©æ¨ï¼ä¸¦åæææäº¤éäºææ¨¡å¼ä¸­åºæçæéç¸éæ§ãæå¾ï¼èæ®å°é æ¸¬ç®ççè¤éæ§ï¼è¨­è¨äºä¸åå¤è®éåå±¤æå¤±å½æ¸ãå¨å©åçå¯¦æ¸æéä¸çå¤§éå¯¦é©é©è­äºæåæ¨¡ååªæ¼æåé²æ¹æ³çåªè¶æ§ã

##### **Overcoming Uncertain Incompleteness for Robust Multimodal Sequential Diagnosis Prediction via Knowledge Distillation and Random Data Erasing**
2407.19540v1 by Heejoon Koo

In this paper, we present NECHO v2, a novel framework designed to enhance the
predictive accuracy of multimodal sequential patient diagnoses under uncertain
missing visit sequences, a common challenge in clinical settings. Firstly, we
modify NECHO to handle uncertain modality representation dominance under the
imperfect data. Next, we develop a systematic knowledge distillation by
employing the modified NECHO as both teacher and student. It encompasses a
modality-wise contrastive and hierarchical distillation, transformer
representation random distillation, along with other distillations to align
representations tightly and effectively. We also utilise random erasing on
individual data points within sequences during both training and distillation
of teacher to lightly simulate scenario with missing visit information to
foster effective knowledge transfer. As a result, NECHO v2 verifies itself by
showing superiority in multimodal sequential diagnosis prediction on both
balanced and imbalanced incomplete settings on multimodal healthcare data.

æè¦ï¼å¨æ¬æä¸­ï¼æåæåºäº NECHO v2ï¼ä¸åæ°ç©çæ¡æ¶ï¼æ¨å¨å¢å¼·å¤æ¨¡æé åºæ£èè¨ºæ·çé æ¸¬æºç¢ºåº¦ï¼å¨è¨åºç°å¢ä¸­å¸¸è¦çææ°æ¯ä¸ç¢ºå®éºæ¼çè¨ªååºåãé¦åï¼æåä¿®æ¹ NECHO ä»¥èçä¸å®ç¾æ¸æä¸çä¸ç¢ºå®æ¨¡æè¡¨ç¤ºåªå¢ãæ¥ä¸ä¾ï¼æåééä½¿ç¨ä¿®æ¹å¾ç NECHO ä½çºæå¸«åå­¸çä¾éç¼ç³»çµ±çç¥è­æçãå®åå«æ¨¡æå°æ¯ååå±¤æçãTransformerè¡¨ç¤ºé¨æ©æçä»¥åå¶ä»æçï¼ä»¥ç·å¯ææå°å°é½è¡¨ç¤ºãæåéå¨è¨ç·´åæå¸«æçéç¨ä¸­å°åºåä¸­çåå¥æ¸æé»ä½¿ç¨é¨æ©æ¦é¤ï¼ä»¥è¼å¾®æ¨¡æ¬éºæ¼è¨ªåä¿¡æ¯çå ´æ¯ï¼ä»¥ä¿é²ææçç¥è­å³éãå æ­¤ï¼NECHO v2 ééå¨å¤æ¨¡æé«çä¿å¥æ¸æçå¹³è¡¡åä¸å¹³è¡¡ä¸å®æ´è¨­ç½®ä¸é¡¯ç¤ºå¤æ¨¡æé åºè¨ºæ·é æ¸¬çåªè¶æ§ä¾é©è­èªèº«ã

##### **Nudging Consent and the New Opt Out System to the Processing of Health Data in England**
2407.19447v1 by Janos Meszaros, Chih-hsing Ho, Marcelo Corrales Compagnucci

This chapter examines the challenges of the revised opt out system and the
secondary use of health data in England. The analysis of this data could be
very valuable for science and medical treatment as well as for the discovery of
new drugs. For this reason, the UK government established the care.data program
in 2013. The aim of the project was to build a central nationwide database for
research and policy planning. However, the processing of personal data was
planned without proper public engagement. Research has suggested that IT
companies, such as in the Google DeepMind deal case, had access to other kinds
of sensitive data and failed to comply with data protection law. Since May
2018, the government has launched the national data opt out system with the
hope of regaining public trust. Nevertheless, there are no evidence of
significant changes in the ND opt out, compared to the previous opt out system.
Neither in the use of secondary data, nor in the choices that patients can
make. The only notorious difference seems to be in the way that these options
are communicated and framed to the patients. Most importantly, according to the
new ND opt out, the type 1 opt out option, which is the only choice that truly
stops data from being shared outside direct care, will be removed in 2020.
According to the Behavioral Law and Economics literature (Nudge Theory),
default rules, such as the revised opt out system in England, are very
powerful, because people tend to stick to the default choices made readily
available to them. The crucial question analyzed in this chapter is whether it
is desirable for the UK government to stop promoting the type 1 opt outs, and
whether this could be seen as a kind of hard paternalism.

æè¦ï¼<paragraph>æ¬ç« æ¢è¨äºè±åä¿®æ¹å¾çéåºæ©å¶åäºæ¬¡ä½¿ç¨å¥åº·è³ææé¢è¨çææ°ãåæéäºè³æå°æ¼ç§å­¸åé«çæ²»çä»¥åç¼ç¾æ°è¥ç©èè¨ï¼å¯è½éå¸¸æå¹å¼ãåºæ¼æ­¤åå ï¼è±åæ¿åºæ¼ 2013 å¹´å»ºç«äº care.data è¨ç«ãè©²å°æ¡çç®æ¨æ¯å»ºç«ä¸åå¨åæ§çä¸­å¤®è³æåº«ï¼ä»¥é²è¡ç ç©¶åæ¿ç­è¦åãç¶èï¼åäººè³æçèçæ¯å¨æ²æé©ç¶å¬ç¾åèçææ³ä¸é²è¡è¦åçãç ç©¶è¡¨æï¼ä¾å¦å¨ Google DeepMind äº¤ææ¡ä¾ä¸­ï¼IT å¬å¸å¯ä»¥å­åå¶ä»é¡åçææè³æï¼ä¸æªè½éµå®è³æä¿è­·æ³ãèª 2018 å¹´ 5 æä»¥ä¾ï¼æ¿åºå·²æ¨åºå¨åè³æéåºæ©å¶ï¼å¸æè½éæ°ç²å¾å¬ç¾ä¿¡ä»»ãåç®¡å¦æ­¤ï¼èååçéåºæ©å¶ç¸æ¯ï¼ä¸¦ç¡è­æé¡¯ç¤ºå¨åè³æéåºæ©å¶æé¡¯èè®åãç¡è«æ¯å¨äºæ¬¡è³æçä½¿ç¨ä¸ï¼ææ¯å¨æ£èå¯ä»¥ååºçé¸æä¸ï¼çæ¯å¦æ­¤ãå¯ä¸é¡¯èçå·®ç°ä¼¼ä¹å¨æ¼éäºé¸é çæºéåå³éæ¹å¼ãæéè¦çæ¯ï¼æ ¹ææ°çå¨åè³æéåºæ©å¶ï¼é¡å 1 éåºé¸é ï¼éæ¯å¯ä¸çæ­£è½é»æ­¢è³æå¨ç´æ¥ç§è­·ä¹å¤è¢«åäº«çé¸é ï¼å°æ¼ 2020 å¹´è¢«ç§»é¤ãæ ¹æè¡çºæ³èç¶æ¿å­¸æç»ï¼æ¨è«çè«ï¼ï¼é è¨­è¦åï¼ä¾å¦è±åä¿®æ¹å¾çéåºæ©å¶ï¼éå¸¸ææï¼å çºäººåå¾åæ¼å æå®¹æåå¾çé è¨­é¸é ãæ¬ç« åæçééµåé¡æ¯ï¼è±åæ¿åºåæ­¢æ¨å»£é¡å 1 éåºæ¯å¦å¯åï¼ä»¥åéæ¯å¦å¯ä»¥è¦çºä¸ç¨®å´å²çç¶æ¬ä¸»ç¾©ã</paragraph>

##### **ASI-Seg: Audio-Driven Surgical Instrument Segmentation with Surgeon Intention Understanding**
2407.19435v1 by Zhen Chen, Zongming Zhang, Wenwu Guo, Xingjian Luo, Long Bai, Jinlin Wu, Hongliang Ren, Hongbin Liu

Surgical instrument segmentation is crucial in surgical scene understanding,
thereby facilitating surgical safety. Existing algorithms directly detected all
instruments of pre-defined categories in the input image, lacking the
capability to segment specific instruments according to the surgeon's
intention. During different stages of surgery, surgeons exhibit varying
preferences and focus toward different surgical instruments. Therefore, an
instrument segmentation algorithm that adheres to the surgeon's intention can
minimize distractions from irrelevant instruments and assist surgeons to a
great extent. The recent Segment Anything Model (SAM) reveals the capability to
segment objects following prompts, but the manual annotations for prompts are
impractical during the surgery. To address these limitations in operating
rooms, we propose an audio-driven surgical instrument segmentation framework,
named ASI-Seg, to accurately segment the required surgical instruments by
parsing the audio commands of surgeons. Specifically, we propose an
intention-oriented multimodal fusion to interpret the segmentation intention
from audio commands and retrieve relevant instrument details to facilitate
segmentation. Moreover, to guide our ASI-Seg segment of the required surgical
instruments, we devise a contrastive learning prompt encoder to effectively
distinguish the required instruments from the irrelevant ones. Therefore, our
ASI-Seg promotes the workflow in the operating rooms, thereby providing
targeted support and reducing the cognitive load on surgeons. Extensive
experiments are performed to validate the ASI-Seg framework, which reveals
remarkable advantages over classical state-of-the-art and medical SAMs in both
semantic segmentation and intention-oriented segmentation. The source code is
available at https://github.com/Zonmgin-Zhang/ASI-Seg.

æè¦ï¼æè¡å¨æ¢°åå²å°æ¼æè¡å ´æ¯çè§£è³ééè¦ï¼
å¾èä¿é²æè¡å®å¨ãç¾ææ¼ç®æ³ç´æ¥åµæ¸¬è¼¸å¥å½±åä¸­ææé å®ç¾©é¡å¥çå¨æ¢°ï¼ç¼ºä¹æ ¹æå¤ç§é«å¸«æååå²ç¹å®å¨æ¢°çè½åãå¨æè¡çä¸åéæ®µï¼å¤ç§é«å¸«æå°ä¸åçæè¡å¨æ¢°è¡¨ç¾åºä¸åçåå¥½åéæ³¨ãå æ­¤ï¼ä¸ç¨®éµå¾ªå¤ç§é«å¸«æåçå¨æ¢°åå²æ¼ç®æ³å¯ä»¥æå¤§ç¨åº¦å°æ¸å°èæè¡ç¡éçå¨æ¢°çå¹²æ¾ï¼ä¸¦å¨å¾å¤§ç¨åº¦ä¸åå©å¤ç§é«å¸«ãæè¿ç Segment Anything Model (SAM) æ­ç¤ºäºæ ¹ææç¤ºåå²ç©ä»¶çè½åï¼ä½æç¤ºçæåè¨»è§£å¨æè¡éç¨ä¸­ä¸åå¯¦éãçºäºè§£æ±ºæè¡å®¤ä¸­çéäºéå¶ï¼æåæåºäºä¸åé³è¨é©åçæè¡å¨æ¢°åå²æ¶æ§ï¼ç¨±çº ASI-Segï¼ééè§£æå¤ç§é«å¸«çé³è¨å½ä»¤ä¾æºç¢ºåå²æéçå¨æ¢°ãå·é«ä¾èªªï¼æåæåºäºä¸åæåå°åçå¤æ¨¡æèåï¼å¾é³è¨å½ä»¤ä¸­è§£éåå²æåä¸¦æª¢ç´¢ç¸éå¨æ¢°ç´°ç¯ä»¥å©æ¼åå²ãæ­¤å¤ï¼çºäºæå°æåç ASI-Seg åå²æéçå¨æ¢°ï¼æåè¨­è¨äºä¸åå°æ¯å­¸ç¿æç¤ºç·¨ç¢¼å¨ï¼ä»¥ææååæéçå¨æ¢°åä¸ç¸éçå¨æ¢°ãå æ­¤ï¼æåç ASI-Seg ä¿é²äºæè¡å®¤ä¸­çå·¥ä½æµç¨ï¼å¾èæä¾äºæéå°æ§çæ¯æ´ï¼ä¸¦éä½äºå¤ç§é«å¸«çèªç¥è² æãé²è¡äºå¤§éçå¯¦é©ä¾é©è­ ASI-Seg æ¶æ§ï¼éæ­ç¤ºäºå¨èªç¾©åå²åæåå°ååå²ä¸­ï¼èå³çµ±çææ°æè¡åé«å­¸ SAM ç¸æ¯ï¼å®å·æé¡¯èçåªå¢ãåå§ç¢¼å¯å¨ https://github.com/Zonmgin-Zhang/ASI-Seg ç²å¾ã

##### **A Generic Review of Integrating Artificial Intelligence in Cognitive Behavioral Therapy**
2407.19422v1 by Meng Jiang, Qing Zhao, Jianqiang Li, Fan Wang, Tianyu He, Xinyan Cheng, Bing Xiang Yang, Grace W. K. Ho, Guanghui Fu

Cognitive Behavioral Therapy (CBT) is a well-established intervention for
mitigating psychological issues by modifying maladaptive cognitive and
behavioral patterns. However, delivery of CBT is often constrained by resource
limitations and barriers to access. Advancements in artificial intelligence
(AI) have provided technical support for the digital transformation of CBT.
Particularly, the emergence of pre-training models (PTMs) and large language
models (LLMs) holds immense potential to support, augment, optimize and
automate CBT delivery. This paper reviews the literature on integrating AI into
CBT interventions. We begin with an overview of CBT. Then, we introduce the
integration of AI into CBT across various stages: pre-treatment, therapeutic
process, and post-treatment. Next, we summarized the datasets relevant to some
CBT-related tasks. Finally, we discuss the benefits and current limitations of
applying AI to CBT. We suggest key areas for future research, highlighting the
need for further exploration and validation of the long-term efficacy and
clinical utility of AI-enhanced CBT. The transformative potential of AI in
reshaping the practice of CBT heralds a new era of more accessible, efficient,
and personalized mental health interventions.

æè¦ï¼èªç¥è¡çºçæ³ (CBT) æ¯ä¸ç¨®å®åçå¹²é æªæ½ï¼ééèª¿æ´é©æä¸è¯çèªç¥åè¡çºæ¨¡å¼ä¾æ¸è¼å¿çåé¡ãç¶èï¼CBT çæä¾å¾å¾åå°è³æºéå¶åç²åéç¤çéå¶ãäººå·¥æºæ§ (AI) çé²æ­¥çº CBT çæ¸ä½è½åæä¾äºæè¡æ¯æ´ãç¹å¥æ¯ï¼é è¨ç·´æ¨¡å (PTM) åå¤§åèªè¨æ¨¡å (LLM) çåºç¾å·æå·¨å¤§çæ½åï¼å¯ä»¥æ¯æ´ãæ´åãæä½³ååèªåå CBT çæä¾ãæ¬æåé¡§äºå° AI æ´åå° CBT å¹²é æªæ½çæç»ãæåå¾ CBT çæ¦è¿°éå§ãç¶å¾ï¼æåä»ç´¹äºå¨åç¨®éæ®µå° AI æ´åå° CBT ä¸­ï¼æ²»çåãæ²»çéç¨åæ²»çå¾ãæ¥ä¸ä¾ï¼æåç¸½çµäºèä¸äº CBT ç¸éä»»åç¸éçè³æéãæå¾ï¼æåè¨è«äºå° AI æç¨æ¼ CBT çå¥½èåç®åçéå¶ãæåå»ºè­°æªä¾ç ç©¶çä¸»è¦é åï¼å¼·èª¿éè¦é²ä¸æ­¥æ¢ç´¢åé©è­ AI å¢å¼· CBT çé·æçæåè¨åºæç¨ãAI å¨éå¡ CBT å¯¦åä¸­çè½åæ½åé ç¤ºèä¸åæ°çæä»£ï¼å³æ´ææ¼åå¾ãæ´ææçåæ´åäººåçå¿çå¥åº·å¹²é æªæ½ã

##### **Empowering Clinicians with Medical Decision Transformers: A Framework for Sepsis Treatment**
2407.19380v1 by Aamer Abdul Rahman, Pranav Agarwal, Rita Noumeir, Philippe Jouvet, Vincent Michalski, Samira Ebrahimi Kahou

Offline reinforcement learning has shown promise for solving tasks in
safety-critical settings, such as clinical decision support. Its application,
however, has been limited by the lack of interpretability and interactivity for
clinicians. To address these challenges, we propose the medical decision
transformer (MeDT), a novel and versatile framework based on the
goal-conditioned reinforcement learning paradigm for sepsis treatment
recommendation. MeDT uses the decision transformer architecture to learn a
policy for drug dosage recommendation. During offline training, MeDT utilizes
collected treatment trajectories to predict administered treatments for each
time step, incorporating known treatment outcomes, target acuity scores, past
treatment decisions, and current and past medical states. This analysis enables
MeDT to capture complex dependencies among a patient's medical history,
treatment decisions, outcomes, and short-term effects on stability. Our
proposed conditioning uses acuity scores to address sparse reward issues and to
facilitate clinician-model interactions, enhancing decision-making. Following
training, MeDT can generate tailored treatment recommendations by conditioning
on the desired positive outcome (survival) and user-specified short-term
stability improvements. We carry out rigorous experiments on data from the
MIMIC-III dataset and use off-policy evaluation to demonstrate that MeDT
recommends interventions that outperform or are competitive with existing
offline reinforcement learning methods while enabling a more interpretable,
personalized and clinician-directed approach.

æè¦ï¼é¢ç·å¼·åå­¸ç¿å·²å±ç¾åºè§£æ±ºè«¸å¦è¨åºæ±ºç­æ¯æ´ç­å®å¨ééµè¨­å®ä¸­ä»»åçæ½åãç¶èï¼å¶æç¨åå°è¨åºé«å¸«å°å¯è§£éæ§åäºåæ§çç¼ºä¹æéå¶ãçºäºæå°éäºææ°ï¼æåæåºäºé«çæ±ºç­è½æå¨ (MeDT)ï¼éæ¯ä¸ååºæ¼ç®æ¨æ¢ä»¶å¼·åå­¸ç¿ç¯ä¾çæ°ç©ä¸å¤åè½çæ¶æ§ï¼ç¨æ¼æè¡çæ²»çå»ºè­°ãMeDT ä½¿ç¨æ±ºç­è½æå¨æ¶æ§ä¾å­¸ç¿è¥ç©åéå»ºè­°çæ¿ç­ãå¨é¢ç·è¨ç·´æéï¼MeDT å©ç¨æ¶éçæ²»çè»è·¡ä¾é æ¸¬æ¯åæéæ­¥é©çç®¡çæ²»çï¼ä¸¦ç´å¥å·²ç¥çæ²»ççµæãç®æ¨å´éç¨åº¦è©åãéå»çæ²»çæ±ºç­ä»¥åç¶ååéå»çé«ççæãæ­¤åæä½¿ MeDT è½å¤ æææ£èçå²ãæ²»çæ±ºç­ãçµæä»¥åå°ç©©å®æ§çç­æå½±é¿ä¹éçè¤éä¾è³´éä¿ãæåæåºçæ¢ä»¶ä½¿ç¨å´éç¨åº¦è©åä¾è§£æ±ºç¨ççåµåé¡ä¸¦ä¿é²è¨åºé«å¸«èæ¨¡åçäºåï¼å¾èå¢å¼·æ±ºç­å¶å®ãå¨è¨ç·´ä¹å¾ï¼MeDT å¯ä»¥ééä»¥æéçæ­£é¢çµæï¼å­æ´»ï¼åä½¿ç¨èæå®çç­æç©©å®æ§æ¹åçºæ¢ä»¶ä¾ç¢çéèº«æé çæ²»çå»ºè­°ãæåå°ä¾èª MIMIC-III è³æéçè³æé²è¡äºå´æ ¼çå¯¦é©ï¼ä¸¦ä½¿ç¨éç­ç¥è©ä¼°ä¾è­æ MeDT æ¨è¦çå¹²é æªæ½åªæ¼æèç¾æçé¢ç·å¼·åå­¸ç¿æ¹æ³å·æç«¶ç­åï¼åæå¯¦ç¾äºæ´å·å¯è§£éæ§ãåæ§ååè¨åºé«å¸«æå°çæ¹æ³ã

##### **Learning to Select the Best Forecasting Tasks for Clinical Outcome Prediction**
2407.19359v1 by Yuan Xue, Nan Du, Anne Mottram, Martin Seneviratne, Andrew M. Dai

We propose to meta-learn an a self-supervised patient trajectory forecast
learning rule by meta-training on a meta-objective that directly optimizes the
utility of the patient representation over the subsequent clinical outcome
prediction. This meta-objective directly targets the usefulness of a
representation generated from unlabeled clinical measurement forecast for later
supervised tasks.
  The meta-learned can then be directly used in target risk prediction, and the
limited available samples can be used for further fine-tuning the model
performance. The effectiveness of our approach is tested on a real open source
patient EHR dataset MIMIC-III. We are able to demonstrate that our
attention-based patient state representation approach can achieve much better
performance for predicting target risk with low resources comparing with both
direct supervised learning and pretraining with all-observation trajectory
forecast.

æè¦ï¼æåæè­°ééåè¨ç·´ä¾åå­¸ç¿ä¸åèªæç£ç£çæ£èè»è·¡é æ¸¬å­¸ç¿è¦åï¼ä¸¦ééåç®æ¨ç´æ¥æä½³åæ£èè¡¨å¾µå¨å¾çºè¨åºçµæé æ¸¬ä¸­çæç¨ãæ­¤åç®æ¨ç´æ¥éå°å¾æªæ¨è¨çè¨åºæ¸¬éé æ¸¬æç¢ççè¡¨å¾µå¨å¾çºç£ç£å¼ä»»åä¸­çæç¨ã
åå­¸ç¿å¾ï¼å¯ä»¥ç´æ¥ç¨æ¼ç®æ¨é¢¨éªé æ¸¬ï¼ä¸å¯ä½¿ç¨æéçå¯ç¨æ¨£æ¬é²ä¸æ­¥å¾®èª¿æ¨¡åæè½ãæåçæ¹æ³ä¹æææ§å·²å¨ä¸åçå¯¦çéæ¾åå§ç¢¼æ£èé»å­çæ­·è³æé MIMIC-III ä¸é²è¡æ¸¬è©¦ãæåè½å¤ è­æï¼èç´æ¥ç£ç£å¼å­¸ç¿åä½¿ç¨ææè§å¯è»è·¡é æ¸¬é²è¡é è¨ç·´ç¸æ¯ï¼æååºæ¼æ³¨æåçæ£èçæè¡¨å¾µæ¹æ³å¯ä»¥éå°æ´å¥½çç®æ¨é¢¨éªé æ¸¬æè½ï¼ä¸è³æºéæ±è¼ä½ã

##### **Integrating Large Language Models into a Tri-Modal Architecture for Automated Depression Classification**
2407.19340v1 by Santosh V. Patapati

Major Depressive Disorder (MDD) is a pervasive mental health condition that
affects 300 million people worldwide. This work presents a novel, BiLSTM-based
tri-modal model-level fusion architecture for the binary classification of
depression from clinical interview recordings. The proposed architecture
incorporates Mel Frequency Cepstral Coefficients, Facial Action Units, and uses
a two-shot learning based GPT-4 model to process text data. This is the first
work to incorporate large language models into a multi-modal architecture for
this task. It achieves impressive results on the DAIC-WOZ AVEC 2016 Challenge
cross-validation split and Leave-One-Subject-Out cross-validation split,
surpassing all baseline models and multiple state-of-the-art models. In
Leave-One-Subject-Out testing, it achieves an accuracy of 91.01%, an F1-Score
of 85.95%, a precision of 80%, and a recall of 92.86%.

æè¦ï¼éåº¦æé¬±ç (MDD) æ¯ä¸ç¨®æ®éçç²¾ç¥å¥åº·ç¾çï¼
å½±é¿å¨ç 3 åäººãéé å·¥ä½æåºäºä¸ç¨®æ°ç©çãåºæ¼ BiLSTM
çä¸æ¨¡ææ¨¡åç´èåæ¶æ§ï¼ç¨æ¼å¾è¨åºè¨ªè«éé³ä¸­å°æé¬±çé²è¡äºååé¡ãææåºçæ¶æ§
çµåäºæ¢ç¾é »çåè­ä¿æ¸ãé¢é¨åä½å®åï¼ä¸¦ä½¿ç¨åºæ¼ GPT-4 çå©æ¬¡å­¸ç¿æ¨¡åä¾èçææ¬æ¸æãéæ¯ç¬¬ä¸å
å°å¤§åèªè¨æ¨¡åç´å¥å¤æ¨¡ææ¶æ§ä»¥å·è¡æ­¤ä»»åçå·¥ä½ãå®å¨ DAIC-WOZ AVEC 2016 ææ°è³½
äº¤åé©è­åå²åçä¸åè©¦èäº¤åé©è­åå²ä¸­åå¾äºä»¤äººå°è±¡æ·±å»ççµæï¼è¶è¶äºææåºç·æ¨¡ååå¤åæåé²çæ¨¡åãå¨
çä¸åè©¦èæ¸¬è©¦ä¸­ï¼å®çæºç¢ºçéå° 91.01%ï¼F1 åæ¸
çº 85.95%ï¼æºç¢ºåº¦çº 80%ï¼å¬åççº 92.86%ã

##### **Multi-Modal CLIP-Informed Protein Editing**
2407.19296v1 by Mingze Yin, Hanjing Zhou, Yiheng Zhu, Miao Lin, Yixuan Wu, Jialu Wu, Hongxia Xu, Chang-Yu Hsieh, Tingjun Hou, Jintai Chen, Jian Wu

Proteins govern most biological functions essential for life, but achieving
controllable protein discovery and optimization remains challenging. Recently,
machine learning-assisted protein editing (MLPE) has shown promise in
accelerating optimization cycles and reducing experimental workloads. However,
current methods struggle with the vast combinatorial space of potential protein
edits and cannot explicitly conduct protein editing using biotext instructions,
limiting their interactivity with human feedback. To fill these gaps, we
propose a novel method called ProtET for efficient CLIP-informed protein
editing through multi-modality learning. Our approach comprises two stages: in
the pretraining stage, contrastive learning aligns protein-biotext
representations encoded by two large language models (LLMs), respectively.
Subsequently, during the protein editing stage, the fused features from editing
instruction texts and original protein sequences serve as the final editing
condition for generating target protein sequences. Comprehensive experiments
demonstrated the superiority of ProtET in editing proteins to enhance
human-expected functionality across multiple attribute domains, including
enzyme catalytic activity, protein stability and antibody specific binding
ability. And ProtET improves the state-of-the-art results by a large margin,
leading to significant stability improvements of 16.67% and 16.90%. This
capability positions ProtET to advance real-world artificial protein editing,
potentially addressing unmet academic, industrial, and clinical needs.

æè¦ï¼<paragraph>èç½è´¨æç®¡çç»´æçå½æéçå¤§å¤æ°çç©åè½ï¼ä½è¦å®ç°å¯æ§çèç½è´¨åç°åä¼åä»ç¶å·ææææ§ãæè¿ï¼æºå¨å­¦ä¹ è¾å©èç½è´¨ç¼è¾ (MLPE) å·²æ¾ç¤ºåºå¨å éä¼åå¨æååå°å®éªå·¥ä½éæ¹é¢çåæ¯ãç¶èï¼å½åæ¹æ³é¾ä»¥åºå¯¹æ½å¨èç½è´¨ç¼è¾çå·¨å¤§ç»åç©ºé´ï¼å¹¶ä¸æ æ³æç¡®ä½¿ç¨çç©ææ¬è¯´æè¿è¡èç½è´¨ç¼è¾ï¼ä»èéå¶äºå®ä»¬ä¸äººç±»åé¦çäº¤äºæ§ãä¸ºäºå¡«è¡¥è¿äºç©ºç½ï¼æä»¬æåºäºä¸ç§ç§°ä¸º ProtET çæ°æ¹æ³ï¼ç¨äºéè¿å¤æ¨¡æå­¦ä¹ è¿è¡é«æç CLIP ç¥æèç½è´¨ç¼è¾ãæä»¬çæ¹æ³åæ¬ä¸¤ä¸ªé¶æ®µï¼å¨é¢è®­ç»é¶æ®µï¼å¯¹æ¯å­¦ä¹ å°åå«ç±ä¸¤ä¸ªå¤§åè¯­è¨æ¨¡å (LLM) ç¼ç çèç½è´¨çç©ææ¬è¡¨ç¤ºå¯¹é½ãéåï¼å¨èç½è´¨ç¼è¾é¶æ®µï¼æ¥èªç¼è¾æä»¤ææ¬ååå§èç½è´¨åºåçèåç¹å¾ä½ä¸ºçæç®æ èç½è´¨åºåçæç»ç¼è¾æ¡ä»¶ãç»¼åå®éªè¡¨æï¼ProtET å¨ç¼è¾èç½è´¨ä»¥å¢å¼ºè·¨å¤ä¸ªå±æ§åçäººç±»é¢æåè½æ¹é¢å·æä¼å¿ï¼åæ¬é¶å¬åæ´»æ§ãèç½è´¨ç¨³å®æ§åæä½ç¹å¼æ§ç»åè½åãProtET å°æåè¿çç»ææé«äºä¸ä¸ªå¾å¤§çå¹åº¦ï¼å¯¼è´ç¨³å®æ§æ¾çæé«äº 16.67% å 16.90%ãè¿ç§è½åä½¿ ProtET è½å¤æ¨è¿ç°å®ä¸ççäººå·¥èç½è´¨ç¼è¾ï¼æå¯è½æ»¡è¶³æªæ»¡è¶³çå­¦æ¯ãå·¥ä¸åä¸´åºéæ±ã</paragraph>

##### **Stochastic Parrots or ICU Experts? Large Language Models in Critical Care Medicine: A Scoping Review**
2407.19256v1 by Tongyue Shi, Jun Ma, Zihan Yu, Haowei Xu, Minqi Xiong, Meirong Xiao, Yilin Li, Huiying Zhao, Guilan Kong

With the rapid development of artificial intelligence (AI), large language
models (LLMs) have shown strong capabilities in natural language understanding,
reasoning, and generation, attracting amounts of research interest in applying
LLMs to health and medicine. Critical care medicine (CCM) provides diagnosis
and treatment for critically ill patients who often require intensive
monitoring and interventions in intensive care units (ICUs). Can LLMs be
applied to CCM? Are LLMs just like stochastic parrots or ICU experts in
assisting clinical decision-making? This scoping review aims to provide a
panoramic portrait of the application of LLMs in CCM. Literature in seven
databases, including PubMed, Embase, Scopus, Web of Science, CINAHL, IEEE
Xplore, and ACM Digital Library, were searched from January 1, 2019, to June
10, 2024. Peer-reviewed journal and conference articles that discussed the
application of LLMs in critical care settings were included. From an initial
619 articles, 24 were selected for final review. This review grouped
applications of LLMs in CCM into three categories: clinical decision support,
medical documentation and reporting, and medical education and doctor-patient
communication. LLMs have advantages in handling unstructured data and do not
require manual feature engineering. Meanwhile, applying LLMs to CCM faces
challenges, including hallucinations, poor interpretability, bias and alignment
challenges, and privacy and ethics issues. Future research should enhance model
reliability and interpretability, integrate up-to-date medical knowledge, and
strengthen privacy and ethical guidelines. As LLMs evolve, they could become
key tools in CCM to help improve patient outcomes and optimize healthcare
delivery. This study is the first review of LLMs in CCM, aiding researchers,
clinicians, and policymakers to understand the current status and future
potentials of LLMs in CCM.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) çå¿«éç¼å±ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨èªç¶èªè¨çè§£ãæ¨çåçææ¹é¢å±ç¾åºå¼·å¤§çè½åï¼å¸å¼äºå¤§éç ç©¶äººå¡å°å° LLM æç¨æ¼å¥åº·åé«å­¸é åçèè¶£ãéçé«å­¸ (CCM) çºçå±æ£èæä¾è¨ºæ·åæ²»çï¼éäºæ£èéå¸¸éè¦å¨éçç£è­·çæ¿ (ICU) ä¸­é²è¡å¯éç£æ§åå¹²é ãLLM è½å¦æç¨æ¼ CCMï¼LLM åå©è¨åºæ±ºç­æï¼æ¯å¦ååé¨æ©é¸éµ¡æ ICU å°å®¶ï¼æ¬ç¯åå¯©æ¥æ¨å¨æä¾ LLM å¨ CCM ä¸­æç¨çå¨æ¯æ¦æ³ãå¾ PubMedãEmbaseãScopusãWeb of ScienceãCINAHLãIEEE Xplore å ACM Digital Library ç­ä¸åè³æåº«ä¸­æå° 2019 å¹´ 1 æ 1 æ¥è³ 2024 å¹´ 6 æ 10 æ¥ä¹éçæç»ãç´å¥äºè¨è« LLM å¨éçç§è­·ç°å¢ä¸­æç¨çåè¡è©å¯©æååæè­°è«æãå¨æåç 619 ç¯è«æä¸­ï¼é¸åº 24 ç¯é²è¡æçµå¯©æ¥ãæ¬å¯©æ¥å° LLM å¨ CCM ä¸­çæç¨åçºä¸é¡ï¼è¨åºæ±ºç­æ¯æ´ãé«çæä»¶åå ±åï¼ä»¥åé«å­¸æè²åé«æ£æºéãLLM å¨èçéçµæ§åè³ææ¹é¢å·æåªå¢ï¼ä¸ä¸éè¦æåç¹å¾µå·¥ç¨ãåæï¼å° LLM æç¨æ¼ CCM é¢è¨ææ°ï¼åæ¬å¹»è¦ºãå¯è§£éæ§å·®ãåå·®åå°é½ææ°ï¼ä»¥åé±ç§åéå¾·åé¡ãæªä¾çç ç©¶æå å¼·æ¨¡åçå¯é æ§åå¯è§£éæ§ï¼æ´åææ°çé«å­¸ç¥è­ï¼ä¸¦å å¼·é±ç§åéå¾·æºåãé¨è LLM çç¼å±ï¼å®åå¯è½ææçº CCM ä¸­çééµå·¥å·ï¼æå©æ¼æ¹åæ£èçæ²»çææä¸¦åªåé«çä¿å¥æåãæ¬ç ç©¶æ¯ LLM å¨ CCM ä¸­çç¬¬ä¸ç¯å¯©æ¥ï¼æå©æ¼ç ç©¶äººå¡ãè¨åºé«çåæ¿ç­å¶å®èäºè§£ LLM å¨ CCM ä¸­çç¾çåæªä¾æ½åã

##### **Channel Boosted CNN-Transformer-based Multi-Level and Multi-Scale Nuclei Segmentation**
2407.19186v1 by Zunaira Rauf, Abdul Rehman Khan, Asifullah Khan

Accurate nuclei segmentation is an essential foundation for various
applications in computational pathology, including cancer diagnosis and
treatment planning. Even slight variations in nuclei representations can
significantly impact these downstream tasks. However, achieving accurate
segmentation remains challenging due to factors like clustered nuclei, high
intra-class variability in size and shape, resemblance to other cells, and
color or contrast variations between nuclei and background. Despite the
extensive utilization of Convolutional Neural Networks (CNNs) in medical image
segmentation, they may have trouble capturing long-range dependencies crucial
for accurate nuclei delineation. Transformers address this limitation but might
miss essential low-level features. To overcome these limitations, we utilized
CNN-Transformer-based techniques for nuclei segmentation in H&E stained
histology images. In this work, we proposed two CNN-Transformer architectures,
Nuclei Hybrid Vision Transformer (NucleiHVT) and Channel Boosted Nuclei Hybrid
Vision Transformer (CB-NucleiHVT), that leverage the strengths of both CNNs and
Transformers to effectively learn nuclei boundaries in multi-organ histology
images. The first architecture, NucleiHVT is inspired by the UNet architecture
and incorporates the dual attention mechanism to capture both multi-level and
multi-scale context effectively. The CB-NucleiHVT network, on the other hand,
utilizes the concept of channel boosting to learn diverse feature spaces,
enhancing the model's ability to distinguish subtle variations in nuclei
characteristics. Detailed evaluation of two medical image segmentation datasets
shows that the proposed architectures outperform existing CNN-based,
Transformer-based, and hybrid methods. The proposed networks demonstrated
effective results both in terms of quantitative metrics, and qualitative visual
assessment.

æè¦ï¼ç²¾ç¢ºçç´°èæ ¸åå²æ¯è¨ç®ççå­¸ä¸­åç¨®æç¨ï¼åæ¬ççè¨ºæ·åæ²»çè¦åï¼çåºç¤ãå³ä½¿ç´°èæ ¸è¡¨ç¾å½¢å¼æè¼å¾®è®åï¼ä¹æå°éäºä¸æ¸¸ä»»åç¢çéå¤§å½±é¿ãç¶èï¼ç±æ¼ç´°èæ ¸èéãå¤§å°åå½¢ççé¡å§è®ç°æ§é«ãèå¶ä»ç´°èç¸ä¼¼ãç´°èæ ¸èèæ¯ä¹éçé¡è²æå°æ¯åº¦è®åç­å ç´ ï¼å¯¦ç¾ç²¾ç¢ºåå²ä»ç¶å·æææ°æ§ãåç®¡å·ç©ç¥ç¶ç¶²è·¯ (CNN) å¨é«å­¸å½±ååå²ä¸­å¾å°å»£æ³æç¨ï¼ä½å®åå¯è½é£ä»¥ææå°æ¼ç²¾ç¢ºç´°èæ ¸æç¹ªè³ééè¦çé·ç¨ä¾è³´æ§ãTransformer è§£æ±ºäºéåéå¶ï¼ä½å¯è½æé¯éå¿è¦çä½éç¹å¾µãçºäºåæéäºéå¶ï¼æåå©ç¨åºæ¼ CNN-Transformer çæè¡å° H&E æè²ççµç¹å­¸å½±åé²è¡ç´°èæ ¸åå²ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºå©ç¨® CNN-Transformer æ¶æ§ï¼å³ç´°èæ ¸æ··åè¦è¦º Transformerï¼NucleiHVTï¼åééå¢å¼·ç´°èæ ¸æ··åè¦è¦º Transformerï¼CB-NucleiHVTï¼ï¼å®åå©ç¨ CNN å Transformer çåªå¢ä¾ææå­¸ç¿å¤å¨å®çµç¹å­¸å½±åä¸­çç´°èæ ¸éçãç¬¬ä¸åæ¶æ§ NucleiHVT åå° UNet æ¶æ§çåç¼ï¼ä¸¦çµåéæ³¨æåæ©å¶ä¾ææææå¤å±¤ç´åå¤å°ºåº¦çèæ¯ãå¦ä¸æ¹é¢ï¼CB-NucleiHVT ç¶²è·¯å©ç¨ééå¢å¼·çæ¦å¿µä¾å­¸ç¿ä¸åçç¹å¾µç©ºéï¼å¢å¼·æ¨¡åååç´°èæ ¸ç¹å¾µç´°å¾®è®åçè½åãå°å©åé«å­¸å½±ååå²è³æéçè©³ç´°è©ä¼°è¡¨æï¼ææåºçæ¶æ§åªæ¼ç¾æçåºæ¼ CNNãåºæ¼ Transformer åæ··åæ¹æ³ãææåºçç¶²è·¯å¨éåææ¨åå®æ§è¦è¦ºè©ä¼°æ¹é¢é½å±ç¤ºäºææçµæã

##### **AgentPeerTalk: Empowering Students through Agentic-AI-Driven Discernment of Bullying and Joking in Peer Interactions in Schools**
2408.01459v1 by Aditya Paul, Chi Lok Yu, Eva Adelina Susanto, Nicholas Wai Long Lau, Gwenyth Isobel Meadows

Addressing school bullying effectively and promptly is crucial for the mental
health of students. This study examined the potential of large language models
(LLMs) to empower students by discerning between bullying and joking in school
peer interactions. We employed ChatGPT-4, Gemini 1.5 Pro, and Claude 3 Opus,
evaluating their effectiveness through human review. Our results revealed that
not all LLMs were suitable for an agentic approach, with ChatGPT-4 showing the
most promise. We observed variations in LLM outputs, possibly influenced by
political overcorrectness, context window limitations, and pre-existing bias in
their training data. ChatGPT-4 excelled in context-specific accuracy after
implementing the agentic approach, highlighting its potential to provide
continuous, real-time support to vulnerable students. This study underlines the
significant social impact of using agentic AI in educational settings, offering
a new avenue for reducing the negative consequences of bullying and enhancing
student well-being.

æè¦ï¼ææä¸è¿éå°è§£æ±ºæ ¡åé¸åå°æ¼å­¸ççå¿çå¥åº·è³ééè¦ãæ¬ç ç©¶æ¢è¨äºå¤§åèªè¨æ¨¡å (LLM) çæ½åï¼è®å­¸çè½å¤ å¨æ ¡åååäºåä¸­ååé¸ååéç©ç¬ï¼é²èè³¦äºå­¸çæ¬åãæåæ¡ç¨ ChatGPT-4ãGemini 1.5 Pro å Claude 3 Opusï¼ä¸¦ééäººå·¥å¯©æ¥ä¾è©ä¼°å¶æè½ãæåççµæé¡¯ç¤ºï¼ä¸¦éææ LLM é½é©åä»£çæ¹æ³ï¼å¶ä¸­ ChatGPT-4 é¡¯ç¤ºåºæå¤§çæ½åãæåè§å¯å° LLM è¼¸åºçå·®ç°ï¼éå¯è½æ¯åå°æ¿æ²»éåº¦æ­£ç¢ºãå§å®¹è¦çªéå¶ä»¥åè¨ç·´è³æä¸­æ¢æåè¦çå½±é¿ãå¨å¯¦æ½ä»£çæ¹æ³å¾ï¼ChatGPT-4 å¨ç¹å®æå¢ä¸­çæºç¢ºæ§è¡¨ç¾åªç°ï¼çªé¡¯å¶æä¾æçºä¸å³ææ¯æ´çµ¦å¼±å¢å­¸ççæ½åãæ¬ç ç©¶å¼·èª¿äºå¨æè²ç°å¢ä¸­ä½¿ç¨ä»£çäººå·¥æºæ§çéå¤§ç¤¾æå½±é¿ï¼çºæ¸å°é¸åçè² é¢å¾æåæåå­¸ççç¦ç¥æä¾äºæ°çéå¾ã

##### **Large Language Models as Co-Pilots for Causal Inference in Medical Studies**
2407.19118v1 by Ahmed Alaa, Rachael V. Phillips, Emre KÄ±cÄ±man, Laura B. Balzer, Mark van der Laan, Maya Petersen

The validity of medical studies based on real-world clinical data, such as
observational studies, depends on critical assumptions necessary for drawing
causal conclusions about medical interventions. Many published studies are
flawed because they violate these assumptions and entail biases such as
residual confounding, selection bias, and misalignment between treatment and
measurement times. Although researchers are aware of these pitfalls, they
continue to occur because anticipating and addressing them in the context of a
specific study can be challenging without a large, often unwieldy,
interdisciplinary team with extensive expertise. To address this expertise gap,
we explore the use of large language models (LLMs) as co-pilot tools to assist
researchers in identifying study design flaws that undermine the validity of
causal inferences. We propose a conceptual framework for LLMs as causal
co-pilots that encode domain knowledge across various fields, engaging with
researchers in natural language interactions to provide contextualized
assistance in study design. We provide illustrative examples of how LLMs can
function as causal co-pilots, propose a structured framework for their
grounding in existing causal inference frameworks, and highlight the unique
challenges and opportunities in adapting LLMs for reliable use in
epidemiological research.

æè¦ï¼åºæ¼çå¯¦ä¸çè¨åºè³æçé«å­¸ç ç©¶ï¼ä¾å¦è§å¯æ§ç ç©¶ï¼å¶æææ§åæ±ºæ¼å¾åºé«çä»å¥å æçµè«æå¿è¦çééµåè¨­ãè¨±å¤å·²ç¼è¡¨çç ç©¶æå­å¨ç¼ºé·ï¼å çºå®åéåäºéäºåè¨­ï¼ä¸¦å°è´äºæ®çæ··æ·ãé¸æåèª¤ä»¥åæ²»çèæ¸¬éæéä¹éçä¸ä¸è´ç­åå·®ãåç®¡ç ç©¶äººå¡æè­å°éäºç¼ºé·ï¼ä½å®åä»ç¶æç¼çï¼å çºå¨å·é«çç ç©¶èæ¯ä¸é æä¸¦è§£æ±ºéäºç¼ºé·å¯è½å·æææ°æ§ï¼é¤éæä¸åé¾å¤§ä¸éå¸¸é£ä»¥æ§å¶çãææå»£æ³å°æ¥­ç¥è­çè·¨å­¸ç§åéãçºäºå½è£éç¨®å°æ¥­ç¥è­å·®è·ï¼æåæ¢ç´¢äºä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) ä½çºå¯é§é§å·¥å·ï¼ä»¥åå©ç ç©¶äººå¡è­å¥ç ´å£å ææ¨è«æææ§çç ç©¶è¨­è¨ç¼ºé·ãæåæåºäº LLM ä½çºå æå¯é§é§çæ¦å¿µæ¶æ§ï¼è©²æ¶æ§ç·¨ç¢¼äºè·¨åç¨®é åçé åç¥è­ï¼ä¸¦ééèªç¶èªè¨äºåèç ç©¶äººå¡äºåï¼ä»¥å¨ç ç©¶è¨­è¨ä¸­æä¾æå¢åçåå©ãæåæä¾äº LLM å¦ä½ä½çºå æå¯é§é§éä½çèªªææ§ç¯ä¾ï¼æåºäºå®åå¨ç¾æå ææ¨è«æ¡æ¶ä¸­æ¥å°ççµæ§åæ¡æ¶ï¼ä¸¦å¼·èª¿äºå¨æµè¡çå­¸ç ç©¶ä¸­é©æ LLM ä»¥å¯¦ç¾å¯é ä½¿ç¨çç¨ç¹ææ°åæ©éã

##### **Solving Robotics Problems in Zero-Shot with Vision-Language Models**
2407.19094v1 by Zidan Wang, Rui Shen, Bradly Stadie

We introduce Wonderful Team, a multi-agent visual LLM (VLLM) framework for
solving robotics problems in the zero-shot regime. By zero-shot we mean that,
for a novel environment, we feed a VLLM an image of the robot's environment and
a description of the task, and have the VLLM output the sequence of actions
necessary for the robot to complete the task. Prior work on VLLMs in robotics
has largely focused on settings where some part of the pipeline is fine-tuned,
such as tuning an LLM on robot data or training a separate vision encoder for
perception and action generation. Surprisingly, due to recent advances in the
capabilities of VLLMs, this type of fine-tuning may no longer be necessary for
many tasks. In this work, we show that with careful engineering, we can prompt
a single off-the-shelf VLLM to handle all aspects of a robotics task, from
high-level planning to low-level location-extraction and action-execution.
Wonderful Team builds on recent advances in multi-agent LLMs to partition tasks
across an agent hierarchy, making it self-corrective and able to effectively
partition and solve even long-horizon tasks. Extensive experiments on VIMABench
and real-world robotic environments demonstrate the system's capability to
handle a variety of robotic tasks, including manipulation, visual
goal-reaching, and visual reasoning, all in a zero-shot manner. These results
underscore a key point: vision-language models have progressed rapidly in the
past year, and should strongly be considered as a backbone for robotics
problems going forward.

æè¦ï¼<paragraph>æåæ¨åº Wonderful Teamï¼éæ¯ä¸åå¤ä»£çè¦è¦º LLM (VLLM) æ¶æ§ï¼ç¨æ¼è§£æ±ºé¶æ¬¡å­¸ç¿æ¨¡å¼ä¸çæ©å¨äººåé¡ãé¶æ¬¡å­¸ç¿æ¯æï¼å°æ¼ä¸åæ°ç°å¢ï¼æåå VLLM æä¾æ©å¨äººç°å¢çåååä»»åæè¿°ï¼ä¸¦è® VLLM è¼¸åºæ©å¨äººå®æä»»åæéçåä½åºåãæ©å¨äººé åä¸­ VLLM çååç ç©¶ä¸»è¦éä¸­å¨ç®¡éæä¸é¨åé²è¡å¾®èª¿çè¨­å®ä¸ï¼ä¾å¦éå°æ©å¨äººè³æå¾®èª¿ LLM æè¨ç·´ä¸åå®ç¨çè¦è¦ºç·¨ç¢¼å¨ä»¥é²è¡æç¥ååä½ç¢çãä»¤äººé©è¨çæ¯ï¼ç±æ¼ VLLM è½åçææ°é²å±ï¼å°æ¼è¨±å¤ä»»åä¾èªªï¼éç¨®å¾®èª¿å¯è½ä¸åå¿è¦ãå¨éé å·¥ä½ä¸­ï¼æåå±ç¤ºäºééä»ç´°çå·¥ç¨è¨­è¨ï¼æåå¯ä»¥æç¤ºä¸åå®ä¸çç¾æ VLLM ä¾èçæ©å¨äººä»»åçæææ¹é¢ï¼å¾é«å±¤ç´è¦åå°ä½å±¤ç´ä½ç½®æåååä½å·è¡ãWonderful Team å»ºç«å¨å¤ä»£ç LLM çææ°é²å±ä¸ï¼ä»¥å¨ä»£çå±¤ç´ä¸­åéä»»åï¼ä½¿å¶å·æèªæä¿®æ­£è½åï¼ä¸¦è½ææå°åéåè§£æ±ºé·é ä»»åãå¨ VIMABench åçå¯¦æ©å¨äººç°å¢ä¸­é²è¡çå»£æ³å¯¦é©è­æäºç³»çµ±èçåç¨®æ©å¨äººä»»åçè½åï¼åæ¬æä½ãè¦è¦ºç®æ¨éæåè¦è¦ºæ¨çï¼ææéäºé½æ¯å¨é¶æ¬¡å­¸ç¿æ¨¡å¼ä¸é²è¡çãéäºçµæå¼·èª¿äºä¸åéé»ï¼è¦è¦ºèªè¨æ¨¡åå¨éå»ä¸å¹´ä¸­é²æ­¥è¿éï¼ä¸¦ä¸æå¼·çèæ®ä½çºæ©å¨äººåé¡æªä¾çåºç¤ã</paragraph>

##### **Using Large Language Models for the Interpretation of Building Regulations**
2407.21060v1 by Stefan Fuchs, Michael Witbrock, Johannes Dimyadi, Robert Amor

Compliance checking is an essential part of a construction project. The
recent rapid uptake of building information models (BIM) in the construction
industry has created more opportunities for automated compliance checking
(ACC). BIM enables sharing of digital building design data that can be used for
compliance checking with legal requirements, which are conventionally conveyed
in natural language and not intended for machine processing. Creating a
computable representation of legal requirements suitable for ACC is complex,
costly, and time-consuming. Large language models (LLMs) such as the generative
pre-trained transformers (GPT), GPT-3.5 and GPT-4, powering OpenAI's ChatGPT,
can generate logically coherent text and source code responding to user
prompts. This capability could be used to automate the conversion of building
regulations into a semantic and computable representation. This paper evaluates
the performance of LLMs in translating building regulations into LegalRuleML in
a few-shot learning setup. By providing GPT-3.5 with only a few example
translations, it can learn the basic structure of the format. Using a system
prompt, we further specify the LegalRuleML representation and explore the
existence of expert domain knowledge in the model. Such domain knowledge might
be ingrained in GPT-3.5 through the broad pre-training but needs to be brought
forth by careful contextualisation. Finally, we investigate whether strategies
such as chain-of-thought reasoning and self-consistency could apply to this use
case. As LLMs become more sophisticated, the increased common sense, logical
coherence, and means to domain adaptation can significantly support ACC,
leading to more efficient and effective checking processes.

æè¦ï¼åè¦æª¢æ¥æ¯ä¸åå»ºè¨­å°æ¡çå¿è¦é¨åãå»ºç¯ç¢æ¥­æè¿å¿«éæ¡ç¨å»ºç¯è³è¨æ¨¡å (BIM)ï¼çºèªåååè¦æª¢æ¥ (ACC) åµé äºæ´å¤æ©æãBIM è½å¤ åäº«å¯ä¾ç¨æ¼èæ³å¾è¦æ±é²è¡åè¦æª¢æ¥çæ¸ä½å»ºç¯è¨­è¨è³æï¼èéäºè¦æ±éå¸¸ä»¥èªç¶èªè¨å³éï¼ä¸ä¸¦éç¨æ¼æ©å¨èçãå»ºç«ä¸åé©å ACC çæ³å¾è¦æ±å¯è¨ç®è¡¨ç¤ºéå¸¸è¤éãæè²´ä¸èæãå¤§åèªè¨æ¨¡å (LLM) ä¾å¦çæå¼é åè¨ç·´è½æå¨ (GPT)ãGPT-3.5 å GPT-4ï¼çº OpenAI ç ChatGPT æä¾ååï¼å¯ä»¥ç¢çåä¹éè¼¯çé£è²«æå­ååå§ç¢¼ï¼ä»¥åæä½¿ç¨èçæç¤ºãæ­¤åè½å¯ç¨æ¼èªååå°å»ºç¯æ³è¦è½æçºèªæåå¯è¨ç®çè¡¨ç¤ºãæ¬æè©ä¼°äº LLM å¨å°å»ºç¯æ³è¦ç¿»è­¯æ LegalRuleML çè¡¨ç¾ï¼ä¸¦æ¡ç¨å°æ¬¡å­¸ç¿è¨­å®ãééåæä¾å°æ¸ç¯ä¾ç¿»è­¯çµ¦ GPT-3.5ï¼å®å¯ä»¥å­¸ç¿æ ¼å¼çåºæ¬çµæ§ãä½¿ç¨ç³»çµ±æç¤ºï¼æåé²ä¸æ­¥æå® LegalRuleML è¡¨ç¤ºï¼ä¸¦æ¢è¨æ¨¡åä¸­æ¯å¦å­å¨å°å®¶é åç¥è­ãæ­¤é¡é åç¥è­å¯è½ééå»£æ³çé åè¨ç·´æ¤å¥ GPT-3.5ï¼ä½éè¦ééä»ç´°çèçµ¡åæè½ç¢çãæå¾ï¼æåæ¢è¨è«¸å¦æèéæ¨çåèªæä¸è´æ§ç­ç­ç¥æ¯å¦é©ç¨æ¼æ­¤ç¨ä¾ãé¨è LLM è®å¾æ´ç²¾ç·»ï¼å¸¸è­ãéè¼¯é£è²«æ§åé åé©ææ¹æ³çå¢å å¯ä»¥é¡¯èæ¯æ´ ACCï¼é²èå¸¶ä¾æ´ææçä¸ææçæª¢æ¥æµç¨ã

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

æè¦ï¼å¨ç¾ä»£é«çä¿å¥ä¸­ï¼è§£æ±ºæºç¢ºç¾çé æ¸¬ååæ§åå»ºè­°çè¤éæ§æ¢è³ééè¦åå·æææ°æ§ãæ¬ç ç©¶å¼å¥äº MLtoGAIï¼å®å°èªç¾©ç¶²è·¯æè¡èæ©å¨å­¸ç¿ (ML) ç¸çµåï¼ä»¥å¢å¼·ç¾çé æ¸¬ä¸¦éé ChatGPT æä¾ä½¿ç¨èååçèªªæãè©²ç³»çµ±åå«ä¸åééµçµæé¨åï¼ä¸åå¯éè¤ä½¿ç¨çç¾çæ¬ä½ï¼å¶ä¸­åå«æéåç¨®ç¾ççè©³ç´°ç¥è­ï¼ä¸åè¨ºæ·åé¡æ¨¡åï¼å®ä½¿ç¨æ£èççä¾æºç¢ºæª¢æ¸¬ç¹å®ç¾çï¼ä»¥åèªç¾©ç¶²è·¯è¦åèªè¨ (SWRL) èæ¬ä½å ChatGPT çæ´åï¼ä»¥ç¢çæ¸æ°ãåæ§åçå¥åº·å»ºè­°ãéç¨®æ¹æ³é¡¯èæé«äºé æ¸¬æºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºææ¼çè§£ççµæï¼è§£æ±ºäºç¾çåä¸åçççè¤éæ§ãMLtoGAI ç³»çµ±å±ç¤ºäºæºç¢ºæ§åä½¿ç¨èæ»¿æåº¦çå¯¦è³ªæ§é²æ­¥ï¼æå©æ¼éç¼æ´æºæ§ä¸æ´ææ¼åå¾çé«çä¿å¥è§£æ±ºæ¹æ¡ãéç¨®åµæ°çæ¹æ³çµåäº ML æ¼ç®æ³çåªé»ï¼ä»¥åéé ChatGPT æä¾éæä¸äººé¡å¯ä»¥çè§£çèªªæçè½åï¼å¨é æ¸¬æºç¢ºæ§åä½¿ç¨èçè§£æ¹é¢åå¾äºé¡¯èçé²æ­¥ãééå©ç¨èªç¾©æè¡åå¯è§£éç AIï¼è©²ç³»çµ±æé«äºç¾çé æ¸¬çæºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºå»ºè­°èåå¥æ£èç¸éä¸ææ¼çè§£ãæåçç ç©¶å¼·èª¿äºæ´ååé²æè¡ä»¥åæé«çè¨ºæ·ä¸­ç¾æææ°çæ½åï¼çºæºæ§é«çä¿å¥ç³»çµ±çæªä¾ç¼å±éªè·¯ãæ­¤å¤ï¼è©²ç³»çµ±ä½¿ç¨ 200 ååææ£èè³æè¨éé²è¡é©è­ï¼ç¢ºä¿äºç©©å¥çæè½åå¯é æ§ã

##### **Is larger always better? Evaluating and prompting large language models for non-generative medical tasks**
2407.18525v1 by Yinghao Zhu, Junyi Gao, Zixiang Wang, Weibin Liao, Xiaochen Zheng, Lifang Liang, Yasha Wang, Chengwei Pan, Ewen M. Harrison, Liantao Ma

The use of Large Language Models (LLMs) in medicine is growing, but their
ability to handle both structured Electronic Health Record (EHR) data and
unstructured clinical notes is not well-studied. This study benchmarks various
models, including GPT-based LLMs, BERT-based models, and traditional clinical
predictive models, for non-generative medical tasks utilizing renowned
datasets. We assessed 14 language models (9 GPT-based and 5 BERT-based) and 7
traditional predictive models using the MIMIC dataset (ICU patient records) and
the TJH dataset (early COVID-19 EHR data), focusing on tasks such as mortality
and readmission prediction, disease hierarchy reconstruction, and biomedical
sentence matching, comparing both zero-shot and finetuned performance. Results
indicated that LLMs exhibited robust zero-shot predictive capabilities on
structured EHR data when using well-designed prompting strategies, frequently
surpassing traditional models. However, for unstructured medical texts, LLMs
did not outperform finetuned BERT models, which excelled in both supervised and
unsupervised tasks. Consequently, while LLMs are effective for zero-shot
learning on structured data, finetuned BERT models are more suitable for
unstructured texts, underscoring the importance of selecting models based on
specific task requirements and data characteristics to optimize the application
of NLP technology in healthcare.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨é«å­¸ä¸­çæç¨æ¥çå»£æ³ï¼ä½å®ååæèççµæ§åé»å­çæ­· (EHR) è³æåéçµæ§åè¨åºè¨»è¨çè½åå°æªå¾å°ååç ç©¶ãæ¬ç ç©¶éå°åç¨®æ¨¡åé²è¡åºæºæ¸¬è©¦ï¼åæ¬åºæ¼ GPT ç LLMãåºæ¼ BERT çæ¨¡åï¼ä»¥åå³çµ±çè¨åºé æ¸¬æ¨¡åï¼ç¨æ¼å©ç¨èåè³æéçéçææ§é«çä»»åãæåä½¿ç¨ MIMIC è³æéï¼ICU çäººè¨éï¼å TJH è³æéï¼æ©æ COVID-19 EHR è³æï¼è©ä¼°äº 14 åèªè¨æ¨¡åï¼9 ååºæ¼ GPTï¼5 ååºæ¼ BERTï¼å 7 åå³çµ±é æ¸¬æ¨¡åï¼éé»éæ³¨æ­»äº¡çååå¥é¢é æ¸¬ãç¾çå±¤ç´éå»ºåçç©é«å­¸å¥å­éå°ç­ä»»åï¼ä¸¦æ¯è¼äºé¶æ¬¡å­¸ç¿åå¾®èª¿å¾çæè½ãçµæè¡¨æï¼LLM å¨ä½¿ç¨è¨­è¨è¯å¥½çæç¤ºç­ç¥æï¼å°çµæ§å EHR è³æå±ç¾åºå¼·å¤§çé¶æ¬¡å­¸ç¿é æ¸¬è½åï¼ç¶å¸¸è¶è¶å³çµ±æ¨¡åãç¶èï¼å°æ¼éçµæ§åçé«çææ¬ï¼LLM çè¡¨ç¾ä¸å¦å¾®èª¿å¾ç BERT æ¨¡åï¼å¾èå¨ç£ç£å¼åéç£ç£å¼ä»»åä¸­é½è¡¨ç¾åºè²ãå æ­¤ï¼åç®¡ LLM å°æ¼çµæ§åè³æçé¶æ¬¡å­¸ç¿å¾æç¨ï¼ä½å¾®èª¿å¾ç BERT æ¨¡åæ´é©åéçµæ§åææ¬ï¼éå¼·èª¿äºæ ¹æç¹å®ä»»åéæ±åè³æç¹æ§é¸ææ¨¡åä»¥åªåé«çä¿å¥ä¸­ NLP æè¡æç¨ä¹éè¦æ§ã

##### **A Role-specific Guided Large Language Model for Ophthalmic Consultation Based on Stylistic Differentiation**
2407.18483v4 by Laiyi Fu, Binbin Fan, Hongkai Du, Yanxiang Feng, Chunhua Li, Huping Song

Ophthalmology consultations are crucial for diagnosing, treating, and
preventing eye diseases. However, the growing demand for consultations exceeds
the availability of ophthalmologists. By leveraging large pre-trained language
models, we can design effective dialogues for specific scenarios, aiding in
consultations. Traditional fine-tuning strategies for question-answering tasks
are impractical due to increasing model size and often ignoring patient-doctor
role function during consultations. In this paper, we propose EyeDoctor, an
ophthalmic medical questioning large language model that enhances accuracy
through doctor-patient role perception guided and an augmented knowledge base
with external disease information. Experimental results show EyeDoctor achieves
higher question-answering precision in ophthalmology consultations. Notably,
EyeDoctor demonstrated a 7.25% improvement in Rouge-1 scores and a 10.16%
improvement in F1 scores on multi-round datasets compared to second best model
ChatGPT, highlighting the importance of doctor-patient role differentiation and
dynamic knowledge base expansion for intelligent medical consultations. EyeDoc
also serves as a free available web based service and souce code is available
at https://github.com/sperfu/EyeDoc.

æè¦ï¼ç¼ç§è«®è©¢å°æ¼è¨ºæ·ãæ²»çåé é²ç¼ç¾è³ééè¦ãç¶èï¼è«®è©¢éæ±çå¢å è¶éäºç¼ç§é«ççä¾æãééå©ç¨å¤§åé è¨ç·´èªè¨æ¨¡åï¼æåå¯ä»¥çºç¹å®å ´æ¯è¨­è¨ææçå°è©±ï¼åå©è«®è©¢ãå³çµ±çå¾®èª¿ç­ç¥å°æ¼åç­ä»»åä¾èªªæ¯ä¸åå¯¦éçï¼å çºæ¨¡åå¤§å°çå¢å ï¼èä¸å¨è«®è©¢æéå¸¸å¸¸å¿½ç¥æ£èåé«ççè§è²åè½ãå¨æ¬æä¸­ï¼æåæåº EyeDoctorï¼éæ¯ä¸åç¼ç§é«çåç­å¤§åèªè¨æ¨¡åï¼ééé«çåæ£èè§è²æç¥æå°åä¸åæ´åçå¤é¨ç¾çè³è¨ç¥è­åº«ä¾å¢å¼·æºç¢ºæ§ãå¯¦é©çµæé¡¯ç¤ºï¼EyeDoctor å¨ç¼ç§è«®è©¢ä¸­éå°äºæ´é«çåç­æºç¢ºåº¦ãå¼å¾æ³¨æçæ¯ï¼èç¬¬äºå¥½çæ¨¡å ChatGPT ç¸æ¯ï¼EyeDoctor å¨å¤è¼ªæ¸æéä¸ Rouge-1 åæ¸æé«äº 7.25%ï¼F1 åæ¸æé«äº 10.16%ï¼éçªé¡¯äºé«çåæ£èè§è²ååååæç¥è­åº«æ´åå°æ¼æºè½é«çè«®è©¢çéè¦æ§ãEyeDoc ä¹ä½çºä¸ååè²»çç¶²è·¯æåï¼åå§ç¢¼å¯ä»¥å¨ https://github.com/sperfu/EyeDoc åå¾ã

##### **Towards Automated Solution Recipe Generation for Industrial Asset Management with LLM**
2407.18992v1 by Nianjun Zhou, Dhaval Patel, Shuxin Lin, Fearghal O'Donncha

This study introduces a novel approach to Industrial Asset Management (IAM)
by incorporating Conditional-Based Management (CBM) principles with the latest
advancements in Large Language Models (LLMs). Our research introduces an
automated model-building process, traditionally reliant on intensive
collaboration between data scientists and domain experts. We present two
primary innovations: a taxonomy-guided prompting generation that facilitates
the automatic creation of AI solution recipes and a set of LLM pipelines
designed to produce a solution recipe containing a set of artifacts composed of
documents, sample data, and models for IAM. These pipelines, guided by
standardized principles, enable the generation of initial solution templates
for heterogeneous asset classes without direct human input, reducing reliance
on extensive domain knowledge and enhancing automation. We evaluate our
methodology by assessing asset health and sustainability across a spectrum of
ten asset classes. Our findings illustrate the potential of LLMs and
taxonomy-based LLM prompting pipelines in transforming asset management,
offering a blueprint for subsequent research and development initiatives to be
integrated into a rapid client solution.

æè¦ï¼æ¬ç ç©¶å¼å¥äºä¸ç¨®åµæ°çå·¥æ¥­è³ç¢ç®¡ç (IAM) æ¹æ³ï¼æ¹æ³æ¯å°åºæ¼æ¢ä»¶çç®¡ç (CBM) ååèå¤§åèªè¨æ¨¡å (LLM) çææ°é²å±ç¸çµåãæåçç ç©¶å¼å¥äºä¸åèªååæ¨¡åå»ºæ§æµç¨ï¼å³çµ±ä¸ä¾è³´æ¼æ¸æç§å­¸å®¶åé åå°å®¶ä¹éçå¯éåä½ãæåæåºäºå©é ä¸»è¦çåµæ°ï¼ä¸ç¨®åé¡å¼å°çæç¤ºçæï¼å®ä¿é²äº AI è§£æ±ºæ¹æ¡éæ¹ï¼recipeï¼çèªååµå»ºï¼ä»¥åä¸çµ LLM ç®¡éï¼æ¨å¨ç¢çä¸åè§£æ±ºæ¹æ¡éæ¹ï¼å¶ä¸­åå«ä¸çµç±æä»¶ãç¯ä¾è³æå IAM æ¨¡åçµæçæåãéäºç®¡éå¨æ¨æºåååçæå°ä¸ï¼è½å¤ çºç°è³ªè³ç¢é¡å¥ç¢çåå§è§£æ±ºæ¹æ¡ç¯æ¬ï¼ç¡éç´æ¥çäººå·¥è¼¸å¥ï¼å¾èæ¸å°å°å»£æ³é åç¥è­çä¾è³´ä¸¦å¢å¼·èªååãæåééè©ä¼°ååè³ç¢é¡å¥çè³ç¢å¥åº·çæ³åæ°¸çºæ§ä¾è©ä¼°æåçæè¡ãæåçç ç©¶çµæèªªæäº LLM ååºæ¼åé¡ç LLM æç¤ºç®¡ç·å¨è½åè³ç¢ç®¡çæ¹é¢çæ½åï¼çºå¾çºçç ç©¶åéç¼è¨ç«æä¾äºèåï¼éäºè¨ç«å°æ´åå°å¿«éå®¢æ¶è§£æ±ºæ¹æ¡ä¸­ã

##### **HDL-GPT: High-Quality HDL is All You Need**
2407.18423v1 by Bhuvnesh Kumar, Saurav Nanda, Ganapathy Parthasarathy, Pawan Patil, Austin Tsai, Parivesh Choudhary

This paper presents Hardware Description Language Generative Pre-trained
Transformers (HDL-GPT), a novel approach that leverages the vast repository of
open-source High Definition Language (HDL) codes to train superior quality
large code models. The core premise of this paper is the hypothesis that
high-quality HDL is all you need to create models with exceptional performance
and broad zero-shot generalization abilities. The paper elucidates the methods
employed for the curation and augmentation of large corpora from open-source
HDL code, transforming highly variable quality data into high-quality data
through careful prompting and context maintenance. We demonstrate that the
careful selection, filtering, and augmentation of data across HDLs can yield
powerful models that surpass current state-of-the-art models. We also explore
the impact of different fine-tuning methods on the quality of results. We
describe experimental results across a range of fine-tuned SOTA LLMs,
substantiating our claims. We demonstrate improvements of 50% to 200% over SOTA
HDL models on current benchmarks in tasks ranging from HDL circuit
explanations, code generation, formal and simulation testbench creation,
triaging bugs, and fixing them. HDL-GPT opens new avenues for the development
of advanced model training techniques for circuit design tasks.

æè¦ï¼æ¬ææåºç¡¬é«æè¿°èªè¨çæå¼é è¨ç·´è½æå¨ (HDL-GPT)ï¼éæ¯ä¸ç¨®æ°æ¹æ³ï¼å©ç¨å¤§ééæºé«å®ç¾©èªè¨ (HDL) ç¨å¼ç¢¼ä¾è¨ç·´åªè³ªçå¤§åç¨å¼ç¢¼æ¨¡åãæ¬æçæ ¸å¿åææ¯é«åè³ªç HDL æ¯å»ºç«å·æåè¶æè½åå»£æ³é¶æ¬¡å­¸ç¿æ¦åè½åæ¨¡åçå¯ä¸è¦ç´ ãæ¬æé¡æäºå¾éæº HDL ç¨å¼ç¢¼ç­å±åæ´åå¤§åèªæåº«æä½¿ç¨çæ¹æ³ï¼ééä»ç´°æç¤ºåèçµ¡ç¶­è­·ï¼å°åè³ªé«åº¦è®ç°çè³æè½ææé«åè³ªè³æãæåè­æäºä»ç´°é¸æãç¯©é¸åæ´å HDL ä¸­çè³æå¯ä»¥ç¢çå¼·å¤§çæ¨¡åï¼è¶è¶ç¾æçæåé²æ¨¡åãæåä¹æ¢è¨äºä¸åå¾®èª¿æ¹æ³å°çµæåè³ªçå½±é¿ãæåæè¿°äºéå°ä¸ç³»åå¾®èª¿éç SOTA LLM çå¯¦é©çµæï¼ä»¥è­å¯¦æåçèªªæ³ãæåè­æäºå¨å¾ HDL é»è·¯èªªæãç¨å¼ç¢¼ç¢çãæ­£å¼åæ¨¡æ¬æ¸¬è©¦å¹³å°å»ºç«ãåé¡é¯èª¤å°ä¿®æ­£é¯èª¤ç­ä»»åçç¾æåºæºä¸­ï¼HDL-GPT æ¯ SOTA HDL æ¨¡åé²æ­¥äº 50% è³ 200%ãHDL-GPT çºé»è·¯è¨­è¨ä»»åçé²éæ¨¡åè¨ç·´æè¡éç¼éåäºæ°éå¾ã

##### **SCALE: Self-regulated Clustered federAted LEarning in a Homogeneous Environment**
2407.18387v1 by Sai Puppala, Ismail Hossain, Md Jahangir Alam, Sajedul Talukder, Zahidur Talukder, Syed Bahauddin

Federated Learning (FL) has emerged as a transformative approach for enabling
distributed machine learning while preserving user privacy, yet it faces
challenges like communication inefficiencies and reliance on centralized
infrastructures, leading to increased latency and costs. This paper presents a
novel FL methodology that overcomes these limitations by eliminating the
dependency on edge servers, employing a server-assisted Proximity Evaluation
for dynamic cluster formation based on data similarity, performance indices,
and geographical proximity. Our integrated approach enhances operational
efficiency and scalability through a Hybrid Decentralized Aggregation Protocol,
which merges local model training with peer-to-peer weight exchange and a
centralized final aggregation managed by a dynamically elected driver node,
significantly curtailing global communication overhead. Additionally, the
methodology includes Decentralized Driver Selection, Check-pointing to reduce
network traffic, and a Health Status Verification Mechanism for system
robustness. Validated using the breast cancer dataset, our architecture not
only demonstrates a nearly tenfold reduction in communication overhead but also
shows remarkable improvements in reducing training latency and energy
consumption while maintaining high learning performance, offering a scalable,
efficient, and privacy-preserving solution for the future of federated learning
ecosystems.

æè¦ï¼è¯é¦å­¸ç¿ (FL) å·²æçºä¸ç¨®è®é©æ§æ¹æ³ï¼ç¨æ¼å¨ä¿è­·ä½¿ç¨èé±ç§çåæåç¨åæ£å¼æ©å¨å­¸ç¿ï¼ä½å®é¢è¨èè«¸å¦éè¨æçä½åä¾è³´æ¼éä¸­å¼åºç¤è¨­æ½ç­ææ°ï¼å°è´å»¶é²åææ¬å¢å ãæ¬ææåºäºä¸ç¨®æ°ç©ç FL æ¹æ³ï¼ééæ¶é¤å°éç·£ä¼ºæå¨çä¾è³´ï¼æ¡ç¨ä¼ºæå¨è¼å©çæ¥è¿åº¦è©ä¼°ä¾æ ¹æè³æç¸ä¼¼æ§ãæè½ææ¨åå°çæ¥è¿åº¦é²è¡åæå¢éå½¢æï¼å¾èåæäºéäºéå¶ãæåçæ´åæ¹æ³ééæ··åå¼åæ£å¼èååå®ä¾å¢å¼·éä½æçåå¯æ´åæ§ï¼è©²åå®å°æ¬å°æ¨¡åè¨ç·´èé»å°é»æ¬éäº¤æä»¥åç±åæé¸åºçé©åç¨å¼ç¯é»ç®¡ççéä¸­å¼æçµèååä½µå¨ä¸èµ·ï¼å¤§å¹æ¸å°äºæ´é«éè¨éé·ãæ­¤å¤ï¼è©²æ¹æ³åæ¬åæ£å¼é©åç¨å¼é¸æãæª¢æ¥é»ä»¥æ¸å°ç¶²è·¯æµéï¼ä»¥åç¨æ¼ç³»çµ±ç©©å¥æ§çå¥åº·çæé©è­æ©å¶ãæåçæ¶æ§ä½¿ç¨ä¹³çè³æéé²è¡é©è­ï¼ä¸åè­æéè¨éé·æ¸å°äºè¿ååï¼èä¸éé¡¯ç¤ºåºå¨éä½è¨ç·´å»¶é²åè½æºæ¶èçåæï¼å­¸ç¿æè½ä»ä¿æå¾é«çé¡¯èæ¹é²ï¼çºè¯é¦å­¸ç¿çæç³»çµ±çæªä¾æä¾äºä¸åå¯æ´åæ§ãé«æä¸ä¿è­·é±ç§çè§£æ±ºæ¹æ¡ã

##### **Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) æ¯å°äººå·¥æºæ§ (AI) åæ©å¨å­¸ç¿ (ML) æ¼ç®æ³æ´åå°è¨åºå¯¦åä¸­çè¾¯è«æ ¸å¿ãé«å·è¡æè½ç AI/ML æ¨¡åï¼ä¾å¦æ´é«å­¸ç¿å¨åæ·±åº¦ç¥ç¶ç¶²è·¯ï¼éå¸¸ç¼ºä¹å¯è§£éæ§ï¼é»ç¤è¨åºé«çå°å¶é æ¸¬çä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æ­£å¨éç¼ XAI æè¡ï¼ä»¥äººé¡å¯ä»¥çè§£çè¡èªæè¿° AI/ML é æ¸¬ãä¸åæå¸æçæ¹åæ¯æ¡ç¨ææåº¦åæ (SA) åå¨çææåº¦åæ (GSA)ï¼å®åæ¬è³ªä¸æä¾ææ¨¡åè¼¸å¥å°é æ¸¬çå½±é¿ä¾å°å¶é²è¡æåãå¨æ­¤ï¼æåä»ç´¹ä¸ç¨®æ°ç delta-XAI æ¹æ³ï¼ééæ´å GSA ææ¨ delta ææ¸ä¾æä¾ ML æ¨¡åé æ¸¬çå±é¨è§£éãdelta-XAI ææ¸è©ä¼°æ¯åç¹å¾µå¼å°åæ­¸ååé¡åé¡ä¸­åå¥ä¾é çé æ¸¬è¼¸åºä¹å½±é¿ãæåå° delta-XAI ææ¸å½¢å¼åï¼ä¸¦æä¾å¶å¯¦ä½çç¨å¼ç¢¼ãä½¿ç¨ç·æ§åæ­¸æ¨¡åå°æ¨¡æ¬æå¢è©ä¼° delta-XAI æ¹æ³ï¼ä¸¦ä»¥ Shapley å¼ä½çºåºæºãçµæé¡¯ç¤º delta-XAI ææ¸éå¸¸è Shapley å¼ä¸è´ï¼ä½å¨å·æé«åº¦å½±é¿åææ¥µç«¯ç¹å¾µå¼çæ¨¡åä¸­å­å¨é¡¯èå·®ç°ãdelta-XAI ææ¸å¨åµæ¸¬ä¸»è¦ç¹å¾µåèçæ¥µç«¯ç¹å¾µå¼æ¹é¢è¡¨ç¾åºæ´é«çææåº¦ãå®æ§å°ä¾èªªï¼delta-XAI ééå©ç¨æ©çå¯åº¦å½æ¸æä¾ç´è§çè§£éï¼ä½¿ç¹å¾µæåæ´æ¸æ°ä¸å°å¾æ¥­äººå¡ä¾èªªæ´å·å¯è§£éæ§ãç¸½é«èè¨ï¼delta-XAI æ¹æ³å°æ¼ç©©å¥å°åå¾ ML æ¨¡åé æ¸¬çå±é¨è§£éä¼¼ä¹å¾æå¸æãå°å¨çå¯¦ä¸ççè¨åºç°å¢ä¸­é²è¡é²ä¸æ­¥èª¿æ¥ï¼ä»¥è©ä¼°å¶å° AI è¼å©è¨åºå·¥ä½æµç¨çå½±é¿ã

##### **Self-supervised pre-training with diffusion model for few-shot landmark detection in x-ray images**
2407.18125v1 by Roberto Di Via, Francesca Odone, Vito Paolo Pastore

In the last few years, deep neural networks have been extensively applied in
the medical domain for different tasks, ranging from image classification and
segmentation to landmark detection. However, the application of these
technologies in the medical domain is often hindered by data scarcity, both in
terms of available annotations and images. This study introduces a new
self-supervised pre-training protocol based on diffusion models for landmark
detection in x-ray images. Our results show that the proposed self-supervised
framework can provide accurate landmark detection with a minimal number of
available annotated training images (up to 50), outperforming ImageNet
supervised pre-training and state-of-the-art self-supervised pre-trainings for
three popular x-ray benchmark datasets. To our knowledge, this is the first
exploration of diffusion models for self-supervised learning in landmark
detection, which may offer a valuable pre-training approach in few-shot
regimes, for mitigating data scarcity.

æè¦ï¼å¨éå»å¹¾å¹´ä¸­ï¼æ·±åº¦ç¥ç¶ç¶²è·¯å·²å»£æ³æç¨æ¼é«çé åçä¸åä»»åï¼å¾å½±ååé¡ååå²å°å°æ¨åµæ¸¬ãç¶èï¼éäºæè¡å¨é«çé åçæç¨å¸¸å¸¸åå°è³æç¨å°çé»ç¤ï¼ç¡è«æ¯å¨å¯ç¨çè¨»è§£æå½±åæ¹é¢ãæ¬ç ç©¶ä»ç´¹äºä¸åæ°çèªç£ç£é è¨ç·´åå®ï¼å®æ¯åºæ¼æ´æ£æ¨¡åï¼ç¨æ¼ X åå½±åä¸­çå°æ¨åµæ¸¬ãæåççµæé¡¯ç¤ºï¼ææåºçèªç£ç£æ¶æ§å¯ä»¥å¨æå°æ¸éçå¯ç¨è¨»è§£è¨ç·´å½±åï¼æå¤ 50 åï¼ä¸æä¾æºç¢ºçå°æ¨åµæ¸¬ï¼åªæ¼ ImageNet ç£ç£å¼é è¨ç·´ä»¥åä¸åç±é X ååºæºè³æéçææ°èªç£ç£å¼é è¨ç·´ãææåæç¥ï¼éæ¯é¦æ¬¡æ¢è¨æ´æ£æ¨¡åç¨æ¼å°æ¨åµæ¸¬ä¸­çèªç£ç£å¼å­¸ç¿ï¼å®å¯è½å¨å°æ¨£æ¬è¨ç·´æ¨¡å¼ä¸­æä¾æå¹å¼çé è¨ç·´æ¹æ³ï¼ä»¥æ¸è¼è³æç¨å°çåé¡ã

##### **Multi-Resolution Histopathology Patch Graphs for Ovarian Cancer Subtyping**
2407.18105v1 by Jack Breen, Katie Allen, Kieran Zucker, Nicolas M. Orsi, Nishant Ravikumar

Computer vision models are increasingly capable of classifying ovarian
epithelial cancer subtypes, but they differ from pathologists by processing
small tissue patches at a single resolution. Multi-resolution graph models
leverage the spatial relationships of patches at multiple magnifications,
learning the context for each patch. In this study, we conduct the most
thorough validation of a graph model for ovarian cancer subtyping to date.
Seven models were tuned and trained using five-fold cross-validation on a set
of 1864 whole slide images (WSIs) from 434 patients treated at Leeds Teaching
Hospitals NHS Trust. The cross-validation models were ensembled and evaluated
using a balanced hold-out test set of 100 WSIs from 30 patients, and an
external validation set of 80 WSIs from 80 patients in the Transcanadian Study.
The best-performing model, a graph model using 10x+20x magnification data, gave
balanced accuracies of 73%, 88%, and 99% in cross-validation, hold-out testing,
and external validation, respectively. However, this only exceeded the
performance of attention-based multiple instance learning in external
validation, with a 93% balanced accuracy. Graph models benefitted greatly from
using the UNI foundation model rather than an ImageNet-pretrained ResNet50 for
feature extraction, with this having a much greater effect on performance than
changing the subsequent classification approach. The accuracy of the combined
foundation model and multi-resolution graph network offers a step towards the
clinical applicability of these models, with a new highest-reported performance
for this task, though further validations are still required to ensure the
robustness and usability of the models.

æè¦ï¼é»è¦è¦è¦ºæ¨¡åè¶ä¾è¶è½å¤ åé¡åµå·¢ä¸ç®ççäºåï¼ä½å®åèççå­¸å®¶ä¸åï¼å®åä»¥å®ä¸è§£æåº¦èçå°çµç¹è²¼çãå¤è§£æåº¦åå½¢æ¨¡åå©ç¨å¤åæ¾å¤§åçä¸è²¼ççç©ºééä¿ï¼å­¸ç¿æ¯åè²¼ççèæ¯ãå¨éé ç ç©¶ä¸­ï¼æåå°åå½¢æ¨¡åé²è¡äºè¿ä»çºæ­¢æå¾¹åºçåµå·¢çäºåé©è­ãä½¿ç¨ 434 åå¨å©è²æå­¸é«é¢ NHS ä¿¡è¨åºéæ¥åæ²»ççæ£èç 1864 å¼µå¨å¹»ççå½±å (WSI) é²è¡äºåäº¤åé©è­ï¼èª¿æ´ä¸¦è¨ç·´äºä¸åæ¨¡åãå°äº¤åé©è­æ¨¡åéæä¸¦ä½¿ç¨ä¾èª 30 åæ£èç 100 å¼µ WSI çå¹³è¡¡çåºæ¸¬è©¦éåä¾èª Transcanadian ç ç©¶ä¸­ 80 åæ£èç 80 å¼µ WSI çå¤é¨é©è­éé²è¡è©ä¼°ãè¡¨ç¾æä½³çæ¨¡åï¼ä¸åä½¿ç¨ 10 å+20 åæ¾å¤§åçè³æçåå½¢æ¨¡åï¼å¨äº¤åé©è­ãçåºæ¸¬è©¦åå¤é¨é©è­ä¸­åå¥çµ¦åº 73%ã88% å 99% çå¹³è¡¡æºç¢ºåº¦ãç¶èï¼éåè¶éäºå¤é¨é©è­ä¸­åºæ¼æ³¨æåçå¤å¯¦ä¾å­¸ç¿çè¡¨ç¾ï¼å¹³è¡¡æºç¢ºåº¦çº 93%ãåå½¢æ¨¡åå¾ä½¿ç¨ UNI åºç¤æ¨¡åèä¸æ¯ ImageNet é è¨ç·´ç ResNet50 é²è¡ç¹å¾µæåä¸­åçåªæ·ºï¼èæ¹è®å¾çºåé¡æ¹æ³ç¸æ¯ï¼éå°æè½ææ´å¤§çå½±é¿ãçµååºç¤æ¨¡ååå¤è§£æåº¦åå½¢ç¶²è·¯çæºç¢ºåº¦çºéäºæ¨¡åçè¨åºæç¨éåºäºä¸æ­¥ï¼å°æ¼éé ä»»åä¾èªªï¼éæ¯æ°çæé«å ±åè¡¨ç¾ï¼åç®¡ä»éè¦é²ä¸æ­¥çé©è­ä¾ç¢ºä¿æ¨¡åçç©©å¥æ§åå¯ç¨æ§ã

##### **HG-PIPE: Vision Transformer Acceleration with Hybrid-Grained Pipeline**
2407.17879v2 by Qingyu Guo, Jiayong Wan, Songqiang Xu, Meng Li, Yuan Wang

Vision Transformer (ViT) acceleration with field programmable gate array
(FPGA) is promising but challenging. Existing FPGA-based ViT accelerators
mainly rely on temporal architectures, which process different operators by
reusing the same hardware blocks and suffer from extensive memory access
overhead. Pipelined architectures, either coarse-grained or fine-grained,
unroll the ViT computation spatially for memory access efficiency. However,
they usually suffer from significant hardware resource constraints and pipeline
bubbles induced by the global computation dependency of ViT. In this paper, we
introduce HG-PIPE, a pipelined FPGA accelerator for high-throughput and
low-latency ViT processing. HG-PIPE features a hybrid-grained pipeline
architecture to reduce on-chip buffer cost and couples the computation dataflow
and parallelism design to eliminate the pipeline bubbles. HG-PIPE further
introduces careful approximations to implement both linear and non-linear
operators with abundant Lookup Tables (LUTs), thus alleviating resource
constraints. On a ZCU102 FPGA, HG-PIPE achieves 2.78 times better throughput
and 2.52 times better resource efficiency than the prior-art accelerators,
e.g., AutoViTAcc. With a VCK190 FPGA, HG-PIPE realizes end-to-end ViT
acceleration on a single device and achieves 7118 images/s, which is 2.81 times
faster than a V100 GPU.

æè¦ï¼è¦è¦ºè®æå¨ (ViT) å éèç¾å ´å¯ç·¨ç¨éé£å (FPGA) åæ»¿åæ¯ï¼ä½å·æææ°æ§ãç¾æçåºæ¼ FPGA ç ViT å éå¨ä¸»è¦ä¾è³´æ¼æéæ¶æ§ï¼å®éééè¤ä½¿ç¨ç¸åçç¡¬é«åå¡ä¾èçä¸åçéç®å­ï¼ä¸¦æ¿åå¤§éçè¨æ¶é«å­åè² æãç¡è«æ¯ç²ç²åº¦æç´°ç²åº¦ï¼æµæ°´ç·æ¶æ§é½æå¨ç©ºéä¸å±é ViT è¨ç®ä»¥æé«è¨æ¶é«å­åæçãç¶èï¼å®åéå¸¸æåå°é¡¯èçç¡¬é«è³æºéå¶åç± ViT çå¨å±è¨ç®ä¾è³´æ§æå¼ç¼çæµæ°´ç·æ°£æ³¡å½±é¿ãå¨æ¬æä¸­ï¼æåä»ç´¹ HG-PIPEï¼ä¸ç¨®ç¨æ¼é«ééåä½å»¶é² ViT èççæµæ°´ç· FPGA å éå¨ãHG-PIPE æ¡ç¨æ··åç²åº¦æµæ°´ç·æ¶æ§ä»¥éä½æ¶çç·©è¡ææ¬ï¼ä¸¦çµåè¨ç®è³ææµç¨åä¸¦è¡è¨­è¨ä»¥æ¶é¤æµæ°´ç·æ°£æ³¡ãHG-PIPE é²ä¸æ­¥å¼å¥ä»ç´°çè¿ä¼¼å¼ï¼ä»¥ä½¿ç¨è±å¯çæ¥é±è¡¨ (LUT) å¯¦ä½ç·æ§åéç·æ§éç®å­ï¼å¾èæ¸è¼è³æºéå¶ãå¨ ZCU102 FPGA ä¸ï¼HG-PIPE çèçéæ¯ç¾æå éå¨ï¼ä¾å¦ AutoViTAccï¼é«åº 2.78 åï¼è³æºæçé«åº 2.52 åãä½¿ç¨ VCK190 FPGAï¼HG-PIPE å¨å®ä¸è£ç½®ä¸å¯¦ç¾ç«¯å°ç«¯ç ViT å éï¼ä¸¦å¯¦ç¾æ¯ç§ 7118 å¼µå½±åï¼æ¯ V100 GPU å¿« 2.81 åã

##### **EEG-SSM: Leveraging State-Space Model for Dementia Detection**
2407.17801v1 by Xuan-The Tran, Linh Le, Quoc Toan Nguyen, Thomas Do, Chin-Teng Lin

State-space models (SSMs) have garnered attention for effectively processing
long data sequences, reducing the need to segment time series into shorter
intervals for model training and inference. Traditionally, SSMs capture only
the temporal dynamics of time series data, omitting the equally critical
spectral features. This study introduces EEG-SSM, a novel state-space
model-based approach for dementia classification using EEG data. Our model
features two primary innovations: EEG-SSM temporal and EEG-SSM spectral
components. The temporal component is designed to efficiently process EEG
sequences of varying lengths, while the spectral component enhances the model
by integrating frequency-domain information from EEG signals. The synergy of
these components allows EEG-SSM to adeptly manage the complexities of
multivariate EEG data, significantly improving accuracy and stability across
different temporal resolutions. Demonstrating a remarkable 91.0 percent
accuracy in classifying Healthy Control (HC), Frontotemporal Dementia (FTD),
and Alzheimer's Disease (AD) groups, EEG-SSM outperforms existing models on the
same dataset. The development of EEG-SSM represents an improvement in the use
of state-space models for screening dementia, offering more precise and
cost-effective tools for clinical neuroscience.

æè¦ï¼çæç©ºéæ¨¡å (SSM) å ææèçé·è³æåºåèååéæ³¨ï¼æ¸å°å°æéåºååéæè¼ç­åéä»¥é²è¡æ¨¡åè¨ç·´åæ¨è«çéè¦ãå³çµ±ä¸ï¼SSM åªæ·åæéåºåè³æçæéåæï¼çç¥åæ¨£éè¦çé »è­ç¹å¾µãæ¬ç ç©¶æåº EEG-SSMï¼ä¸ç¨®æ°çåºæ¼çæç©ºéæ¨¡åçæ¹æ³ï¼ç¨æ¼ä½¿ç¨ EEG è³æé²è¡å¤±æºçåé¡ãæåçæ¨¡åå·æå©é ä¸»è¦çåµæ°ï¼EEG-SSM æéå EEG-SSM é »è­çµæé¨åãæéçµæé¨åæ¨å¨ææçå°èçé·åº¦ä¸åç EEG åºåï¼èé »è­çµæé¨åééæ´å EEG è¨èçé »åè³è¨ä¾å¢å¼·æ¨¡åãéäºçµæé¨åçååä½ç¨è® EEG-SSM è½éæ´»å°ç®¡çå¤è®é EEG è³æçè¤éæ§ï¼å¤§å¹æ¹åä¸åæéè§£æåº¦ä¸çæºç¢ºæ§åç©©å®æ§ãEEG-SSM å¨åé¡å¥åº·å°ç§çµ (HC)ãé¡é¡³èåå¤±æºç (FTD) åé¿è²æµ·é»ç (AD) çµå¥æå±ç¾åºé©äººç 91.0% æºç¢ºåº¦ï¼å¨ç¸åçè³æéä¸åªæ¼ç¾ææ¨¡åãEEG-SSM çéç¼ä»£è¡¨äºä½¿ç¨çæç©ºéæ¨¡åé²è¡å¤±æºçç¯©æª¢çé²æ­¥ï¼çºè¨åºç¥ç¶ç§å­¸æä¾æ´ç²¾ç¢ºä¸æ´å·ææ¬æççå·¥å·ã

##### **Closing the gap between open-source and commercial large language models for medical evidence summarization**
2408.00588v1 by Gongbo Zhang, Qiao Jin, Yiliang Zhou, Song Wang, Betina R. Idnay, Yiming Luo, Elizabeth Park, Jordan G. Nestor, Matthew E. Spotnitz, Ali Soroush, Thomas Campion, Zhiyong Lu, Chunhua Weng, Yifan Peng

Large language models (LLMs) hold great promise in summarizing medical
evidence. Most recent studies focus on the application of proprietary LLMs.
Using proprietary LLMs introduces multiple risk factors, including a lack of
transparency and vendor dependency. While open-source LLMs allow better
transparency and customization, their performance falls short compared to
proprietary ones. In this study, we investigated to what extent fine-tuning
open-source LLMs can further improve their performance in summarizing medical
evidence. Utilizing a benchmark dataset, MedReview, consisting of 8,161 pairs
of systematic reviews and summaries, we fine-tuned three broadly-used,
open-sourced LLMs, namely PRIMERA, LongT5, and Llama-2. Overall, the fine-tuned
LLMs obtained an increase of 9.89 in ROUGE-L (95% confidence interval:
8.94-10.81), 13.21 in METEOR score (95% confidence interval: 12.05-14.37), and
15.82 in CHRF score (95% confidence interval: 13.89-16.44). The performance of
fine-tuned LongT5 is close to GPT-3.5 with zero-shot settings. Furthermore,
smaller fine-tuned models sometimes even demonstrated superior performance
compared to larger zero-shot models. The above trends of improvement were also
manifested in both human and GPT4-simulated evaluations. Our results can be
applied to guide model selection for tasks demanding particular domain
knowledge, such as medical evidence summarization.

æè¦ï¼å¤§åè¯­è¨æ¨¡å (LLM) å¨æ»ç»å»å­¦è¯æ®æ¹é¢å·æå¾å¤§çåæ¯ãæè¿çç ç©¶ä¸»è¦éä¸­å¨ä¸æ LLM çåºç¨ä¸ãä½¿ç¨ä¸æ LLM ä¼å¼å¥å¤ä¸ªé£é©å ç´ ï¼åæ¬ç¼ºä¹éæåº¦åä¾åºåä¾èµæ§ãè½ç¶å¼æº LLM åè®¸æ´å¥½çéæåº¦åå®å¶ï¼ä½å®ä»¬çæ§è½ä¸ä¸æ LLM ç¸æ¯è¿ææä¸è¶³ãå¨è¿é¡¹ç ç©¶ä¸­ï¼æä»¬è°æ¥äºå¾®è°å¼æº LLM å¨å¤å¤§ç¨åº¦ä¸å¯ä»¥è¿ä¸æ­¥æé«å¶å¨æ»ç»å»å­¦è¯æ®æ¹é¢çæ§è½ãå©ç¨åºåæ°æ®é MedReviewï¼å¶ä¸­åå« 8,161 å¯¹ç³»ç»è¯ä»·åæè¦ï¼æä»¬å¾®è°äºä¸ä¸ªå¹¿æ³ä½¿ç¨çå¼æº LLMï¼å³ PRIMERAãLongT5 å Llama-2ãæ»ä½èè¨ï¼ç»è¿å¾®è°ç LLM å¨ ROUGE-L ä¸­å¢å äº 9.89ï¼95% ç½®ä¿¡åºé´ï¼8.94-10.81ï¼ï¼å¨ METEOR åæ°ä¸­å¢å äº 13.21ï¼95% ç½®ä¿¡åºé´ï¼12.05-14.37ï¼ï¼å¨ CHRF åæ°ä¸­å¢å äº 15.82ï¼95% ç½®ä¿¡åºé´ï¼13.89-16.44ï¼ãç»è¿å¾®è°ç LongT5 çæ§è½æ¥è¿äºé¶éå¤´è®¾ç½®ä¸ç GPT-3.5ãæ­¤å¤ï¼è¾å°çå¾®è°æ¨¡åææ¶çè³è¡¨ç°åºä¼äºè¾å¤§çé¶éå¤´æ¨¡åçæ§è½ãä¸è¿°æ¹è¿è¶å¿ä¹ä½ç°å¨äººç±»å GPT4 æ¨¡æè¯ä¼°ä¸­ãæä»¬çç»æå¯ç¨äºæå¯¼æ¨¡åéæ©ï¼ä»¥å®æéè¦ç¹å®é¢åç¥è¯çä»»å¡ï¼ä¾å¦å»å­¦è¯æ®æ»ç»ã

##### **Mpox Detection Advanced: Rapid Epidemic Response Through Synthetic Data**
2407.17762v1 by Yudara Kularathne, Prathapa Janitha, Sithira Ambepitiya, Prarththanan Sothyrajah, Thanveer Ahamed, Dinuka Wijesundara

Rapid development of disease detection models using computer vision is
crucial in responding to medical emergencies, such as epidemics or bioterrorism
events. Traditional data collection methods are often too slow in these
scenarios, requiring innovative approaches for quick, reliable model generation
from minimal data. Our study introduces a novel approach by constructing a
comprehensive computer vision model to detect Mpox lesions using only synthetic
data. Initially, these models generated a diverse set of synthetic images
representing Mpox lesions on various body parts (face, back, chest, leg, neck,
arm) across different skin tones as defined by the Fitzpatrick scale (fair,
brown, dark skin). Subsequently, we trained and tested a vision model with this
synthetic dataset to evaluate the diffusion models' efficacy in producing
high-quality training data and its impact on the vision model's medical image
recognition performance. The results were promising; the vision model achieved
a 97% accuracy rate, with 96% precision and recall for Mpox cases, and
similarly high metrics for normal and other skin disorder cases, demonstrating
its ability to correctly identify true positives and minimize false positives.
The model achieved an F1-Score of 96% for Mpox cases and 98% for normal and
other skin disorders, reflecting a balanced precision-recall relationship, thus
ensuring reliability and robustness in its predictions. Our proposed
SynthVision methodology indicates the potential to develop accurate computer
vision models with minimal data input for future medical emergencies.

æè¦ï¼<paragraph>å©ç¨é»è¦è¦è¦ºå¿«ééç¼ç¾çæª¢æ¸¬æ¨¡åå°æ¼å æé«çç·æ¥äºä»¶ï¼ä¾å¦æµè¡çæçç©ææä¸»ç¾©äºä»¶ï¼è³ééè¦ãå³çµ±çè³ææ¶éæ¹æ³å¨éäºææ³ä¸éå¸¸å¤ªæ¢ï¼éè¦åµæ°çæ¹æ³æè½å¾æå°è³æä¸­å¿«éãå¯é å°ç¢çæ¨¡åãæåçç ç©¶ä»ç´¹äºä¸ç¨®æ°ç©çæ¹æ³ï¼ééå»ºæ§ä¸åå¨é¢çé»è¦è¦è¦ºæ¨¡åï¼åä½¿ç¨åæè³æä¾æª¢æ¸¬ç´ççç¶ãæåï¼éäºæ¨¡åç¢çäºä¸çµå¤æ¨£åçåæå½±åï¼ä»£è¡¨äºä¸åèè²ï¼æ ¹æ Fitzpatrick éè¡¨å®ç¾©çºç½çãæ£è²ãæ·±è²ç®èï¼ä¸ä¸åèº«é«é¨ä½ï¼èé¨ãèé¨ãè¸é¨ãè¿é¨ãé ¸é¨ãæèï¼çç´ççç¶ãé¨å¾ï¼æåä½¿ç¨éååæè³æéè¨ç·´åæ¸¬è©¦ä¸åè¦è¦ºæ¨¡åï¼ä»¥è©ä¼°æ´æ£æ¨¡åç¢çé«åè³ªè¨ç·´è³æçæè½ï¼ä»¥åå¶å°è¦è¦ºæ¨¡åé«å­¸å½±åè¾¨è­æè½çå½±é¿ãçµæä»¤äººæ»¿æï¼è¦è¦ºæ¨¡åéå°äº 97% çæºç¢ºçï¼ç´ççä¾çæºç¢ºåº¦åå¬åççº 96%ï¼æ­£å¸¸åå¶å®ç®èç¾ççä¾çææ¨ä¹åæ¨£é«ï¼è­æäºå®æ­£ç¢ºè¾¨è­çé½æ§ä¸¦å°åé½æ§éè³æä½çè½åãè©²æ¨¡åå¨ç´ççä¾ä¸­éå°äº 96% ç F1 åæ¸ï¼å¨æ­£å¸¸åå¶å®ç®èç¾çä¸­éå°äº 98%ï¼åæ åºå¹³è¡¡çæºç¢ºåº¦å¬åçéä¿ï¼å¾èç¢ºä¿å¶é æ¸¬çå¯é æ§åç©©å¥æ§ãæåæåºç SynthVision æ¹æ³è¡¨æï¼æå¯è½çºæªä¾çé«çç·æ¥äºä»¶éç¼åºæºç¢ºçé»è¦è¦è¦ºæ¨¡åï¼ä¸è³æè¼¸å¥éæå°ã</paragraph>

##### **Cost-effective Instruction Learning for Pathology Vision and Language Analysis**
2407.17734v1 by Kaitao Chen, Mianxin Liu, Fang Yan, Lei Ma, Xiaoming Shi, Lilong Wang, Xiaosong Wang, Lifeng Zhu, Zhe Wang, Mu Zhou, Shaoting Zhang

The advent of vision-language models fosters the interactive conversations
between AI-enabled models and humans. Yet applying these models into clinics
must deal with daunting challenges around large-scale training data, financial,
and computational resources. Here we propose a cost-effective instruction
learning framework for conversational pathology named as CLOVER. CLOVER only
trains a lightweight module and uses instruction tuning while freezing the
parameters of the large language model. Instead of using costly GPT-4, we
propose well-designed prompts on GPT-3.5 for building generation-based
instructions, emphasizing the utility of pathological knowledge derived from
the Internet source. To augment the use of instructions, we construct a
high-quality set of template-based instructions in the context of digital
pathology. From two benchmark datasets, our findings reveal the strength of
hybrid-form instructions in the visual question-answer in pathology. Extensive
results show the cost-effectiveness of CLOVER in answering both open-ended and
closed-ended questions, where CLOVER outperforms strong baselines that possess
37 times more training parameters and use instruction data generated from
GPT-4. Through the instruction tuning, CLOVER exhibits robustness of few-shot
learning in the external clinical dataset. These findings demonstrate that
cost-effective modeling of CLOVER could accelerate the adoption of rapid
conversational applications in the landscape of digital pathology.

æè¦ï¼è¦è¦ºèªè¨æ¨¡åçåºç¾ä¿é²äº AI åç¨æ¨¡åèäººé¡ä¹éçäºåå°è©±ãç¶èï¼å°éäºæ¨¡åæç¨æ¼è¨åºå¿é æå°å¤§è¦æ¨¡è¨ç·´æ¸æãè²¡ååè¨ç®è³æºç­å´å³»ææ°ãå¨æ­¤ï¼æåæåºäºä¸ååçº CLOVER çç¶æ¿é«æçæè©±ççå­¸æä»¤å­¸ç¿æ¶æ§ãCLOVER åè¨ç·´ä¸åè¼éç´æ¨¡çµï¼ä¸¦å¨åçµå¤§åèªè¨æ¨¡ååæ¸çåæä½¿ç¨æä»¤å¾®èª¿ãæåæ²æä½¿ç¨æè²´ç GPT-4ï¼èæ¯éå° GPT-3.5 æåºè¨­è¨è¯å¥½çæç¤ºï¼ä»¥å»ºç«åºæ¼çæçæä»¤ï¼å¼·èª¿å¾ç¶²éç¶²è·¯ä¾æºè¡ççççç¥è­çæç¨ãçºäºæ´å±æä»¤çä½¿ç¨ï¼æåå¨æ¸ä½ççå­¸çèæ¯ä¸æ§å»ºäºä¸çµé«åè³ªçåºæ¼ç¯æ¬çæä»¤ãå¾å©ååºæºè³æéï¼æåçç ç©¶çµææ­ç¤ºäºæ··åå½¢å¼æä»¤å¨ççå­¸è¦è¦ºåç­ä¸­çåªå¢ãå»£æ³ççµæé¡¯ç¤ºäº CLOVER å¨åç­éæ¾å¼åå°éå¼åé¡æ¹é¢çç¶æ¿æçï¼å¶ä¸­ CLOVER åªæ¼ææå¤ 37 åè¨ç·´åæ¸ä¸¦ä½¿ç¨å¾ GPT-4 çæçæä»¤è³æçå¼·å¤§åºæºãééæä»¤å¾®èª¿ï¼CLOVER å¨å¤é¨è¨åºè³æéä¸­å±ç¾äºå°æ¨£æ¬å­¸ç¿çç©©å¥æ§ãéäºç¼ç¾è­æäº CLOVER çç¶æ¿é«æå»ºæ¨¡å¯ä»¥å éå¨æ¸ä½ççé åæ¡ç¨å¿«éå°è©±å¼æç¨ç¨å¼ã

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

æè¦ï¼å¤±æºçæ¯ä¸ç¨®å½±é¿å¨çæ¸ç¾è¬äººçè¡°å¼±æ§ç¥ç¶ç¾çï¼å¨è¨ºæ·ä¸å·æéå¤§ææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼ç¨æ¼å°å¤±æºåéå¤±æºèå¹´æ£èé²è¡åé¡ï¼ä½¿ç¨ 3D å¤§è¦ç£æ¯é å½± (MRI) ææãæåçåæ³æ¡ç¨äºä¸ç¨®ç¨ç¹æè¡ï¼ç¨æ¼é¸ææ§èç MRI åçï¼éé»éæ³¨æç¸éçå¤§è¦ååï¼ä¸¦æé¤ä¿¡æ¯éè¼å°çé¨åãéç¨®æ¹æ³ç±ä¸ååºæ¼ä¿¡å¿çåé¡å§å¡æè£åï¼è©²å§å¡æç±ä¸åèªå®ç¾©æ·±åº¦å­¸ç¿æ¨¡åçµæï¼Dem3D ResNetãDem3D CNN å Dem3D EfficientNetãéäºæ¨¡åååå·¥ä½ä»¥å¢å¼·æ±ºç­çæºç¢ºæ§ï¼å©ç¨å®åçéé«åªå¢ãå¨å½±åç ç©¶éæ¾å­åç³»å (OASIS) è³æéä¸é²è¡æ¸¬è©¦ï¼æåçæ¨¡åéå°äº 94.12% çé©äººæºç¢ºåº¦ï¼è¶éäºç¾ææ¹æ³ãæ­¤å¤ï¼å¨é¿è²æµ·é»çç¥ç¶å½±åå¡è­° (ADNI) è³æéä¸çé©è­è­å¯¦äºæåæ¹æ³çç©©å¥æ§åæ®éæ§ãå¯è§£é AI (XAI) æè¡åå¨é¢çæ¶èç ç©¶é²ä¸æ­¥è­å¯¦äºæåæè¡çæææ§ï¼æä¾äºå°æ±ºç­éç¨åæåæ¹æ³éè¦æ§çè¦è§£ãéé ç ç©¶çºå¤±æºçè¨ºæ·æä¾äºéå¤§é²å±ï¼çºè¨åºæç¨æä¾äºä¸åé«åº¦æºç¢ºä¸é«æçå·¥å·ã


### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-18**|**Building an Ethical and Trustworthy Biomedical AI Ecosystem for the Translational and Clinical Integration of Foundational Models**|Simha Sankar Baradwaj et.al.|[2408.01431v1](http://arxiv.org/abs/2408.01431v1)|null|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v1](http://arxiv.org/abs/2407.05440v1)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v1](http://arxiv.org/abs/2407.15851v1)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v2](http://arxiv.org/abs/2406.16908v2)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. ZajÄc et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel MirÃ³-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|SÃ©amus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|TimothÃ©e Schmude et.al.|[2401.13324v4](http://arxiv.org/abs/2401.13324v4)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v2](http://arxiv.org/abs/2311.12573v2)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|
|**2023-11-03**|**Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**|Emma A. M. Stanley et.al.|[2311.02115v2](http://arxiv.org/abs/2311.02115v2)|[link](https://github.com/estanley16/simba)|
|**2023-10-29**|**Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**|Adam White et.al.|[2310.19174v1](http://arxiv.org/abs/2310.19174v1)|null|
|**2023-10-03**|**Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**|Hossein Shreim et.al.|[2310.01828v2](http://arxiv.org/abs/2310.01828v2)|[link](https://github.com/geoaigroup/geoai-ecrs2023)|
|**2023-09-26**|**Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**|Muhammad Aurangzeb Ahmad et.al.|[2311.01463v1](http://arxiv.org/abs/2311.01463v1)|null|
|**2023-09-20**|**When to Trust AI: Advances and Challenges for Certification of Neural Networks**|Marta Kwiatkowska et.al.|[2309.11196v1](http://arxiv.org/abs/2309.11196v1)|null|
|**2023-09-19**|**Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**|Juan M. GarcÃ­a-GÃ³mez et.al.|[2309.10424v1](http://arxiv.org/abs/2309.10424v1)|null|
|**2023-09-19**|**QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**|Thanveer Shaik et.al.|[2309.10293v3](http://arxiv.org/abs/2309.10293v3)|null|
|**2023-09-18**|**Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**|Adarsa Sivaprasad et.al.|[2309.09917v1](http://arxiv.org/abs/2309.09917v1)|null|
|**2023-08-28**|**Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**|Yanjun Gao et.al.|[2308.14321v1](http://arxiv.org/abs/2308.14321v1)|null|
|**2023-08-18**|**Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**|Yun Xin Teoh et.al.|[2308.09380v1](http://arxiv.org/abs/2308.09380v1)|null|
|**2023-08-16**|**Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**|Munib Mesinovic et.al.|[2308.08407v1](http://arxiv.org/abs/2308.08407v1)|null|
|**2023-08-11**|**FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**|Karim Lekadir et.al.|[2309.12325v3](http://arxiv.org/abs/2309.12325v3)|null|
|**2023-08-10**|**Explainable AI applications in the Medical Domain: a systematic review**|Nicoletta Prentzas et.al.|[2308.05411v1](http://arxiv.org/abs/2308.05411v1)|null|
|**2023-08-01**|**Exploring the Role of Explainability in AI-Assisted Embryo Selection**|Lucia Urcelay et.al.|[2308.02534v1](http://arxiv.org/abs/2308.02534v1)|null|
|**2023-07-26**|**A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**|Timo Speith et.al.|[2307.14246v1](http://arxiv.org/abs/2307.14246v1)|null|
|**2023-07-26**|**Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**|Barnaby Crook et.al.|[2307.14239v1](http://arxiv.org/abs/2307.14239v1)|null|
|**2023-07-26**|**Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**|Henry Fraser et.al.|[2308.02047v1](http://arxiv.org/abs/2308.02047v1)|null|
|**2023-07-21**|**eXplainable Artificial Intelligence (XAI) in aging clock models**|Alena Kalyakulina et.al.|[2307.13704v3](http://arxiv.org/abs/2307.13704v3)|null|
|**2023-07-19**|**Interpreting and Correcting Medical Image Classification with PIP-Net**|Meike Nauta et.al.|[2307.10404v2](http://arxiv.org/abs/2307.10404v2)|[link](https://github.com/m-nauta/pipnet)|
|**2023-07-15**|**Explaining and visualizing black-box models through counterfactual paths**|Bastian Pfeifer et.al.|[2307.07764v3](http://arxiv.org/abs/2307.07764v3)|[link](https://github.com/pievos101/cpath)|
|**2023-07-05**|**Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research**|Toygar Tanyel et.al.|[2307.02131v5](http://arxiv.org/abs/2307.02131v5)|[link](https://github.com/toygarr/counterfactual-explanations-for-medical-research)|
|**2023-06-30**|**AI and Non AI Assessments for Dementia**|Mahboobeh Parsapoor et.al.|[2307.01210v1](http://arxiv.org/abs/2307.01210v1)|null|
|**2023-06-12**|**Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation**|Ruitao Xie et.al.|[2306.07306v1](http://arxiv.org/abs/2306.07306v1)|null|
|**2023-06-09**|**HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine**|Rodrigo Agerri et.al.|[2306.06029v1](http://arxiv.org/abs/2306.06029v1)|null|
|**2023-06-07**|**XInsight: Revealing Model Insights for GNNs with Flow-based Explanations**|Eli Laird et.al.|[2306.04791v1](http://arxiv.org/abs/2306.04791v1)|null|
|**2023-06-06**|**Explainable AI using expressive Boolean formulas**|Gili Rosenberg et.al.|[2306.03976v1](http://arxiv.org/abs/2306.03976v1)|null|
|**2023-06-06**|**Utterance Classification with Logical Neural Network: Explainable AI for Mental Disorder Diagnosis**|Yeldar Toleubay et.al.|[2306.03902v1](http://arxiv.org/abs/2306.03902v1)|null|
|**2023-06-02**|**XAI Renaissance: Redefining Interpretability in Medical Diagnostic Models**|Sujith K Mandala et.al.|[2306.01668v1](http://arxiv.org/abs/2306.01668v1)|null|
|**2023-05-26**|**A Novel real-time arrhythmia detection model using YOLOv8**|Guang Jun Nicholas Ang et.al.|[2305.16727v3](http://arxiv.org/abs/2305.16727v3)|null|
|**2023-05-22**|**Breast Cancer Segmentation using Attention-based Convolutional Network and Explainable AI**|Jai Vardhan et.al.|[2305.14389v2](http://arxiv.org/abs/2305.14389v2)|null|
|**2023-05-18**|**What Symptoms and How Long? An Interpretable AI Approach for Depression Detection in Social Media**|Junwei Kuang et.al.|[2305.13127v2](http://arxiv.org/abs/2305.13127v2)|null|
|**2023-05-17**|**Echoes of Biases: How Stigmatizing Language Affects AI Performance**|Yizhi Liu et.al.|[2305.10201v4](http://arxiv.org/abs/2305.10201v4)|null|
|**2023-05-05**|**Explaining the ghosts: Feminist intersectional XAI and cartography as methods to account for invisible labour**|Goda Klumbyte et.al.|[2305.03376v1](http://arxiv.org/abs/2305.03376v1)|null|

#### Abstracts
##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

æè¦ï¼æ¬ç ç©¶ä½¿ç¨çå­å­¸æ¡æ¶åææ··åäººå·¥æºæ§ç³»çµ±çè¨­è¨æ¨¡å¼åå¶å¨è¨åºæ±ºç­ä¸­çæææ§ãå®åé¡ä¸¦æ¯è¼çµåæ©å¨å­¸ç¿ååºæ¼è¦åçæ¨ççåç¨®æ¶æ§ï¼ä»¥æ·±å¥äºè§£å¶çµæ§åºç¤åé«çä¿å¥æç¨ãéå°å©åä¸»è¦åé¡ï¼å¦ä½æ ¹ææ¢å®çè¨­è¨æ¨¡å¼å°éäºç³»çµ±é²è¡åé¡ï¼ä»¥åå¦ä½ééæ¯è¼åææåè¦è§£ï¼æ¬ç ç©¶ä½¿ç¨è»é«å·¥ç¨ä¸­çè¨­è¨æ¨¡å¼ä¾äºè§£ååªåé«çä¿å¥äººå·¥æºæ§ç³»çµ±ãçå­å­¸æå©æ¼è­å¥å±æ§ä¸¦å»ºç«å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡ï¼å¾èå¢å¼·éäºç³»çµ±çå¯æ´åæ§ãå¯é æ§åæè½ãæª¢æ¥äºäºç¨®ä¸»è¦çæ¶æ§ï¼REMLãMLRBãRBMLãRMLT å PERMLãæ¯ç¨®æ¶æ§é½æç¨ç¹çåªç¼ºé»ï¼å¼·èª¿äºå¨è¨åºä»»åä¸­éè¦éèº«æé çæ¹æ³ãREML å¨è³ææéçè³æéä¸­è¡¨ç¾åºé«ç²¾åº¦çé æ¸¬ï¼MLRB å¨èçå¤§åè³æéåè¤éè³ææ´åæ¹é¢è¡¨ç¾åºè²ï¼RBML å¨å¯è§£éæ§åå¯ä¿¡åº¦æ¹é¢è¡¨ç¾åºè²ï¼RMLT å¨ç®¡çé«ç¶­è³ææ¹é¢è¡¨ç¾åºè²ï¼è PERML åç®¡å¨åææ¹é¢æéï¼ä½å¨ç·æ¥ç§è­·å ´æ¯ä¸­è¡¨ç¾åºæ½åãæ¬ç ç©¶å¼å¥äºåç¨®æ°æ¨¡å¼ï¼å»ºç«äºäºç¨®æ½è±¡åé¡æ¨¡å¼ï¼ä¸¦é²ä¸æ­¥å°éäºç¨®æ¨¡å¼ç´°åçºå·é«çç³»çµ±ãéäºè²¢ç»å¢å¼·äºçå­å­¸çåé¡çµç¹ï¼ä¸¦æä¾äºå°å°å®¶ç¥è­èæ©å¨å­¸ç¿æ´åçæ°æ¹æ³ãçå­å­¸ççµæ§åãæ¨¡çµåæ¹æ³å¨éç¼ååææ··åäººå·¥æºæ§ç³»çµ±ãæ­ç¤ºå±æ§ä»¥åæ¨å»£å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡æ¹é¢å·æé¡¯èåªå¢ãç¸½ä¹ï¼æ¬ç ç©¶å¼·èª¿äºæ··åäººå·¥æºæ§ç³»çµ±å¨æ¨é²é«çä¿å¥ä¸­çééµä½ç¨ï¼ä»¥åçå­å­¸å¨æ¨åäººå·¥æºæ§æ´åé²ä¸æ­¥åµæ°æ¹é¢çæ½åï¼æçµæ¹åè¨åºæ±ºç­æ¯æ´åæ£èçæ²»çææã

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

æè¦ï¼ç±æ¼å¶å¼·å¤§çé æ¸¬è½åï¼æ·±åº¦å­¸ç¿å·²æçºè¨±å¤ç¢æ¥­ä¸­ä¸å¯æç¼ºçå·¥å·ï¼åæ¬é«çä¿å¥ãç¶èï¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åéå¸¸ç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸å¿½ç¥äºå°é æ¸¬ä¸ç¢ºå®æ§ç´å¥èéï¼èéå©åå ç´ æ¯è¨åºæ±ºç­å¶å®çééµçµæé¨åãçºäºç¢çå¯è§£éä¸å·æä¸ç¢ºå®æ§æè­çé æ¸¬ï¼æ¬ç ç©¶æåºäºä¸ååçºè²æ°æ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯ (BKAN) çæ°æ¶æ§ï¼å®çµåäºæ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯çè¡¨éè½åèè²æ°æ¨è«ãæåå¨å©åé«å­¸è³æéä¸ä½¿ç¨ BKANï¼éäºè³æéæ¯è©ä¼°æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸è¨ºæ·ä¸­çå»£æ³ä½¿ç¨åºæºï¼ç®é¦¬å°ç¬¬å®äººç³å°¿çè³æéååéå¤«è­å¿èçè³æéãæåçæ¨¡åæä¾äºå°é æ¸¬ä¿¡å¿åæ±ºç­éççæçè¦è§£ï¼ä¸¦ä¸å¨é æ¸¬æºç¢ºåº¦æ¹é¢åªæ¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åãæ­¤å¤ï¼BKAN è¡¨ç¾é¨æ©åèªè­ä¸ç¢ºå®æ§çè½åï¼å¯ç¢ºä¿é«çç²å¾æ´å¯é ä¸å¼å¾ä¿¡è³´çæ±ºç­æ¯æ´ãæ ¹æå¯¦é©çµæï¼æåçè²æ°ç­ç¥æé«äºæ¨¡åçå¯è§£éæ§ï¼ä¸¦å¤§å¹æ¸å°äºéåº¦æ¬åï¼éå°æ¼å°åä¸ä¸å¹³è¡¡çé«å­¸è³æééå¸¸éè¦ãæåæåºäºå¯è½çæ´ååè½ï¼ä»¥é²ä¸æ­¥å° BKAN ç¨æ¼æ´è¤éçå¤æ¨¡å¼è³æéï¼ä¸¦æ¢è¨éäºç¼ç¾å°æ¼æªä¾å»ºç«å¯é çé«çä¿å¥ AI ç³»çµ±ç ç©¶çéè¦æ§ãéé å·¥ä½çºæ·±åº¦å­¸ç¿æ¨¡åé¨ç½²å¨éæåº¦åå¯é æ§è³ééè¦çéè¦é åä¸­éåäºä¸åæ°çå¸ç¯ã

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

æè¦ï¼å¨ç¾ä»£é«çä¿å¥ä¸­ï¼è§£æ±ºæºç¢ºç¾çé æ¸¬ååæ§åå»ºè­°çè¤éæ§æ¢è³ééè¦åå·æææ°æ§ãæ¬ç ç©¶å¼å¥äº MLtoGAIï¼å®å°èªç¾©ç¶²è·¯æè¡èæ©å¨å­¸ç¿ (ML) ç¸çµåï¼ä»¥å¢å¼·ç¾çé æ¸¬ä¸¦éé ChatGPT æä¾ä½¿ç¨èååçèªªæãè©²ç³»çµ±åå«ä¸åééµçµæé¨åï¼ä¸åå¯éè¤ä½¿ç¨çç¾çæ¬ä½ï¼å¶ä¸­åå«æéåç¨®ç¾ççè©³ç´°ç¥è­ï¼ä¸åè¨ºæ·åé¡æ¨¡åï¼å®ä½¿ç¨æ£èççä¾æºç¢ºæª¢æ¸¬ç¹å®ç¾çï¼ä»¥åèªç¾©ç¶²è·¯è¦åèªè¨ (SWRL) èæ¬ä½å ChatGPT çæ´åï¼ä»¥ç¢çæ¸æ°ãåæ§åçå¥åº·å»ºè­°ãéç¨®æ¹æ³é¡¯èæé«äºé æ¸¬æºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºææ¼çè§£ççµæï¼è§£æ±ºäºç¾çåä¸åçççè¤éæ§ãMLtoGAI ç³»çµ±å±ç¤ºäºæºç¢ºæ§åä½¿ç¨èæ»¿æåº¦çå¯¦è³ªæ§é²æ­¥ï¼æå©æ¼éç¼æ´æºæ§ä¸æ´ææ¼åå¾çé«çä¿å¥è§£æ±ºæ¹æ¡ãéç¨®åµæ°çæ¹æ³çµåäº ML æ¼ç®æ³çåªé»ï¼ä»¥åéé ChatGPT æä¾éæä¸äººé¡å¯ä»¥çè§£çèªªæçè½åï¼å¨é æ¸¬æºç¢ºæ§åä½¿ç¨èçè§£æ¹é¢åå¾äºé¡¯èçé²æ­¥ãééå©ç¨èªç¾©æè¡åå¯è§£éç AIï¼è©²ç³»çµ±æé«äºç¾çé æ¸¬çæºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºå»ºè­°èåå¥æ£èç¸éä¸ææ¼çè§£ãæåçç ç©¶å¼·èª¿äºæ´ååé²æè¡ä»¥åæé«çè¨ºæ·ä¸­ç¾æææ°çæ½åï¼çºæºæ§é«çä¿å¥ç³»çµ±çæªä¾ç¼å±éªè·¯ãæ­¤å¤ï¼è©²ç³»çµ±ä½¿ç¨ 200 ååææ£èè³æè¨éé²è¡é©è­ï¼ç¢ºä¿äºç©©å¥çæè½åå¯é æ§ã

##### **Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) æ¯å°äººå·¥æºæ§ (AI) åæ©å¨å­¸ç¿ (ML) æ¼ç®æ³æ´åå°è¨åºå¯¦åä¸­çè¾¯è«æ ¸å¿ãé«å·è¡æè½ç AI/ML æ¨¡åï¼ä¾å¦æ´é«å­¸ç¿å¨åæ·±åº¦ç¥ç¶ç¶²è·¯ï¼éå¸¸ç¼ºä¹å¯è§£éæ§ï¼é»ç¤è¨åºé«çå°å¶é æ¸¬çä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æ­£å¨éç¼ XAI æè¡ï¼ä»¥äººé¡å¯ä»¥çè§£çè¡èªæè¿° AI/ML é æ¸¬ãä¸åæå¸æçæ¹åæ¯æ¡ç¨ææåº¦åæ (SA) åå¨çææåº¦åæ (GSA)ï¼å®åæ¬è³ªä¸æä¾ææ¨¡åè¼¸å¥å°é æ¸¬çå½±é¿ä¾å°å¶é²è¡æåãå¨æ­¤ï¼æåä»ç´¹ä¸ç¨®æ°ç delta-XAI æ¹æ³ï¼ééæ´å GSA ææ¨ delta ææ¸ä¾æä¾ ML æ¨¡åé æ¸¬çå±é¨è§£éãdelta-XAI ææ¸è©ä¼°æ¯åç¹å¾µå¼å°åæ­¸ååé¡åé¡ä¸­åå¥ä¾é çé æ¸¬è¼¸åºä¹å½±é¿ãæåå° delta-XAI ææ¸å½¢å¼åï¼ä¸¦æä¾å¶å¯¦ä½çç¨å¼ç¢¼ãä½¿ç¨ç·æ§åæ­¸æ¨¡åå°æ¨¡æ¬æå¢è©ä¼° delta-XAI æ¹æ³ï¼ä¸¦ä»¥ Shapley å¼ä½çºåºæºãçµæé¡¯ç¤º delta-XAI ææ¸éå¸¸è Shapley å¼ä¸è´ï¼ä½å¨å·æé«åº¦å½±é¿åææ¥µç«¯ç¹å¾µå¼çæ¨¡åä¸­å­å¨é¡¯èå·®ç°ãdelta-XAI ææ¸å¨åµæ¸¬ä¸»è¦ç¹å¾µåèçæ¥µç«¯ç¹å¾µå¼æ¹é¢è¡¨ç¾åºæ´é«çææåº¦ãå®æ§å°ä¾èªªï¼delta-XAI ééå©ç¨æ©çå¯åº¦å½æ¸æä¾ç´è§çè§£éï¼ä½¿ç¹å¾µæåæ´æ¸æ°ä¸å°å¾æ¥­äººå¡ä¾èªªæ´å·å¯è§£éæ§ãç¸½é«èè¨ï¼delta-XAI æ¹æ³å°æ¼ç©©å¥å°åå¾ ML æ¨¡åé æ¸¬çå±é¨è§£éä¼¼ä¹å¾æå¸æãå°å¨çå¯¦ä¸ççè¨åºç°å¢ä¸­é²è¡é²ä¸æ­¥èª¿æ¥ï¼ä»¥è©ä¼°å¶å° AI è¼å©è¨åºå·¥ä½æµç¨çå½±é¿ã

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

æè¦ï¼å¤±æºçæ¯ä¸ç¨®å½±é¿å¨çæ¸ç¾è¬äººçè¡°å¼±æ§ç¥ç¶ç¾çï¼å¨è¨ºæ·ä¸å·æéå¤§ææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼ç¨æ¼å°å¤±æºåéå¤±æºèå¹´æ£èé²è¡åé¡ï¼ä½¿ç¨ 3D å¤§è¦ç£æ¯é å½± (MRI) ææãæåçåæ³æ¡ç¨äºä¸ç¨®ç¨ç¹æè¡ï¼ç¨æ¼é¸ææ§èç MRI åçï¼éé»éæ³¨æç¸éçå¤§è¦ååï¼ä¸¦æé¤ä¿¡æ¯éè¼å°çé¨åãéç¨®æ¹æ³ç±ä¸ååºæ¼ä¿¡å¿çåé¡å§å¡æè£åï¼è©²å§å¡æç±ä¸åèªå®ç¾©æ·±åº¦å­¸ç¿æ¨¡åçµæï¼Dem3D ResNetãDem3D CNN å Dem3D EfficientNetãéäºæ¨¡åååå·¥ä½ä»¥å¢å¼·æ±ºç­çæºç¢ºæ§ï¼å©ç¨å®åçéé«åªå¢ãå¨å½±åç ç©¶éæ¾å­åç³»å (OASIS) è³æéä¸é²è¡æ¸¬è©¦ï¼æåçæ¨¡åéå°äº 94.12% çé©äººæºç¢ºåº¦ï¼è¶éäºç¾ææ¹æ³ãæ­¤å¤ï¼å¨é¿è²æµ·é»çç¥ç¶å½±åå¡è­° (ADNI) è³æéä¸çé©è­è­å¯¦äºæåæ¹æ³çç©©å¥æ§åæ®éæ§ãå¯è§£é AI (XAI) æè¡åå¨é¢çæ¶èç ç©¶é²ä¸æ­¥è­å¯¦äºæåæè¡çæææ§ï¼æä¾äºå°æ±ºç­éç¨åæåæ¹æ³éè¦æ§çè¦è§£ãéé ç ç©¶çºå¤±æºçè¨ºæ·æä¾äºéå¤§é²å±ï¼çºè¨åºæç¨æä¾äºä¸åé«åº¦æºç¢ºä¸é«æçå·¥å·ã

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

æè¦ï¼å·¥æ¥­ 5.0 èéæ¼äººé¡èäººå·¥æºæ§ (AI) åä½å·è¡è£½é ä¸­çä¸åä»»åï¼æ¶åæ´å¤æ©å¨äººãç©è¯ç¶² (IoT) è£ç½®åäºé£ãæ´å¢/èæ¬å¯¦å¢ (AR) åå¶ä»æºæ§è£ç½®ãéäºè£ç½®åäºé£å¨ç¶æ¿ãé«çä¿å¥ãæè²ååé²ç³»çµ±ç­åç¨®ééµé åçå»£æ³åèï¼å¼ç¼äºå¤ç¨®é¡åçæ½å¨å®å¨æ¼æ´ãAI æ¬èº«å·²è¢«è­ææ¯ç¶²è·¯å®å¨ä¸åé åä¸­éå¸¸ææä¸å¼·å¤§çå·¥å·ï¼ä¾å¦å¥ä¾µåµæ¸¬ãæ¡æè»é«åµæ¸¬åç¶²è·¯é£é­åµæ¸¬ç­ãå°±åå¨è¨±å¤æç¨é åä¸æ¨£ï¼ç¶²è·¯å®å¨å°æ¥­äººå¡ä¸é¡ææ¥åé»ç ML è§£æ±ºæ¹æ¡ä¾æç¨æ¼ç¶²è·¯å®å¨ãéç¨®ä¸é¡æä¿ä½¿å¯è§£éäººå·¥æºæ§ (XAI) ä½çºä¸ç¨®å·¥å·è¢«æ¡ç¨ï¼æå©æ¼èªªæå¨åºæ¼ ML çç³»çµ±ä¸­å¦ä½ååºæ±ºç­ãå¨éé èª¿æ¥ä¸­ï¼æåå°å·¥æ¥­ 5.0 çä¸ååºæ¼ XAI çå¥ä¾µåµæ¸¬ç³»çµ±é²è¡äºå¨é¢çç ç©¶ï¼ä¸¦ä¸æåä¹ééå°æå¼ XIDS (Adv-XIDS) æ¹æ³çè§é»ä¾æ¢è¨å¯è§£éæ§åå¯è©®éæ§å°ç¶²è·¯å®å¨å¯¦åçå½±é¿ãæ­¤å¤ï¼æååæäºå·¥æ¥­ 5.0 ç XAI ç¶²è·¯å®å¨ç³»çµ±ä¸­å¯è½å­å¨çæ©æåææ°ï¼å¼ç¼äºæªä¾éå° XAI åºç¤è§£æ±ºæ¹æ¡çç ç©¶ï¼ä»¥ä¾é«é¢¨éªçå·¥æ¥­ 5.0 æç¨æ¡ç¨ãæåç¸ä¿¡éé å´è¬¹çåæå°çºæå®é åå§çå¾çºç ç©¶å·¥ä½å»ºç«åºç¤æ¶æ§ã

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

æè¦ï¼æ¬ç ç©¶æ¨å¨æ¢è¨å°èªç¶èªè¨èç (NLP) åæ©å¨å­¸ç¿ (ML) æè¡å¯¦ä½æ¼é«çä¿¡å½ç·¨ç¢¼èªååï¼ä¸¦å·åè¦è¦ºåèªªæè½ååè¼éåçæ¬å°é»è¦è¨­å®ãç®åå¨è¨åºç°å¢ä¸­ï¼ç·¨ç¢¼æ¯ä¸ç¨®æåæµç¨ï¼æ¶åçºçæ£æä»¶ä¸­çæ¯é ççãç¨åºåè¥ç©ææ´¾ä»£ç¢¼ (ä¾å¦ï¼ä½¿ç¨ SNOMED CT ä»£ç¢¼ 56265001 è¡¨ç¤ºå¿èç)ãæ­¤é åæä½¿ç¨ææ° ML æ¨¡åé²è¡èªåç·¨ç¢¼çåæ­¥ç ç©¶ï¼ç¶èï¼ç±æ¼æ¨¡åçè¤éæ§åå¤§å°ï¼ä¸¦æªå¯¦ç¾å¯¦éé¨ç½²ãçºäºé²ä¸æ­¥ä¿é²èªåç·¨ç¢¼å¯¦åçå¯è½æ§ï¼æåå¨æ¬å°é»è¦è¨­å®ä¸­æ¢è¨äºä¸äºè§£æ±ºæ¹æ¡ï¼æ­¤å¤ï¼æåæ¢è¨äºèªªæåè½å¨ AI æ¨¡åéæåº¦ä¸­çåè½ãæåä½¿ç¨å¬éç MIMIC-III è³æåº«å HAN/HLAN ç¶²è·¯æ¨¡åé²è¡ ICD ä»£ç¢¼é æ¸¬ãæåéè©¦é©äº ICD å SNOMED CT ç¥è­åº«ä¹éçå°æãå¨æåçå¯¦é©ä¸­ï¼éäºæ¨¡åæä¾äº 97.98% ä»£ç¢¼çæç¨è³è¨ãéé èª¿æ¥çµæå¯ä»¥çºå¯¦åä¸­çèªåè¨åºç·¨ç¢¼å¯¦ä½æä¾ä¸äºè¦è§£ï¼ä¾å¦å¨é«é¢ç°å¢ä¸­ï¼ç±è¨åºé«çä½¿ç¨çæ¬å°é»è¦ï¼å°æ¡é é¢ \url{https://github.com/Glenj01/Medical-Coding}ã

##### **Building an Ethical and Trustworthy Biomedical AI Ecosystem for the Translational and Clinical Integration of Foundational Models**
2408.01431v1 by Simha Sankar Baradwaj, Destiny Gilliland, Jack Rincon, Henning Hermjakob, Yu Yan, Irsyad Adam, Gwyneth Lemaster, Dean Wang, Karol Watson, Alex Bui, Wei Wang, Peipei Ping

Foundational Models (FMs) are emerging as the cornerstone of the biomedical
AI ecosystem due to their ability to represent and contextualize multimodal
biomedical data. These capabilities allow FMs to be adapted for various tasks,
including biomedical reasoning, hypothesis generation, and clinical
decision-making. This review paper examines the foundational components of an
ethical and trustworthy AI (ETAI) biomedical ecosystem centered on FMs,
highlighting key challenges and solutions. The ETAI biomedical ecosystem is
defined by seven key components which collectively integrate FMs into clinical
settings: Data Lifecycle Management, Data Processing, Model Development, Model
Evaluation, Clinical Translation, AI Governance and Regulation, and Stakeholder
Engagement. While the potential of biomedical AI is immense, it requires
heightened ethical vigilance and responsibility. For instance, biases can arise
from data, algorithms, and user interactions, necessitating techniques to
assess and mitigate bias prior to, during, and after model development.
Moreover, interpretability, explainability, and accountability are key to
ensuring the trustworthiness of AI systems, while workflow transparency in
training, testing, and evaluation is crucial for reproducibility. Safeguarding
patient privacy and security involves addressing challenges in data access,
cloud data privacy, patient re-identification, membership inference attacks,
and data memorization. Additionally, AI governance and regulation are essential
for ethical AI use in biomedicine, guided by global standards. Furthermore,
stakeholder engagement is essential at every stage of the AI pipeline and
lifecycle for clinical translation. By adhering to these principles, we can
harness the transformative potential of AI and develop an ETAI ecosystem.

æè¦ï¼åºç¤æ¨¡å (FM) ç±æ¼è½è¡¨ç¤ºåèªå¢åå¤æ¨¡æçç©é«å­¸æ¸æçè½åï¼èæçºçç©é«å­¸ AI çæç³»çµ±çåºç³ãéäºè½åè® FM è½é©æåç¨®ä»»åï¼åæ¬çç©é«å­¸æ¨çãåè¨­ç¢çåè¨åºæ±ºç­å¶å®ãéç¯è©è«è«ææ¢è¨äºä»¥ FM çºä¸­å¿çéå¾·åå¯ä¿¡è³´ AI (ETAI) çç©é«å­¸çæç³»çµ±çåºæ¬çµæé¨åï¼éé»èªªæäºééµææ°åè§£æ±ºæ¹æ¡ãETAI çç©é«å­¸çæç³»çµ±ç±ä¸åééµçµæé¨åå®ç¾©ï¼éäºçµæé¨åå±åå° FM æ´åå°è¨åºç°å¢ä¸­ï¼è³æçå½é±æç®¡çãè³æèçãæ¨¡åéç¼ãæ¨¡åè©ä¼°ãè¨åºè½è­¯ãAI æ²»çåæ³è¦ï¼ä»¥åå©å®³éä¿äººåèãåç®¡çç©é«å­¸ AI çæ½åå·¨å¤§ï¼ä½å®éè¦é«åº¦çéå¾·è­¦è¦ºæ§åè²¬ä»»æãä¾å¦ï¼åè¦å¯è½ä¾èªè³æãæ¼ç®æ³åä½¿ç¨èäºåï¼å æ­¤éè¦å¨æ¨¡åéç¼ä¹åãæéåä¹å¾è©ä¼°åæ¸è¼åè¦çæè¡ãæ­¤å¤ï¼å¯è§£éæ§ãå¯èªªææ§ååè²¬å¶æ¯ç¢ºä¿ AI ç³»çµ±å¯ä¿¡è³´æ§çééµï¼èè¨ç·´ãæ¸¬è©¦åè©ä¼°ä¸­çå·¥ä½æµç¨éæåº¦å°æ¼å¯è¤è£½æ§è³ééè¦ãä¿éçæ£é±ç§åå®å¨æ¶åè§£æ±ºè³æå­åãé²ç«¯è³æé±ç§ãçæ£åè­å¥ãæå¡æ¨è«æ»æåè³æè¨æ¶åç­ææ°ãæ­¤å¤ï¼AI æ²»çåæ³è¦å°æ¼å¨çç©é«å­¸ä¸­ä½¿ç¨éå¾· AI è³ééè¦ï¼ä¸¦ä»¥å¨çæ¨æºçºæå°ãæ­¤å¤ï¼å©å®³éä¿äººåèå¨ AI ç®¡ç·åè¨åºè½è­¯ççå½é±æä¸­æ¯åéæ®µé½è³ééè¦ãéééµå®éäºååï¼æåå¯ä»¥å©ç¨ AI çè½åæ½åï¼ä¸¦éç¼ä¸å ETAI çæç³»çµ±ã

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

æè¦ï¼äººå·¥æºè½ (AI) æ¯æçæ±ºç­å¶å®æ¯æªä¾ 6G ç¶²è·¯ä¸­çééµåç´ ï¼å¶ä¸­å°å¼å¥åç AI çæ¦å¿µãæ­¤å¤ï¼AI å»£æ³ç¨æ¼ä¸åçééµæç¨ä¸­ï¼ä¾å¦èªåé§é§åé«çè¨ºæ·ãå¨éäºæç¨ä¸­ï¼ä½¿ç¨ AI ä½çºé»çæ¨¡åæ¯æé¢¨éªä¸å·æææ°æ§çãå æ­¤ï¼çè§£åä¿¡ä»»éäºæ¨¡åååºçæ±ºç­è³ééè¦ãè§£æ±ºæ­¤åé¡çæ¹æ³æ¯éç¼å¯è§£é AI (XAI) æ¶æ§ï¼æ¨å¨è§£éé»çæ¨¡åè¡çºèå¾çéè¼¯ï¼å¾èç¢ºä¿å¶ææä¸å®å¨çé¨ç½²ãæè¿ï¼æåæåºäºä¸åæ°çåºæ¼æ¾åç XAI-CHEST æ¡æ¶ï¼è©²æ¡æ¶é¢åç¡ç·éä¿¡ä¸­çä¿¡éä¼°è¨ãXAI-CHEST æ¡æ¶çæ ¸å¿ææ³æ¯ééå¨ç¡éè¼¸å¥ä¸å¼å¥é«åªè²ä¾è­å¥ç¸éæ¨¡åè¼¸å¥ãéä»½æç¨¿æä¾äº XAI-CHEST æ¡æ¶çè©³ç´°çè«åºç¤ãç¹å¥æ¯ï¼æåæ¨å°äº XAI-CHEST æå¤±å½æ¸ååªè²é¾å¼å¾®èª¿åªååé¡çè§£æè¡¨éå¼ãå æ­¤ï¼è¨­è¨ç XAI-CHEST æä¾äºä¸ç¨®æºè½è¼¸å¥ç¹å¾µé¸ææ¹æ³ï¼å¯ä»¥å¨åªåæç¨æ¨¡åçæ¶æ§çåæé²ä¸æ­¥æé«æ´é«æ§è½ãæ¨¡æ¬çµæè¡¨æï¼XAI-CHEST æ¡æ¶æä¾äºææçè§£éï¼å¨éä½æéçè¨ç®è¤éåº¦çåæï¼æä¾äºæ¹é²çæ¯ç¹é¯èª¤çæ§è½ï¼èéèåºæ¼å³çµ± DL çä¿¡éä¼°è¨ç¸æ¯ã

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v1 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

æè¦ï¼<paragraph>æ¬ææåºäºç¨äºè§ç½èç¼åºå¾åç¾çåç±»çæ©å¼ æ®å·®ç½ç» (ResNet) æ¨¡åãæ©å¼ å·ç§¯æ»¤æ³¢å¨ç¨äºæ¿æ¢ ResNet æ¨¡åè¾é«å±ä¸­çæ­£å¸¸å·ç§¯æ»¤æ³¢å¨ï¼æ©å¼  ResNetï¼ï¼ä»¥æ¹åä¸ç¨äºç¾çåç±»çæ­£å¸¸ ResNet æ¨¡åç¸æ¯çæåéãæ¬ç ç©¶ä»ç»äºéç¨æ·±åº¦å­¦ä¹ çè®¡ç®æºè¾å©è¯æ­å·¥å·ï¼å¹¶éè¿å¯è§£éç AI ææ¯è¿è¡äºå¢å¼ºãè¿äºææ¯æ¨å¨ä½¿è¯¥å·¥å·çå³ç­è¿ç¨éæåï¼ä»èä½¿å»çä¸ä¸äººåè½å¤çè§£åä¿¡ä»» AI çè¯æ­å³ç­ãå®ä»¬å¨å½ä»å»çä¿å¥é¢åå°¤ä¸ºéè¦ï¼å ä¸ºå¯¹ AI åºç¨ç¨åºçéæåº¦éæ±ä¸æ­å¢é¿ï¼ä»¥ç¡®ä¿å¶å¯é æ§åéå¾·ä½¿ç¨ãæ©å¼  ResNet ç¨ä½æ­£å¸¸ ResNet çæ¿ä»£åï¼ä»¥æé«è§ç½èç¼ççåç±»åç¡®æ§å¹¶åå°æéçè®¡ç®æ¶é´ãæ¬å·¥ä½ä¸­ä½¿ç¨çæ°æ®éæ¯ Ocular Disease Intelligent Recognition (ODIR) æ°æ®éï¼è¿æ¯ä¸ä¸ªç»æåçç¼ç§æ°æ®åºï¼åå«å«ç±»æ¶µçå¤§å¤æ°å¸¸è§è§ç½èç¼çãæ¬å·¥ä½ä¸­ä½¿ç¨çè¯ä¼°ææ åæ¬ç²¾ç¡®åº¦ãå¬åçãåç¡®åº¦å F1 åæ°ãå¨è¿é¡¹å·¥ä½ä¸­ï¼å¯¹æ­£å¸¸ ResNet æ¨¡ååæ©å¼  ResNet æ¨¡åå¨äºä¸ªåä½ï¼å³ ResNet-18ãResNet-34ãResNet-50ãResNet-101 å ResNet-152ï¼ä¹é´è¿è¡äºæ¯è¾ç ç©¶ãä¸æ­£å¸¸ ResNet ç¸æ¯ï¼æ©å¼  ResNet æ¨¡åæ¾ç¤ºåºæå¸æçç»æï¼å¨ ODIR å¤ç±»ç¾çåç±»ä¸­ï¼ä¸è¿°åä¸ªåä½çå¹³å F1 åæ°åå«ä¸º 0.71ã0.70ã0.69ã0.67 å 0.70ã</paragraph>

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v1 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
extant surveys on the trustworthiness of foundation models fail to address
their specific variations and applications within the medical imaging domain.
This survey paper reviews the current research on foundation models in the
major medical imaging applications, with a focus on segmentation, medical
report generation, medical question and answering (Q&A), and disease diagnosis,
which includes trustworthiness discussion in their manuscripts. We explore the
complex challenges of making foundation models for medical image analysis
trustworthy, associated with each application, and summarize the current
concerns and strategies to enhance trustworthiness. Furthermore, we explore the
future promises of these models in revolutionizing patient care. Our analysis
underscores the imperative for advancing towards trustworthy AI in medical
image analysis, advocating for a balanced approach that fosters innovation
while ensuring ethical and equitable healthcare delivery.

æè¦ï¼åºç¤æ¨¡åå¨é«å­¸å½±åä¸çå¿«éé²å±ä»£è¡¨èå¨å¢å¼·è¨ºæ·æºç¢ºåº¦ååäººåæ²»çæ¹é¢éåºäºä¸å¤§æ­¥ãç¶èï¼åºç¤æ¨¡åå¨é«çä¿å¥ä¸­çé¨ç½²éè¦å´æ ¼æª¢æ¥å¶å¯ä¿¡åº¦ï¼åæ¬é±ç§ãç©©å¥æ§ãå¯é æ§ãå¯è§£éæ§åå¬å¹³æ§ãç¶åéæ¼é«å­¸å½±åä¸­åºç¤æ¨¡åçèª¿æ¥æç»é¡¯ç¤ºåºç¸ç¶å¤§çå·®è·ï¼ç¹å¥æ¯å¨å¯ä¿¡åº¦æ¹é¢ãæ­¤å¤ï¼ç¾æçéæ¼åºç¤æ¨¡åå¯ä¿¡åº¦çèª¿æ¥æªè½è§£æ±ºå¶å¨é«å­¸å½±åé åå§çå·é«è®ååæç¨ãéç¯èª¿æ¥è«æåé¡§äºç¶åéæ¼åºç¤æ¨¡åå¨ä¸»è¦é«å­¸å½±åæç¨ä¸­çç ç©¶ï¼éé»éæ³¨åå²ãé«çå ±åçæãé«çåé¡åè§£ç­ (Q&A) ä»¥åç¾çè¨ºæ·ï¼å¶ä¸­åæ¬æç¨¿ä¸­çå¯ä¿¡åº¦è¨è«ãæåæ¢è¨äºè®ç¨æ¼é«å­¸å½±ååæçåºç¤æ¨¡åå¼å¾ä¿¡è³´çè¤éææ°ï¼èæ¯åæç¨ç¸éï¼ä¸¦ç¸½çµäºç¶åæé«å¯ä¿¡åº¦çåé¡åç­ç¥ãæ­¤å¤ï¼æåæ¢è¨äºéäºæ¨¡åå¨é©æ°æ£èç§è­·æ¹é¢çæªä¾åæ¯ãæåçåæå¼·èª¿äºå¨é«å­¸å½±ååæä¸­æèå¯ä¿¡è³´çäººå·¥æºæ§éé²çå¿è¦æ§ï¼æå¡ä¸ç¨®å¹³è¡¡çæ¹æ³ï¼æ¢è½ä¿é²åµæ°ï¼åè½ç¢ºä¿éå¾·åå¬å¹³çé«çä¿å¥æåã

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

æè¦ï¼åºéè¶é³æ³¢ (POCUS) æ¯è¨åºé«å¸«å¨æ£èåºéé²è¡åè§£è®è¶é³æ³¢ææçå¯¦åãç¶èï¼è§£è®éäºå½±åæéçå°æ¥­ç¥è­ç¸ç¶å¯è§ï¼èä¸å¨ç·æ¥ææ³ä¸å¯è½ä¸¦éé¨æå·åãéç¨®ç¾å¯¦ææ³ä½¿å¾æ©å¨å­¸ç¿åé¡å¨ç­æ¼ç®æ³å°æ¼å å¼·äººé¡æ±ºç­è®å¾æ¥µçºæå¹å¼ãPOCUS è£ç½®æ­£ä»¥åçææ¬æ¨åºï¼å°ºå¯¸çºææ©å¤§å°ãå° POCUS è£ç½®è½è®çºæçå·¥å·çææ°å¨æ¼ï¼è§£è®è¶é³æ³¢å½±åéè¦å°éè¨ç·´åç¶é©ãä¸å¹¸çæ¯ï¼åå¾æ­£åè¨ç·´å½±åçå°é£åº¦ä»£è¡¨èå»ºç½®ææçä¸æºç¢ºçåé¡å¨çä¸å¤§éç¤ãå æ­¤ï¼æååè©¦æ¢è¨çåé¡æ¯å¦ä½æ¢ç´¢ç­ç¥ï¼ä»¥æé«ä½¿ç¨ç¨çè³æè¨ç·´çåé¡å¨çæºç¢ºåº¦ãæååè¨­ä½¿ç¨å°æ¸è³æå¯¦ä¾é²è¡è¨ç·´å¯è½ä¸è¶³ä»¥è®åé¡å¨æ¦æ¬ï¼å°è´å®åéåº¦æ¬åãæåçåæ³ä½¿ç¨å¯è§£é AI å¢å¼·æ¹æ³ï¼ä»¥åå©æ¼ç®æ³å¾è¼å°çè³æä¸­å­¸ç¿æ´å¤ï¼ä¸¦æ½å¨åå©åé¡å¨æ´å¥½å°æ¦æ¬ã

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

æè¦ï¼è¿å¹´ä¾ï¼ç¾åè¦è­äºé»å­çæé»å­é¦è¸ä½¿ç¨çå¤§å¹æ¿å¢ï¼å°è´é»å­çåé»å­çä½¿ç¨ç¸éèºæå· (EVALI) çä¾é¡¯èå¢å ï¼å¨ 2019 å¹´ EVALI çç¼æéé æä½é¢åæ­»äº¡ï¼å¸é¡¯äºçè§£é»å­çè¡çºåå¶å®æææè¸ç­ç¥çè¿«åæ§ãç±æ¼ç¤¾ç¾¤åªé«å¹³å°çæ®åï¼å¨çè¶é 47 åä½¿ç¨èä½¿ç¨å®åé²è¡é£çµãæºéãæ°èåå¨æ¨ï¼å¶ä¸­å¾å¤§ä¸é¨åèå¥åº·ç¸éï¼å æ­¤å°ç¤¾ç¾¤åªé«è³æå»ºç«çºå¬å±è¡çç ç©¶ä¸­ç¡å¹çææ©è³æè³æºãå¨æ¬ç ç©¶ä¸­ï¼æåå¾ Reddit ä¸ä¸åé»å­çå­ç¤¾ç¾¤ä¸­æåä¸åç¯ä¾è³æéï¼ä»¥åæä½¿ç¨èçæé»å­çæåãå©ç¨ OpenAI ææ°çå¤§åèªè¨æ¨¡å GPT-4 é²è¡å¥å­å±¤ç´çæé»å­çæååµæ¸¬ï¼æ¬ç ç©¶æ¯è¼äºæ­¤æ¨¡åççµæèå¤è¡äººåè¨åºå°å®¶è¨»è§£ãä½¿ç¨ä¸åçæç¤ºç­ç¥ï¼ä¾å¦é¶æ¬¡å­¸ç¿ãä¸æ¬¡å­¸ç¿ãå°æ¬¡å­¸ç¿åæèéæç¤ºï¼æåéç¼äº 8 åæç¤ºï¼è©³ç´°ç¨åº¦ä¸åï¼å GPT-4 è§£éä»»åï¼ä¸¦è©ä¼°éäºç­ç¥å½¼æ­¤ä¹éçæè½ãéäºåæ­¥ç¼ç¾å¼·èª¿äº GPT-4 å¨ç¤¾ç¾¤åªé«è³æåæä¸­çæ½åï¼ç¹å¥æ¯å¨è­å¥äººé¡åµæ¸¬å¯è½ç¡æ³å¯è¦ºçä½¿ç¨èå¾®å¦æåæ¹é¢ã

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

æè¦ï¼<paragraph>äººå·¥æºæ§ï¼AIï¼ç®åå¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼ç¼ºä¹å¯è§£éæ§çé»çæ©å¨å­¸ç¿æ¨¡åãå¯è§£éæ§äººå·¥æºæ§ï¼XAIï¼é åè´åæ¼è§£æ±ºéåä¸»è¦åé¡ï¼éå¨éèãæ³å¾åå¥åº·ç­é«é¢¨éªé åè³ééè¦ã
æåæåºäºä¸ç¨®åºæ¼ç¯çè«å®ç¾© AI æ¨¡ååå¶å¯è§£éæ§çæ¹æ³ãçºæ­¤ï¼æåæ¡ç¨çµåæ¨¡åçæ¦å¿µï¼å®ä»¥å½¢å¼å¼¦åçå½¢å¼çå¾æ¨¡åï¼éäºå¼¦åæç²äºæ¨¡åçæ½è±¡çµæ§åå¶å·é«å¯¦ç¾ãéç¨®ç¶åè§é»åå«äºç¢ºå®æ§ãæ¦çæ§åéå­æ¨¡åãæåå°åç¨® AI æ¨¡åä½çºçµåæ¨¡åé²è¡æ¯è¼ï¼åæ¬ç·æ§ååºæ¼è¦åçæ¨¡åãï¼éè¿´ï¼ç¥ç¶ç¶²è·¯ãTransformerãVAEï¼ä»¥åå æå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåæ ¹ææ¨¡åççµåçµæ§çµ¦åºæ¨¡åè§£éçå®ç¾©ï¼å±ç¤ºå¦ä½åææ¨¡åçå¯è§£éæ§ï¼ä¸¦ä½¿ç¨å®ä¾æ¾æ¸ XAI ä¸­çå¸¸è¦ä¸»é¡ãæåç¼ç¾ï¼è®æ¨æºçãå§å¨å¯è§£éãæ¨¡åå¦æ­¤éæçåå å¨åè¡¨ä¸­è¡¨ç¾å¾æçºæ¸æ¥ãéå¼å°æåå¾åºæ´ä¸è¬ççµåå¯è§£éï¼CIï¼æ¨¡åæ¦å¿µï¼å®å¦å¤éåæ¬å æãæ¦å¿µç©ºéå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåå±ç¤ºäº CI æ¨¡åçå¯è§£éæ§åªå¢ãé¦åï¼å®åççµåçµæ§åè¨±è¨ç®å¶ä»æèè¶£çéï¼ä¸¦å¯è½ééå¹éæ¨¡åççµæ§ä¾ä¿é²å¾æ¨¡åå°è¢«å»ºæ¨¡ç¾è±¡çæ¨çãå¶æ¬¡ï¼å®ååè¨±å°å¶è¡çºé²è¡åè§£èªªæï¼éäºèªªæåºæ¼å½±é¿ç´æãåè§£æè¡åéå¯«èªªæãæå¾ï¼æåè¨è«äºéç¨®æ¹æ³çè¨±å¤æªä¾æ¹åï¼æåºäºå¦ä½å¨å¯¦è¸ä¸­å­¸ç¿éç¨®ææç¾©ççµæ§åæ¨¡åçåé¡ã</paragraph>

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

æè¦ï¼åå®å®çæ¦å¿µå¨ååé åé½ååéæ³¨ï¼å¶éè¦æç¨ä¹ä¸ä¾¿æ¯é«çä¿å¥ãåå®å®æå·¨å¤§çæ½åééæ¹è®çæ£ç§è­·ãé«å­¸æè²ï¼ä»¥åæå­¸/å­¸ç¿åç ç©¶çæ¹å¼ä¾è½åé«çä¿å¥ãæ¬ç ç©¶çç®çæ¯æä¾åå®å®åºæ¬æ¦å¿µååºç¤æè¡çä»ç´¹ãæ¬ææ¢è¨äºåå®å®å¨é«çä¿å¥èæ¯ä¸çåªç¼ºé»ï¼ä¸¦å¾æè¡å AI çè§åº¦åæå¶æ½åãç¹å¥æ¯ï¼è¨è«äºæ©å¨å­¸ç¿æ¹æ³çè§è²ï¼æåå°èªªæå¦ä½å°æ©å¨å­¸ç¿æ¼ç®æ³æç¨æ¼åå®å®ç¢ççè³æï¼ä»¥ç²å¾é«çä¿å¥æç¨æ¹é¢çæ´ä½³è¦è§£ãæ­¤å¤ï¼æåééæ¢è¨åå¡éç­æ°èæè¡ï¼ä¸¦è§£æ±ºé±ç§åé¡ï¼ä¾æ¢è¨åå®å®å¨é«çä¿å¥æ¹é¢çæªä¾é¡æ¯ãæ¬ç ç©¶çç¼ç¾æå©æ¼æ´æ·±å¥å°äºè§£åå®å®å¨é«çä¿å¥ä¸­çæç¨ï¼ä»¥åå¶å¨é«çæåæä¾æ¹é¢ç¼æ®é©å½æ§è®é©çæ½åã

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

æè¦ï¼æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®å»£æ³çæ¢æ§ç¾çï¼æ²æå·²ç¥çæçµçæ³ä¸ç¼ççå¾é«ãç ç©¶è¡¨æï¼é²è¡æ§æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®ç°è³ªæ§ç¾çï¼æé¡¯èå½±é¿èèçµæ§ååè½ï¼æçµå°è´èè¡°ç«­ãé¨èæéçæ¨ç§»ï¼æ¢æ§èèçå·²å¾å½±é¿å°æ¸äººçè´å½ç¾çè½è®çºä¸ç¨®å´éç¨åº¦ä¸åçå¸¸è¦ç¾çãæ¬ç ç©¶çç®æ¨æ¯ä½¿ç¨éæå­¸ç¿åå¯è§£éç AI é²è¡æ©æé å¾å CKD æª¢æ¸¬ï¼ä¸¦è¦è¦ºåä¸»å°ç¹å¾µãç¹å¾µåæ¸åè¡¨ç¾åºçå¼ãçºæ­¤ï¼æåºäºä¸ç¨® AI é©åçé æ¸¬åææ¹æ³ï¼ä»¥å¹«å©è¨åºé«ççºåå¥æ£èéå·çæ´»æ¹å¼ä¿®æ¹å»ºè­°ï¼ä»¥éä½éç¨®ç¾ççé²å±éåº¦ãæåçæ¸æéæ¯å¾ CKD æ£èåå¥åº·åè©¦èçèº«é«çå½é«å¾µä¸­æ¶éçï¼ä»¥æºç¢ºéç¼æåæåºç AI é©åçè§£æ±ºæ¹æ¡ãå¨éæ¹é¢ï¼æä¾äºè¡æ¶²åå°¿æ¶²æª¢æ¸¬çµæï¼ä¸¦æç¨åºæ¼éææ¨¹çæ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬æªç¼ç¾ç CKD çä¾ãæåçç ç©¶çµæç¶éèèèç§é«ççé·æè«®è©¢å¾å¾å°é©è­ãæåçå¯¦é©åè§£éçµæèåç¨®é«çä¿å¥é åä¸­ç¾æçå¯è§£é AI æç¨é²è¡äºæ¯è¼ï¼åæ¬ CKDãæ¯è¼è¡¨æï¼æåéç¼ç AI æ¨¡åï¼ç¹å¥æ¯é¨æ©æ£®ææ¨¡åï¼å·²ç¶ç¢ºå®äºæ¯ XgBoost æ´å¤ä½çºéè¦è²¢ç»èçç¹å¾µãå¯è§£éæ§ (I) è¡¡ééè¦ç¹å¾µèæ©èç¹å¾µçæ¯çï¼è¡¨ææåç XgBoost æ¨¡åå¨éåææ¨ä¸­ç²å¾äºæ´é«çåæ¸ï¼ç¹å¥æ¯ 98% çä¿çåº¦ï¼ä¸¦ä¸å¨ FII ææ¸ä¸­èªç¶é«æ¼ç«¶ç­æ¨¡åã

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

æè¦ï¼å¿çå¥åº·æ§æäºä¸é è¤éä¸æ®éçå¨çææ°ï¼å½±é¿äºæ¸ç¾è¬äººççæ´»ï¼ä¸¦ç¶å¸¸å°è´å´éçå¾æãå¨æ¬æä¸­ï¼æåé²è¡äºä¸é å¾¹åºçèª¿æ¥ï¼ä»¥æ¢ç´¢æ¸æç§å­¸ãäººå·¥æºæ§åå¿çä¿å¥çäº¤éï¼éé»éæ³¨ééç·ä¸ç¤¾äº¤åªé« (OSM) é²è¡å¿çç¾çæª¢æ¸¬çææ°ç¼å±ãå¾å¤§ä¸é¨åäººå£ç©æ¥µåè OSM å¹³å°ï¼åµé äºä¸åé¾å¤§çäººå¡è³æåº«ï¼å°å¿çå¥åº·åæå·æå·¨å¤§çæ½åãæ¬ææ¢è¨äºå³çµ±çè¨ºæ·æ¹æ³ãæåé²çè³æå AI é©åçç ç©¶ï¼ä»¥åå¿çä¿å¥ä¸­å¯è§£é AI (XAI) æ¨¡åçåºç¾ãæååé¡§äºæåé²çæ©å¨å­¸ç¿æ¹æ³ï¼ç¹å¥æ¯é£äºåºæ¼ç¾ä»£æ·±åº¦å­¸ç¿çæ¹æ³ï¼åæå¼·èª¿äºé«çä¿å¥ AI æ¨¡åä¸­å¯è§£éæ§çå¿è¦æ§ãå¯¦é©è¨­è¨é¨åæä¾äºå°æ®éåæ³çè¦è§£ï¼åæ¬å¯ç¨çè³æéåè©ä¼°æ¹æ³ãæåéæ¾åºè©²é åçä¸»è¦åé¡åææ°ï¼ä¸¦æåºäºæå¸æçæªä¾ç ç©¶æ¹åãç±æ¼å¿çå¥åº·æ±ºç­éè¦éæåº¦ãå¯è§£éæ§åéå¾·èéï¼æ¬ææå©æ¼æ¨é²å¿çä¿å¥ä¸­ééç¤¾äº¤åªé«æ¨é² XAI çæçºè¨è«ãéè£¡æåºçå¨é¢æ¦è¿°æ¨å¨å¼å°ç ç©¶äººå¡ãå¾æ¥­äººå¡åæ¿ç­å¶å®èç¼å±å¿çç¾çæª¢æ¸¬é åã

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

æè¦ï¼<paragraph>é«çç§è­·ä¸­éè¦ AI è¼å©çè¨åºè¨ºæ·ãç¾æçæ·±åº¦å­¸ç¿æ¨¡åç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸ä¸»è¦å°æ³¨æ¼å½±ååæãæè¿éç¼çåæä¸ç¢ºå®å æéä¿å (DUCG) æ¹æ³æ¯å æé©åçãå¯è§£éçï¼ä¸¦ä¸å¨ä¸åçæç¨å ´æ¯ä¸­æ¯ä¸è®çï¼æ²æè³ææ¶éãæ¨è¨ãæ¬åãé±ç§ãåè¦ãæ¦åãé«ææ¬åé«è½èçåé¡ãééè¨åºå°å®¶å DUCG æè¡äººå¡ä¹éçå¯ååä½ï¼æ§å»ºäºæ¶µè 54 åä¸»è¨´ç 46 å DUCG æ¨¡åãå¯ä»¥å¨æ²æåæµçææ³ä¸è¨ºæ·åº 1,000 å¤ç¨®ç¾çãå¨æç¨æ¼å¯¦éä¸çä¹åï¼46 å DUCG æ¨¡åå·²ç±ç¬¬ä¸æ¹é«é¢åæº¯æ§é©è­ãé©è­çè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 95%ï¼å¶ä¸­åæ¬ç½è¦ç¾çå¨å§çæ¯ç¨®ç¾ççè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 80%ãé©è­å¾ï¼46 å DUCG æ¨¡åå·²å¨ä¸­åå¯¦éæç¨ãå·²ç¶å·è¡äºè¶éä¸ç¾è¬åçå¯¦è¨ºæ·æ¡ä¾ï¼åç¼ç¾ 17 åä¸æ­£ç¢ºçè¨ºæ·ãç±æ¼ DUCG çéææ§ï¼ç¼ç¾ä¸¦ç³¾æ­£äºå°è´ä¸æ­£ç¢ºè¨ºæ·çé¯èª¤ãé »ç¹æç¨ DUCG çè¨åºé«ççè¨ºæ·è½åå¾å°äºé¡¯èæé«ãå¨ä»ç´¹äºåé¢æåºç DUCG æ¹æ³è«ä¹å¾ï¼æåºäºæ½å¨å¥åº·æª¢æ¥çæ¨è¦æ¼ç®æ³ï¼ä¸¦æåäº DUCG çééµææ³ã</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

æè¦ï¼ç²¾ç¢ºä¸åæå°åµæ¸¬ä¹³çå°æ¼æ¹åæ£èé å¾è³ééè¦ãè¨ºæ·æ¹æ³å³çµ±ä¸ä¾è³´æ¼å®ä¸æ¨¡å¼æ¹æ³ï¼ç¶èï¼é«çè³æåææ­£å¨æ´åè¶è¶å³çµ±å½±åçåç¨®è³æä¾æºãä½¿ç¨æ´åå½±ååéå½±åè³æçå¤æ¨¡å¼æè¡ï¼æ¨èªèä¹³çè¨ºæ·çè®é©æ§é²å±ãæ¬ç¯ç¶è¿°çç®çæ¯æ¢è¨å¤æ¨¡å¼æè¡çæ°èé åï¼ç¹å¥æ¯å°çµç¹ççå­¸å½±åèéå½±åè³æèåãæ­¤å¤ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°ç¨æ¼é¡æè¤éæ¼ç®æ³çæ±ºç­éç¨ï¼å¼·èª¿è¨ºæ·éç¨ä¸­å¯è§£éæ§çå¿è¦æ§ãæ¬ç¶è¿°å©ç¨å¤æ¨¡å¼è³æä¸¦å¼·èª¿å¯è§£éæ§ï¼ä»¥æé«è¨ºæ·æºç¢ºæ§ãè¨åºé«å¸«çä¿¡å¿åæ£èåèåº¦ï¼æçµä¿é²ä¹³çæ´åäººåçæ²»çç­ç¥ï¼åæä¹æ¾åºå¤æ¨¡å¼åå¯è§£éæ§çç ç©¶å·®è·ï¼å¼å°æªä¾çç ç©¶ï¼ä¸¦çºè©²é åçç­ç¥æ¹åååºè²¢ç»ã

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

æè¦ï¼èªæ³¨æåæ©å¶å·²è¢«æ¡ç¨æ¼å¤åå»£æ³ä½¿ç¨çè¨æ¯å³éç¥ç¶ç¶²è·¯ (MPNN)ï¼ä¾å¦ GATï¼ï¼å®å¯ä»¥èªé©æå°æ§å¶æ²¿èåºå±¤åå½¢éç·£æµåçè³è¨éãéç¨®æ³¨æåçä½¿ç¨ä½¿å¾æ­¤é¡æ¨¡åæçºå¯è§£é AI (XAI) ç ç©¶çåºç·ï¼å çºééæ³¨æåçè©®éå·²å¨åç¨®é åï¼ä¾å¦èªç¶èªè¨èçåé»è¦è¦è¦ºï¼ä¸­æ®åãç¶èï¼ç¾æçç ç©¶éå¸¸ä½¿ç¨å¤©ççè¨ç®æ¹æ³å¾æ³¨æåä¸­æ¨å°åºæ­¸å åæ¸ï¼ä¸¦ä¸æ²æèæ®å°éç·£æ­¸å çç²¾ç¢ºä¸ä»ç´°çè¨ç®ãå¨æåçç ç©¶ä¸­ï¼æåæ¨å¨å¡«è£æ³¨æååç¨ MPNN çå»£æ³ä½¿ç¨èå®åå¨å¾å¤§ç¨åº¦ä¸æªè¢«ååæ¢ç´¢çå¯è§£éæ§ä¹éçå·®è·ï¼éåä¸»é¡å·²å¨å¶ä»é åç©æ¥µç ç©¶ãçºæ­¤ï¼ä½çºç¬¬ä¸æ¬¡åè©¦ï¼æåå° GNN ä¸­æ³¨æåæ¬éçéç·£æ­¸å åé¡å½¢å¼åãç¶å¾ï¼æåæåº GATTï¼ä¸ç¨®å»ºç«å¨è¨ç®æ¨¹ä¸çéç·£æ­¸å è¨ç®æ¹æ³ãééå¨é¢çå¯¦é©ï¼æåå±ç¤ºäºæåæåºçæ¹æ³å¨è©ä¼° GAT çæ­¸å ææå·æçææãç¸åå°ï¼æåæç¶é©é©è­äºåå°åæ³¨æåå±¤ä¸çæ³¨æåæ¬éåå¹³åå¼ä¸è¶³ä»¥è©®é GAT æ¨¡åçè¡çºãç¨å¼ç¢¼å·²å¬éæ¼ https://github.com/jordan7186/GAtt/tree/mainã

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v2 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

æè¦ï¼æ°çåæææ¯å¤§è¦ç¼è²æèå¼±çææï¼æå°è´ç²çç¼ä½ãç²çç¼ä½æå°æªæççå¤§è¦é æä¸è¯å¾æï¼å æ­¤éè¦æ©æè¨ºæ·ãç®åæ°çåç²çæª¢æ¸¬çé»éæ¨æºä¾è³´æ¼é£çºè¦è¨è¦é»åç£æ¸¬ï¼éåæ¬å¨æ°çåå è­·çæ¿ (NICU) å§è¨éå¤ééè¦é»å (EEG) åå³æè¦è¨ç£æ¸¬ãç¶èï¼è¦è¨è¦é»åç£æ¸¬æè¡éè¦è¨åºå°æ¥­ç¥è­ï¼èä¸éå¸¸åéæ¼æè¡åé²ä¸è³æºè±å¯çç°å¢ãå·æææ¬æççæ°æè¡å¯ä»¥å¹«å©é«ççååºæºç¢ºçè¨ºæ·ï¼ä¸¦ç«å³æå¡æ²»çãå¨éé å·¥ä½ä¸­ï¼æåºäºä¸åæ°ç©å¯è§£éçæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥èªååæ°çåç²çæª¢æ¸¬éç¨ï¼ä¸¦æ¸å°è¦é»åè£ç½®ï¼è©²æ¨¡åæ¡ç¨å·ç©ç¶²è·¯ãåæ³¨æåå±¤åå¨é£æ¥å±¤ãé¤äºè½å¤ å³æåµæ¸¬æ¸å°è£ç½®çç²çç¼ä½å¤ï¼æ­¤æ¨¡åéæä¾å³æå¯è§£éæ§çç¨ç¹åªå¢ãééè©ä¼° Zenodo è³æéä¸çæè½ï¼ä¸¦é²è¡ 10 åäº¤åé©è­ï¼ææåºçæ¨¡åå¨æ²ç·ä¸é¢ç© (AUC) åå¬åçåå¥éå° 8.31% å 42.86% ççµå°æ¹åã

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

æè¦ï¼ä¹³ç (BC) æ¯å½±é¿å¨çå¥³æ§æå¸¸è¦çæ¡æ§è«ç¤ä¹ä¸ï¼å æ­¤éè¦é²æ­¥çè¨ºæ·æ¹æ³ï¼ä»¥æ¹åè¨åºçµæãæ¬æå¨é¢æ¢è¨äºå¯è§£éäººå·¥æºæ§ (XAI) æè¡å¨ä¹³çåµæ¸¬åè¨ºæ·ä¸­çæç¨ãé¨èäººå·¥æºæ§ (AI) æè¡æçºæ»²éé«çä¿å¥é åï¼ç¹å¥æ¯å¨è«ç¤å­¸ä¸­ï¼éæä¸å¯è§£éçæ¨¡åéæ±è®å¾å¢å¨å¿è¡ï¼ä»¥å¢å¼·è¨åºæ±ºç­å¶å®åæ£èç§è­·ãæ­¤ç¯è©è«æ¢è¨äºåç¨® XAI æ¹æ³çæ´åï¼ä¾å¦ SHAPãLIMEãGrad-CAM ç­ï¼ä»¥åç¨æ¼ä¹³çåµæ¸¬ååé¡çæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åãééæ¢è¨ä¹³çè³æéçæ¨¡å¼ï¼åæ¬ä¹³æ¿æå½±ãè¶é³æ³¢åå¶å¨ AI ä¸­çèçï¼æ¬æéé»èªªæ XAI å¦ä½è½å°è´æ´æºç¢ºçè¨ºæ·ååäººåæ²»çè¨ç«ãå®ä¹æ¢è¨äºå¯¦æ½éäºæè¡çææ°ï¼ä»¥åå¶å®æ¨æºåè©éææ¨ä»¥è©ä¼° XAI å¨è¨åºç°å¢ä¸­çæææ§çéè¦æ§ãééè©³ç´°çåæåè¨è«ï¼æ¬ææ¨å¨å¼·èª¿ XAI å¨ç¸®å°è¤é AI æ¨¡åèå¯¦åé«çä¿å¥æç¨ä¹éå·®è·çæ½åï¼é²èä¿é²é«çå°æ¥­äººå¡ä¹éçä¿¡ä»»èçè§£ï¼ä¸¦æ¹åæ£èççµæã

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

æè¦ï¼èªé³æç·è¾¨è­ (SER) ç±æ¼å¶å¨å¿çå¥åº·ãæè²åäººæ©äºåç­å¤åæç¨é åèååéæ³¨ãç¶èï¼SER ç³»çµ±çæºç¢ºæ§åå°é«ç¶­ç¹å¾µéçé»ç¤ï¼éäºç¹å¾µéå¯è½åå«ä¸ç¸éååé¤çè³è¨ãçºäºåæéåææ°ï¼æ¬ç ç©¶æåºäºä¸ç¨®ç¨æ¼ SER çè¿­ä»£ç¹å¾µæåæ¹æ³ï¼è©²æ¹æ³å¼·èª¿ç¹å¾µç¸éæ§åå¯è§£éæ§ï¼ä»¥å¢å¼·æ©å¨å­¸ç¿æ¨¡åçæè½ãæåçåæ³æ¶åä»ç´°çç¹å¾µé¸æååæï¼ä»¥å»ºç«é«æç SER ç³»çµ±ãçºäºééæ¨¡åå¯è§£éæ§è§£æ±ºæåçæ ¸å¿åé¡ï¼æåæ¡ç¨äºå·æ Shapley å¼çç¹å¾µè©ä¼°è¿´åï¼ä»¥åè¦æ¹åç¹å¾µéãéåéç¨å¨æ¨¡åæè½åéæåº¦ä¹éåå¾å¹³è¡¡ï¼éä½¿å¾æåè½å¤ å¨é¢äºè§£æ¨¡åçé æ¸¬ãææåºçæ¹æ³æä¾äºå¤é åªé»ï¼åæ¬è­å¥åç§»é¤ä¸ç¸éååé¤çç¹å¾µï¼å¾èå»ºç«æ´ææçæ¨¡åãæ­¤å¤ï¼å®ä¿é²äºå¯è§£éæ§ï¼æå©æ¼çè§£æ¨¡åçé æ¸¬ä»¥åè­å¥æç·æ±ºå®çééµç¹å¾µãææåºçæ¹æ³çæææ§å·²å¨å¤å«å¤æç·èªé³é (TESS)ãæææç·èªé³è³æåº« (EMO-DB)ãè³´ç¾æ£®é³è¨è¦è¦ºæç·èªé³åæ­æ²è³æåº« (RAVDESS) åè©éé³è¨è¦è¦ºè¡¨éæç· (SAVEE) è³æéç SER åºæºä¸å¾å°é©è­ï¼å¶æè½åªæ¼ç¾ææ¹æ³ãææåæç¥ï¼éæ¯ç¬¬ä¸åå°æ¨¡åå¯è§£éæ§ç´å¥ SER æ¶æ§çç ç©¶ãæ¬æçåå§ç¢¼å¯ééæ­¤é£çµå¬éåå¾ï¼https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognitionã

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, HÃ©loÃ¯se de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

æè¦ï¼å¯è§£éæ§éå¸¸å¯¹äºäººå·¥æºè½ (AI) çå¯æ¥åå®æ½è³å³éè¦ãå¨å»çä¿å¥é¢åï¼è¿ä¸ç¹å°¤ä¸ºéè¦ï¼å ä¸ºå³ç­ç´æ¥å½±åæ£èï¼å¹¶ä¸å¯¹ AI ç³»ç»çä¿¡ä»»è³å³éè¦ãè¿ç§ä¿¡ä»»éå¸¸å»ºç«å¨ AI æä¾çè§£éåè¯ éä¹ä¸ãå°½ç®¡ AI å¯è§£éæ§åå¾äºéå¤§è¿å±ï¼ä½ä»ç¶éè¦æç¡®çæå¯¼æ¹éï¼è¯´æå¨å»çç¯å¢ä¸­ä½æ¶ä»¥åå¨å¤å¤§ç¨åº¦ä¸éè¦è§£éãæä»¬æåºäºä¸ç§æ°é¢çåç±»ç³»ç»ï¼è¯¥ç³»ç»å·æåç§ä¸åçè§£éå¿è¦æ§ç±»å«ï¼æå¯¼æéçè§£éçº§å«ï¼æ£èææ ·æ¬ï¼å±é¨ï¼çº§å«ãéåææ°æ®éï¼å¨å±ï¼çº§å«ï¼æä¸¤ä¸ªçº§å«ãæä»¬å¼å¥äºä¸ä¸ªæ°å­¦å¬å¼ï¼è¯¥å¬å¼åºåäºè¿äºç±»å«ï¼å¹¶ä¸ºç ç©¶äººåæä¾äºä¸ä¸ªå®ç¨æ¡æ¶ï¼ä»¥ç¡®å®å»ç AI åºç¨ä¸­æéçè§£éçå¿è¦æ§åæ·±åº¦ãèèäºä¸ä¸ªå³é®å ç´ ï¼è¯ä¼°åè®®çç¨³å¥æ§ãä¸å®¶è§å¯çå¯åæ§ä»¥ååºç¨ç¨åºçè¡¨ç¤ºç»´æ°ãä»è¿ä¸ªè§åº¦æ¥çï¼æä»¬è§£å³äºè¿ä¸ªé®é¢ï¼AI å»çåºç¨ä½æ¶éè¦è§£éï¼ä»¥åéè¦è§£éå°ä½ç§ç¨åº¦ï¼

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

æè¦ï¼äººå·¥æºæ§ (AI) é åæ­£å¿«éå½±é¿èå¥åº·èé«çä¿å¥ï¼ä½å°æ¼é¢è¨å»£æ³çµæ§æ§å£è¿«çäººç¾¤ä¾èªªï¼åè¦åä¸è¯è¡¨ç¾ä¾ç¶å­å¨ãååçç ç©¶å·²æ¸æ¥èªªæï¼éè¦æ´å´æ ¼å°æ³¨æè³æä»£è¡¨æ§åæ¨¡åæè½ï¼ä»¥ä¿é²å¬å¹³æ§ä¸¦æ¸å°åè¦ãç¶èï¼æåææ©æéééç¨ç¤¾ææµè¡çå­¸åå¥åº·å¬å¹³çæä½³å¯¦åï¼ä¾æ¹å AI çå¯è§£éæ§ï¼ä»¥å¹«å©æåéå°ç¼ç¾çéè¯æ§ï¼ç¼å±åè¨­ãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼å¯è§£é AI (XAI)ï¼ä¸¦æè¿°ä¸åè·¨é åå°å®¶å°çµå¯©æ¥æ¶æ§ï¼ä»¥å¾å¤éè§é»è¨è«åæ¹å¤æ§è©ä¼° AI æ¨¡åçè§£éï¼ä¸¦æ¾åºåè¦é ååæªä¾ç ç©¶çæ¹åãæåå¼·èª¿è·¨é åå°å®¶å°çµå°æ¼ç¢çæ´æºç¢ºãå¬å¹³çè©®éè³ééè¦ï¼èéäºè©®éæ¯æ ¹ææ­·å²åèçµ¡èä¾çãè·¨é åå°çµè¨è«æå©æ¼æ¸å°åè¦ãæ¾åºæ½å¨çæ··æ·å ç´ ï¼ä¸¦å¨æç»ä¸­æç¼ºå£ææ¾åºé¡å¤ç ç©¶çæ©æãåéä¾ï¼éäºè¦è§£å¯ä»¥å»ºè­° AI æ¨¡åæ¹é²çæ©æã

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. ZajÄc, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨å¯¦é©å®¤å¯¦é©ä¸­ä¸æ·å°èæ¾å°ç§é«å¸«å¹æµæè¡¨ç¾å¾æ´åºè²ãç¶èï¼ç¼ç¾æ¾å°ç§ AI çºåºç¤ç³»çµ±çå¯¦éå·è¡å¹¾ä¹æ²ææä¾è¨åºå¹å¼ãæ¬ææ¢è¨å¦ä½çº AI è¨­è¨å¨ä¸åæå¢ä¸­è¨åºä¸çæç¨ãæåæ ¹æåè½æ§ AI çºåºç¤ååçä¸æ¬¡è¿­ä»£ï¼å¨ä¸¹éº¥åè¯äºç 7 åè¨åºå ´åè 13 ä½æ¾å°ç§é«å¸«é²è¡äº 19 æ¬¡è¨­è¨æè­°åè¨­è¨ä»å¥ãååç¤¾ææè¡ä¾è³´éä¿è¢«èªçºå°æ¼æ¾å°ç§ä¸­ AI çè¨­è¨è³ééè¦ãæåæ¦å¿µåäºååæè¡é¢åï¼å¿é æ ¹æé æçè¨åºä½¿ç¨æå¢é²è¡è¨­å®ï¼AI åè½ãAI é«çéé»ãAI æ±ºç­éæª»ï¼ä»¥å AI å¯è§£éæ§ãæåæåºåé è¨­è¨å»ºè­°ï¼èªªæå¦ä½èçèé«çç¥è­ãè¨ºæé¡åãä½¿ç¨èå°æ¥­ç¥è­ç­ç´ãæ£èæå¢ï¼ä»¥åå½±é¿éäºæè¡é¢åè¨­å®çä½¿ç¨èæå¢ç¸éçä¾è³´éä¿ã

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

æè¦ï¼é¨èåé²ç AI/MLï¼å°å¯è§£é AI (XAI) çç ç©¶ä¸æ·å¢å ï¼ä»¥åéæ¼äººé¡å¦ä½è AI å XAI äºåä»¥é²è¡ææçäººå·¥æºæ§åä½æ±ºç­å¶å®ãç¶èï¼æåä»ç¶ç¼ºä¹å° AI ç³»çµ±å XAI æå¦ä½é¦ååç¾çµ¦æ²ææè¡èæ¯çç¨æ¶çäºè§£ãå¨æ¬æä¸­ï¼æåå±ç¤ºäºèé«çå°æ¥­äººå¡ (n=12) åä¸»ä¿®é«å­¸åå¥åº·çå­¸ç (n=4) é²è¡åçµæ§åè¨ªè«ççµæï¼ä»¥ç ç©¶å¦ä½æ¹å AI å XAI çå¥éãå°æ¼è¨ªè«ï¼æåå»ºç«å¨äººæ©äºåæºåä¹ä¸ï¼çºä¸­é¢¨åº·å¾©è©ä¼°å AI è§£éç AI ç³»çµ±åµå»ºå¥éææï¼ä¸¦å°å®åä»ç´¹çµ¦åèèãæåçç ç©¶çµæè¡¨æï¼é¤äºåç¾å³çµ±ç AI æ§è½ææ¨å¤ï¼åèèéå¸æåºåä¿¡æ¯ãAI çå¯¦éå¥½èä»¥åäº¤äºè©¦é©ï¼ä»¥æ´å¥½å°å° AI æ§è½æå¢åï¼ä¸¦å®å AI çç®æ¨åæ§è½ãæ ¹æéäºç¼ç¾ï¼æåå¼·èª¿äºæ¹é² AI å XAI ä»¥åäººæ©åä½æ±ºç­å¶å®çå¥éæ¹åã

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

æè¦ï¼æ¬æä½¿ç¨æ©å¨å­¸ç¿ (ML) åå¯è§£éäººå·¥æºæ§ (XAI) æè¡ä¾æ¢è¨çé¤çæ³èé¿è²æµ·é»ç (AD) ç¸éçæ­»äº¡çä¹éçéä¿ãæ¡ç¨ç¬¬ä¸æ¬¡å¨åå¥åº·èçé¤æª¢æ¥èª¿æ¥ (NHANES III) è³æåº«é²è¡åæãé¸æé¨æ©æ£®ææ¨¡åä½çº XAI åæçåºç¤æ¨¡åï¼ä¸¦ä½¿ç¨ Shapley Additive Explanations (SHAP) æ¹æ³ä¾è©ä¼°ç¹å¾µéè¦æ§ãçµæçªé¡¯äºéè¦ççé¤å ç´ ï¼ä¾å¦è¡æ¸ç¶­çç´  B12 åç³åè¡ç´èç½ãè©²ç ç©¶è­æäºé¨æ©æ£®æå¨é æ¸¬ AD æ­»äº¡çæ¹é¢ç¸è¼æ¼å¶ä»ç¾ççæææ§ãæ¬ç ç©¶æä¾äºçé¤å° AD çå½±é¿çè¦è§£ï¼ä¸¦æå©æ¼æ´æ·±å¥å°äºè§£ç¾ççé²å±ã

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

æè¦ï¼<paragraph>åç´ä¿å¥æä¾èå°æ¼æåçåæµåè½è¨ºå°å°ç§ç§è­·è³ééè¦ãå¨éåç¼çææ³ä¸ï¼ç¡ççä¸å¿«éæ¡åå¯è½å°è´è¦ååªå¤±ï¼å æ­¤éè¦åæè½è¨ºçµ¦å°å®¶ãç¶èï¼åç´ç¼ç§ä¿å¥æä¾èå¯è½ç¡æ³è­å¥ç·æ¥ææ³ï¼å¯è½æå»¶èª¤ç§è­·ãæä¾è§£éçäººå·¥æºæ§ (AI) å¯ä»¥å å¼·ä»åçè½è¨ºæ±ºç­ãæåç ç©¶åç¨® AI è§£éå¦ä½å¹«å©æä¾èååéè¦ç«å³æéç·æ¥å°ç§è½è¨ºçæ£èãæåå»ºç«äºè§£éæ§ AI æ¼ç®æ³ï¼ä»¥å¾ä¾è¡ç¼ç§è­·çè³æé æ¸¬éåç¼æè¡éæ±ï¼ä½çºè­å¥é«é¢¨éªæ£èçä»£çãæåç´å¥äºå§å¨åäºå¾è§£éæ§ï¼ä¸¦èé©åå¸«é²è¡äºä¸é ç·ä¸ç ç©¶ï¼ä»¥è©ä¼°äººæ©åéçè¡¨ç¾ï¼è¡¡éè½è¨ºæºç¢ºåº¦ä¸¦åæè AI çäºåï¼åæ¬åæçãä»»åæéåä½¿ç¨èé«é©æç¥ãå¨ 87 ååèèä¸­ï¼AI æ¯æ´æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½¿ç¨ AI/æªä½¿ç¨çæ¯ä¾çº 59.9%/50.8%ï¼ï¼åç®¡äººæ©åéçè¡¨ç¾ä¸å¦å®ç¨ä½¿ç¨ AIãåèèèªçºä»åå¨ä½¿ç¨å§å¨æ¨¡åææ´å¤å°ç´å¥äº AI å»ºè­°ï¼ä¸¦èªçºå®æ´æç¨ä¸æ´æå¸æãæ²æè§£éï¼AI å»ºè­°çåå·®æå¢å ãAI æ¯æ´ä¸¦æªå¢å å·¥ä½éãä¿¡å¿åä¿¡ä»»ï¼ä½æ¸å°äºææ°ãå¨ä¸åå®ç¨çæ¸¬è©¦éä¸­ï¼æåçé»çå­åå§å¨æ¨¡åå¨é æ¸¬æè¡çµææ¹é¢åå¥éå°äº 77% å 71% çæºç¢ºåº¦ãæåæ¾åºå¨åç´ç¼ç§ä¿å¥ä¸­ï¼äººæ©åéåä½ç®¡çéåç¼çæ©æï¼ä¸¦æ³¨æå°éç¶ AI æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½å³ä½¿æè§£éï¼å®ä¹é¡¯ç¤ºåºèå®ç¨ä½¿ç¨ AI ç¸æ¯çæè½å·®è·ãäººé¡åèå¨é«çæ±ºç­ä¸­ä»ç¶è³ééè¦ï¼éå¼·èª¿äºæªä¾ç ç©¶åªååä½ãç¢ºä¿æ­£é¢ç¶é©åå®å¨ä½¿ç¨ AI çå¿è¦æ§ã</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

æè¦ï¼å¨é«å­¸å½±åä¸­ï¼ç¹å¥æ¯å¨æ©æç¾çæª¢æ¸¬åé å¾ä»»åä¸­ï¼è¾¨å¥ AI æ¨¡åé æ¸¬èå¾çåçå°æ¼è©ä¼°å¶æ±ºç­çå¯é æ§è³ééè¦ãå³çµ±çè§£éæ¹æ³å¨è­å¥é«å­¸å½±ååé¡ä¸­å¯è­å¥çæ±ºå®æ§ç¹å¾µæé¢è¨ææ°ï¼å¶ä¸­åå¥æ§ç¹å¾µå¾å¾®å¦æä¸¦ä¸æé¡¯ãçºäºå½åéä¸å·®è·ï¼æåæåºäºä¸åå¯è§£éçæ¨¡åï¼è©²æ¨¡åå·åæ±ºç­æ¨çåç¹å¾µè­å¥è½åãæåçåæ³ä¸åæª¢æ¸¬æå½±é¿åçå½±åæ¨¡å¼ï¼éæ­ç¤ºäºæ¨åæ¨¡åæçµé æ¸¬çæ±ºå®æ§ç¹å¾µãééå¯¦æ½æåçæ¨¡åï¼æåå¯ä»¥ææè­å¥åè¦è¦ºåç±æ¸æé©åæ¨¡åå©ç¨çé¡ç¹å®ç¹å¾µï¼å¾èæ·±å¥äºè§£æ·±åº¦å­¸ç¿æ¨¡åçæ±ºç­éç¨ãæåå¨è¦æ±å´æ ¼çé«å­¸é å¾ä»»åé åé©è­äºæåçæ¨¡åï¼å±ç¤ºäºå¶å¨æé« AI å¨é«çä¿å¥ä¸­çå¯é æ§åç¼ç¾é å¾çè§£åéç¾ççæ°ç¥è­æ¹é¢çåæåæ½åã

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

æè¦ï¼æ¬ç ç©¶æ¢è¨ç·ä¸å¥åº·ç¤¾ç¾¤ä¸­å°æ±è³è¨æ¯æçåé¡ãåæï¼ä»¥åæå¹«å©çè©åä¹éçéä¿ãæåå»ºç«äºä¸çµæ¨è¨çåç­éå°è³æéï¼ä¸¦éç¼äºå¤æ¨¡ææ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥å¯é å°é æ¸¬è³è¨æ¯æåé¡ååæãæåæ¡ç¨å¯è§£éç AI ä¾æ­ç¤ºè³è¨æ¯æäº¤æµä¸­èå«çæç·ï¼è­ææç·å¨æä¾è³è¨æ¯æä¸­çéè¦æ§ãéç¨®æç·æ¯æåè³è¨æ¯æä¹éçè¤éäº¤äºä½ç¨ä»¥åä¸¦æªè¢«ç ç©¶éãæ¬ç ç©¶æ¹é²äºç¤¾ææ¯æçè«ï¼ä¸¦çºä½¿ç¨èæ±ºç­è¼å©å·¥å·çéç¼å¥ å®äºåºç¤ãè¨è«äºé²ä¸æ­¥çå½±é¿ã

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

æè¦ï¼å¨ç§æé£éç¼å±çæä»£ï¼ä¸ä½æå¤çè¨ªå®¢å·²å¨å¨çæå®¤ä¸­ä½æä¸å¸­ä¹å°ï¼é£å°±æ¯äººå·¥æºæ§ãçæå¼ AIï¼ä¾å¦ ChatGPTï¼æ¿è«¾å¨æè²é åæèµ·ä¸å ´é©å½ï¼ä½å®å»æ¯ä¸æéé¢åãå®å¨åäººåå­¸ç¿æ¹é¢çæ½åï¼å»å ä½å¼ãä¸æºç¢ºä»¥åæè²å·¥ä½èé£ä»¥å°å¶ææèå¥æå­¸è¨­è¨ç­åé¡èæµé·ãæåæ­£ç«å¨éæè²åæ²¿çéç·£ï¼é¡¯ç¶æåéè¦éå¸¸å°å¿å°æ¢ç´¢éçé åãéæ¯ä¸åéå¤§çææ°ï¼å¯è½ææå®³æåæè²éç¨çå®æ´æ§åå¹å¼ãé£éº¼ï¼æåå¦ä½å°éäºææ°è½åçºæ©éï¼ç¶ä¸é©ç¶å°ä½¿ç¨æï¼AI å·¥å·å¯è½ææçºè¤è£½è²¼ä¸å¿æçå®ç¾å·¥å·ï¼ä¸¦è¿éèèæ¹å¤æ§æç¶­ãåµé ååæ·±å¥çè§£ï¼éäºé½æ¯æåå¿«éè®åçä¸çä¸­æéè¦çæè½ãæå¸«åè¦ºå¾ä»åæ²æè½åå©ç¨éé æè¡ï¼éæ´å¤§äºæè²å·¥ä½èåæ©æ§ä¹éçæ¸ä½é´»æºãè§£æ±ºéäºåé¡éè¦æ·±å¥çç ç©¶æ¹æ³ãæåå°æ¡ç¨å¯¦è­ç ç©¶ï¼åéæè¡æ¥åæ¨¡åï¼ä¾è©ä¼°æè²å·¥ä½èåå­¸çå°çæå¼ AI çæåº¦ãäºè§£ä»åççæ³ãä½¿ç¨æ¨¡å¼åéç¤æ¯åµé ææè§£æ±ºæ¹æ¡çç¬¬ä¸åééµæ­¥é©ãæ¬ç ç©¶å°ä½çºæªä¾ç ç©¶äººå¡æç¨çæµç¨æåï¼æ ¹ææ­¤èèªªæçæ­¥é©éè¡ä»åèªå·±çæ¸æ

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike GrÃ¼ne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, AndrÃ© Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

æè¦ï¼é¨èé«çä¿å¥ç³»çµ±çæ¸ä½åï¼äººå·¥æºæ§å¨é«å­¸é åä¸­è®å¾æ´å æ®åãç¹å¥æ¯æ©å¨å­¸ç¿å¨æéåºååé¡ç­è¤éä»»åä¸­å±ç¾åºæ¥µå¤§çæ½åï¼ä½éå¸¸æ¯ä»¥éæåº¦åå¯çè§£æ§çºä»£å¹ãéå°è´äººé¡ç¼ºä¹ä¿¡ä»»ï¼å¾èé»ç¤äºå¶ç©æ¥µä½¿ç¨ãå¯è§£éçäººå·¥æºæ§è©¦åééæä¾å°æ±ºç­éç¨çæ´å¯ä¾å½è£éä¸å·®è·ï¼ä½å¶ä¸åæ¹æ³çå¯¦éæç¨å°ä¸æ¸æ¥ãæ¬ææåºäºä¸ååºæ¼ä½¿ç¨èç ç©¶çè©ä¼°ï¼å¶ä¸­åå«äº Grad-CAM è§£éæ¹æ³ï¼ä¸¦å°å¶æç¨æ¼ç¥ç¶ç¶²è·¯ä»¥åé¡æéåºåæ°çåå¼å¸æ¸æä¸­çå¼å¸ãæåå±ç¤ºäºä¸åå©çç¸éèå°å¯è§£éæ§æ¹æ³çæç¥æç¨ï¼æ­ç¤ºäºå¯¦ç¾å¯¦ééæåº¦çé£åº¦ï¼ä»¥åè¨±å¤åèèå¸æç²å¾æ´æ·±å¥çè§£éã

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) èé«çè¨ºæ·æ´å
çºè¨åºæ±ºç­æä¾äºä¸åæåæ¯çéå¾ãæ¬ç ç©¶æ¦è¿°äºä¸ç¨®æ°ç©æ¹æ³çéç¼ï¼ç¨æ¼é¶æ¬¡å­¸ç¿/å°éå­¸ç¿æå¢å­¸ç¿ (ICL)ï¼æ¹æ³æ¯ä½¿ç¨å¤å±¤çµæ§åæç¤ºæ´åé«çé åç¥è­ãæåéæ¢è¨äºä½¿ç¨èè LLM ä¹éå©ç¨®æºéæ¹å¼çåæï¼æ¸å¼å°è©± (NC) æ¹å¼ï¼å®æéæ­¥èçè³æï¼ä»¥åèªç¶èªè¨å®åå (NL-ST) æ¹å¼ï¼å®æä½¿ç¨é·ç¯æäºæç¤ºã
æåçç ç©¶ç³»çµ±æ§å°è©ä¼°äºè¨ºæ·æºç¢ºæ§åé¢¨éªå å­ï¼åæ¬æ§å¥åè¦ååé°æ§çï¼ä½¿ç¨äºä¸ååå« 920 åæ£èè¨éçè³æéï¼æ¡ç¨åç¨®å°éå­¸ç¿æå¢ãçµæè¡¨æï¼å³çµ±çè¨åºæ©å¨å­¸ç¿ (ML) æ¨¡åéå¸¸å¨é¶æ¬¡å­¸ç¿åå°éå­¸ç¿è¨­å®ä¸­è¡¨ç¾åªæ¼ LLMãç¶èï¼ç¶ä½¿ç¨å°éå­¸ç¿ç¯ä¾ä»¥åææçå¯è§£é AI (XAI) æ¹æ³ä½çºé åç¥è­ä¾æºæï¼æè½å·®è·æé¡¯èç¸®å°ãæ­¤å¤ï¼é¨èæéåè¶³åç¯ä¾æ¸éå¢å ï¼å°è©±æ¹å¼ (NC) å¹¾ä¹å¯ä»¥åª²ç¾ ML æ¨¡åçæè½ãæå¼å¾æ³¨æçæ¯ï¼LLM ç¸å°æ¼ ML æ¨¡åå±ç¾åºç¸ç¶ææ´ä½³çææ¬æææºç¢ºåº¦ã
æ¬ç ç©¶è­å¯¦ï¼ééé©ç¶çé åç¥è­åéèº«æé çæºéç­ç¥ï¼LLM å¯ä»¥é¡¯èå¢å¼·è¨ºæ·ç¨åºãéäºç¼ç¾çªé¡¯äºæä½³åè¨ç·´ç¯ä¾æ¸éåæºéæ¹å¼çéè¦æ§ï¼ä»¥æé«æºç¢ºåº¦ä¸¦æ¸å° LLM æç¨ä¸­çåå·®ã

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel MirÃ³-Nicolau, Gabriel MoyÃ -Alcover, Antoni Jaume-i-CapÃ³, Manuel GonzÃ¡lez-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

æè¦ï¼é¨èå°æ·±åº¦å­¸ç¿æ¨¡åä¾è³´æ§çå¢å ï¼å ä¸å¶åºæçéæåº¦ä¸è¶³ï¼ä¿ä½¿ä¸åæ°çç ç©¶é åç¼å±ï¼ç¨±çºå¯è§£é AI (XAI) æ¹æ³ãéäºæ¹æ³æ¨å¨ééæ·±å¥äºè§£æ±ºç­èå¾çåçï¼ä¾æåæçµä½¿ç¨èå°èªååç³»çµ±çä¿¡è³´ãæ¬ææåºäºä¸ç¨®è¡¡éä½¿ç¨èå° XAI ç³»çµ±ä¿¡è³´åº¦çæ°ç©æ¹æ³ï¼åè¨±å°å¶é²è¡æ¹é²ãæåæåºçææ¨çµåäºå®¢è§è§é»ä¸çæè½ææ¨åä¿¡è³´ææ¨ãçºäºé©è­éåæ°ç©çæ¹æ³ï¼æåå¨ä¸åçå¯¦çé«çå ´æ¯ä¸­é²è¡äºä¸åæ¡ä¾ç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±å¾ X åå½±åä¸­åµæ¸¬èºçã

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

æè¦ï¼COVID-19 ç«æå°å¨çå¬å±è¡çé æå£åï¼å¿é é²è¡æºç¢ºçè¨ºæ·åå¹²é ï¼ä»¥æ§å¶ç¾çå³æ­ä¸¦éä½æ­»äº¡çãæ¬æä»ç´¹äºä¸åå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åï¼å°éè¨­è¨ç¨æ¼ééè¸é¨ X å (CXR) å½±åæ¹åå° COVID-19 é å¾ççè§£åä¿¡è³´ãééæ´åå¤§è¦æ¨¡é è¨ç·´å½±åç·¨ç¢¼å¨ãé¢¨éªç¹å® Grad-CAM åè§£ååååµæ¸¬æè¡ï¼æåçåæ³ç¢çååå¯è§£éççµæï¼ææææå¿è¦çç¾çç¹å¾µï¼åæå°æ³¨æ¼ç½è¦ä½ééµçç°å¸¸ååãæåçæ¨¡åé æ¸¬çµæééé¢¨éªååå®ä½æä¾å¢å¼·çæ¸æ°åº¦åéæåº¦ï¼è®è¨åºé«çè½å¤ å¨æ´äºè§£é å¾è¦è§£çææ³ä¸ï¼å°± COVID-19 è¨ºæ·ååºææºçæ±ºç­ãæåå¨å¤ä¸­å¿çå­è³æéä¸è©ä¼°ææåºçæ¹æ³ï¼ä¸¦éééååè³ªåè©ä¼°è­æå¶æææ§ï¼éå°åªç°ç C ææ¸ï¼0.764 å 0.727ï¼åæéç¸é AUCï¼0.799 å 0.691ï¼ãéäºçµæè¡¨æï¼æåå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åå¨é¢¨éªé æ¸¬æ¹é¢è¶è¶å³çµ±ççå­åææ¹æ³ï¼æåè¨åºæ±ºç­çè§£éæ§ï¼ä¸¦å¢å¼· AI ç³»çµ±çä¿¡è³´åº¦ã

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

æè¦ï¼<paragraph>å¨éå»å¹¾å¹´ï¼è¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS) ä¸­çäººå·¥æºæ§ (AI) å¨å©ç¨æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¶æ§æ¹é¢ç¼æ®äºééµä½ç¨ãåç®¡ AI æ¨¡åå·æä»¤äººæ»¿æçè½åï¼ä½ç¼ºä¹éæåº¦åå¯è§£éæ§ï¼ç¹å¥æ¯å¨å¯é æ§çºå¿è¦èéçé«çèæ¯ä¸ï¼éå¸¶ä¾äºéå¤§çææ°ãå¨ä¸å½±é¿é æ¸¬ç²¾æºåº¦çææ³ä¸å¯¦ç¾éæåº¦ä»ç¶æ¯ä¸é ééµææ°ãæ¬ææåºäºä¸ç¨®æ°æ¹æ³ï¼å³ Rad4XCNNï¼ä»¥å¢å¼· CNN è¡çç¹å¾µçé æ¸¬è½åï¼åæå·åæ¾å°ç¹å¾µåºæçå¯è§£éæ§ãRad4XCNN ä¸åæ¼åºæ¼é¡¯èæ§åçå³çµ±æ¹æ³ï¼å®ééæ¾å°çµå­¸å°å¯çè§£çå«ç¾©è CNN è¡çç¹å¾µéè¯èµ·ä¾ï¼çºè¶è¶è¦è¦ºååè¡¨çè§£éæ¹æ³æä¾äºæ°çè§é»ãæåä»¥ä¹³çåé¡ä»»åä½çºæ¡ä¾ç ç©¶ï¼å¨è¶é³æ³¢å½±åè³æéä¸è©ä¼° Rad4XCNNï¼åæ¬ä¸åç·ä¸è³æéåå©åç¨æ¼å§é¨åå¤é¨é©è­çå§é¨è³æéãä¸äºééµçµæå¦ä¸ï¼i) è ViT è¡çç¹å¾µåæ¾å°ç¹å¾µç¸æ¯ï¼CNN è¡çç¹å¾µä¿è­äºæ´ç©©å¥çæºç¢ºåº¦ï¼ii) å³çµ±çè¦è¦ºååè§£éæ¹æ³å­å¨ä¸äºç¼ºé·ï¼iii) Rad4XCNN æ²æç§ç²æ¨¡åæºç¢ºåº¦ä¾æåå¶å¯è§£éæ§ï¼iv) Rad4XCNN æä¾äºå¨å±è§£éè¦è§£ï¼ä½¿é«å¸«è½å¤ åææ¨¡åè¼¸åºåç¼ç¾ãæ­¤å¤ï¼æåå¼·èª¿å°å¯è§£éæ§æ´åå° AI æ¨¡åä¸­å°æ¼å¢å¼·è¨åºå¯¦åä¸­çä¿¡ä»»åæ¡ç¨è³ééè¦ï¼ä¸¦å¼·èª¿äºæåçæ¹æ³å¦ä½è½ç·©è§£èå¯è§£é AI æ¹æ³ç¸éçä¸äºçæ®ã</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) çæ®åæ´åï¼å¨æ¶å AI é©åç³»çµ±çäºæä¸­ï¼è²¬ä»»åç¾©åæ­¸å±¬ç¢çäºè¤éçææ°ãéäºç³»çµ±çäºé£æ§ãAI å¼ç¼äºæçå«çåé¡ï¼å ä¸ AI æè¡çä¸ç¢ºå®æ§åç¼ºä¹ç¸ææ³è¦ï¼ä½¿å¾å³çµ±è²¬ä»»æ­¸å±¬é¢è¨ææ°ãçºæ­¤ï¼æ¬ç ç©¶æåºäºä¸ç¨®è¨ç®åæåè¡¡ (CRE) æ¹æ³ï¼ä»¥å»ºç«ä¸åé£è²«ä¸å¨å«çä¸å¯æ¥åçè²¬ä»»æ­¸å±¬æ¶æ§ï¼é©ç¨æ¼ææå©å®³éä¿äººãè¨ç®æ¹æ³æä¾äºçµæ§åçåæï¼åæäºæ¦å¿µæ¹æ³å¨èçåæä¸å¤é¢åæå¢æçéå¶ï¼å±ç¤ºäºè©²æ¶æ§å¨è²¬ä»»æ­¸å±¬éç¨ä¸­å·åçå¯è§£éæ§ãé£è²«æ§åé©ææ§ãæåæ¢è¨äºèåè¡¡è¨ç®ä¸­ç´¢è³ ç¸éçåå§ååå±¤ç´çééµä½ç¨ãæåä»¥ AI è¼å©é«çæ±ºç­æ¯æ´ç³»çµ±çºæ¡ä¾ç ç©¶ï¼èªªæä¸åçåå§åå¦ä½å°è´ä¸åçè²¬ä»»åéãè©²æ¶æ§æä¾äºå° AI å¼ç¼äºæä¸­åè²¬å¶çå¯¶è²´è¦è§£ï¼ééæçºç£æ§ãä¿®è¨ååæï¼ä¿é²äºæ°¸çºä¸æéæ§çç³»çµ±ç¼å±ã

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

æè¦ï¼äººå·¥æºæ§ééé æ¸¬æ¨¡ååå©é«çå°æ¥­äººå¡ï¼å¤§å¹è½è®äºè¨åºæ±ºç­å¶å®ãæ¬ç ç©¶æ¢è¨äºå¨é«çä¿å¥ä¸­ä½¿ç¨äººå·¥æºæ§æç¨ç¨å¼æå¬å¹³æ§åå¯è§£éæ§çééµéæ±ï¼ä»¥ç¢ºä¿å¨ä¸åçæ£èäººå£çµ±è¨è³æä¸­ç²å¾å¬å¹³ççµæãééå°æ³¨æ¼æè¡çç¸éæ­»äº¡ççé æ¸¬æ¨¡åï¼æåæåºäºä¸ç¨®æ¹æ³ï¼è©²æ¹æ³æå­¸ç¿ä¸åæè½æä½³åçé æ¸¬æ¨¡åï¼ç¶å¾æ¡ç¨è½ç§»å­¸ç¿éç¨ä¾ç¢çä¸åå·ææ´å¥½å¬å¹³æ§çæ¨¡åãæåçæ¨¡åéå¼å¥äºä¸ç¨®æ°ç©çåºæ¼æåçç¹å¾µéè¦æ§æ¼ç®æ³ï¼æ¨å¨é¡ææ¯åç¹å¾µå¨å¢å¼·é æ¸¬å¬å¹³æ§æ¹é¢çè²¢ç»ãèç¾æçå¯è§£éæ§æ¹æ³å°æ³¨æ¼è§£éç¹å¾µå°é æ¸¬æè½çè²¢ç»ä¸åï¼æåæåºçæ¹æ³ç¨ç¹å°å½è£äºçè§£æ¯åç¹å¾µå¦ä½æå©æ¼å¬å¹³æ§çå·®è·ãéé é²å±è³ééè¦ï¼å çºæè¡ççæ­»äº¡çå¾é«ï¼ä¸å¨ä¸åä¹ä¸çé«é¢æ­»äº¡ä¸­æ®æ¼èè§è²ãæåçæ¨¡åä¸åæå©æ¼è­å¥åæ¸è¼é æ¸¬æ¨¡åä¸­çåå·®ï¼éè½ééæé«æ¨¡åé æ¸¬çéæåº¦åå¬å¹³æ§ä¾å¹é¤é«çä¿å¥å©çç¸éèä¹éçä¿¡ä»»ï¼é²èæå©æ¼æä¾æ´å¬å¹³ä¸å¼å¾ä¿¡è³´çé«çä¿å¥æåã

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

æè¦ï¼ç¾ä»ï¼æé¬±çæ¯ä¸åéè¦çè­°é¡ãæ ¹æä¸çè¡ççµç¹ (WHO) çè³æï¼å¨ 2023 å¹´ï¼è¶é 2.8 åäººæ­£å¨èæé¬±çæé¬¥ãéæ¯ä¸åé¾å¤§çæ¸å­ï¼å¦æä¸èªççå¾ï¼éäºæ¸å­å°æå¿«éå¢å ãå¤§ç´æ 48.9 åäººæ¯ç¤¾ç¾¤åªé«ä½¿ç¨èãäººåå¨ TwitterãFacebookãRedditãInstagram ç­å¹³å°ä¸è¡¨éèªå·±çæååæç·ãéäºå¹³å°åå«æå¹å¼çè³è¨ï¼å¯ç¨æ¼ç ç©¶ç®çãå·²ç¶å¨åç¨®ç¤¾ç¾¤åªé«å¹³å°ä¸é²è¡äºå¤§éçç ç©¶ãç¶èï¼éäºåªåä»å­å¨æäºéå¶ãç¹å¥æ¯ï¼ååçç ç©¶åå°æ³¨æ¼åµæ¸¬æ¨æä¸­çæé¬±çåæé¬±ççå¼·åº¦ãæ­¤å¤ï¼è³æéæ¨ç±¤ä¸­å­å¨ä¸æºç¢ºçææ³ãå¨éé ç ç©¶å·¥ä½ä¸­ï¼ä½¿ç¨åºæ¼è©å½æ¨ç±¤ç Twitter è³æåº«ä¸­çæ¨æé æ¸¬äºäºç¨®é¡åçæé¬±çï¼éæ¥µåãéåº¦ãç²¾ç¥çåãéå¸ååç¢å¾ï¼ãå¯è§£éç AI ç¨æ¼ééå¼·èª¿ä»£è¡¨æé¬±çé¡åçæ¨æé¨åä¾æä¾æ¨çãå¾ Transformersï¼BERTï¼ä¸­æåçéåç·¨ç¢¼å¨è¡¨ç¤ºç¨æ¼ç¹å¾µæååè¨ç·´ãæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¹æ³ç¨æ¼è¨ç·´æ¨¡åãBERT æ¨¡ååç¾åºææå¸æççµæï¼éå° 0.96 çæ´é«æºç¢ºåº¦ã

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

æè¦ï¼æ·±åº¦å­¦ä¹ æ­£å¤§å¹è½è®é«å­¸å½±ååæ¾å°ç·å­¸é åï¼è½è¾¨è­é«å­¸å½±åä¸­çççï¼åæ¬é»è¦æ·å±¤ææ (CT) å X åææãç¶èï¼æ·±åº¦å­¸ç¿æ¨¡åçæè½ï¼ç¹å¥æ¯å¨åå²ä»»åä¸­ï¼å¸¸å¸¸åå°å»£æ³è¨»è§£è³æééæ±çéå¶ãçºäºæå°æ­¤ææ°ï¼ééå¯è§£é AI ååäºå¯¦è§£éçç¢çï¼æ¢ç´¢å¼±ç£ç£èªæåå²çè½åãæ¬ç ç©¶çç¯åæ¯éç¼ä¸ç¨®æ°çåäºå¯¦å§ææ¹æ³ (COIN)ï¼è©²æ¹æ³ä½¿ç¨çææ¨¡åå°é æ¸¬çåé¡æ¨ç±¤å¾ç°å¸¸ç¿»è½çºæ­£å¸¸ãä¾å¦ï¼å¦æåé¡å¨å°è¼¸å¥çé«å­¸å½±å X è¦çºç°å¸¸ï¼è¡¨ç¤ºå­å¨ççï¼åçææ¨¡åæ¨å¨å§æç°å¸¸ååï¼å¾èéè½åé¡å¨çåå§é æ¸¬æ¨ç±¤ãæ­¤æ¹æ³ä½¿æåè½å¤ ç¢ççççç²¾ç¢ºåå²ï¼èç¡éä¾è³´æ¼é åå­å¨çåå²é®ç½©ãè³ééè¦çæ¯ï¼å©ç¨å½±åå±¤ç´æ¨ç±¤ï¼éæ¯å»ºç«è©³ç´°çåå²é®ç½©å®¹æåå¾ãè©²æ¹æ³çæææ§ééåå²åæç®æ¨åå¾ææ²å°¼äºå¡ç¾åå¤§å­¸é«é¢åå¾ç CT å½±åä¸­çå¯¦éèèè«ç¤ä¾è­æãç ç©¶çµæè¡¨æï¼COIN é é è¶éå·²å»ºç«çæ­¸å æ¹æ³ï¼ä¾å¦ RISEãScoreCAM å LayerCAMï¼ä»¥å Singla ç­äººæåºçå¦ä¸ç¨®åäºå¯¦è§£éæ¹æ³ãæ­¤è­æè¡¨æï¼COIN æ¯ä¸ç¨®å¾æåéç CT å½±åä¸­è«ç¤èªæåå²æ¹æ³ï¼ä¸¦å¨é«çä¿å¥ä¸­è®æ·±åº¦å­¸ç¿æç¨æ´ææ¼åå¾åæ´ææçéé²ä¸æ­¥ï¼å¶ä¸­è¨»è§£è³æå¾ç¨å°ã

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

æè¦ï¼å¨æ¬æä¸­ï¼æåæ¢è¨æ¸ä½äººæå­¸ç§ (DH) ä½çºä¸éå­¸ç§èæ··åæºè½ (HI) ä½çºä¸åç ç©¶å¸ç¯ä¹éçååä½ç¨ãå¨ DH ç ç©¶ä¸­ï¼æ¸ä½æ¹æ³çä½¿ç¨ï¼ç¹å¥æ¯äººå·¥æºæ§çä½¿ç¨ï¼åå°ä¸ç³»åè¦æ±åéå¶ãæåèªçºéäºè¦æ±åéå¶ç²å¾ HI çè½ååç®æ¨çååæ¯æãæåçè²¢ç»åæ¬æ¾åºäºåéæ¨£ç DH è¦æ±ï¼æåç AI ç³»çµ±éè¦è½å¤  1) èï¼äººé¡ï¼å­¸èåä½ï¼2) æ¯æ´è³ææ¹è©ï¼3) æ¯æ´å·¥å·æ¹è©ï¼4) å¯è¦ºä¸¦è¿ååç¨®è§é»ï¼5) æ¯æ´é è·åè¿è·é¢é±è®ãæåå°æ··åæºè½ç CARE ååï¼åä½ãé©æãè² è²¬åå¯è§£éï¼ä½çºçè«æ¶æ§ï¼ä¸¦å°éäºååå°æå° DH è¦æ±ãå¨æ­¤å°æä¸­ï¼æåç´å¥ç¯ä¾ç ç©¶å°æ¡ãæå¾ï¼æåæ¢è¨å¦ä½å° DH çè¦è§£æç¨æ¼ HIï¼ä¸¦è¨è«çµåéå©åå­¸ç§çéæ¾ææ°ã

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

æè¦ï¼åºç¤æ¨¡å (FM) å·æå¾¹åºæ¹è®é«å­¸å½±åçå·¨å¤§æ½åãç¶èï¼å®åå¨ç¾å¯¦ä¸çè¨åºç°å¢ä¸­çé¨ç½²éè¦å»£æ³çå«çèéãæ¬ææ¨å¨å¼·èª¿è FM ç¸éçå«çåé¡ï¼ä¸¦æåºä¸åæ¡æ¶ä¾æå°å®åå¨é«å­¸ä¸­çè² è²¬ä»»éç¼åå¯¦æ½ãæåä»ç´°å¯©æ¥äºå«çåé¡ï¼ä¾å¦æ£èæ¸æé±ç§ãåå·®ç·©è§£ãæ¼ç®æ³éæåº¦ãå¯è§£éæ§ååè²¬å¶ãææåºçæ¡æ¶æ¨å¨åªåèæ®æ£èç¦å©ãæ¸è¼æ½å¨é¢¨éªï¼ä¸¦å¹é¤å° AI è¼å©é«çä¿å¥çä¿¡ä»»ã

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

æè¦ï¼ç²çèºçæ¯ä¸ç¨®æ¥çå´éçå¨çå¥åº·åé¡ï¼éè¦åé²çè¨ºæ·æ¹æ³ãæ¬ç¯è©è«æ¢è¨äºäººå·¥æºè½èæ¾å°ç¹å¾µåæå¨ç²çèºçè¨ºæ·ä¸­çæç¨ãå¨ç¬¦å PRISMA æåçææ³ä¸ï¼å°å¤åè³æåº«é²è¡äºåé¡§ï¼ç´å° 2023 å¹´ 10 æãééçµåééµå­ï¼ç¼ç¾äºä¸ç¯éæ¼ç²çèºçåç¸éä¸»é¡çè±æå­¸è¡åºçç©ãå¨ç§»é¤ 109 ç¯éè¤æç»å¾ï¼åå§æå°å±åå³ 267 ç¯è«æãå¨æ ¹æé åç¢ºå®çæ¨æºï¼æ·æ±°äº 124 ç¯æç« çæè¦åæ¨é¡å¾ï¼é¸åºäºç¸éç ç©¶ãå¨é²è¡å¨é¢åæå¾ï¼é¡å¤æé¤äºå­é ç ç©¶ãå¨ç´å¥ç 28 é ç ç©¶ä¸­ï¼çµåè¶é³æ³¢ (US) å½±åçæ¾å°ç¹å¾µåæï¼è­æäºå¶å¨è¨ºæ·ç²çèºçæ¹é¢çæææ§ãç ç©¶çµæä¸ä¸ï¼æäºç ç©¶æåºäºåªæ¼ç¾ççæ°ç­ç¥ãæç»å¼·èª¿äºäººå·¥æºè½æ¨¡åé¢è¨çåç¨®ææ°ï¼åæ¬å¯è§£éæ§åé¡ãè³æééå¶åæä½å¡ä¾è³´æ§ã28 é ç´å¥ç ç©¶çç¶åç¼ç¾æå°ï¼éè¦æ¨æºåå·¥ä½ååç»æ§å¤ä¸­å¿ç ç©¶ä¾è§£æ±ºéäºåé¡ãæ­¤å¤ï¼éç¢ºå®äºåæéäºéç¤çæ¹æ³ï¼ä¾å¦å¯è§£éäººå·¥æºè½æè¡ååäººåé«çæè¡çé²æ­¥ãæ¬ç¯è©è«éé»æ¢è¨äºäººå·¥æºè½åæ¾å°ç¹å¾µåæå¦ä½è½è®ç²çèºççè¨ºæ·åæ²»çãåç®¡å­å¨ææ°ï¼ä½æªä¾å°å¤å­¸ç§åä½ãè¨åºé©ç¨æ§é©è­åæ¼ç®æ³æ¹é²çç ç©¶ï¼ä»ææ½åæ¹åç²çèºçæ²»çä¸­çæ£èé å¾åè¨ºæ·ç²¾æºåº¦ã

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼ä¹³çççè¡çè¿éå¢å ï¼ä½¿å¶æçºå¨çä¸»è¦çæ­»äº¡åå ä¹ä¸ãå¨ææççä¸­ï¼ä¹³çè¿ä»çºæ­¢æ¯æå¸¸è¦çãæåè¨ºæ·æ­¤ç¾çéè¦å¤§éçæéåå°æ¥­ç¥è­ãç±æ¼ä¹³ççæª¢æ¸¬éç¨èæï¼å æ­¤ééå»ºç«æ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬ï¼æå©æ¼é²æ­¢å¶é²ä¸æ­¥æ´æ£ãæ©å¨å­¸ç¿åå¯è§£é AI å¨åé¡ä¸­è³ééè¦ï¼å çºå®åä¸åå¯ä»¥æä¾æºç¢ºçé æ¸¬ï¼éå¯ä»¥æ·±å¥äºè§£æ¨¡åå¦ä½ååºæ±ºç­ï¼æå©æ¼çè§£åä¿¡è³´åé¡çµæãå¨æ­¤ç ç©¶ä¸­ï¼æåè©ä¼°ä¸¦æ¯è¼äºäºç¨®ä¸åçæ©å¨å­¸ç¿æ¹æ³çåé¡æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä½¿ç¨äºä¸åä¸»è¦çè³æéï¼éå¡é«å­¸é¢é«é¢ç 500 åæ£èï¼ãäºç¨®ä¸åçç£ç£å¼æ©å¨å­¸ç¿æè¡ï¼åæ¬æ±ºç­æ¨¹ãé¨æ©æ£®æãéè¼¯è¿´æ­¸ãæ´ç´ è²æ°å XGBoostï¼å·²ç¨æ¼å¨æåçè³æéä¸åå¾æä½³çµæãæ­¤å¤ï¼æ¬ç ç©¶å° SHAP åææç¨æ¼ XGBoost æ¨¡åï¼ä»¥è§£éæ¨¡åçé æ¸¬ä¸¦äºè§£æ¯åç¹å¾µå°æ¨¡åè¼¸åºçå½±é¿ãæåæ¯è¼äºå¹¾ç¨®æ¼ç®æ³å°è³æé²è¡åé¡çæºç¢ºåº¦ï¼ä¸¦èè©²é åçå¶ä»æç»é²è¡å°æ¯ãå¨æå¾è©ä¼°å¾ï¼æ¬ç ç©¶ç¼ç¾ XGBoost éå°äºæä½³çæ¨¡åæºç¢ºåº¦ï¼çº 97%ã</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

æè¦ï¼æ·±åº¦å­¸ç¿ (DL) ç¨æ¼å¾ä¹³æ¿æå½±è¡å½±åè¨ºæ·ä¹³ççæ¨¡åéå¸¸ä»¥ãé»çå­ãæ¹å¼éä½ï¼éä½¿å¾é«çä¿å¥å°æ¥­äººå¡é£ä»¥ä¿¡ä»»åçè§£å¶æ±ºç­éç¨ãæ¬ç ç©¶æåºä¸åæ´åæ¶æ§ï¼çµåå·ç©ç¥ç¶ç¶²è·¯ (CNN) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥ä½¿ç¨ CBIS-DDSM è³æéå¢å¼·ä¹³ççè¨ºæ·ãæ¹æ³åå«ä¸åç²¾ç´°çè³æåèçç®¡ç·åé²éè³ææ´åæè¡ï¼ä»¥å°æè³æééå¶ï¼ä¸¦æ¡ç¨é åè¨ç·´çç¶²è·¯ï¼ä¾å¦ VGG-16ãInception-V3 å ResNetï¼é²è¡é·ç§»å­¸ç¿ãæåç ç©¶çéé»æ¯è©ä¼° XAI å¨è§£éæ¨¡åé æ¸¬ä¸­çæææ§ï¼éé»å©ç¨è±ªæ¯å¤å¤«æ¸¬åº¦éåè©ä¼° AI çæçè§£éåå°å®¶è¨»è§£ä¹éçä¸è´æ§ãéç¨®æ¹æ³å°æ¼ XAI å¨ä¿é² AI è¼å©è¨ºæ·ä¸­çå¯ä¿¡åº¦åå«çå¬å¹³æ§è³ééè¦ãæåç ç©¶çç¼ç¾èªªæäº CNN å XAI å¨æ¨é²ä¹³çè¨ºæ·æ¹æ³ä¸­çææåä½ï¼å¾èä¿é²äºåé² AI æè¡å¨è¨åºç°å¢ä¸­çæ´é æ¢æ´åãééå¢å¼· AI é©åæ±ºç­çå¯è§£éæ§ï¼éé å·¥ä½çº AI ç³»çµ±åé«çå¾æ¥­äººå¡ä¹éçæ¹ååä½å¥ å®äºåºç¤ï¼æçµè±å¯äºæ£èç§è­·ãæ­¤å¤ï¼æåç ç©¶çå½±é¿é é è¶åºäºç®åçæè¡ãå®é¼åµé²ä¸æ­¥ç ç©¶å¦ä½çµåå¤æ¨¡å¼è³æä¸¦æ¹å AI è§£éï¼ä»¥æ»¿è¶³è¨åºå¯¦åçéæ±ã

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

æè¦ï¼æ¬ç ç©¶æåºäºä¸ç¨®åµæ°çå¤æ¨¡ææ¸æèåæ¹æ³ï¼ç¨æ¼ç¼çè¡çºè­å¥ï¼å°çµ±è¨ç¸éåæèä»¥äººçºä¸­å¿çè¦è§£ç¸çµåãæåçåæ³å¼å¥äºå©é ééµåµæ°ï¼1) å°æ¸æé©åççµ±è¨ç¸éæ¬éæ´åå°èåç­ç¥ä¸­ï¼ä»¥ææå©ç¨ä¾èªç°è³ªæ¨¡æçè£åä¿¡æ¯ï¼ä»¥å 2) å°ä»¥äººçºä¸­å¿çéåç¹å¾µç´å¥å¤æ¨¡æè¡¨ç¤ºå­¸ç¿ä¸­ï¼ä»¥è©³ç´°å»ºæ¨¡ç¼çè¡çºãæåçæ¨¡åå¨åç¨®æ·±åº¦å­¸ç¿æ¶æ§ä¸­å¾å°é©è­ï¼å±ç¤ºäºåè¶çæ§è½åå»£æ³çé©ç¨æ§ãæåæåºäºä¸åå¯èªå®ç¾©çæ¡æ¶ï¼æ ¹æçµ±è¨é¡¯èæ§å°æ¯åæ¨¡æèåé©çåé¡å¨å°é½ï¼æ¨é²åæ§ååææçå¤æ¨¡æèåãæ­¤å¤ï¼æåçæ¨¡åæä¾å°å¤æ¨¡ææ¸æçå¯è§£éåæï¼æå©æ¼é«çä¿å¥ä¸­çå¯è§£éåå¯è§£é AIãééå¼·èª¿æ¸æå¤æ¨£æ§åæ¨¡æç¹å®è¡¨ç¤ºçéè¦æ§ï¼æåå¢å¼·äºå³çµ±çèåæè¡ï¼ä¸¦çºè­å¥è¤éçç¼çè¡çºè¨­å®äºæ°çæ¨æºãæåçç¼ç¾å°ä¿é²ä»¥æ£èçºä¸­å¿çé«çä¿å¥å¹²é åæ¯æå¯è§£éçè¨åºæ±ºç­å¶å®å·æéè¦æç¾©ã

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

æè¦ï¼ä»¥äººä¸ºæ¬çå¯è§£é AI (HCXAI) å¡å¯¼å°ç¤¾ä¼å±é¢æ´åå° AI è§£éä¸­ãHCXAI è¯è¯­çæ ¸å¿æ¯ç¤¾ä¼éæåº¦ (ST) æ¡æ¶ï¼å¶ç®æ æ¯è®© AI ç³»ç»çç¤¾ä¼ç»ç»èæ¯å¯¹ç¨æ·æ¥è¯´æ¯å¯çè§£çãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å»ºè®®æ©å± ST æ¡æ¶ä»¥è§£å³å¤§åè¯­è¨æ¨¡å (LLM) ä¸­ç¤¾ä¼éè¯¯å½å çé£é©ï¼å°¤å¶æ¯å¨å¿çå¥åº·ç­ææé¢åãäºå®ä¸ï¼LLM è½å¤åºè²å°æ¨¡æè§è²åäººæ ¼ï¼è¿å¯è½å¯¼è´è®¾è®¡èçæå¾åç¨æ·å¯¹ç¤¾ä¼å±æ§çè®¤ç¥ä¹é´åºç°ééï¼ä»èæé£é©ä¿è¿æç»ªæçºµåå±é©è¡ä¸ºãè®¤ç¥ä¸å¬æ­£åä¸åççä¿¡ä»»ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬å»ºè®®ç¨ç¬¬äºä¸ªâW é®é¢âæ¥å¢å¼º ST æ¡æ¶ï¼ä»¥æç¡®è®¾è®¡èåç¨æ·èµäº LLM çå·ä½ç¤¾ä¼å±æ§ãæ­¤è¡¥åæ¨å¨å¼¥å LLM è½ååç¨æ·è®¤ç¥ä¹é´çå·®è·ï¼ä¿è¿åºäº LLM çææ¯å¨éå¾·ä¸è´è´£ä»»å°å¼ååä½¿ç¨ã

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

æè¦ï¼<paragraph>èæ¯ï¼æ°£è¸æ¯ä¸ç¨®å èºé¨èè¸å£ä¹éç°å¸¸éæ°£æå¼èµ·çæ¥æ§è¸èç¾çãçºäºè§£æ±ºæ·±åº¦å­¸ç¿ï¼DLï¼æ¨¡åç¶å¸¸ä¼´é¨çä¸éææ§ï¼å¯è§£éäººå·¥æºæ§ï¼XAIï¼æ¹æ³å·²è¢«å¼å¥ï¼ç¨æ¼æ¦è¿°è DL æ¨¡åååºçæ°£è¸è¨ºæ·ç¸éçååãç¶èï¼éäºè§£éæææèå¯¦éçç¶ååææåºå¥ï¼çªé¡¯åºé²ä¸æ­¥æ¹é²çå¿è¦æ§ãæ¹æ³ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼å°æ°£è¸çè¨åºç¥è­ç´å¥ XAI æ¹æ³ç¢ççæ¨¡åè§£éä¸­ï¼å¾èæåéäºè§£éçåè³ªãå©ç¨æ¾å°ç§é«å¸«å»ºç«ççç¶æç¹ªï¼æåçåæ³é¦åç¢çä¸åæ¨¡æ¿ï¼ç¨æ¼è¡¨ç¤ºæ°£è¸å¯è½ç¼ççååãç¶å¾å°æ­¤æ¨¡æ¿çå å¨æ¨¡åè§£éä¸ï¼ä»¥ç¯©é¸åºè¶åºæ¨¡æ¿éççç¡éè§£éãçºäºé©è­å¶æåï¼æåå°ä¸ç¨® XAI æ¹æ³é²è¡äºæ¯è¼åæï¼å¨å©åçå¯¦ä¸çè³æéä¸­è§£éå©å DL æ¨¡åæï¼åå¥æ¡ç¨åä¸æ¡ç¨æåçæ¨¡æ¿å¼å°ãçµæï¼ææåºçæ¹æ³å¨å»ºç«æ¼ä¸ç¨® XAI æ¹æ³ãå©å DL æ¨¡ååå©åè³æéçåäºç¨®åºæºæå¢ä¸­ï¼å§çµæ¹åäºåºæº XAI æ¹æ³ãå¨æ¯è¼æ¨¡åè§£éåçå¯¦çç¶ååæï¼ééåºæºæè½çæè½æ¹é²è¨ç®åºçå¹³åå¢éç¾åæ¯çºäº¤éæ¯ï¼IoUï¼ç 97.8% åéª°å­ç¸ä¼¼æ§ä¿æ¸ï¼DSCï¼ç 94.1%ãçµè«ï¼å¨æ°£è¸è¨ºæ·çèæ¯ä¸ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼ç¨æ¼æ¹å AI è§£éãæåé ææåçæ¨¡æ¿å¼å°å°ééæ´åè¨åºé åå°æ¥­ç¥è­ï¼çºé¡æ AI æ¨¡åå»ºç«ä¸ç¨®æ°æ¹æ³ã</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by SÃ©amus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

æè¦ï¼<paragraph>å¨ç¶åæ©å¨ç¿»è­¯ (MT) é åä¸­ï¼Transformer æ¶æ§è«ç©èåºï¼æçºé»éæ¨æºï¼ç¹å¥æ¯å°æ¼é«è³æºèªè¨å°ãæ¬ç ç©¶æ¢è¨å¶å°ä½è³æºèªè¨å°çæè½ï¼åæ¬è±èªâæç¾è­èªåè±èªâé¦¬æå°èªèªè¨å°ãå¼å¾æ³¨æçæ¯ï¼æ¬ç ç©¶è­å¥åºæä½³è¶åæ¸åå­è©æ¨¡åé¡åï¼ä»¥é¡¯èæé« Transformer æ¨¡åå°ä½è³æºèªè¨å°çç¿»è­¯åè³ªã
ä½è³æºèªè¨çå¹³è¡è³æéçç¨ç¼ºæé»ç¤ MT çç¼å±ãçºäºè§£æ±ºéååé¡ï¼éç¼äº gaHealthï¼éæ¯æç¾è­èªçç¬¬ä¸åéèªå¥åº·è³æèªæåº«ãå°æ³¨æ¼å¥åº·é åï¼ä½¿ç¨æ­¤åå§è³æééç¼çæ¨¡åå¨ BLEU å¾åæ¹é¢è¡¨ç¾åºéå¸¸é¡¯èçé²æ­¥ï¼è LoResMT2021 å±äº«ä»»åä¸­çæ¨¡åç¸æ¯ãé¨å¾ä½¿ç¨å¤ç¶­åè³ªææ¨é¯èª¤åé¡æ³é²è¡çäººå·¥è©ä¼°é¡¯ç¤ºï¼èåºæ¼ RNN çå°ææ¨¡åç¸æ¯ï¼Transformer ç³»çµ±å¨æ¸å°æºç¢ºæ§åæµæ¢æ§é¯èª¤æ¹é¢è¡¨ç¾åºåªç°çæ§è½ã
æ­¤å¤ï¼æ¬è«æä»ç´¹äº adaptNMT å adaptMLLMï¼éå©åéæºæç¨ç¨å¼ç°¡åäºç¥ç¶æ©å¨ç¿»è­¯æ¨¡åçéç¼ãå¾®èª¿åé¨ç½²ãéäºå·¥å·å¤§å¹ç°¡åäºè¨­å®åè©ä¼°æµç¨ï¼è® MT æ´å®¹æè®éç¼äººå¡åç¿»è­¯äººå¡ä½¿ç¨ãå¼å¾æ³¨æçæ¯ï¼adaptNMT ä»¥ OpenNMT çæç³»çµ±çºåºç¤ï¼ééå¼·èª¿æ¨¡åéç¼çç°å¢è¶³è·¡ä¾ä¿é²çæåå¥½çèªç¶èªè¨èçç ç©¶ãè LoResMT2021 å±äº«ä»»åä¸­çåºæºç¸æ¯ï¼adaptMLLM å° MLLM çå¾®èª¿è­æäºè±èªâæç¾è­èªåè±èªâé¦¬æå°èªéå©åä½è³æºèªè¨å°çç¿»è­¯æ§è½é²æ­¥ã</paragraph>

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

æè¦ï¼ç³å°¿çï¼DMï¼ä½¿æ£èå®¹æåºç¾è¡ç®¡ä½µç¼çã
è¦ç¶²èå½±ååè¡ç®¡åæ èº«é«çå¾®è¡ç®¡åå·¨è¡ç®¡å¥åº·çæ³ãå®åå¯ç¨æ¼è¨ºæ·ç³å°¿çä½µç¼çï¼åæ¬ç³å°¿çè¦ç¶²èçè®ï¼DRï¼ãç¥ç¶çè®ãèçååèç²¥æ¨£ç¡¬åæ§å¿è¡ç®¡ç¾çï¼ä»¥åé æ¸¬å¿è¡ç®¡äºä»¶çé¢¨éªãçºä½¿ç¨æ¸ä½åè¦ç¶²èå½±åé²è¡é«éé DR æª¢æ¸¬èéç¼çäººå·¥æºæ§ï¼AIï¼åç¨ç³»çµ±å·²å¨è¨åºæ¡ç¨ãé¤äº DR ç¯©æª¢å¤ï¼AI æ´åä¹å·æå·¨å¤§çæ½åä¾æå°èç³å°¿çæ£èæ´é«ç§è­·ç¸éçææ°ãå¨éé å·¥ä½ä¸­ï¼æåæ¨å¨å¨é¢åé¡§åºæ¼è¦ç¶²èå½±åç AI æç¨ç¸éç ç©¶çæç»ï¼éäºç ç©¶èç³å°¿ççè¨ºæ·ãé å¾åç®¡çæéãæåå°æè¿°æ´é« AI è¼å©ç³å°¿çç§è­·çç¼ç¾ï¼åæ¬ä½ä¸éæ¼ DR ç¯©æª¢ï¼ä¸¦è¨è«å¯¦æ½æ­¤é¡ç³»çµ±çéç¤ï¼åæ¬èå«çãè³æé±ç§ãå¬å¹³å­ååå¯è§£éæ§æéçåé¡ãééè©ä¼°æ£èçå¥åº·çæ³ï¼åæèéç³å°¿çä½µç¼çä»¥åæªä¾å¿è¡ç®¡ä½µç¼ççé¢¨éªé å¾ï¼AI è¼å©è¦ç¶²èå½±ååæææ½åæçºç³å°¿çæ£èç¾ä»£ååäººåé«ççä¸­å¿å·¥å·ã

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

æè¦ï¼éé ç ç©¶å¾å¤åå©å®³éä¿äººçè§åº¦æ¢è¨ä¸åçäººå·¥æºæ§ (AI) æç¨å¨æè²ä¸çå¯æ¥åæ§ï¼åæ¬å­¸çãèå¸«åå®¶é·ãæ¿èª AI å¨æè²ä¸çè½åæ½åï¼å®è§£æ±ºäºèè³æé±ç§ãAI ä»£çãéæåº¦ãå¯è§£éæ§å AI çéå¾·é¨ç½²ç¸éççæ®ãééå°ææ²æ¹æ³ï¼åèèè¢«åç¾äºåç¨®æå¢ï¼å¶ä¸­ AI çä»£çãéæåº¦ãå¯è§£éæ§åé±ç§åå°æç¸±ãå¨æ¯åæå¢å¾ï¼åèèå®æäºä¸é èª¿æ¥ï¼è©²èª¿æ¥ææäºä»åå° AI çæ´é«æç¨ãåäººæç¨ãæ­£ç¾©ãä¿¡å¿ãé¢¨éªåå¦æå¯ç¨ï¼ä½¿ç¨æ¯åæå¢ç AI çæåççæ³ãè³æèéåå«ä¾èªåä½æ©æ§åç¤¾ç¾¤åªé«æ´»åç 1198 ä½å¤å©å®³éä¿äººåèèçæçµæ¨£æ¬ï¼ä¸¦å°æ³¨æ¼å°åå AI ä½¿ç¨æ¡ä¾çåå¥åæãå°è³æçèª¿è§£åæè¡¨æï¼å° AI çæ¥ååº¦åä¿¡ä»»å¨å©å®³éä¿äººåé«ä¹éæé¡¯èå·®ç°ãæåç¼ç¾ï¼AI çä»£çãéæåº¦åå¯è§£éæ§é«ä½ç¨åº¦ä¹éçééµèª¿è§£èï¼ä»¥åä½¿ç¨ä¸åæè² AI çæåï¼åæ¬æç¥å°çæ´é«æç¨ãæ­£ç¾©åä¿¡å¿ãéé ç ç©¶å¼·èª¿ï¼æ¥å AI å¨æè²ä¸çæç¨æ¯ä¸åå¾®å¦ä¸å¤é¢åçåé¡ï¼é¤äºä¸åçå©å®³éä¿äººççæ³å¤ï¼ééè¦ä»ç´°èæ®å·é«ç AI æç¨åå¶ç¹å¾µã

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

æè¦ï¼<paragraph>åºæ¼å¯ç©¿æ´å¼å®å°ç¨å¿é»å (ECG) è£ç½®çé ç«¯çæ£ç£æ¸¬å¨æ©æåµæ¸¬å¿èç¾çæ¹é¢å·æé¡¯èçæ½åï¼ç¹å¥æ¯èç¨æ¼èªååå¿èç¾çåµæ¸¬çäººå·¥æºæ§ (AI) æ¹æ³çµåä½¿ç¨æãååå·²æç ç©¶æç¨åºæ¼æ·±åº¦å­¸ç¿ç AI æ¹æ³é²è¡å¿èç¾çåµæ¸¬ãç¶èï¼éäºæ¨¡åå°æªè¢«å»£æ³æ¥åçºè¨åºè¨ºæ·çå¯é è¼å©å·¥å·ï¼é¨ååå å¨æ¼åç¹è¨±å¤ AI æ¼ç®æ³çç¶åé»ç®±æç¥ãç¹å¥æ¯ï¼æå¿è¦æ¾åºæå©æ¼ååºæºç¢ºè¨ºæ·ç ECG è¨èééµç¹å¾µï¼å¾èå¢å¼·æ¨¡åçå¯è§£éæ§ãå¨æ¬ç ç©¶ä¸­ï¼æåéç¼äºä¸ç¨®è¦è¦ºè½æå¨æ¹æ³ï¼ä»¥æ ¹æå®å°ç¨ ECG è³ææ¾åºå¿æ¿é¡«åãæ®å·®ç¶²è·¯ (ResNet) æ¹æ³ä¹å·²éç¼åºä¾ï¼ä»¥ä¾¿èè¦è¦ºè½æå¨æ¹æ³é²è¡æ¯è¼ãéäºæ¨¡åæç¨æ¼ Chapman-Shaoxing è³æéï¼ä»¥åé¡å¿æ¿é¡«åï¼ä»¥åå¦ä¸ç¨®å¸¸è¦çå¿å¾ä¸æ´ï¼ç«æ§å¿åéç·©ï¼åæ­£å¸¸ç«æ§å¿å¾çå¿è·³ãéäºæ¨¡åè½å¤ æ¾åºæ±ºå®æçµåé¡çå¿è·³ééµååï¼ä¸¦å¼·èª¿ P æ³¢å T æ³¢ï¼ä»¥åå¿è·³æçºæéåè¨èæ¯å¹å¨ååæ­£å¸¸ç«æ§å¿å¾èå¿æ¿é¡«ååç«æ§å¿åéç·©æ¹é¢çéè¦æ§ã</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

æè¦ï¼æ¬æä»ç´¹äºä¸ç¨®ä½¿ç¨åé²å¤§åèªè¨æ¨¡å (LLM) é²è¡æé¬±çåµæ¸¬åæ²»ççæ°æ¨¡å¼ï¼çæå¼é è¨ç·´Transformer 4 (GPT-4)ãLlama 2 èå¤©æ©å¨äººå Geminiãéäº LLM ç¶éå¾®èª¿ï¼å·åå°æ¥­æç¤ºï¼å¯è¨ºæ·ãè§£éä¸¦å»ºè­°æé¬±ççæ²»çä»å¥æ¹æ³ãä¸ç¨®ç¨ç¹çå°æ¬¡æç¤ºæ¹æ³å¢å¼·äºæ¨¡åæ ¹æ DSM-5 æ¨æºåæåè§£éæé¬±çççè½åãå¨äºåéæ®µï¼éäºæ¨¡åæåèåçå¿å°è©±ç®¡çï¼å¾ PsychDB åèªç¥è¡çºçæ³ (CBT) æåç­è³æºä¸­æ±²åï¼ä¿é²èç¶æ­·éåº¦æé¬±ççäººåçæ¯ææ§äºåãæ­¤å¤ï¼éé ç ç©¶éä»ç´¹äº Illuminate è³æåº«ï¼å¶ä¸­åå«åç¨® CBT æ¨¡çµï¼æå©æ¼åæ§åæ²»çå»ºè­°ãéé ç ç©¶ä½¿ç¨ F1 åæ¸ãæºç¢ºçãå¬åçãé¤å¼¦ç¸ä¼¼åº¦åé¢åå¬åçç Gisting è©ä¼°æ¿èº« (ROUGE) ç­ææ¨ï¼å¨ä¸åçæ¸¬è©¦éä¸­è©ä¼° LLM çè¡¨ç¾ï¼è­æäºå®åçæææ§ãéç¨®ç¶åæ¹æ³çµåäºå°ç«¯ç AI èæ¢å®çå¿çæ¹æ³ï¼çºå¿çä¿å¥æä¾äºæ°çå¯è½æ§ï¼ä¸¦å±ç¤ºäº LLM å¨é©æ°æé¬±çè¨ºæ·åæ²»çç­ç¥æ¹é¢çæ½åã

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v4 by TimothÃ©e Schmude, Laura Koesten, Torsten MÃ¶ller, Sebastian Tschiatschek

Explanations of AI systems rarely address the information needs of people
affected by algorithmic decision-making (ADM). This gap between conveyed
information and information that matters to affected stakeholders can impede
understanding and adherence to regulatory frameworks such as the AI Act. To
address this gap, we present the "XAI Novice Question Bank": A catalog of
affected stakeholders' information needs in two ADM use cases (employment
prediction and health monitoring), covering the categories data, system
context, system usage, and system specifications. Information needs were
gathered in an interview study where participants received explanations in
response to their inquiries. Participants further reported their understanding
and decision confidence, showing that while confidence tended to increase after
receiving explanations, participants also met understanding challenges, such as
being unable to tell why their understanding felt incomplete. Explanations
further influenced participants' perceptions of the systems' risks and
benefits, which they confirmed or changed depending on the use case. When risks
were perceived as high, participants expressed particular interest in
explanations about intention, such as why and to what end a system was put in
place. With this work, we aim to support the inclusion of affected stakeholders
into explainability by contributing an overview of information and challenges
relevant to them when deciding on the adoption of ADM systems. We close by
summarizing our findings in a list of six key implications that inform the
design of future explanations for affected stakeholder audiences.

æè¦ï¼<paragraph>äººå·¥æºæ§ç³»çµ±çèªªæå¾å°è½æ»¿è¶³åæ¼ç®æ³æ±ºç­ (ADM) å½±é¿çäººåçè³è¨éæ±ãå³éçè³è¨èå½±é¿å©å®³éä¿äººéè¦çè³è¨ä¹éçå·®è·ï¼å¯è½æé»ç¤äºè§£åéµå®æ³è¦æ¶æ§ï¼ä¾å¦äººå·¥æºæ§æ³æ¡ãçºäºè§£æ±ºéåå·®è·ï¼æåæåºäºãXAI åå­¸èåé¡åº«ãï¼åå½±é¿å©å®³éä¿äººè³è¨éæ±çç®éï¼æ¶µèå©å ADM ä½¿ç¨æ¡ä¾ï¼å°±æ¥­é æ¸¬åå¥åº·ç£æ¸¬ï¼ï¼æ¶µèè³æãç³»çµ±èçµ¡ãç³»çµ±ä½¿ç¨åç³»çµ±è¦æ ¼é¡å¥ãè³è¨éæ±æ¯ééè¨ªè«ç ç©¶æ¶éçï¼åèèå¨è©¢åå¾æ¶å°èªªæãåèèé²ä¸æ­¥åå ±ä»åççè§£åæ±ºç­ä¿¡å¿ï¼é¡¯ç¤ºéç¶å¨æ¶å°èªªæå¾ä¿¡å¿å¾åæ¼å¢å ï¼ä½åèèä¹éå°äºçè§£ææ°ï¼ä¾å¦ç¡æ³èªªæçºä»éº¼ä»åççè§£æè¦ºä¸å®æ´ãèªªæé²ä¸æ­¥å½±é¿åèèå°ç³»çµ±é¢¨éªåå¥½èççæ³ï¼ä»åææ ¹æä½¿ç¨æ¡ä¾ç¢ºèªææ¹è®éäºçæ³ãç¶é¢¨éªè¢«èªçºå¾é«æï¼åèèè¡¨ç¤ºç¹å¥æèè¶£äºè§£æåçèªªæï¼ä¾å¦çºä»éº¼ä»¥åçºäºä»éº¼ç®çèå»ºç«ç³»çµ±ãéééé å·¥ä½ï¼æåæ¨å¨ééå¨æ±ºç­æ¡ç¨ ADM ç³»çµ±ææä¾ç¸éè³è¨åææ°çæ¦è¦½ï¼ä¾æ¯æ´å°åå½±é¿çå©å®³éä¿äººç´å¥å¯è§£éæ§ãæåæå¾ç¸½çµæåçç¼ç¾ï¼ååºå­é ééµå½±é¿ï¼éäºå½±é¿æåç¥æªä¾éå°åå½±é¿å©å®³éä¿äººåç¾èªªæçè¨­è¨ã</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet GÃ¼rkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éæ¼é²ï¼å°¤å¶æ¯å¨å¤§åèªè¨æ¨¡å (LLM) åçæå¼ AI çé åï¼çºååé åçæç¨éåäºæ°éå¾ï¼ä½å¶å¨åæ¥­æè²ä¸­çè§è²ä»æªè¢«ååæ¢è¨ãæ¬ç ç©¶é¦æ¬¡å¼å¥äºåºæºï¼ç¨ä»¥è©ä¼°ä¸åä¸»è¦ LLM çæè½ï¼åæ¬ OpenAI çæ¨¡å (GPT-3.5 TurboãGPT-4 å GPT-4 Turbo)ãGoogle çæ¨¡å (PaLM 2ãGemini 1.0 Pro) å Anthropic çæ¨¡å (Claude 2 å Claude 2.1)ï¼éäºæ¨¡åå°ç¨æ¼ç ç©¶çåæ¥­èª²ç¨å¥å­¸ç¨åºä¸­çééµèè©¦ GMATãæåçåæé¡¯ç¤ºï¼å¤§å¤æ¸ LLM çè¡¨ç¾é½åªæ¼äººé¡èçï¼å¶ä¸­ GPT-4 Turbo ä¸ååªæ¼å¶ä»æ¨¡åï¼æ´è¶è¶äºé å°åå­¸é¢çç ç©¶çå¹³ååæ¸ãééæ¡ä¾ç ç©¶ï¼æ¬ç ç©¶æ¢è¨äº GPT-4 Turbo å¨è§£éç­æ¡ãè©ä¼°åæãè¾¨è­é¯èª¤ãèª¿æ´èªªæåç¢çæ¿ä»£æå¢æ¹é¢çè½åãèåä¸ä»£çæ¬ç¸æ¯ï¼ææ°ç LLM çæ¬ GPT-4 TurboãClaude 2.1 å Gemini 1.0 Pro å¨æ¨çä»»åæ¹é¢æé¡¯èçé²æ­¥ï¼å¸é¡¯äºå¶å¨è§£æ±ºè¤éåé¡æ¹é¢çæ½åãåç®¡ AI å¨æè²ãè©éåè¼å°æ¹é¢çæ¿è«¾å¾æç¢ºï¼ä½ä»æææ°å­å¨ãæåçç ç©¶ä¸åé¡æäº LLM çå­¸è¡æ½åï¼ä¹å¼·èª¿äºå¨æè²ä¸­å¯©æéç¼åæç¨ AI çå¿è¦æ§ãé¨è AI æè¡çé²æ­¥ï¼å»ºç« AI äºåçæ¶æ§ååå®ãé©è­ AI çæçå§å®¹çæºç¢ºæ§ãç¢ºä¿å¨çåå°å¤åå­¸ç¿èçå­åæ¬ï¼ä»¥ååµé ä¸å AI æ¯æäººé¡å°æ¥­ç¥è­çæè²ç°å¢è³ééè¦ãæ¬ç ç©¶çºé²ä¸æ­¥æ¢ç´¢è² è²¬ä»»å°ä½¿ç¨ AI ä¾è±å¯æè²é«é©ä¸¦æ¹åèè©¦æºååè©éæ¹æ³å¥ å®äºåºç¤ã

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

æè¦ï¼é æ¸¬å è­·çæ¿ (ICU) çæ£çé¢å§æ­»äº¡çæ¯æçµè¨åºçµæçééµãAI å·²å±ç¾åºåªç°çæºç¢ºåº¦ï¼ä½å»ç¼ºä¹å¯è§£éæ§ãçºäºè§£æ±ºéååé¡ï¼æ¬ææåºäºä¸åå¯è§£éçå¤æ¨¡å¼æ­»äº¡çé æ¸¬å¨ (X-MMP)ï¼æ¡ç¨ææä¸å¯è§£éç AI æ¹å¼ï¼èç±å¤æ¨¡å¼ ICU è³æä¾é æ¸¬é¢å§æ­»äº¡çãæåå¨æ¶æ§ä¸­æ¡ç¨å¤æ¨¡å¼å­¸ç¿ï¼å¯ä»¥æ¥æ¶ä¾èªè¨åºè³æçç°è³ªè¼¸å¥ä¸¦ååºæ±ºç­ãæ­¤å¤ï¼æåå¼å¥äºä¸åå¯è§£éçæ¹æ³ï¼ä¹å°±æ¯åå±¤å³æ­è³ Transformerï¼ä½çº LRP æ¹æ³é©ç¶å°å»¶ä¼¸è³ Transformerï¼å°å¤æ¨¡å¼è¼¸å¥ç¢çè§£éï¼ä¸¦æ­é²æ­¸å æ¼é æ¸¬çé¡¯èç¹å¾µãæ­¤å¤ï¼æ¯åæ¨¡å¼å°è¨åºçµæçè²¢ç»å¯ä»¥è¦è¦ºåï¼åå©è¨åºé«å¸«äºè§£æ±ºç­èå¾ççç±ãæåæ ¹æ MIMIC-III å MIMIC-III æ³¢å½¢è³æåº«æ¯å°å­éå»ºæ§äºä¸åå¤æ¨¡å¼è³æéãå¨åºæºè³æéä¸çå¨é¢å¯¦é©è­æï¼æåæåºçæ¶æ§å¯ä»¥éæåççè©®éï¼ä¸¦å·åç«¶ç­åçé æ¸¬æºç¢ºåº¦ãç¹å¥æ¯ï¼æåçæ¶æ§å¯ä»¥è¼é¬å°è½ç§»å°å¶ä»è¨åºä»»åï¼éæå©æ¼å¨é«çä¿å¥ç ç©¶ä¸­ç¼ç¾ééµå ç´ ã

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian GeiÃler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, BjÃ¶rn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias KÃ¼ster, AndrÃ© Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

æè¦ï¼å¨éå»çåå¹´ä¸­ï¼ççå­¸ä¸­çäººå·¥æºæ§ (AI) æ¹æ³å·²å¤§å¹é²æ­¥ãç¶èï¼ç±æ¼è¨±å¤ææ°ï¼åæ¬å°ç ç©¶çµæè½åçºè¨åºè¨ºæ·ç¢åå¨æè¡åæ³è¦æ¹é¢çéç¤ï¼ä»¥åç¼ºä¹æ¨æºåä»é¢ï¼å°è´æ´åå°å¸¸è¦è¨åºå¯¦åä¸­é²å±ç·©æ¢ãéæ¾ä¸èä¾æåç¡éç EMPAIA è¨ç«æå°äºéäºææ°ãå¨æ­¤ï¼æåæä¾ EMPAIA çæå°±åç¶é©æè¨çæ¦è¿°ãEMPAIA æ´åäºççå­¸ AI çæç³»çµ±çååå©å®³éä¿äººï¼å³ççå­¸å®¶ãé»è¦ç§å­¸å®¶åç¢æ¥­ãå¨å¯ååä½ä¸ï¼æåå¶å®äºæè¡äºéæ§æ¨æºãAI æ¸¬è©¦åç¢åéç¼å»ºè­°ï¼ä»¥åå¯è§£éæ§æ¹æ³ãæåå¯¦ä½äºæ¨¡çµåä¸éæ¾åå§ç¢¼ç EMPAIA å¹³èºï¼ä¸¦æåæ´åäºä¾èª 8 åä¸åä¾æåç 14 ååºæ¼ AI çå½±ååææç¨ç¨å¼ï¼å±ç¤ºäºä¸åçæç¨ç¨å¼å¦ä½ä½¿ç¨å®ä¸çæ¨æºåä»é¢ãæååªåèæ®éæ±ï¼ä¸¦è©ä¼°äº AI å¨æ­æ´²åäºæ´²ç 14 åä¸åççå¯¦é©å®¤ä¸­çå¯¦éè¨åºæç¨ãé¤äºæè¡éç¼å¤ï¼æåéçºææå©å®³éä¿äººå»ºç«äºä¸åè«å£ï¼ä»¥åäº«æ¸ä½ççå­¸å AI çè³è¨åç¶é©ãåæ¥­ãè¨åºåå­¸è¡å©å®³éä¿äººç¾å¨å¯ä»¥æ¡ç¨ EMPAIA çå¸¸è¦éæ¾åå§ç¢¼ä»é¢ï¼éçºå¤§è¦æ¨¡æ¨æºååç°¡åæµç¨æä¾äºç¨ç¹çæ©æãéè¦é²ä¸æ­¥çåªåæè½ææä¸å»£æ³å°å»ºç«ä¾è¡å¯¦é©å®¤ä½¿ç¨ä¸­ç AI è¼å©ãçºæ­¤ï¼å·²æç«éçå©åæ EMPAIA Internationalï¼ä»¥ä½çºæ°¸çºåºç¤æ¶æ§ï¼ç¹¼çºé²è¡æ¨æºåï¼ä¸¦æ¯æ´å»£æ³å¯¦ä½åå¡å° AI è¼å©æ¸ä½ççå­¸çæªä¾ã

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

æè¦ï¼åäºå¯¦è§£é (CE) æè¡å·²å¼èµ·éæ³¨ï¼ä½çºä¸ç¨®çºè AI ç³»çµ±äºåçä½¿ç¨èæä¾è¦è§£çæ¹æ³ãéç¶å¨é«å­¸å½±ååèªåé§é§æ±½è»ç­é åå»£æ³ç ç©¶ï¼åå½¢åäºå¯¦è§£é (GCE) æ¹æ³ç¸å°è¼å°è¢«æ¢ç´¢ãGCE æç¢çä¸åé¡ä¼¼æ¼åå§åå½¢çæ°åå½¢ï¼ä¸¦æ ¹æåºç¤é æ¸¬æ¨¡åç¢çä¸åççµæãå¨éäº GCE æè¡ä¸­ï¼åç®¡å¨å¶ä»é åï¼ä¾å¦èè¡é¢¨æ ¼åèªç¶èªè¨å»ºæ¨¡ï¼ä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çæå°±ï¼ä½æ¤åºæ¼çææ©å¶çæè¡ç²å¾çéæ³¨ç¸å°æéãå°çæå¼è§£éå¨çåå¥½æºæ¼å®åå¨æ¨çæéç¢çåäºå¯¦å¯¦ä¾çè½åï¼å©ç¨è¼¸å¥åå½¢çèªä¸»ç²åæ¾åãåºæ¼ä¸è¿°çç±ï¼æåçç ç©¶å¼å¥äº RSGG-CEï¼ä¸ç¨®ç¨æ¼åäºå¯¦è§£éçæ°åç©©å¥é¨æ©åå½¢çæå¨ï¼è½å¤ å¾å­¸ç¿å°çæ½å¨ç©ºéä¸­ç¢çåäºå¯¦ç¯ä¾ï¼èæ®é¨åæåºççæåºåãæ­¤å¤ï¼æåé²è¡å®éåå®æ§åæï¼ä»¥æ¯è¼ RSGG-CE çæè½è SoA çæå¼è§£éå¨ï¼å¼·èª¿å¶å¢å¼·äºç¢çåçè§£éåé¸çè½åã

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

æè¦ï¼å¯è§£é AI çåæ©ä¹ä¸æ¯è®äººåå¨ä½¿ç¨åé¨ç½² AI æ¨¡åæååºæ´å¥½ãæ´ææºçæ±ºç­ãä½éè¦ä»ç´°è©ä¼°ä»¥è©ä¼°æ¯å¦å·²éå°æ­¤é æãç®åçè©ä¼°ä¸»è¦éä¸­å¨è§£éçæ¼ç®æ³ç¹æ§ï¼èæ¶åäººé¡åè©¦èçè©ä¼°éå¸¸æ¡ç¨ä¸»è§åé¡ä¾æ¸¬è©¦äººé¡å°è§£éæç¨æ§ççæ³ï¼èæ²æåºæ¼å®¢è§ææ¨åæ¸¬éãå¨éé å·¥ä½ä¸­ï¼æåè©ä¼°è§£éæ¯å¦å¯ä»¥å¨æ©å¨å­¸ç¿æ¨¡åéç¼çå¯¦éå ´æ¯ä¸­æ¹åäººé¡æ±ºç­å¶å®ãæåé²è¡äºä¸é æ¶åå½±åè³æçæ··åæ¹æ³ä½¿ç¨èç ç©¶ï¼ä»¥è©ä¼° SmoothGradãGradCAM åé è¨è§£éå¨å©åä»»åä¸­ç¢ççé¡¯èæ§åï¼æ¨¡åé¸æååäºå¯¦æ¨¡æ¬ãä»¤äººé©è¨çæ¯ï¼æåæ²æç¼ç¾ä»»ä½é¡¯èæ§åï¼å³ä½¿æ¯è¨­è¨çºææ¼çè§£ä¸é«åº¦æç¤ºç­æ¡çåæé è¨è§£éï¼è½è®ä½¿ç¨èå¨éäºä»»åä¸é¡¯èæ¹åçè­æãåç®¡å¦æ­¤ï¼è§£éç¢ºå¯¦æå©æ¼ä½¿ç¨èæ´æºç¢ºå°æè¿°æ¨¡åãéäºç¼ç¾æç¤ºæåè¦å°åºæ¼é¡¯èæ§çè§£éä¸­å¯è½å­å¨èª¤è§£çæç¨æ§ä¿æè¬¹æã

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

æè¦ï¼å¯è§£éæ§åå®å¨æ§å»ºç«ä¿¡ä»»ãéäºéè¦ä¸åæ¨¡åä¾å±ç¤ºä¸è´æ§åå¯é æ§ãçºäºå¯¦ç¾éäºï¼æå¿è¦ä½¿ç¨ååææ¸æåç¥è­ï¼ä¸¦ä½¿ç¨è AI æç¨ç¸éççµ±è¨åç¬¦è AI æ¹æ³ - å®ç¨ä½¿ç¨ä»»ä½ä¸ç¨®æ¹æ³é½ä¸æå¥æãå æ­¤ï¼æåä¸»å¼µä¸¦è©¦åè­æ NeuroSymbolic AI æ¹æ³æ´é©åæ¼ä½¿ AI æçºåä¿¡ä»»ç AI ç³»çµ±ãæåæåºäº CREST æ¡æ¶ï¼å±ç¤ºäºä¸è´æ§ãå¯é æ§ãä½¿ç¨èå±¤ç´çå¯è§£éæ§åå®å¨æ§æ¯å¦ä½å»ºç«å¨ NeuroSymbolic æ¹æ³ä¸çï¼è©²æ¹æ³ä½¿ç¨æ¸æåç¥è­ä¾æ¯æééµæç¨ï¼ä¾å¦å¥åº·åç¦ç¥ï¼çè¦æ±ãæ¬æéé»éæ³¨å¤§åèªè¨æ¨¡å (LLM)ï¼å çºå®æ¯ CREST æ¡æ¶ä¸­é¸æç AI ç³»çµ±ãLLM å å¶å¨èçå»£æ³çèªç¶èªè¨èç (NLP) å ´æ¯æ¹é¢çå¤åè½æ§èååç ç©¶äººå¡çéæ³¨ãä¾å¦ï¼ChatGPT å Google ç MedPaLM å·²æçºæä¾ä¸è¬åå¥åº·ç¸éæ¥è©¢ä¿¡æ¯çæ¥µæå¸æçå¹³å°ãåç®¡å¦æ­¤ï¼éäºæ¨¡åä»ç¶æ¯é»çå­ï¼åç®¡ç´å¥äºäººé¡åé¥åæä»¤å¼å°çèª¿æ´ãä¾å¦ï¼åç®¡å¶å®äºå®å¨é²è­·æªæ½ï¼ChatGPT ä»å¯è½ç¢çä¸å®å¨çåæãCREST æåºäºä¸ç¨®åççæ¹æ³ï¼å¨ NeuroSymbolic æ¡æ¶ä¸­å©ç¨ç¨åºååºæ¼åè¡¨çç¥è­ï¼ä»¥é¡æè LLM ç¸éçææ°ã

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

æè¦ï¼æ¬ç ç©¶è°æ¥äºå¨ COVID-19 ç«ææé´åä»¥åé¢æµæ­»äº¡çæ¶ï¼å·²é¨ç½²äººå·¥æºè½ (AI) æ¨¡åçæ§è½ãå¯è§£éæ§åç¨³å¥æ§ãä½ä¸ºåç±»ç ç©¶ä¸­çé¦ä¾ï¼æä»¬åç°è´å¶æ¯ç¥ç»ç½ç» (BNN) åæºè½è®­ç»ææ¯è®©æä»¬çæ¨¡åå¨æ°æ®åçéå¤§ååæ¶ä»è½ä¿ææ§è½ãæä»¬çç»æå¼ºè°äºå¼åç¨³å¥ç AI æ¨¡åçéè¦æ§ï¼å³ä½¿å¨å·ææææ§çæ¡ä»¶ä¸ï¼è¿äºæ¨¡åä¹è½å¹éæè¶è¶ä¸´åºå»ççé¢æµãæä»¬å¯¹æ¨¡åå¯è§£éæ§çæ¢ç´¢è¡¨æï¼éæºæ¨¡åä¼äº§çæ´å¤æ ·åä¸ä¸ªæ§åçè§£éï¼ä»èçªåºäºå¨ç°å®ä¸ççä¸´åºç¯å¢ä¸­æä¾è¯¦ç»ä¸ä¸ªæ§åè§è§£ç AI æ¨¡åçå¿è¦æ§ãæ­¤å¤ï¼æä»¬å¼ºè°äºéå AI æ¨¡åä¸­ä¸ç¡®å®æ§çéè¦æ§ï¼è¿ä½¿ä¸´åºå»çè½å¤æ ¹æ®å¯é çé¢æµååºæ´ææºçå³ç­ãæä»¬çç ç©¶æå¡å¨å»çä¿å¥ç AI ç ç©¶ä¸­ä¼åèèå®æ½ç§å­¦ï¼å¹¶ç¡®ä¿ AI è§£å³æ¹æ¡å¨ç°å®ä¸ççä¸´åºç¯å¢ä¸­å®ç¨ãæçä¸å¯æç»­ãéè¿è§£å³å»çä¿å¥ç¯å¢ä¸­çç¬ç¹ææåå¤ææ§ï¼ç ç©¶äººåå¯ä»¥å¼ååºæææ¹åä¸´åºå®è·µåæ£èé¢åç AI æ¨¡åã

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

æè¦ï¼èºçå è±åççæ­»äº¡äººæ¸ç 21%ï¼äºå¹´å­æ´»çå¾å¤§ç¨åº¦åæ±ºæ¼ççè¢«ç¼ç¾çéæ®µãæè¿çç ç©¶å·²è­æäººå·¥æºè½æ¹æ³å·æå¾ä¾è¡ææä¸­æºç¢ºåæ©è¨ºæ·èºççè½åãç¶èï¼æ­¤è­æå°æªè½åçºè¨åºå¯¦åï¼å¶ä¸­ä¸åéç¤æ¯ç¼ºä¹å¯è§£éçæ¨¡åãæ¬ç ç©¶æ¢è¨äºæç¨è®åèªåç·¨ç¢¼å¨ (VAE)ï¼ä¸ç¨®çæå¼äººå·¥æºè½æ¨¡åï¼æ¼èºççç¶ãå°æåºçæ¨¡åè¨ç·´æ¼å¾ LIDC-IDRI å¬å±æ¸æéä¸­æåç 3D é»è¦æ·å±¤ææçç¶ãééèé¡æ¢ç´¢äº VAE çæç 2D åççæ½å¨åéè¡¨ç¤ºï¼ä»¥è­æå¶åè³ªï¼ä¸¦ç¨æ¼èºçè¨ºæ·ç MLP åé¡å¨æ¨¡åï¼æä½³æ¨¡åéå°äº AUC 0.98 å 93.1% æºç¢ºåº¦çæåé²ææ¨ãèé¡åæé¡¯ç¤ºï¼VAE æ½å¨ç©ºéæ ¹æææç¾©çç¹å¾µçµæï¼åæ¬è«ç¤å¤§å°ãå½¢çãæ£èåæ¡æ§é¡å¥ï¼å°æ¡æ§åè¯æ§çç¶çæ¸æéåéãæåéåæ¬æ¨æºé«æ¯ VAE (GVAE) åæ´æ°ççå©åé· VAE (DirVAE) çæ¯è¼åæï¼å¾èç¨çå©åé·åä½åä»£åé©ï¼ä»¥ä¿é²å·æè§£éç¹å¾µè¡¨ç¤ºçæ´å·å¯è§£éæ§çæ½å¨ç©ºéãæå¾ï¼æåå±ç¤ºäºèè¨åºææç¾©çç¹å¾µè®åç¸æçæ½å¨ç©ºéæ©«è¶çæ½åã

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

æè¦ï¼ç¾æçåååé¡å¨è¼¸åºè§£éå·¥å·å¯åçºä¾è³´æ¼æ¨¡åå§é¨å­åæ¬éçç½çï¼ä»¥åèæ¨¡åç¡éçé»çãé¨è AI å¨é«çé åçä½¿ç¨å¢å ï¼å¯è§£éæ§å·¥å·çä½¿ç¨ä¹é¨ä¹å¢å ãç¾æé«å­¸å½±åè§£éçå·¥ä½éé»å¨æ¼ç½çå·¥å·ï¼ä¾å¦ gradcamãç¶èï¼åæå°é»çå·¥å·ææé¡¯çåªé»ï¼åæ¬è½å¤ èä»»ä½åé¡å¨ä¸èµ·ä½¿ç¨ï¼ä»¥åå»£æ³çé»çå·¥å·å¯ä¾é¸æãå¨æ¨æºå½±åä¸ï¼é»çå·¥å·èç½çä¸æ¨£ç²¾ç¢ºãå¨æ¬æä¸­ï¼æåæ¯è¼äºå¤ç¨®é»çæ¹æ³å¨è¦ç MRI è³æéä¸è gradcam çæè½ãæåè­æå¤§å¤æ¸é»çå·¥å·ä¸é©åè§£éé«å­¸å½±ååé¡ï¼ä¸¦è©³ç´°åæå¶ç¼ºé»çåå ãæåéè¡¨æä¸ç¨®é»çå·¥å·ï¼åºæ¼å æå¯è§£éæ§ç rexï¼è¡¨ç¾è \gradcam ä¸æ¨£å¥½ã

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v2 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

æè¦ï¼AI ç¼å±ç¤¾ç¾¤æ¥çå©ç¨ Hugging Face ç­è¨ç®¡ä¸­ä»ï¼æä¾ä½¿ç¨èä¸å³ä¹æ¨¡åèè¨ç·´è³æçç°¡æåå¾ç®¡éãéäºæ¨¡åå¸ééä½äºæ¸åè¬åä½¿ç¨èçæè¡é¨ç½²éæª»ï¼ä½å»å¯è½è¢«ç¨æ¼è¨±å¤æ½å¨æå®³ä¸éæ³çç¨éãå¨æ¬æä¸­ï¼æåèªªæäº AI ç³»çµ±æ¢å¯ä»¥ãåå«ãå§å®¹ï¼ä¹å¯ä»¥ä½çºéæ¾å¼å·¥å·ï¼éæåºäºè¿ä»çºæ­¢ææ£æçå¹³å°æ²»çææ°ä¹ä¸ãæåæä¾ Hugging FaceãGitHub å Civitai ç­ä¸åèªªææ§å¹³å°ä¸æ¸èµ·äºä»¶çæ¡ä¾ç ç©¶ï¼ä»¥æ¢è¨æ¨¡åå¸éå¦ä½æ§ç®¡æ¨¡åãæ ¹ææ­¤åæï¼æåæ¦è¿°äºç¢æ¥­çºåææ§ç®¡éæ±èç¼å±çéè¦ï¼ä½ä»æéï¼å¯¦åï¼ææ¬ãå­ååä½¿ç¨éå¶ãèªåå§å®¹æ§ç®¡åéæ¾å¼æ¿ç­ç¼å±ãåç®¡ç®åé¢è¨çæ¿ç­ææ°ç¸ç¶å´å³»ï¼æåä»æåºäºä¸äºæ³æ³ï¼èªªæå¹³å°å¦ä½è½æ´å¥½å°åå¡è³æºï¼ä½çºè¬¹æãå¬å¹³åé©åº¦çæ³è¦å­åé»ã

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

æè¦ï¼<paragraph>èæ¯åç®æ¨ï¼ééæåéäºè³è¨ï¼æ©å¨ææ·±åº¦å­¸ç¿ (ML/DL) åºæ¼èªä¸»æ¸æåæå·¥å·å¯ä»¥åå©è¨åºé«çåççç ç©¶äººå¡å¾è¤éçæ¸æéä¸­ç¼ç¾æ¨¡å¼åéä¿ãæè¿å·²ç¼è¡¨è¨±å¤åºæ¼ DL çåµå·¢ç (OC) æ¸æåæãéäºåæå¨çççååæ¹é¢ï¼ä¾å¦ï¼å®åæ¶åçå­é ååççé¡åï¼åæ¸æåæåè½æ¹é¢é«åº¦å¤æ¨£åãç¶èï¼ç®åç¼ºä¹å°éäºåæå¨éäºç¹å¾µå AI ä¿è­ (AIA) æ¹é¢çå¨é¢çè§£ãéç¯ç³»çµ±æ§åé¡§æ¨å¨ééæª¢è¦ç¾ææç»ä¸¦æç¢ºéæ³¨ééµç¹å¾µå AI ä¿è­è§é»ï¼ä¾å¡«è£éåç©ºç½ãæ¹æ³ï¼ä½¿ç¨ PRISMA æ¶æ§å¨ä¸åæåè³æåº«ä¸­é²è¡å¨é¢æå°ãåæååæ¬ 2015 å¹´è³ 2023 å¹´éç¼è¡¨æ¼åè¡è©å¯©æåçç ç©¶ãçµæï¼å¨åé¡§ä¸­ï¼ç¸½å±æª¢è¦äº 96 é ç± DL é©åçåæãç ç©¶çµææ­ç¤ºäºå¹¾åéæ¼ç± DL é©åçåµå·¢çæ¸æåæçéè¦è¦è§£ï¼- å¤§å¤æ¸ç ç©¶ 71%ï¼96 é ä¸­æ 68 é ï¼å°æ³¨æ¼æª¢æ¸¬åè¨ºæ·ï¼èæ²æç ç©¶æ¢è¨ OC çé æ¸¬åé é²ã- éäºåæä¸»è¦åºæ¼ä¾èªéå¤åæç¾¤çæ¨£æ¬ï¼75%ï¼96 é ç ç©¶ä¸­ç 72 é ï¼ï¼ï¼åéæ¼æåå°çä½ç½®æåå®¶ã- åªæå°é¨åç ç©¶ï¼å 33%ï¼96 é ç ç©¶ä¸­ç 32 é ï¼å·è¡æ´ååæï¼å¶ä¸­å¤§å¤æ¸ä½¿ç¨åè³ªæ¸æï¼è¨åºæçµå­¸ï¼ã- å¼å¾æ³¨æçæ¯ï¼åªæ 8.3%ï¼96 é ç ç©¶ä¸­ç 8 é ï¼ä½¿ç¨å¤é¨åå¤åæ¸æéé©è­äºå¶æ¨¡åï¼å¼·èª¿äºå å¼·æ¨¡åé©è­çå¿è¦æ§ï¼ä»¥å- å° AIA ç´å¥ççæ¸æåæä»èæ¼éå¸¸æ©æçéæ®µï¼åªæ 2.1%ï¼96 é ç ç©¶ä¸­ç 2 é ï¼ééå¯è§£éæ§æç¢ºæ¢è¨äº AIAã</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

æè¦ï¼<paragraph>è§£éæ§æ¯æ·±åº¦å­¸ç¿ä¸­é·æçææ°ï¼ç¹å¥æ¯å¨é«çä¿å¥ç­é«é¢¨éªé åãå¸¸è¦çè§£éæ§æ¹æ³æå¼·èª¿é©å AI æ¨¡åæ±ºç­çå½±åååãç¶èï¼äººé¡å¾å¤§ç¨åº¦ä¾è³´èªè¨ä¾å³éä¸åæ¯ãå¨åªè£¡ãï¼éæãæ¯ä»éº¼ãçè§£éãæ­¤å¤ï¼å¤§å¤æ¸è§£éæ§æ¹æ³é½å°æ³¨æ¼è§£éåå¥ AI é æ¸¬ï¼èä¸æ¯æè¿° AI æ¨¡åä¸è¬ä½¿ç¨çç¹å¾µãå¾èå°æ¼æ¨¡ååè³æéç¨½æ ¸ç¹å¥æç¨ï¼çè³å¯è½å¨ AI æä¾æç¨æ¼æ°ç©ä»»åæç¢çç¥è­ãå¨æ­¤ï¼æåæåºä¸åä½¿ç¨è¦è¦ºèªè¨æ¨¡åä¾è¾¨è­è¦è¦ºåé¡ä»»åçèªè¨æè¿°ç¬¦çè§£éæ§ç­ç¥ãééå©ç¨å½±ååæå­ä¹éé åè¨ç·´çè¯ååµå¥ç©ºéï¼æåçåæ³å°æ°çåé¡ä»»åä¼°è¨çºä¸åç·æ§æå­çµåï¼å°è´æ¯åæå­é½ææ¬éï¼è¡¨ç¤ºå®èåºæ¼è¦è¦ºçåé¡å¨å°é½ãæåä½¿ç¨å©åé«å­¸å½±ååé¡ä»»åä¾è©ä¼°æåçåæ³ï¼æåç¼ç¾ç¢ççæè¿°ç¬¦å¨å¾å¤§ç¨åº¦ä¸èè¨åºç¥è­ä¸è´ï¼åç®¡ç¼ºä¹ç¹å®é åçèªè¨è¨ç·´ãç¶èï¼æåçåæ³ä¹ç¼ç¾äºæç¨å¬éè³æéä¸­çãæ·å¾é£ç·ãçå¯è½æ§ãçºäºéå°è§£éæ§çåè½æ§è¡¡éï¼æåé²è¡äºä¸é è©¦é©è®èç ç©¶ï¼ç¼ç¾ AI è­å¥çæå­è½è®éå°å®¶äººé¡å¨éå¹³å¡çå±¤ç´å·è¡å°æ¥­çé«çä»»åãç¸½ä¹ï¼æåççµæå¼·èª¿äºä½¿ç¨å¤æ¨¡å¼åºç¤æ¨¡åä¾æä¾ç´è§çãåºæ¼èªè¨çè¦è¦ºä»»åè§£éçæ½åã</paragraph>

##### **Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**
2311.02115v2 by Emma A. M. Stanley, Raissa Souza, Anthony Winder, Vedant Gulve, Kimberly Amador, Matthias Wilms, Nils D. Forkert

Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.

æè¦ï¼<paragraph>ä½¿ç¨é«çå½±åè¨ç·´çäººå·¥æºæ§ (AI) æ¨¡åï¼ç¨æ¼è¨åºä»»åæï¼å¸¸æå¨æè½ä¸å±ç¾åºæ¬¡ç¾¤é«ä¹éçå·®ç°ï¼å½¢æåè¦ãç±æ¼ä¸¦éææçå¯¦ä¸çé«çå½±åè³æä¸­çåè¦ä¾æºé½å®¹æè¾¨è­ï¼å æ­¤å¨é¢è©ä¼°éäºåè¦æ¯å¦ä½ç·¨ç¢¼å°æ¨¡åä¸­ï¼ä»¥ååè¦ç·©è§£æ¹æ³å¨æ¹åæè½å·®ç°æ¹é¢çè½åï¼æ¯ä¸é ææ°ãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸åæ°ç©çåææ¶æ§ï¼ç¨æ¼ç³»çµ±åä¸å®¢è§å°èª¿æ¥é«çå½±åä¸­çåè¦å° AI æ¨¡åçå½±é¿ãæåéç¼ä¸¦æ¸¬è©¦äºéåæ¶æ§ï¼ä»¥é²è¡åæ§çé»è¦æ¨¡æ¬è©¦é©ï¼ä½¿ç¨ä¸åå·¥å·ä¾è©ä¼°é«çå½±å AI ä¸­çåè¦ï¼è©²å·¥å·ç¨æ¼ç¢çå·æå·²ç¥ç¾çå½±é¿ååè¦ä¾æºçåæç£å±æ¯å½±åãå¯è¡æ§ééä½¿ç¨ä¸ååäºå¯¦åè¦æå¢ä¾è¡¡éæ¨¡æ¬åè¦ææå°å·ç©ç¥ç¶ç¶²è·¯ (CNN) åé¡å¨åä¸ååè¦ç·©è§£ç­ç¥çå½±é¿ï¼ä¸¦å±ç¤ºåºä¾ãåæé¡¯ç¤ºï¼ç¶ CNN å¨åæè³æéä¸åè¨æï¼æ¨¡æ¬åè¦æå°è´é æçæ¬¡ç¾¤é«æè½å·®ç°ãæ­¤å¤ï¼éæ°å æ¬è¢«èªçºæ¯æ­¤è¨­å®ä¸­ææåçåè¦ç·©è§£ç­ç¥ï¼æåå±ç¤ºäºè§£éæ§ AI æ¹æ³å¦ä½åå©ä½¿ç¨éåæ¶æ§èª¿æ¥æ¨¡åä¸­åè¦çè¡¨ç¾ãéç¼å¬å¹³ç AI æ¨¡åæ¯ä¸é éå¤§çææ°ï¼å çºé«çå½±åè³æéä¸­å¯è½å­å¨è¨±å¤ä¸ç¶å¸¸æªç¥çåè¦ä¾æºãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼ç¨æ¼å®¢è§å°ç ç©¶åè¦åç·©è§£ç­ç¥å°æ·±åº¦å­¸ç¿ç®¡ç·çå½±é¿ï¼éå¯ä»¥æ¯æ´å¥å¨ä¸è² è²¬ä»»çè¨åº AI çéç¼ã</paragraph>

##### **Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**
2310.19174v1 by Adam White, Margarita Saranti, Artur d'Avila Garcez, Thomas M. H. Hope, Cathy J. Price, Howard Bowman

Machine learning offers great potential for automated prediction of
post-stroke symptoms and their response to rehabilitation. Major challenges for
this endeavour include the very high dimensionality of neuroimaging data, the
relatively small size of the datasets available for learning, and how to
effectively combine neuroimaging and tabular data (e.g. demographic information
and clinical characteristics). This paper evaluates several solutions based on
two strategies. The first is to use 2D images that summarise MRI scans. The
second is to select key features that improve classification accuracy.
Additionally, we introduce the novel approach of training a convolutional
neural network (CNN) on images that combine regions-of-interest extracted from
MRIs, with symbolic representations of tabular data. We evaluate a series of
CNN architectures (both 2D and a 3D) that are trained on different
representations of MRI and tabular data, to predict whether a composite measure
of post-stroke spoken picture description ability is in the aphasic or
non-aphasic range. MRI and tabular data were acquired from 758 English speaking
stroke survivors who participated in the PLORAS study. The classification
accuracy for a baseline logistic regression was 0.678 for lesion size alone,
rising to 0.757 and 0.813 when initial symptom severity and recovery time were
successively added. The highest classification accuracy 0.854 was observed when
8 regions-of-interest was extracted from each MRI scan and combined with lesion
size, initial severity and recovery time in a 2D Residual Neural Network.Our
findings demonstrate how imaging and tabular data can be combined for high
post-stroke classification accuracy, even when the dataset is small in machine
learning terms. We conclude by proposing how the current models could be
improved to achieve even higher levels of accuracy using images from hospital
scanners.

æè¦ï¼æ©å¨å­¸ç¿çºèªåé æ¸¬ä¸­é¢¨å¾ççåå¶å°å¾©å¥çåææä¾äºæ¥µå¤§çæ½åãéé å·¥ä½çéå¤§ææ°åæ¬ç¥ç¶å½±åè³æçç¶­åº¦éå¸¸é«ãå¯ç¨æ¼å­¸ç¿çè³æéè¦æ¨¡ç¸å°è¼å°ï¼ä»¥åå¦ä½ææçµåç¥ç¶å½±ååè¡¨æ ¼è³æï¼ä¾å¦äººå£çµ±è¨è³è¨åè¨åºç¹å¾µï¼ãæ¬ææ ¹æå©ç¨®ç­ç¥è©ä¼°äºå¤ç¨®è§£æ±ºæ¹æ¡ãç¬¬ä¸ç¨®æ¯ä½¿ç¨ç¸½çµ MRI ææç 2D å½±åãç¬¬äºç¨®æ¯é¸ææå©æ¼æé«åé¡ç²¾ç¢ºåº¦çééµç¹å¾µãæ­¤å¤ï¼æåå¼å¥äºå¨çµåå¾ MRI ä¸­æåçæèè¶£ååèè¡¨æ ¼è³æçç¬¦èè¡¨ç¤ºçå½±åä¸è¨ç·´å·ç©ç¥ç¶ç¶²è·¯ (CNN) çæ°ç©æ¹æ³ãæåè©ä¼°äºä¸ç³»å CNN æ¶æ§ï¼2D å 3Dï¼ï¼éäºæ¶æ§å¨ MRI åè¡¨æ ¼è³æçä¸åè¡¨ç¤ºä¸é²è¡è¨ç·´ï¼ä»¥é æ¸¬ä¸­é¢¨å¾å£è¿°åçæè¿°è½åçç¶åæ¸¬éæ¯å¦å¨å¤±èªçæéå¤±èªçç¯åå§ãMRI åè¡¨æ ¼è³æä¾èª 758 ååè PLORAS ç ç©¶çè±èªä¸­é¢¨åå­èãåéå°çç¶å¤§å°çåºç·éè¼¯è¿´æ­¸åé¡æºç¢ºåº¦çº 0.678ï¼ç¶ä¾åºå å¥åå§ççå´éç¨åº¦åæ¢å¾©æéæï¼ä¸åè³ 0.757 å 0.813ãå¨å¾æ¯å MRI ææä¸­æå 8 åæèè¶£ååä¸¦å¨ 2D æ®å·®ç¥ç¶ç¶²è·¯ä¸­èçç¶å¤§å°ãåå§å´éç¨åº¦åæ¢å¾©æéçµåæï¼è§å¯å°æé«çåé¡æºç¢ºåº¦ 0.854ãæåçç ç©¶çµæå±ç¤ºäºå¦ä½å°å½±ååè¡¨æ ¼è³æçµåèµ·ä¾ä»¥ç²å¾é«æ¼ä¸­é¢¨å¾åé¡æºç¢ºåº¦ï¼å³ä½¿å¨æ©å¨å­¸ç¿è¡èªä¸­è³æéå¾å°çææ³ä¸ä¹æ¯å¦æ­¤ãæå¾ï¼æåæåºå¦ä½æ¹é²ç®åçæ¨¡åï¼ä»¥ä½¿ç¨ä¾èªé«é¢ææåçå½±åä¾å¯¦ç¾æ´é«çæºç¢ºåº¦ã

##### **Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**
2310.01828v2 by Hossein Shreim, Abdul Karim Gizzini, Ali J. Ghandour

eXplainable Artificial Intelligence (XAI) has emerged as an essential
requirement when dealing with mission-critical applications, ensuring
transparency and interpretability of the employed black box AI models. The
significance of XAI spans various domains, from healthcare to finance, where
understanding the decision-making process of deep learning algorithms is
essential. Most AI-based computer vision models are often black boxes; hence,
providing explainability of deep neural networks in image processing is crucial
for their wide adoption and deployment in medical image analysis, autonomous
driving, and remote sensing applications. Recently, several XAI methods for
image classification tasks have been introduced. On the contrary, image
segmentation has received comparatively less attention in the context of
explainability, although it is a fundamental task in computer vision
applications, especially in remote sensing. Only some research proposes
gradient-based XAI algorithms for image segmentation. This paper adapts the
recent gradient-free Sobol XAI method for semantic segmentation. To measure the
performance of the Sobol method for segmentation, we propose a quantitative XAI
evaluation method based on a learnable noise model. The main objective of this
model is to induce noise on the explanation maps, where higher induced noise
signifies low accuracy and vice versa. A benchmark analysis is conducted to
evaluate and compare performance of three XAI methods, including Seg-Grad-CAM,
Seg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation
technique. This constitutes the first attempt to run and evaluate XAI methods
using high-resolution satellite images.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) å·²æçºèçä»»åééµæç¨ç¨å¼æçä¸é åºæ¬éæ±ï¼ç¢ºä¿æ¡ç¨é»ç AI æ¨¡åçéæåº¦åå¯è§£éæ§ãXAI çéè¦æ§æ¶µèå¾é«çä¿å¥å°éèçåç¨®é åï¼å¨éäºé åä¸­ï¼äºè§£æ·±åº¦å­¸ç¿æ¼ç®æ³çæ±ºç­å¶å®éç¨è³ééè¦ãå¤§å¤æ¸åºæ¼ AI çé»è¦è¦è¦ºæ¨¡åéå¸¸æ¯é»çå­ï¼å æ­¤ï¼å¨å½±åèçä¸­æä¾æ·±åº¦ç¥ç¶ç¶²è·¯çå¯è§£éæ§å°æ¼å¶å¨é«å­¸å½±ååæãèªåé§é§åéæ¸¬æç¨ä¸­çå»£æ³æ¡ç¨åé¨ç½²è³ééè¦ãæè¿ï¼å·²éå°å½±ååé¡ä»»åå¼å¥äºå¤ç¨® XAI æ¹æ³ãç¸åå°ï¼å½±ååå²å¨å¯è§£éæ§çèæ¯ä¸åå°çéæ³¨ç¸å°è¼å°ï¼åç®¡å®æ¯é»è¦è¦è¦ºæç¨ä¸­çä¸é åºæ¬ä»»åï¼ç¹å¥æ¯å¨éæ¸¬ä¸­ãåªæé¨åç ç©¶æåºç¨æ¼å½±ååå²çåºæ¼æ¢¯åº¦ç XAI æ¼ç®æ³ãæ¬ææ¹ç·¨äºæè¿çç¡æ¢¯åº¦ Sobol XAI æ¹æ³ä»¥é²è¡èªæåå²ãçºäºè¡¡é Sobol æ¹æ³å¨åå²ä¸­çæè½ï¼æåæåºäºä¸ç¨®åºæ¼å¯å­¸ç¿éè¨æ¨¡åçå®é XAI è©ä¼°æ¹æ³ãæ­¤æ¨¡åçä¸»è¦ç®çæ¯å¨è§£éåä¸èªç¼éè¨ï¼å¶ä¸­è¼é«çèªç¼éè¨è¡¨ç¤ºè¼ä½çæºç¢ºåº¦ï¼åä¹äº¦ç¶ãé²è¡åºæºåæä»¥è©ä¼°åæ¯è¼ä¸ç¨® XAI æ¹æ³çæè½ï¼åæ¬ Seg-Grad-CAMãSeg-Grad-CAM++ å Seg-Sobolï¼ä¸¦ä½¿ç¨ææåºçåºæ¼éè¨çè©ä¼°æè¡ãéæ§æäºä½¿ç¨é«è§£æåº¦è¡æå½±åå·è¡åè©ä¼° XAI æ¹æ³çé¦æ¬¡åè©¦ã

##### **Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**
2311.01463v1 by Muhammad Aurangzeb Ahmad, Ilker Yaramis, Taposh Dutta Roy

Large language models have proliferated across multiple domains in as short
period of time. There is however hesitation in the medical and healthcare
domain towards their adoption because of issues like factuality, coherence, and
hallucinations. Give the high stakes nature of healthcare, many researchers
have even cautioned against its usage until these issues are resolved. The key
to the implementation and deployment of LLMs in healthcare is to make these
models trustworthy, transparent (as much possible) and explainable. In this
paper we describe the key elements in creating reliable, trustworthy, and
unbiased models as a necessary condition for their adoption in healthcare.
Specifically we focus on the quantification, validation, and mitigation of
hallucinations in the context in healthcare. Lastly, we discuss how the future
of LLMs in healthcare may look like.

æè¦ï¼å¤§åèªè¨æ¨¡åå¨ç­æéå§å·²å¨å¤åé åä¸­å¤§éæ¿å¢ãç¶èï¼ç±æ¼äºå¯¦æ§ãé£è²«æ§åå¹»è¦ºç­åé¡ï¼é«çåä¿å¥é åå°å¶æ¡ç¨ç¶è±«ä¸æ±ºãéæ¼é«çä¿å¥çé«é¢¨éªæ§è³ªï¼è¨±å¤ç ç©¶äººå¡çè³è­¦åä¸è¦ä½¿ç¨å®ï¼ç´å°éäºåé¡å¾å°è§£æ±ºãå¨é«çä¿å¥ä¸­å¯¦æ½åé¨ç½² LLM çééµæ¯ä½¿éäºæ¨¡åå¼å¾ä¿¡è³´ãéæï¼ç¡å¯è½å¤ï¼ä¸å¯è§£éãå¨æ¬æä¸­ï¼æåæè¿°äºå»ºç«å¯é ãå¼å¾ä¿¡è³´åç¡åè¦æ¨¡åçééµè¦ç´ ï¼ä½çºå®åå¨é«çä¿å¥ä¸­å¾å°æ¡ç¨çå¿è¦æ¢ä»¶ãå·é«ä¾èªªï¼æåå°æ³¨æ¼å¨é«çä¿å¥èæ¯ä¸å°å¹»è¦ºé²è¡éåãé©è­åç·©è§£ãæå¾ï¼æåè¨è«äº LLM å¨é«çä¿å¥ä¸­çæªä¾å¯è½æ¯ä»éº¼æ¨£å­ã

##### **When to Trust AI: Advances and Challenges for Certification of Neural Networks**
2309.11196v1 by Marta Kwiatkowska, Xiyue Zhang

Artificial intelligence (AI) has been advancing at a fast pace and it is now
poised for deployment in a wide range of applications, such as autonomous
systems, medical diagnosis and natural language processing. Early adoption of
AI technology for real-world applications has not been without problems,
particularly for neural networks, which may be unstable and susceptible to
adversarial examples. In the longer term, appropriate safety assurance
techniques need to be developed to reduce potential harm due to avoidable
system failures and ensure trustworthiness. Focusing on certification and
explainability, this paper provides an overview of techniques that have been
developed to ensure safety of AI decisions and discusses future challenges.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å·²å¿«éé²æ­¥ï¼ç¾å·²æºåé¨ç½²æ¼å»£æ³çæç¨ç¨å¼ä¸­ï¼ä¾å¦èªä¸»ç³»çµ±ãé«çè¨ºæ·åèªç¶èªè¨èçãåæ©æ¡ç¨ AI æè¡æ¼å¯¦éæç¨ç¨å¼ä¸¦éæ²æåé¡ï¼ç¹å¥æ¯å°æ¼ç¥ç¶ç¶²è·¯ï¼å®å¯è½ä¸ç©©å®ä¸å®¹æåå°å°ææ§ç¯ä¾çå½±é¿ãå¾é·é ä¾çï¼éè¦éç¼é©ç¶çå®å¨ä¿è­æè¡ï¼ä»¥æ¸å°å å¯é¿åçç³»çµ±æéèé æçæ½å¨å·å®³ï¼ä¸¦ç¢ºä¿å¯ä¿¡è³´æ§ãæ¬æèéæ¼èªè­åå¯è§£éæ§ï¼æ¦è¿°äºå·²éç¼ç¨æ¼ç¢ºä¿ AI æ±ºç­å®å¨çæè¡ï¼ä¸¦è¨è«æªä¾çææ°ã

##### **Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**
2309.10424v1 by Juan M. GarcÃ­a-GÃ³mez, Vicent Blanes-Selva, JosÃ© Carlos de BartolomÃ© Cenzano, Jaime Cebolla-Cornejo, AscensiÃ³n DoÃ±ate-MartÃ­nez

The Directorate General for Parliamentary Research Services of the European
Parliament has prepared a report to the Members of the European Parliament
where they enumerate seven main risks of Artificial Intelligence (AI) in
medicine and healthcare: patient harm due to AI errors, misuse of medical AI
tools, bias in AI and the perpetuation of existing inequities, lack of
transparency, privacy and security issues, gaps in accountability, and
obstacles in implementation.
  In this study, we propose fourteen functional requirements that AI systems
may implement to reduce the risks associated with their medical purpose: AI
passport, User management, Regulation check, Academic use only disclaimer, data
quality assessment, Clinicians double check, Continuous performance evaluation,
Audit trail, Continuous usability test, Review of retrospective/simulated
cases, Bias check, eXplainable AI, Encryption and use of field-tested
libraries, and Semantic interoperability.
  Our intention here is to provide specific high-level specifications of
technical solutions to ensure continuous good performance and use of AI systems
to benefit patients in compliance with the future EU regulatory framework.

æè¦ï¼æ­æ´²è­°æè­°æç ç©¶æåç¸½å±å·²çºæ­æ´²è­°æè­°å¡æºåäºä¸ä»½å ±åï¼å¶ä¸­åèäºäººå·¥æºè½ (AI) å¨é«çä¿å¥é åçä¸é ä¸»è¦é¢¨éªï¼AI é¯èª¤å°è´æ£èåå°å·å®³ãé«ç AI å·¥å·è¢«æ¿«ç¨ãAI å­å¨åè¦ä¸¦å°è´ç¾æ inequities æçºå­å¨ãç¼ºä¹éæåº¦ãé±ç§åå®å¨åé¡ãåè²¬å·®è·ä»¥åå¯¦æ½éç¤ã
  å¨éé ç ç©¶ä¸­ï¼æåæåºäºååé åè½æ§è¦æ±ï¼AI ç³»çµ±å¯ä»¥å¯¦æ½éäºè¦æ±ä¾éä½èå¶é«çç®çç¸éçé¢¨éªï¼AI è­·ç§ãä½¿ç¨èç®¡çãæ³è¦æª¢æ¥ãåéå­¸è¡ç¨éåè²¬è²æãè³æåè³ªè©ä¼°ãè¨åºé«çééæª¢æ¥ãæçºæè½è©ä¼°ãç¨½æ ¸è¿½è¹¤ãæçºå¯ç¨æ§æ¸¬è©¦ãåé¡§åæº¯/æ¨¡æ¬æ¡ä¾ãåè¦æª¢æ¥ãå¯è§£é AIãå å¯åä½¿ç¨ç¶éå¯¦å°æ¸¬è©¦çç¨å¼åº«ï¼ä»¥åèªæäºéæ§ã
  æåå¨æ­¤çç®çæ¯æä¾æè¡è§£æ±ºæ¹æ¡çç¹å®é«éè¦æ ¼ï¼ä»¥ç¢ºä¿æçºè¯å¥½çæè½ï¼ä¸¦ä½¿ç¨ AI ç³»çµ±ï¼ä»¥ç¬¦åæªä¾çæ­çæ³è¦æ¶æ§ï¼å¾èä½¿æ£èåçã

##### **QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**
2309.10293v3 by Thanveer Shaik, Xiaohui Tao, Haoran Xie, Lin Li, Juan D. Velasquez, Niall Higgins

Artificial Intelligence techniques can be used to classify a patient's
physical activities and predict vital signs for remote patient monitoring.
Regression analysis based on non-linear models like deep learning models has
limited explainability due to its black-box nature. This can require
decision-makers to make blind leaps of faith based on non-linear model results,
especially in healthcare applications. In non-invasive monitoring, patient data
from tracking sensors and their predisposing clinical attributes act as input
features for predicting future vital signs. Explaining the contributions of
various features to the overall output of the monitoring application is
critical for a clinician's decision-making. In this study, an Explainable AI
for Quantitative analysis (QXAI) framework is proposed with post-hoc model
explainability and intrinsic explainability for regression and classification
tasks in a supervised learning approach. This was achieved by utilizing the
Shapley values concept and incorporating attention mechanisms in deep learning
models. We adopted the artificial neural networks (ANN) and attention-based
Bidirectional LSTM (BiLSTM) models for the prediction of heart rate and
classification of physical activities based on sensor data. The deep learning
models achieved state-of-the-art results in both prediction and classification
tasks. Global explanation and local explanation were conducted on input data to
understand the feature contribution of various patient data. The proposed QXAI
framework was evaluated using PPG-DaLiA data to predict heart rate and mobile
health (MHEALTH) data to classify physical activities based on sensor data.
Monte Carlo approximation was applied to the framework to overcome the time
complexity and high computation power requirements required for Shapley value
calculations.

æè¦ï¼äººå·¥æºæ§æè¡å¯ç¨æ¼åé¡çæ£çèº«é«æ´»åä¸¦é æ¸¬é è·çæ£ç£æ§çéè¦çå½å¾µè±¡ãåºæ¼æ·±åº¦å­¸ç¿æ¨¡åç­éç·æ§æ¨¡åçåæ­¸åæç±æ¼å¶é»çå­çæ§è³ªèå·ææéçå¯è§£éæ§ãéå¯è½éè¦æ±ºç­èæ ¹æéç·æ§æ¨¡åçµæååºç²ç®çä¿¡ä»°é£èºï¼ç¹å¥æ¯å¨é«çä¿å¥æç¨ä¸­ãå¨éä¾µå¥æ§ç£æ§ä¸­ï¼ä¾èªè¿½è¹¤ææ¸¬å¨åå¶ææè¨åºå±¬æ§ççæ£è³æåç¶é æ¸¬æªä¾çå½å¾µè±¡çè¼¸å¥ç¹å¾µãè§£éåç¨®ç¹å¾µå°ç£æ§æç¨ç¨å¼æ´é«è¼¸åºçè²¢ç»å°æ¼è¨åºé«ççæ±ºç­è³ééè¦ãå¨æ¬ç ç©¶ä¸­ï¼æåºäºä¸åç¨æ¼éååæçå¯è§£éäººå·¥æºæ§ (QXAI) æ¶æ§ï¼è©²æ¶æ§å·æç£ç£å¼å­¸ç¿æ¹æ³ä¸­åæ­¸ååé¡ä»»åçäºå¾æ¨¡åå¯è§£éæ§åå§å¨å¯è§£éæ§ãéééå©ç¨ Shapley å¼æ¦å¿µä¸¦å°æ³¨æåæ©å¶ç´å¥æ·±åº¦å­¸ç¿æ¨¡åä¾å¯¦ç¾ãæåæ¡ç¨äººå·¥ç¥ç¶ç¶²è·¯ (ANN) ååºæ¼æ³¨æåçéå LSTM (BiLSTM) æ¨¡åï¼æ ¹æææ¸¬å¨è³æé æ¸¬å¿çååé¡èº«é«æ´»åãæ·±åº¦å­¸ç¿æ¨¡åå¨é æ¸¬ååé¡ä»»åä¸­é½åå¾äºæåé²çææãå°è¼¸å¥è³æé²è¡å¨å±è§£éåå±é¨è§£éï¼ä»¥äºè§£åç¨®çæ£è³æçç¹å¾µè²¢ç»ãææåºç QXAI æ¶æ§ä½¿ç¨ PPG-DaLiA è³æè©ä¼°ï¼ä»¥é æ¸¬å¿çï¼ä¸¦ä½¿ç¨è¡åå¥åº· (MHEALTH) è³ææ ¹æææ¸¬å¨è³æå°èº«é«æ´»åé²è¡åé¡ãèå°å¡ç¾è¿ä¼¼æ³æç¨æ¼è©²æ¶æ§ï¼ä»¥åæ Shapley å¼è¨ç®æéçæéè¤éåº¦åé«éç®è½åéæ±ã

##### **Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**
2309.09917v1 by Adarsa Sivaprasad, Ehud Reiter, Nava Tintarev, Nir Oren

In explainable artificial intelligence (XAI) research, the predominant focus
has been on interpreting models for experts and practitioners. Model agnostic
and local explanation approaches are deemed interpretable and sufficient in
many applications. However, in domains like healthcare, where end users are
patients without AI or domain expertise, there is an urgent need for model
explanations that are more comprehensible and instil trust in the model's
operations. We hypothesise that generating model explanations that are
narrative, patient-specific and global(holistic of the model) would enable
better understandability and enable decision-making. We test this using a
decision tree model to generate both local and global explanations for patients
identified as having a high risk of coronary heart disease. These explanations
are presented to non-expert users. We find a strong individual preference for a
specific type of explanation. The majority of participants prefer global
explanations, while a smaller group prefers local explanations. A task based
evaluation of mental models of these participants provide valuable feedback to
enhance narrative global explanations. This, in turn, guides the design of
health informatics systems that are both trustworthy and actionable.

æè¦ï¼å¨å¯è§£éäººå·¥æºè½ (XAI) ç ç©¶ä¸­ï¼ä¸»è¦éç¹å¨äºä¸ºä¸å®¶åä»ä¸èè§£éæ¨¡åãæ¨¡åä¸å¯ç¥åå±é¨è§£éæ¹æ³å¨è®¸å¤åºç¨ä¸­è¢«è®¤ä¸ºæ¯å¯è§£éä¸è¶³å¤çãç¶èï¼å¨å»çä¿å¥ç­é¢åï¼æç»ç¨æ·æ¯ç¼ºä¹äººå·¥æºè½æé¢åä¸ä¸ç¥è¯çæ£èï¼å æ­¤è¿«åéè¦æ´æäºçè§£ä¸è½æ¿åå¯¹æ¨¡åæä½çä¿¡ä»»çæ¨¡åè§£éãæä»¬åè®¾çæåè¿°æ§ãæ£èç¹å®ä¸å¨å±ï¼æ¨¡åæ´ä½ï¼çæ¨¡åè§£éå°è½å¤æé«å¯çè§£æ§å¹¶æ¯æå³ç­å¶å®ãæä»¬ä½¿ç¨å³ç­æ æ¨¡åå¯¹æ­¤è¿è¡æµè¯ï¼ä¸ºè¢«è¯å«ä¸ºæ£æå å¿çé«é£é©çæ£èçæå±é¨åå¨å±è§£éãè¿äºè§£éä¼åç°ç»éä¸å®¶ç¨æ·ãæä»¬åç°ç¨æ·å¼ºçåå¥½ç¹å®ç±»åçè§£éãå¤§å¤æ°åä¸èåå¥½å¨å±è§£éï¼èè¾å°çä¸ç»åä¸èåå¥½å±é¨è§£éãåºäºä»»å¡çå¿çæ¨¡åè¯ä¼°ä¸ºè¿äºåä¸èæä¾äºæä»·å¼çåé¦ï¼ä»¥å¢å¼ºåè¿°æ§å¨å±è§£éãè¿åè¿æ¥åæå¯¼äºæ¢å¼å¾ä¿¡èµåå¯æä½çå¥åº·ä¿¡æ¯å­¦ç³»ç»çè®¾è®¡ã

##### **Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**
2308.14321v1 by Yanjun Gao, Ruizhe Li, John Caskey, Dmitriy Dligach, Timothy Miller, Matthew M. Churpek, Majid Afshar

Electronic Health Records (EHRs) and routine documentation practices play a
vital role in patients' daily care, providing a holistic record of health,
diagnoses, and treatment. However, complex and verbose EHR narratives overload
healthcare providers, risking diagnostic inaccuracies. While Large Language
Models (LLMs) have showcased their potential in diverse language tasks, their
application in the healthcare arena needs to ensure the minimization of
diagnostic errors and the prevention of patient harm. In this paper, we outline
an innovative approach for augmenting the proficiency of LLMs in the realm of
automated diagnosis generation, achieved through the incorporation of a medical
knowledge graph (KG) and a novel graph model: Dr.Knows, inspired by the
clinical diagnostic reasoning process. We derive the KG from the National
Library of Medicine's Unified Medical Language System (UMLS), a robust
repository of biomedical knowledge. Our method negates the need for
pre-training and instead leverages the KG as an auxiliary instrument aiding in
the interpretation and summarization of complex medical concepts. Using
real-world hospital datasets, our experimental results demonstrate that the
proposed approach of combining LLMs with KG has the potential to improve the
accuracy of automated diagnosis generation. More importantly, our approach
offers an explainable diagnostic pathway, edging us closer to the realization
of AI-augmented diagnostic decision support systems.

æè¦ï¼é»å­å¥åº·ç´é (EHR) åä¾è¡æä»¶è¨éå¯¦åå¨çæ£çæ¥å¸¸ç§è­·ä¸­æ®æ¼èè³ééè¦çè§è²ï¼æä¾å¥åº·ãè¨ºæ·åæ²»ççæ´é«ç´éãç¶èï¼è¤éä¸åé·ç EHR æè¿°æè®é«çä¿å¥æä¾èè¶è¼ï¼æè¨ºæ·ä¸æºç¢ºçé¢¨éªãå¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾å¶å¨åç¨®èªè¨ä»»åä¸çæ½åï¼ä½å¶å¨é«çä¿å¥é åçæç¨éè¦ç¢ºä¿å°è¨ºæ·é¯èª¤éå°æä½ï¼ä¸¦é²æ­¢çæ£åå°å·å®³ãå¨æ¬æä¸­ï¼æåæ¦è¿°ä¸ç¨®åµæ°çæ¹æ³ï¼ééæ´åé«å­¸ç¥è­åè­ (KG) åä¸ç¨®æ°ç©çåè­æ¨¡åï¼Dr.Knowsï¼éæä¾èªè¨åºè¨ºæ·æ¨çéç¨ï¼ï¼ä¾å¢å¼· LLM å¨èªååè¨ºæ·ç¢çé åçè½åãæåå¾ç¾ååå®¶é«å­¸åæ¸é¤¨ççµ±ä¸é«å­¸èªè¨ç³»çµ± (UMLS) ä¸­è¡çåº KGï¼éæ¯ä¸åå¼·å¤§ççç©é«å­¸ç¥è­å²å­åº«ãæåçåæ³å¦å®äºé åè¨ç·´çéè¦ï¼èæ¯å° KG ä½çºè¼å©å·¥å·ï¼åå©è§£éåç¸½çµè¤éçé«å­¸æ¦å¿µãä½¿ç¨çå¯¦ä¸ççé«é¢è³æéï¼æåçå¯¦é©çµæè­æï¼å° LLM è KG çµåçå»ºè­°æ¹æ³ææ½åæé«èªååè¨ºæ·ç¢ççæºç¢ºæ§ãæ´éè¦çæ¯ï¼æåçåæ³æä¾äºä¸æ¢å¯è§£éçè¨ºæ·éå¾ï¼è®æåæ´æ¥è¿å¯¦ç¾ AI å¢å¼·çè¨ºæ·æ±ºç­æ¯æ´ç³»çµ±ã

##### **Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**
2308.09380v1 by Yun Xin Teoh, Alice Othmani, Siew Li Goh, Juliana Usman, Khin Wee Lai

Existing artificial intelligence (AI) models for diagnosing knee
osteoarthritis (OA) have faced criticism for their lack of transparency and
interpretability, despite achieving medical-expert-like performance. This
opacity makes them challenging to trust in clinical practice. Recently,
explainable artificial intelligence (XAI) has emerged as a specialized
technique that can provide confidence in the model's prediction by revealing
how the prediction is derived, thus promoting the use of AI systems in
healthcare. This paper presents the first survey of XAI techniques used for
knee OA diagnosis. The XAI techniques are discussed from two perspectives: data
interpretability and model interpretability. The aim of this paper is to
provide valuable insights into XAI's potential towards a more reliable knee OA
diagnosis approach and encourage its adoption in clinical practice.

æè¦ï¼ç¾æçç¨æ¼è¨ºæ·èéª¨éç¯ç (OA) çäººå·¥æºæ§ (AI) æ¨¡åå å¶ç¼ºä¹éæåº¦åå¯è§£éæ§èåå°æ¹è©ï¼åç®¡å®åéå°äºé¡ä¼¼é«å­¸å°å®¶çè¡¨ç¾ãéç¨®ä¸éææ§ä½¿å¾å®åå¨è¨åºå¯¦åä¸­é£ä»¥è¢«ä¿¡ä»»ãæè¿ï¼å¯è§£éäººå·¥æºæ§ (XAI) å·²æçºä¸ç¨®å°éæè¡ï¼å®è½ééæ­ç¤ºé æ¸¬çæ¨å°æ¹å¼ä¾æä¾å°æ¨¡åé æ¸¬çä¿¡å¿ï¼å¾èä¿é²å¨é«çä¿å¥ä¸­ä½¿ç¨ AI ç³»çµ±ãæ¬ææä¾äºéå°èéª¨éç¯çè¨ºæ·æä½¿ç¨ç XAI æè¡çç¬¬ä¸ä»½èª¿æ¥ãXAI æè¡å¾å©åè§åº¦é²è¡è¨è«ï¼è³æå¯è§£éæ§åæ¨¡åå¯è§£éæ§ãæ¬æçç®çæ¯æä¾å° XAI å¨æ´å¯é çèéª¨éç¯çè¨ºæ·æ¹æ³ä¸­çæ½åçå¯¶è²´è¦è§£ï¼ä¸¦é¼åµå¨è¨åºå¯¦åä¸­æ¡ç¨å®ã

##### **Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**
2308.08407v1 by Munib Mesinovic, Peter Watkinson, Tingting Zhu

Recent advancements in AI applications to healthcare have shown incredible
promise in surpassing human performance in diagnosis and disease prognosis.
With the increasing complexity of AI models, however, concerns regarding their
opacity, potential biases, and the need for interpretability. To ensure trust
and reliability in AI systems, especially in clinical risk prediction models,
explainability becomes crucial. Explainability is usually referred to as an AI
system's ability to provide a robust interpretation of its decision-making
logic or the decisions themselves to human stakeholders. In clinical risk
prediction, other aspects of explainability like fairness, bias, trust, and
transparency also represent important concepts beyond just interpretability. In
this review, we address the relationship between these concepts as they are
often used together or interchangeably. This review also discusses recent
progress in developing explainable models for clinical risk prediction,
highlighting the importance of quantitative and clinical evaluation and
validation across multiple common modalities in clinical practice. It
emphasizes the need for external validation and the combination of diverse
interpretability methods to enhance trust and fairness. Adopting rigorous
testing, such as using synthetic datasets with known generative factors, can
further improve the reliability of explainability methods. Open access and
code-sharing resources are essential for transparency and reproducibility,
enabling the growth and trustworthiness of explainable research. While
challenges exist, an end-to-end approach to explainability in clinical risk
prediction, incorporating stakeholders from clinicians to developers, is
essential for success.

æè¦ï¼æè¿å¨é«çä¿å¥ä¸­çäººå·¥æºæ§æç¨é²å±é¡¯ç¤ºåºä»¤äººé£ä»¥ç½®ä¿¡çæ¿è«¾ï¼å¨è¨ºæ·åç¾çé å¾æ¹é¢è¶è¶äººé¡è¡¨ç¾ãç¶èï¼é¨èäººå·¥æºè½æ¨¡åçæ¥çè¤éï¼äººåå°å¶ä¸éææ§ãæ½å¨åå·®åå°å¯è§£éæ§çéæ±æå°ææãçºäºç¢ºä¿äººå·¥æºè½ç³»çµ±çä¿¡ä»»åå¯é æ§ï¼å°¤å¶æ¯å¨è¨åºé¢¨éªé æ¸¬æ¨¡åä¸­ï¼å¯è§£éæ§è®å¾è³ééè¦ãå¯è§£éæ§éå¸¸è¢«ç¨±çºäººå·¥æºè½ç³»çµ±æä¾å¶æ±ºç­éè¼¯ææ±ºç­æ¬èº«å°äººé¡å©çç¸éèçå¼·æåè§£éçè½åãå¨è¨åºé¢¨éªé æ¸¬ä¸­ï¼å¯è§£éæ§çå¶ä»æ¹é¢ï¼å¦å¬å¹³æ§ãåè¦ãä¿¡ä»»åéæåº¦ï¼ä¹ä»£è¡¨äºè¶è¶å¯è§£éæ§çéè¦æ¦å¿µãå¨æ¬æ¬¡å¯©æ¥ä¸­ï¼æåæ¢è¨äºéäºæ¦å¿µä¹éçéä¿ï¼å çºå®åç¶å¸¸ä¸èµ·æäºæä½¿ç¨ãæ¬å¯©æ¥éè¨è«äºçºè¨åºé¢¨éªé æ¸¬éç¼å¯è§£éæ¨¡åçææ°é²å±ï¼å¼·èª¿äºå¨è¨åºå¯¦è¸ä¸­å°å¤ç¨®å¸¸è¦æ¨¡å¼é²è¡å®éåè¨åºè©ä¼°åé©è­çéè¦æ§ãå®å¼·èª¿äºå¤é¨é©è­åå¤æ¨£åå¯è§£éæ§æ¹æ³ç¸çµåçå¿è¦æ§ï¼ä»¥å¢å¼·ä¿¡ä»»åå¬å¹³æ§ãæ¡ç¨å´æ ¼çæ¸¬è©¦ï¼ä¾å¦ä½¿ç¨å·æå·²ç¥çæå ç´ çåææ¸æéï¼å¯ä»¥é²ä¸æ­¥æé«å¯è§£éæ§æ¹æ³çå¯é æ§ãéæ¾ç²ååä»£ç¢¼å±äº«è³æºå°æ¼éæåº¦åå¯éè¤æ§è³ééè¦ï¼å¾èä¿é²å¯è§£éç ç©¶çå¢é·åå¯ä¿¡åº¦ãåç®¡å­å¨ææ°ï¼ä½å¾è¨åºé«çå°éç¼äººå¡ï¼æ¡ç¨ç«¯å°ç«¯çå¯è§£éæ§æ¹æ³å°æ¼è¨åºé¢¨éªé æ¸¬çæåè³ééè¦ã

##### **FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**
2309.12325v3 by Karim Lekadir, Aasa Feragen, Abdul Joseph Fofanah, Alejandro F Frangi, Alena Buyx, Anais Emelie, Andrea Lara, Antonio R Porras, An-Wen Chan, Arcadi Navarro, Ben Glocker, Benard O Botwe, Bishesh Khanal, Brigit Beger, Carol C Wu, Celia Cintas, Curtis P Langlotz, Daniel Rueckert, Deogratias Mzurikwao, Dimitrios I Fotiadis, Doszhan Zhussupov, Enzo Ferrante, Erik Meijering, Eva Weicken, Fabio A GonzÃ¡lez, Folkert W Asselbergs, Fred Prior, Gabriel P Krestin, Gary Collins, Geletaw S Tegenaw, Georgios Kaissis, Gianluca Misuraca, Gianna Tsakou, Girish Dwivedi, Haridimos Kondylakis, Harsha Jayakody, Henry C Woodruf, Horst Joachim Mayer, Hugo JWL Aerts, Ian Walsh, Ioanna Chouvarda, IrÃ¨ne Buvat, Isabell Tributsch, Islem Rekik, James Duncan, Jayashree Kalpathy-Cramer, Jihad Zahir, Jinah Park, John Mongan, Judy W Gichoya, Julia A Schnabel, Kaisar Kushibar, Katrine Riklund, Kensaku Mori, Kostas Marias, Lameck M Amugongo, Lauren A Fromont, Lena Maier-Hein, Leonor CerdÃ¡ Alberich, Leticia Rittner, Lighton Phiri, Linda Marrakchi-Kacem, LluÃ­s Donoso-Bach, Luis MartÃ­-BonmatÃ­, M Jorge Cardoso, Maciej Bobowicz, Mahsa Shabani, Manolis Tsiknakis, Maria A Zuluaga, Maria Bielikova, Marie-Christine Fritzsche, Marina Camacho, Marius George Linguraru, Markus Wenzel, Marleen De Bruijne, Martin G Tolsgaard, Marzyeh Ghassemi, Md Ashrafuzzaman, Melanie Goisauf, Mohammad Yaqub, MÃ³nica Cano AbadÃ­a, Mukhtar M E Mahmoud, Mustafa Elattar, Nicola Rieke, Nikolaos Papanikolaou, Noussair Lazrak, Oliver DÃ­az, Olivier Salvado, Oriol Pujol, Ousmane Sall, Pamela Guevara, Peter Gordebeke, Philippe Lambin, Pieta Brown, Purang Abolmaesumi, Qi Dou, Qinghua Lu, Richard Osuala, Rose Nakasi, S Kevin Zhou, Sandy Napel, Sara Colantonio, Shadi Albarqouni, Smriti Joshi, Stacy Carter, Stefan Klein, Steffen E Petersen, Susanna AussÃ³, Suyash Awate, Tammy Riklin Raviv, Tessa Cook, Tinashe E M Mutsvangwa, Wendy A Rogers, Wiro J Niessen, XÃ¨nia Puig-Bosch, Yi Zeng, Yunusa G Mohammed, Yves Saint James Aquino, Zohaib Salahuddin, Martijn P A Starmans

Despite major advances in artificial intelligence (AI) for medicine and
healthcare, the deployment and adoption of AI technologies remain limited in
real-world clinical practice. In recent years, concerns have been raised about
the technical, clinical, ethical and legal risks associated with medical AI. To
increase real world adoption, it is essential that medical AI tools are trusted
and accepted by patients, clinicians, health organisations and authorities.
This work describes the FUTURE-AI guideline as the first international
consensus framework for guiding the development and deployment of trustworthy
AI tools in healthcare. The FUTURE-AI consortium was founded in 2021 and
currently comprises 118 inter-disciplinary experts from 51 countries
representing all continents, including AI scientists, clinicians, ethicists,
and social scientists. Over a two-year period, the consortium defined guiding
principles and best practices for trustworthy AI through an iterative process
comprising an in-depth literature review, a modified Delphi survey, and online
consensus meetings. The FUTURE-AI framework was established based on 6 guiding
principles for trustworthy AI in healthcare, i.e. Fairness, Universality,
Traceability, Usability, Robustness and Explainability. Through consensus, a
set of 28 best practices were defined, addressing technical, clinical, legal
and socio-ethical dimensions. The recommendations cover the entire lifecycle of
medical AI, from design, development and validation to regulation, deployment,
and monitoring. FUTURE-AI is a risk-informed, assumption-free guideline which
provides a structured approach for constructing medical AI tools that will be
trusted, deployed and adopted in real-world practice. Researchers are
encouraged to take the recommendations into account in proof-of-concept stages
to facilitate future translation towards clinical practice of medical AI.

æè¦ï¼åç®¡å¨é«å­¸åé«çä¿å¥æ¹é¢çäººå·¥æºæ§ (AI) æéå¤§çé²å±ï¼ä½ AI æè¡çé¨ç½²åæ¡ç¨å¨ç¾å¯¦ä¸ççè¨åºå¯¦åä¸­ä»ç¶æéãè¿å¹´ä¾ï¼äººåå°æ¼èé«ç AI ç¸éçæè¡ãè¨åºãå«çåæ³å¾é¢¨éªæåºäºçæ®ãçºäºå¢å ç¾å¯¦ä¸ççæ¡ç¨çï¼é«ç AI å·¥å·å¿é ç²å¾æ£èãè¨åºé«çãé«çæ©æ§åç¶å±çä¿¡ä»»åæ¥åãéé å·¥ä½å° FUTURE-AI æåæè¿°çºæå°é«çä¿å¥ä¸­å¯ä¿¡è³´ AI å·¥å·éç¼åé¨ç½²çç¬¬ä¸ååéå±è­æ¶æ§ãFUTURE-AI è¯çæç«æ¼ 2021 å¹´ï¼ç®åç±ä¾èª 51 ååå®¶ç 118 ä½è·¨é åå°å®¶çµæï¼ä»£è¡¨æææ´²ï¼åæ¬ AI ç§å­¸å®¶ãè¨åºé«çãå«çå­¸å®¶åç¤¾æç§å­¸å®¶ãå¨å©å¹´çæéè£¡ï¼è©²è¯çééä¸ååè¦éç®çéç¨å®ç¾©äºå¯ä¿¡è³´ AI çæå°åååæä½³å¯¦åï¼åæ¬æ·±å¥çæç»åé¡§ãä¿®æ¹å¾çå¾·ç¾è²èª¿æ¥åç·ä¸å±è­æè­°ãFUTURE-AI æ¶æ§æ¯åºæ¼é«çä¿å¥ä¸­å¯ä¿¡è³´ AI ç 6 é æå°ååå»ºç«çï¼å³å¬å¹³æ§ãæ®éæ§ãå¯è¿½æº¯æ§ãå¯ç¨æ§ãç©©å¥æ§åå¯è§£éæ§ãééå±è­ï¼å®ç¾©äºä¸çµ 28 é æä½³å¯¦åï¼æ¶µèæè¡ãè¨åºãæ³å¾åç¤¾æå«çå±¤é¢ãå»ºè­°æ¶µèäºé«ç AI çæ´åçå½é±æï¼å¾è¨­è¨ãéç¼åé©è­å°æ³è¦ãé¨ç½²åç£æ§ãFUTURE-AI æ¯ä¸ååºæ¼é¢¨éªãç¡åè¨­çæåï¼æä¾äºä¸åçµæ§åçæ¹æ³ï¼ç¨æ¼å»ºæ§å°å¨ç¾å¯¦ä¸çå¯¦åä¸­åå°ä¿¡ä»»ãé¨ç½²åæ¡ç¨çé«ç AI å·¥å·ãé¼åµç ç©¶äººå¡å¨æ¦å¿µé©è­éæ®µèæ®éäºå»ºè­°ï¼ä»¥ä¿é²æªä¾å°é«ç AI è½åçºè¨åºå¯¦åã

##### **Explainable AI applications in the Medical Domain: a systematic review**
2308.05411v1 by Nicoletta Prentzas, Antonis Kakas, Constantinos S. Pattichis

Artificial Intelligence in Medicine has made significant progress with
emerging applications in medical imaging, patient care, and other areas. While
these applications have proven successful in retrospective studies, very few of
them were applied in practice.The field of Medical AI faces various challenges,
in terms of building user trust, complying with regulations, using data
ethically.Explainable AI (XAI) aims to enable humans understand AI and trust
its results. This paper presents a literature review on the recent developments
of XAI solutions for medical decision support, based on a representative sample
of 198 articles published in recent years. The systematic synthesis of the
relevant articles resulted in several findings. (1) model-agnostic XAI
techniques were mostly employed in these solutions, (2) deep learning models
are utilized more than other types of machine learning models, (3)
explainability was applied to promote trust, but very few works reported the
physicians participation in the loop, (4) visual and interactive user interface
is more useful in understanding the explanation and the recommendation of the
system. More research is needed in collaboration between medical and AI
experts, that could guide the development of suitable frameworks for the
design, implementation, and evaluation of XAI solutions in medicine.

æè¦ï¼äººå·¥æºæ§å¨é«çé åä¸­å·²åå¾é¡¯èé²å±ï¼å¨é«å­¸å½±åãçäººç§è­·åå¶ä»é åä¸­åºç¾äºæ°èæç¨ãéç¶éäºæç¨å·²å¨åé¡§æ§ç ç©¶ä¸­è¢«è­å¯¦æ¯æåçï¼ä½å¯¦éä¸åªææ¥µå°æ¸æç¨æ¼å¯¦åãé«ç AI é åé¢è¨èåç¨®ææ°ï¼åæ¬å»ºç«ä½¿ç¨èä¿¡ä»»ãéµå®æ³è¦ãä½¿ç¨è³æç¬¦åå«çãå¯è§£é AI (XAI) çç®æ¨æ¯è®äººé¡äºè§£ AI ä¸¦ç¸ä¿¡å¶çµæãæ¬æéå°æè¿å¹¾å¹´ç¼è¡¨ç 198 ç¯æç« çå·ä»£è¡¨æ§æ¨£æ¬ï¼æåºæéé«çæ±ºç­æ¯æ´ç XAI è§£æ±ºæ¹æ¡çææ°ç¼å±çæç»åé¡§ãç¸éæç« çç³»çµ±æ§ç¶åæ´çç¢çäºå¤é ç¼ç¾ï¼(1) éäºè§£æ±ºæ¹æ¡å¤§å¤æ¡ç¨èæ¨¡åç¡éç XAI æè¡ï¼(2) æ·±åº¦å­¸ç¿æ¨¡åçä½¿ç¨çé«æ¼å¶ä»é¡åçæ©å¨å­¸ç¿æ¨¡åï¼(3) å¯è§£éæ§è¢«ç¨æ¼ä¿é²ä¿¡ä»»ï¼ä½å¾å°æç ç©¶å ±åé«å¸«åèè¿´åï¼(4) è¦è¦ºåäºåå¼ä½¿ç¨èä»é¢å°æ¼çè§£ç³»çµ±çè§£éåå»ºè­°æ´æç¨ãéè¦æ´å¤é«çå AI å°å®¶åä½é²è¡ç ç©¶ï¼éæå©æ¼çºé«çé åç XAI è§£æ±ºæ¹æ¡çè¨­è¨ãå¯¦ä½åè©ä¼°æä¾é©ç¶æ¶æ§ã

##### **Exploring the Role of Explainability in AI-Assisted Embryo Selection**
2308.02534v1 by Lucia Urcelay, Daniel Hinjos, Pablo A. Martin-Torres, Marta Gonzalez, Marta Mendez, Salva CÃ­vico, Sergio Ãlvarez-Napagao, Dario Garcia-Gasulla

In Vitro Fertilization is among the most widespread treatments for
infertility. One of its main challenges is the evaluation and selection of
embryo for implantation, a process with large inter- and intra-clinician
variability. Deep learning based methods are gaining attention, but their
opaque nature compromises their acceptance in the clinical context, where
transparency in the decision making is key. In this paper we analyze the
current work in the explainability of AI-assisted embryo analysis models,
identifying the limitations. We also discuss how these models could be
integrated in the clinical context as decision support systems, considering the
needs of clinicians and patients. Finally, we propose guidelines for the sake
of increasing interpretability and trustworthiness, pushing this technology
forward towards established clinical practice.

æè¦ï¼é«å¤åç²¾æ¯æ²»çä¸å­çæå»£æ³çæ¹æ³ä¹ä¸ãå¶ä¸»è¦ææ°ä¹ä¸æ¯è©ä¼°åé¸æèèé²è¡æ¤å¥ï¼æ­¤éç¨å·æå¾å¤§çè¨åºéåè¨åºå§è®ç°æ§ãåºæ¼æ·±åº¦å­¸ç¿çæ¹æ³æ­£åå°éæ³¨ï¼ä½å¶ä¸éæçæ§è³ªæå½±é¿å¶å¨è¨åºç°å¢ä¸­çæ¥ååº¦ï¼èéæåº¦å¨æ±ºç­å¶å®ä¸­è³ééè¦ãå¨æ¬æä¸­ï¼æååæäº AI è¼å©èèåææ¨¡åçå¯è§£éæ§æ¹é¢çç¾æå·¥ä½ï¼ä¸¦æ¾åºå¶å±éæ§ãæåéè¨è«äºå¦ä½å°éäºæ¨¡åä½çºæ±ºç­æ¯æç³»çµ±æ´åå°è¨åºç°å¢ä¸­ï¼åæèæ®è¨åºé«çåæ£èçéæ±ãæå¾ï¼æåæåºäºæé«å¯è§£éæ§åå¯ä¿¡åº¦çæºåï¼æ¨é²éé æè¡æèæ¢å®çè¨åºå¯¦åéé²ã

##### **A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**
2307.14246v1 by Timo Speith, Markus Langer

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

æè¦ï¼å¨éæ±å·¥ç¨ (RE) é åä¸­ï¼å¯è§£éäººå·¥æºæ§ (XAI) å¨å° AI æ¯æçç³»çµ±èä½¿ç¨èéæ±ãç¤¾æææåæ³è¦æ¨æºç¸ç¬¦æ¹é¢çéè¦æ§æ¥çé¡¯èï¼å·²ç²å¾èªå¯ãä¸è¬ä¾èªªï¼å¯è§£éæ§å·²æçºå½±é¿ç³»çµ±åè³ªçéè¦éåè½éæ±ãç¶èï¼å¯è§£éæ§èæè½ä¹éçåå®æ¬è¡¡ææ°äºå¯è§£éæ§çåå®æ­£é¢å½±é¿ãå¦ææ»¿è¶³å¯è§£éæ§çéæ±éè¦éä½ç³»çµ±æè½ï¼é£éº¼å¿é ä»ç´°èæ®éäºåè³ªé¢åä¸­åªä¸ååªåï¼ä»¥åå¦ä½å¨å®åä¹éé²è¡æè¡·ãå¨æ¬æä¸­ï¼æåæ¹å¤æ§å°æ¢è¨äºéç¨®åå®çæ¬è¡¡ãæåèªçºï¼æå¥½çæ¹æ³æ¯ä»¥ä¸ç¨®ç´°ç·»çæ¹å¼ä¾èçï¼éç¨®æ¹å¼åå«è³æºå¯ç¨æ§ãé åç¹æ§åé¢¨éªèéãééæä¾æªä¾ç ç©¶åæä½³å¯¦åçåºç¤ï¼éé å·¥ä½æ¨å¨æå AI ç RE é åã

##### **Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**
2307.14239v1 by Barnaby Crook, Maximilian SchlÃ¼ter, Timo Speith

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

æè¦ï¼å¨éæ±å·¥ç¨ï¼REï¼é¢åï¼å¯è§£éäººå·¥æºè½ï¼XAIï¼å¨å°äººå·¥æºè½æ¯æçç³»ç»ä¸ç¨æ·éæ±ãç¤¾ä¼ææåçç®¡æ åç¸ä¸è´æ¹é¢çéè¦æ§æ¥çå¸æ¾ï¼å¹¶è·å¾äºè®¤å¯ãä¸è¬æ¥è¯´ï¼å¯è§£éæ§å·²æä¸ºå½±åç³»ç»è´¨éçéè¦éåè½æ§éæ±ãç¶èï¼å¯è§£éæ§åæ§è½ä¹é´çæè¡¡ææäºå¯è§£éæ§çæ­£é¢å½±åãå¦ææ»¡è¶³å¯è§£éæ§çè¦æ±éè¦éä½ç³»ç»æ§è½ï¼é£ä¹å¿é¡»ä»ç»èèè¿äºè´¨éæ¹é¢ä¸­çåªä¸ä¸ªä¼åï¼ä»¥åå¦ä½å¨å®ä»¬ä¹é´è¿è¡æè¡¡ãå¨æ¬æä¸­ï¼æä»¬æ¹å¤æ§å°èå¯äºæè°çæè¡¡ãæä»¬è®¤ä¸ºï¼æå¥½ä»¥ä¸ç§ç»è´å¥å¾®çæ¹å¼æ¥å¤çå®ï¼è¿ç§æ¹å¼ç»åäºèµæºå¯ç¨æ§ãé¢åç¹å¾åé£é©èèãéè¿ä¸ºæªæ¥çç ç©¶åæä½³å®è·µæä¾åºç¡ï¼è¿é¡¹å·¥ä½æ¨å¨æ¨è¿äººå·¥æºè½ç RE é¢åã

##### **Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**
2308.02047v1 by Henry Fraser, Jose-Miguel Bello y Villarino

This paper critically evaluates the European Commission's proposed AI Act's
approach to risk management and risk acceptability for high-risk AI systems
that pose risks to fundamental rights and safety. The Act aims to promote
"trustworthy" AI with a proportionate regulatory burden. Its provisions on risk
acceptability require residual risks from high-risk systems to be reduced or
eliminated "as far as possible", having regard to the "state of the art". This
criterion, especially if interpreted narrowly, is unworkable and promotes
neither proportionate regulatory burden, nor trustworthiness. By contrast the
Parliament's most recent draft amendments to the risk management provisions
introduce "reasonableness", cost-benefit analysis, and are more transparent
about the value-laden and contextual nature of risk acceptability judgements.
This paper argues that the Parliament's approach is more workable, and better
balances the goals of proportionality and trustworthiness. It explains what
reasonableness in risk acceptability judgments would entail, drawing on
principles from negligence law and European medical devices regulation. And it
contends that the approach to risk acceptability judgments need a firm
foundation of civic legitimacy: including detailed guidance or involvement from
regulators, and meaningful input from affected stakeholders.

æè¦ï¼æ¬æå´æ ¼è©ä¼°æ­æ´²å§å¡ææåºç AI æ³æ¡å°é¢¨éªç®¡çåé¢¨éªå¯æ¥åæ§çæ¹æ³ï¼ç¨æ¼å°åºæ¬æ¬å©åå®å¨æ§æé¢¨éªçé«é¢¨éª AI ç³»çµ±ãè©²æ³æ¡æ¨å¨ä»¥ç¸ç¨±çç£ç®¡è² æä¿é²ãå¼å¾ä¿¡è³´ãç AIãå¶éæ¼é¢¨éªå¯æ¥åæ§çæ¢æ¬¾è¦æ±å°é«é¢¨éªç³»çµ±çæ®é¤é¢¨éªæ¸ä½ææ¶é¤ãç¡å¯è½ãï¼ä¸¦èæ®ãæè¡çæããæ­¤æºåï¼ç¹å¥æ¯å¦æç¹ç¾©è§£éï¼ç¡æ³å·è¡ï¼æ¢ä¸ä¿é²ç¸ç¨±çç£ç®¡è² æï¼ä¹ä¸ä¿é²å¯ä¿¡è³´æ§ãç¸æ¯ä¹ä¸ï¼è­°æå°é¢¨éªç®¡çæ¢æ¬¾çææ°ä¿®æ­£èæ¡å¼å¥äºãåçæ§ããææ¬æçåæï¼ä¸¦ä¸æ´éæå°èªªæäºé¢¨éªå¯æ¥åæ§å¤æ·çå¹å¼è§åèæ¯æ§è³ªãæ¬æè«è­è­°æçæ¹æ³æ´å¯è¡ï¼ä¸è½æ´å¥½å°å¹³è¡¡ç¸ç¨±æ§åå¯ä¿¡è³´æ§çç®æ¨ãæ¬æèªªæé¢¨éªå¯æ¥åæ§å¤æ·ä¸­çåçæ§æå¸¶ä¾ä»éº¼ï¼ä¸¦æ ¹æéå¤±æ³åæ­æ´²é«çå¨ææ³è¦ä¸­çååé²è¡èªªæãæ¬æä¸»å¼µé¢¨éªå¯æ¥åæ§å¤æ·çæ¹æ³éè¦ç©©åºçå¬æ°åæ³æ§åºç¤ï¼åæ¬ç£ç®¡æ©æ§çè©³ç´°æå°æåèï¼ä»¥ååå½±é¿å©å®³éä¿äººçææç¾©æå¥ã

##### **eXplainable Artificial Intelligence (XAI) in aging clock models**
2307.13704v3 by Alena Kalyakulina, Igor Yusipov, Alexey Moskalev, Claudio Franceschi, Mikhail Ivanchenko

eXplainable Artificial Intelligence (XAI) is a rapidly progressing field of
machine learning, aiming to unravel the predictions of complex models. XAI is
especially required in sensitive applications, e.g. in health care, when
diagnosis, recommendations and treatment choices might rely on the decisions
made by artificial intelligence systems. AI approaches have become widely used
in aging research as well, in particular, in developing biological clock models
and identifying biomarkers of aging and age-related diseases. However, the
potential of XAI here awaits to be fully appreciated. We discuss the
application of XAI for developing the "aging clocks" and present a
comprehensive analysis of the literature categorized by the focus on particular
physiological systems.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) æ¯æ©å¨å­¸ç¿ä¸­å¿«éé²å±çé åï¼æ¨å¨è§£éè¤éæ¨¡åçé æ¸¬ãXAI å¨æææç¨ä¸­ç¹å¥éè¦ï¼ä¾å¦å¨é«çä¿å¥ä¸­ï¼ç¶è¨ºæ·ãå»ºè­°åæ²»çé¸æå¯è½ä¾è³´æ¼äººå·¥æºæ§ç³»çµ±ååºçæ±ºç­æãäººå·¥æºæ§æ¹æ³ä¹å·²å»£æ³ç¨æ¼èåç ç©¶ï¼ç¹å¥æ¯å¨éç¼çç©æéæ¨¡ååè­å¥èååèå¹´é½¡ç¸éç¾çççç©æ¨èªç©æ¹é¢ãç¶èï¼éè£¡ XAI çæ½åæå¾ååèªè­ãæåè¨è«äº XAI å¨éç¼ãèåæéãæ¹é¢çæç¨ï¼ä¸¦å°æç¹å®ççç³»çµ±çéé»åé¡çæç»é²è¡äºå¨é¢çåæã

##### **Interpreting and Correcting Medical Image Classification with PIP-Net**
2307.10404v2 by Meike Nauta, Johannes H. Hegeman, Jeroen Geerdink, JÃ¶rg SchlÃ¶tterer, Maurice van Keulen, Christin Seifert

Part-prototype models are explainable-by-design image classifiers, and a
promising alternative to black box AI. This paper explores the applicability
and potential of interpretable machine learning, in particular PIP-Net, for
automated diagnosis support on real-world medical imaging data. PIP-Net learns
human-understandable prototypical image parts and we evaluate its accuracy and
interpretability for fracture detection and skin cancer diagnosis. We find that
PIP-Net's decision making process is in line with medical classification
standards, while only provided with image-level class labels. Because of
PIP-Net's unsupervised pretraining of prototypes, data quality problems such as
undesired text in an X-ray or labelling errors can be easily identified.
Additionally, we are the first to show that humans can manually correct the
reasoning of PIP-Net by directly disabling undesired prototypes. We conclude
that part-prototype models are promising for medical applications due to their
interpretability and potential for advanced model debugging.

æè¦ï¼é¨åååæ¨¡åæ¯å¯è§£éè¨­è¨çå½±ååé¡å¨ï¼ä¹æ¯é»ç®± AI çä¸åæåéçæ¿ä»£æ¹æ¡ãéç¯è«ææ¢è¨äºè§£éæ§æ©å¨å­¸ç¿ï¼ç¹å¥æ¯ PIP-Netï¼å¨çå¯¦ä¸çé«å­¸å½±åè³æä¸èªååè¨ºæ·æ¯æ´çé©ç¨æ§åæ½åãPIP-Net å­¸ç¿äººé¡å¯çè§£çååå½±åé¨åï¼æåè©ä¼°å¶å¨éª¨ææª¢æ¸¬åç®èçè¨ºæ·æ¹é¢çæºç¢ºæ§åå¯è§£éæ§ãæåç¼ç¾ PIP-Net çæ±ºç­å¶å®éç¨ç¬¦åé«å­¸åé¡æ¨æºï¼åæåæä¾å½±åå±¤ç´é¡å¥æ¨ç±¤ãç±æ¼ PIP-Net å°ååçç¡ç£ç£é è¨ç·´ï¼å æ­¤å¯ä»¥è¼é¬è­å¥è³æåè³ªåé¡ï¼ä¾å¦ X åä¸­çä¸éè¦æå­ææ¨ç±¤é¯èª¤ãæ­¤å¤ï¼æåé¦æ¬¡å±ç¤ºäººé¡å¯ä»¥ééç´æ¥åç¨ä¸éè¦çååä¾æåä¿®æ­£ PIP-Net çæ¨çãæåå¾åºçµè«ï¼é¨åååæ¨¡åç±æ¼å¶å¯è§£éæ§åé²éæ¨¡åé¤é¯çæ½åï¼å æ­¤æææç¨æ¼é«çã

##### **Explaining and visualizing black-box models through counterfactual paths**
2307.07764v3 by Bastian Pfeifer, Mateusz Krzyzinski, Hubert Baniecki, Anna Saranti, Andreas Holzinger, Przemyslaw Biecek

Explainable AI (XAI) is an increasingly important area of machine learning
research, which aims to make black-box models transparent and interpretable. In
this paper, we propose a novel approach to XAI that uses the so-called
counterfactual paths generated by conditional permutations of features. The
algorithm measures feature importance by identifying sequential permutations of
features that most influence changes in model predictions. It is particularly
suitable for generating explanations based on counterfactual paths in knowledge
graphs incorporating domain knowledge. Counterfactual paths introduce an
additional graph dimension to current XAI methods in both explaining and
visualizing black-box models. Experiments with synthetic and medical data
demonstrate the practical applicability of our approach.

æè¦ï¼å¯è§£é AI (XAI) æ¯æ©å¨å­¸ç¿ç ç©¶ä¸­æ¥çéè¦çé åï¼å¶ç®æ¨æ¯è®é»ç®±æ¨¡åéæä¸å¯è§£éãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°ç XAI æ¹æ³ï¼è©²æ¹æ³ä½¿ç¨ç±ç¹å¾µæ¢ä»¶ç½®æç¢ççæè¬åäºå¯¦è·¯å¾ãè©²æ¼ç®æ³ééè­å¥ç¹å¾µçé åºç½®æä¾è¡¡éç¹å¾µéè¦æ§ï¼éäºç½®ææè½å½±é¿æ¨¡åé æ¸¬çè®åãå®ç¹å¥é©åæ ¹æåå«é åç¥è­çç¥è­åè­ä¸­çåäºå¯¦è·¯å¾ä¾ç¢çè§£éãåäºå¯¦è·¯å¾å¨è§£éåè¦è¦ºåé»ç®±æ¨¡åæï¼çºç®åç XAI æ¹æ³å¼å¥äºé¡å¤çåå½¢ç¶­åº¦ãä½¿ç¨åæåé«çè³æé²è¡çå¯¦é©è­æäºæåæ¹æ³çå¯¦ç¨é©ç¨æ§ã

##### **Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research**
2307.02131v5 by Toygar Tanyel, Serkan Ayvaz, Bilgin Keserci

The field of explainability in artificial intelligence (AI) has witnessed a
growing number of studies and increasing scholarly interest. However, the lack
of human-friendly and individual interpretations in explaining the outcomes of
machine learning algorithms has significantly hindered the acceptance of these
methods by clinicians in their research and clinical practice. To address this
issue, our study uses counterfactual explanations to explore the applicability
of "what if?" scenarios in medical research. Our aim is to expand our
understanding of magnetic resonance imaging (MRI) features used for diagnosing
pediatric posterior fossa brain tumors beyond existing boundaries. In our case
study, the proposed concept provides a novel way to examine alternative
decision-making scenarios that offer personalized and context-specific
insights, enabling the validation of predictions and clarification of
variations under diverse circumstances. Additionally, we explore the potential
use of counterfactuals for data augmentation and evaluate their feasibility as
an alternative approach in our medical research case. The results demonstrate
the promising potential of using counterfactual explanations to enhance
acceptance of AI-driven methods in clinical research.

æè¦ï¼å¨äººå·¥æºè½ (AI) çå¯è§£éæ§é åä¸­ï¼å·²ç¶çå°è¶ä¾è¶å¤çç ç©¶åå­¸è¡èè¶£ãç¶èï¼å¨è§£éæ©å¨å­¸ç¿æ¼ç®æ³ççµææç¼ºä¹äººæ§åååäººåçè©®éï¼éé¡¯èé»ç¤äºè¨åºé«çå¨ç ç©¶åè¨åºå¯¦åä¸­æ¥åéäºæ¹æ³ãçºäºè§£æ±ºéååé¡ï¼æåçç ç©¶ä½¿ç¨åäºå¯¦è§£éä¾æ¢è¨ãå¦æï¼ãæå¢å¨é«å­¸ç ç©¶ä¸­çé©ç¨æ§ãæåçç®æ¨æ¯æ´å±æåå°ç¨æ¼è¨ºæ·å°åå¾é¡±çª©è¦è«ç¤çç£å±æ¯æå (MRI) ç¹å¾µççè§£ï¼è¶è¶ç¾æççç·ãå¨æåçæ¡ä¾ç ç©¶ä¸­ï¼ææåºçæ¦å¿µæä¾äºä¸ç¨®æ°ç©çæ¹æ³ä¾æª¢è¦æ¿ä»£æ±ºç­æå¢ï¼æä¾åäººååç¹å®æ¼æå¢çè¦è§£ï¼å¾èè½å¤ é©è­é æ¸¬ä¸¦éæ¸å¨ä¸åææ³ä¸çå·®ç°ãæ­¤å¤ï¼æåæ¢è¨äºåäºå¯¦ç¨æ¼è³ææ´åçæ½å¨ç¨éï¼ä¸¦è©ä¼°å¶ä½çºæåé«å­¸ç ç©¶æ¡ä¾ä¸­æ¿ä»£æ¹æ³çå¯è¡æ§ãçµæè­æäºä½¿ç¨åäºå¯¦è§£éä¾å¢å¼·è¨åºç ç©¶ä¸­ AI é©åæ¹æ³çæ¥ååº¦çæ½åã

##### **AI and Non AI Assessments for Dementia**
2307.01210v1 by Mahboobeh Parsapoor, Hamed Ghodrati, Vincenzo Dentamaro, Christopher R. Madan, Ioulietta Lazarou, Spiros Nikolopoulos, Ioannis Kompatsiaris

Current progress in the artificial intelligence domain has led to the
development of various types of AI-powered dementia assessments, which can be
employed to identify patients at the early stage of dementia. It can
revolutionize the dementia care settings. It is essential that the medical
community be aware of various AI assessments and choose them considering their
degrees of validity, efficiency, practicality, reliability, and accuracy
concerning the early identification of patients with dementia (PwD). On the
other hand, AI developers should be informed about various non-AI assessments
as well as recently developed AI assessments. Thus, this paper, which can be
readable by both clinicians and AI engineers, fills the gap in the literature
in explaining the existing solutions for the recognition of dementia to
clinicians, as well as the techniques used and the most widespread dementia
datasets to AI engineers. It follows a review of papers on AI and non-AI
assessments for dementia to provide valuable information about various dementia
assessments for both the AI and medical communities. The discussion and
conclusion highlight the most prominent research directions and the maturity of
existing solutions.

æè¦ï¼ç®åäººå·¥æºè½é åçé²å±å°è´äºåç¨®é¡åçäººå·¥æºæ§é©åçå¤±æºçè©ä¼°çç¼å±ï¼å¯ç¨æ¼è­å¥èæ¼å¤±æºçæ©æéæ®µçæ£èãå®å¯ä»¥å¾¹åºæ¹è®å¤±æºçè­·çè¨­ç½®ãéè¦çæ¯ï¼é«ççè¦äºè§£åç¨®äººå·¥æºè½è©ä¼°ï¼ä¸¦æ ¹æå¶æææ§ãæçãå¯¦ç¨æ§ãå¯é æ§åæºç¢ºæ§ç¨åº¦ï¼èæ®é¸æå®åä¾æ©æè­å¥å¤±æºçæ£è (PwD)ãå¦ä¸æ¹é¢ï¼äººå·¥æºè½éç¼äººå¡ä¹æè©²äºè§£åç¨®éäººå·¥æºè½è©ä¼°ä»¥åæè¿éç¼çäººå·¥æºè½è©ä¼°ãå æ­¤ï¼éç¯è¨åºé«çåäººå·¥æºè½å·¥ç¨å¸«é½å¯ä»¥é±è®çè«æå¡«è£äºæç»ä¸­éæ¼åè¨åºé«çè§£éç¾æå¤±æºçè­å¥è§£æ±ºæ¹æ¡ä»¥ååäººå·¥æºè½å·¥ç¨å¸«è§£éæç¨æè¡åæå»£æ³çå¤±æºçæ¸æéçç©ºç½ãå®éµå¾ªå°äººå·¥æºè½åéäººå·¥æºè½å¤±æºçè©ä¼°è«æçåé¡§ï¼çºäººå·¥æºè½åé«ççæä¾æéåç¨®å¤±æºçè©ä¼°çå¯¶è²´ä¿¡æ¯ãè¨è«åçµè«éé»ä»ç´¹äºæçªåºçç ç©¶æ¹ååç¾æè§£æ±ºæ¹æ¡çæçåº¦ã

##### **Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation**
2306.07306v1 by Ruitao Xie, Jingbang Chen, Limai Jiang, Rui Xiao, Yi Pan, Yunpeng Cai

Explainability poses a major challenge to artificial intelligence (AI)
techniques. Current studies on explainable AI (XAI) lack the efficiency of
extracting global knowledge about the learning task, thus suffer deficiencies
such as imprecise saliency, context-aware absence and vague meaning. In this
paper, we propose the class association embedding (CAE) approach to address
these issues. We employ an encoder-decoder architecture to embed sample
features and separate them into class-related and individual-related style
vectors simultaneously. Recombining the individual-style code of a given sample
with the class-style code of another leads to a synthetic sample with preserved
individual characters but changed class assignment, following a cyclic
adversarial learning strategy. Class association embedding distills the global
class-related features of all instances into a unified domain with well
separation between classes. The transition rules between different classes can
be then extracted and further employed to individual instances. We then propose
an active XAI framework which manipulates the class-style vector of a certain
sample along guided paths towards the counter-classes, resulting in a series of
counter-example synthetic samples with identical individual characters.
Comparing these counterfactual samples with the original ones provides a
global, intuitive illustration to the nature of the classification tasks. We
adopt the framework on medical image classification tasks, which show that more
precise saliency maps with powerful context-aware representation can be
achieved compared with existing methods. Moreover, the disease pathology can be
directly visualized via traversing the paths in the class-style space.

æè¦ï¼<paragraph>å¯è§£éæ§å°äººå·¥æºæ§ (AI) æè¡æ§æä¸é éå¤§ææ°ãç¶åå°å¯è§£é AI (XAI) çç ç©¶ç¼ºä¹æåå­¸ç¿ä»»åæ´é«ç¥è­çæçï¼å æ­¤å­å¨ä¸ç²¾ç¢ºçé¡¯èæ§ãèæå¢ç¡éçç¼ºå¤±åå«ç³æç¾©ç­ç¼ºé·ãå¨æ¬æä¸­ï¼æåæåºé¡å¥éè¯åµå¥ (CAE) æ¹æ³ä¾è§£æ±ºéäºåé¡ãæåæ¡ç¨ç·¨ç¢¼å¨-è§£ç¢¼å¨æ¶æ§ä¾åµå¥æ¨£æ¬ç¹å¾µï¼ä¸¦åæå°å®ååçºé¡å¥ç¸éååé«ç¸éçæ¨£å¼åéãå°çµ¦å®æ¨£æ¬çåé«æ¨£å¼ä»£ç¢¼èå¦ä¸åæ¨£æ¬çé¡å¥æ¨£å¼ä»£ç¢¼éæ°çµåï¼æç¢çä¸åå·æä¿çåé«ç¹å¾µä½æ¹è®é¡å¥åéçåææ¨£æ¬ï¼éµå¾ªå¾ªç°å°æå­¸ç¿ç­ç¥ãé¡å¥éè¯åµå¥å°ææå¯¦ä¾çå¨å±é¡å¥ç¸éç¹å¾µæçå°ä¸åçµ±ä¸çé åä¸­ï¼ä¸¦å¨é¡å¥ä¹éæè¯å¥½çååãç¶å¾å¯ä»¥æåä¸åé¡å¥ä¹éçè½æè¦åï¼ä¸¦é²ä¸æ­¥æç¨æ¼åå¥å¯¦ä¾ãç¶å¾ï¼æåæåºä¸åä¸»å XAI æ¡æ¶ï¼å®æ²¿èå¼å°è·¯å¾æä½ç¹å®æ¨£æ¬çé¡å¥æ¨£å¼åéï¼æèåé¡å¥ç§»åï¼å¾èç¢çä¸ç³»åå·æç¸ååé«ç¹å¾µçåä¾åææ¨£æ¬ãå°éäºåäºå¯¦æ¨£æ¬èåå§æ¨£æ¬é²è¡æ¯è¼ï¼å¯ä»¥å°åé¡ä»»åçæ§è³ªæä¾å¨å±ãç´è§çèªªæãæåæ¡ç¨è©²æ¡æ¶é²è¡é«å­¸å½±ååé¡ä»»åï¼çµæè¡¨æï¼èç¾ææ¹æ³ç¸æ¯ï¼å¯ä»¥ç²å¾æ´ç²¾ç¢ºçé¡¯èæ§åï¼ä¸¦å·æå¼·å¤§çèæå¢ç¡éçè¡¨ç¤ºãæ­¤å¤ï¼ç¾çççå­¸å¯ä»¥ç´æ¥ééå¨é¡å¥æ¨£å¼ç©ºéä¸­éæ­·è·¯å¾ä¾é²è¡å¯è¦åã</paragraph>

##### **HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine**
2306.06029v1 by Rodrigo Agerri, IÃ±igo Alonso, Aitziber Atutxa, Ander Berrondo, Ainara Estarrona, Iker Garcia-Ferrero, Iakes Goenaga, Koldo Gojenola, Maite Oronoz, Igor Perez-Tejedor, German Rigau, Anar Yeginbergenova

Providing high quality explanations for AI predictions based on machine
learning is a challenging and complex task. To work well it requires, among
other factors: selecting a proper level of generality/specificity of the
explanation; considering assumptions about the familiarity of the explanation
beneficiary with the AI task under consideration; referring to specific
elements that have contributed to the decision; making use of additional
knowledge (e.g. expert evidence) which might not be part of the prediction
process; and providing evidence supporting negative hypothesis. Finally, the
system needs to formulate the explanation in a clearly interpretable, and
possibly convincing, way. Given these considerations, ANTIDOTE fosters an
integrated vision of explainable AI, where low-level characteristics of the
deep learning process are combined with higher level schemes proper of the
human argumentation capacity. ANTIDOTE will exploit cross-disciplinary
competences in deep learning and argumentation to support a broader and
innovative view of explainable AI, where the need for high-quality explanations
for clinical cases deliberation is critical. As a first result of the project,
we publish the Antidote CasiMedicos dataset to facilitate research on
explainable AI in general, and argumentation in the medical domain in
particular.

æè¦ï¼æä¾åºæ¼æ©å¨å­¸ç¿ç AI é æ¸¬çé«åè³ªèªªææ¯ä¸é å·æææ°æ§åè¤éæ§çä»»åãè¦é å©é²è¡ï¼å®éè¦å·åä¸åå ç´ ï¼é¸æé©ç¶çèªªææ®éæ§/ç¹æ®æ§å±¤ç´ï¼èéèªªæåçäººå°æèæ®ç AI ä»»åççæç¨åº¦åè¨­ï¼åç§ä¿ææ±ºç­çç¹å®åç´ ï¼å©ç¨å¯è½ä¸å±¬æ¼é æ¸¬ç¨åºçä¸é¨åçé¡å¤ç¥è­ï¼ä¾å¦å°å®¶è­æï¼ï¼ä¸¦æä¾æ¯æå¦å®åè¨­çè­æãæå¾ï¼ç³»çµ±éè¦ä»¥æ¸æ°å¯è§£éä¸å¯è½ä»¤äººä¿¡æçæ¹å¼å¶å®èªªæãåºæ¼éäºèéï¼ANTIDOTE ä¿æäºå¯è§£é AI çæ´åé¡æ¯ï¼å¶ä¸­æ·±åº¦å­¸ç¿ç¨åºçä½éç¹å¾µèäººé¡è«è­è½åçé«éæ¶æ§ç¸çµåãANTIDOTE å°å©ç¨æ·±åº¦å­¸ç¿èè«è­çè·¨é åè½åï¼ä¾æ¯æå¯è§£é AI æ´å»£æ³ä¸åµæ°çè§é»ï¼å¶ä¸­å°è¨åºæ¡ä¾å¯©è­°çé«åè³ªèªªæéæ±è³ééè¦ãä½çºè©²å°æ¡çç¬¬ä¸åææï¼æåç¼å¸äº Antidote CasiMedicos è³æéï¼ä»¥å©æ¼ä¸è¬å¯è§£é AI çç ç©¶ï¼ç¹å¥æ¯é«çé åçè«è­ã

##### **XInsight: Revealing Model Insights for GNNs with Flow-based Explanations**
2306.04791v1 by Eli Laird, Ayesh Madushanka, Elfi Kraka, Corey Clark

Progress in graph neural networks has grown rapidly in recent years, with
many new developments in drug discovery, medical diagnosis, and recommender
systems. While this progress is significant, many networks are `black boxes'
with little understanding of the `what' exactly the network is learning. Many
high-stakes applications, such as drug discovery, require human-intelligible
explanations from the models so that users can recognize errors and discover
new knowledge. Therefore, the development of explainable AI algorithms is
essential for us to reap the benefits of AI.
  We propose an explainability algorithm for GNNs called eXplainable Insight
(XInsight) that generates a distribution of model explanations using GFlowNets.
Since GFlowNets generate objects with probabilities proportional to a reward,
XInsight can generate a diverse set of explanations, compared to previous
methods that only learn the maximum reward sample. We demonstrate XInsight by
generating explanations for GNNs trained on two graph classification tasks:
classifying mutagenic compounds with the MUTAG dataset and classifying acyclic
graphs with a synthetic dataset that we have open-sourced. We show the utility
of XInsight's explanations by analyzing the generated compounds using QSAR
modeling, and we find that XInsight generates compounds that cluster by
lipophilicity, a known correlate of mutagenicity. Our results show that
XInsight generates a distribution of explanations that uncovers the underlying
relationships demonstrated by the model. They also highlight the importance of
generating a diverse set of explanations, as it enables us to discover hidden
relationships in the model and provides valuable guidance for further analysis.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼åç¥ç¶ç¶²è·¯çé²å±è¿éï¼å¨è¥ç©ç¼ç¾ãé«çè¨ºæ·åæ¨è¦ç³»çµ±æ¹é¢é½æè¨±å¤æ°ç¼å±ãéç¶éäºé²å±å¾éè¦ï¼ä½è¨±å¤ç¶²è·¯é½æ¯ãé»çå­ãï¼å°æ¼ç¶²è·¯å°åºå¨å­¸ç¿ãä»éº¼ãäºè§£çå°ãè¨±å¤é«é¢¨éªæç¨ï¼ä¾å¦è¥ç©ç¼ç¾ï¼éè¦æ¨¡åæä¾äººé¡å¯ä»¥çè§£çè§£éï¼ä»¥ä¾¿ä½¿ç¨èå¯ä»¥è¾¨è­é¯èª¤ä¸¦ç¼ç¾æ°ç¥è­ãå æ­¤ï¼å¯è§£é AI æ¼ç®æ³çéç¼å°æ¼æåç²å AI çå¥½èè³ééè¦ã
æåæåºäºä¸ç¨®ç¨±çº eXplainable Insight (XInsight) ç GNN å¯è§£éæ§æ¼ç®æ³ï¼å®ä½¿ç¨ GFlowNets ç¢çæ¨¡åè§£éåä½ãç±æ¼ GFlowNets æç¢çæ©çèçåµææ­£æ¯çç©ä»¶ï¼å æ­¤èåååå­¸ç¿æå¤§çåµç¯ä¾çæ¹æ³ç¸æ¯ï¼XInsight å¯ä»¥ç¢çå¤æ¨£åçè§£ééåãæåééçºå¨å©ååå½¢åé¡ä»»åä¸­è¨ç·´ç GNN ç¢çè§£éä¾å±ç¤º XInsightï¼ä½¿ç¨ MUTAG è³æéå°è´çªè®ååç©é²è¡åé¡ï¼ä¸¦ä½¿ç¨æåå·²éæ¾åå§ç¢¼çåæè³æéå°éç°çåå½¢é²è¡åé¡ãæåééä½¿ç¨ QSAR å»ºæ¨¡åæç¢ççååç©ä¾å±ç¤º XInsight è§£éçæç¨ï¼æåç¼ç¾ XInsight æç¢çæè¦ªèæ§ï¼å·²ç¥çè´çªè®ç¸éæ§ï¼åç¾¤çååç©ãæåççµæé¡¯ç¤º XInsight æç¢çä¸åè§£éåä½ï¼æ­ç¤ºæ¨¡åæå±ç¤ºçåºå±¤éä¿ãå®åä¹å¼·èª¿ç¢çå¤æ¨£åè§£ééåçéè¦æ§ï¼å çºå®ä½¿æåè½å¤ ç¼ç¾æ¨¡åä¸­çé±èéä¿ï¼ä¸¦çºé²ä¸æ­¥åææä¾æå¹å¼çæå°ã</paragraph>

##### **Explainable AI using expressive Boolean formulas**
2306.03976v1 by Gili Rosenberg, J. Kyle Brubaker, Martin J. A. Schuetz, Grant Salton, Zhihuai Zhu, Elton Yechao Zhu, Serdar KadÄ±oÄlu, Sima E. Borujeni, Helmut G. Katzgraber

We propose and implement an interpretable machine learning classification
model for Explainable AI (XAI) based on expressive Boolean formulas. Potential
applications include credit scoring and diagnosis of medical conditions. The
Boolean formula defines a rule with tunable complexity (or interpretability),
according to which input data are classified. Such a formula can include any
operator that can be applied to one or more Boolean variables, thus providing
higher expressivity compared to more rigid rule-based and tree-based
approaches. The classifier is trained using native local optimization
techniques, efficiently searching the space of feasible formulas. Shallow rules
can be determined by fast Integer Linear Programming (ILP) or Quadratic
Unconstrained Binary Optimization (QUBO) solvers, potentially powered by
special purpose hardware or quantum devices. We combine the expressivity and
efficiency of the native local optimizer with the fast operation of these
devices by executing non-local moves that optimize over subtrees of the full
Boolean formula. We provide extensive numerical benchmarking results featuring
several baselines on well-known public datasets. Based on the results, we find
that the native local rule classifier is generally competitive with the other
classifiers. The addition of non-local moves achieves similar results with
fewer iterations, and therefore using specialized or quantum hardware could
lead to a speedup by fast proposal of non-local moves.

æè¦ï¼æåæåºä¸¦å¯¦ä½ä¸åå¯è§£éæ©å¨å­¸ç¿åé¡æ¨¡åï¼ç¨æ¼åºæ¼è¡¨éå¼å¸æå¬å¼çå¯è§£é AI (XAI)ãæ½å¨æç¨åæ¬ä¿¡ç¨è©ååé«ççæ³è¨ºæ·ãå¸æå¬å¼å®ç¾©äºä¸åå·æå¯èª¿æ´è¤éæ§ï¼æå¯è§£éæ§ï¼çè¦åï¼æ ¹æè©²è¦åå°è¼¸å¥æ¸æé²è¡åé¡ãéæ¨£çå¬å¼å¯ä»¥åå«ä»»ä½å¯æç¨æ¼ä¸åæå¤åå¸æè®æ¸çéç®å­ï¼å¾èèæ´å´æ ¼çåºæ¼è¦åååºæ¼æ¨¹çæ¹æ³ç¸æ¯ï¼æä¾æ´é«çè¡¨éè½åãåé¡å¨ä½¿ç¨åçå±é¨æä½³åæè¡é²è¡è¨ç·´ï¼ææå°æç´¢å¯è¡å¬å¼çç©ºéãæ·ºå±¤è¦åå¯ä»¥ç¨å¿«éçæ´æ¸ç·æ§è¦å (ILP) æäºæ¬¡ç¡ç´æäºåæä½³å (QUBO) æ±è§£å¨ä¾ç¢ºå®ï¼éäºæ±è§£å¨å¯è½ç±ç¹æ®ç¨éçç¡¬é«æéå­è£ç½®æä¾æ¯æ´ãæåå°åçå±é¨æä½³åå¨çè¡¨éè½ååæçèéäºè£ç½®çå¿«ééç®ç¸çµåï¼ééå·è¡éå±é¨ç§»åä¾æä½³åå®æ´å¸æå¬å¼çå­æ¨¹ãæåæä¾å»£æ³çæ¸å¼åºæºæ¸¬è©¦çµæï¼å¶ä¸­åå«å¨ç¾æå¨ç¥çå¬å±è³æéä¸ä½¿ç¨å¤ååºç·ãæ ¹æçµæï¼æåç¼ç¾åçå±é¨è¦ååé¡å¨éå¸¸èå¶ä»åé¡å¨å·æç«¶ç­åãå å¥éå±é¨ç§»åä»¥è¼å°çåè¦éç®æ¬¡æ¸éæé¡ä¼¼ççµæï¼å æ­¤ä½¿ç¨å°ç¨æéå­ç¡¬é«å¯è½æééå¿«éæåºéå±é¨ç§»åä¾å éã

##### **Utterance Classification with Logical Neural Network: Explainable AI for Mental Disorder Diagnosis**
2306.03902v1 by Yeldar Toleubay, Don Joven Agravante, Daiki Kimura, Baihan Lin, Djallel Bouneffouf, Michiaki Tatsubori

In response to the global challenge of mental health problems, we proposes a
Logical Neural Network (LNN) based Neuro-Symbolic AI method for the diagnosis
of mental disorders. Due to the lack of effective therapy coverage for mental
disorders, there is a need for an AI solution that can assist therapists with
the diagnosis. However, current Neural Network models lack explainability and
may not be trusted by therapists. The LNN is a Recurrent Neural Network
architecture that combines the learning capabilities of neural networks with
the reasoning capabilities of classical logic-based AI. The proposed system
uses input predicates from clinical interviews to output a mental disorder
class, and different predicate pruning techniques are used to achieve
scalability and higher scores. In addition, we provide an insight extraction
method to aid therapists with their diagnosis. The proposed system addresses
the lack of explainability of current Neural Network models and provides a more
trustworthy solution for mental disorder diagnosis.

æè¦ï¼çºäºè§£æ±ºå¿çå¥åº·åé¡çå¨çææ°ï¼æåæåºä¸ååºæ¼éè¼¯ç¥ç¶ç¶²è·¯ (LNN) çç¥ç¶ç¬¦è AI æ¹æ³ä¾è¨ºæ·å¿çç¾çãç±æ¼ç¼ºä¹ææçå¿çç¾çæ²»çæ¶µèç¯åï¼å æ­¤éè¦ä¸ç¨® AI è§£æ±ºæ¹æ¡ä¾åå©æ²»çå¸«é²è¡è¨ºæ·ãç¶èï¼ç®åçé¡ç¥ç¶ç¶²è·¯æ¨¡åç¼ºä¹å¯è§£éæ§ï¼æ²»çå¸«å¯è½ç¡æ³ä¿¡ä»»å®åãLNN æ¯ä¸ç¨®éè¿´ç¥ç¶ç¶²è·¯æ¶æ§ï¼å®çµåäºç¥ç¶ç¶²è·¯çå­¸ç¿è½åååºæ¼ç¶å¸éè¼¯ç AI çæ¨çè½åãææåºçç³»çµ±ä½¿ç¨ä¾èªè¨åºè¨ªè«çè¼¸å¥è¬è©ä¾è¼¸åºå¿çç¾çé¡å¥ï¼ä¸¦ä½¿ç¨ä¸åçè¬è©åªææè¡ä¾å¯¦ç¾å¯æ´åæ§åæ´é«çåæ¸ãæ­¤å¤ï¼æåæä¾äºä¸åè¦è§£æåæ¹æ³ä¾åå©æ²»çå¸«é²è¡è¨ºæ·ãææåºçç³»çµ±è§£æ±ºäºç¶åé¡ç¥ç¶ç¶²è·¯æ¨¡åç¼ºä¹å¯è§£éæ§çåé¡ï¼ä¸¦çºå¿çç¾çè¨ºæ·æä¾äºæ´å¼å¾ä¿¡è³´çè§£æ±ºæ¹æ¡ã

##### **XAI Renaissance: Redefining Interpretability in Medical Diagnostic Models**
2306.01668v1 by Sujith K Mandala

As machine learning models become increasingly prevalent in medical
diagnostics, the need for interpretability and transparency becomes paramount.
The XAI Renaissance signifies a significant shift in the field, aiming to
redefine the interpretability of medical diagnostic models. This paper explores
the innovative approaches and methodologies within the realm of Explainable AI
(XAI) that are revolutionizing the interpretability of medical diagnostic
models. By shedding light on the underlying decision-making process, XAI
techniques empower healthcare professionals to understand, trust, and
effectively utilize these models for accurate and reliable medical diagnoses.
This review highlights the key advancements in XAI for medical diagnostics and
their potential to transform the healthcare landscape, ultimately improving
patient outcomes and fostering trust in AI-driven diagnostic systems.

æè¦ï¼é¨èæ©å¨å­¸ç¿æ¨¡åå¨é«çè¨ºæ·ä¸­è¶ä¾è¶æ®éï¼å¯è§£éæ§åéæåº¦çéæ±è®å¾è³ééè¦ãXAI å¾©èæ¨èªèè©²é åçéå¤§è½è®ï¼æ¨å¨éæ°å®ç¾©é«çè¨ºæ·æ¨¡åçå¯è§£éæ§ãæ¬ææ¢è¨äºå¯è§£é AI (XAI) é åå§çåµæ°æ¹æ³åæ¹æ³è«ï¼éäºæ¹æ³åæ¹æ³è«æ­£å¨é©æ°é«çè¨ºæ·æ¨¡åçå¯è§£éæ§ãééé¡æåºç¤æ±ºç­å¶å®éç¨ï¼XAI æè¡ä½¿é«çä¿å¥å°æ¥­äººå¡è½å¤ çè§£ãä¿¡ä»»ä¸¦ææå°å©ç¨éäºæ¨¡åé²è¡æºç¢ºä¸å¯é çé«çè¨ºæ·ãæ¬ç¶è¿°éé»ä»ç´¹äº XAI å¨é«çè¨ºæ·æ¹é¢çééµé²å±åå¶è½è®é«çä¿å¥é åçæ½åï¼æçµæ¹åæ£èçæ²»çææä¸¦å¹é¤å° AI é©åçè¨ºæ·ç³»çµ±çä¿¡ä»»ã

##### **A Novel real-time arrhythmia detection model using YOLOv8**
2305.16727v3 by Guang Jun Nicholas Ang, Aritejh Kr Goil, Henryk Chan, Jieyi Jeric Lew, Xin Chun Lee, Raihan Bin Ahmad Mustaffa, Timotius Jason, Ze Ting Woon, Bingquan Shen

In a landscape characterized by heightened connectivity and mobility, coupled
with a surge in cardiovascular ailments, the imperative to curtail healthcare
expenses through remote monitoring of cardiovascular health has become more
pronounced. The accurate detection and classification of cardiac arrhythmias
are pivotal for diagnosing individuals with heart irregularities. This study
underscores the feasibility of employing electrocardiograms (ECG) measurements
in the home environment for real-time arrhythmia detection. Presenting a fresh
application for arrhythmia detection, this paper leverages the cutting-edge
You-Only-Look-Once (YOLO)v8 algorithm to categorize single-lead ECG signals. We
introduce a novel loss-modified YOLOv8 model, fine-tuned on the MIT-BIH
arrhythmia dataset, enabling real-time continuous monitoring. The obtained
results substantiate the efficacy of our approach, with the model attaining an
average accuracy of 99.5% and 0.992 mAP@50, and a rapid detection time of 0.002
seconds on an NVIDIA Tesla V100. Our investigation exemplifies the potential of
real-time arrhythmia detection, enabling users to visually interpret the model
output within the comfort of their homes. Furthermore, this study lays the
groundwork for an extension into a real-time explainable AI (XAI) model capable
of deployment in the healthcare sector, thereby significantly advancing the
realm of healthcare solutions.

æè¦ï¼<paragraph>å¨ä»¥é«åº¦é£æ¥æ§åæµåæ§çºç¹å¾µçç°å¢ä¸­ï¼å ä¸å¿è¡ç®¡ç¾ççæ¿å¢ï¼ééé ç¨ç£æ§å¿è¡ç®¡å¥åº·ä¾åæ¸é«çä¿å¥æ¯åºçå¿è¦æ§è®å¾æ´å æé¡¯ãæºç¢ºæª¢æ¸¬ååé¡å¿å¾ä¸æ´å°æ¼è¨ºæ·æ£æå¿èä¸è¦åçäººè³ééè¦ãæ¬ç ç©¶å¼·èª¿äºå¨å®¶ä¸­ä½¿ç¨å¿é»å (ECG) æ¸¬éé²è¡å¯¦æå¿å¾ä¸æ´æª¢æ¸¬çå¯è¡æ§ãæ¬ææåºäºä¸ç¨®æ°çå¿å¾ä¸æ´æª¢æ¸¬æç¨ï¼å©ç¨å°ç«¯ç You-Only-Look-Once (YOLO)v8 æ¼ç®æ³å°å®å°è¯ ECG è¨èé²è¡åé¡ãæåå¼å¥äºä¸åæ°ç©çæå¤±ä¿®æ¹ YOLOv8 æ¨¡åï¼ä¸¦éå° MIT-BIH å¿å¾ä¸æ´è³æéé²è¡äºå¾®èª¿ï¼å¾èå¯¦ç¾äºå¯¦æçæçºç£æ§ãç²å¾ççµæè­å¯¦äºæåæ¹æ³çæææ§ï¼è©²æ¨¡åå¨ NVIDIA Tesla V100 ä¸éå°äº 99.5% çå¹³åæºç¢ºåº¦å 0.992 mAP@50ï¼ä»¥å 0.002 ç§çå¿«éæª¢æ¸¬æéãæåçç ç©¶èªªæäºå¯¦æå¿å¾ä¸æ´æª¢æ¸¬çæ½åï¼ä½¿ç¨æ¶è½å¤ å¨å®¶ä¸­èé©å°è¦è¦ºåè§£è®æ¨¡åè¼¸åºãæ­¤å¤ï¼æ¬ç ç©¶çºæ´å±å°å¯¦æå¯è§£é AI (XAI) æ¨¡åå¥ å®äºåºç¤ï¼è©²æ¨¡åè½å¤ é¨ç½²å¨é«çä¿å¥é åï¼å¾èé¡¯èæ¨é²é«çä¿å¥è§£æ±ºæ¹æ¡çé åã</paragraph>

##### **Breast Cancer Segmentation using Attention-based Convolutional Network and Explainable AI**
2305.14389v2 by Jai Vardhan, Taraka Satya Krishna Teja Malisetti

Breast cancer (BC) remains a significant health threat, with no long-term
cure currently available. Early detection is crucial, yet mammography
interpretation is hindered by high false positives and negatives. With BC
incidence projected to surpass lung cancer, improving early detection methods
is vital. Thermography, using high-resolution infrared cameras, offers promise,
especially when combined with artificial intelligence (AI). This work presents
an attention-based convolutional neural network for segmentation, providing
increased speed and precision in BC detection and classification. The system
enhances images and performs cancer segmentation with explainable AI. We
propose a transformer-attention-based convolutional architecture (UNet) for
fault identification and employ Gradient-weighted Class Activation Mapping
(Grad-CAM) to analyze areas of bias and weakness in the UNet architecture with
IRT images. The superiority of our proposed framework is confirmed when
compared with existing deep learning frameworks.

æè¦ï¼ä¹³çï¼BCï¼ä»ç¶æ¯ä¸åéå¤§çå¥åº·å¨èï¼ç®åå°ç¡é·ææ²»ççæ¹æ³ãæ©æç¼ç¾è³ééè¦ï¼ä½ä¹³æ¿æå½±çå¤è®å»åå°é«åé½æ§ååé°æ§çé»ç¤ãç±æ¼ä¹³ççç¼ççé è¨å°è¶éèºçï¼å æ­¤æ¹åæ©ææª¢æ¸¬æ¹æ³è³ééè¦ãç±åæå½±ä½¿ç¨é«è§£æåº¦ç´å¤ç·ç¸æ©ï¼ç¹å¥æ¯å¨èäººå·¥æºæ§ï¼AIï¼çµåä½¿ç¨æï¼æä¾äºå¸æãéé å·¥ä½æåºäºä¸ååºæ¼æ³¨æåçå·ç©ç¥ç¶ç¶²è·¯ç¨æ¼åå²ï¼å¨ä¹³çæª¢æ¸¬ååé¡ä¸­æä¾äºæ´é«çéåº¦åç²¾åº¦ãè©²ç³»çµ±å¢å¼·å½±åä¸¦å·è¡å¯è§£éç AI ççåå²ãæåæåºäºä¸ååºæ¼Transformeræ³¨æåçå·ç©æ¶æ§ï¼UNetï¼ç¨æ¼æéè­å¥ï¼ä¸¦ä½¿ç¨æ¢¯åº¦å æ¬é¡æ¿æ´»æ å°ï¼Grad-CAMï¼ä¾åæ UNet æ¶æ§ä¸­åè¦åå¼±é»çååï¼ä½¿ç¨ IRT å½±åãèç¾æçæ·±åº¦å­¸ç¿æ¡æ¶ç¸æ¯ï¼æåæåºçæ¡æ¶çåªè¶æ§å¾å°è­å¯¦ã

##### **What Symptoms and How Long? An Interpretable AI Approach for Depression Detection in Social Media**
2305.13127v2 by Junwei Kuang, Jiaheng Xie, Zhijun Yan

Depression is the most prevalent and serious mental illness, which induces
grave financial and societal ramifications. Depression detection is key for
early intervention to mitigate those consequences. Such a high-stake decision
inherently necessitates interpretability. Although a few depression detection
studies attempt to explain the decision based on the importance score or
attention weights, these explanations misalign with the clinical depression
diagnosis criterion that is based on depressive symptoms. To fill this gap, we
follow the computational design science paradigm to develop a novel Multi-Scale
Temporal Prototype Network (MSTPNet). MSTPNet innovatively detects and
interprets depressive symptoms as well as how long they last. Extensive
empirical analyses using a large-scale dataset show that MSTPNet outperforms
state-of-the-art depression detection methods with an F1-score of 0.851. This
result also reveals new symptoms that are unnoted in the survey approach, such
as sharing admiration for a different life. We further conduct a user study to
demonstrate its superiority over the benchmarks in interpretability. This study
contributes to IS literature with a novel interpretable deep learning model for
depression detection in social media. In practice, our proposed method can be
implemented in social media platforms to provide personalized online resources
for detected depressed patients.

æè¦ï¼æé¬±çæ¯ææ®éä¸å´éçç²¾ç¥ç¾çï¼æé æå´éçè²¡ååç¤¾æå¾æãæé¬±ççåµæ¸¬å°æ¼æ©æä»å¥ä»¥æ¸è¼éäºå¾æè³ééè¦ãå¦æ­¤éå¤§çæ±ºå®æ¬è³ªä¸éè¦å¯è§£éæ§ãåç®¡ä¸äºæé¬±çåµæ¸¬ç ç©¶åè©¦æ ¹æéè¦æ§åæ¸ææ³¨æåæ¬éä¾è§£ééåæ±ºå®ï¼ä½éäºè§£éèåºæ¼æé¬±çççè¨åºæé¬±çè¨ºæ·æ¨æºä¸ä¸è´ãçºäºå¡«è£éåç¼ºå£ï¼æåéµå¾ªè¨ç®è¨­è¨ç§å­¸ç¯ä¾ä¾éç¼ä¸åæ°ç©çå¤å°ºåº¦æéååç¶²è·¯ (MSTPNet)ãMSTPNet åµæ°å°åµæ¸¬ä¸¦è§£éæé¬±ççä»¥åå®åæçºå¤ä¹ãä½¿ç¨å¤§è¦æ¨¡è³æéé²è¡çå»£æ³å¯¦è­åæé¡¯ç¤ºï¼MSTPNet ä»¥ 0.851 ç F1 åæ¸åªæ¼æåé²çæé¬±çåµæ¸¬æ¹æ³ãæ­¤çµæéæ­ç¤ºäºèª¿æ¥æ¹æ³ä¸­æªæ³¨æå°çæ°ççï¼ä¾å¦åäº«å°ä¸åçæ´»çæ¬½ä½©ãæåé²ä¸æ­¥é²è¡ä½¿ç¨èç ç©¶ï¼ä»¥è­æå¶å¨å¯è§£éæ§æ¹é¢åªæ¼åºæºãæ¬ç ç©¶ä»¥ä¸åæ°ç©çå¯è§£éæ·±åº¦å­¸ç¿æ¨¡åçºæé¬±çåµæ¸¬å¨ç¤¾ç¾¤åªé«ä¸­ç IS æç»ååºè²¢ç»ãå¨å¯¦åä¸ï¼æåæåºçæ¹æ³å¯ä»¥å¯¦ä½å¨ç¤¾ç¾¤åªé«å¹³å°ä¸­ï¼ä»¥æä¾åäººåçç·ä¸è³æºçµ¦è¢«åµæ¸¬åºæé¬±ççæ£èã

##### **Echoes of Biases: How Stigmatizing Language Affects AI Performance**
2305.10201v4 by Yizhi Liu, Weiguang Wang, Guodong Gordon Gao, Ritu Agarwal

Electronic health records (EHRs) serve as an essential data source for the
envisioned artificial intelligence (AI)-driven transformation in healthcare.
However, clinician biases reflected in EHR notes can lead to AI models
inheriting and amplifying these biases, perpetuating health disparities. This
study investigates the impact of stigmatizing language (SL) in EHR notes on
mortality prediction using a Transformer-based deep learning model and
explainable AI (XAI) techniques. Our findings demonstrate that SL written by
clinicians adversely affects AI performance, particularly so for black
patients, highlighting SL as a source of racial disparity in AI model
development. To explore an operationally efficient way to mitigate SL's impact,
we investigate patterns in the generation of SL through a clinicians'
collaborative network, identifying central clinicians as having a stronger
impact on racial disparity in the AI model. We find that removing SL written by
central clinicians is a more efficient bias reduction strategy than eliminating
all SL in the entire corpus of data. This study provides actionable insights
for responsible AI development and contributes to understanding clinician
behavior and EHR note writing in healthcare.

æè¦ï¼é»å­å¥åº·ç´é (EHR) ä½çºé æ³ä¸­ç±äººå·¥æºæ§ (AI) æ¨åçé«çä¿å¥è½åçéè¦è³æä¾æºãç¶èï¼åæ å¨ EHR åè¨»ä¸­çè¨åºåè¦å¯è½å°è´ AI æ¨¡åç¹¼æ¿ä¸¦æ´å¤§éäºåè¦ï¼é²èé æå¥åº·å·®ç°ãæ¬ç ç©¶æ¢è¨ EHR åè¨»ä¸­æ±ååèªè¨ (SL) å°ä½¿ç¨åºæ¼ Transformer çæ·±åº¦å­¸ç¿æ¨¡ååå¯è§£é AI (XAI) æè¡é æ¸¬æ­»äº¡ççå½±é¿ãæåçç ç©¶çµæè¡¨æï¼ç±è¨åºé«çæ°å¯«ç SL æå° AI æè½ç¢çä¸å©å½±é¿ï¼ç¹å¥æ¯å°é»äººæ£èèè¨ï¼çªé¡¯ SL æ¯ AI æ¨¡åéç¼ä¸­ç¨®æå·®ç°çä¾æºãçºäºæ¢ç´¢ä¸ç¨®éä½ä¸ææççæ¹æ³ä¾æ¸è¼ SL çå½±é¿ï¼æåééè¨åºé«ççåä½ç¶²è·¯æ¢è¨ SL ç¢ççæ¨¡å¼ï¼ä¸¦æ¾åºæ ¸å¿è¨åºé«çå° AI æ¨¡åä¸­çç¨®æå·®ç°æè¼å¤§çå½±é¿ãæåç¼ç¾ï¼ç§»é¤ç±æ ¸å¿è¨åºé«çæ°å¯«ç SL æ¯æ¯æ¶é¤è³æéä¸­ææ SL æ´ææççåè¦æ¸å°ç­ç¥ãæ¬ç ç©¶æä¾å¯è¡çè¦è§£ï¼ç¨æ¼è² è²¬ä»»ç AI éç¼ï¼ä¸¦æå©æ¼äºè§£è¨åºé«çè¡çºåé«çä¿å¥ä¸­ç EHR åè¨»æ°å¯«ã

##### **Explaining the ghosts: Feminist intersectional XAI and cartography as methods to account for invisible labour**
2305.03376v1 by Goda Klumbyte, Hannah Piehl, Claude Draude

Contemporary automation through AI entails a substantial amount of
behind-the-scenes human labour, which is often both invisibilised and
underpaid. Since invisible labour, including labelling and maintenance work, is
an integral part of contemporary AI systems, it remains important to sensitise
users to its role. We suggest that this could be done through explainable AI
(XAI) design, particularly feminist intersectional XAI. We propose the method
of cartography, which stems from feminist intersectional research, to draw out
a systemic perspective of AI and include dimensions of AI that pertain to
invisible labour.

æè¦ï¼ç¶ä»£éé AI çèªååéè¦å¤§éçå¹å¾äººåï¼ééå¸¸æ¢ä¸å¯è¦ä¸èªè³éä½ãç±æ¼ä¸å¯è¦çååï¼åæ¬æ¨ç±¤åç¶­è­·å·¥ä½ï¼æ¯ç¶ä»£ AI ç³»çµ±ççµæé¨åï¼å æ­¤è®ä½¿ç¨èäºè§£å¶è§è²ä»ç¶å¾éè¦ãæåå»ºè­°éå¯ä»¥ééå¯è§£éç AIï¼XAIï¼è¨­è¨ä¾å®æï¼ç¹å¥æ¯å¥³æ§ä¸»ç¾©äº¤åç XAIãæåæåºæºèªå¥³æ§ä¸»ç¾©äº¤åç ç©¶çè£½åæ¹æ³ï¼ä»¥æåº AI çç³»çµ±è§é»ï¼ä¸¦ç´å¥èä¸å¯è¦ååç¸éç AI ç¶­åº¦ã


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-08**|**DIVE: Subgraph Disagreement for Graph Out-of-Distribution Generalization**|Xin Sun et.al.|[2408.04400v1](http://arxiv.org/abs/2408.04400v1)|null|
|**2024-08-08**|**MM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models**|Haoxuan Li et.al.|[2408.04388v1](http://arxiv.org/abs/2408.04388v1)|[link](https://github.com/luminosityx/mm-forecast)|
|**2024-08-08**|**Judgment2vec: Apply Graph Analytics to Searching and Recommendation of Similar Judgments**|Hsuan-Lei Shao et.al.|[2408.04382v1](http://arxiv.org/abs/2408.04382v1)|null|
|**2024-08-08**|**wav2graph: A Framework for Supervised Learning Knowledge Graph from Speech**|Khai Le-Duc et.al.|[2408.04174v1](http://arxiv.org/abs/2408.04174v1)|null|
|**2024-08-07**|**ArtVLM: Attribute Recognition Through Vision-Based Prefix Language Modeling**|William Y. Zhu et.al.|[2408.04102v1](http://arxiv.org/abs/2408.04102v1)|null|
|**2024-08-07**|**CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**|Xiangyan Liu et.al.|[2408.03910v1](http://arxiv.org/abs/2408.03910v1)|[link](https://github.com/modelscope/modelscope-agent)|
|**2024-08-07**|**PAGED: A Benchmark for Procedural Graphs Extraction from Documents**|Weihong Du et.al.|[2408.03630v2](http://arxiv.org/abs/2408.03630v2)|null|
|**2024-08-07**|**Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks**|Zaijing Li et.al.|[2408.03615v1](http://arxiv.org/abs/2408.03615v1)|null|
|**2024-08-07**|**Exploring the extent of similarities in software failures across industries using LLMs**|Martin Detloff et.al.|[2408.03528v2](http://arxiv.org/abs/2408.03528v2)|null|
|**2024-08-06**|**Enhancing Complex Causality Extraction via Improved Subtask Interaction and Knowledge Fusion**|Jinglong Gao et.al.|[2408.03079v1](http://arxiv.org/abs/2408.03079v1)|null|
|**2024-08-06**|**Fact Finder -- Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs**|Daniel Steinigen et.al.|[2408.03010v1](http://arxiv.org/abs/2408.03010v1)|null|
|**2024-08-06**|**Leveraging Inter-Chunk Interactions for Enhanced Retrieval in Large Language Model-Based Question Answering**|Tiezheng Guo et.al.|[2408.02907v1](http://arxiv.org/abs/2408.02907v1)|null|
|**2024-08-05**|**A Few-Shot Approach for Relation Extraction Domain Adaptation using Large Language Models**|Vanni Zavarella et.al.|[2408.02377v1](http://arxiv.org/abs/2408.02377v1)|null|
|**2024-08-05**|**Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction**|Albert Sawczyn et.al.|[2408.02337v1](http://arxiv.org/abs/2408.02337v1)|null|
|**2024-08-04**|**MedSyn: LLM-based Synthetic Medical Text Generation Framework**|Gleb Kumichev et.al.|[2408.02056v1](http://arxiv.org/abs/2408.02056v1)|null|
|**2024-08-04**|**DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models**|Bowen Wang et.al.|[2408.01933v2](http://arxiv.org/abs/2408.01933v2)|null|
|**2024-08-03**|**Integrating Large Language Models and Knowledge Graphs for Extraction and Validation of Textual Test Data**|Antonio De Santis et.al.|[2408.01700v1](http://arxiv.org/abs/2408.01700v1)|null|
|**2024-08-02**|**DERA: Dense Entity Retrieval for Entity Alignment in Knowledge Graphs**|Zhichun Wang et.al.|[2408.01154v1](http://arxiv.org/abs/2408.01154v1)|null|
|**2024-08-02**|**Bridging Information Gaps in Dialogues With Grounded Exchanges Using Knowledge Graphs**|Phillip Schneider et.al.|[2408.01088v1](http://arxiv.org/abs/2408.01088v1)|null|
|**2024-08-02**|**Automatic Extraction of Relationships among Motivations, Emotions and Actions from Natural Language Texts**|Fei Yang et.al.|[2408.00966v1](http://arxiv.org/abs/2408.00966v1)|null|
|**2024-08-01**|**DisTrack: a new Tool for Semi-automatic Misinformation Tracking in Online Social Networks**|Guillermo Villar-RodrÃ­guez et.al.|[2408.00633v1](http://arxiv.org/abs/2408.00633v1)|null|
|**2024-08-01**|**On the Limitations and Prospects of Machine Unlearning for Generative AI**|Shiji Zhou et.al.|[2408.00376v1](http://arxiv.org/abs/2408.00376v1)|null|
|**2024-08-01**|**Multi-Modal Parameter-Efficient Fine-tuning via Graph Neural Network**|Bin Cheng et.al.|[2408.00290v1](http://arxiv.org/abs/2408.00290v1)|null|
|**2024-07-31**|**CEAR: Automatic construction of a knowledge graph of chemical entities and roles from scientific literature**|Stefan Langer et.al.|[2407.21708v1](http://arxiv.org/abs/2407.21708v1)|null|
|**2024-07-31**|**eSPARQL: Representing and Reconciling Agnostic and Atheistic Beliefs in RDF-star Knowledge Graphs**|Xinyi Pan et.al.|[2407.21483v3](http://arxiv.org/abs/2407.21483v3)|null|
|**2024-07-31**|**Navigating Beyond Instructions: Vision-and-Language Navigation in Obstructed Environments**|Haodong Hong et.al.|[2407.21452v1](http://arxiv.org/abs/2407.21452v1)|null|
|**2024-07-31**|**Tree-of-Traversals: A Zero-Shot Reasoning Algorithm for Augmenting Black-box Language Models with Knowledge Graphs**|Elan Markowitz et.al.|[2407.21358v1](http://arxiv.org/abs/2407.21358v1)|null|
|**2024-07-31**|**SimpleLLM4AD: An End-to-End Vision-Language Model with Graph Visual Question Answering for Autonomous Driving**|Peiru Zheng et.al.|[2407.21293v1](http://arxiv.org/abs/2407.21293v1)|null|
|**2024-07-30**|**Be aware of overfitting by hyperparameter optimization!**|Igor V. Tetko et.al.|[2407.20786v1](http://arxiv.org/abs/2407.20786v1)|null|
|**2024-07-30**|**Harvesting Textual and Structured Data from the HAL Publication Repository**|Francis Kulumba et.al.|[2407.20595v1](http://arxiv.org/abs/2407.20595v1)|null|
|**2024-07-30**|**CLR-Fact: Evaluating the Complex Logical Reasoning Capability of Large Language Models over Factual Knowledge**|Tianshi Zheng et.al.|[2407.20564v1](http://arxiv.org/abs/2407.20564v1)|null|
|**2024-07-30**|**Prompt2DeModel: Declarative Neuro-Symbolic Modeling with Natural Language**|Hossein Rajaby Faghihi et.al.|[2407.20513v1](http://arxiv.org/abs/2407.20513v1)|null|
|**2024-07-29**|**What if Red Can Talk? Dynamic Dialogue Generation Using Large Language Models**|Navapat Nananukul et.al.|[2407.20382v1](http://arxiv.org/abs/2407.20382v1)|null|
|**2024-07-29**|**MindSearch: Mimicking Human Minds Elicits Deep AI Searcher**|Zehui Chen et.al.|[2407.20183v1](http://arxiv.org/abs/2407.20183v1)|[link](https://github.com/internlm/mindsearch)|
|**2024-07-29**|**rLLM: Relational Table Learning with LLMs**|Weichen Li et.al.|[2407.20157v1](http://arxiv.org/abs/2407.20157v1)|[link](https://github.com/rllm-project/rllm)|
|**2024-07-29**|**Prometheus Chatbot: Knowledge Graph Collaborative Large Language Model for Computer Components Recommendation**|Yunsheng Wang et.al.|[2407.19643v2](http://arxiv.org/abs/2407.19643v2)|[link](https://github.com/iamryanshengwang/prometheus-chatbot)|
|**2024-07-29**|**TopicTag: Automatic Annotation of NMF Topic Models Using Chain of Thought and Prompt Tuning with LLMs**|Selma Wanna et.al.|[2407.19616v1](http://arxiv.org/abs/2407.19616v1)|null|
|**2024-07-27**|**Semantic Communication Enhanced by Knowledge Graph Representation Learning**|Nour Hello et.al.|[2407.19338v1](http://arxiv.org/abs/2407.19338v1)|null|
|**2024-07-26**|**GraphBPE: Molecular Graphs Meet Byte-Pair Encoding**|Yuchen Shen et.al.|[2407.19039v1](http://arxiv.org/abs/2407.19039v1)|null|
|**2024-07-26**|**Knowledge Graph Structure as Prompt: Improving Small Language Models Capabilities for Knowledge-based Causal Discovery**|Yuni Susanti et.al.|[2407.18752v3](http://arxiv.org/abs/2407.18752v3)|[link](https://github.com/littleflow3r/kg-structure-as-prompt)|
|**2024-07-26**|**Using GPT-4 to guide causal machine learning**|Anthony C. Constantinou et.al.|[2407.18607v1](http://arxiv.org/abs/2407.18607v1)|null|
|**2024-07-26**|**Multi-turn Response Selection with Commonsense-enhanced Language Models**|Yuandong Wang et.al.|[2407.18479v1](http://arxiv.org/abs/2407.18479v1)|null|
|**2024-07-25**|**Gene Regulatory Network Inference from Pre-trained Single-Cell Transcriptomics Transformer with Joint Graph Learning**|Sindhura Kommu et.al.|[2407.18181v1](http://arxiv.org/abs/2407.18181v1)|null|
|**2024-07-24**|**MathViz-E: A Case-study in Domain-Specialized Tool-Using Agents**|Arya Bulusu et.al.|[2407.17544v1](http://arxiv.org/abs/2407.17544v1)|[link](https://github.com/emergenceai/mathviz-e)|
|**2024-07-23**|**Ranking protein-protein models with large language models and graph neural networks**|Xiaotong Xu et.al.|[2407.16375v1](http://arxiv.org/abs/2407.16375v1)|[link](https://github.com/haddocking/deeprank-gnn-esm)|
|**2024-07-23**|**PhenoFlow: A Human-LLM Driven Visual Analytics System for Exploring Large and Complex Stroke Datasets**|Jaeyoung Kim et.al.|[2407.16329v1](http://arxiv.org/abs/2407.16329v1)|null|
|**2024-07-23**|**Graph-Structured Speculative Decoding**|Zhuocheng Gong et.al.|[2407.16207v1](http://arxiv.org/abs/2407.16207v1)|null|
|**2024-07-23**|**Evaluating Long Range Dependency Handling in Code Generation Models using Multi-Step Key Retrieval**|Yannick Assogba et.al.|[2407.21049v1](http://arxiv.org/abs/2407.21049v1)|null|
|**2024-07-23**|**Finetuning Generative Large Language Models with Discrimination Instructions for Knowledge Graph Completion**|Yang Liu et.al.|[2407.16127v1](http://arxiv.org/abs/2407.16127v1)|[link](https://github.com/nju-websoft/dift)|
|**2024-07-22**|**Unsupervised Robust Cross-Lingual Entity Alignment via Joint Modeling of Entity and Relation Texts**|Soojin Yoon et.al.|[2407.15588v1](http://arxiv.org/abs/2407.15588v1)|[link](https://github.com/eralign/eralign)|
|**2024-07-22**|**The Ontoverse: Democratising Access to Knowledge Graph-based Data Through a Cartographic Interface**|Johannes Zimmermann et.al.|[2408.03339v1](http://arxiv.org/abs/2408.03339v1)|null|
|**2024-07-22**|**Pre-Training and Prompting for Few-Shot Node Classification on Text-Attributed Graphs**|Huanjing Zhao et.al.|[2407.15431v1](http://arxiv.org/abs/2407.15431v1)|null|
|**2024-07-22**|**LLMExplainer: Large Language Model based Bayesian Inference for Graph Explanation Generation**|Jiaxing Zhang et.al.|[2407.15351v2](http://arxiv.org/abs/2407.15351v2)|null|
|**2024-07-21**|**Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation**|Yu Zhang et.al.|[2407.15141v1](http://arxiv.org/abs/2407.15141v1)|null|
|**2024-07-20**|**On the Design and Analysis of LLM-Based Algorithms**|Yanxi Chen et.al.|[2407.14788v1](http://arxiv.org/abs/2407.14788v1)|[link](https://github.com/modelscope/agentscope)|
|**2024-07-19**|**LaMAGIC: Language-Model-based Topology Generation for Analog Integrated Circuits**|Chen-Chia Chang et.al.|[2407.18269v1](http://arxiv.org/abs/2407.18269v1)|null|
|**2024-07-19**|**Hierarchical Windowed Graph Attention Network and a Large Scale Dataset for Isolated Indian Sign Language Recognition**|Suvajit Patra et.al.|[2407.14224v1](http://arxiv.org/abs/2407.14224v1)|null|
|**2024-07-19**|**Enhancing Data-Limited Graph Neural Networks by Actively Distilling Knowledge from Large Language Models**|Quan Li et.al.|[2407.13989v1](http://arxiv.org/abs/2407.13989v1)|null|
|**2024-07-18**|**A Comprehensive Review of Recommender Systems: Transitioning from Theory to Practice**|Shaina Raza et.al.|[2407.13699v1](http://arxiv.org/abs/2407.13699v1)|null|
|**2024-07-18**|**MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains**|Guoli Yin et.al.|[2407.18961v2](http://arxiv.org/abs/2407.18961v2)|[link](https://github.com/apple/axlearn)|
|**2024-07-17**|**Is Sarcasm Detection A Step-by-Step Reasoning Process in Large Language Models?**|Ben Yao et.al.|[2407.12725v1](http://arxiv.org/abs/2407.12725v1)|null|
|**2024-07-17**|**Subgraph-Aware Training of Text-based Methods for Knowledge Graph Completion**|Youmin Ko et.al.|[2407.12703v3](http://arxiv.org/abs/2407.12703v3)|null|
|**2024-07-17**|**Abstraction Alignment: Comparing Model and Human Conceptual Relationships**|Angie Boggust et.al.|[2407.12543v1](http://arxiv.org/abs/2407.12543v1)|[link](https://github.com/mitvis/abstraction-alignment)|
|**2024-07-17**|**Struct-X: Enhancing Large Language Models Reasoning with Structured Data**|Xiaoyu Tan et.al.|[2407.12522v1](http://arxiv.org/abs/2407.12522v1)|null|
|**2024-07-17**|**Explainable Biomedical Hypothesis Generation via Retrieval Augmented Generation enabled Large Language Models**|Alexander R. Pelletier et.al.|[2407.12888v1](http://arxiv.org/abs/2407.12888v1)|[link](https://github.com/pinglab-utils/rugged)|
|**2024-07-16**|**A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting**|He Chang et.al.|[2407.11638v1](http://arxiv.org/abs/2407.11638v1)|null|
|**2024-07-16**|**Learning on Graphs with Large Language Models(LLMs): A Deep Dive into Model Robustness**|Kai Guo et.al.|[2407.12068v2](http://arxiv.org/abs/2407.12068v2)|null|
|**2024-07-16**|**CIC-BART-SSA: Controllable Image Captioning with Structured Semantic Augmentation**|Kalliopi Basioti et.al.|[2407.11393v2](http://arxiv.org/abs/2407.11393v2)|[link](https://github.com/SamsungLabs/CIC-BART-SSA)|
|**2024-07-15**|**Think-on-Graph 2.0: Deep and Interpretable Large Language Model Reasoning with Knowledge Graph-guided Retrieval**|Shengjie Ma et.al.|[2407.10805v3](http://arxiv.org/abs/2407.10805v3)|null|
|**2024-07-15**|**Graphusion: Leveraging Large Language Models for Scientific Knowledge Graph Fusion and Construction in NLP Education**|Rui Yang et.al.|[2407.10794v1](http://arxiv.org/abs/2407.10794v1)|[link](https://github.com/irenezihuili/cgprompt)|
|**2024-07-15**|**GraphEval: A Knowledge-Graph Based LLM Hallucination Evaluation Framework**|Hannah Sansford et.al.|[2407.10793v1](http://arxiv.org/abs/2407.10793v1)|null|
|**2024-07-15**|**Scaling 3D Reasoning with LMMs to Large Robot Mission Environments Using Datagraphs**|W. J. Meijer et.al.|[2407.10743v1](http://arxiv.org/abs/2407.10743v1)|null|
|**2024-07-14**|**AutoGRAMS: Autonomous Graphical Agent Modeling Software**|Ben Krause et.al.|[2407.10049v1](http://arxiv.org/abs/2407.10049v1)|[link](https://github.com/autograms/autograms)|
|**2024-07-13**|**FarFetched: Entity-centric Reasoning and Claim Validation for the Greek Language based on Textually Represented Environments**|Dimitris Papadopoulos et.al.|[2407.09888v1](http://arxiv.org/abs/2407.09888v1)|[link](https://github.com/lighteternal/farfetched_nlp)|
|**2024-07-12**|**GOFA: A Generative One-For-All Model for Joint Graph Language Modeling**|Lecheng Kong et.al.|[2407.09709v1](http://arxiv.org/abs/2407.09709v1)|[link](https://github.com/jiaruifeng/gofa)|
|**2024-07-12**|**Human-like Episodic Memory for Infinite Context LLMs**|Zafeirios Fountas et.al.|[2407.09450v1](http://arxiv.org/abs/2407.09450v1)|null|
|**2024-07-12**|**The $Î¼\mathcal{G}$ Language for Programming Graph Neural Networks**|Matteo Belenchia et.al.|[2407.09441v1](http://arxiv.org/abs/2407.09441v1)|null|
|**2024-07-12**|**Towards More Trustworthy and Interpretable LLMs for Code through Syntax-Grounded Explanations**|David N. Palacio et.al.|[2407.08983v1](http://arxiv.org/abs/2407.08983v1)|null|
|**2024-07-12**|**Domain-Hierarchy Adaptation via Chain of Iterative Reasoning for Few-shot Hierarchical Text Classification**|Ke Ji et.al.|[2407.08959v1](http://arxiv.org/abs/2407.08959v1)|null|
|**2024-07-11**|**Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight**|Zhiqiang Xie et.al.|[2407.08694v1](http://arxiv.org/abs/2407.08694v1)|null|
|**2024-07-11**|**Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents**|Haoyi Xiong et.al.|[2407.08516v4](http://arxiv.org/abs/2407.08516v4)|null|
|**2024-07-10**|**A Comprehensive Survey on the Security of Smart Grid: Challenges, Mitigations, and Future Research Opportunities**|Arastoo Zibaeirad et.al.|[2407.07966v1](http://arxiv.org/abs/2407.07966v1)|null|
|**2024-07-10**|**Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs**|Hao-Tien Lewis Chiang et.al.|[2407.07775v2](http://arxiv.org/abs/2407.07775v2)|null|
|**2024-07-10**|**Teaching Transformers Causal Reasoning through Axiomatic Training**|Aniket Vashishtha et.al.|[2407.07612v1](http://arxiv.org/abs/2407.07612v1)|null|
|**2024-07-10**|**STAGE: Simplified Text-Attributed Graph Embeddings Using Pre-trained LLMs**|Aaron Zolnai-Lucas et.al.|[2407.12860v1](http://arxiv.org/abs/2407.12860v1)|[link](https://github.com/aaronzo/STAGE)|
|**2024-07-10**|**GLBench: A Comprehensive Benchmark for Graph with Large Language Models**|Yuhan Li et.al.|[2407.07457v2](http://arxiv.org/abs/2407.07457v2)|[link](https://github.com/nineabyss/glbench)|
|**2024-07-09**|**Decoding Climate Disagreement: A Graph Neural Network-Based Approach to Understanding Social Media Dynamics**|Ruiran Su et.al.|[2407.07038v1](http://arxiv.org/abs/2407.07038v1)|null|
|**2024-07-09**|**Graph-Based Captioning: Enhancing Visual Descriptions by Interconnecting Region Captions**|Yu-Guan Hsieh et.al.|[2407.06723v1](http://arxiv.org/abs/2407.06723v1)|null|
|**2024-07-09**|**Combining Knowledge Graphs and Large Language Models**|Amanda Kau et.al.|[2407.06564v1](http://arxiv.org/abs/2407.06564v1)|null|
|**2024-07-09**|**FuncEvalGMN: Evaluating Functional Correctness of SQL via Graph Matching Network**|Yi Zhan et.al.|[2407.14530v1](http://arxiv.org/abs/2407.14530v1)|null|
|**2024-07-08**|**MST5 -- Multilingual Question Answering over Knowledge Graphs**|Nikit Srivastava et.al.|[2407.06041v1](http://arxiv.org/abs/2407.06041v1)|[link](https://github.com/dice-group/MST5)|
|**2024-07-08**|**Enhancing Vision-Language Models with Scene Graphs for Traffic Accident Understanding**|Aaron Lohner et.al.|[2407.05910v1](http://arxiv.org/abs/2407.05910v1)|null|
|**2024-07-08**|**Affordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation**|Jiaqi Chen et.al.|[2407.05890v1](http://arxiv.org/abs/2407.05890v1)|null|
|**2024-07-08**|**KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions**|Yanxu Zhu et.al.|[2407.05868v1](http://arxiv.org/abs/2407.05868v1)|[link](https://github.com/yanxuzhu/kg-fpq)|
|**2024-07-07**|**Language Models Encode Collaborative Signals in Recommendation**|Leheng Sheng et.al.|[2407.05441v1](http://arxiv.org/abs/2407.05441v1)|[link](https://github.com/lehengthu/alpharec)|
|**2024-07-07**|**LTLBench: Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models**|Weizhi Tang et.al.|[2407.05434v1](http://arxiv.org/abs/2407.05434v1)|[link](https://github.com/rutatang/ltlbench)|
|**2024-07-05**|**Leveraging Graph Structures to Detect Hallucinations in Large Language Models**|Noa Nonkes et.al.|[2407.04485v1](http://arxiv.org/abs/2407.04485v1)|[link](https://github.com/noanonkes/Hallucination-Detection-in-LLMs)|
|**2024-07-05**|**AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents**|Petr Anokhin et.al.|[2407.04363v1](http://arxiv.org/abs/2407.04363v1)|[link](https://github.com/airi-institute/arigraph)|
|**2024-07-04**|**Semantic Graphs for Syntactic Simplification: A Revisit from the Age of LLM**|Peiran Yao et.al.|[2407.04067v1](http://arxiv.org/abs/2407.04067v1)|[link](https://github.com/U-Alberta/AMRS3)|
|**2024-07-04**|**Functional Faithfulness in the Wild: Circuit Discovery with Differentiable Computation Graph Pruning**|Lei Yu et.al.|[2407.03779v1](http://arxiv.org/abs/2407.03779v1)|null|

#### Abstracts
##### **DIVE: Subgraph Disagreement for Graph Out-of-Distribution Generalization**
2408.04400v1 by Xin Sun, Liang Wang, Qiang Liu, Shu Wu, Zilei Wang, Liang Wang

This paper addresses the challenge of out-of-distribution (OOD)
generalization in graph machine learning, a field rapidly advancing yet
grappling with the discrepancy between source and target data distributions.
Traditional graph learning algorithms, based on the assumption of uniform
distribution between training and test data, falter in real-world scenarios
where this assumption fails, resulting in suboptimal performance. A principal
factor contributing to this suboptimal performance is the inherent simplicity
bias of neural networks trained through Stochastic Gradient Descent (SGD),
which prefer simpler features over more complex yet equally or more predictive
ones. This bias leads to a reliance on spurious correlations, adversely
affecting OOD performance in various tasks such as image recognition, natural
language understanding, and graph classification. Current methodologies,
including subgraph-mixup and information bottleneck approaches, have achieved
partial success but struggle to overcome simplicity bias, often reinforcing
spurious correlations. To tackle this, we propose DIVE, training a collection
of models to focus on all label-predictive subgraphs by encouraging the models
to foster divergence on the subgraph mask, which circumvents the limitation of
a model solely focusing on the subgraph corresponding to simple structural
patterns. Specifically, we employs a regularizer to punish overlap in extracted
subgraphs across models, thereby encouraging different models to concentrate on
distinct structural patterns. Model selection for robust OOD performance is
achieved through validation accuracy. Tested across four datasets from GOOD
benchmark and one dataset from DrugOOD benchmark, our approach demonstrates
significant improvement over existing methods, effectively addressing the
simplicity bias and enhancing generalization in graph machine learning.

æè¦ï¼<paragraph>éç¯è«ææ¢è¨äºåå½¢æ©å¨å­¸ç¿ä¸­éåä½ (OOD) æ¦åçææ°ï¼éæ¯ä¸åå¿«éç¼å±çé åï¼ä½å»å¨æå°ä¾æºåç®æ¨è³æåä½ä¹éçå·®ç°ä¸éå°å°é£ãå³çµ±çåå½¢å­¸ç¿æ¼ç®æ³åºæ¼è¨ç·´è³æåæ¸¬è©¦è³æä¹éåå»åä½çåè¨­ï¼ä½å¨éååè¨­å¤±æçå¯¦éææ³ä¸­æåºç¾åé¡ï¼å°è´æ¬¡ä½³æè½ãé æéç¨®æ¬¡ä½³æè½çä¸»è¦å ç´ æ¯ééé¨æ©æ¢¯åº¦ä¸é (SGD) è¨ç·´çç¥ç¶ç¶²è·¯åºæçç°¡ååå·®ï¼å®åå¥½è¼ç°¡å®çç¹å¾µï¼èéæ´è¤éä½é æ¸¬è½åç¸åææ´é«çç¹å¾µãéç¨®åå·®æå°è´ä¾è³´èåç¸éæ§ï¼å°åç¨®ä»»åï¼ä¾å¦å½±åè¾¨è­ãèªç¶èªè¨çè§£ååå½¢åé¡ï¼ç OOD æè½ç¢çè² é¢å½±é¿ãç®åçæè¡æ¹æ³ï¼åæ¬å­åæ··ååè³è¨ç¶é ¸æ¹æ³ï¼å·²åå¾é¨åæåï¼ä½ä»é£ä»¥åæç°¡ååå·®ï¼èä¸å¸¸å¸¸æå¼·åèåç¸éæ§ãçºäºè§£æ±ºéååé¡ï¼æåæåºäº DIVEï¼è¨ç·´ä¸çµæ¨¡åä»¥éæ³¨æææ¨ç±¤é æ¸¬å­åï¼æ¹æ³æ¯é¼åµæ¨¡åå¨å­åé®ç½©ä¸ä¿é²å·®ç°ï¼éé¿éäºæ¨¡ååéæ³¨å°ææ¼ç°¡å®çµæ§æ¨¡å¼çå­åçéå¶ãå·é«ä¾èªªï¼æåæ¡ç¨ä¸åæ­£è¦åå¨ä¾æ²ç½°æ¨¡åä¹éæåçå­åä¸­çéçï¼å¾èé¼åµä¸åçæ¨¡åå°æ³¨æ¼ä¸åççµæ§æ¨¡å¼ãééé©è­æºç¢ºåº¦ï¼å¯ä»¥é¸ææ¨¡åä»¥ç²å¾ç©©å¥ç OOD æè½ãæåçåæ³å¨ GOOD åºæºä¸­çååè³æéå DrugOOD åºæºä¸­çå¶ä¸­ä¸åè³æéä¸é²è¡äºæ¸¬è©¦ï¼çµæé¡¯ç¤ºåºæ¯ç¾ææ¹æ³æé¡¯èçé²æ­¥ï¼ææå°è§£æ±ºäºç°¡ååå·®ï¼ä¸¦å¢å¼·äºåå½¢æ©å¨å­¸ç¿ä¸­çæ¦åè½åã</paragraph>

##### **MM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models**
2408.04388v1 by Haoxuan Li, Zhengmao Yang, Yunshan Ma, Yi Bin, Yang Yang, Tat-Seng Chua

We study an emerging and intriguing problem of multimodal temporal event
forecasting with large language models. Compared to using text or graph
modalities, the investigation of utilizing images for temporal event
forecasting has not been fully explored, especially in the era of large
language models (LLMs). To bridge this gap, we are particularly interested in
two key questions of: 1) why images will help in temporal event forecasting,
and 2) how to integrate images into the LLM-based forecasting framework. To
answer these research questions, we propose to identify two essential functions
that images play in the scenario of temporal event forecasting, i.e.,
highlighting and complementary. Then, we develop a novel framework, named
MM-Forecast. It employs an Image Function Identification module to recognize
these functions as verbal descriptions using multimodal large language models
(MLLMs), and subsequently incorporates these function descriptions into
LLM-based forecasting models. To evaluate our approach, we construct a new
multimodal dataset, MidEast-TE-mm, by extending an existing event dataset
MidEast-TE-mini with images. Empirical studies demonstrate that our MM-Forecast
can correctly identify the image functions, and further more, incorporating
these verbal function descriptions significantly improves the forecasting
performance. The dataset, code, and prompts are available at
https://github.com/LuminosityX/MM-Forecast.

æè¦ï¼æåç ç©¶å¤æ¨¡ææéäºä»¶é æ¸¬ä¸­ä¸åæ°èä¸æè¶£çèªè¨æ¨¡ååé¡ãç¸è¼æ¼ä½¿ç¨æå­æåè¡¨æ¨¡æï¼å©ç¨å½±åé²è¡æéäºä»¶é æ¸¬çç ç©¶å°æªè¢«ååæ¢ç´¢ï¼ç¹å¥æ¯å¨å¤§åèªè¨æ¨¡å (LLM) çæä»£ãçºäºå¡«è£éåç©ºç½ï¼æåç¹å¥æèè¶£çå©åééµåé¡æ¯ï¼1) çºä»éº¼å½±åæå©æ¼æéäºä»¶é æ¸¬ï¼ä»¥å 2) å¦ä½å°å½±åæ´åå°åºæ¼ LLM çé æ¸¬æ¡æ¶ä¸­ãçºäºåç­éäºç ç©¶åé¡ï¼æåæè­°æ¾åºå½±åå¨æéäºä»¶é æ¸¬å ´æ¯ä¸­æ®æ¼çå©ååºæ¬åè½ï¼å³çªé¡¯åè£åãç¶å¾ï¼æåéç¼ä¸ååçº MM-Forecast çæ°æ¡æ¶ãå®ä½¿ç¨å½±ååè½è­å¥æ¨¡çµï¼ä½¿ç¨å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) å°éäºåè½è­å¥çºæå­æè¿°ï¼ä¸¦é¨å¾å°éäºåè½æè¿°ç´å¥åºæ¼ LLM çé æ¸¬æ¨¡åä¸­ãçºäºè©ä¼°æåçæ¹æ³ï¼æåééä½¿ç¨å½±åæ´åç¾æçäºä»¶è³æé MidEast-TE-miniï¼å»ºæ§äºä¸åæ°çå¤æ¨¡æè³æé MidEast-TE-mmãå¯¦è­ç ç©¶è¡¨æï¼æåç MM-Forecast å¯ä»¥æ­£ç¢ºè­å¥å½±ååè½ï¼æ­¤å¤ï¼ç´å¥éäºæå­åè½æè¿°å¯ä»¥é¡¯èæ¹åé æ¸¬æè½ãè³æéãç¨å¼ç¢¼åæç¤ºå¯å¨ https://github.com/LuminosityX/MM-Forecast åå¾ã

##### **Judgment2vec: Apply Graph Analytics to Searching and Recommendation of Similar Judgments**
2408.04382v1 by Hsuan-Lei Shao

In court practice, legal professionals rely on their training to provide
opinions that resolve cases, one of the most crucial aspects being the ability
to identify similar judgments from previous courts efficiently. However,
finding a similar case is challenging and often depends on experience, legal
domain knowledge, and extensive labor hours, making veteran lawyers or judges
indispensable. This research aims to automate the analysis of judgment text
similarity. We utilized a judgment dataset labeled as the "golden standard" by
experts, which includes human-verified features that can be converted into an
"expert similarity score." We then constructed a knowledge graph based on
"case-article" relationships, ranking each case using natural language
processing to derive a "Node2vec similarity score." By evaluating these two
similarity scores, we identified their discrepancies and relationships. The
results can significantly reduce the labor hours required for legal searches
and recommendations, with potential applications extending to various fields of
information retrieval.

æè¦ï¼å¨æ³åº­å¯¦åä¸­ï¼æ³å¾å°æ¥­äººå£«ä¾è³´å¶å¹è¨æä¾æè¦ä»¥è§£æ±ºæ¡ä»¶ï¼å¶ä¸­æééµçæ¹é¢ä¹ä¸æ¯ææè­å¥ååæ³é¢çé¡ä¼¼å¤æ±ºçè½åãç¶èï¼æ¾åºé¡ä¼¼æ¡ä»¶å·æææ°æ§ï¼ä¸éå¸¸åæ±ºæ¼ç¶é©ãæ³å¾é åç¥è­åå¤§éçååæéï¼éä½¿å¾è³æ·±å¾å¸«ææ³å®ä¸å¯æç¼ºãæ¬ç ç©¶æ¨å¨èªååå¤æ±ºææ¬ç¸ä¼¼æ§çåæãæåå©ç¨å°å®¶æ¨è¨çºãé»éæ¨æºãçå¤æ±ºè³æéï¼å¶ä¸­åæ¬å¯è½æçºãå°å®¶ç¸ä¼¼æ§è©åãçäººå·¥é©è­ç¹å¾µãç¶å¾ï¼æåæ ¹æãæ¡ä¾-æ¢æãéä¿å»ºæ§ç¥è­åè­ï¼ä½¿ç¨èªç¶èªè¨èçå°æ¯åæ¡ä¾é²è¡æåï¼ä»¥å¾åºãNode2vec ç¸ä¼¼æ§è©åããééè©ä¼°éå©åç¸ä¼¼æ§è©åï¼æåæ¾åºå¶å·®ç°åéä¿ãçµæå¯ä»¥å¤§å¹æ¸å°æ³å¾æå°åå»ºè­°æéçååæéï¼æ½å¨æç¨ç¯åæ´åè³è¨æª¢ç´¢çååé åã

##### **wav2graph: A Framework for Supervised Learning Knowledge Graph from Speech**
2408.04174v1 by Khai Le-Duc, Quy-Anh Dang, Tan-Hanh Pham, Truong-Son Hy

Knowledge graphs (KGs) enhance the performance of large language models
(LLMs) and search engines by providing structured, interconnected data that
improves reasoning and context-awareness. However, KGs only focus on text data,
thereby neglecting other modalities such as speech. In this work, we introduce
wav2graph, the first framework for supervised learning knowledge graph from
speech data. Our pipeline are straightforward: (1) constructing a KG based on
transcribed spoken utterances and a named entity database, (2) converting KG
into embedding vectors, and (3) training graph neural networks (GNNs) for node
classification and link prediction tasks. Through extensive experiments
conducted in inductive and transductive learning contexts using
state-of-the-art GNN models, we provide baseline results and error analysis for
node classification and link prediction tasks on human transcripts and
automatic speech recognition (ASR) transcripts, including evaluations using
both encoder-based and decoder-based node embeddings, as well as monolingual
and multilingual acoustic pre-trained models. All related code, data, and
models are published online.

æè¦ï¼ç¥è­åè­ (KG) ééæä¾çµæ§åãç¸äºé£çµçè³æï¼é²èæ¹åå¤§åèªè¨æ¨¡å (LLM) åæå°å¼æçæè½ï¼æåæ¨çåèçµ¡æç¥ãç¶èï¼KG åªéæ³¨æå­è³æï¼å æ­¤å¿½ç¥äºå¶ä»å½¢å¼ï¼ä¾å¦èªé³ãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹ wav2graphï¼éæ¯ç¬¬ä¸åå¾èªé³è³æä¸­ç£ç£å­¸ç¿ç¥è­åè­çæ¶æ§ãæåçæµç¨å¾ç´æ¥ï¼(1) æ ¹æè½éçå£èªè¡¨éåå½åå¯¦é«è³æåº«å»ºæ§ KGï¼(2) å° KG è½æçºåµå¥åéï¼ä»¥å (3) è¨ç·´åå½¢ç¥ç¶ç¶²è·¯ (GNN) ä»¥é²è¡ç¯é»åé¡åé£çµé æ¸¬ä»»åãééä½¿ç¨æåé²ç GNN æ¨¡åå¨æ­¸ç´åè½å°å­¸ç¿çç°å¢ä¸­é²è¡å»£æ³çå¯¦é©ï¼æåæä¾ç¯é»åé¡åé£çµé æ¸¬ä»»åçåºæºçµæåé¯èª¤åæï¼å¶ä¸­åæ¬ä½¿ç¨ç·¨ç¢¼å¨çºåºç¤åè§£ç¢¼å¨çºåºç¤çç¯é»åµå¥ï¼ä»¥åå®èªåå¤èªé³å­¸é è¨ç·´æ¨¡åçè©ä¼°ãææç¸éç¨å¼ç¢¼ãè³æåæ¨¡åçå·²å¨ç·ä¸ç¼å¸ã

##### **ArtVLM: Attribute Recognition Through Vision-Based Prefix Language Modeling**
2408.04102v1 by William Y. Zhu, Keren Ye, Junjie Ke, Jiahui Yu, Leonidas Guibas, Peyman Milanfar, Feng Yang

Recognizing and disentangling visual attributes from objects is a foundation
to many computer vision applications. While large vision language
representations like CLIP had largely resolved the task of zero-shot object
recognition, zero-shot visual attribute recognition remains a challenge because
CLIP's contrastively-learned vision-language representation cannot effectively
capture object-attribute dependencies. In this paper, we target this weakness
and propose a sentence generation-based retrieval formulation for attribute
recognition that is novel in 1) explicitly modeling a to-be-measured and
retrieved object-attribute relation as a conditional probability graph, which
converts the recognition problem into a dependency-sensitive language-modeling
problem, and 2) applying a large pretrained Vision-Language Model (VLM) on this
reformulation and naturally distilling its knowledge of image-object-attribute
relations to use towards attribute recognition. Specifically, for each
attribute to be recognized on an image, we measure the visual-conditioned
probability of generating a short sentence encoding the attribute's relation to
objects on the image. Unlike contrastive retrieval, which measures likelihood
by globally aligning elements of the sentence to the image, generative
retrieval is sensitive to the order and dependency of objects and attributes in
the sentence. We demonstrate through experiments that generative retrieval
consistently outperforms contrastive retrieval on two visual reasoning
datasets, Visual Attribute in the Wild (VAW), and our newly-proposed Visual
Genome Attribute Ranking (VGARank).

æè¦ï¼è¾¨è­åååç©ä»¶çè¦è¦ºå±¬æ§ï¼æ¯è¨±å¤é»è¦è¦è¦ºæç¨ç¨å¼çåºç¤ãéç¶å CLIP éæ¨£çå¤§åè¦è¦ºèªè¨è¡¨å¾µï¼å·²å¨å¾å¤§ç¨åº¦ä¸è§£æ±ºäºé¶æ¬¡å­¸ç¿ç©ä»¶è¾¨è­çä»»åï¼ä½é¶æ¬¡å­¸ç¿è¦è¦ºå±¬æ§è¾¨è­ä»ç¶æ¯ä¸åææ°ï¼å çº CLIP å°æ¯å­¸ç¿çè¦è¦ºèªè¨è¡¨å¾µï¼ç¡æ³æææ·åç©ä»¶å±¬æ§ä¾è³´æ§ãå¨æ¬æä¸­ï¼æåéå°æ­¤å¼±é»ï¼ä¸¦æåºä¸ååºæ¼å¥å­çæçæª¢ç´¢å¬å¼ï¼ç¨æ¼å±¬æ§è¾¨è­ï¼å¶æ°ç©ä¹èå¨æ¼ï¼1) æç¢ºå°å°å¾æ¸¬éåæª¢ç´¢çç©ä»¶å±¬æ§éä¿å»ºæ¨¡çºæ¢ä»¶æ©çåï¼éå°è¾¨è­åé¡è½æçºä¾è³´ææçèªè¨æ¨¡ååé¡ï¼2) å¨æ­¤éæ°å¬å¼åä¸æç¨å¤§åé è¨ç·´çè¦è¦ºèªè¨æ¨¡å (VLM)ï¼ä¸¦èªç¶å°èåå¶å°å½±åç©ä»¶å±¬æ§éä¿çç¥è­ï¼ç¨æ¼å±¬æ§è¾¨è­ãå·é«ä¾èªªï¼å°æ¼è¦å¨å½±åä¸è¾¨è­çæ¯åå±¬æ§ï¼æåæ¸¬éå¨å½±åä¸ç·¨ç¢¼å±¬æ§èç©ä»¶éä¿çç°¡ç­å¥å­çè¦è¦ºæ¢ä»¶æ©çãèå°æ¯æª¢ç´¢ä¸åï¼å°æ¯æª¢ç´¢æ¯ééå°å¥å­çåç´ æ´é«æ¯å°å°å½±åä¾æ¸¬éå¯è½æ§ï¼çææª¢ç´¢åå°å¥å­ä¸­ç©ä»¶åå±¬æ§çé åºåä¾è³´æ§å¾ææãæåééå¯¦é©è­æï¼çææª¢ç´¢å¨å©åè¦è¦ºæ¨çè³æéï¼éå¤è¦è¦ºå±¬æ§ (VAW) åæåæ°æåºçè¦è¦ºåºå çµå±¬æ§æå (VGARank) ä¸ï¼å§çµåªæ¼å°æ¯æª¢ç´¢ã

##### **CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**
2408.03910v1 by Xiangyan Liu, Bo Lan, Zhiyuan Hu, Yang Liu, Zhicheng Zhang, Wenmeng Zhou, Fei Wang, Michael Shieh

Large Language Models (LLMs) excel in stand-alone code tasks like HumanEval
and MBPP, but struggle with handling entire code repositories. This challenge
has prompted research on enhancing LLM-codebase interaction at a repository
scale. Current solutions rely on similarity-based retrieval or manual tools and
APIs, each with notable drawbacks. Similarity-based retrieval often has low
recall in complex tasks, while manual tools and APIs are typically
task-specific and require expert knowledge, reducing their generalizability
across diverse code tasks and real-world applications. To mitigate these
limitations, we introduce \framework, a system that integrates LLM agents with
graph database interfaces extracted from code repositories. By leveraging the
structural properties of graph databases and the flexibility of the graph query
language, \framework enables the LLM agent to construct and execute queries,
allowing for precise, code structure-aware context retrieval and code
navigation. We assess \framework using three benchmarks: CrossCodeEval,
SWE-bench, and EvoCodeBench. Additionally, we develop five real-world coding
applications. With a unified graph database schema, \framework demonstrates
competitive performance and potential in both academic and real-world
environments, showcasing its versatility and efficacy in software engineering.
Our application demo:
https://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agent.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨ç¨ç«ç¨å¼ç¢¼ä»»åä¸­è¡¨ç¾åºè²ï¼ä¾å¦ HumanEval å MBPPï¼ä½èçæ´åç¨å¼ç¢¼å²å­åº«æå»éå°å°é£ãéåææ°ä¿ä½¿ç ç©¶äººå¡å å¼· LLM èç¨å¼ç¢¼åº«çäºåï¼ä¸¦ä»¥å²å­åº«çºè¦æ¨¡ãç®åçè§£æ±ºæ¹æ¡ä¾è³´æ¼åºæ¼ç¸ä¼¼æ§çæ·åææåå·¥å·å APIï¼æ¯ç¨®æ¹æ³é½æé¡¯èçç¼ºé»ãåºæ¼ç¸ä¼¼æ§çæ·åå¨è¤éä»»åä¸­éå¸¸å¬åçä½ï¼èæåå·¥å·å API éå¸¸æ¯ç¹å®æ¼ä»»åçï¼éè¦å°å®¶ç¥è­ï¼éæéä½å®åå¨ä¸åç¨å¼ç¢¼ä»»ååå¯¦éæç¨ä¸­çæ¦æ¬æ§ãçºäºæ¸è¼éäºéå¶ï¼æåå¼å¥äº \frameworkï¼ä¸åå° LLM ä»£çèå¾ç¨å¼ç¢¼å²å­åº«ä¸­æåçåå½¢è³æåº«ä»é¢æ´åçç³»çµ±ãééå©ç¨åå½¢è³æåº«ççµæ§ç¹æ§ååå½¢æ¥è©¢èªè¨çéæ´»æ§ï¼\framework ä½¿ LLM ä»£çè½å¤ å»ºæ§åå·è¡æ¥è©¢ï¼åè¨±ç²¾ç¢ºãæç¨å¼ç¢¼çµæ§æè­çå§å®¹æ·ååç¨å¼ç¢¼å°è¦½ãæåä½¿ç¨ä¸ååºæºä¾è©ä¼° \frameworkï¼CrossCodeEvalãSWE-bench å EvoCodeBenchãæ­¤å¤ï¼æåéç¼äºäºåå¯¦éçç¨å¼ç¢¼æç¨ç¨å¼ãæäºçµ±ä¸çåå½¢è³æåº«æ¶æ§ï¼\framework å¨å­¸è¡åå¯¦éç°å¢ä¸­é½å±ç¾åºç«¶ç­åçæè½åæ½åï¼å±ç¤ºäºå®å¨è»é«å·¥ç¨ä¸­çå¤åè½æ§åæææ§ãæåçæç¨ç¨å¼ç¤ºç¯ï¼https://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agentã

##### **PAGED: A Benchmark for Procedural Graphs Extraction from Documents**
2408.03630v2 by Weihong Du, Wenrui Liao, Hongru Liang, Wenqiang Lei

Automatic extraction of procedural graphs from documents creates a low-cost
way for users to easily understand a complex procedure by skimming visual
graphs. Despite the progress in recent studies, it remains unanswered: whether
the existing studies have well solved this task (Q1) and whether the emerging
large language models (LLMs) can bring new opportunities to this task (Q2). To
this end, we propose a new benchmark PAGED, equipped with a large high-quality
dataset and standard evaluations. It investigates five state-of-the-art
baselines, revealing that they fail to extract optimal procedural graphs well
because of their heavy reliance on hand-written rules and limited available
data. We further involve three advanced LLMs in PAGED and enhance them with a
novel self-refine strategy. The results point out the advantages of LLMs in
identifying textual elements and their gaps in building logical structures. We
hope PAGED can serve as a major landmark for automatic procedural graph
extraction and the investigations in PAGED can offer insights into the research
on logic reasoning among non-sequential elements.

æè¦ï¼èªåå¾æä»¶ä¸­èåç¨åºåè¡¨æ¯ä¸ç¨®ä½ææ¬çæ¹å¼ï¼è®ä½¿ç¨èè½ééçè¦½è¦è¦ºååè¡¨ï¼è¼é¬çè§£è¤éçç¨åºãåç®¡è¿æç ç©¶å·²ææé²å±ï¼ä½ä»æå¾è§£ç­çåé¡ï¼ç¾æçç ç©¶æ¯å¦å·²å¦¥åè§£æ±ºæ­¤ä»»åï¼Q1ï¼ï¼ä»¥åæ°èçå¤§èªè¨æ¨¡åï¼LLMï¼æ¯å¦è½çºæ­¤ä»»åå¸¶ä¾æ°çå¥æ©ï¼Q2ï¼ãçºæ­¤ï¼æåæåºä¸åæ°çåºæº PAGEDï¼éåå¤§åé«åè³ªè³æéåæ¨æºè©éãå®æ¢è¨äºäºåæåé²çåºç·ï¼æ­ç¤ºäºå®åç¡æ³è¯å¥½å°èåæä½³ç¨åºåè¡¨ï¼åå å¨æ¼å®åéåº¦ä¾è³´æå¯«è¦ååæéçå¯ç¨è³æãæåé²ä¸æ­¥å¨ PAGED ä¸­ç´å¥ä¸ååé²ç LLMï¼ä¸¦ééæ°ç©çèªç²¾é²ç­ç¥å ä»¥å¼·åãçµææåº LLM å¨è­å¥ææ¬åç´ æ¹é¢çåªå¢ï¼ä»¥åå®åå¨å»ºç«éè¼¯çµæ§æ¹é¢çå·®è·ãæåå¸æ PAGED è½æçºèªåç¨åºåè¡¨èåçä¸»è¦éç¨ç¢ï¼è PAGED ä¸­çæ¢è¨è½çºéé åºåç´ éçéè¼¯æ¨çç ç©¶æä¾è¦è§£ã

##### **Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks**
2408.03615v1 by Zaijing Li, Yuquan Xie, Rui Shao, Gongwei Chen, Dongmei Jiang, Liqiang Nie

Building a general-purpose agent is a long-standing vision in the field of
artificial intelligence. Existing agents have made remarkable progress in many
domains, yet they still struggle to complete long-horizon tasks in an open
world. We attribute this to the lack of necessary world knowledge and
multimodal experience that can guide agents through a variety of long-horizon
tasks. In this paper, we propose a Hybrid Multimodal Memory module to address
the above challenges. It 1) transforms knowledge into Hierarchical Directed
Knowledge Graph that allows agents to explicitly represent and learn world
knowledge, and 2) summarises historical information into Abstracted Multimodal
Experience Pool that provide agents with rich references for in-context
learning. On top of the Hybrid Multimodal Memory module, a multimodal agent,
Optimus-1, is constructed with dedicated Knowledge-guided Planner and
Experience-Driven Reflector, contributing to a better planning and reflection
in the face of long-horizon tasks in Minecraft. Extensive experimental results
show that Optimus-1 significantly outperforms all existing agents on
challenging long-horizon task benchmarks, and exhibits near human-level
performance on many tasks. In addition, we introduce various Multimodal Large
Language Models (MLLMs) as the backbone of Optimus-1. Experimental results show
that Optimus-1 exhibits strong generalization with the help of the Hybrid
Multimodal Memory module, outperforming the GPT-4V baseline on many tasks.

æè¦ï¼æé ä¸åéç¨ä»£çæ¯äººå·¥æºæ§é åé·ä¹ä»¥ä¾çé¡æ¯ãç¾æçä»£çå¨è¨±å¤é åé½æé¡¯èçé²æ­¥ï¼ä½å®åä»é£ä»¥å¨éæ¾ä¸çä¸­å®æé·æç¨ä»»åãæåå°æ­¤æ­¸å æ¼ç¼ºä¹å¿è¦çç¥è­åå¤æ¨¡æç¶é©ï¼éäºç¥è­åç¶é©å¯ä»¥å¼å°ä»£çå®æåç¨®é·æç¨ä»»åãå¨æ¬æä¸­ï¼æåæåºä¸åæ··åå¤æ¨¡æè¨æ¶é«æ¨¡çµä¾è§£æ±ºä¸è¿°ææ°ãå® 1) å°ç¥è­è½æçºéå±¤å¼å°åç¥è­åï¼è®ä»£çè½å¤ æç¢ºå°è¡¨ç¤ºåå­¸ç¿ä¸çç¥è­ï¼ä»¥å 2) å°æ­·å²è³è¨æè¦ææ½è±¡çå¤æ¨¡æç¶é©æ± ï¼çºä»£çæä¾è±å¯çåèï¼ä»¥ä¾¿é²è¡æå¢å­¸ç¿ãå¨æ··åå¤æ¨¡æè¨æ¶é«æ¨¡çµä¹ä¸ï¼å»ºæ§äºä¸åå¤æ¨¡æä»£çï¼Optimus-1ï¼å®å·åå°ç¨çç¥è­å°åè¦åå¨åç¶é©é©åçåå°å¨ï¼æå©æ¼å¨ Minecraft ä¸­é¢å°é·æç¨ä»»åæé²è¡æ´å¥½çè¦åååæãå»£æ³çå¯¦é©çµæé¡¯ç¤ºï¼Optimus-1 å¨å·æææ°æ§çé·æç¨ä»»ååºæºä¸é¡¯èåªæ¼ææç¾æä»£çï¼ä¸¦ä¸å¨è¨±å¤ä»»åä¸å±ç¾åºæ¥è¿äººé¡çæè½ãæ­¤å¤ï¼æåå¼å¥åç¨®å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) ä½çº Optimus-1 çéª¨å¹¹ãå¯¦é©çµæé¡¯ç¤ºï¼Optimus-1 å¨æ··åå¤æ¨¡æè¨æ¶é«æ¨¡çµçå¹«å©ä¸å±ç¾åºå¼·å¤§çæ³åè½åï¼å¨è¨±å¤ä»»åä¸åªæ¼ GPT-4V åºæºã

##### **Exploring the extent of similarities in software failures across industries using LLMs**
2408.03528v2 by Martin Detloff

The rapid evolution of software development necessitates enhanced safety
measures. Extracting information about software failures from companies is
becoming increasingly more available through news articles.
  This research utilizes the Failure Analysis Investigation with LLMs (FAIL)
model to extract industry-specific information. Although the FAIL model's
database is rich in information, it could benefit from further categorization
and industry-specific insights to further assist software engineers.
  In previous work news articles were collected from reputable sources and
categorized by incidents inside a database. Prompt engineering and Large
Language Models (LLMs) were then applied to extract relevant information
regarding the software failure. This research extends these methods by
categorizing articles into specific domains and types of software failures. The
results are visually represented through graphs.
  The analysis shows that throughout the database some software failures occur
significantly more often in specific industries. This categorization provides a
valuable resource for software engineers and companies to identify and address
common failures.
  This research highlights the synergy between software engineering and Large
Language Models (LLMs) to automate and enhance the analysis of software
failures. By transforming data from the database into an industry specific
model, we provide a valuable resource that can be used to identify common
vulnerabilities, predict potential risks, and implement proactive measures for
preventing software failures. Leveraging the power of the current FAIL database
and data visualization, we aim to provide an avenue for safer and more secure
software in the future.

æè¦ï¼<paragraph>è»é«éç¼å¿«éæ¼é²ï¼è¿«åéè¦å¢å¼·å®å¨æªæ½ãå¾å¬å¸æ°èæç« ä¸­èåè»é«æéè³è¨æ­£è®å¾è¶ä¾è¶å®¹æã
æ­¤ç ç©¶å©ç¨å¤§åèªè¨æ¨¡åï¼LLMï¼æéåæèª¿æ¥ï¼FAILï¼æ¨¡åèåç¢æ¥­ç¹å®è³è¨ãåç®¡ FAIL æ¨¡åçè³æåº«è³è¨è±å¯ï¼ä½è¥è½é²ä¸æ­¥åé¡ä¸¦æä¾ç¢æ¥­ç¹å®è¦è§£ï¼å°æå©æ¼è»é«å·¥ç¨å¸«ã
å¨ååçç ç©¶ä¸­ï¼æåå¾ä¿¡è­½è¯å¥½çä¾æºæ¶éæ°èæç« ï¼ä¸¦å°å¶åé¡çºè³æåº«ä¸­çäºä»¶ãæ¥èæç¨æç¤ºå·¥ç¨åå¤§åèªè¨æ¨¡åï¼LLMï¼èåèè»é«æéç¸éçè³è¨ãæ­¤ç ç©¶ééå°æç« åé¡å°ç¹å®é ååè»é«æéé¡åï¼å»¶ä¼¸äºéäºæ¹æ³ãçµæééåè¡¨è¦è¦ºååç¾ã
åæé¡¯ç¤ºï¼å¨æ´åè³æåº«ä¸­ï¼æäºè»é«æéå¨ç¹å®ç¢æ¥­ä¸­ç¼ççé »çé¡¯èè¼é«ãæ­¤åé¡çºè»é«å·¥ç¨å¸«åå¬å¸æä¾äºå¯¶è²´çè³æºï¼å¯è­å¥ä¸¦è§£æ±ºå¸¸è¦æéã
æ­¤ç ç©¶å¼·èª¿äºè»é«å·¥ç¨èå¤§åèªè¨æ¨¡åï¼LLMï¼ä¹éçç¶æä½ç¨ï¼å¯èªååä¸¦å¢å¼·è»é«æéåæãééå°è³æåº«ä¸­çè³æè½æçºç¢æ¥­ç¹å®æ¨¡åï¼æåæä¾äºä¸é å¯¶è²´çè³æºï¼å¯ç¨æ¼è­å¥å¸¸è¦æ¼æ´ãé æ¸¬æ½å¨é¢¨éªï¼ä¸¦å¯¦æ½ä¸»åæªæ½ä¾é é²è»é«æéãæåå©ç¨ç¾æ FAIL è³æåº«åè³æè¦è¦ºåçåªå¢ï¼æ¨å¨çºæªä¾æä¾æ´å®å¨ä¸ç©©å®çè»é«ã</paragraph>

##### **Enhancing Complex Causality Extraction via Improved Subtask Interaction and Knowledge Fusion**
2408.03079v1 by Jinglong Gao, Chen Lu, Xiao Ding, Zhongyang Li, Ting Liu, Bing Qin

Event Causality Extraction (ECE) aims at extracting causal event pairs from
texts. Despite ChatGPT's recent success, fine-tuning small models remains the
best approach for the ECE task. However, existing fine-tuning based ECE methods
cannot address all three key challenges in ECE simultaneously: 1) Complex
Causality Extraction, where multiple causal-effect pairs occur within a single
sentence; 2) Subtask~ Interaction, which involves modeling the mutual
dependence between the two subtasks of ECE, i.e., extracting events and
identifying the causal relationship between extracted events; and 3) Knowledge
Fusion, which requires effectively fusing the knowledge in two modalities,
i.e., the expressive pretrained language models and the structured knowledge
graphs. In this paper, we propose a unified ECE framework (UniCE to address all
three issues in ECE simultaneously. Specifically, we design a subtask
interaction mechanism to enable mutual interaction between the two ECE
subtasks. Besides, we design a knowledge fusion mechanism to fuse knowledge in
the two modalities. Furthermore, we employ separate decoders for each subtask
to facilitate complex causality extraction. Experiments on three benchmark
datasets demonstrate that our method achieves state-of-the-art performance and
outperforms ChatGPT with a margin of at least 30% F1-score. More importantly,
our model can also be used to effectively improve the ECE performance of
ChatGPT via in-context learning.

æè¦ï¼äºä»¶å æéä¿èå (ECE) çç®æ¨æ¯å¾ææ¬ä¸­èååºå æäºä»¶å°ãåç®¡ ChatGPT æè¿ç²å¾æåï¼å¾®èª¿å°åæ¨¡åä»æ¯ ECE ä»»åçæä½³æ¹æ³ãç¶èï¼ç¾æçåºæ¼å¾®èª¿ç ECE æ¹æ³ç¡æ³åæè§£æ±º ECE ä¸­çä¸åä¸»è¦ææ°ï¼1) è¤éå æéä¿èåï¼å¶ä¸­å¤åå æéä¿å°åºç¾å¨å®ä¸å¥å­ä¸­ï¼2) å­ä»»åäºåï¼éæ¶åå° ECE çå©åå­ä»»åï¼å³èåäºä»¶åè­å¥èåäºä»¶ä¹éçå æéä¿ï¼ä¹éçç¸äºä¾è³´æ§é²è¡å»ºæ¨¡ï¼3) ç¥è­èåï¼ééè¦ææå°èåå©ç¨®æ¨¡å¼ä¸­çç¥è­ï¼å³è¡¨éå¼çé è¨ç·´èªè¨æ¨¡ååçµæ§åçç¥è­åè­ãå¨æ¬æä¸­ï¼æåæåºä¸åçµ±ä¸ç ECE æ¡æ¶ (UniCE)ï¼ä»¥åæè§£æ±º ECE ä¸­çææä¸ååé¡ãå·é«ä¾èªªï¼æåè¨­è¨äºä¸åå­ä»»åäºåæ©å¶ï¼ä»¥å¯¦ç¾å©å ECE å­ä»»åä¹éçç¸äºäºåãæ­¤å¤ï¼æåè¨­è¨äºä¸åç¥è­èåæ©å¶ä¾èåå©ç¨®æ¨¡å¼ä¸­çç¥è­ãæ­¤å¤ï¼æåéå°æ¯åå­ä»»åæ¡ç¨å®ç¨çè§£ç¢¼å¨ï¼ä»¥ä¿é²è¤éå æéä¿çèåãå¨ä¸ååºæºè³æéä¸çå¯¦é©è¡¨æï¼æåçæ¹æ³éå°äºæåé²çæè½ï¼ä¸¦ä¸ä»¥è³å° 30% ç F1 åæ¸åªæ¼ ChatGPTãæ´éè¦çæ¯ï¼æåçæ¨¡åä¹å¯ä»¥ééæå¢å­¸ç¿ææå°æå ChatGPT ç ECE æè½ã

##### **Fact Finder -- Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs**
2408.03010v1 by Daniel Steinigen, Roman Teucher, Timm Heine Ruland, Max Rudat, Nicolas Flores-Herr, Peter Fischer, Nikola Milosevic, Christopher Schymura, Angelo Ziletti

Recent advancements in Large Language Models (LLMs) have showcased their
proficiency in answering natural language queries. However, their effectiveness
is hindered by limited domain-specific knowledge, raising concerns about the
reliability of their responses. We introduce a hybrid system that augments LLMs
with domain-specific knowledge graphs (KGs), thereby aiming to enhance factual
correctness using a KG-based retrieval approach. We focus on a medical KG to
demonstrate our methodology, which includes (1) pre-processing, (2) Cypher
query generation, (3) Cypher query processing, (4) KG retrieval, and (5)
LLM-enhanced response generation. We evaluate our system on a curated dataset
of 69 samples, achieving a precision of 78\% in retrieving correct KG nodes.
Our findings indicate that the hybrid system surpasses a standalone LLM in
accuracy and completeness, as verified by an LLM-as-a-Judge evaluation method.
This positions the system as a promising tool for applications that demand
factual correctness and completeness, such as target identification -- a
critical process in pinpointing biological entities for disease treatment or
crop enhancement. Moreover, its intuitive search interface and ability to
provide accurate responses within seconds make it well-suited for
time-sensitive, precision-focused research contexts. We publish the source code
together with the dataset and the prompt templates used.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±å±ç¤ºäºå®åå¨åç­èªç¶èªè¨æ¥è©¢æ¹é¢çè½åãç¶èï¼å®åçæææ§åå°ç¹å®é åç¥è­æéçé»ç¤ï¼éå¼èµ·äºå°å¶åæå¯é æ§çææãæåå¼å¥äºä¸åæ··åç³»çµ±ï¼è©²ç³»çµ±ä½¿ç¨ç¹å®é åçç¥è­åè­ (KG) ä¾æ´å LLMï¼å¾èæ¨å¨ä½¿ç¨åºæ¼ KG çæª¢ç´¢æ¹æ³ä¾å¢å¼·äºå¯¦æ­£ç¢ºæ§ãæåå°æ³¨æ¼ä¸åé«å­¸ KG ä¾æ¼ç¤ºæåç methodologyï¼å¶ä¸­åæ¬ (1) é èçï¼(2) Cypher æ¥è©¢çæï¼(3) Cypher æ¥è©¢èçï¼(4) KG æª¢ç´¢ï¼ä»¥å (5) LLM å¢å¼·çåæçæãæåå¨ä¸åç± 69 åæ¨£æ¬çµæçç²¾é¸æ¸æéä¸è©ä¼°æåçç³»çµ±ï¼å¨æª¢ç´¢æ­£ç¢ºç KG ç¯é»æéå°äº 78% çç²¾åº¦ãæåçç ç©¶çµæè¡¨æï¼æ··åç³»çµ±å¨æºç¢ºæ§åå®æ´æ§æ¹é¢é½è¶éäºå®ç¨ç LLMï¼ééé LLM ä½çºè©å¯©è©ä¼°æ¹æ³å¾å°é©è­ãéå°ç³»çµ±å®ä½çºå°æç¨ç¨å¼ä¾èªªä¸åæåéçå·¥å·ï¼éäºæç¨ç¨å¼éè¦äºå¯¦æ­£ç¢ºæ§åå®æ´æ§ï¼ä¾å¦ç®æ¨è­å¥ââå¨ç¾çæ²»çæä½ç©æ¹è¯ä¸­ç²¾ç¢ºå®ä½çç©å¯¦é«çééµéç¨ãæ­¤å¤ï¼å¶ç´è§çæå°ä»é¢åå¨æ¸ç§å§æä¾æºç¢ºåæçè½åä½¿å¶éå¸¸é©åæéææãæ³¨éç²¾ç¢ºåº¦çç ç©¶æå¢ãæåå°åå§ç¢¼èæ¸æéåä½¿ç¨çæç¤ºç¯æ¬ä¸èµ·ç¼å¸ã

##### **Leveraging Inter-Chunk Interactions for Enhanced Retrieval in Large Language Model-Based Question Answering**
2408.02907v1 by Tiezheng Guo, Chen Wang, Yanyi Liu, Jiawei Tang, Pan Li, Sai Xu, Qingwen Yang, Xianlin Gao, Zhi Li, Yingyou Wen

Retrieving external knowledge and prompting large language models with
relevant information is an effective paradigm to enhance the performance of
question-answering tasks. Previous research typically handles paragraphs from
external documents in isolation, resulting in a lack of context and ambiguous
references, particularly in multi-document and complex tasks. To overcome these
challenges, we propose a new retrieval framework IIER, that leverages
Inter-chunk Interactions to Enhance Retrieval. This framework captures the
internal connections between document chunks by considering three types of
interactions: structural, keyword, and semantic. We then construct a unified
Chunk-Interaction Graph to represent all external documents comprehensively.
Additionally, we design a graph-based evidence chain retriever that utilizes
previous paths and chunk interactions to guide the retrieval process. It
identifies multiple seed nodes based on the target question and iteratively
searches for relevant chunks to gather supporting evidence. This retrieval
process refines the context and reasoning chain, aiding the large language
model in reasoning and answer generation. Extensive experiments demonstrate
that IIER outperforms strong baselines across four datasets, highlighting its
effectiveness in improving retrieval and reasoning capabilities.

æè¦ï¼åå¾å¤é¨ç¥è­ä¸¦æç¤ºå¤§åèªè¨æ¨¡åæä¾ç¸éè³è¨ï¼æ¯æååç­ä»»åæè½çææå¸ç¯ãååçç ç©¶éå¸¸å­¤ç«å°èçå¤é¨æä»¶ä¸­çæ®µè½ï¼å°è´ç¼ºä¹èçµ¡åæ¨¡ç¨å©å¯çåèï¼ç¹å¥æ¯å¨å¤æä»¶åè¤éçä»»åä¸­ãçºäºåæéäºææ°ï¼æåæåºä¸åæ°çæª¢ç´¢æ¶æ§ IIERï¼å©ç¨åå¡éäºåä¾å¢å¼·æª¢ç´¢ãéåæ¶æ§ééèéä¸ç¨®é¡åçäºåä¾æ·åæä»¶åå¡ä¹éçå§é¨é£çµï¼çµæ§ãééµå­åèªæãç¶å¾ï¼æåå»ºæ§ä¸åçµ±ä¸çåå¡äºååï¼ä»¥å¨é¢è¡¨ç¤ºææå¤é¨æä»¶ãæ­¤å¤ï¼æåè¨­è¨ä¸ååºæ¼åå½¢çè­æéæª¢ç´¢å¨ï¼å©ç¨ååçè·¯å¾ååå¡äºåä¾å¼å°æª¢ç´¢ç¨åºãå®æ ¹æç®æ¨åé¡è­å¥å¤åç¨®å­ç¯é»ï¼ä¸¦åè¦æå°ç¸éåå¡ä»¥æ¶éä½è­è­æãéåæª¢ç´¢ç¨åºç²¾çäºèçµ¡åæ¨çéï¼åå©å¤§åèªè¨æ¨¡åé²è¡æ¨çåç­æ¡ç¢çãå»£æ³çå¯¦é©è­æï¼IIER å¨ååè³æéä¸åªæ¼å¼·å¤§çåºæºï¼çªé¡¯å¶å¨æ¹åæª¢ç´¢åæ¨çè½åæ¹é¢çæè½ã

##### **A Few-Shot Approach for Relation Extraction Domain Adaptation using Large Language Models**
2408.02377v1 by Vanni Zavarella, Juan Carlos Gamero-Salinas, Sergio Consoli

Knowledge graphs (KGs) have been successfully applied to the analysis of
complex scientific and technological domains, with automatic KG generation
methods typically building upon relation extraction models capturing
fine-grained relations between domain entities in text. While these relations
are fully applicable across scientific areas, existing models are trained on
few domain-specific datasets such as SciERC and do not perform well on new
target domains. In this paper, we experiment with leveraging in-context
learning capabilities of Large Language Models to perform schema-constrained
data annotation, collecting in-domain training instances for a
Transformer-based relation extraction model deployed on titles and abstracts of
research papers in the Architecture, Construction, Engineering and Operations
(AECO) domain. By assessing the performance gain with respect to a baseline
Deep Learning architecture trained on off-domain data, we show that by using a
few-shot learning strategy with structured prompts and only minimal expert
annotation the presented approach can potentially support domain adaptation of
a science KG generation model.

æè¦ï¼ç¥è­åè­ (KG) å·²æåæç¨æ¼åæè¤éçç§å­¸æè¡é åï¼èªå KG çææ¹æ³éå¸¸å»ºæ§æ¼éä¿èåæ¨¡åä¸ï¼ææææ¬ä¸­é åå¯¦é«ä¹éçç´°ç²åº¦éä¿ãéç¶éäºéä¿å®å¨é©ç¨æ¼åç§å­¸é åï¼ä½ç¾ææ¨¡åæ¯ç¨ SciERC ç­å°æ¸ç¹å®é åçè³æéè¨ç·´ï¼èä¸å¨æ°ç®æ¨é åçè¡¨ç¾ä¸ä½³ãå¨æ¬è«æä¸­ï¼æååè©¦å©ç¨å¤§åèªè¨æ¨¡åçèçµ¡å­¸ç¿è½åï¼å·è¡åæ¶æ§ç´æçè³ææ¨è¨»ï¼æ¶éé åå§è¨ç·´å¯¦ä¾ï¼ç¨æ¼é¨ç½²å¨å»ºç¯ãçé ãå·¥ç¨åçé (AECO) é åç ç©¶è«ææ¨é¡åæè¦çåºæ¼ Transformer çéä¿èåæ¨¡åãééè©ä¼°ç¸å°æ¼å¨é åå¤è³æä¸è¨ç·´çåºæºæ·±åº¦å­¸ç¿æ¶æ§çæè½æåï¼æåå±ç¤ºééä½¿ç¨å¸¶æçµæ§åæç¤ºçå°éå­¸ç¿ç­ç¥ï¼ä»¥ååæå°çå°å®¶æ¨è¨»ï¼ææåºçæ¹æ³æå¯è½æ¯æ´ç§å­¸ KG çææ¨¡åçé åé©æã

##### **Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction**
2408.02337v1 by Albert Sawczyn, Katsiaryna Viarenich, Konrad Wojtasik, Aleksandra DomogaÅa, Marcin Oleksy, Maciej Piasecki, Tomasz Kajdanowicz

Advancements in AI and natural language processing have revolutionized
machine-human language interactions, with question answering (QA) systems
playing a pivotal role. The knowledge base question answering (KBQA) task,
utilizing structured knowledge graphs (KG), allows for handling extensive
knowledge-intensive questions. However, a significant gap exists in KBQA
datasets, especially for low-resource languages. Many existing construction
pipelines for these datasets are outdated and inefficient in human labor, and
modern assisting tools like Large Language Models (LLM) are not utilized to
reduce the workload. To address this, we have designed and implemented a
modern, semi-automated approach for creating datasets, encompassing tasks such
as KBQA, Machine Reading Comprehension (MRC), and Information Retrieval (IR),
tailored explicitly for low-resource environments. We executed this pipeline
and introduced the PUGG dataset, the first Polish KBQA dataset, and novel
datasets for MRC and IR. Additionally, we provide a comprehensive
implementation, insightful findings, detailed statistics, and evaluation of
baseline models.

æè¦ï¼äººå·¥æºè½åèªç¶èªè¨èççé²å±å¾¹åºæ¹è®äºæ©å¨èäººé¡çèªè¨äºåï¼å¶ä¸­åç­ (QA) ç³»çµ±æ®æ¼äºééµè§è²ãç¥è­åº«åç­ (KBQA) ä»»åå©ç¨çµæ§åçç¥è­åè­ (KG)ï¼å¯ä»¥èçå¤§éçç¥è­å¯éååé¡ãç¶èï¼KBQA è³æéå­å¨èé¡¯èçå·®è·ï¼ç¹å¥æ¯å°æ¼ä½è³æºèªè¨ãè¨±å¤ç¾æçéäºè³æéå»ºæ§ç®¡éå·²ç¶éæä¸å¨äººåä¸æçä½ä¸ï¼èåå¤§åèªè¨æ¨¡å (LLM) éæ¨£çç¾ä»£è¼å©å·¥å·ä¸¦æªè¢«ç¨æ¼æ¸å°å·¥ä½è² è¼ãçºäºè§£æ±ºéååé¡ï¼æåè¨­è¨ä¸¦å¯¦ä½äºä¸ç¨®ç¾ä»£çåèªååæ¹æ³ä¾å»ºç«è³æéï¼æ¶µèäºå°ééå°ä½è³æºç°å¢éèº«æé çä»»åï¼ä¾å¦ KBQAãæ©å¨é±è®çè§£ (MRC) åè³è¨æª¢ç´¢ (IR)ãæåå·è¡äºéåç®¡éä¸¦å¼å¥äº PUGG è³æéï¼éæ¯ç¬¬ä¸åæ³¢è­ KBQA è³æéï¼ä»¥å MRC å IR çæ°ç©è³æéãæ­¤å¤ï¼æåæä¾äºå¨é¢çå¯¦ä½ãæè¦å°çç¼ç¾ãè©³ç´°ççµ±è¨è³æååºæºæ¨¡åçè©ä¼°ã

##### **MedSyn: LLM-based Synthetic Medical Text Generation Framework**
2408.02056v1 by Gleb Kumichev, Pavel Blinov, Yulia Kuzkina, Vasily Goncharov, Galina Zubkova, Nikolai Zenovkin, Aleksei Goncharov, Andrey Savchenko

Generating synthetic text addresses the challenge of data availability in
privacy-sensitive domains such as healthcare. This study explores the
applicability of synthetic data in real-world medical settings. We introduce
MedSyn, a novel medical text generation framework that integrates large
language models with a Medical Knowledge Graph (MKG). We use MKG to sample
prior medical information for the prompt and generate synthetic clinical notes
with GPT-4 and fine-tuned LLaMA models. We assess the benefit of synthetic data
through application in the ICD code prediction task. Our research indicates
that synthetic data can increase the classification accuracy of vital and
challenging codes by up to 17.8% compared to settings without synthetic data.
Furthermore, to provide new data for further research in the healthcare domain,
we present the largest open-source synthetic dataset of clinical notes for the
Russian language, comprising over 41k samples covering 219 ICD-10 codes.

æè¦ï¼åæææ¬ççæè§£å³äºéç§ææé¢åï¼å¦å»çä¿å¥ï¼ä¸­æ°æ®å¯ç¨æ§çææãæ¬ç ç©¶æ¢è®¨äºåææ°æ®å¨å®éå»çç¯å¢ä¸­çéç¨æ§ãæä»¬å¼å¥äº MedSynï¼è¿æ¯ä¸ä¸ªæ°é¢çå»å­¦ææ¬çææ¡æ¶ï¼å®å°å¤§åè¯­è¨æ¨¡åä¸å»å­¦ç¥è¯å¾è°± (MKG) ç¸ç»åãæä»¬ä½¿ç¨ MKG ä¸ºæç¤ºéæ ·åéªå»å­¦ä¿¡æ¯ï¼å¹¶ä½¿ç¨ GPT-4 åå¾®è°ç LLaMA æ¨¡åçæåæä¸´åºæ³¨éãæä»¬éè¿å¨ ICD ä»£ç é¢æµä»»å¡ä¸­çåºç¨è¯ä¼°äºåææ°æ®çä¼å¿ãæä»¬çç ç©¶è¡¨æï¼ä¸æ²¡æåææ°æ®çè®¾ç½®ç¸æ¯ï¼åææ°æ®å¯ä»¥å°éè¦ä¸å·ææææ§çä»£ç çåç±»åç¡®æ§æé«å¤è¾¾ 17.8%ãæ­¤å¤ï¼ä¸ºäºä¸ºå»çä¿å¥é¢åçè¿ä¸æ­¥ç ç©¶æä¾æ°æ°æ®ï¼æä»¬å±ç¤ºäºæå¤§çå¼æ¾æºä»£ç åææ°æ®éï¼å¶ä¸­åå«è¶è¿ 41k ä¸ªæ¶µç 219 ä¸ª ICD-10 ä»£ç çä¸´åºæ³¨éã

##### **DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models**
2408.01933v2 by Bowen Wang, Jiuyang Chang, Yiming Qian, Guoxin Chen, Junhao Chen, Zhouqiang Jiang, Jiahao Zhang, Yuta Nakashima, Hajime Nagahara

Large language models (LLMs) have recently showcased remarkable capabilities,
spanning a wide range of tasks and applications, including those in the medical
domain. Models like GPT-4 excel in medical question answering but may face
challenges in the lack of interpretability when handling complex tasks in real
clinical settings. We thus introduce the diagnostic reasoning dataset for
clinical notes (DiReCT), aiming at evaluating the reasoning ability and
interpretability of LLMs compared to human doctors. It contains 511 clinical
notes, each meticulously annotated by physicians, detailing the diagnostic
reasoning process from observations in a clinical note to the final diagnosis.
Additionally, a diagnostic knowledge graph is provided to offer essential
knowledge for reasoning, which may not be covered in the training data of
existing LLMs. Evaluations of leading LLMs on DiReCT bring out a significant
gap between their reasoning ability and that of human doctors, highlighting the
critical need for models that can reason effectively in real-world clinical
scenarios.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æè¿å±ç¤ºäºéå¡çè½åï¼æ¶µèå»£æ³çä»»ååæç¨ï¼åæ¬é«çé åçä»»ååæç¨ãGPT-4 ç­æ¨¡åå¨é«çåé¡è§£ç­æ¹é¢è¡¨ç¾åºè²ï¼ä½å¨èçå¯¦éè¨åºå ´æ¯ä¸­çè¤éä»»åæï¼å¯è½æé¢è¨ç¼ºä¹å¯è§£éæ§çææ°ãå æ­¤ï¼æåå¼å¥äºè¨åºç­è¨è¨ºæ·æ¨çæ¸æé (DiReCT)ï¼æ¨å¨è©ä¼° LLM èäººé¡é«çç¸æ¯çæ¨çè½ååå¯è§£éæ§ãå®åå« 511 åè¨åºç­è¨ï¼æ¯åç­è¨é½ç¶éé«çä»ç´°è¨»è§£ï¼è©³ç´°èªªæäºå¾è¨åºç­è¨ä¸­çè§å¯çµæå°æçµè¨ºæ·çè¨ºæ·æ¨çéç¨ãæ­¤å¤ï¼éæä¾äºè¨ºæ·ç¥è­åè­ï¼ä»¥æä¾æ¨çæéçåºæ¬ç¥è­ï¼éå¯è½æªæ¶µèå¨ç¾æ LLM çè¨ç·´æ¸æä¸­ãå¨ DiReCT ä¸å°é åç LLM é²è¡è©ä¼°ï¼ç¼ç¾å®åçæ¨çè½åèäººé¡é«ççæ¨çè½åä¹éå­å¨é¡¯èå·®è·ï¼éçªé¡¯äºå¨ç¾å¯¦ä¸ççè¨åºå ´æ¯ä¸­è½å¤ æææ¨ççæ¨¡åçééµéæ±ã

##### **Integrating Large Language Models and Knowledge Graphs for Extraction and Validation of Textual Test Data**
2408.01700v1 by Antonio De Santis, Marco Balduini, Federico De Santis, Andrea Proia, Arsenio Leo, Marco Brambilla, Emanuele Della Valle

Aerospace manufacturing companies, such as Thales Alenia Space, design,
develop, integrate, verify, and validate products characterized by high
complexity and low volume. They carefully document all phases for each product
but analyses across products are challenging due to the heterogeneity and
unstructured nature of the data in documents. In this paper, we propose a
hybrid methodology that leverages Knowledge Graphs (KGs) in conjunction with
Large Language Models (LLMs) to extract and validate data contained in these
documents. We consider a case study focused on test data related to electronic
boards for satellites. To do so, we extend the Semantic Sensor Network
ontology. We store the metadata of the reports in a KG, while the actual test
results are stored in parquet accessible via a Virtual Knowledge Graph. The
validation process is managed using an LLM-based approach. We also conduct a
benchmarking study to evaluate the performance of state-of-the-art LLMs in
executing this task. Finally, we analyze the costs and benefits of automating
preexisting processes of manual data extraction and validation for subsequent
cross-report analyses.

æè¦ï¼èªå¤ªè£½é å¬å¸ï¼ä¾å¦æ³°é·è²é¿èå°¼äºå¤ªç©ºå¬å¸ï¼è¨­è¨ãéç¼ãæ´åãé©è­åé©è­ä»¥é«è¤éåº¦åä½é«ç©çºç¹å¾µçç¢åãä»åä»ç´°è¨éæ¯åç¢åçææéæ®µï¼ä½ç±æ¼æä»¶ä¸­è³æçç°è³ªæ§åéçµæ§åæ§è³ªï¼å°è´è·¨ç¢åçåæå·æææ°æ§ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ··åæ¹æ³ï¼å©ç¨ç¥è­åè­ (KG) çµåå¤§åèªè¨æ¨¡å (LLM)ï¼ä¾æ·ååé©è­éäºæä»¶ä¸­åå«çè³æãæåèæ®äºä¸åæ¡ä¾ç ç©¶ï¼éé»å¨æ¼è¡æé»å­é»è·¯æ¿çæ¸¬è©¦è³æãçºæ­¤ï¼æåæ´åäºèªç¾©ææ¸¬å¨ç¶²è·¯æ¬ä½ãæåå°å ±åçåè³æå²å­å¨ KG ä¸­ï¼èå¯¦éæ¸¬è©¦çµæå²å­å¨å¯ééèæ¬ç¥è­åè­å­åç Parquet ä¸­ãé©è­éç¨ä½¿ç¨åºæ¼ LLM çæ¹æ³ç®¡çãæåéé²è¡åºæºç ç©¶ï¼ä»¥è©ä¼°æåé²ç LLM å¨å·è¡æ­¤ä»»åæçæè½ãæå¾ï¼æååæäºèªååç¾ææåè³ææ·ååé©è­ç¨åºçææ¬åå¥½èï¼ä»¥é²è¡å¾çºçè·¨å ±ååæã

##### **DERA: Dense Entity Retrieval for Entity Alignment in Knowledge Graphs**
2408.01154v1 by Zhichun Wang, Xuan Chen

Entity Alignment (EA) aims to match equivalent entities in different
Knowledge Graphs (KGs), which is essential for knowledge fusion and
integration. Recently, embedding-based EA has attracted significant attention
and many approaches have been proposed. Early approaches primarily focus on
learning entity embeddings from the structural features of KGs, defined by
relation triples. Later methods incorporated entities' names and attributes as
auxiliary information to enhance embeddings for EA. However, these approaches
often used different techniques to encode structural and attribute information,
limiting their interaction and mutual enhancement. In this work, we propose a
dense entity retrieval framework for EA, leveraging language models to
uniformly encode various features of entities and facilitate nearest entity
search across KGs. Alignment candidates are first generated through entity
retrieval, which are subsequently reranked to determine the final alignments.
We conduct comprehensive experiments on both cross-lingual and monolingual EA
datasets, demonstrating that our approach achieves state-of-the-art performance
compared to existing EA methods.

æè¦ï¼å¯¦é«å°é½ (EA) æ¨å¨æ¯å°ä¸åç¥è­åè­ (KG) ä¸­çç­æå¯¦é«ï¼éå°æ¼ç¥è­èååæ´åéå¸¸éè¦ãæè¿ï¼åºæ¼åµå¥ç EA å·²å¼èµ·ç¸ç¶å¤§çéæ³¨ï¼ä¸¦ä¸å·²æåºè¨±å¤æ¹æ³ãæ©æçæ¹æ³ä¸»è¦å°æ³¨æ¼å¾ KG ççµæ§ç¹å¾µä¸­å­¸ç¿å¯¦é«åµå¥ï¼éäºç¹å¾µç±éä¿ä¸åçµå®ç¾©ãå¾çºçæ¹æ³å°å¯¦é«çåç¨±åå±¬æ§ä½çºè¼å©è³è¨ï¼ä»¥å¢å¼· EA çåµå¥ãç¶èï¼éäºæ¹æ³éå¸¸ä½¿ç¨ä¸åçæè¡ä¾ç·¨ç¢¼çµæ§åå±¬æ§è³è¨ï¼éå¶äºå®åçäºååç¸äºå¢å¼·ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸åå¯éå¯¦é«æ·åæ¶æ§ï¼ç¨æ¼ EAï¼å©ç¨èªè¨æ¨¡åä¾çµ±ä¸ç·¨ç¢¼å¯¦é«çåç¨®ç¹å¾µï¼ä¸¦ä¿é²è·¨ KG çæè¿å¯¦é«æå°ãå°é½åé¸èé¦åééå¯¦é«æ·åç¢çï¼ç¶å¾éæ°æåºä»¥ç¢ºå®æçµå°é½ãæåå°è·¨èªè¨åå®èªè¨ EA è³æéé²è¡äºå¨é¢çå¯¦é©ï¼è­æèç¾æç EA æ¹æ³ç¸æ¯ï¼æåçåæ³éå°äºæåé²çæè½ã

##### **Bridging Information Gaps in Dialogues With Grounded Exchanges Using Knowledge Graphs**
2408.01088v1 by Phillip Schneider, Nektarios Machner, Kristiina Jokinen, Florian Matthes

Knowledge models are fundamental to dialogue systems for enabling
conversational interactions, which require handling domain-specific knowledge.
Ensuring effective communication in information-providing conversations entails
aligning user understanding with the knowledge available to the system.
However, dialogue systems often face challenges arising from semantic
inconsistencies in how information is expressed in natural language compared to
how it is represented within the system's internal knowledge. To address this
problem, we study the potential of large language models for conversational
grounding, a mechanism to bridge information gaps by establishing shared
knowledge between dialogue participants. Our approach involves annotating human
conversations across five knowledge domains to create a new dialogue corpus
called BridgeKG. Through a series of experiments on this dataset, we
empirically evaluate the capabilities of large language models in classifying
grounding acts and identifying grounded information items within a knowledge
graph structure. Our findings offer insights into how these models use
in-context learning for conversational grounding tasks and common prediction
errors, which we illustrate with examples from challenging dialogues. We
discuss how the models handle knowledge graphs as a semantic layer between
unstructured dialogue utterances and structured information items.

æè¦ï¼ç¥è­æ¨¡åæ¯å°è©±ç³»çµ±çåºæ¬è¦ç´ ï¼ç¨æ¼åç¨å°è©±äºåï¼ééè¦èçç¹å®é åçç¥è­ãç¢ºä¿å¨æä¾è³è¨çå°è©±ä¸­é²è¡ææçæºéï¼éè¦å°ä½¿ç¨èççè§£èç³»çµ±å¯ç¨çç¥è­çµåèµ·ä¾ãç¶èï¼å°è©±ç³»çµ±ç¶å¸¸é¢è¨èªæä¸ä¸è´çææ°ï¼å¨èªç¶èªè¨ä¸­è¡¨éè³è¨çæ¹å¼èå¨ç³»çµ±å§é¨ç¥è­ä¸­è¡¨ç¤ºè³è¨çæ¹å¼ä¸åãçºäºè§£æ±ºéååé¡ï¼æåç ç©¶å¤§åèªè¨æ¨¡åå¨å°è©±åºç¤ä¸­çæ½åï¼éæ¯ä¸ç¨®ééå¨å°è©±åèèä¹éå»ºç«å±äº«ç¥è­ä¾å½åè³è¨å·®è·çæ©å¶ãæåçåæ³åæ¬è¨»è§£äºåç¥è­é åä¸­çäººé¡å°è©±ï¼ä»¥å»ºç«ä¸åæ°çå°è©±èªæåº«ï¼ç¨±çº BridgeKGãééå°æ­¤è³æéé²è¡ä¸ç³»åå¯¦é©ï¼æåå¯¦è­è©ä¼°å¤§åèªè¨æ¨¡åå¨åé¡åºç¤è¡çºåè­å¥ç¥è­åçµæ§ä¸­çåºç¤è³è¨é ç®çè½åãæåçç¼ç¾æä¾äºéæ¼éäºæ¨¡åå¦ä½ä½¿ç¨æå¢å­¸ç¿ä¾é²è¡å°è©±åºç¤ä»»ååå¸¸è¦é æ¸¬é¯èª¤çè¦è§£ï¼æåç¨å·æææ°æ§çå°è©±ç¯ä¾ä¾èªªæãæåè¨è«æ¨¡åå¦ä½å°ç¥è­åå½¢è¦çºéçµæ§åå°è©±èªå¥åçµæ§åè³è¨é ç®ä¹éçèªæå±¤ã

##### **Automatic Extraction of Relationships among Motivations, Emotions and Actions from Natural Language Texts**
2408.00966v1 by Fei Yang

We propose a new graph-based framework to reveal relationships among
motivations, emotions and actions explicitly given natural language texts. A
directed acyclic graph is designed to describe human's nature. Nurture beliefs
are incorporated to connect outside events and the human's nature graph. No
annotation resources are required due to the power of large language models.
Amazon Fine Foods Reviews dataset is used as corpus and food-related
motivations are focused. Totally 92,990 relationship graphs are generated, of
which 63% make logical sense. We make further analysis to investigate error
types for optimization direction in future research.

æè¦ï¼æåæåºä¸åæ°çåºæ¼åå½¢çæ¶æ§ï¼ç¨æ¼æ­ç¤ºå¨èªç¶èªè¨ææ¬ä¸­æç¢ºçµ¦åºçåæ©ãæç·ååä½ä¹éçéä¿ãæåç¡ç°åè¢«è¨­è¨ç¨æ¼æè¿°äººé¡çæ¬æ§ãå¹é¤ä¿¡å¿µè¢«ç´å¥å¶ä¸­ï¼ç¨æ¼é£æ¥å¤é¨äºä»¶åäººé¡çæ¬æ§åãç±æ¼å¤§åèªè¨æ¨¡åçå¼·å¤§åè½ï¼ä¸éè¦è¨»è§£è³æºãäºé¦¬éç¾é£è©è«æ¸æéè¢«ç¨ä½èªæåº«ï¼ä¸¦ä¸éé»éæ³¨èé£ç©ç¸éçåæ©ãç¸½å±çæäº 92,990 åéä¿åï¼å¶ä¸­ 63% å·æéè¼¯æç¾©ãæåé²ä¸æ­¥åæä»¥èª¿æ¥é¯èª¤é¡åï¼ä»¥ä¾¿çºæªä¾çç ç©¶æä¾åªåæ¹åã

##### **DisTrack: a new Tool for Semi-automatic Misinformation Tracking in Online Social Networks**
2408.00633v1 by Guillermo Villar-RodrÃ­guez, Ãlvaro Huertas-GarcÃ­a, Alejandro MartÃ­n, Javier Huertas-Tato, David Camacho

Introduction: This article introduces DisTrack, a methodology and a tool
developed for tracking and analyzing misinformation within Online Social
Networks (OSNs). DisTrack is designed to combat the spread of misinformation
through a combination of Natural Language Processing (NLP) Social Network
Analysis (SNA) and graph visualization. The primary goal is to detect
misinformation, track its propagation, identify its sources, and assess the
influence of various actors within the network.
  Methods: DisTrack's architecture incorporates a variety of methodologies
including keyword search, semantic similarity assessments, and graph generation
techniques. These methods collectively facilitate the monitoring of
misinformation, the categorization of content based on alignment with known
false claims, and the visualization of dissemination cascades through detailed
graphs. The tool is tailored to capture and analyze the dynamic nature of
misinformation spread in digital environments.
  Results: The effectiveness of DisTrack is demonstrated through three case
studies focused on different themes: discredit/hate speech, anti-vaccine
misinformation, and false narratives about the Russia-Ukraine conflict. These
studies show DisTrack's capabilities in distinguishing posts that propagate
falsehoods from those that counteract them, and tracing the evolution of
misinformation from its inception.
  Conclusions: The research confirms that DisTrack is a valuable tool in the
field of misinformation analysis. It effectively distinguishes between
different types of misinformation and traces their development over time. By
providing a comprehensive approach to understanding and combating
misinformation in digital spaces, DisTrack proves to be an essential asset for
researchers and practitioners working to mitigate the impact of false
information in online social environments.

æè¦ï¼<paragraph>å¼è¨ï¼æ¬æä»ç´¹ DisTrackï¼éæ¯ä¸ç¨®æ¹æ³åå·¥å·ï¼ç¨æ¼è¿½è¹¤ååæç·ä¸ç¤¾äº¤ç¶²è·¯ï¼OSNï¼ä¸­çé¯èª¤è³è¨ãDisTrack çè¨­è¨ç®çæ¯ééçµåèªç¶èªè¨èçï¼NLPï¼ãç¤¾äº¤ç¶²è·¯åæï¼SNAï¼ååå½¢è¦è¦ºåä¾å°æé¯èª¤è³è¨çæ£å¸ãä¸»è¦ç®æ¨æ¯åµæ¸¬é¯èª¤è³è¨ãè¿½è¹¤å¶å³æ­ãæ¾åºå¶ä¾æºï¼ä¸¦è©ä¼°ç¶²è·¯ä¸­åååèèçå½±é¿åã
æ¹æ³ï¼DisTrack çæ¶æ§çµåäºå¤ç¨®æ¹æ³ï¼åæ¬ééµå­æå°ãèªæç¸ä¼¼æ§è©ä¼°ååå½¢ç¢çæè¡ãéäºæ¹æ³å±åä¿é²äºé¯èª¤è³è¨çç£æ§ãåºæ¼èå·²ç¥èåèªªæ³çæ¯å°ä¾åé¡å§å®¹ï¼ä»¥åééè©³ç´°åå½¢è¦è¦ºåå³æ­å±¤çãæ­¤å·¥å·ç¶ééèº«æé ï¼ç¨æ¼æ·åååææ¸ä½ç°å¢ä¸­é¯èª¤è³è¨æ£å¸çåæç¹æ§ã
çµæï¼DisTrack çæè½ééä¸åæ¡ä¾ç ç©¶ç²å¾é©è­ï¼éäºç ç©¶å°æ³¨æ¼ä¸åçä¸»é¡ï¼è²¶ä½/ä»æ¨è¨è«ãåç«èé¯èª¤è³è¨ï¼ä»¥åéæ¼ä¿ç¾æ¯-çåè­è¡çªçèåæè¿°ãéäºç ç©¶é¡¯ç¤ºåº DisTrack å¨ååå³æ­èåè³è¨ååå¶èåè³è¨çè²¼æï¼ä»¥åè¿½è¹¤é¯èª¤è³è¨å¾å¶éç«¯æ¼è®çéç¨ä¸­æå·åçè½åã
çµè«ï¼ç ç©¶è­å¯¦ DisTrack æ¯é¯èª¤è³è¨åæé åä¸­ä¸åæå¹å¼çå·¥å·ãå®ææååäºä¸åé¡åçé¯èª¤è³è¨ï¼ä¸¦è¿½è¹¤å¶é¨èæéæ¨ç§»çç¼å±ãééæä¾ä¸ç¨®å¨é¢çæ¹æ³ä¾çè§£åå°ææ¸ä½ç©ºéä¸­çé¯èª¤è³è¨ï¼DisTrack è­æäºèªå·±æ¯åå©ç ç©¶äººå¡åå¯¦åå·¥ä½èæ¸è¼ç·ä¸ç¤¾äº¤ç°å¢ä¸­èåè³è¨å½±é¿åçéè¦è³ç¢ã</paragraph>

##### **On the Limitations and Prospects of Machine Unlearning for Generative AI**
2408.00376v1 by Shiji Zhou, Lianzhe Wang, Jiangnan Ye, Yongliang Wu, Heng Chang

Generative AI (GenAI), which aims to synthesize realistic and diverse data
samples from latent variables or other data modalities, has achieved remarkable
results in various domains, such as natural language, images, audio, and
graphs. However, they also pose challenges and risks to data privacy, security,
and ethics. Machine unlearning is the process of removing or weakening the
influence of specific data samples or features from a trained model, without
affecting its performance on other data or tasks. While machine unlearning has
shown significant efficacy in traditional machine learning tasks, it is still
unclear if it could help GenAI become safer and aligned with human desire. To
this end, this position paper provides an in-depth discussion of the machine
unlearning approaches for GenAI. Firstly, we formulate the problem of machine
unlearning tasks on GenAI and introduce the background. Subsequently, we
systematically examine the limitations of machine unlearning on GenAI models by
focusing on the two representative branches: LLMs and image generative
(diffusion) models. Finally, we provide our prospects mainly from three
aspects: benchmark, evaluation metrics, and utility-unlearning trade-off, and
conscientiously advocate for the future development of this field.

æè¦ï¼çæå¼ AI (GenAI) æ¨å¨å¾æ½å¨è®æ¸æå¶ä»è³ææ¨¡å¼ä¸­åæé¼çä¸å¤æ¨£åçè³æç¯ä¾ï¼å·²å¨èªç¶èªè¨ãå½±åãé³è¨ååå½¢ç­åç¨®é åä¸­åå¾é¡¯èææãç¶èï¼å®åä¹å°è³æé±ç§ãå®å¨æ§èéå¾·æ§æææ°åé¢¨éªãæ©å¨éºå¿æ¯ç§»é¤ææ¸å¼±ç¹å®è³æç¯ä¾æç¹å¾µå°å·²è¨ç·´æ¨¡åçå½±é¿ï¼åæä¸å½±é¿å¶å¨å¶ä»è³ææä»»åä¸çæè½ãéç¶æ©å¨éºå¿å·²å¨å³çµ±æ©å¨å­¸ç¿ä»»åä¸­å±ç¾é¡¯èçåæï¼ä½ä»ä¸æ¸æ¥å®æ¯å¦è½åå© GenAI è®å¾æ´å®å¨ä¸ç¬¦åäººé¡çææãçºæ­¤ï¼æ¬ç«å ´æä»¶æ·±å¥æ¢è¨äº GenAI çæ©å¨éºå¿æ¹æ³ãé¦åï¼æåå¶å® GenAI ä¸æ©å¨éºå¿ä»»åçåé¡ï¼ä¸¦ä»ç´¹èæ¯ãæ¥èï¼æåæç³»çµ±å°æª¢è¦æ©å¨éºå¿å¨ GenAI æ¨¡åä¸çéå¶ï¼éé»æ¾å¨å©åä»£è¡¨æ§çåæ¯ï¼LLM åå½±åçæï¼æ´æ£ï¼æ¨¡åãæå¾ï¼æåä¸»è¦å¾åºæºãè©ä¼°ææ¨åæç¨éºå¿æ¬è¡¡ä¸åé¢åæä¾æåçå±æï¼ä¸¦å¯©æå¡è­°è©²é åçæªä¾ç¼å±ã

##### **Multi-Modal Parameter-Efficient Fine-tuning via Graph Neural Network**
2408.00290v1 by Bin Cheng, Jiaxuan Lu

With the advent of the era of foundation models, pre-training and fine-tuning
have become common paradigms. Recently, parameter-efficient fine-tuning has
garnered widespread attention due to its better balance between the number of
learnable parameters and performance. However, some current parameter-efficient
fine-tuning methods only model a single modality and lack the utilization of
structural knowledge in downstream tasks. To address this issue, this paper
proposes a multi-modal parameter-efficient fine-tuning method based on graph
networks. Each image is fed into a multi-modal large language model (MLLM) to
generate a text description. The image and its corresponding text description
are then processed by a frozen image encoder and text encoder to generate image
features and text features, respectively. A graph is constructed based on the
similarity of the multi-modal feature nodes, and knowledge and relationships
relevant to these features are extracted from each node. Additionally, Elastic
Weight Consolidation (EWC) regularization is incorporated into the loss
function to mitigate the problem of forgetting during task learning. The
proposed model achieves test accuracies on the OxfordPets, Flowers102, and
Food101 datasets that improve by 4.45%, 2.92%, and 0.23%, respectively. The
code is available at https://github.com/yunche0/GA-Net/tree/master.

æè¦ï¼é¨èåºç¤æ¨¡åæä»£çå°ä¾ï¼é è¨ç·´åå¾®èª¿å·²æçºå¸¸è¦çç¯ä¾ãæè¿ï¼ç±æ¼åæ¸ææå¾®èª¿å¨å¯å­¸ç¿åæ¸æ¸éåæè½ä¹éåå¾æ´å¥½çå¹³è¡¡ï¼å æ­¤ååéæ³¨ãç¶èï¼ä¸äºç®åçåæ¸ææå¾®èª¿æ¹æ³åå»ºæ¨¡å®ä¸æ¨¡æï¼ä¸ç¼ºä¹å¨ä¸æ¸¸ä»»åä¸­å©ç¨çµæ§ç¥è­ãçºäºè§£æ±ºæ­¤åé¡ï¼æ¬ææåºäºä¸ç¨®åºæ¼åå½¢ç¶²è·¯çå¤æ¨¡æåæ¸ææå¾®èª¿æ¹æ³ãæ¯åå½±åé½æè¼¸å¥å°å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) ä¸­ï¼ä»¥ç¢çæå­æè¿°ãç¶å¾ï¼å½±ååå¶å°æçæå­æè¿°æç±åçµçå½±åç·¨ç¢¼å¨åæå­ç·¨ç¢¼å¨èçï¼åå¥ç¢çå½±åç¹å¾µåæå­ç¹å¾µãæ ¹æå¤æ¨¡æç¹å¾µç¯é»çç¸ä¼¼æ§å»ºæ§ä¸ååå½¢ï¼ä¸¦å¾æ¯åç¯é»ä¸­èååºèéäºç¹å¾µç¸éçç¥è­åéä¿ãæ­¤å¤ï¼å½æ§æ¬éæ´å (EWC) æ­£ååæç´å¥æå¤±å½æ¸ä¸­ï¼ä»¥æ¸è¼å¨ä»»åå­¸ç¿æééºå¿çåé¡ãææåºçæ¨¡åå¨ OxfordPetsãFlowers102 å Food101 è³æéä¸éæçæ¸¬è©¦æºç¢ºåº¦åå¥æåäº 4.45%ã2.92% å 0.23%ãç¨å¼ç¢¼å¯å¨ https://github.com/yunche0/GA-Net/tree/master åå¾ã

##### **CEAR: Automatic construction of a knowledge graph of chemical entities and roles from scientific literature**
2407.21708v1 by Stefan Langer, Fabian Neuhaus, Andreas NÃ¼rnberger

Ontologies are formal representations of knowledge in specific domains that
provide a structured framework for organizing and understanding complex
information. Creating ontologies, however, is a complex and time-consuming
endeavor. ChEBI is a well-known ontology in the field of chemistry, which
provides a comprehensive resource for defining chemical entities and their
properties. However, it covers only a small fraction of the rapidly growing
knowledge in chemistry and does not provide references to the scientific
literature. To address this, we propose a methodology that involves augmenting
existing annotated text corpora with knowledge from Chebi and fine-tuning a
large language model (LLM) to recognize chemical entities and their roles in
scientific text. Our experiments demonstrate the effectiveness of our approach.
By combining ontological knowledge and the language understanding capabilities
of LLMs, we achieve high precision and recall rates in identifying both the
chemical entities and roles in scientific literature. Furthermore, we extract
them from a set of 8,000 ChemRxiv articles, and apply a second LLM to create a
knowledge graph (KG) of chemical entities and roles (CEAR), which provides
complementary information to ChEBI, and can help to extend it.

æè¦ï¼æ¬ä½æ¯ç¹å®é åä¸­ç¥è­çå½¢å¼åè¡¨ç¤ºï¼å®æä¾äºä¸åçµæ§åçæ¡æ¶ï¼ç¨æ¼çµç¹åçè§£è¤éçè³è¨ãç¶èï¼å»ºç«æ¬ä½æ¯ä¸é è¤éä¸èæçåªåãChEBI æ¯åå­¸é åä¸­ä¸åèåçæ¬ä½ï¼å®æä¾äºä¸åå¨é¢çè³æºï¼ç¨æ¼å®ç¾©åå­¸å¯¦é«åå¶å±¬æ§ãç¶èï¼å®åæ¶µèäºåå­¸é åå¿«éå¢é·çç¥è­ä¸­çä¸å°é¨åï¼ä¸¦ä¸æ²ææä¾ç§å­¸æç»çåèãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ç¨®æ¹æ³ï¼å®æ¶åä½¿ç¨ä¾èª Chebi çç¥è­æ´åç¾æçè¨»éææ¬èªæåº«ï¼ä¸¦å¾®èª¿å¤§åèªè¨æ¨¡å (LLM)ï¼ä»¥è­å¥åå­¸å¯¦é«åå¶å¨ç§å­¸ææ¬ä¸­çä½ç¨ãæåçå¯¦é©è­æäºæåæ¹æ³çæææ§ãééçµåæ¬ä½ç¥è­å LLM çèªè¨çè§£è½åï¼æåå¨è­å¥ç§å­¸æç»ä¸­çåå­¸å¯¦é«åä½ç¨æ¹é¢éå°äºå¾é«çæºç¢ºåº¦åå¬åçãæ­¤å¤ï¼æåå¾ä¸çµ 8,000 ç¯ ChemRxiv æç« ä¸­æåå®åï¼ä¸¦æç¨ç¬¬äºå LLM ä¾å»ºç«ä¸ååå­¸å¯¦é«åä½ç¨ (CEAR) çç¥è­åè­ (KG)ï¼å®æä¾è£å ChEBI çè³è¨ï¼ä¸¦æå©æ¼æ´åå®ã

##### **eSPARQL: Representing and Reconciling Agnostic and Atheistic Beliefs in RDF-star Knowledge Graphs**
2407.21483v3 by Xinyi Pan, Daniel HernÃ¡ndez, Philipp Seifer, Ralf LÃ¤mmel, Steffen Staab

Over the past few years, we have seen the emergence of large knowledge graphs
combining information from multiple sources. Sometimes, this information is
provided in the form of assertions about other assertions, defining contexts
where assertions are valid. A recent extension to RDF which admits statements
over statements, called RDF-star, is in revision to become a W3C standard.
However, there is no proposal for a semantics of these RDF-star statements nor
a built-in facility to operate over them. In this paper, we propose a query
language for epistemic RDF-star metadata based on a four-valued logic, called
eSPARQL. Our proposed query language extends SPARQL-star, the query language
for RDF-star, with a new type of FROM clause to facilitate operating with
multiple and sometimes conflicting beliefs. We show that the proposed query
language can express four use case queries, including the following features:
(i) querying the belief of an individual, (ii) the aggregating of beliefs,
(iii) querying who is conflicting with somebody, and (iv) beliefs about beliefs
(i.e., nesting of beliefs).

æè¦ï¼å¨éå»å¹¾å¹´ï¼æåè¦è­äºå¤§åç¥è­åè­çåºç¾ï¼çµåä¾èªå¤åä¾æºçè³è¨ãææï¼éäºè³è¨æä»¥å°å¶ä»æ·è¨çæ·è¨å½¢å¼æä¾ï¼å®ç¾©æ·è¨ææçèçµ¡ãæè¿å° RDF çæ´åï¼åè¨±å°é³è¿°é²è¡é³è¿°ï¼ç¨±çº RDF-starï¼æ­£å¨ä¿®è¨çº W3C æ¨æºãç¶èï¼ç®åæ²æéå°éäº RDF-star é³è¿°çèªæå»ºè­°ï¼ä¹æ²æå§å»ºçéä½åè½ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®åºæ¼åå¼éè¼¯çç¥è­ RDF-star åè³ææ¥è©¢èªè¨ï¼ç¨±çº eSPARQLãæåæåºçæ¥è©¢èªè¨æ´åäº RDF-star çæ¥è©¢èªè¨ SPARQL-starï¼æ°å¢ä¸ç¨® FROM å­å¥é¡åï¼ä»¥å©æ¼ä½¿ç¨å¤éä¸ææç¸äºè¡çªçä¿¡å¿µé²è¡éä½ãæåå±ç¤ºäºææåºçæ¥è©¢èªè¨å¯ä»¥è¡¨éåç¨®ä½¿ç¨æ¡ä¾æ¥è©¢ï¼åæ¬ä»¥ä¸åè½ï¼(i) æ¥è©¢åäººçä¿¡å¿µï¼(ii) å½ç¸½ä¿¡å¿µï¼(iii) æ¥è©¢èæäººè¡çªçæ¯èª°ï¼ä»¥å (iv) éæ¼ä¿¡å¿µçä¿¡å¿µï¼å³ä¿¡å¿µçå·¢çï¼ã

##### **Navigating Beyond Instructions: Vision-and-Language Navigation in Obstructed Environments**
2407.21452v1 by Haodong Hong, Sen Wang, Zi Huang, Qi Wu, Jiajun Liu

Real-world navigation often involves dealing with unexpected obstructions
such as closed doors, moved objects, and unpredictable entities. However,
mainstream Vision-and-Language Navigation (VLN) tasks typically assume
instructions perfectly align with the fixed and predefined navigation graphs
without any obstructions. This assumption overlooks potential discrepancies in
actual navigation graphs and given instructions, which can cause major failures
for both indoor and outdoor agents. To address this issue, we integrate diverse
obstructions into the R2R dataset by modifying both the navigation graphs and
visual observations, introducing an innovative dataset and task, R2R with
UNexpected Obstructions (R2R-UNO). R2R-UNO contains various types and numbers
of path obstructions to generate instruction-reality mismatches for VLN
research. Experiments on R2R-UNO reveal that state-of-the-art VLN methods
inevitably encounter significant challenges when facing such mismatches,
indicating that they rigidly follow instructions rather than navigate
adaptively. Therefore, we propose a novel method called ObVLN (Obstructed VLN),
which includes a curriculum training strategy and virtual graph construction to
help agents effectively adapt to obstructed environments. Empirical results
show that ObVLN not only maintains robust performance in unobstructed scenarios
but also achieves a substantial performance advantage with unexpected
obstructions.

æè¦ï¼ç°å®ä¸ççå¯¼èªéå¸¸æ¶åå¤çæå¤çéç¢ï¼ä¾å¦å³ççé¨ãç§»å¨çç©ä½åä¸å¯é¢æµçå®ä½ãç¶èï¼ä¸»æµçè§è§åè¯­è¨å¯¼èª (VLN) ä»»å¡éå¸¸åè®¾æä»¤ä¸åºå®çåé¢å®ä¹çå¯¼èªå¾å®å¨ä¸è´ï¼æ²¡æä»»ä½éç¢ãè¿ç§åè®¾å¿½ç¥äºå®éå¯¼èªå¾åç»å®æä»¤ä¸­æ½å¨çå·®å¼ï¼è¿å¯è½ä¼å¯¼è´å®¤ååå®¤å¤ä»£çåºç°éå¤§æéãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬éè¿ä¿®æ¹å¯¼èªå¾åè§è§è§å¯ï¼å°åç§éç¢æ´åå° R2R æ°æ®éä¸­ï¼å¼å¥äºåæ°æ°æ®éåä»»å¡ï¼å³å¸¦ææå¤éç¢ç R2R (R2R-UNO)ãR2R-UNO åå«åç§ç±»ååæ°éçè·¯å¾éç¢ï¼ä»¥çæ VLN ç ç©¶çæä»¤-ç°å®ä¸å¹éãå¨ R2R-UNO ä¸çå®éªè¡¨æï¼æåè¿ç VLN æ¹æ³å¨é¢å¯¹æ­¤ç±»ä¸å¹éæ¶ä¸å¯é¿åå°ä¼éå°éå¤§ææï¼è¿è¡¨æå®ä»¬ä¸¥æ ¼éµå¾ªæä»¤ï¼èä¸æ¯èªéåºå°å¯¼èªãå æ­¤ï¼æä»¬æåºäºä¸ç§ç§°ä¸º ObVLNï¼åé» VLNï¼çæ°æ¹æ³ï¼å¶ä¸­åæ¬è¯¾ç¨è®­ç»ç­ç¥åèæå¾æå»ºï¼ä»¥å¸®å©ä»£çææå°éåºåé»ç¯å¢ãç»éªç»æè¡¨æï¼ObVLN ä¸ä»å¨æ éç¢åºæ¯ä¸­ä¿æäºç¨³å¥çæ§è½ï¼èä¸å¨æå¤éç¢ä¸­ä¹è·å¾äºå®è´¨æ§çæ§è½ä¼å¿ã

##### **Tree-of-Traversals: A Zero-Shot Reasoning Algorithm for Augmenting Black-box Language Models with Knowledge Graphs**
2407.21358v1 by Elan Markowitz, Anil Ramakrishna, Jwala Dhamala, Ninareh Mehrabi, Charith Peris, Rahul Gupta, Kai-Wei Chang, Aram Galstyan

Knowledge graphs (KGs) complement Large Language Models (LLMs) by providing
reliable, structured, domain-specific, and up-to-date external knowledge.
However, KGs and LLMs are often developed separately and must be integrated
after training. We introduce Tree-of-Traversals, a novel zero-shot reasoning
algorithm that enables augmentation of black-box LLMs with one or more KGs. The
algorithm equips a LLM with actions for interfacing a KG and enables the LLM to
perform tree search over possible thoughts and actions to find high confidence
reasoning paths. We evaluate on two popular benchmark datasets. Our results
show that Tree-of-Traversals significantly improves performance on question
answering and KG question answering tasks. Code is available at
\url{https://github.com/amazon-science/tree-of-traversals}

æè¦ï¼ç¥è­åè­ (KG) ééæä¾å¯é ãçµæ§åãç¹å®æ¼é åä¸ææ°çå¤é¨ç¥è­ï¼ä¾è£åå¤§åèªè¨æ¨¡å (LLM)ã
ç¶èï¼KG å LLM éå¸¸æ¯åééç¼ï¼ä¸¦ä¸å¿é å¨è¨ç·´å¾æ´åãæåä»ç´¹äº Tree-of-Traversalsï¼ä¸ç¨®æ°ç©çé¶æ¬¡æ¨çæ¼ç®æ³ï¼å®è½è®é»ç LLM ä½¿ç¨ä¸åæå¤å KGãè©²æ¼ç®æ³çº LLM æä¾è KG ä»é¢çåä½ï¼ä¸¦è® LLM è½å¨å¯è½çæèååä½ä¸å·è¡æ¨¹çæå°ï¼ä»¥æ¾åºé«åº¦ä¿¡å¿çæ¨çè·¯å¾ãæåå¨å©åç±éçåºæºè³æéä¸é²è¡è©ä¼°ãæåççµæé¡¯ç¤ºï¼Tree-of-Traversals å¤§å¹æåäºåé¡è§£ç­å KG åé¡è§£ç­ä»»åçæè½ãç¨å¼ç¢¼å¯å¨ \url{https://github.com/amazon-science/tree-of-traversals} åå¾

##### **SimpleLLM4AD: An End-to-End Vision-Language Model with Graph Visual Question Answering for Autonomous Driving**
2407.21293v1 by Peiru Zheng, Yun Zhao, Zhan Gong, Hong Zhu, Shaohua Wu

Many fields could benefit from the rapid development of the large language
models (LLMs). The end-to-end autonomous driving (e2eAD) is one of the
typically fields facing new opportunities as the LLMs have supported more and
more modalities. Here, by utilizing vision-language model (VLM), we proposed an
e2eAD method called SimpleLLM4AD. In our method, the e2eAD task are divided
into four stages, which are perception, prediction, planning, and behavior.
Each stage consists of several visual question answering (VQA) pairs and VQA
pairs interconnect with each other constructing a graph called Graph VQA
(GVQA). By reasoning each VQA pair in the GVQA through VLM stage by stage, our
method could achieve e2e driving with language. In our method, vision
transformers (ViT) models are employed to process nuScenes visual data, while
VLM are utilized to interpret and reason about the information extracted from
the visual inputs. In the perception stage, the system identifies and
classifies objects from the driving environment. The prediction stage involves
forecasting the potential movements of these objects. The planning stage
utilizes the gathered information to develop a driving strategy, ensuring the
safety and efficiency of the autonomous vehicle. Finally, the behavior stage
translates the planned actions into executable commands for the vehicle. Our
experiments demonstrate that SimpleLLM4AD achieves competitive performance in
complex driving scenarios.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çå¿«éç¼å±å¯è½ä½¿è¨±å¤é ååçãç«¯å°ç«¯èªåé§é§ (e2eAD) æ¯å¸åé åä¹ä¸ï¼å çº LLM æ¯æ´è¶ä¾è¶å¤çæ¨¡å¼ï¼å æ­¤é¢è¨æ°çæ©æãå¨æ­¤ï¼ééå©ç¨è¦è¦ºèªè¨æ¨¡å (VLM)ï¼æåæåºäºä¸åç¨±çº SimpleLLM4AD ç e2eAD æ¹æ³ãå¨æåçæ¨¡åä¸­ï¼e2eAD ä»»ååçºååéæ®µï¼åå¥æ¯æç¥ãé æ¸¬ãè¦ååè¡çºãæ¯åéæ®µåå«å¤åè¦è¦ºåç­ (VQA) éå°ï¼ä¸ VQA éå°ç¸äºé£æ¥ï¼æ§å»ºä¸åç¨±çºåå½¢ VQA (GVQA) çåå½¢ãéé VLM åéæ®µæ¨ç GVQA ä¸­çæ¯å VQA éå°ï¼æåçæ¨¡åå¯ä»¥ééèªè¨å¯¦ç¾ç«¯å°ç«¯é§é§ãå¨æåçæ¨¡åä¸­ï¼æ¡ç¨è¦è¦ºTransformer (ViT) æ¨¡åä¾èç nuScenes è¦è¦ºè³æï¼åæå©ç¨ VLM ä¾è©®éåæ¨çå¾è¦è¦ºè¼¸å¥ä¸­æåçè³è¨ãå¨æç¥éæ®µï¼ç³»çµ±è­å¥ååé¡é§é§ç°å¢ä¸­çç©ä»¶ãé æ¸¬éæ®µæ¶åé æ¸¬éäºç©ä»¶çæ½å¨ç§»åãè¦åéæ®µå©ç¨æ¶éçè³è¨ä¾å¶å®é§é§ç­ç¥ï¼ç¢ºä¿èªåé§é§æ±½è»çå®å¨æ§åæçãæå¾ï¼è¡çºéæ®µå°è¦åçåä½è½æçºè»è¼å¯å·è¡çå½ä»¤ãæåçå¯¦é©è­æï¼SimpleLLM4AD å¨è¤éçé§é§å ´æ¯ä¸­å¯¦ç¾äºç«¶ç­åã

##### **Be aware of overfitting by hyperparameter optimization!**
2407.20786v1 by Igor V. Tetko, Ruud van Deursen, Guillaume Godin

Hyperparameter optimization is very frequently employed in machine learning.
However, an optimization of a large space of parameters could result in
overfitting of models. In recent studies on solubility prediction the authors
collected seven thermodynamic and kinetic solubility datasets from different
data sources. They used state-of-the-art graph-based methods and compared
models developed for each dataset using different data cleaning protocols and
hyperparameter optimization. In our study we showed that hyperparameter
optimization did not always result in better models, possibly due to
overfitting when using the same statistical measures. Similar results could be
calculated using pre-set hyperparameters, reducing the computational effort by
around 10,000 times. We also extended the previous analysis by adding a
representation learning method based on Natural Language Processing of smiles
called Transformer CNN. We show that across all analyzed sets using exactly the
same protocol, Transformer CNN provided better results than graph-based methods
for 26 out of 28 pairwise comparisons by using only a tiny fraction of time as
compared to other methods. Last but not least we stressed the importance of
comparing calculation results using exactly the same statistical measures.

æè¦ï¼æ©å¨å­¸ç¿ä¸­éå¸¸é »ç¹å°ä½¿ç¨è¶åæ¸æä½³åã
ç¶èï¼å°å¤§åæ¸ç©ºéé²è¡æä½³åå¯è½æå°è´æ¨¡åéæ¬åãå¨æè¿å°æº¶è§£åº¦é æ¸¬çç ç©¶ä¸­ï¼ä½èå¾ä¸åçæ¸ææºæ¶éäºä¸åç±åå­¸åååå­¸æº¶è§£åº¦æ¸æéãä»åä½¿ç¨äºæåé²çåºæ¼åå½¢çæ¹æ³ï¼ä¸¦æ¯è¼äºä½¿ç¨ä¸åçæ¸ææ¸æ´åè­°åè¶åæ¸æä½³åçºæ¯åæ¸æééç¼çæ¨¡åãå¨æåçç ç©¶ä¸­ï¼æåè¡¨æè¶åæ¸æä½³åä¸¦éç¸½æ¯æç¢çæ´å¥½çæ¨¡åï¼éå¯è½æ¯ç±æ¼å¨ä½¿ç¨ç¸åççµ±è¨æ¸¬éæç¼çéæ¬åãå¯ä»¥ä½¿ç¨é è¨­çè¶åæ¸è¨ç®é¡ä¼¼ççµæï¼å¾èå°è¨ç®å·¥ä½éæ¸å°ç´ 10,000 åãæåéééæ·»å åºæ¼ç¬å®¹çèªç¶èªè¨èççè¡¨ç¤ºå­¸ç¿æ¹æ³ï¼ç¨±çº Transformer CNNï¼ä¾æ´å±ååçåæãæåè¡¨æï¼å¨ä½¿ç¨å®å¨ç¸åçåè­°å°ææåæçéåé²è¡åææï¼Transformer CNN å¨ 28 åæå°æ¯è¼ä¸­æ 26 åæ¯è¼æ¯åºæ¼åå½¢çæ¹æ³æä¾äºæ´å¥½ççµæï¼èèå¶ä»æ¹æ³ç¸æ¯ï¼æç¨çæéåªæ¯å¾å°çä¸é¨åãæå¾ä½ä¸¦éæä¸éè¦çæ¯ï¼æåå¼·èª¿äºä½¿ç¨å®å¨ç¸åççµ±è¨æ¸¬éä¾æ¯è¼è¨ç®çµæçéè¦æ§ã

##### **Harvesting Textual and Structured Data from the HAL Publication Repository**
2407.20595v1 by Francis Kulumba, Wissam Antoun, Guillaume Vimont, Laurent Romary

HAL (Hyper Articles en Ligne) is the French national publication repository,
used by most higher education and research organizations for their open science
policy. As a digital library, it is a rich repository of scholarly documents,
but its potential for advanced research has been underutilized. We present
HALvest, a unique dataset that bridges the gap between citation networks and
the full text of papers submitted on HAL. We craft our dataset by filtering HAL
for scholarly publications, resulting in approximately 700,000 documents,
spanning 34 languages across 13 identified domains, suitable for language model
training, and yielding approximately 16.5 billion tokens (with 8 billion in
French and 7 billion in English, the most represented languages). We transform
the metadata of each paper into a citation network, producing a directed
heterogeneous graph. This graph includes uniquely identified authors on HAL, as
well as all open submitted papers, and their citations. We provide a baseline
for authorship attribution using the dataset, implement a range of
state-of-the-art models in graph representation learning for link prediction,
and discuss the usefulness of our generated knowledge graph structure.

æè¦ï¼HALï¼ç·ä¸è¶é£çµæç« ï¼æ¯æ³ååå®¶åºçç©è³æåº«ï¼
å¤§å¤æ¸é«ç­æè²åç ç©¶çµç¹é½ä½¿ç¨å®ä¾å¶å®éæ¾ç§å­¸
æ¿ç­ãä½çºä¸åæ¸ä½åæ¸é¤¨ï¼å®æ¯ä¸åè±å¯çå­¸è¡æä»¶è³æåº«ï¼
ä½å®å¨é²éç ç©¶çæ½åå°æªè¢«ååå©ç¨ãæåæåº
HALvestï¼ä¸åç¨ç¹çè³æéï¼å®å½è£äºå¼æç¶²è·¯å
å¨ HAL ä¸æäº¤çè«æå¨æä¹éçå·®è·ãæåééç¯©é¸ HAL
ä¸­çå­¸è¡åºçåä¾å»ºç«æåçè³æéï¼æå¾å¾å°ç´ 70 è¬ä»½æä»¶ï¼
æ¶µè 13 åå·²è­å¥é åç 34 ç¨®èªè¨ï¼é©åèªè¨æ¨¡å
è¨ç·´ï¼ä¸¦ç¢çç´ 165 ååè©å½ï¼å¶ä¸­æ³ææ 80 ååï¼
è±ææ 70 ååï¼æ¯æå·ä»£è¡¨æ§çèªè¨ï¼ãæåå°
æ¯ç¯è«æçåè³æè½ææå¼æç¶²è·¯ï¼ç¢çä¸åæå
ç°è³ªåå½¢ãæ­¤åå½¢åå«å¨ HAL ä¸å¯ä¸è­å¥çä½èï¼ä»¥å
ææå¬éæäº¤çè«æåå¶å¼æãæåæä¾ä¸ååºæº
ä½¿ç¨è³æéé²è¡ä½èæ­¸å±¬ï¼å¯¦ä½ä¸ç³»å
æåé²çåå½¢è¡¨ç¤ºå­¸ç¿æ¨¡åé²è¡é£çµé æ¸¬ï¼
ä¸¦è¨è«æåç¢ççç¥è­åå½¢çµæ§çå¯¦ç¨æ§ã

##### **CLR-Fact: Evaluating the Complex Logical Reasoning Capability of Large Language Models over Factual Knowledge**
2407.20564v1 by Tianshi Zheng, Jiaxin Bai, Yicheng Wang, Tianqing Fang, Yue Guo, Yauwai Yim, Yangqiu Song

While large language models (LLMs) have demonstrated impressive capabilities
across various natural language processing tasks by acquiring rich factual
knowledge from their broad training data, their ability to synthesize and
logically reason with this knowledge in complex ways remains underexplored. In
this work, we present a systematic evaluation of state-of-the-art LLMs' complex
logical reasoning abilities through a novel benchmark of automatically
generated complex reasoning questions over general domain and biomedical
knowledge graphs. Our extensive experiments, employing diverse in-context
learning techniques, reveal that LLMs excel at reasoning over general world
knowledge but face significant challenges with specialized domain-specific
knowledge. We find that prompting with explicit Chain-of-Thought demonstrations
can substantially improve LLM performance on complex logical reasoning tasks
with diverse logical operations. Interestingly, our controlled evaluations
uncover an asymmetry where LLMs display proficiency at set union operations,
but struggle considerably with set intersections - a key building block of
logical reasoning. To foster further work, we will publicly release our
evaluation benchmark and code.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºä»¤äººå°è±¡æ·±å»çè½åï¼å¯ééå¾å»£æ³çè¨ç·´è³æä¸­ç²åè±å¯çäºå¯¦ç¥è­ï¼å·è¡åç¨®èªç¶èªè¨èçä»»åï¼ä½å®åç¶åéç¨ä¸¦ä»¥è¤éçæ¹å¼éç¨æ­¤ç¥è­é²è¡éè¼¯æ¨ççè½åä»æå¾é²ä¸æ­¥æ¢è¨ãå¨éé å·¥ä½ä¸­ï¼æåééä¸åèªåçæçä¸è¬é ååçç©é«å­¸ç¥è­åè¡¨è¤éæ¨çåé¡çæ°åºæºï¼å°æåé²ç LLM è¤ééè¼¯æ¨çè½åé²è¡ç³»çµ±æ§è©ä¼°ãæåçå»£æ³å¯¦é©æ¡ç¨å¤æ¨£åçæå¢å­¸ç¿æè¡ï¼æ­ç¤ºåº LLM æé·å°ä¸è¬ä¸çç¥è­é²è¡æ¨çï¼ä½å¨èçç¹å®é åçå°æ¥­ç¥è­æåé¢è¨éå¤§ææ°ãæåç¼ç¾ï¼ä½¿ç¨æç¢ºçæèéæ¢ç¤ºç¯é²è¡æç¤ºï¼å¯ä»¥å¤§å¹æ¹å LLM å¨å·æå¤æ¨£åéè¼¯éç®çè¤ééè¼¯æ¨çä»»åä¸­çè¡¨ç¾ãæè¶£çæ¯ï¼æåçåæ§è©ä¼°æ­é²äºä¸åä¸å°ç¨±æ§ï¼å¶ä¸­ LLM å±ç¾åºå¨éåè¯ééç®æ¹é¢ççç·´åº¦ï¼ä½å¨éåäº¤éæ¹é¢å»é¡¯å¾ç¸ç¶ååï¼èéåäº¤éæ­£æ¯éè¼¯æ¨ççééµçµæé¨åãçºäºä¿é²å¾çºç ç©¶ï¼æåå°å¬éç¼å¸æåçè©ä¼°åºæºåç¨å¼ç¢¼ã

##### **Prompt2DeModel: Declarative Neuro-Symbolic Modeling with Natural Language**
2407.20513v1 by Hossein Rajaby Faghihi, Aliakbar Nafar, Andrzej Uszok, Hamid Karimian, Parisa Kordjamshidi

This paper presents a conversational pipeline for crafting domain knowledge
for complex neuro-symbolic models through natural language prompts. It
leverages large language models to generate declarative programs in the
DomiKnowS framework. The programs in this framework express concepts and their
relationships as a graph in addition to logical constraints between them. The
graph, later, can be connected to trainable neural models according to those
specifications. Our proposed pipeline utilizes techniques like dynamic
in-context demonstration retrieval, model refinement based on feedback from a
symbolic parser, visualization, and user interaction to generate the tasks'
structure and formal knowledge representation. This approach empowers domain
experts, even those not well-versed in ML/AI, to formally declare their
knowledge to be incorporated in customized neural models in the DomiKnowS
framework.

æè¦ï¼æ¬ææåºäºä¸åå°è©±å¼ç®¡éï¼ééèªç¶èªè¨æç¤ºï¼çºè¤éçç¥ç¶ç¬¦èæ¨¡åå»ºç«é åç¥è­ãå®å©ç¨å¤§åèªè¨æ¨¡åå¨ DomiKnowS æ¡æ¶ä¸­ç¢çå®£åå¼ç¨å¼ãæ­¤æ¡æ¶ä¸­çç¨å¼æå°æ¦å¿µåå¶éä¿è¡¨ç¤ºçºåå½¢ï¼ä¸¦å¨å®åä¹éå ä¸éè¼¯ç´æãä¹å¾ï¼å¯ä»¥æ ¹æéäºè¦æ ¼å°åå½¢é£æ¥å°å¯è¨ç·´çç¥ç¶æ¨¡åãæåæåºçç®¡éå©ç¨åææå¢ä¸­ç¤ºç¯æª¢ç´¢ãåºæ¼ç¬¦èè§£æå¨åé¥çæ¨¡åç²¾çãè¦è¦ºååä½¿ç¨èäºåç­æè¡ï¼ä»¥ç¢çä»»åçµæ§åå½¢å¼ç¥è­è¡¨ç¤ºãéç¨®æ¹æ³è®é åå°å®¶ï¼å³ä½¿æ¯ä¸çææ©å¨å­¸ç¿ï¼äººå·¥æºæ§çäººï¼ä¹è½æ­£å¼å®£åä»åçç¥è­ï¼ä¸¦å°å¶ç´å¥ DomiKnowS æ¡æ¶ä¸­çèªè¨ç¥ç¶æ¨¡åã

##### **What if Red Can Talk? Dynamic Dialogue Generation Using Large Language Models**
2407.20382v1 by Navapat Nananukul, Wichayaporn Wongkamjan

Role-playing games (RPGs) provide players with a rich, interactive world to
explore. Dialogue serves as the primary means of communication between
developers and players, manifesting in various forms such as guides, NPC
interactions, and storytelling. While most games rely on written scripts to
define the main story and character personalities, player immersion can be
significantly enhanced through casual interactions between characters. With the
advent of large language models (LLMs), we introduce a dialogue filler
framework that utilizes LLMs enhanced by knowledge graphs to generate dynamic
and contextually appropriate character interactions. We test this framework
within the environments of Final Fantasy VII Remake and Pokemon, providing
qualitative and quantitative evidence that demonstrates GPT-4's capability to
act with defined personalities and generate dialogue. However, some flaws
remain, such as GPT-4 being overly positive or more subtle personalities, such
as maturity, tend to be of lower quality compared to more overt traits like
timidity. This study aims to assist developers in crafting more nuanced filler
dialogues, thereby enriching player immersion and enhancing the overall RPG
experience.

æè¦ï¼è§è²æ®æ¼éæ² (RPG) çºç©å®¶æä¾ä¸åè±å¯ä¸äºåçä¸çä¾å¶æ¢ç´¢ãå°è©±ä½çºéç¼èèç©å®¶ä¹éçä¸»è¦æºéæ¹å¼ï¼ä»¥æåãNPC äºååèªªæäºç­åç¨®å½¢å¼åç¾ãéç¶å¤§å¤æ¸éæ²ä¾è³´æ¼æ¸é¢è³æ¬ä¾å®ç¾©ä¸»ç·æäºåè§è²åæ§ï¼ä½ééè§è²ä¹éçéèäºåï¼å¯ä»¥å¤§å¹æåç©å®¶çæ²æµ¸æãé¨èå¤§åèªè¨æ¨¡å (LLM) çåºç¾ï¼æåå¼å¥äºä¸åå°è©±å¡«åæ¡æ¶ï¼å©ç¨ç±ç¥è­åè­å¢å¼·ç LLM ä¾ç¢çåæä¸ç¬¦åæå¢çå°è©±äºåãæåå¨ Final Fantasy VII Remake åå¯¶å¯å¤¢çç°å¢ä¸­æ¸¬è©¦äºéåæ¡æ¶ï¼æä¾äºå®æ§åå®éçè­æï¼è­æäº GPT-4 å·åä»¥å®ç¾©å¥½çåæ§è¡åä¸¦ç¢çå°è©±çè½åãç¶èï¼ä»å­å¨ä¸äºç¼ºé·ï¼ä¾å¦ GPT-4 éæ¼æ­£é¢ï¼æèè¼çºç´°å¾®çåæ§ï¼ä¾å¦æçåº¦ï¼å¾å¾åè³ªä½æ¼è¼æé¡¯çç¹è³ªï¼ä¾å¦è½æ¯ãæ¬ç ç©¶æ¨å¨åå©éç¼èæé æ´ç´°ç·»çå¡«åå°è©±ï¼å¾èè±å¯ç©å®¶çæ²æµ¸æä¸¦æåæ´é« RPG é«é©ã

##### **MindSearch: Mimicking Human Minds Elicits Deep AI Searcher**
2407.20183v1 by Zehui Chen, Kuikun Liu, Qiuchen Wang, Jiangning Liu, Wenwei Zhang, Kai Chen, Feng Zhao

Information seeking and integration is a complex cognitive task that consumes
enormous time and effort. Inspired by the remarkable progress of Large Language
Models, recent works attempt to solve this task by combining LLMs and search
engines. However, these methods still obtain unsatisfying performance due to
three challenges: (1) complex requests often cannot be accurately and
completely retrieved by the search engine once (2) corresponding information to
be integrated is spread over multiple web pages along with massive noise, and
(3) a large number of web pages with long contents may quickly exceed the
maximum context length of LLMs. Inspired by the cognitive process when humans
solve these problems, we introduce MindSearch to mimic the human minds in web
information seeking and integration, which can be instantiated by a simple yet
effective LLM-based multi-agent framework. The WebPlanner models the human mind
of multi-step information seeking as a dynamic graph construction process: it
decomposes the user query into atomic sub-questions as nodes in the graph and
progressively extends the graph based on the search result from WebSearcher.
Tasked with each sub-question, WebSearcher performs hierarchical information
retrieval with search engines and collects valuable information for WebPlanner.
The multi-agent design of MindSearch enables the whole framework to seek and
integrate information parallelly from larger-scale (e.g., more than 300) web
pages in 3 minutes, which is worth 3 hours of human effort. MindSearch
demonstrates significant improvement in the response quality in terms of depth
and breadth, on both close-set and open-set QA problems. Besides, responses
from MindSearch based on InternLM2.5-7B are preferable by humans to ChatGPT-Web
and Perplexity.ai applications, which implies that MindSearch can already
deliver a competitive solution to the proprietary AI search engine.

æè¦ï¼è³è¨æå°èæ´åæ¯ä¸é è¤éçèªç¥ä»»åï¼æèè²»å¤§éæéèç²¾åãå¨å¤§åèªè¨æ¨¡åé¡¯èé²å±çåç¼ä¸ï¼è¿æç ç©¶åè©¦çµåå¤§åèªè¨æ¨¡åèæå°å¼æä¾è§£æ±ºæ­¤ä»»åãç¶èï¼éäºæ¹æ³ä»å ä¸é ææ°èç¡æ³ç²å¾ä»¤äººæ»¿æçæè½ï¼(1) è¤éçæ¥è©¢éå¸¸ç¡æ³ç±æå°å¼æä¸æ¬¡æºç¢ºä¸å®æ´å°æ·åï¼(2) è¦æ´åçå°æè³è¨æ£å¸å¨å¤åç¶²é ä¸­ä¸ä¼´é¨èå¤§ééè¨ï¼ä»¥å (3) å¤§éå§å®¹éé·çç¶²é å¯è½æå¿«éè¶éå¤§åèªè¨æ¨¡åçæå¤§èçµ¡é·åº¦ãå¨äººé¡è§£æ±ºéäºåé¡çèªç¥éç¨ä¸­ç²å¾éæï¼æåå¼å¥äº MindSearch ä¾æ¨¡æ¬äººé¡å¿æºå¨ç¶²é è³è¨æå°èæ´åä¸­çè¡çºï¼éå¯ä»¥ç¨ä¸åç°¡å®ä½ææçåºæ¼å¤§åèªè¨æ¨¡åçå¤ä»£çæ¶æ§ä¾å¯¦ä¾åãWebPlanner ä»¥åæåå½¢å»ºæ§éç¨ä¾å»ºæ¨¡äººé¡å¿æºçå¤æ­¥é©è³è¨æå°ï¼å®å°ä½¿ç¨èæ¥è©¢åè§£æåå½¢ä¸­çç¯é»ï¼ä½çºåå­åå­åé¡ï¼ä¸¦æ ¹æ WebSearcher çæå°çµæéæ­¥å»¶ä¼¸åå½¢ãWebSearcher ä»¥æ¯åå­åé¡çºä»»åï¼å·è¡æå°å¼æçåå±¤å¼è³è¨æ·åï¼ä¸¦çº WebPlanner æ¶éæå¹å¼çè³è¨ãMindSearch çå¤ä»£çè¨­è¨è®æ´åæ¶æ§å¯ä»¥å¨ 3 åéå§å¹³è¡å°å¾æ´å¤§è¦æ¨¡ï¼ä¾å¦è¶é 300 åï¼çç¶²é ä¸­æå°ä¸¦æ´åè³è¨ï¼éç¸ç¶æ¼ 3 å°æçäººåãMindSearch å¨æ·±åº¦åå»£åº¦æ¹é¢é½é¡¯èæåäºåæåè³ªï¼ç¡è«æ¯å¨å°éå¼æéæ¾å¼åç­åé¡ä¸ãæ­¤å¤ï¼äººé¡æ´åå¥½åºæ¼ InternLM2.5-7B ç MindSearch åæï¼åé ChatGPT-Web å Perplexity.ai æç¨ç¨å¼ï¼éè¡¨ç¤º MindSearch å·²ç¶å¯ä»¥çºå°æ AI æå°å¼ææä¾æç«¶ç­åçè§£æ±ºæ¹æ¡ã

##### **rLLM: Relational Table Learning with LLMs**
2407.20157v1 by Weichen Li, Xiaotong Huang, Jianwu Zheng, Zheng Wang, Chaokun Wang, Li Pan, Jianhua Li

We introduce rLLM (relationLLM), a PyTorch library designed for Relational
Table Learning (RTL) with Large Language Models (LLMs). The core idea is to
decompose state-of-the-art Graph Neural Networks, LLMs, and Table Neural
Networks into standardized modules, to enable the fast construction of novel
RTL-type models in a simple "combine, align, and co-train" manner. To
illustrate the usage of rLLM, we introduce a simple RTL method named
\textbf{BRIDGE}. Additionally, we present three novel relational tabular
datasets (TML1M, TLF2K, and TACM12K) by enhancing classic datasets. We hope
rLLM can serve as a useful and easy-to-use development framework for
RTL-related tasks. Our code is available at:
https://github.com/rllm-project/rllm.

æè¦ï¼æåå¼å¥äº rLLM (relationLLM)ï¼ä¸åå°çºå¤§åèªè¨æ¨¡å (LLM) çéä¿è¡¨å­¸ç¿ (RTL) æè¨­è¨ç PyTorch å½å¼åº«ãæ ¸å¿æ¦å¿µæ¯å°æåé²çåå½¢ç¥ç¶ç¶²è·¯ãLLM åè¡¨ç¥ç¶ç¶²è·¯åè§£çºæ¨æºåæ¨¡çµï¼ä»¥ä¾¿ä»¥ç°¡å®çãçµåãå°é½åå±åè¨ç·´ãæ¹å¼å¿«éå»ºæ§æ°å RTL é¡åæ¨¡åãçºäºèªªæ rLLM çç¨æ³ï¼æåå¼å¥äºåçº \textbf{BRIDGE} çç°¡å® RTL æ¹æ³ãæ­¤å¤ï¼æåééå¼·åç¶å¸è³æéä¾åç¾ä¸åæ°ç©çéä¿è¡¨æ ¼è³æé (TML1MãTLF2K å TACM12K)ãæåå¸æ rLLM è½å¤ ä½çº RTL ç¸éä»»åæç¨çä¸ææ¼ä½¿ç¨çéç¼æ¶æ§ãæåçç¨å¼ç¢¼å¯å¨ä»¥ä¸ç¶²ååå¾ï¼
https://github.com/rllm-project/rllmã

##### **Prometheus Chatbot: Knowledge Graph Collaborative Large Language Model for Computer Components Recommendation**
2407.19643v2 by Yunsheng Wang, Songhao Chen, Kevin Jin

Knowledge graphs (KGs) are essential in applications such as network
alignment, question-answering, and recommender systems (RSs) since they offer
structured relational data that facilitate the inference of indirect
relationships. However, the development of KG-based RSs capable of processing
user inputs in natural language faces significant challenges. Firstly, natural
language processing units must effectively handle the ambiguity and variability
in human language to interpret user intents accurately. Secondly, the system
must precisely identify and link entities, like product names, to their
corresponding nodes in KGs. To overcome these challenges, supported by Lenovo,
we developed a novel chatbot called "Prometheus," which integrates a KG with a
large language model (LLM), specifically designed for recommending computer
components. This chatbot can accurately decode user requests and deliver
personalized recommendations derived from KGs, ensuring precise comprehension
and response to their computer setup needs.

æè¦ï¼ç¥è­åè­ (KG) å¨ç¶²è·¯æ¯å°ãåç­åæ¨è¦ç³»çµ± (RS) ç­æç¨ä¸­è³ééè¦ï¼å çºå®åæä¾çµæ§åçéä¿è³æï¼æå©æ¼æ¨æ·éæ¥éä¿ãç¶èï¼éç¼è½å¤ èçèªç¶èªè¨ä½¿ç¨èè¼¸å¥çåºæ¼ KG ç RS é¢è¨èéå¤§çææ°ãé¦åï¼èªç¶èªè¨èçå®åå¿é ææèçäººé¡èªè¨ä¸­çæ¨¡ç³æ§åè®ç°æ§ï¼æè½æºç¢ºå°è§£éä½¿ç¨èæåãå¶æ¬¡ï¼ç³»çµ±å¿é æºç¢ºè­å¥åé£çµå¯¦é«ï¼ä¾å¦ç¢ååç¨±ï¼å° KG ä¸­å°æçç¯é»ãçºäºåæéäºææ°ï¼å¨è¯æ³çæ¯æ´ä¸ï¼æåéç¼äºä¸æ¬¾åçºãæ®ç¾ç±³ä¿®æ¯ãçæ°èå¤©æ©å¨äººï¼å®å° KG èå¤§åèªè¨æ¨¡å (LLM) æ´åå¨ä¸èµ·ï¼å°éç¨æ¼æ¨è¦é»è¦çµä»¶ãæ­¤èå¤©æ©å¨äººå¯ä»¥æºç¢ºå°è§£ç¢¼ä½¿ç¨èè¦æ±ï¼ä¸¦æä¾å¾ KG ä¸­è¡ççåäººåæ¨è¦ï¼ç¢ºä¿ç²¾ç¢ºçè§£ååæå¶é»è¦è¨­å®éæ±ã

##### **TopicTag: Automatic Annotation of NMF Topic Models Using Chain of Thought and Prompt Tuning with LLMs**
2407.19616v1 by Selma Wanna, Ryan Barron, Nick Solovyev, Maksim E. Eren, Manish Bhattarai, Kim Rasmussen, Boian S. Alexandrov

Topic modeling is a technique for organizing and extracting themes from large
collections of unstructured text. Non-negative matrix factorization (NMF) is a
common unsupervised approach that decomposes a term frequency-inverse document
frequency (TF-IDF) matrix to uncover latent topics and segment the dataset
accordingly. While useful for highlighting patterns and clustering documents,
NMF does not provide explicit topic labels, necessitating subject matter
experts (SMEs) to assign labels manually. We present a methodology for
automating topic labeling in documents clustered via NMF with automatic model
determination (NMFk). By leveraging the output of NMFk and employing prompt
engineering, we utilize large language models (LLMs) to generate accurate topic
labels. Our case study on over 34,000 scientific abstracts on Knowledge Graphs
demonstrates the effectiveness of our method in enhancing knowledge management
and document organization.

æè¦ï¼ä¸»é¡å»ºæ¨¡æ¯ä¸ç¨®å¾å¤§ééçµæ§åææ¬ä¸­çµç¹åæåä¸»é¡çæè¡ãéè² ç©é£åè§£ (NMF) æ¯ä¸ç¨®å¸¸è¦çç¡ç£ç£æ¹æ³ï¼å®å°è©é »-éæä»¶é »ç (TF-IDF) ç©é£åè§£çºæ½å¨ä¸»é¡ï¼ä¸¦ææ­¤å°æ¸æéé²è¡åæ®µãåç®¡ NMF å¯ç¨æ¼å¼·èª¿æ¨¡å¼åç¾¤çµæä»¶ï¼ä½å®ä¸æä¾æç¢ºçä¸»é¡æ¨ç±¤ï¼ééè¦ä¸»é¡å°å®¶ (SME) æååéæ¨ç±¤ãæåæåºäºä¸ç¨®æ¹æ³ï¼ç¨æ¼èªåæ¨è¨éé NMF é²è¡ç¾¤çµçæä»¶ï¼ä¸¦èªåç¢ºå®æ¨¡å (NMFk)ãééå©ç¨ NMFk çè¼¸åºä¸¦æ¡ç¨æç¤ºå·¥ç¨ï¼æåå©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾çææºç¢ºçä¸»é¡æ¨ç±¤ãæåå°è¶é 34,000 ç¯éæ¼ç¥è­åè­çç§å­¸æè¦é²è¡çæ¡ä¾ç ç©¶è­æäºæåçæ¹æ³å¨å¢å¼·ç¥è­ç®¡çåæä»¶çµç¹æ¹é¢çæææ§ã

##### **Semantic Communication Enhanced by Knowledge Graph Representation Learning**
2407.19338v1 by Nour Hello, Paolo Di Lorenzo, Emilio Calvanese Strinati

This paper investigates the advantages of representing and processing
semantic knowledge extracted into graphs within the emerging paradigm of
semantic communications. The proposed approach leverages semantic and pragmatic
aspects, incorporating recent advances on large language models (LLMs) to
achieve compact representations of knowledge to be processed and exchanged
between intelligent agents. This is accomplished by using the cascade of LLMs
and graph neural networks (GNNs) as semantic encoders, where information to be
shared is selected to be meaningful at the receiver. The embedding vectors
produced by the proposed semantic encoder represent information in the form of
triplets: nodes (semantic concepts entities), edges(relations between
concepts), nodes. Thus, semantic information is associated with the
representation of relationships among elements in the space of semantic concept
abstractions. In this paper, we investigate the potential of achieving high
compression rates in communication by incorporating relations that link
elements within graph embeddings. We propose sending semantic symbols solely
equivalent to node embeddings through the wireless channel and inferring the
complete knowledge graph at the receiver. Numerical simulations illustrate the
effectiveness of leveraging knowledge graphs to semantically compress and
transmit information.

æè¦ï¼æ¬æç ç©¶äºå¨è¯­ä¹éä¿¡çæ°å´èä¾ä¸­å°æåå°å¾ä¸­çè¯­ä¹ç¥è¯è¡¨ç¤ºåå¤ççä¼å¿ãææåºçæ¹æ³å©ç¨è¯­ä¹åè¯­ç¨æ¹é¢ï¼ç»åäºå¤§è¯­è¨æ¨¡å (LLM) çææ°è¿å±ï¼ä»¥å®ç°è¦å¤çåå¨æºè½ä»£çä¹é´äº¤æ¢çç¥è¯çç´§åè¡¨ç¤ºãè¿æ¯éè¿ä½¿ç¨ LLM åå¾ç¥ç»ç½ç» (GNN) ççº§èä½ä¸ºè¯­ä¹ç¼ç å¨æ¥å®æçï¼å¶ä¸­è¦å±äº«çä¿¡æ¯è¢«éæ©ä¸ºå¯¹æ¥æ¶èææä¹ãç±ææåºçè¯­ä¹ç¼ç å¨äº§ççåµå¥åéä»¥ä¸åç»çå½¢å¼è¡¨ç¤ºä¿¡æ¯ï¼èç¹ï¼è¯­ä¹æ¦å¿µå®ä½ï¼ãè¾¹ï¼æ¦å¿µä¹é´çå³ç³»ï¼ãèç¹ãå æ­¤ï¼è¯­ä¹ä¿¡æ¯ä¸è¯­ä¹æ¦å¿µæ½è±¡ç©ºé´ä¸­åç´ ä¹é´å³ç³»çè¡¨ç¤ºç¸å³èãå¨æ¬æä¸­ï¼æä»¬ç ç©¶äºéè¿åå¹¶å°å¾åµå¥ä¸­çåç´ èç³»èµ·æ¥çå³èæ¥å®ç°é«åç¼©ççæ½åãæä»¬å»ºè®®ä»éè¿æ çº¿ä¿¡éåéè¯­ä¹ç¬¦å·ï¼è¿äºç¬¦å·å®å¨ç­æäºèç¹åµå¥ï¼å¹¶å¨æ¥æ¶å¨å¤æ¨æ­åºå®æ´çç¥è¯å¾ãæ°å¼æ¨¡æè¯´æäºå©ç¨ç¥è¯å¾è¯­ä¹åç¼©åä¼ è¾ä¿¡æ¯çæææ§ã

##### **GraphBPE: Molecular Graphs Meet Byte-Pair Encoding**
2407.19039v1 by Yuchen Shen, BarnabÃ¡s PÃ³czos

With the increasing attention to molecular machine learning, various
innovations have been made in designing better models or proposing more
comprehensive benchmarks. However, less is studied on the data preprocessing
schedule for molecular graphs, where a different view of the molecular graph
could potentially boost the model's performance. Inspired by the Byte-Pair
Encoding (BPE) algorithm, a subword tokenization method popularly adopted in
Natural Language Processing, we propose GraphBPE, which tokenizes a molecular
graph into different substructures and acts as a preprocessing schedule
independent of the model architectures. Our experiments on 3 graph-level
classification and 3 graph-level regression datasets show that data
preprocessing could boost the performance of models for molecular graphs, and
GraphBPE is effective for small classification datasets and it performs on par
with other tokenization methods across different model architectures.

æè¦ï¼é¨èåå­æ©å¨å­¸ç¿åå°çéæ³¨åº¦è¶ä¾è¶é«ï¼å¨è¨­è¨æ´å¥½çæ¨¡åææåºæ´å¨é¢çåºæºæ¹é¢å·²ç¶æäºåç¨®åµæ°ãç¶èï¼å°æ¼åå­åçæ¸æé èçè¨ç«ç ç©¶è¼å°ï¼å¨è©²è¨ç«ä¸­ï¼åå­åçä¸åè¦åå¯è½ææåæ¨¡åçæè½ãåå°å¨èªç¶èªè¨èçä¸­å»£æ³æ¡ç¨çå­è©å½æ¨è¨åæ¹æ³ Byte-Pair ç·¨ç¢¼ (BPE) æ¼ç®æ³çåç¼ï¼æåæåºäº GraphBPEï¼å®å°åå­åæ¨è¨åçºä¸åçå­çµæ§ï¼ä¸¦ä½çºèæ¨¡åæ¶æ§ç¡éçé èçè¨ç«ãæåå¨ 3 ååå½¢å±¤ç´åé¡å 3 ååå½¢å±¤ç´åæ­¸è³æéä¸çå¯¦é©é¡¯ç¤ºï¼è³æé èçå¯ä»¥æååå­åæ¨¡åçæè½ï¼è GraphBPE å°æ¼å°ååé¡è³æéææï¼ä¸¦ä¸å¨ä¸åçæ¨¡åæ¶æ§ä¸­èå¶ä»æ¨è¨åæ¹æ³è¡¨ç¾ç¸ç¶ã

##### **Knowledge Graph Structure as Prompt: Improving Small Language Models Capabilities for Knowledge-based Causal Discovery**
2407.18752v3 by Yuni Susanti, Michael FÃ¤rber

Causal discovery aims to estimate causal structures among variables based on
observational data. Large Language Models (LLMs) offer a fresh perspective to
tackle the causal discovery problem by reasoning on the metadata associated
with variables rather than their actual data values, an approach referred to as
knowledge-based causal discovery. In this paper, we investigate the
capabilities of Small Language Models (SLMs, defined as LLMs with fewer than 1
billion parameters) with prompt-based learning for knowledge-based causal
discovery. Specifically, we present KG Structure as Prompt, a novel approach
for integrating structural information from a knowledge graph, such as common
neighbor nodes and metapaths, into prompt-based learning to enhance the
capabilities of SLMs. Experimental results on three types of biomedical and
open-domain datasets under few-shot settings demonstrate the effectiveness of
our approach, surpassing most baselines and even conventional fine-tuning
approaches trained on full datasets. Our findings further highlight the strong
capabilities of SLMs: in combination with knowledge graphs and prompt-based
learning, SLMs demonstrate the potential to surpass LLMs with larger number of
parameters. Our code and datasets are available on GitHub.

æè¦ï¼å æç¼ç¾æ¨å¨æ ¹æè§æ¸¬æ¸æä¼°è¨è®æ¸ä¹éçå æçµæ§ãå¤§åèªè¨æ¨¡å (LLM) æä¾äºä¸åæ°çè§é»ä¾è§£æ±ºå æç¼ç¾åé¡ï¼æ¹æ³æ¯æ¨è«èè®æ¸ç¸éçåæ¸æï¼èä¸æ¯å®åçå¯¦éæ¸æå¼ï¼éç¨®æ¹æ³ç¨±çºåºæ¼ç¥è­çå æç¼ç¾ãå¨æ¬æä¸­ï¼æåæ¢è¨äºå°èªè¨æ¨¡å (SLMï¼å®ç¾©çºåæ¸å°æ¼ 10 åç LLM) çè½åï¼ä¸¦æ¡ç¨åºæ¼æç¤ºçå­¸ç¿é²è¡åºæ¼ç¥è­çå æç¼ç¾ãå·é«ä¾èªªï¼æåæåºäº KG Structure as Promptï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼ç¨æ¼å°ä¾èªç¥è­åè­ççµæ§è³è¨ï¼ä¾å¦å±åé°å±ç¯é»ååè·¯å¾ï¼æ´åå°åºæ¼æç¤ºçå­¸ç¿ä¸­ï¼ä»¥å¢å¼· SLM çè½åãå¨å°æ¬¡åè©¦è¨­å®ä¸ï¼éå°ä¸ç¨®é¡åççç©é«å­¸åéæ¾é åè³æéçå¯¦é©çµæè­æäºæåæ¹æ³çæææ§ï¼è¶è¶äºå¤§å¤æ¸åºæºï¼çè³è¶è¶äºå¨å®æ´è³æéä¸è¨ç·´çå³çµ±å¾®èª¿æ¹æ³ãæåçç¼ç¾é²ä¸æ­¥çªåºäº SLM çå¼·å¤§åè½ï¼çµåç¥è­åè­ååºæ¼æç¤ºçå­¸ç¿ï¼SLM å±ç¤ºäºè¶è¶å·ææ´å¤åæ¸ç LLM çæ½åãæåçç¨å¼ç¢¼åè³æéå¯å¨ GitHub ä¸åå¾ã

##### **Using GPT-4 to guide causal machine learning**
2407.18607v1 by Anthony C. Constantinou, Neville K. Kitson, Alessio Zanga

Since its introduction to the public, ChatGPT has had an unprecedented
impact. While some experts praised AI advancements and highlighted their
potential risks, others have been critical about the accuracy and usefulness of
Large Language Models (LLMs). In this paper, we are interested in the ability
of LLMs to identify causal relationships. We focus on the well-established
GPT-4 (Turbo) and evaluate its performance under the most restrictive
conditions, by isolating its ability to infer causal relationships based solely
on the variable labels without being given any context, demonstrating the
minimum level of effectiveness one can expect when it is provided with
label-only information. We show that questionnaire participants judge the GPT-4
graphs as the most accurate in the evaluated categories, closely followed by
knowledge graphs constructed by domain experts, with causal Machine Learning
(ML) far behind. We use these results to highlight the important limitation of
causal ML, which often produces causal graphs that violate common sense,
affecting trust in them. However, we show that pairing GPT-4 with causal ML
overcomes this limitation, resulting in graphical structures learnt from real
data that align more closely with those identified by domain experts, compared
to structures learnt by causal ML alone. Overall, our findings suggest that
despite GPT-4 not being explicitly designed to reason causally, it can still be
a valuable tool for causal representation, as it improves the causal discovery
process of causal ML algorithms that are designed to do just that.

æè¦ï¼èª ChatGPT åå¬ä¼åå¸ä»¥æ¥ï¼å®äº§çäºåææªæçå½±åãè½ç¶ä¸äºä¸å®¶èµæ¬äº AI çè¿æ­¥å¹¶å¼ºè°äºå¶æ½å¨é£é©ï¼ä½å¶ä»äººä¸ç´æ¹è¯å¤§åè¯­è¨æ¨¡å (LLM) çåç¡®æ§åæç¨æ§ãå¨æ¬æä¸­ï¼æä»¬å¯¹ LLM è¯å«å æå³ç³»çè½åæå´è¶£ãæä»¬ä¸æ³¨äºæçç GPT-4ï¼Turboï¼ï¼å¹¶å¨æä¸¥æ ¼çæ¡ä»¶ä¸è¯ä¼°å¶æ§è½ï¼éè¿å­¤ç«å¶ä»æ ¹æ®åéæ ç­¾æ¨æ­å æå³ç³»çè½åï¼èä¸æä¾ä»»ä½ä¸ä¸æï¼å±ç¤ºäºå½ä»æä¾æ ç­¾ä¿¡æ¯æ¶äººä»¬å¯ä»¥é¢æçæä½æææ§æ°´å¹³ãæä»¬è¡¨æï¼é®å·åä¸èè®¤ä¸º GPT-4 å¾å½¢å¨è¯ä¼°ç±»å«ä¸­æ¯æåç¡®çï¼ç´§éå¶åçæ¯ç±é¢åä¸å®¶æå»ºçç¥è¯å¾è°±ï¼å ææºå¨å­¦ä¹  (ML) è¿è¿è½åãæä»¬ä½¿ç¨è¿äºç»ææ¥å¼ºè°å æ ML çéè¦å±éæ§ï¼å®ç»å¸¸äº§çè¿èå¸¸è¯çå æå¾ï¼å½±åäººä»¬å¯¹å®ä»¬çä¿¡ä»»ãç¶èï¼æä»¬è¡¨æå° GPT-4 ä¸å æ ML éå¯¹å¯ä»¥åæè¿ä¸éå¶ï¼ä»èäº§çä»çå®æ°æ®ä¸­å­¦å°çå¾å½¢ç»æï¼ä¸é¢åä¸å®¶è¯å«çç»æç¸æ¯ï¼æ´ç´§å¯å°ä¸ä¹å¯¹é½ï¼èä¸æ¯ä»ç±å æ ML å­¦å°çç»æãæ»ä½èè¨ï¼æä»¬çç ç©¶ç»æè¡¨æï¼å°½ç®¡ GPT-4 å¹¶æªæç¡®è®¾è®¡ä¸ºå ææ¨çï¼ä½å®ä»ç¶å¯ä»¥æä¸ºå æè¡¨ç¤ºçå®è´µå·¥å·ï¼å ä¸ºå®æ¹è¿äºæ¨å¨æ§è¡æ­¤æä½çå æ ML ç®æ³çå æåç°è¿ç¨ã

##### **Multi-turn Response Selection with Commonsense-enhanced Language Models**
2407.18479v1 by Yuandong Wang, Xuhui Ren, Tong Chen, Yuxiao Dong, Nguyen Quoc Viet Hung, Jie Tang

As a branch of advanced artificial intelligence, dialogue systems are
prospering. Multi-turn response selection is a general research problem in
dialogue systems. With the assistance of background information and pre-trained
language models, the performance of state-of-the-art methods on this problem
gains impressive improvement. However, existing studies neglect the importance
of external commonsense knowledge. Hence, we design a Siamese network where a
pre-trained Language model merges with a Graph neural network (SinLG). SinLG
takes advantage of Pre-trained Language Models (PLMs) to catch the word
correlations in the context and response candidates and utilizes a Graph Neural
Network (GNN) to reason helpful common sense from an external knowledge graph.
The GNN aims to assist the PLM in fine-tuning, and arousing its related
memories to attain better performance. Specifically, we first extract related
concepts as nodes from an external knowledge graph to construct a subgraph with
the context response pair as a super node for each sample. Next, we learn two
representations for the context response pair via both the PLM and GNN. A
similarity loss between the two representations is utilized to transfer the
commonsense knowledge from the GNN to the PLM. Then only the PLM is used to
infer online so that efficiency can be guaranteed. Finally, we conduct
extensive experiments on two variants of the PERSONA-CHAT dataset, which proves
that our solution can not only improve the performance of the PLM but also
achieve an efficient inference.

æè¦ï¼ä½çºé«ç´äººå·¥æºæ§çä¸ååæ¯ï¼å°è©±ç³»çµ±æ­£è¬åç¼å±ãå¤è¼ªåæç¨æ¶åæé¸ææ¯å°è©±ç³»çµ±ä¸­ä¸åéç¨çç ç©¶åé¡ãå¨èæ¯è³è¨åé åè¨ç·´çèªè¨æ¨¡åçåå©ä¸ï¼æåé²çæ¹æ³å¨æ­¤åé¡ä¸çè¡¨ç¾ç²è´ä»¤äººå°è±¡æ·±å»çé²æ­¥ãç¶èï¼ç¾æçç ç©¶å¿½ç¥äºå¤é¨å¸¸è­ç¥è­çéè¦æ§ãå æ­¤ï¼æåè¨­è¨äºä¸åæ¹ç¾ç¶²è·¯ï¼å¶ä¸­ä¸åé åè¨ç·´çèªè¨æ¨¡åèä¸ååç¥ç¶ç¶²è·¯ï¼SinLGï¼åä½µãSinLG å©ç¨é åè¨ç·´çèªè¨æ¨¡åï¼PLMï¼ä¾ææèªå¢ååæåé¸ä¸­çè©å½éè¯ï¼ä¸¦å©ç¨åç¥ç¶ç¶²è·¯ï¼GNNï¼å¾å¤é¨ç¥è­åè­æ¨çæç¨çå¸¸è­ãGNN æ¨å¨åå© PLM é²è¡å¾®èª¿ï¼ä¸¦åéå¶ç¸éè¨æ¶ä»¥ç²å¾æ´å¥½çè¡¨ç¾ãå·é«ä¾èªªï¼æåé¦åå¾å¤é¨ç¥è­åè­ä¸­æåç¸éæ¦å¿µä½çºç¯é»ï¼ä»¥æ§å»ºä¸åå­åï¼å¶ä¸­èªå¢åæå°ä½çºæ¯åç¯ä¾çè¶ç´ç¯é»ãæ¥ä¸ä¾ï¼æåéé PLM å GNN çºèªå¢åæå°å­¸ç¿å©åè¡¨ç¤ºãå©åè¡¨ç¤ºä¹éçç¸ä¼¼æ§æå¤±ç¨æ¼å°å¸¸è­ç¥è­å¾ GNN è½ç§»å° PLMãç¶å¾åä½¿ç¨ PLM ä¾é²è¡ç·ä¸æ¨è«ï¼ä»¥ä¾¿ä¿è­æçãæå¾ï¼æåå° PERSONA-CHAT è³æéçå©åè®é«é²è¡äºå»£æ³çå¯¦é©ï¼éè­ææåçè§£æ±ºæ¹æ¡ä¸åå¯ä»¥æé« PLM çæè½ï¼éè½å¯¦ç¾é«æçæ¨è«ã

##### **Gene Regulatory Network Inference from Pre-trained Single-Cell Transcriptomics Transformer with Joint Graph Learning**
2407.18181v1 by Sindhura Kommu, Yizhi Wang, Yue Wang, Xuan Wang

Inferring gene regulatory networks (GRNs) from single-cell RNA sequencing
(scRNA-seq) data is a complex challenge that requires capturing the intricate
relationships between genes and their regulatory interactions. In this study,
we tackle this challenge by leveraging the single-cell BERT-based pre-trained
transformer model (scBERT), trained on extensive unlabeled scRNA-seq data, to
augment structured biological knowledge from existing GRNs. We introduce a
novel joint graph learning approach that combines the rich contextual
representations learned by pre-trained single-cell language models with the
structured knowledge encoded in GRNs using graph neural networks (GNNs). By
integrating these two modalities, our approach effectively reasons over boththe
gene expression level constraints provided by the scRNA-seq data and the
structured biological knowledge inherent in GRNs. We evaluate our method on
human cell benchmark datasets from the BEELINE study with cell type-specific
ground truth networks. The results demonstrate superior performance over
current state-of-the-art baselines, offering a deeper understanding of cellular
regulatory mechanisms.

æè¦ï¼å¾å®ç´°è RNA å®åº (scRNA-seq) è³ææ¨è«åºå èª¿æ§ç¶²è·¯ (GRN) æ¯ä¸é è¤éçææ°ï¼éè¦ææ¡åºå èå¶èª¿æ§äº¤äºä½ç¨ä¹éçè¤ééä¿ãå¨æ­¤ç ç©¶ä¸­ï¼æåééå©ç¨å¨å»£æ³çæªæ¨è¨ scRNA-seq è³æä¸è¨ç·´çå®ç´°è BERT åºæ¼é è¨ç·´è½æå¨æ¨¡å (scBERT)ï¼ä¾åææ­¤ææ°ï¼ä»¥æ´åç¾æ GRN ä¸­ççµæ§åçç©ç¥è­ãæåå¼å¥ä¸ç¨®æ°ç©çè¯ååå½¢å­¸ç¿æ¹æ³ï¼å®çµåäºé è¨ç·´å®ç´°èèªè¨æ¨¡åæå­¸ç¿å°çè±å¯èçµ¡è¡¨å¾µï¼ä»¥åä½¿ç¨åå½¢ç¥ç¶ç¶²è·¯ (GNN) å° GRN ä¸­ç·¨ç¢¼ççµæ§åç¥è­ãééæ´åéå©ç¨®æ¹å¼ï¼æåçåæ³ææå°å° scRNA-seq è³ææä¾çåºå è¡¨ç¾å±¤ç´ç´æå GRN ä¸­åºæççµæ§åçç©ç¥è­é²è¡æ¨çãæåä½¿ç¨ BEELINE ç ç©¶ä¸­çäººé¡ç´°èåºæºè³æéï¼ä»¥åç´°èé¡åç¹å®çåºæ¬äºå¯¦ç¶²è·¯ï¼ä¾è©ä¼°æåçæ¹æ³ãçµæè­æå¶æè½åªæ¼ç®åæåé²çåºæºï¼æä¾äºå°ç´°èèª¿æ§æ©å¶çæ´æ·±å¥çè§£ã

##### **MathViz-E: A Case-study in Domain-Specialized Tool-Using Agents**
2407.17544v1 by Arya Bulusu, Brandon Man, Ashish Jagmohan, Aditya Vempaty, Jennifer Mari-Wyka, Deepak Akkil

There has been significant recent interest in harnessing LLMs to control
software systems through multi-step reasoning, planning and tool-usage. While
some promising results have been obtained, application to specific domains
raises several general issues including the control of specialized domain
tools, the lack of existing datasets for training and evaluation, and the
non-triviality of automated system evaluation and improvement. In this paper,
we present a case-study where we examine these issues in the context of a
specific domain. Specifically, we present an automated math visualizer and
solver system for mathematical pedagogy. The system orchestrates mathematical
solvers and math graphing tools to produce accurate visualizations from simple
natural language commands. We describe the creation of specialized data-sets,
and also develop an auto-evaluator to easily evaluate the outputs of our system
by comparing them to ground-truth expressions. We have open sourced the
data-sets and code for the proposed system.

æè¦ï¼æè¿ï¼äººä»¬å¯¹å©ç¨å¤§åè¯­è¨æ¨¡å (LLM) æ¥éè¿å¤æ­¥éª¤æ¨çãè§ååå·¥å·ä½¿ç¨æ¥æ§å¶è½¯ä»¶ç³»ç»äº§çäºæå¤§çå´è¶£ãè½ç¶å·²ç»åå¾äºä¸äºæå¸æçç»æï¼ä½åºç¨äºç¹å®é¢åä¼å¼åå ä¸ªæ®éæ§é®é¢ï¼åæ¬å¯¹ä¸ä¸é¢åå·¥å·çæ§å¶ãç¼ºä¹ç¨äºè®­ç»åè¯ä¼°çç°ææ°æ®éï¼ä»¥åèªå¨åç³»ç»è¯ä¼°åæ¹è¿çéå¹³å¡æ§ãå¨æ¬æä¸­ï¼æä»¬æåºäºä¸ä¸ªæ¡ä¾ç ç©¶ï¼å¶ä¸­æä»¬ç ç©¶äºç¹å®é¢åèæ¯ä¸çè¿äºé®é¢ãå·ä½æ¥è¯´ï¼æä»¬å±ç¤ºäºä¸ä¸ªç¨äºæ°å­¦æè²çèªå¨åæ°å­¦å¯è§åå¨åæ±è§£å¨ç³»ç»ãè¯¥ç³»ç»åè°æ°å­¦æ±è§£å¨åæ°å­¦ç»å¾å·¥å·ï¼ä»¥æ ¹æ®ç®åçèªç¶è¯­è¨å½ä»¤çæåç¡®çå¯è§åææãæä»¬æè¿°äºä¸é¨æ°æ®éçåå»ºï¼è¿å¼åäºä¸ä¸ªèªå¨è¯ä¼°å¨ï¼éè¿å°æä»¬çç³»ç»è¾åºä¸çå®è¡¨è¾¾å¼è¿è¡æ¯è¾ï¼è½»æ¾è¯ä¼°å¶è¾åºãæä»¬å·²ç»å¼æºäºææè®®ç³»ç»çä»£ç åæ°æ®éã

##### **Ranking protein-protein models with large language models and graph neural networks**
2407.16375v1 by Xiaotong Xu, Alexandre M. J. J. Bonvin

Protein-protein interactions (PPIs) are associated with various diseases,
including cancer, infections, and neurodegenerative disorders. Obtaining
three-dimensional structural information on these PPIs serves as a foundation
to interfere with those or to guide drug design. Various strategies can be
followed to model those complexes, all typically resulting in a large number of
models. A challenging step in this process is the identification of good models
(near-native PPI conformations) from the large pool of generated models. To
address this challenge, we previously developed DeepRank-GNN-esm, a graph-based
deep learning algorithm for ranking modelled PPI structures harnessing the
power of protein language models. Here, we detail the use of our software with
examples. DeepRank-GNN-esm is freely available at
https://github.com/haddocking/DeepRank-GNN-esm

æè¦ï¼èç½-èç½äº¤äºä½ç¨ (PPI) èåç¨®ç¾çç¸éï¼åæ¬ççãææåç¥ç¶éåæ§ç¾çãåå¾éäº PPI çä¸ç¶­çµæ§è³è¨ï¼ä½çºå¹²æ¾å®åæå¼å°è¥ç©è¨­è¨çåºç¤ãå¯ä»¥éµå¾ªåç¨®ç­ç¥ä¾å»ºæ¨¡éäºè¤åé«ï¼ææéäºç­ç¥éå¸¸æç¢çå¤§éçæ¨¡åãæ­¤éç¨ä¸­çææ°æ§æ­¥é©ï¼æ¯å¾å¤§éç¢ççæ¨¡åä¸­æ¾åºå¥½çæ¨¡åï¼æ¥è¿åç PPI æ§è±¡ï¼ãçºäºæå°éåææ°ï¼æåä¹åéç¼äº DeepRank-GNN-esmï¼éæ¯ä¸ç¨®åºæ¼åå½¢çæ·±åº¦å­¸ç¿æ¼ç®æ³ï¼ç¨æ¼å°å»ºæ¨¡ç PPI çµæ§é²è¡æåï¼å©ç¨èç½è³ªèªè¨æ¨¡åçåéãå¨éè£¡ï¼æåè©³ç´°èªªæäºæåè»é«çä½¿ç¨ç¯ä¾ãDeepRank-GNN-esm å¯å¨ https://github.com/haddocking/DeepRank-GNN-esm åè²»åå¾

##### **PhenoFlow: A Human-LLM Driven Visual Analytics System for Exploring Large and Complex Stroke Datasets**
2407.16329v1 by Jaeyoung Kim, Sihyeon Lee, Hyeon Jeon, Keon-Joo Lee, Hee-Joon Bae, Bohyoung Kim, Jinwook Seo

Acute stroke demands prompt diagnosis and treatment to achieve optimal
patient outcomes. However, the intricate and irregular nature of clinical data
associated with acute stroke, particularly blood pressure (BP) measurements,
presents substantial obstacles to effective visual analytics and
decision-making. Through a year-long collaboration with experienced
neurologists, we developed PhenoFlow, a visual analytics system that leverages
the collaboration between human and Large Language Models (LLMs) to analyze the
extensive and complex data of acute ischemic stroke patients. PhenoFlow
pioneers an innovative workflow, where the LLM serves as a data wrangler while
neurologists explore and supervise the output using visualizations and natural
language interactions. This approach enables neurologists to focus more on
decision-making with reduced cognitive load. To protect sensitive patient
information, PhenoFlow only utilizes metadata to make inferences and synthesize
executable codes, without accessing raw patient data. This ensures that the
results are both reproducible and interpretable while maintaining patient
privacy. The system incorporates a slice-and-wrap design that employs temporal
folding to create an overlaid circular visualization. Combined with a linear
bar graph, this design aids in exploring meaningful patterns within irregularly
measured BP data. Through case studies, PhenoFlow has demonstrated its
capability to support iterative analysis of extensive clinical datasets,
reducing cognitive load and enabling neurologists to make well-informed
decisions. Grounded in long-term collaboration with domain experts, our
research demonstrates the potential of utilizing LLMs to tackle current
challenges in data-driven clinical decision-making for acute ischemic stroke
patients.

æè¦ï¼<paragraph>æ¥æ§ä¸­é¢¨éè¦è¿éè¨ºæ·åæ²»çï¼æè½éå°æä½³ççäººæ²»ççµæãç¶èï¼èæ¥æ§ä¸­é¢¨ç¸éçè¨åºè³æè¤éä¸ä¸è¦åï¼ç¹å¥æ¯è¡å£ (BP) æ¸¬éï¼å°ææçè¦è¦ºåæåæ±ºç­å¶å®æ§æéå¤§éç¤ãééèç¶é©è±å¯çç¥ç¶ç§é«å¸«é·éä¸å¹´çåä½ï¼æåéç¼äº PhenoFlowï¼éæ¯ä¸åè¦è¦ºåæç³»çµ±ï¼å©ç¨äººèå¤§åèªè¨æ¨¡å (LLM) ä¹éçåä½ä¾åææ¥æ§ç¼ºè¡æ§ä¸­é¢¨æ£èçå»£æ³ä¸è¤éè³æãPhenoFlow éåµäºä¸ç¨®åµæ°çå·¥ä½æµç¨ï¼å¶ä¸­ LLM æä»»è³ææ´çå¡ï¼èç¥ç¶ç§é«å¸«åä½¿ç¨è¦è¦ºååèªç¶èªè¨äºåä¾æ¢ç´¢åç£ç£è¼¸åºãéç¨®æ¹æ³ä½¿ç¥ç¶ç§é«å¸«è½å¤ æ´å°æ³¨æ¼æ±ºç­å¶å®ï¼åæéä½èªç¥è² æãçºäºä¿è­·ææççäººè³è¨ï¼PhenoFlow åå©ç¨åè³æé²è¡æ¨è«ä¸¦åæå¯å·è¡ç¨å¼ç¢¼ï¼èä¸æå­ååå§çäººè³æãéç¢ºä¿äºçµææ¢å¯éç¾åå¯è§£éï¼åæç¶­è­·çäººçé±ç§ãè©²ç³»çµ±æ¡ç¨åæ®µååè£è¨­è¨ï¼æ¡ç¨æéæºçä¾å»ºç«çå çåå½¢è¦è¦ºåãçµåç·æ§é·æ¢åï¼æ­¤è¨­è¨æå©æ¼æ¢ç´¢ä¸è¦åæ¸¬éè¡å£è³æä¸­çææç¾©æ¨¡å¼ãééæ¡ä¾ç ç©¶ï¼PhenoFlow å·²è­æå¶æ¯æ´å°å»£æ³è¨åºè³æéé²è¡åè¦åæçè½åï¼éä½èªç¥è² æä¸¦ä½¿ç¥ç¶ç§é«å¸«è½å¤ ååºææºçæ±ºç­ãæåçç ç©¶ä»¥èé åå°å®¶é·æåä½çºåºç¤ï¼è­æäºå©ç¨ LLM ä¾æå°ç¶åæ¥æ§ç¼ºè¡æ§ä¸­é¢¨æ£èè³æé©åè¨åºæ±ºç­å¶å®ææ°çæ½åã</paragraph>

##### **Graph-Structured Speculative Decoding**
2407.16207v1 by Zhuocheng Gong, Jiahao Liu, Ziyue Wang, Pengfei Wu, Jingang Wang, Xunliang Cai, Dongyan Zhao, Rui Yan

Speculative decoding has emerged as a promising technique to accelerate the
inference of Large Language Models (LLMs) by employing a small language model
to draft a hypothesis sequence, which is then validated by the LLM. The
effectiveness of this approach heavily relies on the balance between
performance and efficiency of the draft model. In our research, we focus on
enhancing the proportion of draft tokens that are accepted to the final output
by generating multiple hypotheses instead of just one. This allows the LLM more
options to choose from and select the longest sequence that meets its
standards. Our analysis reveals that hypotheses produced by the draft model
share many common token sequences, suggesting a potential for optimizing
computation. Leveraging this observation, we introduce an innovative approach
utilizing a directed acyclic graph (DAG) to manage the drafted hypotheses. This
structure enables us to efficiently predict and merge recurring token
sequences, vastly reducing the computational demands of the draft model. We
term this approach Graph-structured Speculative Decoding (GSD). We apply GSD
across a range of LLMs, including a 70-billion parameter LLaMA-2 model, and
observe a remarkable speedup of 1.73$\times$ to 1.96$\times$, significantly
surpassing standard speculative decoding.

æè¦ï¼<paragraph>æ¨æ¸¬æ§è§£ç¢¼å·²æçºä¸ç¨®æåéçæè¡ï¼å¯ééä½¿ç¨å°åèªè¨æ¨¡åèµ·èåè¨­åºåï¼ç¶å¾ç±å¤§åèªè¨æ¨¡å (LLM) é©è­è©²åºåï¼å¾èå éå¤§åèªè¨æ¨¡å (LLM) çæ¨çãæ­¤æ¹æ³çæææ§å¨å¾å¤§ç¨åº¦ä¸åæ±ºæ¼èç¨¿æ¨¡åçæ§è½åæçä¹éçå¹³è¡¡ãå¨æåçç ç©¶ä¸­ï¼æåå°æ³¨æ¼ééçæå¤ååè¨­èä¸æ¯åªçæä¸ååè¨­ä¾æé«è¢«æ¥åçºæçµè¼¸åºçèç¨¿ä»¤ççæ¯ä¾ãéåè¨± LLM å¾ä¸­é¸ææ´å¤é¸é ï¼ä¸¦é¸æç¬¦åå¶æ¨æºçæé·åºåãæåçåæè¡¨æï¼èç¨¿æ¨¡åç¢ççåè¨­å±äº«è¨±å¤å¬å±ä»¤çåºåï¼éè¡¨æåªåè¨ç®çå¯è½æ§ãå©ç¨éä¸è§å¯çµæï¼æåå¼å¥äºä¸ç¨®åµæ°çæ¹æ³ï¼å©ç¨æåç¡ç°å (DAG) ä¾ç®¡çå·²ç·¨å¶çåè¨­ãéç¨®çµæ§ä½¿æåè½å¤ ææå°é æ¸¬ååä½µéè¤çä»¤çåºåï¼å¾èå¤§å¤§éä½äºèç¨¿æ¨¡åçè¨ç®éæ±ãæåå°éç¨®æ¹æ³ç¨±çºåçµæ§æ¨æ¸¬æ§è§£ç¢¼ (GSD)ãæåå° GSD æç¨æ¼ä¸ç³»å LLMï¼åæ¬ä¸å 700 ååæ¸ç LLaMA-2 æ¨¡åï¼ä¸¦è§å¯å°é¡¯èçå éï¼å¾ 1.73 åå° 1.96 åï¼é¡¯èè¶éæ¨æºæ¨æ¸¬æ§è§£ç¢¼ã</paragraph>

##### **Evaluating Long Range Dependency Handling in Code Generation Models using Multi-Step Key Retrieval**
2407.21049v1 by Yannick Assogba, Donghao Ren

As language models support larger and larger context sizes, evaluating their
ability to make effective use of that context becomes increasingly important.
We analyze the ability of several code generation models to handle long range
dependencies using a suite of multi-step key retrieval tasks in context windows
up to 8k tokens in length. The tasks progressively increase in difficulty and
allow more nuanced evaluation of model capabilities than tests like the popular
needle-in-the-haystack test. We find that performance degrades significantly
(up to 2x) when a function references another function that is defined later in
the prompt. We also observe that models that use sliding window attention
mechanisms have difficulty handling references further than the size of a
single window. We perform simple prompt modifications using call graph
information to improve multi-step retrieval performance up to 3x. Our analysis
highlights different facets of long-context performance and is suggestive of
prompt construction strategies for code completion tools

æè¦ï¼é¨èèªè¨æ¨¡åæ¯æ´çå§å®¹å¤§å°è¶ä¾è¶å¤§ï¼è©ä¼°å¶ææå©ç¨è©²å§å®¹çè½åè®å¾è¶ä¾è¶éè¦ãæååæäºå¹¾åç¨å¼ç¢¼çææ¨¡åèçé·è·é¢ä¾è³´éä¿çè½åï¼ä½¿ç¨ä¸çµå¤æ­¥é©ééµæª¢ç´¢ä»»åï¼å¨é·é 8k ä»¤ççå§å®¹è¦çªä¸­ãä»»åéæ¼¸å¢å é£åº¦ï¼ä¸¦åè¨±å°æ¨¡ååè½é²è¡æ¯æµè¡çéé ­ä¹¾èå æ¸¬è©¦æ´ç´°ç·»çè©ä¼°ãæåç¼ç¾ï¼ç¶å½å¼åç§ç¨å¾å¨æç¤ºä¸­å®ç¾©çå¦ä¸åå½å¼æï¼æè½æé¡¯èä¸éï¼æå¤ 2 åï¼ãæåéè§å¯å°ï¼ä½¿ç¨æ»åè¦çªæ³¨ææ©å¶çæ¨¡åé£ä»¥èçè¶åºå®ä¸è¦çªå¤§å°çåç§ãæåä½¿ç¨å¼å«åå½¢è³è¨å·è¡ç°¡å®çæç¤ºä¿®æ¹ï¼ä»¥å°å¤æ­¥é©æª¢ç´¢æè½æåè³ 3 åãæåçåæçªé¡¯äºé·å§å®¹æè½çä¸åé¢åï¼ä¸¦æç¤ºäºç¨å¼ç¢¼å®æå·¥å·çæç¤ºå»ºæ§ç­ç¥

##### **Finetuning Generative Large Language Models with Discrimination Instructions for Knowledge Graph Completion**
2407.16127v1 by Yang Liu, Xiaobin Tian, Zequn Sun, Wei Hu

Traditional knowledge graph (KG) completion models learn embeddings to
predict missing facts. Recent works attempt to complete KGs in a
text-generation manner with large language models (LLMs). However, they need to
ground the output of LLMs to KG entities, which inevitably brings errors. In
this paper, we present a finetuning framework, DIFT, aiming to unleash the KG
completion ability of LLMs and avoid grounding errors. Given an incomplete
fact, DIFT employs a lightweight model to obtain candidate entities and
finetunes an LLM with discrimination instructions to select the correct one
from the given candidates. To improve performance while reducing instruction
data, DIFT uses a truncated sampling method to select useful facts for
finetuning and injects KG embeddings into the LLM. Extensive experiments on
benchmark datasets demonstrate the effectiveness of our proposed framework.

æè¦ï¼å³çµ±ç¥è­åè­ï¼KGï¼å®æåè½æ¨¡åå­¸ç¿åµå¥ï¼ä»¥é æ¸¬éºå¤±çäºå¯¦ãæè¿çå·¥ä½åè©¦ä»¥å¤§åèªè¨æ¨¡åï¼LLMï¼ä»¥æå­çæçæ¹å¼å®æ KGãç¶èï¼ä»åéè¦å° LLM çè¼¸åºåºç¤å»ºç«å¨ KG å¯¦é«ä¸ï¼éä¸å¯é¿åå°æå¸¶ä¾é¯èª¤ãå¨æ¬æä¸­ï¼æåæåºäºä¸åå¾®èª¿æ¡æ¶ DIFTï¼æ¨å¨éæ¾ LLM ç KG å®æåè½ï¼ä¸¦é¿ååºç¤é¯èª¤ãçµ¦å®ä¸åä¸å®æ´çäºå¯¦ï¼DIFT ä½¿ç¨ä¸åè¼éç´æ¨¡åä¾ç²å¾åé¸å¯¦é«ï¼ä¸¦å¾®èª¿ä¸å LLMï¼ä¸¦ä½¿ç¨è¾¨å¥æä»¤å¾çµ¦å®çåé¸é ä¸­é¸ææ­£ç¢ºçå¯¦é«ãçºäºå¨æ¸å°æä»¤æ¸æçåææåæè½ï¼DIFT ä½¿ç¨ä¸åæªæ·æ½æ¨£æ¹æ³ä¾é¸ææç¨çäºå¯¦ä»¥é²è¡å¾®èª¿ï¼ä¸¦å° KG åµå¥æ³¨å¥å° LLM ä¸­ãå¨åºæºè³æéä¸çå»£æ³å¯¦é©è­æäºæåæåºçæ¡æ¶çæææ§ã

##### **Unsupervised Robust Cross-Lingual Entity Alignment via Joint Modeling of Entity and Relation Texts**
2407.15588v1 by Soojin Yoon, Sungho Ko, Tongyoung Kim, SeongKu Kang, Jinyoung Yeo, Dongha Lee

Cross-lingual entity alignment (EA) enables the integration of multiple
knowledge graphs (KGs) across different languages, providing users with
seamless access to diverse and comprehensive knowledge.Existing methods, mostly
supervised, face challenges in obtaining labeled entity pairs. To address this,
recent studies have shifted towards a self-supervised and unsupervised
frameworks. Despite their effectiveness, these approaches have limitations: (1)
they mainly focus on entity features, neglecting the semantic information of
relations, (2) they assume isomorphism between source and target graphs,
leading to noise and reduced alignment accuracy, and (3) they are susceptible
to noise in the textual features, especially when encountering inconsistent
translations or Out-Of-Vocabulary (OOV) problems.
  In this paper, we propose ERAlign, an unsupervised and robust cross-lingual
EA framework that jointly performs Entity-level and Relation-level Alignment
using semantic textual features of relations and entities. Its refinement
process iteratively enhances results by fusing entity-level and relation-level
alignments based on neighbor triple matching. The additional verification
process examines the entities' neighbor triples as the linearized text. This
\textit{Align-and-Verify} pipeline that rigorously assesses alignment results,
achieving near-perfect alignment even in the presence of noisy textual features
of entities. Our extensive experiments demonstrate that robustness and general
applicability of \proposed improved the accuracy and effectiveness of EA tasks,
contributing significantly to knowledge-oriented applications.

æè¦ï¼è·¨èªè¨å¯¦é«å°é½ (EA) è½å¤ æ´åä¸åèªè¨ä¸­çå¤åç¥è­åè­ (KG)ï¼è®ä½¿ç¨èè½ç¡ç¸«å°å­åå¤åä¸å¨é¢çç¥è­ãç¾ææ¹æ³å¤§å¤æ¯æç£ç£çï¼å¨åå¾æ¨è¨å¯¦é«å°æé¢è¨ææ°ãçºäºè§£æ±ºéååé¡ï¼æè¿çç ç©¶å·²è½åèªç£ç£åç¡ç£ç£çæ¶æ§ãåç®¡éäºæ¹æ³å¾ææï¼ä½å®åæä»¥ä¸éå¶ï¼(1) å®åä¸»è¦éæ³¨å¯¦é«ç¹å¾µï¼å¿½ç¥éä¿çèªç¾©è³è¨ï¼(2) å®ååè¨­ä¾æºåè­åç®æ¨åè­ä¹éåæ§ï¼å°è´éè¨åå°é½æºç¢ºåº¦éä½ï¼(3) å®åå®¹æåå°æå­ç¹å¾µä¸­çéè¨å½±é¿ï¼ç¹å¥æ¯å¨éå°ä¸ä¸è´çç¿»è­¯æè©å½å¤åé¡ (OOV) æã
å¨æ¬æä¸­ï¼æåæåº ERAlignï¼ä¸åç¡ç£ç£ä¸ç©©å¥çè·¨èªè¨ EA æ¶æ§ï¼å®ä½¿ç¨éä¿åå¯¦é«çèªç¾©æå­ç¹å¾µï¼åæå·è¡å¯¦é«å±¤ç´åéä¿å±¤ç´å°é½ãå®çç²¾çç¨åºééæ ¹æé°æ¥ä¸åçµå¹éèåå¯¦é«å±¤ç´åéä¿å±¤ç´å°é½ï¼åè¦å¢å¼·çµæãé¡å¤çé©è­ç¨åºå°å¯¦é«çé°æ¥ä¸åçµè¦çºç·æ§åæå­é²è¡æª¢æ¥ãéåå´æ ¼è©ä¼°å°é½çµæçãå°é½åé©è­ãç®¡ç·ï¼å³ä½¿å¨å­å¨å¯¦é«çéè¨æå­ç¹å¾µæä¹è½éæè¿ä¹å®ç¾çå°é½ãæåå»£æ³çå¯¦é©è­æï¼\proposed çç©©å¥æ§åæ®éé©ç¨æ§æåäº EA ä»»åçæºç¢ºåº¦åæææ§ï¼å°ç¥è­å°åæç¨ç¨å¼æé¡¯èçè²¢ç»ã

##### **The Ontoverse: Democratising Access to Knowledge Graph-based Data Through a Cartographic Interface**
2408.03339v1 by Johannes Zimmermann, Dariusz Wiktorek, Thomas Meusburger, Miquel Monge-Dalmau, Antonio Fabregat, Alexander Jarasch, GÃ¼nter Schmidt, Jorge S. Reis-Filho, T. Ian Simpson

As the number of scientific publications and preprints is growing
exponentially, several attempts have been made to navigate this complex and
increasingly detailed landscape. These have almost exclusively taken
unsupervised approaches that fail to incorporate domain knowledge and lack the
structural organisation required for intuitive interactive human exploration
and discovery. Especially in highly interdisciplinary fields, a deep
understanding of the connectedness of research works across topics is essential
for generating insights. We have developed a unique approach to data navigation
that leans on geographical visualisation and uses hierarchically structured
domain knowledge to enable end-users to explore knowledge spaces grounded in
their desired domains of interest. This can take advantage of existing
ontologies, proprietary intelligence schemata, or be directly derived from the
underlying data through hierarchical topic modelling. Our approach uses natural
language processing techniques to extract named entities from the underlying
data and normalise them against relevant domain references and navigational
structures. The knowledge is integrated by first calculating similarities
between entities based on their shared extracted feature space and then by
alignment to the navigational structures. The result is a knowledge graph that
allows for full text and semantic graph query and structured topic driven
navigation. This allows end-users to identify entities relevant to their needs
and access extensive graph analytics. The user interface facilitates graphical
interaction with the underlying knowledge graph and mimics a cartographic map
to maximise ease of use and widen adoption. We demonstrate an exemplar project
using our generalisable and scalable infrastructure for an academic biomedical
literature corpus that is grounded against hundreds of different named domain
entities.

æè¦ï¼<paragraph>é¨èç§å­¸åºçç©åé å°æ¬æ¸éåææ¸å¢é·ï¼å·²ç¶é²è¡äºå¤é åè©¦ä¾æ¢ç´¢éåè¤éä¸æ¥çè©³ç´°çé åãéäºåè©¦å¹¾ä¹å®å¨æ¡ç¨äºç¡æ³ç´å¥é åç¥è­ä¸ç¼ºä¹ç´è§äºåå¼äººé¡æ¢ç´¢åç¼ç¾æéççµæ§æ§çµç¹çç¡ç£ç£æ¹æ³ãç¹å¥æ¯å¨é«åº¦è·¨å­¸ç§çé åä¸­ï¼æ·±å¥äºè§£è·¨ä¸»é¡çç ç©¶å·¥ä½çé£éæ§å°æ¼ç¢çè¦è§£è³ééè¦ãæåéç¼äºä¸ç¨®ç¨ç¹çæ¹æ³ä¾é²è¡è³æå°èªï¼è©²æ¹æ³ä¾è³´æ¼å°çè¦è¦ºåï¼ä¸¦ä½¿ç¨åå±¤çµæ§çé åç¥è­ï¼ä½¿ç¨æ¶è½å¤ æ¢ç´¢å»ºç«å¨ä»åæèè¶£çç®æ¨é åä¸­çç¥è­ç©ºéãéå¯ä»¥å©ç¨ç¾æçæ¬ä½ãå°ææºæ§æ¨¡å¼ï¼æç´æ¥å¾åºç¤è³æä¸­ééåå±¤ä¸»é¡å»ºæ¨¡è¡çåºä¾ãæåçåæ³ä½¿ç¨èªç¶èªè¨èçæè¡å¾åºç¤è³æä¸­æåå½åå¯¦é«ï¼ä¸¦æ ¹æç¸éçé ååèåå°èªçµæ§å°å®åé²è¡æ¨æºåãç¥è­çæ´åé¦åééæ ¹æå±äº«çæåç¹å¾µç©ºéè¨ç®å¯¦é«ä¹éçç¸ä¼¼æ§ï¼ç¶å¾ééèå°èªçµæ§çå°é½ä¾é²è¡ãçµææ¯ä¸åç¥è­åï¼åè¨±é²è¡å¨æåèªç¾©åæ¥è©¢ä»¥åçµæ§åä¸»é¡é©åå°èªãéä½¿ç¨æ¶è½å¤ è­å¥èå¶éæ±ç¸éçå¯¦é«ï¼ä¸¦å­åå»£æ³çåå½¢åæãä½¿ç¨èä»é¢ä¿é²äºèåºç¤ç¥è­åå½¢çåå½¢äºåï¼ä¸¦æ¨¡æ¬è£½åå°åä»¥æå¤§éåº¦å°æé«æç¨æ§åæ´å¤§æ¡ç¨çãæåå±ç¤ºäºä¸åç¯ä¾å°æ¡ï¼ä½¿ç¨æåéå°æ¸ç¾åä¸åçå½åé åå¯¦é«å»ºç«çéç¨ä¸å¯æ´åçåºç¤æ¶æ§ï¼ç¨æ¼å­¸è¡çç©é«å­¸æç»èªæåº«ã</paragraph>

##### **Pre-Training and Prompting for Few-Shot Node Classification on Text-Attributed Graphs**
2407.15431v1 by Huanjing Zhao, Beining Yang, Yukuo Cen, Junyu Ren, Chenhui Zhang, Yuxiao Dong, Evgeny Kharlamov, Shu Zhao, Jie Tang

The text-attributed graph (TAG) is one kind of important real-world
graph-structured data with each node associated with raw texts. For TAGs,
traditional few-shot node classification methods directly conduct training on
the pre-processed node features and do not consider the raw texts. The
performance is highly dependent on the choice of the feature pre-processing
method. In this paper, we propose P2TAG, a framework designed for few-shot node
classification on TAGs with graph pre-training and prompting. P2TAG first
pre-trains the language model (LM) and graph neural network (GNN) on TAGs with
self-supervised loss. To fully utilize the ability of language models, we adapt
the masked language modeling objective for our framework. The pre-trained model
is then used for the few-shot node classification with a mixed prompt method,
which simultaneously considers both text and graph information. We conduct
experiments on six real-world TAGs, including paper citation networks and
product co-purchasing networks. Experimental results demonstrate that our
proposed framework outperforms existing graph few-shot learning methods on
these datasets with +18.98% ~ +35.98% improvements.

æè¦ï¼ææ¬å±æ§å¾ (TAG) æ¯ä¸ç§éè¦ççå®ä¸çå¾ç»æåæ°æ®ï¼å¶ä¸­æ¯ä¸ªèç¹é½ä¸åå§ææ¬ç¸å³èãå¯¹äº TAGï¼ä¼ ç»çå°æ°éå¤´èç¹åç±»æ¹æ³ç´æ¥å¯¹é¢å¤ççèç¹ç¹å¾è¿è¡è®­ç»ï¼èä¸èèåå§ææ¬ãæ§è½å¨å¾å¤§ç¨åº¦ä¸åå³äºç¹å¾é¢å¤çæ¹æ³çéæ©ãå¨æ¬æä¸­ï¼æä»¬æåºäº P2TAGï¼è¿æ¯ä¸ä¸ªä¸ä¸º TAG ä¸çå°æ°éå¤´èç¹åç±»è®¾è®¡çæ¡æ¶ï¼å·æå¾é¢è®­ç»åæç¤ºãP2TAG é¦åä½¿ç¨èªæçç£æå¤±å¯¹ TAG ä¸çè¯­è¨æ¨¡å (LM) åå¾ç¥ç»ç½ç» (GNN) è¿è¡é¢è®­ç»ãä¸ºäºååå©ç¨è¯­è¨æ¨¡åçè½åï¼æä»¬ä¸ºæä»¬çæ¡æ¶è°æ´äºæ©ç è¯­è¨å»ºæ¨¡ç®æ ãç¶åä½¿ç¨é¢è®­ç»æ¨¡åè¿è¡å°æ°éå¤´èç¹åç±»ï¼éç¨æ··åæç¤ºæ¹æ³ï¼åæ¶èèææ¬åå¾ä¿¡æ¯ãæä»¬å¯¹å­ä¸ªçå®ä¸çç TAG è¿è¡äºå®éªï¼åæ¬è®ºæå¼ç¨ç½ç»åäº§åå±åè´­ä¹°ç½ç»ãå®éªç»æè¡¨æï¼æä»¬æåºçæ¡æ¶å¨è¿äºæ°æ®éä¸ä¼äºç°æçå¾å°æ°éå¤´å­¦ä¹ æ¹æ³ï¼æ¹è¿äº +18.98% ~ +35.98%ã

##### **LLMExplainer: Large Language Model based Bayesian Inference for Graph Explanation Generation**
2407.15351v2 by Jiaxing Zhang, Jiayi Liu, Dongsheng Luo, Jennifer Neville, Hua Wei

Recent studies seek to provide Graph Neural Network (GNN) interpretability
via multiple unsupervised learning models. Due to the scarcity of datasets,
current methods easily suffer from learning bias. To solve this problem, we
embed a Large Language Model (LLM) as knowledge into the GNN explanation
network to avoid the learning bias problem. We inject LLM as a Bayesian
Inference (BI) module to mitigate learning bias. The efficacy of the BI module
has been proven both theoretically and experimentally. We conduct experiments
on both synthetic and real-world datasets. The innovation of our work lies in
two parts: 1. We provide a novel view of the possibility of an LLM functioning
as a Bayesian inference to improve the performance of existing algorithms; 2.
We are the first to discuss the learning bias issues in the GNN explanation
problem.

æè¦ï¼è¿æç ç©¶è©¦åééå¤ç¨®éç£ç£å¼å­¸ç¿æ¨¡åä¾æä¾åç¥ç¶ç¶²è·¯ (GNN) çå¯è§£éæ§ãç±æ¼è³æéçç¨å°ï¼ç®åçæ¼ç®æ³å®¹æåå°å­¸ç¿åå·®çå½±é¿ãçºäºè§£æ±ºéååé¡ï¼æåå°å¤§åèªè¨æ¨¡å (LLM) ä½çºç¥è­åµå¥å° GNN è§£éç¶²è·¯ä¸­ï¼ä»¥é¿åå­¸ç¿åå·®çåé¡ãæåå° LLM ä½çºè²æ°æ¨è« (BI) æ¨¡çµæ³¨å¥ï¼ä»¥æ¸è¼å­¸ç¿åå·®ãBI æ¨¡çµçæè½å·²å¨çè«ä¸åå¯¦é©ä¸å¾å°è­å¯¦ãæåå¨åæåçå¯¦ä¸çè³æéä¸é²è¡å¯¦é©ãæåå·¥ä½çåµæ°ä¹èå¨æ¼å©é¨åï¼1. æåæä¾ LLM ä½çºè²æ°æ¨è«ä»¥æ¹åç¾ææ¼ç®æ³æè½çå¯è½æ§ä¹æ°è§é»ï¼2. æåçåè¨è« GNN è§£éåé¡ä¸­çå­¸ç¿åå·®åé¡ã

##### **Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation**
2407.15141v1 by Yu Zhang, Ruijie Yu, Kaipeng Zeng, Ding Li, Feng Zhu, Xiaokang Yang, Yaohui Jin, Yanyan Xu

High-throughput reaction condition (RC) screening is fundamental to chemical
synthesis. However, current RC screening suffers from laborious and costly
trial-and-error workflows. Traditional computer-aided synthesis planning (CASP)
tools fail to find suitable RCs due to data sparsity and inadequate reaction
representations. Nowadays, large language models (LLMs) are capable of tackling
chemistry-related problems, such as molecule design, and chemical logic Q\&A
tasks. However, LLMs have not yet achieved accurate predictions of chemical
reaction conditions. Here, we present MM-RCR, a text-augmented multimodal LLM
that learns a unified reaction representation from SMILES, reaction graphs, and
textual corpus for chemical reaction recommendation (RCR). To train MM-RCR, we
construct 1.2 million pair-wised Q\&A instruction datasets. Our experimental
results demonstrate that MM-RCR achieves state-of-the-art performance on two
open benchmark datasets and exhibits strong generalization capabilities on
out-of-domain (OOD) and High-Throughput Experimentation (HTE) datasets. MM-RCR
has the potential to accelerate high-throughput condition screening in chemical
synthesis.

æè¦ï¼é«ééåææ¢ä»¶ (RC) ç¯©é¸æ¯åå­¸åæä¸­çåºç¤ãç¶èï¼ç¶åç RC ç¯©é¸æéå°ç¹ç£ä¸æè²´çè©¦é¯å·¥ä½æµç¨ãå³çµ±çé»è¦è¼å©åæè¦å (CASP) å·¥å·ç¡æ³æ¾å°åé©ç RCï¼éæ¯å çºè³æç¨çä¸åæè¡¨ç¤ºä¸è¶³ãå¦ä»ï¼å¤§åèªè¨æ¨¡å (LLM) è½å¤ è§£æ±ºèåå­¸ç¸éçåé¡ï¼ä¾å¦åå­è¨­è¨ååå­¸éè¼¯åç­ä»»åãç¶èï¼LLM å°æªéæåå­¸åææ¢ä»¶çæºç¢ºé æ¸¬ãå¨æ­¤ï¼æåæåº MM-RCRï¼ä¸åææ¬å¢å¼·çå¤æ¨¡æ LLMï¼å®å¾ SMILESãåæååææ¬èªæåº«å­¸ç¿çµ±ä¸çåæè¡¨ç¤ºï¼ä»¥é²è¡åå­¸åææ¨è¦ (RCR)ãçºäºè¨ç·´ MM-RCRï¼æåå»ºæ§äº 120 è¬å°éå°çåç­æä»¤è³æéãæåçå¯¦é©çµæè­æï¼MM-RCR å¨å©åéæ¾åºæºè³æéä¸éå°äºæåé²çæè½ï¼ä¸¦å¨é åå¤ (OOD) åé«ééå¯¦é© (HTE) è³æéä¸å±ç¾åºå¼·å¤§çæ¦åè½åãMM-RCR æå¯è½å éåå­¸åæä¸­çé«ééæ¢ä»¶ç¯©é¸ã

##### **On the Design and Analysis of LLM-Based Algorithms**
2407.14788v1 by Yanxi Chen, Yaliang Li, Bolin Ding, Jingren Zhou

We initiate a formal investigation into the design and analysis of LLM-based
algorithms, i.e. algorithms that contain one or multiple calls of large
language models (LLMs) as sub-routines and critically rely on the capabilities
of LLMs. While LLM-based algorithms, ranging from basic LLM calls with prompt
engineering to complicated LLM-powered agent systems and compound AI systems,
have achieved remarkable empirical success, the design and optimization of them
have mostly relied on heuristics and trial-and-errors, which is largely due to
a lack of formal and analytical study for these algorithms. To fill this gap,
we start by identifying the computational-graph representation of LLM-based
algorithms, the design principle of task decomposition, and some key
abstractions, which then facilitate our formal analysis for the accuracy and
efficiency of LLM-based algorithms, despite the black-box nature of LLMs. We
further consider parallel decomposition for a case study, providing extensive
analytical and empirical study for four concrete examples of this pattern. Our
proposed framework holds promise for advancing LLM-based algorithms, by
revealing the reasons behind curious empirical phenomena, guiding the choices
of hyperparameters, predicting the empirical performance of algorithms, and
inspiring new algorithm design. To promote further study of LLM-based
algorithms, we release our source code at
https://github.com/modelscope/agentscope/tree/main/examples/paper_llm_based_algorithm.

æè¦ï¼<paragraph>æåå°åºæ¼ LLM çæ¼ç®æ³çè¨­è¨ååæå±éæ­£å¼èª¿æ¥ï¼å³åå«ä¸åæå¤åå¤§åèªè¨æ¨¡å (LLM) ä½çºå­å¸¸å¼å¼å«çæ¼ç®æ³ï¼ä¸¦æ¥µåº¦ä¾è³´ LLM çåè½ãåç®¡åºæ¼ LLM çæ¼ç®æ³ï¼å¾å¸¶æç¤ºå·¥ç¨çåºæ¬ LLM å¼å«å°è¤éç LLM é©åçä»£çç³»çµ±åè¤åå¼ AI ç³»çµ±ï¼å·²åå¾é¡¯èçå¯¦è­æåï¼ä½å¶è¨­è¨åæä½³åå¤§å¤ä¾è³´è©¦é©æ³åé¯èª¤ï¼éå¨å¾å¤§ç¨åº¦ä¸æ¯å çºç¼ºä¹å°éäºæ¼ç®æ³çæ­£å¼ååæç ç©¶ãçºäºå¡«è£éåç©ºç½ï¼æåå¾è­å¥åºæ¼ LLM çæ¼ç®æ³çè¨ç®åè¡¨ç¤ºãä»»ååè§£çè¨­è¨ååï¼ä»¥åä¸äºééµæ½è±¡åéå§ï¼ç¶å¾ä¿é²æåå°åºæ¼ LLM çæ¼ç®æ³çæºç¢ºæ§åæçé²è¡æ­£å¼åæï¼åç®¡ LLM æ¬èº«å·æé»çç¹æ§ãæåé²ä¸æ­¥èæ®ä¸¦è¡åè§£ä½çºæ¡ä¾ç ç©¶ï¼çºæ­¤æ¨¡å¼çååå·é«ç¯ä¾æä¾å»£æ³çåæåå¯¦è­ç ç©¶ãæåæåºçæ¶æ§æææ¨é²åºæ¼ LLM çæ¼ç®æ³ï¼æ¹æ³æ¯æ­ç¤ºå¥æªçå¯¦è­ç¾è±¡èå¾çåå ãæå°è¶åæ¸çé¸æãé æ¸¬æ¼ç®æ³çå¯¦è­æè½ï¼ä¸¦æ¿ç¼æ°çæ¼ç®æ³è¨­è¨ãçºäºä¿é²å°åºæ¼ LLM çæ¼ç®æ³çé²ä¸æ­¥ç ç©¶ï¼æåå¨ https://github.com/modelscope/agentscope/tree/main/examples/paper_llm_based_algorithm/ ç¼å¸æåçåå§ç¢¼ã</paragraph>

##### **LaMAGIC: Language-Model-based Topology Generation for Analog Integrated Circuits**
2407.18269v1 by Chen-Chia Chang, Yikang Shan, Shaoze Fan, Jing Li, Shun Zhang, Ningyuan Cao, Yiran Chen, Xin Zhang

In the realm of electronic and electrical engineering, automation of analog
circuit is increasingly vital given the complexity and customized requirements
of modern applications. However, existing methods only develop search-based
algorithms that require many simulation iterations to design a custom circuit
topology, which is usually a time-consuming process. To this end, we introduce
LaMAGIC, a pioneering language model-based topology generation model that
leverages supervised finetuning for automated analog circuit design. LaMAGIC
can efficiently generate an optimized circuit design from the custom
specification in a single pass. Our approach involves a meticulous development
and analysis of various input and output formulations for circuit. These
formulations can ensure canonical representations of circuits and align with
the autoregressive nature of LMs to effectively addressing the challenges of
representing analog circuits as graphs. The experimental results show that
LaMAGIC achieves a success rate of up to 96\% under a strict tolerance of 0.01.
We also examine the scalability and adaptability of LaMAGIC, specifically
testing its performance on more complex circuits. Our findings reveal the
enhanced effectiveness of our adjacency matrix-based circuit formulation with
floating-point input, suggesting its suitability for handling intricate circuit
designs. This research not only demonstrates the potential of language models
in graph generation, but also builds a foundational framework for future
explorations in automated analog circuit design.

æè¦ï¼å¨é»å­åé»æ°£å·¥ç¨é åä¸­ï¼èªååé¡æ¯é»è·¯è¶ä¾è¶éè¦ï¼å çºç¾ä»£æç¨ç¨å¼å·æè¤éä¸å®¢è£½åçéæ±ãç¶èï¼ç¾æçæ¹æ³åéç¼åºæ¼æå°çæ¼ç®æ³ï¼éè¦è¨±å¤æ¨¡æ¬åè¦éç®æè½è¨­è¨å®¢è£½åé»è·¯ææ²ï¼ééå¸¸æ¯ä¸åèæçéç¨ãçºæ­¤ï¼æåå¼å¥äº LaMAGICï¼ä¸ååºæ¼åé©èªè¨æ¨¡åçææ²çææ¨¡åï¼å®å©ç¨ç£ç£å¾®èª¿é²è¡èªååé¡æ¯é»è·¯è¨­è¨ãLaMAGIC å¯ä»¥ææçå°å¾å®¢è£½åè¦æ ¼ä¸­çææä½³åçé»è·¯è¨­è¨ï¼åªéä¸æ¬¡ééãæåçåæ³åæ¬ä»ç´°éç¼ååæé»è·¯çåç¨®è¼¸å¥åè¼¸åºå¬å¼ãéäºå¬å¼å¯ä»¥ç¢ºä¿é»è·¯çæ¨æºè¡¨ç¤ºï¼ä¸¦è LM çèªè¿´æ­¸æ§è³ªä¿æä¸è´ï¼ä»¥ææè§£æ±ºå°é¡æ¯é»è·¯è¡¨ç¤ºçºåå½¢çææ°ãå¯¦é©çµæé¡¯ç¤ºï¼LaMAGIC å¨ 0.01 çå´æ ¼å®¹å·®ä¸å¯¦ç¾äºé«é 96% çæåçãæåéæª¢æ¥äº LaMAGIC çå¯æ´åæ§åé©ææ§ï¼ç¹å¥æ¯æ¸¬è©¦äºå®å¨æ´è¤éé»è·¯ä¸çæè½ãæåçç ç©¶çµææ­ç¤ºäºæååºæ¼é°æ¥ç©é£çé»è·¯å¬å¼èæµ®é»è¼¸å¥çå¢å¼·æè½ï¼è¡¨æå®é©ç¨æ¼èçè¤éçé»è·¯è¨­è¨ãéé ç ç©¶ä¸åå±ç¤ºäºèªè¨æ¨¡åå¨åå½¢çæä¸­çæ½åï¼ä¹çºæªä¾å¨èªååé¡æ¯é»è·¯è¨­è¨ä¸­çæ¢ç´¢å»ºç«äºåºç¤æ¡æ¶ã

##### **Hierarchical Windowed Graph Attention Network and a Large Scale Dataset for Isolated Indian Sign Language Recognition**
2407.14224v1 by Suvajit Patra, Arkadip Maitra, Megha Tiwari, K. Kumaran, Swathy Prabhu, Swami Punyeshwarananda, Soumitra Samanta

Automatic Sign Language (SL) recognition is an important task in the computer
vision community. To build a robust SL recognition system, we need a
considerable amount of data which is lacking particularly in Indian sign
language (ISL). In this paper, we propose a large-scale isolated ISL dataset
and a novel SL recognition model based on skeleton graph structure. The dataset
covers 2,002 daily used common words in the deaf community recorded by 20 (10
male and 10 female) deaf adult signers (contains 40033 videos). We propose a SL
recognition model namely Hierarchical Windowed Graph Attention Network (HWGAT)
by utilizing the human upper body skeleton graph structure. The HWGAT tries to
capture distinctive motions by giving attention to different body parts induced
by the human skeleton graph structure. The utility of the proposed dataset and
the usefulness of our model are evaluated through extensive experiments. We
pre-trained the proposed model on the proposed dataset and fine-tuned it across
different sign language datasets further boosting the performance of 1.10,
0.46, 0.78, and 6.84 percentage points on INCLUDE, LSA64, AUTSL and WLASL
respectively compared to the existing state-of-the-art skeleton-based models.

æè¦ï¼èªåæèª (SL) è­å¥æ¯é»è¦è¦è¦ºç¤¾ç¾¤ä¸­çéè¦ä»»åãè¦å»ºç«å¼·å¥ç SL è­å¥ç³»çµ±ï¼æåéè¦å¤§éçè³æï¼èéå¨å°åº¦æèª (ISL) ä¸­ç¹å¥ç¼ºä¹ãå¨æ¬æä¸­ï¼æåæåºä¸åå¤§è¦æ¨¡çå­¤ç« ISL è³æéï¼ä»¥åä¸ååºæ¼éª¨æ¶åçµæ§çæ°å SL è­å¥æ¨¡åãè©²è³æéæ¶µè 2,002 åè¾åç¤¾ç¾¤ä¸­å¸¸ç¨çæ¥å¸¸å®å­ï¼ç± 20 ä½ (10 ç· 10 å¥³) è¾åæäººæèªèéè£½ï¼åå« 40033 é¨å½±çï¼ãæåæåºä¸å SL è­å¥æ¨¡åï¼å³åå±¤è¦çªåæ³¨æåç¶²è·¯ (HWGAT)ï¼å©ç¨äººé«ä¸åèº«éª¨æ¶åçµæ§ãHWGAT åè©¦éééæ³¨ç±äººé«éª¨æ¶åçµæ§èªå°çä¸åèº«é«é¨ä½ä¾ææç¨ç¹çåä½ãééå»£æ³çå¯¦é©è©ä¼°ææåºçè³æéçæç¨åæåæ¨¡åçæç¨æ§ãæåå¨ææåºçè³æéä¸é è¨ç·´ææåºçæ¨¡åï¼ä¸¦å¨ä¸åçæèªè³æéä¸å¾®èª¿å®ï¼é²ä¸æ­¥æåäº INCLUDEãLSA64ãAUTSL å WLASL ä¸ 1.10ã0.46ã0.78 å 6.84 åç¾åé»çæè½ï¼åå¥èç¾æçæåé²çåºæ¼éª¨æ¶çæ¨¡åç¸æ¯ã

##### **Enhancing Data-Limited Graph Neural Networks by Actively Distilling Knowledge from Large Language Models**
2407.13989v1 by Quan Li, Tianxiang Zhao, Lingwei Chen, Junjie Xu, Suhang Wang

Graphs have emerged as critical data structures for content analysis in
various domains, such as social network analysis, bioinformatics, and
recommendation systems. Node classification, a fundamental task in this
context, is typically tackled using graph neural networks (GNNs).
Unfortunately, conventional GNNs still face challenges in scenarios with few
labeled nodes, despite the prevalence of few-shot node classification tasks in
real-world applications. To address this challenge, various approaches have
been proposed, including graph meta-learning, transfer learning, and methods
based on Large Language Models (LLMs). However, traditional meta-learning and
transfer learning methods often require prior knowledge from base classes or
fail to exploit the potential advantages of unlabeled nodes. Meanwhile,
LLM-based methods may overlook the zero-shot capabilities of LLMs and rely
heavily on the quality of generated contexts. In this paper, we propose a novel
approach that integrates LLMs and GNNs, leveraging the zero-shot inference and
reasoning capabilities of LLMs and employing a Graph-LLM-based active learning
paradigm to enhance GNNs' performance. Extensive experiments demonstrate the
effectiveness of our model in improving node classification accuracy with
considerably limited labeled data, surpassing state-of-the-art baselines by
significant margins.

æè¦ï¼åè¡¨å·²æçºåç¨®é åä¸­å§å®¹åæçééµæ¸æçµæ§ï¼ä¾å¦ç¤¾äº¤ç¶²è·¯åæãçç©è³è¨å­¸åæ¨è¦ç³»çµ±ãç¯é»åé¡æ¯æ­¤èçµ¡ä¸­çåºæ¬ä»»åï¼éå¸¸ä½¿ç¨åå½¢ç¥ç¶ç¶²è·¯ (GNN) ä¾èçãä¸å¹¸çæ¯ï¼åç®¡ç¾å¯¦ä¸çæç¨ä¸­æ®éå­å¨å°æ¨£æ¬ç¯é»åé¡ä»»åï¼ä½å³çµ±ç GNN å¨æ¨è¨ç¯é»å¾å°çææ³ä¸ä»é¢è¨ææ°ãçºäºæå°éä¸ææ°ï¼å·²æåºåç¨®æ¹æ³ï¼åæ¬åå½¢åå­¸ç¿ãé·ç§»å­¸ç¿ååºæ¼å¤§åèªè¨æ¨¡å (LLM) çæ¹æ³ãç¶èï¼å³çµ±çåå­¸ç¿åé·ç§»å­¸ç¿æ¹æ³éå¸¸éè¦ä¾èªåºç¤é¡å¥çåé©ç¥è­ï¼æèç¡æ³å©ç¨æªæ¨è¨ç¯é»çæ½å¨åªå¢ãåæï¼åºæ¼ LLM çæ¹æ³å¯è½æå¿½è¦ LLM çé¶æ¨£æ¬è½åï¼ä¸¦ä¸éåº¦ä¾è³´çæèªå¢çåè³ªãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼å®æ´åäº LLM å GNNï¼å©ç¨ LLM çé¶æ¨£æ¬æ¨è«åæ¨çè½åï¼ä¸¦æ¡ç¨åºæ¼ Graph-LLM çä¸»åå­¸ç¿ç¯ä¾ä¾å¢å¼· GNN çæè½ãå»£æ³çå¯¦é©è­æäºæåçæ¨¡åå¨æ¹é²ç¯é»åé¡æºç¢ºåº¦æ¹é¢çæææ§ï¼æ¨è¨æ¸æç¸ç¶æéï¼é¡¯èè¶è¶äºæåé²çåºæºã

##### **A Comprehensive Review of Recommender Systems: Transitioning from Theory to Practice**
2407.13699v1 by Shaina Raza, Mizanur Rahman, Safiullah Kamawal, Armin Toroghi, Ananya Raval, Farshad Navah, Amirmohammad Kazemeini

Recommender Systems (RS) play an integral role in enhancing user experiences
by providing personalized item suggestions. This survey reviews the progress in
RS inclusively from 2017 to 2024, effectively connecting theoretical advances
with practical applications. We explore the development from traditional RS
techniques like content-based and collaborative filtering to advanced methods
involving deep learning, graph-based models, reinforcement learning, and large
language models. We also discuss specialized systems such as context-aware,
review-based, and fairness-aware RS. The primary goal of this survey is to
bridge theory with practice. It addresses challenges across various sectors,
including e-commerce, healthcare, and finance, emphasizing the need for
scalable, real-time, and trustworthy solutions. Through this survey, we promote
stronger partnerships between academic research and industry practices. The
insights offered by this survey aim to guide industry professionals in
optimizing RS deployment and to inspire future research directions, especially
in addressing emerging technological and societal trends

æè¦ï¼æ¨è¦ç³»çµ± (RS) å¨æåä½¿ç¨èé«é©ä¸­æ®æ¼èä¸å¯æç¼ºçè§è²ï¼ééæä¾åäººåçååå»ºè­°ãéé èª¿æ¥åé¡§äº RS å¨ 2017 å¹´å° 2024 å¹´éçé²å±ï¼ææå°å°çè«é²å±èå¯¦éæç¨é£çµèµ·ä¾ãæåæ¢è¨äºå¾å³çµ±ç RS æè¡ï¼ä¾å¦åºæ¼å§å®¹åååéæ¿¾ï¼å°æ¶åæ·±åº¦å­¸ç¿ãåºæ¼åå½¢çæ¨¡åãå¼·åå­¸ç¿åå¤§èªè¨æ¨¡åç­åé²æ¹æ³çç¼å±ãæåä¹è¨è«äºå°éçç³»çµ±ï¼ä¾å¦æå¢æç¥ãåºæ¼è©è«åå¬å¹³æç¥ç RSãéé èª¿æ¥çä¸»è¦ç®æ¨æ¯å°çè«èå¯¦åçµåèµ·ä¾ãå®è§£æ±ºäºååé åçææ°ï¼åæ¬é»å­ååãé«çä¿å¥åéèï¼å¼·èª¿äºå°å¯æ´åãå³æåå¯ä¿¡è³´çè§£æ±ºæ¹æ¡çéæ±ãéééé èª¿æ¥ï¼æåä¿é²äºå­¸è¡ç ç©¶åç¢æ¥­å¯¦åä¹éæ´å¼·å¤§çå¤¥ä¼´éä¿ãéé èª¿æ¥æä¾çè¦è§£æ¨å¨å¼å°ç¢æ¥­å°æ¥­äººå£«åªå RS é¨ç½²ï¼ä¸¦æ¿åµæªä¾çç ç©¶æ¹åï¼ç¹å¥æ¯å¨è§£æ±ºæ°èçæè¡åç¤¾æè¶¨å¢æ¹é¢ã

##### **MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains**
2407.18961v2 by Guoli Yin, Haoping Bai, Shuang Ma, Feng Nan, Yanchao Sun, Zhaoyang Xu, Shen Ma, Jiarui Lu, Xiang Kong, Aonan Zhang, Dian Ang Yap, Yizhe zhang, Karsten Ahnert, Vik Kamath, Mathias Berglund, Dominic Walsh, Tobias Gindele, Juergen Wiest, Zhengfeng Lai, Xiaoming Wang, Jiulong Shan, Meng Cao, Ruoming Pang, Zirui Wang

Recent advances in large language models (LLMs) have increased the demand for
comprehensive benchmarks to evaluate their capabilities as human-like agents.
Existing benchmarks, while useful, often focus on specific application
scenarios, emphasizing task completion but failing to dissect the underlying
skills that drive these outcomes. This lack of granularity makes it difficult
to deeply discern where failures stem from. Additionally, setting up these
environments requires considerable effort, and issues of unreliability and
reproducibility sometimes arise, especially in interactive tasks. To address
these limitations, we introduce the Massive Multitask Agent Understanding
(MMAU) benchmark, featuring comprehensive offline tasks that eliminate the need
for complex environment setups. It evaluates models across five domains,
including Tool-use, Directed Acyclic Graph (DAG) QA, Data Science and Machine
Learning coding, Contest-level programming and Mathematics, and covers five
essential capabilities: Understanding, Reasoning, Planning, Problem-solving,
and Self-correction. With a total of 20 meticulously designed tasks
encompassing over 3K distinct prompts, MMAU provides a comprehensive framework
for evaluating the strengths and limitations of LLM agents. By testing 18
representative models on MMAU, we provide deep and insightful analyses.
Ultimately, MMAU not only sheds light on the capabilities and limitations of
LLM agents but also enhances the interpretability of their performance.
Datasets and evaluation scripts of MMAU are released at
https://github.com/apple/axlearn/tree/main/docs/research/mmau.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±å¢å äºå°å¨é¢åºæºæ¸¬è©¦çéæ±ï¼ä»¥è©ä¼°å¶ä½çºé¡äººä»£ççè½åãç¾æçåºæºæ¸¬è©¦éç¶æç¨ï¼ä½éå¸¸å°æ³¨æ¼å·é«çæç¨å ´æ¯ï¼å¼·èª¿ä»»åå®æï¼ä½æªè½åæé©åéäºçµæçåºå±¤æè½ãéç¨®ç¼ºä¹ç²åº¦ä½¿å¾é£ä»¥æ·±å¥è¾¨å¥å¤±æçæ ¹æºãæ­¤å¤ï¼è¨­ç½®éäºç°å¢éè¦å¤§éçç²¾åï¼æææåºç¾ä¸å¯é æ§åå¯éè¤æ§çåé¡ï¼ç¹å¥æ¯å¨äºåä»»åä¸­ãçºäºè§£æ±ºéäºéå¶ï¼æåå¼å¥äºå¤§è¦æ¨¡å¤ä»»åä»£ççè§£ (MMAU) åºæºæ¸¬è©¦ï¼å®å·æå¨é¢çé¢ç·ä»»åï¼æ¶é¤äºå°è¤éç°å¢è¨­ç½®çéæ±ãå®è·¨è¶äºåé åè©ä¼°æ¨¡åï¼åæ¬å·¥å·ä½¿ç¨ãæåç¡ç°å (DAG) åç­ãæ¸æç§å­¸åæ©å¨å­¸ç¿ç·¨ç¢¼ãç«¶è³½ç´ç·¨ç¨åæ¸å­¸ï¼ä¸¦æ¶µèäºé åºæ¬è½åï¼çè§£ãæ¨çãè¦åãåé¡è§£æ±ºåèªæç³¾æ­£ãMMAU ç¸½å±åå« 20 é ç²¾å¿è¨­è¨çä»»åï¼æ¶µèè¶é 3K åä¸åçæç¤ºï¼çºè©ä¼° LLM ä»£ççåªå¢åå±éæ§æä¾äºä¸åå¨é¢çæ¡æ¶ãééå¨ MMAU ä¸æ¸¬è©¦ 18 åä»£è¡¨æ§æ¨¡åï¼æåæä¾äºæ·±å¥èæè¦å°çåæãæçµï¼MMAU ä¸åé¡æäº LLM ä»£ççè½ååå±éæ§ï¼éå¢å¼·äºå¶æ§è½çå¯è§£éæ§ãMMAU çæ¸æéåè©ä¼°è³æ¬å·²ç¼å¸å¨ https://github.com/apple/axlearn/tree/main/docs/research/mmauã

##### **Is Sarcasm Detection A Step-by-Step Reasoning Process in Large Language Models?**
2407.12725v1 by Ben Yao, Yazhou Zhang, Qiuchi Li, Jing Qin

Elaborating a series of intermediate reasoning steps significantly improves
the ability of large language models (LLMs) to solve complex problems, as such
steps would evoke LLMs to think sequentially. However, human sarcasm
understanding is often considered an intuitive and holistic cognitive process,
in which various linguistic, contextual, and emotional cues are integrated to
form a comprehensive understanding of the speaker's true intention, which is
argued not be limited to a step-by-step reasoning process. To verify this
argument, we introduce a new prompting framework called SarcasmCue, which
contains four prompting strategies, $viz.$ chain of contradiction (CoC), graph
of cues (GoC), bagging of cues (BoC) and tensor of cues (ToC), which elicits
LLMs to detect human sarcasm by considering sequential and non-sequential
prompting methods. Through a comprehensive empirical comparison on four
benchmarking datasets, we show that the proposed four prompting methods
outperforms standard IO prompting, CoT and ToT with a considerable margin, and
non-sequential prompting generally outperforms sequential prompting.

æè¦ï¼ééé¡è¿°ä¸ç³»åä¸­éæ¨çæ­¥é©ï¼å¤§å¹æåå¤§åèªè¨æ¨¡å (LLM) è§£æ±ºè¤éåé¡çè½åï¼å çºéäºæ­¥é©æä¿ä½¿ LLM æé åºæèãç¶èï¼äººé¡çè«·åºçè§£éå¸¸è¢«èªçºæ¯ä¸ç¨®ç´è¦ºä¸å¨é¢çèªç¥éç¨ï¼å¶ä¸­åç¨®èªè¨ãèªå¢åæç·ç·ç´¢æ´åå¨ä¸èµ·ï¼ä»¥å¨é¢äºè§£èªªè©±èççå¯¦æåï¼éè¢«èªçºä¸åéæ¼å¾ªåºæ¼¸é²çæ¨çéç¨ãçºäºé©è­éåè«é»ï¼æåå¼å¥äºä¸åæ°çæç¤ºæ¡æ¶ï¼ç¨±çº SarcasmCueï¼å¶ä¸­åå«åç¨®æç¤ºç­ç¥ï¼å³çç¾é (CoC)ãç·ç´¢å (GoC)ãç·ç´¢è¢ (BoC) åç·ç´¢å¼µé (ToC)ï¼å®å¼ç¼ LLM ééèæ®é åºåéé åºæç¤ºæ¹æ³ä¾æª¢æ¸¬äººé¡çè«·åºãééå°åååºæºæ¸æéé²è¡å¨é¢çå¯¦è­æ¯è¼ï¼æåè¡¨æææåºçåç¨®æç¤ºæ¹æ³ä»¥ç¸ç¶å¤§çå¹åº¦åªæ¼æ¨æº IO æç¤ºãCoT å ToTï¼ä¸¦ä¸éé åºæç¤ºéå¸¸åªæ¼é åºæç¤ºã

##### **Subgraph-Aware Training of Text-based Methods for Knowledge Graph Completion**
2407.12703v3 by Youmin Ko, Hyemin Yang, Taeuk Kim, Hyunjoon Kim

Fine-tuning pre-trained language models (PLMs) has recently shown a potential
to improve knowledge graph completion (KGC). However, most PLM-based methods
encode only textual information, neglecting various topological structures of
knowledge graphs (KGs). In this paper, we empirically validate the significant
relations between the structural properties of KGs and the performance of the
PLM-based methods. To leverage the structural knowledge, we propose a
Subgraph-Aware Training framework for KGC (SATKGC) that combines (i)
subgraph-aware mini-batching to encourage hard negative sampling, and (ii) a
new contrastive learning method to focus more on harder entities and harder
negative triples in terms of the structural properties. To the best of our
knowledge, this is the first study to comprehensively incorporate the
structural inductive bias of the subgraphs into fine-tuning PLMs. Extensive
experiments on four KGC benchmarks demonstrate the superiority of SATKGC. Our
code is available.

æè¦ï¼å¾®èª¿é è¨ç·´èªè¨æ¨¡å (PLM) è¿ä¾é¡¯ç¤ºåºæ¹åç¥è­åè­å®æåè½ (KGC) çæ½åãç¶èï¼å¤§å¤æ¸åºæ¼ PLM çæ¹æ³åç·¨ç¢¼æå­è³è¨ï¼å¿½ç¥äºç¥è­åè­ (KG) çåç¨®ææ²çµæ§ãå¨æ¬æä¸­ï¼æåééç¶é©é©è­äº KG ççµæ§å±¬æ§èåºæ¼ PLM çæ¹æ³æè½ä¹éçéè¦éä¿ãçºäºå©ç¨çµæ§ç¥è­ï¼æåæåºäºä¸åç¨æ¼ KGC çå­åæç¥è¨ç·´æ¶æ§ (SATKGC)ï¼å®çµåäºï¼(i) å­åæç¥å°æ¹æ¬¡èçä»¥é¼åµå°é£è² é¢æ½æ¨£ï¼ä»¥å (ii) ä¸ç¨®æ°çå°æ¯å­¸ç¿æ¹æ³ï¼å¨çµæ§å±¬æ§æ¹é¢æ´å°æ³¨æ¼æ´å°é£çå¯¦é«åæ´å°é£çè² ä¸åçµãææåæç¥ï¼éæ¯ç¬¬ä¸åå°å­åççµæ§æ­¸ç´åèª¤å¨é¢ç´å¥ PLM å¾®èª¿çç ç©¶ãå¨åå KGC åºæºä¸çå»£æ³å¯¦é©è­æäº SATKGC çåªè¶æ§ãæåçç¨å¼ç¢¼ç¾å·²å¬éã

##### **Abstraction Alignment: Comparing Model and Human Conceptual Relationships**
2407.12543v1 by Angie Boggust, Hyemin Bang, Hendrik Strobelt, Arvind Satyanarayan

Abstraction -- the process of generalizing specific examples into broad
reusable patterns -- is central to how people efficiently process and store
information and apply their knowledge to new data. Promisingly, research has
shown that ML models learn representations that span levels of abstraction,
from specific concepts like "bolo tie" and "car tire" to more general concepts
like "CEO" and "model". However, existing techniques analyze these
representations in isolation, treating learned concepts as independent
artifacts rather than an interconnected web of abstraction. As a result,
although we can identify the concepts a model uses to produce its output, it is
difficult to assess if it has learned a human-aligned abstraction of the
concepts that will generalize to new data. To address this gap, we introduce
abstraction alignment, a methodology to measure the agreement between a model's
learned abstraction and the expected human abstraction. We quantify abstraction
alignment by comparing model outputs against a human abstraction graph, such as
linguistic relationships or medical disease hierarchies. In evaluation tasks
interpreting image models, benchmarking language models, and analyzing medical
datasets, abstraction alignment provides a deeper understanding of model
behavior and dataset content, differentiating errors based on their agreement
with human knowledge, expanding the verbosity of current model quality metrics,
and revealing ways to improve existing human abstractions.

æè¦ï¼æ½è±¡åââå°ç¹å®ç¯ä¾æ¦æ¬çºå»£æ³å¯éè¤ä½¿ç¨çæ¨¡å¼çéç¨ââæ¯äººåææèçåå²å­è³è¨ï¼ä¸¦å°å¶ç¥è­æç¨æ¼æ°è³æçæ ¸å¿ãæå¸æçæ¯ï¼ç ç©¶é¡¯ç¤º ML æ¨¡åå­¸ç¿è·¨è¶æ½è±¡å±¤ç´çè¡¨å¾µï¼å¾ãç´°é å¸¶ãåãæ±½è»è¼ªèãç­å·é«æ¦å¿µå°ãå·è¡é·ãåãæ¨¡åãç­æ´ä¸è¬çæ¦å¿µãç¶èï¼ç¾æçæè¡å­¤ç«å°åæéäºè¡¨å¾µï¼å°å­¸ç¿å°çæ¦å¿µè¦çºç¨ç«çç¢ç©ï¼èä¸æ¯æ½è±¡çç¸äºé£çµç¶²è·¯ãå æ­¤ï¼åç®¡æåå¯ä»¥è­å¥æ¨¡åç¨ä¾ç¢çå¶è¼¸åºçæ¦å¿µï¼ä½å¾é£è©ä¼°å®æ¯å¦å­¸ç¿å°æ¦å¿µçäººé¡å°é½æ½è±¡ï¼éäºæ¦å¿µå°æ¦æ¬å°æ°çè³æãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äºæ½è±¡å°é½ï¼ä¸ç¨®è¡¡éæ¨¡åå­¸ç¿çæ½è±¡èé æçæ½è±¡ä¹éä¸è´æ§çæ¹æ³ãæåééå°æ¨¡åè¼¸åºèäººé¡æ½è±¡åå½¢ï¼ä¾å¦èªè¨éä¿æé«çç¾çå±¤ç´çµæ§ï¼é²è¡æ¯è¼ä¾éåæ½è±¡å°é½ãå¨è§£éå½±åæ¨¡åãåºæºèªè¨æ¨¡åååæé«çè³æéçè©ä¼°ä»»åä¸­ï¼æ½è±¡å°é½æä¾äºå°æ¨¡åè¡çºåè³æéå§å®¹æ´æ·±å¥ççè§£ï¼æ ¹æèäººé¡ç¥è­çä¸è´æ§ååé¯èª¤ï¼æ´å±ç¶åæ¨¡ååè³ªææ¨çè©³ç´°ç¨åº¦ï¼ä¸¦æ­ç¤ºæ¹åç¾æäººé¡æ½è±¡çæ¹æ³ã

##### **Struct-X: Enhancing Large Language Models Reasoning with Structured Data**
2407.12522v1 by Xiaoyu Tan, Haoyu Wang, Xihe Qiu, Yuan Cheng, Yinghui Xu, Wei Chu, Yuan Qi

Structured data, rich in logical and relational information, has the
potential to enhance the reasoning abilities of large language models (LLMs).
Still, its integration poses a challenge due to the risk of overwhelming LLMs
with excessive tokens and irrelevant context information. To address this, we
propose Struct-X, a novel framework that operates through five key phases:
``read-model-fill-reflect-reason'' efficiently enabling LLMs to utilize
structured data. It begins by encoding structured data into a topological space
using graph embeddings, followed by filling in missing entity information with
knowledge retrieval modules, and filtering out irrelevant tokens via a
self-supervised module. The final phase involves constructing a topological
network with selected tokens to further reduce the total token length for more
effective LLM inference. Additionally, Struct-X includes an Auxiliary Module
trained to generate prompts, aiding LLMs in analyzing structured data.
Extensive experiments on benchmarks, including the knowledge graph
question-answer task and the long document reading comprehension task, show
that Struct-X notably improves LLM reasoning, demonstrating the effectiveness
of structured data augmentation in improving LLM inference with complex input
context.

æè¦ï¼çµæ§åè³æå¯å«éè¼¯åéä¿è³è¨ï¼ææ½åå¢å¼·å¤§åèªè¨æ¨¡å (LLM) çæ¨çè½åãåç®¡å¦æ­¤ï¼ç±æ¼éå¤ç¬¦èåç¡éèçµ¡è³è¨å¯è½æè® LLM ä¸å ªè² è·ï¼å æ­¤æ´åæ­¤é¡è³ææ§æäºä¸é ææ°ãçºäºè§£æ±ºæ­¤åé¡ï¼æåæåº Struct-Xï¼éæ¯ä¸åééäºåééµéæ®µéä½çæ°ç©æ¶æ§ï¼``è®å-å»ºæ¨¡-å¡«è£-åæ-æ¨ç''ï¼ææå°è® LLM è½å¤ å©ç¨çµæ§åè³æãå®é¦åä½¿ç¨åå½¢åµå¥å°çµæ§åè³æç·¨ç¢¼å°ææ²ç©ºéä¸­ï¼æ¥èå©ç¨ç¥è­æ·åæ¨¡çµå¡«è£éºå¤±çå¯¦é«è³è¨ï¼ä¸¦ééèªæç£ç£æ¨¡çµç¯©é¸åºç¡éç¬¦èãæå¾ä¸åéæ®µæ¶åå»ºæ§ä¸åææ²ç¶²è·¯ï¼å¶ä¸­åå«é¸å®çç¬¦èï¼ä»¥é²ä¸æ­¥æ¸å°ç¸½ç¬¦èé·åº¦ï¼ä»¥ä¾¿æ´ææå°é²è¡ LLM æ¨è«ãæ­¤å¤ï¼Struct-X éåæ¬ä¸åè¼å©æ¨¡çµï¼ç¶éè¨ç·´å¯ä»¥ç¢çæç¤ºï¼åå© LLM åæçµæ§åè³æãå¨åºæºä¸çå¤§éå¯¦é©ï¼åæ¬ç¥è­åè­åç­ä»»ååé·ç¯æä»¶é±è®çè§£ä»»åï¼é¡¯ç¤º Struct-X æé¡¯æ¹åäº LLM æ¨çï¼è­æäºçµæ§åè³ææ´åå¨æ¹å LLM æ¨è«æçæææ§ï¼ç¹å¥æ¯å¨è¼¸å¥èçµ¡è¤éçææ³ä¸ã

##### **Explainable Biomedical Hypothesis Generation via Retrieval Augmented Generation enabled Large Language Models**
2407.12888v1 by Alexander R. Pelletier, Joseph Ramirez, Irsyad Adam, Simha Sankar, Yu Yan, Ding Wang, Dylan Steinecke, Wei Wang, Peipei Ping

The vast amount of biomedical information available today presents a
significant challenge for investigators seeking to digest, process, and
understand these findings effectively. Large Language Models (LLMs) have
emerged as powerful tools to navigate this complex and challenging data
landscape. However, LLMs may lead to hallucinatory responses, making Retrieval
Augmented Generation (RAG) crucial for achieving accurate information. In this
protocol, we present RUGGED (Retrieval Under Graph-Guided Explainable disease
Distinction), a comprehensive workflow designed to support investigators with
knowledge integration and hypothesis generation, identifying validated paths
forward. Relevant biomedical information from publications and knowledge bases
are reviewed, integrated, and extracted via text-mining association analysis
and explainable graph prediction models on disease nodes, forecasting potential
links among drugs and diseases. These analyses, along with biomedical texts,
are integrated into a framework that facilitates user-directed mechanism
elucidation as well as hypothesis exploration through RAG-enabled LLMs. A
clinical use-case demonstrates RUGGED's ability to evaluate and recommend
therapeutics for Arrhythmogenic Cardiomyopathy (ACM) and Dilated Cardiomyopathy
(DCM), analyzing prescribed drugs for molecular interactions and unexplored
uses. The platform minimizes LLM hallucinations, offers actionable insights,
and improves the investigation of novel therapeutics.

æè¦ï¼<paragraph>ç¾ä»å¤§éççç©é«å­¸è³è¨å°è©¦åæææ¶åãèçåçè§£éäºç¼ç¾çç ç©¶äººå¡æ§æéå¤§ææ°ãå¤§åèªè¨æ¨¡å (LLM) å·²æçºå¨éåè¤éä¸å·ææ°æ§çè³æç°å¢ä¸­å°èªçå¼·å¤§å·¥å·ãç¶èï¼LLM å¯è½æå°è´å¹»è¦ºåæï¼éä½¿å¾æª¢ç´¢æ´å¢çæ (RAG) å°æ¼ç²å¾æºç¢ºè³è¨è³ééè¦ãå¨éååå®ä¸­ï¼æåæåº RUGGEDï¼åå½¢å°å¼å¯è§£éç¾çååçæª¢ç´¢ï¼ï¼éæ¯ä¸åå¨é¢çå·¥ä½æµç¨ï¼æ¨å¨æ¯æ´ç ç©¶äººå¡é²è¡ç¥è­æ´åååè¨­ç¢çï¼æ¾åºç¶éé©è­çé²å±è·¯å¾ãä¾èªåºçç©åç¥è­åº«çç¸éçç©é«å­¸è³è¨æééææ¬æ¢åéè¯åæåç¾çç¯é»çå¯è§£éåå½¢é æ¸¬æ¨¡åé²è¡æª¢é±ãæ´ååèåï¼é æ¸¬è¥ç©åç¾çä¹éçæ½å¨éè¯ãéäºåæé£åçç©é«å­¸ææ¬ææ´åå°ä¸åæ¶æ§ä¸­ï¼è©²æ¶æ§ä¿é²ä½¿ç¨èå°åçæ©å¶é¡æï¼ä»¥åéé RAG åç¨ç LLM é²è¡åè¨­æ¢è¨ãä¸åè¨åºä½¿ç¨æ¡ä¾å±ç¤ºäº RUGGED è©ä¼°åæ¨è¦ç¨æ¼å¿å¾å¤±å¸¸æ§å¿èçè® (ACM) åæ´å¼µåå¿èçè® (DCM) çæ²»çæ¹æ³çè½åï¼åæèæ¹è¥ç©çåå­äº¤äºä½ç¨åæªæ¢ç´¢çç¨éãéåå¹³å°å° LLM å¹»è¦ºéå°æä½ï¼æä¾å¯æä½çè¦è§£ï¼ä¸¦æ¹åæ°æ²»çæ¹æ³çç ç©¶ã</paragraph>

##### **A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting**
2407.11638v1 by He Chang, Chenchen Ye, Zhulin Tao, Jie Wu, Zhengmao Yang, Yunshan Ma, Xianglin Huang, Tat-Seng Chua

Recently, Large Language Models (LLMs) have demonstrated great potential in
various data mining tasks, such as knowledge question answering, mathematical
reasoning, and commonsense reasoning. However, the reasoning capability of LLMs
on temporal event forecasting has been under-explored. To systematically
investigate their abilities in temporal event forecasting, we conduct a
comprehensive evaluation of LLM-based methods for temporal event forecasting.
Due to the lack of a high-quality dataset that involves both graph and textual
data, we first construct a benchmark dataset, named MidEast-TE-mini. Based on
this dataset, we design a series of baseline methods, characterized by various
input formats and retrieval augmented generation(RAG) modules. From extensive
experiments, we find that directly integrating raw texts into the input of LLMs
does not enhance zero-shot extrapolation performance. In contrast,
incorporating raw texts in specific complex events and fine-tuning LLMs
significantly improves performance. Moreover, enhanced with retrieval modules,
LLM can effectively capture temporal relational patterns hidden in historical
events. Meanwhile, issues such as popularity bias and the long-tail problem
still persist in LLMs, particularly in the RAG-based method. These findings not
only deepen our understanding of LLM-based event forecasting methods but also
highlight several promising research directions.We consider that this
comprehensive evaluation, along with the identified research opportunities,
will significantly contribute to future research on temporal event forecasting
through LLMs.

æè¦ï¼è¿æï¼å¤§åè¯­è¨æ¨¡å (LLM) å¨åç§èµææ¢åä»»å¡ä¸­å±ç°åºæå¤§çæ½åï¼ä¾å¦ç¥è¯é®ç­ãæ°å­¦æ¨çåå¸¸è¯æ¨çãç¶èï¼LLM å¨æ¶é´äºä»¶é¢æµæ¹é¢çæ¨çè½åå°æªè¢«ååæ¢ç´¢ãä¸ºäºç³»ç»æ§å°è°æ¥å¶å¨æ¶é´äºä»¶é¢æµæ¹é¢çè½åï¼æä»¬å¯¹åºäº LLM çæ¶é´äºä»¶é¢æµæ¹æ³è¿è¡äºå¨é¢çè¯ä¼°ãç±äºç¼ºä¹åæ¶åå«å¾è¡¨åææ¬èµæçé«åè´¨æ°æ®éï¼æä»¬é¦åæå»ºäºä¸ä¸ªåä¸º MidEast-TE-mini çåºåæ°æ®éãåºäºæ­¤æ°æ®éï¼æä»¬è®¾è®¡äºä¸ç³»ååºçº¿æ¹æ³ï¼å¶ç¹ç¹æ¯åç§è¾å¥æ ¼å¼åæ£ç´¢å¢å¼ºçæ (RAG) æ¨¡åãä»å¹¿æ³çå®éªä¸­ï¼æä»¬åç°ç´æ¥å°åå§ææ¬æ´åå° LLM çè¾å¥ä¸­å¹¶ä¸ä¼å¢å¼ºé¶æ¬¡å­¦ä¹ å¤æ¨æ§è½ãç¸æ¯ä¹ä¸ï¼å¨ç¹å®å¤æäºä»¶ä¸­çº³å¥åå§ææ¬å¹¶å¾®è° LLM ä¼æ¾èæé«æ§è½ãæ­¤å¤ï¼éè¿æ£ç´¢æ¨¡åçå¢å¼ºï¼LLM å¯ä»¥ææå°ææéèå¨åå²äºä»¶ä¸­çæ¶é´å³ç³»æ¨¡å¼ãåæ¶ï¼è¯¸å¦æµè¡åº¦åå·®åé¿å°¾é®é¢ç­é®é¢ä»ç¶å­å¨äº LLM ä¸­ï¼å°¤å¶æ¯å¨åºäº RAG çæ¹æ³ä¸­ãè¿äºåç°ä¸ä»å æ·±äºæä»¬å¯¹åºäº LLM çäºä»¶é¢æµæ¹æ³ççè§£ï¼è¿çªåºäºå ä¸ªæåæ¯çç ç©¶æ¹åãæä»¬è®¤ä¸ºï¼è¿é¡¹å¨é¢çè¯ä¼°ï¼è¿åå·²ç¡®å®çç ç©¶æºä¼ï¼å°æå¤§å°ä¿è¿éè¿ LLM è¿è¡æ¶é´äºä»¶é¢æµçæªæ¥ç ç©¶ã

##### **Learning on Graphs with Large Language Models(LLMs): A Deep Dive into Model Robustness**
2407.12068v2 by Kai Guo, Zewen Liu, Zhikai Chen, Hongzhi Wen, Wei Jin, Jiliang Tang, Yi Chang

Large Language Models (LLMs) have demonstrated remarkable performance across
various natural language processing tasks. Recently, several LLMs-based
pipelines have been developed to enhance learning on graphs with text
attributes, showcasing promising performance. However, graphs are well-known to
be susceptible to adversarial attacks and it remains unclear whether LLMs
exhibit robustness in learning on graphs. To address this gap, our work aims to
explore the potential of LLMs in the context of adversarial attacks on graphs.
Specifically, we investigate the robustness against graph structural and
textual perturbations in terms of two dimensions: LLMs-as-Enhancers and
LLMs-as-Predictors. Through extensive experiments, we find that, compared to
shallow models, both LLMs-as-Enhancers and LLMs-as-Predictors offer superior
robustness against structural and textual attacks.Based on these findings, we
carried out additional analyses to investigate the underlying causes.
Furthermore, we have made our benchmark library openly available to facilitate
quick and fair evaluations, and to encourage ongoing innovative research in
this field.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®èªç¶èªè¨èçä»»åä¸­é½å±ç¾åºåè¶çæè½ãæè¿ï¼å·²éç¼åºå¤ååºæ¼ LLM çç®¡éï¼ä»¥å¢å¼·å·ææå­å±¬æ§çåå½¢å­¸ç¿ï¼å±ç¾åºä»¤äººæ»¿æçæè½ãç¶èï¼åå½¢å®¹æåå°å°ææ§æ»æï¼è LLM å¨åå½¢å­¸ç¿ä¸­æ¯å¦å±ç¾åºç©©å¥æ§ä»ä¸æ¸æ¥ãçºäºè§£æ±ºéåå·®è·ï¼æåçç ç©¶æ¨å¨æ¢è¨ LLM å¨åå½¢å°ææ§æ»æä¸­çæ½åãå·é«ä¾èªªï¼æåéå°å©åé¢åæ¢è¨å¶å°åå½¢çµæ§åæå­æ¾åçç©©å¥æ§ï¼LLM ä½çºå¢å¼·å¨å LLM ä½çºé æ¸¬å¨ãééå»£æ³çå¯¦é©ï¼æåç¼ç¾ï¼èæ·ºå±¤æ¨¡åç¸æ¯ï¼LLM ä½çºå¢å¼·å¨å LLM ä½çºé æ¸¬å¨å¨çµæ§æ§åæå­æ»æä¸­é½æä¾åªç°çç©©å¥æ§ãæ ¹æéäºç¼ç¾ï¼æåé²è¡äºé¡å¤çåæä¾æ¢è¨å¶æ ¹æ¬åå ãæ­¤å¤ï¼æåå·²å¬éæåçåºæºåº«ï¼ä»¥å©å¿«éä¸å¬å¹³çè©ä¼°ï¼ä¸¦é¼åµæçºé²è¡éæ¹é¢çåµæ°ç ç©¶ã

##### **CIC-BART-SSA: Controllable Image Captioning with Structured Semantic Augmentation**
2407.11393v2 by Kalliopi Basioti, Mohamed A. Abdelsalam, Federico Fancellu, Vladimir Pavlovic, Afsaneh Fazly

Controllable Image Captioning (CIC) aims at generating natural language
descriptions for an image, conditioned on information provided by end users,
e.g., regions, entities or events of interest. However, available
image-language datasets mainly contain captions that describe the entirety of
an image, making them ineffective for training CIC models that can potentially
attend to any subset of regions or relationships. To tackle this challenge, we
propose a novel, fully automatic method to sample additional focused and
visually grounded captions using a unified structured semantic representation
built on top of the existing set of captions associated with an image. We
leverage Abstract Meaning Representation (AMR), a cross-lingual graph-based
semantic formalism, to encode all possible spatio-semantic relations between
entities, beyond the typical spatial-relations-only focus of current methods.
We use this Structured Semantic Augmentation (SSA) framework to augment
existing image-caption datasets with the grounded controlled captions,
increasing their spatial and semantic diversity and focal coverage. We then
develop a new model, CIC-BART-SSA, specifically tailored for the CIC task, that
sources its control signals from SSA-diversified datasets. We empirically show
that, compared to SOTA CIC models, CIC-BART-SSA generates captions that are
superior in diversity and text quality, are competitive in controllability,
and, importantly, minimize the gap between broad and highly focused controlled
captioning performance by efficiently generalizing to the challenging highly
focused scenarios. Code is available at
https://github.com/SamsungLabs/CIC-BART-SSA.

æè¦ï¼å¯æ§å¾åæ æ³¨ (CIC) æ¨å¨çæèªç¶è¯­è¨æè¿°ä»¥æè¿°å¾åï¼æ¡ä»¶æ¯æ ¹æ®æç»ç¨æ·æä¾çèµè®¯ï¼ä¾å¦åºåãå®ä½ææå´è¶£çäºä»¶ãç¶èï¼ç°æçå¾åè¯­è¨æ°æ®éä¸»è¦åå«æè¿°æ´ä¸ªå¾åçæ æ³¨ï¼ä½¿å¶æ æ³ææè®­ç» CIC æ¨¡åï¼èè¿äºæ¨¡åæå¯è½å³æ³¨ä»»ä½åºåæå³ç³»çå­éãä¸ºäºåºå¯¹è¿ä¸ææï¼æä»¬æåºäºä¸ç§æ°é¢çãå¨èªå¨çæ¹æ³ï¼ä½¿ç¨å»ºç«å¨ä¸å¾åå³èçç°ææ æ³¨éä¹ä¸çç»ä¸ç»æåè¯­ä¹è¡¨ç¤ºæ¥æ½æ ·å¶ä»èç¦ä¸è§è§æ¥å°çæ æ³¨ãæä»¬å©ç¨è·¨è¯­è¨å¾å¼è¯­ä¹å½¢å¼åæ½è±¡æä¹è¡¨ç¤º (AMR) æ¥ç¼ç å®ä½ä¹é´ææå¯è½çç©ºé´è¯­ä¹å³ç³»ï¼èä¸ä»ä»æ¯å½åæ¹æ³ä¸­ä»å³æ³¨çç©ºé´å³ç³»ãæä»¬ä½¿ç¨è¿ç§ç»æåè¯­ä¹å¢å¼º (SSA) æ¡æ¶æ¥å¢å¼ºç°æçå¾åæ æ³¨æ°æ®éï¼ä½¿å¶æ¥å°ä¸å¯æ§çæ æ³¨ï¼å¢å å®ä»¬çç©ºé´åè¯­ä¹å¤æ ·æ§ä»¥åç¦ç¹è¦çèå´ãç¶åï¼æä»¬å¼åäºä¸ä¸ªæ°æ¨¡å CIC-BART-SSAï¼ä¸é¨éå¯¹ CIC ä»»å¡éèº«å®å¶ï¼å¶æ§å¶ä¿¡å·æ¥èª SSA å¤æ ·åçæ°æ®éãæä»¬å­ç»éªè¡¨æï¼ä¸ SOTA CIC æ¨¡åç¸æ¯ï¼CIC-BART-SSA çæçæ æ³¨å¨å¤æ ·æ§åææ¬è´¨éæ¹é¢æ´èä¸ç­¹ï¼å¨å¯æ§æ§æ¹é¢å·æç«äºåï¼èä¸éè¦çæ¯ï¼éè¿ææå°æ¨å¹¿å°å·ææææ§çé«åº¦èç¦åºæ¯ï¼æå¤§éåº¦å°ç¼©å°äºå¹¿æ³åé«åº¦èç¦çåæ§æ æ³¨æ§è½ä¹é´çå·®è·ãä»£ç å¯ä» https://github.com/SamsungLabs/CIC-BART-SSA è·å¾ã

##### **Think-on-Graph 2.0: Deep and Interpretable Large Language Model Reasoning with Knowledge Graph-guided Retrieval**
2407.10805v3 by Shengjie Ma, Chengjin Xu, Xuhui Jiang, Muzhi Li, Huaren Qu, Jian Guo

Retrieval-augmented generation (RAG) has significantly advanced large
language models (LLMs) by enabling dynamic information retrieval to mitigate
knowledge gaps and hallucinations in generated content. However, these systems
often falter with complex reasoning and consistency across diverse queries. In
this work, we present Think-on-Graph 2.0, an enhanced RAG framework that aligns
questions with the knowledge graph and uses it as a navigational tool, which
deepens and refines the RAG paradigm for information collection and
integration. The KG-guided navigation fosters deep and long-range associations
to uphold logical consistency and optimize the scope of retrieval for precision
and interoperability. In conjunction, factual consistency can be better ensured
through semantic similarity guided by precise directives. ToG${2.0}$ not only
improves the accuracy and reliability of LLMs' responses but also demonstrates
the potential of hybrid structured knowledge systems to significantly advance
LLM reasoning, aligning it closer to human-like performance. We conducted
extensive experiments on four public datasets to demonstrate the advantages of
our method compared to the baseline.

æè¦ï¼æª¢ç´¢å¢å¼·çæ (RAG) å·²å¤§å¹æåå¤§åèªè¨æ¨¡å (LLM)ï¼èç±åç¨åæè³è¨æª¢ç´¢ä¾æ¸è¼ç¢çå§å®¹ä¸­çç¥è­å·®è·åå¹»è¦ºãç¶èï¼éäºç³»çµ±å¨è¤éæ¨çåä¸åæ¥è©¢éçä¸è´æ§æ¹é¢ç¶å¸¸æåºé¯ãå¨æ¬æä¸­ï¼æåæåº Think-on-Graph 2.0ï¼ä¸åå¢å¼·ç RAG æ¶æ§ï¼å®æå°åé¡èç¥è­åè­å°é½ï¼ä¸¦å°å¶ç¨ä½å°èªå·¥å·ï¼éæå æ·±åæ¹å RAG å¸ç¯ä»¥é²è¡è³è¨æ¶éåæ´åãKG å¼å°çå°èªä¿é²æ·±åº¦ä¸é·ç¨éè¯ï¼ä»¥ç¶­æéè¼¯ä¸è´æ§ï¼ä¸¦æä½³åæª¢ç´¢ç¯åä»¥æåç²¾æºåº¦åäºæä½æ§ãçµåä½¿ç¨ï¼äºå¯¦ä¸è´æ§å¯ééç±ç²¾ç¢ºæç¤ºå¼å°çèªç¾©ç¸ä¼¼æ§ç²å¾æ´å¥½çç¢ºä¿ãToG${2.0}$ ä¸åæå LLM åæçæºç¢ºåº¦åå¯é åº¦ï¼ä¹è­ææ··åçµæ§åç¥è­ç³»çµ±ææ½åå¤§å¹æå LLM æ¨çï¼ä½¿å¶æ´æ¥è¿äººé¡è¬çè¡¨ç¾ãæåå¨ååå¬éè³æéä¸é²è¡å»£æ³çå¯¦é©ï¼ä»¥è­ææåçæ¹æ³åªæ¼åºç·ã

##### **Graphusion: Leveraging Large Language Models for Scientific Knowledge Graph Fusion and Construction in NLP Education**
2407.10794v1 by Rui Yang, Boming Yang, Sixun Ouyang, Tianwei She, Aosong Feng, Yuang Jiang, Freddy Lecue, Jinghui Lu, Irene Li

Knowledge graphs (KGs) are crucial in the field of artificial intelligence
and are widely applied in downstream tasks, such as enhancing Question
Answering (QA) systems. The construction of KGs typically requires significant
effort from domain experts. Recently, Large Language Models (LLMs) have been
used for knowledge graph construction (KGC), however, most existing approaches
focus on a local perspective, extracting knowledge triplets from individual
sentences or documents. In this work, we introduce Graphusion, a zero-shot KGC
framework from free text. The core fusion module provides a global view of
triplets, incorporating entity merging, conflict resolution, and novel triplet
discovery. We showcase how Graphusion could be applied to the natural language
processing (NLP) domain and validate it in the educational scenario.
Specifically, we introduce TutorQA, a new expert-verified benchmark for graph
reasoning and QA, comprising six tasks and a total of 1,200 QA pairs. Our
evaluation demonstrates that Graphusion surpasses supervised baselines by up to
10% in accuracy on link prediction. Additionally, it achieves average scores of
2.92 and 2.37 out of 3 in human evaluations for concept entity extraction and
relation recognition, respectively.

æè¦ï¼<paragraph>ç¥è­åè­ (KG) å¨äººå·¥æºæ§é åè³ééè¦ï¼ä¸¦å»£æ³æç¨æ¼ä¸æ¸¸ä»»åï¼ä¾å¦å¢å¼·åç­ (QA) ç³»çµ±ãç¥è­åè­çå»ºæ§éå¸¸éè¦é åå°å®¶çå¤§éå·¥ä½ãæè¿ï¼å¤§åèªè¨æ¨¡å (LLM) å·²è¢«ç¨æ¼ç¥è­åè­å»ºæ§ (KGC)ï¼ç¶èï¼ç¾ææ¹æ³å¤§å¤éæ³¨å±é¨è§é»ï¼å¾åå¥å¥å­ææä»¶ä¸­æåç¥è­ä¸åçµãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹äº Graphusionï¼ä¸åå¾èªç±ææ¬ä¸­é²è¡é¶æ¬¡å­¸ç¿ç KGC æ¡æ¶ãæ ¸å¿èåæ¨¡çµæä¾ä¸åçµçå¨å±è§é»ï¼åå«å¯¦é«åä½µãè¡çªè§£æ±ºåæ°ä¸åçµç¼ç¾ãæåå±ç¤ºäºå¦ä½å° Graphusion æç¨æ¼èªç¶èªè¨èç (NLP) é åï¼ä¸¦å¨æè²å ´æ¯ä¸­é©è­å®ãå·é«ä¾èªªï¼æåä»ç´¹äº TutorQAï¼ä¸åæ°çç±å°å®¶é©è­çåè­æ¨çååç­åºæºï¼åå«å­é ä»»ååç¸½è¨ 1,200 ååç­å°ãæåçè©ä¼°è¡¨æï¼Graphusion å¨é£çµé æ¸¬çæºç¢ºåº¦ä¸æ¯ç£ç£å¼åºæºé«åº 10%ãæ­¤å¤ï¼å¨æ¦å¿µå¯¦é«æååéä¿è­å¥çäººé¡è©ä¼°ä¸­ï¼å®åå¥ç²å¾äº 3 åä¸­ç 2.92 åå 2.37 åã</paragraph>

##### **GraphEval: A Knowledge-Graph Based LLM Hallucination Evaluation Framework**
2407.10793v1 by Hannah Sansford, Nicholas Richardson, Hermina Petric Maretic, Juba Nait Saada

Methods to evaluate Large Language Model (LLM) responses and detect
inconsistencies, also known as hallucinations, with respect to the provided
knowledge, are becoming increasingly important for LLM applications. Current
metrics fall short in their ability to provide explainable decisions,
systematically check all pieces of information in the response, and are often
too computationally expensive to be used in practice. We present GraphEval: a
hallucination evaluation framework based on representing information in
Knowledge Graph (KG) structures. Our method identifies the specific triples in
the KG that are prone to hallucinations and hence provides more insight into
where in the response a hallucination has occurred, if at all, than previous
methods. Furthermore, using our approach in conjunction with state-of-the-art
natural language inference (NLI) models leads to an improvement in balanced
accuracy on various hallucination benchmarks, compared to using the raw NLI
models. Lastly, we explore the use of GraphEval for hallucination correction by
leveraging the structure of the KG, a method we name GraphCorrect, and
demonstrate that the majority of hallucinations can indeed be rectified.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) åæè©ä¼°æ¹æ³åä¸ä¸è´æ§åµæ¸¬ï¼åç¨±çºå¹»è¦ºï¼ï¼ç¸å°æ¼ææä¾çç¥è­ï¼å°æ¼ LLM æç¨æ­£è®å¾è¶ä¾è¶éè¦ãç®åçææ¨ç¡æ³æä¾å¯è§£éçæ±ºç­ãç³»çµ±æ§å°æª¢æ¥åæä¸­çææè³è¨ï¼èä¸å¨å¯¦åä¸ä½¿ç¨æï¼éå¸¸éæ¼èè²»éç®è³æºãæåæåº GraphEvalï¼ä¸ååºæ¼ç¥è­å (KG) çµæ§ä¾è¡¨ç¤ºè³è¨çå¹»è¦ºè©ä¼°æ¶æ§ãæåçæè¡è­å¥åºå®¹æåºç¾å¹»è¦ºç KG ä¸­ç¹å®ä¸åçµï¼å æ­¤æ¯ä»¥å¾çæ¹æ³æ´æ·±å¥å°äºè§£åæä¸­å¹»è¦ºç¼çå¨åªè£¡ï¼å¦ææçè©±ï¼ãæ­¤å¤ï¼å°æåçæ¹æ³èæåé²çèªç¶èªè¨æ¨è« (NLI) æ¨¡åçµåä½¿ç¨ï¼èä½¿ç¨åå§ NLI æ¨¡åç¸æ¯ï¼å¯ä»¥å¨åç¨®å¹»è¦ºåºæºä¸æé«å¹³è¡¡æºç¢ºåº¦ãæå¾ï¼æåæ¢ç´¢ä½¿ç¨ GraphEval ä¾é²è¡å¹»è¦ºä¿®æ­£ï¼æ¹æ³æ¯å©ç¨ KG ççµæ§ï¼æåå°æ­¤æ¹æ³å½åçº GraphCorrectï¼ä¸¦è­æå¤§å¤æ¸å¹»è¦ºç¢ºå¯¦å¯ä»¥å¾å°ç³¾æ­£ã

##### **Scaling 3D Reasoning with LMMs to Large Robot Mission Environments Using Datagraphs**
2407.10743v1 by W. J. Meijer, A. C. Kemmeren, E. H. J. Riemens, J. E. Fransman, M. van Bekkum, G. J. Burghouts, J. D. van Mil

This paper addresses the challenge of scaling Large Multimodal Models (LMMs)
to expansive 3D environments. Solving this open problem is especially relevant
for robot deployment in many first-responder scenarios, such as
search-and-rescue missions that cover vast spaces. The use of LMMs in these
settings is currently hampered by the strict context windows that limit the
LMM's input size. We therefore introduce a novel approach that utilizes a
datagraph structure, which allows the LMM to iteratively query smaller sections
of a large environment. Using the datagraph in conjunction with graph traversal
algorithms, we can prioritize the most relevant locations to the query, thereby
improving the scalability of 3D scene language tasks. We illustrate the
datagraph using 3D scenes, but these can be easily substituted by other dense
modalities that represent the environment, such as pointclouds or Gaussian
splats. We demonstrate the potential to use the datagraph for two 3D scene
language task use cases, in a search-and-rescue mission example.

æè¦ï¼æ¬æè¨è«äºå°å¤§åå¤æ¨¡ææ¨¡å (LMM) æ´å±å°å»£é 3D ç°å¢çææ°ãè§£æ±ºéåéæ¾æ§åé¡å°æ¼æ©å¨äººå¨è¨±å¤ç¬¬ä¸åæäººå¡å ´æ¯ä¸­çé¨ç½²ç¹å¥ç¸éï¼ä¾å¦æ¶µèå»£éç©ºéçææä»»åãéäºè¨­å®ä¸­ä½¿ç¨ LMM ç®ååå°å´æ ¼çä¸ä¸æè¦çªéå¶ï¼ééå¶äº LMM çè¼¸å¥å¤§å°ãå æ­¤ï¼æåå¼å¥äºä¸ç¨®æ°ç©çæ¹æ³ï¼è©²æ¹æ³å©ç¨è³æåçµæ§ï¼åè¨± LMM è¿­ä»£æ¥è©¢å¤§åç°å¢çè¼å°é¨åãééå°è³æåèåå½¢éæ­·æ¼ç®æ³çµåä½¿ç¨ï¼æåå¯ä»¥åªåèæ®èæ¥è©¢æç¸éçä½ç½®ï¼å¾èæé« 3D å ´æ¯èªè¨ä»»åçå¯æ´åæ§ãæåä½¿ç¨ 3D å ´æ¯èªªæè³æåï¼ä½éäºå ´æ¯å¯ä»¥è¼é¬å°ç±å¶ä»è¡¨ç¤ºç°å¢çå¯éæ¨¡å¼åä»£ï¼ä¾å¦é»é²æé«æ¯é»ãæåå±ç¤ºäºå¨ææä»»åç¯ä¾ä¸­ä½¿ç¨è³æåé²è¡å©å 3D å ´æ¯èªè¨ä»»åç¨ä¾çæ½åã

##### **AutoGRAMS: Autonomous Graphical Agent Modeling Software**
2407.10049v1 by Ben Krause, Lucia Chen, Emmanuel Kahembwe

We introduce the AutoGRAMS framework for programming multi-step interactions
with language models. AutoGRAMS represents AI agents as a graph, where each
node can execute either a language modeling instruction or traditional code.
Likewise, transitions in the graph can be governed by either language modeling
decisions or traditional branch logic. AutoGRAMS supports using variables as
memory and allows nodes to call other AutoGRAMS graphs as functions. We show
how AutoGRAMS can be used to design highly sophisticated agents, including
self-referential agents that can modify their own graph. AutoGRAMS's
graph-centric approach aids interpretability, controllability, and safety
during the design, development, and deployment of AI agents. We provide our
framework as open source at https://github.com/autograms/autograms .

æè¦ï¼æåä»ç´¹ AutoGRAMS æ¡æ¶ï¼ç¨æ¼ç·¨å¯«èèªè¨æ¨¡åçå¤æ­¥é©äºåãAutoGRAMS å° AI ä»£çè¡¨ç¤ºçºä¸ååå½¢ï¼å¶ä¸­æ¯åç¯é»å¯ä»¥å·è¡èªè¨å»ºæ¨¡æä»¤æå³çµ±ä»£ç¢¼ãåæ¨£å°ï¼åå½¢ä¸­çè½æå¯ä»¥ç±èªè¨å»ºæ¨¡æ±ºç­æå³çµ±åæ¯éè¼¯æ§å¶ãAutoGRAMS æ¯æ´ä½¿ç¨è®æ¸ä½çºè¨æ¶é«ï¼ä¸¦åè¨±ç¯é»å¼å«å¶ä» AutoGRAMS åå½¢ä½çºå½å¼ãæåå±ç¤ºå¦ä½ä½¿ç¨ AutoGRAMS è¨­è¨é«åº¦è¤éçä»£çï¼åæ¬å¯ä»¥ä¿®æ¹èªèº«åå½¢çèªåç§ä»£çãAutoGRAMS ä»¥åå½¢çºä¸­å¿çæ¹æ³æå©æ¼å¨ AI ä»£ççè¨­è¨ãéç¼åé¨ç½²éç¨ä¸­æé«å¯è§£éæ§ãå¯æ§æ§åå®å¨æ§ãæåå¨ https://github.com/autograms/autograms æä¾æåçæ¡æ¶ä½çºéæºã

##### **FarFetched: Entity-centric Reasoning and Claim Validation for the Greek Language based on Textually Represented Environments**
2407.09888v1 by Dimitris Papadopoulos, Katerina Metropoulou, Nikolaos Matsatsinis, Nikolaos Papadakis

Our collective attention span is shortened by the flood of online
information. With \textit{FarFetched}, we address the need for automated claim
validation based on the aggregated evidence derived from multiple online news
sources. We introduce an entity-centric reasoning framework in which latent
connections between events, actions, or statements are revealed via entity
mentions and represented in a graph database. Using entity linking and semantic
similarity, we offer a way for collecting and combining information from
diverse sources in order to generate evidence relevant to the user's claim.
Then, we leverage textual entailment recognition to quantitatively determine
whether this assertion is credible, based on the created evidence. Our approach
tries to fill the gap in automated claim validation for less-resourced
languages and is showcased on the Greek language, complemented by the training
of relevant semantic textual similarity (STS) and natural language inference
(NLI) models that are evaluated on translated versions of common benchmarks.

æè¦ï¼ç¶²è·¯è³è¨çæ´ªæµç¸®ç­äºæåçéé«æ³¨æåæéãéé \textit{FarFetched}ï¼æåè§£æ±ºäºæ ¹æå¾å¤åç·ä¸æ°èä¾æºå½ç¸½çè­æé²è¡èªååè²æé©è­çéæ±ãæåå¼å¥äºä¸åä»¥å¯¦é«çºä¸­å¿çæ¨çæ¡æ¶ï¼å¶ä¸­äºä»¶ãåä½æé³è¿°ä¹éçæ½å¨éè¯ééå¯¦é«æåè¢«æ­é²ï¼ä¸¦å¨åå½¢è³æåº«ä¸­è¡¨ç¤ºãä½¿ç¨å¯¦é«é£çµåèªç¾©ç¸ä¼¼æ§ï¼æåæä¾ä¸ç¨®æ¹å¼ä¾æ¶éåçµåä¾èªä¸åä¾æºçè³è¨ï¼ä»¥ç¢çèä½¿ç¨èè²æç¸éçè­æãç¶å¾ï¼æåå©ç¨ææ¬èæ¶µè­å¥ä¾æ ¹æå»ºç«çè­æéåç¢ºå®æ­¤æ·è¨æ¯å¦å¯ä¿¡ãæåçåæ³è©¦åå¡«è£è³æºè¼å°çèªè¨çèªååè²æé©è­æ¹é¢çç©ºç½ï¼ä¸¦å¨å¸èèªä¸­å±ç¤ºï¼è¼ä»¥å°ç¸éèªç¾©ææ¬ç¸ä¼¼æ§ (STS) åèªç¶èªè¨æ¨è« (NLI) æ¨¡åçè¨ç·´ï¼éäºæ¨¡åå¨å¸¸è¦åºæºçç¿»è­¯çæ¬ä¸é²è¡è©ä¼°ã

##### **GOFA: A Generative One-For-All Model for Joint Graph Language Modeling**
2407.09709v1 by Lecheng Kong, Jiarui Feng, Hao Liu, Chengsong Huang, Jiaxin Huang, Yixin Chen, Muhan Zhang

Foundation models, such as Large Language Models (LLMs) or Large Vision
Models (LVMs), have emerged as one of the most powerful tools in the respective
fields. However, unlike text and image data, graph data do not have a
definitive structure, posing great challenges to developing a Graph Foundation
Model (GFM). For example, current attempts at designing general graph models
either transform graph data into a language format for LLM-based prediction or
still train a GNN model with LLM as an assistant. The former can handle
unlimited tasks, while the latter captures graph structure much better -- yet,
no existing work can achieve both simultaneously. In this paper, we identify
three key desirable properties of a GFM: self-supervised pretraining, fluidity
in tasks, and graph awareness. To account for these properties, we extend the
conventional language modeling to the graph domain and propose a novel
generative graph language model GOFA to solve the problem. The model
interleaves randomly initialized GNN layers into a frozen pre-trained LLM so
that the semantic and structural modeling abilities are organically combined.
GOFA is pre-trained on newly proposed graph-level next-word prediction,
question-answering, and structural tasks to obtain the above GFM properties.
The pre-trained model is further fine-tuned on downstream tasks to obtain
task-solving ability. The fine-tuned model is evaluated on various downstream
tasks, demonstrating a strong ability to solve structural and contextual
problems in zero-shot scenarios. The code is available at
https://github.com/JiaruiFeng/GOFA.

æè¦ï¼åºç¤æ¨¡åï¼ä¾å¦å¤§åèªè¨æ¨¡å (LLM) æå¤§åè¦è¦ºæ¨¡å (LVM)ï¼å·²æçºåèªé åä¸­ææåçå·¥å·ä¹ä¸ãç¶èï¼èææ¬åå½±åè³æä¸åï¼åå½¢è³ææ²ææç¢ºççµæ§ï¼å°éç¼åå½¢åºç¤æ¨¡å (GFM) æ§ææ¥µå¤§çææ°ãä¾å¦ï¼ç®åè¨­è¨éç¨åå½¢æ¨¡åçåè©¦ï¼ä¸æ¯å°åå½¢è³æè½æçºèªè¨æ ¼å¼ä»¥ä¾åºæ¼ LLM çé æ¸¬ï¼å°±æ¯è¨ç·´ GNN æ¨¡åï¼ä¸¦ä»¥ LLM ä½çºè¼å©ãåèå¯ä»¥èçç¡éçä»»åï¼èå¾èå¯ä»¥æ´å¥½å°æ·ååå½¢çµæ§ï¼ä½ç¾æçå·¥ä½ç¡æ³åæéæéå©èãå¨æ¬æä¸­ï¼æåæ¾åº GFM çä¸åééµçæ³ç¹æ§ï¼èªæç£ç£é è¨ç·´ãä»»åæµæ¢åº¦ååå½¢æç¥ãçºäºèééäºç¹æ§ï¼æåå°å³çµ±çèªè¨å»ºæ¨¡æ´åå°åå½¢é åï¼ä¸¦æåºä¸åæ°ç©ççæå¼åå½¢èªè¨æ¨¡å GOFA ä¾è§£æ±ºåé¡ãæ­¤æ¨¡åå°é¨æ©åå§åç GNN å±¤äº¤é¯æå¥åçµçé è¨ç·´ LLM ä¸­ï¼ä»¥ä¾¿èªæåçµæ§å»ºæ¨¡è½åææ©çµåãGOFA æ¡ç¨æ°æåºçåå½¢å±¤ç´ä¸ä¸åå­é æ¸¬ãåç­åçµæ§ä»»åé²è¡é è¨ç·´ï¼ä»¥åå¾ä¸è¿° GFM ç¹æ§ãé è¨ç·´æ¨¡åé²ä¸æ­¥å¨ä¸æ¸¸ä»»åä¸é²è¡å¾®èª¿ï¼ä»¥åå¾è§£æ±ºä»»åçè½åãå¾®èª¿æ¨¡åå¨åç¨®ä¸æ¸¸ä»»åä¸é²è¡è©ä¼°ï¼è­æäºå¨é¶æ¬¡å­¸ç¿å ´æ¯ä¸­è§£æ±ºçµæ§åä¸ä¸æåé¡çå¼·å¤§è½åãç¨å¼ç¢¼å¯å¨ https://github.com/JiaruiFeng/GOFA åå¾ã

##### **Human-like Episodic Memory for Infinite Context LLMs**
2407.09450v1 by Zafeirios Fountas, Martin A Benfeghoul, Adnan Oomerjee, Fenia Christopoulou, Gerasimos Lampouras, Haitham Bou-Ammar, Jun Wang

Large language models (LLMs) have shown remarkable capabilities, but still
struggle with processing extensive contexts, limiting their ability to maintain
coherence and accuracy over long sequences. In contrast, the human brain excels
at organising and retrieving episodic experiences across vast temporal scales,
spanning a lifetime. In this work, we introduce EM-LLM, a novel approach that
integrates key aspects of human episodic memory and event cognition into LLMs,
enabling them to effectively handle practically infinite context lengths while
maintaining computational efficiency. EM-LLM organises sequences of tokens into
coherent episodic events using a combination of Bayesian surprise and
graph-theoretic boundary refinement in an on-line fashion. When needed, these
events are retrieved through a two-stage memory process, combining
similarity-based and temporally contiguous retrieval for efficient and
human-like access to relevant information. Experiments on the LongBench dataset
demonstrate EM-LLM's superior performance, outperforming the state-of-the-art
InfLLM model with an overall relative improvement of 4.3% across various tasks,
including a 33% improvement on the PassageRetrieval task. Furthermore, our
analysis reveals strong correlations between EM-LLM's event segmentation and
human-perceived events, suggesting a bridge between this artificial system and
its biological counterpart. This work not only advances LLM capabilities in
processing extended contexts but also provides a computational framework for
exploring human memory mechanisms, opening new avenues for interdisciplinary
research in AI and cognitive science.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºéå¡çè½åï¼ä½ä»é£ä»¥èçå»£æ³çèçµ¡ï¼ééå¶äºå®åå¨é·åºåä¸­ç¶­æé£è²«æ§åæºç¢ºæ§çè½åãç¸è¼ä¹ä¸ï¼äººè¦æé·å¨å»£å¤§çæéå°ºåº¦ä¸çµç¹åæåæç¯é«é©ï¼è·¨è¶ä¸çãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äº EM-LLMï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼å®å°äººé¡æç¯è¨æ¶åäºä»¶èªç¥çééµé¢åæ´åå° LLM ä¸­ï¼è®å®åè½å¤ ææå°èçå¯¦éä¸ç¡éçèçµ¡é·åº¦ï¼åæç¶­æéç®æçãEM-LLM ä½¿ç¨è²æ°é©åååè«éçç²¾çççµåï¼ä»¥ç·ä¸æ¹å¼å°åºåæ¨è¨çµç¹æé£è²«çæç¯äºä»¶ãå¨éè¦æï¼éäºäºä»¶æééå©éæ®µçè¨æ¶éç¨ä¾æåï¼çµååºæ¼ç¸ä¼¼æ§åæéé£çºæ§çæåï¼ä»¥ææä¸é¡ä¼¼äººé¡çæ¹å¼å­åç¸éè³è¨ãå¨ LongBench è³æéä¸çå¯¦é©è­æäº EM-LLM çåè¶æè½ï¼å¨åç¨®ä»»åä¸­åªæ¼æåé²ç InfLLM æ¨¡åï¼å¨ PassageRetrieval ä»»åä¸­æ¹é²äº 33%ãæ­¤å¤ï¼æåçåææ­ç¤ºäº EM-LLM çäºä»¶åå²èäººé¡æç¥äºä»¶ä¹éçå¼·ç¸éæ§ï¼é¡¯ç¤ºäºéåäººå·¥ç³»çµ±èå¶çç©å°æç©ä¹éçæ©æ¨ãéé å·¥ä½ä¸åæåäº LLM å¨èçå»¶ä¼¸èçµ¡æ¹é¢çè½åï¼ä¹æä¾äºä¸åéç®æ¶æ§ä¾æ¢ç´¢äººé¡è¨æ¶æ©å¶ï¼çº AI åèªç¥ç§å­¸çè·¨é åç ç©¶éåäºæ°çéå¾ã

##### **The $Î¼\mathcal{G}$ Language for Programming Graph Neural Networks**
2407.09441v1 by Matteo Belenchia, Flavio Corradini, Michela Quadrini, Michele Loreti

Graph neural networks form a class of deep learning architectures
specifically designed to work with graph-structured data. As such, they share
the inherent limitations and problems of deep learning, especially regarding
the issues of explainability and trustworthiness. We propose $\mu\mathcal{G}$,
an original domain-specific language for the specification of graph neural
networks that aims to overcome these issues. The language's syntax is
introduced, and its meaning is rigorously defined by a denotational semantics.
An equivalent characterization in the form of an operational semantics is also
provided and, together with a type system, is used to prove the type soundness
of $\mu\mathcal{G}$. We show how $\mu\mathcal{G}$ programs can be represented
in a more user-friendly graphical visualization, and provide examples of its
generality by showing how it can be used to define some of the most popular
graph neural network models, or to develop any custom graph processing
application.

æè¦ï¼åå½¢ç¥ç¶ç¶²è·¯å½¢æä¸é¡æ·±åº¦å­¸ç¿æ¶æ§ï¼ç¹å¥è¨­è¨ç¨æ¼èçåå½¢çµæ§åçè³æãå æ­¤ï¼å®åå·ææ·±åº¦å­¸ç¿åºæçéå¶ååé¡ï¼ç¹å¥æ¯å¨å¯è§£éæ§åå¯ä¿¡è³´æ§åé¡ä¸ãæåæåº $\mu\mathcal{G}$ï¼ä¸ç¨®ç¨æ¼æå®åå½¢ç¥ç¶ç¶²è·¯çååµé åç¹å®èªè¨ï¼æ¨å¨åæéäºåé¡ãå¼å¥äºèªè¨çèªæ³ï¼ä¸¦ééæç¤ºèªç¾©å´æ ¼å®ç¾©å¶å«ç¾©ãéæä¾äºéç®èªç¾©å½¢å¼çç­æç¹å¾µæè¿°ï¼ä¸¦èé¡åç³»çµ±ä¸èµ·ç¨æ¼è­æ $\mu\mathcal{G}$ çé¡åå¥å¨æ§ãæåå±ç¤ºäºå¦ä½å° $\mu\mathcal{G}$ ç¨å¼è¡¨ç¤ºçºæ´ååçåå½¢è¦è¦ºåï¼ä¸¦ééå±ç¤ºå¦ä½ä½¿ç¨å®å®ç¾©ä¸äºææµè¡çåå½¢ç¥ç¶ç¶²è·¯æ¨¡åæéç¼ä»»ä½èªè¨åå½¢èçæç¨ç¨å¼ï¼ä¾æä¾å¶éç¨æ§çç¯ä¾ã

##### **Towards More Trustworthy and Interpretable LLMs for Code through Syntax-Grounded Explanations**
2407.08983v1 by David N. Palacio, Daniel Rodriguez-Cardenas, Alejandro Velasco, Dipin Khati, Kevin Moran, Denys Poshyvanyk

Trustworthiness and interpretability are inextricably linked concepts for
LLMs. The more interpretable an LLM is, the more trustworthy it becomes.
However, current techniques for interpreting LLMs when applied to code-related
tasks largely focus on accuracy measurements, measures of how models react to
change, or individual task performance instead of the fine-grained explanations
needed at prediction time for greater interpretability, and hence trust. To
improve upon this status quo, this paper introduces ASTrust, an
interpretability method for LLMs of code that generates explanations grounded
in the relationship between model confidence and syntactic structures of
programming languages. ASTrust explains generated code in the context of syntax
categories based on Abstract Syntax Trees and aids practitioners in
understanding model predictions at both local (individual code snippets) and
global (larger datasets of code) levels. By distributing and assigning model
confidence scores to well-known syntactic structures that exist within ASTs,
our approach moves beyond prior techniques that perform token-level confidence
mapping by offering a view of model confidence that directly aligns with
programming language concepts with which developers are familiar. To put
ASTrust into practice, we developed an automated visualization that illustrates
the aggregated model confidence scores superimposed on sequence, heat-map, and
graph-based visuals of syntactic structures from ASTs. We examine both the
practical benefit that ASTrust can provide through a data science study on 12
popular LLMs on a curated set of GitHub repos and the usefulness of ASTrust
through a human study.

æè¦ï¼å¯ä¿¡åº¦åå¯è§£éæ§æ¯ LLM ä¸­å¯ä¸å¯åçæ¦å¿µãLLM çå¯è§£éæ§è¶é«ï¼å®çå¯ä¿¡åº¦å°±è¶é«ãç¶èï¼ç¶æç¨æ¼èç¨å¼ç¢¼ç¸éçä»»åæï¼ç®åè§£é LLM çæè¡ä¸»è¦éä¸­å¨æºç¢ºæ§æ¸¬éãæ¨¡åå°è®åçåææ¸¬éæåå¥ä»»åè¡¨ç¾ï¼èä¸æ¯å¨é æ¸¬æéæéçç´°ç²åº¦è§£éï¼å¾èæé«å¯è§£éæ§åå æ­¤æé«ä¿¡ä»»åº¦ãçºäºæ¹åéç¨®ç¾çï¼æ¬æä»ç´¹äº ASTrustï¼éæ¯ä¸ç¨®ç¨æ¼ç¨å¼ç¢¼ LLM çå¯è§£éæ§æ¹æ³ï¼å®ææ ¹ææ¨¡åä¿¡å¿èç¨å¼èªè¨çèªæ³çµæ§ä¹éçéä¿ç¢çè§£éãASTrust å¨åºæ¼æ½è±¡èªæ³æ¨¹çèªæ³é¡å¥çä¸ä¸æä¸­è§£éç¢ççç¨å¼ç¢¼ï¼ä¸¦å¹«å©å¯¦åäººå¡å¨å±é¨ï¼åå¥ç¨å¼ç¢¼çæ®µï¼åå¨åï¼è¼å¤§çç¨å¼ç¢¼è³æéï¼å±¤ç´äºè§£æ¨¡åé æ¸¬ãééå°æ¨¡åä¿¡å¿åæ¸åéåæå®çµ¦ AST ä¸­å­å¨çç¾æå¨ç¥çèªæ³çµæ§ï¼æåçåæ³è¶è¶äºååçæè¡ï¼éäºæè¡ééæä¾èéç¼äººå¡çæçç¨å¼èªè¨æ¦å¿µç´æ¥å°é½çæ¨¡åä¿¡å¿è¦åä¾å·è¡ä»¤çç´å¥çä¿¡å¿å°æãçºäºå¯¦è¸ ASTrustï¼æåéç¼äºä¸åèªååè¦è¦ºåå·¥å·ï¼å®èªªæäºçå å¨ AST èªæ³çµæ§çåºåãç±åååºæ¼åå½¢çè¦è¦ºææä¸çèåæ¨¡åä¿¡å¿åæ¸ãæåæª¢æ¥äº ASTrust å¯ä»¥ééå° 12 åæµè¡ç LLM å¨ä¸çµç²¾é¸ç GitHub å²å­åº«ä¸é²è¡è³æç§å­¸ç ç©¶æä¾çå¯¦éå¥½èï¼ä»¥åééäººé«ç ç©¶æä¾ç ASTrust çæç¨æ§ã

##### **Domain-Hierarchy Adaptation via Chain of Iterative Reasoning for Few-shot Hierarchical Text Classification**
2407.08959v1 by Ke Ji, Peng Wang, Wenjun Ke, Guozheng Li, Jiajun Liu, Jingsheng Gao, Ziyu Shang

Recently, various pre-trained language models (PLMs) have been proposed to
prove their impressive performances on a wide range of few-shot tasks. However,
limited by the unstructured prior knowledge in PLMs, it is difficult to
maintain consistent performance on complex structured scenarios, such as
hierarchical text classification (HTC), especially when the downstream data is
extremely scarce. The main challenge is how to transfer the unstructured
semantic space in PLMs to the downstream domain hierarchy. Unlike previous work
on HTC which directly performs multi-label classification or uses graph neural
network (GNN) to inject label hierarchy, in this work, we study the HTC problem
under a few-shot setting to adapt knowledge in PLMs from an unstructured manner
to the downstream hierarchy. Technically, we design a simple yet effective
method named Hierarchical Iterative Conditional Random Field (HierICRF) to
search the most domain-challenging directions and exquisitely crafts
domain-hierarchy adaptation as a hierarchical iterative language modeling
problem, and then it encourages the model to make hierarchical consistency
self-correction during the inference, thereby achieving knowledge transfer with
hierarchical consistency preservation. We perform HierICRF on various
architectures, and extensive experiments on two popular HTC datasets
demonstrate that prompt with HierICRF significantly boosts the few-shot HTC
performance with an average Micro-F1 by 28.80% to 1.50% and Macro-F1 by 36.29%
to 1.5% over the previous state-of-the-art (SOTA) baselines under few-shot
settings, while remaining SOTA hierarchical consistency performance.

æè¦ï¼<paragraph>æè¿ï¼å·²ç»æåºäºå¤ç§é¢è®­ç»è¯­è¨æ¨¡å (PLM)ï¼ä»¥è¯æå®ä»¬å¨å¹¿æ³çå°éæ ·æ¬ä»»å¡ä¸å·æä»¤äººå°è±¡æ·±å»çæ§è½ãç¶èï¼ç±äº PLM ä¸­éç»æåçåéªç¥è¯åå°éå¶ï¼å æ­¤é¾ä»¥å¨å¤æç»æååºæ¯ï¼ä¾å¦å±æ¬¡ææ¬åç±» (HTC)ï¼ä¸­ä¿æä¸è´çæ§è½ï¼å°¤å¶æ¯å¨ä¸æ¸¸æ°æ®æå¶ç¨å°çæåµä¸ãä¸»è¦çæææ¯å¦ä½å° PLM ä¸­éç»æåçè¯­ä¹ç©ºé´è½¬ç§»å°ä¸æ¸¸åå±æ¬¡ç»æãä¸ä»¥åç´æ¥æ§è¡å¤æ ç­¾åç±»æä½¿ç¨å¾ç¥ç»ç½ç» (GNN) æ³¨å¥æ ç­¾å±æ¬¡ç»æç HTC å·¥ä½ä¸åï¼å¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å¨å°éæ ·æ¬è®¾ç½®ä¸ç ç©¶ HTC é®é¢ï¼ä»¥å° PLM ä¸­çç¥è¯ä»éç»æåæ¹å¼éåºå°ä¸æ¸¸å±æ¬¡ç»æãä»ææ¯ä¸è®²ï¼æä»¬è®¾è®¡äºä¸ç§ç®åèææçæ¹æ³ï¼ç§°ä¸ºå±æ¬¡è¿­ä»£æ¡ä»¶éæºåº (HierICRF)ï¼ä»¥æç´¢æå·é¢åæææ§çæ¹åï¼å¹¶ç²¾ç»å°å°é¢åå±æ¬¡ç»æéåºä½ä¸ºåå±è¿­ä»£è¯­è¨å»ºæ¨¡é®é¢ï¼ç¶åå®é¼å±æ¨¡åå¨æ¨çæé´è¿è¡å±æ¬¡ä¸è´æ§èªææ ¡æ­£ï¼ä»èå®ç°å·æå±æ¬¡ä¸è´æ§ä¿ççç¥è¯è½¬ç§»ãæä»¬å¨åç§æ¶æä¸æ§è¡ HierICRFï¼å¨ä¸¤ä¸ªæµè¡ç HTC æ°æ®éä¸çå¤§éå®éªè¡¨æï¼ä½¿ç¨ HierICRF çæç¤ºæ¾çæé«äºå°éæ ·æ¬ HTC æ§è½ï¼å¹³å Micro-F1 ä» 28.80% æé«å° 1.50%ï¼Macro-F1 ä» 36.29% æé«å° 1.5% å¨å°éæ ·æ¬è®¾ç½®ä¸è¶è¿äºä»¥åæåè¿ (SOTA) åºåï¼åæ¶ä¿æ SOTA å±æ¬¡ä¸è´æ§æ§è½ã</paragraph>

##### **Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight**
2407.08694v1 by Zhiqiang Xie, Yujia Zheng, Lizi Ottens, Kun Zhang, Christos Kozyrakis, Jonathan Mace

Runtime failure and performance degradation is commonplace in modern cloud
systems. For cloud providers, automatically determining the root cause of
incidents is paramount to ensuring high reliability and availability as prompt
fault localization can enable faster diagnosis and triage for timely
resolution. A compelling solution explored in recent work is causal reasoning
using causal graphs to capture relationships between varied cloud system
performance metrics. To be effective, however, systems developers must
correctly define the causal graph of their system, which is a time-consuming,
brittle, and challenging task that increases in difficulty for large and
dynamic systems and requires domain expertise. Alternatively, automated
data-driven approaches have limited efficacy for cloud systems due to the
inherent rarity of incidents. In this work, we present Atlas, a novel approach
to automatically synthesizing causal graphs for cloud systems. Atlas leverages
large language models (LLMs) to generate causal graphs using system
documentation, telemetry, and deployment feedback. Atlas is complementary to
data-driven causal discovery techniques, and we further enhance Atlas with a
data-driven validation step. We evaluate Atlas across a range of fault
localization scenarios and demonstrate that Atlas is capable of generating
causal graphs in a scalable and generalizable manner, with performance that far
surpasses that of data-driven algorithms and is commensurate to the
ground-truth baseline.

æè¦ï¼å¨ç¾ä»£é²ç«¯ç³»çµ±ä¸­ï¼å·è¡æææéåæè½éä½æ¯å¸ç©ºè¦æ£çäºãå°æ¼é²ç«¯ä¾æåèè¨ï¼èªåæ¾åºäºä»¶çæ ¹æ¬åå å°æ¼ç¢ºä¿é«å¯é æ§åå¯ç¨æ§è³ééè¦ï¼å çºåæçæéå®ä½å¯ä»¥è®è¨ºæ·ååé¡æ´å¿«éï¼ä»¥å©æ¼åæè§£æ±ºåé¡ãæè¿çå·¥ä½ä¸­æ¢è¨äºä¸åå¼äººæ³¨ç®çè§£æ±ºæ¹æ¡ï¼å³ä½¿ç¨å æåä¾æ·ååç¨®é²ç«¯ç³»çµ±æè½ææ¨ä¹ééä¿çå ææ¨çãç¶èï¼ç³»çµ±éç¼äººå¡å¿é æ­£ç¢ºå®ç¾©å¶ç³»çµ±çå æåæè½ç¼æ®æç¨ï¼èéé ä»»åèæãèå¼±ä¸å·æææ°æ§ï¼å°æ¼å¤§åä¸åæçç³»çµ±èè¨é£åº¦æ´é«ï¼èä¸éè¦é åå°å®¶ç¥è­ãæèï¼ç±æ¼äºä»¶çåºæç¨å°æ§ï¼èªååè³æé©åæ¹æ³å°æ¼é²ç«¯ç³»çµ±çæåæéãå¨éé å·¥ä½ä¸­ï¼æåæåº Atlasï¼ä¸ç¨®èªååæé²ç«¯ç³»çµ±å æåçæ°æ¹æ³ãAtlas å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä½¿ç¨ç³»çµ±æä»¶ãéæ¸¬åé¨ç½²åé¥ä¾ç¢çå æåãAtlas æ¯è³æé©åå æç¼ç¾æè¡çè£åï¼æåé²ä¸æ­¥ä½¿ç¨è³æé©åé©è­æ­¥é©ä¾å¢å¼· Atlasãæåå¨åç¨®æéå®ä½æå¢ä¸­è©ä¼° Atlasï¼ä¸¦è­æ Atlas è½å¤ ä»¥å¯æ´åä¸å¯æ¦åçæ¹å¼ç¢çå æåï¼å¶æè½é é è¶éè³æé©åæ¼ç®æ³ï¼ä¸¦ä¸èçå¯¦åºç·ç¸ç¶ã

##### **Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents**
2407.08516v4 by Haoyi Xiong, Zhiyuan Wang, Xuhong Li, Jiang Bian, Zeke Xie, Shahid Mumtaz, Laura E. Barnes

This article explores the convergence of connectionist and symbolic
artificial intelligence (AI), from historical debates to contemporary
advancements. Traditionally considered distinct paradigms, connectionist AI
focuses on neural networks, while symbolic AI emphasizes symbolic
representation and logic. Recent advancements in large language models (LLMs),
exemplified by ChatGPT and GPT-4, highlight the potential of connectionist
architectures in handling human language as a form of symbols. The study argues
that LLM-empowered Autonomous Agents (LAAs) embody this paradigm convergence.
By utilizing LLMs for text-based knowledge modeling and representation, LAAs
integrate neuro-symbolic AI principles, showcasing enhanced reasoning and
decision-making capabilities. Comparing LAAs with Knowledge Graphs within the
neuro-symbolic AI theme highlights the unique strengths of LAAs in mimicking
human-like reasoning processes, scaling effectively with large datasets, and
leveraging in-context samples without explicit re-training. The research
underscores promising avenues in neuro-vector-symbolic integration,
instructional encoding, and implicit reasoning, aimed at further enhancing LAA
capabilities. By exploring the progression of neuro-symbolic AI and proposing
future research trajectories, this work advances the understanding and
development of AI technologies.

æè¦ï¼æ¬ææ¢è¨äºé£æ¥ä¸»ç¾©åç¬¦èäººå·¥æºæ§ï¼AIï¼çå¯æµï¼å¾æ­·å²è¾¯è«å°ç¶ä»£é²å±ãå³çµ±ä¸è¢«èªçºæ¯ä¸åçç¯å¼ï¼é£æ¥ä¸»ç¾© AI å°æ³¨æ¼ç¥ç¶ç¶²è·¯ï¼èç¬¦è AI åå¼·èª¿ç¬¦èè¡¨å¾µåéè¼¯ãå¤§åèªè¨æ¨¡å (LLM) çææ°é²å±ï¼ä»¥ ChatGPT å GPT-4 çºä¾ï¼çªé¡¯äºé£æ¥ä¸»ç¾©æ¶æ§å¨èçäººé¡èªè¨ä½çºç¬¦èå½¢å¼æ¹é¢çæ½åãç ç©¶èªçºï¼ç± LLM è³¦è½çèªä¸»ä»£çï¼LAAï¼é«ç¾äºéç¨®ç¯å¼æ¶æãééå©ç¨ LLM é²è¡åºæ¼æå­çç¥è­å»ºæ¨¡åè¡¨å¾µï¼LAA æ´åäºç¥ç¶ç¬¦è AI åçï¼å±ç¤ºäºå¢å¼·çæ¨çåæ±ºç­è½åãå¨ç¥ç¶ç¬¦è AI ä¸»é¡ä¸­æ¯è¼ LAA èç¥è­åè­ï¼çªé¡¯äº LAA å¨æ¨¡æ¬é¡äººæ¨çéç¨ãæææ´åå¤§åè³æéä»¥åå©ç¨æå¢ç¯ä¾èä¸éæç¢ºéæ°è¨ç·´æ¹é¢çç¨ç¹åªå¢ãç ç©¶å¼·èª¿äºç¥ç¶åéç¬¦èæ´åãæä»¤ç·¨ç¢¼åå§é±æ¨çä¸­åæ¯çå¥½çéå¾ï¼æ¨å¨é²ä¸æ­¥å¢å¼· LAA çè½åãééæ¢ç´¢ç¥ç¶ç¬¦è AI çé²å±ä¸¦æåºæªä¾çç ç©¶è»è·¡ï¼éé å·¥ä½ä¿é²äºå° AI æè¡ççè§£åç¼å±ã

##### **A Comprehensive Survey on the Security of Smart Grid: Challenges, Mitigations, and Future Research Opportunities**
2407.07966v1 by Arastoo Zibaeirad, Farnoosh Koleini, Shengping Bi, Tao Hou, Tao Wang

In this study, we conduct a comprehensive review of smart grid security,
exploring system architectures, attack methodologies, defense strategies, and
future research opportunities. We provide an in-depth analysis of various
attack vectors, focusing on new attack surfaces introduced by advanced
components in smart grids. The review particularly includes an extensive
analysis of coordinated attacks that incorporate multiple attack strategies and
exploit vulnerabilities across various smart grid components to increase their
adverse impact, demonstrating the complexity and potential severity of these
threats. Following this, we examine innovative detection and mitigation
strategies, including game theory, graph theory, blockchain, and machine
learning, discussing their advancements in counteracting evolving threats and
associated research challenges. In particular, our review covers a thorough
examination of widely used machine learning-based mitigation strategies,
analyzing their applications and research challenges spanning across
supervised, unsupervised, semi-supervised, ensemble, and reinforcement
learning. Further, we outline future research directions and explore new
techniques and concerns. We first discuss the research opportunities for
existing and emerging strategies, and then explore the potential role of new
techniques, such as large language models (LLMs), and the emerging threat of
adversarial machine learning in the future of smart grid security.

æè¦ï¼å¨éé ç ç©¶ä¸­ï¼æåå°æºæ§é»ç¶²å®å¨æ§é²è¡å¨é¢æª¢è¦ï¼æ¢è¨ç³»çµ±æ¶æ§ãæ»ææ¹æ³ãé²ç¦¦ç­ç¥åæªä¾çç ç©¶æ©æãæåæ·±å¥åæåç¨®æ»æåªä»ï¼å°æ³¨æ¼æºæ§é»ç¶²ä¸­åé²çµä»¶æå¼å¥çæ°æ»æé¢ãæ¬æª¢è¦ç¹å¥åå«å°åèª¿æ»æçå»£æ³åæï¼å¶ä¸­åå«å¤ç¨®æ»æç­ç¥ä¸¦å©ç¨åç¨®æºæ§é»ç¶²çµä»¶ä¸­çæ¼æ´ä¾å¢å å¶è² é¢å½±é¿ï¼å±ç¤ºéäºå¨èçè¤éæ§åæ½å¨å´éæ§ãå¨æ­¤ä¹å¾ï¼æåæ¢è¨åµæ°çåµæ¸¬åç·©è§£ç­ç¥ï¼åæ¬åå¼è«ãåè«ãåå¡éåæ©å¨å­¸ç¿ï¼è¨è«å®åå¨å°æä¸æ·æ¼è®çå¨èåç¸éç ç©¶ææ°æ¹é¢çé²å±ãç¹å¥æ¯ï¼æåçæª¢è¦æ¶µèå°å»£æ³ä½¿ç¨çåºæ¼æ©å¨å­¸ç¿çç·©è§£ç­ç¥çå¾¹åºæª¢é©ï¼åæå®åå¨ç£ç£å¼ãéç£ç£å¼ãåç£ç£å¼ãæ´é«å¼åå¼·åå­¸ç¿ä¸­çæç¨åç ç©¶ææ°ãæ­¤å¤ï¼æåæ¦è¿°æªä¾çç ç©¶æ¹åä¸¦æ¢è¨æ°æè¡ååé¡ãæåé¦åè¨è«ç¾æåæ°èç­ç¥çç ç©¶æ©æï¼ç¶å¾æ¢è¨æ°æè¡çæ½å¨ä½ç¨ï¼ä¾å¦å¤§åèªè¨æ¨¡å (LLM)ï¼ä»¥åå°æå¼æ©å¨å­¸ç¿å¨æºæ§é»ç¶²å®å¨æªä¾çå¨èã

##### **Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs**
2407.07775v2 by Hao-Tien Lewis Chiang, Zhuo Xu, Zipeng Fu, Mithun George Jacob, Tingnan Zhang, Tsang-Wei Edward Lee, Wenhao Yu, Connor Schenck, David Rendleman, Dhruv Shah, Fei Xia, Jasmine Hsu, Jonathan Hoech, Pete Florence, Sean Kirmani, Sumeet Singh, Vikas Sindhwani, Carolina Parada, Chelsea Finn, Peng Xu, Sergey Levine, Jie Tan

An elusive goal in navigation research is to build an intelligent agent that
can understand multimodal instructions including natural language and image,
and perform useful navigation. To achieve this, we study a widely useful
category of navigation tasks we call Multimodal Instruction Navigation with
demonstration Tours (MINT), in which the environment prior is provided through
a previously recorded demonstration video. Recent advances in Vision Language
Models (VLMs) have shown a promising path in achieving this goal as it
demonstrates capabilities in perceiving and reasoning about multimodal inputs.
However, VLMs are typically trained to predict textual output and it is an open
research question about how to best utilize them in navigation. To solve MINT,
we present Mobility VLA, a hierarchical Vision-Language-Action (VLA) navigation
policy that combines the environment understanding and common sense reasoning
power of long-context VLMs and a robust low-level navigation policy based on
topological graphs. The high-level policy consists of a long-context VLM that
takes the demonstration tour video and the multimodal user instruction as input
to find the goal frame in the tour video. Next, a low-level policy uses the
goal frame and an offline constructed topological graph to generate robot
actions at every timestep. We evaluated Mobility VLA in a 836m^2 real world
environment and show that Mobility VLA has a high end-to-end success rates on
previously unsolved multimodal instructions such as "Where should I return
this?" while holding a plastic bin. A video demonstrating Mobility VLA can be
found here: https://youtu.be/-Tof__Q8_5s

æè¦ï¼<paragraph>å°èªç ç©¶ä¸­ä¸åé£ä»¥ææ¸çç®æ¨ï¼æ¯å»ºç«ä¸åæºè½ä»£çï¼å®å¯ä»¥çè§£åæ¬èªç¶èªè¨åå½±åçå¤æ¨¡ææä»¤ï¼ä¸¦å·è¡æç¨çå°èªãçºäºéææ­¤ç®æ¨ï¼æåç ç©¶äºä¸é¡å»£æ³æç¨çå°èªä»»åï¼æåç¨±ä¹çºç¤ºç¯å°è¦½çå¤æ¨¡ææä»¤å°èª (MINT)ï¼å¶ä¸­ç°å¢åé©æ¯ééååéè£½çç¤ºç¯å½±çæä¾çãè¦è¦ºèªè¨æ¨¡å (VLM) çè¿æé²å±ï¼å±ç¤ºäºä¸æ¢å¯¦ç¾æ­¤ç®æ¨çæåæ¯è·¯å¾ï¼å çºå®å±ç¤ºäºæç¥åæ¨çå¤æ¨¡æè¼¸å¥çè½åãç¶èï¼VLM éå¸¸è¨ç·´ç¨æ¼é æ¸¬æå­è¼¸åºï¼èå¦ä½æä½³å©ç¨å®åé²è¡å°èªï¼åæ¯ä¸åéæ¾çç ç©¶åé¡ãçºäºè§£æ±º MINTï¼æåæåºäº Mobility VLAï¼éæ¯ä¸ç¨®åå±¤çè¦è¦º-èªè¨-åä½ (VLA) å°èªæ¿ç­ï¼å®çµåäºé·èªå¢ VLM çç°å¢çè§£åå¸¸è­æ¨çè½åï¼ä»¥ååºæ¼ææ²åçå¼·å¥ä½éå°èªæ¿ç­ãé«éæ¿ç­åå«ä¸åé·èªå¢ VLMï¼å®æ¡ç¨ç¤ºç¯å°è¦½å½±çåå¤æ¨¡æä½¿ç¨èæä»¤ä½çºè¼¸å¥ï¼ä»¥å¨å°è¦½å½±çä¸­æ¾å°ç®æ¨å¹ãæ¥ä¸ä¾ï¼ä½éæ¿ç­ä½¿ç¨ç®æ¨å¹åé¢ç·å»ºæ§çææ²åï¼å¨æ¯åæéæ­¥ç¢çæ©å¨äººåä½ãæåå¨ 836 å¹³æ¹å¬å°ºççå¯¦ä¸çç°å¢ä¸­è©ä¼°äº Mobility VLAï¼ä¸¦å±ç¤ºäº Mobility VLA å¨ååæªè§£æ±ºçå¤æ¨¡ææä»¤ï¼ä¾å¦ãææè©²æéåå¡è ç®±æ­¸éå°åªè£¡ï¼ãï¼ä¸å·æå¾é«çç«¯å°ç«¯æåçï¼åææ¿èä¸åå¡è ç®±ãå±ç¤º Mobility VLA çå½±çå¯ä»¥å¨éè£¡æ¾å°ï¼https://youtu.be/-Tof__Q8_5s</paragraph>

##### **Teaching Transformers Causal Reasoning through Axiomatic Training**
2407.07612v1 by Aniket Vashishtha, Abhinav Kumar, Abbavaram Gowtham Reddy, Vineeth N Balasubramanian, Amit Sharma

For text-based AI systems to interact in the real world, causal reasoning is
an essential skill. Since interventional data is costly to generate, we study
to what extent an agent can learn causal reasoning from passive data.
Specifically, we consider an axiomatic training setup where an agent learns
from multiple demonstrations of a causal axiom (or rule), rather than
incorporating the axiom as an inductive bias or inferring it from data values.
A key question is whether the agent would learn to generalize from the axiom
demonstrations to new scenarios. For example, if a transformer model is trained
on demonstrations of the causal transitivity axiom over small graphs, would it
generalize to applying the transitivity axiom over large graphs? Our results,
based on a novel axiomatic training scheme, indicate that such generalization
is possible. We consider the task of inferring whether a variable causes
another variable, given a causal graph structure. We find that a 67 million
parameter transformer model, when trained on linear causal chains (along with
some noisy variations) can generalize well to new kinds of graphs, including
longer causal chains, causal chains with reversed order, and graphs with
branching; even when it is not explicitly trained for such settings. Our model
performs at par (or even better) than many larger language models such as
GPT-4, Gemini Pro, and Phi-3. Overall, our axiomatic training framework
provides a new paradigm of learning causal reasoning from passive data that can
be used to learn arbitrary axioms, as long as sufficient demonstrations can be
generated.

æè¦ï¼<paragraph>å°æ¼åºæ¼æå­çäººå·¥æºæ§ç³»çµ±èçå¯¦ä¸çäºåä¾èªªï¼å ææ¨çæ¯ä¸é å¿è¦çæè½ãç±æ¼ä»å¥è³æçç¢çææ¬å¾é«ï¼æåç ç©¶ä¸ä½ä»£çäººå¾è¢«åè³æä¸­å­¸ç¿å ææ¨ççç¨åº¦ãå·é«ä¾èªªï¼æåèæ®ä¸åå¬çè¨ç·´è¨­ç½®ï¼å¶ä¸­ä¸ä½ä»£çäººå¾å æå¬çï¼æè¦åï¼çå¤åç¤ºç¯ä¸­å­¸ç¿ï¼èä¸æ¯å°å¬çä½çºæ­¸ç´åèª¤æå¾è³æå¼ä¸­æ¨æ·åºä¾ãä¸åééµåé¡æ¯ä»£çäººæ¯å¦æå­¸æå¾å¬çç¤ºç¯æ¨å»£å°æ°çå ´æ¯ãä¾å¦ï¼å¦æä¸åTransformeræ¨¡åå¨å°åè¡¨ä¸å æå³éæ§å¬ççç¤ºç¯ä¸­æ¥åè¨ç·´ï¼å®æ¯å¦ææ¨å»£å°å¨å¤§åè¡¨ä¸æç¨å³éæ§å¬çï¼æåççµæåºæ¼ä¸åæ°ç©çå¬çè¨ç·´æ¹æ¡ï¼è¡¨æéæ¨£çæ¦æ¬æ¯å¯è½çãæåèæ®æ¨è«ä¸åè®æ¸æ¯å¦å°è´å¦ä¸åè®æ¸çä»»åï¼çµ¦å®ä¸åå æåçµæ§ãæåç¼ç¾ä¸å 6700 è¬ååæ¸çTransformeræ¨¡åï¼å¨ç·æ§å æéï¼ä»¥åä¸äºéè¨è®åï¼ä¸è¨ç·´æï¼å¯ä»¥å¾å¥½å°æ¦æ¬å°æ°é¡åçåå½¢ï¼åæ¬æ´é·çå æéãé åºç¸åçå æéåå·æåæ¯çåå½¢ï¼å³ä½¿å®æ²æéå°æ­¤é¡è¨­ç½®é²è¡æç¢ºè¨ç·´ãæåçæ¨¡åè¡¨ç¾èè¨±å¤è¼å¤§çèªè¨æ¨¡åï¼ä¾å¦ GPT-4ãGemini Pro å Phi-3ï¼ç¸ç¶ï¼çè³æ´å¥½ï¼ãç¸½é«èè¨ï¼æåçå¬çè¨ç·´æ¡æ¶æä¾äºä¸åå¾è¢«åè³æä¸­å­¸ç¿å ææ¨ççæ°ç¯ä¾ï¼åªè¦å¯ä»¥ç¢çè¶³å¤ çç¤ºç¯ï¼å°±å¯ä»¥ç¨æ¼å­¸ç¿ä»»æå¬çã</paragraph>

##### **STAGE: Simplified Text-Attributed Graph Embeddings Using Pre-trained LLMs**
2407.12860v1 by Aaron Zolnai-Lucas, Jack Boylan, Chris Hokamp, Parsa Ghaffari

We present Simplified Text-Attributed Graph Embeddings (STAGE), a
straightforward yet effective method for enhancing node features in Graph
Neural Network (GNN) models that encode Text-Attributed Graphs (TAGs). Our
approach leverages Large-Language Models (LLMs) to generate embeddings for
textual attributes. STAGE achieves competitive results on various node
classification benchmarks while also maintaining a simplicity in implementation
relative to current state-of-the-art (SoTA) techniques. We show that utilizing
pre-trained LLMs as embedding generators provides robust features for ensemble
GNN training, enabling pipelines that are simpler than current SoTA approaches
which require multiple expensive training and prompting stages. We also
implement diffusion-pattern GNNs in an effort to make this pipeline scalable to
graphs beyond academic benchmarks.

æè¦ï¼æåæåºäºç°¡åæå­å±¬æ§ååµå¥ (STAGE)ï¼éæ¯ä¸ç¨®ç´æ¥ä½ææçæ¹æ³ï¼ç¨æ¼å¢å¼·åç¥ç¶ç¶²è·¯ (GNN) æ¨¡åä¸­çç¯é»ç¹å¾µï¼éäºæ¨¡åæç·¨ç¢¼æå­å±¬æ§å (TAG)ãæåçåæ³å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾çºæå­å±¬æ§ç¢çåµå¥ãSTAGE å¨åç¨®ç¯é»åé¡åºæºä¸åå¾äºæç«¶ç­åççµæï¼åæå¨å¯¦ä½ä¸ä¹ç¶­æäºç°¡æ½æ§ï¼ç¸è¼æ¼ç®åçæè¡æ°´æº (SoTA)ãæåå±ç¤ºäºä½¿ç¨é è¨ç·´ç LLM ä½çºåµå¥ç¢çå¨ï¼å¯çºæ´é« GNN è¨ç·´æä¾å¼·å¥çç¹å¾µï¼é²èå»ºæ§æ¯ç®å SoTA åæ³æ´ç°¡å®çç®¡éï¼èå¾èéè¦å¤åæè²´çè¨ç·´åæç¤ºéæ®µãæåä¹å¯¦ä½äºæ´æ£æ¨¡å¼ GNNï¼ä»¥æè®éåç®¡éè½æ´åå°å­¸è¡åºæºä¹å¤çåå½¢ã

##### **GLBench: A Comprehensive Benchmark for Graph with Large Language Models**
2407.07457v2 by Yuhan Li, Peisong Wang, Xiao Zhu, Aochuan Chen, Haiyun Jiang, Deng Cai, Victor Wai Kin Chan, Jia Li

The emergence of large language models (LLMs) has revolutionized the way we
interact with graphs, leading to a new paradigm called GraphLLM. Despite the
rapid development of GraphLLM methods in recent years, the progress and
understanding of this field remain unclear due to the lack of a benchmark with
consistent experimental protocols. To bridge this gap, we introduce GLBench,
the first comprehensive benchmark for evaluating GraphLLM methods in both
supervised and zero-shot scenarios. GLBench provides a fair and thorough
evaluation of different categories of GraphLLM methods, along with traditional
baselines such as graph neural networks. Through extensive experiments on a
collection of real-world datasets with consistent data processing and splitting
strategies, we have uncovered several key findings. Firstly, GraphLLM methods
outperform traditional baselines in supervised settings, with LLM-as-enhancers
showing the most robust performance. However, using LLMs as predictors is less
effective and often leads to uncontrollable output issues. We also notice that
no clear scaling laws exist for current GraphLLM methods. In addition, both
structures and semantics are crucial for effective zero-shot transfer, and our
proposed simple baseline can even outperform several models tailored for
zero-shot scenarios. The data and code of the benchmark can be found at
https://github.com/NineAbyss/GLBench.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çåºç¾å¾¹åºæ¹è®äºæåèåè¡¨äºåçæ¹å¼ï¼é²èç¢çä¸ç¨®ç¨±çº GraphLLM çæ°å¸ç¯ãåç®¡è¿å¹´ä¾ GraphLLM æ¹æ³å¿«éç¼å±ï¼ä½ç±æ¼ç¼ºä¹å·æä¸è´å¯¦é©åå®çåºæºï¼å æ­¤è©²é åçé²å±åçè§£ä»ä¸æç¢ºãçºäºå½è£éåå·®è·ï¼æåå¼å¥äº GLBenchï¼éæ¯ç¬¬ä¸åç¨æ¼è©ä¼° GraphLLM æ¹æ³å¨ç£ç£å¼åé¶æ¬¡å­¸ç¿å ´æ¯ä¸­çç¶ååºæºãGLBench æä¾å°ä¸åé¡å¥ç GraphLLM æ¹æ³é²è¡å¬å¹³ä¸å¾¹åºçè©ä¼°ï¼ä»¥åå³çµ±åºæºï¼ä¾å¦åç¥ç¶ç¶²è·¯ãééå°ä¸çµçå¯¦ä¸çè³æéé²è¡å»£æ³å¯¦é©ï¼ä¸¦æ¡ç¨ä¸è´çè³æèçååå²ç­ç¥ï¼æåç¼ç¾äºå¹¾åééµç¼ç¾ãé¦åï¼GraphLLM æ¹æ³å¨ç£ç£å¼è¨­å®ä¸­åªæ¼å³çµ±åºæºï¼å¶ä¸­ LLM ä½çºå¢å¼·å¨é¡¯ç¤ºåºæç©©å¥çæè½ãç¶èï¼ä½¿ç¨ LLM ä½çºé æ¸¬å¨è¼ä¸ææï¼èä¸ç¶å¸¸å°è´ç¡æ³æ§å¶çè¼¸åºåé¡ãæåéæ³¨æå°ï¼å°æ¼ç®åç GraphLLM æ¹æ³ä¸¦ä¸å­å¨æç¢ºçç¸®æ¾å®å¾ãæ­¤å¤ï¼çµæ§åèªç¾©å°æ¼ææçé¶æ¬¡å­¸ç¿å³è¼¸è³ééè¦ï¼èæåæåºçç°¡å®åºæºçè³å¯ä»¥åªæ¼éå°é¶æ¬¡å­¸ç¿å ´æ¯éèº«æé çå¹¾åæ¨¡åãåºæºçè³æåç¨å¼ç¢¼å¯ä»¥å¨ https://github.com/NineAbyss/GLBench ä¸­æ¾å°ã

##### **Decoding Climate Disagreement: A Graph Neural Network-Based Approach to Understanding Social Media Dynamics**
2407.07038v1 by Ruiran Su, Janet B. Pierrehumbert

This work introduces the ClimateSent-GAT Model, an innovative method that
integrates Graph Attention Networks (GATs) with techniques from natural
language processing to accurately identify and predict disagreements within
Reddit comment-reply pairs. Our model classifies disagreements into three
categories: agree, disagree, and neutral. Leveraging the inherent graph
structure of Reddit comment-reply pairs, the model significantly outperforms
existing benchmarks by capturing complex interaction patterns and sentiment
dynamics. This research advances graph-based NLP methodologies and provides
actionable insights for policymakers and educators in climate science
communication.

æè¦ï¼æ¬ç ç©¶ä»ç´¹ ClimateSent-GAT æ¨¡åï¼éæ¯ä¸ç¨®åµæ°çæ¹æ³ï¼å®å°åæ³¨æåç¶²è·¯ (GAT) èèªç¶èªè¨èçæè¡æ´åï¼ä»¥æºç¢ºè­å¥ä¸¦é æ¸¬ Reddit çè¨åè¦å°ä¸­çåæ­§ãæåçæ¨¡åå°åæ­§åçºä¸é¡ï¼åæãä¸åæåä¸­ç«ãééå©ç¨ Reddit çè¨åè¦å°çå§å¨åå½¢çµæ§ï¼æ­¤æ¨¡åè½å¤§å¹è¶è¶ç¾æåºæºï¼ææè¤éçäºåæ¨¡å¼åæç·åæãéé ç ç©¶æ¨åäºåºæ¼åå½¢ç NLP æ¹æ³ï¼ä¸¦çºæ°£åç§å­¸æºéä¸­çæ¿ç­å¶å®èåæè²å·¥ä½èæä¾å¯è¡çè¦è§£ã

##### **Graph-Based Captioning: Enhancing Visual Descriptions by Interconnecting Region Captions**
2407.06723v1 by Yu-Guan Hsieh, Cheng-Yu Hsieh, Shih-Ying Yeh, Louis BÃ©thune, Hadi Pour Ansari, Pavan Kumar Anasosalu Vasu, Chun-Liang Li, Ranjay Krishna, Oncel Tuzel, Marco Cuturi

Humans describe complex scenes with compositionality, using simple text
descriptions enriched with links and relationships. While vision-language
research has aimed to develop models with compositional understanding
capabilities, this is not reflected yet in existing datasets which, for the
most part, still use plain text to describe images. In this work, we propose a
new annotation strategy, graph-based captioning (GBC) that describes an image
using a labelled graph structure, with nodes of various types. The nodes in GBC
are created using, in a first stage, object detection and dense captioning
tools nested recursively to uncover and describe entity nodes, further linked
together in a second stage by highlighting, using new types of nodes,
compositions and relations among entities. Since all GBC nodes hold plain text
descriptions, GBC retains the flexibility found in natural language, but can
also encode hierarchical information in its edges. We demonstrate that GBC can
be produced automatically, using off-the-shelf multimodal LLMs and
open-vocabulary detection models, by building a new dataset, GBC10M, gathering
GBC annotations for about 10M images of the CC12M dataset. We use GBC10M to
showcase the wealth of node captions uncovered by GBC, as measured with CLIP
training. We show that using GBC nodes' annotations -- notably those stored in
composition and relation nodes -- results in significant performance boost on
downstream models when compared to other dataset formats. To further explore
the opportunities provided by GBC, we also propose a new attention mechanism
that can leverage the entire GBC graph, with encouraging experimental results
that show the extra benefits of incorporating the graph structure. Our datasets
are released at \url{https://huggingface.co/graph-based-captions}.

æè¦ï¼<paragraph>äººé¡ä½¿ç¨ç°¡å®çæå­æè¿°ï¼è±å¯çé£çµåéä¿ï¼ä¾æè¿°è¤éçå ´æ¯ãéç¶è¦è¦ºèªè¨çç ç©¶æ¨å¨éç¼å·æçµåçè§£è½åçæ¨¡åï¼ä½ç¾æçæ¸æéå°æªåæ éä¸é»ï¼éäºæ¸æéå¨å¾å¤§ç¨åº¦ä¸ä»ä½¿ç¨ç´ææ¬ä¾æè¿°ååãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°çè¨»éç­ç¥ï¼åºæ¼åè¡¨çæ¨é¡ (GBC)ï¼å®ä½¿ç¨æ¨ç±¤åè¡¨çµæ§ä¾æè¿°ååï¼å¶ä¸­åå«åç¨®é¡åçç¯é»ãGBC ä¸­çç¯é»æ¯ä½¿ç¨ç©é«æª¢æ¸¬åå¯éæ¨é¡å·¥å·å¨ç¬¬ä¸éæ®µåµå»ºçï¼ä»¥éè¿´åµå¥çæ¹å¼ç¼ç¾åæè¿°å¯¦é«ç¯é»ï¼ä¸¦å¨ç¬¬äºéæ®µä½¿ç¨æ°é¡åçç¯é»çªåºé¡¯ç¤ºï¼å¾èå°å®åé²ä¸æ­¥é£çµå¨ä¸èµ·ï¼å¯¦é«ä¹éççµååéä¿ãç±æ¼ææ GBC ç¯é»é½åå«ç´ææ¬æè¿°ï¼å æ­¤ GBC ä¿çäºèªç¶èªè¨ä¸­çéæ´»æ§ï¼ä½ä¹å¯ä»¥å¨å¶éç·£ç·¨ç¢¼åå±¤ä¿¡æ¯ãæåè­æäº GBC å¯ä»¥ä½¿ç¨ç¾æçå¤æ¨¡æ LLM åéæ¾è©å½æª¢æ¸¬æ¨¡åèªåçæï¼ééæ§å»ºä¸åæ°çæ¸æé GBC10Mï¼æ¶éäºå¤§ç´ 10M CC12M æ¸æéååç GBC è¨»éãæåä½¿ç¨ GBC10M ä¾å±ç¤º GBC ç¼ç¾çè±å¯ç¯é»æ¨é¡ï¼ä¸¦ä½¿ç¨ CLIP è¨ç·´é²è¡æ¸¬éãæåè¡¨æï¼èå¶ä»æ¸æéæ ¼å¼ç¸æ¯ï¼ä½¿ç¨ GBC ç¯é»çè¨»éââç¹å¥æ¯å­å²å¨çµååéä¿ç¯é»ä¸­çè¨»éââæé¡¯èæåä¸æ¸¸æ¨¡åçæ§è½ãçºäºé²ä¸æ­¥æ¢ç´¢ GBC æä¾çæ©æï¼æåéæåºäºä¸ç¨®æ°çæ³¨ææ©å¶ï¼å®å¯ä»¥å©ç¨æ´å GBC åè¡¨ï¼ä¸¦ééé¼åµæ§çå¯¦é©çµæå±ç¤ºäºçµååè¡¨çµæ§çé¡å¤å¥½èãæåçæ¸æéç¼å¸å¨ \url{https://huggingface.co/graph-based-captions}ã</paragraph>

##### **Combining Knowledge Graphs and Large Language Models**
2407.06564v1 by Amanda Kau, Xuzeng He, Aishwarya Nambissan, Aland Astudillo, Hui Yin, Amir Aryani

In recent years, Natural Language Processing (NLP) has played a significant
role in various Artificial Intelligence (AI) applications such as chatbots,
text generation, and language translation. The emergence of large language
models (LLMs) has greatly improved the performance of these applications,
showing astonishing results in language understanding and generation. However,
they still show some disadvantages, such as hallucinations and lack of
domain-specific knowledge, that affect their performance in real-world tasks.
These issues can be effectively mitigated by incorporating knowledge graphs
(KGs), which organise information in structured formats that capture
relationships between entities in a versatile and interpretable fashion.
Likewise, the construction and validation of KGs present challenges that LLMs
can help resolve. The complementary relationship between LLMs and KGs has led
to a trend that combines these technologies to achieve trustworthy results.
This work collected 28 papers outlining methods for KG-powered LLMs, LLM-based
KGs, and LLM-KG hybrid approaches. We systematically analysed and compared
these approaches to provide a comprehensive overview highlighting key trends,
innovative techniques, and common challenges. This synthesis will benefit
researchers new to the field and those seeking to deepen their understanding of
how KGs and LLMs can be effectively combined to enhance AI applications
capabilities.

æè¦ï¼è¿å¹´æ¥ï¼èªç¶è¯­è¨å¤ç (NLP) å¨åç§äººå·¥æºè½ (AI) åºç¨ä¸­åæ¥äºéè¦ä½ç¨ï¼ä¾å¦èå¤©æºå¨äººãææ¬çæåè¯­è¨ç¿»è¯ãå¤§è¯­è¨æ¨¡å (LLM) çåºç°æå¤§å°æé«äºè¿äºåºç¨ç¨åºçæ§è½ï¼å¨è¯­è¨çè§£åçææ¹é¢æ¾ç¤ºåºæäººçç»æãç¶èï¼å®ä»¬ä»ç¶è¡¨ç°åºä¸äºç¼ºç¹ï¼ä¾å¦å¹»è§åç¼ºä¹ç¹å®é¢åçç¥è¯ï¼è¿äºç¼ºç¹ä¼å½±åå®ä»¬å¨ç°å®ä¸çä¸­çä»»å¡ä¸­çè¡¨ç°ãéè¿çº³å¥ç¥è¯å¾è°± (KG) å¯ä»¥ææå°åè½»è¿äºé®é¢ï¼ç¥è¯å¾è°±ä»¥ç»æåæ ¼å¼ç»ç»ä¿¡æ¯ï¼ä»¥å¤åè½ä¸å¯è§£éçæ¹å¼æè·å®ä½ä¹é´çå³ç³»ãåæ ·ï¼KG çæå»ºåéªè¯æåºäº LLM å¯ä»¥å¸®å©è§£å³çææãLLM å KG ä¹é´çäºè¡¥å³ç³»å¯¼è´äºä¸ç§å°è¿äºææ¯ç¸ç»åä»¥å®ç°å¯ä¿¡ç»æçè¶å¿ãè¿é¡¹å·¥ä½æ¶éäº 28 ç¯æ¦è¿°äº KG é©±å¨ç LLMãåºäº LLM ç KG å LLM-KG æ··åæ¹æ³çæ¹æ³çè®ºæãæä»¬ç³»ç»å°åæåæ¯è¾äºè¿äºæ¹æ³ï¼ä»¥æä¾ä¸ä¸ªå¨é¢çæ¦è¿°ï¼éç¹ä»ç»å³é®è¶å¿ãåæ°ææ¯åå±åææãè¿ç§ç»¼åå°ä½¿è¯¥é¢åçæ°ç ç©¶äººååé£äºå¯»æ±å æ·±å¯¹å¦ä½ææå°å° KG å LLM ç¸ç»åä»¥å¢å¼º AI åºç¨è½åççè§£çäººåçã

##### **FuncEvalGMN: Evaluating Functional Correctness of SQL via Graph Matching Network**
2407.14530v1 by Yi Zhan, Yang Sun, Han Weng, Longjie Cui, Guifeng Wang, Jiajun Xie, Yu Tian, Xiaoming Yin, Boyi Liu, Dongchi Huang

In this paper, we propose a novel graph-based methodology to evaluate the
functional correctness of SQL generation. Conventional metrics for assessing
SQL code generation, such as matching-based and execution-based methods (e.g.,
exact set match and execution accuracy), are subject to two primary
limitations. Firstly, the former fails to effectively assess functional
correctness, as different SQL queries may possess identical functionalities.
Secondly, the latter is susceptible to producing false positive samples in
evaluations. Our proposed evaluation method, \texttt{FuncEvalGMN}, does not
depend on the sufficient preparation of the test data, and it enables precise
testing of the functional correctness of the code. Firstly, we parse SQL using
a relational operator tree (ROT) called \textit{Relnode}, which contains rich
semantic information from the perspective of logical execution.Then, we
introduce a GNN-based approach for predicting the functional correctness of
generated SQL. This approach incorporates global positional embeddings to
address the limitations with the loss of topological information in
conventional graph matching frameworks. As an auxiliary contribution, we
propose a rule-based matching algorithm, Relnode Partial Matching
(\texttt{RelPM}) as a baseline. Finally, we contribute a dataset,
\texttt{Pair-Aug-Spider} with a training set and two testing sets, each
comprising pairs of SQL codes to simulate various SQL code evaluation
scenarios. The training set and one testing dataset focus on code generation
using large language models (LLMs), while the other emphasizes SQL equivalence
rewriting.

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çåºæ¼åçæ¹æ³ä¾è©ä¼° SQL çæçåè½æ­£ç¢ºæ§ãè©ä¼° SQL ç¨å¼ç¢¼çæçå³çµ±ææ¨ï¼ä¾å¦åºæ¼å¹éååºæ¼å·è¡çææ¨ï¼ä¾å¦ï¼ç²¾ç¢ºéåå¹éåå·è¡æºç¢ºåº¦ï¼ï¼å­å¨å©åä¸»è¦çéå¶ãé¦åï¼åèç¡æ³ææè©ä¼°åè½æ­£ç¢ºæ§ï¼å çºä¸åç SQL æ¥è©¢å¯è½å·æç¸åçæ©è½ãå¶æ¬¡ï¼å¾èå¨è©ä¼°ä¸­å®¹æç¢çåé½æ§æ¨£æ¬ãæåæåºçè©ä¼°æ¹æ³ \texttt{FuncEvalGMN} ä¸ä¾è³´æ¼æ¸¬è©¦è³æçååæºåï¼ä¸¦ä¸å¯ä»¥ç²¾ç¢ºæ¸¬è©¦ç¨å¼ç¢¼çåè½æ­£ç¢ºæ§ãé¦åï¼æåä½¿ç¨ç¨±çº \textit{Relnode} çéä¿éç®åæ¨¹ (ROT) ä¾è§£æ SQLï¼å¶ä¸­åå«å¾éè¼¯å·è¡çè§åº¦ä¾çè±å¯çèªç¾©è³è¨ãç¶å¾ï¼æåå¼å¥ä¸ç¨®åºæ¼ GNN çæ¹æ³ä¾é æ¸¬çæç SQL çåè½æ­£ç¢ºæ§ãéç¨®æ¹æ³çµåäºå¨å±ä½ç½®åµå¥ï¼ä»¥è§£æ±ºå³çµ±åå½¢å¹éæ¡æ¶ä¸­ææ²è³è¨éºå¤±çéå¶ãä½çºè¼å©è²¢ç»ï¼æåæåºäºä¸ååºæ¼è¦åçå¹éæ¼ç®æ³ï¼å³ Relnode é¨åå¹é (\texttt{RelPM}) ä½çºåºç·ãæå¾ï¼æåè²¢ç»äºä¸åè³æé \texttt{Pair-Aug-Spider}ï¼å¶ä¸­åå«ä¸åè¨ç·´éåå©åæ¸¬è©¦éï¼æ¯åæ¸¬è©¦éé½åå«æå°ç SQL ç¨å¼ç¢¼ä¾æ¨¡æ¬åç¨® SQL ç¨å¼ç¢¼è©ä¼°å ´æ¯ãè¨ç·´éåä¸åæ¸¬è©¦è³æéå°æ³¨æ¼ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) é²è¡ç¨å¼ç¢¼çæï¼èå¦ä¸ååå¼·èª¿ SQL ç­å¹éå¯«ã</paragraph>

##### **MST5 -- Multilingual Question Answering over Knowledge Graphs**
2407.06041v1 by Nikit Srivastava, Mengshi Ma, Daniel Vollmers, Hamada Zahera, Diego Moussallem, Axel-Cyrille Ngonga Ngomo

Knowledge Graph Question Answering (KGQA) simplifies querying vast amounts of
knowledge stored in a graph-based model using natural language. However, the
research has largely concentrated on English, putting non-English speakers at a
disadvantage. Meanwhile, existing multilingual KGQA systems face challenges in
achieving performance comparable to English systems, highlighting the
difficulty of generating SPARQL queries from diverse languages. In this
research, we propose a simplified approach to enhance multilingual KGQA systems
by incorporating linguistic context and entity information directly into the
processing pipeline of a language model. Unlike existing methods that rely on
separate encoders for integrating auxiliary information, our strategy leverages
a single, pretrained multilingual transformer-based language model to manage
both the primary input and the auxiliary data. Our methodology significantly
improves the language model's ability to accurately convert a natural language
query into a relevant SPARQL query. It demonstrates promising results on the
most recent QALD datasets, namely QALD-9-Plus and QALD-10. Furthermore, we
introduce and evaluate our approach on Chinese and Japanese, thereby expanding
the language diversity of the existing datasets.

æè¦ï¼ç¥è­åè¡¨åç­ (KGQA) ç°¡åäºä½¿ç¨èªç¶èªè¨æ¥è©¢å²å­å¨åå½¢åæ¨¡åä¸­çå¤§éç¥è­ãç¶èï¼ç ç©¶ä¸»è¦éä¸­å¨è±æä¸ï¼éå°éè±èªä½¿ç¨èä¾èªªæ¯ä¸å©çãåæï¼ç¾æçå¤èªè¨ KGQA ç³»çµ±å¨éæèè±æç³»çµ±ç¸åª²ç¾çæè½æ¹é¢é¢è¨ææ°ï¼çªé¡¯äºå¾ä¸åèªè¨ç¢ç SPARQL æ¥è©¢çå°é£æ§ãå¨éé ç ç©¶ä¸­ï¼æåæåºäºä¸ç¨®ç°¡åçæ¹æ³ï¼ééå°èªè¨å­¸èæ¯åå¯¦é«è³è¨ç´æ¥ç´å¥èªè¨æ¨¡åçèçç®¡éï¼ä¾å¢å¼·å¤èªè¨ KGQA ç³»çµ±ãèä¾è³´æ¼å®ç¨ç·¨ç¢¼å¨ä¾æ´åè¼å©è³è¨çç¾ææ¹æ³ä¸åï¼æåçç­ç¥å©ç¨å®ä¸çãé è¨ç·´çå¤èªè¨è½æå¨èªè¨æ¨¡åä¾ç®¡çä¸»è¦è¼¸å¥åè¼å©è³æãæåçæè¡é¡¯èæåäºèªè¨æ¨¡åæºç¢ºå°å°èªç¶èªè¨æ¥è©¢è½æçºç¸é SPARQL æ¥è©¢çè½åãå®å¨ææ°ç QALD è³æéï¼å³ QALD-9-Plus å QALD-10 ä¸å±ç¤ºäºæå¸æççµæãæ­¤å¤ï¼æåå¨ä¸­æåæ¥æä¸­å¼å¥ä¸¦è©ä¼°äºæåçåæ³ï¼å¾èæ´å±äºç¾æè³æéçèªè¨å¤æ¨£æ§ã

##### **Enhancing Vision-Language Models with Scene Graphs for Traffic Accident Understanding**
2407.05910v1 by Aaron Lohner, Francesco Compagno, Jonathan Francis, Alessandro Oltramari

Recognizing a traffic accident is an essential part of any autonomous driving
or road monitoring system. An accident can appear in a wide variety of forms,
and understanding what type of accident is taking place may be useful to
prevent it from reoccurring. The task of being able to classify a traffic scene
as a specific type of accident is the focus of this work. We approach the
problem by likening a traffic scene to a graph, where objects such as cars can
be represented as nodes, and relative distances and directions between them as
edges. This representation of an accident can be referred to as a scene graph,
and is used as input for an accident classifier. Better results can be obtained
with a classifier that fuses the scene graph input with representations from
vision and language. This work introduces a multi-stage, multimodal pipeline to
pre-process videos of traffic accidents, encode them as scene graphs, and align
this representation with vision and language modalities for accident
classification. When trained on 4 classes, our method achieves a balanced
accuracy score of 57.77% on an (unbalanced) subset of the popular Detection of
Traffic Anomaly (DoTA) benchmark, representing an increase of close to 5
percentage points from the case where scene graph information is not taken into
account.

æè¦ï¼è¾¨è­äº¤éäºææ¯ä»»ä½èªåé§é§æéè·¯ç£æ§ç³»çµ±çå¿è¦é¨åãäºæå¯è½ä»¥åç¨®å½¢å¼åºç¾ï¼äºè§£äºæé¡åå¯è½æå©æ¼é²æ­¢åæ¬¡ç¼çãå°äº¤éäºæå ´æ¯åé¡çºç¹å®äºæé¡åçä»»åæ¯éé å·¥ä½çéé»ãæåå°äº¤éäºæå ´æ¯æ¯å»çºåå½¢ä¾è§£æ±ºåé¡ï¼å¶ä¸­æ±½è»ç­ç©é«å¯ä»¥è¡¨ç¤ºçºç¯é»ï¼èå®åä¹éçç¸å°è·é¢åæ¹ååè¡¨ç¤ºçºéç·£ãéç¨®äºæè¡¨ç¤ºå¯ä»¥ç¨±çºå ´æ¯åï¼ä¸¦ç¨ä½äºæåé¡å¨çè¼¸å¥ãä½¿ç¨å°å ´æ¯åè¼¸å¥èè¦è¦ºåèªè¨è¡¨ç¤ºèåçåé¡å¨å¯ä»¥ç²å¾æ´å¥½ççµæãéé å·¥ä½å¼å¥äºä¸åå¤éæ®µãå¤æ¨¡æç®¡éï¼ç¨æ¼é èçäº¤éäºæå½±çãå°å¶ç·¨ç¢¼çºå ´æ¯åï¼ä»¥åå°æ­¤è¡¨ç¤ºèè¦è¦ºåèªè¨æ¨¡å¼å°é½ä»¥é²è¡äºæåé¡ãç¶å¨ 4 åé¡å¥ä¸é²è¡è¨ç·´æï¼æåçæ¨¡åå¨ç±éäº¤éç°å¸¸æª¢æ¸¬ (DoTA) åºæºçï¼ä¸å¹³è¡¡ï¼å­éä¸å¯¦ç¾äº 57.77% çå¹³è¡¡æºç¢ºçï¼æ¯ä¸èæ®å ´æ¯åè³è¨çææ³æé«äºæ¥è¿ 5 åç¾åé»ã

##### **Affordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation**
2407.05890v1 by Jiaqi Chen, Bingqian Lin, Xinmin Liu, Xiaodan Liang, Kwan-Yee K. Wong

LLM-based agents have demonstrated impressive zero-shot performance in the
vision-language navigation (VLN) task. However, these zero-shot methods focus
only on solving high-level task planning by selecting nodes in predefined
navigation graphs for movements, overlooking low-level control in realistic
navigation scenarios. To bridge this gap, we propose AO-Planner, a novel
affordances-oriented planning framework for continuous VLN task. Our AO-Planner
integrates various foundation models to achieve affordances-oriented motion
planning and action decision-making, both performed in a zero-shot manner.
Specifically, we employ a visual affordances prompting (VAP) approach, where
visible ground is segmented utilizing SAM to provide navigational affordances,
based on which the LLM selects potential next waypoints and generates low-level
path planning towards selected waypoints. We further introduce a high-level
agent, PathAgent, to identify the most probable pixel-based path and convert it
into 3D coordinates to fulfill low-level motion. Experimental results on the
challenging R2R-CE benchmark demonstrate that AO-Planner achieves
state-of-the-art zero-shot performance (5.5% improvement in SPL). Our method
establishes an effective connection between LLM and 3D world to circumvent the
difficulty of directly predicting world coordinates, presenting novel prospects
for employing foundation models in low-level motion control.

æè¦ï¼åºæ¼ LLM çä»£çå·²å¨è¦è¦ºèªè¨å°èª (VLN) ä»»åä¸­å±ç¤ºåºä»¤äººå°è±¡æ·±å»çé¶æ¬¡å­¸ç¿æè½ãç¶èï¼éäºé¶æ¬¡å­¸ç¿æ¹æ³åå°æ³¨æ¼ééé¸æé å®ç¾©å°èªåå½¢ä¸­çç¯é»ä¾è§£æ±ºé«éä»»åè¦åï¼å¿½ç¥äºå¯¦éå°èªå ´æ¯ä¸­çä½éæ§å¶ãçºäºå½åæ­¤å·®è·ï¼æåæåº AO-Plannerï¼ä¸åç¨æ¼é£çº VLN ä»»åçæ°åä»¥å¯è² ææ§çºå°åçè¦åæ¶æ§ãæåç AO-Planner æ´ååç¨®åºç¤æ¨¡åï¼ä»¥å¯¦ç¾ä»¥å¯è² ææ§çºå°åçåä½è¦åååä½æ±ºç­ï¼å©èé½ä»¥é¶æ¬¡å­¸ç¿çæ¹å¼å·è¡ãå·é«ä¾èªªï¼æåæ¡ç¨è¦è¦ºå¯è² ææ§æç¤º (VAP) æ¹æ³ï¼å¶ä¸­å©ç¨ SAM å°å¯è¦å°é¢é²è¡åå²ï¼ä»¥æä¾å°èªå¯è² ææ§ï¼LLM æ ¹æéäºå¯è² ææ§é¸ææ½å¨çä¸ä¸åèªé»ï¼ä¸¦éå°æé¸èªé»ç¢çä½éè·¯å¾è¦åãæåé²ä¸æ­¥å¼å¥ä¸åé«éä»£ç PathAgentï¼ä»¥è­å¥æå¯è½çåºæ¼åç´ çè·¯å¾ï¼ä¸¦å°å¶è½æçº 3D åº§æ¨ï¼ä»¥å¯¦ç¾ä½éåä½ãå¨å·æææ°æ§ç R2R-CE åºæºæ¸¬è©¦ä¸çå¯¦é©çµæè¡¨æï¼AO-Planner éå°äºæåé²çé¶æ¬¡å­¸ç¿æè½ï¼SPL æå 5.5%ï¼ãæåçæ¨¡åå¨ LLM å 3D ä¸çä¹éå»ºç«äºä¸åææçé£çµï¼ä»¥è¦é¿ç´æ¥é æ¸¬ä¸çåº§æ¨çé£é¡ï¼çºå¨ä½éåä½æ§å¶ä¸­æ¡ç¨åºç¤æ¨¡åæä¾äºæ°çåæ¯ã

##### **KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions**
2407.05868v1 by Yanxu Zhu, Jinlin Xiao, Yuhang Wang, Jitao Sang

Recent studies have demonstrated that large language models (LLMs) are
susceptible to being misled by false premise questions (FPQs), leading to
errors in factual knowledge, know as factuality hallucination. Existing
benchmarks that assess this vulnerability primarily rely on manual
construction, resulting in limited scale and lack of scalability. In this work,
we introduce an automated, scalable pipeline to create FPQs based on knowledge
graphs (KGs). The first step is modifying true triplets extracted from KGs to
create false premises. Subsequently, utilizing the state-of-the-art
capabilities of GPTs, we generate semantically rich FPQs. Based on the proposed
method, we present a comprehensive benchmark, the Knowledge Graph-based False
Premise Questions (KG-FPQ), which contains approximately 178k FPQs across three
knowledge domains, at six levels of confusability, and in two task formats.
Using KG-FPQ, we conduct extensive evaluations on several representative LLMs
and provide valuable insights. The KG-FPQ dataset and code are available
at~https://github.com/yanxuzhu/KG-FPQ.

æè¦ï¼æè¿çç ç©¶è¡¨æï¼å¤§åè¯­è¨æ¨¡å (LLM) å®¹æè¢«éè¯¯åæé®é¢ (FPQ) è¯¯å¯¼ï¼ä»èå¯¼è´äºå®ç¥è¯éè¯¯ï¼å³äºå®å¹»è§ãç¨äºè¯ä¼°æ­¤æ¼æ´çç°æåºåä¸»è¦ä¾èµäºæå¨æå»ºï¼å¯¼è´è§æ¨¡æéä¸ç¼ºä¹å¯æ©å±æ§ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å¼å¥äºä¸ä¸ªåºäºç¥è¯å¾è°± (KG) åå»º FPQ çèªå¨åå¯æ©å±ç®¡éãç¬¬ä¸æ­¥æ¯ä¿®æ¹ä» KG ä¸­æåççä¸åç»ä»¥åå»ºéè¯¯åæãéåï¼å©ç¨ GPT çæåè¿åè½ï¼æä»¬çæäºè¯­ä¹ä¸°å¯ç FPQãåºäºææåºçæ¹æ³ï¼æä»¬æåºäºä¸ä¸ªç»¼ååºåï¼å³åºäºç¥è¯å¾è°±çéè¯¯åæé®é¢ (KG-FPQ)ï¼å®åå«å¤§çº¦ 178k ä¸ª FPQï¼æ¶µçä¸ä¸ªç¥è¯åï¼å­ä¸ªæ··æ·çº§å«åä¸¤ç§ä»»å¡æ ¼å¼ãä½¿ç¨ KG-FPQï¼æä»¬å¯¹å ä¸ªæä»£è¡¨æ§ç LLM è¿è¡äºå¹¿æ³çè¯ä¼°ï¼å¹¶æä¾äºæä»·å¼çè§è§£ãKG-FPQ æ°æ®éåä»£ç å¯å¨~https://github.com/yanxuzhu/KG-FPQ è·å¾ã

##### **Language Models Encode Collaborative Signals in Recommendation**
2407.05441v1 by Leheng Sheng, An Zhang, Yi Zhang, Yuxin Chen, Xiang Wang, Tat-Seng Chua

Recent studies empirically indicate that language models (LMs) encode rich
world knowledge beyond mere semantics, attracting significant attention across
various fields. However, in the recommendation domain, it remains uncertain
whether LMs implicitly encode user preference information. Contrary to the
prevailing understanding that LMs and traditional recommender models learn two
distinct representation spaces due to a huge gap in language and behavior
modeling objectives, this work rethinks such understanding and explores
extracting a recommendation space directly from the language representation
space. Surprisingly, our findings demonstrate that item representations, when
linearly mapped from advanced LM representations, yield superior recommendation
performance. This outcome suggests the homomorphism between the language
representation space and an effective recommendation space, implying that
collaborative signals may indeed be encoded within advanced LMs. Motivated by
these findings, we propose a simple yet effective collaborative filtering (CF)
model named AlphaRec, which utilizes language representations of item textual
metadata (e.g., titles) instead of traditional ID-based embeddings.
Specifically, AlphaRec is comprised of three main components: a multilayer
perceptron (MLP), graph convolution, and contrastive learning (CL) loss
function, making it extremely easy to implement and train. Our empirical
results show that AlphaRec outperforms leading ID-based CF models on multiple
datasets, marking the first instance of such a recommender with text embeddings
achieving this level of performance. Moreover, AlphaRec introduces a new
language-representation-based CF paradigm with several desirable advantages:
being easy to implement, lightweight, rapid convergence, superior zero-shot
recommendation abilities in new domains, and being aware of user intention.

æè¦ï¼<paragraph>æè¿çç ç©¶å¯¦è­è¡¨æï¼èªè¨æ¨¡å (LM) ç·¨ç¢¼è±å¯çä¸çç¥è­ï¼è¶è¶äºå®ç´çèªç¾©ï¼å¸å¼äºååé åçæ¥µå¤§éæ³¨ãç¶èï¼å¨æ¨è¦é åä¸­ï¼LM æ¯å¦é±å«ç·¨ç¢¼ä½¿ç¨èåå¥½è³è¨ä»ä¸ç¢ºå®ãèæ®éèªç¥ç¸åï¼LM åå³çµ±æ¨è¦æ¨¡åç±æ¼èªè¨åè¡çºå»ºæ¨¡ç®æ¨çå·¨å¤§å·®è·èå­¸ç¿å©åä¸åçè¡¨ç¤ºç©ºéï¼éé å·¥ä½éæ°æèéç¨®çè§£ï¼ä¸¦æ¢ç´¢ç´æ¥å¾èªè¨è¡¨ç¤ºç©ºéä¸­æåæ¨è¦ç©ºéãä»¤äººé©è¨çæ¯ï¼æåçç ç©¶çµæè¡¨æï¼ç¶å¾åé²ç LM è¡¨ç¤ºä¸­ç·æ§æ å°æï¼é ç®è¡¨ç¤ºæç¢çåªç°çæ¨è¦æè½ãæ­¤çµæè¡¨æèªè¨è¡¨ç¤ºç©ºéåææçæ¨è¦ç©ºéä¹éå­å¨åææ§ï¼éæå³èåä½è¨èç¢ºå¯¦å¯è½ç·¨ç¢¼å¨åé²ç LM ä¸­ãåéäºç ç©¶çµæçåç¼ï¼æåæåºäºä¸åç°¡å®ä½ææçååéæ¿¾ (CF) æ¨¡åï¼åçº AlphaRecï¼å®å©ç¨é ç®æå­åè³æï¼ä¾å¦æ¨é¡ï¼çèªè¨è¡¨ç¤ºï¼èä¸æ¯å³çµ±åºæ¼ ID çåµå¥ãå·é«ä¾èªªï¼AlphaRec ç±ä¸åä¸»è¦çµæé¨åçµæï¼å¤å±¤æç¥å¨ (MLP)ãåå½¢å·ç©åå°æ¯å­¸ç¿ (CL) æå¤±å½æ¸ï¼ä½¿å¶æ¥µææ¼å¯¦ä½åè¨ç·´ãæåçå¯¦è­çµæè¡¨æï¼AlphaRec å¨å¤åè³æéä¸åªæ¼é åçåºæ¼ ID ç CF æ¨¡åï¼æ¨èªèéç¨®å·ææå­åµå¥çæ¨è¦ç³»çµ±é¦æ¬¡éå°æ­¤æè½æ°´æºãæ­¤å¤ï¼AlphaRec å¼å¥äºä¸åæ°çåºæ¼èªè¨è¡¨ç¤ºç CF å¸ç¯ï¼å·æå¤é çæ³çåªé»ï¼ææ¼å¯¦ä½ãè¼éç´ãå¿«éæ¶æãå¨æ°çé åä¸­å·æåªç°çé¶æ¬¡å­¸ç¿æ¨è¦è½åï¼ä¸¦ä¸å¯ä»¥äºè§£ä½¿ç¨èçæåã</paragraph>

##### **LTLBench: Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models**
2407.05434v1 by Weizhi Tang, Vaishak Belle

Temporal reasoning (TR) is a critical component of artificial intelligence,
encompassing understanding and processing temporal information and
relationships between events. To discover and study the TR ability in Large
Language Models (LLMs), various datasets have been constructed in different
ways for evaluating various aspects of TR ability. Our work proposes a novel
approach to design and develop a pipeline for constructing datasets to evaluate
the TR ability of LLMs by leveraging random directed graph generation, LTL
formula, and the NuSMV model checker. Based on the pipeline, we have also
constructed a dataset as a benchmark, namely LTLBench, consisting of 2,000 TR
challenges and evaluated six LLMs with it. Furthermore, we have conducted
additional experiments to discover the impact of increasing the number of
events and formula operators on the complexity of TR problems and the
performance of LLMs. We have demonstrated that although LLMs exhibit some
promise in handling TR challenges, they still struggle with complex TR. We
expect this work can offer insights into TR ability in LLMs while also
providing a valuable tool for future TR evaluations.

æè¦ï¼æéæ¨ç (TR) æ¯äººå·¥æºæ§çä¸é ééµçµæé¨åï¼
æ¶µèäºå°æéè³è¨åäºä»¶ä¹ééä¿ççè§£åèçãçºäºç¼ç¾åç ç©¶å¤§åèªè¨æ¨¡å (LLM) ä¸­ç TR è½åï¼å·²ééåç¨®æ¹å¼å»ºæ§åç¨®è³æéï¼ç¨æ¼è©ä¼° TR è½åçååé¢åãæåçå·¥ä½æåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼ç¨æ¼è¨­è¨åéç¼ä¸åå»ºæ§è³æéçç®¡éï¼ä»¥è©ä¼° LLM ç TR è½åï¼æ¹æ³æ¯å©ç¨é¨æ©æååçæãLTL å¬å¼å NuSMV æ¨¡åæª¢æ¥å¨ãæ ¹æéåç®¡éï¼æåéå»ºæ§äºä¸åè³æéä½çºåºæºï¼å³ LTLBenchï¼å¶ä¸­åå« 2,000 å TR ææ°ï¼ä¸¦ç¨å®è©ä¼°äºå­å LLMãæ­¤å¤ï¼æåéé²è¡äºé¡å¤çå¯¦é©ï¼ä»¥ç¼ç¾å¢å äºä»¶æ¸éåå¬å¼éç®å­å° TR åé¡è¤éæ§å LLM æè½çå½±é¿ãæåå·²ç¶è­æï¼åç®¡ LLM å¨èç TR ææ°æ¹é¢è¡¨ç¾åºä¸äºå¸æï¼ä½å®åä»ç¶é£ä»¥èçè¤éç TRãæåé æéé å·¥ä½å¯ä»¥æä¾å° LLM ä¸­ TR è½åçè¦è§£ï¼åæä¹çºæªä¾ç TR è©ä¼°æä¾ä¸åæå¹å¼çå·¥å·ã

##### **Leveraging Graph Structures to Detect Hallucinations in Large Language Models**
2407.04485v1 by Noa Nonkes, Sergei Agaronian, Evangelos Kanoulas, Roxana Petcu

Large language models are extensively applied across a wide range of tasks,
such as customer support, content creation, educational tutoring, and providing
financial guidance. However, a well-known drawback is their predisposition to
generate hallucinations. This damages the trustworthiness of the information
these models provide, impacting decision-making and user confidence. We propose
a method to detect hallucinations by looking at the structure of the latent
space and finding associations within hallucinated and non-hallucinated
generations. We create a graph structure that connects generations that lie
closely in the embedding space. Moreover, we employ a Graph Attention Network
which utilizes message passing to aggregate information from neighboring nodes
and assigns varying degrees of importance to each neighbor based on their
relevance. Our findings show that 1) there exists a structure in the latent
space that differentiates between hallucinated and non-hallucinated
generations, 2) Graph Attention Networks can learn this structure and
generalize it to unseen generations, and 3) the robustness of our method is
enhanced when incorporating contrastive learning. When evaluated against
evidence-based benchmarks, our model performs similarly without access to
search-based methods.

æè¦ï¼å¤§åèªè¨æ¨¡åå»£æ³æç¨æ¼åç¨®ä»»åä¸­ï¼ä¾å¦å®¢æ¶æ¯æ´ãå§å®¹åµä½ãæè²è¼å°åæä¾è²¡åæå°ãç¶èï¼ä¸åç¾æå¨ç¥çç¼ºé»æ¯å®åå¾åæ¼ç¢çå¹»è¦ºãéæå®³äºéäºæ¨¡åææä¾è³è¨çå¯ä¿¡åº¦ï¼å½±é¿äºæ±ºç­å¶å®åä½¿ç¨èä¿¡å¿ãæåæåºäºä¸ç¨®ééè§å¯æ½å¨ç©ºéççµæ§ä¸¦æ¾åºå¹»è¦ºåéå¹»è¦ºçæä¸­çéè¯ä¾åµæ¸¬å¹»è¦ºçæ¹æ³ãæåå»ºç«äºä¸ååå½¢çµæ§ï¼é£æ¥å¨åµå¥ç©ºéä¸­ç·å¯ç¸é£ççæãæ­¤å¤ï¼æåæ¡ç¨äºä¸ååå½¢æ³¨æåç¶²è·¯ï¼å®å©ç¨è¨æ¯å³éä¾å½ç¸½ä¾èªç¸é°ç¯é»çè³è¨ï¼ä¸¦æ ¹ææ¯åç¸é°ç¯é»çç¸éæ§çºå¶æå®ä¸åç¨åº¦çéè¦æ§ãæåçç ç©¶çµæé¡¯ç¤ºï¼1) æ½å¨ç©ºéä¸­å­å¨ä¸åçµæ§ï¼å¯ä»¥ååå¹»è¦ºåéå¹»è¦ºçæï¼2) åå½¢æ³¨æåç¶²è·¯å¯ä»¥å­¸ç¿éåçµæ§ä¸¦å°å¶æ¦æ¬å°æªè¦ççæä¸­ï¼ä»¥å 3) ç¶ç´å¥å°æ¯å­¸ç¿æï¼æåæ¹æ³çç©©å¥æ§æå¾å°å¢å¼·ãç¶æ ¹æåºæ¼è­æçåºæºé²è¡è©ä¼°æï¼æåçæ¨¡åå¨ç¡æ³åå¾åºæ¼æå°çæ¹æ³çææ³ä¸ï¼è¡¨ç¾å¾é¡ä¼¼ã

##### **AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents**
2407.04363v1 by Petr Anokhin, Nikita Semenov, Artyom Sorokin, Dmitry Evseev, Mikhail Burtsev, Evgeny Burnaev

Advancements in generative AI have broadened the potential applications of
Large Language Models (LLMs) in the development of autonomous agents. Achieving
true autonomy requires accumulating and updating knowledge gained from
interactions with the environment and effectively utilizing it. Current
LLM-based approaches leverage past experiences using a full history of
observations, summarization or retrieval augmentation. However, these
unstructured memory representations do not facilitate the reasoning and
planning essential for complex decision-making. In our study, we introduce
AriGraph, a novel method wherein the agent constructs a memory graph that
integrates semantic and episodic memories while exploring the environment. This
graph structure facilitates efficient associative retrieval of interconnected
concepts, relevant to the agent's current state and goals, thus serving as an
effective environmental model that enhances the agent's exploratory and
planning capabilities. We demonstrate that our Ariadne LLM agent, equipped with
this proposed memory architecture augmented with planning and decision-making,
effectively handles complex tasks on a zero-shot basis in the TextWorld
environment. Our approach markedly outperforms established methods such as
full-history, summarization, and Retrieval-Augmented Generation in various
tasks, including the cooking challenge from the First TextWorld Problems
competition and novel tasks like house cleaning and puzzle Treasure Hunting.

æè¦ï¼çæå¼ AI çé²æ­¥æ´å±äºå¤§åèªè¨æ¨¡å (LLM) å¨èªä¸»ä»£çéç¼ä¸­çæ½å¨æç¨ãå¯¦ç¾çæ­£çèªä¸»æ§éè¦ç´¯ç©åæ´æ°å¾èç°å¢äºåä¸­ç²å¾çç¥è­ï¼ä¸¦ææå©ç¨å®ãç¶åçåºæ¼ LLM çæ¹æ³å©ç¨éå»çç¶é©ï¼ä½¿ç¨å®æ´çè§å¯ãæè¦ææª¢ç´¢æ´åãç¶èï¼éäºéçµæ§åçè¨æ¶è¡¨å¾µä¸¦ä¸è½ä¿é²è¤éæ±ºç­å¶å®ä¸­å¿ä¸å¯å°çæ¨çåè¦åãå¨æåçç ç©¶ä¸­ï¼æåä»ç´¹äº AriGraphï¼éæ¯ä¸ç¨®æ°æ¹æ³ï¼å¶ä¸­ä»£çæ§å»ºäºä¸åè¨æ¶åï¼è©²åå¨æ¢ç´¢ç°å¢ææ´åäºèªç¾©åæç¯è¨æ¶ãéç¨®åå½¢çµæ§ä¿é²äºç¸äºè¯ç¹«çæ¦å¿µçææéè¯æ§æª¢ç´¢ï¼èä»£ççç¶åçæåç®æ¨ç¸éï¼å¾èä½çºä¸åææçç°å¢æ¨¡åï¼å¢å¼·äºä»£ççæ¢ç´¢åè¦åè½åãæåå±ç¤ºäºæåç Ariadne LLM ä»£çï¼éåäºéç¨®æè­°çè¨æ¶æ¶æ§ï¼ä¸¦å¢å¼·äºè¦ååæ±ºç­å¶å®ï¼ææå°èçäº TextWorld ç°å¢ä¸­é¶æ¬¡å­¸ç¿çè¤éä»»åãæåçåæ³é¡¯èåªæ¼å·²å»ºç«çæ¹æ³ï¼ä¾å¦å®æ´æ­·å²ãæè¦åæª¢ç´¢å¢å¼·çæï¼å¨åç¨®ä»»åä¸­ï¼åæ¬ä¾èªç¬¬ä¸å TextWorld åé¡ç«¶è³½çç¹é£ªææ°åæ¿å±æ¸æ½åæ¼åå°å¯¶ç­æ°ä»»åã

##### **Semantic Graphs for Syntactic Simplification: A Revisit from the Age of LLM**
2407.04067v1 by Peiran Yao, Kostyantyn Guzhva, Denilson Barbosa

Symbolic sentence meaning representations, such as AMR (Abstract Meaning
Representation) provide expressive and structured semantic graphs that act as
intermediates that simplify downstream NLP tasks. However, the
instruction-following capability of large language models (LLMs) offers a
shortcut to effectively solve NLP tasks, questioning the utility of semantic
graphs. Meanwhile, recent work has also shown the difficulty of using meaning
representations merely as a helpful auxiliary for LLMs. We revisit the position
of semantic graphs in syntactic simplification, the task of simplifying
sentence structures while preserving their meaning, which requires semantic
understanding, and evaluate it on a new complex and natural dataset. The
AMR-based method that we propose, AMRS$^3$, demonstrates that state-of-the-art
meaning representations can lead to easy-to-implement simplification methods
with competitive performance and unique advantages in cost, interpretability,
and generalization. With AMRS$^3$ as an anchor, we discover that syntactic
simplification is a task where semantic graphs are helpful in LLM prompting. We
propose AMRCoC prompting that guides LLMs to emulate graph algorithms for
explicit symbolic reasoning on AMR graphs, and show its potential for improving
LLM on semantic-centered tasks like syntactic simplification.

æè¦ï¼ç¬¦èå¥å­æç¾©è¡¨å¾µï¼ä¾å¦ AMRï¼æ½è±¡æç¾©è¡¨å¾µï¼ï¼æä¾è¡¨éæ§åçµæ§åçèªç¾©åè¡¨ï¼ä½çºç°¡åä¸æ¸¸ NLP ä»»åçä¸­ä»ãç¶èï¼å¤§åèªè¨æ¨¡å (LLM) çæä»¤éµå¾ªè½åæä¾äºä¸åæ·å¾ä¾ææè§£æ±º NLP ä»»åï¼è³ªçèªç¾©åè¡¨çæç¨ãåæï¼æè¿çç ç©¶ä¹è¡¨æåå°æç¾©è¡¨å¾µç¨ä½ LLM çè¼å©å·¥å·çé£åº¦ãæåéæ°å¯©è¦èªç¾©åè¡¨å¨èªæ³ç°¡åä¸­çä½ç½®ï¼èªæ³ç°¡åçä»»åæ¯å¨ä¿çå¥å­çµæ§çåæç°¡åå¥å­çµæ§ï¼ééè¦èªç¾©çè§£ï¼ä¸¦å¨ä¸åæ°çè¤éä¸èªç¶çæ¸æéä¸å°å¶é²è¡è©ä¼°ãæåæåºçåºæ¼ AMR çæ¹æ³ AMRS$^3$ è­æäºæåé²çæç¾©è¡¨å¾µå¯ä»¥å°è´ææ¼å¯¦ç¾çç°¡åæ¹æ³ï¼å¨ææ¬ãå¯è§£éæ§åæ³åæ¹é¢å·æç«¶ç­åªå¢åç¨ç¹åªå¢ãä»¥ AMRS$^3$ çºé¨é»ï¼æåç¼ç¾èªæ³ç°¡åæ¯ä¸é èªç¾©åè¡¨æå©æ¼ LLM æç¤ºçä»»åãæåæåº AMRCoC æç¤ºï¼æå° LLM æ¨¡æ¬åå½¢æ¼ç®æ³ï¼å° AMR åå½¢é²è¡æç¢ºçç¬¦èæ¨çï¼ä¸¦å±ç¤ºå¶å¨æ¹é² LLM å¨ä»¥èªç¾©çºä¸­å¿çä»»åï¼å¦èªæ³ç°¡åï¼æ¹é¢çæ½åã

##### **Functional Faithfulness in the Wild: Circuit Discovery with Differentiable Computation Graph Pruning**
2407.03779v1 by Lei Yu, Jingcheng Niu, Zining Zhu, Gerald Penn

In this paper, we introduce a comprehensive reformulation of the task known
as Circuit Discovery, along with DiscoGP, a novel and effective algorithm based
on differentiable masking for discovering circuits. Circuit discovery is the
task of interpreting the computational mechanisms of language models (LMs) by
dissecting their functions and capabilities into sparse subnetworks (circuits).
We identified two major limitations in existing circuit discovery efforts: (1)
a dichotomy between weight-based and connection-edge-based approaches forces
researchers to choose between pruning connections or weights, thereby limiting
the scope of mechanistic interpretation of LMs; (2) algorithms based on
activation patching tend to identify circuits that are neither functionally
faithful nor complete. The performance of these identified circuits is
substantially reduced, often resulting in near-random performance in isolation.
Furthermore, the complement of the circuit -- i.e., the original LM with the
identified circuit removed -- still retains adequate performance, indicating
that essential components of a complete circuits are missed by existing
methods.
  DiscoGP successfully addresses the two aforementioned issues and demonstrates
state-of-the-art faithfulness, completeness, and sparsity. The effectiveness of
the algorithm and its novel structure open up new avenues of gathering new
insights into the internal workings of generative AI.

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æåä»ç´¹äºå°ç¨±çºé»è·¯ç¼ç¾ä»»åçå¨é¢éæ°è¡¨è¿°ï¼ä»¥å DiscoGPï¼ä¸ç¨®åºæ¼å¯å¾®é®ç½©çç¼ç¾é»è·¯çæ°ç©ä¸ææçæ¼ç®æ³ãé»è·¯ç¼ç¾æ¯ééå°å¶åè½åè½åè§£åæç¨çå­ç¶²è·¯ï¼é»è·¯ï¼ä¾è©®éèªè¨æ¨¡åï¼LMï¼çéç®æ©å¶çä»»åãæåå¨ç¾æçé»è·¯ç¼ç¾å·¥ä½ä¸­ç¼ç¾äºå©åä¸»è¦çéå¶ï¼ï¼1ï¼åºæ¼æ¬éååºæ¼é£æ¥éç·£çæ¹æ³ä¹éçäºåæ³è¿«ä½¿ç ç©¶äººå¡å¨ä¿®åªé£æ¥ææ¬éä¹éé²è¡é¸æï¼å¾èéå¶äº LM æ©å¶è©®éçç¯åï¼ï¼2ï¼åºæ¼åç¨ä¿®è£çæ¼ç®æ³å¾åæ¼è­å¥å¨åè½ä¸æ¢ä¸å¿ å¯¦ä¹ä¸å®æ´çé»è·¯ãéäºå·²è­å¥é»è·¯çæè½å¤§å¹éä½ï¼éå¸¸å°è´å­¤ç«çè¿ä¹é¨æ©æè½ãæ­¤å¤ï¼é»è·¯çè£æ¸ââå³ç§»é¤å·²è­å¥é»è·¯çåå§ LMââä»ä¿çäºè¶³å¤ çæè½ï¼éè¡¨ç¤ºç¾ææ¹æ³é¯å¤±äºå®æ´é»è·¯çåºæ¬çµæé¨åã
DiscoGP æåå°è§£æ±ºäºä¸è¿°å©ååé¡ï¼ä¸¦å±ç¤ºäºæåé²çå¿ å¯¦åº¦ãå®æ´æ§åç¨çæ§ãè©²æ¼ç®æ³çæææ§åå¶æ°ç©ççµæ§çºæ·±å¥ç­è§£çæå¼ AI çå§é¨éä½éé¢äºæ°çéå¾ã</paragraph>


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-08**|**Arctic-TILT. Business Document Understanding at Sub-Billion Scale**|Åukasz Borchmann et.al.|[2408.04632v1](http://arxiv.org/abs/2408.04632v1)|null|
|**2024-08-08**|**Puppet-Master: Scaling Interactive Video Generation as a Motion Prior for Part-Level Dynamics**|Ruining Li et.al.|[2408.04631v1](http://arxiv.org/abs/2408.04631v1)|null|
|**2024-08-08**|**LogogramNLP: Comparing Visual and Textual Representations of Ancient Logographic Writing Systems for NLP**|Danlu Chen et.al.|[2408.04628v1](http://arxiv.org/abs/2408.04628v1)|null|
|**2024-08-08**|**Transformer Explainer: Interactive Learning of Text-Generative Models**|Aeree Cho et.al.|[2408.04619v1](http://arxiv.org/abs/2408.04619v1)|null|
|**2024-08-08**|**Better Alignment with Instruction Back-and-Forth Translation**|Thao Nguyen et.al.|[2408.04614v1](http://arxiv.org/abs/2408.04614v1)|null|
|**2024-08-08**|**Code-switching in text and speech reveals information-theoretic audience design**|Debasmita Bhattacharya et.al.|[2408.04596v1](http://arxiv.org/abs/2408.04596v1)|null|
|**2024-08-08**|**Img-Diff: Contrastive Data Synthesis for Multimodal Large Language Models**|Qirui Jiao et.al.|[2408.04594v1](http://arxiv.org/abs/2408.04594v1)|[link](https://github.com/modelscope/data-juicer)|
|**2024-08-08**|**HiLo: A Learning Framework for Generalized Category Discovery Robust to Domain Shifts**|Hongjun Wang et.al.|[2408.04591v1](http://arxiv.org/abs/2408.04591v1)|null|
|**2024-08-08**|**Towards Resilient and Efficient LLMs: A Comparative Study of Efficiency, Performance, and Adversarial Robustness**|Xiaojing Fan et.al.|[2408.04585v1](http://arxiv.org/abs/2408.04585v1)|null|
|**2024-08-08**|**SCENE: Evaluating Explainable AI Techniques Using Soft Counterfactuals**|Haoran Zheng et.al.|[2408.04575v1](http://arxiv.org/abs/2408.04575v1)|null|
|**2024-08-08**|**Learning Fine-Grained Grounded Citations for Attributed Large Language Models**|Lei Huang et.al.|[2408.04568v1](http://arxiv.org/abs/2408.04568v1)|[link](https://github.com/luckyyysta/fine-grained-attribution)|
|**2024-08-08**|**Conversational Prompt Engineering**|Liat Ein-Dor et.al.|[2408.04560v1](http://arxiv.org/abs/2408.04560v1)|null|
|**2024-08-08**|**Bias-Aware Low-Rank Adaptation: Mitigating Catastrophic Inheritance of Large Language Models**|Yupeng Chang et.al.|[2408.04556v1](http://arxiv.org/abs/2408.04556v1)|[link](https://github.com/cyp-jlu-ai/ba-lora)|
|**2024-08-08**|**MolyÃ©: A Corpus-based Approach to Language Contact in Colonial France**|Rasul Dent et.al.|[2408.04554v1](http://arxiv.org/abs/2408.04554v1)|null|
|**2024-08-08**|**MemeMind at ArAIEval Shared Task: Spotting Persuasive Spans in Arabic Text with Persuasion Techniques Identification**|Md Rafiul Biswas et.al.|[2408.04540v1](http://arxiv.org/abs/2408.04540v1)|null|
|**2024-08-08**|**Compromesso! Italian Many-Shot Jailbreaks Undermine the Safety of Large Language Models**|Fabio Pernisi et.al.|[2408.04522v1](http://arxiv.org/abs/2408.04522v1)|null|
|**2024-08-08**|**Articulatory Configurations across Genders and Periods in French Radio and TV archives**|Benjamin Elie et.al.|[2408.04519v1](http://arxiv.org/abs/2408.04519v1)|null|
|**2024-08-08**|**Towards Synergistic Deep Learning Models for Volumetric Cirrhotic Liver Segmentation in MRIs**|Vandan Gorade et.al.|[2408.04491v1](http://arxiv.org/abs/2408.04491v1)|null|
|**2024-08-08**|**SegXAL: Explainable Active Learning for Semantic Segmentation in Driving Scene Scenarios**|Sriram Mandalika et.al.|[2408.04482v1](http://arxiv.org/abs/2408.04482v1)|null|
|**2024-08-08**|**Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive Debate**|Yiqun Zhang et.al.|[2408.04472v1](http://arxiv.org/abs/2408.04472v1)|[link](https://github.com/zhangyiqun018/agent-for-debate)|
|**2024-08-08**|**Crowd Intelligence for Early Misinformation Prediction on Social Media**|Megha Sundriyal et.al.|[2408.04463v1](http://arxiv.org/abs/2408.04463v1)|null|
|**2024-08-08**|**RiskAwareBench: Towards Evaluating Physical Risk Awareness for High-level Planning of LLM-based Embodied Agents**|Zihao Zhu et.al.|[2408.04449v1](http://arxiv.org/abs/2408.04449v1)|null|
|**2024-08-08**|**FedAD-Bench: A Unified Benchmark for Federated Unsupervised Anomaly Detection in Tabular Data**|Ahmed Anwar et.al.|[2408.04442v1](http://arxiv.org/abs/2408.04442v1)|null|
|**2024-08-08**|**Recognizing Emotion Regulation Strategies from Human Behavior with Large Language Models**|Philipp MÃ¼ller et.al.|[2408.04420v1](http://arxiv.org/abs/2408.04420v1)|null|
|**2024-08-08**|**Enhancing Robustness of Retrieval-Augmented Language Models with In-Context Learning**|Seong-Il Park et.al.|[2408.04414v1](http://arxiv.org/abs/2408.04414v1)|null|
|**2024-08-08**|**Exploring Reasoning Biases in Large Language Models Through Syllogism: Insights from the NeuBAROCO Dataset**|Kentaro Ozeki et.al.|[2408.04403v1](http://arxiv.org/abs/2408.04403v1)|[link](https://github.com/kmineshima/neubaroco)|
|**2024-08-08**|**DIVE: Subgraph Disagreement for Graph Out-of-Distribution Generalization**|Xin Sun et.al.|[2408.04400v1](http://arxiv.org/abs/2408.04400v1)|null|
|**2024-08-08**|**Automated Educational Question Generation at Different Bloom's Skill Levels using Large Language Models: Strategies and Evaluation**|Nicy Scaria et.al.|[2408.04394v1](http://arxiv.org/abs/2408.04394v1)|null|
|**2024-08-08**|**Open-domain Implicit Format Control for Large Language Model Generation**|Yiqun Yao et.al.|[2408.04392v1](http://arxiv.org/abs/2408.04392v1)|null|
|**2024-08-08**|**MM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models**|Haoxuan Li et.al.|[2408.04388v1](http://arxiv.org/abs/2408.04388v1)|[link](https://github.com/luminosityx/mm-forecast)|
|**2024-08-08**|**Judgment2vec: Apply Graph Analytics to Searching and Recommendation of Similar Judgments**|Hsuan-Lei Shao et.al.|[2408.04382v1](http://arxiv.org/abs/2408.04382v1)|null|
|**2024-08-08**|**Overview of the NLPCC 2024 Shared Task on Chinese Metaphor Generation**|Xingwei Qu et.al.|[2408.04378v1](http://arxiv.org/abs/2408.04378v1)|null|
|**2024-08-08**|**Simulating Articulatory Trajectories with Phonological Feature Interpolation**|Angelo Ortiz Tandazo et.al.|[2408.04363v1](http://arxiv.org/abs/2408.04363v1)|null|
|**2024-08-08**|**Towards Explainable Network Intrusion Detection using Large Language Models**|Paul R. B. Houssel et.al.|[2408.04342v1](http://arxiv.org/abs/2408.04342v1)|null|
|**2024-08-08**|**KnowPC: Knowledge-Driven Programmatic Reinforcement Learning for Zero-shot Coordination**|Yin Gu et.al.|[2408.04336v1](http://arxiv.org/abs/2408.04336v1)|null|
|**2024-08-08**|**Enhancing Journalism with AI: A Study of Contextualized Image Captioning for News Articles using LLMs and LMMs**|Aliki Anagnostopoulou et.al.|[2408.04331v1](http://arxiv.org/abs/2408.04331v1)|null|
|**2024-08-08**|**HydraFormer: One Encoder For All Subsampling Rates**|Yaoxun Xu et.al.|[2408.04325v1](http://arxiv.org/abs/2408.04325v1)|[link](https://github.com/hydraformer/hydraformer)|
|**2024-08-08**|**Learning with Digital Agents: An Analysis based on the Activity Theory**|Mateusz Dolata et.al.|[2408.04304v1](http://arxiv.org/abs/2408.04304v1)|null|
|**2024-08-08**|**Trans-Tokenization and Cross-lingual Vocabulary Transfers: Language Adaptation of LLMs for Low-Resource NLP**|FranÃ§ois Remy et.al.|[2408.04303v1](http://arxiv.org/abs/2408.04303v1)|[link](https://github.com/lagom-nlp/transtokenizer)|
|**2024-08-08**|**Tackling Noisy Clients in Federated Learning with End-to-end Label Correction**|Xuefeng Jiang et.al.|[2408.04301v1](http://arxiv.org/abs/2408.04301v1)|[link](https://github.com/sprinter1999/fedelc)|
|**2024-08-08**|**Are Social Sentiments Inherent in LLMs? An Empirical Study on Extraction of Inter-demographic Sentiments**|Kunitomo Tanaka et.al.|[2408.04293v1](http://arxiv.org/abs/2408.04293v1)|null|
|**2024-08-08**|**EMTeC: A Corpus of Eye Movements on Machine-Generated Texts**|Lena Sophia Bolliger et.al.|[2408.04289v1](http://arxiv.org/abs/2408.04289v1)|[link](https://github.com/dili-lab/emtec)|
|**2024-08-08**|**LLM-DetectAIve: a Tool for Fine-Grained Machine-Generated Text Detection**|Mervat Abassy et.al.|[2408.04284v1](http://arxiv.org/abs/2408.04284v1)|null|
|**2024-08-08**|**LaDiMo: Layer-wise Distillation Inspired MoEfier**|Sungyoon Kim et.al.|[2408.04278v1](http://arxiv.org/abs/2408.04278v1)|null|
|**2024-08-08**|**Analysis of Argument Structure Constructions in the Large Language Model BERT**|Pegah Ramezani et.al.|[2408.04270v1](http://arxiv.org/abs/2408.04270v1)|null|
|**2024-08-08**|**Unveiling Hidden Visual Information: A Reconstruction Attack Against Adversarial Visual Information Hiding**|Jonggyu Jang et.al.|[2408.04261v1](http://arxiv.org/abs/2408.04261v1)|null|
|**2024-08-08**|**EfficientRAG: Efficient Retriever for Multi-Hop Question Answering**|Ziyuan Zhuang et.al.|[2408.04259v1](http://arxiv.org/abs/2408.04259v1)|null|
|**2024-08-08**|**Explicating the Implicit: Argument Detection Beyond Sentence Boundaries**|Paul Roit et.al.|[2408.04246v1](http://arxiv.org/abs/2408.04246v1)|null|
|**2024-08-08**|**Scalable Transformer for High Dimensional Multivariate Time Series Forecasting**|Xin Zhou et.al.|[2408.04245v1](http://arxiv.org/abs/2408.04245v1)|[link](https://github.com/xinzzzhou/scalabletransformer4highdimensionmtsf)|
|**2024-08-08**|**The Ungrounded Alignment Problem**|Marc Pickett et.al.|[2408.04242v1](http://arxiv.org/abs/2408.04242v1)|[link](https://github.com/EmergenceAI/babybeaver)|
|**2024-08-08**|**Learning to Rewrite: Generalized LLM-Generated Text Detection**|Wei Hao et.al.|[2408.04237v1](http://arxiv.org/abs/2408.04237v1)|null|
|**2024-08-08**|**Probabilistic Circuits for Cumulative Distribution Functions**|Oliver Broadrick et.al.|[2408.04229v1](http://arxiv.org/abs/2408.04229v1)|null|
|**2024-08-08**|**Evaluating Language Model Math Reasoning via Grounding in Educational Curricula**|Li Lucy et.al.|[2408.04226v1](http://arxiv.org/abs/2408.04226v1)|[link](https://github.com/allenai/mathfish)|
|**2024-08-08**|**VideoQA in the Era of LLMs: An Empirical Study**|Junbin Xiao et.al.|[2408.04223v1](http://arxiv.org/abs/2408.04223v1)|null|
|**2024-08-08**|**Connective Viewpoints of Signal-to-Noise Diffusion Models**|Khanh Doan et.al.|[2408.04221v1](http://arxiv.org/abs/2408.04221v1)|null|
|**2024-08-08**|**Diffusion Guided Language Modeling**|Justin Lovelace et.al.|[2408.04220v1](http://arxiv.org/abs/2408.04220v1)|[link](https://github.com/justinlovelace/diffusion-guided-lm)|
|**2024-08-08**|**Simplifying Translations for Children: Iterative Simplification Considering Age of Acquisition with LLMs**|Masashi Oshika et.al.|[2408.04217v1](http://arxiv.org/abs/2408.04217v1)|[link](https://github.com/nttcslab-nlp/simplifyingmt_acl24)|
|**2024-08-08**|**Attention Mechanism and Context Modeling System for Text Mining Machine Translation**|Shi Bo et.al.|[2408.04216v1](http://arxiv.org/abs/2408.04216v1)|null|
|**2024-08-08**|**MMREC: LLM Based Multi-Modal Recommender System**|Jiahao Tian et.al.|[2408.04211v1](http://arxiv.org/abs/2408.04211v1)|null|
|**2024-08-08**|**MMRole: A Comprehensive Framework for Developing and Evaluating Multimodal Role-Playing Agents**|Yanqi Dai et.al.|[2408.04203v1](http://arxiv.org/abs/2408.04203v1)|[link](https://github.com/yanqidai/mmrole)|
|**2024-08-08**|**Pairwise Judgment Formulation for Semantic Embedding Model in Web Search**|Mengze Hong et.al.|[2408.04197v1](http://arxiv.org/abs/2408.04197v1)|null|
|**2024-08-08**|**Uncertainty-Aware Crime Prediction With Spatial Temporal Multivariate Graph Neural Networks**|Zepu Wang et.al.|[2408.04193v1](http://arxiv.org/abs/2408.04193v1)|null|
|**2024-08-08**|**Listwise Reward Estimation for Offline Preference-based Reinforcement Learning**|Heewoong Choi et.al.|[2408.04190v1](http://arxiv.org/abs/2408.04190v1)|[link](https://github.com/chwoong/lire)|
|**2024-08-08**|**wav2graph: A Framework for Supervised Learning Knowledge Graph from Speech**|Khai Le-Duc et.al.|[2408.04174v1](http://arxiv.org/abs/2408.04174v1)|null|
|**2024-08-08**|**Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions**|Qingbin Zeng et.al.|[2408.04168v1](http://arxiv.org/abs/2408.04168v1)|null|
|**2024-08-08**|**Semantics or spelling? Probing contextual word embeddings with orthographic noise**|Jacob A. Matthews et.al.|[2408.04162v1](http://arxiv.org/abs/2408.04162v1)|[link](https://github.com/jam963/semantics-or-spelling)|
|**2024-08-08**|**The Data Addition Dilemma**|Judy Hanwen Shen et.al.|[2408.04154v1](http://arxiv.org/abs/2408.04154v1)|[link](https://github.com/the-chen-lab/data-addition-dilemma)|
|**2024-08-08**|**UNLEARN Efficient Removal of Knowledge in Large Language Models**|Tyler Lizzo et.al.|[2408.04140v1](http://arxiv.org/abs/2408.04140v1)|null|
|**2024-08-08**|**Enhancing Healthcare through Large Language Models: A Study on Medical Question Answering**|Haoran Yu et.al.|[2408.04138v1](http://arxiv.org/abs/2408.04138v1)|null|
|**2024-08-07**|**Incorporating Spatial Awareness in Data-Driven Gesture Generation for Virtual Agents**|Anna Deichler et.al.|[2408.04127v1](http://arxiv.org/abs/2408.04127v1)|null|
|**2024-08-07**|**Can Rule-Based Insights Enhance LLMs for Radiology Report Classification? Introducing the RadPrompt Methodology**|Panagiotis Fytas et.al.|[2408.04121v1](http://arxiv.org/abs/2408.04121v1)|null|
|**2024-08-07**|**Zero-shot Factual Consistency Evaluation Across Domains**|Raunak Agarwal et.al.|[2408.04114v1](http://arxiv.org/abs/2408.04114v1)|null|
|**2024-08-07**|**Patchview: LLM-Powered Worldbuilding with Generative Dust and Magnet Visualization**|John Joon Young Chung et.al.|[2408.04112v1](http://arxiv.org/abs/2408.04112v1)|null|
|**2024-08-07**|**Hardware-Assisted Virtualization of Neural Processing Units for Cloud Platforms**|Yuqi Xue et.al.|[2408.04104v1](http://arxiv.org/abs/2408.04104v1)|null|
|**2024-08-07**|**ArtVLM: Attribute Recognition Through Vision-Based Prefix Language Modeling**|William Y. Zhu et.al.|[2408.04102v1](http://arxiv.org/abs/2408.04102v1)|null|
|**2024-08-07**|**Tree Attention: Topology-aware Decoding for Long-Context Attention on GPU clusters**|Vasudev Shyam et.al.|[2408.04093v1](http://arxiv.org/abs/2408.04093v1)|null|
|**2024-08-07**|**AEye: A Visualization Tool for Image Datasets**|Florian GrÃ¶tschla et.al.|[2408.04072v1](http://arxiv.org/abs/2408.04072v1)|[link](https://github.com/eth-disco/aeye)|
|**2024-08-07**|**Digital Avatars: Framework Development and Their Evaluation**|Timothy Rupprecht et.al.|[2408.04068v1](http://arxiv.org/abs/2408.04068v1)|null|
|**2024-08-07**|**PowerPM: Foundation Model for Power Systems**|Shihao Tu et.al.|[2408.04057v1](http://arxiv.org/abs/2408.04057v1)|null|
|**2024-08-07**|**Learning Rate-Free Reinforcement Learning: A Case for Model Selection with Non-Stationary Objectives**|Aida Afshar et.al.|[2408.04046v1](http://arxiv.org/abs/2408.04046v1)|null|
|**2024-08-07**|**Human Speech Perception in Noise: Can Large Language Models Paraphrase to Improve It?**|Anupama Chingacham et.al.|[2408.04029v1](http://arxiv.org/abs/2408.04029v1)|[link](https://github.com/uds-lsv/llm_eval_pi-spin)|
|**2024-08-07**|**Multimodal Gender Fairness in Depression Prediction: Insights on Data from the USA & China**|Joseph Cameron et.al.|[2408.04026v1](http://arxiv.org/abs/2408.04026v1)|null|
|**2024-08-07**|**Improving Large Language Model (LLM) fidelity through context-aware grounding: A systematic approach to reliability and veracity**|Wrick Talukdar et.al.|[2408.04023v1](http://arxiv.org/abs/2408.04023v1)|null|
|**2024-08-07**|**Image-to-LaTeX Converter for Mathematical Formulas and Text**|Daniil Gurgurov et.al.|[2408.04015v1](http://arxiv.org/abs/2408.04015v1)|[link](https://github.com/d-gurgurov/im2latex)|
|**2024-08-07**|**SLIM-RAFT: A Novel Fine-Tuning Approach to Improve Cross-Linguistic Performance for Mercosur Common Nomenclature**|VinÃ­cius Di Oliveira et.al.|[2408.03936v1](http://arxiv.org/abs/2408.03936v1)|null|
|**2024-08-07**|**From Words to Worth: Newborn Article Impact Prediction with LLM**|Penghai Zhao et.al.|[2408.03934v1](http://arxiv.org/abs/2408.03934v1)|null|
|**2024-08-07**|**CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**|Xiangyan Liu et.al.|[2408.03910v1](http://arxiv.org/abs/2408.03910v1)|[link](https://github.com/modelscope/modelscope-agent)|
|**2024-08-07**|**Decoding Biases: Automated Methods and LLM Judges for Gender Bias Detection in Language Models**|Shachi H Kumar et.al.|[2408.03907v1](http://arxiv.org/abs/2408.03907v1)|null|
|**2024-08-07**|**Speech-MASSIVE: A Multilingual Speech Dataset for SLU and Beyond**|Beomseok Lee et.al.|[2408.03900v1](http://arxiv.org/abs/2408.03900v1)|[link](https://github.com/hlt-mt/speech-massive)|
|**2024-08-07**|**Simplifying Scholarly Abstracts for Accessible Digital Libraries**|Haining Wang et.al.|[2408.03899v1](http://arxiv.org/abs/2408.03899v1)|null|
|**2024-08-07**|**MORTAR: A Model-based Runtime Action Repair Framework for AI-enabled Cyber-Physical Systems**|Renzhi Wang et.al.|[2408.03892v1](http://arxiv.org/abs/2408.03892v1)|null|
|**2024-08-07**|**Personalized Clinical Note Generation from Doctor-Patient Conversations**|Nathan Brake et.al.|[2408.03874v1](http://arxiv.org/abs/2408.03874v1)|null|
|**2024-08-07**|**Inter-Series Transformer: Attending to Products in Time Series Forecasting**|Rares Cristian et.al.|[2408.03872v1](http://arxiv.org/abs/2408.03872v1)|null|
|**2024-08-07**|**BeeManc at the PLABA Track of TAC-2023: Investigating LLMs and Controllable Attributes for Improving Biomedical Text Readability**|Zihao Li et.al.|[2408.03871v1](http://arxiv.org/abs/2408.03871v1)|[link](https://github.com/hecta-uom/plaba-mu)|
|**2024-08-07**|**Why transformers are obviously good models of language**|Felix Hill et.al.|[2408.03855v1](http://arxiv.org/abs/2408.03855v1)|null|
|**2024-08-07**|**Hate Speech Detection and Classification in Amharic Text with Deep Learning**|Samuel Minale Gashe et.al.|[2408.03849v1](http://arxiv.org/abs/2408.03849v1)|null|
|**2024-08-07**|**MaxMind: A Memory Loop Network to Enhance Software Productivity based on Large Language Models**|Yuchen Dong et.al.|[2408.03841v1](http://arxiv.org/abs/2408.03841v1)|null|
|**2024-08-07**|**WalledEval: A Comprehensive Safety Evaluation Toolkit for Large Language Models**|Prannaya Gupta et.al.|[2408.03837v1](http://arxiv.org/abs/2408.03837v1)|[link](https://github.com/walledai/walledeval)|
|**2024-08-07**|**Target Prompting for Information Extraction with Vision Language Model**|Dipankar Medhi et.al.|[2408.03834v1](http://arxiv.org/abs/2408.03834v1)|null|
|**2024-08-07**|**Automated Code Fix Suggestions for Accessibility Issues in Mobile Apps**|Forough Mehralian et.al.|[2408.03827v1](http://arxiv.org/abs/2408.03827v1)|null|

#### Abstracts
##### **Arctic-TILT. Business Document Understanding at Sub-Billion Scale**
2408.04632v1 by Åukasz Borchmann, MichaÅ Pietruszka, Wojciech JaÅkowski, Dawid Jurkiewicz, Piotr Halama, PaweÅ JÃ³ziak, Åukasz Garncarek, PaweÅ Liskowski, Karolina Szyndler, Andrzej Gretkowski, Julita OÅtusek, Gabriela Nowakowska, Artur ZawÅocki, Åukasz Duhr, PaweÅ Dyda, MichaÅ Turski

The vast portion of workloads employing LLMs involves answering questions
grounded on PDF or scan content. We introduce the Arctic-TILT achieving
accuracy on par with models 1000$\times$ its size on these use cases. It can be
fine-tuned and deployed on a single 24GB GPU, lowering operational costs while
processing Visually Rich Documents with up to 400k tokens. The model
establishes state-of-the-art results on seven diverse Document Understanding
benchmarks, as well as provides reliable confidence scores and quick inference,
which are essential for processing files in large-scale or time-sensitive
enterprise environments.

æè¦ï¼çµå¤§å¤æ¸ä½¿ç¨å¤§åèªè¨æ¨¡åçå·¥ä½è² è¼ï¼é½æ¶ååç­åºæ¼ PDF æææå§å®¹çåé¡ãæåä»ç´¹äº Arctic-TILTï¼å¨éäºç¨ä¾ä¸å¯¦ç¾äºèå¶å¤§å° 1000 åçæ¨¡åç¸ç¶çæºç¢ºåº¦ãå®å¯ä»¥å¨å®å 24GB GPU ä¸é²è¡å¾®èª¿åé¨ç½²ï¼å¨èçå¤é 400k åä»¤ççè¦è¦ºè±å¯æä»¶æéä½éçææ¬ãè©²æ¨¡åå¨ä¸åä¸åçæä»¶çè§£åºæºä¸å»ºç«äºæåé²ççµæï¼ä¸¦æä¾äºå¯é çç½®ä¿¡åº¦åæ¸åå¿«éæ¨çï¼éå°æ¼å¨å¤§åææéææçä¼æ¥­ç°å¢ä¸­èçæä»¶è³ééè¦ã

##### **Puppet-Master: Scaling Interactive Video Generation as a Motion Prior for Part-Level Dynamics**
2408.04631v1 by Ruining Li, Chuanxia Zheng, Christian Rupprecht, Andrea Vedaldi

We present Puppet-Master, an interactive video generative model that can
serve as a motion prior for part-level dynamics. At test time, given a single
image and a sparse set of motion trajectories (i.e., drags), Puppet-Master can
synthesize a video depicting realistic part-level motion faithful to the given
drag interactions. This is achieved by fine-tuning a large-scale pre-trained
video diffusion model, for which we propose a new conditioning architecture to
inject the dragging control effectively. More importantly, we introduce the
all-to-first attention mechanism, a drop-in replacement for the widely adopted
spatial attention modules, which significantly improves generation quality by
addressing the appearance and background issues in existing models. Unlike
other motion-conditioned video generators that are trained on in-the-wild
videos and mostly move an entire object, Puppet-Master is learned from
Objaverse-Animation-HQ, a new dataset of curated part-level motion clips. We
propose a strategy to automatically filter out sub-optimal animations and
augment the synthetic renderings with meaningful motion trajectories.
Puppet-Master generalizes well to real images across various categories and
outperforms existing methods in a zero-shot manner on a real-world benchmark.
See our project page for more results: vgg-puppetmaster.github.io.

æè¦ï¼æåæåº Puppet-Masterï¼ä¸åäºåå¼å½±ççææ¨¡åï¼å¯ç¨ä½é¨åå±¤ç´åæçåä½åé©ãå¨æ¸¬è©¦æï¼çµ¦å®å®ä¸å½±ååä¸çµç¨ççåä½è»è·¡ï¼å³ææ³ï¼ï¼Puppet-Master å¯ä»¥åæå½±çï¼æç¹ªåºç¬¦åçµ¦å®ææ³äºåçé¼çé¨åå±¤ç´åä½ãéæ¯ééå¾®èª¿å¤§åé åè¨ç·´å½±çæ´æ£æ¨¡åä¾å¯¦ç¾çï¼æåçºæ­¤æåºæ°çå¶ç´æ¶æ§ï¼ä»¥æææ³¨å¥ææ³æ§å¶ãæ´éè¦çæ¯ï¼æåå¼å¥å¨å°ä¸æ³¨æåæ©å¶ï¼éæ¯å»£æ³æ¡ç¨çç©ºéæ³¨æåæ¨¡çµçæ¿ä»£æ¹æ¡ï¼ééè§£æ±ºç¾ææ¨¡åä¸­çå¤è§åèæ¯åé¡ï¼é¡¯èæ¹åçæåè³ªãèå¶ä»å¨éå¤å½±çä¸è¨ç·´ä¸ä¸»è¦ç§»åæ´åç©é«çåä½æ¢ä»¶å½±ççæå¨ä¸åï¼Puppet-Master æ¯å¾ Objaverse-Animation-HQï¼ä¸ç¨®ç¶éæ´ççé¨åå±¤ç´åä½çæ®µçæ°è³æéï¼å­¸ç¿çãæåæåºç­ç¥ï¼èªåéæ¿¾ææ¬¡ä½³åç«ï¼ä¸¦ä½¿ç¨ææç¾©çåä½è»è·¡æ´ååææ¸²æãPuppet-Master å¨åç¨®é¡å¥ççå¯¦å½±åä¸­é½è½å¾å¥½å°æ¦æ¬ï¼ä¸¦å¨çå¯¦ä¸ççåºæºä¸ä»¥é¶æ¬¡å­¸ç¿çæ¹å¼åªæ¼ç¾ææ¹æ³ãè«åé±æåçå°æ¡é é¢ä»¥åå¾æ´å¤çµæï¼vgg-puppetmaster.github.ioã

##### **LogogramNLP: Comparing Visual and Textual Representations of Ancient Logographic Writing Systems for NLP**
2408.04628v1 by Danlu Chen, Freda Shi, Aditi Agarwal, Jacobo Myerston, Taylor Berg-Kirkpatrick

Standard natural language processing (NLP) pipelines operate on symbolic
representations of language, which typically consist of sequences of discrete
tokens. However, creating an analogous representation for ancient logographic
writing systems is an extremely labor intensive process that requires expert
knowledge. At present, a large portion of logographic data persists in a purely
visual form due to the absence of transcription -- this issue poses a
bottleneck for researchers seeking to apply NLP toolkits to study ancient
logographic languages: most of the relevant data are images of writing.
  This paper investigates whether direct processing of visual representations
of language offers a potential solution. We introduce LogogramNLP, the first
benchmark enabling NLP analysis of ancient logographic languages, featuring
both transcribed and visual datasets for four writing systems along with
annotations for tasks like classification, translation, and parsing. Our
experiments compare systems that employ recent visual and text encoding
strategies as backbones. The results demonstrate that visual representations
outperform textual representations for some investigated tasks, suggesting that
visual processing pipelines may unlock a large amount of cultural heritage data
of logographic languages for NLP-based analyses.

æè¦ï¼æ¨æºèªç¶èªè¨èç (NLP) ç®¡ç·éä½å¨èªè¨çç¬¦èè¡¨ç¤ºä¸ï¼éå¸¸ç±é¢æ£è¨èåºåçµæãç¶èï¼çºå¤ä»£è¡¨ææå­ç³»çµ±å»ºç«é¡æ¯è¡¨ç¤ºæ³æ¯ä¸åæ¥µåº¦ååçéç¨ï¼éè¦å°å®¶ç¥è­ãç®åï¼ç±æ¼ç¼ºä¹è½éï¼å¤§é¨åè¡¨æè³æä»ä»¥ç´ç²¹è¦è¦ºå½¢å¼å­å¨ââéååé¡å°å°æ±ä½¿ç¨ NLP å·¥å·åç ç©¶å¤ä»£è¡¨ææå­ççç ç©¶äººå¡æ§æç¶é ¸ï¼å¤§é¨åç¸éè³æé½æ¯æå­å½±åã
æ¬ææ¢è¨æ¯å¦ç´æ¥èçèªè¨çè¦è¦ºè¡¨ç¤ºè½æä¾æ½å¨è§£æ±ºæ¹æ¡ãæåä»ç´¹ LogogramNLPï¼éæ¯ç¬¬ä¸åè½å°å¤ä»£è¡¨ææå­é²è¡ NLP åæçåºæºæ¸¬è©¦ï¼æä¾ååæå­ç³»çµ±çè½éåè¦è¦ºè³æéï¼ä»¥ååé¡ãç¿»è­¯ååæç­ä»»åçè¨»è§£ãæåçå¯¦é©æ¯è¼æ¡ç¨è¿æè¦è¦ºåæå­ç·¨ç¢¼ç­ç¥ä½çºä¸»å¹¹çç³»çµ±ãçµæé¡¯ç¤ºï¼å°æ¼ä¸äºç ç©¶ä»»åï¼è¦è¦ºè¡¨ç¤ºçè¡¨ç¾åªæ¼æå­è¡¨ç¤ºï¼éè¡¨ç¤ºè¦è¦ºèçç®¡ç·å¯è½çº NLP åæè§£éå¤§éè¡¨ææå­çæåéºç¢è³æã

##### **Transformer Explainer: Interactive Learning of Text-Generative Models**
2408.04619v1 by Aeree Cho, Grace C. Kim, Alexander Karpekov, Alec Helbling, Zijie J. Wang, Seongmin Lee, Benjamin Hoover, Duen Horng Chau

Transformers have revolutionized machine learning, yet their inner workings
remain opaque to many. We present Transformer Explainer, an interactive
visualization tool designed for non-experts to learn about Transformers through
the GPT-2 model. Our tool helps users understand complex Transformer concepts
by integrating a model overview and enabling smooth transitions across
abstraction levels of mathematical operations and model structures. It runs a
live GPT-2 instance locally in the user's browser, empowering users to
experiment with their own input and observe in real-time how the internal
components and parameters of the Transformer work together to predict the next
tokens. Our tool requires no installation or special hardware, broadening the
public's education access to modern generative AI techniques. Our open-sourced
tool is available at https://poloclub.github.io/transformer-explainer/. A video
demo is available at https://youtu.be/ECR4oAwocjs.

æè¦ï¼Transformer å¾¹åºæ¹è®äºæ©å¨å­¸ç¿ï¼ä½å¶å§é¨éä½å°è¨±å¤äººä¾èªªä»ç¶ä¸éæãæåå±ç¤º Transformer Explainerï¼éæ¯ä¸åäºåå¼è¦è¦ºåå·¥å·ï¼å°çºéå°å®¶è¨­è¨ï¼éé GPT-2 æ¨¡åä¾äºè§£ Transformerãæåçå·¥å·ééæ´åæ¨¡åæ¦è§ä¸¦å¨æ¸å­¸éç®åæ¨¡åçµæ§çæ½è±¡å±¤ç´ä¹éå¯¦ç¾å¹³æ»éæ¸¡ï¼å¹«å©ä½¿ç¨èäºè§£è¤éç Transformer æ¦å¿µãå®å¨ä½¿ç¨èççè¦½å¨ä¸­æ¬å°å·è¡ä¸åå³æç GPT-2 å·è¡åé«ï¼ä½¿ç¨æ¶è½å¤ ä½¿ç¨èªå·±çè¼¸å¥é²è¡å¯¦é©ï¼ä¸¦å³æè§å¯ Transformer çå§é¨çµä»¶ååæ¸å¦ä½ååéä½ä¾é æ¸¬ä¸ä¸åä»£å¹£ãæåçå·¥å·ä¸éè¦å®è£æç¹æ®ç¡¬é«ï¼æ´å¤§äºå¤§ç¾å°ç¾ä»£çæå¼ AI æè¡çæè²ç®¡éãæåçéæºå·¥å·å¯å¨ https://poloclub.github.io/transformer-explainer/ åå¾ãå½±çç¤ºç¯å¯å¨ https://youtu.be/ECR4oAwocjs åå¾ã

##### **Better Alignment with Instruction Back-and-Forth Translation**
2408.04614v1 by Thao Nguyen, Jeffrey Li, Sewoong Oh, Ludwig Schmidt, Jason Weston, Luke Zettlemoyer, Xian Li

We propose a new method, instruction back-and-forth translation, to construct
high-quality synthetic data grounded in world knowledge for aligning large
language models (LLMs). Given documents from a web corpus, we generate and
curate synthetic instructions using the backtranslation approach proposed by Li
et al.(2023a), and rewrite the responses to improve their quality further based
on the initial documents. Fine-tuning with the resulting (backtranslated
instruction, rewritten response) pairs yields higher win rates on AlpacaEval
than using other common instruction datasets such as Humpback, ShareGPT, Open
Orca, Alpaca-GPT4 and Self-instruct. We also demonstrate that rewriting the
responses with an LLM outperforms direct distillation, and the two generated
text distributions exhibit significant distinction in embedding space. Further
analysis shows that our backtranslated instructions are of higher quality than
other sources of synthetic instructions, while our responses are more diverse
and complex than those obtained from distillation. Overall we find that
instruction back-and-forth translation combines the best of both worlds --
making use of the information diversity and quantity found on the web, while
ensuring the quality of the responses which is necessary for effective
alignment.

æè¦ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼å³æä»¤ä¾åç¿»è­¯ï¼ç¨æ¼æ§å»º
åºæ¼ä¸çç¥è­çé«åè³ªåæè³æï¼ä»¥å°é½å¤§å
èªè¨æ¨¡å (LLM)ãçµ¦å®ä¾èªç¶²è·¯èªæåº«çæä»¶ï¼æåçæä¸¦
ä½¿ç¨ Li
et al.(2023a) æåºçåè­¯æ¹æ³æ´çåææä»¤ï¼ä¸¦æ ¹æ
åå§æä»¶é²ä¸æ­¥æ¹å¯«åæä»¥æåå¶åè³ªãä½¿ç¨ç¢ççï¼åè­¯
æä»¤ãæ¹å¯«åæï¼éå°é²è¡å¾®èª¿ï¼å¨ AlpacaEval ä¸ç¢ççç²åç
é«æ¼ä½¿ç¨å¶ä»å¸¸è¦æä»¤è³æéï¼ä¾å¦ HumpbackãShareGPTãOpen
OrcaãAlpaca-GPT4 å Self-instructãæåä¹è­æäºä½¿ç¨ LLM æ¹å¯«
åæçè¡¨ç¾åªæ¼ç´æ¥èåï¼èä¸éå©åçæç
æå­åä½å¨åµå¥ç©ºéä¸­å±ç¾åºé¡¯èçåå¥ãé²ä¸æ­¥çåæé¡¯ç¤ºï¼æåçåè­¯
æä»¤åè³ªé«æ¼å¶ä»åææä»¤ä¾æºï¼èæåçåæåæ¯å¾èåä¸­ç²å¾ç
åææ´çºå¤åä¸è¤éãç¸½é«èè¨ï¼æåç¼ç¾æä»¤ä¾åç¿»è­¯çµåäºå©å¨å¶ç¾çåªé»
ââå©ç¨ç¶²è·¯ä¸çè³è¨å¤åæ§åæ¸éï¼åæ
ç¢ºä¿åæçåè³ªï¼éå°æ¼ææçå°é½æ¯å¿è¦çã

##### **Code-switching in text and speech reveals information-theoretic audience design**
2408.04596v1 by Debasmita Bhattacharya, Marten van Schijndel

In this work, we use language modeling to investigate the factors that
influence code-switching. Code-switching occurs when a speaker alternates
between one language variety (the primary language) and another (the secondary
language), and is widely observed in multilingual contexts. Recent work has
shown that code-switching is often correlated with areas of high information
load in the primary language, but it is unclear whether high primary language
load only makes the secondary language relatively easier to produce at
code-switching points (speaker-driven code-switching), or whether
code-switching is additionally used by speakers to signal the need for greater
attention on the part of listeners (audience-driven code-switching). In this
paper, we use bilingual Chinese-English online forum posts and transcripts of
spontaneous Chinese-English speech to replicate prior findings that high
primary language (Chinese) information load is correlated with switches to the
secondary language (English). We then demonstrate that the information load of
the English productions is even higher than that of meaning equivalent Chinese
alternatives, and these are therefore not easier to produce, providing evidence
of audience-driven influences in code-switching at the level of the
communication channel, not just at the sociolinguistic level, in both writing
and speech.

æè¦ï¼å¨éé å·¥ä½ä¸­ï¼æåä½¿ç¨èªè¨æ¨¡åä¾æ¢è¨å½±é¿ä»£ç¢¼è½æçå ç´ ãä»£ç¢¼è½æç¼çå¨èªªè©±èå¨ä¸åèªè¨è®é«ï¼ä¸»è¦èªè¨ï¼åå¦ä¸åï¼æ¬¡è¦èªè¨ï¼ä¹éäº¤æ¿æï¼ä¸¦ä¸å¨å¤èªè¨ç°å¢ä¸­å»£æ³è§å¯å°ãæè¿çç ç©¶è¡¨æï¼ä»£ç¢¼è½æéå¸¸èä¸»è¦èªè¨ä¸­è³è¨è² è¼é«çååç¸éï¼ä½ç®åå°ä¸æ¸æ¥é«ä¸»è¦èªè¨è² è¼æ¯å¦åä½¿æ¬¡è¦èªè¨å¨ä»£ç¢¼è½æé»æ´å®¹æç¢çï¼èªªè©±èé©åçä»£ç¢¼è½æï¼ï¼ææ¯å¦ä»£ç¢¼è½æé²ä¸æ­¥ç±èªªè©±èç¨æ¼å³éè½ç¾éè¦æ´å¤æ³¨æçéè¦ï¼åç¾é©åçä»£ç¢¼è½æï¼ãå¨æ¬æä¸­ï¼æåä½¿ç¨éèªä¸­è±èªç·ä¸è«å£æç« åèªç¼ä¸­è±èªèªé³çè½éï¼ä»¥è¤è£½ååçç¼ç¾ï¼å³é«ä¸»è¦èªè¨ï¼ä¸­æï¼è³è¨è² è¼èè½æå°æ¬¡è¦èªè¨ï¼è±èªï¼ç¸éãç¶å¾ï¼æåè­æè±èªç¢åºçè³è¨è² è¼çè³é«æ¼æç¾©ç­å¹çä¸­æé¸é ï¼å æ­¤éäºé¸é ä¸¦ä¸å®¹æç¢çï¼æä¾äºå¨ä»£ç¢¼è½æä¸­åç¾é©åå½±é¿çè­æï¼ä¸åå¨ç¤¾æèªè¨å±¤é¢ï¼ä¹å¨å¯«ä½åèªé³ä¸­ï¼å¨æºéç®¡éå±¤é¢ã

##### **Img-Diff: Contrastive Data Synthesis for Multimodal Large Language Models**
2408.04594v1 by Qirui Jiao, Daoyuan Chen, Yilun Huang, Yaliang Li, Ying Shen

High-performance Multimodal Large Language Models (MLLMs) rely heavily on
data quality. This study introduces a novel dataset named Img-Diff, designed to
enhance fine-grained image recognition in MLLMs by leveraging insights from
contrastive learning and image difference captioning. By analyzing object
differences between similar images, we challenge models to identify both
matching and distinct components. We utilize the Stable-Diffusion-XL model and
advanced image editing techniques to create pairs of similar images that
highlight object replacements. Our methodology includes a Difference Area
Generator for object differences identifying, followed by a Difference Captions
Generator for detailed difference descriptions. The result is a relatively
small but high-quality dataset of "object replacement" samples. We use the the
proposed dataset to fine-tune state-of-the-art (SOTA) MLLMs such as MGM-7B,
yielding comprehensive improvements of performance scores over SOTA models that
trained with larger-scale datasets, in numerous image difference and Visual
Question Answering tasks. For instance, our trained models notably surpass the
SOTA models GPT-4V and Gemini on the MMVP benchmark. Besides, we investigate
alternative methods for generating image difference data through "object
removal" and conduct thorough evaluation to confirm the dataset's diversity,
quality, and robustness, presenting several insights on synthesis of such
contrastive dataset. To encourage further research and advance the field of
multimodal data synthesis and enhancement of MLLMs' fundamental capabilities
for image understanding, we release our codes and dataset at
https://github.com/modelscope/data-juicer/tree/ImgDiff.

æè¦ï¼é«æ§è½å¤æ¨¡æå¤§åè¯­è¨æ¨¡å (MLLM) ä¸¥éä¾èµæ°æ®è´¨éãæ¬ç ç©¶å¼å¥äºä¸ä¸ªåä¸º Img-Diff çæ°æ°æ®éï¼æ¨å¨éè¿å©ç¨å¯¹æ¯å­¦ä¹ åå¾åå·®å¼æè¿°çè§è§£æ¥å¢å¼º MLLM ä¸­çç»ç²åº¦å¾åè¯å«ãéè¿åæç¸ä¼¼å¾åä¹é´çå¯¹è±¡å·®å¼ï¼æä»¬æææ¨¡åè¯å«å¹éåä¸åçç»ä»¶ãæä»¬å©ç¨ Stable-Diffusion-XL æ¨¡åååè¿çå¾åç¼è¾ææ¯åå»ºäºä¸å¯¹ç¸ä¼¼å¾åï¼çªåºæ¾ç¤ºå¯¹è±¡æ¿æ¢ãæä»¬çæ¹æ³åæ¬ç¨äºè¯å«å¯¹è±¡å·®å¼çå·®å¼åºåçæå¨ï¼ç¶åæ¯ç¨äºè¯¦ç»å·®å¼æè¿°çå·®å¼æè¿°çæå¨ãç»ææ¯ä¸ä¸ªç¸å¯¹è¾å°ä½é«è´¨éçâå¯¹è±¡æ¿æ¢âæ ·æ¬æ°æ®éãæä»¬ä½¿ç¨ææåºçæ°æ®éå¯¹æåè¿ (SOTA) MLLMï¼ä¾å¦ MGM-7Bï¼è¿è¡å¾®è°ï¼å¨ä¼å¤å¾åå·®å¼åè§è§é®ç­ä»»å¡ä¸­ï¼ä¸ä½¿ç¨æ´å¤§è§æ¨¡æ°æ®éè®­ç»ç SOTA æ¨¡åç¸æ¯ï¼æ§è½å¾åå¾å°äºå¨é¢æé«ãä¾å¦ï¼æä»¬è®­ç»çæ¨¡åå¨ MMVP åºåä¸ææ¾è¶è¶äº SOTA æ¨¡å GPT-4V å Geminiãæ­¤å¤ï¼æä»¬ç ç©¶äºéè¿âå¯¹è±¡ç§»é¤âçæå¾åå·®å¼æ°æ®çæ¿ä»£æ¹æ³ï¼å¹¶è¿è¡äºå½»åºçè¯ä¼°ä»¥ç¡®è®¤æ°æ®éçå¤æ ·æ§ãè´¨éåé²æ£æ§ï¼æåºäºå¯¹è¿ç§å¯¹æ¯æ°æ®éåæçè¥å¹²è§è§£ãä¸ºäºé¼å±è¿ä¸æ­¥çç ç©¶åæ¨è¿å¤æ¨¡ææ°æ®åæåå¢å¼º MLLM å¯¹å¾åçè§£çåºæ¬è½åçé¢åï¼æä»¬å¨ https://github.com/modelscope/data-juicer/tree/ImgDiff ä¸åå¸äºæä»¬çä»£ç åæ°æ®éã

##### **HiLo: A Learning Framework for Generalized Category Discovery Robust to Domain Shifts**
2408.04591v1 by Hongjun Wang, Sagar Vaze, Kai Han

Generalized Category Discovery (GCD) is a challenging task in which, given a
partially labelled dataset, models must categorize all unlabelled instances,
regardless of whether they come from labelled categories or from new ones. In
this paper, we challenge a remaining assumption in this task: that all images
share the same domain. Specifically, we introduce a new task and method to
handle GCD when the unlabelled data also contains images from different domains
to the labelled set. Our proposed `HiLo' networks extract High-level semantic
and Low-level domain features, before minimizing the mutual information between
the representations. Our intuition is that the clusterings based on domain
information and semantic information should be independent. We further extend
our method with a specialized domain augmentation tailored for the GCD task, as
well as a curriculum learning approach. Finally, we construct a benchmark from
corrupted fine-grained datasets as well as a large-scale evaluation on
DomainNet with real-world domain shifts, reimplementing a number of GCD
baselines in this setting. We demonstrate that HiLo outperforms SoTA category
discovery models by a large margin on all evaluations.

æè¦ï¼å»£ç¾©é¡å¥ç¼ç¾ (GCD) æ¯ä¸é å·æææ°æ§çä»»åï¼å¶ä¸­ï¼å¨çµ¦å®é¨åæ¨ç±¤è³æéçææ³ä¸ï¼æ¨¡åå¿é å°æææªæ¨ç±¤å¯¦ä¾é²è¡åé¡ï¼ç¡è«å®åä¾èªæ¨ç±¤é¡å¥éæ¯æ°é¡å¥ãå¨æ¬æä¸­ï¼æåææ°äºéé ä»»åä¸­çä¸åå©é¤åè¨­ï¼ææååå±äº«ç¸åçç¶²åãå·é«ä¾èªªï¼æåå¼å¥äºä¸åæ°ä»»ååæ¹æ³ä¾èç GCDï¼ç¶æªæ¨ç±¤è³æä¹åå«ä¾èªèæ¨ç±¤éä¸åç¶²åçååæãæåæåºç `HiLo` ç¶²è·¯æåé«ç´èªç¾©åä½ç´ç¶²åç¹å¾µï¼ç¶å¾æå°åè¡¨ç¤ºä¹éçäºä¿¡æ¯ãæåçç´è¦ºæ¯åºæ¼ç¶²åä¿¡æ¯åèªç¾©ä¿¡æ¯çèé¡æè©²æ¯ç¨ç«çãæåé²ä¸æ­¥æ´å±äºæåçæ¹æ³ï¼ä½¿ç¨å°ééå° GCD ä»»åéèº«å®å¶çç¶²åæ´åï¼ä»¥åèª²ç¨å­¸ç¿æ¹æ³ãæå¾ï¼æåå¾æå£çç´°ç²åº¦è³æéæ§å»ºäºä¸ååºæºï¼ä»¥åå¨å·æçå¯¦ä¸çç¶²åè½ç§»ç DomainNet ä¸é²è¡å¤§è¦æ¨¡è©ä¼°ï¼å¨æ­¤è¨­ç½®ä¸­éæ°å¯¦ç¾äºè¨±å¤ GCD åºç·ãæåè­æ HiLo å¨ææè©ä¼°ä¸­é½æ¯ SoTA é¡å¥ç¼ç¾æ¨¡åè¡¨ç¾åºè²ã

##### **Towards Resilient and Efficient LLMs: A Comparative Study of Efficiency, Performance, and Adversarial Robustness**
2408.04585v1 by Xiaojing Fan, Chunliang Tao

With the increasing demand for practical applications of Large Language
Models (LLMs), many attention-efficient models have been developed to balance
performance and computational cost. However, the adversarial robustness of
these models remains under-explored. In this work, we design a framework to
investigate the trade-off between efficiency, performance, and adversarial
robustness of LLMs by comparing three prominent models with varying levels of
complexity and efficiency -- Transformer++, Gated Linear Attention (GLA)
Transformer, and MatMul-Free LM -- utilizing the GLUE and AdvGLUE datasets. The
AdvGLUE dataset extends the GLUE dataset with adversarial samples designed to
challenge model robustness. Our results show that while the GLA Transformer and
MatMul-Free LM achieve slightly lower accuracy on GLUE tasks, they demonstrate
higher efficiency and either superior or comparative robustness on AdvGLUE
tasks compared to Transformer++ across different attack levels. These findings
highlight the potential of simplified architectures to achieve a compelling
balance between efficiency, performance, and adversarial robustness, offering
valuable insights for applications where resource constraints and resilience to
adversarial attacks are critical.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) å¯¦ç¨æç¨éæ±çå¢å ï¼è¨±å¤æ³¨éæççæ¨¡åå·²è¢«éç¼åºä¾ï¼ä»¥å¹³è¡¡æè½åéç®ææ¬ãç¶èï¼éäºæ¨¡åçå°ææ§ç©©å¥æ§ä»æªåå°ååæ¢è¨ãå¨éé ç ç©¶ä¸­ï¼æåè¨­è¨äºä¸åæ¶æ§ä¾æ¢è¨ LLM çæçãæè½åå°ææ§ç©©å¥æ§ä¹éçåæ¨ï¼æ¹æ³æ¯æ¯è¼ä¸åå·æä¸åç¨åº¦è¤éæ§åæççèåæ¨¡åââTransformer++ãéæ§ç·æ§æ³¨æå (GLA) Transformer åç¡ MatMul LMââä¸¦å©ç¨ GLUE å AdvGLUE è³æéãAdvGLUE è³æéæ´åäº GLUE è³æéï¼å¶ä¸­åå«æ¨å¨ææ°æ¨¡åç©©å¥æ§çå°ææ§æ¨£æ¬ãæåççµæé¡¯ç¤ºï¼éç¶ GLA Transformer åç¡ MatMul LM å¨ GLUE ä»»åä¸çæºç¢ºåº¦ç¥ä½ï¼ä½å®åå±ç¾åºæ´é«çæçï¼ä¸¦ä¸å¨ä¸åæ»æå±¤ç´ä¸ï¼å¨ AdvGLUE ä»»åä¸å±ç¾åºåªæ¼æç¸ç¶çç©©å¥æ§ï¼åªæ¼ Transformer++ãéäºç¼ç¾çªé¡¯äºç°¡åæ¶æ§å¨æçãæè½åå°ææ§ç©©å¥æ§ä¹éåå¾ä»¤äººä¿¡æçå¹³è¡¡çæ½åï¼çºè³æºåéä¸å°ææ»æå¾©ååè³ééè¦çæç¨ç¨å¼æä¾äºå¯¶è²´çè¦è§£ã

##### **SCENE: Evaluating Explainable AI Techniques Using Soft Counterfactuals**
2408.04575v1 by Haoran Zheng, Utku Pamuksuz

Explainable Artificial Intelligence (XAI) is essential for enhancing the
transparency and accountability of AI models, especially in natural language
processing (NLP) tasks. This paper introduces SCENE (Soft Counterfactual
Evaluation for Natural language Explainability), a novel evaluation method that
leverages large language models (LLMs) to generate Soft Counterfactual
explanations in a zero-shot manner. By focusing on token-based substitutions,
SCENE creates contextually appropriate and seman-tically meaningful Soft
Counterfactuals without extensive fine-tuning. SCENE adopts Validitysoft and
Csoft metrics to evaluate the effectiveness of model-agnostic XAI methods in
text classification tasks. Applied to CNN, RNN, and BERT architectures, SCENE
provides valuable insights into the strengths and limitations of various XAI
techniques.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°æ¼æåäººå·¥æºæ§æ¨¡åçéæåº¦èå¯åè²¬æ§è³ééè¦ï¼ç¹å¥æ¯å¨èªç¶èªè¨èç (NLP) ä»»åä¸­ãæ¬æä»ç´¹ SCENEï¼èªç¶èªè¨å¯è§£éæ§çè»åäºå¯¦è©ä¼°ï¼ï¼éæ¯ä¸ç¨®æ°ç©çè©ä¼°æ¹æ³ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä»¥é¶æ¬¡å­¸ç¿çæ¹å¼ç¢çè»åäºå¯¦è§£éãSCENE å°æ³¨æ¼åºæ¼ä»£ç¢¼çæ¿æï¼å¨ä¸é²è¡å»£æ³å¾®èª¿çææ³ä¸ï¼å»ºç«ç¬¦åèçµ¡ä¸å·æèªç¾©æç¾©çè»åäºå¯¦ãSCENE æ¡ç¨ Validitysoft å Csoft ææ¨ä¾è©ä¼°æ¨¡åä¸å¯ç¥ XAI æ¹æ³å¨æå­åé¡ä»»åä¸­çæææ§ãSCENE æç¨æ¼ CNNãRNN å BERT æ¶æ§ï¼æä¾äºå¯¶è²´çè¦è§£ï¼äºè§£åç¨® XAI æè¡çåªé»åéå¶ã

##### **Learning Fine-Grained Grounded Citations for Attributed Large Language Models**
2408.04568v1 by Lei Huang, Xiaocheng Feng, Weitao Ma, Yuxuan Gu, Weihong Zhong, Xiachong Feng, Weijiang Yu, Weihua Peng, Duyu Tang, Dandan Tu, Bing Qin

Despite the impressive performance on information-seeking tasks, large
language models (LLMs) still struggle with hallucinations. Attributed LLMs,
which augment generated text with in-line citations, have shown potential in
mitigating hallucinations and improving verifiability. However, current
approaches suffer from suboptimal citation quality due to their reliance on
in-context learning. Furthermore, the practice of citing only coarse document
identifiers makes it challenging for users to perform fine-grained
verification. In this work, we introduce FRONT, a training framework designed
to teach LLMs to generate Fine-Grained Grounded Citations. By grounding model
outputs in fine-grained supporting quotes, these quotes guide the generation of
grounded and consistent responses, not only improving citation quality but also
facilitating fine-grained verification. Experiments on the ALCE benchmark
demonstrate the efficacy of FRONT in generating superior grounded responses and
highly supportive citations. With LLaMA-2-7B, the framework significantly
outperforms all the baselines, achieving an average of 14.21% improvement in
citation quality across all datasets, even surpassing ChatGPT.

æè¦ï¼åç®¡å¨è³è¨æå°ä»»åä¸­è¡¨ç¾åºè²ï¼å¤§åèªè¨æ¨¡å (LLM) ä»é£ä»¥åæå¹»è¦ºåé¡ãå·æ­¸å åè½ç LLM å¯å¨ç¢ççæå­ä¸­å å¥å§æå¼æï¼å·²å±ç¾åºæ¸è¼å¹»è¦ºä¸¦æåå¯é©è­æ§çæ½åãç¶èï¼ç¾è¡çåæ³ä»°è³´æ¼æå¢å­¸ç¿ï¼å æ­¤å¼æåè³ªä¸ä½³ãæ­¤å¤ï¼åå¼è¿°ç²ç¥çæä»¶è­å¥ç¢¼ï¼ä½¿ç¨æ¶é£ä»¥é²è¡ç´°å¾®çé©è­ãå¨æ¬æä¸­ï¼æåä»ç´¹ FRONTï¼ä¸ç¨®è¨ç·´æ¶æ§ï¼æ¨å¨æå° LLM ç¢çç´°å¾®ç Ð¾Ð±Ð¾ÑÐ½Ð¾å¼æãééå°æ¨¡åè¼¸åºå»ºç«å¨ç´°å¾®çæ¯æ´å¼æä¸­ï¼éäºå¼æå¯å¼å°ç¢ç Ð¾Ð±Ð¾ÑÐ½Ð¾ä¸ä¸è´çåæï¼ä¸åæåå¼æåè³ªï¼éè½ä¿é²ç´°å¾®çé©è­ãå¨ ALCE åºæºä¸çå¯¦é©è­æäº FRONT å¨ç¢çåªç°ç Ð¾Ð±Ð¾ÑÐ½Ð¾åæåé«åº¦æ¯ææ§å¼ææ¹é¢çæè½ãéé LLaMA-2-7Bï¼æ­¤æ¶æ§å¤§å¹åªæ¼ææåºç·ï¼å¨ææè³æéä¸­çå¼æåè³ªå¹³åæå 14.21%ï¼çè³è¶è¶äº ChatGPTã

##### **Conversational Prompt Engineering**
2408.04560v1 by Liat Ein-Dor, Orith Toledo-Ronen, Artem Spector, Shai Gretz, Lena Dankin, Alon Halfon, Yoav Katz, Noam Slonim

Prompts are how humans communicate with LLMs. Informative prompts are
essential for guiding LLMs to produce the desired output. However, prompt
engineering is often tedious and time-consuming, requiring significant
expertise, limiting its widespread use. We propose Conversational Prompt
Engineering (CPE), a user-friendly tool that helps users create personalized
prompts for their specific tasks. CPE uses a chat model to briefly interact
with users, helping them articulate their output preferences and integrating
these into the prompt. The process includes two main stages: first, the model
uses user-provided unlabeled data to generate data-driven questions and utilize
user responses to shape the initial instruction. Then, the model shares the
outputs generated by the instruction and uses user feedback to further refine
the instruction and the outputs. The final result is a few-shot prompt, where
the outputs approved by the user serve as few-shot examples. A user study on
summarization tasks demonstrates the value of CPE in creating personalized,
high-performing prompts. The results suggest that the zero-shot prompt obtained
is comparable to its - much longer - few-shot counterpart, indicating
significant savings in scenarios involving repetitive tasks with large text
volumes.

æè¦ï¼æç¤ºæ¯äººé¡è LLM æºéçæ¹å¼ãæä¾è³è¨çæç¤ºå°æ¼å¼å° LLM ç¢çæéçè¼¸åºè³ééè¦ãç¶èï¼æç¤ºå·¥ç¨éå¸¸æ¢ä¹å³åèæï¼éè¦å¤§éçå°æ¥­ç¥è­ï¼éå¶äºå¶å»£æ³ä½¿ç¨ãæåæåºå°è©±å¼æç¤ºå·¥ç¨ (CPE)ï¼éæ¯ä¸åä½¿ç¨èååçå·¥å·ï¼å¯åå©ä½¿ç¨èçºå¶ç¹å®ä»»åå»ºç«åäººåçæç¤ºãCPE ä½¿ç¨èå¤©æ¨¡åèä½¿ç¨èé²è¡ç°¡ç­çäºåï¼åå©ä»åè¡¨éå¶è¼¸åºåå¥½ä¸¦å°éäºåå¥½æ´åå°æç¤ºä¸­ãéåéç¨åå«å©åä¸»è¦éæ®µï¼é¦åï¼æ¨¡åä½¿ç¨ä½¿ç¨èæä¾çæªæ¨è¨è³æä¾ç¢çè³æé©åçåé¡ï¼ä¸¦å©ç¨ä½¿ç¨èçåæä¾å¡é åå§æä»¤ãç¶å¾ï¼æ¨¡ååäº«ç±æä»¤ç¢ççè¼¸åºï¼ä¸¦ä½¿ç¨ä½¿ç¨èçåé¥é²ä¸æ­¥æ¹åæä»¤åè¼¸åºãæçµçµææ¯ä¸åå°æ¬¡æç¤ºï¼å¶ä¸­ä½¿ç¨èæ ¸åçè¼¸åºä½çºå°æ¬¡ç¯ä¾ãéå°æè¦ä»»åé²è¡çä½¿ç¨èç ç©¶è­æäº CPE å¨å»ºç«åäººåãé«å·è¡æè½æç¤ºæ¹é¢çå¹å¼ãçµæé¡¯ç¤ºï¼ç²å¾çé¶æ¬¡æç¤ºèå¶é·å¾å¤çå°æ¬¡å°ææç¤ºç¸ç¶ï¼éè¡¨ç¤ºå¨æ¶åå¤§éæå­å§å®¹çéè¤æ§ä»»åä¸­å¯ä»¥å¤§å¹ç¯çã

##### **Bias-Aware Low-Rank Adaptation: Mitigating Catastrophic Inheritance of Large Language Models**
2408.04556v1 by Yupeng Chang, Yi Chang, Yuan Wu

Large language models (LLMs) have exhibited remarkable proficiency across a
diverse array of natural language processing (NLP) tasks. However, adapting
LLMs to downstream applications typically necessitates computationally
intensive and memory-demanding fine-tuning procedures. To mitigate these
burdens, parameter-efficient fine-tuning (PEFT) techniques have emerged as a
promising approach to tailor LLMs with minimal computational overhead. While
PEFT methods offer substantial advantages, they do not fully address the
pervasive issue of bias propagation from pre-training data. In this work, we
introduce Bias-Aware Low-Rank Adaptation (BA-LoRA), a novel PEFT method
designed to counteract bias inheritance. BA-LoRA incorporates three distinct
regularization terms: (1) consistency regularizer, (2) diversity regularizer,
and (3) singular vector decomposition regularizer. These regularizers
collectively aim to improve the generative models' consistency, diversity, and
generalization capabilities during the fine-tuning process. Through extensive
experiments on a variety of natural language understanding (NLU) and natural
language generation (NLG) tasks, employing prominent LLMs such as LLaMA,
Mistral, and Gemma, we demonstrate that BA-LoRA surpasses the performance of
LoRA and its state-of-the-art variants. Moreover, our method effectively
mitigates the deleterious effects of pre-training bias, leading to more
reliable and robust model outputs. The code is available at
https://github.com/cyp-jlu-ai/BA-LoRA.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨®èªç¶èªè¨èç (NLP) ä»»åä¸­å±ç¾åºåè¶çè½åãç¶èï¼è¦å° LLM èª¿æ´å°ä¸æ¸¸æç¨ç¨å¼éå¸¸éè¦è¨ç®å¯éä¸éè¦å¤§éè¨æ¶é«çå¾®èª¿ç¨åºãçºäºæ¸è¼éäºè² æï¼åæ¸ææå¾®èª¿ (PEFT) æè¡å·²æçºä¸ç¨®æåéçæ¹æ³ï¼å¯éå° LLM é²è¡å®¢è£½åï¼ä¸è¨ç®è² ææå°ãåç®¡ PEFT æ¹æ³å·æé¡¯èçåªå¢ï¼ä½å®åä¸¦æªå®å¨è§£æ±ºé è¨ç·´è³æä¸­åå·®å³æ­çæ®éåé¡ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºå·ååå·®æç¥è½åçä½ç§©é©æ (BA-LoRA)ï¼éæ¯ä¸ç¨®æ°ç©ç PEFT æ¹æ³ï¼æ¨å¨å°æåå·®éºå³ãBA-LoRA çµåäºä¸åä¸åçæ­£ååé ç®ï¼(1) ä¸è´æ§æ­£ååå¨ã(2) å¤æ¨£æ§æ­£ååå¨ï¼ä»¥å (3) å¥ç°å¼åè§£æ­£ååå¨ãéäºæ­£ååå¨å±åæ¨å¨æ¹åçææ¨¡åå¨å¾®èª¿éç¨ä¸­çä¸è´æ§ãå¤æ¨£æ§åæ³åè½åãééå¨åç¨®èªç¶èªè¨çè§£ (NLU) åèªç¶èªè¨çæ (NLG) ä»»åä¸é²è¡å»£æ³çå¯¦é©ï¼æ¡ç¨ LLaMAãMistral å Gemma ç­èåç LLMï¼æåè­æäº BA-LoRA è¶è¶äº LoRA åå¶æåé²çè®é«çæè½ãæ­¤å¤ï¼æåçæ¨¡åæææ¸è¼äºé è¨ç·´åå·®çæå®³å½±é¿ï¼é²èç¢çæ´å¯é ä¸ç©©å¥çæ¨¡åè¼¸åºãç¨å¼ç¢¼å¯å¨ https://github.com/cyp-jlu-ai/BA-LoRA åå¾ã

##### **MolyÃ©: A Corpus-based Approach to Language Contact in Colonial France**
2408.04554v1 by Rasul Dent, Juliette JanÃ¨s, Thibault ClÃ©rice, Pedro Ortiz Suarez, BenoÃ®t Sagot

Whether or not several Creole languages which developed during the early
modern period can be considered genetic descendants of European languages has
been the subject of intense debate. This is in large part due to the absence of
evidence of intermediate forms. This work introduces a new open corpus, the
Moly\'e corpus, which combines stereotypical representations of three kinds of
language variation in Europe with early attestations of French-based Creole
languages across a period of 400 years. It is intended to facilitate future
research on the continuity between contact situations in Europe and Creolophone
(former) colonies.

æè¦ï¼æ©æç¾ä»£ææç¼å±åºçå¹¾ç¨®åéå¥§ç¾èªæ¯å¦å¯ä»¥è¦çºæ­æ´²èªè¨çéºå³å¾è£ï¼ä¸ç´æ¯ç­è«æ¿ççè­°é¡ãéå¨å¾å¤§ç¨åº¦ä¸æ¯å çºç¼ºä¹ä¸­éå½¢å¼çè­æãéé ç ç©¶å¼å¥äºæ°çéæ¾èªæåº«ï¼å³ Moly\'e èªæåº«ï¼çµåäºæ­æ´²ä¸ç¨®èªè¨è®é«çå»æ¿å°è±¡ï¼ä»¥å 400 å¹´ä¾ä»¥æ³èªçºåºç¤çåéå¥§ç¾èªçæ©æè­æãå¶ç®çæ¯ä¿é²æªä¾å°æ­æ´²æ¥è§¸çæ³èåéå¥§ç¾èªï¼åï¼æ®æ°å°ä¹éçé£çºæ§çç ç©¶ã

##### **MemeMind at ArAIEval Shared Task: Spotting Persuasive Spans in Arabic Text with Persuasion Techniques Identification**
2408.04540v1 by Md Rafiul Biswas, Zubair Shah, Wajdi Zaghouani

This paper focuses on detecting propagandistic spans and persuasion
techniques in Arabic text from tweets and news paragraphs. Each entry in the
dataset contains a text sample and corresponding labels that indicate the start
and end positions of propaganda techniques within the text. Tokens falling
within a labeled span were assigned "B" (Begin) or "I" (Inside), "O",
corresponding to the specific propaganda technique. Using attention masks, we
created uniform lengths for each span and assigned BIO tags to each token based
on the provided labels. Then, we used AraBERT-base pre-trained model for Arabic
text tokenization and embeddings with a token classification layer to identify
propaganda techniques. Our training process involves a two-phase fine-tuning
approach. First, we train only the classification layer for a few epochs,
followed by full model fine-tuning, updating all parameters. This methodology
allows the model to adapt to the specific characteristics of the propaganda
detection task while leveraging the knowledge captured by the pre-trained
AraBERT model. Our approach achieved an F1 score of 0.2774, securing the 3rd
position in the leaderboard of Task 1.

æè¦ï¼æ¬æéé»å¨æ¼åµæ¸¬æ¨æåæ°èæ®µè½ä¸­çé¿æä¼¯èªå®£å³ç¯ååèªªææå·§ãè³æéä¸­æ¯åæ¢ç®åå«ä¸åæå­ç¯æ¬åå°ææ¨ç±¤ï¼æ¨ç±¤ææåºæå­ä¸­å®£å³æå·§çéå§åçµæä½ç½®ãè½å¨æ¨ç±¤ç¯åå§çæ¨è¨æè¢«æå®çºãBãï¼éé ­ï¼æãIãï¼ä¸­éï¼ããOãï¼å°æå°ç¹å®çå®£å³æå·§ãæåä½¿ç¨æ³¨æåé®ç½©ï¼çºæ¯åç¯åå»ºç«çµ±ä¸é·åº¦ï¼ä¸¦æ ¹ææä¾çæ¨ç±¤çºæ¯åæ¨è¨æå® BIO æ¨ç±¤ãç¶å¾ï¼æåä½¿ç¨ AraBERT-base é è¨ç·´æ¨¡åé²è¡é¿æä¼¯èªæå­æ¨è¨ååå§åµï¼ä¸¦ä½¿ç¨æ¨è¨åé¡å±¤ä¾è­å¥å®£å³æå·§ãæåçè¨ç·´éç¨åå«ä¸åå©éæ®µå¾®èª¿æ¹æ³ãé¦åï¼æååªè¨ç·´åé¡å±¤å¹¾åææï¼æ¥èé²è¡å®æ´æ¨¡åå¾®èª¿ï¼æ´æ°ææåæ¸ãéç¨®æ¹æ³è®æ¨¡åè½å¤ é©æå®£å³åµæ¸¬ä»»åçç¹å®ç¹å¾µï¼åæéç¨é è¨ç·´ AraBERT æ¨¡åæ·åçç¥è­ãæåçåæ³éå° 0.2774 ç F1 åæ¸ï¼å¨ä»»å 1 çæè¡æ¦ä¸­åå¾ç¬¬ 3 åã

##### **Compromesso! Italian Many-Shot Jailbreaks Undermine the Safety of Large Language Models**
2408.04522v1 by Fabio Pernisi, Dirk Hovy, Paul RÃ¶ttger

As diverse linguistic communities and users adopt large language models
(LLMs), assessing their safety across languages becomes critical. Despite
ongoing efforts to make LLMs safe, they can still be made to behave unsafely
with jailbreaking, a technique in which models are prompted to act outside
their operational guidelines. Research on LLM safety and jailbreaking, however,
has so far mostly focused on English, limiting our understanding of LLM safety
in other languages. We contribute towards closing this gap by investigating the
effectiveness of many-shot jailbreaking, where models are prompted with unsafe
demonstrations to induce unsafe behaviour, in Italian. To enable our analysis,
we create a new dataset of unsafe Italian question-answer pairs. With this
dataset, we identify clear safety vulnerabilities in four families of
open-weight LLMs. We find that the models exhibit unsafe behaviors even when
prompted with few unsafe demonstrations, and -- more alarmingly -- that this
tendency rapidly escalates with more demonstrations.

æè¦ï¼é¨èå¤åçèªè¨ç¤¾ç¾¤åä½¿ç¨èæ¡ç¨å¤§åèªè¨æ¨¡å (LLM)ï¼è©ä¼°å¶è·¨èªè¨å®å¨æ§è®å¾è³ééè¦ãåç®¡æçºåªåè® LLM å®å¨ï¼ä½ä»å¯ééè¶çæè¡è®å®åè¡¨ç¾å¾ä¸¦ä¸å®å¨ï¼éæ¯ä¸ç¨®æç¤ºæ¨¡åå¨éä½æºåä¹å¤æ¡åè¡åçæè¡ãç¶èï¼éå° LLM å®å¨æ§åè¶ççç ç©¶è¿ä»ä¸»è¦éä¸­å¨è±æï¼ééå¶äºæåå°å¶ä»èªè¨ä¸­ LLM å®å¨æ§çäºè§£ãæåééèª¿æ¥å¤ç¼è¶ççæææ§ä¾ç¸®å°éåå·®è·ï¼å¶ä¸­æç¤ºæ¨¡åééä¸å®å¨çç¤ºç¯ä¾èªç¼ä¸å®å¨çè¡çºï¼ä»¥ç¾©å¤§å©æé²è¡ãçºäºé²è¡åæï¼æåå»ºç«äºä¸åæ°çä¸å®å¨ç¾©å¤§å©æåç­éå°è³æéãéééåè³æéï¼æåå¨ååéæ¾æ¬é LLM å®¶æä¸­æ¾åºæç¢ºçå®å¨æ¼æ´ãæåç¼ç¾ï¼å³ä½¿æç¤ºçç¤ºç¯ä¸å¤ï¼éäºæ¨¡åä¹æè¡¨ç¾åºä¸å®å¨çè¡çºï¼èä¸æ´ä»¤äººææçæ¯ï¼éç¨®è¶¨å¢æé¨èç¤ºç¯çå¢å èè¿éåé«ã

##### **Articulatory Configurations across Genders and Periods in French Radio and TV archives**
2408.04519v1 by Benjamin Elie, David Doukhan, RÃ©mi Uro, Lucas Ondel-Yang, Albert Rilliard, Simon Devauchelle

This paper studies changes in articulatory configurations across genders and
periods using an inversion from acoustic to articulatory parameters. From a
diachronic corpus based on French media archives spanning 60 years from 1955 to
2015, automatic transcription and forced alignment allowed extracting the
central frame of each vowel. More than one million frames were obtained from
over a thousand speakers across gender and age categories. Their formants were
used from these vocalic frames to fit the parameters of Maeda's articulatory
model. Evaluations of the quality of these processes are provided. We focus
here on two parameters of Maeda's model linked to total vocal tract length: the
relative position of the larynx (higher for females) and the lips protrusion
(more protruded for males). Implications for voice quality across genders are
discussed. The effect across periods seems gender independent; thus, the
assertion that females lowered their pitch with time is not supported.

æè¦ï¼æ¬æä½¿ç¨å¾è²å­¸å°èªé³åæ¸çåæ¼ç ç©¶äºè·¨æ§å¥åææçèªé³éç½®è®åãå¾ä¸ååºæ¼æ³èªåªé«æªæ¡çæ­·æèªæåº«ï¼è·¨è¶ 1955 å¹´è³ 2015 å¹´ç 60 å¹´ï¼èªåè½éåå¼·å¶å°é½åè¨±æåæ¯ååé³çä¸­å¿å¹ãå¾è·¨æ§å¥åå¹´é½¡é¡å¥ç 1000 å¤åèªªè©±èä¸­ç²å¾äºè¶éä¸ç¾è¬åå¹ãå¾éäºåé³å¹ä¸­ä½¿ç¨å®åçå±æ¯å³°ä¾æ¬å Maeda èªé³æ¨¡åçåæ¸ãæä¾äºéäºéç¨è³ªéçè©ä¼°ãæåéè£¡éé»éæ³¨èç¸½è²éé·åº¦ç¸éç Maeda æ¨¡åçå©ååæ¸ï¼åé ­çç¸å°ä½ç½®ï¼å¥³æ§è¼é«ï¼åå´åçªåºï¼ç·æ§è¼çªåºï¼ãè¨è«äºè·¨æ§å¥çè²é³åè³ªçå½±é¿ãè·¨ææçå½±é¿ä¼¼ä¹èæ§å¥ç¡éï¼å æ­¤ï¼å¥³æ§é¨èæééä½é³é«çèªªæ³å¾ä¸å°æ¯æã

##### **Towards Synergistic Deep Learning Models for Volumetric Cirrhotic Liver Segmentation in MRIs**
2408.04491v1 by Vandan Gorade, Onkar Susladkar, Gorkem Durak, Elif Keles, Ertugrul Aktas, Timurhan Cebeci, Alpay Medetalibeyoglu, Daniela Ladner, Debesh Jha, Ulas Bagci

Liver cirrhosis, a leading cause of global mortality, requires precise
segmentation of ROIs for effective disease monitoring and treatment planning.
Existing segmentation models often fail to capture complex feature interactions
and generalize across diverse datasets. To address these limitations, we
propose a novel synergistic theory that leverages complementary latent spaces
for enhanced feature interaction modeling. Our proposed architecture,
nnSynergyNet3D integrates continuous and discrete latent spaces for 3D volumes
and features auto-configured training. This approach captures both fine-grained
and coarse features, enabling effective modeling of intricate feature
interactions. We empirically validated nnSynergyNet3D on a private dataset of
628 high-resolution T1 abdominal MRI scans from 339 patients. Our model
outperformed the baseline nnUNet3D by approximately 2%. Additionally, zero-shot
testing on healthy liver CT scans from the public LiTS dataset demonstrated
superior cross-modal generalization capabilities. These results highlight the
potential of synergistic latent space models to improve segmentation accuracy
and robustness, thereby enhancing clinical workflows by ensuring consistency
across CT and MRI modalities.

æè¦ï¼èç¡¬åæ¯å¨çæ­»äº¡çä¸»è¦åå ï¼éè¦å¯¹ ROI è¿è¡ç²¾ç¡®åå²ï¼ä»¥è¿è¡ææçç¾ççæµåæ²»çè®¡åãç°æçåå²æ¨¡åéå¸¸æ æ³ææå¤æçç¹å¾äº¤äºï¼å¹¶å¨ä¸åçæ°æ®éä¸è¿è¡æ³åãä¸ºäºè§£å³è¿äºéå¶ï¼æä»¬æåºäºä¸ç§æ°é¢çååçè®ºï¼è¯¥çè®ºå©ç¨äºè¡¥çæ½å¨ç©ºé´æ¥å¢å¼ºç¹å¾äº¤äºå»ºæ¨¡ãæä»¬æåºçæ¶æ nnSynergyNet3D éæäºè¿ç»­åç¦»æ£çæ½å¨ç©ºé´ï¼ç¨äº 3D ä½ç§¯ï¼å¹¶å·æèªå¨éç½®çè®­ç»ãè¿ç§æ¹æ³ææå°äºç»ç²åº¦åç²ç²åº¦ç¹å¾ï¼ä»èè½å¤ææå°å¯¹å¤æçç¹å¾äº¤äºè¿è¡å»ºæ¨¡ãæä»¬æ ¹æ® 339 åæ£èç 628 ä¸ªé«åè¾¨ç T1 è¹é¨ MRI æ«æçç§ææ°æ®éå¯¹ nnSynergyNet3D è¿è¡äºå®è¯éªè¯ãæä»¬çæ¨¡åæ¯åºçº¿ nnUNet3D çæ§è½æé«äºå¤§çº¦ 2%ãæ­¤å¤ï¼å¨æ¥èªå¬å± LiTS æ°æ®éçå¥åº·èè CT æ«æä¸è¿è¡é¶æ ·æ¬æµè¯è¯æäºå¶åè¶çè·¨æ¨¡ææ³åè½åãè¿äºç»æçªåºäºååæ½å¨ç©ºé´æ¨¡åå¨æé«åå²ç²¾åº¦åé²æ£æ§æ¹é¢çæ½åï¼ä»èéè¿ç¡®ä¿ CT å MRI æ¨¡æçä¸è´æ§æ¥å¢å¼ºä¸´åºå·¥ä½æµç¨ã

##### **SegXAL: Explainable Active Learning for Semantic Segmentation in Driving Scene Scenarios**
2408.04482v1 by Sriram Mandalika, Athira Nambiar

Most of the sophisticated AI models utilize huge amounts of annotated data
and heavy training to achieve high-end performance. However, there are certain
challenges that hinder the deployment of AI models "in-the-wild" scenarios,
i.e., inefficient use of unlabeled data, lack of incorporation of human
expertise, and lack of interpretation of the results. To mitigate these
challenges, we propose a novel Explainable Active Learning (XAL) model,
XAL-based semantic segmentation model "SegXAL", that can (i) effectively
utilize the unlabeled data, (ii) facilitate the "Human-in-the-loop" paradigm,
and (iii) augment the model decisions in an interpretable way. In particular,
we investigate the application of the SegXAL model for semantic segmentation in
driving scene scenarios. The SegXAL model proposes the image regions that
require labeling assistance from Oracle by dint of explainable AI (XAI) and
uncertainty measures in a weakly-supervised manner. Specifically, we propose a
novel Proximity-aware Explainable-AI (PAE) module and Entropy-based Uncertainty
(EBU) module to get an Explainable Error Mask, which enables the machine
teachers/human experts to provide intuitive reasoning behind the results and to
solicit feedback to the AI system via an active learning strategy. Such a
mechanism bridges the semantic gap between man and machine through
collaborative intelligence, where humans and AI actively enhance each other's
complementary strengths. A novel high-confidence sample selection technique
based on the DICE similarity coefficient is also presented within the SegXAL
framework. Extensive quantitative and qualitative analyses are carried out in
the benchmarking Cityscape dataset. Results show the outperformance of our
proposed SegXAL against other state-of-the-art models.

æè¦ï¼å¤§å¤æ¸åé²ç AI æ¨¡åé½å©ç¨å¤§éæ¨è¨»è³æåå´æ ¼è¨ç·´ä¾éæé«éæè½ãç¶èï¼å¨ AI æ¨¡åãå¨éãå ´æ¯ä¸­é¨ç½²æï¼æéå°æäºææ°ï¼ä¾å¦ï¼éæ¨è¨»è³æä½¿ç¨æçä¸å½°ãç¼ºä¹æ´åäººé¡å°æ¥­ç¥è­ï¼ä»¥åç¼ºä¹å°çµæçè©®éãçºäºæ¸è¼éäºææ°ï¼æåæåºä¸åæ°ç©çå¯è§£éä¸»åå­¸ç¿ (XAL) æ¨¡åï¼åºæ¼ XAL çèªæåå²æ¨¡åãSegXALãï¼å®å¯ä»¥ (i) ææå©ç¨éæ¨è¨»è³æï¼(ii) ä¿æãäººé¡å¨è¿´åä¸­ãçæ¨¡å¼ï¼ä»¥å (iii) ä»¥å¯è§£éçæ¹å¼æ´åæ¨¡åçæ±ºç­ãç¹å¥æ¯ï¼æåæ¢è¨ SegXAL æ¨¡åå¨é§é§å ´æ¯ä¸­ç¨æ¼èªæåå²çæç¨ãSegXAL æ¨¡åæåºéè¦æ¨ç±¤åå©çå½±åååï¼èç±å¯è§£é AI (XAI) åä¸ç¢ºå®æ§æ¸¬éï¼ä»¥å¼±ç£ç£çæ¹å¼ä¾éæãå·é«ä¾èªªï¼æåæåºä¸åæ°ç©çé°è¿æç¥å¯è§£é AI (PAE) æ¨¡çµååºæ¼çµçä¸ç¢ºå®æ§ (EBU) æ¨¡çµï¼ä»¥åå¾å¯è§£éé¯èª¤é®ç½©ï¼éè®æ©å¨æå¸«/äººé¡å°å®¶è½å¤ å°çµææä¾ç´è¦ºæ§çæ¨çï¼ä¸¦ééä¸»åå­¸ç¿ç­ç¥å AI ç³»çµ±å¾µæ±åé¥ãéç¨®æ©å¶ééåä½æºæ§ï¼ç¸®å°äººé¡èæ©å¨ä¹éçèªæå·®è·ï¼äººé¡è AI è½å¤ ç©æ¥µå°å¢å¼·å½¼æ­¤çäºè£åªå¢ãSegXAL æ¶æ§ä¸­ä¹æåºä¸åæ°ç©çé«ä¿¡å¿æ¨£æ¬é¸åæè¡ï¼åºæ¼ DICE ç¸ä¼¼ä¿æ¸ãå¨åºæº Cityscape è³æéä¸­é²è¡å»£æ³çéååè³ªååæãçµæé¡¯ç¤ºæåæåºç SegXAL åªæ¼å¶ä»ç¾ææè¡æ¨¡åã

##### **Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive Debate**
2408.04472v1 by Yiqun Zhang, Xiaocui Yang, Shi Feng, Daling Wang, Yifei Zhang, Kaisong Song

Competitive debate is a comprehensive and complex computational argumentation
task. Large Language Models (LLMs) encounter hallucinations and lack
competitiveness in this task. To address these challenges, we introduce Agent
for Debate (Agent4Debate), a dynamic, multi-agent framework based on LLMs
designed to enhance their capabilities in competitive debate. Drawing
inspiration from human behavior in debate preparation and execution,
Agent4Debate employs a collaborative architecture where four specialized agents
(Searcher, Analyzer, Writer, and Reviewer) dynamically interact and cooperate.
These agents work throughout the debate process, covering multiple stages from
initial research and argument formulation to rebuttal and summary. To
comprehensively evaluate framework performance, we construct the Chinese Debate
Arena, comprising 66 carefully selected Chinese debate motions. We recruite ten
experienced human debaters and collect records of 200 debates involving
Agent4Debate, baseline models, and humans. The evaluation employs the Debatrix
automatic scoring system and professional human reviewers based on the
established Debatrix-Elo and Human-Elo ranking. Experimental results indicate
that the state-of-the-art Agent4Debate exhibits capabilities comparable to
those of humans. Furthermore, ablation studies demonstrate the effectiveness of
each component in the agent structure.

æè¦ï¼ç«¶ç­æ§è¾¯è«æ¯ä¸ç¨®å¨é¢ä¸è¤éçè¨ç®è«è­ä»»åãå¤§åèªè¨æ¨¡å (LLM) å¨æ­¤ä»»åä¸­æéå°å¹»è¦ºï¼ä¸ç¼ºä¹ç«¶ç­åãçºäºæå°éäºææ°ï¼æåå¼å¥äºè¾¯è«ä»£ç (Agent4Debate)ï¼éæ¯ä¸ååºæ¼ LLM çåæå¤ä»£çæ¶æ§ï¼æ¨å¨å¢å¼·å¶å¨ç«¶ç­æ§è¾¯è«ä¸­çè½åãAgent4Debate å¾äººé¡å¨è¾¯è«æºååå·è¡ä¸­çè¡çºä¸­æ±²åéæï¼æ¡ç¨åä½æ¶æ§ï¼å¶ä¸­ååå°éä»£çï¼æå°èãåæå¸«ãæ°ç¨¿äººåå¯©é±èï¼åæäºåä¸¦åä½ãéäºä»£çå¨æ´åè¾¯è«éç¨ä¸­å·¥ä½ï¼æ¶µèå¾åå§ç ç©¶åè«è­å¶å®å°åé§åç¸½çµçå¤åéæ®µãçºäºå¨é¢è©ä¼°æ¡æ¶æè½ï¼æåæ§å»ºäºåå« 66 åç²¾å¿æé¸çä¸­æè¾¯è«åè­°çä¸­æè¾¯è«ç«¶æå ´ãæåæåäºåä½ç¶é©è±å¯çäººé¡è¾¯è«èï¼ä¸¦æ¶éäº 200 å ´æ¶å Agent4Debateãåºç·æ¨¡ååäººé¡çè¾¯è«è¨éãè©ä¼°æ¡ç¨ Debatrix èªåè©åç³»çµ±åå°æ¥­çäººé¡å¯©é±èï¼æ ¹ææ¢å®ç Debatrix-Elo å Human-Elo æåãå¯¦é©çµæè¡¨æï¼æåé²ç Agent4Debate æè¡¨ç¾åºçè½åå¯èäººé¡ç¸åª²ç¾ãæ­¤å¤ï¼æ¶èç ç©¶è­æäºä»£ççµæ§ä¸­æ¯åçµæçæææ§ã

##### **Crowd Intelligence for Early Misinformation Prediction on Social Media**
2408.04463v1 by Megha Sundriyal, Harshit Choudhary, Tanmoy Chakraborty, Md Shad Akhtar

Misinformation spreads rapidly on social media, causing serious damage by
influencing public opinion, promoting dangerous behavior, or eroding trust in
reliable sources. It spreads too fast for traditional fact-checking, stressing
the need for predictive methods. We introduce CROWDSHIELD, a crowd
intelligence-based method for early misinformation prediction. We hypothesize
that the crowd's reactions to misinformation reveal its accuracy. Furthermore,
we hinge upon exaggerated assertions/claims and replies with particular
positions/stances on the source post within a conversation thread. We employ
Q-learning to capture the two dimensions -- stances and claims. We utilize deep
Q-learning due to its proficiency in navigating complex decision spaces and
effectively learning network properties. Additionally, we use a
transformer-based encoder to develop a comprehensive understanding of both
content and context. This multifaceted approach helps ensure the model pays
attention to user interaction and stays anchored in the communication's
content. We propose MIST, a manually annotated misinformation detection Twitter
corpus comprising nearly 200 conversation threads with more than 14K replies.
In experiments, CROWDSHIELD outperformed ten baseline systems, achieving an
improvement of ~4% macro-F1 score. We conduct an ablation study and error
analysis to validate our proposed model's performance. The source code and
dataset are available at https://github.com/LCS2-IIITD/CrowdShield.git.

æè¦ï¼éè¯¯ä¿¡æ¯å¨ç¤¾äº¤åªé«ä¸è¿éå³æ­ï¼ééå½±é¿å¬ç¾è¼¿è«ãå®£å³å±éªè¡çºæä¾µèå°å¯é ä¾æºçä¿¡ä»»ï¼é æå´éæå®³ãå®çå³æ­éåº¦å¤ªå¿«ï¼ä»¥è³æ¼å³çµ±çäºå¯¦æ¥æ ¸ç¡æ³æå°ï¼éå¼·èª¿äºå°é æ¸¬æ¹æ³çéæ±ãæåå¼å¥äº CROWDSHIELDï¼éæ¯ä¸ç¨®åºæ¼ç¾¤ç¾æºæ§çæ©æé¯èª¤ä¿¡æ¯é æ¸¬æ¹æ³ãæååè¨­ç¾¤ç¾å°é¯èª¤ä¿¡æ¯çåææ­ç¤ºäºå®çæºç¢ºæ§ãæ­¤å¤ï¼æåä¾è³´æ¼å°è©±ç·ç¨ä¸­æºå¸å­çèªå¼µæ·è¨/ä¸»å¼µåå·æç¹å®ç«å ´/æåº¦çåå¾©ãæåæ¡ç¨ Q å­¸ç¿ä¾ææéå©åç¶­åº¦ââç«å ´åä¸»å¼µãæåå©ç¨æ·±åº¦ Q å­¸ç¿ï¼å çºå®æé·å¨è¤éçæ±ºç­ç©ºéä¸­å°èªä¸¦ææå°å­¸ç¿ç¶²è·¯å±¬æ§ãæ­¤å¤ï¼æåä½¿ç¨åºæ¼ Transformer çç·¨ç¢¼å¨ä¾å¨é¢çè§£å§å®¹åä¸ä¸æãéç¨®å¤æ¹é¢çéå¾æå©æ¼ç¢ºä¿æ¨¡åéæ³¨ç¨æ¶äºåä¸¦é¨å®å¨éä¿¡å§å®¹ä¸­ãæåæåºäº MISTï¼éæ¯ä¸åæåæ¨è¨»çé¯èª¤ä¿¡æ¯æª¢æ¸¬ Twitter èªæåº«ï¼åå«è¿ 200 åå°è©±ç·ç¨ï¼å¶ä¸­æè¶é 14K æ¢åå¾©ãå¨å¯¦é©ä¸­ï¼CROWDSHIELD åªæ¼åååºæºç³»çµ±ï¼å®è§ F1 åæ¸æé«äºç´ 4%ãæåé²è¡æ¶èç ç©¶åé¯èª¤åæï¼ä»¥é©è­æåæåºçæ¨¡åçæ§è½ãæºä»£ç¢¼åæ¸æéå¯å¨ https://github.com/LCS2-IIITD/CrowdShield.git ä¸ç²å¾ã

##### **RiskAwareBench: Towards Evaluating Physical Risk Awareness for High-level Planning of LLM-based Embodied Agents**
2408.04449v1 by Zihao Zhu, Bingzhe Wu, Zhengyou Zhang, Baoyuan Wu

The integration of large language models (LLMs) into robotics significantly
enhances the capabilities of embodied agents in understanding and executing
complex natural language instructions. However, the unmitigated deployment of
LLM-based embodied systems in real-world environments may pose potential
physical risks, such as property damage and personal injury. Existing security
benchmarks for LLMs overlook risk awareness for LLM-based embodied agents. To
address this gap, we propose RiskAwareBench, an automated framework designed to
assess physical risks awareness in LLM-based embodied agents. RiskAwareBench
consists of four modules: safety tips generation, risky scene generation, plan
generation, and evaluation, enabling comprehensive risk assessment with minimal
manual intervention. Utilizing this framework, we compile the PhysicalRisk
dataset, encompassing diverse scenarios with associated safety tips,
observations, and instructions. Extensive experiments reveal that most LLMs
exhibit insufficient physical risk awareness, and baseline risk mitigation
strategies yield limited enhancement, which emphasizes the urgency and
cruciality of improving risk awareness in LLM-based embodied agents in the
future.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æ´åå°æ©å¨äººæè¡ä¸­ï¼é¡¯èæåäºå·èº«ä»£ççè§£åå·è¡è¤éèªç¶èªè¨æä»¤çè½åãç¶èï¼å¨ç¾å¯¦ä¸çç°å¢ä¸­é¨ç½²åºæ¼ LLM çå·èº«ç³»çµ±å¯è½æé ææ½å¨çç©çé¢¨éªï¼ä¾å¦è²¡ç¢æå£åäººèº«å·å®³ãç¾æç LLM å®å¨åºæºå¿½ç¥äºå°åºæ¼ LLM çå·èº«ä»£ççé¢¨éªæè­ãçºäºè§£æ±ºéååé¡ï¼æåæåºäº RiskAwareBenchï¼éæ¯ä¸åèªååæ¡æ¶ï¼æ¨å¨è©ä¼°åºæ¼ LLM çå·èº«ä»£çä¸­çç©çé¢¨éªæè­ãRiskAwareBench åå«ååæ¨¡çµï¼å®å¨æç¤ºçæãé¢¨éªå ´æ¯çæãè¨ç«çæåè©ä¼°ï¼ä»¥æå°çä»å¥å¯¦ç¾å¨é¢çé¢¨éªè©ä¼°ãå©ç¨éåæ¡æ¶ï¼æåç·¨å¶äº PhysicalRisk è³æéï¼å¶ä¸­åå«åç¨®å ´æ¯ä»¥åç¸éçå®å¨æç¤ºãè§å¯åèªªæãå¤§éçå¯¦é©é¡¯ç¤ºï¼å¤§å¤æ¸ LLM é½è¡¨ç¾åºä¸è¶³çç©çé¢¨éªæè­ï¼èä¸åºæºé¢¨éªç·©è§£ç­ç¥ç¢ççæ¹åæéï¼éå¼·èª¿äºå¨æªä¾æ¹ååºæ¼ LLM çå·èº«ä»£çä¸­çé¢¨éªæè­çè¿«åæ§åéè¦æ§ã

##### **FedAD-Bench: A Unified Benchmark for Federated Unsupervised Anomaly Detection in Tabular Data**
2408.04442v1 by Ahmed Anwar, Brian Moser, Dayananda Herurkar, Federico Raue, Vinit Hegiste, Tatjana Legler, Andreas Dengel

The emergence of federated learning (FL) presents a promising approach to
leverage decentralized data while preserving privacy. Furthermore, the
combination of FL and anomaly detection is particularly compelling because it
allows for detecting rare and critical anomalies (usually also rare in locally
gathered data) in sensitive data from multiple sources, such as cybersecurity
and healthcare. However, benchmarking the performance of anomaly detection
methods in FL environments remains an underexplored area. This paper introduces
FedAD-Bench, a unified benchmark for evaluating unsupervised anomaly detection
algorithms within the context of FL. We systematically analyze and compare the
performance of recent deep learning anomaly detection models under federated
settings, which were typically assessed solely in centralized settings.
FedAD-Bench encompasses diverse datasets and metrics to provide a holistic
evaluation. Through extensive experiments, we identify key challenges such as
model aggregation inefficiencies and metric unreliability. We present insights
into FL's regularization effects, revealing scenarios in which it outperforms
centralized approaches due to its inherent ability to mitigate overfitting. Our
work aims to establish a standardized benchmark to guide future research and
development in federated anomaly detection, promoting reproducibility and fair
comparison across studies.

æè¦ï¼è¯é¦å­¸ç¿ (FL) çåºç¾æä¾äºä¸åæåéçæ¹æ³ï¼å¯ä»¥å¨ç¶­è­·é±ç§çåæå©ç¨åæ£çæ¸æãæ­¤å¤ï¼FL åç°å¸¸æª¢æ¸¬ççµåç¹å¥å¼äººæ³¨ç®ï¼å çºå®åè¨±å¾å¤åä¾æºï¼ä¾å¦ç¶²è·¯å®å¨åé«çä¿å¥ï¼ä¸­æª¢æ¸¬ç½è¦åééµçç°å¸¸ï¼éå¸¸å¨æ¬å°æ¶éçæ¸æä¸­ä¹å¾ç½è¦ï¼ãç¶èï¼å¨ FL ç°å¢ä¸­å°ç°å¸¸æª¢æ¸¬æ¹æ³çæ§è½é²è¡åºæºæ¸¬è©¦ä»ç¶æ¯ä¸åæªè¢«ååæ¢ç´¢çé åãæ¬æä»ç´¹äº FedAD-Benchï¼éæ¯ä¸åç¨æ¼è©ä¼° FL èæ¯ä¸ç¡ç£ç£ç°å¸¸æª¢æ¸¬æ¼ç®æ³ççµ±ä¸åºæºãæåç³»çµ±å°åæä¸¦æ¯è¼äºæè¿æ·±åº¦å­¸ç¿ç°å¸¸æª¢æ¸¬æ¨¡åå¨è¯é¦è¨­ç½®ä¸çæ§è½ï¼éäºæ¨¡åéå¸¸åå¨éä¸­å¼è¨­ç½®ä¸­é²è¡è©ä¼°ãFedAD-Bench æ¶µèäºå¤æ¨£åçæ¸æéåææ¨ï¼ä»¥æä¾å¨é¢çè©ä¼°ãééå¤§éçå¯¦é©ï¼æåç¢ºå®äºééµææ°ï¼ä¾å¦æ¨¡åèåæçä½ä¸åææ¨ä¸å¯é ãæåæ·±å¥äºè§£ FL çæ­£ååææï¼æ­ç¤ºäºç±æ¼å¶åºæçæ¸è¼éåº¦æ¬åçè½åï¼å®å¨åªäºå ´æ¯ä¸­åªæ¼éä¸­å¼æ¹æ³ãæåçç®æ¨æ¯å»ºç«ä¸åæ¨æºååºæºï¼ä»¥æå°è¯é¦ç°å¸¸æª¢æ¸¬çæªä¾ç ç©¶åéç¼ï¼ä¿é²è·¨ç ç©¶çå¯éè¤æ§åå¬å¹³æ¯è¼ã

##### **Recognizing Emotion Regulation Strategies from Human Behavior with Large Language Models**
2408.04420v1 by Philipp MÃ¼ller, Alexander Heimerl, Sayed Muddashir Hossain, Lea Siegel, Jan Alexandersson, Patrick Gebhard, Elisabeth AndrÃ©, Tanja Schneeberger

Human emotions are often not expressed directly, but regulated according to
internal processes and social display rules. For affective computing systems,
an understanding of how users regulate their emotions can be highly useful, for
example to provide feedback in job interview training, or in psychotherapeutic
scenarios. However, at present no method to automatically classify different
emotion regulation strategies in a cross-user scenario exists. At the same
time, recent studies showed that instruction-tuned Large Language Models (LLMs)
can reach impressive performance across a variety of affect recognition tasks
such as categorical emotion recognition or sentiment analysis. While these
results are promising, it remains unclear to what extent the representational
power of LLMs can be utilized in the more subtle task of classifying users'
internal emotion regulation strategy. To close this gap, we make use of the
recently introduced \textsc{Deep} corpus for modeling the social display of the
emotion shame, where each point in time is annotated with one of seven
different emotion regulation classes. We fine-tune Llama2-7B as well as the
recently introduced Gemma model using Low-rank Optimization on prompts
generated from different sources of information on the \textsc{Deep} corpus.
These include verbal and nonverbal behavior, person factors, as well as the
results of an in-depth interview after the interaction. Our results show, that
a fine-tuned Llama2-7B LLM is able to classify the utilized emotion regulation
strategy with high accuracy (0.84) without needing access to data from
post-interaction interviews. This represents a significant improvement over
previous approaches based on Bayesian Networks and highlights the importance of
modeling verbal behavior in emotion regulation.

æè¦ï¼äººé¡çæç·éå¸¸ä¸æç´æ¥è¡¨éåºä¾ï¼èæ¯æ ¹æå§é¨éç¨åç¤¾æå±ç¤ºè¦åé²è¡èª¿ç¯ãå°æ¼ææéç®ç³»çµ±èè¨ï¼äºè§£ä½¿ç¨èå¦ä½èª¿ç¯æç·å¯è½éå¸¸æç¨ï¼ä¾å¦å¨é¢è©¦å¹è¨æå¿çæ²»çå ´æ¯ä¸­æä¾åé¥ãç¶èï¼ç®åå°ç¡æ¹æ³å¯å¨è·¨ä½¿ç¨èå ´æ¯ä¸­èªååé¡ä¸åçæç·èª¿ç¯ç­ç¥ãåæï¼æè¿çç ç©¶è¡¨æï¼ç¶éæç¤ºèª¿æ´çå¤§åèªè¨æ¨¡å (LLM) å¯ä»¥å¨ä¸ç³»åææè¾¨è­ä»»åä¸­éå°ä»¤äººå°è±¡æ·±å»çè¡¨ç¾ï¼ä¾å¦åé¡æç·è¾¨è­ææç·åæãéç¶éäºçµæä»¤äººæ¯å¥®ï¼ä½ LLM çè¡¨å¾µè½åå¨æ´ç´°å¾®çä½¿ç¨èå§é¨æç·èª¿ç¯ç­ç¥åé¡ä»»åä¸­è½ç¼æ®å¤å¤§ä½ç¨ä»ä¸æ¸æ¥ãçºäºç¸®å°éåå·®è·ï¼æåå©ç¨æè¿æ¨åºçãæ·±åº¦ãèªæåº«ä¾å»ºæ¨¡æç·ç¾æ¥çç¤¾æå±ç¤ºï¼å¶ä¸­æ¯åæéé»é½æ¨è¨»äºä¸ç¨®ä¸åçæç·èª¿ç¯é¡å¥ä¹ä¸ãæåå¾®èª¿äº Llama2-7B ä»¥åæè¿æ¨åºç Gemma æ¨¡åï¼ä½¿ç¨ä½ç§©æä½³åèçå¾ãæ·±åº¦ãèªæåº«ä¸­ä¸åè³è¨ä¾æºç¢ççæç¤ºãéäºè³è¨åæ¬è¨èªåéè¨èªè¡çºãåäººå ç´ ï¼ä»¥åäºåå¾æ·±å¥è¨ªè«ççµæãæåççµæé¡¯ç¤ºï¼å¾®èª¿å¾ç Llama2-7B LLM è½å¤ ä»¥é«æºç¢ºåº¦ (0.84) åé¡æä½¿ç¨çæç·èª¿ç¯ç­ç¥ï¼èä¸éè¦å­åäºåå¾è¨ªè«çè³æãéä»£è¡¨ç¸è¼æ¼åºæ¼è²æ°ç¶²è·¯çååæ¹æ³æé¡¯èçé²æ­¥ï¼ä¸¦çªé¡¯äºå¨æç·èª¿ç¯ä¸­å»ºæ¨¡è¨èªè¡çºçéè¦æ§ã

##### **Enhancing Robustness of Retrieval-Augmented Language Models with In-Context Learning**
2408.04414v1 by Seong-Il Park, Seung-Woo Choi, Na-Hyun Kim, Jay-Yoon Lee

Retrieval-Augmented Language Models (RALMs) have significantly improved
performance in open-domain question answering (QA) by leveraging external
knowledge. However, RALMs still struggle with unanswerable queries, where the
retrieved contexts do not contain the correct answer, and with conflicting
information, where different sources provide contradictory answers due to
imperfect retrieval. This study introduces an in-context learning-based
approach to enhance the reasoning capabilities of RALMs, making them more
robust in imperfect retrieval scenarios. Our method incorporates Machine
Reading Comprehension (MRC) demonstrations, referred to as cases, to boost the
model's capabilities to identify unanswerabilities and conflicts among the
retrieved contexts. Experiments on two open-domain QA datasets show that our
approach increases accuracy in identifying unanswerable and conflicting
scenarios without requiring additional fine-tuning. This work demonstrates that
in-context learning can effectively enhance the robustness of RALMs in
open-domain QA tasks.

æè¦ï¼æª¢ç´¢å¢å¼·èªè¨æ¨¡å (RALM) ééå©ç¨å¤é¨ç¥è­ï¼å¤§å¹æåäºéæ¾é ååç­ (QA) çæè½ãç¶èï¼RALM ä»é£ä»¥æå°ç¡æ³åç­çæ¥è©¢ï¼å¶ä¸­æª¢ç´¢å°çèçµ¡ä¸åå«æ­£ç¢ºç­æ¡ï¼ä»¥åçç¾è³è¨ï¼å¶ä¸­ä¸åçä¾æºå æª¢ç´¢ä¸å®ç¾èæä¾ç¸äºçç¾çç­æ¡ãæ¬ç ç©¶å¼å¥åºæ¼èçµ¡ä¸­å­¸ç¿çæ¹æ³ï¼ä»¥å¢å¼· RALM çæ¨çè½åï¼ä½¿å¶å¨ä¸å®ç¾çæª¢ç´¢æå¢ä¸­æ´å¼·å¥ãæåçåæ³çµåäºæ©å¨é±è®çè§£ (MRC) ç¤ºç¯ï¼ç¨±çºæ¡ä¾ï¼ä»¥æåæ¨¡åè¾¨è­æª¢ç´¢å°çèçµ¡ä¸­ç¡æ³åç­åçç¾ä¹èçè½åãå¨å©åéæ¾é å QA è³æéä¸çå¯¦é©é¡¯ç¤ºï¼æåçåæ³æåäºè¾¨è­ç¡æ³åç­åçç¾æå¢çæºç¢ºåº¦ï¼èç¡éé¡å¤çå¾®èª¿ãéé å·¥ä½è­æäºèçµ¡ä¸­å­¸ç¿å¯ä»¥ææå¢å¼· RALM å¨éæ¾é å QA ä»»åä¸­çå¼·å¥æ§ã

##### **Exploring Reasoning Biases in Large Language Models Through Syllogism: Insights from the NeuBAROCO Dataset**
2408.04403v1 by Kentaro Ozeki, Risako Ando, Takanobu Morishita, Hirohiko Abe, Koji Mineshima, Mitsuhiro Okada

This paper explores the question of how accurately current large language
models can perform logical reasoning in natural language, with an emphasis on
whether these models exhibit reasoning biases similar to humans. Specifically,
our study focuses on syllogistic reasoning, a form of deductive reasoning
extensively studied in cognitive science as a natural form of human reasoning.
We present a syllogism dataset called NeuBAROCO, which consists of syllogistic
reasoning problems in English and Japanese. This dataset was originally
designed for psychological experiments to assess human reasoning capabilities
using various forms of syllogisms. Our experiments with leading large language
models indicate that these models exhibit reasoning biases similar to humans,
along with other error tendencies. Notably, there is significant room for
improvement in reasoning problems where the relationship between premises and
hypotheses is neither entailment nor contradiction. We also present
experimental results and in-depth analysis using a new Chain-of-Thought
prompting method, which asks LLMs to translate syllogisms into abstract logical
expressions and then explain their reasoning process. Our analysis using this
method suggests that the primary limitations of LLMs lie in the reasoning
process itself rather than the interpretation of syllogisms.

æè¦ï¼éç¯è«ææ¢è¨äºç®åå¤§åèªè¨æ¨¡åå¨èªç¶èªè¨ä¸­å·è¡éè¼¯æ¨ççæºç¢ºæ§ï¼éé»å¨æ¼éäºæ¨¡åæ¯å¦è¡¨ç¾åºèäººé¡é¡ä¼¼çæ¨çåå·®ãå·é«ä¾èªªï¼æåçç ç©¶éé»å¨æ¼ä¸æ®µè«æ¨çï¼éæ¯ä¸ç¨®æ¼ç¹¹æ¨çå½¢å¼ï¼å¨èªç¥ç§å­¸ä¸­è¢«å»£æ³ç ç©¶çºäººé¡æ¨ççèªç¶å½¢å¼ãæåæåºäºä¸ååçº NeuBAROCO çä¸æ®µè«æ¸æéï¼å¶ä¸­åå«è±èªåæ¥èªçä¸æ®µè«æ¨çåé¡ãæ­¤æ¸æéæåæ¯çºå¿çå¯¦é©è¨­è¨çï¼ç¨æ¼ä½¿ç¨åç¨®å½¢å¼çä¸æ®µè«è©ä¼°äººé¡æ¨çè½åãæåèé åçå¤§åèªè¨æ¨¡åé²è¡çå¯¦é©è¡¨æï¼éäºæ¨¡åè¡¨ç¾åºèäººé¡é¡ä¼¼çæ¨çåå·®ï¼ä»¥åå¶ä»é¯èª¤å¾åãå¼å¾æ³¨æçæ¯ï¼å¨åæååè¨­ä¹éçéä¿æ¢ä¸æ¯èæ¶µä¹ä¸æ¯çç¾çæ¨çåé¡ä¸­ï¼æå¾å¤§çæ¹é²ç©ºéãæåéä½¿ç¨æ°çææ³éæç¤ºæ¹æ³æä¾äºå¯¦é©çµæåæ·±å¥åæï¼è©²æ¹æ³è¦æ± LLM å°ä¸æ®µè«ç¿»è­¯ææ½è±¡éè¼¯è¡¨éå¼ï¼ç¶å¾è§£éä»åçæ¨çéç¨ãæåä½¿ç¨æ­¤æ¹æ³é²è¡çåæè¡¨æï¼LLM çä¸»è¦éå¶å¨æ¼æ¨çéç¨æ¬èº«ï¼èä¸æ¯å°ä¸æ®µè«çè§£éã

##### **DIVE: Subgraph Disagreement for Graph Out-of-Distribution Generalization**
2408.04400v1 by Xin Sun, Liang Wang, Qiang Liu, Shu Wu, Zilei Wang, Liang Wang

This paper addresses the challenge of out-of-distribution (OOD)
generalization in graph machine learning, a field rapidly advancing yet
grappling with the discrepancy between source and target data distributions.
Traditional graph learning algorithms, based on the assumption of uniform
distribution between training and test data, falter in real-world scenarios
where this assumption fails, resulting in suboptimal performance. A principal
factor contributing to this suboptimal performance is the inherent simplicity
bias of neural networks trained through Stochastic Gradient Descent (SGD),
which prefer simpler features over more complex yet equally or more predictive
ones. This bias leads to a reliance on spurious correlations, adversely
affecting OOD performance in various tasks such as image recognition, natural
language understanding, and graph classification. Current methodologies,
including subgraph-mixup and information bottleneck approaches, have achieved
partial success but struggle to overcome simplicity bias, often reinforcing
spurious correlations. To tackle this, we propose DIVE, training a collection
of models to focus on all label-predictive subgraphs by encouraging the models
to foster divergence on the subgraph mask, which circumvents the limitation of
a model solely focusing on the subgraph corresponding to simple structural
patterns. Specifically, we employs a regularizer to punish overlap in extracted
subgraphs across models, thereby encouraging different models to concentrate on
distinct structural patterns. Model selection for robust OOD performance is
achieved through validation accuracy. Tested across four datasets from GOOD
benchmark and one dataset from DrugOOD benchmark, our approach demonstrates
significant improvement over existing methods, effectively addressing the
simplicity bias and enhancing generalization in graph machine learning.

æè¦ï¼<paragraph>éç¯è«ææ¢è¨äºåå½¢æ©å¨å­¸ç¿ä¸­éåä½ (OOD) æ¦åçææ°ï¼éæ¯ä¸åå¿«éç¼å±çé åï¼ä½å»å¨æå°ä¾æºåç®æ¨è³æåä½ä¹éçå·®ç°ä¸éå°å°é£ãå³çµ±çåå½¢å­¸ç¿æ¼ç®æ³åºæ¼è¨ç·´è³æåæ¸¬è©¦è³æä¹éåå»åä½çåè¨­ï¼ä½å¨éååè¨­å¤±æçå¯¦éææ³ä¸­æåºç¾åé¡ï¼å°è´æ¬¡ä½³æè½ãé æéç¨®æ¬¡ä½³æè½çä¸»è¦å ç´ æ¯ééé¨æ©æ¢¯åº¦ä¸é (SGD) è¨ç·´çç¥ç¶ç¶²è·¯åºæçç°¡ååå·®ï¼å®åå¥½è¼ç°¡å®çç¹å¾µï¼èéæ´è¤éä½é æ¸¬è½åç¸åææ´é«çç¹å¾µãéç¨®åå·®æå°è´ä¾è³´èåç¸éæ§ï¼å°åç¨®ä»»åï¼ä¾å¦å½±åè¾¨è­ãèªç¶èªè¨çè§£ååå½¢åé¡ï¼ç OOD æè½ç¢çè² é¢å½±é¿ãç®åçæè¡æ¹æ³ï¼åæ¬å­åæ··ååè³è¨ç¶é ¸æ¹æ³ï¼å·²åå¾é¨åæåï¼ä½ä»é£ä»¥åæç°¡ååå·®ï¼èä¸å¸¸å¸¸æå¼·åèåç¸éæ§ãçºäºè§£æ±ºéååé¡ï¼æåæåºäº DIVEï¼è¨ç·´ä¸çµæ¨¡åä»¥éæ³¨æææ¨ç±¤é æ¸¬å­åï¼æ¹æ³æ¯é¼åµæ¨¡åå¨å­åé®ç½©ä¸ä¿é²å·®ç°ï¼éé¿éäºæ¨¡ååéæ³¨å°ææ¼ç°¡å®çµæ§æ¨¡å¼çå­åçéå¶ãå·é«ä¾èªªï¼æåæ¡ç¨ä¸åæ­£è¦åå¨ä¾æ²ç½°æ¨¡åä¹éæåçå­åä¸­çéçï¼å¾èé¼åµä¸åçæ¨¡åå°æ³¨æ¼ä¸åççµæ§æ¨¡å¼ãééé©è­æºç¢ºåº¦ï¼å¯ä»¥é¸ææ¨¡åä»¥ç²å¾ç©©å¥ç OOD æè½ãæåçåæ³å¨ GOOD åºæºä¸­çååè³æéå DrugOOD åºæºä¸­çå¶ä¸­ä¸åè³æéä¸é²è¡äºæ¸¬è©¦ï¼çµæé¡¯ç¤ºåºæ¯ç¾ææ¹æ³æé¡¯èçé²æ­¥ï¼ææå°è§£æ±ºäºç°¡ååå·®ï¼ä¸¦å¢å¼·äºåå½¢æ©å¨å­¸ç¿ä¸­çæ¦åè½åã</paragraph>

##### **Automated Educational Question Generation at Different Bloom's Skill Levels using Large Language Models: Strategies and Evaluation**
2408.04394v1 by Nicy Scaria, Suma Dharani Chenna, Deepak Subramani

Developing questions that are pedagogically sound, relevant, and promote
learning is a challenging and time-consuming task for educators. Modern-day
large language models (LLMs) generate high-quality content across multiple
domains, potentially helping educators to develop high-quality questions.
Automated educational question generation (AEQG) is important in scaling online
education catering to a diverse student population. Past attempts at AEQG have
shown limited abilities to generate questions at higher cognitive levels. In
this study, we examine the ability of five state-of-the-art LLMs of different
sizes to generate diverse and high-quality questions of different cognitive
levels, as defined by Bloom's taxonomy. We use advanced prompting techniques
with varying complexity for AEQG. We conducted expert and LLM-based evaluations
to assess the linguistic and pedagogical relevance and quality of the
questions. Our findings suggest that LLms can generate relevant and
high-quality educational questions of different cognitive levels when prompted
with adequate information, although there is a significant variance in the
performance of the five LLms considered. We also show that automated evaluation
is not on par with human evaluation.

æè¦ï¼<paragraph>å°æ¼æè²å·¥ä½èä¾èªªï¼å¶å®å·ææå­¸æç¾©ãç¸éä¸è½ä¿é²å­¸ç¿çåé¡æ¯ä¸é å·æææ°æ§ä¸èæçä»»åãç¾ä»£å¤§åèªè¨æ¨¡å (LLM) å¯ç¢çè·¨å¤åé åçé«åè³ªå§å®¹ï¼æ½å¨æå©æ¼æè²å·¥ä½èå¶å®é«åè³ªçåé¡ãèªååæè²åé¡ç¢ç (AEQG) å¨æ´å±ç·ä¸æè²ä»¥è¿åå¤åçå­¸çæç¾¤æ¹é¢éå¸¸éè¦ãéå»åè©¦ AEQG å·²é¡¯ç¤ºåºå¨ç¢çè¼é«èªç¥å±¤ç´åé¡æ¹é¢çè½åæéãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨äºç¨®ä¸åè¦æ¨¡çææ° LLM ç¢çä¸åèªç¥å±¤ç´çå¤æ¨£åä¸é«åè³ªåé¡çè½åï¼æ­£å¦å¸é­¯å§åé¡æ³æå®ç¾©çãæåä½¿ç¨å·æä¸åè¤éæ§çé²éæç¤ºæè¡é²è¡ AEQGãæåé²è¡å°å®¶ååºæ¼ LLM çè©ä¼°ï¼ä»¥è©ä¼°åé¡çèªè¨åæå­¸ç¸éæ§ååè³ªãæåçç ç©¶çµæè¡¨æï¼ç¶æç¤ºæä¾è¶³å¤ çè³è¨æï¼LLM å¯ä»¥ç¢çä¸åèªç¥å±¤ç´çç¸éä¸é«åè³ªæè²åé¡ï¼åç®¡æèæ®çäºç¨® LLM å¨æè½ä¸å­å¨é¡¯èå·®ç°ãæåä¹è¡¨æï¼èªååè©ä¼°ç¡æ³èäººé¡è©ä¼°ç¸æä¸¦è«ã</paragraph>

##### **Open-domain Implicit Format Control for Large Language Model Generation**
2408.04392v1 by Yiqun Yao, Wenjia Ma, Xuezhi Fang, Xin Jiang, Xiang Li, Xuying Meng, Peng Han, Jing Li, Aixin Sun, Yequan Wang

Controlling the format of outputs generated by large language models (LLMs)
is a critical functionality in various applications. Current methods typically
employ constrained decoding with rule-based automata or fine-tuning with
manually crafted format instructions, both of which struggle with open-domain
format requirements. To address this limitation, we introduce a novel framework
for controlled generation in LLMs, leveraging user-provided, one-shot QA pairs.
This study investigates LLMs' capabilities to follow open-domain, one-shot
constraints and replicate the format of the example answers. We observe that
this is a non-trivial problem for current LLMs. We also develop a dataset
collection methodology for supervised fine-tuning that enhances the open-domain
format control of LLMs without degrading output quality, as well as a benchmark
on which we evaluate both the helpfulness and format correctness of LLM
outputs. The resulting datasets, named OIFC-SFT, along with the related code,
will be made publicly available at https://github.com/cofe-ai/OIFC.

æè¦ï¼æ§å¶å¤§åèªè¨æ¨¡å (LLM) çæçè¼¸åºæ ¼å¼å¨åç¨®æç¨ä¸­æ¯ä¸é ééµåè½ãç®åçæ¹æ³éå¸¸ä½¿ç¨åºæ¼è¦åçèªåæ©é²è¡ç´æè§£ç¢¼æä½¿ç¨äººå·¥è£½ä½çæ ¼å¼æä»¤é²è¡å¾®èª¿ï¼éå©ç¨®æ¹æ³é½é£ä»¥æ»¿è¶³éæ¾é åçæ ¼å¼è¦æ±ãçºäºè§£æ±ºéåéå¶ï¼æåå¼å¥äºä¸åæ°çæ¡æ¶ï¼ç¨æ¼å¨ LLM ä¸­é²è¡åæ§çæï¼å©ç¨ç¨æ¶æä¾çå®æ¬¡åç­å°ãéé ç ç©¶èª¿æ¥äº LLM éµå¾ªéæ¾é åãå®æ¬¡ç´æåè¤è£½ç¯ä¾ç­æ¡æ ¼å¼çè½åãæåè§å¯å°éå°æ¼ç®åç LLM ä¾èªªæ¯ä¸åä¸å¹³å¡çåé¡ãæåééç¼äºä¸ç¨®ç¨æ¼ç£ç£å¾®èª¿çæ¸æéæ¶éæ¹æ³ï¼è©²æ¹æ³å¢å¼·äº LLM çéæ¾é åæ ¼å¼æ§å¶ï¼èä¸æéä½è¼¸åºè³ªéï¼ä¸¦å»ºç«äºä¸ååºæºï¼æåæ ¹ææ­¤åºæºè©ä¼° LLM è¼¸åºçæç¨æ§åæ ¼å¼æ­£ç¢ºæ§ãçæçæ¸æéåçº OIFC-SFTï¼é£åç¸éä»£ç¢¼ï¼å°å¨ https://github.com/cofe-ai/OIFC ä¸å¬éã

##### **MM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models**
2408.04388v1 by Haoxuan Li, Zhengmao Yang, Yunshan Ma, Yi Bin, Yang Yang, Tat-Seng Chua

We study an emerging and intriguing problem of multimodal temporal event
forecasting with large language models. Compared to using text or graph
modalities, the investigation of utilizing images for temporal event
forecasting has not been fully explored, especially in the era of large
language models (LLMs). To bridge this gap, we are particularly interested in
two key questions of: 1) why images will help in temporal event forecasting,
and 2) how to integrate images into the LLM-based forecasting framework. To
answer these research questions, we propose to identify two essential functions
that images play in the scenario of temporal event forecasting, i.e.,
highlighting and complementary. Then, we develop a novel framework, named
MM-Forecast. It employs an Image Function Identification module to recognize
these functions as verbal descriptions using multimodal large language models
(MLLMs), and subsequently incorporates these function descriptions into
LLM-based forecasting models. To evaluate our approach, we construct a new
multimodal dataset, MidEast-TE-mm, by extending an existing event dataset
MidEast-TE-mini with images. Empirical studies demonstrate that our MM-Forecast
can correctly identify the image functions, and further more, incorporating
these verbal function descriptions significantly improves the forecasting
performance. The dataset, code, and prompts are available at
https://github.com/LuminosityX/MM-Forecast.

æè¦ï¼æåç ç©¶å¤æ¨¡ææéäºä»¶é æ¸¬ä¸­ä¸åæ°èä¸æè¶£çèªè¨æ¨¡ååé¡ãç¸è¼æ¼ä½¿ç¨æå­æåè¡¨æ¨¡æï¼å©ç¨å½±åé²è¡æéäºä»¶é æ¸¬çç ç©¶å°æªè¢«ååæ¢ç´¢ï¼ç¹å¥æ¯å¨å¤§åèªè¨æ¨¡å (LLM) çæä»£ãçºäºå¡«è£éåç©ºç½ï¼æåç¹å¥æèè¶£çå©åééµåé¡æ¯ï¼1) çºä»éº¼å½±åæå©æ¼æéäºä»¶é æ¸¬ï¼ä»¥å 2) å¦ä½å°å½±åæ´åå°åºæ¼ LLM çé æ¸¬æ¡æ¶ä¸­ãçºäºåç­éäºç ç©¶åé¡ï¼æåæè­°æ¾åºå½±åå¨æéäºä»¶é æ¸¬å ´æ¯ä¸­æ®æ¼çå©ååºæ¬åè½ï¼å³çªé¡¯åè£åãç¶å¾ï¼æåéç¼ä¸ååçº MM-Forecast çæ°æ¡æ¶ãå®ä½¿ç¨å½±ååè½è­å¥æ¨¡çµï¼ä½¿ç¨å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) å°éäºåè½è­å¥çºæå­æè¿°ï¼ä¸¦é¨å¾å°éäºåè½æè¿°ç´å¥åºæ¼ LLM çé æ¸¬æ¨¡åä¸­ãçºäºè©ä¼°æåçæ¹æ³ï¼æåééä½¿ç¨å½±åæ´åç¾æçäºä»¶è³æé MidEast-TE-miniï¼å»ºæ§äºä¸åæ°çå¤æ¨¡æè³æé MidEast-TE-mmãå¯¦è­ç ç©¶è¡¨æï¼æåç MM-Forecast å¯ä»¥æ­£ç¢ºè­å¥å½±ååè½ï¼æ­¤å¤ï¼ç´å¥éäºæå­åè½æè¿°å¯ä»¥é¡¯èæ¹åé æ¸¬æè½ãè³æéãç¨å¼ç¢¼åæç¤ºå¯å¨ https://github.com/LuminosityX/MM-Forecast åå¾ã

##### **Judgment2vec: Apply Graph Analytics to Searching and Recommendation of Similar Judgments**
2408.04382v1 by Hsuan-Lei Shao

In court practice, legal professionals rely on their training to provide
opinions that resolve cases, one of the most crucial aspects being the ability
to identify similar judgments from previous courts efficiently. However,
finding a similar case is challenging and often depends on experience, legal
domain knowledge, and extensive labor hours, making veteran lawyers or judges
indispensable. This research aims to automate the analysis of judgment text
similarity. We utilized a judgment dataset labeled as the "golden standard" by
experts, which includes human-verified features that can be converted into an
"expert similarity score." We then constructed a knowledge graph based on
"case-article" relationships, ranking each case using natural language
processing to derive a "Node2vec similarity score." By evaluating these two
similarity scores, we identified their discrepancies and relationships. The
results can significantly reduce the labor hours required for legal searches
and recommendations, with potential applications extending to various fields of
information retrieval.

æè¦ï¼å¨æ³åº­å¯¦åä¸­ï¼æ³å¾å°æ¥­äººå£«ä¾è³´å¶å¹è¨æä¾æè¦ä»¥è§£æ±ºæ¡ä»¶ï¼å¶ä¸­æééµçæ¹é¢ä¹ä¸æ¯ææè­å¥ååæ³é¢çé¡ä¼¼å¤æ±ºçè½åãç¶èï¼æ¾åºé¡ä¼¼æ¡ä»¶å·æææ°æ§ï¼ä¸éå¸¸åæ±ºæ¼ç¶é©ãæ³å¾é åç¥è­åå¤§éçååæéï¼éä½¿å¾è³æ·±å¾å¸«ææ³å®ä¸å¯æç¼ºãæ¬ç ç©¶æ¨å¨èªååå¤æ±ºææ¬ç¸ä¼¼æ§çåæãæåå©ç¨å°å®¶æ¨è¨çºãé»éæ¨æºãçå¤æ±ºè³æéï¼å¶ä¸­åæ¬å¯è½æçºãå°å®¶ç¸ä¼¼æ§è©åãçäººå·¥é©è­ç¹å¾µãç¶å¾ï¼æåæ ¹æãæ¡ä¾-æ¢æãéä¿å»ºæ§ç¥è­åè­ï¼ä½¿ç¨èªç¶èªè¨èçå°æ¯åæ¡ä¾é²è¡æåï¼ä»¥å¾åºãNode2vec ç¸ä¼¼æ§è©åããééè©ä¼°éå©åç¸ä¼¼æ§è©åï¼æåæ¾åºå¶å·®ç°åéä¿ãçµæå¯ä»¥å¤§å¹æ¸å°æ³å¾æå°åå»ºè­°æéçååæéï¼æ½å¨æç¨ç¯åæ´åè³è¨æª¢ç´¢çååé åã

##### **Overview of the NLPCC 2024 Shared Task on Chinese Metaphor Generation**
2408.04378v1 by Xingwei Qu, Ge Zhang, Siwei Wu, Yizhi Li, Chenghua Lin

This paper presents the results of the shared task on Chinese metaphor
generation, hosted at the 13th CCF Conference on Natural Language Processing
and Chinese Computing (NLPCC 2024). The goal of this shared task is to generate
Chinese metaphors using machine learning techniques and effectively identifying
basic components of metaphorical sentences. It is divided into two subtasks: 1)
Metaphor Generation, which involves creating a metaphor from a provided tuple
consisting of TENOR, GROUND, and VEHICLE. The goal here is to synthesize a
metaphor that connects the subject (i.e. TENOR) with the object (i.e. VEHICLE),
guided by the concept of the GROUND. 2) Metaphor Components Identification,
which extracts the most fitting TENORs, GROUNDs, and VEHICLEs from a
metaphorical sentence. This component requires the identification of the most
fitting metaphor elements that correspond to the specified grounds. In addition
to overall results, we report on the setup and insights from the metaphor
generation shared task, which attracted a total of 4 participating teams across
both subtasks.

æè¦ï¼æ¬æå±ç¤ºäºå¨èªç¶èªè¨èçåä¸­æè¨ç®çç¬¬ 13 å±ä¸­åè¨ç®æ©è¯åææè­° (NLPCC 2024) ä¸èè¾¦çä¸­æé±å»çæå±äº«ä»»åççµæãæ­¤å±äº«ä»»åçç®æ¨æ¯ä½¿ç¨æ©å¨å­¸ç¿æè¡çæä¸­æé±å»ï¼ä¸¦ææè­å¥é±å»å¥å­çåºæ¬çµæé¨åãå®åçºå©åå­ä»»åï¼1) é±å»çæï¼åæ¬å¾æä¾çåå« TENORãGROUND å VEHICLE çåçµä¸­åµå»ºé±å»ãæ­¤èçç®æ¨æ¯ç¶åä¸åå°ä¸»é« (å³ TENOR) èå®¢é« (å³ VEHICLE) è¯ç¹«èµ·ä¾çé±å»ï¼ä¸¦ä»¥ GROUND çæ¦å¿µçºæå°ã2) é±å»çµæé¨åè­å¥ï¼å¾é±å»å¥å­ä¸­æåæåé©ç TENORãGROUND å VEHICLEãæ­¤çµæé¨åéè¦è­å¥èæå® GROUND ç¸æçæåé©é±å»åç´ ãé¤äºæ´é«çµæå¤ï¼æåéå ±åäºé±å»çæå±äº«ä»»åçè¨­ç½®åè¦è§£ï¼è©²ä»»åå±å¸å¼äº 4 ååèåéåèå©åå­ä»»åã

##### **Simulating Articulatory Trajectories with Phonological Feature Interpolation**
2408.04363v1 by Angelo Ortiz Tandazo, Thomas Schatz, Thomas Hueber, Emmanuel Dupoux

As a first step towards a complete computational model of speech learning
involving perception-production loops, we investigate the forward mapping
between pseudo-motor commands and articulatory trajectories. Two phonological
feature sets, based respectively on generative and articulatory phonology, are
used to encode a phonetic target sequence. Different interpolation techniques
are compared to generate smooth trajectories in these feature spaces, with a
potential optimisation of the target value and timing to capture
co-articulation effects. We report the Pearson correlation between a linear
projection of the generated trajectories and articulatory data derived from a
multi-speaker dataset of electromagnetic articulography (EMA) recordings. A
correlation of 0.67 is obtained with an extended feature set based on
generative phonology and a linear interpolation technique. We discuss the
implications of our results for our understanding of the dynamics of biological
motion.

æè¦ï¼ä½çºæåæ¶åç¥è¦º-ç¢çè¿´è·¯çå®æ´èªé³å­¸ç¿è¨ç®æ¨¡åéåºçç¬¬ä¸æ­¥ï¼æåç ç©¶äºå½åä½å½ä»¤åèªé³è»è·¡ä¹éçååæ å°ãå©åé³é»ç¹å¾µéåå¥åºæ¼çæé³é»å­¸åèªé³é³é»å­¸ï¼ç¨æ¼ç·¨ç¢¼é³æ¨ç®æ¨åºåãæ¯è¼ä¸åçæå¼æè¡ä»¥å¨éäºç¹å¾µç©ºéä¸­ç¢çå¹³æ»è»è·¡ï¼ä¸¦å°ç®æ¨å¼åæéé²è¡æ½å¨æä½³åä»¥ææå±ç¼é³ææãæåå ±åäºçæè»è·¡çç·æ§æå½±èå¾é»ç£èªé³æè¨ (EMA) è¨éçå¤èªªè©±èæ¸æéæ´¾ççèªé³æ¸æä¹éçç®ç¾æ£®ç¸éæ§ãä½¿ç¨åºæ¼çæé³é»å­¸åç·æ§æå¼æè¡çæ´å±ç¹å¾µéï¼ç²å¾ 0.67 çç¸éæ§ãæåè¨è«äºæåççµæå°æåçè§£çç©éåååå­¸çå½±é¿ã

##### **Towards Explainable Network Intrusion Detection using Large Language Models**
2408.04342v1 by Paul R. B. Houssel, Priyanka Singh, Siamak Layeghy, Marius Portmann

Large Language Models (LLMs) have revolutionised natural language processing
tasks, particularly as chat agents. However, their applicability to threat
detection problems remains unclear. This paper examines the feasibility of
employing LLMs as a Network Intrusion Detection System (NIDS), despite their
high computational requirements, primarily for the sake of explainability.
Furthermore, considerable resources have been invested in developing LLMs, and
they may offer utility for NIDS. Current state-of-the-art NIDS rely on
artificial benchmarking datasets, resulting in skewed performance when applied
to real-world networking environments. Therefore, we compare the GPT-4 and
LLama3 models against traditional architectures and transformer-based models to
assess their ability to detect malicious NetFlows without depending on
artificially skewed datasets, but solely on their vast pre-trained acquired
knowledge. Our results reveal that, although LLMs struggle with precise attack
detection, they hold significant potential for a path towards explainable NIDS.
Our preliminary exploration shows that LLMs are unfit for the detection of
Malicious NetFlows. Most promisingly, however, these exhibit significant
potential as complementary agents in NIDS, particularly in providing
explanations and aiding in threat response when integrated with Retrieval
Augmented Generation (RAG) and function calling capabilities.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¾¹åºæ¹è®äºèªç¶èªè¨èçä»»åï¼ç¹å¥æ¯ä½çºèå¤©æ©å¨äººãç¶èï¼å®åå¨å¨èåµæ¸¬åé¡ä¸­çé©ç¨æ§ä»ä¸ææãæ¬ææ¢è¨äºä½¿ç¨ LLM ä½çºç¶²è·¯å¥ä¾µåµæ¸¬ç³»çµ± (NIDS) çå¯è¡æ§ï¼åç®¡å®åçéç®éæ±å¾é«ï¼ä½ä¸»è¦æ¯çºäºå¯è§£éæ§ãæ­¤å¤ï¼å·²ç¶æå¥å¤§éè³æºéç¼ LLMï¼å®åå¯è½çº NIDS æä¾æç¨ãç®åæåé²ç NIDS ä¾è³´äººå·¥åºæºè³æéï¼å°è´å¨æç¨æ¼å¯¦éç¶²è·¯ç°å¢ææè½åå·®ãå æ­¤ï¼æåå° GPT-4 å LLaMa3 æ¨¡åèå³çµ±æ¶æ§ååºæ¼è½æå¨çæ¨¡åé²è¡æ¯è¼ï¼ä»¥è©ä¼°å®åå¨ä¸ä¾è³´äººå·¥åå·®è³æéï¼èåä¾è³´å®åé¾å¤§çé åè¨ç·´ç²å¾çç¥è­ä¾åµæ¸¬æ¡æ NetFlow çè½åãæåççµæé¡¯ç¤ºï¼åç®¡ LLM å¨ç²¾ç¢ºçæ»æåµæ¸¬æ¹é¢æå°é£ï¼ä½å®åå¨å¯è§£éç NIDS è·¯å¾æ¹é¢å·æé¡¯èçæ½åãæåçåæ­¥æ¢è¨è¡¨æï¼LLM ä¸é©ååµæ¸¬æ¡æç NetFlowãç¶èï¼æä»¤äººæ¯å¥®çæ¯ï¼éäºæ¨¡åä½çº NIDS ä¸­çè¼å©ä»£çå·æé¡¯èçæ½åï¼ç¹å¥æ¯å¨æä¾è§£éåå¨èæª¢ç´¢æ´åçæ (RAG) åå½å¼å¼å«åè½æ´åæåå©å¨èåææ¹é¢ã

##### **KnowPC: Knowledge-Driven Programmatic Reinforcement Learning for Zero-shot Coordination**
2408.04336v1 by Yin Gu, Qi Liu, Zhi Li, Kai Zhang

Zero-shot coordination (ZSC) remains a major challenge in the cooperative AI
field, which aims to learn an agent to cooperate with an unseen partner in
training environments or even novel environments. In recent years, a popular
ZSC solution paradigm has been deep reinforcement learning (DRL) combined with
advanced self-play or population-based methods to enhance the neural policy's
ability to handle unseen partners. Despite some success, these approaches
usually rely on black-box neural networks as the policy function. However,
neural networks typically lack interpretability and logic, making the learned
policies difficult for partners (e.g., humans) to understand and limiting their
generalization ability. These shortcomings hinder the application of
reinforcement learning methods in diverse cooperative scenarios.We suggest to
represent the agent's policy with an interpretable program. Unlike neural
networks, programs contain stable logic, but they are non-differentiable and
difficult to optimize.To automatically learn such programs, we introduce
Knowledge-driven Programmatic reinforcement learning for zero-shot Coordination
(KnowPC). We first define a foundational Domain-Specific Language (DSL),
including program structures, conditional primitives, and action primitives. A
significant challenge is the vast program search space, making it difficult to
find high-performing programs efficiently. To address this, KnowPC integrates
an extractor and an reasoner. The extractor discovers environmental transition
knowledge from multi-agent interaction trajectories, while the reasoner deduces
the preconditions of each action primitive based on the transition knowledge.

æè¦ï¼é¶æ¬¡å­¸ç¿åèª¿ (ZSC) ä»ç¶æ¯åä½ AI é åçä¸é éå¤§ææ°ï¼å¶ç®æ¨æ¯è®ä»£çå­¸ç¿èè¨ç·´ç°å¢çè³æ°ç©ç°å¢ä¸­æªè¦çåä½å¤¥ä¼´åä½ãè¿å¹´ä¾ï¼ä¸ç¨®æµè¡ç ZSC è§£æ±ºæ¹æ¡ç¯ä¾æ¯æ·±åº¦å¼·åå­¸ç¿ (DRL)ï¼çµååé²çèªæå°å¼æåºæ¼æç¾¤çæ¹æ³ï¼ä»¥å¢å¼·ç¥ç¶ç­ç¥èçæªè¦åä½å¤¥ä¼´çè½åãåç®¡åå¾ä¸äºæåï¼éäºæ¹æ³éå¸¸ä¾è³´é»çç¥ç¶ç¶²è·¯ä½çºç­ç¥å½æ¸ãç¶èï¼ç¥ç¶ç¶²è·¯éå¸¸ç¼ºä¹å¯è§£éæ§åéè¼¯ï¼éä½¿å¾åä½å¤¥ä¼´ï¼ä¾å¦äººé¡ï¼é£ä»¥çè§£æå­¸ç¿çç­ç¥ï¼ä¸¦éå¶å¶æ³åè½åãéäºç¼ºé»é»ç¤äºå¼·åå­¸ç¿æ¹æ³å¨åç¨®åä½å ´æ¯ä¸­çæç¨ãæåå»ºè­°ä½¿ç¨å¯è§£éç¨å¼è¡¨ç¤ºä»£ççç­ç¥ãèç¥ç¶ç¶²è·¯ä¸åï¼ç¨å¼åå«ç©©å®çéè¼¯ï¼ä½å®åä¸å¯å¾®åä¸é£ä»¥æä½³åãçºäºèªåå­¸ç¿æ­¤é¡ç¨å¼ï¼æåå¼å¥äºéå°é¶æ¬¡å­¸ç¿åèª¿çç¥è­é©åç¨å¼åå¼·åå­¸ç¿ (KnowPC)ãæåé¦åå®ç¾©äºä¸ååºç¤çç¹å®é åèªè¨ (DSL)ï¼åæ¬ç¨å¼çµæ§ãæ¢ä»¶åºæ¬åç´ ååä½åºæ¬åç´ ãä¸åéå¤§çææ°æ¯é¾å¤§çç¨å¼æå°ç©ºéï¼éä½¿å¾é£ä»¥æææ¾å°é«å·è¡æè½çç¨å¼ãçºäºè§£æ±ºéååé¡ï¼KnowPC æ´åäºä¸åèåå¨åä¸åæ¨çå¨ãèåå¨å¾å¤éä»£çäºåè»è·¡ä¸­ç¼ç¾ç°å¢è½æç¥è­ï¼èæ¨çå¨åæ ¹æè½æç¥è­æ¨è«æ¯ååä½åºæ¬åç´ çåææ¢ä»¶ã

##### **Enhancing Journalism with AI: A Study of Contextualized Image Captioning for News Articles using LLMs and LMMs**
2408.04331v1 by Aliki Anagnostopoulou, Thiago Gouvea, Daniel Sonntag

Large language models (LLMs) and large multimodal models (LMMs) have
significantly impacted the AI community, industry, and various economic
sectors. In journalism, integrating AI poses unique challenges and
opportunities, particularly in enhancing the quality and efficiency of news
reporting. This study explores how LLMs and LMMs can assist journalistic
practice by generating contextualised captions for images accompanying news
articles. We conducted experiments using the GoodNews dataset to evaluate the
ability of LMMs (BLIP-2, GPT-4v, or LLaVA) to incorporate one of two types of
context: entire news articles, or extracted named entities. In addition, we
compared their performance to a two-stage pipeline composed of a captioning
model (BLIP-2, OFA, or ViT-GPT2) with post-hoc contextualisation with LLMs
(GPT-4 or LLaMA). We assess a diversity of models, and we find that while the
choice of contextualisation model is a significant factor for the two-stage
pipelines, this is not the case in the LMMs, where smaller, open-source models
perform well compared to proprietary, GPT-powered ones. Additionally, we found
that controlling the amount of provided context enhances performance. These
results highlight the limitations of a fully automated approach and underscore
the necessity for an interactive, human-in-the-loop strategy.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) åå¤§åå¤æ¨¡ææ¨¡å (LMM) å·²é¡¯èå½±é¿äº AI ç¤¾ç¾¤ãç¢æ¥­ååç¨®ç¶æ¿é¨éãå¨æ°èæ¥­ä¸­ï¼æ´å AI æ§æäºç¨ç¹çææ°åæ©éï¼ç¹å¥æ¯å¨æåæ°èå ±å°çåè³ªåæçæ¹é¢ãæ¬ç ç©¶æ¢è¨äº LLM å LMM å¦ä½ééçºæ°èæç« éåç¢çæå¢åæ¨é¡ï¼ä¾åå©æ°èå¯¦åãæåä½¿ç¨ GoodNews è³æéé²è¡å¯¦é©ï¼ä»¥è©ä¼° LMMï¼BLIP-2ãGPT-4v æ LLaVAï¼ç´å¥å©ç¨®æå¢é¡åï¼æ´ç¯æ°èæç« ææ½åçå½åå¯¦é«ï¼çè½åãæ­¤å¤ï¼æåå°å¶æè½èç±æ¨é¡æ¨¡åï¼BLIP-2ãOFA æ ViT-GPT2ï¼çµæçå©éæ®µç®¡ç·é²è¡æ¯è¼ï¼ä¸¦æ­é LLMï¼GPT-4 æ LLaMAï¼é²è¡äºå¾æå¢åãæåè©ä¼°äºåç¨®æ¨¡åï¼ç¼ç¾éç¶æå¢åæ¨¡åçé¸ææ¯å©éæ®µç®¡ç·çéè¦å ç´ ï¼ä½å¨ LMM ä¸­ä¸¦éå¦æ­¤ï¼å¶ä¸­è¼å°åãéæ¾åå§ç¢¼çæ¨¡åè¡¨ç¾è¯å¥½ï¼åªæ¼å°æç GPT é©åæ¨¡åãæ­¤å¤ï¼æåç¼ç¾æ§å¶æä¾çèçµ¡æ¸éææåæè½ãéäºçµæçªé¡¯äºå¨èªååæ¹æ³çéå¶ï¼ä¸¦å¼·èª¿äºäºåå¼ãäººé¡åèç­ç¥çå¿è¦æ§ã

##### **HydraFormer: One Encoder For All Subsampling Rates**
2408.04325v1 by Yaoxun Xu, Xingchen Song, Zhiyong Wu, Di Wu, Zhendong Peng, Binbin Zhang

In automatic speech recognition, subsampling is essential for tackling
diverse scenarios. However, the inadequacy of a single subsampling rate to
address various real-world situations often necessitates training and deploying
multiple models, consequently increasing associated costs. To address this
issue, we propose HydraFormer, comprising HydraSub, a Conformer-based encoder,
and a BiTransformer-based decoder. HydraSub encompasses multiple branches, each
representing a distinct subsampling rate, allowing for the flexible selection
of any branch during inference based on the specific use case. HydraFormer can
efficiently manage different subsampling rates, significantly reducing training
and deployment expenses. Experiments on AISHELL-1 and LibriSpeech datasets
reveal that HydraFormer effectively adapts to various subsampling rates and
languages while maintaining high recognition performance. Additionally,
HydraFormer showcases exceptional stability, sustaining consistent performance
under various initialization conditions, and exhibits robust transferability by
learning from pretrained single subsampling rate automatic speech recognition
models\footnote{Model code and scripts:
https://github.com/HydraFormer/hydraformer}.

æè¦ï¼å¨èªåèªé³è¾¨è­ä¸­ï¼æ¬¡æ½æ¨£å°æ¼èçåç¨®å ´æ¯è³ééè¦ãç¶èï¼å®ä¸æ½æ¨£çä¸è¶³ä»¥æå°åç¨®ç¾å¯¦ä¸çççæ³ï¼éå¸¸éè¦è¨ç·´åé¨ç½²å¤åæ¨¡åï¼å¾èå¢å ç¸éææ¬ãçºäºè§£æ±ºéååé¡ï¼æåæåºäº HydraFormerï¼å®åå«ä¸ååºæ¼ Conformer çç·¨ç¢¼å¨ HydraSub åä¸ååºæ¼ BiTransformer çè§£ç¢¼å¨ãHydraSub æ¶µèå¤ååæ¯ï¼æ¯ååæ¯ä»£è¡¨ä¸åä¸åçæ½æ¨£çï¼åè¨±å¨æ¨çéç¨ä¸­æ ¹æå·é«ç¨ä¾éæ´»å°é¸æä»»ä½åæ¯ãHydraFormer å¯ä»¥ææå°ç®¡çä¸åçæ½æ¨£çï¼é¡¯èéä½è¨ç·´åé¨ç½²è²»ç¨ãå¨ AISHELL-1 å LibriSpeech æ¸æéä¸çå¯¦é©è¡¨æï¼HydraFormer å¯ä»¥ææå°é©æåç¨®æ½æ¨£çåèªè¨ï¼åæä¿æè¼é«çè¾¨è­æ§è½ãæ­¤å¤ï¼HydraFormer å±ç¾åºåè¶çç©©å®æ§ï¼å¨åç¨®åå§åæ¢ä»¶ä¸é½è½ä¿æä¸è´çæ§è½ï¼ä¸¦ééå¾é è¨ç·´çå®æ½æ¨£çèªåèªé³è¾¨è­æ¨¡åä¸­å­¸ç¿ï¼å±ç¾åºå¼·å¤§çå¯ç§»æ¤æ§ã

##### **Learning with Digital Agents: An Analysis based on the Activity Theory**
2408.04304v1 by Mateusz Dolata, Dzmitry Katsiuba, Natalie Wellnhammer, Gerhard Schwabe

Digital agents are considered a general-purpose technology. They spread
quickly in private and organizational contexts, including education. Yet,
research lacks a conceptual framing to describe interaction with such agents in
a holistic manner. While focusing on the interaction with a pedagogical agent,
i.e., a digital agent capable of natural-language interaction with a learner,
we propose a model of learning activity based on activity theory. We use this
model and a review of prior research on digital agents in education to analyze
how various characteristics of the activity, including features of a
pedagogical agent or learner, influence learning outcomes. The analysis leads
to identification of IS research directions and guidance for developers of
pedagogical agents and digital agents in general. We conclude by extending the
activity theory-based model beyond the context of education and show how it
helps designers and researchers ask the right questions when creating a digital
agent.

æè¦ï¼æ¸ä½ä»£çè¢«è¦çºä¸ç¨®éç¨æè¡ãå®åå¨ç§äººåçµç¹ç°å¢ä¸­è¿éå³æ­ï¼åæ¬æè²ãç¶èï¼ç ç©¶ç¼ºä¹ä¸åæ¦å¿µæ¡æ¶ä¾æè¿°èæ­¤é¡ä»£çäºåçæ´é«æ¹å¼ãéç¶å°æ³¨æ¼èæå­¸ä»£ççäºåï¼å³ä¸ç¨®è½å¤ èå­¸ç¿èé²è¡èªç¶èªè¨äºåçæ¸ä½ä»£çï¼æåæ ¹ææ´»åçè«æåºäºä¸åå­¸ç¿æ´»åæ¨¡åãæåä½¿ç¨æ­¤æ¨¡ååå°æè²ä¸­æ¸ä½ä»£ççååç ç©¶çåé¡§ä¾åææ´»åçåç¨®ç¹å¾µï¼åæ¬æå­¸ä»£çæå­¸ç¿èçç¹å¾µï¼å¦ä½å½±é¿å­¸ç¿ææãåæå°è´è­å¥è³è¨ç³»çµ±ç ç©¶æ¹ååå°æå­¸ä»£çåä¸è¬æ¸ä½ä»£çéç¼äººå¡çæå°ãæåæå¾æ´å±äºåºæ¼æ´»åçè«çæ¨¡åï¼è¶è¶æè²çç¯çï¼ä¸¦å±ç¤ºå®å¦ä½å¹«å©è¨­è¨å¸«åç ç©¶äººå¡å¨å»ºç«æ¸ä½ä»£çææåºæ­£ç¢ºçåé¡ã

##### **Trans-Tokenization and Cross-lingual Vocabulary Transfers: Language Adaptation of LLMs for Low-Resource NLP**
2408.04303v1 by FranÃ§ois Remy, Pieter Delobelle, Hayastan Avetisyan, Alfiya Khabibullina, Miryam de Lhoneux, Thomas Demeester

The development of monolingual language models for low and mid-resource
languages continues to be hindered by the difficulty in sourcing high-quality
training data. In this study, we present a novel cross-lingual vocabulary
transfer strategy, trans-tokenization, designed to tackle this challenge and
enable more efficient language adaptation. Our approach focuses on adapting a
high-resource monolingual LLM to an unseen target language by initializing the
token embeddings of the target language using a weighted average of
semantically similar token embeddings from the source language. For this, we
leverage a translation resource covering both the source and target languages.
We validate our method with the Tweeties, a series of trans-tokenized LLMs, and
demonstrate their competitive performance on various downstream tasks across a
small but diverse set of languages. Additionally, we introduce Hydra LLMs,
models with multiple swappable language modeling heads and embedding tables,
which further extend the capabilities of our trans-tokenization strategy. By
designing a Hydra LLM based on the multilingual model TowerInstruct, we
developed a state-of-the-art machine translation model for Tatar, in a
zero-shot manner, completely bypassing the need for high-quality parallel data.
This breakthrough is particularly significant for low-resource languages like
Tatar, where high-quality parallel data is hard to come by. By lowering the
data and time requirements for training high-quality models, our
trans-tokenization strategy allows for the development of LLMs for a wider
range of languages, especially those with limited resources. We hope that our
work will inspire further research and collaboration in the field of
cross-lingual vocabulary transfer and contribute to the empowerment of
languages on a global scale.

æè¦ï¼<paragraph>ä½è³æºåä¸­è³æºèªè¨çå®èªèªè¨æ¨¡åçéç¼ï¼æçºåå°é«åè³ªè¨ç·´è³æä¾æºçå°é£æé»ç¤ãå¨éé ç ç©¶ä¸­ï¼æåæåºäºä¸åæ°ç©çè·¨èªè¨è©å½è½ç§»ç­ç¥ï¼ç¨±çºè·¨æ¨è¨åï¼æ¨å¨è§£æ±ºéåææ°ï¼ä¸¦å¯¦ç¾æ´ææççèªè¨é©æãæåçåæ³èéæ¼ééä½¿ç¨ä¾èªä¾æºèªè¨çèªç¾©ç¸ä¼¼æ¨è¨åµå¥çå æ¬å¹³åå¼ï¼å°é«è³æºå®èª LLM é©æå°æªè¦çç®æ¨èªè¨ï¼ä¾åå§åç®æ¨èªè¨çæ¨è¨åµå¥ãçºæ­¤ï¼æåå©ç¨æ¶µèä¾æºèªè¨åç®æ¨èªè¨çç¿»è­¯è³æºãæåä½¿ç¨ä¸ç³»åè·¨æ¨è¨å LLMï¼ä¹å°±æ¯ Tweetiesï¼é©è­æåçæ¨¡åï¼ä¸¦å¨åç¨®ä¸æ¸¸ä»»åä¸­ï¼æ¼ä¸çµæ¸éå°ä½å¤æ¨£åçèªè¨ä¸­ï¼å±ç¤ºåºå®åå·æç«¶ç­åçè¡¨ç¾ãæ­¤å¤ï¼æåå¼å¥äº Hydra LLMï¼éæ¯ä¸ç¨®å·æå¤åå¯äº¤æèªè¨æ¨¡åé ­ååµå¥è¡¨çæ¨¡åï¼é²ä¸æ­¥æ´å±äºæåçè·¨æ¨è¨åç­ç¥çåè½ãééæ ¹æå¤èªè¨æ¨¡å TowerInstruct è¨­è¨ Hydra LLMï¼æåéç¼äºä¸åæåé²çéé¼èªæ©å¨ç¿»è­¯æ¨¡åï¼ä»¥é¶æ¬¡å­¸ç¿çæ¹å¼ï¼å®å¨ç¹éå°é«åè³ªå¹³è¡è³æçéæ±ãå°æ¼åéé¼èªéç¨®é«åè³ªå¹³è¡è³æé£ä»¥åå¾çä½è³æºèªè¨èè¨ï¼éåçªç ´ç¹å¥éè¦ãéééä½è¨ç·´é«åè³ªæ¨¡åçè³æåæééæ±ï¼æåçè·¨æ¨è¨åç­ç¥åè¨±çºæ´å¤èªè¨éç¼ LLMï¼ç¹å¥æ¯é£äºè³æºæéçèªè¨ãæåå¸ææåçç ç©¶è½æ¿åµè·¨èªè¨è©å½è½ç§»é åé²ä¸æ­¥çç ç©¶ååä½ï¼ä¸¦æå©æ¼å¨å¨çç¯åå§è³¦è½èªè¨ã</paragraph>

##### **Tackling Noisy Clients in Federated Learning with End-to-end Label Correction**
2408.04301v1 by Xuefeng Jiang, Sheng Sun, Jia Li, Jingjing Xue, Runhan Li, Zhiyuan Wu, Gang Xu, Yuwei Wang, Min Liu

Recently, federated learning (FL) has achieved wide successes for diverse
privacy-sensitive applications without sacrificing the sensitive private
information of clients. However, the data quality of client datasets can not be
guaranteed since corresponding annotations of different clients often contain
complex label noise of varying degrees, which inevitably causes the performance
degradation. Intuitively, the performance degradation is dominated by clients
with higher noise rates since their trained models contain more misinformation
from data, thus it is necessary to devise an effective optimization scheme to
mitigate the negative impacts of these noisy clients. In this work, we propose
a two-stage framework FedELC to tackle this complicated label noise issue. The
first stage aims to guide the detection of noisy clients with higher label
noise, while the second stage aims to correct the labels of noisy clients' data
via an end-to-end label correction framework which is achieved by learning
possible ground-truth labels of noisy clients' datasets via back propagation.
We implement sixteen related methods and evaluate five datasets with three
types of complicated label noise scenarios for a comprehensive comparison.
Extensive experimental results demonstrate our proposed framework achieves
superior performance than its counterparts for different scenarios.
Additionally, we effectively improve the data quality of detected noisy
clients' local datasets with our label correction framework. The code is
available at https://github.com/Sprinter1999/FedELC.

æè¦ï¼è¿å¹´æ¥ï¼èé¦å­¦ä¹  (FL) å¨ä¸çºç²å®¢æ·ç«¯ææçç§äººä¿¡æ¯çæåµä¸ï¼å¨åç§æ³¨ééç§çåºç¨ç¨åºä¸­åå¾äºå¹¿æ³çæåãç¶èï¼ç±äºä¸åå®¢æ·ç«¯çç¸åºæ³¨ééå¸¸åå«ä¸åç¨åº¦çå¤ææ ç­¾åªå£°ï¼å æ­¤æ æ³ä¿è¯å®¢æ·ç«¯æ°æ®éçæ°æ®è´¨éï¼è¿ä¸å¯é¿åå°ä¼å¯¼è´æ§è½ä¸éãç´è§å°è¯´ï¼æ§è½ä¸éä¸»è¦ç±åªå£°çè¾é«çå®¢æ·ç«¯ä¸»å¯¼ï¼å ä¸ºä»ä»¬è®­ç»çæ¨¡ååå«æ´å¤æ¥èªæ°æ®éè¯¯ä¿¡æ¯ï¼å æ­¤æå¿è¦è®¾è®¡ä¸ä¸ªææçä¼åæ¹æ¡æ¥åè½»è¿äºåªå£°å®¢æ·ç«¯çè´é¢å½±åãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬æåºäºä¸ä¸ªä¸¤é¶æ®µæ¡æ¶ FedELC æ¥è§£å³è¿ä¸ªå¤æçæ ç­¾åªå£°é®é¢ãç¬¬ä¸é¶æ®µæ¨å¨æå¯¼æ£æµæ ç­¾åªå£°è¾é«çåªå£°å®¢æ·ç«¯ï¼èç¬¬äºé¶æ®µæ¨å¨éè¿ç«¯å°ç«¯æ ç­¾æ ¡æ­£æ¡æ¶æ¥æ ¡æ­£åªå£°å®¢æ·ç«¯æ°æ®çæ ç­¾ï¼è¿æ¯éè¿ååä¼ æ­å­¦ä¹ åªå£°å®¢æ·ç«¯æ°æ®éçå¯è½çå®æ ç­¾æ¥å®ç°çãæä»¬å®ç°äºåå­ç§ç¸å³æ¹æ³ï¼å¹¶ä½¿ç¨äºç§æ°æ®éè¯ä¼°äºä¸ç§ç±»åçå¤ææ ç­¾åªå£°åºæ¯ï¼ä»¥è¿è¡å¨é¢æ¯è¾ãå¤§éçå®éªç»æè¡¨æï¼æä»¬æåºçæ¡æ¶å¨ä¸ååºæ¯ä¸æ¯å¶å¯¹åºæ¡æ¶å®ç°äºæ´å¥½çæ§è½ãæ­¤å¤ï¼æä»¬éè¿æ ç­¾æ ¡æ­£æ¡æ¶ææå°æé«äºæ£æµå°çåªå£°å®¢æ·ç«¯æ¬å°æ°æ®éçæ°æ®è´¨éãä»£ç å¯å¨ https://github.com/Sprinter1999/FedELC ä¸­è·å¾ã

##### **Are Social Sentiments Inherent in LLMs? An Empirical Study on Extraction of Inter-demographic Sentiments**
2408.04293v1 by Kunitomo Tanaka, Ryohei Sasano, Koichi Takeda

Large language models (LLMs) are supposed to acquire unconscious human
knowledge and feelings, such as social common sense and biases, by training
models from large amounts of text. However, it is not clear how much the
sentiments of specific social groups can be captured in various LLMs. In this
study, we focus on social groups defined in terms of nationality, religion, and
race/ethnicity, and validate the extent to which sentiments between social
groups can be captured in and extracted from LLMs. Specifically, we input
questions regarding sentiments from one group to another into LLMs, apply
sentiment analysis to the responses, and compare the results with social
surveys. The validation results using five representative LLMs showed higher
correlations with relatively small p-values for nationalities and religions,
whose number of data points were relatively large. This result indicates that
the LLM responses including the inter-group sentiments align well with actual
social survey results.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ééå¾å¤§éçæå­è¨ç·´æ¨¡åï¼åè¨­æç¿å¾ç¡æè­çäººé¡ç¥è­åæåï¼ä¾å¦ç¤¾æå¸¸è­ååè¦ãç¶èï¼å°ä¸æ¸æ¥ç¹å®ç¤¾æç¾¤é«çæç·å¯ä»¥å¨ä¸å LLM ä¸­è¢«ææå°å¤å°ãå¨æ¬ç ç©¶ä¸­ï¼æåå°æ³¨æ¼ä»¥åç±ãå®æåç¨®æ/æ°æå®ç¾©çç¤¾æç¾¤é«ï¼ä¸¦é©è­äº LLM ä¸­å¯ä»¥ææåæåç¤¾æç¾¤é«ä¹éæç·çç¨åº¦ãå·é«ä¾èªªï¼æåå°éæ¼ä¸çµå°å¦ä¸çµçæç·åé¡è¼¸å¥ LLMï¼å°åæé²è¡æç·åæï¼ä¸¦å°çµæèç¤¾æèª¿æ¥é²è¡æ¯è¼ãä½¿ç¨äºåä»£è¡¨æ§ LLM é²è¡é©è­ççµæé¡¯ç¤ºï¼åç±åå®æçæç·ç¸éæ§è¼é«ï¼ä¸ p å¼ç¸å°è¼å°ï¼å¶æ¸æé»æ¸éç¸å°è¼å¤§ãæ­¤çµæè¡¨æï¼åæ¬ç¾¤éæç·å¨å§ç LLM åæèå¯¦éç¤¾æèª¿æ¥çµæéå¸¸å»åã

##### **EMTeC: A Corpus of Eye Movements on Machine-Generated Texts**
2408.04289v1 by Lena Sophia Bolliger, Patrick Haller, Isabelle Caroline Rose Cretton, David Robert Reich, Tannon Kew, Lena Ann JÃ¤ger

The Eye Movements on Machine-Generated Texts Corpus (EMTeC) is a naturalistic
eye-movements-while-reading corpus of 107 native English speakers reading
machine-generated texts. The texts are generated by three large language models
using five different decoding strategies, and they fall into six different text
type categories. EMTeC entails the eye movement data at all stages of
pre-processing, i.e., the raw coordinate data sampled at 2000 Hz, the fixation
sequences, and the reading measures. It further provides both the original and
a corrected version of the fixation sequences, accounting for vertical
calibration drift. Moreover, the corpus includes the language models' internals
that underlie the generation of the stimulus texts: the transition scores, the
attention scores, and the hidden states. The stimuli are annotated for a range
of linguistic features both at text and at word level. We anticipate EMTeC to
be utilized for a variety of use cases such as, but not restricted to, the
investigation of reading behavior on machine-generated text and the impact of
different decoding strategies; reading behavior on different text types; the
development of new pre-processing, data filtering, and drift correction
algorithms; the cognitive interpretability and enhancement of language models;
and the assessment of the predictive power of surprisal and entropy for human
reading times. The data at all stages of pre-processing, the model internals,
and the code to reproduce the stimulus generation, data pre-processing and
analyses can be accessed via https://github.com/DiLi-Lab/EMTeC/.

æè¦ï¼<paragraph>æ©è­¯ææ¬èªæåº«ä¸­çç¼çéå (EMTeC) æ¯ä¸åèªç¶ä¸»ç¾©èªæåº«ï¼åå« 107 ä½è±èªæ¯èªäººå£«å¨é±è®æ©å¨ç¢ççææ¬æçè¦ç·éåãéäºææ¬ç±ä¸åå¤§åèªè¨æ¨¡åä½¿ç¨äºç¨®ä¸åçè§£ç¢¼ç­ç¥ç¢çï¼ä¸¦åçºå­ç¨®é¡åçææ¬ãEMTeC åå«é èçææéæ®µçç¼çéåæ¸æï¼å³ä»¥ 2000 èµ«è²æ¡æ¨£çåå§åæ¨æ¸æãæ³¨è¦åºååé±è®æ¸¬éãå®é²ä¸æ­¥æä¾äºæ³¨è¦åºåçåå§çæ¬åæ ¡æ­£çæ¬ï¼ä¸¦èæ®äºåç´æ ¡æºæ¼ç§»ãæ­¤å¤ï¼èªæåº«éåæ¬çæåºæ¿ææ¬çèªè¨æ¨¡åå§é¨ï¼è½æåæ¸ãæ³¨æååæ¸åé±èçæãåºæ¿ç©ææ ¹æææ¬åè©å½å±¤ç´çåç¨®èªè¨ç¹å¾µé²è¡æ¨è¨»ãæåé æ EMTeC å¯ç¨æ¼åç¨®ä½¿ç¨æ¡ä¾ï¼ä¾å¦ï¼ä½ä¸éæ¼ï¼èª¿æ¥æ©å¨ç¢ççææ¬ä¸çé±è®è¡çºä»¥åä¸åè§£ç¢¼ç­ç¥çå½±é¿ï¼ä¸åææ¬é¡åä¸çé±è®è¡çºï¼éç¼æ°çé èçãæ¸æéæ¿¾åæ¼ç§»æ ¡æ­£æ¼ç®æ³ï¼èªè¨æ¨¡åçèªç¥å¯è§£éæ§åå¢å¼·ï¼ä»¥åè©ä¼°é©è¨åº¦åçµå°äººé¡é±è®æéçé æ¸¬è½åãå¯ä»¥å¨ https://github.com/DiLi-Lab/EMTeC/ è¨ªåé èçææéæ®µçæ¸æãæ¨¡åå§é¨ä»¥åç¨æ¼éç¾åºæ¿çæãæ¸æé èçååæçç¨å¼ç¢¼ã</paragraph>

##### **LLM-DetectAIve: a Tool for Fine-Grained Machine-Generated Text Detection**
2408.04284v1 by Mervat Abassy, Kareem Elozeiri, Alexander Aziz, Minh Ngoc Ta, Raj Vardhan Tomar, Bimarsha Adhikari, Saad El Dine Ahmed, Yuxia Wang, Osama Mohammed Afzal, Zhuohan Xie, Jonibek Mansurov, Ekaterina Artemova, Vladislav Mikhailov, Rui Xing, Jiahui Geng, Hasan Iqbal, Zain Muhammad Mujahid, Tarek Mahmoud, Akim Tsvigun, Alham Fikri Aji, Artem Shelmanov, Nizar Habash, Iryna Gurevych, Preslav Nakov

The widespread accessibility of large language models (LLMs) to the general
public has significantly amplified the dissemination of machine-generated texts
(MGTs). Advancements in prompt manipulation have exacerbated the difficulty in
discerning the origin of a text (human-authored vs machinegenerated). This
raises concerns regarding the potential misuse of MGTs, particularly within
educational and academic domains. In this paper, we present
$\textbf{LLM-DetectAIve}$ -- a system designed for fine-grained MGT detection.
It is able to classify texts into four categories: human-written,
machine-generated, machine-written machine-humanized, and human-written
machine-polished. Contrary to previous MGT detectors that perform binary
classification, introducing two additional categories in LLM-DetectiAIve offers
insights into the varying degrees of LLM intervention during the text creation.
This might be useful in some domains like education, where any LLM intervention
is usually prohibited. Experiments show that LLM-DetectAIve can effectively
identify the authorship of textual content, proving its usefulness in enhancing
integrity in education, academia, and other domains. LLM-DetectAIve is publicly
accessible at https://huggingface.co/spaces/raj-tomar001/MGT-New. The video
describing our system is available at https://youtu.be/E8eT_bE7k8c.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è¢«å»£æ³æç¨æ¼å¤§ç¾ï¼å¤§å¹æ´å¤§äºæ©å¨ç¢ççææ¬ (MGT) çå³æ­ãæç¤ºæä½çé²æ­¥å åäºè¾¨å¥ææ¬ä¾æºï¼äººå·¥æ°å¯«èæ©å¨ç¢çï¼çé£åº¦ãéå¼èµ·äºå° MGT å¯è½è¢«æ¿«ç¨çææï¼ç¹å¥æ¯å¨æè²åå­¸è¡é åãå¨æ¬æä¸­ï¼æåæåºäº $\textbf{LLM-DetectAIve}$ï¼ä¸åå°éè¨­è¨ç¨æ¼ç²¾ç´° MGT æª¢æ¸¬çç³»çµ±ãå®è½å¤ å°ææ¬åé¡çºåç¨®é¡å¥ï¼äººå·¥æ°å¯«ãæ©å¨ç¢çãæ©å¨æ°å¯«äººå·¥åï¼ä»¥åäººå·¥æ°å¯«æ©å¨æ½¤é£¾ãèå·è¡äºååé¡çåå MGT æª¢æ¸¬å¨ç¸åï¼å¨ LLM-DetectiAIve ä¸­å¼å¥å©åé¡å¤çé¡å¥ï¼æä¾äºå°ææ¬åµå»ºéç¨ä¸­ LLM ä»å¥ç¨åº¦çä¸åè¦è§£ãéå¯è½å¨æäºé åï¼å¦æè²ï¼ä¸­å¾æç¨ï¼å¨éäºé åä¸­éå¸¸ç¦æ­¢ä»»ä½ LLM ä»å¥ãå¯¦é©è¡¨æï¼LLM-DetectAIve å¯ä»¥ææè­å¥ææ¬å§å®¹çä½èï¼è­æäºå®å¨å å¼·æè²ãå­¸è¡åå¶ä»é åçèª ä¿¡æ¹é¢çæç¨æ§ãLLM-DetectAIve å¯å¨ https://huggingface.co/spaces/raj-tomar001/MGT-New å¬éç²å¾ãæè¿°æåç³»çµ±çå½±çå¯å¨ https://youtu.be/E8eT_bE7k8c åå¾ã

##### **LaDiMo: Layer-wise Distillation Inspired MoEfier**
2408.04278v1 by Sungyoon Kim, Youngjun Kim, Kihyo Moon, Minsung Jang

The advent of large language models has revolutionized natural language
processing, but their increasing complexity has led to substantial training
costs, resource demands, and environmental impacts. In response, sparse
Mixture-of-Experts (MoE) models have emerged as a promising alternative to
dense models. Since training MoE models from scratch can be prohibitively
expensive, recent studies have explored leveraging knowledge from pre-trained
non-MoE models. However, existing approaches have limitations, such as
requiring significant hardware resources and data. We propose a novel
algorithm, LaDiMo, which efficiently converts a Transformer-based non-MoE model
into a MoE model with minimal additional training cost. LaDiMo consists of two
stages: layer-wise expert construction and routing policy decision. By
harnessing the concept of Knowledge Distillation, we compress the model and
rapidly recover its performance. Furthermore, we develop an adaptive router
that optimizes inference efficiency by profiling the distribution of routing
weights and determining a layer-wise policy that balances accuracy and latency.
We demonstrate the effectiveness of our method by converting the LLaMA2-7B
model to a MoE model using only 100K tokens, reducing activated parameters by
over 20% while keeping accuracy. Our approach offers a flexible and efficient
solution for building and deploying MoE models.

æè¦ï¼å¤§åèªè¨æ¨¡åçåºç¾å¾¹åºæ¹è®äºèªç¶èªè¨èçï¼ä½å®åæ¥çå¢é·çè¤éæ§å°è´äºå¤§éçè¨ç·´ææ¬ãè³æºéæ±åç°å¢å½±é¿ãçºäºè§£æ±ºéååé¡ï¼ç¨çæ··åå°å®¶ (MoE) æ¨¡åå·²æçºç¨ å¯æ¨¡åçæåéçæ¿ä»£æ¹æ¡ãç±æ¼å¾é ­éå§è¨ç·´ MoE æ¨¡åå¯è½æéå¸¸æè²´ï¼å æ­¤æè¿çç ç©¶æ¢ç´¢äºå©ç¨é è¨ç·´é MoE æ¨¡åçç¥è­ãç¶èï¼ç¾ææ¹æ³å­å¨å±éæ§ï¼ä¾å¦éè¦å¤§éçç¡¬é«è³æºåè³æãæåæåºäºä¸ç¨®æ°æ¼ç®æ³ LaDiMoï¼å®å¯ä»¥ææå°å°åºæ¼ Transformer çé MoE æ¨¡åè½æçº MoE æ¨¡åï¼èé¡å¤çè¨ç·´ææ¬æ¥µä½ãLaDiMo åå«å©åéæ®µï¼éå±¤å°å®¶æ§é åè·¯ç±ç­ç¥æ±ºç­ãééå©ç¨ç¥è­è¸é¤¾çæ¦å¿µï¼æåå£ç¸®æ¨¡åä¸¦å¿«éæ¢å¾©å¶æè½ãæ­¤å¤ï¼æåéç¼äºä¸åèªé©æè·¯ç±å¨ï¼å®ééåæè·¯ç±æ¬éçåä½ä¸¦ç¢ºå®å¹³è¡¡æºç¢ºæ§åå»¶é²çéå±¤ç­ç¥ï¼ä¾æä½³åæ¨çæçãæåééä½¿ç¨å 100K åç¬¦èå° LLaMA2-7B æ¨¡åè½æçº MoE æ¨¡åä¾è­ææåæ¹æ³çæææ§ï¼å¨ä¿ææºç¢ºæ§çåæï¼å°å·²åç¨çåæ¸æ¸å°äº 20% ä»¥ä¸ãæåçåæ³çºå»ºæ§åé¨ç½² MoE æ¨¡åæä¾äºä¸åéæ´»ä¸ææççè§£æ±ºæ¹æ¡ã

##### **Analysis of Argument Structure Constructions in the Large Language Model BERT**
2408.04270v1 by Pegah Ramezani, Achim Schilling, Patrick Krauss

This study investigates how BERT processes and represents Argument Structure
Constructions (ASCs), extending previous LSTM analyses. Using a dataset of 2000
sentences across four ASC types (transitive, ditransitive, caused-motion,
resultative), we analyzed BERT's token embeddings across 12 layers.
Visualizations with MDS and t-SNE and clustering quantified by Generalized
Discrimination Value (GDV) were used. Feedforward classifiers (probes)
predicted construction categories from embeddings. CLS token embeddings
clustered best in layers 2-4, decreased in intermediate layers, and slightly
increased in final layers. DET and SUBJ embeddings showed consistent clustering
in intermediate layers, VERB embeddings increased in clustering from layer 1 to
12, and OBJ embeddings peaked in layer 10. Probe accuracies indicated low
construction information in layer 1, with over 90 percent accuracy from layer 2
onward, revealing latent construction information beyond GDV clustering. Fisher
Discriminant Ratio (FDR) analysis of attention weights showed OBJ tokens were
crucial for differentiating ASCs, followed by VERB and DET tokens. SUBJ, CLS,
and SEP tokens had insignificant FDR scores. This study highlights BERT's
layered processing of linguistic constructions and its differences from LSTMs.
Future research will compare these findings with neuroimaging data to
understand the neural correlates of ASC processing. This research underscores
neural language models' potential to mirror linguistic processing in the human
brain, offering insights into the computational and neural mechanisms
underlying language understanding.

æè¦ï¼æ¬ç ç©¶æ¢è¨ BERT å¦ä½èçåè¡¨ç¤ºè«è­çµæ§æ§ä½ (ASC)ï¼ä¸¦æ´å±ååç LSTM åæãæåä½¿ç¨åå«åç¨® ASC é¡åç 2000 åå¥å­çè³æéï¼åç©ãéåç©ãè´ä½¿åæãçµæï¼ï¼åæäº BERT å¨ 12 å±¤ä¸­çæ¨è¨åµå¥ãæåä½¿ç¨äº MDS å t-SNE è¦è¦ºåä»¥åç±å»£ç¾©ååå¼ (GDV) éåçåç¾¤ãåé¥åé¡å¨ï¼æ¢æ¸¬å¨ï¼æ ¹æåµå¥é æ¸¬æ§ä½é¡å¥ãCLS æ¨è¨åµå¥å¨ç¬¬ 2-4 å±¤ä¸­æä½³åç¾¤ï¼å¨ä¸­éå±¤ä¸­æ¸å°ï¼å¨æå¾ä¸å±¤ä¸­ç¥æå¢å ãDET å SUBJ åµå¥å¨ä¸­éå±¤ä¸­é¡¯ç¤ºä¸è´çåç¾¤ï¼VERB åµå¥å¾ç¬¬ 1 å±¤å°ç¬¬ 12 å±¤çåç¾¤å¢å ï¼è OBJ åµå¥å¨ç¬¬ 10 å±¤éå°å³°å¼ãæ¢æ¸¬æºç¢ºåº¦è¡¨æç¬¬ 1 å±¤ä¸­çæ§ä½è³è¨è¼ä½ï¼å¾ç¬¬ 2 å±¤éå§æºç¢ºåº¦è¶é 90%ï¼æ­ç¤ºäºè¶è¶ GDV åç¾¤çæ½å¨æ§ä½è³è¨ãæ³¨æåæ¬éç Fisher å¤å¥æ¯ (FDR) åæé¡¯ç¤ºï¼OBJ æ¨è¨å°æ¼åå ASC è³ééè¦ï¼å¶æ¬¡æ¯ VERB å DET æ¨è¨ãSUBJãCLS å SEP æ¨è¨ç FDR åæ¸å¾®ä¸è¶³éãæ¬ç ç©¶å¼·èª¿äº BERT å°èªè¨æ§ä½çåå±¤èçåå¶è LSTM çåå¥ãæªä¾çç ç©¶å°æéäºç¼ç¾èç¥ç¶å½±åè³æé²è¡æ¯è¼ï¼ä»¥äºè§£ ASC èççç¥ç¶ç¸éæ§ãæ¬ç ç©¶å¼·èª¿äºç¥ç¶èªè¨æ¨¡åå¨åæ äººé¡å¤§è¦ä¸­èªè¨èçæ¹é¢çæ½åï¼ä¸¦æä¾äºå°èªè¨çè§£çè¨ç®åç¥ç¶æ©å¶çè¦è§£ã

##### **Unveiling Hidden Visual Information: A Reconstruction Attack Against Adversarial Visual Information Hiding**
2408.04261v1 by Jonggyu Jang, Hyeonsu Lyu, Seongjin Hwang, Hyun Jong Yang

This paper investigates the security vulnerabilities of
adversarial-example-based image encryption by executing data reconstruction
(DR) attacks on encrypted images. A representative image encryption method is
the adversarial visual information hiding (AVIH), which uses type-I adversarial
example training to protect gallery datasets used in image recognition tasks.
In the AVIH method, the type-I adversarial example approach creates images that
appear completely different but are still recognized by machines as the
original ones. Additionally, the AVIH method can restore encrypted images to
their original forms using a predefined private key generative model. For the
best security, assigning a unique key to each image is recommended; however,
storage limitations may necessitate some images sharing the same key model.
This raises a crucial security question for AVIH: How many images can safely
share the same key model without being compromised by a DR attack? To address
this question, we introduce a dual-strategy DR attack against the AVIH
encryption method by incorporating (1) generative-adversarial loss and (2)
augmented identity loss, which prevent DR from overfitting -- an issue akin to
that in machine learning. Our numerical results validate this approach through
image recognition and re-identification benchmarks, demonstrating that our
strategy can significantly enhance the quality of reconstructed images, thereby
requiring fewer key-sharing encrypted images. Our source code to reproduce our
results will be available soon.

æè¦ï¼æ¬è«æééå°å å¯å½±åå·è¡è³æéå»º (DR) æ»æï¼æ¢è¨å°æç¯ä¾åºç¤å½±åå å¯çå®å¨æ¼æ´ãå·æä»£è¡¨æ§çå½±åå å¯æ¹æ³çºå°æè¦è¦ºè³è¨é±è (AVIH)ï¼å®ä½¿ç¨é¡å I å°æç¯ä¾è¨ç·´ï¼ä»¥ä¿è­·ç¨æ¼å½±åè¾¨è­ä»»åçååº«è³æéãå¨ AVIH æ¹æ³ä¸­ï¼é¡å I å°æç¯ä¾æ¹æ³æç¢ççèµ·ä¾å®å¨ä¸åï¼ä½æ©å¨ä»å°å¶è¾¨è­çºåå§å½±åçå½±åãæ­¤å¤ï¼AVIH æ¹æ³å¯ä»¥ä½¿ç¨é åå®ç¾©çç§å¯éé°çææ¨¡åï¼å°å å¯å½±åéåçºå¶åå§å½¢å¼ãçºäºç²å¾æä½³å®å¨æ§ï¼å»ºè­°çºæ¯åå½±åæå®ä¸åå¯ä¸éé°ï¼ä½æ¯ï¼å²å­éå¶å¯è½éè¦ä¸äºå½±åå±ç¨åä¸åéé°æ¨¡åãéçº AVIH æåºäºä¸åéè¦çå®å¨æ§åé¡ï¼æå¤å°å½±åå¯ä»¥å®å¨å°å±ç¨åä¸åéé°æ¨¡åï¼èä¸æåå° DR æ»æçå±å®³ï¼çºäºåç­éååé¡ï¼æåéå° AVIH å å¯æ¹æ³å¼å¥äºä¸åééç­ç¥ DR æ»æï¼æ¹æ³æ¯ç´å¥ (1) çæå°ææå¤±å (2) å¢å¼·èº«åæå¤±ï¼ä»¥é²æ­¢ DR éåº¦æ¬åï¼éæ¯ä¸åé¡ä¼¼æ¼æ©å¨å­¸ç¿ä¸­çåé¡ãæåçæ¸å¼çµæééå½±åè¾¨è­åéæ°è¾¨è­åºæºé©è­äºéåæ¹æ³ï¼è­ææåçç­ç¥å¯ä»¥é¡¯èæåéå»ºå½±åçåè³ªï¼é²èæ¸å°éè¦éé°å±ç¨çå å¯å½±åãæåç¨ä¾ç¢ççµæçåå§ç¢¼å°å¾å¿«æä¾ã

##### **EfficientRAG: Efficient Retriever for Multi-Hop Question Answering**
2408.04259v1 by Ziyuan Zhuang, Zhiyang Zhang, Sitao Cheng, Fangkai Yang, Jia Liu, Shujian Huang, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang

Retrieval-augmented generation (RAG) methods encounter difficulties when
addressing complex questions like multi-hop queries. While iterative retrieval
methods improve performance by gathering additional information, current
approaches often rely on multiple calls of large language models (LLMs). In
this paper, we introduce EfficientRAG, an efficient retriever for multi-hop
question answering. EfficientRAG iteratively generates new queries without the
need for LLM calls at each iteration and filters out irrelevant information.
Experimental results demonstrate that EfficientRAG surpasses existing RAG
methods on three open-domain multi-hop question-answering datasets.

æè¦ï¼æª¢ç´¢å¢å¼·çæï¼RAGï¼æ¹æ³å¨èçè¤éåé¡ï¼ä¾å¦å¤è·³æ¥è©¢ï¼ææéå°å°é£ãéç¶åè¦æª¢ç´¢æ¹æ³ééæ¶éé¡å¤è³è¨ä¾æåæè½ï¼ä½ç®åçä½æ³éå¸¸ä»°è³´å¤§åèªè¨æ¨¡åï¼LLMï¼çå¤éå¼å«ãå¨æ¬æä¸­ï¼æåä»ç´¹ EfficientRAGï¼éæ¯ä¸ç¨®ç¨æ¼å¤è·³åç­çé«ææª¢ç´¢å¨ãEfficientRAG æåè¦ç¢çæ°æ¥è©¢ï¼èç¡éå¨æ¯æ¬¡åè¦æå¼å« LLMï¼ä¸¦æéæ¿¾æç¡éçè³è¨ãå¯¦é©çµæè­æï¼EfficientRAG å¨ä¸åéæ¾é åå¤è·³åç­è³æéä¸åªæ¼ç¾æç RAG æ¹æ³ã

##### **Explicating the Implicit: Argument Detection Beyond Sentence Boundaries**
2408.04246v1 by Paul Roit, Aviv Slobodkin, Eran Hirsch, Arie Cattan, Ayal Klein, Valentina Pyatkin, Ido Dagan

Detecting semantic arguments of a predicate word has been conventionally
modeled as a sentence-level task. The typical reader, however, perfectly
interprets predicate-argument relations in a much wider context than just the
sentence where the predicate was evoked. In this work, we reformulate the
problem of argument detection through textual entailment to capture semantic
relations across sentence boundaries. We propose a method that tests whether
some semantic relation can be inferred from a full passage by first encoding it
into a simple and standalone proposition and then testing for entailment
against the passage. Our method does not require direct supervision, which is
generally absent due to dataset scarcity, but instead builds on existing NLI
and sentence-level SRL resources. Such a method can potentially explicate
pragmatically understood relations into a set of explicit sentences. We
demonstrate it on a recent document-level benchmark, outperforming some
supervised methods and contemporary language models.

æè¦ï¼å³çµ±ä¸ï¼åµæ¸¬è¬è©å­çèªç¾©è«åè¢«å»ºæ¨¡çºå¥å­å±¤ç´çä»»åãç¶èï¼å¸åçè®èæå¨æ¯è¬è©è¢«å¼ç¼çå¥å­æ´å»£æ³çèçµ¡ä¸­å®ç¾å°è©®éè¬è©-è«åéä¿ãå¨éé å·¥ä½ä¸­ï¼æåééææ¬èæ¶µéæ°å¶å®è«ååµæ¸¬çåé¡ï¼ä»¥ææè·¨è¶å¥å­éççèªç¾©éä¿ãæåæåºä¸åæ¹æ³ï¼ééå°èªç¾©éä¿ç·¨ç¢¼æä¸åç°¡å®ä¸ç¨ç«çå½é¡ï¼ç¶å¾æ¸¬è©¦èæ®µè½çèæ¶µéä¿ï¼ä¾æ¸¬è©¦æ¯å¦å¯ä»¥å¾ä¸åå®æ´çæ®µè½ä¸­æ¨è«åºä¸äºèªç¾©éä¿ãæåçéç¨®æ¹æ³ä¸éè¦ç´æ¥ç£ç£ï¼ééå¸¸ç±æ¼è³æéçç¨å°èç¡æ³é²è¡ï¼ä½å®å»ºç«å¨ç¾æç NLI åå¥å­å±¤ç´ SRL è³æºä¹ä¸ãéç¨®æ¹æ³æå¯è½å°èªç¨çè§£çéä¿è§£éçºä¸çµæç¢ºçå¥å­ãæåå¨æè¿çæä»¶å±¤ç´åºæºä¸å±ç¤ºäºå®ï¼å¶è¡¨ç¾åªæ¼ä¸äºç£ç£å¼æ¹æ³åç¶ä»£èªè¨æ¨¡åã

##### **Scalable Transformer for High Dimensional Multivariate Time Series Forecasting**
2408.04245v1 by Xin Zhou, Weiqing Wang, Wray Buntine, Shilin Qu, Abishek Sriramulu, Weicong Tan, Christoph Bergmeir

Deep models for Multivariate Time Series (MTS) forecasting have recently
demonstrated significant success. Channel-dependent models capture complex
dependencies that channel-independent models cannot capture. However, the
number of channels in real-world applications outpaces the capabilities of
existing channel-dependent models, and contrary to common expectations, some
models underperform the channel-independent models in handling high-dimensional
data, which raises questions about the performance of channel-dependent models.
To address this, our study first investigates the reasons behind the suboptimal
performance of these channel-dependent models on high-dimensional MTS data. Our
analysis reveals that two primary issues lie in the introduced noise from
unrelated series that increases the difficulty of capturing the crucial
inter-channel dependencies, and challenges in training strategies due to
high-dimensional data. To address these issues, we propose STHD, the Scalable
Transformer for High-Dimensional Multivariate Time Series Forecasting. STHD has
three components: a) Relation Matrix Sparsity that limits the noise introduced
and alleviates the memory issue; b) ReIndex applied as a training strategy to
enable a more flexible batch size setting and increase the diversity of
training data; and c) Transformer that handles 2-D inputs and captures channel
dependencies. These components jointly enable STHD to manage the
high-dimensional MTS while maintaining computational feasibility. Furthermore,
experimental results show STHD's considerable improvement on three
high-dimensional datasets: Crime-Chicago, Wiki-People, and Traffic. The source
code and dataset are publicly available
https://github.com/xinzzzhou/ScalableTransformer4HighDimensionMTSF.git.

æè¦ï¼å¤åæéåºå (MTS) é æ¸¬çæ·±åº¦æ¨¡åæè¿å·²å±ç¾é¡¯èçæåãééä¾è³´æ¨¡åææééç¨ç«æ¨¡åç¡æ³ææçè¤éä¾è³´éä¿ãç¶èï¼å¯¦éæç¨ä¸­çééæ¸éè¶éç¾æééä¾è³´æ¨¡åçè½åï¼èä¸èä¸è¬é æç¸åï¼æäºæ¨¡åå¨èçé«ç¶­åº¦æ¸ææè¡¨ç¾ä¸å¦ééç¨ç«æ¨¡åï¼éå¼ç¼äºéæ¼ééä¾è³´æ¨¡åæè½çåé¡ãçºäºè§£æ±ºéååé¡ï¼æåçç ç©¶é¦åæ¢è¨éäºééä¾è³´æ¨¡åå¨é«ç¶­åº¦ MTS æ¸æä¸è¡¨ç¾ä¸ä½³çåå ãæåçåæé¡¯ç¤ºï¼å©åä¸»è¦åé¡å¨æ¼ä¾èªä¸ç¸éåºåçéè¨ï¼å¢å äºææééµéééä¾è³´éä¿çé£åº¦ï¼ä»¥åç±æ¼é«ç¶­åº¦æ¸æé æçè¨ç·´ç­ç¥ææ°ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäº STHDï¼å³é«ç¶­åº¦å¤åæéåºåé æ¸¬çå¯æ´åTransformerãSTHD æä¸åçµæé¨åï¼a) éä¿ç©é£ç¨çæ§ï¼éå¶å¼é²çéè¨ä¸¦æ¸è¼è¨æ¶é«åé¡ï¼b) ReIndex ä½çºè¨ç·´ç­ç¥æç¨ï¼ä»¥åç¨æ´éæ´»çæ¹æ¬¡å¤§å°è¨­å®ä¸¦å¢å è¨ç·´æ¸æçå¤æ¨£æ§ï¼c) Transformerï¼èç 2D è¼¸å¥ä¸¦ææééä¾è³´éä¿ãéäºçµæé¨åå±åä½¿ STHD è½ç®¡çé«ç¶­åº¦ MTSï¼åæç¶­æéç®å¯è¡æ§ãæ­¤å¤ï¼å¯¦é©çµæé¡¯ç¤º STHD å¨ä¸åé«ç¶­åº¦è³æéä¸å¤§å¹é²æ­¥ï¼Crime-ChicagoãWiki-People å Trafficãåå§ç¨å¼ç¢¼åè³æéå¬éæ¼ https://github.com/xinzzzhou/ScalableTransformer4HighDimensionMTSF.gitã

##### **The Ungrounded Alignment Problem**
2408.04242v1 by Marc Pickett, Aakash Kumar Nain, Joseph Modayil, Llion Jones

Modern machine learning systems have demonstrated substantial abilities with
methods that either embrace or ignore human-provided knowledge, but combining
benefits of both styles remains a challenge. One particular challenge involves
designing learning systems that exhibit built-in responses to specific abstract
stimulus patterns, yet are still plastic enough to be agnostic about the
modality and exact form of their inputs. In this paper, we investigate what we
call The Ungrounded Alignment Problem, which asks How can we build in
predefined knowledge in a system where we don't know how a given stimulus will
be grounded? This paper examines a simplified version of the general problem,
where an unsupervised learner is presented with a sequence of images for the
characters in a text corpus, and this learner is later evaluated on its ability
to recognize specific (possibly rare) sequential patterns. Importantly, the
learner is given no labels during learning or evaluation, but must map images
from an unknown font or permutation to its correct class label. That is, at no
point is our learner given labeled images, where an image vector is explicitly
associated with a class label. Despite ample work in unsupervised and
self-supervised loss functions, all current methods require a labeled
fine-tuning phase to map the learned representations to correct classes.
Finding this mapping in the absence of labels may seem a fool's errand, but our
main result resolves this seeming paradox. We show that leveraging only letter
bigram frequencies is sufficient for an unsupervised learner both to reliably
associate images to class labels and to reliably identify trigger words in the
sequence of inputs. More generally, this method suggests an approach for
encoding specific desired innate behaviour in modality-agnostic models.

æè¦ï¼ç¾ä»£æ©å¨å­¸ç¿ç³»çµ±å·²ééæ¡ç¨æå¿½ç¥äººé¡æä¾çç¥è­çæ¹æ³å±ç¤ºåºé©äººçè½åï¼ä½çµåå©ç¨®é¢¨æ ¼çåªé»ä»ç¶æ¯ä¸é ææ°ãå¶ä¸­ä¸åç¹å¥çææ°æ¶åè¨­è¨å­¸ç¿ç³»çµ±ï¼éäºç³»çµ±å°ç¹å®çæ½è±¡åºæ¿æ¨¡å¼è¡¨ç¾åºå§å»ºåæï¼ä½ä»å·æè¶³å¤ çå¯å¡æ§ï¼å¯ä»¥å°è¼¸å¥çæ¨¡å¼åç¢ºåå½¢å¼ä¿æä¸å¯ç¥è«ãå¨æ¬æä¸­ï¼æåæ¢è¨æåç¨±ä¹çºãæªæ¥å°å°é½åé¡ãçåé¡ï¼å®æåºäºä¸ååé¡ï¼æåå¦ä½å¨æåä¸ç¥éçµ¦å®åºæ¿å°å¦ä½æ¥å°çç³»çµ±ä¸­å»ºæ§é å®ç¾©çç¥è­ï¼æ¬ææ¢è¨äºéåä¸è¬åé¡çç°¡åçæ¬ï¼å¶ä¸­éç£ç£å¼å­¸ç¿èæçå°ææ¬èªæåº«ä¸­è§è²çä¸ç³»åååï¼èéåå­¸ç¿èç¨å¾ææ ¹æå¶è­å¥ç¹å®ï¼å¯è½æ¯ç½è¦ï¼é åºæ¨¡å¼çè½åé²è¡è©ä¼°ãéè¦çæ¯ï¼å­¸ç¿èå¨å­¸ç¿æè©ä¼°æéä¸æç²å¾ä»»ä½æ¨ç±¤ï¼ä½å¿é å°ä¾èªæªç¥å­é«ææåçååæ å°å°å¶æ­£ç¢ºçé¡å¥æ¨ç±¤ãä¹å°±æ¯èªªï¼å¨ä»»ä½æåï¼æåçå­¸ç¿èé½ä¸æç²å¾æ¨ç±¤ååï¼å¶ä¸­åååéèé¡å¥æ¨ç±¤æç¢ºéè¯ãåç®¡å¨éç£ç£å¼åèªç£ç£å¼æå¤±å½æ¸æ¹é¢æåè¶³çå·¥ä½ï¼ä½ææç®åçæ¹æ³é½éè¦ä¸åæ¨ç±¤å¾®èª¿éæ®µï¼æè½å°å­¸ç¿å°çè¡¨ç¤ºæ å°å°æ­£ç¢ºçé¡å¥ãå¨æ²ææ¨ç±¤çææ³ä¸æ¾å°æ­¤æ å°å¯è½çèµ·ä¾åå»ççå·®äºï¼ä½æåçææè§£æ±ºäºéåçä¼¼çç¾çç¾è±¡ãæåè¡¨æï¼åå©ç¨å­æ¯äºåçµé »çå°±è¶³ä»¥è®éç£ç£å¼å­¸ç¿èå°ååå¯é å°éè¯å°é¡å¥æ¨ç±¤ï¼ä¸¦å¯é å°è­å¥è¼¸å¥åºåä¸­çè§¸ç¼å­ãæ´æ®éå°èªªï¼æ­¤æ¹æ³æåºäºä¸ç¨®å¨èæ¨¡å¼ç¡éçæ¨¡åä¸­ç·¨ç¢¼ç¹å®æéåå¤©è¡çºçæ¹æ³ã

##### **Learning to Rewrite: Generalized LLM-Generated Text Detection**
2408.04237v1 by Wei Hao, Ran Li, Weiliang Zhao, Junfeng Yang, Chengzhi Mao

Large language models (LLMs) can be abused at scale to create non-factual
content and spread disinformation. Detecting LLM-generated content is essential
to mitigate these risks, but current classifiers often fail to generalize in
open-world contexts. Prior work shows that LLMs tend to rewrite LLM-generated
content less frequently, which can be used for detection and naturally
generalizes to unforeseen data. However, we find that the rewriting edit
distance between human and LLM content can be indistinguishable across domains,
leading to detection failures. We propose training an LLM to rewrite input
text, producing minimal edits for LLM-generated content and more edits for
human-written text, deriving a distinguishable and generalizable edit distance
difference across different domains. Experiments on text from 21 independent
domains and three popular LLMs (e.g., GPT-4o, Gemini, and Llama-3) show that
our classifier outperforms the state-of-the-art zero-shot classifier by up to
20.6% on AUROC score and the rewriting classifier by 9.2% on F1 score. Our work
suggests that LLM can effectively detect machine-generated text if they are
trained properly.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¯è½æè¢«å¤§è¦æ¨¡æ¿«ç¨ï¼ç¨æ¼å»ºç«éäºå¯¦å§å®¹ä¸¦æ£å¸é¯èª¤è¨æ¯ãåµæ¸¬ LLM çæçå§å®¹å°æ¼æ¸è¼éäºé¢¨éªè³ééè¦ï¼ä½ç®åçåé¡å¨éå¸¸ç¡æ³å¨éæ¾ä¸ççç°å¢ä¸­é²è¡æ¦åãååçç ç©¶é¡¯ç¤ºï¼LLM å¾åæ¼æ¸å°æ¹å¯« LLM çæçå§å®¹ï¼éå¯ç¨æ¼åµæ¸¬ä¸¦èªç¶æ¦åå°ç¡æ³é è¦çè³æãç¶èï¼æåç¼ç¾äººé¡å LLM å§å®¹ä¹éçæ¹å¯«ç·¨è¼¯è·é¢å¨ä¸åé åä¸­å¯è½ç¡æ³ååï¼å°è´åµæ¸¬å¤±æãæåå»ºè­°è¨ç·´ LLM æ¹å¯«è¼¸å¥æå­ï¼å° LLM çæçå§å®¹ç¢çæå°çç·¨è¼¯ï¼å°äººé¡æ°å¯«çæå­ç¢çè¼å¤çç·¨è¼¯ï¼å¾èå¾åºä¸åé åä¸­å¯ååä¸å¯æ¦åçç·¨è¼¯è·é¢å·®ç°ãéå°ä¾èª 21 åç¨ç«é ååä¸åç±é LLMï¼ä¾å¦ GPT-4oãGemini å Llama-3ï¼çæå­é²è¡çå¯¦é©é¡¯ç¤ºï¼æåçåé¡å¨å¨ AUROC åæ¸ä¸æ¯æåé²çé¶æ¬¡å­¸ç¿åé¡å¨é«åº 20.6%ï¼å¨ F1 åæ¸ä¸æ¯æ¹å¯«åé¡å¨é«åº 9.2%ãæåçç ç©¶è¡¨æï¼åªè¦ç¶éé©ç¶çè¨ç·´ï¼LLM å¯ä»¥ææåµæ¸¬æ©å¨ç¢ççæå­ã

##### **Probabilistic Circuits for Cumulative Distribution Functions**
2408.04229v1 by Oliver Broadrick, William Cao, Benjie Wang, Martin Trapp, Guy Van den Broeck

A probabilistic circuit (PC) succinctly expresses a function that represents
a multivariate probability distribution and, given sufficient structural
properties of the circuit, supports efficient probabilistic inference.
Typically a PC computes the probability mass (or density) function (PMF or PDF)
of the distribution. We consider PCs instead computing the cumulative
distribution function (CDF). We show that for distributions over binary random
variables these representations (PMF and CDF) are essentially equivalent, in
the sense that one can be transformed to the other in polynomial time. We then
show how a similar equivalence holds for distributions over finite discrete
variables using a modification of the standard encoding with binary variables
that aligns with the CDF semantics. Finally we show that for continuous
variables, smooth, decomposable PCs computing PDFs and CDFs can be efficiently
transformed to each other by modifying only the leaves of the circuit.

æè¦ï¼æ©çé»è·¯ (PC) ç°¡æ½å°è¡¨éä¸åè¡¨ç¤ºå¤è®éæ©çåä½çå½æ¸ï¼ä¸¦ä¸å¨é»è·¯å·æè¶³å¤ çµæ§ç¹æ§çææ³ä¸ï¼æ¯æ´ææçæ©çæ¨è«ãPC éå¸¸æè¨ç®åä½çæ©çè³ªé (æå¯åº¦) å½æ¸ (PMF æ PDF)ãæåèæ® PC è¨ç®ç´¯ç©åä½å½æ¸ (CDF)ãæåè­æï¼å°æ¼äºåé¨æ©è®æ¸ä¸çåä½ï¼éäºè¡¨ç¤ºæ³ (PMF å CDF) æ¬è³ªä¸æ¯ç­æçï¼å çºå¶ä¸­ä¸åå¯ä»¥å¨å¤é å¼æéå§è½æçºå¦ä¸åãç¶å¾ï¼æåå±ç¤ºé¡ä¼¼çç­å¹æ§å¦ä½é©ç¨æ¼æéé¢æ£è®æ¸ä¸çåä½ï¼æ¹æ³æ¯ä¿®æ¹å·æäºåè®æ¸çæ¨æºç·¨ç¢¼ï¼ä½¿å¶è CDF èªç¾©ä¿æä¸è´ãæå¾ï¼æåè­æå°æ¼é£çºè®æ¸ï¼è¨ç® PDF å CDF çå¹³æ»ãå¯åè§£ PC å¯ä»¥ééåä¿®æ¹é»è·¯çèç¯é»ä¾ææå°ç¸äºè½æã

##### **Evaluating Language Model Math Reasoning via Grounding in Educational Curricula**
2408.04226v1 by Li Lucy, Tal August, Rose E. Wang, Luca Soldaini, Courtney Allison, Kyle Lo

Our work presents a novel angle for evaluating language models' (LMs)
mathematical abilities, by investigating whether they can discern skills and
concepts enabled by math content. We contribute two datasets: one consisting of
385 fine-grained descriptions of K-12 math skills and concepts, or standards,
from Achieve the Core (ATC), and another of 9.9K problems labeled with these
standards (MathFish). Working with experienced teachers, we find that LMs
struggle to tag and verify standards linked to problems, and instead predict
labels that are close to ground truth, but differ in subtle ways. We also show
that LMs often generate problems that do not fully align with standards
described in prompts. Finally, we categorize problems in GSM8k using math
standards, allowing us to better understand why some problems are more
difficult to solve for models than others.

æè¦ï¼æåçç ç©¶æåºäºä¸åè©ä¼°èªè¨æ¨¡å (LM) æ¸å­¸è½åçæ°è§åº¦ï¼æ¹æ³æ¯èª¿æ¥å®åæ¯å¦è½è¾¨å¥æ¸å­¸å§å®¹æåç¨çæè½åæ¦å¿µãæåè²¢ç»äºå©åæ¸æéï¼ä¸ååå« 385 å K-12 æ¸å­¸æè½åæ¦å¿µææ¨æºçç´°ç·»æè¿°ï¼ä¾èª Achieve the Core (ATC)ï¼å¦ä¸ååå« 9.9K åæ¨è¨äºéäºæ¨æºçåé¡ (MathFish)ãèç¶é©è±å¯çèå¸«åä½ï¼æåç¼ç¾ LM å¾é£æ¨è¨åé©è­èåé¡ç¸éçæ¨æºï¼èæ¯é æ¸¬æ¥è¿çå¯¦ææ³ä½ä»¥å¾®å¦æ¹å¼ä¸åçæ¨ç±¤ãæåéå±ç¤ºäº LM éå¸¸æç¢çèæç¤ºä¸­æè¿°çæ¨æºå®å¨ä¸ä¸è´çåé¡ãæå¾ï¼æåä½¿ç¨æ¸å­¸æ¨æºå° GSM8k ä¸­çåé¡é²è¡åé¡ï¼è®æåè½æ´å¥½å°äºè§£çºä»éº¼æäºåé¡å°æ¨¡åä¾èªªæ¯å¶ä»åé¡æ´é£è§£æ±ºã

##### **VideoQA in the Era of LLMs: An Empirical Study**
2408.04223v1 by Junbin Xiao, Nanxin Huang, Hangyu Qin, Dongyang Li, Yicong Li, Fengbin Zhu, Zhulin Tao, Jianxing Yu, Liang Lin, Tat-Seng Chua, Angela Yao

Video Large Language Models (Video-LLMs) are flourishing and has advanced
many video-language tasks. As a golden testbed, Video Question Answering
(VideoQA) plays pivotal role in Video-LLM developing. This work conducts a
timely and comprehensive study of Video-LLMs' behavior in VideoQA, aiming to
elucidate their success and failure modes, and provide insights towards more
human-like video understanding and question answering. Our analyses demonstrate
that Video-LLMs excel in VideoQA; they can correlate contextual cues and
generate plausible responses to questions about varied video contents. However,
models falter in handling video temporality, both in reasoning about temporal
content ordering and grounding QA-relevant temporal moments. Moreover, the
models behave unintuitively - they are unresponsive to adversarial video
perturbations while being sensitive to simple variations of candidate answers
and questions. Also, they do not necessarily generalize better. The findings
demonstrate Video-LLMs' QA capability in standard condition yet highlight their
severe deficiency in robustness and interpretability, suggesting the urgent
need on rationales in Video-LLM developing.

æè¦ï¼å½±çå¤§åèªè¨æ¨¡åï¼Video-LLMï¼è¬åç¼å±ï¼ä¸¦æåäºè¨±å¤å½±çèªè¨ä»»åãå½±çåç­ï¼VideoQAï¼ä½çºä¸åé»éæ¸¬è©¦å¹³å°ï¼å¨ Video-LLM çç¼å±ä¸­æ®æ¼èèè¶³è¼éçè§è²ãéé å·¥ä½å° Video-LLM å¨ VideoQA ä¸­çè¡çºé²è¡åæä¸å¨é¢çç ç©¶ï¼æ¨å¨é¡æå®åçæåèå¤±ææ¨¡å¼ï¼ä¸¦æä¾æ´è¦ä»¥æåæ´é¡ä¼¼äººé¡çå½±ççè§£ååé¡è§£ç­ãæåçåæè­æ Video-LLM å¨ VideoQA ä¸­è¡¨ç¾åºè²ï¼å®åå¯ä»¥éè¯èçµ¡ç·ç´¢ï¼ä¸¦å°åç¨®å½±çå§å®¹çåé¡ç¢çåççåæãç¶èï¼æ¨¡åå¨èçå½±çæéæ§æ¹é¢è¡¨ç¾ä¸ä½³ï¼ç¡è«æ¯å¨æ¨è«æéå§å®¹æåºï¼éæ¯å»ºç«è QA ç¸éçæéé»æ¹é¢ãæ­¤å¤ï¼éäºæ¨¡åçè¡çºä¸ç´è§ââå®åå°å°ææ§å½±çæ¾åæ²æåæï¼ä½å°åé¸ç­æ¡ååé¡çç°¡å®è®åå¾ææãæ­¤å¤ï¼å®åä¸ä¸å®è½é²è¡æ´å¥½çæ¦æ¬ãéäºç¼ç¾è­æäº Video-LLM å¨æ¨æºæ¢ä»¶ä¸ç QA è½åï¼ä½ä¹çªåºäºå®åå¨ç©©å¥æ§åå¯è§£éæ§æ¹é¢çå´éä¸è¶³ï¼éè¡¨æå¨ Video-LLM éç¼ä¸­è¿«åéè¦ä¾æã

##### **Connective Viewpoints of Signal-to-Noise Diffusion Models**
2408.04221v1 by Khanh Doan, Long Tung Vuong, Tuan Nguyen, Anh Tuan Bui, Quyen Tran, Thanh-Toan Do, Dinh Phung, Trung Le

Diffusion models (DM) have become fundamental components of generative
models, excelling across various domains such as image creation, audio
generation, and complex data interpolation. Signal-to-Noise diffusion models
constitute a diverse family covering most state-of-the-art diffusion models.
While there have been several attempts to study Signal-to-Noise (S2N) diffusion
models from various perspectives, there remains a need for a comprehensive
study connecting different viewpoints and exploring new perspectives. In this
study, we offer a comprehensive perspective on noise schedulers, examining
their role through the lens of the signal-to-noise ratio (SNR) and its
connections to information theory. Building upon this framework, we have
developed a generalized backward equation to enhance the performance of the
inference process.

æè¦ï¼æ´æ£æ¨¡å (DM) å·²æçºçææ¨¡åçåºæ¬çµæé¨åï¼å¨åç¨®é åä¸­è¡¨ç¾åªç°ï¼ä¾å¦å½±åå»ºç«ãé³è¨çæåè¤éè³æå§æãä¿¡èå°éè¨æ´æ£æ¨¡åæ§æä¸åå¤åçå®¶æï¼æ¶µèå¤§å¤æ¸æåé²çæ´æ£æ¨¡åãéç¶å·²ç¶æå¹¾é åè©¦å¾åç¨®è§åº¦ç ç©¶ä¿¡èå°éè¨ (S2N) æ´æ£æ¨¡åï¼ä½ä»éè¦ä¸é ç¶åç ç©¶ï¼é£çµä¸åçè§é»ä¸¦æ¢ç´¢æ°çè§é»ãå¨æ¬ç ç©¶ä¸­ï¼æåéå°éè¨æç¨å¨æä¾å¨é¢çè§é»ï¼ééä¿¡èå°éè¨æ¯ (SNR) çè§é»å¯©æ¥å®åçè§è²åå¶èè³è¨çè«çéè¯ãå»ºç«å¨éåæ¶æ§ä¹ä¸ï¼æåéç¼äºä¸åå»£ç¾©å¾åæ¹ç¨å¼ï¼ä»¥å¢å¼·æ¨çç¨åºçæè½ã

##### **Diffusion Guided Language Modeling**
2408.04220v1 by Justin Lovelace, Varsha Kishore, Yiwei Chen, Kilian Q. Weinberger

Current language models demonstrate remarkable proficiency in text
generation. However, for many applications it is desirable to control
attributes, such as sentiment, or toxicity, of the generated language --
ideally tailored towards each specific use case and target audience. For
auto-regressive language models, existing guidance methods are prone to
decoding errors that cascade during generation and degrade performance. In
contrast, text diffusion models can easily be guided with, for example, a
simple linear sentiment classifier -- however they do suffer from significantly
higher perplexity than auto-regressive alternatives. In this paper we use a
guided diffusion model to produce a latent proposal that steers an
auto-regressive language model to generate text with desired properties. Our
model inherits the unmatched fluency of the auto-regressive approach and the
plug-and-play flexibility of diffusion. We show that it outperforms previous
plug-and-play guidance methods across a wide range of benchmark data sets.
Further, controlling a new attribute in our framework is reduced to training a
single logistic regression classifier.

æè¦ï¼<paragraph>ç®åçèªè¨æ¨¡åå¨æå­çææ¹é¢å±ç¾åºåè¶ççç·´åº¦ãç¶èï¼å°æ¼è¨±å¤æç¨ç¨å¼ä¾èªªï¼æ§å¶çæèªè¨çå±¬æ§ï¼ä¾å¦æç·ææ¯æ§ï¼æ¯å¿è¦çï¼çæ³ææ³ä¸æéå°æ¯åç¹å®ç¨ä¾åç®æ¨åç¾é²è¡èª¿æ´ãå°æ¼èªè¿´æ­¸èªè¨æ¨¡åï¼ç¾æçå¼å°æ¹æ³å®¹æåºç¾è§£ç¢¼é¯èª¤ï¼éäºé¯èª¤æå¨çæéç¨ä¸­ç´è¯ä¸¦éä½æè½ãç¸æ¯ä¹ä¸ï¼æå­æ´æ£æ¨¡åå¯ä»¥å¾å®¹æå°è¢«å¼å°ï¼ä¾å¦ï¼ä½¿ç¨ä¸åç°¡å®çç·æ§æç·åé¡å¨ï¼ä½å®åçå°æåº¦é¡¯èé«æ¼èªè¿´æ­¸æ¿ä»£æ¹æ¡ãå¨æ¬æä¸­ï¼æåä½¿ç¨å¼å°æ´æ£æ¨¡åä¾ç¢çä¸åæ½å¨ææ¡ï¼å¼å°èªè¿´æ­¸èªè¨æ¨¡åçæå·ææéå±¬æ§çæå­ãæåçæ¨¡åç¹¼æ¿äºèªè¿´æ­¸æ¹æ³ç¡èå«æ¯çæµæ¢æ§ä»¥åæ´æ£çå³æå³ç¨éæ´»æ§ãæåè¡¨æï¼å®å¨å»£æ³çåºæºè³æéä¸åªæ¼ååçå³æå³ç¨å¼å°æ¹æ³ãæ­¤å¤ï¼å¨æåçæ¡æ¶ä¸­æ§å¶ä¸åæ°çå±¬æ§è¢«ç°¡åçºè¨ç·´ä¸åå®ä¸çéè¼¯è¿´æ­¸åé¡å¨ã</paragraph>

##### **Simplifying Translations for Children: Iterative Simplification Considering Age of Acquisition with LLMs**
2408.04217v1 by Masashi Oshika, Makoto Morishita, Tsutomu Hirao, Ryohei Sasano, Koichi Takeda

In recent years, neural machine translation (NMT) has been widely used in
everyday life. However, the current NMT lacks a mechanism to adjust the
difficulty level of translations to match the user's language level.
Additionally, due to the bias in the training data for NMT, translations of
simple source sentences are often produced with complex words. In particular,
this could pose a problem for children, who may not be able to understand the
meaning of the translations correctly. In this study, we propose a method that
replaces words with high Age of Acquisitions (AoA) in translations with simpler
words to match the translations to the user's level. We achieve this by using
large language models (LLMs), providing a triple of a source sentence, a
translation, and a target word to be replaced. We create a benchmark dataset
using back-translation on Simple English Wikipedia. The experimental results
obtained from the dataset show that our method effectively replaces high-AoA
words with lower-AoA words and, moreover, can iteratively replace most of the
high-AoA words while still maintaining high BLEU and COMET scores.

æè¦ï¼è¿å¹´ä¾ï¼ç¥ç¶æ©å¨ç¿»è­¯ï¼NMTï¼å·²å»£æ³æç¨æ¼æ¥å¸¸çæ´»ãç¶èï¼ç¾æ NMT ç¼ºä¹èª¿æ´ç¿»è­¯é£åº¦ä»¥ç¬¦åä½¿ç¨èèªè¨ç¨åº¦çæ©å¶ãæ­¤å¤ï¼ç±æ¼ NMT è¨ç·´è³æçåå·®ï¼ç°¡å®çåå§å¥æææç¿»è­¯æä½¿ç¨è¤éè©å½çå¥å­ãç¹å¥æ¯ï¼éå¯è½æå°åç«¥é æåé¡ï¼å çºä»åå¯è½ç¡æ³æ­£ç¢ºçè§£ç¿»è­¯çå«ç¾©ãå¨æ¬ç ç©¶ä¸­ï¼æåæåºäºä¸ç¨®æ¹æ³ï¼å°ç¿»è­¯ä¸­é«ç¿å¾å¹´é½¡ (AoA) çå­è©æ¿æçºè¼ç°¡å®çå­è©ï¼ä»¥ç¬¦åä½¿ç¨èçç¨åº¦ãæåééä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾éææ­¤ç®çï¼æä¾åå§å¥å­ãç¿»è­¯åè¦æ¿æçç®æ¨å­è©çä¸åçµãæåä½¿ç¨ç°¡å®è±èªç¶­åºç¾ç§ä¸çååç¿»è­¯å»ºç«åºåè³æéãå¾è³æéä¸­ç²å¾çå¯¦é©çµæé¡¯ç¤ºï¼æåçæ¨¡åææå°å°é« AoA å­è©æ¿æçºä½ AoA å­è©ï¼èä¸éè½åè¦æ¿æå¤§å¤æ¸é« AoA å­è©ï¼åæä»ç¶­æé« BLEU å COMET åæ¸ã

##### **Attention Mechanism and Context Modeling System for Text Mining Machine Translation**
2408.04216v1 by Shi Bo, Yuwei Zhang, Junming Huang, Sitong Liu, Zexi Chen, Zizheng Li

This paper advances a novel architectural schema anchored upon the
Transformer paradigm and innovatively amalgamates the K-means categorization
algorithm to augment the contextual apprehension capabilities of the schema.
The transformer model performs well in machine translation tasks due to its
parallel computing power and multi-head attention mechanism. However, it may
encounter contextual ambiguity or ignore local features when dealing with
highly complex language structures. To circumvent this constraint, this
exposition incorporates the K-Means algorithm, which is used to stratify the
lexis and idioms of the input textual matter, thereby facilitating superior
identification and preservation of the local structure and contextual
intelligence of the language. The advantage of this combination is that K-Means
can automatically discover the topic or concept regions in the text, which may
be directly related to translation quality. Consequently, the schema contrived
herein enlists K-Means as a preparatory phase antecedent to the Transformer and
recalibrates the multi-head attention weights to assist in the discrimination
of lexis and idioms bearing analogous semantics or functionalities. This
ensures the schema accords heightened regard to the contextual intelligence
embodied by these clusters during the training phase, rather than merely
focusing on locational intelligence.

æè¦ï¼éç¯è«ææåºäºä¸åæ°ç©çæ¶æ§æ¨¡å¼ï¼ä»¥ Transformer å¸ç¯çºåºç¤ï¼ä¸¦åµæ°å°èåäº K-means åé¡æ¼ç®æ³ï¼ä»¥å¢å¼·æ¨¡å¼çèªå¢çè§£è½åãTransformer æ¨¡åå¨æ©å¨ç¿»è­¯ä»»åä¸­è¡¨ç¾è¯å¥½ï¼éè¦æ­¸åæ¼å¶ä¸¦è¡éç®è½ååå¤é ­æ³¨æåæ©å¶ãç¶èï¼å¨èçé«åº¦è¤éçèªè¨çµæ§æï¼å®å¯è½æéå°èªå¢æ­§ç¾©æå¿½ç¥å±é¨ç¹å¾µãçºäºè¦é¿éåéå¶ï¼æ¬è«æçµåäº K-Means æ¼ç®æ³ï¼ç¨æ¼å°è¼¸å¥ææ¬è³æçè©å½åæ£ç¨èªé²è¡åå±¤ï¼å¾èä¿é²å°èªè¨çå±é¨çµæ§åèªå¢æºæ§çåªè¶è­å¥åä¿çãéç¨®çµåçåªé»å¨æ¼ K-Means å¯ä»¥èªåç¼ç¾ææ¬ä¸­çä¸»é¡ææ¦å¿µååï¼éå¯è½èç¿»è­¯åè³ªç´æ¥ç¸éãå æ­¤ï¼æ¬æè¨­è¨çæ¨¡å¼å° K-Means ä½çº Transformer ä¹åçæºåéæ®µï¼ä¸¦éæ°æ ¡æºå¤é ­æ³¨æåæ¬éï¼ä»¥åå©ååå·æé¡ä¼¼èªç¾©æåè½çè©å½åæ£ç¨èªãéç¢ºä¿äºæ¨¡å¼å¨è¨ç·´éæ®µé«åº¦éè¦éäºç¾¤éæé«ç¾çèªå¢æºæ§ï¼èä¸ä»ä»éæ³¨ä½ç½®æºæ§ã

##### **MMREC: LLM Based Multi-Modal Recommender System**
2408.04211v1 by Jiahao Tian, Jinman Zhao, Zhenkai Wang, Zhicheng Ding

The importance of recommender systems is growing rapidly due to the
exponential increase in the volume of content generated daily. This surge in
content presents unique challenges for designing effective recommender systems.
Key among these challenges is the need to effectively leverage the vast amounts
of natural language data and images that represent user preferences. This paper
presents a novel approach to enhancing recommender systems by leveraging Large
Language Models (LLMs) and deep learning techniques. The proposed framework
aims to improve the accuracy and relevance of recommendations by incorporating
multi-modal information processing and by the use of unified latent space
representation. The study explores the potential of LLMs to better understand
and utilize natural language data in recommendation contexts, addressing the
limitations of previous methods. The framework efficiently extracts and
integrates text and image information through LLMs, unifying diverse modalities
in a latent space to simplify the learning process for the ranking model.
Experimental results demonstrate the enhanced discriminative power of the model
when utilizing multi-modal information. This research contributes to the
evolving field of recommender systems by showcasing the potential of LLMs and
multi-modal data integration to create more personalized and contextually
relevant recommendations.

æè¦ï¼æ¨è¦ç³»çµ±çéè¦æ§æ­£å¿«éæåï¼åå å¨æ¼æ¯å¤©ç¢ççå§å®¹éåææ¸ç´å¢é·ãéç¨®å§å®¹æ¿å¢å°è¨­è¨ææçæ¨è¦ç³»çµ±æåºäºç¨ç¹çææ°ãéäºææ°ä¸­çééµå¨æ¼éè¦ææå©ç¨å¤§éçèªç¶èªè¨è³æåä»£è¡¨ä½¿ç¨èåå¥½çåçãæ¬ææåºäºä¸ç¨®æ°æ¹æ³ï¼ééå©ç¨å¤§åèªè¨æ¨¡å (LLM) åæ·±åº¦å­¸ç¿æè¡ä¾å¢å¼·æ¨è¦ç³»çµ±ãææåºçæ¶æ§æ¨å¨ééæ´åå¤æ¨¡æè³è¨èçåä½¿ç¨çµ±ä¸çæ½å¨ç©ºéè¡¨ç¤ºä¾æ¹åæ¨è¦çæºç¢ºæ§åç¸éæ§ãæ¬ç ç©¶æ¢è¨äºå¤§åèªè¨æ¨¡åå¨æ¨è¦æå¢ä¸­æ´äºè§£åå©ç¨èªç¶èªè¨è³æçæ½åï¼ä¸¦è§£æ±ºäºååæ¹æ³çéå¶ãè©²æ¶æ§ééå¤§åèªè¨æ¨¡åææå°èååæ´åæå­ååçè³è¨ï¼å¨æ½å¨ç©ºéä¸­çµ±ä¸ä¸åçæ¨¡æï¼ä»¥ç°¡åæåæ¨¡åçå­¸ç¿æ­·ç¨ãå¯¦é©çµæè­æäºè©²æ¨¡åå¨ä½¿ç¨å¤æ¨¡æè³è¨æå¢å¼·çå¤å¥è½åãéé ç ç©¶ééå±ç¤ºå¤§åèªè¨æ¨¡ååå¤æ¨¡æè³ææ´åå¨å»ºç«æ´åäººååèæå¢ç¸éçæ¨è¦æ¹é¢çæ½åï¼çºæ¨è¦ç³»çµ±çæ¼é²é åååºè²¢ç»ã

##### **MMRole: A Comprehensive Framework for Developing and Evaluating Multimodal Role-Playing Agents**
2408.04203v1 by Yanqi Dai, Huanran Hu, Lei Wang, Shengjie Jin, Xu Chen, Zhiwu Lu

Recently, Role-Playing Agents (RPAs) have garnered increasing attention for
their potential to deliver emotional value and facilitate sociological
research. However, existing studies are primarily confined to the textual
modality, unable to simulate humans' multimodal perceptual capabilities. To
bridge this gap, we introduce the concept of Multimodal Role-Playing Agents
(MRPAs), and propose a comprehensive framework, MMRole, for their development
and evaluation, which comprises a personalized multimodal dataset and a robust
evaluation method. Specifically, we construct a large-scale, high-quality
dataset, MMRole-Data, consisting of 85 characters, 11K images, and 14K single
or multi-turn dialogues. Additionally, we present a robust evaluation method,
MMRole-Eval, encompassing eight metrics across three dimensions, where a reward
model is trained to score MRPAs with the constructed ground-truth data for
comparison. Moreover, we develop the first specialized MRPA, MMRole-Agent.
Extensive evaluation results demonstrate the improved performance of
MMRole-Agent and highlight the primary challenges in developing MRPAs,
emphasizing the need for enhanced multimodal understanding and role-playing
consistency. The data, code, and models will be available at
https://github.com/YanqiDai/MMRole.

æè¦ï¼<paragraph>æè¿ï¼è§è²æ®æ¼ä»£çï¼RPAï¼å å¶æä¾ææä»·å¼åä¿è¿ç¤¾ä¼å­¦ç ç©¶çæ½åèå¤åå³æ³¨ãç¶èï¼ç°æç ç©¶ä¸»è¦å±éäºææ¬æ¨¡å¼ï¼æ æ³æ¨¡æäººç±»çå¤æ¨¡ææç¥è½åãä¸ºäºå¼¥åçè®ºå·®è·ï¼æä»¬å¼å¥äºå¤æ¨¡æè§è²æ®æ¼ä»£çï¼MRPAï¼çæ¦å¿µï¼å¹¶æåºäºä¸ä¸ªç¨äºå¼ååè¯ä¼°çç»¼åæ¡æ¶ MMRoleï¼å¶ä¸­åæ¬ä¸ªæ§åå¤æ¨¡ææ°æ®éåå¥å£®çè¯ä¼°æ¹æ³ãå·ä½æ¥è¯´ï¼æä»¬æå»ºäºä¸ä¸ªå¤§è§æ¨¡ãé«è´¨éçæ°æ®é MMRole-Dataï¼å¶ä¸­åæ¬ 85 ä¸ªè§è²ã11K å¼ å¾åå 14K ä¸ªåè½®æå¤è½®å¯¹è¯ãæ­¤å¤ï¼æä»¬æåºäºä¸ä¸ªå¥å£®çè¯ä¼°æ¹æ³ MMRole-Evalï¼å®åå«ä¸ä¸ªç»´åº¦ä¸çå«ä¸ªææ ï¼å¶ä¸­è®­ç»äºä¸ä¸ªå¥å±æ¨¡åï¼ä½¿ç¨æå»ºå¥½çåºæ¬äºå®æ°æ®å¯¹ MRPA è¿è¡è¯åä»¥è¿è¡æ¯è¾ãæ­¤å¤ï¼æä»¬å¼åäºç¬¬ä¸ä¸ªä¸é¨ç MRPAï¼å³ MMRole-Agentãå¹¿æ³çè¯ä¼°ç»æè¯æäº MMRole-Agent çæ§è½å¾å°æ¹åï¼å¹¶çªåºäºå¼å MRPA çä¸»è¦ææï¼å¼ºè°äºå¯¹å¢å¼ºçå¤æ¨¡æçè§£åè§è²æ®æ¼ä¸è´æ§çéæ±ãæ°æ®ãä»£ç åæ¨¡åå°å¨ https://github.com/YanqiDai/MMRole ä¸æä¾ã</paragraph>

##### **Pairwise Judgment Formulation for Semantic Embedding Model in Web Search**
2408.04197v1 by Mengze Hong, Chen Jason Zhang

Semantic Embedding Model (SEM), a neural network-based Siamese architecture,
is gaining momentum in information retrieval and natural language processing.
In order to train SEM in a supervised fashion for Web search, the search engine
query log is typically utilized to automatically formulate pairwise judgments
as training data. Despite the growing application of semantic embeddings in the
search engine industry, little work has been done on formulating effective
pairwise judgments for training SEM. In this paper, we make the first in-depth
investigation of a wide range of strategies for generating pairwise judgments
for SEM. An interesting (perhaps surprising) discovery reveals that the
conventional pairwise judgment formulation strategy wildly used in the field of
pairwise Learning-to-Rank (LTR) is not necessarily effective for training SEM.
Through a large-scale empirical study based on query logs and click-through
activities from a major commercial search engine, we demonstrate the effective
strategies for SEM and highlight the advantages of a hybrid heuristic (i.e.,
Clicked > Non-Clicked) in comparison to the atomic heuristics (e.g., Clicked >
Skipped) in LTR. We conclude with best practices for training SEM and offer
promising insights for future research.

æè¦ï¼èªæåµå¥æ¨¡å (SEM)ï¼ä¸ç¨®åºæ¼ç¥ç¶ç¶²è·¯çé£é«æ¶æ§ï¼å¨è³è¨æª¢ç´¢åèªç¶èªè¨èçä¸­æ­£ç²å¾å»£æ³çæç¨ãçºäºä»¥ç£ç£å¼çæ¹å¼è¨ç·´ç¶²è·¯æå°ç SEMï¼æå°å¼ææ¥è©¢è¨ééå¸¸ç¨æ¼èªåå»ºç«æå°çå¤æ·ï¼ä½çºè¨ç·´è³æãåç®¡èªæåµå¥å¨æå°å¼æç¢æ¥­çæç¨æ¥çå»£æ³ï¼ä½å°æ¼å»ºç«ææçæå°å¤æ·ä»¥è¨ç·´ SEMï¼å»é®®å°æç ç©¶ãå¨æ¬æä¸­ï¼æåé¦æ¬¡æ·±å¥æ¢è¨äºå»£æ³çç­ç¥ï¼ä»¥ç¢ç SEM çæå°å¤æ·ãä¸åæè¶£çï¼ä¹è¨±ä»¤äººé©è¨çï¼ç¼ç¾è¡¨æï¼æå°å­¸ç¿æå (LTR) é åä¸­å»£æ³ä½¿ç¨çå³çµ±æå°å¤æ·å¶å®ç­ç¥ï¼å°æ¼è¨ç·´ SEM ä¸¦éä¸å®ææãééå¤§åçå¯¦è­ç ç©¶ï¼æ ¹æä¸»è¦åæ¥­æå°å¼æçæ¥è©¢è¨éåé»ææ´»åï¼æåå±ç¤ºäº SEM çææç­ç¥ï¼ä¸¦å¼·èª¿äºæ··ååç¼å¼æ¹æ³ï¼å³ï¼å·²é»æ > æªé»æï¼è LTR ä¸­çåå­åç¼å¼æ¹æ³ï¼ä¾å¦ï¼å·²é»æ > å·²ç¥éï¼ç¸æ¯çåªé»ãæåç¸½çµäºè¨ç·´ SEM çæä½³å¯¦åï¼ä¸¦çºæªä¾çç ç©¶æä¾äºæåæ¯çè¦è§£ã

##### **Uncertainty-Aware Crime Prediction With Spatial Temporal Multivariate Graph Neural Networks**
2408.04193v1 by Zepu Wang, Xiaobo Ma, Huajie Yang, Weimin Lvu, Peng Sun, Sharath Chandra Guntuku

Crime forecasting is a critical component of urban analysis and essential for
stabilizing society today. Unlike other time series forecasting problems, crime
incidents are sparse, particularly in small regions and within specific time
periods. Traditional spatial-temporal deep learning models often struggle with
this sparsity, as they typically cannot effectively handle the non-Gaussian
nature of crime data, which is characterized by numerous zeros and
over-dispersed patterns. To address these challenges, we introduce a novel
approach termed Spatial Temporal Multivariate Zero-Inflated Negative Binomial
Graph Neural Networks (STMGNN-ZINB). This framework leverages diffusion and
convolution networks to analyze spatial, temporal, and multivariate
correlations, enabling the parameterization of probabilistic distributions of
crime incidents. By incorporating a Zero-Inflated Negative Binomial model,
STMGNN-ZINB effectively manages the sparse nature of crime data, enhancing
prediction accuracy and the precision of confidence intervals. Our evaluation
on real-world datasets confirms that STMGNN-ZINB outperforms existing models,
providing a more reliable tool for predicting and understanding crime dynamics.

æè¦ï¼ç¯ç½ªé æ¸¬æ¯é½å¸åæä¸­çééµçµæï¼ä¹æ¯ç¶ä»ç¤¾æç©©å®çå¿è¦æ¢ä»¶ãèå¶ä»æéåºåé æ¸¬åé¡ä¸åï¼ç¯ç½ªäºä»¶æ¯ç¨ççï¼ç¹å¥æ¯å¨å°åååç¹å®æéæ®µå§ãå³çµ±çæç©ºæ·±åº¦å­¸ç¿æ¨¡åéå¸¸é£ä»¥èçéç¨®ç¨çæ§ï¼å çºå®åéå¸¸ç¡æ³ææèçç¯ç½ªæ¸æçéé«æ¯æ§è³ªï¼èç¯ç½ªæ¸æçç¹å¾µæ¯é¶å¼å¤ä¸éåº¦åæ£çæ¨¡å¼ãçºäºæå°éäºææ°ï¼æåå¼å¥äºä¸ç¨®æ°æ¹æ³ï¼ç¨±çºæç©ºå¤åé¶è¨è¹è² äºé åç¥ç¶ç¶²è·¯ (STMGNN-ZINB)ãæ­¤æ¶æ§å©ç¨æ´æ£åå·ç©ç¶²è·¯ä¾åææç©ºåå¤åç¸éæ§ï¼å¾èè½å¤ å°ç¯ç½ªäºä»¶çæ©çåä½é²è¡åæ¸åãééç´å¥é¶è¨è¹è² äºé æ¨¡åï¼STMGNN-ZINB ææå°ç®¡çç¯ç½ªæ¸æçç¨çæ§è³ªï¼æåé æ¸¬æºç¢ºåº¦åä¿¡è³´åéçç²¾ç¢ºåº¦ãæåå°çå¯¦ä¸çè³æéçè©ä¼°ç¢ºèªï¼STMGNN-ZINB åªæ¼ç¾ææ¨¡åï¼æä¾äºä¸åæ´å¯é çå·¥å·ä¾é æ¸¬åçè§£ç¯ç½ªåæã

##### **Listwise Reward Estimation for Offline Preference-based Reinforcement Learning**
2408.04190v1 by Heewoong Choi, Sangwon Jung, Hongjoon Ahn, Taesup Moon

In Reinforcement Learning (RL), designing precise reward functions remains to
be a challenge, particularly when aligning with human intent. Preference-based
RL (PbRL) was introduced to address this problem by learning reward models from
human feedback. However, existing PbRL methods have limitations as they often
overlook the second-order preference that indicates the relative strength of
preference. In this paper, we propose Listwise Reward Estimation (LiRE), a
novel approach for offline PbRL that leverages second-order preference
information by constructing a Ranked List of Trajectories (RLT), which can be
efficiently built by using the same ternary feedback type as traditional
methods. To validate the effectiveness of LiRE, we propose a new offline PbRL
dataset that objectively reflects the effect of the estimated rewards. Our
extensive experiments on the dataset demonstrate the superiority of LiRE, i.e.,
outperforming state-of-the-art baselines even with modest feedback budgets and
enjoying robustness with respect to the number of feedbacks and feedback noise.
Our code is available at https://github.com/chwoong/LiRE

æè¦ï¼å¨å¼·åå­¸ç¿ (RL) ä¸­ï¼è¨­è¨ç²¾ç¢ºççåµå½æ¸ä»ç¶æ¯ä¸åææ°ï¼ç¹å¥æ¯å¨èäººé¡æåä¿æä¸è´æãåºæ¼åå¥½ç RL (PbRL) è¢«å¼å¥ä¾è§£æ±ºéååé¡ï¼æ¹æ³æ¯å¾äººé¡åé¥ä¸­å­¸ç¿çåµæ¨¡åãç¶èï¼ç¾æç PbRL æ¹æ³æå¶å±éæ§ï¼å çºå®åå¸¸å¸¸å¿½ç¥æç¤ºåå¥½ç¸å°å¼·åº¦çäºéåå¥½ãå¨æ¬æä¸­ï¼æåæåºäºåå®çåµä¼°è¨ (LiRE)ï¼éæ¯ä¸ç¨®é¢ç· PbRL çæ°æ¹æ³ï¼å®ééæ§å»ºè»éæåæ¸å® (RLT) ä¾å©ç¨äºéåå¥½è³è¨ï¼è RLT å¯ä»¥ééä½¿ç¨èå³çµ±æ¹æ³ç¸åçä¸äººåé¥é¡åä¾ææå»ºæ§ãçºäºé©è­ LiRE çæææ§ï¼æåæåºäºæ°çé¢ç· PbRL è³æéï¼è©²è³æéå®¢è§å°åæ äºä¼°è¨çåµçææãæåå¨è³æéä¸é²è¡çå»£æ³å¯¦é©è­æäº LiRE çåªè¶æ§ï¼å³å³ä½¿å¨é©åº¦çåé¥é ç®ä¸ï¼ä¹è½åªæ¼æåé²çåºç·ï¼ä¸¦ä¸å¨åé¥æ¸éååé¥éè¨æ¹é¢è¡¨ç¾åºç©©å¥æ§ãæåçç¨å¼ç¢¼å¯å¨ https://github.com/chwoong/LiRE åå¾

##### **wav2graph: A Framework for Supervised Learning Knowledge Graph from Speech**
2408.04174v1 by Khai Le-Duc, Quy-Anh Dang, Tan-Hanh Pham, Truong-Son Hy

Knowledge graphs (KGs) enhance the performance of large language models
(LLMs) and search engines by providing structured, interconnected data that
improves reasoning and context-awareness. However, KGs only focus on text data,
thereby neglecting other modalities such as speech. In this work, we introduce
wav2graph, the first framework for supervised learning knowledge graph from
speech data. Our pipeline are straightforward: (1) constructing a KG based on
transcribed spoken utterances and a named entity database, (2) converting KG
into embedding vectors, and (3) training graph neural networks (GNNs) for node
classification and link prediction tasks. Through extensive experiments
conducted in inductive and transductive learning contexts using
state-of-the-art GNN models, we provide baseline results and error analysis for
node classification and link prediction tasks on human transcripts and
automatic speech recognition (ASR) transcripts, including evaluations using
both encoder-based and decoder-based node embeddings, as well as monolingual
and multilingual acoustic pre-trained models. All related code, data, and
models are published online.

æè¦ï¼ç¥è­åè­ (KG) ééæä¾çµæ§åãç¸äºé£çµçè³æï¼é²èæ¹åå¤§åèªè¨æ¨¡å (LLM) åæå°å¼æçæè½ï¼æåæ¨çåèçµ¡æç¥ãç¶èï¼KG åªéæ³¨æå­è³æï¼å æ­¤å¿½ç¥äºå¶ä»å½¢å¼ï¼ä¾å¦èªé³ãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹ wav2graphï¼éæ¯ç¬¬ä¸åå¾èªé³è³æä¸­ç£ç£å­¸ç¿ç¥è­åè­çæ¶æ§ãæåçæµç¨å¾ç´æ¥ï¼(1) æ ¹æè½éçå£èªè¡¨éåå½åå¯¦é«è³æåº«å»ºæ§ KGï¼(2) å° KG è½æçºåµå¥åéï¼ä»¥å (3) è¨ç·´åå½¢ç¥ç¶ç¶²è·¯ (GNN) ä»¥é²è¡ç¯é»åé¡åé£çµé æ¸¬ä»»åãééä½¿ç¨æåé²ç GNN æ¨¡åå¨æ­¸ç´åè½å°å­¸ç¿çç°å¢ä¸­é²è¡å»£æ³çå¯¦é©ï¼æåæä¾ç¯é»åé¡åé£çµé æ¸¬ä»»åçåºæºçµæåé¯èª¤åæï¼å¶ä¸­åæ¬ä½¿ç¨ç·¨ç¢¼å¨çºåºç¤åè§£ç¢¼å¨çºåºç¤çç¯é»åµå¥ï¼ä»¥åå®èªåå¤èªé³å­¸é è¨ç·´æ¨¡åçè©ä¼°ãææç¸éç¨å¼ç¢¼ãè³æåæ¨¡åçå·²å¨ç·ä¸ç¼å¸ã

##### **Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions**
2408.04168v1 by Qingbin Zeng, Qinglong Yang, Shunan Dong, Heming Du, Liang Zheng, Fengli Xu, Yong Li

This paper considers a scenario in city navigation: an AI agent is provided
with language descriptions of the goal location with respect to some well-known
landmarks; By only observing the scene around, including recognizing landmarks
and road network connections, the agent has to make decisions to navigate to
the goal location without instructions. This problem is very challenging,
because it requires agent to establish self-position and acquire spatial
representation of complex urban environment, where landmarks are often
invisible. In the absence of navigation instructions, such abilities are vital
for the agent to make high-quality decisions in long-range city navigation.
With the emergent reasoning ability of large language models (LLMs), a tempting
baseline is to prompt LLMs to "react" on each observation and make decisions
accordingly. However, this baseline has very poor performance that the agent
often repeatedly visits same locations and make short-sighted, inconsistent
decisions. To address these issues, this paper introduces a novel agentic
workflow featured by its abilities to perceive, reflect and plan. Specifically,
we find LLaVA-7B can be fine-tuned to perceive the direction and distance of
landmarks with sufficient accuracy for city navigation. Moreover, reflection is
achieved through a memory mechanism, where past experiences are stored and can
be retrieved with current perception for effective decision argumentation.
Planning uses reflection results to produce long-term plans, which can avoid
short-sighted decisions in long-range navigation. We show the designed workflow
significantly improves navigation ability of the LLM agent compared with the
state-of-the-art baselines.

æè¦ï¼<paragraph>æ¬ææ¢è¨åå¸å°èªä¸­çå ´æ¯ï¼æä¾çµ¦ AI ä»£çéæ¼ç®æ¨ä½ç½®çèªè¨æè¿°ï¼ç¸å°æ¼ä¸äºèåçå°æ¨ï¼åééè§å¯å¨åå ´æ¯ï¼åæ¬è¾¨è­å°æ¨åéè·¯ç¶²è·¯é£æ¥ï¼ä»£çå¿é ååºæ±ºå®ï¼å¨æ²ææç¤ºçææ³ä¸å°èªå°ç®æ¨ä½ç½®ãéååé¡éå¸¸å·æææ°æ§ï¼å çºå®è¦æ±ä»£çå»ºç«èªæå®ä½ä¸¦åå¾è¤éåå¸ç°å¢çç©ºéè¡¨å¾µï¼å¶ä¸­å°æ¨éå¸¸æ¯ä¸å¯è¦çãå¨æ²æå°èªæç¤ºçææ³ä¸ï¼éäºè½åå°æ¼ä»£çå¨é·è·é¢åå¸å°èªä¸­ååºé«åè³ªçæ±ºç­è³ééè¦ãé¨èå¤§åèªè¨æ¨¡å (LLM) çæ¨çè½ååºç¾ï¼ä¸åèªäººçåºæºæ¯æç¤º LLM å°æ¯åè§å¯ãååºåæãä¸¦ææ­¤ååºæ±ºç­ãç¶èï¼éååºæºçæè½å¾å·®ï¼ä»£çç¶å¸¸éè¤é è¨ªç¸åå°é»ï¼ä¸¦ååºç­è¦ä¸ä¸ä¸è´çæ±ºç­ãçºäºè§£æ±ºéäºåé¡ï¼æ¬æä»ç´¹äºä¸ç¨®æ°ç©çä»£çå·¥ä½æµç¨ï¼å¶ç¹é»æ¯å·ææç¥ãåçåè¦åçè½åãå·é«ä¾èªªï¼æåç¼ç¾ LLaVA-7B å¯ä»¥å¾®èª¿ä»¥æç¥å°æ¨çæ¹ååè·é¢ï¼ä¸¦å·æè¶³å¤ çæºç¢ºåº¦é²è¡åå¸å°èªãæ­¤å¤ï¼åçæ¯ééè¨æ¶æ©å¶å¯¦ç¾çï¼å¶ä¸­éå»çç¶é©è¢«å²å­ï¼ä¸¦å¯èç¶åçæç¥ä¸èµ·æª¢ç´¢ï¼ä»¥é²è¡ææçæ±ºç­è«è­ãè¦åä½¿ç¨åççµæç¢çé·æè¨ç«ï¼éå¯ä»¥é¿åå¨é·è·é¢å°èªä¸­ååºç­è¦çæ±ºç­ãæåå±ç¤ºè¨­è¨çå·¥ä½æµç¨é¡¯èæåäº LLM ä»£ççå°èªè½åï¼åªæ¼æåé²çåºæºã</paragraph>

##### **Semantics or spelling? Probing contextual word embeddings with orthographic noise**
2408.04162v1 by Jacob A. Matthews, John R. Starr, Marten van Schijndel

Pretrained language model (PLM) hidden states are frequently employed as
contextual word embeddings (CWE): high-dimensional representations that encode
semantic information given linguistic context. Across many areas of
computational linguistics research, similarity between CWEs is interpreted as
semantic similarity. However, it remains unclear exactly what information is
encoded in PLM hidden states. We investigate this practice by probing PLM
representations using minimal orthographic noise. We expect that if CWEs
primarily encode semantic information, a single character swap in the input
word will not drastically affect the resulting representation,given sufficient
linguistic context. Surprisingly, we find that CWEs generated by popular PLMs
are highly sensitive to noise in input data, and that this sensitivity is
related to subword tokenization: the fewer tokens used to represent a word at
input, the more sensitive its corresponding CWE. This suggests that CWEs
capture information unrelated to word-level meaning and can be manipulated
through trivial modifications of input data. We conclude that these PLM-derived
CWEs may not be reliable semantic proxies, and that caution is warranted when
interpreting representational similarity

æè¦ï¼é è¨ç·´èªè¨æ¨¡å (PLM) çé±èçæç¶å¸¸è¢«ç¨ä½
èªå¢åå­è©åµå¥ (CWE)ï¼ç·¨ç¢¼
çµ¦å®èªè¨èªå¢çèªç¾©è¨æ¯çé«ç¶­è¡¨ç¤ºãå¨
è¨ç®èªè¨å­¸ç ç©¶çè¨±å¤é åä¸­ï¼CWE ä¹éçç¸ä¼¼æ§è¢«è§£éçº
èªç¾©ç¸ä¼¼æ§ãç¶èï¼ä»ä¸æ¸æ¥ PLM é±èçæä¸­ç·¨ç¢¼äºåªäºè¨æ¯ãæåä½¿ç¨æå°çæ­£å­æ³éè¨æ¢æ¸¬ PLM
è¡¨ç¤ºä¾èª¿æ¥æ­¤åæ³ãæåé æï¼å¦æ CWE ä¸»è¦ç·¨ç¢¼èªç¾©è¨æ¯ï¼è¼¸å¥
å­è©ä¸­çå®ä¸å­åäº¤æå°ä¸æå¤§å¹å½±é¿ç¢ççè¡¨ç¤ºï¼åªè¦æè¶³å¤ ç
èªè¨èªå¢ãä»¤äººé©è¨çæ¯ï¼æåç¼ç¾ç±ç±é PLM ç¢çç CWE å°è¼¸å¥è³æä¸­çéè¨é«åº¦ææï¼èä¸éç¨®æææ§èå­å­è©æ¨è¨åæéï¼ç¨æ¼è¡¨ç¤ºè¼¸å¥ä¸­å­è©çæ¨è¨è¶å°ï¼å¶å°æç CWE å°±è¶ææãéè¡¨æ CWE æ·åèå­è©å±¤ç´æç¾©ç¡éçè¨æ¯ï¼ä¸¦ä¸å¯ä»¥ééè¼¸å¥è³æçå¾®å°ä¿®æ¹ä¾æç¸±ãæåå¾åºçµè«ï¼éäº PLM è¡çç CWE å¯è½ä¸æ¯å¯é çèªç¾©ä»£çï¼ä¸¦ä¸å¨
è§£éè¡¨ç¤ºç¸ä¼¼æ§ææè¬¹æ

##### **The Data Addition Dilemma**
2408.04154v1 by Judy Hanwen Shen, Inioluwa Deborah Raji, Irene Y. Chen

In many machine learning for healthcare tasks, standard datasets are
constructed by amassing data across many, often fundamentally dissimilar,
sources. But when does adding more data help, and when does it hinder progress
on desired model outcomes in real-world settings? We identify this situation as
the \textit{Data Addition Dilemma}, demonstrating that adding training data in
this multi-source scaling context can at times result in reduced overall
accuracy, uncertain fairness outcomes, and reduced worst-subgroup performance.
We find that this possibly arises from an empirically observed trade-off
between model performance improvements due to data scaling and model
deterioration from distribution shift. We thus establish baseline strategies
for navigating this dilemma, introducing distribution shift heuristics to guide
decision-making on which data sources to add in data scaling, in order to yield
the expected model performance improvements. We conclude with a discussion of
the required considerations for data collection and suggestions for studying
data composition and scale in the age of increasingly larger models.

æè¦ï¼å¨è¨±å¤é«çä¿å¥ä»»åçæ©å¨å­¸ç¿ä¸­ï¼æ¨æºè³æéæ¯ééæ¶éä¾èªè¨±å¤éå¸¸æ ¹æ¬ä¸åçä¾æºçè³æèå»ºæ§çãä½æ¯ï¼ä½ææ°å¢æ´å¤è³ææå¹«å©ï¼èä½ææé»ç¤å¨ç¾å¯¦ä¸çè¨­å®ä¸­éæé æçæ¨¡åææï¼æåå°æ­¤ææ³èªå®çºãè³ææ°å¢å°å¢ãï¼è­æå¨æ­¤å¤ä¾æºæ´åçèæ¯ä¸æ°å¢è¨ç·´è³æï¼ææå¯è½æå°è´æ´é«æºç¢ºåº¦éä½ãä¸ç¢ºå®çå¬å¹³æ§çµæï¼ä»¥åæå·®å­ç¾¤é«æè½éä½ãæåç¼ç¾éå¯è½æ¯ç±æ¼è³ææ´åå°è´çæ¨¡åæè½æåèåéè½ç§»å°è´çæ¨¡åå£åä¹éçç¶é©æ§æ¬è¡¡æè´ãå æ­¤ï¼æåå»ºç«äºæå°æ­¤å°å¢çåºæ¬ç­ç¥ï¼å¼å¥äºåéè½ç§»åç¼æ³ï¼ä»¥æå°æéå¨è³ææ´åä¸­æ°å¢åªäºè³æä¾æºçæ±ºç­å¶å®ï¼ä»¥ç¢çé æçæ¨¡åæè½æåãæåæå¾è¨è«äºè³ææ¶éæéçèéå ç´ ï¼ä¸¦å»ºè­°ç ç©¶è³æçµæåè¦æ¨¡å¨æ¨¡åè¦æ¨¡æ¥çæ´å¤§çæä»£ã

##### **UNLEARN Efficient Removal of Knowledge in Large Language Models**
2408.04140v1 by Tyler Lizzo, Larry Heck

Given the prevalence of large language models (LLMs) and the prohibitive cost
of training these models from scratch, dynamically forgetting specific
knowledge e.g., private or proprietary, without retraining the model has become
an important capability. This paper proposes a novel method to achieve this
objective called UNLEARN. The approach builds upon subspace methods to identify
and specifically target the removal of knowledge without adversely affecting
other knowledge in the LLM. Results demonstrate 96% of targeted knowledge can
be forgotten while maintaining performance on other knowledge within 2.5% of
the original model, significantly outperforming the discriminatory abilities of
the previous state-of-the-art. A dual method called LEARN is also proposed for
targeted knowledge addition. Results show LEARN can match the fine-tuning
accuracy of Low-Rank Adaptation (LoRA) without adversely affecting similar
tasks.

æè¦ï¼éæ¼å¤§åèªè¨æ¨¡å (LLM) ççè¡ï¼ä»¥åå¾é ­è¨ç·´éäºæ¨¡åçé«æææ¬ï¼åæéºå¿ç¹å®ç¥è­ï¼ä¾å¦ç§äººæå°æç¥è­ï¼ï¼èç¡ééæ°è¨ç·´æ¨¡åï¼å·²æçºä¸é éè¦çåè½ãæ¬ææåºäºä¸ç¨®æ°çæ¹æ³ä¾å¯¦ç¾éåç®æ¨ï¼ç¨±çº UNLEARNãæ­¤æ¹æ³å»ºç«å¨å­ç©ºéæ¹æ³ä¹ä¸ï¼ç¨æ¼è­å¥ä¸¦ç¹å¥éå°ç¥è­ç§»é¤ï¼èä¸æå° LLM ä¸­çå¶ä»ç¥è­é æä¸å©å½±é¿ãçµæè¡¨æï¼96% çç®æ¨ç¥è­å¯ä»¥è¢«éºå¿ï¼åæå¨å¶ä»ç¥è­ä¸çæè½ç¶­æå¨åå§æ¨¡åç 2.5% ä»¥å§ï¼é¡¯èåªæ¼ååæåé²æè¡çè­å¥è½åãéæåºäºä¸ç¨®ç¨±çº LEARN çééæ¹æ³ï¼ç¨æ¼ç®æ¨ç¥è­æ°å¢ãçµæé¡¯ç¤ºï¼LEARN å¯ä»¥å¹éä½ç§©é©æ (LoRA) çå¾®èª¿æºç¢ºåº¦ï¼èä¸æå°é¡ä¼¼ä»»åé æä¸å©å½±é¿ã

##### **Enhancing Healthcare through Large Language Models: A Study on Medical Question Answering**
2408.04138v1 by Haoran Yu, Chang Yu, Zihan Wang, Dongxian Zou, Hao Qin

In recent years, the application of Large Language Models (LLMs) in
healthcare has shown significant promise in improving the accessibility and
dissemination of medical knowledge. This paper presents a detailed study of
various LLMs trained on the MedQuAD medical question-answering dataset, with a
focus on identifying the most effective model for providing accurate medical
information. Among the models tested, the Sentence-t5 combined with Mistral 7B
demonstrated superior performance, achieving a precision score of 0.762. This
model's enhanced capabilities are attributed to its advanced pretraining
techniques, robust architecture, and effective prompt construction
methodologies. By leveraging these strengths, the Sentence-t5 + Mistral 7B
model excels in understanding and generating precise medical answers. Our
findings highlight the potential of integrating sophisticated LLMs in medical
contexts to facilitate efficient and accurate medical knowledge retrieval, thus
significantly enhancing patient education and support.

æè¦ï¼è¿å¹´ä¾ï¼å¤§åèªè¨æ¨¡å (LLM) å¨é«çä¿å¥ä¸­çæç¨å·²å±ç¾åºé¡¯èçå¸æï¼å¯æ¹åé«çç¥è­çå¯åæ§åå³æ­ãæ¬æéå°å¨ MedQuAD é«çåç­è³æéä¸è¨ç·´çåç¨® LLM é²è¡è©³ç´°ç ç©¶ï¼éé»å¨æ¼æ¾åºæä¾æºç¢ºé«çè³è¨æææçæ¨¡åãå¨æ¸¬è©¦çæ¨¡åä¸­ï¼Sentence-t5 çµå Mistral 7B è¡¨ç¾åªç°ï¼éå° 0.762 çç²¾æºåº¦åæ¸ãæ­¤æ¨¡åçå¢å¼·åè½æ­¸åæ¼å¶åé²çé è¨ç·´æè¡ãå¼·å¤§çæ¶æ§åææçæç¤ºå»ºæ§æ¹æ³ãSentence-t5 + Mistral 7B æ¨¡åèç±éç¨éäºåªå¢ï¼å¨çè§£åç¢çç²¾ç¢ºçé«çç­æ¡æ¹é¢è¡¨ç¾åºè²ãæåçç ç©¶çµæçªé¡¯äºå°è¤éç LLM æ´åå°é«çèæ¯ä¸­çæ½åï¼ä»¥ä¿é²ææçä¸æºç¢ºçé«çç¥è­æ·åï¼é²èé¡¯èæåçæ£æè²åæ¯æã

##### **Incorporating Spatial Awareness in Data-Driven Gesture Generation for Virtual Agents**
2408.04127v1 by Anna Deichler, Simon Alexanderson, Jonas Beskow

This paper focuses on enhancing human-agent communication by integrating
spatial context into virtual agents' non-verbal behaviors, specifically
gestures. Recent advances in co-speech gesture generation have primarily
utilized data-driven methods, which create natural motion but limit the scope
of gestures to those performed in a void. Our work aims to extend these methods
by enabling generative models to incorporate scene information into
speech-driven gesture synthesis. We introduce a novel synthetic gesture dataset
tailored for this purpose. This development represents a critical step toward
creating embodied conversational agents that interact more naturally with their
environment and users.

æè¦ï¼æ¬æéé»å¨æ¼ééå°ç©ºéèçµ¡æ´åè³èæ¬ä»£çäººçéèªè¨è¡çºï¼ç¹å¥æ¯æå¢ï¼ä¾å¢é²äººæ©æºéãè¿æå¨å±èªæå¢çææ¹é¢çé²å±ä¸»è¦ä½¿ç¨è³æé©åæ¹æ³ï¼éç¨®æ¹æ³æç¢çèªç¶åä½ï¼ä½æå°æå¢ç¯åéå¶çºå¨çç©ºä¸­å·è¡çåä½ãæåçç ç©¶æ¨å¨ééè®çææ¨¡åå°å ´æ¯è³è¨ç´å¥èªé³é©åæå¢åæä¸­ï¼ä¾å»¶ä¼¸éäºæ¹æ³ãæåå¼å¥ä¸åæ°çåææå¢è³æéï¼å°éç¨æ¼æ­¤ç®çãæ­¤ç¼å±ä»£è¡¨äºå¨åµé èç°å¢åä½¿ç¨èäºåæ´èªç¶çèº«é«åå°è©±ä»£çäººæ¹é¢éåºçééµä¸æ­¥ã

##### **Can Rule-Based Insights Enhance LLMs for Radiology Report Classification? Introducing the RadPrompt Methodology**
2408.04121v1 by Panagiotis Fytas, Anna Breger, Ian Selby, Simon Baker, Shahab Shahipasand, Anna Korhonen

Developing imaging models capable of detecting pathologies from chest X-rays
can be cost and time-prohibitive for large datasets as it requires supervision
to attain state-of-the-art performance. Instead, labels extracted from
radiology reports may serve as distant supervision since these are routinely
generated as part of clinical practice. Despite their widespread use, current
rule-based methods for label extraction rely on extensive rule sets that are
limited in their robustness to syntactic variability. To alleviate these
limitations, we introduce RadPert, a rule-based system that integrates an
uncertainty-aware information schema with a streamlined set of rules, enhancing
performance. Additionally, we have developed RadPrompt, a multi-turn prompting
strategy that leverages RadPert to bolster the zero-shot predictive
capabilities of large language models, achieving a statistically significant
improvement in weighted average F1 score over GPT-4 Turbo. Most notably,
RadPrompt surpasses both its underlying models, showcasing the synergistic
potential of LLMs with rule-based models. We have evaluated our methods on two
English Corpora: the MIMIC-CXR gold-standard test set and a gold-standard
dataset collected from the Cambridge University Hospitals.

æè¦ï¼éç¼åºè½å¤ å¾è¸é¨ X åæª¢æ¸¬çççå½±åæ¨¡åï¼å°æ¼å¤§åè³æéä¾èªªï¼å¨ææ¬åæéä¸é½å¯è½æ¯ç¦æ­¢çï¼å çºå®éè¦ç£ç£æè½éå°æåé²çæè½ãç¸åå°ï¼å¾æ¾å°ç§å ±åä¸­æåçæ¨ç±¤å¯ä»¥ç¨ä½é ç«¯ç£ç£ï¼å çºéäºæ¨ç±¤éå¸¸ä½çºè¨åºå¯¦åçä¸é¨åèç¢çãåç®¡å»£æ³ä½¿ç¨ï¼ä½ç®åç¨æ¼æ¨ç±¤æåçåºæ¼è¦åçæ¹æ³ä¾è³´æ¼å»£æ³çè¦åéï¼å¶å°èªæ³è®ç°çå¥å£¯æ§æéãçºäºæ¸è¼éäºéå¶ï¼æåå¼å¥äº RadPertï¼éæ¯ä¸ååºæ¼è¦åçç³»çµ±ï¼å®å°ä¸åä¸ç¢ºå®æ§æç¥è³è¨æ¶æ§èä¸çµç°¡åçè¦åæ´åå¨ä¸èµ·ï¼å¾èå¢å¼·äºæè½ãæ­¤å¤ï¼æåééç¼äº RadPromptï¼éæ¯ä¸åå¤è¼ªæç¤ºç­ç¥ï¼å®å©ç¨ RadPert ä¾å å¼·å¤§åèªè¨æ¨¡åçé¶æ¬¡å­¸ç¿é æ¸¬è½åï¼å¨å æ¬å¹³å F1 åæ¸ä¸å¯¦ç¾äºç¸å°æ¼ GPT-4 Turbo ççµ±è¨é¡¯èæ¹é²ãæå¼å¾æ³¨æçæ¯ï¼RadPrompt è¶è¶äºå¶åºç¤æ¨¡åï¼å±ç¤ºäºåºæ¼è¦åçæ¨¡åè LLM çååæ½åãæåå·²å¨å©åè±æèªæåº«ä¸è©ä¼°äºæåçæ¹æ³ï¼MIMIC-CXR é»éæ¨æºæ¸¬è©¦éåå¾åæ©å¤§å­¸é«é¢æ¶éçé»éæ¨æºè³æéã

##### **Zero-shot Factual Consistency Evaluation Across Domains**
2408.04114v1 by Raunak Agarwal

This work addresses the challenge of factual consistency in text generation
systems. We unify the tasks of Natural Language Inference, Summarization
Evaluation, Factuality Verification and Factual Consistency Evaluation to train
models capable of evaluating the factual consistency of source-target pairs
across diverse domains. We rigorously evaluate these against eight baselines on
a comprehensive benchmark suite comprising 22 datasets that span various tasks,
domains, and document lengths. Results demonstrate that our method achieves
state-of-the-art performance on this heterogeneous benchmark while addressing
efficiency concerns and attaining cross-domain generalization.

æè¦ï¼éé å·¥ä½æ¢è¨äºææ¬çæç³»çµ±ä¸­äºå¯¦ä¸è´æ§çææ°ãæåçµ±ä¸èªç¶èªè¨æ¨è«ãæè¦è©ä¼°ãäºå¯¦é©è­åäºå¯¦ä¸è´æ§è©ä¼°çä»»åï¼ä»¥è¨ç·´åºè½å¤ è©ä¼°è·¨ä¸åé åçä¾æºç®æ¨å°çäºå¯¦ä¸è´æ§çæ¨¡åãæåä½¿ç¨åå« 22 åè³æéçç¶ååºæºå¥ä»¶ï¼å´æ ¼è©ä¼°éäºæ¨¡åï¼éäºè³æéæ¶µèåç¨®ä»»åãé ååæä»¶é·åº¦ãçµæè¡¨æï¼æåçæ¨¡åå¨æ­¤ç°è³ªåºæºä¸åå¾äºæåé²çæè½ï¼åæè§£æ±ºäºæçåé¡ä¸¦å¯¦ç¾äºè·¨é åæ¦åã

##### **Patchview: LLM-Powered Worldbuilding with Generative Dust and Magnet Visualization**
2408.04112v1 by John Joon Young Chung, Max Kreminski

Large language models (LLMs) can help writers build story worlds by
generating world elements, such as factions, characters, and locations.
However, making sense of many generated elements can be overwhelming. Moreover,
if the user wants to precisely control aspects of generated elements that are
difficult to specify verbally, prompting alone may be insufficient. We
introduce Patchview, a customizable LLM-powered system that visually aids
worldbuilding by allowing users to interact with story concepts and elements
through the physical metaphor of magnets and dust. Elements in Patchview are
visually dragged closer to concepts with high relevance, facilitating
sensemaking. The user can also steer the generation with verbally elusive
concepts by indicating the desired position of the element between concepts.
When the user disagrees with the LLM's visualization and generation, they can
correct those by repositioning the element. These corrections can be used to
align the LLM's future behaviors to the user's perception. With a user study,
we show that Patchview supports the sensemaking of world elements and steering
of element generation, facilitating exploration during the worldbuilding
process. Patchview provides insights on how customizable visual representation
can help sensemake, steer, and align generative AI model behaviors with the
user's intentions.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¯ä»¥ééç¢çä¸çåç´ ï¼ä¾å¦æ´¾ç³»ãè§è²åå°é»ï¼ä¾åå©ä½å®¶å»ºæ§æäºä¸çãä¸éï¼è¦çè§£è¨±å¤ç¢ççåç´ å¯è½æè®äººä¸ç¥ææªãæ­¤å¤ï¼å¦æä½¿ç¨èæ³è¦ç²¾ç¢ºæ§å¶é£ä»¥ç¨è¨èªèªªæçç¢çåç´ é¢åï¼é£éº¼å®ç´çæç¤ºå¯è½ä¸è¶³å¤ ãæåä»ç´¹ Patchviewï¼éæ¯ä¸åå¯èªè¨ç LLM é©åç³»çµ±ï¼ééç£éµåç°å¡µçå¯¦é«é±å»ï¼è®ä½¿ç¨èè½èæäºæ¦å¿µååç´ é²è¡äºåï¼é²èè¦è¦ºååå©å»ºæ§ä¸çãPatchview ä¸­çåç´ æè¢«è¦è¦ºåå°ææ³å°é«åº¦ç¸éçæ¦å¿µéè¿ï¼ä¿é²çè§£ãä½¿ç¨èä¹å¯ä»¥ééæåºåç´ å¨æ¦å¿µä¹éççæ³ä½ç½®ï¼ä¾å¼å°ç¢çé£ä»¥ç¨è¨èªè¡¨éçæ¦å¿µãç¶ä½¿ç¨èä¸åæ LLM çè¦è¦ºååç¢çæï¼ä»åå¯ä»¥éééæ°å®ä½åç´ ä¾é²è¡ä¿®æ­£ãéäºä¿®æ­£å¯ä»¥èª¿æ´ LLM æªä¾çè¡çºï¼èä½¿ç¨èçèªç¥ä¿æä¸è´ãééä½¿ç¨èç ç©¶ï¼æåå±ç¤º Patchview æ¯æ´ä¸çåç´ ççè§£ååç´ ç¢ççå¼å°ï¼ä¿é²å»ºæ§ä¸çéç¨ä¸­çæ¢ç´¢ãPatchview æä¾è¦è§£ï¼èªªæå¯èªè¨çè¦è¦ºåè¡¨ç¤ºå¦ä½åå©çè§£ãå¼å°åèª¿æ´ç¢çå¼ AI æ¨¡åçè¡çºï¼ä»¥ç¬¦åä½¿ç¨èçæåã

##### **Hardware-Assisted Virtualization of Neural Processing Units for Cloud Platforms**
2408.04104v1 by Yuqi Xue, Yiqi Liu, Lifeng Nai, Jian Huang

Cloud platforms today have been deploying hardware accelerators like neural
processing units (NPUs) for powering machine learning (ML) inference services.
To maximize the resource utilization while ensuring reasonable quality of
service, a natural approach is to virtualize NPUs for efficient resource
sharing for multi-tenant ML services. However, virtualizing NPUs for modern
cloud platforms is not easy. This is not only due to the lack of system
abstraction support for NPU hardware, but also due to the lack of architectural
and ISA support for enabling fine-grained dynamic operator scheduling for
virtualized NPUs.
  We present TCloud, a holistic NPU virtualization framework. We investigate
virtualization techniques for NPUs across the entire software and hardware
stack. TCloud consists of (1) a flexible NPU abstraction called vNPU, which
enables fine-grained virtualization of the heterogeneous compute units in a
physical NPU (pNPU); (2) a vNPU resource allocator that enables pay-as-you-go
computing model and flexible vNPU-to-pNPU mappings for improved resource
utilization and cost-effectiveness; (3) an ISA extension of modern NPU
architecture for facilitating fine-grained tensor operator scheduling for
multiple vNPUs. We implement TCloud based on a production-level NPU simulator.
Our experiments show that TCloud improves the throughput of ML inference
services by up to 1.4$\times$ and reduces the tail latency by up to
4.6$\times$, while improving the NPU utilization by 1.2$\times$ on average,
compared to state-of-the-art NPU sharing approaches.

æè¦ï¼ç¾ä»çé²ç«¯å¹³å°å·²é¨ç½²ç¥ç¶èçå®å (NPU) ç­ç¡¬é«å éå¨ï¼ç¨æ¼æ¯æ´æ©å¨å­¸ç¿ (ML) æ¨è«æåãçºäºå¨ç¢ºä¿åçæååè³ªçåææå¤§åè³æºä½¿ç¨çï¼ä¸ç¨®èªç¶çæ¹æ³æ¯å° NPU èæ¬åï¼ä»¥ææçå°çºå¤ç§æ¶ ML æåå±äº«è³æºãç¶èï¼çºç¾ä»£é²ç«¯å¹³å°èæ¬å NPU ä¸¦ä¸å®¹æãéä¸åæ¯å çºç¼ºä¹å° NPU ç¡¬é«çç³»çµ±æ½è±¡æ¯æ´ï¼éå çºç¼ºä¹æ¶æ§å ISA æ¯æ´ï¼ç¡æ³å°èæ¬å NPU é²è¡ç´°ç²åº¦çåæéç®å­æç¨ã
æåæåº TCloudï¼ä¸åæ´é«ç NPU èæ¬åæ¶æ§ãæåç ç©¶äºéå°æ´åè»é«åç¡¬é«å çç NPU èæ¬åæè¡ãTCloud åå« (1) ä¸åç¨±çº vNPU çå½æ§ NPU æ½è±¡ï¼å®è½å°å¯¦é« NPU (pNPU) ä¸­çç°è³ªéç®å®åé²è¡ç´°ç²åº¦çèæ¬åï¼(2) ä¸å vNPU è³æºåéå¨ï¼å®è½æ¯æ´æéä»è²»çéç®æ¨¡å¼åå½æ§ç vNPU å°æ pNPU æ å°ï¼ä»¥æ¹åè³æºä½¿ç¨çåææ¬æçï¼(3) ç¾ä»£ NPU æ¶æ§ç ISA å»¶ä¼¸ï¼ç¨æ¼ä¿é²éå°å¤å vNPU çç´°ç²åº¦å¼µééç®å­æç¨ãæåæ ¹æçç¢ç´å¥ç NPU æ¨¡æ¬å¨å¯¦ä½ TCloudãæåçå¯¦é©é¡¯ç¤ºï¼èæåé²ç NPU å±äº«æ¹æ³ç¸æ¯ï¼TCloud å° ML æ¨è«æåçååéæåäº 1.4 åï¼å°å°¾é¨å»¶é²éä½äº 4.6 åï¼åæå° NPU ä½¿ç¨çå¹³åæåäº 1.2 åã

##### **ArtVLM: Attribute Recognition Through Vision-Based Prefix Language Modeling**
2408.04102v1 by William Y. Zhu, Keren Ye, Junjie Ke, Jiahui Yu, Leonidas Guibas, Peyman Milanfar, Feng Yang

Recognizing and disentangling visual attributes from objects is a foundation
to many computer vision applications. While large vision language
representations like CLIP had largely resolved the task of zero-shot object
recognition, zero-shot visual attribute recognition remains a challenge because
CLIP's contrastively-learned vision-language representation cannot effectively
capture object-attribute dependencies. In this paper, we target this weakness
and propose a sentence generation-based retrieval formulation for attribute
recognition that is novel in 1) explicitly modeling a to-be-measured and
retrieved object-attribute relation as a conditional probability graph, which
converts the recognition problem into a dependency-sensitive language-modeling
problem, and 2) applying a large pretrained Vision-Language Model (VLM) on this
reformulation and naturally distilling its knowledge of image-object-attribute
relations to use towards attribute recognition. Specifically, for each
attribute to be recognized on an image, we measure the visual-conditioned
probability of generating a short sentence encoding the attribute's relation to
objects on the image. Unlike contrastive retrieval, which measures likelihood
by globally aligning elements of the sentence to the image, generative
retrieval is sensitive to the order and dependency of objects and attributes in
the sentence. We demonstrate through experiments that generative retrieval
consistently outperforms contrastive retrieval on two visual reasoning
datasets, Visual Attribute in the Wild (VAW), and our newly-proposed Visual
Genome Attribute Ranking (VGARank).

æè¦ï¼è¾¨è­åååç©ä»¶çè¦è¦ºå±¬æ§ï¼æ¯è¨±å¤é»è¦è¦è¦ºæç¨ç¨å¼çåºç¤ãéç¶å CLIP éæ¨£çå¤§åè¦è¦ºèªè¨è¡¨å¾µï¼å·²å¨å¾å¤§ç¨åº¦ä¸è§£æ±ºäºé¶æ¬¡å­¸ç¿ç©ä»¶è¾¨è­çä»»åï¼ä½é¶æ¬¡å­¸ç¿è¦è¦ºå±¬æ§è¾¨è­ä»ç¶æ¯ä¸åææ°ï¼å çº CLIP å°æ¯å­¸ç¿çè¦è¦ºèªè¨è¡¨å¾µï¼ç¡æ³æææ·åç©ä»¶å±¬æ§ä¾è³´æ§ãå¨æ¬æä¸­ï¼æåéå°æ­¤å¼±é»ï¼ä¸¦æåºä¸ååºæ¼å¥å­çæçæª¢ç´¢å¬å¼ï¼ç¨æ¼å±¬æ§è¾¨è­ï¼å¶æ°ç©ä¹èå¨æ¼ï¼1) æç¢ºå°å°å¾æ¸¬éåæª¢ç´¢çç©ä»¶å±¬æ§éä¿å»ºæ¨¡çºæ¢ä»¶æ©çåï¼éå°è¾¨è­åé¡è½æçºä¾è³´ææçèªè¨æ¨¡ååé¡ï¼2) å¨æ­¤éæ°å¬å¼åä¸æç¨å¤§åé è¨ç·´çè¦è¦ºèªè¨æ¨¡å (VLM)ï¼ä¸¦èªç¶å°èåå¶å°å½±åç©ä»¶å±¬æ§éä¿çç¥è­ï¼ç¨æ¼å±¬æ§è¾¨è­ãå·é«ä¾èªªï¼å°æ¼è¦å¨å½±åä¸è¾¨è­çæ¯åå±¬æ§ï¼æåæ¸¬éå¨å½±åä¸ç·¨ç¢¼å±¬æ§èç©ä»¶éä¿çç°¡ç­å¥å­çè¦è¦ºæ¢ä»¶æ©çãèå°æ¯æª¢ç´¢ä¸åï¼å°æ¯æª¢ç´¢æ¯ééå°å¥å­çåç´ æ´é«æ¯å°å°å½±åä¾æ¸¬éå¯è½æ§ï¼çææª¢ç´¢åå°å¥å­ä¸­ç©ä»¶åå±¬æ§çé åºåä¾è³´æ§å¾ææãæåééå¯¦é©è­æï¼çææª¢ç´¢å¨å©åè¦è¦ºæ¨çè³æéï¼éå¤è¦è¦ºå±¬æ§ (VAW) åæåæ°æåºçè¦è¦ºåºå çµå±¬æ§æå (VGARank) ä¸ï¼å§çµåªæ¼å°æ¯æª¢ç´¢ã

##### **Tree Attention: Topology-aware Decoding for Long-Context Attention on GPU clusters**
2408.04093v1 by Vasudev Shyam, Jonathan Pilault, Emily Shepperd, Quentin Anthony, Beren Millidge

Self-attention is the core mathematical operation of modern transformer
architectures and is also a significant computational bottleneck due to its
quadratic complexity in the sequence length. In this work, we derive the scalar
energy function whose gradient computes the self-attention block, thus
elucidating the theoretical underpinnings of self-attention, providing a
Bayesian interpretation of the operation and linking it closely with
energy-based models such as Hopfield Networks. Moreover, due to this
formulation, we discover that we can use efficient and optimized
automatic-differentiation techniques to derive a highly efficient Tree
Attention algorithm to compute the gradient of the energy and hence
self-attention. Our formulation reveals that the reduction across the sequence
axis can be efficiently computed in parallel through a tree reduction. Our
algorithm, for parallelizing attention computation across multiple GPUs,
enables cross-device decoding to be performed asymptotically faster (up to 8x
faster) than alternative approaches such as Ring Attention, while also
requiring significantly less communication volume and incurring 2x less peak
memory. Our code is publicly available here:
\url{https://github.com/Zyphra/tree_attention}

æè¦ï¼èªææ³¨æåæ¯ç¾ä»£Transformeræ¶æ§çæ ¸å¿æ¸å­¸éç®ï¼èä¸ç±æ¼å¶å¨åºåé·åº¦ä¸­çäºæ¬¡è¤éæ§ï¼å®ä¹æ¯ä¸åéè¦çè¨ç®ç¶é ¸ãå¨éé å·¥ä½ä¸­ï¼æåæ¨å°åºæ¨éè½éå½æ¸ï¼å¶æ¢¯åº¦è¨ç®èªææ³¨æååå¡ï¼å¾èé¡æèªææ³¨æåççè«åºç¤ï¼æä¾è©²éç®çè²èæ¯è©®éï¼ä¸¦å°å¶èåºæ¼è½éçæ¨¡åï¼ä¾å¦éæ®è²ç¾å¾·ç¶²è·¯ï¼ç·å¯é£çµãæ­¤å¤ï¼ç±æ¼éåå¬å¼ï¼æåç¼ç¾æåå¯ä»¥ä½¿ç¨é«æä¸æä½³åçèªåå¾®åæè¡ä¾æ¨å°ä¸åé«æçæ¨¹æ³¨æåæ¼ç®æ³ï¼ä»¥è¨ç®è½éçæ¢¯åº¦ï¼å¾èèªææ³¨æãæåçå¬å¼æ­ç¤ºäºåºåè»¸ä¸çç´ç°¡å¯ä»¥ééæ¨¹ç´ç°¡ææå°ä¸¦è¡è¨ç®ãæåçæ¼ç®æ³ï¼ç¨æ¼å¨å¤å GPU ä¸ä¸¦è¡åæ³¨æåè¨ç®ï¼ä½¿è·¨è£ç½®è§£ç¢¼è½å¤ æ¯æ¿ä»£æ¹æ³ï¼ä¾å¦ç°å½¢æ³¨æåï¼å·è¡å¾æ´å¿«ï¼å¿« 8 åï¼ï¼åæä¹éè¦é¡¯èæ¸å°éè¨éï¼ä¸¦æ¸å° 2 åçå³°å¼è¨æ¶é«ãæåçç¨å¼ç¢¼å¨æ­¤å¬éï¼
\url{https://github.com/Zyphra/tree_attention}

##### **AEye: A Visualization Tool for Image Datasets**
2408.04072v1 by Florian GrÃ¶tschla, Luca A. LanzendÃ¶rfer, Marco Calzavara, Roger Wattenhofer

Image datasets serve as the foundation for machine learning models in
computer vision, significantly influencing model capabilities, performance, and
biases alongside architectural considerations. Therefore, understanding the
composition and distribution of these datasets has become increasingly crucial.
To address the need for intuitive exploration of these datasets, we propose
AEye, an extensible and scalable visualization tool tailored to image datasets.
AEye utilizes a contrastively trained model to embed images into semantically
meaningful high-dimensional representations, facilitating data clustering and
organization. To visualize the high-dimensional representations, we project
them onto a two-dimensional plane and arrange images in layers so users can
seamlessly navigate and explore them interactively. AEye facilitates semantic
search functionalities for both text and image queries, enabling users to
search for content. We open-source the codebase for AEye, and provide a simple
configuration to add datasets.

æè¦ï¼ååè³æéä½çºé»è¦è¦è¦ºä¸­æ©å¨å­¸ç¿æ¨¡åçåºç¤ï¼é¤äºæ¶æ§èéå¤ï¼ä¹é¡¯èå½±é¿æ¨¡åçè½åãæè½ååå·®ãå æ­¤ï¼äºè§£éäºè³æéççµæååä½è®å¾è¶ä¾è¶éè¦ãçºäºæ»¿è¶³ç´è§æ¢ç´¢éäºè³æéçéæ±ï¼æåæåº AEyeï¼ä¸ç¨®éå°ååè³æééèº«æé çå¯å»¶ä¼¸åå¯æ´åè¦è¦ºåå·¥å·ãAEye å©ç¨å°æ¯è¨ç·´æ¨¡åå°åååµå¥å°å·æèªç¾©æç¾©çé«ç¶­è¡¨ç¤ºä¸­ï¼ä¿é²è³æç¾¤éåçµç¹ãçºäºè¦è¦ºåé«ç¶­è¡¨ç¤ºï¼æåå°å®åæå½±å°ä¸åäºç¶­å¹³é¢ï¼ä¸¦å°åååå±¤æåï¼ä»¥ä¾¿ä½¿ç¨èå¯ä»¥ç¡ç¸«å°çè¦½åäºåæ¢ç´¢å®åãAEye ä¿é²èªç¾©æå°åè½ï¼é©ç¨æ¼æå­åååæ¥è©¢ï¼ä½¿ç¨æ¶è½å¤ æå°å§å®¹ãæåéæ¾ AEye çç¨å¼ç¢¼åº«ï¼ä¸¦æä¾ä¸åç°¡å®ççµæä¾æ°å¢è³æéã

##### **Digital Avatars: Framework Development and Their Evaluation**
2408.04068v1 by Timothy Rupprecht, Sung-En Chang, Yushu Wu, Lei Lu, Enfu Nan, Chih-hsiang Li, Caiyue Lai, Zhimin Li, Zhijun Hu, Yumei He, David Kaeli, Yanzhi Wang

We present a novel prompting strategy for artificial intelligence driven
digital avatars. To better quantify how our prompting strategy affects
anthropomorphic features like humor, authenticity, and favorability we present
Crowd Vote - an adaptation of Crowd Score that allows for judges to elect a
large language model (LLM) candidate over competitors answering the same or
similar prompts. To visualize the responses of our LLM, and the effectiveness
of our prompting strategy we propose an end-to-end framework for creating
high-fidelity artificial intelligence (AI) driven digital avatars. This
pipeline effectively captures an individual's essence for interaction and our
streaming algorithm delivers a high-quality digital avatar with real-time
audio-video streaming from server to mobile device. Both our visualization
tool, and our Crowd Vote metrics demonstrate our AI driven digital avatars have
state-of-the-art humor, authenticity, and favorability outperforming all
competitors and baselines. In the case of our Donald Trump and Joe Biden
avatars, their authenticity and favorability are rated higher than even their
real-world equivalents.

æè¦ï¼æåæåºäºä¸ç¨®ç¨æ¼äººå·¥æºè½é©åæ¸ä½æ¿èº«çæ°æç¤ºç­ç¥ãçºäºæ´å¥½å°éåæåçæç¤ºç­ç¥å¦ä½å½±é¿å¹½é»ãçå¯¦æ§åå¥½æåº¦ç­æ¬äººåç¹å¾µï¼æåæåºäºç¾¤ç¾æç¥¨ - Crowd Score çä¸ç¨®æ¹ç·¨ï¼å®åè¨±è©å¯©å¨åç­ç¸åæé¡ä¼¼æç¤ºçç«¶ç­èä¸­é¸åºä¸ä½å¤§åèªè¨æ¨¡å (LLM) åé¸äººãçºäºè¦è¦ºåæåç LLM çåæä»¥åæåæç¤ºç­ç¥çæææ§ï¼æåæåºäºä¸åç«¯å°ç«¯çæ¡æ¶ï¼ç¨æ¼åµå»ºé«ä¿çåº¦çäººå·¥æºè½ (AI) é©åçæ¸ä½æ¿èº«ãæ­¤ç®¡ç·ææææåäººçäºåæ¬è³ªï¼æåçä¸²æµæ¼ç®æ³å¾ä¼ºæå¨å°è¡åè£ç½®æä¾é«åè³ªçæ¸ä½æ¿èº«ï¼ä¸¦é²è¡å³æé³è¨ä¸²æµãæåçè¦è¦ºåå·¥å·åç¾¤ç¾æç¥¨ææ¨é½è­æäºæåçäººå·¥æºæ§é©åçæ¸ä½æ¿èº«å·åæåé²çå¹½é»æãçå¯¦æ§åå¥½æåº¦ï¼åªæ¼ææç«¶ç­èååºæºãå°±æåçåç´å¾·Â·å·æ®åå¬Â·æç»æ¿èº«èè¨ï¼ä»åççå¯¦æ§åå¥½æåº¦çè³é«æ¼ä»åå¨ç¾å¯¦ä¸çä¸­çå°æèã

##### **PowerPM: Foundation Model for Power Systems**
2408.04057v1 by Shihao Tu, Yupeng Zhang, Jing Zhang, Yang Yang

The emergence of abundant electricity time series (ETS) data provides ample
opportunities for various applications in the power systems, including
demand-side management, grid stability, and consumer behavior analysis. Deep
learning models have advanced ETS modeling by effectively capturing sequence
dependence. Nevertheless, learning a generic representation of ETS data for
various applications remains challenging due to the inherently complex
hierarchical structure of ETS data. Moreover, ETS data exhibits intricate
temporal dependencies and is suscepti ble to the influence of exogenous
variables. Furthermore, different instances exhibit diverse electricity
consumption behavior. In this paper, we propose a foundation model PowerPM to
model ETS data, providing a large-scale, off-the-shelf model for power systems.
PowerPM consists of a temporal encoder and a hierarchical encoder. The temporal
encoder captures both temporal dependencies in ETS data, considering exogenous
variables. The hierarchical encoder models the correlation between hierarchy.
Furthermore, PowerPM leverages a novel self-supervised pretraining framework
consisting of masked ETS modeling and dual-view contrastive learning, which
enable PowerPM to capture temporal dependency within ETS windows and aware the
discrepancy across ETS windows, providing two different perspectives to learn
generic representation. Our experiments involve five real world scenario
datasets, comprising private and public data. Through pre-training on massive
ETS data, PowerPM achieves SOTA performance on diverse downstream tasks within
the private dataset. Impressively, when transferred to the public datasets,
PowerPM maintains its superiority, showcasing its remarkable generalization
ability across various tasks and domains. Moreover, ablation studies, few-shot
experiments provide additional evidence of the effectiveness of our model.

æè¦ï¼è±å¯é»åæéåºå (ETS) è³æçåºç¾ï¼çºé»åç³»çµ±ä¸­çåç¨®æç¨æä¾äºåè¶³çæ©æï¼åæ¬éæ±å´ç®¡çãé»ç¶²ç©©å®æ§åæ¶è²»èè¡çºåæãæ·±åº¦å­¸ç¿æ¨¡åééæææ·ååºåä¾è³´æ§ï¼æåäº ETS å»ºæ¨¡ãåç®¡å¦æ­¤ï¼ç±æ¼ ETS è³æåºæçè¤ééå±¤çµæ§ï¼å­¸ç¿éç¨ ETS è³æè¡¨ç¤ºä»¥ä¾åç¨®æç¨ä»ç¶å·æææ°æ§ãæ­¤å¤ï¼ETS è³æè¡¨ç¾åºè¤éçæéä¾è³´æ§ï¼ä¸¦ä¸å®¹æåå°å¤çè®æ¸çå½±é¿ãæ­¤å¤ï¼ä¸åçå¯¦ä¾è¡¨ç¾åºä¸åçé»åæ¶èè¡çºãå¨æ¬æä¸­ï¼æåæåºäºä¸ååºç¤æ¨¡å PowerPM ä¾å»ºæ¨¡ ETS è³æï¼çºé»åç³»çµ±æä¾ä¸åå¤§è¦æ¨¡çç¾ææ¨¡åãPowerPM åå«ä¸åæéç·¨ç¢¼å¨åä¸åéå±¤ç·¨ç¢¼å¨ãæéç·¨ç¢¼å¨æ·å ETS è³æä¸­çæéä¾è³´æ§ï¼ä¸¦èæ®å¤çè®æ¸ãéå±¤ç·¨ç¢¼å¨å°éå±¤ä¹éçç¸éæ§é²è¡å»ºæ¨¡ãæ­¤å¤ï¼PowerPM å©ç¨ä¸åæ°ç©çèªç£ç£é è¨ç·´æ¶æ§ï¼å¶ä¸­åå«é®è½ ETS å»ºæ¨¡åéè¦å°æ¯å­¸ç¿ï¼éä½¿ PowerPM è½å¤ æ·å ETS è¦çªä¸­çæéä¾è³´æ§ï¼ä¸¦äºè§£ ETS è¦çªä¹éçå·®ç°ï¼æä¾å©ç¨®ä¸åçè§é»ä¾å­¸ç¿éç¨è¡¨ç¤ºãæåçå¯¦é©æ¶åäºåçå¯¦ä¸çå ´æ¯è³æéï¼åå«ç§äººåå¬å±è³æãééå¨å¤§é ETS è³æä¸é²è¡é è¨ç·´ï¼PowerPM å¨ç§äººè³æéä¸­å¯¦ç¾äº SOTA å¨åç¨®ä¸æ¸¸ä»»åä¸çæè½ãä»¤äººå°è±¡æ·±å»çæ¯ï¼ç¶è½ç§»å°å¬å±è³æéæï¼PowerPM ä¿æå¶åªè¶æ§ï¼å±ç¤ºå¶å¨åç¨®ä»»ååé åä¸­çé¡¯èæ³åè½åãæ­¤å¤ï¼æ¶èç ç©¶ãå°æ¨£æ¬å¯¦é©æä¾äºæåæ¨¡åæææ§çé¡å¤è­æã

##### **Learning Rate-Free Reinforcement Learning: A Case for Model Selection with Non-Stationary Objectives**
2408.04046v1 by Aida Afshar, Aldo Pacchiano

The performance of reinforcement learning (RL) algorithms is sensitive to the
choice of hyperparameters, with the learning rate being particularly
influential. RL algorithms fail to reach convergence or demand an extensive
number of samples when the learning rate is not optimally set. In this work, we
show that model selection can help to improve the failure modes of RL that are
due to suboptimal choices of learning rate. We present a model selection
framework for Learning Rate-Free Reinforcement Learning that employs model
selection methods to select the optimal learning rate on the fly. This approach
of adaptive learning rate tuning neither depends on the underlying RL algorithm
nor the optimizer and solely uses the reward feedback to select the learning
rate; hence, the framework can input any RL algorithm and produce a learning
rate-free version of it. We conduct experiments for policy optimization methods
and evaluate various model selection strategies within our framework. Our
results indicate that data-driven model selection algorithms are better
alternatives to standard bandit algorithms when the optimal choice of
hyperparameter is time-dependent and non-stationary.

æè¦ï¼å¼·åå­¸ç¿ (RL) æ¼ç®æ³çæè½åæ±ºæ¼è¶åæ¸çé¸æï¼å¶ä¸­å­¸ç¿çç¹å¥å·æå½±é¿åãç¶å­¸ç¿çæªæä½³è¨­å®æï¼RL æ¼ç®æ³ç¡æ³éå°æ¶ææéè¦å¤§éçæ¨£æ¬ãå¨éé å·¥ä½ä¸­ï¼æåè­ææ¨¡åé¸ææå©æ¼æ¹å RL çå¤±ææ¨¡å¼ï¼éäºå¤±ææ¨¡å¼æ¯ç±æ¬¡ä½³å­¸ç¿çé¸æé æçãæåæåºä¸åå­¸ç¿çç¡éå¼·åå­¸ç¿çæ¨¡åé¸ææ¶æ§ï¼æ¡ç¨æ¨¡åé¸ææ¹æ³ä¾åæé¸ææä½³å­¸ç¿çãéç¨®èªé©æå­¸ç¿çèª¿æ´æ¹æ³æ¢ä¸ä¾è³´æ¼åºç¤ RL æ¼ç®æ³ï¼ä¹ä¸ä¾è³´æ¼æä½³åå¨ï¼èä¸åä½¿ç¨åé¥çåµä¾é¸æå­¸ç¿çï¼å æ­¤ï¼æ­¤æ¶æ§å¯ä»¥è¼¸å¥ä»»ä½ RL æ¼ç®æ³ä¸¦ç¢çå¶å­¸ç¿çç¡éçæ¬ãæåéå°ç­ç¥æä½³åæ¹æ³é²è¡å¯¦é©ï¼ä¸¦å¨æåçæ¶æ§ä¸­è©ä¼°åç¨®æ¨¡åé¸æç­ç¥ãæåççµæè¡¨æï¼ç¶è¶åæ¸çæä½³é¸æèæéç¸éä¸éå¹³ç©©æï¼è³æé©åçæ¨¡åé¸ææ¼ç®æ³æ¯æ¨æºå¤èèèæ©æ¼ç®æ³çè¼ä½³æ¿ä»£æ¹æ¡ã

##### **Human Speech Perception in Noise: Can Large Language Models Paraphrase to Improve It?**
2408.04029v1 by Anupama Chingacham, Miaoran Zhang, Vera Demberg, Dietrich Klakow

Large Language Models (LLMs) can generate text by transferring style
attributes like formality resulting in formal or informal text. However,
instructing LLMs to generate text that when spoken, is more intelligible in an
acoustically difficult environment, is an under-explored topic. We conduct the
first study to evaluate LLMs on a novel task of generating acoustically
intelligible paraphrases for better human speech perception in noise. Our
experiments in English demonstrated that with standard prompting, LLMs struggle
to control the non-textual attribute, i.e., acoustic intelligibility, while
efficiently capturing the desired textual attributes like semantic equivalence.
To remedy this issue, we propose a simple prompting approach,
prompt-and-select, which generates paraphrases by decoupling the desired
textual and non-textual attributes in the text generation pipeline. Our
approach resulted in a 40% relative improvement in human speech perception, by
paraphrasing utterances that are highly distorted in a listening condition with
babble noise at a signal-to-noise ratio (SNR) -5 dB. This study reveals the
limitation of LLMs in capturing non-textual attributes, and our proposed method
showcases the potential of using LLMs for better human speech perception in
noise.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å¯ä»¥ééè½ç§»å½¢å¼å±¬æ§ï¼ä¾å¦æ­£å¼æ§ï¼ä¾ç¢çæå­ï¼ç¢çæ­£å¼æéæ­£å¼çæå­ãç¶èï¼æç¤º LLM ç¢çå¨å£èªªæå¨è²å­¸å°é£çç°å¢ä¸­æ´ææçæå­ï¼æ¯ä¸åå°æªååæ¢è¨çä¸»é¡ãæåé²è¡äºç¬¬ä¸åç ç©¶ï¼ä»¥è©ä¼° LLM å¨ä¸åæ°çä»»åä¸ï¼å³ç¢çè²å­¸ä¸å¯çè§£çåç¾©è©ï¼ä»¥æ¹åäººé¡å¨åªé³ä¸­çè¨èªæç¥ãæåçè±èªå¯¦é©è­æï¼å¨æ¨æºæç¤ºä¸ï¼LLM é£ä»¥æ§å¶éæå­å±¬æ§ï¼å³è²å­¸å¯çè§£æ§ï¼åæææå°æææéçæå­å±¬æ§ï¼ä¾å¦èªç¾©ç­å¹æ§ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸åç°¡å®çæç¤ºæ¹æ³ï¼æç¤ºåé¸æï¼å®ééå¨æå­ç¢çç®¡éä¸­è§£è¦æéçæå­åéæå­å±¬æ§ä¾ç¢çåç¾©è©ãæåçåæ³å¨äººé¡è¨èªæç¥æ¹é¢ç¢çäº 40% çç¸å°æ¹åï¼ééå¨ä¿¡èéè¨æ¯ (SNR) -5 dB çå§é¬§åªé³ä¸­è½åæ¢ä»¶ä¸ï¼å°å¤±çå´éçèªå¥é²è¡åç¾©è©æ¿æãéé ç ç©¶æ­ç¤ºäº LLM å¨ææéæå­å±¬æ§æ¹é¢çéå¶ï¼èæåæåºçæ¹æ³å±ç¤ºäºä½¿ç¨ LLM å¨åªé³ä¸­æ¹åäººé¡è¨èªæç¥çæ½åã

##### **Multimodal Gender Fairness in Depression Prediction: Insights on Data from the USA & China**
2408.04026v1 by Joseph Cameron, Jiaee Cheong, Micol Spitale, Hatice Gunes

Social agents and robots are increasingly being used in wellbeing settings.
However, a key challenge is that these agents and robots typically rely on
machine learning (ML) algorithms to detect and analyse an individual's mental
wellbeing. The problem of bias and fairness in ML algorithms is becoming an
increasingly greater source of concern. In concurrence, existing literature has
also indicated that mental health conditions can manifest differently across
genders and cultures. We hypothesise that the representation of features
(acoustic, textual, and visual) and their inter-modal relations would vary
among subjects from different cultures and genders, thus impacting the
performance and fairness of various ML models. We present the very first
evaluation of multimodal gender fairness in depression manifestation by
undertaking a study on two different datasets from the USA and China. We
undertake thorough statistical and ML experimentation and repeat the
experiments for several different algorithms to ensure that the results are not
algorithm-dependent. Our findings indicate that though there are differences
between both datasets, it is not conclusive whether this is due to the
difference in depression manifestation as hypothesised or other external
factors such as differences in data collection methodology. Our findings
further motivate a call for a more consistent and culturally aware data
collection process in order to address the problem of ML bias in depression
detection and to promote the development of fairer agents and robots for
wellbeing.

æè¦ï¼ç¤¾ç¾¤ä»£çäººåæ©å¨äººå¨å¹¸ç¦æè¨­å®ä¸­æ­£è¶ä¾è¶å»£æ³å°è¢«ä½¿ç¨ã
ç¶èï¼ä¸åééµçææ°æ¯éäºä»£çäººåæ©å¨äººéå¸¸ä¾è³´æ©å¨å­¸ç¿ (ML) æ¼ç®æ³ä¾åµæ¸¬ååæåäººå¿çå¥åº·ãML æ¼ç®æ³ä¸­çåå·®åå¬å¹³æ§åé¡æ­£æçºè¶ä¾è¶å¤§çéæ³¨ä¾æºãåæï¼ç¾ææç»ä¹æåºå¿çå¥åº·çæ³æå¨ä¸åæ§å¥åæåä¸­ä»¥ä¸åçæ¹å¼é¡¯ç¾ãæååè¨­ç¹å¾µï¼è²é³ãæå­åè¦è¦ºï¼çåç¾åå¶è·¨æ¨¡æéä¿æå ä¸åæååæ§å¥çåè©¦èèç°ï¼å¾èå½±é¿åç¨® ML æ¨¡åçæè½åå¬å¹³æ§ãæåééå°ä¾èªç¾ååä¸­åçå©åä¸åè³æéé²è¡ç ç©¶ï¼æåºé¦æ¬¡å°æé¬±çè¡¨ç¾çå¤æ¨¡ææ§å¥å¬å¹³æ§è©ä¼°ãæåé²è¡å¾¹åºççµ±è¨å ML å¯¦é©ï¼ä¸¦éå°å¤ç¨®ä¸åçæ¼ç®æ³éè¤å¯¦é©ï¼ä»¥ç¢ºä¿çµæä¸ä¾è³´æ¼æ¼ç®æ³ãæåçç ç©¶çµæè¡¨æï¼åç®¡å©åè³æéä¹éå­å¨å·®ç°ï¼ä½ç¡æ³ç¢ºå®éæ¯å¦æ¯ç±æ¼åè¨­çæé¬±çè¡¨ç¾å·®ç°æå¶ä»å¤é¨å ç´ ï¼ä¾å¦è³ææ¶éæ¹æ³çå·®ç°ï¼æé æãæåçç ç©¶çµæé²ä¸æ­¥å¼ç±²æ¡ç¨æ´ä¸è´ä¸å·ææåæè­çè³ææ¶éç¨åºï¼ä»¥è§£æ±ºæé¬±çåµæ¸¬ä¸­ç ML åå·®åé¡ï¼ä¸¦ä¿é²éç¼æ´å¬å¹³çä»£çäººåæ©å¨äººï¼ä»¥æåå¹¸ç¦æã

##### **Improving Large Language Model (LLM) fidelity through context-aware grounding: A systematic approach to reliability and veracity**
2408.04023v1 by Wrick Talukdar, Anjanava Biswas

As Large Language Models (LLMs) become increasingly sophisticated and
ubiquitous in natural language processing (NLP) applications, ensuring their
robustness, trustworthiness, and alignment with human values has become a
critical challenge. This paper presents a novel framework for contextual
grounding in textual models, with a particular emphasis on the Context
Representation stage. Our approach aims to enhance the reliability and ethical
alignment of these models through a comprehensive, context-aware methodology.
By explicitly capturing and representing relevant situational, cultural, and
ethical contexts in a machine-readable format, we lay the foundation for
anchoring a model's behavior within these contexts. Our approach leverages
techniques from knowledge representation and reasoning, such as ontologies,
semantic web technologies, and logic-based formalisms. We evaluate our
framework on real-world textual datasets, demonstrating its effectiveness in
improving model performance, fairness, and alignment with human expectations,
while maintaining high accuracy. Furthermore, we discuss the other key
components of the framework, including context-aware encoding, context-aware
learning, interpretability and explainability, and continuous monitoring and
adaptation. This research contributes to the growing body of work on
responsible AI, offering a practical approach to developing more reliable,
trustworthy, and ethically-aligned language models. Our findings have
significant implications for the deployment of LLMs in sensitive domains such
as healthcare, legal systems, and social services, where contextual
understanding is paramount.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) å¨èªç¶èªè¨èç (NLP) æç¨ä¸­è®å¾è¶ä¾è¶è¤éä¸æ®éï¼ç¢ºä¿å®åçç©©å¥æ§ãå¯ä¿¡åº¦åèäººé¡å¹å¼è§çä¸è´æ§å·²æçºä¸é ééµææ°ãæ¬ææåºäºææ¬æ¨¡åä¸­æå¢åºç¤çæ°æ¡æ¶ï¼ç¹å¥å¼·èª¿æå¢è¡¨å¾µéæ®µãæåçåæ³æ¨å¨ééå¨é¢ä¸éè¦æå¢ççæ¹æ³ä¾å¢å¼·éäºæ¨¡åçå¯é æ§åå«çä¸è´æ§ãééä»¥æ©å¨å¯è®çæ ¼å¼æç¢ºæ·ååè¡¨å¾µç¸éçæå¢ãæååå«çæå¢ï¼æåçºå¨éäºæå¢ä¸­é¨å®æ¨¡åçè¡çºå¥ å®äºåºç¤ãæåçåæ³å©ç¨äºç¥è­è¡¨å¾µåæ¨ççæè¡ï¼ä¾å¦æ¬ä½è«ãèªç¾©ç¶²æè¡ååºæ¼éè¼¯çå½¢å¼åãæåå¨çå¯¦ä¸ççææ¬è³æéä¸è©ä¼°æåçæ¡æ¶ï¼è­æå¶å¨æ¹åæ¨¡åæè½ãå¬å¹³æ§åèäººé¡é æçå»ååº¦æ¹é¢çæææ§ï¼åæä¿æé«æºç¢ºåº¦ãæ­¤å¤ï¼æåè¨è«äºæ¡æ¶çå¶ä»ééµçµæé¨åï¼åæ¬æå¢æç¥ç·¨ç¢¼ãæå¢æç¥å­¸ç¿ãå¯è§£éæ§åå¯èªªææ§ï¼ä»¥åæçºç£æ§åé©æãéé ç ç©¶æå©æ¼è² è²¬ä»»çäººå·¥æºæ§çæ¥çå¢é·çå·¥ä½ï¼æä¾äºä¸ç¨®å¯¦ç¨çæ¹æ³ä¾éç¼æ´å¯é ãå¯ä¿¡è³´ä¸ç¬¦åå«ççèªè¨æ¨¡åãæåçç ç©¶çµæå° LLM å¨é«çä¿å¥ãæ³å¾ç³»çµ±åç¤¾ææåç­ææé åçé¨ç½²å·æéå¤§æç¾©ï¼å¨éäºé åä¸­ï¼æå¢çè§£è³ééè¦ã

##### **Image-to-LaTeX Converter for Mathematical Formulas and Text**
2408.04015v1 by Daniil Gurgurov, Aleksey Morshnev

In this project, we train a vision encoder-decoder model to generate LaTeX
code from images of mathematical formulas and text. Utilizing a diverse
collection of image-to-LaTeX data, we build two models: a base model with a
Swin Transformer encoder and a GPT-2 decoder, trained on machine-generated
images, and a fine-tuned version enhanced with Low-Rank Adaptation (LoRA)
trained on handwritten formulas. We then compare the BLEU performance of our
specialized model on a handwritten test set with other similar models, such as
Pix2Text, TexTeller, and Sumen. Through this project, we contribute open-source
models for converting images to LaTeX and provide from-scratch code for
building these models with distributed training and GPU optimizations.

æè¦ï¼å¨éåå°æ¡ä¸­ï¼æåè¨ç·´ä¸åè¦è¦ºç·¨ç¢¼å¨-è§£ç¢¼å¨æ¨¡åï¼å¾æ¸å­¸å¬å¼åæå­çå½±åç¢ç LaTeX ç¨å¼ç¢¼ãå©ç¨å¤æ¨£åçå½±åå° LaTeX è³æéï¼æåå»ºç«äºå©åæ¨¡åï¼ä¸åä½¿ç¨ Swin Transformer ç·¨ç¢¼å¨å GPT-2 è§£ç¢¼å¨çåºç¤æ¨¡åï¼è¨ç·´æ¼æ©å¨ç¢ççå½±åï¼ä»¥åä¸åä½¿ç¨ä½ç§©é©æ (LoRA) å¾®èª¿ççæ¬ï¼è¨ç·´æ¼æå¯«å¬å¼ãæ¥èï¼æåå°æåå°éæ¨¡åå¨æå¯«æ¸¬è©¦éä¸ç BLEU æè½èå¶ä»é¡ä¼¼æ¨¡åé²è¡æ¯è¼ï¼ä¾å¦ Pix2TextãTexTeller å Sumenãéééåå°æ¡ï¼æåè²¢ç»äºç¨æ¼å°å½±åè½æçº LaTeX çéæºæ¨¡åï¼ä¸¦æä¾å¾é ­éå§å»ºæ§éäºæ¨¡åçåå§ç¢¼ï¼åå«åæ£å¼è¨ç·´å GPU æä½³åã

##### **SLIM-RAFT: A Novel Fine-Tuning Approach to Improve Cross-Linguistic Performance for Mercosur Common Nomenclature**
2408.03936v1 by VinÃ­cius Di Oliveira, Yuri FaÃ§anha Bezerra, Li Weigang, Pedro Carvalho Brom, Victor Rafael R. Celestino

Natural language processing (NLP) has seen significant advancements with the
advent of large language models (LLMs). However, substantial improvements are
still needed for languages other than English, especially for specific domains
like the applications of Mercosur Common Nomenclature (NCM), a Brazilian
Harmonized System (HS). To address this gap, this study uses TeenyTineLLaMA, a
foundational Portuguese LLM, as an LLM source to implement the NCM application
processing. Additionally, a simplified Retrieval-Augmented Fine-Tuning (RAFT)
technique, termed SLIM-RAFT, is proposed for task-specific fine-tuning of LLMs.
This approach retains the chain-of-thought (CoT) methodology for prompt
development in a more concise and streamlined manner, utilizing brief and
focused documents for training. The proposed model demonstrates an efficient
and cost-effective alternative for fine-tuning smaller LLMs, significantly
outperforming TeenyTineLLaMA and ChatGPT-4 in the same task. Although the
research focuses on NCM applications, the methodology can be easily adapted for
HS applications worldwide.

æè¦ï¼èªç¶èªè¨èç (NLP) é¨èå¤§åèªè¨æ¨¡å (LLM) çåºç¾èç²å¾é¡¯èé²å±ãç¶èï¼å°æ¼è±èªä»¥å¤çèªè¨ï¼ç¹å¥æ¯åå·´è¥¿çµ±ä¸å¶åº¦ (HS) çåæ¹å±åå¸å ´å±åæ³è¦ (NCM) æç¨ç­ç¹å®é åï¼ä»éè¦å¤§å¹æ¹é²ãçºäºè§£æ±ºéåå·®è·ï¼æ¬ç ç©¶ä½¿ç¨ TeenyTineLLaMAï¼ä¸ç¨®åºç¤çè¡èçèª LLMï¼ä½çº LLM ä¾æºï¼ä¾å¯¦ä½ NCM æç¨èçãæ­¤å¤ï¼æåºäºä¸ç¨®ç°¡åçæª¢ç´¢å¢å¼·å¾®èª¿ (RAFT) æè¡ï¼ç¨±çº SLIM-RAFTï¼ç¨æ¼ LLM çä»»åç¹å®å¾®èª¿ãéç¨®æ¹æ³ä¿çäºæèé (CoT) æ¹æ³ï¼ç¨æ¼ä»¥æ´ç°¡æ½åæµæ¢çæ¹å¼éç¼æç¤ºï¼ä¸¦å©ç¨ç°¡ç­ä¸éé»æç¢ºçæä»¶é²è¡è¨ç·´ãææåºçæ¨¡åå±ç¤ºäºä¸åææä¸ç¶æ¿çæ¿ä»£æ¹æ¡ï¼ç¨æ¼å¾®èª¿è¼å°ç LLMï¼å¨ç¸åçä»»åä¸­é¡¯èåªæ¼ TeenyTineLLaMA å ChatGPT-4ãåç®¡ç ç©¶éé»å¨æ¼ NCM æç¨ï¼ä½è©²æ¹æ³å¯ä»¥å¾å®¹æå°é©ç¨æ¼å¨çç HS æç¨ã

##### **From Words to Worth: Newborn Article Impact Prediction with LLM**
2408.03934v1 by Penghai Zhao, Qinghua Xing, Kairan Dou, Jinyu Tian, Ying Tai, Jian Yang, Ming-Ming Cheng, Xiang Li

As the academic landscape expands, the challenge of efficiently identifying
potentially high-impact articles among the vast number of newly published works
becomes critical. This paper introduces a promising approach, leveraging the
capabilities of fine-tuned LLMs to predict the future impact of newborn
articles solely based on titles and abstracts. Moving beyond traditional
methods heavily reliant on external information, the proposed method discerns
the shared semantic features of highly impactful papers from a large collection
of title-abstract and potential impact pairs. These semantic features are
further utilized to regress an improved metric, TNCSI_SP, which has been
endowed with value, field, and time normalization properties. Additionally, a
comprehensive dataset has been constructed and released for fine-tuning the
LLM, containing over 12,000 entries with corresponding titles, abstracts, and
TNCSI_SP. The quantitative results, with an NDCG@20 of 0.901, demonstrate that
the proposed approach achieves state-of-the-art performance in predicting the
impact of newborn articles when compared to competitive counterparts. Finally,
we demonstrate a real-world application for predicting the impact of newborn
journal articles to demonstrate its noteworthy practical value. Overall, our
findings challenge existing paradigms and propose a shift towards a more
content-focused prediction of academic impact, offering new insights for
assessing newborn article impact.

æè¦ï¼é¨èå­¸è¡é åçæ´å±ï¼å¨å¤§éæ°åºççä½åä¸­æææ¾åºæ½å¨é«å½±é¿åæç« çææ°è®å¾è³ééè¦ãæ¬æä»ç´¹äºä¸ç¨®æåéçæ¹æ³ï¼å©ç¨å¾®èª¿ LLM çè½åä¾é æ¸¬æ°çæç« çæªä¾å½±é¿ï¼åæ ¹ææ¨é¡åæè¦ãè¶è¶äºå³çµ±æ¹æ³ï¼è©²æ¹æ³ä¾è³´æ¼å¤é¨è³è¨ï¼æåºçæ¹æ³å¾å¤§éçæ¨é¡æè¦åæ½å¨å½±é¿å°ä¸­è¾¨å¥åºé«å½±é¿åè«æçå±ç¨èªç¾©ç¹å¾µãéäºèªç¾©ç¹å¾µé²ä¸æ­¥ç¨æ¼åæ­¸ä¸åæ¹é²çææ¨ TNCSI_SPï¼è©²ææ¨å·²è³¦äºå¼ãæ¬ä½åæéæ­£è¦åå±¬æ§ãæ­¤å¤ï¼éæ§å»ºä¸¦ç¼å¸äºä¸åç¶åè³æéï¼ç¨æ¼å¾®èª¿ LLMï¼å¶ä¸­åå«è¶é 12,000 åæ¢ç®ï¼ä»¥åå°æçæ¨é¡ãæè¦å TNCSI_SPãå®éçµæï¼NDCG@20 çº 0.901ï¼è­æäºèç«¶ç­å°æç¸æ¯ï¼ææåºçæ¹æ³å¨é æ¸¬æ°çæç« çå½±é¿æ¹é¢éå°äºæåé²çæè½ãæå¾ï¼æåå±ç¤ºäºä¸åç¾å¯¦ä¸ççæç¨ï¼ç¨æ¼é æ¸¬æ°çæåæç« çå½±é¿ï¼ä»¥è­æå¶é¡¯èçå¯¦ç¨å¹å¼ãç¸½çä¾èªªï¼æåçç¼ç¾ææ°äºç¾æçç¯ä¾ï¼ä¸¦å»ºè­°è½åæ´æ³¨éå§å®¹çå­¸è¡å½±é¿é æ¸¬ï¼çºè©ä¼°æ°çæç« å½±é¿æä¾äºæ°çè¦è§£ã

##### **CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**
2408.03910v1 by Xiangyan Liu, Bo Lan, Zhiyuan Hu, Yang Liu, Zhicheng Zhang, Wenmeng Zhou, Fei Wang, Michael Shieh

Large Language Models (LLMs) excel in stand-alone code tasks like HumanEval
and MBPP, but struggle with handling entire code repositories. This challenge
has prompted research on enhancing LLM-codebase interaction at a repository
scale. Current solutions rely on similarity-based retrieval or manual tools and
APIs, each with notable drawbacks. Similarity-based retrieval often has low
recall in complex tasks, while manual tools and APIs are typically
task-specific and require expert knowledge, reducing their generalizability
across diverse code tasks and real-world applications. To mitigate these
limitations, we introduce \framework, a system that integrates LLM agents with
graph database interfaces extracted from code repositories. By leveraging the
structural properties of graph databases and the flexibility of the graph query
language, \framework enables the LLM agent to construct and execute queries,
allowing for precise, code structure-aware context retrieval and code
navigation. We assess \framework using three benchmarks: CrossCodeEval,
SWE-bench, and EvoCodeBench. Additionally, we develop five real-world coding
applications. With a unified graph database schema, \framework demonstrates
competitive performance and potential in both academic and real-world
environments, showcasing its versatility and efficacy in software engineering.
Our application demo:
https://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agent.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨ç¨ç«ç¨å¼ç¢¼ä»»åä¸­è¡¨ç¾åºè²ï¼ä¾å¦ HumanEval å MBPPï¼ä½èçæ´åç¨å¼ç¢¼å²å­åº«æå»éå°å°é£ãéåææ°ä¿ä½¿ç ç©¶äººå¡å å¼· LLM èç¨å¼ç¢¼åº«çäºåï¼ä¸¦ä»¥å²å­åº«çºè¦æ¨¡ãç®åçè§£æ±ºæ¹æ¡ä¾è³´æ¼åºæ¼ç¸ä¼¼æ§çæ·åææåå·¥å·å APIï¼æ¯ç¨®æ¹æ³é½æé¡¯èçç¼ºé»ãåºæ¼ç¸ä¼¼æ§çæ·åå¨è¤éä»»åä¸­éå¸¸å¬åçä½ï¼èæåå·¥å·å API éå¸¸æ¯ç¹å®æ¼ä»»åçï¼éè¦å°å®¶ç¥è­ï¼éæéä½å®åå¨ä¸åç¨å¼ç¢¼ä»»ååå¯¦éæç¨ä¸­çæ¦æ¬æ§ãçºäºæ¸è¼éäºéå¶ï¼æåå¼å¥äº \frameworkï¼ä¸åå° LLM ä»£çèå¾ç¨å¼ç¢¼å²å­åº«ä¸­æåçåå½¢è³æåº«ä»é¢æ´åçç³»çµ±ãééå©ç¨åå½¢è³æåº«ççµæ§ç¹æ§ååå½¢æ¥è©¢èªè¨çéæ´»æ§ï¼\framework ä½¿ LLM ä»£çè½å¤ å»ºæ§åå·è¡æ¥è©¢ï¼åè¨±ç²¾ç¢ºãæç¨å¼ç¢¼çµæ§æè­çå§å®¹æ·ååç¨å¼ç¢¼å°è¦½ãæåä½¿ç¨ä¸ååºæºä¾è©ä¼° \frameworkï¼CrossCodeEvalãSWE-bench å EvoCodeBenchãæ­¤å¤ï¼æåéç¼äºäºåå¯¦éçç¨å¼ç¢¼æç¨ç¨å¼ãæäºçµ±ä¸çåå½¢è³æåº«æ¶æ§ï¼\framework å¨å­¸è¡åå¯¦éç°å¢ä¸­é½å±ç¾åºç«¶ç­åçæè½åæ½åï¼å±ç¤ºäºå®å¨è»é«å·¥ç¨ä¸­çå¤åè½æ§åæææ§ãæåçæç¨ç¨å¼ç¤ºç¯ï¼https://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agentã

##### **Decoding Biases: Automated Methods and LLM Judges for Gender Bias Detection in Language Models**
2408.03907v1 by Shachi H Kumar, Saurav Sahay, Sahisnu Mazumder, Eda Okur, Ramesh Manuvinakurike, Nicole Beckage, Hsuan Su, Hung-yi Lee, Lama Nachman

Large Language Models (LLMs) have excelled at language understanding and
generating human-level text. However, even with supervised training and human
alignment, these LLMs are susceptible to adversarial attacks where malicious
users can prompt the model to generate undesirable text. LLMs also inherently
encode potential biases that can cause various harmful effects during
interactions. Bias evaluation metrics lack standards as well as consensus and
existing methods often rely on human-generated templates and annotations which
are expensive and labor intensive. In this work, we train models to
automatically create adversarial prompts to elicit biased responses from target
LLMs. We present LLM- based bias evaluation metrics and also analyze several
existing automatic evaluation methods and metrics. We analyze the various
nuances of model responses, identify the strengths and weaknesses of model
families, and assess where evaluation methods fall short. We compare these
metrics to human evaluation and validate that the LLM-as-a-Judge metric aligns
with human judgement on bias in response generation.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨èªè¨çè§£åç¢çäººé¡å±¤ç´æå­æ¹é¢è¡¨ç¾åºè²ãç¶èï¼å³ä½¿ç¶éç£ç£å¼è¨ç·´åäººé¡æ ¡æºï¼éäº LLM ä»å®¹æåå°å°ææ§æ»æï¼æ¡æä½¿ç¨èå¯ä»¥æç¤ºæ¨¡åç¢çä¸è¯æå­ãLLM æ¬èº«ä¹ç·¨ç¢¼äºæ½å¨åè¦ï¼å¯è½å¨äºåéç¨ä¸­é æåç¨®æå®³å½±é¿ãåè¦è©ä¼°ææ¨ç¼ºä¹æ¨æºåå±è­ï¼ç¾ææ¹æ³éå¸¸ä¾è³´æ¼äººå·¥ç¢ççç¯æ¬åè¨»è§£ï¼éäºç¯æ¬åè¨»è§£æè²´ä¸èè²»äººåãå¨éé å·¥ä½ä¸­ï¼æåè¨ç·´æ¨¡åèªåå»ºç«å°ææ§æç¤ºï¼å¾ç®æ¨ LLM å¼åºæåè¦çåæãæåæåºåºæ¼ LLM çåè¦è©ä¼°ææ¨ï¼ä¸¦åæäºå¹¾ç¨®ç¾æçèªåè©ä¼°æ¹æ³åææ¨ãæååææ¨¡ååæçåç¨®ç´°å¾®å·®å¥ï¼æ¾åºæ¨¡åç³»åçåªç¼ºé»ï¼ä¸¦è©ä¼°è©ä¼°æ¹æ³çä¸è¶³ä¹èãæåå°éäºææ¨èäººé¡è©ä¼°é²è¡æ¯è¼ï¼ä¸¦é©è­ LLM ä½çºè©å¤ææ¨èäººé¡å°åæä¸­åè¦çå¤æ·ä¸è´ã

##### **Speech-MASSIVE: A Multilingual Speech Dataset for SLU and Beyond**
2408.03900v1 by Beomseok Lee, Ioan Calapodescu, Marco Gaido, Matteo Negri, Laurent Besacier

We present Speech-MASSIVE, a multilingual Spoken Language Understanding (SLU)
dataset comprising the speech counterpart for a portion of the MASSIVE textual
corpus. Speech-MASSIVE covers 12 languages from different families and inherits
from MASSIVE the annotations for the intent prediction and slot-filling tasks.
Our extension is prompted by the scarcity of massively multilingual SLU
datasets and the growing need for versatile speech datasets to assess
foundation models (LLMs, speech encoders) across languages and tasks. We
provide a multimodal, multitask, multilingual dataset and report SLU baselines
using both cascaded and end-to-end architectures in various training scenarios
(zero-shot, few-shot, and full fine-tune). Furthermore, we demonstrate the
suitability of Speech-MASSIVE for benchmarking other tasks such as speech
transcription, language identification, and speech translation. The dataset,
models, and code are publicly available at:
https://github.com/hlt-mt/Speech-MASSIVE

æè¦ï¼æåæåº Speech-MASSIVEï¼ä¸åå¤èªè¨çå£èªçè§£ (SLU)
è³æéï¼åå« MASSIVE ææ¬èªæåº«ä¸é¨åçå£èªå°æé¨åãSpeech-MASSIVE æ¶µèäºä¾èªä¸åèªç³»ç 12 ç¨®èªè¨ï¼ä¸¦ç¹¼æ¿äº MASSIVE ä¸­ç¨æ¼æåé æ¸¬åæ§½ä½å¡«è£ä»»åçè¨»è§£ã
æåçæ´å±æ¯ç±å¤§éçå¤èªè¨ SLU è³æéçç¨ç¼ºæ§ä»¥åè©ä¼°è·¨èªè¨åä»»åçåºç¤æ¨¡å (LLMãèªé³ç·¨ç¢¼å¨) å°éç¨èªé³è³æéæ¥çå¢é·çéæ±ææ¨åçãæåæä¾äºä¸åå¤æ¨¡æãå¤ä»»åãå¤èªè¨çè³æéï¼ä¸¦å¨åç¨®è¨ç·´å ´æ¯ï¼é¶æ¬¡å­¸ç¿ãå°æ¬¡å­¸ç¿åå®å¨å¾®èª¿ï¼ä¸­å ±åäºä½¿ç¨ä¸²è¯åç«¯å°ç«¯æ¶æ§ç SLU åºç·ãæ­¤å¤ï¼æåå±ç¤ºäº Speech-MASSIVE é©ç¨æ¼å°å¶ä»ä»»åï¼ä¾å¦èªé³è½éãèªè¨è­å¥åèªé³ç¿»è­¯ï¼é²è¡åºæºæ¸¬è©¦ãè³æéãæ¨¡ååç¨å¼ç¢¼å¯å¨ä»¥ä¸ä½ç½®å¬éç²å¾ï¼
https://github.com/hlt-mt/Speech-MASSIVE

##### **Simplifying Scholarly Abstracts for Accessible Digital Libraries**
2408.03899v1 by Haining Wang, Jason Clark

Standing at the forefront of knowledge dissemination, digital libraries
curate vast collections of scientific literature. However, these scholarly
writings are often laden with jargon and tailored for domain experts rather
than the general public. As librarians, we strive to offer services to a
diverse audience, including those with lower reading levels. To extend our
services beyond mere access, we propose fine-tuning a language model to rewrite
scholarly abstracts into more comprehensible versions, thereby making scholarly
literature more accessible when requested. We began by introducing a corpus
specifically designed for training models to simplify scholarly abstracts. This
corpus consists of over three thousand pairs of abstracts and significance
statements from diverse disciplines. We then fine-tuned four language models
using this corpus. The outputs from the models were subsequently examined both
quantitatively for accessibility and semantic coherence, and qualitatively for
language quality, faithfulness, and completeness. Our findings show that the
resulting models can improve readability by over three grade levels, while
maintaining fidelity to the original content. Although commercial
state-of-the-art models still hold an edge, our models are much more compact,
can be deployed locally in an affordable manner, and alleviate the privacy
concerns associated with using commercial models. We envision this work as a
step toward more inclusive and accessible libraries, improving our services for
young readers and those without a college degree.

æè¦ï¼ä½çºç¥è­å³æ­çæåç·ï¼æ¸ä½åæ¸é¤¨ç®¡çèé¾å¤§ç§å­¸æç»çéåãç¶èï¼éäºå­¸è¡å¯«ä½éå¸¸åæ»¿è¡èªï¼ä¸¦éå°é åå°å®¶éèº«æé ï¼èéä¸è¬å¤§ç¾ãèº«çºåæ¸é¤¨å¡ï¼æåè´åæ¼çºå¤ååç¾æä¾æåï¼åæ¬é±è®è½åè¼ä½èãçºäºå°æåçæåæ´å±å°å®ç´å­åä¹å¤ï¼æåå»ºè­°å¾®èª¿èªè¨æ¨¡åï¼å°å­¸è¡æè¦æ¹å¯«çºæ´ææ¼çè§£ççæ¬ï¼å¾èè®å­¸è¡æç»å¨éè¦ææ´ææ¼å­åãæåé¦åå¼å¥ä¸åå°éè¨­è¨ç¨æ¼è¨ç·´æ¨¡åä»¥ç°¡åå­¸è¡æè¦çèªæåº«ãæ­¤èªæåº«åå«ä¾èªä¸åé åçä¸åå¤å°æè¦åéè¦æ§è²æãç¶å¾ï¼æåä½¿ç¨æ­¤èªæåº«å¾®èª¿äºååèªè¨æ¨¡åãæ¥èï¼å¾æ¨¡åè¼¸åºççµæä¸­ï¼æåå®éæª¢æ¥äºå¯å­åæ§åèªç¾©ç¸å¹²æ§ï¼ä¸¦å®æ§æª¢æ¥äºèªè¨åè³ªãå¿ å¯¦åº¦åå®æ´æ§ãæåçç ç©¶çµæé¡¯ç¤ºï¼éäºæ¨¡åå¯ä»¥å°å¯è®æ§æåè¶éä¸åå¹´ç´ç¨åº¦ï¼åæç¶­æå°åå§å§å®¹çå¿ å¯¦åº¦ãåç®¡åæ¥­æåé²çæ¨¡åä»ä½æä¸å¸­ä¹å°ï¼ä½æåçæ¨¡åæ´çºç²¾ç°¡ï¼å¯ä»¥ç¶æ¿å¯¦æ çæ¹å¼å¨æ¬å°é¨ç½²ï¼ä¸¦æ¸è¼èä½¿ç¨åæ¥­æ¨¡åç¸éçé±ç§åé¡ãæåå°éé å·¥ä½è¦çºéåæ´å·åå®¹æ§åå¯å­åæ§çåæ¸é¤¨çä¸æ­¥ï¼æ¹åæåå°å¹´è¼è®èåæ²æå¤§å­¸å­¸ä½çè®èçæåã

##### **MORTAR: A Model-based Runtime Action Repair Framework for AI-enabled Cyber-Physical Systems**
2408.03892v1 by Renzhi Wang, Zhehua Zhou, Jiayang Song, Xuan Xie, Xiaofei Xie, Lei Ma

Cyber-Physical Systems (CPSs) are increasingly prevalent across various
industrial and daily-life domains, with applications ranging from robotic
operations to autonomous driving. With recent advancements in artificial
intelligence (AI), learning-based components, especially AI controllers, have
become essential in enhancing the functionality and efficiency of CPSs.
However, the lack of interpretability in these AI controllers presents
challenges to the safety and quality assurance of AI-enabled CPSs (AI-CPSs).
Existing methods for improving the safety of AI controllers often involve
neural network repair, which requires retraining with additional adversarial
examples or access to detailed internal information of the neural network.
Hence, these approaches have limited applicability for black-box policies,
where only the inputs and outputs are accessible during operation. To overcome
this, we propose MORTAR, a runtime action repair framework designed for AI-CPSs
in this work. MORTAR begins by constructing a prediction model that forecasts
the quality of actions proposed by the AI controller. If an unsafe action is
detected, MORTAR then initiates a repair process to correct it. The generation
of repaired actions is achieved through an optimization process guided by the
safety estimates from the prediction model. We evaluate the effectiveness of
MORTAR across various CPS tasks and AI controllers. The results demonstrate
that MORTAR can efficiently improve task completion rates of AI controllers
under specified safety specifications. Meanwhile, it also maintains minimal
computational overhead, ensuring real-time operation of the AI-CPSs.

æè¦ï¼ç¶²è·¯ç©çç³»çµ± (CPS) å¨åç¨®ç¢æ¥­åæ¥å¸¸çæ´»é åä¸­è¶ä¾è¶æ®éï¼æç¨ç¯åå¾æ©å¨äººä½æ¥­å°èªåé§é§ãé¨èäººå·¥æºæ§ (AI) çææ°é²å±ï¼åºæ¼å­¸ç¿çåä»¶ï¼å°¤å¶æ¯ AI æ§å¶å¨ï¼å·²æçºå¢å¼· CPS åè½åæççå¿è¦æ¢ä»¶ã
ç¶èï¼éäº AI æ§å¶å¨ç¼ºä¹å¯è§£éæ§ï¼å° AI é©åç CPS (AI-CPS) çå®å¨æ§èåè³ªä¿è­æåºäºææ°ãç¾æçæ¹å AI æ§å¶å¨å®å¨æ§çæ¹æ³éå¸¸æ¶åç¥ç¶ç¶²è·¯ä¿®å¾©ï¼ééè¦ä½¿ç¨é¡å¤çå°ææ§ç¯ä¾éæ°è¨ç·´æåå¾ç¥ç¶ç¶²è·¯çè©³ç´°å§é¨è³è¨ã
å æ­¤ï¼éäºæ¹æ³å°æ¼é»çæ¿ç­çé©ç¨æ§æéï¼å çºå¨æä½æéåªè½å­åè¼¸å¥åè¼¸åºãçºäºåæéååé¡ï¼æåå¨éé å·¥ä½ä¸­æåºäº MORTARï¼ä¸åå°çº AI-CPS è¨­è¨çå·è¡æéåä½ä¿®å¾©æ¶æ§ãMORTAR é¦åå»ºç«ä¸åé æ¸¬æ¨¡åï¼ç¨æ¼é æ¸¬ AI æ§å¶å¨å»ºè­°çåä½åè³ªãå¦æåµæ¸¬å°ä¸å®å¨çåä½ï¼MORTAR æ¥èæååä¸åä¿®å¾©ç¨åºä¾ä¿®æ­£å®ãä¿®å¾©åä½çç¢çæ¯ééä¸åæä½³åç¨åºéæï¼éåç¨åºç±é æ¸¬æ¨¡åçå®å¨ä¼°è¨å¼å¼å°ãæåè©ä¼°äº MORTAR å¨åç¨® CPS ä»»åå AI æ§å¶å¨ä¸­çæææ§ãçµæè­æ MORTAR è½å¨æå®çå®å¨æ§è¦ç¯ä¸ææçå°æ¹å AI æ§å¶å¨çä»»åå®æçãåæï¼å®ä¹ç¶­ææå°çéç®è² æï¼ç¢ºä¿ AI-CPS çå³ææä½ã

##### **Personalized Clinical Note Generation from Doctor-Patient Conversations**
2408.03874v1 by Nathan Brake, Thomas Schaaf

In this work, we present a novel technique to improve the quality of draft
clinical notes for physicians. This technique is concentrated on the ability to
model implicit physician conversation styles and note preferences. We also
introduce a novel technique for the enrollment of new physicians when a limited
number of clinical notes paired with conversations are available for that
physician, without the need to re-train a model to support them. We show that
our technique outperforms the baseline model by improving the ROUGE-2 score of
the History of Present Illness section by 13.8%, the Physical Examination
section by 88.6%, and the Assessment & Plan section by 50.8%.

æè¦ï¼å¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°çæè¡ä¾æ¹åé«å¸«çè¨åºèç¨¿ç­è¨åè³ªãæ­¤æè¡éä¸­å¨æ¨¡æ¬é±å«çé«å¸«å°è©±é¢¨æ ¼åç­è¨åå¥½çè½åãæåéå¼å¥äºä¸ç¨®æ°çæè¡ï¼ç¨æ¼å¨åªæå°æ¸éå°å°è©±çè¨åºç­è¨å¯ç¨æ¼è©²é«å¸«æè¨»åæ°é«å¸«ï¼èç¡ééæ°è¨ç·´æ¨¡åä¾æ¯æ´ä»åãæåå±ç¤ºäºæåçæè¡ééå°ç¾çå²é¨åç ROUGE-2 åæ¸æé« 13.8%ãèº«é«æª¢æ¥é¨åæé« 88.6%ãè©ä¼°åè¨ç«é¨åæé« 50.8%ï¼è¡¨ç¾åªæ¼åºæºæ¨¡åã

##### **Inter-Series Transformer: Attending to Products in Time Series Forecasting**
2408.03872v1 by Rares Cristian, Pavithra Harsha, Clemente Ocejo, Georgia Perakis, Brian Quanz, Ioannis Spantidakis, Hamza Zerhouni

Time series forecasting is an important task in many fields ranging from
supply chain management to weather forecasting. Recently, Transformer neural
network architectures have shown promising results in forecasting on common
time series benchmark datasets. However, application to supply chain demand
forecasting, which can have challenging characteristics such as sparsity and
cross-series effects, has been limited.
  In this work, we explore the application of Transformer-based models to
supply chain demand forecasting. In particular, we develop a new
Transformer-based forecasting approach using a shared, multi-task per-time
series network with an initial component applying attention across time series,
to capture interactions and help address sparsity. We provide a case study
applying our approach to successfully improve demand prediction for a medical
device manufacturing company. To further validate our approach, we also apply
it to public demand forecasting datasets as well and demonstrate competitive to
superior performance compared to a variety of baseline and state-of-the-art
forecast methods across the private and public datasets.

æè¦ï¼æéåºåé æ¸¬å¨è¨±å¤é åä¸­é½æ¯ä¸é éè¦çä»»åï¼å¾ä¾æéç®¡çå°å¤©æ°£é æ¸¬é½ææ¶åãæè¿ï¼Transformer ç¥ç¶ç¶²è·¯æ¶æ§å¨å¸¸è¦æéåºååºæºè³æéçé æ¸¬ä¸­å±ç¾äºä»¤äººæ»¿æçææãç¶èï¼æç¨æ¼ä¾æééæ±é æ¸¬çç¯çåå°éå¶ï¼å çºä¾æééæ±é æ¸¬å¯è½å·æç¨çæ§åè·¨ç³»åææç­å·ææ°æ§çç¹å¾µã
  å¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äºå°åºæ¼ Transformer çæ¨¡åæç¨æ¼ä¾æééæ±é æ¸¬ãç¹å¥æ¯ï¼æåéç¼äºä¸ç¨®æ°çåºæ¼ Transformer çé æ¸¬æ¹æ³ï¼ä½¿ç¨ä¸åå±ç¨çãæ¯åæéåºåçå¤ä»»åç¶²è·¯ï¼ä¸¦å¨åå§åä»¶ä¸­å¥ç¨è·¨æéåºåçæ³¨æåï¼ä»¥æ·åäºåä¸¦åå©è§£æ±ºç¨çæ§åé¡ãæåæä¾äºä¸åæ¡ä¾ç ç©¶ï¼æç¨æåçåæ³æåæ¹åäºä¸å®¶é«çå¨æè£½é å¬å¸çéæ±é æ¸¬ãçºäºé²ä¸æ­¥é©è­æåçåæ³ï¼æåä¹å°å¶æç¨æ¼å¬éçéæ±é æ¸¬è³æéï¼ä¸¦è­æèåç¨®åºç·åæåé²çé æ¸¬æ¹æ³ç¸æ¯ï¼å¨ç§æåå¬éè³æéä¸­çè¡¨ç¾å·æç«¶ç­åæåªæ¼éäºæ¹æ³ã

##### **BeeManc at the PLABA Track of TAC-2023: Investigating LLMs and Controllable Attributes for Improving Biomedical Text Readability**
2408.03871v1 by Zihao Li, Samuel Belkadi, Nicolo Micheletti, Lifeng Han, Matthew Shardlow, Goran Nenadic

In this system report, we describe the models and methods we used for our
participation in the PLABA2023 task on biomedical abstract simplification, part
of the TAC 2023 tracks. The system outputs we submitted come from the following
three categories: 1) domain fine-tuned T5-like models including Biomedical-T5
and Lay-SciFive; 2) fine-tuned BARTLarge model with controllable attributes
(via tokens) BART-w-CTs; 3) ChatGPTprompting. We also present the work we
carried out for this task on BioGPT finetuning. In the official automatic
evaluation using SARI scores, BeeManc ranks 2nd among all teams and our model
LaySciFive ranks 3rd among all 13 evaluated systems. In the official human
evaluation, our model BART-w-CTs ranks 2nd on Sentence-Simplicity (score
92.84), 3rd on Term-Simplicity (score 82.33) among all 7 evaluated systems; It
also produced a high score 91.57 on Fluency in comparison to the highest score
93.53. In the second round of submissions, our team using ChatGPT-prompting
ranks the 2nd in several categories including simplified term accuracy score
92.26 and completeness score 96.58, and a very similar score on faithfulness
score 95.3 to re-evaluated PLABA-base-1 (95.73) via human evaluations. Our
codes, fine-tuned models, prompts, and data splits from the system development
stage will be available at https://github.com/ HECTA-UoM/PLABA-MU

æè¦ï¼<paragraph>å¨éåç³»çµ±å ±åä¸­ï¼æåæè¿°äºæåå¨ TAC 2023 è»éçä¸é¨åï¼PLABA2023 çç©é«å­¸æè¦ç°¡åä»»åä¸­æä½¿ç¨çæ¨¡ååæ¹æ³ãæåæäº¤çç³»çµ±è¼¸åºä¾èªä»¥ä¸ä¸ç¨®é¡å¥ï¼1) é åå¾®èª¿ç T5 é¡ä¼¼æ¨¡åï¼åæ¬ Biomedical-T5 å Lay-SciFiveï¼2) å¾®èª¿ BARTLarge æ¨¡åï¼å·æå¯æ§å±¬æ§ï¼ééä»£å¹£ï¼BART-w-CTsï¼3) ChatGPT æç¤ºãæåéå±ç¤ºäºæåå¨ BioGPT å¾®èª¿ä¸­çºéé ä»»åæåçå·¥ä½ãå¨ä½¿ç¨ SARI åæ¸çå®æ¹èªåè©ä¼°ä¸­ï¼BeeManc å¨ææåéä¸­æåç¬¬ 2ï¼æåçæ¨¡å LaySciFive å¨ææ 13 åè©ä¼°ç³»çµ±ä¸­æåç¬¬ 3ãå¨å®æ¹äººå·¥è©ä¼°ä¸­ï¼æåçæ¨¡å BART-w-CTs å¨å¥å­ç°¡æ½æ§ï¼åæ¸ 92.84ï¼ä¸­æåç¬¬ 2ï¼å¨è¡èªç°¡æ½æ§ï¼åæ¸ 82.33ï¼ä¸­æåç¬¬ 3ï¼å¨ææ 7 åè©ä¼°ç³»çµ±ä¸­æåç¬¬ 3ï¼å®éç¢çäº 91.57 çé«æµæ¢åº¦åæ¸ï¼èæé«åçº 93.53ãå¨ç¬¬äºè¼ªæäº¤ä¸­ï¼æåä½¿ç¨ ChatGPT æç¤ºçåéå¨å¹¾åé¡å¥ä¸­æåç¬¬ 2ï¼åæ¬ç°¡åè¡èªæºç¢ºåº¦åæ¸ 92.26 åå®æ´æ§åæ¸ 96.58ï¼ä»¥åå° PLABA-base-1ï¼95.73ï¼éæ°è©ä¼°çå¿ å¯¦åº¦åæ¸ 95.3 éå¸¸ç¸ä¼¼ééäººå·¥è©ä¼°ãæåçä»£ç¢¼ãå¾®èª¿æ¨¡åãæç¤ºåç³»çµ±éç¼éæ®µçæ¸æåå²å°å¨ https://github.com/ HECTA-UoM/PLABA-MU ä¸­æä¾</paragraph>

##### **Why transformers are obviously good models of language**
2408.03855v1 by Felix Hill

Nobody knows how language works, but many theories abound. Transformers are a
class of neural networks that process language automatically with more success
than alternatives, both those based on neural computations and those that rely
on other (e.g. more symbolic) mechanisms. Here, I highlight direct connections
between the transformer architecture and certain theoretical perspectives on
language. The empirical success of transformers relative to alternative models
provides circumstantial evidence that the linguistic approaches that
transformers embody should be, at least, evaluated with greater scrutiny by the
linguistics community and, at best, considered to be the currently best
available theories.

æè¦ï¼æ²æäººç¥éèªè¨æ¯å¦ä½éä½çï¼ä½æè¨±å¤çè«æµå³ãTransformeræ¯ä¸ç¨®ç¥ç¶ç¶²è·¯ï¼å¯ä»¥èªåèçèªè¨ï¼æ¯å¶ä»åºæ¼ç¥ç¶éç®åä¾è³´å¶ä»ï¼ä¾å¦æ´å·è±¡å¾µæ§çï¼æ©å¶çæ¿ä»£æ¹æ¡æ´æåãå¨æ­¤ï¼æéé»èªªæTransformeræ¶æ§èèªè¨çæäºçè«è§é»ä¹éçç´æ¥éè¯ãTransformerç¸å°æ¼æ¿ä»£æ¨¡åçç¶é©æåæä¾äºç°å¢è­æï¼è­æTransformeræé«ç¾çèªè¨æ¹æ³æè³å°åå°èªè¨å­¸ççæ´å´æ ¼è©ä¼°ï¼ä¸¦å¨æå¥½çææ³ä¸è¢«èªçºæ¯ç¶åå¯ç¨çæä½³çè«ã

##### **Hate Speech Detection and Classification in Amharic Text with Deep Learning**
2408.03849v1 by Samuel Minale Gashe, Seid Muhie Yimam, Yaregal Assabie

Hate speech is a growing problem on social media. It can seriously impact
society, especially in countries like Ethiopia, where it can trigger conflicts
among diverse ethnic and religious groups. While hate speech detection in
resource rich languages are progressing, for low resource languages such as
Amharic are lacking. To address this gap, we develop Amharic hate speech data
and SBi-LSTM deep learning model that can detect and classify text into four
categories of hate speech: racial, religious, gender, and non-hate speech. We
have annotated 5k Amharic social media post and comment data into four
categories. The data is annotated using a custom annotation tool by a total of
100 native Amharic speakers. The model achieves a 94.8 F1-score performance.
Future improvements will include expanding the dataset and develop state-of-the
art models.
  Keywords: Amharic hate speech detection, classification, Amharic dataset,
Deep Learning, SBi-LSTM

æè¦ï¼ä»æ¨è¨è«æ¯ç¤¾ç¾¤åªé«ä¸æ¥çå´éçåé¡ãå®æå´éå½±é¿ç¤¾æï¼ç¹å¥æ¯å¨åè¡£ç´¢æ¯äºéæ¨£çåå®¶ï¼å®æå¼ç¼ä¸åç¨®æåå®æåé«ä¹éçè¡çªãéç¶è³æºè±å¯çèªè¨ä»æ¨è¨è«åµæ¸¬æ­£å¨é²å±ä¸­ï¼ä½åé¿å§åæèªéæ¨£çä½è³æºèªè¨å»ç¼ºä¹ãçºäºè§£æ±ºéåå·®è·ï¼æåéç¼äºé¿å§åæèªä»æ¨è¨è«è³æå SBi-LSTM æ·±åº¦å­¸ç¿æ¨¡åï¼å¯ä»¥åµæ¸¬ä¸¦å°æå­åé¡çºåç¨®é¡å¥çä»æ¨è¨è«ï¼ç¨®æãå®æãæ§å¥åéä»æ¨è¨è«ãæåå·²å° 5 ååé¿å§åæèªç¤¾ç¾¤åªé«è²¼æåçè¨è³æè¨»è§£çºåç¨®é¡å¥ãè³ææ¯ç±ç¸½å± 100 ä½æ¯èªçºé¿å§åæèªçè¬èä½¿ç¨èªè¨è¨»è§£å·¥å·é²è¡è¨»è§£ãè©²æ¨¡åéå°äº 94.8 ç F1 åæ¸è¡¨ç¾ãæªä¾çæ¹é²å°åæ¬æ´åè³æéåéç¼æåé²çæ¨¡åã
ééµå­ï¼é¿å§åæèªä»æ¨è¨è«åµæ¸¬ãåé¡ãé¿å§åæèªè³æéãæ·±åº¦å­¸ç¿ãSBi-LSTM

##### **MaxMind: A Memory Loop Network to Enhance Software Productivity based on Large Language Models**
2408.03841v1 by Yuchen Dong, XiaoXiang Fang, Yuchen Hu, Renshuang Jiang, Zhe Jiang

The application of large language models to facilitate automated software
operations and tool generation (SOTG), thus augmenting software productivity,
mirrors the early stages of human evolution when the ability to create and use
tools accelerated the progress of civilization. These complex tasks require AI
to continuously summarize and improve. Current research often overlooks the
importance of converting real-time task experiences into system memory and
differentiating the value of existing knowledge for future reference. This
paper addresses these issues by evolving external memory models into
Memory-Loop Networks for timely memorization and experience referencing. We
also enhance a RAG mechanism with knowledge precision segmentation to utilize
memory based on value differentiation, and design the MaxMind model for SOTG
accordingly.To demonstrate our approach, we developed MaxMind4Sheet, an
electronic spreadsheet processing system aligned with the MaxMind philosophy.
Comparative experiments with SheetCopilot have demonstrated that the
accumulation and recycling of task memories lead to a steady enhancement in
task success rate, with an improvement rate of approximately 3%-6% per round in
this implementation example. Note that as the memories continue to grow, this
cumulative improvement may be substantial. The inclusion of memory recycling
can also boost the system's task execution efficiency by up to 25%, and it can
address the retraining issue faced by LLMs when handling specialized tasks
through memories transfer.These suggest that MaxMind has significant potential
to enhance the capabilities and productivity of LLM systems in SOTG.

æè¦ï¼å¤§åèªè¨æ¨¡åçæç¨æå©æ¼ä¿é²èªååè»é«æä½åå·¥å·çæ (SOTG)ï¼é²èæåè»é«çç¢åï¼éåæ äºäººé¡æ¼åçæ©æéæ®µï¼ç¶æåµé åä½¿ç¨å·¥å·çè½åå éäºææçé²æ­¥ãéäºè¤éçä»»åéè¦ AI æçºç¸½çµåæ¹é²ãç®åçè¨±å¤ç ç©¶å¸¸å¸¸å¿½ç¥å°å³æä»»åç¶é©è½æçºç³»çµ±è¨æ¶ï¼ä»¥åååç¾æç¥è­å°æªä¾åèå¹å¼çéè¦æ§ãæ¬æééå°å¤é¨è¨æ¶æ¨¡åæ¼è®æè¨æ¶è¿´åç¶²è·¯ï¼ä»¥å¯¦ç¾åæè¨æ¶åç¶é©åèï¼ä¾è§£æ±ºéäºåé¡ãæåä¹ééç¥è­ç²¾æºåæ®µä¾å¼·å RAG æ©å¶ï¼ä»¥æ ¹æå¹å¼ååä¾å©ç¨è¨æ¶ï¼ä¸¦ææ­¤è¨­è¨ç¨æ¼ SOTG ç MaxMind æ¨¡åãçºäºå±ç¤ºæåçåæ³ï¼æåéç¼äº MaxMind4Sheetï¼éæ¯ä¸åè MaxMind çå¿µä¸è´çé»å­è©¦ç®è¡¨èçç³»çµ±ãè SheetCopilot é²è¡çæ¯è¼å¯¦é©å·²è­æï¼ä»»åè¨æ¶çç´¯ç©ååå©ç¨ææçºæåä»»åæåçï¼å¨æ­¤å¯¦ä½ç¯ä¾ä¸­ï¼æ¯ååçæåçç´çº 3%-6%ãè«æ³¨æï¼é¨èè¨æ¶çæçºå¢å ï¼éç¨®ç´¯ç©æåå¯è½æå¾å¯è§ãç´å¥è¨æ¶åå©ç¨ä¹è½æåç³»çµ±çä»»åå·è¡æçï¼æé«å¯é 25%ï¼èä¸å®è½ééè¨æ¶è½ç§»ä¾è§£æ±º LLM å¨èçå°æ¥­ä»»åææé¢è¨çéæ°è¨ç·´åé¡ãéäºé½é¡¯ç¤ºåº MaxMind å¨æå LLM ç³»çµ±å¨ SOTG ä¸­çè½ååçç¢åæ¹é¢å·æé¡¯èçæ½åã

##### **WalledEval: A Comprehensive Safety Evaluation Toolkit for Large Language Models**
2408.03837v1 by Prannaya Gupta, Le Qi Yau, Hao Han Low, I-Shiang Lee, Hugo Maximus Lim, Yu Xin Teoh, Jia Hng Koh, Dar Win Liew, Rishabh Bhardwaj, Rajat Bhardwaj, Soujanya Poria

WalledEval is a comprehensive AI safety testing toolkit designed to evaluate
large language models (LLMs). It accommodates a diverse range of models,
including both open-weight and API-based ones, and features over 35 safety
benchmarks covering areas such as multilingual safety, exaggerated safety, and
prompt injections. The framework supports both LLM and judge benchmarking, and
incorporates custom mutators to test safety against various text-style
mutations such as future tense and paraphrasing. Additionally, WalledEval
introduces WalledGuard, a new, small and performant content moderation tool,
and SGXSTest, a benchmark for assessing exaggerated safety in cultural
contexts. We make WalledEval publicly available at
https://github.com/walledai/walledevalA.

æè¦ï¼WalledEval æ¯ä¸åå¨é¢ç AI å®å¨æ¸¬è©¦å·¥å·åï¼æ¨å¨è©ä¼°å¤§åèªè¨æ¨¡å (LLM)ãå®å®¹ç´äºåç¨®æ¨¡åï¼åæ¬éæ¾æ¬éååºæ¼ API çæ¨¡åï¼ä¸¦å·æè¶é 35 åå®å¨åºæºï¼æ¶µèå¤èªè¨å®å¨ãèªå¼µå®å¨åæç¤ºæ³¨å¥ç­é åãè©²æ¡æ¶æ¯æ´ LLM åè©å¯©åºæºæ¸¬è©¦ï¼ä¸¦æ´åèªè¨è®ç°å¨ï¼ä»¥éå°åç¨®æå­æ¨£å¼è®ç°ï¼ä¾å¦æªä¾å¼ååç¾©æ¹å¯«ï¼æ¸¬è©¦å®å¨æ§ãæ­¤å¤ï¼WalledEval å¼å¥äº WalledGuardï¼éæ¯ä¸åæ°çãå°å·§ä¸é«æçå§å®¹å¯©æ ¸å·¥å·ï¼ä»¥å SGXSTestï¼ä¸åç¨æ¼è©ä¼°æåèæ¯ä¸­èªå¤§å®å¨æ§çåºæºãæåå¨ https://github.com/walledai/walledevalA ä¸å¬é WalledEvalã

##### **Target Prompting for Information Extraction with Vision Language Model**
2408.03834v1 by Dipankar Medhi

The recent trend in the Large Vision and Language model has brought a new
change in how information extraction systems are built. VLMs have set a new
benchmark with their State-of-the-art techniques in understanding documents and
building question-answering systems across various industries. They are
significantly better at generating text from document images and providing
accurate answers to questions. However, there are still some challenges in
effectively utilizing these models to build a precise conversational system.
General prompting techniques used with large language models are often not
suitable for these specially designed vision language models. The output
generated by such generic input prompts is ordinary and may contain information
gaps when compared with the actual content of the document. To obtain more
accurate and specific answers, a well-targeted prompt is required by the vision
language model, along with the document image. In this paper, a technique is
discussed called Target prompting, which focuses on explicitly targeting parts
of document images and generating related answers from those specific regions
only. The paper also covers the evaluation of response for each prompting
technique using different user queries and input prompts.

æè¦ï¼è¿æå¤§åè¦è¦ºèèªè¨æ¨¡åçè¶¨å¢çºè³è¨èåç³»çµ±çå»ºç½®æ¹å¼å¸¶ä¾äºæ°çè®åãVLMs ä»¥å¶å¨çè§£æä»¶åå»ºç«è·¨ç¢æ¥­åç­ç³»çµ±çææ°æè¡æ¨¹ç«äºæ°çåºæºãå®åå¨å¾æä»¶å½±åç¢çæå­åæä¾æºç¢ºçç­æ¡æ¹é¢é¡¯èå°æ´åºè²ãç¶èï¼å¨ææå©ç¨éäºæ¨¡åä¾å»ºç«ç²¾ç¢ºçå°è©±ç³»çµ±æ¹é¢ä»æä¸äºææ°ãèå¤§åèªè¨æ¨¡åä¸èµ·ä½¿ç¨çä¸è¬æç¤ºæè¡éå¸¸ä¸é©åéäºç¹å¥è¨­è¨çè¦è¦ºèªè¨æ¨¡åãæ­¤é¡ä¸è¬è¼¸å¥æç¤ºç¢ççè¼¸åºå¾æ®éï¼èæä»¶çå¯¦éå§å®¹ç¸æ¯æå¯è½æåå«è³è¨å·®è·ãçºäºç²å¾æ´æºç¢ºä¸å·é«çç­æ¡ï¼è¦è¦ºèªè¨æ¨¡åéè¦ä¸åæç¢ºçç®æ¨æç¤ºï¼ä»¥åæä»¶å½±åãå¨æ¬æä¸­ï¼è¨è«äºä¸ç¨®ç¨±çºç®æ¨æç¤ºçæè¡ï¼å¶å°æ³¨æ¼æç¢ºéå®æä»¶å½±åçé¨åï¼ä¸¦åå¾é£äºç¹å®ååç¢çç¸éç­æ¡ãæ¬æéæ¶µèäºä½¿ç¨ä¸åçä½¿ç¨èæ¥è©¢åè¼¸å¥æç¤ºå°æ¯ç¨®æç¤ºæè¡çåæè©ä¼°ã

##### **Automated Code Fix Suggestions for Accessibility Issues in Mobile Apps**
2408.03827v1 by Forough Mehralian, Titus Barik, Jeff Nichols, Amanda Swearngin

Accessibility is crucial for inclusive app usability, yet developers often
struggle to identify and fix app accessibility issues due to a lack of
awareness, expertise, and inadequate tools. Current accessibility testing tools
can identify accessibility issues but may not always provide guidance on how to
address them. We introduce FixAlly, an automated tool designed to suggest
source code fixes for accessibility issues detected by automated accessibility
scanners. FixAlly employs a multi-agent LLM architecture to generate fix
strategies, localize issues within the source code, and propose code
modification suggestions to fix the accessibility issue. Our empirical study
demonstrates FixAlly's capability in suggesting fixes that resolve issues found
by accessibility scanners -- with an effectiveness of 77% in generating
plausible fix suggestions -- and our survey of 12 iOS developers finds they
would be willing to accept 69.4% of evaluated fix suggestions.

æè¦ï¼ç¡éç¤åè½å°æ¼åå®¹æ§æç¨ç¨å¼å¯ç¨æ§è³ééè¦ï¼ä½éç¼äººå¡ç¶å¸¸å ç¼ºä¹æè­ãå°æ¥­ç¥è­åå·¥å·ä¸è¶³èé£ä»¥è­å¥åä¿®å¾©æç¨ç¨å¼ç¡éç¤æ§åé¡ãç®åçç¡éç¤æ§æ¸¬è©¦å·¥å·å¯ä»¥è­å¥ç¡éç¤æ§åé¡ï¼ä½å¯è½ç¡æ³å§çµæä¾å¦ä½è§£æ±ºéäºåé¡çæå°ãæåä»ç´¹ FixAllyï¼éæ¯ä¸åèªååå·¥å·ï¼æ¨å¨çºèªååç¡éç¤æ§ææå¨æª¢æ¸¬å°çç¡éç¤æ§åé¡å»ºè­°åå§ç¢¼ä¿®å¾©ç¨å¼ãFixAlly æ¡ç¨å¤ä»£ç LLM æ¶æ§ä¾ç¢çä¿®å¾©ç­ç¥ï¼å¨åå§ç¢¼ä¸­æ¾åºåé¡ï¼ä¸¦æåºä¿®å¾©ç¡éç¤æ§åé¡çç¨å¼ç¢¼ä¿®æ¹å»ºè­°ãæåçå¯¦è­ç ç©¶è­æäº FixAlly å¨å»ºè­°ä¿®å¾©ç¨å¼ä»¥è§£æ±ºç¡éç¤æ§ææå¨ç¼ç¾çåé¡æ¹é¢çè½åââå¨ç¢ççä¼¼åççä¿®å¾©å»ºè­°æ¹é¢ææççº 77%ââèä¸æåå° 12 ä½ iOS éç¼äººå¡çèª¿æ¥ç¼ç¾ï¼ä»åé¡ææ¥å 69.4% çè©ä¼°ä¿®å¾©å»ºè­°ã

