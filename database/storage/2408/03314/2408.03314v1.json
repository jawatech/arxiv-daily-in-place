{"2408.03314": {"publish_time": "2024-08-06", "title": "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters", "paper_summary": "Enabling LLMs to improve their outputs by using more test-time computation is\na critical step towards building generally self-improving agents that can\noperate on open-ended natural language. In this paper, we study the scaling of\ninference-time computation in LLMs, with a focus on answering the question: if\nan LLM is allowed to use a fixed but non-trivial amount of inference-time\ncompute, how much can it improve its performance on a challenging prompt?\nAnswering this question has implications not only on the achievable performance\nof LLMs, but also on the future of LLM pretraining and how one should tradeoff\ninference-time and pre-training compute. Despite its importance, little\nresearch attempted to understand the scaling behaviors of various test-time\ninference methods. Moreover, current work largely provides negative results for\na number of these strategies. In this work, we analyze two primary mechanisms\nto scale test-time computation: (1) searching against dense, process-based\nverifier reward models; and (2) updating the model's distribution over a\nresponse adaptively, given the prompt at test time. We find that in both cases,\nthe effectiveness of different approaches to scaling test-time compute\ncritically varies depending on the difficulty of the prompt. This observation\nmotivates applying a \"compute-optimal\" scaling strategy, which acts to most\neffectively allocate test-time compute adaptively per prompt. Using this\ncompute-optimal strategy, we can improve the efficiency of test-time compute\nscaling by more than 4x compared to a best-of-N baseline. Additionally, in a\nFLOPs-matched evaluation, we find that on problems where a smaller base model\nattains somewhat non-trivial success rates, test-time compute can be used to\noutperform a 14x larger model.", "paper_summary_zh": "\u8b93 LLM \u80fd\u5920\u900f\u904e\u4f7f\u7528\u66f4\u591a\u6e2c\u8a66\u6642\u9593\u904b\u7b97\u4f86\u6539\u5584\u5176\u7522\u51fa\uff0c\u662f\u5efa\u7acb\u4e00\u822c\u81ea\u6539\u5584\u4ee3\u7406\u7a0b\u5f0f\u7684\u91cd\u8981\u6b65\u9a5f\uff0c\u8a72\u4ee3\u7406\u7a0b\u5f0f\u53ef\u4ee5\u5728\u958b\u653e\u5f0f\u81ea\u7136\u8a9e\u8a00\u4e2d\u904b\u4f5c\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u7814\u7a76\u4e86 LLM \u4e2d\u63a8\u8ad6\u6642\u9593\u904b\u7b97\u7684\u64f4\u5145\uff0c\u91cd\u9ede\u5728\u56de\u7b54\u4e0b\u5217\u554f\u984c\uff1a\u5982\u679c\u5141\u8a31 LLM \u4f7f\u7528\u56fa\u5b9a\u4f46\u975e\u7463\u788e\u7684\u63a8\u8ad6\u6642\u9593\u904b\u7b97\u91cf\uff0c\u5b83\u53ef\u4ee5\u5728\u5177\u6311\u6230\u6027\u7684\u63d0\u793a\u4e2d\u6539\u5584\u591a\u5c11\u6548\u80fd\uff1f\u56de\u7b54\u9019\u500b\u554f\u984c\u4e0d\u50c5\u5c0d LLM \u53ef\u9054\u5230\u7684\u6548\u80fd\u6709\u5f71\u97ff\uff0c\u4e5f\u5c0d LLM \u9810\u8a13\u7df4\u7684\u672a\u4f86\u4ee5\u53ca\u5982\u4f55\u6b0a\u8861\u63a8\u8ad6\u6642\u9593\u8207\u9810\u8a13\u7df4\u904b\u7b97\u7522\u751f\u5f71\u97ff\u3002\u5118\u7ba1\u5176\u91cd\u8981\u6027\uff0c\u4f46\u5f88\u5c11\u6709\u7814\u7a76\u5617\u8a66\u4e86\u89e3\u5404\u7a2e\u6e2c\u8a66\u6642\u9593\u63a8\u8ad6\u65b9\u6cd5\u7684\u64f4\u5145\u884c\u70ba\u3002\u6b64\u5916\uff0c\u76ee\u524d\u7684\u5de5\u4f5c\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u70ba\u8a31\u591a\u9019\u4e9b\u7b56\u7565\u63d0\u4f9b\u4e86\u8ca0\u9762\u7d50\u679c\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5206\u6790\u4e86\u5169\u7a2e\u64f4\u5145\u6e2c\u8a66\u6642\u9593\u904b\u7b97\u7684\u4e3b\u8981\u6a5f\u5236\uff1a(1) \u91dd\u5c0d\u5bc6\u96c6\u7684\u3001\u57fa\u65bc\u7a0b\u5e8f\u7684\u9a57\u8b49\u5668\u734e\u52f5\u6a21\u578b\u9032\u884c\u641c\u5c0b\uff1b\u4ee5\u53ca (2) \u6839\u64da\u6e2c\u8a66\u6642\u9593\u7684\u63d0\u793a\uff0c\u81ea\u9069\u61c9\u5730\u66f4\u65b0\u6a21\u578b\u5728\u56de\u61c9\u4e0a\u7684\u5206\u4f48\u3002\u6211\u5011\u767c\u73fe\uff0c\u5728\u9019\u5169\u7a2e\u60c5\u6cc1\u4e0b\uff0c\u64f4\u5145\u6e2c\u8a66\u6642\u9593\u904b\u7b97\u7684\u4e0d\u540c\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u6703\u6839\u64da\u63d0\u793a\u7684\u96e3\u5ea6\u800c\u6709\u986f\u8457\u5dee\u7570\u3002\u9019\u500b\u89c0\u5bdf\u7d50\u679c\u4fc3\u4f7f\u6211\u5011\u63a1\u7528\u300c\u904b\u7b97\u6700\u4f73\u5316\u300d\u64f4\u5145\u7b56\u7565\uff0c\u8a72\u7b56\u7565\u7684\u4f5c\u7528\u662f\u91dd\u5c0d\u6bcf\u500b\u63d0\u793a\u81ea\u9069\u61c9\u5730\u6700\u6709\u6548\u5730\u914d\u7f6e\u6e2c\u8a66\u6642\u9593\u904b\u7b97\u3002\u4f7f\u7528\u9019\u500b\u904b\u7b97\u6700\u4f73\u5316\u7b56\u7565\uff0c\u8207\u6700\u4f73 N \u57fa\u6e96\u7dda\u76f8\u6bd4\uff0c\u6211\u5011\u53ef\u4ee5\u5c07\u6e2c\u8a66\u6642\u9593\u904b\u7b97\u64f4\u5145\u7684\u6548\u7387\u63d0\u9ad8 4 \u500d\u4ee5\u4e0a\u3002\u6b64\u5916\uff0c\u5728 FLOPs \u5339\u914d\u7684\u8a55\u4f30\u4e2d\uff0c\u6211\u5011\u767c\u73fe\u5c0d\u65bc\u8f03\u5c0f\u7684\u57fa\u790e\u6a21\u578b\u9054\u5230\u76f8\u7576\u4e0d\u5e73\u51e1\u7684\u6210\u529f\u7387\u7684\u554f\u984c\uff0c\u6e2c\u8a66\u6642\u9593\u904b\u7b97\u53ef\u7528\u65bc\u512a\u65bc\u5927 14 \u500d\u7684\u6a21\u578b\u3002", "author": "Charlie Snell et.al.", "authors": "Charlie Snell, Jaehoon Lee, Kelvin Xu, Aviral Kumar", "id": "2408.03314v1", "paper_url": "http://arxiv.org/abs/2408.03314v1", "repo": "null"}}